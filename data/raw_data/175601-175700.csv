question_id,title,body,tags
3144103,Is it possible to find $n^{th}$ derivative of $\frac{1}{e^{ax}+b}$?,"Is it possible to find $n^{th}$ derivative of $\frac{1}{e^{ax}+b}$ ? I am introduced to $n^{th}$ differentiation and leibniz theorem as a first year undergraduate.
But what i observe is there are some explicit formula for the $n^{th}$ derivative of $\sin x$ , $\cos x$ , $\log(ax+b)$ , $\frac{1}{ax+b}$ , etc but why there isn't any method given for $\sec x$ , $\csc x$ etc. If the highlighted question can be answered then it is possible to find the $n^{th}$ derivative of secx.
How ? $$y=\sec x=\frac{1}{\cos x}=\frac{2 e^{ix}}{e^{2ix}+1}$$ Now one can use lebniz theorem of $n^{th}$ differentiation to find the n derivative of product of two functions whose general derivative is known. Now here $e^{ix}$ whose derivative can be found easily. The latter part $\frac{1}{e^{2ix+1}}$ is not known.","['calculus', 'derivatives', 'algebra-precalculus']"
3144133,How does one prove that $\text{Isom}(\mathbb{S}^2 \times \mathbb{R}) = \text{Isom}(\mathbb{S}^2) \times \text{Isom}(\mathbb{R})$?,"Everywhere I'm looking a lot of authors claim (without any proof, but I'm sure they're right) that the group of isometries of $\mathbb{S}^2 \times \mathbb{R}$ and $\mathbb{H}^2 \times \mathbb{R}$ are $4$ dimensional and equal to $ \text{Isom}(\mathbb{S}^2) \times \text{Isom}(\mathbb{R})$ and $ \text{Isom}(\mathbb{H}^2) \times \text{Isom}(\mathbb{R})$ , respectively. How can I prove those claims and what's the geometric intuition behind it?","['isometry', 'riemannian-geometry', 'differential-geometry']"
3144190,Product in category of cyclic groups.,"I know that if $ G_1, G_2 $ are cyclic groups then $ G_1 \times G_2 $ is cyclic if and only if $ |G_1| $ and $ |G_2| $ are coprimes. But I have to reponds a similar question in the context of category theory: show that $ \mathbb{Z}_n $ , $ \mathbb{Z}_m $ have a product in the category of cyclic groups if and only if $ n, m $ are coprimes. For the implication $ \leftarrow \ $ I consider that $ n,m $ coprimes $ \rightarrow \mathbb{Z}_n \times \mathbb{Z}_m $ is cyclic, so this group is an element of the cateogory. Now we can take the proyection $$
p_1 : \mathbb{Z}_n \times \mathbb{Z}_m \rightarrow \mathbb{Z}_n 
,\ \ \ \
p_1(x,y) = x
$$ and $$ 
p_2 : \mathbb{Z}_n \times \mathbb{Z}_m \rightarrow \mathbb{Z}_m
, \ \ \ \
p_2(x,y) = y 
$$ that are homomorphism. Easily I can show that $ \mathbb{Z}_n \times \mathbb{Z}_m $ and $ p_1, p_2 $ form a product of $ \mathbb{Z}_n $ and $ \mathbb{Z}_m $ in the category of cyclic groups. But I am stuck in the proof of the implication $ \rightarrow $ .","['group-theory', 'category-theory']"
3144216,derivative of log(y) function. [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question I am trying to find derivative of log function. How would I apply the chain rule on a basic example? $$\ln(y)=m+bx$$ I think it is $$\frac{dy}{dx}=e^{m+bx} *b.$$ Is this correct?","['derivatives', 'logarithms']"
3144386,if $f(0) = 0$ and $f'(0) = 1$ then $f$ is positive,"I am having these two results : 
  Let $f \in C^1([0,1], \mathbb{R})$ : (1) If $f(0) = 0$ and $f'(0) >0$ then there is a $\epsilon > 0$ such that $f(x) \geq 0$ on $]0, \epsilon[$ (2) If $f(0) = f(1) = 0$ and $f$ is positive there is $\epsilon > 0$ such that $f'$ is positive on $[0, \epsilon[$ and negative on $]1-\epsilon, 1]$ Note that these are assumptions so I am not sure both these results are true. I think I might have a solution for $(1)$ using an aysmptics. Since $f$ is $C^1$ we have : $f(h) = f(0) + hf'(0) + o(h)$ in a neighboorhood of $0$ . Thus $f(h) = hf'(0) + \epsilon(h)$ where $\epsilon$ is a continuous function which goes to $0$ when $h \to 0$ .Yet since $hf'(0) = O(h)$ (since $f'(0) > 0)$ then $hf'(0) \geq \epsilon(h)$ for $h$ small enough. Hence there is an $\epsilon$ which veryfy the conditions of $(1)$ Is it correct ? 
If it's correct I am really interested in an other way of proving this result. Moreover I don't at all how to proceed for $(2)$ . Thank you.","['partial-differential-equations', 'sequences-and-series', 'ordinary-differential-equations', 'real-analysis']"
3144412,Does there always exist $x_0 \in \mathbb{R}$ such that $f(x_0) + f'(x_0)(x - x_0) + \frac{f''(x_0)}{2}(x - x_0)^2 \ge 0$ for all $x \in \mathbb{R}$? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Let $f: \mathbb{R} \to (0, \infty)$ be two times differentiable function. Does there always exist $x_0 \in \mathbb{R}$ such that $f(x_0) + f'(x_0)(x - x_0) + \frac{f''(x_0)}{2}(x - x_0)^2 \ge 0$ for all $x \in \mathbb{R}$ ?","['derivatives', 'taylor-expansion', 'real-analysis']"
3144423,Side length of the smallest square that can be dissected into $n$ squares with integer sides,"Let $s_n$ be the shortest possible side length of a square constructed from exactly $n$ squares of positive integer side lengths. If no such square exists, let $s_n = 0$ . The first few values are as follows: n | s(n)
---+------
 1 |  1
 2 |  0
 3 |  0
 4 |  2
 5 |  0
 6 |  3
 7 |  4
 8 |  4
 9 |  3
10 |  4
11 |  5
12 |  6
13 |  4
14 |  5 If we search this Integer Sequence in an Online Encyclopedia , something very remarkable happens: there is exactly one search hit . That sequence is A300001 , or in English, ""Side length of the smallest equilateral triangle that can be dissected into n equilateral triangles with integer sides, or 0 if no such triangle exists."" Do my square sequence's values agree with the triangle sequence's values? If so, why? If not, when do they first disagree? At first I thought, maybe there's some manner of bijection between my square dissections and the triangular dissections: if you halve each subsquare along its diagonals, numerically the result should fit in the entire square halved along its own diagonal. But fitting them together requires some nonobvious geometrical fiddling, and I'm not at all confident this subobject-size-preserving bijection is well defined over all dissections. Is it?","['combinatorics', 'packing-problem']"
3144460,What's wrong with this bogus proof?,What is the mistake here? Is it matter of the unit?,"['proof-verification', 'discrete-mathematics']"
3144469,"Prove that if $n,m \in \Bbb N$ then $\frac{1}{n} + \frac{1}{m} = \frac{7}{17} $ doesn't have any solutions.","Prove that if $n,m \in \Bbb N$ then $\frac{1}{n} + \frac{1}{m} = \frac{7}{17} $ doesn't have any solutions. My try I wrote the equation in $2$ forms, but i can't get anything there without analyzing a lot of cases: $1ยบ$ $\frac{17}{n} + \frac{17}{m} = 7$ $2ยบ$ $17(m+n)=7mn$ In the second case i tried to use the fact that $17$ and $7$ are primes, but i found nothing. Any hints?","['elementary-number-theory', 'algebra-precalculus', 'prime-numbers']"
3144470,Is this integral unsolvable?,"So I took an integration test in AP Calculus yesterday and everything went smoothly except for one question. $$\int \frac{e^x}{x^2}dx$$ I tried chain rule, $u$ substitution, and all methods we have since been taught. Nothing worked. Now, I really wanted to know what the answer was, so I just now plugged it into a few antiderivative/integral calculator and all but two said something along the lines of ""cannot solve."" One said $\frac{exp(x)}{x^2} + C$ . The other said $Ei(x) - \frac{e^x}{x} + C$ . A physics forum about the same integration seemed to say that it is unsolvable. I am thoroughly confused. Can anybody help clarify? Edit :
The teacher made a little error. The real question was supposed to be, which is of course much easier: $$\int \frac{e^\frac{1}{x}}{x^2}$$","['integration', 'indefinite-integrals']"
3144496,Hypersurfaces in Schwarzchild Spacetime,"The Schwarzschild Spacetime metric is  is given by : $\text ds^2=-\left(1-\frac{2M}{r}\right)dt^2+\left(1-\frac{2M}{r}\right)^{-1}dr^2+r^2(d\theta^2+\sin^2\theta\,d\phi^2)$ I am currently studying doing an extra project for an introductory GR course, I was reading the book by Eric Poisson ""A Relativist's Toolkit: The Mathematics of Black-Hole Mechanics"". And I am trying to solve exercise 1 of Chapter 3. It asks us to consider a hypersurface $T = constant$ in Schwarzschild   Spacetime, where $$T = t + 4M \Bigg[ \sqrt{\frac{r}{2M}} + {\frac{1}{2}\ln\Bigg( \frac{\sqrt{\frac{r}{2M}}-1}{\sqrt{\frac{r}{2M}}+1}   \Bigg) }     \Bigg] .$$ Use as (r, $\theta$ , $\phi$ ) as coordinates on the hypersurface. a) Calculate the unit normal $n_{\alpha}$ and find the parametric equations describing the hypersurface. I am having problem starting as I want to use the equation defined in the book 
as 3.1.4, which is $n_{\alpha} = \frac{\xi\Phi_{;\alpha}}{\mid g^{\mu\nu}\Phi_{;\mu} \Phi_{;\nu}       \mid^{\frac{1}{2}} }$ but I am not sure if my hypersurface, here denoted by $\xi$ is timelike or spacelike. I have read the introduction but I am not understanding how could I compute it. Please note $\xi$ is given in eq. 3.1.3 as $n^{\alpha}n_{\alpha} =\xi =  \Bigg\{  \pm $ 1 if $\sum$ (the hypersurface is timelike (+1) or spacelike (-1)) EDIT : I have determine the unit normal and determined the hypersurface to be spacelike. I am struggling now to determine the parametric equations. Can I use $x = r\sin\theta\cos\phi$ , $y = r\sin\theta\sin\phi$ and $z =r\cos\theta$ ? 
I am not sure how can I use the normal vector though to calculate the tangent vectors","['general-relativity', 'differential-geometry']"
3144509,How to convert a rate involving radians to something that can be applied to a straight direction in a related rates problem.,"I can do related rates problems a little bit, but I've been given one that requires me to use a rate of $\frac{-\pi}{6}$ radians per second to figure out how fast a plane is going. Since I assume that plane is moving in a straight line, I'm not sure how to proceed. I think the answer might be to find out how fast the given rate is moving in terms of horizontal speed, and then apply implicit differentiation on that to find the answer, but I'm not sure. I could use the angular velocity formula, $\omega = \frac{\theta}{t}$ , but I'm worried that's not the right way since it gives an average. How can I convert a rate with radians to a rate involving purely horizontal/straight movement? Problem Text: A plane flies horizontally at an altitude of 5 km and passes directly over a tracking telescope on the ground. When the angle of elevation is ฯ/3, this angle is decreasing at the rate of ฯ/6 radians per minute. How fast is the plane traveling at that time? I have worked through it, and I've discovered that the plane, the telescope, and the distance of the plane from the ground can be formed into a right triangle. Since, $\frac{\pi}{3}$ radians is $60^\circ$ and a right triangle has a $90^\circ$ corner too, that means the the last corner must also be $60^\circ$ . Using the Law of Sines, I have found the hypotenuse is $\frac{10\sqrt{3}}{3}$ kilometers long and the other two edges are both $5$ kilometers. I haven't been able to get further than that.","['word-problem', 'calculus', 'implicit-differentiation', 'related-rates', 'derivatives']"
3144550,How many ways can we define prime number?,"So the other day I was in an interview for a PhD program, one of the professors asked me to give the definition of a prime number . So I gave him the following usual definition- Any positive number $p>1$ is called a prime number if the only divisors of $p$ are $1$ and $p$ itself. Then he asked me what are the other definitions of a prime number? To which I had no answer as I don't know any other definition. Then he said the following- A natural number $n > 1$ is a prime number if and only if $(n-1)!=-1 (\text{mod} ~n).$ Which is basically the statement of Wilson's theorem. My question is, can we use these kind of results//theorems as definitions of prime numbers? If I say, ""for any natural number $n>1$ , if $\phi(n)=n-1,$ then $n$ is a prime, where $\phi$ is Euler's Totient function."" would also qualifies to be a definition of prime number? If so what are the other definitions of prime numbers? Thanks for any valuable input. Edit : So from the comments I got several examples, thanks for that, I got the idea. So now I want an answer to the question, can we use these kind of results//theorems as definitions of prime numbers?","['number-theory', 'definition', 'prime-numbers']"
3144560,Evaluating $\lim\limits_{x \to 0} \frac{(1+x)^{1/x} - e + \frac{1}{2}ex}{x^2}$ without expansions in limits,"Evaluate $\lim\limits_{x \to 0} \frac{(1+x)^{1/x} - e  + \frac{1}{2}ex}{x^2}$ One way that I can immediately think of is expanding each of the terms and solving like, $$(1+x)^{1/x} = e^{\log_e (1+x)^{1/x}} = e^{\frac{1}{x} (x-\frac{x^2}{2} -\frac{x^3}{3}+...)}$$ and then after complete expansion of each and every and substuting into back to limit and solving I get $\frac{11e}{24}$ as an answer. Now, this is a relatively long and complicated way to solve as you can see. I want to know if there is an easier way to solve this problem. Please help. Thank you!","['limits', 'calculus']"
3144563,Find $\displaystyle \min_{f \in \mathcal{A}} \int_{0}^{1} (1+x^{2})(f(x))^{2} dx $,"Find $$ \min_{f \in \mathcal{A}} \int_{0}^{1} (1+x^{2})(f(x))^{2} dx $$ where $$ \mathcal{A}=\left\{ f \in C[a,b] \ | \ \int_{0}^{1} f(x) dx = 1 \right\}.$$ I used the Hรถlder's inequality to try to solve the problem but I do not know how to reduce the term with $(f (x))^{4}$ , i.e, $$\int_{0}^{1} (1+x^{2})(f(x))^{2} dx 
 \leq \left( \int_{0}^{1} (1+x^{2})dx \right)^{\frac{1}{2}} \left(  \int_{0}^{1} (f(x))^{4} dx \right)^{\frac{1}{2}} $$ I appreciate any help.",['real-analysis']
3144564,Radon-Nikodym derivative of a convolution of signed measures,"I'm trying to prove the next: Let $M(\mathcal{B}_{\mathbb{R}})$ be the space of all finite measures over $(\mathbb{R},\mathcal{B}_{\mathbb{R}}).$ Let $\lambda$ be the Lebesgue measure over real numbers, and $\mu,\nu\in M(\mathcal{B}_{\mathbb{R}}).$ If $\mu<<\lambda$ then $\mu*\nu<<\lambda$ and $$\frac{d(\mu*\nu)}{d(\lambda)}=\frac{d\mu}{d\lambda}*\frac{d\nu}{d\lambda}.$$ Here $\mu*\nu$ denotes convolution between both measures. I've proved absolute continuity $\mu*\nu<<\lambda$ but I am having trouble with the equality; I don't feel comfortable with my proof: Let $f,g$ be the Radon-Nikodym derivatives of $\mu$ and $\nu,$ respectively. For each $E\in\mathcal{B}_{\mathbb{R}}$ we have $$\mu*\nu(E)=\int_{\mathbb{R}^2} 1_E(x+y)d\mu(x)d\nu(y)=\int_{\mathbb{R}^2} 1_E(x+y)f(x)d\lambda(x)g(y)d\lambda(y).$$ Utilizing variable change $t=x+y$ and the invariance of Lebesgue measure it follows: $\begin{eqnarray}
\mu*\nu(E)&=&\int\int_{\mathbb{R}^2}1_E(t)f(t-y)g(y)d\lambda(t)d\lambda(y)
= \int_{\mathbb{R}}1_E(t)\int_{\mathbb{R}}f(t-y)g(y)d\lambda(y)d\lambda(t)\\
&=& \int_{\mathbb{R}}1_E(t)f*g(t)d\lambda(t)=\int_{E}f*g(t)d\lambda(t)
\end{eqnarray}$ Then we have the desired result. However I think I am manipulating ""algebraically"" notation of Radon-Nikodym derivative which is wrong. How Could we formalize the proof? Any kind of help is thanked in advanced.","['measure-theory', 'lebesgue-measure']"
3144612,Geometry high school math competition question,"Let $ABC$ be an equilateral triangle with side length $2$ .
  Let the circle with diameter AB be $\gamma$ .
  Consider the two tangents from $C$ to $\gamma$ , and let the tangency point closer to $A$ be $D$ .
  Find the area of triangle $CAD$ . I was able to figure out that $CD$ has to be $\sqrt2$ . I can not figure out the height of triangle $CAD$ . I am trying to calculate the height from $D$ to $AC.$ Alternatively, if I could find the length of $AD$ , then I should also be able to solve problem.","['contest-math', 'euclidean-geometry', 'circles', 'geometry', 'triangles']"
3144616,Is $\sin^2+\cos^2-1=0$ the only relation for $\sin$ and $\cos$? [duplicate],"This question already has answers here : Is Pythagoras the only relation to hold between $\cos$ and $\sin$? (2 answers) Closed 5 years ago . I'm trying to figure out if for any polynomial $f$ , $f(\cos(t),\sin(t))=\sum_{i,j}a_{i,j}\cos(t)^i\sin(t)^j=0$ implies $x^2+y^2-1$ divides $f$ . Trigonometric identities are not exactly central to the class I am taking, so I believe the question simply wants me to assume this, but I'm still curious as to why it is true. In trying to prove this, I know that through polynomial division one can get $f=qg+r$ where the degree of $x$ in $r$ is 1 or 0 and $r(\cos(t),\sin(t))=0$ . If the degree of $x$ in $r$ is zero we simply have a polynomial in $\sin(t)$ , and a polynomial only has finitely many roots whereas $\sin(t)$ can take infinitely many values, so $r=0$ . If the degree of $x$ in $r$ is one, and there is only an $x$ term, one can argue that we can choose $t$ to make all the $\sin$ terms arbitrarily small and the $\cos$ term close to 1, and if the constant term is equal to -1 just stop close to 1, and if it is close to -1 stop at 1. However, I don't know how to proceed when there are terms like $xy$ in $r$ . I was thinking of looking at it as $x$ times a polynomial in $y$ plus a polynomial in $y$ , but I'm not sure if that helps. I'm sure there is a more simple way to do this that I'm not seeing, any hints?","['trigonometry', 'polynomials']"
3144655,Recovering a matrix from a linear ODE given observations,"To make this simple, let's say we have $x: \mathbb{R} \rightarrow \mathbb{R}^2$ such that $$\frac{d}{dt}\vec{x}(t) = \begin{pmatrix} x_1'(t) \\ x_2'(t) \end{pmatrix} = A \vec{x}(t)$$ for some constant matrix $A$ . We know that the general solution has the form $$\vec{x}(t) = e^{A t} \begin{pmatrix}x_1(0) \\ x_2(0) \end{pmatrix},$$ where $e^{At}$ denotes the matrix exponential . Suppose we are given $\vec{x}(0)$ and also have the observations $$\hat{x}(t_1), \ldots, \hat{x}(t_k) $$ for some known collection $\{t_i\}_{i=1}^k.$ Right now, we don't worry about whether the observations are noisy; we just assume they are perfect. The goal is to recover the matrix $A$ , rather than $\vec{x}(t)$ . All we know is that $A$ is constant. This is stumping me, because it seems so simple; however, the standard matrix differential equation techniques (e.g. here ) usually assume that $A$ is given. One option numerically is to define the error function $$ err(A) = \sum_{i=1}^k \| \vec{x}(t_i,A) - \hat{x}(t_i)\|^2 $$ for the given $\{t_i\}_{i=1}^k$ and compute $$ \min_{A \in \mathbb{R}^{2 \times 2}} err(A) $$ in $\texttt{Matlab}$ (or some other program). However, I keep getting incorrect/unstable results, which is worrisome since $A$ is only $2 \times 2$ . In general, I am not even sure what it means to minimize $err(A)$ with respect to a matrix , so I also do not understand what $\texttt{Matlab}$ is doing from a theoretical standpoint in this computation. How can one recover the matrix $A$ theoretically or via some brute-force algorithm -- and if the latter is used, why does that algorithm converge to or output the correct $A$ ?","['numerical-methods', 'numerical-optimization', 'ordinary-differential-equations']"
3144663,When does the recurrence $a_k = 3a_{k - 1} + 1$ reach a power of 2?,"Almost a year ago, I posed a question on Brilliant involving the following recurrence: Given $n$ , let $a_0 = n$ and $a_k = 3a_{k - 1} + 1$ . That question asked whether for any choice of $n$ , the sequence generated by this recurrence always contained a power of 2. (The answer is no, see below for examples). It is useful to put this problem in Diophantine equation form. Since $a_k = 3^kn + (3^k - 1)/2$ (easily shown by induction), if $a_x = 2^y$ at some point, we have the Diophantine equation $$2^{y + 1} + 1 = 3^x(2n + 1).$$ I thought an interesting problem would be to classify values of $n$ for which the sequence never reaches a power 2. Did a bit of computer checking up to $n < 10^8$ , and I was surprised to see that for most values of $n$ , they do not reach a power of 2 for $a_k < 1 \text{ googol}$ , and when they do, do so within the first handful of sequence elements. ( Computational results here. ) Low-hanging fruit: Trivial case: If $n = 2^x$ , $a_0$ is a power of 2. For $n > 2$ , if $n \equiv 2,3 \pmod{4}$ , then $a_k \mod 4$ cycles between 2 and 3 (for consecutive terms in the sequence), and thus will never be divisible by 4, and so will never reach a power of 2 greater than 2. So, for $n > 2$ , we only need to consider the case where $n \equiv 0,1 \pmod{4}$ . For $k > 0$ , $a_k \equiv 1 \pmod{3}$ , so $a_k \neq 2^{2m + 1} \equiv -1 \pmod{3}$ for positive $k$ . In other words, if we look past the trivial case, we are actually looking for powers of 4. For $n = (3^z - 1)/2$ where $z > 2$ , the equation above implies $2^{y + 1} + 1 = 3^{x + z}$ , whereupon Mihฤilescu's theorem (Catalan conjecture) stipulates $y + 1 = 3$ and $x + z = 2$ . In particular, since $x \geq 0$ , $z \leq 2$ , contra $z > 2$ in our assumption. So for such $n$ , the sequence contains no power of 2. But, my question is whether there is a known complete characterization of $n$ such that the sequence starting with $a_0 = n$ contains no powers of 2. To be specific, I think I will define ""complete characterization"" to mean an algorithm (with finite resources, including time) which when given an $n \in \mathbb{N}$ , determines whether the sequence $a_0, a_1, \dots$ contains a power of 2. Put another way, I am looking for a predicate $P$ for which the following statement is true: $\forall n : [(a_0 = n \wedge P(n)) \Leftrightarrow \forall x,y : a_x \neq 2^y]$ . Please let me know if anything requires clarification/elaboration.","['number-theory', 'perfect-powers', 'recurrence-relations', 'diophantine-equations']"
3144672,"Simplifying $\prod\limits_{k\neq j=0}^{n-1}\frac1{\lambda_{n,k}-\lambda_{n,j}}$ for $\lambda_{n,k}=\exp\frac{i\pi(2k+1)}{n}$","I have been able to show that for $n\in\Bbb N_{\geq2}$ $$\phi(n)=\int_0^1\frac{dx}{x^n+1}=\sum_{k=0}^{n-1}\Gamma_{n,k}\log\frac{\lambda_{n,k}-1}{\lambda_{n,k}}$$ Where $$\lambda_{n,k}=\exp\frac{i\pi(2k+1)}{n}$$ And $$\Gamma_{n,k}=\prod_{k\neq j=0}^{n-1}\frac1{\lambda_{n,k}-\lambda_{n,j}}$$ And I was wondering: how do we simplify $\Gamma_{n,k}$ to ease the manual calculation of $\phi(n)$ values. The integral is always real, so I am sure there is a major way we can simplify $\Gamma_{n,k}$ , but I have been so far unable to find it. I do suspect however that the product $$P_n=\prod_{k=0}^{n-1}\Gamma_{n,k}$$ May play a significant role in finding the simplification I seek. For those interested, a proof. Note that $x^n+1$ bay be factored as $$x^n+1=\prod_{k=0}^{n-1}(x-\lambda_{n,k})$$ Hence $$\phi(n)=\int_0^1\prod_{k=0}^{n-1}\frac1{x-\lambda_{n,k}}dx$$ Then define $\Gamma_{n,k}$ by saying that $$\prod_{k=0}^{n-1}\frac1{x-\lambda_{n,k}}=\sum_{k=0}^{n-1}\frac{\Gamma_{n,k}}{x-\lambda_{n,k}}$$ Multiplying both sides by $\prod_{j=0}^{n-1}(x-\lambda_{n,j})$ : $$1=\sum_{k=0}^{n-1}\frac{\Gamma_{n,k}}{x-\lambda_{n,k}}\prod_{j=0}^{n-1}(x-\lambda_{n,j})$$ $$1=\sum_{k=0}^{n-1}\Gamma_{n,k}\prod_{k\neq j=0}^{n-1}(x-\lambda_{n,j})$$ So for any integer $0\leq m\leq n-1$ we may plug in $x=\lambda_{n,m}$ and simplify to get $$\Gamma_{n,m}=\prod_{m\neq j=0}^{n-1}\frac1{\lambda_{n,m}-\lambda_{n,j}}$$ And our result follows directly. Perhaps another motivation for easing manual calculation of this product would be that $$\sum_{k=0}^{\infty}\frac{(-1)^k}{nk+1}=\phi(n)$$ Which brings about a plethora of interesting closed forms. Edit: A little progress We define $$c_{n,j}=\operatorname{Re}\lambda_{n,j}=\cos\frac{\pi(2j+1)}{n}$$ And $$s_{n,j}=\operatorname{Im}\lambda_{n,j}=\sin\frac{\pi(2j+1)}{n}$$ So $$\log\frac{\lambda_{n,k}-1}{\lambda_{n,k}}=\log\left(1-\lambda_{n,k}^{-1}\right)=\log\left(1-c_{n,k}+is_{n,k}\right)$$ And we also see that $$\begin{align}
\prod_{k\neq j=0}^{n-1}\frac1{\lambda_{n,k}-\lambda_{n,j}}&=\prod_{k\neq j=0}^{n-1}\frac1{e^{i\pi(2k+1)/n}-e^{i\pi(2j+1)/n}}\\
&=\prod_{k\neq j=0}^{n-1}\frac{e^{-i\pi(2k+1)/n}}{1-e^{i\pi(2j-2k)/n}}\\
&=e^{i(2k+1)(2-n)/n}\prod_{k\neq j=0}^{n-1}\frac12\left(1+i\cot\frac{\pi(j-k)}n\right)\\
\Gamma_{n,k}&=\frac{\lambda_{n,k}^{2-n}}{2^{n-2}}\prod_{k\neq j=0}^{n-1}\left(1+i\cot\frac{\pi(j-k)}n\right)
\end{align}$$ But the remaining product I do not know how to deal with.","['definite-integrals', 'closed-form', 'products', 'sequences-and-series', 'complex-numbers']"
3144688,Mean concentration implies median concentration,"Exercise 2.14 in Wainwright, ""High-Dimensional Statistics"", states that if $X$ is such that $$P[|X-\mathbb{E}[X]|\geq t] \leq c_1 e^{-c_2t^2},$$ for $c_1, c_2$ positive constants, $t\geq 0$ , then for any median $m_X$ it holds that $$P[|X-m_X|\geq t] \leq c_3 e^{-c_4t^2},$$ with $c_3=4c_1$ and $c_4=c_2/8$ . I can get some loose concentration around the median using $|\mathbb{E}[X]-m_X|\leq \sqrt{\mathbb{V}[X]}$ , but this does not achieve the constants proposed. Any ideas for how to get the suggested bound, or any other bound resembling it?","['statistics', 'concentration-of-measure', 'median']"
3144707,Prove or disprove sentence about $\int f$,"I post this question a few months ago. I solved the items (1) and (3), but I cannot to solve (2). Today I read this question again and I'm curious about solution of (2). Today, I had an idea, but I dont know if it works. Idea . A monotone function has only jump discontinuities. So, $f|_{[f(x_{0}^{-}),f(x_{0}^{+})]}$ is continuous, then there is a maximum and minimum. If $w$ is a minimum on $[f(x_{0}^{-}),f(x_{0}^{+})]$ , then $$w \leq f(x) \Longrightarrow w(x-x_{0}) \leq \int_{x_{0}}^{x}f(t)dt = F(x) - F(x_{0})$$ taking, WLOG, $x \geq x_{0}$ . But, this works for $f$ on $[f(x_{0}^{-}),f(x_{0}^{+})]$ . What about the general case?","['derivatives', 'real-analysis']"
3144732,"Minimal ""dominating"" rank-$1$ matrix","Given a matrix ${\bf A} \in \Bbb R^{n \times n}$ , I would like to find a minimal  rank- $1$ matrix ${\bf B} \in \Bbb R^{n \times n}$ such that the Frobenius norm of $ \| {\bf A} - {\bf B} \|_{\text{F}} $ is minimal under the constraint of $ a_{ij} \leq b_{ij}$ for all $i, j \in \{ 1, \dots, n \}$ . Also, is there a name for the element-wise  ""domination"" constraint?","['matrices', 'optimization', 'linear-algebra', 'rank-1-matrices']"
3144760,How is $\frac{dx }{z(x+y) } = \frac{dy}{z(x-y) } = \frac{dz }{x^2 + y^2 } $ equivalent to $\frac{ y dx + xdy - zdz}{0}=\frac{ xdx - ydy -zdz}{0}$?,"In the book of PDE by Kumar, it is given that However, I couldn't figure out how is $$\frac{dx }{z(x+y) } = \frac{dy}{z(x-y) } = \frac{dz }{x^2 + y^2 }  $$ is equivalent to $$\frac{ y dx + xdy - zdz}{0 } = \frac{ x dx - y dy -z dz}{ 0}  .$$","['ordinary-differential-equations', 'partial-differential-equations']"
3144768,Martingale convergence theory question,"I'm confused on what this proof would look like. I know that by Martingale Convergence Theorem: $$X= \lim Z_n / \mu^n$$ exists a.s. I also know that Kesten Stigum Theorem: Assume that $E[L] >1$ and that $p_1 \neq 1$ . Then $X>0$ a.s. on the event of survival iff $E[L\log_{+} L] < \infty$ Is that theorem useful in proving what i want to prove? Edit: Let $\xi{i}^n , i, n, \geq 1$ be i.i.d. nonnegative integer random variables. Define a sequence $Z_n, n \geq 0 $ by $Z_0 =1$ and $Z_{n+1} = \xi_1^{n+1}+...+ \xi_{Z_n}^{n+1}$ if $Z_n >0$ , $0$ if $Z_n=0$ $Z_n$ is the galton-watosn process. $ \mu = E\xi_m^i \in (0,\infty)$","['martingales', 'measure-theory']"
3144813,$\| X'(t) \| = (\| X(t) \|)'$,Let $X : \mathbb{R} \to \mathbb{R}^n$ be a $C^1$ function. Let $\| .\|$ be the norm : $\| v \| = \max_{1 \leq i \leq N} \mid v_i \mid$ . Then is it true that : $$\| X'(t) \|  = (\| X(t) \|)'$$ ? I am wondering if in general if I have any function $f : \mathbb{R}^n \to \mathbb{R}^p$ and a norm $N$ on a : $\mathbb{R}^p$ then is it always possible to invert the norm and the differential operator or the norm and in the integral? Thank you.,"['normed-spaces', 'derivatives', 'real-analysis']"
3144840,An inequation about real pairwise commuting matrices,"Let A and B be two real $n\times n$ matrices such that $AB=BA$ . Itโs known that $\det(A^2+B^2)\geq 0$ . I wonder if itโs true that: For $k$ pairwise commuting real matrices $A_1,\cdots,A_k$ ,we have: $\det(\sum_{i=1}^{k}A_{i}^2)\geq0$ .","['matrices', 'determinant', 'linear-algebra']"
3144881,Find the formula for the sum: $1+3x^2+5x^4+7x^6+...+(2n+1)x^{2n}$,"The formula is supposed to be valid for $x \neq \pm 1$ . Here is how I did it: $$\bar{S}_n = \frac{d}{dx}\left( x+x^3+x^5+...+x^{2n+1} \right)$$ The term in the brackets is the geometric sequence. So call the sum up to term $x^{2n+1}$ as $S_n$ , then: $$S_n = \frac{x(1-x^{2n})}{1-x^2}$$ and so: $$\bar{S}_n = \frac{d}{dx} \left( S_n \right)$$ which gives me: $$\frac{2x^2 (1-x^{2n})}{(1-x^2)^2}+\frac{1}{1-x^2}\left( 1-x^{2n}(1+2n) \right)$$ apparently, that's wrong. Embarrassing I cannot solve such a simple problem.","['derivatives', 'sequences-and-series']"
3144897,Example of a locally compact + Hausdorff + ยฌnormal + connected space,"Playing with $\pi$ -base for a while, I found that all locally compact Hausdorff second-countable spaces are regular, but this search lacks counterexamples: In fact, only four spaces on $\pi$ -base satisfy the first three properties. My question is: Can we prove or disprove the existence of a locally compact + Hausdorff +  ยฌnormal + connected space? Many thanks! Related: https://mathoverflow.net/questions/53300/locally-compact-hausdorff-space-that-is-not-normal","['connectedness', 'examples-counterexamples', 'separation-axioms', 'general-topology', 'compactness']"
3144905,What does it mean for partial derivative to exist but not continuous?,What does it mean for partial derivative to exist but not continuous? Continuous partial derivatives imply differentiability and differentiability imply continuity of a function and the existence of partial derivatives. I also understand that any other implication of this statement is false.,"['continuity', 'multivariable-calculus']"
3144912,"In how many ways can 9 different books and 17 identical cakes be divided on 6 children, so that each child receive at least one book and one cake?","I'm trying to learn how to count but I'm having some problem. The problem: In how many ways can $9$ different books and $17$ identical cakes be divided on $6$ (different) children, so that each child receive at least one book and one cake? I got: The number of ways to divide $6$ different books on $6$ different children is the same as finding all surjective functions from a set $X$ , with $|X|=9$ to set $Y$ , where $|6|$ . The number is $6!รS(9,6)$ . The number of ways to divide $17$ identical cakes on $6$ different children (here is where I am wrong) should in my mind be, after you give out one cake to each child, an unordered sequence with repetition: $\binom{11+6-1}6$ . However this is wrong, the right answer here is $\binom{11+6-1}5$ . Can someone please explain that last step to me?","['combinatorics', 'discrete-mathematics']"
3144925,Ergodic transformation on a atomless measure space,"I am currently reading KakutaniโRokhlin lemma and faced a problem which is given below :--- Let $(X,\mathscr B,\mu,T)$ be an invertible measure preserving system such that $\mu(\{x\})=0,\forall x\in X$ . Suppose $T$ is ergodic we have to show, $$\mu\bigg(\bigcup_{k\in \Bbb Z,k\not=0}\{x\in X:T^k(x)=x\}\bigg)=0.$$ I don't how do I start with this problem. Any help will be appreciated.","['measure-theory', 'ergodic-theory']"
3144959,Is $X+Y$ regularly varying at zero if $X$ and $Y$ are and are independent?,"Imagine it holds that $$\lim\limits_{t \to 0}F(tx)/F(t)=x^\alpha,$$ where $F$ is the cdf of $X$ respectively $Y$ and $\alpha>0$ . Does it then also hold that $$\lim\limits_{t \to 0}F_{X+Y}(tx)/F_{X+Y}(t)=x^\beta,$$ for some $\beta>0$ ? It is a well known fact that this is true if $X$ and $Y$ are regularly varying at infinity(Then X+Y is regularly varying at infinity as well with the same $\alpha$ ), however it is not possible to easily adapt this result to this problem","['probability-distributions', 'probability-theory']"
3145079,The set of differentiable functions $f:M \to \mathbb{R}$ whose domains include a given point $m\in M$ doesn't form an algebra?!,"I am reading the book ""Differentiable Manifolds"" by Brickell and Clark. on page 54, it  is written that:If we denote the set of differentiable functions $f:M \to \mathbb{R}$ on a manifold $M$ whose domains include a given point $m\in M$ by $\mathcal{F}(m)$ , then $\mathcal{F}(m)$ does not form a vector space over the set of real number $\mathbb{R}$ . And that is because $\mathcal{F}(m)$ does not contain a function $-f$ such that $f + (-f) = 0$ for all $f\in \mathcal{F}(m)$ ! I'm confused a little bit. Because if a function $f$ is defined at a point $m\in M$ , then $-f$ is also defined at $m$ . Am i making a mistake? Thanks for any help.","['smooth-manifolds', 'differential-geometry']"
3145082,Compute number of combinations,"I got really stuck with this task: Nine of ten cards, among which there is an ace of hearts, are
  distributed to three players so that the first one receives 3, the
  second - 4, and the third - 2 cards. How many cards combinations exist,
  where an ace of hearts gets to a third player? I think that number of combinations formula is $c_{9}^{1} * c_{3}^{1} * c_{2}^{1} = 6$ Am I right? I will be so grateful for your help!)","['combinatorics', 'card-games', 'discrete-mathematics']"
3145151,Implicit multivariable differentiation with Jacobian matrix,"Two functions $u = u(x,y)$ and $v = v(x,y)$ are defined by the system of equations: $$u-v=x-y$$ $$yu-xv=1$$ The problem asks for the partial derivatives $\frac {\partial u} {\partial x},~ \frac {\partial u} {\partial y},~ \frac {\partial v} {\partial x},~\frac {\partial v} {\partial y}$ and the added picture below is showing my solution using a Jacobian matrix. We have received the our professor's solution and he solved the system manually without the Jacobian by solving the system simultaneously. It seems I have got the correct answer for both partials with respect to x. But the partials with respect to y are seemingly not. In his solution $\frac {\partial u}{\partial y}=\frac {u-x}{x+y}$ and $\frac {\partial v}{\partial y}=\frac{u+y}{x+y}$ I don't understand why my method worked for the partials with respect to x, but not with respect to y. How can that be? If both are wrong, then fine, there must be some mistake, but one is correct one is not with the same method? What am I missing? Thanks in advance for any help on this. $$\\$$","['matrices', 'multivariable-calculus']"
3145178,Measurability of maximal functions,"I have been reading Fourier Analysis by J. Duoandikoetxea. I got stuck on proving the measurability of maximal functions. The general maximal function/operator in this book is from the following proposition: The theorem as it is stated is, in my opinion, simply false; I don't see how $T^*f$ is measurable. (PS. The definition is that $T_t$ and $T^*$ should map $L^p$ functions to measurable functions $X\to\mathbb{C}$ .) Incidentally: Well, the proof of this particular theorem carries over verbatim if we use Lebesgue outer measure instead. However, later in the book the Marcinkiewicz interpolation theorem is used for these maximal functions, so it seems that we have to prove its measurability... For specific functions (such as the famous HardyโLittlewood maximal function), the measurability can be proved directly (in this case, one observes that it suffices to take rational $t$ ). In general, I need the measurability of the following type of maximal functions (as is used later in the book): Let $\phi\in L^1(\mathbb{R}^n)$ such that $\int\phi=1$ . Let $\phi_t=t^{-n}\phi(x/t)$ . Then $T^*f(x):=\sup_{t\in\mathbb{R}}|\phi_t*f(x)|$ is measurable. Is this true?","['measure-theory', 'fourier-analysis', 'harmonic-analysis', 'lebesgue-integral', 'real-analysis']"
3145187,How can I prove that $(a_1+a_2+\dotsb+a_n)(\frac{1}{a_1}+\frac{1}{a_2}+\dotsb+\frac{1}{a_n})\geq n^2$ [duplicate],"This question already has answers here : Prove that $\left(\sum^n_{k=1}x_k\right)\left(\sum^n_{k=1}y_k\right)\geq n^2$ (8 answers) Closed 5 years ago . I've been struggling for several hours, trying to prove this horrible inequality: $(a_1+a_2+\dotsb+a_n)\left(\frac{1}{a_1}+\frac{1}{a_2}+\dotsb+\frac{1}{a_n}\right)\geq n^2$ . Where each $a_i$ 's are positive and $n$ is a natural number. First I tried the usual ""mathematical induction"" method, but it made no avail, since I could not show it would be true if $n=k+1$ . Suppose the inequality holds true when $n=k$ , i.e., $(a_1+a_2+\dotsb+a_k)\left(\frac{1}{a_1}+\frac{1}{a_2}+\dotsb+\frac{1}{a_k}\right)\geq n^2$ . This is true if and only if $(a_1+a_2+\dotsb+a_k+a_{k+1})\left(\frac{1}{a_1}+\frac{1}{a_2}+\dotsb+\frac{1}{a_k}+\frac{1}{a_{k+1}}\right) -a_{k+1}\left(\frac{1}{a_1}+\dotsb+\frac{1}{a_k}\right)-\frac{1}{a_{k+1}}(a_1+\dotsb+a_k)-\frac{a_{k+1}}{a_{k+1}} \geq n^2$ . And I got stuck here. The question looks like I have to use AM-GM inequality at some point, but I do not have a clue. Any small hints and clues will be appreciated.","['inequality', 'analysis']"
3145200,Confusion in this limits problem,"Evaluate $$\lim\limits_{n\to \infty} \frac{1^2 + 2^2 +...+n^2}{n^3}$$ This is the original method to solve this is: Taking summation of the square numbers $1^2 + 2^2 + 3^2 +...+n^2 = \frac{1}{6}n(n+1)(2n+1)$ $$\lim\limits_{n\to \infty} \frac{1^2 + 2^2 +...+n^2}{n^3} = \frac{\frac{1}{6}n(n+1)(2n+1)}{n^3}$$ $$=\lim\limits_{n \to \infty} \frac{(n+1)(2n+1)}{6n^2} = \lim\limits_{n\to \infty} \frac{1}{6}(1+\frac{1}{n})(2+\frac{1}{n})$$ $$=\frac{2}{6} = \frac{1}{3}$$ But when looking at the limit in a different angle I get a different answer, $$\lim\limits_{n\to \infty} \frac{1^2 + 2^2 +...+n^2}{n^3} = \lim\limits_{n\to \infty} \frac{1^2}{n^3}+\frac{2^2}{n^3}+...+\frac{1}{n}$$ $$=0+0+...+0 = 0$$ Both the method seem right to me, but why I am getting different answers? What have I done wrong? Please Explain. Thank you!","['limits', 'calculus', 'summation']"
3145242,Parametrization of unitary matrices,Does anyone know a simple way to parametrize the space of $n\times n$ complex unitary matrices into a set of independent complex numbers in some complex-rectangle? Specifically the mapping and inverse mapping that does this. Like a generalized Euler angle.,"['unitary-matrices', 'reference-request', 'matrices', 'linear-algebra', 'complex-numbers']"
3145245,The definition of the tangent vector of a manifold,"In many textbooks of differential manifold, authors usually define the tangent vector on a manifold as below: Definition : Suppose $m$ is a $n$ -dimensional smooth manifold, $x\in M$ , the tangent vector of smooth manifold $M$ at point $x$ , if map $v: C_x^\infty\rightarrow\mathbb{R}$ is applied to all of the conditions below: (1) $\forall f,g\in C_x^\infty, v\left(f+g\right)=v\left(f\right)+v\left(g\right)$ ; (2) $\forall f\in C_x^\infty, \forall \lambda\in\mathbb{R}, v\left(\lambda f\right)=\lambda\cdot v\left(f\right)$ ; (3) $\forall f,g\in C_x^\infty, v\left(f\cdot g\right)=f\left(x\right)\cdot v\left(g\right)+g\left(x\right)v\left(f\right).$ My questions are: (1)Why donโt we use the definition in the Euclidean space (treat a manifold as embedded in an Euclidean)? And why do we define a new one above? (2)Whatโs the idea or the purpose of giving the definition above? (3)How to treat the tangent vector in the Euclidean space as a particular case of the def. above? Thanks of your attention to these questions and your opinions about them!","['geometry', 'smooth-manifolds']"
3145329,Eigenvalues of a $A^T A$,"Given the matrix of order $1\times{n}$ , $A=(a_1, a_2, ..., a_n)$ , where $a_i$ are real;
The question is to find all eigenvalues of $A^T A$ . I have proved that it is a non-invertible matrix, therefore $0$ is one of the values.
And the product matrix is an $nxn$ matrix with the diagonal elements being $a_1^2, a_2^2,...,a_n^2$ .
I am struggling with finding the other eigenvalues, tried by calculating the det of $A - aI$ , but didn't go anywhere.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
3145334,Similarity between $e^x$ power series and Gamma function integral?,"The power series for $e^x$ is as follows. $$e^{x} =\sum ^{\infty }_{n=0}\frac{x^{n}}{n!}$$ If we define $n! = \Gamma(n+1)$ , then we have $$n!=\int ^{\infty }_{0} x^{n} e^{-x} dx.$$ An extremely surface level observation is that if we compare the summand/integrand of each equation to their corresponding left-hand-sides, we end up with the following correspondences. $$e^x \longleftrightarrow \frac{x^n}{n!} \hspace{2 in} n! \longleftrightarrow \frac{x^n}{e^x}$$ Very naรฏvely, one could make the observation that the correspondence on the left looks like an algebraic manipulation of the correspondence on the right (multiply both sides by $n!$ and divide by $e^x$ ). Is this merely coincidence or is there some deeper connection here?","['improper-integrals', 'factorial', 'gamma-function', 'calculus', 'exponential-function']"
3145342,"Maximum of $\int_a^b \frac{f(x)}{x}\,\mathrm dx$","Let $b>a>0$ and $M>0$ be fixed. Let $F$ be the set of all functions $f:[a,b]\to[-M,M]$ such that $$\int_a^bf(x)\,\mathrm dx=0.$$ Find $$\max_{f\in F}\int_a^b\frac{f(x)}x\,\mathrm dx.$$ I tried to use the CBS inequality for integrals for the functions $(f(x))^2$ and $\dfrac{1}{x^2}$ , but when I tried to find the equality case, the function $f(x)=\dfrac{k}{x}$ I got did not satisfy $\displaystyle\int_a^bf(x)\,\mathrm dx=0$ . So the maximum must be lower than what I found. But I do not know anything about the continuity of $f$ and I don't know how to continue.","['inequality', 'definite-integrals', 'real-analysis']"
3145363,Is the free product of residually finite groups always residually finite?,"Suppose groups $G$ and $H$ are residually finite. Does that imply, that $G \ast H$ is residually finite? What have I tried to prove this: Suppose, $a = g_1h_1g_2h_2โฆg_nh_n \in G \ast H$ , $g_1, .. g_n \in G$ , $h_1, โฆ , h_n \in H$ and $b = g_1g_2โฆg_n \neq e$ , then the natural homomorphism $\alpha: G \ast H \to \frac{G \ast H}{\langle \langle H \rangle \rangle} \cong G$ maps $a$ to $b$ . Now suppose, that $\beta$ is the homomorphism from $G$ to a finite group $K$ , such that $\beta(b)$ is non-trivial (such homomorphism exists as $G$ is residually finite). Then $\beta \alpha$ is the homomorphism that maps $a$ to a non-trivial element of a finite group. The same arguments can be applied in case, when $h_1h_2 โฆ  h_n \neq e$ . However, I do not know, what to do in case, when $g_1g_2โฆg_n = h_1h_2 โฆ  h_n = e$ .","['group-homomorphism', 'infinite-groups', 'abstract-algebra', 'free-product', 'group-theory']"
3145415,Any affine conic is isomorphic to $V(y-x^2)$ or $V(xy-1)$,"I'm trying to solve the above exercise in Ghatmann's notes on algebraic geometry. I tried to consider the real case and I suspect that X1 should correspond to a plane that intersects with exactly one of the cones, whereas X2 is the case in which both cones are intersected (not at the origin). Next i tried to look at the general case of a quadratic polynomial in two variables to see what happens if I act on it with an affine change of coordinates(i.e. linear transformation followed by translation), this quickly got very complicated. My guess is that I need to figure out how the irreducibility condition affects the general equation, and maybe extend the intuition I gained for the real case to arbitrary fields(of characteristic $\ne$ 2). However, right now I'm kind of stuck, so any help would be appreciated. Thanks. Note that the field $K$ is assumed to be algebraically closed.","['algebraic-geometry', 'abstract-algebra', 'conic-sections', 'commutative-algebra']"
3145419,"Is there an explicit function mapping $2^n+2^m$ to $(n,m)$?","We know that the number $2^n+2^m$ is unique for $n,m\in\mathbb{N}$ . Is there any explicit way of writing a function $\sigma:\mathbb{N}\to\mathbb{N}^2$ such that $$
\sigma(2^n+2^m)=(n,m),
$$ for all $n,m\in\mathbb{N}$ ? Remark (edit): Here, $(n,m)$ is to be interpreted as the unordered pair $\{n,m\}$ , since I'm only interested in the pair. More specifically, I want to find functions $\sigma,f$ and $g$ such that $$
\sigma(k)=(g(k),f(k)),
$$ where $k=2^{g(k)}+2^{f(k)}$ , $\forall k \in\mathbb{N}$ .","['elementary-number-theory', 'functions']"
3145430,"If A is a real non-singular square matrix, then there exists a real matrix $B$ such that $e^B$ $=$ $A^2$","If we consider the matrix exponential map on $M_n(\mathbb R)$ , then what will be the image set of the exponential map? I have seen this . From there I can say that $exp(M_n(\mathbb C))=GL_n(\mathbb C)$ . But what about the set $exp(M_n(\mathbb R))$ ? In the exercise 66 of this link I have $exp(M_n(\mathbb R))\neq GL_n(\mathbb R)$ . Even it says that : If A is a real non-singular square matrix, then there exists a real matrix B such that $e^B=A^2$ How can I prove this statement? 
Any help please. Thanks in advance.","['matrices', 'group-theory', 'matrix-exponential', 'linear-algebra']"
3145457,Is the limit of the spectral radius the spectral radius of the limit?,"Let $A$ be an unital Banach algebra, $x \in A$ and $(x_n)$ a sequence in $A$ converging to $x$ . I want to show that $$ \lim\limits_n \rho (x_n) = \rho (x).$$ I can show that $$\limsup \rho(x_n) \leq \rho(x)$$ for every Banach algebra. In addition, if A is a commutative algebra, it's easy to prove that $$\liminf \rho(x_n) \geq \rho(x),$$ so the proposition it's true in commutative Banach algebras. Can we prove it when A is non commutative? If it's not, how can we show a counterexample? I've tried to build some counterxamples in the space of non-singular matrix, but nothing seems to work. My other idea is consider the Banach algebra of operators defined in some Hilbert/Banach space, but the spectral radius is a bit difficult to calculate. Anyone can help me? Thank you very much.","['operator-algebras', 'operator-theory', 'banach-algebras', 'functional-analysis', 'spectral-theory']"
3145466,Convex hull of a compact in $R^n$ is compact,"Show that if $A \subset \mathbb{R}^n$ is compact then the convex hull of $A$ is compact. Solution: $A \subset \mathbb{R}^n$ is compact then is limited and closed, therefore $A \subset B_{[0,r]}$ (Ball closed center $0$ and radius $r$ ) for some $r>0$ . Since $B_{[0,r]}$ is convex and $Conv(A)$ is the least convex that contains $A$ : $Conv(A) \subset B_{[0,r]}$ . It remains to show that $Conv (A)$ is closed, how do I do this?","['general-topology', 'functional-analysis', 'real-analysis']"
3145509,Characterisation of permutation matrices,"$\newcommand\mat{\mathbf}$ A permutation matrix is a matrix whose columns are a permutation of the columns of the identity matrix $\mat I$ . In other words, a permutation matrix is a matrix $\mat P$ with precisely one $1$ per row/column and zeros everywhere else. A few easy observations about permutation matrices are: $\mat P^{-1} = \mat P^\mathsf{T}$ (orthogonality) $\mat P\mat 1 = \mat P^\mathsf{T}\mat1= \mat 1$ (doubly stochastic), where $\mat 1 = (1,\dots,1)$ is the all-ones vector Eigenvalues are $e^{2i\pi k/n}$ for $k=1,\dots,n$ , where $n$ is the least positive integer such that $\mat P^n = \mat I$ . But I don't think these three properties suffice to characterise permutation matrices, and the latter two aren't too nice to work with anyway. Is there a nice set of equations one can work with which completely capture the behaviour of permutation matrices?","['permutations', 'permutation-matrices', 'matrices', 'abstract-algebra', 'linear-algebra']"
3145521,Newton law of cooling with variable surrounding temperature.,"Newton law of cooling is a very popular law of nature to study for first differential equation in high school. It says that an object's temperature rate of change (time derivative) is proportional to the difference of temperatures of object and surrounding. $$\frac{\partial{T}}{\partial t} = k(T(t)-T_s)$$ Usually here $T_s$ (Temperature of (s)urrounding) is assumed constant. But what happens if $T_s$ is not constant? For example let us model outdoor temperature as a cosine with minimum at midnight: $$T_s(t) = 20-10\cos\left(\frac{2\pi t}{24}\right)$$ This could be a typical Swedish summer day, temperature between $10$ and $30$ degrees (celcius). Assume at a party someone forgets a beer at pre-party $t=22$ in evening ( $10$ pm ) but finds it again at after-party $t=26$ ( $2$ am ). How can we approach this problem of calculating how much warmer the beer has gotten ( in other words of solving $T(t)$ )?","['physics', 'calculus', 'soft-question', 'ordinary-differential-equations']"
3145533,Determine the value for the constant c that makes the probability statement correct?,"$P(c \le |Z|) = 0.016$ where Z is normally distributed . I know that this means that either $Z \ge c$ or $Z \le -c$ , but I'm not sure how to use this to find the value of c.","['statistics', 'probability']"
3145590,$x^5 + x^4 +1$ to be a perfect square,"Find all positive integers x such that $x^5 + x^4 +1$ is a perfect square. My progress: factoring gives $(x^3-x+1)(x^2+x+1)$ . The gcd of the factors is 1 or 7 and the first case is easily ruled out.
But what if both multipliers are 7 times a square? Any help appreciated.","['number-theory', 'diophantine-equations']"
3145591,Continuous function with $f(x^m+y^n) \le f(x+y) $,"Let $m>n\ge 1$ be integers. If $m$ is even and $f:\mathbb{R} \to \mathbb{R} $ is continuous, nonconstant, with $f(x^m+y^n) \le f(x+y) $ , $\forall x, y \in \mathbb{R} $ , prove that $n$ is even. I think that we should suppose $n$ is odd and reach some kind of contradiction. By taking $x=0$ we get that $f(y) \ge f(y^n), \forall y\in \mathbb{R} $ , but I don't know how to use this. EDIT: Is there any chance that the problem is wrong? An user in the comments pointed out that the fact that $m$ is even is redundant. This makes me doubt a little the correctness of the problem, but I can't make any progress in this direction either. Bump","['continuity', 'functions', 'functional-analysis', 'real-analysis']"
3145725,What am I doing wrong with this derivative? (Product rule & derivative of arctan),"This is my first time posting here, so sorry if I don't get the formatting right! For my Calc 2 pretest, this was one of the questions: Let $f(x)=\mathrm{x^3}\!\cdot\!\mathrm{tan^{-1} (2x)}$ Find $f'(x)$ Here is what I did to attempt to solve the problem. First, applying the product rule: $$f'(x)=\mathrm{x^3}\!\cdot\!\mathrm{\frac{d}{dx}[tan^{-1}(2x)]} + \mathrm{tan^{-1}(2x)}\!\cdot\!\mathrm{\frac{d}{dx}(x^3)}$$ \mathrm{u}!\cdot!\mathrm{v} Second, I am applying the chain rule and the derivative of $tan^{-1}(x)$ to simplify the first addend, and then applying the power rule to find the derivative of $x^3$ . $$f'(x)=\mathrm{x^3}\!\cdot\!\mathrm{\frac1{1+(2x)^2}}\!\cdot\!\mathrm{\frac{d}{dx}[2x]} + \mathrm{tan^{-1}(2x)}\!\cdot\!\mathrm{3x^2}$$ Next up, using the power rule to find the derivative of $2x$ and then the calculus part will be done: $$f'(x)=\mathrm{x^3}\!\cdot\!\mathrm{\frac1{1+(2x)^2}}\!\cdot\!\mathrm{2} + \mathrm{tan^{-1}(2x)}\!\cdot\!\mathrm{3x^2}$$ Now I simplify and get that $f'(x)=$ $$\frac{2x^3}{1+4x^2}+3x^2tan^{-1}(2x)$$ But the problem is this wasn't one of the answers! I did it again and again and kept getting this answer, but no matter what I tried I couldn't manipulate the above expression to match one of my multiple choice answers. I ended up guessing wrong and losing points on the pretest, but I am not able to see what the correct answer is. Hopefully someone can tell me where I went wrong!","['calculus', 'derivatives']"
3145726,Definition of line bundle associated to a Cartier Divisor.,"Let $D$ be a Cartier Divisor on a scheme $X$ represented by $\{(U_i, f_i)\}$ where $U_i$ is an open cover on $X$ , $f_i \in \Gamma(U_i, \mathcal{K}^*)$ and such that $f_i/f_j \in \Gamma(U_i \cap U_j, \mathcal{O}^*)$ . We define the sheaf associated to $D$ denoted by $\mathcal{L}(D)$ to be the sub $\mathcal{O}_X$ -module of $\mathcal{K}$ generated by $f_i^{-1}$ on $U_i$ . Why take the inverse here? It seems that $D$ as described already is a line bundle via the map $\mathcal{O}_X \vert_{U_i} \to \mathcal{D} \vert_{U_i}$ defined as $1 \mapsto f_i$ .",['algebraic-geometry']
3145729,Do Vitali sets really explain measure-theoretic probability?,"Iโve read several answers about how how crazy sets like Vitaliโs set are (one of the reasons) why we need $\sigma$ -algebra and measure theory for probability spaces. However, Vitaliโs set is only eliminated by requiring non-trivial translation-invariant measures. So either (a) Vitaliโs set wasnโt a problem in the first place or (b) probability spaces need translation-invariance. No definition of probability spaces Iโve seen mentions translation invariance, leaving us with (a): Vitaliโs set is not a problem for probabilists. Then: Why do people mention Vitali's set while explaining the measure-theoretic formulation of probability? Why do, in fact, we need measure theory for probability? Are there any other paradoxes arising from uncountable sets to worry about that do apply to regular measures and probability?",['probability-theory']
3145745,"For a finitely generated ideal $I$, $I^2=I$ implies $A/I$ is flat over $A$ or $I$ is principal with an idempotent","This is exercise 1.2.4 from Liu's Algebraic Geometry and Algebraic Curves Let $I$ be a finitely generated ideal of a (commutative with $1$ ) ring $A$ . The following are equivalent: (a) $A/I$ is flat over $A$ (b) $I=I^2$ (c) There exists an $e\in A$ with $e^2=e$ and $I=eA$ After writing down the question and my concerns, I inevitably found the answer which I'm posting below. I still would like to know if there is a way to prove (b) implies (a), and if Liu's Nakayama's lemma (as stated below), is enough to prove (b) implies (c). Let $(A,\mathfrak m)$ local, $M$ a finitely generated module and $M=\mathfrak m M$ . Then $M=0$ .","['abstract-algebra', 'proof-verification', 'commutative-algebra']"
3145747,Why is $\frac{20+16\cos{\alpha}}{25+20\cos{\alpha}}=\frac45$,I am doing a question about conic sections and in order to prove a given theorem it is required to prove the following: $$\frac{20+16\cos{\alpha}}{25+20\cos{\alpha}}=\frac{20-16\cos{\alpha}}{25-20\cos{\alpha}}=\frac45$$ For all $\alpha\in\mathbb{R}$ . I do not understand how this simplification is made as the supplied worked answer simply writes $\frac{20+16\cos{\alpha}}{25+20\cos{\alpha}}=\frac45$ with no intermediate working.,"['algebra-precalculus', 'trigonometry']"
3145771,Understanding generalized Holder inequality proof,"There are questions that concerns me when I read the following proof regarding the generalized Holder inequality : Let $U$ be a subset of $\mathbb{R}$ . Let $1 < p, q, r < \infty$ with $p^{-1} + q^{-1} + r^{-1} = 1$ . Let $f \in L^p(U), g \in L^q(U)$ and $h \in L^r(U)$ . Then $$||fgh||_1 \leq ||f||_p||g||_q||h||_r.$$ Assume that we have the original version of Holder inequality :
Let $1 < p,q < \infty$ . For $f \in L^p(U)$ and $g \in L^q(U)$ , $$||fg||_1 \leq ||f||_p||g||_q.$$ $\textbf{Proof}$ Let $s = (1/p + 1/q)^{-1}.$ Then $1/s + 1/r = 1.$ Then apply the original Holder inequlity gives $$\int_U (fg)h dx \leq ||h||_r (\int_U (fg)^s)^{1/s}.$$ Then apply Holder again to $(fg)^s$ to get the result. $\textbf{Question}$ My confusion is that when $s$ is set. The next step is to apply the original Holder inequality to $(fg)$ and $h$ . Clearly, $h \in L^r$ . But how do we know that $fg \in L^s$ ? Is it trivial to see that $fg \in L^s$ ?? I try to verify this, but not quite successful. (Note if $fg$ is NOT in $L^s$ , then its integrate is $\infty$ . How can $\infty \leq ||f||_p||g||_q$ which suppose to be a finite number!! )","['holder-inequality', 'analysis', 'real-analysis']"
3145818,"If a group $G\leq S_{13}$ has an element of order $40$, then $G$ has a normal non-trivial subgroup.","I came across with the following question and I have no idea how to approach it. Let $G\leq S_{13}$ be a subgroup with an element of order $40$ . Prove that $G$ has a normal proper non-trivial subgroup. I thought of using the sylow theorem but I don't know order $G$ . How should I prove it? Also, if someone knows from which book the question was taken it will be great (Would like to practice with similar questions).","['permutations', 'group-theory', 'abstract-algebra']"
3145821,Why isnโt Brownian motion differentiable?,"Intuitively, if increments become infinitesimally small, why doesnโt Brownian motion become a differentiable function?","['differential-forms', 'stochastic-processes', 'brownian-motion', 'derivatives', 'stochastic-calculus']"
3145873,Is there a solution to this problem?,"I have been thinking about this for some time, but haven't hit upon anything yet. Any help will be appreciated. Is there a function mapping $\mathbf R$ into $\mathbf R$ satisfying the following: It is entirely differentiable on the real line, everywhere positive and its derivative decreases as $x$ (the argument) increases. If it is impossible, why? I have mostly just tried to think of combinations of functions I know, but without luck. Also, I tried to show its impossibility, but have come up with nothing so far.","['calculus', 'functions', 'analysis', 'real-analysis']"
3145885,"Let $S=\{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\}$.How many subsets of S are there where the sum of all the elements in the subset is an odd number?","Let $S$ be a set of twelve integers $\{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\}$ . How many subsets of $S$ are there such that the sum of all the elements in the subset is an odd number? Here's what I tried. There are $2^{12}=4096$ ways to create a subset from $S$ . I tried to find the number of what I call ""even"" subsets, or subsets whose elements only summed to even numbers. I divided $S$ into two subsets, one for all even numbers, and one for all odd numbers, knowing that all the subsets of those two subsets must have an even sum. Counting the sum and subtracting from $4096$ , I get $2^{12}-2^6-2^6=3968$ . However, now I realize that there are more ways to create ""even"" subsets, for example, two odds, four evens. I am now stuck. Can someone help?","['elementary-set-theory', 'number-theory', 'combinatorics']"
3145890,Sequence in Hausdorff Space can have at most $2^\mathfrak{c}$ many cluster points,"I need to show that in a Hausdorff space any sequence can have at most $2^\mathfrak{c}$ many cluster points. I've tried rigging some product space in such a way to make this work, but honestly I'm at a loss with how to proceed with this one. I'm also supposed to show that if I have the extra condition that this space is first countable, then I can have at most $2^\omega$ many cluster points with my sequence. I tried to think of an example of a Hausdorff space which has a sequence with $2^\mathfrak{c}$ many cluster points to get a feel for the this sort of space, but I couldn't even do that. I'd appreciate any guidance. Thanks.","['elementary-set-theory', 'general-topology']"
3145896,Solving $\log_6(2x-3)+\log_6(x+5)=\log_3x$,"Solve for $x$ I have an equation that I have been working on solving; I know the solution, but I cannot get to it myself. Almost every simplification I do reverts back to a previous step. Can anyone show me how to solve for $x$ in this equation? Equation: $$\log_6(2x-3)+\log_6(x+5)=\log_3x$$ Solution: $$x โ \frac{3347}{2000} โ 1.6735$$ Note: upon further analysis of the answer, while close, it does not seem to be the exact solution. What I Have Tried So Far $$\log_6(2x-3) + \log_6(x + 5) = \log_3x$$ $$\frac{\log(2x-3)}{\log6} + \frac{\log(x + 5)}{\log6} = \frac{\log x}{\log3}$$ $$\log3 \cdot \log(2x-3) + \log3 \cdot \log(x + 5) = \log6 \cdot \log x$$ $$\log3 \cdot \log \left[(2x - 3)(x + 5)\right] = \log6 \cdot \log x$$ $$\frac{\log \left[(2x - 3)(x + 5)\right]}{\log_3 10} = \frac{\log6}{\log_x10}$$ $$\log_x10 \cdot \log \left[(2x - 3)(x + 5)\right] = \log_3 10 \cdot \log6$$ $$\log_x \left[(2x - 3)(x + 5)\right] = \log_3 6$$ $$\log_x3 \cdot \log_x \left[(2x - 3)(x + 5)\right] = \frac{\log_3 6}{\log_3 x}$$ $$\log_x \left[(2x - 3)(x + 5)\right]^{\ \log_x3} = \log_x 6$$ $$\left[(2x - 3)(x + 5)\right]^{\ \log_x3} = 6$$ $$(2x - 3)(x + 5) = x^{\log_3 6}$$ I know these steps aren't really working towards the solution at points; I was sort of just playing around with the equation. Regardless, I really don't know how to go about moving forward from here.","['exponentiation', 'algebra-precalculus', 'logarithms']"
3145934,"If $\lim_{x\rightarrow0}\left(\frac{f(x) - f(0)}{x}\right) = 3$, does $\lim_{h\rightarrow0}\left(\frac{f(h(h+2)) - f(0)}{h(h+2)}\right) = 3$?","Given that $f'(0) = 3$ , I need to solve the limit: $$\lim_{x\rightarrow1}\left(\frac{f(x^2 -1) - f(0)}{x^3 -1}\right)$$ Because $f'(0) = 3$ , from first principles, I know that $\lim_{x\rightarrow0}\left(\frac{f(x) - f(0)}{x}\right) = 3$ .
After some algebra, I arrive at $$\lim_{x\rightarrow1}\left(\frac{f(x^2 -1) - f(0)}{x^3 -1}\right) = \lim_{x\rightarrow1}\left(\frac{f((x-1)(x+1)) - f(0)}{(x-1)(x+1)}\right)\times\lim_{x\rightarrow1}\left(\frac{x+1}{x^2 + x + 1}\right)$$ Substitute $h = x-1$ $$\lim_{x\rightarrow1}\left(\frac{f(x^2 -1) - f(0)}{x^3 -1}\right)= \lim_{h\rightarrow0}\left(\frac{f(h(h+2)) - f(0)}{h(h+2)}\right)\times\frac{2}{3}$$ If $\displaystyle\lim_{x\rightarrow0}\left(\frac{f(x) - f(0)}{x}\right) = 3$ , does $\displaystyle\lim_{h\rightarrow0}\left(\frac{f(h(h+2)) - f(0)}{h(h+2)}\right) = 3$ ? If so, the solution is $2$ .","['calculus', 'derivatives']"
3145935,Does classification of 1-manifolds with boundary give induced orientation of image of closed interval under a smooth immersion?,"My book is An Introduction to Manifolds by Loring W. Tu. Pictured below is the last example from Section 22, Manifolds with Boundary. I have been trying to wrap my head around this for about 2 hours (3.5 hours, if you include the 1.5 hours spent on the other question ). An alternative way I approach the example: classification of smooth 1-manifolds with boundary Does the classification of smooth 1-manifolds with boundary imply $C = c[a,b]$ and $[a,b]$ are diffeomorphic to $[0,1]$ and thus diffeomorphic to each other and thus $\partial C$ is diffeomorphic to $\partial [a,b] = \{a,b\}$ , and $C^o$ is diffeomorphic to $(a,b)$ ? Must $c$ be an embedding and in particular $c$ is injective? Update : The classification theorem assumes nonempty boundary. L et's do so as well otherwise the example is wrong. Also see here for the same question but not specifically to do with the classification theorem.","['geometry', 'manifolds', 'general-topology', 'derivatives', 'differential-geometry']"
3145980,How can I show that this matrix has no inverse?,"Let $A = [a_{ij}]$ be an $n \times n$ matrix with entries in $\mathbb{R}$ . Suppose there exists an $m$ with $a_{ij} = 0$ for $i \ge m$ and $j \le m$ , and $a_{i,i} \ne 0$ for $1 \le i \lt m$ . Show that $A$ has no inverse. From my understanding no diagonal value is zero, but all the non-diagonal values more than some arbitrary $m$ is zero. And, I know I must show that the determinant is zero, but I'm not sure how to do this.","['matrices', 'linear-algebra', 'inverse']"
3145981,Why canโt measures be defined on uncountable powersets? Example that actually applies to probability theory,"What actually breaks in probability when you let $\mathcal F = 2^\Omega$ for uncountable $\Omega$ ? To the best of my knowledge, this is not a duplicate question. While there are similar-sounding questions, answers to them usually cite: Vitali sets. However, only translation-invariant measures prevent Vitali sets. Probability measures donโt need to be translation-invariant, so Vitali sets are irrelevant. You can totally have a probability measure and $\sigma$ -algebra containing Vitali sets. Lebesgue measures. Same objection as above. Banach-Tarski. But measures must be at least rotation-invariant to prevent Banach-Tarski (or live in 2-D). Probability measures donโt need to be rotation-invariant, so Banach-Tarski is irrelevant. AFAICT, there seems to be a logical gap in the usual explanations. Could someone provide a concrete example of any paradoxes that emerge from uncountable sets that apply to probability theory? Any issues with letting $\mathcal F = 2^\Omega$ ? Perhaps there is no such paradox. For example, $\delta_a(\cdot)$ seems like a perfectly good probability measure that works with $\mathcal F = 2^\Omega$ . The answer might โThereโs no paradox, but here is an extra property X we want from our probability measures, hereโs why it matters, and for this restricted class of measures, they cannot be defined on $\mathcal F = 2^\Omega$ .โ If so, Iโd love to know what this property $X$ would be. Apologies if Iโve made an error in this post; Iโm new to measure theory!",['probability-theory']
3145988,show this identity with trigometric,"I sent a post earlier. Follow is  an original problem. I got an error identity from a previous calculation error. Now there should be no problem. Problem: : let $x,y\in (0,\dfrac{\pi}{2})$ . show that $$\dfrac{\sin{(x+y)}\tan{x}-\cos{(x+y)}}{\sin{(x+y)}\tan{y}-\cos{(x+y)}}=\dfrac{\cos{(2x+y)}\cos{y}}{\cos{(x+2y)}\cos{x}}$$ This identity comes from the fact that I deal with a geometric problem and use trigonometric functions to calculate an identity that needs to be proved.Thanks",['trigonometry']
3146025,Covering a board problem,"Take a 10x10 board. We're going to try to cover it with 2x2 squares that can overlap. Let an arrangement where the board is covered but one piece can be removed and the board still be covered be redundant. If one cannot do this, then the arrangement is non-redundant. The smallest non-redundant covering evidently is 25 squares. (a) Show that there is a non-redundant covering with 35 squares.
b) Show that every covering with 55 squares is redundant.
c) Can these bounds be improved? By messing around this seems to work and the bounds do not seem to be those that are above but I have no idea how to prove it.",['combinatorics']
3146041,Proving that a spectral measure is $\sigma$-additive,"Given the measurable space $\big(\mathbb{R},\mathcal{B(\mathbb{R})}\big)$ (where $\mathcal{B}(\mathbb{R})$ is the Borel's $\sigma$ -algebra of $\mathbb{R}$ ), a Hilbert space $H$ and two spectral measures $E,F:\mathcal{B(\mathbb{R})}\rightarrow B(H)$ (where $B(H)$ is the space of bounded operators $T: H\rightarrow H$ ); Paul Halmos claims in his book: Introduction to Hilbert Space and the Theory of Spectral Multiplicity, that we can form a spectral measure $G:\mathcal{B(\mathbb{C})}\rightarrow B(H)$ by extending the following map \begin{align}
\mathcal{R}&\longrightarrow B(H)\\
A\times B&\longmapsto  E_A \circ F_B
\end{align} to the $\sigma$ -algebra $\mathcal{B(\mathbb{C}})$ ( $\mathcal{R}$ is the set of products of real Borel sets). I'm having trouble proving that this map is $\sigma$ -additive on $\mathcal{R}$ in the strong operator topology on $B(H)$ . That is equivalent to prove that for all $x \in H$ the function \begin{align}
\mathcal{m}_{x}:\mathcal{R}&\longmapsto \mathbb{R}\\
A\times B&\longmapsto \langle x,E_AF_B(x)\rangle
\end{align} is a premeasure in the sense that if $\{A_i\times B_i\}_{i \in \mathbb{N}}\subset \mathcal{R}$ is a sequence of pairwise disjoint borel rectangles and $A\times B=\bigcup_{i\in \mathbb{N}} A_i\times B_i \in \mathcal{R},$ then $$\langle x,E_AF_B(x)\rangle=\sum_{i\in \mathbb{N}} \langle x,E_{A_i}F_{B_i}(x)\rangle.$$ Could you give me an idea of how to prove this? my work done so far has only given me results that are already implied by the properties of the spectral measures $E$ and $F$ .","['measure-theory', 'linear-algebra', 'functional-analysis', 'real-analysis']"
3146085,Is $T_n$ an unbiased estimator of $\theta$? Prove your answer.,"Let $(x_1, x_2, \dots, x_n)$ be an observed sample from a distribution with probability density function given by $$f(x) =\begin{cases}\displaystyle\frac{1}{5\theta+8}&\text{if }0 \leq x \leq 5 \theta + 8\\0&\text{otherwise. }\end{cases}$$ Where $\theta \in \mathbb R^+$ is an unknown parameter. It can be shown that $T_n = \frac{X_{(n)}-8}{5}$ is an $MLE$ of $\theta$ , where $X_{(n)}$ is the $n^{th}$ order statistic. $\big($ i.e. max $\{X_1, X_2, \dots, X_n\}$$\big)$ . (a) Is $T_n$ an unbiased estimator of $\theta$ ? Prove your answer. (b) Is $T_n$ asymptotically unbiased for $\theta$ ? Give reasons for your answer. (c) Is $T_n$ consistent for $\theta$ in probability? Prove your answer. ATTEMPT $(a)$ $$F_{X}(x) = \int_{0}^{x} f(t)dt = \int_{0}^{x} \frac{1}{5 \theta +8} dt = \frac{1}{5\theta+8}t|_{0}^{x} = \frac{1}{5\theta+8}x$$ $$F_{X_{(n)}}(x) = \left(\frac{x}{5\theta+8}\right)^n$$ $$f_{X_{(n)}}(x) = \frac{dF_{X_{(n)}}(x)}{dx} = \frac{n}{(5 \theta + 8)^n}x^{n-1}, 0 \leq x \leq 5 \theta + 8$$ $$\mathsf{E}T_n = \mathsf{E}\left[\left(\frac{X_{(n)} - 8}{5}\right)\right] = 1/5(\mathsf{E}(X_{(n)}) - 8)$$ $$\begin{align}\mathsf{E}(X_{(n)}) = \int_{0}^{5 \theta + 8} x f_{X_{(n)}}(x)dx &= \int_{0}^{5 \theta + 8}\frac{n}{(5 \theta + 8)^n}x^{n}dx \\ &= \frac{n}{(5 \theta + 8)^n(n+1)}x^{n+1}\bigg|_{0}^{5 \theta+8} = \frac{n(5 \theta + 8)^{n+1}}{(5 \theta + 8)^n(n+1)} = \frac{(5 \theta + 8)n}{n+1}\end{align}$$ $$\mathsf{E}T_n = 1/5(\mathsf{E}(X_{(n)}) - 8) = 1/5 \left (\frac{(5 \theta + 8)n}{n+1} - 8 \right) \neq \theta,$$ so $T_n$ is not an unbiased estimator of $\theta.$ $(b)$ Yes, because $\lim\limits_{n\to\infty} \mathsf{E}T_n = \lim\limits_{n\to\infty} 1/5 \left (\dfrac{(5 \theta + 8)n}{n+1} - 8 \right) = \theta$ $(c)$ $$\begin{align}\mathsf{E}(X^2_{(n)}) = \int_{0}^{5 \theta + 8} x^2 f_{X_{(n)}}(x)dx &= \int_{0}^{5 \theta + 8}\frac{n}{(5 \theta + 8)^n}x^{n+1}dx \\ & = \frac{n}{(5 \theta + 8)^n(n+2)}x^{n+2}\bigg|_{0}^{5 \theta+8} = \frac{n(5 \theta + 8)^{n+2}}{(5 \theta + 8)^n(n+2)}= \frac{(5 \theta + 8)^2n}{n+2}\end{align}$$ $$\begin{align}\lim\limits_{n\to\infty} \mathsf{Var}(X_{(n)}) = \lim\limits_{n\to\infty} \left(\mathsf{E}X^2_{(n)} - (\mathsf{E}X_{(n)})^2\right) = \lim\limits_{n\to\infty} \left(\frac{(5 \theta + 8)^2n}{n+2} -  \left(\frac{(5 \theta + 8)n}{n+1}\right)^2\right) = 0\end{align}$$ $T_n$ is consistent for $\theta$ in probability because $(1)$ $T_n$ is asymptotically unbiased for $\theta$ and $(2)$ $\lim\limits_{n\to\infty} \mathsf{Var}(X_{(n)}) = 0$ Is this correct?","['statistics', 'probability']"
3146131,"Is $[0,1) \cup \{2\}$ a manifold with boundary? My issue is the $2$.","This has been asked about here: Understanding topological and manifold boundaries on the real line , and Sharkos said Personally I'd say $M$ wasn't a valid manifold with boundary because the $\{2\}$ doesn't have a neighborhood with any structure like an open ball/half-ball. This is actually an exercise from An Introduction to Manifolds by Loring W. Tu and is not mentioned in an errata . I have spent almost 2 hours thinking about an exercise that looked like it would take only 15 minutes and even tried pasting lemma (it's a good thing Professor Tu has solutions unlike Professor Lee ): The result of all that thinking is that I don't think $[0,1) \cup \{2\}$ , $(\varepsilon,1) \cup \{2\}$ or $\{2\}$ is homeomorphic to any open subset of $\mathscr H^1$ or $\mathscr L^1$ . I was able to show $\{0\} \subseteq \partial M$ and $(0,1)\subseteq M^0$ , but I don't quite know where $2$ belongs. I believe $M$ is not locally $\mathscr H^1$ . Also, I have double checked: I believe ""manifold boundary"" was defined for manifolds with boundary, so this isn't some trick where ""manifold boundary"" is actually defined for a Hausdorff and second countable space that need not be locally $\mathscr H^n$ . To generalize, Is a half-open interval and a point not in the interval's closure a manifold with boundary?","['geometry', 'manifolds', 'general-topology', 'differential-topology', 'differential-geometry']"
3146170,Why is this Weil divisor not a Cartier divisor,"I'm reading ""Introduction to toric varieties"" by ""William Fulton"", here is an example in page 61 illustrating the difference between Weil divisors and Cartier divisors. Here my question is only about these divisors(not about toric variety), so I change the form such that it doesn't involve the toric variety. I know only basic definition of divisors so correct me if I write something wrong. Example: In the cone $XZ-Y^2$ , the line $X=Y=0$ is a Weil divisor $D$ . Then $D$ is not a Cartier divisor but $2D$ is, and $2D$ is a principal divisor. What is the function that give the principal divisor $2D$ ? Is it just $X^2$ ? Then why function $X$ does not give a principal divisor $D$ ?","['divisors-algebraic-geometry', 'algebraic-geometry']"
3146197,Prove that $\neg \exists x$ such that $ \lvert x-1\rvert+\lvert x+1 \rvert <1$ [duplicate],"This question already has answers here : $|x-1| +|x+1| <1$ (4 answers) Closed 5 years ago . In Spivak Calculus, chapter 1 question 11 vi. asks the reader to find all numbers $x$ for which $\lvert x-1\rvert+\lvert x+1 \rvert <1$ . Intuitively speaking, it is quite obvious that there is no number $x$ that would make this inequality true, and in checking a graph of the equation I am now certain of this. Despite the textbook not asking for a proof, I am curious as to how one would go about proving this rigorously? Would this require using multiple cases or is it possible without? Thanks for any insight. Note : Ideally any proof presented would not require calculus, as that is beyond the scope of the first chapter of the book, but I'd still be interested in any proof involving calculus as this is purely out of curiosity.","['calculus', 'algebra-precalculus', 'absolute-value', 'inequality']"
3146211,Probability of third ball drawn,"Having a box containing 15 red and 7 blue balls. We want to draw 3 balls at random by these conditions on each draw: If the ball is red you set it aside If the ball is blue put it back in What is probability that the third draw is blue? (If you get a blue ball it counts as a draw even though you put it back in the box.) Can I say by these rules? We have three balls drawn the total possibility is the sum of: Both the first two balls are red Both the first two balls are blue The first ball is red and the second is blue The first ball is blue and the second is red. Then for each case I can calculate the probability of blue ball at third draw. $
P=\frac{15}{22}*\frac{14}{21}*\frac{7}{20}+\frac{7}{22}*\frac{7}{22}*\frac{7}{22}+\frac{7}{22}*\frac{15}{22}*\frac{7}{21}+\frac{15}{22}*\frac{7}{21}*\frac{7}{21}
$","['balls-in-bins', 'probability']"
3146231,"Is there a way to find $\min\{m(|X-c|), \:c \in \mathbb{R}\}$?","Suppose X is a random variable, such that $F(t) := P(X < t) \in C(\mathbb{R})$ . Is there a way to find $\min\{m(|X-c|), c \in \mathbb{R}\}$ ? Here $m$ stands for median. I know the solutions for two particular cases: (and they both use a similar method): If $X \sim U[a, b]$ , then $$P(|X - c| < t) = P(c - t < X < c + t) =
  \begin{cases}
    0       & \quad \text{if } c + t < a\\
0       & \quad \text{if } c - t > b\\
\frac{2t}{b - a}       & \quad \text{if } a < c - t < c + t < b\\
\frac{c + t - a}{b - a}  & \quad \text{if } c - t < a < c + t < b\\
    1  & \quad \text{if } c - t < a < b < c + t\\
 \frac{b - c + t}{b - a} & \quad \text{if } a < c - t < b < c + t
  \end{cases}
$$ That results in $$m(|X-c|) = \begin{cases}
\frac{b + a}{2} - c    & \quad \text{if } c < \frac{3a + b}{4}\\
\frac{b - a}{4}     & \quad \text{if } c \in [\frac{3a + b}{4}; \frac{a+3b}{4}]\\
   c - \frac{a + b}{2}  & \quad \text{if } c > \frac{a+3b}{4}  \end{cases}$$ And that means, that $\min\{m(|X-c|), \:c \in \mathbb{R}\} = \frac{b - a}{4}$ . If $X \sim Exp(\lambda)$ , then $$P(|X - c| < t) = P(c - t < X < c + t) =
  \begin{cases}
    0       & \quad \text{if } c < -t\\
1 - e^{-\lambda(c + t))}       & \quad \text{if } c \in [-t; t]\\
2e^{-\lambda c}sinh(\lambda t) & \quad \text{if } c > t  \end{cases}
$$ That results in $$m(|X-c|) = \begin{cases}
\frac{\ln2}{\lambda} - c    & \quad \text{if } c < \frac{\ln2}{2\lambda}\\
  \frac{arsinh(\frac{e^{\lambda c}}{4})}{\lambda} & \quad \text{if } c > \frac{\ln2}{2\lambda} \end{cases}$$ And that means, that $\min\{m(|X-c|), \:c \in \mathbb{R}\} = \frac{\ln2}{2\lambda}$ However, I failed to apply this method to the general case.","['optimization', 'median', 'probability-theory', 'probability']"
3146289,Two answers for Integral of $ \int_0^\infty \frac{\tan^{-1}ax - \tan^{-1}x}{x}\mathrm dx$,"$$ I= \int_0^\infty \frac{\tan^{-1}ax - \tan^{-1}x}{x}\mathrm dx$$ Now by using Leibnitz Rule by differentiating w.r.t. to $a$ we get, $$\frac{\mathrm dI}{\mathrm da}=\frac{\pi}{2a}$$ $$I=\frac{\pi}{2}\ln a$$ But consider , $$I_1= \int_0^\infty \frac{\tan^{-1}ax}{x}\mathrm dx$$ $$I_2= \int_0^\infty \frac{\tan^{-1}x}{x}\mathrm dx$$ So
Substituting $ax=t$ in $I_1$ $$I_1= \int_0^\infty \frac{\tan^{-1}t}{t}\mathrm dt$$ So $$I=I_1-I_2=0$$ So where am I wrong here? I know there is some mistake
In second method as the function is always positive integral can't be $0$ . But i am not able to figure out where am I wrong. Note: $a$ is a positive number","['integration', 'definite-integrals']"
3146344,Is $\mathbb R^J$ normal in the box topology when $J$ is uncountable?,"Question: Is $\mathbb R^J$ normal in the box topology when $J$ is uncountable? I know $\mathbb R^J$ is not normal in the product topology, see ""Proof"" that $\mathbb{R}^J$ is not normal when $J$ is uncountable ; I also know $\mathbb R^{\omega}$ is normal in the box topology assuming the continuum hypothesis, see Is it still an open problem whether $\mathbb R^{\omega}$ is normal in the box topology? . That's the motivation for this problem. Unfortunately, the above two theorems don't imply anything about the normality of $\mathbb R^J$ . Any hint would be appreciated.","['general-topology', 'box-topology', 'separation-axioms']"
3146415,"What is ""locally integral"" in Mumford's GIT book?","I think ""locally integral"" means for each point of a scheme, its local ring is a domain. In my definition, ""normal"" obviously implies ""locally integral"". But ""normal"" and ""locally integral"" is mentioned independently in Mumford's GIT book, as the image below. What is definition of ""locally integral""? And if my definition of it is correct, how can I prove that ""locally integral"" is preserved by taking a categorical quotient?","['algebraic-geometry', 'geometric-invariant-theory', 'abstract-algebra']"
3146428,Correct notation for broadcasting operation,"In Python numpy a row vector $u \in \mathbb{R}^n$ and its transposed $u^T$ can be added, multiplied or subtracted, yielding a $\mathbb{R}^{n\times n}$ matrix, where each element $(i,j)$ is the addition, subtraction or multiplication of the element $u_i$ and $u_j$ . For example import numpy as np
x = np.array([[0],[1],[2]])
x-x.T yields the matrix [[ 0, -1, -2],
 [ 1,  0, -1],
 [ 2,  1,  0]] I am struggling however to understand how to write this in a nice mathematical notation. Rank 1 products can be written mathematically as $x x^T$ , but what for other operations, like addition? I don't think $x+x^T$ is a viable one, as in the case of product the dot product is meant.","['matrices', 'notation', 'python', 'linear-algebra']"
3146452,Associocommutativity,"One thing I've noticed is that addition and multiplication both form commutative groups over the reals, but subtraction, division, and exponentiation are neither associative nor commutative. Ignoring issues with closure for division and possibly exponentiation, all 5 have the property that $(a \star b) \star c = (a \star c) \star b$ (that I call ""right associocommutativity"" because the swapped operands are on the right). Both left and right associocommutativity are implied by the combination of associativity and commutativity. However, tetration ( $\uparrow\uparrow$ , repeated exponentiation) has neither left nor right associocommutativity. Now, my questions: Is there a better name for this? What other operations that aren't both associative and commutative have this property? Why doesn't this work for tetration? Is there a similar property that all of these operations have?","['abelian-groups', 'associativity', 'arithmetic', 'group-theory', 'tetration']"
3146453,"A subset of nonzero integers that for every three elements of it, we have: $b_1 \not= b_2 + b_3$?","If $A $ is a subset of nonzero integers with $n $ elements, is there any subset of A such B with $|B| \geq n/3$ that for every three elements of B, we have: $b_1 \not= b_2 + b_3$ ? Edit: For example if $|A| =$ {1, -1, 2, 4, 6, 9, -5, -8, -7}
then $|B| $ can be {1, 2, 4, -8} because we cannot find any subset of $|B| $ with three elements that in that subset, any two elements sum to a third one. Now my question is that can we find such $|B|$ for any given $|A|$ ?","['probability-theory', 'probability']"
3146525,$ \int_0^x f(t)dt=\int_0^{ax}f(t)dt+ \int_0^{bx}f(t)dt$ implies $f$ constant,"Let $a,b \in (0,1)$ be such that $a+b=1$ and $f:[0,1] \to \mathbb R$ be a continuous function such that $ \int_0^x f(t)dt=\int_0^{ax}f(t)dt+ \int_0^{bx}f(t)dt$ . We have to prove that $f$ is constant. Using the derivative, we get: $f(x)=af(ax)+bf(bx)$ I did the case $a=b=1/2$ , but I don't know how to make it with $a,b$ arbitrary and $a,b \in (0,1)$ $a+b=1$","['functional-equations', 'calculus', 'functions', 'derivatives']"
3146531,Construct a permutation of the set N of all natural numbers that maps all the multiples of 3 onto the set of all even numbers. [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Question: Construct a permutation of the set N of all natural numbers that maps all the multiples of 3 onto the set of all even numbers. I am confused as to how to get started on the problem. I have tried creating multiple mappings that map multiples of 3 into even numbers, but how do I include natural numbers in my permutation?",['discrete-mathematics']
3146542,Integrate $\int \frac{dx}{\sqrt{x^2-9}}$ by trig substitution [duplicate],"This question already has answers here : Integral of $\int \frac{dx}{\sqrt{x^2 -9}}$ (2 answers) Closed 5 years ago . $$
\begin{align}
x = 3\sec\theta, dx &= 3\sec\theta\tan\theta d\theta\\\\
\int \frac{dx}{\sqrt{x^2-9}} &= \int \frac{3\sec\theta\tan\theta d\theta}{\sqrt{(3\sec\theta)^2 - 3^2}} \\\\
& = \int \frac{3\sec\theta\tan\theta d\theta}{\sqrt{3^2(\sec^2\theta -1)}} \\\\
&= \int \frac{3\sec\theta\tan\theta d\theta}{\sqrt{3^2\tan^2\theta}} = \int \sec\theta\\\\
&= \ln|\sec\theta + \tan\theta| + C = \ln| \frac{x}{3} + \frac{\sqrt{x^2-9}}{3}|
\end{align}
$$ However, wolphram alpha says the answer is $\ln |x+ \sqrt{x^2-9}$ I am wondering how did it get rid of the 3 in the denominator? This is pretty much how I got my answer: $$
x = 3\sec\theta \\
\frac{x}{3} = \sec\theta \\
\frac{\sqrt{x^2-9}}{3} = \tan\theta
$$","['integration', 'calculus', 'derivatives', 'trigonometry']"
3146556,"How many five digit numbers formed from digits $1,2,3,4,5$ (used exactly once) are divisible by $12$?","How many five digit numbers formed from digits $1,2,3,4,5$ (used exactly once) are divisible by $12$ ? My answer is $24$ but I doubt if it's right or not. Sum of all the digits is $15$ , so all the numbers are divisible by $3$ . Also there are $24$ numbers divisible by $4$ . I have found this by Fixing $4$ at units place , so I must place $2$ at tens place and number divisible by $4$ is $3!=6$ Fixing $2$ at units place, so I have $1,3$ or $5$ at tens place and number divisible by $4$ is $3!ร3=18$ Since $12=3ร4$ and all numbers are divisible by $3$ so numbers divisible by $12$ is $24$ . Is the reason valid?","['permutations', 'combinatorics', 'divisibility']"
3146561,Cascading Summation $\sum_{i_1=1}^n \sum_{i_2=i_1}^n \sum_{i_3=i_2}^n.... \sum_{i_{p-1}=i_{p-2}}^n \sum_{i_{p}=i_{p-1}}^n f(i_p)$,Is there  relation  between the two summations $$\sum_{i_1=1}^n \sum_{i_2=i_1}^n \sum_{i_3=i_2}^n.... \sum_{i_{p-1}=i_{p-2}}^n \sum_{i_{p}=i_{p-1}}^n f(i_p)$$ and $$\sum_{i_1=1}^n \sum_{i_2=1}^{i_1} \sum_{i_3=1}^{i_2}.... \sum_{i_{p-1}=1}^{i_{p-2}} \sum_{i_{p}=1}^{i_p} f(i_p)$$,['discrete-mathematics']
3146597,"What is the dot in ""$1.2.4$""?","I am not a mathematician.  I did additional maths Oโlevel back in the stone age but did not pursue maths further (much to my regret). I am reading David Achesonโs fascinating book โThe Story of Calculusโ and have just about kept up till I got a use of โ $\cdot$ ' (dot) that I do not understand.  It is in his Chapter $14$ โan Enigmaโ and first occurs here in the context of chain rule :- Suppose, for instance, that $y$ is some function of $x$ , and that $x$ itself is a function of some other variable - say $t$ .  Then we can, if we wish, consider $y$ as a function of $t$ , and then $\frac{dy}{dt}=\frac{dy}{dx}\cdot \frac{dx}{dt}$ What is the dot doing?  I looked at the suggested previous questions about the dot without success.  Does it mean $\&$ (as it does in propositional logic, where $P.Q$ stands for $P \& Q$ ? The (or a ) mysterious dot corps up again in Chapter $23$ , about $e$ numbers, on the topic of the Taylor series .   Here we find the series $$e^x=1+x+\frac{x^2}{1.2}+\frac{x^3}{1.2.3}+...$$ What is the ' $.$ ' doing here, please?  Is it in some way a concatenation?  Or what is it?","['notation', 'limits', 'calculus', 'sequences-and-series']"
3146621,Evaluate integral $\int \sin^4(t)\cos^3(t)dt$,"$$\int \sin^4(t)\cos^3(t)dt =  \int \sin^4(t)(1-\sin^2(t))\cos(t) dt $$ $$u = \sin(t) \\ du = \cos(t)dt$$ $$ \int \sin^4(t)\cos^3(t)dt = \int u^4(1-u^2) du \\
= u^4 - u^6 = \frac{1}{5}u^5 - \frac{1}{7}u^7 + C \\ 
= \frac{1}{5}\sin^5(t) - \frac{1}{7}\sin^7(t) + C  $$ This seems like a simple enough trig substitution integral problem to me. However, when I check my answer with wolphram alpha, it gives: This looks like a simplified version of my answer, but it is not entirely clear to me how it gets reduced down. The furthest I can get is this: $$ \frac{1}{5}\sin^5(t) - \frac{1}{7}\sin^7(t) = \sin^5(t) \bigg( \frac{1}{5} - \frac{1}{7} sin^2(t) \bigg) \\
= \frac{1}{5}\sin^5(t) \bigg(\frac{1}{5} - \frac{1}{7} \cdot \frac{1}{2} (1 - \cos 2x) \bigg) \\
= \frac{1}{5}\sin^5(t) \bigg(\frac{1}{5} - \frac{1}{14} - \frac{1}{14}\cos 2x\bigg) \\
= \frac{1}{5}\sin^5(t) \bigg(\frac{14}{90} - \frac{5}{90} - \frac{5}{90} \cos 2x \bigg)$$ and I feel like my simplification is not really going anywhere meaningful...","['integration', 'calculus', 'derivatives', 'trigonometry']"
3146631,Are the bounded Lipschitz functions dense in $L^1(\mu)$?,"I am currently reading a paper (L. Ambrosio and B. Kirchheim. Currents in metric spaces) and I stumbled uppon a fact which I don't know how to prove. I have the following setting: Let $X$ be a complete metric space, $\mu$ a finite Borel measure and let $\text{Lip}_b(X)$ denote the bounded Lipschitz functions $X \rightarrow \mathbb{R}$ . Then $\text{Lip}_b(X)$ is supposed to be dense in $L^1(X,\mu)$ . I assume I need to do something with some density of $\text{Lip}_b(X)$ in $C(X, \mathbb{R})$ , but since we don't have any compactness assumptions, we can't apply Stone-Weierstrass and I don't know how we got that fact.","['functional-analysis', 'lipschitz-functions']"
3146659,A Counter Examples in Linear Algebra (Vector Space),"I have been studying linear algebra for a few years now and in fact, also teaching it. What makes learning (and teaching) mathematics more interesting is to find examples and/or counterexamples of what we learn. As a process, I am trying to find counterexamples of sets along with two operations $+$ and $\cdot$ , which we will call for the time being ""addition"" and ""scalar multiplication"" which do not form a vector space because they fail to satisfy exactly one of the axioms of a vector space. If I am to list out the axioms and hence the definition, it proceeds as follows:- A set $V$ along with two operations $+: V \times V \rightarrow V$ and $\cdot: \mathbb{F} \times V \rightarrow V$ , where $\mathbb{F}$ is a field, is called a ""vector space"" over the field $\mathbb{F}$ if: $\forall x, y, z \in V$ we have $\left( x + y \right) + z = x + \left( y + z \right)$ $\forall x, y, \in V$ we have $x + y = y + x$ $\exists 0 \in V$ such that $\forall x \in V$ , we have $x + 0 = x$ $\forall x \in V$ , $\exists y \in V$ such that $x + y = 0$ $\forall x, y \in V$ and $\forall \alpha \in \mathbb{F}$ , we have $\alpha \cdot \left( x + y \right) = \alpha \cdot x + \alpha \cdot y$ $\forall x \in V$ and $\forall \alpha, \beta \in \mathbb{F}$ , we have $\left( \alpha + \beta \right) \cdot x = \alpha \cdot x + \beta \cdot y$ $\forall x \in V$ and $\forall \alpha, \beta \in \mathbb{F}$ , we have $\alpha \cdot \left( \beta \cdot x \right) = \left( \alpha \beta \right) \cdot x$ , where $\alpha \beta$ denotes the multiplication of $\alpha$ with $\beta$ in the field $\mathbb{F}$ $\forall x \in V$ , we have $1 \cdot v = v$ , where $1 \in \mathbb{F}$ is the unity. It is not so difficult (if not easy) to find counterexamples of sets, fields and operations which satisfy all but one property from $1$ through $7$ . However, I have not yet been able to find an example which satisfy all properties except $8$ and hence fails to be a vector space. I would like some help in constructing such a counter example.","['linear-algebra', 'vector-spaces', 'examples-counterexamples']"
3146697,Proof that $n$ planes cut a solid torus into a maximum of $\frac16(n^3+3n^2+8n)$ pieces,"Question: How many pieces can a solid torus be cut into with three (affine) planar cuts? A google search will quickly reveal that the answer is thirteen, as can be read about here . The picture below displays this solution. However, despite being able to look at the diagram and confirm that thirteen pieces is indeed possible, I do not see how one would prove this is the maximum number of cuts. Furthermore, I have found the following general formula for $n$ cuts: $f(n)=\frac{1}{6}(n^3+3n^2+8n)$ , but have not been able to find a proof for this either. Better Question: How does one prove that thirteen is the maximum number of pieces with three cuts, and that $f$ provides the number of pieces with $n$ cuts?","['proof-explanation', 'visualization', 'puzzle', 'geometry']"
3146736,What is the probability somebody's birthday is the day before mine?,"What is the probability that someone's birthday is the day before my birthday? For example, my birthday is Feb 28, what is the probability that my mom's birthday is Feb 27? Is it just $\frac1{365}$ ? That seems too simple to me but maybe I'm just complicating things unnecessarily.","['statistics', 'probability']"
3146737,Can the result of a change of one simple rule to build a Pascal's triangle be mathematically explained?,"The only rule that is changed is this: when adding two numbers from row $(n-1)$ to get the number $N_n$ of row $n$ we also add the number from row $(n-2)$ that is aligned (vertically) with the position of the number $N_n$ . We start with the same triangle $$1$$ $$1---1$$ The next line will be $$1---3---1$$ because we added the first $1$ aligned with the result of adding $1+1$ from row $2$ . If we keep using this rule, we will get a Pascal's triangle whose diagonals are very interesting. Since I don't know how to format a Pascal's triangle with mathjax, I will simply list few diagonals. The first diagonal is: $$1--3--5--7--9--11--13--15--15--17--19--21...$$ The second diagonal is given by $A001844$ which gives centered square numbers. $$1--5--13--25--41--61--85--113--145--181--221...$$ The third diagonal is given by $A001845$ which gives centered octahedral numbers (also called crystal ball sequence for cubic lattice). $$1--7--25--63--129--231--377--575--833--1159...$$ The fourth diagonal is given by $A001846$ which gives centered 4-dimensional orthoplex numbers (also called crystal ball sequence for 4-dimensional cubic lattice). $$1--9--41--129--321--681--1289--2241--3649...$$ The fifth diagonal is given by $A001847$ which gives crystal ball sequence for 5-dimensional cubic lattice numbers. The sixth diagonal is given by $A001848$ which gives crystal ball sequence for 6-dimensional cubic lattice numbers. I suppose the next sequence will give the 7-dimensional cubic lattice numbers ( I checked it ) and higher. Some of the formulas to generate the numbers are given in the OEIS sequences given above. The first $7$ rows of the this triangle look like this: $$1$$ $$1---1$$ $$1---3---1$$ $$1---5---5---1$$ $$1---7---13---7---1$$ $$1---9---25---25---9---1$$ $$1---11---41---63---41---11---1$$ Note the pattern that repeats indefinitely formed by multiplying numbers under the starting $1$ at the top in the following way: $$1*3+1*1=4=2^2=(1+1)^2$$ $$3*13+5*5=64=8^2=(3+5)^2$$ $$13*63+25*25=1444=38^2=(13+25)^2$$ . The triangle has other properties that deserve to be mentioned. If we add term by term the first diagonal and the second to get: $$(1+1),(3+5), (5+13), (7+25), (9+41), (11+61), (13+85)...$$ we get the sequence $2n^2$ . If we add the second diagonal and the third term by term, we get the sequence A035597 which gives the number of points of L1 norm 3 in cubic lattice Z^n. Its formula is ( $4n^3+2n)/3$ : $$(1+1), (5+7), (13+25), (25+63), (41+129), (61+231)...$$ But we can also get new numbers by multiplying term by term the first and second diagonals. We get OEIS A005917 Rhombic dodecahedral numbers: $a(n) = n^4 - (n - 1)^4$ $$1, 15, 65, 175, 369, 671, 1105, 1695, 2465, 3439...$$ There are probably more hidden patterns waiting to be found in this triangle. Only a systematic search can find them. There are many questions that come to mind. 1-How come one simple modification of a rule provides such a change. 2-What mathematics (formulas, theorems...) is common to both triangles (assuming some features are common to both triangles which is not obvious at all at this point). 3-Have the effect of other modifications of the rule to build a Pascal's triangle been systematically studied before? ( For example, one can think of a classical Pascal's triangle where the result is squared...). If someone can think of more meaningful tags, please add them or change them.","['binomial-coefficients', 'combinatorics', 'discrete-mathematics']"
3146741,Heat semigroup norm between fractional Sobolev and $L^p$ spaces,"What is the actual inequality that holds for the heat semigroup between fractional Sobolev space $W^{2\alpha,p}$ and classical Lebesgue space $L^q$ ? I am trying to derive an inequality $$
\lvert\lvert e^{t\Delta}f  \rvert\rvert_{W^{2\alpha,p}} \leq \frac{C}{t^\beta} 
\lvert\lvert f  \rvert\rvert_{L^q} $$ but i cannot manage to find the right value of $\beta$ . I am trying to write the heat semigroup as a convolution $$ e^{t\Delta}f = K_t*f $$ where $K_t$ is the heat kernel, and use Holder inequality for convolutions, but I am stuck when computing $$ \lvert\lvert (I-\Delta)^\alpha K_t  \rvert\rvert_{L^r}  $$ where $\frac{1}{q}+\frac{1}{r} = \frac{1}{p}+1$ . Any help is appreciated.","['semigroup-of-operators', 'fractional-sobolev-spaces', 'functional-analysis']"
