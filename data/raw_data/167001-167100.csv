question_id,title,body,tags
2912743,Proving associativity of matrix multiplication,"I'm trying to prove that matrix multiplication is associative, but seem to be making mistakes in each of my past write-ups, so hopefully someone can check over my work. Theorem. Let $A$ be $\alpha \times \beta$, $B$ be $\beta \times \gamma$, and $C$ be $\gamma \times \delta$. Prove that $(AB)C = A(BC)$. Proof. Define general entries of the matrices $A$, $B$, and $C$ by $a_{g,h}$, $b_{i,j}$, and $c_{k,m}$, respectively. Then, for the LHS:
\begin{align*}
& (AB)_{\alpha, \gamma} = \sum\limits_{p=1}^{\beta} a_{\alpha,p} b_{p,\gamma} \\
& \left((AB)C\right)_{\alpha, \delta} = \sum\limits_{n=1}^{\gamma} \left(AB\right)_{\alpha, n} c_{n, \delta} = \sum\limits_{n=1}^{\gamma} \left(\sum\limits_{p=1}^{\beta} a_{\alpha,p} b_{p,n} \right) c_{n, \delta} = \sum\limits_{n=1}^{\gamma} \sum\limits_{p=1}^{\beta} \left(a_{\alpha,p} b_{p,n}\right) c_{n, \delta}.
\end{align*}
For the RHS: 
\begin{align*}
& \left(BC\right)_{\beta, \delta} = \sum\limits_{n=1}^{\gamma} b_{\beta, n} c_{n, \delta} \\
& \left(A\left(BC\right)\right)_{\alpha,\delta} = \sum\limits_{p=1}^{\beta} a_{\alpha,p} (BC)_{p, \delta} = \sum\limits_{p=1}^{\beta} a_{\alpha,p} \left(\sum\limits_{n=1}^{\gamma} b_{p, n} c_{n, \delta} \right) = \sum\limits_{p=1}^{\beta} \sum\limits_{n=1}^{\gamma} a_{\alpha,p} \left(b_{p, n} c_{n, \delta} \right).
\end{align*}
Assuming I have written these correctly, we can make two observations: first, the summands are equivalent, as multiplication is associative. Second, the order of the summations doesn't matter when we're summing a finite number of entries. Thus, $(AB)C = A(BC)$. How does this look?","['proof-verification', 'linear-algebra']"
2912783,Model for symplectic geometry,"An almost symplectic structure on a smooth even dimension manifold $M$ can be viewed as a reduction of structure group $Sp(2n,\mathbb{R}) \hookrightarrow GL(2n,\mathbb{R})$ for the principal frame bundle $\mathcal{F}(M)$. If this structure group reduction corresponds to a closed section of $\mathcal{F}(M)/Sp(2n,\mathbb{R})$ then it is a symplectic structure. It is claimed in here that, as an integrable $G$-structure, a symplectic manifold is a Cartan geometry. So, if we want to describe a symplectic manifold as a Cartan geometry of type $(G,H)$ what are the possible choices of Lie groups $G$ and $H$? Different choices of $G$ and $H$ will give rise to homogeneous spaces $G/H
$ that are related by model mutation. I am primarily concerned with the groups that give rise to a compact model $G/H$ for symplectic manifolds.","['cartan-geometry', 'symplectic-geometry', 'differential-geometry']"
2912793,A continuous bijection between two complete metric spaces that is not a homeomorphism.,Suppose $X$ and $Y$ are two metric spaces and $f: X\to Y$ be a continuous bijection. Now my question is does the completeness of $X$ and $Y$ implies $f$ to be a Homeomorphism? My idea . First of all I try to prove $f$ to be a closed map assuming $X$ and $Y$ be a complete metric space. But this idea didn't work. I know if $X$ is given to be compact then whether or not $Y$ complete given initially $f$ becomes a homeomorphism. But that is not the case here. So I try to find a counter example . I take $Y=\Bbb{R}$ and try to choose $X$ to be a non compact but closed subset of $\Bbb{R}$ (and $\Bbb{R}^2$ ) but the problem is in that situation the bijections I found was not continuous . Also I cannot found any example beyond the metric spaces $\Bbb{R}$ or $\Bbb{R}^2$ as my $X$ . Can any one help me to figure out how to construct an counter example here. Thanks ...,"['general-topology', 'metric-spaces']"
2912800,An integer sequence related to Penrose tessellation,"Consider covering the plane by means of the classical Penrose tiles (i.e. the ""fat"" and ""thin"" rhombi) in a spiraling fashion, adding step by step a new tile around a given one, as introduced in this post . At each step, we need one of the two tiles (and only one), as illustrated in the following picture: The starting tile is the pink one. The segments connecting the centers of the tiles represent the consecutive steps of the spiral walk around the starting tile. The numbers inside the tiles (1, fat rhombus; $\color{red} 0$, thin rhombus), highlight the alternation of the two kinds of tiles as a function of the walk step. Displaying these numbers in a sequence, we find: $s(n)=1$,$1$,$1$,$1$,$\color{red}0$,$1$,$1$,$\color{red}0$,$1$,$\color{red}0$,$\color{red}0$,$1$,$\color{red}0$,$\color{red}0$,$1$,$1\ldots$ My question is: Is there a closed formula for $s(n)$? Thanks for your suggestions!","['number-theory', 'integers', 'geometry', 'sequences-and-series', 'tiling']"
2912824,Upper and Lower bounds on probability intersection,"How do I go about answering the following question. Given two events A,B with (A) = 3/4 and P(B) = 1/3, what is the smallest possible value of P(A $\cap$ B)? The largest? That is, a and b such that,
$$a \leq P(A \cap B) \leq b,$$
holds and any value in the closed interval [a,b] is possible. a = ?
b = ? Below is a image of what I think is the shaded area of interest. Is this correct? If so, then is the probability 1/4 x 2/3 = 1/6. In which case, a = 1/4 and b = 2/3?","['probability-theory', 'probability']"
2912834,Prove that an odd square cannot be a pseudoprime with both base 2 and base 3,"Background: The Baillie PSW primality test 1 tests if the number is a square before the Selfridge parameter selection. The Mathematica implementation of PrimeQ does not test if the number is square, but tests if the number is not both a pseudoprime with base 2 and a pseudoprime with base 3. Apparently a square number cannot pass both tests, as otherwise the Selfridge selection would fail. I could not find any example of a square number that passed both tests to about $5\cdot10^{18}$. My question is: Can it be proved that an odd square number cannot be both pseudoprime with base 2 and a pseudoprime with base 3?","['number-theory', 'square-numbers', 'pseudoprimes']"
2912854,An ant is to walk from $A$ to $B$. Calculate the number of paths. [duplicate],"This question already has answers here : Counting number of moves on a grid (2 answers) Closed 5 years ago . An ant has to walk from the left most lower corner to top most upper corner of $4 \times 4$ square.  However, it can take a right step or an upward step, but not necessarily in order. Calculate the number of paths.","['permutations', 'combinatorics']"
2912882,$\int_{2018}^\infty\frac{\cos^2(x)}{x^{7/6}+x^{1/6}\cos^3x}$ does this integral converge?,"This is from an assignment i got, i need to show if it converges and if it converge absolutely.
I believe it diverges and i tried to show it by subtracting a known converging  integral from it, and thus receiving another integral which is easier to show that it diverges, hence the original integral is diverging, because if he was converging than the integral after the subtraction was suppose to converge as well. The problem was that i could not manage to find another integral which will give me my desired answer. $$\int_{2018}^\infty\frac{\cos^2(x)}{x^{7/6}+x^{1/6}\cos^3x}$$","['integration', 'calculus', 'real-analysis']"
2912883,Is it possible to construct primes with arbitrary messages in them?,"Motivation: A friend of mine told me that the number gained by interpreting the binary code of is quite often a prime. A slight copyright themed discussion later and after developing an algorithm to make any visual medium a prime: While(notPrime):
    mutate The question arose if there is a wasteful lossless encoding of the form: Number Data Encodinginformation e.g.: Encode ""a"" as 10110000101111 which is: 1 (number sought to make it prime)
01100001(ascii for ""a"")
0111(encoding of length of String)
1(always last number to ensure the number is odd) Math Question: given a number $n$ coprime to $b$ is there a prime of the form
$$p=n+\sum_{i=k}^m a_ib^i$$
where $a_i\in\{0,\ldots,b-1\}$, $m$ is arbitrary and $k=\lceil log_b(n) \rceil$?","['number-theory', 'prime-numbers', 'computer-science']"
2912913,Sufficient Statistics: Proof of a lemma by Halmos and Savage,"I am reading the paper ""Application of the Radon-Nikodym Theorem to the Theory of Sufficient Statistics"" by Halmos and Savage and have much trouble following the proof of Lemma 7. Below is (my paraphrase of) the statement of the lemma and its proof. Lemma: Let $\mathcal{P}$ be a family of probability measures on the measurable space $(\Omega, \mathcal{F})$. If $\mathcal{P}$ is dominated by a finite measure $\nu$ (i.e. $\mathbb{P} \ll \nu$ for all $\mathbb{P}\in\mathcal{P}$), then there exists a countable subset $\mathcal{P}_0\subset\mathcal{P}$ such that for every $A\in\mathcal{F}$, $\mathbb{P}_0(A)=0$ for all $\mathbb{P}_0\in\mathcal{P}_0$ implies $\mathbb{P}(A)=0$ for all $\mathbb{P}\in\mathcal{P}$. The proof provided in the paper is as follows. Define the collection of sets $\mathcal{K}$ like so: We say that the $\mathcal{F}$-measurable set $K\in\mathcal{K}$ if and only if there exists some $\mathbb{P}\in\mathcal{P}$ corresponding to this $K$ such that $\mathbb{P}(K)>0$ and $\frac{d\mathbb{P}}{d\nu}>0$ on $K$. Let $\mathcal{C}$ be the collection of all sets of the form $\dot{\bigcup}^\infty_{i=1}K_i$, where $(K_i)^\infty_{i=1}\subset\mathcal{K}$ are disjoint. Then it can be shown that $\mathcal{C}$ is closed under countable unions. We now construct our countable subset $\mathcal{P}_0$. Choose a sequence $(C_i)^\infty_{i=1}\subset\mathcal{C}$ such that $\nu(C_i)\to\sup_{C\in\mathcal{C}}\nu(C)$ and let $C$ be the union of the $C_i$s. Then since $\mathcal{C}$ is closed under countable unions, $C\in\mathcal{C}$ and there exists $(K_i)^\infty_{i=1}\subset\mathcal{K}$ such that $C=\dot{\bigcup}^\infty_{i=1}K_i$. We then let $\mathcal{P}_0=\{\mathbb{P}_1, \mathbb{P}_2,\cdots\}$, where each $\mathbb{P}_i$ is the probability measure corresponding to $K_i$. Let $A\in\mathcal{F}$ be such that $\mathbb{P}_i(A)=0$ for each $i$ and $\mathbb{P}$ be any probability measure in $\mathcal{P}$. Denote $B=\{\omega\in\Omega: \frac{d\mathbb{P}}{d\nu}(\omega)>0\}$ Since $\color{red}{\mathbb{P}(A\cap B^c)=0}$, we may assume WLOG that $A\subset B$. It remains to show $\mathbb{P}(A)=0$. We first show that $\mathbb{P}(A\cap C^c)=0$. Suppose not. Then $\nu(A\cap C^c)>0$ and therefore, because $\color{red}{A\cap C^c\in\mathcal{K}}$, $\color{red}{A\cup C\in\mathcal{C}}$ with $\color{red}{\nu(A\cup C)>\nu(C)}$, contradicting the maximality of $\nu(C)$. Hence $\mathbb{P}(A\cap C^c)=0$. Finally we show also that $\mathbb{P}(A\cap C)=0$. By $\sigma$-additivity and the fact that $\mathbb{P} \ll \nu$, this follows if we can show that $\nu(A\cap K_i)=0$ for every i. But this is true since $0 = \mathbb{P}_i(A\cap K_i) = \int_{A\cap K_i} \frac{d\mathbb{P}_i}{d\nu} d\nu$ and $\frac{d\mathbb{P}_i}{d\nu}$ is strictly positive on $A\cap K_i$. This completes the proof. I am most definitely missing many obvious things but I am unable to grasp nor understand why the following claims are true: $\mathbb{P}(A\cap B^c)=0$ ${A\cap C^c\in\mathcal{K}}$ $A\cup C\in\mathcal{C}$ $\nu(A\cup C)$ is strictly greater than $\nu(C)$ The motivation behind the construction of $\mathcal{P}_0$ I would appreciate it if anyone could enlighten me on this. Thank you!","['statistical-inference', 'statistics', 'measure-theory', 'real-analysis', 'probability-theory']"
2912932,"Terminology for a ""subgroup"" that has a different identity element.","Let $M$ denote a monoid. Then to refer to submonoids of $M$ that just happens to be a group, I think the phrase ""subgroup of $M$"" is okay, as it's unlikely to cause confusion as long as you instruct the reader you'll be using the word in this way. However, sometimes you've got a monoid $M$ with a subsemigroup $M$ that just happens to be a group, but whose identity element is different to that of $M$. This happens with sandpiles for example; there's a monoid $M$ of sandpiles, and this has a special ""subgroup"", but the subgroup has a different identity element to $M$. Question. Is there a term for this?","['monoid', 'abstract-algebra', 'semigroups', 'group-theory', 'terminology']"
2912948,Exercise on differential forms.,"Let $\theta: S^1 \rightarrow \mathbb{R}:(x,y) \mapsto \arctan(\dfrac{y}x)$. Prove that $d\theta$ is a closed 1-form which is not exact. I managed to prove that it was closed but how can it possibly not be exact? Isn't it implicit in the notation that it is? It would be like asking me to prove that $2n$ isn't an even number. Is there a mistake in the question or what am I missing here? Cheers.","['differential-forms', 'differential-geometry']"
2912999,"Prob. 10 (a), Sec. 26, in Munkres' TOPOLOGY, 2nd ed: A Partial Converse To The Uniform Limit Theorem","Here is Prob. 10 (a), Sec. 26, in the book Topology by James R. Munkres, 2nd edition: Prove the following partial converse to the uniform limit theorem: Theorem . Let $f_n \colon X \to \mathbb{R}$ be a sequence of continuous functions, with $f_n(x) \to f(x)$ for each $x \in X$ . If $f$ is continuous, and if the sequence $f_n$ is monotone increasing, and if $X$ is compact, then the convergence is uniform. [We say that $f_n$ is monotone increasing if $f_n(x) \leq f_{n+1}(x)$ for all $n$ and $x$ .] Here is another post of mine here on Math Stack Exchange on this very problem, where I've also given a proof of the analogue of this very result. In what follows, I'll try to give a different proof of this result. My Attempt: Let $\varepsilon > 0$ be given. For each $x \in X$ , as the sequence $f_n(x)$ is a monotonically increasing, convergent sequence of real numbers with limit $f(x)$ , so we must have $$ f(x) = \sup \left\{ \ f_n(x) \ \colon \ n \in \mathbb{N} \ \right\}. \tag{0} $$ Moreover, the set $$ \big( \ f(x) - \varepsilon, \, f(x) + \varepsilon \ \big) = \{ \ y \in \mathbb{R} \ \colon \ f(x) - \varepsilon < y < f(x) + \varepsilon \ \} $$ is an open subset of $\mathbb{R}$ , and as $f$ is continuous, so the inverse image $$U_x \colon= f^{-1} \left( \  \big( \ f(x) - \varepsilon, \, f(x) + \varepsilon \ \big)   \  \right)
= \{ \ u \in X \ \colon \ f(x) - \varepsilon < f(u) < f(x) + \varepsilon \ \}  \tag{1} $$ is an open set in $X$ and $x \in f^{-1} \left( \  \big( \ f(x) - \varepsilon, \, f(x) + \varepsilon \ \big)   \  \right)$ , because $$ f(x) - \varepsilon < f(x) < f(x) + \varepsilon \tag{2} $$ holds. Furthermore, as $$ \lim_{n \to \infty} f_n(x) = f(x), $$ so there exists a natural number $N_x$ such that $$ \left\lvert f_n(x) - f(x) \right\rvert < \varepsilon \tag{3} $$ for all natural numbers $n > N_x$ . The collection $\left\{ \ U_x \ \colon \ x \in X \right\}$ in (1) above is an open covering of $X$ , and as $X$ is compact, so there are finitely many sets $U_{x_1}, \ldots, U_{x_K}$ , say, such that $$ X = \bigcup_{i=1}^K U_{x_i}. \tag{4} $$ Now let us put $$ N \colon= \max \left\{ \ N_{x_1}, \ldots, N_{x_K} \ \right\}. \tag{5} $$ Now for any natural number $n > N$ , we have $n > N_i$ for each $i = 1, \ldots, K$ and so by (3) above we have $$ \left\lvert f_n \left(x_i \right) - f \left(x_i \right) \right\rvert < \varepsilon   \tag{6}$$ for each $i = 1, \ldots, K$ . Now if $x \in X$ is arbitrary, then $x \in U_{x_r}$ for some $r = 1, \ldots, K$ [Refer to (4) above.]. Then by (1) above we conclude that $$ f(x) \in \left( \ f \left( x_r \right) - \varepsilon, \, f \left( x_r \right) + \varepsilon \right), $$ that is, $$ f \left( x_r \right) - \varepsilon < f(x) < f \left( x_r \right) + \varepsilon. $$ which is equivalent to $$ \left\lvert f(x) - f \left( x_r \right) \right\rvert < \varepsilon. \tag{7} $$ So by (6) and (7) above, we conclude that, for all $x \in X$ and for every natural number $n > N$ , we have $$ \left\lvert f_n(x) - f(x) \right\rvert \leq $$ Is what I've done so far correct? If so, is it going to lead us to our desired proof? If yes, then how to proceed from here? How to complete the proof?","['continuity', 'uniform-convergence', 'sequences-and-series', 'general-topology', 'compactness']"
2913018,Determinant of block matrix with singular blocks on the diagonal,"Let $A$ and $D$ be square matrices, and let $B$ and $C$ be matrices of valid shapes to allow the formation of
$$
M =
\begin{bmatrix}
    A & B \\
    C & D
\end{bmatrix}.
$$
If $\det{A}\neq0$, we may use the Schur complement to express $\det{M}$ in terms of its constituent blocks as
$$
\det{M} = \det{A}\cdot\det(D-CA^{-1}B),
$$
and if $\det{D}\neq0$ we have in a similar fashion that
$$
\det{M} = \det(A-BD^{-1}C)\cdot\det{D}.
$$ My question: Does there exist a similar formula expressing $\det{M}$ in terms of its constituent blocks, that is valid in case $\det{A}=\det{D}=0$?","['matrices', 'schur-complement', 'determinant', 'block-matrices']"
2913020,Prime pattern found in the integral $\int_0^\pi \exp\left(\frac{\cos t}{8}\right)\cos\left(\frac{\sin t}{8}\right) \cos(nt )dt$,"I hope there is no problem asking this. I am struggling to find a closed form/pattern for this integral $$I(n)=\int_0^\pi \exp\left(\frac{\cos t}{8}\right)\cos\left(\frac{\sin t}{8}\right) \cos(nt )dt$$ while trying to solve another integral found here: https://math.stackexchange.com/a/2912878/515527 .I started by finding small values for $I(n)$. Il just write them for $\frac{\pi}{I(n)}$ \begin{array}{|c|c|}
\hline
n & \frac{\pi}{I(n)} \\ \hline
1 & 2^4 \\ \hline
2 & 2^8 \\ \hline
3 & 2^{11}\cdot3 \\ \hline
4 & 2^{16}\cdot3 \\ \hline
5 & 2^{19}\cdot3\cdot5 \\ \hline
6 & 2^{23} \cdot 3^2 \cdot5 \\ \hline
9 & 2^{35}\cdot3^4\cdot5\cdot7 \\ \hline
10 & 2^{39}\cdot3^{4}\cdot5^2\cdot 7 \\ \hline
20 & 2^{79}\cdot3^8\cdot5^4\cdot7^2\cdot11\cdot13\cdot17\cdot19 \\ \hline
25 & 2^{98}\cdot3^{10}\cdot5^6\cdot7^3\cdot11^2\cdot13\cdot17\cdot19\cdot23\\ \hline
\end{array}
It seems to me, that if $n$ is not simultaneously a multiple of $2$ and a perfect square then the first term is of the form $2^{4n-1}$, howeverer this fails for $n=25$. Also the power counts how many primes (and multiples of that primes) are found untill $n$ and adds $1$ (to the power) if $n$ was already a perfect square, for example for $n=25$. $13,17,19,23$ are found once. $11$ is found twice as it can be written as $11 $and $2\cdot11$. $5$ is found $5$ times between $1$ and $25$ but as $25=5^2$ adds $1$ more to its power. Unfortunately I cant see a proper pattern. Could you perhaps share some help with this integral? It might be helpful to mention that $$\sum_{n=1}^\infty \frac{1}{3^n} I(n) =\frac{\pi}{2} \left(\sqrt[24]{e}-1\right)$$","['integration', 'closed-form', 'prime-numbers', 'sequences-and-series']"
2913143,Summation of this series ${1\over 2}\left[1+{1 \over 3}\left({1 \over 4}\right)^2+ {1 \over 5}\left({1 \over 4}\right)^4+\cdots\right]$,"I have this series, $${1\over 2}\left[1+{1 \over 3}\left({1 \over 4}\right)^2+ {1 \over 5}\left({1 \over 4}\right)^4+\cdots\right]$$ I have shown that this series converges. It looks like some combination of geometric series and harmonic series to me. I am not able to proceed from here. I would love to have some hint. Sorry this time I have nothing to write in ""my efforts"" as I am completely stuck.","['sequences-and-series', 'real-analysis']"
2913153,Equilibrium Solution in Solving a Linear ODE using an Integrating Factor,"Problem I've stumbled upon this differential equation during the second week of my ODE class in university: $$ y' - \frac{2}{t+1}y = (t+1)^2$$ And I solved it using the exact procedure in the ""Attempt"" section below. I checked my work and indeed got the right answer, but as I was solving the problem, I was having difficulty discerning the domain of the function and the equilibrium solutions that arise in the midst of solving such a problem. I believe there are no equilibrium solutions to take into account in this case, but my main goal of asking this question is for the answerer to outline when to check for equilibrium solutions , how to go about doing it , and providing best practices for constraining both the dependent and independent variables, as well as constants found along the way. Attempt Here is my attempt at the solution: $$ y' - \frac{2}{t+1}y = (t+1)^2 $$ $ t \neq -1 $ is implicitly assumed. $$ \mu(t) = e^{\int p(t)dt} $$
$$ p(t) = -\frac{2}{t+1} $$
$$ \int p(t)dt = \int -\frac{2}{t+1}dt = -2ln|t+1|+C_1 $$ for $ C_1 \in \mathbb R $. $$ \mu(t) = e^{-2ln|t+1| + C_1} = e^{C_1}e^{ln|t+1|^{-2}} $$ Let $ C_2 = e^{C_1}$ for $ C_2 \in \mathbb R $, $ C_2 \gt 0 $. $$ \mu(t) = C_2 e^{ln(\frac{1}{(t+1)^2})} $$
$$ \mu(t) = C_2 \frac{1}{(t+1)^2} $$ Multiplying both sides by the integrating factor $ \mu(t) $, $$ C_2 \frac{1}{(t+1)^2} y' - C_2 \frac{1}{(t+1)^2} \frac{2}{(t+1)}y = C_2 \frac{1}{(t+1)^2} (t+1)^2 $$
$$ (t + 1)^{-2} y' - 2(t+1)^{-3}y = 1 $$
$$ ((t+1)^{-2}y)' = 1 $$
$$ (t+1)^{-2}y = \int 1 dt $$
$$ (t+1)^{-2}y = t + C_3 $$ for $ C_3 \in \mathbb R $. Dividing both sides by $ \mu(t) $ we get, $$ \frac{(t+1)^2}{C_2 (t+1)^2} y = \frac{(t+1)^2(t+C_3)}{C_2} $$
$$ y = (t+1)^2(t+C_3) $$ Notes I'd love the answerer to identify where to check for equilibrium cases in this situation, as well as answer the above bolded questions. I understand equilibrium solutions are to be checked when variables may be separated to solve a differential equation, but I'd love to know all the other cases and have that part be elaborated to me. Here's the direction field for $ y' = f(t,y) $: Thanks in advance!","['integration', 'ordinary-differential-equations']"
2913191,Proving that $x^{2^n} + 1$ is irreducible in $\mathbb Q[x]$,"$x^{2^n} + 1$ is irreducible in $\mathbb Q[x]$ . I've been working on this and this is my process:
I would like to use Eisenstein's criterion so I considered the substitution $y=x-1$ . So $$x^{2^n}+1=(y+1)^{2^n}+1=\sum_{k=0}^{2^n}{2^n \choose k}y^{2^n-k}+1$$ $$={2^n \choose 0}y^{2^n}+{2^n \choose 1}y^{2^n-1}+\ldots+{2^n \choose 2^{n}-1}y+2$$ Take $p=2$ . Since $p$ doesn't divide $1=a_{2^n}$ and $p^2=4$ doesn't divide $2=a_0$ it only remains to show that  every ${2^n \choose j}$ for $1\leq j \leq 2^n-1$ is divisible by $2$ but I haven't succed showing the latter. Any ideas? Also, is my process correct? Thanks in advance","['irreducible-polynomials', 'abstract-algebra', 'cyclotomic-polynomials', 'polynomials']"
2913242,Computing fixpoints of noncrossing matchings of $2n$ points under rotation.,"For a definition of the cyclic sieving phenomena, see "" The cyclic sieving phenomenon: a survey "", by B. Sagan. A matching of $[2n] = \{1,2,\dots, 2n \}$ is a graph with vertex set $[2n]$ and with $n$ non-incident edges. A matching is noncrossing if there are no edges $ab$ and $cd$ such that $$a<c<b<d.$$ We denote the set of noncrossing matchings on $2n$ points by $\text{NCM}(2n)$ The cyclic group of order $2n$ has a natural group action on $\text{NCM}(2n)$ by rotation , see the picture from Sagan's survey: rotation of noncrossing matchings . I have seen several sources saying that the triple $(\text{NCM}(2n), C_{2n}, \text{Cat}_n(q))$ exhibits the cyclic sieving phenomena but I have not seen a proof of this fact anywhere. I know how to evaluate $\text{Cat}_n(q)$ in $2n$ :th roots of unity but I cannot figure out how to compute the fixpoints of $\text{NCM}(2n)$ under some rotation. Either an explanation of how to compute the fixpoints under some rotation or a link to some proof of this fact would be much appreciated! EDIT: As was pointed out in the comments, the $q$ -Catalan numbers can refer to more than one family of polynomials. The one that we are using, in this case, is indeed $$\text{Cat}_n(q)=\frac{1}{[1+n]_q}\left[2n \atop n\right]_q $$","['matching-theory', 'group-actions', 'combinatorics', 'discrete-mathematics']"
2913243,Understanding gradients on Riemannian Manifolds,"I am trying to understand how the gradients are defined on a Riemannian manifold, at least in a shallow way. The wikipedia definition is as the following: What I understand from this is, given a manifold $M$ with the metric $g$, the gradient of function $f$on the manifold $M$ is the vector field $(\nabla f)_x$ which produces for every $x \in M$ and $X_x \in T_xM$ a scalar $(\partial_{X}f)(x)$. According to the definition here, $(\partial_{X}f)(x)$ is equal to the directional derivative of $f$ at the direction of $X$, both evaluated at $x$. So, this should be $\nabla f(x)^TX_x$, if I understand correctly. But this understanding seems trivial; then the required $\nabla f$ will be just the evaluation of the function $f$'s gradient at each $x \in M$. And the last definition of $\partial_{X}f$ with the coordinate chart $\phi$ seems to tell something else; so I am confused here. What is the actual, correct interpretation of this definition?","['manifolds', 'calculus', 'riemannian-geometry', 'differential-geometry']"
2913250,Precise meaning of infinitely many,"I have a rather lame question here. I need a clarification with the definition of "" infinitely many "". 
I have come across statements like: There are infinitely many reals . I know that reals are non-denumerable (uncountably infinite). Again we have: There are infinitely many integers . I also know that integers are denumerable (countably infinite). So my question is what do we actually infer from ""infinitely many"" about the countability or the uncountability? Also kindly correct me if I am wrong somewhere.","['elementary-set-theory', 'definition', 'infinity']"
2913294,Show that $\left|\int_a^b f(x) dx\right|\leqslant \frac{M}{12}(b-a)^3$?,"$f$ is second order diffierentiable over $[a,b]$, $f(a)=f(b)=0$, $|f''(x)|\leqslant M$, Show that $\left|\displaystyle\int_a^b f(x) dx\right|\leqslant \dfrac{M}{12}(b-a)^3$? To make out the coefficient $\dfrac{1}{12}$, I tried this way: Write that $c=\dfrac{a+b}{2}$, according to the Taylor's formula, 
$$f(x)=f(c)+f'(c)(x-c)+\dfrac{f''(\eta)}{2}(x-c)^2,$$
Putting $x=a, x=b$, notice that $f(a)=f(b)=0$, then
$$
			      \begin{split}
				      0&=f(c)+f'(c)(a-c)+\dfrac{f''(\eta_1)}{2}(a-c)^2,\\
				      0&=f(c)+f'(c)(b-c)+\dfrac{f''(\eta_2)}{2}(b-c)^2,\\
			      \end{split}
$$
Then according to Darboux theorem, there exists $\zeta$ such that
$$f(c)=-\dfrac{(b-a)^2}{16}(f''(\eta_1)+f''(\eta_2))=-\dfrac{(b-a)^2}{8}f''(\zeta).$$
Then 
$$f(x)=\color{red}{{-\dfrac{(b-a)^2}{8}f''(\zeta)}}+\color{blue}{f'(c)(x-c)}+\color{green}{\dfrac{f''(\eta)}{2}(x-c)^2}.$$ Integrate both sides, the red part gives $-\dfrac{1}{8}$, the blue part gives zero, and the green part gives $\dfrac{1}{24}$, then the coeffcient $\dfrac{1}{12}$ shows up. However, I cannot get a proper inequality from this.","['integration', 'definite-integrals', 'calculus', 'integral-inequality', 'derivatives']"
2913323,about limit of exponential function [duplicate],"This question already has answers here : Limit of $\lim\limits_{n\to\infty} (1 + \frac{x_n}{n})^n$ (2 answers) Closed 5 years ago . Maybe the answer is obvious. I'm sorry for this I know for all $x \in \mathbb{R}$ that $$
\lim_\limits{n \to \infty}\left(1 + \frac{x}{n} \right)^{n} = \exp(x).
$$ Now suppose I have a sequence $\{x_{n}\}_{n \in \mathbb{N}}$ such that $$
\lim_\limits{n \to \infty} x_{n} = x \in \mathbb{R}.
$$ Can I also conclude that $$
\lim_\limits{n \to \infty}\left(1 + \frac{x_{n}}{n} \right)^{n} = \exp(x)?
$$","['sequences-and-series', 'exponential-function', 'real-analysis']"
2913333,Proving homomorphism from a cyclic group of prime order to some other group is injective or trivial,"Here's my attempt: I'll be using this for my proof: If $\varphi : G \to G^\prime $ is a group homomorphism and $a \in G$
  with $\text{ord} (a) = r$ then $\text{ord} (\varphi (a))$ divides $r$. Let $G=\langle a \rangle$ where $\text{ord} (a) = p$ for some prime $p$ and $G^{\prime }$ be any other group. Also it is easy to notice if $\varphi$ is any homomorphism from $G$ to $G^{\prime }$ then $\varphi$ is determined by $\varphi (a)$. (In other words, to define the homomorphism we only need to define $\varphi (a)$. Now if $\varphi (a) = e_{G^{\prime}}$ then for any $n \in \mathbb{Z}_p$, we have $\varphi (a^n)= (\varphi (a)) ^n = e_{G^{\prime}}$. Thus making $\varphi$ the trivial homomorphism. Now, suppose that $\varphi (a) \ne e_{G^{\prime}}$ then we need to show $\varphi$ is injective. Let $x,y \in G$. Then  $x=a^m$ and $y=a^n$ for some $m,n \in \mathbb{Z}_p$. If $\varphi (x) = \varphi (y)$ then $\varphi (a^m ) = \varphi (a^n )$. It follows that $(\varphi (a))^{m-n} = e_{G^{\prime}}$. Now, by the corollary at the beginning of the proof, we must have that $\text{ord} (\varphi (a))$ divides $p$. Thus, it must be that $\text{ord} (\varphi (a)) = p$. And if  $(\varphi (a))^{m-n} = e_{G^{\prime}}$ then $p$ divides $m-n$ but $m-n < p$ (since $m,n \in \mathbb{Z}_p$) thus it must be that $m=n$. And therefore, $x=y$ and thus $\varphi$ is injective. Is my proof correct? Or am I missing out something?","['group-theory', 'abstract-algebra']"
2913363,Find the radius of a cylinder of given volume V if its surface area is a minimum.,"this question is driving me crazy as I'm not sure how they've got the answer. The surface area is given as $S = 2\pi r^2 + \frac {1}{50r} $ and they are asking for the value of r for which S is minimum. The derivative of this (I hope!) is $4\pi r - \frac {1}{50r^2}$ Then to find the value of r when S is a minimum I presume you set the derivative to equal $0$. The book shows the value $200π - \frac 13 $ but I'm not sure how they've got this figure from setting the derivative to $0$. Any insight would be appreciated! Edit: My bad, answer is raised to negative $ \frac {1}{3}$, you live, you learn. Thanks for pointing this out.",['derivatives']
2913379,Under what conditions we have $\|Tx\| = \|T\| \|x\|$?,"For bounded linear operator we have  $\|Tx\| \le \|T\| \|x\|$ but when the equality takes, i.e., $\|Tx\| = \|T\| \|x\|$? PS. 
If $T$ is an isometry then $\|Tx\|=\|x\|$ and $\|T\|=1$, therefore the equality holds for all $x$, right?","['operator-theory', 'functional-analysis']"
2913385,Associative law for infinite unions,"Let $A$ be a function s.t. $\mbox{dom}(A)=I\times J$. Prove that: $\bigcup_{i \in I,j \in J}A_{ij}=\bigcup_{i \in I}\left ( \bigcup_{j \in J}A_{ij}\right )$. The problem is that I cannot interpret the right-hand side of the equation. By the book, if $A$ is a function with $\mbox{dom}A=I$, $\bigcup_{i \in I}A_{i}:=\bigcup\mbox{rng}(A)$. On the left-hand side of the equality I have to prove, we clearly have a function. On the right-hand side, no matter how I rearrange it, I cannot interpret the nested union by definition. Let me explain. By definition, on the left-hand side I have $\bigcup_{i \in I,j \in J}A_{ij}\\
:=\bigcup_{(i,j)\in I\times J}A(i,j)\\
:=\bigcup\mbox{rng}A.$ Let's see an example with: $I\times J=\{(0,0),(0,1),(1,0),(1,1)\},\\
A(0,0)=\{0\},\\
A(0,1)=\{1\},\\
A(1,0)=\{2\},\\
A(1,1)=\{3\}.\\$ Then 
$A=\{\\
((0,0),\{0\}),\\ 
((0,1),\{1\}),\\ 
((1,0),\{2\}),\\ 
((1,1),\{3\})\}.$ And in the following calculations we can see what we get left-hand side. $\mbox{rng}A\\
=\{y:\exists x[(x,y)\in A]\}\\
=\{\{0\},\{1\},\{2\},\{3\}\}$. $\bigcup_{(i,j)\in I\times J}A(i,j)\\
=\bigcup \mbox{rng}A\\
=\{x:\exists y \in \mbox{rng}A(x \in y)\}\\
=\{x:\exists y \in \{\{0\},\{1\},\{2\},\{3\}\}(x \in y)\}\\
=\{0,1,2,3\}$. For the right hand side we define the following functions. Let $i \in \{0,1\}$. $A\upharpoonright (\{i\}\times \{0,1\})=A\cap (\{(i,0),(i,1)\}\times \mbox{rng}A),\\
A\upharpoonright (\{0\}\times \{0,1\})=A\cap (\{(0,0),(0,1)\}\times \mbox{rng}A),\\
A\upharpoonright (\{1\}\times \{0,1\})=A\cap (\{(1,0),(1,1)\}\times \mbox{rng}A)$. We have then: $\mbox{rng}A\upharpoonright (\{0\}\times \{0,1\}),\\
=\{y:\exists x[(x,y)\in A\upharpoonright (\{0\}\times \{0,1\})]\},\\
=\{\{0\},\{1\}\}$. $\mbox{rng}A\upharpoonright (\{1\}\times \{0,1\}),\\
=\{y:\exists x[(x,y)\in A\upharpoonright (\{1\}\times \{0,1\})]\},\\
=\{\{2\},\{3\}\}$. $\bigcup_{j \in J}A\upharpoonright (\{0\}\times \{0,1\})_{j}\\
:=\bigcup \mbox{rng}A\upharpoonright (\{0\}\times \{0,1\})\\
=\{x:\exists y \in \mbox{rng}A\upharpoonright (\{0\}\times \{0,1\})(x \in y)\}\\
=\{x:\exists y \in \{\{0\},\{1\}\}(x \in y)\}\\
=\{0,1\}$ $\bigcup_{j \in J}A\upharpoonright (\{1\}\times \{0,1\})_{j}\\
=\{1,2\}$. So it is clear by this example that taking the union for $i=1,2$ we get $\{1,2,3,4\}$. Still, I don't have the definition for the nested union so I cannot really prove the theorem not knowing what am dealing with. Is there a more general definition of infinite union I am not aware of? Notation from: Introduction to Set Theory, Donald Monk.","['elementary-set-theory', 'logic']"
2913412,Expectation and variance of top 10% of any normal distribution,"Short:
With the standard curve (i.e. mean=0, std dev=1), does the top 10% form its own normal distribution with the expectation about 1.74 and the standard deviation about .40? Long:
I wrote a little program that takes the numbers 0.005,.015,.025,...,0.995, which is 100 numbers. I take the top 10 (.905-.995), find their z-score (1.31,1.37,...,2.58), sum them and divide by 10 and get 1.7447. In a similar manner, I go about finding the variance and get .1578, or a standard deviation of about .3972. All seems well so far. I then take the lower 90 numbers and calculate the expectation and get -.194. This works because if I use the law of iterated expectations, the expectation turns out to be 0, which we expect from the standard curve. I then use the law of total variance and get the unusual answer of 1.118, instead of 1. The expectation of the two variances is .658 and the variance of the two expectations is .460. This doesn't seem so bad, after all I'm approximating with 100 numbers. So then I ran it again with 1000 numbers and then with 10,000 numbers. It seems to be converging on a variance of about 1.116, which I did not expect. Any ideas on the discrepancy or a better way to figure this out? TIA,
Cary",['statistics']
2913430,Find the limit of $\sum\limits_{r=\lfloor an \rfloor}^{\lfloor bn \rfloor} {n \choose r } p^r (1-p)^{n-r}$ using the central limit theorem,"Let $p \in(0,1)$. What is the distribution of the sum of $n$ independent Bernoulli random variables with parameter $p$? Let $0 \leq a < b \leq 1$. Use approprtiate limit theorems to determine how the following depends on $a$ and $b$: 
  $$\lim_{n\to\infty} \sum_{r=\lfloor an \rfloor}^{\lfloor bn \rfloor} {n \choose r } p^r (1-p)^{n-r}\ $$ I know that the sum of $n$ Bernoulli random variables with parameter $p$ has binomial distribution $Bin(n,p)$. I see that the above is equal to $P(an \leq X \leq bn) $ where $X$ is the sum, and I can see how to use the weak law of large numbers in the cases where $p \neq a$ and $p \neq b$ to find the appropriate limits, but I can't see what I have to do when $p=a$ or $p=b$. I assume I have to apply the central limit theorem, but I really don't see how to do that. Any help you could give me would be really appreciated.","['central-limit-theorem', 'probability-distributions', 'law-of-large-numbers', 'probability-theory', 'probability']"
2913438,Solving an absolute-value inequality: $−|x|+2 \geq 8x $,"How would I go about solving the domain of this inequality?
$$−|x|+2 \geq 8x $$
I can't combine the $x$'s so I don't know what to do. Could I say:
$$-x + 2 ≥ 8x $$
and
$$x - 2 ≥ 8x $$
and solve the domain from there?","['algebra-precalculus', 'absolute-value', 'inequality']"
2913483,The limit as a function on functions?,"Is the observation that, "" The limit is a function on functions ,"" true or meaningful? Since the limit is unique, if it exists, then the pair
$\displaystyle(c,\lim_{x\to c}f(x))$ itself defines a function for some function $f$. I was just thinking about the idea and wanted some outside feedback.","['limits', 'calculus']"
2913526,Continuous Functional Calculus Argument in Fell's Paper,"I am reading an old paper of Fell's and I am having some problems sorting out one of his continuous functional calculus arguments. The essential problem is this. Let $A$ be a C$^{*}$-algebra and let $b$ and $p$ be elements in $A$ such that $b$ is positive and $p$ is a projection with the additional assumptions that: 1) $pbp=b$ 2) $\|p-b\|<1/8$. Let $\psi\colon\mathbb{R}\to[0,\infty)$ be continuous and bounded function that satisfies
$$
\begin{aligned}
\psi(r)=
\begin{cases}
0&\text{if } r=0,\\
1&\text{if } |r-1|\leq 1/8.
\end{cases}
\end{aligned}
$$ The claim is that $\psi(b)=p$.
  I am having trouble showing this. I'm not sure how to relate fact 2) with the fact that $\psi$ is identically $1$ on $[7/8,9/8]$ and, moreover, how to use this (or another method) to yield the result.","['c-star-algebras', 'operator-theory', 'functional-analysis', 'operator-algebras']"
2913601,Speed of convergence of Riemann sums,"This question is inspired by a previous question . It was shown that, for all function $f \in \mathcal{C} ([0, 1])$, $$ \lim_{n \to + \infty} \sum_{k=0}^{n} f \left( \frac{k}{n+1} \right) - \sum_{k=0}^{n-1} f \left( \frac{k}{n} \right) = \int_0^1 f (x) \ dx.$$ A stronger statement would be that there exists some constant $a(f)$ such that: $$\sum_{k=0}^{n-1} f \left( \frac{k}{n} \right) = n \int_0^1 f (x) \ dx + a(f) + o(1),$$ or, in other words, that there is an asymptotic development at order $1$ of the Riemann sums: $$\frac{1}{n} \sum_{k=0}^{n-1} f \left( \frac{k}{n} \right) = \int_0^1 f (x) \ dx + \frac{a(f)}{n} + o(n^{-1}).$$ Given $f$, can we always find such a constant $a(f)$? If this is false, can we find a counter-example? If this is true, can $a(f)$ be written explicitely? I have had a quick look at the litterature, but most asymptotics for the Riemann sums involve different meshes, which depend on the function $f$.","['riemann-sum', 'asymptotics']"
2913608,Which method to use to integrate this function?,Recently I've been working on problems including integration and I'm having some difficulties solving this integral : $$\int_0^1 (1-x)\sqrt{4x-x^2} {dx}$$ I tried to rewrite it in this form: $$\int_0^1 (1-x)x\sqrt{\frac{4-x}{x}} dx$$ and then subsitute $\frac{4-x}{x}=t^2$ and by this substitution I get a function way easier integrated of this form: $$-32\int\frac{(t^2-3)t^2}{(1+t^2)^4}dt$$ I can integrate this function easily by simplifying it but the problem is that I cannot define its borders because $t$ is not defined for $x=0$ so this means that my substitution doesn't hold. But I don't have any other idea how to solve it so any help will be appreciated.Thank you!,"['integration', 'definite-integrals', 'real-analysis']"
2913610,Find a real-valued vector solution to a system of differential equations,"Given: 
$$\vec x'(t) = \begin{bmatrix}
    4&-1\\
13&0
    \end{bmatrix} \vec x(t) $$ Evaluating to find eigenvalues:
$$ (4-\lambda)(-\lambda)+13=0 $$$$ (\lambda-2)^2=-9$$ $$\lambda=2\pm3i$$ Finding the eigenvector for the eigenvalue $\lambda = 2+3i$:
$$ \left[
\begin{array}{cc|c}
  2-3i&-1&0\\
  13&-2-3i&0
\end{array}
\right] $$
Since, for a 2x2, the rows must be complex scalar multiples of each other (here: R2 = (2 + 3i)R1 ), then picking row 2: \begin{align*} \begin{cases} v_1=\frac{2+3i}{13}v_2 \\ v_2=free \end{cases} \end{align*} $$\vec v= v_2 \begin{bmatrix}
    \frac{2+3i}{13}\\
1
    \end{bmatrix} = v_2\begin{bmatrix}
    2+3i\\
13
    \end{bmatrix}$$
The solution takes the form of:
$$e^{\lambda_1t}\vec v_1 = e^{(2+3i)t}\begin{bmatrix}
    2+3i\\
13
    \end{bmatrix}
$$
However, this is not a real-valued vector solution, since the eigenvector has an imaginary part. How should I proceed?","['ordinary-differential-equations', 'eigenvalues-eigenvectors']"
2913639,If two spaces are homeomorphic and one is a metric space must the other be as well?,"Suppose $X$, and $Y$ are topological spaces, and that they are homeomorphic. If $X$ is a metric space must $Y$ be as well? Here is my thought process. If $X$ is a metric space then there exists some distance function  on $X$ given by $d:X\times X\rightarrow\Bbb R$. Let $\varphi:X\rightarrow Y$ be a homeomorphism between $X$ and $Y$. Then for any distinct points $y_1,y_2\in Y$ we can determine a ""distance"" between them by $d(\varphi^{-1}(y_1),\varphi^{-1}(y_2))\in\Bbb R$ To be a metric space however, I need some way of combining this idea of passing the points back to $X$ from $Y$ in a nice way, and then applying the distance function on $X$. Would it be as simple as defining $d'(y_1,y_2) = d(\varphi^{-1}(y_1),\varphi^{-1}(y_2))$? If not is there a way to do that? Is this enough to say that $Y$ is a metric space? Or am I just out of my mind?","['general-topology', 'metric-spaces']"
2913661,"Are Unions/Intersections of Cartesian Products of Indexed Sets ""Distributive""?","In a situation like $\bigcup\limits_{x \in [0,1]} [x,1] \times [0,x^2]$, could one correctly assume that $\bigcup\limits_{x \in [0,1]} [x,1] \times \bigcup\limits_{x \in [0,1]}[0,x^2]$ also holds true? That is to say, is it ""distributive"" in some sense of the word? In general, if $\bigcup\limits_{i \in I} A_i \times B_i$ or $\bigcap\limits_{i \in I} A_i \times B_i$ for some indexed sets $A_i, B_i$, does it hold that: $$\bigcup\limits_{i \in I} A_i \times B_i = \bigcup\limits_{i \in I} A_i \times \bigcup\limits_{i \in I} B_i$$
$$\bigcap\limits_{i \in I} A_i \times B_i = \bigcap\limits_{i \in I} A_i \times \bigcap\limits_{i \in I} B_i$$ in general?","['elementary-set-theory', 'proof-writing']"
2913682,"Evaluating the integral $\int_{0}^{\infty} \frac{\exp(-u^2)}{1+u^2} \, du$","I am trying to calculate the following integral $$ \int_{0}^{\infty} \frac{\exp(-u^2)}{1+u^2} \, du. $$ Wolfram gives a beautiful analytical answer: ${\rm e}\pi\operatorname{erfc}(1)$. I've tried every trick in my book (change of variable, contour, ...). I would love to see a proof of that beautiful result :)
Thanks in advance for any help.","['integration', 'contour-integration']"
2913689,How can I show that the system of non-linear differential equations does not have periodic orbits?,"The system is the following: $\left\{\begin{matrix}
x'=&2x-x^5-xy^4 \\ 
y'=&y-y^3-x^2y 
\end{matrix}\right.$. What I did was to find singular points in the system: from which I got the following singular points: $(0,0); (0,1);(0, -1);(\sqrt[4]{2},0);(\sqrt[4]{2},0)$. Then, I have classified them if they are attractors, chair, etc. But I do not know how to prove that the system does not have periodic orbits. Can someone guide me? Please. Thanks in advance. Best regards.","['nonlinear-system', 'ordinary-differential-equations']"
2913726,Only prime in a large interval,"Prove there exists a prime number $p > 10^{100}$ such that $p$ is the only prime number in the interval $[p − 10^{20}, p + 10^{20}]$. I was looking through NT notes online and came across this homework question on a problem set. I am not sure how to gain traction on this problem. So far I tried bounding a bit with Bertrand but I'm not sure that's leading anywhere.","['number-theory', 'prime-numbers']"
2913765,Using geometry to show that $\int_{0}^{b} \sqrt{1-x^2} dx = \frac{1}{2}b\sqrt{1-b^2}+\frac{1}{2}\sin^{-1}b$,"Show that for $0\leq b\leq1$ , $$\int_{0}^{b} \sqrt{1-x^2} dx = \frac{1}{2}b\sqrt{1-b^2}+\frac{1}{2}\sin^{-1}b$$ by using geometry. This is what I have thus far: $\int_{0}^{b} \sqrt{1-x^2} dx$ $$=y=\sqrt{1-x^2}$$ $$=y^2=1-x^2$$ $$=x^2+y^2=1$$ From the picture above, to find the area we add the area of the sector and the area of the triangle.
Area of sector: $\frac{θ}{2}r^2$ Area of triangle: $\frac{1}{2}bh$ Side note: $(h=a)$ I have no clue what to do next. Please help.","['integration', 'triangles', 'area', 'geometry']"
2913868,"Integral $\int_0^\infty \frac{\arctan(x) }{x(1+x^2)}\,dx$?","How would one evaluate the integral $$\int_0^\infty \frac{\arctan(x) }{x(1+x^2)}\,dx$$ ? I was told it had a nice closed form and could have been solved with differentiation under the integral sign; however, I tried to set $$I(\alpha) = \int_0^\infty \frac{\arctan(\alpha x)}{x(1+x^2)}~dx$$ and got nowhere (the resulting integral was very messy). Is there a much more clever substitution that can be used to tackle the integral?","['integration', 'calculus', 'definite-integrals']"
2913875,"Beginner probability question about the phrase ""order doesn't matter""","This is a lame question but it's been bugging me for a while... A father and his son are at a diner and each make one selection (randomly and independently) from a list of $10$ different dishes on a menu. What is the probability they choose different dishes? Let $E$ be the event that they choose separate dishes. Let's condition on the father ordering first (call the event $F$) then, $$P(E) = P(E \mid F) P(F) + P(E \mid F^c) P(F^c)=\left(\frac{1}{2}\right)\left(\frac{9}{10}\right)+\left(\frac{1}{2}\right)\left(\frac{9}{10}\right) = \frac{9}{10}$$ Question 1: I don't think you can say ""order doesn't matter"" for this problem. I think order does matter. Is that correct? You could say ""regardless of the order for this situation the conditional probabilities happen to be symmetrical, $P(E|F) = P(E|F^c) = 9/10$, and since the probability of the conditioning event is one half, the probability of the event in question is equal to just one of the conditional probabilities."" That is $P(E) = P(E|F)$. Is that the right way to think about this problem? Let's say I condition on the dish ordered by the first person $$\sum_{i=1}^{10} P(E \mid T=i)P(T=i) = \sum_{i=1}^{10} \frac{9}{10}\frac{1}{10} = 9/10$$ Question 2: Is this the same situation where ""order does matter"" it's just that the $P(E)$ is equal to either $P(E \mid T=i)P(T=i)$ summed for all $i$ whether the father or son goes first? Question 3: If order does matter, then how does the problem change if you say they choose them exactly simultaneously? Thanks.","['conditional-probability', 'probability']"
2913877,Trouble understanding filter and ultrafilter,"A filter F on S is a collection of subsets of S in which two conditions hold: If A and B belong to the collection F then A∩B also belongs to the collection.
If A belongs to the collection F and A is a subset of B then B also belongs to the collection. (If A⊂B then B is said to be a superset of A.)
For S={a, b, c} one filter is the collection :
{ {a}, {a, b}, {a, b, c} }
Why is {a,c} not in the filter collection here, {a} is a subset of {a,c} so it must be in the example given above .
Can someone make me understand ultrafilter with respect to Boolean Algebra ?","['elementary-set-theory', 'boolean-algebra', 'filters']"
2913924,Suppose that $f:\mathcal{P}(A) \to \mathcal{P}(A)$ is an increasing mapping. Then there exists $G\subseteq A$ such that $f(G)=G$,"Suppose that $f:\mathcal{P}(A) \to \mathcal{P}(A)$ is an increasing mapping with respect to $\subseteq$, i.e. if $B\subseteq C$ then $f(B)\subseteq f(C)$. Then there exists $G\subseteq A$ such that $f(G)=G$. My attempt: Let $\mathcal G=\{B\in \mathcal{P}(A) \mid B\subseteq f(B)\}$ and $G=\bigcup\limits_{B\in\mathcal G}B$. If $B\in\mathcal G$ then $B\subseteq G$ and consequently $f(B)\subseteq f(G)$. Thus $B\subseteq f(B)\subseteq f(G)$ for all $B\in\mathcal G$ and thus $G=\bigcup\limits_{B\in\mathcal G}B \subseteq f(G)$. Hence $G\in\mathcal G$. Since $G\subseteq f(G),f(G)\subseteq f(f(G))$. As a result, $f(G)\in \mathcal G$. It follows that $f(G)\subseteq G$. To sum up, we have $G\subseteq f(G)$ and $f(G)\subseteq G$. This implies that $f(G)=G$. Does this proof look fine or contain gaps? Do you have suggestions? Many thanks for your dedicated help!","['elementary-set-theory', 'proof-verification']"
2913953,Geodesic curvature for orthogonal parametrization,"On page 252 of do Carmo's book ""Differential Geometry of Curves and Surfaces"" there is a proof given of the following proposition: Let $x(u,v)$ be an orthogonal parametrization (that is, $F=0$) of a
  neighborhood of an oriented surface $S$, and $w(t)$ be a
  differentiable field of unit vectors along the curve $x(u(t), v(t))$.
  Then
  $$\left[\frac{Dw}{dt}\right]=\frac{1}{2\sqrt{EG}}\left\{G_u\frac{dv}{dt}-E_v\frac{du}{dt}\right\}+\frac{d\varphi}{dt}$$
  where $\varphi(t)$ is the angle from $x_u$ to $w(t)$ in the given
  orientation. Here is up to the relevant part the proof. I don't understand how the last equality in the below proof comes about. That equality is $\left\langle \left(\frac{x_u}{\sqrt{E}}\right)_u,\frac{x_v}{\sqrt{G}} \right\rangle=-\frac{1}{2}\frac{E_v}{\sqrt{EG}}$ and I don't see why the partial by $u$ on the left hand side does not effect the denominator $\sqrt{E}$ give that $E$ should be defined as $x_u \cdot x_u$ Proof. Let $e_1 = x_u/\sqrt{E}$, $e_2=x_v/\sqrt{G}$ be the unit vectors tangent to the coordinate curves. Observe that $e_1\wedge e_2=N$, where $N$ is the given orientation of $S$. By using Lemma 2, we may write $$\left[\frac{Dw}{dt}\right]=\left[\frac{De_1}{dt}\right]+\frac{d\varphi}{dt}$$ where $e_1(t)=e_1(u(t),v(t))$ is the field $e_1$ restricted to the curve $x(u(t),v(t))$. Now $$\left[\frac{De_1}{dt}\right]=\left\langle\frac{de_1}{dt},N\wedge e_1\right\rangle=\left\langle\frac{de_1}{dt},e_2\right\rangle=\left\langle(e_1)_u,e_2\right\rangle\frac{du}{dt}=\left\langle(e_1)_v,e_2\right\rangle\frac{dv}{dt}$$.
On the other hand, since $F=0$, we have $$\langle x_{uu},x_v \rangle=-\frac{1}{2}E_v$$, and therefore $$\left\langle (e_1)_u,e_2 \right\rangle=\left\langle \left(\frac{x_u}{\sqrt{E}}\right)_u,\frac{x_v}{\sqrt{G}} \right\rangle=-\frac{1}{2}\frac{E_v}{\sqrt{EG}}$$","['geodesic', 'curvature', 'differential-geometry']"
2913954,Composite tangent function questions (domain and solving an equation),"The question is as follows: Let $h$ be the function such that $h(x) = \tan\left(\sqrt{\dfrac{1}{x+2}}\right)$. (a) Find the domain of $h$ and (b) find the values of $x$ such that $h(x)=1$. For part a, I notice that $1/(x+2)$ is the argument of a square root function. My class defaults to functions having a domain and codomain of real numbers, so it follows that $1/(x+2)$ must be nonnegative. By interval testing, I determine that $x \in   (-2,\infty)$. I also notice that tangent has undefined values, i.e. the undefined values of $\tan(x)$ are $x \in \pi/2 + \pi n, n \in \mathbb{Z}$. So this must also be considered in the domain: $$\sqrt{\frac{1}{x+2}} \ne \frac{\pi}{2} + \pi n, n \in \mathbb{Z}$$ If I square both sides and then isolate $x$, it results in $$ x \ne \dfrac{1}{\left(\frac{\pi}{2} + \pi n\right)^2} -2,\ n\in\mathbb{Z}$$ So the domain of $h$ is $$\left\{x \mid x\in\mathbb{R}, x\in (-2,\infty), x \ne \frac{1}{(\pi/2+\pi n)^2}-2, n \in\mathbb{Z} \right\} $$ Is this answer and set-builder notation okay? For part b, solving $ \tan\left(\sqrt{\frac{1}{x+2}}\right) = 1$ lead me to $$ \sqrt{\frac{1}{x+2}} = \frac{\pi}{4} + \pi n,\ n\in\mathbb{Z}$$ and squaring both sides and solving for $x$ gives $$ x = \frac{1}{\left(\frac{\pi}{4} + \pi n\right)^2} - 2,\ n\in\mathbb{Z}$$ This seems to hold for $n\ge 0$, but for negative $n$, this results in a wrong result (leading to $h$ giving values of $-1$ instead of $1$). How could I have predicted an extra restriction for $n$?","['calculus', 'rational-functions', 'trigonometry']"
2913955,$a$ is an element of a set of a set of $a$?,I'm having a hard time conceptualizing what this means: $a \in \{\{a\}\}$ Is this saying that the a is an element of the set of set a?,['elementary-set-theory']
2914005,Why can't $\frac{1}{\sin(x)\cos(x)}$ be expressed in the form $\frac{A}{\sin x}+\frac{B}{\cos x}$,"I've tried expressing $\frac{1}{\sin(x)\cos(x)}$ as partial fractions: $$\frac{1}{\sin(x)\cos(x)} = \frac{A}{\sin x}+\frac{B}{\cos x}
\implies 1=A\cos x + B\sin x$$ I let $x=\frac{\pi}{2}$, getting $A=-1$. Then I let $x=\pi$, getting $B=1$. This means that $1=\cos x-\sin x$ which is obviously wrong most of the time. But why is it wrong? If the denominator had something like $(x^2-1)$ I still can get a correct answer for different values I substitute.","['trigonometry', 'partial-fractions']"
2914105,Inverse of an element of the group $\mathbb{Z}_n$ under addition $\pmod{n}$,"Quick Check: Find the inverse of the element $13$ in $\mathbb{Z}_{20}$ under addition $\pmod{20}$. For any $j>0$ in $\mathbb{Z}_n$, the inverse of $j$ is $n-j$. Hence, our inverse element is $7$ since $(13+7) \equiv 0 \mod20.$ This seems pretty straightforward, however the answer in the back of my book says the inverse element is $17$. Is this a typo?",['group-theory']
2914114,Convergence of $\sum_{n=1}^{\infty}\left(\left(\sqrt{n}\right)\left(n^{\alpha\cos(\frac{1}{n})}-n-\cos\left(\frac{1}{n}\right)\right)\right)^{-1}$,"Convergence of the following series as $\alpha \in \mathbb{R}$ $$\sum_{n=1}^{\infty}\left(\left(\sqrt{n}\right)\left(n^{\alpha\cos(\frac{1}{n})}-n-\cos\left(\frac{1}{n}\right)\right)\right)^{-1}$$ As $n \to +\infty$ we have $a_n\sim \left(n^{\frac{1}{2}}\left(n^{\alpha}-n-1\right)\right)^{-1} = \left(n^{\frac{2\alpha+1}{2}}-n^\frac{3}{2}-n^\frac{1}{2}\right)^{-1}$ Hence, as $0<\alpha<1$ we have $a_n =\mathcal{O}\left(\frac{1}{n^\frac{3}{2}}\right)$, as $n \to +\infty$, that converges. As $\alpha>1$ we have $a_n=\mathcal{O}\left(\frac{1}{n^\frac{2\alpha+1} {2}}\right)$, as $n \to +\infty$, which converges in turn. Is it right or I got rid of too much informations in the asymptotic expansion?","['sequences-and-series', 'real-analysis']"
2914123,The semidirect product $(C_7\times C_{13})\rtimes C_3$,"Following this page , in the classification of groups of order $273$ , the product of the Sylow group $S:=C_7C_{13}\simeq C_{7}\times C_{13}$ is normal, hence can be acted on by the Sylow $C_3$ to produce semidirect products. Since $\operatorname{Aut}(S)\simeq C_6\times C_{12}$ , one only needs to find an order 3 element there to produce the homomorphism $C_3\rightarrow \operatorname{Aut}(S)$ . In particular, if $C_6=\langle x\rangle$ and $C_{12}=\langle y\rangle$ , up to choice of generators of $C_3$ , the group is classified by the 5 actions corresponding to: $(1,1), (x^2,1), (1,y^4), (x^2,y^4), (x^{-2},y^4)$ . It is easy to see that the center of the corresponding groups has order $273, 13, 7, 1, 1$ respectively. So my question is: how do we show that the last two groups are actually non-isomorphic? P.S. In a similar example with $(C_7\times C_7)\rtimes C_3$ on the same page , the last two groups can be distinguished since every subgroup of order $7$ can be shown to be normal in one but not the other.","['semidirect-product', 'group-theory', 'abstract-algebra', 'finite-groups']"
2914135,Computing the derivative of matrix inverse using the chain rule,"Let $\text{Inv}: GL_n(\mathbb{R})\to GL_n(\mathbb{R})$ be defined by $\text{Inv}(X)= X^{-1}.$ Problem $33$ in Chapter $5$ of Pugh's Real Mathematical Analysis states: ""Observe that $Y = \text{Inv}(X)$ solves the implicit function problem $F(X, Y)-I =0$ where $F(X, Y)= XY.$ Assume it is known that $\text{Inv}$ is smooth and use the chain rule to derive from this equation a formula for the derivative of $\text{Inv}.$"" My attempt: Differentiating both sides of the given equation wrt $X$ at an arbitrary $A \in M_{n}(\mathbb{R})$and using the chain rule for the $LHS$ we get $\left(\dfrac{\partial F}{\partial X}\right)_{A}+ \left(\dfrac{\partial F}{\partial Y}\right)_AY'(A) =0.$ My problem is in evaluating the partials of $F$ wrt $X$ and $Y.$ For $n=2,$ I wrote $X= \begin{pmatrix} x_{11} &x_{12}\\x_{21}&x_{22}\end{pmatrix}$ and $Y= \begin{pmatrix} y_{11} &y_{12}\\y_{21}&y_{22}\end{pmatrix}$ so that $F(X, Y) = XY =\begin{pmatrix} x_{11}y_{11}+x_{12}y_{21} &x_{11}y_{12}+x_{12}y_{22}\\x_{21}y_{11}+x_{22}y_{21}&x_{21}{y_{12}+x_{22}y_{22}}\end{pmatrix}$ then $\dfrac{\partial F}{\partial X} = \begin{pmatrix} Y^{T} &0_{2\times2}\\0_{2\times2}&Y^{T}\end{pmatrix} $ and $\dfrac{\partial F}{\partial Y} = X \otimes I_{2\times 2}$ where $\otimes$ denotes the Kronecker product . For $\dfrac{\partial F}{\partial X}$ to act on $A$, we must write $A$ as a $4 \times 1$ column vector $\begin{pmatrix} a_{11}&a_{12}&a_{21}&a_{22}\end{pmatrix}^{T}$ so that rewriting $\left(\dfrac{\partial F}{\partial X}\right)_{A} = \dfrac{\partial F}{\partial X}(A)$ as a $2\times 2$ matrix we get $AY$ and rewriting $\left(\dfrac{\partial F}{\partial Y}\right)_{A} = \dfrac{\partial F}{\partial Y}(A)$ we get $XA$. Plugging back in the above equation and using the fact that $Y= X^{-1}$ we get $AY'(A) = -X^{-1}AX^{-1}.$ My question: what have I done wrong that caused me to get stuck with an extra $A$ on the LHS? (From first principles I have proven that correct answer is $Y'(A) = -X^{-1}AX^{-1})$ but I am unable to get that formula from this approach. I am unable to pinpoint what I have made a mistake in. Is it the inconsistent treatment of $A$? I'd appreciate any pointers or hints. Thanks in advance.","['partial-derivative', 'multivariable-calculus', 'proof-verification', 'matrix-calculus']"
2914158,How many combinations in a parliament?,"Imagine a parliament with 4 parties that can form a government (this is a parliamentary democracy, not the US style democracy). The government does not need to have a majority behind it in the parliament (in the long run it does need it but not for this example). How many possible combinations of parties are there? I thought you calculated this using permutations but 4/4 returns 24 and when I do this manually I only come up with 15 combinations: ABCD
ABC
ABD
ACD
BCD
AB
AC
AD
BC
BD
CD
A
B
C
D https://www.calculatorsoup.com/calculators/discretemathematics/permutations.php?n=4&r=4&action=solve In my case order does not matter (that is, ABC and CBA is the same) and items must not repeat. Does a regular permutation calculation take this into account? If not, how do I calculate this? Something like ""combination (4 elements out of of 4 elements) + combination (3 of 4) + combination (2 of 4) + combination (1 of 4)""? What is this called?","['combinations', 'combinatorics']"
2914181,Let $X$ be uncountable and $A$ be a countable subset of $X$. Then $X$ and $X \setminus A$ are equinumerous,"Let $X$ be uncountable and $A$ be a countable subset of $X$. Then $X$ and $X \setminus A$ are equinumerous. I have previously proved that Suppose that $X$ is infinite and that $A$ is a finite subset of $X$. Then $X$ and $X\setminus A$ are equinumerous here . I have a feeling that the result can be extended by this theorem, so I tried to give a shot. Does this proof look fine or contain gaps? Do you have suggestions? Many thanks for your dedicated help! My attempt: Lemma 1 : If $A \sim \Bbb N$ and $B \sim \Bbb N$, then $A\cup B \sim \Bbb N$. Lemma 2 : If $X$ is uncountable, then there exists $B\subsetneq X$ such that $B \sim \Bbb N$. There are only two cases. $A$ is finite (I presented a proof here ) $A$ is infinite Then $A$ is countably infinite and consequently $A\sim\Bbb N$. Since $X$ is uncountable and $A$ is countable, then $X\setminus A$ is uncountable. By Lemma 2 , there exists $B\subsetneq X\setminus A$ such that $B \sim \Bbb N$. Let $f_1:(X\setminus A)\setminus B \to (X\setminus A)\setminus B$ be the identity map on $(X\setminus A)\setminus B$, then $f_1$ is a bijection. Since $A\cup B\sim \Bbb N$ by Lemma 1 and $A \sim \Bbb N$, there exists a bijection $f_2:B \to A\cup B$. We define $f:X\setminus A \to X$ by $f(x)=f_1(x)$ for all $x\in (X\setminus A)\setminus B$ and $f(x)=f_2(x)$ for all $x\in B$. Thus $f$ is a bijection. Hence $X\setminus A \sim X$.","['elementary-set-theory', 'functions', 'proof-verification', 'infinity']"
2914208,What is this function related with continued fractions?,"Playing with continued fractions, I came with the idea of iterating the limit of the simplest one: $$1 + \cfrac{1}{1+\cfrac{1}{1+\cfrac{1}{1+\cfrac{1}{1+\cfrac{1}{1+\cdots}}}}}\ = \Phi$$ And then I thoght about iterating the result:
$$\Phi + \cfrac{1}{\Phi+\cfrac{1}{\Phi+\cfrac{1}{\Phi+\cfrac{1}{\Phi+\cfrac{1}{\Phi+\cdots}}}}}\ = ?$$ And after that keep iterating again and again. Essentially, what I am doing is solving this: $$x = a + \frac{1}{x}$$ for different values of $a$. Whose solution is: $$ x = \frac{a \pm \sqrt{a^2 + 4}}{2}$$ And I'm just staying with the positive solution. At the end, I'm just exploring this sequence defined recursively: $$ f(1) = \Phi \\
f(n+1) = \frac{f(n) + \sqrt{f(n)^2 + 4}}{2}
$$ When you see the plot of the terms of the sequence, you get this picture: I would like to know which is the function that generates that curve . It really seems to be a continuos function (notice that the picture is a set of points so close, that may seem to be continuous, but it's not). So... What's the function underlying this curve and how can we find it? Many thanks in advance!","['golden-ratio', 'recurrence-relations', 'real-analysis', 'sequences-and-series', 'continued-fractions']"
2914240,About Affine planes,"I am studying about affine planes
An affine plane can be defined as
It is an ordered pair ($\mathcal{P}$
,$\mathcal{L}$), P is non-empty set of points and and L is non-empty collection of the subsets of $\mathcal{P}$ called lines satisfying the following properties Given any two points, there is a unique line joining any two points. Given a point P and a line L not containing P, there is a unique line that contains P
and does not intersect L. There are four points, no three of which are collinear. (This rule is just to eliminate
the silly case where all of your points are on the same line.)
Now what is the problem and what I am thinking about affine plane is the example of Rational affine plane where
$$\mathcal{P}=\{(x,y)/x,y\in Q\}$$
and $$\mathcal{L}=\{(x,y)/ ax+by=c\}$$
But in this case the each line in rational affine plane seems to dots.
means line is discontineous.
Similalry in case of the finite affine planes I am thinking.
Can anyone help to remove my this confusion.
Thanks in advance","['euclidean-geometry', 'affine-geometry', 'differential-geometry']"
2914247,Doubt on limits evaluation.,Can anyone tell me what am I doing wrong here. The limit provided is$$\lim_{x \to 0}\dfrac{xe^x-\ln(1+x)}{x²}$$ Method 1 (using standard limits) $$= \ \ \ \  \dfrac{\displaystyle \lim_{x \to 0}\dfrac{xe^x}{x}-\lim_{x \to 0}\dfrac{\ln(1+x)}{x}}{\displaystyle \lim_{x \to 0}x}$$ $$= \ \ \ \  \dfrac{\displaystyle \lim_{x \to 0}e^x-\lim_{x \to 0} 1}{\displaystyle \lim_{x \to 0}x}$$ $$= \ \ \ \  \lim_{x \to 0} \dfrac{e^x-1}{x}$$ $$= \ \ \ \ 1$$ Method 2 (using  Maclaurin series ) $$\lim_{x \to 0}\dfrac{xe^x-\ln(1+x)}{x²}$$ $$= \ \ \ \ \dfrac{3}{2}$$ Even with L'Hopital rule I get $\dfrac{3}{2}$. Then what's wrong with method 1. Some limit's properties,['limits']
2914270,Taylor Expansion of a Differential,"How can the differential of an arbitrary function $f(t,S_t)$, through a second-order Taylor Expansion, become: $df = \frac{∂f}{∂t}​dt+ \frac{∂f}{∂S_t}​dS_t​ + \frac{1}{2}​\frac{∂²f}{∂S^2_t}(dSt_t)^2$ What are the steps to arrive at this equation? Is the function expanded first and differentiated next? Or are ""f,x, and a"" of an ordinary TE replaced before expansion?","['taylor-expansion', 'ordinary-differential-equations']"
2914281,Is the Carathéodory measurability criterion optimal in some sense?,"If $m$ is an outer measure defined on a set $X$, we say that a subset $E$ of $X$ is Carathéodory-measurable with respect to $m$ if for all subsets $A$ of $X$, we have $m(A)=m(A\cap E) + m(A\cap E^c)$.  And if $M$ is the set of all Carathéodory-measurable sets with respect to $m$, then $M$ is a complete sigma algebra on $X$
and $m$ restricted to $M$ is a complete measure on $X$. My question is, is $M$ ""optimal"" in some way?  Is it the biggest or smallest subset of $P(X)$ such that $m$ restricted to that subset is a measure?  Is it the biggest or smallest subset of $P(X)$ such that $m$ restricted to that subset is a complete measure? To put it another way, what is it that makes the Carathéodory measurability criterion the ""best"" criterion for measurability?  Or is it not the best, but just an arbitrary choice out of a sea of infinitely many equally good stronger and weaker measurability criteria?","['measure-theory', 'lebesgue-measure', 'outer-measure']"
2914309,Proof of a combination identity: $\sum\limits_{i=0}^m\sum\limits_{j=0}^m\binom{i+j}{i}\binom{2m-i-j}{m-i}=\frac {m+1}2\binom{2m+2}{m+1}$,"I'm studying the special case of question Finding expected area enclosed by the loop when $m=n$ and $A=2n$. I found $f_{n,n}(2n)=S(n-2)$, where $S$ is defined as $$S(m)=\sum_{i=0}^m\sum_{j=0}^m\binom{i+j}{i}\binom{2m-i-j}{m-i}.$$ Wolframalpha gives $S(m)=\displaystyle\frac {m+1}2\binom{2m+2}{m+1}$. How to prove it? Some thoughts so far: I found that $f_{n,n}(2n)=\displaystyle\frac {n-1}2\binom{2n-2}{n-1}=\frac {n-1}2f_{n,n}(2n-1)$, so there might have a combinatorial proof for the summation.","['summation', 'combinations', 'combinatorial-proofs', 'binomial-coefficients', 'combinatorics']"
2914334,All real functions such that $(x+y)(f(x) - f(y)) = (x - y)f(x + y)$,"Find all functions $f:\mathbb R \rightarrow \mathbb R$ such that $(x + y)(f(x) - f(y)) = (x - y)f(x + y), \forall x,y \in \mathbb R$ Rearranging we get $$\frac{f(x) - f(y)}{x - y} = \frac{f(x + y)}{x + y}$$ which is just the slope of the graph of $f$ equated to it's output divided by it's input. I don't know what term you give for $\frac{output}{input}$, but I guess the answer can be found this way. How do I continue?","['algebra-precalculus', 'functions']"
2914354,A matrix problem about egienvalue and trace,"Consider an  $m\times m$ positive definite and Hermitian matrix $\mathbf{M}$
and an arbitrary $m\times n (m>n)$  para-unitary matrix  $\mathbf{R}$, i.e.,
$\mathbf{R}^H\mathbf{R}=\mathbf{I}_n$. then， is there any strict proof for:
Let $\mu_1,...,\mu_{n}$ and
$\lambda_1,...,\lambda_{n}$ denote the eigenvalues in descending order of
$(\mathbf{R}^H\mathbf{M}\mathbf{R})^{-1}$ and
$\mathbf{R}^H\mathbf{M}^{-1}\mathbf{R}$, respectively,  we have
$\mu_k \le \lambda_k, \forall k$. ? I use matlab and generate many random matrices to check the result. I think it must be true. However, how to prove it?","['matrices', 'hessian-matrix', 'matrix-equations', 'matrix-calculus']"
2914375,Write this in matrix form?,"I'm trying to work on my linear algebra skills. I came across this equation in Bishop PRML (Equation 4.93): $$ \nabla E(w) = \sum_{n=1}^N(\mathbf{w}^T\mathbf{\phi}_n-t_n)\mathbf{\phi}_n = \mathbf{\Phi}^T\mathbf{\Phi w} - \mathbf{\Phi^T t}$$ Where $\mathbf{w, \phi_n, t}$ are vectors and $\mathbf{\Phi}$ is a $N$ by $M$ matrix whose $n^{th}$ row is given by $\mathbf{\phi}_n^T$. The matrix form confuses me. I understand how he derives the $\mathbf{\Phi ^Tt}$ part, but really can't figure out how he came up with $\mathbf{\Phi^T\Phi w}$ I hope one of you can explain it to me :) Thanks P.S. Tips on how to structurally figure these matrix forms out in general are really appreciated.","['multivariable-calculus', 'matrix-calculus', 'linear-algebra']"
2914388,Probability of exactly $2$ aces within first $5$ cards?,"Every person gets $5$ cards from a deck of cards ($52$). What is the probability that the first $5$ cards will contain exactly $2$ aces? I have tried to calculate it by $\frac{5}{52} \times \frac{5}{47} = \frac{25}{2444}$. I know my answer is incorrect, but I dont know how I should approach this.","['statistics', 'probability']"
2914409,Real part of complex integral,"Let $x:\Omega \subset 
%TCIMACRO{\U{2102} }%
%BeginExpansion
\mathbb{R}^2
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ harmonic (I do not know if you need) and $\frac{\partial x}{\partial u_{1}},\frac{\partial x}{%
\partial u_{2}}:\Omega \subset 
%TCIMACRO{\U{2102} }%
%BeginExpansion
\mathbb{R}^2
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ their partial derivatives, with $\Omega $ simply connected open. Show that 
$$ 
x\left( z\right) =\Re \int_{0}^{z}\left( \frac{\partial x}{%
\partial u_{1}}\left( z\right) -i\frac{\partial x}{\partial u_{2}}\left(
z\right) \right) dz. $$ I have looked in books of complex analysis, but I can not find the property that allows me this equality.","['complex-analysis', 'differential-geometry', 'riemannian-geometry', 'real-analysis']"
2914456,May I ask why the following operator between Banach spaces is continuous please?,"I am reading the paper ""On the Initial Value Problem of Stochastic Evolution Equations in Hilbert Spaces"" ( Here is the link for electronic version ). But when reading it, I meet a problem and would like to ask for help: Background : 1.The event space is $\Omega$ with sigma algebra and probability measure $P$. 2.$H$ and $K$ are two real Hilberts. 3.$L^2(\Omega,H)$ denotes the collection of strongly measurable, square-integrable, $H$-valued random variables and it is a Banach space with norm: for any element $u$, $\|u(.)\|_{L^2}=(E\|u(.,\omega)\|)^{1/2}$, where the expectation $E$ is defined by $Eu=\int_{\Omega}u(\omega)dP$, $\omega\in\Omega$. 4.$W_{t}$ denotes the cylindrical Wiener process valued in $K$ with covariance operator $Q$. 5.Let $J$ denotes some closed subinterval in $[0,\infty)$, $C(J,L^2(\Omega,H))$ denotes the collection of continuous processes from $J$ to $L^2(\Omega,H)$ such that $sup_{t\in J}E\|u(t)\|^2<\infty$. It is a Banach space with the norm $\|u\|_{C}=(sup_{t \in J}E\|u\|^2)^{1/2}$. 6.$A$ is an operator on $H$ which generates a family of compact operators $(S_{t})_{t>0}$. Problem: Assume $f:J\times H \to L_{HS}(K,H)$ is continuous nonlinear map, where $L_{HS}(K,H)$ denotes the Hilbert-Schmidt operators; the set $\{E\|f(t,u(t))\|^2:t \in J \}$ is bounded for any bounded $E\|u(t) \|^2$. Then consider a subinterval $[t_0,t_0+h]$ of $J$, the map $(Fu)(t) = \int_{to}^tS(t-s)f(s,u(s))dW_s$ is continuous from $C(J,L^2(\Omega,H))$ to itself. (The above map is different from formula (7) in the paper, but the essential should be the same. ) 
For its proof, it is just pointed out that due to continuity of $f$, map $F$ is continuous, I could not figure out why. Furthermore, if we put randomness on $f$, for instance $f$ is a stochastic process valued in the space of continuous maps between $H$ and $L_{HS}(K,H)$ with continuous sample paths, will the same argument hold please? Thank you very much!","['stochastic-processes', 'stochastic-pde', 'functional-analysis']"
2914466,Why the reversal in inclusion between $l^p$ and $L^p$ spaces?,"Anyone who has studied classical functional analysis has been exposed to the sequence spaces ($l^p$ spaces) and the Lebesgue spaces ($L^p$ spaces). It's known that there is a reversal of inclusion in these spaces when the underlying manifold of Lebesgue spaces has finite measure. Understanding that sequences are indeed functions defined on the set of natural numbers, the prior observation seems counter-intuitive, when coupling the concept of convergence of real series with the integral test. I would appreciate it if someone could throw some light on this issue, or if I should be a bit more elaborate.",['functional-analysis']
2914474,"How to prove the integral $\int_{0}^{\infty} x^{-1}\sin (x+x^{-1})\,dx=\pi J_0(2)$","$$I=\int_{0}^{\infty} \frac{\sin \left(x+\frac{1}{x}\right)}{x}dx=\pi J_0(2)$$ I'v found:$$I=2\int_{0}^{\infty}\frac{\sin \left(x^2+\frac{1}{x^2}\right)}{x}dx=3\int_{0}^{\infty}\frac{\sin \left(x^3+\frac{1}{x^3}\right)}{x}dx=...=n\int_{0}^{\infty}\frac{\sin \left(x^n+\frac{1}{x^n}\right)}{x}dx$$
But I still wouldn't prove the integral，can someone help me?","['integration', 'calculus', 'definite-integrals', 'bessel-functions']"
2914484,"[Stuck]: Final step of solving limit, Calculus I","Calculate the value of $k$ such that the following limit has a finite solution, $L$ such that $L \ne 0$: $$\lim_{x\rightarrow0} \frac{(e^{x^2}-x^2-1)(\cos(x)-1)}{x^k}$$ I use the Taylor Series expansions of $e^x$ and $\cos(x)$ and simplify the above expression to the following: $$\lim_{x\rightarrow0} \frac{-\frac{1}{4}x^6+(\frac{1}{48}-\frac{1}{12})x^8+(\frac{1}{144})x^{10}}{x^k}$$ Now I have a mental roadblock. For $k<6$ the above limit goes to zero and for $k>6$ this expression should diverge but in my head it goes to zero again.... I am trying to think of a simple example to convince myself but can't. Can someone please help me understand this? Thanks.","['limits', 'calculus', 'taylor-expansion']"
2914499,"Prob. 7, Sec. 6.1, in Bartle & Sherbert's INTRO TO REAL ANALYSIS: A necessary and sufficient condition for the existence of $\big(|f|\big)^\prime$","Here is Prob. 7, Sec. 6.1, in the book Introduction To Real Analysis by Robert G. Bartle & Donald R. Sherbert, 4th edition: Suppose that $f \colon \mathbb{R} \to \mathbb{R}$ is differentiable at $c$ and that $f(c) = 0$. Show that $g(x) \colon= \lvert f(x) \rvert$ is differentialbe at $c$ if and only if $f^\prime(c)=0$. My Attempt: Suppose that $f^\prime(c)=0$. Then, given a real number $\varepsilon > 0$, we can find a real number $\delta > 0$ such that 
  $$ \left\lvert \frac{ f(x) - f(c) }{ x -c } \right\rvert = \left\lvert \frac{ f(x)  }{ x -c } \right\rvert < \varepsilon $$ 
  for all $x \in \mathbb{R}$ which satisfy 
  $$ 0 < \lvert x-c \rvert < \delta. $$ Therefore for all $x \in \mathbb{R}$ which satisfy 
  $$ 0 < \lvert x-c \rvert < \delta, $$ we find that 
  $$ \left\lvert \frac{g(x) - g(c) }{x-c} - 0 \right\rvert = \left\lvert \frac{ \lvert f(x) \rvert - \lvert f(c) \rvert }{ x-c} \right\rvert = \left\lvert \frac{ \lvert f(x) \rvert  }{ x-c} \right\rvert = \frac{ \lvert f(x) \rvert  }{ \lvert x-c \rvert } = \left\lvert \frac{ f(x)  }{ x -c } \right\rvert < \varepsilon. $$ 
  Since $\varepsilon > 0$ was arbitrary, it follows that $g$ is differentiable at $c$ and that
  $$ g^\prime(c) = 0. $$ Conversely, suppose that $f^\prime(c) \neq 0$. Then either $f^\prime(c) < 0$ or $f^\prime(c) > 0$. Case 1. If $f^\prime(c) > 0$, then for $\varepsilon \colon= f^\prime(c)/2$, we can find a real number $\delta > 0$ such that 
  $$ \left\lvert \frac{ f(x) - f(c) }{ x -c } - f^\prime(c) \right\rvert < f^\prime(c)/2 $$
  or 
  $$ 0 < \frac{f^\prime(c)}{2} =  f^\prime(c) - f^\prime(c)/2 <  \frac{ f(x) - f(c) }{ x -c } < f^\prime(c) + f^\prime(c)/2 $$
  for all $x \in \mathbb{R}$ which satisfy 
  $$ 0 < \lvert x-c \rvert < \delta. $$ But $f(c) = 0$.  Thus for all $x \in \mathbb{R}$ which satisfy 
  $$ 0 < \lvert x-c \rvert < \delta, $$ 
  we have 
  $$ \frac{ f(x) }{x-c} > \frac{f^\prime(c)}{2} > 0, \tag{1} $$ 
  which implies that, for all $x \in \mathbb{R}$, 
  $$ f(x) \ \begin{cases}   > 0 \ \mbox{ if } & c < x < c + \delta, \\  < 0 \ \mbox{ if } & c-\delta < x < c. \end{cases} $$
  So from (1) it follows that 
  $$ \frac{g(x) - g(c) }{x-c} = \frac{ \lvert f(x) \rvert }{ x-c} = \begin{cases} \frac{f(x)}{x-c} & \mbox{ if } \ c < x < c+\delta, \\ -\frac{ f(x)}{x-c} & \mbox{ if } \  c-\delta < x < c. \end{cases} \tag{2}$$
  Moreover, from (2) we can also conclude that 
  $$ \lim_{x \to c+} \frac{g(x) - g(c)}{x-c} = \lim_{x \to c+} \frac{ f(x) }{x-c} = \lim_{x \to c+} \frac{ f(x) - f(c) }{x-c} = f^\prime(c), $$
  and 
  $$ \lim_{x \to c-} \frac{g(x) - g(c)}{x-c} = \lim_{x \to c-}\left(- \frac{ f(x) }{x-c} \right) = \lim_{x \to c-} \left( -  \frac{ f(x) - f(c) }{x-c}\right) = - \lim_{x \to c-}   \frac{ f(x) - f(c) }{x-c}=- f^\prime(c). $$
  Thus if $f^\prime(c) > 0$, then
  $$ \lim_{x \to c+} \frac{g(x) - g(c)}{x-c} \neq \lim_{x \to c-} \frac{g(x) - g(c)}{x-c}, $$
  and so $g^\prime(c)$ does not exist. Therefore if $g$ is differentiable at $c$, then we must have $f^\prime(c) \not> 0$. Case 2. If $f^\prime(c) < 0$, then for $\varepsilon \colon= -f^\prime(c)/2 > 0$, we can find a real number $\delta > 0$ such that 
  $$ \left\lvert \frac{ f(x) - f(c) }{ x -c } - f^\prime(c) \right\rvert < - f^\prime(c)/2 $$
  or 
  $$ \frac{3f^\prime(c)}{2} =  f^\prime(c) - \frac{-f^\prime(c)}{2} <  \frac{ f(x) - f(c) }{ x -c } < f^\prime(c) + \frac{-f^\prime(c)}{2} = \frac{ f^\prime(c)}{2} < 0 $$
  for all $x \in \mathbb{R}$ which satisfy 
  $$ 0 < \lvert x-c \rvert < \delta. $$ But $f(c) = 0$.  Thus for all $x \in \mathbb{R}$ which satisfy 
  $$ 0 < \lvert x-c \rvert < \delta, $$ 
  we have 
  $$ \frac{ f(x) }{x-c} < \frac{f^\prime(c)}{2} < 0, \tag{3} $$ 
  which implies that, for all $x \in \mathbb{R}$, 
  $$ f(x) \ \begin{cases}   < 0 \ \mbox{ if } & c < x < c + \delta, \\  > 0 \ \mbox{ if } & c-\delta < x < c. \end{cases} $$
  So from (3) it follows that 
  $$ \frac{g(x) - g(c) }{x-c} = \frac{ \lvert f(x) \rvert }{ x-c} = \begin{cases} -\frac{f(x)}{x-c} & \mbox{ if } \ c < x < c+\delta, \\ \frac{ f(x)}{x-c} & \mbox{ if } \  c-\delta < x < c. \end{cases} \tag{4}$$
  Moreover, from (4) we can also conclude that 
  $$ \lim_{x \to c-} \frac{g(x) - g(c)}{x-c} = \lim_{x \to c-} \frac{ f(x) }{x-c} = \lim_{x \to c-} \frac{ f(x) - f(c) }{x-c} = f^\prime(c), $$
  and 
  $$ \lim_{x \to c+} \frac{g(x) - g(c)}{x-c} = \lim_{x \to c+}\left(- \frac{ f(x) }{x-c} \right) = \lim_{x \to c+} \left( -  \frac{ f(x) - f(c) }{x-c}\right) = - \lim_{x \to c+}   \frac{ f(x) - f(c) }{x-c}=- f^\prime(c). $$
  Thus if $f^\prime(c) < 0$, then
  $$ \lim_{x \to c+} \frac{g(x) - g(c)}{x-c} \neq \lim_{x \to c-} \frac{g(x) - g(c)}{x-c}, $$
  and so $g^\prime(c)$ does not exist. Therefore if $g$ is differentiable at $c$, then we must have $f^\prime(c) \not< 0$. From the above two cases, we can conclude that if $g$ is differentiable at $c$, then we must have $f^\prime(c)=0$. Is this proof correct? If so, then is the presentation clear and rigorous enough too? If not, then where are the issues as far as accuracy, rigor, or clarity of the argument go?","['proof-verification', 'analysis', 'real-analysis', 'limits', 'derivatives']"
2914514,The Cartesian product of a finite number of countable sets is countable [duplicate],"This question already has answers here : The cartesian product of a finite amount of countable sets is countable. (2 answers) Closed last year . The Cartesian product of a family $(A_i\mid i\in I)$ is defined as $$\prod\limits_{i\in I}A_i=\{f:I\to\bigcup A_i\mid f(i)\in A_i\}$$ Let $I_n=\{i \in \mathbb N \mid i \le n\}$ for $n\in \Bbb N$ and $A_i$ be countable for all $i\in I_n$ . Then $\prod\limits_{i\in I_n}A_i$ is countable. My attempt: Lemma 1: $(\prod\limits_{i\in I_n}A_i) \times A_{n+1}$ and $\prod\limits_{i\in I_{n+1}}A_i$ are equinumerous for all $n \in \mathbb N$ . (I presented a proof here ) Lemma 2: If $A$ and $B$ are countable, then $A \times B$ is countable. (I presented a proof here ) I will prove the theorem by induction on $n$ . The theorem is trivially true for $n=0$ . Assume that the theorem is true for $n=k$ , then $\prod\limits_{i\in I_k}A_i$ is countable. Since $\prod\limits_{i\in I_k}A_i$ is countable (by inductive hypothesis) and $A_{k+1}$ is countable, then by Lemma 2 $(\prod\limits_{i\in I_n}A_i) \times A_{n+1}$ is countable. Furthermore, by Lemma 1 $(\prod\limits_{i\in I_k}A_i) \times A_{k+1}$ and $\prod\limits_{i\in I_{k+1}}A_i$ are equinumerous, then $\prod\limits_{i\in I_{k+1}}A_i$ is countable too. Thus the theorem is true for $n=k+1$ . This completes the proof. Does this proof look fine or contain gaps? Do you have suggestions? Many thanks for your dedicated help!","['elementary-set-theory', 'proof-verification']"
2914516,"Expectation of $\max_{j=1,\dots,M}X_j^2$ with normal distributed $X_j$","This is my first question here and I have thought about it for a long time. I found following Lemma in a paper: Consider the independent random variables $X_1,\dots,X_M \sim \mathcal{N}(0,1)$. Then it holds
\begin{align*}
\mathbb{E}\left[\max_{j=1,\dots,M}X_j^2 \right]\leq 3\log M +1. 
\end{align*} The proof uses
\begin{align*}
\max_{j=1,\dots,M}X_j^2\leq \sum_{j=1}^MX_j^2\cdot\chi\left(\lvert X_j\rvert>T\right)+T^2  
\end{align*}
for any $T>0$. At the beginning one shows $\mathbb{E}\left[X_j^2\cdot\chi\left(\lvert X_j\rvert>T\right)\right]\leq \left(1+(2\pi)^{-1/2}T\right)e^{-T^2/2}$. The author uses
\begin{align*}
\mathbb{E}\left[X_j^2\cdot\chi\left(\lvert X_j\rvert>T\right)\right]=(2\pi)^{-1/2}\int_T^{\infty}x^2e^{-x^2/2}\mathrm{d}x.
\end{align*}
I think this is not correct, since the right hand side should be doubled. Although, I tried to follow the proof further but I am not able to fix this mistake. The question is: Is this a mistake in the proof or am I overseeing something very trivial? And if the proof is wrong, does anyone know a proof or how to fix it?","['statistics', 'normal-distribution', 'expected-value', 'probability-theory', 'random-variables']"
2914522,Probability that the sum of two integers is even between 20 and 40,"Question: What is the probability that the sum of two randomly chosen integers between $20$ and $40$ inclusive is even (the possibility of the two integers being equal is allowed)? Comment on the answers (a) $\frac{1}{2}$, (b) $\frac{11}{21}$, and (c) $\frac{11^2}{21^2}$ My attempt so far: I know there are $11$ even numbers between $20$ and $40$ and $10$ odd numbers between $20$ and $40$. So with even numbers, there is a total of $121$ options and $100$ options between odd numbers. https://answers.yahoo.com/question/index?qid=20130608150439AA7kjc3 (This is the link I am working off of to understand the problem). I understand where the $221$ comes from...where/what is the $441$?","['combinatorics', 'probability']"
2914564,Nonempty collection of letters formed by four A's and eight B's,"Question: How many nonempty collections of letters can be formed from four As and eight Bs? We can make collections of letters with a maximum of 12 letter since $4+8=12$. We can split the problem into cases of collections of letters containing $1$ letter to $12$ letters. For 1 letter: either an A or a B: 2 collections For 2 letters: AA,BB,AB: 3 collections For 3 letters: (2A,1B),(1A,2B),(3A),(3B): 4 collections For 4 letters: This is where I get stuck My attempt at 4 letters : (4A,0B),(3A,1B),(2A,2B),(1A,3B),(0A,4B): 5 collections If anyone can help me with 4 letters up to 12 letters. Completed Answer: For 5 letters: (5B,0A),(4B,1A),(3B,2A),(2B,3A),(1B,4A): 5 ways For 6 letters: (6B,0A),(5B,3A),(4B,2A),(3B,3A),(2B,4A): 5 ways For 7 letters: (7,0),(6,1),(5,2),(4,3),(3,4): 5 ways For 8 letters: (8,0),(7,1),(6,2),(5,3),(4,4): 5 ways For 9 letters: (8,1),(7,2),(6,3),(5,4): 4 ways For 10 letters: (8,2),(7,3),(6,4): 3 ways For 11 letters: (8,3),(7,4): 2 ways For 12 letters: (8,4): 1 way Adding these up, $$2+3+4+5\times{5}+4+3+2+1 = 44 \text{collections of letters} $$",['combinatorics']
2914565,Books on Abstract Algebra and its applications to solve puzzles,"I am currently reading some introductory textbooks on abstract algebra (""Contemporary Abstract Algebra"" by Gallian and ""A book on Abstract Algebra"" by Pinter). I am learning the concepts from these books but I am not yet confident about using them in solving real-world problems. I know that Abstract Algebra can be used to solve a lot of interesting puzzles( For example, 15-puzzle, Rubik's cube, etc). Are there any books or websites that includes usage of abstract algebra framework to solve some puzzles?","['book-recommendation', 'reference-request', 'abstract-algebra', 'group-theory', 'soft-question']"
2914569,Surface with prescribed first fundamental form,"Consider a Riemannian manifold $(S,g)$ of dimension 2. 
What can we say about the possibility of an isometric immersion of this surface into $\mathbb{R}^3$? Of course this is not unique, even up to rigid motions (like in the case of zero Gaussian curvature). How can we find at least one of the possible isometries? Do we have a condition for uniqueness? If you want to make it simpler, think about a $U \subset \mathbb{R}^2$ with assigned $g_{ij}\neq \delta_{ij}$ (with respect to the standard Cartesian coordinates).","['surfaces', 'riemannian-geometry', 'curvature', 'isometry', 'differential-geometry']"
2914583,What am I doing wrong in this probability exercise?,"In the experiment of throwing a die $n$ successive times, what's the probability of observing two consecutive 3's? The consecutive threes can be observed in the first and the second throw, in the second and third throw, in the third and fourth throw, in the fourth and fifth throw, ..., and in the (n-1)-th and n-th throw. I would say these combinations account for $(n-1)*6^{n-2}$ favorable outcomes out of a total of $6^{n}$ different possibilities. Then, I concluded the answer had to be something like $(n-1)*6^{n-2}$ over $6^{n}$. Where does my argument go astray? Thanks a bunch for your help","['statistics', 'probability-distributions', 'probability-theory', 'probability']"
2914592,How to find a simple function in Lambda Calculus?,"I was doing this exercise :
Find the function $$exchange$$ such that:
   $$(exchange)t \simeq \lambda p(p)t_2 t_1$$
where $$t= \lambda p(p)t_1 t_2.$$
I found $$ exchange= \lambda p(p) (\lambda c (S \ \textit{FALSE} 
 \ \textit{TRUE} (c))) $$
where $$\textit{TRUE} = \lambda x \lambda y x$$
             $$\textit{FALSE}= \lambda x \lambda y y$$
             $$S= \lambda x \lambda y \lambda z(xz(yz))$$ Is it correct?
Thank you,
Alessandro.","['lambda-calculus', 'functions', 'formal-languages', 'computer-science']"
2914598,"If $A$ and $B$ are countable, then $A\times B$ is countable","If $A$ and $B$ are countable, then $A\times B$ is countable. My attempt: Lemma 1 : $A$ is countable if and only if there exists a injective mapping $f:A \to \Bbb N$. Lemma 2 : $\Bbb N\times\Bbb N$ is countable. Since $A$ and $B$ are countable, there exist injections $j_A:A \to \Bbb N$ and $j_B:B \to \Bbb N$ by Lemma 1 . We define a mapping $j:A\times B \to \Bbb N\times\Bbb N$ by $j(a,b)=(j_A(a),j_B(b))$. It's clear that $j$ is injective. Since $\Bbb N\times\Bbb N$ is countable by Lemma 2 , there exists an injection $f:\Bbb N\times\Bbb N \to \Bbb N$ by Lemma 1 . Hence $f\circ j:A\times B \to \Bbb N$ in injective and hence $A\times B$ is countable by Lemma 1 . Does this proof look fine or contain gaps? Do you have suggestions? Many thanks for your dedicated help!","['elementary-set-theory', 'proof-verification']"
2914619,The ambigous definition of vacuous truth,"It is no doubt that the vacuous truth is related to material implication  ""$P\Rightarrow Q$"". We say the material implication statement is true when $P$ is false. However, seems that this is not the definition for vacuously truth. Do we call it vacuously true only when $P$ can never be true? (Seems that all examples are in this way). More clearly, suppose we have a statement ""$P(x)\Rightarrow Q(x)$"", and at some domains of $x$ (we may denote the domain by $T_x$), $P(x)$ is true;  at some other domains of $x$ (denote the domain by $F_x$), $P(x)$ is false. Can we say the statement is vacuously true in the domain $F_x$? Is there any real example? To make the problem more clear, we may check the statement ""For all $x$, $P(x)\Rightarrow Q(x)$"". Can we say this statement is vacuously true in the domain $F_x$ ($F_x$ is defined as above)?","['elementary-set-theory', 'logic']"
2914678,Convolution of independent standard normal random variables,"Let $X$ and $Y$ be two independent random variables, each with the standard
  normal density. Compute $f_{X+Y} (a)$. The solution uses a convolution of the form $$f_{X+Y}(a)= {1\over 2\pi} \int_{-\infty}^{\infty}
e^{-{(a-y)^2}\over2}e^{-{y^2}\over2} \ dy$$ I am wondering why the bounds are $\infty$ and not $a$ and $0$ such as I found in another problem- Let $X$ and $Y$ be two independent exponential random variables with common
parameter $λ$. Compute $f_{X+Y} (a)$ , where the solution uses $f_{X+Y}(a)= \int_{0}^{a}
λe^{-λ(a-y)}λe^{-λy}\ dy$ Why are the bounds $\infty$ when the sum of $X$ and $Y$ is no more than $a$? Is this something special about the standard normal variable?","['statistics', 'probability-distributions', 'probability']"
2914686,proof about commutative operators and T-cyclic vectors,"Let $V$ be a finite dimensional vector space over $F$. Let $T:V \to V$ be a linear operator.
Prove that if every linear operator $U$ which commutes with $T$ is a polynomial of $T$, than $T$ has a $T$-cyclic vector. I don't really know where to start...
can someone please point me in the right direction?",['linear-algebra']
2914700,Lebesgue measure of measurable sets of $\mathbb{R}^n$.,"I unfortunately urgently need to learn the basics of measure theory. For this reason I am ""collecting"" important properties of the Lebesgue measure of measurable sets of $\mathbb{R}^n$ (at this point I'm not worried to know how to demonstrate them). Below I'll put the properties that I think are important. My question: Is everything below correct? Please, if you know another property that you think important post here. Firstly, given a bounded interval $I\subset\mathbb{R}$ with $a=\inf I$ and $b=\sup I$ we define the length $l(I)$ of the interval $I$ as $l(I):=b-a$. Proposition: Given any measurable set $E$ of $\mathbb{R}^n$ it is possible to associate to this set a number $\mu(E)$, called the Lebesgue measure of $E$, which obeys the following conditions: If $E=\emptyset $, then $\mu (E)=0$. If $A\subseteq B$, and $A$ and $B$ are both measurable, then $\mu(A)\leq \mu(B)$. If $\{A_i\}_{i\in I}$ is a finite collection of measurable sets, then $\mu\left(\bigcup_{i\in I}A_i\right)\leq \sum_{i\in I}\mu(A_i)$. If $\{A_i\}_{i\in I}$ is a finite collection of disjoint measurable sets, then $\mu\left(\bigcup_{i\in I}A_i\right)= \sum_{i\in I}\mu(A_i)$. If $\{A_i\}_{i\in I}$ is a countable collection of measurable sets, then $\mu\left(\bigcup_{i\in I}A_i\right)\leq \sum_{i\in I}\mu(A_i)$. If $\{A_i\}_{i\in I}$ is a countable collection of disjoint measurable sets, then $\mu\left(\bigcup_{i\in I}A_i\right)= \sum_{i\in I}\mu(A_i)$. If $A$ is a measurable set, and $x_0\in\mathbb{R}^n$, then $A+x_0:=\{x+x_0:x\in A\}$ is also measurable, and $\mu(A+x_0)=\mu(A)$. If $I\subset \mathbb{R}$ is a bounded interval with $a=\inf I$ and $b=\sup I$, then $\mu(I)=l(I)=b-a$ If $A=I_1\times I_2\times \cdots \times I_n$ is the cartesian product of $n$ bounded intervals $I_i$, then $\mu (A)=\prod _{i=1}^n\mu (I_i)=\prod _{i=1}^n l (I_i)$ The first 7 items are in the book ""Analysis II"" written by Terence Tao. Therefore I know they are correct. I just put them to show what properties I know. My main question is about the items $8$ and $9$. Are they correct? Also, do you know of any other property that you consider important?","['measure-theory', 'lebesgue-measure']"
2914719,Question regarding kernels in Hilbert-Schmidt operators,"I'm studying some Hilbert-Schmidt integral operator theory. I read that a Hilbert-Schmidt integral operator is uniquely determined by its kernel, and I wonder how exactly that is. I guess what I'm looking for are hints/suggestions on how to show that Hilbert-Schmidt integral operators are uniquely determined by their kernels. Here are the definitions I'm going by: $\textit{Let k be a function of two variables }(x,y)\in I \times I=I^2$ $\textit{ where }I\textit{ is a finite or infinite real interval. We define a linear integral operator K with kernel }$
$k(x,y)\textit{ as }$ $$Ku(x)=\int_{I}k(x,y)u(y)\ dy,\ \ x\in I$$ $\textit{whenever this integral makes sense. The domain D(K) will have to be specified in order to accomplish this.}$ $\textit{An integral operator on }L^2(I)\textit{ is called a Hilbert-Schmidt operator if the kernel }k\textit{ is in }L^2(I\times I),\textit{that is if}$ $$||k||_{L^{2}}^2=\int_{I}\int_{I}|k(x,y)|^2\ dxdy<\infty$$ The book I'm using now says it's possible to show that a Hilbert-Schmidt operator is uniquely determined by its kernel, that is, if $$\int_{I}k(x,y)u(y)\ dy=\int_{I}h(x,y)u(y)\ dy$$ for all $u\in L^2(I)$, then $k=h$ in $L^2(I\times I)$. This is where I'm unsure of how to show this.
Thanks in advance!","['operator-theory', 'functional-analysis', 'real-analysis']"
2914724,Proving Multivariable limit Exists,"I am trying to determine and prove the limit for the function
$f(x,y)=\frac{y^2-4|y|-2|x|}{|x|+2|y|}$ after setting $y=mx$ I found out that the limit is not dependent on m and -2 is a potential candidate for the limit so I set up my equation for the squeeze theorem $\lim_{(x,y)\to(0,0)} |\frac{y^2-4|y|-2|x|}{|x|+2|y|}+2|=\lim_{(x,y)\to(0,0)}\frac{y^2}{|x|+2|y|}$ and from this point on I'm having a bit of trouble to set up an inequality to satisfy the squeeze theorem. Would I be able to claim that $y^2 \leq y^2(|x|+2|y|)$","['multivariable-calculus', 'limits', 'calculus']"
2914728,The limit of $\frac{n^3-3}{2n^2+n-1}$,"I have to find the limit of the sequence above. Firstly, I tried to multiply out $n^3$, as it has the largest exponent.
$$\lim_{n\to\infty}\frac{n^3-3}{2n^2+n-1} = 
\lim_{n\to\infty}\frac{n^3(1-\frac{3}{n^3})}{n^3(\frac{2}{n} + \frac{1}{n^2} - \frac{1}{n^3})} = 
\lim_{n\to\infty}\frac{1-\frac{3}{n^3}}{\frac{2}{n} + \frac{1}{n^2} - \frac{1}{n^3}}$$
$$
\begin{align}
\lim_{n\to\infty}1-\frac{3}{n^3} = 1 \\[1ex]
\lim_{n\to\infty}\frac{2}{n} + \frac{1}{n^2} - \frac{1}{n^3} = 0 \\[1ex]
\lim_{n\to\infty}\frac{n^3-3}{2n^2+n-1} = \frac{1}{0}
\end{align}
$$ Then, after realizing $\frac{1}{0}$ might not be a plausible limit, I tried to multiply out the variable with the largest exponent in both the dividend and the divisor. $$\lim_{n\to\infty}\frac{n^3-3}{2n^2+n-1} = \lim_{n\to\infty}\frac{n^3(1 - \frac{3}{n^3})}{n^2(2 + \frac{1}{n} - \frac{1}{n^2})} = 
\lim_{n\to\infty}n\cdot\frac{1 - \frac{3}{n^3}}{2 + \frac{1}{n} - \frac{1}{n^2}}$$
$$
\begin{align}
\lim_{n\to\infty}1-\frac{3}{n^3} = 1 \\
\lim_{n\to\infty}2 + \frac{1}{n} - \frac{1}{n^2} = 2 \\
\lim_{n\to\infty}\frac{n^3-3}{2n^2+n-1} = \frac{1}{2} \\
\lim_{n\to\infty}n = \infty
\end{align}
$$ So, my questions about this problem: Could $\frac{1}{0}$ be a valid limit? Does $\infty\cdot\frac{1}{2}$
equal to $\infty$? In conclusion, what is the limit of the sequence
above? $\infty?$ Thank you!","['limits', 'calculus', 'infinity']"
2914734,If $\frac {a_{(n+1)} }{a_n} < \frac {n^2}{(n+1)^2}$ and if $a_n > 0$ for all n . $\sum a_n$ converges or not,If $\frac {a_{(n+1)} }{a_n} < \frac {n^2}{(n+1)^2}$ and if $a_n > 0$ for all n . Then what can we say about the series $\sum a_n$? Can anyone please help me by giving some hints?  I can not find any counter example to show that the series may not converge. Is it true?,"['sequences-and-series', 'real-analysis']"
2914757,Pin group isomorphisms,"My goal is to identify the $Pin$ group 
$$
1 \to Spin(n) \to  Pin^{\pm}(n) \to \mathbb{Z}_2 \to 1
$$
such that $Pin^{\pm}(n)$ are isomorphisms to other more familiar groups. My trick is that to look at the center $Z$ of $Pin$ group, say $Z(Pin(n))$ . We see that, for $k \in \mathbb{Z}^+$, when $n=4k+1$,
$$
Z(Pin^+(4k+1))=\mathbb{Z}_2 \times \mathbb{Z}_2,
$$
$$
Z(Pin^-(4k+1))=\mathbb{Z}_4.
$$ when $n=4k+3$,
$$
Z(Pin^+(4k+3))=\mathbb{Z}_4,
$$
$$
Z(Pin^-(4k+3))=\mathbb{Z}_2 \times \mathbb{Z}_2.
$$ when $n=4k$ or when $n=4k+2$,
$$
Z(Pin^+(n))=Z(Pin^-(n))=\mathbb{Z}_2.
$$ So my naive attempt is that we have the following $Pin$ group isomorphisms: $$Pin^+(1)=\mathbb{Z}_2 \times \mathbb{Z}_2, \quad Pin^-(1)=\mathbb{Z}_4.$$ $$Pin^+(3)=SO(3)  \times \mathbb{Z}_ 4, \quad Pin^-(3)=Spin(3) \times \mathbb{Z}_2.$$ $$Pin^+(5)=Spin(5) \times \mathbb{Z}_2,\quad Pin^-(5)=SO(5) \times \mathbb{Z}_4.$$ $$Pin^+(4k+1)=Spin(4k+1) \times \mathbb{Z}_2,\quad Pin^-(4k+1)=SO(4k+1) \times \mathbb{Z}_4.$$ $$Pin^+(4k+3)=SO(4k+3)  \times \mathbb{Z}_ 4, \quad Pin^-(4k+3)=Spin(4k+3) \times \mathbb{Z}_2.$$ Question 1 : Am I correct about the above statements? I am not so sure, 
  $Pin^+(3)=SO(3)  \times \mathbb{Z}_ 4$, could it be that instead
  $Pin^+(3)=\frac{Spin(3)  \times \mathbb{Z}_4}{\mathbb{Z}_2}?$
  (It looks that mine agrees with Wikipedia, but I doubt Wikipedia may be wrong about $Pin^+(3)=SO(3)  \times \mathbb{Z}_ 4$... ) Question 2 : Are there other $Pin$ group isomorphisms for $n=4k$, or $4k+2$, say $$Pin^{+/-}(4k)\simeq ?$$ and 
  $$Pin^{+/-}(4k+2)\simeq?$$ Thanks for your comments in advance.","['spin-geometry', 'exact-sequence', 'manifolds', 'group-theory', 'lie-groups']"
2914774,Find the domain of x $\left \lfloor x \right \rfloor + \left \lfloor x+\frac{1}{2} \right \rfloor + \left \lfloor x-\frac{1}{3} \right \rfloor =8$,"Find the domain of x $$\left  \lfloor x \right \rfloor + \left  \lfloor x+\frac{1}{2}  \right \rfloor   + \left  \lfloor x-\frac{1}{3}  \right \rfloor    =8$$ 
My approach When x is an integer $x+x+x-1=8$ or x=3 But for case when x is not an integer i am not able to substitute, manually x is $\frac{10}{3}$ which i did by trial method. My final answer is $3\le x <\frac{10}{3} $",['functions']
2914788,How to reduce this to have only one x ...,"Let $f(x)=\frac{5}{x+4} $ Reduce the difference quotient in the alternate definition of the derivative below so that you only have one x:
$$\frac{f(x) - f(2)}{x-2}$$ I've gotten down to $\frac{5(10-x)}{x-2}$ . but I can't figure out how to reduce it to one $x$. Am I doing something wrong? I have tried long division, which ended up being incorrect, so I have no idea.","['calculus', 'derivatives']"
2914807,"Prob. 17, Sec. 6.1, in Bartle & Sherbert's INTRO TO REAL ANALYSIS, 4th ed: Straddle Lemma","Here is Prob. 17, Sec. 6.1, in the book Introduction To Real Analysis by Robert G. Bartle & Donald R. Sherbert, 4th edition: Let $f \colon I \to \mathbb{R}$ be differentiable at $c \in I$ . Establish the Straddle Lemma . Give $\varepsilon > 0$ there exists $\delta (\varepsilon) > 0$ such that if $u, v \in I$ satisfy $c-\delta(\varepsilon)<u\leq c \leq v < c+\delta(\varepsilon)$ , then we have $\left\lvert f(v) - f(u) - (v-u)f^\prime(c) \right\rvert \leq \varepsilon (v-u)$ . [ Hint : The $\delta(\varepsilon)$ is given by Definition 6.1.1. Subtract and add the term $f(c) - c f^\prime(c)$ on the left side and use the Triangle Inequality.] Here is Definition 6.1.1 in Bartle & Sherbert, 4th edition: Let $I \subset \mathbb{R}$ be an interval, let $f \colon I \to \mathbb{R}$ , and let $c \in I$ . We say that a real number $L$ is the derivative of $f$ at $c$ if given any $\varepsilon > 0$ there exists $\delta(\varepsilon)>0$ such that if $x \in I$ satisfies $0 < \lvert x-c \rvert < \delta(\varepsilon)$ , then $$ \tag{1} \left\lvert \frac{ f(x) - f(c) }{ x-c} - L \right\rvert < \varepsilon. $$ In this case we say that $f$ is differentiable at $c$ , and we write $f^\prime(c)$ for $L$ . In other words, the derivative of $f$ at $c$ is given by the limit $$ \tag{2} f^\prime(c) = \lim_{x \to c} \frac{ f(x) - f(c) }{ x-c}  $$ provided this limit exists. (We allow the possibility that $c$ may be the endpoint of the interval.) My Attempt: As $f$ is differentiable at $c \in I$ , so there is a real number $f^\prime(c)$ such that  given any real number $\varepsilon > 0$ we can find a real number $\delta(\varepsilon) > 0$ such that $$ \left\lvert \frac{ f(x) - f(c) }{ x-c} - f^\prime(c) \right\rvert < \varepsilon \tag{1} $$ or $$ \left\lvert \frac{ f(x) - f(c) - (x-c) f^\prime(c)  }{ x-c} \right\rvert < \varepsilon \tag{1'} $$ for all $x \in I$ which satisfy $$ 0 < \lvert x-c\rvert < \delta(\varepsilon), $$ which is equivalent to $$ c-\delta(\varepsilon) < x < c+ \delta(\varepsilon) \ \mbox{ and } \ x \neq c. $$ So if $x \in I$ and $0 < \lvert x-c \rvert < \delta(\varepsilon)$ , then upon multiplying both sides of (1') by $\lvert x-c\rvert$ , we get $$ \left\lvert f(x)-f(c) - (x-c)f^\prime(c) \right\rvert < \varepsilon \lvert x-c \rvert. \tag{2} $$ And for $x=c$ both sides of (2) equal $0$ . Therefore we can conclude that $$ \left\lvert f(x)-f(c) - (x-c)f^\prime(c) \right\rvert \leq \varepsilon \lvert x - c \rvert \tag{2'} $$ for all $x \in I$ for which $c-\delta(\varepsilon) < x < c+\delta(\varepsilon)$ . From (2') we conclude that if $u, v \in I$ and $c-\delta(\varepsilon) < u \leq c \leq v < c + \delta(\varepsilon)$ , then we have $$ \left\lvert f(u)-f(c) - (u-c)f^\prime(c) \right\rvert \leq \varepsilon \lvert u-c \rvert =  \varepsilon ( c-u ) \tag{2*} $$ and also $$ \left\lvert f(v)-f(c) - (v-c)f^\prime(c) \right\rvert \leq \varepsilon \lvert v-c \rvert =  \varepsilon (v-c), \tag{2**} $$ and therefore $$ 
\begin{align}
& \ \ \ \ \left\lvert f(v) - f(u) - (v-u) f^\prime(c) \right\rvert \\ 
&= \left\lvert f(v) - f(c) + f(c) - f(u) - (v-c + c - u) f^\prime(c) \right\rvert \\
&= \left\lvert \left( f(v)-f(c) - (v-c)f^\prime(c) \right) + \left( f(c) - f(u) - (c-u)f^\prime(c) \right) \right\rvert \\
&\leq \left\lvert f(v)-f(c) - (v-c)f^\prime(c) \right\rvert + \left\lvert f(c) - f(u) - (c-u)f^\prime(c) \right\rvert \\
&\leq \varepsilon ( v-c ) + \varepsilon ( c-u ) \qquad \mbox{[ using (2*) and (2**) above ] } \\
&= \varepsilon (v-u).
\end{align}
$$ Is this proof good enough? Or, are there any problems in it? Where has this lemma originated? Any applications of this lemma? Some references please.","['inequality', 'solution-verification', 'derivatives', 'real-analysis']"
2914826,Volume of a section of a sphere,"A section of a sphere is described by $0 ≤ 𝑟 ≤ 2$, $0 ≤ 𝜃 ≤ 90°$, $30° ≤ 𝜑 ≤ 90°$. Now, just by using simple symmetry, I can see that the volume of this section will be less than 1/8th of the volume of a sphere with radius 2. Volume of the section < (Volume of the sphere of radius $2$) $/$ $8$ Volume of a sphere of radius $2$ is $33.51$ according to $4/3 \pi r^3$. I solved it using differential method but my answer is more than $1/8$th of the volume. What is wrong here?","['multivariable-calculus', 'spherical-coordinates', 'volume']"
2914860,(Puzzle) Find the area of the orange quadrilateral in the given figure,"Given: in the figure below, ABCD is a square, and DH=CG=FB=AE. Areas of quadrilaterals green, red and blue are given in the figure. Find: area of the orange quadrilateral. I'm struggling with this problem. I can see that we can find congruent triangles HDG, GCF, FBE and AEH. And most likely this is useful in the solution, but I don't see how. Hints and solutions welcomed. Sorry if this is a dup.","['contest-math', 'puzzle', 'geometry']"
2914864,Clarification on definition of smooth map between smooth manifolds,"Let $M$ and $N$ be $n$-dimensional smooth manifolds. A map $F: M \to N$ is smooth if for each $p \in M$ there exists smooth charts $(U, \varphi)$ containing $p$ and $(V, \psi)$ containing $F(p)$ such that $F(U) \subset V$ and the composite map $\psi \circ F \circ \varphi^{-1} : \varphi(U) \to \psi(V)$ is smooth. My confusion is: Does this definition hold for all smooth charts containing $p$? In other words, if $(W, \sigma)$ is any chart for containing $p$, in any smooth atlas for $M$, will there be a corresponding chart $(V_2, \psi_2)$ containing $F(p)$ such that $F(W) \subset V_2$ and $\psi_2 \circ F \circ \sigma^{-1} : \sigma(W) \to \psi_2(V_2)$ is smooth.? Or is the definition saying that if $F$ is smooth then there exists at least one chart containing $p$ satisfying the conditions.","['smooth-functions', 'smooth-manifolds', 'definition', 'differential-topology', 'differential-geometry']"
2914895,Is there a name for functions from $A^k$ to A?,"Is there a name for functions whose domain is a cartesian product of the range? If not, is there a name for functions whose domain is the same as the range?","['elementary-set-theory', 'functions']"
2914913,Binomial Calculating Probability of Airline Tickets,"Because not all airline passengers show up for their reserved seat, an airline sells 125 tickets for a flight that holds only 115 passengers. The probability that a passenger does not show up is 0.05, and the passengers behave independently. Round your answers to four decimal places (e.g. 98.7654). a) What is the probability that every passenger who shows up can take the flight? b) What is the probability that the flight departs with at least one empty seat? I am not using a statistics program to calculate my answers like I have seen many answers on here use, but by using a formula:
For example: P(115) =
125 C 115 * (.95)^115 * (.05)^10 = .0475 Similarly I have: P(116) = .0778 P(117) = .1137 P(118) = .1465 P(119) = .1637 P(120) = .1556 P(121) = .1221 P(122) = .0761 P(123) = .0353 P(124) = .0108 P(125) = .0016 So for part a) I did: 1 - P(X > 115) = 1 - .9032 = .0968 and for part b) I did: 1 - P(x >= 115) = 1 - .9507 = .0493 These numbers just do not seem correct to me. And I am confused as to why the probabilites are increasing from P(115) to P(119), (I would expect them to decrease, however I guess if they are on the rising part of the binomial distribution and then go to the falling part of the distribution at P(120) Edit: I know understand these values are correct and fall around the most probable value P(119) which is the mean. Thank you for help in clarifying.","['statistics', 'binomial-distribution']"
2914921,"Use Dominated Convergence Theorem to find limit of $\int n f(x) e^{-nx} \, dx$","I was working on an old practice qual and I came across this problem.  I have a solution, but it's rather...convoluted...and I feel like there should be a simple way of using the dominated convergence theorem to solve it.  Anyways, here's the problem: Let $f: [0,\infty) \rightarrow \mathbb{R}$ be Lebesgue integrable and suppose that $\lim_{x\rightarrow 0} f(x) = 2016$.  Show that $$\lim_{n\rightarrow \infty} \int_0^\infty nf(x)e^{-nx} \, dx = 2016$$ If you change variables, you get that the integral is equal to $\int_0^\infty f(\frac{x}{n})e^{-x}\, dx$, and so the claim is easy to prove if you know that $f$ is bounded.  In particular, if $f$ is continuous with compact support, the problem is solved.  However, despite the fact that we can prove the claim for a dense subset of $L^1$, it doesn't seem to follow for all of $L^1$ (as far as I can tell). I'll put my solution (without directly using the DCT) in the answers because it's pretty long.","['convergence-divergence', 'lebesgue-integral', 'real-analysis']"
2914940,"What is the conditional probability that the first die shows 5, conditional on the event that exactly three dice show 5?","Suppose that we roll four fair six-sided dice. What is the conditional probability that the first die shows 5, conditional on the
event that exactly three dice show 5? Let $A=\{\text{first dice shows 5}\}$ Let $B=\{\text{3 dice shows 5}\}$ We want $P(A|B)=P(A\cap B)/P(B)$ I know that the size of the sample space $S=6^4$ , but I don't know how to compute $P(A \cap B)$ The $P(B)=(1/6)^3$, since for each dice its $1/6$ chance of showing $5$. I am stuck on the intersection part.","['conditional-probability', 'discrete-mathematics', 'probability']"
2914976,Showing that $ \lim_{x \to \infty} x(1/2)^x = 0$,"Can someone explain to me why $$ \lim\limits_{x \to \infty} x\bigg(\frac{1}{2}\bigg)^x = 0$$ 
Is it because the $\big(\frac{1}{2} \big)^x$ goes towards zero as $ x $ approaches $\infty$, and anything multiplied by $0 $ included $\infty$ is $0$ ? Or does this kind of question require using l'hopital's rule because it is in the form (0*$\infty$)? I thought it could be solved this way. Please let me know if it is correct:
$$ \lim\limits_{x \to \infty} \bigg(\frac{x}{\frac{1}{2^{-x}}}\bigg)$$ L'hopitalize the above and get:
$$ \lim\limits_{x \to \infty} \bigg(\frac{1}{x(2^{x-1})}\bigg) = 0$$",['limits']
