question_id,title,body,tags
2323226,Folland Real Analysis Exercise 1.2.3,"This is my attempt at an exercise from Folland's Real Analysis . Could someone evaluate it (particularly the second claim)? Let $\mathcal M$ be an infinite $\sigma$-algebra. Claim: $\mathcal M$ contains an infinite sequence of disjoint sets. Proof: Since $\mathcal M$ is infinite, it must contain a sequence $\left\{E_j\right\}_{j=1}^\infty$ such that $E_n\neq E_m$ whenever $n\neq m$. Let $F_j=E_j\setminus\bigcup_{k=1}^{j-1}E_k$. Then $\left\{F_j\right\}_{j=1}^\infty$ is an infinite sequence in $\mathcal M$ of disjoint sets. Claim: $\text{card}\left(\mathcal M\right)\geq\mathfrak c$. Proof: Let $C=\left\{0,1\right\}^\mathbb N$. Then $\text{card}\left(C\right)=\mathfrak c$. Define $f:C\to\mathcal M$ by $c\mapsto\bigcup\left\{F_j:c_j=1,j\in\mathbb N\right\}$. Then $f$ is well-defined and injective: suppose otherwise that $c,d\in C$ with $f(c)=f(d)$ and $c\neq d$. Let $k\in\mathbb N$ be such that $c_k\neq d_k$. Assume, without loss of generality, that $c_k=1$. Then, since the $F_j$'s are disjoint, there is an $x\in F_k\subset f(c)$ such that $x\notin f(d)$, contradicting the assumption that $f(c)\subset f(d)$.","['real-analysis', 'measure-theory']"
2323265,Antisymmetric matrix operating on $\mathbb R_{\ge 0}^n$,"While looking at something related to game theory, I came across this problem. Given an antisymmetric matrix $\mathbf A$, show that there is a vector $\mathbf t \ne \mathbf 0$ with only nonnegative entries such that $\mathbf{At}$ has only nonpositive entries. I've managed to prove some things about $\mathbf t$. In particular, for all $i$, at most one of $t_i$ and $[At]_i$ can be nonzero. However, I can't seem to prove that $\mathbf t$ necessarily exists. Any tips on how I might prove this? Or, for that matter, is there a counterexample?",['linear-algebra']
2323294,$\sum_1^\infty{\frac{1}{n(n+1)(n+2)}}$? [duplicate],This question already has answers here : Find the sum of the series $\sum \frac{1}{n(n+1)(n+2)}$ (10 answers) Closed 7 years ago . How to find the sum of the series $\sum_1^\infty{\frac{1}{n(n+1)(n+2)}}$? I expanded it via partial fractions but it does not look like a telescoping series which I was expecting. Am I missing something obvious or easy manipulation here?,['sequences-and-series']
2323300,Are proper subgroups of $\Bbb C^*$ cyclic?,Let $\Bbb C$ be the field of Complex numbers and $\Bbb C^*$ be the group of non zero Complex numbers under multiplication.  Then every proper subgroup of  $\Bbb C^*$ is cyclic.  Is it correct statement? I know that every finite subgroup of  $\Bbb C^*$ is cyclic.  But I am doubtful about above statement. Please clarify my doubt.  If $\Bbb C^*$ has infinite proper subgroup then it will not be cyclic. But I don't have any example.  Please correct me if I am wrong.,"['abstract-algebra', 'group-theory', 'cyclic-groups']"
2323338,$F$ is Lipschitzian if for every $f$ AC，$F◦f$ is AC,"Let a function $F$ on [a, b] be such that the
composition $F◦f$ is absolutely continuous for every absolutely continuous function
$f$ with values in [a, b]. Prove that $F$ is Lipschitzian. I found it proved by Fichtenholz, but unfortunately it's written in Russian. Could anyone show the main idea of the proof? 3x Maybe one can follow this: http://www.mathnet.ru/links/fcd916a74bbfdb3911ca6b52105af230/sm6853.pdf","['real-analysis', 'measure-theory']"
2323365,"Evaluate $\int_1^{\infty} {\frac{\ln{x}}{(x-1)(2x-1)}\,dx}$","Evaluate: $$\int_1^{\infty} {\left(\frac{\ln{x}}{\left(x-1\right)\left(2x-1\right)}\,dx\right)}$$ It turns out that the value of the integral is exactly: $$\frac{1}{12}\left(\pi^2+6\ln^2{2}\right)$$ as found by WolframAlpha, but Wolfram gives no indication of how it arrives at this curious result. How would one solve the integral analytically? A first step might be the $u$-sub, $u=\frac{1}{x}$, which gives: $$\int_1^{\infty} {\left(\frac{\ln{x}}{\left(x-1\right)\left(2x-1\right)}\,dx\right)}=-\int_0^1 {\left(\frac{\ln{x}}{\left(1-x\right)\left(2-x\right)}\,dx\right)}$$ Thanks!",['integration']
2323374,How long does it take for rain drops cover a square?,"Consider a square divided into $n \times n$ grid. Each rain drop falls from the sky and covers an $r \times r$ grid chosen uniformly at random within the square. What is the expected number of rain drops needed to cover the whole square? To avoid boundary conditions, we can assume that the square is actually a torus . In other words, the top and the bottom of the square are glued together, while the left side and the right side of the squares are guled together. If $r=1$, then this is the classical coupon collector problem . It also gives an upper bound of $n^2 \log(n^2)$ for this rain drop model. I wonder if this model has already been studied? It seems to be natural extension of coupon collector.","['probability-theory', 'probability']"
2323378,Finding solutions of modulus functions,"I decided to do some practice with some functions, and was posed with the following question: So, I sketched the two graphs. For convenience I'll display a photo of them from Desmos. The blue line is | $3x - 2$ | and the red is | $x-5$ |. Now, to find when the two intersect, it the case where the two equations have the same output with the same input is achieved. However, the modulus sign seemed to trip me up when I was writing | $3x - 2$ | = | $x-5$ | and begin doing algebra. I couldn't merely solve it like the function had no modulus sign, since that is a different function. So, I figured by inspection that only the left side of the red function makes the intersections, so the following conditions are the only valid ones. $$-x-5 = 3x-2$$ $$-x-5 = -3x+2$$ And with that I can find the inputs necessary. However, is there a general way to solve this type of problem? Say, if I didn't have the graph to make the inference that I did? How could I solve this problem if I couldn't graph the two functions?","['absolute-value', 'functions']"
2323428,Transpose and adjoint of a linear operator,"I am looking for a formal definition of the transpose of a linear operator (if there is). I've read an article about linear preservers and the author used the notation $A^{Tr}$ to denote the transpose of an operator $A$ (on Hilbert space $H$ ) with respect to a fixed but arbitrary orthonormal basis of $H$ . I don't know if the transpose $A^{Tr}$ that he's talking about is actually the adjoint of an operator $A$ , but he just simply used different terminology. I'm a bit confused. Can you please help me on this? Does an operator have a transpose? Or it is just the same as the adjoint?","['functional-analysis', 'operator-algebras', 'linear-algebra', 'operator-theory']"
2323436,Calculus and Geometry Word Problem,"The Chemist's Dilemma: Mary, the chemist, is making a solution in her laboratory, pouring ChemA into ChemB. Mary pours 1 mg of ChemA per second into an inverted 60º cone of vertical length .5 meters containing 10 g of ChemB for 1 minute; however, she does not notice a hole at the bottom of the cone that lets 1 mg of the solution in the cone out every second. When Mary's finished, what percentage of the solution is ChemB? [Assume that ChemA and ChemB mix instantaneously and fully on touch] In my attempts to solve this problem, I've attempted to construct an integral that would include a function determining the current percentages of ChemA and ChemB in the solution so I could calculate how much of each would be left after losing the 1 mg; however, I soon realized that function, which seemed fairly necessary to me, was actually just the original integral I was trying to find. I didn't know what to do at this recursion so I stopped there, but if anyone cares to help me (I came up with this putzing around and would just love to know the answer), it'd be greatly appreciated.","['multivariable-calculus', 'calculus', 'geometry']"
2323468,How are lengths of tuples defined if k-tuples are pairs?,"In the book ""Set Theory And Logic"" I read the following sentence: The ordered triple x, y, z, symbolized by (x, y, z), is defined to be the ordered pair ((x, y), z). The wikipedia page on tuples also mentions the same definition. To me, this seems absurd, as in that case a 3-tuple is also a 2-tuple, so it wouldn't really make sense anymore to talk about the length of a tuple. Having just begun, I'm assuming I'm the one not seeing clearly here. Please open my eyes.",['elementary-set-theory']
2323490,Proof that $|\sin(nx)| \le n|\sin(x)|$ [duplicate],"This question already has an answer here : How to prove by induction that $|\sin(nx)| \leq n|\sin x|$? (1 answer) Closed 4 years ago . I have to show that for every $x \in \mathbb{R}$ and every $n \in \mathbb{N}$ $$|\sin(nx)| \le n|\sin(x)|  $$
In the previous exercise, I have showed that $|\sin(x)|≤|x|$ with the use of the mean value theorem. I think that I cannot use this approach this time. I also tried to write $\sin(nx)$ as a series expansion but that doesn't work either. Does anyone know how I can solve this?","['real-analysis', 'trigonometry', 'analysis', 'functions']"
2323500,How to find number of solutions to $2^x=x^2$ without Graphing,Find number of real solutions to $2^x=x^2$ without plotting graph: I considered $f(x)=2^x -x^2$ $$f'(x)=2^x \ln 2-2x=0$$ we get again a transcendental equation. Any good approach please,"['algebra-precalculus', 'exponential-function', 'transcendental-numbers']"
2323548,"What is the Krull dimension of $C(X)$ for $X$ infinite, compact and Hausdorff?","What is the Krull dimension of the ring of continuous real-valued functions on an infinite compact Hausdorff space? If the Krull dimension is not finite, we will say that it is infinite, and not try to define it as a cardinal or an ordinal. Of course the Krull dimension of $C(X)$ depends a priori on $X$, but I'd be very happy if it could be computed even in the most particular cases.","['functional-analysis', 'abstract-algebra', 'commutative-algebra']"
2323561,Why a finite dimensional algebra always has a smallest submodule having semisimple quotient,"$A$ is a finite-dimensional algebra (possible without unit, the corresponding field is $\mathbb{F}$), I want to prove that A has a smallest submodule having semisimple quotient. What I have got is that if $M$ and $N$ are submodules of $A$ (as an $A$-module) such that $A/M$ and $A/N$ are semisimple $A$-modules, then $A/M\cap N$ is a semisimple $A$-module. So to prove the original proposition, all I need to do is to prove that there are at most finite submodules of $A$ having semisimple quotient. If I prove this, I can finish my job by using the result above and by induction. But I don't know how to prove this. Any help or hint will be appreciated. Thanks in advance.","['finite-groups', 'abstract-algebra', 'modules', 'group-theory']"
2323584,How do I find singularities and residue?,Given is $f(z)=\sin(\exp(\frac{1}{z}))$. How do I find singularities and residue? I know that singularity for my function is $z_0=0$. But how do I find residue?,['complex-analysis']
2323611,Why we study Endo-Trivial Modules?,"Recently I came across the notion of Endo-Trivial modules (out of brevity's sake e-t), and was a surprise for me that there is a huge (and rather complicated) theory behind them. I recall that an e-t module is a finitely-generated $\mathbb{K}G$-module over a field of positive characteristic $\mathbb{K}$ and say $G$ a $p$-group, such that $M^{*} \otimes M \cong  \mathbb{K} \oplus \textit{(proj)}$, where $(proj)$ states for some projective $\mathbb{K}G$-module. Apparently there should be a kind of modular represenation theoretic argument to study those objects, however isn't clear to me. Do you know what's the initiative behind their study? Also, there is a decomposition of those modules always, namely 
$$M = M_0 \oplus \textit{(proj)},$$
for some indecomposable submodule $M_0$, and some projective. However this isn't clear either. The latter should be some kind of version of Krull-Schmidt theorem, since $M$ is a f.g module over an Artinian Ring (and therefore of finite length), hence a decomposition into indecomposables exists and is unique (up to isomorphism). However the theorem doesn't mention anything about projectivity for the indecomposables, so I can't come up with a better idea unfortunately. Could you please help me out?","['abstract-algebra', 'modules', 'representation-theory']"
2323626,Finding the number of k-tuples of sets.,"Find the number of k-tuples of sets $<S_1,...,S_k>$ where $S_1,...,S_k ⊆$ {1,...,n} and where: $S_1⊆S_2⊇S_3⊆S_4⊇S_5⊆S_6⊇ ...$ So I think it will look something like this: picture but can't figure how to find the answer.  Any ideas?",['combinatorics']
2323636,Total number of possible order possible in this binary search tree?,"When searching for the key value $60$ in a binary search tree, nodes containing the key values $10, 20, 40, 50, 70, 80, 90$ are traversed, not necessarily in the order given. How many different orders are possible in which these key values can occur on the search path from the root to the node containing the value $60$ ? $35$ $64$ $128$ $5040$ My attempt: This is previous question of GATE CS/IT. This question is explained somewhere as: There are $4$ values that are smaller than $60$ and $3$ values are greater than $60$ . We can rearrange in $4! = 24$ ways smaller values and rearrange $3! = 6$ ways.
Total number of different order are $= 7! /(4!*3!) = 35$ ways. My argument is: Same as : Number of binary search tree of height $6$ We can have $2^4$ number of sub-trees in left of root $60$ and $2^3$ number of sub-trees in right of root $60$ (in This case, both right subtree and left sub-tree will have skewed, that means linear).
So, total number of such trees $= 2^4 \times 2^3 = 2^7 = 128$ I am asking, what is flaw in my argument? Can you explain it, please?","['computer-science', 'binary', 'permutations', 'combinatorics', 'discrete-mathematics']"
2323651,Probability of at least one die holding $6$ among $3$ dice,"When one throws three equal dice, how could we find what the probability that at least one die is holding the number 6 would be? Here’s my solution. The sample space is $$\mathbb C = \{(x,y,z)\mid x,y,z, \in \mathbb N\setminus\{0\}, 1\le x,y,z \le 6 \}.$$ Then, the event space is $$C = \{(x,y,z) \in \mathbb C \mid (x,y,z)
 \in (6,y,z)\cup(x,6,z)\cup(x,y,6)\}.$$ Now, $|\mathbb C| = 6\cdot6\cdot6 = 216$ and $|C| = 36+36+36 - (6+6+6) + 1 =91$ . Thus the probability equals $\frac{91}{216}$ . Is this correct?","['probability', 'dice', 'solution-verification']"
2323671,Is Borel-field different from $\sigma$-field?,"My mathematical statistics book denotes $\sigma$-field as following: Let $\Bbb B$ be the collection of subsets of $\Bbb C$ where $\Bbb C$ denotes sample space which is the collection of all possible events. Then $\Bbb B$ is $\sigma$-field if (1) $\emptyset \in \Bbb B$ and $\exists b \in \Bbb B$ s.t. $\emptyset \subset b$ (2) $C \in \Bbb B \Rightarrow C^c\in \Bbb B $ where $C \in \Bbb C$ (3) $\{C_1, C_2, C_3..\} \in  \Bbb B \Rightarrow \cup_{i=1}^{\infty}C_i \in \Bbb B$ where $\{C_1, C_2, C_3..\}$ is countable collection of subsets of $\Bbb C$ Is this field a specific example of Borel Field? or this field is eqaully defined with Borel Field?","['borel-sets', 'measure-theory']"
2323688,If $f (x) +f'(x) = x^3+5x^2+x+2$ then find $f (x)$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question If  $f (x) +f'(x) = x^3+5x^2+x+2$  then  find $f(x)$. $f'(x)$ is the first derivative of $f (x)$. I have no idea about this question, please help me.",['calculus']
2323767,Complex Integral Satisfying Differential Equation,"So I'm taking a complex analysis course on EdX, and this is the first problem on the first problem set. It's far overdue, so I'm not looking to submit it. I just want to know what are the inner workings of how one gets from the question to the answer. The integral is:
$$K(\lambda) = \int_{-\infty}^{\infty}e^{-\lambda t^2}\frac{dt}{t-ib}$$ The equation that it apparently satisfies is (and I don't know this to start with, this is just from clicking on Show Answer; there are blanks in place of the $'$, $b^2$, and $\displaystyle \frac {b}{\sqrt{\lambda}}$): $$K' - b^2K=-i\sqrt{\pi}\frac{b}{\sqrt{\lambda}}$$ This is a differentiation w.r.t. parameter problem, so $\displaystyle K'\equiv\frac{dK}{d\lambda}$. I've tried expanding the $\displaystyle \frac{1}{t-ib}$ term, but that doesn't seem to lead anywhere. I've tried differentiating the $e^{-\lambda t^2}$ term w.r.t. parameter, but that doesn't make the expression look like anything nice either. I don't know how to go about this, and this is quite literally the first problem of a course in which I can follow the lectures.","['complex-analysis', 'definite-integrals', 'ordinary-differential-equations']"
2323816,Solution to an annoying ODE,"I'm very sorry if this is a duplicate, but searching for a specific equation is rather difficult. I have encountered the following ODE during my physics research (have a PDE which has a similarity solution), and am wondering whether there's any chance of obtaining an analytic solution to it:
\begin{equation} x y' = -2(A(y) y')' ,\end{equation} for $y(x)$ with $y'=\frac{\mathrm{d}y}{\mathrm{d}x}$, just to be clear. $A(y) = 1-\zeta y(4-3y)$, for $\zeta \ge 0$, although I suspect that if we find ourselves invoking that we've probably already failed, so maybe treat $A(y)$ as being generic for now. I've fiddled around with it, but without much success. In terms of boundary conditions, well, they're up for grabs, was hoping the solution would tell me a bit more about them; physically $0 \le y \le 1$, and would probably like to prescribe Dirichlet conditions on either side of a finite domain. If it helps, I got to this equation using this: https://arxiv.org/pdf/0710.4000.pdf , around page 5. Of course, asymptotic solutions as $x\rightarrow 0$ or $x\rightarrow \pm \infty$ would also be very cool, as would advice about how to tackle it numerically if analytic solution attempts prove fruitless.","['ordinary-differential-equations', 'calculus', 'analysis']"
2323845,How do I create a 4 on 4 tournament where every player plays with every other player an equal number of times?,"I would like to create a 4 on 4 tournament with 8 players (4 players on a team where two teams play against each other each game), where every player plays with every other player an equal number of times.  A simple example of this would be if you had a 2 on 2 tournament with 4 players then: 12 v 34 13 v 24 14 v 23 If it were 6 players doing 3 v 3 then you could have 10 games covering the 20 combinations possible. (i.e. 123 v 456 and so forth). With 4 v 4 using 8 players it is difficult or at least impossible and impractical to cover all combinations with 8 Choose 4 being 105.  I would like to determine a 'very close' practical solution that would require no more than 10 games, so really an ideal would be 7 games where each player plays with every other player 3 times total on their team.  I haven't been able to figure out a good algorithmic way to approach this aside from doing it by hand and adjusting as I go to ensure player 1 plays with all others 3 times, then player 2 plays with all others (3-8) 3 times, then player 3 plays with all others (4-8) 3 times, making changes that preserve the previous counts.  Any suggestions or solutions? Second Update: I have solved the problem by hand below, where each player has each other player as a teammate for exactly 3 matches: 1235 4678 1458 2367 1347 2568 1278 3456 1368 2457 1246 3578 1567 2348 I performed this by hand by looking for imbalances and attempting a rebalance that preserved the partner match count for player 1. For instance if there was one match with 46 paired but 5 for 48 paired then I looked to change a 48 pairing into a 46 and then preserve the balance of the matchups for player 1 by changing yet another 48 into a 46. Then, recheck to verify all pairings up to the ""4s"" were still balanced and continue. I feel like it was dumb luck paired with a generally sound higher probability approach that enabled me to reach this perfect solution.",['combinatorics']
2323869,Milnor's proof that $f^{-1}(y)$ is a finite set,"Suppose $f : M \to N$ is a smooth mapping between manifolds of the same dimension $m$.Milnor says the following Observe that if $M$ is compact and $y \in N$ is a regular value, then $f^{-1}(y)$ is a finite set (possibly empty) For $f^{-1}(y)$ is in any case compact, being a closed subset of a compact space $M$; and $f^{-1}(y)$ is discrete, since $f$ is one-to-one in a neighbourhood of each $x \in f^{-1}(y)$ The fact that $f^{-1}(y)$ is closed in $M$ follows from the fact that $\{y\}$ is closed in $N$ and since $f$ is continuous, we have $f^{-1}(y)$ to also be closed But I can't see how the fact that $f$ is one-to-one in a neighbourhood of each $x \in f^{-1}(y)$ implies that $f^{-1}(y)$ is finite. The fact that $f$ is one-to-one follows from the inverse function theorem","['general-topology', 'differential-topology']"
2323898,Is there an injective operator with a dense nonclosed one-codimensional range?,"Let $H$ be an infinite dimensional separable Hilbert Space. Is there an operator $A\in B\left( H\right) $ such that $Im\left(
A\right) \neq \overline{Im\left( A\right) }=H$, $ codim\left(Im%
\left( A\right)\right) =1$
and
 $\ker \left( A\right) =\left\{ 0\right\} $ ?","['hilbert-spaces', 'operator-theory', 'functional-analysis', 'linear-transformations', 'linear-algebra']"
2323993,A list of Multiple Zeta values of depth three,"The multiple zeta function of depth three has a following integral representation: 
\begin{eqnarray}
\zeta(t^{-1},p,q,r) &:=& \sum\limits_{m_1 > m_2 > m_3 > 0} \frac{t^{m_1}}{m_1^p} \frac{1}{m_2^q} \frac{1}{m_3^r} \\
&=& \int\limits_0^t \frac{[\log(t/\xi)]^{p-1}}{(p-1)!} \int\limits_0^{\xi} \frac{[\log(\xi/\xi_1)]^{q-1}}{(q-1)!} \cdot \frac{Li_r(\xi_1)}{1-\xi_1} d\xi_1 \frac{1}{1-\xi} d\xi 
\end{eqnarray}
By using the formula above we calculated the following list of values at plus unity for weights from four to six. We have:
\begin{eqnarray}
\zeta(2,1,1) &=& \zeta(4)\\
\hline\\
\zeta(3,1,1) &=& -  \zeta(2) \zeta(3) + 2 \zeta(5)\\
\zeta(2,2,1) &=& + 3\zeta(2) \zeta(3) -\frac{11}{2} \zeta(5)\\
\zeta(2,1,2) &=& - 2\zeta(2) \zeta(3) + \frac{9}{2} \zeta(5)\\
\hline \\
\zeta(4,1,1) &=& -  \zeta(3)^2 + \frac{23}{16} \zeta(6)\\
\zeta(3,2,1) &=& +3  \zeta(3)^2 - \frac{203}{48} \zeta(6)\\
\zeta(3,1,2) &=& -\frac{3}{2}  \zeta(3)^2 + \frac{53}{24} \zeta(6)\\
\zeta(2,3,1) &=& -\frac{3}{2}  \zeta(3)^2 + \frac{53}{24} \zeta(6)\\
\zeta(2,2,2) &=& \frac{3}{16} \zeta(6) \\
\zeta(2,1,3) &=& + \zeta(3)^2 - \frac{13}{16} \zeta(6)\\
\hline
\zeta(5,1,1)&=&-\frac{5}{4} \zeta(3) \zeta(4)-2 \zeta(2)\zeta(5) +5 \zeta(7)\\
\zeta(4,2,1)&=&+\frac{-236 \zeta(3) \zeta(2)^2+28776 \zeta(5) \zeta(2)+18902 \zeta(3) \zeta(4)-72267 \zeta(7)}{5232}\\
\zeta(4,1,2)&=&-\frac{451}{327} \zeta(3) \zeta(2)^2+\frac{5}{2} \zeta(5) \zeta(2)-\frac{395 \zeta(3) \zeta(4)}{1308}+\frac{5 \zeta(7)}{8}\\
\zeta(3,3,1)&=&-\frac{77}{109} \zeta(3)\zeta(2)^2-\frac{9}{2} \zeta(5) \zeta(2)+\frac{385}{218} \zeta(3) \zeta(4)+\frac{61 \zeta(7)}{8}\\
\zeta(3,2,2)&=&+\frac{15908 \zeta(3) \zeta(2)^2-39240 \zeta(5) \zeta(2)-27998 \zeta(3) \zeta(4)+51339 \zeta(7)}{5232}\\
\zeta(3,1,3)&=&+\frac{1600 \zeta(3) \zeta(2)^2-3673 \zeta(3) \zeta(4)-327\zeta(7)}{1308}\\
\zeta(2,4,1)&=&+\frac{59 \zeta(3) \zeta(2)^2}{1308}+5 \zeta(5) \zeta(2)-\frac{3565 \zeta(3) \zeta(4)}{2616}-\frac{109 \zeta(7)}{16}\\
\zeta(2,3,2)&=&-\frac{1519}{654} \zeta(3) \zeta(2)^2-\frac{11}{2} \zeta(5) \zeta(2)+\frac{7595 \zeta(3) \zeta(4)}{1308}+\frac{75 \zeta(7)}{8}\\
\zeta(2,2,3)&=&+\frac{844 \zeta(3) \zeta(2)^2+62784 \zeta(5) \zeta(2)-9958 \zeta(3) \zeta(4)-95157 \zeta(7)}{5232}\\
\zeta(2,1,4)&=&+\frac{1}{8} (14 \zeta(3) \zeta(4)-44 \zeta(2) \zeta(5)+61 \zeta(7))\\
\hline\\
\zeta(6,1,1)&=&+\frac{1}{2} \zeta (3)^2 \zeta(2)-3 \zeta (3) \zeta (5)+\frac{61 \zeta(8)}{24}\\
\zeta(5,2,1)&=&+\frac{7}{4} \zeta(6,2)-\zeta (3)^2 \zeta(2)+\frac{7 \zeta (3) \zeta (5)}{2}-\frac{289\zeta(8)}{144}\\
\zeta(5,1,2)&=&-\zeta(6,2)-\frac{3}{2} \zeta (3)^2 \zeta(2)+\frac{9 \zeta (3) \zeta (5)}{2}-\frac{145 \zeta(8)}{72}\\
\zeta(4,3,1)&=&-\frac{25}{4} \zeta(6,2)+\frac{1}{2} \zeta (3)^2\zeta(2)+\frac{21 \zeta (3) \zeta (5)}{2}-\frac{677 \zeta(8)}{48}\\
\zeta(4,2,2)&=&+\frac{9}{2} \zeta(6,2)+3 \zeta (3)^2 \zeta(2)-20 \zeta (3) \zeta (5)+\frac{1271\zeta(8)}{72}\\
\zeta(4,1,3)&=&+\frac{5}{2} \zeta(6,2)+\frac{1}{2} \zeta (3)^2 \zeta(2)-\frac{15 \zeta (3) \zeta (5)}{2}+\frac{583 \zeta(8)}{72}\\
\zeta(3,4,1)&=&+\frac{15}{4} \zeta(6,2)-2 \zeta (3)^2\zeta(2)+\frac{673 \zeta(8)}{144}\\
\zeta(3,3,2)&=&+\frac{13}{4} \zeta(6,2)+\frac{9}{2} \zeta (3)^2 \zeta(2)-23 \zeta (3) \zeta (5)+\frac{857 \zeta(8)}{48}\\
\zeta(3,2,3)&=&-10 \zeta(6,2)-6\zeta (3)^2 \zeta(2)+\frac{89 \zeta (3) \zeta (5)}{2}-\frac{245 \zeta(8)}{6}\\
\zeta(3,1,4)&=&+\frac{3}{2} \zeta (3)^2 \zeta(2)-\frac{11 \zeta (3) \zeta (5)}{2}+\frac{241\zeta(8)}{72}\\
\zeta(2,5,1)&=&+\frac{7}{4} \zeta(6,2)+2 \zeta (3)^2 \zeta(2)-12 \zeta (3) \zeta (5)+\frac{487 \zeta(8)}{48}\\
\zeta(2,4,2)&=&-10 \zeta(6,2)-5 \zeta (3)^2 \zeta(2)+40 \zeta (3)\zeta (5)-\frac{677 \zeta(8)}{18}\\
\zeta(2,3,3)&=&+\frac{27}{4} \zeta(6,2)+2 \zeta (3)^2 \zeta(2)-\frac{45 \zeta (3) \zeta (5)}{2}+\frac{1111 \zeta(8)}{48}\\
\zeta(2,2,4)&=&+\frac{11}{2} \zeta(6,2)+2\zeta (3)^2 \zeta(2)-20 \zeta (3) \zeta (5)+\frac{121 \zeta(8)}{6}\\
\zeta(2,1,5)&=&-\frac{5}{2} \zeta(6,2)-\zeta (3)^2 \zeta(2)+\frac{21 \zeta (3) \zeta (5)}{2}-\frac{181 \zeta(8)}{18}\\
\hline\\
\zeta(7,1,1)&=&-3 \zeta (7) \zeta(2)-\frac{9}{4} \zeta (5) \zeta(4)-\frac{7}{4} \zeta (3) \zeta(6)+\frac{28 \zeta (9)}{3}+\frac{\zeta (3)^3}{6}\\
\zeta(6,2,1)&=&+11 \zeta (7) \zeta(2)+\frac{13}{2} \zeta(5) \zeta(4)+\frac{9}{2} \zeta (3) \zeta(6)-\frac{2189 \zeta (9)}{72}-\frac{\zeta (3)^3}{3}\\
\zeta(6,1,2)&=&+7 \zeta (7) \zeta(2)-\frac{1}{4} \zeta (5) \zeta(4)-\frac{5}{3} \zeta (3)\zeta(6)-\frac{313 \zeta (9)}{36}-\frac{\zeta (3)^3}{3}\\
\zeta(5,3,1)&=&-17 \zeta (7) \zeta(2)-\frac{23}{4} \zeta (5) \zeta(4)-\frac{3}{4} \zeta (3) \zeta(6)+\frac{845 \zeta (9)}{24}+\frac{\zeta(3)^3}{6}\\
\zeta(5,2,2)&=&-21 \zeta (7) \zeta(2)+\frac{7}{4} \zeta (5) \zeta(4)-\frac{8}{3} \zeta (3) \zeta(6)+\frac{2513 \zeta (9)}{72}+\frac{2 \zeta (3)^3}{3}\\
\zeta(5,1,3)&=&-7 \zeta (7)\zeta(2)+\frac{1}{2} \zeta (5) \zeta(4)+\frac{5}{4} \zeta (3) \zeta(6)+\frac{121 \zeta (9)}{12}-\frac{\zeta (3)^3}{3}\\
\zeta(4,4,1)&=&+18 \zeta (7) \zeta(2)+5 \zeta (5) \zeta(4)+\frac{4}{3}\zeta (3) \zeta(6)-\frac{328 \zeta (9)}{9}-\frac{\zeta (3)^3}{3}\\
\zeta(4,3,2)&=&+14 \zeta (7) \zeta(2)-\frac{35}{2} \zeta (5) \zeta(4)-\frac{8}{3} \zeta (3) \zeta(6)-\frac{53 \zeta (9)}{36}+\frac{2\zeta (3)^3}{3}\\
\zeta(4,2,3)&=&+28 \zeta (7) \zeta(2)+10 \zeta (5) \zeta(4)+\frac{5}{3} \zeta (3) \zeta(6)-59 \zeta (9)-\frac{\zeta (3)^3}{3}\\
\zeta(4,1,4)&=&-3 \zeta (5) \zeta(4)-\frac{41}{12} \zeta (3)\zeta(6)+\frac{115 \zeta (9)}{18}+\frac{2 \zeta (3)^3}{3}\\
\zeta(3,5,1)&=&-10 \zeta (7) \zeta(2)+\frac{5}{4} \zeta (5) \zeta(4)+\frac{5}{4} \zeta (3) \zeta(6)+\frac{341 \zeta (9)}{24}-\frac{\zeta(3)^3}{3}\\
\zeta(3,4,2)&=&-14 \zeta (7) \zeta(2)+\frac{15}{2} \zeta (5) \zeta(4)-\frac{7}{3} \zeta (3) \zeta(6)+\frac{593 \zeta (9)}{36}+\frac{2 \zeta (3)^3}{3}\\
\zeta(3,3,3)&=&-\frac{1}{2} \zeta (3)\zeta(6)+\frac{\zeta (9)}{3}+\frac{\zeta (3)^3}{6}\\
\zeta(3,2,4)&=&-28 \zeta (7) \zeta(2)-\frac{11}{2} \zeta (5) \zeta(4)+\frac{29}{4} \zeta (3) \zeta(6)+46 \zeta (9)-\frac{4 \zeta(3)^3}{3}\\
\zeta(3,1,5)&=&+7 \zeta (7) \zeta(2)-\frac{1}{4} \zeta (5) \zeta(4)-\frac{1}{2} \zeta (3) \zeta(6)-\frac{131 \zeta (9)}{12}+\frac{\zeta (3)^3}{6}\\
\zeta(2,6,1)&=&+7 \zeta (7) \zeta(2)-\frac{7}{4}\zeta (5) \zeta(4)-\frac{43}{12} \zeta (3) \zeta(6)-\frac{461 \zeta (9)}{72}+\frac{2 \zeta (3)^3}{3}\\
\zeta(2,5,2)&=&-11 \zeta (7) \zeta(2)+\frac{41}{6} \zeta (3) \zeta(6)+\frac{439 \zeta(9)}{36}-\frac{4 \zeta (3)^3}{3}\\
\zeta(2,4,3)&=&+31 \zeta (7) \zeta(2)-\frac{15}{2} \zeta (5) \zeta(4)+\zeta (3) \zeta(6)-\frac{1567 \zeta (9)}{36}-\frac{\zeta (3)^3}{3}\\
\zeta(2,3,4)&=&-32 \zeta (7)\zeta(2)+12 \zeta (5) \zeta(4)-\frac{25}{6} \zeta (3) \zeta(6)+\frac{1567 \zeta (9)}{36}+\frac{2 \zeta (3)^3}{3}\\
\zeta(2,2,5)&=&+31 \zeta (7) \zeta(2)-\zeta (5) \zeta(4)-\frac{25}{6} \zeta (3)\zeta(6)-\frac{3319 \zeta (9)}{72}+\frac{2 \zeta (3)^3}{3}\\
\zeta(2,1,6)&=&-11 \zeta (7) \zeta(2)+\frac{1}{4} \zeta (5) \zeta(4)+\frac{37}{12} \zeta (3) \zeta(6)+\frac{551 \zeta (9)}{36}-\frac{\zeta(3)^3}{3}\\
\hline\\
\zeta(8,1,1)&=&+\zeta (3) \zeta (5) \zeta(2)+\frac{1}{2} \zeta (3)^2 \zeta(4)+\frac{333 \zeta(10)}{80}-4 \zeta (3) \zeta (7)-2 \zeta (5)^2\\
\zeta(7,2,1)&=&-\zeta (3)^2 \zeta(4)-\frac{377\zeta(10)}{60}-\zeta(2) \zeta(6,2)+\frac{9}{4} \zeta(8,2)+\frac{9 \zeta (3) \zeta (7)}{2}+\frac{9 \zeta (5)^2}{4}\\
\zeta(7,1,2)&=&-7 \zeta (3) \zeta (5) \zeta(2)-\zeta (3)^2\zeta(4)-\frac{77 \zeta(10)}{48}+\zeta(2) \zeta(6,2)-\zeta(8,2)+10 \zeta (3) \zeta (7)+5 \zeta (5)^2\\
\zeta(6,3,1)&=&-4 \zeta (3) \zeta (5) \zeta(2)+\frac{1}{2} \zeta (3)^2\zeta(4)-\frac{3219 \zeta(10)}{160}+\frac{5}{2} \zeta(2) \zeta(6,2)-\frac{35}{4} \zeta(8,2)+\frac{29 \zeta (3) \zeta (7)}{2}+\frac{37 \zeta (5)^2}{4}\\
\zeta(6,2,2)&=&+8 \zeta (3) \zeta (5)\zeta(2)+2 \zeta (3)^2 \zeta(4)+\frac{539 \zeta(10)}{16}+\zeta(2) \zeta(6,2)+3 \zeta(8,2)-28 \zeta (3) \zeta (7)-18 \zeta (5)^2\\
\zeta(6,1,3)&=&+16 \zeta (3) \zeta (5)\zeta(2)-\frac{1}{2} \zeta (3)^2 \zeta(4)+\frac{511 \zeta(10)}{160}-\frac{7}{2} \zeta(2) \zeta(6,2)+\frac{7}{2} \zeta(8,2)-21 \zeta (3) \zeta (7)-9 \zeta (5)^2\\
\zeta(5,4,1)&=&-5 \zeta(3) \zeta (5) \zeta(2)-\zeta (3)^2 \zeta(4)+\frac{9209 \zeta(10)}{240}+\frac{21}{2} \zeta(8,2)-10 \zeta (3) \zeta (7)-\frac{27 \zeta (5)^2}{2}\\
\zeta(5,3,2)&=&+35 \zeta (3) \zeta (5) \zeta(2)+2\zeta (3)^2 \zeta(4)-\frac{5683 \zeta(10)}{160}-\frac{25}{2} \zeta(2) \zeta(6,2)+\frac{19}{4} \zeta(8,2)-\frac{63 \zeta (3) \zeta (7)}{2}-\frac{3 \zeta (5)^2}{4}\\
\zeta(5,2,3)&=&-50 \zeta (3)\zeta (5) \zeta(2)-2 \zeta (3)^2 \zeta(4)-\frac{719 \zeta(10)}{20}+10 \zeta(2) \zeta(6,2)-\frac{49}{4} \zeta(8,2)+\frac{161 \zeta (3) \zeta (7)}{2}+\frac{163 \zeta(5)^2}{4}\\
\zeta(5,1,4)&=&-10 \zeta (3) \zeta (5) \zeta(2)+\frac{1}{2} \zeta (3)^2 \zeta(4)-\frac{1027 \zeta(10)}{480}+\frac{5}{2} \zeta(2) \zeta(6,2)-\frac{7}{2} \zeta(8,2)+14 \zeta (3)\zeta (7)+\frac{9 \zeta (5)^2}{2}\\
\zeta(4,5,1)&=&+15 \zeta (3) \zeta (5) \zeta(2)-\frac{1173 \zeta(10)}{32}-\frac{5}{2} \zeta(2) \zeta(6,2)-7 \zeta(8,2)-3 \zeta (3) \zeta (7)+9 \zeta(5)^2\\
\zeta(4,4,2)&=&-40 \zeta (3) \zeta (5) \zeta(2)+\frac{249 \zeta(10)}{40}+10 \zeta(2) \zeta(6,2)-\frac{15}{2} \zeta(8,2)+49 \zeta (3) \zeta (7)+15 \zeta (5)^2\\
\zeta(4,3,3)&=&-20 \zeta (3) \zeta(5) \zeta(2)+\frac{3233 \zeta(10)}{40}+10 \zeta(2) \zeta(6,2)+\frac{7}{2} \zeta(8,2)-7 \zeta (3) \zeta (7)-\frac{59 \zeta (5)^2}{2}\\
\zeta(4,2,4)&=&+80 \zeta (3) \zeta (5) \zeta(2)+\zeta(3)^2 \zeta(4)-\frac{\zeta(10)}{6}-20 \zeta(2) \zeta(6,2)+\frac{35}{2} \zeta(8,2)-105 \zeta (3) \zeta (7)-35 \zeta (5)^2\\
\zeta(4,1,5)&=&-11 \zeta (3) \zeta (5) \zeta(2)+\zeta (3)^2\zeta(4)+\frac{4937 \zeta(10)}{480}+\frac{5}{2} \zeta(2) \zeta(6,2)+7 \zeta (3) \zeta (7)+2 \zeta (5)^2\\
\zeta(3,6,1)&=&-13 \zeta (3) \zeta (5) \zeta(2)-\zeta (3)^2 \zeta(4)+\frac{53\zeta(10)}{40}+\zeta(2) \zeta(6,2)+\frac{7}{4} \zeta(8,2)+\frac{35 \zeta (3) \zeta (7)}{2}+\frac{21 \zeta (5)^2}{4}\\
\zeta(3,5,2)&=&+20 \zeta (3) \zeta (5) \zeta(2)+2 \zeta (3)^2\zeta(4)+\frac{2303 \zeta(10)}{32}+\frac{5}{2} \zeta(2) \zeta(6,2)+\frac{13}{2} \zeta(8,2)-60 \zeta (3) \zeta (7)-\frac{81 \zeta (5)^2}{2}\\
\zeta(3,4,3)&=&+30 \zeta (3) \zeta (5)\zeta(2)-\frac{2703 \zeta(10)}{20}-20 \zeta(2) \zeta(6,2)+17 \zeta (3) \zeta (7)+50 \zeta (5)^2\\
\zeta(3,3,4)&=&-10 \zeta (3) \zeta (5) \zeta(2)+\frac{1}{2} \zeta (3)^2\zeta(4)+\frac{2191 \zeta(10)}{40}+10 \zeta(2) \zeta(6,2)-\frac{7}{2} \zeta(8,2)-11 \zeta (3) \zeta (7)-\frac{41 \zeta (5)^2}{2}\\
\zeta(3,2,5)&=&-52 \zeta (3) \zeta (5) \zeta(2)-4 \zeta(3)^2 \zeta(4)-\frac{241 \zeta(10)}{5}+10 \zeta(2) \zeta(6,2)-\frac{63}{4} \zeta(8,2)+\frac{195 \zeta (3) \zeta (7)}{2}+\frac{159 \zeta (5)^2}{4}\\
\zeta(3,1,6)&=&+17 \zeta (3) \zeta (5)\zeta(2)+\frac{1}{2} \zeta (3)^2 \zeta(4)+\frac{891 \zeta(10)}{160}-\frac{7}{2} \zeta(2) \zeta(6,2)+\frac{7}{2} \zeta(8,2)-25 \zeta (3) \zeta (7)-10 \zeta (5)^2\\
\zeta(2,7,1)&=&+6 \zeta(3) \zeta (5) \zeta(2)+2 \zeta (3)^2 \zeta(4)+\frac{419 \zeta(10)}{20}+\frac{9}{4} \zeta(8,2)-\frac{41 \zeta (3) \zeta (7)}{2}-\frac{43 \zeta (5)^2}{4}\\
\zeta(2,6,2)&=&-16 \zeta (3) \zeta (5)\zeta(2)-4 \zeta (3)^2 \zeta(4)-\frac{3249 \zeta(10)}{40}-\zeta(2) \zeta(6,2)-\frac{21}{2} \zeta(8,2)+63 \zeta (3) \zeta (7)+41 \zeta (5)^2\\
\zeta(2,5,3)&=&+20 \zeta (3) \zeta (5)\zeta(2)+\frac{5969 \zeta(10)}{80}+11 \zeta(8,2)-56 \zeta (3) \zeta (7)-\frac{89 \zeta (5)^2}{2}\\
\zeta(2,4,4)&=&-40 \zeta (3) \zeta (5) \zeta(2)-\zeta (3)^2 \zeta(4)-\frac{289\zeta(10)}{48}+10 \zeta(2) \zeta(6,2)-10 \zeta(8,2)+56 \zeta (3) \zeta (7)+20 \zeta (5)^2\\
\zeta(2,3,5)&=&+28 \zeta (3) \zeta (5) \zeta(2)+2 \zeta (3)^2 \zeta(4)-\frac{425\zeta(10)}{16}-10 \zeta(2) \zeta(6,2)+\frac{23}{4} \zeta(8,2)-\frac{63 \zeta (3) \zeta (7)}{2}+\frac{17 \zeta (5)^2}{4}\\
\zeta(2,2,6)&=&+8 \zeta (3) \zeta (5) \zeta(2)+2 \zeta (3)^2\zeta(4)+\frac{3817 \zeta(10)}{80}+\frac{15}{2} \zeta(8,2)-35 \zeta (3) \zeta (7)-23 \zeta (5)^2\\
\zeta(2,1,7)&=&-6 \zeta (3) \zeta (5) \zeta(2)-\zeta (3)^2 \zeta(4)-\frac{256\zeta(10)}{15}+\zeta(2) \zeta(6,2)-\frac{7}{2} \zeta(8,2)+18 \zeta (3) \zeta (7)+9 \zeta (5)^2\\
\hline\\
\end{eqnarray}
For each weight it turns out that it is pretty easy to calculate the quantity on the very top and that the complexity increases as we move from the top to the bottom. Now my question is are all multiple zeta values defined above reduce-able to single zeta values and if not what is the lowest weight when this is not the case.  Another question is can we establish recurrence relations (just as we did in Calculating alternating Euler sums of odd powers for the respective quantities of depth two ) between those values and solve them for any given weight.","['zeta-functions', 'sequences-and-series']"
2323998,Finding intersection angle at intersection point of two curves,"I've got two curves:
$$(x,y) = (t^2,t+1), \quad t\in\mathbb{R}$$
$$5x^2 + 5xy + 3y^2 -8x -6y + 3 = 0$$ I've found the intersection points: 
$$(0,1) , (1,0)$$. But I can't figure out how to the the angle between the two curves at these intersection points? Should I use derivative somehow? How do I derive a parametric function?","['graphing-functions', 'calculus', 'functions']"
2324044,Find a combinatorial proof to 10!=7!6!,"Prove combinatorically that $ 10!=7!6! $. By ""prove combinatorically"" i mean everything that does not pass by computing $10!,7!,6! $ or some factors of them. This is clearly equivalent to find a bijection (or prove it does exist) between $S_{10}$ and $ S_7 \times S_6 $ where $S_n$ is the symmetric group of order $n$.","['combinatorics', 'factorial', 'group-theory', 'symmetric-groups']"
2324051,Zeros of $f(z) = z^5+3z^4+9z^3+10$ in the unit disk,"Show that $f(z) = z^5+3z^4+9z^3+10$ has $2$ zeros in the unit disk I'm  trying to use Rouche's theorem. So I tried to find a function $g$ that has 2 zeros in the unit disk and: $$|f(z)- g(z)| < |f(z)|+|g(z)| \quad \forall z \in \mathbb{D}  \quad \text{(1)}$$ However, I couldn't find  such function. I tried $g(z) = 3z^4+9z^3+10$. This function has $2$ zeros  in the unit disk according to Wolfram Alpha . I wasn't able to prove $(1)$ and that $g$ has 
$2$ zeros  in the unit disk  with an analytical method. I did the same for the function $g(z) = z^5+9z^3+10$ that has two zeros in unit disk by Wolfram Alpha . It didn't work either. Could somebody help out to prove that $f$ has $2$ zeros in the unit disk?","['complex-analysis', 'polynomials', 'complex-numbers', 'rouches-theorem']"
2324066,Laplace Transform to evaluate $\int_{0}^{\infty} e^{-2t} *t*\sin(4t)dt$,"The question is, how can I find the value of the integral $$\int_{0}^{\infty} e^{-2t} *t*\sin(4t)dt$$ I thought I could solve it by saying this is $L(t\sin(4t))(2)$. Since $L(t\sin(4t)) = \frac{8s}{(s^2+16)^2}$ we have that the integral is this at $s = 2$, or that it is $\frac{1}{25}$. I know this is wrong, but why? EDIT: just checked wolfram alpha, it's right. But is it mathematically rigorous? (My instructor gave a MUCH longer answer).","['laplace-transform', 'calculus']"
2324079,"Find extremas of $f(x,y) = xy \ln(x^2+y^2), x>0, y>0$","As the title says I need to find extreme values(maximum and minimum) of $$f(x,y) = xy \ln(x^2+y^2), x>0, y>0$$ I don't understand how to find critical points of this problem.
I start with finding partial derivative and set derivatives equal to zero. And that is where I am stuck currently. So any help would be appreciated. So: $
\frac{\partial f}{\partial x} = \frac{\partial}{\partial x} (xy* ln(x^2+y^2)) = y*ln(x^2+y^2) + \frac{2xy^2}{x^2+y^2}
$
$
\frac{\partial f}{\partial y} = \frac{\partial}{\partial y} (xy* ln(x^2+y^2)) = x*ln(x^2+y^2) + \frac{2x^2y}{x^2+y^2}
$ So we have now: $
\nabla f(x,y) = (0,0) 
$ $
 y*ln(x^2+y^2) + \frac{2xy^2}{(x^2+y^2)^2} = 0
$ And $
 x*ln(x^2+y^2) + \frac{2x^2y}{(x^2+y^2)^2} = 0
$ After trying to solve these equations I get that $x=y$ Is that correct?. So I don't understand what are then critical points as It can't be (0,0)?",['multivariable-calculus']
2324114,Calculating the volume element,"Let $M$ be a smooth oriented $k$-manifold on $\mathbb{R}^n$, with a parametrization $g\colon U \to \mathbb{R}^n$ where $U \subseteq \mathbb{R}^k$. Suppose we have a continuous function $f\colon \mathbb{R}^n \to \mathbb{R}$ with compact support, and we wish to integrate it over $M$. We want then to calculate: $$\int_M f dV$$ Where $dV$ is a volume element, a differential $k$-form particular to this manifold $M$. I've read on wikipedia that the pullback of the volume element is given by: $$g^*(dV) = \left|g'^T \cdot g'\right|dx_1 \wedge\cdots \wedge dx_k$$ Where $dx_i$ are the usual projection forms in $\mathbb{R}^k$ and $g'$ is the Jacobian matrix of $g$. I would like to understand why though. I'm not even sure what a formal definition of the volume element of a $k$-manifold on $\mathbb{R}^n$ is. Sure, if $k = n$, then this will simply be $dV = dx_1\wedge \cdots \wedge dx_n$ with the projections happening in $\mathbb{R}^n$. The pullback is easy to calculate then, as it commutes with exterior products and exterior derivatives. Outside this realm, I'm quite lost on what's going on. What is the length element of a curve in $\mathbb{R}^2$? Or the area element of a surface in $\mathbb{R}^3$? How does all of this generalizes to $k$-manifolds over the $n$-space?","['smooth-manifolds', 'differential-forms', 'multivariable-calculus', 'integration', 'manifolds']"
2324158,"How can I evaluate $\displaystyle\int_{0}^{\infty}\frac{x\log(x)}{1+e^x}\,dx$?","My attempt : Evaluate a more general case, $$F(a) = \int_{0}^{\infty}\frac{x\log x}{1+e^x}\cdot a^{1+e^x} \,dx$$ $$F'(a) = \int_{0}^{\infty}x\cdot \log(x)\cdot a^{e^x} \,dx$$ Is there any way to take it from here without using by parts multiple times ? Will Feynman's trick be of any help here ? Please don't give away the entire solution. Thanks :)",['integration']
2324186,Computing Hessian of a particular function,"Let $x \in \mathbb{R}^k$, $D \in \mathbb{R}^{k \times k}$, and $b \in \mathbb{R}$. Assume $D$ is symmetric. Consider the function $f : \mathbb{R}^k \rightarrow \mathbb{R}$ defined by $$f(x) = (x^TDx - b^2)^2.$$ I want to compute the Hessian $\nabla^2f$. The gradient can be computed via the chain rule: \begin{align*} \nabla f(x) & = 2(x^TDx - b^2)Dx. \\
& = 2[(x^TDx)Dx - b^2Dx].\end{align*} If we differentiate the second term again, we get $\nabla(b^2Dx) = b^2D$. However, I am not sure how to differentiate the first term. Can anyone help with this?","['multivariable-calculus', 'derivatives']"
2324195,Variational argument with probability measures,"Let $\mathscr M(\mathbb Z^d)$ denote the set of probability measures on $\mathbb Z^d$ Let $\mu \in \mathscr M(\mathbb Z^{d+1}), $. Let $\mu_d $ be the marginal distribution $\sum_{z\in \mathbb Z}\mu(x,z)$ for $x\in \mathbb Z^d$ and $\mu_1=\sum_{x\in \mathbb Z^d}\mu(x,z)$ for $z\in \mathbb Z$. Let $f_d$ be some function which takes measures where the index denotes the dimension of the measure. Assume we have $$f_{d+1}(\mu) \ge \sum_{x\in \mathbb Z^d} \mu_d(x)f_1(\frac {\mu(x,.)}{\mu_d(x)})+\sum_{z\in \mathbb Z} \mu_1(z)f_d(\frac {\mu(.,z)}{\mu_1(z)})$$ My question is: how can I conclude from there that $$\inf_{\nu\in \mathscr M^{d+1}} f_{d+1}(\nu)\ge
\inf_{\nu\in\mathscr M^1} f_1(\nu)
+\inf_{\nu \in \mathscr M^d} f_d(\nu)$$ The book I am reading says ""varying over $\mu$"" but I don't know what they mean by this. It seems reasonable as $\mu_d(x)$ summed over all $x$ equals 1 and thus we want to minimize the first coordinate in the first sum and vice versa in the second one, but what would be the formal proof?","['probability-theory', 'probability', 'probability-distributions']"
2324209,About the self-adjoint extension of one linear differential operator,"I`m trying to solve some problems and I need your help. Consider $$A: \;\;-\frac{d^2y}{dx^2}: C[0,\pi] \to C[0,\pi];\;\;\; y(0)=y(\pi)=0$$. It is unbounded, closed and symmetric, but not self-adjoint. The question is how can I find conditions of existence of self-adjoint extension; what is the simpiest way to solve it? Is it necessary to find deficiency indices (the necessary and sufficient condition is an equality of deficiency indices)
or this problem has a simple decision? And what literature would you advice? Thanks a lot.","['functional-analysis', 'real-analysis', 'operator-theory', 'analysis']"
2324213,How can I tell if elements generate or $F_n$ or $F_n \times F_n$?,"Let $F_n$ be the free group on the letters $x_1,...,x_n$.  Given a set of elements $\{ w_1,...,w_m \} \subset F_n$ how can I tell if they generate $F_n$? Are there nice necessary/sufficient conditions? Similarly I would like to be able to tell if a finite setoff elements in $F_n \times F_n$ generate the whole group?  Is there an algorithmic way to do this?","['geometric-group-theory', 'group-theory', 'free-groups']"
2324229,Integer solutions for $\frac{1}{x}+\frac{1}{y}+\frac{1}{z}+\frac{1}{xy}+\frac{1}{yz}+\frac{1}{zx}+\frac{1}{xyz}=1$,Is there a beautiful solution for this equation over the integers? $$\frac{1}{x}+\frac{1}{y}+\frac{1}{z}+\frac{1}{xy}+\frac{1}{yz}+\frac{1}{zx}+\frac{1}{xyz}=1$$,"['algebra-precalculus', 'elementary-number-theory']"
2324245,Combinatorics proof using bijection.,"This is the 'equation' I need to prove. I am trying to represent the LHS with a Venn Diagram, but I am having troubles with it. 
I defined the them as A, B, and C respectively and stated that B is a subset of A and C is A-B. However, where would 'i' go? i is not part of (at least to me it seems like) any of the sets. Thanks in advance:)","['combinatorics', 'proof-writing', 'discrete-mathematics']"
2324302,Obtaining an explicit expression of $U_n$ given by $U_{n+1}=\frac{2}{3}U_n -1$ and $U_0=2$,"Let $(U_n)_n\geq 0$ be the sequence defined by: $$U_0=2\qquad, U_{n+1}=\frac{2}{3}U_n -1\quad\text{for all } n \geq 0$$ . My question Here is : How do I write  $U_n$ with a function of $n$ ?","['recurrence-relations', 'closed-form', 'generating-functions', 'sequences-and-series', 'discrete-mathematics']"
2324324,Proof of minor claim related to the Twin Primes Conjecture,"Question: How can it be proven that integers of the form $n=6jk\pm j \pm k;\ j,k\in \mathbb N^*,$ are the only ones which (when multiplied by $6$) correspond to multiples of $6$ not between twin primes? How do we know that no other integers exist such that when they are multiplied by $6$ their products are also not between twin primes? Context: A few years ago, I asked this question hoping that someone might have some advice about tackling Diophantine equations of this sort. No such luck. Specifically, the question has to do with finding integer solutions $n, j, k \in \mathbb N^*$ to the following equation 
$$
n=6jk\pm j\pm k
$$ Since every pair of twin primes must have a multiple of $6$ between them, it is a simple matter to show that integers, $n$, of this form correspond to multiples of $6$ that don't flag a twin prime pair - i.e. $6n+1$ or $6n-1$ is not prime. The reasoning is simply that whenever a multiple of $6$ is divisible by an integer one less or one greater than some other multiple of $6$, then there is a nearby multiple of $6$ which is adjacent to a multiple of that same number one less or one greater. For instance, $30$ is divisible by $5$, so neither $24$ nor $36$ can fall between twin primes since they are adjacent to $25$ and $35$ respectively. Likewise, $210$ is a multiple of $6$ which is not between twin primes since $209=11\times 19$, and this can be determined with the formula since $210=6\times 35$, $35=33+2$, and $33$ is a multiple of $11=6\times 2 -1$. In other words, this equation acts as a sieve selecting out multiples of $6$ which definitely do not neighbor twin primes. Therefore, this line of reasoning imposes a necessary condition on any potential twin prime candidates. Is this condition not only necessary but sufficient? OEIS contributor Jon Perry seems to think that it is sufficient since he claims here that ""6n-1 and 6n+1 are twin primes iff n is not of the form 6ab +- a +- b."" The proof of the conditional is fairly straightforward (as I have already explained), but the converse is far less obvious to me. How can one prove that ""If $n$ is not of the form $6ab\pm a \pm b$, then $6n-1$ and $6n+1$ are twin primes""?","['diophantine-equations', 'number-theory', 'twin-primes', 'oeis', 'prime-numbers']"
2324347,"Representations of $S O( n )$ coming from $GL( N ,\mathbb{ R})$","I would like to show that ""the finite-dimensional spinor representation of $SO(N)$ does not arise from a finite-dimensional representation of $GL(N)$"" , as stated here and here . Apparently we should take this to mean that you can't find/embed the double cover of $SO(n)$ in $GL(n,\mathbb{R})$. (If needed, the original statement is here ). I am hoping what's done below is correct, any comments/fixes/illustrations/generalizations (even just in the comments section) would be greatly appreciated. I am not clear on the very end (posted a pic of that bit of the proof) and the generalization so comments on that would be helpful! Consider first the group of rotations $SO(2)$, 
$$\begin{bmatrix} x' \\ y' \end{bmatrix} = \begin{bmatrix} \cos(\theta) && - \sin(\theta) \\ \sin(\theta) && \cos(\theta) \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix}$$
of in the $(x,y)$ plane. We can explicitly derive the double cover by defining 
$$\begin{aligned} 
\zeta_0 &= \pm \sqrt{\frac{x-iy}{2}} \\ 
\zeta_1 &= \pm \sqrt{ \frac{-x-iy}{2} } 
\end{aligned},$$
they transform under rotations as 
$$\begin{aligned} 
\zeta_0' &= \pm \sqrt{\frac{x'-iy'}{2}} = \pm \sqrt{\frac{x \cos(\theta) - y \sin(\theta) - i x \sin(\theta) - i y \cos(\theta)}{2}} \\ 
&= \pm \sqrt{\frac{(x - i y)\cos(\theta) - i(x - iy) \sin(\theta)}{2}} = \pm  \sqrt{\frac{(x - i y)e^{-i \theta}}{2}} = e^{-i \theta/2} \zeta_0 \\ 
\zeta_1' &= \pm \sqrt{ \frac{-x'-iy'}{2} } = \pm \sqrt{ \frac{-x \cos(\theta) + y \sin(\theta) - i x \sin(\theta) - i y \cos(\theta)}{2} }  \\ 
&= \pm \sqrt{ \frac{-(x + iy) \cos(\theta) - i(x + i y)\sin(\theta) }{2} } = \pm \sqrt{ \frac{-(x + iy) e^{i \theta} }{2} } = e^{i \theta/2}\zeta_1
\end{aligned},$$
or
$$ \begin{bmatrix} \zeta_0' \\ \zeta_1' \end{bmatrix} = \begin{bmatrix} e^{-i\theta/2} && 0 \\ 0 && e^{i \theta/2} \end{bmatrix} \begin{bmatrix} \zeta_0 \\ \zeta_1 \end{bmatrix}$$ 
so that after a rotation by $2 \pi$ the signs change
$$ \begin{aligned} 
\zeta_0' &= \pm \sqrt{\frac{x'-iy'}{2}} = \pm \sqrt{\frac{e^{-i 2 \pi}(x-iy)}{2}} = \mp \sqrt{\frac{x-iy}{2}} \\ 
\zeta_1' &= \pm \sqrt{ \frac{-x'-iy'}{2} } = \mp \sqrt{ \frac{-x-iy}{2} }  \\ 
\begin{bmatrix} e^{-i\theta/2 - i \pi} && 0 \\ 0 && e^{i \theta/2 + i \pi} \end{bmatrix} &= \begin{bmatrix} - e^{-i\theta/2} && 0 \\ 0 && - e^{i \theta/2} \end{bmatrix} \end{aligned}.$$
In other words, to every $(x,y)$ there corresponds both a $(\zeta_0,\zeta_1)$ and a $(-\zeta_0,-\zeta_1)$, or  to every rotation matrix
$$\begin{bmatrix} \cos(\theta) && - \sin(\theta) \\ \sin(\theta) && \cos(\theta) \end{bmatrix}  $$
there correspond the two matrices
$$\begin{bmatrix} e^{-i\theta/2} && 0 \\ 0 && e^{i \theta/2} \end{bmatrix}, \begin{bmatrix} - e^{-i\theta/2} && 0 \\ 0 && - e^{i \theta/2} \end{bmatrix}.$$
Thus we have a 2-valued representation of the group of rotations, in the sense that one rotation $R$ in $SO(2)$ maps to two elements above. Now consider the elements of $A = \begin{bmatrix} a && b \\ c && d \end{bmatrix} \in SL(2,\mathbb{R}), \det(A) = 1$. We wish to know whether a representation of $A$ acting on a finite number of variables has the above 2-valued representation of $SO(2)$ as a sub-representation, that is, whether $SL(2,\mathbb{R})$ has multi-valued representations in the sense that $A$ in $SL(2,\mathbb{R})$ corresponds to multiple elements of a representation of $SL(2,\mathbb{R})$. If we were seeking to find multi-valued representations $\rho$ of $SL(2,\mathbb{C})$ then we would immediately see they do not exist since $SL(2,\mathbb{C})$ is simply connected. If we could find multi-valued representations of $SL(2,\mathbb{C})$ then defining a closed path $A(t)$ in $SL(2,\mathbb{C})$ we'd see $A(0) = A(1)$ while $\rho(A(0)) \neq \rho(A(1))$. On deforming the closed path down to a point, we have both $\rho(A(0)) = \rho(A(1))$ and $\rho(A(0)) \neq \rho(A(1))$ which is a contradiction. Since $SO(2)$ is not simply connected, we can't use this proof. Analyzing $A \in SL(2,\mathbb{R})$ we see $\det(A) = 1$ allowing us to view elements as rotations and so we see the closed loops in $SL(2,\mathbb{R})$ are rotations about a circle thus the fundamental group (set of equivalence classes of closed loops) is $\mathbb{Z}$. If we show the universal cover of $SL(2,\mathbb{R})$ with center $\mathbb{Z}$ is connected (in the page below) then this or it's representations cannot be used to obtain the above multi-valued representation. This shows that ""the finite-dimensional spinor representation of $SO(2)$ does not arise from a finite-dimensional representation of $GL(2)$."" For $N > 2$, I'm not sure why the above doesn't prove it by only focusing on two variables, indeed one source I read does this, but others seem to generalize it by modifying the end (e.g. the center is not $\mathbb{Z}$). Assuming the above is okay, this part is a bit unclear, the page it's taken from is below in case: It seems that the way to do this is to analyze
$$y' = \frac{ay + b}{cy + d}$$
with $\det(A) > 0$ for $y \in \mathbb{R}$, set $y' = \tan(x') , y = \tan(x)$ and then differentiate 
$$\tan(x') = \frac{ a \tan(x) + b}{c \tan(x) + d}$$
to find regions of increase/decrease, then study the $x = 0$ case and shift the parameters by $\lambda$
$$\tan(x') = \frac{b + \lambda b_0}{d + \lambda d_0}$$
from $0$ to $\infty$ then $-\infty$ to $0$ to find the same $(a,b,c,d)$ give $x + \pi$ and repeating this shows to every $x$ we get an infinite number of $x'$'s.","['spin-geometry', 'matrices', 'representation-theory', 'lie-algebras', 'lie-groups']"
2324397,Difference between Aut(V) and GL(V),"In some texts they treat them as the same but in others they seem they would not necessarily be the same. Please correct me in the following. 1) Let V be a vector space of finite dimension n on a field F (not necessarily the real numbers or complex numbers), then Aut(V) = GL(V) (not just isomorphic but equal to each other). 2) What if V has infinite dimension on a field F, is there a difference between Aut(V) and GL(V)? I had this question because for example, if A is a finite-dimensional non-associative algebra over F, the book i am reading just states Aut(A) as a subgroup of GL(A) (screenshot is attached below). They use this fact in here too. I don't think they are referring to a trivial subgroup, so I guess they are not equal to each other for some situations. If GL(V) and Aut(V) are not always the same, could you please state a generalized concept for each of those groups?
Thanks in avance!","['abstract-algebra', 'group-theory']"
2324408,Which invariant rings of finite reflection groups are also subrings of the ring of symmetric polynomials?,"The invariant rings of the finite reflection groups corresponding to root systems like $A_{n-1}$, $BC_n$ or $D_n$ are subrings of the ring of symmetric polynomials in $n$ variables. In the paper Polynomial Invariants and Harmonic Functions
Related to Exceptional Regular Polytopes by Iwasaki et al., they give generators for the corresponding invariant rings of $H_3$, $H_4$, $F_4$ and they are all (even) symmetric polynomials, so these invariant rings are also subrings of the ring of (even) symmetric polynomials. It seems that for dihedral groups the above is not true (or does this depend on the representation?). (I haven't found papers that compute basic invariants for the groups corresponding to $E_6$, $E_7$ or $E_8$ or at least is not easy for me to see if the obtained generators are symmetric) So, is that true for other irreducible finite reflection groups? Also, how would one prove it without computing a set of generators?","['finite-groups', 'invariant-theory', 'group-theory']"
2324410,Evaluating Nested Limits,"In my attempt to prove $\frac d{dx}\left(e^x\right)=e^x$, I arrived at the following step:
$$\frac d{dx}\left(e^x\right)=e^x\lim_{h\to0}\frac{e^h-1}{h}$$
At this point, I substituted in 
$$e=\lim_{n\to\infty}{\left(1+\frac 1n\right)^n}$$
to arrive at
$$\frac d{dx}\left(e^x\right)=e^x\lim_{h\to0}\frac{\lim_{n\to\infty}{\left(1+\frac 1n\right)^{nh}}-1}{h}$$
Then, I let $h=\frac 1n$ to get
$$\frac d{dx}\left(e^x\right)=e^x\lim_{h\to0}\frac{(1+h)^{h\left(\frac 1h\right)}-1}{h}$$
at which point a lot of things simplify and the limit is clearly equal to one. My question concerns the $h=\frac 1n$ step. While I see why this might be true, I don't really have a good conceptual or mathematical grasp of why this works, or whether this is even valid at all. Can the nested limit just be removed that way and $n$ replaced, or is there something else at work here?","['derivatives', 'exponential-function', 'calculus', 'limits']"
2324412,$e^{2\sqrt{2} \pi i}=(e^{2 \pi i})^{\sqrt{2}}=1$?,"This is probably stupid. But this true?$$e^{2\sqrt{2} \pi i}=(e^{2 \pi i})^{\sqrt{2}}=1$$
I feel like this is wrong but I cannot see how. Any help is appreciated. Thank you",['complex-analysis']
2324431,The set of all regular points of a smooth map is open,"Let $M$ be an smooth manifold manifold of dimension $m$ and let $N$ be a smooth manifold of dimension $n$, and let $F:M\rightarrow N$ be a smooth map. Then the set $W=\left\{ p\in M:F\mbox{ has full rank at }p\right\}$ 
  is open. Here is my attempt at the proof. Suppose without loss of generality that $m<n$. Let $\left(U,\varphi\right)$ be a chart at $p$ and let $\left(V,\psi\right)$  be a chart at $F\left(p\right)$ such that $F\left(U\right)\subseteq V$. By identifying linear maps with matrices (with respect to the standard bases for $\mathbb{R}^{n}$ and $\mathbb{R}^{m}$), the map $G:\varphi\left(U\right)\rightarrow M\left(n\times m,\mathbb{R}\right)$ defined by $x\longmapsto d\left(\psi\circ F\circ\varphi^{-1}\right)_{x}$ is continuous. For each $n\times m$ matrix $A$, let $m_A$ be the set of all invertible $m\times m$  submatrices of $A$. It is a standard result in linear algebra that $A$ has full rank if and only if $m_A$ is nonempty. The map $H:M(n\times m,\mathbb{R})\rightarrow\mathbb{R}$ defined 
  by $A\longmapsto\sum_{S\in m_{A}}\left|\mbox{det}S\right|$ is continuous. It follows that the composition $H\circ G\circ\varphi$ is continuous. Hence, $\left(H\circ G\circ\varphi\right)^{-1}\left(\mathbb{R}-\left\{ 0\right\} \right)$ is an open subset of $U$. Taking the union of all such sets will result in $W$. Therefore $W$ is open. Is it correct?","['smooth-manifolds', 'linear-algebra']"
2324433,What is the purpose of a function being surjective?,"So as far as I understand, a function $f\colon A \to B$ is surjective if and only if for every $b\in B$ there exists $a\in A$ such that $f(a) = b$. My question is when is this actually relevant? Couldn't you arbitrarily define the set $B$ so that any elements never ""used"" are removed from the set, leaving you with a surjective function?","['elementary-set-theory', 'functions']"
2324467,Solving equation of type $a\cos x+b\cos y-c=0$ and $a\sin x+b\sin y-d=0$,"Here's the questions
There are two equations:
$a\cos x+b\cos y-c=0 $ and $ a\sin x+b\sin y-d=0$ .
For instance 
What is the value of $x$ and $y$ in following question?
$$2\cos x+3\cos y-2=0$$
$$2\sin x+3\sin y-8=0$$","['trigonometry', 'systems-of-equations']"
2324498,Finding the ratio of cosines of a triangle given the ratio of sines,"The ratio of sines of the angles in a triangle is $5:6:7$. Find the ratio of cosines of this triangle in its simplest form. This question was asked in a recent trigonometry test, and many had no idea how to answer it. Our class has only covered basic trigonometry up to sums or differences as products. How would someone approach and answer this question? Some approaches I've brainstormed are: 1)Using sine=opposite/hypotenuse and cosine=adjacent/hypotenuse (I would have no clue how to continue this) 2)Find an equation involving the ratios and sine and use $\cos\theta= \sin(90 - \theta)$ (angles are in degree units) 3)Find an equation from the sine rule and substitute the cosine rule (?) Sorry, I don't know how to format this properly!","['ratio', 'trigonometry']"
2324499,Suppose $R$ is a relation on $X$. What does it mean if $R$ is both a partial order and an equivalence?,"Suppose $R$ is a relation on $X$. What does it mean if $R$ is both a partial order and an equivalence? I couldn't think of anything else other than $\emptyset$, is this correct?","['relations', 'equivalence-relations', 'elementary-set-theory']"
2324511,Proof that eigenvalue of matrix product smaller than 1,"Suppose that we are given an $M\times N$ complex matrix 
$\mathbf{A}$ and an $N\times N$ real diagonal matrix $\mathbf{D}$ with non-negative entries on the diagonal. Through numerical simulations, I found that the eigenvalues of $\mathbf{B}$, which is defined as $$\mathbf{B}=\mathbf{A}(\mathbf{A}^{\mathrm{H}}\mathbf{A} + \mathbf{D})^{-1}\mathbf{A}^{\mathrm{H}},$$ are no larger than $1$, where $(\cdot)^\mathrm{H}$ denotes matrix conjugate transpose. How can I prove that such an observation holds theoretically? Or is there any counter-example to show that this observation does not always hold? I notice that $\mathbf{A}(\mathbf{A}^{\mathrm{H}}\mathbf{A} + \mathbf{D})^{-1}\mathbf{A}^{\mathrm{H}}$ shares the same non-zero eigenvalues as 
$(\mathbf{A}^{\mathrm{H}}\mathbf{A} + \mathbf{D})^{-1}\mathbf{A}^{\mathrm{H}}\mathbf{A}$. This motivates me to consider if I could approach this proof through an upper bound for the largest eigenvalue of matrix product, i.e., the product of $(\mathbf{A}^{\mathrm{H}}\mathbf{A} + \mathbf{D})^{-1}$ and $\mathbf{A}^{\mathrm{H}}\mathbf{A}$. However, so far I have gone nowhere. Any suggestion would be greatly appreciated.","['eigenvalues-eigenvectors', 'linear-algebra']"
2324522,Quotient map is continuous,"In the above proof, I do not get how the union of equivalence classes in $U$ is open in $X$. Can someone explain this to me? Thank you","['general-topology', 'quotient-spaces']"
2324551,"Show that $(2,0,4) , (4,1,-1) , (6,7,7)$ form a right triangle","What I tried: Let $A(2,0,4)$, $B(4,1,-1)$, $C(6,7,7)$ then $$\vec{AB}=(2,1,-5), \vec{AC}=(4,7,3), \vec{BC}=(2,6,8)$$ Then I calculated the angle between vectors: $$\begin{aligned}
\alpha_1 &= \cos^{-1}\left(\frac{(2,1,-5)(4,7,3)}{\sqrt{2^2+1^2+(-5)^2}\sqrt{4^2+7^2+3^2}}\right) \\
&= \cos^{-1}(0)=90° \\
\alpha_2 &= \cos^{-1}\left(\frac{(4,7,3)(2,6,8)}{\sqrt{4^2+7^2+3^2}\sqrt{2^2+6^2+8^2}}\right) \\
&= \cos^{-1}\left(\frac{74}{\sqrt{74}\sqrt{104}}\right)=32.49\\
\alpha_3 &= \cos^{-1}\left(\frac{(2,6,8)(2,1,-5)}{\sqrt{2^2+6^2+8^2}\sqrt{2^2+1^2+(-5)^2}}\right) \\
&= \cos^{-1}\left(\frac{-30}{\sqrt{104}\sqrt{30}}\right)=122.5°
\end {aligned}$$ As you can see, these angles don't even form a triangle, what am I doing wrong, any thoughts?","['proof-verification', 'analytic-geometry', 'inner-products', 'geometry', 'vectors']"
2324596,Why does the fundamental theorem of calculus imply $\frac{dy}{dx}=f(x)\iff y(x)=\int f(x)dx+C$,"I understand that as a consequence of the fundamental theorem of calculus it is true that $$\frac{d}{dx}\int_a^x f(t)dt=f(x)$$ Reading an intro ODE text the very first chapter says that $$\frac{dy}{dx}=f(x)\implies y(x)=\int f(x)dx+C$$ by integrating on both sides. I assume this is a consequence of the FTC, but I don't quiet see it. If I integrate on both sides I get $$\frac{dy}{dx}=f(x)\implies \int \frac{d}{dx}y(x)dx=\int f(x)dx$$ at this point to apply the FTC I have to make an assumption about the interchangeability of the integral and derivative operators, which hopefully only requires $\frac{d}{dx}y(x)$ to be integrable, I am not sure but willing to overlook that part for now.  So I have $$ \frac{d}{dx} \int y(x)dx=\int f(x)dx$$ But to be able to actually claim that the integral and the derivative cancel, I need to make the integral definite: $$ y(x)=\frac{d}{dx} \int_a^x y(t)dt=\int_a^x f(x)dx$$ At this point for the text to make sense, I'm guessing it is implicitly assumed when I see indefinite integrals in PDE/ODE textbooks that all statements about them are meant to hold true for any arbitrary interval in the domain, which can be represented by $[a,x]$. Is that reasonable? Am I missing something obvious? Thanks","['multivariable-calculus', 'ordinary-differential-equations', 'calculus']"
2324622,PMF of Matching Problem Hats,"This is a variation of a famous problem, that I have heard before but I have never seen it in this format before. $N$ Guests arrive at a party, each wearing a hat. We collect all the hats and then randomly redistribute the hats, giving each person one of the $N$ has randomly. Letting $X_N$ be the number of hats that are matched correctly, what is the $PMF$ of $X_N$? I.e. 
  $P(X_N=k)=$ The common variations of this problem that I have seen usually involve the probability that no one gets the correct hat or as $N$ approaches $\infty$. I am struggling to identify a distribution that would result in any type of general formula for $PMF$ of this random variable. Has anyone seen this before?","['probability', 'density-function', 'discrete-mathematics']"
2324685,Prove $\cos6x=32\cos^{6}x-48\cos^{4}x+18\cos^{2}x-1 $,So far I've done this: LHS $ =\cos^{2}3x-\sin^{2}3x$ $={(4\cos^{3}x-3\cos{x})}^2 -{(3\sin{x}-4\sin^{3}x)}^2$ $=16\cos^{6}x+9\cos^{2}x-24\cos^{4}x-9\sin^{2}x-16\sin^{6}x+24\sin^{4}x$ I can tell I'm going in the right direction but how should I proceed further? EDIT I used the identity $\cos{2x}=2\cos^{2}x-1$ to solve it in a simpler way. viz. LHS $= 2\cos^{2}3x-1$ $=2{(4\cos^{3}x-3\cos{x})}^2-1$ $2(16\cos^{6}x+9\cos^{2}x-24\cos^{4}x)-1$ $=32\cos^{6}x+18\cos^{2}x-48\cos^{4}x-1$ Still thank you for the answers!,['trigonometry']
2324692,Dual Group of $\Bbb{R}$,"The Dual Group of $\mathbb{R}$ is isomorphic to $\Bbb{R}$ itself in the following way:
The map
$$\Bbb{R} \to \hat{\Bbb{R}}, \quad y \mapsto \exp(ixy) $$
is an isomorphism. Further it is stated in the literature that this map is also an homeomorphism. See for exmaple Conway, A course in functional analysis Theorem 9.11. I am trying to prove this result. While proving the continuity is straightforward, i am stuck proving that the inverse is continous. One should note that $ \Bbb{R}$ is equipped with the standard topology and $\hat{\Bbb{R}}$ with the topology induced by compact convergence. That means a function converges iff it converges unfirom on every compact subset. I tried some ways, none of wich was promising. I am grateful for any hint on how to do this. Edit 2: I have found a proof based on non trivial results as seen below. However i am still interested if this can be proven more direct without the help of said results. Edit 1:
The proof that the map is bijective is often done in the following way: One shows that $\gamma \in \hat{\Bbb{R}}$ fullfills this differential equation:
$$ \left\{ \begin{array}{cl}
	\gamma'(x) &= \gamma'(0) \gamma(x) \\
	\gamma(0) &= 1\\
	\end{array}\right. $$
with the condition $| \gamma(x)| = 1 $ for all $x \in \Bbb{R}$.
Then it is clear that $\gamma(x)  = \exp(x\gamma'(0))$ and we now that $y = -  i\gamma'(0)$ in $\gamma(x) = \exp(ixy)$. If one could show that the map 
$\hat{\mathbb{R}}  \to \Bbb{R}, \; \gamma \mapsto \gamma'(0) $ is continous this would prove the continouity of the inverse. Comments and ideas considering this approach are greatly appreciated.","['group-theory', 'duality-theorems']"
2324718,Intuition behind method for finding the inverse of a function,"To find the inverse of a function, you switch the spots of $x$ and $y$ in the function and solve for the new $y$ output. For example: $y = 3 + \sin\ x$ Switch positions of $x$ and $y$ $x = 3 + \sin\ y$ Solve for this new $y$ $y = \sin^{-1}(x-3)$ However, I've never wondered why this is the case. Does anyone have an explanation as to where this method came about? In addition, how would one find the inverse of a function with 3 variables $x$, $y$, and $z$?","['inverse-function', 'functions', 'inverse']"
2324739,An intuitive way we can see that $(1+1/n)^n$ is increasing,"It can be proved that $(1+1/n)^n$ is increasing $n\in \mathbb{N}$. Now look at the picture given below, the dark $>$ signs are actually ""greater"" sign, and you can check that those inequality holds perfectly! Now take a look at at the rectangle(there those arrows are vectors). Let us define vectors on $\vec{AB}$, if the value in $A$ is greater than the value in $B$. We denote $A_{ij} =(1+1/i)^j$. $""+"" \text{and}\space ""=""$ defined as follows: $\vec{AB}+\vec{BC}=\vec{AC}$ is value of $A>$ value in $B>$ value in $C$, implies value of $A>$ value in $C$. Consequently we also have $A_{nn}<A_{(n+1)(n+1)}$. This completes the whole thing. (ignore the word ""Consequently"") On the other way we can also say that to preserve the system $A_{nn}<A_{(n+1)(n+1)}$ has to happen. Which one is true??","['intuition', 'calculus', 'soft-question', 'sequences-and-series', 'vectors']"
2324764,Notation for element-wise function application,"Is there some kind of specific notation I could use to specify that function $f$ is applied to each element of matrix $W$ and not to a matrix as a whole. Specifically, I am writing about applying activation function for a layer of neural network. Or just writing this is clear enough: $f(W)$?","['matrices', 'notation', 'functions']"
2324786,Morera Theorem And Cauchy's Integral Theorem,"Cauchy's Integral Theorem says that if a function is analytic in open and simply connected domain and $\gamma$ is a closed curve so: $$\int_\gamma f(z) \, dz=0$$ Morera Theorem says that if a function is continuous on an open domain such that for every closed curve $$\int_\gamma f(z) \, dz=0$$ So: the function is analytic So those both theorem are two different directions of iff statement?",['complex-analysis']
2324847,How to derive the Rotation Matrix from the Euler Formula,"I'm trying to understand how the two dimensional rotation matrix (i.e. $R \in \mathbb{R}^2$) can be derived from the Euler Formula ($e^{i\theta} = \cos \theta + i \sin \theta$). $R$ is given as: $$
R(\theta) =
\begin{bmatrix}
  \cos\theta & -\sin\theta\\
  \sin\theta & \cos\theta
 \end{bmatrix}
$$ $$
\begin{bmatrix}
  x' \\
  y'
 \end{bmatrix} =
\begin{bmatrix}
  \cos\theta & -\sin\theta\\
  \sin\theta & \cos\theta
 \end{bmatrix}
\begin{bmatrix}
  x \\
  y
 \end{bmatrix}
$$
$$
  x' = x \cos \theta - y \sin \theta 
$$
$$
  y' = x \sin \theta + y \cos \theta
$$ My questions are: Why can be $i$ omitted from the rotation matrix? (I tried to look for explanations 1 , 2 but none of these explanations goes beyond that  $i$ is omitted) Why can we derive a rotation matrix for $\mathbb{R}^2$ from a form that is defined in $\mathbb{C}^2$? How comes we don't get complex numbers as a result after some rotations?","['matrices', 'rotations']"
2324857,Discuss the monotonicity of the following function without using differentiation.,Can I discuss the monotonicity of the following function without using differentiation? $$f(x) = x + \frac{9}{x}$$ Could anyone help me?,"['derivatives', 'calculus']"
2324890,Why are this function's second partial derivatives not continuous?,"so we know that for a function's mixed partial derivatives to be symmetrical we need their second partial derivatives to be continuous. In this example
f(x,y) =
  \begin{array}{l l}
    \dfrac{xy(x^2-y^2)}{x^2+y^2} & \quad \text{for $(x,y) \neq (0,0)$}\\
    0 & \quad \text{for $(x,y)=(0,0)$}
  \end{array}
they $Fxy$ and $Fyx$ are not the same in $(0,0)$, but I'm not so sure how to prove their second derivatives are not continous in that point, how would I go about it?",['multivariable-calculus']
2324939,Forced conjugation of elements in finite groups,"The dihedral group
$$
D_8 = \langle\ a,\ b \ \mid \ a^4,\ b^2,\ (ab)^2\ \rangle
$$
has a central involution $c=a^2$ and a non-central one, $b$. Q. Can we embed $D_8$ into a finite group $G$ in which $c$ and $b$ become conjugate?","['finite-groups', 'group-theory']"
2324964,Shooting Game for Fun,"Trigger Warning: Murder is mentioned. Let there be $n>1$ people (players) on a plane, each having a loaded gun and each being a perfect shot (assuming that each bullet is laced with one gram of plutonium-239 to ensure that hit targets do not survive and that the bullets are not penetrative enough to hit multiple bodies).  Suppose that the distances between the players are pairwise distinct.  At a signal, each player shoots the player closest to him (all the actions occur simultaneously).  For those who have studied relativity, I assume that all players are initially at rest with respect to a fixed inertial frame so that it makes sense to discuss the simultaneity of the actions. What is the minimum possible number of survivors?  What is the maximum possible number of survivors?  Do the answers change in higher dimensions (or even in other geodesic spaces like the $d$-dimensional torus)? Below are my speculations. The minimum is $n\!\!\mod\!2$ (this part is trivial and independent of the geometry of the space). I think the maximum for $n\geq 5$ is $n-\left(2q+s_r\right)$, if $n=10q+r$, where $q$ and $r$ are integers such that $0\leq r<10$, with $s_0=0$, $s_1=s_2=s_3=s_4=1$, and $s_5=s_6=s_7=s_8=s_9=2$. The case $n=10q+5$ seems to be the most difficult case for me. I found a mistake in my original bound, and now the new bound is worse.  At the moment, the best bound is that at least $n-2q-s_r$ can survive, where $n=9q+r$ with $q,r\in\mathbb{Z}$ such that $0\leq r<9$, and $s_0=0$, $s_1=s_2=1$, and $s_3=s_4=s_5=s_6=s_7=s_8=2$. Since a $d$-dimensional Euclidean space can be locally embedded into a $d$-dimensional geodesic space, I don't expect the answers to change (for a given dimension $d$) if the space is not Euclidean.  However, the dimension should play a huge role in this shooting game. EDIT I: After some more thought, I realized the answers may indeed be different in the non-Euclidean case.  For example, a player cannot be shot by more than five bullets in the $2$-dimensional Euclidean case, but in a $2$-dimensional hyperbolic space, it seems to be possible that somebody is gunned down by at least six players. EDIT II: In the $3$-dimensional Euclidean case, I expect the maximum number of survivors to be around $\frac{10}{11}n$.  In the $d$-dimensional Euclidean space, this number should be around $\frac{L_d-2}{L_d-1}n$, where $L_d$ is the Kissing number in $d$ dimension.","['graph-theory', 'combinatorial-geometry', 'euclidean-geometry', 'geometry', 'combinatorics']"
2324996,A curious integral,"The following integral has been on my mind for a while
$$\int_0^\infty \frac{\sin(x)}{e^x-1}\,\mathrm d x \tag{$\dagger$}$$ Let us indicate the integrand as $f(x)=\frac{\sin(x)}{e^x-1}$. The following are a couple of observations. The integrand can be extended by continuity in $0$ since
$$\lim_{x\to 0}f(x)=\lim_{x\to 0}\frac{\frac{\sin(x)}{x}}{\frac{e^x-1}{x}}=1$$
This is the original reason I started playing around with this integral. Mathematica yields the result
$$\int_0^\infty \frac{\sin(x)}{e^x-1}\,\mathrm d x=\frac{\pi}{2}\textrm{Coth}(\pi)-\frac 12 \approx 1.076674047$$
which, following numerical evidence, seems correct. Complex analysis may be useful here, since the integrand is a holomorphic function on $\mathbb C$. I tried writing $\sin(z)=\frac{e^{iz}-e^{-iz}}{2i}$, but I was not able to find an appropriate integration contour to solve the problem. The $-1$ in the denominator breaks the simmetry of the expression. This made most of my substitutions useless. Can this integral be evaluated correctly, preferrably through complex analytic methods?","['complex-analysis', 'improper-integrals']"
2325007,"Is $f$ identically zero on $[0, 1]$?","Let $f$ be a continuous real-valued function on $[0,1]$ such that there is $K>0$ for which $|f(x)|\le K \int_0^x|f(t)|dt$ for all $x\in [0,1]$. Does it follow that $f=0$ on $[0,1]$? What I know is just $f(0)=0.$","['real-analysis', 'integration', 'analysis']"
2325017,An Idea of Associative Cartesian Product,"Let $A,B$ be two nonempty sets, then the Cartesian product of $A$ and $B$ is defined as $$A\times B:=\left\{(x,y)|\ x\in A,\ y\in B\right\}$$
Here  $(x,y):=\left\{x,\left\{x,y\right\}\right\}.$ And $(x,y,z):=((x,y),z),\ A\times B\times C:=(A\times B)\times C,$ etc. In general, there is $$((x,y),z)\neq (x,(y,z)),$$and$$(A\times B)\times C \neq A\times(B\times C).$$
So Cartesian product is not associative.
I've come up with an idea of defining an ""associative Cartesian product"". Definition: Let $A$ be a nonempty set. Then $\forall\ m,n\in \mathbb{N},\ \forall\ x=(x_1,\cdots,x_m)\in A^m,\ y=(y_1,\cdots,y_n)\in A^n, $ we define 
  $$x\circledast_A y:=(x_1,x_2,\cdots,x_m,y_1,y_2,\cdots,y_n)\in A^{m+n}.$$
  And $\forall C\subset A^m,\ D\subset A^n,$ we define that
  $$C\otimes_A D:=\left\{x\circledast_A y | \ x\in C,\ y\in D \right\}$$ I call the operation $\otimes_A$ ""associative Cartesian product"", because if my definition is well-defined, then we have $(C\otimes_A D)\otimes_A E=C\otimes_A (D\otimes_A E)$ for any set $C,D,E\subset A.$ And particularly, we have $\mathbb{R}^m\otimes_{\mathbb{R}} \mathbb{R}^n=\mathbb{R}^{m+n},\ $and $ (x,y)\circledast_{\mathbb{R}} z =x\circledast_{\mathbb{R}} (y,z),$ for any $x,y,z\in \mathbb{R}. $ Question : Is my definition above (in the yellow square frame) well-defined and proper ?",['elementary-set-theory']
2325035,Poisson-processes and it's arrival times,"I am currently studying for my non-life insurance exam and have the following problem: Let $S(t) = \sum_{i=1}^{N(t)} (X_i + T_i)^2$, where $X_i$ are i.i.d. r.v. with density $f(x)$ and $T_i$ are the arrival times of the homogeneous possion process $N(t)$ with intensity $\lambda =2$. With a fiven density $f(x) = \exp(-x)$ for $x \geq 0$, how can one calculate $E[S(t)]$? Now I know that $P(T_1 > t) = \exp(-\int_0^t \lambda(s) ds) = \exp(-2t)$. So the density would be given by $g_1(t) = 2\exp(-2t) $. Furthermore I could write the following: $$ S(t) = \sum_{i=1}^{N(t)} (X_i + T_i)^2 = \sum_{i=1}^{N(t)} X_i^2 + 2\sum_{i=1}^{N(t)} X_i T_i + \sum_{i=1}^{N(t)}T_i^2 $$ If I would have only $\sum_{i=1}^{N(t)} X_i^2$ I'd know that $$ E[S(t)] = E[S(t) \mid N(t)] = E[N(t)]E[X_i^2] $$ How can I proceed with the arrival times?","['stochastic-processes', 'expectation', 'probability-theory', 'poisson-process', 'probability']"
2325055,Laurent Expansion - Complex Analysis question,"Exercise : Find the Laurent Expansion of the function : $$f(z) = \frac{1}{(z-2i)(z^2 +4)}$$ around $z_0 = -2i$, in the biggest possible ring that includes the point $z=-2 + 2i$. Attempt : We have : $$f(z) = \frac{1}{(z-2i)(z^2 +4)} = \frac{1}{(z-2i)(z + 2i)(z-2i)} = \frac{1}{(z-2i)^2(z + 2i)} $$ We have the rings : $$D_1 : 0<|z+2i|<4$$ $$D_2 : |z+2i|>4$$ Because $|(-2+2i) + 2i| = |-2 + 4i| = \sqrt{20} > 4$, the biggest ring with center $z_0=-2i$ that contains the point $z=-2+2i$, is : $$D_2 : |z+2i|>4$$ Now, such exercises can be handled by creating such a fraction, such as to use the usual geometric series : $$\frac{1}{1-w} = \sum_{n=0}^{\infty}w^n ,|w|<1$$ $$\frac{1}{1+w} = \sum_{n=0}^{\infty}(-1)^nw^n,|w|<1$$ It is : $$f(z) = \frac{1}{(z-2i)^2(z + 2i)} = \frac{1}{(z-2i)^2[(z - 2i)+4i]} = \frac{1}{(z-2i)^2(z - 2i)\big(1-\frac{4i}{z-2i}\big)} = \frac{1}{(z-2i)^3\big(1-\frac{4i}{z-2i}\big)}  $$ But in order to have $|w|<1 $ it must hold that : $|z-2i| > 4$, but our ring is $|z+2i|>4$. My question is : Is the exercise wrong ? Maybe it means around the center $z_0 = 2i$ ? Or is it something that I am doing wrong ? If nothing is wrong, how do I proceed here ? Except if I use : $$\frac{1}{(z-2i)^2(z + 2i)} = \frac{1}{(z+2i)^3\big(1-\frac{4i}{z+2i}\big)^2} = \frac{1}{(z+2i)^3}\frac{1}{ \big(1-\frac{4i}{z+2i}\big)^2} = \frac{1}{(z+2i)^3} \Bigg( \sum_{n=0}^{\infty} \bigg(\frac{4i}{z+2i}\bigg)^n\Bigg)^2 $$ because if so, it is $|z+2i|>4$. I would really appreciate some thorough help.","['taylor-expansion', 'calculus', 'laurent-series', 'complex-analysis', 'sequences-and-series']"
2325070,Finding derivatives value at $x=0$,"So i have function: $$f(x)=x^{10} \ln(x+1)$$ And i need to find what value its 2016th derivative has at $x=0$. So first I got its Taylor expansion around $x=0$ It's like this: $$f(x)= x^{10} \sum_{n=0}^{\infty} \frac{(-1)^{n+1}x^n}{n}$$ So  now is it enough to just look at the 2016th coefficient which is $-\frac{1}{2016}$ since its derivative at $x=0$? Perhaps I understand it wrongly, but want to check it somehow. Thank you in advance for any help I may get.","['derivatives', 'taylor-expansion', 'calculus']"
2325074,Isometry between circles,"Let $C_{1}$ and $C_{2}$ be two circles, respectively with radius $1$ and $2$ endowed with the riemannian metric induced by the euclidean metric. I need to show that they are not isometric. This seems simple but I cannot get a proof. Here is what I have tried. I work with a generic circle $C_{r}$ of radius $r>0$ . First, we have the local coordinate $\theta$ on the circle such that, locally: $$\phi(\theta)=(r\cos(\theta),r\sin(\theta)),\quad \theta\in[0,2\pi)$$ Denote by $g_{0}=(dx)^{2}+(dy)^{2}$ the euclidean metric on $\mathbb{R}^{2}$ . The induced metric is given by $$\phi^{\ast}g_{0}=r^{2}(d\theta)^{2}$$ If $\gamma:I\to M$ is a differentiable curve (in the sequel, a curve) from an interval $I\subset\mathbb{R}$ to a riemannian manifold $M,g$ , the length of $\gamma$ is defined as $$\ell(\gamma)=\int_{I}\sqrt{g(\dot\gamma(t),\dot\gamma(t))}$$ The distance between two points $x,y\in M$ relatively to the metric $g$ is defined as $$d_{g}(x,y) = \inf\{\ell(\gamma)\mid\gamma:[0,1]\to M,\gamma\text{ is a curve},\gamma(0)=x,\gamma(1)=y\}$$ It is easy to see that if $$i:M,g\to N,h$$ is an isometry (i.e. a diffeomorphism such that $i^{\ast}h=g$ ), then for any curve $\gamma:I\to M$ we have $$\ell(\gamma)=\ell(i\circ\gamma).$$ Hence, we have $$d_{g}(x,y) = d_{h}(i(x),i(y))$$ Therefore, let $$\gamma:[0,1]\to C_{r}:t\mapsto \gamma(t) = (r\cos(s(t)),r\sin(s(t)))$$ A quick computation shows that $$\ell(\gamma)=r\int_{0}^{1}\vert \dot s(t)\vert_{1} dt$$ where $\vert v\vert_{k}$ denotes the euclidean norm of $v\in\mathbb{R}^{k}$ . As we want to prove that $C^{1}$ and $C^{2}$ are not isometric, we need to show that there exists no isometry $i:C^{1}\to C^{2}$ . If we suppose there exists such an isometry, we must have $$\ell(\gamma)=\ell(i\circ \gamma)$$ for any curve $\gamma:[0,1]\to C_{1}$ . But I am stuck. How to conclude from this?","['curves', 'riemannian-geometry', 'differential-geometry', 'geodesic']"
2325093,Can I break this limit into individual terms?,$$\lim_{x\to \infty}  {\frac{x}{x^2+1} +\frac{x}{x^2+2} + ... + \frac{x}{x^2+x} }$$ It seems obvious that the result is zero for each term but in order to break the limit into its individual  parts we must know that every term's limit exists .,['limits']
2325095,Going Through Yellows,"I have observed that I am almost never the last car through a traffic light. Sometimes I stop (because it is yellow or red), in which case, of course, the car behind me also stops and the car in front of me proves the last car through. And sometimes I go (because it is green or yellow), in which case, usually, the car behind me follows me through. I long felt that this showed that I am more likely (than other people) to stop at a light; I am relatively cautious. Otherwise, why should I rarely be last through? But this conclusion came with a guilty conscience. Because it seemed obvious that I couldn’t know, from my own experience alone, whether other drivers felt the same way about themselves, apparently making me typical after all. I’m re-thinking that guilt, and this is to ask your help. On the one hand, if I observe that I’m late to work 5% of the time, this gives me no information about whether I’m late to work more often that the average person or less often. For that conclusion, I would need to gather data about other people. But on the other hand, suppose that I observe that in the last 50 cases in which I reached a yellow light, in 40 cases I stopped, in 9 cases I went through followed by another car, and in 1 case I went through alone. I see that I have stopped in (40/50)=80% of the cases while the fellow behind me stopped in only (1/10)=10% of cases. (I think that I'm here ignoring the fact that the driver behind me is reaching this yellow light later than I did, increasing his probability of stopping. Should I?) Is there some sort of problem of independence here, such that the people behind me when I go through do not represent all drivers? I realize that if the numbers 9 and 1 were switched -- so that I stopped in (40/50)=80% of cases, I went through alone in 9 cases, and I went through followed by a car in 1 case -- we could not make the opposite inference that I am relatively reckless – could we? Because of the complicated problem of dealing with instances in which I go but there is simply no car behind me, stopping or proceeding? Or for some other reason? Is there some standard nomenclature for the issue I'm raising, distinguishing the late-to-work analysis from the traffic-light analysis?","['probability', 'statistical-inference']"
2325126,Two definitions for derivative,"This may be a very stupid question and could be blatantly obvious, but I want to clear the confusion that I have about it. There are two equivalent definitions of the derivative: Let $g: A \rightarrow \mathbf{R}$ be a function defined on an interval
   $A$. Given $c \in A$, the derivative of $g$ at $c$ is defined by
   $$g'(c) = \lim_{x \rightarrow c} \frac{g(x) - g(c)}{x-c}$$ provided
   this limit exists. and Let $g: A \rightarrow \mathbf{R}$ be a function defined on an interval
   $A$. Given $c \in A$, the derivative of $g$ at $c$ is defined by
   $$g'(c) = \lim_{h \rightarrow 0} \frac{g(c+h) - g(c)}{h}$$ provided
   this limit exists. My question is, what's the formal reasoning why these two definitions are equivalent? For example, are we using the Algebraic Limit Theorem for functional limits? It is very clear to me ""intuitively"" why they are equivalently, i.e., simply let $x = c+h$ and one can see that in the first definition, as $x$ tends towards $c$ we ""get"" the expression $\frac{g(c)-g(c)}{c-c}$ while for the second definition, as $h$ tends towards $0$ we ""get"" the same expression $\frac{g(c)-g(c)}{c-c}$. But such reasoning is certainly not very rigorous and is very primitive, I wish to know why they are equivalent using formally justified reasons for each step in the process. For example, why can one substitute $x = c+h$ into the first definition and why after the substitution does the limiting variable change from $x$ to $h$? EDIT: To be more precise, let $\phi(x)=\frac{g(x)-g(c)}{x-c}$ and let $\gamma(h) = \frac{g(c+h)-g(c)}{h}$, how can I prove that $\lim_{x \rightarrow c} \phi(x) = \lim_{h \rightarrow 0} \gamma(h)$ with the substitution $x = c+h$?","['derivatives', 'real-analysis', 'definition', 'limits']"
2325138,Is $|x| \cdot |x| = |x^2| = x^2$?,"Is $|x| \cdot |x| = |x^2| = x^2$ ? I'm very sorry if this question is a duplicate but I couldn't find anything about it (most likely because it's wrong..). But I'm not sure if this is correct so I need to ask you. $$|x| \cdot |x| = |x^2| \text{ should be alright}$$ Now my confusion starts. $x^2$ should be positive / neutral for any value. That would mean we can ignore the absolute value sign? On the other hand we could have that $|-x^2|$. But that would be a different thing than $|x^2|$, they are not equal to each other...? Please help me if I do this little thing wrong the entire task will be wrong. I got some thinking error here.. When there is the same question (I couldn't find one), please link me to it and I will delete this one immediately.","['algebra-precalculus', 'absolute-value']"
2325179,geodesic flow and the vector field on $TM$,"I'm trying to understand what my teacher wrote. We build a vector field $\cal{X}$ on $TM$ for which the flow, called geodesic flow , consists in the curves $(\gamma(t),\dot{\gamma}(t))$ where $\gamma$ is a geodesic $${\cal{X}}_X=(X^1,\cdots,X^n,-\Gamma^1_{ij}X^iX^j,\cdots,-\Gamma^n_{ij}X^iX^j)$$ Then $$\frac{d\gamma^k}{dt} = X^k\\ \frac{dX^k}{dt} = -\Gamma^k_{ij}X^iX^j$$
  is the system of equations of the flow of $\cal{X}$. Why is that system the set of equations defining the flow of $\cal{X}$? it is clear that the curves $(\gamma(t),\dot{\gamma}(t))$, with $\gamma$ a geodesic, satisfy the equations but how do we know that no other curve on $TM$ satisfies these equations","['riemannian-geometry', 'differential-geometry', 'geodesic']"
2325203,$u$-substitution always evaluates to $0$,"Consider the integral $$ \int_a^b f(x) \,dx $$ now make the $u$-substitution $u \mapsto c + (x-a)(x-b)$. The resulting integral is $$ \int_c^c h(u) \,du $$ where $h(u)$ is the integrand $f$ after the substitution, however, regardless of $f$ the integral $\int_c^c du = 0$. Looking at the definition Wikipedia provides I believe the substitution meets every condition. It's differentiable and has a integrable derivative, because it's a polynomial. So what's wrong with this substitution such that it always results in $0$?","['substitution', 'integration', 'calculus']"
2325215,The diagonal is not contained in $\mathscr A\times \mathscr A$,"This is a prelim problem I ran across: suppose $(X,\mathscr A)$ is a measurable space, and $|X|>\mathfrak{c}.$ Then, $D=\left \{ (x,x):x\in X \right \}\not \in \mathscr A\times \mathscr A.$ Here is a rough sketch of my approach, which I would like to make rigorous: First note that if we take the collection $\mathscr C$ of subsets of $D$, that have the form $A\times A:A\in \mathscr A$, then, there is a sequence $\left \{ A_n\times A_n \right \}$ such that $D\in \sigma (\left \{ A_n\times A_n \right \}).$ This follows by considering the union $\mathscr B$ of the sigma algebras generated by the collection of countable families from $\mathscr C$ and showing that $\mathscr B$ is a sigma algebra that satisfies $\mathscr C\subseteq \mathscr B\subseteq \sigma (\mathscr C).$ The idea now is to get a contradiction by injecting $D$ into $\left \{ 0,1 \right \}^{\mathbb N}.\ $ So, define a map $(x,x)\mapsto \left \{ \chi_{A_n}(x) \right \}_n\ $ and suppose that $x$ and $x'$ both belong to exactly the same $A_n.$  I want to conclude from this that the sections $D_x$ and $D_{x'}$ are the same, which would in turn imply that the map is injective. Is my approach workable? If so, can you provide hints on how to make it rigorous?","['real-analysis', 'set-theory', 'measure-theory']"
2325248,Find the point of intersection between a line segment $AC$ and a perpendicular line going through a point $B$ not on $AC$,"I've asked this question first on Stack Overflow ( How to find position in pixels of intersection of two lines? ) but it's actually a math question so I'm asking it here and I'll delete the SO one. I have $3$ points $A$, $B$ and $C$ and I need to calculate point $D$ in the picture above, so I can draw that shorter line segment. We should have $AC\perp BD$. It should be simple  (high school difficulty), but I don't know how to solve it. Do I need to calculate the line equations that go through two point and then perpendicular line equation that go through a point and then intersection of two lines, or is there easiest way? It seems that when the ratio is $4:3$ the point is in golden point but if ratio is different the point is in other place.","['euclidean-geometry', 'geometry']"
2325252,What can be said about the sequence $(\left\Vert A^{n}\left( x\right) \right\Vert ^{\frac{1}{n}})_{n}$,"Let $H$ be a separable infinite dimensional Hilbert space and let $A\in B(H)$ be a bounded operator.
For any $x\in H$ is $(\left\Vert A^{n}\left( x\right) \right\Vert ^{\frac{1}{n}})_{n}$ a decreasing and/or a convergent sequence ?
Recall that $\lim \left\Vert A^{n} \right\Vert ^{\frac{1}{n}}$ is the spectral radius of $A$.","['operator-theory', 'calculus', 'linear-transformations', 'spectral-theory', 'linear-algebra']"
2325322,What is this function for this graph?,Trying to find a function like this: 2 y-axis asymptotes: -1 / 1 x values range from -infinity to infinity.,['functions']
2325323,$\sum_{k=0}^{3^n-1}\binom{2k}{k}$ is divisible by $3^n$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Prove that the sum $$\sum_{k=0}^{3^n-1}\binom{2k}{k}$$ is divisible by $3^n$.
 Use by Vandermonde's Identity. So
$$\binom{2k}{k}
=\sum_{j=0}^{k}\binom{k}{j}^2 $$. Any hints or solutions are greatly appreciated.","['combinatorics', 'elementary-number-theory']"
2325377,"Looking for series that suits 1,1,-1,-1,1,1,-1,-1 ..","I'm looking for a series that will give me 1,1,-1,-1,1,1,-1,-1 ...... The best I came up with is: $a_n =sin(n\pi/2)+cos(n\pi/2)$ But I am looking for something more elegant. It is important that it will suit for all $n>=0$","['sequences-and-series', 'calculus']"
2325382,Why does Hartshorne have hypothesis $(*)$ in II.6?,"In Hartshorne's chapter on Weil divisors he fixes the following hypothesis: $(*)$ Every scheme is Noetherian , integral, separated, and regular in codimension 1 I can understand why you would want the first three hypotheses, but the regularity in codimension 1 is a little mysterious to me. What is the motivation behind this hypothesis? Is there any geometric reason, or does this just make the algebra in this chapter easier? For reference, regular in codimension 1 means that any local ring of $X$ of dimension 1 is regular.","['regular-rings', 'algebraic-geometry', 'local-rings']"
2325386,Can we extend the proof of density of $\sin(n)$ to $\sin(n^2)$?,"We know that $(x_n)_{n\in\mathbb{N}} $ defined as $x_n=\sin(n) $ is dense in the interval $[-1,1]$ , can we extend this to prove also $\sin(n^2) $ is dense in $[-1,1]$ ? First i present my proof of density of $\sin(n)$ to let you understand the key step i have in mind to pass to $\sin(n^2) $ .
Since $ \sin(n)=\sin(n+2k\pi) $ where $k\in \mathbb{Z}$ the problem is equivalent to prove $ n+2k\pi $ is dense in $\mathbb{R}$ , or equivalently $ n-2k\pi $ is dense in $[0,2\pi)$ it's enough. For the proof i will need this theorem: Dirichlet's approximation theorem For any real number $\alpha$ and natural number $N$ there exists integers $p,q$ with $ 1\le q \le N $ such that $$ |q\alpha-p|<\frac{1}{N} $$ A consequence of this theorem it's that for every irrational alpha $\alpha$ the inequality $$ \left|{\alpha -\frac{p}{q}} \right|<\frac{1}{q^2} \ \ \  \Longleftrightarrow \ \ \ |q\alpha-p|<\frac{1}{q} \ \ \ \ \ \ \ (*)$$ is satisfied for infinitely many integers $p,q$ . For $(*)$ there exists infinitely many integers $p,q$ such that $|2\pi q-p|<\frac{1}{q}$ this is equivalent to $ \inf_{n,m\in \mathbb{N}}|n-2\pi m|=0$ then $\forall \epsilon >0 $ there exists $m,n$ such that $ |n-2\pi m|<\epsilon $ . Now let $n-2\pi m = \Delta $ and $\alpha \in [0,2\pi) $ a real number. We have two cases: $\Delta>0 $ we have $ 0<\Delta < \epsilon $ and let $ k=\lfloor \frac{\alpha}{\Delta} \rfloor$ then $$ 0< \frac{\alpha}{\Delta} -k <1 \ \ \ \Longrightarrow \ \ \ \ 0<\alpha-k\Delta < \Delta $$ Then we have $$ 0<\alpha-k\Delta=\alpha-(kn-2\pi mk) < \Delta < \epsilon \ \ \ \ \ (1) $$ $\Delta<0 $ we have $ -\epsilon<\Delta < 0 $ and let $ k=\lfloor \frac{\alpha-2\pi}{\Delta} \rfloor$ then $$ 0< \frac{\alpha-2\pi}{\Delta} -k <1 \ \ \ \Longrightarrow \ \ \ \ 0> \alpha-2\pi-k\Delta > \Delta $$ Then $$ 0 >\alpha-2\pi-k\Delta = \alpha-(kn-2\pi (mk-1)) > \Delta >-\epsilon$$ So we have proved that $ \forall \epsilon >0 $ we can find a number $Q$ in the form $ Q=n-2\pi m $ for some $m,n$ integers such that $ |Q-\alpha|< \epsilon $ so the set $ \{ n-2\pi m \} $ is dense in $[0,2\pi) $ and our proof is complete. I tried to extend this proof to $\sin(n^2) $ but i failed, my main idea is :
Can we find a ""cubic form"" or something similar to Dirichlet's approximation theorem? If we can find a statement with same hypothesis like, for some $c\in \mathbb{R} $ : $$ \left|{\alpha -\frac{p}{q}} \right|<\frac{1}{cq^3} \ \ \  \Longleftrightarrow \ \ \ |q\alpha-p|<\frac{1}{cq^2} \Longrightarrow |q^2\alpha-(pq)|<\frac{1}{cq}$$ we would be able to prove density of $ \{n^2-2\pi m \}$ in $[0,2\pi) $ .
Does something similar do exist? Or we must go to a different approach?","['general-topology', 'measure-theory', 'calculus', 'density-function']"
2325411,$f(x)$ not continous at 0 but $f(x) + \frac{1}{f(x)}$ continuous at 0: Is my example valid?,"I'm but a lowly electrical engineering student interested in mathematics. Recently, I've been working through the second edition of Stephen Abbott's Understanding Analysis and I encountered a problem that I'm not entirely sure about, specifically problem 4.3.6, part d, which states: Provide an example or explain why the request is impossible: A function $f(x)$ which is not continuous at 0 such that $f(x) + \frac{1}{f(x)}$ is continuous at 0. Now, being supremely lazy, my instinct at first was to say, ""sure, consider the function $f:\mathbb{R} \to \mathbb{R}$ defined by 
$$f(x) =
\begin{cases}
1,  & \text{if $x=0$} \\
0, & \text{if $x \neq 0$}
\end{cases}""$$
Then, my reasoning was that the only way we can define $g(x) = f(x) + \frac{1}{f(x)}$ is via the restriction of $f$ onto the domain $\{0\}$. So, since 0 is clearly an isolated point in the domain of $g$, it follows that $g(x)$ must be continuous at 0. Does this answer fit the ""spirit"" of the question? Or am I only allowed to choose an $f$ such that $g$ can have the same domain as $f$? Thanks for your help!","['continuity', 'real-analysis', 'functions']"
2325436,Do eigenvectors of Hermitian operators span the space in infinite dimensions?,"I was reading Introduction to quantum mechanics by David J. Griffiths and came across following paragraph: $3$ . The eigenvectors of a hermitian transformation span the space. As we have seen, this is equivalent to the statement that any hermitian matrix can be diagonalized. This rather technical fact is , in a sense, the mathematical support on which much of a quantum mechanics leans . It turns out to be a thinner reed then one might have hoped, because the proof does not carry over to infinite-dimensional spaces. "" My thoughts: If much of a quantum mechanics leans on it, but the proof does not carry over to infinite-dimensional spaces, then hermitian transformations with infinite dimensionality are spurious. But there is infinite set of separable solutions for e.g. particle in a box. So Hamiltionan for that system has spectrum with infinite number of eigenvectors and is of infinite dimensionality. If we can't prove that this infinite set of eigenvectors span the space then how can we use completness all the time? Am I missing something here? Any missconceptions? I'd appriciate any help.","['quantum-mechanics', 'mathematical-physics', 'functional-analysis', 'spectral-theory', 'unbounded-operators']"
2325498,Derivative of the logit function,"I have plotted a logit function and its derivative. My first question is that how can I interpret the derivative graph of the logit function and second, why in logit function, the second derivative becomes the logit function itself?","['derivatives', 'calculus']"
2325528,Dog and Goose Circular Pursuit Problem,"Imagine there is a Goose swimming counter-clockwise at the edge of a circular pond of radius $R$, and a dog (starting at the center of the pond) is paddling to catch it such that the dog is always pointing towards the goose. If the goose is travelling at speed $u$, what is the minimum speed that the dog must travel in order to eventually catch the goose?
  What is the minimum speed needed for the dog to catch the goose in time $\tau$? I've seen pursuit problems like this in my Dynamical Systems textbook (indeed, this is very similar to one) and I've never had any luck solving them. I've found some solutions online to certain problems, but they tend to explain it very poorly in my opinion (for the record, all solutions I've seen to circular pursuit problems involve introducing alternate coordinate systems) My attempt: Let $x_d$ be the position vector of the dog, $x_g$ be the position vector of the goose, and $v_d$ be the velocity vector of the dog. Drawing a diagram makes it evident that for any speed $||v_d||$ at fixed time $t$, $\exists \lambda \in \mathbb{R}$ s.t. $$x_d + \lambda v_d = x_g = (R \cos(u t/R), R \sin(ut/R))$$ Generally, $\lambda = \lambda(t)$, which makes this much more difficult, but we are able to get two differential equations out of it: $$x_d' + \frac{x_d}{\lambda(t)} = \frac{R}{\lambda(t)} \cos(ut/R) $$ $$y_d' + \frac{y_d}{\lambda(t)} = \frac{R}{\lambda(t)} \sin(ut/R) $$ Which is a first-order linear ODE, but I don't even know if the integrating factor $exp(\int \frac1{\lambda(t)} dt)$ exists, let alone how to find $\lambda(t) $ In order to catch the goose, we'd need $||x_d - x_g|| = 0$ for some $t \in \mathbb {R} $. I believe the minimum would occur when $||x_d - x_g|| \ne 0 \space\space \forall t \in \mathbb {R} \space \text { with } \space \lim_{t \to \infty} ||x_d - x_g|| = 0$. As mentioned, I'm not sure how I'd find $\lambda $ if it's even worthwhile to introduce to the problem (I originally debated trying Lagrange multipliers or two-timing for this part, but am unsure how if it's possible). I am open to seeing alternative methods as well as seeing if there's any way to actually use my thought process. I am also aware that pursuit problems often lack a closed solution, but I thought I'd try my hand it nonetheless.","['ordinary-differential-equations', 'alternative-proof', 'proof-verification']"
2325534,"Finding all pairs $(a,b)$ of positive integers such that $a^2+nab+b^2$ is a perfect square.","When $n=2$, the question is trivial. Is there a general method to find all such pairs for $n\ge{3}$ and $n\in{\mathbb{N}}$?","['number-theory', 'quadratic-forms']"
2325565,Is it possible to calculate probability density function from a data set? [closed],Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question Is it possible to calculate probability density function from a data set of values? I assume this should be some kind of a function fitting exercise.,"['probability-theory', 'probability', 'statistics', 'probability-distributions']"
2325582,Outer automorphisms of a connected Lie group,"A compact, connected Lie group $G$ is finitely covered by a group of the form $T \times K$, where $T$ is a torus and $K$ is simply-connected. I am under the impression the outer automorphism group $$\mathrm{Aut} (T \times K) / \mathrm{Inn}(T \times K) $$ is just
$$\mathrm{Aut}\, T \times \prod_{k} \Big( \big(\prod_{j \in J_k} \mathrm{Aut}\,\Gamma_j \big)\rtimes S_{J_k}\Big),$$ where $J_1 \amalg \cdots \amalg J_n$ is a partition of the indices $j$ corresponding to the partition of the simple factors $K_j$ of $K$ by isomorphism type, 
$S_{J_k}$ is the symmetric group permuting these factors,
and $\Gamma_j$ is the Dynkin diagram of $K_j$ I also think $\mathrm{Out}\,G$ is the subgroup leaving the kernel of $T \times K \twoheadrightarrow G$ invariant (this condition is well-defined because the kernel is central). In the case of a noncompact, still connected Lie group $H$, there is still a maximal compact subgroup $G$, unique up to conjugacy, so any outer automorphism is in the class of an automorphism preserving $G$ and hence induces an automorphism of $G$. Thus $\mathrm{Out}\, H$ can naturally be identified as a subgroup of $\mathrm{Out}\, G$. The reasoning, such as it is, is basically that the center must remain invariant, all the compositions $K_j \to K \to K_k$ must be Lie group homomorphisms, and ""diagonal"" homomorphisms $T \to T \times K_k$ or $K_j \to K_j \times K_k$,
in case $T,K_j < K$, don't extend to automorphisms of $T \times K_k$ or $K_j \times K_k$ because that would require too much commutativity of $K_k$. Is this right or have I missed something ? If it is okay, should I have seen this somewhere already ? Where? What's an example of a pair $(H,G)$ and an automorphism of $G$ not extending to $H$ ?","['algebraic-topology', 'automorphism-group', 'differential-geometry', 'lie-groups']"
2325592,"""X is distributed as ..."" notation","A question about notation: We sometimes use $\sim$ to denote ""distributed as"" e.g. if $X$ is Gaussian we write $X \sim N(\mu, \sigma^2)$. Is it acceptable to use the ""~"" notation for an arbitrary distribution? e.g. can we write $$X \sim \begin{cases} \frac{3}{2}x^2, & x \in [-1,1] \\0 & \text{otherwise} \end{cases}$$ If not, is there another way to write ""$X$ is distributed as ...""? i.e. without the more verbose ""Let $p_X(x)$ be the pdf of $X$. Then $p_X(x)=$ ...","['probability', 'notation', 'probability-distributions']"
2325606,Finding the invariant lines of a vector field,"How do I find the invariant lines of the following system: $x' = x(1-x+y)$ $y' = y(1-3x-y)$ The fixed points of the system are $\{(0,0),(0,1),(1,0),(0.5,-0.5)\}$ I know there are 4 lines. The invariant lines $x = 0$ and $y = 0$ are trivial. How do I find the remaining 2?","['ordinary-differential-equations', 'dynamical-systems']"
2325631,Three different result for the same indefinite integral,"I was killing time solving some indefinite integrals, when I found this one: \begin{equation}
  \int\frac{1}{(x+1)\sqrt{x^2+2x}}\ \mathrm{d}x
  \tag{1}\label{integral}
\end{equation} Not a particularly difficult one, I'll post my solution here: \begin{equation}
  \begin{split}
  \int\frac{1}{(x+1)\sqrt{x^2+2x}}\ \mathrm{d}x = \int\frac{1}{(x+1)\sqrt{(x+1)^2-1}}\ \mathrm{d}x
  \end{split}
\tag{2}\label{calculus}
\end{equation} by substituting $t = x+1$ , d $t = \mathrm{d}x$ , and then $s = \sqrt{t^2-1} \rightarrow \mathrm{d}s = \frac{t}{\sqrt{t^2-1}}\mathrm{d}t$ \begin{equation}
  \begin{split}
   = \int\frac{1}{t\sqrt{t^2-1}}\ \mathrm{d}t &= \int\frac{1}{(x+1)\sqrt{(x+1)^2-1}}\ \mathrm{d}x =\\
  &= \int\frac{\mathrm{d}s}{1+s^2} =\\
  &= \arctan{s} + \mathrm{cost}\\
  &= \arctan{\sqrt{t^2-1}} + \mathrm{cost}\\
  &= \arctan{\sqrt{\left(x+1\right)^2-1}} + \mathrm{cost}
  \end{split}
\tag{3}\label{calculus2}
\end{equation} I then derived (I recommend, if you wanna check my results to use this online derivative calculator which actually shows steps...) my solution finding the starting function: $$\frac{\mathrm{d}}{\mathrm{d}x}(\arctan{\sqrt{(x+1)^2-1}} + \mathrm{cost}) = \frac{1}{(x+1)\sqrt{x^2+2x}}$$ The graph (plotted with Grapher from Mac Os X), with $\color{red}{\text{function}}$ and $\color{blue}{\text{integral}}$ : Now this integral comes from the exercise book Problems in Mathematical Analysis by Boris Demidovich and it's the number 1271 , and even if I'm pretty sure this mine is the correct solution I lost quite time to understand the proposed solution of the book, which, if you don't have it and you can't check for yourself, is 1271 . $\qquad-\arcsin(\frac{1}{1+x})$ deriving this function you'll find: \begin{equation}
  \begin{split}
   \frac{\mathrm{d}}{\mathrm{d}x}&\left[-\arcsin(\frac{1}{1+x})\right] =\\
  &= \dfrac{1}{\left(x+1\right)^2\sqrt{1-\frac{1}{\left(x+1\right)^2}}}\\
  &= \dfrac{1}{\frac{\left(x+1\right)^2}{\sqrt{(x+1)^2}}\sqrt{\left(x+1\right)^2-1}}\\
 &= \dfrac{1}{\frac{\left(x+1\right)^2}{|x+1|}\sqrt{\left(x+1\right)^2-1}}\\
 &= \dfrac{1}{{\left(x+1\right)}\mathrm{sgn}(x+1)\sqrt{\left(x+1\right)^2-1}}\\
  \end{split}
\tag{4}\label{calculus3}
\end{equation} Plotting the result will give you an idea about the mistakte he could have done, in cyan the $\color{cyan}{Demidovich's~~primitive}$ : So I was pretty sure I was right and he was not, so I tried integrate the \eqref{integral} with Mathematica, with another unsatisfying outcome: \begin{equation}
  \int\frac{1}{(x+1)\sqrt{x^2+2x}}\ \mathrm{d}x = \frac{\sqrt{2}\sqrt{x}\sqrt{x+2}\arctan(\sqrt{\frac{x}{x+2}})}{\sqrt{x(x+2)}}
\end{equation} This solution, in $\color{orange}{orange}$ , is almost like mine, even if it does not comprehend the negative values of the function... Also, if I try to derive (I've done it with calculator, as it's quite long to do for yourself...) you get $$\left(\frac{\sqrt{2}\sqrt{x}\sqrt{x+2}\arctan(\sqrt{\frac{x}{x+2}})}{\sqrt{x(x+2)}}\right)' = $$ $$-\dfrac{\left(\sqrt{x+2}\left(-x^\frac{7}{2}-3x^\frac{5}{2}-2x^\frac{3}{2}\right)+\left(x+2\right)^\frac{3}{2}\left(x^\frac{5}{2}+x^\frac{3}{2}\right)\right)\arctan\left(\frac{\sqrt{x}}{\sqrt{x+2}}\right)-x^3-4x^2-4x}{\left(x\left(x+2\right)\right)^\frac{3}{2}\left(x^2+3x+2\right)}$$ Now, since I've found that in my range of definition $x^2-2x>0$ the primitive function that i found, derived, gives me the starting function, this should tell me that I am right and others (computer, this case) have bugs or they encounter problems deriving such a function. So which of the three solution $\color{blue}{mine}$ , $\color{orange}{Mathematica's}$ or $\color{cyan}{Demidovich's}$ is the correct one? Why are them wrong, if they are? Does it depend on calculator's bug or it's my problem? Thanks for attention.","['derivatives', 'calculus', 'indefinite-integrals', 'integration', 'graphing-functions']"
