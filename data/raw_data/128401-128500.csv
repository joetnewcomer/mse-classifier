question_id,title,body,tags
1971630,What does $\mathbf G_m$ really mean?,"My understanding is that $\mathbf G_m$ stands for $k^*$ (the multiplicative group of the field $k$ ) as a group scheme. But I have also seen symbols like $H^1(X_{\text{et}},\mathbf G_m)$ .  Is this talking about the first cohomology group of $X_{et}$ with coefficients in the constant sheaf with values in $\mathbf G_m$ ?","['group-schemes', 'notation', 'algebraic-geometry']"
1971657,"Multivariable limit $\lim_{(x,y)\to(0,0)}\frac{\sqrt{4-x+y}-2}{7x-7y}$","Welp. I can't find anything helpful, so here we go. I'm trying to find the multivariable limit (if it exists) of
$$\lim_{(x,y)\to(0,0)}\frac{\sqrt{4-x+y}-2}{7x-7y}$$ Mathematica and Wolfram Alpha both say that it evaluates to $\frac{-1}{28}$. Unfortunately, I have no idea how to reach this conclusion - or any conclusion, really. I've tried using polar substitution, approaching $(0,0)$ along the x- and y-axes, as $y = x$ and $y = -x$... Nothing works.","['multivariable-calculus', 'limits']"
1971658,Why probability of unordered samples is not equally likely?,"Consider a survey where a sample of size k is collected by choosing people from a population of size n one at a time, with replacement and with equal probabilities. Then the n^k ordered samples are equally likely, making the naive definition applicable, but the  ""n+k-1 choose k"" unordered samples (where all that matters is how many times each person was sampled) are not equally likely. [Source: Introduction to probability by joseph k. blitzstein] Could you please explain why is it like that?",['probability']
1971675,What is the right way to approximate $e^{-1/x^2}$ by polynomials?,"It's well known that $f(x) = e^{-1/x^2}$ (with zero added) is a smooth function that's not analytic at $x=0$, because every derivative at zero is zero, and so all of its Taylor polynomials are zero. For the sake of simplicity fix the center at zero for the rest of the question. This function isn't all that pathological and it seems like there should still be a principled way to approximate it by polynomials by using some other natural data about $f$. More concretely, what is a method for approximating a smooth function $f(x)$ by polynomials that has the following properties: Optimal by some natural criterion (analogous to how the degree-$k$ Taylor polynomial is optimal among degree $k$ polynomials on a sufficiently small interval) Graded, i.e. there is a parameter $n$ so that larger values of $n$ use higher-degree polynomials and improve the approximation. Efficiently computable, i.e., there is a $\text{poly}(n)$-time algorithm which constructs the polynomial representation from the input parameter of $n$ Nontriviality for $e^{-1/x^2}$","['real-analysis', 'polynomials', 'calculus', 'algorithms', 'approximation']"
1971696,Area in axiomatic geometry,"Let's say we have axiomatic geometry as defined by Hilbert's axioms. For line segments, angles, triangles, squares, etc. we have the notion of congruency to determine whether two of them are ""the same"". But this doesn't seem sufficient to determine whether two figures of different shape have the same area. For example, I don't see how the Pythagorean theorem can be proved using only the notion of congruency. So basically my question is: how is area defined in axiomatic geometry?","['euclidean-geometry', 'geometry']"
1971718,A set of small measure in the real line with an interesting property,"Let $\epsilon>0$.Construct an open set $E$ $\subseteq$ $\mathbb{R}$ such that $m(E\cap I)>0$ for every I interval in  $\mathbb{R}$ and $m(E)\leqslant\epsilon$,
where the symbol $m$ denotes the lebesgue measure What i did: Let $\epsilon>0$ and $\mathbb{Q}=\{q_1,q_2,,,q_n,,,\}$. I took $E=\bigcup_{n=1}^{\infty}(q_n-\epsilon/2^{n+1},q_n+\epsilon/2^{n+1})$. By doing some calculations and using the lebesgue measure's subadditivity, we can easily see that $m(E)\leqslant \epsilon$ Let $I=(a,b)$ ,$a<b$.From the density of the rationals in the real line $\exists q\in \mathbb{Q}$ such that $a<q<b$. Also $\exists n \in \mathbb{N}$ such that $q=q_n$. Now we notice that $a-\epsilon/2^{n+1}<q_n-\epsilon/2^{n+1}<q_n+\epsilon/2^{n+1}<b+\epsilon/2^{n+1}$. If we take $E\cap I=(c,d)$ were $c=max\{q_n-\epsilon/2^{n+1},a\}$ and $d=min\{q_n+\epsilon/2^{n+1},b\}$ then we have $m(E\cap I)>0$. For the case where $I=(-\infty,a)$ and $J=(b,+\infty)$ the we can  express $I=\bigcup_{n=1}^{\infty}(-n,a)$ and $J=\bigcup_{n=1}^{\infty}(b,n)$ and apply the above argument. The same arguemt applies for closed intervals. Is this proof correct or am i missing something here? Can someone help? Thank you in advance!","['real-analysis', 'lebesgue-measure', 'measure-theory', 'proof-verification']"
1971722,Constructing a potential energy function from a conservative force field,"Given: $F(x,y,z)=(x-y,-x-y+z,y+z)$ Find a potential energy that corresponds to this force field. Check your answer by taking its gradient. I've already shown that this force field is conservative by $$\nabla \times  F =0$$ Now, I used $\nabla U=-F$ to find the potential function. I did so by $$U=-\int F \cdot \vec{dr}$$
$$=-\left [\int (x-y)dx + \int(-x-y+z)dy + \int (y+z)dz \right ]$$
$$=\frac{1}{2}(-x^2+y^2-z^2)+2xy-2yz$$ Now I need to check it by taking its gradient, but its not resulting in the original force field. $$\nabla U=-F$$
$$F=-\nabla U$$
$$=- \left [\frac{\partial U}{\partial x}+\frac{\partial U}{\partial x}+\frac{\partial U}{\partial x} \right ]$$
$$=- \left [ (-x+2y)+(y+2x-2z)+(-z-2y)\right ]$$
$$=(x-2y)+(-2x-y+2z)+(2y+z)$$ What did I miss?","['derivatives', 'vector-fields', 'calculus', 'vector-analysis']"
1971730,Solve the differential equation $\frac{dy}{dx} + 3yx = 0$ for the values $x = 0$ when $y = 1$ - Solution Review,"Solve the differential equation $\frac{dy}{dx} + 3yx = 0$; $x = 0$ when $y = 1$. I solved this DE using the integration factor method. However, online calculators are giving me a different answer, where they instead used the separation of variables method. Please review my solution and indicate if/where my reasoning is false, why it is false, how to fix it, and what the correct reasoning should be. Thank you. My solution is as follows. $\dfrac{dy}{dx} + 3xy = 0$ $e^{ \int 3x } dx = e^{ \frac{3x^2}{2} }$ $ \dfrac{dy}{dx} e^{ \frac{3x^2}{2} } + 3yxe^{ \frac{3x^2}{2} } = 0$ $ \dfrac{d}{dx} \left( y e^{ \frac{3x^2}{2}} \right) = \dfrac{dy}{dx} e^{ \frac{3x^2}{2} } + 3xye^{ \frac{3x^2}{2}} $ $ \therefore \dfrac{d}{dx} \left( y e^{ \frac{3x^2}{2}} \right) = 0$ $ \displaystyle\int \dfrac{d}{dx} \left( y e^{ \frac{3x^2}{2}} \right) dx + C = 0$ $ \Rightarrow y e^{ \frac{3x^2}{2}} + C = 0$ We want to solve for y. We know that $x = 0$. $ \therefore ye^0 + C = 0$ $ \Rightarrow y = -C$",['ordinary-differential-equations']
1971777,Maximal Ideals in polynomial quotient rings,"I am having trouble unpacking this problem involving finding maximal ideals. It would be great to gain some insight into how maximal ideals work in polynomial quotients. The example I'm trying to understand is $\mathbb{R}[x]/(x^2)$. The way I went about understanding this problem was to first find out what elements in the quotient looked like: Elements in $\mathbb{R}[x]$ look like $$a_nx^n + \cdots + a_2 x^2 + a_1 x + a_0$$ for $a_0,...,a_n \in \mathbb{R}$ Elements in $\mathbb{R}[x]/(x^2)$ are cosets of the ideal $I = (x^2)$ which are of the form $$f(x)+I$$ and $$f(x)*I$$ for $f(x) \in\mathbb{R}[x]$. This is where I get lost and I'm not sure how to proceed, perhaps there are some theorems to do with $(x^2)$ being principal ideal generated by a monic polynomial. Am I approaching this problem in the right way? Thanks for your help.","['abstract-algebra', 'ring-theory']"
1971785,Multivariable Limit of Rational Function $\frac{x^3y^2}{x^4+y^6}$,"I am struggling to show if this does or does not exist: $$\lim_{(x,y) \to (0,0)}\frac{x^3y^2}{x^4+y^6}$$ I usually have no problems with limits like these. This one is throwing me through a loop because the power of $x$ is larger than the power of $y$ in the numerator, but the opposite is true in the denominator. So alot of the usual tricks for doing this kind of limit aren't working. I tried approaching along all sorts of lines of the form $y=kx^a$ and I'm always getting that the limit is $0$. However I am struggling to prove this using the limit definition or the squeeze theorem. The triangle inequality, $2|x||y|\leq x^2 + y^2$, and other tricks aren't working for me. Thanks for the help. NOTE: We have not covered polar coordinates, so the solution shouldn't have to use that.","['multivariable-calculus', 'calculus', 'limits']"
1971790,Maximal open coverings without finite subcoverings and the Axiom of Choice.,"In my first attempt to prove that the Ultrafilter Lemma implies Alexander subbase theorem , I tried to prove that the Ultrafilter Lemma could be used to show that if $X$ is not compact, then there exists a maximal open cover for $X$ with no finite subcovers. After failing at it, I posted the question linked above, where I learnt an alternative way to do so. However, this make me wonder about the different equivalences (in ZF) of the statement "" every non compact space has a maximal open cover without finite subcovers "". It may be a bit silly, but I cannot figure it out if the above statement is equivalent to the Axiom of Choice or any of its restrictions. So, I would appreciate any references or comments concerning this.","['general-topology', 'set-theory', 'compactness', 'axiom-of-choice']"
1971839,Show that $\int ^2_1\int^x_{\sqrt{x}}\sin \frac{\pi x}{2y}dydx+\int^4_2\int^2_{\sqrt{x}}\sin \frac{\pi x}{2y}dydx=\frac{4(\pi+2)}{\pi^3}$,"Show that $$\int ^2_1\int^x_{\sqrt{x}}\sin \frac{\pi x}{2y}dydx+\int^4_2\int^2_{\sqrt{x}}\sin \frac{\pi x}{2y}dydx=\frac{4(\pi+2)}{\pi^3}$$
I sketched out the domain of the integration, it seems these two part can not be combined together. I tried change the order of the integration. However, even for the second part, which is easier when change order, is not easy to calculate. Like
$$\int^4_2\int^2_{\sqrt{x}}\sin \frac{\pi x}{2y}dydx=\int^2_{\sqrt{2}}[\int^{y^2}_2\sin\frac{\pi x}{2y}dx]dy=\int^2_{\sqrt{2}}\frac{-2y}{\pi}(\cos \frac{\pi y}{2}-\cos\frac{\pi}{y})dy$$
still not easy to compute... Any other methods? Thanks~","['integration', 'calculus', 'functions']"
1971868,Rational function field of product affine varieties,"Let $X, Y$ be affine varieties, we know that the coordinate ring of the product variety $X\times Y$ satisfies $k[X\times Y]\cong k[X]\otimes_k k[Y]$. My question is is it true that for rational function field, we also have  $k(X\times Y)\cong k(X)\otimes_k k(Y)$? If not, is there a way to relate $k(X\times Y)$ with $k(X)$, and $k(Y)$ ?",['algebraic-geometry']
1971903,Anyone Understand how the chain rule was applied here?,Just start from the top with how they applied the chain rule. What have I tried: Google (googling chain rule multivariate function didn't help. Clearly $\frac{df}{dt}=\sum \frac{\partial x_i}{\partial t}\frac{\partial f}{\partial x_i} $ but how they reached their conclusion is beyond me.),"['multivariable-calculus', 'manifolds', 'chain-rule', 'calculus']"
1971908,Is it possible to rewrite $\sin(x) / \sin(y)$ in the form of $\sin(z)$?,"I'm looking to get a particular answer in the form of $\sin(z)$, and I managed to reach an answer in the form $\sin(x)/\sin(y)$. I've checked on a calculator which has confirmed that they're the same number, but how can I convert the fraction into a single sin in order to show that without relying on the calculator?",['trigonometry']
1971920,norm convergence in Hilbert space,"Given a sequnce $y_i\in H$ ($H$ is Hilbert space over $\mathbb{C}$) which satisfies
$$
||\sum\beta_i y_i||<A
$$
where $A$ is real constant and the latter inequality is true for any sequence of scalars $\{\beta_i\}$, $0\leq|\beta_i|\leq1$ which are zero except (maybe) finite number of indices. I need to show that $\sum y_i$ converges in norm. I tried to show that $\sum ||y_i|| < \infty$ (and than it is enough) however I can only show that $\sum ||y_i||^2 < \infty$: The latter follows from the fact that for any finite number of elements $x_i\in H$ there are scalars $c_i$, |c_i|=1 such that $||\sum c_i x_i||^2\geq \sum ||x_i||^2$ how can I proceed from here? thank you","['functional-analysis', 'hilbert-spaces']"
1971928,True or False? The transformation $T$ on the set of all continuous functions that is defined by $T(f) = f (1)$ is a linear transformation.,"True or False? The transformation $T$ on the set of all continuous functions that is defined by $T(f)= f(1)$ is a linear transformation. Intuitively, I can see that this might be true if you plugin stuff like $f(x) = x$ and $g(x) = \cos(x)$. Thus, $T(a_1\cdot x + a_2\cdot \cos(x)) = a_1 \cdot 1 + a_2 \cdot \cos(1) = a_1\cdot T(x) + a_2\cdot T(\cos(x)).$ But how do I definitely prove this? I have heard about arbitrary function arguments, but I don't know enough about functions to really make an argument here either way.","['linear-algebra', 'functions', 'linear-transformations']"
1971990,"If $\operatorname{rank}(A)$ = $\operatorname{rank}(A^2)$, show that nullspace of $A$ = nullspace of $A^2$","Let $A$ be a square matrix. If $\operatorname{rank}(A)$ = $\operatorname{rank}(A^2)$ Prove that nullspace of $A$ = nullspace of $A^2$ The first thing I notice is that this $\implies$ $\operatorname{nullity}(A)=\operatorname{nullity}(A^2)$ Then I am kinda stuck, any hints?","['matrix-rank', 'linear-algebra']"
1972010,Reference for automorphic form via representation theory,"I don't know anything about automorphic form but I heard it is related to representation theory and number theory. I am interested in both fields, so I would like to know if there is any introductory textbook or online paper that starts from the very basic. I only know a basic of finite group representation theory and algebraic number theory (not class field theory.)
So the more elementary, the better.","['reference-request', 'algebraic-number-theory', 'number-theory', 'automorphic-forms', 'representation-theory']"
1972079,algorithm for splitting splines into arc and line,"I would like to split splines of DXF files to lines and arcs in 2D for a graphic editor. From DXF file, I have extracted the following data: degree of spline curve number of knots and knot vectors number of control points and their coordinates number of fit points and their coordinates Using the extracted data, start and end point of lines start and end point, center point, radius of arcs are needed to find. I get confused which control points are controlling which knots by seeing the extracted data.
I have found this paper about biarc curve fitting. Is it only for only two connected arc or useful for splines with so many knot points? But, it still needs tangents to calculate the points of arc. Which algorithms should I use to find the points of arcs and lines?","['spline', 'algorithms', 'interpolation', 'geometry']"
1972114,Proving the existence of a sequence of functions converging to 0 with an added property,"This is a problem from Rudin's Functional Analysis: Show that there is a sequence of functions $\{ f_n \}$ in $X$ (the vector space of all complex functions) such that $f_n \to 0$ pointwise, but if any sequence $\{ \gamma_n \}$ tends to $\infty$, $\gamma_n f_n \not\to 0$. The hint says to use the fact that the collections of all complex sequences converging to $0$ has the same cardinality as $[0,1]$. Honestly, this confused me more than it helped me. My main issue is through the method of showing existence: I am not sure if I should attempt to construct an explicit sequence $f_n$, or if I need to appeal to other nonconstructive means such as Zorn's Lemma, etc. I have been trying to construct clever choices of sequences for a good bit now, but it always seems like I will be able to find a sequence that diverges slowly enough to allow that $\gamma_n f_n \to 0$. Thanks!","['functional-analysis', 'sequences-and-series']"
1972160,How to efficiently solve this question? Possibly using Max Mod Principle,"Let $f: {\mathbb{D}} \rightarrow {\mathbb{C}}$ be holomorphic and continuous on the closed unit disk $\bar {\mathbb{D}}$. Assume that $|f(z)| \leq 1$ whenever $|z| = 1$ and $Im(z) > 0$; and
$|f(z)| \leq 9$ whenever  $|z| = 1$ and $Im(z) < 0$.
Show that $|f(0)| \leq 3$. Is it possible to solve this using the Max Mod Principle?","['complex-analysis', 'maximum-principle']"
1972232,"Determine accumulation points of $m+n\sqrt{2}$ and conclude, if this set if open,closed(or nor open neither closed)","My solution: There is no accumulation point in this set. But suppose, 2.4 is accumulation point of this set. But $N_{\epsilon}(2.4)\cap(X without (2.4)) = {} $ So, there is no accumulation point. Set is not open, because $\epsilon$-Neighbourhood near 1+sqrt(2) (1+sqrt(2)- $\epsilon$,1+sqrt(2)+ $\epsilon$) is not in our set. But what about closed set? If set don't have accumulation points, what can i conclude about closeness of set? And chech, if my logic is correct(open set< accumulation point)","['general-topology', 'elementary-set-theory']"
1972241,$\lim_{x\rightarrow 0}\frac{1-\cos a_{1}x \cdot \cos a_{2}x\cdot \cos a_{3}x\cdot \cdot \cdot \cdot \cdot \cos a_{n}x}{x^2}$,$\displaystyle \lim_{x\rightarrow 0}\frac{1-\cos a_{1}x \cdot \cos a_{2}x\cdot \cos a_{3}x\cdot \cdot \cdot \cdot \cdot \cos a_{n}x}{x^2}$ without D l hospital rule and series expansion. i have solved it series expansion of $\cos x$ but want be able to go  further without series expansion,['limits']
1972248,Find all possible values which following expression can take $\sqrt{x^2-7x+6}$,"Given expression is: $\sqrt{x^2-7x+6}$. Now i first find values of x for which this is a valid question by putting guy inside square root equals to greater than 0. I get $x \in[-\infty,1]\cup[6,\infty] $. Now i completed the square and i got $$\sqrt{(x-\frac{7}{2})^2-\frac{25}{4}}$$.
Now from here i calculated range as x $\in$ $[0,\infty]$. Now i have taken intersection of values of  obtained and i got answer to be $[0,1]\cup[6,\infty]$. but my textbook says answer to be $[0,\infty]$. Where is my mistake? Thanks",['algebra-precalculus']
1972276,Why the geodesic line is the projections of the integral curves of the geodesic flow?,"Picture below is from 54 page of  Jost's Riemannian Geometry and Geometric Analysis , Why the geodesic line is the projections of the integral curves of the geodesic flow ?","['riemannian-geometry', 'ordinary-differential-equations', 'differential-geometry', 'geodesic']"
1972291,"Right quotient of $L_1=L(a^*baa^*)$, and $L_2=L(ab^*)$.","Given $L_1=L(a^*baa^*)$, $L_2=L(ab^*)$. The regular expression corresponding to language $L_3=L_1/L_2$ (right quotient) is given by $a^*b$ $a^*baa^*$ $a^*ba^*$ None of the above My attempt: The right quotient (or simply quotient) of a formal language ${\displaystyle L_{1}} $ with a formal language ${\displaystyle L_{2}}$ is the language consisting of strings $w$ such that $wx$ is in ${\displaystyle L_{1}}$ for some string $x$ in ${\displaystyle L_{2}} $. Given, $L_1=(a^*baa^*)=\{ba, baa, aba, abaa,\dots\}$ $L_2=(ab^*)=\{a, ab, abb, abbb,\dots\}$ Therefore, $L_3=L_1/L_2=\{b, ba, ab, aba,\dots\}=(a^*ba^*)$ I have used only string $'a'$ of language $L_2$ Option $(3)$ is true. But, some where it explained as $L_1 =\{ba,aba,abaa,baa,\dots\}$ $L_2=\{ab^*\}$ $L_1 / L_2$ operation not successful here So, Ans $(4)$. Can you explain it, please?","['regular-language', 'discrete-mathematics', 'regular-expressions', 'context-free-grammar', 'automata']"
1972306,"Finding $R \circ S$, $S \circ R$, and $R \circ R$ for given relations $R,S$","For the following relations on $\{1,2,3,4,5,6,7,8,9,10\}$. $R=\{(1,2),(3,6),(4,1),(5,5),(6,4),(7,5)\}$ $S=\{(2,1),(3,6),(9,4)\}$ What I got: $R∘S = \{(2,2),(3,4),(9,1)\}$ $S∘R = \{(1,1)\}$ $R∘R = \{(3,4),(4,2),(5,5),(6,1),(7,5)\}$ The question stated that ""If it is not possible to determine the relation then explain the reason."" So I would like to ask is there are any answer not to possible to determine the relation?","['discrete-mathematics', 'function-and-relation-composition', 'elementary-set-theory', 'relations', 'solution-verification']"
1972321,Equivalence of Axiom of choice and all subsets of $\mathbb{R}$ are Lebesgue Measurable?,"In my Measure theory course, we proved Vitali's Theorem which stated that there exist a subset of $\mathbb{R}$ which is not Lebesgue Measurable.
We assumed axiom of choice to show that there exist a set which will not be lebesgue measurable by contradiction. then my professor made the statement that 
Axiom of choice is equivalent to saying that all subsets of $\mathbb{R}$ are Lebesgue Measurable. My confusion is Axiom of choice helped us to find a non-measurable set
therefore how it is equivalent to saying all subsets are measurable. My thinking of equivalence here is if we assume one we should be able to prove the other. EDIT: Okay so I discussed this with my professor again based on the answers.
He said that By equivalent he did not mean Mathematical Equivalence but equivalent in a sense of axioms More precisely,
If we look at the contrapositive of the above theorem it says that,
All subsets of $\mathbb{R}$ are lesbegue measurable then axiom of choice is not true. 
He meant that One can take ""all subsets of $\mathbb{R}$ are Lebesgue Measurable"" as an Axiom and it will be independent of Axiom of Choice and the existing ZF.","['lebesgue-measure', 'logic', 'measure-theory', 'axiom-of-choice']"
1972335,Is the measure of the sum equal to the sum of the measures?,"Let $A,B$ be subsets in $\mathbb{R}$. Is it true that
$$m(A+B)=m(A)+m(B)?$$
Provided that the sum is measurable. I think it should not be true, but could not find a counterexample.","['sumset', 'lebesgue-measure', 'measure-theory']"
1972360,Number of Solutions to the equation $\sin x=mx.$,"I would like to know if there any analytical methods that can be used to solve this equation. So far, I've made the following observations: We have to only check for solutions within the domain $-1/m\leq x\leq1/m.$ More than one solution is possible when $0\leq |m|<1.$ I am also guessing that if the slope $0<m\leq \frac{2}{(4n+1)\pi}$ where $n$ is whole number, then the number of solutions $x>0$ will be $2n.$",['trigonometry']
1972373,Prove $30|(a^3b-ab^3) $,"Prove that if three distinct integers are chosen at random then there will exists two among them, say $a$ and $b$ such that $30|(a^3 b-ab^3)$",['combinatorics']
1972398,"The limit of a two-variable function $\lim_{ (x, y) \to (0,0) } \frac{ xy \sin y }{ x^2 + y^2 }$","I'm trying to check if this two-variable function has a limit on the point $(0,0)$: $$\lim _{ (x, y) \to (0,0) } {{ xy \sin y } \over { x^2 + y^2 }}$$ So my method was: $$ {{xy \sin y} \over {x^2 + y^2}} = {{y \sin y} \over y^2} {x \over { ( {x^2 \over y^2 }) + 1 }} $$ Clearly $$ \lim_{y \to 0} {y \sin y \over y^2} = 1 $$ But $$ {x \over { ( {x^2 \over y^2 }) + 1 }} = { xy^2 \over x^2 + y^2 } $$ Moreover $$ | { xy^2 \over x^2 + y^2 } | < |x| $$ and $\lim_{x \to 0} x = 0$. Thus $$ \lim _{(x, y) \to (0, 0)} {x \over { ( {x^2 \over y^2 }) + 1 }} = 0 $$ Hence $$\lim _{ (x, y) \to (0,0) } {{ xy \sin y } \over { x^2 + y^2 }} = 1 \times 0 = 0$$ But calculators say that the limit does not exist. I wonder where I have done wrong.","['multivariable-calculus', 'functions', 'limits']"
1972402,What is conjugate in group theory?,Definition of conjugates: Conjugate wiki link . Suppose $G$ is a group. Two elements $a$ and $b$ of $G$ are called conjugate if there exists an element $g$ in $G$ with $g*a*g^{−1} = b$ . Here $*$ is operation on group. Question: If $g * g^{−1}$ will give us identity. Then equation will become $a * e = b$ hence $a = b$ . Then why we call them conjugate of each other? I am missing basic thing here. Please help to understand conjugate.,"['abstract-algebra', 'group-theory']"
1972405,How do I can evaluate this integral: $\int_{1}^{\infty}\frac{y\cosh(yx)}{\sinh(y\pi)}dy$?,"I'm interested to know how do I evaluate this integral: $$\int_{1}^{\infty}\frac{y\cosh(yx)}{\sinh(y\pi)}dy.$$ Wolfram alpha gives the output $$\frac1{(\pi-x)^2}+\text{Li}(-2e^{-2\pi})-\frac{\log(1-e^{-2\pi})}{\pi}-\frac12+O(\pi-x).$$ Note : I have tried to put $x=y$ to show if the above integral easy for
evaluation where I took $t=\tan\frac{x}{2}$ but I got a complicated form which I can't use some standard and simple trigonometric transformations for, Thank you for any help.","['special-functions', 'integration']"
1972447,"Number of oblong rectangles up to similarity having integer side lengths in [1, r]","How many oblong rectangles are there up to similarity which have integer side lengths between (and including) $1$ and $r$ for $r\in\Bbb Z^+$? This is a problem I set for myself for fun a few hours ago, but I still don't know where to begin. Any hint would be appreciated.","['rectangles', 'geometry']"
1972460,(Dis)Prove that the sum is positive,"Question Let $\alpha \in ]0,1]$ be arbitrary and $c \in [\frac{\alpha-1}{\alpha},1]$. I have the following sum: $$
\frac{\partial}{\partial c}\left[\sum_{(i_{m-1},\dots,i_0)\in \{0,1\}^{m-1}} q_{(i_{m-1},\dots, i_0)}(c)  \cdot \left(\sum_{j=0}^{m-1} i_j\right)^2 \right]
$$
with $q_{(i_{m-1},\dots, i_0)}(c) = (i_{m-1} (1-\alpha) + (1-i_{m-1}) \alpha) \cdot P_{i_{m-1},i_{m-2}}(c) \cdot \dots \cdot P_{i_1,i_0}(c)$ with
$$
P(c) = \begin{pmatrix}
(1-\alpha)c + \alpha & (\alpha - 1)c + (1-\alpha)\\
(-\alpha) c + \alpha & \alpha c + (1-\alpha)
\end{pmatrix},
$$
so for example $P_{0,1}(c)$ is just $(\alpha-1)c + (1-\alpha)$. I would like to prove or disprove that this sum is positive. I have proven it for the case $k = 2$ and for the general case I considered the following strategy: General idea Split it up into the different possible values for $\sum_{j=0}^{m-1}i_j$, if this value is equal to $1$ the corresponding possibilities for the different $i$ are: $(1,0,\dots,0),(0,1,\dots,0),\dots,(0,\dots,0,1,0)$ and $(0,\dots,0,1)$ and for this case we get in the total sum the value:
$$
1\cdot\left((1-\alpha) P_{10} P_{00}^{m-2} + \alpha P_{10} P_{00}^{m-2} P_{01} + \alpha P_{01} P_{00}^{m-1}\right),
$$
and we can continue like this (see ""start solution""). Examples I have done the calculations numerically for $m = 2,\dots,7$ with the following results for the sum (which are all clearly positive on the domain we're interested in):
$$
\begin{cases}
-2(\alpha - 1)\alpha\\
-4(\alpha - 1)\alpha (1+c)\\ 
-2 (\alpha-1)\alpha(3+4c+3c^2)\\ 
-4(\alpha-1)\alpha(2+3c+3c^2+2c^3)\\ 
-2(\alpha-1)\alpha (5+8c+9c^2+8c^3+5c^4)\\ 
-4(\alpha-1)\alpha (3+5c+6c^2+6c^3+5c^4+3c^5)\\ 
-2(\alpha-1)\alpha (7+12c+15c^2+16c^3+15c^4+12c^5+7c^6)
\end{cases}
$$ Start of solution Writing out the sum as described in ""General Idea"" gives us:
$$
\sum_{n=1}^{m-1} n^2(2Q_1 + Q_3 + Q_4) + m^2(m-1) \cdot (1-\alpha) \cdot P_{11}^{m-2} \cdot \alpha,
$$
where
$$
\begin{cases}
Q_1 = \sum_{k=1}^{n\wedge(m-n)} \binom{n-1}{k-1} \binom{m-1-n}{k-1} \alpha \frac{\partial}{\partial_c}(P_{01}^kP_{10}^{k-1}P_{00}^{m-k-n}P_{11}^{n-k})\\
Q_3 = \sum_{k=1}^{n\wedge(m-n-1)} \binom{m-n-1}{k}\binom{n-1}{k-1} \alpha \frac{\partial}{\partial_c}(P_{01}^kP_{10}^kP_{00}^{m-k-n-1}P_{11}^{n-k})\\
Q_4 = \sum_{k=1}^{(n-1) \wedge (m-n)} \binom{n-1}{k} \binom{m-n-1}{k-1} (1-\alpha) \frac{\partial}{\partial_c}(P_{01}^k P_{10}^k P_{00}^{m-k-n} P_{11}^{n-k-1})
\end{cases}
$$
I have also checked this form with mathematica for the cases $k = 2,3,4,5,6,7$ that this expressions gives the same values as the original expression and it indeed does. Solution (Without proof) I think I've found the solution (but I don't know how to prove it). As in the examples we write the $n$'th polynomial as:
$$
-2(\alpha-1)\alpha \cdot p_n(c)
$$
if we now write out the triangle made by the coefficients of $p_n$ we clearly see a pattern: The pattern is just: Thus we claim that in general our polynomial is given by:
$$
-2(\alpha-1)\alpha\left(\sum_{j=0}^{n-1} (j+1)\cdot(n-j)\cdot c^j\right)
$$
the only thing that remains to be done is check that this is correct, perhaps by induction. Proof by induction (start) We have the following recursive formula for $q$:
$$
q_{(i_m,\dots,i_0)} = \frac{\pi_{i_k}}{\pi_{i_{k-1}}} P_{i_k,i_{k-1}} q_{(i_{k-1},\dots,i_0)},
$$
with $\pi_0 = \alpha$ and $\pi_1 = (1-\alpha)$ moreover we easily get from this:
$$
\frac{\partial}{\partial c} q_{(i_m,\dots,i_0)} = \frac{\pi_{i_k}}{\pi_{i_{k-1}}} \frac{\partial}{\partial c}(P_{i_k,i_{k-1}} q_{(i_{k-1},\dots,i_0)})$$ I splitted the sum over $(i_m,\dots,i_0)$ into four parts letting $(i_m,i_{m-1}) \in \{0,1\}^2$ which seems to be working pretty well. Let us define:
$$
R_{m-1} :=
\frac{\partial}{\partial c}\left[\sum_{(i_{m-1},\dots,i_0)\in \{0,1\}^{m-1}} q_{(i_{m-1},\dots, i_0)}(c)  \cdot \left(\sum_{j=0}^{m-1} i_j\right)^2 \right]
$$ then I have shown that:
$$
R_m = R_{m-1} + \frac{\partial}{\partial c}\sum_{i_{m-1},\dots,i_0} P_{i_{m-1}1} q_{(i_{m-1},\dots,i_0)} (2\sum_{j=0}^{m-1} i_j + 1)
$$
Using this I narrowed the problem down to proving that:
$$
\frac{\partial}{\partial c} \sum_{(i_m,\dots,i_0)} P_{i_m1}q_{(i_m,\dots,i_0)}(2\sum_{j=0}^m i_j + 1) = -2 \alpha(\alpha-1) \left( \sum_{j=0}^{m-1} (j+1) c^j + (m+1) c^m \right)
$$
I have also checked numerically that this equality indeed holds, now we can try to prove this equality by using induction. After some more simplificiations it remains to find an expression for:
$$
\sum_{i_{m-2},\dots,i_0} (2 \sum_{j=0}^{m-2} i_j + 1) q_{(0,i_{m-2},\dots,i_0)}.
$$","['derivatives', 'matrices', 'calculus', 'combinatorics', 'summation']"
1972476,Expected area of a rectangle made by breaking a stick into four pieces,You are given a straight stick of length 21.97 cm. You break the stick at a position chosen uniformly at random along its length. Each of the two stick portions you break in half and make a rectangle with the four bits of the stick. What is the expected area of the rectangle? If I call the first point the stick is broken at $X$ then I have obtained an expression for the area of the rectangle: $\frac{21.97X-X^2}4$. But I am not able to understand how to work out the value of $X$. I have no idea how to go about finding the area of the rectangle made by the four sticks. Any help would be much appreciated.,"['uniform-distribution', 'statistics', 'probability', 'random-variables']"
1972494,Understanding a recurrence to solve the Coupon Collector problem?,I recently came across this recurrence for the coupon collector problem: $$\text{draws}(n) = \text{draws}(n-1) \cdot\dfrac{n}{n-1} + 1$$ where $\text{draws}(n)$ is the expected number of coupons to be drawn to get all $n$ unique coupons. Why is this recurrence true? I would prefer an intuitive approach.,"['combinatorics', 'recurrence-relations', 'probability']"
1972529,Push-forward measure's Radon-Nikodim Derivative,"Suppose $\mu$ and $\nu$ are probability measures on $\langle \Omega,\mathfrak{F}\rangle$ such that
$$
(\forall A \in \mathfrak{F})\, \mu(A) \triangleq\int_{\Omega}1_A(x)f(x)d\nu(x),
$$
for some measurable function $f$.  Furthermore suppose that $\nu\sim\mu$ are equivalent probability measures. If $F:\langle \Omega,\mathfrak{F}\rangle\rightarrow \langle \Omega,\mathfrak{F}\rangle$ is a bijective measurable function with measurable inverse then is the push-forward measure $F_{\star}\mu$ of the form
$$
F_{\star}\mu(A) = \int_{\Omega} 1_AF\circ fd\nu?
$$","['functional-analysis', 'probability-theory', 'concentration-of-measure', 'measure-theory']"
1972535,Studies about $\sum_{k=1}^{n} x^{\frac 1k}$,"Are there any studies about this function?
 $$f(x,n)=\sum_{k=1}^{n} x^{1/k}=x+x^{1/2}+x^{1/3}+x^{1/4}+\cdots +x^{1/n}$$ EDIT: My first notes about it. $f(1,n)=n$ $f'(1,n)=H_n$ $\int_0^1 \frac{f(x,n)}x\cdot dx=\frac{n^2+n}2$ where $f'(x,n)=\frac{d}{dx}f(x,n)$ To avoid fractional powers we can let $x=y^{n!}$ to change it into integer-powers, but the obtained polynomial does not have uniform paterm of powers. $$f(y,n)=\sum_{k=1}^{n}y^{n!/k}=y^{n!}+y^{n!/2}+y^{n!/3}+y^{n!/4}+\cdots+y^{n!/n}$$
$$=y^{n!/n}\left(y^{n!-(n!/n)}+y^{(n!/2)-(n!/n)}+y^{(n!/3)-(n!/n)}+y^{(n!/4)-(n!/n)}+\cdots+y^{(n!/(n-1))-(n!/n)}+1\right)$$ As example let $n=4$
$$f(y,4)=y^6(y^{18}+y^6+y^2+y+1)$$","['reference-request', 'sequences-and-series', 'functions', 'summation', 'power-series']"
1972554,Is the sheaf of meromorphic functions flasque?,Let $X$ be a compact Riemann surface. Is the sheaf of meromorphic function $\mathcal M_X$ a flasque sheaf? Remember that flasque means that the restrition morphisms are surjective.,"['riemann-surfaces', 'sheaf-theory', 'complex-geometry', 'algebraic-geometry']"
1972560,"If there is a need to distinguish between 'image' and 'codomain', why not do this on the input side of a function?","I see lots of reasons provided for distinguishing between codomain and image.  But it seems to me I can take all those reasons and make them into reasons for making a similar distinction on the input side (e.g. to discriminate between a 'domain of discourse' and 'domain of definition'). For example, here are some quotes from a discussion on the need to distinguish between 'image' and 'codomain' Why is it important to have a discrepancy between image and codomain? : for many functions it's not particularly important what its image is, while at the same time it would be tricky to figure this out. The codomain however is easy, it describes the type of value one can get. Is it a real number, a complex number, a fraction? For some functions, the same is true for the input side. That is, when dealing with a function I want to describe the type of input values (real numbers, or complex numbers, or?) that I would like that function to deal with, but the function may be a really hairy function for which its actual domain is tricky (if not impossible, if I define some function over Turing-machines and have their halting behavior be an essential aspect as to whether the output value is defined) to figure out. Codomain and Image of a function are two completely different concepts. The codomain of a function often has a structure, like being a topological space or something like this. It will be very inconvenient to put all that structure in the image, which is only a set, and often not such a nice one. Again, I think the same could be said on the input side ... for some functions it will be very inconvenient to describe its domain, as it's not a nice one, and as it's just a set, rather than a structure. I would like two similar concepts on the input side as well. You cannot speak about surjectivity (that is, whether it is onto) otherwise. If we would define the codomain of every function to be its image, then every function would be surjective. I can likewise say: ""You cannot speak of totality if you don't distinguish between 'domain of discourse' and 'domain of definition'. If we would define the 'domain of discourse' to be its 'domain of definition', then every function would be total."" What is a function? Informally, it is a process, or an assignment, from an input set to an output set. It is not just the process or assignment that forms a function, but specifying the input and output is part of what it is. Right ... so that would suggest we define a 'domain of discourse' before we figure out for which values the function is actually defined. I need to define a co-domain before the image makes sense. Same for the input: if you give me something like $f(x) = 1/x$, I would first need to know the domain of discourse (real numbers? Complex numbers?) before I can figure out its actual domain of definition. Finally, if it is so important for functions to have a codomain in addition to an image, why is it that when I take the inverse of a function (assuming it has one), its codomain will always be the same as its image, namely the domain of the original function? It seems to me that if you do make a distinction between 'domain of discourse' and 'domain of definition', then right there you have your 'codomain' and 'image' of the inverse that actually can be different and serve their respective purposes for the inverse. So, my question is this:  why then don't we typically make a similar discrepancy on the input as we do on the output? (and yes, I believe some mathematical texts do make this distinction, but my question is why don't we typically make this distinction?)  Why don't we have two terms on the input side that are the conceptual counterparts of 'co-domain' vs 'image' on the output side?  Is this mere historical 'accident' and mostly a matter of 'well, we've always done things this way', or are there actual good practical reasons for this?","['math-history', 'functions', 'definition']"
1972590,Compute the integral $\int_{-1}^1 \frac{|x-y|^{\alpha}}{(1 - x^2)^{\frac{1+\alpha}{2}}}dx = \frac{\pi}{\cos(\pi \alpha/2)}$,"$$
\mbox{How to prove that}\
\int_{-R}^{R}\frac{\left\vert x - y\right\vert^{\alpha}}
{\left(R^{2} - x^{2}\right)^{\large\left(1+\alpha\right)/2}}
\,\mathrm{d}x = \frac{\pi}{\cos\left(\pi \alpha/2\right)}\
{\Large ?},
$$ where $-1 < \alpha < 1$ , $-R \le y \le R$ . Since the right hand side does not depend on $y$ , I suppose, there must be some physical interpretation. I'll be grateful for any hints.","['real-analysis', 'integration', 'definite-integrals']"
1972611,First order ODE with Dirac delta funtcion,"I am looking for a direct method to solve this first order ODE with Dirac delta funtcion $$\frac{dU(t)}{dt}+k^2U(t)=\frac{1}{\sqrt{2\pi}}\delta(t)$$ with the initial condition $U(0)=\frac{1}{\sqrt{2\pi}}$. The solution to this problem is $$U(t)=\frac{1}{\sqrt{2\pi}}e^{-k^2t}$$ My try The integrating factor for this ode is
$$I=e^{\int k^2 dt }=e^{ k^2 t  }$$ then multiplying both sides of the differential equation by  $\,\,e^{ k^2 t  }$, we get $$\frac{d }{d t}\left(e^{ k^2 t  } U(t)\right)=\frac{1}{\sqrt{2\pi}}e^{ k^2 t  } \delta(t)$$
Integrating both sides, we have $$e^{ k^2 t  } U(t)=\frac{1}{\sqrt{2\pi}}\int{e^{ k^2 t  } \delta(t)}dt+C$$ From here on, I am lost. Any suggestions? Back ground of this problem The above ode we got after applying Fourier transform to the following PDE
$$u_{t}=u_{xx}+\delta{(x)}\delta{(t)}$$
with $u(x,0)=\delta(x)$.","['dirac-delta', 'ordinary-differential-equations']"
1972630,Completeness of induced metric on quotient,"Let $(X,d)$ be a metric spaces and $G$ a discrete group which acts by isometries on $X$ and the action is properly discontinuous. Then it's possible to define an induced metric $\hat{d}$ on the quotient space $\hat{X}:=X/G$ saying that the distance between two orbits is the infimum of the distance between any pair of representatives. I've read that the completeness of $(\hat{X},\hat{d})$ implies the completeness of $(X,d)$, but I can't work out the proof. Suppose $x_n$ is a Cauchy sequence for $d$, then, if $\hat{x}_n$ is the sequence of orbits in $\hat{X}$, $\hat{x}_n$ is Cauchy for $\hat{d}$ in $\hat{X}$. Then we know there exists $\hat{x}\in \hat{X}$ which is the limit point of $\hat{x}_n$ in $\hat{X}$ for $\hat{d}$. But I can't see why this should imply the existence of a limit point $x$ for $x_n$ in $X$ for $d$.","['general-topology', 'metric-spaces']"
1972633,What is the difference between moment projection and information projection?,"Moment projection is defined as $$\text{arg min}_{q\in Q} D(p||q)$$ while information projection is defined as $$\text{arg min}_{q\in Q} D(q||p)$$. Aside from the difference in the formula, how should one interpret the difference in the two measure intuitively? And when should one use moment projection over information projection, and vice versa?","['map-projections', 'probability']"
1972652,Probability an 6 sided die will be higher than a 8 sided die?,"Say one person rolls an 8 sided die and the other rolls a six, what is the probability that the six sided die is higher than the 8? I know that the expected value of the eight is 4.5 and the six is 3.5 but am having trouble figuring out how to find the probability. EDIT: Answer is 15/48 but still curious if there's a way of doing this without creating a grid.","['probability', 'dice']"
1972659,Dividing a set into 3 'unlabeled' subsets,"So I have a problem from an old exam in my Discrete Mathematics-course where I come to a conclusion that feels logical enough for me, but it's not the correct one - please help me realize where I'm going wrong. The problem is as follows; In how many ways can the set {A,B,C,D,1,2,3,...,12} be divided into 3 'unlabeled' subsets
so that A and B are in different subsets and 1, 2 and 3 are in different subsets aswell? The way I've thought it about is this; 1) Put 1, 2 and 3 into one subset each, making all the 3 subsets labeled. 
2) Find the total amount of combinations that are now available (not considering the first
constraint): 3^13 since all the 13 remaining objects can be placed in one of the three
subsets. 
3) Subtract the number of combinations in which A and B are in the same subset => I got this
to 3 * 3^11 since A and B can be put in any of the 3 subsets and then the remaining 11 
objects can be put in any of the 3 subsets.
4) Get the final answer 3^13 - 3 * 3^11 = 3^13 - 3^12. However, the answer is supposed to be $6 * 3^{10} $","['combinatorics', 'discrete-mathematics']"
1972662,Are there infinite number of sizes of gaps between primes?,"Are there an infinite number of sizes of gaps between primes? let $p_n$ be the nth prime number.  Let $g_n = p_{n+1} - p_n$  (i.e. size of gaps between consecutive primes). As $p_n$ goes to infinity, does $g_n$ go to infinity also?",['number-theory']
1972714,Must subgroups sharing a common element be nested in each other?,"Let $H$ and $K$ be subgroups of a group $G$ which have a common element besides the identity. Does this mean that either $H$ or $K$ is a subgroup of other? Let $a$ be the common element, then both subgroups contain the subgroup generated by $a$. I know it is possible for a subgroup to have an element which is not in other subgroup. Any counterexamples?",['group-theory']
1972717,Finding perturbed eigenvectors in degenerate first order perturbation theory,"Consider a symmetric matrix $H(t)$ parametrized smoothly by $t\in\mathbb R$.
Suppose there are orthonormal eigenvectors $\phi_i(t)$ with corresponding eigenvalues $\lambda_i(t)$:
$$
H(t)\phi_i(t)=\lambda_i(t)\phi_i(t).
\tag{1}
$$
Given $H(0)$ and $H'(0)$, I would like to find $\phi_i'(0)$.
If $H(0)$ has degenerate eigenvalues, I do not see how to find all components of the eigenfunctions corresponding to a degenerate eigenvalue at $t=0$.
Let me elaborate.
$\newcommand{\ip}[2]{\langle#1,#2\rangle}$ Let me drop the argument $(t)$ whenever $t=0$.
First, the eigenvectors are normalized, yielding
$$
\ip{\phi_i'}{\phi_i}=0.
\tag{2}
$$
Differentiating (1) with respect to $t$ at $t=0$ gives
$$
H'\phi_i
+H\phi_i'
=
\lambda_i'\phi_i
+\lambda_i\phi_i'.
\tag{3}
$$
Taking inner product with $\phi_i$ and using symmetry and (2) gives
$$
\lambda_i'=\ip{\phi_i}{H'\phi_i}.
\tag{4}
$$
These are the first order perturbations of the eigenvalues. I also want to find the first order perturbation of the eigenvectors, $\phi_i'$.
Doing so is equivalent with finding the inner product $\ip{\phi_j}{\phi_i'}$ for all $j$. Taking inner product of (3) with $\phi_j$ for $j\neq i$ gives
$$
\ip{\phi_j}{H'\phi_i}
=
(\lambda_i-\lambda_j)\ip{\phi_j}{\phi_i'}.
$$
Thus if $\lambda_j\neq\lambda_i$, we obtain
$$
\ip{\phi_j}{\phi_i'}
=
\frac{\ip{\phi_j}{H'\phi_i}}{\lambda_i-\lambda_j}.
\tag{5}
$$
On the other hand, if $\lambda_j=\lambda_i$, we obtain $\ip{\phi_j}{H'\phi_i}=0$.
That is, the block of $H'$ corresponding to the eigenspace of $H$ of eigenvalue $\lambda_i$ is diagonal.
We have freedom in choosing the orthonormal basis when the spectrum degenerates, and it must be chosen in this way to make $\phi_i(t)$ depend continuously on $t$.
Therefore the diagonal values in (4) are in fact eigenvalues of this block matrix. For $i=j$ the desired inner product $\ip{\phi_j}{\phi_i'}$ is given by (2).
If $i\neq j$ and $\lambda_i\neq\lambda_j$, it is given by (5). But what is the inner product $\ip{\phi_j}{\phi_i'}$ when $i\neq j$ and $\lambda_i=\lambda_j$? It seems to me that the presented calculations give no constraints.
I have lost no information by taking the inner product of (3) with all $\phi_j$ and looking at all the inner products instead of the vector equation.
I must be missing something. (This puzzled me for quite a while and I found no answer elsewhere, so I decided to share the question and an answer here. Actually, I figured it out while writing this question. Other answers are very much welcome!)","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra', 'perturbation-theory']"
1972732,Adding a function of a subset over all possible subsets,"So the context that I have for this problem comes from what I'm currently working on, but I can reduce the point that I'm stuck at to a more abstract problem. Since it stems from another problem, I can give more details about the nature of relevant terms if it simplifies anything. Consider some set of positive numbers $X=\{x_1\cdots x_n\}$. Let $S_k$ be a $k$ element subset of $X$. Define $D_{S_k} = \sum_{x\in S_k} x$. What I'm interested in is expressing $\sum_{S_k} f(D_{s_k})$ in terms of statistics of the set $X$ and the function $f$, where $\sum_{S_k}$ is to be interpreted as a sum over all possible $k$ element subsets of $X$. Now, for simple functions like $f(x)=x$, I can show that 
$$\sum_{S_k} D_{s_k} = \sum_{S_k} k\langle X\rangle = \binom{n}{k}k\langle X \rangle$$
and similarly for $f(x)=x^2$ I can show that $\sum_{S_k} D_{s_k}^2 = \binom{n}{k}\times\left((k\langle X \rangle)^2 + k (\langle X^2 \rangle - \langle X \rangle^2)\right)$. I can similarly solve for $f(x)=x^n$. Now where I'm stuck at, is in getting expressions for when $f(x)=1/x$ or $f(x)=1/x^2$. Of course if someone could tell me how to go about doing this for general $f$ that would be great, but right now just $f$ in these two forms could be pretty helpful. If it helps, in my context $x_i\in \mathbb{N}$. EDIT: So it turns out that just $f(x)=1/x$ and $f(x)=1/x^2$ wont suffice for my context, rather I'll need $f(x)=1/x^r$ for arbitrary $r\in \mathbb{N}$ for the purposes of my problem where I'm coming up with this. I guess that only makes things worse. Any ideas on how to proceed? EDIT2: I have also posted this on Math Overflow here EDIT3: Does anyone have any idea about possible directions or maybe other problems that are somewhat similar in nature to what I need?","['binomial-coefficients', 'symmetric-polynomials', 'combinatorics', 'summation', 'random-variables']"
1972856,In what sense is $S^\infty$ the same as $\{x \in \ell_2 : \|x\| = 1 \}$?,"I hear things that sound like topologists equate $S^\infty$ (defined as the union or ""directed colimit"" of $n$-spheres) with the actual unit sphere in, say, a nice vector space like $\ell_2$. In what sense is this a rigorous statement? Are they homeomorphic? Or is it weaker?","['algebraic-topology', 'general-topology', 'banach-spaces', 'differential-topology']"
1972860,Avoiding the limit notation during long algebraic manipulations,"For example, look at this: $$
\begin{align}
\lim_{x \rightarrow \infty}\frac{x}{x+1} &= \lim_{x \rightarrow \infty}{\frac{\frac{x}{x}}{\frac{x}{x}+\frac{1}{x}}}\\
&= \lim_{x \rightarrow \infty}{\frac{1}{1+0}} \\
&= \lim_{x \rightarrow \infty}{\frac{1}{1}} \\
&= \lim_{x \rightarrow \infty}{1} \\
&= 1 \\
\end{align}
$$ Maybe this isn't the best example as most of those steps are unnecessary, but sometimes you end up with something like that, having to write $\lim_{x \rightarrow \infty}$ over and over again. Is there any notation or method one can use to avoid having to do this?","['notation', 'limits']"
1972888,A version of the Riemann existence theorem,"While I was reading these notes , I've found the following version of the so called ""Riemann existence theorem"". Do you know any reference for the proof of this statement ? Remark: In the algebraic setting, the result is very easy to show because the sheaf of meromorphic functions $\mathscr M_X$ is replaced by the locally constant sheaf given by the function field $K(X)$ (see this question ). I think that the key word here is ""GAGA""but I don't know exactly how to use it.","['algebraic-curves', 'riemann-surfaces', 'sheaf-theory', 'algebraic-geometry']"
1972922,Is the Laplace transform a linear operator?,"Many sources online states that the Laplace transform $\mathcal{L}: V \to W,  f(t) \mapsto F(s)$ is a linear operator For example: http://www2.fiu.edu/~aladrog/PropLaplaceTransform.pdf ( Wayback Machine ) http://www.saylor.org/site/wp-content/uploads/2013/04/ME401-1.2.2-LaplaceTransform.pdf However, closely examining the definition of linear operator on Wikipedia, it says: In mathematics, a linear map (also called a linear mapping, linear
transformation or, in some contexts, linear function) is a mapping V →
W between two modules (including vector spaces) that preserves (in the
sense defined below) the operations of addition and scalar
multiplication. An important special case is when V = W, in which case the map is
called a linear operator ,[1] or an endomorphism of V. Do we know that the Laplace transform is a endomorphism? It doesn't seem plausible given that we are taking a function in time domain, say $L_2[0, \infty)$ space, and mapping it into $H_2$ space So should the Laplace transform be a linear operator?","['fourier-analysis', 'laplace-transform', 'signal-processing', 'operator-theory', 'functional-analysis']"
1972962,finite morphism is proper,"I've got stuck in the exercise II.4.1 in Hartshorne. Note that it is ""a finite morphism is proper"". Most of the solutions starts with ""Proper morphism is local on the base..."" and uses valuative criterion without noetherian hypothesis. But it is on the corollary 4.8 which needs noetherian hypothesis. Hartshorne give me a notice for noetherian hypothesis but I cannot read french (EGA). So, Can you give me tight condition for valuative criterion? Do corollary 4.6 and 4.8 (Properties of separated or proper morphisms) need any additional condition (like noetherian) or need only separatedness/properness?","['schemes', 'algebraic-geometry']"
1972992,Looking for a reference to a proof of $(I - A)^{-1} = I + A + A^2 + A^3 + \ldots$,"On some online forum, there is the claim: Given some square matrix: $$(I - A)^{-1} = I + A + A^2 + A^3 + \ldots$$ This is true if the right side converges, which is true if and only if
  all of the eigenvalues of A have absolute value smaller than $1$. Reference https://www.physicsforums.com/threads/matrix-inverse-equals-power-series.423897/ I really like this result, because it relies on the more intuitive spectral radius rather than matrix norm which is defined as: \begin{align} \|A\| &= \sup\{\|Ax\| : x\in K^n \mbox{ with }\|x\|= 1\} \\ &= \sup\left\{\frac{\|Ax\|}{\|x\|} : x\in K^n \mbox{ with }x\ne 0\right\}. \end{align} Can someone provide a reference to the proof of this claim?","['matrices', 'reference-request', 'matrix-calculus', 'sequences-and-series', 'linear-algebra']"
1972994,A circle inside an ellipse,"Consider an ellipse with semi-axes $a$ and $b$, taller than it is wide with a small circle of radius $r$ inside.  Assume the circle falls to the lowest point possible while staying inside the ellipse. If $2r\le a-c$ then the circle and ellipse will meet at a single point at the bottom. If $2r>a-c$ the circle and ellipse will intersect at two points on the opposite side, leaving a space between the bottom of the circle and the bottom of the ellipse. For this case, given the radius of the circle and the dimensions of the ellipse how do I calculate the distance $d$ between the bottom of the circle and the bottom of the ellipse?","['circles', 'conic-sections', 'geometry']"
1972996,On the Cramér-Granville Conjecture and finding prime pairs whose difference is 666,"Questions If $p= \text{NextPrime}[q]$ (the smallest prime greater than $p$), and $p-q = 666,$ what are $p$ and $q$? (There may be multiple choices. I am interested in finding one.) Cramér-Granville Conjecture: Defining $p_0=2$, and $p_n$ as the nth odd prime, and the nth prime gap as $g_n=p_{n+1}-p_n$, then  $g_n< M \log(p_n)^2$ for some $M>1$. Reference link: http://mathworld.wolfram.com/Cramer-GranvilleConjecture.html If $g_n =666$,  what are generally good estimates for $M$ and $p_n$ according to the
Cramér-Granville Conjecture? Can we make use of current sieve technology and probabilistic modeling to solve our problem efficiently? Commentary & Previous Work If $g_n = 666$ and $p_n = 18691113008663$, then the conjecture is satisfied for any $M>1$. We let  $\text{primegap}_{avg} = x/\pi(x) = g_n = 666$. 
If $\pi(x) = x/(li(x) + sqrt(x) * log(x)/(8\pi))$, then we have  $x/\pi(x) = 666$ which implies $x = 4.73231\times10^{289}$ and $\pi(x) =7.10558\times10^{286}$.  So our upper bound estimate of $p_n$ will be less than $4.73231\times10^{289}$. Therefore, we shall focus our attention on finding consecutive prime pairs whose difference is $666$ in the open interval, $(18691113009329, 4.73231*10^{289})$. And we should expect to find approximately $(c/333)(\pi(4.73231×10^{289})-\pi(18691113009329)) = c *7.10558×10^{286}/333$, or $c * 2.133808*10^{284}$ consecutive prime pairs whose difference is $666$ where 
$0.5 < c < 1$. Note:  $c \to 1$ as $x\to\infty$ according to the Polignac Conjecture. Furthermore, we also expect to discover sufficiently many prime gaps greater than $666$ in the open interval, $(18691113009329, 4.73231×10^{289})$, so that the prime gap density or average of $666$ is maintained.  And according to the Cramér-Granville Conjecture, the maximum prime gap of $\log(4.73231\times10^{289})^2 = 444892$, more or less, exists in the open interval. Reference links https://terrytao.wordpress.com/2009/08/18/the-least-quadratic-nonresidue-and-the-square-root-barrier/#comment-472548 ; http://www.ams.org/journals/mcom/1989-52-185/S0025-5718-1989-0947470-1/S0025-5718-1989-0947470-1.pdf/ ; https://en.wikipedia.org/wiki/Polignac%27s_conjecture ; https://www.quora.com/What-great-conjectures-in-mathematics-combine-additive-theory-of-numbers-with-the-multiplicative-theory-of-numbers/answer/David-Cole-146 ; https://terrytao.files.wordpress.com/2009/08/prime-number-theory1.pdf ; Boeyens, Jan C. A.; Levendis, Demetrius C. (2008), Number Theory and the Periodicity of Matter, Berlin: Springer-Verlag, ISBN 978-1-4020-6659-7; 'A Primer in Density Functional Theory', http://link.springer.com/book/10.1007%2F3-540-37072-2 ; https://www.wired.com/2016/11/physicists-uncover-strange-numbers-particle-collisions/ . “Repetition and growth of prime gaps are essential for the efficient generation of the integers.”","['number-theory', 'sieve-theory', 'probability', 'mathematical-modeling', 'prime-numbers']"
1973015,Contrapositive of the statement with quantifiers,"$\forall x$, $2 |x \implies x^2 = 4$ False statement but lets go with it Find the contrapositive: Would it be, $\forall x$ $x^2 \ne 4 \implies 2 \not | x$ OR $\exists x$ $x^2 \ne 4 \implies 2 \not | x$ Question: whenever we take a negation of an implication with a quantifier, must we negate that too?","['algebra-precalculus', 'proof-writing']"
1973045,Function to express a stick sliding until it hits the floor,"I have a stick standing leaning against a wall. On the exact middle of the stick, I have painted a red dot. The stick is sliding until it hits the floor. What figure does the red dot 'draw in the air' and how do I find the function expression for this 'pattern'/'figure'? I have painted this figure of the situation: The black line is the wall and the grey line is the stick with the red dot. The stick is first standing against the wall (figure 1) and then slides slowly until it hits the floor (figure 4). I guess it follows one of these patterns (green path, blue path, pink path), and it might be possible to draw this pattern using a trigonometric function.","['puzzle', 'trigonometry', 'functions']"
1973149,Integration Question with Root of Trigonometric functions at the Bottom,"$$\int ^{\frac{\pi}{2}} _{0} \frac{dx}{\sqrt{(1+\mathrm{cos}\ x)(\mathrm{sin}\ x + \mathrm{cos}\ x)}}$$
I tried using double angle formula to convert $\sqrt{(1+\mathrm{cos}\ x}$ to $\sqrt{2}\ \mathrm{cos}\ \frac{x}{2}$ and then $\sqrt{\mathrm{sin}\ x + \mathrm{cos}\ x} = \sqrt{2\ \mathrm{sin}\ \frac{x}{2}\ \mathrm{cos}\ \frac{x}{2} + 1 - 2\ \mathrm{sin}^2 \frac{x}{2}}$ =  $\sqrt{(\mathrm{sin}\ \frac{x}{2} + \mathrm{cos}\ \frac{x}{2})^2 - \ 2\ \mathrm{sin}^2 \frac{x}{2}}$. But I am not sure what to do after that. Also I tried $f(x) = f(\frac{\pi}{2} - x)$ and then adding them together and then using double angle formulas like above, but I still couldn't solve it. Any help is greatly appreciated.","['integration', 'trigonometry']"
1973228,Why is this function not a solution to this ODE?,"If we consider the autonomous ODE: $\frac{dx}{dt} = f(x) = ax$, where $a$ is in $\mathbb{R}$, $x(0) = x_{0}$ then this has a unique solution for every initial condition $x(0) = x_{0}$ since $f$ is continuous and so is $\frac{df}{dx}$, namely: $x(t) = x_{0}e^{at}$. But if we just consider the initial condition $x(0) = 0$, fix a constant $b > 0$, and define a function: $z(t) = e^{a(t - b)}$    if $t > b$, and   $z(t) = 0$     if $t \leq b$. Now I differentiated and plugged it into the ODE (not realising there was a discontinuity at $t = b$) and found that it seemed to be a solution to the IVP ($x(0) = 0$) - if this was a solution to the IVP  for any choice of $b$, then it would violate uniqueness of solutions as we would have infinitely many choices of $b$ that we could make - so clearly it is not a solution to the IVP, since we already know $x(t) = 0$ for all $t$ is a solution to the IVP, and $z \neq x$. But why is $z(t)$ not a solution? Someone pointed out to me that it was because $z(t)$ was discontinuous at $t = b$ and was clearly not differentiable there - initially I found this satisfactory but then I looked at another example in my lecture notes: $\frac{dx}{dt} = x^2$, $x(0) = x_{0}$ The solution is $x(t) = \frac{x_{0}}{1 - x_{0}t}$, and it was said that the solution 'blows up' for $t = \frac{1}{x_{0}}$ as we are dividing by 0 there. But this solution is discontinuous and not differentiable at $t = \frac{1}{x_{0}}$ just like $z$, but is being recognised as a solution. Indeed, my lecture notes say the solution is only for 'finite time'. What does this mean? So do we say $z$ is a solution only for 'finite time'? What would/does this mean, that we ignore the point $t = b$? But then we still have the problem of this being a different solution to $x(t) = 0$. I am very confused by this and feel I must have misunderstood something somewhere. Hopefully I haven't been too vague or unclear - I'd be happy to clarify anything in the comments! Any help would be greatly appreciated! Thanks!","['ordinary-differential-equations', 'proof-verification']"
1973229,Two versions of the Fredholm alternatives,"Here are two version of the Fredholm alternatives among which I would like to know the relation: One version is from the appendix of Evans's Partial Differential Equations: Here $H$ is a Hilbert space. Another version is from an old post in Terry Tao's blog: Having gone through the details of each of the theorems above, I have the following questions : Can one get Theorem 5 from Theorem 1 by making $\lambda=1$? Are these two versions of the Fredholm alternatives equivalent when
$X$ is assumed to be a Hilbert space in Theorem 1?",['functional-analysis']
1973255,Why is $A = \begin{bmatrix} 0 & 1 \\ 0 & 0 \end{bmatrix}$ not diagonalizable,"I have a number of sufficient conditions as to when a matrix $A$ is diagonalizable, namely: When $A$ is symmetric When $A$ has distinct eigenvalues Given $A = \begin{bmatrix} 0 & 1 \\ 0  & 0 \end{bmatrix}$ $A$ has nondistinct eigenvalues $\lambda = 0$ with algebraic multiplicity $2$, is there some conditions that says this is when the matrix fails to be diagonalizable?","['matrix-equations', 'matrices', 'diagonalization', 'linear-transformations', 'linear-algebra']"
1973270,Periodic light rays in ellipse,"I was just fiddling with GeoGebra when I found this: imagine a light ray in an elliptical mirror; whenever I choose a point $A$ on the ellipse and a positive integer $n$, I can adjust $B$ so that the ray starting from $A$ and going towards $B$ returns to $A$ and touches the ellipse in exactly $n$ points.
Here are some examples. The last picture shows 28 reflections. First of all, is this true? If so, is it possible to prove it with not too advanced tools? Is this a peculiarity of the ellipse only, or there are other curves with the same property?","['conic-sections', 'reflection', 'geometry']"
1973271,Proof of 'sandwich theorem' for sequences,"Please bear with me here and please try to read it all and spot any mistakes or errors as I'm trying to prove this result but I'm unsure of whether I have done it or not. THANK YOU. Suppose we have the following statement $(a_n)\rightarrow \ell , (b_n)\rightarrow \ell $ and we have $$a_n\leq c_n\leq b_n$$ then $(c_n)\rightarrow \ell $.
I think I have a proof which goes as follow ;
$$a_n\leq c_n\leq b_n\leq  \ \Rightarrow 0\leq c_n-a_n\leq b_n-a_n $$, as the terms are all larger than 0, taking the absolute value will not change any of the signs of the inequalities. So we have $$0\leq |c_n-a_n|\leq|b_n-a_n|. $$
Now consider $$|b_n-a_n|=|(b_n-\ell )+(\ell - a_n)|\leq |b_n-\ell |+|a_n - \ell | \text{ (by triangle inequality)} .$$
Using the definition of a sequence tending to a value, if $(a_n)\rightarrow \ell $ then $\exists N_1\in \mathbb{N} \text{ s.t} \ \forall n>N, |a_n-\ell |<\epsilon \ ,\forall \epsilon >0 .$
We do the same for $(b_n) $ but replacing $N_1 $ with $N_2$ and using the same $\epsilon $ without loss of generality. 
So we can now say that $$|b_n-a_n|\leq |b_n-\ell |+|a_n - \ell |<2\epsilon . $$
So we have $$0\leq |c_n-a_n |\leq|b_n-a_n|<\epsilon _0, \text{ where } \epsilon _0=2\epsilon .$$
So we can conclude (using sandwich theorem for null sequences) that $(c_n-a_n)\rightarrow 0 \Rightarrow (c_n)\rightarrow (a_n)\Rightarrow (c_n)\rightarrow \ell $ since $(a_n)\rightarrow \ell . \ \ \ \square $","['real-analysis', 'sequences-and-series', 'analysis']"
1973280,Show $\frac{2}{\pi} \mathrm{exp}(-z^{2}) \int_{0}^{\infty} \mathrm{exp}(-z^{2}x^{2}) \frac{1}{x^{2}+1} \mathrm{d}x = \mathrm{erfc}(z)$,"I used the result $$\frac{2}{\pi} \mathrm{exp}(-z^{2}) \int\limits_{0}^{\infty} \mathrm{exp}(-z^{2}x^{2}) \frac{1}{x^{2}+1} \mathrm{d}x = \mathrm{erfc}(z)$$ to answer this MSE question . As I mentioned in the link, I obtained this result from the DLMF . I happened to find this solution after failing to evaluate the integral using a variety of substitutions. A solution would be appreciated. Addendum Expanding @Jack D'Aurizio's solution, we have \begin{align}
\frac{2}{\pi} \mathrm{e}^{-z^{2}} \int\limits_{0}^{\infty} \frac{\mathrm{e}^{-z^{2}x^{2}}}{x^{2} + 1} \mathrm{d}x &=
\frac{2z}{\pi} \mathrm{e}^{-z^{2}} \int\limits_{0}^{\infty} \frac{\mathrm{e}^{-t^{2}}}{z^{2} + t^{2}} \mathrm{d}t \\
&= \frac{z}{\pi} \mathrm{e}^{-z^{2}} \int\limits_{-\infty}^{\infty} \frac{\mathrm{e}^{-t^{2}}}{z^{2} + t^{2}} \mathrm{d}t
\end{align}
we used the substitution $x=t/z$. For the integral
\begin{equation}
\int\limits_{-\infty}^{\infty} \frac{\mathrm{e}^{-t^{2}}}{z^{2} + t^{2}} \mathrm{d}t
\end{equation}
we let $f(t) = \mathrm{e}^{-t^{2}}$ and $g(t) = 1/(z^{2} + t^{2})$ and take Fourier transforms of each,
\begin{equation}
\mathrm{F}(s) = \mathcal{F}[f(t)] = \frac{\mathrm{e}^{-s^{2}/4}}{\sqrt{2}}
\end{equation}
and
\begin{equation}
\mathrm{G}(s) = \mathcal{F}[g(t)] = \frac{1}{z}\sqrt{\frac{\pi}{2}} \mathrm{e}^{-z|s|}
\end{equation}
then invoke Parseval's theorem \begin{equation}
\int\limits_{-\infty}^{\infty} f(t)\overline{g(t)} \mathrm{d}t 
= \int\limits_{-\infty}^{\infty} \mathrm{F}(s)\overline{\mathrm{G}(s)} \mathrm{d}s
\end{equation}
dropping constants, the integral becomes \begin{align}
\int\limits_{-\infty}^{\infty} \mathrm{e}^{-s^{2}/4} \mathrm{e}^{-z|s|} \mathrm{d}s
&= 2\int\limits_{0}^{\infty} \mathrm{e}^{-s^{2}/4} \mathrm{e}^{-z|s|} \mathrm{d}s \\
&= 2\mathrm{e}^{z^{2}} \int\limits_{0}^{\infty} \mathrm{e}^{-(s+2z)^{2}/4} \mathrm{d}s \\
&= 4\mathrm{e}^{z^{2}} \int\limits_{0}^{\infty} \mathrm{e}^{-y^{2}} \mathrm{d}y \\
&= 2\sqrt{\pi}\mathrm{e}^{z^{2}} \mathrm{erfc}(z)
\end{align}
We completed the square in the exponent and used the substitution $y=z+s/2$. Putting the pieces together yields our desired result
\begin{align}
\frac{2}{\pi} \mathrm{e}^{-z^{2}} \int\limits_{0}^{\infty} \frac{\mathrm{e}^{-z^{2}x^{2}}}{x^{2} + 1} \mathrm{d}x &=
\frac{z}{\pi} \mathrm{e}^{-z^{2}} \int\limits_{-\infty}^{\infty} \frac{\mathrm{e}^{-t^{2}}}{z^{2} + t^{2}} \mathrm{d}t \\
&= \frac{z}{\pi} \mathrm{e}^{-z^{2}} \frac{1}{\sqrt{2}} \frac{1}{z} \sqrt{\frac{\pi}{2}} 2\sqrt{\pi} \mathrm{e}^{z^{2}} \mathrm{erfc}(z) \\
&= \mathrm{erfc}(z)
\end{align}","['special-functions', 'integration', 'definite-integrals', 'error-function']"
1973295,Using Poisson to find probability in a range,Suppose the counts recorded by a Geiger counter follow a Poisson process with an average of three counts per minute. What is the probability that the first count occurs between 1 and 2 minutes after start-up? $\lambda=3$ per minute Am I supposed to calculate $P(X=2)-P(X=1)$? And would $\lambda$ change between those two terms because of the different time intervals? Very confused.,"['statistics', 'probability']"
1973340,Prove that finite unions of compact sets are compact,"The question is: let $F_1, ... F_n$ be compact subsets of X. Show that $\cup^{N}_{n=1} F_n$ is compact. know that a set $ F  \subset X$ is compact if every open cover $\mathcal {G}$ of F contains a finite subcover $\mathcal {H}$. Intuitively, I think that since $F_1, .. F_n$ are compact, they contain finite subcovers and so $\cup^{N}_{n=1} F_n$ at most has finite subcovers. I'm just stuck at trying to formally prove this out. Help would be much appreciated!","['general-topology', 'real-analysis']"
1973344,"Be $f:\;(a,b)\rightarrow\mathbb{R}$ a continuous function. Suppose $c\in(a,b)$ ...","I got a problem with this theorem: Theorem: Let $f:\;(a,b)\rightarrow\mathbb{R}$ be a continuous function. Suppose $c\in(a,b)$ is such that f is differentiable in $(a,c)$and in $(c,b)$ and $\lim_{x\rightarrow c}f'(x)=L$. Prove $f$ is differentiable in $c$ and $f'(c)=L$ Proof: $$\lim_{x\rightarrow c}\frac{f(x)-f(c)}{x-c}=\lim_{x\rightarrow c}\frac{f(c)-f(x)}{c-x}=\lim_{x\rightarrow c}f'(x)=L$$ Then $f'(c)$ exists and $f'(c)=L$ Is my proof fine?","['derivatives', 'real-analysis', 'real-numbers', 'calculus']"
1973351,Directional directive vs partial derivative,"Can someone clarify the relationship between directional derivative and partial derivatives for a function from $\mathbb{R}^n$ to $\mathbb{R}$? To my understanding, if the function is continuously differentiable, then both directional and partial derivatives exist. Is that correct? Consider this function: 
\begin{align}
f(x,y) = 
\begin{cases} 
     \sin( \frac{y^2}{x})\sqrt{x^2 + y^2}& x \ne 0 \\
      0 &  x = 0
   \end{cases}
\end{align}
How would one verify this function has direction derivatives at $(0,0)$?","['multivariable-calculus', 'real-analysis']"
1973369,Right-angled Triangle and Triangles Inside it,Let $ABC$ be a right-angled triangle with |AB|=|BC|. Let $D$ and $E$ be points on the side $BC$ satisfying $|BD|=|CE|$. Let $P$ be the intersection point of the line through $B$ perpendicular to $AD$ with the side $AC$. Prove that $\angle PEC=\angle ADB$ Any hints? Thanks,"['euclidean-geometry', 'geometry']"
1973397,Cardinality function is measurable,"Let $f: [0,1] \rightarrow \mathbb{R}$ be a continuous function. Let also $g$ be a function, defined by the following condition:for each $a \in [0, + \infty]$ $$g(a)=\text{card} \{ x \in [0, 1] | f(x) = a \} \in [0, + \infty)$$ I would like to prove that $g$ is also a measurable function.  Are there any hints that might help? Probably, it is worth trying to prove it more or less directly, by checking that $\{ a \in [0, + \infty] | g(a) < c \}$ is measurable for any $c$, but this approach does not seem to be clear enough, since the preimage of $g$ would be some cardinal number.","['real-analysis', 'lebesgue-integral', 'measure-theory', 'lebesgue-measure']"
1973432,"Prove that if $a \ge c$ for all $c < b$, then $a \geq b$","Let $a$ and $b$ be elements in an ordered field, prove that if $a \ge c$ for every $c$ such that $c \lt b$, then $a\ge b$. My proof idea below: Let $S = \{x | x<b\}$. Then $a$ is an upper bound for $S$. If I can show that $b$ is the least upper bound for $S$, then it follows from the definition of least upper bound that $a\ge b$. However, I have a hard time proving the claim that $b$ is the least upper bound for $S$. Am I on the right direction? Can anyone help? Thank you.",['real-analysis']
1973441,How to prove this is homeomorphism?,"Let $\Bbb R^n \cup\{\infty\} $ be the Alexandroff compactification of  $\Bbb R^n$. Prove that the function $\phi:\Bbb R^n \cup\{\infty\}\rightarrow\Bbb R^n \cup\{\infty\}, \ $ $\phi(x)=x/|x|^2$ if $ x\neq0,\infty$, $\phi(0)=\infty$ and $\phi(\infty)=0$ is an homeomorphism. It's clear in case $x\neq0,\infty,$ but I don't know how to prove the continuity in the zero and infinity points. I also know if $\phi$ is continuous, then it's an homeomorphism because $\phi=\phi^{-1}$.","['general-topology', 'differential-geometry']"
1973470,For which polynomials $p\in\mathbb{C}[w]$ are the branches of the inverse $p^{-1}$ expressible using algebraic operations?,"The collection of all degree-$n$ polynomials in the variable $w$ (call this set $\mathbb{C}[w]_n$) can be identifies with $\mathbb{C}^{n+1}$ by the bijection $F:\mathbb{C}^{n+1}\to\mathbb{C}[w]_n$ defined by $$F:(a_0,a_1,\ldots,a_n)\mapsto w=p(z)=a_0+a_1z+\cdots+a_nz^n.$$  Let $\mathcal{A}_n\subset\mathbb{C}^{n+1}$ denote the set of polynomials (using the above identification) defined by saying that $p(z)\in\mathcal{A}_n$ if and only if each branch of the inverse $z=p^{-1}(w)$ is expressible as an explicit formula using finitely many algebraic operations (ie addition/subtraction, multiplication/division, and roots).  That is, something like $$z=p^{-1}(w)=\sqrt{w+\sqrt{2/w}}.$$  Note that for any polynomial $p(z)\in\mathbb{C}^{n+1}$, either each branch of $p^{-1}$ is so expressible, or none is (since every branch can be reached as an analytic continuation of any other). My Question: What is the structure of $\mathcal{A}_n$ in $\mathbb{C}^{n+1}$?  Is it an algebraic variety?  What is its dimension?  What can we say about its topology?","['complex-analysis', 'galois-theory', 'polynomials', 'algebraic-geometry']"
1973478,When are conditional expectations differentiable?,"Let $(\Omega,\mathcal{F},P)$ denote a probability space and let $X:\Omega\to \mathbb{R}$ and $Y:\Omega\to \mathbb{R}$ denote two random variables with finite second moments. Let $g_0: \mathbb{R} \to \mathbb{R}$ be a measurable function that minimizes
$$
E(X - g(Y))^2
$$ 
over all measurable functions $g$. 
$g_0(Y)$ is the conditional expectation of $X$ given $Y$. Are there general conditions under which $g_0$ is known to be absolutely continuous?","['probability-theory', 'conditional-expectation', 'measure-theory']"
1973487,F-relatedness and product vector field,"Let $M_1, M_2$ be smooth manifolds. $f: M_1 \times M_2 \longrightarrow M_1$ be the projection map. Let $X: M_1 \longrightarrow TM_1$ be a vector field. Show that there exists some vector field 
$$Y: M_1 \times M_2 \longrightarrow T(M_1 \times M_2)$$ Such that $Y \text{ and } X$ are $f$-related. I need to verify that $$(1) \ \ \ (f_*)_pY_p = X_{p_1} \forall p = (p_1,p_2)\in M_1 \times M_2 $$ which is equivalent to $\forall h \in C^{\infty}(M_1)$ $$(2) \ \ \ Y(h\circ f) = Xh \circ f $$ So I constructed such $Y$ where $Y_p = (X_{p_1}, 0_{p_2})$ where $0_{p_2} \in T_{p_2}M_2$ is just the zero derivation. It seems ""obvious"" that the zero derivation doesn't do anything therefore the second condition is ""automatic""? But I'm not sure how to formally state that and as of right now it seems sketchy.","['smooth-manifolds', 'differential-geometry']"
1973489,Prime divisors of $n! +k$,"For $n > 5$ and $1 < k < n+1$ prove that $n! + k$ has a prime divisor that is greater than $n$. This question appears as an exercise in the book ""Not always buried deep"" by Paul Pollack. There is a reference, but the paper is in German! It seems to be enough to prove the existence of a prime divisor of $n!+k$ that is greater than $k$ for if all prime divisors of $n!+k$ were less than $n+1$, then they would divide n! and hence would have to divide $k$. The case $k = 1$ is easy to handle, but am stuck for $k > 1$.",['number-theory']
1973523,Strong Induction: Prove $a_n=(-3)^n$,"I need help with the following problem. $a_0=1$ $a_1=-3$ $a_n=-2*a_{n-1}+3*a_{n-2}$, for all $n\ge2$ prove $a_n=(-3)^n$ I understand the base cases, I'm just confused on how to do the strong induction step. I know that we are showing that if P(n) is true then it must hold for P(n+1) but I don't know how to do that with $a_{n+1}$","['induction', 'discrete-mathematics']"
1973526,"Seemingly simple differential equation, $y'=(4x+y)/(x+4y)$","My friend has asked me for help solving the following differential equation (of which the explicit solutions are supposedly derivable): $$\frac{dy}{dx}=\frac{4x+y}{x+4y}\tag{1}$$ I have tried hitting it with every technique I know, but none of my efforts have proved fruitful. Could you help me out? All I can end up with is a complicated implicit solution. I will now outline every approach I have taken. (Note: I have tagged every equation for referencing convenience). [Homogeneous Substitution] This equation is manifestly homogeneous when put in the following form: $$\frac{dy}{dx}=\frac{4+\frac{y}{x}}{1+4\frac{y}{x}}\tag{2}$$ So let's try the substitution $u=y/x$. We can work out that $y'=xu'+u$, so plugging everything in gives us: $$xu'+u=\frac{4+u}{1+4u}\tag{3}$$ $$\implies \frac{u'}{\frac{4+u}{1+4u}-u}=\frac{1}{x}\tag{4}$$ I can solve this by integrating both sides with respect to $x$ (left side requires heavy algebraic massaging): $$\ln \left|(1-u)^{-5/8}(1+u)^{-3/8}\right|=\ln |x| +C\tag{5}$$ After re-substituting $u=y/x$, this then simplifies down to $$(x-y)^5(x+y)^3=C\tag{6}$$ So the solution seems to be the solution to a eight-order polynomial, which I'm not sure can be solved for explicitly (well, it should be because why else would it show up on an entry-level DFQ homework assignment?). On top of that, a few of my previous steps have implicitly imposed domain restraints on my solution (e.g. every step where I divide by a quantity that could be zero). I've plotted the solution below, where I have taken note of the homogeneity of the original equation (the case where $C=0$ is special though - then the solutions are just $y=\pm x$). [Integrating Factor - Exact Equation] Ok, maybe the exact form of the solution is buried in that polynomial. Let's see if this can be made exact. Putting it in the standard form gives us: $$f(x,y)dx+g(x,y)dy=0,$$ $$~~\textrm{where}~ f(x,y)=(4x+y)~~\textrm{and}~~ g(x,y)=-(x+4y)\tag{7}$$ This isn't an exact equation by itself ($f_y\neq g_x$). Moreover, no integrating factor of one variable (either $x$ or $y$) will work because calculating the integrating factor involves calculating an integral like: $$\int \frac{\frac{\partial f}{\partial y}-\frac{\partial g}{\partial x}}{g(x,y)}dx\tag{8}$$ and we can't do that integral explicitly because the numerator is a constant for the specific $f(x,y)$ and $g(x,y)$ in this problem, while the denominator is a full function of $x$ and $y$. So this seems to be a no go. [Laplace/D'Alembert Equation Form] A [Laplace or d'Alembert equation][2] (no, not the Laplace's equation or d'Alembert's solution/formula) is first-order ordinary differential equation of the type $$y=xf(y')+g(y')\tag{9}$$ which can be morphed into the simpler linear equation: $$\frac{dx}{d(y')}=\left(\frac{f'(y')}{y'-f(y')}\right)x+\frac{g'(y')}{y'-f(y')}\tag{10}$$ I have found that I can manipulate the original differential equation into the desired form: $$y=\left(\frac{y'-4}{1-4y'}\right)x\tag{11}$$ from which we can read off (well, calculate really) the corresponding differential equation for $x(y')$: $$\frac{dx}{d(y')}=-\frac{15x}{4(1-y'^2)(1-4y')}\tag{12}$$ This is separable. Solving this gives me: $$\ln \left|\frac{(1-y')^{5/8}(1+y')^{3/8}}{4y'-1}\right|=\ln |x| +C\tag{13}$$ this seems to be the most highly nonlinear and implicit first-order differential equation that I have ever seen. I don't know what I could realistically do from here. ~~ADDENDUM~~ These are the exact instructions from the assignment $$\textrm{1. Find all solutions:}~~~~\frac{dy}{dx}=\frac{4x+y}{x+4y} $$ https://en.wikibooks.org/wiki/Ordinary_Differential_Equations/d%27Alembert","['ordinary-differential-equations', 'calculus']"
1973529,How does $\cos x=\frac12(e^{ix}+e^{-ix})$?,"I have seen the following definition many times:
$$\cos x=\frac12(e^{ix}+e^{-ix})$$ However, it makes little sense to me as it appears far from obvious. Please help me understand this definition, either a derivation or explanation of how the values on the right equal $\cos x$.","['trigonometry', 'complex-numbers']"
1973627,Help explaining Structural Induction,"I am trying to wrap my head around structural induction. Can someone break it down and explain it around this problem? Let S, a subset of $\mathbb{N}*\mathbb{N}$ , be defined recursively by: Base case: $(0,0)$ $\in S$ Constructor case: If $(m,n) \in S$ , then $(m+5,n+1) \in S$ Prove that if $(m,n) \in S$ , then m+n is a multiple of 3. How is it different than normal induction (using this example please) and what is the point of a Constructor case? Can someone wright the proof out so i can see what this structural induction proof looks like?","['induction', 'discrete-mathematics']"
1973666,Count the number of bit strings of length 14 that have exactly seven 0's and neither begin with 11 nor end in 11.,"I am stuck on this question. I tried doing this.
$$
_{14}C_7 - _{12}C_7 - (_{12}C_7 - _{10}C_7) = 1968
$$","['combinatorics', 'discrete-mathematics']"
1973667,Prove that if $\sqrt[n]{\prod\limits_{i\leq n}a_i}$ converges to a finite limit then $a_n$ converges,"Prove that if $$\lim_{n\to\infty} \sqrt[n]{\prod_{i\leq n}a_i} < \infty$$
then $\lim_{n\to\infty} a_n$ exists. Given that $\{a_i\}$ is bounded and positive. So I used Cesaro means to show that $\lim_{n\to\infty} \sqrt[n]{\prod_{i\leq n}a_i}  = \lim_{n\to\infty} a_n$ if the limit exists, but how to prove that the limit exists?","['cesaro-summable', 'sequences-and-series', 'limits']"
1973794,Modified tower of hanoi,"In  the  Tower  of  Hanoi  puzzle ,  suppose  our  goal  is  to  transfer  all  n  disks  from  peg  1  to  peg  3, but we cannot move a
 disk  directly  between  pegs  1  and  3 .  Each  move  of  a  disk
must  be  a   move  involving  peg 2 .  As usual ,  we  cannot
 place  a  disk  on  top  of  a  smaller  disk. My Attempt/Approach-: Using Basic Tower of  Hanoi,our goal is to transfer $n$ disks from peg1 to peg2 using peg3. Steps-: 1. Transfer  n-1 disks from peg1 to peg3 using $H_{n-1}$. 2. Move the $n$th disk from peg1 to peg2 (only 1 movement). 3. Transfer n-1 disks from peg3 to peg2 using $H_{n-1}$. so,We are done with $H_{n}=2H_{n-1}+1$. But ,i am not getting how to solve this algorithm using the restriction that "" Each move of a disk must be a move involving peg 2."" I know the solution to this question is here ,so i am writing steps as i get is Steps-: 1. Transfer  n-1 disks from peg1 to peg3 using $H_{n-1}$. 2. Move the $n$th disk from peg1 to peg2 (only 1 movement). 3. Transfer  n-1 disks from peg3 to peg2 using $H_{n-1}$ giving the same recurrence relation ..where i am wrong??","['recurrence-relations', 'discrete-mathematics']"
1973819,Determine the elements of a triangle knowing relationships between lengths and angles,"A triangle's sides' lengths are three successive numbers (meaning b=a+1, c=a+2). The smallest angle is a half of the triangle's biggest angle.
Find the area of this triangle and its angles. Solution: Sides are 4, 5 and 6. Area: $15\sqrt{7}/4$ Angles : $41° 24' 34""$ and $82°49'8""$",['trigonometry']
1973826,"What is the difference between the words ""variables"", ""constants"", ""parameters"" and ""arguments""?","This has been nagging me for a while and then I saw a question on English SE asking what the difference is between variables and parameters. In the context of mathematics, what is the difference between variables constants parameters arguments I get 1. and 2. confused because, for example the general form of the quadratic function is often expressed $f(x)=ax^2+bx+c, a \neq 0$ and $x$ is the variable so what does that make a,b and c? I assume since math is so rigorous with precise definitions, these have one, but it is also a valid answer that as words they do not have a single precise definition.","['functions', 'definition']"
1973864,"Minimal sufficient statistics for uniform distribution on $(-\theta, \theta)$","Let $X_1,\dots,X_n$ be a sample from uniform distribution on $(-\theta,\theta)$ with parameter $\theta>0$. It is easy to show that $T(X) = (X_{(1)},X_{(n)})$ is a sufficient statistic for $\theta$ where $X_{(1)}$ and $X_{(n)}$ stands for the minimum and the maximum from the sample $X_1,\dots,X_n$ respectively. I want to show that it is also minimal sufficient . To do so I look at the ratio of the densities $$
\frac{f(x_1,\dots,x_n;\theta)}{f(y_1,\dots,y_n;\theta)}
=
\frac{1_{[-\theta<x_{(1)}\leq x_{(n)}<\theta]}}{1_{[-\theta<y_{(1)}\leq y_{(n)}<\theta]}}
$$
We want to show that this ratio is a constant as a function of $\theta$ iff $(x_{(1)},x_{(n)})=(y_{(1)},y_{(n)})$. 1. question: how should I understand the ratio if it is not defined (e.g. $\frac{0}{0}$)? It is easy to show that if $(x_{(1)},x_{(n)})=(y_{(1)},y_{(n)})$ than the ratio is constant as a function of $\theta$ (if I neglect the problem of understanding the $\frac{0}{0}$ case). But: 2. question: how to show that if the ratio is constant as a function of $\theta$ then $(x_{(1)},x_{(n)})=(y_{(1)},y_{(n)})$?","['statistics', 'sufficient-statistics', 'order-statistics', 'statistical-inference']"
1973885,memoryless property of exponential distributions with random variables,"It is true that $P(X>t+s|X>t)=P(X>s)$ for certain values $t$ and $s$. However, how can I show that this still holds if: $T$ is a continuous random variable. That is $P(X>T+s|X>T)=P(X>s)$ Both $T$ and $S$ are continuous RVs: $P(X>T+S|X>T)=P(X>S)$ All the random variables are independent.","['probability-theory', 'probability-distributions', 'probability', 'exponential-distribution', 'random-variables']"
1973916,Why is the definition of derivative what it is?,"In our lectures, we've been taught the following: We say that $f:\mathbb{R}^3\to\mathbb{R}$ is differentiable at a point $X$,iff there exists $\alpha\in\mathbb{R}^3$ such that $$\epsilon (H)=\frac{f(X+H)-f(X)-\alpha\cdot H}{\|H\|}\to0$$ as $\|H\|\to0$ and the derivative is $\alpha$ But I can't understand why this should work? What is the intuition behind setting up $\epsilon(H)$ like this? Why the dot product ($\alpha\cdot H$)? What does $\alpha$ represent physically on the curve? Please help, thanks.","['intuition', 'derivatives', 'calculus', 'multivariable-calculus', 'definition']"
1973927,"If $\sum_{n=1}^\infty a_n$ converges to $A$, then ${1 \over 2}(a_1 + a_2) + {1 \over 2}(a_2 + a_3) + \cdots$ converges","I need to prove If $a_1 + a_2 + a_3 + \cdots$ converges to $A$, then ${1\over2}(a_1 +a_2) + {1\over2}(a_2 + a_3) + {1\over2}(a_3+a_4) + \cdots$ converges. Find what the latter series converges to. PROOF : Given that $\displaystyle \sum_{n=1}^\infty a_n$ converges to $A$, then the sequence of partial sums of the series, $\{s_n\}$, converges to $A$, where $\displaystyle s_n = \sum_{k=1}^na_k$. That is, $$\lim_{n\to\infty}s_n = A.$$ Now, for the $2^{nd}$ series, observe that we may describe its sequence of partial sums as $\{t_n\}$, where $\displaystyle t_n =  {1\over2}\sum_{k=1}^n\left(a_k + a_{k+1}\right)$. Then $$\begin{align}\lim_{n\to\infty}t_n &= \lim_{n\to\infty}\left({1\over2}\sum_{k=1}^n(a_k + a_{k+1})\right) \\ &= {1\over2}\lim_{n\to\infty}\left(\sum_{k=1}^na_k + \sum_{k=1}^na_{k+1}\right) \tag{$*$}\\ &= {1\over2}\lim_{n\to\infty}\sum_{k=1}^na_k + {1\over2}\lim_{n\to\infty}\sum_{k=1}^na_{k+1}\\&= {1\over2}\lim_{n\to\infty}s_n + {1\over2}\lim_{n\to\infty}s_{n+1} \tag{$\bf{\star}$}\\ &= {1\over2}A + {1\over2}A \\&= A.\end{align}$$ Thus, the sequence of partial sums, $\{t_n\}$, converges and hence the series ${1\over2}(a_1 +a_2) + {1\over2}(a_2 + a_3) + {1\over2}(a_3+a_4) + \cdots$ converges to $A$. $\square$ QUESTION: I may split the sequence of partial sums at $(*)$ up because it is a finite sum, correct? If it were an infinite series, then I don't think it would be valid since we don't necessarily know that it converges to begin with (which is what we're trying to show). Also, is it correct to write $\lim_{n\to\infty}s_{n+1}$ at $(\star)$? Or is it supposed to be $\lim_{n\to\infty}s_n$?","['real-analysis', 'sequences-and-series', 'calculus', 'proof-verification', 'convergence-divergence']"
1973957,Non-Isometric surfaces with equal curvature,"The two surfaces $S_1$, $S_2$ parameterised respectively by $$\sigma_1(u,v) = (u\cos v,u\sin v, \ln u)$$
$$\sigma_2(u,v) = (u\cos v, u\sin v, v),$$ are, as I understand, not locally isometric. How can this be proven? They have the same Gaussian curvature, so that's not enough. The coefficients of the first fundamental form in each are not equal, but is that enough to conclude that they're not isometric? I've been taught that the coefficients of the first fundamental form depend on the parameterisation, so just because those of the above patches don't agree, how can we be sure that there isn't some local isometry $f$ such that $f\circ \sigma_1$ is a parameterisation of $S_2$?","['differential-geometry', 'surfaces']"
1974075,Proving $\sin 2x = 2\sin x \cos x$ using Taylor Series and Cauchy products,"I have that the Taylor series of $\sin x$ and $\cos x$ are
\begin{equation*}
\sin x = \sum_{n=0}^{\infty} \frac{(-1)^n}{(2n+1)!}x^{2n+1} \\
\cos x = \sum_{n=0}^{\infty} \frac{(-1)^n}{(2n)!}x^{2n}
\end{equation*}
which I understand yields the product series $\sum_{n=0}^{\infty} c_{n}x^n$ where
\begin{equation*}
c_n = \begin{cases} \sum\limits_{k=0}^{m} \frac{(-1)^{k}(-1)^{m-k}}{(2k+1)!(2m-2k)!} & n = 2m + 1 \\ \hspace{32 pt} 0 & n = 2m \end{cases}
\end{equation*}
$\forall \hspace{3 pt} m \in \mathbb{N}$. I then know by simple substitution that
\begin{equation*}
\frac{1}{2} \sin 2x = \sum_{n=0}^{\infty} \frac{(-1)^{n}2^{2n}}{(2n+1)!}x^{2n+1}
\end{equation*}
I know I need to show that the odd $c_n$'s and the terms of the above series equal (the even ones are irrelevant as they are all $0$ and so have no bearing on sum) but I am having trouble doing so. Can someone please show how to reduce said equality? Thanks in advance.","['cauchy-product', 'real-analysis', 'taylor-expansion', 'trigonometry']"
1974076,"If $d\equiv 2,3\pmod 4$, then the ring of integer of $K$ is $\mathbb Z[\sqrt d]$.","Let $K=\mathbb Q(\sqrt d)$ with $[K:\mathbb Q]=2$. Show that if $d\equiv 2,3\pmod 4$ the ring of integer $\mathcal O_K:=\bar{ \mathbb Z}\cap K$ is $\mathbb Z[\sqrt d]$. The proof goes as: Let show that $\mathcal O_K\subset \mathbb Z[\sqrt d]$. Let $q\in \mathcal O_K$. The, $q$ is solution of a polynomial $X^2+bX+c$ with $b,c\in \mathbb Z$. Then, $$q=\frac{-b+\sqrt{b^2-4c}}{2}$$
and s.t. $b^2-4c=f^2d$ for $f\in \mathbb Z$. Q1) Why $q=\frac{-b+\sqrt{b^2-4c}}{2}$ and not $q=\frac{-b\pm\sqrt{b^2-4c}}{2}$ ? Q2) Why $b^2-4c=f^2d$ ? Since $f^2\equiv 0,1\pmod 4$, we must have $b^2-4c\not\equiv 1\pmod 4$. By the way, we see that $b^2-4c\equiv 0,1\pmod 4$, and thus $b^2-4c\pmod 0\pmod 4$. Q3) Why $f^2\equiv 0,1\pmod 4$ and why $b^2-4c\equiv0,1\pmod 4$ ? Sorry, but I don't understand all this. For the rest, it's fine. For $\mathbb Z[\sqrt d]\subset \mathcal O_K$, let $a+b\sqrt d\in \mathbb Z[\sqrt d]$. Then, it's a root of $$X^2-2aX+(a^2-db^2)=(X-(a+b\sqrt d))(X-(a-b\sqrt d))$$
and thus $\mathbb Z[\sqrt d]\subset \mathcal O_K$. Q4) Here I don't understand why the fact that $$X^2-2aX+(a^2-db^2)=(X-(a+b\sqrt d))(X-(a-b\sqrt d))$$
implies that $\mathbb Z[\sqrt d]\subset \mathcal O_K$.","['number-theory', 'abstract-algebra', 'algebraic-number-theory']"
1974078,Classify groups all of whose subgroups are nested,"We consider groups $G$ for which taking intersections of subgroups does not produce ""new"" subgroups. Let us define: We say that a group $G$ has the strong nesting-subgroups property if for any subgroups $H$ and $K$ of $G$, either $H \subset K$ or $K \subset H$. And we say $G$ has the weak nesting-subgroups property if for any subgroups $H$ and $K$ such that $H \cap K \ne \{ e\}$ we have either $H \subset K$ or $K \subset H$. PROBLEM: Classify all groups $G$ with the strong nesting-subgroups property, and classify all groups with the weak nesting-subgroups property. If the general problem is too hard, solutions of special cases like when $G$ is finite and/or abelian etc. would also be interesting. This was inspired by the thread Must subgroups sharing a common element be nested in each other? Update: From the comments to the question it is clear that the thread found and linked by lhf covers all cases with the strong property (these groups must be abelian since for arbitrary elements $a,b\in G$ the subgroups $\langle a\rangle$ and $\langle b\rangle$ are inside each other, so $ab=ba$). Therefore we are only interested in (partial or full) answers to the weak nesting-subgroups property part.",['group-theory']
1974106,How to show the space of closed curve is Hilbert manifold?,"In the picture below ,$(M,g)$ is a Riemannian manifold. Why $\mathcal L_M$ is a Hilbert submanifold of $L^{1,2}(S^1,R^r)$ ? Besides, what is the inner and name  of $L^{1,2}(S^1,R^r)$ ? The picture below is from the 3 page of  Kwangho Choi and Thomas H. Parker's Convergence of the heat flow for closed geodesics .","['global-analysis', 'riemannian-geometry', 'differential-geometry']"
