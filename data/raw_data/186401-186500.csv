question_id,title,body,tags
3453504,Formula to Calculate Each Pie Angle Where the Intercepted Arc is NOT the Center Point of the Circle AND All Slices are Equal Sized,"I saw this picture titled ""How to Start a Fight at Thanksgiving"" and it made me laugh and then it made me wondered how to cut a pie into (N) number of pieces of equal surface area, but the central point of arc interception (C) is NOT the center point, instead it's located somewhere else inside the pie at coordinates X,Y. Is there a formula to calculate the different angles so that each slice has the same surface area? For discussion assume (r) Radius 4.5"", (n) Number of slices is 6, (c) central point of arc interception is 1"" moved to the left (west) of the true center point of the circle and 1.5"" towards the top (north). $\frac{\pi r^2}{n} = $ ~10.603 sq.inches for each slice, so what would be the different angles so that each slice equals ~10.603 sq. inches? Assumption: the first single cut is the shortest line possible from the common point to the perimeter and were dealing with 3 or more (n) number of slices. I thought this would be a fun Thanksgiving puzzle to solve. Thanks for playing.","['angle', 'circles', 'geometry', 'polar-coordinates', 'pi']"
3453551,An approach to the derivative of $e^x$ in Calculus 1,"While I know there are plenty of topics on here concerning the derivative of $e^x$ , I was wondering if what I have below is ""okay"" for the proof of it, or if there are holes in logic. Proof: $\displaystyle\frac{d}{dx}e^x = \lim_{h \to 0}{\frac{e^{x+h}-e^x}{h}}=\lim_{h\to 0}\frac{e^xe^h-e^x}{h}=\lim_{h \to 0} \frac{e^x(e^h-1)}{h}$ Now, $\displaystyle e=\lim_{x \to \infty}(1+\frac{1}{x})^x$ Letting $\displaystyle x=\frac{1}{h} \Rightarrow e=\lim_{h \to 0}(1+h)^{1/h}$ because $h \to 0$ as $x\to \infty$ . If you raise both sides to the $h$ power you would then get $\displaystyle e^h=\lim_{h\to 0}(1+h)$ . You could then make a substitution for $e^h$ back into line one, though I am a little concerned. Namely, couldn't I simplify $\displaystyle \lim_{h\to 0}(1+h)=1$ , but then substituting would not give the correct answer then. NOTE: I wanted to find a proof that a Calculus 1 student could follow, but I also wanted to go about it as if we don't know the result of $\displaystyle\frac{d}{dx}\ln(x)$ yet nor have learned Taylor Series (as that would be Calculus 2).","['calculus', 'proof-verification', 'derivatives', 'proof-writing']"
3453557,After performing KPA on Hill Cipher the matrix is formed wrong.,"Whenever I'm solving the hill cipher's key the final matrix is not in the original form. When I do the one from Wikipedia and also the one that I made myself neither comes back in the original form for the encryption or decryption key. First Wikipedia example. C=Cipher-text Matrix. P=Plain-text Matrix. C= $\begin{bmatrix}
7&8& \\
0&19 \\
\end{bmatrix}$ P= $\begin{bmatrix}
7&4\\
11&15 \\
\end{bmatrix}$ To calculate the decryption key I have to setup the formula like so. $D = [C]^{-1} ~\cdot P$ Then I calculate the modular multiplicative inverse of C as follows. $[C]^{-1} = \det[C]^{-1} \cdot adj([C])$ $det[C]= (ad - bc) \mod 26$ $7*19 - 8*0 \mod 26 = 133 \mod 26 = 3 $ mod inverse of 3 mod 26 is 9. $adj([C]) = \begin{bmatrix}19&-8\\0&7 \end{bmatrix}$ $[C]^{-1} =9 \cdot \begin{bmatrix}19&-8\\0&7 \end{bmatrix} \mod 26 \Rightarrow \begin{bmatrix}15&6\\0&11\end{bmatrix} $ $D=\begin{bmatrix}15&6 \\ 0&11 \end{bmatrix} \cdot \begin{bmatrix}7&4\\11&15\end{bmatrix} \mod 26 \Rightarrow \begin{bmatrix}129&255\\44&165\end{bmatrix} \mod 26 \Rightarrow D = \begin{bmatrix} 15&20\\17&9\end{bmatrix}$ Wikipedia's decryption matrix though is $\begin{bmatrix}15&17\\20&9\end{bmatrix}$ It seems to hold true for all matricies that I calculate that the end result matrix is $\begin{bmatrix}a&c\\b&d\end{bmatrix}$ every single time. I don't know if this is normal or not but I don't get it. My own matricies. $K=\begin{bmatrix}7&11\\8&11\end{bmatrix}$ $P=\begin{bmatrix}7&11\\4&11\end{bmatrix}$ $C=\begin{bmatrix}15&16\\22&1\end{bmatrix}$ $D=\begin{bmatrix}25&1\\22&23\end{bmatrix}$ If I convert my $C^{-1}$ and rotate it to instead be $\begin{bmatrix}a&c\\b&d\end{bmatrix}$ then I get back the encryption key correctly. I don't know what's going on with it though as the vectors are setup like wikipedia. P.S.
I'm writing a lab to show the rest of the students how I solved a hill cipher CTF challenge utilizing the KPA against it but it seems like I've forgotten how in the world I solved it. My goal is to make it so that everyone at my community college who's interested in doing such events has the knowledge as to how to do such events. Somehow, somewhere I'm rotating things and I don't know how/why/where. I had it working Tuesday Morning at 01:30 when I woke up with the answer and did it on my phone's calculator but I didn't write it down and now I'm back into the same boat again.","['matrices', 'linear-algebra', 'modular-arithmetic', 'cryptography']"
3453558,Getting different answers when integrating using different techniques,"Question: Is it possible to get multiple correct results when evaluating an indefinite integral?  If I use two different techniques to evaluate an integral, and I get two different answers, have I necessarily done something wrong? Often, an indefinite integral can be evaluated using different techniques.  For example, an integrand might be simplified via partial fractions or other algebraic techniques before integration, or it might be amenable to a clever substitution.  These techniques give different results.  For example, looking over a few other questions on MSE: From this question : evaluate $$ \int x(x^2+2)^4\,\mathrm{d}x. $$ Via the substitution $u = x^2+2$ , this becomes $$ \int x(x^2+2)^4\,\mathrm{d}x
      = \frac{1}{10}x^{10} + x^8 + 4x^6 + 8x^4 + 8x^2 + \frac{32}{5} + C. 
   $$ However, multiplying out the polynomial and integrating using the power rule gives $$ \int x(x^2+2)^4\,\mathrm{d}x
      = \frac{1}{10}x^{10} + x^8 + 4x^6 + 8x^4 + 8x^2 + C
   $$ From this question :  evaluate $$ \int \frac{1-x}{(x+1)^2} \,\mathrm{d}x. $$ Simplifying the integrand using partial fractions then integrating gives $$ \int \frac{1-x}{(x+1)^2} \,\mathrm{d}x
      = \frac{-2}{(x+1)} - \ln|x+1| + C.
   $$ Via integration by parts, we get $$ \int \frac{1-x}{(x+1)^2} \,\mathrm{d}x
      = \frac{x-1}{(x+1)} - \ln|x+1| + C.
   $$ From this question : evaluate $$ \int \frac {\tan(\pi x)\sec^2(\pi x)}2\,\mathrm{d}x. $$ Using the substitution $u = \sec(\pi x)$ , this becomes $$ \int \frac {\tan(\pi x)\sec^2(\pi x)}2\,\mathrm{d}x
      = \frac {\sec^2(\pi x)}{4\pi} + C.
   $$ Using the substitution $u = \tan(\pi x)$ , this becomes $$ \int \frac {\tan(\pi x)\sec^2(\pi x)}2\,\mathrm{d}x
      = \frac {\tan^2(\pi x)}{4\pi} + C.
   $$","['integration', 'indefinite-integrals', 'calculus', 'faq']"
3453624,Check the $\alpha$-mixing conditions: Stochastic process,"I want to determine if $\{Y_{t,T},X_{t,T}\}, t=1,\dotsc,T; T\geq 1$ , is $\alpha$ -mixing for some special cases. Let $X_{t,T}\sim i.i.d. U[0,1]$ and $Y_{t,T}=1$ (degenerate random variable); $Y_{t,T}=f(X_{t,T})$ , $f$ measurable function; $Y_{t,T}=g(\epsilon_{t,T})$ , $g$ measurable (linear) function so that $\{\epsilon_{t,T}\}$ is a $\alpha$ -mixing. My attempt My tools for this subject is rudimentary. I will write some ideas. Define the mixing coefficient by $$\alpha(j)=\sup_T\sup_{1\leq k\leq T-j}\sup\{\lvert P(A\cap B)-P(A)P(B)\rvert: B\in\mathcal{F}_{T,1}^{k},A\in\mathcal{F}_{T,k+j}^T\}$$ where $\mathcal{F}_{T,i}^{k}=\sigma((Y_{l,T},X_{l,T}):i\leq l\leq k)$ which is known to be equal $\sigma(\bigcup_{l=i}^k \sigma(Y_{l,T},X_{l,T}))$ . So the array $\{Y_{t,T},X_{t,T}\}$ is called $\alpha$ -mixing if $\alpha(j)\to0$ as $j\to\infty$ .
I will denote independence by $\perp$ . I believe that if a sequence $\{X_{t}\}$ is independent, then $\mathcal{F}_{1}^k\perp \mathcal{F}_{k+j}^\infty$ , implying that $\alpha(j)=0$ . The same should hold for the triangular array $X_{t,T}$ . As far as I see, it trivially means $\alpha$ -mixing. Now I start to answer the questions for each case. As $Y_{t,T} \perp X_{i,T},$ we have $\sigma(Y_{i,T},X_{i,T})\perp \sigma(Y_{i,T},X_{i,T})$ for $ t,i=1,\dotsc,T, T\geq 1$ . It means $\mathcal{F}_{T,1}^k\perp \mathcal{F}_{T,k+j}^\infty$ for any $j>0$ . So $\alpha(j)=0$ for all positive $j$ . (Here, my arguments lack formality) $\sigma(Y_{i,T},X_{i,T})$ is it the product sigma algebra? Or just $\sigma(\sigma(Y_{i,T})\cup \sigma(X_{i,T}))$ ? In both cases, $\sigma(f(X_{t,T}))=\{X^{-1}\circ f^{-1}(B):B\in\mathcal{B}_{\mathbb{R}}\}\subseteq \{X^{-1}(B):B\in\mathcal{B}_{\mathbb{R}}\}=\sigma(X_{t,T})$ . This should imply $\sigma(f(X_{i,T}),X_{i,T})\subseteq \sigma(X_{i,T},X_{i,T})$ . Using similar arguments of item 1 and the independence of $\{X_{t,T}\}$ , $\alpha(j)=0$ . Using the argument of item 2, $g(\epsilon_{t,T})$ is $\alpha$ -mixing and we can proceed considering $Y_{t,T}=\epsilon_{t,T}$ . I see that $\sigma(\epsilon_{t,T},X_{t,T})$ is not necessarily independent of $\sigma(\epsilon_{i,T},X_{i,T})$ anymore due to $\epsilon$ . I think that as $\epsilon_{i,T}$ is $\alpha$ -mixing, the presence of independent $X_{t,T}$ doesn't affect the limit $\lim_{j\to\infty}\alpha(j)=0$ . As you can see, my ideas are rudimentary and based on intuition. Can you help me to prove these results in a properly way? I wonder if there is a general result for $\alpha$ -mixing sequences $\{Y_t\},\{X_t\}$ such that $Y_t$ and $X_t$ are independent that says $\{(Y_t,X_t)\}$ is $\alpha$ -mixing.","['stochastic-processes', 'self-learning', 'probability-theory', 'mixing']"
3453643,Do eigenvectors of a squared matrix A tell us anything about the eigenvectors of A?,I have a following task: Let $X$ be an eigenvector of $A$ . a) Prove that $X$ is also an eigenvector of $A^2$ b) Is the convere theorem true? I had no problem with the first part. Ive tried disproving the second part this way: Let $e$ be the eigenvalue of $A^2$ corresponding to the eigenvector $X$ . By definition we know that: $A^2X=eX \to (A^2-eI)X=0 \to (A-eI)(A+eI)X=0$ If im not mistaken that proves that $X$ is an eigenvector either for $A$ or $-A$ (since $X$ is a nonzero vector). How can I evaluate which of those two matrices share the common eigenvector with $A^2$ ? Thanks in advance!,"['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
3453650,Finding an uncountable chain of subsets the integers,"How to find an uncountable subset of $P(\mathbb{N})$ such that every two elements of it can be compared. In fact, give an uncountable subset of $P(\mathbb{N})$ such that has totality property. We mean by $P(\mathbb{N})$, the powerset of natural numbers set $\mathbb{N}$.","['elementary-set-theory', 'order-theory']"
3453788,integral with function Gamma [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question In the article The Annals of Statistics Vol 18 March 1990, Natural exponential families with cubic variance functions , he is shown with a probabilistic method that $$\int_0^{\infty}\frac{x^{x+p-1}e^{-x}}{\Gamma(x+p+1)}dx=\frac{1}{p}.$$ I am looking for a proof of analysis","['integration', 'calculus']"
3453844,Construct axis if you have drawn $y=x^2$ plot,In the coordinate plane $xOy$ you have drawn parabola $y=x^2$ . Now delete the coordinate axes. Using a straightedge and a compass reconstruct coordinate axes.,"['graphing-functions', 'conic-sections', 'geometry', 'geometric-construction']"
3453898,At most how many common arithmetic progressions passing through 2 numbers in $\mathbb{Z}_p$?,"Given a positive prime number $p$ . 
An $k$ -term arithmetic progression ( $k$ -AP) in $\mathbb{Z}_p=\mathbb{Z}/p\mathbb{Z}$ (modulo $p$ classes) is defined as a set $\{a_1,\dots,a_k\}$ of $k$ numbers in $\mathbb{Z}_p$ so that $$a_i=a_1+(i-1)d$$ for some $d\neq 0$ and all $i=1,\dots,k$ . Question: Assume $3\le k\ll p$ . For two distinct numbers $a,b$ in $\mathbb{Z}_p$ , let $$\mathcal{S}(a,b):=\{S\subseteq \mathbb{Z}_p: |S|=k-1, S\cup\{a\}\text { and }S\cup\{b\}\text{ are both $k$-APs}\}.$$ Can you give an upper bound $f(k)$ on $\max_{a,b\in\mathbb{Z}_P:a\neq b}|\mathcal{S}(a,b)|$ , where $f(k)$ is a function only depending on $k$ (but not $p$ )? Example: Given $a=1,b=4$ in $\mathbb{Z}_p$ for $p$ large enough and $k=3$ , then $S=\{3,5\}$ is one of what we should count, as $\{1,3,5\}$ and $\{3,4,5\}$ are both $3$ -term arithmetic progressions in $\mathbb{Z}_p$ . $\{2,3\}$ is another one we should count. So if some upper bound $f(k)$ exists, it should be at least 2. Idea: Someone claims $k^6$ is an upper bound. And their reason is that assume $x_1,x_2\in S$ and the positions of $x_1,x_2$ in the arithmetic progressions containing $a$ are $i_1,i_2$ , respectively, and are $j_1,j_2$ for the other arithmetic progression containing $b$ . Similarly assume $a,b$ are in the $i,j$ places of these arithmetic progressions, respectively. When $i_1,i_2,j_1,j_2,i,j$ are determined (in at most $k^6$ ways), the differences $d_1,d_2$ of two arithmetic progressions can be determined. Then it will be done. But I am not sure why it is true.
As we can establish linear equations for unknowns $x_1,x_2,d_1,d_2$ as $$x_1-a=(i_1-i)d_1$$ $$x_1-b=(j_1-j)d_2$$ $$x_2-a=(i_2-i)d_1$$ $$x_2-b=(j_2-j)d_2.$$ But the determinant of the coefficient matrix will be $(i_2-i)(j-j_1)+(i-i_1)(j-j_2)$ . I don't know why it is nonzero even we can assume $i,i_1,i_2$ are distinct and $j,j_1,j_2$ are distinct.","['number-theory', 'abstract-algebra', 'linear-algebra', 'combinatorics']"
3453928,Why does this method of using trigonometric functions to calculate relativistic gamma work?,"When I studied special relativity, I noticed that some of the problems and answers on calculating $\gamma$ would be fractions of c that looked like ratios of side lengths in right triangles. For example, when $v = 4/5c$ , $\gamma = 5/3.$ By playing around with trigonometric functions, I found an alternative formula to calculate $\gamma$ , $$ \gamma = \frac 1 {\sin(\arccos(\frac{v}{c}))} $$ I am not very familiar with trigonometric identities. Can someone explain why this works?","['special-relativity', 'physics', 'trigonometry']"
3453934,Question about the XOR function on two binary strings,"Nota bene: Just so you're aware, being no avid mathematician, I might start making up terminology in this question to make what I'm asking a little more clear. Define a set $C$ of infinitely long binary strings so that $$C_0=000000000000...$$ $$C_1=111111111111...$$ $$C_2=101010101010...$$ $$C_3=110011001100...$$ $$C_4=111000111000...$$ $$C_5=111100001111...$$ and so every $C_n$ for $n\ge2$ is equivalent to $n-1$ ones followed by $n-1$ zeroes followed by $n-1$ ones, and so on. Now define a function $\Psi(C_n,q)$ taking one member of $C$ and a non-negative integer $q$ as an argument. The function $\Psi$ will operate on the binary string $C_n$ , returning another binary string which consists of $C_n$ shifted to the left by $q$ elements. For example: $$\Psi(C_4,2)=100011100011...$$ Finally, define the XOR operation $A\oplus B$ as operating on any two binary strings $A$ and $B$ with infinite length. This operation will perform the XOR function on each pair of corresponding members of $A$ and $B$ , and return the result. This is hard to put into words, so here is an example: $$1010101...\oplus 1101101...=0111000...$$ An infinitely long binary string $U$ is said to be comprehensible if it can be expressed as $\Psi(C_m,p)\oplus\Psi(C_n,q)$ for any two elements of $C$ , $C_m$ and $C_n$ , and any two non-negative integers, $p$ and $q$ . What is the shortest finite binary string that cannot begin a comprehensible infinitely long binary string, if any exist?","['logic', 'discrete-mathematics', 'computer-science']"
3453942,Find the general solution of $e^y (\cos xy - y \sin xy)dx + e^y (\cos xy - x \sin xy)dy = 0$,"I'm trying to find out whether I screwed up. I used $\mu(x,y)=e^{-y}\cos^{-1}xy$ as an integrating factor: $$(1-y\tan xy)dx + (1-x\tan xy)dy = 0$$ But since this is an exact differential equation, we can just look for a differentiable field $F$ such that $$\begin{cases} F_x & = 1-y\tan xy  \\ F_y & = 1-x\tan xy \end{cases}$$ Integrating $F_x$ w.r.t. $x$ we get $$\int (1-y\tan xy) dx = x + \ln|\cos xy| + \phi(y)$$ When we compute the derivative of this expression w.r.t. $y$ we can infer that $\phi'(y)=1$ , so $\phi(y)=y+C$ . Hence $$F(x,y)= x + y + \ln|\cos xy| + C$$ So the general solution is implicitly defined by the one-parameter family of equations $F(x,y)=0$ . Is this correct? How can I know I did not gain nor lose solutions when multiplying by $\mu(x,y)$ ?",['ordinary-differential-equations']
3453954,Sum of the series $\sum_{n=0}^{\infty} \lfloor n\sqrt{2} \rfloor x^n$?,Can we find the sum of the series $\sum_{n=0}^{\infty} \lfloor n\sqrt{2} \rfloor x^n$ explicitly? The question is related to this one where sum is computed if $\sqrt{2}$ is replaced by some rational number $r$ .,"['irrational-numbers', 'functions', 'analysis', 'real-analysis']"
3453963,Markov Chain Expectation Variance Covariance,"Given a Markov chain on {0, 1} defined by: \begin{gather}
    P = \begin{bmatrix} 1-p & p \\ q & 1-q  \end{bmatrix} 
\end{gather} With an initial distribution $\pi(0)$ = [ $\frac{q}{p+q}$ , $\frac{p}{p+q}$ ]. I have to find the Expectation $\mathbf{E}[X_n]$ , the Variance $\mathbf{V}[X_n]$ and the $\mathbf{Cov}[X_{m+n}, X_n]$ . Intuitively I would say that I can compute the expectation and the variance by multiplying {0,1} with the stationary probabilities. I this correct?  How would I factor in the covariance? Isn't this just equal to 0, because the chain converges to a stable distribution i.e. there is no difference between time m=n and n in the long run?","['statistics', 'markov-chains', 'probability']"
3453965,Coupon collector's problem: mean and variance in number of coupons to be collected to complete a set (unequal probabilities),"There are $n$ coupons in a collection. A collector has the ability to purchase a coupon, but can't choose the coupon they purchase. Instead, the coupon is revealed to be coupon $i$ with probability $p_i=\frac 1 n$ . Let $N$ be the number of coupons they'll need to collect before they have at least one coupon of each type. Find the expected value and variance of $N$ . Bonus: generalize to the case where the probability of collecting the $j$ th coupon is $p_j$ with $\sum\limits_{j=1}^n p_j=1$ . I recently came across this problem and came up with/ unearthed various methods to solve it. I'm intending this page as a wiki with various solutions. I'll be posting all the solutions I'm aware of (4 so far) over time. EDIT: As mentioned in the comments, this question is different from the one people are saying it is a duplicate of since (for one thing) it includes an expression for the variance and it covers the general case where all coupons have unequal probabilities. The case of calculating the variance for the general case of coupons having unequal probabilities has not been covered anywhere on the site apart from an earlier post by me , which this one intends to consolidate along with other approaches to solve this problem. EDIT: Paper on the solutions on this page submitted to ArXiv: http://arxiv.org/abs/2003.04720","['coupon-collector', 'probability']"
3453982,Probability got at least R in a 6-sided die at least X out of Y rolls and the expected return,"I'm working on calculating the probability that I got at least R in a 6-die at in at least X out of Y rolls. I tried complement to solve this with R = 5, X = 2 and Y = 3 Probability that no 5 or 6 will be rolled in 3 rolls: $({\frac{4}{6}})^3$ Probability that a 5 or 6 is rolled in the first rolls and not appear in the two next rolls: $({\frac{2}{6}}) * ({\frac{4}{6}})^2$ . Count possiblities that each of the 3 die could be 5 or 6 and the rest not: ${\binom{3}{2}}$ . Total it would be: 1 - $({\frac{4}{6}})^3$ - $({\frac{2}{6}}) * ({\frac{4}{6}})^2$ * ${\binom{3}{2}}$ . Is my solution correct? And how would it be generalized? And how do I count the expected return from this given that if I do gambling and  actually got $\geq$ 5 at least 2 out of 3 rolls, I would be paid W = 3 times the amount of what I bet? Thank you for your help.","['discrete-mathematics', 'combinatorics', 'probability']"
3453990,Confidence Intervals: Influence,Why would increasing the sample size decrease the confidence interval width? Wouldn't increasing sample size lead to an increase in the variability (and thus the standard deviation) of the data?,"['statistics', 'confidence-interval']"
3453999,How professional mathematicians work through problems [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 4 years ago . Improve this question I've seen other questions on this site asking for problem-solving tips and general problem-solving strategies but I haven't seen any questions asking for the thought process of professional mathematicians as they approach problems (although if there are some, feel free to link them). What are the first things that go through your mind when you read a problem? How do you understand what the problem wants from you, or what knowledge the solution requires? How do your methods and your process change as the solution becomes longer or more crafty? Anything else that goes through you mind as you work through a problem. As someone fairly new to rigorous, proof-based math, I am really interested in answers to these questions. Below, I've provided a few problems from Lang's Linear Algebra I was hoping could be used to illustrate a professional mathematician's thought process. Chapter 8, section 4, exercise 20: Chapter 7, section 3, exercise 14: Chapter 5, section 4, exercise 4: If it's of any relevance, I am nearing the end of Lang's Linear Algebra and I have previously studied most of Spivak's Calculus. I have largely felt comfortable with the material in both books. Some techniques I have found useful in problem solving include making sure I understand the relevant definitions and specialized terms used in difficult questions question, looking for similar examples in the text, and trying to see if I can recognize any previous methods of proof that may apply to the problem at hand.","['linear-algebra', 'problem-solving', 'education']"
3454007,what is 1 - 1/2 + 1/3 - 1/4 + 1/5 - 1/6 + 1/7 - 1/8 +1/9 - ...? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question I know that it is converging because it is alternating series with terms getting smaller to zero. but I do not know what it converges to value",['sequences-and-series']
3454077,"Probability of $\mathbf X+n\mathbf Y$ mod K where $\mathbf X, \mathbf Y$ are independent uniform","I am trying to solve a problem (from Durrett's PTE), and a component of it requires me to find the distribution of $\mathbf{Z_n}=\mathbf{X} + n\mathbf{Y}$ mod $\mathit{K}$ where $\mathit{K}\geq 3$ is a prime number, $\mathbf{X}$ and $\mathbf{Y}$ are uniformly distributed as $\{0,1,...,\mathit{K}-1\}$ , and $0\leq\mathbf{n}\lt\mathit{K}$ . Since $\mathit{K}$ is prime, I know that the range of possible values of $\mathbf{Z_n}$ is $\{0,1,...,\mathit{K}-1\}$ , and doing a bunch of examples by hand (and it makes sense intuitively), I can see that the distribution is: $\mathbf{P}[\mathbf{Z_n}=i]=1/K$ , $0\leq\ i \lt\mathit{K}$ so in other words $\mathbf{Z_n}\sim uniform\{0,1,...,\mathit{K}-1\}$ But I am at a bit of a loss as to how to show this rigorously. Or this a standard result that I can find in some book that you can point me to?","['elementary-number-theory', 'probability-distributions', 'probability-theory', 'probability']"
3454120,A necessary and sufficient criterion for a bounded sequence ${(a_n)_{n=1}^\infty}$ to classically converge to a limit ${L}$,"I real the generalised limit functionals in Tao's article: https://terrytao.wordpress.com/2017/05/11/generalisations-of-the-limit-functional/ Consider the space $\mathcal{l}_{\infty}$ of all bounded sequence and the classical limit is the linear functional on a subspace of $\mathcal{l}_{\infty}$ . Define the sublinear linear functional $p(x)=\limsup a_n$ for sequence $a_n\in \mathcal{l}_{\infty}$ . By Hahn-Banach theorem, we can extend the classical limit (linear functional) to general limit (denoted by LIM) in $\mathcal{l}_{\infty}$ . I have some questions: (1)For instance, consider the sequence $a_n=(-1)^n$ . For any number $\theta\in [-1,1]$ , there exists a generalised limit functional that assigns that number $\theta$ as the ""limit"" of the sequence $a_n=(-1)^n$ . This claim can be seen by first designing such a limit functional on the vector space spanned by the convergent sequences and by $(a_n)_{1}^{\infty}$ . That is, LIM $a_n =\theta$ If I define the subspace $V$ of the convergent sequences of $\mathcal{l}_{\infty}$ . So how to understand Tao's claim? Any details are grateful. I feel like it extends the classical limit to space $V+(a_n)$ . (2)This observation also gives a necessary and sufficient criterion for a bounded sequence ${(a_n)_{n=1}^\infty}$ to classically converge to a limit ${L}$ , namely that all generalized limits of this sequence must equal ${L}$ .That is, $(a_n)$ converges if and only if every generalized limit takes the same value. How to prove it?","['functional-analysis', 'real-analysis']"
3454128,Evaluating $\int_{0}^1 \ln \left\lfloor \frac{1}{x} \right\rfloor dx$,"Inspired by this question , I decided to ask about $$I = \int_{0}^1 \ln  \left\lfloor \frac{1}{x} \right\rfloor dx$$ This can be easily converted to an infinite summation by considering each segment: the $n$ th segment, starting at $n = 1$ from the right and going to the left, has length $\frac{1}{n}-\frac{1}{n+1}$ and height equal to $\ln(n)$ . This then means that the integral is equal to $$S_1 = \sum_{n=1}^{\infty} \left( \frac{1}{n}-\frac{1}{n+1} \right) \ln(n)$$ Through telescoping, this can be rewritten as $$S_2 = \sum_{n=2}^{\infty} \frac{\ln(n)-\ln(n-1)}{n}$$ I don't know how $S_2$ or either of the other representations can be solved, but I am fairly certain that it converges since numerical approximations have given me an answer around $0.788$ . Any help in solving the integral would be appreciated. Edit: By using $$\frac{\ln(n)-\ln(n-1)}{n} = \sum_{m=2}^{\infty} \frac{1}{(m-1)n^m}$$ the series can be rewritten as $$S_3 = \sum_{n=2}^{\infty} \sum_{m=2}^{\infty} \frac{1}{(m-1)n^m} = \sum_{m=2}^{\infty} \frac{\zeta(m) - 1}{m-1}$$","['integration', 'ceiling-and-floor-functions', 'definite-integrals', 'sequences-and-series']"
3454196,6 colored balls in 3 numbered boxes,"There are six balls, colored red, orange, yellow, green, blue, and purple. There are also 3 boxes, numbered 1, 2, and 3. How many ways are there to put the balls in the boxes, such that each box has at least 1 ball? I had 2 methods of doing the problem and got different answers. Method 1: I pick a ball to put in box 1, then a ball to put in box 2, and a ball to put in box 3. There are $6\cdot5\cdot4$ ways to do that. Then, the three balls can be randomly put in the three boxes, giving $3^3$ . Multiplying them together gives $6\cdot5\cdot4\cdot3^3=3240$ ways. Method 2：I use complementary counting. There are $3^6$ ways to put the distinct balls into the distinct boxes (without any restrictions). Then, I subtract the ways to put the balls into 2 boxes: $3\cdot2^6$ for the $3$ ways to pick the two boxes, and $2^6$ ways to put the balls into the boxes. Then, I add the ways to put the balls into 1 box: $3\cdot1^6$ to pick a box and put all the balls in it. I get $3^6-3\cdot2^6+3\cdot1^6=540$ ways. Which method, if any, is correct?","['combinatorics', 'balls-in-bins']"
3454230,A purely discontinuous process with jumps +1 is Poisson.,"I am reading Bass's book on Stochastic processes on my own. I cam across the following exercise in Chapter 17. 17.8 Suppose $X_t$ is an increasing process with paths that are right continuous with left limits, $X_0=0$ a.s., $X$ is purely discontinuous, and all jumps are of size $+1$ only. Suppose that $\lim\limits_{t\to \infty}X_t=\infty,$ a.s. Then prove that $X_t$ is a time change Poisson process. I am feeling uneasy about this exercise. Suppose, I have a (deterministic) process which jumps at every integer, and jump sizes are one. Then this process satisfies all the hypothesis in the question, but how can it be a Poisson process? Jumps in Poisson process  are completely unpredictable. I can not wrap my head around this problem. I would appreciate if somebody can elucidate the issue and explain to me what I am missing?","['stochastic-processes', 'probability-theory', 'poisson-process']"
3454235,"Question about ""Klein Bottle"" in 3 dimension. Algebraic Topology, Hatcher. Exercise 1.2.12.","Klein bottle in $3$ dimension named $Y$ is given here (the circle of self-intersection is deleted). Its CW complex structure is given at right. $\pi_1(Y)$ is generated by $a, b, c, d$ with $cbc^{-1}d=1, aba^{-1}b^{-1}d^{-1}=1$ . It can be reduced to $aba^{-1}b^{-1}cbc^{-1}=1$ , so $\pi_1(Y)=\langle a,b,c \mid aba^{-1}b^{-1}cbc^{-1}=1 \rangle$ . Hatcher's book Algebraic Topology in page 53-54 says $\pi_1(Y)$ also has presentation $\langle a,b,c \mid aba^{-1}b^{-1}cb^\color{red}{-1}c^{-1}=1 \rangle$ (this gives isomorphic group as above). My question: $1$ . How can we find a CW complex structure s.t. $\pi_1(Y)$ has presentation $\langle a,b,c \mid aba^{-1}b^{-1}cb^\color{red}{-1}c^{-1}=1 \rangle$ ? $2$ . How can we show $\langle a,b,c \mid aba^{-1}b^{-1}cbc^{-1}=1 \rangle\cong \langle a,b,c \mid aba^{-1}b^{-1}cb^\color{red}{-1}c^{-1}=1 \rangle$ by giving explicit isomorphism? Thanks for your times and effort.","['group-theory', 'fundamental-groups', 'abstract-algebra', 'general-topology', 'algebraic-topology']"
3454267,Is it correct to assume that if $n \in \mathbf{Z}_+$ then $ \Big|\frac{\sin(n)}{2^n}\Big| \leq \Big|\frac{1}{2^n}\Big|$?,"I am always wary of making mistakes when dealing with trigonometric functions and ratios, but I believe that it makes sense to say that $$
|\sin(n)| \leq 1 \implies \frac{1}{2^n}|\sin(n)| \leq \frac{1}{2^n} \implies \Big|\frac{\sin(n)}{2^n}\Big| \leq \Big|\frac{1}{2^n} \Big|
$$ Is there anything invalid with this line of reasoning?","['algebra-precalculus', 'absolute-value', 'real-analysis']"
3454313,Finding the family of functions given an equation,"I played with the solution for the problem $$\text{if }\; x + \frac{1}{x} = a$$ what is $$x^5 + \frac{1}{x^5}$$ I tried different exponents other than 5 and tried finding the solution to it. I defined $f(x) = a^x + \frac{1}{a^x}$ . I got $f(x + y)=f(x)f(y) - f(x-y).$ I tried reversing the equation I got to get $f(x)$ but I only got these: $$f(0) = 2$$ by substituting $b=0$ $$f(x)=f(-x)$$ $$(f(a)^2 - 4)(f(b)^2 - 4) \geq 0$$ $$f'(0)=0$$ Can this be solved using the given information? Is $f(x) = a^x + \frac{1}{a^x}$ the only solution? Thanks in advance! Edit: I already got the solution for $x^5 + \frac{1}{x^5}$ , I'm asking if how can I get the family of functions $f(x)$ from $f(x + y)=f(x)f(y) - f(x-y)$ , sorry for the unclear question","['functions', 'exponential-function']"
3454327,Characterization of local compactness,k-spaces can be characterized as the topological inductive limit of compact spaces. Locally compact spaces are k-spaces but not conversely (k-spaces can also be characterized as quotients of locally compact spaces). Locally compact spaces have the distinguished property that they have a bunch of relatively compact open sets: every compact set is contained in a relatively compact open set and moreover that if $K$ is compact and $U$ is open with $K \subseteq U$ then one can find an open set $U'$ and a compact set $K'$ such that $K \subseteq U' \subseteq K' \subseteq U$ . Do these properties completely characterize locally compact spaces? A locally compact space is also the topological inductive limit of its relatively compact open sets. Can this be used to characterize locally compact spaces as an inductive limit of particular systems of topological spaces?,['general-topology']
3454344,Does Surjective-infinite implies Dedekind infinite,"Suppose we define a set $A$ to be Surjective-infinite iff there is an surjection $f:A \rightarrow A$ such that it is not an injection. Is this true that $A$ is also dedekind-infinite, i.e there exist a $f^*$ from $A$ to $A$ that is injective but not surjective. Conceptually, using AC if need be. I could use the given $f$ to construct $f^*$ by sort of 'removing' the duplicates from the pre-image of $a$ under $f$ , meaning if $f(c)=f(b)=a,$ define $f^*(a)$ to just be $b$ . If this is true, how do I do it more concretely ? Cheers","['functions', 'set-theory']"
3454348,Gradient of $F(\mathbf{x}) = \|\mathbf{Ax}-\mathbf{b}\|_{2}^2$,"So, I have a matrix $A\in\mathbb{R}^{M\times N}$ , $M\geq N$ with rank $N$ and $\mathbf{b}\in\mathbb{R}^M$ . Unfortunately I'm a bit rusty on how to do multivariable calculus, so I would like to know how to calculate $\nabla F$ of $$F(\mathbf{x})=\|\mathbf{Ax}-\mathbf{b}\|_{2}^2$$ I would furthermore also appreciate literature suggestions regarding sources where multivariable calculus is well explained, especially differentiation.","['derivatives', 'multivariable-calculus', 'linear-algebra', 'real-analysis']"
3454350,"Construction of a metric from a ""topological"" measure","Is there a way to construct (perhaps cannonical) a metric from a measure on Borel sets of a Hausdorff topological space? I know of theorems regarding topological spaces inducing measures, such as the Haar measure theorem and Riesz-Markov-Kakutani theorem. My question, is are there theorems regarding ""the other"" direction of constructing a metric from say a Radon measure on a Hausdorff first countable locally compact space. I saw somewhere where they said that the hyperbolic measure $\dfrac{dxdy}{y^2}$ induces the hyperbolic distance, and I was wondering whether there is a standard construction that I am oblivious to.","['general-topology', 'measure-theory']"
3454372,Finding $\lim_{n\to\infty}{\frac{n}{a^{n+1}}\left(a+\frac{a^2}{2}+\frac{a^3}{3}+\cdots+\frac{a^n}{n}\right)}$ where $a>1$,"$$\underset{n\rightarrow\infty}\lim{\frac{n}{a^{n+1}}\left(a+\frac{a^2}{2}+\frac{a^3}{3}+\cdots+\frac{a^n}{n}\right)}=?, \;\;a>1$$ In Shaum's Mathematical handbook of formulas and table s I've seen: $$\;\;\;\;\;\;\;\;\;\;\ln(1+x)=x-\frac{x^2}{2}+\frac{x^3}{3}-\frac{x^4}{4}+\cdots\;,x\in\langle-1,1]\;\;\;\;\;\;\;$$ $$\frac{1}{2}\ln{\Bigg(\frac{1+x}{1-x}\Bigg)}=1+\frac{x^3}{3}+\frac{x^5}{5}+\frac{x^7}{7}+\cdots\;\;\;,x\in\langle-1,1\rangle$$ The term in parentheses reminded me of the harmonic series. I thought of using the Taylor series. Is that a good idea?
It says $a>0$ so I probably can't use these two formulas.
On the other hand: $$e^x=x+\frac{x^2}{2!}+\frac{x^3}{3!}+\frac{x^4}{4!}+\cdots\;\;\;\;\;\;,$$ but there are no factorials in the denominators. Source in Croatian: 2.kolokvij, matematička analiza","['limits', 'calculus', 'real-analysis']"
3454436,"Show that for $f,g \in L^{1}(G)$ we have $f*g \in L^{1}(G)$.","Let G be a locally compact group and consider ( $L^{1}(G), \|\cdot\|_{1}$ ) where $\|f\|_{1}=\int_{G}|f(x)|dx$ for $f \in L^{1}(G)$ . Define convolution $*$ by $(f*g)(y)=\int_{G}f(x)g(x^{-1}y)dx$ for $f,g \in L^{1}(G)$ and $y \in G$ Show that for $f,g \in L^{1}(G)$ we have $f*g \in L^{1}(G)$ . I know that this amounts to showing that $\int_{G}|(f*g)(y)|dy=\int_{G}|\int_{G}f(x)g(x^{-1}y)dx|dy<\infty$ ,but I really don't know how to show that this integral is finite.","['integration', 'measure-theory', 'topological-groups', 'group-theory', 'general-topology']"
3454463,"How do I sketch this graph, when I can only find the y-intercept and vertex?","I want to sketch the graph of this function: $y = x^2 + 2$ Since the coefficient of $x^2$ is $1$ , the graph opens upwards. When $y = 0$ , I find that the graph does not cut the $x$ -axis. (It is above it.) When $x = 0$ , I find that the graph cuts the $y$ -axis at $(0, 2)$ . Hence, the equation of the line of symmetry is $x = 0$ . I still do not know the steepness of the parabola. From this limited information, how do I sketch the graph of this function without using graphing software? What additional formula(s) or method(s) would I need to sketch this graph? A demonstration based on my problem would be helpful.","['algebra-precalculus', 'functions', 'graphing-functions']"
3454534,How to prove $A\setminus(B\setminus C) = (A \setminus B) \cup (A \cap C)$ [duplicate],"This question already has an answer here : A\(B∩C) = (A\B) ∪ (A\C) how to prove? (1 answer) Closed 4 years ago . I have to prove that. While I know this is true by thinking about it I'm having a lot of trouble actually writing the proof
how can I prove $A\setminus(B\setminus C) = (A \setminus B) \cup (A \cap C)$ first of all it's true?",['elementary-set-theory']
3454535,Proving that $8^x+4^x\geq 5^x+6^x$ for $x\geq 0$.,"I want to prove that $$8^x+4^x\geq 6^x+5^x$$ for all $x\geq 0$ . How can I do this? My attempt: I try by AM-GM: $$8^x+4^x\geq 2\sqrt{8^x4^x}=2(\sqrt{32})^x.$$ However, $\sqrt{32}\approx 5.5$ so I am not sure if $$2(\sqrt{32})^x\geq 5^x+6^x$$ is true. Also, I try to compute derivatives but this doesn't simplify the problem. What can I do?","['contest-math', 'exponentiation', 'inequality', 'real-analysis']"
3454555,"Given the following Riccati equation and the 4 solutions $y_{1}$ , $y_{2}$ , $y_{3}$ , $y_{4}$ . prove that the following expression is constant.","Riccati equation: $$y'(x)=c(x)+b(x)\,y(x)+a(x)\,y^{2}(x)$$ with the solutions: $y_{1}$ , $y_{2}$ , $y_{3}$ , $y_{4}$ Prove that $q$ is constant: $$ q=\frac{\ (y_{3} -y_{1})(y_{4} - y_{2})}{(y_{3}-y_{2})(y_{4}-y_{1})}$$",['ordinary-differential-equations']
3454587,"If there exists a positive integer $n$ such that any element $x$ of a ring $R$ satisfies $x^{4^n+2} = x$, then every element $x$ in $R$ is idempotent","Let $R = (A,+,\cdot)$ be a ring. If there exists a positive integer $n$ such that any element $x$ of a ring $R$ satisfies $x^{4^n+2} = x$ , then every element $x$ in $R$ is idempotent. I have studied some group theory but I don't think it's that helpful here. Basically by multiplying both sides a bunch of times with $x^{4^n + 1}$ you can show that $$x^{k(4^n + 1) + 1} = x \hspace{5px} \forall k \in \mathbb{N}.$$ My intuition goes along the lines of ""if $x^a = x$ and $x^b = x$ then $x^{(a,b)} = x$ "" but in the absence of multiplicative inverses that wouldn't work (the reason I thought this might have been helpful is because the exponent of $2$ in $4^n + 2$ is always $1$ , so by finding an appropriate $k$ we could make the gcd $2$ ). How should I proceed?","['ring-theory', 'abstract-algebra', 'idempotents']"
3454610,Can a transcendent matrix have an algebraic spectrum?,"Let $K$ be an algebraically closed field (e.g $\mathbb{A}$ ) and $K'/K$ a transcendent field extension (e.g. $\mathbb{C}/\mathbb{A}$ ). Let $A\in K'^{n\times n}$ be a matrix over K', which has at least one entry from $K'\setminus K$ . Is it still possible that all eigenvalues of $A$ lie in $K$ ?",['linear-algebra']
3454668,counting integer solutions with restrictions,"How many combinations of non-negative values $x_i$ fulfill $$x_1 + x_2 + x_3 + \ldots + x_L = N$$ if one restricts the sum of any $k$ adjacent variables by an upper limit $n$ , e.g. $x_1 + x_2 +x_3 < n$ $x_2 + x_3 + x_4 < n$ $\ldots$ $x_L + x_1 + x_2 < n$ (we assume periodic boundary conditions) I failed decoupling the restrictions in order to use a stars&bars method or generating functions. Also, introducing variables $y_i = x_i + x_{i+1} + \ldots + x_{(i+k) mod L}$ decouples the restrictions, but the variables $y_i$ are no longer independent from each other. How to implement such restrictions that couple/correlate the variables $x_i$ ?","['combinatorics', 'discrete-mathematics']"
3454674,Calculate the maximum in the Collatz sequence,"Consider the notorious Collatz function $$ T(n) = \begin{cases}(3n+1)/2&\text{ if $n$ is odd,}\\n/2&\text{ if $n$ is even.}\end{cases} $$ One of the most important acceleration techniques of the convergence test is the usage of a sieve (test $k$ least significant bits of $n$ , the sieve has the size of $2^k$ entries), and test only those numbers that do not join the path of a lower number in $k$ steps. This technique is greatly explained, e.g., here or here . For example, consider the sieve for $k=2$ and particularly the numbers of the form $4n+1$ which join the path of $3n+1$ in two steps. Their path is $$ 4n+1 \rightarrow 6n+2 \rightarrow 3n+1 \text{.}$$ What I don't understand is how this can be used to search for the highest number occurring in the sequence ( path records in the terminology of Eric Roosendaal). The sieve cuts the calculation before the computation of any intermediate value (which can actually be the maximum, like the value $6n+2$ in the above example). How can I detect that $4n+1$ does lead to a maximum if no $6n+2$ is computed? Testing the path of $3n+1$ no longer makes sense since the maximum $6n+2$ occurs before this term. Am I missing something?","['computational-mathematics', 'number-theory', 'collatz-conjecture', 'sequences-and-series']"
3454700,"Proof attempt of exercise 3.2, Ch. III Hartshorne","I try to prove that if a Noetherian scheme $X$ has each irreducible component affine, then $X$ is affine. Here's my attempted proof: Choose an irreducible component $i:Y \to X$ and a quasi-coherent sheaf $\mathcal{F}$ on $X$ . If $U = X\setminus Y$ , $j:U\to X$ , then we have the short exact sequence $0 \to \mathcal{F}_U \to \mathcal{F} \to \mathcal{F}_Y \to 0$ , where $\mathcal{F}_U = j_!(\mathcal F|_U)$ and $\mathcal{F}_Y = i_*(\mathcal F|_Y)$ . By taking the long exact sequence in cohomology we get the surjective maps \begin{align}
H^p(X,\mathcal{F}_U) \to H^p(X,\mathcal{F}) \to H^p(X,\mathcal{F}_Y) = 0,
\end{align} where the last group is $0$ since $Y$ is affine and $\mathcal{F}_Y$ is quasi-coherent. Hence it is enough to prove that $H^p(X,\mathcal{F}_U) = 0$ (then apply Serre's criterion for affineness). Now I want to use the fact that $\mathcal{F}_U$ is a quasi-coherent sheaf on $\overline{U}$ , which has less irreducible components than $X$ , and to use some induction on the number of irreducible components to get that $H^p(X,\mathcal{F}_U)  = 0$ . My question is how I make rigorous this last fact. More precisely, how do I show that $H^p(\overline{U},\mathcal{F}_U|_\overline{U})  = H^p(X,\mathcal{F}_U)$ ?","['affine-schemes', 'algebraic-geometry']"
3454705,$\frac{a_{max}}{\sum a_i} \to 0$: Proof or Counterexample,"Suppose I have a sequence of positive integers $\{a_n\}$ . Let us denote $b_n=\max_{1\le i\le n} a_i$ . Suppose $$\frac{b_n}{\sum\limits_{i=1}^n a_i} \to 0$$ then show that $$\frac{b_n^2}{\sum\limits_{i=1}^n a_i^2} \to 0$$ I am not sure if it is true. But I didn't find any Counterexample. I was trying to get a reasonable lower bound for the denominator. I could not find any. Bounds like $$\sum_{i=1}^n a_i^2 \ge \sum_{i=1}^n a_i$$ won't help though. Note that the converse is true. As you can easily get an upper bound using: $$\sum_{i=1} a_i^2 \le b_n\sum_{i=1} a_i$$ Any help/suggestions? Edit: Note that $a_n$ 's are positive integers, that's why $\sum a_i^2 \ge \sum a_i$ is true.","['number-theory', 'analysis', 'real-analysis', 'sequences-and-series', 'limits']"
3454802,Structure of inflation/deflation on Penrose Tilings?,"Thinking about P2/P3 type penrose tilings (kites/darts or rhombs - for this question they should be equivalent?) we know we can ""inflate""/""deflate"" any tiling of the plane to get another. We also know that the number of Penrose tilings is uncountably infinite. Do we know what structure the ""inflation/deflation"" procedure bestows upon the set of penrose tilings? To be more precise, for example we know that the 'sun' and the 'star' penrose tilings are dual under inflation/deflation. Are there any other 'cycles' of penrose tilings? In my mind, the inflation/deflation introduces a kind of 'local linear order' on the set of penrose tilings - is it known how to describe this structure more carefully? Unsure of where to go for answers - I've been trying to find Penrose's paper “The Role of Aesthetics in Pure and Applied Mathematical Research.” in Bulletin of the Institute of Mathematics and Its Applications, 10, 1974. pp. 266–271. to no avail","['euclidean-geometry', 'geometry', 'tiling']"
3454808,Problem with derivative of generating function and sequence of Catalan number,"$Q^1$ : Given that \begin{align}
a_0 &= 0\\
a_{n+1} &= na_n+1\\
\end{align} find the closed form $?$ My attempt : \begin{align}
\sum_{n\geq0}^{\infty}a_{n+1}x^{n+1}&=\sum_{n\geq0}^{\infty}na_nx^{n+1}+\sum_{n\geq0}^{\infty}1.x^{n+1}\\
(G(z)-a_0)&=G'(z)x^2+\frac{x}{1-x} \qquad\text{Using }G'(z)x=\sum_{n\geq0}^{\infty}na_nx^n
\end{align} But how to deal with $G'(z)?$ $Q^2$ : Let $\{C_n\}$ be the sequence of Catalan
  numbers, that is, the solution to the recurrence relation $C_n=\sum_{k=0}^{n-1}C_kC_{n-k-1}$ with $C_0=C_1=1$ $(a)$ Show that if $G(x)$ is the generating function for the sequence of Catalan numbers, then $xG(x)^2-G(x)+1=0$ concluding $G(x)=\frac{1-\sqrt{1-4x}}{2x}$ . $(b)$ Conclude that $G(x)=\sum_{n=0}^{\infty}\frac{1}{n+1}\binom{2n}{n}x^n$ so that $C_n=\frac{1}{n+1}\binom{2n}{n}$ My attempt : I solve $(a)$ but stuck in $(b)$ . The solution provided said that Using the extended binomial theorem: $$(1-4x)^{-\frac{1}{2}}=\sum_{k=0}^{\infty}\binom{2k}{k}x^k$$ $\color{red}{\text{Note that}(1-4x)^{-\frac{1}{2}}\text{is the derivative of}G(x)=\frac{1-\sqrt{1-4x}}{2x},\text{thus }xG(x)\text{is the integral of}(1-4x)^{-\frac{1}{2}}}$ $$xG(x)=\int_0^x(1-4x)^{-\frac{1}{2}}dx=\cdots=\sum_{n=0}^{\infty}\frac{1}{n+1}\binom{2n}{n}x^n$$ Hence, $C_n=\frac{1}{n+1}\binom{2n}{n}$ . I didn't understood the red line. I know asking one question at a time but since these two question related with derivative and integration hence putted on a single thread. Thanks in advance and thanks for your time .","['recurrence-relations', 'discrete-mathematics', 'generating-functions']"
3454818,If $u_n \rightharpoonup u$ in $H_0^1 (\Omega)$ then $u_n^2 \to u^2$ in $L^{6/5}(\Omega)$,"My question regards a minor detail in the proof of a lemma in a research paper I am reading. Let $\Omega$ be an smooth, bounded open set of $\mathbb{R}^3$ and suppose $u_n \rightharpoonup u$ in $H_0^1 (\Omega)$ . The author claims that since $H_0^1 (\Omega) \hookrightarrow L^q(\Omega)$ with compact embedding it follows that $u_n^2 \to u^2$ in $L^{6/5}(\Omega)$ . Why is this true?","['lp-spaces', 'sobolev-spaces', 'functional-analysis', 'weak-convergence']"
3454821,Expected value of the number of bills,"Every day I put 1 or 2 dollars in the piggy bank with probability $1/2$ . 
What's is expected value number of 2-dollar bills when in the piggy bank will be for the first time at least 100 dollars ? I know what is going on. Let $X$ - number of 2-dollar bills. 1) $X=1$ : 1 dollar - 98 bills and 2 dollars - 1 bill or 1 dollar - 99 bills and 2-dollars - 1 bill 2) $X=2$ 1 dollar - 96 bills and 2 dollars - 2 bills or 1 dollar - 97 bills and 2 dollars - 2 bills etc. Unfortunately, I can't think of a quick way.","['expected-value', 'probability']"
3454834,Find the largest score a rugby team cannot get exactly using just 3-point field goals and 7-point tries.,"Want to try prove the above using induction. I have worked out the largest impossible score is 11, thus meaning any score 12 or larger should be possible. Where I'm struggling is to actually come up with some sort of expression to prove. It is my instinct to say that any score above 12 should be divisible by a linear combination of 7x + 3y for some x and y that are natural numbers. Can anyone help point me in the right direction to begining my induction proof?","['induction', 'discrete-mathematics']"
3455055,How to express $\cos\left(\frac{\theta}{3}\right)$ in terms of $\cos(\theta)$? [duplicate],"This question already has answers here : Express $\cos 6\theta $ in terms of $\cos \theta$ (3 answers) Find a formula for $\sin(3a)$ and use to calculate $\sin(π/3)$ and $\cos(π/3)$? (2 answers) Closed 4 years ago . There are plenty of formulae for half-angles, double angles, but I haven't manage to find nor derive an expression for $\cos\left(\frac{\theta}{3}\right)$ in terms of $\cos(\theta)$ . How would one proceed? Extending the question, is there a general way to express $\cos\left(\frac{\theta}{k}\right)$ in terms of $\cos(\theta)$ ? (with $k\in\mathbb{N}$ ).",['trigonometry']
3455086,$g(g(f(z)))=z$ and $\prod\limits_{f(x)=0}^{} g(x)=1$.,"My friend recently gave me this system of functional equations, asking me if I could find holomorphic $f,g: \mathbb{C} \to \mathbb{C}$ satisfying: $g(g(f(z))) = z$ $\displaystyle\prod_{f(x)=0}^{} g(x)=1$ To which I promptly said, “no.” Thoughts? Hints?","['complex-analysis', 'functional-equations']"
3455140,What's wrong in my calculation of $\lim\limits_{n \to \infty} \sum\limits_{k=1}^n \arcsin \frac{k}{n^2}$,"I have the following limit to find: $$\lim\limits_{n \to \infty} \sum\limits_{k=1}^n \arcsin \dfrac{k}{n^2}$$ This is what I did: $$\lim\limits_{n \to \infty} \sum\limits_{k=1}^n \arcsin \dfrac{k}{n^2} = \lim\limits_{n \to \infty} \bigg ( \arcsin \dfrac{1}{n^2} + \arcsin \dfrac{2}{n^2} + ... + \arcsin \dfrac{n}{n^2} \bigg )$$ $$ \hspace{.8cm} = \arcsin 0 + \arcsin 0 + ... + \arcsin 0 $$ $$= 0 + 0 + ... + 0 \hspace{2.9cm}$$ $$=0 \hspace{5.2cm}$$ However, my textbook claims that the actual answer is in fact $\dfrac{1}{2}$ . I don't see how I could reach this answer.","['limits', 'calculus', 'trigonometry']"
3455167,Help creating a formula for a rating system with weighed ranks.,"I am attempting to create a 5 star rating system with a twist. Instead of calculating how many people rated something 5 stars then adding that to the total 4 stars etc..., I want to do something different. I want to use a ranking system that returns a rank between 0 and 5. When someone with a higher rank rates someone else, their rating carries more weight than someone with a lower rank giving the same rate. For example. User A is ranked 4.375 User B is ranked 4.0 User C is ranked 2.0 User A give User B 5 stars. That should dramatically increase User B 's rank. (ie +0.5%) If User C gives User B 5 stars. User B 's rank would go up a little. (ie +0.1%) The percentages are just examples. Second example User A gives User B a 1 star rating. User B 's rank will drop significantly. (ie -0.5%) User C gives User B a 1 star rating. User B 's rank will drop a little. (ie -0.1%) Again the percentages are purely fictional. And only meant to
  represent the idea that someone with a lower rank doesn't really
  affect someone with a bigger rank than them. I tried something like this which is the weighted rank, but instead of whole numbers (how many people rated someone 5 stars), I used the Raters Rank for the Raters Rank ((My Rank  * Raters Rank) + new rating) / (Raters Rank + 1) I would like to keep at least 3 significant figures and stay clamped between 0 and 5. I will only be storing the user's rank and a count of how many people have rated a user over time. No historical data will be kept. As in, you don't know User A rated User B 1.0","['average', 'statistics', 'means']"
3455176,"ODE system, case algebraic multiplicity = 3 , geometric multiplicity = 2","I am solving a ODE system with k = 3 (algebraic multiplicity) and s=2 (geometric multiplicity): $\dot X(t) = AX(t)$ , Where A= \begin{bmatrix}
    2 & 1 & 1 \\
    1 & 2 & 1 \\
    -2 & -2 & -1
  \end{bmatrix} When I solve det(A−λ)= 0 I get 1 eigenvalue λ =1 with k=3, then I get 2 eigenvectors \begin{bmatrix}
    -1 \\
    0 \\
    1 
  \end{bmatrix} \begin{bmatrix}
    -1 \\
    1 \\
    0 
  \end{bmatrix} Now I am lost, I really dont know what to do next or how to find the general form of X(t). EDIT: I found what to do in the case of k=3 and s=1: you solve (A−λ) $V_1$ =0, (A−λ) $V_2$ = $V_1$ and (A−λ) $V_3$ = $V_2$ . Then $X(t)=C_1V_1e^{λ_1}+c_2e^{λ_1}(V_1t+V_2)+ C_3e^{λ_1}(\frac{V_1t^2}{2}+V_2t+V_3)$ . I know that a part of the solution I'm looking is $C_1V_1e^{λ_1}+ C_2V_2e^{λ_1}$ , with $V_1$ and $V_2$ the eigenvetors that I already have found. So I am looking for the last part of the solution.","['linear-algebra', 'ordinary-differential-equations', 'eigenvalues-eigenvectors']"
3455211,Graph with three bridges not in single path whith perfect matching,I want to show that it is possible to have a cubic graph $G$ with the following two properties: $G$ has three bridges that do not lie on a single path. $G$ has a perfect matching. My attempts have been modifying the following graph (Image source: https://mathoverflow.net/questions/98385/cubic-graphs-without-a-perfect-matching-and-a-vertex-incident-to-three-bridges ) I have tried to replace the vertex $1$ with a graph such that it allowed to include all the edges adjacent to $1$ but all of my attempts have been unsuccessful.,"['graph-theory', 'matching-theory', 'discrete-mathematics']"
3455241,Local/global maximum,Suppose I have the following function $f(x)=x^2(1-x^2)$ . Now this function has maxima at $\pm\frac1{\sqrt2}$ and they are equal. Is this maximum absolute or relative? It is absolute right?,"['maxima-minima', 'calculus', 'algebra-precalculus']"
3455253,For what classes of schemes can we compute cohomology via standard methods?,"I am trying to really get comfortable with sheaf cohomology by actually sitting down and computing a whole heap of examples. But I am wondering what schemes can we actually reasonably compute the cohomology of? Let's just restrict ourselves to projective schemes over a field to start with. Probably the simplest case is the cohomology of a hypersurface by taking the long exact sequence corresponding to the SES: $$
0 \longrightarrow \mathcal{O}(d) \longrightarrow \mathcal{O} \longrightarrow i_{*}\mathcal{O}_{V}(d) \longrightarrow 0
$$ for the closed immersion $i : V \rightarrow \mathbb{P}^{n}$ . Complements of hypersurfaces are similarly easy. For the case of curves, we know that the cohomology must vanish in degrees higher than $1$ , so we via a Serre duality argument we really only need to calculate the global sections, right? So what about arbitrary projective varieties? I know we can obtain the Hilbert polynomial by resolving the sheaf by line bundles. But can we actually calculate the explicit cohomology in any more general cases? What about complete intersections or smooth varieties? Or is any real generality hopeless? I tagged this as a soft question too since there may not be a concrete answer.","['sheaf-cohomology', 'soft-question', 'algebraic-geometry', 'homology-cohomology', 'schemes']"
3455290,"Degrees of Freedom, Standard Deviation, and the Geometry of it all","This question is going to be a little broad because I'm still quite the novice in about what I'm asking about. Regardless, here goes: I've started learning statistics, and something that I've found really beautiful is the connection between statistics and geometry. As I've come to understand the degrees of freedom, they're the number of dimensions of the sub-space that a random vector is constrained to. Here, let me start by giving a brief example, and then I'll get on with my question: Brief Example: If $\vec{x}$ is a vector with $n$ independent observations of some random variable $X$ , then it has $n$ degrees of freedom, because each of its components can take on whichever value, regardless of the values the other components took. In other words, $\vec{x}$ exists in $n$ dimensional space. As another example, let $\bar{x}$ be the mean of our $n$ datapoints. Then, the error vector... $$\vec{e} = \begin{bmatrix}x_1-\bar{x}\\x_2-\bar{x}\\ x_3-\bar{x}\\ \vdots \\x_n-\bar{x}\end{bmatrix}$$ ...which contains the errors of our sample-set from its mean as its components, is constrained to an $(n-1)$ dimensional subspace, as $\vec{e}\cdot\vec{1}$ , where $\vec{1}$ is a vector with $n$ rows of $1$ , is equal to zero. That is, the sum of the absolute errors from the mean is zero. Wikipedia explains it better than I do btw: https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics) My Question I originally had a longer question...but, as I don't want to say too much because I may very well be extremely confused... What role, geometrically, does $n-1$ play when calculating the standard deviation of a sample set? Here are my thoughts so far... If we know the mean of the population which we took the sample from, and the sample is to be representative of the population, then the mean of the sample must be equal to the mean of the population, and thus it can only exist in $(n-1)$ dimensional space (because once we know $n-1$ rows, we must also know the last component if the sample is to have a specific known mean). Then, for some reason, we need to divide the length of this vector by the square root of the number of dimensions it can exist in...why? .... I know my question isn't yet very clear, but that's because I'm still quite confused. I'll try to update it more as I learn more about degrees of freedom. Thank you.","['statistics', 'standard-deviation', 'geometry', 'intuition', 'probability']"
3455300,"If $H$ and $K$ are subgroups of a group $G$ and if $|H|$ and $|K|$ are relatively prime, prove that $H\cap K=\{1\}$","I've worked through this problem but I'm not sure if my logic is correct. This is my attempt of proof: Suppose $H\cap K\neq{\{1\}}$ then exists $a\neq{1}\in H\cap K$ such that $a\in H\wedge a\in K$ . We know that $1=|H|r+|K|s$ , then: $a=a^{|H|r+|K|s}=(a^{r})^{|H|}(a^{s})^{|K|}=1$ ! That way $a=1$ and $H\cap K=\{1\}$ . $\blacksquare$","['group-theory', 'abstract-algebra', 'proof-verification']"
3455306,"Let $A,B \in \mathcal{B}(\mathcal{H})$ with $A$ self-adjoint and $B$ positive. Prove that if $BAB + A = 0$, then $A = 0$.","What I need to prove: Let $A,B \in \mathcal{B}(\mathcal{H})$ with $A$ self-adjoint and $B$ positive. Prove that if $BAB + A = 0$ , then $A = 0$ . Since the definition of a positive operator relies on inner products, I've been trying to use the fact that $\langle (BAB + A)x, (BAB + A)x \rangle = 0$ to show that $\langle Ax, Ax \rangle = 0$ . I started by using the fact that the inner product is linear to split it into four inner products. I know that $\langle BABx, BABx \rangle$ and $\langle Ax, Ax \rangle$ are nonnegative, but I don't know how to show that $\langle ABx,BAx \rangle$ and $\langle BAx,ABx \rangle$ are nonnegative, which would force all four inner products to be zero. Could I have a hint?","['hilbert-spaces', 'operator-theory', 'functional-analysis']"
3455514,Continuation of functions beyond natural boundaries,"The article Continuation of functions beyond natural boundaries by John L. Gammel states I am particularly interested in the convergence of the $[N/N+1]$ Padé approximants beyond the natural boundary, since, as is well known, Borel [2] has shown that there exists a kind of analytic continuation which differs from the usual kind (the theory of the usual kind is due to Weierstrass), and Borel made use of examples such as the ones studied here in showing that in some cases it is possible to continue functions beyond what Weierstrass called natural boundaries. I am interested in these examples because they seem to me suggestive of the direction in which comprehensive theorems about the domains in which Padé approximants converge and theorems about to what they converge are to be sought. where [2] references E. Borel, Lecons sur les fonctions monogènes d'une variable complexe , Gauthier-Villars, Paris, 1917. Unfortunately, it is in French and inaccessible to me. Does anyone know what technique of Borel Gammel is referring to? How is it possible to continue a function beyond its natural boundary?","['pade-approximation', 'analytic-continuation', 'analysis', 'lacunary-series', 'analytic-functions']"
3455520,"What is the longest, continuous line I can fit within a rectangular box under minimum radius of curvature and line separation conditions?","I have a rectangular area of known dimensions, $x$ and $y$ . I want to draw a continuous (i.e. non-crossing) line inside this rectangle that is as long as possible. The radius of curvature at any point on the line can not be less than a value, $r$ , and the line cannot come closer that distance, $p$ , to any other point on that line.
How do I determine the layout of this line, and its maximum length? This is inspired by the Hamiltonian path approach as a solution to the video game snake, as exhibited here . The Hamiltonian approach clearly has a defined analytical solution, but I suspect that with my additional constraints this mutates into a numerically-driven optimisation problem. I do not, as yet, have any other constraints, such as starting and finishing within the same region - I just want to maximise the line length per unit rectangle area. Can anyone direct me to a starting point? My initial takes were to develop solutions along the theme of spirals - either entirely concentric or racetrack-like but this leaves a lot of real estate (particularly the centre) untouched. I'd like to think there is a Hamiltonian-esque solution to fill-in the gaps.",['differential-geometry']
3455556,Prove that the following series converges to $1 - \frac{\pi}{4}$.,"We got the following identity by solving a problem in two different ways, but we don't know how to prove it. $$\sum_{n=0}^{\infty} [Si((4n+1)\pi)-Si((4n+3)\pi)] = 1 - \frac{\pi}{4}$$ where $$Si(x)=\int_0^x \frac{\sin(t)}{t}dt$$ We were able to verify that the first few thousand partial sums are very close to the RHS. Is there a way to prove this identity?","['definite-integrals', 'fourier-analysis', 'sequences-and-series']"
3455567,Why is Euler's Formula for Planar Graph Not Working Here?,"I have worked out $r(n) = 2^n$ , $e(n) = 1 + 3 \times 2^n$ , $v(n) = 2\times(2^n - 1) + 4$ The expressions of $r(n)$ , $e(n)$ , and $v(n)$ are correct and this can be verified with $n = 0, 1, 2, 3\ldots$ But when I calculate $v(n) - e(n) + r(n)$ , it does not equal to $2$ . What's wrong? Also, can we derive the relationship between v(n) and e(n) using the sum of degree of vertices?","['graph-theory', 'proof-verification', 'discrete-mathematics', 'planar-graphs']"
3455580,Why does the monotone convergence theorem not apply on Riemann integrals?,"I had just learned in measure theory class about the monotone convergence theorem in this version: For every monotonically increasing sequence of functions $f_n$ from measurable space $X$ to $[0, \infty]$ , $$
\text{if}\quad
\lim_{n\to \infty}f_n = f,
\quad\text{then}\quad
\lim_{n\to \infty}\int f_n \, \mathrm{d}\mu = \int f \,\mathrm{d}\mu
.
$$ I tried to find out why this theorem apply only for a Lebesgue integral, but I didn't find a counter example for Riemann integrals, so I would appreciate your help. (I guess that $f$ might not be integrable in some cases, but I want a concrete example.)","['measure-theory', 'riemann-integration', 'examples-counterexamples']"
3455582,"The position of a hidden machine part, given a reading of total pollution","A machine has $n$ independent (hidden) movable parts and each part can have one of two different settings, $A$ or $B$ . The position of each movable part is governed by a set of probabilities, $w_{A_j}$ and $w_{B_j} = 1 - w_{A_j}$ , where $j$ denotes the particular part. Assuming that whenever a part has a setting of $A$ , it generates an amount of exhaust captured by the normal random variable $N (\mu_A, \sigma_A)$ . Furthermore, whenever a part has a setting of $B$ , it generates an amount of exhaust captured by the normal random variable $N (\mu_B, \sigma_B)$ . In that situation, the CDF for the total level of exhaust, $T$ , produced by the machine is given by: $\frac{W_A \text{erfc}\left(\frac{\mu _A-T}{\sqrt{2} \sigma _A}\right)+\left(n W_B\right) \text{erfc}\left(\frac{\mu _B-T}{\sqrt{2} \sigma _B}\right)}{2 n}$ , where $W_A$ is the sum of all $w_{A_j}$ and $W_B$ is the sum of all $w_{B_j}$ . Deriving the above: I found the above using Mathematica. Assuming a machine with only four part, we have \[ScriptCapitalD] = MixtureDistribution[{w1A1, 1 - w1A1, w2A2, 1 - w2A2 , w3A3, 1 - w3A3, w4A4, 1 - w4A4 }, {NormalDistribution[muA1, sdA1], NormalDistribution[muB1, sdB1], NormalDistribution[muA2, sdA2], NormalDistribution[muB2, sdB2], NormalDistribution[muA3, sdA3], NormalDistribution[muB4, sdB4], NormalDistribution[muA4, sdA4], NormalDistribution[muB4, sdB4]}] producing the following $CDF$ Function[\[FormalX], (1/8)*w2A2*Erfc[(-\[FormalX] + muA)/(Sqrt[2]*sdA)] +(1/8)*w3A3*Erfc[(-\[FormalX] + muA)/(Sqrt[2]*sdA)] + (1/8)*w4A4*Erfc[(-\[FormalX] + muA)/(Sqrt[2]*sdA)] + (1/8)*w1A1*Erfc[(-\[FormalX] + muA1)/(Sqrt[2]*sdA1)] +(1/8)*(1 - w2A2)*Erfc[(-\[FormalX] + muB)/(Sqrt[2]*sdB)] + (1/8)*(1 - w3A3)*Erfc[(-\[FormalX] + muB)/(Sqrt[2]*sdB)] + (1/8)*(1 - w4A4)*Erfc[(-\[FormalX] + muB)/(Sqrt[2]*sdB)] + (1/8)*(1 - w1A1)*Erfc[(-\[FormalX] + muB1)/(Sqrt[2]*sdB1)]] Now, assuming that all settings of $A$ have equal means and variances, and assuming the same for every setting of $B$ , we get the much simpler $CDF$ : (1/8)*((w1A1 + w2A2 + w3A3 + w4A4)*Erfc[(-\[FormalX] + muA)/(Sqrt[2]*sdA)] -(-4 + w1A1 + w2A2 + w3A3 + w4A4)*Erfc[(-\[FormalX] + muB)/(Sqrt[2]*sdB)]) A pattern thus appears, which allowed me to express the general formula stated above. And now for the question: Question: Let us assume that an inspector is interested one particular part of the machine (let's say the first part). The inspector obtains a precise reading of the total level of exhaust, and now wonders ""what is the probability that the focus part is in position A?""","['conditional-probability', 'probability-distributions', 'probability-theory', 'probability']"
3455608,What is the probability of randomly generating a tautology?,"Suppose we randomly generate a classical Hilbert propositional calculus formula $F$ with $n$ variables, using the following method: $F = x_i$ for each of $i \leq n$ with probability $\frac{1}{n+2}$ . $F = \neg F_1$ , where $F_1$ is generated independently using the same method. $F = F_1 \to F_2$ , where $F_1$ and $F_2$ are generated independently using the same method. It follows from the extinction criterion for the Galton-Watson branching processes , that the process of generation will terminate with probability $1$ and thus our random formula is well defined. My question is: What is the probability that $F$ is a tautology? It is clearly less, than $\frac{2}{n+2}$ . However, it is clearly greater, than $\frac{n}{(n + 2)^3}$ which is the probability of generating a formula of the form $x_i \to x_i$ .","['propositional-calculus', 'logic', 'hilbert-calculus', 'stochastic-processes', 'probability']"
3455740,Can we find the complex roots by using Newton's method? [duplicate],"This question already has answers here : How to find a starting point for root finding in complex plane? (2 answers) Closed 4 years ago . Is it possible to find the complex roots of a function by using Newton's method? If the answer is yes, how to do it?","['newton-raphson', 'derivatives', 'complex-numbers', 'roots']"
3455773,Are elements of a sample i.i.d. realizations of the same random variable or realizations of different i.i.d. random variables?,"If there is some sample $X^n=(x_1,x_2,\dots,x_n)$ , do we consider the elements of this sample $x_i$ independent and identically-distributed realizations of the same random variable $X$ or are they all realizations of different independent and identically distributed random variables $X_1,X_2,...,X_n$ (observation $x_1$ is the realization of a random variable $X_1$ , observation $x_2$ is the realization of a random variable $X_2$ etc.)? I hope this makes sense.","['statistics', 'probability-theory', 'probability', 'random-variables']"
3455807,Proving the coefficients of the power series are the Taylor coefficients,"Supose we have $f:I \to \mathbb{R}$ a $C^{\infty}$ function and let $I=(a- \delta, a+\delta)$ $\forall x \in I$ we can write the function as the power series $f(x) = \sum_{n = 0}^{\infty} a_n (x - x_0)^n$ I need to show that the coefficients are exactly the Taylor coefficients: $a_n = \frac{f^{(n)} (x_0)}{n!}$ I know the standard approach would be to argue we can derive each term but since we don't know if the series of the derivatives converge uniformly, we would have to show that every power series converge uniformly in a compact inside its convergence interval and also show the series of derivatives has the same convergence radius of the original series. I know I am being overly cautious here, but I would like to know if there is another way. For example, using induction to show what the formula of the n-th derivative of the series would be... Any comment would help!","['power-series', 'taylor-expansion', 'analysis', 'real-analysis']"
3455849,"How to prove $\int^{\infty}_0 e^{-c^2/a^2}c^4\,dc=\frac{3}{8}a^5\sqrt\pi$?","How do i prove this integral can someone give me proof i've been trying this too long i tried direct integration by parts, differentiation all to no avail.Please support us :) $$\int^{\infty}_0 e^{\frac{-c^2}{a^2}}c^4\,dc=\frac{3}{8}a^5\sqrt\pi$$","['integration', 'improper-integrals', 'analysis', 'real-analysis']"
3455875,"If sequence converges only uniformly, could any of the mean serieses converge absolutly?","TIL that if a series converges absolutely, the arithmetic, geometric, and harmonic means' serieses also converge to the same limit. Mathematically speaking: If $$\lim_{n \to \infty} a_n = L $$ Then: $$\lim_{n \to \infty} \frac{a_1 + a_2 + ... + a_n}{n} = \lim_{n \to \infty} \sqrt[n]{a_1 a_2 a_3 ... a_n} = \lim_{n \to \infty} \frac{n}{a_1^{-1}+a_2^{-1}+\ldots+a_n^{-1}} = L$$ Partial proofs: Prove convergence of the sequence $(z_1+z_2+\cdots + z_n)/n$ of Cesaro means On Cesàro convergence: If $ x_n \to x $ then $ z_n = \frac{x_1 + \dots +x_n}{n} \to x $ Would this be true if $L = \infty$ ? If not, I'm seeking an example that will satisfy: $$lim_{n \to \infty} a_n = \infty $$ While: $$lim_{n \to \infty} \frac{a_1 + a_2 + ... + a_n}{n} = S $$","['limits', 'means', 'sequences-and-series', 'real-analysis']"
3455945,Proving a level set is a submanifold or is empty,"Let $A$ be an invertible, symmetric $n\times n$ matrix and define $F:\mathbb R^n\rightarrow\mathbb R$ by $F(x)=x\cdot Ax$ For $k>0$ , how can I show that the set $T_k=\{x\in\mathbb R^n:F(x)=k\}$ is either empty or a submanifold of $\mathbb R^n$ ? I know that if $rank(\delta F(x))=1$ for all $x\in T_k$ , then $T_k$ is a submanifold of $\mathbb R^n$ $\delta F(x)=(\delta_1 F(x)...\delta_n F(x))$ The rank of $\delta F(x)$ is zero iff all the partial derivatives are zero, why does this imply that $T_k$ is empty?","['matrices', 'multivariable-calculus', 'differential-topology']"
3455961,"If $H$ Hilbert, $A\colon H\to H$ bounded and $A(M)$ closed for all closed subspaces $M$, then $A(H)$ and $\ker(A)$ not both infinite dimensional?","Let $H$ be a Hilbert space over $\mathbb{C}$ and $A\colon H\to H$ a bounded linear map. Assume that $A(M)$ is closed for all closed subspaces $M$ of $H$ . How do I prove that $A(H)$ and $\ker(A)$ cannot both be infinite dimensional? As the hint of the exercise suggests, I tried to construct an orthonormal sequence $u_{n}:=a_{n}x_{n}+b_{n}y_{n}$ for some suitable scalars $a_{n},b_{n}\in\mathbb{C}$ , and orthonormal sequences $x_{n}\in\ker(A)^{\perp}$ and $y_{n}\in\ker(A)$ . Then the closed linear span $M$ of $\{u_{n}\}_{n}$ should yield a contradiction. So if $\ker(A)$ is infinite dimensional, we can indeed find an orthonormal sequence $(y_{n})$ in $\ker(A)$ . I'm not sure why we can find one in $\ker(A)^{\perp}$ yet, but assume that it is possible and choose an orthonormal sequence in $(x_{n})$ in $\ker(A)^{\perp}$ . Then choose a real sequence $a\in\ell^{1}(\mathbb{N})$ with $a_{n}^{2}\leq1$ and define another sequence by $b_{n}:=(1-a_{n}^{2})^{1/2}$ (for example $a_{n}=1/n^{2}$ ). Then $u_{n}:=a_{n}x_{n}+b_{n}y_{n}$ is an orthonormal sequence. Then define $$v_{m}:=\sum_{n=1}^{m}u_{n}$$ and note that $$Av_{m}=\sum_{n=1}^{m}\alpha_{n}Ax_{n}\qquad\text{(since $Ay_{n}=0$)}.$$ The sequence $(v_{m})$ does not converge because it is a sum of pairwise orthonormal vectors. Now I was hoping to conclude that $(Av_{m})$ does converge and that the limit does not lie in $A(M)$ , where $M$ is closed span of $\{u_{n}\}_{n}$ . Is my reasoning right? And if it is, how do I finish the proof? Any suggestions are greatly appreciated.","['orthonormal', 'hilbert-spaces', 'linear-algebra', 'functional-analysis', 'sequences-and-series']"
3455967,$(xy+2xy\ln^2y+y\ln y)\text{d}x+(2x^2\ln y+x)\text{d}y=0$,"Solve: (Hint: use $x\ln y=t$ ) $$(xy+2xy\ln^2y+y\ln y)\text{d}x+(2x^2\ln y+x)\text{d}y=0$$ My Work: $$x\ln y=t, \text{ d}t=\ln y \text{ d}x+\frac{x}{y} \text{ d}y$$ $$(x+2x\ln^2y+\ln y)\text{ d}x+\left(\frac{2x^2}{y}\ln y+\frac{x}{y}\right)\text{d}y=0$$ $$(x+2x\ln^2y)\text{ d}x+\left(\frac{2x^2}{y}\ln y\right)\text{d}y+\text{d}t=0$$ $$(x+2t\ln y)\text{ d}x+\left(\frac{2x}{y}t\right)\text{d}y+\text{d}t=0$$ $$\left(\frac{x}{t}+2\ln y\right)\text{d}x+\left(2\frac{x}{y}\right)\text{d}y+\frac{\text{d}t}{t}=0$$ $$\frac{x}{t}\text{d}x+2\text{ d}t+\frac{\text{d}t}{t}=0$$ $$\frac{x}{t}\text{d}x=\left(-2-\frac{1}{t}\right)\text{d}t$$ $$\frac{x^2}{2}=-t^2-t+c$$ $$\frac{x^2}{2}=-x^2\ln^2y-x\ln y+c$$ 1. Is my answer correct? 2. How we could recognize that we should use $x\ln y=t$ . If question didn't Hint? 3. All the way that I did to solve this equation was weird for me (because for example we had $dx,dy,dt$ in line 3) and had not saw this way to solve differential equation before is There any other way to simplification?",['ordinary-differential-equations']
3455970,Conjecture: smallest missing mod value always yields previous prime,"I've come up with a conjecture that seems similar in strength to Legendre's or Oppermann's, but maybe subtly different. Let $a_n$ be the smallest nonnegative value such that there is no $m$ in $1<m<n/2$ where $n \equiv a_n \pmod m$ . Then for all $n>2$ , we have $n-a_n=p_{\pi(n)-1}$ , the closest previous prime to $n$ . Take $n=16$ as an example: $$\begin{eqnarray}
16 &\equiv 0 \pmod 2 \\
   &\equiv 1 \pmod 3 \\
   &\equiv 0 \pmod 4 \\
   &\equiv 1 \pmod 5 \\
   &\equiv 4 \pmod 6 \\
   &\equiv 2 \pmod 7
\end{eqnarray}$$ The smallest value not seen is $a_n=3$ , and $16-3=13$ is the previous prime. In cases where $n$ itself is prime, e.g. $17$ yielding the values $\{1,2,1,2,5,3,1\}$ , you can either interpret $0$ as the missing value and $17$ as the prime, or $4$ giving $17-4=13$ . (I'm not sure which is the more consistent interpretation.) I've verified this empirically through $10^5$ , but cannot come up with a proof. In fact, I suspect a proof would be very difficult since what this seems to come down to is whether there is always a prime in the interval $(n,n+d)$ for a composite $n$ , where $d$ is the largest proper divisor of $n$ . This has its worst case for forms of $p^2$ , which seem to require a prime in $\left(p^2, p(p+1)\right)$ . Note that when $a_n < \lfloor \sqrt{n} \rfloor$ , it is easily provably true; the problem is you can't guarantee it will be in that range, despite the fact that it almost certainly is for all $n \geq 127$ . I'm curious whether this conjecture already exists somewhere or is actually equivalent to one of the better-known prime gap conjectures. Better yet would be a proof, but that's obviously wishful thinking.","['conjectures', 'modular-arithmetic', 'number-theory', 'elementary-number-theory', 'prime-gaps']"
3455973,"What can be said about the theory of inner product spaces using only the group structure and the mapping $(u, v, w) \mapsto \langle u, v \rangle w$?","Consider the language $(+, -, 0, \langle - , - \rangle -)$ of abelian groups, with an additional ternary operation $\langle - , - \rangle -$ , which is intended to represent the operation of taking vectors $u, v, w$ of an inner product space and returning $\langle u, v \rangle w$ . Let $T$ be the theory consisting of all first-order sentences written in this language which are satisfied by all real inner product spaces (or maybe even ""rational inner product spaces""?). My broad question is: what can be said about $T$ ? Is it interesting, has it been studied? Two concrete questions are: Is $T$ finitely axiomatizable? What are interesting structures that model $T$ , apart from inner product spaces? (This question does not have an application in mind, it is plain curiosity.)","['universal-algebra', 'model-theory', 'logic', 'linear-algebra']"
3456011,"Given a space $X$, construct a CW complex $L(X)$ s.t. they have the same fundamental group","This is exercise 1.2.15 in Hatcher's Algebraic topology Given a space $X$ with basepoint $x_0∈X$ , we may construct a CW complex $L(X)$ having a single $0$ -cell, a $1$ -cell $e^1_γ$ for each loop $γ$ in $X$ based at $x_0$ , and a $2$ -cell $e^2_τ$ for each map $τ$ of a standard triangle $PQR$ into $X$ taking the three vertices $P,Q$ and $R$ of the triangle to $x_0$ . The $2$ -cell $e^2_τ$ is attached to the three $1$ -cells that are the loops obtained by restricting $τ$ to the three oriented edges $PQ,PR$ and $QR$ . Show that the natural map $L(X)→X$ induces an isomorphism $π_1(L(X))\cong π_1(X,x_0)$ . I met some problem in constructing the CW complex $L(X)$ , here are my thoughts: $1$ . $L(X)$ have a single $0$ -cell, and for each loop $γ$ in $X$ based at $x_0$ , is has a $1$ -cell $e^1_γ$ . At this time, $L(X)$ is a wedge sum of circles, each circle $S^1$ represents a loop in $X$ based at $x_0$ . $2$ . For map $\tau:\text{triangle } PQR\to X$ , $\tau$ maps $P,Q,R$ to $x_0$ and maps $PQ$ , $PR$ , $QR$ to loops in $X$ based at $x_0$ . Let $\overrightarrow{PQ}$ correspond to loop $a$ in $X$ (also a loop in $L(X))$ , $\overrightarrow{PR}$ correspond to loop $b$ , then $\overrightarrow{QR}$ correspond to $a^{-1}b$ . $3$ . $2$ -cell $e^2_\tau$ is attached to the three $1$ cells $a,b,a^{-1}b$ , we obtain relation $a\cdot a^{-1}b \cdot b^{-1}=1$ , which is trivial. There's something wrong here since I don't fully understand the construction of $L(X)$ . So how does the 2-cells $e^2_\tau$ attached to $1$ -skeleton of $L(X)$ ? Update : I now realized that triangles in $L(X)$ is just triangulation of $2$ -cells in $X$ , and it doesn't change homotopy type, so $\pi_1(L(X))\cong \pi_1(X,x_0)$","['general-topology', 'algebraic-topology']"
3456018,Sum of squares of Weber Modular Functions,"Let $\tau\in\mathbb C$ such that $\mathrm{Im}\left(\tau\right)>0$ . Define $q=e^{2\pi i\tau}$ . Then define the Weber modular functions as $$
\mathfrak f\left(\tau\right)=q^{-\frac1{48}}\prod_{n=1}^\infty\left(1+q^{n-\frac12}\right)=e^{-\frac{i\pi}{24}}\frac{\eta\left(\frac{\tau+1}2\right)}{\eta\left(\tau\right)}=\frac{\eta\left(\tau\right)^2}{\eta\left(\frac\tau2\right)\eta\left(2\tau\right)}\\
\mathfrak f_1\left(\tau\right)=q^{-\frac1{48}}\prod_{n=1}^\infty\left(1-q^{n-\frac12}\right)=\frac{\eta\left(\frac\tau2\right)}{\eta\left(\tau\right)}\\
\mathfrak f_2\left(\tau\right)=\sqrt2q^{\frac1{24}}\prod_{n=1}^\infty\left(1+q^n\right)=\frac{\sqrt2\eta\left(2\tau\right)}{\eta\left(\tau\right)}
$$ Can $$
S\left(\tau\right)=\mathfrak f\left(\tau\right)^2+\mathfrak f_1\left(\tau\right)^2+\mathfrak f_2\left(\tau\right)^2
$$ be written more compactly? Am I missing any helpful identites? This came up in a physics problem I was solving. Extra Question I managed to show that $S\left(\tau+8\right)=e^{-\frac{2\pi i}3}S\left(\tau\right)$ , so I realised that this integral is interesting too: $$
g\left(a\right)=\frac18\int_0^8\left\lvert S\left(b+ia\right)\right\rvert^2\mathrm db
$$ But I have no idea how to solve it. Any help would be appreciated.","['analytic-number-theory', 'number-theory', 'modular-forms', 'special-functions']"
3456068,"Solving an estimating problem with MLE of a function, condition of $\theta$","I was given a question to find the estimator $\theta$ by moments method of the function: $$f_{X}(x)= \begin{Bmatrix}
\frac{3x^2}{2\theta^3} & -\theta<x<\theta\\ 
 0& \text{else}
\end{Bmatrix}$$ The first moment is zero, and by the second moment I got that: $$\hat{\theta}= \sqrt{\frac{5S^2_x}{3}}$$ Now if I were to find the estimator with MLE, for the sports, I would find the function $L(\theta)$ : $$L(\theta) = \prod_{i=1}^n \frac{3x_i^2}{2\theta^3} \times{I_{(-\theta<x_i<\theta)}}$$ Now I'll play a little with the condition of the Indicator variable I so that: $$ L(\theta) = \prod_{i=1}^{n}\Bigl(\frac{3x_i^2}{2\theta^3}\Bigr) \times I_{(-\theta<\min(x_i))} \times I_{(\max(x_i)<\theta}$$ Suppose I ignore the constant $ \prod_{i=1}^{n}\Bigl(\frac{3x_i^2}{2}\Bigr)$ part, and I'm only trying to convert the condition on $x$ to a condition of $\theta$ , but I'm in a little problem here: $$-\theta<\min(x_i) \rightarrow-\min(x_i)<\theta$$ And $$\max(x_i)<\theta $$ Eventually I can only tell what is smallr than $\theta$ , but not what bounds it from above.
Virtually I'm looking for a condition such as $$f(x_i) <\theta<g(x_i)$$ where $f$ and $g$ are some functions that probably involve $\max$ or $\min$ .
Can anyone direct me where can I extract a condition of an upper bound?","['statistics', 'maximum-likelihood']"
3456121,Large deviation bound for squared norm of the sum of two random variables,"I want to pose this question as general as possible and ask for reference of what to do in similar situations. I'll incrementally add details to narrow down the problem. I want to derive large deviation bound for $\| X + Y \|_2^2$ , where $X$ and $Y$ are $p$ -dimensional dependent vectors; I believe in my situation it is impossible to compute the quantiles of $Z = \| X + Y \|_2^2$ . Formally, I want to get something like $$
\mathbb{P}( \| X + Y \|_2^2 > \lambda(x)) \le e^{-x},
$$ where $\lambda(x)$ is a deterministic function of $x$ and characteristics of $X$ and $Y$ . Are there any general techniques, approaches or ways of thinking in this most generic situation? Detail 1. I know that $Y \sim \mathcal{N}(0, \mathbf\Sigma)$ . Detail 2. I know that $\mathbb{E} \| X \|_2^2 \le \Delta$ , for fixed $\Delta$ . Detail 3. I know that the magnitude of $Y$ is much higher than that of $X$ , but I cannot formally deduce the above-mentioned inequality to something similar to $$
\mathbb{P}(\| Y \|_2^2 \ge \lambda_Y(x)) \le e^{-x}. 
$$ However, I know that $\lambda(x)$ should be large only because of $Y$ and not $X$ . Notice that if $\lambda(x)$ is allowed to be random then the choice $\lambda(x) = \lambda_Y(x) + \| X \|_2 + 2X^\top Y$ would do the job just fine. I'd appreciate any ideas, suggestions and/or comments.","['statistics', 'concentration-of-measure', 'large-deviation-theory', 'normal-distribution', 'probability']"
3456122,Probability density function of harmonic oscillation,"This is within the domain of physics, but I am interested in this problem from a mathematical / probability perspective. Suppose a mass on a spring is pulled to a length A and released. The mass undergoes harmonic oscillation. I know that the motion is of the form: $$x(t) = A \cos(\omega t + \phi) $$ Now I am interested in finding the probability density function of the position $x$ at time $t$ , assuming time is a random variable uniformly distributed along the period of oscillation. How can this be done, given the above formula?","['physics', 'probability-distributions', 'probability']"
3456149,"Find derivative $\frac{dy}{dx}$, given $y(x)=\sin^{-1}\left(\frac{5\sin x+4\cos x}{\sqrt{41}}\right)$","Find $\dfrac{dy}{dx}$ if $y=\sin^{-1}\bigg[\dfrac{5\sin x+4\cos x}{\sqrt{41}}\bigg]$ My Attempt Put $\cos\theta=5/\sqrt{41}\implies\sin\theta=4/\sqrt{41}$ $$
y=\sin^{-1}\big[\sin(x+\theta)\big]\implies\sin y=\sin(x+\theta)\\
y=n\pi+(-1)^n(x+\theta)\\
\boxed{\frac{dy}{dx}=(-1)^n}
$$ But my reference gives the solution $y'=1$ , am I missing something here ?","['trigonometry', 'inverse-function', 'derivatives']"
3456214,Finding $\cos^2(C)+\cos^2(A)+2\sin(C)\sin(A)\cos(B)$ in $\Delta \text{ABC}$,"I am attempting the following trigonometry problem. Given that in an acute angled triangle $\Delta \text{ABC}$ , the following equalities hold true $$\cos^2(A)+\cos^2(B)+2\sin(A)\sin(B)\cos(C)=\dfrac{15}{8}\\
\cos^2(B)+\cos^2(C)+2\sin(B)\sin(C)\cos(A)=\dfrac{14}{9}$$ Find the value of $\cos^2(C)+\cos^2(A)+2\sin(C)\sin(A)\cos(B)$ . My Attempt : Let the unknown quantity be $x$ . Then we have, by adding all the terms. $$2\sum_{cyc}\cos^2(A)-2\sum_{cyc}\sin(A)\sin(B)\cos(A+B)=\dfrac{15}{8}+\dfrac{14}{9}+x$$ Also simplifying the second summation term as follows, we get $$\sin(A)\sin(B)\cos(A+B)=\dfrac{\sin(2A)\sin(2B)}{4}-(1-\cos^2(A))(1-\cos^2(B))$$ I'm not sure how to proceed further. Any hints are appreciated. Even hints to other possible pathways to the solution are welcome. Thanks","['contest-math', 'trigonometry', 'triangles', 'geometry']"
3456239,Limit along the line,"I came across the following passage: Limit of a function $f$ along the line $l: (x_0  +t\cos a, y_0+t\sin a)$ , $t\in \mathbb{R}, a\in [0,\pi]$ , through the point $(x_0, y_0)$ is the following limit: $$\lim_{t\to 0}f(x_0  +t\cos a, y_0+t\sin a)$$ I don't understand the representation of the line $l$ . Is the collection of points $(x_0  +t\cos a, y_0+t\sin a)$ a set of points that satisfies the equation of the line $l$ ?
I'm familiar with polar coordinates and I've tried representing a point $(x,y)$ and plugging in the equation $y=mx+n$ but I don't get anything similar to the stuff in the passage above.","['limits', 'multivariable-calculus', 'polar-coordinates']"
3456244,Statement with limits of sequences,"I have some statements with limits. We can have arbirary $a(n)$ . *First $\implies$ if limit of $n*a(n)$ is zero, then $a(n)$ must be zero, because if we multiply something with no-zero value and it is still zero, then it must be zero. If limit of $a(n)$ is zero, then $a(n)$ is limited. $\impliedby$ counter: $a(n)=1/n$ is limited, but $n*(1/n)$ is one, so it is not correct *Second $\implies$ counter: if we have limit of $((n)^{1/2})/n$ , it is zero, but $(n)^{1/2}$ is not limited, so it is not correct $\impliedby$ I am not quite sure about this one, dont know it is correct for all sequences, especially sin and so on, can you please explain? *Third Both are true, because if limit of $a(n)$ was $-1$ , multiplied by $3$ , it would have been $-1$ , but it is $1$ , so a(n) must be one Thank you for your feedback and please give me hand especially with that second one "" $\impliedby$ "".","['limits', 'sequences-and-series']"
3456268,The case of the missing ninth of a $2$€ coin,"In answering Expected value of the number of bills , I came across a phenomenon the likes of which I don't think I've encountered before, and I'd like to know more about it. You draw coins, each coin independently being a $1$ € coin or a $2$ € coin with equal probability. Obviously you'd expect to draw as many $2$ € coins as $1$ € coins. In particular, the expectation of $A-B$ , where $A$ is the number of $1$ € coins drawn and $B$ is the number of $2$ € coins drawn, is $0$ after any given number of draws. However, conditional on reaching a total value of $n$ euros, the expectation of $A-B$ tends to $\frac13$ for $n\to\infty$ (in fact, it's positive for all $n\gt2$ ): The probability to reach $n$ euros with $k$ $2$ € coins and $n-2k$ $1$ € coins is $\binom{n-k}k2^{k-n}$ , so the expectation of $B$ is \begin{eqnarray*}
&&\frac{\sum_{k=0}^n\binom{n-k}k2^{k-n}k}{\sum_{k=0}^n\binom{n-k}k2^{k-n}}=\frac{\frac2{27}(3n-1)+O\left(2^{-n}\right)}{\frac23+O\left(2^{-n}\right)}=\frac n3-\frac19+O\left(2^{-n}\right)\;,\\
\end{eqnarray*} the expectation of $A=n-2B$ is $\frac n3+\frac29+O\left(2^{-n}\right)$ , and  the expectation of $A-B$ is $\frac13+O\left(2^{-n}\right)$ . This is rather counterintuitive (to me): For any given number of coins the expectation is $0$ , but for any given value of the coins it's positive. This is the stuff that paradoxes are made of if you're not careful how you talk about it, e.g.: “Someone is playing this game. What value do you expect for $A-B$ ?” – “ $0$ .” – “So far they drew $137$ €. Now what do you expect?” – “ $\frac13$ .” The resolution here is (as it often is) that the conditions aren't properly defined – we don't know why and when the person is telling us this amount. If they fixed a number of draws to wait for and then told us the total value at that point, the correct answer would still be $0$ ; if they fixed a total value to wait for and then told us when it was reached, the correct answer would be $\frac13$ , but then the paradox of changing our mind just because we were told some number, no matter which one, wouldn't arise, because it's the stopping protocol that makes the difference. Still, a certain uneasy sense of paradox remains, even if it temporarily retreats under the glare of careful analysis. I don't have any concrete questions about this, but I'd be interested to hear about any other cases where such a phenomenon occurs, or names by which it's known, or approaches to deal with it, and perhaps also to ease that lingering sense of paradox.","['expected-value', 'paradoxes', 'soft-question', 'probability']"
3456281,$\int \frac{dx}{x^3+x^2\sqrt{x^2-1}-x}$,solve: $$\int \frac{\mathrm dx}{x^3+x^2\sqrt{x^2-1}-x}$$ I tried: $$\begin{align}\int \frac{\mathrm dx}{x(x^2-1)+x^2\sqrt{x^2-1}}&=\int \frac{\mathrm dx}{x(\sqrt{x^2-1}\sqrt{x^2-1})+x^2\sqrt{x^2-1}}\\&=\int \frac{\mathrm dx}{x\sqrt{x^2-1}(\sqrt{x^2-1}+x)}\end{align}$$ $x=\sin t$ $$\int \frac{\mathrm dt}{\cos t\sin t-\sin^2t}$$ And I can not continue from here.,['integration']
3456296,"If $V = \text{null}(\textsf{T}-\lambda\textsf{I}) \oplus \text{range}(\textsf{T}-\lambda\textsf{I})$, then prove that $\textsf{T}$ is diagonalizable","If $\textsf{V}$ is a finite-dimensional complex vector space, $\textsf{T}\in\mathcal{L}(\textsf{V})^1$ , $\lambda$ is arbitrary in $\mathbb{C}$ and if $$\textsf{V} = \text{null}(\textsf{T}-\lambda\textsf{I}) 
\oplus \text{range}(\textsf{T}-\lambda\textsf{I})$$ then prove that $\textsf{T}$ is diagonalizable. Attempt : I am solving Axler's 3 edition book in Exercise $5c.$ The book hasn't introduced the Jordan normal form or the generalized eigenvectors. Could someone please give a direction to move ahead. Thanks a lot for your help. $^1$ $\mathcal{L}(\textsf{V})$ is the set of all linear maps from $\textsf{V}$ to itself.","['diagonalization', 'linear-algebra', 'linear-transformations', 'eigenvalues-eigenvectors']"
3456307,A bound for $\sqrt\frac{b+c-a}a+\sqrt\frac{c+a-b}b+\sqrt\frac{a+b-c}c$ in a triangle,"Assume that $ABC$ is a triangle with $a\geq b\geq c$ , where the angle $A$ has a fixed value. We denote by $\Sigma$ the sum $$\sqrt\frac{b+c-a}a+\sqrt\frac{c+a-b}b+\sqrt\frac{a+b-c}c.$$ Then the only possible values of $A$ are $\pi/3\leq A<\pi$ and we have: (i) The smallest possible value $\Sigma$ is $$\frac{4\sin\frac A2+\sqrt{2\left( 1-\sin\frac A2\right)}}{\sqrt{2\sin\frac A2}}.$$ (ii) If $\pi/3\leq A<\pi/2$ then the largest possible value of $\Sigma$ is $$\frac{4\cos A+\sqrt{2\left( 1-\cos A\right)}}{\sqrt{2\cos A}}.$$ (iii) If $\pi/2\leq A<\pi$ then there is no finite upper bound for $\Sigma$ . My question is how to prove (i), (ii), and (iii). I firstly tried to square the $LHS$ , but nothing. I also tried the Radulescu-Maftei theorem, but it didn't help. Hence, I am looking forward to seeing your ideas.","['contest-math', 'inequality', 'geometric-inequalities', 'geometry']"
3456395,"$\frac{d}{dx} \frac{1}{x+\frac{1}{x+\frac{1}{ \ddots}}}$, the derivative of an infinite continued fraction.","I computed the first few derivatives in the sequence $\frac{1}{x+\frac{1}{x}}, \frac{1}{x+\frac{1}{x+\frac{1}{x}}} \dots$ and eventually lost feeling in my fingers and also realized I was seeing nothing meaningful. Let $$f(x,t) = \overbrace{\cfrac{1}{x+\cfrac{1}{x+\cfrac{1}{\ddots}}}}^{x\text{ appearing }t \text{ times.}}$$ My question: does there exist a closed-form of the derivative of an infinite continued fraction, at least for positive arguments? That is, does $g(x)$ such that: $$g(x)=\lim_{t \to \infty}\frac{d}{dx}f(x,t)$$ Have a closed-form expression?","['continued-fractions', 'fractions', 'calculus', 'derivatives']"
3456402,Is it acceptable to say that a divergent series that tends to infinity is 'equal to' infinity?,"Consider a divergent series that tends to infinity such as $1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\cdots$ . The limit of this series is unbounded, and I have often seen people say that the sum 'equals infinity' as a shorthand for this. However, is it acceptable to write $1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\cdots = \infty$ in formal mathematics, or is it better to denote that the limit is equal to infinity? If so, how does one do this?","['real-analysis', 'notation', 'calculus', 'sequences-and-series', 'limits']"
3456432,"Study the convergence of $x_n$, $ x_{n+1}=\frac{1}{2}\big(\frac{x_n+3}{ x_n}\big)$, with $x_0=1.$","How can we prove that the limit of the sequence $x_n$ defined by: $ x_{n+1}=\frac{1}{2}\big(\frac{x_n+3}{ x_n}\big)$ , with $x_0=1$ exists? I have tried to prove that it is Cauchy , but I failed? Can I get some help, and thanks in advance.",['sequences-and-series']
3456440,Regarding the definition of a periodic function,"In a local textbook, a real function of the real variable $x$ is said to be periodic if there exists a positive real $T$ such that $$(\forall x \in D_f) \quad : \quad \begin{cases}x + T \in D_f \\ \\ f(x + T) = f(x) \end {cases}$$ What's confusing to me are two things the authors mention afterwards : They drew the corollary that for all $x \in D_f$ , for all $\mathbf{n \in \underline{\mathbb{Z}}}$ $f(x+nT)=f(x)$ For a $T$ -periodic function, it suffices to study it on $D_f \cap [0,T]$ . My question regarding point (1) : How do we prove $f(x+nT)=f(x)$ for $n \in \underline{\mathbb{Z}^-}$ while we haven't adopted the definition that imposes the further information $x-T\in D_f$ in the definition. My question regarding point (2) : Isn't it a redundance to use $[0,T]$ instead of $[0,T[$ while we know that $0 \in D_f \iff T \in D_f $ and $f(0) = f(T)$ when $0\in D_f$ . Thanks for any clarifications.","['periodic-functions', 'functions']"
3456449,Hardy inequality,"I'm looking for a reference or proof about the classical Hardy's inequality: $$\int_0^{+\infty} \left(\int_0^xf(t) \,dt\right)^p x^\alpha \, dx \leq C_1 \int_0^{+\infty}f(x)^px^{\alpha+p} \, dx \text{ for } \alpha<-1 \tag{$*$} $$ and $$\int_0^{+\infty}\left(\int_x^{+\infty}f(t)\,dt\right)^p x^\alpha \, dx \leq C_2 \int_0^{+\infty} f(x)^px^{\alpha+p}\,dx \text{ for } \alpha>-1 \tag{$**$} $$ for some constant $C_1,C_2>0$ independent of $f.$ I looked up wikipedia where there is a similar inequality but I'm not satisfied with the proof given. I also looked up the encyclopedia of mathematics but there a similar inequality is given without proof. I looked up the classic reference [ G.H. Hardy, J.E. Littlewood, G. Pólya, ""Inequalities"" , Cambridge Univ. Press (1934) ], where I found in the chapter named "" Hilbert's inequality [...]"" at page 245 the identity (330) , which is the same as the one I'm interested in except for the fact that $\alpha=-r$ and so the hypothesis becomes $r<1,r>1$ . The discussion preceding the identity, which supposedly subsumes its proof, seems quite lengthy and involved, and I feel there should be a more direct and easy proof. I would like a precise reference or even some proof written down here.","['integration', 'analysis', 'reference-request', 'real-analysis', 'functional-analysis']"
3456469,Summing discrete 3d coordinate lengths,"Consider a three dimensional discrete coordinate system $(x,y,z)$ , where $x,y,z\in$ natural numbers. The number of digits describing an integer coordinate for each dimension is $l_c=\lfloor log(c) \rfloor+1$ , where $c$ is $x$ , $y$ or $z$ . The total number of digits describing a point in the space is $l=\lfloor log(x) \rfloor+\lfloor log(y) \rfloor+\lfloor log(z) \rfloor+3$ . I am looking for a formula to describe how many points each total coordinate digit length can describe. Any suggestions? Example: As one digit for each dimension can describe a total of $(10)(10)(10)$ points, the total coordinate length $3$ can describe a total of $10^3$ points in the space. Two digits for any of the dimensions and one digit for the rest gives a total number of points possible to describe as $(3)(10^2-10)(10)(10)$ . In other words, a total of four digits can describe a maximum of $27000$ points in the space. A total of five coordinate digits can describe a maximum of $$(3)(10^3-10^2)(10)(10)+(3)(10^2-10)^2(10)=513000$$ points in the space. Six digits can describe a total number of $$(3)(10^4-10^3)(10)(10)+(6)(10^3-10^2)(10^2-10)(10)+(10^2-10)^3=8289000$$ points in the space. And so on. Any suggestions on how to produce a formula are greatly appreciated.","['permutations', 'summation', 'number-theory', 'discrete-mathematics', 'arithmetic']"
3456471,Finding $\int_0^\infty \frac{\ln{x}}{(x^2+e^2)^2}dx$,"How would one approach this integral? $$\int_0^{\infty} \frac{\ln{x}}{(x^2+e^2)^2}dx$$ For context, this was a part of an integration exercise, where the previous parts led to showing that $\int_0^{\infty} \frac{\ln{x}}{(x^2+a^2)}dx=\frac{\pi \ln{a}}{2a}$ , using a keyhole method involving residues (these parts were fine). We are required to use this result in solving the integral mentioned at the beginning of this post. Could someone guide me on how to approach this part? My first thought process was to let $a = e$ in the proven result, then multiplying top and bottom by $(x^2+e^2)$ in order to make it look like the integral we are trying to solve: $$\int_0^{\infty} \frac{\ln {x}}{(x^2+e^2)}dx  = \int_0^{\infty} \frac{x^2 \ln{x}}{(x^2+e^2)^2}dx+\int_0^{\infty}\frac{e^2\ln x}{(x^2+e^2)^2}dx$$ If one uses the $u=e^2/x$ substitution on the first term, then they can introduce the integral given in the question, but this results in having to evaluate the integral of a rational function with a fourth power denominator. I guess one could use partial fractions or contour integrals again to deal with this part, but I have a feeling that this approach probably not the intention of the exercise, although I may be wrong. Any help, and especially any help with some kind of description of the motivations behind the steps, would be greatly appreciated.","['integration', 'contour-integration', 'improper-integrals']"
3456477,Closed form of sum $\sum\limits_{k=1}^{\infty } \frac{(-1)^{k+1}}{\left\lfloor \sqrt{k}\right\rfloor}$,"In two previous problems ( Closed expression for sum $\sum_{k=1}^{\infty} (-1)^{k+1}\frac{\left\lfloor \sqrt{k}\right\rfloor}{k}$ and Closed expression for sum $\sum_{k = 1}^{\infty} \frac{\left\lfloor \sqrt{k} \right \rfloor}{k^2}$ ) the infinite sums contained the floor function (of a square root) in the numerator. Here we ask, in a simple example, what happens if the floor function is in the denominator. Question: what is the closed form of $\sum _{k=1}^{\infty } \frac{(-1)^{k+1}}{\left\lfloor \sqrt{k}\right\rfloor }$","['ceiling-and-floor-functions', 'closed-form', 'sequences-and-series']"
3456503,"Does $\sum_{n=0}^{\infty} \frac{x^2}{(1+x^2)^n}$ converge uniformly on $(-\infty,\infty)$?","Does $\displaystyle \sum_{n=0}^{\infty} \frac{x^2}{(1+x^2)^n}$ converge uniformly on $(-\infty,\infty)$ ? My attempt: No. Consider the case where $x=0$ , then $\displaystyle \sum_{n=0}^{\infty} \frac{x^2}{(1+x^2)^n} = 0$ . For $x \neq 0$ , observe $\displaystyle 0 \lt \frac{1}{(1+x^2)^n} \lt 1$ , so by geometric series formula $\displaystyle \sum_{n=0}^{\infty} \frac{x^2}{(1+x^2)^n}$ $\displaystyle = \frac{x^2}{1 - \frac{1}{1+x^2}} = 1+x^2$ (1) So clearly the series doesn't even converge for all $x$ , let alone converge uniformly. Now, my question is about the case where $x \neq 0$ . Does it converge uniformly to $1 + x^2$ ? (2) I think, ""yes"". By Dini's theorem for series the convergence of the series to $1 + x^2$ must be uniform since $1+x^2$ is continuous and $(-\infty,0) \cup (0,\infty)$ is compact. Is my reasoning for (1) and (2) correct?","['proof-verification', 'sequences-and-series', 'uniform-convergence', 'real-analysis']"
3456535,Show that following determinant is divisible by $\lambda^2$ and find the other factor.,"Show that $\begin{vmatrix}
a^2+\lambda &ab &ac \\ 
ab & b^2+\lambda & bc \\
ac & bc & c^2+\lambda
\end{vmatrix}=0$ is divisible by $\lambda^2$ and find the other factor. My attempt is as follows:- $$R_1\rightarrow R_1+R_2+R_3$$ $$\begin{vmatrix}
a(a+b+c)+\lambda &b(a+b+c)+\lambda &c(a+b+c)+\lambda \\ 
ab & b^2+\lambda & bc \\
ac & bc & c^2+\lambda
\end{vmatrix}=0$$ $$C_1\rightarrow C_1-\dfrac{a}{b}C_2$$ $$C_2\rightarrow C_2-\dfrac{b}{c}C_3$$ $$\begin{vmatrix}
\lambda-\dfrac{a\lambda}{b}&\lambda-\dfrac{b\lambda}{c} &c(a+b+c)+\lambda \\ 
-\lambda & \lambda & bc \\
0 & -\lambda & c^2+\lambda
\end{vmatrix}=0$$ Taking $\lambda^2$ common $$\lambda^2\begin{vmatrix}
1-\dfrac{a}{b}&1-\dfrac{b}{c} &c(a+b+c)+\lambda \\ 
-1 & 1 & bc \\
0 & -1 & c^2+\lambda
\end{vmatrix}=0
$$ $$\dfrac{\lambda^2}{bc}\begin{vmatrix}
b-a&c-b &c(a+b+c)+\lambda \\ 
-b & c & bc \\
0 & -c & c^2+\lambda
\end{vmatrix}=0
$$ $$R_1\rightarrow R_1-R_3$$ $$\dfrac{\lambda^2}{bc}\begin{vmatrix}
b-a&2c-b &ca+bc \\ 
-b & c & bc \\
0 & -c & c^2+\lambda
\end{vmatrix}=0$$ $$R_1\rightarrow R_1-R_2$$ $$\dfrac{\lambda^2}{bc}\begin{vmatrix}
2b-a&c-b &ca \\ 
-b & c & bc \\
0 & -c & c^2+\lambda
\end{vmatrix}=0$$ Now expanding it $$\dfrac{\lambda^2}{bc}\left(c(2b^2c-abc+abc)+(c^2+\lambda)(2bc-ac+bc-b^2)\right)=0$$ $$\dfrac{\lambda^2}{bc}\left(2b^2c^2+(c^2+\lambda)(3bc-ac-b^2)\right)=0$$ $$\dfrac{\lambda^2}{bc}\left(2b^2c^2+3bc^3-ac^3-b^2c^2+3bc\lambda-\lambda ac-\lambda b^2\right)=0$$ $$\dfrac{\lambda^2}{bc}\left(b^2c^2+3bc^3-ac^3+3bc\lambda-\lambda ac-\lambda b^2\right)=0$$ $$\dfrac{\lambda^2}{bc}\left(c^2(b^2+3bc-ac\right)+\lambda(3bc-ac-b^2)=0$$ So another factor seems to be $\dfrac{1}{bc}\left(c^2(b^2+3bc-ac)+\lambda\left(3bc-ac-b^2\right)\right)$ But actual answer is $a^2+b^2+c^2+\lambda$ . I tried to find my mistake, but everything seems correct. What am I missing here? Please help me in this.","['matrices', 'determinant']"
