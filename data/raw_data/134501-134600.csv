question_id,title,body,tags
2119371,How do you solve $x$ for this triangle? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question How do you solve for $x$ for this triangle? The $1$m square is enclosed by the triangle, which is not a side length of the triangle - that's why I'm having trouble.","['triangles', 'geometry']"
2119399,"Quadratic equation, find $1/x_1^3+1/x_2^3$",In an exam there is given the general equation for quadratic: $ax^2+bx+c=0$. It is asking: what does $\dfrac{1}{{x_1}^3}+\dfrac{1}{{x_2}^3}$ equal?,"['polynomials', 'roots', 'algebra-precalculus', 'symmetric-polynomials', 'quadratics']"
2119448,Number of nonnegative integral solutions of $3x+y+z \leq 25$,Find the number of nonnegative integral solutions of $$3x+y+z \leq 25$$ I can get the answer to $3x+y+z=25$ but I can't get the answer with inequality. Please help.,"['combinatorics', 'polytopes']"
2119465,Show that a function is differentiable,"I have a function 
$$f(x)=
\begin{cases}
x & \text{if } x \ge0 \\
x^2 & \text{if } x<0
\end{cases}
$$
and want to show that it is continuous but not differentiable at $x=0$ Now to show that a function is differentable we show that 
$$f'(x_0)= \lim_{x \to x_0}\frac{f(x)-f(x_0)}{x-x_0}$$ but I am always confused with such funtions. Do I have to choose $x$ or $x^2$ Taking the comments into consideration a functions is differentiable if the difference quotient $\frac{f(x)-f(x_0)}{x-x_0}, x_0\ne0$ approaches a limit. And limit exist only if left- and right-hand side limit is equal. So $$\lim_{x \to 0^-}= \frac{x^2-0}{x-0}=\frac{x^2}{x}=x=0$$
and $$\lim_{x \to 0^+}= \frac{x-0}{x-0}=\frac{x}{x}=1$$
thus they are not equal which means f is not differentiable. For the continuity part I am considering the definition: $\forall \varepsilon >0 \ \exists \delta>0$ s.t $\mid f(x)-f(x_0)\mid < \varepsilon$ if $\mid x-x_0 \mid < \delta.$","['derivatives', 'real-analysis']"
2119476,Gambler's ruin and martingale,"I don't understand 2 steps of the solution to a gambler's ruin exercise. set-up for the gambler's ruin problem: $(X_n)_{n\geq 1}$ are i.i.d. rv with $P(X_1=1)=1-P(X_1=-1)=p$ and $p\in (0,1),\ p\neq 1/2$ . We have integers $0<a<b$ , a sequence $S_0:=a$ with $S_n:=S_{n-1}+X_n\quad n\geq 1$ and $\mathcal{F}_n=\sigma(X_1,\dots,X_n)$ and $T$ is the stopping time when either $S_n=0$ or $S_n=b$ . Exercises Deduce the value of $P(S_T=0)$ and $P(S_T=b)$ Compute $E(T)$ I had to show that the following two are martingales, so this is known: $$M_n:=\left(\frac{1-p}{p}\right)^{S_n}\qquad N_n:=S_n -n(2p-1)$$ The solutions says this: The stopped Martingales $M_T$ and $N_T$ are bounded, thus uniformely integrable with terminal value $M_T$ and $N_T$ . As a consequence: $$\left(\frac{1-p}{p}\right)^{a}=P(S_T=b)\left(\frac{1-p}{p}\right)^{b}+(1-P(S_T=b))\left(\frac{1-p}{p}\right)^{0}$$ I don't understand this equation. I understand that $E(M_T)=E(M_0)=\left(\frac{1-p}{p}\right)^{a}$ and it also makes sense that $S_T$ is either $b$ or $0$ . But I don't understand why this $M_T$ is Bernoulli distributed with these parameters. Can someone explain? $E(N_T)=a$ that is $E(S_T)-(2p-1)E(T)=a$ . We deduce: $$E(T)=\frac{\left(\frac{\left(\frac{1-p}{p}\right)^{a}-1}{\left(\frac{1-p}{p}\right)^{b}-1}\right)b-a}{(2p-1)}$$ I don't see why $$E(S_T)=\left(\frac{\left(\frac{1-p}{p}\right)^{a}-1}{\left(\frac{1-p}{p}\right)^{b}-1}\right)b$$","['stochastic-processes', 'probability-theory', 'conditional-expectation', 'martingales']"
2119486,Zeros of zeta function,"I am a beginner of analytic number theory. In studying about zero of zeta function, i faced a Question. Is there any zero $s=\sigma +t i$ of Riemann zeta function such that $\sigma> 1$ ??There is no answer, of course. I want to know its proof as simple as possible","['complex-analysis', 'analytic-number-theory', 'riemann-zeta']"
2119503,What is the second derivative of a B-spline?,"A B-spline of degree $j$ is defined at knots $\vec k$ by the Cox-de Boor recursion formula
\begin{align} 
    B_{i,1}(x) &= \left\{
        \begin{matrix} 
            1 & \mathrm{if} \quad k_i \leq x < k_{i+1} \\
            0 & \mathrm{otherwise} 
        \end{matrix}
    \right. \\
    B_{i,j}(x) &= \frac{x - k_i}{k_{i+j-1} - k_i} B_{i,j-1}(x) + \frac{k_{i+j} - x}{k_{i+j} - k_{i+1}} B_{i+1,j-1}(x)
\end{align} and has derivative
\begin{equation}
    \frac{\text{d}B_{i,j}(x)}{\text{d}x}
    =
    (j-1)
    \left(
        \frac{-B_{i+1,j-1}(x)}{k_{i+j}-k_{i+1}}
        +
        \frac{B_{i,j-1}(x)}{k_{i+j-1}-k_i}
    \right).
\end{equation} I am trying to implement the O'Sullivan penalty which requires second derivatives. What is the second derivative of a B-spline?","['derivatives', 'spline', 'polynomials', 'calculus']"
2119539,Proving that the Zariski topology in $\mathbb{A}^2$ is not the product topology of $\mathbb{A}^1\times \mathbb{A}^1$,"I am trying to prove this: The Zariski topology in $\mathbb{A}^2$ is not the product topology of $\mathbb{A}^1\times \mathbb{A}^1$ Here is the proof: We will work over a field $k$ which is algebraically closed. We will work with the set $S=V(x-y)$. This set is closed in $\mathbb{A}^2$. We will show that $\mathbb{A}^2-S$ is not open in $\mathbb{A}^1\times \mathbb{A}^1$ (which gives a contradiction). To show that $\mathbb{A}^2-S$ is not open, we will show that no basic set of $\mathbb{A}^1\times \mathbb{A}^1$ is contained inside $\mathbb{A}^2-S$. The basic sets of $\mathbb{A}^1\times \mathbb{A}^1$ are of the form $(\mathbb{A}^1-V(f))\times (\mathbb{A}^1-V(g))$ where $f,g\in k[x]$ ($k[x]$ is a PID as $k$ is a field). Let $V(f)=\{x_1, x_2,\dots, x_n\}$ and $V(g)=\{y_1, y_2,\dots, y_n\}$. We can find a $z\in k$ such that $f(z)\neq 0$ and $g(z)\neq 0$. Then the point $(z,z)\in \mathbb{A}^2$ has the property that $(z,z)\in (\mathbb{A}^1-V(f))\times (\mathbb{A}^1-V(g))$ but $(z,z)\notin \mathbb{A}^2-S$, which proves our claim. Is the proof fine ?","['zariski-topology', 'algebraic-geometry', 'proof-verification']"
2119545,Prove that a doubly stochastic matrix is a square matrix,"A matrix denoted by $(a_{ij})_{m \times n}$  is said to be doubly stochastic if: $$ \sum_{i}{a_{ij}} = \sum_{j}{a_{ij}} = 1 $$ I am trying to prove that such a matrix is a square matrix. I thought of multiplying or adding 2 of such matrices together but this leads to nowhere. I also wrote down down a generalised doubly stochastic matrix in this form: $$
\begin{bmatrix}a_{11} & a_{12} & \cdots & a_{1n}\\a_{21} & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \vdots & \vdots \\
a_{m1} & a_{m2} & \cdots & a_{mn}
\end{bmatrix}
$$ I can't see any relationship between the different rows and columns from this form. Could anyone please give me some hints?","['matrices', 'linear-algebra']"
2119600,Find the sum of the series $\frac{1}{1\cdot 2\cdot 3}+\frac{1}{4\cdot 5\cdot 6}+\frac{1}{7\cdot 8\cdot 9}+...=$ [duplicate],"This question already has answers here : How find this sum $\sum\limits_{n=0}^{\infty}\frac{1}{(3n+1)(3n+2)(3n+3)}$ (5 answers) Closed 7 years ago . Given : $$\frac{1}{1\cdot 2\cdot 3}+\frac{1}{4\cdot 5\cdot 6}+\frac{1}{7\cdot 8\cdot 9}+ ...$$ What is the sum of this series, how can one rewrite it to look simpler ? EDIT : Actually I found how to rewrite it : $$\sum _{n=1}^{\infty }\:\frac{1}{\left(3n-2\right)\left(3n-1\right)3n}$$","['real-analysis', 'summation', 'sequences-and-series']"
2119634,Hölder continuity definition through distributions.,"I am trying to prove that for a given Hölder parameter $\alpha \in (0, 1)$ and a distribution $f \in \mathcal{D}'(\mathbb{R}^d)$ the following are equivalent: $f \in C^{\alpha}$ For any $x$ there exists a polynomial $P_x$ such that $| \langle f - P_x, \phi_x^{\lambda} \rangle | \le C \lambda^{\alpha.}$ Where the latter estimate holds uniformly over all$x$ and $\phi \in \mathcal{D}$ with compact support in the unit ball, and: $$\phi_x^{\lambda}(\cdot) = \lambda^{-d} \phi\left( \frac{\cdot \ - \ x}{\lambda} \right)$$ Proving that the first implies the second is fairly easy. The other way around gives me some problems. The first step I took is to realize that we care only about the order zero term of $P_x,$ since all other terms vanish at a order higher than $\alpha.$
Here we assume that the polynomial is centered in $x.$ Then I would like to prove that $P_x(x) = g(x)$ defines a $\alpha$ - Hölder function. Thus we would get that $g \in \mathcal{D}'.$ Eventually I would like to prove that $g = f$ in $\mathcal{D}'.$ My problem is that I can't prove any implications between 2,3,4 nor any of 2,3,4 starting from 1. Any hints, help, suggestions?","['functional-analysis', 'distribution-theory', 'stochastic-pde', 'holder-spaces']"
2119636,"$f:\mathbb{R}\rightarrow \mathbb{R}$ differentiable, $f'(x)>f(x)$ for all $x$, and $f(0)=0$, then $f(x)>0$ for all $x>0$","Suppose $f:\mathbb{R}\rightarrow \mathbb{R}$ is differentiable everywhere, $f'(x)>f(x)$ for all $x\in \mathbb{R}$, and $f(0)=0$, then $f(x)>0$ for all $x>0$. I tried using the proof given in this post: Show that if $f( 0 ) = 0$ and $f'( x ) > f( x )$ for all $x \in \mathbb{ R }$ then $f( x ) > 0$ for all $x > 0$. but I realized that I am not given that $f'$ is continuous. I have been playing with the following: Since $f'(x)>f(x)$ for all $x$ then $f'(0)=\lim_{h\rightarrow 0} \frac{f(h)}{h}>f(0)=0$. I want to say that this means that $f$ must be positive over $N_{\epsilon}(0)$ for some $\epsilon>0$. Otherwise, this would somehow contradict that $f$ is differentiable. If I know that $f$ is positive over some epsilon neighborhood around zero, I know that the function has ""lift off"" after zero. From there I can argue that the function can't come back down to zero because it would contradict that $f'(x)>f(x)$. Can someone help me formalize this hand wavy argument? I would greatly appreciate it!","['derivatives', 'real-analysis', 'continuity']"
2119721,Simplify Inverse Trigonometric Expression,"The problem asks to simplify the expression $\arccos (\frac 3 5 \cos x + \frac 4 5 \sin x)$ where $x \in \; [\frac {-3\pi} 4 , \frac \pi 4]$. Here's my approach. Let $\frac 3 5 = r \cos y$ and $\frac 4 5 = r \sin y$. Therefore, $r^2 = 1 \implies r = \pm 1\\
y = \arctan \frac 4 3$ Replacing $\frac 3 5$ and $\frac 4 5$ with their supposed values in the given expression we get, $\arccos \; [r(\cos x \cos y + \sin x \sin y)]$ Now, 2 cases arise. Case-I $(r = 1)$ The given expression becomes, $\arccos \; [\cos(x - y)]\\
= x - y\\
= x - \arctan \frac 4 3$ Another equivalent answer is $\arctan \frac 4 3 - x$. This is the only answer according to my book. Case-II $(r = -1)$ The given expression becomes, $\arccos \; [-\cos(x - y)]\\
= \pi - (x - y)\\
= \pi - x + \arctan \frac 4 3$ Now this answer is what created the problem. My book doesn't give this answer. Is this answer wrong? Does it have to do something with the interval in which $x$ lies? Or is there something wrong with my approach. I mean if I suppose $\frac 3 5$ and $\frac 4 5$ as only $\cos y$ and $\sin y$ respectively, I wouldn't face this problem. Any help would be appreciated. Edit As I can suppose $\frac 3 5$ and $\frac 4 5$ to be $\cos y$ and $\sin y$ respectively, I believe there is nothing wrong is assuming them as $-\cos y$ and $-\sin y$ either. Or is there something wrong with this assumption? If there's nothing wrong with it then what about the answers we get with this assumption? Aren't they correct too? So shouldn't I suppose $\frac 3 5$ and $\frac 4 5$ as $\pm \cos y$ and $\pm \sin y$ respectively?",['trigonometry']
2119767,"$a_n := 1/\sqrt{n} $. Show that the sequence is bounded, monotone decreasing...","I'm given the following: $(a_n)_{n\in\mathbb{N}} $ is a real sequence defined as $a_n := 1/\sqrt{n} $ for $n \in \mathbb{N}$. i) Show that $(a_n)_{n\in\mathbb{N}} $ is bounded from above and below, and give the explicit boundaries. ii) Show that, $(a_n)_{n\in\mathbb{N}} $, is monotonely decreasing. iii) Give $\lim_{n\to\infty} a_n  $ Now I understand all of this, Im just not sure how to write a good mathematical proof for it. Basically my idea is like this... Since n can only be a positive integer, when n = 1, it will basically be  $1/\sqrt{1} = 1$. When n > 1, then the fraction will become smaller, and thats why the above boundary is 1. As n approaches inifinity, then the fraction $1/\sqrt{n}$ will approach 0. So the lower boundary is 0. The function is monotone decreasing since ($1/\sqrt{n}) \geq (1/\sqrt{n+1})$. And $\lim_{n\to\infty} a_n = 0 $ This is all clear to me, but I just feel like if I write it like this, it is not really a mathematical proof and I am not sure how I can formulate this as a proper valid proof.","['proof-writing', 'sequences-and-series', 'calculus', 'limits']"
2119784,Need help for proving: $f(f^{−1}(A)) ⊆ A$. [duplicate],"This question already has answers here : Need help for proving that: $f(f^{-1}(A)) ⊆ A$ (4 answers) Closed 7 years ago . Informations:
$f:X \longrightarrow X$ and $A \subseteq X$. How can i prove this statement:
$f(f^{-1}(A)) \subseteq A$ This is my thoughts until now: $f^1(A)=\{x\in X |f(x)\in A\} \subseteq X$. $f(A)=\{f(x)|x\in A\}$ $f(f^1(A))=\{y\in A:\exists \in f^1(A):y=f(x)\} \in A$",['elementary-set-theory']
2119799,"Show that if all convergent sub-sequences of a sequence ${s_n}$ converge to 0 and ${s_n}$ is bounded, then ${s_n}$ converges to $0$","Problem: Show that if all convergent sub-sequences of a sequence ${s_n}$ converge to $0$ and ${s_n}$ is bounded, then ${s_n}$ converges to $0$. Attempt: I am trying to solve this problem using the contra-positive. Here is my attempt so far. If $s_n$ diverges to positive or negative infinity, then ${s_n}$ is not bounded. If $s_n$ converges to a non-zero real number, then any sub-sequence of $s_n$ converges to the same value (which is not zero). Now where I am stuck is the case where $s_n$ diverges. Any hints much appreciated. Edit: This part of the question is important:  ""all convergent sub-sequences of a sequence ${s_n}$ converge to $0$ "", this does not assume that any sub-sequence is in fact convergent. Also I believe the contrapositive of this statement is that
$s_n$ does not converge to zero implies that there exists a sub-sequence of $s_n$ that does not converge to $0$ or that $s_n$ is un-bounded.","['real-analysis', 'sequences-and-series']"
2119853,Lebesgue measure and countable partition,"I would like to know how to solve this ""paradox"". First of all I define some functions and syntax: Let's define the Lebesgue Measure of the closed interval [x ; y] this way: LM([x;y]). So the Lebesgue Measure of the interval [0;1] is: LM([0;1])=1. From the definition of a measure function, let's define L(n) as the sum of the n parts (sub-intervals) of equal length of the interval [0;1]. We have L(n) = LM([0,1]) and for any n: $$
L(n) = \sum\limits_{i=1}^{n}LM([-1/n + \sum\limits_{j=1}^{i}1/n ; \sum\limits_{j=1}^{i}1/n]) 
$$ For example L(2) = LM([0;0.5])+LM([0.5;1])=LM([0;1]) Let's take the limit of L(n) when n goes to infinity with two different points of view (infinity in calculus and set theory): Calculus Since the limit of -1/n is zero, the first option is to consider the sub-interval a singleton [x;x]. The problem is that an infinite number of closed intervals of measure zero is zero and L(n)=0 != LM([0;1])=1; Set Theory The structure of the sub-intervals is [A,B], A and B being rationals. We cannot have a countable number of singleton sub-intervals like this: [A;A] because the set of reals between [0;1] is uncountable and the set of rationals is countable. From the definition of the function L(n) we are mapping an uncountable number of reals (interval [0;1]) in a countable number of parts (sub-intervals) so A must be different from B. 
In this case the sub-intervals are not zero in length since any real closed interval with A!=B has LM(A,B)=epsilon > 0. The problem is that an infinite number of closed interval of measure epsilon>0 is infinity and L(n)=infinity != LM([0;1])=1; Both options make me think about the Archimedean property of reals and the infinitesimals. Could someone please help me to understand what is wrong in both results? Thanks a lot for your comments.","['lebesgue-measure', 'infinity', 'elementary-set-theory']"
2119866,Need help for proving that: $f(f^{-1}(A)) ⊆ A$,"I realised I needed to show more information, which I now did: $$f: X \rightarrow X \,\,\,\rm{and}\,\,\,\, A \subseteq X$$ Proof that: $$f(f^{-1}(A)) \subseteq A$$ This is my proof: By defintion: $$f^{-1}(A)=\{x \in X\mid f(x) \in A\}$$ 
and $$f(A)=\{f(x) \mid x \in A\} = \{y \in X \mid \exists x \in A: y=f(x)\} \subseteq X$$ Therefore we can end the proof by a final definition:\
$$f(f^{-1}(A))=\{y \in A: \exists x \in f^{-1}(A):y=f(x)\} \subseteq A$$ Is this a legit ""proof""? And is it even a proof, when i only use definitions?",['elementary-set-theory']
2119880,Show that $F$ is smooth if and only if $f^{n}(0)=0$ for all $n \ne 3k$ [duplicate],"This question already has answers here : When is the Composite with Cube Root Smooth (3 answers) Closed 2 years ago . Let $f$ be a smooth function. Suppose that $F(x)=f(x^{\frac{1}{3}})$. Show that $F$ is smooth if and only if $f^{n}(0)=0$ for all $n \ne 3k$, where $n,k \in \mathbb{N}$. Solution: ($\implies$) Since $F$ is smooth, differentiating once gives $$F'(x)=f'(x^{\frac{1}{3}})\frac{1}{3}x^{-\frac{2}{3}}$$which is same as $$3x^{\frac{2}{3}}F'(x)=f'(x^{\frac{1}{3}})$$ Taking limit as $x \to 0$ on both sides we get $f'(0)=0$. Now differentiating the equation again and multiplying through out by $3x^{\frac{2}{3}}$ we get $$6x^{\frac{1}{3}}F'(x)+9x^{\frac{4}{3}}F''(x)=f''(x^{\frac{1}{3}})$$ Now taking the limit as $x \to 0$ on both sides we get $f''(0)=0$. Differentiating again we get $$ 54xF''(x)+27x^2F'''(x)+6F'(x)=f'''(x^{\frac{1}{3}})$$
Taking limit as $x \to 0$ on both sides we get $F'(0)=\frac{f'''(0)}{6}$, which is as expected. Now the question is How do I get from here?? I can always differentiate and go further but for how many times?? The usual method in this cases is to use induction and conclude. Now I am unable to find any particular relation which can be exploited in the induction hypothesis. $(\impliedby)$ Now suppose that $f^{n}(0)=0$ for all $n \ne 3k$. The first thing that comes to my mind is L'Hospital's rule. So I start with it. The only point which needs to be checked at is $0$. Then for $x \ne 0$, we have $$F'(x)=f'(x^{\frac{1}{3}})\frac{1}{3}x^{-\frac{2}{3}}=\frac{1}{3}\frac{f'(x^{\frac{1}{3}})}{x^{\frac{2}{3}}}$$Thus, $$\lim_{x \to 0}F'(x)=\lim_{x \to 0}\frac{f''(x^{\frac{1}{3}})x^{-\frac{2}{3}}}{6x^{-\frac{1}{3}}}=\lim_{x \to 0}\frac{f''(x^{\frac{1}{3}})}{6x^{\frac{1}{3}}}=\frac{f'''(0)}{6}$$ Hence $F'(x)$ is continuous at $x=0$. I can always apply L'Hospital rule again to establish the continuity of $F''(x)$ and so on. I don't see an obvious way to extend or generalize this thing to higher order derivatives. The other thing that comes to my mind is the Taylor's series expansion which works very well for $F'(x)$ but no further. How do I do that?? The other thing I can do is look at the Taylor Series Expansion of $f$ near $0$. Then $$f(x)=\sum_{k=0}^n\frac{x^{3k}}{(3k)!}f^{3k}(0)+R_{n+1}(x)$$
So $$F(x)=\sum_{k=0}^n\frac{x^{k}}{(3k)!}f^{3k}(0)+R_{n+1}(x)$$ Can I do term by term differentiation to conclude??
Thanks for the help!!","['derivatives', 'taylor-expansion', 'smooth-manifolds', 'functions', 'continuity']"
2119896,Can every closed subspace be realized as kernel of a bounded linear operator from a Banach space to itself?,Let $X$ be a Banach space and $Y$ a closed subspace of $X$. Does there exist a bounded linear operator $T \colon X \to X$ such that $\ker T=Y$ ?,"['functional-analysis', 'banach-spaces', 'operator-theory']"
2119898,Solution for $\int \frac{1}{1-we^w}dw$,"I am looking for a solution or a method of approximation for :
 $$\int \frac{1}{1-we^w}dw$$ 
that came up while working on an ODE problem. Got any suggestions? Note: $w$ is also a one variable function Thanks to anyone who can lend a hand Update : The original ODE is: $$xdw=(e^{-w}-w)dx$$","['exponential-function', 'calculus', 'integration', 'ordinary-differential-equations', 'approximation']"
2119902,$\cos(x-90)$ and $\cos(-(x-90))$ how can they be the same?,"I plotted two lines in Desmos Calculator. $\cos(x-90)$ which looks exactly like a $\sin x$ graph. $\cos (-(x-90))$ which looks exactly the same. However, I thought that $f(-x)$ reflects the entire line in the $y$-axis. So why do the two lines above look the same, based on graph transformations? I might be stupid, but just a question.",['trigonometry']
2119925,Is $\cos(4x)+\sin(2x)$ periodic and how do I calculate the primitive period?,"My first attempt is under this, i can work out the primitive period of both of the $\cos(4x)$ and $\sin(2x)$ but how do I calculate the primitive period of $\cos(4x)+\sin(2x)$? My attempt: Let $u=4x$ then $x=\frac{u}{4}$ and $\cos(u)$ is $2\pi$ periodic thus $T=\frac{2\pi}{4}$ hence $\cos(4x)$ is periodic with primitive period $T=\frac{\pi}{4}$. Now Let $H=2x$ and thus $x=\frac{H}{2}$ and $\sin(H)$ is also $2\pi$ periodic Thus $\sin(2x)$ is periodic with primitive period $T=\frac{2\pi}{2}=\pi$ but i dont know how to combine these results to calculate the primitive period of the sum of both $\cos(4x)$ and $\sin(2x)$","['periodic-functions', 'trigonometry']"
2119934,Trapezoids - Which definition has a stronger case?,"Today my daughter Ella asked me ""Is a trapezoid an irregular polygon?"" and I realized I cannot give her a definitive answer. According to the Internet, trapezoids are alternately defined as having only one pair of parallel lines, and also at least one pair of parallel lines.  My understanding is that this is simply an unresolved ambiguity in mathematics. My question is, which definition has the stronger case? So far I have this: The case for ""only one"": Many people seem to think this is more intuitive and/or traditional The case for ""at least one"": Inclusive definitions are generally more useful (if this true I'd like to learn why) It's the only definition that fits with the concept of trapezoidal sums in calculus What am I missing?","['calculus', 'geometry']"
2119937,Limit of ratio ${f(x)\over x}$ equal to limit of difference $f(x+1)-f(x)$.,"Using my right to ask for help once again. I can't solve the following problem for quite a long time. Just have no idea how to do that. Here it is.
Let $f(x)$ be bounded on any interval $(1,b), b>1$. Then $\lim_{x\to+\infty}{f(x) \over x}=\lim_{x\to+\infty}(f(x+1)-f(x))$.
It is from the Russian book ""Lekcii po matematicheskomu analizu"" by G.I.Arkhipov, V.A.Sadovnichy and V.N.Chubarikov, 2nd ed., Moscow, 2000, page 676. Please, keep in mind, that times, when I did homework had passed long time ago. Now I'm solving problems for pleasure.",['limits']
2119956,What is the meaning of the inner product of a vector and a gradient?,"Recently I came across the following expression: $$ \langle \nabla f(x_1),x_2 \rangle$$ I do understand how to calculate the value of the expression. You take the derivatives of each of the entry in the function and then substitute $x_1$ in it and then take the dot product between the resulting value and $x_2$. But is there any meaning for this expression? What does this expression represent? Please help.","['multivariable-calculus', 'scalar-fields', 'vectors', 'derivatives']"
2119963,Polar coordinates; Jacobian and order of the variables,"I'm trying to understand the Jacobian a bit. I know the general form of the transformation with two variables: $$\int\int_Ag(x,y)\,\mathrm dx\,\mathrm dy=\int\int_{T(A)}g\big(x(u,v),y(u,v)\big)\lvert J(u,n)\rvert \,\mathrm du\,\mathrm dv.$$ Say we'd like to change to polar coordinates; $$\int\int_Ag(x,y)\,\mathrm dx\,\mathrm dy=\int\int_{T(A)}g\big(x(r,\theta),y(r,\theta)\big)\lvert J(r,\theta)\rvert \,\mathrm dr\,\mathrm d\theta.$$ How do we know the order of $(r,\theta)$? Could it also have been $(\theta,r)$? This would yield to the same Jacobian determinant but with the opposite sign.","['multivariable-calculus', 'polar-coordinates', 'jacobian']"
2119983,"Understanding how to properly determine if reflexive, symmetric, and transitive.","Determine which of the reflexive, symmetric, and transitive properties are satisfied by the given relation R defined on set S... S= {1,2,3} R= {(1,1), (1,3), (2,2), (2,3), (3,1), (3,2), (3,3)} I've concluded that it is not reflexive due to that there is no (1,2) or (2,1) in R. I'm not too confident to say its not symmetric... Basically would anyone be able to properly simplify an explanation on how to find whether its reflexive, transitive, and/ or symmetric?","['equivalence-relations', 'relations', 'discrete-mathematics']"
2119999,Definition of intensity of a counting process,"Fix a filtered probability space $(\Omega,\mathcal{F},P,(\mathcal{F}_t)_{t\geq 0})$. Let $N=(N_t)_{t\geq 0}$ be a counting process. Then we have the following definitions for the intensity of a counting process:
Brémaud gives the following definition in his book ""Point processes and queues"". Definition 1: A progressive process $\lambda=(\lambda_t)_{t\geq 0}$ is called the intensity of a counting process if
  $$\int_0^t\lambda_s ds<\infty$$
  for all $t\geq 0$ and
  $$E\left[\int_0^\infty C_sdN_s\right]=E\left[\int_0^\infty C_s \lambda_s ds\right]$$ for all non-negative $(\mathcal{F}_t)_{t\geq 0}$ predictable processes $C=(C_t)_{t\geq 0}$. Then on wikipedia, we have the following definition: Definition 2: Let $N=(N_t)_{t\geq 0}$ be a counting process. Then $N$ is a submartingale and $$M=N-A$$
  is a martingale where $A$ is a predictable increasing process. A is called the cummulative intensity of $N$ and if it is of the form $$A_t=\int_0^t\lambda_s ds$$, then $\lambda=(\lambda_t)_{t\geq 0}$ is the intensity of $N$. On wikipedia, we have also another definition: Definition 3: The intensity process $\lambda=(\lambda_t)_{t\geq 0}$ is defined by $$\lambda_t=\lim_{h\downarrow 0}\frac{1}{h}E[N_{t+h}-N_t\mid \mathcal{F}_t]$$ Now my question is if these definitions are all equivalent. For the last definition, we have $$\frac{1}{h}E[N_{t+h}-N_t\mid \mathcal{F}_t]=\frac{1}{h}E[M_{t+h}+A_{t+h}-M_t-A_t\mid \mathcal{F}_t]=\frac{1}{h}E[A_{t+h}-A_t\mid\mathcal{F}_t].$$ 
Is it true to say that $$\lim_{h\downarrow 0}\frac{1}{h}E[A_{t+h}-A_t\mid\mathcal{F}_t]=E[\lim_{h\downarrow 0}\frac{1}{h}(A_{t+h}-A_t)\mid\mathcal{F}_t].$$ When we have $A_t=\int_0^t\lambda_r ds$, then $$E[\lim_{h\downarrow 0}\frac{1}{h}(A_{t+h}-A_t)\mid\mathcal{F}_t]=E[\lambda_t\mid \mathcal{F}_t]=\lambda_t,$$ which would yield $(2)\implies (3)$. $(3)\implies(1)$ follows probably by 
$$E[\int_0^\infty\lambda_sC_s ds]=E[\int_0^\infty\lim_{h\downarrow 0}E[N_{s+h}-N_s\mid\mathcal{F}_s]C_s ds]=E[\int_0^\infty\lim_{h\downarrow 0}(N_{s+h}-N_s) C_sds]=E[\int_0^\infty N_s'C_sds]=E[\int_0^\infty C_s dN_s]$$","['stochastic-processes', 'statistics', 'stochastic-calculus']"
2120048,Derivative and limit of $\sqrt[3]{x-\sin x}$,"Given $f:R\rightarrow R, f(x) = \sqrt[3]{x-\sin x}$, compute $f'(0)$.Now, this can be done by using the definition of the derivative : $$f'(x_0) = \lim_{x\to{x_0}} \frac{f(x)-f(x_0)}{x-x_0}$$This yields the right answer.However, why can't we derive the function and then plug in 0? I mean: $$f'(x) = \frac{1-\cos x}{3\sqrt[3]{(x-\sin x)^2}}$$ And this is undefined for $x = 0$. Why does this happen?",['derivatives']
2120049,Orientable manifold using definition.,"I'm reading the Do Carmo book in the section of the orientable surfaces, but I still don't understand the idea of orientability , because the examples he uses to clarify the concept doesn't use explicitely the definition he gives, so I want to ask you if anyone could explain me with an example using the definition he uses for orientability The definition he uses is: A regular surface $S$ is called orientable if it is possible to cover it with a family of coordinate neighborhoods in such way that if point $p\in S$ belongs to two neighborhoods of this family, then the change of coordinates has positive Jacobian at $p$. The choice of such family is called an orientation of $S$ and $S$, in this case, is called oriented . EDIT: The examples Do Carmo gives are these ones: A surface which is the graph of a differentiable function
(cf. Sec. 2-2, Prop. I) is an orientable surface. In fact, all surfaces which can
be covered by one coordinate neighborhood are trivially orientable. The sphere is an orientable surface. Instead of proceeding to
a direct calculation, let us resort to a general argument. The sphere can be
covered by two coordinate neighborhoods, with parameters $(u, v)$ (using stereographic projection) and $(\overline{u}, \overline{v})$, in such a way that the intersection W of these neighborhoods (the sphere minus two points)
is a connected set. Fix a point $p$ in $W$. If the Jacobian of the coordinate change at $p$ is negative, we interchange $u$  and $v$ in the first system, and the Jacobian becomes positive. Since the Jacobian is different from zero in $W$ and positive at $p\in W$, it follows from the connectedness of $W$ that the Jacobian is everywhere positive. There exists, therefore, a family of coordinate neighborhoods satisfying Def. I, and so the sphere is orientable.","['intuition', 'orientation', 'differential-geometry']"
2120056,How to find $\tan(-\frac{5\pi}{16})$ with half-angle formulas?,How to find $\tan(-\frac{5\pi}{16})$ with half-angle formulas? I tried the $\pm \sqrt{\frac{1-\cos{A}}{1+\cos{A}}}$ and $\frac{\sin{A}}{1+\cos{A}}$ but got stuck once there were square roots on top and bottom like $\frac{\sqrt{...}}{1-\sqrt{...}}.$ Using the cosine over cosine in square root I got up to $$=-\sqrt{ \frac{ 1+\sqrt{\frac{1+\cos(5\pi/3)}{2}}}{1-\sqrt{\frac{1+\cos(5\pi/3)}{2}}} }$$,['trigonometry']
2120069,Separable but not exact equation,"In class, my professor stated that all separable equations are exact, and we even proved it for homework, but I think I found an equation that is separable but not exact: $$(x\ln y+xy)+(y\ln x+xy)y′ =0$$ My Work: \begin{align*}
  M &= x\ln y + xy \\
  M_y &= \frac{x}{y} +x \\
  N &= y\ln x + xy \\
  N_x &= \frac{y}{x} +y \\
  M_y &\neq N_x
\end{align*} But
\begin{align*}
  x(\ln y + y) + y \times y'\times (\ln x +x) &= 0 \\
  x(\ln y + y) &= - y \times y'\times (\ln x +x) \\
  \frac{x}{\ln x +x} &= \frac{- y \times y'}{\ln y + y}
\end{align*} Separated So whats up? Am I doing something wrong?",['ordinary-differential-equations']
2120085,"Prob. 11, Chap. 4 in Baby Rudin: uniformly continuous extension from a dense subset to the entire space","Here is Prob. 11, Chap. 4 in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: Suppose $f$ is a uniformly continuous mapping of a metric space $X$ into a 
  metric space $Y$ and prove that $\left\{ f\left( x_n \right) \right\}$ is a Cauchy sequence in $Y$ for every Cauchy sequence 
  $\left\{ x_n \right\}$ in $X$. Use this result to give an alternative proof of the theorem stated in Exercise 13. Now here is Prob. 13, Chap. 4 in Baby Rudin, 3rd edition: Let $E$ be a dense subset of a metric space $X$, and let $f$ be a unifromly continuous real function defined on $E$. Prove that $f$ has a continuous extension from $E$ to $X$. ... (Uniqueness follows from Exercise 4.) ... And, here is Prob. 4, Chap. 4: Let $f$ and $g$ be continuous mappings of a metric space $X$ into a metric space $Y$, and let $E$ be a dense subset of $X$. Prove that $f(E)$ is dense in $f(X)$. If $g(p) = f(p)$ for all $p \in E$, prove that $g(p) = f(p)$ for all $p \in X$. (In other words, a continuous mapping is determined by its values on a dense subset of its domain.) My effort: Since $f$ is uniformly continuous on $X$, corresponding to every real number $\varepsilon > 0$, we can find a real number $\delta > 0$ such that $$d_Y\left(f(x), f(y)\right) < \varepsilon$$ for all points $x, y \in X$ which satisfy $$d_X(x,y)<\delta.$$ Now since $\left\{ x_n \right\}$ is a Cauchy sequence in $\left( X, d_X \right)$, therefore corresponding to the real number $\delta$ in the preceding paragraph we can find a natural number $N$ such that $$d_X\left(x_m, x_n \right)< \delta \ \mbox{ for any natural numbers } m \mbox{ and } n \mbox{ such that } m > N \mbox{ and } n > N.$$ So from the preceding two paragraphs we can conclude that $$d_Y\left( f\left(x_m\right), f\left(x_n\right) \right) < \varepsilon \ \mbox{ for any natural numbers } m \mbox{ and } n \mbox{ such that } m > N \mbox{ and } n > N,$$ 
  from which it follows that $\left\{ f\left(x_n\right) \right\}$ is a Cauchy sequence in $\left( Y, d_Y \right)$. Now let $E$ be a dense set in $\left(X, d_X \right)$, $\left( Y, d_Y \right)$ be a complete metric space, and $f$ be a uniformly continuous mapping of $E$ into $Y$. We now show that there exists a unique uniformly continuous mapping $g$ of $X$ into $Y$ such that $g(p) = f(p)$ for all $p \in E$. Let $p \in X$. Since $E$ is dense in $X$, we can find a sequence $\left\{p_n\right\}$ in $E$ converging to the point $p$ in $\left( X, d_X \right)$. Now as the sequence $\left\{ p_n \right\}$ is a Cauchy sequence in $E$ and as $f$ is uniformly continuous, so the image sequence $\left\{ f\left(p_n \right)\right\}$ is a Cauchy sequence in the complete metric space $Y$, and so this sequence converges to some point $q$ in $Y$. We now show that this point $q$ is independent of the particular sequence $\left\{ p_n \right\}$ in $E$ which converges to $p$. For this, let $\left\{ p^\prime_n \right\}$ be another sequence in $E$ converging in $X$ to the point $p$. Then as before the image sequence $\left\{ f\left(p^\prime_n\right)\right\}$ converges in $Y$ to some point $q^\prime$. Now consider the sequence $\left\{ x_n \right\}$ in $E$ defined as follows: Let $$x_n = \begin{cases} p_{\frac{n}{2}} \ \mbox{ if $n$ is even}; \\ p^\prime_{\frac{n+1}{2}} \ \mbox{ if $n$ is odd}. \end{cases}$$ This sequence too converges to point $p$ in $X$ and is therefore Cauchy and so its image sequence $\left\{ f\left( x_n \right) \right\}$ is also a Cauchy sequence in $Y$, which is a complete metric space; so the sequence $\left\{ f\left( x_n \right) \right\}$ converges in $Y$ to some point $y$. Therefore every subsequence of $\left\{ f\left( x_n \right) \right\}$ also converges to $y$. But we note that, 
  $$p_n = x_{2n} \ \mbox{ and } p^\prime_n = x_{2n-1} \ \mbox{ for all } n \in \mathbb{N}.$$ So 
  $$q = \lim_{n \to \infty} f\left(p_n \right) = \lim_{n \to \infty} f\left( x_{2n}\right) = y,$$
  where the limit is in $Y$, and similarly $$q^\prime = \lim_{n\to\infty} f\left(p_{2n-1}\right) = y.$$ Thus $q^\prime = q$. Now let's define the mapping $g$ of $X$ into $Y$ as follows: For any point $p \in X$, let  $$\tag{1} g(p) = \lim_{n \to \infty} f \left(p_n \right),$$ the limit being in the metric space $\left(Y, d_Y \right)$, where $\left\{ p_n \right\}$ is any sequence in $E$ such that $$\tag{2} \lim_{n \to \infty} p_n = p$$ in $\left( X, d_X \right)$. If $p \in E$, then we can take $p_n = p$ for all $n$ so that $$g(p) = \lim_{n \to \infty} f\left(p_n\right) = f(p).$$ 
  Thus $g$ is an extension of $f$ from $E$ to $X$. Let $\varepsilon > 0$ be a given real number. Since $f$ is uniformly continuous on $E$, we can find a real number $\delta > 0$ such that $$d_Y\left( f(p), f(q) \right) < \frac{\varepsilon}{3}$$ for all points $p$ and $q$ in $E$ for which $$d_X\left(p, q\right) < \delta. $$ Now let $u$ and $v$ be any two points of $X$ which satisfy $$d_X\left(u, v\right) < \frac{\delta}{3}.$$ 
  Then since $E$ is dense in $X$, we can find points $u^\prime$ and $v^\prime$ in $E$ such that 
  $$\tag{3} d_X \left( u, u^\prime \right) < \frac{\delta}{3} \mbox{ and } d_Y\left(g(u), f(u^\prime) \right) < \frac{\varepsilon}{3},$$
  and also 
  $$\tag{4} d_X \left( v, v^\prime \right) < \frac{\delta}{3} \mbox{ and } d_Y\left( g(v), f(v^\prime) \right) < \frac{\varepsilon}{3}.$$
  This is possible in view of (1) and (2) above. Then we note that 
  $$d_X \left( u^\prime, v^\prime \right) \leq d_X\left(u^\prime, u \right) + d_X\left(u, v\right) + d_X\left(v, v^\prime\right) < \frac{\delta}{3} + \frac{\delta}{3} + \frac{\delta}{3} = \delta,$$
  which implies that 
  $$ \tag{5} d_Y\left( f\left(u^\prime \right), f\left(v^\prime\right) \right) < \frac{\varepsilon}{3},$$
  and therefore from (3), (4), and (5) we can conclude that 
  $$
\begin{align} 
d_Y\left( g\left(u\right), g\left(v\right) \right) &\leq d_Y\left( g\left(u \right), f\left(u^\prime \right) \right) + d_Y\left( f\left(u^\prime\right), f\left(v^\prime\right) \right) + d_Y\left( f\left(v^\prime\right), g\left(v\right) \right) \\
&< \frac{\varepsilon}{3} + \frac{\varepsilon}{3} + \frac{\varepsilon}{3} \\
&= \varepsilon.
\end{align} 
$$ Let us take a real number $\eta$ such that $$0 < \eta < \frac{\delta}{3}.$$ Thus, corresponding to every real number $\varepsilon > 0$, we can find a positive real number $\eta$ such that $$d_Y \left( g(u), g(v) \right) < \varepsilon$$
  for all points $u$ and $v$ in $X$ for which $$ d_X \left(u, v \right) < \eta.$$ Hence $g$ is uniformly continuous on $X$. Let $g^\prime$ be (also)  a (uniformly) continuous extension of $f$ from $E$ to $X$. Since $g^\prime(p) = f(p) = g(p)$ for all $p \in E$ and since $E$ is dense in $X$, therefore by virtue of the conclusion in Prob. 4 we can conclude that $g^\prime(p) = g(p)$ for all $p \in X$. Now I know that the first part of the above solution, where we are required to show that $\left\{ f\left(x_n\right) \right\}$ is a Cauchy sequence in $Y$ for every Cauchy sequence $\left\{ x_n \right\}$ in $E$, is correct, isn't it? What about the second part? Is the result I've stated correct? If so, then is my proof correct also?","['real-analysis', 'cauchy-sequences', 'uniform-continuity', 'metric-spaces', 'analysis']"
2120091,Divisor effective on compact Riemann surface,"I have the following problem: $\texttt
{(1)Show that every divisor of degree ≥ p on a compact Riemann surface}$
$\texttt {of genus p is linearly equivalent to an effective divisor.}$ My initial action is to prove that: (2) $D$ be a divisor on compact Riemann surface is linearly equivalent to an effective divisor $\Leftrightarrow h^{0}(D)\ge 1$. So if I prove (2), I prove (1). I wonder if you're reasonable. And some idea to prove (2)? Thank you!","['riemann-surfaces', 'algebraic-geometry']"
2120102,How is this manifold non-Hausdorff?,"Let $\Phi$ be the diffeomorphism $\mathbb{R}^2/\{0\}\to \mathbb{R}^2/\{0\}$, given by $$\Phi(x,y)=(2x,\frac{1}{2}y).$$ Let $\text{~}$ be equivalence relation generated by $p \text{~} \Phi(p)$. Let $M$ be the quotient space, with quotient map $\pi:\mathbb{R}^2/\{0\}\to M$. Every open subset $V\subseteq \mathbb{R}^2/\{0\}\to $ for which the restriction $\pi|_V: V\to M$ is injective defines a chart $(U,\phi)$, where 
$$
U=\pi(V), \phi\circ \pi|_V=id_V.
$$ I am wondering if we can use counterexamples such as $p_1=\pi((1,1)),p_2=\pi(1,0)$. Such that every chart containing $p_2$ would also contain $p_1$, thus this is non-Hausdorff. However, I became kind of skeptical that whether these points are nonseparable, since it seems that we can always take nbhd infinitesimally small such that it can actually separates the two points. Can anyone help me with this?","['differential-geometry', 'geometry']"
2120108,Example of affine scheme $X=\operatorname{Spec} R$ and irreducible $U\subset X$ such that $\mathcal{O}(U)$ is not a localisation of $R$,"The definition of the structure sheaf of an affine scheme $\operatorname{Spec}  R$ is often done by extending a sheaf defined on the standard opens $D(f)$, $f\in R$. From this definition it is not quite clear what the rings $\mathcal{O}(U)$ look like for general $U\subset \operatorname{Spec}  R$. As Ravi Vakil notes in the lecture notes, one might hope that 
$$\mathcal{O}(U)\cong R_S$$
where 
$$S=\{r\in R\mid \forall \mathfrak{p}\in U: r\not\in \mathfrak{p}\}$$
He also notes that this is not true, and gives an example of two planes intersecting at a point, and then removing the point. More precisely
$$X=\operatorname{Spec}  \mathbb{C}[w,x,y,z]/(wy,wz,xy,xz), U=X\setminus\{(w,x,y,z)\}$$
But $U$ is clearly the union of two open subsets: $U_1$ the $xw$-plane with the origin removed and $U_2$ the $yz$-plane with the origin removed. So then one can construct sections on $U_1$ and $_2$ separately and glue them to a section on $U$. This makes it clear the $\mathcal{O}(U)$ is not a localisation of $\mathbb{C}[w,x,y,z]/(wy,wz,xy,xz)$. However, this example is in some sense trivial in that it relies upon the fact that if $U$ is a disjoint union of $U_1$ and $U_2$ then
$$\mathcal{O}(U)=\mathcal{O}(U_1)\times \mathcal{O}(U_2)$$
So I wonder if there are examples that do not rely on this fact. So if there is an affine scheme $\operatorname{Spec} R$ with an irreducible open subset $U$ such that $\mathcal{O}(U)$ is not a localisation of $R$. Edit: another way of looking at the same question is by taking Hartshornes perspective. Sections over $U$ are maps to the stalks that can locally be realised by fractions. So is there an example of an irreducible $U$ and a section $s:U\to \bigcup_{\mathfrak{p}\in U}R_\mathfrak{p}$ so that locally $s=\frac{g}{h}$, but it is not possible to write $s$ like this on all of $U$?","['schemes', 'examples-counterexamples', 'algebraic-geometry']"
2120124,All subsets of $\mathbb{R}$ which are countable or the complement of a countable set,"Let C be the class of all subsets of $\mathbb{R}$ which are either countable or are the complement of a countable set. Show that C is a $\sigma$ field. This is what I have right now: (i) $\varnothing$ $\in$ $C$ since $\emptyset$ is countable . (ii) A $\in$ C since A is countable since given C is countable. (iii) $\bigcup^{\infty}_{i=1}A_i$ $\in$ C, is true since $A_1,A_2$, are countable then so is $\cup^{}_{n}A_n$ since a countable union of countable sets is countable. I need help understanding (ii) and (iii).","['probability-theory', 'measure-theory']"
2120129,Proving convergent sequences are Cauchy sequences,"Prove that if $x_n \rightarrow a, n \rightarrow \infty$ then $\{x_n\}$ is a Cauchy sequence. I believe I have found the proof as follows, wondering if there are any simpler methods or added intuition. For me, it makes sense that if a sequence has a limit, then distances between elements in the sequence must be getting smaller, in order for it to converge. Given $\epsilon > 0, \exists N_1 \ s.t. \ \forall n \geq N_1:$ $|x_n - a| < \frac{\epsilon}{2} < \epsilon$ and for $m > n \geq N_1$ we also have: $|x_m -a| < \frac{\epsilon}{2} < \epsilon$ Let $N \geq N_1$, then $\forall n,m \geq N$ we have: $|x_n-x_m| = |x_n - a -x_m+a| < |x_n - a| + |-(x_m -a)| < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon$ Therefore $\{x_n\}$ is a Cauchy sequence. Also, if a sequence is Cauchy does it always converge ? In other words, is it sufficient to check if a sequence is Cauchy to check for convergence.","['real-analysis', 'cauchy-sequences', 'proof-verification', 'limits']"
2120233,$X$ is a basis for free abelian group $A_{n}$ if and only if $\det (M) = \pm 1$,"This question is related to another problem I asked a question about here . In fact, it is part (b) of a problem whose part (a) was Let $X = \{ x_{1}, x_{2}, \dots, x_{n}\}$ be a set of elements of the free abelian group $A_{n}$.  Let $M$ be the $n\times n$ matrix of coordinates of elements $x_{i}$ in terms of the basis $B=\{b_{1},b_{2},\dots, b_{n}\}$ (where $x_{i}=r_{i1}b_{1}+r_{i2}b_{2}+\cdots + r_{in}b_{n}$, and the coordinates $r_{ij}$ define the matrix $M=(r_{ij})$). Assume $M^{\prime}$ is a matrix obtained from $M$ by a sequence of elementary transformations. Prove that $M^{\prime}=ZMY$, where $Z$, $Y$ are some matrices in $GL(n, \mathbb{Z})$. For the part of the problem I'm asking about now, I need to show that $X$ is a basis for $A_{n}$ if and only if $\det (M) = \pm 1$. For the direction $(\Longleftarrow)$, I was given the hint: ""How is $\det(M)$ changed under transformations of $M$?"" Using this hint, I was able to get to the following point: Suppose $\det M = \pm 1$. By Part (a), if $M^{\prime}$ is a matrix
  obtained by a sequence of elementary transformations on $M$, then
  $M^{\prime}=ZMY$, where $Z$, $Y$ $\in GL(n,\mathbb{Z})$. Since $Z, Y
 \in GL(n, \mathbb{Z})$, $\det(Z) = \pm 1$ and $\det(Y) = \pm 1$. From
  linear algebra, we know that the determinant of a product of matrices
  is equal to the product of the determinants, so $\det(Z) \cdot \det
 (M) \cdot \det(Y) = (\pm 1) (\pm 1) (\pm 1) = \pm 1 =
\det(M^{\prime})$. This was as far as I was able to get though, because I am having trouble understanding how to reconcile this with $X$ being a basis for $A_{n}$. For the $(\Longrightarrow)$ direction, I was able to get even less, primarily because of the fact that I don't understand how $X$ being a basis for $A_{n}$ has anything to do with  what the determinant of $M$ is. I started by saying that if $X$ is a basis for $A_{n}$, then $\forall
a_{i} \in A_{n}$, $\exists c_{i1}, c_{i2}, \cdots , c_{in} \in
 \mathbb{Z}$ such that $a_{i}=c_{i1}x_{1} + c_{i2}x_{2}+\cdots +
 c_{in}x_{n}$, where the $c_{ij}$ are the entries in the matrix $M$.
  And wasn't sure where to go from there. Could someone please tell me where to go from where I've stopped (in both directions)? I'm very much stuck and this point. (And be prepared to be patient and answer lots of follow-up questions!) Thank you! :)","['matrices', 'abstract-algebra', 'free-abelian-group', 'abelian-groups', 'group-theory']"
2120251,Show that $\hat{β}_1 = \dfrac{\sum_{i=1}^nx_iy_i}{\sum_{i=1}^nx_i^2}$ under the least squares optimality criterion.,"I need to prove that $\hat{β}_1 = \dfrac{\sum_{i=1}^nx_iy_i}{\sum_{i=1}^nx_i^2}$. I have not seen this as a definition for $\hat{β}_1$ before and am having trouble even starting this proof, but it must have something to do with the least-squares normal equations and the least-squares estimators. Any thoughts?","['statistics', 'proof-writing', 'regression-analysis', 'least-squares']"
2120257,Real methods for evaluating $\int_{0}^{\infty}\frac{\log x \sin x}{e^x}\mathrm{d}x$,"Recently I came across the following integral - 
$$\int_{0}^{\infty}\frac{\log x \sin x}{e^x}\mathrm{d}x$$ One way to do it is to rewrite $\sin$ in terms of exponent, and then to relate to derivative of Gamma function. However this invokes complex analysis. Are there other ways using only real analysis techniques for solving this integral. In the standard approach we try to manipulate $\int_{0}^{\infty}x^ae^{-x} \sin x\mathrm{d}x$ to arrive at the Gamma function, but I do not have any idea, how to do it without rewriting $\sin x$. And if it is only rewriting it, and using some trivial arithmetic with complex numbers as if they were reals, it is OK, but I do not see how to do it. Maybe we should work with the original integral. However I think that we should at some point come up with the Gamma, as the answer contains Euler-Macheroni constant, which is related to derivatives of Gamma, and I do not see how otherwise we could reach this particular constant.","['real-analysis', 'integration', 'gamma-function']"
2120262,Is this an action?,"Suppose that you have some group $G$ acting on a set $S$ under the action $\cdot: G \curvearrowright S$, and then you have a set of all functions $T = \{ f: S \to \mathbb{C} \}$. I want to define an action $*: G \curvearrowright T$. Let $\omega_g: s \in S \mapsto g \cdot s$, then I want to define $g * f(x) = f(g \cdot x)$. This seems to be associative: $a * ( b * f(x)) = a *(f(b \cdot x)) = f(a\cdot (b \cdot x)) = f((ab) \cdot x) = ab * f(x)$ However, when I try to write this action out in terms of $\omega_g$ it gets problematic (I'll denote the action here by $\times$ for clarity) $a \times ( b \times f(x)) = a \times ( f \circ \omega_b) = (f \circ \omega_b) \circ \omega_a = f \circ \omega_{ba} = ba \times f(x)$ These two actions are obviously not the same, but I can't seem to write my first action in the $\omega_g$ notation. I am wondering whether the first action is really an action, or whether the notation is hiding something which makes it not an action. Moreover, how can it be written in the $\omega_g$ notation? I can fix the omega notation by mapping to $\omega_{g^{-1}}$, but paradoxically it doesn't seem to be associative if I use my first notation.","['finite-groups', 'group-actions', 'group-theory']"
2120263,Smooth function between compact manifold and connected manifold,"I have this problem and I don't know how to proceed with it: Let $M$ be a compact manifold $N$ a connected manifold and $f\colon M \longrightarrow N$ a smooth function. If $f$ doesn't have critical points, then prove that $f$ is surjective. What I know is that since $f$ doesn't have critical points, all the points in $N$ are regular. Since $M$ is compact, then $f(M)$ is compact too. Now, if $n\in N$ is a point such that $n\notin f(M)$ , then I can define the function $g\colon M \longrightarrow \mathbb{R}$ where $g$ defines the shortest length from $x\in M$ to $n$ , I know that this function must have a maximum and a minimum, but from this the only thing I can infer is that there is an open neighborhood for $n$ in $N$ . What can I do to finish the problem? EDIT: $M$ and $N$ are of the same dimension.","['compact-manifolds', 'differential-geometry', 'smooth-functions']"
2120271,Multiple-choice: sum of primes below $1000$,"I sat an exam 2 months ago and the question paper contains the problem: Given that there are $168$ primes below $1000$. Then the sum of all primes
  below 1000 is (a) $11555$ (b) $76127$ (c) $57298$ (d) $81722$ My attempt to solve it: We know that below $1000$ there are $167$ odd primes and 1 even prime (2), so the sum has to be odd, leaving only the first two numbers. Then I tried to use the formula ""Every prime can be written in of the form $6n-1$,$6n+1$ except $2$ and $3$."", but I got stuck at that.","['algebra-precalculus', 'summation']"
2120280,How to use finite differences to determine an equation of a polynomial given consecutive integer $x$ and corresponding $y$ coordinates of the graph?,"This chart is given: for $x=-3$, $y=-9$ for $x=-2$, $y=3$ for $x=-1$, $y=3$ for $x=0$, $y=-3$ for $x=1$, $y=-9$ for $x=2$, $y=-9$ for $x=3$, $y=3$ I found the finite differences to be 6 and degree of the polynomial with the given points to be 3 ($n=3$). But how do I find the polynomial function rule out of this information? Given no factors? Please help with a short solution. Thanks a lot in advance. I also did $y=kx^3$, $-9=k(-3)^3$, $k=1/3$. But of course the rule isn't $y=1/3x^3$.",['algebra-precalculus']
2120307,Is the following limit finite ....?,"I would like to see some clue for the following problem: Let $a_1=1$ and $a_n=1+\frac{1}{a_1}+\cdots+\frac{1}{a_{n-1}}$, $n>1$. Find
$$
\lim_{n\to\infty}\left(a_n-\sqrt{2n}\right).
$$","['real-analysis', 'asymptotics', 'sequences-and-series']"
2120341,Finding out the limit $\lim_{a \to \infty} \frac{f(a)\ln a}{a}$,For any real number $a \geq 1$ let $f(a)$ denote the real solution of the equation $x(1+\ln x)=a$ then the    question is to find out $$ \lim_{a \to \infty} \frac{f(a)\ln a}{a}$$. It is clear that if we denote $h(a)$ by $h(a)=a(1+\ln a)$ then $f(a)$ is the inverse function of $h(a)$. Also $f(a)$ is increasing function in its domain. Also the limit persuades using lhospital's but I cannot see how to apply it here. Thanks.,['limits']
2120379,$ \lim_{n \rightarrow \infty} n \left( \frac{1}{(n+1)^2} + \frac{1}{(n+2)^2} + \cdots + \frac{1}{(2n)^2} \right)$ as Riemann sum?,"I am trying to evaluate the limit $$
\lim_{n \rightarrow \infty} n \left( \frac{1}{(n+1)^2} + \frac{1}{(n+2)^2} + \cdots + 
\frac{1}{(2n)^2} \right).$$ I have been trying to convert it to the Riemann sum of some integral, but have been unable to recongize what the integral should be. How should I go about solving this problem?","['real-analysis', 'calculus']"
2120401,"Show that limit of $\frac{\sin(xy)}{\sqrt{x^2+y^2}} = 0$ as $(x,y) \to (0,0)$","I'm asked to show that the limit of $\frac{\sin(xy)}{\sqrt{x^2+y^2}} = 0$ as $(x,y) \to (0,0)$. I guess the easiest way to do this would be by converting to polar form, so this is what I did: $$\frac{\sin(xy)}{\sqrt{x^2+y^2}} = \frac{\sin(r^2\cos\theta \sin\theta)}{\sqrt{r^2\cos^2\theta+r^2\sin^2\theta}} = \frac{\sin(r^2\cos\theta \sin\theta)}{\sqrt{r^2(\cos^2\theta+\sin^2\theta)}} = \frac{\sin(r^2\cos\theta \sin\theta)}{r}$$ from here I guess I should try to prove using the definition, so I did the following: since we know L is $0$ $$\left|\frac{\sin(r^2\cos\theta \sin\theta)}{r} - 0\right| = \left|\frac{\sin(r^2\cos\theta \sin\theta)}{r}\right| \leq \left| \frac{1}{r} \right| = \frac{1}{r}$$ which is true because $sin$ is bounded by $0$ and $1$, and $r$ is always a positive value.  I also know that, since we are using polar coordinates, the distance between $(0,0)$ and $(x,y)$ is $r$. But I'm stuck here, I don't really know where to go from this. I guess I'm not getting the strategy behind the definition? I think I'm pretty close to the answer, so feel free to give me the last steps if there's little to be done, it won't spoil the fun for me :)","['multivariable-calculus', 'calculus', 'limits']"
2120415,Is $(11)$ a prime ideal of $\mathbb{Z}[\sqrt{-5}]$?,"Is $(11)$ a prime ideal of $\mathbb{Z}[\sqrt{-5}]$? I know that $11$ is an irreducible element in $\mathbb{Z}[\sqrt{-5}]$. Now to determine whether it is prime we can say $\mathbb{Z}[\sqrt{-5}]$ isomorphic to $\mathbb{Z}[x]/(x^2 + 5)$. So we get an isomorphism
$$ 
\mathbb{Z}[\sqrt{-5}]/(11) \;\;\simeq\;\; \mathbb{Z}_{11}[x]/(x^2 + 5)
\,.$$ Since $\mathbb{Z}_{11}$ is a field, $\mathbb{Z}_{11}[x]$ is a PID, and since $(x^2 + 5)$ is irreducible over $\mathbb{Z}_{11}[x]$, the ring $\mathbb{Z}_{11}[x]/(x^2 + 5)$ is a field. Hence $(11)$ can be treated as a maximal ideal as well as a prime ideal in the ring $\mathbb{Z}[\sqrt{-5}]$.","['abstract-algebra', 'ring-theory', 'field-theory']"
2120425,Why is Geometry so neglected in undergraduate curricula?,"In my university (a pretty large state school in the U.S.) we have only one undergraduate geometry class. Even in grades 6-12, students typically only take 1 year of geometry. Is there really not much to gain in the grander scheme of things by studying geometry?","['soft-question', 'geometry']"
2120514,Is the empty set a neighborhood of itself?,"My topology textbook (Lee, Introduction to Manifolds) says a $\textbf{neighborhood}$ of $p$ is just an open
  subset of $X$ containing $p$. More generally, if $K\subseteq X$, a neighborhood of the subset $K$ is an open subset containing $K$. (In some books, the word “neighborhood” is used in the more general sense of a subset containing an open subset containing $p$ or $K$; but for us neighborhoods are always open subsets.) The empty set is an open subset of every topology, by definition. The empty set also ""contains"" itself, in the sense that $\emptyset\subseteq\emptyset$. Since it meets these two conditions, is it not a neighborhood of itself? The answer to this related question states The empty set ∅ is not a neighborhood of any point $x∈X$, because as you correctly observed, there are no elements of ∅. However, nowhere in this definition are sets with no elements explicitly excluded from consideration for being neighborhoods.","['general-topology', 'elementary-set-theory']"
2120542,$48$ reasons why a matrix is singular,"Currently using the MIT recordings from Prof.Strang to review deduction of the determinant formula . Let's say we take a closer look at $$
\left\vert\begin{array}{c c}
a & 0\\
c & 0
\end{array}\right\vert
$$ And to quote from the transcript: Why is that determinant nothing, forget him? Well, it has a column of zeros. And by the -- well, so one way to think is, well, it's a singular matrix. Oh, for, for like forty-eight different reasons. That determinant is zero. Now $48$, that's an oddly specific number. And while I do believe he was exaggerating, it did make me curious about just how many reasons (the determinant's being zero not included, of course) there really are for that matrix' being singular. What are they?","['matrices', 'linear-algebra', 'determinant']"
2120617,"Is that possible to change any gamma distribution to $\Gamma(k=0,\theta=1)$","If a random variable $x$ follows a Gamma distribution $\Gamma(k,\theta)$, is it possible to transform the variable and make it follows $\Gamma(k=0,\theta=1)$, like we transfer the variable which follows a Gaussian distribution to Normal distribution through $(x-\mu)/\sigma$ ($\mu$ is the mean and $\sigma$ is the standard deviation)? Many thanks.",['statistics']
2120630,What can I get from measure $0$ set?,"I'm having issues with this problem: Let $f:[0,1]\rightarrow[0,1]$ injective and continuous function. Let A=$\bigcup_i (a_i,b_i)$ $\forall x_1, x_2 \in (a_i,b_i)$, $|f(x_1)-f(x_2)|\leq |x_1-x_2|$ $f([0,1]\setminus A)$ has Lebesgue measure $0$ I have to show $\forall x_1, x_2 \in [0,1]$, $|f(x_1)-f(x_2)|\leq |x_1-x_2|$. What I know: 
I noticed that $[0,1]\setminus A$ needs to have empty interior.
Moreover, $f$ has to be increasing (because of continuity and injectivity).
I also noticed that it has to work in the for $x_1,x_2\in [a_i,b_i]$.
This leads me to believe that I can get more out of the $0$ measure, am I missing something?","['real-analysis', 'lebesgue-measure', 'measure-theory']"
2120642,lattice of subgroup,"In the spirit of category theory, we use relations between objects to describe the object themselves. In the same sense I want to use the lattice structure of subgroups to decide whether a subgroup is normal. 
We know that if $H \lhd G$ and $K \subset G$, then there is a lattice preserving bijection from subgroups of $K$ containing $H \cap K$ to subgroups of $HK$ containing $H$. This gives us a categorical description of normality. My question is: Does the converse hold? That is, if for every $K \subset G$, this bijection also holds, must $H$ be normal in $G$? (Here we need a modification: $HK$ needs to be replaced by $\langle H, K \rangle$.)","['category-theory', 'normal-subgroups', 'lattice-orders', 'group-theory']"
2120654,Finding the number of combinations.,"I have been struggling with this problem for a while. I'd be glad if anyone could help me with this. My wife and I recently attended a party at which there were three other married couples. Various handshakes took place. No one shook hands with oneself, nor with one's spouse, and no one shook hands with the same person more than once. After all the handshakes were over, I asked each person, including my wife, how many hands he (or she) had shaken. To my surprise each gave a different answer. How many hands did my wife shake? I understand that the maximum and minimum number of handshakes that can take place are 6 and 0 and that these people must be married. Similarly I get that other pairs should be (5,1) (4,2) and (3,3). What has really been bothering me is that how do I know which pair is me and my wife?",['combinatorics']
2120668,Solving $(x^{y+1}x\ln x - x^2 y^x)y' = y^{x+2}\ln y - x^y y^2$,"I had the differential equation $$(x^{y+1}x\ln x - x^2 y^x)y' = y^{x+2}\ln y - x^y y^2$$
 and simplified it to $$x(xx^y(y'\ln x)+yx^y (yx^{-1})))+y(yy^x(\ln y)+xy^x(xy^{-1}y'))=0$$ But what to do next ? Any hints?",['ordinary-differential-equations']
2120685,Subgroup of finite index contains a normal subgroup of finite index [duplicate],"This question already has answers here : For $G$ group and $H$ subgroup of finite index, prove that $N \subset H$ normal subgroup of $G$ of finite index exists (3 answers) Closed 10 months ago . Let $G$ be a group and $H\leq G$. Suppose $[G:H]$ is finite. Show that
  there exists a normal subgroup $N \subseteq H$ in $G$ which is also of
  finite index in $G$. My idea was to use $$N := \bigcap_{g \in G} gHg^{-1}$$ It is clear that $N$ is normal in $G$ and that $H$ contains $N$. Is it true that this specific $N$ is of finite index? How would I show it?",['abstract-algebra']
2120717,There are quasi-affine varieties which are not affine,"I see this sentence in Hartshorne, exercices 3.6 in chapter 1. And he build a counter-example, namely $\mathbb{A}^2 \backslash \{(0,0)\}.$ But for me, this sentence is absolutely trivial. Indeed, an affine variety is closed and a quasi-affine variety is dense open. So if a variety is affine and quasi-affine, it is the whole space $\mathbb{A}^n
.$ There is something that I'm probably missing here. Thanks for any helpful comment.",['algebraic-geometry']
2120798,Find $\lim_{n\rightarrow \infty }\left(\sum_{k=0}^{n-1}{\frac{e^{\frac{k}{n}}}{n}}\right)$.,"Find $$\lim_{n\rightarrow \infty }\left ( \frac{1}{n} + \frac{e^{\frac{1}{n}}}{n} +  \frac{e^{\frac{2}{n}}}{n} + \frac{e^{\frac{3}{n}}}{n}+.....+ \frac{e^{\frac{n-1}{n}}}{n}\right ).$$ Solving a bit and applying GP, I got $\left ( e-1 \right )\lim_{n\rightarrow \infty } \frac{1}{n.\left ( e^{\frac{1}{n}} -1 \right )}$ Now, limit gives the expression as $\left ( e-1 \right )\lim_{n\rightarrow \infty } \frac{1}{\infty *0}$ How do I find it now? Should I use the $\frac{0}{0}$ form?",['limits']
2120812,"Why is the ""Buffalo Way"" considered inelegant?","I was going through an ""article"" on the ""Buffalo Way"" , where the author said that one should NEVER use the Buffalo Way for proving inequalities in actual real-time contests as it is ""highly inelengant"". What is the reason behind this notion ? In Mathematics, there are a whole lot of ways to attempt a given question. If the BW provides a proof for some inequality, then why it is given the downvote ?","['inequality', 'polynomials', 'algebra-precalculus', 'contest-math', 'buffalo-way']"
2120816,Approximation of $e^x$,"I was working on the approximation of $y=$ $e^x$ at $x=x_2$ in terms of its known value at a neighbour point $x=x_1$. Approximation by derivatives gives us this: 
$y_2$ =$e^{x_2}=e^{x_1}+(x_2-x_1)e^{x_1}$=$y_1+(x_2-x_1)y_1$ I was trying to get something even more accurate and I've come up with this: $lny_2$= $x_1(\frac{lnx_2}{lnx_1})^{lnx_1}$
 where $lnx$ is the natural logarithm. I've checked that this one is more accurate. It's less accurate than the derivative formula for $x_1=1,2,3$ but for higher $x_1>3$, it gives a better approximation. 1. Is my formula some special case of some already discovered approximation rule or have I come up with something new? 2. Is it useless? I've derived approximations of other functions also but the one for $e^x$ was the least messy. Update: I just checked that it's more accurate even when $x_1=3$. By taking $x_1=3$, I tried approximating $e^{3.5}$. The actual value is 33.1. The derivative approximation gave 30.11 and my formula gave 31.98. For somewhat large $x$, it is far better than the derivative. Try approximating $e^{12}$ by taking $x_1=10$ by derivative and by my method. Update:Oh, I just figured out that my formula is equivalent to saying $x_2$=$x_1(\frac{lnx_2}{lnx_1})^{lnx_1}$
 , where $x_1$ and $x_2$ are any two neighbouring numbers. So, I think it's useless then. But still is it a new relation between two neighbouring numbers and their logarithms?.","['derivatives', 'exponential-function', 'approximation']"
2120842,The rate at which distance between ships change,"I know this looks like a physics problem but its given in my maths question sheets so I am asking it here.  Two ships A and B are sailing away from a fixed point   O such that $AOB=120 ^\circ $ . At a particular instant OA is $8km $ and OB is $6km $ and ships A,B are sailing at $20km/hr,30km/hr $ respectively. Then the distance between them is changing at the rate (km/hr)?$$\text {Attempt} $$  I assumed  B is moving along X axis and A is having motion in both directions . So  at any time t the distance travelled by $B $ is $30t $ and that by A is $x=-10t,y=10\sqrt{3}t $ thus total distance between A and B  is given by $d=\sqrt {{20}t^2}+10\sqrt {3}t $ .Now we want rate change so I differentiated it . But I am not sure if this is correct so wanted to verify and get idea on how to solve such problems.","['derivatives', 'trigonometry', 'calculus']"
2120857,Limit of a function with e.,"I'm struggling with calculating the limit of the following function:
$$\lim_{x\to 0^-}\frac{e^{\frac{1}{x}}}{x}$$
I tried using L'Hopital's rule, but I'm still getting $\frac{0}{0}$ and the denominator keeps getting greater exponent.","['functions', 'limits']"
2120861,Laurent Series of $\frac{1}{(z-2)(z+1)}$,"$$\frac{1}{(z-2)(z+1)}=\frac{A}{z-2}+\frac{B}{z+1}$$ \begin{cases}A+B=0 \\ A-2B=1
\end{cases} $$A=\frac{1}{3} \\ B=-\frac{1}{3}$$ $$\frac{1}{(z-2)(z+1)}=\frac{\frac{1}{3}}{z-2}+\frac{-\frac{1}{3}}{z+1}$$ Laurent Series $$\rvert z \rvert <1$$ $$\frac{1}{(z-2)(z+1)}=-\frac{1}{6} \ \frac{1}{-\frac{z}{2}+1}-\frac{1}{3} \ \frac{1}{1-(-z)}= \\=-\frac{1}{6} \sum_{n=0}^{+\infty} (\frac{z}{2})^n-\frac{1}{3} \sum_{n=0}^{+\infty} (-z)^n  $$ $$1 < \rvert z \rvert <2$$ $$\frac{1}{(z-2)(z+1)}=-\frac{1}{6} \ \frac{1}{-\frac{z}{2}+1}-\frac{1}{3} \ \frac{1}{z(1-(-\frac{1}{z}) )}= \\ \\ = -\frac{1}{6} \sum_{n=0}^{+\infty} (\frac{z}{2})^n-\frac{1}{3} \sum_{n=0}^{+\infty} (-\frac{1}{z})^{n+1} $$ $$ \rvert z \rvert >2$$ $$\frac{1}{(z-2)(z+1)}=\frac{1}{3} \ \frac{1}{z(1-\frac{2}{z})}-\frac{1}{3} \ \frac{1}{z(1-(-\frac{1}{z}) )}= \\ \\ = \frac{1}{3} \sum_{n=0}^{+\infty} (\frac{2}{z})^{n+1}-\frac{1}{3} \sum_{n=0}^{+\infty} (-\frac{1}{z})^{n+1} $$ Is it correct? Thanks!","['laurent-series', 'complex-analysis', 'sequences-and-series', 'analysis']"
2120879,Determine $z = x+iy \in \mathbb{C}$ for which the derivative of $f(z) = x^{2}-y+ixy^{2}$ exists.,"May i know if my approach is correct? We need to solve the Cauchy Riemann equations to deduce which points $f(z)$ is differentiable at. Let $u(x,y) = x^{2}-y, v(x,y)= xy^{2}$ and thus $$u_x = 2x ~,~ u_y = -1~,~v_x =y^{2}~,~v_y = 2xy$$ we clearly see that $u_x,u_y,v_x,v_y$ are continuous on $\mathbb{C}$ since they are polynomials, thus to find where $f$ is differentiable, we proceed to solve the Cauchy - Riemann equations. $$u_x = v_y, u_y = -v_x$$ \begin{equation}
u_x = v_y, u_y = -v_x \Rightarrow \begin{cases}
2x=2xy \\
y^{2} = 1
\end{cases}
\end{equation} By solving the above equation, we have two sets of solutions where $(x,1),(0,-1)$ and hence $f$ is differentiable at $z = -i$ and $z= x+i$ for all $x \in \mathbb{R}$","['derivatives', 'complex-analysis', 'partial-derivative', 'complex-numbers']"
2120945,Let $S$ be the set of all circles on the unit sphere in $\mathbf{R}^3$. Give a smooth manifold structure to $S$.,"I am not sure how to do this. $S$ includes singletons too (radius $0$). I have tried mapping a circle to the pair consisting of its center point and its radius, but it isn't injective.","['manifolds', 'smooth-manifolds', 'differential-geometry']"
2120946,Why is central difference preferred over backward and forward difference in convolution?,It is mentioned in some literature that we should always use central difference when computing the derivatives of an image instead of forward or backward difference. Does anyone knows why is that? Central difference = $\frac{df(x)}{dx} = \frac{f(x+h) - f(x-h)}{2h}$ Forward difference = $\frac{df(x)}{dx} = \frac{f(x+h) - f(x)}{h}$ Backward difference = $\frac{df(x)}{dx} = \frac{f(x) - f(x-h)}{h}$,"['derivatives', 'image-processing', 'numerical-methods']"
2120962,Does there exist continous function $f(x)$ defined on $(-\infty ; +\infty)$?,"Does there  exist continous function $f(x)$ such that 
$$f(x)=\begin{cases} \frac{m}{n} & \text{if } x \text{ is irrational,} \\
\text{irrational} & \text{if } x \text{ is rational} \end{cases}$$
I think it's impossible, as definition of that function is similar to Dirichlet Function or Thomae's function. And these functions are always discontinous somewhere. Please help, I don't know what to start with. I'm first year undergraduate","['continuity', 'calculus', 'functions']"
2120963,Finding the limit of $s((1+\frac{1}{s})^{s} - e)$ as $s$ aproaches infinity [duplicate],"This question already has answers here : Limit of $x\left(\left(1 + \frac{1}{x}\right)^x - e\right)$ when $x\to\infty$ (4 answers) Closed 4 years ago . I came across that limit: $\lim_{s\to\infty} s\bigg(\big(1+\frac{1}{s}\big)^{s} - e\bigg)$
I tried to solve it using l'Hospital's rule: $\lim_{s\to\infty} s\bigg(\big(1+\frac{1}{s}\big)^{s} - e\bigg) = \lim_{t\to0} \frac{1}{t} \bigg(\big(1+t\big)^{\frac{1}{t}} - e\bigg) = \lim_{t\to0} e^{\frac{1}{t}\log(1+t)}\big(\frac{1}{t(t+1)} - \frac{\log(1+t)}{t^{2}}\big)$ I used l'Hospital's rule after the second equality. However I got nothing really valuable. Do you have any ideas how to solve that problem?",['limits']
2121001,Exponential of a symmetric tridiagonal Toeplitz matrix,"Let $\alpha$ be a (strictly) positive real number. Consider the following tridiagonal Toeplitz matrix
$$
A=\alpha\begin{bmatrix}
0 & 1 & 0 &\cdots & 0\\
1 & 0 & 1 &\ddots & \vdots \\
0 & 1 & 0 & \ddots & 0\\
\vdots & \ddots & \ddots & \ddots & 1 \\
0 & \cdots & 0 & 1 & 0
\end{bmatrix}.
$$ My question. Does there exist a closed-form expression for $\exp(A)$? I played around a little bit with the truncated series $\sum_{k=0}^N \frac{A^k}{k!}$ but I didn't manage to provide an answer to my question. Pointers to the literature are also welcome!","['tridiagonal-matrices', 'matrices', 'reference-request', 'toeplitz-matrices', 'matrix-exponential']"
2121004,"Prove that if A and B are doubly-stochastic matrices of order n, then AB is also a doubly-stochastic matrix","Prove that if A and B are doubly-stochastic matrices of order n, then AB is also a doubly-stochastic matrix. My attempt: Since the size of A is nxn and the size of B is nxn, then the size of AB is also nxn. Let A = ($a_{ij}$) and B = ($b_{ij}$). Consider the sum of the entries in the $i$th row of AB: $a_{i1}b_{11} + a_{i2}b_{21} + a_{i3}b_{31} + ... + a_{in}b_{n1}$ + $a_{i1}b_{12} + a_{i2}b_{22} + a_{i3}b_{32} + ... + a_{in}b_{n2}$ + $...a_{in}b_{nn}$ = $a_{i1}(b_{11} + b_{12} + ... + b_{1n}) + a_{i2}(b_{21} + b_{22} + ... + b_{2n}) + ...+ a_{in}(b_{n1} + b_{n2} + ... + b_{nn})$ = $a_{i1} + a_{i2} + ... + a_{in}$ = $1$ Next, I would consider the sum of the entries in the jth column of AB. However, at this point, I'm stuck. So, I'm wondering if my method is possible. Is there also a better way to prove this?","['matrices', 'linear-algebra']"
2121006,Show through chain rule that $(u\cdot v)' = uv' + v'u$,Let function be $f(x)=u\cdot v$ where $u$ and $v$ are in terms of $x$. Then how to make someone understand that $f'(x) = uv' + u'v $ only using chain rule? My attempt: I don't even think it is possible but I may be wrong.,"['derivatives', 'chain-rule', 'calculus']"
2121015,Finding the variation field,"Let $M$ be a complete connected Riemannian manifold and $r\in M$ and $p,q\in B(r;R)$ where $R$ is the convexity radius at point $r$. Let $u\in T_pM$ and $v\in T_qM$ and $\epsilon>0$ be such that $\exp_psu,\exp_qsv\in B(r;R)$ and $\Gamma:(-\epsilon,\epsilon)\times[0,1]\to M$ be defined by $$\Gamma(s,t)=\exp_{\exp_psu}(t\exp^{-1}_{\exp_psu}\exp_qsv)$$ I want to calculate the variation field $V(t)=\partial_s\Gamma(0,t)$ at $t=0$ and $t=1$, that is $$\partial_s\Gamma(0,t)=\frac d{ds}\Gamma(s,t)|_{s=0}$$ If $\gamma(s)=t\exp^{-1}_{\exp_psu}\exp_qsv$ ,then
$$\frac d{ds}\Gamma(s,t)|_{s=0}=(\exp_{\exp_psu})_{*t\exp^{-1}_pq}(\dot\gamma(0))$$ if $\mu=\exp_qsv$, then
$$\dot\gamma(0)=(t\exp^{-1}_{\exp_psu})_{*q}(\dot\mu(0))$$
So, 
$$V(0)=(\exp_{\exp_psu})_{*0}((0)_{*q}(\dot\mu(0)))$$
and
$$V(1)=(\exp_{\exp_psu})_{*\exp^{-1}_pq}((\exp^{-1}_{\exp_psu})_{*q}(\dot\mu(0)))$$
but I don't know how continue from here. In this paper is claimed that $V(0)=u$ and $V(1)=v$ without any explanation. Can anyone give me some hint for calculating of $V(0)$ and $V(1)$, please?","['manifolds', 'riemannian-geometry', 'differential-geometry', 'differential-topology']"
2121032,Fully prove that curve is of certain type,"I apologize for the generic title. By type I mean that it belongs to a class of curves, such as helixes, circles, lines, etc. To the point however, I stumbled into an exercise where asked to describe which type of curve that has the following parameterization: $$\vec{r} = (a \cos t \sin t)\hat{i} + (a \sin^2 t)\hat{j} + bt\hat{k}, $$ What I did was that I tried to express the $x$- and $y$-components in the form $C_1 \sin f(t)$ and $C_2 \cos f(t)$ respectively. So: $$x=a \cos t \sin t=\frac{a}{2} \sin 2t$$
$$y = a \sin^2 t=a\frac{1-\cos^2 2t}{2} \iff 2y - a = -a\cos 2t$$ Using this, I confirmed that:
$$x^2 + \left(y - \frac{a}{2}\right)^2 = \left( \frac{a}{2} \right)
^2$$ This implies that the curve lies on the cylinder with the above equation. However, this is where I get a bit confused as to how to proceed. It is seemingly clear that the equation represents a helix, considering that $z$ is increasing and both $x$ and $y$ draws out projections that are circles in the $xy$-plane. But how do I actually prove this? Technically, it could be the line $x = y = 0$ as well, if I don't proceed to somehow that $x$ and $y$ are ""behaving circular"" (you get what I mean, hopefully). Worth mentioning is that the book doesn't seem to prove this either. Question: Can I in this particular case prove that the curve is a helix? My initial guess was that it had to do with $x,y \in C^0$, along with some other constraint, but I can't really get any further. Any help would be gladly appreciated!","['multivariable-calculus', 'curves']"
2121035,Evaluate a limit involving definite integral,"Evaluate the following limit:
$$\lim_{n \to \infty} \left[n - n^2 \int_{0}^{\pi/4}(\cos x - \sin x)^n dx\right]$$ I've tried to rewrite the expression as follows:
$$\lim_{n \to \infty} \left[n - n^2 \sqrt{2}^n \int_{0}^{\pi/4}\sin^n \left( \frac{\pi}{4} - x \right) dx\right]$$ However, this doesn't seem to help too much. Thank you!","['definite-integrals', 'limits']"
2121060,Counting the number of non-consecutive subsets of integers from $1$ to $n$. [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question Given a set $X=\{1,2,\ldots,n\}$, how would I count the number of subsets containing only nonconsecutive elements? For example: $X=\{1,2,3,4\}$ implies 3 nonconsecutive subsets: $\{1,3\}, \, \{2,4\}, \, \{1,4\}$",['combinatorics']
2121069,Does $(\ell^\infty)^*$ have the cardinality of the continuum?,"I have a sort of intuitive but non-rigorous understanding of the dual of $\ell^\infty(\Bbb N)$. It is the span of evaluation maps of bounded sequences and of evaluations ""at infinity"": consistent ways of picking out limit points of sequences. This seems like a very big space. Is it still ""small enough"" to have the cardinality of the continuum?","['functional-analysis', 'banach-spaces', 'cardinals']"
2121087,Evaluation of $\int ^{\pi/2}_{0} \sqrt{\sin {2x}} \cdot \sin{x} \cdot dx$,Evaluate the given integral $$\int ^{\pi/2}_{0} \sqrt{\sin {2x}} \cdot  \sin{x} \cdot dx$$ I am varying various trigonometric manipulation but like reducing it to $\int ^{\pi/2}_{0}  \frac{\sin ^2 x}{\sqrt{\tan x}}.dx$ but nothing leads to any fruitful result. Could someone give me some hint?,"['integration', 'definite-integrals', 'calculus']"
2121118,Minimize Expected squared Prediction Error (EPE),"I have difficulty understanding when minimizing expected squared prediction error: $$\operatorname{EPE}(\beta)=\int (y-x^T \beta)^2 \Pr(dx, dy),$$ how to reach the solution that $$\operatorname{E}[yx]-\operatorname{E}[xx^{T}\beta]=0.$$ From A Solution Manual and Notes for the Text: The Elements of Statistical Learning (page 2), I noticed the formula (2): $$\frac{\partial \operatorname{EPE}}{\partial \beta}=\int 2(y-x^T\beta)(-1) x \Pr(dx, dy).$$ I understand chain rule is used here to solve the derivative, but why the last part is $x$ instead of $x^T$? As $x$ is a column vector and the Jacobian of a constant w.r.t. $x$ should be a row vector. $$\frac{\partial x^T\beta}{\partial \beta}=x^T.$$ What is missing in my analysis? According to the Jacobian matrix , shouldn't the $\frac{\partial x^T\beta}{\partial \beta}$ be a row vector instead of a column vector? $$\frac{\partial EPE}{\partial \mathbf{\beta}}=  \left (\frac{\partial EPE}{\partial \beta_{1}}, \frac{\partial EPE}{\partial \beta_{2}}, \dots, \frac{\partial EPE}{\partial \beta_{N}}  \right )$$",['statistics']
2121175,Is it possible to have a spherical object with only hexagonal faces?,"If so, what would be the most efficient algorithm for generating spheres with different number of hexagonal faces at whatever interval required to make them fit uniformly or how might you calculate how many hexagonal faces are required for each subdivision?","['polyhedra', 'graph-theory', 'geometry']"
2121188,How would I prove the dual of $L^1$ Is isomorphic to $L^\infty$?,I've really hit a brick wall trying to prove the dual of $L^1$ Is isomorphic (as a normed space) to $L^\infty$ ?,"['derivatives', 'real-analysis', 'ordinary-differential-equations', 'linear-algebra']"
2121194,On connected components of a topological/Lie group,"Let $G$ be a topological group (or a Lie group). If $G^0$ is the identity component, we know that $G^0$ is a normal subgroup of $G$. But is it true that if $C$ is any connected component of $G$, there is $a\in G$ such that $C=aG^0$? I tried to come up with some counter-example, to no avail (I'm low on imagination, I guess), and I couldn't prove it either. Initially I thought about the problem for topological groups, but if the situation is somehow easier for Lie groups you can discuss this case. Help?","['abstract-algebra', 'topological-groups', 'group-theory', 'lie-groups']"
2121200,"Prob. 12, Chap. 4 in Baby Rudin: A uniformly continuous function of a uniformly continuous function is uniformly continuous","Here is Prob. 12, Chap. 4 in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: A uniformly continuous function of a uniformly continuous function is uniformly continuous. State this more precisely and prove it. Here is my effort: Theorem:** Let $\left(X, d_X\right)$ , $\left(Y, d_Y \right)$ , and $\left( Z, d_Z \right)$ be metric spaces, let $f$ be a uniformly continuous mapping of $X$ into $Y$ , let $g$ be a uniformly continuous mapping of $f(X)$ into $Z$ , and let $h = g \circ f$ . Then $h$ is a uniformly continuous mapping of $X$ into $Z$ . Proof:** Let $\varepsilon$ be a given real number such that $\varepsilon > 0$ . Since $g$ is a unifromly continuous mapping of $f(X)$ into $Z$ , we can find a real number $\eta > 0$ such that $$\tag{1} d_Z \left( g \left( y_1 \right), g \left( y_2 \right) \right) < \varepsilon$$ for any points $y_1$ and $y_2$ in $f(X)$ for which $$\tag{2} d_Y \left( y_1, y_2 \right) < \eta.$$ Now as $f$ is a uniformly continuous mapping of $X$ into $Y$ , so, corresponding to the real number $\eta > 0$ in particular, we can find a real number $\delta > 0$ such that $$ \tag{3} d_Y \left( f \left(x_1 \right), f \left( x_2 \right)  \right) < \eta$$ for any points $x_1$ and $x_2$ in $X$ for which $$ \tag{4} d_X \left( x_1, x_2 \right) < \delta.$$ So, we can conclude from (1), (2), (3), (4) above that, for any points $x_1$ and $x_2$ in $X$ which satisfy $$d_X \left( x_1, x_2 \right) < \delta,$$ the following is true. $$ d_Z \left( h \left(x_1 \right), h\left( x_2 \right) \right)  = d_Z \left( g\left( f\left( x_1 \right) \right), g\left( f\left( x_2 \right) \right) \right) < \varepsilon, $$ from which it follows that $h = g \circ f$ is a uniformly continuous mapping of $X$ into $Z$ . Have I managed to get the statement of the theorem right? If so, then is my proof correct?","['real-analysis', 'continuity', 'uniform-continuity', 'metric-spaces', 'analysis']"
2121205,Finding a geometric interpretation,"I recently solved a question of complex numbers which was this: $A\left( \frac{2}{\sqrt{3}} e^\frac{i\pi}{2}\right)$, $B\left( \frac{2}{\sqrt{3}} e^\frac{-i\pi}{6}\right)$, $C\left( \frac{2}{\sqrt{3}} e^\frac{-5i\pi}{6}\right)$ are the vertices of an equilateral triangle. If $P$ be a point on the incircle of the triangle, prove that $AP^2 + BP^2 + CP^2 = 5$. My approach: The point $P$ is given by $z = \frac{1}{\sqrt{3}}e^{i\theta}$, since the radius of the incircle of an equilateral triangle is half its circumradius. Then, $$
AP² = |A - z|^2 \\
= (A - z)(A^* - z^*) \\
= AA^* - Az^* - A^*z + zz^* \\
= |A|² + |z|² - Az^* - A^*z \\
= \frac43 + \frac13 - Az^* - A^*z \\
= \frac53 - Az^* - A^*z.
$$ Now, $$
AP^2 + BP^2 + CP^2 \\
= 3\times\frac53 - z^*(A+B+C) - z(A^*+B^*+C^*) \\
= 5
$$ since $A+B+C = A^*+B^*+C^* = 0$ because the position vectors $\vec{A}$, $\vec{B}$ and $\vec{C}$ are coplanar and are mutually separated by $120^\circ$. This, I guess, is a pretty neat solution. But what I'm looking for is a more intuitive solution, rather a geometric interpretation. Does anyone know such an approach?","['complex-numbers', 'geometry']"
2121211,find Asymptotes of $f(x) = \arcsin(\frac{2x}{1+x^2})$,"I'm trying to find the asymptotes of $f(x) = \arcsin(\frac{2x}{1+x^2})$. I've found that this function has no vertical asymptote, since $f$ is bounded between $[-\pi/2 , \pi/2 ]$, and since $\arcsin x$ is continuous where it is defined - for every $x_0 \in R$, $\lim_{x\to x0^+}|f(x)| = |f(x_0)| \neq \infty $. Hopefully this once is correct, please correct me if it isn't. I think I'm wrong in the calculation of the horizontal asymptotes : if $y=ax+b$ is a horizontal asymptote at $\infty$, then $a = \lim_{x\to\infty}\frac{f(x)}{x} = 0$. Now, $b= \lim_{x\to\infty}(f(x)-ax) = \lim_{x\to\infty}f(x) = 0$ So I'm getting that this function has no vertical asymptotes, which I guess is correct, but I also get $y=0$ as a horizontal asymptotes which I'm pretty sure is wrong.. Where is my mistake?","['asymptotics', 'functions', 'limits']"
2121250,"Cardinality of $[0,1]$","Assuming we know that the cardinality of $(0,1)$ is $c$. Can we from this determine the cardinality of $[0,1]$?
Is it valid to say that $[0,1]$ also has cardinality c because adding a finite number of elements to $(0,1)$ (i.e. including the boundaries) does not affect the cardinality?","['cardinals', 'elementary-set-theory']"
2121260,infinite product of $Z$ hasn't a basis,"I was reading this brief article (I don't know if I am allowed to post links, if don't I apologize) concerning the fact that $\prod_{i=1}^{\infty} \mathbb{Z}$ has no basis and is not a free group. The problem is just before the end of the article. When he says that the last equation has solutions for $n=n_1,n_2, \dots$, shouldn't he stop at $n_i$? Then how can he conclude using the final lemma, if we have only a finite number of integers that allow a solution? (that is exacly what the lemma is saying, and so I shouldn't get an absurd).
Probably I am getting something wrong, but I can't figure out where my mistake is. Thanks for the help.","['abstract-algebra', 'group-theory', 'free-groups']"
2121340,Combinatorics - Which Approach,"I'm being asked 2 questions: 1) In a restaurant, there is exactly one table with $8$ seats unoccupied. How many possibilities are there for $6$ people? 2) In a class with $23$ people, $3$ are called to the teacher. How many possibilities are there? Now, Question 1 can be solved using: $8\cdot 7\cdot 6\cdot 5\cdot 4\cdot 3$ Question 2 however, can only be solved using the binomial coefficient of $23$ and $3$ So my question is: why can't I use the approach used in the first question, with the second one?",['combinatorics']
2121360,Show directional derivative equals $0$ for the local maximum or minimum along the same direction,"Let $(A,V,\|\cdot\|_V)$ be a $n$ -dimensional normed affine space where $A$ is the point set and $V$ is a $F$ -vector space, and $F$ is equipped with a modulus $|\cdot|$ . Let $(B,W,\|\cdot\|_W)$ be a one-dimensional normed affine space in which $W$ is a one dimensional $F$ -vector space. If we choose an origin $b\in B$ and a non-zero vector ${\bf w}\in W$ then every point in $B$ can be written as $b+c{\bf w}$ for some $c \in F$ . Here all norms and modulus are real-valued. Again, note $B$ and $W$ are ONE-DIMENSIONAL. 1. Directional derivative A function $f:A \to B$ , we say $f$ is differentiable at $a \in A$ along direction ${\bf{v}}\in V$ if there exists some ${\bf u} \in W$ s.t. $\lim_{h→0}⁡\frac{‖f({ a}+h{\bf v})-f({ a})-h{\bf u}‖_W}{|h|}=0$ where $h \to 0$ is a notation for $|h| \to 0$ . We say $\frac{\partial f({ a})}{\partial {\bf v}}={\bf u}$ is the derivative of $f$ along direction $\bf {v}$ at $ a$ . 2. Local maximum and minimum along a direction When an origin $b\in B$ and a base ${\bf w} \in W$ are chosen, a $f:A \to B$ map is equivalent to a corresponding $f_F:A\to F$ map since every point in $B$ is uniquely mapped to a coordinate in $F$ . A function $f:A\to B$ achieves a local maximum at point $a^* \in A$ along direction ${\bf v} \in V$ if there exists $\epsilon > 0$ s.t. $|f_F(a^*+h{\bf v})|\le|f_F(a^*)|$ for all $|h|<\epsilon$ . Similarly $f$ achieves a local minimum at $a^* \in A$ along direction $\bf v$ if there exists $\epsilon > 0$ s.t. $|f_F(a^*+h{\bf v})|\ge|f_F(a^*)|$ for all $|h|<\epsilon$ . Problem Now the problem is to prove if $f$ is differentiable along direction $\bf v$ near and at a local maximum or minimum $a^*$ , then $\frac{\partial f({ a^*})}{\partial {\bf v}}={\bf 0}$","['multivariable-calculus', 'real-analysis', 'differential-geometry', 'linear-algebra']"
2121402,"What is the differential of the adjoint action of a Lie group, $\partial_t{\rm Ad}(\gamma(t))V(t)$?","Given a Lie group $G$ with Lie algebra $\mathfrak{g}$, the adjoint action $Ad:G \rightarrow GL(\mathfrak{g})$ is given as the differential of the conjugation map in the unit element. Given two curves $\gamma: I \rightarrow G$ and $V:I \rightarrow \mathfrak{g}$. What is $\frac{d}{dt} Ad (\gamma(t)) V(t)$? I think the answer should be $$\frac{d}{dt} Ad (\gamma(t)) V(t) = ad \left( dL_{\gamma(t)^{-1}}\gamma'(t) \right) V(t)+Ad(\gamma(t))V'(t),$$ but I am not sure. $Ad$ is a special case of a map $f:M \times N \rightarrow P$ from a product manifold into some other manifold.
For $(m,n) \in M \times N$ and $V \in T_mM$, $W \in T_nN$ we have (remember $T(M\times N) \simeq TM \times TN$):
$$
df_{(m,n)}(V,W)
=
df_{(m,n)}(V,0)+df_{(m,n)}(0,W)
\\
=
d\left( f \mid_{M \times \{n\}} \right)(W,0)+d\left( f \mid_{\{m\} \times N} \right)(0,W).
$$ In the case of $Ad$:
$$\frac{d}{dt} Ad (\gamma(t)) V(t)
\\
=
d Ad_{(\gamma(t),V(t))} (\gamma \times V)'(t)
\\
=
d Ad_{(\gamma(t),V(t))} (\gamma \times const)'(t)
+
d Ad_{(\gamma(t),V(t))} (const \times V)'(t)
\\
=
\frac{d}{ds} \mid_{s=t} Ad (\gamma (s)) V(t)
+
\frac{d}{ds} \mid_{s=t} Ad (\gamma (t)) V(s)
\\
=
\frac{d}{ds} \mid_{s=t} Ad (\gamma (s)) V(t)
+
Ad (\gamma(t))V'(t).
$$
But why is $\frac{d}{ds} \mid_{s=t} Ad (\gamma (s)) V(t)=ad (dL_{\gamma^{-1}(t)} \gamma'(t)) V(t)$? 
Or is this the case anyway?","['differential-geometry', 'lie-algebras', 'lie-groups']"
2121411,Two-sample test for ordinal data.,I have a question in a survey X that can be rated between 1 and 10 (ordinal). The answers can be split in group A and group B. I want to know if the mean of group A's answers significantly differ from groups B rating. Which test is the best one to do so and how can I do this with SPSS? Thank you very much for your help!,"['statistics', 'correlation', 'hypothesis-testing']"
2121416,Open set intersect closed set,I'm trying to figure out if the following set is open or closed. Let $X$ be a topological space and let $\bigcup_i U_i $ be an open covering. Suppose $V$ is a closed subspace of $X$. Then is $ U_i \cap V$ open or closed in $V$ ? All I know is that $U_i \cap V$ is closed in $U_i$ but I can't see how this helps.,"['general-topology', 'elementary-set-theory']"
2121435,Do probabilities imply a static underlying system?,"I'm trying to wrap my head around how to interpret probabilities. Specifically, I work in sociolinguistics where language items (e.g. presence or absence of R at the end of words in English) are treated as variables whose realizations are associated with extra-linguistic variables. One takes a corpus of speech, finds all the tokens of a particular variable, determines the relative frequencies for the realizations of that variable and analyzes it according to various social variables (e.g. age of speakers, sex of speakers, etc.). The relative frequencies are typically converted to probabilities which are thought by some to represent the grammatical rules of the speakers in the corpus. The problem I have with this is at the point where relative frequencies are converted to probabilities. Language is thought to be constantly changing, but to me, probabilities seem to suggest that there's a static underlying system that generates the data that's being observed. A simple example: if one measures how many nights in a row the moon comes out, one can calculate a relative frequency from that and then go further and calculate a probability that it will come out on any given night. That probability will likely be 100% because what's actually being observed is a static system where the moon is orbiting the Earth according to physical laws. A probability in this case seems to be simply a calculation of an observation of the results produced by a law in action that we have not yet identified. If this is an accurate description of what probabilities actually represent, then does it makes sense to calculate them when working with a system that is constantly changing, e.g. language and its grammatical rules? A grammatical rule that says whether speakers of a particular dialect of English should pronounce an R at the end of words or not is not static; it's expected to change. If a group of people produce an R for 65% of all tokens, that may very well mean that they used to not produce an R but are starting to produce it more and more. I'm not exactly sure that there's utility in converting that relative frequency into a probability if the relative frequency simply represents the state the system was in at the time and not a static system where every single speaker makes sure to produce R 65% of the time and not the rest of the time. If my question points to an ongoing debate in probability theory as opposed to something that's been settled among mathematicians, what are the major arguments for how to interpret probabilities? Are there important articles in the literature that I could read to understand how mathematicians approach this topic?","['probability-theory', 'probability']"
2121441,"Lifting Finite Group Actions to Bundles, and Fixed Points","I want to let $G$ be a finite group and $X$ be an algebraic variety.  We define a holomorphic $G$-bundle on $X$ to be a holomorphic vector bundle $V$ on $X$ where the action of $G$ on $X$ lifts to $V$.  My first question is quite simply, how is this lift of the action defined?  I'm guessing if $g \cdot x = x'$ with $x,x' \in X$ and $g \in G$, then we need to give a rule which assigns a vector in the fiber over $x$ to a vector in the fiber over $x'$ in a compatible way with the action.  But this is extra data we need to provide, right?  This seems far from unique. My main question has to do with fixed points of the action.  Let $X^{g}$ be the points in $X$ which are fixed by $g \in G$ (I'm happy to let this be a point, for concreteness).  I then want to consider the following decomposition into line bundles: $$TX\big|_{X^{g}} = \oplus_{\lambda}V_{\lambda},$$ for all $\lambda \in \mathbb{Q} \cap [0,1)$ such that $\lambda$ acts on $V_{\lambda}$ by $e^{2 \pi i \lambda}$.  I'm incredibly confused by these $V_{\lambda}$.  For concreteness, assume $X^{g}$ is a point.  So we're given $X$, we're given an action of $G$ on $X$, and we have some isolated fixed point.  Do we get a summand $V_{\lambda}$ for every single rational $\lambda$ between 0 and 1, or does the existence of such, depend on the action?  Actually we clearly can only have as many summands $V_{\lambda}$ as the complex dimension of $X$.  I'm failing to see how the $\lambda$ relate to the underlying $G$-action on $X$.","['differential-geometry', 'algebraic-geometry']"
2121459,How to find the limit of a function involving two variables.,"How would I find the limit of the function $\frac{x^2-4y^2}{x+2y}$ as $(x,y) \to (2,-1)$.
So far I have considered lines approaching the point from different direction like $x=-2y$ but every time I substitute it into the function I get $0/0$. Does this mean the limit doesn't exist? 
Many thanks for your help","['multivariable-calculus', 'limits']"
2121478,Ramification indices: what does it mean geometrically that $2$ is the only ramified prime in $\Bbb{Z}[i]$?,"I am learning number theory, specifically ramification indices, and I was looking at the example of what primes in $\Bbb{Z}$ ramify in $\Bbb{Z}[i]$. Of course, the only one to do so is $2$, because it is the only prime $p$ such that $x^2+1$ can be written as $f(x)^2$ modulo $p$. From a scheme-theoretic point of view, we have a map $Spec(\Bbb{Z}[i])\to Spec(\Bbb{Z})$, and we can look at the fiber of each prime $p\in\Bbb{Z}$. From this point of view, the fiber over $2$ turns out to be $Spec(\Bbb{Z}/2[x]/(x+1)^2)$, and in this sense it is the only prime whose fiber is a single point where the ring of global functions has nilpotents (i.e. the point has ""fuzz"" around it as Vakil likes to say). I am wondering what the connection is here? What is the intuition for $2$ being the only prime which both ramifies and has ""fuzz""?","['ramification', 'algebraic-number-theory', 'algebraic-geometry']"
2121545,"Write the function $f(x) = 0, \text{if $x \leq 0$}; x, \text{if $x > 0$}$ as a single formula using the absolute value sign.","I found this exercise in Demidovich's ""Problems in Mathematical Analysis"", and found it quite interesting. Write the function
  $$
f(x) =
\begin{cases}
0, & \text{if $x \leq 0$} \\
x, & \text{if $x > 0$}
\end{cases}
$$
  as a single formula using the absolute value sign. I've posted my solution below.","['real-analysis', 'absolute-value', 'functions']"
