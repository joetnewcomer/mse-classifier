question_id,title,body,tags
3755335,Intersection of maximal subgroup with subgroup is maximal in subgroup?,"As soon as it looks obvious one way, it looks obvious the other way: if $G$ is a group, $M$ is maximal subgroup and $N$ is subgroup of G, is $M\cap N$ maximal subgroup of $N$ ? What if $N\lhd G$ ? In last case I thought: $M/(M\cap N)\cong MN/N\le G/N\;$ ...but I can't continue. Other condition: same question if we assume $N\lhd G$ is of finite index...? Then in the above we have $G/N\;$ finite group, so $\;M/N\le G/N\;$ also finite...but still stuck. Any help/direction will be thanked.",['group-theory']
3755346,Convergence of a sequence of measures.,"On a measure space $(E,\mathcal{E},\mu)$ , let $(\mathcal{F}_n)$ a filtration on $\mathcal{E}$ , with $\mathcal{F}_n \uparrow \mathcal{E}$ , and let $(\mu_n)$ be a sequence of finite measures defined on $\mathcal{E}$ such that $$ \mu_n(A) = \mu(A) \qquad \text{for all $A \in \mathcal{F}_n$}. $$ Is it true that the sequence $(\mu_n)$ converges towards $\mu$ ? Which kind of convergence is expected? Is $(\mu_n)$ a Cauchy sequence?","['measure-theory', 'convergence-divergence', 'cauchy-sequences']"
3755351,"Double integral on a 2D rotated area : $\iint_D (x+y)^3 (x-y)^2 \,\mathrm{d}x\,\mathrm{d}y$","I was assigned an exercise in which I have to calculate a double integral of a given function, in an area which is made from four lines. $D$ is defined by the relations: $x+y=1$ , $x-y=1$ , $x+y=3$ , $x-y=-1$ . The integral is $$\iint\limits_D (x+y)^3 \cdot (x-y)^2 \,\mathrm{d}x\,\mathrm{d}y$$ I came to the conclusion that the lines form a rotated square, with edges the points $A(0,1)$ $B(1,2)$ $C(2,1)$ $D(1,0)$ . I guess my last step is to calculate the double integral in that area. My problem is, can I split the rotated square in 2 isosceles' triangles with points $ABC$ , $ADC$ and sum those double integrals together, for more ease? If so, do I have to mention a theorem of some sort that I can't remember?
Is there another way to calculate the double integral on that area? Thanks in advance for your help!","['integration', 'multivariable-calculus', 'multiple-integral', 'definite-integrals']"
3755355,Every group of order 4 is isomorphic to $\mathbb{Z}_{4}$ or the Klein group,"I wanted to prove that every group or order $4$ is isomorphic to $\mathbb{Z}_{4}$ or to the Klein group. I also wanted to prove that every group of order $6$ is isomorphic to $\mathbb{Z}_{6}$ or $S_{3}$ . For the first one I tried to prove that $H$ (a random group of order 4) is cyclic or the Klein group, because if $H$ is cyclic I can prove that a cyclic group of order $n$ is isomorphic to $\mathbb{Z}_{n}$ . Because $H$ has order $4$ it's only possible for elements in $H$ to have order $1$ , $2$ , $4$ (Lagrange). Say that $H$ is not cyclic. Then all the elements need to have order $1$ or $2$ . Not all the elements can have order $1$ so there must be one element of order $2$ . Say that $b$ is an element with order $2$ . Then take $c$ an element not the unit element or $b$ . Then $H=\{e, b, c, bc \}$ , so $c$ must have order $2$ because otherwise $H$ would have an order bigger than $4$ . This is the Klein group. I wanted to do the second one analogously but I can't make a proper proof out of it. Can someone help and correct me? (I'm so sorry for my English mistakes but I'm really trying.)",['group-theory']
3755362,Prove that $(\bigcup\mathcal F)\setminus(\bigcup\mathcal G)\subseteq\bigcup(\mathcal F\setminus\mathcal G).$,"Not a duplicate of Suppose $F$ and $G$ are families of sets. Prove that $(\bigcup F) \setminus (\bigcup G) \subseteq \bigcup (F \setminus G)$. This is exercise $3.4.20.a$ from the book How to Prove it by Velleman $($$2^{nd}$ edition $)$ : Suppose $\mathcal F$ and $\mathcal G$ are families of sets. Prove that $(\bigcup\mathcal F)\setminus(\bigcup\mathcal G)\subseteq\bigcup(\mathcal F\setminus\mathcal G).$ Here is my proof: Let $x$ be an arbitrary element of $(\bigcup\mathcal F)\setminus(\bigcup\mathcal G)$ . This means $x\in\bigcup\mathcal F$ and $x\notin\bigcup\mathcal G$ . Since $x\in\bigcup\mathcal F$ , we can choose some $A_0$ such that $A_0\in \mathcal F$ and $x\in A_0$ . $x\notin\bigcup\mathcal G$ is equivalent to $\forall B(B\in\mathcal G\rightarrow x\notin B)$ and in particular $A_0\in\mathcal G\rightarrow x\notin A_0$ . From $A_0\in\mathcal G\rightarrow x\notin A_0$ and $x\in A_0$ , $A_0\notin\mathcal G$ . From $A_0\in\mathcal F$ and $A_0\notin\mathcal G$ , $A_0\in\mathcal F\setminus\mathcal G$ . From $A_0\in\mathcal F\setminus\mathcal G$ and $x\in A_0$ , $x\in\bigcup(\mathcal F\setminus\mathcal G)$ . Therefore if $x\in(\bigcup\mathcal F)\setminus(\bigcup\mathcal G)$ then $x\in\bigcup(\mathcal F\setminus\mathcal G)$ . Since $x$ is arbitrary, $\forall x\Bigr(x\in(\bigcup\mathcal F)\setminus(\bigcup\mathcal G)\rightarrow x\in\bigcup(\mathcal F\setminus\mathcal G)\Bigr)$ and so $(\bigcup\mathcal F)\setminus(\bigcup\mathcal G)\subseteq\bigcup(\mathcal F\setminus\mathcal G)$ . $Q.E.D.$ Is my proof valid $?$ Thanks for your attention.","['elementary-set-theory', 'proof-writing', 'solution-verification']"
3755392,"Proving $f(x) = x + \frac{x^2}{2} + \frac{x^3}{3} + \frac{x^4}{4} + ... $ is continuous for a fixed $x_0 \in (-1,1)$ by using the Weierstrass M-test","I am trying to prove that $f(x) = x + \frac{x^2}{2} + \frac{x^3}{3} + \frac{x^4}{4} + ...$ is continuous for a fixed $x_0 \in (-1,1)$ by using the Weierstrass M-test. Now, the solution in the book is not what I expected, and not even close to what I had in my own mind. So, can some one verify if I am totally of with my approach to solve this Here was my suggestion: Let $M_n = x^n$ , then for each $f_n(x) = \frac{x^n}{n}$ we have that $f_n(x) \leq M_n$ . We know that $\sum_{n=1}^{\infty} M_n$ converges since it is a geometric series, hence $\sum_{n=1}^{\infty} f_n(x)$ converges uniformly by Weierstrass M-test, and by the Continuous Limit Theorem f(x) is continuous at $x_0$ . I guess there is a mistake here somewhere...could anybody point it out for me?","['proof-writing', 'continuity', 'functions', 'solution-verification', 'power-series']"
3755413,"Find the area of the region bounded by $\sin(x)\sin(y)=k$ where $0 \leq x \leq \pi$, $0 \leq y \leq \pi$, and $0 \leq k \leq 1$","On the coordinate plane, the equation $\sin(x)\sin(y)=k$ where $0 \leq x \leq \pi$ , $0 \leq y \leq \pi$ , and $0 \leq k \leq 1$ forms a closed region. Find the area of this region in terms of $k$ . I've had some progress, but I've hit a dead end with an integral that appears to not be solvable. Solving in terms of $x$ , you get that $y=\arcsin(\dfrac{k}{\sin(x)})$ . When you integrate from the bounds given by the minimum and maximum $x$ of this region, you get $\int_{\arcsin(k)}^{\pi-\arcsin(k)} \arcsin(\dfrac{k}{\sin(x)}) dx$ . Thus, considering the fact that this integral gives the region below the closed region, the expression for the closed region is $$\pi(\pi-2\arcsin(k))-2\int_{\arcsin(k)}^{\pi-\arcsin(k)} \arcsin\left(\dfrac{k}{\sin(x)}\right).$$ However, I need help with the integral as WolframAlpha cannot evaluate it. Help would be appreciated (or perhaps even a better solution than this!) Thanks","['integration', 'area', 'alternative-proof', 'calculus', 'trigonometry']"
3755431,What does $\frac{1}{1+\frac{2}{2+\frac{3}{{\vdots}}}}$ evaluate to? [duplicate],"This question already has answers here : Continued Fraction: Please prove $\frac{1}{e \gamma (x+1,1)}=x+\frac{1}{x+1+\frac{2}{x+2+\frac{3}{x+3+\frac{4}{\dots}}}}$ (1 answer) Continued fraction for $\frac{1}{e-2}$ (2 answers) Closed 3 years ago . I was curious what does $$\cfrac{1}{1+\cfrac{2}{2+\cfrac{3}{3+\cfrac{4}{\vdots}}}}$$ evaluate to. Empirically, I observed that it equals approximately $0.5819767$ , and a calculator found that this value agrees with $\frac{1}{e-1}$ to at least 8 places. Is $\frac{1}{e-1}$ the exact value of this continued fraction? If this is true, is this result new? And how could the equivalence be proved?","['eulers-number-e', 'continued-fractions', 'real-analysis']"
3755433,eigenvectors of an eigenvector matrix,"Suppose I have a square matrix $A\in \mathbb{R}^{d\times d}$ , with eigenvectors $v_1,v_2,\ldots,v_n$ . Suppose I construct a new matrix $V = [v_1\ v_2\ \cdots\ v_n]$ . Can anything be said about the eigenvalues or eigenvectors of this new matrix $V$ . Do, $A$ and $V$ have same eigenvalues? PS: I've not assumed A to be symmetric and $d$ can be greater than $n$ . But if it helps derive something, please feel free to assume so or any other assumptions required. PPS: I know that if $V$ is full rank, it diagonalizes $A$ . I'm just wondering if there is any other relation. Edit 1 : Adding some special cases, that can be considered $A$ is real-symmetric, so that $v_1, v_2, \ldots$ are orthogonal and $d=n$ . $A$ is normal (above holds).","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
3755437,"If a 'distance function' does not possess triangle inequality property, would the limit of a converging sequence still be unique?","Let $X$ be a set and $d$ be a function such that $d:X\times X\to \mathbb{R}$ such that it satisfies positivity, that is, $d(x,y)\geq 0$ and $d(x,y)=0 \iff x=y.$ Moreover suppose it satisfies symmetry property, that is, $d(x,y)=d(y,x).$ However it does not satisfy triangle inequality. Obviously if triangle inequality was to be satisfied then this will make $(X,d)$ a metric space and subsequently every converging sequence will have a unique limit. Hence I am just curious if this property is taken away, can there still be examples such that every converging sequence has a unique limit with respect to this function $d$ ? I hope I explained my question sufficiently clear, many thanks in advance!","['metric-spaces', 'analysis', 'real-analysis', 'sequences-and-series', 'limits']"
3755439,A linear algebra problem regarding $AB-BA=A$,"Let $A$ be a $n \times n$ complex matrix. Show (1) is equivalent to (2) (1) There exists $B$ such that $AB-BA = A$ (2) $A^n=0$ Furthermore, prove $B^n\neq 0$ in (1) if $A \neq 0$ . Attmept for (1) $\implies$ (2) $A^2 = A^2B - ABA = ABA-BA^2$ . Therefore $A^2 = \frac12 (A^2B - BA^2)$ . Inductively $A^n = \frac 1 n (A^nB- BA^n)$ . Take submultiplicative norms, we obtain $\| A^n \|\leq \frac 2n \|A^n \| \|B\| $ . But here I don't know how to preceed.","['matrices', 'matrix-equations', 'linear-algebra']"
3755475,Can An irreducible Markov chain with infinitely many states be a positive recurrent chain or periodic chain?,"I understand that any irreducible finite Markov chain is necessarily positive recurrent, however can this be the case for a Markov chain with infinitely many states? Similarly for periodicity? There also seems to be a link between the 2, either both statements are true or false.","['stochastic-processes', 'markov-chains', 'probability-theory', 'probability']"
3755483,Calculate the determinant of $n^\text{th}$ order,"Calculate the determinant of $n^\text{th}$ order: $$
\begin{vmatrix}
1 + a_1  & 1 + a_1^2 & \dots & 1 + a_1^n \\ 
1 + a_2  & 1 + a_2^2 & \dots & 1 + a_2^n \\  
\vdots  & \vdots   & \ddots & \vdots \\ 
1 + a_n  & 1 + a_n^2 & \dots & 1 + a_n^n \\ 
\end{vmatrix}
$$ So whenever any two of the variables are equal the determinant becomes $0$ . Therefore, it has $$\prod_{1 \le k < i \le n} (a_i - a_k)$$ as a factor. But I haven't been able to find the rest of the factors. Any help is appreciated.","['matrices', 'determinant', 'linear-algebra']"
3755509,Inverse of block anti-diagonal matrix,"Let $A \in \mathbb R^{n\times n}$ be an invertible block anti-diagonal matrix (with $d$ blocks), i.e. $$
A = \begin{pmatrix} & & & A_1 \\ & & A_2 & \\ & \cdot^{\textstyle \cdot^{\textstyle \cdot}} &  & \\ A_d\end{pmatrix},
$$ with all square blocks $A_1, \ldots, A_d$ invertible. Is there a formula for its inverse? In the diagonal case, it is just the diagonal block matrix with the inverses of the blocks, is there an equivalent for the anti-diagonal case?","['matrices', 'linear-algebra', 'inverse', 'block-matrices']"
3755516,"Is this space subspace of $[0,1]^{\mathbb{N}}$ Polish?","Let $D := \{ x \in [0, 1]^{\mathbb{N}} \mid \forall n: x_n = 1 \Rightarrow x_{n+1} = 1 \}$ be the set of sequences in $[0, 1]$ such that if $x_n = 1$ for some $n$ then $x_{n+m} = 1$ for all $m \geq 0$ . I know that $[0, 1]^{\mathbb{N}}$ is Polish. Is $D$ with the subspace topology also Polish? I can represent $D$ as a countable union of pairwise disjoint closed sets $D = (\{ 1 \} \times \{ 1 \} \times \dots) \cup ([0, 1) \times \{ 1 \} \times \{ 1 \} \times \dots) \cup ([0, 1) \times [0, 1) \times \{ 1 \} \times \{ 1 \} \dots) \cup \dots \cup ([0, 1) \times [0, 1) \times \dots)$ but there is no theorem stating that such subsets are necessarily Polish. I can also represent $D$ as a countable intersection as follows: translate the condition $x_n = 1 \Rightarrow x_{n+1} = 1$ into the set $A = ([0, 1) \times [0, 1]) \cup (\{ 1 \} \times \{ 1 \})$ . Then $D = (A \times [0, 1] \times [0, 1] \times \dots) \cap ([0, 1] \times A \times [0,1] \times [0,1] \times \dots) \cap ([0,1] \times [0,1] \times A \times [0,1] \times [0,1] \times \dots) \cap \dots$ . To show that $D$ is Polish it is enough to prove that $A$ is Polish. (Then the sets $A \times [0,1] \times \dots$ and so on are all Polish (as countable products of Polish spaces are Polish) and therefore their countable intersection $D$ is Polish.) $A$ with the Euclidean metric is not complete. Is it possible to construct a compatible complete metric on $A$ ?","['measure-theory', 'descriptive-set-theory']"
3755530,Is the commutator subgroup of a subgroup the same as the commutator subgroup of the group intersected with that subgroup?,"I might be overthinking this, but anyway: Let $G$ be a group and $H$ a subgroup. Let $K'$ be the commutator subgroup of $H$ , i.e. $K' = \langle [x, y] \mid x, y, \in H \rangle$ . Is it true that $K' = G' \cap H$ ? Attempt: I believe that $K' \subset G' \cap H$ , because if $k \in K'$ then $k$ is a product of commutators in $K$ , so $k \in G'$ . By closure, $k$ is in $H$ , so $k \in G' \cap H$ . I'm uncertain about the $\supset$ direction.",['group-theory']
3755556,A coin is thrown until two heads and two tails appears. What is the cumulative distribution function of this situation?,"A coin is thrown until two heads and two tails appears. Let $Y$ be the number of throws until this happens. What is the cumulative distribution function of $Y$ ? What I have gotten so far: The last throw can end up being either head or tail. Let's look at this situations separately. Last throw is tail: $$\sum^n_{k=2}P(Y=k)k=0,5^k\cdot k(k-1), \qquad n\ge4.$$ This happens to also be the probability mass function when the last throw is head. Now summing up the two cases, we get $$0,5^k\cdot k(k-1)+0,5^k\cdot k(k-1)=2k(k-1)\cdot0,5^k$$ which is the probability mass function of the situation. Does this seem correct?","['integration', 'cumulative-distribution-functions', 'probability']"
3755592,Almost sure limit of geometric type sum,"Let $S_n$ be a random walk defined as $S_n = X_1 + \dots + X_n $ ( $S_0 = 0$ ), where $X_i$ are i.i.d. with $P(X_i = 0) = P(X_i=1) = 1/2$ . Let $r \in (0,1)$ . My question is: what is the almost sure limit of $$ \sum_{k=0}^{n} r^{S_n - S_k}.$$ When considering $\sum_{k=0}^{n} r^{S_k}$ , we should have that it converges to $\sum_{k=0}^{\infty} r^{S_k}$ a.s., but what about the case above?","['stochastic-processes', 'probability-theory', 'random-walk']"
3755593,IMO $2001$ problem $2$,"Let $a,b,c \in \mathbb{R}_+^*$ . Prove that $$\frac{a}{\sqrt{a^2+8bc}} + \frac{b}{\sqrt{b^2+8ca}}+ \frac{c}{\sqrt{c^2+8ab}} \geqslant 1.$$ I tried to follow the proposed solution for this which depended on Hölder's inequality, but I'm a bit confused about how they came up with the expression. How I remember Hölder's is that it states that $$\sum_{i=1}^n |x_iy_i| \leqslant (\sum_{i=1}^n|x_i|^p)^{1/p}(\sum_{i=1}^n|y_i|^q)^{1/q}$$ and we need the same Conjugate property as in Young's inequality $\frac{1}{p} + \frac{1}{q} =1.$ What they had was $$(\sum \frac{a}{\sqrt{a^2+8bc}})(\sum \frac{a}{\sqrt{a^2+8bc}})(\sum a(a^2+8bc)) \geqslant (a+b+c)^3.$$ From here it was quite straightforward, but any clarification on how we can get this result from Hölder's would be appreciated.","['contest-math', 'inequality', 'proof-explanation', 'algebra-precalculus', 'holder-inequality']"
3755602,Counterexample to finiteness of KL divergence?,"Suppose $P,Q$ are two probability distributions on a measurable space $(X, \mathcal F)$ . The KL-divergence between $P$ and $Q$ is defined as \begin{equation}
D_{KL}[P||Q] = \int_X \log \frac {dP}{dQ}dP 
\end{equation} when $P$ is absolutely continuous wrt $Q$ , and $ + \infty$ otherwise. So we know that $P$ not absolutely continuous wrt $Q$ yields $D_{KL}[P\|Q]=+\infty$ . My question is whether the converse holds: are there distributions with $P \ll Q$ (absolutely continuous) and $D_{KL}[P\|Q]=+\infty$ ?","['measure-theory', 'probability-distributions', 'examples-counterexamples', 'information-geometry', 'absolute-continuity']"
3755603,a product of distances inequality of circumscribed polygon,"I learned the following theorem from Roger Johnson's book Advanced Euclidean Geometry §101g: Theorem:  If a polygon is inscribed in a circle, and A is a point of
the circle, the product of the distances from A to the sides of the
polygon, equals the product of the distances from A to the tangents of
the circle at the vertices of the polygon. Is the following true: If the point A is inside the circle, the first product is always less than the second product, regardless of the convexity of the polygon. The inequality also holds for concave polygons (Coloring is produced by Geometer's Sketchpad: colour the point $A$ with purple if the first product is less than the second product)","['euclidean-geometry', 'geometric-inequalities', 'geometry', 'plane-geometry']"
3755638,A locus problem related to circumcenters and conic sections [duplicate],"This question already has an answer here : Show that the locus of a point in this geometric construction is a conic (1 answer) Closed 8 months ago . Given a point $A$ , a circle $O$ and conic section $e$ , if $BC$ is a moving chord of the circle $O$ tangent to $e$ , then prove that the locus of △ $ABC$ 's circumcenters $T$ is a conic section. The question was posted in 纯几何吧 by TelvCohl and remained unsolved for many years but regrettably I cannot provide the link because the post was deleted by Baidu accidentally. It seems that the locus related to circumcenter is often a conic section.Another example: The directions of two sides of a triangle is fixed and the third side passes through a fixed point, then the locus of the circumcenter is a conic section.( The elementary geometry of conics .1883)","['projective-geometry', 'locus', 'conic-sections', 'geometry', 'plane-geometry']"
3755709,How do you prove that the derivative $\tan^{-1}(x)$ is equal to $\frac{1}{1+x^2}$ geometrically,How do you prove that the derivative of $\tan^{-1}(x)$ is equal to $\frac{1}{1+x^2}$ geometrically? I figured it out by working it out using implicit differentiation. I also found how to plot a semi-circle using $\cos^2(x)+\sin^2(x)=1$ and found that $((x^2-1))^{0.5}$ plots a semi-circle because if you wanted to find $\sin(x)$ with $\cos(x)$ you would do $(\cos(x)^2-1)^{0.5}$ . The reason only a semi circle is in order for it to work it must be both the positive and negative solutions. I saw that $1$ and the $x^2$ and thought you could visually see that the derivative of $\tan^{-1}(x)$ is $\frac{1}{1+x^2}$ but I couldn't find any way so far.,"['alternative-proof', 'calculus', 'geometry']"
3755727,Does the staircase paradox apply to areas or volume?,"So there is the “ staircase paradox ” that is sometimes used to “show” that $\pi = 4$ (in the case of approximating a circle), or that $\sqrt{2} = 2$ (in the case of approximating the hypotenuse of a triangle). But when we define things like the integral, don’t we also speak of approximating something, in a similar fashion to approaching the hypotenuse of a triangle by staircases from above and below? For example, for the Riemann integral, we speak of approaching the area by looking at the supremum of the lower sums and the infimum of the upper sums; if these two numbers agree, then we say it is integrable. So why do we seem to not “run into such problems” when considering area/volume (or at least, the problems we run into are not quite the same), whereas we have problems when we (naively) consider lengths? Is it a matter of defining the area/volume as the limit (but this doesn’t seem satisfactory, because after all isn't a big purpose to model phenomena and solve problems, and avoid paradoxes that conflict with basic geometry)? Does it perhaps have to do with measure or dimension, e.g. approaching a line segment by line segments is sort of like approaching a 1-dimensional object by another 1-dimensional object, allowing some “space for things to go wrong”? (And, in general, approaching an $n$ -dimensional object by $n$ -dimensional ones?) My basic question is that, a priori, there might not appear much of a reason (not that I’m saying we need one) to confidently/fully believe that our definitions and axioms of area/volume do not run into such paradoxes or do not conflict with some basic geometric properties that we seek to have. So how do we work around this and ensure that our definitions and considerations are consistent and good and all that (whatever that means)?","['calculus', 'geometry', 'real-analysis']"
3755744,"Expected number of children question from ""Introduction to Probability""","This question appeared on Introduction to Probability (by Joe Blitzstein and Jessica Hwang) A couple decides to keep having children until they have at least one
boy and at least one girl, and then stop. Assume they never have
twins, that the “trials” are independent with probability $1/2$ of a
boy, and that they are fertile enough to keep producing children
indefinitely. What is the expected number of children? So the answer and explanation provided in the book are as followed: Let X be the number of children needed, starting with the 2nd child,
to obtain one whose gender is not the same as that of the firstborn.
Then $X - 1$ is $Geom(1/2)$ , so $E(X) = 2$ . This does not include the
firstborn, so the expected total number of children is $E(X + 1) = E(X) + 1 = 3$ I have two question regarding this: Is my approach for the question also correct? Or it shouldn't be that way? Let X be the number of children needed, including the firstborn. Therefore $X - 1 \sim Geom(1/2)$ , but there are two possibility (i.e. first child is a boy, first child is a girl) As a result, $E(X - 1) = 2$ (not sure how to explain this but by Geom(1/2) the expected value should be 1, while there are 2 possibilities so it becomes 2) Geom(p) didn't include the ""success"" case, so we compute it back -> $E(X) = 2+1 = 3$ Is the reason for the question setting X to be ""starting from second child"" to prevent getting 2 possibilities (like I did) and condition on whatever the first child's gender is. Or if anyway can explain the logic behind the formal answer as I am not really sure how the story goes. Thanks a lot! EDIT: suddenly one more approach here (Linearity of expectation), is it also valid? Expectation of having the first child = 1 (regardless of boy/girl) Expectation of having a child of a specific gender = 2 (we need a specific gender that is the opposite sex of the first child) By linearity = 1+2 = 3","['expected-value', 'probability-distributions', 'probability']"
3755778,Does this arrangement of polygons necessarily contain a hole?,"Consider an arrangement of finitely-many open polygons in the plane (not necessarily convex) such that each polygon intersects at least two other non-intersecting polygons. Is there always a sub-arrangement such that the union of all polygons in the sub-arrangement contains a hole? In the illustration below, the blue arrangement on the left satisfies the requirements and indeed it contains a hole; the brown arrangement on the right does not satisfy the requirements (each polygon intersects two other polygons, but these other polygons intersect), and it does not contain a hole.","['geometry', 'polygons']"
3755804,Interested in a closed form for this recursive sequence.,"Consider the following game: you start with $ n $ coins.  You flip all of your coins.  Any coins that come up heads you ""remove"" from the game, while any coins that come up tails you keep in the game.  You continue this process until you have removed all coins from the game.  Let your score $ s $ be defined as the number of rounds of flipping before the game was over (including the last flip, say). Let $ a_n $ be the expected value of the score when you start with $ n $ coins.  It is not hard to see that $$
a_n = \frac{1}{2^n - 1} \left(1 + \sum_{m=0}^{n-1}{{n\choose m} (a_m + 1)}\right)
$$ Are there any generating functionology wizards out there who know if this could be turned into a closed-form formula for $ a_n $ ? Note, this question was asked here: You are flipping n fair coins, putting aside those that come up heads after each flip. What's the expected number of rounds? , but the answer is entirely unsatisfactory; they only provide a heuristic which is asymptotically correct. Edit: here is a quick mathematica experiment: Edit 2: While investigating the first differences of this function, we find a lovely pattern.  I plotted the following function $$
g(n) := n \left( \frac{1}{\log(2)} - n (a_{n+1} - a_{n}) \right)
$$ resulting in the following plot, clearly oscillating about $ 1/\log(2) $ : (Here, ""dev[n]"" is the first-difference function $ a_{n+1} - a_n $ .)","['probability', 'generating-functions']"
3755807,Minimizing the total distance between points,"Let $P_0, P_1, P_2$ be the vertices of a given triangle. I'm interested in finding $K$ points $P_3, P_4, .... P_{K+2}$ that lie inside the triangle and minimize the total distance given by the expression $\sum_{i=3}^{K+2} \sum_{j=0, j \neq i}^{K+2} (P_i - P_j)^2 $ . This is basically the sum of distances of points $P_3, P_4, .... P_{K+2}$ to all the other points. When $K = 3$ , the solution is the barycenter of the triangle. I'm interested in finding the solution using an analytical approach when $K > 3$ . EDIT :
Distance should be $D = \sum_i min_{i\neq j}|| P_i - P_j||^2 $ . The objective is to ""maximally spread"" the points inside the triangle as pointed out in the first answer. For that $D$ has to be maximized.","['optimization', 'triangles', 'maxima-minima', 'geometry']"
3755826,Prove that if $\bigcup\mathcal F\nsubseteq\bigcup\mathcal G$ then $\exists A\in\mathcal F\forall B\in\mathcal G(A \nsubseteq B)$.,"This is exercise $3.4.21$ from the book How to Prove it by Velleman $($$2^{nd}$ edition $)$ : Suppose $\mathcal F$ and $\mathcal G$ are families of sets. Prove that if $\bigcup\mathcal F\nsubseteq\bigcup\mathcal G$ , then there is some $A\in\mathcal F$ such that for all $B\in\mathcal G$ , $A\nsubseteq B$ . The author gives a proof by contradiction but I attempted to give a direct proof as follows: Suppose $\bigcup\mathcal F\nsubseteq\bigcup\mathcal G$ . So we can choose some $x_0$ such that $x_0\in \bigcup\mathcal F$ and $x_0\notin\bigcup\mathcal G$ . Since $x_0\in\bigcup\mathcal F$ , we can choose some $A_0$ such that $A_0\in\mathcal F$ and $x_0\in A_0$ . Let $B$ be an arbitrary element of $\mathcal G$ . From $x_0\notin\bigcup\mathcal G$ and $B\in\mathcal G$ , $x_0\notin B$ . Since $x_0\in A$ but $x_0\notin B$ , $A\nsubseteq B$ . Since $B$ is arbitrary, $\forall B\in\mathcal G(A\nsubseteq B)$ . From $A_0\in\mathcal F$ and $\forall B\in\mathcal G(A\nsubseteq B)$ , $\exists A\in\mathcal F\forall B\in\mathcal G(A\nsubseteq B)$ . Therefore if $\bigcup\mathcal F\nsubseteq\bigcup\mathcal G$ then $\exists A\in\mathcal F\forall B\in\mathcal G(A\nsubseteq B)$ . $Q.E.D.$ Is my proof valid $?$ Also please help me to correct the title of my question $($ I did everything I could $)$ . Thanks for your attention.","['elementary-set-theory', 'proof-writing', 'solution-verification']"
3755838,Show that $(\sum a_{n}^{3} \sin n)$ converges given $\sum{a_n}$ converges,"Given that $\sum a_{n}$ converges $\left(a_{n}>0\right) ;$ Then $(\sum a_{n}^{3} \sin n)$ is My approach: Since, $\sum a_{n}$ converges, we have $\lim _{n \rightarrow \infty} n \cdot a_{n}$ converges. i.e. $\left|n \cdot a_{n}\right| \leq 1$ for $n \geq K(\text { say })$ $\Rightarrow n \cdot a_{n}<1 \quad\left[\because a_{n}>0\right]$ $\Rightarrow a_{n}<\frac{1}{n}$ $\therefore a_{n}^{3}<\frac{1}{n^{3}}$ $\Rightarrow a_{n}^{3} \sin n \leq \frac{1}{n^{3}} \sin n \leq \frac{1}{n^{3}}$ $\Rightarrow \sum a_{n}^{3} \sin n \leq \sum \frac{1}{n^{3}}$ $\because \mathrm{RHS}$ converges so LHS will also converge. Any other better approach will be highly appreciated and correct me If I am wrong","['convergence-divergence', 'solution-verification', 'sequences-and-series', 'real-analysis']"
3755846,Understanding one step in the Neyman-Pearson lemma proof,"In Georgii's book they state: Given $(\chi,\mathcal{F},P_0,P_1)$ with simple hypothesis and alternative and $0<\alpha<1\ $ a given significance level. Then: $(a)$ There exists a Neyman-Pearson-test $\phi$ with $E_0(\phi)=\alpha$ . They begin the proof like this: Let $c$ be any $\alpha$ -fractil ( $1-\alpha$ quantil) of $P_0\circ R^{-1}$ where $R$ is the likelihood-quotient. By definition we have: $$P_0(R>c)\leq \alpha \quad P_0(R\geq c)\geq \alpha$$ Exactly this is the part I don't get. How come we have $P_0(R\geq c)\geq \alpha$ ? $P_0(R>c)\leq \alpha$ is exactly by definition of the $1-\alpha$ -quantil but how come taking one more point into consideration we have that it becomes greater than $\alpha$ . Could anyone explain to me how that is derived?","['statistics', 'hypothesis-testing']"
3755850,Why is the twin prime conjecture hard?,"If $\pi_2(x)$ is the number of twin primes of magnitude less than or equal to $x$ . We want to prove that $$\lim_{x\,\to\,\infty}\pi_2(x)=\infty$$ which should be easier than finding and proving an asymptotic formula like $x/\log(x)$ for $\pi(x)$ . How is it that modern mathematics cannot prove even the awful estimate $$\pi_2(x)\ge \log\log\,...\log x\quad\quad x\text{ big enough}$$ with $100$ or $1000$ nested $\log$ s? Any function with unbounded growth (no matter how slow) does the trick. It seems so weird that no argument, sieve-theoretic nor analytic or algebraic, can prove such a ""simple result"". I am asking for a concrete obstacle in a would-be proof of this type. Thanks!","['number-theory', 'twin-primes', 'prime-numbers', 'upper-lower-bounds']"
3755851,Variance of a sample median,"Suppose $X_1,\ldots,X_n\sim\text{i.i.d.}\operatorname N(\mu,\sigma^2).$ I think I've only ever seen one way to prove that the sample mean of $X_1,\ldots,X_n$ has a smaller variance than does the sample median, and it uses some moderately hefty results and doesn't say what the variance of the sample median is. Specifically, two theorems are used: The Lehmann–Scheffé theorem from the theory of estimation, and the one-to-one-ness of the two-sided Laplace transform: $$
\left( \mathcal L g\right)(\theta) = \int_{-\infty}^{+\infty} g(x) e^{\theta x} \, dx. \\[16pt]
\text{If } \mathcal L g = \mathcal L h \text{ then } g=h \text{ a.e.}
$$ Is there an elementary and efficient way to show that the sample median has a larger variance than the sample mean? And (here's the question on a specific definite integral, justifying one of the tags) is there a closed form for the variance of the sample median? (Here someone could possibly object that this whole thing is trivially reducible to the case where $\mu=0$ and $\sigma=1.$ The two theorems mentioned above both have hypotheses saying either than something doesn't change as $(\mu,\sigma^2)$ changes or that something is true of all values of $(\mu,\sigma^2).$ So I suppose you could construe this question like this: Supposing the hypothesis $\mu=0,\sigma=1$ is assumed, since there is clearly no loss of generality. How do you prove the result then? Is this a case where it is better to forgo a simplifying assumption that discards no generality?)","['statistics', 'definite-integrals', 'parameter-estimation', 'median']"
3755879,On Logarithmic Derivative transformation,"I am curious about a certain transformation called the logarithmic derivative that seems to appear a lot in different cool ideas, for example: The use in generating functions for recursions of the form $a_{n+1}=\sum _{k=0}^n\binom{n}{k}a_kb_{n-k}$ gives the functional equation $A'=AB$ implying that $B=(\log A)'.$ Cumulants are defined as the coefficients of the logarithm of the Moment generating function, so the generating function is $K(x)=\log(\mathbb{E}[e^{tX}]),$ and so $K'(x)=\mu +\sigma ^2x+O(x^2)$ giving, for example, the mean when evaluated at $x=0.$ The method of singular part transformation , when you use $u = (\log x)'$ as a change of variable (Present, for example, in the work of Painleve that gives raise to the Painleve equations). The digamma function is defined as $\psi(z)=(\log \Gamma(z))'$ and for example, evaluated at $z=1$ gives the euler-mascheroni constant $\gamma .$ The relation in between the zeta and sigma Weierstrass functions in number theory is given by this transformation i.e., $\zeta (z,\Lambda) =(\log \sigma(z,\Lambda))'.$ In the multiplicative calculus , the derivative is defined as $$f^*(x)=\lim _{h\rightarrow  \infty}\left (\frac{f(x+h)}{f(x)}\right )^{1/h},$$ it turns out that if $f$ is positive and differentiable at $f$ one has the relation $$\ln (f^*(x))=\left (\ln f\right )'.$$ reference The Maurer-Cartan form on matrix lie groups look like $\omega _g=g^{-1}dg$ as established here In the proof of a condition for the $\mu -$ equidistribution of a sequence in the space of conjugacy classes of a compact group G, with $\mu$ the Haar measure, by some properties of the L-functions $L(s,\rho).$ Discussed, for example, here . To pass from Witt components to ghost components in the theory of Witt vectors. i.e., $$\left (\log \left (\prod _{n=1}^{\infty}(1-x_nt^n)\right )\right )'=\sum _{n=1}^{\infty}w_n(x)t^n.$$ This is done, for example, here. In the proof of the Gauss-Lucas theorem that says that the roots of $p'$ are in the convex hull of the roots of $p$ where $p$ is a polynomial. The analysis is done thru $p'/p.$ See e.g., here. The argument principle theorem relates the integral of the logarithmic derivative of a function with the difference in between the poles and the zeros. I kind of get that this transformation eliminates simple singularities and changes roots to poles and viceversa but I would like to know other parts of math where this is useful or if there is a more general idea of why this transformation is so powerful.","['generating-functions', 'special-functions', 'ordinary-differential-equations', 'reference-request']"
3755888,solution to a general integral $\int_0^\infty \frac{\cos(tx)}{x^2+k^2}e^{-sx}dx$,"I would like to find a general solution to the integral: $$I(s,t,k)=\int_0^\infty \frac{\cos(tx)}{x^2+k^2}e^{-sx}dx$$ so far using the substitution $u=\frac xk$ I have managed to reduce this to: $$I(s,t,k)=\frac 1k\int_0^\infty\frac{\cos(tku)}{u^2+1}e^{-sku}du$$ and then by defining $\alpha=tk,\beta=sk$ we can come up with a simpler integral: $$J(\alpha,\beta)=\int_0^\infty\frac{\cos(\alpha u)}{u^2+1}e^{-\beta u}du$$ We can calculate that: $$J_{\beta\beta}=\int_0^\infty\frac{u^2\cos(\alpha u)}{u^2+1}e^{-\beta u}du$$ $$=\int_0^\infty\cos(\alpha u)e^{-\beta u}du-J$$ $$=\frac{\beta}{\beta^2+\alpha^2}-J$$ $$J_{\alpha\alpha}=-J_{\beta\beta}$$ We now know that: $\nabla^2J=0$ Now to form a system of equations I found that: $$J(0,0)=\frac \pi2$$ $$J(\alpha,0)=\frac{\pi}{2}e^{-\alpha}$$ However I am struggling to find a solution to $J(0,\beta)$ although I know that it satisfies the equation: $$K''(\beta)+K(\beta)=\frac 1\beta,K(0)=\frac \pi2$$ It seems clear to me that $\lim_{\beta\to\infty}J(\alpha,\beta)=0$ so if I could solve for $K$ I should have everything I need to try and solve this problem. I think its obvious but I should add that: $$I(s,t,k)=\frac 1kJ(tk,sk)$$ Basically, could anyone help me find $J(0,\beta)$ or proceed with solving the pde I stated. Thanks! EDIT wolfram alpha gives: $$J(0,\beta)=\operatorname{Ci}(b)\sin(b)+\frac{\pi-2\operatorname{Si}(b)}{2}\cos(b)$$","['integration', 'definite-integrals', 'ordinary-differential-equations', 'partial-differential-equations', 'leibniz-integral-rule']"
3755922,"""Pedantic"" derivation of geodesic equation using pullback bundles","I'm trying to get more comfortable with manipulations involving connections and vector fields so I've tried to derive the geodesic equations without having to resort to any familiarities using standard calculus, everything computed ""properly"" from the definitions. For a Reimannian manifold $(M,g)$ I have a curve $\gamma : \mathbb{R} \rightarrow M$ which in local coordinates can be written as $\gamma(t) = \left(x^1(t), \ldots, x^n(t)\right)$ . If I wish $\gamma(t)$ to be a geodesic then I want its tangent vector to be auto-parallel. The tangent vector is given by the pushforward of coordinate vector field on $\mathbb{R}$ $``\hspace{01mm}\dot{\gamma}(t)\hspace{-0.5mm}"" := \gamma_*\left(\frac{\partial}{\partial t}\right) = \dot{x}^i(t) \frac{\partial}{\partial x^i}$ I want $\nabla_\dot\gamma \dot{\gamma} = 0$ , but this expression is misleading since the vector field $\dot{\gamma}(t)$ only exists along the image of $\gamma(t)$ , but we can consider the pullback of $M$ by $\gamma$ and take the connection and vector bundle with us. If $\nabla$ is the Levi-Civita connection on $(M,g)$ denote $\widetilde{\nabla}$ as its pullback connection by $\gamma$ Then $\gamma$ is geodesic if $\widetilde{\nabla}_\frac{\partial}{\partial t}\gamma_*\left(\frac{\partial}{\partial t}\right) = 0$ . At this point I start to get stuck, I have the following definition from a worked exam question that inspired me to do this exercise: I'm not quite sure if I'm in the lucky situation where $\gamma_*\left(\frac{\partial}{\partial t}\right)$ is already of the form $v \circ u$ , and I'm not so sure what this even means, if my bundle is the tangent bundle of $M$ , then my sections $e_i = \frac{\partial}{\partial x^i}$ are vector fields, how does one compose a vector field with a map? I think this has something to do with where we are evaluating $\gamma_*\left(\frac{\partial}{\partial t}\right)f = \left.\dot{x}^i(t) \frac{\partial f}{\partial x^i}\right|_{\gamma(t)}$ , that is, $e_i = \left.\frac{\partial}{\partial x^i}\right|_p$ for $p \in M$ whereas $e_i \circ \gamma = \left.\frac{\partial}{\partial x^i}\right|_{\gamma(t)}$ . I'm not sure how to properly justify this but it certainly feels more correct that $\gamma_*\left(\frac{\partial}{\partial t}\right)$ should be ""evaluating"" on $\gamma(t)$ rather than any old $p$ since the whole point of this pullback stuff was to differentiate along the curve. If we accept the above handwaving then my calculation is as follows: $$\widetilde{\nabla}_\frac{\partial}{\partial t}\gamma_*\left(\frac{\partial}{\partial t}\right) := \nabla_{\gamma_*\left(\frac{\partial}{\partial t}\right)}\gamma_*\left(\frac{\partial}{\partial t}\right) 
= \nabla_{\dot{x}^i(t) \frac{\partial}{\partial x^i}}\dot{x}^j(t) \frac{\partial}{\partial x^j}$$ Using $C^\infty(M)$ linearity of a connection in the lower argument and the Liebnitz rule gives $$ = \dot{x}^i(t) \nabla_{\frac{\partial}{\partial x^i}}\dot{x}^j(t) \frac{\partial}{\partial x^j} = \dot{x}^i(t)\frac{\partial}{\partial x^i}\left(\dot{x}^j\right)\frac{\partial}{\partial x^j} +  \dot{x}^i(t)\dot{x}^j(t)\nabla_{\frac{\partial}{\partial x^i}}\frac{\partial}{\partial x^j}$$ The second term is $\dot{x}^i(t)\dot{x}^j(t)\Gamma_{ij}^k\frac{\partial}{\partial x^k}$ which starts to look on the right tracks, but I have no idea what to do to the first term to get a second time derivative, and if my approach is even correct. Apologies for the wall of equations, but I wanted to get down all my thoughts and where my confusions lie, I am looking for how to finish the derivation and an explanation of all this stuff with pullback bundles and correct any misunderstandings I have. Thanks in advance.","['geodesic', 'riemannian-geometry', 'connections', 'vector-bundles', 'differential-geometry']"
3755928,Find the volume between $z=\sqrt{x^{2}+y^{2}}$ and $x^2+y^2+z^2=2$ in spherical cordinates,"I am asking to find the volume of the volume trap above the cone $z=\sqrt{x^{2}+y^{2}}$ and below the sphere $x^2+y^2+z^2=2$ When I checked the solution I noticed that it was writen as $$V=\int_{0}^{2 \pi} \int_{0}^{\frac{\pi}{4}} \int_{0}^{\sqrt{2}} r^{2} \sin \theta \,d r \,d \theta \,d \varphi$$ and my question is why the boundries of $\theta$ is between $0$ to $\frac{\pi}{4}$ and not $0$ to $\pi$ . why $0$ to $\pi$ is wrong? I just can't imagine the scenerio in my head","['integration', 'volume', 'multivariable-calculus', 'spherical-coordinates', 'multiple-integral']"
3755940,Solving $\frac{dy}{dx}=1+(a_mx^m+a_{m-1}x^{m-1}+...+a_0)y^2$,"I have a problem with the following equation, $\frac{dy}{dx}=1+P_m(x)y^2$ Where $P_m(x)$ is a polynomial function. I have solution for $P_m(x)=x$ using Mathematica, and Prof @Claude Leibovici solved for me the special case when $P_m(x)=x^n$ . Regrading to Prof @Claude Leibovici useful answer, I need a much general solution for $P_m(x)=a_mx^m+a_{m-1}x^{m-1}+...+a_0$ The equation can be rewritten by parametrizeing $y=\frac{u}{u'}$ as $u''+P_m(x)u=0$ ; i want declare that problem i introduced is a simplified form from  such equation! I need absoulte solution (not approximate) for the case $P_m(x)=a_mx^m+a_{m-1}x^{m-1}+...+a_0$ . And its ok if the solution is in special functions (becacuse, actually, its the only way to do it). Can anyone here help me please? Thank you guys","['calculus', 'ordinary-differential-equations']"
3755953,limit of subsequence where $X_n - X_{n-1}\rightarrow 0$.,"suppose $X_{n}$ is a sequence of real numbers such that $X_{n} - X_{n-1} \rightarrow 0$ . prove that the limit of subsequence is empty or single point set or interval . . I know the limit of subsequence is the set of limits of subsequences of { $P_{n}$ } n=1,2,... { $P_{n}$ } is the sequence in metric space (X,d). . My effort in this regard is as follows:
Suppose it has two boundary points. We want to prove that all points between these two points are boundary points.such as a & b. Consider a point between these two points.such as c.(a<c<b) Now we have to consider the radius of the neighborhood around this point. . Now I can not calculate this radius correctly and I do not know how the rest of the question will be proved.
Please help me!","['limits', 'analysis']"
3755995,Polynomial Big List: Find the polynomial whose roots are given by some functions of the roots of given polynomials.,"I would like to create a compilation about polynomials for future reference.  The aim is to capture some scenarios that appear in many exams and contests.  Please feel free to make a contribution. Request. For each answer, please give the setting of your problem (the input polynomials, the function, etc) and the output polynomial.  Please also provide a proof, a proof sketch, or a reference for your claim. The five scenarios I have thought of are listed below.   In what follows, let $\mathbb{K}$ be a field with the algebraic closure $\overline{\mathbb{K}}$ .  (For those who have not yet learned about fields, think of $\mathbb{K}$ as $\mathbb{R}$ , and $\overline{\mathbb{K}}$ as $\mathbb{C}$ .)  For simplicity, all polynomials involved may be assumed to be monic (that is, the leading coefficient is $1$ ). Scenario I. A polynomial $p(x)$ of degree $d$ is given, where $r_1,r_2,\ldots,r_d\in\overline{\mathbb{K}}$ are the roots of $p(x)$ .  For a function $f:\overline{\mathbb{K}}\to\overline{\mathbb{K}}$ , let $q(x)$ be the polynomial of degree $d$ with roots $f(r_1)$ , $f(r_2)$ , $\ldots$ , $f(r_d)$ .  What is $q(x)$ in terms of $p(x)$ and $f$ ? Example I. If $f(t)=\lambda t+\mu$ where $\lambda,\mu\in\mathbb{K}$ with $\lambda\neq 0$ , then $q(x)=\lambda^d\,p\left(\dfrac{x-\mu}{\lambda}\right)$ . If all roots of $p(x)$ are nonzero and $f(t)=\dfrac{1}{t}$ for $t\neq 0$ , then $q(x)=\dfrac{x^d}{p(0)}\,p\left(\dfrac{1}{x}\right)$ . If $f(t)=t^2$ and $p(x)=x^2+ax+b$ , then $q(x)=x^2-(a^2-2b)x+b^2$ . Scenario II. A polynomial $p(x)$ of degree $d$ is given, where $r_1,r_2,\ldots,r_d\in\overline{\mathbb{K}}$ are the roots of $p(x)$ .  For a symmetric function $f:\overline{\mathbb{K}}\times\overline{\mathbb{K}}\to\overline{\mathbb{K}}$ , let $q(x)$ be the polynomial of degree $\dfrac{d(d-1)}{2}$ with roots $f(r_i,r_j)$ where $i$ and $j$ are integers such that $1\leq i<j\leq d$ .  What is $q(x)$ in terms of $p(x)$ and $f$ ? Example II. If $f(t_1,t_2)=t_1+t_2$ and $p(x)=x^3+ax^2+bx+c$ , then $$q(x)=x^3+2a\,x^2+(a^2+b)\,x+(ab-c)\,.$$ Scenario III. A polynomial $p(x)$ of degree $d$ is given, where $r_1,r_2,\ldots,r_d\in\overline{\mathbb{K}}$ are the roots of $p(x)$ .  For an asymmetric function $f:\overline{\mathbb{K}}\times\overline{\mathbb{K}}\to\overline{\mathbb{K}}$ , let $q(x)$ be the polynomial of degree $d(d-1)$ with roots $f(r_i,r_j)$ where $i,j\in\{1,2,\ldots,d\}$ are such that $i\neq j$ .  What is $q(x)$ in terms of $p(x)$ and $f$ ? Example III. If $f(t_1,t_2)=\dfrac{t_1}{t_2}$ and $p(x)=x^2+ax+b$ with $b\neq 0$ , then $$q(x)=x^2-\left(\dfrac{a^2}{b}-2\right)\,x+1\,.$$ Scenario IV. A polynomial $p(x)$ of degree $d$ is given, where $r_1,r_2,\ldots,r_d\in\overline{\mathbb{K}}$ are the roots of $p(x)$ .  Let $s>2$ and $f:\overline{\mathbb{K}}^s\to\overline{\mathbb{K}}$ be given.  If $q(x)$ is a polynomial whose roots are given by $f(r_{i_1},r_{i_2},\ldots,r_{i_s})$ where $(i_1,i_2,\ldots,i_s)$ is in some subset $S$ of $\{1,2,\ldots,d\}^s$ , then what is $q(x)$ in terms of $p(x)$ and $f$ ? Example IV. If $f(t_1,t_2,t_3)=t_1t_2t_3$ , $p(x)=x^4+a_3x^3+a_2x^2+a_1x+a_0$ , and $$S=\big\{(1,2,3),(1,2,4),(1,3,4),(2,3,4)\big\}\,,$$ then $$q(x)=x^4+a_1\,x+a_2a_0\,x+a_3a_0^2\,x+a_0^3\,.$$ More generally, for a given polynomial $p(x)=\sum\limits_{k=0}^d\,a_k\,x^k$ of degree $d>1$ , if $$f(t_1,t_2,\ldots,t_{d-1})=t_1t_2\cdots t_{d-1}$$ with $$S=\big\{(i_1,i_2,\ldots,i_{d-1})\,\big|\,1\leq i_1<i_2<\ldots<i_{d-1}\leq d\big\}\,,$$ we have $$q(x)=\sum\limits_{k=0}^d\,(-1)^{d(d-k)}\,a_{d-k}\,a_0^{d-k-1}\,x^k\,,$$ where we use the conventions $a_0^0=1$ and $a_0\,a_0^{-1}=1$ even if $a_0=0$ . Scenario V. Polynomials $p_1(x),p_2(x),\ldots,p_n(x)\in\mathbb{K}[x]$ are given, where $p_i(x)$ has degree $d_i$ with roots $r_i^j\in\overline{\mathbb{K}}$ for $j=1,2,\ldots,d_i$ .  For a function $f:\overline{\mathbb{K}}^n\to\overline{\mathbb{K}}$ , let $q(x)\in\overline{\mathbb{K}}[x]$ be the polynomial of degree $\prod\limits_{i=1}^n\,d_i$ with roots $f\left(r_1^{j_1},r_2^{j_2},\ldots,r_n^{j_n}\right)$ with $j_i\in\{1,2,\ldots,d_i\}$ for every $i=1,2,\ldots,n$ .  What is $q(x)$ in terms of $p_1(x),p_2(x),\ldots,p_n(x)$ and $f$ ? Example V. If $p_1(x)=x^2+a_1x+b_1$ , $p_2(x)=x^2+a_2x+b_2$ , and $f(t_1,t_2)=t_1t_2$ , then $$q(x)=x^4-a_1a_2\,x^3+(a_1^2b_2+a_2^2b_1-2b_1b_2)\,x^2-a_1a_2b_1b_2\,x+b_1^2b_2^2\,.$$ Proof of Example V. Recall that $$r_i^1+r_i^2=-a_i\text{ and }r_i^1r_i^2=b_i\text{ for }i\in\{1,2\}\,.$$ Therefore, $$\sum_{j_1,j_2\in\{1,2\}}\,f(r_1^{j_1},r_1^{j_2})=(r_1^1+r_1^2)(r_2^1+r_2^2)=a_1a_2$$ and $$\prod_{j_1,j_2\in\{1,2\}}\,f(r_1^{j_1},r_1^{j_2})=(r_1^1r_1^2)^2(r_2^1r_2^2)^2=b_1^2b_2^2\,.$$ Observe that $$\begin{align}\sum_{\big\{(j_1,j_2),(j'_1,j'_2),(j''_1,j''_2)\big\}\in\binom{\{0,1\}^2}{3}}\,&f(r_1^{j_1},r_2^{j_2})\cdot f(r_1^{j'_1},r_2^{j'_2})\cdot f(r_1^{j''_1},r_2^{j''_2})\\&=b_1b_2\,\sum_{j_1,j_2\in\{1,2\}}\,f(r_1^{j_1},r_1^{j_2})=a_1a_2b_1b_2\,.\end{align}$$ Finally, $$\begin{align}\sum_{\big\{(j_1,j_2),(j'_1,j'_2)\big\}\in\binom{\{0,1\}^2}{2}}\,f(r_1^{j_1},r_2^{j_2})\cdot f(r_1^{j'_1},r_2^{j'_2})&=b_2\,\sum_{j=1}^2\,(r_1^j)^2+b_1\,\sum_{j=1}^2\,(r_2^j)^2+2b_1b_2\\&=b_2(a_1^2-2b_1)+b_1\,(a_2^2-2b_2)+2b_1b_2\\&=a_1^2b_2+a_2^2b_1-2b_1b_2\,.\end{align}$$ The proof is now complete.","['contest-math', 'big-list', 'reference-request', 'polynomials', 'algebra-precalculus']"
3756009,$\operatorname{U}(2n) \supset \frac{\operatorname{Sp}(n) \times \operatorname{Sp}(m)}{\mathbb{Z}_2}$ for what maximum of $m$?,"I know that the Sp( $n$ ) group is a real Lie group which is compact, connected, and simply connected
with $n(2n+1)$ real Lie algebra generators. It can be constructed out of the intersections between
a non-compact, simply connected, simple Lie group $\operatorname{Sp}(2n;\mathbf C)$ and the unitary group $\operatorname{U}(2n)$ as
related by $$
\operatorname{Sp}(n):=\operatorname{Sp}(2n;\mathbf C)\cap\operatorname{U}(2n)=\operatorname{Sp}(2n;\mathbf C)\cap\operatorname {SU} (2n) \tag{1}.
$$ I also know that: $$
\operatorname{U}(2n) \supset \operatorname{SU}(2n) 
\supset\operatorname{Sp}(n) \supset \operatorname{U}(n) \tag{2}.
$$ Now can we show the following: $$
\operatorname{U}(2n) \supset 
\frac{\operatorname{Sp}(n) \times \operatorname{Sp}(1)}{\mathbb{Z}_2}? \text{ for some large enough $n$}? \tag{Q1}.
$$ $$
\operatorname{U}(2n) \supset 
\frac{\operatorname{Sp}(n) \times \operatorname{Sp}(m)}{\mathbb{Z}_2} \text{ for some large enough $n$ and for what maximum of $m$}? \tag{Q2}.
$$ Q1 and Q2 are my questions, for what maximum of $m$ ? Lie group experts, please illuminate! Thanks! p.s. For $n=1$ , Q1 is wrong since $\operatorname{U}(2n) \supset 
\frac{\operatorname{Sp}(n) \times \operatorname{Sp}(1)}{\mathbb{Z}_2}$ but it is wrong $\operatorname{U}(2) \not\supset 
\frac{\operatorname{Sp}(1) \times \operatorname{Sp}(1)}{\mathbb{Z}_2}$ .","['symplectic-geometry', 'manifolds', 'group-theory', 'lie-groups', 'differential-geometry']"
3756014,What does conditioning on an observed sample mean?,"Suppose we have a collection of samples $\mathcal{D} = \{x_1, \ldots, x_n\}$ drawn independently from a fixed but unknown distribution $p(x)$ , Bayesian estimation uses $\mathcal{D}$ to determine $p(x|\mathcal{D})$ . I am having trouble transforming the above to rigorous mathematical language. The formal definition for conditional distribution is $f|_{X|Y}(x|y) = \frac{f(x,y)}{f(y)}$ , but that requires both $X$ and $Y$ to be random variables. I do not know how to think of $\mathcal{D}$ as a random variable. Should it be thought of as $P(X = x| (X_1, \ldots, X_n) = (x_1, \ldots, x_n))$ where $X_1, \ldots, X_n$ are i.i.d randome variables.","['statistics', 'probability-theory', 'probability']"
3756019,Group Ring and Augmentation Ideal of Baumslag Solitar Groups,"Let $m,n$ be integers. The Baumslag Solitar Group if defined by $$G=G_{m,n}=\langle a,b: ba^{m}b^{-1}=a^{n}\rangle $$ This group acts naturally on $\mathbb{R}^{2}$ by multiplication and I want to compute the Cohomology groups $H^{k}(G_{1,2},\mathbb{R}^{2})$ for $k=0,1,2,...$ My Approach: The matrices $A=\left(
\begin{array}{cc}
 1 & 1 \\
 0 & 1 \\
\end{array}
\right)$ and $B=\left(
\begin{array}{cc}
 2 & 0 \\
 0 & 1 \\
\end{array}
\right)$ make a copy of $G=G_{1,2}$ . By definition $$H^{0}(G,\mathbb{R}^{2})=\{x\in \mathbb{R}^{2}:g\cdot x=x, \ \text{for all} \ g\in G\}$$ It is easy to see by a simple calculation that $H^{0}(G,\mathbb{R}^{2})=0$ . On the other hand $H^{1}(G,\mathbb{R}^{2})$ is defined by $$H^{1}(G,\mathbb{R}^{2})=\frac{\operatorname{Der}(G,\mathbb{R}^{2})}{ \operatorname{Ider}(G,\mathbb{R}^{2})}$$ And.... again... by a simple calculation $H^{1}(G,\mathbb{R}^{2})=0$ In order to compute $H^{2}(G,\mathbb{R}^{2})$ I want to use the identity $$H^{2}(G,\mathbb{R}^{2})=H^{1}(G, \operatorname{Hom}_{\mathbb{Z}}(I[G], \mathbb{R}^{2}))$$ My quetions are: 1.- If $G=\langle A,B\rangle $ how to compute the group ring $\mathbb{Z}[G]$ ? 2.- If $G=\langle A,B\rangle $ how to compute the augmentation ideal $I[G]$ ? 3.- Is there an easy way to compute $H^{2}(G,\mathbb{R}^{2})$ ? 4.- How to compute $H^{k}(G,\mathbb{R}^{2})$ for $k>2$ ?","['group-theory', 'group-cohomology']"
3756063,$\operatorname{U}(4n) \supset \frac{\operatorname{Sp}(n) \times \operatorname{Sp}(m)}{\mathbb{Z}_2}$ for some maximum of $m$?,"I know that the Sp( $n$ ) group is a real Lie group which is compact, connected, and simply connected
with $n(2n+1)$ real Lie algebra generators. It can be constructed out of the intersections between
a non-compact, simply connected, simple Lie group $\operatorname{Sp}(2n;\mathbf C)$ and the unitary group $\operatorname{U}(2n)$ as
related by $$
\operatorname{Sp}(n):=\operatorname{Sp}(2n;\mathbf C)\cap\operatorname{U}(2n)=\operatorname{Sp}(2n;\mathbf C)\cap\operatorname {SU} (2n) \tag{1}.
$$ I also know that: $$
\operatorname{U}(2n) \supset \operatorname{SU}(2n) 
\supset\operatorname{Sp}(n) \supset \operatorname{U}(n) \tag{2}.
$$ Now can we show the following: $$
\operatorname{U}(4n) \supset 
\frac{\operatorname{Sp}(n) \times \operatorname{Sp}(1)}{\mathbb{Z}_2}? \tag{Q1}.
$$ $$
\operatorname{U}(4n) \supset 
\frac{\operatorname{Sp}(n) \times \operatorname{Sp}(m)}{\mathbb{Z}_2} \text{ for some $n$, and for what maximum of $m$}? \tag{Q2}.
$$ Q1 and Q2 are my questions, for what maximum of $m$ ? Lie group experts, please illuminate! Thanks!","['symplectic-geometry', 'smooth-manifolds', 'group-theory', 'lie-groups', 'differential-geometry']"
3756068,Geometric meaning of Koszul (co)homology?,"Let $R$ be a ring, associative and unital, and let $A$ be a left $R$ -module. Let $x\in A$ and define the complex $K(x)$ to be the complex $0\to R\to R\to 0$ where the middle map is multiplication by $x.$ The homology of $K(x)\otimes A$ are the Koszul homology modules $H_q(x,A)$ and the cohomology of the complex $\mathrm{Hom}(K(x),A)$ are the Koszul cohomology modules $H^q(x,A).$ For $\mathbf{x}=(x_1,\ldots, x_n)$ we define $K(\mathbf{x})$ to be the total complex of the tensor product $K(x_1)\otimes\cdots\otimes K(x_n)$ and then define $H_q(\mathbf{x},A)$ and $H^q(\mathbf{x},A)$ similarly. We also define the local cohomology (of $A$ at $\mathbf x$ ? I am not sure of the terminology here) to be the direct limit $$H^q_\mathbf x(A)=\varinjlim H^q(\mathbf x^i, A).$$ My question is this: what, if any, is the geometric meaning behind these modules ? The general theory is all well and good, but I feel that when I'm done studying these things they will just slip out of my mind because I have nothing to connect them to. It looks sort of like localization to me, kind of like how the localization of a ring $R$ at an element $x\in R$ is the direct limit of the system $R\to R\to R\to\cdots $ where each map is multiplication by $x.$ I don't have much experience in algebraic geometry however (especially from the scheme-theoretic point of view) so I can't put this into words myself.","['homology-cohomology', 'modules', 'ring-theory', 'algebraic-geometry', 'soft-question']"
3756081,"Let $X,Y$ be banach spaces $T,T_n: X\to Y$ and let $T_n \to T$ pointwise, show $T_n \to T$ uniformly on all compact sets","Let $X,Y$ be banach spaces $T,T_n: X\to Y$ and let $T_n \to T$ pointwise (weak*), show $T_n \to T$ uniformly on all compact sets. I reason like this: I claim that $T_n$ are equicontinuous. That is true as by uniform boundedness principle $\|T_n\|\leq M$ for all $n$ . Thus $T_n$ are all lipshitz of constant less than $M$ , which means they are equicontinuous. Now Pointwise+equicontinuity imply uniform on a compact sets, and so the result follows. Is this correct? IS there another solution to this problem?","['banach-spaces', 'solution-verification', 'functional-analysis', 'uniform-convergence', 'pointwise-convergence']"
3756086,Is $\lim_{s \to \infty} \int f(x) g(s)dx$ equal to $\int f(x) (\lim_{s \to \infty}g(s) ) dx$?,"$$\lim_{s \to \infty} \int f(x) g(s)dx = \int f(x) (\lim_{s \to \infty}g(s) ) dx$$ Is this equality true? Can you move the limit operator inside of the integral, since we're not integrating with respect to the variable in the limit?","['limits', 'calculus']"
3756097,Are there other important measure spaces which are not obtained directly from an outer measure or from the Caratheodory extension theorem?,"I have just started to study measure theory and I have a question. But before presenting it, I will provide the context from which it comes. Given a nonempty set $\Omega$ , we say that a set function $\mu$ defined on a algebra $\mathcal{F}\subseteq\mathcal{P}(\Omega)$ is a measure if $\mu(A)\geq 0$ for all $A\in\mathcal{F}$ , $\mu(\varnothing) = 0$ , $\mu$ satisfies the countable additivity property. We say the set function $\mu^{*}:\mathcal{P}(\Omega)\to[0,+\infty)$ is an outer measure if $\mu^{*}(\varnothing) = 0$ , it satisfies the monotonicity property and the countable subadditivity property. We also say that $A\subseteq\Omega$ is $\mu^{*}$ -measurable if, for any set $E\subseteq\Omega$ , one has that \begin{align*}
\mu^{*}(E) = \mu^{*}(E\cap A) + \mu^{*}(E\cap A^{c})
\end{align*} Then we have the following theorem: Let $\mu^{*}$ be an outer measure on $\mathcal{P}(\Omega)$ . Let $\mathcal{M} := \mathcal{M}_{\mu^{*}} := \{A:A\,\text{is}\,\mu^{*}\text{-measurable}\}$ . Then $\mathcal{M}$ is a $\sigma$ -algebra $\mu^{*}$ restriced to $\mathcal{M}$ is a measure, and $\mu^{*}(A) = 0$ implies that $\mathcal{P}(A)\subset\mathcal{M}$ . This result makes $(\Omega,\mathcal{M}_{\mu^{*}},\mu^{*})$ a complete measure space. Moreover, it gives an inexhaustible source method to construct measure spaces (as far as I have understood). We may now state the Caratheodory's extension theorem, which says: Let $\mu$ be a measure on a semi-algebra $\mathcal{C}$ and let $\mu^{*}$ be the set function induced by $\mu$ defined on $\mathcal{P}(\Omega)$ s.t. \begin{align*}
\mu^{*}(A) = \inf\left\{\sum_{i=1}^{\infty}\mu(A_{i}):\{A_{n}\}_{n\geq1}\subset\mathcal{C},\,A\subset\bigcup_{i=1}^{\infty}A_{n}\right\}
\end{align*} Then we have that $\mu^{*}$ is an outer measure, $\mathcal{C}\subset\mathcal{M}_{\mu^{*}}$ , and $\mu^{*} = \mu$ on $\mathcal{C}$ Now let us consider the semialgebra \begin{align*}
\mathcal{C} = \{(a,b]:-\infty\leq a\leq b<\infty\}\cup\{(a,\infty):-\infty\leq a < \infty\}
\end{align*} as well as the nondecreasing functions $F:\textbf{R}\to\textbf{R}$ which induces the following measure on $\mathcal{C}$ : \begin{align*}
\begin{cases}
\mu_{F}((a,b]) = F(b+) - F(a+)\\\\
\mu_{F}((a,\infty)) = F(\infty) - F(a+)
\end{cases}
\end{align*} Let $(\textbf{R},\mathcal{M}_{\mu^{*}_{F}},\mu^{*}_{F})$ be the Caratheodory extesion of $\mu_{F}$ . Then the book defines such measure space as the Lebesgue-Stieltjes measure space and $\mu^{*}_{F}$ is the Lebesgue-Stieltjes measure generated by $F$ . My question is: are there other important measure spaces which are not obtained directly from an outer measure or from the Caratheodory extension theorem? I am new to this so any contribution is appreciated.","['measure-theory', 'outer-measure', 'real-analysis']"
3756136,Why is the category of fields seemingly so poorly behaved?,"Compared to the categories of other “common” algebraic objects like groups and rings, it seems that fields as a whole are missing some important properties: There are no initial or terminal objects There are no free fields No products or coproducts Every arrow is a mono (maybe not a bad thing, but still indicates how restrictive the category is) A logician once told me in passing that part of the reason is that the properties for fields contain a decidedly “weird” property, namely that every element in a field except zero has a multiplicative inverse. If I understood him correctly, this property is sufficiently different from the others that the category of all such objects loses some features. But I have no idea if this was a heuristic or a proven theorem.","['field-theory', 'abstract-algebra', 'category-theory']"
3756153,Counting polynomials with complex roots,"Let $G$ be the set of polynomials of the form $P(z)=z^n+c_{n-1}z^{n-1}+\cdots+c_2z^2+c_1z+50$ ,
where $c_1,c_2,\cdots, c_{n-1}$ are integers and $P(z)$ has $n$ distinct roots of the form $a+ib$ with $a$ and $b$ integers. How many polynomials are in $G$ ? My observations so far are that we'll have this product $(a_1^2+b_1^2)(a_2^2+b_2^2)\cdots (a_n^2+a_{n-1}^2)=50$ . I have tried counting directly since $50$ has few factors, but I'm not sure that I have all of the possible arrangements, and it has lead to the incorrect answer. The actual answer is 528. I would appreciate hints on how to go on.","['combinatorics', 'polynomials']"
3756197,Derivative of Gauss map is the second fundamental form,"I have been messing around with Grassmannians lately. Let $M^k\subseteq \Bbb R^n$ be an embedded submanifold equipped with the induced Riemannian metric, and consider the Gauss map $G\colon M \to {\rm Gr}_k(\Bbb R^n)$ given by $G(p) = T_pM$ , taking values in the Grassmannian of $k$ -planes of $\Bbb R^n$ . Then the derivative is a map ${\rm d}G_p\colon T_pM \to {\rm Hom}(T_pM, T_pM^\perp)$ , which by currying may be seen as a bilinear map ${\rm d}G_p\colon T_pM \times T_pM \to T_pM^\perp$ . The only reasonable guess is that ${\rm d}G_p$ is the second fundamental form ${\rm II}_p$ , but I'm not sure how to even start this. Can someone show me the calculation or give a reference? Thanks. Note: I can see that $${\rm d}G_p(v,w) = \frac{\partial \alpha}{\partial s}(0,0)$$ where $\alpha \colon (-\epsilon,\epsilon)^2 \to M$ is given by $\alpha(t,s) = \exp_{\gamma(t)}(sw(t))$ , where $t \mapsto \gamma(t)$ is any curve in $M$ with $\gamma(0) = p$ and $\gamma'(0) = v$ , while $t \mapsto w(t)$ is a curve of vectors such that $w(0) = w$ and $w(t) \in T_{\gamma(t)}M$ for all $t$ . But it is not clear to me how to make $\nabla$ and ${\rm D}$ appear here. Nevermind, it is trivial. We may assume that $t \mapsto w(t)$ is a parallel field along $\gamma$ , so $$w'(t) = \frac{{\rm D}w}{{\rm d}t}(t) + {\rm II}_{\gamma(t)}(\gamma'(t),w(t))\implies w'(0) = {\rm II}_p(v,w)$$ as wanted. I'll leave this open in case someone realizes I'm royally screwing the pooch here...","['grassmannian', 'riemannian-geometry', 'differential-geometry']"
3756227,Mordell equation with prime-squared constant,"I'm interested in a specific case of the Mordell equation: $$E: y^2=x^3+k$$ where $k=p^2$ for some prime $p$ . Most of the literature I've been able to find regarding the Mordell equation either explicitly assumes $k$ to be square-free or avoids the case altogether. I want to show that the torsion subgroup of $E(\mathbb{Q})$ is (isomorphic to) $\mathbb{Z}/3\mathbb{Z}$ . By the Nagell-Lutz theorem, we can narrow down the possibilities to $$y \in \{\pm{1},\pm{3},\pm{p},\pm{3p},\pm{p^2},\pm{3p^2}\}$$ By a factoring argument, I can prove that the $y=\pm{1}$ case yields no solutions (except a specific side-case for $p=3$ that yields a non-torsion point). I can't seem to uncover an analogous argument, or really any argument,  for the $y=\pm{3}$ case, which boils down to solving $$x^3=9-p^2=(3-p)(3+p)$$ Here's what I know: $x$ must be an integer if it is a rational solution; $9-x^3$ doesn't factor over $\mathbb{Z}$ so we can't use the same argument as in the $p=\pm{1}$ case; $p=2$ yields no solutions, so we can assume that $p$ is odd, which leads to $x$ being even, which in turn shows that $8\vert(3-p)(3+p)$ . I've tried to extend out point #3 above but keep on running into dead ends. Are there other techniques that I'm missing here? Any pointers would be helpful. Thanks!","['elliptic-curves', 'divisibility', 'number-theory', 'diophantine-equations', 'mordell-curves']"
3756252,Bounds of $1^n + 2^{n-1} + 3^{n-2} + \cdots + n^1$,"I want to estimate the value of this sequence for large $n$ (with a reasonable lower bound and upper bound). That is, can we find a function $f(n)$ such that $$ \frac{1^n + 2^{n-1} + 3^{n-2} + \cdots + n^1}{f(n)} \rightarrow 1?$$ I tried to approximate $ (n - x)^x $ as a Gaussian, look at how close it is visually, but the manipulation escapes me. Here is the case where $n=20$ : Addendum: This post might be relevant .","['convergence-divergence', 'upper-lower-bounds', 'sequences-and-series']"
3756280,How to find all abelian subgroups of Möbius transformations?,"How to find all abelian subgroups of Möbius transformations? It's a problem from conway's functions of one complex variable. The things I have known is that when two Möbius transformations commute,they will have the same fixed point. And I think this is related to abelian groups of matrix group since the composition of transformations is just like matrix multiplication. Any help will be thanked.","['complex-analysis', 'group-theory', 'abelian-groups', 'conformal-geometry']"
3756347,The operator norm $\|L\|$,"Let $C_0([0, 1])$ be a subspace of $C([0, 1])$ , a functional space consisting of real-value continuous functions over the interval $[0, 1]$ , such that $C_0 ([0, 1]) = \left\{ f \in C([0, 1]) \mid \int_0^1 f(t) dt = 0 \right\}$ , and define the norm as $\| f \|_\infty = \sup_{x \in [0, 1]} |f(x)|$ . Then, define linear operator $L: C_0 ([0, 1]) \to C ([0, 1])$ as $(Lf)(x) = \int_0^x (x-t)f(t)\, dt\quad (x \in [0, 1])$ I can show that $L$ is bounded by using some inequalities, but what is the operator norm $||L||$ ? So far, I hypothesize that $\|L\| = \frac{1}{4}$ , by considering the definition $\|L\| = \sup\{\|Lf\|_\infty: f \in C_0 ([0, 1]) {\rm with} \|f\|_\infty = 1\}$ , and then thinking of a continuous function that is very close to this one: $f(x) = 
\left\{ \begin{array}{ll}
    1 & (0 \leq x \leq 1/2) \\
    -1 & (1/2 < x \leq 1)
  \end{array} \right.$ (I know this is not even continuous, but I'm thinking of an intuitive way to estimate $\|L\|$ by thinking of a function $f$ that satisfies $\|f\|_\infty = 1$ , and would give the maximum of $\|Lf\|_\infty$ .) And then I get the $\frac{1}{4}$ by calculating (assume $x > 1/2$ ) $\int_0^x (x-t)f(t)\, dt = \int_0^{1/2} (x - t)\, dt + \int_{1/2}^x (t-x)\, dt = -\frac{1}{2}x^2 + x -\frac{1}{4}$ and finding the maximum value of the result ( $\frac{1}{4}$ at $x = 1$ ) Where do I go from here? How can I give a more mathematical approach to calculating $\|L\|$ ? Thank you in advance.","['integration', 'normed-spaces', 'analysis']"
3756348,If $|z|^2+\bar{A}z^2+A(\bar{z})^2+B\bar{z}+\bar{B}z+c=0$ represents a pair of intersecting lines.... find the value of $|A|$.,"If $|z|^2+\bar{A}z^2+A(\bar{z})^2+B\bar{z}+\bar{B}z+c=0$ represents a pair of intersecting lines with angle of intersection $'\theta'$ then find the value of |A|. I tried using general equation of straight line in complex form as $a\bar{z}+\bar{a}z+b=0$ where b is real,where slope of line is $\frac{-a}{\bar{a}}$ and multiplying two such lines and then compairing coefficient.I found that c is real and used $$\tan(\theta)=\big|\left(\frac{\text{slope}_1-\text{slope}_2}{1+\text{slope}_1*\text{slope}_2}\right)\big|$$ one thought was also that the use of $|z_1+z_2|^2=(z_1+z_2)(\bar{z_1}+\bar{z_2})=|z_1|^2+|z_2|^2+\bf{z_1\bar{z_2}+z_2\bar{z_1}}$ But this is becoming very long and I think this is also not much effective and there should be some good way, is there a better way out ?","['slope', 'angle', 'geometry', 'complex-numbers']"
3756351,"Finding real $(x,y)$ solutions that satisfies a system of equation.","I was given: $x + y^2 = y^3 ...(i) \\ y + x^2 = x^3...(ii)$ And was asked to find real $(x,y)$ solutions that satisfy the equation. I substracted $(i)$ by $(ii)$ : $x^3 - y^3 + y^2 - x^2 + x - y = 0$ Then factored it out so I have: $(x-y)(x^2 + xy + y^2 - x - y + 1) = 0$ Multiplying it by two, I get: $(x-y)(2x^2 + 2xy + 2y^2 - 2x - 2y + 2) = 0 \\
(x-y)((x^2 - 2x + 1) + (y^2 - 2y + 1) + (x^2 + 2xy + y^2)) = 0 \\
(x-y)((x-1)^2 + (y-1)^2 + (x+y)^2) = 0$ I noticed that a solution exists only if $x=y$ because there are no real solutions for $x$ and $y$ that satisfies $(x-1)^2 + (y-1)^2 + (x+y)^2 = 0$ . Substituting $x=y$ into the first equation, I get: $y(y^2-y-1)=0$ where the roots are $y= 0, \frac{1+\sqrt{5}}{2}, \frac{1-\sqrt{5}}{2}$ . Hence, the real solutions of $(x,y)$ that satisfy are: $(x,y) = (0,0), (\frac{1+\sqrt{5}}{2},\frac{1+\sqrt{5}}{2}), (\frac{1-\sqrt{5}}{2}, \frac{1-\sqrt{5}}{2})$ . What I would like to ask is: Is there a better way to solve the question? It's from a local university entrance test, where this kind of questions are aimed to be done in < 3 minutes. It took me a while to manipulate the algebraic stuffs above. Someone in a local forum said something about symmetric systems which says that the solution does not exist for $x \neq y$ . How do I know if the equation is a symmetric one? (Never heard of something before throughout high school here...) I would love to see a resource for this!","['algebra-precalculus', 'systems-of-equations', 'symmetric-polynomials']"
3756401,A problem about differential of a smooth map,"Problem: We have a map $ f: \mathbb{R}^3\rightarrow M(2,R)$ $$f(x,y,z)=exp \begin{pmatrix}
    x & y+z \\
    y-z & -x \\
    \end{pmatrix}$$ Here, we denote the set of all 2-dimensional real square matrices as $M(2,R)$ . Find the points where the differential of $f$ is not injective and draw the graph of this set. What I have done: (You can ignore the following part) Let's denote $\begin{pmatrix} x & y+z \\ y-z & -x \\ \end{pmatrix}$ as $A$ . Then $A^2 = \begin{pmatrix} x^2+y^2-z^2 & 0 \\ 0 & x^2+y^2-z^2 \\ \end{pmatrix} = (x^2+y^2-z^2)I$ Then, we can get the value of $A^n:$ $$ 
\begin{array}{c|c|c}
  &\\\hline
  A^0&I&\\
  A^1&&A\\
  A^2&(x^2+y^2-z^2)I&\\
  A^3&&(x^2+y^2-z^2)A\\
  A^4&(x^2+y^2-z^2)^2I&\\
  A^5&&(x^2+y^2-z^2)^2A\\
\cdots&\cdots&\cdots
\end{array}
 $$ It is easy for us to calculate: $$\begin{align}exp A 
& = I+ \color{red}{A}+\frac{A^2}{2!}+\color{red}{\frac{A^3}{3!}}+\frac{A^4}{4!}+\color{red}{\frac{A^5}{5!}}+\cdots \\  
& = I (1 + \frac{(x^2+y^2-z^2)}{2!} + \frac{(x^2+y^2-z^4)^2}{4!} +\cdots )+ \color{red}{A} ( \color{red}{1}+ \color{red}{\frac{(x^2+y^2-z^2)}{3!}} + \color{red}{\frac{(x^2+y^2-z^2)^2}{5!}} +\cdots ) \\ 
& = I (1 + \frac{(x^2+y^2-z^2)}{2!} + \frac{(x^2+y^2-z^4)^2}{4!} +\cdots )\\
& + \color{red}{\frac{A}{\sqrt{x^2+y^2-z^2}}} ( \color{red}{\sqrt{x^2+y^2-z^2}}+ \color{red}{\frac{(x^2+y^2-z^2)^\frac{3}{2}}{3!}} + \color{red}{\frac{(x^2+y^2-z^2)^\frac{5}{2}}{5!}} +\cdots ) 
\end{align}$$ When $x^2+y^2-z^2>0$ , $$\begin{align}exp A 
& = cosh\sqrt{x^2+y^2-z^2}I + \color{red}{\frac{A}{\sqrt{x^2+y^2-z^2}} sinh \sqrt{x^2+y^2-z^2}} \\
& = \begin{pmatrix}
    cosh\sqrt{x^2+y^2-z^2} + \color{red}{\frac{x}{\sqrt{x^2+y^2-z^2}} sinh \sqrt{x^2+y^2-z^2}} & \color{red}{\frac{y+z}{\sqrt{x^2+y^2-z^2}} sinh \sqrt{x^2+y^2-z^2}}  \\
    \color{red}{\frac{y-z}{\sqrt{x^2+y^2-z^2}} sinh \sqrt{x^2+y^2-z^2}} & cosh\sqrt{x^2+y^2-z^2} - \color{red}{\frac{x}{\sqrt{x^2+y^2-z^2}} sinh \sqrt{x^2+y^2-z^2}}  \\
    \end{pmatrix}
\end{align} \tag{1}$$ Similarly, We can calculate that when $x^2+y^2-z^2<0$ , $$exp A= \begin{pmatrix}
    cos\sqrt{z^2-(x^2+y^2)} + \color{red}{\frac{x}{\sqrt{z^2-(x^2+y^2)}} sin \sqrt{z^2-(x^2+y^2)}} & \color{red}{\frac{y+z}{\sqrt{z^2-(x^2+y^2)}} sin \sqrt{z^2-(x^2+y^2)}}  \\
    \color{red}{\frac{y-z}{\sqrt{z^2-(x^2+y^2)}} sin \sqrt{z^2-(x^2+y^2)}} & cos\sqrt{z^2-(x^2+y^2)} - \color{red}{\frac{x}{\sqrt{z^2-(x^2+y^2)}} sin \sqrt{z^2-(x^2+y^2)}}  \\
    \end{pmatrix} \tag{2}$$ When $x^2+y^2-z^2=0$ , $ exp A = \begin{pmatrix} 1+x & y+z\\ y-z & 1-x\end{pmatrix} \tag{3}$ The standard way to solve the problem may be to identify $M(2,R)$ as $\mathbb{R}^4:$ $$\begin{pmatrix} x & z \\ y & w\end{pmatrix} \mapsto (x,y,z,w)$$ then calculate the differential for (1) (2) and (3) and decide when their rank $<3$ . But I found it is hard to calculate. So is to find under which condition rank $<3$ . Any one can give me some ideas or which books deal with related topics?","['matrices', 'manifolds', 'multivariable-calculus', 'exponential-function']"
3756474,Can the step-functions be chosen monotonically?,"Assume we are on the interval $[a,b]$ . Assume we have a partition of the interval $\{a=x_0<x_1<x_2,<\ldots x_{n+1}\}$ . A step-function is a function $f$ where there exists $c_0,c_1,\ldots ,c_n$ such that $$f(x)=c_0I_{x_0}(x)+\sum\limits_{i=0}^nc_iI_{(x_i,x_{i+1}]}(x).$$ Assume that $g\in L^1([a,b])$ , $g\ge0$ . Then there exists a sequence of step-functions such that they converge to $g$ in $L^1([a,b])$ . Can this sequence be chosen so that they converge monotonically?","['measure-theory', 'approximation', 'real-analysis', 'lp-spaces', 'convergence-divergence']"
3756548,Baire's Theorem with locally compact Hausdorff space,"Statement of the theorem: If $S$ is either a) a complete metric space, or b) a locally compact Hausdorff space, Then the intersection of every countable collection of dense open subsets of $S$ is dense in $S$ . The idea of the proof is to show that every open set $B$ intersects the countable union of given dense open subsets. Specifically if $\left\{ V_i \right\}_{i \in \mathbb{N}}$ is such a collection and $B$ is an arbitrary open set the following recursion is then defined $$
\begin{array}{l}
B_0 = B \\
\bar{B}_{n} \subset V_n \cap B_{n-1}
\end{array}
$$ Later we define $$
K = \bigcap_{n=1}^{\infty} \bar{B}_n
$$ The author at this point states that $K$ isn't empty by compactness.
I cannot really understand why. From wikipedia : Let $X$ be a topological space. Most commonly $X$ is called locally compact, if every point $x$ of $X$ has a compact neighbourhood, i.e., there exists an open set $U$ and a compact set $K$ , such that ${\displaystyle x\in U\subseteq K}$ I guess this is the definition that we're trying to apply, but I can't figure how exactly we apply it.","['proof-explanation', 'general-topology', 'functional-analysis']"
3756594,Bijective map from a set to a subset of reals?,"There is a concept that I have been thinking about quite a lot lately as I am currently self-studying point-set topology: Say we have a bijective map from one interval, $[a,b]$ , to another interval, $[c,d]$ , both of which are in $\mathbb{R}$ . Also set $c$ and $d$ so that $[c,d] \subseteq [a,b]$ . How can it be that function maps to a subset which is a proper subset of the map's preimage bijectively? I.e. How can the map be both one-to-one and onto when the image should contain ""less"" elements than the domain? One example would be $f(x) := \frac{x}{1+x}: [0,10] \to [0, \frac{10}{11}]$ I'm hoping someone can show me why this isn't such a strange concept? Is there a theorem or result that explains this or provides some intuition?","['elementary-set-theory', 'general-topology', 'real-analysis']"
3756615,Wimbledon's final,"Tom and Jack are playing the final of Wimbledon and they are 6:6 at the last set. They play to the bitter end until one of them is ahead by two games. For Tom the probability to win the next games is $p$ , and for Jack $1-p$ . Every games is independent from the others. Find the probability that the match end 9 to 7 for one of them. For $A=($ Tom wins 9 to 7 $)$ and $B=($ Jack wins 9 to 7 $)$ , we have $\rightarrow \mathbb{P}(A\cup B)=2p(1-p)[p^2+(1-p)^2]$ Find the probability that it needs more than 4 games to end the match. For $X=($ # games to the end $)$ , we have $\rightarrow \mathbb{P}(X>4)=1-\mathbb{P}(X\leq 4)=1-\mathbb{P}(X\leq 4|A\cup B)=1-\frac{\mathbb{P}(X\leq 4 \cap A)+\mathbb{P}(X\leq4\cap B)}{\mathbb{P}(A)+\mathbb{P}(B)}=1-\frac{2[p^2+(1-p)^2]}{[p^2-(1-p)^2]}$ Find the probability that Tom wins. Hoping 1) and 2) are right, do you have any ideas for point 3)? Thanks in advance.",['probability']
3756619,Definition of étale morphism in Mumford,"I am trying to understand the definition of étale morphism in Mumford Chapter III Section 5, which I find confusing. I would appreciate any clarifications. A morphism $f: X \to Y$ of finite type is étale, if for all $x \in X$ , there are open neighbourhoods $U \subset X$ of $x$ and $V \subset Y$ of $f(x)$ such that $f(U) \subseteq V$ and such that $f$ restricted to $U$ looks like: $$
\begin{array}
&U  & \xrightarrow{\text{open immersion}}  &\operatorname{Spec}R[X_1, .., X_n]/(f_1, ..., f_n) \\
\downarrow\rlap{\scriptstyle\text{res} \, f} & & \quad\downarrow{} \\
V & \xrightarrow{\phantom{open immersion}}  & \operatorname{Spec} R
\end{array}
$$ where $\det (\partial f_i/ \partial x_j) (x) \neq 0$ . What is the map $V \to \operatorname{Spec} R$ ? In particular, does this have to be an open immersion as well? How do I make sense of $\det (\partial f_i/ \partial x_j) (x)$ ? Thank you.","['affine-schemes', 'algebraic-geometry', 'schemes']"
3756653,Measurability of a function on sub sigma algebra,"Let $\Omega$ be a compact Hausdorff space in $\mathbb{C}^2$ . Let $\sigma_\Omega$ be the Borel sigma algebra on $\Omega$ . Let $f: \Omega\longrightarrow\partial \mathbb{D}$ be a non constant continuous  function. Let $\sigma_{\partial \mathbb{D}}$ be the Borel sigma algebra on $\partial \mathbb{D}$ (Unit circle on the complex plane). Now consider the sigma algebra $\sigma_0=\{f^{-1}(A): \;A\in \sigma_{\partial \mathbb{D}}\}\subset \sigma_\Omega$ . Now consider the function $g: \Omega\longrightarrow\mathbb{C}$ as $g(z_1,z_2)=z_1^mz_2^n(\bar{z_1})^p(\bar{z_2})^q$ , where $m,n,p,q\in\mathbb{N}.$ Now as $g$ is continuous, it is clearly measurable w.r.t $\sigma_\Omega$ but. will it be measurable w.r.t $\sigma_0$ ? Is there any additional condition that can be put on $f$ , so that the above holds?","['complex-analysis', 'measure-theory', 'conditional-expectation']"
3756664,Probability of drawing an ace or 2 after an ace [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question From a standard 52 card deck, we draw one card at a time without replacement. After having drawn the first ace, the game continues until either We draw another ace, or We draw a 2, and the game then stop. Which events of the two is more likely, and what are the corresponding probabilities? Edit:
It is not very hard to get the probability = 0.5 with calculations. but can we come up with some more intuitive explanations?","['poker', 'probability']"
3756704,Solving $2\sin\left(2x\right)=3\left(1-\cos x\right)$,"Background - this was part of a homework packet for students looking to skip HS pre-calc. There is a text book they use as well, but this particular problem was not in it. $$2\sin\left(2x\right)=3\left(1-\cos\left(x\right)\right)$$ My first step was to eliminate the double angle. $$4\sin\left(x\right)\cos\left(x\right)=3\left(1-\cos\left(x\right)\right)$$ and distribute on right side $$4\sin\left(x\right)\cos\left(x\right)=3-3\cos\left(x\right)$$ And this is where I am stuck. Now, I can see that $0$ and $2\pi$ are solutions, but with a graph of both sides, one more. The worksheet instructions do not say whether or not graphing is allowed, although the particular chapter in the book for this seems to rely heavily on calculator work. My question Can this be solved by manipulation, if so, how? If not, what is the hint to stop and go to the graph?",['trigonometry']
3756717,Finite differences second derivative as successive application of the first derivative,"The finite difference expressions for the first, second and higher derivatives in the first, second or higher order of accuracy can be easily derived from Taylor's expansions. But, numerically, the successive application of the first derivative, in general, is not same as application of the second derivative. First, a case where it works. Let's say that we want to compute second derivative of function $f$ given on 3-points stencil $(i-1, i, i+1)$ . The finite difference formula is: $$\left(\frac{\partial^2 f}{\partial x^2}\right)_i = \frac{1}{h^2}(f_{i-1} - 2f_i + f_{i+1})$$ This result is derived from Taylor's expansions, but it can also be interpreted in the following way. The first derivatives of the first order accuracy at the intervals $(i-1, i)$ and $(i, i+1)$ are: $$\left(\frac{\partial f}{\partial x}\right)_{i-1/2} = \frac{1}{h}(f_i - f_{i-1})$$ and $$\left(\frac{\partial f}{\partial x}\right)_{i+1/2} = \frac{1}{h}(f_{i+1} - f_{i})$$ where I use $i-1/2$ and $i+1/2$ because these derivatives are representative for the cell faces (In the first order I have actually approximated my function as piece-wise linear between the grid points $x_i$ . Therefore, in every grid point the slope on the left and the right hand side of it is not the same.) The second derivative in point $i$ is now: $$\left(\frac{\partial^2 f}{\partial x^2}\right)_{i} = \frac{1}{h}(f'_{i+1/2} - f'_{i-1/2}) = \frac{1}{h^2}(f_{i+1} - f_{i} - (f_i - f_{i-1})) $$ And this is identical to the finite difference expression for the second derivative in the second order of accuracy. I wonder if there is a similar procedure to represent the second derivative in the 4th order accuracy (on 5-points stencil) as successive application of two first order derivative of the lower accuracy (on shorter stencils)? A naive approach would be to apply first derivatives of the second order accuracy to the stencils $(i-2, i-i, i)$ and $(i, i+1, i+2)$ : $$\left(\frac{\partial u}{\partial x}\right)_{i-1} = \frac{1}{2h}(u_i - u_{i-2})$$ and $$\left(\frac{\partial u}{\partial x}\right)_{i+1} = \frac{1}{2h}(u_{i+2} - u_{i})$$ and then to find the second derivative as the first derivative of the previous two: $$\left(\frac{\partial^2 u}{\partial x^2}\right)_{i} = \frac{1}{4h^2}(u_{i+2} - 2u_{i} - u_{i-2})$$ This is obviously not correct or, at least, not the same as application of the second derivative of the 4th order straight away: $$\left(\frac{\partial^2 u}{\partial x^2}\right)_{i} = \frac{1}{12h^2}(-u_{i-2} + 16u_{i-1} + 30 u_i + 16 u_{i+1} - u_{i+2})$$ So, is there a way to reproduce the last equation as a successive combination of first derivatives of the lower accuracy order? If not, why not? Many thanks for help! This is driving me crazy!","['finite-difference-methods', 'numerical-calculus', 'numerical-methods', 'derivatives', 'finite-differences']"
3756729,Problem about the generalized pigeonhole principle,"This problem from Discrete Mathematics and its application's for Rosen What is the least number of area codes needed to guarantee that the 25
million phones in a state can be assigned distinct 10-digit telephone
numbers? (Assume that telephone numbers are of the form NXX-NXX-XXXX,
where the first three digits form the area code, N represents a digit
from 2 to 9 inclusive, and X represents any digit.) The answer I found in the book is : There are eight million different phone numbers of the form NXX-XXXX
(as shown in Example 8 of Section 6.1). Hence, by the generalized
pigeonhole principle, among 25 million telephones, at least $\lceil25,000,000/8,000,000\rceil = 4$ of them must have identical phone numbers.
Hence, at least four area codes are required to ensure that all
10-digit numbers are different Can anyone please explain this answer as I tried a lot to understand it but I can't.","['pigeonhole-principle', 'combinatorics', 'discrete-mathematics']"
3756806,Why isn't the zero ring the field with one element?,"I've heard that in the study of finite fields, and other concepts related to finite fields, mathematicians have found a sort of gap: there are various results and things that seem like they correspond to a field with one element, $\mathbf{F}_1$ , even though there is no such field. Of course, there is an object which seems similar to a field with one element: the zero ring, $\mathbf{Z}_1$ , defined as having one element, $0$ , obeying the equations $$0 + 0 = 0 - 0 = 0 \cdot 0 = 1 = 0.$$ The zero ring seems to behave like a field in every respect, except for the fact that it fails to satisfy $0 \ne 1$ . (But the importance of the axiom $0 \ne 1$ isn't clear to me.) However, in any case, there seems to be consensus that the zero ring is not the field with one element. People say that the zero ring ""does not behave like a finite field"" ( Wikipedia ) or that it ""does not have the features that mathematicians need"" ( this Stack Exchange answer by a deleted user ). I'm not familiar enough with algebraic geometry to understand the properties that $\mathbf{F}_1$ is expected to have. Is there an elementary, undergraduate-level explanation of why it seems like a field with one element ""ought to exist"" in the first place, what properties we expect it to have and why, and how the zero ring fails to satisfy these properties? Or do I need to study algebraic geometry if I want to have an understanding of any of this? (A side question: do we have a good answer to the question of whether the single element of $\mathbf{F}_1$ ought to be $0$ , $1$ , both, or neither?)","['field-theory', 'finite-fields', 'algebraic-geometry']"
3756831,Function $f$ with $f(x_1\cdot x_2)=f(x_1)+f(x_2)$ that is not $\log$?,"Is the log-function the only function that enables the transformation of a product to a sum: $$f(x_1\cdot x_2)=f(x_1)+f(x_2)\,?$$ Yes, I can approximate the log function by a Taylor Series, but are there different functions that fulfill this property? In order to extend the question, is there a (bijective) function (which is also defined for negative values) $f:\mathbb{R}\setminus\{0\} \to \mathbb{R}$ with this property? (This excludes $\log(|x|)$ .) If possible use laymen terms in your answer. Edit: I never realized how much we can do with prime numbers. @ECL is answering my original question, so I will accept it, but out of curiosity and maybe for the sake of completeness:   Can we conclude that there aren't any other functions besides $log$ and $exp$ in $\mathcal{C}^k(D) ,  D \subseteq \mathbb{R}^+$ and $k\geq0$ with the property?","['functional-equations', 'functions', 'logarithms']"
3756882,Double-checking correctness of big O formulas found online,"I found the formulas below on a website of a New Zealand university. This is the solution part to a question on big O formulas and wether they are right or wrong, and I wanted to check if these are actually correct. I specifically have doubts about the fourth staement $5n+8n^2+100n^3 =O(n^4)$ This is assumed correct. Since we usually take the highest leading element, should it not be $O(n^3)$ as opposed to $O(n^4)$ ? Are the other proofs correct?","['logarithms', 'asymptotics', 'functions', 'discrete-mathematics', 'algorithms']"
3756908,"Discretization formula for system of differential equations. ""Solution to one of these is the initial condition of the other"". In which sense?","Consider the following stochastic differential equation \begin{equation}
dy=\left(A-\left(A+B\right)y\right)dt+C\sqrt{y\left(1-y\right)}dW\tag{1}
\end{equation} where $A$ , $B$ and $C$ are parameters and $dW$ is a Wiener increment. Equation $(1)$ will be our point of reference in what follows. Now, first let us consider a ""method"" for equation $\left(1 \right)$ which can be described by the following one-step discretization scheme: \begin{equation}
y_{n+1}=y_n+\left(A-\left(A+B\right)y_n\right)\Delta t +C\sqrt{y_n\left(1-y_n\right)}\Delta W_n + D\left(y_n\right)\left(y_n-y_{n+1}\right)\tag{2}
\end{equation} where $\Delta t$ is the length of the time discretization interval, $\Delta W_n$ is a Wiener increment and $D(y_n)$ is the system of control functions and takes the form $$
D(y_n)=d^0(y_n)\Delta t + d^1\left(y_n\right)|\Delta W_n|
$$ with $$ 
d^1(y)=
\begin{cases}
C\sqrt{\frac{1-\varepsilon}{\varepsilon}}\hspace{0.5cm}\text{if }y<\varepsilon\\
C\sqrt{\frac{1-y}{y}}\hspace{0.5cm}\text{if }\varepsilon\le y<\frac{1}{2}\\
C\sqrt{\frac{y}{1-y}}\hspace{0.5cm}\text{if }\frac{1}{2}\le y\le 1-\varepsilon\\
C\sqrt{\frac{1-\varepsilon}{\varepsilon}}\hspace{0.5cm}\text{if }y>1-\varepsilon
\end{cases}
$$ At this point, let us consider a ""method"" which decomposes $\left(1\right)$ into two equations. Specifically, the first equation is a stochastic one, that consists of the diffusion term of $\left(1\right)$ only (see eqtn $\left(3\right)$ ), while the second one is an ordinary differential equation (see eqtn $\left(4\right)$ ) that consists of the drift part of $\left(1\right)$ . We have: $\begin{equation}
dy_1=C\sqrt{y_1\left(1-y_1\right)}dW\tag{3}
\end{equation}$ $\begin{equation}
dy_2=\left(A-\left(A+B\right)y_2\right)dt\tag{4}
\end{equation}$ This last method approximates the solution to $\left(3\right)$ at each time step using $\left(2\right)$ (and numerical solution to $\left(3\right)$ is used as the initial condition in $\left(4\right)$ ), while $\left(4\right)$ can be solved using the Euler method. Thus, such a method can be described by the following one step discretization formula: $$
y_{n+1}=y_n+\left(A-\left(A+B\right)y_n\right)\Delta t + \dfrac{C\sqrt{y_n\left(1-y_n\right)}\Delta W_n}{1+d^1\left(y_n\right)|\Delta W_n|}\left(1-\left(A+B\right)\Delta t\right)\tag{5}
$$ My doubts: I cannot understand in which way the last method approximates solution to $\left(3\right)$ at each time step using $\left(2\right)$ . Could you please explicit such an approximation? How is it obtained by means of $\left(2\right)$ ? In which sense numerical solution to $\left(3\right)$ is used as the initial condition in $\left(4\right)$ ? Which is such an initial condition? Could you please explicit the way in which solution to $\left(3\right)$ and solution to $\left(4\right)$ are combined so as to obtain discretization formula $\left(5\right)$ ?","['ordinary-differential-equations', 'stochastic-differential-equations', 'numerical-calculus', 'numerical-methods', 'probability-theory']"
3756928,Cat Dog problem using integration,"Consider this equation : $$\sqrt{\left( \frac{dy\cdot u\,dt}{L}\right)^2+(dy)^2}=v\,dt,$$ where $t$ varies from $0$ to $T$ , and $y$ varies from $0$ to $L$ . 
Now how to proceed ? This equation arises out of following problem : A cat sitting in a field suddenly sees a standing dog. To save its life, the cat runs away in a straight line with speed $u$ . Without any delay, the dog starts with running with constant speed $v>u$ to catch the cat. Initially, $v$ is perpendicular to $u$ and $L$ is the initial separation between the two. If the dog always changes its direction so that it is always heading directly at the cat, find the time the dog takes to catch the cat in terms of $v, u$ and $L$ . See my solution below : Let initially dog be at $D$ and cat at $C$ and after time $dt$ they are at $D'$ and $C'$ respectively. Dog velocity is always pointing towards cat. Let $DA = dy, \;AD' = dx$ Let $CC'=udt,\;DD' = vdt$ as interval is very small so $DD'$ can be taken straight line. Also we have $\frac{DA}{DC}= \frac{AD'}{ CC'}$ using triangle property. $\frac{dy}{L}= \frac{dx}{udt}\\ dx = \frac{dy.udt}{L}$ $\sqrt{(dx)^2 + (dy)^2} = DD' = vdt \\ \sqrt{(\frac{dy.udt}{L})^2 + (dy)^2} = vdt $ Here $t$ varies from $0-T$ , and $y$ varies from $0-L$ . Now how to proceed?","['integration', 'mathematical-modeling', 'ordinary-differential-equations', 'calculus', 'physics']"
3756948,Are there sets where it cannot possibly have a metric on it?,"To avoid any ambiguity, a metric space, by definition, is a set $X$ with a distance function $d$ such that $d$ satisfies positivity, symmetry property and triangle inequality. I was wondering does there exist a set where there cannot possibly be equipped with a distance function? In other words this set cannot possibly be made into a metric space? I hope I explained my question sufficiently clear and apologies in advance if this question was not clear. Many thanks in advance!","['examples-counterexamples', 'metric-spaces', 'analysis']"
3756967,Is this the correct use of the $\lor$ symbol?,"I have little to no knowledge about logical operators, so please pardon me if the answer to this question is obvious. Let's say that we have a simple statement related to set theory. It states that if $x \in U$ , where $U$ denotes the universal set and we're talking about a system of two sets only, specifically, $A$ and $B$ , then either $x \in A \cap B$ or $x \in A-B$ or $x \in B-A$ or $x \in (A \cup B)^c$ , then can this s help write like this : $$x \in U \implies x \in A-B ~\lor x \in B-A ~\lor x \in A \cap B ~\lor x \in (A \cup B) ^c$$ Thanks!","['elementary-set-theory', 'logic']"
3756972,Is there a name for the isosceles triangle whose height is equal to its base?,"This triangle seems ""special"" to me, because its height is equal to the length of its base, so when inscribed in a square the top vertex is exactly the middle of the top side of the square. $\hspace{4cm}$ Is there a name for the isosceles triangle whose height is equal to its base? Seems useful in architecture, engineering and maybe have some symbolism attached to it. Does it have a name?","['geometry', 'terminology']"
3756979,Confusion in proving $\phi: Z_n \to Z_k$ defined by $\phi (x)=x \mod k$ to be a homomorphism.,"It is to be proven that if $k|n$ and $\phi: Z_n \to Z_k$ is defined by $\phi (x)=x\mod k $ , then $\phi$ is a homomorphism. $\phi$ is well defined as : $x=y\implies x\mod k=y \mod k$ To prove that $\phi$ is operation preserving, let $x,y \in Z_n$ , it is possible that $x+y \notin Z_n$ so we consider $\phi ((x+y) \mod n)=((x+y)\mod n)\mod k \tag{1}$ I got stuck here. I want to show that $\phi ((x+y) \mod n)=\phi(x)+\phi (y) \tag{2}$ . The problem is that since in general, $(x+y) \mod n \mod k \ne (x+y) \mod k \mod n$ and also $(x+y) \mod n=(x\mod n+ y\mod n) \mod n$ , I don't know how to show that $(1)$ implies $(2)$ . Thanks for your time.","['group-homomorphism', 'group-theory', 'abstract-algebra']"
3757026,Can you write $1-x-\frac{x^2}{2!}+\frac{x^3}{3!}-\dots$ with elementary functions,"Can you write $$1-x-\frac{x^2}{2!}+\frac{x^3}{3!}-\frac{x^4}{4!}+\frac{x^5}{5!}+\frac{x^6}{6!}-\frac{x^7}{7!}-\dots$$ with elementary functions, where the function is related to the Thue-Morse sequence stated here ?
I was told it converges with all inputs. But I don't know how to write it in elementary functions. Thanks","['elementary-functions', 'calculus', 'taylor-expansion']"
3757038,How can I prove that 3 planes are arranged in a triangle-like shape without calculating their intersection lines?,"The problem So recently in school, we should do a task somewhat like this (roughly translated): Assign a system of linear equations to each drawing Then, there were some systems of three linear equations (SLEs) where each equation was describing a plane in their coordinate form and some sketches of three planes in some relation (e.g. parallel or intersecting at 90°-angles. My question For some reason, I immediately knew that these planes: belonged to this SLE: $$ x_1 -3x_2 +2x_3 = -2 $$ $$ x_1 +3x_2 -2x_3 = 5 $$ $$-6x_2 + 4x_3 = 3$$ And it turned out to be true. In school, we proved this by determining the planes' intersecting lines and showing that they are parallel, but not identical. However, I believe that it must be possible to show the planes are arranged like this without a lot of calculation. Since I immediately saw/""felt"" that the planes described in the SLE must be arranged in the way they are in the picture (like a triangle). I could also determine the same ""shape"" on a similar question, so I do not believe that it was just coincidence. What needs to be shown? So we must show that the three planes described by the SLE cut each other in a way that I do not really know how to describe. They do not intersect with each other perpendicular (at least they don' have to to be arranged in a triangle), but there is no point in which all three planes intersect. If you were to put a line in the center of the triangle, it would be parallel to all planes. The three planes do not share one intersecting line as it would be in this case: (which was another drawing from the task, but is not relevant to this question except for that it has to be excluded) My thoughts If you were to look at the planes exactly from the direction in which the parallel line from the previous section leads, you would see something like this: The red arrows represent the normal of each plane (they should be perpendicular). You can see that the normals somehow are part of one (new) plane. This is already given by the manner how the planes intersect with each other (as I described before).
If you now were to align your coordinate system in such a way that the plane in which the normals lie is the $x_1 x_2$ -plane, each normals would have an $x_3$ value of $0$ . If you were now to further align the coordinate axes so that the $x_1$ -axis is identical to one of the normals (let's just choose the bottom one), the values of the normals would be somehow like this: $n_1=\begin{pmatrix}
a \\
0 \\
0 
\end{pmatrix}$ for the bottom normal $n_2=\begin{pmatrix}
a \\
a \\
0 
\end{pmatrix}$ for the upper right normal and $n_3=\begin{pmatrix}
a \\
-a \\
0 
\end{pmatrix}$ for the upper left normal Of course, the planes do not have to be arranged in a way that the vectors line up so nicely that they are in one of the planes of our coordinate system. However, in the SLE, I noticed the following: -The three normals (we can simpla read the coefficients since the equations are in coordinate form) are $n_1=\begin{pmatrix}
1 \\
-3 \\
2 
\end{pmatrix}$ , $n_2=\begin{pmatrix}
1 \\
3 \\
-2 
\end{pmatrix}$ and $n_3=\begin{pmatrix}
0 \\
-6 \\
4 
\end{pmatrix}$ . As we can see, $n_1$ and $n_2$ have the same values for $x_1$ and that $x_2(n_1)=-x_2(n_2)$ ; $x_3(n_1)=-x_3(n_2)$ Also, $n_3$ is somewhat similar in that its $x_2$ and $x_3$ values are the same as the $x_2$ and $x_3$ values of $n_1$ , but multiplied by the factor $2$ . I also noticed that $n_3$ has no $x_1$ value (or, more accurately, the value is $0$ ), while for $n_1$ and $n_2$ , the value for $x_1$ is identical ( $n_1=1$ ). Conclusion I feel like I am very close to a solution, I just don't know what to do with my thoughts/approaches regarding the normals of the planes. Any help would be greatly appreciated. How can I show that the three planes are arranged in this triangular-like shape by using their normals, i.e. without having to calculate the planes' intersection lines? (Probably we will need more than normals, but I believe that they are the starting point). Update: I posted a new question that is related to this problem, but is (at least in my opinion) not the same question.","['systems-of-equations', 'vectors', 'linear-algebra', 'geometry']"
3757047,Is it possible to reflect over non-linear functions like quadratics or cubics?,This is a problem I have been investing for a while now and I have come up with several ideas. For the purpose of simplicity I am taking $y=x^2$ as my example and reflecting $y=0$ over it. Take the tangent of certain points on $x^2$ and relate the distance from the tangent to $y=0$ to the reflection of the point over $y=x^2$ (might be a bit confusing) Take the square root of the quadratic to linearize it then reflect the line over linear function and square it afterwards. Because the quadratic is symmetrical both sides will be the same. Try to derive a common equation using a similar method to what is shown here except for a quadratic https://www.slideshare.net/hcr1991/reflection-of-a-point-about-a-line-a-plane-in-2d-3d-space-geometry-by-hcr,"['reflection', 'functions']"
3757048,"How do I show $\lim_{n \to \infty} \int_0^\infty \frac{n}{n^2+x}\sin(\frac{1}{x})\, dx = 0\,$?","How do I show $$\lim_{n \to \infty} \int_0^\infty \frac{n}{n^2+x}\sin\left(\frac{1}{x}\right)\, dx = 0\,\,?$$ I've tried splitting into the cases where $x \leq 1$ and $x \geq 1$ but I am having trouble finding bounds so that I can apply the dominated convergence theorem.","['limits', 'measure-theory', 'real-analysis']"
3757141,How to solve this system of ODE: $ u'= - \frac{2v}{t^2}$ and $v'=-u $?,"I have this system of differential equations: $$ \left\{\begin{array}{ccc}u'&=& - \dfrac{2v}{t^2}\,, \\ v'&=&-u
\,.\end{array}\right. $$ I want to find the general solution by deriving an Euler differential equation for $v$ and giving a fundamental system. So $v''= -u' \implies v''t^2-2v=0 $ . I am having issues solving this Euler differential equation.  How do I proceed?","['calculus', 'ordinary-differential-equations']"
3757149,"On the diophantine equation $x^{m-1}(x+1)=y^{n-1}(y+1)$ with $x>y$, over integers greater or equal than two","I don't know if the following diophantine equation (problem) is in the literature. We consider the diophantine equation $$x^{m-1}(x+1)=y^{n-1}(y+1)\tag{1}$$ over integers $x\geq 2$ and $y\geq 2$ with $x>y$ , and over integers $m\geq 2$ and $n\geq 2$ . These are four integral variables $x,y,m$ and $n$ . The solutions that I know for the problem $(1)$ are two, the solution $(x,y;m,n)=(3,2;2,3)$ and $(98,21;2,3)$ . Question 1. Do you know if this problem is in the literature? Alternatively, if this problem isn't in the literature can you find more solutions? If the equation or problem $(1)$ is in the literature please refer it answering this question as a reference request, and I try to search and read the statements for new solutions from the literature. In other case compute more solutions or add upto what uppers limits you got evidence that there aren't more solutions. Question 2. I would like to know what work can be done with the purpose to know if the problem $(1)$ have finitely many solutions $(x,y;m,n)$ . I mean what relevant reasonings or heuristics you can to deduce with the purpose to study if the problem have finitely solutions. If this second question is in the literature, please refer the literature answering this question as a reference request, and I try to search and read the statements from the literature.","['prime-factorization', 'divisibility', 'number-theory', 'elementary-number-theory', 'diophantine-equations']"
3757158,Extensions of $\mathbb{Z_3}$ by $\mathbb{Z_9}$,"I'm working through MacLane's Homological Algebra , and I was trying to compute some easy examples of Ext groups, but just confused myself: I'm trying to compute all three (I know there's three by the first theorem in the third chapter) extensions of $Z_9$ by $Z_3$ . If I resolve $Z_3$ and set it up, it looks like this: $$\begin{matrix}
0 & \to & 3Z & \xrightarrow{i} & Z & \xrightarrow{\pi} & Z_3 & \to & 0 \\
\ & \   & \downarrow^{h^i} & \ & \downarrow^{\psi} \ & \ & \downarrow^{\simeq} \\
0 & \to & Z_9 & \xrightarrow{i'} & P & \xrightarrow{\pi'} & Z_3 & \to & 0
\end{matrix}$$ Now as he proves, the class of the extension we get by filling in the bottom given $h^i$ is a function of the homotopy class of $h^i$ (considered as a morphism of complexes lifting the identity on $Z_3$ ). To fill in the bottom (can't figure out how to make $\psi, i', \pi'$ dashed). We compute the pushout of the left square. Ok, so starting with $h^0 = 0$ , it's easy to see that I just get the split extension as expected. Then taking $h^1(3n) = n \text{ mod } 9$ , I get $Z_{27}$ , no problem. Next I choose $h^2(3n) = 3n \text{ mod } 9$ . Then to compute the pushout $P \simeq \frac{Z_9 \bigoplus Z}{N}$ for $N = \{ (-3n \text{ mod } 9, 3n) : 3n \in 3Z \}$ . So after starting at this for a day or two, I believe this is metacycic? Anyways, this group of order 27 is something like (here's where I get v. confused): $P = \langle a,b \mid 3a = 3b, 9a = 9b = 0, b^{-1} a b = a\rangle$ . But looking at grouppros groups of order 27, the semidirect product I think this should be ( https://groupprops.subwiki.org/wiki/M27 ) doesn't have these relations (or atleast it's not obvious how to change basis), and moreover isn't abelian. What's going on? What is the third isomorphism class of extensions here? Thanks! As I was told in the comments, there are only two abelian extensions of $Z_9$ by $Z_3$ . I was going based on MacLane's Proposition 1.1 in Chapter 3, which says that for Abelian A, $\text{Ext}_Z(Z_m,A) \simeq A/mA$ . Still not sure why I interpreted that wrong, but I'll update this when I figure that out. Also, not sure why P as defined above isn't a group, but that's probably not too hard once I think about it in a less braindead state (thought it does seem to fit the description of metacyclics by presentations here https://mathworld.wolfram.com/MetacyclicGroup.html ).","['homological-algebra', 'group-theory', 'group-cohomology', 'exact-sequence']"
3757201,Every Lie algebra endomorphism of $\mathfrak{so}(3)$ is given by the anticommutator with a symmetric matrix.,"I want to prove that for every Lie algebra endomorphism $T$ on $\mathfrak g=\mathfrak{so}(3)$ , there exists a symmetric $3\times 3$ matrix $B$ such that $T( x)=Bx+xB$ for all $x \in \mathfrak g$ . I cannot figure this out. Edit: This is a problem in the book Quantum Mechanics for Mathematicians by Takhtajan Edit The endomorphism is assumed to be symmetric.","['matrices', 'semisimple-lie-algebras', 'lie-algebras', 'symmetric-matrices']"
3757202,Are all finite-dimensional algebras of a fixed dimension over a field isomorphic to one another?,"Suppose I have a finite-dimensional algebra $V$ of dimension $n$ over a field $\mathbb{F}$ . Then $V$ is an $n$ -dimensional vector space and comes equipped with a bilinear product $\phi : V \times V \to V$ . Suppose now that I have another finite-dimensional algebra $W$ of dimension $n$ over $\mathbb{F}$ equipped with a bilinear product $\psi: W \times W \to W$ . Certainly, $V$ and $W$ are isomorphic as vector spaces but are they isomorphic as $\mathbb{F}$ -algebras? The question I'm really asking here is - Are all $n$ -dimensional algebras over $\mathbb{F}$ isomorphic to one another? If the answer is yes, then this is my attempt at constructing such an isomorphism. Suppose I want to define an $\mathbb{F}$ -algebra isomorphism between $V$ and $W$ . To do this I'd need to define a map $f : V \to W$ such that $f(ax) = af(x)$ for all $a \in \mathbb{F}, x \in V$ $f(x+y) = f(x) + f(y)$ for all $x, y \in V$ $f(\phi(x, y)) = \psi(f(x), f(y))$ for all $x, y \in V$ If $\{v_1, \dots, v_n\}$ and $\{w_1, \dots, w_n\}$ are bases for $V$ and $W$ respectively then both $\phi$ and $\psi$ being bilinear maps are completely determined by their action on basis vectors $\phi(v_i, v_j)$ and $\psi(w_i, w_j)$ for $1 \leq i, j, \leq n$ . It turns out that $$\phi(v_i, v_j) = \sum_{k=1}^n \gamma_{i,j,k}v_k$$ and $$\psi(v_i, v_j) = \sum_{k=1}^n \xi_{i,j,k}w_k$$ for some collection of scalars $\gamma_{i,j,k}$ and $\xi_{i,j,k}$ called structure coefficients . So then if both the $n^3$ collections of scalars $\gamma_{i,j,k}$ and $\xi_{i,j,k}$ are all non-zero then we can define $f : V \to W$ by $$f(a_1v_1 + \cdots + a_nv_n) = a_1 \frac{\xi_{i,j,1}}{\gamma_{i,j,1}}w_1 + \cdots + \frac{\xi_{i,j,n}}{\gamma_{i,j,n}}w_n$$ and it will turn out that $f$ is the desired isomorphism of algebras as one can then check that $f(\phi(v_i, v_j)) = \psi(w_i, w_j) = \psi(f(v_i), f(v_j))$ for all $i$ and $j$ . However what if it's the case that for $\phi$ some $\gamma_{i, j, k}$ is zero and the corresponding $\xi_{i, j, k}$ is non-zero? I don't see any way to get an isomorphism in that case. Is it still possible to construct an isomorphism in that case?","['ring-isomorphism', 'vector-spaces', 'ring-theory', 'abstract-algebra', 'algebras']"
3757209,Embedding whole flat 2-Torus in $\Bbb R^3$,"I am trying to better understand an isometric embedding of a flat 2-Torus in $\Bbb R^3$ via a $C^1$ map. Here is a visualization involving $C^1$ fractals: This embedding is warped by an infinite sequence of waves called corrugations, according to the Hévéa Project (thanks to @dvitek for the reference). Due to this infinity, it is unclear how the points of this surface can be defined. My question is if this surface can be described as a function of the $x,y,z$ coordinates in $\Bbb R^3$ either in the explicit or parametric way.","['metric-spaces', 'riemannian-geometry', 'differential-geometry']"
3757264,Proof verification: Baby Rudin Chapter 5 Exercise 11,"Baby Rudin, Chapter 5, Exercise 11 Suppose $f$ is defined in a neighborhood of $x$ , and suppose $f^{\prime\prime}(x)$ exists. Show that \begin{equation}\tag{11.0}
    \lim_{h \to 0} \frac{f(x+h)+ f(x-h)-2f(x)}{h^2} = f^{\prime\prime}(x)
\end{equation} My attempt: Firstly, notice that we can obtain alternative and equivalent versions of the definition of the derivative by making some notational maneuvers in the standard definition. We state the new definitions as follows: Let $f$ be defined (and real valued) on $[a, b]$ . For any $x\in [a, b]$ , the rate of change of the function $f$ at the point $x$ , denoted by $f^{\prime}(x)$ , is defined as \begin{equation}\tag{11.1}
   f^{\prime}(x) = \lim_{h \to 0}\; \frac{f(x)-f(x-h)}{x-(x-h)} = \lim_{h \to 0}\; \frac{f(x)-f(x-h)}{h}
\end{equation} where $a< t< b$ and $t \ne x$ . Moreover, leaving everything else unchanged, we can rewrite $(11.1)$ as \begin{equation}\tag{11.2}
   f^{\prime}(x) = \lim_{h \to 0}\; \frac{f(x+h)-f(x)}{x+h-(x)} = \lim_{h \to 0}\; \frac{f(x+h)-f(x)}{h}
\end{equation} Next, if we assume that $f^{\prime}(x)$ exists in a neighborhood of $x$ and $f^{\prime}$ is differentiable at the point $x$ , then, using (11.2) we can define $f^{\prime\prime}(x)$ as: \begin{equation}\tag{11.3}
   f^{\prime\prime}(x) = \lim_{h \to 0}\; \frac{f^{\prime}(x+h)-f^{\prime}(x)}{h}
\end{equation} We only need to perform some routine algebra to show (11.0). Suppose $f$ is defined in a neighborhood of $x, [a, b]$ , and suppose $f^{\prime\prime}(x)$ exists. Then, we know that $f^\prime$ exists in a neighborhood of $x$ and is differentiable at $x$ . Thus, (11.3) holds and by (11.1), we have \begin{equation}\tag{11.4}
    f^{\prime}(x+h) = \lim_{h \to 0}\; \frac{f(x+h)-f[(x+h)-h]}{(x+h)-[(x+h)-h]} = \lim_{h \to 0}\; \frac{f(x+h)-f(x)}{h}
\end{equation} By substituting (11.4) and (11.1) in (11.3), we get \begin{align*}
    f^{\prime\prime}(x) &= \frac{1}{h}\cdot \lim_{h \to 0}\; \left[\frac{f(x+h)-f(x)}{h} -  \left(\frac{f(x)-f(x-h)}{h}\right)\right] \\
    &= \frac{1}{h^2} \lim_{h \to 0}\; \left[f(x+h)-f(x)-f(x)+f(x-h)\right]
\end{align*} which proves (11.0). My question: Is my proof correct? If not, how can the mistakes in this proof be patched up? Especially, is the expression in (11.4) and the process for obtaining (11.4) correct? I've basically shown that the right hand sides of (11.4) and (11.2) are the same, despite the fact their left hand sided are not equal.","['proof-explanation', 'solution-verification', 'derivatives', 'real-analysis']"
3757270,How to measure the angle between two parallel lines?,"In some geometries, parallel lines ""meet/touch/coincide"" at infinity. This being the case, there must necessarily be an angle between them. I was wondering what the ""value"" of this angle would be. Is it always $\pi/2$ ? Is it $0$ ? Is it infinite? is it $2\pi$ ? Or is there some formula which makes the angle variable depending on the perpendicular distance between the lines? I'm particularly interested in answers that approach the question from multiple different geometries, including geometries where parallel lines don't meet (in which case the question becomes, ""what is the angle between two lines which don't meet?""). As mentioned, the concept of ""angle"" is meaningless in projective geometry. What does this question look like from the perspective of hyperbolic, euclidean, and elliptical geometries? (It has been a while since I've done serious mathematics and my terminology might be off. I've put words which I'm not sure about in scare quotes. Feel free to edit.)","['hyperbolic-geometry', 'angle', 'projective-geometry', 'geometry']"
3757281,Is there analytical solution to this heat equation?,"I have a PDE of the following form: $$\frac{1}{\sin\theta}\frac{\partial}{\partial\theta}\left(\sin\theta\frac{\partial f}{\partial\theta}\right)+\frac{1}{\sin^2\theta}\frac{\partial^2f}{\partial\phi^2} = A\cos\theta\,\max(\cos\phi, 0) + B-Cf^4~.$$ Does anyone know if an analytical solution exists for this equation? We can assume periodic boundary condition such that $f(\theta,0)=f(\theta, 2\pi)$ .","['elliptic-equations', 'multivariable-calculus', 'heat-equation', 'partial-differential-equations']"
3757356,Properties needed to define Derivatives on Topological space,"I just started learning topology and was curious about defining derivatives on general topological spaces. Since we can define continuous functions on Topological spaces, my question is what additional properties one would need to define derivatives on Topological spaces. I guessed one might only need converging sequences to define derivative, so space must have, metrizability: to define some sort of distance between points so one can define converging sequences on space. Hausdorff property: so convergence would be unique. but on the other hand, these properties are conserved under homeomorphism, where differentiability does not. so, there should be some more properties (maybe other than topological properties) one would need to define derivatives, and I'm not sure what kind of property it would be that conserves differentiability. I hope my question makes sense. Thanks.","['general-topology', 'derivatives', 'real-analysis']"
3757386,The projective closure of the twisted cubic curve,"I'm now reading Hartshorne's Algebraic Geometry and trying to solve Exercise 2.9(b). Let $Y$ be an affine variety in $\mathbb{A}^n$ . Identifying $\mathbb{A}^{n}$ with the open subset $U_0$ of $\mathbb{P}^n$ by the homeomorphism $\varphi_{0}: (x_0,x_1,..,x_n)\mapsto (\dfrac{x_1}{x_0},...,\dfrac{x_n}{x_0})$ . Then we can speak about $\bar{Y}$ , the projective closure of $Y$ in $\mathbb{P}^{n}$ . (a) Show that $I(\bar{Y})$ is an ideal generated by $\beta(I(Y))$ (b) Prove that if $f_1,...,f_r$ generate $I(Y)$ , then $\beta(f_1),...,\beta(f_r)$ do not necessarily generate $I(\bar{Y})$ , using the example of the twisted cubic curve. I have proved (a). My question is on the projective closure of the twisted cubic curve. In exercise 1.2 of Hartshorne, the affine twisted cubic curve $Y$ is defined as the image of the map $$
v: k \rightarrow \mathbb{A}^3; \quad t \mapsto (t, t^2, t^3).
$$ Many questions and answers related to this question on MSE seems to take it for granted or claim that it is trivial that the projective closure of $Y$ is the image of the map $$
\bar{v}: \mathbb{P}^1 \rightarrow \mathbb{P}^3; [X_0, X_1] \mapsto [X_0^3, X_0^2 X_1, X_0 X_1^2, X_1^3].
$$ My question is: Why the projective closure $\bar{Y}$ is $\mathrm{image}(\bar{v})$ ? I have tried to prove but have no ideas on this. I have looked up book like Joe Harris' Algebraic Geometry: A First Course and the definition of $v$ and $\bar{v}$ appears in Example 1.10. But Prof. Joe Harris did not show that as well. Thank you for your helps! P.S. The LaTeX code for the quoted exercise is adapted from MSE question 275034, i.e. Projective closure: How to determine?","['affine-varieties', 'algebraic-geometry', 'projective-varieties']"
3757548,Correlation of conditional expectation of uncorrelated random variables,"Let $X,Y\in\mathcal{L}_{2}\left(\Omega,\mathcal{F},\mathbb{P}\right)$ satisfy $\mathbb{E}\left[X\right]=\mathbb{E}\left[Y\right]=\mathbb{E}\left[XY\right]=0$ , and $\mathbb{E}\left[X^2\right]=\mathbb{E}\left[Y^2\right]=1$ . The problem asks to show (i) $\mathbb{E}\left[\mathbb{E}\left[X|\mathcal{G}\right]\mathbb{E}\left[Y|\mathcal{G}\right]\right]\leq\frac12$ for any sub $\sigma$ -algebra $\mathcal{G}\subset \mathcal{F}$ , and (ii) to find $\mathcal{G}\subset\mathcal{F}$ for which the equality holds, assuming that $X,Y$ are i.i.d. Any help is appreciated. Thanks in advance!","['conditional-expectation', 'correlation', 'inequality', 'probability-theory', 'random-variables']"
3757563,Geometric meaning of generating graded algebras in degree 1.,"It is well known that gradings of a commutative ring correspond to actions of the multiplicative group on the corresponding affine variety. Frequently one encounters the condition that with respect to a grading, the ring is generated by degree 1 homogeneous elements. What does this condition mean in terms of the multiplicative group action?","['graded-rings', 'reference-request', 'algebraic-geometry', 'group-actions', 'commutative-algebra']"
3757564,Literature review of a (possibly) open differential geometry problem,"I recently came across an apparently simple-sounding problem in basic differential geometry, as mentioned below, Problem Let $S \subset \mathbb{R}^3$ be a closed surface of diameter $d$ . Suppose that there exists a constant $h < d$ so that whenever a pair of planes separated by a distance of $h$ intersects $S$ , the area of $S$ contained between these planes is constant. Does it then follow that $S$ is a sphere? I searched for references/reviews regarding progress made for this problem, but could not find anything relevant. It would be helpful if someone could point out any relevant material/concepts regarding this problem.","['soft-question', 'reference-request', 'differential-geometry']"
3757587,Why does the plot of $f(x)=|\cos x|-|\sin x|$ look almost piecewise linear?,I recently stumbled upon an interesting plot that I - even until today - could not quite explain: It's the plot of $f(x) = \lvert \cos(x) \rvert - \lvert \sin(x) \rvert$ . I mean this is almost piecewise linear... I tried to derive this shape from the Taylor series but I could not quite see it. Does anyone have some mathematical intuition for me concerning the shape of this plot?,"['trigonometry', 'calculus', 'algebra-precalculus', 'real-analysis']"
3757598,"If sets $A, B$ in Euclidean space are closed sets, they have the same boundary and their interior's intersection is non-empty, can we say $A=B$?","If sets $A, B$ in Euclidean space are closed sets, they have the same boundary and their interiors intersection is non-empty, can we say $A=B$ ? Any suggestions and comments are welcome!","['general-topology', 'real-analysis']"
3757616,$\mathbb{Z}_p=\varprojlim \mathbb{Z}/p^{n}\mathbb{Z}$ is uncountable.,The ring of $p$ -adic integers is given by $\mathbb{Z}_p=\varprojlim \mathbb{Z}/p^{n}\mathbb{Z}$ . From this description how can we conclude that $\mathbb{Z}_p$ is uncountable ? It follows from the description that each nonzero element of $\mathbb{Z}_p$ is of infinite order (as an element of component wise additive group $\mathbb{Z}_p$ ). But I cannot produce any contradiction assuming countability of $\mathbb{Z}_p$ . Help me.,"['formal-completions', 'p-adic-number-theory', 'ring-theory', 'abstract-algebra', 'elementary-set-theory']"
3757621,Extreme points of a function at domain ends,"Consider the following function: $f(x) = x\sqrt{9-x^2}$ $\quad \quad\quad \quad\quad \quad\quad \quad\quad \quad\quad \quad $ $f'(x) = \frac{-2x^2+9}{\sqrt{9-x^2}}$ and $D(f) = [-3,3]$ therefore the critical points of the function are $x_{c_i} = \left\{ -3, -\frac{3\sqrt2}{2}, \frac{3\sqrt2}{2}, 3 \right\}$ Apparently the points $\{-\frac{3\sqrt2}{2}, \frac{3\sqrt2}{2}\}$ are global minumum and global maximum respectively. But what about the domain ends $\{-3, 3\}$ ? Are they considered to be saddle points, local minimums, or local maximums and why?","['maxima-minima', 'calculus', 'functions']"
3757648,catching 10 fish: a combinatorics question,"Suppose that 10 fish are caught at a lake that contains 5 distinct types of fish. among the 10 fish at least 2 are trout. also, it is given that all 5 different types of fishes have been caught at least once. How many different outcomes are possible, where an outcome specifies the numbers of caught fish of each of the 5 types my attempt: let $(x_1+1),(x_2+1),(x_3+1),(x_4+1) $ represent the numbers of fish caught of type 1, 2, 3 and 4 respectively. let $(x_5+2)$ represent the number of trout fishes caught. then it is given that $(x_1+1)+(x_2+1)+(x_3+1)+(x_4+1)+(x_5+2) = 10$ $=>x_1+x_2+x_3+x_4+x_5 = 4$ , where $x_1, x_2, x_3, x_4,x_5$ are non-negative integers. => the total number of outcomes are $\binom{4+5-1}{5-1} = \binom{8}{4} = 70$ , is this correct?","['combinations', 'combinatorics']"
