question_id,title,body,tags
3397697,Math of Jury Sizes,"If we go by the assumption that a Jury is a representation of the public at large, then is 12 people statistically signficant? When doing any scientific survey or poll, a sample of 12 people would be laughable. Particularly if the results are close to 50-50. Is there any math done on this? For example. We might go by some axioms such as, we should only convict someone if 2/3 of the public think they are guilty. Then with that we can calculate the probability that a jury of 12 will wrongly convict or wrongly release a suspect. For example if the proportional of the public that think the man is guilty is $x$ . Then the probability that the jury will convict is if we convict if 2/3 of the Jury (8 or more men) say they are guilty is: $$P(convict) = x^{12} + 12 (1-x)x^{11} + 66 (1-x)^2 x^{10} + 220 (1-x)^3 x^9 + 594 (1-x)^4 x^8$$ So for example if 3/4 of the public think the man is guilty he should be convicted. But the jury will convict 88% of the time and release on 12% of the time. With the assumptions here is my question: Assume public is effectively infinite A man should be convicted if 2/3 of the public think he is guilty. Given a number of jurors $N$ and what proportional of jurors $f(N)$ should we convict a man so that there is a 95% agreement with the public and the jury when 3/4 of the public think the man is guilty. (Extra: Does this suggest an ideal jury size?)","['applications', 'statistics', 'combinatorics', 'probability']"
3397702,Where is the flaw in my stability analysis of this ODE?,"The ODE $${d^2x\over dt^2}=-kx$$ can be converted in the system of linear equations as $$\begin{align}
{dx\over dt} & =v\\
{dv\over dt} &= -kx\\
\end{align}$$ Using Euler’s method, given $x_n$ and $y_n$ and for the time step $\Delta t$ , the next values can be determined as $$\left[ \begin{matrix}
x_{n+1}\\
v_{n+1}\\
\end{matrix}\right] = 
\left[\begin{matrix}
1&\Delta t\\
-k\Delta t&1
\end{matrix}\right]
\left[\begin{matrix}
x_n\\
v_n\\
\end{matrix}\right].$$ Now the absolute value of the (possibly complex) eigenvalues should be less than $1$ for this algorithm to be stable. But the eigenvalues turn out to be $1\pm i\sqrt{k}\Delta t$ whose absolute values are strictly greater than $1$ for any nonzero time-step $\Delta t$ . So the algorithm should not work for any value of $\Delta t$ , however small. But clearly, this is not the case as my programs do come up with (an approximate) solution though. So where is the flaw in my reasoning?","['numerical-linear-algebra', 'numerical-methods', 'ordinary-differential-equations']"
3397730,"If $X/S$ is smooth of relative diemsnion $n$ over characteristic $p$, then $F_{X/S}$ is finite locally free of rank $p^n$?","Given a morphism $f:X\to Y $ , we say $f$ is finite locally free of rank $k$ if $f_* \mathcal{O}_X$ is locally free of rank $k$ as an $\mathcal{O}_Y$ -module. see this tag for details about finite locally free morphism. See this tag for details about relative Frobenius morphism Let $S$ be a scheme of characterisctic $p$ , and $f:X\to S$ be a smooth morphism of relative dimension $n$ , (so locally it factors through $\mathbb{A}^n_S$ , $U\stackrel{etale}{\to} \mathbb{A}_S^n\to S$ ), then we want to show that the relative Frobenius morphism $F_{X/S}$ is finite locally free of rank $p^n$ . Since this question is local, We can assume $X\stackrel{etale}{\to} \mathbb{A}_S^n\to S$ . It is not hard to show $F_{\mathbb{A}^n_S/S}$ is finite locally free of rank $p^n$ , but I can't relate it with $F_{X/S}$ .","['etale-cohomology', 'algebraic-geometry', 'schemes']"
3397827,Rational functions on algebraic curves,"This might be super elementary but, after having read abstract concepts of algebraic curves, I have trouble dealing with actual examples. For instance, why is the $\phi=\dfrac{y}{x}$ a rational function on the curve $F=y^2+y+x^2$ ? I know that any rational function on this curve should be of the form $\{\phi=\dfrac{f}{g}:f,g\in K[x,y]/(F), g\neq 0\}$ , but what do I need to actually check to show that this is a rational function on $F$ ? Also, if anybody can give more examples of this kind I will be very grateful. Thanks for your help in advance.","['algebraic-curves', 'algebraic-geometry']"
3397855,Probability someone never gets promoted?,"I was doing some simulations on societal structures. For example, given a population, with a heirachy of N levels. e.g. one prime-minister, 10 cabinet members, 100 MPs, and so on. Let $P$ be the number of people that a person on a higher level has under their control. (In this case P=10). And assuming that everyone starts their carreer on the bottom of the heirachy. And that everyone retires at a specified age. When someone retires, one person on the level below randomly gets promoted (and someone moves up to replace them and so on) and one new person starts at the bottom level. (We can assume some steady birth rate so the working population stays constant.) Then I asked questions such as how long will the person at the top stay in power? Let $L$ be the length of anyone's career before retirement. (e.g. 50 years). I found that the average length of time the top person will stay in their job will be $L/N$ years. In other words for a flatter heirachy the ruler will stay in basically half their life. Whereas for a tall heirachy the ruler will usually be very old by the time they get to the top and only stay there for a short time. (Think of the case where $N\approx 1$ and the case where $P\approx 1$ ). In fact I compared this with the UK heirachical structure (I set $P=30$ and $N\approx 5.3$ ) and I get the length of time for a prime minister to be roughly the right 10 years. Which is kind of right. But I also wanted to calculate the probability that someone in the lowest heirachichy will never get promoted and stay on the bottom rung all their life? Or to be more general the probability that someone will reach level $M$ before retirement.","['applications', 'statistics', 'probability']"
3397892,Why is $\bigcap_{\lambda\ge0}I^\lambda_0 = \bigcap_{\lambda\lt0}I^\lambda_0$?,"In ""Introductory Mathematics: Algebra and Analysis"" by Smith the excercise 1.2 (k) reads: "" ... write down the set which is different ... In parts (j) and (k), the symbol $I^s_r$ denotes the set of real numbers $\{\eta\ |\ r\le\eta\lt s\}$ where $r$ and $s$ are themselves real numbers. (k) (i) $\bigcap_{\lambda\gt0}I^\lambda_0$ ,  (ii) $\bigcap_{\lambda\ge0}I^\lambda_0$ , 
 (iii) $\bigcap_{\lambda\lt0}I^\lambda_0$ "" My thinking is that (i)=(ii) which is a set of 0 to $\lambda$ , but not included. The (iii) will always have {} because $\lambda\lt0$ will never satisfy $I^\lambda_0$ ; $\{\eta\ |\ 0\le\eta\lt \lambda\}$ . The answer on the other hand says that (i) differs from the other two; which implies (ii)=(iii). Why?",['elementary-set-theory']
3397903,"True or False: If the product of n elements of a group is the identity element, it remains so no matter in what order the terms are multiplied.","I am working my way through Charles Pinter's book: A Book of Abstract Algebra. From recommendations on this site, I found a page/web address on Wisconsin University's Math Department that provides solutions to many (perhaps all) of the abundant exercises that are present in Pinter's book. One of the proposed solutions to Pinter's exercises is the following generalization: If the product of n elements of a group is the identity element, it remains so no matter in what order the terms are multiplied. I take issue with this claim and think it is only valid if the group is abelian. Using a simple 3 element example, consider: $a\circ b \circ c = e$ Using the definition of inverses (and knowing that inverses commute...by defintion) and the associative law, I generated the following cases that must be true: $a \circ (b \circ c) =e$ and therefore $(b \circ c) \circ a =e$ $(a \circ b) \circ c=e$ and therefore $c \circ (a \circ b)=e$ However, there are still several permutations of this list of elements that require consideration...for example: $a \circ (c \circ b) =e$ It seems to me this can only be true if the group is abelian. Therefore, should the solution manual be amended to say: If the product of n elements of an abelian group is the identity element, it remains so no matter in what order the terms are multiplied. ?",['group-theory']
3398037,Generating function proof of floor identity,"I have a problem in a book I am working in that asks: Let $c_n = \binom{n}{\lfloor{n/2}\rfloor}$ . Prove: $$\sum_{k=0}^{n} \binom{n}{k}c_kc_{n-k} = c_nc_{n+1}$$ The solution given is some counting argument, but I am interested in a solution involving generating functions since the $c_kc_{n-k}$ term looks really tempting.","['combinatorics', 'generating-functions']"
3398042,Sum of the digits in base $p+1$,"Check link for M.O. post https://mathoverflow.net/q/346862/149083 Definition Let $W$ be the function ,  defined as $W(a,b)=r$ given $a,b\in \mathbb{Z_+}$ and $a>1$ Take $m$ to be the integer s.t. $a^{m+1} \ge b > a^{m}$ , i.e. $m = \lceil \log{b}/\log{a} \rceil - 1$ . Convert number $a^{m+1} - b$ in base $a$ and add it's digits $$a^{m+1} - b = (r_{l} r_{l-1} ... r_{1} r_{0})_{a}$$ Where $r=\sum_{i=0}^{l}r_{i}$ Example $W(5,77)=8$ Identity $1$ if $W(a,b)=r$ then $b+r\equiv 1($ mod $a-1)$ ◆ $S$ is a function defined as $$S(a,n)=\sum_{i=1}^{a}i^{n}$$ Where $a$ and $n$ are positive integer. Let $p$ is prime
and $p+1=z$ Question show that If $ z>2n+2$ Then $W(z,W(z,S(z,2n)))=z$ Example Let $n=1$ here, choose any $z>4$ Let $z=6$ So $W(6,W(6,S(6,2)))=W(6,W(6,91))=W(6,10)=6$ Python programming for calculate $W$ function n1=5
n2=77
rem_array = []
while n2 != 1:
    mod = n2%n1
    if mod != 0:
      rem = n1-mod
      n2 = n2 + rem
      rem_array.append(round(rem))
      n2=n2/n1
    else:
        n2 = n2/n1
        rem_array.append(0)
print(rem_array[::-1])
print(sum(rem_array)) Proof for, if $p>n+1$ then $p|S(p,n)$ Formula $$ S(a,n)= \sum_{i=1}^{a} i^{n}=\sum_{b=1}^{n+1} \binom{a}b\sum_{j=0}^{b-1} (-1)^{j}(b-j)^{n}\binom{b-1}j$$ for formula Proof Let $a=p(prime)>n+1$ We can see, $a$ can be common out from $\sum_{b=1}^{n+1}\binom{a}b\sum_{j=0}^{b-1} ...$ $\implies a|S(a,n)$ Proof for, If $ p|S(p,2n)$ Then $W(z,W(z,S(z,2n)))=(z-1)r+1=pr+1$ Proof See $S(z,2n)=pr_1+1$ $\implies W(z,W(z,S(z,2n)))$ $\ \ \ by\ identity1$ $=W(z,W(z,pr_1+1))$ $=W(z,pr_2)$ $=pr+1=(z-1)r+1$ For some $r,r_1,r_2\in\mathbb{Z}$ I believe $r$ is always $1$ for all $z>2n+2$ , that's my question. Related questions To count such $p$ which $p\nmid S(p,2n)$ Special observation on prime number and π(n)","['number-theory', 'elementary-number-theory', 'prime-numbers']"
3398064,Brouwer's fixed point theorem and continuous functional dependence on the fixed point.,"The famous Brower's fixed-point theorem states that any $ f $ function that maps a compact and convex set itself has a fixed point. I would like to know if minor disturbances in the  function $ f $ could only cause minor disturbances in the  fixed point $ x $ of $ f $ . In other words the question would be as follows. If a  function $ g $ is close to $ f $ then will the fixed points of $ f $ be close to the fixed points of $ g $ ? One problem with this question is that the number of  fixed points of $ g $ may be greater or less than the number of  fixed points of $ f $ . Thus, there may be a fixed point $ x_f $ of $ f $ such that $ g (x) \neq x $ to $ x $ in some neighborhood of $ x_f $ . However the Brouwer's fixed-point theorem guarantees that the number of fixed points of $ g $ is always greater than or equal to $ 1 $ . Thus, the question could be improved and put in the following terms. In the set $ \mathrm{Fix}(f) $ of  fixed points of $ f $ there would be $ x_f \in  \mathrm{Fix} (f) $ such that if any $ g $ application is close to $ f $ there would be $ x_g \in  \mathrm{Fix }(g) $ tal which $ x_f $ is close to $ x_g $ ? Technically the question would be as follows. Let $ \Omega \subset \mathbb{R}^n$ be a compact and convex set. Rig the set $ C^0(\Omega, \mathbb{R}^n) $ with the supreme norm $ \| f \|_{\infty}: = \sup \{| f (x) |: x \in \Omega \} $ . Take $ f \in C^0(\Omega, \mathbb{R}^n)$ such that $ f (\Omega) \subseteq \Omega $ . Given $ \epsilon> 0 $ and $ g $ satisfying the condition $ \| f-g \|_\infty <\epsilon $ , with $ g(\Omega) \subseteq \Omega $ , there is $ x_f \in \mathrm{Fix} (f) $ , $ \delta> 0 $ and $ x_g \in  \mathrm{Fix} (g) $ such that $ \| x_f-x_g \| <\delta $ ? How to prove it?","['fixed-point-theorems', 'general-topology', 'analysis']"
3398078,"Solve discrete logarithm, $a^x = b \bmod 2^N$ by p-adic logarithm","I want to find the smallest solution, $x$ , for $$a^x = b \bmod 2^N$$ by using p-adic logarithm . We suppose $a \bmod 4 =1$ and $b \bmod 4 = 1$ . Another case can be solved easily or converted to $a, b \bmod 4 = 1$ case.
For $a \bmod 4=1$ , and $b \bmod 4 = 1$ , p-adic logarithm can be defined as you can find in the link above. Then by using 2-adic logarithm, $x$ can be write as
below. $$x = \frac{\log{b}}{\log{a}}$$ However, this solution is not always the smallest solution.
For example, let's consider the problem, $$5^x = 9 \bmod 16$$ by using 2-adic logarithm.
Since $9\bmod 4 = 1$ and $5\bmod 4=1$ , 2-adic logarithm can be defined for $9$ and $5$ . Then $x = \log(9) / \log(5)$ . Let's calculate the $\log{9}$ and $\log{5}$ by formal power series. $$\log(1 + 8) = 8 - (1/2) 8^2 + ... = 8$$ $$\log(1 + 4) = 4 - (1/2) 4^2 + ... = -4 = 12$$ Then, $\log(9) / \log(5) = 2 / 3$ . Since $3$ is coprime to $16$ , inverse of $3$ , $3^{-1}=11 \bmod 16$ ,  can be found by extended euclidean algorithm (or by expanding $1/3=1-2+2^2-2^3+2^4-...$ ). Then, $x=2/3=2\times 11=6 \bmod \phi(16)$ . Here, $\phi(n)$ is the Euler function of $n$ . We find the solution, $x=6$ . Let's check this is actually the solution, $$5^6 = 15625 = 9 \bmod 16$$ .
However, this is not the smallest solution. The smallest solution of $x$ is $x=2$ as below. $$5^2=25=9 \bmod 16$$ We can find such case infinitely. My question is, can we construct the smallest solution by using p-adic logarithm?","['modular-arithmetic', 'number-theory', 'p-adic-number-theory', 'modules', 'algorithms']"
3398174,Convergence of related improper integrals,"Suppose a positive function $f:[1,\infty) \to (0,\infty)$ has $\int_1^\infty \frac{f(x)}{x} dx < +\infty$ .  Is it also possible that $\int_1^\infty \frac{1}{xf(x)} dx$ converges? I can make progress when $f(x)$ is monotone decreasing. Since $f(x)/x$ is also decreasing and the improper integral converges it must hold that $\lim_{x \to \infty} xf(x)/x = \lim_{x \to \infty} f(x) = 0$ . Then there exists $C > 0$ such that $f(x) < 1$ and $1/(xf(x)) > 1/x$ for $x > C$ . By the comparison test the integral of $1/(xf(x))$ diverges since $\int_C^\infty dx/x = + \infty$ .","['integration', 'convergence-divergence', 'improper-integrals']"
3398236,The N(I+V) must be bigger than 4 in complex matrices?,"In this problem, all matrices are $n*n$ with complex entries. Let $U$ and $V$ be matrices such that $UV \not = VU$ . Assume that $U$ is diagonalizable and commutes with $VUV^{-1}$ (a).For $\lambda , \mu \in \mathbb C$ , let $E_{\lambda , \mu}=\{x \in \mathbb C^n|Ux= \lambda x ,VUV^{-1}x=\mu x \}.$ Show that there exist couples $(\lambda_1,\mu_1) \not = (\lambda_2,\mu_2)$ ,satisfying $\lambda_i \not = \mu_i$ and $E_{\lambda_i , \mu_i} \not = 0$ for $ i = 1,2.$ (b).For a matrix $A$ , we define $N(A):=tr(A^*A),$ where $A^*$ is the conjugate transpose of $A$ . Assume that $U$ and $V$ are unitary (namely, $U^*U=V^*V$ is the identity matrix).Deduce that $N(1+V) \ge 4$ .","['matrices', 'linear-algebra']"
3398317,Necklace infinte sum,"Consider the function: $$S(n)=\sum_{j=1}^{\infty}\frac{j^n}{2^j}=\frac1 2+\frac{2^n}{4}+\frac{3^n}{8}+\frac{4^n}{16}+\frac{5^n}{32}+...$$ Euler found the sum of the first few of these as: $S(0)=1$ ; (as per the usual geometric series.) $S(1)=2$ ; etc.  This creates a series of sums as follows: 1, 2, 6, 26, 150, 1082, 9366, 94586, … , which is the OEIS sequence A000629, “Number of necklaces of partitions of $n+1$ labelled beads”. My question is - what connection is there between this infinite series and necklace combinatorics?  Or is the connection accidental or illusory?","['necklace-and-bracelets', 'sequences-and-series']"
3398350,How to analyze $\{|f(z)|\le M\}$ is bounded?,"Given a continuously differentiable function $f:\mathbb{R^2}\to\mathbb{R^2}$ . If $\{x : \det Jf(x)=0 \}$ is finite, and for each positive constant $M$ , $\{z\in \mathbb{R^2} :|f(z)|\le M\}$ is bounded. Prove that $f$ is surjective. My attempt I wanted to prove that $ f(\mathbb{R^2})$ is open and closed. In order to do this I proved that $f(\mathbb{R^2}\setminus\{x : \det Jf(x)=0 \})$ is open. I wanted to prove then that $f(\mathbb{R^2})$ is closed. But I got stuck on how to use the condition that $\{z\in \mathbb{R^2} :|f(z)|\le M\}$ is bounded. Any hints? Thanks in advance!","['jacobian', 'multivariable-calculus', 'real-analysis']"
3398428,$f^n(x)$ where $n \in \mathbb{R}^+$,"Given a function $f(x)$ whose image is a subset of its domain, we can define $$
f^n(x) = \underbrace{f(f(f(\dots f(x) \dots )))}_{n \text{ times}}
$$ This makes sense when $n$ is a nonnegative integer. Can we extend this definition to continuous values of $n$ ? Such as $f^{\frac{1}{2}}(x)$ ?",['analysis']
3398522,"Solving a ""twisty puzzle"" on $S_{20}$","I'm trying to solve a twisty puzzle that permutes the integers 1 thru 20 according to the following rules: $R = \begin{pmatrix} 1 & 2 & \cdots & 19 & 20\\
20 & 1 & \cdots & 18 & 19 \end{pmatrix},\quad$ a ""slide"" to the right $L = R^{-1} = \begin{pmatrix} 1 & 2 & \cdots & 19 & 20\\
2 & 3 & \cdots & 20 & 1 \end{pmatrix},\quad$ a ""slide"" to the left $T = \begin{pmatrix} 1 & 2 & 3 & 4 & 5 & \cdots & 20\\
4 & 3 & 2 & 1& 5 & \cdots & 20 \end{pmatrix},\quad$ a ""twist"" of the first four elements After fidgeting around with it a bit, I quickly realized that if $n$ is at the front, and $n+1$ is in the third position, then the operation $RTRTLTL$ (from right to left, as operators) will leave $n$ fixed, and move $n+1$ after it as desired. Repeating this procedure numerous times, it's not hard to solve most of the puzzle. However things get tricky when you get to the last 4 integers than need sorting. In particular, I'm currently stuck with only 1 and 20 swapped, and everything else in-order. Does anyone have any suggestions about how one might create commutators (or other operations) to swap a single pair of adjacent integers? And, more generally, how does this puzzle change with adjustments to the length of integers, or the size of the ""twist""? More precisely, if we are working in $S_n$ , and the ""twist"" operation reverses the first $k$ integers, with $k < n$ , what can we say about the puzzles various states? Is this enough to generate the entire group $S_n$ ? Does the answer depend on the values of $n$ and $k$ explicitly? Is there something particularly interesting about $n=20$ , or was this just a design choice by the manufacturer of the puzzle?","['permutations', 'group-theory', 'puzzle', 'symmetric-groups']"
3398548,"$ƒ(x,y)=\sqrt{x^2+y^2}+\sqrt{x^2+y^2-2x+1}+\sqrt{x^2+y^2-2y+1}+\sqrt{x^2+y^2-6x-8y+25}$","QUESTION: Let $ƒ(x,y)=\sqrt{x^2+y^2}+\sqrt{x^2+y^2-2x+1}+\sqrt{x^2+y^2-2y+1}+\sqrt{x^2+y^2-6x-8y+25}$ (A) Minimum value of $ƒ(x,y)= 5+\sqrt2$ (B) Minimum value of $ƒ(x,y)= 5-\sqrt2$ (C) Minimum value occurs of $ƒ(x,y)$ for $x=\frac{3}{7}$ (D) Minimum value occurs of $ƒ(x,y)$ for $y=\frac{4}{7}$ My approach , all values in the square roots needs to be positive. ${x^2+y^2\ge 0}$ hence it encloses the whole graph ${x^2+y^2-2x+1}$ , ${(x-1)^2+y^2\ge 0}$ $x^2+y^2-2y+1$ , $ x^2+(y-1)^2\ge 0$ $x^2+y^2-6x-8y+25$ , $(x-3)^2+(y-4)^2\ge 0$ Not able to approach from here",['functions']
3398576,Prove two linear functions cannot both be bounded.,"If $X$ is a nonzero normed space. $S,T \in Lin(X)$ satisfies $ST-TS=I$ , where $I$ is the identity function. Prove the two linear operators cannot be both bounded. My attempt: Suppose $S,T$ are bounded, then $\Vert Tx\Vert \leq a_1\Vert x\Vert,\Vert Sx\Vert \leq a_2\Vert x\Vert$ $\Vert x\Vert =\Vert (ST-TS)x\Vert$ I am not sure how to combine the two conditions to reach a contradiction. Any help would be appreciated.","['normed-spaces', 'functional-analysis', 'analysis']"
3398586,"There exists $2n-1$ pairs $(a_i, a_j)$ s.t. $a_i+a_j\geq 0$.","Let $a_1, a_2,..., a_{2n}\in \mathbb {R} $ s.t. $a_1+a_2+...+a_{2n}=0$ . Show that there exists $2n-1$ pairs $(a_i, a_j)$ s.t. $a_i+a_j\geq 0$ . My idea: I consider that $a_1,..., a_k\geq 0$ and $a_{k+1},..., a_{2n}<0$ (I put them the sign minus). Then there are $\frac {k (k-1)}{2} $ pairs. Also $a_1+...a_k=a_{k+1}+...+a_{2n} $ . But I am stuck.",['algebra-precalculus']
3398645,What is values of exponential in complex plane,I have a doubt about value of $e^{z}$ at $\infty$ in one of my book they are mentioning that as $\lim_{z \to \infty} e^z  \to \infty $ But in another book they are saying it doesn't exist.I am confused now As we can see $e^{z}$ is entire function then as $z \to \infty $ then $e^{z}$ must go to $\infty$ Please help.,['complex-analysis']
3398754,Finding the summation of a series,"Determine the following sum $$\frac{5}{3 \cdot 6 }\cdot \frac{1}{4^2} + \frac{5\cdot 8}{3 \cdot 6 \cdot 9 }\cdot \frac{1}{4^3} + \frac{5 \cdot 8 \cdot 11}{3 \cdot 6 \cdot 9 \cdot 12}\cdot \frac{1}{4^4} + \frac{5\cdot8\cdot 11\cdot 14}{3 \cdot 6\cdot 9\cdot 12 \cdot 15}\cdot \frac{1}{4^5} + \dots \dots$$ I tried to use Generalised Binomial Theorem, but I am unable to find $x,y,r$ The Generalized Binomial Theorem $$(x+y)^{r}=\sum _{k=0}^{\infty }{r \choose k}x^{r-k}y^{k}$$ where the ${r \choose k }$ denotes the falling factorial.
  I notice that the factors in the numerator is increasing, hence I am unable to use it.","['real-numbers', 'algebra-precalculus', 'real-analysis']"
3398757,Endomorphism ring of module quotient radical,"Let $R$ be a ring of arbitrary characteristic and let $A$ be an $R$ -module. Denote $\mathrm{Rad}(A)$ as the radical of $A$ (i.e. the the intersection of maximal submodules). Then do we have $$
 \mathrm{End}(A/\mathrm{Rad}(A)) \cong \mathrm{End}(A) / 
 \mathrm{Rad}\big(\mathrm{End}(A)\big),
$$ when $A$ is not necessarily semisimple but $A/\mathrm{Rad}(A)$ is semisimple? If this is not generally true, then in what generality does this hold?","['representation-theory', 'modules', 'ring-theory', 'abstract-algebra', 'commutative-algebra']"
3398761,Torsion-free module over a DVR,"I have a question on the proof of Lemma 53.2.3 . the claim is: Lemma 52.2.3 . Let $k$ be a field. Let $f:X\to Y$ be a nonconstant morphism of curves over $k$ . If $Y$ is normal, then $f$ is flat. the curves are assumed to be smooth and therefore all stalks $\mathcal{O}_{Y,y}$ are either fields or a discrete valuation rings ( Lemma 32.43.16 ). $f$ is non constant and therefore dominant, since $X,Y$ are irreducible of dimension $1$ . 'This implies that $\mathcal{O}_{Y,y} \to \mathcal{O}_{X,x}$ is injective. $\mathcal{O}_{X,x}$ is torsion-free as a $\mathcal{O}_{Y,y}$ -module ...' The last argument I not understand. Why injectivity of $\mathcal{O}_{Y,y} \to \mathcal{O}_{X,x}$ implies that $\mathcal{O}_{X,x}$ is torsion-free as a $\mathcal{O}_{Y,y}$ -module? The theory of finitely generated modules over pid (dvr are pid) gives decomposition of $\mathcal{O}_{X,x}$ as $\mathcal{O}_{X,x}= \mathcal{O}_{Y,y}^m \bigoplus \oplus_{j=1} ^k \mathcal{O}_{Y,y}/\mathfrak{m}_y$ with torsion part $\oplus_{j=1} ^k \mathcal{O}_{Y,y}/\mathfrak{m}_y$ . recall $\mathcal{O}_{Y,y}$ has only one non trivial prime $\mathfrak{m}_y$ . Question: Why injectivity of $\mathcal{O}_{Y,y} \to \mathcal{O}_{X,x}$ and this decomption implies that $\mathcal{O}_{X,x}$ is torsion-free as a $\mathcal{O}_{Y,y}$ -module?","['ring-theory', 'algebraic-geometry', 'commutative-algebra']"
3398821,Find optimal fishing plan,"A population of $N$ fish in a certain lake grow at rate $$N'(t) = aN(t) - bN^2(t)$$ if undisturbed by people. Fish can be withdrawn from the lake and consumed at
  rate $c(t)$ , yielding utility $w(c(t))$ to the consuming community and reducing the
  fish growth rate accordingly: $$N'(t) = aN(t) - bN^2(t) - c(t)$$ Assume future utilities to the community are discounted at constant rate $r$ .
  Characterize a fishing (consumption) plan to maximize the present value of the
  discounted stream of utilities. Assume that $N(0) = \frac{a}{b}$ , and that $u' > 0$ , $u'' < 0$ .","['optimal-control', 'control-theory', 'ordinary-differential-equations', 'operations-research']"
3398854,Is it true that $\mu\left(\left\{x\in\partial K : \limsup_{r\to 0^+}\ \frac{\mu(B_r(x)\cap K^c)}{\mu(B_r(x))}>0\right\}\right)=0?$,"Let $(X,d)$ be a complete separable metric space. If $x\in X$ and $r>0$ , denote by $B_r(x)$ the ball centered in $x$ of radius $r$ of $(X,d)$ . Suppose that $\mu$ is a finite Borel measure of $(X,d)$ . Define $\operatorname{supp}(\mu):=\{x\in X : \forall r>0, \mu(B_r(x))>0\}$ . Let $K\subset X$ be a compact of $(X,d)$ such that $\mu(\partial K)>0$ . Is it true that $\left\{x\in\partial K \cap \operatorname{supp}(\mu) : \limsup_{r\to 0^+}\ \frac{\mu(B_r(x)\cap K^c)}{\mu(B_r(x))}>0\right\}$ is contained in a Borel set of $\mu$ -measure zero? I know that the result holds true if the Lebesgue's differentiation theorem holds true in $(X,d)$ (a characterization of metric spaces that have this property can be found here https://arxiv.org/pdf/1802.02069.pdf ). However, does it hold true in general (or maybe under less stringent conditions)?","['measure-theory', 'geometric-measure-theory']"
3398856,Three polynomials which have the same value for a variable,"Let $P_1(x)= ax^2-bx-c$ , $P_2(x)=bx^2-cx-a$ , and $P_3(x)= cx^2-ax-b$ be three quadratic polynomials, where $a,b$ , and $c$ are non-zero real numbers. Suppose that there exists a real number $k$ such that $$ P_1(k) = P_2(k)= P_3(k) $$ Prove that $a=b=c$ . Hello everybody! The above is a question I got stuck on. This problem is from an Indian Olympiad. Here is what I did: After manipulating the given information, we derive at $(a-b)k^2-(b-c)k-(c-a)=0$ $(b-c)k^2-(c-a)k-(a-b)=0 $ and $(c-a)k^2 - (a-b)k - (b-c)$ . Now the solution involves some addition and subtraction to factor it and get $a=b=c$ . But my question is: Can’t I just compare the coefficients of the three equations because they are all zero from which we get $b-c = c-a$ , $c-a = a-b $ and $a-b = b-c$ and get $a=b=c$ ? If not, why? Thanks","['contest-math', 'algebra-precalculus', 'polynomials']"
3398869,How to split a set into two disjoint subsets in a special way?,"Suppose $S$ is a finite set (the number of its members is not large).
The set $\Sigma=\{s_1, \ldots, s_N\}$ is a set of subsets of $S$ , i. e. $s_i \in S$ . Is it possible to split $S$ into disjoint parts $S_1$ and $S_2$ that for any $i$ : $s_i \cap S_1 \not= \emptyset$ and $s_i \cap S_2 \not= \emptyset$ (in other words, any $s_i$ is composed from both $S_1$ and $S_2$ )? I seek an algorithm enabling to decide if such division is possible (or not).","['elementary-set-theory', 'set-partition', 'combinatorics', 'discrete-mathematics']"
3398934,What do two ODEs with the same Lyapunov function have in common,"Assume I have two $N$ -dimensional systems ofODEs $\frac{dX}{dt}=F(X)$ with $F: \mathbb{R}^N\rightarrow\mathbb{R}^N$ and $\frac{dY}{dt}=G(Y)$ with $G: \mathbb{R}^N\rightarrow\mathbb{R}^N$ . Also, assume I have a function $V:\mathbb{R}^N\rightarrow \mathbb{R}$ such that $V$ is a complete Lyapunov function for both $F$ as well as $G$ (most importantly $V$ is strictly decreasing on parts of $\mathbb{R}^N$ which are not chain-recurrent, and iff $V(X)=V(Y)$ then $x$ and $y$ are part of the same chain-recurrent set). What else can we say then about the relationship between $F$ and $G$ ? Obviously $F$ and $G$ must have the same chain-recurrent sets, that is they have the same attractor structure. However, the flow of $F$ and $G$ can still be quite different. Intuitively it seems that $F$ and $G$ should be topologically equivalent, but I can't find any proof for that.","['lyapunov-functions', 'ordinary-differential-equations', 'dynamical-systems']"
3399000,Proof verification regarding equal sets,"$RTP$ : { $12a+4b$ : $a,b ∈ $ Z} = { $4c$ : $c ∈ $ Z} Solution : Let's first show that $LHS$ is a subset of our $RHS$ . x ∈ { $x ∣4(3a+b)=x$ : a,b ∈  Z} → x ∈ { $x ∣4c=x$ : c ∈  Z} Which is true. We can always choose $(3a+b)$ such that it equals $c$ Now let's show that $RHS$ is a subset of our $LHS$ x ∈ { $x ∣4c=x$ : c ∈  Z} → x ∈ { $x ∣4(3a+b)=x$ : a,b ∈  Z} Which is true as well. We can always choose $c$ such that it equals $(3a+b)$ . Correct?","['elementary-set-theory', 'proof-verification']"
3399017,Prove that $\int_X |f|^p = \int_0^\infty pt^{p-1} \mu (\{x:|f(x)| \geq t\}) dt$ [duplicate],"This question already has an answer here : Prove $\int_X |f|^p=p\int^{\infty}_{0} t^{p-1}\mu({x: |f(x)>t}) dt\,$ [duplicate] (1 answer) Closed 4 years ago . I am stuck in this problem.
We can assume that we are working in a $\sigma$ -finite measure space and we have some measurable function $f$ . Now, the first thing I do is obtain two integrals $$\int_0^\infty pt^{p-1} \mu(\{x:|f(x)|\geq t\}) dt = \int_0^\infty \int_Xpt^{p-1} \chi_{\{x:|f(x)|\geq t\}} d\mu dt$$ Now, since we are working under the assumption that $p>0, t\geq 0$ and also since the indicator function $\chi$ is non-negative, we can use Fubini's theorem to swap the integrals, and get $$\int_X \int_0^\infty pt^{p-1} \chi_{\{x:|f(x)|\geq t\}} dt d\mu$$ From here, I am unsure if I should somehow prove that the integrand is Riemann-integrable so I can perform a change of variables. On the other hand, I saw that, for the special case $p=1$ , the following identity is used: $$\int_0^\infty \chi_{\{x:|f(x)|\geq t\}} dt = \int_0^{|f(x)|} dt$$ Is it possible to use a change of variables $s = t^p$ to get the following integral? $$\int_0^\infty \chi_{\{x:|f(x)|^p\geq s\}}ds=\int_0^{|f(x)|^p}ds$$ If so, how can this be made rigorous? Also, how do I prove the identity?","['integration', 'measure-theory', 'lebesgue-integral', 'real-analysis', 'lp-spaces']"
3399038,How to calculate this cohomology?,"Let $X = \mathbb{P}^{3}$ and $C \subset X$ an irreducible smooth curve. Let $I_{C}$ be the ideal sheaf of $C$ . I am trying to calculate the following cohomology: $$H^{i}(X, \Omega_{X}^{1} \otimes \bigwedge^{i+1}T_{X} \otimes S^{i}(\mathcal{F}) \otimes I_{C}(m))$$ with $i = 1, 2$ and $0 < m \leq 2$ ,  where: 1) $\mathcal{F}$ is a locally free sheaf of $\text{rank}$ one. More precisely, in my case, it is: $\mathcal{F} = \mathcal{O}_{X}(c + d)$ and $S^{i}(\mathcal{F})$ is the $\text{i-th}$ symmetric power of $\mathcal{F}$ . 2) $I_{C}$ is the ideal sheaf of $C$ . My objective is : $H^{i}(X, \Omega_{X}^{1} \otimes \bigwedge^{i+1}T_{X} \otimes S^{i}(\mathcal{F}) \otimes I_{C}(m)) = 0$ with $i = 1, 2$ What i'm trying to do : For a question asked here in the forum:  ( https://math.stackexchange.com/users/715318/emanuell ), Holomorphic Vector Bundle and Non-Degenerate Pairing, I have the following isomorphisms: a) For $i = 1$ . $$\bigwedge^{2}T_{X} \simeq \Omega_{X}^{1}(4)$$ b) For $i = 2$ $$\bigwedge^{3}T_{X} \simeq \mathcal{O}_{X}(4)$$ My problem now is the $S^{i}(\mathcal{F})$ . I don't know what is: $\bigwedge^{i+1}T_{X} \otimes S^{i}(\mathcal{F})$ (*) After understanding this (*), I will try to use the following tools: Mumford's Regularity Theorem , because: i) Bott's formula tells us that $\Omega_{X}^{1}$ is 2-regular . ii) The corollary 2.1 of the article: Vanishing Theorems, A Theorem Of  Severi and the equations defining projective variety , that says about the aforementioned regularity for an ideal sheaf. Thank you  and a lot from now, any help.","['algebraic-geometry', 'sheaf-cohomology']"
3399114,"Approximate the probability of $n$, given the sum of $n$ stochastic variables.","I've been given the following problem to solve (hastily translated to English) in an undergraduate course in probability theory:
A small library has 46 running meters of books. The thickness of each book can be seen as independent stochastic variables which all have the expected value of 1.8cm and standard deviation 0.7cm. Approximate the probability of the library containing more than 2500 books. I'm certain it's an application of the central limit theorem but can't really get my head around it. I've started with some notation: given that $X_i$ is the thickness of book $i$ , we have that $\sum_{i=1}^nX_i=4600$ , $\mu=1.8$ and $\sigma=0.7$ . Via the central limit theorem one could approximate the probability of the sum of $n$ books thickness' being between $a$ and $b$ cm as $$P(a<\sum_{i=1}^nX_i\leq b)\approx\Phi\left(\frac{b-n\mu}{\sigma\sqrt{n}}\right)-\Phi\left(\frac{a-n\mu}{\sigma\sqrt{n}}\right)=\Phi\left(\frac{b-1.8n}{0.7\sqrt{n}}\right)-\Phi\left(\frac{a-1.8n}{0.7\sqrt{n}}\right)$$ but that's not really the probability I'm looking for since the total length is known (and $n$ not). Another different approach could be to let $Y_k$ denote the no. of books in meter $k$ and calculate $$P\left(\sum_{k=1}^{46}Y_k >2500\right)$$ given that $\sum_{i=1}^nX_i=4600$ but to do so with the given information one must formulate how $Y$ depends on $X$ and that I am unsure of. Do anyone have a solution?","['central-limit-theorem', 'probability']"
3399127,"Gaussian binomial coefficients, lattice paths, and vector spaces","The Gaussian binomial coefficient ${n+k \choose k}_q$ gives a probability generating function for the number of lattice paths from $(0,0)$ to $(n,k)$ enclosing an area $a$ in the upper-right quadrant i.e. this count is given by the coefficient of $q^a$ in the corresponding series expansion of ${n+k \choose k}_q$ . For example, the number of lattice paths in the $10 \times 10$ box between the bottom left and top right corners is ${20 \choose 10}$ , and those which enclose an area of 8 is the coefficient of $q^8$ in the corresponding series $${20 \choose 10}_q = 1 + q + 2 q^2 + 3 q^3 + 5 q^4 + \dots +2 q^{98} + q^{99} + q^{100}$$ which happens to be 22. The Gaussian coefficient ${n+k \choose k}_q$ also counts the number of $k$ -dimensional vector subspaces of an $n+k$ -dimensional vector space over $F_q$ . What is the relation here? Is the vector space interpretation also somehow a generalisation of the notion of partitioning something under a set of constraints (here, into $k$ parts no larger than $n$ )? What, for example, does the lattice path generating function 'mean' when we set $q \neq 1$ ?","['finite-fields', 'combinatorics', 'probability', 'q-analogs']"
3399233,If $G$ is finite and every subgroup is characteristic then $G$ is abelian and cyclic,"I've been trying to prove that if $G$ is finite and every subgroup is characteristic then $G$ is cyclic.
If I suppose that $G$ is abelian I've been able to prove it this way The statement is true if $|G|=1$ , so lets supose by induction that it is true for every group of order less than $n$ . Then if $|G|=n=p_1^{\alpha_1} \cdots p_m^{\alpha_m}$ with $p_i$ primes, as $G$ is abelian, we know that is direct product of its uniques Sylow subgroups $$G=P_1P_2 \cdots P_m$$ Let $K$ be a subgroup of $P_i$ and $f \in Aut(P_i)$ , then we can define $h:G \longrightarrow G$ such that given $a \in G$ and $a=a_1 \cdots a_m$ its unique expresion as a product where $a_j \in P_j$ , $$h(a)=h(a_1\cdots a_m)=a_1 \cdots a_{i-1} f(a_i) a_{i+1} \cdots a_m$$ The function $h$ is a homomorphism because given $a, b \in G$ , if we express $a=a_1 \cdots a_m$ , $b=b_1 \cdots b_m$ in the unique way as specified before, we have that $$ab=(a_1\cdots a_m)(b_1\cdots b_m)=(a_1b_1) \cdots (a_mb_m)$$ and again, because $a_jb_j \in P_j$ , by uniqueness of the expresion we have $$h(ab)=(a_1b_1) \cdots (a_{i-1}b_{i-1}) f(a_ib_i) (a_{i+1}b_{i+1}) \cdots (a_mb_m)=\\=(a_1b_1) \cdots (a_{i-1}b_{i-1}) f(a_i)f(b_i) (a_{i+1}b_{i+1}) \cdots (a_mb_m)=\\=(a_1 \cdots a_{i-1} f(a_i) a_{i+1} \cdots a_m)(b_1 \cdots b_{i-1} f(b_i) b_{i+1} \cdots b_m)=\\=h(a)h(b)$$ Furthermore, $h$ is inyective because if $h(a)=h(b)$ then $$a_1 \cdots a_{i-1} f(a_i) a_{i+1} \cdots a_m=b_1 \cdots b_{i-1} f(b_i) b_{i+1} \cdots b_m$$ and again by uniqueness of the expression of an element of $G$ as a product of elements of $P_j$ we have that $a_j=b_j$ if $j=1, \cdots, i-1,i+1, \cdots m$ and $f(a_i)=f(b_i)$ , and as $f$ is injective, $a_j=b_j$ and $a=b$ .
We stated that $G$ is finite so $h$ is onto and we conclude that $h \in Aut(G)$ .
Now, we observe that as $K \subset P_i$ and it is a characteristic group of $G$ , $f(K)=h(K)=K$ so $K$ is a characteristic group of $P_i$ . So, we have proven that every subgroup of $P_i$ is characteristic in $P_i$ so by induction hypothesis, every $P_i$ is cyclic and there exists elements $a_1, \cdots, a_m$ in $G$ such that $o(a_i)=p_i^{\alpha_i}$ .
Lastly, we observe that as the $\gcd(p_1^{\alpha_1}, \cdots, p_m^{\alpha_m})=1$ and $G$ is abelian, we conclude that $$o(a_1\cdots a_m)=p_1^{\alpha_1} \cdots p_m^{\alpha_m}=|G|$$ and then $G$ is cyclic. My doubts now are if this prove is correct and, in case it is correct, is there a way to prove in an easy way that if $G$ is finite and every subgroup is characteristic then $G$ is abelian? Thank you very much for the comments.","['group-theory', 'abstract-algebra', 'finite-groups']"
3399235,For which values of $k$ does the equation $2\cos^{2}\theta +k\sin \theta + k = 2$ have real solutions?,"So I take A level maths and this question was in our textbook. We solved an inequality for when the discriminant is less than zero and this gave us  the same answer that is in the textbook. The problem is that the solutions also have to give $\sin \theta$ as between one and minus one, and we didn't know how to solve that inequality. Any help would be appreciated, thanks!","['trigonometry', 'quadratics', 'inequality']"
3399239,Prove or disprove : there exist at most two root of $f(x)=f'(x)$.,"Let $f(x)$ be differentiable over $[0,+\infty)$ , and $f'(x)$ be
  increasing and convex over $[0,+\infty).$ If $f(0)=f'(0)=0$ , then
  there exist at most two roots of $f(x)=f'(x)$ over $[0,+\infty).$ Apparently, $x=0$ is already a root, hence we only need prove there exists at most one nonzero root else. Maybe we may construct an auxiliary function $F(x):=e^{-x}f(x)$ , then $F'(x)=e^{-x}(f'(x)-f(x))$ . This will help? Besides, notice that we are not told that $f''(x)$ exists.",['calculus']
3399356,Spectrum can be an arbitrary subset.,"Given any subset $E$ of field $\mathbb{F}$ (real or complex), does there exist a normed linear space $X$ over $\mathbb{F}$ and a bounded linear operator $$A:X\rightarrow X$$ such that spectrum of $A$ is precisely the set $E$ . NOTE : It is known that this is true for compact sets as we can use their separability to construct such an operator.","['operator-theory', 'spectral-theory', 'functional-analysis']"
3399366,Finding the value of function defined as the limit of multivariable function,"Suppose we have a function $f(x,y) = \frac{\cos{x}-\cos{y}}{2(x^2+y^2)}$ and we define $F(x) := \lim_{y \to 0} f(x,y)$ How would I go about finding $F(0)$ ? I am unclear whether to plug the value in first, and then take the limit, eg. $F(0) = \lim_{y \to 0} f(0,y) = \frac{1}{4}$ or take the limit first, and then plug in the value. $F(x) = \lim_{y \to 0} f(x,y) = \frac{\cos{x}-1}{2(x)^2} $ $F(0) = \frac{\cos{0}-1}{2(0)^2} $ In this case, the function is undefined. I have attempted to compute the value in Maple, and I've gotten the following f := (x, y) -> (cos(x) - cos(y))/(2*y^2 + 2*x^2)
F := x -> limit(f(x, y), y = 0)
F(0) = 1/4 This would suggest the first approach being correct, but I am still unsure whether this is actually true and why it is correct.","['limits', 'multivariable-calculus']"
3399387,Basis of extension of scalars,"Let $A$ be a $k$ -algebra of finite dimension, where $k$ is a field, with $k$ -basis $e_1,\cdots,e_n$ . Let $K$ be some field extension of $k$ . The extension of scalars is defined as $A\otimes_kK$ . What's a $K$ -basis of $A\otimes_kK$ ? Would $e_1\otimes1,\cdots,e_n\otimes1$ work? It clearly generates $A\otimes_kK$ . However, I am having trouble showing linear independence. Let $\lambda_1,\cdots,\lambda_n \in K$ , suppose $\sum_{i=1}^ne_i\otimes\lambda_i=0$ , why does this imply $\lambda_1=\cdots=\lambda_n=0$ ? If $\lambda_i\in k$ then I can exploit bilinearity to get $\sum_{i=1}^ne_i\otimes\lambda_i=0=(\sum_{i=1}^ne_i\lambda_i)\otimes1.$ So $(\sum_{i=1}^ne_i\lambda_i)=0$ and $\lambda_1=\cdots=\lambda_n=0.$ But I don't know what to do in the case where $\lambda_i\in K.$ Any hints are appreciated.","['extension-field', 'abstract-algebra', 'tensor-products']"
3399390,An heuristic description of parabolic points in rational iteration theory,"I've been digging around the iteration of rational functions. By chance I came across a mapping $R(z)$ such that there is only one reppelling fixed point  and two parabolic points. I'm still far from understading the texts in the field, e.g. Beardon's or the classical text by Milnor , but all mention that the study of a mapping with parabolic points is significantly more difficult than the case of attracting and reppelling fixed points. Can someone give, perhaps a heuristically, explanation why this analysis is more difficult? In particular, I would like to understand if the dynamics depends explicitly on the mapping (in which case there's nothing much to do, I guess), or if it's really ""difficult"" in the sense of the complexity of proving theorems about the dynamics. Examples will be much appreciated.","['complex-analysis', 'complex-dynamics']"
3399446,Determining if a function is strictly increasing for all natural numbers on a specific interval,"I am having some difficulties with tackling the following problem: Show that $f(x)=x^n$ (where n ∈ $\mathbb{N}$ ) is strictly increasing on the interval $[0, ∞)$ . I am familiar with the following definition: Strictly increasing means if $x_1 < x_2$ then $f(x_1) < f(x_2)$ . So, I started with this definition. However, I am not sure if this is supposed to be proved using the mathematical induction method. I tried to split it into two cases: an even and an odd exponent, but this didn't really lead me anywhere, unfortunately.","['calculus', 'functions', 'proof-writing']"
3399467,Free software / online tool to plot complex functions as maps of grids,"I teach an introductory course in Complex Analysis and it would help me a lot if I could use a free online tool to plot how a particular function maps a given grid in $z$ -plane to $w$ -plane but I am unable to find anything close to what I want. To specify a bit more: Needham's book Visual Complex Analysis uses exactly this approach; I am NOT interested in anything using coloring plotting; I tried Sage but could not find what I wanted (it would be great if Sage did because it is a free pretty much universal math software). Do you possibly know about such a tool? I know one could write a code for that but that is not what I am asking about - ideally, one would define a function (an elementary one) and then specify a grid (say an $x$ -range and $y$ -range and number of horizontal and vertical lines) and it would draw the picture of the grid transformed by the function.","['complex-analysis', 'graphing-functions']"
3399476,Vector field induced by parallel translation is smooth,"I'm studying properties of flat manifolds, and I've come across the following lemma (from ""Introduction to Riemannian Manifolds"" by John M. Lee): Suppose $M$ is a smooth manifold, and $\nabla$ is any connection on $M$ satisfying $$
\nabla_X \nabla_Y Z - \nabla_Y \nabla_X Z = \nabla_{[X,Y]}Z, \qquad \forall \: X, Y, Z \in \mathcal{X}(M).
$$ Then given $p \in M$ and any vector $v \in T_pM$ , there exists a parallel vector field $V$ on a neighborhood of $p$ such that $V_p = v$ . Lee constructs the vector field in the following way: define a coordinate cube $C_\epsilon = \{(x^1, \ldots x^n) : |x^i| < \epsilon \: \forall i\} \subset M$ centered at $p \in M$ . Parallel-transport $v$ along the $x^1$ -axis, then from each point $(c^1, 0, \ldots, 0)$ on the $x^1$ axis, parallel-transport the resulting vector along the coordinate curve $t \mapsto (c^1, t, 0, \ldots, 0)$ ""parallel"" to the $x^2$ -axis. Then do the same thing to along the curve $t \mapsto (c^1, c^2, t, 0, \ldots, 0)$ , etc. This eventually defines a rough vector field $V$ on the coordinate cube $C_\epsilon$ . Claim: The vector field $V$ defined like so is smooth. What I've tried: This supposedly follows from the existence and uniqueness theorem for systems of linear differential equations: Let $I \subset \mathbb R$ bea n open interval, and for $1 \leq j, k \leq n$ , let $A_j^k : I \to \mathbb R$ be smooth functions. For all $t_0 \in I$ and every initial vector $c = (c^1, \ldots, c^n) \in \mathbb R^n$ , the linear initial value problem \begin{align*}
\dot V^k(t) &= A_j^k(t) V^j(t) \\ V^k(t_0) &= c^k
\end{align*} has a unique smooth solution on all of $I$ , and the solution depends smoothly on $(t_0,c) \in I \times \mathbb R^n$ . I can show this if $\dim M = 1$ . Suppose it's true if $\dim M = n-1$ . Let $N = C_{\epsilon} \cap \{x^n = 0\}$ . Then $V$ is smooth on $N$ . For each curve $\gamma_c(t) = (c^1, \ldots, c^{n-1}, t)$ for $c \in \mathbb R^{n-1}$ , parallel-translate $V$ along $\gamma_c(t)$ . Since $V$ is parallel along $\gamma_c$ , $D_tV \equiv 0$ , or $$
\dot V^k(t) = -\dot\gamma^i_c(t) V^j(t) \Gamma_{ij}^k(\gamma_c(t)) \quad \forall k = 1, \ldots, n, 
$$ where $\Gamma_{ij}^k : C_\epsilon \to \mathbb R$ are the Christoffel symbols of $\nabla$ in $C_\epsilon$ -coordinates. Since $\dot\gamma_c(t) = \partial_{n}\big|_{\gamma_c(t)}$ , we know $\dot\gamma_c^i \equiv \delta_n^i$ . So along each curve $t \mapsto (c,t) \in C_\epsilon$ , $c \in \mathbb R^{n-1}$ , the coordinates of $V$ satisfy the initial value problem \begin{align*}
\dot V^k(c,t) &= -V^j(c,t) \Gamma_{nj}^k\left(c^1, \ldots, c^{n-1},t\right) \\
V^k(c,0) &= V^k\big|_N(c,0)
\end{align*} If we could let $A^k_j(t) = -\Gamma_{nj}^k(c,t)$ , then we'd be good and the problem would be solved by induction and the existence and uniqueness theorem (since the solution depends smoothly on choice of initial condition). My problem: I'm not sure the functions $A^k_j$ are allowed to depend on the initial condition. Changing our initial condition in this case also changes the functions $A^k_j$ . Does smoothness of $V$ still follow? Alternatively, is there a reason why $\dfrac{\partial}{\partial x^i} \Gamma^k_{nj} \equiv 0$ for $1 \leq i \leq n-1$ ?","['connections', 'smooth-manifolds', 'ordinary-differential-equations', 'differential-geometry']"
3399498,Write the expression in terms of $\sin$ only $\sin(4x)-\cos(4x)$,I am currently taking a Precalc II (Trig) course in college. There is a question in the book that I can't figure out how to complete it. The question follows: Write the expression in terms of sine only: $\sin(4x)-\cos(4x)$ So far I have $A\sin(x)+B\cos(x)=k\cdot\sin(x+\theta)$ I believe I have found k: $k=\sqrt{A^2+B^2}=\sqrt{2}$ So I think it would be $\sqrt{2}\cdot\sin(4x+\theta)$ but I do not know how I would find $\theta$ . Thanks in advance for all of your help. You have no idea how much I appreciate it!,['trigonometry']
3399509,Every infinite group has a non-trivial subgroup,"Theorem : Every infinite group $G$ has a subgroup $H$ that is non-trivial ( $H \ne G, \lbrace e \rbrace$ ). Proof: This will be a proof by contradiction. So we will assume every subgroup is trivial and bring the cyclic subgroups to the table. For the non-identity $\forall x \in G$ , $\langle x \rangle \ne \lbrace e \rbrace$ . Hence $\langle x \rangle = G.$ Thus every non-identity element of $G$ must be a generator of $G$ . Then it must be possible to write any element as the exponent of another. For $\forall y \in G$ , $$y =x^n.$$ Since $x^2 \in G$ by closure, it is also a generator and we must be able to write $x$ as an exponent of $x^2$ . Yet this is not possible unless our group is finite. So our assumption must be false and our conjecture must be true. $\square$ Is my proof watertight? And is it rigorous enough? Thanks for your reviews.","['group-theory', 'proof-verification', 'infinite-groups']"
3399514,Squaring a simple inequality,"I came across this problem: $$\sqrt{(x^2+1)}-2x+1>0$$ So I wanted to solve it by squaring the inequality: $$\sqrt{(x^2+1)}>2x-1$$ If I understand correctly if I want to square the equation, I need to show that $2x-1$ is a positive number, as $\sqrt{(x^2+1)}$ is positive for all real numbers. So I got $2x-1\geqslant 0$ , so we get: $x\geqslant\frac{1}{2}$ I used this as a perimeter for the first equation when inequalities do not change, after squaring both sides I got: $$(x^2+1)>4x^2-4x+1$$ $$0>x(3x-4)$$ Then we can see that the equation is less than zero on interval: $(0,\frac{4}{3})$ Here I used intersection with $x\geqslant\frac{1}{2}$ . So the parameter becomes(Solution 1): $[\frac{1}{2},\frac{4}{3})$ Then I created another parameter for when $x<\frac{1}{2}$ After some algebra with the same square but the change of the direction of inequality, I got the new parameter intersection (Solution 2) with $x<\frac{1}{2}$ : $$x<0$$ By joining the solution 1 and solution 2 with union, I got parameter for $x$ : $$(-\infty,0) \cup [\frac{1}{2}, \frac{4}{3}) $$ There seems to be something that I missed, as the correct solution is: $x<\frac{4}{3}$ Where did my problem-solving go wrong?","['algebra-precalculus', 'functions', 'inequality', 'real-analysis']"
3399552,Primes above 2 and 3 in a quadratic number field,"I'm reading Keith Conrad's note on the discriminant of a number field. So far I've made it about 1/3rd of a page :) In example 1.2, he considers $K = \mathbb Q (\alpha)$ for $\alpha$ a root of $T^3 - 9T - 6$ . He determines $N(\alpha) = N(\alpha+3) = N(\alpha-3) =6$ and then and then says ""It follows that $(\alpha) = p_2 p_3$ , $(\alpha - 3) = p_2' p_3$ and $(\alpha + 3) = p_2' p_3$ "". (Here I think $p_2, p_2'$ are primes above $2$ and $p_3$ above $3$ ). I can see why the norms imply $(\alpha)$ is the product of a prime above $2$ and $3$ , but I don't immediately see why $(\alpha -3)$ must have a different prime above $2$ but the same prime above $3$ , for example. Using Dedekind Kummer's theorem I can show there's just one prime above $3$ , and two above $2$ , so that would get me part of the way. But the entire point of this example seems to be computing the factorization of $(2)$ and $(3)$ , so I'm guessing there's a simpler way to see this intermediate step...","['number-theory', 'algebraic-number-theory']"
3399677,Trying to solve a recurrence relation by using generating functions: $a_n=3a_{n-1} + a_{n-2}$,"I'm trying to solve the recurrence relation below by using generating function: \begin{equation}
  a_n=\begin{cases}
    0, & \text{if $n<0$}\\
    2, & \text{if $n=0$}\\
    1, & \text{if $n=1$}\\  
    3a_{n-1} + a_{n-2}, & \text{otherwise}.
  \end{cases}
\end{equation} The first thing I did was make the recurrence relation valid for all $n$ by using a kronecker delta: $a_0 = 3.(0) + 0 + 2.(\delta_{n,0}) = 2$ $a_1 = 3.(2) + 0 - 5.(\delta_{n,1}) = 1$ The result I got was: $$a_n = 3a_{n-1} + a_{n-2} + 2\delta_{n,0} - 5\delta_{n,1}$$ Multiplying by $x^n$ : $$a_n . x^n = 3a_{n-1} . x^n + a_{n-2} . x^n + 2\delta_{n,0} . x^n - 5\delta_{n,1} . x^n$$ Summing up both sides: $$\sum_{n\geq0} a_n . x^n = \sum_{n\geq0}3a_{n-1} . x^n + \sum_{n\geq0}a_{n-2} . x^n + \sum_{n\geq0}2\delta_{n,0} . x^n - \sum_{n\geq0}5\delta_{n,1} . x^n$$ And making $F(x) = \sum_{n\geq0} a_n . x^n$ , I got: $$F(x) = 3xF(x) + x^2F(x) + 2 - 5x$$ which is: $$F(x) = \frac{2 - 5x}{1-3x-x^2}$$ So far so good but from here on I can't find a way to calculate the $a_n$ I've heard it has something to do with partials fractions but I'm a newbie in this subject and I have no idea how to follow through. Does anyone can help me to finish the calculation? Thanks in advance.","['recurrence-relations', 'discrete-mathematics', 'generating-functions']"
3399720,"What is the derivative of $ \|X^TW-Y\|_{2,1}$ w.r.t. $W$? How to compute it?","$W$ is a variable. $\|X^TW-Y\|_{2,1}$ is not smooth due to the $\|\cdot\|_{2,1}$ -norm. In order to be differentiable, $\|X^TW-Y\|_{2,1}$ is relaxed to $2\operatorname{Tr}((X^TW-Y)^TD(X^TW-Y))$ , where $$D_{ii} = \frac{1}{2\|(X^TW-Y)_i\|_2+\varepsilon}$$ and $\varepsilon$ denotes a small constant. $X \in \mathbb{R}^{d \times n}$ , $Y \in \mathbb{R}^{n \times l}$ and $W \in \mathbb{R}^{d\times l}$ . Note that: the norm $\|\cdot\|_{2,1}$ of a matrix $W \in \mathbb{R}^{d \times l}$ is defined as $$
\Vert W \Vert_{2,1} 
= \sum_{i=1}^d \Vert w^{i} \Vert_2
= \sum_{i=1}^d \left( \sum_{j=1}^l |w_{ij}|^2 \right)^{1/2}
$$ where $w^i$ denotes $i^\text{th}$ row of $W$ , $w_{ij}$ denotes a element of $W$ . Some papers as follows: Multi-Label Informed Feature Selection Efficient and Robust Feature Selection via Joint $l_{2,1}$ -Norms Minimization","['real-analysis', 'matrices', 'matrix-calculus', 'matrix-norms', 'derivatives']"
3399776,"Why this trick apparently works to make piecewise function differentiable? (also, difference between right derivative and right limit of derivative?)","In high school Calculus a few weeks ago we were given the following problem - it has haunted me ever since and I finally decided to ask about it here: $$f(x) = \left\{\begin{array}{ll}
2x^2+x+1\ &\text{if }x\leq 0,\\
ax+b &\text{if }x>0.
\end{array}\right.$$ 1. Determine the values of $a$ and $b$ such that $f$ is continuous for all x-values. 2. Determine the values of $a$ and $b$ such that $f$ is differentiable for all x-values. (Hint/reminder: for $f$ to be differentiable, both $f$ and $f'$ must be continuous.) Part 1 was easy and I believe I understand why it works. And clearly $b=1$ because that's the solution to $a(0)+b = 2(0)^2+0+1$ . Part 2 was conceptually much more difficult. The first issue is that the statement in the question that ""for $f$ to be differentiable ... $f'$ must be continuous"" is demonstrably false. Being the math nerd that I am, I remembered quickly that in fact the function $f(x)=x^2\sin(1/x)$ , where $f(0)=0$ , is differentiable at $x=0$ but nevertheless $f'$ is NOT continuous there. The second tricky thing is that even though my teacher's premise was apparently false, the solution they derived from that premise was apparently correct! (or at least I have no reason to believe it was incorrect) Specifically, they set the derivative at $x=0$ of the top expression, $4(0)+1$ , equal to that of the bottom expression, $a$ , and quickly found $a=1$ ( $b$ is, of course, still 1 as well). That's a really nifty trick -- just set the derivatives of the two expressions equal to one another and solve. So at this point I'm super confused. Assuming the method my teacher used did in fact work, why did it work? Furthermore, when researching this topic I came across the idea of right and left-hand derivatives. My understanding is that those two terms are related to, but distinct from, the left and right-hand limits of the derivative function at a  point. In other words, my understanding is that the left derivative at $x=a$ is defined as.... $$f'_{-}(a)=\lim_{h\to 0^-}\frac{f(a+h)-f(a)}{h}$$ ... while the limit of the derivative function as $x$ approaches $a$ from the left is simply... $$\lim_{x\to a^-}f'(x)$$ Am I correct that there's a difference between those two concepts (and, regardless, does it matter to my ultimate inquiry?) I am aware that others have asked somewhat similar questions here in the past (e.g. here and here ). However, the answers I have seen either gloss over things I'm confused about or otherwise have not helped me achieve full understanding. I'll note, lastly, that I've also tried to think about this problem graphically. I suppose that has shown me that the teacher's solution was somewhat sensible (it did give me an intuitive idea that the ""slopes"" need to ""match"" on each side), but it has not completely convinced me in the way a formal justification would. Furthermore, oftentimes it just takes me back in circles to the difference (if any) between a right-hand derivative and the right-hand limit of the derivative function.","['continuity', 'calculus', 'derivatives']"
3399787,Approximate a measurable function by simple functions in a product measure space,"This is a theorem in Yeh's Real Analysis : Let $(X, \mathbf{A}, \mu)$ and $(Y, \mathbf{B}, v)$ be two finite measure spaces. Consider the
product measure space $(X \times Y, \sigma(\mathbf{\mathbf { A }} \times \mathbf{B}), \mu \times v) .$ Let $\mathbf{P}$ be the collection of nonnegative
functions on $X \times Y$ of the type $$\psi(x, y)=\sum_{j=1}^{k} c_{j} \mathbf{1}_{A_{j}}(x) \mathbf{1}_{B_{j}}(y)$$ where $c_{j}>0, A_{j} \in \mathbf{A},$ and $B_{j} \in \mathbf{B}$ for $j=1, \ldots, k .$ Then forevery nonnegative extended
real-valued $\sigma(\mathbf{A} \times \mathbf{B})$ -measurable function $f$ on $X \times Y,$ there exists an increasing sequence $\left(\psi_{n}: n \in \mathbb{N}\right)$ in $\mathbf{P}$ such that $\psi_{n} \uparrow f$ a.e. on $X \times Y .$ The suthor first approximate $f$ using simple functions in the product measure space, and then approximate sets in $\sigma(\mathbf{\mathbf { A }} \times \mathbf{B})$ by sets in $\mathbf{\mathbf { A }} \times \mathbf{B}$ . However, I find that the proof does not completely solve the problem. Instead, it only proves that there exists a sequence of $\psi_{n}$ that converges a.e. to $f$ , but they may not be monotone. Can anyone give a correct proof to this theorem please ?","['measure-theory', 'product-measure', 'real-analysis']"
3399809,Isomorphisms of vector bundles preserve orientability,"Let $E$ and $\tilde{E}$ be vector bundles of rank $k$ over $M$ , and assume they can be trivialized over the same cover $\{U_\alpha\}$ . Suppose $E$ is orientable. The definition of orientable that I know is that the transition maps of $E$ , say $t_{\alpha\beta}: U_\beta \cap U_\alpha \to GL(k, \mathbf{R})$ always has positive determinant. It's unclear to me why $\tilde{E}$ must also be orientable if there is a vector bundle isomorphism $\varphi: E \to \tilde{E}$ . For example such a vector bundle isomorphism is given by the data of smooth maps $h_\alpha: U_\alpha \to GL(k, \mathbf{R})$ such that $\tilde{t}_{\alpha\beta} = h_\alpha t_{\alpha\beta} h_\beta^{-1}$ . In fact, I think you might as well take the $h_\alpha$ 's to be arbitrary and define $\tilde{E}$ to be the vector bundle over $M$ with transition maps given by the above formula. But in general it doesn't seem like there's any guarantee that $\tilde{t}_{\alpha\beta}$ has positive determinant, as $h_\alpha$ and $h_\beta$ might have determinants of different signs. Even if you can fix this locally by flipping a sign in a chart, it isn't clear to me that this can be done without causing problems in intersections with other charts.","['differential-topology', 'vector-bundles', 'differential-geometry']"
3399830,Some basic questions about weak-metrizable subsets,"Sorry to bother but I'm having some problems proving some properties in my way to prove some others weak and weak-* metrizability properties. First If I got a Banach space $X$ , wich its dual $X^{*}$ is separable. Then the closed unit ball of the dual is separable with respect to the norm of $X^{*}$ which is the usual. In this case, I think I have to find a dense and countable family which fulfills what we need Second Once we prove the above statement, lets suppose that the countable dense family we found is $\phi$ contained in the closed unit ball of the dual. Then if we define: $d(x,y)=\sum_{k=1}^{\infty} 2^{-k}|\phi_{k}(x-y)|$ for $x,y\in X$ Im having problems proving that is in fact a metric. In particular, I'm struggling with the implication $d(x,y)=0 \implies x=y$ . Thanks so much for your help!","['functional-analysis', 'weak-convergence', 'real-analysis']"
3399832,Definition of Ito integral: Progressively measurable vs. measurable/adapted,"Consider the probability space $(\Omega,\mathcal{F}\,P)$ and the filtration $\mathcal{F}_t$ . In Oksendal's book the Ito integral $I(f)(\omega)=\int_S^T f(t,\omega)dB_t(\omega)$ is defined on a space $\mathcal{V}(S,T)$ . This is the space of functions such that $(t,\omega)\to f(t,\omega)$ is $\mathcal{B}\times\mathcal{F}$ measurable where $\mathcal{B}$ is the borel sigma algebra on $[0,\infty)$ . $f(t,\cdot)$ is $\mathcal{F}_t$ adapted. $E[\int_S^Tf^2(t,\omega)dt]<\infty$ Then the Ito integral of $f$ is defined by $$\int_S^T f(t,\omega)dB_t(\omega):=\lim_{n\to \infty}\int_S^T \phi_n (t,\omega) dB_t(\omega)\,\,in\,\, L^2(P)$$ where $\{\phi_n\}$ is sequence of elementary functions such that $$E\Big[\int_S^T (f(t,\omega)-\phi_n(t,\omega))^2 dt\Big]\to 0 \,\,as\,\,n\to\infty$$ In some other text books I found that instead of this space $\mathcal{V}$ the space (say $\mathcal{W}$ ) of progressively measurable processes such that $(3)$ holds. Now I am quite sure that $\mathcal{W}\subset \mathcal{V}$ . But I am wondering why the difference in approaches? As far as I have noticed, they lead to the same assertions ( the integrals are martingales etc etc.). Or is there any striking difference between these two approaches?","['stochastic-integrals', 'stochastic-processes', 'probability-theory', 'stochastic-calculus']"
3399859,Are the letter choices in algebra meaningful?,"p= F−E(S)
/ k I saw someone post a math problem like the one above. I wonder why they used those letters, if they have a particular meaning or if they could be swapped out for different letters and mean the same thing? Example: X= A−B(C)
/ D","['notation', 'algebra-precalculus']"
3399911,How can I calculate this kind of limit?,"How can I calculate this limit? $$\lim _{(x,y) \to (0,0)} \frac{\vert{x\vert\vert{y}\vert}}{x^2 +y^2}$$ I don't have idea and I will be appreciate for your help.",['multivariable-calculus']
3399914,$\lim_{n \to \infty}\left(\frac {\ln(n^2+n+100)}{\ln(n^{100}+999n-1)}\right)$,"I'm having trouble with the following limit: $$\lim_{n \to \infty}\left(\frac {\ln(n^2+n+100)}{\ln(n^{100}+999n-1)}\right)$$ I'd be grateful for any help. I've tried to write that as $$\lim_{n\to \infty}\left(\frac {\ln(n^2) + \ln(1+\frac 1 n+\frac {100}{n^2})}{\ln(n^{100})+\ln(1+\frac {999n}{n^{100}}-\frac{1}{n^{100}})}\right)$$ Now we know that two of those limits are equal to $0$ , so that limit should be equal to $\lim_{n\to \infty}(\log_{n^{100}}n^2)= \frac{1}{50}$ ; But my question is: am I not making some mistakes here operating partly on limits and partly on values of those limits? Thank you!",['limits']
3399947,"a line tangent to curve $y = \frac{x}{2−2x}$ goes through (1, -1)",$y = \frac{x}{2−2x}$ $y = \frac{f(x)}{g(x)} \rightarrow y' = \frac{f'(x) \cdot g(x) - g'(x)\cdot f(x)}{{g(x)}^2}$ $y = \frac{x}{2−2x}$ $y' = \frac{(2-2x)-(x \cdot (-2))}{{(2−2x)}^2}$ $\rightarrow$ $y' = \frac{(2-2x+2x)}{{(2−2x)}^2} = \frac{2}{{(2-2x)}^2}$ why cant i find the gradient with derivative?,"['curves', 'derivatives']"
3399978,Euclidean division $n$ and $m$,"$\lim_{n\to \infty}\frac{1}{n^2}\bigl(\sum_{m = 1}^ {n}n\bmod m\bigl)$ Where $n\bmod m $ is the remainder of the Euclidean division of $n$ by $m$ I would like to know if I am right or if something is missing: $n \bmod m=n-m\left \lfloor \frac{n}{m}\right\rfloor$ and so \begin{align}
&\lim_{n\to\infty}\frac{1}{n^2}\sum_{m=1}^n(n \bmod m)=\lim_{n\to\infty}\frac{1}{n^2}\sum_{m=1}^n\left(n-m\left \lfloor \frac{n}{m}\right\rfloor\right)=1-\lim_{n\to\infty}\frac{1}{n^2}\sum_{m=1}^nm\left\lfloor\frac{n}{m}\right\rfloor \\
&=1-\lim_{n\to\infty}\frac{1}{n}\sum_{m=1}^n\frac{m}{n}\left \lfloor \frac{n}{m}\right\rfloor=1-\int_0^1x\left\lfloor\frac{1}{x}\right\rfloor dx =1-\int_1^{\infty}\frac{\lfloor x \rfloor}{x^3}\,dx\\&=1-\sum_{n=1}^{\infty}\int_n^{n+1}\frac{n}{x^3}\,dx 
=1-\frac{1}{2}\sum_{n=1}^{\infty}n\left(\frac{1}{n^2}-\frac{1}{(n+1)^2}\right) =1-\sum_{n=1}^{\infty}\frac{n+1/2}{n(n+1)^2}\\[1ex]
&=1-\sum_{n=1}^{\infty}\frac{1}{(n+1)^2}-\frac{1}{2}\sum_{n=1}^{\infty}\frac{1}{n(n+1)}+\frac{1}{2}\sum_{n=1}^{\infty}\frac{1}{(n+1)^2}=1-\frac{\pi^2}{12}.
\end{align}","['contest-math', 'limits', 'calculus', 'proof-verification']"
3400034,Number of subgroups of $\mathbb Z _m \times \mathbb Z_n$,Let $\mathbb Z_m$ denote the additive group of residue classes modulo $m$ . Is there a closed form for the number of subgroups of $\mathbb Z_m\times\mathbb Z_n$ ?,"['group-theory', 'abstract-algebra', 'combinatorics', 'modular-arithmetic']"
3400035,Factor $x^{35}+x^{19}+x^{17}-x^2+1$,I tried to factor $x^{35}+x^{19}+x^{17}-x^2+1$ and I can see that $\omega$ and $\omega^2$ are two conjugate roots of $x^{35}+x^{19}+x^{17}-x^2+1$ . So I divide it by $x^2+x+1$ and the factorization comes to the following $$(x^2+x+1)(x^{33}-x^{32}+x^{30}-x^{29}+x^{27}-x^{26}+x^{24}-x^{23}+x^{21}-x^{20}+x^{18}-x^{16}+2x^{15}-x^{14}-x^{13}+2x^{12}-x^{11}-x^{10}+2x^{9}-x^{8}-x^{7}+2x^6-x^5-x^4+2x^3-x^2-x+1)$$ I couldn't go further. My question is is it end here or there is a simple way to do further?,"['algebra-precalculus', 'factoring', 'polynomials']"
3400052,Average of sequence random variables convergence,"Let $X_1,X_2, \cdots$ be a sequence of random variables that converges to random variable $X$ almost surely OR in $L_p$ norm OR in probability OR in distribution. That is $$X_n\stackrel{a.s.}{\longrightarrow} X$$ OR $$X_n\stackrel{L_p}{\longrightarrow}X$$ OR $$X_n\stackrel{\mathscr{P}}{\rightarrow} X$$ OR $$X_n\stackrel{\mathscr{D}}{\rightarrow} X$$ Let $Y=\frac{1}{n}\sum_{i=1}^{n}X_i$ , I am interested in the convergence of the average sequence $\{Y_n\}$ in different cases. i.e. Which of the following conjectures is true? $$X_n\stackrel{a.s.}{\longrightarrow} X \Rightarrow Y_n\stackrel{a.s.}{\longrightarrow} X$$ $$X_n\stackrel{L_p}{\longrightarrow}X\Rightarrow Y_n\stackrel{L_p}{\longrightarrow} X$$ $$X_n\stackrel{\mathscr{P}}{\rightarrow} X\Rightarrow Y_n\stackrel{\mathscr{P}}{\longrightarrow} X$$ $$X_n\stackrel{\mathscr{D}}{\rightarrow} X\Rightarrow Y_n\stackrel{\mathscr{D}}{\longrightarrow} X$$ If any one of them is incorrect, please give a specific counter example where the limit random variable $X$ is a non-degenerate variable, i.e. $X$ is not a real number(if it is possible). If there is not an $X$ could be non-degenerate, why? (Maybe we can add a non-degenerate $X$ to the existing counter example? Namely, if $X$ is non-degenerate, then let $X_n^{\prime}=X_n-X$ . Thus, we have $X_n^{\prime}\rightarrow 0$ in different modes. By the additivity of limit, it is make sense for non-degenrate case. Would it be all right? ) Many thanks. Update: Now we know that for the arithmetic mean, case 1 and case 2 are true, meanwhile case 3 and case 4 are false. Further, I want to know can the conclusion be extended to geometric mean, harmonic mean and quadratic mean? By the continuous mapping theorem, I think, for case 1, so does geometric mean, harmonic mean and quadratic mean as well. But I am not sure about the case 2. Moreover, for the other forms of mean, will the conclusions of the other two cases change?","['weak-convergence', 'law-of-large-numbers', 'convergence-divergence', 'probability-theory', 'probability']"
3400120,Matrix-by-matrix derivative,"The definition of the matrix-by-matrix derivative is: $$
\frac{\partial X_{kl}}{\partial X_{ij}}=\delta_{ik}\delta_{lj}
$$ If the matrices are $n\times n$ , then the resulting matrix will be $n^2 \times n^2$ . Is the following identity valid for the matrix-by-matrix derivative? $$
\frac{\partial}{\partial A} AB = \frac{\partial A}{\partial A} B + A\frac{\partial B}{\partial A}
$$ If so, I do not understand how we can multiply a $n^2 \times n^2$ matrix by a $n \times n$ matrix? $$
\frac{\partial}{\partial A} AB = \underbrace{\frac{\partial A}{\partial A}}_{n^2\times n^2} \overbrace{B}^{n\times n} + \overbrace{A}^{n\times n} \underbrace{\frac{\partial B}{\partial A}}_{n^2 \times n^2}
$$","['matrix-calculus', 'derivatives']"
3400134,Solving a system of ordinary differential equations with complex roots,"I need help solving the differential equation $$x' = \left(\begin{matrix} 
0 & -1 \\
1 & 0 
\end{matrix}\right)x$$ with initial state $x(0) = \left(\begin{matrix} z \\ 0 \end{matrix}\right)$ . Here, $x' = \frac{dx}{ds}$ . The teacher got the following solution $$x = \left(\begin{matrix} \cos(s) && -\sin(s) \\ \sin(s) && \cos(s) \end{matrix}\right)\left(\begin{matrix} z \\ 0 \end{matrix}\right)$$ But I have no idea how he got this. Could somebody please explain it to me?","['matrices', 'linear-algebra', 'ordinary-differential-equations']"
3400186,How many commuting pairs of unitriangular matrices are there in $GL_{n}(F_{p})$?,"I've been doing some work counting commuting pairs of unitriangular
matrices over $GL_{n}(F_{p})$ .  So far, I believe that for $n=2$ ,
there are $p^2$ such pairs, and for $n=3$ there are $p^5+p^4-p^3$ such pairs.  Can anybody recognize these polynomials, generalize to
arbitrary $n<p$ ? Recall that unitriangular matrices are upper-triangular matrices of
having entries of $1$ on the diagonal. Any help would be appreciated so much. Thank you all.","['finite-fields', 'matrices', 'linear-algebra', 'combinatorics', 'group-theory']"
3400410,Signed spherical angle between two great circle arcs,"I am trying to calculate the signed spherical angle between two intersecting great circle arcs. In my specific case, I am considering a unit sphere ( $r=1$ ). The first great circle arc goes from $A(\lambda_A, \phi_A)$ to $B(\lambda_B, \phi_B)$ , while the second great circle arc goes from $B$ (the intersection point) to $C(\lambda_C, \phi_C)$ . Here, $\lambda$ is longitude, or the angle with the reference meridian, while $\phi$ is latitude, or the angle with respect to the equatorial plane, like is the case in the geographic coordinate system. My spherical coordinates are related to cartesian coordinates as follows: $$ x = \cos(\lambda) \cos(\phi) $$ $$ y = \sin(\lambda) \cos(\phi) $$ $$ z = \sin(\phi) $$ The reference meridian is thus described by $y=0, x>0$ and the equatorial plane is defined as $z=0$ . I can calculate the angle between $AB$ and $BC$ . First, I describe $A$ , $B$ , $C$ as cartesian vectors, e.g. $$\vec{A}= \big(\cos(\lambda_A) \cos(\phi_A),\ \sin(\lambda_A) \cos(\phi_A),\ \sin(\phi_A) \big).$$ Then I take the cross products $\vec{V_{ab}} = \vec{A}\times\vec{B}$ and $\vec{V_{bc}} = \vec{B}\times\vec{C}$ . Then I take the angle between these two vectors (which describe the planes that the great circle arcs $AB$ and $BC$ respectively lie on): $$\text{spherical angle}(AB, BC) = \frac{\vec{V_{ab}}\cdot \vec{V_{bc}}}{ ||\vec{V_{ab}}||\cdot ||\vec{V_{bc}}||}. $$ However, I want the signed spherical angle, so that the angle that $AB$ forms with $BC$ is defined clockwise between $[0, 2\pi]$ . Note: Perhaps it helps to say that $A$ in my specific case is the North Pole, i.e. $A = (0, 0, 1)$ or equivalently $\lambda_A = \frac{1}{2}\pi$ . A solution that works for this particular case is fine as well. The correct approach should thus for $A(0,\frac{1}{2}\pi)$ , $B(0,0)$ and $C(\frac{1}{2}\pi, 0)$ output $\frac{1}{2}\pi$ , while for $C(-\frac{1}{2}\pi, 0)$ it should output $\frac{3}{2}\pi$ (or equivalently $-\frac{1}{2}\pi$ )","['spherical-trigonometry', 'trigonometry', 'spherical-coordinates']"
3400482,Set of rapidly increasing functions is uncountable?,"Let $$ S=\{f \colon \mathbb{N} \mapsto \mathbb{R} \mid f(n+1) \ge 2^{f(n)} \}.$$ How to prove $S$ is uncountable ? I tried proving by contradiction, but not able to construct a new function different from the countable collection. Any help would be appreciated.","['elementary-set-theory', 'real-analysis']"
3400484,Is it true that $\phi(\mu)=\mu F(\mu)^2-\int_{\mu}^{\overline{v}}F(v)[1-F(v)]dv\geq 0$?,"Consider a random variable $V$ with distribution function $F$ and density function $f$ with support $[\underline{v},\overline{v}]$ , where $0\leq\underline{v}<\overline{v}$ . The mean is $\mu$ . Here $f$ is assumed to be differentiable on its support and log-concave (i.e. $\ln \circ f$ is a concave function). I would like to prove (or disprove) that $$\tag{1}\phi(\mu)=\mu F(\mu)^2-\int_{\mu}^{\overline{v}}F(v)[1-F(v)]dv\geq 0$$ for all such probability distributions. I have not been able to find any examples of distributions for which inequality $(1)$ is violated (I have tried the beta and Kumaraswamy distributions on $[0,1]$ with many different combinations of parameters). An example of an $f$ that is not log concave for which $\phi(\mu)<0$ would also be helpful (as I am not entirely sure whether the log-concavity is relevant). Inequality $(1)$ can also be written as (using integration by parts): $$\begin{align}&E[V\mid V\geq \mu]\cdot P(V\geq \mu)+\mu\cdot P[V\leq \mu]-E[\hat{V}\mid \hat{V}\geq \mu]\cdot P(\hat{V}\geq \mu)\\
&=\int_{\mu}^{\overline{v}}vf(v)dv+\mu F(\mu)-\int_{\mu}^{\overline{v}}v\hat{f}(v)dv\\\tag{2}
&=\int_{\mu}^{\overline{v}}vf(v)dv+\mu F(\mu)-\int_{\mu}^{\overline{v}}v[2f(v)F(v)]dv\\
&=\int_{\mu}^{\overline{v}}vf(v)[1-2F(v)]dv+\mu F(\mu)\geq 0\end{align} $$ where $\hat{V}$ denotes the random variable that is the maximum of two independent copies of $V$ , $\hat{F}$ given by $\hat{F}(v)=[F(v)]^2$ is its distribution function and $\hat{f}$ given by $\hat{f}(v)=2f(v)F(v)$ is its density function. Some extra details: Let $\phi(x)=g(x)-h(x)$ where $g$ and $h$ are given by $$g(x)=\int_{x}^{\overline{v}}vf(v)dv+\mu F(x),\qquad \text{and} \qquad h(x)=\int_{x}^{\overline{v}}v[2f(v)F(v)]dv$$ Then inequality $(1)$ is $\phi(\mu)\geq 0$ . Denoting the mean of $\hat{F}$ by $\hat{\mu}$ , it is easy to see that: $$\phi(\underline{v})=\mu-\hat{\mu}<0\quad \text{and}\quad  \phi(\overline{v})=\mu>0$$ Also, $\phi$ is strictly increasing: $$\phi'(x)=(\mu-x+2xF(x))f(x)\geq xF(x)f(x)>0,\quad \forall x\in(\underline{v},\overline{v})$$ where the first inequality follows from Markov's inequality. It follows that there exists a unique $\bar{x}\in(\underline{v},\overline{v})$ such that $$\phi(x)\lesseqqgtr0\iff x \lesseqqgtr\bar{x}.$$ Additionally $$g'(x)\gtreqqless0\iff x \lesseqqgtr\mu$$ so that the maximum of $g$ is $g(\mu)$ . Note also that integrating by parts gives $$g(x)=\bar{v}+(\mu-x)F(x)-\int_x^{\overline{v}}F(v)dv\qquad \text{and}\qquad h(x)=\bar{v}-x[F(x)]^2-\int_x^{\overline{v}}[F(v)]^2dv$$ Some facts related to log-concavity: Log-concavity of $f$ implies log-concavity of $F$ and $1-F$ If $f$ is differentiable then log-concavity of $F$ is equivalent to $f^2-Ff'\geq 0$ and log-concavity of $1-F$ is equivalent to $(1-F)f'+f^2\geq 0$ Log-concavity of $F$ implies $F(\mu)\geq \frac{1}{e}$ Products of log-concave functions are log concave. For example $F[1-F]$ is log-concave.
-Log-concave densities are (strongly) unimodal A proof that $\phi(\mu)\geq 0$ if $\mu\geq m$ and $\mu\geq \overline{v}/2$ Let $m$ be the median of $F$ . Then $$\phi(m)=\frac{1}{4}(2\mu-m)-\int_m^{\overline{v}}F(v)[1-F(v)]dv\geq \frac{1}{4}(2\mu-\overline{v})$$ where the last inequality follows because the integrand is at most $1/4$ . Since $\phi$ is increasing and $\mu\geq m$ , the result follows. (Note that this result allows us to conclude that $\phi(\mu)\geq 0$ for all symmetric distributions.) A lower bound for $\phi(\mu)$ From Chebyshev's integral inequality : $$\int_{\mu}^{\overline{v}}[F(v)]^2dv\geq \frac{1}{\overline{v}-\mu}\left[\int_{\mu}^{\overline{v}}F(v)dv\right]^2$$ Thus $$-\int_{\mu}^{\overline{v}}F(v)[1-F(v)]dv\geq -\frac{1}{\overline{v}-\mu}\int_{\mu}^{\overline{v}}F(v)dv\left(\overline{v}-\mu-\int_{\mu}^{\overline{v}}F(v)dv\right)$$ Since $\int_{\mu}^{\overline{v}}F(v)dv\leq \overline{v}-\mu$ and $$\int_{\mu}^{\overline{v}}F(v)dv=\overline{v}-\mu F(\mu)-\int_{\mu}^{\overline{v}}vf(v)dv$$ we get $$-\int_{\mu}^{\overline{v}}F(v)[1-F(v)]dv\geq \mu[1-F(\mu)]-\int_{\mu}^{\overline{v}}vf(v)dv.$$ It follows that $$\begin{align*}
\phi(\mu)&\geq\mu F(\mu)^2+\mu[1-F(\mu)]-\int_{\mu}^{\overline{v}}vf(v)dv \\
&=\mu-\int_{\mu}^{\overline{v}}vf(v)dv-\mu F(\mu)[1-F(\mu)]\\
\tag{3}
&=\int_{\underline{v}}^{\mu}vf(v)dv-\mu F(\mu)[1-F(\mu)]\\
&=\mu F(\mu)^2-\int_{\underline{v}}^{\mu}F(v)dv
\end{align*}$$ The lower bound above seems to be nonnegative for the beta distributions and Kumaraswamy distributions. It is exactly zero for the uniform distribution on $[0,1]$ . A proof that $\phi(\mu)\geq 0$ when $f$ is increasing on $[\underline{v},\mu]$ and $F(\mu)\geq 1/2$ Since $F(\mu)[1-F(\mu)]\leq 1/4$ , the lower bound $(3)$ gives the following sufficient condition for $\phi(\mu)\geq 0$ : $$\int_{\underline{v}}^{\mu}vf(v)dv\geq\frac{1}{4}\mu$$ If $f$ is increasing on $[\underline{v},\mu]$ and $F(\mu)\geq 1/2$ then, $$\int_{\underline{v}}^{\mu}vf(v)dv\geq \frac{\mu+\underline{v}}{2}F(\mu)\geq \frac{1}{4}\mu$$ where the first inequality comes from by Chebyshev's integral inequality.","['inequality', 'probability-distributions', 'integral-inequality', 'probability']"
3400491,"Given a set of N resistors, not guaranteed identical, how many different arrangements using k resistors can be made?","I'm trying to develop a program that evaluates all possible arrangements (combinations of series and parallel) of k resistors from a set. From what I've read, if the resistors were identical values, then this would just be a permutation formula. But what if the k resistors have different values? Say I don't care if any arrangements end up having the same net resistance as each other, I just want to know the total number of ways I can arrange R1, R2, ... Rk. Ignoring the set for the moment (or setting N = k), I get that when k =1, there's only one arrangement (obviously). When k=2, there are 2 (both in series, both in parallel). When k = 3, I get 8: 1 x all three in series 1 x all three in parallel 3 x 1 in parallel with 2 in series, and 3 x 1 in series with 2 in parallel When k becomes 4 or above, this becomes a lot more complicated. 3 series resistors can be parallel with 1, or 1 can be in series with 3 parallel, or 2 parallel resistors can be in series with 2 other parallel resistors, or 2 series can be in series with 2 parallel, etc. Does anybody have a solution for this problem, or know of any statistical formula that would help me? EDIT : after a quick and dirty attempt to sketch out all possible arrangements for 4 resistors, I counted 52 different arrangements. As best as I can explain: 1 x all 4 in series 1 x all 4 in parallel 4 x 1 in series with 3 in parallel 12 x 1 in series with 1 resistor in parallel with 2 others in series 6 x 2 in series, in series with 2 in parallel 3 x 2 in parallel in series with 2 in parallel 3 x 2 in series parallel with 2 in series 6 x 2 in series in parallel with 2 in parallel 4 x 1 in parallel with 3 in series 12 x 1 in parallel with (1 in series with 2 in parallel) That's probably not very easy to follow, but I'm pretty sure I'm correct. So now I have for N=k, k = 1: y = 1 k = 2: y = 2 k = 3: y = 8 k = 4: y = 52 k = 5: y = ??","['graph-theory', 'statistics', 'permutations', 'combinations']"
3400533,Linearity of a function on multivariable calculus,"Let $f \colon \mathbb {R}^n  \to  \mathbb {R} $ be a $C^1$ class function such that $f (\frac {x}{2}) = \frac {1}{2} f(x)$ . Show that $f$ is linear. Hint : show that $\nabla f (x) = \nabla f (0)$ , for all x, and conclude that that $f (x) = \nabla f (x) \bullet x $ (dot product or scalar product). I have no idea how can the hint help me. Can anyone give me some help?","['derivatives', 'real-analysis']"
3400546,Total number of integer solutions with constraints,"Find the number of ways 5 dices can be rolled to get a sum of 25. While solving this question, the way we solve it is $x_1+x_2+x_3+x_4+x_5$ $=25$ where $1<=x_i<=6$ So we replace $x_i$ by $y_i =6-x_i$ , which is $x_i=6-y_i$ substituting $x_i$ in the above equation we get it as→ $(6*5) – (y_1+y_2+y_3+y_4+y_5)$ $=25$ $(y_1+y_2+y_3+y_4+y_5)$ = $5$ After solving this equation by integer solutions formula $(n-r+1)! / (n! * (r-1)!)$ we get the ans as → $126$ Now consider this problem, The number of non-negative integer solutions such that $x_1+x_2+x_3=17$ where $x_1>1, x_2>2 , x_3>3$ is ___________________ While solving this we are solving it like → $y_1= x_1-2$ , $y_2=x_2 -3$ , $y_3=x_3-4$ so, $x_1= y_1+2$ , $x_2=y_2 +3$ , $x_3=y_3+4$ Now we substitute this in our original equation to get→ $ y_1+2+y_2 +3+y_3+4 =17$ $ y_1+y_2 +y_3 =8$ and after solving this we get the ans as $45$ Now I have a $DOUBT$ here, in the second problem since when $x_1>1$ we make it as $x_1 = y_1+2$ , but in the first problem all the dices should have value $>0$ , so why in that case we haven’t made $x_i=y_i+1$ for all the cases? And moreover what if the question was like $x_1+x_2+x_3=12$ , $2<=x<=5$ then how to solve this using integer solution and applying the formula $(n-r+1)! / (n! * (r-1)!)$ ?",['discrete-mathematics']
3400591,"Is there an isomorphic copy of $SL(a,q^b)$ in $SL(b,q^a)$","Let $q$ be a prime power and $a,b$ be positive coprime integers.  Let $SL(a,q^b)$ be the special linear group of $a\times a$ matrices over the field $\mathbb F_{q^b}$ . 
Is it true that there is no isomorphic copy of $SL(a,q^b)$ in $SL(b,q^a)$ ?
I can show it by cardinality arguments if $a>b$ but I am not sure on how to do the other case. The general argument seems to be that the map has to be both $\mathbb F_{q^a}$ and $\mathbb F_{q^b}$ linear, so it has to be $\mathbb F_{q^{ab}}$ linear, but since the inclusion is purely abstract you cannot really conclude that. You can assume that $q$ is large enough if needed and/or that the isomorphic copy has to be transitive of $\mathbb F_{q^a}\setminus 0$ .","['finite-fields', 'general-linear-group', 'group-theory']"
3400642,Čech cohomology of $\mathbb{P}^2_k \setminus [1:0:0]$,"We can cover $X=\mathbb{P}^2_k \setminus [1:0:0]=D_+(y) \cup D_+(z)$ and the Čech complex is given by $$
0 \rightarrow \mathcal{O}_X(D_+(y)) \oplus \mathcal{O}_X(D_+(z)) \rightarrow \mathcal{O}_X(D_+(yz) ) \rightarrow 0
$$ where the non-trivial map is $d:(f,g) \mapsto f|_{\mathcal{O}_X(D_+(yz) )}-g|_{\mathcal{O}_X(D_+(yz) )}$ Explicitly we have $\mathcal{O}_X(D_+(y))=k[\frac{x}{y},\frac{z}{y}]$ and $\mathcal{O}_X(D_+(z))=k[\frac{x}{z},\frac{y}{z}]$ , while $\mathcal{O}_X(D_+(yz) )=k[\frac{x}{z},\frac{y}{z},\frac{z}{y}]$ . Now $\check{H}^1(X,\mathcal{O}_X)=\mathrm{coker}(d)$ , but I have some problem computing it. Any hint?","['algebraic-geometry', 'projective-schemes', 'sheaf-cohomology']"
3400667,Proving the time-integral of Brownian motion is not Markov,"Let us assume $(W_t)_{t\geq 0}$ is a Brownian motion with continuous paths. Let us define $$Y_t:=\int^t_0 W_s\,ds$$ One knows that $(W_t,Y_t)$ is a Gaussian process with strictly positive density on $\mathbb R^2$ for $t>0$ . Now we want to show that $Y$ is not a Markov process with respect to $\mathcal F^W_t$ . So assume that $W_t$ is a Markov process. Then by the Markov property one has for $0<s\leq t$ $$\mathbb E[Y_t\mid \mathcal F_s^W]=\mathbb E[Y_t\mid Y_s] = Y_s+(t-s)W_s$$ Hence therefore $$(t-s)W_s=\mathbb E[Y_t\mid Y_s]-Y_s$$ which makes $W_s$ a $\sigma(Y_s)$ -measurable random variable. Now I had two things in mind about how the proof should be proceeded and the first one is my favourite Approach 1. So this all means that there exists some Borel set $U$ such that $$\{\omega\ : \ W_s(\omega)\in [0,1]\}=\{\omega \ : \ Y_s(\omega)\in U\}$$ Note that $U\neq\emptyset$ because the set on the LHS has positive measure.  So there is this $u\in U$ for which one has the following: $$Y_s(\omega)=u \Longrightarrow W_s(\omega)\in [0,1]$$ But that cannot be true since one can certainly find an $\omega$ for which $Y_s(\omega)=u$ but $W_s(\omega)>2$ . Basically what I'm saying is that one can find an integral with the same value for a totally different function. But here problem arises as: the set $\{Y_s=u\}$ has measure zero so how should we make sense of this? And what makes one sure that another path of the BM $W$ exist for which $W_s(\omega)>2$ ? Approach 2. So apparently one has $W_s=g(Y_s)$ for some Borel measurable function $g$ . Let $$A=\{(x,g(x))\in\mathbb R^2 \ : \ x\in [0,1]\}$$ Then $$0<\mathbb P(Y_s\in [0,1])=\mathbb P((Y_s,W_s)\in A)$$ But $A$ is a graph of Borel-measurable function so it has zero Lebesgue measure contradicting that we had a positive Lebesgue density. Question. Are my approaches plausible? Otherwise, what are needed to fix them ? To be honest,  I'm more certain in approach 2, although I think that approach 1 can be rescued. I also know that this question can be done through covariance characterization of Gaussian Markov processes. I know there is also a post about that on this site, but I'm not really into that.","['stochastic-processes', 'markov-process', 'brownian-motion', 'probability-theory']"
3400671,Number of rational roots,"Let $f(x) = a_0 + a_1 x + ...... + a_n x^n$ be a polynomial of degree n with integral coefficients. If $f(1), a_0, a_n$ are odd then number of rational roots are. My Try: Let $f(x)=(x-\alpha)g(x), \alpha \in \mathbb I$ $f(0)=(0-\alpha)g(x)$ is odd, therefore both $\alpha$ and $g(0)$ must be odd, hence $(1-\alpha)$ must be even but $f(1)$ is odd. Therefore it won't have any integral root. How to prove for rational root?","['functions', 'roots', 'polynomials']"
3400687,"Let $(X_n)$ be a sequence of i.i.d. r.v.'s. Proving that if $A$ is a tail event, then it is also symmetric.","Let $(\Omega, \mathbb{F}, P)$ be a probability space and $(X_n)_{n \in \mathbb{N}}$ be a sequence of independent and identically distributed random variables. How can one prove that every tail event $A$ ; i.e., $A \in \chi  = \bigcap_{n} \mathbb{F}^{\infty}_{n}$ , such that $\mathbb{F}^{\infty}_{n} = \sigma(X_n, X_{n+1}, \cdots)$ , $\forall n$ , is also symmetric? Recall that an event $A$ is said to be symmetric if $\pi(A) = A$ , where $\pi(\cdot)$ is an one-to-one mapping such that $\pi(n) = n$ for every $n$ with a finite number or exceptions.","['probability-theory', 'probability']"
3400694,"Maximal ideal of ring of continuous real-valued functions on $[0, 1]$ is not finitely generated.","Consider the ring $R = C([0,1])$ . Let $c\in [0,1]$ and consider the ideal $I_{c} = \{f \in R : f(c) = 0 \}$ . I want to show that this ideal is not finitely generated. I was thinking that if $I_{c} = \langle \{f_{1},...,f_{n} \} \rangle$ , then I could consider $R/I$ , as it is a field and maybe derive some contradiction, but I am otherwise stuck.","['ring-theory', 'abstract-algebra', 'ideals']"
3400695,Find the smallest prime divisor of $1^{60}+2^{60}+...+33^{60}$,"Find the smallest prime divisor of $1^{60}+2^{60}+...+33^{60}$ . I found a solution online, but I have a few questions: In the beginning, the solver claims that $S^n = \begin{cases}S &\text{if } (p-1)\nmid n,\\ \{1\}&\text{if } (p-1)\mid n\end{cases}$ . Can he do this because $S^n \equiv S\mod n \text{ if } (p-1)\nmid n$ and $S^n\equiv 1\mod n \text{ if } (p-1)\mid n$ ? $n$ does not need to be prime, so how does this follow from Fermat's Little Theorem? Apparently this claim is wrong . I don't get why $\sum_{n}$ is divisible by $n$ if $(p-1)\nmid n$ and equivalent to $-1\mod n$ otherwise. I guess I can sort of understand why it could be a multiple of $n$ , but why does that depend on whether $(p-1)\mid n$ ? Why was the solver able to claim that $T_{k,n}=q\sum_{n}+1^n+2^n+\dots+r^n=\begin{cases}1^n+2^n+\dots+r^n &\text{ if } (p-1)\nmid n\\ r-q &\text { if } (p-1)\mid n\end{cases}$ ? The first case I understand because if $(p-1)\nmid n$ , then $\sum_{n}\equiv 0\mod n$ . And as for the second case, I know he uses the fact that if $(p-1)\mid n,\text { then } \sum_{n}\equiv -1\mod n$ . Everything else I understand.","['number-theory', 'modular-arithmetic', 'primitive-roots']"
3400699,Lagrange Multiplier Theorem,"I'm wondering why the Lagrange multiplier method only works when we assume that $\nabla g$ does not equal to $0$ . I functionally understand why the algebra does not work out if this is that case, but could you provide a conceptual explanation for what this situation represents?","['multivariable-calculus', 'lagrange-multiplier']"
3400705,"Looking for an example of non coherent sheaf $F$ over $X\subset P_R^n$ s.t. $H^{n+1}(X,F)\neq 0$.","This is related to Ueno's Algebraic Geometry, Thm 6.21. Thm 6.21 Let $S$ be a graded ring s.t. $S$ is f.g. over $R$ as an algebra and its finite generators are in degree 1. Assume $R$ is noetherian. Then for a coherent sheaf $F$ over $X=Proj(S)$ , $H^p(X,F)$ is finite $R-$ module. Furthermore, there is $m_0\geq 0$ s.t. $\forall m\geq m_0$ , $H^p(X,F(m))=0$ . For any coherent sheaf $F$ over $X$ , there is $n_0$ s.t. $\forall p\geq n_0$ $H^p(X,F)=0$ . $\textbf{Q:}$ Since the proof uses coherency of $F$ via resolution of $F$ by $O_X$ 's, I am looking for an example of $F$ that is not coherent s.t $H^i(X,F)$ is not finite over $R$ for some $i$ and $H^p(X,F)\neq 0$ when $p=n+1$ . $\textbf{Q':}$ How bad is situation if $F$ is quasicoherent not coherent? $\textbf{Q'':}$ If $F$ is not coherent, how bad do I fail $H^p(X,F(m))=0$ for all $p\geq 0$ when $m$ large.","['algebraic-geometry', 'abstract-algebra']"
3400714,"Show: $\int_0^1\int_0^1\frac{dx\,dt}{(xt)^2+xt+1}=\frac{2}{\sqrt3}\mathrm{Cl}_2\left(\tfrac{2\pi}{3}\right)$","How do you prove that $$\int_0^1\int_0^1\frac{dx\,dt}{(xt)^2+xt+1}=\frac{2}{\sqrt3}\mathrm{Cl}_2\left(\tfrac{2\pi}{3}\right)?$$ My proof: Suppose we have a sequence $(q_n)_{n\ge0}$ defined by the recurrence $$q_{n+2}=aq_{n+1}+bq_n,\qquad q_0,q_1,a,b \text{ given}.$$ We define the generating function $$q(t)=\sum_{n\ge0}q_nt^n,$$ and see that $$q(t)-q_1t-q_0=at(q(t)-q_0)+bt^2q(t),$$ so that $$q(t)=\frac{(q_1-aq_0)t+q_0}{1-at-bt^2}.$$ Consider the case $$\begin{align}
q_0&=0\\
q_1&=1\\
a&=-1\\
b&=-1,
\end{align}$$ i.e. $q_{n+2}+q_{n+1}+q_n=0$ for all $n\in\Bbb Z_{\ge0}$ , with $q_0=0,q_1=1$ . This has the generating function $$q(t)=\frac{t}{t^2+t+1}.$$ Note that if $q_n=0$ and $q_{n+1}=1$ for any $n\in\Bbb Z_{\ge0}$ , then $q_{n+2}=-1$ . This implies that $q_n=q_{n+3}$ for all $n$ , that is, the sequence is periodic with a period of $3$ . The first few values are $0,1,-1,0,1,-1,0,1,-1,..$ . Because of the alternating behavior of the sequence, we can represent it as a sine function: $$q_n=\alpha \sin(n\beta).$$ Since $1=q_1=\alpha\sin\beta\ne 0$ and $-1=q_2=\alpha\sin2\beta\ne0$ , both $\alpha$ and $\beta$ are nonzero, and additionally $\beta/\pi\not\in\Bbb Z$ . Since $q_n=0$ for $3|n$ , $3\beta/\pi\in\Bbb Z$ . Finally, if we ensure that $\alpha$ and $\beta$ are both positive, we get that $\beta=2\pi/3$ and $\alpha=2/\sqrt3$ . Thus $$\frac{1}{t^2+t+1}=\frac{2}{\sqrt3}\sum_{n\ge1}\sin\left(\tfrac{2\pi}{3}n\right)t^{n-1}.$$ If we replace $t$ by $xt$ and integrate over $(x,t)\in[0,1]\times[0,1]$ , we get $$\begin{align}
\int_0^1\int_0^1\frac{dxdt}{(xt)^2+xt+1}&=\frac{2}{\sqrt3}\sum_{n\ge1}\sin\left(\tfrac{2\pi}{3}n\right)\int_0^1x^{n-1}dx\int_0^1 t^{n-1}dt\\
&=\frac{2}{\sqrt3}\sum_{n\ge1}\frac{\sin\left(\tfrac{2\pi}{3}n\right)}{n^2}\\
&=\frac{2}{\sqrt3}\mathrm{Cl}_2\left(\tfrac{2\pi}{3}\right).
\end{align}$$ $\square$ From @LeBlanc's comment, $$\int_0^1 \int_0^1\frac{dx\,dt}{(xt)^2-2xt\cos\theta+1}=\frac1{\sin\theta}\mathrm{Cl}_2(\theta).$$","['integration', 'alternative-proof', 'definite-integrals', 'special-functions']"
3400738,Absolute Value of Integrals,"It is clear that $\left|\displaystyle\int fd\mu\right|\leq\displaystyle\int|f|d\mu$ in any general setting of measure space $(X,\Sigma,\mu)$ . But it is necessary that, for any $\delta>0$ , there exists some $A_{\delta}\in\Sigma$ such that $\left|\displaystyle\int_{A_{\delta}}fd\mu\right|>(1-\delta)\displaystyle\int_{X}|f|d\mu$ ? At least I think this is true in Euclidean Lebesgue integrals, as I have seen some authors take it for granted. One may have to choose $A_{\delta}$ to be ""switching"" the negative part of $f$ to the positive one to do the job, but I am struggling to make it. Any idea? Edit: So how does the author manage to choose such a $B_{n}$ to make the integral greater than the $1/4$ of the absolute integrand one?","['integration', 'measure-theory', 'lebesgue-integral', 'analysis', 'real-analysis']"
3400758,Use proof by mathematical induction to prove explicit formula for recursive sequence is correct,"Here is the question I am having trouble with. Suppose you have the following recursively defined sequence: P 1 = 4 P k = P k-1 + 4 · 3 k for all integers k ≥ 2 Suppose you have used the method of iteration to find the following explicit formula: P 1 = 4 P n = 2 · 3 n+1 - 14 for all integers n ≥ 1 Use proof by mathematical induction to show this is the correct explicit formula. Here is what I have so far: Base case: n = 1, 4 = 2 · 3 1+1 - 14; 4 = 2 · 9 - 14; 4 = 18 - 14; 4 = 4 ✓ Assume: P k = 2 · 3 k+1 - 14 for all integers k >= 1 Now we must show that P k+1 = 2 · 3 (k+1)+1 - 14 Then we must get P k+1 = P k + 4 · 3 k to look like what was previously stated. First, let’s substitute in our assumption: (2 · 3 k+1 - 14) + 4 · 3 k I will say that’s as far as I got because I have tried simplifying this multiple ways and I cannot even get it close to what it should look like. I’m starting to think I’ve made a mistake elsewhere. Any help is appreciated, thanks!","['induction', 'discrete-mathematics', 'recursion']"
3400765,A bijection $\phi:\mathbb R \to \mathbb R$ that must be an identity,"A bijection $\phi:\mathbb R \to \mathbb R$ that satisfies: $$\phi(a+b)=\phi(a) +\phi(b)\text{, }$$ $$\phi(ab)=\phi(a)\phi(b)$$ $$\forall a,b\in \mathbb R$$ must be the identiy function. What I've done is to show the obvious $\phi(0)=0$ and that the function is the identity $\forall a,b\in \mathbb Z$ , which follows from $\phi(\underbrace{a+\dots +a}_n)=n\phi(a)=\phi(a)\phi(n) \implies \phi(n)=n \text{ }\forall n\in \mathbb N$ . Now it is easy to show that $\phi(-1)=-1$ and to extend the identity to the integers. I can't seem to find a way to the reals.",['functions']
3400779,Using a line integral to find work,"For the life of me I can't see where I'm going wrong with this. Given the vector field $$ F(x, y) = \left[ xy, \frac{2y}{x} \right] $$ a particle travels on the hyperbola $$ \frac{x^2}{4} - y^2 = 1 $$ from $ \left(2\sqrt{10}, -3 \right) $ to $ \left(2, 0 \right) $ how much work is done by the force over the path? My take on this is to solve for x and parametrize $t = y^2 + 1$ such that $$ x = 2\sqrt{t} $$ $$ y = \sqrt{t-1} $$ $$ t\in\left[10,1\right]$$ for which $$ \int_C F(r(t)) \cdot r'(t) dt = \int_{10}^1 2\sqrt{t}\sqrt{t-1}\frac{1}{\sqrt{t}} + \frac{2\sqrt{t-1}}{2\sqrt{t}}\frac{1}{2\sqrt{t-1}} $$ $$ = \left. \left(\frac{4}{3}\left(t-1\right)^{\frac{3}{2}} + \sqrt{t} \right) \right|_{10}^1 = -35 - \sqrt{10} $$ would be grateful for any input.",['multivariable-calculus']
3400798,Schwarz's theorem,"We were provided the following example in the context of Schwarz's theorem: Let be $f:\mathbb{R}^2 \to \mathbb{R}$ , given by: $$
f{x \choose y}=\left\{\begin{array}{ll} \frac {xy^3}{x^2+y^2}, & {x \choose y}\neq {0 \choose 0} \\
         0, & {x \choose y}={0 \choose 0}\end{array}\right. .
$$ If we calculate the second order partial derivatives for each ${x \choose y} \neq {0 \choose 0}$ we get: $$
D_{12}f{x \choose y} = D_{21}f{x \choose y}.
$$ However, at point ${0 \choose 0}$ we have: $$
D_{12}f{0 \choose 0} =1 \neq 0 = D_{21}f{0 \choose 0}.
$$ Our lecture notes say that we now can deduce only from Schwarz's theorem, that both second order derivatives $D_{12}f{x \choose y}$ and $D_{21}f{x \choose y}$ cannot be continuous at point ${0 \choose 0} $ . I don't understand how we can deduce this fact only from Schwarz's theorem? Couldn't it be possible that only one of the two second order derivatives is continuous?","['partial-derivative', 'continuity', 'multivariable-calculus']"
3400844,"If $\lim\limits_{h\to 0^+}\frac{f(x+h)-f(x)}{h}=0$ for all $x\in I$, then $f$ is constant.","So suppose $I\subset \mathbb{R}$ is an open interval and $f: I\to \mathbb{R}$ a continuous function such that $$\lim\limits_{h\to 0^+}\frac{f(x+h)-f(x)}{h}=0$$ for all $x\in I$ . Show that $f$ is constant. My ideas: Proof by contraposition. Suppose $f$ is not constant; thus there are $a,b\in I$ with $a<b$ such that $f(a)\neq f(b)$ . I am given the hint that I should check the $\sup$ of $$M:=\left \{ x\in [a,b] : \frac{f(x)-f(a)}{x-a} < \frac{f(b)-f(a)}{2(b-a)}\right\}.$$ I tried wrapping my head around the geometric meaning of $\frac{f(x)-f(a)}{x-a} $ and $\frac{f(b)-f(a)}{2(b-a)}$ . I came to the conclusion that $\frac{f(x)-f(a)}{x-a} $ approximates the slope of the curve at $a$ for sufficient $x$ . $\frac{f(b)-f(a)}{2(b-a)}$ is half of the slope of the secant line connecting $a$ with $b$ . But what does finding the $\sup$ of $M$ mean and how does it contradict the fact that $f$ is not constant?","['continuity', 'supremum-and-infimum', 'derivatives', 'real-analysis']"
3400863,Does the Fundamental Theorem of Algebra follow from the real Spectral Theorem?,"I found a slick way to prove that every real normal matrix is orthogonally equivalent to a block diagonal form consisting of diagonal parts and $2 \times 2$ parts of the form $$\begin{pmatrix}a & b \\ -b & a\end{pmatrix}.$$ This seems awfully close to proving FTA - if every real polynomial is the characteristic polynomial of a normal matrix, then every real polynomial consequently splits over $\mathbb C$ . So my question is: Is there a  slick way to find a real normal matrix given a characteristic polynomial? Note that the companion matrix is not normal in general.","['general-topology', 'abstract-algebra', 'linear-algebra']"
3400868,Ring Homomorphism determined by a 6th root of unity,"I am working on the following problem : Let $K$ denote the algebraic closure of the 5 element field $F_5$ . Let $f: F_5[x] \longrightarrow K$ be the ring homomorphism determined by $f(x) = \omega$ , where $\omega$ is a primitive 6th root of 1 in $K$ . a) What is $f(3x^{50} - 2x^{45} +2)$ ? b) Find the dimension, over $F_5$ , of the image of $f$ . c) Find the kernel of $f$ . I think I've got a good grasp on part a). We use basic properties that any ring homomorphism satisfies: $f(3x^{50} - 2x^{45} + 2) = f(3x^{50}) - f(2x^{45}) + f(2)$ = $3[f(x)]^{50} - 2[f(x)]^{45} + f(2)$ = $3(\omega^{50}) - 2(\omega^{45}) + f(2)$ = $3(\omega^2) - 2(\omega^3) + f(2)$ (using that $\omega^6 = 1$ ) = $3 \cdot \omega^2 - 2 \cdot \omega^3$ My only question here is, am I justified in saying $f(2) = 0$ , since the homomorphism is determined completely by $f(x) = \omega$ ? b) I'm not sure about this part. I thought of using the rank-nullity theorem, but since $F_5[x]$ is not finite-dimensional, I don't know of a clever way to use this to determine the dimension of the image. Is there some other way here to determine the dimension of the image? c) I know of the identity $1 + \omega + \omega^2 + ... + \omega^{n-1} = 0$ , where $\omega$ is an nth root of unity. But, how can I take $f$ of an element in $F_5[x]$ and obtain $1 + \omega + ... + \omega^5$ , if I don't know what $f(1)$ is ? I can only deduce what $f(0)$ is, since a ring homomorphism sends identity elements to identity elements. Also, after, if possible, I can find what element in $F_5[x]$ gets sent to $1 + \omega + ... + \omega^5 = 0$ , is there any other element of $F_5[x]$ that can get send to $0$ by $f$ , besides $0$ ? Or is the kernel only consisting of $0$ and the element mapping to $1 + \omega + .. + \omega^5$ ? Thanks!","['ring-homomorphism', 'ring-theory', 'abstract-algebra', 'complex-numbers']"
3400930,Trace map from finite surjective morphism of normal irreducible varieties,"I am trying to understand why if $f: Y \rightarrow X$ is a finite surjective morphism of normal (irreducible) complex varieties, there is a trace-map $f_{\ast} \mathcal{O}_Y \rightarrow \mathcal{O}_X$ splitting the natural inclusion in the other direction. What I understand so far is (1) that the finiteness condition ensures that $f_{\ast} \mathcal{O}_Y$ is integral over $\mathcal{O}_X$ , so $K(Y)$ is algebraic over $K(X)$ and (2) that there is a trace map from the algebraic closure $K(Y)$ to $K(X)$ , which restricts since the extension is integral. However these steps feel a little shakey to me, and also I haven't used normality. Is it just required for the extension of fields to be Galois (I guess it guarantees it will be a normal extension?) I don't quite understand this part. For reference, I am trying to understand the proof of the Injectivity Lemma 4.1.14 in Lazarsfeld. Thanks for your help.","['algebraic-geometry', 'abstract-algebra']"
3400937,Convergence in Measure and Continuity,"I am trying to solve this problem:
Consider measure space $(\Omega,\mathcal{F},\mu)$ . Also, $\mu$ is $\sigma$ -finite. Suppose that a sequence of measurable functions $h_n$ converges to $h$ in measure. Assume $h$ is integrable and there exists a finite constant $K$ such that $\int |h_n|d\mu \leq K$ for all $n$ . Prove that $g(h_n)$ converges in measure to $g(h)$ for any continuous function $g$ . My try: We can write \begin{align}
& \mu(\{\omega: |g(h_n)-g(h)|\geq \epsilon\}) \\&=\mu(\{\omega: |g(h_n)-g(h)|\geq \epsilon, |h_n(\omega)-h(\omega)|\geq \delta_m\})+ \mu(\{\omega: |g(h_n)-g(h)|\geq \epsilon, |h_n(\omega)-h(\omega)|\leq \delta_m\})
\end{align} where $\delta_m$ goes to zero from above. Then, I try to prove that the first term on the RHS is zero because when $m \to \infty$ is basically zero since the set is empty, and the second term on the RHS is also zero due to the fact that $h_n$ converges to $h$ in measure. My problem is I did not use the fact that $\int |h_n|d\mu \leq k$ . So, what is the problem of my proof?
Can we prove this using DCT or MCT?","['measure-theory', 'convergence-divergence', 'probability-theory', 'real-analysis']"
3400941,Strong Markov Property: Having Trouble Understanding Proof Using Strong Markov,"I'm having trouble understanding this proof of Example 1.4.4 From Norris' Markov Chains: Let $X_n$ be a DTMC, with transition matrix P and state-space $I$ . Let $Y_m=X_{T_m}$ for $m \in \mathbb{N}$ .
Show $Y_m$ is a DTMC. Define $$T_0=\inf\{n\geq0:X_n\in J\subset I\}$$ and $$T_{m+1}=\inf\{n> T_{m}:X_n\in J\subset I\}$$ For $i_0,...,i_{m+1} \in J$ we have \begin{align*}
&P(Y_{m+1}=i_{m+1}|Y_0=i_0, ..., Y_m=i_m)\\
&=P(X_{T_{m+1}}=i_{m+1}|X_{T_{0}}=i_0,...,X_{T_{m}}
=i_m)\\
&=P(X_{T_{m+1}}=i_{m+1}|X_{T_m}=i_m)\\
&=P(X_{T_{1}}=i_{m+1}|X_{0}=i_m)
\end{align*} I'm confused by several lines of the proof. Does the second equality follow from the fact that $X_n$ is a DTMC and thus by Markov property?
Does the third equality follow form the fact that $T_m$ is a stopping time so by Strong Markov Property Markov Chain regenerates at $T_m$ so its like starting from $0$ and hitting for first time. So shouldn't it be $X_{T_{0}}=i_{m+1}$ and not $X_{T_{1}}=i_{m+1}$ ? (Really confused about this). Also I don't get how the proof shows that $Y_m$ is a Markov chain. We showed that $P(Y_{m+1}=i_{m+1}|Y_0=i_0, ..., Y_m=i_m)=P(X_{T_{1}}=i_{m+1}|X_{0}=i_m)$ . How does this show that $Y_m$ is a Markov chain and has the Markov property?","['markov-chains', 'real-analysis', 'stochastic-processes', 'probability-theory', 'probability']"
3400950,"Primitive instances where $c^3|(a^3+b^3)$ with $a,b,c\in\mathbb{N}$","It is known that by Fermat's Last Theorem there are no solutions to $a^3+b^3=c^3$ for $a,b,c\in\mathbb{N}$ . I wondered about how multiplying the $c^3$ by a constant would change this fact. Accordingly, I have been looking into instances where $c^3|(a^3+b^3)$ for $a,b\in\mathbb{N}$ . In other words, solutions to the Diophantine Equation: $a^3+b^3=dc^3$ where $a,b,$ and $c$ are pairwise co-prime and $a,b,c>0$ Obviously there are some trivial solutions. If $c=1$ , for example, $a$ and $b$ can be any integers, and $d$ can be chosen to simply be $a^3+b^3$ . By requiring that $a,b,$ and $c$ are pairwise co-prime and that $c\not=1$ , we eliminate the trivial solutions, and what remains is of much more interest. For $a,b,c,d\le20$ , there are 5 solutions: $4^3+5^3=7*3^3$ $2^3+7^3=13*3^3$ $1^3+8^3=19*3^3$ $3^3+5^3=19*2^3$ $1^3+19^3=20*7^3$ Under $100$ there are $16$ solutions, as found by Mathematica. My  question about this equation: Has it been studied previously? Are there infinitely many primitive solutions (which it seems like there are)? If so, can they be parametrized?","['cubics', 'number-theory', 'elementary-number-theory', 'integers', 'diophantine-equations']"
3400978,Proof of the Kramers-Kronig relation for amplitude and phase,"I learned that the the amplitude and phase of a transfer function of a minimum phase system are related by the Hilbert transform, specifically, $$\arg(H(\Omega))=-\frac{1}{\pi} \mathrm{PV}\int_{-\infty}^{\infty}\frac{\ln|H(\omega)|}{\Omega-\omega}d\omega  $$ where $\mathrm{PV}$ denotes principal value. A proof I found will be provided at the end of this post. My question concerns the other direction: We can also obtain the amplitude from the phase by Hilbert transform, up to a constant multiplicative factor $c$ , i.e., $$ \mathcal{H} \{\arg(H(\omega))\}=\ln{|cH(\omega)|} $$ However, I am unable to find a rigorous proof. Does anyone know how to prove this? Thanks. Appendix: Proof of the forward direction (amp-to-phase). Referring to the contour below. By minimum phase, the transfer function $H$ has no zero at the lower half $\omega$ -plane, and thus $\ln{H(\omega)}$ is analytic there. Then by Cauchy integral theorem, we have $$\int_{C_P+C_R+C_0}\frac{\ln{H(\omega)}}{\omega^2-\Omega^2}d\omega=0$$ Integration along $C_0$ vanishes as the radius goes to infinity, because the denominator is second order. (It is not the case if the denominator is only first order, as in the standard proof of the real-imag form of KK relation, because the log function goes to $\infty$ in the lower half $\omega$ -plane.) Hence we have $$\mathrm{PV}\int_{-\infty}^{\infty}\frac{\ln{H(\omega)}}{\omega^2-\Omega^2}d\omega=-\int_{C_R}\frac{\ln{H(\omega)}}{\omega^2-\Omega^2}d\omega\\=-i\pi\{\mathrm{res}_{\Omega}[\frac{\ln{H(\omega)}}{\omega^2-\Omega^2}]+\mathrm{res}_{-\Omega}[\frac{\ln{H(\omega)}}{\omega^2-\Omega^2}]\}\\=-i\pi\{\frac{\ln{H(\Omega)}}{2\Omega}+\frac{\ln{H(-\Omega)}}{-2\Omega}\}=\frac{\pi}{\Omega}\arg(H(\Omega))$$ Since the RHS is real, we only have to consider the real part of the LHS. By writing $\frac{1}{\omega^2-\Omega^2}=\frac{1}{2\Omega}[\frac{1}{\omega-\Omega}-\frac{1}{\omega+\Omega}]$ , and noting that $|H(\omega)|$ is an even function of $\omega$ , we have $$\frac{\pi}{\Omega}\arg(H(\Omega))=\frac{1}{2\Omega}\mathrm{PV}\int_{-\infty}^{\infty}\frac{\ln{|H(\omega)|}}{\omega-\Omega}-\frac{\ln{|H(\omega)|}}{\omega+\Omega}d\omega\\
=-\frac{1}{\Omega}\mathrm{PV}\int_{-\infty}^{\infty}\frac{\ln{|H(\omega)|}}{\Omega-\omega}d\omega$$ as was to be shown.",['complex-analysis']
3401011,Classic Hat Probability Problem,"This is a textbook example and I am confused about the explanation. This question was asked by different people in stack-exchange already but I couldn't find the solution to my question. Here's the problem: At a party $n$ man take their hats. The hats are then mixed up and each man randomly selects one. We say that a match occurs if a man selects his own hat. What is the probability of no matches? What is the probability of exactly $k$ matches? Solution (summarized): $P_n = P(E) =$ the event that no matches occur, dependence on $n$ , $M =$ first man selects his own hat $M^c=$ first man does not select his own hat So, $P_n = P(E) = P(E|M)P(M) + P(E|M^c)P(M^c)$ Since $P(E|M) = 0$ , we get $P(E)=P(E|M^c)* \frac{n-1}{n}$ Here's my question: the solution says $P(E|M^c)$ is the probability of no matches when $(n−1)$ men select from a set of $n − 1$ hats that does not contain the hat of one of these men. This can happen in either of two mutually exclusive ways. Either there are no matches and the extra man does not select the extra hat (this being the hat of the man that chose first), or there are no matches and the extra man does select the extra hat. Therefore, we get $P(E|M^c)= P(E|M^c)=P_{n−1}+ \frac{1}{n-1}*P_{n−2}$ What does the bolded part exactly mean? Who is the extra man? Is he the last person to choose the hat? If so, if the extra man does select the extra hat, shouldn't the probability of no matches be $0$ . Can we do this question in  a different way? like setting $X_i=$ the $i^{th}$ person selecting his hat, and the probability of no matches will be $P(\sum_{i=1}^n X_i = 0)$",['probability']
3401045,How many right triangles can be built from points,"There are array of points, I need to determine how many right-angled triangles can be built from them. This is a task for both programming and geometry. Because the number of points can be very large, and the time to run the program is limited. Please tell me whether it is possible to somehow derive a formula to determine the number of possible triangles. Input format:
The first line contains a single integer N - the number of points in the set
Next, N lines contain two integers: xi, yi My code: from math import sqrt

def f(x1,y1,x2,y2,x3,y3):
    a = [(x2-x1)**2+(y2-y1)**2, (x3-x2)**2+(y3-y2)**2, (x1-x3)**2+(y1-y3)**2]
    a.sort()
    if a[0]+a[1]==a[2]:
        return True
    return False 

N = int(input())
ar = []
for i in range(N):
    ar.append([int(j) for j in input().split()])

count = 0
for ia in range(N):
    for ib in range(N):
        for ic in range(N):
            if ia!=ib and ia!=ic and ib!=ic :
                a = ar[ia]; b = ar[ib]; c = ar[ic]
                if f(a[0],a[1],b[0],b[1],c[0],c[1]): 
                    count+=1
print(count//6) my code goes beyond time limits P.S. DSolved the problem using vectors, also does not pass in time def f1(x1,y1,x2,y2,x3,y3):
    a = [x2-x1,y2-y1]
    b = [x3-x2,y3-y2]
    if a[0]*b[0]+a[1]*b[1] is 0:
        return True 
    return False

N = int(input())
ar = []
for i in range(N):
    ar.append([int(j) for j in input().split()])

count = 0
for ia in range(N):
    for ib in range(N):
        for ic in range(N):
            if ia!=ib and ia!=ic and ib!=ic :
                a = ar[ia]; b = ar[ib]; c = ar[ic]
                if f1(a[0],a[1],b[0],b[1],c[0],c[1]): 
                    count+=1 
print(count//2) Beginning of implementation of the algorithm with polar angles: from math import *

def polar(a,b):
    res = atan2(b,a)
    if (res < 0) :
      res += 2 * pi
    return res

N = int(input())
A = []

for i in range(N):
    A.append([int(j) for j in input().split()])

DS = []
for i in range(N):
    p = A[i]
    for j in range(N):
        if j!=i:
            D = [A[j][0]-p[0], A[j][1]-p[1]]
            ang = polar(D[0],D[1]) 
            DS.append(ang)

DS.sort()
#what's next?","['triangles', 'python', 'geometry']"
3401054,Assume $ A(v) \cdot v \leq -|v|^2$ for all $v \in V$. Show that $ \lim_{t\to\infty} e^{tA} = 0$,"$V$ is a finite inner product space, and $A$ is linear map $A:V\to V$ . Assume $$ A(v) \cdot v \leq -|v|^2 \qquad \text{for all} \quad v \in V.$$ Show that $ \lim_{t\to\infty} e^{tA} = 0$ . My thinking is: So $\operatorname{tr}(A) \leq -\dim(V) = -n $ , and hence $\det(e^{tA})=e^{\operatorname{tr}(tA)} \leq e^{-tn} = 0$ as $t \to \infty$ . So $ \exists v\in V$ , $\lim_{t\to\infty} e^{tA}(v) = 0 $ . And then I am stuck. Any suggestions? Thanks!","['matrix-exponential', 'linear-algebra', 'functional-analysis', 'vector-spaces']"
3401102,$x_1$ and $x_2$ are the solutiton of $\frac{2\cdot \sin(x) \cdot \cos(2x)}{\cos (x) \cdot \sin (2x)} - 5 \tan(x) + 5 = 0$,"$x_1$ and $x_2$ are the solutiton of $\frac{2\cdot \sin(x) \cdot \cos(2x)}{\cos (x) \cdot \sin (2x)} - 5 \tan(x) + 5 = 0$ then, $\tan(x_1 + x_2) = ....$ i can do it by doing it $\dfrac{2\cdot \sin(x) \cdot (\cos^2x - \sin^2x)}{\cos (x) \cdot 2 \sin x \cos x} - 5 \tan(x) + 5 = 0$ leads to $(\sin x - \cos x)(\sin x + 6 \cos x) = 0$ but it's complicated, do you know the less complicated way to solve it?","['algebra-precalculus', 'trigonometry']"
3401103,Actual meaning of Confidence Interval,"I am a little confusing about the right understanding of confidence interval. $100$ random samples are taken to estimates the mean $\mu$ . A $95$ %
  confidence interval on the mean is $0.49 \leq \mu \leq 0.82$ . Consider
  the following statement: There is a $95$ % chance that $\mu$ is between $0.49$ and $0.82$ . Is the statement correct? Explain your answer. I suppose the statement is wrong and the right one must be: There is a $95$ % chance that $\mu$ is actually in some interval that are found.For example, by researching, I found 100 different intervals and 95 of them contains $\mu$ in average.",['statistics']
