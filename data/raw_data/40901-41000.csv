question_id,title,body,tags
403062,Notation for the pushforward measure,"Given a measure space $(X,\Sigma,\mu)$, a measurable space $(Y,\Xi)$ and a measurable map $f\in\Sigma/\Xi$, the pushforward measure $\nu:=\mu\circ f^{-1}$ is given by
$$
  \nu[A] = \mu[f^{-1}(A)]
$$
for any $A\in \Xi$. That is, $f$ pushes $\mu$ from $(X,\Sigma)$ to $(Y,\Xi)$. The notation $\mu\circ f^{-1}$ is often used in probability theory, but it is not really convenient. I saw also a notation with an asterisk such as $\nu = f^*\mu$ here and $\nu = f_*\mu$ here and here . Since I have no much experience with pushforwards and pullbacks in other fields, I am not sure which of the notations is the right one: with an asterisk on the top or bottom. I would be happy if somebody clarifies this. P.S. If one considers the category of measurable maps and stochastic (conditional) kernels as arrows, $f$ and $\mu$ are both special cases of arrows so actually in that notation it appears that
$$
  \nu = f\circ \mu
$$
which is very confusing taking into account the probabilistic variant $\nu = \mu\circ f^{-1}$. I've found another notation $f_\#\mu$ here .","['probability-theory', 'measure-theory', 'notation']"
403076,Kernel of a morphism between coherent sheaves.,"Throughout this book, http://books.google.co.kr/books/about/Algebraic_Geometry_and_Arithmetic_Curves.html?id=uaLKdA0PxS4C&redir_esc=y , kernel of a morphism between coherent sheaves on a locally Noetherian scheme is also coherent. More precisely, let $X$ be a locally Noetherian scheme and  $u:\mathcal{F}\to\mathcal{G}$ be a morphism of coherent sheaves on $X$. Then $\textrm{Ker }u$ is also coherent. The author says, this is trivially true. However, I cannot prove it. Moreover, I do not know whether it is really true or not. Even though I do not have any explicit example, I think this would be false in following sense; when $X$ is locally Noetherian scheme and $\mathcal{F}$ is a coherent sheaf on $X$, it is known that $\mathcal{F}(U)$ is finitely generated $\mathcal{O}_X(U)$-module for any affine open subset $U$ of $X$. If $\textrm{Ker }u$ is coherent, then the sequence $\textrm{Ker }u(U)\to\mathcal{F}(U)\to\mathcal{G}(U)$ of $\mathcal{O}_X(U)$-modules is an exact for any affine open $U$. However, in general, a submodule of a finitely generated module is not finitely generated. So, maybe there would be an example that arises form the sequence $\textrm{ker} f \to L\xrightarrow{f}M$ where $L,M$ are finitely generated modules and $\textrm{ker }f$ cannot be generated by any finite set. Is this reasonable? Actually, we can find the same statement for $X$ is Noetherian case in Hartshorne's book. If the above statement is true, how can we expand the case?","['algebraic-geometry', 'abstract-algebra']"
403083,Is martingale problem interesting?,"Why is the Martingale problem interesting, or useful to areas outside of math like economics, game theory, physics, etc.? As a reminder, the Martingale problem is about finding a process so that when a given linear operator is applied to it, you get a martingale. http://www.ma.utexas.edu/mediawiki/index.php/Martingale_Problem Impreciseness is fine, I'm only looking for intuition and scope of knowledge here. (For instance, that website is too advanced for me to understand technically.) I know Gaussian processes and Markov Chains are useful to physics.  Are Martingales also useful to physics?","['probability-theory', 'martingales']"
403084,Complex differentiable but not analytic on circle of convergence,"I'm trying to get a better handle on behavior of complex power series on the boundary of their maximal disk of convergence. I'm reading Bak-Newman's Complex Analysis , Chapter 18.1. A regular point $z_0$ on the circle bounding the maximal disk of convergence is defined as one where the function in question can be continued analytically to some open neighborhood of $z_0$. My understanding of analytic at a point in this book is that it is always used to indicate differentiability on some neighborhood of the point , so that being analytic at a point is equivalent to being analytic in some open disk around a point. (By differentiable at a point $z_0$ I mean that $\lim_{z \to z_0}\frac{f(z)-f(z_0)}{z - z_0}$ exists, or that equivalently the function $\mathbb{R}^2 \to \mathbb{R}^2$ is differentiable and the Cauchy-Riemann equations hold.) This section of the book also defines a singularity on the circle of convergence to be a point which is not a regular point. I'm trying to figure out how this definition of singularity relates to the notion of isolated singularity with which I'm already (more or less) comfortable. My question is this: Is it possible to be differentiable at a point on the circle of convergence, but not analytic at that point? More or less, I'm trying to figure out if there is a function which is defined in some open neighborhood of the closed unit disk, analytic in the open unit disk, complex differentiable at $z = 1$, but not differentiable at each of a sequence of real $x_n > 1$ which converge to $1$. Can this happen?","['power-series', 'analyticity', 'complex-analysis']"
403096,Solving the next differential equation,"How can I solve the next differential equation?
$$\cos(x+y)dx=x\sin(x+y)dx+x\sin(x+y)dy$$
I dont know what kind of equation it is.
It's not homogeneous, separable differential equation or linear. Any suggestions?","['ordinary-differential-equations', 'calculus']"
403099,Definition of a primitive polynomial,"I understand there are already some questions ( A , B ) on primitive polynomials.  But none of these clears my confusion. In page 84 of Handbook of Applied Cryptography , primitive polynomial has been defined as, Now, if I try to understand the definition by dissecting the parts, This is an irreducible polynomial, that means, it cannot be factored into the product of two or more non-trivial polynomials. The polynomial $f(x) \in \mathbb{Z}_p[x]$. So, the polynomial belongs to the  polynomial ring $\mathbb{Z}_p [x]$, where, $\mathbb{Z}_p [x]$  is the ring formed by the set of all polynomials in the indeterminate $x$ having coefficients from $\mathbb{Z}_p$. Here $\mathbb{Z}_p$, will be the integers modulo $p$,  set of (equivalence classes of) integers
$\{0, 1, 2, . . . , p âˆ’ 1\}$. $x$ is a generator of $\mathbb{F}^*_{p^m}$: I am coming to this part regarding $x$ later on. $\mathbb{F}^*_{p^m}$,  is the multiplicative group of $\mathbb{F}_{p^m}$ such that $ \{a \in \mathbb{F}_{p^m} | \gcd(a, p) = 1\}$. $\mathbb{F}_{p^m} = \mathbb{Z}_p[x]/(f(x))$, denotes the set of (equivalence classes of) polynomials in $\mathbb{Z}_p[x]$
of degree less than $n = \deg f (x)$. Addition and multiplication are performed modulo $f (x)$. Now, coming back to the point of $x$, I began to realize that I must have some 
serious flaw in my understanding above. So far, I have seen that generators have always been numbers. 
Here the generator is $x$, which is an indeterminate. Could you please point out the where I have gone off the track? Perhaps the best way to salvage me will be to simply rewrite my points 1-4. Adding an example will make things perfect.","['finite-fields', 'discrete-mathematics', 'polynomials']"
403101,3D line integral question,"Let $C$ be the curve of intersection of the cylinder $x^2 + y^2 = 1$ and the surface $z = xy$, oriented counterclockwise around the cylinder. Compute the integral $\int_C y\,dx + z\,dy + x\,dz$.","['multivariable-calculus', 'calculus', 'integration']"
403113,"If $(1,1)$ is an eigenvector of $A=\begin{pmatrix}2 &5\\3&k\end{pmatrix}$,then one of the eigenvalues of $A$ is :-","If $(1,1)$ is an eigenvector of $A=\begin{pmatrix}2 &5\\3&k\end{pmatrix}$,then one of the eigenvalues of $A$ is :- $0,-1,1,2$ Can I get some hints please.","['matrices', 'linear-algebra']"
403114,$\text{Inn}(G)$ cannot be nontrivial cyclic group,"Let $G$ be any group, and let $Z$ be its center. (a) Show that $G/Z\cong \text{Inn}(G)$ . (b) Conclude that $\text{Inn}(G)$ cannot be a nontrivial cyclic group. I've already gotten part (a) by considering the mapping $\pi:G\rightarrow\text{Inn}(G)$ such that $\pi(g)$ is the automorphism that takes $x$ to $g^{-1}xg$ for all $x\in G$ . The mapping $\pi$ is clearly a surjective homomorphism with kernel $Z$ , and part (a) follows from the isomorphism theorem. For part (b), I must prove that $G/Z$ cannot be a nontrivial cyclic group. If it were, the group would equal $\{Z,Zg,Zg^2,\ldots,Zg^{n-1}\}$ for some $g\in G$ . Also, $G/Z$ would be an abelian group, and it follows that the commutator subgroup $G'$ belongs to $Z$ . I don't see how to derive a contradiction from there.","['group-theory', 'abstract-algebra']"
403120,"Why is ""for all $x\in\varnothing$, $P(x)$"" true, but ""there exists $x\in\varnothing$ such that $P(x)$"" false? [duplicate]","This question already has answers here : Why is predicate ""all"" as in all(SET) true if the SET is empty? (6 answers) Closed 11 years ago . There exists an $X\in A$ such that $P(X)$. When $A$ is the empty set then this statement is false because there is nothing in $A$ that when plugged in for $X$, makes $P(X)$ come out True. However, when the quantifier is the universal one, meaning ""For all $X\in A$"" (which is the empty set), then the statement is true !! How is that ? .. Because by the reasoning in the first statement, there are not any values of $X$ that makes $P(X)$ come out True. I'm missing something !! (I'm studying Electrical Engineering and self studying velleman's how to prove it and the quantifiers are already kicking my butt so simplify the answers for me if possible :))","['logic', 'quantifiers', 'elementary-set-theory']"
403152,How do one solve a nonlinear combinatoric problem?,"I am an undergraduate CS student and I am struggling with a problem. $Qx = b$ where $Q$ is a constant $m \times n$ matrix (with $m>n$), $x$ is a $n \times 1$ vector and $b$ is a $m\times 1$ vector. I want to maximize the number of zeros in vector $b$. subject to: $x(i)>0$ for $i=1,2, \ldots,n$ How do one tackle a problem like this ?","['nonlinear-optimization', 'integer-programming', 'linear-algebra', 'combinatorics']"
403170,"elements of sets, subsets relations","give an example (if possible) such that: a)$x\in y$ and $x\not\subseteq y$ here I take $x=\{1,2\}$ and $y=\mathcal{P(x)}=\{\emptyset, \{1\},\{2\},\{1,2\}\}$ then $x\in y$ but $x\not\subseteq y$ as e.q $1\not\in y$ b)$x\subseteq y$ and $x\not\in y$ here I cannot find any counter example...By definition of subset any element in x must be in y...
is it true? c)$x\in y$ and $x\subseteq y$ Here I take $x=\emptyset$ and $y=\mathcal{P(x)}=\{\emptyset, \{\emptyset\}\}$ then $x\in y$ and $x\subseteq y$ could someone please check?",['elementary-set-theory']
403172,$G/Z$ cannot be isomorphic to quaternion group,"Let $Q_8$ be the quaternion group. Show that $G/Z$ can never be isomorphic to $Q_8$ , where $Z$ is the center of $G$ . Hint: if $G/Z\cong Q_8$ , show that $G$ has two abelian subgroups of index $2$ . I'm trying to prove the hint by looking at the canonical homomorphism $\pi:G\rightarrow G/Z$ . Well, $Q_8$ has some abelian subgroups of index $2$ , such as $H=\{1,-1,i,-i\}$ , but that doesn't seem to map to abelian subgroups of index $2$ of $G$ . (We know that $\pi(ab)=\pi(a)\pi(b)=\pi(b)\pi(a)=\pi(ba)$ for $a,b$ in $\pi^{-1}(H)$ , but that only yields $aba^{-1}b^{-1}\in Z$ , not $aba^{-1}b^{-1}=1$ .)","['group-theory', 'abstract-algebra']"
403179,Closure of operators,"Let $X$ and $Y$ Banach. We say that the linear operator $A:\mathcal{D}(A)\subseteq X\rightarrow Y$ admits a closure if there's a linear operator $B:\mathcal{D}(B)\subseteq X\rightarrow Y$ such that $\mathcal{D}(A)\subseteq \mathcal{D}(B)$, $B|_{\mathcal{D}(A)} = A$
and $\mathcal{G}(B)= \overline{\mathcal{G}(A)}$, where $\mathcal{G}(Z)$ is the graph of $Z$. I want to prove that $A$ admits a closure if and only if every sequence $\{x_n\}_{n\in\mathbb{N}}\subseteq \mathcal{D}(A)$ such that $(x_n,A(x_n))\xrightarrow{n\rightarrow\infty}(0,y)$, with $y\in Y$, satisfy that $y=0$. I proved ($\Rightarrow$), but I have had problems in ($\Leftarrow$), because I don't know how to define the operator $B$. Please, somebody can help me? Thanks in advance.","['operator-theory', 'functional-analysis']"
403184,Smallest prime of the form 41033333333...?,"What is the smallest prime of the form $410333333333...$ ?
 It should have more than $10,000$ digits. [added from answer posted 2013 May 26 at 20:52 by Peter] I thought it would be clear, but it seems not to be.
 Of course, after $410$ , only $3$ 's should follow.
 Otherwise, it would be very easy to find primes.
 I checked the numbers up to about $10,000$ digits,
 but of course, I would be glad if someone checks
 this, too. I do not understand the question, WHY this number
 is interesting for me. Mersenne primes are not so
 much more interesting, but recently a prize of $100,000\$ $ was payed for a community finding a $17$ -million-digit mersenne prime. I would have
 better ideas what to do with all this money ...","['prime-numbers', 'number-theory']"
403188,Is there a simpler closed form for $\sum_{n=1}^\infty\frac{(2n-1)!!\ (2n+1)!!}{4^n\ (n+2)\ (n+2)!^2}$,"I have the following infinite sum that can be expressed in terms of the generalized hypergeometric function :
$$\sum_{n=1}^\infty\frac{(2n-1)!!\ (2n+1)!!}{4^n\ (n+2)\ (n+2)!^2}=\frac{31}8-4\times{_4F_3}\left(-\frac12,\frac12,1,1;\ 2,2,2;\ 1\right)\\\ \\\approx0.008749644047541935203478962326551903908774780849356243615274...$$
I wonder if it can be expressed in terms of simpler functions and well-known mathematical constants.","['sequences-and-series', 'closed-form', 'calculus', 'hypergeometric-function']"
403189,integrating a vector over a sphere,"I have the following triple integral in spherical coordinates $(r,\theta,\phi)$: $$\int_0^{2\pi}\int_0^\pi\int_0^RCr^3\hat\theta\cdot r^2dr\sin{\theta}d\theta d\phi$$ How do I handle the $\hat\theta$? If I ignore it, I get $\frac{2}{3}\pi CR^6$. So is my answer the vector $\frac{2}{3}\pi CR^6\hat\theta$? Do I need to integrate the unit vector $\hat\theta$? If so, how?","['definite-integrals', 'multivariable-calculus', 'spherical-coordinates']"
403199,Is the following polynomial reducible over Q?,"I am looking at an exercise saying that ""Demonstrate that x 4 -22x 2 +1 is reducible over Q. I have the solution manual and it solves like the following: If x 4 -22x 2 +1 is reducible over Z, then it factors in Z[x], and must therefore
either have a linear factor in Z[x] or factor into two quadratics in Z[x]. The only possibilites for a
linear factor are x Â± 1, and clearly neither 1 nor -1 is a zero of the polynomial, so a linear factor is
impossible. Suppose
x 4 -22x 2 +1 = (x 2 + ax + b)(x 2 + cx + d).
Equating coefficients, we see that
x 3 coefficient : 0 = a + c
x 2 coefficient : âˆ’22 = ac + b + d
x coefficient : 0 = bc + ad
constant term : 1 = bd so either b = d = 1 or b = d = âˆ’1.
Suppose b = d = 1. Then âˆ’22 = ac + 1 + 1 so ac = âˆ’24. Because a + c = 0, we have a = âˆ’c, so
âˆ’c2 = âˆ’24 which is impossible for an integer c. Similarly, if b = d = âˆ’1, we deduce that âˆ’c2 = âˆ’20,
which is also impossible. Thus the polynomial is irreducible. My question is: 1)What does it mean ""over Q""? What is the difference between saying over Z and over Q? 2)Why do we factor it as (x 2 + ...)(x 2 + ...)? Can't it be like (x 3 + ...)(x + ...). Also, why don't we factor it like (ax 2 + ...)(bx 2 + ...), i mean how do we know that the head coefficients are 1?Can someone help with this? Thanks","['abstract-algebra', 'polynomials']"
403233,prove 3rd derivative of a function in a point,"Let $f$ be twice differentiable and $f'''$ exists in one point $x\in D$. I want to show for this one point $$f'''(x)=\lim_{h\rightarrow0}\frac{f(x+3h)-3f(x+2h)+3f(x+h)-f(x)}{h^3}$$ I did the following: I know $\lim_{h_1\rightarrow0}\frac{f(x+h_1)-f(x)}{h_1}=f'(x)$ and so follows by pluging in $$f''(x)=\lim_{h_2\rightarrow0}\frac{f'(x+h_2)-f'(x)}{h_2}=...=\lim_{h_1\rightarrow0}\frac{f(x+h_1)+f(x-h_1)-2f(x)}{h_1^2}$$ Doing this one more time I'll get ($f'''$ exists in $x$) $$f'''(x)=\lim_{h_3\rightarrow0}\frac{f''(x+h_3)-f''(x)}{h_3}=...=\lim_{h_1\rightarrow0}\frac{f(x+3h_1)-3f(x+2h_1)+3f(x+h_1)-f(x)}{h_1^3}$$ First question: Can you do it like that? And my second question: Why can we always choose 'the same $h$' for the limits? Formally for e.g. $f''$ it's $$\lim_{h_2\rightarrow0}\frac{\lim_{h_1\rightarrow0}\frac{f(x+h_1+h_2)-f(x+h_2)}{h_1}-\lim_{h_1\rightarrow0}\frac{f(x+h_1)-f(x)}{h_1}}{h_2}$$ and I have $h_1$ and $h_2$ in it. Edit Using L'Hospital twice on the right side I get
$$\dots=\lim_{h\rightarrow0}\frac{3f''(x+3h)-4f''(x+2h)+f''(x+h)}{2h}$$ And so we get $\begin{align}&\dots\\&=\lim_{h\rightarrow0}\left\{\frac16\frac{3f''(x+h)-3f''(x)}{h}-\frac13\frac{12f''(x+2h)-12f''(x)}{2h}+\frac12\frac{9f''(x+3h)-9f''(x)}{3h}\right\}\\&=\frac36\lim_{h\rightarrow0}\frac{f''(x+h)-f''(x)}{h}-\frac{12}3\lim_{h\rightarrow0}\frac{f''(x+2h)-f''(x)}{2h}+\frac92\lim_{h\rightarrow0}\frac{f''(x+3h)-f''(x)}{3h}\\&=f'''(x)\end{align}$","['calculus', 'real-analysis', 'analysis']"
403247,Sylvester's sequence: is there an exact closed form?,"I'm afraid this is one of those ""amateur mathematician with no journal access"" questions. Anyhow, Wikipedia ( here ) and OEIS give this closed form for the terms Sylvester's sequence: $S_n = \lfloor E^{2^{n+1}} + \frac12\rfloor$ (where $E \approx 1.264$). Is this the best we can do for a closed form, or is there an exact formula known? Is it known that there is no such formula?","['closed-form', 'sequences-and-series']"
403250,Logic problem that i am struggling with,"$1$-   The universal set for this problem is the set of students attending Miskatonic University. Let -$M$ denote the set of Math majors. -$CS$ denote the set of Computer Science majors. -$T$ denotes the set of students who had a test on Friday. -$P$ denotes those students who ate pizza last Thursday. Using only the set theoretical notation we have following assertions $1$. Computer Science majors had a test on Friday $$CS \subseteq T$$ $2$. No Math majors ate pizza last Thursday-----> $$M^c \subseteq P$$ or $$M \cap P=\varnothing$$ (The book said that the answer is $M \cap P=\varnothing$, idk why?) $3$. Some Math majors did not eat pizza last Thursday$$C^c \cap P=\varnothing?$$ I am struggling with translating context to symbols. $4$. Those Computer Science majors who did not have a test on Friday ate pizza on Thursday
$$CS^c \in T \subseteq P?$$
$5$. Math or Computer Science major who ate pizza on Thursday did not have a test on Friday
$$M \cup CS \subseteq P \land T = \varnothing?$$ I need help please. I am trying my best to learn the logic and operations on sets. I understand that $A \cup B$ reads ""$x \in A$ or $x \in B$""; $A \cap B$"" means $x \in A$ and $x \in B$"" but when it comes to question like this, I have no clue how to write. For instance, $(2)$, how is $M \cap P = \varnothing$? Why can't it be $M^C  \subseteq P$? How does ""and"" or"" ""E"" used to write symbols?","['discrete-mathematics', 'elementary-set-theory']"
403255,$|\phi(G):\phi(H)|$ divides $|G:H|$,"Let $\phi$ be a homomorphism defined on a finite group $G$, and let $H\subseteq G$. Show that $|\phi(G):\phi(H)|$ divides $|G:H|$. Not quite sure where to start on this one. We have a theorem saying that $\phi(H)$ is a subgroup of $\phi(G)$, but what is $|\phi(H)|$? If $H$ contains the kernel $N$ of $\phi$, then I think everything behaves nicely and $|\phi(G):\phi(H)|=|G:H|$. But if $N\not\subseteq H$, I don't know what I can conclude.","['group-theory', 'abstract-algebra']"
403259,Finding all Laurent expansions of $f=\frac{1}{z}$,"I have the following homework problem I need help with: Let $G=\{z\in\mathbb{C}:\, z\neq0\}$ and define $f:\, G\to G$ by
  $f(z)=\frac{1}{z}$. Find all possible Laurent expansions of $f$ which are not Taylor
  expansions and for each such expansion specify in what set the Laurent
  series converges. What I tried: For the point $z=z_{0}$ there are Laurent expansions in $$E_{1}:=0<|z|<R$$
and in $$E_{2}:=|z|>R$$ Where $R>0$ is real. I am unsure about in which set the Laurent series converges to $f$
, but it seems that in both cases the Laurent series of $f$ is simply
$\frac{1}{z}$ and it converges in all points of $E_{1}$or $E_{2}$
(according to the case). Am I correct ? For $z_{0}\ne0$ the Laurent expansions which is not Taylor is in
$$E_{1}:=0\leq|z|<R$$ where $R>|z_{0}|$ and $$E_{2}:=|z|>R$$ where
$R<|z_{0}|$. I am not sure about where I should of used $<$ or $\leq$ in the
description of $E_{1},E_{2}$. I am also having difficulty finding the Laurent series at $E_{i}$
and telling where it is convergent. Can someone please help me out with the case $z\neq z_0$ and tell me if I did correctly the first case ($z=z_0$) ?","['laurent-series', 'complex-analysis']"
403282,Physical interpretation of C* property,"From a mathematical point of view, quantum mechanics can be formulated in the language of a non-commutative, unital C*-algebra $\mathcal A$ (of observables). In this context, what does the C*-property $$\vert\vert A^*A \vert\vert = \vert\vert A \vert\vert^2 \qquad \forall A \in  \mathcal A$$ mean from a physical point of view, i.e. which physical oberservation is modeled by requiring this property?","['c-star-algebras', 'functional-analysis']"
403283,Do we really know the value of expressions with irrational powers?,"The way we evaluate decimal powers such as $a^.75$ is by splitting it into $(a^3)$^(1/4). How then can we evaluate irrational powers? I know that we can approximate, but whenever we graph a^x we assume continuity at the irrational numbers, but how can we be certain of this?","['exponentiation', 'exponential-function', 'algebra-precalculus']"
403284,Nielsen-Schreier and the Axiom of Choice,"The Nielse-Schreier (NS) Theorem says that every subgroup of a free group is free. The proof uses the Axiom of Choice, and LÃ¤uchli showed in 1962 that the negation of NS is consistent with ZFA (ZF with atoms). By a result of Jech-Sochor, this result can be transferred to ZF. So some form of Choice is needed to prove NS. In 1985, Paul Howard showed that the Axiom of Choice for sets of finite sets follows from NS. Is the NS theorem known to be equivalent to the Axiom of Choice or some weak form of Choice?","['logic', 'set-theory', 'group-theory', 'axiom-of-choice']"
403298,A problem from distribution theory.,"Let $f$, $g\in C(\Omega)$, and suppose that $f \neq g$ in $C(\Omega)$. How can we prove that $f \neq g$ as distributions? Here's the idea of my proof. $f$ and $g$ are continuous functions, so they will be locally integrable. Now, take any $\phi \neq 0 \in D(\Omega)$. Let us suppose that $\langle T_f,\phi\rangle =\langle T_g,\phi \rangle $ and $f\neq g$ $\langle T_f,\phi \rangle = \langle T_g,\phi \rangle$ $\implies \int_\Omega f(x) \phi(x) dx = \int_\Omega g(x) \phi(x) dx$ $\implies \int_\Omega \phi(x)[f(x)-g(x)] dx =0$ i.e., the area under above function is zero. We know that $\phi$ is non zero, we just need to prove that this integral will be zero only when $f(x)-g(x)=0$ and it will make contradiction to our supposition that $f$ and $g$ are not equal. [Please help me prove the last point]","['distribution-theory', 'functional-analysis']"
403301,Describing/sketching region of integration of triple integral,"I'm having great difficulty with the following problem: This question concerns the integral $\int_{0}^{2}\int_{0}^{\sqrt{4-y^2}}\int_{\sqrt{x^2+y^2}}^{\sqrt{8-x^2-y^2}}\!z\ \mathrm{d}z\ \mathrm{d}x\ \mathrm{d}y$. Sketch or describe in words the domain of integration. Rewrite the integral in both cylindrical and spherical coordinates. Which is easier to evaluate? Below is what I believe I have established so far... The projection of this integral's domain onto the $xy$-plane is the portion of the circle $x^2+y^2=4$ on $0\le x\le2,\ y\ge0$. The bounds on $z$ correspond to $z^2=x^2+y^2$ (cone) and $x^2+y^2+z^2=8$ (sphere). These bounds intersect at $x^2+y^2=4$. Below $z=2$ (where the bounds on $z$ intersect), I believe that the cone and cylinder, $x^2+y^2=4$, are completely inside the sphere. Would it hence be correct to say that the region of integration is the solid lying between the cone and the cylinder, on $x\ge0$, $y\ge0$ and $0\le z\le2$? I'm struggling to visualize this problem. When I attempt to move on, and evaluate the integral in cylindrical/spherical coordinates, my solutions differ by a factor of 2. That is, I evaluated this integral as, $\int_{0}^{\frac{\pi}{2}}\int_{0}^{2}\int_{0}^{\sqrt{8-r^2}}\!z\ r\ \mathrm{d}z\ \mathrm{d}r\ \mathrm{d}\theta=2\pi$ And, $\int_{0}^{\frac{\pi}{2}}\int_{0}^{\frac{\pi}{2}}\int_{0}^{2\sqrt{2}}\!\rho\ \cos\phi\ \rho^2 \sin \phi\ \mathrm{d}\rho\ \mathrm{d}\theta\ \mathrm{d}\phi=4\pi$ Can you please help me to identify where I am going wrong? Thank you very much.","['multivariable-calculus', 'integration']"
403311,Change of variables in a convolution..,"I'm in trouble with change of variables in a convolution: Definition: The convolution of two $2\pi$-periodic functions $f$ and $g$ is defined as $$(f*g)(x)=\frac{1}{2\pi}\int_{-\pi}^{\pi}
f(y)g(x-y)\ dy.$$ I wan't to show $f*(g*h)=(f*g)*h$. Well, $$[f*(g*h)](x)=\frac{1}{2\pi}\int_{-\pi}^{\pi}f(\tau)(g*h)(x-\tau)\ d\tau\\ =\frac{1}{2\pi}\int_{-\pi}^{\pi}f(\tau)\left(\frac{1}{2\pi}\int_{-\pi}^{\pi}g(\rho)h(x-\tau -\rho)\ d\rho\right)\ d\tau.$$ Now I wan't to make the change of variables $\sigma=\tau+\rho$ but I don't know how to proceed with $d\rho$ and with the extremals $-\pi$, $\pi$. Can anyone explain me that? How can I know what is fixed in $h(x-\tau-\rho)$ inside the integral?","['fourier-analysis', 'partial-differential-equations', 'analysis']"
403316,"curl of what yields $(0,s^{-1},0)$ in cylindrical coordinates?","In cylindrical coordinates $(s,\theta,z)$, what function $\mathbf{A}$ has the property $$\nabla\times \mathbf{A} = (0, \frac{1}{s} , 0) $$ I know generally that $$\nabla\times \mathbf{A} = \left(\frac{1}{s}\frac{\partial A_3}{\partial \theta}-\frac{\partial A_2}{\partial z}, \frac{\partial A_1}{\partial z}-\frac{\partial A_3}{\partial s} , \frac{1}{s} \left( \frac{\partial}{\partial z}(s\cdot A_2) - \frac{\partial A_1}{\partial \theta}\right)\right) $$ Is there some better way of solving for $\mathbf{A}$ other than a lot of ugly equations?","['multivariable-calculus', 'vector-analysis', 'partial-differential-equations']"
403318,Interesting Normality Condition (topology),"I just got through an inquiry-based course in introductory topology, and I enjoyed the experience a lot. If you're unfamiliar, this roughly means that we were given a text full of theorems and the class consisted of providing as many proofs as possible, with student presentations in lieu of lectures. There was one theorem which I got a lot of use out of, but was never able to prove. It wasn't assigned, and I talked to the professor about it a couple times, but he didn't have any advice for me that I hadn't figured out myself. The text calls it the ""Normality Lemma"" if that helps, but it doesn't appear to be a standard term. Let $A$ and $B$ be subsets of a topological space $X$ and let $\{U_i\}_{i\in\mathbb N}$ and $\{V_i\}_{i\in\mathbb N}$ be two collections of open sets such that: $A\subseteq \bigcup_{i\in\mathbb{N}} U_i$ and $B\subseteq \bigcup_{i\in\mathbb{N}} V_i$ $\overline{U_i}\cap B$ and $\overline{V_i}\cap A$ are empty for all $i\in\mathbb N$. Then there are disjoint open sets $U$ and $V$ such that $A\subseteq U$ and $B\subseteq V$. The thing that really puzzles me about this is the countability condition. Is this doing anything more than saying the collections need to be infinite? Another interesting quirk about this theorem is that it doesn't show that $X$ is normal explicitly. Rather it guarantees disjoint open sets around a specific pair of (sufficiently ''cushioned'') arbitrary sets for any space. Can anyone help me through a proof of this?",['general-topology']
403321,which vectors are perpendicular to each other? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question which vectors are perpendicular to each other? $\vec a = (1, -2, 3)$, $\vec b = (5, 4, 1)$, $\vec c = (1, 0, -5)$ Do i just take the dot product of 2 of them. If the dot product they are at $90^\circ$? But how do i know if there perpendicular?","['vector-spaces', 'linear-algebra']"
403331,avalanche invariants in an Abelian sandpile,"In the Abelian sandpile model, is the following statement true: the number of times the trigger site topples in an avalanche is invariant, that is it does not depend on the order of the toppling. The trigger site is the first critical site in an avalanche; toppling it creates the avalanche. Assume the sandpile is given on a regular grid (square grid in 2d, cubic grid in 3d, etc) and that all sites on the sides are the sink sites, which is the usual setup in simulations. I ran some numerical experiments with the 2d and 3d sandpiles and observed that the number of topplings of the trigger site was the same for two particular orderings of toppling, namely, parallel ordering and wave ordering. Please provide the proof if possible, although a reference will be sufficient. If the statement is false, a counter-example would be useful.","['graph-theory', 'discrete-mathematics', 'abelian-groups']"
403332,Random variable with density proportional to a function and finite in some points,"Let $X$ be a random variable on $[-1,3]$ with density $f(x) = k x^2$ (with $k \in \mathbb{R} $ to be determined) on $[-1,3]$ apart from some points s.t. $p(X=-1) = p(X=3) = \dfrac{1}{4} $ and $p(X=0) = \dfrac{1}{3}$. What is the cumulative distribution function of $X$? How much is $p(-1 \leq X < 3) $? To find $k$ I would just calculate $$ k = \dfrac{1}{\int_{-1}^3 x^2 \ dx} $$ and then the cumulative distribution should be $$F(x) = \int_{-1}^x f(t) \ dt $$
while
$$p(-1 \leq X < 3) = 1 - p(X = 3) = \dfrac{3}{4}$$
Any suggestion would be appreciated.","['statistics', 'probability-distributions', 'probability']"
403338,"Continuity of a function defined differently on $\mathbb Q,\mathbb R\setminus \mathbb Q$","Let's say I define the function $f(x)=2^x$ for rational $x$, and $f(x)=1$ for irrational $x$. My question is: is this function continuous everywhere? I think it's not, because for any $2$ irrational numbers you can find a rational in between, and for any $2$ rationals you can find an irrational in between. My second question is: is the function continuous and differentiable at $x=0$? I think it is, and I think that $f'(0)=0$ because of the picture . Am I correct? (By the way please keep the answers at a pretty low level, I'm a calculus AB student.) Thanks!","['calculus', 'real-analysis', 'analysis']"
403345,Differentiating $ y= xe^{1\over x} $,"Can someone please help me? I'm trying, but I really can't find the second derivative of $y= xe^{1/x}$. Thanks!","['calculus', 'derivatives']"
403346,"Prove if $n^2$ is even, then $n$ is even.","I am just learning maths, and would like someone to verify my proof. Suppose $n$ is an integer, and that $n^2$ is even.  If we add $n$ to $n^2$, we have $n^2 + n = n(n+1)$, and it follows that $n(n+1)$ is even.  Since $n^2$ is even, $n$ is even. Is this valid?","['algebra-precalculus', 'solution-verification']"
403352,Transversality condition equation,"I'm somewhat baffled:
 I have a problem in  calculus of variations: $$
\int_0^T \!(x-\dot x^2)dt,\qquad x(0)=0,\qquad x(T)=T^2-2.
$$ Let $
F(t,x, \dot x) =x-\dot x^2.
$ I calculate all the necessary derivatives:
$$F_x=1 \qquad F_{\dot x} = -2\dot x \qquad \frac{d}{dt}F_{\dot x} = -2\ddot x$$ and write down an Euler-Lagrange equation:
$1+2\ddot x=0$ And calculate my quotients:
$$x=c_1t+c_2-\frac{t^2}{4} \qquad x(0)=0 \Longrightarrow  c_2=0$$ And then I get stuck:
I know that if I have
$$
J = \int_{t_1}^{t_2} F(t,x,\dot x) dt
$$and the right end follows a curve $x=\varphi(t)$, the transversality condition should hold:
$$
F(t_2,x_2, \dot x_2) + [\dot \varphi(t_2)-\dot x_2]F_{\dot x}(t_2,x_2, \dot x_2) =0
$$
where $x_2=x(t_2)$. But I can't wrap my mind about it: what is $\varphi$ in my case, and how would the transversality equation look like? 
Please help with any hints.","['calculus', 'calculus-of-variations']"
403367,Square root of $8^3$,I'm only in intermediate algebra. I know that $\sqrt{8^3}$ is equal to $16\sqrt{2}$ but could you simply explain the process on how to get to that?,['algebra-precalculus']
403388,What's the probability of a set of only three digits appearing in a random 9 digit set?,"I'd like to know the method for correctly calculating the probability of a random sequence of $9$ numbers only containing $3$ unique, different numbers. For the purpose of this question: there are 10 numbers $0,1,2,3,4,5,6,7,8,9$ i.e. the probability of this: $123123123$ - for all unique combinations of $3$ digits (e.g $071$ in $071717717$) My initial instinct is $(1/3)^9$ - is this correct?",['probability']
403401,Is There A Function Of Constant Area?,"If I take a point $(x,y)$ and multiply the coordinates $x\times y$ to find the area $(A)$ defined by the rectangle formed with the axes, then is there a function $f(x)$ so that $xy = A$, regardless of what value of $x$ is chosen?","['geometry', 'functions']"
403432,How to find $A$ such that $A^2$ is the zero matrix?,"Let $\space t:\mathbb{R^3} \to \mathbb{R^3}$ such that $\space t(v)=0 \space \forall \space v \in \mathbb{R^3}$. The matrix form would be a $3$ by $3$, zero matrix. If $\space t=f \circ f$, where $f:\mathbb{R^3} \to \mathbb{R^3}$ and $f\neq t$, what is the matrix form of $f$? I know that $\space t=f \circ f= f\cdot f$ and if one let $A$ to be the matrix of $f$ and $\space T$ the matrix of $t$, then $T=A^2$. And so $A^2$ would be a zero matrix. Is there a systematic way to solve this problem? Thanks for the hints.","['matrices', 'linear-algebra']"
403434,Differentiate $g(t)= {e^t - e^{-t} \over e^t + e^{-t}}$,I'm having some trouble trying to differentiate the function $g(t)= \dfrac{e^t - e^{-t}}{e^t + e^{-t}}$ Can someone help me? Thanks a lot!,"['calculus', 'derivatives']"
403449,Convergence of Riemann maps,"For $\epsilon > 0$, let $K_\epsilon = \{e^{i\theta} : \theta \in [0,\pi-\epsilon]\}$ be an almost-semicircle. Let $D_\epsilon = H \setminus K_\epsilon$, where $H$ is the upper half plane. Let $\phi_\epsilon : D_\epsilon \rightarrow H$ be the Riemann map normalized so that $\lim_{z\rightarrow\infty} \phi_\epsilon(z) -z = 0$. Let $\psi_\epsilon = \phi_\epsilon/\phi_\epsilon'(0)$ on the intersection of $A$ of the unit disk with the upper half plane. I am trying to show that $\psi_\epsilon$ converges uniformly on compact subsets of $A$ to a conformal map from $A$ to $H$ as $\epsilon \rightarrow 0$. Intuitively, as $\epsilon \rightarrow 0$, $D_\epsilon$ approaches a domain with two connected components, and an appropriately normalize map should approach a biholomorphism on each. But, I do not have much of an idea as to how to turn this intuition into a proof. Does anyone have any suggestions? Even better, are there any general results about the limits of Riemann maps on domains which are ""almost disconnected"" which can be applied here?",['complex-analysis']
403454,Is there a simpler approach to these system of equations?,"I recently came across the following system of equations: $$x + y + z = 1 \\
x^2 + y^2 + z^2 = 2  \\
x^3 + y ^3 + z^3 = 3$$ And I have two questions: One, is there a way to prove or disprove whether there is a solution for this particular set of equations? Furthermore, is there a way to expand the proof for a more generalized set of equations, that is for this set : $$x + y + z = 1 \\ x^2 + y^2 + z^2 = 2 \\ ...\\x^n + y^n + z^n = n$$ Two, is there a simpler approach for the prior solution set than substitution? As of now, I'm not getting anywhere with this method. I end up getting into a long-winded series of substitution and isolation that yields something like $z = z$ or $1 = 1$. Sorry if it's a repeat question; I couldn't exactly find an accurate way to search for the equations.","['symmetric-polynomials', 'algebra-precalculus', 'systems-of-equations']"
403483,Other log solutions?,"I am evaluating the expression: $\ln(1)$ And I know the trivial solution is $0$. Are there other solutions to this equation? I feel there should be, my logic is as follows: if: $\ln(1) = x \implies 1 = e^x \implies 1 = 1 + x + x^2/2! + x^3/3!... $
$\qquad\qquad\qquad\qquad\qquad\implies 0 = x + x^2/2! + x^3/3!...$ $\implies x = 0$ is one solution, the other solution is all $x$ such that: $$1 + x/2! + x^2/3! + x^3/4! ... = 0$$ There have to be other solutions, or limiting solutions... What are they?","['logarithms', 'algebra-precalculus', 'taylor-expansion']"
403497,Relationship of the support of a test function with the support of distribution.,"Let $\phi\in D(\Omega)$ and $f\in D'(\Omega)$. If $\phi$ is $0$ in a neighbourhood of $\operatorname{supp}(f)$, then how will we prove that $\langle f, \phi
\rangle$ is also $0$? Will it be sufficient if $\phi$ vanishes on $\operatorname{supp}(f)$? Definition of $\operatorname{supp}(f)$: Let $f$ be a distribution, and $U$ an open set in $\Bbb R^n$ such that, for all test functions $\phi$ with the support of $\phi$ contained in $U$, $f(\phi) = 0$. Then $f$ is said to vanish on $U$. Hence we can define the support of $f$ as the complement of the largest open set on which $f$ vanishes. Alternatively, we can say $\operatorname{supp}(f)$ is the subset of $\Bbb R^n$ such that $x \in \operatorname{supp}(f)$, if and only if for all neighbourhoods $\mathcal U$ of $x$, there is $\phi \in D(\mathcal U)$ such that $\langle f, \phi\rangle \neq 0$.","['distribution-theory', 'functional-analysis']"
403504,A question related to Riemann zeta function,"Does anyone know why the following statement is correct? Let $f(x)$ be the function whose value on the interval $m\pi<x<(m+1)\pi, m=0,1,2,\cdots$, is $(-1)^m\frac{\pi}{4}$.  Let $0<s<1$. Then $$\int_0^\infty x^{s-1}f(x)\,dx$$ represents an analytic function for $\Re s<1$ and is equal to $$2(1-2^{s+1})\zeta(1-s)$$ for $\Re s<0$.
Here $\zeta(\cdot)$ is the Riemann zeta function. Edit. I think now I partially understand the first part. Let $\alpha(x)$ be the function defined by $$\int_0^x u(t)\,dt$$ where $u(t)=(-1)^m$ on $[m\pi,(m+1)\pi], m=0,1,2,\cdots.$ Then the integral $\int_0^\infty x^{s-1}f(x)\,dx$ is equal to the Riemann-Stieltjes integral $\frac{\pi}{4}\int_0^\infty x^{s-1}\,d\alpha$. For $0<s<1$, this can be written as $$\frac{\pi}{4}\left(\int_0^\pi x^{s-1}\,dx-\pi^s-(s-1)\int_{\pi}^\infty\frac{\alpha(x)}{x^{2-s}}\,dx\right),$$ which is analytic in $s$ for $0<\Re s<1$. Now I need to know how to do it for $\Re s\le 0$ and how to make it equal to $2(1-2^{s+1})\zeta(1-s)$ for $\Re s<0$.","['special-functions', 'riemann-zeta', 'complex-analysis']"
403505,"Given $x,y\in\mathbb{C}^n$ s.t. $f(x,y)=\sup_{\theta,\phi}\{\|e^{i\theta}x-e^{i\phi}y\|^2,\theta,\phi\in\mathbb{R}\}$ [duplicate]","This question already has an answer here : Consider $f(x,y)=\sup_{Î¸,Ï†}\{||e^{i Î¸ }x+ e^{i Ï† }y||^2: Î¸,Ï†âˆˆR\}$ in which $x,y\in\mathbb C^n$ (1 answer) Closed 6 years ago . Given$$x,y\in\mathbb{C}^n,\quad f(x,y)=\sup_{\theta,\phi}\{\|e^{i\theta}x-e^{i\phi}y\|^2,\theta,\phi\in\mathbb{R}\}$$ Then which is/are the following are true? $1.\ f(x,y)\le \|x\|^2+\|y\|^2-2Re|\langle x,y\rangle|$ $2.\ f(x,y)\le \|x\|^2+\|y\|^2+2Re|\langle x,y\rangle|$ $3.\ f(x,y)= \|x\|^2+\|y\|^2+2Re\langle x,y\rangle$ $4.\ f(x,y)\ge \|x\|^2+\|y\|^2-2Re\langle x,y\rangle$ I have no idea how to start with or how to solve, could any one help me?",['complex-analysis']
403509,"Adjoint operator, bijective","Let $A\in\mathcal{L}(X,Y)$, where $X,Y$ are normed vector spaces. Define the adjoint operator
$$\begin{array}{ll}
A^{\prime}\ : & Y^{\prime}\rightarrow X^{\prime},\\
 & G \mapsto A^{\prime}(G)\ =\ G\circ A.
\end{array}$$
Its easy to show that $A^{\prime}\in\mathcal{L}(Y^{\prime}, X^{\prime})$ and $\|A\| = \|A^{\prime}\|$. Now, suppose that $A$ is bijective, then show that $A^{\prime}$ is also bijective. First at all, I have proven that $[\mbox{Im}(A)]^{\circ} = \mbox{Ker}(A^{\prime})$, and then $\mbox{Ker}(A^{\prime}) = \{O\}$. Therefore $A^{\prime}$ is injective. My problem is that I don't know how I can show that $A^{\prime}$ is onto. Please I need help. Thanks in advance.","['operator-theory', 'functional-analysis']"
403519,Primality of the numbers in the form of $2n^2-1$,"I have a question about primality of integers in the form of $2n^2-1$. I can prove that for the certain type of n such integers are always composite. For example, if $n=7k+2$ or $n=7k+5$, the whole expression would be always divisible by $7$. The same is applicable to the whole (probably infinite) set of numbers in the form of $n=ak+b$, where $a$ is $7$, $17$, $23$ etc. and $b$ usually has two values (like $2$ and $5$ for $a=7$).
($a$ is prime here and $b \le a-1$) I also suspect that the only composite values of $2n^2-1$ are those whose factors are from that set of a (like $7$, $17$, $23$ etc.). I am trying to see if there anything else can be said about primality or compositness of those numbers $n$. Is there any other forms of n that can guarantee compositness (or primality)? I would appreciate any ideas. Thanks!","['prime-numbers', 'divisibility', 'number-theory']"
403545,Injectivity of $A-\lambda I$,I'm reading a paper on determinants and on one point the author states that: A complex number $\lambda$ is called an eigenvalue of matrix $A$ if $A-\lambda I$ is not injective. Why is this? Could someone clarify :) Thank you! =),"['matrices', 'linear-algebra', 'eigenvalues-eigenvectors', 'determinant']"
403547,"$C^{1}[a,b]$ equipped with the norm given by $\lVert x\rVert _{\infty} = \sup_{t\in [0, 1]} \lvert x(t) \rvert$ is an incomplete normed space.","I have to show that the real linear space $C^{1}[a,b]$ of all continuously differential functions defined on $[0, 1]$ equipped with the norm given by $\lVert x\rVert _{\infty} = \sup_{t\in [0, 1]} \lvert x(t) \rvert$ is an incomplete normed space. I have taken sequence $\{x_{n}\} = \sqrt{t^2 +\frac{1}{n}}$ in $C^{1}[a,b]$. Please tell me whether my procedure to show that $\{x_{n}\}$ is Cauchy in $C^{1}[a,b]$ is correct or not. Here is my attempt. Let $n \geq m$ $\lVert x_n - x_m\rVert  = \lVert \sqrt{t^2 +\frac{1}{n}} - \sqrt{t^2 +\frac{1}{m}}\rVert 
 = \frac { \frac{1}{n} - \frac{1}{m}}{\sqrt{t^2 +\frac{1}{n}} + \sqrt{t^2 +\frac{1}{m}}}\leq \frac{1}{n} +  \frac{1}{m} \leq \frac{1}{2m}\leq \frac{1}{m} \leq \epsilon $ Further I have shown that $\{x_{n}\}$ converges pointwise to $x(t) =  \frac{1}{\sqrt n}$. But $x(t)$ is not differentiable at $t = 0$ and hence the proof. Also could anybody provide me any other example? Thanks.","['functional-analysis', 'banach-spaces']"
403565,When a quotient of a UFD is also a UFD?,Let $R$ be a UFD and let $a\in R$ be nonzero element. Under what conditions will $R/aR$ be a UFD? A more specific question: Suppose $R$ is a regular local ring and let $I$ be a height two ideal which is radical. Can we find an element $a\in I$ such that $R/aR$ is a UFD?,"['commutative-algebra', 'algebraic-geometry', 'unique-factorization-domains']"
403585,A Calculus Question on onto functions with a specified range.,"The following question was from a mock test of a competitive exam. Suppose $f:\mathbb{R} \to [-8,8]$ is an onto function and $f(x) = \dfrac{bx}{(a-3)x^3 + x^2 + 4}$ where $a,b \in \mathbb{R}^+$. If the set of all values of $m$ for which the equation $f(x) = mx$ has three distinct real solutions in the open interval $(p,q)$, then find the value of $a+b+p+q$. I tried the problem and obtained an answer. According to me, it is $43$. I will post the answer later. My solution was quite involved and long. I want to know if there is a quick solution to this problem. Thank you.","['calculus', 'algebra-precalculus', 'polynomials']"
403590,Statistics and confidence - intervals,"An account on server A is more expensive than an account on server B. However, server A is faster. To see whether it's optimal to go with the faster but more expensive server, a manager needs to know how much faster it is . A certain computer algorithm is executed 20 times on server A and 30 times on server B with the following results, Server A  Server B 
Sample means      6.7 min   7.5 min  
Sample std. dev.  0.6 min   1.2 min A 95% confidence interval for the difference $\mu_{1} - \mu_{2}$ between the mean execution times on server A and server B is [-1.4,-0.2] . Is there a significant  difference between the two servers? (a) Use the confidence interval above to conduct a two-sided test at the 1% level of significance. (b) Compute a p-value of the two-sided test in (a). (c) Is server A really faster? How strong is the evidence? Formulate the suitable hypothesis and alternative and compute the corresponding p-value.","['statistics', 'probability']"
403611,Every preorder is a topological space,"Let $(X,\leq)$ be a preorder, i.e. $\leq$ is a reflexive and transitive binary relation on $X$. I want to show that $\leq$ induces a topological structure on $X$. Hence I need to specify when a subset $A$ of $X$ must be considered open. My personal guess is that $A$ is open iff it is contained in its interior, where the interior $A^Â°$ of $A$ is defined as follows: $$A^Â°:=\{s\in X: \forall f\in X (s\leq f\rightarrow f\in A\}$$ Do you think this makes sense? If not, which could be the right definition of an open? A ""dual"" definition for the interior of $A$ could be $$A^Â°:=\{s\in X: \forall p\in X (p\leq s\rightarrow p\in A\}$$ Do the two definitions work in order to get a topological space? Do they define the same topology on $X$ (if they define any?) In the same spirit, we could define a topology by mean of closed subsets. I say that a subset $C$ of $X$ is closed when the closure of $C$ is contained in $C$, and i define the closure of $\overline{C}$ of $C$ as follows:
$$\overline{C}:=\{s\in X:\exists f\in X(s\leq f\wedge f\in C\}$$
or, dually, as
$$\overline{C}:=\{s\in X: \exists p\in X(p\leq s\wedge p\in C\}$$
The question is the same: do this define a topology on $X$? If so, what kind of topology is this? Has it some evident description, is it the obviuous one, or natural in some sense?","['general-topology', 'order-theory']"
403614,Eigenvalues of outer product matrix of two N-dimensional vectors,"I have a vector $\textbf{a}=(a_1, a_2, ....)$, and the outer product $M_{ij}=a_i a_j$. What are the eigenvalues of this matrix? and what can you say about the co-ordinate system in which $M$ is diagonal? I have proved that the only eigenvalue of the matrix is the norm of the vector squared, and that one of the eigenvectors is $\textbf{a}$ itself. $$Mu=a a^{T}u=\lambda u\\\ \implies a^{T}(aa^{T})u=a^{T}\lambda u \implies a^{T}a (a^{T}u)=\lambda a^{T}u \implies ||a||^2=\lambda$$ Also it is obvious that $a$ is the eigenvector of $aa^{T}$, which implies $M= \begin{pmatrix} ||a||^2 &0 &0 &..... \\0 & ||a||^2\\.\\.\\\\. \end{pmatrix}$ Is this correct? What are all the eigenvectors of this the outer product? and what intuitively happens in the transformed basis when M is diagonal?","['tensor-products', 'linear-algebra', 'diagonalization']"
403629,Why is $ \|T(x) \|\le \| T\| \|x \|$?,"Let $X$ and $Y$ be normed linear spaces and let $T$ be a bounded linear operator from $X$ to $Y$. The norm of $T$ is defined as
$$\|T \|=\sup\{\|T(x) \|\;:\;\|x \|\le 1\}. $$ From the definition of the norm, we can say that $\|T(x) \|\le \|T \|\;\forall \;x,$ and that $\|T \|\|x \|\le \|T \|$ as $\|x\|\le 1$. However I don't understand why we write $\|T(x)\|\le \|T\|\|x\|$?",['functional-analysis']
403635,Injectivity of a map between manifolds,"I'm learning the concepts of immersions at the moment. However I'm a bit confused when they define an immersion as a function $f: X\rightarrow Y$ where $X$ and $Y$ are manifolds with dim$X <$ dim$Y$ such that $df_x: T_x(X)\rightarrow T_y(Y)$ is injective. I was wondering why don't we let $f$ be injective and say that's the best case we can get for the condition dim$X <$ dim$Y$(since under this condition we can't apply the inverse function theorem)? Also does injectivity of $df_x$ inply the injectivity of $f$ (it seems that I can't prove it)? How should we picture immersion as (something like the tangent space of $X$ always ""immerses"" into the tangent space of $Y$)? Thanks for everyone's help!","['differential-topology', 'manifolds', 'differential-geometry']"
403640,lagrange multipliers fails,"I am looking for a certain counter example. Assume a $C^1$ function $f$ is to be optimized with respect to a $C^1$ constraint $g=0$, and we have at a point $(x,y)$, the existence of a lagrange multiplier $\lambda$ with
$$
\begin{align}
&\nabla f(x,y)=\lambda\nabla g(x,y)\\
&\nabla g(x,y)\neq0\\
\end{align}
$$
But $f$ fails to have an extremum at this point with respect to $g=0$ thanks","['optimization', 'lagrange-multiplier', 'real-analysis', 'analysis']"
403648,The characteristic polynomial of a recurrence relation.,"If I have a linear homogeneous recurrence relation $$y_n=c_1y_{n-1}+\ldots+c_ky_{n-k},$$ I can get its characteristic equation, which is $$r^k=c_1r^{k-1}+\ldots+c_k.$$ In particular for $y_n=cy_{n-1},$ I get $r=c.$ While I see that this obviously gives the right solution, something seems not right. For a differential equation $y'=cy,$ I get a similar characteristic equation: $r=c$, however, as I understand it, the the analogy between differential equations and recurrence relations is given by $y'\sim y_n-y_{n-1},$ not $y'\sim y_n.$ By this logic, I think the characteristic equation for the recurrence relation $y_n=cy_{n-1}$ should be $r=c-1,$ because the recurrence relation is equivalent to $y_n-y_{n-1}=(c-1)y_{n-1}.$ Could you help me understand why the analogy breaks down here (or why it doesn't)?","['ordinary-differential-equations', 'recurrence-relations']"
403651,Derivative of order 16 - is there a method to do so?,"I have the following exercise: Find the $16^{\text{th}}$ derivative of $y$, (i.e. $y^{(16)}$), for $y = \sin x$. Is there any method to do so, or I simply have to differentiate the function $16$ times?","['calculus', 'derivatives']"
403654,First Course in Linear Algebra book suggestions? [duplicate],This question already has answers here : Where to start learning Linear Algebra? [closed] (16 answers) Closed 11 years ago . I'm starting maths degree this September and hoping to do some reading on Linear Algebra before I start. What are some good introductory books? Is there something that starts from the very beginning but also covers stuff in depth? (Is there a book that will be useful for both 1st year and 2nd year linear algebra modules?) It would also be great if the book has lots of exercises (proof questions!) and solutions given as well. Thanks in advance.,"['linear-algebra', 'reference-request']"
403655,Divergence theorem in volume integral,"We have a partial differential equation
 \begin{equation}
\nabla \cdot (p_1^2\nabla\alpha)=0\,.
\end{equation} Question: from this equation how can I write the following condition? \begin{equation}
\int_\Omega\alpha\nabla \cdot(p_1^2\nabla\alpha)=
\int_{\partial\Omega}\alpha p_1^2 n\cdot\nabla\alpha
-\int_\Omega p_1^2(\nabla\alpha)^2=0 \,.
\end{equation}
$p_1$ and $\alpha$ are position dependent variable.","['multivariable-calculus', 'vector-analysis', 'partial-differential-equations']"
403678,Why does the (topology given by) Hausdorff metric depend only on the topology?,"If I have a compact metric space $(X,d)$, I can define the Hausdorff metric on the set $K(X)$ of all non-empty compact (equivalently, closed) subsets of $X$ as $$d_H(A,B) = \max ( \sup_{x \in A} \inf_{y \in B} d(x,y),  \sup_{y \in A} \inf_{x \in B} d(x,y))$$ Now, I'm told, ""the topology on $K(X)$ depends only on the topology of $X$, as any two metrics on $X$ are equivalent"". Should I interpret the any two metrics are equivalent as ""they generate the same topology""? Then, the implication of the Hausdorff metrics being equivalent is not clear at all. On the other hand, if I interpret two metrics being equivalent as $c d_1<d_2 < Cd_1$, then the Hausdorff metrics producing the same topology seems clear, but the fact that any two metrics on $X$ are equivalent is suspicious. Does the compactness of $X$ force this? Even if I know one of the interpretation to be correct, I can then try and prove the statement. In fact, I would prefer that, over a complete proof of the statement. As an aside, is there a standard notation for my $K(X)$? The book I'm reading uses $2^X$, although I suspect due to typographical limitations.","['general-topology', 'metric-spaces', 'compactness']"
403686,Prove that a polynomial of degree $d$ has at most $d$ roots (without induction),"Let $p(x)$ be a non-zero polynomial in $F[x]$, $F$ a field, of degree $d$. Then $p(x)$ has at most $d$ distinct roots in $F$. Is it possible to prove this without using induction on degree? If so, how can I do this?","['field-theory', 'abstract-algebra', 'polynomials']"
403706,Extending a function beyond the completion/closure of its domain,"In  analysis there are certain theorems that tell under which conditions you can continuously extend a continuous functions to the closure/completion of its domain (which actually give the same set, since when talking about completions we have to be (at least) in a metric space). The theorems I have in mind are these three: Every uniformly continuous mapping between a metric space and a complete metric can be extended uniformly continuous to a mapping between the completion of the domain and the range. Every continuous function on a dense subset can be continuously extend to the closure of that subspace (which is by definition of ""dense"", the whole space). The theorem from here . What I'm looking for is a collection of theorems that tell me under which circumstances one can extend a  continuous function beyond the completion or the closure of it's domain. The only theorem of this kind that I know of is the famous Tietze-Urysohn extension theorem (which applies to function whose domain is already a closed set). I'd be also happy with a reference, as long as the theorems listed there are quickly accessible (i.e. don't require reading through a thicket of abstract/very specialized definitions before getting to the theorems - the more ""concrete"" the theorems are (as in $\mathbb{R}^n$, or a metric space), the better.","['general-topology', 'metric-spaces', 'reference-request', 'analysis']"
403715,Tails of Fourier Transformed family of functions,"I am reading a thesis where on page 39, Definition 4, $\epsilon$-oscillatory is defined as a property for a family of functions $\{f_{\epsilon}\}_{0<\epsilon<1}$ in $L^2(\mathbb{R}^d)$ to have if $$\lim_{R\to\infty}\limsup_{\epsilon\to 0}\int_{\{\left|\xi\right|>R\}}\frac{1}{\epsilon^d}\left|\widehat{f_{\epsilon}}\left(\frac{\xi}{\epsilon}\right)\right|^2d\xi=0.$$ It is mentioned soon after that for this property to hold it suffices that the weak derivative $\{\epsilon\nabla f_{\epsilon}\}$ is bounded in $L^2$. I cannot connect the two. The most I could do was the following $$\sup_{\epsilon}||\epsilon\nabla f_{\epsilon}||_{L^2}<C \implies \sup_{\epsilon}||\epsilon\widehat{\nabla f_{\epsilon}}||_{L^2}<C\implies\sup_{\epsilon}||\epsilon\xi \widehat{f_{\epsilon}}||_{L^2}<C$$ $$\implies \sup_{\epsilon}\int_{\mathbb{R}^d}\frac{1}{\epsilon^d}\left|p\widehat{f_{\epsilon}}\left(\frac{p}{\epsilon}\right)\right|^2dp<C$$ after a change of variables $\epsilon\xi=p$. Could someone please help me in figuring out the rest?","['measure-theory', 'fourier-analysis', 'functional-analysis', 'analysis']"
403774,Are there non-continuable functions that become continuable when raised to some power?,"Let $X$ be a complex algebraic variety (integral, separated scheme of finite type over $\mathbb C$) and $U\hookrightarrow X$ an open subvariety. I will say that $f\in\mathscr O_X(U)$ is continuable if there exists some $g\in \mathscr O_X(X)$ with $g|_U=f$. My question is simply: Can it happen that $f$ is not continuable, but there exists a $k\in\mathbb N^+$ with $f^k$ continuable? I was debating with a friend who thinks it is possible but could not give an example, while I thought that it is impossible but wasn't able to give a satisfying proof. So, I'd be really glad if you could provide one of the two (that is, a simple example of such a phenomenon or a proof that it can not happen).",['algebraic-geometry']
403781,Exponential map and connection,"Suppose you have a Riemannian manifold $(M,g)$ and a point $p\in M$ fixed. Let $v: s\mapsto v(s)$ be a curve in $T_pM$. Now consider the map $f(s):=\exp_p(v(s))$. Can one get an explicit formula for $f'(s)$? Maybe that is confusing but I thought of something like
$f'(s)=d(\exp_p)_{v(s)}(\nabla_sv(s))$, where $\nabla_s$ denotes the covariant derivative. Formally, $d(\exp_p)_{v(s)}$ is a map from $T_{v(s)}T_pM$ to $T_{\exp_p(v(s))}M$ and one can identify $T_{v(s)}T_pM\cong T_pM$. I would like to know if the formula above is true and how this identification is related to the Levi-Civita-connection on $M$. Thanks for any explanation.","['riemannian-geometry', 'differential-geometry']"
403811,Is the adjoint operation WOT-WOT continuous?,"This is a well-known property of the Hilbert-space adjoint operator that it is WOT continuous. Is a similar true for Banach spaces? That is, for a given Banach space $X$ is the operation $\varphi\colon B(X)\to B(X^*)$, $\varphi(T)=T^*$ continuous with respect to WOT-topologies of $B(X)$ and $B(X^*)$? I guess it will be the case for $X$ reflexive.","['operator-theory', 'functional-analysis', 'banach-spaces']"
403815,Golden ratio rectangles,I'm designing a layout and I would like to use four golden ratio rectangles. The total width of the layout is 960px. How do I find the height (x)? Below is a diagram of the layout.,"['golden-ratio', 'applications', 'algebra-precalculus']"
403818,Evaluating $\sum_{k=1}^{\infty} \frac{\cos^2(k)}{4k^2-1}$,What options do I have for this series? No idea how to do it. $$\sum_{k=1}^{\infty} \frac{\cos^2(k)}{4k^2-1}$$,['sequences-and-series']
403819,Problem solving approaches in graph theory,"From my experience with problems in graph theory, these pose certain obstacles that to me seem to particular for discrete mathematics, among them are 1) A solution might be obvious at first sight, but extremely hard to rigorously formulate/proof. 2) A problem statement is very hard to grasp, such that I don't even know how to start. 3) I rarely see a measure of ""progress towards a solution""; either I get nowhere or I know from the beginning how to solve a problem/what theorem to use 4) Most problems seem to be ""individual"" in a sense that I can't identify a general concept that might be helpful for a problem that I will face in the future. In particular that means that finding too strong hints or even full solutions does not help at all.
In other fields of math, even copying a well worked out solution might help, since it elucidates in what setting one can properly use a theorem/approach. Do you have any recommendations of how to figure out conceptual elements in graph theory problem solving, i.e. how to figure out a setting and a general strategy that might be applicable to a certain style of problems? Are there any good reads in graph theory that point out problem solving strategies/ways of thinking, instead of focusing on results?","['graph-theory', 'discrete-mathematics']"
403823,Product of two compact topological spaces is compact.,"Proof: I am following this . But, I feel, I am missing something. Consider two compact spaces $X_1$ and $X_2$ and some cover $U$ of their product space. Consider an element $x\in X_1$. The sets $A_{x,y}$ within $U$ contain $(x,y)$ for each $y\in X_2$. 
Now, define $\pi_2:A_{(x,y)}$ which forms an open cover for $X_2$ and has finite subcover $\{A_{(x,y_i)}\}$. It's clear up to this point. Let $\{B_x\}$ be the intersection of $\{\pi_1:(A_y)\}$ within $A_{y_i}$, which is open. Thus, $\{B_x\}$ forms an open cover, which has a finite subcover, $\{B_{x_i}\}$. The corresponding sets $\{A_{x_i,y_i}\}$ is finite, and forms an open subcover of the set. First, we know the covers cover $X_1$ and $X_2$ respectively. But, how do we know that they cover $X_1*X_2$? Second, I believe $\pi_1$ is not necessarily non-empty. So how can we be sure that it is open? I would appreciate any comments or other opinions. P.S. The notations may be, like in original source, somewhat ambigious too.","['general-topology', 'compactness', 'real-analysis', 'analysis']"
403841,curves and surfaces. curvature of a regular curve,"Let $\gamma(t)$ be a regular curve lies on a sphere $S^2$ with center $(0, 0, 0)$ (origin) and
radius $r$. Show that the curvature of $\gamma$ is non-zero, i.e., $Îº \ne 0$. Furthermore, if the torsion of the curve $\tau \ne 0$ we have: $\gamma(t)= - p \overrightarrow{n} - p'\alpha \overrightarrow{b} $ where: $p=1/k, \\ \alpha=1/\tau, \\ r^2=p^2+(p'\alpha)^2  $","['algebraic-curves', 'differential-geometry']"
403876,Show that $\lim\limits_{x\to0}\frac{e^x-1}{x}=1$,"Show that $\displaystyle\lim_{x\to0}\frac{e^x-1}{x}=1$ Letting $y=e^x-1\implies e^x=y+1\implies x=\log(y+1)$ the evaluation is easy. But I can't understand how to express given function as a composition of two functions so that the following rule can be used limit operation can be done. Let $A\subset\mathbb R,f:A\to\mathbb R,g:D\to\mathbb R$ such that $f(A)\subset D.$ Let $c$ be a limit point of $A$ and $\lim_{x\to c}f(x)=l.$ If $l\in D$ and $g$ is cont at $l$ then $\lim_{x\to c}(gf)(x)=g(l)$ and if $l\notin D$ but a limit point of $D$ then $\lim_{x\to c}(gf)(x)=\lim_{y\to l}g(y).$",['limits']
403884,Why isn't the derivative of $e^x$ equal to $xe^{(x-1)}$?,"When we take a derivative of a function where the power rule applies, e.g. $x^3$, we multiply the function by the exponent and subtract the current exponent by one, receiving $3x^2$. Using this method, why is it that the derivative for $e^x$ equal to itself as opposed to $xe^{x-1}$? I understand how the actual derivative is derived (through natural logs), but why can't we use the original method to differentiate? Furthermore, why does the power rule even work? Thank you all in advance for all of your help.","['calculus', 'derivatives']"
403904,"Evaluating $\int_{0}^{1} \frac{\ln^{n} x}{(1-x)^{m}} \, \mathrm dx$","On another site, someone asked about proving that $$ \int_{0}^{1} \frac{\ln^{n}x}{(1-x)^{m}} \, dx = (-1)^{n+m-1} \frac{n!}{(m-1)!} \sum_{j=1}^{m-1} (-1)^{j} s (m-1,j) \zeta(n+1-j), \tag{1} $$ where $n, m \in \mathbb{N}$, $n \ge m$, $m \ge 2$, and $s(m-1,j)$ are the Stirling numbers of the first kind . My attempt at proving $(1)$ : $$ \begin{align}\int_{0}^{1} \frac{\ln^{n}x}{(1-x)^{m}} \, dx  &= \frac{1}{(m-1)!} \int_{0}^{1} \ln^{n} x \sum_{k=m-1}^{\infty} k(k-1)  \cdots (k-m+2) \  x^{k-m+1} \ dx \\ &= \frac{1}{(m-1)!} \sum_{k=m-1}^{\infty} k(k-1)  \cdots (k-m+2)  \int_{0}^{1} x^{k-m+1} \ln^{n} x \, dx \\ &= \frac{1}{(m-1)!} \sum_{k=m-1}^{\infty} k(k-1) \cdots (k-m+2) \frac{(-1)^{n} n!}{(k-m+2)^{n+1}}\\ &= \frac{1}{(m-1)!} \sum_{k=m-1}^{\infty} \sum_{j=0}^{m-1} s(m-1,j) \  k^{j}  \ \frac{(-1)^{n} n!}{(k-m+2)^{n+1}} \\ &= (-1)^{n}  \frac{n!}{(m-1)!} \sum_{j=0}^{m-1} s(m-1,j)  \sum_{k=m-1}^{\infty}   \frac{k^{j}}{(k-m+2)^{n+1}} \end{align} $$ But I don't quite see how the last line is equivalent to the right side of $(1)$. (Wolfram Alpha does say they are equivalent for at least a few particular values of $m$ and $n$.)","['definite-integrals', 'riemann-zeta', 'integration', 'stirling-numbers']"
403924,$x^p-c$ has no root in a field $F$ if and only if $x^p-c$ is irreducible?,"Hungerford's book of algebra has exercise $6$ chapter $3$ section $6$ [Probably impossible with the tools at hand.]: Let $p \in \mathbb{Z}$ be a prime; let $F$ be a field  and let $c \in
 F$ . Then $x^p - c$ is irreducible in $F[x]$ if and only if $x^p - c$ has no root  in $F$ . [Hint: consider two cases: $\mathrm{char}(F) = p$ and $\mathrm{char}(F) \ne p$ .] I have attempted this a lot. Anyone has an answer?","['irreducible-polynomials', 'abstract-algebra', 'polynomials']"
403961,Quotient of Cayley graph of the free group on two generators by a subgroup.,"If $F=F(\{a,b\})$ is the free group on two generators $a$ and $b$ and $G$ is the subgroup $$G=\:\langle b^n a b^{-n}|\: n\in \mathbb{N}\rangle \leq F$$
I am trying to work out what the quotient graph $\Delta / G$ looks like, where $\Delta = \Delta(F;\{a,b\})$, the Cayley graph of F with respect to it's generators. I think that $\Delta$ is the 4-regular tree, and I think I understand that if you quotient out the Cayley graph by the group itself then all of the vertices become one and so you get a wedge of $|S|$ circles where $S$ is the generating set, but clearly when we quotient out by a smaller group, we see that not all vertices become one. In fact, $G$ is not finitely generated (as far as I can tell), and so do we get a sort of infinite wedge of circles? I assume we would if we looked at the quotient $\Delta(G;S)/G$ for $S$ the set of generators of $G$, but we are taking a bigger initial group so I would think that it would still be an infinite wedge of circles, but with a 'bigger' infinite number... In that case its only vertex would have infinite valence. Or do we just think of it as the Cayley graph of the finitely generated group with generators $a,b$ but an infinite set of relations (those given by the elements of $G$?) So is it just an infinite 4-regular graph?","['graph-theory', 'geometric-group-theory', 'group-theory']"
403993,Question on primes.,Let $p(n)$ denote the number of primes less than $n$. Show that there are infinitely many $n$ for which $n$ is divisible by $p(n)$. Source : here,"['prime-numbers', 'algebra-precalculus', 'number-theory']"
404006,Biggest ball included in an intersection of balls,"I would like to prove that  for any family of balls $\{B(c_i,r_i)\}_i \subset \mathbb{R}^d$ such that $\{c_1, \dots, c_n\} \subset \bigcap_i B(c_i,r_i) $ and $\forall i, r_i \geq 1$, there exists a ball of radius $1-\frac{\theta_d}{2}$ included in the intersection $\bigcap_i B(c_i,r_i)$
where $\theta_d/2 = \frac{1}{2}\sqrt{\frac{2d}{d+1}}$ denotes the ratio between the diameter and the radius of the smallest enclosing ball of a regular simplex. Intuitively, it seems that the way of making the smallest intersection is to assign all points $c_i$ to the vertices of a regular simplex of diameter $1$ and all $r_i$ to $1$. By doing so, one can check that the ball of radius $1-\frac{\theta_d}{2}$ centered at $x$ the barycenter of $\{c_1,\dots,c_n\}$ is included in the intersection of balls $ \bigcap_i B(c_i,r_i)$.
Indeed, in the case of a simplex, the radius of the biggest ball centered at $x$ and included in the intersection of balls is $1-\text{Radius}(\sigma) = 1 - \frac{\theta_d}{2}$ (hence the constant is tight in this case). I am having difficulties to prove that this case is indeed the worst case. 
I was just able to prove that the result holds when all balls have the same radius.
Does this result seems familiar to someone? I would really appreciate any comment, idea or reference. ps : The topology tag is here for several reason. One of them is that the biggest radius of the ball included in the intersection corresponds to the weak feature size of the complement of the intersection. Another one is that this result is linked to a collapsibily result.","['general-topology', 'geometry', 'computational-geometry', 'euclidean-geometry']"
404024,Every function in $D'(\Omega)$ is the limit of a sequence in $D'(\Omega)$ with compact support.,How will we prove that for every $f\in D'(\Omega)$ there exists a sequence $(f_j)$ in $D'(\Omega)$ with compact support such that $f$ is the limit of $(f_j)$?,"['weak-convergence', 'fourier-analysis', 'functional-analysis']"
404031,"Prove that if Triangles ABC = DEF in a metric geometry, then line AB contains exactly two of the points D, E, and F.","Prove that if Triangles ABC = DEF in a metric geometry, then line AB contains exactly two of the points D, E, and F. We are not allowed to use the facts: In a metric geometry, if triangles ABC=DEF, then {A,B,C} = {D,E,F} or In a metric Geometry, if A, B, and C are not collinear, then A is an extreme point of triangle ABC. Naturally, I tried to do this with a proof by contradiction by assuming line AB does NOT contain exactly two of the points D,E, or F. I set up three cases for this. Line AB contains none of D,E, or F; Line AB contains one of D, E, or F. (Where I'd imagine the same contradiction will arise no matter which point I choose); Line AB contains all three of D, E, and F. In the first two cases, I can't find where a contradiction will arise. Please Help. Some Definitions The definition of a triangle that I am given is If {A,B,C} are not collinear points in a metric geometry, then the triangle ABC is the set $\bigtriangleup$ABC = $\overleftrightarrow{AB}$ $\cup$ $\overleftrightarrow{BC}$ $\cup$  $\overleftrightarrow{CA}$ The definition of a line segment I am given is $\overleftrightarrow{AB}$ = {C $\in$ $\mathscr{P}$ | A-C-B or C=A or C=B} The definition of between I am given is A-C-B iff A, B, C are collinear and d(A,B) = d(A,C) + d(C,B) ; where $d$ is the distance function for a metric geometry.",['geometry']
404034,Algebraic Tangent Space and Vector - an intuitive understanding?,"In this question I am looking for help in understanding the Algebraic Tangent vector and what the difference is between it and the ""regular"" Tangent vector. A ""differentiable function"" near p is a pair $(f,U)$ where $U \subset$ is open with $p \in U$, and $f:U \rightarrow \mathbb{R}$ is a differentiable function.   We say that two such pairs $(f,U), (g,W)$ are ""equivalent"" - the notation is $(f,U) \sim (g,W)$, if and only if there exists an open $V \subset U \cap W$ with $p \in V$ such that $f|_{V}$ and $g|_{V}$.  So f and g coincide in a small neighborhood of p. $\sim$ is an equivalence relation. Note:  I am thinking that this is an equivalence relation (intuitively) because we are just looking at some neighborhood of point p - that which is  $V \subset U \cap W$ and so other mapping $h: Y \rightarrow \mathbb{R}$ where $Z \subset U \cap W$ is also in the equivalence relation defined by: $$E_{p} \equiv \left\{(f,U)|(f,U) \text{ is a differential function near } p \right\}/\sim$$ Now the equivalence class of a pair $(f,U)$ is denoted by $[f,U]$ and is called the ""germ"" of a differentiable function at  $p$. Note: From my understanding $[f,U]$, the germ, is showing that locally these functions $\in [f,U]$ are differentiable.  I am guessing that is just scratching the surface - but furthermore other than knowing something has to be differentiable to find the tangent (at least in the sense of being $C^{1}$). While I am trying to wrap my head around the above, it seems to get worse.. An element $v$ of the dual space of $E_{p}, v \in Hom(E_{p},\mathbb{R}) =\left\{v:E_{p} \rightarrow \mathbb{R} | \text{ is linear} \right\}$ is called a ""derivation"" if $\forall [f,U],[g,W] \in E_{p}$ the product rule $$v([f,U] \cdot [g,W]) = v([f,U]) \cdot [g,W](p) + [f,U] \cdot v([g,W])$$ holds Defn:  The Algebraic Tangent space of a space X at p is: $T_{p}^{alg}X  \equiv \left\{v \in E_{p}^{*} | v \text{ a derivation}\right\}$ An element of $T_{p}^{alg}X$ is called an algebraic tangent vector of X at p. So what is the point of the Algebraic Tangent vector and space? Thanks much for any thoughts, Brian","['manifolds', 'differential-geometry']"
404037,Prove $\lim_{n\to \infty}\frac{n}{n+1} = 1$ using epsilon delta,$\lim_{n\to \infty}\frac{n}{n+1} = 1$ Prove using epsilon delta.,"['epsilon-delta', 'limits']"
404043,Reduction modulo $p$ in number fields,"For every prime number $p$, there exist a map
  $$f:\mathbb{P}^n(\mathbb{Q})\to\mathbb{P}^n(\mathbb{F}_p)$$ defined
  by: for $P\in \mathbb{P}^n(\mathbb{Q})$, we can find a unique tuple
  $(x_1,\dots,x_n)\in\mathbb{Z}^n$ of coprime integers such that
  $P=[x_1,\dots,x_n]$. Then
  $f(P):=[\overline{x_1},\dots,\overline{x_n}]\in \mathbb{P}^n(\mathbb{F}_p)$. Now, replace $\mathbb{Q}$ by a number field $K$ and $p$ by a prime ideal $\mathfrak{p}$ of $\mathcal{O}_K$. A paper I read speaks of a map
$$f:\mathbb{P}^n(K)\to\mathbb{P}^n(\mathcal{O}/\mathfrak{p}).$$
But how is this defined ? For $P\in\mathbb{P}^n(K)$, we can find $(x_1,\dots,x_n)\in\mathcal{O}_K^n$ such that $P=[x_1,\dots,x_n]$, however, if $\mathcal{O}_K$ is not a UFD, we cannot necessarily choose them such that $x_i\not\in\mathfrak{p}$ for some $i$ as in the rational case...","['algebraic-geometry', 'algebraic-number-theory']"
404057,"Tricky a.e. limit question, studying the $ \text{a.e.-lim}_{t \rightarrow \infty} \frac {1}{t} \int_0 ^ t W_s ~ds$","Could someone give some advice in order to study  $$\underset{t\to\infty}{\operatorname{a.e.-lim}} \frac {1}{t} \int_0 ^ t W_s ~ds,$$ where $(W_t)_{t\geq 0}$ is a standard brownian motion starting at zero ? Thank's in advance.","['probability-theory', 'stochastic-processes', 'stochastic-calculus']"
404059,"How to simulate a sequence of partial sums $(X)_n(w) = \sum\limits_{i=1}^n (Y_i(w)-Y_{i-1}(w)),$ given some properties.","I want to generate/simulate a sequence of partial sums. $$(X)_n(w) = \sum\limits_{i=1}^n (Y_i(w)-Y_{i-1}(w)),\text{ for }1 \leq n \leq 100$$ Let $W$ be a random variable such that: $W \thicksim N(0,1)$. I know that: 
$\forall i, (Y_i(w)-Y_{i-1}(w))$ has the same distribution as $W$. However, I don't know anything about how the individual $Y_i$ random variables are distributed, other than to say that they are, together with W, defined on the same probability space. I'm really confused by a number of aspects about this question. In order to generate the partial sums, is it sufficient to take n independent draws out of a standard normal and then calculate the partial sums of these as my sequence $(X)_n(w)$? But then, from the definition of the partial sums above, it is clear that $w$ is fixed throughout the partial sum. What does that mean for me? My intuitive response is to ignore the fixed $w$. While I can draw on my knowledge of the distribution of $Y_i - Y_{i-1}$ to draw randomly from that distribution, I don't actually know anything about what their underlying functions look like. And so, for different values of $i$, $(Y_i(w) - Y_{i-1}(w)$ may map the same $w$ to vastly different values.","['statistics', 'probability-distributions', 'random-variables', 'probability-theory']"
404062,Normal form of a vector field in $\mathbb {R}^2$,"Edited after considering the comments Problem: What is the normal form of the vector field:
$$\dot x_1=x_1+x_2^2$$
$$\dot x_2=2x_2+x_1^2$$ Solution: The eugine values of the matrix of the linearised around $(0,0)$ system are $2$ and $1$. We, therefore, have the only resonance $2=2\dot{}1+0\dot{} 2$. The resonant vector-monome is $(0,x_1^2)$. The normal form is then
$$\dot x_1=x_1$$
$$\dot x_2=2x_2+cx_1^2$$ Question: I believe this is correct, is it not?","['dynamical-systems', 'ordinary-differential-equations']"
404067,"Proving that brownian motion pass almost ever by zero in $]0,t[$","Consider $B=(B_0)_{t\geq 0}$ a real $\mathcal F_t$ - brownian motion starting at zero, in a probability space $(\Omega, \mathcal F, (\mathcal F_t)_{t\geq 0}, \mathbb P)$. Then, consider 
$$ \Phi_t(x) :=  \mathbb P \left\{\exists s \in ]0, t[ : B_s + x= 0\right\}$$ 
Show that $\Phi_t(0)=1 \forall t \geq 0$. I have tried to explore the fact that $\Phi_t$ is even, since $- B$ is also a brownian motion. However, I still don't see how to prove it. Any advice will be appreciate. Thank's in advance.","['probability-theory', 'stochastic-processes', 'stochastic-calculus']"
404073,Explanation of where this trig identity comes from,"I'm working on a problem but it's been a while since I last saw trig identities so I'd love some help or being pointed in the right direction. Basically, I'd like to understand where this identity comes from; $$\tan(2t) = \dfrac{2\tan(t)}{1 - \tan^2(t)}$$ Thanks for any help you can give - if it's useful to know the context of the problem, I'm writing a bit of code that converges on $\pi$ faster than Leibniz's series. (Please don't give too much away about the rest of the problem though, I'd like to get there myself :) )",['trigonometry']
404106,The 'compactness cardinal' of a space,"I'm looking for references (and a name!) for the following invariant of a topological space $X$: The least (infinite) cardinal $\kappa$ such that any open cover of $X$ has a subcover of cardinality less than $\kappa$. For compact spaces, for example, this cardinal is $\aleph_0$.","['general-topology', 'terminology', 'compactness', 'reference-request']"
404116,Proving that $T_t := S_t -\left| x \right| -\frac {n-1}{2} \int _0 ^t \frac {1}{S_u}~du$ is a brownian motion,"Consider $B=(B_t)_{t\geq 0}$ $\mathcal F_t$ - brownian motion in $\mathbb R ^n, \  (n\geq 2)$ starting at zero, in a probability space $(\Omega, \mathcal F, (\mathcal F_t)_{t\geq 0}, \mathbb P)$ . Then, consider $X_t ^x = x + B_t $ and $S_t = \left|X^x_t\right|$ .
I was trying to show that $(T_t)_{t\geq 0}$ defined by $$T_t := S_t -\left| x \right| -\frac {n-1}{2} \int _0 ^t \frac {1}{S_u}~du$$ is a real $\mathcal F_t$ - brownian motion. It's not difficult to see that $W_t = S_t -\left| x \right|$ is a real $\mathcal F_t$ - brownian motion. Inded, Ito's lemma implies that $$ W_t = \int _0 ^t \frac{X^x_t}{\left| X^x_t \right| }~ dB_s $$ wich is well defined since $\mathbb P (\exists t>0 :  S_t =\left| X^x_t \right| =0) =0$ . Then by Pauls-LÃ©vy Theorem we have that $(W_t)$ is a real $\mathcal F_t$ - brownian motion. So, $$T_t = W_t  -\frac {n-1}{2} \int _0 ^t \frac {1}{S_u}~du.$$ Have anybody a smarter idea that compute its mean and covariance in order to apply again Paul-LÃ©vy theorem ? If not, any smart advices to simplify the calculation? Thank's in advance. Edit: Maybe this other result could helpful to crack this proof. I could show that $\mathbb E \left\{ \int _0 ^t \frac {1}{S_u}~du\right\} =0$ since $M_t := \int _0 ^t \frac {1}{S_u}~du$ is a bounded local martingale.
Then for the covariation we have $$ \mathbb E \left \{T_s T_t  \right\}=t \wedge s -c (\mathbb E \left \{W_s M_t  \right\} +\mathbb E \left \{M_s W_t  \right\}) + \mathbb E \left \{M_s M_t  \right\}$$ New Edit: Could someone please check the question at the end of my solution try at the answer ?","['probability-theory', 'stochastic-processes', 'stochastic-calculus', 'stochastic-integrals']"
404123,Proof of Lusin's Theorem,"$\mathbf{Theorem}$. Let $A \subset \mathbb{R}$ be a measurable set, $\mu(A)<\infty$ and $f$ a measurable function with domain $A$. Then, for every $\varepsilon >0$ there exists a compact set $K \subset A$ with $\mu(A \smallsetminus K) <\varepsilon$, such that the restriction of $f$ to $K$ is continuous. Proof .  Let $\{V_n\}_{n\in\mathbb N}$ be an enumeration of the open intervals with rational endpoints. Fix compact sets $K_n\subset f^{-1}[V_n]$ and $K'_n\subset A \smallsetminus f^{-1}[V_n]$ for each $n$, so that 
$\mu\big(A \smallsetminus (K_n \cup K'_n)\big) < \varepsilon/2^n$. Set $$K = \bigcap_{n=1}^{\infty} \big(K_n \cup K'_n\big). $$ 
Clearly $\mu(A \smallsetminus K) < \varepsilon$. Given $x \in K$ and $n$, such that $f(x) \in V_n$, we can prove continuity of $f$ when restricted on $K$, by choosing a compact neighbourhood $\tilde{K}_n$, such that $x \in \tilde{K}_n$ and $f(\tilde{K}_n \cap K) \subset V_n$.  $\qquad\qquad\square$ $\mathbf{Q1}$: I don't see how $K = \bigcap_{n=1}^{\infty}(K_n \cup K'_n) $ yields $\mu(A \setminus K) < \epsilon$. The way I see it, the intersection should have a really small measure. 
\begin{align}
K = \bigcap_{n=1}^{\infty}(K_n \cup K'_n) =\Bigg( \bigcup_{n=1}^{\infty} (K_n \cup K'_n)^{c} \Bigg)^{c}\\
\mu(K) = \mu \Bigg (\Bigg( \bigcup_{n=1}^{\infty} (K_n \cup K'_n)^{c} \Bigg)^{c} \Bigg) = \mu(A) - \mu \Bigg( \bigcup_{n=1}^{\infty} (K_n \cup K'_n)^{c} \Bigg)
\end{align}
the union of $(K_n \cup K'_n)^{c}$ is probably going to cover almost the entire $A$, right? If this is the case then $\mu(K)=\mu(A)-(\mu(A)-\delta) = \delta$. Where $\delta$ is a small number. Did I make a mistake somewhere? $\mathbf{Q2}$: Do I understand it correctly that we're removing all the compacts $K'_n \subseteq A \setminus f^{-1}(V_n)$ from $A$ in order to achieve continuity? Because for $x \in K'_n$ we don't have $f(x) \in V_n$.","['measure-theory', 'real-analysis']"
404142,"$u\in W^{1,p}(B)$ implies $u\in W^{1,p}(\partial B_t)$ for almost $t\in (0,1]$?","Suppose that $u\in W^{1,p}(B)$ where $B=B(0,1)\subset\mathbb{R}^N$ and $p\geq 1$. It was showed on this post (as an application of Fubini's theorem) that for almost $t\in (0,1]$  $$u_{|\partial B_t},(\nabla u)_{|\partial B_t}\in L^p(\partial B_t)$$ where $B_t=B(0,t)$. My question is: Is there any simple way to see that $u\in W^{1,p}(\partial B_t)$ for those balls where $u_{|\partial B_t},(\nabla u)_{\partial B_t}$ are defined and if $v\in L^p(\partial B_t)^N$ is the gradient of $u$ in the distributional sense, then $v=(\nabla u)_{|\partial B_t}$? Update: I have an idea. Let $u_n\in C^1(\overline{B})$ such that $u_n\to u$ in $W^{1,p}(B)$. Note that byt Fatou's Lemma: $$\int_0^1\liminf\int_{\partial B}(|u_n(r\omega)-u(r\omega)|^p+|\nabla u_n(r\omega)-\nabla u(r\omega)|^p)r^{N-1}drd\Gamma\leq \\ \lim\int_B(|u_n(x)-u(x)|^p+|\nabla u_n(x)-\nabla u(x)|^p)dx \to 0$$ Hence, for almost $t\in (0,1]$, there exist a subsequence of $u_n$ not relabeled such that $$\int_{\partial B_t}(|u_n(y)-u(y)|^p+|\nabla u_n(y)-\nabla u(y)|^p)d\Gamma_t\to 0$$ Can I conclude what I have estated from the last convergence? Thank you","['sobolev-spaces', 'measure-theory', 'partial-differential-equations']"
404143,What is convex combination of two points?,"I am studying algorithms and i saw a definition like the following: Given $3$ points $p_1 = (x_1, y_1)$, $p_2 = (x_2, y_2)$ and
$p_3 = (x_3, y_3)$, $p_3$ is a convex combination of $p_1$ and $p_2$ iff
$\exists 0 \le a \le 1$ such that: (i) $x_3 = x_1 + (1 âˆ’a )x_2$ (ii) $y_3 = y_1 + (1 âˆ’ a)y_2$ If $p_3$ is a convex combination of $p_1$ and $p_2$, we also write
$p_3 = p_1 + (1 âˆ’a )p_2$ My question is, i did not understand what this definition means, and what does convex combination means intuitively? I appreciate any help. Thanks","['geometry', 'algorithms']"
404155,Chebyshev and Markov inequalities,"Chebyshev inequality: Let $(\mathcal{X},\mathcal{A},\mu)$ be a measurable space, $f$ a non-negative measurable function defined on $\mathcal{X}$. Then, $$\mu([f>c]) \le \frac{1}{c^p} \int_{\mathcal{X}} f^p d\mu$$ Proof: 
$$\int_{\mathcal{X}} f^p d\mu  \ge \int_{[f>c]} f^p d\mu \ge \int_{[f>c]} c^p d\mu =c^p \mu([f>c])$$ Of course we can have the Chebyshev inequality in a probabilistic setting. Let $(\Omega, \mathcal{A},\mathbb{P})$ be the stochastic basis, $X$ a non-negative  random variable. Then: $$ \mathbb{P}[X>t] \le \frac{1}{t^p} \mathbb{E}[X^p]$$
Markov inequality: $$ \mathbb{P}[X>t] \le \frac{1}{t} \mathbb{E}[X]$$ So it would seem that the Markov inequality is a special case of Chebyshev ($p=1)$. Is that correct?","['measure-theory', 'inequality', 'probability']"
