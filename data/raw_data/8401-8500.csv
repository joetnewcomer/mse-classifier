question_id,title,body,tags
63551,Derivative of function including matrix logarithm,"Is the following equation a first order approximation or incorrect for general matrix Lie groups? And what are the higher order terms? $$\frac{\partial}{\partial\mathbf x} (\log(\mathtt A\cdot\exp(\widehat{\mathbf x})\cdot \mathtt B))^\vee \approx \mathtt{Ad_A}$$ with $\mathtt{A,B}$ are element of a Matrix Lie group $G(n)$ (=$n\times n$-matrices),
$\mathbf x$ being a n-vector, $\exp(\cdot)$ being the matrix exponential, $\log(\cdot)$ being the matrix logarithm, $\widehat{\cdot}$ being an operator which maps an $n$-vector to a Lie algebra element (=$n\times n$-matrix), v being the corresponding inverse, and $\mathtt{Ad_A}$ is the adjoint of $\mathtt A$ (in matrix form). Before I start with my approach let me first talk about the definitions and some underlying lemmas in more detail. You might want to skip this and jump directly to my attempt below the line (=======). The operator $\widehat{\cdot}$ maps a vector onto the Lie algebra element $\widehat{\cdot}:\mathbb R^n\rightarrow g, \widehat{\mathbf x} = \sum_i x_i \mathtt G_i$, with $\mathtt G_i$ being the generators of the Lie algebra $g$. The vee operator $(\cdot)^\vee: g\rightarrow \mathbb R^n$ is the corresponding inverse. Example for SO3: $\widehat{\mathbf x} = \begin{bmatrix} 0&-x_3& x_2\\ x_3&0,&-x_1\\-x_2&x_1&0\end{bmatrix}$ $(\mathtt R)^\vee= \begin{bmatrix}R_{3,2}\\R_{1,3}\\R_{2,1}\end{bmatrix}=\frac{1}{2} \begin{bmatrix}R_{3,2}-R_{2,3}\\R_{1,3}-R_{3,1}\\R_{2,1}-R_{1,2}\end{bmatrix} = -\begin{bmatrix}R_{2,3}\\R_{3,1}\\R_{1,2}\end{bmatrix} $ Now let us look at the definition of the adjoint: $Adj_\mathtt A(\widehat{\mathbf x}) := \mathtt A \widehat{\omega}  \mathtt A^{-1}$ with $\mathbf x$ being an $n$-vector and $\mathtt A$ a matrix Lie group element. $Adj_\mathtt A$ can be seen as linear operator. Thus, there exists a $n\times n$ matrix $\mathtt{Ad_A}$ such at that $\mathtt{Ad_A}\cdot \mathbf x = (Adj_\mathtt A(\widehat{\mathbf x}))^\vee.$ Example for SO3:
$\mathtt{Ad_R}\mathbf x = \mathtt R \widehat{\mathbf x} \mathtt R^\top$ $\Rightarrow$ $\mathtt{Ad_R=R}$ Since $\mathtt A\exp(\mathtt B)\mathtt A^{-1}=\exp(\mathtt{ABA}^{-1})$ it is true that $\exp(\widehat{\mathtt{Ad_A} \mathbf x}) = \mathtt{A} \exp(\widehat{\mathbf x}) \mathtt{A}^{-1}.$ 
Thus:
$$\exp(\widehat{\mathtt{Ad_A} \mathbf x}) \mathtt A= \mathtt{A} \exp(\widehat{\mathbf x}) \quad (1)$$ Let us look at the formula $\text{BCH}(\mathtt{A,B) := \log(\exp(A),\exp(B))}$. (2) We know, if $\mathtt {A,B}$ commute, $\text{BCH}(\mathtt{A,B}) = \mathtt{A+B}$. Otherwise, it can be approximated with the Baker-Campell-Hausdorff (BCH) formula. The first two terms are: $t_1 = \mathtt{A+B}$ $t_2 = \frac{1}{2}(\mathtt{AB-BA})$ =============================================== My approach: Let $\mathbf c := \log(\mathtt{AB})$ $\frac{\partial}{\partial\mathbf x} (\log(\mathtt A\cdot\exp(\widehat{\mathbf x})\cdot \mathtt B))^\vee = \frac{\partial}{\partial\mathbf x} (\log(\exp(\widehat{\mathtt {Ad_A}\mathbf x})\mathtt A\mathtt B))^\vee$ (using (1)) $= \frac{\partial}{\partial\mathbf x} (\text{BCH}(\widehat{\mathtt {Ad_A}\mathbf x},\mathbf c))^\vee$ (using (2)) Now if $\mathtt {A,B}$ are elements of commutative group (thus, $\widehat{\mathtt{Ad_A}\mathbf x}$ and $\mathbf c$ are elements of a commutative algebra) , we simply get: $= \frac{\partial}{\partial\mathbf x}  \mathtt{Ad_A}\mathbf x + \frac{\partial}{\partial\mathbf x} (\mathbf c)^\vee$ 
$=   \mathtt{Ad_A} + \mathtt O= \mathtt{Ad_A}$ (Edit: Actually, in this case $\mathtt{Ad_A}=\mathtt I$ always.) However, if $\mathtt {A,B}$ are elements of a general (non-commutative) matrix group, we have to use the BCH formula...","['optimization', 'matrices', 'lie-algebras', 'lie-groups']"
63552,Composite functions and one to one,"I am stuck with a question, Let $f: A\rightarrow B$ and $g:B\rightarrow C$ show that if $g\circ f$ is one to one then $f$ is one to
  one.
  Can anyone please help me out. I have no idea where to start with and how end it up. Thanks","['functions', 'function-and-relation-composition']"
63555,"Are integrations on forms ""different"" from Riemann integrations?","I was amazed by the power of integration on forms when I learned that the Stokes' theorem can be written in a beautiful way (don't assume that I know more than this fact itself):
$$
\int_{\Omega}d\omega=\int_{\partial\Omega}\omega.
$$
from which Green's theorem, the divergence theorem, and the fundamental theorem of calculus follow. I learned the definition (it might not be the most general one) from Loring W. Tu's An Introduction to Manifolds : Let $\omega=f(x)dx^1\wedge \cdots\wedge dx^n$ be a $C^{\infty}$ $n$-form on an open subset $U\subset{\mathbb R}^n$, with standard coordinates $x^1,\cdots,x^n$. Its integral over a subset $A\subset U$ is defined to be the Riemann integral of $f(x)$:
  $$
\int_{A}\omega=\int_{A}f(x)dx^1\wedge\cdots\wedge dx^n:=\int_{A}f(x)dx^1\cdots dx^n
$$
  if the Riemann integral exists. As I understand, since ""integration on forms"" is defined by the Riemann integral, it does not provide a new kind of integrals (e.g. Lebesgue integrals in measure theory, Itō integrals in stochastic analysis, etc.). Instead of doing so, it provides a new view of Riemann integral, in which for example $f(x)dx$ has its new meaning, $1$-form. Here are my questions: Is what I understand above correct? Or what's the fundamental difference between these two kinds of integrals? Can I say that this new integration provides a new way to prove the theorems in Riemann integral theory? [EDIT: Is the above definition the only way to define ""integration on forms""?] I feel that my questions might be vague. Any suggestions to improve it will be really appreciated.","['differential-geometry', 'soft-question', 'integration', 'real-analysis']"
63559,How to create a one to one correspondence between two sets?,"I am stuck with, Give a one to one correspondence between Z+ and positive even
  integers. Now, I don't have an idea how to show that there is a one to one correspondence between the two. I would be thankful for some hints.",['functions']
63563,Difference between one to one function and one to one correspondence,"I am confused in the difference between one to one function and one to one correspondence. Please help me out to distinguish between the two. 
Thanks",['functions']
63567,Basis for topology of weak convergence of probability measures,"Let $S$ be a metric space with be Borel $\sigma$-algebra $\Sigma$. Let $\boldsymbol{P}(S)$ be the set of probability measures on $(S,\Sigma)$. According to wikipedia , ""the weak topology is generated by the following basis of open sets: $$\left\{ U_{\phi, x, \delta} \,\left|\, \begin{array}{c} \phi \colon S \to \mathbb{R} \text{ is bounded and continuous,} \\ x \in \mathbb{R} \text{ and } \delta > 0 \end{array} \right. \right\}$$ where $$U_{\phi, x, \delta} := \left\{ \mu \in \boldsymbol{P}(S) \,:\, \left| \int_{S} \phi \, \mathrm{d} \mu - x \right| < \delta \right\}.""$$ I want to verify that this is in fact a basis. It is easy to see that any $\nu\in\boldsymbol{P}(S)$ is contained in some basis element (for any $\delta$ and $\phi$, take $x=\int \phi d\nu$). The next property is that if $\nu$ belongs to the intersection of two basis elements $B_{1}$ and $B_{2}$, then there is a basis element $B_{3}\ni\nu$ such that $B_{3}\subseteq B_{1}\cap B_{2}$. In other words, given that (1) $\displaystyle\left| \int_{S} \phi_1 \, \mathrm{d} \nu - x_1 \right| < \delta_1$; and (2) $\displaystyle\left| \int_{S} \phi_2 \, \mathrm{d} \nu - x_2 \right| < \delta_2$, I need to find $\delta^\ast, x^\ast\in\mathbb{R}$ and a continuous, bounded, real-valued function $\phi^\ast$ such that $\displaystyle\left| \int_{S} \phi^\ast \, \mathrm{d} \nu - x^\ast \right| < \delta^\ast$ implies (1) and (2). I would appreciate any suggestions on how to proceed. Thanks!","['general-topology', 'probability-theory']"
63568,Independence of Events,"I'd appreciate some help with this problem:
There are 2 plants that make keyboards. Keyboard faults are classified in 3 categories: letter, number, and other. If a keyboard is chosen at random, are the events ""faulty letter"" and ""plant 2"" independent? Plant    Letter    Number    Other 1        15        45        40 2        75        30        45 I know that to prove independence, I need to show $P(A|B) = P(A)$; or $P(B|A) = P(B)$; or $P(A \cap B) = P(A)P(B)$. But my question is, how can I do this if I'm only given $P(A)$ and $P(B)$? The intersection of those, divided by either $A$ or $B$ (as needed), will always give me the other probability, so this isn't useful. In case it matters, this IS a textbook problem, but only for my benefit, not class.","['statistics', 'probability']"
63569,Weakest topology with respect to which ALL linear functionals are continuous,"One often considers a Banach space $X$ under the ""weak topology"", ie. the weakest topology such that all bounded linear functionals are continuous. This leads me to wonder about the weakest topology on $X$ such that ALL linear functionals (including unbounded ones) are continuous. A priori this topology is not necessarily stronger or weaker than the standard norm topology. Does it possess any interesting properties? Is it Hausdorf? Connected? Discrete, even?","['general-topology', 'functional-analysis']"
63580,Question about UFD,"I want to know some examples with the following properies. Let $R$ be a domain such that every non unit element $x$ is a product of finite irreducible elements, but $R$ is not a UFD, and there is some element $y\in R$ such that $y$ has two distinct factorizations with different lengths. Textbooks tell me, $\mathbb{Z}[\sqrt{-5}]$ is a non-UFD since $6=2\cdot3=(1+\sqrt{-5})(1-\sqrt{-5})$ .
Since $\mathbb{Z}[\sqrt{-5}]$ is Noetherian, then it is easy to show that every non unit element is a product of finite irreducible elements. But I donot know if every two factorizations of any given element of $\mathbb{Z}[\sqrt{-5}]$ have the same lengths ? That is to ask if this is an example? More, what about general algebraic integer domains ? What is the famous (easy understood) example that a atomic domain is not a HFD (any two factorizations of any given $x$ have the same length)? Thanks.","['ring-theory', 'algebraic-number-theory', 'abstract-algebra']"
63585,Continuity of $f(x)$ involving infinity,"$f(x)= \frac{\sin(\pi x)}{x(1-x)}$ How can I define $f(0)$ and $f(1)$ to make $f(x)$ continuous on $[0,1]$? I've found that the limit at $0 = \pi$, and the limit from the left at $1 = \infty$. I understand that if $f(0)=\pi$ then $f(x)$ is continuous on $[0,1)$, but must I define $f(1)=\infty$? Would that make $f(x)$ continuous? EDIT: Also, can someone explain why $\lim\limits_{x \to 0} \frac{\sin\pi x}{x} = \pi$?","['calculus', 'infinity', 'limits']"
63609,Invertibility of elements in a left Noetherian ring,Let $A$ be a left Noetherian ring.  How do I show that every element $a\in A$ which is left invertible is actually two-sided invertible?,"['noncommutative-algebra', 'ring-theory', 'abstract-algebra']"
63619,Distances between closed sets on metric spaces,"Which says that $\mathbb R^n$ the distance between a point $b$ and a set $X$ defined by$$
\inf \left\{ d(b,x) \mid x \in X \right\}
$$ The proposition: If $X$ is closed, this distance is reached at some point in the set $X$. To prove it I assumed without loss of generality that $X$ is also bounded, because if not, it intersected with (e.g.) $$
B_b (n) = \left\{ x \in \mathbb R^n \mid d(b,x) \leqslant n \right\},
$$
where $n$ for example, can be chosen as the first natural number such that the intersection is not empty, and obviously the rest of the points of $X$, are at a greater distance, and will not be candidates. Then define $$
f(x) = \left| x - b \right| \quad \text{for }x \in X
$$
and since the domain is compact we conclude the result, that reaches its minimum at some point in the set. This demonstration clearly not true for any metric space, because  being closed and bounded is not enough to be compact in general, but anyway maybe it can be shown in a more general way. That is my question, is this true?","['metric-spaces', 'real-analysis']"
63635,Compute $\cos'(0)$,"I know that $\cos'(0)$ is $0$, but my work follows: $$\begin{align}\cos'(0) &= \lim_{\Delta x\to 0}\frac{f(0+\Delta x) - f(0)}{\Delta x}\\
&= \frac{\cos(0+\Delta x) - \cos(0)}{\Delta x}\\
&= \frac{\cos(0) - \cos(0)}{0} = \frac{0}{0}\end{align}$$ Where have I gone wrong? What can I do to show that it equals 0? (Note: No derivative rules are allowed in my calculus class yet, just difference quotients)","['trigonometry', 'calculus', 'limits']"
63650,Dimension of Continuous functions,"I think that $\{\text{continuous functions on } [0,1]\}$ has a different dimension from $\{\text{continuous functions on } [0,1]:F(0)=0, F\in C^1(0,1)\}$ due to the constraints in the latter. But how do I prove this? (I realize that this question may be similar to the question Bases of spaces of continuous functions I asked previously, but this is hopefully more concise and I have thought about @Florian's enlightenment that the dimension of the set of continuous functions on a closed interval is infinite.) Thanks loads!","['linear-algebra', 'functional-analysis']"
63651,how can I prove formally that this set is not path connected,"Let $ \mathbb{R}^2 $ with its usual topology, let $D$ the set of all the lines that pass through the origin, with rational slope. And add to $D$ some point that does not lie in any of the lines ( call this new set $X$). For example $ (e,e 2^{1/2}) $ It is easy to show that this set is connected since, all the lines are connected and the intersection of these is not empty, then the union is also connected. And any set that lies between $D$ and its closure will also be connected, the closure is all $ \mathbb{R}^2 $ so $X$ is also connected. The question is if this set it´s also path connected, but I don´t think so , only for geometrically reasons. But in general it´s difficult to me, that this assertion )=. If someone can help me )=","['general-topology', 'connectedness', 'metric-spaces', 'path-connected']"
63659,"Is isomorphism of two subgroups, one of them normal, enough to guarantee that the other is normal as well?","Let $G$ be a group and $H$, $K$ subgroups such that $H$ is normal in $G$ and $H$, $K$ are isomorphic. After some thought i intuitively concluded that $K$ is not necessarilly normal in $G$. Is that the case? Any rigorous argument? (e.g. counterexample)",['abstract-algebra']
63668,Transforming a sum in an integral,"I have a second question about the article ""Imperfect Bose Gas with Hard-Sphere Interaction"". The authors begins with the sum:
$$\frac{{E_2 }}{{E_0 }} = \frac{{16\pi ^2 a^2 \lambda ^2 }}{{V^2 }}\sum\limits_{} {'\frac{{\langle n_\alpha  \rangle \langle n_\gamma  \rangle \langle n_\lambda  \rangle }}{{\frac{1}{2}\left( {k_\alpha ^2  + k_\beta ^2  - k_\gamma ^2  - k_\lambda ^2 } \right)}}\delta \left( {\vec k{}_\alpha   + \vec k{}_\beta   - \vec k{}_\gamma   - \vec k{}_\lambda  } \right)} 
$$
which represents the second order perturbation term of the energy. ${\langle n_\alpha  \rangle }$ is:
$$\langle n_\alpha  \rangle  = \sum\limits_{n = 0}^\infty  {n\left( {ze^{ - \beta \varepsilon _\alpha  } } \right)} ^n /\sum\limits_{n = 0}^\infty  {\left( {ze^{ - \beta \varepsilon _\alpha  } } \right)} ^n  = \frac{{ze^{ - \beta \varepsilon _\alpha  } }}{{1 - ze^{ - \beta \varepsilon _\alpha  } }}
$$
In the sum the terms with a vanishing denominator are omitted. There is also the
restriction ${\vec k{}_\alpha   \ne \vec k{}_\beta  }\ \ $  and ${\vec k{}_\gamma   \ne \vec k{}_\lambda  }\ \ $. Now the passage that is unclear to me is the passage to the integral:
$$\frac{{E_2 }}{{E_0 }} = \frac{{16\pi  a^2 \lambda ^2 }}{{V^2 }}\left( {\frac{{4V^3 }}{{\pi ^3 \lambda ^5 }}} \right)\sum\limits_{i,j,k}^\infty  {\frac{{z^{j + k + l} }}{{\left( {j + k + l} \right)^{1/2} \left( {j - k} \right)l}}} \frac{{\partial J}}{{\partial u}}
$$
where:
$$J = \int\limits_0^\infty  {\int\limits_0^\infty  {dqdq\frac{{\cosh \left( {upq} \right)}}{{q^2  - p^2 }}} } e^{ - vq^2  - wp^2 } 
$$
and:
$$u = \frac{{\hbar ^2 \beta }}{{2m}}\left( {\frac{{2\left( {j - k} \right)l}}{{j + k + l}}} \right)
$$
$$v = \frac{{\hbar ^2 \beta }}{{2m}}\left( {\frac{{\left( {j + k} \right)l}}{{j + k + l}}} \right)
$$
$$w = \frac{{\hbar ^2 \beta }}{{2m}}\left( {\frac{{\left( {j + k} \right)l + 4jk}}{{j + k + l}}} \right)
$$
$\frac{{\partial J}}{{\partial u}}$ is calculated here: Evaluating the integral $I(u,v,w)=\iint_{(0,\infty)^2}\sinh(upq) e^{-vq^2 - wp^2}pq(q^2-p^2)^{-1}dpdq$ Do you have any suggestion?","['multivariable-calculus', 'integration', 'physics']"
63681,"Calculate width and height of a rectangle, given its diagonal and ratio","Well, I know, it's easy. We did it in class some time ago and I forgot it, I'm stupid because I can't figure it out: E.g. I have a 32"" TV with 16:9 ratio and I want to know its width and height. I'd like to know the whole derivation so I can understand it (again) ... Enlightenment, please! Thanks.",['trigonometry']
63686,How to solve this equation: $\frac{\sqrt[5]{x^3 \sqrt{x\sqrt[3]{x^{-2}}}}}{\sqrt[4]{x\sqrt[3]{x}}}=3$,"Please, help me to solve this equation: $$\frac{\sqrt[5]{x^3\sqrt{x\sqrt[3]{x^{-2}}}}}{\sqrt[4]{x\sqrt[3]{x}}}=3$$ I tried to shorten fraction, but I get very weird numbers like 
$$\frac{\sqrt[30]{x^{19}}}{\sqrt[3]{x}}=3,$$ and I'm stuck there :(",['algebra-precalculus']
63687,Bound for divisor function,"I have been searching for a bound of the divisor function $d(n)$, meaning the number of divisors of n. So far I have found that it can be bounded by 
$$ d(n) \le e^{O(\frac{\log n}{\log \log n})}$$
Wigert has proven the constant is $\log 2$ so 
$$  d(n) \le e^{(\log 2+ o(1)) \frac{\log n}{\log \log n}} $$
However, when I tried to check that bound on a computer, it did not seem right. 
I have drawn $d(n)$ (in blue), $e^{\frac{\log n}{\log \log n}}$ (in red) and $e^{\log 2 \frac{\log n}{\log \log n}}$ (in green) on the following graph: Furthermore, when I plot $\frac{\log d(n)}{\log n / \log \log n}$, it does not seem to have $\log 2$ as a limit either. See this other graph: It appears the constant 1 is a much better fit ! So my question is: is Wigert's bound only true for large $n$ (i.e larger than $10^6$) ? My confusion comes from the second equation, which is clearly a bound (see this post on Tao's blog ) and the result of Wikipedia , which is a limit.","['algorithms', 'number-theory']"
63697,Why is closure omitted in some group definitions?,"In some texts, there are three group axioms and in some there are four. The difference is that one of the axioms, the closure ($a,b\in G$ then $a*b \in G$) is omitted. Why is this so?","['group-theory', 'definition']"
63700,Double exponential distribution,"Let $\zeta$ and $\eta$ be independent random variable with $\exp(\lambda)$ distribution. What is  the distribution of $Z=|\zeta-\eta|$ . I am trying to calculate it by finding $\Pr(\zeta-\eta>x)$, and $\Pr(\eta-\zeta>x)$. Thank you in advance","['probability-distributions', 'probability']"
63703,Meeting of people | Combinatorics,"In a group of $k$ people, some are acquainted with each other and some are not. Every evening, one person invites all his acquaintances to a party and introduces them to each other (if they are not acquainted). Suppose that after each person has arranged at least one party, some $2$ people don’t know each other. Prove that they don’t meet each other in the next meeting. Can this be solved using PHP? I began by assuming that some arbitrary person out of the $k$ available has thrown a party, then everybody who comes there will know everybody else, so if they are not acquainted after this party, it means they won't meet at the next party. Is my working right?",['combinatorics']
63721,"Question on proof that first countable, countable compact space is sequentially compact [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 9 years ago . Improve this question Note. This question concerns steps in a specific proof of the statement from the title, a link to which is (was) provided in the question. That link is now dead, and since the question does not contain all of the information required to accurately answer the question, it will be closed. I'm reading some notes with a proof that a first countable, countably compact space is sequentially compact. On page 118 of these notes (third page of the pdf), they are constructing a convergent subsequence. They state that $B_{n(k)+1}\cap T_{n(k)+1}\neq\emptyset$, so you can take an $x_{n(k+1)}\in B_{n(k)+1}$, showing there exists an $x_{n(i)}\in B_{n(i)}$ for all $i\in\mathbb{N}$. How do they get that? Don't you only have that $x_{n(k+1)}\in B_{n(k)+1}$, not $B_{n(k+1)}$?","['general-topology', 'compactness']"
63725,Isomorphism between infinite dimensional vector spaces,"Does defining an isomorphism $\theta: \mathbb R^{\mathbb N} \to \{\text{polynomials}\}$ make sense? It does intuitively, but I am worried about the infinite nature. Thanks.","['vector-spaces', 'linear-algebra']"
63732,How to study for analysis?,"I am currently a first year undergraduate majoring in mathematics. I'm taking an introductory analysis course and find it very hard compared to other math couses. I know that the topics covered in the course are really the basics of real analysis, such as properties of $\mathbb{R}$, sequences and series, limits, continuity, Riemann integral, etc. I work much harder in analysis than in other courses such as abstract algebra, and am spending a lot of time to memorize all the theorems and their proofs mentioned in class. However, when it comes to work out a problem in the book or in the assignment on my own, I'm stuck. My guess is that I never learned how to do math rigorously, and I always rely on my intuition, which proved usually accurate in the past. The textbook we are using is ""Introduction to Real Analysis"" by Robert Bartle, 3rd ed., but I also downloaded and use some extra analysis notes from a few professors' webpages. Could you please give me any advice on how to study analysis? I'm now really desperate :(","['education', 'learning', 'analysis']"
63745,basic probability question - effect of repetition on odds,"If I have a 5% chance of catching a cold by hugging someone with a cold, what are the odds that I will catch a cold if I hug someone 150 times?  Sorry, basic question.","['statistics', 'probability']"
63750,Probability of dividing a deck of cards into 4 equal piles each containing an ace,"After dividing a standard deck of cards into 4 equal sized piles, what's the probability that exactly one ace is in each pile? I've had a couple of ideas about how to set this problem up but nothing seems to come out correctly. For instance, I can look at the probabilities that each pile has a single ace and set this up as a multiplication of conditional probabilities. It also occurred to me that I could view the events as (the event that Ace of Spades and Ace of Hearts are in different piles), (the event that Ace Spades, Diamonds, and Hearts are in different piles), and (the event that all aces are in different piles). However, I'm having a hard time even determining what the first of these probabilities should be. Is it correct that the probability of the first pile having a single ace is $\dfrac{\binom{4}{1}\binom{48}{12}}{\binom{52}{13}}$? It's been a while since I've done probability so I'm having a little trouble getting started, though I know that eventually I'm going to multiply a number of conditional probabilities together.",['probability']
63756,Tail sum for expectation,"In Pitman's Probability , the tail sum formula for expectation is introduced for a nonnegative (0,1,...) discrete random variable $X$: $$E(X) = \sum_{i=0}^\infty P(X > i).$$ I wonder if there is a similar formula for nonnegative continuous
random variable $X$: $$E(X) = \int_0^\infty P(X > x) dx?$$ If no, are there some conditions for it to hold? And how can it be
proved? Here is my thought: If the cdf $F$ of $X$ is bijective, then $X=F^{-1}(U)$ for some
random variable $U$ uniformly distributed over $[0,1)$. So $$E(X) =
    \int_0^1 F^{-1}(u) du.$$ To prove the tail sum formula, it suffices to prove $$\int_0^1
    F^{-1}(u) du = \int_0^\infty P(X > x) dx.$$ But I am stuck here. What's more, is the condition that the cdf $F$ of $X$ is bijective
really necessary for tail sum formula to hold? Can tail sum formula be generalized to a random variable that is not
necessarily nonnegative? Thanks!","['probability', 'integration']"
63766,vector field on sphere with two handles,Consider a sphere with two handles. If I don't make a mistake it is torus with one handle: Can you give me an example of vector field on it with one singular point. Thanks.,['general-topology']
63774,What is the limit $\lim\limits_{n \to \infty} \frac{n^{\sqrt{n}}}{2^n}$?,"Question : Prove that $\displaystyle
\lim\limits_{n \to \infty} \frac{n^{\sqrt{n}}}{2^n} = 0.
$ I was thinking of using the Squeeze Theorem (might not be the right way to go), but finding an upper-bound function proved to be quite tricky.","['calculus', 'limits']"
63792,How would I tackle statistics problems of these types?,"Suppose you have a loaded coin, and we assume a priori that when you flip it you get heads 20% of the time and tails 80%. If I wanted to be 99% certain that this coin is a fraud, how many times do I need to flip? I know this involves some advanced statistics, but I can't recall?","['statistics', 'probability', 'combinatorics']"
63793,"Motivation for the term ""separable"" in topology","A topological space is called separable if contains a countable dense subset. This is a standard terminology, but I find it hard to associate the term to its definition. What is the motivation for using this term? More vaguely, is it meant to capture any suggestive image or analogy that I am missing?","['general-topology', 'terminology', 'soft-question']"
63794,Probability of iid random variables to be equal?,"Suppose $X_1$ and $X_2$ are iid random variables. I want to determine $P(X_1=X_2)$. If they are integer-valued random variables, then $$P(X_1=X_2) = \sum_{i \in \mathbb{Z}} P_{X_1,X_2}(i,i) = \sum_{i \in \mathbb{Z}} P_{X_1}(i)^2. $$ If they are continuous random variables, then $$P(X_1=X_2) = \int_{x \in \mathbb{R}} f_{X_1,X_2}(x,x) dx  = \int_{x \in \mathbb{R}} f_{X_1}(x)^2 dx. $$ But when  $X_1$ and $X_2$ are uniformly distributed over $[0,1)$, $$P(X_1=X_2)   = \int_{x \in \mathbb{R}} f_{X_1}(x)^2 dx = \int_{x \in [0,1)} 1 dx = 1. $$ Intuitively it is not possible, since $P(X_1\neq X_2) > 0$. So is there some mistake I have made? Thanks!",['probability']
63804,(Explicitly) Constructing Deformation Retractions,"I'm having trouble building the actual deformation retractions, although I understand the concepts behind them, homotopies, etc. For example, when constructing a deformation retraction for $\mathbb{R}^n-\{0\}$ to $S^{n-1}$, I found that you could define the mapping $F(x,t) = (\frac{x_1}{t||x||+(1-t)},...,\frac{x_n}{t||x||+(1-t)})$. However, I still don't see how one thought of that in the first place.
I get the idea of turning the $x_n$'s into unit vectors, but I don't understand the intuition behind the $+(1-t)$, etc. Anyone want to give some advice on how you approach constructing such a family of functions? In terms of an actual problem, I'm trying to construct a def. retraction of $T_2-\{p\}$ onto a graph with 2 circles intersecting in a point (the longitude/meridian circles of the torus). I understand why this is possible, but my intuition fails to construct the actual def. retraction.","['general-topology', 'algebraic-topology']"
63819,Determine angle $x$ using only elementary geometry,"Using only elementary geometry, determine angle x. You may not use trigonometry, such as sines and cosines, the law of sines, the law of cosines, etc.","['geometry', 'angle', 'triangles', 'intuition']"
63826,Number of real roots of a separable real polynomial doesn't change under small perturbations,"Say we have a polynomial with real coefficients and no repeated roots.  Knowing that the roots of a polynomial vary continuously in the coefficients (so long as we don't change the degree), it seems intuitive that all sufficiently close polynomials will have the same number of real roots, because in order to make two real roots non-real, or vice versa, you'd have to first bring them together in order to satisfy the constraint that the non-real ones must be conjugates, and it's not too hard to see that all sufficiently close polynomials will also have no repeated roots (nonzero discriminant is an open set). However I'm at a loss as to how to formalize the ""you'd have to bring them together"" argument above.  That repeated roots can be avoided is easy because we have the discriminant as noted above, and looking at the sign of the discriminant shows the number of real roots won't change mod 4, but I'm not sure how to do better than that algebraically.  It would be nice if Sturm's Theorem could be used but I don't expect that the polynomial quotients involved would be continuous at all the relevant points. Is there any sort of nice algebraic way to do this, or is the best way to formalize the intuitive argument using continuity of roots?  In the latter case, how would you actually prove that you have to bring two of them together? (A possible workaround I thought of for the algebraic approach would be to use a different, more general Sturm chain -- in particular, for polynomials of degree n, consider $\mathbb{R}(a_0,\ldots,a_n)$ ($a_0,\ldots,a_n$ indeterminates) and the generic polynomial $a_n x^n+\ldots+a_0$ and its derivative, take quotients and remainders there, and only afterward plug in the real numbers, thus getting rid of discontinuous-degree-change issues.  However this, or at least this particular variant, doesn't seem to actually work, as far as I can tell -- checking by hand the degree 3 case seems to indicate that this won't work since anything that's an intermediate initial coefficient will end up getting divided by, and the first one of those is $\frac{2}{9}\frac{a_2^2}{9a_3}-\frac{2}{3}a_1$, which can still be 0 without either $a_3$ or the discriminant being 0, which are the two things that can obviously be safely divided by.)","['polynomials', 'roots', 'abstract-algebra', 'analysis']"
63827,Book advice to brush up on Calculus and PDEs,"I just graduated from an engineering school and am about to begin classes as a PhD candidate.  As I review my undergraduate classes and sift through old notes, I find myself wanting for more math knowledge.  While I did well in math classes, I always felt as though I was following steps rather than gaining a depth of understanding and intuition.  To get to the point: Can you recommend any books to brush up on and perhaps gain a more advanced understanding of calculus and PDEs? As an undergraduate, I used Salas Hille and Etgen, which I felt was great at teaching rote steps to solve problems but lacked some depth. Thanks in advance! (Questions regarding a reasonable self-guided book have very frequently been brought up on this forum.  However, I like to think this is unique and apologize if this feels ""repeated."")","['calculus', 'reference-request']"
63830,Limit proof as $x$ goes to infinity,"Trying to help my girlfriend since we're both in Calculus this semester, but my class never went this in depth into limit proofs. A little help so I can pass it on? (: The limit at infinity $\lim_{x\to\infty} f(x) = L$ means that for any
  $\varepsilon > 0$, there exists $N > 0$ such that $|f(x) - L| < \varepsilon$ whenever $x > N$. Use this definition to prove the following statements. $\lim\limits_{x \to +\infty} \frac{10}{x} = 0.$ $\lim\limits_{x \to +\infty} \frac{2x+1}{x} = 2.$ Thanks in advance!","['calculus', 'limits']"
63851,Intersection maximal ideals of a polynomial ring,"Let $k$ be a field and let $k[x,y]$ be the polynomial ring in two variables. Why this ring has trivial Jacobson radical?","['commutative-algebra', 'abstract-algebra']"
63859,Is the algebraic norm of an euclidean integer ring also an euclidean domain norm?,"Let $K$ be a finite extension of $\mathbb{Q}$ (a number field) and $\mathcal{O}_K$ its ring of integers. One defines the norm of an element $\alpha\in K$ to be the determinant of the transformation $m_\alpha: K\to K$ of multiplication by $\alpha$ (where $K$ is considered as a vector space over $\mathbb{Q}$). Now sometimes the integer ring is also a euclidean domain, i.e. it has a ""euclidean norm"" satisfying the defining property of division algorithm. My question is: in an integer ring which is also euclidean, will the norm defined above also serve as a euclidean norm? Put otherwise: is there an example for a euclidean integer ring whose norm is not an euclidean norm?","['ring-theory', 'algebraic-number-theory', 'abstract-algebra']"
63865,A continued fraction involving prime numbers,"What is the limit of the continued fraction $$\cfrac{1}{2+\cfrac{1}{3+\cfrac{1}{5+\cfrac{1}{7+\cfrac{1}{11+\cfrac{1}{13+\cdots}}}}}}\ ?$$ Is the limit algebraic, or expressible in terms of e or $\pi$? What is the fastest way to approximate the limit?","['prime-numbers', 'continued-fractions', 'limits']"
63870,A classical problem about limit of continuous function at infinity and its connection with Baire Category Theorem,"When I google ""baire category theorem"", I get a link to Ben Green's website. And at the end of the paper, he mentioned such a classic problem: Suppose that $f:\mathbb{R}^+\to\mathbb{R}^+$ is a continuous function with following property: for all $x\in\mathbb{R}^+$, the sequence $f(x), f(2x), f(3x),\dots$ tends to $0$. Prove that $\lim_{t\to\infty}f(t)=0$. I find the problem 1.17 on P.27 of the book "" Selected problems of real analysis "", and on P.169 gives the answer by prove the following lemma: If $G$ is a unbounded open set of $\mathbb{R}^+$, then for any closed
  interval $[p,q]\  (0<p<q)$, there exist a $x_0\in [p,q]$ such that
  $G$ contains infinitely many points of the form $nx_0\ (n\in\mathbb{N})$. But, on the above book, it also says: If $\lim_{n\to\infty}f(nx)$ exists only for points $x$ in a nonempty
  closed set without isolated points , then $\lim_{x\to\infty}f(x)$  also
  exist. I didn't find a proof for this result, I want to know whether for any nonempty closed set with no isolated points, the above lemma is true? and could someone tell me why Ben Green mentioned this problem on his paper (see the hint of his paper)?","['baire-category', 'real-analysis']"
63873,Name of principal root function modified to return real values if possible,"Is there a concise name for the function $f_n(x)\colon\mathbb{C}\to\mathbb{C}$ which returns the principal $n$th root of $x$, except in the case when $n$ is odd and $x$ is a negative real number, in which case the real root is returned?","['terminology', 'functions']"
63875,Vector subspaces proof check,"Suppose I wish to show that for a finite dimensional vector space, $V$, with basis $B=\{b_1,...,b_n\}$ and a given subspace $X$ of $V$, there exists a subset of $B$ that generates a subspace $Y$, such that $V=X\bigoplus Y$. Would the following argument make sense? Suppose $X$ has basis $B_X$ which elements are expressed in terms of $B$. List them, together with the elements of $B$, in a matrix and perform Gaussian elimination preserving the $B_X$ rows. then the remaining (non-zero) vectors in the matrix, $M$, will be a basis for $V$. Let ($M$ \ $B_X$)  be the basis of $Y$. Then, $V=X+Y$. Added: The matrix $M$ should only have $n$ non-zero rows. What it meant by ""perform[ing] Gaussian elimination"" is just to list all the basis vectors in $B$ and those for $X$. Then there are linearly dependent vectors. So we use Gaussian elimination to kill those off. But we choose to kill off the basis vectors in the original $B$, leaving those of $X$ in our matrix $M$. So that $M$ contains the basis vectors of $X$ but has only $n$ entries/L.I, vectors. $X\cap Y=\{0\}$ because the the bases for $X$ and $Y$ are linearly independent. Therefore, the statement is true. Comment : Firstly, I am not entirely sure that my argument is necessarily valid. Secondly, it seems to lack rigor. Thanks in advance for any help!","['vector-spaces', 'linear-algebra']"
63877,"Eigenvalues, kernel and rank of a compact operator: how to start?","I'm trying to solve the following exercise: Let $f\in\mathcal{C}([0,1])$ and let $T$ an operator such that $Tf(x)=\int_0^1(x-t)f(t)dt$. I have proved that $T$ is a bounded linear operator and, by means of Ascoli-Arzelà theorem, that it is a compact operator. Now I need to find its kernel, its rank (showing a basis) and its spectrum. I'm quite stucked, without an idea which could make me start. Thank you for any suggestion!","['operator-theory', 'eigenvalues-eigenvectors', 'functional-analysis']"
63909,"Intuition behind ""ideal""","To briefly put forward my question, can anyone beautifully explain me in your own view, what was the main intuition behind inventing the ideal of a ring? I want a clarified explanations in these points: Why is the name ""ideal"" coined?. In English 'ideal' means ""One that is regarded as a standard or model of perfection or excellence."" Why did people gave the name of ideal to such group? And why are the ideals not present in the case of groups? And give me a very fantastic intuition and motivation behind the ideals and what are the roles served by them in advanced mathematics. Thanks a lot, to every one.","['ideals', 'abstract-algebra', 'number-theory']"
63911,Does the image of the projection morphism of a fiber product contain an open set?,"Let $f: X\times_S Y \to X$ be the projection morphism in the definition of fiber product.$ U\subset X\times_S Y$ be an open set. Does $f(U)$ contain a non-empty open set of $X$? I know this can be reduced to the affine case. If it is not true in general, can we save it by adding extra condition such as :$X,Y$ are noetherian, integral, etc.? The problem comes from the attempt to prove: when $X$ is a noetherian integral separated scheme which is regular in codimension one, then $X\times_{\operatorname{Spec}\mathbb{Z}}\operatorname{Spec}(\mathbb{Z}[t])$ is also integral.",['algebraic-geometry']
63945,Number of crossing 1-factors in $K_{2n}$,"Given a vertex set $\{1,\ldots,n\}$,
two edges $\{i,j\}$ and $\{k,\ell\}$ are crossing iff $i\lt k\lt j \lt \ell$. I'm interested in the number of 1-factors in the complete graph over $2n$ vertices, such that each edge of the 1-factor crosses some other edge of the 1-factor. Does anyone have any ideas about this? Edit: This is closely related enumerating circle graphs. Thank you","['graph-theory', 'combinatorics']"
63951,Why is this sum equal to the Logarithmic Integral?,"I am using this sum: $$\sum_{k=1}^\infty \frac{(-1)^{k-1}}{k}\left((-1)^{k-1} (n-1) + \sum_{j=1}^{k-1}\frac{(-1)^{j+k-1}n (\log n)^j}{j!}\right)$$ Empirically, this is precisely equal to $$\sum_{k=1}^\infty \frac{(\log n)^k}{k! k}$$ which is the most significant term in this expansion of the logarithmic integral $$\operatorname{li}(n) = \log \log n + \gamma + \sum_{k=1}^\infty \frac{(\log n)^k}{k! k}$$ where $\gamma$ is the Euler-Mascheroni constant. Can anyone show why my sum is equal to the sum from the logarithmic integral?","['special-functions', 'number-theory']"
63956,"""Conjugate"" of a monotone unbounded function $f : \mathbb N \to \mathbb N$","Fix $\mathbb N = \{0,1,2,\ldots\}$. I remember reading (a few years back) about a way to define a ""dual"" or ""conjugate"" of an unbounded monotone function $f : \mathbb N \to \mathbb N$. But I do not remember the source, nor can I reproduce any nice properties or theorems satisfactorily. The definition I am thinking of goes like this. For an unbounded monotone $f$, define $f^\star$ by: $$
f^\star (y) = \min \{ x \in \mathbb N \,:\, f(x) \geq y \} \ \ \ \ \ \ \ \ \  \text{(proposed)}
$$ It's easy to show that $f^\star$ is also unbounded monotone. I think this definition is more or less correct, but I might very well be wrong on the precise details. My questions are: Has this or a similar object been studied before systematically? What is the standard terminology for it? I remember that the $\star$ operation is involutive: $(f^\star)^\star = f$, and I am looking for a proof or a counter-example. (Note that this property will also make this operation automatically bijective.) I have a weak argument showing it's true, but it's not  at all convincing. \\ EDIT: For the above definition, $(f^\star)^\star \neq f$ in general. But it turns out the definition can be tweaked if we want this property to hold. See Arturo's answer for details. Finally, if this operation makes sense, I feel it should actually be a special case of a more general construction for functions defined on, for instance, lattices. As a bonus question, are any such generalizations known and is there any reference that discusses them? EDIT: Qiaochu's answer gives such a generalization.","['reference-request', 'functions', 'combinatorics']"
63960,What does it mean when a set is the exponent?,"Can you help me understand what the exponent means here? $$ (A\cap B) \cup D^C $$ A, B, C and D are all sets of a universal set U. Thank you.",['elementary-set-theory']
63973,How do I reflect a function about a specific line?,"Starting with the graph of $f(x) = 3^x$, write the equation of the graph that results from reflecting $f(x)$ about the line $x=3$. I thought that it would be $f(x) = 3^{-x-3}$ (aka shift it three units to the right and reflect it), but it's wrong. The right answer is $f(x) = 3^{-x+6}$ but I just can't get to it! An explained step by step would be appreciated so I can follow what is being done. Thanks in advance!","['graphing-functions', 'reflection', 'functions']"
63976,Fatou's Lemma and Almost Sure Convergence (Pt. 1),"I have a question regarding Fatou's Lemma and a sequence of random variables converging almost surely.  Fatou's Lemma states If $\forall n \in \mathbb{N}, \,\, X_{n} \ge 0$ and $\displaystyle X = \liminf_{n \rightarrow \infty} X_{n}$, then $\displaystyle\mathbb{E}[ \liminf_{n \rightarrow \infty}\: X_{n}] \le \liminf_{n \rightarrow \infty}\: \mathbb{E}[ X_{n}]$ Suppose we also know that $X_{n} \rightarrow X$ almost surely.  How can we connect this to the requirements of Fatou's Lemma?  It seems to me that the Lemma asks for pointwise convergence, a wholly different beast.","['probability-theory', 'real-analysis', 'limits']"
63977,Why adjoining non-Archimedean element doesn't work as calculus foundation?,Consider the smallest ordered field that contains R and does not satisfy the Archimedean property . I assume this is a much simpler construction than ultrafilters and other big caliber artillery used in non-standard analysis. Why does this approach fail?,"['nonstandard-analysis', 'calculus', 'abstract-algebra']"
63986,Asymptotic behaviour of sums of consecutive powers,"Let $S_k(n)$, for $k = 0, 1, 2, \ldots$, be defined as follows $$S_k(n) = \sum_{i=1}^n \ i^k$$ For fixed (small) $k$, you can determine a nice formula in terms of $n$ for this, which you can then prove using e.g. induction. For small $k$ we for example get $$\begin{align}
S_0(n) &= n\\
S_1(n) &= \frac{1}{2}n^2 + \frac{1}{2}n \\
S_2(n) &= \frac{1}{3}n^3 + \frac{1}{2}n^2 + \frac{1}{6}n \\
S_3(n) &= \frac{1}{4}n^4 + \frac{1}{2}n^3 + \frac{1}{4}n^2 \\
S_4(n) &= \frac{1}{5}n^5 + \frac{1}{2}n^4 + \frac{1}{3}n^3 - \frac{1}{30}n
\end{align}$$ The coefficients of these polynomials are related to the Bernoulli-numbers, and getting arbitrary coefficients in these polynomials (i.e. the coefficient of $n^m$ in $S_k(n)$ for large $k,m$) is not so easy. However, th first two coefficients follow a simple pattern: the coefficient of $n^{k+1}$ is $\frac{1}{k+1}$ and the coefficient of $n^k$ (for $k > 0$) is always $\frac{1}{2}$. My main question now is: How can we prove that $S_k(n) = \frac{1}{k+1}n^{k+1} + \frac{1}{2}n^k + O(n^{k-1})$ for $k > 0$? The first coefficient can be explained intuitively, as $$S_k(n) = \sum_{i=1}^n \ i^k \approx \int_{i=1}^n i^k di \approx \frac{n^{k+1}}{k+1}$$ Maybe you could make this more rigorous, but I don't see how you will get the term $\frac{1}{2}n^k$ with this. Also, while the coefficient of $n^{k+1}$ can be explained intuitively, it's not clear to me why the coefficient of $n^k$ is $\frac{1}{2}$, and why this one is fixed while e.g. the coefficient of $n^{k-1}$ is different for different $k$. If someone could explain that, that would be appreciated as well. Thanks.","['asymptotics', 'number-theory']"
63987,Name for $(1-x)$?,"The multiplicative inverse of $x$ is $\frac{1}{x}$, and the additive inverse of $x$ is $-x$, is there a similar term for $(1-x)$?","['terminology', 'functions']"
63997,Description of $R \otimes R$ for $R$ a ring of integers,"If $K/k$ is a finite Galois extension of fields, with Galois group $G$, there's an isomorphism
$$ K \ \otimes_k \ K \simeq \oplus_{\sigma_i \in G} \ K$$
given by sending $a \otimes b$ to $ (...,  \sigma_i(a) b, ...)$ and extending linearly. This is even an isomorphism of $K$-vector spaces, where $a \in K$ is acting by multiplication on the first factor in $K \otimes K$, and by multiplication by $(\sigma_i(a))$ on $\oplus_{\sigma_i} K$. There's also an obvious $k[G]$-module structure that's preserved. My question is what happens if instead of $K$, we consider $R \otimes_S R$, where $R$ and $S$ are the rings of integers of number fields $K$ and $k$ respectively. I tried playing around with quadratic extensions, and I'm pretty sure that the same map above from $R \otimes R$ to $\oplus R$ is not surjective, so the same argument doesn't work? Is there a nice description of $R \otimes R$ as either an $R$ module, or an $S[G]$ module? Thanks.","['abstract-algebra', 'number-theory']"
64021,Gandalf's adventure (simple vector algebra),"So, I found the correct answer to this homework question, but I was hoping there was an easier way to find the same answer. Here's the question: Gandalf the Grey started in the Forest of Mirkwood at a point with coordinates $(-2, 1)$ and arrived in the Iron Hills at the point with coordinates $(-1, 6)$. If he began walking in the direction of the vector $\bf v = 5 \mathbf{I} + 1 \mathbf{J}$ and changes direction only once, when he turns at a right angle, what are the coordinates of the point where he makes the turn. The answer is $((-1/13), (18/13))$. Now, I know that the dot product of two perpendicular vectors is $0$, and the sum of the two intermediate vectors must equal $\langle 1, 5\rangle$. Also, the tutor solved the problem by using a vector-line formula which had a point, then a vector multiplied by a scalar. I'm looking for the easiest and most intuitive way to solved this problem. Any help is greatly appreciated! I'll respond as quickly as I can.",['multivariable-calculus']
64022,The limit of binomial distributed random variable,"Edit (As Robert pointed out, what I was trying to prove is incorrect.  So now I ask the right question here, to avoid duplicate question) For infinite independent Bernoulli trials with probability $p$ to success, define a random variable N which equals to the number of successful trial.  Intuitively, we know if $p > 0$,  $\Pr \{N < \infty \} = 0$, in other word $N \rightarrow \infty$.  But I got stuck when I try to prove it mathematically. \begin{aligned}
\Pr \{ N < \infty \} 
& = \Pr \{ \cup_{n=1}^{\infty} [N \le n] \} \\
& = \lim_{n \rightarrow \infty} \Pr \{ N \le n \} \\
& = \lim_{n \rightarrow \infty}\sum_{i=1}^{n} b(i; \infty, p) \\
& = \sum_{i=1}^{\infty} b(i; \infty, p) \\
\end{aligned} I've totally no idea how to calculate the last expression. (Original Question) For infinite independent Bernoulli trials with probability $p$ to success, define a random variable N which equals to the number of successful trial.  Can we prove that $\Pr \{N < \infty \} = 1$  by: \begin{aligned}
\Pr \{ N < \infty \} 
& = \Pr \{ \cup_{n=1}^{\infty} [N \le n] \} \\
& = \lim_{n \rightarrow \infty} \Pr \{ N \le n \} \\
& = \lim_{n \rightarrow \infty}\sum_{i=1}^{n} b(i; \infty, p) \\
& = \sum_{i=1}^{\infty} b(i; \infty, p) \\
& = \lim_{m \rightarrow \infty}\sum_{i=1}^{m} b(i; m, p) \\
& = \lim_{m \rightarrow \infty}[p + (1 - p)]^m \\
& = \lim_{m \rightarrow \infty} 1^m \\
& = 1
\end{aligned} I know there must be some mistake in the process because if $p = 1$, N must infinite. So the  equation only holds when $ p < 1 $.  Which step is wrong?","['infinity', 'probability']"
64028,Expectation of pairwise differences between uniform random points in hypercube,"Say you have 2 iid random variables $x,y\sim U[0,1]^k$, i.e. the uniform distribution over the k-dimensional unit cube.
What's the expected value of the Euclidean distance between them when they have been normalized by the maximum distance possible, i.e. $\sqrt k$? For $k=1$, I worked out that this is 1/3. For $k=100$, monte carlo simulations tell me it's a little over 0.4. I tried  to work out the math but
$$\frac{1}{\sqrt{k}}\int_{S_x} \int_{S_y} \sqrt{(x-y)^T (x-y)}\;dx\;dy$$
where $S_x,S_y=[0,1]^k$ for general $k$ is beyond me.","['probability', 'integration']"
64035,Can a nonzero polynomial evaluate to the zero function in a suitable infinite ring of char 0?,"I shall assume all rings to be commutative in this question. The impatient can scroll down to the ""blockquote"" to read the actual question. Whenever we have a polynomial over a ring, it defines a function from the ring to itself by evaluation. It's reasonable to ask when two different polynomials define the same function. From the factor theorem it follows that an $n^\text{th}$ degree polynomial over an integral domain has at most $n$ roots. Then it's easy to show this: Theorem. Let $R$ be an infinite integral domain and let $f \in R[X]$ such that $f(a)=0$ for all $a \in R$, then $f = 0$. Proof. $f$ has infinitely many roots, so it must be the zero polynomial. $\quad\square$ For finite rings a kind of opposite situation occurs: Theorem. For any finite ring $R$ there are polynomials over $R$ that are different but agree on all elements. Proof. There are only finitely many functions from $R$ to itself, but $R[X]$ is infinite. $\quad\square$ If we make further assumptions it's of course possible to prove more, as Pete L. Clark wrote in this post: [ 1 ] Then there is the question of infinite rings that are not integral domains. It's relatively easy to come up with examples of a ring $R$ with positive characteristic and a nonzero polynomial that evaluates to the zero function, e.g.:
$$ R := \bigoplus_{n=1}^\infty \mathbb{Z}/6\mathbb{Z} \quad\text{and}\quad f(X) := X^3-X.$$ The Question: This leaves open the case alluded to in this post's title: Is there a commutative ring of characteristic $0$ (hence infinite) such that a nonzero polynomial evaluates to the zero function?","['ring-theory', 'abstract-algebra']"
64047,"What is $f(x, y) = |x| - |y|$ called?","$f(x,y)=x^2-y^2$ is your friendly neighbourhood hyperbolic paraboloid. $f(x, y) = |x| - |y|$ naturally has similar appearance. Do shapes of the latter form have a name?","['geometry', '3d']"
64050,Do groups of order $p^3$ have subgroups of order $p^2$?,"If $G$ is a nonabelian group of order $p^3$ for $p$ a prime, and every nonidentity element has order $p$, does there exist a subgroup isomorphic to $\mathbb{Z}_p\times\mathbb{Z}_p$? Based on some searching, I bet it's true. I read a construction of such a subgroup by taking a element $x$ of order $p\in Z(G)$. Then you can ""pull back to $G$ a subgroup of $G/\langle x\rangle$ of order $p$. The resulting subgroup will be normal with index $p$, and isomorphic to $\mathbb{Z}_p\times\mathbb{Z}_p$ since it's an abelian group killed by $p$."" This writing is all very vague to me. Is there a clearer explicit explanation of why a subgroup of order $p^2$ isomorphic to $\mathbb{Z}_p\times\mathbb{Z}_p$ exists in $G$?",['abstract-algebra']
64061,How does one determine $n$-spheres of curvature?,"I am aware of circles of curvature and I am simply wondering to what extent does this generalize to $n$-dimensions.  Specifically, if some surface in $n$-dimensional space is represented parametricaly, how does one determine the $n$-sphere of curvature at any given point?","['calculus', 'differential-geometry', 'analysis']"
64066,A question on Gram matrix,"The entries of Gram matrix is defined by $ \langle x_i,x_j\rangle$ in the $(i,j)^{\text{th}}$ position. It is known that Gram matrix is positive semidefinite. Is it still positive semidefinite if $ \langle x_i,x_j\rangle$  is replaced by  $ |\langle x_i,x_j\rangle|$?",['matrices']
64067,Evaluate the integral $\int_0^{\infty} \lfloor x \rfloor e^{-x}\mathrm dx$,I'd like some help with the following integral: $$\int_0^\infty \lfloor x \rfloor e^{-x}\mathrm dx .$$ Thanks.,"['calculus', 'integration']"
64078,How to prove something is a sufficient statistic?,"If you have $n$ random variables that are iid with density $\frac{1}{p}e^{-x/p}$, how do you show that the sum of the $x_i$'s is a sufficient statistic? Attempt: Take likelihood function and express in terms of $g(p)h(x)$ and use factorization theorem to show that it is a sufficient statistic.
So likelihood = $\frac{1}{p^n} \exp(\sum \frac{-x_i}{p}) = \frac{1}{p^n} \exp(\frac{1}{p}  \sum (-x_i))$.",['statistics']
64079,Uniform Boundedness for Holomorphic Functions,"Let $\mathcal{F}$ be a family of holomorphic functions on a common domain $U \subset \mathbb C$. Suppose that $\mathcal{F}$ is pointwise bounded in the sense that for each $z \in U$, there is a constant $b > 0$ (potentially dependent on $z$) such that $|f(z)| \leq b$ for all $f \in \mathcal{F}$. Must it hold that $\mathcal{F}$ is uniformly bounded on each compact subset of $U$? Using a covering argument, I can show that this holds provided $\mathcal{F}$ is equicontinuous. Moreover, the set $\mathcal{F} = \{f(z) =1/z\}$ is a counterexample if we don't require the sets on which the functions are bounded be compact. However, I am unsure about whether this is true as stated.","['functional-analysis', 'complex-analysis']"
64085,Is a countable direct sum of free modules free?,I had a very basic question about free modules that I wanted to use as an ingredient in a proof but I am not sure if it is true in general. Let $R$ be a commutative ring with multiplicative identity.  Suppose $ \{ F_i \}_{i \in \mathbb{N} }$ are a countable family of free $R$-modules. Is the countable direct sum $F_1 \oplus F_2 \oplus F_3 \oplus F_4 \oplus \ldots$ free? If so is there an easy way to prove this?,"['modules', 'linear-algebra', 'abstract-algebra']"
64107,"Is there a particularly elegant proof that if $|G|=pqr$, then $G$ is solvable?","I know for a fact that if a group $G$ has order $pqr$ with $p,q,r$ distinct primes, then $G$ is solvable. Most proofs I see of this are very ugly, and require a lot of case checking to show most cases lead to contradictions. So is there a relatively ""nice"" proof of this fact, or am I too optimistic is asking for such thing?",['group-theory']
64112,Finding limit of $\lim\limits_{h\to 0} \frac1{h}\left(\frac1{\sqrt{x+h-2}}-\frac1{\sqrt{x-2}}\right)$,"As expected, if you plug in 0 into the initial equation, the answer is undefined or indeterminate. I tried multiplying the conjugate $\frac1{\sqrt{x+h-2}}+\frac1{\sqrt{x-2}}$ to the numerator and the denominator, but i couldn't simplify this equation enough to avoid the indeterminate value. $$\lim_{h\to 0} \dfrac{\frac1{\sqrt{x+h-2}}-\frac1{\sqrt{x-2}}}{h}$$","['calculus', 'limits']"
64118,Dirac Delta distribution of discrete variables,"There exists the following relation for the Besselfunctions $j_{l}(\alpha\,x)$, $j_{l}(\beta\,x)$ with $\alpha$, $\beta$ $\in \mathbb{R}$  and  $x\in \mathbb{R}$ $$\int_{0}^{\infty}dx \, x^{2}\, j_{l}(\alpha\,x)\, j_{l}(\beta\,x) = \frac{\pi}{\beta}\, \delta(\alpha^{2}-\beta^{2}). $$ Now, assume $\alpha_{n} , \beta_{n} \in \mathbb{Z}$ , i.e. are discrete numbers, then the above equation can be rewritten in terms of $$\int_{0}^{\infty}dx \, x^{2}\, j_{l}(\alpha_{n}\,x)\, j_{l}(\beta_{n}\,x) = 
\int_{0}^{\infty} \,dy \, dz \, \delta(y-\alpha_{n}) \, \delta(z-\beta_{n}) dx \, x^{2}\, j_{l}(y\,x)\, j_{l}(z\,x)$$
$$= \int_{0}^{\infty} \,dy \, dz \, \delta(y-\alpha_{n}) \, \delta(z-\beta_{n})
\frac{\pi}{z}\, \delta(y^{2}-z^{2})$$
$$=\frac{\pi}{\beta_{n}}\, \delta(\alpha_{n}^{2}-\beta_{n}^{2}). $$ Question: I don't understand how the Delta Distribution which is supposed to be continuous can be understood in terms of discrete variables, since the Dirac Delta within the theory of generalized functions is always used with some test function which is integrated over which is not possible in this case.",['analysis']
64126,Even numbers greater than 10 as sum of two specific odd numbers,"It is well known fact that it is very hard to prove Goldbach's strong conjecture but perhaps some weaker variations can be proved(or disproved) ,so my question is:
Is it true that every even number greater than 10 can be represented as the sum of an odd prime number and an odd semiprime ?","['prime-numbers', 'number-theory']"
64138,"Same Div, different Curl, Equal on the boundary of some region?","""Find a pair of fields having equal divergences in some region, having the same
values on the boundary of that region, and yet having different curls"" Can anyone name a pair of fields that fit this requirement (It would be awesome if the region was the unit sphere)","['multivariable-calculus', 'vector-analysis']"
64149,Largest Normal subgroup,"let $G$ be a finite group and $H$ any subgroup. $\psi_{H}$ be the left action of $G$ on $G/H$. It was asked to prove that the action is transitive and the kernel of $\psi_{H}$ is the 'largest normal subgroup'. It was easy to see that it is transitive. What does this 'largest normal subgroup' mean? Is it some thing anologous to maximal ideal definition? Or does it mean the normal subgroup with greatest cardinality? (note that $G$ need not be finite).
Thanks Edit: By $G/H$ I mean the set of left cosets.","['group-theory', 'abstract-algebra']"
64160,"Sequence of $L^2$-normed functions, s.t. $L^2$-norm of derivatives diverges","Does there exist a sequence of smooth functions $(f_n) \subset C^\infty([0,1])$ with $\|f_n\|_{L^2} = 1$ for all $n$ but $\|f^\prime_n\|_{L^2} \to \infty$? I looked already at approximations of the Dirac function, but they are all stated with the property $\|g_\epsilon\|_{L^1} = 1$, i.e. normed w.r.t the $L^1$-norm, and I couldn't adopt them. Thanks.","['functions', 'calculus', 'real-analysis']"
64164,Defining a measure as a supremum,"Let $\Sigma$ be a $\sigma$-algebra over a set $X$, and $\mu_1$ and $\mu_2$ measures in it. It can be shown that $$ \begin{align}
\mu_\sup: &\Sigma \to [0,\infty]\\
&E \mapsto \sup_{F \in \Sigma}\, \{\mu_1 (E \cap F) + \mu_2 (E\setminus F)\}
\end{align}$$ is a measure. How do I show that it's the smallest measure $\mu$ with domain $\Sigma$ such that $\mu\geq\max\{\mu_1, \mu_2\}$?",['measure-theory']
64165,Should the domain of a function be inferred?,"It is a common practice to have students of elementary algebra infer the domain of a function as an exercise. I believe this is contrary to the spirit of the definition of a function as a collection of ordered pairs, no two of which have the same first term. In all serious, set-theoretic presentations of functions, relations, of which functions are a special case, come first, and then the definition of domain and range. So, if any inference is to be done, it would seem like it should be of the “formula”, or explicit rule, if there is one, that defines how the ordinate is obtained from the abscissa. What the inference amounts to in practice is finding what values of the independent variable would result in either a denominator of 0 or the positive even root of a negative number. This sounds like a made-to-order exercise for students of elementary algebra, and so I can understand the temptation to take this path. Still, it does seem to me to go against the very spirit of the subject. Furthermore, I recall seeing someplace a discussion that ran something like this: A.  Why don’t we just agree that the domain of the function is the set of all values for which the formula is meaningful? B.  We can’t do even that, because such a maximal set of such values is not necessarily unique. Speaker B then goes on to give an explicit example where there is more than one maximal set of numbers satisfying the formula. If I recall correctly, this diaglog was in a book on complex variables, or within a larger discussion regarding complex variables. Of course, we can easily construct a crude counterexample by citing the function that takes every number to its square root: for real numbers the domain is the set of non-negative real numbers, but for complex numbers the domain is the set of all complex numbers. However, I believe the example given by speaker B had something to do with a tricky denominator. Does anyone know the dialog/example I am referring to? So, I believe the answer to this question is in the negative, but I wanted to see what the community thinks. After all, here at MSE, we seem to take such exercises in stride, such as here: Domain of a function and here: Finding a function's domain from the function's formula","['education', 'algebra-precalculus', 'soft-question']"
64174,Calabi-Yau Manifolds,"In short, I'm hoping for some reading recommendations. I'm starting to do some work with Calabi-Yau manifolds, though my prerequisites are fairly minimal in differential geometry. I've taken a relaxed reading course on differential geometry, hopping around Spivak, and I'm taking a full course this semester. I've also taken a reading course on elliptic curves and a full course in algebraic geometry, building up to Riemann-Roch, in case there are some reads that build from that angle. So, does anyone have any recommendations for good reading material for my situation? Mostly I'm asking because I've been informed I have to read papers and present (relaxed) talks on the material, and I'd like to not fall flat on my face on the very first talk! Thanks! (Also, any recommendations on presenting material you very not familiar with is welcome.)","['complex-geometry', 'self-learning', 'reference-request', 'differential-geometry']"
64178,Set of linear transformations,"How to determine the dimension of {$T\in$ Lin($X,Y$) s.t. $T(A)\subset B$} where $A,B$ are subspaces of finite-dimensional vector spaces $X$ and $Y$? Thanks in advance! P.S. Is there a general way of determining the dimension of a given set of functions? References to examples and/or explicit examples would be appreciated.","['linear-algebra', 'functions']"
64186,Intuition behind using complementary CDF to compute expectation for nonnegative random variables,"I've read the proof for why $\int_0^\infty P(X >x)dx=E[X]$ for nonnegative random variables (located here ) and understand its mechanics, but I'm having trouble understanding the intuition behind this formula or why it should be the case at all. Does anyone have any insight on this? I bet I'm missing something obvious.","['statistics', 'expected-value', 'probability']"
64194,Are the primes found as a subset in this sequence $a_n$?,"Below is a introduction that contains some background to my question. The question is found at the bottom. By calculating the eigenvalues of the matrix defined by the recurrence: $\displaystyle T(n,1)=1, T(1,k)=1, n \geq k: -\sum\limits_{i=1}^{k-1} T(n-i,k), n<k: -\sum\limits_{i=1}^{n-1} T(k-i,n)$ mentioned in: Do these series converge to the von Mangoldt function? we get eigenvalues whose signs appear to be equal to a rearrangement of the Möbius function but whose magnitudes differ: Example: The $6 \times 6$ determinant equal to zero: $$\begin{vmatrix} 1-\lambda&1&1&1&1&1 \\ 1&-1-\lambda&1&-1&1&-1 \\ 1&1&-2-\lambda&1&1&-2 \\ 1&-1&1&-1-\lambda&1&-1 \\ 1&1&1&1&-4-\lambda&1 \\ 1&-1&-2&-1&1&2-\lambda \end{vmatrix}=0$$ gives eigenvalues: {-5.2439, -3.4641, 3.4641, 2.5169, -2.2730, 0} Compare this with the eigenvalues from the $7$ x $7$ determinant: {-6.8444, -5.2217, -3.4641, 3.4641, 3.0150, -1.9489, 0} From Todd Timberlake's paper ""Random numbers and random matrices: Quantum chaos meets number theory"" (2005-2006) I learned that one needs to unfold the eigenvalues in order to plot their distribution. I did not understand the unfolding process so I asked Todd Timberlake via email how to do it for a finite list of eigenvalues (all in all $11$ eigenvalues in my mail). In the answer he said that the unfolding approximation method should not be applied to only $11$ eigenvalues. From his paper I also read the following sentence: ""Furthermore, it indicates that if the prime numbers are eigenvalues of some quantum system, then the classical counterpart of that system should be integrable."" Putting the lambdas "" $\lambda$ "" along the diagonal rarely seems to give integer values.
Instead we can try putting them at all elements: $$\begin{vmatrix} 1-\lambda&1-\lambda \\ 1-\lambda&-1-\lambda \end{vmatrix}=0$$ This gives the equation: $$-2 + 2 \lambda = 0$$ and we see that $\lambda$ is integer. Now this works up to a $4$ x $4$ matrix or so, after that the $\lambda$ :s become zero. But this is not the right thing to do as this is like taking the determinant of the original matrix. And because $\lambda$ is not an eigenvalue anymore we will instead of $\lambda$ use $x$ . Another option is to insert the $-x$ into the recurrence instead. Now this gives the sequence of real numbers I am going to ask a question about, but with negative signs. Because I want the sequence to be positive I therefore insert "" $x$ "" into the recurrence which then becomes: $\displaystyle T(n,1)=1, T(1,k)=1, n \geq k: x -\sum\limits_{i=1}^{k-1} T(n-i,k), n<k: x -\sum\limits_{i=1}^{n-1} T(k-i,n)$ This then gives a matrix that starts as this $6$ x $6$ determinant equal to zero: $$\begin{vmatrix}1&1&1&1&1&1 \\ 1&-1+x&1&-1+x&1&-1+x \\ 1&1&-2+x&1&1&-2+x \\ 1&-1+x&1&-1&1&-1+x \\ 1&1&1&1&-4+x&1 \\ 1&-1+x&-2+x&-1+x&1&2-2x \end{vmatrix} = 0$$ which results in the equation: $\displaystyle 180 x - 306 x^2 + 184 x^3 - 46 x^4 + 4 x^5 = 0$ for which the $5$ solutions are: $\displaystyle x=0,\; x=3/2,\; x=2,\; x=3,\; x=5$ The polynomials for the $1$ x $1$ to $n$ x $n$ determinants start: $\displaystyle \begin{align*}
&1=0\\
&-2+x=0\\
&6-5 x+x^2=0\\
&-6 x+5 x^2-x^3=0\\
&30 x-31 x^2+10 x^3-x^4=0\\
&180 x-306 x^2+184 x^3-46 x^4+4 x^5=0\\
&-1260 x+2322 x^2-1594 x^3+506 x^4-74 x^5+4 x^6=0\\
&1260 x^2-2322 x^3+1594 x^4-506 x^5+74 x^6-4 x^7=0\\
&-2520 x^3+4644 x^4-3188 x^5+1012 x^6-148 x^7+8 x^8=0\\
&-25200 x^3+61560 x^4-59744 x^5+29248 x^6-7552 x^7+968 x^8-48 x^9=0
\end{align*}$ The $n$ :th polynomial appears to have $n-1$ solutions, when counting solutions equal to zero, and $n$ :th polynomial also appears to have those $n-1$ solutions in common with the $n+1$ :th polynomial. This allows us to order the solutions which then become the following infinite sequence $a_n$ starting: $\displaystyle a_n = (), 2,3,0,5,\frac{3}{2},7,0,0,\frac{5}{3},11,0,13,\frac{7}{4},\frac{15}{7},0,17,0,19,0,\frac{7}{3},\frac{11}{6},23,0,0,\frac{13}{7},0,0,29,\frac{15}{11},31...$ The number of distinct primes dividing the number $n$ , $\omega(n)$ , appears to describe this sequence and there are similarities with the Möbius function. But I find it difficult to understand $\dfrac{15}{7}$ , for example. The Mathematica program for printing the matrix for the determinant with its polynomial and solutions is: Clear[nn, t, n, k, M, x];
nn = 12; (*size of matrix*)
t[n_, 1] = 1;
t[1, k_] = 1;
t[n_, k_] := 
  t[n, k] = 
   If[n < k, 
    If[And[n > 1, k > 1], x - Sum[t[k - i, n], {i, 1, n - 1}], 0], 
    If[And[n > 1, k > 1], x - Sum[t[n - i, k], {i, 1, k - 1}], 0]];
M = Table[Table[t[n, k], {k, 1, nn}], {n, 1, nn}];
MatrixForm[M]
Det[M] (*polynomial*)
Solve[Det[M] == 0, x] (*solutions to the polynomial*) My question is: Are all the primes found among the solutions to the polynomials above? And can you describe the sequence of solutions $a_n$ using $\omega(n)$ ? Edit: 16.9.2011 Plot of the 32:nd polynomial: Edit 2: 16.9.2011 The Mathematica code for the plot is: Clear[nn, t, n, k, M, x];
nn = 32;(*size of matrix*)t[n_, 1] = 1;
t[1, k_] = 1;
t[n_, k_] := 
  t[n, k] = 
       If[n < k, 
    If[And[n > 1, k > 1], x - Sum[t[k - i, n], {i, 1, n - 1}], 0], 
    If[And[n > 1, k > 1], x - Sum[t[n - i, k], {i, 1, k - 1}], 0]];
M = Table[Table[t[n, k], {k, 1, nn}], {n, 1, nn}];
MatrixForm[M];
Plot[{Log[Det[M]], -Log[-Det[M]]}, {x, 0, nn + 2}, Filling -> Axis] Edit 18.11.2012:
It appears that by using the formula by Wolfgang Schramm, one gets the terms of the sequence $a_n$ as solutions to much simpler polynomials that have the form: $$\sum\limits_{k=1}^{k=n} T(n,k) \cdot \cos(-2 \pi \frac{k}{n}) = 0$$ But this way there is only one solution per polynomial compared to the determinant polynomial that gives n-1 consecutive terms of the sequence $a_n$ as its solutions. Edit 3.7.2022: Replace $x$ with $i*(-1)^{(-s)}$ and solve for $s$ instead: (*start*)TableForm[Table[Clear[nn, t, n, k, M, x, c];
  nn = mm;
  t[n_, 1] = 1;
  t[1, k_] = 1;
  t[n_, k_] := 
   t[n, k] = 
    If[n < k, 
     If[And[n > 1, k > 1], 
      I*(-1)^(-s) - Sum[t[k - i, n], {i, 1, n - 1}], 0], 
     If[And[n > 1, k > 1], 
      I*(-1)^(-s) - Sum[t[n - i, k], {i, 1, k - 1}], 0]];
  M = Table[Table[t[n, k], {k, 1, nn}], {n, 1, nn}];
  MatrixForm[M];
  Det[M]; FullSimplify[(s /. Solve[Det[M] == 0, s])], {mm, 2, 10}]]
MatrixForm[M]
TableForm[N[%%, 14]]
(*end*) $$M=\left(
\begin{array}{cccccccccc}
 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
 1 & -1+i (-1)^{-s} & 1 & -1+i (-1)^{-s} & 1 & -1+i (-1)^{-s} & 1 & -1+i (-1)^{-s} & 1 & -1+i (-1)^{-s} \\
 1 & 1 & -2+i (-1)^{-s} & 1 & 1 & -2+i (-1)^{-s} & 1 & 1 & -2+i (-1)^{-s} & 1 \\
 1 & -1+i (-1)^{-s} & 1 & -1 & 1 & -1+i (-1)^{-s} & 1 & -1 & 1 & -1+i (-1)^{-s} \\
 1 & 1 & 1 & 1 & -4+i (-1)^{-s} & 1 & 1 & 1 & 1 & -4+i (-1)^{-s} \\
 1 & -1+i (-1)^{-s} & -2+i (-1)^{-s} & -1+i (-1)^{-s} & 1 & 2-2 i (-1)^{-s} & 1 & -1+i (-1)^{-s} & -2+i (-1)^{-s} & -1+i (-1)^{-s} \\
 1 & 1 & 1 & 1 & 1 & 1 & -6+i (-1)^{-s} & 1 & 1 & 1 \\
 1 & -1+i (-1)^{-s} & 1 & -1 & 1 & -1+i (-1)^{-s} & 1 & -1-i (-1)^{-s} & 1 & -1+i (-1)^{-s} \\
 1 & 1 & -2+i (-1)^{-s} & 1 & 1 & -2+i (-1)^{-s} & 1 & 1 & -2-i (-1)^{-s} & 1 \\
 1 & -1+i (-1)^{-s} & 1 & -1+i (-1)^{-s} & -4+i (-1)^{-s} & -1+i (-1)^{-s} & 1 & -1+i (-1)^{-s} & 1 & 4-4 i (-1)^{-s}
\end{array}
\right)$$ Solving for $s$ appears to give always real part one half: $$\begin{array}{llllll}
 \frac{1}{2}+\frac{i \log (2)}{\pi } & \text{} & \text{} & \text{} & \text{} & \text{} \\
 \frac{1}{2}+\frac{i \log (2)}{\pi } & \frac{1}{2}+\frac{i \log (3)}{\pi } & \text{} & \text{} & \text{} & \text{} \\
 \frac{1}{2}+\frac{i \log (2)}{\pi } & \frac{1}{2}+\frac{i \log (3)}{\pi } & \text{} & \text{} & \text{} & \text{} \\
 \frac{1}{2}+\frac{i \log (2)}{\pi } & \frac{1}{2}+\frac{i \log (3)}{\pi } & \frac{1}{2}+\frac{i \log (5)}{\pi } & \text{} & \text{} & \text{} \\
 \frac{1}{2}+\frac{i \log \left(\frac{3}{2}\right)}{\pi } & \frac{1}{2}+\frac{i \log (2)}{\pi } & \frac{1}{2}+\frac{i \log (3)}{\pi } & \frac{1}{2}+\frac{i \log (5)}{\pi } & \text{} & \text{} \\
 \frac{1}{2}+\frac{i \log \left(\frac{3}{2}\right)}{\pi } & \frac{1}{2}+\frac{i \log (2)}{\pi } & \frac{1}{2}+\frac{i \log (3)}{\pi } & \frac{1}{2}+\frac{i \log (5)}{\pi } & \frac{1}{2}+\frac{i \log (7)}{\pi } & \text{} \\
 \frac{1}{2}+\frac{i \log \left(\frac{3}{2}\right)}{\pi } & \frac{1}{2}+\frac{i \log (2)}{\pi } & \frac{1}{2}+\frac{i \log (3)}{\pi } & \frac{1}{2}+\frac{i \log (5)}{\pi } & \frac{1}{2}+\frac{i \log (7)}{\pi } & \text{} \\
 \frac{1}{2}+\frac{i \log \left(\frac{3}{2}\right)}{\pi } & \frac{1}{2}+\frac{i \log (2)}{\pi } & \frac{1}{2}+\frac{i \log (3)}{\pi } & \frac{1}{2}+\frac{i \log (5)}{\pi } & \frac{1}{2}+\frac{i \log (7)}{\pi } & \text{} \\
 \frac{1}{2}+\frac{i \log \left(\frac{3}{2}\right)}{\pi } & \frac{1}{2}+\frac{i \log \left(\frac{5}{3}\right)}{\pi } & \frac{1}{2}+\frac{i \log (2)}{\pi } & \frac{1}{2}+\frac{i \log (3)}{\pi } & \frac{1}{2}+\frac{i \log (5)}{\pi } & \frac{1}{2}+\frac{i \log (7)}{\pi }
\end{array}$$ Edit a while later: A more eigenvalue like equation: (*start*)
mmm = 6;
TableForm[Table[Clear[nn, t, n, k, M, x, c];
  nn = mm;
  t[n_, 1] = 1;
  t[1, k_] = 1;
  t[n_, k_] := 
   t[n, k] = 
    If[n < k, 
     If[And[n > 1, k > 1], -Sum[t[k - i, n], {i, 1, n - 1}], 0], 
     If[And[n > 1, k > 1], -Sum[t[n - i, k], {i, 1, k - 1}], 0]];
  M = Table[Table[t[n, k], {k, 1, nn}], {n, 1, nn}];
  MatrixForm[M];
  Det[M];
  FullSimplify[(s /. 
     NSolve[Det[M - I*(-1)^(s)*IdentityMatrix[mm]] == 0, s])], {mm, 1,
    mmm}]]
MatrixForm[M - I*(-1)^(s)*IdentityMatrix[mmm]]
(*end*) where key equation is: NSolve[Det[M - I*(-1)^(s)*IdentityMatrix[mm]] == 0, s] $$\left(
\begin{array}{cccccc}
 1-i (-1)^s & 1 & 1 & 1 & 1 & 1 \\
 1 & -1-i (-1)^s & 1 & -1 & 1 & -1 \\
 1 & 1 & -2-i (-1)^s & 1 & 1 & -2 \\
 1 & -1 & 1 & -1-i (-1)^s & 1 & -1 \\
 1 & 1 & 1 & 1 & -4-i (-1)^s & 1 \\
 1 & -1 & -2 & -1 & 1 & 2-i (-1)^s
\end{array}
\right)$$ This gives numerical zeros: But those don't have the same consistent signs on the real part. Added 26.12.2022: (*start*)
(*Mathematica*)
Clear[nn, t, n, k, M, x];
nn = 16;(*nn = the size of the matrix*)
t[n_, 1] = 1;
t[1, k_] = 1;
t[n_, k_] := 
  t[n, k] = 
   If[n < k, 
    If[And[n > 1, k > 1], 
     1/n^(-x - 1) - Sum[t[k - i, n], {i, 1, n - 1}], 0], 
    If[And[n > 1, k > 1], 
     1/k^(-x - 1) - Sum[t[n - i, k], {i, 1, k - 1}], 0]];
M = Table[Table[t[n, k], {k, 1, nn}], {n, 1, nn}];
MatrixForm[M]
polynomial = Det[M];
Factor[polynomial]
(*end*) $$t(\text{n$\_$},1)=1;
t(1,\text{k$\_$})=1;
t(\text{n$\_$},\text{k$\_$})\text{:=}t(n,k)=\text{If}\left[n<k,\text{If}\left[n>1\land k>1,\frac{1}{n^{-x-1}}-\sum _{i=1}^{n-1} t(k-i,n),0\right],\text{If}\left[n>1\land k>1,\frac{1}{k^{-x-1}}-\sum _{i=1}^{k-1} t(n-i,k),0\right]\right]$$ 6x6 matrix: $$\left(
\begin{array}{cccccc}
 1 & 1 & 1 & 1 & 1 & 1 \\
 1 & 2^{x+1}-1 & 1 & 2^{x+1}-1 & 1 & 2^{x+1}-1 \\
 1 & 1 & 3^{x+1}-2 & 1 & 1 & 3^{x+1}-2 \\
 1 & 2^{x+1}-1 & 1 & -2^{x+1}+4^{x+1}-1 & 1 & 2^{x+1}-1 \\
 1 & 1 & 1 & 1 & 5^{x+1}-4 & 1 \\
 1 & 2^{x+1}-1 & 3^{x+1}-2 & 2^{x+1}-1 & 1 & -2^{x+2}-3^{x+1}+6^{x+1}+2
\end{array}
\right)$$ The factored determinant has the Euler product for the Riemann zeta function in it: $$45\ 2^{x+4} \left(2^x-1\right)^3 \left(3^x-1\right)^2 \left(5^x-1\right)$$ The determinant of the 16x16 matrix also has the Euler product as a factor in it: $$875875\ 2^{7 x+15} 3^{x+6} \left(2^x-1\right)^8 \left(3^x-1\right)^5 \left(5^x-1\right)^3 \left(7^x-1\right)^2 \left(11^x-1\right) \left(13^x-1\right)$$ when setting $x=-s$ , that is.","['sequences-and-series', 'number-theory', 'polynomials', 'matrices', 'prime-numbers']"
64207,How can I analytically determine a 1D projection of a high-dimensional ellipsoid?,"For an axis-aligned ellipsoid $a_{11}x_1^2+a_{22}x_2^2+a_{33}x_3^2+a_{44}x_4^2=1$ it is easy to see that $x_1$ is in the range $-1/\sqrt{a_{11}}$ to $1/\sqrt{a_{11}}$. However, in the general case of a rotated ellipsoid, $\sum_{i,j} a_{ij}x_ix_j=1$ (eq. 1) where $a_{ij}$ forms a positive definite matrix, how do I calculate the limits for $x_1$? In other words, I want to project the ellipsoid (which in my case has ~100 000 dimensions) onto its first dimension. What I have come up with so far is solving eq. 1 wrt. $x_1$ $x_1 = \frac1{a_{11}}\left[-\sum_{j\neq1}x_ja_{1j}\pm\sqrt{a_{11}(\sum_{i\neq1, j\neq1}x_ix_ja_{ij})-((\sum_{j\neq1}x_ja_{1j})^2) }\right]$ and taking its first derivative with respect to the other $x_k$ $\frac{dx_1}{dx_k}=\frac1{a_{11}}\left[-a_{1k}\pm\frac{a_{11}x_k(\sum_{j\neq1}x_ja_{kj})-A_{1k}}{\sqrt{a_{11}(\sum_{i\neq1, j\neq1}x_ix_ja_{ij})-((\sum_{j\neq1}x_ja_{1j})^2) }}\right]$ to exploit the necessary condition $\frac{dx_1}{dx_k}=0$ for extrema. However, the resulting system of equations does not look like I could find a general solution easily, especially since all the sums still contain $x_k$ :-(. Is there possibly a much smarter way to solve this problem? Or am I stuck with plugging the formula for $x_1$ and its derivative into a numerical solver to find minimum and maximum?",['algebraic-geometry']
64233,Fatou's Lemma and Almost Sure Convergence (Pt. 2),"This is an extension to the question I asked earlier here .  The overarching question was the following homework problem, Let $X_{n} \rightarrow X$ in probability.  Show that $\liminf_{n} \mathbb{E}[X_{n}] \ge \mathbb{E}[X]$. Obviously, this is very similar to the statement of Fatou's Lemma.  I also know the following, $X_{n} \rightarrow X$ in probability if and only if for all subsequences $X_{n(m)}$ of $X_{n}$ there exists a sub-subsequence $X_{n(m_{k})} \rightarrow X$ almost surely. Given what was answered in my last question, it is trivial to show that Fatou's lemma applies to all of these sub-subsequences $X_{n(m_{k})}$, but how can I bring this back to $X_{n}$ itself, being that it lacks almost sure convergence to $X$? EDIT Another condition is that $X_n \ge 0$","['probability-theory', 'measure-theory']"
64235,How to make a uniform grid of points in a curved space?,"If a space has a differential volume element defined by: $d\Omega=\sin^2(\alpha)\sin(\theta)d\alpha d\theta d\phi$ And $\alpha \in [0,\pi/2]$, $\theta \in [0,\pi]$, and $\phi \in [0,2\pi]$ How can I make a regular grid of points over the space that is uniform with respect to the the differential volume element? I imagine a solution where I reparameterize the space in terms of, e.g., $u,v,w$, which are sampled uniformly. Then to get $\alpha,\theta,\phi$ I apply some transformation: $\alpha = f(u)$ $\theta = g(v)$ $\phi = h(w)$ or something like that.  How would I do this (i.e. find f, g, and h)?","['multivariable-calculus', 'differential-geometry']"
64249,Is there a general result that groups of order $2^n\cdot 3$ are solvable?,"For the past day or so I've been trying to solve an exercise in Lang showing all groups of order less than $60$ are solvable. Excluding the case of order $56$, most cases are taken care of by other theorems. The ones that are giving me trouble are groups of order $2^n\cdot 3$, namely, $12, 24, 48$. I can solve these individually by counting arguments, but I'd rather knock them all out in one go with a more general result. I've been searching for a proof that groups of order $2^n\cdot 3$ are solvable, but haven't found one. Does anyone have a clean proof of this fact? Thank you. P.S. I'd rather not use Burnside's Theorem, since I think that's a little overkill for the spirit of this problem.","['finite-groups', 'group-theory']"
64261,Good upper bound for $\sum\limits_{i=1}^{k}{n \choose i}$?,I want an upper bound on $$\sum_{i=1}^k \binom{n}{i}.$$ $O(n^k)$ seems to be an overkill -- could you suggest a tighter bound ?,"['asymptotics', 'discrete-mathematics', 'binomial-coefficients', 'combinatorics']"
64262,Counting bases to which numbers are pseudoprime,"Let $n=p_1^{a_1}\cdots p_k^{a_k}$ be an odd composite.  Then the number of bases $1\le b\le n-1$ for which n is a strong pseudoprime is $$
\left(1 + \frac{2^{k\nu}-1}{2^k-1}\right) \prod_{i=1}^k\gcd\left(n^*,\ p_i^*\right)
$$ where $v_2(x)$ is the largest e such that $2^e|x-1$ and $\nu$ is the minimum of $v_2(p_i)$ over all the $p_i$, and $x^*$ is the largest odd divisor of $x-1$. 1. What is the analogous formula for pseudoprimes? I've seen it but misplaced the reference. 2. What is the original source of this formula?  I've never seen an attribution, it's always stated as folk knowledge.  Does it date back to the time of Fermat? 3. Similarly, what is the source of the formula above for strong pseudoprimes?","['ring-theory', 'math-history', 'number-theory']"
64263,Self-Teaching: Is Geometry the Nexus of all Mathematics?,"Necessary prologue: I'd really like to become more fluent in the language of mathematics. I don't have a schedule that permits me taking a class and any on-line tutors that I find seem relatively sketchy. So, I'm looking to teach myself. After reading quite a few books on the history of mathematics, it's become clear to me that geometry seems to be where mathematics all started. Not only that, but it seems to lead into other branches of mathematics quite well (for example, everything geometric can be discussed and represented algebraically, so I'll, by necessity, bump into algebra along the way). My question: Given that I'm looking to teach myself, that I have no direct NEED for understanding a specific branch of mathematics, and that I intend to be studying casually, like, for the rest of my life off and on, is it fair to assume that geometry is a good starting place for a general mathematics education?","['geometry', 'algebraic-geometry', 'learning', 'education']"
64266,Nomenclature in complex analysis,"I am having a little confusion on the naming of functions in complex analysis.
If $f$ is a holomorphic function on the complex plane and its domain is the complex plane then it's called an entire function. If $g$ is holomorphic everywhere on the complex plane apart from its poles and its domain is the complex plane then it's a meromorphic function. But...
If $g$'s domain is extended to the Riemann sphere (and it doesn't have a essential singularity at infinity) is it a ""meromorphic function with domain of Riemann sphere"" or ""holomorphic function with domain of Riemann sphere"" or a ""rational function""? Thanks!","['terminology', 'complex-analysis']"
64276,Interpret density plot,"I'm trying to understand this density plot.  The X axis is the time between requests.  What is the probability of the purple data source having a time between request of 500?  What is the probability of the purple data source having a time between requests of 250 - 500? Also, where's a good source to explain how to interpret a density plot? https://i.sstatic.net/Usre8.png","['statistics', 'probability']"
64284,Finding $ \lim_{a \to \infty} \int\limits_0^{2010} \sqrt{x(1+\cos ax)}\ \mathrm dx $,"Could someone give a suggestion to calculate this limit please? $$
\lim_{a \to \infty} \int\limits_0^{2010} \sqrt{x(1+\cos ax)}\ \mathrm dx
$$ I don't know methods for solving such limits with integrals. Thanks.","['calculus', 'integration', 'limits']"
64292,Boxcar Recursive Method for Finding Standard Deviation,"I'm trying to develop a real time algorithm for finding level areas of an electrical signal. To do so I need to find the variance for a particular rolling time interval. From John Cook's blog and the Art of Computer Programming the algorithm for quickly determining variance is: M k = M k-1 + (x k - M k-1 )/k S k = S k-1 + (x k - M k-1 ) * (x k - M k ) Where the kth estimate of the variance is: $ s^2 = S_k / (k-1) $ This works great, but I need to keep a 'rolling' variance of 100 samples. With each step I would add one new sample and take the 100th sample off the list. If I know the value of x k-100 is there a quick algorithm for 'erasing' it from the variance result?","['statistics', 'recurrence-relations', 'algorithms']"
64301,Proof of $X\cup Y\neq V$,"Suppose $X,Y$ are subspaces of dimension $n-k$ of the vector space $V$ of dimension $n$. Why is it always true that $X\cup Y\neq V$? I can show this by arguing that if $X=Y$ then clearly by the difference in dimension, that $X\cup Y\neq V$. If $X\neq Y$ then there is a member, $x$, in the basis of $X$ that in not in $Y$ and vice versa. Then $x+y\not\in X\cup Y$ but is in $V$. Is this argument valid? Is there a more elegant/simpler argument? Thanks!","['vector-spaces', 'linear-algebra']"
64305,"Texts on Principal Bundles, Characteristic Classes, Intro to 4-manifolds / Gauge Theory","I am looking for a textbook that might serve as an introduction to principal bundles, curvature forms and characteristic classes, and perhaps towards 4-manifolds and gauge theory. Currently, the only books I know of in this regard are: ""From Calculus to Cohomology"" (Madsen, Tornehave) ""Geometry of Differential Forms"" (Morita) ""Differential Forms in Algebraic Topology"" (Bott, Tu) I have been reading both ""Calculus to Cohomology"" and ""Geometry of Differential Forms,"" but am occasionally frustrated by the lack of thoroughness.  Both are at the perfect level for me, and cover almost exactly what I'm looking for, but I really prefer textbooks which are as thorough as possible, ideally to the extent of, say, John Lee's books (which I adore).  Meanwhile, Bott and Tu is a little advanced for me right now. Of course, I don't mean to be picky, but I also can't believe that the three I've listed are the most thorough accounts of the subject.","['principal-bundles', 'differential-geometry', 'reference-request', 'differential-topology', 'gauge-theory']"
64307,Physics: Uniform Motion,"Ok so I have this homework problem. I dont want to give out the information because i want to put in the values myself, but basically I have one object moving at said speed.  Said time later, another object leaves the same location as the object 1 and said speed faster.  At some time later, object 2 is only said distance away from object 1.  I have to find both their speeds.  If this is too vague then i can re-write the question.  Anybody got any tips?","['algebra-precalculus', 'physics']"
64313,Primer on complex analysis and Riemann surfaces for undergraduate physics / theoretical physics majors,"Ref: The Road to Reality: a complete guide to the laws of the universe, (Vintage, 2005) by Roger Penrose [Chap. 7: Complex-number calculus and Chap. 8: Riemann surfaces and complex mappings] I'm searching for an easily readable and understandable book (or resource of any kind; but preferably textbook with many worked-out problems and solutions and problem sets) to learn complex analysis and basics of Riemann surfaces - and applications to theoretical physics. (Particularly: material geared towards / written with undergraduate-level physics / theoretical physics students in view). Any suggestions? My math background: I have a working knowledge of single- and multivariable calculus, linear algebra, and differential equations; also some rudimentary real analysis.","['riemann-surfaces', 'big-list', 'complex-analysis']"
64326,Are column operations legal in matrices also?,"In linear algebra we have been talking a lot about the three elementary row operations. What I don't understand is why we can't multiply by any column by a constant? Since a matrix is really just a grouping of column vectors, shouldn't we be able to multiply a whole column by a constant but maintain the same set of solutions for the original and resulting matrices?","['vector-spaces', 'linear-algebra']"
64332,Precalculus Project decision,OK so I have to do a research paper/presentation on an experiment/project that relates to my precalculus class.  Only problem is that I was given no topics to choose from and I couldn't find any real good ones online.  Can anybody give me some good ideas/topics that I can do? (P.S. if its fun then that's a plus :D),['algebra-precalculus']
