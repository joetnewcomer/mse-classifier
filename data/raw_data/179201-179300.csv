question_id,title,body,tags
3251256,"Do Carmo Riemannian Geometry, definition 2.6","Bit of trouble understanding the following definition: Let $M$ be a differentiable manifold. A differentiable function $\alpha : (-\epsilon,+\epsilon)\to M$ is called a differentiable curve in $M$ . Suppose $\alpha(0) = p \in  M$ , and let $\mathcal{D}$ be the set of functions on $M$ that are differentiable at $p$ . The tangent vector to the curve $\alpha$ at $t=0$ is a function $\alpha'(0):\mathcal{D}\to \mathbb{R}$ given by $$
\alpha'(0) f = \left( \frac{d(f \circ \alpha)}{dt} \right)_{t=0}
$$ The definition continues but it's irrelevant for my question. Because I don't know the image of the function $f$ , but it is assumed to be differentiable shall I assume that $f$ is real valued somehow? Definition 2.5. defines a mapping $\varphi$ from a manifold to another to be differentiable if its expression is differentiable. The expression is a well defined function from $\mathbb{R}^m$ to $\mathbb{R}^n$ . However in the definition above of tangent vector I don't think $f$ is necessarely a function between two manifolds. The question is how is the definition of $\alpha'(0)$ well defined to be a function from $\mathcal{D}$ to $\mathbb{R}$ ?","['manifolds', 'definition', 'differential-geometry']"
3251262,How should Matrix Calculus be thought of with respect to Vector and Multi-variable Calculus?,"My question boils down to identifying the ways in which Matrix Calculus is distinct from Vector and Multi-variable Calculus, and how they overlap. Is Matrix Calculus simply a notation on top of these other types of Calculus, or does it actually contain new theorems/lemmas/results separate from the other two? The subject of Matrix Calculus does not seem to be a subject of courses at universities and I struggle to find resources to actually learn about it.","['multivariable-calculus', 'calculus', 'linear-algebra']"
3251279,"Let $A, B$ and $C$ be the angles of an acute triangle. Show that: $\sin A+\sin B +\sin C > 2$. [duplicate]","This question already has answers here : Question about sines of angles in an acute triangle (3 answers) Closed 5 years ago . Let $A, B$ and $C$ be the angles of an acute triangle. Show that: $\sin A+\sin B +\sin C > 2$ . I started from considering $$\begin{align}\sin A+\sin B+\sin (180^o-A-B) &= \sin A+\sin B+\sin(A+B) 
\\&=\sin A+\sin B+\sin A\cos B + \cos A\sin B 
\\&=\sin A(1+\cos B)+\sin B(1+\cos A).\end{align}$$ How to proceed?","['inequality', 'trigonometry', 'geometric-inequalities', 'substitution', 'karamata-inequality']"
3251286,"If $f$ is an entire function and $f(z) \not \in [0,1]$ for every $z$, then $f$ is constant","I want to prove that if $f$ is an entire function and $f(z) \not \in [0,1]$ for every $z$ , then $f$ is constant. If it was written that $|f(z)| \not \in [0,1]$ I would have used the fact that $\frac{1}{f}$ is entire function and Cauchy's formula to bound it. However it is not the case here, so I don't really see what to do. I can still use the fact that $\frac{1}{f}$ is also entire, but appart from that, I am clueless. Help would be appreciated","['complex-analysis', 'entire-functions', 'cauchy-integral-formula']"
3251287,"$\lim_{(x,y)\to 0} \frac{x\sin(y)- y\sin(x)}{x^4 + y^4}$ without polar coordinates?","I have the following limit: $$\lim_{(x,y)\to 0} \frac{x\sin(y)- y\sin(x)}{x^4 + y^4}$$ And I must evaluate it without polar coordinates. I have tried a lot of stuff but nothing works. Can someone give me a hint?",['limits']
3251290,Hitting times by Brownian motion,"[Edited] Suppose that $A$ is a (Borel) measurable set and $X$ is an Ito diffusion, i.e., $dX_{t}=\mu(X_t)dt+\sigma(X_t)dB_t$ . Consider a hitting time $\tau_A$ of the given set $A$ by the process $X$ : $\tau_A:=\inf\{t\geq0:X_t\in A\}$ . Also, let $\tau_\bar{A}:=\inf\{t\geq0:X_t\in \bar{A}\}$ where $\bar{A}$ is the closure of $A$ . Now, my question is: Is $\tau_\bar{A} = \tau_A$ (a.s.)? I think this must be true, but I do not find any reference for this... In case my conjecture is incorrect, any idea on reasonable conditions (either on $A$ or $X$ ) under which this is true? I'd really appreciate your help! Based on the comments below, suppose that $X_t$ is an Ito diffusion process and let me refine my question as follows: Let $X_0 = x$ . If the process $X$ comes back to $x$ infinitely often in any time interval $(0,\epsilon)$ , $\epsilon>0$ , then can we say that my assertion above ( $\tau_\bar{A} = \tau_A$ (a.s.)) is true? My intuition is that if $X$ has this property, then along with the Markov property of $X$ , for any given $t$ , a sample path $X_{s>t}$ always ""zig-zagged"" around $X_t$ for any $s>t$ . So, given any set $A$ , as soon as $X$ hits its boundary point of $A$ (which belongs to the closure of $A$ ), it should also hit $A$ in arbitrarily small time $\epsilon>0$ . Does my argument make sense? If #1 is correct, then the follow-up question is: under what condition on $\mu(\cdot)$ and $\sigma(\cdot)$ an Ito diffusion $X$ has this property? As a canonical example, does a Brownian motion with drift ( $\mu(\cdot)=\mu$ and $\sigma(\cdot)=\sigma$ ) have this property? Any idea or suggestion for the reference would be really appreciated!","['stochastic-processes', 'stopping-times', 'brownian-motion', 'probability-theory']"
3251311,Does this limit exist or is undefined?,"$$\lim_{x\to -\infty}\ln\left(\frac{x^2+1}{x-3}\right)=\infty$$ This is the answer I get from wolfram alpha, but shouldn't the answer be the limit doesn't exist? For large negative values of x, we can ignore the +1 and -3 so we can change the limit to $$\lim_{x\to -\infty}\ln\left(\frac{x^2}{x}\right)$$ As x approaches - $\infty$ , $\left(\frac{x^2}{x}\right)$ also approaches - $\infty$ so we get $\ln\left(-\infty\right)$ . However, $\ln\left(-\infty\right)$ doesn't make sense because ln(x) isn't even defined for negative numbers. So, the limit doesn't exist and is therefore undefined. Am I wrong?","['limits', 'calculus']"
3251351,Local properties of rings,"Let $R$ be a ring or more genrally a $R$ -module $M$ . My question is what is the intuition behind or more precisely when following argumentation is applicable: Let $\mathcal{P}$ be a ring theoretical property then $R$ has $\mathcal{P}$ if and only if ALL localisations $R_m$ with respect to the maximal ideals $m$ of $R$ have property $\mathcal{P}$ What is the deeper nature of the properties $\mathcal{P}$ which are compatible with the argumentation technique described above? Taking into account the theory of schemes one can simply say that this concerns ""local"" properties. Is there any intuition to recognize when such property has local nature?","['algebraic-geometry', 'abstract-algebra', 'commutative-algebra']"
3251360,Showing that $a_{n+1}=\frac{n}{a_n}-a_n-a_{n-1}$ with $a_0 = 0$ and $a_1=2\Gamma(\frac34)\big/\Gamma(\frac14)$ stays positive for $n\geq1$.,"This posting consists of several mildly-related questions, motivated from this posting . The main object is the following sequence. $$a_0 = 0, \qquad a_1 = x, \qquad a_{n+1} = \frac{n}{a_n} - a_n - a_{n-1}. \tag{*}$$ Question 1. Numerical experiment suggests that there is a unique value of $x$ for which $a_n > 0$ for all $n \geq 1$ . Can we prove/disprove this? If we write $I_n = \{ x \in \mathbb{R} : a_1 > 0, \cdots, a_n > 0\}$ , then obviously $I_n$ is a nested sequence of open sets that begins with $I_1 = (0, \infty)$ . Moreover, the experiment suggests that $I_n$ are all intervals, and the endpoints of $I_n$ are adjacent poles of $a_{n+1}$ and $a_{n+1}$ is strictly monotone on $I_n$ . Provided this is correct, we easily see that there is a unique zero of $a_{n+1}$ on $I_{n+1}$ , which then determines $I_{n+1}$ . Question 2. The same experiment also suggests that the value of such unique $x$ is $$ \frac{\operatorname{AGM}(1,\sqrt{2})}{\sqrt{\pi}}
= \frac{2\Gamma\left(\frac{3}{4}\right)}{\Gamma\left(\frac{1}{4}\right)}
\approx 0.675978240067284728995\cdots.$$ At this point, I completely have no idea why this value arises, but I have checked that this is correct up to hundreds of digits. (I progressively refined the range of $x$ so that $a_n$ stays positive for a longer time.) Again, will it ever have a chance to be proved? My original suspicion was that we may rearrange the recurrence relation to obtain continued fraction, but it was of no avail. To be honest, I have never seen this type of problem, and will be glad if I can learn anything new about it. Question 3. Given that the above question seems to bold to answer, perhaps we may consider its variants: (Variant 1) $a_0 = 0$ , $a_1 = x$ , and $a_{n+1} = \frac{n}{a_n} - a_n - p a_{n-1}$ , where $p \in \mathbb{R}$ . (Variant 2) $a_0 = 0$ , $a_1 = x$ , and $a_{n+1} = \frac{1}{a_n} - a_n - a_{n-1}$ . (Variant 3) $a_0 = 0$ , $a_1 = x$ , and $a_{n+1} = \frac{n^2}{a_n} - a_n - a_{n-1}$ . Again, in each case, numerical experiment suggests that there is a unique $x$ for which $(a_n)_{n\geq 1}$ stays positive. Moreover, For Variant 1, it seems that $x = 1/\sqrt{3}$ for $p = -2$ but I have no guess for general $p$ , even when it is an integer. For Variant 2, it is conjectured that $x = 4/3\sqrt{3}$ . For Variant 3, we can check that $x = 1/\sqrt{3}$ is such one. Indeed, we find that $a_n = n/\sqrt{3}$ solves the recurrence relation. Then we may ask whether the version of Question 1-2 can be proved for these variants. Progress. I managed to answer Question 1 . Check this answer .","['analysis', 'sequences-and-series']"
3251408,Applying Graph Theory to Linear Algebra (not the other way around),"I know about applications of Linear Algebra to Graph Theory, I find them boring. What interests me is whether one can draw graph-like pictures of linear functions to understand them better. Do you know of any results like that? I have one particular question I would like to know the answer to: Let $f : V \rightarrow V$ be a linear function and $b_1,...,b_n \in V$ a basis of $V$ . Also for every $v \in V$ define $v_1,...,v_n$ so that $v_1 b_1 + ... + v_n b_n = v$ .
Finally let $G = (B,E)$ be the graph with $B = \{b_1,...,b_n\}$ and $E = \{ (b_i, b_j) \text{ with weight } f(b_i)_j \mid i,j \in \{1,...,n\} \}$ .
In words: draw a circle for every basis element and connect them so that you can see how $f$ maps the basis elements to each other. Now delete all weights that are zero and assume the other weights are positive. Can we say something like: There is a cycle in $G$ if and only if $f$ has an eigenvector? To me that sounds like the Perron–Frobenius theorem . I'm also wondering if one could prove the existence of Jordan-Normal-Forms using graphs like this. (generalized eigenvectors are then maybe cycles connected by a tree) In general I feel like there should be a graph-theoretic perspective on the (basic) concepts I've seen in linear algebra. What do you think?","['graph-theory', 'linear-algebra']"
3251425,Let $\{a_n\}$ be a sequence of positive real numbers such that $\sum_{n=1}^\infty a_n$ is divergent. Which of the following series are convergent?,"Let $\{a_n\}$ be a sequence of positive real numbers such that $\sum_{n=1}^\infty a_n$ is
divergent. Which of the following series are convergent? a. $\sum_{n=1}^\infty \frac{a_n}{1+a_n}$ b. $\sum_{n=1}^\infty \frac{a_n}{1+n a_n}$ c. $\sum_{n=1}^\infty \frac{a_n}{1+ n^2a_n}$ My Solution:- (a)Taking $a_n=n$ , then $\sum_{n=1}^\infty \frac{n}{1+n}$ diverges. (b) Taking $a_n=n$ , $\sum_{n=1}^\infty \frac{n}{1+n^2}$ diverges using limit comparison test with $\sum_{n=1}^\infty \frac{1}{n}$ (c) $\frac{a_n}{1+n^2a_n}\leq \frac{a_n}{n^2a_n}=\frac{1}{n^2} $ . Using comparison test. Series converges. I am not able to conclude for general case for (a) and (b)?",['sequences-and-series']
3251436,Why this function is not integrable,"I have a question as I look at the example 8.9(a) in Rudin's Real and Complex Analysis : Let $X$ and $Y$ be the closed unit interval $[0,1]$ , let $\{\delta_n\}$ be an increasing sequence of distinct points in $[0,1]$ that converges to $1$ , and to each positive integer $n$ , let $g_n$ be a real continuous function on $[0,1]$ with support in $(\delta_n,\delta_{n+1})$ , and such that $\int_{0}^{1} g_n(t)~dt=1$ . Define $f$ over $X\times Y$ as follows: $$
f(x,y):=\sum_{n=1}^\infty[g_n(x)-g_{n+1}(x)]g_n(y).
$$ It is easy to check that the Fubini Theorem does not apply for $f(x,y)$ . And the book says that this is because the function of $f(x,y)$ is not integrable, i.e. $$\int_0^1\,dx\int_0^1|f(x,y)|\,dy=\infty$$ But I could not easily see why it is not integrable.","['integration', 'calculus', 'fubini-tonelli-theorems', 'real-analysis']"
3251491,A limit of a power series,"I was trying to make some undergraduate level analysis problem. The point was interval of convergence of power series. It seems that the students are bored with usual coefficients. So I considered the following 'relatively' new kind of power series. $$ f(x) = \sum_{n=1}^\infty \left( 1-\frac{1}{n}\right)^{n^2} x^n $$ The question I proposed is to find the interval of convergence of $f(x)$ .
Soon after, I realized using this series I can make rather interesting questions. Prove that $\lim_{x \rightarrow e^-} f(x) = \infty$ and find the limit $\lim_{x \rightarrow -e^+} f(x)$ . I think this maybe an  interesting question for undergraduate students. However I have failed to make a reasonable solution. Please help me to improve this questions.","['power-series', 'limits', 'calculus', 'real-analysis']"
3251597,What is a Borel set?,"I am reading DeGroot's book titled 'Optimal Statistical Decisions' in which he says the following: If $S$ is the $n$ -dimensional space $\mathbb{R}^n$ , then the $\sigma$ -field will be taken to be the $\sigma$ -field of Borel sets, i.e. , the smallest $\sigma$ -field containing all $n$ -dimensional intervals. and If the function $g$ is measurable with respect to a $\sigma$ -field and $B$ is any Borel set on the real line, then the subset $g^{-1}(B)$ of $S$ , defined by the relation $g^{-1}(B)=\{s:g(s)\in B\}$ , also belongs to the $\sigma$ -field. I have no prior exposure to measure theory and topology, hence I find these two statements difficult to comprehend. However, I do understand what a $\sigma$ -field is and the three properties that a collection of subsets of sample space $S$ must fulfill in order to become a $\sigma$ -field. I hope someone can provide a simple and concise explanation of what a Borel set is, so that I can develop a deeper understanding of these two statements above. I only want to learn from a probabilistic standpoint right now and would appreciate it if the explanation would leave out measure theory and topology altogether. Thanks.","['borel-sets', 'measure-theory', 'probability']"
3251604,Proving that $\sum_{k=0}^{n}\frac{(-1)^k}{{n\choose k}}=[1+(-1)^n] \frac{n+1}{n+2}.$,"Various examinations ask students to prove that $$\frac{1}{{n \choose k}}=(n+1) \int_{0}^{1} x^k (1-x)^{n-k} dx ~~~~~(1)$$ by evaluating  the integral $\int_{0}^{1}
(tx+1-x)^n~dt$ two ways. When I came across (1), I could prove that $$\sum_{k=0}^{n}\frac{(-1)^k}{{n\choose k}}=[1+(-1)^n] \frac{n+1}{n+2}.~~~~(2)$$ as below: $$S_n=\frac{1}{n+1}\sum_{k=0}^{n}\frac{(-1)^k}{{n\choose k}}=\int_{0}^1 \sum_{k=0}^{n} (-1)^k  x^k (1-x)^{n-k} dx =  \int_{0}^{1}  (1-x)^n \sum_{k=0}^{n}\left(\frac{-x}{1-x} \right)^k dx =\int_{0}^{1}(1-x)^n \frac{ \left( \frac{-x}{1-x}\right)^{n+1}-1}{\left(\frac{-x}{1-x}\right)-1}dx$$ $$=\int_{0}^{1}[(1-x)^{n+1}-(-x)^{n+1}] dx =\frac{1+(-1)^n}{n+2}.~~~~(3)$$ Therefore, $$S_{2m+1}=0 ~~~~(4) ~~~ \mbox{and}~~~ S_{2m}= \frac{2m+1}{m+1}.~~~~(5)$$ Now the question is: Can one prove (2) in some other way(s)?","['binomial-coefficients', 'definite-integrals', 'sequences-and-series']"
3251616,Show the matrix commutes with companion matrix is a polynomial,"Let $A$ be a linear transform on $n$ -dimensional $V$ over a field $F$ . Under a basis $\alpha_1, \cdots, \alpha_n$ , the matrix representation of $A$ is as follows: $$A = \begin{bmatrix}
0 & 0 & \dots & 0 & -a_0 \\
1 & 0 & \dots & 0 & -a_1 \\
0 & 1 & \dots & 0 & -a_2 \\
\vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & \dots & 1 & -a_{n-1}
\end{bmatrix}.$$ Let $C(A):= \{T: T\text{ is a linear transform on $V$ and } TA = AT \}$ , and let $F[A]$ denotes all the polynomials in $A$ . Show that: $$C(A) = F[A]; \dim(C(A)) = n.$$ First of all, the minimal polynomial $m(\lambda)$ of $A$ is the same as its characteristic polynomial $f(\lambda)$ , namely $m(\lambda) = f(\lambda) = \lambda^n + a_{n-1}\lambda^{n-1} + \cdots a_0$ . Thus, plugging in $A$ , we see that all $A^{k}$ with $k \geq n$ could be expressed by $I, A, A^2, \cdots, A^{n-1}$ . So $\dim F[A] \leq n$ . If $\dim F[A] < n$ , say $k_0 I + k_1 A + \cdots + k_r A^r = 0$ with $r < n$ and some $k_j \neq 0$ , then we have that $g(\lambda) = k_0 + k_1 \lambda + \cdots + k_r \lambda^r$ is another polynomial with $g(A) = 0$ . By the definition of minimal polynomial, we must have that $r \geq n$ , a contradiction. So $\dim(F[A]) = n$ , and it remains to show the first equality $C(A) = F[A]$ . Also, one could see that $F[A] \subseteq C(A)$ . But I am not sure how to show the other direction. Could someone give me a hint?","['matrices', 'minimal-polynomials', 'linear-algebra', 'companion-matrices']"
3251623,"Given $f(x) = x \sin\frac1x$, find roots of $f'(x)$ in the interval $0\le x \le \frac 1{\pi}$.","This question is taken from book: Advanced Calculus: An Introduction to Classical Analysis, by Louis Brand. The book is concerned with introductory analysis. If $f(x) = x \sin\frac1x\;(x\ne 0), f(0) = 0$ , does Rolle's theorem guarantee a root of $f'(x)$ in the interval $0\le x \le \frac 1{\pi}$ ? Show that $f'(x)$ has an infinite number of roots $x_l \gt x_2 \gt x_3\gt \cdots$ in the given interval which may be put in one-to-one correspondence with the roots of $\tan y = y\,$ in the interval $\pi \le y \lt \infty$ . Calculate $x_1$ to three decimal places. Given $f(x) = x \sin\frac1x(x\ne 0), f(0) = 0$ . At $x=0, f(0) = 0 \sin(\infty)$ , but $\sin(\infty)\in[-1,1]$ , which means the range corresponding to $x=0$ is undefined. But, the value of $f(0)$ is stated to be $0$ . This is a point of confusion as how this range point is specified. Also at $x =\frac 1{\pi}$ , the fn. yields $f(x) = \frac 1{\pi} \sin(\pi) =0.$ So, $f(0)= f\left(\frac 1{\pi}\right) = 0$ . Rolle's theorem needs three conditions: Let $f(x)$ be continuous on a closed interval $[a, b]$ , and, $f(x)$ be differentiable on the open interval $(a, b)$ . If $f(a) = f(b)$ , then there is at least one point $c$ in $(a, b)$ where $f'(c) = 0$ . By being a product of polynomial & a trigonometric function, both of which are differentiable & continuous, the product too is. Hence, all three conditions are satisfied. So, root of $f'(x)$ is guaranteed in the given interval $\big[0,\frac{1}{\pi}\big]$ . First need calculate $x_1$ , so find $f'(x)$ . It is given by $\sin\left(\frac 1x\right)-\frac 1x \cos \left(\frac 1x\right)$ . $f'(x)=0\implies x\sin\left(\frac 1x\right)=\cos \left(\frac 1x\right)\implies x=\cot\left(\frac 1x\right)$ . Unable to solve further. I hope that the solution of the above equation can help with the rest two questions, although have doubts for each as stated below: $f'(x)$ has an infinite number of roots $x_l \gt x_2 \gt x_3\gt \cdots$ in the interval $0 \le x \le \frac 1{\pi}$ . Unable to understand how it is possible to have the given scenario of infinite roots in a given order. These roots may be put in one-to-one correspondence with the roots of $\tan y = y\,$ in the interval $\pi \le y \lt \infty$ . Here, the two equations whose roots are to be paired are: $x = \cot\left(\frac 1x\right)$ and $ y = \tan(y)$ with connection not visible. Edit The book states the answer for $x_1=0.2225$ . Still have no clue about attaining it.","['trigonometry', 'rolles-theorem']"
3251627,Two challenging sums $\sum_{n=1}^\infty\frac{(-1)^nH_n^{(2)}}{n^3}$ and $\sum_{n=1}^\infty\frac{(-1)^nH_n^2}{n^3}$,"where $H_n$ is the harmonic number and can be defined as: $H_n=1+\frac12+\frac13+...+\frac1n$ $H_n^{(2)}=1+\frac1{2^2}+\frac1{3^2}+...+\frac1{n^2}$ again, my goal of posting these two challenging sums is to use them as a reference. I will provide my solutions soon. I would like to mention that these two sums can also be found in Cornel's book "" almost impossible integrals, sums, and series"".","['integration', 'real-analysis', 'harmonic-numbers', 'calculus', 'sequences-and-series']"
3251643,Second fundamental form for Lie group $SO(n)$,"I'm given $\mathbb{R}^{n^2} = \mathbb{R}^{n \times n}$ with the usual metric $\langle A, B \rangle = \text{Trace} (AB^T) = \text{Trace} (A^T B)$ . Then $SO(n)$ is a submanifold of $\mathbb{R}^{n^2}$ of dimension $\frac{1}{2} n (n-1)$ . I have shown that the tangent space $T_{I} SO(n)$ consists of all skew-symmetric matrices with zero trace. I wish to show that the normal space $N_I SO(n)$ consists of symmetric matrices. Furthermore, I need to calculate the second fundamental form tensor for $SO(n)$ . I'm given $X$ and $Y$ left-invariant vector fields determined by skew-symmetric matrices at the identity. If $O$ is an arbitrary orthogonal matrix, then $X(O) = OA $ and $Y(O) = OB$ . I need to prove that $$D_Y X(O) = \frac{1}{2} O [B, A] + \frac{1}{2} O (BA + AB) $$ and to find expressions for $\nabla_Y X$ , $h(X,Y)$ and $[X, Y]$ . Here $\nabla_X Y$ denotes the covariant derivative on $SO(n)$ , while $D_X Y$ denotes the covariant derivative on $\mathbb{R}^{n^2}$ . Also, $h(X,Y)$ denotes the second fundamental form tensor. Attempt: I know that $D_X Y = \nabla_X Y + h(X,Y)$ is the Gauss formula. On $\mathbb{R}^{n^2}$ , I have $$ D_Y X (O) = D_{Y(O)} X = Y(O) X. $$ To calculate the latter, we take a curve through $O$ with tangent vector $Y(O) = OB$ . Such a curve is $O \exp(Bt)$ . Then $$ Y(O) X = \frac{d}{dt}_{t = 0} X (O \exp (Bt)) = OBA. $$ How can I prove that $$ 2 h(X,Y) = D_X Y + D_Y X $$ ? This would give me that $$h(X,Y) (O) = \frac{1}{2} O (AB + BA). $$ Also, I'm not sure how to calculate $\nabla_Y X$ .","['riemannian-geometry', 'lie-groups', 'differential-geometry']"
3251647,Tricky limit as $n$ tends to infinity of an expression involving a bunch of roots,"In this question , @user513057 asked how to prove that for $n$ large enough, $$
(n+1)\cdot ((n+1)!)^{\frac{1}{n+1}} -n\cdot (n!)^\frac{1}{n}< n+1
$$ In the answer by @Von Neumann, the latter rewrote this inequality as $$
[2 \pi (n+1)]^{1/(2(n+1))}\frac{n+1}{e} - \frac{n^2}{e(n+1)}(2\pi n)^{\frac1{2n}} < 1
$$ Then he argued, that one can replace $n+1$ by $n$ if $n$ is large enough. I don't see how to formally justify this though. In order to do this, I would like to determine the limit $$
\lim_{x\to\infty} [2 \pi (x+1)]^{1/(2(x+1))}\frac{x+1}{e} - \frac{x^2}{e(x+1)}(2\pi x)^{\frac{1}{2x}}.
$$ Wolfram Alpha says that this limit equals $\frac2e$ . I don't see any way of proving this though. I tried computing the derivative of the above function in order to show that it is decreasing, but that didn't lead to any results. I also tried computing the difference of the $n+1$ -st and the $n$ -th term, but that didn't work either. EDIT: This is equivalent to proving that $$
\lim_{x\to\infty} \frac1x\left((x+1)\cdot\frac{x+1}e\cdot \sqrt[2(x+1)]{2\pi(x+1)}-x\cdot\frac{x}e\cdot \sqrt[2x]{2\pi x}\right)=\frac2e
$$ or equivalently that $$
\lim_{x\to\infty} \frac1x\left((x+1)^2\cdot \sqrt[2(x+1)]{2\pi(x+1)}-x^2\cdot \sqrt[2x]{2\pi x}\right)=2
$$ or rewritten again that $$
\lim_{x\to\infty} \frac{(x+1)^2}x\cdot \sqrt[2(x+1)]{2\pi(x+1)}-x\cdot \sqrt[2x]{2\pi x}=2
$$ Wolfram Alpha query for the last limit . EDIT 2:
  Using l'Hospital, one could also prove that \begin{multline}
\frac12 (4x-\ln(2\pi (x+1))+5) (2\pi (x+1))^{1/(2 x+2)}\\-2 (2\pi x)^{1/(2x)}(x-(1/4)\ln(2\pi x)+\frac14)
\end{multline} converges to $2$ . Third Wolfram Alpha query","['limits', 'calculus', 'sequences-and-series', 'real-analysis']"
3251664,"What is the difference between ""arbitrarily close"" and ""sufficiently close"" in term of limits?","The definition of limit as always “the limit of $f(x)$ , as $x$ approaches $a$ , equals $L$ ” means we can
  make the values of $f(x)$ arbitrarily close to $L$ by restricting x to
  be sufficiently close to $a$ but not equal to $a$ . What exactly mean by phrases ""arbitrarily close"" for $f(x)$ and ""sufficiently close"" for $x$ ? Are they interchangeable ?","['limits', 'calculus', 'terminology']"
3251685,Problem in convex analysis : Easy or hard one?,"I hope your day is going well. This is a problem, I don't know how to solve it since 1 week. It's going to be a relief and a pleasure to get your help. Problem : Let $X = \{x_{1},\ldots,x_{N+M} \}$ such as $\{x_{1},\ldots,x_{N} \} \subset  \Omega := \text{int}( \text{conv} ( \{x_{N+1},\ldots,x_{N+M} \} )  )$ a convex polygon with $ \text{conv} $ the convex hull. Let $u \in R^{X}$ such as $u(x_{N+i}) = 0$ ( $u=0$ on the edge) and $\tilde{u}^{**}(x_{i}) = u(x_{i})$ ( $u$ is its convex conjugate on $X$ ). Here's some explications and definitions : Let $\tilde{u}$ which is $u(x_{i})$ when $x_{i} \in X$ and $+\infty$ otherwise. 
Its convex conjugate is $\tilde{u}^{*}(x) = \sup_{y \in \mathbb{R}^{n}} \{ \langle x,y \rangle - \tilde{u}(x)\} = \max_{x \in X} \{ \langle x,y \rangle - \tilde{u}(x) \}$ .
Then I take the convex conjugate once again, I called it $v$ . Question : Show $v=0$ on the edge $\partial{\Omega}$ I think we can use that $v$ is the supremum of affine function $\varphi$ such as $\varphi \le \tilde{u}$ .
Which can be written : If $\Sigma = \{(p,r) ; \forall y \in \mathbb{R}^{n}, \langle p,y \rangle + r \le \tilde{u}(y) \}$ we have : \begin{align*}
    \sup\{ \langle p,y \rangle + r ; (p,r) \in \Sigma \}   =  v(y)
\end{align*} I wish you a very good day.","['convex-hulls', 'convex-optimization', 'convex-geometry', 'real-analysis', 'convex-analysis']"
3251705,"If $f$ is holomorphic in $\{|z|<1\}$ \ $\{0\}$ and doesn't get values in $(-\infty ,0]$ then $0$ is a removable singular point [duplicate]","This question already has an answer here : $f$ holomorphic on $D\setminus \{0\}$ and takes no values in $(-\infty,0],$ then $0$ removable (1 answer) Closed 5 years ago . Let $f$ b a holomorphic in $\{|z|<1\}$ \ $\{0\}$ . I want to show that if $f$ doesn't get values in $(-\infty ,0]$ then $0$ is a removable singular point. I am not sure where to start, but since $f$ is never equal to $0$ then I can probably work with $\frac{1}{f}$ which is also holomorphic in the same domain. From Riemann's theorem, I know that if $f$ is bounded in a neighborhood of $0$ then it is a removable singular point. However I don't think it gets me anywhere here. Help would be appreciated","['complex-analysis', 'singularity']"
3251727,Proof that 1-P(B|C)=P(~B|C). Is everything correct?,"Proof: Suppose we have a set of students. Different students study different subjects, with some of them studing several subjects at once. Suppose among many other subjects we have Biology and Chemistry. Then $P(B|C)$ would be probability of selecting a Biology student out of set of Chemistry students. Now we need to ask ourselves: what would be the complement of event ""selecting a Biology student out of set of Chemistry students""?. Remember that we select a Biology student out of set of Chemistry students, NOT from all students. In other words, our sample space shrunk to the size of the set of Chemistry students. The complement event would be selecting a Chemistry student who does NOT study Biology (although the person can study other subjects along with Chemistry). The probability of selecting such person out of set of Chemistry students can be written as $P(\tilde B|C)$ . Thus $1-P(B|C)=P(\tilde B|C)$ because $P(B|C)$ and $P(\tilde B|C)$ are complements of each other.","['conditional-probability', 'proof-verification', 'probability']"
3251777,Luxemburg norm as argument of Young's function: $\Phi\left(\lVert f \rVert_{L^{\Phi}}\right)$,"Let $\Phi$ be a Youngs's function , i.e. $$ \Phi(t) = \int_0^t \varphi(s) \,\mathrm d s$$ for some $\varphi$ satifying $\varphi:[0,\infty)\to[0,\infty]$ is increasing $\varphi$ is lower semi continuous $\varphi(0) = 0$ $\varphi$ is neither identically zero nor identically infinite and define the Luxemburg norm of $f:\Omega\to\mathbb{R}$ as $$ \lVert f \rVert_{L^{\Phi}} := \inf \left\{\gamma\,\middle|\,\gamma>0,\,\int_{\Omega} \Phi\left(\frac {\lvert f(x)\rvert}{\gamma} \right)\,\mathrm{d}x\leq 1\right\}.$$ Question : What can we say about $\Phi\left(\lVert f \rVert_{L^{\Phi}}\right)$ ? In particular, I'd like to know, if $$\Phi\left(\lVert f \rVert_{L^{\Phi}}\right) \leq C \int_{\Omega}\Phi(\lvert f(x)\rvert) \,\mathrm d x$$ holds for some $C$ independent of $f$ . Any idea or hint for a reference is welcome! Notes : The above inequality trivially holds for $\Phi(t) = t^p$ , where $p>1$ Maybe it's appropriate to consider this question in the more general framework of Musielak-Orlicz spaces. However, e.g. in Lebesgue and Sobolev Spaces with Variable Exponents I was unable to find an appropriate result. Since there has been no response yet, I also asked the question on MathOverflow .","['banach-spaces', 'functional-analysis', 'orlicz-spaces']"
3251788,Number of $5$ full connected directed graphs,"Find number of full connected directed graphs where $|V|=5$ (directed $K_5$ ) solution According to OEIS there are $42$ graphs like that. Let say that we have graph $G$ and we want to find how many there are graphs which are non isomorphic to it and has the same build (I mean directions of edges between given nodes). I want to use Polya theorem. We have $5$ rotations due to normal rotate and $2$ rotation due to mirror reflection. So we can treat that as operation with group $$ \mathbb Z_2 \times \mathbb Z_5 \mbox{ a it has $10$ elements } $$ Ok. So let look at cycles: identity - $5$ cycles of size $1$ : $x_1^5$ rotate one right - $1$ cycle of size $5$ : $x_5$ rotate two right - $1$ cycle of size $5$ : $x_5$ rotate four right - $1$ cycle of size $5$ : $x_5$ rotate five right - $1$ cycle of size $5$ : $x_5$ and the same system when we do mirror reflection Ok so our cyclic index is $$I(x_1,x_2,x_3,x_4,x_5) = \frac{2}{10}(x_1^5 + 4x_5) = \frac{1}{5}(x_1^5 + 4x_5) $$ I want to use $1$ color so $I(1,1,1,1,1) = 1$ . So for given system of direction I have exactly $1$ non isomorphic graph. It means that only what we have to do is count all combinations of directions. So result is $$ 2^{\binom{5}{2}} = 2^{10} = 1024 \neq 42$$ Where I failed...?","['graph-theory', 'polya-counting-theory', 'combinatorics', 'discrete-mathematics']"
3251806,Similarity between Axiomatic Set Theory and Modern Algebra,"Continuum Hypothesis(CH) is independent of ZFC Axioms, which means there exist models of ZFC where CH is true, and models where CH is false. Can I say something similar for groups? Something like the following: The statement $\forall a\forall b[a,b\in G\Rightarrow ab=ba]$ (i.e. any two elements commute) is independent of the axioms of a group because there are examples of groups where this is true (Abelian groups), and groups where this is false. By ""axioms of a group"", I mean things we have in the definition of a group (associativity, the existence of an identity, etc). A group is a set, so set theory axioms are included here as well. Can I say $\forall a\forall b[ab=ba]$ is independent of group axioms, and can I refer to an example of a group (e.g. $\mathbb Z_n$ ) a model of group axioms? This might be a strange question, but it is important. The meaning of ""independence of CH"" and the concept of Model is very difficult for a learner to understand; the fact that a group can be either Abelian or not can be easily understood. So are they really the same thing according to my interpretation above? If they are not exactly the same, then how are they different? PS: there are a lot of cross-overs between set theory and Algebra. For example, boolean algebra. I do find some very general discussion on the topic, for example here , but none of them go into such details.","['group-theory', 'abstract-algebra', 'model-theory']"
3251843,How to plot a phase space,"I was trying to study the function $x(t)=\int_0^t e^{-s^2}ds$ , which I did successfully using high school maths. After that, I decided that I wanted to try to study it using some multivariable calculus, but couldn't really do it, so I'm asking for the proper way to face this: the problem is equivalent to the ODE $x'(t)=e^{-t^2}$ given some initial value. Let $y(t)=t$ and therefore $y'(t)=1$ . Now I want to study the phase space of the system $\begin{cases} x'=e^{-y^2}\\ y'=1 \end{cases}$ . How can I do it? There are no equilibrium points and the Jacobian's only eigenvalue is $0$ . Also, the linearized system is $\begin{cases}x'=(-2y_0e^{-y_0^2})\cdot y \\ y'=0\end{cases}\;$ which makes no sense since in $(0, 0)$ it gives $x'=0, y'=0$ whereas in the original one it is $x'=1, y'= 1$ . What's the proper way to study this system?","['multivariable-calculus', 'ordinary-differential-equations', 'dynamical-systems']"
3251846,The difference between Orthonormal Basis and the Standard Basis,"I am pretty confused about the relation and the difference between these two concepts.
At first glance, when I hear: Orthonormal basis I instantly relates it to the standard basis - but I'm not sure about this relation. Firstly, if these two concepts were the same - why have they got different names?
Secondly, I have a sneaking suspicion that these are fundamentally different concepts - where one is mentioned when we concern about an inner product space and the other one (standard basis) is relevant when we represent column vectors over a field. Nevertheless, I have no satisfying explanation to myself about what is the intrinsic difference between the both concepts. So, can someone clarify this intrinsic difference between the concepts?","['inner-products', 'linear-algebra', 'orthogonality']"
3251868,"About $\log (1 + x)$ on p.427 ""Calculus 4th Edtion"" by Michael Spivak","I am reading ""Calculus 4th Edtion"" by Michael Spivak. On p.427 he wrote as follows: From the calculations on page 413, we see that for $x \geq 0$ we have $$\log(1+x)=x-\frac{x^2}{2}+\frac{x^3}{3}-\frac{x^4}{4}+\cdots+\frac{(-1)^{n-1}x^n}{n}+\frac{(-1)^n}{n+1}t^{n+1}$$ where $$\left \vert {\frac{(-1)^n}{n+1} t^{n+1}}\right\vert \leq \frac{x^{n+1}}{n+1}$$ and there is a slightly more complicated estimate when $-1 < x < 0$ (Problem 16). I guess $t \in (0, x)$ if $x > 0$ and $t = 0$ if $x = 0$ . Does the above equality really hold? I guess Spivak applied Taylor's theorem(p.424, Lagrange form of the remainder) incorrectly to $\log(1 + x)$ .","['logarithms', 'proof-explanation', 'analysis', 'calculus', 'taylor-expansion']"
3251882,How to complete a primitive vector to a unimodular matrix,"I would like to understand the following relation between unimodular matrices and its columns in some sense: if $x$ is a primitive vector (that is to say an integer column of $n$ rows whose entries are coprime), then it can be completed to an $n\times n$ unimodular matrix. In the case of $2 \times 2$ matrices, I can see that it is equivalent to a Bezout relation, but is there a generalisation of this proof to show this property for all $n$ ?","['matrices', 'gcd-and-lcm']"
3251921,Grazing area for a goat around a circle.,"I am doing this math question and i am really confused on how to approach it. This is the question: A retired mathematics professor has decided to raise a goat. He owns a silo and a barn. The barns front wall is tangent to the silo at the corner. The silo has a circular base with a radius of 10 feet. The professor has decided to tether the goat to a chain that is anchored at the corner of the barn, the point of tangency. He has also cut the chain so that it is long enough to wrap around the silo exactly once- that is, the length of the chain equals the circumference of the silo. The barn length is longer than the chain. This is an image of the barn (square), the silo (circle) and the goat's grazing area. The answer I got is -4762.48876, but area is positive, so i made it 4762.48876. These are the steps i took to getting the answer I have: $$x(\phi)= -R\sin\phi + \phi R\cos\phi, \qquad y(\phi) = R-R\cos\phi - \phi R\sin\phi$$","['integration', 'calculus', 'area']"
3252039,An optimal procedure for vertex elimination in a graph,"Figure: An example of my problem Hi everyone. I'm struggling with a problem, and I really appreciate any hint.
I have attached picture of an example where vertex 1 and 2 are connected to multiple vertices (green circles and blue squares). I want to gradually eliminate some of these blue and green vertices such that the number of edges connected to vertex 1 or 2 does not exceed 4. Also, my objective is doing this with the minimum number of eliminations. So, let's define it mathematically. If $d_B$ and $d_G$ respectively denote the number of remaining blue squares and green circles after elimination, and also if $d_i$ denotes the connected edges to vertex $i$ after elimination,  my problem is how to organize an optimal elimination procedure such that it maximizes $min(d_B,d_G)$ while it satisfies $d_i\leq4$ for $i=1,2$ .","['coloring', 'graph-theory', 'matrices', 'algorithms', 'optimization']"
3252055,Alternate way of computing the probability of being dealt a 13 card hand with 3 kings given that you have been dealt 2 kings,"We are dealt 13 cards from a standard 52 card deck.  If $A$ is the event where we are dealt at least two kings and $B$ is the event where we are dealt at least 3 kings, we want to know $P(B|A)$ .  I believe the correct way to do this is to calculate the probability of being dealt a hand with each number of kings separately as follows: $\displaystyle \frac{{4 \choose 3}{48 \choose 10} + {4 \choose 4}{48 \choose 9}}{{4 \choose 2}{48 \choose 11} + {4 \choose 3}{48 \choose 10} + {4 \choose 4}{48 \choose 9}} \approx .17$ . However, it also makes sense to me that if we know we have been dealt 2 kings, it doesn't matter where in our hand they are, the $P(B|A)$ should be the same as the probability of getting dealt either 1 or 2 kings in an 11 card hand from a 50 card deck with two kings in it as follows: $\displaystyle \frac{{2 \choose 1}{48 \choose 10} + {2 \choose 2}{48 \choose 9}}{{50 \choose 11}} \approx .4$ (Or compute $1-p$ , where $p$ is the probability of getting no kings in an 11 card hand from a deck with 50 cards and only 2 kings.) What is the issue with my logic here?","['conditional-probability', 'probability']"
3252072,Double Integration Problem $\int_{0}^{1} \int_0^1 \frac{1}{1+y(x^2-x)}dydx$,"Compute $$I = \int_{0}^{1} \int_0^1 \frac{1}{1+y(x^2-x)}dydx$$ Here are my steps: $$\begin{split}
I &=\int_{0}^{1} \left(\int_0^1 \frac{dy}{1+y(x^2-x)}\right)dx\\
  &=\int_{0}^{1} \left[\frac{\ln(1+y(x^2-x))}{x^2-x}\right]_0^1dx\\
  &=\int_{0}^{1} \left[\frac{\ln(1+(1)(x^2-x))}{x^2-x}
                      -\frac{\ln(1+(0)(x^2-x))}{x^2-x}\right]dx\\
  &=\int_{0}^{1} \frac{\ln(1+x^2-x)}{x^2-x}dx
\end{split}
$$ And here I can't find any substitution to solve this integral. Can anyone help me? By the way, I also used Simpson's 3/8 method to find the approximation and got $1.063$ . But I want to find it using Calculus.","['integration', 'calculus', 'definite-integrals']"
3252076,What is $\mathbb{Q}_3(\sqrt{-6})^{\times}/\left(\mathbb{Q}_3(\sqrt{-6})^{\times}\right)^3$?,"I'm doing some Galois cohomology stuff (specifically, trying to calculate $H^1(\mathbb{Q}_3,E[\varphi])$ , where $\varphi:E\to E'$ is an isogeny of elliptic curves), and it involves calculating $\mathbb{Q}_3(\sqrt{-6})^{\times}/(\mathbb{Q}_3(\sqrt{-6})^{\times})^3$ . Here's what I've done so far. Let $K=\mathbb{Q}(\sqrt{-6})$ . As $-6\not\equiv 1$ (mod 4), we have that $\mathcal{O}_K=\mathbb{Z}[\sqrt{-6}]$ . Let $v$ be the finite place of $K$ corresponding to the (non-principal) prime ideal $(3,\sqrt{-6})$ . It's fairly easy to see that $K_v=\mathbb{Q}_3(\sqrt{-6})$ , and that the residue field is $k_v\cong\mathcal{O}_{K}/(3,\sqrt{-6})\cong\mathbb{F}_3$ .  Now, by Hensel's lemma, $\sqrt{-2}\in\mathbb{Q}_3$ , so it follows that $\sqrt{3}\in\mathbb{Q}_2(\sqrt{-6})$ . In $\mathcal{O}_K$ , $(3)$ decomposes as $(3,\sqrt{-6})^2$ , so $v(3)=2$ , and hence $v(\sqrt{3})=1$ . So we can legitimately choose $\sqrt{3}$ as a uniformizer of $\mathcal{O}_{K_v}$ . This means that every element of $\mathcal{O}_{K_v}$ has a unique representation $$\sum_{n=0}^{\infty}a_n\sqrt{3}^n, \text{ where } a_n\in\{-1,0,1\}.$$ The elements of $\mathcal{O}_{K_v}^{\times}$ are the ones where $a_0=\pm1$ . Now, using Hensel's lemma I went ahead and showed that $$(\mathcal{O}_{K_v}^{\times})^3=\{\pm1+\sum_{n=3}^{\infty}a_n\sqrt{3}^n~|~a_n\in\{-1,0,1\}\}.$$ But how do I find distinct representatives for $\mathcal{O}_{K_v}^{\times}/(\mathcal{O}_{K_v}^{\times})^3$ ? Does modding out by the group above mean that I can just look up to sign and ignore everything past $\sqrt{3}^3$ , so that a set of representatives would be $\{1,1\pm\sqrt{3},1\pm3,1\pm\sqrt{3}\pm3\}$ , which has size 9 (the 2 $\pm$ 's are independent in the last expression)? Perhaps my working is not useful, because I've written things additively but the groups are multiplicative. Also, I could just as well have chosen $\sqrt{-6}$ as my uniformizer. Can I replace $\sqrt{3}$ with $\sqrt{-6}$ everywhere and still get a set of representatives for $\mathcal{O}_{K_v}^{\times}/(\mathcal{O}_{K_v}^{\times})^3$ ? I'm very confused! Of course, once $\mathcal{O}_{K_v}^{\times}/(\mathcal{O}_{K_v}^{\times})^3$ is determined, finding $K_v^{\times}/(K_v^{\times})^3$ is easy.","['local-field', 'number-theory', 'algebraic-number-theory', 'kummer-theory']"
3252225,Dealing with the singularity of a complex polynomial in $1/z$,"Disclaimer: I have virtually no complex analysis knowledge and I am seeking to get up to speed in this area of analysis. At the moment, I am surveying material on elementary complex functions and the related ideas pertaining to their singularities. I apologise if the questions I ask might be incredibly banal or obvious, but I really have very little knowledge in this are and am desperately seeking to better myself therein. For $n\in\mathbb N$ and $\{a_n\in\mathbb F:n\in\mathbb N\}$ where $\mathbb F\in\{\mathbb R, \mathbb C\}$ consider the complex polynomial in $\frac{1}z$ given by $f:D(f)\subseteq\mathbb C\to\mathbb C$ where $f$ is defined $$f(z):=\sum_{i=0}^na_nz^{-n}.$$ The domain of $f$ , denoted $D(f)$ , is clearly the set $\mathbb C/\{0\}$ , since $f(z=0)$ is not well defined. My question : is there any way to extend $f$ to all of $\mathbb C$ ? So as to have, for our above $f$ , that $D(f)\equiv\mathbb C$ ? If so, how, precisely, does one go about ""plugging in"" the point $c=0$ ? (I have a feeling that this is to do with the notion of a singularity)","['complex-analysis', 'functions', 'polynomials', 'complex-numbers']"
3252234,About Poincaré-Hopf theorem: can we find and draw $v$ with only one zero on $S$?,"Disclaimer: It turns that that there is a positive answer to a more general question than my original question (see here ), but this answer isn't what I am really looking for: I would like some visual constructions. Also I don't want to make a new post because an answer has already been posted. The Poincaré-Hopf theorem (for surfaces) states that if $v$ is a smooth vector field with isolated zeros on a compact surface $S$ , then the sum of the index of these zeros is equal to the Euler characteristic of $S$ : $$\sum_{x\text{ zero of }v} ind(v,x)=\chi(S).$$ Also during the proof that I know, we constructed explicitly a vector field $v$ on $S$ with isolated zeros, namely by triangulating the surface. My original question was: In the case where $\chi(S)\neq 0$ , i.e $S$ is neither a torus nor a klein bottle, can we ask that $v$ has only one zero $x_0$ , which therefore satisfies $ind(v,x_0)=\chi(S)~?$ So it turns out that this is true in general (even in higher dimensions). What I really want to know, now that the existence of such vector field is proven, is this: Can we provide some (nice) pictures of these vector fields $v$ on $S$ ? This can be done when $S$ is the sphere $S^2$ , by pulling back the constant vector field $\frac{\partial}{\partial x}$ on $\Bbb R^2$ via the stereographic projection and extending this pulled-back vector field to $0$ on the north pole. The picture is as follows (with a zoom on the right): For the case where $S$ is the protective plane $\Bbb{RP}^2=S^2/_{\{\pm id\}}$ , this is also possible. 
If we take the vector field on the sphere which is drawn below (each trajectory stays in horizontal hyperplanes basically) then this vector field has two zeros (the north pole $N$ and the south pole $S$ ), both of degree one. Moreover, this vector field is invariant under the antipodal map, and therefore it gives rise to a vector field on $\Bbb{RP}^2$ and this vector field has only one zero, namely $x_0=\{N,S\}$ , with degree $1$ . For the case $S=M_g$ of the connected sum of $g\geq 2$ torus, I tried to do drawings and write $M_g$ as a polygon with edges identified, but I can't find an example. For example at least when $g=2$ , I am hoping to find a comprehensive picture (on the embedded surface or on the polygon with edges identified). I haven't thought about the other cases yet (connected sum of projective planes), but it should be of the same difficulty. Any help would be greatly appreciated!","['vector-fields', 'differential-topology', 'surfaces', 'differential-geometry']"
3252264,Derivation of an integral result,"In this thread it is mentioned that: $$\int_0^\infty \left ( \mathrm{arccot} x \right )^3\; \mathrm{d}x = \frac{3 \pi^2 \ln 2}{4} - \frac{21\zeta(3)}{8}$$ where $\zeta$ is the Riemann zeta function . The steps to the solution I took are: \begin{align*}
\int_{0}^{\infty} \left ( \mathrm{arccot}x \right )^3 \, \mathrm{d}x &= \int_{0}^{\infty} \left ( x \right ) ' \left ( \mathrm{arccot}x \right )^3 \, \mathrm{d}x  \\ 
 &=\left [ x \left ( \mathrm{arccot}x \right )^3 \right ]_0^{\infty} +3 \int_{0}^{\infty} \frac{x\left( \mathrm{arccot }x \right )^2}{ x^2+1} \, \mathrm{d}x \\ 
 &=3  \left [ \frac{\ln \left ( 1+x^2 \right ) \, \left (\mathrm{arccot}(x)  \right )^2}{2} \right ]_0^{\infty} + 3 \int_{0}^{\infty} \frac{\ln \left ( 1+x^2 \right ) \mathrm{arccot} x}{x^2+1} \, \mathrm{d}x  \\ 
 &=3 \left ( \int_{0}^{1} \frac{\ln \left ( 1+x^2 \right ) \mathrm{arccot} x}{x^2+1} \, \mathrm{d}x + \int_1^{\infty} \frac{\ln \left ( 1+x^2 \right ) \mathrm{arccot} x}{x^2+1} \, \mathrm{d}x  \right ) \\
 &=3 \left ( \int_{0}^{1} \frac{\ln \left ( 1+x^2 \right ) \mathrm{arccot} x}{x^2+1} \, \mathrm{d}x + \int_{0}^{1} \frac{\ln \left ( 1+\frac{1}{x^2} \right ) \arctan x}{1+\frac{1}{x^2}} \cdot \frac{1}{x^2} \, \mathrm{d}x \right ) \\
 &=3 \left ( \int_{0}^{1} \frac{\ln \left ( 1+x^2 \right ) \mathrm{arccot} x}{x^2+1} \, \mathrm{d}x  + \int_{0}^{1} \frac{\left (\ln \left ( 1+x^2 \right ) - 2 \ln x  \right ) \arctan x}{1+x^2} \, \mathrm{d}x \right )\\
&=3\left ( \int_{0}^{1} \frac{\ln \left ( 1+x^2 \right )\left ( \mathrm{arccot} x + \arctan x \right )}{x^2+1} \, \mathrm{d}x - 2 \int_{0}^{1} \frac{\ln x \arctan x}{1+x^2} \, \mathrm{d}x \right ) \\
&=3\left ( \frac{\pi}{2} \int_{0}^{1} \frac{\ln \left ( 1+x^2 \right )}{1+x^2} \, \mathrm{d}x - 2 \int_{0}^{1} \frac{\ln x \arctan x}{1+x^2} \, \mathrm{d}x \right ) 
\end{align*} Let us now calculate the the first integral: \begin{align*}
\int_{0}^{1} \frac{\ln \left ( 1+x^2 \right )}{1+x^2} \, \mathrm{d}x &\overset{x=\tan \theta}{=\! =\! =\! =\! =\!} \int_{0}^{\pi/4} \frac{\ln \left ( 1+\tan^2 \theta \right )}{1+\tan^2 \theta} \cdot \sec^2 \theta \, \mathrm{d}\theta\\ 
 &=\int_{0}^{\pi/4} \ln \left ( 1+ \tan^2 \theta \right ) \, \mathrm{d}\theta \\ 
 &= \int_{0}^{\pi/4} \ln \sec^2 \theta \, \mathrm{d} \theta \\
 &=2 \int_{0}^{\pi/4} \ln \sec \theta \, \mathrm{d} \theta \\
 &=-2 \int_{0}^{\pi/4} \ln \cos \theta \, \mathrm{d} \theta \\
 &=-2 \left ( -\int_{0}^{\pi/4} \left (\sum_{n=1}^{\infty} (-1)^n \frac{\cos 2n \theta}{n} - \ln 2  \right ) \, \mathrm{d}\theta \right )\\
 &=2 \sum_{n=1}^{\infty}  \frac{(-1)^n}{n} \int_{0}^{\pi/4} \cos 2n\theta \, \mathrm{d} \theta +2 \int_{0}^{\pi/4} \ln 2 \, \mathrm{d}\theta \\
 &= 2 \sum_{n=1}^{\infty} \frac{(-1)^n \sin \frac{n \pi}{2}}{2n^2} +\frac{\pi \ln 2}{2} \\
 &= \sum_{n=1}^{\infty} \frac{(-1)^n \sin \frac{n \pi}{2}}{2n^2} + \frac{\pi \ln 2}{2} \\
 &=\frac{\pi \ln 2}{2} + \sum_{n=0}^{\infty} \frac{(-1)^n}{(2n+1)^2}\\
 &= \frac{\pi \ln 2}{2} - \mathcal{G}
\end{align*} where $\mathcal{G}$ is the Catalan's constant . Let's move on to the second integral: \begin{align*}
\int_{0}^{1} \frac{\ln x \arctan x}{1+x^2} \, \mathrm{d}x &=\int_{0}^{1} \ln x \sum_{n=1}^{\infty} (-1)^{n-1} \left ( \mathcal{H}_{2n} - \frac{\mathcal{H}_n}{2} \right ) x^{2n-1} \, \mathrm{d}x \\ 
 &=\sum_{n=1}^{\infty} (-1)^{n-1} \left ( \mathcal{H}_{2n} - \frac{\mathcal{H}_n}{2} \right ) \int_{0}^{1}x^{2n-1} \ln x \, \mathrm{d}x \\ 
 &=-\frac{1}{4}\sum_{n=1}^{\infty} (-1)^{n-1} \frac{\mathcal{H}_{2n}- \frac{\mathcal{H}_n}{2}}{n^2}  \\ 
 &= \frac{1}{4} \sum_{n=1}^{\infty} (-1)^n \frac{\mathcal{H}_{2n} - \frac{\mathcal{H}_n}{2}}{n^2} \\
 &=\frac{1}{4} \sum_{n=1}^{\infty} (-1)^n \frac{\mathcal{H}_{2n}}{n^2}  -\frac{1}{8} \sum_{n=1}^{\infty} (-1)^{n} \frac{\mathcal{H}_n}{n^2}
\end{align*} The second sum is an old chestnut evaluating to $$\sum_{n=1}^{\infty} (-1)^n \frac{\mathcal{H}_n}{n^2} = -\frac{5 \zeta(3)}{8}$$ see for example this link .The first sum should bring the $\mathcal{G}$ in . The question is how?","['integration', 'definite-integrals', 'sequences-and-series', 'real-analysis']"
3252295,Asymptotic behavior of $a_{n+1}=\frac{a_n^2+1}{2}$,"Define a sequence as follows: $$a_0=0$$ $$a_{n+1}=\frac{a_n^2+1}{2}$$ I would like to know the asymptotic behavior of $a_n$ . I already know (by roughly approximating $a_n$ with a differential equation) that $$a_n\sim 1-\frac{2}{n}$$ as $n\to\infty$ . However, my approximation is very crude. Can anyone find a couple more terms? I expect (from numerical data) that the next term is something like $\frac{\log(n)}{n^2}$ . In case anyone wants context for this problem, I am trying to find the optimal strategy for a game with the following rules: There are $n$ offers of money whose amounts are hidden from you, and whose quantities are random (independently and uniformly distributed from $0$ to $1$ ). One at a time, the offers are shown to you, and as you view each offer, you may either accept it or reject it. Once you accept an offer, the game is over and you may accept no more offers. It turns out that $a_n$ is the minimum value of the first offer for which you should accept that offer, in a game with $n+1$ offers. This is why I am interested in the asymptotic behavior of $a_n$ .","['approximation', 'asymptotics', 'recurrence-relations', 'iterated-function-system', 'sequences-and-series']"
3252299,Does the following imply Lipschitz continuity?,"Let $f: \mathbb{C}^d \rightarrow \mathbb{C}^d$ be a function such that there is a $c > 0$ with $$
|\langle f(x) - f(y),x-y \rangle| \leq c \langle x-y,x-y \rangle
$$ for all $x, \; y \in \mathbb{C}^d$ , where $\langle \cdot , \cdot \rangle$ denotes the Hermitian product. Does this imply that $f$ is Lipschitz continuous?","['lipschitz-functions', 'real-analysis', 'continuity', 'calculus', 'vector-analysis']"
3252311,Prove $(A\times B)^C \sim A^C\times B^C$,"Let A,B,C be sets. Prove $(A\times B)^C \sim A^C\times B^C$ In order to prove it, we need to define a function and show: The function is to range of defined function. The function is injective. The function is surjective. My question is only regarding the first step. Proof of first step: We define a function $H: A^C\times B^C \to (A\times B)^C$ with the following rule: $\forall(f,g)\in A^C\times B^C$ , $H((f,g))$ is a function from $C$ to $A\times B$ which defined by the following rule: $\forall x\in C, (H(f,g))(x)=(f(x),g(x))$ . Let be an arbitrary element $p\in Img(H)$ , we need to show $p\in (A\times B)^C$ to complete this part of the proof. $p\in Img(H)$ then exist $m\in A^C\times B^C$ such that $H(m)=p$ . My difficult is to show formally the first step, I mean, we need to show $Img(H)\subseteq (A\times B)^C$ and since it is very clear, I found a difficulty to formalize it. While defining the function above, I have tried a lot to define the function H when the domain is the $(A\times B)^C$ and the range is $A^C\times B^C$ bijective. However, I did not succeed write it formally, so I will be glad to see the if it could be defined formally. (Where the issue? $\forall g\in (A\times B)^C$ , $H(g)=(g^{-1}\cap A\times A,g^{-1}\cap B\times B)$ How can I be sure that $g$ is inverse(bijective) when I define it, is it fine or I need first to show that is bijective so $g$ is inverse?)",['elementary-set-theory']
3252315,Show that $\int_{0}^{\pi/4}\int_{0}^{\pi/4}\left(\sec(x+y)+\sec(x-y)\right)\mathrm{d}x\mathrm{d}y=2G$,"Show that $$
\int_{0}^{\pi/4}\int_{0}^{\pi/4}
\left[\vphantom{\large A}\sec\left(x + y\right) +
\sec\left(x - y\right)\right]\,\mathrm{d}x\mathrm{d}y =
2G
$$ where $G$ is Catalan's constant .
I am not sure where to start or how to begin.","['integration', 'definite-integrals']"
3252317,If $A=\int_{0}^{1} x^n(1-x)^ndx$ then $A^{-1} \in \mathbb{N}$.,Consider the integral $$A=\int_{0}^{1} x^n(1-x)^ndx$$ Prove that $A^{-1}$ is a natural number. I have no idea how to compute the integral. But by putting $n=1$ I got $A^{-1}=6$ a natural number. Is there any simple method to show that $A^{-1}$ is a natural number?,"['definite-integrals', 'analysis']"
3252341,Survivor distribution following a zombie outbreak,"Suppose there is initially a population of $A$ humans and $B$ zombies. You are sitting on a nearby hill with a shotgun; however, you're not a very good shot, so each time you pull the trigger, one of the members of the population is hit uniformly at random. If you hit a zombie, the zombie dies. If you hit a human, the zombies pile onto the poor wounded human and turn them into a new zombie. Undeterred by your lack of skill, you continue to take shots into the population until there are no more zombies. At this point, what can be said about the distribution of the number of human survivors? For example, we can try to compute the probability $q(A,B)$ that there are no survivors at the end of the process. This quantity should satisfy the recurrence $$q(A,B) = \frac{A}{A+B} q(A-1, B+1) + \frac{B}{A+B} q(A, B-1)$$ with the initial conditions $q(0,k) = 1$ for $k\ge 0$ and $q(k,0) = 0$ for $k>0$ . Is there a simple formula for $q(A,B)$ or reasonable asymptotics? What can be said about the probability $q(k,A,B)$ that there are $k$ survivors for $1\le k \le A$ ? Also, looking at some data seems to suggest that we always have a ""reverse unimodal"" property $$q(0,A,B) > q(1,A,B) > \cdots < q(A-1, A, B) < q(A, A, B)$$ with $q(0,A, B) > q(A, A, B)$ , i.e. it is likeliest to have zero survivors. Is it possible to show this in general?","['combinatorics', 'probability-theory', 'probability']"
3252351,"When solving a linear system, why SVD is preferred over QR to make the solution more stable?","I have seen many posts stating that SVD is more stable as a preprocessing for solving least square or linear system problem than QR. Certainly QR is less expensive than SVD, so I guess it makes sense. But why?","['svd', 'least-squares', 'linear-algebra', 'numerical-linear-algebra', 'numerical-methods']"
3252396,Grading equivalent to action of multiplicative group scheme,"Consider the group scheme $\mathbb{G}_m = \mathrm{Spec}(\mathbb{Z}[t, t^{-1}])$ . An action of $\mathbb{G}_m$ on an affine scheme $X = \mathrm{Spec}(A)$ is a morphism of schemes $$
\sigma: \mathbb{G}_m \times X \to X
$$ such that for every scheme $T$ , $\sigma_T : \mathbb{G}_m(T) \times X(T) \to X(T)$ is a group action in the standard definition. I want to show that the action $\sigma$ is equivalent to a $\mathbb{Z}$ -grading on $A$ . I've been trying to do this for a little while but I am stuck. How can I prove/think about this? The closest I've got to solving this is by using the idea of considering $A$ as a $\mathbb{Z}[t, t^{-1}]$ -comodule using the ring homomorphism $$
\Delta: A \to A \otimes \mathbb{Z}[t, t^{-1}] \cong A[t, t^{-1}]
$$ dual to the action $\sigma$ . This was taking from example 1.6.6 in Hida's book on geometric modular forms, which refers to Jantzen's book on Reps of Algebraic Groups. However, I'm not comfortable with the idea of comodules, including why this is a comodule map. However, I think I see why, if this is a comodule map and satisfies the requesite properties mentioned in Jantzen, then we get a grading. Given a grading, there seems to be an obvious way to define a homomorphism $\Delta$ taking $a \mapsto \sum_{n \in \mathbb{Z}} p_n(a) \otimes t^n$ where $p_n$ is the projection map onto the $n^{th}$ graded piece. Is it true that this gives a group action? Again I'm not that comfortable with this equivalence between group actions and $G$ -modules and $\mathbb{Z}[t, t^{-1}]$ -comodules. If the above description is the best way to think of this then I will try to understand these better, but I wanted an outside opinion on how to prove/think about this.","['group-schemes', 'algebraic-geometry', 'commutative-algebra']"
3252469,Does $C_0(X)$ determine the topology for a locally compact space $X$?,"Given a locally compact Hausdorff space, does $C_0(X)$ , the continuous functions vanishing at infinity, determine the topology of $X$ ? For example, for a net $\{x_{\alpha}\}\subset X$ if I have $f(x_\alpha)\to f(x)$ for all $f\in C_0(X)$ , does it follow that $x_{\alpha} \to x$ ? I cannot find any reference to the Banach-Stone theorem that proves this. I would really appreciate some feedback. Thanks!","['general-topology', 'functional-analysis']"
3252485,Why does this partial derivative gives this result?,"I have to progress this partial derivative. $$
\partial n^{1/2} e^{iφ} / \partial t
$$ Using the rule $$
(ab)' = a'b + ab'
$$ I would guess that the result would be: $$
(1/2) n^{-1/2}e^{iφ} + n^{1/2}ie^{iφ}
$$ But the result is this: $$
(1/2) n^{-1/2}e^{iφ} \partial n/\partial t+ n^{1/2}ie^{iφ} \partial φ/\partial t
$$ So why were the two extra partial parts there?","['partial-derivative', 'derivatives']"
3252491,Prove that $(x+1)^x-x^x(x-1)$ only has one (real) root,"For $x>0$ , I want to prove that $(x+1)^x-x^x(x-1)$ only has one root","['calculus', 'analysis']"
3252517,Can you help me solve this 2nd order ode?!,$$\frac{d^2y}{dx^2}+\frac{1}{x}\frac{dy}{dx}-ye^{-x}=0$$ subjected to $y'(1)=-1$ and $y'(a)=0$ . I was trying to fit it to the general bessel differential equation. But no luck. :(  :(,"['differential', 'bessel-functions', 'ordinary-differential-equations', 'partial-differential-equations']"
3252543,"If $G$ is the fundamental group of a graph of finite groups, is there a ""graph structure"" preserved by automorphisms?","For clarity, let me recall: By a graph of finite groups, I mean a finite graph $\Gamma$ with edge set $E$ and vertex set $V$ , together with, for each vertex $v$ , a finite group $G_v$ , and for each edge $e$ a finite group $G_e$ . Additionally, we have monomorphisms $G_e \to G_{i(e)}$ and $G_e \to G_{t(e)}$ , where $i(e)$ , $t(e)$ denote the initial and terminal vertices of $e$ , respectively. (See Serre's Trees or the Wikipedia article on Bass–Serre theory ) The finiteness assumption on the groups $G_v$ , $G_e$ is part of my question, not the usual definition. Write $F(\Gamma,G_v,E)$ for the free product of the $G_v$ and the free group on the set $E$ . If $T$ is a maximal tree in $\Gamma$ , define $G = \pi_1(\Gamma,T)$ , the fundamental group of the graph of groups $\Gamma$ with respect to $T$ to be the quotient of $F(\Gamma,G_v,E)$ adding the relations $\bar e = e^{-1}$ , where $\bar e$ is the edge $e \in E$ with the opposite orientation. $ei_e(x)e^{-1} = t_e(x)$ , where $e \in E$ and $x \in G_e$ . $e = 1$ for $e$ an edge in $T$ . The group $G$ is virtually free, hence word-hyperbolic, and thus has finitely many conjugacy classes of finite subgroups. As such, $\operatorname{Out}(G)$ permutes these conjugacy classes. Some questions: Do the $G_v$ form a set of representatives for the conjugacy classes of maximal (with respect to inclusion) finite subgroups of $G$ ? Does each $\Phi\in\operatorname{Out}(G)$ have a representative $\varphi$ that preserves the ""splitting type""? In the sense that there is a graph of groups decomposition with vertex groups $\varphi(G_v)$ , edge groups $\varphi(G_e)$ and a graph isomorphism between the underlying graphs that respects $G_v \mapsto \varphi(G_v)$ ? The answer to both questions is yes in the case that $\Gamma$ has all edge groups trivial, by the Grushko decomposition theorem. I suspect if $\Gamma$ is a tree it should also be true, but I worry about the case of nontrivial HNN extensions.","['geometric-group-theory', 'group-theory']"
3252564,"Show that if $A = \begin{bmatrix} 0 & 1 \\ 1 & 1 \end{bmatrix} $, $\mathrm{tr}(A^{k}) = \mathrm{tr}(A^{k-1}) + \mathrm{tr}(A^{k-2})$","$\newcommand{\tr}{\operatorname{tr}}$ If $A =   \begin{bmatrix}
     0 & 1  \\
     1 & 1    \end{bmatrix} $ , then $\tr(A^{k}) = \tr(A^{k-1}) + \tr(A^{k-2})$ . Hint: If $AB=0$ , then $\tr[(A+B)^k]=\tr(A^k)+\tr(B^k)$ . I tried to decompose \begin{bmatrix}
    0 & 1  \\
    1 & 1 
  \end{bmatrix} to $P$ and $Q$ such that $P+Q=\begin{bmatrix}
    0 & 1  \\
    1 & 1 
  \end{bmatrix}$ and $PQ=0$ , but it seems that this does not work.","['matrices', 'linear-algebra']"
3252593,Solve $\frac{\sin(xº)\sin(80º)}{\sin(170º - xº) \sin(70º)} = \frac {\sin(60º)}{\sin (100º)}$,"Solve: $$\frac{\sin(xº)\sin(80º)}{\sin(170º - xº) \sin(70º)} = \frac {\sin(60º)}{\sin (100º)}$$ I was solving a geometry problem with trigonometry, and after applying a lot of law of sines i got to this equation in 1 variable, but i'm not capable of solving it. The answer to the problem is $40º$ , and by Wolfram Alpha i saw that this equation it's correct, but i don't know how to solve it by hand. Any hints? ( $xº$ is a value for an right triangle, that's why i'm looking for one solution.) Here is the problem if anyone find a different answer:","['triangles', 'euclidean-geometry', 'trigonometry', 'geometry']"
3252602,Is the invariant subspace problem open for invertible maps?,"Let $T: H \rightarrow H$ be a bounded linear operator with bounded inverse on the separable complex Hilbert space. Does $T$ preserve a closed proper non-trival invariant subspace? I'm aware the question is (famously) open for bounded linear maps, and of partial results, but no survey (or Tao's blog, etc) seem to address the invertible case. If it is open, does a positive or negative answer imply the answer in the non-invertible case?","['functional-analysis', 'real-analysis']"
3252703,Which vectors are weight vectors for some Cartan subalgebra?,"Let $\mathfrak g$ be a semisimple Lie algebra and $V$ - its representation, both finite-dimensional over $\mathbb C$ . By the well-known results, one can choose in $\mathfrak g$ a Cartan subalgebra and decompose the vector space $V$ as a direct sum of its weight spaces. Elements of the weight spaces are called weight vectors. This decomposition depends on the choice of a Cartan subalgebra. Define a set $\Xi$ to consist of all $x \in V$ such that $x$ is a weight vector for some choice of a Cartan subalgebra. What can be said about the set $\Xi$ ? I'm asking about topological properties (both with respect to the usual and the Zariski topology), characterizations in terms of explicit equations, if possible finer geometric characteristics (e.g. dimension).","['lie-algebras', 'algebraic-groups', 'representation-theory', 'algebraic-geometry', 'lie-groups']"
3252737,Show that $\int_{0}^{\pi/2} \sin^3x \cos^2 x \cos7x ~ dx= \frac{1}{60}.$,Show that $$\int_{0}^{\pi/2} \sin^3x \cos^2 x \cos7x ~ dx= \frac{1}{60}$$ I could solve this integral by making use of the special expansion $$\cos 7x=64 \cos^7 x- 112\cos^5 x + 56 \cos^3 x -7\cos x$$ and then using $ \cos x =t.$ But I would like to know if there is a simpler way to solve this integral.,"['trigonometry', 'definite-integrals']"
3252739,Maximizing the value of a determinant,"Given the entries of a matrix how can we optimize its determinant? So, if the entries of a $n\times n$ matrix belong to the set $\{a_1,a_2,\ldots ,a_p\}$ , how to arrange them to maximize or minimize the determinant? I have seen a result concerning $3 \times 3$ matrices,which says that determinant is maximum when all the diagonal elements are $\min\{a_i\}_{1\leq i\leq p}$ and all the off-diagonal elements are $\max\{a_i\}_{1\leq i\leq p}$ .
And once we maximize it, switching two rows or two columns we get the minimum value. Also, i don't have any clue for higher order matrices. Any help would be appreciated. Thanks in advance.","['determinant', 'matrices', 'linear-algebra', 'discrete-optimization', 'optimization']"
3252750,Prove the light will never go through a vertex,In the equilateral triangle ABC we send a light beam through The vertex A so that it hits D on side BC so that: BD/BC= 1/√2 How many times does the light beam have to reflect so that it goes back through a vertex? Now I know the answer is it will never go back through a vertex but I want the proof. To be more specific why is it when BD/BC=irrational number then the light will never go through a vertex?,"['euclidean-geometry', 'geometry']"
3252757,How to use the derivative definition to prove the derivative of a straight horizontal line is zero,"If I have the function $f(x)=2$ then $f'(x)$ will obviously be equal to zero because at any x-value on the $f(x)$ function, the slope is zero. What I am trying to do is prove that $f'(x)=0$ using the derivative definition $f'(x)=\lim_{z\to x}\frac{f(z)-f(x)}{z-x}$ where $(x,f(x))$ will be the point where our tangent line connects to $f(x)$ and where $(z,f(z))$ is our arbitrary point that will get infinitely closer to $(x,f(x))$ . I keep getting an indeterminate answer and I can't find a way around this.","['limits', 'calculus']"
3252765,Criterion for fundamental solutions to Pell's equation of the form $X^2-DY^2=C$,"We are trying to codify in terms of modern algorithm the works of the ancient Indian mathematician Udayadivakara (CE 1073). In his work Sundari , he quotes one Acarya Jayadeva who has given methods to solve Pell's equations. In these methods, one can find the the cyclic Chakravala method to deal with $X^2-DY^2=1$ wrongly attributed to Bhaskara. He also gives the method to solve $X^2-DY^2=C$ for any integer $C$ . His algorithm starts off by finding the nearest square integer $>D$ named $P^2$ . Then $a=P^2-D$ . Now some $b$ is chosen in such a way that $Db^2+Ca$ is some perfect square $Q^2$ . Then the $X$ and $Y$ solutions can be found by using $Y=\frac{Q\pm P b}{a}$ and $X=PY \mp b$ . This procedure can continue indefinitely to find all the solutions. Coming to the question of the fundamental solution i.e. the solution with which Bhavana has to be performed repeatedly to get other solutions (related to the modern automorphism group of the quadratic form), Prof. K.S. Shukla who first translated the work from Sanskrit to English, in his example says that it should be chosen ""appropriately"". Our primary question is then what is the criterion to derive this fundamental solution ? Is there a way to derive such a criterion? The whole procedure seems to resemble Conway's topograph method which has been posted here several times Does the Pell-like equation $X^2-dY^2=k$ have a simple recursion like $X^2-dY^2=1$? It is quite fascinating to think that some wonderful mind came up with this algorithm about 1000 years ago and the optimality of it is equally amazing. P.S: If anyone so wishes, we would be happy to provide a version of the original paper written by Prof. Shukla in 1950 dealing with this!","['number-theory', 'elementary-number-theory', 'pell-type-equations', 'algorithms', 'math-history']"
3252780,Find a simple and smooth curve $C$ such that $\displaystyle \int_C\vec{F}\cdot d\vec{r}$ gets its maximum value,"I've been trying to solve this problem for a while, but for too long couldn't I continue my partial solution. I would be glad if you could shed some light on my solution. The task :
Given the vector field $\vec{F}(x,y)\equiv(P(x,y),Q(x,y))$ such that $P(x,y)=y^3-3y+xy^2$ and $Q(x,y)=3x-x^3+x^2y$ , which is defined on $D=\{(x,y)\ |\ x^2+y^2\leq2\}$ , find a simple and smooth curve $C$ from $A(1,1)$ to $B(-1,-1)$ which is inside $D$ such that: $$\int_C\vec{F}\cdot d\vec{r}$$ gets its maximum value. My solution Let $C$ and $C_0$ be two curves that satisfy the requirements of the question, such that they are the boundaries of a closed area $S\subseteq D$ . We will choose $C$ to be positively oriented, whereas $C_0$ will be negatively oriented. Now, as $\vec{F}\in C^1$ , we are able to use Green's Theorem .
We can see that: $$\frac{\partial Q}{\partial x}-\frac{\partial P}{\partial y}=6-3(x^2+y^2)$$ So according to the theorem, defining $\Gamma\equiv C\ \cup\ C_0$ : $$\oint_{\Gamma}\vec{F}\cdot d\vec{r}=\int_C\vec{F}\cdot d\vec{r}-\int_{C_0}\vec{F}\cdot d\vec{r}=\iint_Sr(6-3r^2)drd\theta$$ Accordingly: $$\int_C\vec{F}\cdot d\vec{r}=\int_{C_0}\vec{F}\cdot d\vec{r}+\iint_Sr(6-3r^2)drd\theta$$ Since $\displaystyle \iint_Sr(6-3r^2)drd\theta$ is always positive inside $D$ $(0\leq r\leq\sqrt2)$ , the obvious would be to choose $C_0$ such that $S$ is the biggest area we can fit inside $D$ . The problem is, that this might cause $\displaystyle \int_{C_0}\vec{F}\cdot d\vec{r}$ to be relatively small. That is where I got stuck. P.S.: I also looked at the field, geometrically. It seems that inside $r=\sqrt2$ it looks different than the outside. I bet that's a thing I should take into account, but I don't know how. Thanks!","['integration', 'greens-theorem', 'multivariable-calculus']"
3252803,how many abelian transitive subgroups of $S_{n}$,"It's well-known that any abelian transitive subgroup A of a symmetric group $S_{n}$ has order $n$ . Moreover, does anyone know how many abelian transitive subgroups of $S_{n}$ and what do they look like?","['finite-groups', 'abstract-algebra', 'combinatorics', 'symmetric-groups', 'group-theory']"
3252850,On finite simple groups whose orders are perfect powers,"A short note in Group Atlas v2.0 states: $\mathrm{PSp}(4,7)$ is the smallest simple group whose order is a proper power. Question: Is there other known finite simple groups whose orders are perfect powers? I have checked all finite simple groups whose order $<10^{10}$ without finding out another example.","['number-theory', 'group-theory', 'simple-groups']"
3252860,Find the eigenvalue and eigenfunction successions for S-L BVP,"The problem in question is $(1+x)y''(x)+\frac12y'(x) + \lambda y(x)=0$ subject to $y(0)=y(3)=0$ . Thanks to a suggested change of variable ( $y(x)=u(\sqrt{1+x})$ ), I've managed to find the general solution to the equation: $y(x)=c_1\cos(2\sqrt{\lambda}\sqrt{1+x})+c_ 2\sin(2\sqrt{\lambda}\sqrt{1+x})$ for $c_1, c_2 \in \mathbb{R}$ . However, the boundary values don't help much to find the problem's solution (is it even possible?), so I don't know how to proceed in finding the eigenvalues and eigenfunctions. Does anyone have any suggestion? Edit: this sums up to finding $\lambda$ such that the system $Sc = 0$ below admits solutions other than $c=0$ : $$Sc=0\Leftrightarrow\begin{bmatrix}\cos(2\sqrt{\lambda}) & \sin(2\sqrt{\lambda}) \\ \cos(4\sqrt{\lambda}) & \sin(4\sqrt{\lambda})\end{bmatrix}\begin{bmatrix}c_1 \\ c_2\end{bmatrix}=\begin{bmatrix}0\\0\end{bmatrix}$$ Taking the determinant of $S$ , we get $\cos(2\sqrt{\lambda})\sin(4\sqrt{\lambda}) - \cos(4\sqrt{\lambda})\sin(2\sqrt{\lambda})=\sin(2\sqrt{\lambda})$ . If $Sc=0$ for $c\neq0$ , then $\det(S)=0$ , so we're pretty much done: $$\sin(2\sqrt{\lambda})=0\Leftrightarrow\lambda=\frac{k^2\pi^2}4,\, k\in\mathbb{Z}.$$ After this, we can find that $c_1=0$ and $c_2$ can be anything, so the solution to this problem would be $y(x) = c_2\sin(k\pi\sqrt{1+x})$ .","['sturm-liouville', 'ordinary-differential-equations']"
3252917,Is the image of a smooth map with constant rank a submanifold,"I have two compact manifolds $M$ and $N$ and a smooth map $f:M\to N$ with constant rank $k \leq \dim M$ . Is it true that $f(M)$ is a submanifold in $N$ ? If not, what other properties do I need? Would it suffice that $f$ is continuous instead of smooth? I've been trying to see how this could work using the constant rank level set theorem by constructing a sort of ""inverse"" $g : N \to M$ , but that approach seems to fail, as $f$ can be non-injective.","['general-topology', 'differential-geometry']"
3252960,How to show $\sum_{k=0}^{n}\binom{n+k}{k}\frac{1}{2^k}=2^{n}$,"How does one show that $$\sum_{k=0}^{n}\binom{n+k}{k}\frac{1}{2^k}=2^{n}$$ for each nonnegative integer $n$ ? I tried using the Snake oil technique but I guess I am applying it incorrectly. With the snake oil technique we have $$F(x)= \sum_{n=0}^{\infty}\left\{\sum_{k=0}^{n}\binom{n+k}{k}\frac{1}{2^k}\right\}x^{n}.$$ I think I have to interchage the summation and do something. But I am not quite comfortable in interchanging the summation. Like after interchaging the summation will $$F(x)=\sum_{k=0}^{n}\sum_{n=0}^{\infty}\binom{n+k}{k}\frac{1}{2^k}x^{n}?$$ Even if I continue with this I am unable to get the correct answer. How does one prove this using the Snake oil technique? A combinatorial proof is also welcome, as are other kinds of proofs.","['binomial-coefficients', 'combinatorics', 'combinatorial-proofs', 'generating-functions']"
3252964,Fibrating $X=\Bbb R^2 / \{0\}$ by breaking up the space with hyperbola?,"Attending graduate school this Fall and need to understand fibrations better. I will be taking geometry and algebra. I've read a neat article Quanta Magazine Article on the topic of mirror worlds and symplectic spaces but I'd like to gain a deeper understanding of these concepts. Consider $X=\Bbb R^2 / \{0\}.$ How do you fibrate $X$ by breaking up the space with hyperbola $y=k/x?$ I understand this basically for a sphere as our symplectic space, but not for the hyperbola. With a sphere you can just fibrate it into tori, then take the reciprocal of each tori and re-assemble to create another geometric shape.","['differential-topology', 'symplectic-geometry', 'mirror-symmetry', 'differential-geometry']"
3252984,Books Recommendation that contains about Versine,"What is recommendations for the best books of trigonometry contain material about versine, coversine and other trigonometric functions that are rarely used, basic trigonometry, and concept about deriving Trigonometry identities?","['trigonometry', 'book-recommendation']"
3253003,A strange trigonometric identity,"In this paper , equation (4.5), the authors state the trigonometic identity $$
\sin\left( \frac{n\pi }{1-\theta}  \right) = (-1)^{n} \sin\left( \frac{n\pi \theta}{1-\theta}\right)
$$ Nothing like it is on Wikipedia's list of trigonometric identities. How can we prove this?",['trigonometry']
3253006,New bound for Am-Gm of 2 variables,"Today I'm interested by the following problem : Let $x,y>0$ then we have : $$x+y-\sqrt{xy}\leq\exp\Big(\frac{x\ln(x)+y\ln(y)}{x+y}\Big)$$ The equality case comes when $x=y$ My proof uses derivative because for $x\geq y $ the function : $$f(x)=x+y-\sqrt{xy}-\exp\Big(\frac{x\ln(x)+y\ln(y)}{x+y}\Big)$$ is decreasing and for $y\geq x$ the function is increasing and the maximum occurs when $x=y$ My question is : Have you an alternative proof wich doesn't use derivative ? Thanks in advance.","['a.m.-g.m.-inequality', 'real-analysis', 'alternative-proof', 'inequality', 'exponential-function']"
3253019,Can the concepts of abstract algebra be visualized as in analysis? [duplicate],This question already has an answer here : Visual approach to abstract algebra (1 answer) Closed last year . I like to visualize everything I study but yet I have found pretty nothing to visualize in abstract algebra.I have studied group theory upto subgroups Cyclic groups and Cosets and Lagrange's theorem.Is there any way of visualizing these things?Please suggest some good reference book/text also which discusses these things and also the motivation/idea behind different theorems and concepts.,"['cyclic-groups', 'real-analysis', 'calculus', 'abstract-algebra', 'group-theory']"
3253047,Sum of reciprocal binomial coefficients,"I am aware that $$\sum_{n=0}^\infty \binom{2n}{n}^{-1} = \frac{4}{3} + \frac{2\pi\sqrt{3}}{27}$$ though I do not know why it is true.  More generally, I'm interested in the value of the series $$S_k = \sum_{n=k}^\infty \binom{2n}{n-k}^{-1}$$ where $k$ is a fixed positive integer.  The series converges by the ratio test.  Does anybody know how to evaluate these sums, or have a reference where they are evaluated?","['binomial-coefficients', 'closed-form', 'sequences-and-series']"
3253101,Reparameterisation of Curve as a Regular Curve (Topology),"There is a result that a curve or topological path can be reparameterized as a regular curve contained in the paper ""Reparametrizations of continuous paths - Ulrich Fahrenberg and Martin Raussen"" https://arxiv.org/pdf/0706.3560.pdf For me the concepts are too advanced. Is there a simpler proof for this ? The definitions that follow are taken from the paper (more or less). A path is a continuous mapping $p$ from the closed unit interval $I = [0, 1]$ to a topological space $X$ . Excluding the case that the image of a path is a single point in X, then a path is regular if there is no closed interval $[a, < b] \subset I$ on which $p$ is constant. A reparametrization $\phi$ is a non-decreasing surjective continuous map $\phi: I \to I$ with $\phi(0) = 0; \phi(1) = 1$ . Theorem : for any path $p: I \to X$ there is a regular path $q: I \to X$ and a reparametrization $\phi$ such that $p = q \circ \phi$ . It looks straightforward to prove this in the case that $p$ has a finite number of stop intervals (on which $p$ is constant) by cutting them out one by one and composing the corresponding $\phi$ functions. Clearly the number of stop intervals is countable, but how to deal with a countably infinite number of them ?","['alternative-proof', 'curves', 'general-topology']"
3253123,Expected time until a repeat in a sequence of infinitely many coin flips?,"Consider flipping infinitely many coins and recording the result in a string $x_0 x_1 x_2 \dots$ Let $s_t$ be the substring of length $n$ starting from position $t$ . Let $\tau_n = \min(t > 0 : s_0 = s_t)$ be the random variable calculating the first time from when the initial substring $s_0$ is repeated. What is $\Bbb{E}(\tau_n)$ ? It is easy to show $\Bbb{E}(\tau_1) = 2$ : in the case that $n = 1$ , what we are calculating is simply the average minimum $t > 0$ such that $x_t = x_0$ , and we can take advantage of the independence of the coin flips. The probability that $x_t = x_0$ and $x_i \ne x_0 \ \ \forall \ 0 < i < t$ is $\left(\frac12\right) \cdot \left( \frac12 \right)^{t-1}$ , then $$\Bbb{E}(\tau_1) = \sum_{n=1}^\infty n \cdot \Pr(\tau_1 = n) = \sum_{n=1}^\infty n \cdot \left(\frac12\right) \cdot \left( \frac12 \right)^{n-1} = 2$$ Experimental data suggests $\Bbb{E}(\tau_n) = 2^n$ . I considered an inductive argument: waiting for a repeat of $n+1$ flips necessarily requires a repeat of $n$ flips, and then additional wait time until the last, single $n+1$ -th character occurs - a wait time equal in distribution(?) to $\tau_1$ , in which case $\Bbb{E}(\tau_{n+1}) = \Bbb{E}(\tau_n) \cdot \Bbb{E}(\tau_1)$ ? I don't know how to make this rigorous though.","['expected-value', 'probability', 'random-variables']"
3253139,Find $\lim_{n \rightarrow \infty} P(n[Y_n]=k)$,"Suppose $X_1,X_2,...,X_n$ is a random sample from $U(0,\theta)$ for some unknown $\theta>0$ .Let $Y_n$ be the minimum of $X_1,X_2,..,X_n$ .
Find $\lim_{n \rightarrow \infty} P(n[Y_n]=k)$ for $k=0,1,2,...$ where $[x]$ denotes the largest integer less than or equal to $x$ . My approach : We first write down the pdf of $Y_{n}$ : $f(y)=\frac{n}{\theta}(1-\frac{y}{\theta})^{n-1}$ Now, let $Z=[Y_n]$ $P(Z=z)=P([Y_n]=z)=P(z \le Y_n < z+1)=\int_{z}^{z+1} \frac{n}{\theta}(1-\frac{y}{\theta})^{n-1} dy=(1-\frac{z}{\theta})^n-(1-\frac{z+1}{\theta})^n$ Now, plugging in $\frac{k}{n}$ for $z$ ,we have $P(Z=\frac{k}{n})=(1-\frac{k}{n \theta})^n-(1-\frac{k+n}{n \theta})^n$ , but I cannot find the limit .
Perhaps, I have made a mistake somewhere. Please help!!","['statistics', 'probability-distributions', 'probability-theory', 'probability', 'random-variables']"
3253177,Regular polygons with rational area,"Problem : Find all natural numbers $n\ge 3$ such that the area of a regular $n$ -gon of radius $1$ is rational. Given a circle of radius $1$ , the only regular polygons inscribed in it with integer area are the square and the dodecagon. The area of the former is $2$ and the later's, $3$ . Since $\pi<4$ there are no more examples. But this bound says nothing about if the area can be rational for other polygons. The feeling is that there are no more examples with rational area (actually, I learned recently about the dodecagon and I found it quite surprising), but I don't know anything about a proof. I assume that it would involve the known theory about constructible numbers, but I'm not really sure.","['field-theory', 'geometry', 'geometric-construction']"
3253196,Find $m$ such that $(m-1)x^{2}+(m-1)x+m-3<0$,"I need to find $m$ real parameter such that $(m-1)x^{2}+(m-1)x+m-3<0$ for all real $x$ . My try: First condition $m-1<0$ so $m<1$ Second condition: the discriminant $<0$ from which I got $m\in(-\infty,1)\cup(\frac{11}{3},\infty)$ So when I intersectate the intervals I get $m\in(-\infty,1)$ which in my book is the wrong answer.
I need to chose from: A. m does not exist. B. $m\in(-\infty,1)\cup(\frac{11}{3},\infty)$ C. $m\in(-\infty,0)$ D. $m\in(-\infty,1)$ E.Another answer (The right answer is E.)
I miss something?","['functions', 'linear-algebra']"
3253240,Are polynomials with the same roots identical?,"I know that polynomials can be refactored in terms of their roots. However, this must imply that two different polynomials have different roots (this is just what I think). So my question is: Are polynomials with the same roots identical? - if so, why? A follow-up question that is also about the uniqueness of roots and polynomials can be found here: Is the set of roots unique for each $g(x)$ in $a_n x^n + g(x)$?","['algebra-precalculus', 'polynomials']"
3253242,"Grassmannian is homogeneous, isotropic, and symmetric","I'm trying to prove the Grassmann manifold $\mathrm G_k(\mathbb R^n)$ of $k$ -dimensional linear subspaces of $\mathbb R^n$ is isotropic and symmetric. By ""isotropic"" I specifically that for every point $P \in \mathrm G_k(\mathbb R^n)$ , and for every pair of unit tangent vectors $u, v \in T_P \mathrm G_k(\mathbb R^n)$ , there is an isometry $\phi : \mathrm G_k(\mathbb R^n) \to \mathrm G_k(\mathbb R^n)$ fixing $P$ and with $d\phi_P u = v$ . By ""symmetric"" I mean for every $P \in \mathrm G_k(\mathbb R^n)$ , there is an isometry $\phi$ fixing $P$ and so that $d\phi_P = -\mathrm{Id} : T_P \mathrm G_k(\mathbb R^n) \to T_P \mathrm G_k(\mathbb R^n)$ . There appear to be a few different definitions for each, and I want to be clear with which one I'm using. My setting: $\mathrm G_k(\mathbb R^n)$ has a unique smooth structure with respect to which the natural action of $\mathrm{GL}(n,\mathbb R)$ on $\mathrm G_k(\mathbb R^n)$ is smooth. To define the Riemannian metric, we consider the Stiefel manifold $\mathrm V_k(\mathbb R^n)$ of $k$ -tuples of orthonormal vectors in $\mathbb R^n$ . This may be considered a submanifold of the space $\mathrm M(n \times k, \mathbb R)$ of $n \times k$ real matrices, with the Euclidean metric from identifying $\mathrm M(n \times k, \mathbb R) \approx \mathbb R^{nk}$ . The map $\pi : \mathrm V_k(\mathbb R^n) \to \mathrm G_k(\mathbb R^n)$ sending a $k$ -tuple of orthonormal vectors to its span is a surjective smooth submersion. One can show $\mathrm O(k)$ acts on the right of $\mathrm V_k(\mathbb R^n)$ isometrically, vertically (meaning for $A \in O(k)$ , $B \in \mathrm V_k(\mathbb R^n)$ , we have $\pi(BA) = \pi(B)$ ), and transitively on fibers (meaning if $B$ and $B'$ are two orthonormal $k$ -tuples with the same span, there's some $A \in \mathrm O(k)$ with $BA = B'$ ). It follows that there is a unique Riemannian metric on $\mathrm G_k(\mathbb R^n)$ with respect to which $\pi : \mathrm V_k(\mathbb R^n) \to \mathrm G_k(\mathbb R^n)$ is a Riemannian submersion, meaning for each $B \in \mathrm V_k(\mathbb R^n)$ , $d\pi_B : \ker\left(d\pi_B\right)^\perp \to T_{\pi(B)} \mathrm G_k(\mathbb R^n)$ is a linear isometry. Call this metric $g$ on $\mathrm G_k(\mathbb R^n)$ . My strategy: I know $\mathrm O(n)$ acts on the left transitively and isometrically on $\mathrm V_k(\mathbb R^n)$ , and hence acts transitively and isometrically on $\mathrm G_k(\mathbb R^n)$ , so $\mathrm G_k(\mathbb R^n)$ is homogeneous. So I only need to prove $\mathrm G_k(\mathbb R^n)$ is isotropic and symmetric at a single point; say the subspace $P = \mathbb R^k \subset \mathbb R^n$ , spanned by the first $k$ coordinates. The isotropy group in $\mathrm O(n)$ of this point is $G_P := \mathrm O(k) \oplus \mathrm O(n-k)$ . It seems intuitively obvious that with an appropriate choice of matrix $A \in \mathrm O(k) \oplus \mathrm O(n-k)$ , the differential of the action map $\theta_A : \mathrm G_k(\mathbb R^n) \to \mathrm G_k(\mathbb R^n)$ may either reflect the tangent space at $P$ or act transitively on unit tangent vectors, but I'm having trouble with the specifics. Plus the coordinates of the Grassmannian seem kind of weird and intimidating. Is there a coordinate-free way to make this argument rigorous?","['grassmannian', 'riemannian-geometry', 'differential-geometry']"
3253252,Evaluation of undefined limit,"I am supposed to evaluate this limit. $$\lim_{x\rightarrow 0} \, \frac{\sqrt[3]{x} \ln(\ln x)}{\sqrt[3]{(2x+3)\ln x}}$$ I tried to solve it as two limits, in the way that: $$\lim_{x\rightarrow 0} \, \frac{\sqrt[3]{x}}{\sqrt[3]{2x+3}}$$ $$\lim_{x\rightarrow 0} \, \frac{\ln(\ln x)}{\sqrt[3]{\ln x}}$$ so that the first one is zero, but the second one is not difined for zero. Can anyone help me to continue? Thanks.","['limits', 'calculus', 'limits-without-lhopital', 'real-analysis']"
3253262,Is it possible to have 2 different but equal size real number sets that have the same mean and standard deviation?,"By inspection I notice that Shifting does not change the standard deviation but change mean. {1,3,4} has the same standard deviation as {11,13,14} for example. Sets with the same (or reversed) sequence of adjacent difference have the same standard deviation. For example, {1,3,4} , {0,2,3} , {0,1,3} have the same standard deviation. But the means are different. My conjecture: There are no two distinct sets with the same length, mean and standard deviation. Question Is it possible to have 2 different but equal size real number sets that have the same mean and standard deviation?","['statistics', 'standard-deviation', 'means']"
3253266,"Find $f$ if $f'(t) = 3^t - \frac{3}{t},$ $f(1) = 2,$ and $f(-1) = 1$.","This is problem #38 from section 4.9 of Stewarts Calculus Early Transcendentals 8th edition. I know how these problems are typically solved, but I don't know why in this problem there are two initial conditions on $f$ that seem to contradict each other. Here it is in the book to verify: Here's my work: $$f(t) = \frac{3^t}{\ln(3)} - 3\ln|t| + C.$$ Since $f(1) = 2,$ then $$2 = \frac{3}{\ln(3)} - 3\ln|1| + C,$$ so $$C = 2 - \frac{3}{\ln(3)} \approx -0.73072.$$ However, since $f(-1) = 1$ , then $$1 = \frac{3^{-1}}{\ln(3)} - 3\ln|-1| + C  = \frac{1}{3\ln(3)} - 3\ln(1) + C,$$ so $$C = 1 - \frac{1}{3\ln(3)} \approx 0.69657.$$ My initial thought was that it had something to do with natural log, but the antiderivative should have an absolute value, which should make it okay to plug in negative values. So what's going on here?","['integration', 'logarithms', 'calculus', 'derivatives', 'exponential-function']"
3253279,Commuting elements in product fundamental group,"From Hatcher 1.1.10: From the isomorphism $\pi_1(X \times Y, (x_0, y_0)) \simeq \pi_1(X,x_0) \times \pi_1(Y,y_0)$ it follows that loops in $X \times \lbrace x_0 \rbrace$ and $\lbrace x_0 \rbrace \times Y$ represent commuting elements of $\pi_1(X \times Y, (x_0, y_0))$ . Construct an explicit homotopy demonstrating this. My thinking thus far is that if $a(s)$ is a loop in $X \times \lbrace y_0 \rbrace$ then it induces a loop in $X \times Y$ , $(a(s), y_0)$ , and similarly for a loop $b(s)$ in $Y \times \lbrace x_0 \rbrace$ . It is clear that I want to show that $[(a(s), y_0)] \cdot [(x_0, b(s))] = [(a(s), b(s))] = [(x_0, b(s))] \cdot [(a(s), y_0)]$ but I'm at a loss on how to create a homotopy showing this. Any hints would be appreciated.","['general-topology', 'homotopy-theory', 'algebraic-topology']"
3253319,Sobolev Spaces with different measures,"Consider $H^1(\mathbb{R})$ the standard Sobolev space of functions $f\in L^2$ such that the weak derivative of $f$ is also in $L^2$ . Now, my question is the following: if instead of considering the usual Lebesgue measure you endow $H^1(\mathbb{R})$ with, for instance, the following measure $d\mu=e^{-|x|}dx$ , would usual Sobolev embeddings still hold? I am particularly interested in, for example, the embedding $H^1\hookrightarrow L^\infty$ (which is a basic result in the one-dimensional case for the Lebesgue measure). Can someone recommend me some references to learn a little bit about this kind of questions?","['measure-theory', 'partial-differential-equations']"
3253340,Prove that second partial derivatives are not equal [duplicate],"This question already has an answer here : Show that both mixed partial derivatives exist at the origin but are not equal (1 answer) Closed 5 years ago . $$
f(x,y)=
\begin{cases}
\frac{x^3y-y^3x}{x^2+y^2},\ \ (x,y)\ne(0,0)\\
0,\ \ (x,y)=(0,0)
\end{cases}
$$ I have to prove that $$
\frac{\partial^2f}{\partial x\partial y}\ne
\frac{\partial^2f}{\partial y\partial x}
$$ To be honest, I don't really get this task.
If I find second partial derivatives at $(x,y)\ne(0,0)$ , I'll get total equality because both of them are continuous. If I find either first partial derivative at $(0,0)$ , I'll get $0$ . It seems to me that, therefore, second partial derivatives at $(0,0)$ will be zeros too. So, what am I doing wrong?","['partial-derivative', 'calculus', 'functions', 'derivatives']"
3253367,Is $\sum_{n=1}^{+ \infty}\left(\frac {1}{n}-\frac{1}{p_n}\right)$ convergent?,"It is known that $$\sum_{n=1}^{+ \infty} \frac {1}{n}$$ is divergent. Also, it is known that $$\sum_{n=1}^{+ \infty} \frac {1}{p_n}$$ is divergent where $p_n$ is $n$ -th prime number. I was thinking what would happen (in the sense of convergence) if we termwise subtract these two series to obtain $$\sum_{n=1}^{+ \infty} \left(\frac {1}{n}-\frac{1}{p_n}\right)$$ Is $$\sum_{n=1}^{+ \infty} \left(\frac {1}{n}-\frac{1}{p_n}\right)$$ convergent?","['convergence-divergence', 'calculus', 'sequences-and-series', 'real-analysis']"
3253389,Definition of a closable operator,"Given an unbounded densely defined operator $D: {\frak dom}(D) \subseteq \mathbb{H} \to \mathbb{H}$ , on some Hilbert space $\mathbb{H}$ , it graph is the subspace $$
\mathcal{G}(D) := \{(x,D(x)) \text{ such that } x \in {\frak dom}(D)\}.
$$ We say that an operator is closed if $\mathcal{G}(D)$ is a closed subspace of $\mathbb{H \oplus H}$ . My question is asking of the definition of closure for $D$ . We could say, $D$ is closable if A) the closure of $\mathcal{G}(D)$ in $\mathbb{H \oplus H}$ is the graph of some operator OR B) there exists a closed operator $\widetilde{D}$ such that $\mathcal{G}(D) \subseteq \mathcal{G}(\widetilde{D})$ . Clearly, if $D$ is closable in the sense of A then it is cloasble in the sense of B. Is the opposite inference true? If not what is an instructive example?","['hilbert-spaces', 'functional-analysis', 'unbounded-operators', 'operator-algebras']"
3253398,"Characteristic of a connected, locally compact, Hausdorff space X which is locally connected.","Q. Prove that a connected, locally compact, Hausdorff space X is locally connected if and only if for each compact subset K and each open set U containing K, all but a finite number of components of X-K lie in U. I tried to solve this using the exercise ""Let X be a Hausdorff, locally connected and locally compact space. Let U be a connected subset of X and let x,y∈U. Prove there exists a compact connected subset T of U such that T contains both x,y"" solved by Henno Brandsma, but unable to conclude anything.","['connectedness', 'general-topology', 'locally-connected', 'compactness']"
3253424,Is there a closed form for a give infinite sum?,"I've been asked to evaluate this sum $$\sum_{n=0}^{\infty}\frac{C_n^2}{2^{4n}}(H_{n+1}-H_n)$$ where $C_n=\frac1{n+1}{2n\choose n}$ denotes the $n$ th Catalan number and $H_n$ denotes the nth Harmonic number.
I'm wondering is this sum has a closed form. Update Using the idea of Jack D'Aurizio in this answer , I can write that $$\sum_{n=0}^{\infty}\frac{C_n^2}{2^{4n}}(H_{n+1}-H_n)=\int_0^1 x K(x) \log^2(x)\mathrm{d}x$$ No as he stated in his solution $$ K(x)\stackrel{L^2(0,1)}{=}\sum_{n\geq 0}\frac{2}{2n+1}P_n(2x-1) $$ My question turn out to find the Fourier-Legendre expansion of the function $f(x)=x\log^2(x)$ .","['harmonic-numbers', 'catalan-numbers', 'sequences-and-series']"
3253432,"$\iiint_vz^2\, \mathrm dx \, \mathrm dy\, \mathrm dz$, $x^2 +y^2 +(z-R)^2\leq R^2$","$\iiint_vz^2dxdydz$ , $x^2 +y^2 +(z-R)^2\leq R^2$ . $\theta$ interval will be from $0$ to $2\pi$ . I substituted $x^2 +y^2$ for $r^2$ and got $(z-R)^2\leq R^2 -r^2$ . Thus $z\in[R-\sqrt{R^2-r^2}, R +\sqrt{R^2 -r^2}]$ and $r$ belongs to $[0,R]$ . Is that correct, because I got $0$ from calculating triple integral (understandable, since there is no $\theta$ in primary function $z^2$ or in any interval). Is it correct?","['multivariable-calculus', 'calculus']"
3253439,Is there an effective way to tell whether two homogeneous polynomials are isomorphic?,"Let $f,g\in \mathbb C[x_1,\ldots,x_n]_d$ be two given homogeneous polynomials of degree $d$ . We say they are isomorphic if they differ by a linear coordinates change, i.e. a natural action by some element in $\mathrm{GL}_{n}(\mathbb C)$ . I would like to know that, is there an effective way to tell whether two homogeneous polynomials are isomorphic? I know the Torelli theorem says for curves we can just compute the Jacobian, and there is also a general Torelli theorem works for hypersurfaces. However, it only says the isomorphism classes are determined by some ring structures, and it is still not easy to tell whether two ring structures are isomophic. I would like to know if there are some numbers we can really compute.","['complex-geometry', 'reference-request', 'algebraic-geometry', 'polynomials', 'commutative-algebra']"
3253487,Using residue theorem to calculate following integral,"I'm trying to evaluate the following integral using the residue theorem \begin{align}\label{eq:int_1}
S(z) = \dfrac{1}{2\pi}\int_{0}^{2\pi} \dfrac{e^{i\phi}+z}{e^{i\phi}-z} e^{-\lambda\sin^{2}(\phi/2)} \mathrm d\phi
\end{align} where $\lambda$ is a real positive parameter. Now here's my attempt which I'm pretty sure is incorrect. We can transform the above real integral into a contour integral over the unit circle using the substitution $w = e^{i\phi}$ . First note that - \begin{align}
\exp(-\lambda\sin^{2}(\phi/2)) &= \exp(-\lambda/2)\exp((\lambda/4)(e^{i\phi} + e^{-i\phi})) \\
&= \exp(-\lambda/2)\exp((\lambda/4)(w + 1/w))
\end{align} Therefore the above integral now becomes - $$S(z) = \dfrac{\exp(-\lambda/2)}{2\pi i}\oint_{\mathcal{C}} \dfrac{w+z}{w-z} \exp\bigg(\dfrac{\lambda}{4}\bigg(w + \dfrac{1}{w}\bigg)\bigg)\dfrac{\mathrm dw}{w}
$$ The integrand has singularities at $w = z$ and $w = 0$ (I'm interested in the case when $|z|<1$ ) so we can evaluate the residues at both of these singularities and then employ the residue theorem. The residue at $w = z$ is found to be $$2 \exp\bigg(\dfrac{\lambda}{4}\bigg(z + \dfrac{1}{z}\bigg)\bigg) $$ whereas to evaluate the residues at $w = 0$ , we need to expand the exponential as a power series and keep only all those terms which possess a simple pole at $w=0$ . Since $$\exp\bigg(\dfrac{\lambda}{4}\bigg(w + \dfrac{1}{w}\bigg)\bigg)\dfrac{1}{w} = \sum_{n=0}^{\infty} \dfrac{1}{n!}\bigg(\dfrac{\lambda}{4}\bigg)^{n}\dfrac{(w^2+1)^{n}}{w^{n+1}}$$ and from the binomial  expansion we know that $$(w^2+1)^{n} = \sum_{k=0}^{n} {n\choose k } w^{2k} $$ It's clear that only the terms with even n yield a simple pole since we must have $n=2k$ . And I think finally the residue evaluates to a modified Bessel function of the form $ - I_{0}(\lambda/2)$ where the negative sign comes about from the $(w+z)/(w-z)$ part. And so we obtain $$S(z) = \exp(-\lambda/2)\bigg( 2 \exp\bigg(\dfrac{\lambda}{4}\bigg(z + \dfrac{1}{z}\bigg)\bigg) - I_{0}(\lambda/2) \bigg)$$ But something seems to have gone wrong here since the above expression has a singularity at $z = 0$ whereas the original expression for the function is clearly finite at $z=0$ . I'm really unsure where I've made the mistake. Any help is hugely appreciated. Thanks !!","['integration', 'analysis', 'complex-analysis', 'contour-integration', 'residue-calculus']"
3253522,Limit of a power series in $\beta$ multiplied by $(1 - \beta)$,"Suppose that you are given a bounded sequence of real numbers $|w_k| \le W$ . What should be the limit $\lim_{\beta \rightarrow 1^-}\  (1 - \beta) \sum_{k = 0}^\infty \beta^k w_k$ ? To see that the limit exists, consider that the function $v(\beta) = (1 - \beta) \sum_{k = 0}^\infty \beta^k w_k$ is analytic and that $|v(\beta)| \le (1 - \beta) \sum_{k = 0}^\infty W \beta^k \le W$ so it is bounded near $\beta = 1$ and admits a limit. I guess that is should be something like $\limsup_n \frac1n \sum_{k = 0}^{n - 1} w_k$ but I failed to prove it. Edit: The limit could not exist, see the answer of metamorphy.
I'm still interested if the relation $$ \limsup_{\beta \rightarrow 1^-} \ (1 - \beta) \sum_{k = 0}^\infty \beta^k w_k = \limsup_n \frac1n \sum_{k = 0}^{n - 1} w_k$$ holds or not.","['divergent-series', 'limsup-and-liminf', 'analyticity', 'power-series', 'limits']"
3253527,What is Tarski’s definition of real number multiplication?,"Alfred Tarski came up with the following axiomatization of the real numbers, which only references the notions of “less than” and addition: If $x < y$ , then not $y < x$ . That is,  “ $<$ "" is an asymmetric relation. If $x < z$ , there exists a $y$ such that $x < y$ and $y < z$ . In other words, "" $<$ "" is dense in $\mathbb{R}$ . "" $<$ "" is Dedekind-complete. More formally, for all $X,Y \subseteq \mathbb{R}$ , if for all $x \in X$ and $y \in Y$ , $x < y$ , then there exists a $z$ such that for all $x \in X$ and $y \in Y$ , if $z \neq x$ and $z \neq y$ , then $x < z$ and $z < y$ . $x + (y + z) = (x + z) + y$ . For all $x$ , $y$ , there exists a $z$ such that $x + z = y$ . If $x + y < z + w$ , then $x < z$ or $y < w$ . $1\in\mathbb{R}$ $1 < 1 + 1$ . But it’s still equivalent to the usual axiomatization of the real numbers, which includes axioms for multiplication. Here is what Wikipedia says: Tarski sketched the (nontrivial) proof of how these axioms and primitives imply the existence of a binary operation called multiplication and having the expected properties, so that $\mathbb{R}$ is a complete ordered field under addition and multiplication. This proof builds crucially on the integers with addition being an abelian group and has its origins in Eudoxus' definition of magnitude. My question is, what is Tarski’s definition of multiplication in this system? I skimmed Tarski’s book “Introduction to Logic and to the Methodology of Deductive Sciences”, and I found the above axioms, but I couldn’t find a definition of multiplication or a proof that multiplication satisfies the usual properties.","['real-numbers', 'logic', 'real-analysis', 'ordered-fields', 'second-order-logic']"
3253534,An easy proof that an isometry preserving the zero vector is linear,"I want to show that for real inner product spaces $V$ and $W$ , if $L:V\to W$ satisfies the following properties: $$\parallel L(\vec{x})-L(\vec{y})\parallel=\parallel \vec{x} -\vec{y}\parallel\\$$ and $$L(\vec{0})=\vec{0},$$ then this map is linear. I am aware of the existence of the (more general) theorem of Mazur-Ulam, but I was wondering if there is more accessible proof, which is suitable for beginners in linear algebra. Thanks in advance!","['isometry', 'linear-algebra', 'linear-transformations']"
3253553,Proof confirmation regarding the intersection of an indexed collection of sets,"Let $\{A_\alpha:\alpha \in \Lambda\}$ be an indexed collection of sets. If $\bigcap \{A_\alpha:\alpha \in \Lambda\} \neq \emptyset$ , then for each $\beta \in \Lambda$ , $A_\beta \neq \emptyset$ . My thought was a proof through contraposition: Assume $A_\beta = \emptyset$ for some $\beta \in \Lambda.$ It would follow that the intersection of $A_\beta$ with another set $A_\gamma$ ,  where $\gamma \in \Lambda$ would yield the empty set. Thus $\bigcap \{A_\alpha:\alpha \in \Lambda\} = \emptyset$ . Is this proof valid or did I maybe overlook something. Any thoughts would be appreciated.","['elementary-set-theory', 'proof-verification']"
3253557,Which integer partitions correspond to the most set partitions?,"Which integer partitions of n correspond to the most distinct set partitions? For small n where it is feasible to calculate these values for every integer partition and compare, this is a straightforward exercise with the multinomial function...but beyond that range, what constraints can be put on the form of the integer partitions realizing that maximum? For example, the five integer partitions of n=4 correspond to the block sizes of the fifteen set partitions like so: 4    [1234]
31   [123,4],[124,3],[134,2],[234,1]
22   [12,34],]13,24],[14,23]
211  [12,3,4],[13,2,4],[14,2,3],[23,1,4],[24,1,3],[34,1,2]
1111 [1,2,3,4] Thus 211 is the integer partition yielding the most set partitions for n=4. The optimal partition is not always unique, and its maximum part size doesn't even increase monotonically, so rather than relying on empirical guesswork I was wondering if the underlying patterns had been identified previously, perhaps under a different name. n   max set partitions           int partition
    1   1                            (1,)
    3   3                            (2, 1)
    4   6                            (2, 1, 1)
    5   15                           (2, 2, 1)
    6   60                           (3, 2, 1)
    7   210                          (3, 2, 1, 1)
    8   840                          (3, 2, 2, 1)
    9   3780                         (3, 2, 2, 1, 1)
    13  2702700                      (4, 3, 2, 2, 1, 1)
    16  756756000                    (4, 3, 3, 2, 2, 1, 1)
    18  38594556000                  (4, 3, 3, 2, 2, 2, 1, 1)
    21  17110253160000               (4, 3, 3, 3, 2, 2, 2, 1, 1)
    22  141159588570000              (4, 4, 3, 3, 2, 2, 2, 1, 1)
    23  1298668214844000             (5, 4, 3, 3, 2, 2, 2, 1, 1)
    25  108222351237000000           (4, 4, 3, 3, 3, 2, 2, 2, 1, 1)
    26  1125512452864800000          (5, 4, 3, 3, 3, 2, 2, 2, 1, 1)
    27  11395813585256100000         (5, 4, 4, 3, 3, 2, 2, 2, 1, 1)
    29  1156675078903494150000       (5, 4, 4, 3, 3, 2, 2, 2, 2, 1, 1)
    30  15422334385379922000000      (5, 4, 4, 3, 3, 3, 2, 2, 2, 1, 1)
    31  159364121982259194000000     (5, 4, 4, 3, 3, 3, 2, 2, 2, 1, 1, 1) Equivalently, which monomial/s of the exponential Bell polynomials for a given n have the largest coefficient, as n increases?","['integer-partitions', 'combinatorics', 'extremal-combinatorics']"
3253593,"Properties of the matrix $A = uv^T$, where $u, v \in \mathbb R^{m}$","Clarification: this is a review problem, not a homework problem or anything—I'm not getting graded on this. That being said, I cannot seem to figure out how to do the last part. Consider the matrix $A = u v^T$ , where $u, v \in \mathbb R^{m}$ . (a) What is the rank of $A$ ? Find a basis for the range of $A$ . This part is easy: we know that Range( $uv^T$ ) is just span({ $u$ }). (b) List all eigenvalue of $A$ . What are their geometric and algebraic multiplicities? Since the columns of $A$ are just linear combinations of $u$ , it should be easy to say that 0 is an eigenvalue with geometric and algebraic multiplicity $m - 1$ since the eigenspace associated with $\lambda = 0$ is just Null( $A$ ). The other eigenvalue I feel can only be found through observation: $uv^T*u$ = $u<u, v>$ = $<u, v> u$ , so the eigenvalue is $<u,v>$ with geometric and algebraic multiplicities 1. If there's any other way to find this, please let me know. (c) Find the eigenvector for the nonzero eigenvalue of $A$ . From above: $u$ (d) Find an orthogonal projector onto the range of $A$ . This is pretty obvious again just by looking at the definition of a projector and because Range( $A$ ) = span({ $u$ }): $\frac{1}{\|u\|^2}uu^T$ . (e) Find an orthogonal projector onto the nullspace of $A$ . No idea. I'm having a sort of disconnect here and really can't figure it out.","['matrices', 'projection-matrices', 'linear-algebra']"
3253619,"Jacobian Variety, analytic definition","Define a map as follows: $$
\varphi:H_1(C, \mathbb{Z}) \longrightarrow H^0(\omega_C)^*, \, \,  [\gamma]\longmapsto (\omega \longmapsto \int_{\gamma}\omega).
$$ where $H^0(\omega_C)$ is the $g$ -dimensional $\mathbb{C}$ -vector space of holomorphic 1-forms and $H_1(C, \mathbb{Z})$ is the homology group of $C$ . It is a fact that the $\varphi$ map is injective. How to conclude this fact that $H_1(C, \mathbb{Z})$ is a lattice in $H^0(\omega_C)^*$ ? Another question is: the quotient $\frac{H^0(\omega_C)^*}{H_1(C, \mathbb{Z})}$ a quotient between groups? Thanks","['algebraic-geometry', 'abelian-varieties']"
