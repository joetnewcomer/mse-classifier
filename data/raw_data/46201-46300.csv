question_id,title,body,tags
463051,Beach Path math question,"Anyone who has walked on the beach knows that walking speed is dependent upon how far away from the ocean one walks. If you walk on the wet sand you can walk much more quickly than if you walked on the dry sand. I have a question that discusses this principal. On a Cartesian $xy$ plane limited by: Domain: {$x|0 \le x \le 1$} Range: {$y|0 \le y \le 1$} you start at the point ($0,0$) and you would like to travel on a defined path to ($1,1$) in the shortest amount of time. This sounds simple just take the path $y=x$ because it is the shortest path so it will take the shortest amount of time, but there is a catch. Your forward speed $\frac{dS}{dt}$ is equal to ($1âˆ’\frac{3}{4}y$). With this constraint in mind the path $y=x$ would not be the fastest path. What is the fastest path. I am open to questions about the problem itself if I have not been clear. Thank you.","['geometry', 'calculus-of-variations']"
463073,Why does the Cauchy-Schwarz inequality hold in any inner product space?,"I am working through linear algebra problems in Apostol's Calculus , and he has numerous problems that seem to imply that Cauchy-Schwarz holds no matter how the inner product is defined. Then, he has problems where the triangle inequality holds despite alternative definitions of vector norm. This got me thinking, since the proof of the triangle inequality in Apostol relies on Cauchy-Schwarz, that the triangle inequality would hold regardless of how the vector norm is defined (if it involves the dot product). I then found this response to a question, which states what I was thinking. Are there any proofs that the Cauchy-Schwarz inequality holds in any inner product space (I looked for some and found none and could not prove it myself)? I've had a semester of algebra (Artin) and some analysis, if there is a proof at such a level of understanding. Intuitive explanations are good, too.","['inner-products', 'linear-algebra', 'inequality']"
463079,How can every $p$-adic integer be the limit of a sequence of non-negative integers?,"See Andrew Baker's P-adic Notes .  Every element of $\mathbb{Z}_p = \{a \in \mathbb{Q}_p : |a|_p \leq 1 \}$ is a limit of a sequence of non-negative integers, with respect to the $|\cdot|_p$ norm.  How is this possible?","['p-adic-number-theory', 'algebraic-number-theory', 'abstract-algebra', 'analysis']"
463082,"Does ""independence"" of moments imply independence?","Suppse you have two random variables $X,Y$ and you are given that for any $m,n$ that: $$E(X^n Y^m) = E(X^n)E(Y^m)$$ Does this imply that $X$ and $Y$ are independent? Are there some condtions on how fast the moments grow can be added to help? Attempt at solution:
I know that if the characteristic functions split like $E(e^{i(X,Y)\cdot(s,t)}) = E(e^{iXs})E(e^{iYt})$, (where $.$ is the Schur product) then the RV's are independent. I would try to approximate this by the moments. However, I think you might need some condition that the moments don't grow too fast to make this work.","['probability-theory', 'probability', 'characteristic-functions']"
463092,"Prove that if $gcd(a, b) = c$ then $c^2|ab$.","I recently just started this topic in class and have been going over some examples without much success. I understand the concept behind if a|b and b|c then a|c but when it comes to more complex ones, I become a  tad confused.. *Thanks for the help everyone!!",['discrete-mathematics']
463110,Inverse of a function $e^x + 2e^{2x}$,"The function is $f(x) = e^x+2e^{2x}$ So to find the inverse I went $$WTS: x = ____$$ $$y =  e^x+2e^{2x}$$ $$ log3(y)=log3(3e^{2x})$$
$$ log3(y) = 2x$$
$$ log3(y)=5x$$
$$ x=\frac{log3(y)}{2}$$ Am i correct?","['calculus', 'algebra-precalculus']"
463127,Does this integral have a closed form expression?,"I have been working with two related integrals. The first one yields a simple expression, but I can't seem to find a simple expression for the second. Integral 1 $$ \begin{align*}
I_x &= \int_z^{1-y+z} \sqrt{\frac{1}{1-x-y+z} + \frac{1}{x-z}} \, dx\\
&= \int_z^{1-y+z} \sqrt{\frac{1-y}{(1-x-y+z)(x-z)}} \, dx\\
&= \sqrt{1-y} \int_z^{1-y+z} \frac{1}{\sqrt{(1-x-y+z)(x-z)}} \, dx\\
\end{align*} $$ We can substitute $u=\frac{x-z}{1-y}$, so $x=u(1-y)+z$, and $dx=(1-y) \, du$. Then we have: $$ \begin{align*}
I_x &= \sqrt{1-y} \int_0^1 u^{\frac{1}{2}-1}(1-u)^{\frac{1}{2}-1} \, du\\
&= \sqrt{1-y} \, \operatorname{B} \left( \tfrac{1}{2}, \tfrac{1}{2} \right)\\
&= \sqrt{1-y} \, \pi
\end{align*} $$ So this integral has a simple expression because the substitution led to the exact form of the beta function. Integral 2 $$ I_z = \int_{\max(0,x+y-1)}^{\min(x,y)} \sqrt{\frac{1}{1-x-y+z} + \frac{1}{x-z} + \frac{1}{y-z} + \frac{1}{z}} \, dz $$ This seems related to the first integral, but I can't seem to simplify it. Even if we assume one of the four ""cases"" of integration limits ($\int_0^x$, $\int_0^y$, $\int_{x+y-1}^x$, or $\int_{x+y-1}^y$) and try to proceed, it doesn't seem to help. Am I missing something simple? Is there an obscure integration technique that would help? Or is there just no way to simplify this? Update (6-26-14): From Jacquet & Szpankowski, 2003, ""Markov Types and Minimax Redundancy for Markov Sources"" ( link ), p.10, we have the following, which may (or may not) help here: $$ \begin{align*}
I_{JS} &= 4 \int_0^1 \frac{1}{\sqrt{(1{-}x)x}} \, dx \int_0^{\min(x,1{-}x)} \frac{1}{(1{-}x{-}y)(x{-}y)} \, dy\\
&= 8 \int_0^{\frac{1}{2}} \frac{\log(1{-}2x) - \log\left(1{-}2\sqrt{(1{-}x)x}\right)}{\sqrt{(1{-}x)x}} \, dx\\
&= 16 \int_0^{\frac{\pi}{4}} \log \left( \frac{\cos(2\theta)}{1{-}\sin(2\theta)} \right) \, d\theta\\
&= 16 \, G\\
\end{align*} $$ where $G \approx 0.915965594$ is Catalan's constant .","['definite-integrals', 'integration']"
463139,Symmetry functions and integration,"I have this: Case 1) If f is a pair function $f(-x)=f(x)$ then $\int_{-a}^a f(x)dx=2\int_0^af(x)dx$ Case 2) If $f$ is a inpair function $f(-x)=-f(x)$ then $\int_{-a}^a f(x)dx=0$ I understand the reasons for the case 1 to be double area and for case 2 to be zero, but, I'll be grateful if some one can tell me a little more of this symmetry aspect How can I realize when and where this symmetry exist in a function Particularly will be helpful if someone explain how to interpret $f(-x)=-f(x)$ and $f(-x)=f(x)$ I'd to understand better what do they imply",['calculus']
463174,How To Slice $Re(1/(1+z))$ Into A Cartesian Function For Any Angle?,"The complex function $\frac{1}{1+z^2}$  may be broken into real and imaginary components : $$Re \bigg(\frac{1}{(1+z^2)}\bigg)=\frac{1+x^2-y^2}{(1+x^2-y^2)^2+4x^2y^2}$$ $$Im \bigg(\frac{1}{(1+z^2)}\bigg)=\frac{-2xyi}{(1+x^2-y^2)^2+4x^2y^2}$$ Graphing the real components and colouring them according to the imaginary components yields: Slicing the graph of the real components along the x-axis yeilds the graph of $\frac{1}{1+x^2}$, which is: Slicing the graph of the real components along the y-axis yields the graph of $\frac{1}{1-x^2}$, which is: Is it possible to write a cartesian equation equivalent to slicing the above 3D graph of $Re(1/(1+z))$ for any angle between the x and y axes? For your convenience see the graph the $Re(1/(1+z^2))$ on Wolfram Alpha ! Note that graphing the imaginary components yields something entirely different .","['complex-numbers', 'terminology', 'functions', 'graphing-functions']"
463190,"Show that $\gcd(a + b, a^2 + b^2) = 1\mbox{ or } 2$ [duplicate]","This question already has answers here : How can I find the possible values that $\gcd(a+b,a^2+b^2)$ can take, if $\gcd(a,b)=1$ (6 answers) Closed 10 years ago . How to show that $\gcd(a + b, a^2 + b^2) = 1\mbox{ or } 2$ for coprime $a$ and $b$? I know the fact that $\gcd(a,b)=1$ implies $\gcd(a,b^2)=1$ and $\gcd(a^2,b)=1$, but how do I apply this to that?","['elementary-number-theory', 'algebra-precalculus', 'contest-math']"
463197,Prove that $\sum\limits_{i=1}^{n-k} (-1)^{i+1} \cdot \frac{(k-1+i)!}{k! \cdot(i-1)!} \cdot \frac{n!}{(k+i)! \cdot (n-k-i)!}=1$,"Prove that, for $n>k$, $$\sum\limits_{i=1}^{n-k} (-1)^{i+1} \cdot \frac{(k-1+i)!}{k! \cdot(i-1)!} \cdot \frac{n!}{(k+i)! \cdot (n-k-i)!}=1$$ I found this problem in a book at the library of my my university, but sadly the book doesn't show a solution. I worked on it quite a long time, but now I have to admit that this is above my (current) capabilities. Would be great if someone could help out here and write up a solution for me.","['summation', 'sequences-and-series']"
463203,Prove that $D_3 \oplus D_4$ is not isomorphic to $D_{12}\oplus\mathbb Z_2$,"This is a problem from the textbook, doing this for practice and not assignment. Prove that $D_3 \oplus D_4$ is not isomorphic to $D_{12}\oplus\mathbb Z_2$. So we know $|D_3| = 6$ and $|D_4| = 8$ then $|D_3\oplus D_4| = 6\cdot 8 = 48,$ and similarly $|D_{12}\oplus\mathbb Z_2| = 24\cdot 2 = 48.$ So the groups are of same size. We can also see that none of the groups are cyclic since orders of the individual groups are not relatively prime. Would there be a intuitive way of approaching this question, rather then looking at the number of elements of each order in the two groups?","['finite-groups', 'group-theory', 'abstract-algebra']"
463216,Counting numbers of the form $ai + bj + cij$ and finding related L-series?,"Let $a,b,c$ be given nonnegative integers with $gcd(a,b,c)=1$. Consider a given positive integer $n$ and positive integers $i,j$. Let $f_n(a,b,c)$ be the number of distinct solutions to $1<ai + bj + cij<n$. As an example $f_n(1,1,2) = n-(\pi(2n+1)-1)$ where $\pi$ is the prime counting function. And ofcourse $f_n(0,0,1)=n-\pi(n)$. Other easy ones are $f_n(0,b,c)$ or $f_n(a,b,0)$. But how about the general case ?? How about $f_n(2,3,5)$ ? I assume there is alot of theory behind this such as closed form identities, recursions, related L-series, GRH analogues and sieves. And what about the circle method ; can it be used here ? Are there generalizations to PNT involved ? I would like to understand $f_n(a,b,c)$ better. EDIT !! I have seen tommy1729 today and he guessed that for $a=2,2<p<q$ and $p,q$ a prime twin or a sophie germain prime pair, we have that $f_n(2,p,q)$ ~ $n - \dfrac{\alpha\pi(n)}{q!}$ where $\alpha$ is an integer. For instance $f_n(2,3,5)$ should be about $n - \dfrac{\pi(n)}{k}$ where $k$ is $2$ or $3$.
The ""logic"" is suppose to be that we sieve out multiples of type $5n+2$ or $5n+3$ for numbers of type $5n + 6$ as explained by Gerry Myerson's answer. This sieved part is suppose to be something like $\dfrac{n}{\sum \dfrac{1}{5y+m}}$ for $m=2,3$ or such, from where $n - \dfrac{\pi(n)}{k}$ follows. I wondered about products like $\prod_{X=5n+2} (1-\dfrac{1}{X})$. I was fascinated by that quick brute guess he made. Could it be true ? COMMENT I forgot to mention sophie germain prime pair in my first edit so I edited my first edit, and by this comment I hope this does not go unnoticed. Sorry for being sloppy.","['zeta-functions', 'sieve-theory', 'number-theory', 'prime-numbers', 'dirichlet-series']"
463218,Show thereâ€™s at most $n\choose \left \lfloor\frac{n}{2} \right\rfloor$ subsets $A\subset[n]$ such that $\displaystyle\sum\limits_{i\in{A}} a_i=\alpha$,"Let $a_1, a_2, a_3, ... , a_n$ and  $\alpha$ be n+1 non-zero real numbers. Prove that there are at most $n\choose \left\lfloor\frac{n}{2}\right\rfloor$ subsets $A\subset[n]$ such that $\displaystyle\sum\limits_{i\in{A}} a_i=\alpha$ I'm not quite sure how to approach this but I suspect it is something to do with the fact that every antichain is size at most $n\choose \left \lfloor \frac{n}{2} \right \rfloor$. I was thinking that all such $A$ that satisfy the condition could somehow relate to an antichain, but I don't quite see how this works, especially since if (say) $x_1+x_2=\alpha$ and $x_1+x_2+x_3+x_4=\alpha$ this would relate to the sets $\left\{ {1, 2}\right\}$ and $\left\{ {1, 2, 3, 4}\right\}$ which clearly isn't part of an antichain. Any help would be very much appreciated!","['additive-combinatorics', 'extremal-combinatorics', 'number-theory', 'combinatorics']"
463227,Solving inequalities at powers greater than $2$,"Usually when I see an inequality like $x^2 - 6x - 16 < 0$, I know that the answer is $-2 < x < 8$ because I can picture where the graph would lie below zero. However, for a problem like $x^2(x+5)^3(x-3) \ge 0$, I'm not sure how to set up the inequalities because I can't picture a graph like this as easily. I'm not supposed to use a calculator for this, and I highly doubt my teacher is expecting us to plot points. Is there a trick to figure out inequalities greater than the second power by using the number of exponents given?","['inequality', 'algebra-precalculus']"
463266,Pythagorean Quadruples:,"Consider the set of integers $x_1, x_2, x_3, x_4$ Such that: $$x_1^2 + x_2^2 + x_3^2 = x_4^2$$ How does one compute all the solutions to this system? I have the following method in place for computing solutions given the initial condition that $$x_1^2 + x_2^2 = y^2$$ for some integer $y$. One can make the standard Pythagorean triple reduction given this condition and then repeat the reduction again thus generating a general solution for all integers. But what if there exists 3 square numbers such that the sum of any 2 squares in this set if not a square but the sum of all 3 squares is a square? I have no reason to rule out this possibility and no way of generating such solutions As a side note: Given a number and told that it is part of a Pythagorean triple (let's say it's the hypotenuse) how do you find the other squares that sum to it?","['sums-of-squares', 'elementary-number-theory', 'diophantine-equations', 'number-theory']"
463269,"Proving that $\left\lfloor\frac{n m -1}{m-1}\right\rfloor, n>0, m>0$ yields only natural numbers that is not a multiple of $m$","Let $A(n,m)$ denote a set such that: $$A(n,m) = \{k\in\mathbb{N}_{>0} \mid (j \in \mathbb{N}) \wedge (k \neq jm)\} \implies$$
$$A(n,2) = \{1,3,5,7,\dots\}$$
$$A(n,4) = \{1,2,3,5,6,7,9,\dots\}$$ To be more explicit: $A(n,m)$ denotes the $n$th natural number larger than $0$, which is not a product of $m$ and any natural number, $j$. How could one prove that: $$A(n,m) = \left \lfloor \frac{n m -1}{m-1} \right \rfloor$$ Any help with tagging more appropriately would be appreciated!","['natural-numbers', 'elementary-set-theory']"
463270,Showing $E(\Omega)$ is a Hilbert Space,"Let $E(\Omega)=\{ u\in \{L^2 (\Omega)\}^n : \text{div } u \in L^2(\Omega)\}$, that is $E(\Omega)$ consists of vector valued functions $u=(u^1, \cdots , u^n)$ where each component function $u^i$, $i\in \{ 1, \cdots n\}$ is a $L^2(\Omega)$ function and $\frac{\partial u^1}{\partial x_1}+\cdots+\frac{\partial u^n}{\partial x_n}\in L^2(\Omega)$. We want to show that under the norm induced by this inner product $$
(u,v)_{E(\Omega)}=\sum_{i=1}^{n} (u_j, v_j)_{L^2(\Omega)}+(\text{div } u, \text{div }v)_{L^2(\Omega)}
$$ $(E(\Omega), ||.||_{E(\Omega)})$ is a Hilbert Space. This is what I manage to do. Suppose $\{u_m=(u^1, \cdots , u^n)\}_{m\in \mathbb{N}}$ is a Cauchy sequence in $(E(\Omega), ||.||_{E(\Omega)})$. Fix $i \in \{1,\cdots, n \}$. Because $(u^i_m-u^i_l, u^i_m-u^i_l )$=$||u^i_m-u^i_l ||^2_{L^2(\Omega)} \leq  ||u_m-u_l||^2_{E(\Omega)}$ and the fact that $\{u_m=(u^1, \cdots , u^n)\}_{m\in \mathbb{N}}$ is a Cauchy sequence in $(E(\Omega), ||.||_{E(\Omega)})$, we see that $\{u^i_m\}_{m\in\mathbb{N}}$ is Cauchy in $L^2(\Omega)$. By the completeness of $L^2(\Omega)$, we concluded that $u^i_m \rightarrow u^i \in L^2(\Omega)$ in $L^2$ norm as $m\rightarrow \infty$. Hence we concluded that $u=(u^1, \cdots, u^n) \in \{L^2(\Omega)\}^n$. Also note that $$
(\text{div }(u_m-u_l), \text{div }(u_m-u_l))_{L^2(\Omega)}=||\text{div } u_m - \text{div } u_l||^2_{L^2(\Omega)}\leq ||u_m-u_l||^2_{E(\Omega)}
$$ Hence $\{\text{div } u_m\}_{m\in\mathbb{N}}$ is Cauchy  in $L^2(\Omega)$. Again by the completeness of $L^2(\Omega)$, we can conclude that $\text{div } u_m \rightarrow g\in L^2(\Omega)$ in $L^2$ norm as $m \rightarrow \infty$. Now to show $u \in E(\Omega)$, we need to show $\text{div } u$ exists and is also in $L^2(\Omega)$. This is achieved by showing $g=\text{div }u$. But this is where I get stuck, how do we show this last part? I don't even know that the partial derivative of $u^i$ exists. Thanks.","['partial-differential-equations', 'real-analysis']"
463279,Identifying a line bundle on $\mathbb{P}^1$,"I have a geometric line bundle $L$ on $\mathbb{P}^1 = \{[x_0:x_1]\}$.  With respect to the standard affine cover $U_0 = \{x_0 \neq 0\}$ and $U_1 = \{x_1 \neq 0\}$, I have the transition function $[x_0:x_1] \mapsto (\frac{x_0}{x_1})^n$.  If I'm not mistaken, the invertible sheaf of sections $\mathscr{L}$ associated to this line bundle should be
\begin{align*}
\mathscr{L}(U) = \{&(h_0: U \cap U_0 \to k, h_1: U \cap U_1 \to k) \mid \\ &h_0([x_0:x_1]) = (\frac{x_0}{x_1})^n h_1([x_0:x_1]) \text{ on } U \cap U_0 \cap U_1\} \\
\Gamma(\mathbb{P}^1, \mathscr{L}) = \{&(h_0 \in k[x_0,x_1,x_0^{-1}], h_1 \in k[x_0,x_1,x_1^{-1}]) \mid \frac{h_0}{x_0^n} = \frac{h_1}{x_1^n} \text{ on } U \cap U_0 \cap U_1\}.
\end{align*} By the classification of line bundles on projective space, the sheaf $\mathscr{L}$ is isomorphic to $\mathscr{O}_{\mathbb{P}^1}(m)$ for some $m \in \mathbb{Z}$.  My question is: which $m$ is it? My guess is that $\mathscr{L} \cong \mathscr{O}_{\mathbb{P}^1}(-n)$, but I can't seem to show this.  In fact, the sheaf I wrote down doesn't even seem to be coherent since there is no bound on the degrees of $h_0$ and $h_1$, so I must be doing something wrong.  Can someone help me out?","['sheaf-theory', 'algebraic-geometry', 'vector-bundles', 'projective-space']"
463281,Problem on quasi - compact morphisms of schemes,"I am doing a problem a problem in Hartshorne (2.3.2) which asks to show that a morphism of schemes $f : X \to Y$ is quasi compact iff for every affine open $U \subseteq Y$, $f^{-1}(U)$ is quasi compact. Now one direction is tautological so for the other direction take $U \subseteq Y$ an affine open subset. Let $\{V_i\}$ be a cover of $Y$ by open affines such that for every $i$, $f^{-1}(V_i)$ is quasi - compact. Then for every $i$ we can write $$U \cap V_i =  \bigcup_{j} V_{ij}$$ where the $V_{ij}$ are open and principal in both $U$ and $V_i$ . Since $\bigcup_i (U \cap V_i) = \bigcup_i \bigcup_j V_{ij}$ is an open cover of $U$ and since $U$ is quasi compact, this means $U = \bigcup_{k=1}^n V_{i_k j_k}$ for some indices $i_k,j_k$. Thus $f^{-1}(U)$ is a finite union of the open sets $f^{-1}(V_{i_k,j_k})$. Now if each of these is quasi - compact then $f^{-1}(U)$ being a finite union of quasi - compact sets is quasi - compact. My question is: Why is each $f^{-1}(V_{i_k,j_k})$ quasi - compact? I know that for every $i_k$, $f^{-1}(V_{i_k})$ can be covered by a finite union of open affine sets by assumption. Does this mean then that $f^{-1}(V_{i_k,j_k})$ is principal in each of these open affines (and thus quasi - compact)?",['algebraic-geometry']
463286,"Are (some) axioms ""unprovable truths"" of Godel's Incompleteness Theorem?","Like any math newbie, Godel's Incompleteness Theorems are easy to understand in general layman's terms, but difficult to understand beyond the typical ""liar's paradox"" and ""barber's paradox"" type examples. But then I started thinking, are axioms examples of the truths of mathematics that can't be proven?  For example, Peano's Postulates: a very popular ""starting point"" for deducing other mathematical truths.  One of the postulates is, ""0 is a natural number.""  Well wait a second: what is ""0""? What is a ""natural number""?  In order to take that axiom as a truth, there must be a definition for what 0 is, and what a natural number is.  But even if we assign them definitions in English, can those definitions be proven ? If I follow this train of thought, I eventually find myself completely outside of mathematics, and more into philosophy --- can we even prove what a ""natural number"" actually is ?  If I'm not careful, eventually I end up in lala land thinking about the meaning of existence and reality itself. Does this even make sense?  My mind has been blown so many times on this topic, I spend more time scooping my brain off the floor than forming coherent questions.","['logic', 'axioms', 'discrete-mathematics', 'incompleteness']"
463292,Find a basis of $V$ containing $v$ and $w$,"Find a basis of $V$ containing $v$ and $w$, where $V=\mathbb{R}^4, v=(0,0,1,1), w=(1,1,1,1)$. I am not sure how to begin so a hint would be appreciated. I suspect I must use the following fact: If $V$ is a finite dimensional vector space and if $U$ is a subspace of $V$, then any independent subset of $U$ can be enlarged to a finite basis of $U$. Alright, here's my stab at an attempt for a solution: $V_{\text{basis}}=\{(0,0,1,1),(1,1,1,1),(0,0,0,1),(1,0,0,0) \}$ Would this be correct? The two vectors I added to the basis were the standard basis vectors for $\mathbb{R}^4.$","['vector-spaces', 'linear-algebra', 'solution-verification']"
463308,How to find the sum $\sum\limits_{k=1}^n (k^2+k+1)k!$?,How to find the sum $$\sum^n_{k=1} (k^2+k+1)k!$$ What I tried as follows : $$\sum^n_{k=1} (k^2+k+1)k!$$ =$$\sum^n_{k=1} (k^2)k!+ \sum^n_{k=1} (k)k! + \sum^n_{k=1} (1)k!$$ Now we can write $\sum^n_{k=1} (k^2) $ as $$\frac{n(n+1)(2n+1)}{6}$$ but what to do with $k!$ please guide thanks.......,"['sequences-and-series', 'algebra-precalculus']"
463309,"Prove that, $f:\mathbb{R}\rightarrow \mathbb{R} $ is a isomorphism if, only if $f(x)=x $.","Prove that, $f:\mathbb{R}\rightarrow \mathbb{R} $ is a isomorphism if, only if $f(x)=x $. For any rational element that is right, but do not know how to prove to the irrational. I would like to prove it using only the properties of complete ordered field.","['calculus', 'real-analysis']"
463321,Primes of ramification index 1 with inseparable residue field extension,"I've been reading through Neukirch's Algebraic Number Theory , and I'm a little puzzled about a possibility with ramification of primes. As usual, let $\mathcal{O}_K$ be a Dedekind domain with field of fractions $K$, let $L/K$ be a finite algebraic extension, and let $\mathcal{O}_L$ be the algebraic closure of $\mathcal{O}_K$ in $L$. Let $\mathfrak{p}$ be a prime of $\mathcal{O}_K$, and let $\mathfrak{p} = \prod_{i=1}^{r} \mathfrak{P}_i^{e_i}$ be its prime factorization in $\mathcal{O}_L$. Neukirch defines $\mathfrak{P}_i$ to be unramified over $\mathcal{O}_K$ provided that $e_i = 1$ and the residue field $\mathcal{O}_L/\mathfrak{P}_i$ is separable over $\mathcal{O}_K/\mathfrak{p}$. It's the latter condition that has me wondering: What if $e_i = 1$, but the residue field extension is inseparable (perhaps even purely inseparable)? In other words, can a prime be ramified despite having ramification index 1? The definition suggests it can, but no examples readily come to mind, probably because most of the examples I've worked with are perfect fields. Also, is there some good geometric way of thinking about what it means for a point to be ramified with ramification index 1? I usually think of ramification points as ""points with multiplicity"" or something along those lines, but that doesn't make sense if $e_i = 1$. Is there an example â€” ideally, a reasonably natural one â€” that illustrates this phenomenon?","['arithmetic-geometry', 'algebraic-number-theory', 'abstract-algebra']"
463342,Prove that there's no fractions that can't be written in lowest term with Well Ordering Principle,"This is from Class Note from 6.042 ocw courses at MIT: ""Well Ordering Principle"" section: ( Sorry for not posting latex; I have less than 10 reputations to post images ) You can read the original here at page 1 and 2; Well Ordering Principle: http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-042j-mathematics-for-computer-science-fall-2010/readings/MIT6_042JF10_chap03.pdf In fact, looking back, we took the Well Ordering Principle for granted
  in proving that $\sqrt{2}$ is irrational. That
  proof assumed that for any positive integers $m$ and $n$, the fraction $\frac{m}{n}$
  can be written in lowest terms, that is, in the form $\frac{m'}{n'}$ where $m'$
  and $n'$ are positive integers with no common factors. How do we know
  this is always possible? Suppose to the contrary that there were $m$, $n$ in $\mathbb{Z}^+$ such that the fraction $\frac{m}{n}$ cannot be written in lowest
  terms. Now let $C$ be the set of positive integers that are numerators
  of such fractions. Then $m$ in $C$, so $C$ is nonempty. Therefore, by Well
  Ordering, there must be a smallest integer, $m_0$ in $C$. So by definition of
  $C$, there is an integer $n_0 > 0$ such that the fraction $\frac{m_0}{n_0}$ cannot be
  written in lowest terms. This means that $m_0$ and $n_0$ must have a common
  factor, $p > 1$. But $(\frac{m_0}{p}) / (\frac{n_0}{p}) = \frac{m_0}{n_0}$ so any way of expressing the left hand fraction in lowest terms would
  also work for $\frac{m_0}{n_0}$, which implies the fraction($\frac{m_0}{p}) / (\frac{n_0}{p})$ cannot be in written in lowest terms either. So by definition of $C$, the numerator, $\frac{m_0}{p}$, is in $C$. But $\frac{m_0}{p} < m_0$,
  which contradicts the fact that $m_0$ is the smallest element of $C$. Since
  the assumption that $C$ is nonempty leads to a contradiction, it follows
  that $C$ must be empty. That is, that there are no numerators of
  fractions that canâ€™t be written in lowest terms, and hence there are
  no such fractions at all. I don't really understand the part where, the author says: So by definition of $C$, there is an integer $n_0 > 0$ such that: $\frac{m_0}{n_0}$ cannot be written in lowest terms. This means that $m_0$ and $n_0$ must have a common factor, $p > 1$. Why $\frac{m_0}{n_0}$ cannot be written in lowest terms means $m_0$ and $n_0$ must have a common factor? What does '$\frac{m_0}{n_0}$ cannot be written in lowest terms' actually means? I'm not native English speaker so it may be confusing at places to understand the words. And I don't quite understand this statement, too: But: $(\frac{m_0}{p}) / (\frac{n_0}{p}) = \frac{m_0}{n_0}$ so any way of expressing the left hand fraction in lowest terms would also work for $\frac{m_0}{n_0}$, which implies the fraction $(\frac{m_0}{p}) / (\frac{n_0}{p})$ cannot be in written in lowest terms either. Thanks!",['discrete-mathematics']
463353,Question about a proof showing that the center of $S_n$ is trivial,"How do I need to modify this in order for it to be correct? The center of $S_n$ (for $n\geq$ 3) is the trivial identity. Proof: Assume the center of $S_n$ is $C = \{ id , \tau \}$ where $ \tau \in S_n$ and $\tau \neq \ id$. Then for some $n$ the factor group $S_n\backslash C$ is abelian and solvable, a contradiction.","['permutations', 'symmetric-groups', 'group-theory', 'abstract-algebra']"
463357,What is the intuitive or geometric explaination of fractional derivatives?,"I'm starting to study more advanced solid mechanics, particularly understanding elastomers' stress strain relationships and creep. A common way of describing the variation in the aforementioned relationship as the material is cycled to describe energy loss due to entropy change and this is mathematically described using fractional derivatives. Is there an intuitive description for a fractional derivative? To use extremely simple calculus examples, by intuitive, I mean the way derivatives are described as rates of change of one variable with respect to another and integrals are described as net change. Or a geometric interpretation such as slopes of lines and areas under curves.","['fractional-calculus', 'calculus']"
463375,limit of absolute value of something equals absolute value of limit of something?,"Does limit of  absolute value of something always equal absolute value of limit of something?
Specifically, can I just say the below equality is true or do I need to prove it?
I'm not sure how to prove it.
Could you help me?","['calculus', 'real-analysis']"
463415,Angle between two 3D lines,"I know  for given 2 vector $\vec{u},\vec{v}$ the angle between them achieved by -  $$\cos{\theta} = \frac{\vec{u} \cdot \vec{v}}{\|\mathbf{u}\|\|\mathbf{v}\|}$$ but what if I want to calculate the $\theta$ between two 3D line   ? For example given 2 lines which each of them represented by two 3D points  - 
$$line1: (3,2,-5)\hspace{5 mm }, (1,1,1) \\ line2: (1,-4,6)\hspace{5 mm }, (1,1,1)$$ How should I caclculate the angle $\theta$ between those 2 lines ?","['linear-algebra', '3d']"
463436,On a conformal mapping,"I was asked to find a one-to-one analytic map $f$ of unit disc $\mathbb{D}\subset \mathbb{C}$ so that $\mathbb{D}$ is mapped to $\{(x,y):y<x^2\}$. I thought the core procedure could be done by certain one-to-one holomorphic function, say $g(z)=z^2$ on $(-1,1)\times(0,\infty) \subset \mathbb{C}$(which is one-to-one), but this maps to some field of parabolic that does not contain an interval: $\{(x,y);x\leq 1-y^2/4\}\setminus [0,1]$. I found it difficult to overcome the wield displacement of $[0,1]$, or was I going ahead in a wrong way? Thanks for the comment below it suffices to choose domain such as $H:=\{\Re z>1\}$ we can get the desired conformal map. But now I am concerned if the target set is the other side of the parabola, say, $\{(x,y):y>x^2\}$? It seems function $z \to z^2$ does not send simple domain to the other side of the parabola, so how should I modify my conformal mapping at this time?",['complex-analysis']
463468,How to prove the continuity of the functional $v \mapsto \int \vert v \vert^2$ on this function space?,"I am trying to prove the continuity of the functional \begin{equation} f: v \mapsto \int_{\mathbb{R}^N} \vert v \vert^2 \end{equation}
on the space \begin{align} V(\mathbb{R}^N) = \lbrace v = v_1 + i v_2 : \mathbb{R}^N \to \mathbb{C} ~ | ~ &\nabla v \in L^2(\mathbb{R}^N), \\ &v_1 \in L^2(\mathbb{R}^N), \\ &v_2 \in L^4(\mathbb{R}^N),\\ & \nabla v_1 \in L^\frac{4}{3}(\mathbb{R}^N)  \rbrace,  \end{align} equipped with the norm $$ \Vert v \Vert_{V(\mathbb{R}^N)} = \Vert \nabla v \Vert_{L^2(\mathbb{R}^N)} + \Vert v_1 \Vert_{L^2(\mathbb{R}^N)} + \Vert v_2 \Vert_{L^4(\mathbb{R}^N)} + \Vert \nabla v_1 \Vert_{L^\frac{4}{3}(\mathbb{R}^N)}.$$ Now, if I try to prove the continuity I choose $v,w \in V(\mathbb{R}^N)$ such that $$ \Vert v - w \Vert_V < \delta $$ for some $\delta>0$. In particular, $$\Vert \nabla v \Vert_{L^2(\mathbb{R}^N)} = \int \vert \nabla v_1- \nabla w_1 \vert^2+\vert \nabla v_2-\nabla w_2 \vert^2< \delta.$$  I go on to compute \begin{align} \vert f(v) - f(w) \vert &=  \left\vert \int \vert \nabla v \vert^2 - \int \vert  \nabla w \vert^2 \right\vert \\ &= \left\vert \int \vert\nabla v_1\vert^2 - \vert\nabla w_1\vert^2 + \vert \nabla v_2 \vert^2 - \vert\nabla w_2\vert^2  \right\vert \end{align} Here I'm stuck. How do I show that this is smaller than any $\varepsilon>0$ if only $\delta$ is small enough? Or is there another way to show the continuity? Any hint is much appreciated! EDIT. In the contrary: $\vert \vert a \vert^2-\vert b \vert^2 \vert \not\leq C \vert a - b \vert^2$ in general (for $N=1$ try $b=a-\varepsilon$).",['functional-analysis']
463475,Homogeneous differential equation proof,"Show that a straight line through the origin intersects all integral curves of a homogeneous equation at the same angle.
I tried like this in homogeneous equation $y'=f(x,y)$ that is $f(tx,ty)=f(x,y)$.
Afterwards I do not know what to do.",['ordinary-differential-equations']
463489,Are simple algebraic groups absolutely simple?,"Let $k$ be a field. By a simple algebraic group over $k$ I mean an affine group scheme $G$ of finite type over $k$ such that $G$ is connected, non-commutative and every normal closed subgroup of $G$ is trivial. I would like to know an example of a simple algebraic group such that the base extension $G_{\overline{k}}$ of $G$ to the algebraic closure $\overline{k}$ of $k$ is not simple anymore. If $G$ is connected and non-commutative then also $G_{\overline{k}}$ is connected and non-commutative. So the problem is really about normal subgroups of $G_{\overline{k}}$ not being defined over $k$.","['reference-request', 'algebraic-geometry', 'algebraic-groups', 'group-theory']"
463498,"Let $R$ be a Artinian commutative ring with $1 \neq 0$. If $I$ is prime, then $I$ is maximal.","Prove: Let $R$ a Artinian commutative ring with $1 \neq 0$. If $I$ is prime, then $I$ is maximal. I got stuck on this. I understand that every ideal is generated by finitely many elements. Here is my approach: It's enough to prove the following implication:
$$ R/I \ \text{is a domain} \quad \Rightarrow \quad R/I \ \text{is a field}$$
Then only finding an inverse is left. So let $x \in R$ in arbitrary. We have to find an inverse element of $x+I \in R/I$, that as an element y so that $x \cdot y \in I+1$.
We denote $I = (x_1, x_2, \cdots, x_n)$. 
Now I have to find y so that $xy -1 = r_1 x_1+ r_2 x_2 + \cdots + r_n x_n$. This is where I no more knew what to do. Your advise will be appreciated.","['ring-theory', 'abstract-algebra']"
463506,Factorize $(x+1)(x+2)(x+3)(x+6)- 3x^2$,"I'm preparing for an exam and was solving a few sample questions when I got this question - Factorize : $$(x+1)(x+2)(x+3)(x+6)- 3x^2$$ 
I don't really know where to start, but I expanded everything to get :
$$x^4 + 12x^3 + 44x^2 + 72x + 36$$ I used rational roots test and Descartes rule of signs to get guesses for the roots. I tried them all and it appears that this polynomial has no rational roots.So, what  should I do to factorize this polynomial ? (I used wolfram alpha and got the factorization : $(x^2 + 4x + 6) (x^2 + 8x + 6)$ But can someone explain how to get there ?)","['factoring', 'algebra-precalculus', 'polynomials']"
463557,"Is the set $U(n,\mathbb R)$ of all upper triangular $n\times n$ matrices over $\mathbb R$ a connected set in $M(n,\mathbb R)?$","Is the set $U(n,\mathbb R)$ of all upper triangular $n\times n$ matrices over $\mathbb R$ a connected set in $M(n,\mathbb R)$ (with its usual topology after identification with $R^{n^2})?$ I think the answer is yes since connectedness is a productive property, $\mathbb R,\{0\}$ are connected and $$U(n,\mathbb R)=\\\mathbb R\times\mathbb R\times...\times\mathbb R\\\times\{0\}\times \mathbb R\times...\times\mathbb R\\...\\\times\{0\}\times\{0\}\times...\times\mathbb R$$ Please tell me whether the attempt is right or wrong!",['general-topology']
463561,Existance and uniqueness of solution for a point with fixed distances to three other points,"I have two sets of known points in $\mathbb{R}^2$: Four points $\mathbf{p_1}, \mathbf{p_2}, \mathbf{p_3}, \mathbf{p_x}$ , and three other points $\mathbf{q_1}, \mathbf{q_2}, \mathbf{q_3}$. I would like to find $\mathbf{q_x}$ such that the ratios of Euclidian distances between $\mathbf{q_x}$ and $\mathbf{q_1}, \mathbf{q_2}, \mathbf{q_3}$, are the same as between $\mathbf{p_x}$ and $\mathbf{p_1}, \mathbf{p_2}, \mathbf{p_3}$. That is, I want to find $\mathbf{q_x}$ such that $\frac{d(\mathbf{q_1},\mathbf{q_x})}{\sum_i d(\mathbf{q_i},\mathbf{q_x})} = \frac{d(\mathbf{p_1},\mathbf{p_x})}{\sum_i d(\mathbf{p_i},\mathbf{p_x})}$ and 
$\frac{d(\mathbf{q_2},\mathbf{q_x})}{\sum_i d(\mathbf{q_i},\mathbf{q_x})} = \frac{d(\mathbf{p_2},\mathbf{p_x})}{\sum_i d(\mathbf{p_i},\mathbf{p_x})}$ and $\frac{d(\mathbf{q_3},\mathbf{q_x})}{\sum_i d(\mathbf{q_i},\mathbf{q_x})} = \frac{d(\mathbf{p_3},\mathbf{p_x})}{\sum_i d(\mathbf{p_i},\mathbf{p_x})},$ where $d(\cdot,\cdot)$ is the Euclidian distance. Or to rewrite it a bit nicer: $d(\mathbf{q_x},\mathbf{q_k}) = w \cdot d(\mathbf{p_x},\mathbf{q_k}) $ for $ k = 1,2,3$, where $w$ is the unknown factor $w = \frac{\sum_i d(\mathbf{q_i},\mathbf{q_x})}{\sum_i d(\mathbf{p_i},\mathbf{p_x})}$. Note also the more to the point problem formulation by Blue in the comments. This looks like three equations with three unknowns (x-, and y- coordinates of $\mathbf{q_x}$ and $w$). However, I have been struggling for quite a while now to find out if there is always a unique solution, and to find this solution, or to find an optimal solution if no solution exists. Any help that you can offer is greatly appreciated!","['algebra-precalculus', 'euclidean-geometry']"
463565,How does indexing work in EGA/ how to search for a result in EGA?,"I am interested in a certain result which says that if we have an open cover $F_i$ of a sheaf $F$ with each $F_i$ representable, then $F$ is representable. The reason I am interested in this is because I am learning about the construction of the fibered product of two schemes (over a fixed base scheme) using representable functors. Now the only reference I have been able to find is supposed to be proposition 0.4.5.4 in EGA mentioned by Akhil Mathew here . But how do I find this result in EGA? There are so many volumes/chapters that I get confused! If I understand correctly, the 0 in the beginning followed by 4 means chapter 0 of EGA IV yes? But I can't find it there. Can someone familiar with EGA help me please?","['category-theory', 'algebraic-geometry', 'reference-request']"
463567,"Given three integers in $\{0,\ldots,100\}$ which sum up to $100$. What is the probabilty that two of them are the same?","We pick $3$ numbers (one by one) from set $\{0,1,...,100\}$.
What is probabilty that two numbers are the same if sum of those $3$ numbers is $100$? My solution:
Which two are the same we can pick in $\binom {3}{2}$ ways. Suggest $x_2=x_3$- we need to find compositon $x_1+x_2+x_2=100 \implies x_1+2x_2=100$ which implies that $x_1$ is even so we can divide this by $2$. Now we get $y_1+y_2=50$ , and using formula there are $$\binom{50+2-1}{2-1}=51$$ compositions. So, probability is $$\frac{51*3}{\binom{100+3-1}{3-1}}$$ Is this right answer? P.S.$\binom{100+3-1}{3-1}$ is number of compositions of 100 into 3 parts (allowing $0$)","['discrete-mathematics', 'solution-verification', 'elementary-number-theory', 'probability', 'combinatorics']"
463577,Why can we use inspection for solving equation with multiple unknowns?,"In our algebra class, our teacher often does the following: $a + b\sqrt{2} = 5 + 3\sqrt{2} \implies \;\text{(by inspection)}\; a=5, b = 3
$ I asked her why we can make this statement. She was unable to provide a satisfactory answer. So I tried proving it myself. $a + b\sqrt{2} = x + y\sqrt{2}$. We are required to prove that $a = x$, and $b = y$. Manipulating the equation, we get $\sqrt{2}(b - y) = x - a$, or $\sqrt{2} = \frac{x-a}{b-y}$. Expanding this, we get $\sqrt{2} = \frac{x}{b-y} + \frac{a}{b-y}$. I tried various other transformations, but nothing seemed to yield a result.",['algebra-precalculus']
463584,Finding a function whose value at $n$ is the $n^{\text{th}}$ prime,"For positive integers $a$ and $b$, evaluate: $$f\left ( a,b \right )=\frac{1}{a}\sum_{j=1}^{a}\cos\left ( \frac{2\pi jb}{a} \right )$$ Hence, find a function $g\left ( n \right )$, $n \in \mathbb{Z}$, such that $g(n)=1$ if $n$ is prime and $g(n)=0$ if $n$ is composite. Use $g(n)$ to construct a function $p\left ( n \right )$ whose value at $n$ is the $n^{\text{th}}$ prime number.","['prime-numbers', 'summation', 'functions', 'polynomials']"
463600,Evaluating $\int_{0}^{\infty}\frac{1}{x}\big (\frac{\sinh ax}{\sinh x}-ae^{-2x}\big )dx$,"Some time ago, stumbled out of an integral: $$\int_{0}^{\infty}\frac{1}x{}\left (\frac{\sinh ax}{\sinh x}-ae^{-2x}\right )dx=\ln\frac{\pi\cos\frac{a\pi}{2}}{\Gamma^2(\frac{a+1}{2})};\left | a \right |<1$$ I have no idea where to start?",['integration']
463601,A partition of the unit interval into uncountably many dense uncountable subsets,"The title says it all: Is there a partition of $[0,1]$ into uncountably many dense uncountable subsets ?",['real-analysis']
463604,$2 \cos^{-1}x =\sin^{-1}(2x \sqrt {1-x^2})$ is valid for which values of $x $,Problem : $2 \cos^{-1}x =\sin^{-1}(2x \sqrt {1-x^2})$ is valid for which values of $x $ Solution : $2 \cos^{-1}x =\sin^{-1}(2x \sqrt {1-x^2})$ $2 \cos^{-1}x =2 \sin^{-1}x$ $ \cos^{-1}x = \sin^{-1}x$ Am I doing right ?,['trigonometry']
463650,Convergent Sequence and Cauchy Criterion- Counter Example,"Consider the sequence $\left \{ x_{n} \right \}$ that satisfies the condition:
$$\left | x_{n+1}-x_{n} \right |< \frac{1}{2^{n}}
\ \ \ for\  all\  n=1,2,3,...$$
Part (1): Prove that the sequence $\left \{ x_{n} \right \}$ is convergent. Part (2): Does the result in part (1) hold if we only assume that $\left | x_{n+1}-x_{n} \right |< \frac{1}{n}
\ \ \ for\  all\  n=1,2,3,...$? For part (1), I proved that the sequence is Cauchy and hence it is convergent.
For part (2), I feel like the sequence is not necessarily convergent. I am trying to come up with a sequence that is divergent, but satisfies the condition given in part (2). Any ideas?","['cauchy-sequences', 'sequences-and-series', 'real-analysis', 'analysis']"
463656,Using the definition of the derivative prove that if $f(x)=x^\frac{4}{3}$ then $f'(x)=\frac{4x^\frac{1}{3}}{3}$,"So I have that $f'(x)=\lim_{h \to 0} \frac{f(x+h)-f(x)}{h}$ 
and know that applying $f(x)=x^\frac{4}{3}=f\frac{(x+h)^\frac{4}{3} -x^\frac{4}{3}}{h}$ but am at a loss when trying to expand 
$(x+h)^\frac{4}{3}$","['calculus', 'derivatives', 'definition']"
463669,Is this bijection between subsets of $\mathbb{Z}$ right?,"I was trying to prove the following: For some fixed $n \in \mathbb{N}$ define the following set of integers $S_4(n) = \{k \in \mathbb{Z} : k = n+j, j \in \{0,1,2,3\}\subset \mathbb{Z}\}$, then if $A = \{0,1,2,3\}\subset \mathbb{Z}$, the function $f : S_4(n) \to A$ which sends each number to the remainder of the division by $4$ is a bijection. My proof was the following: write $n = 4q + r$ where $q$ is the quotient of the division by $4$ and $r$ is the remainder. Then, $S_4(n) = \{n_k \in \mathbb{Z} : n_k = 4q+(r+k), k \in \{0,1,2,3,4\}\subset \mathbb{Z}\}$. First we prove injectivity. For some $n_i, n_j \in S_4(n)$  consider $f(n_i) = f(n_j)$. But $n_i = 4q+(r+i)$ and $n_j = 4q + (r+j)$, and so $f(n_i) = r+ i$ and $f(n_j) = r+j$ and in that case we have $i = j$ implying that $n_i = n_j$ and thus $f$ is injective. To prove surjectivity we do as follows: given $a \in \{0,1,2,3,4\}$ we want $n_k = 4q+(r+k)$ such that $f(n_k) = a$. But this means $r+k = a$ and so we simply take $k = a - r$ which is the same as taking $n_{a -r}$, so that we have $f(n_{a-r}) = r+(a-r)=a$ as desired, so that $f$ is surjective. Is this proof correct? I think there's just a problem. First, I didn't prove that if $r$ is the remainder of $n$ by $4$ then $r+1$ is the remainder of $n+1$ by $4$. Second, I didn't prove that $a - r \in \{0,1,2,3,4\}$ which is necessary so that $n_{a-r} \in S_n(4)$. Are those real problems with this proof? Are any other errors there? If some, how can I make this better? Thanks very much in advance!","['elementary-number-theory', 'elementary-set-theory', 'proof-verification']"
463671,"Galois Group of $x^p - 2$, $p$ an odd prime","Question is to determine the Galois group of $x^p-2$ for an odd prime $p$ . For finding the Galois group, we look for the splitting field of $x^p-2$ which can be seen as $\mathbb{Q}(\sqrt[p]{2},\zeta)$ where $\zeta$ is a primitive $p^{th}$ root of unity. Consider $\mathbb{Q}\subset \mathbb{Q}(\zeta) \subset \mathbb{Q}(\sqrt[p]{2},\zeta)$ .we know that $\mathbb{Q}(\sqrt[p]{2},\zeta)$ is Galois over $\mathbb{Q}(\zeta)$ ,  we find Corresponding Galois Group say $G_1$ . Consider $\mathbb{Q}\subset \mathbb{Q}(\sqrt[p]{2}) \subset \mathbb{Q}(\sqrt[p]{2},\zeta)$ .
we know that $\mathbb{Q}(\sqrt[p]{2},\zeta)$ is galois over $ \mathbb{Q}(\sqrt[p]{2})$ , we find Corresponding Galois Group say $G_2$ . Then Galois Group of $\mathbb{Q}(\sqrt[p]{2},\zeta)$ would possibly be Product of these two subgroups $G_1$ and $G_2$ with some relation between the generators. For $Gal(\mathbb{Q}(\sqrt[p]{2},\zeta)/\mathbb{Q}(\zeta))$ , consider $\tau: \mathbb{Q}(\sqrt[p]{2},\zeta) \rightarrow \mathbb{Q}(\sqrt[p]{2},\zeta)$ fixing $\zeta$ and sending $\sqrt[p]{2} \rightarrow \sqrt[p]{2}\zeta$ . $\tau(\sqrt[p]{2})=\sqrt[p]{2}\zeta$ , $\tau^2(\sqrt[p]{2})=\tau(\tau(\sqrt[p]{2}))=\tau(\sqrt[p]{2}\zeta)=\tau(\sqrt[p]{2})\tau(\zeta)=\sqrt[p]{2}\zeta^2$ , For similar Reasons, $\tau^{p}(\sqrt[p]{2})=\sqrt[p]{2}\zeta^p=\sqrt[p]{2}$ . No power of $\tau$ less than $p$ gives identity as no power of $\zeta$ less than $p$ gives identity. So, $Gal(\mathbb{Q}(\sqrt[p]{2},\zeta)/\mathbb{Q}(\zeta)) \cong \mathbb{Z}_p \cong \big< \tau \big>$ . For $Gal(\mathbb{Q}(\sqrt[p]{2},\zeta)/\mathbb{Q}(\sqrt[p]{2}))$ , consider $\sigma : \mathbb{Q}(\sqrt[p]{2},\zeta) \rightarrow \mathbb{Q}(\sqrt[p]{2},\zeta)$ fixing $\sqrt[p]{2}$ and sending $\zeta \rightarrow \zeta^2$ $\sigma(\zeta)=\zeta^2$ $\sigma^2(\zeta)=\sigma(\sigma(\zeta))=\sigma(\zeta^2)=\zeta^{(2^2)}$ For similar reasons, $\sigma^{p-1}(\zeta)=\zeta^{(2^{p-1})}$ , as for every $a\in \mathbb{F}_p^\times$ , we have $a^{p-1}=1$ we have in particular $2^{p-1} \equiv~1~mod~p$ . So, $\sigma^{p-1}(\zeta)=\zeta^{(2^{p-1})}=\zeta$ (as $\zeta$ is a $p^{th}$ root of unity). No power of $\sigma$ less than $p-1$ gives identity as $2\in \mathbb{F}_p$ generates Multiplicative group, no power of $2$ less than $p-1$ can be equal to $1~mod~p$ . So, $Gal(\mathbb{Q}(\sqrt[p]{2},\zeta)/\mathbb{Q}(\sqrt[p]{2})) \cong \mathbb{Z}_{p-1} \cong \big< \sigma\big>$ . As $[\mathbb{Q}(\sqrt[p]{2},\zeta):\mathbb{Q}]=p(p-1)$ and $|\sigma|=p-1$ and $|\tau|=p$ i strongly feel Galois group should be possibly generated by $\sigma$ and $\tau$ with ""Some extra related conditions""But not very sure to confirm this. I am not able to go any further, I can see that $\sigma$ and $\tau$ do not commute with each other. I am unable to produce a know group which contain isomorphic copies of $\mathbb{Z}_{p-1}$ and $\mathbb{Z}_p$ as subgroups. I would be thankful if some one can help me out in this case. Thank You.","['galois-theory', 'abstract-algebra']"
463682,Closed form of $\operatorname{Li}_2(\varphi)$ and $\operatorname{Li}_2(\varphi-1)$,"I am trying to calculate the dilogarithm of the golden ratio and its conjugate $\Phi = \varphi-1$. Eg the solutions of the equation $u^2 - u = 1$. 
From Wikipdia one has the following \begin{align*} 
  \operatorname{Li}_2\left( \frac{1 + \sqrt{5}}{2} \right)
   & = -\int_0^\varphi \frac{\log(1-t)}{t}\,\mathrm{d}t 
     =  \phantom{-}\frac{\pi^2}{10} - \log^2\left( \Phi\right) \\
  \operatorname{Li}_2\left( \frac{1 - \sqrt{5}}{2} \right)
   & = -\int_0^\Phi \frac{\log(1-t)}{t}\,\mathrm{d}t 
     =  -\frac{\pi^2}{15} - \log^2\left( -\Phi\right) \\
 \end{align*} I am quite certain that these two special values can be shown by combining the identites for the dilogarithm, and forming a system of equations. But I am having some problems obtaining a set of equations only involving $\operatorname{Li}_2(\varphi)$ and $\operatorname{Li}_2(\Phi)$. Can anyone show me how to set up the system of equations from the identites, or perhaps a different path in showing these two values?","['polylogarithm', 'special-functions', 'integration', 'real-analysis']"
463708,Does the Jordan curve theorem apply to non-closed curves?,"A Jordan curve is a continuous closed curve in $\Bbb R^2$ which is simple, i.e. has no self-intersections. The Jordan curve theorem states that the complement of any Jordan curve has two connected components, an interior and an exterior. Now let's define an unbounded curve to be a continuous map $f: (-\infty,\infty)\to\Bbb R^2$ such that $f((-\infty,0))$ and $f((0,\infty))$ are both unbounded. My question is, does the complement of a simple unbounded curve always have two connected components? It seems intuitively true, since you'd expect the curve to have two sides, but considering how long it took to prove the Jordan curve theorem, things may not be as straightforward as they appear. Any help would be greatly appreciated. Thank You in Advance. EDIT: As @dfeuer suggested, let's also require that the curve goes off to infinity in both directions.  To make this precise, let's say that there exists two lines $L_1$ and $L_2$, parametrized by $L_1(t) = (a_1 + b_1 t, c_1 + d_1 t)$ and $L_2(t) = (a_2 + b_2 t, c_2 + d_2 t)$, such that the limit of $d(f(t), L_1(t))$ as $t$ goes to $-\infty$ is $0$, and the limit of $d(f(t), L_2(t))$ as $t$ goes to $\infty$ is $0$.  Under that condition, does the complement of the curve have two connected components?","['general-topology', 'connectedness', 'real-analysis']"
463718,Find the value of $\sin 2013^\circ$,"How do I find the value of $\sin 2013^\circ$? A precise decimal is not required, but must be expressed with $\sin 30^\circ,$ $\sin 45^\circ,$ and $\sin 60^\circ$ (cosine is also fine). Hint:  Use half/double angle formula.","['trigonometry', 'contest-math']"
463727,Triangular matrices and commutators,"From Humphreys' Introduction to Lie Algebras and Representation Theory : We conclude this subsection by mentioning several other subalgebras of $gl(n,F)$ which play an important subsidiary role for us. Let $t(n,F)$ be the set of upper triangular matrices $(a_{ij})$, $a_{ij}=0$ if $i>j$. Let $n(n,F)$ be the strictly upper triangular matrices ($a_{ij}=0$ if $i\geq j$). Finally, let $o(n,F)$ be the set of all diagonal matrices . It is trivial to check that each of these is closed under the bracket. Notice also that $t(n,F)=o(n,F)+n(n,F)$ (vector space direct sum), with $[o(n,F),n(n,F)]=n(n,F)$, hence $[t(n,F),t(n,F)]=n(n,F)$. (If $H,K$ are subalgebras of $L$, $[H K]$ denotes the subspace of $L$ spanned by commutators $[xy]$, $x\in H, y\in K$.) I am confused about why $[t(n,F),t(n,F)]=n(n,F)$. If we have two upper triangular matrices $X,Y$, then $XY$ is also upper triangular, and so $XY-YX$ is upper triangular, so it should stay in $t(n,F)$. But I don't see why $XY-YX$ should be strictly upper triangular.","['linear-algebra', 'abstract-algebra']"
463729,Does there exist an holomorphic function such that $|f(z)|\geq \frac{1}{\sqrt{|z|}}$?,"I have some trouble solving this problem: Does there exist a holomorphic function $f$ on $\mathbb C\setminus \{0\}$ such that $$|f(z)|\geq \frac{1}{\sqrt{|z|}}$$ for all $z\in\mathbb C \setminus \{0\}$ ? I don't know where to start. My intuition is that you would get a problem with the singularity near $0$ , but I am not sure how to prove it. Any help would be appreciated! Thanks!",['complex-analysis']
463755,A Step Involving the Binomial Theorem: Can You Explain Why its Valid?,"I have been given a step in an evaluation of an integral, but I can't work out what theorem has been used: See: $=\int_d^e\sum\limits_{n=0}^\infty\dfrac{(-1)^na^n\left((b+c)\cos x-\sqrt{b^2-(b+c)^2\sin^2x}\right)^{2n}}{n!}dx$ $=\int_d^e\sum\limits_{n=0}^\infty\sum\limits_{m=0}^n\dfrac{(-1)^nC_{2m}^{2n}a^n(b+c)^{2n-2m}\cos^{2n-2m}x\left(\sqrt{b^2-(b+c)^2\sin^2x}\right)^{2m}}{n!}dx-\int_d^e\sum\limits_{n=0}^\infty\sum\limits_{m=1}^n\dfrac{(-1)^nC_{2m-1}^{2n}a^n(b+c)^{2n-2m+1}\cos^{2n-2m+1}x\left(\sqrt{b^2-(b+c)^2\sin^2x}\right)^{2m-1}}{n!}dx$ Certainly the binomial theorem has been used, but why are the two terms valid? There must be a trick used but I can't work it out... -Alex","['calculus', 'combinatorics']"
463758,What is the product of this by telescopic method?,$$\prod_{k=0}^{\infty} \biggl(1+ {\frac{1}{2^{2^k}}}\biggr)$$ My teacher gave me this question and said that this is easy only if it strikes the minute you read it. But I'm still thinking. Help! P.S. This question is to be attempted by telescopic method.,"['sequences-and-series', 'infinite-product']"
463770,defining a dominant rational map from an algebra homomorphism (Theorem I 4.4 in Hartshorne),"The following shows up in the proof of theorem I 4.4 in Hartshorne. Let $X,Y$ be varieties and $\theta: K(Y) \rightarrow K(X)$ a homomorphism of $k$-algebras. We want to construct a dominant rational map $X \rightarrow Y$. We can assume that $Y$ is affine with coordinate ring $A(Y)$. Let $y_1,\cdots,y_n$ be $k$-algebra generators of $A(Y)$. Then $\theta(y_1),\cdots,\theta(y_n) \in K(X)$ and we can find an open set $U$ of $X$ such that $\theta(y_i)$ is regular on $U$. Then by restricting $\theta$ on $A(Y)$ we obtain a $k$-algebra homomorphism $A(Y) \rightarrow \mathcal{O}(U)$. So far, i have clear understanding. But then Hartshorne says that the homomorphism $A(Y) \rightarrow \mathcal{O}(U)$ is injective, and this is where i am stuck. Here is my effort: Let $p(y)$ be inside the kernel. Then $\theta|_{A(Y)}(p(y))=0 \Rightarrow p(\theta(y))=0 \Rightarrow p(\theta(y_1)(P),\cdots,\theta(y_n)(P))=0, \forall P \in X \Rightarrow (\theta(y_1)(P),\cdots,\theta(y_n)(P)) \in \mathcal{Z}(p)$. The goal should be to show that $p$ actually vanishes on $Y$, which would be true if every point of $Y$ can be written in the form $(\theta(y_1)(P),\cdots,\theta(y_n)(P))$. But why would this be true? Edit: Additionally, how do we see that the induced morphism of varieties $U \rightarrow Y$ gives a dominant rational map $X \rightarrow Y$?",['algebraic-geometry']
463785,Is Collatz' conjecture the only stable solution of its type?,"The Collatz Conjecture is well known with the sequence $$f(n) = \begin{cases} n/2 &;\text{if } n \equiv 0 \pmod{2}\\ k\,n+1 &; \text{if } n\equiv 1 \pmod{2} \end{cases}$$ and $k=3$; the sequence converging $1$ (so called oneness ). Is there any conjecture/theorem on whether the sequence would converge for any other value of $k$; or could it be shown that the sequence diverges for values of $k$ other than $3$? By convergence here I mean that the sequence after finite steps ends with a stable fixed number such as in case of Collatz it is the case with the number $1$. Append: In the mean time I wrote out a conjecture on this over here >>> , for those who might be interested.","['dynamical-systems', 'collatz-conjecture', 'sequences-and-series', 'number-theory', 'elementary-number-theory']"
463791,Prove that $A^TD-C^TB=I$,"Let A,B,C,D be complex matrices $n \times n$ such that $AB^T,CD^T$ are symmetric and $AD^T-BC^T=I$. Prove that $A^TD-C^TB=I$. Can anyone give me any idea? Thank you.",['matrices']
463794,Solve : $\frac{2012!}{2^{2010}}-\sum^{2010}_{k=1} \frac{k^2k!}{2^k}-\sum^{2010}_{k=1} \frac{k\cdot k!}{2^k}$,Solve : $$\frac{2012!}{2^{2010}}-\sum^{2010}_{k=1} \frac{k^2k!}{2^k}-\sum^{2010}_{k=1} \frac{k\cdot k!}{2^k}$$ Can we take like this : Let us take (k+1)th term  = $$\frac{(k+1)^2(k+1)!}{2^{k+1}} ; \frac{(k+1)(k+1)!}{2^{k+1}}$$ and (k-1)th  term is : $$\frac{(k-1)^2(k-1)!}{2^{k-1}};  \frac{(k-1)(k-1)!}{2^{k-1}}$$ What can we do further to this series... please suggest ......thanks.,"['sequences-and-series', 'algebra-precalculus']"
463804,Showing $\mathcal{H}$ is a hilbert space.,"So this is an early exercise in Conway's A Course In Functional Analysis. I'm trying to get to grips with this upto open mapping and closed graph to see if I want to do any more functional analysis. Analysis isn't really my thing but knowing lots of math is empowering and yadda yadda. Anyway the problem: Let $\mathcal{H}=\{f:[0,1]\rightarrow \mathbb{F} \,:\, f\text{ is absolutely continuous, }f(0)=0, f'\in\mathcal{L}^2(0,1)\}$ (where $\mathbb{F}$ is either $\mathbb{R}$ or $\mathbb{C}$). Define $\langle f,g\rangle=\int_0^1 f'(t)\overline{g'(t)}\, dt$ Show $\mathcal{H}$ is a Hilbert space. So I'm happy that $\langle \cdot,\cdot\rangle$ defines an inner product, I just want to show completeness in the metric induced by the norm. So my first stab was given a cauchy sequence $\{f_n\}$ to define 
$$g(x)=\lim_{n\rightarrow\infty} f_n'(x)\text{ (in $\mathcal{L}^2$'s norm)}$$ 
This defines $g$ almost everywhere as the sequence $f'(n)$ is Cauchy in $\mathcal{L}^2(0,1)$ (this is direct from the definition of $\mathcal{H}$'s norm). Then I want to define $f(x)=\int_0^x g(t)dt$. Now I am struggling to show that $f$ is absolutely continuous (it's been a while since real analysis, I could be missing something simple), I'm happy that FTC deals with $f(0)=0$ and $f'\in\mathcal{L}^2(0,1)$ once I've shown this.","['cauchy-sequences', 'measure-theory', 'continuity', 'hilbert-spaces', 'functional-analysis']"
463822,shortest distant of curve from origin,"what'd be shortest distance of curve from origin(0,0) function is $$ y=\frac{e^x+ e^{-x}}{2} $$ 
I tried taking some x and y points on curve then using distance formula finding distant then i found differential coefficient and equated to zero $$ dS/dx =0 $$  but did't got my answer","['derivatives', 'differential-geometry']"
463823,"Show that in any group of order $23 \cdot 24$, the $23$-Sylow subgroup is normal.","Show that in any group of order $23 \cdot 24$, the $23$-Sylow subgroup is normal. Let $P_k$ denote the $k$-Sylow subgroup and let $n_3$ denote the number of conjugates of $P_k$. $n_2 \equiv 1 \mod 2$ and $n_2 | 69 \implies n_2= 1, 3, 23, 69$ $n_3 \equiv 1 \mod 3$ and $n_3 | 184 \implies n_3 = 1, 4, 184$ $n_{23} \equiv 1 \mod 23$ and $n_{23} | 24 \implies n_{23} = 1, 24$ Suppose for contradiction that $n_{23} = 24$. Then $N(P_{23})=552/24=23$. So the normalizer of $P_3$ only contains the identity and elements of order $23$. It is impossible for $n_2$ to equal $23$ or $69$, or for $n_3$ to equal $184$, since we would then have more than $552$ elements in G. Case 1: Let $n_2 = 1$. Then we have $P_2 \triangleleft G$, and so we have a subgroup $H=P_2P_{23}$ in G. We know that $|H|=\frac{|P_2||P_{23}|}{|P_2 \cap P_{23}} = 184$. We also know that the $23$-Sylow subgroup of $H$ is normal, so it's normalizer is of order $184$. Since a $p$-sylow subgroup is the largest subgroup of order $p^k$ for some $k$; and since the order of the $23$-Sylow subgroup of H and G both equal $23$, they must coincide. But that means that elements of orders not equal to $23$ normalize $P_{23}$, which is a contradiction. Case 2: Suppose that $n_3=1$. Then we have $P_3 \triangleleft G$, and so we have a subgroup $K=P_2P_{23}$ in $G$. Since $|K|=\frac{|P_3||P_{23}|}{|P_2 \cap P_{23}}= 69$, the $23$-sylow subgroup of $K$ is normal. Again, as in case 1, we have an element of order not equal to $23$ that normalizes $P_{23}$. Case 3: Let $n_3=4$ and $n_2=3$. But then $N(P_2)=184$. So this is the same as case 1, since we have a subgroup of G of order $184$. Do you think my answer is correct? Thanks in advance","['sylow-theory', 'finite-groups', 'proof-verification', 'abstract-algebra']"
463835,Methods for determining thresholds for future use based on historical data (in R or Excel),"Let's say I have some data about the amounts of reports to Help Desk (about technical problems) which were monitored and registered every five minutes for the whole day (even during the night). Is there any way to efficiently calculate the ""alarming"" thresholds: top - above this means there are too many reports in the system! Time to get to work! (most important).
bottom - lower than this means there are too few of them (report system got broken?)
The problems I face: System is fairly new, so at the start of the registering process there were extreme outliers. I want to have thresholds for a more stable system in the future.
People obviously don't work during the night, so there's a lot of observations (let's call them ""moments"" - those ""five minutes"") where the number of reports stays the same.",['statistics']
463839,Prove that g(0)=0?,"(taken from Spivak's calculus page 281) Suppose that $f$ and $g$ are differentiable functions satisfying
  $$ \int_{0}^{f(x)} (fg)(t) \, \mathrm{d}t=g(f(x))$$
  Prove that $g(0)=0$. Now if $f(x)=0$ in some point then it's straightforward that $g(f(x))=g(0)=0$. Anyways:
differentiating the first formula we get the following equation : $$f'(x).(fg)(f(x))=g'(f(x)).f'(x).$$ Let's suppose that $f'(x)=0$, thus $f$ is constant i.e $f(x)=c$, if $c=0$ we are done, $g(0)=0$ , if $c\neq 0$ then : $\displaystyle \int_{0}^{c} fg(t) \, \mathrm{d}t$=g(c) $\displaystyle \int_{0}^{c} g(t) \, \mathrm{d}t$=g(c)/c, i'm stuck here , how can we prove that g(0)=0 (or get a contradiction) from this equation?
EDIT : i had a lot of typos fixed them , sorry first time posting..
EDIT 2 : i checked spivak's calculus solutions book and i didn't find this question he just jumos from question 7 to 9 (ignoring this one )","['calculus', 'integration', 'real-analysis', 'analysis']"
463845,Is the projection from a Zariski product of Zariski closed subsets an open map?,Let $X \subseteq \mathbb A^n$ and $Y \subseteq \mathbb A^m$ be Zariski closed.  Then the (Zariski) product $X \times Y \subseteq \mathbb A^{n + m}$ is closed and there is a projection map $p\colon X \times Y \to X$ which is continuous in the Zariski topology. Question: When is $p$ an open map? This is always the case when $X \times Y$ is given the product topology but here we give it the Zariski product topology and when we do that the result is not always true.  I know it's true when $X$ and $Y$ are irreducible and the field is algebraically closed.  Martin gave a very short answer to that effect here (and if someone could point me too a more elementary proof in that case I would appreciate it).  The projection $\mathbb R^2 \to \mathbb R$ onto the first coordinate is not open (look at the complement of a circle) so even when $X$ and $Y$ are irreducible we need the field to be algebraically closed.  What about when the field is algebraically closed but $X$ and $Y$ are not necessarily irreducible?,['algebraic-geometry']
463855,Fully factored integer polynomials with constant differences,"Given a degree $d$, it is possible to construct a pair $(F,\delta),$ where $F$ is a polynomial in $\mathbb{Z}[X]$ and $\delta$ a non-zero integer, such that $F(X)$ and $F(X)+\delta$ both split into linear factors over $\mathbb{Z}[X]$ ? This is easy for $d=2$, as shown by the pair $F(X)=X^2$ and $\delta=-a^2$ (for an arbitrary integer $a$). Indeed, $F(X)=X \cdot X$ and $F(X)+\delta=(X-a)\cdot (X+a).$ What can be said for $d>2$ ?","['roots', 'abstract-algebra', 'polynomials']"
463861,"Intruiging Symmetric harmonic sum $\sum_{n\geq 1} \frac{H^{(k)}_n}{n^k}\, = \frac{\zeta{(2k)}+\zeta^{2}(k)}{2}$","I proved the following equation $$\sum_{n\geq 1}  \frac{H^{(k)}_n}{n^k}\, = \frac{\zeta{(2k)}+\zeta^{2}(k)}{2}$$ We define $$H^{(k)}_n=\sum_{m= 1}^n \frac{1}{m^k}$$ I am looking forward to seeing what approaches would you use .",['sequences-and-series']
463865,Permutations that preserve all algebraic relations between the roots of a polynomial,"When trying to answer the question of whether a given equation can be solved with radicals, historically people have paid lots of attention to permutations that preserve all algebraic relations between the roots of the polynomial. The idea finally led to the solution of the problem by Galois, but the idea of looking at such permutations pre-dates him. Is there any nice simple explanation of why such permutations are related with solve-ability of polynomial equations with radicals? (An explanation that doesn't directly involve the Galois group).","['math-history', 'reference-request', 'abstract-algebra']"
463876,Do simply connected open sets in $\Bbb R^2$ always have continuous boundaries?,"A Jordan curve is a continuous closed curve in $\Bbb R^2$ which is simple, i.e. has no self-intersections.  The Jordan curve theorem states that the complement of any Jordan curve has two connected components, an interior and an exterior. Let us define an unbounded curve to be a continuous map $f: \Bbb R\to\Bbb R^2$ such that the limit of $|f(t)|$ as $t$ goes to plus or minus infinity is infinity.  Then as discussed in the comments to my question here, the complement of an unbounded simple curve has two connected components: Does the Jordan curve theorem apply to non-closed curves? My question is, is every simply connected open set in $\Bbb R^2$ a connected component of the complement of either a Jordan curve or an unbounded simple curve?  To put it another way, is the boundary of a simply connected open set always a continuous curve, or do there exist sets with weirder boundaries than that? If they do always have continuous boundaries, can this be generalized to higher dimensions? Any help would be greatly appreciated. Thank You in Advance.","['general-topology', 'connectedness', 'plane-curves', 'real-analysis']"
463881,Evaluate $ \int_{25\pi/4}^{53\pi/4}\frac{1}{(1+2^{\sin x})(1+2^{\cos x})}dx $,"How to evaluate the integral
$$\int_{25\pi / 4}^{53\pi / 4}\frac{1}{(1+2^{\sin x})(1+2^{\cos x})}dx\ ?$$","['definite-integrals', 'integration']"
463898,Why is $\left(e^{2\pi i}\right)^i \neq e^{-2 \pi}$?,"Here's my (obviously flawed) proof that $1=e^{-2 \pi}$:
$$
1^i=1\\
e^{2 \pi i} = 1\\
\left(e^{2\pi i}\right)^i = 1^i\\
e^{-2 \pi} = 1
$$ What's the issue? I understand that exponentiation is not injective (and thus $-1 \neq 1$ even though $(-1)^2 = 1^2$), but I don't think that's an issue here: I'm only raising things to the power of $i$, which I don't think is multi-valued.","['complex-numbers', 'complex-analysis', 'exponentiation']"
463919,"Example of a regular strong solution of an SDE, which doesn't satisfy a Lyapunov condition?","Let $$dX_t = a(t,X_t) \, dt + b(t, X_t) \, dW_t, \quad t \in [0,T]$$ be a stochastic differential equation, where $W$ is an $m$-dimensional Brownian motion, $X_0 = x \in \mathbb{R}^d$, and the coefficients are given by $a(t,x) : [0,T] \times \mathbb{R}^d \rightarrow \mathbb{R}^d$ and $b(t,x) : [0,T] \times \mathbb{R}^{d \times m} \rightarrow \mathbb{R}^d$. Furthermore the coefficients satisfy some local Lipschitz and linear growth condition, i.e. if $B_R := \{x \in \mathbb{R}^d : |x| < R \}$, then for every cylinder $[0,T] \times B_R$ there exists a constant $B$ s.t.
$$|a(s,x) - a(s,y)| + \sum_{i=1}^m |b_i(s,x) - b_i(s,y)| \leq B|x-y|$$
and
$$|b(s,x)| + \sum_{i=1}^m |b_i(s,x)| \leq B(1+|x|)$$
for every $(s,x),(s,y) \in [0,T] \times B_R$. There is a Lyapunov-criterion, which guarantees the existence of a strong solution, which is also regular, i.e. there are no explosions in $[0,T]$.
E.g. Theorem 3.5 in Khasminskii's book ""Stochastic Stability of differential equations"" states the following: If there exists a Lyapunov-function $V: [0,T] \times \mathbb{R}^d \rightarrow \mathbb{R}$, which is two times continuous differentiable w.r.t. $x$ and once w.r.t. $t$,
$$\lim_{R \rightarrow \infty} \inf_{t \in [0,T],|x| > R} V(t,x) = \infty,$$
and there exists a constant $c>0$, s.t.
$$LV(t,x) \leq cV(t,x),$$
where $L$ is the generator of the SDE, then there exists a strong regular solution. Finally my question: Is there any example of an SDE, which possesses a regular strong solution, but doesn't satisfy the above Lyapunov condition? Or does even the other direction hold, i.e. if we have a strong regular solution, such a Lyapunov-function exists? Thank you very much.","['probability-theory', 'stochastic-calculus', 'stochastic-analysis']"
463937,Matrices as generators of free group.,In the introduction section of the paper Triples of $2\times 2$ matrices which generate free groups the authors mentioning some thing... In my words: The matrices $\begin{pmatrix}1 & 0 \\ 2 & 1\end{pmatrix}$ and $\begin{pmatrix}1 & 2 \\ 0 & 1\end{pmatrix}$ are generating the free group of two generators. How to prove the above statement?,"['matrices', 'free-groups', 'group-theory', 'abstract-algebra']"
463959,Coordinate Geometry-Finding vertices given midpoints [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question If (2,1), (4,5), (1,-3) are the midpoints of the sides of a triangle, find the co-ordinates of its vertices",['geometry']
463968,Finding the intermediate fields of $\Bbb{Q}(\zeta_7)$.,"Let $F= \Bbb{Q}(\zeta_7)$ with $\zeta_7 = e^{2\pi/7}$ . a) What is the Galois group of $F$ over $\Bbb{Q}$ ? b) Find all intermediate fields between $\Bbb{Q}$ and $F$ . (Write each in the form $\Bbb{Q}(\alpha)$ for some specific $\alpha \in F$ .) c) For each intermediate field $E$ above, give the Galois group of $E$ over $\Bbb{Q}$ . a) Since $\Bbb{Q}(\zeta_7)$ is the splitting field for the cyclotomic polynomial $x^6+x^5+\dots+1$ , $Gal(\Bbb{Q}(\zeta_7)/\Bbb{Q}) \cong U_7 \cong \Bbb{Z}^{\times}_7 \cong \Bbb{Z}_6$ . b) $Gal(\Bbb{Q}(\zeta_7)/\Bbb{Q}) \cong \Bbb{Z}_6$ So we have the following diagram for $\Bbb{Z}_6$ , And a corresponding diagram for $\Bbb{Q}(\zeta_7)$ for some $\alpha$ and $\beta$ Since $\Bbb{Q}(\zeta_7)$ has complex numbers, we can look at $\Bbb{Q}(i)$ to see if it has degree 2 or 3 over $\Bbb{Q}$ . Since $x^2+1$ is its minimal polynomial, we see that $[\Bbb{Q(i)} : \Bbb{Q}]=2$ and so it must correspond to $\Bbb{Z}_3$ , and $\beta=i$ . Sending every number to its conjugate is one possible automorphism. Of course, it has order 2 and so is isomorphic to $\Bbb{Z}_2$ . Since it fixes every real number, the corresponding intermediate field must be of the form $\Bbb{Q}(\alpha)$ for some real number $\alpha$ , and must have degree 3 over $\Bbb{Q}$ . If we look at $\zeta_7 + \zeta_7^6$ , we see that $\cos(2\pi/7) + i\sin(2\pi/7) + cos(12\pi/7) + i\sin(12\pi/7)$ $= \cos(2\pi/7) + i\sin(2\pi/7) + \cos(-2\pi/7) + i\sin(-2\pi/7)$ $= 2\cos(2\pi/7)$ which is irrational. So $\Bbb{Q}(\zeta_7 + \zeta_7^6)$ is either a proper subfield of $\Bbb{Q}(\alpha)$ or is equal to it. But from the diagram, we know that there is only one other intermediate field, so $\Bbb{Q}(\zeta_7 + \zeta_7^6) = \Bbb{Q}(\alpha)$ . c) The corresponding Galois group of $\Bbb{Q}(i)$ is isomorphic to $\Bbb{Z}_3$ and that of $\Bbb{Q}(\zeta_7 + \zeta_7^6)$ is isomorphic to $\Bbb{Z}_2$ . Do you think this is correct? Thanks in advance","['galois-theory', 'abstract-algebra', 'field-theory']"
463978,Minimize the sum of distances between two point and a circle,"Let's $A$,$B$ and $O$ be random point in a plane, such that they are not colinear. Let's $c$ be a circle centered on $O$, such that points $A$ and $B$ are outside of it. Find a point $X$ that lies on the circle $c$ and the sum $AX + BX$ is minimal. First I tried to minimize the function: $$f(x,y) = \sqrt{(A.x - x)^2 + (A.y - y)^2} + \sqrt{(B.x - x)^2 + (B.y - y)^2}$$ with  constraint $$g(x,y) = x^2 + y^2 - r^2 = 0$$ By moving $O$ to $(0,0)$ and do the same with $A$,$B$ so the relative distance will not change. But these works when we know the coordinates of $A$,$B$ and the radius of the circle. Yet this isn't the right way because the problem is to construct that point. Later I tried to approach using geometry. The smallest distance from the point $A$ to the circle is the intersection of the circle $c$ and the ray $OA$, this is the same for $B$. Then we construct circles centered on $A$ and $B$ that are tangent to $c$. If the two circle intersect we'll get a common point for the both $A$ and $B$ and the distance will be minimal. Using computer I find the point X should be somewhere around the intercetion of the circle $c$ and the ray from $O$ to the new point. Sometimes the optimal point differs just a bit and also this method fails when the two circles do not intersect each other","['geometry', 'plane-curves', 'circles']"
463986,"Prove that $f$ is a linear combination of $f_1,f_2,\dots,f_n$.","Let $V$ be a vector space and let $f, f_1,f_2,\dots,f_n$ be linear maps from $V$ to $\mathbb{R}$. Suppose that $f(x)=0$ whenever $f_1(x)=f_2(x)=\cdots=f_n(x)=0$. Prove that $f$ is a linear combination of $f_1,f_2,\ldots,f_n$. The solution can be found here (first problem). . but I disagree that $a_k$ is guaranteed to exist. What if the set containing all vectors $u\in V$ such that $f_1(u)=f_2(u)=\cdots =f_{k-1}(u)$ is empty?","['linear-algebra', 'contest-math']"
463987,"How to find the derivative of $F(t) = \int_0^t f(t, x) \, dx$?","Let $f: \mathbb{R}^2 \to \mathbb{R}$ be a continuous function. Define $F: \mathbb{R} \to \mathbb{R}$ by,
$$
F(t) = \int_0^t f(t, x) \, dx
$$
Then, I'm not sure how to get $F'$. If, there are functions $g$ and $h$ such that $f(t, x) = g(t)h(x)$, then of course we have
$$
F(t) = \int_0^t f(t, x) \, dx = \int_0^t g(t)h(x) \, dx = g(t)\int_0^t h(x) \, dx
$$
which can then be differentiated using the product rule. But apart from this special case, I don't know how to get $F'$.","['multivariable-calculus', 'calculus', 'real-analysis']"
463991,Does the series $1 + \frac{1}{2} - \frac{1}{3} + \frac{1}{4} + \frac{1}{5} - \frac{1}{6} + \dots$ converge?,"Does the following variant of the harmonic series converge? If it diverges (which I think it does), can I know if it diverges to $\infty$ or has no limit? Note that the series is not alternating in the classical sense of the word.
$$1 + \frac{1}{2} -\frac{1}{3} + \frac{1}{4} + \frac{1}{5} - \frac{1}{6} + \dots$$ The generic term of the series would have to be something like, $$a_n = \left\{\begin{array}{ll} -\frac{1}{n}, & \text{if } 3 \mid n  \\ \;\,
\,\, \frac{1}{n}, & \text{otherwise}\end{array}\right.$$
I'm not sure if it's very helpful. The terms divisible by 3 are negative, and the others are positive. Is there a way to decide and prove whether an alternating series of this sort (e.g. with a period other than 2) converges? Or one where terms are positive or negative according to some other rule? Almost all convergence tests I've come across are generally limited to either simple alternating series or where all the terms are positive.","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
463993,Can a cyclic quadrilateral be inscribed in a parabola?,"It is quite obvious that a quadrilateral can be inscribed in a parabola. However, can somebody provide a nice (meaning: intuitive ) proof that a cyclic quadrilateral can be inscribed in it? Further, if you can prove that it is possible to have an inscribed quadrilateral such that the diagonals are equal, then it'd be great!","['geometry', 'conic-sections']"
464000,Non-unital module over a ring with identity?,"Is there a nontrivial example of a non-unital module over a ring with identity?  By trivial, I mean modules  with $rm = 0$ for all $r$ and $m$. Just an idle question.  (Why is there no tag for that?)","['modules', 'ring-theory', 'abstract-algebra']"
464027,Is my proof correct about limit of $\sin\left(\frac{1}{x}\right)$?,"Apostol's book Calculus asks to show that there is not a value $A$ such that $f(x)=\sin\left(\frac{1}{x}\right)\to A$ when $x \to 0$. And my proof is: Suppose for the sake of contradiction that there exists such $A$. If we take $\epsilon=1$, we have two cases: If $A>0$, then $A - \epsilon > -1$, so $-1$ does not satisfy $|-1-A|<\epsilon$ inequality. Now for given $\delta>0$ we can take a natural number $n$ such that
$\frac{2-3\pi\delta}{4\pi\delta}<n $
and then $0<\frac{1}{\pi\left( \frac{3}{2}+2n \right)}<\delta$. But 
$$f\left( \left( \frac{3}{2}\pi+2n\pi \right)^{-1} \right)=\sin \pi\left( \frac{3}{2}+2n \right)=-1. $$ If $A\le0$, then $A+\epsilon\le1$ so $1$ does not satisfy $|1-A|<\epsilon $ inequality. Now for given $\delta>0$ we can take a natural number $n$ such that 
$\frac{2-\pi\delta}{4\pi\delta}<n $ and then 
$0<\frac{1}{\pi\left( \frac{1}{2}+2n \right)}<\delta$.
But 
$$f\left( \left( \frac{1}{2}\pi+2n\pi \right)^{-1} \right)=\sin \pi\left( \frac{1}{2}+2n \right)=1.$$ We have proved that with $\epsilon=1$ for every $\delta>0$ there exist $x$ such that $0<x<\delta$ but $|\sin \frac{1}{x} - A|<\epsilon$ does not hold. Therefore we have a contradiction, so such $A$ does not exist. Is my proof correct? there is a shorter argument?. Thanks in advance.","['alternative-proof', 'calculus', 'proof-verification', 'limits']"
464030,Derivation linear map examples,"From Humphreys' Introduction to Lie Algebras and Representation Theory : By an $F$-algebra (not necessarily associative) we simply mean a vector space $U$ over $F$ endowed with a bilinear operation $U\times U\rightarrow U$, usually denoted by juxtaposition (unless $U$ is a Lie algebra, in which case we always use the bracket). By a derivation of $U$ we mean a linear map $\delta:U\rightarrow U$ satisfying the familiar product rule $\delta(ab)=a\delta(b)+\delta(a)b$. I'm wondering what is an example of a derivation. Suppose I take $U=\mathbb{R}^n$. Clearly the map that takes everything to $0$ is a derivation. The map $\delta(x)=kx$ is not a derivation for $k\neq 0$, because then $kab\neq kab+kab$. What are some other linear maps satisfying that product rule?",['linear-algebra']
464031,Find the sum : $\frac{1}{\cos0^\circ\cos1^\circ}+\frac{1}{\cos1^\circ \cos2^\circ} +\frac{1}{\cos2^\circ \cos3^\circ}+......+$,"Find the sum of the following : (i) $$\frac{1}{\cos0^\circ \cos1^\circ}+\frac{1}{\cos1^\circ\cos2^\circ} +\frac{1}{\cos2^\circ \cos3^\circ}+......+\frac{1}{\cos88^\circ \cos89^\circ}$$ I tried : 
$$\frac{1}{\cos1^\circ}\left[\frac{\cos(1^\circ-0^\circ)}{\cos0^\circ\cos1^\circ} + \frac{\cos(2^\circ-1^\circ)}{\cos1^\circ\cos2^\circ}+...\right]$$ = $$\frac{1}{\cos1^\circ}\left[\frac{\cos1^\circ\cos0^\circ}{\cos0^\circ\cos1^\circ} - \frac{\sin1^\circ \sin0^\circ}{\sin0^\circ\cos1^\circ} + \frac{\cos2^\circ \cos1^\circ}{\cos1^\circ\cos2^\circ} -\frac{\sin2^\circ \sin1^\circ}{\cos1^\circ\cos2^\circ}...\right]$$ For this, as well, I am not getting any pattern to solve further. Please suggest, thanks.","['trigonometry', 'sequences-and-series', 'algebra-precalculus']"
464049,What is the Probability that a Knight stays on chessboard after N hops?,"Say a $8 \times 8$ chessboard as per picture. A position is represented here by co-ordinates $(x,y)$. A move is aslo considered as valid, where the Knight lands outside the chessboard
 [   For eg. from $(3,2)$ towards $(3,1)$ but ends up outside chess-board.  ] But once outside, it can't come back. Question: Knight starts from $(0,0)$. 
What is the Probability that a Knight stays on chessboard after N hops? Expected Solution: I don't want exact result like $ \frac{12}{64} $  but need your help on a. the thought/procedure/methodology to find it with b. A concluding formulae in terms of permutation/combination, Well my thought: After $(N-1)$th move, if the Kngiht is between $(x,y)$ where $3 \le x \le 6$ and $3 \le y \le 6$ then next move i.e $n$th move must ensure the knight will be within chessboard. Might be my thought is entirely wrong as it tries to find ""must be within chessboard"" In any $5 \times 5$ sub part with Knight in middle, it has $8$ possible moves. If initial position is $(0,0)$ out of those $8$ it has choice of $2$ only satisfying ""within chessboard"" constraint. Next move I am lost! Please help me think . Why cant we treat it like: a. The question is valid only if N-1 moves already done with the Knight on board.

  b. Now to find Nth move s.t Knight hops out of board - say probability P(out)

  c. 1 - P(out) now gives the answer { In Case b above we can use some stats like the following: Legal moves -> L      Illegal moves -> I
1. for 16 positions enclosed by {3c - 3f - 6c -6f} : 16 x 8 L
2. for each 4 positions {2b,2g,7b,7g} : 4L, 4I  =>  16L , 16I 
3. for each 16 positions  {7c-7f ,  2c-2f, 3b-6b, 3g-6g } : 6L,2I => 96L,32I
4. for each 4 corners: 2L,6I => 8L, 24I
5. for each 8 positions {7a,8b , 8g,7h , 2h,1g , 1b,2a} : 3L,5I => 24L,40I
6. for each 16 positions  {3a-6a ,  3h-6h, 8c-8f, 1c-1f } : 4L,4I => 64L,64I }","['statistics', 'recreational-mathematics', 'probability', 'combinatorics']"
464064,"A is similar to $A^k$, then each eigenvalue of $A$ is a root of unity","Let $A \in \mathbb{C}(n,n)$ and $k \geq 2$ be an integer such that $$A \sim A^k$$ . Show that if $A$ is non-singular then each eigenvalue of $A$ is a root of unity. Attempt: Since $A \sim A^k$ , $$PA = A^kP$$ where $P$ is an invertible matrix. Since $A$ is invertible, $0$ cannot be an eigenvalue of $A$ . Suppose $$Av = \lambda v \quad v \neq 0$$ then $$PAv = \lambda Pv$$ $$\therefore A^k(Pv) = \lambda (Pv) $$ which  implies that $Pv$ is an eigenvector of $A^k$ . But the eigenvalues of $A^k$ are $\lambda^k$ $$\therefore \lambda^k=\lambda$$ which gives the conclusion required. My questions is: Is the logic correct? If so, Am I missing any details? If not, then how could I approach this? Thanks!","['linear-algebra', 'eigenvalues-eigenvectors']"
464069,"If $I\subseteq J\subseteq A$ have same image in localization by all maximal ideals, then $I=J$","I will state my question first: Suppose $I\subseteq J\subseteq A$ are two ideals in a commutative ring $A$. Furthermore, assume
  that for every maximal ideal $\mathfrak{m}$ of $A$, the image of $I$
  and $J$ under the canonical map $A\to A_{\mathfrak{m}}$ is the same.
  How can I prove that $I=J$ ? The aforementioned canonical map $A\to A_{\mathfrak{m}}$ is $a\mapsto a/1$. My attempts: I think we might need to use the following fact. If $f: M\to N$ is $A$-module homomorphism, then the following statements are equivalent: 1) $f$ is injective. 2) The induced map $f_{\mathfrak{m}}: M_{\mathfrak{m}}\to N_{\mathfrak{m}}$ is injective for every maximal ideal $\mathfrak{m}$ of $A$. Now, if we let $M=I$ and $N=J$ (as ideals of $A$ are naturally $A$-modules), then the inclusion map $i: I\to J$ is injective. So, the induced maps $i_{\mathfrak{m}}: I_{\mathfrak{m}}\to J_{\mathfrak{m}}$ are also injective, for each maximal ideal $\mathfrak{m}$ of $A$. Now I would like to use the fact that $I$ and $J$ have same extensions in $A_{\mathfrak{m}}$. Can this approach be made to work? Thanks for your time.","['commutative-algebra', 'ideals', 'abstract-algebra']"
464080,Lagrange's theorem (Group Theory) applications,How can we prove that every finite group $G$ has a generating set of size not more than $\log_2|G|$? Can someone give me an hint.,['abstract-algebra']
464083,"A semigroup $X$ is a group iff for every $g\in X$, $\exists! x\in X$ such that $gxg = g$","The following could have shown up as an exercise in a basic Abstract Algebra text, and if anyone can give me a reference, I will be most grateful. Consider a set $X$ with an associative law of composition, not known to have an identity or inverses. Suppose that for every $g\in X$, there is a unique $x\in X$ with $gxg=g$. Show that $X$ is a group. Note that Iâ€™m not asking for a proof (though a really short one would please me!), just some place where this has been published.","['reference-request', 'semigroups', 'group-theory', 'abstract-algebra']"
464085,How to prove there exists a polynomial with degree at most $100\sqrt{nk}$ satisfying this condition,"Show that for arbitrary positive integers $n,k$,  there exists a
  polynomial $p(x)$, with degree at most $100\sqrt{nk}$, such that
  $$p(0)>(|p(1)+|p(2)|+\cdots+|p(n)|)+(|p(-1)|+|p(-2)|+\cdots+|p(-k)|)$$ This problem is problem A.511 from Problems in Mathematics, May 2010. See here . This problem doesn't have a solution posted. Thank you.","['algebra-precalculus', 'contest-math', 'polynomials']"
464105,a doubt in finding distance in graph theory,"I was studying about a product graph which is defined as : . I am taking $G_1$ and $G_2$ as connected graphs. I found that for any 2 vertices $(g,h),(g',g')$, $d(g,h),(g',h')$ = 1 if $g \sim g'$ or $h\sim h'$ $d(g,h),(g',h')$ = 2 if $ g=g' ~or ~h=h'$ $d(g,h),(g',h')$ = min{d(g,g'),d(h,h')}, otherwise. Here d denotes the distance between vertices and ~ means adjacency. Am I right in finding the above result? Is there any flaw. Please rectify if I am wrong. Heartily thanks. NOTE : 1st clause in the the formula directly follows from definition. In 2nd clause i took g=g'. the the vertices are like (g,h) and (g,h'). There must exist a vertex b such that g is adjacent to b . thus we get a path of length 2: (g,h)(b,c)(g,h'), where c is any vertex in $G_2$. thus distance is 2 in this case. I am doubtful about 3rd clause.","['graph-theory', 'discrete-mathematics', 'algebraic-graph-theory', 'combinatorics']"
464113,Quartic Equation having Galois Group as $S_4$,"Let $f(x)\in \mathbb{Z}[x]$ be an irreducible quartic polynomial with $S_4$ as Galois Group. Let $\theta$ be a root of $f(x)$ and set $K=\mathbb{Q}(\theta)$ . Now, the question is: Prove that $K$ is an extension of $\mathbb{Q}$ of degree 4 which has no proper subfields. Are there any Galois extensions of $\mathbb{Q}$ of degree 4 with no proper subfields? As I have adjoined a root of an irreducible quartic, I can see that $K$ is of degree $4$ over $\mathbb{Q}$ . But, why does there is no proper subfield of $K$ containing $\mathbb{Q}$ ? Suppose $L$ is proper subfield of $K$ , then $L$ has to be of degree $2$ over $\mathbb{Q}$ . So, $L$ is Galois over $\mathbb{Q}$ , i.e., $L$ is normal. So the corresponding subgroup of Galois group has to be normal. I tried working in this way but could not able to conclude anything from this. Any help/suggestion would be appreciated. Thank You","['galois-theory', 'abstract-algebra']"
464122,A problem in Folland's Real Analysis...,"This is problem 36 in Chapter 2 of the Folland's book. If $\mu(E_n)<\infty$ for all $n\in\mathbb N$ and $\chi_{E_n}\to f$ in $L^1$, then $f$ is a.e. equal to the characteristic function on a measurable set. My ""proof"": Convergence in $L^1$ implies convergence a.e. of a subsequence. So say $\chi_{E_{n_k}} \to f$ except on a set $A$ with $\mu(A)=0$ There exists $N\in \mathbb N$ such that $|\chi_{E_{n_k}}(x)-f(x)|<1/2 $ for all $k\geq N$,  for $x\in A^c$. Now I think it is clear that if $k\geq N$ then ${E_{n_k}}$ and ${E_{n_{k+1}}}$ can differ at most by a null set.  So taking $E=\bigcap _{k\geq N} {E_{n_k}}$, we are removing at most a null set $B$.  Then I think $f=\chi_E$ on the complement of $A\cup B$. That's my best attempt so far, but I did not use the assumption $\mu(E_n)<\infty$.  I may have needed to use completeness of the Lebesgue measure to guarantee $B$ is measurable.","['measure-theory', 'convergence-divergence', 'real-analysis']"
464137,"A set of the plane recursively including ""crosses""...","Definition: Call ""cross with center in $(x,y) \in \mathbb R^2$"" a set of $\mathbb R^2$ given by $(I_1(x)\times\{y\}) \cup (\{x\}\times I_2(y))$ where $I_1(x) \subseteq \mathbb R$ is a neighbourhood of $x$ and $I_2(y) \subseteq \mathbb R$ is a neighbourhood of $y$. Problem: Let $A \subseteq \mathbb R^2$ be a set such that for any $z \in A$ there exists a cross with center in $z$ which is all included in $A$. Is it true that $A$ must include a nonempty open set? ( Warm up exercise: prove that $A$ can actually be not open.)","['general-topology', 'real-analysis']"
464151,Proving Distributivity of Matrix Multiplication,"If $A,B,C$ are matrices I am thinking how to show that $$ A(B + C) = AB + AC$$ Is possible to show without sums like $\sum_i a_i, ..., \sum_j b_j$? It seems if I do the proof with many indexes then is tedious and I don't learn much from it.",['linear-algebra']
464164,Is it true that $\frac{1}n\sum_{k=1}^n\frac{2^k\mod k}k<\frac{1}2 ?$,"Let $r(n)$ be the remainder of $2^n$ divide by $n$ , such as $r(6)=4,r(p)=2(2<p\in \mathbb P)$ . Denote $$a_n=\frac{1}n\sum_{k=1}^n\frac{r(k)}k.$$ Is it true that $a_n<\frac{1}2 \forall n\in \mathbb N$ ? Since $0\leq r(k)<k,0\leq a_n<1$ , it seems that $\lim_{n\to \infty}a_n=\dfrac{1}2$ , if it exist. $a_{10}=0.33,a_{100}=0.31,a_{1000}=0.29,a_{10000}=0.31,a_{100000}=0.35.$ Denote $$a(m,n)=\frac{1}{n-m+1}\sum_{k=m}^n\frac{2^k\mod k}k,$$ then $a_n=a(1,n).$ $a(10^7,10^7+10^4)=0.40,a(10^8,10^8+10^4)=0.41,a(10^{10},10^{10}+10^4)=0.42,a(10^{20},10^{20}+10^4)=0.46$",['number-theory']
464179,"""Constrained"" numerical solutions of ODEs with conservation laws?","I know little about numerical methods and I was considering the following problem that possibly has standard solution in the literature. Suppose you have an ODE for wich we already know that it must satisfy a conservation law for some ""energy"" (for example hamiltonian dynamical systems such as $\frac 1 2 m \dot{x}^2+U(x)=\mbox{const}$). Then if we try to solve it with standard Runge Kutta methods we are likely to have errors for the energy at each step, which possibly will sum up. But what if I want to sacrifice a little accuracy for the ""position"" in order to have a greater accuracy for the energy? (This could be relevant if for example I am interested in having good approximation of long time asimptotic behaviors which should not be affected by errors in short time dynamics). Are there numerical methods which tries to give the best approximation given the constrain of keeping the energy ""strictly"" fixed?","['dynamical-systems', 'ordinary-differential-equations', 'real-analysis', 'numerical-methods']"
464181,"interesting Integral , alternative solution.","Show the following relation: $$\int_{0}^{\infty} \frac{x^{29}}{(5x^2+49)^{17}} \,\mathrm dx = \frac{14!}{2\cdot 49^2 \cdot 5^{15 }\cdot 16!}.$$ I came across this intgeral on a physics forum and solved by  (1) making a substitution (2) finding a recursive formula (with integration by parts). I would like to see a clever alternative solution to this one, since the only way I would solve such an integral is by finding a recursive formula. But I'm sure there are other ways/methods to do it (maybe more elegant) that  I want to discover.","['alternative-proof', 'integration']"
464223,Find the sum $\frac{1}{\sqrt{1}+\sqrt{2}} + \frac{1}{\sqrt{2}+\sqrt{3}} + ...+ \frac{1}{\sqrt{99}+\sqrt{100}}$,"I would like to check I have this correct Find the sum 
  $$\frac{1}{\sqrt{1}+\sqrt{2}} + \frac{1}{\sqrt{2}+\sqrt{3}} + ...+ \frac{1}{\sqrt{99}+\sqrt{100}}$$
  Hint: rationalise the denominators to get a 'telescoping' sum: a sum of terms in which many pairs add up to zero. I rationalised the denominators to get a series like this:
$$\frac{\sqrt{1}-\sqrt{2}}{-1}+\frac{\sqrt{2}-\sqrt{3}}{-1} +...+\frac{\sqrt{99}-\sqrt{100}}{-1}  $$
Which can be written:
$$\sqrt{2}-\sqrt{1} + \sqrt{3}-\sqrt{2}+\sqrt{4}-\sqrt{3}...+ \sqrt{99}-\sqrt{98} +\sqrt{100}-\sqrt{99}$$
Which is the telescoping sum the question talks about.
Most of the terms drop out to leave 
$$-\sqrt{1} +\sqrt{100} = 9$$ Have I got this correct?","['radicals', 'summation', 'algebra-precalculus', 'telescopic-series']"
