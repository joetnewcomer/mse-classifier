question_id,title,body,tags
830859,Reference request: algebraic methods in geometry,"I am a (soon to be) third year undergraduate who has just finished courses in linear and abstract algebra. While I enjoyed the study of algebraic structures in their own right, my favorite part of the courses were the applications of the algebraic machinery developed to geometric problems (i.e. the connection between Galois theory and compass-straightedge constructions.) As such, I was hoping for a reference that developed this general approach of using algebraic techniques to better understand problems in geometry. I realize this is a really broad request, but unfortunately as I know almost nothing about this ""algebraic geometry"" I don't know what to specifically ask for. Anything that falls under this category is fine with me. My understanding of algebra is still fairly elementary, so I would appreciate references that don't require too much background (read: I have nowhere near enough knowledge of commutative algebra to embark on the study of algebraic geometry, at least in its modern form.) If it helps, I specifically have covered almost all of Axler's Linear Algebra Done Right, and all of the material on groups and rings, as well as a little bit on fields, from Dummit and Foote. Thanks!","['geometry', 'reference-request', 'abstract-algebra']"
830864,Prove that $512^3 + 675^3 + 720^3$ is a composite number,We have to prove that the number $$N=512^3 + 675^3 + 720^3$$ is composite. I tried to use the identity $(a^3+b^3+c^3)=(a+b+c)(a^2+b^2+c^2-ab-bc-ca)+3abc$ hoping to take out some common factors from the R.H.S. but it didn't work. I also used $a^3+b^3=(a+b)(a^2-ab+b^2)$ (in all possible combos) and tried to combine with $c^3$ but that too didn't work. I nearly spent about 5 hours struggling with the question but no result :( Please help! Thanks in advance.,"['elementary-number-theory', 'algebra-precalculus', 'prime-numbers']"
830932,Airy differential equation and Galois group,"Consider the Airy equation $y^{(2)}=ry$ where $r \in \Bbb{C}(z)$ but not constant. How do you show that $G^0=G$, where $G$ is the galois group of the picard vessiot extension of solutions over $\Bbb{C}(z)$ and $G^0$ is its connected component. It would be helpful if someone could give me some reference for this fact.","['ordinary-differential-equations', 'algebraic-topology', 'abstract-algebra', 'algebraic-groups', 'group-theory']"
830945,Closed form of a trigonometric integral sought,"I am trying to evaluate the definite integral $I(a,b)$, with $a,b\in\mathbb{R}$, defined by $$I(a,b):=\int_{0}^{2\pi}\sqrt{1-(a+b\cos{\theta})^2}\mathrm{d}\theta.$$ Assume $a,b$ are suitably restricted to keep the integrand real-valued. My attempt. Introduce the parameter $w$ into the integrand and differentiate with respect to it: $$\begin{align}I(a,b,w)&=\int_{0}^{2\pi}\sqrt{1-(a+b\cos{(w\theta)})^2}\mathrm{d}\theta\\
\implies \partial_w I(a,b,w)&=\int_{0}^{2\pi}\frac{b\theta\sin{(w\theta)}(a+b\cos{(w\theta)})}{\sqrt{1-(a+b\cos{w\theta})^2}}\mathrm{d}\theta\\
&=ab\int_{0}^{2\pi}\frac{\theta\sin{(w\theta)}}{\sqrt{1-(a+b\cos{w\theta})^2}}\mathrm{d}\theta+b^2\int_{0}^{2\pi}\frac{\theta\sin{(w\theta)}\cos{(w\theta)}}{\sqrt{1-(a+b\cos{w\theta})^2}}\mathrm{d}\theta\end{align}.$$ My next step would probably be to integrate by parts, but at this point I'm wondering if there is a less messy way to go about this. Thoughts?","['definite-integrals', 'trigonometry', 'closed-form', 'integration']"
830946,Is this question too easy or am I getting it wrong?,"In my homework, I am asked to find the limit $$\lim\limits_{x\to0}{\frac{x}{e^x}}$$ But obviously, you could just substitute $x = 0$: $$\lim\limits_{x\to0}{\frac{x}{e^x}} = \lim\limits_{x\to0}{\frac{0}{e^0}}=\lim\limits_{x\to0}{\frac{0}{1}}=\lim\limits_{x\to0}{0} = 0$$ This seemed – by far – too easy. Is this really all there is to it? Is my solution valid? Edit : Apparently, this is valid. Still, I do wonder if these are the only conditions that allow me to actually substitute my limit variable.","['exponential-function', 'calculus', 'limits']"
830961,"Let $E ⊂ [0,1]$ be a measurable set, $m(E) ≥ \frac{99}{100} .$ Prove that there exists $x ∈ [0,1]$","I need some help on the following real analysis past qual problem.  I would appreciate some help. Let $E ⊂ [0,1]$ be a measurable set, $m(E) ≥ \frac{99}{100} .$ Prove that there exists $x ∈ [0,1]$
such that for any $r ∈ (0, 1),$
$m(E ∩ (x − r, x + r)) ≥ \frac{r}{4} .$ Is there a way to use the
Hardy-Littlewood maximal inequality?","['lebesgue-integral', 'measure-theory', 'lebesgue-measure', 'real-analysis']"
830980,How did they find this equilibrium condition?,"I'm studying from a book titled ""Mathematical Models in Population Biology and Epidemiology"" and we're dealing with SIS models. In a chapter called ""Infective Periods of Fixed Length"", we get to this differential-difference equation $$I'(t) = \beta I(t) [K - I(t)] - \beta I(t - \tau) [K - I(t - \tau)]$$ We find equilibria by incorporating initial data for $-\tau \leq t \leq 0 $ into the model by writing it in the integrated form, $$I(t) = \int_{t - \tau}^{t} \beta I(x) [K - I(x)] dx$$ The authors get that the equilibrium condition for $I(t)$ is $$I = 0 \text{ or } 1 = \beta \tau (K - I)$$ I met with my professor before he left, and he could not figure out how they came up with this. Perhaps, one you could help me understand how they found this equilibrium condition.","['ordinary-differential-equations', 'mathematical-modeling']"
831002,"probability, expectation, variance","A 10-digit long number is picked randomly and each digit's pick is independent and has an equal probability of being picked (1/9 because there's digits 1 to 9). Let $X = \#\{\text{missing digits}\}$ (i.e. if the # is 1357768931, X = 2 because there's no 2 or 4) What is E(X)? Var(X)? I am so confused as to how to start this. Some guidance please?","['statistics', 'covariance', 'random-variables', 'expectation']"
831019,Why the ideal defining a closed subscheme is unique?,"Let $X$ be a scheme.
We defined a closed subscheme of $X$ to be a scheme $(Z, \mathcal{O}_Z)$ such that $Z$ is a closed subset of $X$
and $i_*\mathcal{O}_Z \simeq \mathcal{O}_X/\mathcal{J}$, where $\mathcal{J}$ is an ideal of $\mathcal{O}_X$ and $i : Z \hookrightarrow X$ the inclusion map.
Why the ideal $\mathcal{J}$ is unique ?",['algebraic-geometry']
831020,What's the spectrum of this operator in $\ell^2$?,"Suppose that $\ell^2 = \biggl\{(x_n)_n \in \mathbb{K}^{\mathbb{N}_0} \biggm|
\sum_{n=1}^{\infty}|{x_n}^2| < +\infty \biggr\}$ is a Hilbert-space with the inproduct $\langle\cdot,\cdot\rangle_2: \ell^2 \to \ell^2: (x,y) \mapsto \sum_{n=1}^\infty \overline{x_n}y_n$. Consider the operator $f: \ell^2 \to \ell^2: (x_0, x_1, \ldots) \mapsto (x_0, 0, x_1, 0, \ldots)$. I'm supposed to give the spectrum $\sigma(f) = \{\lambda \in \mathbb{K} \mid f-\lambda I \text{ not invertible}\}$, where $I$ is the identical function. I've already shown that 1 is the only eigenvalue of $f$, so 1 should be part of $\sigma(f)$, because $f-I$ isn't injective. I also think that $f$ isn't surjective, so 0 should be in the spectrum too. Unfortunately, I didn't find a way to calculate the whole spectrum, although I'm having the feeling that it shouldn't be that difficult. How can I do this?","['spectral-theory', 'hilbert-spaces', 'analysis']"
831022,Mathematical research of Pokémon,"In competitive Pokémon-play, two players pick a team of six Pokémon out of the 718 available. These are picked independently, that is, player $A$ is unaware of player $B$'s choice of Pokémon. Some online servers let the players see the opponents team before the match, allowing the player to change the order of its Pokémon. (Only the first matters, as this is the one that will be sent into the match first. After that, the players may switch between the chosen six freely, as explained below.) Each Pokémon is assigned four moves out of a list of moves that may or may not be unique for that Pokémon. There are currently 609 moves in the move-pool. Each move is assigned a certain type, and may be more or less effective against Pokémon of certain types. However, a Pokémon may have more than one type. In general, move effectiveness is given by $0.5\times$, $1\times$ and $2\times$. However, there are exceptions to this rule. Ferrothorn, a dual-type Pokémon of steel and grass, will take $4\times$ damage against fire moves, since both of its types are weak against fire. All moves have a certain probability that it will work. In addition, there are moves with other effects than direct damage. For instance, a move may increase one's attack, decrease your opponent's attack, or add a status deficiency on your opponent's Pokémon, such as making it fall asleep. This will make the Pokémon unable to move with a relatively high probability. If it is able to move, the status of ""asleep"" is lifted. Furthermore, each Pokémon has a ""Nature"" which increases one stat (out of Attack, Defense, Special Attack, Special Defense, Speed), while decreases another. While no longer necessary for my argument, one could go even deeper with things such as IV's and EV's for each Pokémon, which also affects its stats. A player has won when all of its opponents Pokémon are out of play. A player may change the active Pokémon freely. (That is, the ""battles"" are 1v1, but the Pokémon may be changed freely.) Has there been any serious mathematical research towards competitive Pokémon play? In particular, has there been proved that there is always a best strategy? What about the number of possible ""positions""? If there always is a best strategy, can one evaluate the likelihood of one team beating the other, given best play from both sides? (As is done with chess engines today, given a certain position.) EDIT: For the sake of simplicity, I think it is a good idea to consider two positions equal when 1) Both positions have identical teams in terms of Pokémon. (Natures, IVs, EVs and stats are omitted.) As such, one can create a one-to-one correspondence between the set of $12$ Pokémon in position $A$ and the $12$ in position $B$ by mapping $a_A \mapsto a_B$, where $a_A$ is Pokémon $a$ in position $A$. 2) $a_A$ and $a_B$ have the same moves for all $a\in A, B$.","['game-theory', 'probability', 'soft-question', 'combinatorics']"
831032,This is question 3.3 from Alan Karr's Probability,"What is the minimum number of points a sample space must contain in order that there exist $n$ independent events none of which has probability zero or one? I'm thinking the answer is $2^n$, but this is just from checking by hand for the values $n=2$ and $n=3$.  I thought maybe a proof by induction would be appropriate, but didn't make it terribly far with it. I'm merely studying probability because I want to be better at it, and this seems to be a pretty classic problem. So it seemed like a good problem to understand.",['probability']
831036,Estimating a finite sum of complex numbers (Rudin Lemma 6.3).,"In Rudin's book, Real and Complex analysis, Lemma 6.3. states: If $z_1,...,z_N$ are complex numbers then, there is a subset $S$ of $\{1,...,N\}$ for which $$\left|\sum_{k\in S} z_k\right|\ge \frac{1}{\pi}\sum _{k=1}^N |z_k|.$$ In the proof he claims the following: Let $\theta_0$ be the value for which $$\sum _{k=1}^N |z_k|\cos^{+}(\alpha_k-\theta),$$ attains it's maximum. Therefore $$\sum _{k=1}^N |z_k|\cos^{+}(\alpha_k-\theta_0)\ge \frac{1}{2\pi}\int_{-\pi}^\pi\sum _{k=1}^N |z_k|\cos^{+}(\alpha_k-\eta)d\eta=\frac{1}{\pi}\sum _{k=1}^N |z_k|,\tag{1}$$ i.e. the maximum is bounded below by the avergae of the sum over $[-\pi,\pi]$. Could someone help me to understand why this is true. I can see, for example, that there is a constant $0<C<1$ such that inequality $(1)$ is true for $C$ instead of $\pi$, however, I fail to see why his claim is true. Moreover, is $1/\pi$ the best constant?",['analysis']
831043,Is there a correlation between numbers with record totient valence and the factorials?,"For example, there are 10 values of $n$ such that $\phi(n) = 24$, and that's more than for any smaller, positive integer. It's not true of 120 but it is true of 720. I haven't verified it for 5040.",['number-theory']
831077,Multiple integral over a disc,"I would need some help on this integration problem: $$I=\int_0^{2\pi}\int_0^{R}\int_0^{2\pi}\int_0^{R}\exp(-a\ r_{12})	\ r_1 \ r_2 \,\mathrm{d}r_1\,\mathrm{d}\phi_1\,\mathrm{d}r_2\,\mathrm{d}\phi_2$$ Here, $r_1, r_2, \phi_1$ and $\phi_2$ are the polar coordinates for the integral on a disc with radius R. And $r_{12}$ is the distance between the coordinates, which can be calculated by $$r_{12}=\sqrt{r_1^2+r_2^2-2r_1r_2\cos(\phi_1-\phi_2)}.$$ Below a plot of the problem for $a=1$, $R=1$ and fixed coordinates of the first point at $(0,0)$:","['multivariable-calculus', 'polar-coordinates', 'exponential-function', 'integration']"
831093,for which value of $a$ that $ \big(\sum\frac {1}{u_n}\big) $ converges?,"For any real number $a$ (positive or negative), define a sequence $\{u_n\}$ (depending on $a$) recursively by $u_0=2$ and
$$ \int_{u_n}^{u_{n+1}}(\ln u)^a\,du=1.$$ For which $a\in\mathbb{R}$ does
$$ \sum_{n=0}^\infty \frac {1}{u_n}$$
 converge? Thank you for your replies","['convergence-divergence', 'sequences-and-series']"
831096,Do row and column permutations generate all permutations?,"Suppose $m,n\ge 1$ are integers. Do row and column permutations of an $m\times n$ matrix generate the group of all permutations of the $mn$ entries of the matrix? More formally, let $A_1$ be the matrix
$$
A_1 = \left[\begin{array}{cccc} 1 & 2 & \cdots & n \\
n+1 & n+2 & \cdots & 2n \\
\vdots & \vdots & \ddots &\vdots \\
(m-1)n+1 & (m-1)n + 2 & \cdots & mn
 \end{array}\right]
$$
and let $A_2$ be an $m\times n$ matrix such that each of the numbers $1,\ldots, mn$ appears (exactly once) as an entry in $A_2$. Is there necessarily a sequence of row and column permutations that transforms $A_1$ into $A_2$? If not, can one easily characterize which permutations are generated by row and column permutations?","['matrices', 'permutations', 'group-theory', 'group-actions']"
831097,"Given an ellipse's center, focus and point, find its equation.","Given an ellipse's center is $(2,1)$, focus is (2,4) and point is (3,-3), we have Plug in center: $\frac{(x-2)^2}{a^2}+\frac{(y-1)^2}{b^2} = 1$ Use focus: $4^2=a^2-b^2$ $16=a^2-b^2$ Use point: $\frac{(3-2)^2}{a^2}+\frac{(-3-1)^2}{b^2} = 1$ $\frac{1}{a^2}+\frac{16}{b^2} = 1$ $b^2+16a^2 = a^2b^2$ Is this right? Combine equations: $b^2+16a^2 = a^2b^2$ $16=a^2-b^2$ So, we have: $0 = b^2 - b^2 - 16^2$ $b^2 = \frac{1}{2} (1+5 \sqrt{41})$ and $a^2 = 16 + \frac{1}{2} (1+5 \sqrt{41})$","['analytic-geometry', 'algebra-precalculus']"
831121,Show $f$ is analytic if $f^8$ is analytic,"This is from Gamelin's book on Complex Analysis. Problem : Show that if $f(z)$ is continuous on a domain $D$, and if $f(z)^8$ is analytic on $D$, then $f(z)$ is analytic on $D$. (I assume the intention is that $D$ is nice, i.e. open and connected) I'm not exactly sure how to approach this. I'm guessing it has something to do with zeroes of $f$. For example, around non-zeroes, $f$ is analytic since $z^{1/8}$ is nonzero in a neighborhood. Or something along those lines. The details are eluding me. Any help would be appreciated!","['complex-numbers', 'complex-analysis', 'analysis']"
831126,Limit evaluation method inconsistency?,"I'm having trouble understanding what really happens when we evaluate the limit of a certain function f(x) as x approaches a certain value. For ex, if we have lim x-->2 $\frac{x^2 + x -6}{(x-2)}$ we can't just plug in 2 and evaluate that because f(x) is undefined when x=2. So we factor out the numerator and find that lim x-->2 $\frac{x^2 + x -6}{(x-2)} = \frac{(x+3)(x-2)}{(x-2)}$ Here is where there seems to be an inconsistency as far as I understand what's going on. We are ok with canceling out the (x+2) terms because we're not saying that x=2, we're saying x approaches 2, so (x-2) in the denominator =/= 0 and we can simplify. However, then it seems we just plug 2 into (x+3) and say that lim x-->2 $\frac{x^2 + x -6}{(x-2)} = 5$. That's very confusing to me because we go from not being ok with plugging in the value 2, instead imagining that we're getting closer and closer to it from both ends, to just plugging in 2 and saying (2+3) = 5. I understand that there's no more problem with using 2 once we got rid of (x-2) in the denominator, but what happened to just approaching x?","['calculus', 'limits']"
831137,"$2^b-1$ does not divide $2^a+1$,how can I show it? [duplicate]","This question already has answers here : Prove $2^b-1$ does not divide $2^a + 1$ for $a,b>2$ (6 answers) Closed 8 years ago . $$\text{ If } a,b \geq 3, \text{ show that } \  2^b-1 \text{ does not divide } 2^a+1$$ How can I do this? Could you give me a hint?",['number-theory']
831143,Advanced Galois theory/field theory book suggestions,I have done the equivalent of an undergraduate algebra course(rings/fields/groups) and have read Stewart's Galois theory book. Galois theory was a lot of fun and I would like to continue studying it but I have no idea how to progress studying it or what the big theorems/questions further are. I would like any suggestions on books that extend basic galois theory. All the suggestions  I can find are at the level of Stewart's book(ie. end with essentially a proof of the insolubility of the quintic).,"['galois-theory', 'book-recommendation', 'abstract-algebra']"
831157,Recovering a character from a cohomology class,"Let $G$ be a finite group, and consider $\mathbf Z, \mathbf Q$ and $\mathbf Q/\mathbf Z$ as trivial $G$-modules. Then $H^1(G, \mathbf Q/\mathbf Z) = {\rm Hom}(G, \mathbf Q/\mathbf Z) = \widehat{G}$. Moreover, for a finite group, we have $H^i(G, \mathbf Q)=0$ for $i>0$. The long exact sequence of cohomology coming from $\mathbf Z \to \mathbf Q \to \mathbf Q/\mathbf Z$ therefore induces an isomorphism
$$\widehat{G} = H^2(G, \mathbf Z).$$ The group $H^2(G, \mathbf Z)$ is in bijection with central extensions of $G$ by $\mathbf Z$. Using this, we can describe the map $\epsilon: \widehat{G} \to H^2(G, \mathbf Z)$ realizing the above isomorphism: namely, given a character $\chi : G \to \mathbf Q/\mathbf Z$, we can pull-back the sequence $\mathbf Z \to \mathbf Q \to \mathbf Q/\mathbf Z$ along $\chi$ to get a sequence $\mathbf Z \to E \to G$, which is a central extension of $G$ by $\mathbf Z$. Of course the map $\epsilon$ exists even when $G$ is not finite, but when $G$ is finite, $\epsilon$ is an isomorphism. I am wondering if there is a simple way of describing the inverse of $\epsilon$ in the case where $G$ is finite. Namely, given a central extension $\mathbf Z \to E \to G$, how can one construct the corresponding character of $G$?","['group-cohomology', 'group-theory']"
831159,Evaluating $\sum_{n=1}^{99}\sin(n)$ [duplicate],"This question already has answers here : How can we sum up $\sin$ and $\cos$ series when the angles are in arithmetic progression? (8 answers) Closed 10 years ago . I'm looking for a trick, or a quick way to evaluate the sum $\displaystyle{\sum_{n=1}^{99}\sin(n)}$. I was thinking of applying a sum to product formula, but that doesn't seem to help the situation. Any help would be appreciated.","['trigonometry', 'summation', 'algebra-precalculus', 'contest-math']"
831211,Axis of rotation of composition of rotations (Artin's Algebra),"Say $R_1$, $R_2$ are rotations in $\mathbb{R}^3$ with axes and angles $(v_1,\theta_1), (v_2,\theta_2)$ respectively. Since $SO_3$ is a group, we have that $R_2 \circ R_1$ is a rotation with some axis $v$. Is there a geometric way of finding $v$? This is problem 4.5.10 in Artin's Algebra . My attempts have included looking at $v$ as a differentiable function of $\theta_1$ and $\theta_2$, writing out the corresponding matrix equations, staring at a wall, and guessing. Not sure where to go from here.","['geometry', 'linear-algebra', 'eigenvalues-eigenvectors', 'euclidean-geometry']"
831267,"Is there a case ""infinite"" p-group is meaningful?","I'm hesitating to choose my definition for ""p-subgroup"". If i only consider finite cases, i would define it as a group with the order which is a power of $p$. If i should consider infinite cases too, i would define it as a group such that every order of an element is a power of $p$. Is there a case in which the concept of infinite p-group is useful?","['group-theory', 'abstract-algebra']"
831273,Cubic convergence of Rayleigh quotient iteration?,"Trefethen and Bau, Numerical Linear Algebra, p. 208 states that Rayleigh quotient iteration (combining Rayleigh quotient estimate for eigenvalues and inverse power iteration) converges cubically ...the convergence is ultimately cubic in the sense that if
  $\lambda_J$ is an eigenvalue of $A$ and $v^{(0)}$ is sufficiently
  close to the eigenvector $q_J$, 
  then $$\|v^{(k+1)} - (\pm q_J)\| =  O(\|v^{(k)} - (\pm q_J)\|^3)$$ and $$|\lambda^{(k+1)} - \lambda_J| =
> O(|\lambda^{(k)} - \lambda_J|^3)$$ as $k \rightarrow \infty$. Their argument is as follows. Suppose that convergence occurs, and that
$\|v^{(k)} - q_J\| \leq \epsilon$ for some small $\epsilon$.
Then the Rayleigh quotient estimation for an eigenvalue gives an eigenvalue
estimate $\lambda^{(k)}$ with $|\lambda^{(k)} - \lambda_J| = O(\epsilon^2)$. Then apply the proof of the inverse power iteration for one step to obtain $v^{(k+1)}$ from $v^{(k)}$ and $\lambda^{(k)}$, so that
$$\|v^{(k+1)} - q_J \|= O(|\lambda^{(k)}-\lambda_J| \|v^{(k)} - q_J\|) = O(\epsilon^3)$$
with the constants in the big-Oh symbols uniform in sufficiently small neighborhoods. I don't see the left most equality above, nor why the constants are uniform. It seems that all power iteration gives is
$$O(|\lambda^{(k)}-\lambda_J|/|\lambda^{(k)}-\lambda_K|)$$
where $\lambda_K$ is the second closest eigenvalue.","['linear-algebra', 'numerical-methods']"
831278,Value of the given limit,"I need to calculate the value of : $$\lim_{n\to \infty}\frac{1}{n}\sum_{r=1}^{2n}{\frac{r}{\sqrt{n^2+r^2}}}$$ I had been trying to use Cesàro summation but somehow, I might be messing up. The options are : $$\sqrt{5}+1,\sqrt{5}-1,\sqrt{2}-1,\sqrt{2}+1$$","['summation', 'limits']"
831283,Nontrivial subsequences of the harmonic series that diverge on the order of $\log(\log(\log(n)))$.,"It is common knowledge that $$\sum_{\text{Integer}}^\infty \frac{1}{n} \sim \log(n),$$ and that $$\sum_{\text{Prime}}^\infty \frac{1}{p} \sim \log(\log(n)).$$ I am looking for another subseries of the harmonic series that diverges with some number of iterated logarithms like $$\sum_{??}^\infty \frac{1}{q} \sim \log(\log(\log(n))).$$ For convenience this will be called ""third order"" divergence. I am specifically looking for a series that is not trivial. A trivial example would be a series that is constructed so that terms are only added when the cumulative sum is less than $\log(\log(\log(\log (n)))$. The more ""natural"" the better (although I realize that this is subjective). Any answers could include the reciprocal of primes of the form $4n+1$, all twin primes, all odd perfect numbers, etc. The only other thing needed would be to show the order of divergence. I am also looking for verification/disproof of the current conjectured answer. Thank you. Bounty rules: I am looking for a proof or significant demonstration of a series that exhibits this behavior. It is not only limited to ""third order"" logarithms and can be any ""order"" greater than $2$. I have decided to accept and bounty Winther's answer even though it would not be considered ""natural"". I believe that the proof is correct and it generalizes to any order of logarithm. It also provides a good explanation as to why the prime series diverges by second order logarithms. Even though the question is answered I would still accept the submission of other ""more natural"" series if any of them happen to pop up.",['sequences-and-series']
831288,"Can you find this limit in a ""nicer"" way?","I'm trying to show that: $$\lim\limits_{n\to\infty}{n(\sqrt[n]{n}-1)} = \infty$$ From what I've tried now, all I end up with is basically rewriting the left term as: $$\lim\limits_{n\to\infty}{\frac{\sqrt[n]{n}-1}{\frac{1}{n}}}$$ and then applying De L'Hôpital's rule (which gets really messy considering that we're deriving $\sqrt[n]{n}$, since $\frac{d}{dn}\sqrt[n]{n} = -n^{\frac{1}{n}-2}(\ln(n)-1)$). Is there any ""nice and quick"" way to solve this?","['calculus', 'derivatives', 'limits']"
831304,How to evaluate improper integral $\int_{0}^{\infty}\frac{\tan^{-1}{x}}{e^{ax}-1}dx$?,"I'm trying to evaluate the improper integral, $$I(a)=\int_{0}^{\infty}\frac{\tan^{-1}{x}}{e^{ax}-1}\mathrm{d}x,~~~\text{where }a\in\mathbb{R}^+.$$ Does this integral have a simple closed form expression? And if so, how best to obtain it? My attempt My first idea was to integrate by parts using $f=\tan^{-1}{x}$ and $dg=\frac{\mathrm{d}x}{e^{ax}-1}$, with the hope that the resulting integral would be amenable to solution by differentiating under the integral sign. So I found the indefinite integral, $$\int\frac{\tan^{-1}{x}}{e^{ax}-1}\mathrm{d}x=\tan^{-1}{x}\left(\frac{1}{a}\log{(1-e^{ax})}-x\right)-\int\left(\frac{\log{(1-e^{ax})}}{a(x^2+1)}-\frac{x}{x^2+1}\right)\mathrm{d}x,$$ but then I realized that this would result in an imaginary boundary term for the corresponding definite integral over $[0,\infty)$ since, $$\begin{cases}\lim_{x\to\infty}\tan^{-1}{x}\left(\frac{1}{a}\log{(1-e^{ax})}-x\right)=i\frac{\pi^2}{2a},\\
\lim_{x\to0}\tan^{-1}{x}\left(\frac{1}{a}\log{(1-e^{ax})}-x\right)=0.\end{cases}$$ I want to avoid complex variables if at all possible, so I don't know if I want to continue down this route. Can anyone offer any hints or suggestions? CORRECTION: As Vladimir pointed out, the correct anti-derivative is actually, $$\int\frac{\tan^{-1}{x}}{e^{ax}-1}\mathrm{d}x=\tan^{-1}{x}\left(\frac{1}{a}\log{(e^{ax}-1)}-x\right)-\int\left(\frac{\log{(e^{ax}-1)}}{a(x^2+1)}-\frac{x}{x^2+1}\right)\mathrm{d}x.$$ Then, since, $$\begin{cases}\lim_{x\to\infty}\tan^{-1}{x}\left(\frac{1}{a}\log{(e^{ax}-1)}-x\right)=\frac{\pi}{2}\cdot0=0,\\
\lim_{x\to0}\tan^{-1}{x}\left(\frac{1}{a}\log{-e^{ax}-1)}-x\right)=0,\end{cases}$$ we have, $$I(a)=-\int_{0}^{\infty}\left(\frac{\log{(e^{ax}-1)}}{a(x^2+1)}-\frac{x}{x^2+1}\right)\mathrm{d}x.$$","['definite-integrals', 'improper-integrals', 'closed-form', 'integration']"
831330,"GCD(a,b) as a linear combination of a,b","I know that the GCD(a,b) can be written as a linear combination of a,b (ma + nb = GCD(ab)). How can I select which coefficient (m or n) is positive? In other words, for example, if after executing extended euclidean division, I obtain the coefficient for b to be negative, how do I manipulate the linear combination so that the coefficient for b is no positive?",['discrete-mathematics']
831344,How find this ODE solution $f''(x)=f(x)(1+2\tan^2{x})$,"Question: Find the ODE solution:
  $$f''(x)=f(x)(1+2\tan^2{x})$$ such $f(0)=0$ My idea: let $y=f(x)$
 then
$$y''=y(1+2\tan^2{x})$$
$$\Longrightarrow \dfrac{y''}{y}=1+2\tan^2{x}$$ and I found  use wolf : http://www.wolframalpha.com/input/?i=y%27%27%3Dy%281%2B2tan%5E2x%29&dataset= Now How can you find this solution? by hand? Thank you",['ordinary-differential-equations']
831352,Locus using Euclidean geometry,"Let $P$ be any point in the plane. Find the locus of $P$ such that $PA^2 + PB^2 = PC^2$, where $ABC$  is a  triangle. I have found the locus. It's a circle having center at point $Q$, such that $AQBC$ is a parallelogram. Now from $A$, drop a perpendicular $AD$  on $BC$. Taking $BC$ as diameter, draw a circle and say it intersects $AD$ at $K$. Draw $MC$ perpendicular to $KC$ and equal to $KC$. Take the length $KM$ and draw a circle having radius equal to $KM$ with its center at at $Q$. This circle represents the locus of $P$. I have found the proof using coordinate geometry. Can someone suggest a solution using pure Euclidean geometry?","['geometry', 'vectors', 'locus', 'euclidean-geometry']"
831361,Do cyclic permutations of rows and column entries generate all permutations?,"Background: I am interested in the group of permutations of the entries of a general $m\times n$ matrix. In particular, I am interested in (1) interesting sets of simple generators for this group that might be used in a puzzle or game and (2) algorithms for computing the smallest sequence of generators that produce a given permutation.
This question focuses on one candidate set of generators. Question: Suppose $m,n\ge 1$ are integers. Consider the set of permutations of a general $m\times n$ matrix containing all single-row cyclic permutations and all single-column cyclic permutations. Is every possible permutation of matrix entries generated by this set? More formally, for all integers $r>0$, let $\sigma_r$ be the permutation of $1,\ldots,r$ defined by $1\mapsto 2\mapsto 3\mapsto \cdots \mapsto r \mapsto 1$. For each $k=1,\ldots,m$, let $r_k:\mathbb{R}^{m\times n}\to\mathbb{R}^{m\times n}$ be defined by
$$
(r_k A)_{ij} = \begin{cases}
A_{ij} &\text{if } i\ne k \\
A_{i\sigma_n(j)} &\text{if }i=k.
\end{cases}
$$
Similarly, for each $l=1,\ldots,n$, let $c_l:\mathbb{R}^{m\times n}\to\mathbb{R}^{m\times n}$ be defined by
$$
(c_l A)_{ij} = \begin{cases}
A_{ij} &\text{if } j\ne l \\
A_{\sigma_m(i) j} &\text{if }j=l.
\end{cases}
$$ Clearly, each $r_k$ and $c_l$ is a permutation of the entries of an $m\times n$ matrix. Are all such permutations generated by $\{r_1,\ldots,r_m,c_1,\ldots,c_n\}$ ? If not, is there any easy characterization of the generated group? EDIT: As @Omnomnomnom pointed out in his answer, a parity argument can be used to show all odd permutations of entries cannot be generated if both $m$ and $n$ are odd, because all the generators then have even parity. But that is (obviously) not a full characterization of the permutation group generated by these cycles.","['matrices', 'permutations', 'group-theory']"
831362,$X_n \to X$ a.s. implies...,"Let $X_n$ be independent. $ X_n \to X \, a.s.$ implies $ \sum_n P( |X_n-X|>\epsilon) < \infty$ I tried to prove as follows, which is wrong. Note that $ X_n \to X \, a.s.$ is equivalent to $\forall \epsilon>0, \, P( |X_n-X|>\epsilon \quad \textrm{i.o})=0.$ Then, using contraposition of 2nd Borel-Cantelli lemma, I get to the conclusion. Here, I made a mistake on application of BC lemma since independence of $\{X_n\}$ does not imply independence of $\{X_n-X\}$ . Anyone who could give me some hint about this? Thanks in advance.",['probability-theory']
831365,The Jordan-Hölder Theorem,"I want to solve the following exercise from Dummit & Foote's Abstract Algebra (exercise 10 in page 106): Prove part (2) of the Jordan-Hölder Theorem by induction on $\min\{r,s\}$. [Apply the inductive hypothesis to $H=N_{r-1} \cap M_{s-1}$ and use the preceding exercises.] The Jordan-Hölder Theorem as stated in the book is: Let $G$ be a finite group with $G \neq 1$. Then $G$ has a composition series and The composition factors in a composition series are unique, namely, if $1=N_0 \leq N_1 \leq \dots \leq N_r=G$ and $1=M_0 \leq M_1 \leq \dots \leq M_s=G$ are two composition series for $G$, then $r=s$ and there is some permutation $\pi$ of $\{1,2,\dots,r\}$ such that $$M_{\pi(i)} / M_{\pi(i)-1} \cong N_i/N_{i-1}, \; \; \; \; \; \; \; \; \; \; \; 1 \leq i \leq r.  $$ My attempt: We induct on $n:=\min\{r,s\}$. The case $n=2$ was proven in Exercise 9. We assume the induction hypothesis holds for all groups with two composition series the shorter length of which is $<n$. Let $G$ be a group with two composition series as stated in the theorem such that $\min\{r,s\}=n$. The hint suggests to consider $H=N_{r-1} \cap M_{s-1}$. However, I don't see how: I don't have two composition series for $H$ in mind, and even if I had, I (seemingly) couldn't deduce anything about the composition factors of $G$. Please help me complete this proof, Thanks!","['finite-groups', 'group-theory']"
831387,Expectations and variance with rolling a dice 10 times,"Let's say you roll a fair dice 10 times and X is the number of sides that never show up.
(i.e. Roll 1 - 10 = 1424145221, X = 2 because 3 and 6 never show up) Values of $N=0,1,2,3,4,5.\\
P(N=6) = 0$ because at least one of the numbers has to show up. SOLUTION: Use inclusion-exclusion","['statistics', 'dice', 'expectation', 'summation', 'probability']"
831404,probability in roulette!,"So I have read how to play roulette...still a little confused, and now I'm faced with a probability question about it which makes the problem a little harder. Please help me reason this where possible. Let's say you're in a debt of $500. You have $250 and you're going to use that to try to pay back your debt. What are the advantages of: Betting all on black So if I bet all on black, I have a 0.5 chance of winning \$250 (and then having $500). So simply advantages are quick return if I win...and just being bankrupt otherwise. Probably a risk not taking. Betting $50 on black 5 times (and if you haven't won, then you're just bankrupt). Would this be an expectation question? I can make X~Bern(p). Would I have to use any conditional cases here? Betting in increments of $x until you make it all back or you go bankrupt.","['statistics', 'probability-distributions', 'probability', 'gambling']"
831408,Is distance between two sets equal to that between their boundary?,"I am not sure if the statement below is true. The statement is:
Let $(M,d)$ be a connected metric space and $A, B$ be two nonempty subsets of $M.$ Assume the boundary $\partial A$ and $\partial B$ are nonempty. Suppose that $A\cap B=\emptyset.$ Then
$$d(A,B)=d(\partial A, \partial B).$$
Here $d(E,F):=\inf\{d(x,y)\mid x\in E, y\in F\}, \forall E,F\subset M.$ If the statement is true, how to prove it?  If it is not valid, give a counterexample, and is it valid  if  $(M, d)$ is complete?","['general-topology', 'metric-spaces']"
831434,Minimal polynomial reducible modulo every prime $p$,"Suppose $K = \mathbb{Q}(\alpha)$ with $\alpha = a + b\sqrt{D_1}+c\sqrt{D_2}+d\sqrt{D_1D_2}$ with $D_1,D_2 \in \mathbb{Z}$. Prove that the minimal polynomial $m_\alpha(x)$ for $\alpha$ over $\mathbb{Q}$ is irreducible of degree 4 over $\mathbb{Q}$ but is reducible modulo every prime $p$. In particular show that the polynomial $x^4 - 10x^2 +1$ is irreducible in $\mathbb{Z}[x]$ but is reducible modulo every prime. [Use the fact that there are no biquadratic extensions over finite fields.] So far I have established the following: $[\mathbb{Q}(\alpha):\mathbb{Q}]=\deg(m_\alpha(x))=4$ $Gal(\mathbb{F}_{p^n}/\mathbb{F}_p)$ is cyclic, hence no biquadratic extension (which is iso to $V_4$) exists over finite fields. I'm having a problem proving the reducibility mod every prime though. Any hints?","['galois-theory', 'finite-fields', 'abstract-algebra', 'minimal-polynomials']"
831440,Have the answer. Need the problem.,I took a combinatorics course last semester and to my surprise it was really interesting. A common theme in the class was to to come up with questions given the answer. I am working on a problem at the moment that escapes my powers of creativity. It goes as follows: Come up with a problem whose answer is: $$(k+1) \binom{k+n+3}{k+2}-\binom{k+n+2}{k}$$ Does anyone know a good way to solve problems of this nature? Or can help me come up with a scheme to tackle this problem? Thank you.,['combinatorics']
831443,Split groups and quasi-split groups.,"By definition, a quasi-split group over a field is a reductive group with a Borel subgroup defined over the field. A split group is a quasi-split group which has split torus ($T = \mathbb{G}_m^n$, $\mathbb{G}_m$ is the multiplicative group). Are there some examples of quasi-split groups which are not split? Thank you very much.","['algebraic-groups', 'abstract-algebra']"
831471,Problem from Apostol's analytic number theory book,"Im trying to solve the exercise 13.2 in Apostol's analytic number theory book: Let $A(x)=\sum_{n\leq x}a(n)$, where $a(n)$ is zero unless $n=p^k$ for some prime $p$, in that case $a(n)=1/k$. Prove that $A(x)=\pi(x)+O(\sqrt{x}\log \log x)$. I've tried things like this: 
By the definition of the function $a$, we have that \begin{equation*}A(x)=\underset{p\leq x}{\sum}\sum_{\substack{k\in \mathbb{Z}^+\\  p^k\leq x}}a(p^k)+1=\underset{p\leq x}{\sum}\sum_{\substack{k\in \mathbb{Z}^+\\  p^k\leq x}}\frac{1}{k}.\end{equation*}
The last formula holds for $x\geq 1$. Look that, for all $k\in \mathbb{Z}^+$, we have the following
$$p^k\leq x \iff k\log p=\log (p^k)\leq \log x \iff k \leq \log_p(x).$$ 
Here $\log_p x:=\frac{\log x}{\log p}$. By all this and theorem 3.2 from Apostol, we get \begin{eqnarray*}
A(x) & = & \underset{p\leq x}{\sum}\sum_{\substack{k\in \mathbb{Z}^+\\  p^k\leq x}}\frac{1}{k}= \underset{p\leq x}{\sum}\sum_{\substack{k\in \mathbb{Z}^+ \\ k\leq \log _p x}}\frac{1}{k}= \underset{p\leq x}{\sum}[\log \log_p x + C + O(\frac{\log p}{\log x})]\\
& = & \underset{p\leq x}{\sum}O(\log \log x)+\underset{p\leq x}{\sum}C+\underset{p\leq x}{\sum}O(\log^{-1}x)\\
& = & O(\log \log x)\underset{p\leq x}{\sum}1+C\underset{p\leq x}{\sum}1+O(\log^{-1}x)\underset{p\leq x}{\sum}1\\
& = & O(\log \log x)\pi(x)+(C-1+1)\pi(x)+O(\log^{-1}x)\pi(x)\\
& = & O(\log \log x)O(\frac{x}{\log x})+(C-1)O(\frac{x}{\log x})+\pi(x)+O(\log^{-1}x)O(\frac{x}{\log x}).
\end{eqnarray*} Could someone please help me finishing this exercise? Due to Greg Martin's answer (again) i made this solution: First, look that if $k$ is a positive integer suchthat $p^k \leq x$ for some prime $p$, then $2^k \leq p^k \leq x$, so $k\log 2=\log 2^k\leq \log x$ and $k\leq \log_2 x$. Therefore \begin{eqnarray*}
A(x) & = & \sum_{k\in \mathbb{Z}^{+}} \sum_{\substack{p \text{ prime}\\ p^k \leq x}} \frac{1}{k}=\sum_{k=1}^{[\log_2 x]}\frac{1}{k}\sum_{\substack{p \text{ prime}\\ p \leq x^{1/k}}}1\\
& = & \sum_{k=1}^{[\log_2 x]}\frac{\pi(x^{1/k})}{k}\\
& = & \pi(x)+\sum_{k=2}^{[\log_2 x]}\frac{\pi(x^{1/k})}{k}\\
& = & \pi(x) +\sum_{k=2}^{[\log_2 x]} \frac{\overbrace{x^{1/k}/\log x^{1/k}+o(x^{1/k}/\log x^{1/k})}^{\text{by the prime number theorem}}}{k}\\
& = & \pi(x)+\sum_{k=2}^{[\log_2 x]}\frac{x^{1/k}}{k \log x^{1/k}}+ \sum_{k=2}^{[\log_2 x]}\frac{\overbrace{O(x^{1/k}/\log x^{1/k})}^{\text{every }o\text{ is }O}}{k}\\
& = & \pi(x)+\frac{1}{\log x}\sum_{k=2}^{[\log_2 x]} x^{1/k}+O(\sum_{k=2}^{[\log_2 x]}\frac{x^{1/k}/\log x^{1/k}}{k}) \\
&=& \pi(x)+\frac{1}{\log x}O(\sqrt{x}\log x)+O(\frac{1}{\log x}\sum_{k=2}^{[\log_2 x]} x^{1/k})\\
&=&\pi(x) +O(\sqrt{x})+O(\frac{1}{\log x}O(\sqrt{x}\log x))\\
&=& \pi(x) +O(\sqrt{x})=\pi(x) +O(\sqrt{x}\log \log x).
\end{eqnarray*} In the seventh equality we used the following $$\sum_{k=2}^{[\log_2 x]}x^{1/k}\leq \sum_{k=2}^{[\log_2 x]}\sqrt{x}\leq \sqrt{x}\log_2 x=\frac{\sqrt{x}\log x}{\log 2} \text{ for all }x\geq 1.$$","['analytic-number-theory', 'number-theory']"
831482,Proof of $\lim_{n\to\infty}\frac{e^nn!}{n^n\sqrt{n}}=\sqrt{2\pi}$,"I'm looking for a proof of the following limit:
$$\lim_{n\to\infty}\frac{e^nn!}{n^n\sqrt{n}}=\sqrt{2\pi}$$
This follows from Stirling's Formula, but how can it be proven?",['limits']
831509,Why is infinity multiplied by zero considered zero here?,"I watched an online video lecture by some professor and she was solving a convergence problem of the power series $$\sum_{n=1}^\infty n!x^n,$$  i.e., she was finding the values of $x$ for which this power series is convergent. She did the ratio test and winded up with $(n+1)x$ and now she started to compute the limit of this thing as $n$ approaches infinity and that's where my confusion started! She said that : i) If $x \neq 0$, the limit is infinity (I agree with that). ii) If $x = 0$, the limit is $0$ (this is what I don't agree with because if $x = 0$, and $n$ approaches infinity, I should have the indeterminate form of $0\cdot\infty$. So why did she decide to make it zero? P.S. Here is the video I'm talking about and this problem starts approximately after 6 min https://www.youtube.com/watch?v=M8cojIKoxJg I'd love if I can have this confusion sorted out. Thanks!","['power-series', 'sequences-and-series', 'indeterminate-forms', 'proof-explanation', 'limits']"
831520,Which of the following 5 statements are true?,"I am having trouble finding which of the following statements are true: Which of the following statements are true? [a] Pizza does NOT have mushrooms [b] Pizza does have mushrooms AND bacon [c] Pizza does have mushrooms OR bacon [d] Pizza does have mushrooms AND NOT shrimps [e] Pizza does NOT have mushrooms OR NOT bacon I've tried to solve this problem like below. I assigned a letter to each unique statement: P=Pizza does have mushrooms Q=Pizza does have bacon R=Pizza does have shrimps I've translated each statement in terms of P,Q,R like this:
$$a=\neg P$$
$$b=P \wedge Q$$
$$c=P \vee Q$$
$$d=P \wedge \neg R$$
$$e=\neg P \vee \neg Q$$ Because I don't know the value of truth of neither P,Q or R I could just assume ""what if P is true"" and then ""what if Q is true"" and then ""what if R is true"" and all other combinations (which is 2^3 because |{T,F}|=2 and |{P,Q,R}|=3). Just having that table it doesn't (seem to) help me deciding which are really true because in one case or another any of them can be true, depending on our assumption regarding the value of truth for P,Q,R. According to the book's key the answer should be [c] and [e]. I can remark in my table that if I have to compare/count which of [a]->[e] have more T than others then [c] and [e] are the winners. But this is not a formal proof, does it? Please give me a tip or point me into the right direction.
Thx.",['discrete-mathematics']
831554,efficient way to invert a Matrix plus a diagonal one,"Let $\Sigma$ be a $n \times n$ matrix, $V$ a $2 \times 2$ matrix and $I_{2 n}$ the identity matrix on dimension $2n \times 2n$. Both $\Sigma$ and $V$ are covariance matrices, thus real, symmetric and positive definite. I need to calculate $(\Sigma\otimes V+\phi I_{2 n})^{-1}$ where $\phi$ is a positive scalar and $\otimes$ is the Kronecker product. How can I use the property of the Kronecker product to compute the inversion efficiently?","['matrices', 'covariance']"
831612,"Which of the following sets are dense in $C[0,1]$","Which of the following sets are dense in $C[0,1]$ with respect to sup-norm topology? $1$. {$f$$\in$ $C[0,1]$ : $f$ is a polynomial } $2$. {$f$$\in$ $C[0,1]$ :$f(0)$=$0$} $3$. {$f$$\in$ $C[0,1]$ :$f(0)$$\neq$$0$} $4$. {$f$$\in$$C[0,1]$ :$\int_{0}^{1}f(x)dx$$=$5} I am thinking to apply Stone-weierstrass theorem but I don't know how to use it properly. Please help!","['general-topology', 'metric-spaces', 'real-analysis']"
831632,How to prove $k!+(2k)!+\cdots+(nk)!$ has a prime divisor greater than $k!$,"Question: Let $k$ be a positive integer. Show that there exist $n$ such that
  $$I=k!+(2k)!+(3k)!+\cdots+(nk)!$$ has a prime divisor $P$ such that  $P>k!$. My idea: Let us denote by $d_{p}(n)$ the maximal power of p that n is divisible by.
$$I=k![1+(k+1)(k+2)\cdots (2k)+\cdots+(k+1)(k+2)\cdots (nk)]$$
Then I can't prove it. Maybe we can use Zsigmondy's theorem ? It is said can use follow inequality
  $$\left(1+\dfrac{1}{12n}\right)\left(\dfrac{n}{e}\right)^n\cdot\sqrt{2n\pi}<n!<\left(1+\dfrac{1}{4n}\right)\left(\dfrac{n}{e}\right)^n\cdot\sqrt{2n\pi}$$
  By the way: I fell this problem is very interesting.But I can't prove it. This is  In 2014 China mathematics national team training question(Now china Select 6 people for training, is for China to participate in the IMO. This problem  is from the training topic) Maybe @Ivanh and so on  can help me .Thank you.","['contest-math', 'number-theory']"
831654,Application of Riemann Roch,"I have read that thanks to Riemann Roch theorem, if get $\Sigma$ a compact Riemann Surface of genus $g$ there exists a conformal branch covering $\phi: \Sigma \rightarrow S^2$ of degree less than $g+1$. Unfortunately I have found only very abstract references which not clearly implies this fact. does any one can explain this to me? Ideally with a basic reference.","['complex-geometry', 'algebraic-geometry', 'differential-geometry']"
831676,Complex Contour Integration - Complex Analysis: $\int_{0}^{\infty} \frac{dz}{\cosh(z)} = \frac{\pi}{2}$,"I'm just practising for my upcoming exam, and I've come across a question I'm having a bit of difficulty with. I've been asked to show the following;
$$\int_{0}^{\infty} \frac{dz}{\cosh(z)} = \frac{\pi}{2}$$ Which, we're told, needs to be integrated around an appropriate contour, with the hint that this countour should be a rectangle with vertices at $-R$, $R$, $R + \pi i$, $-R + \pi i$, oriented in the positive sense. So, I started by noting that the function $f(z) = \frac{1}{\cosh(z)}$ is even, so we can say that, as $R \rightarrow \infty$, $\int_{-R}^{R} f(z)\cdot dz = PV \int_{-\infty}^{\infty} f(z)\cdot dz = \int_{-\infty}^{\infty} f(z)\cdot dz$ So, now, we can evaluate the contour using Cauchy's Residue Theorem, noting that the only singularity to occur within this contour is $z = \frac{\pi i}{2}$, which has the residue $-i$, so the integral simply becomes;
$$\int_C \frac{dz}{\cosh(z)} = 2 \pi i \times -i = 2 \pi$$ Then, I need to deal with the integrals above the real axis. So, let's do the following;
$$\Gamma_{1} = \int_{0}^{R + \pi i} f(z) \cdot dz$$
$$\Gamma_{2} = \int_{R + \pi i}^{-R + \pi i} f(z) \cdot dz$$
$$\Gamma_{3} = \int_{0}^{-R + \pi i} f(z) \cdot dz$$
Then;
$$\int_{\Gamma_{1} + \Gamma_{2} + \Gamma_{3}}f(z) \cdot dz = \int_{\Gamma_1}f(z) \cdot dz + \int_{\Gamma_2}f(z) \cdot dz + \int_{\Gamma_3}f(z) \cdot dz$$
$$ = \int_{0}^{R + \pi i} f(z) \cdot dz + \int_{R + \pi i}^{-R + \pi i} f(z) \cdot dz - \int_{-R + \pi i}^{0} f(z) \cdot dz$$
$$ = \int_{0}^{R + \pi i} f(z) \cdot dz + \int_{0}^{-R + \pi i} f(z) \cdot dz +\int_{R + \pi i}^{0} f(z) \cdot dz - \int_{0}^{-R + \pi i} f(z) \cdot dz$$
$$ = \int_{0}^{R + \pi i} f(z) \cdot dz +\int_{R + \pi i}^{0} f(z) \cdot dz = 0$$ Assuming I've done all of that correctly, I get;
$$Lim(R \rightarrow \infty) \int_{-R}^{R} \frac{dz}{\cosh(z)} = \int_{-\infty}^{\infty} \frac{dz}{\cosh(z)} = 2\pi$$ And, as $f(z)$ is even, we have; $$\int_{0}^{\infty} \frac{dz}{\cosh(z)} = \pi$$ What have I missed?? Unless those three gamma integrads are meant to equate to give $\pi$, I can't see what I've done incorrectly here. I know it's a lot of working to go through, but any help would be fantastic. :)","['integration', 'complex-analysis', 'contour-integration']"
831700,To Solve an ODE,"To Solve: $\displaystyle (1+x^2)\frac{d^2y}{dx^2}+1+\left(\frac{dy}{dx}\right)^2=0$ My Attempt: Take $\displaystyle \frac{dy}{dx}=p$ Now we have: $\displaystyle (1+x^2)\frac{dp}{dx}+1+p^2=0$ $\displaystyle \frac{dp}{1+p^2}=-\frac{dx}{(1+x^2)}$ Integrating, $\displaystyle \tan^{-1}p=-\tan^{-1}x$ So now, can we take this as $\displaystyle p = -x$ ? If I can,we end with: $\displaystyle \frac{dy}{dx}=-x+c_1$ The answer seems different: $\displaystyle y=c_1x+(c_1^2+1)\log(x-c_1)+c_2$ Where am I going wrong?",['ordinary-differential-equations']
831701,How to find the sum $\sum_{n = 1}^{\infty}\left[n\sin\left(1 \over n\right)\right]^{n^{3}} $,"$$\sum_{n = 1}^\infty {\left(n\sin\left(\frac{1}{n}\right)\right)^{n^3} } \,\,\sim \,\,\,\sum_{n = 1}^\infty { \left(n\left(\,\,\frac{1}{n}-\frac{1}{6n^3}+o\left (\frac{1}{n}\right)\,\, \right)\right)^{n^3} } $$ $$\lim_{n \to \infty} a_n = \lim_{n \to \infty} { \left(1-\frac{1}{6n^2}+o\left(\frac{1}{n}\right)\right)^{n^3} } \sim \lim_{n \to \infty} q^n =0\,\,\,\,(0<q<1)$$
Does this series converge?","['calculus', 'limits']"
831708,Infinitesimal deformation of coherent sheaves,"Let $\mathcal F$ a coherent sheaf over an affine subset U, then we can consider it as an R module, if $U=Spec(R)$. Let $R$ an algebra over an algebraically closed field $\mathbb K$ and consider the category of Artin local $\mathbb K$-algebras with residue field $\mathbb K$. An infinitesimal deformation of a R-module M is the data of an $R\otimes A$-module $M_A$, which is flat on $A$, together with an ismorphism $\varphi:M_A\otimes_A\mathbb K\rightarrow M$. If 
$$\cdots\rightarrow P^{-n}\rightarrow\cdots P^{-1}\rightarrow P^0\rightarrow M\rightarrow 0$$
is a projective resolution of $M$, is a well know fact that the flatness of $M$ allows us to lift the projective resolution to an exact complex of $R\otimes_{\mathbb K}A$-modules flats on $A$: $$\cdots\rightarrow P^{-n}\otimes_{\mathbb K} A\rightarrow\cdots P^{-1}\otimes_{\mathbb K} A\rightarrow P^0\otimes_{\mathbb K} A\rightarrow M_A\rightarrow 0.$$ I would like to show the following statement:
If $M_A$ and $M_A'$ are isomorphic deformations of $M$,then the isomorphism between them lifts to an isomorphism betwen the deformed complex $(P^*\otimes_{\mathbb K} A, d_A)$ and $(P^*\otimes_{\mathbb K} A, d'_A)$, which a priori are two differnt deformation of the projective resolution of $M$.","['algebraic-geometry', 'deformation-theory']"
831714,Sum of two truncated gaussian,"What is the CDF and the PDF (or approximation) of the sum of two independent truncated gaussian random variable $X \sim TN_x(\mu_x,\sigma_x;a_x,b_x)$ and $Y \sim TN_y(\mu_y,\sigma_y;a_y,b_y)$ ? $TN(\mu,\sigma;a,b)$ denotes the truncated normal distribution, where a and b are the the lower and upper bounds of the truncation, respectively.","['normal-distribution', 'probability-distributions', 'probability']"
831745,How to prove $\sum_{n=0}^\infty \frac1{n!}=e\ $?,How to prove $\displaystyle\sum_{n=0}^\infty \frac1{n!}=e\ $? I thought about it but I could not find a proof. Please give me some hints?,"['sequences-and-series', 'algebra-precalculus']"
831791,Cartesian product of reflexive spaces is reflexive,"Given $(E,\|\|_E),(F,\|\|_F)$ reflexive normed vector spaces.
I have to prove that also $(E\times F,\|\|_{E\times F})$ is reflexive where $\|\|_{E\times F}$ is the product norm. What I know is that $(E\times F)'$ is algebrically and topologically isomorphic to $E'\times F'$.","['normed-spaces', 'functional-analysis']"
831823,Finding determinant of 4*4 Matrix via LU Decomposition?,"What is the shortcut way of finding the determinant of a 4 by 4 matrix (and I assume this applies to any n by n square matrix greater than 2) once you have found an LU or PLU decomposition? Given that det(A)=det(P)det(L)det(U) or det(A)=det(L)det(U) (if no permutation matrix was necessary). Here is a PLU decomposition example: http://www.wolframalpha.com/input/?i=LU+decomposition+of+%7B%7B4%2C3%2C2%2C1%7D%2C%7B1%2C10%2C3%2C4%7D%2C%7B5%2C3%2C2%2C-4%7D%2C%7B4%2C8%2C7%2C9%7D%7D The determinant of that matrix is 602. If I recall, one is supposed to multiply the diagonal entries of the Upper Matrix starting from row 1, column 1 (which gets me -602) and then...    magic? What happens from there?","['matrices', 'calculus']"
831829,Sum of reciprocals of primes for known primes.,I was reading through some old analytic number theory notes earlier and found the interesting fact that even though $\sum\frac{1}{p}$ diverges: $\sum_{\text{known primes}}\frac{1}{p} < 4$. However these notes were written pre-$2003$. I was wondering if this is still the case. If not then how much bigger has this sum got?,"['prime-numbers', 'analytic-number-theory', 'number-theory']"
831917,Frequency of Words in Document,"I'm trying to figure this out: Would someone care to explain how one would go about using this function? More specifically, I don't understand the interval part, how does one count the intervals? Hope this is not to broad...","['summation', 'regular-language', 'functions']"
831922,Find the greatest common divisors,"I am given the following exercise: If $p$ is a prime and $(a,b)=p$,calculate $(a^2,b^2), (a^2,b)$ That's what I have tried: Both $a$ and $b$ contain $p$ and at least one of them contains $p$ with exponent $1$.
The two canonical forms of $a$ and $b$ have not an other common prime. So,it can be $a=p \cdot p_1^{a_1} \cdot p_2^{a_2} \cdots p_k^{a_k} \text{ and } b=p^{d} \cdot q_1^{d_1} \cdot q_2^{d_2} \cdots q_m^{a_m}$ $a=p^{a_0} \cdot p_1^{a_1} \cdots p_k^{a_k} \text{ and } b=p \cdot q_1^{b_1} \cdots q_m^{b_m}$ where $p_i \neq q_j \forall i,j$ So: $(a^2,b^2)=p^{\min\{2,2d \}}=p^2$ $(a^2,b^2)=p^{\min \{ 2,2a_0\}}=p^2$ $(a^2,b)=\left\{\begin{matrix}
p,d=1\\ 
p^2,d \geq 2
\end{matrix}\right. $ $(a^2,b)=p$ Could you tell me if it is right?",['number-theory']
831936,"Is the property reflexive, symmetric, anti-symmetric, transitive, equivalence relation, partially ordered given the relation below?","I'm working on this and I'm supposed to figure out if the following properties apply to the below relations. Properties are: 1. Reflexive
2. Symmetric
3. Anti-Symmetric
4. Transitive
5. Equivalence Relation
6. Partially Ordered Set Relation: The relation $R$ on the set of all real function $f: \mathbb{N} \to \mathbb{R}^+$ where $f \ R \ g$ if and only if $f(n) = O(g(n))$ The relation $R$ on the set of all real function $f : \mathbb{N} \to \mathbb{R}^+$ where $f \ R \ g$ if and only if $f(n) = \Theta(g(n))$ My work so far: For first relation: a. YES: b. NO: c. NO: d. YES: e. NO: f. NO: For second relation a.YES: b.YES: c.NO: d.YES: e.YES: f.NO: Am I doing this right? Thank you so much for any help.","['relations', 'equivalence-relations', 'discrete-mathematics', 'algorithms']"
831955,Solving $r'(x) = \frac{ p(x)-r(x)s'(x) }{ s(x) }$,"Can we solve $$r'(x) = \frac{ p(x)-r(x)s'(x) }{ s(x) }$$ with unknown $p(x)$, if we are allowed to pick any $s(x)$ that makes the differential equation easiest? Or, if we need to know $p(x)$, and can pick any $s(x)$ that we like (for instance, one that makes solving easiest), how do we solve this? In both cases, we are solving for $r'(x)$.",['ordinary-differential-equations']
832000,Is there an established notion for the square root of a set?,"I'm looking for reading I could do around the concept of square rooting a set. I'm defining$\sqrt{A}$ to be the largest $B$ (by $\subseteq$), s.t. $B^2 \subseteq A$. So $\sqrt{A\times B} = A \cap B$. I'd like to know whether it has an established name, alternate descriptions, documented inequalities, etc., also can it be written as a fixed point of some set transformation function? Thanks in advance :)",['elementary-set-theory']
832016,Number of digits of the number of digits of the number of digits of $2014^{2014}$,"How would you solve that problem : What is the number of digits of the number of digits of the number of digits of $2014^{2014}$ ? (for instance the number of digits of $12345678901234567890$ is $20$, and the numbers of digits of $20$ is $2$, and the numbers of digits of $2$ is $1$, so the number of digits of the number of digits of the number of digits of $12345678901234567890$ is $1$)",['algebra-precalculus']
832021,$f(x) = x^3 - x$ then $f(n)$ is multiple of 3 [duplicate],"This question already has answers here : Prove by induction that $3\mid n^3 - n$ (3 answers) Closed 3 years ago . If $f(x) = x^3 - x$ then $f(n)$ is multiple of 3 for all integer $n$ . First I tried $$f(n) = n^3-n=n(n+1)(n-1)\qquad\forall n\ .$$ When $x$ is an integer then  at least one factor on the right is even, and exactly one factor on the right is divisible by $3$ . It follows that for any $n\in{\mathbb Z}$ the right hand side is divisible by $6$ , and so is the left hand side. That is to say: $n^3=n$ mod $6$ for all integers $n$ . Is that correct? or there are another simple solution for this? Thanx.","['elementary-number-theory', 'algebra-precalculus', 'divisibility', 'polynomials']"
832026,Domain of a composite function,"I was given the question: Find the domain of the function $f(x)=\ln(\ln(\ln x))$ I found the answer by inspection: $\qquad D(\ln x)=(0,\infty)$ $\therefore\quad D(\ln(\ln x))=(1,\infty)$ $\therefore\quad D(\ln(\ln(\ln x))=(e,\infty)$ But I wante to find a 'rule' that I could use for any composite function. My internet search left me with the 'rule': $$D(f \circ g)=\{x | x \in D(g) \cap g(x) \in D(f)\}$$ So I tried my hand at this 'rule' on the question and got $D(\ln x)=\{x|x \in (-\infty,\infty) \cap x \in (0,\infty)\}=(0,\infty)$ $D(\ln(\ln x))=\{x|x \in (0,\infty) \cap \ln x \in (0,\infty)\}$ $\qquad\qquad\quad =\{x|x \in (0,\infty) \cap x \in (1,\infty)\}=(1,\infty)$ $D(\ln(\ln(\ln x)))=\{x|x \in (1,\infty) \cap \ln(\ln x) \in (0,\infty)\}$ $\qquad\qquad\qquad \,\ =\{x|x \in (1,\infty) \cap \ln x \in (1,\infty)\}$ $\qquad\qquad\qquad\:\ =\{x|x \in (1,\infty) \cap x \in (e,\infty)\}=(e,\infty)$ Which looks like a rather long-winded way of going about it. Is there anything wrong with my notation? Can you suggest a better method other than inspection?","['notation', 'elementary-set-theory', 'functions', 'function-and-relation-composition']"
832065,Complex integral of $\frac{\cos x}{x^2+4} $,"I want to evaluate: $$ \int_{-\infty}^{\infty}\frac{\cos x}{x^2 +4} dx $$ Using wolfram alpha, it gave an answer of $\frac{\pi}{2e^2}$. Wolfram Alpha is never wrong. Attempt $$ \int_{-\infty}^{\infty}\frac{\cos z}{z^2 +4} dx = \frac{1}{2} \frac{e^{-iz} + e^{iz}}{(z+2i)(z-2i)} $$ Residue at $z=2i$ is $ \frac{\cosh 2}{4i} $ Taking this particular contour: Expanding radius to infinity, by Jordan's Lemma $\int_\gamma \rightarrow 0$ and we are left with: $$ \int_{-\infty}^{\infty} \frac{e^{-ix} + e^{iz}}{(x+2i)(x-2i)} dx = 2\pi i \times \frac{\cosh 2}{4i} $$ $$  \int_{-\infty}^{\infty}\frac{\cos x}{x^2 +4} dx  = \frac{\pi}{4} \cosh (2) $$","['complex-analysis', 'contour-integration']"
832071,$f^2+(1+f')^2\leq 1 \implies f=0$,"Find all $f\in C^1(\mathbb R,\mathbb R)$ such that $f^2+(1+f')^2\leq 1$ It's quite likely the answer is $f=0$. Note that $|f|\leq 1$ and $-2\leq f'\leq 0$. Therefore $f$ is decreasing and bounded. What then ? I tried contradiction, without success.",['real-analysis']
832074,Being g a continuous function show that,"$$
(f_n)_{n\in\mathbb N}, \quad x\in \mathbb R
$$
$$
f_n(x) = \begin{cases} n+n^2 x & \text{if } x\in\left[-\frac 1 n , 0 \right], \\
n - n^2 x & \text{if } x\in\left[0,\frac 1 n \right], \\
0 & \text{if } x\not\in\left[-\frac 1 n , \frac 1 n \right]. \end{cases}
$$
$$
g(y) = \lim_{n\to\infty} \int_{-\infty}^\infty g(x) f_n(y-x) \, dx \quad \forall y\in\mathbb R.
$$ Considering a given sequence, $f_n$ is asked to show it is pointwise convergent.
Then considering a continuous function $g(y)$, with $y \in\mathbb R$, it is asked to show that the equality is always true. Thanks!","['sequences-and-series', 'functions', 'limits']"
832115,Limit of $\sqrt{4x^2 + 3x} - 2x$ as $x \to \infty$,"$$\lim_{x\to\infty} \sqrt{4x^2 + 3x} - 2x$$ I thought I could multiply both numerator and denominator by $\frac{1}{x}$, giving $$\lim_{x\to\infty}\frac{\sqrt{4 + \frac{3}{x}} -2}{\frac{1}{x}}$$ then as x approaches infinity, $\frac{3}{x}$ essentially becomes zero, so we're left with 2-2 in the numerator and $\frac{1}{x}$ in the denominator, which I thought would mean that the limit is zero. That's apparently wrong and I understand (algebraically) how to solve the problem using the conjugate, but I don't understand what's wrong about the method I tried to use.","['radicals', 'calculus', 'limits']"
832181,Solving combinatorical problem using characteristic polynomial,"How many $6$ length strings above $\left\{1,2,3,4\right\}$ are there such that $24$ and $42$ aren't allowed. The suitable recurrence relation for this problem is: $a_{n+2} = 2a_{n-1} + 4a{n-2}$. Hence, the characteristic polynomial is: $x^2 -2x -4 = 0$.It's roots are: $1+\sqrt5,1-\sqrt5$. So, the genral function is: $\alpha (1+\sqrt5)^n + \beta (1-\sqrt5)^n$ 
We know that: $a_0=1$ and $a_1=4$. Hence, $\beta = \frac{1}{2} - \frac{3}{2\sqrt5}$,
$\alpha = \frac{1}{2} + \frac{3}{2\sqrt5}$ All in all, $$(\frac{1}{2} + \frac{3}{2\sqrt5})(1+\sqrt5)^n + (\frac{1}{2} - \frac{3}{2\sqrt5})(1-\sqrt5)^n$$ Now, for $n=6$ the result is $1344$, but the book says $1216$. Who's right?","['recurrence-relations', 'discrete-mathematics', 'combinatorics']"
832186,Will this sequence of polynomials converge to a Hermite polynomial pointwise?,"While trying to solve this question my testing lead to an observation that I found interesting in its own right. Consider the linear transformation $L:P\to P$ from the space of polynomial functions $p\in\Bbb{R}[x]$ to itself defined by setting $L(p)=p+p'$ , and its iterates $$
L^n(p)=\sum_{i=0}^\infty\binom{n}{i}p^{(i)}.
$$ Write $G_{m,n}(x):=L^n(x^m)$ . These polynomials are monic of degree $m$ . If we then make the linear substitution $$
H_{m,n}(x):=\frac1{n^{m/2}}G_{m,n}(\sqrt n x-n)
$$ we get another sequence of monic polynomials of degree $m$ . It seems to me that we have the limit $$
\lim_{n\to\infty}H_{m,n}(x)=He_m(x),
$$ where the polynomial $He_m(x)$ is the so called probabilists' Hermite polynomial . Here the convergence can be thought of as either pointwise or in terms of the coefficients of the polynomials. Can you prove this? Is it known? The evidence that I have supports this very strongly, for we can calculate that $$
\begin{aligned}
H_{1,n}(x)&=x,\\
H_{2,n}(x)&=x^2-1,\\
H_{3,n}(x)&=x^3-3x+\frac2{\sqrt{n}},\\
H_{4,n}(x)&=x^4-6x^2+\frac8{\sqrt{n}}x+3-\frac6n,\\
H_{5,n}(x)&=x^5-10x^3+\frac{20}{\sqrt{n}}x^2+\left(15-\frac{30}n\right)x+\frac{24}{n^{3/2}}-\frac{20}{\sqrt n}.
\end{aligned}
$$ Taking the limit as $n\to\infty$ is trivial here, and the results agree with $He_m(x)$ . Furthermore, the operator $L$ commutes with differentiation, so if we assume that the limit $\tilde{H}_m(x)=\lim_{n\to\infty}H_{m,n}(x)$ exists as a polynomial for all $m$ , then the chain rule gives us as a consequence of $Dx^m=mx^{m-1}$ that $$
\tilde{H}_m'(x)=m\tilde{H}_{m-1}(x).
$$ This is one of properties listed of the probabilist's Hermite polynomials in that Wikipedia-article. If only we could determine the constant term, then this might lead to a proof by induction. A follow-up question is related to the conjecture I made while trying to answer that other question. The answer by George Lowther shows that for any monic polynomial $p$ of degree $m$ the polynomials $L^n(p)$ have $m$ distinct real roots for all large enough integers $n$ . If we number these zeros as $z_{1,n}>z_{2,n}>\cdots>z_{m,n}$ , then will the limits $$
z_i=\lim_{n\to\infty}\frac{z_{i,n}+n}{\sqrt n}
$$ exist, and agree with the zeros of $He_m(x)$ . The evidence that I have for this is not as strong. It does look like the contribution of the leading term of $p$ in $L^n(p)$ will dominate the others for large $n$ . However, I am very rusty at estimating the error terms, and don't have that result about the limits yet either :-(","['orthogonal-polynomials', 'real-analysis', 'polynomials']"
832192,Contour integration of $\frac{(\ln z)^2}{z^2+1} $,"I'm supposed to take the principal branch of $\ln z$ and evaluate this integral: $$ \oint \frac{(\ln z)^2}{z^2+1}  $$ Attempt I suppose the integral they are talking about is something like this: The simple poles are at $z=\pm i$, and since the contour doesn't include any of them the integral is zero. Then this doesn't help part (c) at all..","['complex-analysis', 'contour-integration']"
832199,Uniqueness of solutions to linear recurrence relations,"I understand that if I have a linear homogeneous recurrence relation of the form $q_n = c_1 q_{n-1} + c_2 q_{n-2} + \cdots + c_d q_{n-d}$, I can construct the characteristic polynomial $p(t) = t^d - c_1 t^{d-1} - \cdots - c_{d-1} t - c_d$, and if the roots are $r_1, \ldots, r_d$ (say distinct, for simplicity)
I can be assured that $q_n = k_1 r_1^n + \cdots k_d r_d^n$ is a solution for any choice of coefficients $k_i$.  But are these the only solutions?  Is there a clean way to show this?","['ordinary-differential-equations', 'recurrence-relations']"
832226,The Weibull as the limiting distribution of the Burr distribution,"I often deal with ""payout patterns"" which are vectors of the cumulative percentage of a loss that has been paid over time. For example, for $t \in [0, 1, 2, 3, 4, 5]$ I may have $p_t = (5\%, 15\%, 60\%, 85\%, 98\%, 100\%)$ . As these vectors have to be between $0$ and $1$ , I tend to used smoothed versions obtained by finding the ""closest"" parametric cumulative distribution function, almost always minimizing the sum squared distance between the empirical value and the CDF at each observations (similar to finding the distribution with the minimum Cramer-von Mises criterion). Two of the distributions I often use are the Burr and the Weibull. I use the common North American actuarial parametrization as brought in Klugman, Panjer, and Wilmott (1998). For clarity, in terms of the distribution functions, they are: $$
\begin{align}
\Large F(x)_\textrm{Weibull} &= \LARGE 1 - e^{-\left(\frac{x}{\theta}\right)^\tau}\\
\Large F(x)_\textrm{Burr} &= \Large 1 - \left(\frac{1}{1 + \left(\frac{x}{\theta}\right)^\gamma}\right)^\alpha
\end{align}
$$ What I have seen many times when solving for the minimum distance, is that if the Burr's $\theta$ and $\alpha$ diverge to $\infty$ , the Burr CDF approaches the Weibull and the Burr $\gamma$ is the Weibull $\tau$ . I have sketched out a framework for a proof, but I a do not believe it is rigorous. What I would appreciate is: Corrections, comments, or any constructive criticism on whether or not this relationship can be formally proven, and Whether there is any way to estimate the Weibull $\theta$ from the diverging Burr (which I doubt for reasons brought below). Proof attempt We have the two distributions brought above. The question can be stated as proving: $$
\lim_{\alpha, \theta \rightarrow \infty} \left(\frac{1}{1 + \left(\frac{x}{\theta}\right)^\gamma}\right)^\alpha \to \Large e^{-\left(\frac{x}{\theta}\right)^\tau}
$$ Firstly, re-write the left side as: $$
\lim_{\alpha, \theta \rightarrow \infty}\left({1 + \frac{x^\gamma}{\theta^\gamma}}\right)^{-\alpha}
$$ Now let $\xi = \theta^\gamma$ . We now have $$
\lim_{\alpha, \xi \rightarrow \infty}\left({1 + \frac{x^\gamma}{\xi}}\right)^{-\alpha}
$$ Now here is the weak part. As both $\alpha$ and $\xi$ are approaching $\infty$ , replace both with $n$ . Firstly, I'm not sure that is necessarily mathematically legal, and secondly, this is where question 2 probably fails, since notwithstanding that both $\alpha$ and $\xi (\theta^\gamma)$ diverge, they do so at different rates. That being said, we now have $$
\lim_{n \rightarrow \infty}\left({1 + \frac{x^\gamma}{n}}\right)^{-n}
$$ Taking the log and re-arranging, we get a L'Hopital condition of $$
\lim_{n \rightarrow \infty} \frac{\log\left[1 + \frac{x^\gamma}{n}\right]}{-\frac{1}{n}}
$$ as both numerator and denominator approach 0. Taking the individual derivatives of the numerator and denominator we get $$
\lim_{n \rightarrow \infty} \Large \frac{\left[\frac{1}{1 + \frac{x^\gamma}{n}}\right]\cdot\left({-x}^\gamma\right) n^{-2}}{n^{-2}}
$$ The powers of $n$ cancel leaving us with $$
\lim_{n \rightarrow \infty} \Large \left[\frac{1}{1 + \frac{x^\gamma}{n}}\right]\cdot\left({-x}^\gamma\right)
$$ which converges to $-x^\gamma$ . Since we originally logged the formula, we actually have $$
\lim_{\alpha, \theta \rightarrow \infty} \left(\frac{1}{1 + \left(\frac{x}{\theta}\right)^\gamma}\right)^\alpha \to \Large e^{-x^\gamma}
$$ which is very close to what we actually want. What is missing is the $\theta^\gamma$ in the denominator, realizing that this $\theta$ has nothing to do with that found in the Burr. So, I would appreciate help in making this more rigorous, if possible, understanding any limitations, and any other opportunities to learn. Thank you.","['statistics', 'solution-verification', 'probability-distributions', 'limits']"
832238,About reparametrization of timelike curves in $\mathbb{L}^3$ (Lorentz-Minkowski space),"I think there is something wrong with the proof this text gives of Lemma $2.1.5$ , in pages $19$ and $20$, for timelike curves. I used another function, and it seems to work. Either I'm wrong, or he is. Can someone check, please?
I'm using the convention $$\langle (x_1,y_1,z_1),(x_2,y_2,z_2) \rangle = x_1x_2+y_1y_2 - z_1z_2$$ and, just to remind, $\|(x,y,z)\| = \sqrt{|\langle (x,y,z),(x,y,z)\rangle|}$. My work: We consider $\alpha: I \rightarrow \mathbb{L}^3$ a timelike curve. Fix $t_0 \in I$ and consider the function $$s(t) = \int_{t_0}^t \sqrt{- \langle \alpha ' (\xi), \alpha'(\xi) \rangle} \mathrm{d}\xi$$ Then we have $s'(t) = \sqrt{- \langle \alpha ' (t), \alpha'(t) \rangle} > 0$, then $s$ is strictly increasing, so we have an inverse $h$. Since $h(s(t)) = t$ for all $t \in I$, by differentiation, we have $$\begin{align} h'(s(t)) \cdot s'(t) &= 1 \\ h'(s(t)) &= \frac{1}{\sqrt{- \langle \alpha ' (t), \alpha'(t) \rangle}}\end{align}$$ and so $h'(t) = \dfrac{1}{\sqrt{- \langle \alpha ' (h(t)), \alpha'(h(t)) \rangle}}$. To finish it, I just have to check that the parametrization $\alpha \circ h$ satisfies $\| (\alpha \circ h)'(t) \| = 1$. So: $$\begin{align}\| (\alpha \circ h)'(t) \| &= \| \alpha'(h(t)) \cdot h'(t) \| \\ &= \left\|\alpha'(h(t)) \cdot \frac{1}{\sqrt{- \langle \alpha ' (h(t)), \alpha'(h(t)) \rangle}} \right\| \\[2pt] &=\sqrt{\left|\left\langle \frac{\alpha'(h(t))}{\sqrt{- \langle \alpha ' (h(t)), \alpha'(h(t)) \rangle}}, \frac{\alpha'(h(t))}{\sqrt{- \langle \alpha ' (h(t)), \alpha'(h(t)) \rangle}} \right\rangle\right|} \\[2pt] &= \sqrt{\left| \frac{1}{-\langle \alpha'(h(t)), \alpha'(h(t))\rangle} \cdot \langle \alpha'(h(t)), \alpha'(h(t)) \rangle\right|} \\ &=\sqrt{\left| \frac{1}{-1}\right|} = 1\end{align}$$
$\hspace{15 cm}\square$ Thank you!","['calculus', 'differential-geometry', 'mathematical-physics', 'semi-riemannian-geometry', 'proof-verification']"
832250,Is there notation or a name for the complement of the unbounded face of a planar graph?,"Let $G$ be a finite graph embedded in $\mathbb{C}$.  Let $F$ denote denote its unbounded face.  Is there notation or a name for $F^c$ without referring directly to $F$.  Of course this is equivalent to the union of $G$ with all its bounded faces. More generally, if $G$ is a bounded set in $\mathbb{C}$, and $F$ is the unbounded component of $G^c$, I would like notation for $F^c$ which refers to $G$ and not $F$. If there is no notation already I will probably use ""$\text{fill}(G)$"", because I am ""filling"" $G$.  Any better suggestion?","['notation', 'graph-theory', 'elementary-set-theory']"
832251,Question of analysis,"If we have a function $f$ which is analytic inside (but not on) the unit disc, can $f$ have infinitely many zeroes inside the unit disc? I feel like it would break some holy law if it did, but can't quite prove it. Consider $f(z) = \sum_{n=1}^{\infty}\mu(n)z^n$
Where $\mu$ is the mobius function. I was just wondering if it were possible for $f$ to oscillate signs infinitely often as $z\to 1^-$ along the real line. It seemes very unlikely that a function whose coefficients are all $\pm1$  could act so uncourteously, but nonetheless it is perhaps possible.",['complex-analysis']
832291,Natural connection on tautological bundle over real Grassmannian,"Let me get to the point immediately: Is there a natural connection on the tautological vector bundle over a Grassmannian (of a real vector space equipped with an inner product)? In a paper I'm reading there is a smooth 1-parameter family of $k$-dimensional subspaces $W_t$ of a vector space $V$. From this, we need to get a 1-parameter family of injections $\phi_t : W_0 \to V$ such that the image of $\phi_t$ is $W_t$, and such that $\phi_0$ is the inclusion of $W_0$.
In other words, we need to identify all the $W_t$ with the initial subspace $W_0$. I have no trouble setting up such an identification (in an explicit way using projections and charts on Grassmannians, and small steps of the parameter $t$), but I'm looking for a natural way, mostly because I want to do these things for vector bundles later). I figured one way would be to have a connection on the tautological vector bundle of $k$-planes in $V$ and identify $W_0$ with $W_t$ using parallel transport along the path $\phi_t$. There is an inner product on $V$.",['differential-geometry']
832297,Confused about a linear equation,"So I am working through some notes on Linear Algebra and I cant seem to follow this one part. The question asks to 
Solve: $x+y-z+2w=-20$ $2x-y+z+w=11$ $3x-2y+z-2w+27$ I don't have a problem with putting the equation into matrix form and even reducing it. The way the notes explains it is what I don't understand at all. So first once its in echelon,
$$
\begin{bmatrix} 
1 & 1 & -1 & 2 & -20\\ 
0 & 1 & -1 & 1 & -17\\ 
0 & 0 & 1 & 3 &-2\\ 
\end{bmatrix} 
$$the notes states: ""The solution is therefore $$
X=\begin{pmatrix}
-w-3\\
-4w-19\\
-3w-2\\
2\\
\end{pmatrix}
$$ (This is the first place I am confused? Why are there $4$ rows now? And how did they get these numbers?). Then, we can reduce and have 
$$
\begin{bmatrix}
1&0&0&1&-3\\
0&1&0&4&-19\\
0&0&1&3&-2
\end{bmatrix}
$$ Now for the second confusing part, it then states: ""Note, the solution is $$
X=\begin{pmatrix}
-3\\
-19\\
-2\\
0\\
\end{pmatrix} +w\begin{pmatrix}
-1\\
-4\\
-3\\
1\\
\end{pmatrix}
$$ Note that the rank is $3$ and there is $1$ parameter. Thanks a lot for the help guys. Hopefully I can understand it.","['matrix-equations', 'matrices', 'linear-algebra']"
832348,What is the most efficient method to evaluate this indefinite integral?,"$$\int x^5 e^x\,\mathrm{d}x$$ Is there another, more efficient way to solve this integral that is not integration by parts?","['calculus', 'integration', 'indefinite-integrals']"
832362,"In regards to lagrange multipliers, Confusion about derivation.","In my calculus III textbook, the following sentence is causing trouble for me and preventing me from understanding the theory behind Lagrange multipliers. ""Since the gradient vector for a given function is orthogonal to its level curves at any given point, for a level curve of $f$ to be tangent to the constraint curve $g(x,y) = 0$, the gradients of $f$ and $g$ must be parallel"" There are bits and pieces I understand, but I'm missing the holistic picture that will put my mind at ease. I'm quite certain that I understand that for a given curve $f(x,y)$, its gradient will be tangent to the level surface $f(x,y,z) = k$ because its directional derivative will be $0$. Specifically, I'm hung up on the idea that they must be parallel I cannot directly see how the case where they are anti-parallel isn't possible. Furthermore, I'm not sure why the constraint curve $g(x,y)$ is set to $0$ in this explanation. If someone could explain in detail the ideas behind this sentence, I would appreciate it.","['multivariable-calculus', 'intuition', 'lagrange-multiplier']"
832363,Differentiability of multivariate functions.,"I would appreciate if someone could share some intuition as to the geometric meaning of differentiability condition of functions defined on $\mathbb{R}^n$.
Such a function say $f:\mathbb{R}^n\rightarrow \mathbb{R}$ is differentiable if there is a matrix (vector in this case) $A$ such that 
$$\lim\limits_{\mathbf{h} \to 0} \frac{|f(\mathbf{x}+\mathbf{h})-f(\mathbf{x})-A\cdot \mathbf{h}|}{|\mathbf{h}|}=0.$$ 
$A$ is the vector of partial derivatives of $f$, but the above condition is stronger than the mere existence. I would like to know the geometric nature of what more is required.
Specifically, with respect to the formula for computing directional derivatives,
$$D_{\mathbf{v}} f=A\cdot \mathbf{v}$$
Rudin gives a nice example of a non differentiable function with all directional derivatives exist but the above equation is false. So to be more precise I ask 1) Is the existence of all directional derivatives and the equation
$$D_{\mathbf{v}} f=A\cdot \mathbf{v}$$ equivalent to differentiablity. 2)For which $X$ is ""all directional derivatives exist"" +X, equivalent to differentiablilty. 3) Does the existence of directional derivatives in $n$ independent directions imply all directional derivatives exist.","['multivariable-calculus', 'calculus', 'real-analysis']"
832367,Solving polynomial equations over finite fields,"I have looked (a bit) at questions like finding the number of roots of $x^n =1$ over a finite field. Now I would like to understand how to solve polynomial equations over finite fields. From what I understand the solution to the quadratic equation has the same solution formula. That means that it all comes down to finding square roots. I know that there are formulas for solving higher degree equations, but I am wondering if some of these things look different in some way over a finite field. I am asking for a reference that specifically deals with solving polynomial equations over finite fields. It would be nice if the reference is accessible to an advanced undergraduate student.","['reference-request', 'abstract-algebra', 'polynomials']"
832369,"Global and local coordinates on a manifold, and their relations to curvature","I would be pleased to have some information about coordinates in differential geometry. A) First I would like to check whether or not the definitions I use are correct. (Mainly for the sake of clarity.)
Let us consider a smooth $n$-dimensional manifold $\cal M$. Local coordinates are defined by a diffeomorphism $f$ such that $\begin{array}{ccc}
f \colon & U & \to & f(U) \subset \mathbb{R}^n \\
& p & \mapsto & (x^0, \ldots, x^n) \, ,
\end{array}$ where $U$ is a neighborhood of the point $p$. Global coordinates are given by a chart defined on the whole manifold, hence such that its domain $U$ can be extended to $\cal M$. Are these definitions correct? B) When one is able to define global coordinates on a manifold, does it imply that the manifold is flat? (In my case of interest, I consider a four-dimensional Lorentzian manifold $\cal M$. If global coordinates can be defined, does it imply $\cal M$ is Minkowskian?) If this is indeed the case, how can it be shown? Thanks for your help! Xavier","['coordinate-systems', 'curvature', 'differential-geometry']"
832370,Proving conditional independence,"I have the following problem: Three random variables have the following joint distribution: $$
P(X,Y,Z) = P(X)P(Y|X)P(Z|Y)
$$ Show that $X$ and $Z$ are conditionally independent given $Y$. The solution that I have been given is: $$
P(X)P(Y|X)P(Z|Y) = \frac{P(X)P(Y|X)P(Z|Y)}{P(Y)} = \frac{P(X,Y)}{P(Y)}P(Z|Y) = P(X|Y)P(Z|Y)
$$ But no explanation was given for how each of these steps where reached - is anyone able to elaborate on this?","['statistics', 'conditional-probability']"
832401,proving that continuous function smaller than integral is identically zero,"$f : [0,1] \to \mathbb{R}$ is continuous and $f \geq 0$. There is $C>0$ with $|f(x)| < C \int_{0}^{x} |f(t)| dt$ for all $x \in [0,1]$. (so $f(0)=0$) Is it true that $f = 0$? or is there any counterexamples? Thanks.","['calculus', 'analysis']"
832415,Asymptotic Bounds for the distribution of $f_n(X_n)$.,"Let $\{X_n\}_{n \in \mathbb{N}}$ be a sequence of $\mathbb{R}^{k}$-valued random variables defined on some probability space $(\Omega, \mathcal{F}, \mathbb{P})$ converging almost surely to $X$. Suppose there is a sequence of functions $\{f_n: \mathbb{R}^{k} \rightarrow \mathbb{R}\}_{n \in \mathbb{N}}$ such that for every converging sequence $\{h_n\}$ in $\mathbb{R}^{k}$, with limit $h$, we have: $$-\infty<g_1(h) \leq \liminf_{n \rightarrow \infty} f_n(h_n) < \limsup_{n \rightarrow \infty} f_n(h_n) \leq g_2(h)<\infty$$ for some continuous functions $g_1,g_2: \mathbb{R}^{k} \rightarrow \mathbb{R}$. Question: Is there anything clever that we can say about: $$\liminf_{n \rightarrow \infty} \mathbb{P} \{ \omega \in \Omega \: |\: f_n(X_n(\omega)) \leq c)\} \text{ and } \limsup_{n \rightarrow \infty} \mathbb{P} \{ \omega \in \Omega \: |\: f_n(X_n(\omega)) \leq c)\}, c \in \mathbb{R}$$ What I have in mind is that for a fixed $\omega$, there is $N({\omega},\epsilon)$ such that for $n>N(\omega,\epsilon)$: $$ f_n(X_n(\omega)) \leq c \implies \liminf_{n \rightarrow \infty} f_n(X_n(\omega)) < c + \epsilon \implies g_1(X(\omega)) \leq c+\epsilon.  $$ If $N(\omega,\epsilon)$ were only a function of $\epsilon$, we could say that for all $\epsilon>0$: $$ \limsup_{n \rightarrow \infty} \mathbb{P} \{ \omega \in \Omega \: |\: f_n(X_n(\omega)) \leq c)\}\leq \mathbb{P}\{\omega \in \Omega \: | \: g_1(X(\omega))\leq c+\epsilon\}. $$ However, I don't think one can ignore the dependence on $\omega$. If that is the case, I am not sure about how to bound the asymptotic distribution of $f_n(X_n)$. Let me know if this makes sense. Thanks!","['convergence-divergence', 'statistics', 'measure-theory', 'probability-theory', 'probability']"
832422,Limiting distribution.,"Let $Y_n \sim \chi^2(n) $. Find the limiting distribution, $(Y_n-n)/ \sqrt{2n}$ as $n\rightarrow \infty $, using moment generating functions. I don't know how to properly calculate the moment generating function. Or to calculate the limit. I'll be grateful for the help and advices.","['statistics', 'probability']"
832434,Why is the domain of convergence of a power series a perfect disk?,"I've been going over power series in my Differential Equations class for approximating solutions, and one thing that's been fascinating me is the statement that there is a radius of convergence, around the point for which the series converges. Now, I understand that when a function has an asymptote, like $f(x)=\frac1x$, this is naturally going to ""obstruct"" convergence, and so the series has to stop converging for values too close to the asymptote. But why should this hinder convergence on the other side of the point? Furthermore, this implies that when dealing with a complex power series, the region of convergence is a perfect disk . Why can't we have more irregular regions of convergence? What keeps convergence about the point perfectly symmetric?","['power-series', 'calculus', 'analysis']"
832466,Basic Quantum Mechanics Concepts with Continuous Spectra,"The following are a couple excerpts of the first chapter of Sakurai and Napolitano, Modern Quantum Mechanics , 2nd edition: Prior to these formulas, the text discusses the fundamental mathematics of quantum mechanics with finite dimensional state spaces, in particular spin $\frac{1}{2}$ systems. The left hand sides of the formulas above are associated with cases involving finite dimensional (or at least countable) state spaces and the right hand sides are corresponding equations for continuous spectra. I understand everything on the left hand side. In particular: $|\alpha\rangle$ is a vector in a separable Hilbert space. $\langle \cdot | \cdot \rangle$ is the Hilbert space inner product $\langle \alpha | \beta \rangle \in \mathbb{C}$. But I'm confused by the formulas on the right hand side. What are the types of objects involved? For example, should one still think of $\langle \cdot | \cdot \rangle$ as a Hilbert space inner product yielding a complex number? If so, how can one interpret the right hand side of (1.6.2a) without some high intensity  hand waving? The $\delta(\xi'-\xi'')$ expression suggests one should think of $\langle \xi'|\xi''\rangle$ as some type of linear operator, not an ordinary complex number. I am also tempted to make the integrals on the right hand side disappear by thinking of something (maybe $|\xi'\rangle$?) as an integral operator as studied in functional analysis. Composing or applying integral operators may then yield integral expressions, but the linear operator perspective would be more fundamental and enlightening. Any help from domain experts would be greatly appreciated.","['quantum-mechanics', 'hilbert-spaces', 'functional-analysis']"
832484,Probability Generating Functions with Three Dice,"Three identical dice are thrown. The dice are fair, that is, for all three dice the probability of turning up face $j$ is $1/6$, $1 \le j \le 6$. Let $X_1,\ X_2,\ X_3$ be the independent random variables representing the numbers on dice $1$, $2$, and $3$ respectively. Find the probability generating function (pgf) of $X_1$. Let $G_Y(z)$ be the pgf of $Y = X_1 + X_2 + X_3$. Show that
  $$
G_Y(z) = \dfrac{z^3 (1 - z^6)^3}{216} \sum_{k = 0}^{\infty} \binom{k + 2}{2} z^k.
$$
  You need to specify every rule you have used. Hence find $P(Y = 9)$. I got the first two parts. I am having issues with the third part. My thought is to sum the coefficients of $z^9$? Is this the correct approach? If not, could you please demonstrate the correct approach please? PS: Please show how to do part $3$ from part $2$ instead of computing the probability directly.","['random-variables', 'probability-theory', 'generating-functions', 'probability-distributions', 'probability']"
832490,Quotient group of $\mathbb{Z} \times \mathbb{Z}$,"I'm working on some practice problems and would like to get a few solutions checked (more coming!). Let $H$ be the subgroup of $\mathbb{Z} \times \mathbb{Z}$ generated by the elements $(2, 2)$ and $(3, 4)$. First give a minimal set of elements which generate $(\mathbb{Z} \times \mathbb{Z}) ~ / ~ H$ (as their images by the natural homomorphism $g \mapsto g + H$) and list all the elements in this quotient group, and then describe this quotient group. First we simplify the presentation of $H$ a bit by simplifying the generators: if $H$ is generated by $(2, 2)$ and $(3, 4)$, then it is generated by $(2, 2)$ and $(3, 4) - (2, 2) = (1, 2)$, and so it is generated by $(2, 2) - (1, 2) = (1, 0)$ and $(1, 2)$, and so it is generated by $(1, 0)$ and $(1, 2) - 2 (1, 0) = (0, 2)$ (this could be formalized into a theorem since it's essentially the Euclidean algorithm). So geometrically $H$ spans the set of lattice points of the form $(m, 2n)$ where $m$ and $n$ are integers. Hence it partitions $(\mathbb{Z} \times \mathbb{Z})$ into exactly two cosets $H$ and $(0, 1) + H$. Since $(0, 2) + H = H$, the quotient group is generated by a single element $(0, 1) + H$, and contains two elements $H$ and $(0, 1) + H$. As such, it is isomorphic to $C_2$. Is this a (correct and) rigorous answer and are there things that could be improved? One thing I am a bit concerned about is that the problem asks me to find a set of generators for the quotient group before asking for its elements and its description, whereas I've done the opposite - was there a better approach to finding its generators?","['group-theory', 'solution-verification']"
832530,Are there high performance computing applications for symbolic integration?,"Currently there are a number of applications for numerical integration in applied mathematics and physics. Many of these are integral transforms (often Fourier or Laplace), or solving definite integrals with no closed form solution such as running the numbers on the Dirac equation for molecular modelling or doing lattice quantum chromodynamics to predict things like the mass of the proton. Years ago I thought it might be interesting to try to implement the Risch algorithm as a library function for similar HPC applications, but it's my understanding that symbolic integration of indefinite integrals isn't of much use in these areas because most integrals don't have closed form solutions. Apparently there are heuristics for finding definite integrals for expressions that don't have closed form antiderivatives that often exploit special functions to make the numerical integration easier. I'm curious if there's any high performance computing need to do symbolic integration or if it could help improve the performance of the applications where we currently do fairly dumb brute force numerical integration. Do we only need symbolic integration for doing the set up for packages that run numerical methods? Are there applications for symbolic integration where you want to run the Risch algorithm (and other symbolic integration methods) over millions of expressions, or is the utility of symbolic integration in computer algebra systems only as a research tool that doesn't require large amounts of computational power the way numerical integration does? Are there any applications for high performance computing symbolic integration packages? If so, what are some examples?","['integration', 'symbolic-computation', 'soft-question', 'numerical-methods', 'computer-algebra-systems']"
832551,Number of ways to partition a set into three subsets with given sum.,"Given a set S, with n elements out of which if any element is repeating then it is repeated at maximum 2 times. How to count the number of ways in which S can be partitioned into 3 subsets such that the sum of elements in each subset is required to be A, B, C respectively which are given. Can there be a polynomial time algorithm for it ?",['discrete-mathematics']
832564,Nullstellensatz non-valid for non-algebraically closed fields,"I want an example (with details, please) showing that Nullstellensatz may be false over non-algebraically closed fields. Thanks in advance!","['commutative-algebra', 'algebraic-geometry']"
832597,Interesting line integral using green's theorem,"Find $$\int_C \frac{2x^3+2xy^2-2y}{ x^2+y^2} \, dx+\frac{2y^3+2x^2y+2x}{ x^2+y^2} \, dy$$ Where $C$ is any simple closed loop which contains the origin. What I figured out I cannot use the direct version of Green's theorem. I know that there is another version of greens theorem which is as follows : $$\oint_{C+S} P \,dx + Q\,dy  = \iint_D \left(\frac{\partial Q}{\partial x}-\frac{\partial P}{\partial y} \right)dA,$$
where $C$ and $S$ are oriented opposite to each other and $D$ is the region enclosed between the two loops. Using that I found
\begin{align*}
\int_{C+S} \left( 2x-\frac{2y}{ x^2+y^2}\right) \, dx+\left(2y+\frac{2x}{ x^2+y^2} \right) \, dy
&= \iint_D \left[\left(2+\frac{4xy}{(x^2+y^2)^2} \right)-\left(2-\frac{4xy}{(x^2+y^2)^2} \right) \right]dA \\
&=\iint_D \frac{8xy}{(x^2+y^2)^2} dA
\end{align*} The region inside any closed loop can be defined in polar coordinates as $$\{(r, \theta)\in D \mid 0\leq r\leq r(\theta), \, 0\leq \theta \leq 2\pi \}$$ In polar coordinates the integral becomes $$ =\iint_D \frac{8xy}{(x^2+y^2)^2} dA = \int_0^{2\pi}\!\!\int_0^{r(\theta)} \frac{4\sin2\theta}{r} dr\,d\theta $$ Oops, I am again stuck; it's not zero.","['multivariable-calculus', 'calculus', 'integration']"
832618,"The elementary methods to compute $\int_0^\pi\frac{e^{ix}}{x-\alpha e^{ix}}\,dx\quad;\quad\text{for}\, \alpha>0$","How to compute the following integral using elementary methods (high school methods). \begin{equation}\int_0^\pi\frac{e^{ix}}{x-\alpha e^{ix}}\,dx\qquad;\qquad\text{for}\, \alpha>0\end{equation} Honestly, I don't know how to compute this integral. I have posted this problem in other forum and I only got a link direction to another problem but it didn't help me so that's why I post the problem here. So far I could manage to get
\begin{equation}
\frac{e^{ix}}{x-\alpha e^{ix}}=\frac{x\cos x-\alpha}{x^2-2\alpha x\cos x+\alpha^2}+i\frac{x\sin x}{x^2-2\alpha x\cos x+\alpha^2}
\end{equation}
or
\begin{equation}
\frac{e^{ix}}{x-\alpha e^{ix}}=\frac{1}{\alpha(\beta xe^{-ix}-1)}\qquad;\qquad\text{where}\, \beta=\frac{1}{\alpha}
\end{equation}
but none of them is easy to be computed. These are related questions that might help: [1] and [2] . Any help would be greatly appreciated. Thank you.","['definite-integrals', 'calculus', 'integration', 'real-analysis']"
