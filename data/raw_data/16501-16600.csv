question_id,title,body,tags
134437,Subgroups of finite nonabelian simple groups,"I'm not sure how to go about this question: Let $G$ be a finite nonabelian simple group. Let $H\leq G$. Use the action $(G,G/H)$ to show that $|G:H|\geq 5$. Now very good on group actions, could anyone help?",['group-theory']
134438,"Evaluate or simplify $\int\frac{1}{\ln x}\,dx$","I did a bit of work on this, but I'm not so sure about the parts towards the end. Starting with$$\int\frac{1}{\ln x}\,dx$$$$u=\ln x,1=\frac{dx}{du}\frac{1}{x},dx=x\,du,dx=e^{\ln x}du,dx=e^u\,du$$$$\int\frac{e^u}{u}\,du=\int\frac{1}{u}e^u\,du=\int\frac1u\sum_{n=1}^\infty\frac{u^n}{n!}\,du=\int\sum_{n=1}^\infty\frac{u^{n-1}}{n!}\,du$$$$\sum_{n=1}^\infty\frac{u^n}{n\cdot n!}=\sum_{n=1}^\infty\frac{\ln(x)^n}{n\cdot n!}$$which WolframAlpha tells me converges to $-\ln\left(-\ln x\right)-\Gamma\left(0,-\ln x\right)-\gamma$. I'm not sure what happened in this last step.","['special-functions', 'sequences-and-series', 'calculus', 'integration']"
134442,Finding a fourth vector that makes a set a basis,"The following vectors are linearly independent - $v1 = (1, 2, 0, 2)$ $v2 = (1,1,1,0)$ $v3 = (2,0,1,3)$ Find a fourth vector v4 so that the set { v1, v2, v3, v4 } is a basis fpr $\mathbb{R}^4$? I asked this question before here - Show vectors are linearly independent and finding a basis - and someone suggested a way of doing it. However I am wondering if there is a simpler way. I put the vector $\begin{bmatrix} 0 \\ 0 \\ 0 \\ x \end{bmatrix}$ as the fourth column in a matrix of these vectors, then row reduce. $\begin{bmatrix} 1 & 1 & 2 & 0 & | & 0 \\ 2 & 1 & 0 & 0 & | & 0 \\ 0 & 1 & 1 & 0 & | & 0 \\ 2 & 0 & 3 & x & | & 0 \end{bmatrix}$ By doing this I will be left with the fourth column looking like, for example, $(0, 0, 0, x-2)$. Then as long as x is not equal to 2, there will be pivots in each column and the vectors will be linearly independent? In the matrix above the fourth column ends up as $(0, 0, 0, x)$. So as long as x is not equal to 0 the vectors will be linearly independent? Edit: David Mitra's answer here - Show vectors are linearly independent and finding a basis - is the best way to do this imo.",['linear-algebra']
134459,How to calculate the improper integral $\int_{0}^{\infty} \log\biggl(x+\frac{1}{x}\biggr) \cdot \frac{1}{1+x^{2}} \ dx$,How to Prove: $$\int_{0}^{\infty} \log\biggl(x+\frac{1}{x}\biggr) \cdot \frac{1}{1+x^{2}} \ dx = \pi \: \log{2}$$,"['improper-integrals', 'calculus', 'integration']"
134479,Introduction to Elementary Functions,"I'm looking for an introductory text on algebraic treatment of elementary functions. Really short and easy-going. Video lectures are even better. I want to learn basic ideas (i.e. definitions) behind integration and differentiation of elementary functions. I'm also interested in how computer algebra systems like REDUCE or AXIOM treat them as rational functions with some ""kernels"" (exponents and logarithm's and so on). Though ideally I'd be happy to start with just polynomials and exponents (sin, cos). So to write symbolic integration and differentiation for a simpler class of functions (no logarithms, division and roots).","['differential-algebra', 'functions', 'abstract-algebra', 'reference-request', 'computer-algebra-systems']"
134482,Solving a differential equation involving $y$ and its exponential,Hi all I have a question Ive been asked to solve. But I have no idea where to begin. The equation is $y'=\dfrac{y+e^x}{x+e^y}$. I think this is homogeneous but I have no idea as to how to manipulate this to get it into the required form.,['ordinary-differential-equations']
134499,Why is the dual space of $H_0^1(\Omega)$ denoted $H^{-1}(\Omega)$?,"Why is the dual of the Sobolev space $H_0^1(\Omega)$ denoted $H^{-1}(\Omega)$ ? For a positive integer $k$, $H^k(\Omega)=W^{k,2}(\Omega)$. What is the motivation behind the $-1$ exponent?","['sobolev-spaces', 'functional-analysis']"
134511,The Real line uniqueness ...,"I have a question in the following exercise:
 Let $\langle X, <\rangle$ be a total ordering with no first or last element, connected in the order topology and separable.Show that $\langle X,<\rangle$ is isomorphic to the reals,$\langle R,< \rangle$. We know that every countable totally order set which has no first or last element and which is dense in itself is isomorphic to the rationals. What I want to do is to extend the isomorphism
$f$ between $D$ ,which is the countable dense subset of X, and the rationals. To extend this isomorphism I used the hypothesis  that the space is connected, but I'm not sure if my extended function is well-defined : Let $a \in X$, $D_{&lta}=\{d \in D: d&lta\}$ and $D_{>a}=\{d \in D: d>a\}$, since $R$ is connected   $\exists r_a \in R$ $($$f(D_{&lta}) < r_a < f(D_{>a})$$)$ , so the extended function will be $F(a)=r_a$. The thing is that I'm not sure if I use the ""connected"" hypothesis properly and if $F$ is well-defined. 
Can someone help me?","['general-topology', 'order-theory']"
134521,Splitting field of an irreducible polynomial over $\mathbb{Q}$,"Let $P(x)$ be an irreducible polynomial over $\mathbb{Q}$ ; I am interested its splitting field. I know that $\mathbb{Q}[x]/\langle P(x)\rangle $ have one of the roots of $P(x)$ , and that regardless of what root $\xi$ we take the field $\mathbb{Q}(\xi)$ obtained by adjoining $\xi$ to $\mathbb{Q}$ is isomorphic to $\mathbb{Q}[x]/\langle P(x)\rangle$ I think think that if two field are isomorphic then a polynomial is irreducible over one of them implies it's irreducible over the second (is this true ? is it an iff claim ?) From here I think that adding one root implies we added them all and so we know the splitting field of $P(x)$ . Are some of my claims wrong ? (why ?)","['abstract-algebra', 'field-theory']"
134523,Left and right transversals of groups.,"I have recently been looking at Hall's marriage theorem. One application of it is that given a finite group $G$ and a subgroup $H\leq G$, there is a left transversal of $H$ that is also a right transversal. I can see the theoretical importance of this, but am struggling to find any situations when one would actually use this. If anybody can enlighten me, that would be greatly appreciated.","['finite-groups', 'group-theory']"
134536,Show that the minimum eigenvalue of a Hermitian matrix $A$ is less than or equal to the smallest diagonal element of $A$,"I have a following question: Let $A \in  C^{n\times n}$ be Hermitian and $\lambda_\min$ be the smallest eigenvalue of $A$ , i.e., $\lambda_\min = \min\{\lambda_1, \ldots, \lambda_n\}$ . Show that $\lambda_{\min} \leq \min_j a_{j}$ . Hint: use the properties of the Rayleigh quotient. I got started with the problem, as follows: Rayleigh quotient, for any vector $x$ , is given as, $$r(x) = \frac{\langle Ax,x\rangle}{\langle x,x\rangle}.$$ If $x$ is an eigenvector, $r(x) = \lambda$ . For a Hermitian matrix, $r(x)\in\mathbb R$ , the eigenvalues are real. Now, a Hermitian matrix can be diagonalized as: $A = UDU^*$ , where U is a unitary matrix of eigenvectors, and $D$ is a diagonal matrix of eigenvalues of $A$ . I am missing the final link, that I need to solve my problem. Thanks.","['numerical-linear-algebra', 'linear-algebra']"
134539,Show bounded harmonic function on $\mathbb{C}$ is constant.,"There is another post with this exact same prompt which got several down-votes for not showing  their work.  So I'll show what work I've got.  I know being a harmonic function implies satisfying the Mean Value Property, thus what I thought I'd do is consider two arbitrary points in $\mathbb{C}$ and prove that: $$|u(z) - u(w)|=|\frac{1}{2\pi}\int_0^{2\pi}u(z - re^{i\theta})d\theta - \frac{1}{2\pi}\int_0^{2\pi}u(w - te^{i\theta})d\theta| $$
$$= |\frac{1}{2\pi}\int_0^{2\pi}u(z - re^{i\theta}) - u(w - te^{i\theta})d\theta|$$ Now what I wan't to do is take r and t to infinity and prove this integral goes to zero, but I can't figure out how to do that.  I've used the fact that my harmonic function u is defined on all of $\mathbb{C}$ in taking t and r to infinity but I still need to use the fact that it's bounded. I also read through the proof of Liouville's Theorem, given as an answer in that other post, which seems intuitively correct but rather un-rigorous.  It actually says that the value in the center of a ball is equal to the average over the ball's volume.  I imagine this can be proven from the average over the boundary since the average over the boundary will not change as you continuously shrink the boundary down to its center. This however would require the difference of two surface integrals, or is there a simpler way? I was also considering using the Maximum Modulus Principle somehow but I haven't found a way yet.  I've probably made this way more complicated than it has to be, hopefully someone can help me, thanks! =]. Edit: Ok after thinking some more about the accepted answer in that other post, I've decided what I need to do is look at the canonical holomorphic function whose real part is my harmonic function u, and prove that holomorphic function is bounded.  From there I can prove that since it's entire and bounded that it's constant, and from there prove that then its real part must be constant.  So could someone talk a bit about the construction of this canonical holomorphic function?",['complex-analysis']
134577,Integrate $\int \frac{1}{a + \cos x} dx$,"How do you integrate $$\int \frac{1}{a + \cos x} dx$$ Is it solvable by elementary methods? I was trying to do it while incorrectly solving a homework problem. But, I couldn't find the answer. Thanks!","['trigonometric-integrals', 'calculus', 'integration', 'indefinite-integrals']"
134581,Problem about solving infinity limit with square root,"(I)
$$\lim_{x \to \infty } \, \left(\sqrt{x^2+x}-\sqrt{x^2-x}\right)=$$
$$\lim_{x \to \infty } \, \left(x\sqrt{1+1/x}-x\sqrt{1-1/x}\right)=$$
$$\lim_{x \to \infty } \, \left(x\sqrt{1}-x\sqrt{1}\right)=\lim_{x \to \infty } \, \left(x-x\right)=0$$
(II)
$$\lim_{x \to \infty } \, \left(\sqrt{x^2+x}-\sqrt{x^2-x}\right)=$$
$$\lim_{x \to \infty } \, \left(\left(\sqrt{x^2+x}-\sqrt{x^2-x}\right)*\frac{\left(\sqrt{x^2+x}+\sqrt{x^2-x}\right)}{\left(\sqrt{x^2+x}+\sqrt{x^2-x}\right)}\right)=$$
$$\lim_{x \to \infty } \, \frac{2x}{\left(\sqrt{x^2+x}+\sqrt{x^2-x}\right)}=$$
$$\lim_{x \to \infty } \, \frac{2x}{\left(x\sqrt{1+1/x}+x\sqrt{1-1/x}\right)}=$$
$$\lim_{x \to \infty } \, \frac{2x}{\left(x\sqrt{1}+x\sqrt{1}\right)}=\lim_{x \to \infty } \, \frac{2x}{2x}=1$$ I found these two ways to evaluate this limit. I know the answer is 1. The first one is surely wrong. The question is: why? What is wrong there?",['limits']
134588,question about binomial expansion's coefficients,"I am trying to show that if $$\left( 1+x\right) ^{n}=p_{0}+p_{1}x+p_{2}x^{2}+\ldots $$ and n being a positive integer, then $$p_{0}-p_{2}+p_{4}+\ldots = 2^{\frac {n} {2} }\cos \dfrac {n\pi } {4}$$ and $$p_{1}-p_{3}+p_{5}+\ldots = 2^{\frac {n} {2} }\sin \dfrac {n\pi } {4}$$. Solution Attempt First i thought of using $$ (1 + x)^n = \sum_{r=0}^{n} \binom{n}{r} x^r$$ as in getting the values of the coefficient so $$p_{0}-p_{2}+p_{4}+\ldots = 1-\dfrac {n!} {2!\left( n-2\right) !}+\dfrac {n!} {4!\left( n-4\right) !}-\dfrac {n!} {6!\left( n-6\right) !}$$ I do n't know how to deal with the n! and n related factorial terms in the denominator,The two algebraic manipulations which come to mind both seem fruitless. Any help with a solution or proof strategy would be much appreciated. PS : If i was to assume all the p coefficients are complex numbers and wanted to write them using the cos and sin version is there any mathematical relationship between consecutive p's theta values ? so if $p_{0} =\cos\theta_{0} + i\sin\theta_{0}$ and $p_{1} =\cos\theta_{1} + i\sin\theta_{1}$ is there a relationship between $\theta_{0}$ and $\theta_{1}$ ?","['trigonometry', 'complex-numbers', 'sequences-and-series', 'real-analysis']"
134594,Are groups algebras over an operad?,"I'm trying to understand a little bit about operads. I think I understand that monoids are algebras over the associative operad in sets, but can groups be realised as algebras over some operad? In other words, can we require the existence of inverses in the structure of the operad? Similarly one could ask the same question about (skew-)fields.","['general-topology', 'abstract-algebra', 'universal-algebra', 'operads', 'category-theory']"
134598,Complex analytic $f$ with $f(z)=u(x)+iv(y)$ must be linear?,"Question: Let f be a function such that: $$f(x+iy) = u(x) + iv(y)$$ (that is, such that u does not depend on y and v does not depend on $x$ ). Prove that if f is analytic in C then $f(z) = az + b$ for some a, b elements of C. Solution: As f is analytic it satisfies the Cauchy Riemann equations. $u_x = v_y$ , $u_y = -v_x$ By definition $f'(z) = u_x + iv_x$ but $v_x = 0$ so $f'(z) = u_x$ Now $u_x$ is just some element of C. Call it a. $f'(z) = a$ Integrate both sides with respect to z and we get $f(z) = az + b$ Does this look right? Particularly the part where I let $u_x = a$ ?",['complex-analysis']
134604,Prove $\lim\limits_{n\to\infty}na_n\ln(n)=0$ [duplicate],"This question already has answers here : If $(a_n)\subset[0,\infty)$ is non-increasing and $\sum_{n=1}^\infty a_n<\infty$, then $\lim\limits_{n\to\infty}{n a_n} = 0$ (16 answers) Closed 6 years ago . Let $a_n>0$ , $\sum a_n$ is convergent, $na_n$ is monotone, Prove: $$\lim\limits_{n\to\infty}na_n\ln(n)=0.$$ I try to prove $a_n=o(n\ln(n))$ , but it doesn't work.","['sequences-and-series', 'calculus', 'limits']"
134612,Tiling problem about dominos,"The number of ways to fully-cover a m -by- n rectangle with mn/2 dominoes is: 
$\prod_{j=1}^m \prod_{k=1}^n \left ( 4\cos^2 \frac{\pi j}{m + 1} + 4\cos^2 \frac{\pi k}{n + 1} \right )^{1/4}.$ Is there any more general result of the number of ways to fully-cover any fully-coverable Polyomino by dominoes",['combinatorics']
134616,The Integral of a Harmonic Function,"Show that: $$\frac{1}{2\pi}\int_0^{2\pi}\log|re^{i\theta} - z_0|d\theta = \begin{cases}
\log|z_0| & if & |z_0| < r \\ 
\log|r| & if & |z_0| > r
\end{cases}.$$ I know $\log|z|$ is a harmonic function in the slit plane since it is the real part of the analytic function $\log(z)$ on the slit plane.  What I don't understand is that for $|z_0| > r$ this integral is exactly the average of a harmonic function along the boundary of a disk upon which $\log|z|$ is harmonic, thus by the Mean-Value Property it should be equal to $\log|z_0|$, yet it's supposed to be $\log|r|$.  What is going on?",['complex-analysis']
134623,Intersection of countably infinite sets,"Let S and T be two countably infinite sets. Suppose S is not a subset of T and vice-versa. Is the intersection of S and T a finite set? If not, please provide counterexamples. I originally asked this question because it occurred to me when trying to prove that the union of two countably infinite sets is countable. I recently picked up Ralph Boas' Primer of Real Functions and have been trying to do the exercises. However, in the book, Boas doesn't introduce the notion of countability using injective functions and I have been trying to come up with a proof that doesn't involve injections. I fooled myself with a 'proof' but now I'm just stuck. Any hints to help me along the way? 
I'm very new to real analysis. So please bear with me.
Also, what proportion of exercises should I be able to do if I really understand the material?
I guess what I'm asking is that how do the exercises serve as a barometer for my mathematical skill?",['elementary-set-theory']
134630,The discussion about $\int_a^b P^2(x)f(x)dx=0$,"$f$ is Riemann integrable in $[a,b]$,and $\int_a^b f(x)dx>0$. If the polynomial $P(x)$ satisfies $\int_a^b P^2(x)f(x)dx=0$. Prove $P(x)=0$.",['calculus']
134633,Complex Analysis - Question about branch cuts,"I am having trouble understanding how branch cuts work. For example, the function $f(z)=
\sqrt{z}$ has a branch cut where you reject the negative real axis. But how do you define the output so that the function is 1-1 and onto? For example what is $f(1 + i)$? And $f(1-i)$? Also does the function containing the branch cut have to be analytic?","['branch-cuts', 'complex-analysis']"
134635,How can I lift a path to $\mathrm{Spin}(n)$?,"Suppose I am given an explicit differentiable path $\gamma\colon[a,b]\to SO(n)$, with $\gamma(a)=\gamma(b)=I$.  Then $\gamma$ either does or does not lift to a closed loop in $\mathrm{Spin}(n)$.  How do I tell which is which? For example, let $\gamma\colon[0,2\pi]\to SO(4)$ be the function
$$
\gamma(t) \;=\; \begin{bmatrix}
\cos t \cos 2t & \sin t \cos 2t & 0 & \sin 2t \\[6.5pt]
-\sin t\cos 3t & \cos t \cos 3t & \sin 3t & 0 \\[6.5pt]
\sin t \sin 3t & -\cos t \sin 3t & \cos 3t & 0 \\[6.5pt]
-\cos t \sin 2t & -\sin t \sin 2t & 0 & \cos 2t
\end{bmatrix}
$$
Does this lift to a loop in $\mathrm{Spin}(4)$, or not?  What calculation would I need to do to figure this out? Edit: Following Ryan's suggestion, I made a plot of the eigenvalues of the above matrix in Mathematica .  Only the two eigenvalues with $\mathrm{Im}(\lambda)>0\text{ }$are shown, but the other two are simply the complex conjugates: Note that a $-1$ eigenvalue corresponds to the top edge of the rectangle.  There are four obvious values of $t$ where one of the eigenvalues passes through $-1$ transversely, but it also appears that one of the eigenvalues is tangent to $-1$ at $t=\pi$. To resolve the tangency, I perturbed the path $\gamma(t)$ by a path $\delta(t) \in SO(4)$ that stays close to the identity matrix.  Here are the eignevalues for the product $\delta(t)\gamma(t)$: The tangency has now resolved itself into two transverse intersections, making a total of six transverse intersections.  Since six is even, this path lifts to a loop in $\mathrm{Spin}(4)$.","['lie-groups', 'algebraic-topology', 'differential-geometry']"
134642,How can we define the Inner Product of multi-variable functions?,"How can we define the Inner Product of multi-variable functions? For example, what is the value of the inner product of $\nabla f$ and $\nabla g$? $$\langle \nabla f, \nabla g\rangle = ?? $$ Here $\langle\cdot,\cdot\rangle$ is used for the inner product in $L^2$.",['multivariable-calculus']
134648,Prove that the set of extreme points in $B$ is equal to an atom,"How to prove this? Please help me. Thank you very much. A measurable set $E$ in a measure space $(X, \mathcal{M}, \mu)$ is said to be an atom if $\mu (E) > 0$ and no proper measurable subset of $E$ has positive $\mu$ measure. Let $(X, \mathcal{M}, \mu)$ be a $\sigma$ - finite measure space. Prove that the set of extreme points in $B_{L^1(\mu)}=\{v \in L^1(\mu): \|v\| \le 1\}$ is equal to $\{\pm \mu(F)^{-1} \chi_F: F \mbox{ is an atom of }\mu\}$ .","['measure-theory', 'functional-analysis', 'real-analysis']"
134651,The Nambu bracket,"Does anybody know how to show the Jacobi identity for the Nambu bracket in $\mathbb{R}^3$? The Nambu bracket with respect to $c \in \mathcal{F}(\mathbb{R}^3)$ is defined as $$\{F,G\}_c = \langle\nabla c , \nabla F \times\nabla G\rangle $$ where $F,G \in \mathcal{F}(\mathbb{R}^3).$ I don't know if this will help but, if one shows that the homomorphism $$ F \rightarrow \{F, \bullet\}_c = \langle\nabla \bullet , \nabla c \times \nabla F\rangle,$$ between $\mathcal{F}(\mathbb{R}^3)$ and the divergenceless vector fields $\nabla c \times \nabla F,$ preserve the lie algebra structure then it is done... Thank you very much for the help!","['lie-algebras', 'classical-mechanics', 'differential-geometry']"
134665,Does a branch of a square root determine a branch of a logarithm?,"Suppose I have a branch of the logarithm, that is, a continuous function $L(z)$ on some region $\Omega$ such that $e^{L(z)} = z$. We see that this defines a branch for the square root function on $\Omega$, via $\sqrt{z} = \exp(1/2 L(z))$, since $$(\exp(1/2 L(z))^2 = \exp(L(z)) = z$$ I am wondering if a sort of converse of this holds. Suppose on the other hand, we have a branch for the square root, i.e. some continuous function $R(z)$ on $\Omega$ such that $R(z)^2 = z$. Is there some way to get a branch of the logarithm from $R(z)$? If so, does this generalize (i.e. what branches for multi-valued functions will determine a branch of the logarithm)?",['complex-analysis']
134668,Must a complete space be locally compact?,"There are two versions of second category space: one is complete metric space, the other is locally compact space. As we know, an open interval is locally compact but not complete. But how about the opposite? Must a complete space be locally compact? If not, must a complete topological vector space  be second category?","['topological-vector-spaces', 'functional-analysis']"
134676,Integration by Parts with multi-variable functions,"I want to prove that 
$$ - \int\limits_{\mathbb R^n} y_t \Delta y =  \int\limits_{\mathbb R^n} \sum_{j=1}^n \left(\frac{\partial y}{\partial x_j}\right)\left(\frac{\partial y_t}{\partial x_j}\right) $$ 
Here $ \Delta y  =  \sum\limits_{j=1}^n \frac{\partial^2 y}{\partial x_j^2} $, and $y = y(t,x_1, \cdots x_n ) \in  C^\infty ([0,\infty) \times \mathbb R^n )$,  $y_t(t, \cdot) \in L^2$.",['multivariable-calculus']
134681,What's the difference between analytic singularity and algebraic singularity?,"Let $f$ be a holomorphic function defined in $U\in \mathbb{C}^n$, and $f=0$ gives an analytic variety. Suppose $f$ is irreducible as a germ of holomorphic function in $\mathcal{A}_z$, here $z$ is a fixed point in $U$, $\mathcal{A_z}$ denotes ring of germs of holomorphic function defined near $z$. Question: Can we find a reparametrisation of $f(z)$ to be a polynomial? More precisely, can we find a biholomorphic map $g:V\rightarrow B(z_,\epsilon)$ for some open set $V\subset \mathbb{C}^n$ and some $\epsilon>0$ such that $f\circ g:V\rightarrow \mathbb{C}$ is a polynomial function? When $n=1$, we can always find such $g$ since every holomorphic function $f$ of one variable can be written as $f(z)=f(z_0)+a(z-z_0)^m+$Higher Order Terms ($a\neq0$), then we can find a single-value branch $h(z)$ of the multi-value function $(f(z)-f(z_0))^{1/m}$ near $z_0$, and we always have $h'(z_0)=a^{1/m}\neq 0$, hence $f(z)=f(z_0)+h(z)^m$, hence $g=h^{-1}$ gives a reparametrisation of $f$ as $(f\circ g) (w)=f(z_0)+w^m$. Also, when $n\geq 2$ and $df_{z_0}\neq 0$, then $g$ always exists by implicit function theorem. But I don't know whether such $g$ exists when $z_0$ is a singular point of $f=0$. Any comments are welcome. Remark: I found a closed related question here: https://mathoverflow.net/questions/73945/wanted-example-of-a-non-algebraic-singularity","['algebraic-geometry', 'several-complex-variables']"
134693,"sequence of absolutely continuous functions, uniform convergence","Let $\{f_n\}$ be absolutely continuous functions on $[0,1]$, $f_n \geq 0$ $\forall n \in \mathbb{N}$. 
Suppose that $\lim_{n \to \infty} \int^1_0 f_n dx = 0$. 
Moreover, suppose that $\forall$ $\epsilon > 0$ $\exists$ $\delta > 0$ such that $\int_{E} |f_n'(x)|dx$ < $\epsilon$ $\forall n \in \mathbb{N}$,  if $m(E) < \delta$. 
Prove that $f_n$ converges to $0$ uniformly on $[0,1]$. Can someone help show this?
Thanking you in advance.","['measure-theory', 'real-analysis']"
134699,How can I prove that the inequality,"I want to prove that for any $g \in C_0^\infty$, $g\colon[0,\infty) \times \mathbb R \rightarrow \mathbb R$, and $g = g(t,x)$, $$\sup_{x\in \mathbb R} |g(t,x)| \leqslant \int_\mathbb R \hspace{2mm} \left(\left|g(t,x)\right| + \left| \frac{\partial g(t,x)}{\partial x} \right| \right) \hspace{2mm}dx$$ for any $t$.","['multivariable-calculus', 'real-analysis']"
134708,Set operators vs. Logical operators while discussing probability theory.,"Let $S = \{1, 2, \dots, 10\}$  Let $A$ be the event that a number selected from $S$ is even. Let $B$ be the event that a number selected from $S$ is a multiple of $3$. If any number is equally likely to be selected from $S$, the probability that a number selected from the set $S$ is neither even nor a multiple of $3$ is $\frac{3}{10}$. I write it as $P(\overline A \cap \overline B) = \frac{3}{10}$. But I have some people writing it as $P(\neg A \text{ and } \neg B) = \frac{3}{10}$. I don't understand the reason for this notation. They seem to be using logical operators which apply to statements in propositional logic. But $A$ and $B$ are not statements. They are events, and events are sets. Shouldn't we stick strictly to set theory notation while discussing probability? If we have to use logical operators, shouldn't we use $P(\neg A \land \neg B)$ instead of $P(\neg A \text{ and } \neg B)$?","['notation', 'probability']"
134747,Sum of cubes of binomial coefficients,"I reduced a homework problem in combinatorics to giving an asymptotic estimate for
$\sum_{k=0}^n{n \choose k}^3$. I assume Stirling's approximation can help, but I'm not experienced with making estimates and need some help.","['asymptotics', 'binomial-coefficients', 'combinatorics']"
134786,Complex logarithm problem,"Show that
$$Log((1+i)^2) = 2Log(1+i),$$
while
$$Log((-1+i)^2) \not= 2Log(-1+i)$$ Solution: I am using $[0 , 2\pi]$ for the principle argument. The first part worked out fine, I got: $Log((1+i)^2) = log(2) + i \frac{\pi}{2}$ $2Log(1+i)= log(2) + i \frac{\pi}{2}$ But the second part is not working out because I found that the results are equal: $Log((-1+i)^2) = log(2) + i \frac{3\pi}{2}$ $2Log((-1+i) = log(2) + i \frac{3\pi}{2}$",['complex-analysis']
134796,Conjugation of Matrices and Conjugation of Complex Numbers,"Are conjugation of matrices and conjugation of complex numbers related? What I mean is that if $A$ is an $n \times n$ matrix then the conjugation of $A$ by an invertible $n \times n$ matrix $C$ is given by $CAC^{-1}$. On the other hand, if $a + bi$ is a complex number then it's conjugate is $a-bi$. These two operations don't really seem to have anything to do with one another but if they're unrelated why is the same term used to describe the operation?",['linear-algebra']
134798,invariant lines avoiding fixed subvarieties,"Could anybody help me with the following question ? Assume we are given: (1) a finite order (linear) automorphism $g$ of the projective space $\mathbb{P}^r$, (2) a closed algebraic subvariety $Z \subset \mathbb{P}^r$ of codimension at least 2. Is it always possible to find a line in $\mathbb{P}^r$ which is stable under $g$ and does not meet $Z$? Thanks in advance!","['projective-space', 'algebraic-geometry']"
134804,Elegant Trigonometric Sums,"While studying characters of a finite field and the Polya-Vinogradov inequality, I've found some nice identities (verified by simulations) that I'm not sure how to prove. They seem to be related to Chebyshev's polynomials of the second kind. The identities are: $$ \sum_{a=1}^{q-1} \left( \frac{\sin (\frac{\pi N a}{q})}{\sin (\frac{\pi a}{q})}\right)^2 = N(q-N) \tag{1}$$ $$ \sum_{a=1}^{q-1} (-1)^a \frac{\sin (\frac{\pi N a}{q})}{\sin (\frac{\pi a}{q})} = -N \cdot 1_{N+q \equiv 1 \mod 2}\tag{2}$$ Another function that interests me is the following: $$ f(N,q,c) = \sum_{a=1}^{q-1} (-1)^{a+ac} \frac{\sin (\frac{\pi N a}{q})}{\sin (\frac{\pi a}{q})} \frac{\sin (\frac{\pi N ac}{q})}{\sin (\frac{\pi ac}{q})}\tag{3}$$
For $c=\pm 1$ it coincides with $1$. How does it behave in general? $N,q$ and $C$ are positive integers satisfying $N&ltq$.",['trigonometry']
134819,Prove: $f(t)\leq t+1$,"Let $f(x)$ be a strictly positive continuous function in $[0,1]$ such that $f^2(t) \leq 1 + 2\int_0^t f(s)\, \mathrm{d}s$. Prove that $f(t)\leq t+1$. Obviously, if $f(x)$ can be differentiated, it is true. But I can't deal with the case that it is not differentiated.",['calculus']
134870,How was Euler able to create an infinite product for sinc by using its roots?,"In the Wikipedia page for the Basel problem , it says that Euler, in his proof, found that $$\begin{align*}
\frac{\sin(x)}{x} &=
\left(1 - \frac{x}{\pi}\right)\left(1 + \frac{x}{\pi}\right)\left(1 - \frac{x}{2\pi}\right)\left(1 + \frac{x}{2\pi}\right)\left(1 - \frac{x}{3\pi}\right)\left(1 + \frac{x}{3\pi}\right) \cdots
\end{align*}$$ because the roots are at $\pm\pi, \pm2\pi, \pm3\pi, \cdots$ and finite polynomials are in this form (i.e. $(x-\text{root}_1)(x-\text{root}_2)\cdots$). How was he able to do this?  Why does this not simply make a polynomial function that has the roots same roots of $(\sin x)/x$?  Can this method be used to make other trigonometric functions?","['sequences-and-series', 'products', 'roots', 'polynomials', 'trigonometry']"
134872,Does such a subset has a nonempty interior?,"Let $(a_n)_{n=1}^\infty$ be a sequence such that $0\leq a_n \leq 1$, $\sum_{n=1}^\infty a_n=1$ and let $card \{a_n: n \in \mathbb{N} \}=\infty$.  Let's consider the set $$S=\{ \sum_{n\in I} a_n: I \subset \mathbb{N} \}.$$ 
It may happens that $S=[0,1]$ for example for $(\frac{1}{2},\frac{1}{2^2},\frac{1}{2^3}...)$, or $(\frac{1}{3}, \frac{1}{3}, \frac{1}{3^2}, \frac{1}{3^2},...)$.
Under what condition $S$ contain an interval?
Is it then $S=[0,1]$?","['metric-spaces', 'analysis']"
134883,Prove that the fields $\mathbb Z_{11}[x]/\langle x^2+1\rangle$ and $\mathbb Z_{11}[x]/\langle x^2+x+4 \rangle$ are isomorphic,"I have been stuck in this problem for some time now. Prove that $x^2+2$ and $x^2+x+4$ are irreducible over $\mathbb{Z}_{11}$. Also, prove further $\mathbb Z_{11}[x]/\langle x^2+1\rangle$
  and $\mathbb Z_{11}[x]/\langle x^2+x+4\rangle$ are isomorphic, each
  having $121$ elements. The first part is easy to prove since there is no element of $\mathbb Z_{11}$ that satisfies either of the polynomials given in the question. However, proving that  $\mathbb Z_{11}[x]/\langle x^2+1\rangle$ and $\mathbb Z_{11}[x]/\langle x^2+x+4\rangle$ are isomorphic has been a challenge for me. How do I proceed? Moreover, how do I show that the the fields $\mathbb {Z}_{11}[x]/\langle x^2+1\rangle$ and $\mathbb {Z}_{11}[x]/\langle x^2+x+4\rangle$ each have $121$ elements?","['finite-fields', 'abstract-algebra', 'field-theory']"
134884,Eigenvalues of product of two hermitian matrices,"I know that if $A$ and $B$ are hermitian matrices, then it doesn't follow that the eigenvalues of $AB$ are real, because of the following counter-example: $A=\begin{bmatrix}
0 &1 \\ 
 1& 0
\end{bmatrix}$ and $B=\begin{bmatrix}
1 & 0\\ 
 0& -1
\end{bmatrix}$ On the other hand, I came across the following problem, which says that if $A$ is hermitian and positive definite, and $B$ is hermitian, then $AB$ has real eigenvalues. Why if we add the property ""positive definite"" to $A$, the eigenvalues of $AB$ become real? The proof I read in the book says: Let $\lambda $ be an eigenvalue of the hermitian matrix $AB$ with non zero eigenvector $x$. Then: $$\left \langle BABx,x \right \rangle=\left \langle ABx,Bx \right \rangle=\left \langle \lambda x,Bx \right \rangle=\lambda \left \langle x,Bx \right \rangle$$ Since $$ \left \langle BABx,x \right \rangle$$ and $$\left \langle x,Bx \right \rangle,$$ then $\lambda$ is real. However, I can't see where in the proof the fact that $A$ is positive definite is used. Can anyone explain, please?","['linear-algebra', 'eigenvalues-eigenvectors']"
134890,Clarification regarding a derivative symbol,"I came across the following expression: $$\frac{\partial^{i_1+\cdots+i_m}P(x_1,\ldots,x_m)}{\partial x_1^{i_1}\cdot\cdot\cdot \partial x_m^{i_m}}$$ for $P(x_1,\ldots,x_m)$ a polynomial in $m$ variables $x_1,\ldots,x_m$, and I must say that I find it rather confusing, as I've never encountered this notation before. So my question is: Given a monomial of the form $x_1^{j_1}\cdots x_m^{j_m}$, what does $\dfrac{\partial^{i_1+\,\cdots\,+i_m} x_1^{j_1} \cdots x_m^{j_m} }{\partial x_1^{i_1}\cdots \partial x_m^{i_m}}$ look like?","['notation', 'derivatives', 'polynomials']"
134906,"Do ""Parabolic Trigonometric Functions"" exist?","The parametric equation $$\begin{align*}
x(t) &= \cos t\\
y(t) &= \sin t
\end{align*}$$ traces the unit circle centered at the origin ($x^2+y^2=1$).   Similarly, $$\begin{align*}
x(t) &= \cosh t\\
y(t) &= \sinh t
\end{align*}$$ draws the right part of a regular hyperbola ($x^2-y^2=1$).  The hyperbolic trigonometric functions are very similar to the standard trigonometric function. Do similar functions exist that trace parabolas (because it is another conic section) when set up as parametric equations like the above functions?  If so, are they also similar to the standard and hyperbolic trigonometric functions?","['trigonometry', 'parametric', 'conic-sections']"
134912,Poisson Distribution,"I've a question here that I may possibly help with: ""Suppose that the number X of errors in an assignment submitted by each student in a certain group is a random variable that has a Poisson Distrubition with parameter Lambda = 4. Suppose also that all the assignments submitted are independent of one another. (a) What is the probability that a given submitted assignment contains no errors? (b) What is the probability that, among 10 assignments submitted, there are at least two that contain no errors? Now, our lecturer gave us the answer which is: Answer: Let Y = Number of assignments among the 10 submitted that contain no errors. Then Y has a binomial distribution with parameters n = 10 and p = P[X=0]. However, I would like to elaborate on this answer. Is this approach correct? Answer for (a): Let k = 0 and Lambda = 4 in our Poisson formula, yielding e^-4 (which I think is the probability that a given assignment contains no errors). for (b): Use the Binomial pmf (in the context mentioned above), with n=10, p=e^-4, 1-p = 1-e^-4 and compute the probabilities for k = 0 and 1 respectively. (i.e. No assignments are free of errors, only one assignment is free of errors) I obtained P(k=0) as 0.831225... and P(k=1) as 0.155085... Adding these two together should yield 0.98631.., now subtract this from one to find the probability of at least two assignments with no errors as 0.01369. Thank you. Just to clarify, this is not homework; it's just important I get the method right.",['statistics']
134917,Difficulties in a proof by mathematical induction (involves evaluating $\sum r3^r$).,Please help. I've been stuck on this for 2 days. Haven't found any easy explaining text. The question is: Prove by mathematical induction that : $$ \sum_{r=1}^n r3^r = \frac{3}{4} \left[ 3^n \left( 2n-1\right)+1 \right] $$ I've done a lot of stuff but can't put them down in tex properly.,"['induction', 'summation', 'sequences-and-series']"
134953,Classification of simple modules for algebra of upper triangular matrices?,"I've been refreshing my linear algebra, and this is a question of curiosity I have. Let $U:=U_n(F)$ be the algebra of upper triangular $n\times n$ matrices over a field $F$. Is there a classification of all simple $U$-modules (up to isomorphism of course)? I've been researching around, but didn't find any relevant results on first look. I'd also be happy for a reference showing such classification if one exists. Thank you.","['abstract-algebra', 'matrices', 'linear-algebra', 'reference-request', 'modules']"
134955,Solving $Ax = B$ when $A$ has a large condition number.,"There's two parts to this problem the first is implementation related the second is theoretical. Part 1: 
I've been given $A$ & $B$ and need to solve for $x$. To do this I've been using an SVD. The problem is when $A$ has a large condition number the SVD loses enough precision that returned matrix becomes useless (filled with nan values). The condition number is quotient of the absolute value of largest and smallest eigenvalues. Part of the reason the condition number is so large is the min value is on the order of $10^{-19}$. I used the Jacobi method to calculate the eigenvalues of $A$. Both the SVD & Jacobi implementations come from Numerical Recipes in C 3rd ed. I've heard that you can threshold the SVD to ignore such small values but can't find reference to it in the NR and LAPACK implementations or on papers on SVD implementation. Am I missing something does this not exist? Part 2:
What other methods are used to solve $Ax = B$? Thanks,
Jon","['linear-algebra', 'reference-request']"
134960,Power series $x f''(x) + f'(x) + xf(x) = 0$,"Find a power series with radius of convergence $R = \infty$ such that $$f(x) = \sum_{n=1}^{\infty} a_{n}x^{n}$$ satisfies $$x f''(x) + f'(x) + xf(x)= 0, \forall \mbox{ } x \in \mathbb R.$$ How should I go about solving this question? I have a gut feeling that it has to do with trig functions because I know that the terms in each power series have to cancel out in the resulting addition to satisfy the equation.","['power-series', 'ordinary-differential-equations', 'special-functions', 'real-analysis']"
134964,Morphism between projective schemes induced by surjection of graded rings,"Ravi Vakil 9.2.B is ""Suppose that $S \rightarrow R$ is a surjection of graded rings. Show that the induced morphism $\text{Proj }R \rightarrow  \text{Proj }S$ is a closed embedding."" I don't even see how to prove that the morphism is affine. The only ways I can think of to do this are to either classify the affine subspaces of Proj S, or to prove that when closed morphisms are glued, one gets a closed morphism. Are either of those possible, and how can this problem be done?",['algebraic-geometry']
134991,How can I find the infinite sum of this non-conventional geometric series?,"There's something about a geometric series that makes it easily verifiable. Series like $\sum\frac{10^n}{9^n}$ or $\sum\frac{1}{2^n}$ aren't too bad; the variables $n$ are simple and easily reachable, and the fractions are not complex. But I'm having trouble with a series that looks somewhat different: $$\sum\frac{2^n}{9^{2n+1}}$$ Its sequence converges, so I know I can apply the learned methods. The first thing I did was extract a constant from the sequence. So I go from the original sequence, which is: $$a_n = \{\frac{2}{729}, \frac{4}{59049}, \frac{8}{478296}, \frac{16}{387420489}\}$$ to $$a_n = \frac{2}{9}(\frac{1}{81}, \frac{2}{6561}, \frac{4}{531441}, \frac{8}{43046721})$$ I figured out the new sequence as: $\frac{2^n}{9^{2n}}$, and after the simplifying the constants, I was able to recreate the series in an almost geometric form of $ar^{n-1}$, with $\frac{1}{9}$ as $a$ and $\frac{2^n}{9^{2n}}$ as kind of my $r$. Right now, I have this: $$\sum\frac{1}{9}(\frac{2^n}{9^{2n}})$$ This is sort of my dilemma. Having the $2n$ in the denominator is a serious issue; it prevents me from creating an $ar^{n-1}$ formula, and I need an $ar^{n-1}$ formula if I want to test the convergence of this series, at least with the methods I've learned so far. So I'm quite stuck. Did something go wrong in my calculations? How can I turn this into the proper formula so I can test the series' convergence? Any help is appreciated. Much Thanks, -Zolani","['sequences-and-series', 'calculus']"
135008,A book for self-study of matrix decompositions,"I am a third year math student and I noticed that there are many uses for decomposing a matrix (I mean decompositions like SVD, LU etc'). Is there a good book for self-study of the subject ? Note that I don't want to read about different decompositions but rather understand the proof for their existence and if there is an explanation for ""where the decomposition came from"" it will be fantastic. Any suggestions ?","['matrices', 'numerical-linear-algebra', 'reference-request', 'soft-question']"
135036,Showing that $\cos n\pi\theta$ is periodic unless $\theta$ is an even integer.,"I am trying to show that $\cos n\pi\theta$ is periodic unless $\theta$ is an even integer. I wish to provide a proof based on an example of the $\sin n\pi\theta$ case of the first result, I would appreciate if you could let me know if it is correct or what improvements could be made, I am somewhat doubt full about the last few steps of the irrational case. If $\theta$ is rational then let $\theta = \frac {p} {q}$ and let $n = aq + b$
then $$\phi(n) = \cos n \frac{p}{q} \pi = \cos(ap\pi + \frac{bp}{q} \pi) $$
Since $a\in Z+$ so $$\cos(ap\pi + \frac{bp}{q} \pi)  = (-1)^{ap}\cos(\frac{bp}{q} \pi)$$ Now if p is even as n increases from $0$ to $q-1$ then $\phi(n)$ takes the values 
$$1, \cos\frac{p}{q} \pi, \cos\frac{2p}{q} \pi, \dots, \cos\frac{(q-1)p}{q} \pi$$ These values repeat as n goes from $q$ to $2q -1$ hence $\phi(n)$ is cyclic. Assuming if p is odd as n increases and is odd or even we get $np$ as odd or even determined by n and we observe cyclic values. Let $\theta$ be irrational and without loss of generality be a constant in $0<\theta&lt1$.
Since $|\phi(n)| < 1$ either it periodically or tends to a limit. If $\cos n \theta \pi \rightarrow l$ so $$\cos (n+1) \theta \pi -\cos n\theta \pi = 2 \sin((n+\frac{1}{2})\theta\pi)\sin\frac{\theta\pi}{2} \rightarrow 0$$
Hence $$\sin((n+\frac{1}{2})\theta\pi) \rightarrow 0$$ 
then $$(n+\frac{1}{2})\theta = k_{n} + \frac{1}{2} + \epsilon_{n}$$ where $k_{n} \in Z$ and $\epsilon_{n}\rightarrow 0$. Hence $$\theta = k_{n} - k_{n-1} + \epsilon_{n} - \epsilon_{n-1} =l_{n}+\eta_{n}$$ where $l_{n} \in Z$ and $\eta_{n}\rightarrow 0$.
This is impossible since $\theta$ is a constant and lies between $0 < \theta < 1 $. So we have reached a contradiction. If you could shed some light on the arguments provided in the proof from the entry of $k_{n}$ forwards that would be much appreciated.","['trigonometry', 'proof-writing', 'real-analysis', 'limits']"
135042,Help me prove the identity $\overline{f(0)} = \frac{1}{2\pi}\int_0^{2\pi}\frac{e^{i\phi}}{e^{i \phi}-z}\overline{f(e^{i\phi})}d\phi$,"Let f be an analytic function defined in an open set containing the closed unit disk and let z in ℂ be fixed.  I've simplified a more complicated expression down to this identity, and as implausible as it looks, after some numerical checking it does in fact appear to be true, although if you think you can find a counterexample be my guest: $$\overline{f(0)} = \frac{1}{2\pi}\int_0^{2\pi}\frac{e^{i\phi}}{e^{i \phi}-z}\overline{f(e^{i\phi})}d\phi$$ The functions I tried were: z, z+1, and z+i, so nothing transcendental.  We don't know that $\overline{f(z)}$ is analytic and we can't even push the conjugate inside the function, thus I feel like I don't have many tools at my disposal except for algebraic manipulation, and so far that hasn't gotten me anywhere.",['complex-analysis']
135046,Geometric interpretation of reduction of structure group to $SU(n)$.,"Let $E \to X$ be a complex vector bundle of rank $k$.  Then the structure group of $E$ can be reduced to $U(k)$, as this is equivalent to specifying a hermitian inner product on $E$ which can always be done using a partition of unity (or more high-browly, since $U(k)$ is homotopy equivalent to $GL(k,\mathbb C))$.  My question is if there is a nice geometric structure on $E$ that is equivalent to having a reduction of the structure group to $SU(k)$. Note that I am not talking about the holonomy group but the group that the transition functions take values in.","['algebraic-topology', 'differential-geometry']"
135047,Perspectives on Riemann Surfaces,"So, I have come to a somewhat impasse concerning my class selection for next term, and I have exhausted all the 'biased' sources. So, I was wondering if anyone in this fantastic mathematical community has any input on the matter. Next term I would like to take a course on Riemann surfaces. Initially I had intended to do an independent study with a fantastic teacher and use Otto Forsters book Lectures on Riemann Surfaces . But, recently I have come to learn that there is going to be a graduate course on Riemann surfaces taught as well. This class is taught by an expert in moduli spaces and will use Riemann Surfaces by Way of Complex Analytic Geometry by Dror Varolin (freely available on the author's website: here ). These books differ greatly in style--in the way that they approach the subject. So, of course it's important to decide which course I am going to take, and so it made sense to ask around about these different styles in the books. Here is what I have gathered: Forster's book is much more classical. It does things fairly sheaf-theoretically and involves quite a bit of algebra. Moreover, it seems to focus much more on topological algebraic considerations than anything else. Varolin's book is much, much more analytic and PDEish. Most of the proofs seem to be calculations of sorts. So, the issue is this. I am, at least historically, of a very algebraic persuasion. I eventually think I want to do something in algebraic geometry or algebraic number theory. This automatically makes me want to go more for Forster since I have a fair amount of experience with sheaves and cohomology. Moreover, I also have (only half-seriously) a dislike of very computational analysis [even though I know it's useful]. That said, I have been told by multiple people that Forster's approach to the subject is ""dead""--no one does things like that any more. They tell me that Varolin's approach is much more focused on modern techniques, that it's closer to ""the source"". So, the two things I was hoping someone could clear up for me is 1) Is it true that the analysis/PDE approach is much closer to what is actually important to learn about Riemann surfaces? Is that where the powerful theorems and techniques lie? 2) I am chiefly interested in Riemann surfaces so that I have a good geometric background for algebraic geometry. I do not want to be one of those people that can understand all of the algebra yet is clueless as to what is geometrically going on. Is Forster or Varolin's approach better suited to this goal? Of course, any input about anything even slightly related to this that I did not ask, but you think would be helpful to know will be greatly appreciated. Thanks again everyone! NB: If you're answer is going to be ""you should do both"" (which I would imagine is both likely and correct) please, instead, indicate which you think would be preferable to do first. I know I will do both in tandem regardless, but I shall end up (inevitably) focusing on one approach over the other. EDIT: I would like to make clear that one of the main reasons for this question is to basically figure out if people doing work/studying intensely in algebraic complex geometry or algebraic number theory (the more algebraic geometry side--like arithmetic geometry) feel that there is a reason for me to do the analysis part. Will it provide a prospective on things that will be elucidating, or helpful. EDIT(2): I have decided to also post this on mathoverflow. While I know there is a considerable intersection between the participants here and there, I feel as though this question may be better suited for that website.","['riemann-surfaces', 'complex-analysis', 'learning', 'intuition', 'advice']"
135050,Proving the measure of an increasing sequence of measurable sets is the limit of the measures,"Show that if $A_1\subseteq A_2\subseteq A_3\subseteq\cdots$ is an increasing sequence of measurable sets (so $A_j\subseteq A_{j+1}$ for every positive integer $j$ ), then we have $$m\left(\bigcup_{j=1}^\infty A_j\right)=\lim_{j\to\infty}m(A_j)$$ Here is my proof: According to the $\sigma$ -algebra property, $\bigcup_{j=1}^{\infty}A_j$ is a measurable set, so it makes sense to talk about $m(\bigcup_{j=1}^{\infty}A_j)$ . Firstly, I prove that $\lim_{j\to\infty}m(A_j)\leq m(\bigcup_{j=1}^{\infty}A_j)$ . This is because for any given positive integer $N$ , $A_N\subseteq \bigcup_{j=1}^{\infty}A_i$ , according to monotonicity, we have $m(A_N)\leq m(\bigcup_{j=1}^{\infty}A_i)$ . Take the limit,we will have $\lim_{j\to\infty}m(A_j)\leq m(\bigcup_{j=1}^{\infty}A_j)$ . Secondly, I prove that $m(\bigcup_{j=1}^{\infty}A_j)\leq \lim_{j\to\infty}m(A_j)$ . For any given positive integer $N$ , $\bigcup_{j=1}^N A_j = A_N$ . According to monotonicity,we have $m\left(\bigcup_{j=1}^N A_j\right)=m(A_N)\leq \lim_{j\to\infty}m(A_j)$ . Take the limit, we will have $m\left(\bigcup_{j=1}^\infty A_j\right) \leq \lim_{j\to\infty} m(A_j)$ . Combine the above two arguments, we will see that $$m\left(\bigcup_{j=1}^\infty A_j\right)=\lim_{j\to\infty} m(A_j)$$ $\Box$ The above is my proof, unlike many books, my proof does not use the property of countable additivity. So I doubt my proof is correct. Who can point out where are my mistakes?","['measure-theory', 'real-analysis']"
135052,How does $\cos(\pi ) = -1$?,"I know this is a very elementary question, but how does $\cos(\pi) = -1$? I thought the cosine function required a minimum of 2 numbers, the adjacent side and hypotenuse of a triangle?",['trigonometry']
135056,Radius of convergence of power series or geometric series,"To find radius of convergence of geometric series $$\sum_{n=1}^\infty a_n$$ I need to use ratio/root test to find $|L|&lt1$ To find radius of convergence of power series $$\sum_{n=1}^\infty c_n (x-a)^n$$ I am supposed to find the limit $L$ of just the constant term $c_n$? $$\sum_{n=1}^\infty \frac{(2x-5)^n}{n^2}, \qquad c_n = \frac{2^n}{n^2}, \qquad R = 2^{-1}=1/2$$ How do I know what is a constant? Free of $n$? Or I should focus on getting it into the form $\sum_{n=1}^\infty c_n (x-a)^n$. Thats what I did below $$\sum_{n=1}^\infty \frac{(x-1)^{n-3} + (x-1)^{n-1}}{4^n + 2^{2n-1}}$$ I first factorized what I can $$ = \sum_{n=1}^\infty (x-1)^n \cdot \frac{(x-1)^{-3} + (x-1)^{-1}}{4^n(1 + 2^{-1})}$$ So I guess $$c_n=\frac{(x-1)^{-3} + (x-1)^{-1}}{4^n(1 + 2^{-1})}$$ Then $$L=|\frac{c_{n+1}}{c_n}|$$ But what do I do with the $x$? Correct method is supposed to be knowing its a geometric series of common ratio $\frac{x-1}{4}$. Then radius is |x-1|<4 . But here, don't I need to get the radius of $x$ alone, without the $-1$? Anyways, I think the main thing I am confused about is when to use which method. For geometric series, I am doing the ratio/root test for the whole $a_n$ while in power series, I am ""separating"" the $a_n$ into $c_n (x-a)^n$ form? And doing test on the constant terms ($c_n$)?",['sequences-and-series']
135061,Confusion concerning Burnside's Lemma,"In our undergraduate combinatorics class we covered Burnside's lemma. In our lecture notes it states that: Suppose $G$ is a finite permutation group which acts on $A$, and for each $g\in G$ let $A^g$ denote the subset of $A$ fixed by $g$. The number of orbits, denoted $|A/G|$ is $$|A/G| = \frac{1}{|G|}\sum_{g\in G} |A^g|$$ I'm quite confused with a few points due to the fact that I haven't yet done a course on group theory (group theory is not a prerequisite for this combinatorics paper) so our lecturer said that we don't need to understand the notation above as long as we know how to apply burnside's  lemma using cycle index terms etc. I'd like to know in a concrete setting, what the set $A$ is? (Or you can give me a different/another example). Our lecturer proved burnside's lemma using a double counting argument and to help as understand what the set $A$ he gave us an example of $A$ being the set of all $2$ colorings of a cube with a string on the center of one of the faces where we color only $4$ of the faces (so the face opposite the face with the string doesn't count in the colouring). To illustrate what I mean take this cube http://uva.onlinejudge.org/external/2/253img1.gif and say the string is on face $1$ and face $6$ doesn't have a coloring. So we only color the faces $2,3,4,5$ with either red or blue say. Let $G=\{R_0,R_{90},R_{180},R_{270}\}$ where $R_0$ is the identity. This is where I'm confused. I thought the set $A$ is a set the the elements of $G$ act on. So I thought $A=\{2,3,4,5\}$ in the case of the cube where the numbers in the set $A$ refer to the faces, not the set of all colorings of the cube i.e $A=\{ (R,R,R,R), (R,R,R,B),...,(B,B,B,B)\}$ and hence $A=|16|$. Simply put, what do $A$ and $A^g$ look like in terms of sets for the example above or some other example that you may freely give?","['group-theory', 'combinatorics']"
135064,what's the ordinary derivative of the kronecker delta function?,"What's ordinary derivative of the kronecker delta function? I have used ""ordinary"" in order not to confuse the reader with the covariant derivative. I have tried the following: 
$$\delta[x-n]=\frac{1}{2\pi}\int_{0}^{2\pi}e^{i(x-n)t}dt$$ 
but that doesn't work since. $x,n \in \mathbb{Z}$, while I look for the case $x \in \mathbb{R}$","['calculus', 'real-analysis']"
135065,Projection matrix and Eigenvalue,Would like to have some guidance. $P$ is projection matrix on $U$ and $0\notin v\notin \mathbb{R}^2$ I need to show that if $v$ is element of $U$ than $v$ is Eigenvector of $P$ with Eigenvalue 1. I know that for projection matrix Eigenvalue is $1$ or $0$... but why in this case only $1$?,"['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
135094,Prove that B is a basis for a topology,"Let $X = \{0,1,2,3,\ldots\}$ (the non-negative integers), let $$B_1 = \{\{n\} : n \in X \text{ and }n > 0\}= \{\{1\}, \{2\}, \{3\},\ldots\}$$  $$B_2 = \{Z \subset X : X \setminus Z = \{1,2,\ldots n\} \text{ for some }n \in \mathbb{N} \}$$ a) Prove that $B$ is a basis for a topology on $X$. b) Let $T$ be the topology from part 1. Prove that $(X; T )$ is $T_2$.",['general-topology']
135107,Are projective modules over exterior algebras of vector spaces necessarily free?,"Let $E(V)$ be the exterior algebra of a vector space $V$ (I've also seen this denoted $\Lambda(V)$).Is it true that any projective $E(V)$-module is necessarily free? If it's any easier, is it at least true if we assume $V$ has finite dimension? This popped into my head for some reason while I was experimenting with projective complexes. I couldn't tell either way, but I hope it's not embarrassingly simple. Thanks.","['modules', 'exterior-algebra', 'abstract-algebra']"
135133,Does this $\zeta(s)$ identity have a name?,"I have generalized the product from this thread: Let $s=2n+1$ for $n\ge1$,
$$\zeta (s)=\frac{\zeta (2 s)}{\zeta (2)} \prod _{n=1}^{\infty } \frac{\sum _{i=0}^{s-1}(-p_n){}^i}{(p_{n}-1)p_{n}^{s-2}}$$ This is a $\zeta(s)$ identity for each odd $s$. Does it have a name?  I can only find $\zeta(3)$ in the literature.","['prime-numbers', 'conjectures', 'riemann-zeta', 'number-theory']"
135135,How to prove $|F(x)|\leq\frac{M(b-a)^2}{8}$,"$f(x)$ is derivable in $[a,b]$, $|f^{'}(x)|\leq M$. $\int_a^b f(x)dx=0$. Let $F(x)=\int_a^x f(t)dt$. Try to prove $|F(x)|\leq\frac{M(b-a)^2}{8}$ I want to use Taylor expansion at $f(\xi)=0$, but I can't continue.",['calculus']
135149,Simplify the category of  finite abelian groups,"Consider the category $\mathsf{FinAb}$ of finite abelian groups. The structure theorem tells us that we can write down a skeleton for this category (a set of representatives for the isomorphism classes), which consists of the groups $\mathbb{Z}/n_1 \oplus \cdots \oplus  \mathbb{Z}/n_s$ with positive integers satisfying $n_1 | \cdots | n_s$. But this does not tell us anything about the morphisms between finite abelian groups. Question. Can we improve the structure theorem in such a way that we find an explicit and easy to describe (this also includes the morphisms), countable category $\mathcal{C}$ together with an equivalence of categories $\mathcal{C} \cong \mathsf{FinAb}$? Of course, ""the full subcategory consisting of all $\mathbb{Z}/n_1 \oplus \cdots \oplus  \mathbb{Z}/n_s$"" is no answer. Variants: a) There is an equivalence of categories $\mathsf{FinAb} \cong \mathsf{FinAb}^{op}$, given by $\hom(-,\mathbb{Q}/\mathbb{Z})$. We could require that $\mathcal{C}$ also comes equipped with an explicit anti-equivalence and that $\mathcal{C} \cong \mathsf{FinAb}$ is compatible. b) Actually $\mathsf{FinAb}$ is a symmetric monoidal (abelian) category with the usual tensor product $\otimes_{\mathbb{Z}}$ (without unit). It would be great if we can set up an equivalence of symmetric monoidal categories $\mathcal{C} \cong \mathsf{FinAb}$; in particular $\mathcal{C}$ should be symmetric monoidal. c) Probably everything may be reduced to $\mathsf{FinAb}_p$, the category of finite abelian $p$-groups, where $p$ is a prime number. d) I am also happy with the category of finitely generated abelian groups. This is the initial finitely cocomplete symmetric monoidal abelian category.","['category-theory', 'finite-groups', 'abstract-algebra', 'abelian-groups']"
135180,Integrable monotonic functions,"Suppose that $f \in L^1(0,+\infty)$ is a monotonic function. Prove that $\lim_{x \to +\infty} x f(x)=0$.",['calculus']
135195,Find $\frac{dy}{dx}$ when $y=\frac{x^2-1}{x^4-1}$,"Find $\frac{dy}{dx}$ $$\begin{align*}
y&=\frac{x^2-1}{x^4-1}\\
&=\frac{x^4-1(2x)-x^2-1(4x^3)}{(x^4-1)^2}\\
&=\frac{2x^5-2x-4x^5-4x^3}{(x^4-1)^2}
\end{align*}$$
but the right answer is 
$$\frac{-2x^5+4x^3-2x}{(x^4-1)^2}$$
what did I do right, I used  quotient rule. I want to use below formula, but i don't know how to $$\frac{dy}{dx}=\frac{v\frac{du}{dx}-u\frac{dv}{dx}}{v^2}$$ many thanks in advance!","['calculus', 'derivatives']"
135197,Find an orthogonal basis consisting of eigenvectors,"Find an orthogonal basis for $\mathbb R^3$ consisting of the eigenvectors of the matrix
$$\begin{bmatrix} 1 & 2 & 2 \\ 2 & 1 & 2 \\ 2 & 2 & 1 \end{bmatrix}$$ Isn't this question basically just asking 'find the eigenvectors of this matrix'? And the part about finding 'an orthogonal basis' is irrelevant?","['matrices', 'linear-algebra']"
135208,"Prove that $\mathbb{C}[x,y] \ncong \mathbb{C}[x]\oplus\mathbb{C}[y]$","Prove that $\mathbb{C}[x,y] \ncong \mathbb{C}[x]\oplus\mathbb{C}[y]$ $\mathbb{C}[x,y]$ is the polynomial ring of two variables over $\mathbb{C}$.  I guess that we can consider images of $xy$ and $x+y$, but can't complete my argument. Can you help please?","['commutative-algebra', 'ring-theory', 'abstract-algebra']"
135211,Distribution for random harmonic series,"Consider random variable $X$ formed by the following infinite series: $X = \pm 1 \pm \frac{1}{2} \pm \frac{1}{3} \pm ... \frac{1}{n} ...$, where $+$ or $-$ sign for every summand is chosen independently w.p. $1/2$. What is the distribution of $X$? If it is not some well-known distribution, does it have any interesting properties?","['probability-distributions', 'probability']"
135214,Inner product for vector - valued functions,"I understand that, for example the inner product space $L^2(X)$ of complex - valued functions defined on $X$ has the inner product
\begin{equation}
(f,g) = \int f \, \overline{g\,}.
\end{equation} Now I am reading a text where the elements of my inner product space are vector - valued functions, and it is assumed the reader knows how to adjust the inner product so that it works in this case. I am not sure how to do this, here is a guess and it would be great if I could get feedback on whether this is the right way to generalize to vector - valued functions: \begin{equation}
(f,g) = \sum_{i = 1}^n \int f_i \, \overline{g_i} 
\end{equation} (here, $n$ is the dimension of the range, and $f_i$ is the $i^{th}$ component of the function $f$). Many thanks !","['measure-theory', 'inner-products', 'functional-analysis']"
135218,Set Theory - Subset of set,"I have labelled this
$$
\{\{1\}\}\subseteq\{1,2,\{1,2\}\}
$$ 
as true, it is a subset of the third element, is this true?",['elementary-set-theory']
135231,How to verify the following function is convex or not?,"Consider function
$$f(x)=\frac{x^{n_{1}}}{1-x}+\frac{(1-x)^{n_{2}}}{x},x\in(0,1)$$
where $n_{1}$ and $n_2$ are some fixed positive integers. My question: Is $f(x)$ convex for any fixed $n_1$ and $n_2$? The second derivation of function $f$ is very complex, so I wish there exists other method to verify convex property.","['convex-analysis', 'functions']"
135234,Showing $f(x)=x^4$ is not uniformly continuous,"I am looking at uniform continuity  (for my exam) at the moment and I'm fine with showing that a function is uniformly continuous but I'm having a bit more trouble showing that it is not uniformly continuous, for example: show that $x^4$ is not uniformly continuous on $\mathbb{R}$, so my solution would be something like: Assume that it is uniformly continuous then: $$\forall\epsilon\geq0\exists\delta>0:\forall{x,y}\in\mathbb{R}\ \mbox{if}\ |x-y|<\delta \mbox{then} |x^4-y^4|<\epsilon$$ Take $x=\frac{\delta}{2}+\frac{1}{\delta}$ and $y=\frac{1}{\delta}$ then we have that $|x-y|=|\frac{\delta}{2}+\frac{1}{\delta}-\frac{1}{\delta}|=|\frac{\delta}{2}|<\delta$ however 
$$|f(x)-f(y)|=|\frac{\delta^3}{8}+3\frac{\delta}{4}+\frac{3}{2\delta}|$$ Now if $\delta\leq 1$ then $|f(x)-f(y)|>\frac{3}{4}$ and if $\delta\geq 1$ then $|f(x)-f(y)|>\frac{3}{4}$ so there exists not $\delta$ for $\epsilon < \frac{3}{4}$ and we have a contradiction. So I was wondering if this was ok (I think it's fine) but also if this was the general way to go about showing that some function is not uniformly continuous? Or if there was any other ways of doing this that are not from the definition? Thanks very much for any help","['uniform-continuity', 'real-analysis', 'analysis']"
135235,Find $g'(3)$ if $g(x)$,"if $f(3)=-2$ and $f'(3)=5$, find $g'(3)$ if, $g(x)=3x^2-5f(x)$ the answer is -7,
I find that very hard to understand the question.
thanks","['calculus', 'derivatives']"
135243,"Is the $ L^{p}$$[0,1]$ norm continuous in p?","I ran into the following problem when I was doing my homework, and I have no thoughts on where I should start with: (1) If $f\in L^{2}$, show that $\displaystyle \lim_{p \rightarrow 1^{+}}\int_{[0,1]}|f|^{p}=\int_{[0,1]}|f|$ (2) If $0<p$, show that $\displaystyle \lim_{q\rightarrow p^{-}}||f||_{q}=||f||_{p}$ My first thought was Generalized LDCT, but it didn't seem to work. I also made some other attempts but none of them were successful... Can anybody give me some hints on how I should look at this question? Also, I know if $p\rightarrow\infty$ then $||f||_{p}\rightarrow||f||_{\infty}$ on $[0,1]$, but does similar continuity in p holds for other $L^{p}[0,1]$ norms in general? Thank you! Edit: Sorry if I did not make it clear enough in the question. All $L^{p}$ refers to $L^p[0,1]$. The first question is found here (thanks to t.b.), but the second question remains, mainly because $f$ is not guaranteed to be in any $L^{p}$.","['measure-theory', 'real-analysis', 'limits']"
135257,"$G$ is a finite abelian group, $G$ is cyclic if and only if order of $G$ is equal to exponent of $G$","Let $G$ be a finite abelian group. How do I prove if exponent of $G$ is equal to order of $G$ , $G$ is cyclic?",['group-theory']
135264,Inverse of the natural log function $y =\ln x$,"Of course, it is a well known fact that the inverse of $y=\ln x$ (natural logarithm of x) is $e^x$. Assuming we haven't heard of the exponential function at all, how do we prove that the inverse of $\ln x$ i.e ($\ln^{-1} x$ ) is some other function, which indeed is the so called exponential function $e^x$? Let me be a little more concrete. If $y = \ln x$, then $x= A^y$, how do I prove that $A= e$? There's another method by which I tried to arrive at the inverse of natural logarithm of $x$. By a theorem of differentiation of inverse functions $$\left.\dfrac{df}{dx}\right|_{x=a} \cdot\left.\dfrac{df^{-1}}{dx}\right|_{x=f(a)}=1$$ I got an equation which looked like $$\left.\dfrac{dF(x)}{dx}\right|_{x=\ln k}=k$$  where $k$ is a real number. How do I actually show that $F(x)$ is that same exponential function $e^x$? Is there any way of solving such an equation, or such a problem? Or am I just talking nonsense? I would love to be enlightened by all of you. Thanks in advance. :)","['logarithms', 'calculus', 'algebra-precalculus']"
135267,About $\nabla$'s Property.,"For a scalar function $g$, and a vector function $f$,
$$ | \nabla ( (\nabla g) \cdot f ) | \leqslant |f| \cdot \text{Something} $$
Is this inequality possible? If possible, what would ""$\text{Something}$"" be?",['multivariable-calculus']
135270,Why is $F^*(\mathcal L) = \mathcal L^{\otimes p}$ where $F$ is the absolute Frobenius and $\mathcal L$ is an invertible sheaf?,"Suppose $S$ is such that $\mathcal O_S$ is killed by multiplication by $p$. The absolute Frobenius $F: S \to S$ is defined to be be the identity on the underlying points topological space of $S$, with the sheaf map $F^\#: \mathcal O_S \to \mathcal O_S$ given by $x \mapsto x^p$ for any section. The pullback sheaf is defined to be $$F^*(\mathcal L) = F^{-1} L \otimes_{F^{-1}\mathcal O_S} \mathcal O_S$$ Where $F^{-1} \mathcal L$ is the sheafification of the presheaf defined by $$U \mapsto \lim_{F(V)\supset U}  \mathcal L (V)$$ But since $F$ is the identity on the underlying space, won't we have $F^{-1} \mathcal L = \mathcal L$ and $F^{-1} \mathcal O_S$ = $\mathcal O_S$, and hence $F^* \mathcal L = \mathcal L$? I can't see how to bring $F^\#$ into the calculation. I know the intuitive answer is that the transition functions are sent to their p-th powers. But I can't work out the details.",['algebraic-geometry']
135289,"How to find $h'(x)$, if $h(x) = f(g(x))$.","Let $f'(x) = \sqrt{3x + 4}$ and $g(x)=x^2-1$. Find $h'(x)$, if $h(x) = f(g(x))$. I know that $g'(x) = 2x$, but I don't know how to do further. The answer is $h'(x) = 2x \sqrt{3x^2 + 1}$.","['calculus', 'derivatives']"
135298,Maximal solution of differential or integral equation. Apply it to $\frac{d u}{d x}=\sqrt{u}$,"What is the definition of maximal solution to an integral equation and differential equation. For example, how should I understand the maximal solution of the following differential equation $\frac{d u}{d x}=\sqrt{u}$?","['ordinary-differential-equations', 'integral-equations', 'real-analysis']"
135301,Limit of a sequence of multivariate normal vectors,"I have a question regarding sequences of multivariate normal vectors: Let $ (X_k)_{k \geq 1} $ be a sequence of random vectors of fixed length $ n \geq 1 $ with multivariate normal distribution on a probability space $ (\Omega, \mathcal{F}, P) $ , such that  $ X_k \rightarrow X, \ P-a.s.,$ as $ k \rightarrow + \infty $. Is is true then that $ X $ has again multivariate normal distribution?
And would you happen to know where I can find a proof of this? Thanks a lot for your help & have a nice week!","['probability-theory', 'probability']"
135305,Calculating mean and Gaussian curvature,I am stuck on this question from a tutorial sheet I am going through. Compute the mean and Gaussian curvature of a surface in $\mathbb{R}^3$ that is given by $z=f(x)+g(y)$ for some good functions $f(x)$ and $g(y)$. I tried calculating the first and second fundamental forms to then find $\kappa=\dfrac{det II}{det I}$ but it seems long and I feel like there should be an easier way. Also that doesn't tell me the mean curvature.,['differential-geometry']
135306,Bowl of the spherical cap and its diameter,"Bowl has the shape of spherical cap. Its height is v=15 cm. If you want all the water in the bowl to leak out, you must to tilt the bowl at least 60°. like this: What is the inner diameter of the widest part of the bowl, calculated to the nearest mm?",['geometry']
135311,how to show that a group is elementarily equivalent to the additive group of integers,"Is there any fairly easy way of showing a group is elementarily equivalent to the additive group of the integers? I've found a simple characterization here: A ‘natural’ theory without a prime model , but the proof in Szmielew's paper is quite long and much more general, while I'm looking for something more elementary. Specifically, I'd like to show that the subgroup of rationals generated by fractions of the form 1/p for p prime is equivalent to integers, but a more general, relatively simple solution would be appreciated. edit:
As pointed out in the comments, i mean the additive group of rationals (clearly, since for the multiplicative group the fractions would generate the entire group, and it's certainly not equivalent to integers, whether it's multiplicative or additive), and the subgroup can also be characterized as the group of fractions with squarefree denominators, while elementary equivalence is a concept from model theory (as indicated in tags). szmielew's paper considering equivalence classes of abelian groups can be found here: matwbn.icm.edu.pl/ksiazki/fm/fm41/fm41122.pdf , but it's from the 50's, making it quite hard to read due to outdated language and very apparent lack of modern latex.","['model-theory', 'group-theory', 'abelian-groups']"
135320,Does uniform convergence preserves absolute continuity?,"Here's a question I came up randomly just now: If a sequence of absolutely continuous functions $\{\phi_{n}\}$ converges uniformly to a function $f$, does it imply that $f$ is also absolutely continuous? I am having trouble judging if this is true. If the statement is not true, can anybody help me find a counter-example? Thank you!","['measure-theory', 'convergence-divergence', 'real-analysis']"
135325,Probability that a coin lands on tails an odd number of times when it is tossed $100$ times [duplicate],"This question already has answers here : A coin is tossed $n$ times. What is the probability of getting odd number of heads? [duplicate] (5 answers) Closed 10 months ago . The community reviewed whether to reopen this question 4 months ago and left it closed: Original close reason(s) were not resolved A coin is tossed 100 times , Find the probability that tail occurs odd number of times! I do not know the answer, but I tried this, that there are these $4$ possible outcomes in which tossing of a coin $100$ times can unfold. head occurs odd times head occurs even times tail occurs odd times tail occurs even times Getting a head is equally likely as getting a tail, similarly for odd times and even times.
Thus, all of these events must have same the probability, i.e. $\dfrac{1}{4}$ . Is this the correct answer? Is there an alternate way of solving this problem? Lets hear it! Remark This question was closed for being a duplicate of A coin is tossed $n$ times. What is the probability of getting odd number of heads? . However, the latter was posted in Nov 17, 2017, hence more than 5 years after this one.",['probability']
135341,Find values which make a matrix singular,"Find all the values of c for which the following matrix is singular:
$$\begin{bmatrix} 1 & c & c \\ c & c & c \\ 2 & c & 3 \end{bmatrix}$$ Anyone know how to solve this?","['matrices', 'linear-algebra']"
135343,Find $k$-tuples satisfies $j=n_2+2n_3+\cdots+(k-1)n_k$ if $n_1+\cdots+n_k=n$.,"Let $n_i \in N$, $i=1,\ldots,k$ and such that $n_1+\cdots+n_k=n$.
Fix $j \in N$. I would like to find all $k$-tuples (or algorithm how to find $k$-tuples) satisfies
$$
j=n_2+2n_3+\cdots+(k-1)n_k
$$ Any help would be very appreciated. Thank you.","['number-theory', 'elementary-number-theory', 'numerical-methods', 'prime-numbers', 'combinatorics']"
135344,"How to calculate the area of a circle ( given: origin, radius ) on a sphere ( Earth )?","I know that the Earth isn't a sphere, not even an ellipsoid, but for my measurements, its an acceptable approximation.
Assuming I have a coordinate(lat,lon) and a distance( e.g.: 1000km ), what is the surface area on the earth with that distance radius?","['geometry', 'spherical-geometry']"
135368,How to figure out the log of a number without a calculator?,"I have seen people look at log (several digit number) and rattle off the first couple of digits. I can get the value for small values (aka the popular or easy to know roots), but is there a formula.  Similar to how to tell if a number is divisible by an integer. I have read this and this but could some one explain why it works?","['logarithms', 'algebra-precalculus', 'soft-question']"
135393,"If $K=K^2$ then every automorphism of $\mbox{Aut}_K V$, where $\dim V< \infty$, is the square of some endomorphism.","I have to show the following: Let $K$ be a field such that $\mbox{char } K \neq 2$ and each element of $K$ is a square (i.e. $K^2=K$) and let $V$ be a finite-dimensional vector spaces over $K$. Then, for every automorphism $\tau \in \mbox{Aut}_K V$ there exists an endomorphism $\rho \in \mbox{End}_K V$ such that $\tau = \rho^2$. I have proved (according to the hint given in the problem) that if $\sigma$ is a nilpotent endomorphism, then there exists an endomorphism $\rho$ such that $\rho^2=1_V+\sigma$. So, I guess (although I am not sure) that under our assumptions one could show the automorphism $\tau$ can be represented as $\tau=1_V+\sigma$, where $\sigma$ is nilpotent. I'll be grateful for your help.","['linear-algebra', 'field-theory']"
135401,Convergence to the stable law,"I am reading the book Kolmogorov A.N., Gnedenko B.V. Limit distributions for sums of independent random variables. From the general theory there it is known that if $X_i$ are symmetric i.i.d r.v such that  $P(|X_1|>x)=x^{-\alpha},\, x \geq 1$, then $(X_1+\ldots+X_n)n^{-1/\alpha}\to Y$, where c.f. of $Y$ equals $\varphi_Y(t)=e^{-c|t|^{\alpha}}, \alpha \in (0,2]$, so $Y$ has stable law of distribution. I want to check it without using that general theorems. So I start as the following, $X_1$ has density of distribution $f_X(x)=|x|^{-\alpha-1}\alpha/2, |x|>1$. Using Levy theorem one must prove that $\varphi^n_{X_1}(t/n^{1/\alpha})\to \varphi_Y(t),\, n \to \infty$ for all $t\in \mathbb R$. $$\varphi_{X_1}(t/n^{1/\alpha})=\int_{1}^{\infty}\cos(tx/n^{1/\alpha})\alpha x^{-\alpha-1}\,dx,$$ for all it is evident that $t$ $\varphi_{X_1}(t/n^{1/\alpha})\to 1, n \to \infty$ so we have indeterminate form $1^\infty$. So we are to find $n(\varphi_{X_1}(t/n^{1/\alpha})-1)$, but $\varphi_{X_1}(t/n^{1/\alpha})\sim 1+1/2(2txn^{-1/\alpha})^2$, and I can only say something about $\alpha=2$ and I got stuck here. Perhaps, I made a mistake somewhere. Could you please help me? Thanks.","['stochastic-processes', 'convergence-divergence', 'probability-theory', 'probability', 'limits']"
135405,Module M/IM of finite length $\implies$ Ring A/I of finite length,"This question is due to a proof in an algebra book (on the topic of dimension theory) which I don't fully understand (specifically, the proof of Thm 6.9b) in Kommutative Algebra by Ischebeck). It may have a very simple answer which I currently don't see. Let A be a semilocal, noetherian ring, $M$ a finite A-module with $\mathrm{Ann}_A(M)=0$ and $a_1,\ldots,a_s\in \mathrm{Jac}(A)$ with $l_A(M/(a_1,\ldots,a_s)M)\lt\infty.$
  Why is $l_A(A/(a_1,\ldots,a_s))\lt\infty$ ? (where $\mathrm{Ann}_A(M)=\{x\in A\mid xM=0\}$, $\mathrm{Jac}(A)=\bigcap\limits_{\text{m is maximal ideal in } A} m$, $l_X(Y)=$ length of $Y$ as an $X$-module) My ideas: I know that from $l_A(M/(a_1,\ldots,a_s)M)\lt \infty$ it follows that the ring $A/\mathrm{Ann}_A(M/(a_1,\ldots,a_s)M)$ is of finite length, because it can be embedded (as an $A$-module) in $M/(a_1,\ldots,a_s)M.$ But I don't know if/why $\mathrm{Ann}_A(M/(a_1,\ldots,a_s)M)=(a_1,\ldots,a_s)$. Also I don't know if $A$ being semilocal or $a_1,\ldots,a_s\in \mathrm{Jac}(A)$ instead of $a_1,\ldots,a_s\in A$ is of any relevance to the question. As further information, the final goal is to show that the degree of the polynomial p(n), which for large n gives the length $l_{A/Jac(A)}(M/Jac(A)^nM)$, is lesser or equal the minimum number s for which $l(M/(a_1,..,a_s)M)<∞$ as above.","['modules', 'commutative-algebra', 'ring-theory', 'abstract-algebra']"
135417,basic question about sets,"I'm reading the book Discrete Mathematics and its Applications 4th Edition by Susanne Epp. One of the questions is: Indicate the elements in the following sets: $$
\{n \in \mathbb{Z} \mid n = (-1)^k, \text{ for some integer } k \}
$$ the answer given is the set $\{-1, 1\}$ Could someone explain to me how this works? I don't understand how you can find this set without knowing what k is. If it's even then n will have to equal 1, if it's uneven it will have to equal -1.","['discrete-mathematics', 'elementary-set-theory']"
