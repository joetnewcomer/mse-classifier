question_id,title,body,tags
568969,Does $S:\Bbb{R}^m\to \Bbb{R}^n$ have to be a matrix?,"Let $S:\Bbb{R}^m\to \Bbb{R}^n$ be a linear transformation. Every textbook that I have come across states that $S$ is an $n\times m$ matrix. It is easy to see that such a matrix satisfies the properties of such a linear transformation. However, can $S$ be something other than a matrix? I can't think of a way of proving that $S$ can only be a matrix and nothing else. Thanks in advance!",['multivariable-calculus']
568971,Semicircle contour for integrating $t^2/(t^2+a^2)^3$,"Let $a\in\mathbb{R}$. Evaluate $$\int_0^{\infty}\dfrac{t^2}{(t^2+a^2)^3}dt$$ The function is even, so the value of the integral is half of $\int_{-\infty}^{\infty}\dfrac{t^2}{(t^2+a^2)^3}dt$ I'm going to use countour integration along the semicircle in upper-half plane with radius $R$. The integral along the real line is $\int_{-R}^{R}\dfrac{t^2}{(t^2+a^2)^3}dt$. Now for the curved part of the semicircle, I parametrize $z=Re^{it}$ for $0\leq t\leq 2\pi$. Then the integral becomes $$\int  \frac{z^2}{(z^2+a^2)^3}dz=\int_0^{2\pi}\frac{R^2e^{2it}}{(R^2e^{2it}+a^2)^3}\cdot Rie^{it}dt$$ And the absolute value of this integral is bounded from above by $\left|\dfrac{2\pi R^3}{(R^2e^{2it}+a^2)^3}\right|$. Why does this go to zero as $R\rightarrow \infty$? It seems like it's because the denominator has larger power of $R$, but how to make that rigorous?","['integration', 'complex-analysis']"
568973,Combinatorial Proof of Multinomial Theorem - Without Induction or Binomial Theorem,"I've been trying to rout out an exclusively combinatorial proof of the Multinomial Theorem with bounteous details but only lighted upon this one - see P2 . Any other helpful ones? $(x_1+\cdots+x_k)^n =$ Top of Page 39 from UNC :
  $\sum\limits_{\large{(a_1, ..., a_{k - 1}) \; \ni \; 0 \le a_1+...+ a_{k - 1} \le n}}\dbinom{n}{a_1,...,a_{k-1}}\cdot x_1^{a_1} \cdots x_{k-1}^{a_{k-1}}x_k^{\large{n - a_1 - \cdots - a_{k-1}}}$ $= \sum\limits_{\large{a_1+...+a_k = n \; \& \; a_i \ge 0 }}\dbinom{n}{a_1,...,a_k} x_1^{a_1} \cdots x_k^{a_k}$ Bottom of P1 from MSU . I see that both are the Multinomial Theorem but which one is better? I thought to try this myself, following the combinatorial proof of the Binomial Theorem. So  esteem each term (in green) in $(x_1+\cdots+x_k)^n = \underbrace{\color{green}{[x_1+\cdots+x_k]...[x_1+\cdots+x_k]}}_{\text{n terms}}$ as one box from which to choose $x_1, ..., x_k$. Since each term/box (in green) contains $k$ terms, the total number of terms $ = k^n$. First, consider $x_1$. ● For $x_1^n$, must have $a_ 1 = n\qquad \& \qquad a_2 = ... = a_k = 0$. ● For $x_1^{n - 1}$, must have $a_1 = n - 1 \qquad \& \qquad a_2 \text{ OR } ... \text{ OR } a_k = 1$ (the latter due to $a_1+...+a_k = n$ in definition from P1 of MSU) ... ● For $x_1^{1},$ must have $a_1 = 1 \qquad \& \qquad a_2 \text{ OR } ... \text{ OR } a_k = n - 1$ ● For $x_1^{0},$ must have $a_1 = 0 \qquad \& \qquad a_2 \text{ OR } ... \text{ OR } a_k = n$ The above extends to and must hold for all $x_1, ..., x_k$. How to translate all this into combinatorial notation? How to forge ahead and complete please?","['alternative-proof', 'combinatorial-proofs', 'combinatorics']"
568976,How to solve the transcendental equation $a^h=bh+c$ with a parameter,"I've got a random Rayleigh variable $\xi$ with $p_\xi(x)=\frac{x}{\sigma^2}\exp\{-\frac{x}{2\sigma^2}\},x\geq0$ There are two hypotheses: $H_0:\sigma=\sigma_0$ and $H_1:\sigma=\sigma_1$ I have built the procedure for Wald sequential analysis and now I have to find $P\{\text{deny } H_0\Bigr|\sigma=a\}=\frac{1-B^h}{A^h-B^h}$ Now I have to find h from the following equation: $$\int\limits_0^{+\infty}\left (\frac{p_1(x)}{p_0(x)}\right)^hp(x;a)=1$$ There are given $\sigma_0=2.2$ and $\sigma_1=2.7$ in the task. After I had simplified the integral, I got the following equation: $$\left (\frac{22}{27}\right)^h=1-\frac{6125}{8809}ha^2$$, that I have to solve for $h$. I think I must get W-Lambert function somehow but I have no ideas so far. I would appreciate any hints.","['statistics', 'transcendental-equations']"
568999,How find this value of $A$?,"Question： Let $z\in C$ Find this value $A$,such $$\lim_{k\to +\infty}\left(k-\dfrac{W_{k^2}(z)}{W_{k}(z)}\right)= A\cdot i$$ where $i^2=-1$,and 
$w_{k}(z)$ is Lambert $W$ function:see http://en.wikipedia.org/wiki/Lambert_W_function and this link give the $W_{k}(x)$ function: $$\begin{align} W(x)&=\frac{x}{2\pi}\int_{-\pi}^{\pi}\frac{(1-v\cot v)^2+v^2}{x+v\csc v \cdot e^{-v \cot v}}\\ W(x)&=\int_{-\infty}^{-1/e}-\frac{1}{\pi}\mathfrak{J}\left[\frac{\text{d}}{\text{d}x}W(x)\right]\ln(1-\frac{z}{x})\text{d}x\\ W(x)&=1+(\ln x-1)e^{i/2\pi \int_0^\infty \frac{1}{t+1}\ln\frac{\ln x+t-\ln t-i\pi}{\ln x+t-\ln t+i\pi}\text{d}t}\\ W_k(x)&=1+(\ln x+2k\pi i-1)e^{i/2\pi \int_0^\infty \frac{1}{t+1}\ln\frac{\ln x+t-\ln t+(2k-1)i\pi}{\ln x+t-\ln t+(2k+1)i\pi}\text{d}t} \end{align}$$ My try: let $z=a+bi$,then I Guess $A\to +\infty$ is true? Thank you","['special-functions', 'limits', 'calculus', 'analysis']"
569023,Evaluate $\int\limits_0^\pi \frac{\sin^2x}{2-\cos x}\ \mathrm dx$ by complex methods,"find integral $$\int\limits_0^\pi  \frac{\sin^2x}{2-\cos x}dx$$ what I had in mind is to use Euler formula, to turn it into a complex integral and change the limits of integration from $ -\pi$  to  $\pi$ so that any odd parts of the integrand would go to zero. But does not seem to make problem easier. Substitution of $u=\tan(x/2)$ would work but the computation is very tedious. Any suggestions for a nicer approach?","['complex-numbers', 'complex-analysis', 'contour-integration']"
569033,Commutative/noncommutative algebra?,"I know basic knowledge of undergraduate algebra till galois theory of finite extensions. I want to learn number theory, but also like algebra. This semester I have to choose to read either commutative algebra or noncommutative algebra. Can somebody tell me briefly the nature of both and what they lead? i want to know what they deal with and also in what way they are relevant in number theory. Thanks!","['noncommutative-algebra', 'advice', 'soft-question', 'abstract-algebra']"
569036,How to prove Cauchy Criterion for limits,"Let $A$ be a nonempty subset of $\mathbb R$ and $f: A\rightarrow \mathbb R$. Suppose $c$ is a cluster point of $A$. Suppose the limit of $f(x)$ at $c$ does not exist. Show that there exists $\varepsilon>0$ and two sequences $(x_n)$ and $(y_n)$ in $A\setminus \{c\}$, both converging to $c$, such that $|f(x_n)-f(y_n)|\geq\varepsilon$ for all $n\in\mathbb N$. limit of $f(x)$ exists if and only if for all $\varepsilon>0$, there exists $\delta>0$ such that if $x,y\in A$ with $0<|x-c|$ ,$|y-c|<\delta$, then $|f(x)-f(y)|<\varepsilon$. I have made some efforts on this but failed. My plan for question 1: the limit of $f(x)$ at $c$ doesn't exist means for every $L$ in $\mathbb R$ there is some $\varepsilon>0$ such that for any $\delta>0$ there is a $x_\delta≠c
$ in the $\delta$-neighborhood of $c$ such that $|f(x_\delta)-f(c)|≥\varepsilon$. Then, since we can find an arbitrary sequence $(y_n)$ in $A\setminus \{c\}$ converging to $c$, by letting $L_n=f(y_n)$ and $\delta_n=1/n$, we can find $\varepsilon_n>0$ so that there is a $x_n≠c$ in the $1/n$-neighborhood of c such that $|f(x_n)-f(y_n)|≥\varepsilon_n$. And it also follows that $(x_n)$ converges to c. So we just need to let $\varepsilon=inf${$\varepsilon_1, \varepsilon_2,...,\varepsilon_n,...$}. Here the question comes that I cannot assure $\varepsilon>0$. Can anybody give a hand? Thanks very much!!","['functions', 'real-analysis']"
569043,A limit problem related to $\log \sec x$,"If $$f(x) = \dfrac{{\displaystyle 3\int_{0}^{x}(1 + \sec t)\log\sec t\,dt}}{(\log\sec x)\{x + \log(\sec x + \tan x)\}}$$ then prove that $$\lim_{x \to {\pi/2}^{-}}f(x) = \frac{3}{2}$$ and $$\lim_{x \to 0}\frac{f(x) - 1}{x^{4}} = \frac{1}{420}$$ Looking at the integral sign in numerator I see that the best way to attack this problem is via L'Hospital Rule. But that requires to show that the integral diverges to $\infty$ as $x \to {\pi/2}^{-}$. Assuming that this is the case I solved the first limit by applying L'Hospital's rule twice. But for the second limit it seems hopeless to try L'Hospital because of denominator $x^{4}$ which might require 4 times its application. Looking at the functions involved it does not look easy to apply Taylor's series expansions. I am not sure if there is any elegant solution for the second problem. Please let me know any hints or a solution to the second limit. Update : I tried some simplification along with LHR for the second limit but still the final solution is eluding. Let $a(x), b(x)$ be the numerator and denominator of $f(x)$. Clearly we can see that
\begin{align}
B &= \lim_{x \to 0}\frac{b(x)}{x^{3}}\notag\\
&= \lim_{x \to 0}\frac{\log\sec x\{x + \log(\sec x + \tan x)\}}{x^{3}}\notag\\
&= -\lim_{x \to 0}\frac{\log\cos x\{x + \log(1 + \sin x) - \log \cos x\}}{x^{3}}\notag\\
&= -\lim_{x \to 0}\frac{\log\cos x}{x^{2}}\cdot\frac{x + \log(1 + \sin x) - \log \cos x}{x}\notag\\
&= -\lim_{x \to 0}\frac{\log(1 + \cos x - 1)}{\cos x - 1}\cdot\frac{\cos x - 1}{x^{2}}\cdot\frac{x + \log(1 + \sin x) - \log \cos x}{x}\notag\\
&= \frac{1}{2}\lim_{x \to 0}\frac{x + \log(1 + \sin x) - \log \cos x}{x}\notag\\
&= \frac{1}{2}\lim_{x \to 0}\left(1 + \frac{\log(1 + \sin x)}{\sin x}\cdot\frac{\sin x}{x} - \frac{\log (1 + \cos x - 1)}{\cos x - 1}\cdot x\cdot \frac{\cos x - 1}{x^{2}}\right)\notag\\
&= \frac{1}{2}\cdot 2 = 1\notag
\end{align}
Thus we can write
\begin{align}
L &= \lim_{x \to 0}\frac{f(x) - 1}{x^{4}}\notag\\
&= \lim_{x \to 0}\frac{a(x) - b(x)}{b(x)x^{4}}\notag\\
&= \lim_{x \to 0}\frac{a(x) - b(x)}{x^{7}}\cdot\frac{x^{3}}{b(x)}\notag\\
&= \lim_{x \to 0}\frac{a(x) - b(x)}{x^{7}}\notag\\
&= \frac{1}{7}\lim_{x \to 0}\frac{a'(x) - b'(x)}{x^{6}}\text{ (via L'Hospital's Rule)}\notag\\
&= \frac{1}{7}\lim_{x \to 0}\frac{3(1 + \sec x)\log\sec x - \tan x\{x + \log(\sec x + \tan x)\} -\log\sec x\{1 + \sec x\}}{x^{6}}\notag\\
&= \frac{1}{7}\lim_{x \to 0}\frac{2(1 + \sec x)\log\sec x - \tan x\{x + \log(\sec x + \tan x)\}}{x^{6}}\notag\\
&= \frac{1}{7}\lim_{x \to 0}\frac{2(1 + \cos x)\log\sec x - \sin x\{x + \log(\sec x + \tan x)\}}{x^{6}\cos x}\notag\\
&= \frac{1}{7}\lim_{x \to 0}\frac{2(1 + \cos x)\log\sec x - \sin x\{x + \log(\sec x + \tan x)\}}{x^{6}}\notag\\
\end{align}
I wonder what could be done to go further.","['calculus', 'limits']"
569105,Why is $\sin(x) = \sin(180^{\circ}-x)$,I cannot seem to understand why this is true. Same for $\cos(x) = -\cos(180^{\circ}-x)$ and $\tan(x) = -\tan(180^{\circ}-x)$. Without the use of the compound angle formulas. Thanks,['trigonometry']
569111,Using the Extension Operator Theorem for Sobolev Spaces,"I want to know if certain conditions hold after applying the Sobolev Extension Theorem: Assume $U$ is a bounded open subset of $\mathbb{R}^{n}$ and $\partial U$ is $C^{1}$. Suppose $1 \leq p < n$. If we fix $1 \leq q < p^{*}$, where $p^{*}$ is the Sobolev conjugate of $p$, then since we also have that $U$ is bounded it follows from Nirenberg-Gagliardo-Sobolev Inequaity that $W^{1,p}(U) \subset L^{q}(U)$ and $||u||_{L^{q}(U)} \leq C||u||_{W^{1,p}(U)}$. If we consider the linear extension operator $P: W^{1,p}(U) \rightarrow W^{1,p}(\mathbb{R}^{n})$, then does the above assumptions still hold? In other words is the following true? $W^{1,p}(\mathbb{R}^{n}) \subset L^{q}(\mathbb{R}^{n})$ and the inequality $||Pu||_{L^{q}(\mathbb{R}^{n})} \leq C||Pu||_{W^{1,p}(\mathbb{R}^{n})}$. Thanks for any assistance.","['sobolev-spaces', 'inequality', 'functional-analysis']"
569138,Navier-Stokes equations in tensorial form on a general coordinate system,How to write the classical Navier-Stokes equations in tensorial form on a general coordinate system? Any references?,"['geometry', 'multivariable-calculus', 'partial-differential-equations', 'mathematical-physics', 'fluid-dynamics']"
569181,Best way to explain how the Infimum and Supremum of this function are obtained...?,"I have the function $\;f(x)=\dfrac{x^{(1/2)}}{2+x}\;$ and I know that $\inf(f)$ does not exist and $\sup(f)=2$ but I don't know how to formally show this rigorously? Anyone got a formal way of showing this, it would be much appreciated...","['functions', 'supremum-and-infimum', 'real-analysis']"
569184,Calculating $\text{erf}^{-1}(z)$ for $z\in\mathbb{C}$,"All the information I found about inverse error function $\text{erf}^{-1}(z)$ was about $z\in\mathbb{R}$. Also I found some Taylor expansions for it, but as the function is unbounded near $z=\pm1$, these expansions only converge in the disk $|z|<1$. I want to look at real and imaginary parts of this function for $z\in\mathbb{C}$. I tried using Mathematica's InverseErf[z] , but it appeared to only support real arguments. I then tried using FindRoot to determine values and plot, but I got somewhat strange results, which don't disappear when I increase WorkingPrecision (tried up to 50 decimal places). Here's what I got for real (left) and imaginary (right) parts on DensityPlot from FindRoot : Very light and very dark regions correspond to values outside of $-3<f<3$ range. As one can see, using Taylor series won't help me with these strange regions, because all they are outside of disk of convergence. So, my questions are: (answered) How can one compute $\text{erf}^{-1}(z)$ for $z\in\mathbb{C}$ including those $|z|\ge1$? Are there any packages which are able to compute it without me having to implement the algorithm? Are properties of this function for complex arguments described anywhere?","['inverse', 'special-functions', 'error-function', 'complex-analysis']"
569185,Equicontinuity and Uniform Boundedness,"If we have a sequence of smooth functions $\{f_{n}\}_{n}$ where $f_{n}: U \rightarrow \mathbb{R}$, where
$U \subset \mathbb{R}^{n}$. We are given the following two results: For $x \in U$ we have $|f_{n}(x)| < \infty$ for all $n=1,2,...$
and also similarly $|Df_{n}(x)| < \infty$ for all $n=1,2,...$ then how does it
follow that $\{f_{n}\}_{n}$ is uniformly bounded and equicontinuous. Note that $Df_{n}$ is the gradient vector. The uniform boundedness seems to follow directly from $|f_{n}(x)| < \infty$
for all $n=1,2,...$ and all $x$, but I can't see how equicontinuity follows, maybe
I'm missing some result that is used? Thanks for any assistance, let me know if something is unclear.","['continuity', 'functional-analysis', 'uniform-convergence']"
569197,Prove that an eigenvector is the maximum of a symmetric matrix,"Let $f : S^{n-1} \rightarrow \mathbb{R}, x \mapsto x^TAx$ ( A is a symmetric matrix), then an eigenvector $\xi$ of A is a local maximum of this function. We are supposed to prove this in 6 steps and I got stuck somewhere.( I have to follow these steps, although it might be easier to prove this slightly different.) (i) Express $S^{n-1}$ in terms of a function $g(x_1,...,x_n)=0$. I did this by saying : $g(x_1,...,x_n) = x_1^2+...+x_n^2-1=0$.
(ii) Assume $\xi=e_n$. Then proof that there is a function $\gamma:B_{\epsilon}(0) \subset \mathbb{R}^{n-1} \rightarrow \mathbb{R} $ such that $ g(x_1,...,x_{n-1},\gamma(x_1,...,x_{n-1})=0$ and show that $D\gamma|_{x_1=0,...,x_{n-1}=0}=0$. Well by implicit function theorem, we get at $(0,...,0,1)$ that $g(0,...,0,1)=0$ and $\partial_{x_n}g(0,...,0,1)=2$ this is invertible and therefore there exists such a curve $\gamma$ and by implicit differentiation we get that $D\gamma|_{x_1=0,...,x_{n-1}=0}=0$. (iii) Look at the function $\bar{f}(x_1,...,x_{n-1})=f(x_1,...,x_n,\gamma(x_1,...,x_{n-1}))$ and prove that whenever $\bar{f}$ has a local maximum, then the same is true for $f$. Okay, this is pretty clear, since $\bar{f}$ and $f$ coincide on a local set and since the question of having a local extremum is only a local property, this is true. (iv) Look at $f$ as a map $f:\mathbb{R}^n \rightarrow \mathbb{R}, x \mapsto x^T Ax$ and calculate $\nabla f|_{x=e_n}$. Well $\nabla f(e_n) = e_n^T A$ (v) And now I am supposed to show that $e_n$ is an eigenvector. I have no idea how to do this, but I think I missed something, since the answer to (iv) is not telling me much. Does anybody have an idea, where I am wrong? Also, I am not sure about the fact: Assume $\xi=e_n$, this should have at least some effect on the proof. If something is unclear, please let me know. Does nobody have an idea or a hint/comment?(Maybe you are also wondering about something.)","['eigenvalues-eigenvectors', 'calculus', 'matrices', 'real-analysis', 'analysis']"
569226,Classification of groups of order 30 [duplicate],This question already has answers here : How many non isomorphic groups of order 30 are there? (2 answers) Closed 10 years ago . How do I find all the groups of order 30? That is I need to find all the groups with cardinality 30. I know Sylow theorems.,"['abstract-algebra', 'sylow-theory', 'finite-groups', 'semidirect-product', 'group-theory']"
569237,The normal bundle of the twisted cubic,"Let $C\subset \mathbb P^3$ be the twisted cubic given by the ideal $I=(xz-y^2,yw-z^2,xw-yz)$. I want to compute the normal bundle $N_{C/\mathbb P^3}$, i.e. the dual of $\mathcal I/\mathcal I^2=(I/I^2)^\sim$. My goal is to find $h^0(N_{C/\mathbb P^3})$, so I would like to write $N_{C/\mathbb P^3}$ in such a way that its $h^0$ can be easily computed. I tried to compute $I^2$, hoping to be able to write down $I/I^2$. But I did not succeed (too many relations), and I do not even know if this is the right track. What do you think? Afterwards, I wrote $$\mathcal I/\mathcal I^2=\mathcal I\otimes_{\mathcal O_{\mathbb P^3}}\mathcal O_{\mathbb P^3}/\mathcal I=\mathcal I\otimes_{\mathcal O_{\mathbb P^3}}\mathcal O_C=\mathcal I|_C.$$ But even there I got stuck, as I cannot compute that restriction. It would be much easier if $C$ were a complete intersection. Any help would be greatly appreciated. Thank you.",['algebraic-geometry']
569261,Is there a continuous function $f:S^1 \to \mathbb R$ which is one-one?,Is there a continuous function $f:S^1 \to \mathbb R$ which is one-one?,['general-topology']
569300,The intersection of two Sylow p-subgroups has the same order,Let $G$ be a finite group and assume it has more than one Sylow $p$-subgroup. It is known that order of intersection of two Sylow p-subgroups may change depending on the pairs of Sylow p-subgroups. I wonder whether there is a condition which guarantees that intersection of any two Sylow $p$-subgroups has the same order. Thanks for your help.,"['sylow-theory', 'finite-groups', 'group-theory', 'abstract-algebra']"
569308,Minimum area of the parallelepiped surface,"Among all the retangular parallelpipeds of volume $V$, find one whose total surface área is minimum Using the Lagrange Multipliers method, I've found that it is a cube with dimensions $ \sqrt[3]{V} $. But I don't know how to prove that it is, indeed, a cube with those dimensions, since I couldn't prove that the function $S_A(x,y,z)=2xy + 2xz + 2yz$ (surface total area) have a minimum. Can you help me with it? Thanks in advance",['multivariable-calculus']
569367,How find this limit $\lim_{x\to 0^{+}}x^{x^{x^{\cdots}}}$,"let $$f_{1}(x)=x,f_{2}(x)=x^x,f_{3}(x)=x^{x^x},f_{4}(x)=x^{x^{x^x}},\cdots,f_{n}(x)=x^{f_{n-1}(x)}$$ Find this follow two  limit (1):let $n<+\infty$ is give a postive integer number,and is 
$$\lim_{x\to 0^{+}}f_{n}(x)=1?$$ (2) if  $n=+\infty$,then
$$\lim_{x\to 0^{+}}f_{n}(x)=1?$$ My try: it is well know this 
$$\lim_{x\to 0^{+}}x^x=e^{\lim_{x\to 0^{+}}x\ln{x}}=1$$
and
$$\lim_{x\to 0^{+}}x^{x^x}=e^{\lim_{x\to 0^{+}}x^x\ln{x}}=1$$ and How can for any $n<+\infty$? Thank you",['limits']
569380,Finding indefinite integral $\int{ \mathrm dx\over \sqrt{\sin^3 x+\sin (x+\alpha)}}$,Could anyone help me how to solve this indefinite integral? $$\int{\mathrm dx\over \sqrt{\sin^3 x+\sin (x+\alpha)}}$$,"['integration', 'indefinite-integrals']"
569398,Radical ideals and $\operatorname{Proj}$,"It is well-known that in $\operatorname{Spec}A$, $V(I)\subset V(J)$ implies $\sqrt{I}\supset\sqrt{J}$. Is it also true in $\operatorname{Proj}A$, where $A$ is an $\mathbb{N}$-graded ring and $I,J\subset A$ are graded ideals? The difficulty in proving this seems to stem from the condition that the elements of $\operatorname{Proj}A$ do not contain  $\sum_{d>0}A_d$.",['algebraic-geometry']
569409,Any even elliptic function can be written in terms of the Weierstrass $\wp$ function,"Given two nonzero complex numbers $\omega_1, \omega_2$, with nonreal ratio, we define the period module $$M= \omega_1 \mathbb Z+ \omega_2 \mathbb Z= \{n_1 \omega_1+ n_2 \omega_2:n_1,n_2 \in \mathbb Z \} $$ 
and the Weierstrass $\wp$ function $$\wp(z; \omega_1, \omega_2) \equiv \wp(z;M)= \frac{1}{z^2}+ \sum_{\omega \in M \setminus \{0 \}} \frac{1}{(z- \omega)^2}-\frac{1}{\omega^2} .$$ I want to solve the following exercise from Ahlfors' complex analysis text (page 274): Show that any even elliptic function with periods $\omega_1$, $\omega_2$ can be expressed in the form
  $$C \prod_{k=1}^n \frac{\wp(z)-\wp(a_k)}{\wp(z)-\wp(b_k)} \text{ ($C$=const.)} $$
  provided  that $0$ is neither a zero nor a pole. What is the corresponding form if the function either vanishes or becomes infinite at the origin? My attempt: Let $f$ be an even elliptic function with periods $\omega_1,\omega_2$, and suppose for the moment that $f$ has neither a zero nor a pole at the origin. If $f$ is constant, we have an empty product representation $$f(z)= C \prod_{k=1}^0 \left( \dots \right). $$
Suppose now that $f$ isn't constant. As an elliptic function $f$ has equal number of (congruent) zeros and poles. Denote its zeros by $a_1, \dots,a_n$ and its poles by $b_1, \dots ,b_n$ (multiple points being repeated), and define $$g(z)=f(z) \bigg/ \prod_{k=1}^n \frac{\wp(z)-\wp(a_k)}{\wp(z)-\wp(b_k)} $$ 
What I want to say is that any numerator $$\wp(z)-\wp(a_k) $$ has a simple zero at $a_k$, and any denominator $$\frac{1}{\wp(z)-\wp(b_k)}$$ has a simple pole at $b_k$. If that's true then $g$ is a holomorphic elliptic function, which reduces to a constant $C$. If $f$ has a zero of order $2m$ at the origin we repeat the proof for $\tilde{f}= \wp^m f$ and we obtain the representation $$f(z)=C \wp(z)^{-m} \prod_{k=1}^n \frac{\wp(z)-\wp(a_k)}{\wp(z)-\wp(b_k)} \text{ ($C$=const.)} $$ If $f$ has a pole of order $2m$ at the origin we repeat the proof for $\tilde{f}= \wp^{-m} f$ and we obtain the representation $$f(z)=C \wp(z)^{+m} \prod_{k=1}^n \frac{\wp(z)-\wp(a_k)}{\wp(z)-\wp(b_k)} \text{ ($C$=const.)} .$$ My question: Why are all values of $\wp$ (except $\infty$) taken ""simply"" (that is with non-vanishing derivative at the point)? I tried considering the ""fundamental parallelogram"" with vertices at $a,a+\omega_1,a+\omega_2,a+\omega_1+\omega_2 $ where $a=-\frac{1}{2} \omega_1-\frac{1}{2} \omega_2$, and WLOG the uppermost and rightmost edges are included. It is known that in this parallelogram all complex values are taken twice. Since $\wp$ is even, if $a$ is an interior point, the value $\wp(a)$ is taken at least twice, at the points $\pm a$. However, if $a$ lies on the part of the boundary of the parallelogram which is included, I can't use the evenness argument, and as far as I can tell $a$ might be a double value of $\wp$ (?) Is my solution correct so far? and can you please help me with the question in boldface? Thanks!","['special-functions', 'elliptic-functions', 'complex-analysis', 'analysis']"
569448,Finding $n \in \mathbb{Z}$ such that $\sqrt{(4n-2)/(n+5)}$ is rational.,"I have to find $n \in \mathbb{Z}$ such that $$\sqrt{\frac{4n-2}{n+5}}\in\mathbb{Q}.$$ I've expressed $\sqrt{\frac{4n-2}{n+5}}$ as $\sqrt{4 - \frac{22}{n+5}}$ and I think that there's no $n$ for it be rational.
Am I correct?","['elementary-number-theory', 'algebra-precalculus']"
569459,Prove that $|A\cup B|^{n}+|A∩B|^{n}≥|A|^{n}+|B|^{n}$,"Let $A, B, C$ three finite sets and $n$ is a natural number nonzero. We denote $| X |$ the cardinal of set $X$. Prove that $$|A\cup B|^n +|A\cap B|^n \geq |A|^n +|B|^n.$$
Since the statement is well known for $n = 1$ it is natural to use mathematical induction, but it is difficult to make the transition from $P (n)$ to $P (n +1)$. Any idea how to do this?",['elementary-set-theory']
569497,Visualizing Sylvester's law,"According to Sylvester's law, every $2 \times 2$ real symmetric matrix is congruent to exactly one of six standard types. List them. I know that the symmetric matrix is congruent to the diagonal matrix, but what do they want me to list. What are the ""standard types"" ? If we consider the operation of $GL_2$ on $2 \times 2$ matrices by $P \star A= PAP^t$m then Sylvester's Law asserts that the symmetric matrices form six orbits. We may view the symmetric matrices as points in $\mathbb{R}^3$, letting $(x,y,z)$ correspond to the matrix $\begin{pmatrix} x& y\\ y& z \end{pmatrix}$. Describe the decomposition of $\mathbb{R}^3$ into orbits geometrically, and make a clear drawing depicting it. Please help, I am really having difficulty",['matrices']
569527,What do physicists mean with this bra-ket notation?,"In Quantum mechanics we said that $\langle x'|\psi \rangle = \psi(x)$, where 
$\langle \phi|\psi \rangle $ is the dot product in $L^2(\mathbb{C})$. I found out, that this is true, if you set x' to be the delta function $\delta(x)$ Now I also found $\langle p'|\psi \rangle = \tilde{\psi}(p)$, where $\tilde{\psi}$ is the fourier transform of $\psi$. My question is: Does anybody here know what $p'$ could be, so that this expression makes sense?","['fourier-analysis', 'calculus', 'mathematical-physics', 'real-analysis', 'analysis']"
569534,Expected length of the shortest polygonal path connecting random points,"$N$ points are selected in a uniformly distributed random way in a disk of a unit radius. Let $L(N)$ denote the expected length of the shortest polygonal path that visits each of the points at least once (the path need not to be closed any may be self-intersecting). For what $N$ do we know the exact value of $L(N)$? Is there a general formula for $L(N)$? What is the asymptotic behavior of $L(N)$ as $N\to\infty$? What are the answers to previous questions, if the disk is replaced with a ball?","['geometry', 'probability-theory', 'asymptotics', 'combinatorial-geometry', 'probability']"
569606,No idea how to prove this property about symmetric matrices,"This is from homework, so please hints only. Suppose $A$ is symmetric such that all of its eigenvalues are 1 or -1. Prove that $A$ is orthogonal. The converse is really easy, but I really have no idea how to do this. Any hints?","['linear-algebra', 'orthonormal']"
569617,Does the Weierstrass $\wp$ function have any double values besides $\infty$?,"Given nonzero complex constants $\omega_1,\omega_2$, with nonreal ratio, we define $$\wp(z;\omega_1,\omega_2)=\frac{1}{z^2}+ \sum_\omega \frac{1}{(z-\omega)^2}-\frac{1}{\omega^2} $$
where the sum is taken over all nonzero linear combinations $\omega=n_1 \omega_1+n_2 \omega_2$ with integer coefficients. It is known that $\wp$ is of order 2, which means that for any $c \in \hat{\mathbb C}$ the equation $\wp(z)=c$ has two non-congruent solutions (two points are called congruent if their difference is linear combination of $\omega_1,\omega_2$ with integer coefficients). In addition, it is known that $\wp$ is even, and that the poles on the ""lattice"" $ \omega_1 \mathbb Z+\omega_2 \mathbb Z$ are all of order 2. My question is: Could there be a point $z_0$ such that $\wp'(z_0)=0$? This would imply that the value $\wp(z_0)$ is taken twice at $z_0$. I tried using the evenness of the function to show that there isn't such point. However starting with $z_0=\frac{1}{2} \omega_1+\frac{1}{2} \omega_2$ this approach fails. Thanks.","['elliptic-functions', 'complex-analysis', 'analysis']"
569719,Maximal ideals in $\mathbb Z[i]$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let $\mathbb Z[i]=\{a+bi \mid a,b∈ℤ\}$ be a subring of $ℂ$. 
Consider two principal ideals $I=(7)$ and $J=(13)$ in $\mathbb Z[i]$. Is the ideal $I$ maximal? Is the ideal $J$ maximal?","['ring-theory', 'ideals', 'maximal-and-prime-ideals', 'abstract-algebra']"
569764,When is the squeeze theorem true?,"Here is the Squeeze Theorem in $\mathbb{R}$: Let $(a_n)$, $(b_n)$ and $(c_n)$ be sequences taking their values in $\mathbb{R}$. Let $x \in \mathbb{R}$. Assume that: $\forall n \in \mathbb{N}, \ \ a_n \leq b_n \leq c_n$; $\lim \limits_{n \to + \infty} a_n = \lim\limits_{n \to + \infty} c_n = x$. Then $\lim \limits_{n \to + \infty} b_n = x$. This theorem is true is one replaces the occurences of $\mathbb{R}$ above by $\overline{\mathbb{R}}$, $\mathbb{R}^n$, $\mathcal{C}_b (\Omega)$ (where $\Omega$ is an open set), $\mathbb{L}^p (\Omega, \mu)$ (where $(\Omega, \mu)$ is a measured space and $p \in [0, + \infty]$), and even in $\mathcal{P} (\mathbb{R})$ (see this related question ). However, the proofs I know of these facts have some points in common, but also some individual ingredients. Is there a general sufficient condition which would ensure that a topological space with a partial order satisfies the Squeeze Theorem, and apply to all examples above? Are there some not too contrived examples of spaces for which the Squeeze Theorem fail?","['general-topology', 'sequences-and-series']"
569774,Are there matrices with with non-real elements?,"I know that the definition of a matrix is a rectangular arrangement of elements, which are real numbers. But does there exist such a thing as a rectangular arrangement of complex numbers? How are these matrices called, if they exist?","['matrices', 'complex-numbers']"
569787,Implicit differentiation,"I want to differentiate $x^2 + y^2=1$ with respect to $x$. The answer is $2x +2yy' = 0$. Can some explain what is implicit differentiation and from where did $y'$ appear ? I can understand that $2x +2yy' = 0$ is a partial derivative but then it becomes multi calc not single. This is in a chapter about chain rule so I assume there is some use of the chain rule here but I can't see any composite functions here. We can express y in terms of x but y is not composite. P.S: I am NOT looking for HOW to solve the problem, I am looking for the WHY as stated above.","['multivariable-calculus', 'implicit-differentiation', 'calculus', 'limits']"
569825,Sample mean is uniformly integrable,"Let $\{X_n\}$ be a sequence of iid random variables such that $E|X_1| = \mu < \infty$. I would like to show that $\{\bar{X}_n\}$ is uniformly integrable. Thoughts By the strong law of large numbers, $\bar{X}_n \rightarrow \mu$ almost surely, so it converges in probability. By the continuous mapping theorem, $|\bar{X}_n| \rightarrow |\mu|$ almost surely. If I could show that $E |X_n| \rightarrow |\mu|$, that would imply $\{\bar{X}_n\}$ is UI. It would also suffice to show $\bar{X}_n \rightarrow \mu$ in $L_1$. I also tried to use the definition of uniform integrability to show that
$$
\lim_{t \rightarrow \infty} \sup_n E(|\bar{X}_n| \, 1[\bar{X}_n > t])
= 0.$$",['probability-theory']
569856,function with zero first to n'th derivative at end points,"As an extension of my earlier question , It is required to find f(x) with following properties, $$ f(0) = 0 \hspace{1cm}f(1) = 1 \\
f'(0) = 0 \hspace{1cm}f'(1) = 0 \\
f''(0) = 0 \hspace{1cm}f''(1) = 0 \\
f'''(0) = 0 \hspace{1cm}f'''(1) = 0 \\
\dots \\
f^{(n)}(0) = 0 \hspace{1cm}f^{(n)}(1) = 0 \\
$$ and most important condition being $f'(\xi) \ge = 0 \hspace{.5cm}\forall \xi \in (0,1)$. Here prime denotes derivative of the function. I have a solution for n = 1 and n= 2 as follows respectively(I don't assume that they are unique),
\begin{eqnarray}
f_1(x) &=&  \frac{1}{2} \left[1- \cos(\pi x)\right] \\
f_2(x) &=& x - \frac{\sin(2\pi x)}{2\pi}
\end{eqnarray} With graphs as follwing, It is clear from the graph that with increasing n, the solution would approach step function with jump at $x = 0.5$. I will be happy if someone can point out solution for n = 3 or higher degrees. Thanks for the attention","['boundary-value-problem', 'calculus', 'functions']"
569873,Fibonacci combinatorial identity: $F_{2n} = {n \choose 0} F_0 + {n\choose 1} F_1 + ... {n\choose n} F_n$ [duplicate],"This question already has answers here : Prove: $\binom{n}{0}F_0+\binom{n}{1}F_1+\binom{n}{2}F_2+\cdots+\binom{n}{n}F_n=F_{2n}$ (3 answers) Closed 7 years ago . Can someone explain how to prove the following identity involving Fibonacci sequence 
$F_n$ $F_{2n} = {n \choose 0} F_0 + {n\choose 1} F_1 + ... {n\choose n} F_n$
?","['fibonacci-numbers', 'summation', 'binomial-coefficients', 'combinatorics']"
569880,How to prove that a group of order $72=2^3\cdot 3^2$ is solvable?,"Let $G$ be a group of order
$$72=2^3\cdot 3^2$$
Without using Burnside's Theorem, how to show that $G$ is solvable? Atempt: If we can show that $G$ has at least one non-trivial normal subgroup $N$, then it would be easy to show it is solvable. Indeed,
$$1\longrightarrow N\longrightarrow G\longrightarrow G/N\longrightarrow 1$$
would be a short exact sequence with $N$ and $N/G$ of order $2^i\cdot3^j$ for some $i,j\in\{0,1,2\}$ and it is not too hard to show that such groups are always solvable. However, I can't find a way to show that $G$ is not simple. Added: If $G$ is not simple, then Sylow's Theorem implies that there are $4$ subgroups of order 9 and 3 or 9 subgroups of order 8. Then, I don't see how to use that to show that $G$ is not simple.","['solvable-groups', 'group-theory']"
569900,log(log(123456789101112131415...))),"How would you fin the integer closest to log(log(1234567891011121314...2013)) where the number is the concatenation of numbers 1 through 2013 inclusive.
log() in this case is log base 10. Also, how would you find the remainder when it is divided by 75?","['logarithms', 'number-theory']"
569919,Shroeder-Bernstein theorem help?,"I understand that theorem lets you prove the existence of a bijection from a set A to a set B just by proving that there is a one-to-one function that maps A to B has another one-to-one function that maps B to A. Also since the question asks for same cardinality, proving that a bijection exists is sufficient. I don't understand, how to apply my knowledge to this situation ? Any help would be greatly appreciated.",['elementary-set-theory']
569928,Prove that the function $\sqrt x$ is uniformly continuous on $\{x\in \mathbb{R} | x \ge 0\}$.,"Prove that the function $\sqrt x$ is uniformly continuous on $\{x\in \mathbb{R} | x \ge 0\}$ . To show uniformly continuity I must show for a given $\epsilon > 0$ there exists a $\delta>0$ such that for all $x_1, x_2 \in \mathbb{R}$ we have $|x_1 - x_2| < \delta$ implies that $|f(x_1) - f(x_2)|< \epsilon.$ What I did was $\left|\sqrt x - \sqrt x_0\right| = \left|\frac{(\sqrt x - \sqrt x_0)(\sqrt x + \sqrt x_0)}{(\sqrt x + \sqrt x_0)}\right| = \left|\frac{x - x_0}{\sqrt x + \sqrt x_0}\right| < \frac{\delta}{\sqrt x + \sqrt x_0}.$ But I found a proof online that made $\delta = \epsilon^2$ which I don't understand how they got it? So, in order for $\delta =\epsilon^2$ , then $\sqrt x + \sqrt x_0$ must $\le \epsilon$ then $\frac{\delta}{\sqrt x + \sqrt x_0} \le \frac{\delta}{\epsilon} = \epsilon$ . But then why would $\epsilon \le \sqrt x + \sqrt x_0?$ Ah, I think I understand it now just by typing this out and from an earlier hint by Michael Hardy here .","['real-analysis', 'uniform-continuity']"
569945,Number of ways to form three distinctive items,"Given a 6 by 5 array, Calculate the number of ways to form a set of three distinct items such that no two of the selected items are in the same row or same column. What I did was $C(30,1) \cdot C(20,1) \cdot C(12,1)$ however this is not the answer. They get 1200. How?","['statistics', 'probability-theory', 'combinatorics']"
569948,Uniqueness of Fourier transform in $L^1$,"The Fourier transform of an $L^1$ function is defined by $$\hat{f}(y)=\int_\mathbb{R}f(x)e^{-ixy}dx$$ Is it true that for functions $f,g\in L^1$, if $\hat{f}=\hat{g}$, then $f=g$?","['fourier-analysis', 'real-analysis']"
569951,What is the difference between a random vector and a stochastic process?,"I am a little confused about random vectors and stochastic processes. I read their definitions in  Wikipedia ( random vector , stochastic process ) and I cannot understand their differences . I would appreciate your help. Thanks.","['stochastic-processes', 'statistics', 'random-variables', 'probability-theory', 'probability']"
569989,Sum of Singular Values of (A+B),How we can prove that: $$\sum_{i=1}^n\sigma_i(A+B)\leq\sum_{i=1}^n\sigma_i(A)+\sum_{i=1}^n\sigma_i(B)$$ Where $\sigma_i$s are singular values  $\sigma_1\geq\sigma_2\geq\cdots\geq\sigma_n\geq0$ .,"['matrices', 'linear-algebra', 'svd']"
569997,Integral of Schwartz function over probability measure,"Let $X$ be a set, $\mathcal F$ a $\sigma$-field of subsets of $X$, and $\mu$ a probability measure on $X$. Given random variables $f,g\colon X\rightarrow\mathbb{R}$ such that $$\int_\mathbb{R}hd{\mu_f}=\int_{\mathbb{R}}hd\mu_g$$ for any Schwartz function $h$. Is it necessarily true that $\mu_f=\mu_g$?","['probability-theory', 'lebesgue-integral', 'measure-theory', 'schwartz-space']"
569998,Show that $\frac{1}{n}\sum_{j=1}^{n}X_{j}$ is Cauchy distributed when the $X_{i}$ are all Cauchy,"Let $X_{1}, \cdots, X_{n}$ be i.i.d. Cauchy random variables with parameters $\alpha=0$ and $\beta=1$. (That is, their density is $f(x)=\frac{1}{\pi\,(1+x^{2})}$, $-\infty < x < \infty$.) Show that $\frac{1}{n} \sum_{j=1}^{n}X_{j}$ also has a Cauchy distribution. We are given the hint to use characteristic functions, but I am wondering if there is an easier way to approach this problem. I tried some stuff using the fact that the $X_{i}$ are independent, but it really didn't go anywhere, so any help you could give would be most appreciated!","['probability-theory', 'probability-distributions', 'characteristic-functions']"
570000,Why is the concept of a codomain useful?,"I don't understand what the point is of specifying the codomain of a function. For example, if I ask, ""Given the function f: $\Bbb R$ $\to$ $\Bbb R$, where $f(x) = x^2$, what is the image of f?"", how is that any different from asking, ""Given the function $f(x) = x^2$ whose domain is $\Bbb R$, what is the image of f?"" In both cases, the answer can only be ""The set of all real numbers greater than or equal to $\theta$"". Supplying the codomain in the first question doesn't add any more useful information. Maybe a more precise way to phrase my question would be: What's the use of distinguishing between a number that's a part of a function's codomain but not its image, and a number that is neither part of the function's codomain nor its image?",['functions']
570003,how many unique patterns exist for a $N\times N$ grid,"I'm trying to figure out if there is a way to determine how many unique patterns exist for a given $N\times N$ grid if you choose N points on the grid. For example, for a $2\times 2$ grid we can get two unique patterns from the six possible combinations. The rest are just rotations and mirrors of the two unique patterns below [x] [x] [ ] [ ] and [x] [ ] [ ] [x] Is there a mathematical way of determining a unique number of patterns for a NxN grid where N=3,4,5,6,7,8? I figured for a 3x3, there are 14 unique patterns for picking 3 random points on the grid, but it gets tedious after that. N: N^2  : N^2 Choose N Unique pattern 2 4 6 2 3 9 84 14 4 16 1820 ???? 5 25 53130 ???? 6 36 1947792 ???? 7 49 85900584 ????","['matrices', 'combinations']"
570017,Show that there is $\xi$ s.t. $f(\xi)=f\left(\xi+\frac{1}{n}\right)$,"Let $f:[0,1]\to\mathbb{R}$ be continuous and $f(0)=f(1)$. Show that for any integer $n\geqslant 2$, there is $\xi\in(0,1)$ s.t.$f(\xi)=f\left(\xi+\frac{1}{n}\right).$ I think this requires the intermediate value theorem somewhere.","['functions', 'calculus', 'real-analysis']"
570022,Help understand this proof of even and odd subsets,"I need help understanding the proof of the following statement, as given in the book I'm following: Show that a non-empty set has an equal number of even subsets (that is, subsets with an even number of elements) and odd subsets. The idea of bijection or C(n,k) hasn't been introduced yet, so the proof relies on simple logic: Divide all subsets into pairs such that each pair differs only in their first element. Each pair contains an even and an odd subset, so their numbers are the same. I'm not at all sure I follow this. If I consider the subsets of $\{1,2,3\}$ to be $\phi, \{1\}, \{2\}, \{3\}, \{1,2\}, \{1,3\}, \{2,3\}, \{1,2,3\}$, how are the pairings to be done? I could start as follows: $$
\{1\} \Leftrightarrow \{2\}
$$
$$
\{3\} \Leftrightarrow \phi
$$
$$
\{1,2\} \Leftrightarrow \{3,2\}
$$ But then I don't see how $\{1,3\}$ and $\{1,2,3\}$ can be paired. More generally, I don't see how the proof works. Please explain.","['elementary-set-theory', 'combinatorics']"
570023,"Copulas, implication","Let $C$ be a copula function. Prove that $C(t,1-t)=0$ for all $t\in[0,1]$ implies that $C(u,v)=\max(u+v-1,0)$. I think the implication other way around is easy to see, however I can't see why the ""upper diagonal"" part of the copula function could not be some type of a different function with $C(u,1)=u$ and $C(1,v)=v$. See the image below - the leftmost plot is the Frechet-Hoeffding lower bound. I need to prove that $C$ is equal to that.","['special-functions', 'probability']"
570072,Find all $\theta$ such that sin$\theta$ and cos$\theta$ are both rational number.,"Find all $\theta$ such that sin$\theta$ and cos$\theta$ are both rational number. I thought this question might have been asked by someone else, but I couldn't find any. Currently I'm studying Pythagorean triple, so naturally I put $X$=cos$\theta$ and $Y$=sin$\theta$, then $$X^2 +Y^2 =1: X,~Y \in \Bbb{Q}$$ By using graph or from the graphical proof of Pythagorean triple, one can show that $$X=\frac{a^2-b^2}{a^2+b^2},~Y=\frac{2ab}{a^2+b^2}$$ where $(a, b)=1$. But then, we have to find $\theta$ which makes $X$ and $Y$ in that form. So I got stuck. I've thought of using the inverse trigonometric function, but we still have two equations then. So I was wondering if there is any simpler way to express $\theta$ which satisfies the given condition. I'm even more confused because I don't have the answer! Thanks.","['trigonometry', 'elementary-number-theory', 'rational-numbers']"
570083,Evaluating $\int e^{-x}\tan(x) \ \mathrm dx$ .,"I was told years ago by a visiting professor that this integral:$$\int e^{-x}\tan(x)dx$$ has an elementary form, but I have never been able to find it.  Any suggestions?  I don't think it's possible anymore, but thought I would ask...","['trigonometry', 'calculus', 'indefinite-integrals']"
570088,"Prove that if positive-definite $f$ is continuous at $0$, it is continuous on $\mathbb{R}$","Long story short, the question I'm stuck on is as follows: Let $f$ be a positive-definite function.  Prove that if $f$ is continuous at $0$, then it is continuous everywhere. Here's the long version: We say that a function $f:\mathbb{R}\to \mathbb{C}$ is positive definite if the matrix $A_f[\{t_1,t_2,\dots,t_n\}]$, whose entries are given by 
$$
A_f[\{t_1,t_2,\dots,t_n\}]=[f(t_i-t_j)]_{i,j=1}^n
$$
Is positive semidefinite for all choices of $t_1,\dots,t_n \in \mathbb{R}$.  In the whole problem, we are meant to show that $f$ has the following properties: $f(-t) = \overline{f(t)}$ $f(0) \in \mathbb{R}$ and $f(0) \geq 0$ $|f(t)|\leq f(0)$ for all $t \in \mathbb{R}$ if $f$ is continuous at $0$, then it is continuous everywhere The first three parts may all be solved by considering the $2\times 2$ matrix $A_f[0,t]$ where $t\in \mathbb{R}$ is arbitrary. Because $A_f[0,t]$ is Hermitian, the first statement holds.  Because $A_f[0,t]$ must have non-negative trace, we conclude that the second statement holds.  Becuase $A_f[0,t]$ has a non-negative determinant, we conclude that the third statement holds.  That fourth statement, however, has me stumped. As far as I can tell, there is no more insight to be gleaned from $2\times 2$ matrices.  Presumably, I need to find an upper bound for $|f(t) - f(t+\delta)|$ given that $|f(\delta) - f(0)|$ can be made arbitrarily small.  I've noticed that $\det A_f[0,t,t+\delta]$ can be finagled into something like $f(0)|f(t) - f(t+\delta)|^2$.  However, it's not clear to me how I would use this to the desired ends. There's also a good chance that I've managed to think myself into a hole, given that this one small part of one problem has given me more trouble than the rest of the assignment. The question claims that this problem can be solved using the fact that a semi-definite matrix has a non-negative trace and determinant, and that all principal submatrices have a non-negative determinant. I think that just about covers it.  If you've made it this far, thank you for your time; I tried not to make this a wall of text.  Any helpful nudges in the right direction would be very much appreciated; an attempt at an answer doubly so.","['matrices', 'linear-algebra']"
570099,Simplification of $\sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2+\dots}}}}$,I'm having trouble understanding how this expression: $$\sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2+\dots}}}} \cdot \left(\frac{\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\dots+\sqrt2}}}}}{\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\dots+\sqrt2}}}}}\right)=$$ got to this one: $$\frac2{\sqrt2\cdot\sqrt{2+\sqrt2}\cdot\sqrt{2+\sqrt{2+\sqrt{2}}}\cdot\dots}$$,"['arithmetic', 'sequences-and-series', 'algebra-precalculus', 'nested-radicals']"
570101,Find all real solutions for $16^{x^2 + y} + 16^{x + y^2} = 1$,"Find all $x, y \in \mathbb{R}$ such that: $$16^{x^2 + y} + 16^{x + y^2} = 1$$ The first obvious approach was to take the log base $16$ of both sides: $$\log_{16}(16^{x^2 + y} + 16^{x + y^2}) = 0$$ manipulating did not give any useful result. The next thing I tried was getting some bounds on $x$ and $y$: If $x, y \geq 0$, $$16^{x^2 + y} + 16^{x + y^2} \geq 2$$ So, $x, y \le 0$. Trying to obtain a lower bound was not fruitful. Also, in general, I have a lot of difficulty solving such problems which require all solutions to a certain equation. Whatever I do is almost always contrary to what the actual solution is and the solution itself involves some bizarre counter-intuitive manipulations or methods. Some tips on how to approach such problems will be helpful for me. Thanks.","['algebra-precalculus', 'diophantine-equations']"
570116,How prove this $a_{n}>1$,"let $0<t<1$, and $a_{1}=1+t$, and such
$$a_{n}=t+\dfrac{1}{a_{n-1}}$$ show that $a_{n}>1$ My try: since 
$$a_{1}=1+t>1$$
$$a_{2}=t+\dfrac{1}{a_{1}}=t+1+\dfrac{1}{1+t}-1>2\sqrt{(t+1)\cdot\dfrac{1}{1+t}}-1=2-1=1$$ $$a_{3}=t+\dfrac{1}{a_{2}}=t+\dfrac{1}{t+\dfrac{1}{t+1}}=t+\dfrac{t+1}{t^2+t+1}=1+\dfrac{t^3+t}{t^2+t+1}>1$$
$$\cdots\cdots\cdots$$
But $a_{n}$ is very ugly,so this problem may use other methods.Thank you very much!","['inequality', 'sequences-and-series']"
570119,"A scheme $X$ finite type over $R$, but $\Gamma(X,O_X)$ is not finitely generated $R$-algebra","A scheme $X$ over $R$ is of finite type if $X$ is quasi-compact and for all affine subsets $U \subset X$,  $\Gamma(U,O_X)$ is a finitely generated $R$-algebra. Is there an example of scheme $X$ finite type over $R$, but $\Gamma(X,O_X)$ is not finitely generated $R$-algebra? And how does it relates to the Hilbert's fourteenth problem: ""$K$ is a subfield of $k(X_1,\dots,X_n)$ does not imply $K\cap k[X_1,\dots,X_n]$ finitely generated""?","['commutative-algebra', 'algebraic-geometry']"
570122,Ring structure on the Galois group of a finite field,"Let $F$ be a finite field. There is an isomorphism of topological groups $(\mathrm{Gal}(\overline{F}/F),\circ) \cong (\widehat{\mathbb{Z}},+)$ . It follows that the Galois group carries the structure of a topological ring isomorphic to $\widehat{\mathbb{Z}}$ . What does the multiplication $*$ look like, intrinsically? Well, if $\sigma$ is the Frobenius, we have $\sigma^n * \sigma^m = \sigma^{n \cdot m}$ for all $n,m \in \mathbb{Z}$ , and this describes $*$ completely. But is there any way to give an explicit and intrinsic formula for $\alpha * \beta$ if $\alpha,\beta$ are $F$ -automorphisms of $\overline{F}$ ? Also, is there any more conceptual reason why the Galois group carries the structure of a topological ring - without computing the Galois group? Maybe the following is a more precise version of the latter question using Grothendieck's Galois theory : Consider the Galois category $\mathcal{C}$ of finite étale $F$ -algebras together with the fiber functor $\mathcal{C} \to \mathsf{FinSet}$ . The automorphism group is exactly $\pi_1(\mathrm{Spec}(F))=\widehat{\mathbb{Z}}$ . So we may ask: Which additional structure on a Galois category is responsible for the ring structure on its automorphism group? Here is an idea: Grothendieck's main theorem of Galois theory states that $G \mapsto G{-}\mathsf{FinSet}$ is an anti-equivalence of categories from profinite groups to Galois categories (with their fiber functors) -- right? The category of profinite groups has finite products (easy), so there are finite coproducts of Galois categories. But how do we describe these, intrinsically? We have $G{-}\mathsf{FinSet} \sqcup H{-}\mathsf{FinSet} = (G \times H){-}\mathsf{FinSet}$ for example. The connection to the question is as follows: The anti-equivalence above induces an anti-equivalence of monoids with respect to the product. So there is an anti-equivalence of categories between topological rings and comonoids of Galois categories , the latter being equipped with some kind of functor $\mathcal{C} \to \mathcal{C} \sqcup \mathcal{C}$ etc. So this seems to be the additional structure I am looking for. And the original question asks to give an explicit functor for the special case $\mathcal{C} = $ finite étale $F$ -algebras.","['ring-theory', 'finite-fields', 'abstract-algebra', 'galois-theory', 'field-theory']"
570127,Linear and Commutative function over Square Matrices.,"Find all functions $f$, such that $f(mA+nB) = mf(A) + nf(B)$ and  $f(AB) = f(BA)$ , where $A, B$ are square matrices and $ m,n$ are scalars. Need to find $f$ as an explicit function of any general matrix M. I observed that $Trace(M)$ is a valid function satisfying the condition, but any methodical approach to find the functions would be helpful.","['vector-spaces', 'matrices', 'linear-algebra']"
570132,Difference between $\mathbb Z^+$ and $\mathbb N$,"$\mathbb Z^+$ stands for the Positive Integers: $\{1,2,3,4,5\dots\}$ $\mathbb N$ stands for the Natural Numbers: $\{1,2,3,4,5\dots\}$ So what is the difference between $\mathbb Z^+$ and $\mathbb N$?","['notation', 'elementary-set-theory']"
570134,Confusing about coordinate curves and quadrilateral formed?,"Below is a problem which states a fact about ""Tchebyshef net"". I don't understand meaning of bolded part. The coordinate curves of a parametrization $x(u, v)$ constitute a Tchebyshef net if the lengths of the opposite sides of any quadrilateral formed by them are equal. Show that a necessary and sufficient condition for this is $$\frac{\partial E}{\partial v} =\frac{\partial G}{\partial u}=0.$$
  Reference: Differential Geometry of Curves and Surfaces [Manfredo P.do carmo] Page 100 Problem 7.","['self-learning', 'differential-geometry']"
570139,Should isometries be linear?,"Question Suppose $V$ is a (finite-dimensional) vector space over $F$ ($\operatorname{char }F\neq2$, due to user1551) equipped with a non-degenerate quadratic form $Q$, and $T$ is a distance-preserving operator on $V$, viz. $Q(Tu-Tv)=Q(u-v)$ for each $u,v\in V$. Is it true that $T$ is linear affine (due to user1551)? Background I'm thinking about the mathematical derivation of Lorentz transformation from the principles of special relativity. In the context, $F=\mathbb R$, $V=F^4$ and $Q$ is the Lorentz quadratic form. The original problem might be with condition that $T$ acts on the space $\mathbb R^3$ as a translate (since they are inertial frames of reference), but $Q(Tu-Tv)=Q(u-v)$ only when $Q(u-v)=0$, which means that the operator preserves light cones. On condition that $F=\mathbb R$ and $Q$ is positive definite the answer is true. It follows from a standard derivation: Suppose $\langle x,y\rangle=(Q(x+y)-Q(x)-Q(y))/2$, then by definition $\langle\circ,\circ\rangle$ is a positive definite bilinear form. Note that $\langle Tu,Tv\rangle=\frac12(Q(Tu)+Q(Tv)-Q(Tu-Tv))=\frac12(Q(u)+Q(v)-Q(u-v))=\langle u,v\rangle$, we have $Q(Tcv-cTv)=\langle Tcv-cTv,Tcv-cTv\rangle=0$ and $Q(T(u+v)-Tu-Tv)=\langle T(u+v)-Tu-Tv,T(u+v)-Tu-Tv\rangle=0$ follows, which implies that $T(u+v)=Tu+Tv$ and $Tcv=cTv$. From the preceding argument, $T(u+v)-Tu-Tv$ and $Tcv-cTv$ are generally isotropic, but I don't know whether they must be zero. Any idea? Thanks!","['quadratic-forms', 'linear-algebra', 'bilinear-form', 'physics']"
570146,Fair division of an octagon,"A land-plot belongs to two partners. Its form is a regular octagon with area 1 . They want to divide it such that one gets area $p$ and one gets area $1-p$, where $p \in (0,1)$ is a given constant. One way to do it is just to continuously move a straight line over the octagon, say, from east to west. The area to the east of the line grows continuously from 0 to 1, therefore by the intermediate value theorem it must cross $p$ at some point. The problem with this division is that one of the plots might be too narrow, and unuseful. So the partners agree on the following condition: Each land-plot should be convex and contain a square with an area of at least half the area of the land-plot . I.e., one partner should get a square with area at least $p \over 2$, and the other should get a square with area at least $(1-p) \over 2$. Is this possible for all $p$? If the answer is no - does it become possible if we allow the land-plots to be non-convex?","['geometry', 'fair-division', 'packing-problem', 'euclidean-geometry']"
570155,Why do the interesting antihomomorphisms tend to be involutions?,"Given a semigroup $S$, define that an antihomomorphism on $S$ is a function $$* :S \rightarrow S$$ satisfying $(xy)^* = y^*x^*.$ Examples abound. Consider: Transposition, where $S$ equals the set of $2 \times 2$ real matrices. Conjugate-transposition, where $S$ equals the set of $2 \times 2$ complex matrices. The map that takes a binary relation to its converse, where $S$ equals the monoid of binary relations on a set $X$. Inversion, in any group. The weird thing is that in all of the above examples, the star operation is actually involutive . In fact, off the top of my head I can't think of any non-trivial antihomomorphisms that aren't also involutions. Why do the antihomomorphisms of interest tend to be involutions? I mean, is there some sort of ""killer theorem"" or something, that just makes involutive antihomomorphisms totally awesome? Conversely, I am also interested in examples of antihomomorphisms that fail to be involutions, but which are still deemed important.","['semigroups', 'intuition', 'abstract-algebra']"
570167,Evaluating $\int_{0}^{\pi} \frac{\cos(nx)}{(p+\cos(x))^2+q^2}\ \mathrm dx$,"I have a formula in my research, but have no idea how to get the explicit formula.
$$\int_{0}^{\pi} \frac{\cos(nx)}{(p+\cos(x))^2+q^2}\ \mathrm dx$$
where n is an integer.",['integration']
570177,"If $G$ is a group and $N$ is a nontrivial normal subgroup, can $G/N \cong G$? [duplicate]","This question already has answers here : Does $G\cong G/H$ imply that $H$ is trivial? (11 answers) Closed 10 years ago . I know $G/N$ is isomorphic to a proper subgroup of $G$ in this case, so the gut instinct I had was 'no'. But there are examples of groups that are isomorphic to proper subgroups, such as the integers being isomorphic to the even integers, so that reasoning doesn't work. However in this case the even integers are not a quotient of the integers. edit: I realize now that $G/N$ is not necessarily isomorphic to a proper subgroup of $G$, just a subgroup of $G$.","['examples-counterexamples', 'hopfian', 'group-theory', 'abstract-algebra']"
570202,Taking the automorphism group of a group is not functorial.,"Once upon a time I proved that there is no functorial 'association'
$$F:\ \mathbf{Grp}\ \longrightarrow\ \mathbf{Grp}:\ G\ \longmapsto\ \operatorname{Aut}(G).$$
A few days ago I casually mentioned this to someone, and was asked for a proof. Unfortunately I could not and still can not recall how I proved it. Here is how much of my proof I do recall: Suppose such a functor does exist. Choose some group $G$ wisely, and let $f\in\operatorname{Hom}(V_4,G)$ and $g\in\operatorname{Hom}(G,V_4)$ be such that $g\circ f=\operatorname{id}_{V_4}$. Then, because $F$ is a co- or contravariant functor we have
$$F(g)\circ F(f)=F(g\circ f)=F(\operatorname{id}_{V_4})=\operatorname{id}_{\operatorname{Aut}(V_4)},$$
or
$$F(f)\circ F(g)=F(g\circ f)=F(\operatorname{id}_{V_4})=\operatorname{id}_{\operatorname{Aut}(V_4)},$$
where $\operatorname{Aut}(V_4)\cong S_3$. In particular $\operatorname{Aut}(G)$ contains a subgroup isomorphic to $S_3$. Then something about the order of $\operatorname{Aut}(G)$ leads to a contradiction. I cannot for the life of me find which goup $G$ would do the trick. Any ideas?","['examples-counterexamples', 'abstract-algebra', 'category-theory', 'finite-groups', 'group-theory']"
570209,infinite intersection of 2 uncountable sets,"Is it true that if the intersection of 2 uncountable sets is infinite, then the intersection is definitely uncountable? How do I start disproving/ proving this statement?",['elementary-set-theory']
570212,About measurability of operators,"I'm triyng without success, to find some examples of functions that: $\bullet$Are WOT-measurable, but not SOT-measurable. $\bullet$Are SOT-measurable, but not $||\cdot||$-measurable. I give the definitions I'm dealing with. We have: $X=\cal{L}$($E_1$,$E_2$) $f:\Omega\to X$$\;,\;\;$$(X,\Sigma,\mu)$ measure space. $\bullet\; ||\cdot||_{X}$-measurable: $\exists s_n:\Omega\to X$, simple, and $\exists A\in\Sigma,\;\mu(A)=0$, with $||s_n(w)-f(w)||_{X}\xrightarrow[n\to\infty]{}0\;\;\forall w\notin A.$ $\bullet\;$ SOT-measurable: $\forall e_1\in E_1$, the function $w\to f(w)(e_1)\;\;$ ($\Omega\to E_2$) is $||\cdot||_{E_2}$-measurable. $\bullet\;$ WOT-measurable: $\forall e_1\in E_1$, and $\forall e_2^{}*\in E_2^{*}$, the function $w\to <f(w)(e_1),e_2^{*}>\;\;$ ($\Omega\to \mathbb{K}$) is measurable (in the usual sense). Thanks a lot for any help finding those examples.","['operator-theory', 'functional-analysis', 'banach-spaces']"
570218,"If $n^c\in\mathbb N$ for every $n\in\mathbb N$, then $c$ is a non-negative integer?","Supposing that a real number $c$ is given, is the following true? ""If $n^c$ is a natural number for every natural number $n$, then $c$ is a non-negative integer."" Though this seems true, I can't prove that. Can anyone help?","['exponentiation', 'calculus', 'algebra-precalculus']"
570225,Why tan(1/z) has a non-isolated singularity at z=0?,Can someone please explain me this concept. Any sort of help will be highly appreciated.,"['trigonometry', 'sequences-and-series', 'complex-analysis']"
570281,What is the correspondence between structure constants and a Lie group?,"Let $T^a$ (with $a = 1,2,\ldots,n$) be a set of generators of a Lie group that satisfy the commutation relations:
\begin{equation}
[T^a,T^b] = i \sum_{c=1}^n f^{abc} T^c \,,
\end{equation}
where $f^{abc}$ are called the structure constants. Is there a one-to-one correspondence between the set of structure constants (up to an overall constant factor and the labelling) and the Lie group? If yes, then does somebody know of an overview somewhere on the web that gives you all the Lie groups and its structure constants? (I am, obviously, a beginner in this field.)","['lie-groups', 'lie-algebras', 'group-theory']"
570295,How find this integral $I=\int_{0}^{1}\sqrt{1-W^2(x)}dx$,"How find this nice integral $$I=\int_{0}^{1}\sqrt{1-W^2(x)}dx$$ where, $W(x)$ is Lambert W function My try: let $$\sqrt{1-W^2(x)}=u\Longrightarrow W(x)=\sqrt{1-u^2}$$ and since $x=W(x)e^{W(x)}$ so $$x=W^{-1}(\sqrt{1-u^2})=\sqrt{1-u^2}e^{\sqrt{1-u^2}}?$$
  so
  $$dx=-ue^{1-u^2}\dfrac{1+\sqrt{1-u^2}}{\sqrt{1-u^2}}du$$
  so
  $$I=\int_{1}^{a}-u^2e^{1-u^2}\dfrac{1+\sqrt{1-u^2}}{\sqrt{1-u^2}}du$$ where $a$ such $$\sqrt{1-a^2}e^{\sqrt{1-a^2}}=1(a>0)$$ then I can't,Thank you very much .","['definite-integrals', 'integration', 'lambert-w']"
570311,A question in Mumford Redbook P91,"Suppose $K_0$ is a field isomorphic to the function field of prevariety$X,Y$. Choose $k-$isomorphism $\alpha:K(X)\to K_0; \beta: K(Y)\to K_0$, we get $A: \operatorname{Spec} K_0\to X, B:\operatorname {Spec}K_0 \to Y$, so we get $(A,B): \operatorname{Spec}K_0\to X\times_kY$, the image of the closed point is $t$. Take its closure we get irreducible subprevariety $T=\bar{\{t\}}$ . How do we show the function field $K(T)$ of $T$ is isomorphic to $K_0$ via $(A,B)^*$ ? Consider the simple case where $X=\operatorname{Spec}k[S],Y=\operatorname{Spec}k[T], K_0=K(U)$, (the rational function field of one variable)$\alpha: S\to U, \beta: T\to  \frac{1}{U}$, then which point in $\mathbb{A}^2$ is mapped to? is it the generic point of curve $ST=1$? How to make this clear? (It is in Mumford's redbook II.3 P91 )",['algebraic-geometry']
570333,Area of a rhombus,"$ABCD$ is a rhombus. We are given the the circumradius of triangles $ABD$ and $ACD$. So how do we compute the area and the side and area of the rhombus? I have tried some properties of the circumcenter, but have failed. If there was a geometric solution, I would like to prefer it.","['geometry', 'triangles']"
570340,What is known about the quotient group $\mathbb{R} / \mathbb{Q}$?,Let $G = \mathbb{R} / \mathbb{Q}$. Is this an interesting group to study? Is it isomorphic to any more natural mathematical objects?,"['reference-request', 'group-theory']"
570348,Why is expectation defined by $\int xf(x)dx$?,"I recently found out that the expectation of a random variable $X$ in a probability space $(\Omega, \mathcal F,  \mathbb P)$, $\mathbb E(X)$, is just the term used in probability theory for the measure of the function $X$; i.e.: $$
\mathbb E(X)=\mathbb P(X)
$$ or, for a real-valued random variable $X:\Omega\to\mathbb R$: $$
\mathbb E(X)=\int_\Omega X(x)\mathbb P(dx)
$$ The thing is, I am also familiar with the definition of the expectation of a random variable $X:\Omega\to\mathbb R$ with probability distribution function $f$ to be: $$
\mathbb E (X)=\int_\mathbb R xf(x)dx
$$ Here, the integral is with respect to the Lebesgue measure on $\mathbb R$. We can define the function $f$ in the following way: we have $F(x)=\int_\mathbb R f(x)dx$, where $F(x)=\mathbb P(X^{-1}((-\infty,x]))$. I can't see any way to show that these two definitions are equal to one another.  The only transformation between integrals with respect to different measures that I know is that $\mu(f^{-1}(g))=\mu(g\circ f)$, which gives that $\mathbb E(g)=\mu_X(g)$, where $\mu_X$ is the image measure $\mathbb P\circ X^{-1}$, but that doesn't seem to help. Why can we write $\mathbb E(X)=\int_\mathbb R xf(x)dx$?  Why are these two definitions consistent?","['probability-theory', 'lebesgue-integral', 'measure-theory']"
570384,Number of possible combination of all subsequences of two strings,"Suppose, two strings $A$ and $B$ of length $x$ and $y$ are given. Now, I have to find out number of possible combination of sub-sequences of these two strings. For example, let A=""abc""; clearly the set of sub-sequences of A is {"""" , ""a"" , ""b"" , ""c"", ""ab"", ""bc"", ""ac"", ""abc"" }. For any string $x$ with length $y$ will have $2^x$ sub-sequences. Now if we assume ""abc"" and ""de"" are two $sub-sequences$ and we combine them then we get, ""abcde"", ""abdce"", ""abdec"", ""adbce"", ""adbec"", ""adebc"", ""dabce"", ""dabec"", ""daebc"" and ""deabc"". So, combining two sub-sequences means a string which contains all the characters of two strings and both are sub-sequences of these combinations. Now, how to find out number of possible combinations of all sub-sequences of $A$ and $B$.","['discrete-mathematics', 'combinatorics']"
570391,$f(x)=\sin x^3$ for $x\in \mathbb{R}$ is not uniformly continuous,"Question is to prove that : $f(x)=\sin x^3$ for $x\in \mathbb{R}$ is not uniformly continuous. What would my first observation in checking uniform continuity is to check if its derivative is bounded. In this case its derivative $f'(x)=3x^2\sin x^3$ which is unbounded. So, I can not rely on this. I tried with definition : $|f(x)-f(y)|=|\sin x^3-\sin y^3|=|2\cos (\frac{x^3+y^3}{2})\sin (\frac{x^3-y^3}{2})|\leq 2 |\sin (\frac{x^3-y^3}{2})|$ I see that $\sin x \leq  x$.. This may not imply $|\sin x|\leq |x|$ but  i am assuming it... So, $|f(x)-f(y)|\leq 2 |\sin (\frac{x^3-y^3}{2})|\leq 2\frac{|x^3-y^3|}{2}=|x^3-y^3|=|x-y||x^2+xy+y^2|$. Though $|x-y|$ is small i should make $|f(x)-f(y)|$ considerably large. I now have $|f(x)-f(y)|\leq 2 |x-y||x^2+xy+y^2|$ I some how can sense that I can make $|x^2+xy+y^2|$ large enough though $|x-y|$ is small but not so sure how to make this in $\epsilon-\delta$ case. Please help me to solve this. Thank you. EDIT : I know that uniform continuous functions takes cauchy sequence to cauchy sequence and tried to use it in this case. But, I could not find correct cauchy sequence that would help me to go through this. I would be thankful if some one can help me in this way too.","['real-analysis', 'uniform-continuity']"
570425,Differentiating inside a conditional expectation,"Let $X$ and $Y$ be random variables, and let $f(x,y)$ and $g(x,y) = \frac{ \partial f }{ \partial x} (x,y)$ be functions. Suppose that $\mathbb{E} \left( g(X,Y) \mid X \right) \leq 0$. Can we say (either in general, or under fairly mild conditions) that $\mathbb{E} \left( f(X,Y) \mid X = x \right)$ is weakly decreasing in $x$?","['probability-theory', 'probability', 'conditional-probability']"
570484,Proving the derivative is $0$ at the extremum and all derivatives are $0$.,"The pictures below show the proof that Apostol uses in his book. I can't understand why Apostol introduces the function $Q(x)$ and proves the theorem by contradiction using the sign preserving property. What we want to prove:$$\lim_{h\to 0}\frac{f(c+h)-f(c)}h=0$$ The way I proved it was: Since $f'(c)$ exists, this means that the function $f$ is continuous at point $c$. Using the definition of continuity at a point $c$ this means that $$\lim_{x\to c}f(x)=f(c)$$ Let $x=c+h$ so the above limit becomes $$\lim_{c+h \to c} f(c+h)=f(c)$$ which is equivalent to $$\lim_{h \to 0} f(c+h)-f(c)=0$$  This is all assuming $c+h$ lies in open interval $I$. So since the above limit appoahes $0$ as $h$ approaches $0$ the limit to be proved is proved. $\square$ Is that right ??","['calculus', 'proof-verification', 'alternative-proof', 'derivatives', 'limits']"
570521,Set problem where $f=A\times B$,"The problem states: If there is function $f:A\to B$ and 
$$\left(f=A \times B \right) \iff \left( A= \varnothing \text{ or } |B| = 1\right)$$ (where $A \times B$ is the cartesian product and $|B|$ is the cardinality of $B$) So I must demonstrate that equivalence.
I've tried to slove it, but i can't wrap my head around what $f=A\times B$ means. Please help me!",['elementary-set-theory']
570542,"Formal power series, the Chain Rule and the Product Rule.","Definitons Let $$\mathbb{C}[[x]] := \left\{ \sum_{n\geq 0} a_n x^n : a_n \in \mathbb{C} \right\}$$ be the set of formal power series of $x$. Exercise i) If $F_1(x)$ and $F_2(x)$ are power series in $\mathbf{C}[[x]]$, and $F_3(x)=F_1(x)F_2(x)$ is their product, then their formal derivatives satisfy the usual 'derivative of the product' formula
$$
F_3'(x)=F_1(x)F_2'(x)+F_1'(x)F_2(x).
$$ I tried making a proof using just the substitution and product rules, but I can't seem to come to an answer. Thanks in advance.","['power-series', 'discrete-mathematics', 'abstract-algebra', 'combinatorics']"
570545,How can I prove this two identities? $\cos^2 x=\frac{1+\cos(2x)}{2}$ and $\sin^2 x=\frac{1-\cos(2x)}{2}$,"How can I simply prove the two following equations? $$\cos^2x=\frac{1+\cos(2x)}{2} \,\,\,\,\,\,\,\,\,\,\text{ and }\,\,\,\,\,\,\,\,\,\, \sin^2 x=\frac{1-\cos(2x)}{2}$$ I already proven them using two methods: $\cos^2x+\sin^2x=1$ $\text{The Pythagorean theorem:}\, \, \text{BC}^2=\text{AB}^2+\text{AC}^2$ So I'm looking for a proof that doesn't use those two methods. Thanks in advance.","['geometry', 'trigonometry', 'algebra-precalculus']"
570555,Image of koebe map,Let $f(z)=\frac {z}{(1-z)^2}$ how can I find the image of unit disk under this transformation? Also is it possible to find an explicit expression for the inverse of this transformation?,['complex-analysis']
570557,How to master integration and differentiation?,"We have learnt in school about differentiation and integration, however I find my knowledge fairly poor. I mean I have problems with taking the derivative/integral even simple functions. So I would like to get some links to articles and guides where I could learn the derivatives and primitive functions of elementary functions and also familiarize with basic techniques to evaluate these.","['calculus', 'integration', 'reference-request', 'soft-question', 'derivatives']"
570589,Proving that well ordering principle implies Zorn's Lemma.,"I am trying to prove that well ordering principle implies Zorn's Lemma. I think that I'm close but don't quite know to make the last step of my proof. Here is what I wrote so far: Given that on every set, a well ordering can be defined, we should prove that Given a partially ordered set $A$, if every increasing chain in $A$ has a maximal element, Then $A$ has a maximal element. Proof: Take $A$ partially ordered by $R$. 
We know that there exists a well ordering $S$ on $A$. Let $k$ be the smallest ordinal s.t. $k=|A|$ and let, $k^+=k+1$. Define by transfinite induction, a function, $g:k^+ \rightarrow A$ as follows: $g(0)$ is the first element in $A$ by $S$. For any , $\alpha < k^+$: If $\alpha$ is a successor ordinal, s.t. $\alpha = \beta + 1$, then, define $g(\alpha)$, the first element (by $S$), $a \in A$ such that $g(\beta) <_{R} a$ if $\alpha$ is a limit ordinal, then, The set $\{g(\beta);\beta<\alpha\}$, is linearly ordered by $R$. Therefor it has an upper bound. From all the uppers bounds, we will take the first (By $S$) to be $g(a)$. $g(k^{+})$ is linearly ordered. So, by the lemma assumption, it has an upper bound in $M \in A$. We claim that $M$ is a maximal element of $A$. Because, if there would be $x >_{R} M$ in $A$, by the construction of $g$, $g(k^{+})$ would contain an element which ia greater or equall (by $R$) to $x$, contradicting the fact that $M$ is an upper bound of $g(k^{+})$. The step which I'm not sure of is step 5. I am not sure weather the fact that $|k|=|A|$ and that $g(k^{+})$ is isomorphic to $k$ are enough.
What do you think? Thank you!
Shir","['elementary-set-theory', 'axiom-of-choice']"
570604,basis of vector space of real sequences over $\mathbb{R}$,"It turns out I cannot find a basis for the vector space of all functions from $\mathbb{N}$ to $\mathbb{R}$ (over $\mathbb{R}$). By Zorn's Lemma, there is a basis. So I guess it cannot be written out constructively? What is the dimension then? I am thinking $2^{\aleph_0}$. It cannot be countable. If it were, then by a bijection of basis, it will be isomorphic to the set of sequences with finitely non-zero entries. My intuition says it is absurd. How to prove this?","['set-theory', 'linear-algebra']"
570611,recurrence relation,It was some time ago I studied recurrence relations and I came across this one that I cannot solve: $a_{n+3}=-3a_{n+2}+4a_{n}$ with $a_{0}=2$ and $a_{1}=-5$ Ansatz: $a_{n}=r^{0}$ then I get $r^{3}+3r^{2}-4=0$ with roots $r=1$ and $r=-2$ of double multiplicity so the solution is $a_{n}=A+B(-2)^{n}+Cn(-2)^{n}$ is this correct? But I cannot find constants as I have 2 equations with 3 indeterminants...,"['recurrence-relations', 'discrete-mathematics']"
570613,Difference between span and basis,What is the difference between the span of the image of a matrix and the basis for the span of the image of a matrix? Are these the same thing?,"['matrices', 'linear-algebra']"
570635,The continuity of the expectation of a continuous stochastic procees,"Let $X_t$ be a continuous stochastic process on a filtered space $(\Omega, \mathcal F, \mathcal F_t, \mathbb P)$. Is $\mathbb E[X_t]$ necessarily a continuous function? My first answer would be no. For example if $X_t$ admits densities $f(t,x)$, the first  equality in: $$\lim_{t \rightarrow t_0} \int_{\mathbb R} x f(t, x) dx=\int_{\mathbb R} \lim_{t \rightarrow t_0} x f(t,x)=\int_{\mathbb R} x f(t_0,x) $$ requires $f$ to be continuous in $t$ uniformly in $x$ to hold. Examples where $\mathbb E[X_t]$ is indeed continuous are abundant. Counterexamples where it is not? Thanks.","['stochastic-processes', 'continuity', 'probability', 'expectation']"
570650,Holder continuity of Ito integral,"Let $\sigma(t,\omega)$ be a progressively measurable function and $\mathbb{E}[\int_0^T \sigma_t^2\mathrm dt] < \infty$. Can we say that the Ito process $\int_0^t \sigma_s \mathrm dW_s$ is Hölder continuous? Can you please provide proof of it. I was trying on the lines of Kolmogorov's continuity theorem, but I couldn't get correct bounds. For example, $$\mathbb{E}\left[\left(\int_0^t\sigma_u\mathrm dW_u - \int_0^s\sigma_u\mathrm dW_u\right)^2\right] = \mathbb{E}\left[\int_s^t\sigma_u^2 \mathrm du\right]$$ So we need to bound the integral on the right hand side by $|t-s|^{1+\alpha}$. However, I think this may not be possible for general $\sigma$. Can some one please provide simple sufficient conditions? On the larger context, I am actually interested to know if the Ito diffusions (solutions to SDE) are Holder continuous with exponents less than $1/2$.","['stochastic-processes', 'stochastic-analysis', 'stochastic-integrals', 'probability-theory', 'holder-spaces']"
570665,Evaluate the limit $\lim_{x\rightarrow 0} \frac{\sqrt{1-\sin(5x)}-\sqrt{1+\sin(5x)}}{x^2+x}$,Trying to find $$\lim_{x\rightarrow 0} \dfrac{\sqrt{1-\sin(5x)}-\sqrt{1+\sin(5x)}}{x^2+x}=\lim_{x\rightarrow 0} \dfrac{(1-\sin(5x))-(1+\sin(5x))}{(x^2+x)(\sqrt{1-\sin(5x)}+\sqrt{1+\sin(5x)})}=\lim_{x\rightarrow 0} \dfrac{-2\sin(5x)}{(x^2+x)(\sqrt{1-\sin(5x)}+\sqrt{1+\sin(5x)})}$$ How to solve it?,"['calculus', 'functions', 'limits']"
570695,Shape Operators and Symmetric Linear Transformations,"The exercise (from Sakai) is: Let $f: E\subseteq \mathbb{R}^{n-1} \rightarrow \mathbb{R}$ be smooth and let $M_f := \{p = (x, f(x)) \in \mathbb{R}^n\,;\,x \in E\}$ be the graph of $f$ considered as a hypersurface of $\mathbb{R}^n$. Then, if $Df(x) = 0$ at $x \in E, \partial_n$ is a unit normal vector to $M_f$ at $x$. The second fundamental form of $M_f$ at $x$ is given by $\langle S (\partial_i , \partial_j), \partial_n \rangle = \partial_i \partial_j f$. Using this fact, let $p$ be a point in a Riemannian manifold $M$, $u \in U_p M$, and $A$ a symmetric linear transformation of $u^{\perp} := \{v \in T_p M \,;\,\langle u, v \rangle = 0\}$. Show that there exists a hypersurface $N$ of $M$ around $p$ with unit normal $u$ at $p$ such that the shape operator $A_u$ is equal to the given $A$. My thought is to let $\text{dim}M=m$ and let $\tilde{M}$ be a submanifold of dimension $m-1$ containing $p$. Then there exists (I hope) $f \in C^{\infty}(\tilde{M})$ with $Df(p)=0$, so $N$ would be the graph of $f$ considered as a hypersurface. If that works, how do I go about showing that $A=A_u$? Is it sufficient to show that $\langle A_u v, w\rangle = \langle A(v,w),u \rangle = v_i v_j \frac{\partial^2 f}{\partial \xi^i \partial \xi^j}(p)$ for some $v,w \in u^{\perp}$ and coordinates $(\xi^i)$ of $M$? Many thanks in advance!","['riemannian-geometry', 'differential-geometry']"
570700,"If $|X_{n}| \leq Y$ almost surely, show that $\sup_{n}|X_{n}|\leq Y$ almost surely as well.","Suppose $|X_{n}|\leq Y$ a.s., each $n$, $n=1,2,3,\cdots$. Show that $\sup_{n}|X_{n}|\leq Y$ a.s. also. This seems pretty intuitive to me, since if $|X_{n}|\leq Y$ a.s., it is bounded above by $Y$, and the sup is the least of these upper bounds. But, somehow I feel like there is more to it than that (especially since this is a starred exercise in my textbook, indicating that it is more challenging than the others?) What exactly is the trick to showing this mathematically rigorously, thereby showing what the problem is actually asking me to show?","['probability-theory', 'convergence-divergence']"
570730,Finding inverse of a matrix,"This question is in my assignment. We are not allowed to use any symbol to represent any elementary row and column operations used in the solution. We must solve it step-by-step. Please help me to check my solution word by word including my spelling and grammar. Question: Find the inverse of $$A=\begin{pmatrix}2& 2& 3\\ 2& 5& 3\\ 1& 0& 8\end{pmatrix}$$ by using only elementary row operations. Solution: We begin by forming the matrix $\begin{pmatrix} A & | & I_3 \end{pmatrix}=\left(\begin{array}{ccc|ccc}2 & 2 & 3 & 1 & 0 & 0\\2 & 5 & 3 & 0 & 1 & 0\\1 & 0 & 8 & 0 & 0 & 1\end{array}\right)$. Interchanging the first and third rows of the matrix $\begin{pmatrix} A & | & I_3 \end{pmatrix}$, we obtain the matrix $\left(\begin{array}{ccc|ccc}1 & 0 & 8 & 0 & 0 & 1\\2 & 5 & 3 & 0 & 1 & 0\\2 & 2 & 3 & 1 & 0 & 0\end{array}\right)$. Adding $(-2)$ times the first row of the matrix $\left(\begin{array}{ccc|ccc}1 & 0 & 8 & 0 & 0 & 1\\2 & 5 & 3 & 0 & 1 & 0\\2 & 2 & 3 & 1 & 0 & 0\end{array}\right)$ to its second row, we obtain the matrix $\left(\begin{array}{ccc|ccc}1 & 0 & 8 & 0 & 0 & 1\\0 & 5 & -13 & 0 & 1 & -2\\2 & 2 & 3 & 1 & 0 & 0\end{array}\right)$. Multiplying the second row of the matrix $\left(\begin{array}{ccc|ccc}1 & 0 & 8 & 0 & 0 & 1\\0 & 5 & -13 & 0 & 1 & -2\\2 & 2 & 3 & 1 & 0 & 0\end{array}\right)$ by $\frac{1}{5}$, we obtain the matrix $\left(\begin{array}{ccc|ccc}1 & 0 & 8 & 0 & 0 & 1\\0 & 1 & -\frac{13}{5} & 0 & \frac{1}{5} & -\frac{2}{5}\\2 & 2 & 3 & 1 & 0 & 0\end{array}\right)$. Adding $(-2)$ times the first row of the matrix $\left(\begin{array}{ccc|ccc}1 & 0 & 8 & 0 & 0 & 1\\0 & 1 & -\frac{13}{5} & 0 & \frac{1}{5} & -\frac{2}{5}\\2 & 2 & 3 & 1 & 0 & 0\end{array}\right)$ to its third row, we obtain the matrix $\left(\begin{array}{ccc|ccc}1 & 0 & 8 & 0 & 0 & 1\\0 & 1 & -\frac{13}{5} & 0 & \frac{1}{5} & -\frac{2}{5}\\0 & 2 & -13 & 1 & 0 & -2\end{array}\right)$. Adding $(-2)$ times the second row of the matrix $\left(\begin{array}{ccc|ccc}1 & 0 & 8 & 0 & 0 & 1\\0 & 1 & -\frac{13}{5} & 0 & \frac{1}{5} & -\frac{2}{5}\\0 & 2 & -13 & 1 & 0 & -2\end{array}\right)$ to its third row, we obtain the matrix $\left(\begin{array}{ccc|ccc}1 & 0 & 8 & 0 & 0 & 1\\0 & 1 & -\frac{13}{5} & 0 & \frac{1}{5} & -\frac{2}{5}\\0 & 0 & -\frac{39}{5} & 1 & -\frac{2}{5} & -\frac{6}{5}\end{array}\right)$. Multiplying the third row of the matrix $\left(\begin{array}{ccc|ccc}1 & 0 & 8 & 0 & 0 & 1\\0 & 1 & -\frac{13}{5} & 0 & \frac{1}{5} & -\frac{2}{5}\\0 & 0 & -\frac{39}{5} & 1 & -\frac{2}{5} & -\frac{6}{5}\end{array}\right)$ by $(-\frac{5}{39})$, we obtain the matrix $\left(\begin{array}{ccc|ccc}1 & 0 & 8 & 0 & 0 & 1\\0 & 1 & -\frac{13}{5} & 0 & \frac{1}{5} & -\frac{2}{5}\\0 & 0 & 1 & -\frac{5}{39} & \frac{2}{39} & \frac{2}{13}\end{array}\right)$. Adding $(\frac{13}{5})$ times the third row of the matrix $\left(\begin{array}{ccc|ccc}1 & 0 & 8 & 0 & 0 & 1\\0 & 1 & -\frac{13}{5} & 0 & \frac{1}{5} & -\frac{2}{5}\\0 & 0 & 1 & -\frac{5}{39} & \frac{2}{39} & \frac{2}{13}\end{array}\right)$ to its second row, we obtain the matrix $\left(\begin{array}{ccc|ccc}1 & 0 & 8 & 0 & 0 & 1\\0 & 1 & 0 & -\frac{1}{3} & \frac{1}{3} & 0\\0 & 0 & 1 & -\frac{5}{39} & \frac{2}{39} & \frac{2}{13}\end{array}\right)$. Adding $(-8)$ times the third row of the matrix $\left(\begin{array}{ccc|ccc}1 & 0 & 8 & 0 & 0 & 1\\0 & 1 & 0 & -\frac{1}{3} & \frac{1}{3} & 0\\0 & 0 & 1 & -\frac{5}{39} & \frac{2}{39} & \frac{2}{13}\end{array}\right)$ to its first row, we obtain the matrix $\left(\begin{array}{ccc|ccc}1 & 0 & 0 & \frac{40}{39} & -\frac{16}{39} & -\frac{3}{13}\\0 & 1 & 0 & -\frac{1}{3} & \frac{1}{3} & 0\\0 & 0 & 1 & -\frac{5}{39} & \frac{2}{39} & \frac{2}{13}\end{array}\right)$. Thus, $A^{-1}=\begin{pmatrix}\frac{40}{39} & -\frac{16}{39} & -\frac{3}{13}\\ -\frac{1}{3} & \frac{1}{3} & 0\\ -\frac{5}{39} & \frac{2}{39} & \frac{2}{13}\end{pmatrix}$.","['matrices', 'linear-algebra', 'inverse']"
