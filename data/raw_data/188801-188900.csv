question_id,title,body,tags
3528700,Prove that there is exactly one identity relation $I_A$ for each set $A$,"Originally, to solve this question. I found the 2 relations and checked if they were the subset of each other to prove that they were the same thing. But the question had a hint which stated, ""As a hint, you can write a rigorous proof of this result without referencing what it means for one relation to be a subset of another. Look at the definition of an identity relation, which gives a series of equalities involving an identity relation. Can you make use of those equalities here?"" I came up with a proof but that used equalities but i'm not really sure if i've done it right. I was wondering if someone can check the proof and critique it. Also if you have another way of proving, that would be very helpful too. My proof: Let's assume $A$ is an arbitrary set. We will prove that $A$ has exactly one identity relation. Let $I_1, I_2$ be identity relations where for every $x$ and every $y$ , $x=y$ and $(x,y) \in$ $A$ x $A$ . To show $I_1 = I_2$ , we can say that if every $x$ and $y$ in $A$ x $A$ such that $x = y$ then $(x,y) \in I_1 = (x,y) \in I_2$ . Therefore we can conclude that there is only one identity relation for each set A. $\blacksquare$","['alternative-proof', 'relations', 'solution-verification', 'discrete-mathematics']"
3528736,Why is $LU$ preferred over $A^{-1}$ to solve matrix equations?,"I understand the whole $LU$ -decomposition vs Gaussian elimination argument. The fact that you can isolate the computationally expensive elimination step and re-use the $L$ and $U$ matrices for $Ax=b$ style equations with different $b$ :s makes sense to me. But I can't seem to find a reason for why the $L$ and $U$ matrices are preferred over an $A^{-1}$ matrix. It can also be used for for multiple $b$ :s. So that's my question, why is $LU$ preferred?","['matrices', 'lu-decomposition', 'linear-algebra', 'numerical-linear-algebra', 'matrix-decomposition']"
3528853,Resolution of the projection map $\text{proj}_P:\mathbb{P}^2\dashrightarrow\mathbb{P}^1$,"If $P=(0:0:1)\in\mathbb{P}_{\mathbb{C}}^2$ , we define the projection from $P$ as the rational map: \begin{align*}
\text{proj}_P:\mathbb{P}^2&\dashrightarrow\mathbb{P}^1\\
(x:y:z)&\mapsto(x:y)
\end{align*} which obviously is not defined in $P$ itself. I heard a speaker say in a lecture that ""blowing up $\mathbb{P}^2$ at $P$ is enough to resolve the indetermination at $P$ "" but I can't see why. I imagine he means the following: if $\pi:X\to\mathbb{P}^2$ is the blow-up of $\mathbb{P}^2$ at $P$ , then the rational map $p:=\text{proj}_P\circ\pi$ is actually a morphism. Here's my attempt to prove it. Let $((x:y:z),(s:t))$ be the coordinates of $\mathbb{P}^2\times\mathbb{P}^1$ and consider the open sets $U,V\subset \mathbb{P}^2\times\mathbb{P}^1$ determined by: \begin{align*}
U:=\{z\neq 0,\, s\neq 0\}\\
V:=\{z\neq 0,\, t\neq 0\}
\end{align*} That way, $X$ is defined by $\{y=tx\}$ in $U$ and by $\{x=sy\}$ in $V$ . Now we may write: \begin{align*}
p|_U:U &\to\mathbb{P}^2 \dashrightarrow\mathbb{P}^1\\
(x,t)&\mapsto (x:tx:1) \mapsto (x:tx)\\ \\
p|_V:V &\to\mathbb{P}^2 \dashrightarrow\mathbb{P}^1\\
(y,s)&\mapsto (sy:y:1) \mapsto (sy:y)
\end{align*} That way $p|_U$ is not determined at $x=0$ and $p|_V$ is not determined at $y=0$ . Doesn't that mean that $p$ is indetermined at every point in $\pi^{-1}(P)$ ? What am I missing?","['algebraic-geometry', 'projective-geometry', 'birational-geometry']"
3528890,Proving the range of a function involving absolute signs (using the double set inclusion technique),"I have been trying to prove that the range of the function $f: \mathbb{R} \to \mathbb{R} $ given by $f(x)=\frac{|x+3|}{|x|+3}$ is the interval $[0,1]$ for some time now without success. I'm aware that in order to formulate a proof, I need to show that $f(\mathbb{R}) \subseteq [0,1]$ , and $[0,1] \subseteq f(\mathbb{R})$ to show that $f(\mathbb{R})$ is indeed equal to $[0,1]$ , however, I'm not sure how to continue from this point onward. So, I have come up with rough work first, which is as follows: ROUGH WORK FOR ( $f(\mathbb{R}) \subseteq [0,1]$ ) We know that $0 \leq \frac{|x+3|}{|x|+3} \leq 1$ . Hence, by doing some re-arragements, we can show that $0 \leq |x+3| \leq |x| + 3$ (since $|x| + 3 \ge 3$ , we could multiply both sides). After multiplying, we basically get the triangle inequality, which has to always be true. Thus, this proves the first inclusion ( $f(\mathbb{R}) \subseteq [0,1]$ ). ROUGH WORK FOR ( $[0,1] \subseteq f(\mathbb{R})$ ) Now, to show the other inclusion $[0,1] \subseteq f(\mathbb{R})$ , I'm not sure how to continue! I have tried using cases $x \ge 0$ and $x \leq 0$ , but that didn't really help. More specifically, I tried showing that if $x \ge 0$ , then $x = \frac{3(1-y)}{y-1}$ which always produces an $x$ in the image, however, since $y \in [0,1]$ , we might get a division by zero. So, I'm not sure what can be done instead. I am quite new to proofs, so any help would be immensely appreciated!","['algebra-precalculus', 'functions', 'proof-writing']"
3528895,Proving $V_{k}(M)=\dfrac{1}{k} \int_{\partial M} \Phi$,"If $M$ is a piece-with-boundary of a k-manifold in $\mathbb{R}^{n}$ where $n\geq k$ . I want to show that the k-volume $V_{k}(M)$ of $M$ is given by $$V_{k}(M)=\dfrac{1}{k} \int_{\partial M} \Phi$$ The first step from the solution manual of the textbook ""Calculus: A Complete Course by Robert A. Adams, 8th Edition"": \begin{aligned}
\Phi &=\sum_{i=1}^{k}(-1)^{i-1} x_{i} d x_{1} \wedge \cdots \wedge \widehat{d x_{i}} \wedge \cdots \wedge d x_{k} \\
d \Phi &=\sum_{i=1}^{k}(-1)^{i-1} d x_{i} \wedge d x_{1} \wedge \cdots \wedge \widehat{d x_{i}} \wedge \cdots \wedge d x_{k} \\
&=\sum_{i=1}^{k} d x_{1} \wedge \cdots \wedge d x_{k}=k d x_{1} \wedge \cdots \wedge d x_{k}
\end{aligned} can someone explain to me where did the term $(-1)^{i-1}$ and $dx_{i}$ in the third line went? And where did the term $k$ come form? I just need to figure out this step.. I can go from there and do the proof.",['differential-geometry']
3528904,Dependency for coin toss,"Hello I have a question regarding dependency. If a fair coin is tossed 6 times, and there is two events: A-there are more heads than tails given that B-the 6th toss is a head. We are trying to find the conditional probability. However, I am confused as to whether these events are independent or dependent. I believe they are dependent because if B is true, then there needs to be at least 3 heads in the first 5 tosses. In other words, the minimum heads in the first 5 depend on whether B is true or not. Is this correct logic?","['statistics', 'independence', 'probability']"
3528960,Finding the number of functions that map two specific elements,"Let's say I have two different sets, set $A$ and set $B$ , where $|A|$ $\geq$ $|B|$ . I am having a problem where one of my exercises is asking me, to sum up the question without totally just asking for answers on my exercises, find the number of functions that $\textbf{DON'T}$ map two specific elements between the sets. We are going from $A$ to $B$ . Where I am at right now, is that I think we are supposed to subtract the number of functions that do map the two elements from $|A|^{|B|}$ , or am I just totally wrong with saying that? I am just confused on how do I find that number of functions I guess?","['inclusion-exclusion', 'functions', 'discrete-mathematics']"
3529004,Exercise 4.3.12 in Understand analysis,"Let $F \subset R$ be a nonempty closed set and define $g(x) = \inf \{ | x - a | : a \in F \}$ . Show that g is continuous on $R$ . I follow a solution, and this is its approach to prove the statement. First, it proves $\forall x \in R$ , there exists a number $a_x \in F$ st, $g(x) = | x - a_x |$ , and uses the result to state that for a constant $x_0$ and its corresponding $a_0$ , $$ | g(x) - g(x_0) | = \inf \{| |x - a| - |x_0 - a_0| | : \forall a \in F \} \space (1) $$ By triangle inequality, it is straightforward to prove, $$|| x - a | - |x_0 - a_0|| \le |x - x_0 | + |a - a_0|$$ The rest of the proof is obvious following definition of continuity. I got stuck in the equation (1), though I obtained the equation, $$ | g(x) - g(x_0) | = |inf \{ | x - a | : a \in F\} - |x_0 - a_0| |$$ How to prove (1)? I also appreciate if you provide any other solution.",['analysis']
3529050,Equivalence of different definitions of sup in expectations,"So the context of my question comes from the proof of Theorem 7.3.1(Norms of Gaussian random matrices) from High Dimensional Probability by Vershynin. In particular assume $A$ is an $m$ by $n$ matrices with independent $\mathcal{N}(0,1)$ entries. Define $T=\mathbb{S}^{n-1}\times \mathbb{S}^{m-1}$ . Let $X_{uv}=\langle Au,  v\rangle$ where $u\in\mathbb{S}^{n-1}$ and $v\in \mathbb{S}^{m-1}$ . We know that the operator norm of $A$ is equivalently defined as $||A|| = \sup_{(u,v)\in T} X_{uv}$ . Now the book claims the following equivalence. $$E||A|| = \sup_{S\subset T} E \left(\sup_{(u,v)\in S} X_{uv}\right)$$ where the outer $sup$ is over all finite subsets $S$ of $T$ . I do not see why this is true at all. Could someone please explain? More generally, my concern is when it is true for a random process $X_t$ that $$E \sup_{t\in T} X_t= \sup_{S\subset T} E\left( \sup_{t\in S} X_t\right)$$ where again the outer $sup$ is over finite subsets $S$ of $T$ . I ask this because this is how Vershynin defines these expectations in the book by taking the sup over finite subsets to avoid measurability issues. I was wondering what merits these definitions because it seems to be commonplace in a lot of introductory high dimensional statistics/probability books.","['statistics', 'probability-theory', 'probability', 'real-analysis']"
3529092,Projection between graphs extends to a covering space,"This is exercise 1.A.10 on page 87 of Hatcher's book Algebraic topology . Let $X$ be the wedge sum of $n$ circles, with its natural graph structure, and let $\tilde X \to X$ be a covering space with $Y \subset \tilde X$ a finite connected subgraph. Show there is a finite graph $Z ⊃ Y$ having the same vertices as $Y$ , such that the projection $Y→X$ extends to a covering space $Z→X$ . Question: How can we obtain graph $Z$ by adding edges from the given finite graph $Y$ ? This turned out to be Marshall Hall's Theorem in Stallings' article Topology of finite graphs . But I need more explanations. For example, an answer says for the case where $X=S^1 \vee S^1$ , $\tilde X$ is the universal covering space, and $Y=B(1,n)$ , i.e. the ball of radius $n$ and centered at $1$ in the graph $\tilde X$ , the covering space $Z \to X$ extending projection $Y \to X$ is just $B(1,n)$ with additional edges between vertices of the sphere $S(1,n)$ . Could someone give an explanation for this? Edit 1: This can be used to prove the residual finiteness of finitely generated free group, which states: If $F$ is a finitely generated free group and $x \in F$ is not the identity element, then there's normal subgroup $H \subset F$ of finite index s.t. $x \not \in F$ , hence $x$ has nontrivial image in a finite quotient group of $F$ . Edit 2: This can be used to prove this: Let $F$ be a finitely generated free group and $H$ be a finitely generated subgroup of $F$ . Let $x∈F−H$ . Then there is a finite index subgroup $K$ of $F$ such that $H⊆K$ and $x∉K$ .","['graph-theory', 'group-theory', 'covering-spaces', 'general-topology', 'algebraic-topology']"
3529112,Simplification of polynomials arising from snub hyperbolic tilings,"Lately I've been generating SVG files of uniform hyperbolic tilings in the Poincaré disc model (PDM). The results are usually very pretty. To generate snub tilings $sr\{p,q\}$ , like $sr\{7,3\}$ above, I need to compute the circumradius of the central polygon (in red above) as seen in the PDM . I do not want to derive this constant numerically, but rather as the root of a polynomial, which is possible because I am not using hyperbolic distances. I have found that, for general $p,q$ with $\frac1p+\frac1q<\frac12$ , the circumradius of the central $p$ -gon is $\frac{\sqrt x-\sqrt{x-4}}2$ where $x$ is the largest real root of the quartic polynomial $$(a-b)^2x^4\\
+8(a-b)(2a^2-2ab-a+2b)x^3\\
+8(12a^4-18a^3b-11a^3+12a^2b^2+29a^2b+2a^2-24ab^2-12ab+12b^2)x^2\\
+32(8a^5-2a^4b-10a^4+8a^3b^2+8a^3b+3a^3-24a^2b^2-10a^2b+24ab^2+4ab-8b^2)x\\
+16(4a^3+4a^2b-3a^2-8ab+4b)^2$$ and $a=\sin^2\frac\pi p$ and $b=\cos^2\frac\pi q$ . A Python implementation can be found here . My question lies in simplifying the coefficients of this polynomial, themselves polynomials in $a$ and $b$ , so to minimise the operation count (and hence time and potential rounding error too) à la this question . The $x^4$ , $x^3$ and constant coefficients look simplified enough; I'm most concerned about the $x^2$ and $x$ coefficients. I've been perturbing up to three monomials at once in hopes of getting a neat factorisation of the perturbed polynomial, and this is the best I've got so far: $$8(12a^4+a^3-ab-(3ab+2a-3b)(6a^2-4ab-a+4b))x^2$$ $$32(a^3(4a-3)(2a-1)-2b(a-1)^2(a^2-4ab-2a+4b))x$$ But can I do better than this? Can I reduce the complexity further? Is it possible to leverage intermediate results for the other coefficients in reducing the complexity?","['hyperbolic-geometry', 'polynomials', 'geometry']"
3529162,Third order nonlinear ODE,"I am looking to solve the following third order nonlinear ODE: $$\frac{\textrm{d}^{3}y}{\textrm{d}x^{3}}+\biggl(\frac{\textrm{d}y}{\textrm{d}x}\biggr)^{2}-y\frac{\textrm{d}^{2}y}{\textrm{d}x^{2}}=0,$$ subject to $$y(x=0)=0,\qquad\frac{\textrm{d}y}{\textrm{d}x}(x=0)=-1,\qquad\frac{\textrm{d}y}{\textrm{d}x}(x\to\infty)\to0.$$ From inspection I can see that the solution is $y(x)=e^{-x}-1$ . However, I would like to be able to derive this solution for myself. I've made a couple of attempts that so far have proved unsuccessful. For example, if I set $z=\textrm{d}y/\textrm{d}x$ then \begin{align*}
\frac{\textrm{d}^{2}y}{\textrm{d}x^{2}}&=z\frac{\textrm{d}z}{\textrm{d}y},
\\
\frac{\textrm{d}^{3}y}{\textrm{d}x^{3}}&=z\biggl(\frac{\textrm{d}z}{\textrm{d}y}\biggr)^{2}+z^{2}\frac{\textrm{d}^{2}z}{\textrm{d}y^{2}}.
\end{align*} So that $$z\biggl(\frac{\textrm{d}z}{\textrm{d}y}\biggr)^{2}+z^{2}\frac{\textrm{d}^{2}z}{\textrm{d}y^{2}}+z^{2}-yz\frac{\textrm{d}z}{\textrm{d}y}=0.$$ The above could be rewritten like so $$\frac{\textrm{d}}{\textrm{d}y}\biggl(z\frac{\textrm{d}z}{\textrm{d}y}\biggr)+z-y\frac{\textrm{d}z}{\textrm{d}y}=0,$$ which is equivalent to $$\frac{\textrm{d}}{\textrm{d}y}\biggl(z\frac{\textrm{d}z}{\textrm{d}y}\biggr)+z^{2}\frac{\textrm{d}}{\textrm{d}y}\biggl(\frac{y}{z}\biggr)=0.$$ Any suggestions as to where to go from here or am I barking up the wrong tree? Thanks","['integration', 'calculus', 'ordinary-differential-equations']"
3529212,Manifolds which are not realized with the regular value theorem,"Are there smooth/holomorphic manifolds which cannot be defined using the regular value theorem? That is, they are not the preimage of a regular value?","['manifolds', 'complex-manifolds', 'complex-geometry', 'differential-geometry']"
3529219,"Find a counterexample: For every antiprime $n>1$, there is a prime divisor $p$ such that $n/p$ is an antiprime","When dinosaurs ruled the earth, one of my assignments in a Problem Seminar in undergraduate was to devise and prove a conjecture about antiprimes, and this was my attempt: An antiprime (also called a highly composite number ) is a positive integer that has more divisors than any number less than it. The first few antiprimes are $$1, 2, 4, 6, 12, 24, 36, 48, 60, 120, 180, 240, 360,...$$ Conjecture : For every antiprime $n>1$ , there is a prime $p$ such that $p\mid n$ and $n/p$ is an antiprime. Anyways, I never found a proof for that, and about ten years ago I asked the xkcd math forums if they could guide me.  Instead, someone posted a counterexample that was quite enormous. A question on MESE is asking about relatively elementary mathematical conjectures whose smallest counterexamples are large numbers.  I'd like to suggest my problem, but the xkcd forums went down five months ago over a data breach and my thread wasn't cached by Google or the Wayback Machine. Can someone find that counterexample?  The person who posted didn't indicate if they came up with their number through mathematical reasoning or programming.  I discovered this morning that OEIS has a list of the first ten thousand antiprimes , so in theory it may just come down to finding the prime decomposition of each of them.  But, if possible, is there a mathematical argument that would lead one to the correct number?","['number-theory', 'examples-counterexamples', 'divisibility', 'elementary-number-theory']"
3529234,Probability of a number to appear once after every number appear once in rolling die,"A die is rolled until every number appears at least once. What is the probability that the number 1 only appears once? I think the problem is related to the Coupon collector's problem, but I cannot think of a good way to solve this problem. Edit: I have used simulation to find that the probability is around 0.4081. I have tried methods such as dividing the case with 1 appears in the last roll, and the case 1 appears not in the last roll, but the computation is too complicated.","['dice', 'coupon-collector', 'probability']"
3529302,Number of non-isomorphic simple graphs whose degrees of all vertices is less than or equal to $2$,"I an looking at the number of non-isomorphic simple graphs $(V,E)$ such that $|V|=n$ and $\forall v \in V, d(v)\le 2$ Specifically, I am asked to find this number for $n =8$ and $n = 9$ . But wonder if there is a nice recursive formula. Attempt:
I let $d_n$ denote this number. By trying out a few examples, I see $d_1=1, d_2=2, d_3=4, d_4=7, d_5=11$ . My graphs are essentially made up of cycles, chains (sticks) and isolated points. I also tried looking at consecutive $n$ 's but to no success.","['graph-theory', 'combinatorics', 'discrete-mathematics']"
3529359,Weak lower semicontinuity of functional with two arguments,"Let $\Omega$ be a bounded and smooth domain and let $J:H^1(\Omega) \times H^1_0(\Omega) \to \mathbb{R}$ be defined by $$J(u,v) = \int_\Omega f(u)|\nabla v|^2$$ where $f\colon \mathbb{R} \to \mathbb{R}$ is a smooth function, bounded above and below away from zero (other assumptions can be added as necessary). Under what conditions on $f$ do I get that $J$ is weakly lower semicontinuous? Obviously if $f \equiv 1$ then it is true, but what about the more genera case?","['continuity', 'sobolev-spaces', 'functional-analysis', 'semicontinuous-functions']"
3529460,Wrong counterexamples with 2nd derivative test,"Today we learned the 2nd Derivative Test of two-variable functions for testing local minimum/maximum points, and saddle points. We have deduced the law by calculating $$D^2_{\mathbf{v}} f=D_{\mathbf{V}} \left(\nabla f  \cdot \mathbf{v}  \right) = \mathbf{v}^{T} H \mathbf{v},$$ where $H$ is the Hessian matrix $\left[\begin
{matrix}f_{xx} & f_{xy} \\ f_{yx} & f_{yy} \end{matrix}\right].$ However, we discovered that by letting $\mathbf{v}=\left<a,b\right>$ where $||\mathbf{v}||=1$ , $$D_{\mathbf{v}}^2 f= f_{xx}a^2+2f_{xy}ab+f_{yy}b^2,$$ hence if $f_{xx}$ and $f_{yy}$ are both nonzero, then $D_{\mathbf{v}}^2 f$ changes its sign at most two times while $\mathbf{v}$ rotates clockwise on the unit circle. 
We thought that this result was absurd, so we tried to construct a counterexample of it. This is what we got: if a function $z=f(x,y)$ is twice differentiable and satisfies $f(t,0)=-At^2, f(0, t)=-Bt^2, f(t, t)=Ct^2, f(t, -t)=Dt^2$ for some $A,B,C,D>0$ and for all sufficiently small $t$ , then $f_{xx}$ and $f_{yy}$ are both nonzero, but the sign of $D_{\mathbf{v}}^2 f$ changes four times as $\mathbf{v}$ rotates once. Comparing with the previous argument, it seems like such function does not exist, but we couldn't prove it. We do not know which is true too. Please help us.","['partial-derivative', 'multivariable-calculus', 'calculus', 'derivatives']"
3529580,Tangent space of Deligne-Lusztig variety,"Let $V$ be a vector space over $\mathbb{F}_p$ equipped with a symplectic form, which means that the dimension of $V$ equals $2m$ . Consider the (proper smooth) variety $LG \subset GR(n,V)$ parametrising maximal isotropic subspaces $W \subset V$ . I am interested in the following (closed) Deligne-Lusztig variety (where $()^p$ means Frobenius twist) \begin{align}
S_V:=\{W \subset V \; | \; \operatorname{Dim} (W \cap W^{(p)}) \ge m-1 \},
\end{align} see for example (5.3) of https://arxiv.org/pdf/1301.1226.pdf and would like to compute its deformation theory. I know that this variety is irreducible and has dimension $m$ and moreover that it is smooth away from its $\mathbb{F}_p$ rational points. But I would like a canonical description of the tangent bundle over the smooth locus. Standard deformation theory arguments will tells us that the tangent space of $GR(n,V)$ (the Grassmannian of $n$ -dimensional subspaces $W$ of $V$ ) at a point $(W) \in GR(n,V)(k)$ is canonically isomorphism to $Hom(W, V/W)$ . Now if $W$ in fact lies in the Lagrangian Grassmannian $LG$ then we get a canonical isomorphism $V/W \simeq V^{\ast}$ using the symplectic pairing and moreover \begin{align}
Hom(W, V/W) \simeq Hom(W, W^{\ast}) \simeq W^{\ast} \otimes W^{\ast}.
\end{align} One can show that the tangent space of $LG$ at $W$ is then given by $\operatorname{Sym}^2 W^{\ast} \subset W^{\ast} \otimes W^{\ast}$ . Question : Is there a similar description of the tangent bundle of $S_V$ over the smooth locus? If $W_0=W \cap W^{(p)}$ then the bundle $\hom(W/W_0, W)$ seems like a good candidate, but I haven't been able to prove this. Bonus Question: If we blow up $S_V$ in its $\mathbb{F}_p$ rational points, is the resulting variety smooth?","['algebraic-geometry', 'deformation-theory']"
3529602,Necessary & sufficient conditions on the parameters in a recursive sequence,"For $a,b\in\mathbb R$ the sequence $(x_n)_{n\in\mathbb N}$ is defined
  recursively: $$x_1:=b,\;\;x_{n+1}=x_n^2+(1-2a)x_n+a^2$$ What is the
  necessary condition on $a,b$ and what the sufficient condition for the
  sequence to converge? Then evaluate $\displaystyle\lim_{n\to\infty}x_n$ . My attempt: As far as I'm concerned, I'm required to prove the sequence $(x_n)_{n\in\mathbb N}$ is a Cauchy sequence ,i.e., the elements become arbitrarily close to each other as the sequence
  progresses. $$f(x):=x_n$$ Since the sequence can be represented by a parabola, I chose the vertex as the candidate for the limit $L\in\mathbb R$ , and therefore: $$\forall x_n\in [L, b]$$ or more precisely by the definition, $$(\forall\varepsilon>0)(\exists n_{\varepsilon}\in\mathbb N)(\forall n\in\mathbb N)((n>n_{\varepsilon})\implies(|x_n-L|<\varepsilon))$$ $$\forall x_n\in[L,b]\;x_n\in\mathcal R_f$$ Using the usual method (and the fact the limit is a fixed point of $f$ ): $$L=L^2-(1-2a)+a^2\iff (L-a)^2=0\implies L=a$$ $$b\in\Gamma_f\implies b\geq 0$$ But, I don't know the answer what the necessary and what the sufficient condition on the parameters $a,b$ is. May I ask for advice on how to end the problem and correction for possible mistakes?","['calculus', 'proof-writing', 'sequences-and-series', 'real-analysis']"
3529608,Measurability with respect to equivalent sub-$\sigma$-algebras for mappings into countably generated spaces,"Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space, and let $\mathcal{G}_1$ and $\mathcal{G}_2$ be sub- $\sigma$ -algebras of $\mathcal{F}$ that are equivalent to each other in the sense that $$ \sigma(\mathcal{G}_1 \cup \{\mathbb{P}\textrm{-null sets}\}) \ = \ \sigma(\mathcal{G}_2 \cup \{\mathbb{P}\textrm{-null sets}\}). $$ Let $(X,\Sigma)$ be a countably generated measurable space. Given a $(\mathcal{G}_1,\Sigma)$ -measurable function $g_1 \colon \Omega \to X$ , does there necessarily exist a $(\mathcal{G}_2,\Sigma)$ -measurable function $g_2 \colon \Omega \to X$ such that $\,g_1 \! \overset{\mathbb{P}\textrm{-a.s.}}{=} \! g_2\,$ ? (I know that the answer is yes if $(X,\Sigma)$ is a standard Borel space, since if we regard $X$ as a Borel subset of $\mathbb{R}$ , then taking $g_2$ to be a suitable version of $\mathbb{E}[g_1|\mathcal{G}_2]$ gives the result. But I am curious about the more general scenario that $(X,\Sigma)$ is a countably generated measurable space.)","['measure-theory', 'probability-theory']"
3529628,Cohomology of $G$-invariant differential forms,"Let $G$ be a Lie group with a left action on a manifold $M$ , $\cdot : G \times M \to M$ . Define a $G$ -invariant differential form $\alpha \in \Omega^{k}(M)$ as a form satisfying $g^{*}\alpha = \alpha,$ where $g:M \to M$ is the action by $g \in G$ . Since pullbacks commute with differentials, the set of all $G$ -invariant forms (which I will denote by $\Omega(M)^G$ ) is a subcomplex of $\Omega(M)$ . I found the following theorem in several places: Theorem: If $G$ is compact and connected, then the inclusion $i: \Omega(M)^{G} \to \Omega(M)$ is induces an isomorphism in de Rham cohomology. One of the places where I found this is https://planetmath.org/invariantdifferentialform . However, there is no proof there, and I would like to find a proof. Does anyone know a good reference on this subject matter?","['de-rham-cohomology', 'smooth-manifolds', 'group-actions', 'lie-groups', 'differential-geometry']"
3529658,Conjugate prior for the Weibull distribution,"On Wikipedia we find a nice overview on conjugate prior distributions. I am interested in the conjugate prior for a random variable $X$ with density $$f(x;\lambda,k) =
\begin{cases}
\frac{k}{\lambda}\left(\frac{x}{\lambda}\right)^{k-1}e^{-(x/\lambda)^{k}} & x \geq 0 ,\\
0 & x<0,
\end{cases}$$ the Weibull. With known rate parameter $k$ the inverse Gamma distribution with density $$g(\lambda; \alpha, \beta)
= \frac{\beta^\alpha}{\Gamma(\alpha)}
(1/\lambda)^{\alpha + 1}\exp\left(-\beta/\lambda\right)$$ is a conjugate prior for $\lambda$ . The posterior distribution of $\lambda$ then is apparently $g$ with $\alpha_*=\alpha+n$ and $\beta*=\beta+\sum_i x_i^k$ (with $i=1,\ldots,n$ ). I cannot seem to be able to show this. Is this result true? And is there a conjugate prior for $k$ as well?","['statistics', 'bayesian']"
3529661,Galois action on Tate twist,"This came up in Greenberg's paper (see chapter 2 in article no. 28 here ) on the Iwasawa theory of elliptic curves. It's a small point, but I'd like to see more of the details. Fix $p$ and let $E$ be an elliptic curve over a number field $K$ with good ordinary reduction at a prime $v\mid p$ . Then  the absolute Galois group $G_{K_v}$ acts on the kernel $A\cong \mathbb{Q}_p/\mathbb{Z}_p$ of the surjective reduction map $E[p^\infty]\rightarrow \tilde E[p^\infty]$ by a character $\varphi:G_{K_v}\rightarrow \mathbb{Z}_p^\times$ since $\operatorname{Aut}(A)\cong \mathbb{Z}_p^\times$ . Greenberg mentions that the action of $G_{K_v}$ on the Tate twist $\hat A(1):= \hom(A,\mu_{p^\infty})$ is given by $\chi\varphi^{-1}:G_{K_v}\rightarrow \mathbb{Z}_p^\times$ , where $\chi:G_{K_v}\rightarrow \mathbb{Z}_p$ is the cyclotomic character coming from the action of $G_{K_v}$ on roots of unity. Why is this (the bold statement) true? Breaking things down, I know that, given two representations $\varphi: G\rightarrow \operatorname{Aut}(V)$ and $\chi:G\rightarrow \operatorname{Aut}(W)$ , the representation $\rho$ on $\hom(V,W)$ is given by defining $\rho(g)f$ , for $f\in \hom(V,W)$ , to be the function \begin{align}\tag{1}
v\mapsto \chi(g)\big(f(\varphi(g)^{-1}(v))\big).
\end{align} So, intuitively, I can see where the $\chi\varphi^{-1}$ is coming from. But I guess I'm struggling a bit to unpack how (1) translates to the above in the case of 1-dimensional representations. That is, given characters $\varphi,\chi: G\rightarrow F^\times$ , coming from two group actions on $A$ and $B$ , say, how does (1) reduce down to the character $\chi\varphi^{-1}:G\rightarrow F^\times$ coming from the action on $\hom(A,B)$ ?","['galois-representations', 'number-theory', 'representation-theory', 'elliptic-curves']"
3529673,"Is there a closed form function for the integral $\int_{0}^{z} \frac{1}{x}\log(1-x)\log(x)\log(1+x)\,dx$?","Recently, in connection with the problem of calculating generating functions of the antisymmetric harmonic number ( https://math.stackexchange.com/a/3526006/198592 , and What's the generating function for $\sum_{n=1}^\infty\frac{\overline{H}_n}{n^3}x^n\ ?$ )  I stumbled on the beautiful integral $$f(z) = \int_{0}^z \frac{\log(1-x)\log(x)\log(1+x)}{x}\,dx\tag{1}$$ which seems to be hard. I tried the common procedure of partial integrations, variable transformations and antiderivatives hunting with Mathematica which generated a multitude of different variants of the integral but finally I could not solve it. Question Can you calculate the integral $(1)$ ? Notice that we are looking here for the integral as a function of the upper limit $z$ , or equvalently, for an antiderivative. The problem counts as solved once $f(z)$ is expressed through known functions, we also say that $f(z)$ has a ""closed functional form"". On the other hand there are myriads of integrations problems in this forum which are similar but have fixed limits, i.e. they are definite integrals which define a constant, and the question is then if this constant is expressible by known constants - has a ""closed form"". Our problem also has a compagnion in the constant species ( Evaluating $\int^1_0 \frac{\log(1+x)\log(1-x) \log(x)}{x}\, \mathrm dx$ ) which provided the closed form for $f(1)$ .","['integration', 'harmonic-numbers', 'polylogarithm']"
3529794,Why is $\sum_{p \in S_n} 2^{c(p)}$ equal to $(n+1)!$?,"It is obvious that $\sum_{p \in S_n} 1=n!$ because it is just counting how many permutations there are of $n$ symbols. But I have also observed that $\sum_{p \in S_n} 2^{c(p)}=(n+1)!$ , where $c(p)$ is the number of cycles of $p$ . What is the combinatorial interpretation of this identity? An example. In $S_3$ we have one permutation with 3 cycles, three permutations with 2 cycles and two with 1 cycle. Then $1\times 2^3+3\times 2^2+2\times 2^1=24=4!$","['permutations', 'combinatorics']"
3529812,Beautiful relation between $\pi$ & $\phi$ via logarithmic integral.,"Given that $$\int_{1/\phi}^{1/\phi^2}{ \dfrac{\ln(1-x)}{x}}dx=\dfrac{\pi^2}{30}$$ Find the value of $$\int_{1/\phi}^{1/\phi^2} \left(\dfrac{\ln(1-x)}{x}\right)^2 dx$$ in terms of $\phi$ and $\pi$ . Where $\phi=\frac{1+\sqrt 5}{2}$ is the golden ratio. I have tried to do it by taylor series, also tried integration by parts but it is getting ugly and too many terms are coming. Source: Made by Prof. Raghava.","['integration', 'contest-math', 'improper-integrals', 'definite-integrals', 'calculus']"
3529953,Blow-up of $\mathbb{P}^2$ at a point has Picard group $\mathbb{Z}\oplus\mathbb{Z}$,"Let $X$ be the blow-up of $\mathbb{P}^2_\mathbb{C}$ at $P=(0:0:1)$ and $\pi:X\to\mathbb{P}^2$ the projection map. I'm trying to prove that: $\text{Pic}(X)\simeq \mathbb{Z}\oplus\mathbb{Z}$ Here is my attempt. Define the map: \begin{align*}
\text{Div}(X)&\to\text{Div}(\mathbb{P}^2)\\
E&\mapsto 0\\
D\neq E&\mapsto \pi(D)
\end{align*} which induces a map $\varphi:\text{Pic}(X)\to\text{Pic}(\mathbb{P}^2)$ . We then have an exact sequence: $$\mathbb{Z}\to\text{Pic}(X)\to\text{Pic}(\mathbb{P}^2)\to 0$$ where the first map is given by $1\mapsto [E]$ . Clearly the map $\pi^*:\text{Pic}(\mathbb{P}^2)\to\text{Pic}(X)$ gives a right split in the sequence. Knowing that $\text{Pic}(\mathbb{P}^2)\simeq \mathbb{Z}$ and using the splitting lemma, the only thing left to prove is that the map $1\mapsto[E]$ is injective. I'm stuck here. If $m[E]=0$ for some $m\geq 1$ , then $mE=\text{div}(f)$ for some $f\in k(X)$ . The problem is that I don't know how to actually write down rational functions in $X$ . Any ideas?","['divisors-algebraic-geometry', 'algebraic-geometry', 'blowup']"
3529959,Does $\sigma(\cup_{n=0}^\infty \mathcal{F}_{S \wedge n}) = \mathcal{F}_S$ hold for every stopping time $S$?,"Suppose $S$ is a stopping time.  How do I show that $\sigma(\cup_{n=0}^\infty \mathcal{F}_{S \wedge n}) = \mathcal{F}_S$ ? This is a VERY basic question but I'm very confused.  The inclusion $\sigma(\cup_{n=0}^\infty \mathcal{F}_{S \wedge n}) \subseteq \mathcal{F}_S$ is trivial, but the reverse direction is impossible for me. Trying to answer myself: Suppose $A \in \mathcal{F}_S \implies A \cap \{S = i\} \in \mathcal{F}_i \quad \forall i\in \mathbb{N}$ $A = \cup_{i = 0}^\infty (A \cap \{S = i\}) \cup (A \cap\{S=\infty\})$ Fix $i$ and choose any $n > i$ . Now $A \cap\{S = i\} \cap\{S\wedge n \leq k\} = A \cap \{S = i\}$ for $k \ge i$ and is the empty set otherwise. As $\mathcal{F}_i \subseteq \mathcal{F}_k$ for $k \ge i$ , we have that $A \cap \{S=i\} \in \mathcal{F}_{S\wedge n} \subset \sigma(\cup_{n \in \mathbb{N}}\mathcal{F}_{S\wedge n})$ I can't figure out why the the event $A \cap \{S = \infty \} \in \sigma(\cup_{n=0}^\infty \mathcal{F}_{S \wedge n})$ , which is all I would need to conclude. Please help me.  This is astronomically demoralizing, because I think this should be really simple.","['measure-theory', 'stopping-times', 'probability-theory']"
3529987,Find the maximum value of $\frac{xyz}{(1+5x)(4x+3y)(5y+6z)(z+18)}$,"Find the maximum value of $\frac{xyz}{(1+5x)(4x+3y)(5y+6z)(z+18)}$ as $x$ , $y$ , and $z$ range over all positive real numbers. My first instinct was to apply AM-GM on each factor in the denominator since every variable is a positive real number. I also thought that it is just right to do so because minimizing the denominator would maximize the expression. The answer I got was $\frac{1}{2880}$ , but the answer key states that it is $\frac{1}{5120}$ . How come?","['inequality', 'maxima-minima', 'multivariable-calculus', 'optimization', 'algebra-precalculus']"
3529999,Value of $f(f(x) – 2y) = 2x – 3y + f(f(y) – x)$,"Let $f : \mathbb{R} \rightarrow \mathbb{R} $ be a polynomial function satisfying $$f(f(x) – 2y) = 2x – 3y + f(f(y) – x),$$ where $x, y \in \mathbb{R}$ . Find the value of $$f(21) – f(14).$$",['functions']
3530019,Conditional expectation conditioned on multiple random variables,"I came across the following expression: $E[X \mid Y=y, Z_1, Z_2] = \frac{\sum_x  x  P(X=x, Y=y \mid Z_1,Z_2)} { P(Y=y \mid Z_1,Z_2)}$ But I have no idea how this simplification works because I am not sure how to deal with conditional expectation when its conditioned on several random variables like "" $Y=y,Z_1,Z_2$ "" as above. Is it possible to just move the $Y=y$ over to the other side like that in a conditional expectation when you have several variables? Can someone please explain the inner workings?","['conditional-expectation', 'probability-theory', 'probability']"
3530024,Showing that $\frac{ 1- \sin\frac{5\pi}{18}}{\sqrt{3} \sin \frac{5\pi}{18}}= \tan\frac{\pi}{18} $,"It's easy to verify on WolframAlpha, but I have difficulty deriving it. 
It's easy to see $$
\tan\left(\frac{\pi}{18}\right)=\frac{\sqrt{3}-\tan(5/18 \pi)}{1+\sqrt{3}\tan(5/18 \pi)}
$$","['trigonometry', 'proof-writing']"
3530072,How to integrate (and use Fubini Theorem) with variables on the boundary of the integrand? ($\int_0^\infty\int_0^x f(s)dsdx$),"As the title goes, I am trying to calculate some norm and encountered integrals looking like $$\int_0^\infty\int_0^x f(s)dsdx$$ where the integrand is a function $$F(x) = \int_0^x f(s)ds.$$ I wonder if it's possible to use Fubini theorem here and do the integral with $x$ variable first. How does that affect the boundary of the inner integral?","['integration', 'calculus', 'analysis']"
3530100,Evaluating the definite integral $\int_0^\pi \frac{\sin^3 \theta}{2\theta - \sin 2\theta} \mathrm{d}\theta$,"I'm interested in finding how and to what the following quantity evaluates out of integral form. $$
\mathcal{I} = \frac{4}{\pi} \frac{R^2}{L^2} \int_0^\pi \frac{\sin^3 \theta}{2\theta - \sin 2\theta} \,\mathrm{d}\theta
$$ This problem arises from an attempt of applying thin airfoil theory to a particularly shaped cone to find an estimate of its associated drag coefficient in a flow field. The cone itself is given by the following parameterization \begin{align}
\theta &= \cos^{-1}\left(1 - \frac{2x}{L}\right) && (0 \leq x \leq L) \\
y &= \frac{R}{\sqrt{\pi}} \sqrt{\theta - \frac{1}{2} \sin 2\theta + C \sin^3 \theta} && (0 \leq \theta \leq \pi).
\end{align} Here, we really care only about $x$ as $\theta$ is just a convenience, $L$ is a positive constant as is $R$ , and $C = 0$ finalizes the cone characterization. We are interested in integrating $((y \circ \theta)')^2$ on the interval for which $x$ is defined. As such, we have \begin{align}
\mathcal{I} &= \frac{1}{L} \int_0^L \frac{32}{\pi} \frac{R^2}{L^4} \frac{(L - x) x}{2\theta(x) - \sin 2\theta(x)} \mathrm{d}x \\
&= \frac{1}{2}\int_0^\pi \frac{32}{\pi} \frac{R^2}{L^4} \frac{(L - (L/2)(1 - \cos\theta)) \ (L/2)(1 - \cos\theta)}{2\theta - \sin 2\theta} \sin\theta \,\mathrm{d}\theta && (\text{$x \to \theta$}) \\
&= \frac{4}{\pi} \frac{R^2}{L^2} \int_0^\pi \frac{(1 + \cos\theta)(1 - \cos\theta)}{2\theta - \sin 2\theta} \sin\theta \,\mathrm{d}\theta \\
&= \frac{4}{\pi} \frac{R^2}{L^2} \int_0^\pi \frac{\sin^3\theta}{2\theta - \sin 2\theta} \,\mathrm{d}\theta.
\end{align} This is where I'm stuck. I realize it can be simplified some more, like \begin{align}
\mathcal{I} &= \frac{2}{\pi} \frac{R^2}{L^2} \int_0^{2\pi} \frac{\sin^3 (\varphi / 2)}{\varphi - \sin \varphi} \,\mathrm{d}\varphi && (\theta = \varphi/2) \\ 
&= \frac{1}{\sqrt{2}\pi} \frac{R^2}{L^2} \int_0^{2\pi} \frac{\sqrt{1 - \cos \varphi}^3}{\varphi - \sin \varphi} \,\mathrm{d}\varphi,
\end{align} but I'm suspicious if these forms are more helpful than before. I thought maybe residue theorem might help, but I question the sole term $\varphi$ for this method. In trying to numerically evaluate the integral in question (as written in the title), Matlab (trapz) and Mathematica (NIntegrate) both insist on differing values. \begin{align}
\frac{\pi}{4} \frac{L^2}{R^2} \mathcal{I} &\sim 1.37368 && \text{(Matlab)} \\
\frac{\pi}{4} \frac{L^2}{R^2} \mathcal{I} &\sim 1.07903 && \text{(Mathematica)}.
\end{align} Actually Matlab insists on NaN, but removing the first entry (so that the integrand is not indeterminate) gives that above. How would one go about to evaluate this integral $\mathcal{I}$ and what is its precise value? Brownie points to go back to the beginning and do it for $C > 0$ .","['calculus', 'definite-integrals', 'trigonometry', 'trigonometric-integrals']"
3530141,Least integer $n$ such that $|exp(1)-S_n| \le 10^{-5}$,"The problem asks to determine the least natural number $n$ such that $$\left| e-\displaystyle\sum_{k=0}^n \dfrac{1}{k!} \right| \le 10^{-5}$$ My approach By definition of $e$ $$e-\displaystyle\sum_{k=0}^n \dfrac{1}{k!} = \displaystyle\sum_{k=n+1}^{+\infty} \dfrac{1}{k!} $$ One may write the RHS as $$\displaystyle\sum_{k=n+1}^{+\infty} \dfrac{1}{k!} = \dfrac{1}{(n+1)!} \left(1 + \dfrac{1}{n+2} + \dfrac{1}{(n+2)(n+3)}+ \cdots \right) $$ Then bound above the sum between brackers by the geometric series sum $$\displaystyle\sum_{i=0}^{+\infty} \left(\dfrac{1}{n+2}\right)^i$$ We get $$\left| e-\displaystyle\sum_{k=0}^n \dfrac{1}{k!} \right| \le \dfrac{(n+2)}{(n+1).(n+1)!}$$ For the LHS to be $\le 10^{-5}$ , it suffices (only :-/) to have $\dfrac{(n+1).(n+1)!}{n+2} \ge 10^5$ which holds for $n = 9$ (calculations) and greater values of $n$ since left side increases with $n$ . How to prove that $9$ is the least such integer. Thanks.","['calculus', 'sequences-and-series']"
3530148,If $R$ is a binary relation over $A$ where $I_A \subseteq R $ and $R \circ R \subseteq R$ then $R$ is reflexive and transitive,"My proof: Lets assume $A$ is an arbitrary set, where $R$ is a relation over the set $A$ . Consider $I_A$ to be an arbitrary identity relation. We will prove if $I_A \subseteq R$ and $R \circ R \subseteq R$ then $R$ is a preorder relation. Consequently we know that $I_A \subseteq R$ , therefore for every $x$ , we know $(x,x) \in R$ . Therefore we can conlude that $R$ is reflexive. We need to prove that $R$ is transitive. To prove $R$ is transitive, we know $R \circ R \subseteq R$ . This tells us that when we combined R with itself, no new relations were created. Because we know no new relations were created,lets assume, a,b and c are arbitrary elements, we can conclude if aRb and bRc then aRc must be true. Therefore the we can conclude $R$ is transitive. This implies that $R$ is reflexive and transitive. $\blacksquare$ My problem: I'm not sure if i've done the proof right, so if anyone can check it. That would be of great help When I tried writing the proof, I felt like i didn't go into too much mathematical detail regarding the composition. To check that if $R \circ R \subseteq$ is really transitive, I did some examples and checked if that was true. Then i did the same thing but with untransitive relations, which resulted in new relations. Which is what i sort of expected, but I couldn't really mathematically explain what $R \circ R$ was actually doing and the mathematical explanation behind why $R \circ R \subseteq R$ is transitive. And like i'm still really confused when I read my proof .","['proof-explanation', 'relations', 'solution-verification', 'discrete-mathematics']"
3530192,Convergence and limit for Collatz type of recurrence,"Let $x_0=1$ and $$x_{n+1}= 2+3\cdot\frac{x_n}{2} \mbox{ if } x_n \mbox{ is even}, $$ $$x_{n+1}= 1+3\cdot x_n \mbox{ otherwise}.$$ Let $$z_n = \frac{\log x_n}{n}.$$ I have numerous questions regarding this sequence. It looks almost like the sequence in the Collatz conjecture , but its behavior is totally different. My main question is whether $z_n$ converges or not. The other questions (and I don't expect an answer for these) are What is the value of $\lim_{n\rightarrow\infty} z_n$ ? Are the binary digits of $x_n$ evenly distributed as $n\rightarrow\infty$ ? On average, is $x_n$ even 50% of the time? Below is a plot of $z_n$ for the first 5,000 values of $n$ : For convenience, below is the piece of code (Perl) that I used for my computations. If you find some issues with it, let me know. It's very basic, based on a brute-force algorithm, except for the fact that it uses exact arithmetic with numbers that have hundreds (or more) digits. use strict;
use bignum;

my $x;
my $ k;
my $logx;

$x=1;

open(OUT,"">collatz.txt"");
for ( $k=1; $ k<5000; $k++) {
 if ($x % 2  == 0) {
   $x = $x >> 1;  # divide by 2
   $x=2+3*$x;
 } else {
   $x =1 + 3*$x;
 }
 if ($k%5 == 0) { print ""$k\n""; select()->flush(); }
 if ($k%25 == 0) { 
   $logx=log($x)/$k; 
   print OUT ""$k\t$ logx\n"";
 }
}
close(OUT);","['recursion', 'discrete-mathematics', 'sequences-and-series', 'limits', 'convergence-divergence']"
3530199,Is $\omega_1 + 1$ sequentially compact?,"I believe there is a mistake in Terence Tao's Analysis II Exercise 2.5.8. It says Show that there exists an uncountable well-ordered set $\omega_1+1$ that has a maximal element $\infty$ , and such that the initial segments $\{x\in ω_1+1:x<y\}$ are countable for all $y\in \omega_1+1\setminus \{\infty\}$ . (Hint: Well-order the real numbers using Exercise 8.5.19, take the union of all the countable initial segments, and then adjoin a maximal element $\infty$ .) If we give  the order topology (Exercise 13.5.5), show that $\omega_1+1$ is compact; however, show that not every sequence has a convergent subsequence. I do not see how is the last assertion true. Every sequence in $\omega_1+1$ is bounded, hence it has $\lim \sup$ , which is a limit point. Can someone point me out to where I am wrong? EDIT: This mistake has already been included in errata for the corrected 3rd edition.","['general-topology', 'analysis']"
3530227,Why define derivative for a function defined on an interval,"In the video lectures on real analysis by Professor Su he uses the following definition for the derivative: A function $f: [a,b] \to \mathbb{R}$ is differentiable at $x \in [a,b]$ if the limit $\lim_{t \to x} \frac{f(t)-f(x)}{t-x}$ exists. In this case we say $f'(x)=\lim_{t \to x} \frac{f(t)-f(x)}{t-x}$ is the derivative of $f$ at $x$ . The definition of limit in $\mathbb{R}$ is as follows: Let $f:E \to \mathbb{R}$ where $E \subset \mathbb{R}$ and let $p$ be a limit point of $E$ , then we say $\lim_{x \to p} f(x)=q$ if $\exists q \in \mathbb{R}: \forall \epsilon>0$ $\exists \delta>0$ s.t. $\forall x \in E$ , $0<\lvert x-p \rvert<\delta \implies \lvert f(x)-q \rvert<\epsilon$ . I was wondering why we restrict ourselves to functions with an interval as its domain. Usually the definitions in metric spaces are based on examples in $\mathbb{R}$ and can be generalized to arbitrary metric spaces, e.g. the definition of limit of a function or continuity of a function can be generalized by replacing the absolute value by a distance function. Of course, the derivative defined as a limit of a quotient cannot be generalized to arbitrary metric spaces since division might not be defined, but why would we restrict ourselves to functions defined on an interval? In light of the definition of the limit we can make sense of this limit for any function defined on a subset $E \subset \mathbb{R}$ . Of course in the case where the domain is $\mathbb{R}$ we do not need to specify the condition that $x$ must be a limit point for the derivative at $x$ to exist since every point of $\mathbb{R}$ is a limit point. However, if we generalize this to functions $f:E \to \mathbb{R}$ where $E \subset \mathbb{R}$ , then we require that $x$ is a limit point for the limit to make sense. This definition would also cover the special cases of intervals. For example, we can let $E=[a,b]$ , then every point in this interval is a limit point as long as $a \neq b$ and we can consider the limit at any point without the need to separately introduce one-sided limits. This is because we can consider $[a,b]$ as a metric space in its own right and for the $\delta$ ball of any radius about $a$ or $b$ in $[a,b]$ is simply cut off at one side (because we only consider points in the metric space). To sum up why do most textbooks/lectures on real analysis restrict to open or closed intervals for derivatives?","['metric-spaces', 'real-analysis', 'definition', 'limits', 'derivatives']"
3530238,When does multiplication with a scalar rv preserve independence?,"Let $X_1,\ldots,X_n$ be independent random variables on $\mathbb{R}$ . Let $f:\mathbb{R}^n \rightarrow \mathbb{R}$ be a (deterministic) function. Under which conditions is the new set of random variables \begin{align*}
f(X_1,\ldots,X_n)X_1,\ldots,f(X_1,\ldots,X_n)X_n
\end{align*} independent? A negative case is: if $f(x_1,\ldots,x_n)=\frac{1}{\sum\limits_{i=1}^n x_i}$ , then the new random vector is not independent because it must sum to one. The same argument works with all kinds of normalizations. It might still be that any subset of $n-1$ random variables is independent though. I'm particularly interested in ""false normalizations"" for continuous random variables: $f(x)=\frac{1}{\sum\limits_{i=1}^n x_i^2}$ This is a false normalization because now, the (Euclidian) norm of the new vector is not deterministic, so I cannot just express one random variable as a function of the others. This is in contrast to the ""true normalization"" $f(x)=\frac{1}{\sqrt{\sum\limits_{i=1}^n x_i^2}}$ where we can immediately deduce that the (Euclidian) norm of the new vector is one so that the new vector cannot be jointly independent. Any insights here would be highly appreciated.","['independence', 'normed-spaces', 'probability-theory', 'probability']"
3530240,Sequence vs Progression,"I understand the difference between these two terms. My textbook says that terms in a sequence follow some definite rule, or an algorithm, and it’s not always possible to express its general term via a mathematical expression. Example : A sequence of consecutive prime numbers. While each terms of a progression follows the same rule and we have a mathematical expression for any arbitrary term of a progression. My problem is, I don’t fully understand this sentence terms of a progression follow the same rule. Can they follow more than one rule? Let’s say we have a general term for a sequence $T_n = \begin{cases}
  \frac{1}{n}  & \text{if } n \in \{1,2,3,...10\}, \\ 
  \frac{-1}{n} & \text{if } n \in \{11,12,.....,20\} \\
  \frac{-1}{3n}& \text{if } n \in \{21,22, \ldots\}
\end{cases}
$ Now we can find any arbitrary term of this sequence because we have its general term (with more than a single mathematical expression). Is it a sequence or a progression ? My own understanding of sequence vs progression says that it should be a progression. If it is, can a progression have a general term which has more than one mathematical expression?","['terminology', 'sequences-and-series']"
3530320,What can be said about the DFT given the following information?,"We are given the following information:- Let $z,w \in \mathbb{C^n}$ be signals, $z_{\delta} = \Omega_nz$ and $w_{\delta} = \Omega_nw$ be the discrete Fourier transformation of $z$ and $w$ . We define $\Omega_n$ as the following: $$\Omega_n = \frac{1}{\sqrt n} \begin{bmatrix}1&1&1&1&...&1\\1&\omega&\omega^2&\omega^3&...&\omega^{n-1}\\1&\omega^2&\omega^4&\omega^6&...&\omega^{2(n-1)}\\1&\omega^3&\omega^6&\omega^9&...&\omega^{3(n-1)}\\...&...&...&...&...&...\\1&\omega^{n-1}&\omega^{2(n-1)}&\omega^{3(n-1)}&...&\omega^{(n-1)(n-1)}\end{bmatrix}$$ Given the fact that the columns of the DFT matrix are normalized, which of the following statements are true? We can say that $z_{{\delta}_{n-1}}$ describes the share of the highest frequencies of of the signal $z$ . In the rows of the DFT matrix $\Omega_n$ , you will find the eigenvectors in a circulant matrix. The convolution of $z$ and $w$ correspond to the elemental multiplication of the transformed signals: $z \cdot w= z_{\delta}⋅w_{\delta}$ For $2.$ I'm pretty sure that it's false because when we take the case of a four point clockwise DFT matrix, we can see that the rows don't contain the eigenvectors in a circulant matrix. For $3.$ I have a feeling that it's true but I'm not sure if I can explain it.","['fourier-analysis', 'real-analysis', 'matrices', 'linear-algebra', 'transformation']"
3530389,Conceptual question about set theory fundamentals: Tao's Analysis I Chapter 3,"In Tao's Analysis I , Chapter $3$ introduces the fundamentals of set theory. In particular, the following lemma and axiom are provided (in this order...i.e. lemma precedes the axiom in the chapter layout): Lemma (Single Choice): Let $A$ be a non-empty set. Then there exists an object $x$ such that $x \in A$ There is an accompanying mini-proof by contradiction that establishes this. Axiom (Singleton sets and pair sets): If $a$ is an object, then there exists a set $\{a\}$ whose only element is $a$ , i.e. for every object $y$ , we have $y \in \{a\}$ if and only if $y=a$ ; we refer to $\{a\}$ as the singleton set whose element is $a$ . Furthermore, if $a$ and $b$ are objects, then there exists a set $\{a,b\}$ whose only elements are $a$ and $b$ ; i.e. for every object $y$ , we have $y \in \{a,b\}$ if and only if $y=a$ or $y=b$ ; we refer to this set as the pair formed by $a$ and $b$ . The aim of this question is not meant to be pedantic; I want to make sure I am understanding the difference between the two statements...because the order of presentation has me slightly confused. It seems to me that it would have made more sense to present the Axiom (Singleton sets and pair sets) first because this is effectively establishing the existence of sets beyond just the empty set (which was stated one page earlier)...i.e. this establishes that ""non-empty sets"" exist (albeit, only non-empty sets containing one or two elements). The lemma seems like it is already baked into this axiom...for example, the singleton set $\{a\}$ is literally defined by $a\in\{a\}$ and the pair set is literally defined by $a\in \{a,b\}$ . And this is sort of why I am confused. Why is there a need for this lemma when the axiom essentially already states this? Moreover, I am anticipating that all sets are effectively ""derived"" from the union of singleton and pair sets...and therefore, once again, the axiom already encodes the lemma, even for non-empty sets greater than size $1$ and $2$ . Any clarity would be greatly appreciated!","['elementary-set-theory', 'real-analysis']"
3530404,Cat chasing mouse on a straight line coin toss,"I recently got keen on ""brainteasers"" and now I am trying to solve and code my daily one. A cat is chasing a mouse in a 1-D space, for example, a tunnel. The mouse is Y meters away from its hole and the cat is further X meters behind the mouse. In every turn, with an equal probability of 1/3, the mouse moves 1 meter forward to it's hole OR the cat moves 2 meters forward OR both of them move +1 meter forward. What is the probability of the mouse getting to its hole or not? What I am trying is to approach by an absorbing Markov chain but I am a bit confused how exactly to formulate it and generalize it in the case of an  asymmetric dice toss each turn to determine who moves and by how far? Could you please recommend any interesting graph theory basics directly applicable to the problem?","['graph-theory', 'markov-chains', 'random-walk', 'probability']"
3530428,"Visualization of a ""Not so intuitive"" problem of linear algebra.","I recently encountered a problem in Hoffmann-Kunze linear algebra: If $(.,.)$ is the standard inner product on $\mathbb C^2$ then show that $(Tv,v)=0 \forall v\in \mathbb C^2 \implies T=0$ , I think the proof is quite tricky and I saw its solution at last after trying myself through a long time. The solution is like this, we put $x+y$ and $x+iy$ for $v$ and prove that $(Tx,y)=0 \forall x,y\in \mathbb C^2$ , thus it follows that $Tx=0 \forall x\in \mathbb C^2$ , but I think it cannot be just a trick, there might be a deeper understanding within this simple 'just a trick' looking proof. I want to visualize why this fact is not true for $\mathbb R^2$ space but true when $\mathbb C$ replaces $\mathbb R$ . I am looking for an intuitive solution of the same problem or a suitable visualization that would help me in better understanding of this problem.","['inner-products', 'visualization', 'motivation', 'linear-algebra', 'intuition']"
3530455,Why is $\det(I + A^{50}) = 4$ here?,"I’m trying to understand the reasoning behind the following: Let $A \in \mathbb{R}^{3\times3}$ with eigenvalues $1$ , $-1$ , $0$ . What is $\det \left(I + A^{50} \right)$ ? The given answer is 4. A is obviously singular due to eigenvalue 0. Moreover, spectral decomposition of $A$ exists: $$
A = T diag(1, -1, 0) T^{-1}\\
A^{50} = T diag(1, -1, 0)^{50} T^{-1}
$$ But I can’t see why $\det(I + T diag(1, -1, 0)^{50}T^{-1})$ would be 4 either, due to the limited knowledge about $T$ . Can somebody shed light on this for me?","['matrices', 'determinant', 'linear-algebra']"
3530490,Do I have to solve a 4th degree equation to find $\cos\alpha$ from $d + t \cos(\alpha) = w \tan(\alpha)$?,"I have the following situation: I know $w$ , $d$ and $t$ . What I want to know is $\alpha$ respectively $\cos(\alpha)$ . I have to solve the following formula for $\alpha$ : $$d + t \cos(\alpha) = w \tan(\alpha)$$ respectively $$d + t \cos(\alpha) = w \frac{\sqrt{1 - \cos(\alpha)^2}}{\cos(\alpha)}$$ That leads to a 4th degree equation. $$d^2 + 2dt \cos(\alpha) + t^2 \cos^2(\alpha) = w^2\frac{1 - \cos^2(\alpha)}{\cos^2(\alpha)}$$ $$d^2 \cos^2(\alpha) + 2dt \cos^3(\alpha) + t^2 \cos^4(\alpha) = w^2 (1 - \cos^2(\alpha))$$ My question is Do I miss something? Is there an alternative solution?","['algebra-precalculus', 'polynomials', 'trigonometry']"
3530497,Accumulation points of a recursive sequence $a_n=\cos\left(\frac{2\pi n}{3}\right)\sqrt[n]{1+2^n+(-3)^n}$,"Find all the accumulation points of the sequence $(a_n)_{n=1}^{\infty}$ defined recursively: $$a_n=\cos\left(\frac{2\pi n}{3}\right)\sqrt[n]{1+2^n+(-3)^n}$$ My attempt: $$\cos\left(\frac{2\pi n}{3}\right)\in\left\{-\frac{1}{2},1\right\}$$ $$\sqrt[n]{1+2^n+(-3)^n}=\sqrt[n]{(-3)^n\left(\left(-\frac{1}{3}\right)^n+\left(-\frac{2}{3}\right)^n+1\right)}=-3\sqrt[n]{\left(-\frac{1}{3}\right)^n+\left(-\frac{2}{3}\right)^n+1}$$ I tried to manipulate with the above expression and apply the squeeze theorem, but I haven't managed to get anything useful for this problem, except: $$\sqrt[n]{1+2^n+(-3)^n}<\sqrt[n]{3\cdot3^n}=3\sqrt[n]{3}$$ I also considered artithmetic inequalities and the comparison: $1+2^n\leq(1+2)^n$ , unsuccessfully.
I would definitely examine the cases $n\pmod{6}$ or $n\pmod{3}$ . How can I move further from this point and what can I do with the $n-\text{th}$ root? I thought I could see how one of the factors behaves since $\cos\left(\frac{2\pi n}{3}\right)$ alternates for $n\in\mathbb N$ . Thank you in advance!","['limits', 'calculus', 'sequences-and-series', 'real-analysis']"
3530512,Convergence in $L^p$: Marcinkiewicz-Zygmund Strong Law of Large Numbers,"If $(X_n)_n$ is a sequence of random variables i.i.d, let $0<p<2,$ $Y_n=\sum_{k=1}^nX_k.$ We can prove, using Kolmogorov three series theorem, Marcinkiewicz-Zygmund Strong Law of Large Numbers: If $X_1 \in L^p$ then $\lim_n\frac{Y_n}{n^{1/p}}=0 \ a.s$ if $p<1$ and $\lim_n\frac{Y_n-nE[X_1]}{n^{1/p}}=0 \ a.s$ if $1\leq p<2$ . I would like to know if there is convergence in $L^p.$",['probability-theory']
3530539,"Is ""taking a limit"" a function? Is it a procedure? A ternary operation?","I was sitting in analysis yesterday and, naturally, we took the limit of some expression. It occurred to me that ""taking the limit"" of some expression abides the rules of a linear transformation $$\lim_{x \rightarrow k}\ c(f(x)+g(x)) = c \lim_{x \rightarrow k} f(x) + c\ \lim_{x \rightarrow k} g(x),$$ and (my group theory is virtually non existent) appears also to be a homomorphism: $$\lim_{x \rightarrow k} (fg)(x) = \lim_{x \rightarrow k} f(x)g(x), $$ etc. Anyway, my real question is, what mathematical construct is the limit?","['limits', 'terminology']"
3530574,Question on Relationship between Modular Forms and Dirichlet L-Series,"The Wolfram MathWorld article Weisstein, Eric W. ""Dirichlet L-Series."" From MathWorld--A Wolfram Web Resource. mentions Hecke (1936) found a remarkable connection between each modular form with Fourier series $$f(\tau )=c(0)+\sum_{n=1}^\infty c(n)\,e^{2 \pi i n \tau}\tag{1}$$ and the Dirichlet L-series $$\phi(s)=\sum_{n=1}^\infty\frac{c(n)}{n^s}\tag{2}$$ This answer to a related question on Math StackExchange seems to contradict the Wolfram MathWorld article. The Wolfram MathWorld article defines a Dirichlet L-series as a series of the form $$L_k(s,\chi)=\sum_{n=1}^\infty\chi_k(n)\,n^{-s}\tag{3}$$ where $\chi_k(n)$ is a Dirichlet character whereas the answer on Math StackExchange claims ""you will never get the coefficients of the Dirichlet series $\zeta(s)$ or $L(s, \chi)$ as the q-expansion coefficients of a modular form"". Note the Wolfram MathWorld article refers to $\phi(s)$ as a Dirichlet L-series which implies $c(n)$ is a Dirichlet character. Question : What is the explanation for this seeming contradiction with respect to the relationship between modular forms and Dirichlet L-series?","['dirichlet-series', 'number-theory', 'modular-forms']"
3530608,When is the dual coframe of an orthonormal frame closed?,"Let $E_1,E_2$ be a smooth orthonormal frame of vector fields on a simply connected open domain $U \subseteq\mathbb{R}^2$ . Let $E^i$ be the associated dual coframe of one-forms, and suppose that $dE^i=0$ . It is true that the $E_i$ are constants? (do not change from point to point). I know that $E^i=du_i$ or equivalently that $E_i=\nabla u_i$ where the $u_i$ are smooth functions on $U$ , but I am not sure how to proceed from here.","['differential-forms', 'differential-topology', 'riemannian-geometry', 'differential-geometry']"
3530624,Where does this proof of $R^n\cong R^m\Rightarrow m=n$ break down for noncommutative rings? [duplicate],"This question already has an answer here : Noncommutative failure of IBN: $\,R^n\cong R^m \Rightarrow n - m,$ ring $R$ with maximal ideal $I$ such that $R/I$ is not a division ring? (1 answer) Closed 4 years ago . It can be that $R\cong R^2$ for some ring as wikipedia says, something like the column finite ring. In this the author proved in lemma 1.1 something different. But I could not find any mistakes in the proof. What is happening?","['ring-theory', 'abstract-algebra', 'commutative-algebra']"
3530636,How to find the coefficients of an iteration of a polynomial function?,"Let $f(x)$ be a polynomial of degree $N$ with real coefficients $c_n$ : $$ f(x) = \sum_{n=0}^{N} x^n c_n$$ Further, let $f^{(1)}(x) =f(x)$ , $f^{(2)}(x) =f(f(x))$ and so on ... It is obvious that the degree of $f^{(i)}(x)$ is $N^i$ . Here is my question:
How do you calculate the coefficients of $f^{(i)}(x)$ ?
I dont know how to tackle this. If for example $i=2$ then $$f(f(x)) =  \sum_{n=0}^{N} c_n ( \sum_{k=0}^{N} x^k c_k)^n$$ But i dont get anywhere with this. Any help is appreciated.","['functions', 'analysis', 'sequences-and-series']"
3530637,Can $\mathbb{Q}(u)$ be of degree 2 over $\mathbb{Q} (u^3)$?,"I came across the following question - Let $u$ be algebraic over $\mathbb Q$ of degree which is not divisible by $3$ . Does necessarily $\mathbb Q(u)=\mathbb Q(u^3)$ ? What I have so far: Since $x^3-u^3$ is reducible over $\mathbb Q$ with $u$ as a root, then the dimension of $\mathbb Q(u)$ over $\mathbb Q(u^3)$ is at most $3$ . From the dimension theorem: $[\mathbb Q(u):\mathbb Q]=[\mathbb Q(u):\mathbb Q(u^3)]\cdot [\mathbb Q(u^3):\mathbb Q]$ The LHS is not divisible by $3$ , and so since $[\mathbb Q(u):\mathbb Q(u^3)]$ is either $1$ or $2$ , and cannot be $3$ . If it is $1$ , then we know that the two fields are equal. But I'm not sure why it can't be $2$ . and can't come up with a counter example which fits the problem. Can anyone help me with proving that the two fields are equal, or coming up with a counter example? Thanks in advance.","['field-theory', 'galois-theory', 'ring-theory', 'abstract-algebra', 'splitting-field']"
3530652,Prove that $\lim\limits_{n\to\infty} \prod\limits_{k=1}^n \sin(k)$ converges to $0$,"$$\lim_{n\to\infty} \prod_{k=1}^n \sin(k) =0$$ How can I show that this in fact is true? I know that when I take the absolute value of this product than it is strictly decreasing and bounded between 0 and 1, but I want to show that this limit is actually 0.","['infinite-product', 'limits', 'limits-without-lhopital', 'sequences-and-series']"
3530667,"From the collection of all permutation matrices of size $10\times10$, one such matrix is randomly picked. What is the expected value of its trace?","From the collection of all permutation matrices of size $10\times10$ , one such matrix is randomly picked. What is the expected value of its trace? (A permutation matrix is one that has precisely
one non-zero entry in each column and in each row, that non-zero entry being 1.) I know that possible options for traces are $0,1,2,3,4,5,6,7,8,9,10$ . Now from this how to find the expectation of the trace?","['matrices', 'trace', 'linear-algebra', 'permutation-matrices']"
3530683,"If $\frac{1}{a+3}+\frac{1}{b+4}+\frac{1}{c+5}=\frac{7}{12}$ for positive integer $a$, $b$, $c$, then find $\frac{a}{a+3}+\frac{b}{b+4}+\frac{c}{c+5}$","Given $a, b, c$ are positive integers, and that $$\frac{1}{a + 3} + \frac{1}{b+4} + \frac{1}{c+5} = \frac{7}{12},$$ compute: $$\frac{a}{a+3} + \frac{b}{b+4} + \frac{c}{c+5}$$ Source (Romanian Math Magazine, Gazeta Matematica S:E19.333, this problem marked as targetting 6th graders) I tried writing the terms as $1 - \frac{1}{a+3}$ and similarly for the others, but I get $3 - \frac{3}{a+3} - \frac{4}{b + 4} - \frac{5}{c + 5}$ which I don't find very helpful. Many thanks in advance!",['algebra-precalculus']
3530775,Generator of sigma field that is generated by an intersection of a decreasing sequence of generators.,"Let $\Omega$ be a non-empty set and let $(E_n)_{n\in\mathbb{N}}$ be 
sequence of intersection stable systems over $\Omega$ (i.e. $E_n$ is a set consisting of subsets of $\Omega$ satisfying $A, B\in E_n$ $\Longrightarrow$ $A \cap B\in E_n$ )  such that $E_{n+1} \subset E_n$ for all $n\in\mathbb{N}$ .
Is it true that $$
\sigma\left(\bigcap_{n\in\mathbb{N}} E_n\right)= \bigcap_{n\in\mathbb{N}} \sigma(E_n),
$$ where $\sigma(E)$ denotes the smallest $\sigma$ -field over $\Omega$ that contains $E$ ?","['measure-theory', 'probability-theory']"
3530794,Image of rational numbers under the polynomial map,"I have the following problem: Problem. For polynomials $f$ and $g$ with rational coefficients prove that $f(\mathbb{Q})=g(\mathbb{Q})$ iff $f(x)=g(ax+b)$ for some rational numbers $a, b$ with $a\neq 0$ . It's clear that if $\ell(x)=ax+b$ where $a\in\mathbb{Q}\backslash\{0\}$ and $b\in\mathbb{Q}$ then $\ell(\mathbb{Q})=\mathbb{Q}$ , so if $f(x)=g(ax+b)$ then $f(\mathbb{Q})=g(\mathbb{Q})$ . However, the converse is not so obvious. My idea was to prove first the statement when leading coefficents of both polynomials are positive, i. e. $$
f=a_nx^n+a_{n-1}x^{n-1}+\ldots+a_0,~g=b_mx^m+b_{m-1}x^{m-1}+\ldots+m_0
$$ and $a_n,b_m>0$ . If degrees of $f(x)$ and $g(x)$ are odd, then there exists $A,M>0$ such that $f(x)$ and $g(x)$ are increasing functions on $[A,+\infty)$ and for all $y_0>M$ there exists unique $x_1=x_1(y)$ and unique $x_2=x_2(y)$ such that $f(x_1)=g(x_2)=y$ . Moreover, if we consider $x_1$ and $x_2$ as functions of variable $y$ , then $$
\lim_{y\rightarrow +\infty}x_1(y)=+\infty,
\\
\lim_{y\rightarrow +\infty}x_2(y)=+\infty.
$$ Since $f(t)\sim a_nt^{n}$ and $g(t)\sim b_mt^{m}$ when $t\rightarrow +\infty$ we obtain that $$
1=\lim_{y\rightarrow +\infty}\frac{y}{y}=\lim_{y\rightarrow +\infty}\frac{f(x_1(y))}{g(x_2(y))}=\lim_{y\rightarrow +\infty}\frac{a_n(x_1(y))^{n}}{b_m(x_2(y))^{m}}.
$$ Hence, $a_n(x_1(y))^{n}\sim b_m(x_2(y))^{m}$ when $y$ tends to infinity. If we prove that $x_1(y)=ax_2(y)+b$ for some $a$ and $b$ , then the equality $f(x)=g(ax+b)$ holds for infinitely many distinct real $x$ , so $f(x)\equiv g(ax+b)$ . However, I don't how even to prove that $n=m$ . So, is there any way to continue this approach?","['contest-math', 'number-theory', 'polynomials']"
3530809,countable dimensional vector space has uncountable eigenvalues?,"Consider $\mathcal{R}^{\infty}$ , and linear map $\mathcal{L} \in L(\mathcal{R}^{\infty})$ , where $\mathcal{L}((x_1,x_2,...))=(x_2,x_3,...)$ . Now, any number $\lambda \in \mathcal{R}$ is an eigenvalue with eigenvector $(c,c\lambda,c \lambda^2,...)$ . But dimention of $\mathcal{R}^{\infty}$ is countable. Is this a problem?",['linear-algebra']
3530823,4th Stiefel whitney class of a 7-dimensional Spin manifold,"In Massey's paper ""On the Stiefel Whitney classes of a manifold I"" he shows that manifolds of dimension n = 4s + 3 have $w_n = w_{n-1} = w_{n-2} = 0$ . Where $w_i$ is a mod 2 Stiefel-Whitney class Also, the first non-zero Stiefel-Whitney class must be $w_{2^k}$ for some k. That means that if $M$ is a 7-dimensinal Spin manifold, the only class which has any hope of not being zero is $w_4$ . In general, it doesn't seem like $w_4$ has any ""special"" meaning (like $w_2$ tells about spin and $w_1$ orientability) but maybe in this specific case it does. Is there a condition that tells us when $w_4$ must be nonzero for 7-d Spin manifolds? Here is an idea: Suppose that $w_4 \neq 0$ . The Poincare duality tells us that there is a nonzero class in $H^3(M)$ . Do we know anything about that three class? Maybe it has to be zero, implying $w_4 = 0$ ?","['characteristic-classes', 'spin-geometry', 'algebraic-topology', 'differential-geometry']"
3530905,Answered question. Ball on shadow,asdfasdfasdfasdfasdfasdfasdfasdfasdfasdfasdfasdf,['geometry']
3530949,Solve $\sin x + \cos x = \sin x \cos x.$,"I have to solve the equation: $$\sin x + \cos x = \sin x \cos x$$ This is what I tried: $$\hspace{1cm} \sin x + \cos x = \sin x \cos x \hspace{1cm} ()^2$$ $$\sin^2 x + 2\sin x \cos x + \cos^2 x = \sin^2 x \cos^2x$$ $$1 + \sin(2x) = \dfrac{4 \sin^2 x \cos^2x}{4}$$ $$1 + \sin(2x) = \dfrac{\sin^2(2x)}{4}$$ $$\sin^2(2x) - 4 \sin(2x) -4 = 0$$ Here we can use the notation $t = \sin(2x)$ with the condition that $t \in [-1,1]$ . $$t^2-4t-4=0$$ Solving this quadratic equation we get the solutions: $$t_1 = 2+ 2\sqrt{2} \hspace{3cm} t_2 = 2 - 2\sqrt{2}$$ I managed to prove that $t_1 \notin [-1, 1]$ and that $t_2 \in [-1, 1]$ . So the only solution is $t_2 = 2 - \sqrt{2}$ . So we have: $$\sin(2x) = 2 - 2\sqrt{2}$$ From this, we get: $$2x = \arcsin(2-2\sqrt{2}) + 2 k \pi \hspace{3cm} 2x = \pi - \arcsin(2-2\sqrt{2}) + 2 k \pi$$ $$x = \dfrac{1}{2} \arcsin(2-2\sqrt{2}) + k \pi \hspace{3cm} x = \dfrac{\pi}{2} - \dfrac{1}{2}\arcsin(2 - 2\sqrt{2})  + k \pi$$ Is this solution correct? It's such an ungly answer, that I kind of feel like it can't be right. Did I do something wrong?","['trigonometry', 'quadratics']"
3530997,"Find integral closure of $\mathbb{Q}(\sqrt{2},i)$","I am having trouble finding a basis for the integral closure of $\mathbb{Q}(\sqrt{2},i)$ . How would I approach such a task? I also need to show that the closure is not $\mathbb{Z}[\sqrt{2},i]$ and I'm having trouble finding a field element not in the smaller ring, but is satisfied by some monic polynomial in the smaller ring. Can anyone help? Thanks.","['number-theory', 'ring-theory', 'abstract-algebra']"
3531045,Perimeter of a triangle with an angle of $120^\circ$ and sides in arithmetic progression,"I need to find the perimeter of the following triangle in terms of $\ell$ . 
  The only extra info I have is the three sides form an arithmetic sequence. I've been tutoring maths on these topics for a couple years now and I am still struggling with this problem. I'm sure there's something rather simple I can't see. Any help is appreciated!","['triangles', 'euclidean-geometry', 'trigonometry', 'geometry']"
3531096,Canonical divisor of $\mathbb{P}^2$,"I'm trying to understand the computation of the canonical divisor of $\mathbb{P}^2$ . The usual explanation goes like this: Let $(X:Y:Z)$ be the coordinates of $\mathbb{P}^2$ . In the local chart $U_Z=\{Z\neq 0\}$ , we define the coordinates $x:=\frac{X}{Z}$ and $y:=\frac{Y}{Z}$ and take the $2$ -form $dx\wedge dy$ , which has no zeros and no poles. In $U_Y:=\{Y\neq 0\}$ , we define $u:=\frac{X}{Y}$ , $v:=\frac{Z}{Y}$ , so that: \begin{align*}
dx\wedge dy&=d\left(\frac{u}{v}\right)\wedge d\left(\frac{1}{v}\right)\\
&=\left(\frac{du}{v}-\frac{u}{v^2}dv\right)\wedge\left(-\frac{1}{v^2}dv\right)\\
&=-\frac{1}{v^3}du\wedge dv
\end{align*} which has a pole of order $3$ , therefore $K_{\mathbb{P}^2}=-3H$ , where $H$ is a hyperplane (in this case, a line). What I don't understand about this argumentation is 1) why don't we need to check the other chart $U_X:=\{X\neq 0\}$ ? and 2) what is this $H$ exactly?","['algebraic-geometry', 'differential-forms', 'projective-space']"
3531107,Lagrange theorem in a limit of a summation,"I need to evaluate $$\lim_{n\to +\infty} \frac{1}{\ln n} \sum_{k=1}^{n-1} \frac{1}{k}$$ The solution of this problem says that $$\ln n = \int_{1}^{n} \frac{1}{x} \text{d}x=\sum_{k=1}^{n-1} \int_{k}^{k+1} \frac{1}{x} \text{d}x$$ Then Lagrange's theorem is used to say that $$\sum_{k=1}^{n-1} \int_{k}^{k+1} \frac{1}{x} \text{d}x=\sum_{k=1}^{n-1} \int_{k}^{k+1} \left[\color{red}{\frac{1}{k}-\frac{x-k}{\xi_k^2}}\right]\text{d}x$$ My problem is how the red part is obtained: I know that Lagrange theorem says, for the function $f(x)=\frac{1}{x}$ in the interval $[k,k+1]$ that exists $\xi_k\in(k,k+1)$ such that $$-\frac{1}{\xi_k^2}=\frac{\frac{1}{k+1}-\frac{1}{k}}{k+1-k}$$ I've done my calculations but I can't get the red part. Can someone explain me where it comes from?
Thanks.","['limits', 'summation', 'definite-integrals', 'analysis']"
3531166,Solving the differential equation $−3xdx+(x^2y+3y)dy=0$,"Solve the following differential equation by finding an appropriate integrating factor $$ −3x\,\mathrm{d}x+(x^2y+3y)\,\mathrm{d}y=0$$ My attempt : The equation is the same as: $$\frac{\mathrm{d}y}{\mathrm{d}x}=\frac{3x}{(x+3)y}$$ Make y=z^{1/2} Then $$\frac{\mathrm{d}y}{\mathrm{d}x}=\frac{1}{2}z^{-1/2}\frac{\mathrm{d}z}{\mathrm{d}x}=\frac{3x}{x^2+3}y^{-1}$$ replace y with $$y=z^{1/2} $$\frac{1}{2}z^{-1/2}\frac{\mathrm{d}z}{\mathrm{d}x}=\frac{3x}{x^2+3}z^{-1/2}$$ $$
z=3\ln(x^2+3)+C, \quad \text{ while } \quad y=z^{1/2}
$$ so $$
y^2-3\ln(x^2+3)=c
$$ screenshot is here: the assignment system said my attemp was wrong without giving the correct answer. Please let me know where I am wrong. thanks a lot! thanks for the help guys. it turns to be a bug of the website.","['calculus', 'solution-verification', 'ordinary-differential-equations']"
3531200,Why is length often a unitless quantity in mathematics?,"This is something that's bothered me for a long time: Why is length often not given any units (e.g. inches or meters) in mathematics? The unit circle is said to have a ""radius of 1,"" with no unit given. A vector is said to have a magnitude of, say, 27, with no unit given. A triangle is said to have a hypotenuse length of, say, 10, again with no unit given. Is the reason no unit is given simply because one could substitute any unit, so long as the proportions between quantities remain the same? I searched around for a little on here but couldn't find any questions directly addressing my concern here. I'd appreciate any clarification.","['vectors', 'dimensional-analysis', 'geometry', 'unit-of-measure', 'trigonometry']"
3531282,Is there a volume-preserving diffeomorphism of the disk with prescribed singular values?,"This question has now been cross-posted at mathoverflow. While working on a variational problem, I have reached to the following question. Let $0<\sigma_1<\sigma_2$ satisfy $\sigma_1\sigma_2=1$ , and let $D \subseteq \mathbb{R}^2$ be the closed unit disk. Does there exist a smooth map $f:D \to D$ such that $df$ has everywhere the fixed singular values $\sigma_1,\sigma_2$ and $\det(df)=1$ ? 
  Is there such a diffeomorphism of $D$ ? The linear map $x \to \begin{pmatrix} \sigma_1 & 0 \\\ 0 & \sigma_2 \end{pmatrix}x$ does not satisfy the requirement; it gets outside of $D$ , as $ \sigma_2 > 1$ . If we exclude a ray from $D$ , then there is such a map, given by $re^{i \theta} \to \sigma_1re^{i(\sigma_2/\sigma_1) \theta}$ . Furthermore, when $\frac{\sigma_2}{\sigma_1}=n$ is an integer, this map is given by $z \to \frac{z^n}{|z|^{n-1}}$ which is in $W^{1,\infty}(D,\mathbb{R}^2)$ . Thus, if we could approximate such a map by smooth maps having fixed singular values, we would finish. Here is an argument (given by a colleague) showing that $f$ cannot be the gradient of a function: Suppose that $f=\nabla u$ . Then $df=\operatorname{Hess}u$ is symmetric and has real eigenvalues. Since $\det(df)=1$ , at every point of $D$ both eigenvalues are positive or both are negative. Thus $\operatorname{tr}(df) \neq 0$ has a definite sign. By composing $f$ with the map $x \to -x$ we can assume the eigenvalues are always positive. Now, $$ \int_{D} \operatorname{div} f = \int_{\partial D} \langle f, n \rangle \le \operatorname{Vol}(\partial D) =2\operatorname{Vol}( D),$$ where in the inequality we have used the fact that $|f| \le 1$ . We showed that $\operatorname{div} f \le 2$ on average, so there exist a point $x \in D$ where $$ \operatorname{div}f (x)=\lambda_1(df_x) + \lambda_2(df_x) \le 2. $$ Since the eigenvalues are positive, and $df=\operatorname{Hess}u$ is symmetric, we have $\lambda_i=\sigma_i$ , so $\sigma_1+\sigma_2=\sigma_1(df_x) + \sigma_2(df_x) \le 2$ . This contradicts the AM-GM inequality $\frac{\sigma_1+\sigma_2}{2} > \sqrt{\sigma_1 \sigma_2}=1$ , which is strict here since $\sigma_1 \neq \sigma_2$ . I tried using Helmholtz decomposition to treat the general case, but that doesn't seem to lead anywhere.","['svd', 'riemannian-geometry', 'ergodic-theory', 'multivariable-calculus', 'differential-geometry']"
3531287,What is the difference between inverse and reciprocal?,"Okay soo, i always thought that the inverse of $y=e^x$ is $\frac{1}{e^x}$ but its not??? It is y= $\log_e(x)$ ? I swear these terms have been used interchangeably. So can someone please explain the difference between reciprocal and inverse? Thanks.","['calculus', 'inverse', 'algebra-precalculus']"
3531288,Using Normal and Binomial approximations for airline tickets,"Question: An airline finds that 7% of the people who make reservations on a certain flight do not show up for the flight. If the airline sells 185 tickets for a flight with only 180 seats, use the normal approximation to the binomial distribution to find the probability that a seat will be available for every person holding a reservation and planning to fly. (Round your answer to four decimal places.) I am frustrated at this problem. I need to use a normal approximation to a binomial distribution. My attempt starts by letting $n=185$ for the total number of tickets sold. Then, I let $p=0.93$ which is the probability of people showing up which leaves $q=0.07$ being no shows. So, this is what I got...
Since $np = 185 \cdot 0.93$ and $nq = 185 \cdot 0.07$ $P(Y \leq 185) \approx P(W \leq 185.5) = P(Z \leq \frac{185.5-172.05}{\sqrt{185 \cdot 0.07 \cdot 0.93}})$ $P(Z \leq \frac{13.45}{\sqrt{12.0435}})$ $P(Z \leq \frac{13.45}{3.470374})$ $P(Z \leq 3.875)$ This is $0.9999$ but this is wrong which I don't understand because I even watched a tutorial video and followed each step. I even use R on this as pbinom(180,185,0.93) which is $0.9969$ and that is still wrong. What am I missing?","['statistical-inference', 'statistics', 'binomial-distribution']"
3531452,"If $f:\mathbb{R}_+\to\mathbb{R}_+$ is strictly concave and strictly increasing with (...), is it true that $f''((f')^{-1}(x))\cdot(f')^{-1}(x)>-x$?","Is this true? If $f:\mathbb{R}_+\to\mathbb{R}_+$ is strictly concave and strictly increasing with $f(0)=0$ , $\lim_{x\to0^+}f'(x)=\infty$ and $\lim_{x\to\infty}f'(x)=0$ , then $$f''((f')^{-1}(x))\cdot (f')^{-1}(x)>-x$$ for all $x>1$ . Here $\mathbb{R}_+$ is the set of nonnegative real numbers. Here are some simplifications. Since $f'((f')^{-1}(x))=x$ differentiation with respect to $x$ gives $f''((f')^{-1}(x))\cdot\frac{d}{dx}(f')^{-1}(x)=1$ . Consequently, $$f''((f')^{-1}(x))\cdot (f')^{-1}(x)=\frac{1}{\frac{d}{dx}(f')^{-1}(x)}\cdot(f')^{-1}(x)=\frac{d}{dx}\log{(f')^{-1}(x)}.$$ The graph of $f$ is represented below.","['calculus', 'functions', 'real-analysis']"
3531497,Gauss-like product $\prod_{k=1}^{(p-1)/2}\csc\frac{\pi k^2}p$,"Let $p$ be an odd prime. Denote $$S_p=\frac{\sqrt p}{2^{(p-1)/2}}\prod_{k=1}^{(p-1)/2}\csc\frac{\pi k^2}p.$$ I conjecture that: (i) For $p\equiv1\pmod4$ , $S_p$ is the fundamental unit of field $\mathbb Q[\sqrt p]$ . (ii) For $p\equiv3\pmod4$ , $S_p=\pm1$ . Can we prove or disprove them? Moreover, (iii) can we calculate the sign of $S_p$ when $p\equiv3\pmod4$ ? I have made some progress proving (ii). When $p\equiv3\pmod4$ , $$S_p^2=\frac{p}{2^{p-1}}\left(\prod_{k=1}^{(p-1)/2}\csc\frac{\pi k^2}p\right)^2$$ Using some basic facts in number theory, we know $\pm k^2\bmod p$ runs over $1$ to $p-1$ when $k=1,\ldots,(p-1)/2$ . Therefore we have $$S_p^2=\frac{p}{2^{p-1}}\prod_{k=1}^{p-1}\csc\frac{\pi k}p=1.$$ But I have no idea how to solve (i) and (iii).","['number-theory', 'trigonometry', 'algebraic-number-theory', 'products']"
3531559,Solution of the linear differential equation: $\frac {dy}{dx} + P(x) \cdot y=Q(x)$. What is the error in this approach?,"Derive the solution of the linear differential equation: $\frac {dy}{dx} + P(x) \cdot y=Q(x)$ Rewriting the given differential equation, we obtain: $(Py-Q) dx+1 \cdot dy=0$ . Let $M=Py-Q, N=1$ . Then : $\dfrac {\partial M }{\partial y}=M_y=P$ and $\dfrac {\partial N}{\partial x}=N_x=0$ . Thus $\dfrac{M_y-N_x}{N}=P(x)$ . Thus, the integrating factor is $I.F= e^{\int P dx}$ . Therefore $e^{\int P dx}(Py-Q) dx+e^{\int P dx} \cdot dy=0$ is an exact differential equation. The solution of this exact differential equation is $\int_{\text {treat y as constant} } M dx + \int \text{terms in N not containing x}~~ dy= $ constant $\implies \int e^{\int P dx}(Py-Q)~ dx + 0=c$ $\implies y \int P~ e^{\int P dx}~dx = \int e^{\int P dx} Q ~dx + c.~$ But the solution of the differential equation in almost every textbook is given as $\implies y e^{\int P dx}~dx = \int e^{\int P dx} Q ~dx + c$ What is the error in the above steps. Thanks a lot for your help.",['ordinary-differential-equations']
3531591,Measurability of intermediate variable in the application of the mean-value theorem,"To prove the differentiability of a function of the form $$g(x) = \int f(t,x)dt$$ where $f:\mathbb{R}^2\rightarrow \mathbb{R}$ is $C^1$ in the second variable I sometimes see applications of the mean-value theorem as follows: Let $h\in \mathbb{R}$ and define $\varphi_t(s) = f(t,x+sh)$ . Then by the mean-value theorem $\varphi_t(1)-\varphi_t(0) = \varphi_t'(\xi(t)) = \partial_xf(t,x+\xi(t) h)h$ where $\xi(t)$ lies between $0$ and 1. Therefore \begin{align*}
\frac{g(x+h)-g(x)}{h} = \int \frac{f(t,x+h)-f(t,x)}{h}dt = \int \partial_xf(t,x+\xi(t)h)dt.
\end{align*} So for instance if we assume som integrability condition on $\partial_x f(t,x)$ (for instance suppose we can find an integrable majorant) then by Lebesgue's dominated convergence theorem $g$ is differentiable with derivative $$g'(x) = \int \partial_x f(t,x)dt.$$ Now what I wonder is if the function $\xi(t)$ appearing in the application of the mean-value theorem is actually measurable? As far as I understand its existence is only a consequence of the fact that a continuous function on a compact set has a maximum and a minimum, since this is how one shows Rolle's theorem which one can then use to prove the mean-value theorem. If $\xi$ is not uniquely defined one must apply the axiom of choice when defining the function right? The measurability of $\xi(t)$ is not vital for the differentiation: Since $$\partial_xf(t,x+\xi(t)h) = \frac{f(t,x+h)-f(t,x)}{h}$$ and since the right-hand side is measurable we find that $t\mapsto \partial_xf(t,x+\xi(t)h)$ is measurable. Supposing there exists some integrable function $F(t)\geq 0$ such that $\partial_xf(t,x)\leq F(t)$ for all $x$ then we can take the limit.","['lebesgue-integral', 'calculus', 'derivatives', 'measure-theory']"
3531625,Prove that $\lim_{h\to 0}\frac{e^h-1}{h}=1$ from the functional equation $f(x+y)=f(x)f(y)$.,"If I have that $e^x$ is defined by the unique continuous function $\mathbb R\to \mathbb R^*$ s.t. $f(x+y)=f(x)f(y)$ for all $x,y\in\mathbb R$ and $f(1)=e$ , is it possible to prove that $$\lim_{h\to 0}\frac{e^h-1}{h}=1\ \ ?$$","['functional-equations', 'real-analysis']"
3531662,Is it possible to make an infinite directed acyclic graph with all vertices having a indegree of at least one,"Is it possible to make an infinite directed acyclic graph with all vertices having a indegree of at least one. Since the graph is infinite and all vertices have a indgree of at least one, that would create cycles. Would that make a directed acyclic graph impossible to be infinite, and would always have to be finite to work?","['graph-theory', 'discrete-mathematics']"
3531708,"Show that a set is compact on $C^K[0,1]$","Show that the set of the functions $A_M:=\{f ∈ C^{k+1}([0, 1]) : \|f\|_{C^{K+1}} ≤ M\}$ is compact in $C^{k}[0,1]\ \  \forall M \geq 0$ . N.B.: $$\| f\|_{C^{K+1}}=\|f\|_{C^{0}}+\|f^{(k+1)}\|_{C^{0}}$$ I started by showing that $C^{k}[0,1]$ is complete with the $C^{k}$ norm. I'd like to use this to show that the set is complete. Then prove that it is totally bounded and so compact. But I don't have an idea of how to do it... Thanks.",['functional-analysis']
3531732,How to show $\int_{\mathbb{R}}{t \choose x}^2{x \choose t}~dx = 1$,"Let $${ a \choose b } = \frac{\Gamma(a+1)}{\Gamma(b+1)\Gamma(a-b+1)}$$ be the continuous extension of the binomial coefficient to non-integer arguments. I noticed this morning that $$\int_{\mathbb{R}}{t \choose x}^2{x \choose t}~dx = 1$$ For all real $t \geq0$ . I tried to simplify the integrand according to the propeties on the MathWorld page for the gamma function, though I don't see where to apply even the reflection formula to: $$\int_{\mathbb{R}}\frac{\Gamma(t+1)}{\Gamma(x+1)\,\Gamma(t-x+1)^2\,\Gamma(x-t+1)}~dx$$ To show that the above equals $1$ . I couldn't find many similar questions on MSE about these sorts of integrals and am unfamiliar with how to approach them, so I bring this one here.","['integration', 'binomial-coefficients', 'definite-integrals', 'gamma-function']"
3531779,Any 3 (or maybe more) random numbers given shall always be in Arithmetic Progression?,"I encountered the question given below in I.M. Gelfand's book. Is it possible that numbers $\frac{1}{2}, \frac{1}{3}, \frac{1}{5}$ are (not necessarily adjacent) terms of the same arithmetic progression?
  Hint: Yes. Try $\frac{1}{30}$ as a difference. The question has already been asked here. I was going through the answers and found this one very interesting. According to the above answer we have to find the G.C.D in order to get the d. Now my question is: - We can always find the G.C.D of any given number of numbers. So
  whenever we encounter such question (mentioned above) we can blindly
  say that they are in A.P. ? or does an example exist which proves my
  theory wrong? [the theory being that any given random numbers (not
  necessarily being adjacent terms of A.P.) shall always be in A.P.]","['algebra-precalculus', 'sequences-and-series']"
3531843,"Triangle $ABC$, with $M$ the midpoint of $BC$, $\angle BAM=\angle C$, and $\angle MAC=15^\circ$. Find $\angle C$","In triangle $ABC$ , $M$ is the midpoint of $BC$ , $\angle BAM=\angle C$ , $\angle MAC=15^{\circ}$ , what is $\angle C$ ? I've been stuck on this question for awhile now. What I've tried so far: I let $BM=MC=a$ and $AM=b$ , then applied Law of Sines on $\triangle BAM$ and $\triangle AMC$ to get: $$\frac{a}{\sin x}=\frac{b}{\sin(165^{\circ}-2x)}$$ $$\frac{a}{\sin 15^{\circ}}=\frac{b}{\sin x}$$ and manipulated this equations to end up with: $$\sin^2 x=\sin(165^{\circ}-2x)\cdot \sin 15^{\circ}$$ but I don't know what to do with this equation. Maybe I'm going in the wrong direction with trig...?","['trigonometry', 'angle', 'triangles']"
3531845,What are the necessary and sufficient conditions on a function between two topological spaces such that it satisfies the following property?,"Let $(X,\tau_X)$ and $(Y,\tau_Y)$ be two topological spaces and $f:X\to Y$ is a function such that for all $A,B\subseteq X$ , $$f(A)\subseteq \overline{f(B)} \implies A\subseteq \overline{B}$$ where $\overline{f(B)}$ denotes the closure of $f(B)$ in $f(X)$ and $\overline{B}$ denotes the closure of $B$ in $X$ . My Questions Does there exist any standard name for these type of functions? If $f$ is continuous, then what other conditions on $f$ are sufficient such that it satisfies the above property? Are the conditions also necessary? My Attempt I already tried asking the question here , however, as you can see I got no response.","['general-topology', 'terminology']"
3531854,"periodic function, find g(6)","If $f$ is periodic, $g$ is polynomial function, $f(g(x))$ is periodic, $g(2)=3$ , and $g(4)=7$ , then $g(6)$ is A) 13 B) 15 C) 11 D) none of these The answer is c) 11, but I did not understand how $g(x)$ was considered linear polynomial (because i got answer when $g(x)$ is $2n -1$ ), isn't there any $g(x)$ with degree greater than 1 make $f(g(x))$ periodic?
Why? How will you solve the problem?","['functions', 'polynomials']"
3531876,Omega Notation in Explanation of Chain Rule,"In his book Multivariate Calculus and Geometry, Sean Dineen explains the chain rule as follows: I understood well enough his point but, then he goes on to introduce an unknown and unexplained $\omega$ to explain something having to do with the unit basis:","['notation', 'multivariable-calculus', 'ordinals']"
3531961,"Prove that $\tan x \geq x + \frac{x^3}{3}$ for $x \in [0, \frac{\pi}{2})$ [duplicate]","This question already has answers here : For $0 < x < \pi/2 $, prove that $x + \frac{x^{3}}{3} <\tan x $ (3 answers) Closed 4 years ago . I am teaching someone basic real analysis. Working through the past exams, they've found the following problem: Prove that $\tan x \geq x + \dfrac{x^3}{3}$ for $x \in \left[0, \dfrac{\pi}{2}\right)$ . What's the simplest way to prove it? I've found two possible solutions, but both seem too complex for the course level: Use Taylor expansion of the $\tan$ function. While Taylor series were covered in the course, this specific one was not. Plug $x = \arctan y$ , and prove that $f(y) = y - \arctan y - \dfrac{\arctan^3 y}{3}$ is monotonically increasing through derivation.
This works, but it's also fairly tricky. Is there a simpler solution that I am missing?","['trigonometry', 'inequality', 'real-analysis']"
3532163,Memorylessness of the geometric distribution: Why are my equations wrong?,"I was trying to get used to the memorylessness of the geometric distribution and came up with the following (flawed) equations: If $X$ is a geometric random variable with parameter $p$ , we have \begin{align*}
p &= 1 - (1-p)\\
&= 1 - \text{Pr}[X\geq 2] \\
&= 1 - \text{Pr}[X\geq k + 2 \mid X \geq k ] \\
&= \text{Pr}[X < k + 2 \mid X \geq k].
\end{align*} This should be correct. However, when we now compute the conditional probability, we obtain \begin{align*}
p &= \text{Pr}[X < k + 2 \mid X \geq k] \\
&= \frac{\text{Pr}[X < k+2 \cap X \geq k]}{\text{Pr}[X \geq k]} \\
&= \frac{\text{Pr}[X = k \cup X = k+1]}{\text{Pr}[X \geq k]} \\
&= \frac{\text{Pr}[X = k] + \text{Pr}[X = k+1]}{\text{Pr}[X \geq k]} \\
&= \frac{p\cdot(1-p)^{k-1} + p \cdot (1-p)^k}{(1-p)^{k-1}} \\
&= p + p \cdot (1-p),
\end{align*} which is of course wrong, unless $p = 1$ or $p = 0$ . Where did I make a mistake?","['probability-distributions', 'probability-theory']"
3532173,Recursive Si integral $I_{n+1}=\int^{I_{n}}_{0}\frac{\sin x}{x}dx$,I have seen this problem somewhere on the internet but I could not prove it. Let $$I_{0}=\int^{\infty}_{0}\frac{\sin x}{x}dx$$ and then define $$I_{n+1}=\int^{I_{n}}_{0}\frac{\sin x}{x}dx.$$ Show that $$\lim_{n\rightarrow\infty}\sqrt{n}\ I_{n}=3.$$,"['integration', 'calculus', 'analysis']"
3532180,Are all almost regular languages regular?,"Let’s define a randomized acceptor as a tuple $V = (A, Q, \Omega, \mathfrak{F}, P, \phi, q_i, Q_t)$ , where $A$ is the input alphabet , $Q$ is the set of states , $(\Omega, \mathfrak{F}, P)$ is a probability space, $\phi: Q \times A \times \Omega \to Q$ is the transition function and $q_i \in Q$ is the initial state and $Q_t \subset Q$ are the terminal states accordingly. We will call $V$ finite iff both $A$ and $Q$ are finite. Let’s extend the transition function $\phi$ from $Q \times A \times \Omega$ to $Q \times A^* \times \Omega$ using the recurrence formulas: $$\phi(q, \Lambda, \omega) = q$$ $$\phi(q, \alpha a, \omega) = \phi(\phi(q, \alpha, \omega), a, \omega) \forall a \in A \alpha \in A^*$$ Now define the acceptance probability of a word $w \in A^*$ in $V$ as $P_V(w) := P(\{\omega \in \Omega| \phi(q_i, w, \omega) \in Q_t)$ . Using this we can define for an arbitrary language $L \subset A^*$ the absolute error of $V$ in respect to it as $Err(V, L) := sup\{|P_V(w) - \mathbb{I}_V(w)| | w \in A^* \}$ .
Let’s call a formal language $L \subset A^*$ almost regular iff $\forall \epsilon > 0$ $\exists$ a finite randomized acceptor $V$ such that $Err(V, L) < \epsilon$ . It is not hard to see, that all regular languages are almost regular. Bug is the converse true? Or does there exist an almost regular formal language, which is not regular?","['regular-language', 'probability', 'automata', 'discrete-mathematics', 'formal-languages']"
3532201,Prove $\sin x + \arcsin x > 2x$ using Maclaurin series,"My teacher asked us to solve this problem using the Maclaurin series, but I could not figure out how to approach.. Prove that the inequality sin x + arcsin x > 2x holds for all values of x such
that 0 < x ≤ 1. I know that the Maclaurin series of 
sin(x) = x - $\frac{x^3}{3!}$ + $\frac{x^5}{5!}$ - $\frac{x^7}{7!}$ + ... arcsin(x) = x + $\frac{1}{2}\cdot\frac{x^3}{3}$ + ( $\frac{1}{2}\cdot\frac{3}{4}$ ) $\cdot\frac{x^5}{5}$ + ... However, I do not know how to prove this using there series...Could anyone have some ideas? Thank you!","['inequality', 'calculus', 'taylor-expansion', 'sequences-and-series', 'trigonometry']"
3532292,"If $\alpha=\sqrt[3]{2}$ and $p,q,r\in\mathbb{Q}$ then show $p+q\alpha+r\alpha^2$ is a subfield of $\mathbb{C}$","If $\alpha=\sqrt[3]{2}$ and $p,q,r\in\mathbb{Q}$ then show $p+q\alpha+r\alpha^2$ is a subfield of $\mathbb{C}$ . For context, this is number $5$ in Chapter $1$ of Ian Stewart's Galois Theory. At this point in the text, we have only learned how to solve cubics and quartics, while introducing subring and subfield language. First to show $$R=\{p+q\alpha+r\alpha^2: p,q,r\in\mathbb{Q} \wedge \alpha=\sqrt[3]{2}\}$$ is a subfield  we show $R$ is a subring of $\mathbb{C}$ and then finish by showing $\forall x\in R,  \exists x^{-1}\in R$ . Note that clearly $R\subset\mathbb{C}$ since $p+q\alpha+r\alpha^2$ is a real number for all rational $p,q,r.$ Take $p=1,q=0,r=0$ to see $1\in R$ . If $p_1+q_1\alpha+r_1\alpha^2\in R$ and $p_2+q_2\alpha+r_2\alpha^2\in R$ , then $$\left(p_1+q_1\alpha+r_1\alpha^2\right)+\left(p_2+q_2\alpha+r_2\alpha^2\right)=\left(p_1+p_2\right)+\left(q_1+q_2\right)\alpha+\left(r_1+r_2\right)\alpha^2\in R$$ $$-(p_1+q_1\alpha+r_1\alpha^2)=-p_2-q_2\alpha-r_2\alpha^2\in R$$ $$\left(p_1+q_1\alpha+r_1\alpha^2\right)\left(p_2+q_2\alpha+r_2\alpha^2\right)$$ $$=\left(p_1p_2+2q_1r_2+2q_2r_1\right)+\left(p_1q_2+p_2q_1+2r_1r_2\right)\alpha+\left(p_1r_2+q_1q_2+p_2r_1\right)\alpha^2\in R$$ The preceding argument follows from the facts that the rationals are closed under addition and multiplication. The above also shows $R$ is a subring of $\mathbb{C}$ . To complete the proof that $R$ is a subfield , we find an expression for the inverse $$(p_1+q_1\alpha+r_1\alpha^2)^{-1}$$ Here is where I run into issues. My first thought was to set the product $\left(p_1+q_1\alpha+r_1\alpha^2\right)\left(p_2+q_2\alpha+r_2\alpha^2\right)$ equal to $1$ : $$\left(p_1+q_1\alpha+r_1\alpha^2\right)\left(p_2+q_2\alpha+r_2\alpha^2\right)=1\implies$$ $$p_1p_2+2q_1r_2+2q_2r_1=1$$ $$p_1q_2+p_2q_1+2r_1r_2=0$$ $$p_1r_2+q_1q_2+p_2r_1=0$$ which is equivalent to $$\begin{pmatrix}
p_2&2r_2&2q_2\\ q_2&p_2&2r_2\\r_2&q_2&p_2\end{pmatrix}\begin{pmatrix}p_1\\q_1\\r_1\end{pmatrix}=\begin{pmatrix}1\\0\\0\end{pmatrix}$$ If I could find an explicit inverse for the above $3\times3$ matrix, the problem would be solved yielding exact expressions for $p_1,q_1, r_1$ in terms of $p_2,q_2,r_2$ . However, I am not seeing a way to guarantee the determinant is nonzero for as long as $p_2,q_2,r_2\neq0$ . I noticed the matrix is Toeplitz, but I don't know if that tells us anything about invertibility. Any help with finding the inverse element here without resorting to high power machinery in these answers Describe the subfields of $\mathbb{C}$ of the form: $\mathbb{Q}(\alpha)$ where $\alpha$ is the real cube root of $2$. and How to show that $\mathbb{Q}(\alpha) = \left\{ p+q\alpha+r\alpha^2 \mid p, q, r\in \mathbb{Q} \right\}$, where $\alpha$ is the real cube root of $2$? is much appreciated.","['abstract-algebra', 'linear-algebra']"
3532329,Proof verification: Closed under countable union,"Let $\Omega$ be countable. Let $\{A_i\}_{i \in \mathbb{N}}$ be a countable collection of subsets of $\Omega$ . Want to show $\bigcup_{n=1}^\infty A_n \subseteq \Omega$ . I just want to check the soundness of my argument below: If $x \in \bigcup_{n=1}^\infty A_n $ , then $\exists$ $n \in \mathbb{N}$ such that $x \in A_n$ . But since $A_n \subseteq \Omega$ , we have that $x \in \Omega$ . Hence, $\bigcup_{n=1}^\infty A_n \subseteq \Omega$ . Similar Question","['elementary-set-theory', 'measure-theory']"
3532362,Does Lyapunov stability imply that the Lyapunov function is monotonically decreasing?,"Suppose we have a system $$\dot x = Ax$$ And a Lyapunov function $$V (x(t)) \geq 0, \forall t $$ My question is, does the fact $\dot V(x) = \nabla V(x)^\top \dot x < 0$ imply that $V(x(t))$ is monotonically decreasing along with time? Ok, so intuitively, integrating bothsides we have $V(x(t)) < V(x(0))$ , $\forall t$ . So it is decreasing relative to the initial time. But what about the time afterwards, can we guarantee $V(x(t_2)) < V(x(t_1)) $ where $t_2>t_1>0$ ?","['lyapunov-functions', 'ordinary-differential-equations', 'dynamical-systems']"
3532371,Find the variance of $R$ where $R$ = $Z_1 + \dotsb + Z_d$ and $Z_i = |X_i - Y_i|^2$,"So I am trying to find the Variance $R$ where $R$ = $Z_1 + \dotsb + Z_d$ and $Z_i = |X_i - Y_i|^2$ $X$ and $Y$ are d-dimensional points from a d-dimensional unit cube with a uniform distribution: $X,Y \in [0,1]^d$ which we can view this as drawing random
variables $X_1, . . . , X_d$ and $Y_1, . . . , Y_d$ independently and uniformly from $[0, 1]$ Assuming that this is correct: \begin{align*}
R &= Z_1 + \dotsb+ Z_d\\
&= d  \cdot Z \\
R^2 &= d^2 \cdot Z^2\\
E[R^2] &= d^2 \cdot E[Z^2]\\
&=\frac{12d^2}{180}\\
&=\frac{d^2}{15}
\end{align*} and with the information from: Expectation and variance of the squared distance between $X$ and $Y$ I was able to get to: \begin{align*}
Var(R) &= E[R^2]-(E[R])^2\\
&=\frac{d^2}{15}-\frac{d^2}{36}
\end{align*} Is this even correct? Or did I make a mistake along the way","['expected-value', 'statistics', 'uniform-distribution', 'variance']"
3532377,Orthogonality with respect to a matrix,"Consider two vectors $x\in\mathbb{R}^n$ and $y\in\mathbb{R}^n$ . Obviously, $x^\top y = 0$ implies that $x$ and $y$ are orthogonal. Now, let $A\in\mathbb{R}^{n \times n}$ be a matrix. What is the meaning of $$x^\top A y = 0$$ ? Does this imply orthogonality of $x$ and $y$ with respect to something?","['matrices', 'linear-algebra', 'analysis', 'eigenvalues-eigenvectors']"
3532408,What exactly is the relationship between the concepts of conjugate complex vector space and conjugations/real structures?,"I started studying the book of Daniel Huybrechts, Complex Geometry An Introduction. I tried studying backwards as much as possible, but I have been stuck on the concepts of almost complex structures and complexification . I have studied several books and articles on the matter including ones by Keith Conrad , Jordan Bell , Gregory W. Moore , Steven Roman , Suetin, Kostrikin and Mainin , Gauthier I have several questions on the concepts of almost complex structures and complexification. Here is one: Assumptions, notations and what I understand so far : Let $V$ be a $\mathbb C$ -vector space. Let $W$ be an $\mathbb R$ -vector space. Let $V_{\mathbb R}$ be the realification of $V$ . For any almost complex structure $I$ on $V_{\mathbb R}$ , denote by $(V_{\mathbb R},I)$ as the unique $\mathbb C$ -vector space whose complex structure is given $(a+bi) \cdot v := av + bI(v)$ . Let $i^{\sharp}$ be the unique almost complex structure on $V_{\mathbb R}$ such that $V=(V_{\mathbb R},i^{\sharp})$ . Let $W^{\mathbb C}$ denote the complexification of $W$ given by $W^{\mathbb C} := (W^2,J)$ , where $J$ is the ' canonical ' almost complex structure on $W^2$ given by $J(v,w):=(-w,v)$ . The map $\chi: W^2 \to W^2$ , $\chi(v,w):=(v,-w)$ is such that $\chi^J: W^{\mathbb C} \to W^{\mathbb C}$ , which is $\chi$ now viewed as a map on $W^{\mathbb C}$ instead of $W^2$ , is the 'canonical' conjugation/real structure . Here, 'canonical' is meant in the sense that we would use $J$ and $\chi$ to define complexifications of $W$ and of elements of $End_{\mathbb R}(W)$ . (See here .) Then the complex conjugate of $V$ is defined $\overline V := (V_{\mathbb R},-i^{\sharp})$ . Question : What exactly is  the relationship between the concept of $\overline V$ , the conjugation of $V$ and the concept of conjugations/real structures on $V$ ?","['complex-geometry', 'complex-analysis', 'abstract-algebra', 'linear-algebra', 'almost-complex']"
3532438,Integral of Poisson Bracket vanishes,"This arose when reading a text on linear PDE. It is a step in an argument that I am not sure how to justify. Let $(M, g)$ be a smooth compact Riemannian manifold and $p(x, \xi) = |\xi|_g= \sqrt{g^{ij}(x) \xi ^i \xi ^j}$ be a smooth function on $T^*M \setminus 0$ and $\omega = d\xi \wedge dx$ the canonical symplectic form. Suppose that $ b \in C^\infty (T^*M \setminus 0)$ and fix $\lambda > 0$ . Is it necessarily true that $$\int_{p < \lambda}\{p, b \} dx d\xi = 0$$ Here $\{p, b\}$ denotes the Poisson bracket and I presume that $dx d\xi = \omega ^n$ . I tried to integrate by parts but it didn't seem to work.","['symplectic-geometry', 'differential-geometry']"
3532529,Is differentiability defined at an isolated point of the function's domain?,"Say we have the function $f:(0,1)\cup\{2\}\rightarrow \mathbb R$ defined by $f(x)=5$ . Is $f$ differentiable or not differentiable (or neither) at $2$ ? Is $f$ a differentiable function?","['derivatives', 'real-analysis']"
