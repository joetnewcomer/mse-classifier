question_id,title,body,tags
413304,Strange integral in 3 space (Maybe Divergence Theorem),"I'm trying to find something called the density of states and the model that I am using specifies $$E = \frac{h^2}{2 m} k^2$$ where $k = |\bf{k}|$. The quantity I am trying to calculate is $$D(E) = \int{(\nabla_k E)^{-1} \mathrm{d}E}$$. I think how to simplify this is to substitute $$\mathrm{d}E = \frac{h^2}{m} \mathrm{d}k$$ and $$\nabla_k E = \nabla_k [\frac{h^2}{2 m} (k_x^2 + k_y^2 + k_z^2)].$$ Therefore, $$\nabla_k E = \frac{h^2}{m}(k_x, k_y, k_z).$$ However this leaves me with $$D(E) = \int{\frac{1}{(k_x, k_y, k_z)} \mathrm{d}k},$$ which I am sure how to solve. Any idea how to solve this with a vector in the denominator? Edit I realized that $D(E) = \int{(\nabla_k E)^{-1} \mathrm{d}E}$ is actually $$D(E) = \int{(\nabla_k E)^{-1} \mathrm{d}\bf{S}}.$$","['multivariable-calculus', 'physics']"
413308,Problems using Euler-Maclaurin for $\sum e^{-2 \pi z a^2}$,"I'm trying to evaluate $\sum_{a=-\infty}^{\infty} e^{-2 \pi z a^2}$ using Euler-Maclaurin, but I get $\frac{1}{\sqrt{2z}}$. The only alternative I have is to calculate the remainder term directly for a small level of approximation, but I don't want to do this if there's a simple mistake I'm making and fixing it would let me avoid doing so, or if for some reason Euler-Maclaurin doesn't work at all. SUMMARY: By Euler-Maclaurin, we have: $\sum_{a=-\infty}^{\infty}e^{-ca^2}-\int_{-\infty}^{\infty} e^{-ca^2} da = \sum_{k=2}^{\infty} \frac{b_k}{k!}(e^{-cx^2})^{(k-1)'}\vert_{-\infty}^{\infty}$, where $b_k=B_k(0)$ are the Bernoulli numbers. Implicitly, the remainder term (due to the large factorial) and the halved endpoints of the sum (due to $e^{-ca^2}$ vanishing in the infinite limits) vanish. First, observe $\frac{d^n}{da^n}e^{-c a^2}$ is of the form $e^{-c a^2}p(a)$ for a polynomial $p$. (1) Secondly, observe that $lim_{a \rightarrow \infty} \frac{p(a)}{e^{c a^2}} = 0$ for any polynomial $p$ and constant $c \gt 0$. (2) Thirdly, observe that $e^{-ca^2}$ is even, and hence its odd derivatives (the derivatives taken for even $k$) are odd, and its even derivatives (odd $k$) are even. The latter implies that for odd $k$, $(e^{-cx^2})^{(k-1)'}\vert_{-\infty}^{\infty}$ vanishes, and for even k, $(e^{-cx^2})^{(k-1)'}\vert_{-\infty}^{\infty} = 2 \lim_{a \rightarrow \infty} (e^{-cx^2})^{(k-1)'}(a) = 2 \lim_{a \rightarrow \infty} e^{-ca^2}p(a) = 0.$ Therefore all terms of the series vanish, implying $\sum_{n=-\infty}^{\infty}e^{-cx^2} = \int_{-\infty}^{\infty} e^{-cx^2} da = \frac{\sqrt{\pi}}{\sqrt{c}}$, and in this case $\frac{\sqrt{\pi}}{\sqrt{2 \pi z}} = \frac{1}{\sqrt{2z}}.$ DETAILS: (1) follows by induction from $\frac{d}{da}e^{-ca^2}p(a) = e^{-ca^2}(\frac{d}{da}p(a)-2ca\ p(a)),$ which is of the form $e^{-ca^2}p(a)$. Proof of (2):
$\frac{\frac{d}{dx}a^n}{\frac{d}{dx}e^{c a^2}} = \frac{a^{n-1}}{2cae^{c a^2}} = \frac{a^{n-2}}{2ce^{c a^2}}, \implies \frac{\frac{d^m}{dx^m}a^n}{\frac{d^m}{dx^m}e^{c a^2}} = \frac{a^{n-2m}}{(2c)^m e^{ca}}, \implies lim_{a \rightarrow \infty} \frac{a^n}{e^{c a^2}} = 0 \implies lim_{a \rightarrow \infty} \frac{p(a)}{e^{c a^2}} = 0$ I have also derived an explicit formula for the derivatives from Faà di Bruno's formula together with $\frac{d^n}{dx^n}f(cx)=c^nf^{(n)}(cx)$, which yields a polynomial multiple of $e^{-ca^2}$, which by (2) vanishes in the limit, and is again even for even derivatives and odd for odd ones.","['sequences-and-series', 'modular-forms', 'euler-maclaurin']"
413316,Modules which are isomorphic to their tensor product.,"Suppose that we have a commutative ring $R$. I am interested in finding the (finitely generated and projective, if you want) $R$-modules $M,$ such that $M\cong M\otimes_R M$ as $R$-modules. I know that it is true for $M=R$ or when $M$ is generated by a finite  set of orthogonal  idempotents. I want to know if whether or not those are all the modules which that property. Thanks.","['modules', 'commutative-algebra', 'projective-module', 'abstract-algebra']"
413319,Hilbert's 17th Problem - Artin's proof,"In this expository article, it is mentioned that Emil Artin proved Hilbert's 17th problem in his paper: E. Artin, Uber die Zerlegung definiter Funktionen in Quadrate, Abh.
  math. Sem. Hamburg 5(1927), 110–115. Not being able to speak German, my question is Does anyone know if English translation of this paper exists somewhere? Or perhaps some link to a book (or article, blog post, etc.) where this proof is given in English? My google searches have been in vain. Note that I am only interested in Artin's proof. (There is a algorithmic proof due to Dellzel, which is in English). Thanks! P.S. I have previously asked for English translation of another paper by E. Artin.","['rational-functions', 'reference-request', 'abstract-algebra']"
413342,Find the coefficient using binomial theorem.,What is the coefficient of $x^{20}$ in the expression: $$(x+1)^{10}.(x^2 -1)^8$$,"['algebra-precalculus', 'binomial-coefficients']"
413345,Finding the number of solutions of a complex valued function $f(z) = z^n$,"This past semester I took a graduate course in complex analysis which I completed moderately well in spite of my expectations (that is I honestly think I deserved a lower grade than I received). I had one assigned question which caused me to join MSE on the subject of Rouché's theorem. This problem comes from Chapter 5 section three of Conway's Functions of a single Complex Variable, the section is on the Argument Principle and Rouché's theorem.
The problem is number 2 of this chapter and proceeds as such: ""Suppose $f$ is analytic on $\bar B(0 ; 1) $ and satisfies $\left| f(z) \right|<1 $ for $ |z|=1$. Find the number of solutions (counting multiplicities) of the equation $f(z) = z^n$ where $n$ is an integer larger than or equal to $1$."" Now my question isn't about solving this problem but more of a hint at where to start. As I understood Rouché's theorem, I am required to compare two functions, say $f$ and $g$, so I can compare the number of poles and zeroes. Every example I could find on MSE however included an equation with more than one term and seemed (at least to me) easier than the one I was given. I unfortunately do not have any work of my own to provide as I was definitely stumped. Any discussion of this will help, or references to MSE questions I might have missed would be greatly appreciated",['complex-analysis']
413371,Why is the operator $2$-norm of a diagonal matrix its largest value?,"I read this in my textbook have tried working through it - I keep getting max 2-norm(Ax), which is just the magnitude of Ax. How should I do this proof? (note, this is not for homework, I'm just trying to understand why as no proof is provided).","['matrix-norms', 'matrices', 'normed-spaces', 'linear-algebra', 'spectral-norm']"
413394,How to calculate this volume?,"Be the sets: $$C:= \lbrace (x,y,0)\in\mathbb{R}^{3}: (x-1)^2+y^2=1\rbrace$$ $$C':= \lbrace (x,0,z)\in\mathbb{R}^{3}: (x+1)^2+z^2=1\rbrace $$ $$\overline{C}= \lbrace tx+(1-t)x': x\in C, x' \in C', t\in [0,1]\rbrace$$ Calculate the volume of $\overline{C}$. 
I drawed the sets $C$ and $C'$, but I can't see how is the set $\overline{C}$","['multivariable-calculus', 'calculus', 'volume']"
413396,help understanding step in derivation of correlation coefficient,"I'm looking to understand the starred step in the derivation below (also, if someone could help with the LaTex alignment, I'd appreciate it). The regression line is $y= b_0 + b_1 x$, where $b_0$ and $b_1$ can be found by: 1) taking the difference between each observed value $y_i$ and the expected point regression line, $b_0 + b_1 x_i$
$$\text{ difference } = y_i - b_0 -b_1 x_i$$ 2) summing the square of the differences from 1) to get the sum of squares
$$SS = \sum \limits_{i=1}^n (y_i - b_0 -b_1 x_i)^2$$
3) taking the partial derivative with respect to $b_0$ and $b_1$, then solving for each
$$
\begin{align}
\text{ solving for } b_0 \\
SS &= \sum(y_i - b_0 -b_1 x_i)^2\\
SS &= \sum (Y_i ^2 - 2Y_i b_0 - 2 Y_i b_1+ 2b_0 b_1X_i + b_1^2X_i^2+b_0^2) &\text{expand the square}\\
\frac{ \partial }{\partial_{b_0} }SS &= \sum (-2Y_i + 2b_1 X_i + 2b_0) &\text{partial derivative wrt} b_0\\
0 &= \sum 2(-Y_i + b_1 X_i + b_0) &\text{factor out 2 from the sum}\\
0 &= \sum (-Y_i + b_1 X_i + b_0) &\text{divide both sides by 2}\\
0 &= \sum -Y_i + \sum b_1 X_i + \sum b_0 &\text{split summation into parts}\\
\sum Y_i &= \sum b_1 X_i + \sum b_0 \\
\sum Y_i &= b_1 \sum X_i + n b_0 \\
\frac{1}{n}(\sum Y_i - b_1 \sum X_i ) &=  b_0 \\
\bar Y - b_1 \bar X &=  b_0 \text {  rewrite sums as averages since } \frac{1}{n} \sum Y_i = \bar Y\\
\end{align}
$$ $$
\begin{align}
\\
\text{solving for } b_1\\
\frac{ \partial }{\partial_{b_1} }SS &= \sum (-2Y_iX_i + 2b_0 X_i + 2 b_1 X_i^2) &\text{ partial derivative wrt } b_1\\
0 &= 2\sum (-Y_iX_i + b_0 X_i +  b_1 X_i^2) \\
0 &= \sum (-Y_iX_i + b_0 X_i +  b_1 X_i^2) \\
0 &=  -\sum Y_iX_i + b_0 \sum X_i +  b_1 \sum X_i^2 &\text{ split summation}\\
0 &=  -\sum Y_iX_i + (\bar Y - b_1 \bar X) \sum X_i +  b_1 \sum X_i^2 &\text{ substitue } b_0\\
0 &=  -\sum Y_iX_i + (\bar Y \sum X_i - b_1 \bar X \sum X_i)  +  b_1 \sum X_i^2 &\text{ distribute sum}\\
b_1 \bar X \sum X_i - b_1 \sum X_i^2 &=  -\sum Y_iX_i + \bar Y \sum X_i     &\text{ collect } b_1 \text{ terms}\\
b_1 (\bar X \sum X_i - \sum X_i^2) &=  -\sum Y_iX_i + \bar Y \sum X_i   \\
b_1  &= { \bar Y \sum X_i -\sum Y_iX_i \over (\bar X \sum X_i - \sum X_i^2)   }\\
b_1  &= { \frac{1}{n} \sum Y_i \sum X_i -\sum Y_iX_i \over (\frac{1}{n} \sum X_i \sum X_i - \sum X_i^2)   } \biggr ( \frac{-n}{-n} \biggr )\\
b_1  &= { n \sum Y_iX_i - \sum Y_i \sum X_i   \over n \sum X_i^2 -(\sum X_i)^2     } \\
\end{align}
$$ $$
\begin{align}
b_0 &= \frac{1}{n} \sum y_i - b_1 \frac{1}{n} \sum x_i\\\\\\
b_1 &= {n \sum x_i y_i - \sum x_i \sum y_i \over n \sum x_i^2-(\sum x_i)^2}
\end{align}
$$
(derivation shown in http://polisci.msu.edu/jacoby/icpsr/regress3/lectures/week2/5.LeastSquares.pdf ) From this point you can use $b_1$ to get the correlation coefficient as follows: $$
\begin{align}
b_1 &= {\frac{1}{n} \sum x_i y_i - (\frac{1}{n}\sum x_i) (\frac{1}{n} \sum y_i ) \over (\frac{1}{n} \sum x_i^2) -(\frac{1}{n}\sum x_i)^2}  & \text{ divide top and bottom by } n^2 \\\\
b_1 &= {\frac{1}{n} \sum x_i y_i - (\bar x) (\bar y ) \over (\frac{1}{n} \sum x_i^2) -(\bar x)^2}  & \text{ rewrite product of sums as averages }  \\\\
b_1 &= {\frac{1}{n} \sum (x_i - \bar x)(y_i - \bar y ) \over \frac{1}{n} \sum (x_i - \bar x)^2}  & \color{red} *\text{application of inscrutably arcane magic} \\\\
b_1 &= { \sum (x_i - \bar x)(y_i - \bar y ) \over \sqrt{\sum (x_i - \bar x)^2} \sqrt{\sum (x_i - \bar x)^2} } & \text{cancel } \frac{1}{n}\text{, factor denominator }\\\\
b_1 &= { \sum (x_i - \bar x)(y_i - \bar y ) \over \sqrt{\sum (x_i - \bar x)^2} \sqrt{\sum ( x_i - \bar x)^2} } \biggr({\sqrt{\sum(y_i - \bar y)^2} \over \sqrt{\sum(y_i - \bar y)^2}}\biggr) & \text{multiply by 1 } \\\\
b_1 &= { \sum (x_i - \bar x)(y_i - \bar y ) \over \sqrt{\sum (x_i - \bar x)^2}  \sqrt{\sum(y_i - \bar y)^2}} \biggr({\sqrt{\sum(y_i - \bar y)^2} \over \sqrt{\sum ( x_i - \bar x)^2} }\biggr) & \text{re-arrange } \\\\
b_1 &= R \frac{S_x}{S_y}
\end {align}
$$","['statistics', 'correlation']"
413404,Proving that the de Moivre-Laplace Theorem is a special case of the Central Limit Theorem.,"I have a problem that I need help on. I want to prove that the de Moivre-Laplace Theorem is a special case of the Central Limit Theorem (note that a binomial random variable is a sum of independent Bernoulli trials). This is what I have tried: Let $ X_{1},X_{2},\ldots,X_{n} $ be Bernoulli trials. If $ S_{n} \stackrel{\text{df}}{=} X_{1} + X_{2} + \cdots + X_{n} $, then
$$
\mathbf{E}[S_{n}] = n \mu \qquad \text{and} \qquad
\mathbf{Var}[S_{n}] = n \sigma^{2},
$$
where $ \mu $ and $ \sigma $ are, respectively, the mean and standard deviation of the $ X_{i} $’s. Standardizing $ S_{n} $, we get $ Z_{n} = \dfrac{S_{n} - n \mu}{\sqrt{n} \sigma} $. However,
$$
\mathbf{E}[S_{n}] = n p \qquad \text{and} \qquad \mathbf{Var}[S_{n}] = n p q,
$$
so $ Z_{n} = \dfrac{S_{n} - n p}{\sqrt{n p q}} $. Applying the Central Limit Theorem, I get the de Moivre-Laplace Theorem. Thanks for your help, and have a nice day.","['probability-limit-theorems', 'probability-theory', 'central-limit-theorem', 'probability-distributions', 'probability']"
413409,Proof of Zassenhaus Lemma,"Lemma 4.52 from Advanced Modern Algebra by Rotman: Given four subgroups $A \triangleleft A^*$ and $B \triangleleft B^*$ of a group G, then $A(A^* \cap B) \triangleleft A(A^* \cap B^*)$ , $B(B^* \cap A) \triangleleft B(B^* \cap A*)$ , and there is an isomorphism $$\frac{A(A^* \cap B^*)}{A(A^* \cap B)} \cong \frac{B(B^* \cap A^*)}{B(B^* \cap A)}$$ Proof We claim that $*(A \cap B^*) \triangleleft (A^* \cap B^*)$ : that is, if $c \in A \cap B^*$ and $x \in A^* \cap B^*$ , then $xcx^{-1} \in A \cap B^*$ . Now $xcx^{-1} \in A$ because $c \in A$ , $x \in A^*$ , and $A \triangleleft A^*$ ; but also $xcx^{-1} \in B^*$ , because $c,x \in B^*$ . Hence, $(A \cap B^*) \triangleleft (A^* \cap B^*)$ ; similarly, $(A^* \cap B) \triangleleft (A^* \cap B^*)$ . Therefore, the subset D, defined by $D = (A \cap B^*)(A^* \cap B)$ , is a normal subgroup of $A^* \cap B^*$ , because it is generated by two normal subgroups. Using the symmetry in the remark, it suffices to show that there is an isomorphism $$\frac{A(A^* \cap B^*)}{A(A^* \cap B)} \rightarrow \frac{A^* \cap B^*}{D}.$$ Define $\phi: A(A^* \cap B^*) \rightarrow (A^* \cap B^*)/D$ by $\phi: ax \rightarrow xD$ , where $a \in A$ and $x \in A^* \cap B^*$ . Now $\phi$ is well-defined: if ax=a'x', where $ax=a'x'$ , where $a' \in A$ and $x' \in A^* \cap B^*$ , then $(a')^{-1}a = x'x^{-1} \in A \cap (A^* \cap B^*) = A \cap B^* \subseteq D$ . Also, $\phi$ is a homomorphism: $axa'x' = a''xx'$ , where $a''=a(xa'x^{-1}) \in A$ (because $A \triangleleft A^*)$ , and so $\phi(axa'x') = \phi(a''xx') = xx'D = \phi(ax)\phi(a'x').$ It is routine to check that $\phi$ is surjective and that $ker \phi = A(A^* \cap B)$ . The First Isomorphism Thoerem completes the proof. I have some problems with seeing that the kernel is $A(A^* \cap B)$ . I understand that any element that belongs to $A(A^* \cap B)$ is of course mapped to the identity. But how do we know that these are the only elements in the kernel? Because we also know that $(A \cap B^*) \subseteq *A^* \cap B^*$ , and any element that belongs to $A(A \cap B^*)$ must also be mapped to the identity, right? Thanks in advance","['group-theory', 'abstract-algebra']"
413414,Let $A$ and $B$ be $n\times n$ matrices. Suppose $A$ is similar to $B$. Prove trace($A$) = trace($B$).,"Let $A$ and $B$ be $n\times n$ matrices. Suppose $A$ is similar to $B$. Prove $\operatorname{trace}(A) = \operatorname{trace}(B)$. I'm not sure where to go on this. So far I have this: If $A$ is similar to $B$, then $B=P^{-1}AP$ and $A=PBP^{-1}$ This implies that: $\operatorname{trace}(B) = \operatorname{trace}(P^{-1}AP)$ and $\operatorname{trace}(A) = \operatorname{trace}(PBP^{-1})$ Not sure where to go from here","['matrices', 'linear-algebra']"
413425,Laplace-Beltrami on a sphere,"I'm trying to compute the Laplace-Beltrami of the function $u(r,\varphi,\theta) = 12\sin(3\varphi)\sin^3(\theta)$ on a unit sphere. Note that $\varphi$ is the azimuth, i.e. $\varphi \in [0,2\pi]$ and $\theta$ the inclination, i.e. $\theta \in [-\frac{\pi}{2},\frac{\pi}{2}]$. For instructive purposes, I'd like to do this step by step. The Laplace-Beltrami of $u$ is defined as $$\Delta u := \mathrm{div} (\mathrm{grad} \; u).$$ Since we're talking about a surface (the sphere), I assume that we should use the surface gradient of $u$, defined as $$\nabla_S u := \nabla u - \vec{n}(\vec{n} \cdot \nabla u).$$ The gradient operator in spherical coordinates is defined as $$\nabla := \frac{\partial }{\partial r} \vec{e_r} + \frac{1}{r} \frac{\partial }{\partial \theta} \vec{e_\theta} + \frac{1}{r\;\sin(\theta)} \frac{\partial }{\partial \varphi} \vec{e_\varphi},$$ which results in $$\nabla u = 0 \vec{e_r} + \frac{1}{r} 36 \sin(3\varphi) \sin^2(\theta) \cos(\theta) \vec{e_\theta} + \frac{1}{r} 36 \cos(3\varphi) \sin^2(\theta) \vec{e_\varphi}.$$ Now, I'm not quite sure about the unit normal $\vec{n}$ on the sphere. I thought it would just be $\vec{e_r}$, but that cannot be right since in that case the inner product $\vec{n} \cdot \nabla u$ is zero (and hence the surface gradient would be equal to the regular gradient). Just to be sure, the inner product for a spherical coordinate setting is defined as $a \cdot b = g_{ij} a^i b^j$ — using Einstein notation — with the metric $g$ defined as $$\left(\begin{array}{ccc}1 & 0 & 0 \\ 0 & r^2 & 0\\ 0 & 0 & r^2 \sin^2(\theta) \end{array}\right),$$ correct? Since the spherical coordinate system is right-handed, taking the cross product of the tangent vectors $\vec{e_\varphi}$ and $\vec{e_\theta}$ again results in $\vec{e_r}$. Could someone point out where I'm going wrong? Next up is the divergence. I assume there is something like the surface divergence , but I couldn't find much about it (any references are most welcome). This would result in $\Delta_S u = \mathrm{div}_S (\nabla_S u)$. It would be great if somebody could help to complete this elaboration. The eventual result of $\Delta_S u$ should be $-12 u$. [Edit] Using the regular divergence operator for a spherical coordinate setting, defined as $$\nabla \cdot := \frac{1}{r^2} \frac{\partial}{\partial r} r^2 \vec{e_r} + \frac{1}{r \sin(\theta)} \frac{\partial}{\partial \theta} \sin(\theta) \vec{e_\theta} + \frac{1}{r \sin(\theta)} \frac{\partial}{\partial \varphi} \vec{e_\varphi},$$ we get (without using the metric $g$ as defined above) $$\frac{1}{r^2 \sin(\theta)} \left( 36 \sin(3\varphi) \left\{ 3 \sin^2(\theta) \cos^2(\theta) - \sin^4(\theta) \right\} \right) + \frac{1}{r^2 \sin(\theta)} \left( -108 \sin(3\varphi) \sin^2(\theta) \right).$$ In case the metric should be used (I'm not sure about this), the result is $$\left( 36 \sin(3\varphi) \left\{ 3 \sin(\theta) \cos^2(\theta) - \sin^3(\theta) \right\} \right) + \left( -108 \sin(3\varphi) \sin^3(\theta) \right).$$ Since the solution should be $-12u = -144 \sin(3\varphi) \sin^3(\theta)$, I'm not sure how I should get rid of the term $108 \sin(3 \varphi) \sin(\theta) \cos^2(\theta)$. Anyone?","['surfaces', 'differential-geometry', 'spherical-coordinates']"
413443,Angle preserving linear maps [duplicate],"This question already has answers here : Question about Angle-Preserving Operators (3 answers) Closed 11 years ago . In Spivak's Calculus On Manifolds , in part (c) of question 1-8, he asks the following question: What are all angle preserving $T:\mathbf{R}^n \to \mathbf{R}^n$? I already showed that if $T$ is diagonalizable with a basis $\{x_1,\ldots,x_n\}$ where $Tx_i = \lambda_i$, then $T$ is angle preserving $\iff$ $|\lambda_i| = |\lambda_j|$ for all $i,j$ (this was part (b)). Perhaps this can be used? Thanks.",['linear-algebra']
413456,Transformations that map points inside the sphere to points inside the sphere,"I am trying to figure out what is the most general linear transformation that maps points inside the unit sphere to points inside the unit sphere. I am slightly abusing the word linear here by allowing also translations. Thus I am looking for $4 \times 4$ matrices that when applied on the vector $v=(1,x,y,z)^T$ with $x^2+y^2+z^2 \leq 1$ gives me another vector $v'=(1,x',y',z')$ that satisfies $x'^2+y'^2+z'^2 \leq 1$. I know this matrix must have as its first row $(1,0,0,0)$ but I am curious to know if this matrices have some name and if their properties are known. By the  properties they have they should form a monoid or a semi group with an identity operation. Any help or useful reference on the structure of these objects will be much appreciated...","['affine-geometry', 'algebraic-geometry']"
413461,Help with conditional probability?,"I've got to show that: $$\mathbb{P} (A | A \cap B) = \frac{ \mathbb{P}(A)}{ \mathbb{P} (A \cap B)}$$ I'm not sure how to get to this. Surely the probability of A occurring given A and B occurs is 1? Or, by the equation... $$\mathbb{P} (A | A \cap B) = \frac{ \mathbb{P} (A \cap A \cap B)}{\mathbb{P} (A \cap B)}$$ Thanks for your help",['probability']
413470,number of subgroups index $p$ equals number of subgroups order $p$,"I'm doing an exercise in Dummit's book ""Abstract Algebra"" and stuck for a long time. I think I'm doing in the right way but I can't finish it. Hope someone can help me. I really appreciate it. Let $A$ be a finite abelian group and let $p$ be a prime. Let $A^{p} = \{a^{p}\mid a \in A\}$ and $A_{p} = \{x\mid x^{p} = 1\}$. Prove that $A/A^{p}$ is isomorphic to $A_{p}$, and the number of subgroups of $A$ of order $p$ equals the number of subgroups of $A$ of index $p$. I can prove that $A/A^{p}$ is isomorphic to $A_{p}$, and every subgroups order $p$ of $A$ must be subgroups order $p$ of $A_{p}$. So the number of subgroups order $p$ of $A$ equals number of subgroups order $p$ of $A_{p}$. Moreover because of the previous result, we must have this number equals number of subgroups order $p$ in $A/A^{p}$. So we try to build a bijection from the set of all subgroups order $p$ of $A/A^{p}$ into set of all subgroups index $p$ of $A$. I think that it's possible, because every subgroup $N$ of $A$ is normal and $A/N$ is a group order $p$. Can anyone help me go on in this way to solve this problem. I know there's a solution in Project Crazy Project, but I think that solution is cumbersome and not beautiful. 
Thanks","['finite-groups', 'group-theory', 'abstract-algebra', 'abelian-groups']"
413479,"Is ""locally of finite type"" affine-local on the source?","Hartshorne exercise II.3.3(c) asks the reader to prove that if $f:X\to Y$ is finite type, then for any $\mathrm{Spec}A\subset Y$ and $\mathrm{Spec}B\subset X$ with $\mathrm{Spec}B\subset f^{-1} \mathrm{Spec}A$ , we have $A\to B$ is of finite type. However, the proof I produced seems to work in the case that $f$ is only locally of finite type, but exercise 2 of that section of Hartshorne asks to prove a strictly weaker condition in that case. (That is, for any affine of $Y$ , the preimage can be covered by affines giving us finite-type homomorphisms.) Is the property of local finite-typeness affine-local on the source? My proof seemed very straightforward: Take any affine open $\mathrm{Spec}\ B$ of $X$ , and also choose a cover $\mathrm{Spec}\ B_i$ of $X$ by affine opens so that each $A\to B_i$ is finite type. (This cover is guaranteed to exist by part II.3.2.(b).) Then by the ""Affine Communication Lemma"" (5.3.2 of Vakil's FOAG - page 155 in the Feb 25, 2013 version) it suffices to show that if $A\to B$ is finite type and $f\in B$ , so is $A\to B_f$ , and if $f_1,\dots,f_n\in B$ generate the unit and each $A\to B_{f_i}$ is finite type, then so is $A\to B$ . The first claim is trivial. As for the second, take $b\in B$ , and choose $b_{i1},\dots,b_{ik}\in B$ which generate $B_{f_i}$ over $A$ . Then we can choose $n$ and $g_{ij}\in A$ for each $i$ we have $f_i^nb=\sum_j g_{ij}b_{ij}$ . Some linear combination of the $f_i^n$ is equal to one, and so we can write $b$ as an $A$ -linear combination of all the $g_{ij}$ . Does this reasoning make sense?",['algebraic-geometry']
413492,The series expansion of $\frac{1}{\sqrt{e^{x}-1}}$ at $x=0$,"The function $ \displaystyle\frac{1}{\sqrt{e^{x}-1}}$ doesn't have a Laurent series expansion at $x=0$ . But according to Wolfram Alpha, it does have a series expansion with terms raised to non-integer powers: $$ \frac{1}{\sqrt{e^{x}-1}} = \frac{1}{\sqrt{x}}- \frac{\sqrt{x}}{4} + \cdots$$ How is that series derived? My initial thought was to use the general binomial theorem, but I'm not sure how.","['sequences-and-series', 'real-analysis']"
413521,What can we say about the order of a group given the order of two elements?,"If I know that a group of finite order has two elements $a$ and $b$ s.t. their orders are $6$ and $10$, respectively. What statements can be made regarding the order of the group? I know by Lagrange's that the elements should divide the order of the group, so I've taken the $\operatorname{lcm}$. I think the order of our group should be a multiple of $30$. But I'm thinking there's more I can say.","['finite-groups', 'group-theory', 'abstract-algebra', 'divisibility']"
413523,Do the tangents of two circles define concentric circles?,"Given two non-overlapping circles, $R_1$ and $R_2$. The radii of $R_1$ and $R_2$ may be different. The distance between the centers of $R_1$ and $R_2$ is defined as $x$. Draw the four tangents between $R_1$ and $R_2$. There will be two tangents that cross between $R_1$ and $R_2$ and two tangents that do not cross between $R_1$ and $R_2$.
Call the two tangents that cross inner tangents and the two tangents that do not cross outer tangents. I assert that there are two concentric circles that can be drawn, $C_1$ and $C_2$. $C_1$ will have the four tangents points of the inner tangents on its circumference and $C_2$ will have the four tangent points of the outer tangents on its circumference. I remember solving this problem using high school geometry, basic algebra and some trig, but that was over $20$ years ago. Is my assertion correct? If so, what is the solution? I vaguely remember that one key point was noting that radii that intersect at tangent points are perpendicular to the tangent line.","['geometry', 'circles', 'euclidean-geometry']"
413540,Broken Line Regression,"$X = $Lot & $Y = $Cost Give a broken line linear model with a breakpoint at $250$:
$$Y = B_0 + B_1X_1 + B_2X_2 + B_3X_3 + e$$
where $X_2 = 0$ or $1$ depending on whether the lot size is $\geq 250$ or $< 250$ and $X_3 = X_1\cdot X_2.$ Which hypothesis statement is equivalent to the statement: The two regression lines have the same intercept term?
$$H_0 : B_0 = 0\\
H_0 : B_1 = 0\\
H_0 : B_2 = 0\\
H_0 : B_3 = 0$$ $B_0$ is obviously the intercept for simple linear regression models, however, the broken line phrasing is causing me to be confused on this. My initial instinct was to assume $B_0$ hypothesis was appropriate, but now I'm wondering if $B_2 = 0$ makes more sense. Any assistance or starting point would be very beneficial as I need to explain through the reasoning algebraically too !","['statistics', 'regression']"
413541,Uniform Continuity of $1/x^3$ on compact intervals.,"So, I have the function $f : (0,\infty) \to \Bbb R$. With $f(x) = \frac{1}{x^2}$ and I have to show that $f(x)$ is uniformly continuous on the set $[1,\infty)$. Is the following proof correct? $[1,\infty) = \cup_{n=1}^{\infty} [n,n+1]$. And each of those sets is compact, and $f(x)$ is continuous so by Heine-Cantor it is UC on every compact set, and thus it is UC on the whole union of them. Is this coherent/consistent?","['real-analysis', 'analysis']"
413544,"""Néron-Ogg-Shafarevich criterion"" in positive characteristic","The Néron-Ogg-Shafarevich theorem usually seems to be cited to say that an abelian variety over a finite extension $K/{Q}_p$ has good reduction at $\ell \neq p$ if and only if the associated $\ell$-adic Galois representation (Tate module) is unramified, as seen in Serre-Tate. I am aware that these conditions can be slightly generalized (cf. the Néron models book). I also know that you get the analogous result at $\ell = p$ if you replace ""unramified"" by ""crystalline,"" but that this was proven much more recently. However, from skimming the proofs of these various results, I don't immediately see where the fact that $K$ is characteristic zero is used. For instance, Serre-Tate doesn't seem to say anything about the characteristic of $K$. Nevertheless, I haven't yet seen this theorem applied when $K$ has positive characteristic, and some of the results (e.g. the Coleman-Iovita paper where it is shown if the p-adic Tate module is crystalline, then the abelian variety has good reduction) do assume that $K$ is characteristic zero (and perfect residue field, but I am less concerned about this). I guess I have a couple of related questions: Does the Néron-Ogg-Shafarevich theorem for abelian varieties hold when $K$ has positive characteristic? If so, could you link to a paper where it is applied in this fashion? Can you get similar results ""at $p$"" when char$(K) = p > 0$?","['abelian-varieties', 'algebraic-geometry']"
413546,Subgroup of elements of order at most $2^{m}$,"The problem A5 in Putnam 2009 reads as follows: Is there a finite abelian group $G$ such that the product of the
  orders of all its elements is $2^{2009}$? The answer is No . I am reading the official solution here . The solution starts by observing that if such group existed, it would be a 2-group. By structure theorem for finitely generated abelian groups, we may write $$G\cong\prod_{i=1}^{\infty} (\mathbb{Z}/2^{i}\mathbb{Z})^{e_i}$$ for some nonnegative integers $e_1, e_2, ...$ all but finitely many of which are $0$. I am having trouble understanding the step that immediately follows: For any nonnegative integer $m$, the elements of $G$ of order at most
  $2^m$ form a subgroup isomorphic to  $$\prod_{i=1}^{\infty}
 (\mathbb{Z}/2^{\min(i, m)}\mathbb{Z})$$ I can see that the elements of order at most $2^{m}$ forms a subgroup. But I don't see why this subgroup must be isomorphic to the group $\prod_{i=1}^{\infty}
 (\mathbb{Z}/2^{\min(i, m)}\mathbb{Z})$. Can someone shed light on this matter? Perhaps even show an explicit isomorphism if possible? I appreciate any input.","['contest-math', 'finite-groups', 'group-theory', 'abstract-algebra']"
413558,"the following inequality is true, but I can't prove it","The inequality $$\sum_{k=1}^{2d}\left(1-\frac{1}{2d+2-k}\right)\frac{d^k}{k!}>e^d\left(1-\frac{1}{d}\right)$$ holds for all integer $d\geq 1$. I use computer to verify it for $d\leq 50$, and find it is true, but I can't prove it.  Thanks for your answer.","['asymptotics', 'approximation', 'inequality', 'probability']"
413560,basic doubt about topological manifold,"In his book ""Introduction to Smooth Manifolds"", J.M. Lee defines a topological manifold to be a second countable, Hausdorff space with every point having a neighbourhood homeomorphic to an open subset of $\mathbb{R}^{n}$ for some $n$. I was wondering should it not say that it should be homeomorphic to a  connected open subset of $\mathbb{R}^{n}$? He also mentions that equivalent definitions are obtained if one replaces open subset by whole of $\mathbb{R}^{n}$ or by the open unit ball. I cannot see how this can happen as a connected open subset cannot be homeomorphic to open unit ball or whole of $\mathbb{R}^{n}$.","['general-topology', 'manifolds']"
413569,"Velocity, Wave Equation, Differential Equations","Suppose you have a differential equation of the form: $$
\frac{\partial^2 u}{\partial z^2} = C \frac{\partial^2 u}{\partial t^2} + D \frac{\partial u}{\partial t}$$ Is it possible to find the velocity from this? For a normal wave equation: $$
\frac{\partial^2 u}{\partial z^2} = C \frac{\partial^2 u}{\partial t^2}
$$ The velocity would be given by: $$\frac{1}{\sqrt{C}}$$ Is it possible to identify the velocity in the former case?","['ordinary-differential-equations', 'partial-differential-equations']"
413571,"How can I calculate $\int_0^\infty \frac{u^3}{(e^u-1)} \, du$?","How can I calculate
$$\int_0^\infty \frac{u^3}{e^u-1} \, du$$ Acutally this is a part of derivation of Stefan-Boltzmann's Law. And equation should give answer $\frac{\pi^4}{15}$.","['improper-integrals', 'integration']"
413593,Application of Rouche's theorem gives two different answers?,"So I am supposed to find how many solutions the equation $z^7-5z^4+iz^2-2 = 0$ has in the region $|z|<1$. Here's the dilemma: $|z^7-5z^4+iz^2|= |(-1)(-z^7+5z^4-iz^2)| = |-z^7+5z^4-iz^2| \geq -|z|^7+|5z^4-iz^2|\geq -|z|^7+5|z|^4-|z|^2 = -1+5-1 = 3 > 2$ (using the triangle inequality) on the circle $|z|=1$, which tells us that $f(z)$ has 7 solutions within the region. However, $|z^7+iz^2-2|\leq|z|^4+|iz|^2+|-2| \leq 1+1+2 = 4 \leq 5 = |-5z^4|$, which leads me to believe that there are 4 solutions within the region. I am really confused! I am probably making a really silly mistake. Can someone please help me out? Thank you very much!","['inequality', 'complex-analysis', 'solution-verification']"
413596,Exterior Algebra of smooth differential forms,"I'm a little bit confused about the exterior algebra of smooth differential forms $\Omega(M)$ on a manifold M. The definition of k-forms is clear to me, but I don't understand how to put them together, s.t. they form $\Omega(M)$ so to speak. Maybe you can help me to get rid of my problems: First of all there is some confusion about the definition of $\Omega(M)$. Some people write $\Omega(M):=\bigoplus\limits_{k=0}^{\dim(M)}\Omega^k(M)$ and some $\Omega(M):=\sum\limits_{k=0}^{\dim(M)}\Omega^k(M)$. I never saw the second notation before, are they both the same by definition or is there a different meaning by the second one? Furthermore, if we accept the definition $\Omega(M):=\bigoplus\limits_{k=0}^{\dim(M)}\Omega^k(M)$ then the elements of $\Omega(M)$ will consist of tuple like $(\omega_0,...,\omega_{\dim(M)})$, whereas $\omega_k\in\Omega^k(M)$. How do I extend the definition of the wedge product of single forms, i.e. $w_i\wedge\omega_j$, to elemts of the algebra, i.e. $(\omega_0,...,\omega_{\dim(M)})\wedge (\alpha_0,...,\alpha_{\dim(M)})=?$
I suggest that one writes the elements as ""formal sums"" like $(\omega_0,...,\omega_{\dim(M)})=:\omega_0+...+\omega_{dim(M)}$ and then extend the wedge product bilinearly. Is that right? I hope someone can help me by answering my two questions. Regards",['differential-geometry']
413600,Show that the $k$th forward difference of $x^n$ is divisible by $k!$,"Define the forward difference operator
$$\Delta f(x) = f(x+1) - f(x)$$
I believe that if $f(x)$ is a polynomial with integer coefficients, $\Delta^k f(x)$ is divisible by k!.  By linearity it suffices to consider a single monomial $f(x) = x^n$.  I've checked this for small values of $n$ and $k$, and believe that a simple proof should exist, but am unable to find it. In particular, brute force gives
$$\Delta^k x^n = \sum_j x^{n-j} \left[ \binom{n}{j} \sum_i (-1)^{k-i} \binom{k}{i} i^j \right]$$
but the terms in brackets appear to have no closed form solution (see (20)-(25) of http://mathworld.wolfram.com/BinomialSums.html ). Motivation: I have an unknown integer coefficient polynomial of degree $n$ sampled at $x = 0, 1, \ldots, n$, and want to prove that all intermediate results in the classical divided difference algorithm are integers.","['finite-differences', 'binomial-coefficients', 'combinatorics']"
413610,why is this Markov Chain aperiodic,"I have this Matrix: $$P=\begin{pmatrix}  0 & 1 \\ 0.3 & 0.7 \end{pmatrix}$$ this markov chain is said to be aperiodic, I dont understand how it comes to it. Period $\delta$ is the gcd of the set of all diagonal elements, right? if $\delta>1$, $P$ is periodic, if $\delta=1$, then aperiodic. but here it is not $\delta=1$, is it? or do i have to transit the matrix to some certain form?","['statistics', 'stochastic-processes', 'markov-chains', 'probability']"
413614,fundamental solution of the laplace Beltrami operator,"It is well know that $s(z,z_0)=\frac{1}{2\pi} \ln \vert z-z_0\vert$ satisfies $\Delta_z s=\delta_{z_0}$ in dimension $2$. Does any one have a reference when we consider a general metric $g$ on an open set of $R^2$? that is to say which is the solution of $(\Delta_g)_z s=\delta_{z_0}$","['partial-differential-equations', 'differential-geometry']"
413619,Strong equidistribution of points on the n-sphere,"The vertices of a Platonic solid are equally distributed on its circumscribing sphere in a very strong sense: each of them has the same number of nearest neighbours and all distances between nearest neighbours are the same. It seems clear to me that the Platonic solids also provide the only examples for such equidistributed arrangements of points on the sphere, i.e. (∗) One can equidistribute (in the strong sense above) only 4, 6, 8, 12, or 20 
  points on the 2-sphere. The latter is - thus - a consequence from the fact that there are only five Platonic solids, which in turn is a consequence of Eulers theorem , for which in turn there is a whole bunch of proofs . My questions are: (1) Are there other ""independent"" and maybe more ""direct"" proofs of (∗)? (2) Are there corresponding results for general $n$-spheres? I assume that one can equidistribute on every $n$-sphere $n+2$ points (the generalized tetrahedron) and $2^{n+1}$ points (the generalized cube). (3) Are there other such (maybe partial) functions $f_3(n), f_4(n), f_5(n),\dots$ with e.g. $f_3(2) = 6, f_4(2) = 12, f_5(2) = 20$?","['geometry', 'polytopes', 'combinatorics']"
413624,Maximum and Minimum Value of $f(x)$,"$$f(x)=\sin(x)+\int_{-\pi/2}^{\pi/2}\left(\sin(x)+t\cos(x)\right)f(t)\,\mathrm dt$$ Find maximum and minimum values of $f(x)$ . I tried to simplify this expression by checking even or odd property of $f(x)$ . We can write the above expression as $$f(x)=(1+I_1)\sin(x)+I_2\cos(x)$$ where $$I_1=\int_{-\pi/2}^{\pi/2}f(t)\,\mathrm dt$$ and $$I_2=\int_{-\pi/2}^{\pi/2}tf(t)\,\mathrm dt$$ if $f$ is even $I_2=0$ and if $f$ is odd $I_1=0$ , but if $f$ is even $$f(x)=(1+I_1)\sin(x)$$ which is odd. Similarly if $f$ is odd $$f(x)=\sin(x)+I_2\cos(x)$$ which is neither even nor odd. So $f(x)$ is neither even nor odd. Now to find maxima or minima $f'(x)=0$ i.e., $$f'(x)=(1+I_1)\cos(x)-I_2\sin(x)=0$$ $\implies$ $$\tan(x)=\frac{1+I_1}{I_2}$$ Unable to proceed further...","['optimization', 'trigonometry', 'calculus', 'integration']"
413636,Help on an integral.,"I have to finish following integral
$$\int_0^{+\infty} \log_2(1+a x) (1-e^{-\frac{x}{2}})^{b-1} \frac{1}{2}e^{-\frac{x}{2}} dx$$
After a week of work on this, I found it may be impossible to have a integral analytically. So I think I need to have an approximation of this. The shape of the integrated function is as following. With fixed b and varying a: With fixed a and varying b: Could you give me a hint on the approximation of the integral?","['definite-integrals', 'integration']"
413655,no. of solution of the equation $[x]^2+a[x]+b = 0$ is,"If $a$ and $b$ are odd integer. Then the no. of solution of the  equation $[x]^2+a[x]+b = 0$ is where $[x] = $ greatest Integer function My Try:: Let $[x] = y$. Then equation become $y^2+ay+b = 0$ Now If given equation has real Roots, Then $\displaystyle y = \frac{-a\pm \sqrt{a^2-4b}}{2}$ Now $a^2-4b = k^2\Leftrightarrow a^2-k^2=4b^2$. where $k\in \mathbb{Z}$ Now How can I solve after that. Help required Thanks",['algebra-precalculus']
413657,To prove that the following equation has no solution,"The question is : Prove that there are no real numbers $(x,y)$ that satisfy the equation $$ 13+\ 12[\arctan(x)]=62[\ln(x)]+8[e^x]+4[\arccos(y)] $$ $ [\ ] \text{ denotes the greatest integer function} $ I tried writing the possible values of $\arctan(x), \arccos(y)$ thereby leading to the values of $x$ and $y$. that turned out to be useless. Can someone help me or is there an alternative approach?",['algebra-precalculus']
413665,"Two spaces homotopy equivalent to eachother, attaching maps, Algebraic Topology.","I have a question regarding algebraic topology with which I was hoping someone could help me with. I've managed to show the following: If $f,g:S^{n-1} \to X$ are homotopic maps, then $X\sqcup_fD^n$ and $X\sqcup_gD^n$ are homotopy equivalent. I showed this by showing they were both deformation retracts of the same space, $Y=X\sqcup_F(D^n\times I)$ where $F$ is my homotopy between maps $f$ and $g$. I feel like this result could help me with the following question: Let $f:S^{n-1} \to X$ be a map and $g:X \to Y$ be a homotopy equivalence. Show that $X\sqcup_fD^n\simeq Y\sqcup_{f\circ g}D^n$. Could I do this similarly as with my original problem. Since if $g$ is a homotopy equivalence between $X$ and $Y$, this tells me that $X\simeq Y$, so they are deformation retracts of a larger space, say Z. Would I then show $X\sqcup_f D^n$ and $Y\sqcup_{f\circ g}D^n$ are deformation retracts of some larger space $W=Z\sqcup_f (D^n\times I)$? 
If I retract $Z$ to $X$ and $(D^n\times I)$ to $(D^n\times ${$0$}$) \cup (S^{n-1}\times I)$, is it valid for me to apply my map $g$ and yield that $Y\sqcup_{f\circ g}D^n$ is a deformation retract of my larger space $W$? Thanks in advance.","['general-topology', 'homotopy-theory', 'algebraic-topology']"
413679,Why the sum of $n$ seems equals the period of the binary expansion of $1/n$?,"The sum of $n$(suppose $n$ is positive odd,using $n=23$ as an example): Step 1 : Get the odd part of  $23 + ~~1 $, which is $~~3$,$~~3\times2^3=23 + ~~ 1$,get $s_1 = 3$ Step 2 : Get the odd part of  $23 + ~~3 $, which is $13$,$13\times2^1=23 + ~~ 3$,get $s_2 = 1$ Step 3 : Get the odd part of  $23 +  13 $, which is $~~9$,$~~9\times2^2=23 +  13$,get $s_3 = 2$ Step 4 : Get the odd part of  $23 +  ~~9 $, which is $~~1$,$~~1\times2^5=23 +  ~~9$,get $s_4 = 5$ Continuing this operation (with $23 + 1$) repeats the same steps as above. There are $4$ steps in the cycle, so the cycle length of $23$ is $4$，and the sum of $23$ is $s_1 + s_2 + s_3 + s_4 = 11$. The period of the binary expansion of $1/23$ is $11$,so why the sum of $23$ seems equals the period of the binary expansion of $1/23$?","['elementary-number-theory', 'number-theory']"
413697,"$L^2$-lower semicontinuity of an integral operator on $G(x,\nabla w(x))$","In the paper "" A posteriori error estimates for variable time-step discretizations of nonlinear evolution equations "" by Nochetto, Savaré, Verdi
we find the following claim in Example 2.4: Let $\mathcal H:=L^2(\Omega),\ p>1$
  $$ \phi(w):=\int_\Omega G(x,\nabla w(x))dx,\quad D(\phi):=L^2(\Omega)\cap W_0^{1,p}(\Omega)$$
  If $G(x,\xi):\Omega\times\mathbb R^d\rightarrow\mathbb R$ is a Carathéodory function convex and continuously differentiable in $\xi$ for a.e. $x\in\Omega$ such that
  $$ G(x,\xi)\geqslant\alpha_0|\xi|^p-\alpha_1,\quad|\nabla_\xi G(x,\xi)|\leqslant\alpha_2 (1+|\xi|^{p-1}), \quad\forall\xi\in\mathbb R^m,a.e. x\in\Omega$$
  with some positive constants $\alpha_i$, then $\phi$ is convex and lower semicontinuous in $\mathcal H=L^2(\Omega)$. Note that l.s.c. is stated in $L^2$. (At least for $p=2$) I am interested in either a reference to such a result with proof or a hint of how to prove this. I have dificulties to relate this to classical results like the theorem of Serrin and generalizations as they yield 
$${\lim \inf}_{n\rightarrow\infty} \phi(u_n)\geqslant\phi(u)$$
only for sequences $u_n\rightarrow u$ wrt the $L^1$ norm where the $u_n$ and $u$ are in $W^{1,1}(\Omega)$ while assumptions are usually weaker. whether or not such a result carries over to the vector-valued case, i.e. $\mathcal H=L^2(\Omega,\mathbb R^N)$. NB: I'm a numerics guy with little practice in analysis...",['functional-analysis']
413702,"Prove that for every $n\in \mathbb{N}^{+}$, there exist a unique $x_{n}\in[\frac{2}{3},1]$ such that $f_{n}(x_{n})=0$","Let $f_{n}(x)=-1+x+\dfrac{x^2}{2^2}+\dfrac{x^3}{3^2}+\cdots+\dfrac{x^n}{n^2}$, (1) Prove that for every $n\in \mathbb{N}^{+}$, then there exist unique $x_{n}\in[\frac{2}{3},1]$ such that
$f_{n}(x_{n})=0$ (2) Show that  the sequence $(x_{n})$ of (1) is such that
$$0<x_{n}-x_{n+p}<\dfrac{1}{n}$$
for all $p\in \mathbb{N}$. (3):$x_{n}=A+\dfrac{B}{n}+\dfrac{C}{n^2}+O(\dfrac{1}{n^2})$, find $A,B,C$? My attempts : For $(1)$, I have prove it :
$$f_{n}(1)=-1+1+\dfrac{1}{2^2}+\cdots+\dfrac{1}{n^2}>0,$$
\begin{align}
f_{n}(\frac{2}{3})&=-1+\dfrac{2}{3}+\cdots+\dfrac{(\dfrac{2}{3})^n}{n^2}\\
&\le-\dfrac{1}{3}+\dfrac{1}{4}\sum_{k=2}^{n}\left(\dfrac{2}{3}\right)^k\\
&=-\dfrac{1}{3}\cdot\left(\dfrac{2}{3}\right)^{n-1}<0
\end{align} and
$$f'_{n}(x)=1+\dfrac{x}{2}+\cdots+\dfrac{x^{n-1}}{n}>0$$ But for $(2)$, I  have methods: since
$$x>0, f_{n+1}(x)=f_{n}(x)+\dfrac{x^{n+1}}{(n+1)^2}>f_{n}(x)$$
so $$f_{n+1}(x_{n})>f_{n}(x_{n})=f_{n+1}(x_{n+1})=0$$
since $f_{n+1}(x)$ is increasing, so $x_{n+1}<x_{n}$ since
$$f_{n}(x_{n})=-1+x_{n}+\dfrac{x^2_{n}}{2^2}+\cdots+\dfrac{x^n_{n}}{n^2}=0$$ $$f_{n+p}(x_{n})=-1+x_{n+p}+\dfrac{x^2_{n+p}}{2^2}+\cdots+\dfrac{x^{n+p}_{n+p}}{(n+p)^2}=0$$
and use $0<x_{n+p}<x_{n}\le 1$ we have \begin{align}
x_{n}-x_{n+p}&=\sum_{k=2}^{n}\dfrac{x^k_{n+p}-x^k_{n}}{k^2}+\sum_{k=n+1}^{n+p}\dfrac{x^k_{n+p}}{k^2}\le\sum_{k=n+1}^{n+p}\dfrac{x^k_{n+p}}{k^2}\\
&\le\sum_{k=n+1}^{n+p}\dfrac{1}{k^2}<\sum_{k=n+1}^{n+p}\dfrac{1}{k(k-1)}=\dfrac{1}{n}-\dfrac{1}{n+p}<\dfrac{1}{n}
\end{align} But for part $(3)$  I can't prove it,Thank you everyone can  help,and for part $(2)$ have other nice methods?",['sequences-and-series']
413712,Basic examples of ordinals,"I'm reading a book on stochastic games which apparently needs ordinals somewhere. This is the first time I meet a concept, and although the definition is clear to me, the lack of practice makes it harder to think of them. That's why I need some help with examples. As far as I understood, the ordinals are exactly equivalence classes w.r.t. order isomorphism of well-ordered sets. In the Wikipedia article on the topic there is a remark, saying that formally such classes are too big to be sets in ZF system of axioms, so one shall rather talk about order types - OK for me as well, so far it is all quite natural. I can also imagine sets which have order types of the ordinal $\xi = 5$ or $7$, or any other natural number - this would be just any well-ordered set with $5$ or $7$ elements, right? It's easy for me to think of $\omega$ as well: one of the examples that has such order type is the set of all natural numbers. What is harder for me, is to find an example of a set which has order types of $\omega+1$, $2\cdot \omega$, $\omega^2$ or $\omega^\omega$. Even more, for the latter I used to think that this is an unordered set of all infinite sequences of natural numbers. However, still it reads that $\omega^\omega$ is a countable ordinal. It would be nice if the example for $\omega+1$ would be something more intuitive than $\omega+1$ itself (which perhaps is not even a set, right?), such as $\Bbb N$ for $\omega$.","['ordinals', 'elementary-set-theory']"
413730,Projection operator for non-orthonormal basis,"Let $V \subset H$ be Hilbert spaces. Let $\{v_j\}_{j=1}^\infty$ be a basis for $V$ and $H$. Define $V_N$ to be the span of $\{v_j\}_{j=1}^N$. We can define a projection operator
$P:H \to V_N$ by
$$P(h) = \sum_{j=1}^N(h,v_j)_Hv_j$$
which is bounded from $H$ to $H$. I can show that $P^2(h) = P(h)$ if the $v_j$ are orthonormal in $H$. If they are not (say they are just a basis, not orthonormal and not orthogonal), then how can I show this identity? Should I define the projection differently?","['operator-theory', 'inner-products', 'hilbert-spaces', 'functional-analysis']"
413737,How to show $( \frac{p}{q})=1 \Leftrightarrow ( \frac{q}{p})=1 $?,"How to show $( \frac{p}{q})=1 \Leftrightarrow ( \frac{q}{p})=1 $?, where p and q are odd primes and $( \frac{p}{q})$ is Legendre symbol and we assume $ q \equiv 1 \pmod 4$.
I would like to have proof which uses Euler's criterion if possible. I guess this is possible to solve without quadratic reciprocity.",['number-theory']
413738,How to prove $(a-b)^3 + (b-c)^3 + (c-a)^3 -3(a-b)(b-c)(c-a) = 0$ without calculations,"I read somewhere that I can prove this identity below with abstract algebra in a simpler and faster way without any calculations, is that true or am I wrong? $$(a-b)^3 + (b-c)^3 + (c-a)^3 -3(a-b)(b-c)(c-a) = 0$$ Thanks","['symmetric-polynomials', 'algebra-precalculus']"
413741,Pseudo norm-exercice,"Let $f$ be a measurable function with finite values almost everywhere. We put $$N_0(f) = \displaystyle\int \dfrac{|f|}{1 + |f|} d \mu.$$
We denoted by $L^0$ the set of measurable functions $f$ such that $N_0(f) < + \infty.$ We know that $L^0$ is a vector space  and $N_0$ is a pseudo-norm on $L^0$. My question is: how we can prove that $L^0$ is a complete metric space?","['topological-vector-spaces', 'lebesgue-integral', 'measure-theory', 'metric-spaces']"
413753,Is it known or where does this lead to?,"I am  eleventh class student, recently I started learning calculus. I was experimenting on various things, and found a new thing. It is as follows. Let us consider a function $f(x)$which is continuous. So we have derivative $f^{\prime}(x)$ of that function, and if we figure out all the values of the function, and the derivative there is an interesting linking between both of them. That is  $$f(b)=f(b-1)+\left\lceil\dfrac{f^{\prime}(b)+f^{\prime}(b-1)}{2}\right\rceil$$ where $\lceil K\rceil$ is the ceil function of K. For example, let us consider $f(x)=x^3,f^{\prime}(x)=3x^2$ and we have $f(1)=1$, so $$f(2)=f(1)+\left\lceil\dfrac{f^{\prime}(2)+f^{\prime}(1)}{2}\right\rceil$$
$$f(2)=1+\left\lceil\dfrac{12+3}{2}\right\rceil=8=2^3$$ Some of my teachers told that its already known and it's called as mean value theorem, but 
I don't know whether it's already there or it's a new one, and what is the intuitive explanation for that ? It is useful in finding the next immediate point, to a given point. Generally we know that $f(a+h) \approx f(a) +f^{\prime}(a).h$, but how is this different from that ? If it is a trivial question for experts present here, please do excuse me, but I will be happy in knowing the reason. Thank you !","['calculus', 'derivatives', 'functions']"
413764,Polygon Inequality,"We know that to form a triangle the 3 sides should obey the triangle inequality . So is there any rule to be followed by the sides of $n$-sided convex polygon. For Eg:- $1,2,4$ cannot form a triangle so can we tell if we are given $n$ line segments can we make a $n$-sided convex polygon.","['geometry', 'polygons', 'inequality']"
413766,Tangent Space of Product Manifold,"I was trying to prove the following statement(#9(a) in Guillemin & Pollack 1.2) but I couldn't make much progress. ""Show that for any manifolds $X$ and $Y$, $$T_{(x,y)}(X\times Y)=T_x(X)\times T_y(Y).$$"" My attempt so far: Parametrise X and Y locally with $U\overset{\phi}{\longrightarrow}X$ and $V\overset{\psi}{\longrightarrow}Y$ where $U\subset \mathbf R^m$ and $V\subset \mathbf R^n$. Now we can parametrise $U\times V\overset{\phi\times \psi}{\longrightarrow}X\times Y$. By taking the derivative map, we have the tangent plane. $\mathbf R^{m+n}\overset{d(\phi\times \psi)}\longrightarrow T_{(x,y)}(X\times Y)$. I don't know what to do after this... Apparently we are supposed to set up some relation between $T_{(x,y)}(X\times Y)$ and $T_x(X)\times T_y(Y)$... Anyone would like to help me out? Thanks!","['differential-topology', 'differential-geometry']"
413768,"How to use Lagrange Multipliers, when the constraint surface has a boundary?","The method called Lagrange Multipliers is used to find critical points of $f(x_1,x_2,\ldots,x_n)$, when $f$ is constrained to the level set $S = \{ x\in \mathbb{R}^n \, | \, g(x_1,x_2,\ldots,x_n)=0 \}$.
These critical points may be used to locate local minima and maxima. When $S$ is a compact set, we know that a global max and min of $f$ exist on $S$. Do we also have to check what happens on the boundary of $S$, in case a boundary exists ?","['multivariable-calculus', 'lagrange-multiplier']"
413773,Representing $A \rightarrow B$ as $A \supseteq B$ [duplicate],"This question already has answers here : Using $p\supset q$ instead of $p\implies q$ (3 answers) Closed 11 years ago . I know that many people like to think of elementary logic in terms of Venn diagrams, i.e., elementary set theory.  I have never found this representation useful, because I can never remember whether implication is supposed to be represented by the relation ""contains"" or to the relation ""is contained in"".  IOW, do we represent $A \rightarrow B$ as $A \supseteq B$ or as $A\subseteq B\;$? For all I know, both representations could result in useful interpretations, depending on the situation. Whenever I come across an exposition that resorts to such a representation of logic through Venn diagrams, for some reason that is (to me at least) very obscure, my initial gut-reaction is that $A \rightarrow B$ corresponds to $A \supseteq B$.  This is annoying, because I eventually come to realize that my instinct is wrong: the intended representation is the one where $A \rightarrow B$ corresponds to $A \subseteq B$. (I want to stress that I have no problem at all understanding the correspondence between $A \rightarrow B$ and $A \subseteq B$.  My problem is only that this correspondence is not at all intuitive: I always need to think it through, or ""compute"" it, so to speak, and this makes this representation more of a hindrance than an aid to my thinking.) I rack my brains trying to figure out why my instinct here is so backwards (and apparently incurably so). The only possible explanation I can come up with (and I'm definitely ""grasping at straws"" here) is that maybe there is some situation in which the representation ""$A \rightarrow B$ is $A\supseteq B\,$"" is actually useful and used, and maybe I learned it first somehow? My question is: does anyone know of a reasonably common application of representing the implication $A \rightarrow B$ as $A \supseteq B\;$?  Conversely, does anyone know of a good reason for why this representation would rarely, if ever, be useful?","['logic', 'propositional-calculus', 'elementary-set-theory']"
413780,"By making the substitution $t=e^x$ and setting $z(t)=y(x)$, rewrite the following differential equation","By making the substitution $t=e^x$ and setting $z(t)=y(x)$, rewrite the following differential equation $y''-y'+e^{2x}y = xe^{2x}-1$,    (1) as one in terms of z and t. Hence find all solutions of (1). I know I should be using the chain rule but I can't work out how to do it. Could someone please explain how to rewrite the equation?",['ordinary-differential-equations']
413787,"Solving the equation $11x^2-6000x-27500 =0$, preferably without the quadratic formula",I obtained this form while solving an aptitude question. $$\frac{3000}{x-50} + \frac{3000}{x+50} = 11$$ I changed it into quadratic equation $$11x^2 -6000x - 27500 =0$$ but I don't know how to solve it. I can't find two factor for 303500 that sums to 6000 or when I use formula the numbers become huge... Without using calculator how to solve it? is there any other simple way to solve [other method]? [or finding factor] I'm a beginner in math. Please explain your answer for me.,['algebra-precalculus']
413788,Product of two primitive polynomials,"I'm having troubles with one of the problems in the book Introduction to Commutative Algebra by Atiyah and MacDonald. It's on page 11, and is the last part of the second question. Given $R$ a commutative ring with unit. Let $R[x]$ be the ring of polynomials in an indeterminate $x$ with coefficients in $R$ . We say that a polynomial $f = \sum\limits_{i=0}^n r_ix^i \in R[x]$ (with coefficients $r_0, r_1, \ldots, r_n$ ) is primitive if $\langle r_0,r_1,...,r_n\rangle = R$ , i.e., the ideal generated by the coefficients of $f$ is $R$ . Let $f$ and $g$ be two polynomials in $R[x]$ . Prove that $fg$ is primitive iff $f$ and $g$ are both primitive. The $\Rightarrow$ part is easy. Say, $f = \sum\limits_{i=0}^n r_ix^i$ , $g = \sum\limits_{i=0}^m s_ix^i$ ; then $fg = \sum\limits_{i=0}^{m+n} c_ix^i$ , where $c_k = \sum\limits_{i + j = k}r_is_j$ . Since $fg$ is primitive, there exists a set of $\{\alpha_i\} \subset R$ , such that $\sum\limits_{i=0}^{m+n} \alpha_ic_i = 1$ , to prove $f$ is primitive, I just need to write all $c_i$ 's in terms of $r_i$ 's, and $s_j$ 's, then group all $r_i$ accordingly, rearranging  it a little bit, and everything is perfectly done. And the proof of the primitivity of $g$ is basically the same. The $\Leftarrow$ part is just so difficult. Say $f = \sum\limits_{i=0}^n r_ix^i$ , $g = \sum\limits_{i=0}^m s_ix^i$ are both primitive, then there exists $\{\alpha_i\}; \{\beta_i\} \subset R$ , such that $\sum\limits_{i=0}^{n} \alpha_ir_i = 1$ , and $\sum\limits_{i=0}^{m} \beta_is_i = 1$ . At first, I thought of multiplying the two together, but it just didn't work. So, I'm stuck since I cannot see any way other than multiplying the two sums together. I hope you guys can give me a small push on this. Thanks very much in advance, And have a good day.","['commutative-algebra', 'abstract-algebra', 'polynomials']"
413813,Why $\mathbb{R}[X]/(X^2+1)\cong\mathbb{C}$?,"There is this isomorphism in my notes but there is no explanation. So I tried to reason myself but still not convincing enough, or my reasoning may even be wrong. I will appreciate if anyone is willing to lend some helps. $\mathbb{R}[X]/(X^2+1)\cong\mathbb{C}$ . I have heard that we can achieve that by putting $i$ into $X$ in the denominator, but if we do that then the denominator will be $0$ , so $\mathbb{R}[X]/(0)=\mathbb{R}[X]$ ? Then how can it be isomorphic to $\mathbb{C}$ ? Thanks so much!","['ring-theory', 'abstract-algebra']"
413822,Constructing a number system,"I have just started working through a book on higher algebra. I'm just at the beginning, where the authors introduce the notation and talk about the various number systems. I found this particular paragraph confusing:- ""The basic idea in the construction of new set of numbers is to take a set, call it $ S $, consisting of mathematical objects, such as numbers you are already familiar with, partition the set $ S $ into a collection of sets in a suitable way, and then attach names or labels, to each of the subsets. These subsets will be elements of a new number system."" What does the author mean, when he says a ""suitable way"" here? Does it mean, that I can partition in any way that I find suitable, or are there requirements to be met, for any number system that is constructed by me? For instance, I'm familiar with the set of natural numbers. So, can I construct $S= ${$1,2,3,4,5,6,7,8,9,10$} and call it a subset of a new number system? Can I go as far as to say that this subset is the only element of my new number system?",['elementary-set-theory']
413830,Period of derivative is the period of the original function,"Let $f:I\to\mathbb R$  be a differentiable and periodic function with prime /minimum period $T$ (it is $T$-periodic) that is, $f(x+T) = f(x)$ for all $x\in I$. It is clear that
$$
f'(x) = \lim_{h\to 0}\frac{f(x+h)-f(x)}{h} = \lim_{h\to 0} \frac{f(x+T+h) - f(x+T)}{h} = f'(x+T),
$$
but how to prove that $f'$ has the same prime/minimum period $T$? I suppose that there exist $\tilde T < T$ such that $f'(x+\tilde T) = f'(x)$ for all $x\in I$ but can't find the way to get a contradiction.","['derivatives', 'real-analysis', 'periodic-functions']"
413832,Gradient of a scalar function acting on a vector function,"If I have a vector function that is constructed from a scalar function acting on a vector function, what is it's gradient? $$\psi(x)=\phi(f(x))$$
where
$$x\in\mathbb{R}^n, f\in\mathbb{R}^n\rightarrow\mathbb{R}^1, \phi\in\mathbb{R}^1\rightarrow\mathbb{R}^1$$ Is the following correct?
$$\nabla\psi(x)=\nabla(\phi(f(x)))=\frac{d\phi}{df}\cdot{\nabla}f(x)$$
where ${\nabla}f(x)=\left[\frac{df}{dx_1},\frac{df}{dx_2},...,\frac{df}{dx_n}\right]^T$",['multivariable-calculus']
413833,CW-pairs are good pairs,Hatcher uses in a proof that every subcomplex of a CW-complex is a deformation retract of some neighborhood. In what way can I see this in the infinite dimensional case?,"['general-topology', 'algebraic-topology']"
413839,Show that the tangent space of the diagonal is the diagonal of the product of tangent space,"I'm stuck on this question for quite a few days and still haven't got a clue what to do. The question is as follows: If $\Delta$ is the diagonal of $X\times X$ where $X$ is a manifold, show that its tangent space $T_{(x,x)}(\Delta)$ is the diagonal of $T_x(X)\times T_x(X)$. Because this question follows a previous part, so I constructed a map $$f:X\longrightarrow X\times X$$ such that f(x)=(x,x). Therefore I have $X\overset{f}{\longrightarrow} X\times X$. Then we take the derivative map $$T_x(X)\overset{df_x}{\longrightarrow} T_{(x,x)}(X,X)$$ However this does not give me the tangent space of the diagonal...","['differential-geometry', 'differential-topology', 'real-analysis', 'analysis']"
413847,A homeomorphism of the plane has a periodic point if it leaves a compact set invariant,"Let $h$ be a homeomorphism of $\mathbb{R}^2$ onto itself such that $h(K)=K$ for some compact subset $K$ of $\mathbb{R}^2$.  Show that $h$ has a periodic point in $\mathbb{R}^2$. My idea is consider a sequence $x, f(x),ff(x),...$ for some $x\in K$, since $K$ is compact this sequence has a cluster point at $K$. But I couldn't go further.","['general-topology', 'fixed-point-theorems']"
413860,"Is perspective transform affine? If it is, why it's impossible to perspective a square by an affine transform, given by matrix and shift vector?","I'm a bit confused. I want to program a perspective transformation and thought that it is an affine one, but seemingly it is not. As an example, I want to perspective a square into a quadrilateral (as shown below), but it seems impossible to represent such a transform as a matrix multiplication+shift: 1) What I can't understand is that by definition affine transform is the one, that preserves all the staight lines. Can you provide an example of straight line, which is not preserved in this case? 2) How do I represent perspective transforms as this one numerically? Thank you.","['affine-geometry', 'linear-algebra', 'transformation']"
413882,Factor Rings of Polynomial Rings.,"Let $\mathbb F$ be a field and $\mathbb F[x]$ the ring of polynomials with coefficients in  $\mathbb F$. Let $p(x)$ be an irreducible polynomial in $\mathbb F[x]$. Let $k$ be a positive integer and consider the vector space $V$, over the field $\frac{\mathbb F[x]}{(p(x))}$with basis $$1, p(x), p(x)^2, \ldots, p(x)^{k-1}.$$ That is, $$V=\left\{q_0+q_1p(x)+\cdots +q_{k-1}p(x)^{k-1}\;\;:\;\;q_i\in\frac{\mathbb F[x]}{(p(x))}\right\}.$$ Define in $V$ a product modulo $p(x)^k$. That is, if $$v=v_0+v_1p(x)+\cdots +v_{k-1}p(x)^{k-1}\;\;\text{and}\;\;u=u_0+u_1p(x)+\cdots +u_{k-1}p(x)^{k-1},$$
then we multiply $v$ by $u$ the obvious way, using the distributivity and assuming that $p(x)^k=0$. This makes $V$ an algebra. My question is: Is this algebra $V$ isomorphic to $\frac{\mathbb F[x]}{(p(x)^k)}$?",['abstract-algebra']
413888,When is $R(G\times H) = R(G) \otimes R(H)$?,"Suppose $G$ and $H$ are discrete groups.  If $\rho_G$ and $\rho_H$ are reps of $G$ and $H$ on $V_G$ and $V_H$, respectively, then we get a rep of $G\times H$ on $V_G\otimes V_H$ by sending $(g,h)$ to $\rho_G(g)\otimes\rho_H(h)$.  This induces a map
$$
R(G) \otimes R(H) \to R(G\times H)
$$
where $R(\cdot)$ denotes the representation ring.  I know, by character theory, that this is an isomorphism for $G$ and $H$ finite. I am guessing this result is not true in general-- what is a simple counterexample? Are there nice conditions on $G$ and $H$ under which the map above is an isomorphism? EDIT Because of some of the issues with the correct definition of representations rings, I will rephrase my question to precisely what I want to know: Is it always the case that any finite dimensional representation (over $\mathbb C$) of $G \times H$ is isomorphic to $\bigoplus_j V_j \otimes W_j$ where $V_j$ is a rep of $G$ and $W_j$ is a rep of $H$?","['representation-theory', 'group-theory']"
413890,Open and Closed Set in Zariski Topology,"I'm confused about the definition closed and open set in Zariski Topology, it is said that the set $$V(I)=\{P \in \operatorname{Spec}(R)\mid I \subseteq P\}$$ are the closed set in Zariski Topology. But it is said in James Munkres's Topology that a subset $U$ of $X$ is an open set of $X$ if $U$ belong to the collection $\tau$. So assuming that $V(I)$ is the closed set of Zariski Topology on $\operatorname{Spec}(R)$, shouldn't the collection of $D(r)$ in which $$D(r)=\{P \in \operatorname{Spec}(R)\mid r \notin P\}$$ are the topology $\tau$ in $\operatorname{Spec}(R)$?
But, in a lecture notes about Zariski Topology www.math.kth.se/~laksov/courses/algebradr01/notes/rings5.pdf‎ , proposition 5.3 to be precise, the one that is proved to be the topology $\tau$ is the collection $V(I)$ instead. Could somebody explain this to me? Thank you.",['algebraic-geometry']
413915,Concrete Mathematics Summation Question,"I'm sorry if this question is too novice, but I am just beginning discrete math. I've been working through the book Concrete Mathematics (Graham,Knuth,Patashnik) and I reached a double summation that has me very confused. I'v been trying to work it out, and I think I have a solution but I'm not sure if it is the correct way to solve it. The question comes from chapter 2 section 4 and it goes as follows:
\begin{equation}
   S = \displaystyle\sum\limits_{1 \le j < k \le n}^{}{(a_k - a_j)(b_k - b_j)}
\end{equation} The authors then go on to say "" We have symmetry when j and k are interchanged:"" and write the new sum:
\begin{equation}
   S = \displaystyle\sum\limits_{1 \le k < j \le n}^{}{(a_j - a_k)(b_j - b_k)}    = \displaystyle\sum\limits_{1 \le k < j \le n}^{}{(a_k - a_j)(b_k - b_j)}
\end{equation}
I understand how they can get to the 2nd sum, because all you're doing is changing index names. But how do the authors get from the 2nd sum to the 3rd sum? Or how do they use their previously mentioned ""Rocky Road"" formula to achieve this result? Thanks, EDIT:
   Sorry for not making the Rocky Road formula clear. The Rocky Road Formula is as follows: \begin{equation}
       \displaystyle\sum\limits_{j \in J}^{}{\displaystyle\sum\limits_{k \in K(j)}^{}{a_j,_k}} = \displaystyle\sum\limits_{k \in K'}^{}{\displaystyle\sum\limits_{j \in J'(k)}^{}{a_j,_k}}
\end{equation}","['summation', 'discrete-mathematics']"
413924,What does the notation $[V]^2$ mean (in graph theory)?,"In graph theory, a graph is a pair $G=(E,V)$ of sets satisfying $E\subseteq[V]^2$. But what is $[V]^2$? I suppose that it is the same as $V\times V=V^2$, but I do not know where the square brackets come from. Thanks in advance!","['notation', 'graph-theory', 'elementary-set-theory']"
413932,Convergence of a Series $\sum_{n=1}^{\infty}\left(\frac{n}{n+1}\right)^{n^2}$- Which Test? [duplicate],"This question already has answers here : Need hint: Determine whether the series $\sum_{n=1}^{\infty}(\frac{n}{n+1})^{n^2}$ is convergent or divergent. (3 answers) Closed 4 years ago . I tried root and ratio tests but it didn't work. Also, i can't use integral tests (and other ""uncommon"" ones) in this homework. (Prove that the series is convergent)
$$\sum_{n=1}^{\infty}\left(\frac{n}{n+1}\right)^{n^2} = \frac{1}{2} + \left(\frac{2}{3}\right)^4 + \left(\frac{3}{4}\right)^9 + ...$$",['sequences-and-series']
413933,The nested self-composition of $f(x) = \frac{\sqrt3}2x+\frac12\sqrt{1-x^2}$,"The function $f(x)$ is defined, for $|x|\leqslant1$ by $$f(x)=\frac{\sqrt 3}{2}x+\frac{1}{2}\sqrt{1-x^2}.$$ Find an expression for $$f^n(x)=\underbrace{f \circ  f \circ \cdots \circ f(x)}_{\text{n times}},$$where $n\in\mathbb{Z^+}$. Now what I did was to first find $f^2(x)$ and my intention was to find $f^3(x)$ and another few cases so as to recognise a pattern. However, $f^2(x)$ is actually very complicated and does not simplify too much. I am looking for hints on how to approach the problem and not complete solutions. Thanks in advance.","['functions', 'function-and-relation-composition']"
413943,Bound on Expectation of a convex function of a Random variable,"My friend asked me the following question, which I at first thought was simple and straightforward: If $X$ is an integrable random variable and $g$ is a convex function(all real valued), then is it true that $\forall a>0$
$$E[g(X)] < \infty \Rightarrow E[g(aX)] < \infty \quad?$$ Question: My guess is that this would be true although when I tried to prove it, I got stuck. Let me describe my attempt: $$E[g(aX)] = \int_{u \in \mathbb{R}}g(au)dF_X(u)$$ Put $au=t$, then you get
$$\frac{1}{a}\int_{t \in \mathbb{R}}g(t)dF_X(t/a)$$ If the $dF_X(t/a)$ was $dF_X(t)$, I'd be done. But I'm probably a step away. Additionally I have not used convexity anywhere so it's probably superfluous. I'd appreciate it if someone could shed some light on this matter. Kindly request clarifications if necessary.","['probability-theory', 'convex-analysis']"
413949,"Berkeley exam summer '79, sequence of continuous functions, integral, convergence","I've recently been browsing some Berkeley exams and I'm particularly interested in Problem 19 here . Let ${f_n}$ be a sequence of continuous real functions deﬁned on $[0,1]$ such that $\int_0^1 (f_n(y))^2 dy \le 5$ 
  for all $n$. Deﬁne $g_n : [0,1] \rightarrow \mathbb{R}$ by
  $g_n(x) = \int ^1_0 \sqrt{x + y} f_{n} (y)dy$. Find a constant $K > 0$ such that $|g_n(x)| \le K$ for all $n$. Prove that a subsequence of the sequence $\{g_n\}$ converges uniformly. Could you help me solve it? Frankly speaking, I don't know how to use the condition that $\int_0^1 (f_n(y))^2 dy \le 5$.","['convergence-divergence', 'calculus', 'integration', 'contest-math', 'continuity']"
413950,Proving Abel-Dirichlet's test for convergence of improper integrals using Integration by parts,"I'm struggling with the following calculus question. Let there be two functions $f,g : [a, \infty) \to \mathbb R$ such that: $g$ is monotonic, differentiable and has a limit at zero $f$ is continuous such that $$\int_a^\infty f(x)dx < M \in \mathbb R$$ Prove that integral $$\int_a^{\infty} f(x)g(x)dx$$ converges. While I do know how to prove the theorem using the Second Mean Value Theorem, I've got no idea how to prove it using integration by parts. How can this be done? Any hints or leads will be greatly appreciated. Thank you","['improper-integrals', 'calculus', 'integration']"
413965,Important numbers in Combinatorics,"I recently went through some important numbers like the Stirling and Bell number for calculation of partitions /equivalence relations. I was wondering if someone can help me get a list of important numbers and their applications in Combinatorics ;
like Catalan , Fibonacci , Stirling etc.???","['fibonacci-numbers', 'catalan-numbers', 'stirling-numbers', 'combinatorics']"
413988,Delta epsilon proof with $x \rightarrow \infty$,"I have a rational function that reaches a horizontal asymptote as $x \rightarrow \infty$ .
How would you do a delta-epsilon proof with $x\to\infty$ . Here is the limit statement: $$\lim_{x\to\infty}\frac{3x+7}{2x-1} = \frac{3}{2}.$$ Hope some one can help. Paulo","['probability-limit-theorems', 'calculus']"
414000,"$f : \mathbb{R} \to \mathbb{R}$ be injective then $f^{ −1} (\mathbb{Q} \cap [0, 1])$ is","Let $f : \mathbb{R} \to \mathbb{R}$ be injective then $f^{ −1} (\mathbb{Q} \cap [0, 1])$ is (a) measurable and its measure is 0. (b) measurable and its measure is 1. (c) measurable and its measure is ∞. (d) need not be measurable. totally clueless, please help. I know  that $[0,1],\mathbb{Q}$ are borel measurable and hence their intersection, also they are lebesgue measurable",['measure-theory']
414012,proof about commutative operators and T-cyclic vectors,"Let $V$ be a finite dimensional vector space over $F$. Let $T:V \to V$ be a linear operator.
Prove that if every linear operator $U$ which commutes with $T$ is a polynomial of $T$, than $T$ has a $T$-cyclic vector. I don't really know where to start...
can someone please point me in the right direction?",['linear-algebra']
414020,approximating essential supremum,"Let $(\Omega,\mathbb{F},P)$ be a filtred probability space. For $t\in [0,T]$, we are given sets $U_t$ of non negative stochastic processes $X=\{X_s;0\le s\le T\}$. We know that for $s\le t$ we have $U_t\subset U_s$. Let $f$ be a positive r.v. in $\mathcal{F}_T$, which is fixed. Now the object I study is the following: $$W_t:=\operatorname{ess}\sup_{X\in U_t}E[X_T f|\mathcal{F}_t]$$ I was able to prove that $\{E[X_T f|\mathcal{F}_t]:X\in U_t\}$ is upward directed. Hence I know that there is a sequence $\{X^n\}$ in $U_t$ such that $$W_t=\lim_n E[X_T^n f|\mathcal{F}_t]$$ where the limit is increasing. I want to prove that $(W_t)$ has the supermartingale property. Using monotone convergence $$E[W_t|\mathcal{F}_s]=\lim_nE[fX_T^n|\mathcal{F}_s]$$ My notes says, because $\{X^n\}\in U_t\subset U_s$, we have $$\lim_nE[fX_T^n|\mathcal{F}_s]\le \operatorname{ess}\sup_{X\in U_s}E[fX_T|\mathcal{F}_s]=W_s$$ Why is this inequality true? This is bothering me now for a while, but I really do not see why it is true. So some help would be appreciated.","['probability-theory', 'stochastic-processes', 'measure-theory']"
414023,"Probability of winning the game ""1-2-3""","Ok, game is as follow, with spanish cards (you can do it with poker cards using the As as a 1) You shuffle, put the deck face bottom, and start turning the cards one by one, saying a number each time you turn a card around ---> 1, 2, 3; 1, 2, 3; etc. If when you say 1 a 1 comes out, you lose, same with 2 and 3. If you finish the deck without losing, you win. I know some basics of probabilities, but is there a way to calculate the probability of winning the game, given a random shuffled deck?","['card-games', 'probability']"
414039,Proof that binomial coefficients are integers - combinatorial interpretation,"For any integers $k \le n$ here is an injective group homomorphism $$S_k \times S_{n-k} \rightarrow S_n$$ such that a tuple $(\sigma, \tau)$ permutes $\{1,...,n\}$ by letting $\sigma$ act on $\{1,...,k\}$ and $\tau$ act on $\{k+1,...,n\}$. By Lagrange's theorem, $k!(n-k)! = |S_k \times S_{n-k}|$ divides $|S_n| = n!$, so $\binom{n}{k} = \frac{n!}{k!(n-k)!}$ is an integer. In the comments of some question from several months ago (that I can't find now) it was asked if we can find a combinatorial interpretation of this result - that the cosets of $S_k \times S_{n-k}$ in $S_n$ should correspond naturally to ways of choosing $k$ elements from a set of $n$. To me there is no obvious correspondence and I would like to know if anyone has an interpretation in that sense.","['group-theory', 'combinatorics']"
414044,Inverse function theorem in complex analysis,"I was wondering whether an inverse function theorem in the complex numbers exists?
I mean, in the real numbers we have that if the derivative of a function is non zero, then  the inverse function is also differentiable in a local region. Is there anything that is related to this for complex functions? Or how would one show that the $Ln$ defined as the inverse function of the exponential function is differentiable?","['calculus', 'complex-analysis', 'analysis']"
414060,Residually finiteness for a factor group,"Suppose we have a finitely presented residually finite group $G=\langle X\,; R \rangle$, two isomorphic finite subgroups $C$ and $D$ of $G$. The question is whether the group $H=\langle X\,; R, C=D \rangle$ is also residually finite. If not, can we prove a similar statement under some reasonable additional assumptions? Here are some related comments. First, factor group of a residually finite group is not necessarily residually finite. So if the above question has an affirmative answer, the finite condition on $C$ and $D$ should be essential. Second, it may worth noting that, if the HNN extension $\langle X, t\,; R, C^t=D \rangle$ is considered instead of $H$, then it is again a residually finite group provided that $C$ and $D$ are finite groups.","['group-theory', 'group-presentation']"
414061,Prove $e^{x+y}=e^{x}e^{y}$ by using Exponential Series,"In order to show $e^{x+y}=e^{x}e^{y}$ by using Exponential Series, I got the following: $$e^{x}e^{y}=\Big(\sum_{n=0}^{\infty}{x^n \over n!}\Big)\cdot \Big(\sum_{n=0}^{\infty}{y^n \over n!}\Big)=\sum_{n=0}^{\infty}\sum_{k=0}^n{x^ky^n \over {k!n!}}$$ But, where should I go next to get $e^{x+y}=\sum_{n=0}^{\infty}{(x+y)^n \over n!}$. Thanks in advance.","['exponential-function', 'real-analysis']"
414071,Volume bounded by sphere $x^2+y^2+z^2=a^2$ and cylinder $x^2+y^2=a|x|$,"What is the volume bounded by the sphere $x^2+y^2+z^2=a^2$ and the cylinder $x^2+y^2=a|x|$? The answer can be in terms of the value $a$ (or $r$). Does someone know how to do this?
Thank you in advance!","['multivariable-calculus', 'volume']"
414074,Simple Differential Equation,"We have
  $$\frac{dx}{dt}=x-y-1$$
  $$\frac{dy}{dt}=x-y+1$$ Express $y$ in terms of only $x$ (i.e. no $t$ term). My professor gave me the hint ""use $\frac{d}{dt}(x-y)$"", but I don't know how this is supposed to help me.","['fluid-dynamics', 'ordinary-differential-equations']"
414107,Ratio between trigonometric sums: $\sum_{n=1}^{44} \cos n^\circ/\sum_{n=1}^{44} \sin n^\circ$,"What is the value of this trigonometric sum ratio: $$\frac{\displaystyle\sum_{n=1}^{44} \cos n^\circ}{\displaystyle \sum_{n=1}^{44} \sin n^\circ} = \quad ?$$ The answer is given as $$\frac{\displaystyle\sum_{n=1}^{44} \cos n^\circ}{\displaystyle \sum_{n=1}^{44} \sin n^\circ}  \approx \displaystyle \frac{\displaystyle\int_{0}^{45}\cos n^\circ dn}{\displaystyle\int_{0}^{45}\sin n^\circ dn} = \sqrt{2}+1$$ Using the fact $$\displaystyle  \sum_{n = 1}^{44}\cos\left(\frac{\pi}{180}\cdot n\right)\approx\int_0^{45}\cos\left(\frac{\pi}{180}\cdot x\right)\, dx $$ My question is that I did not understand the last line of this solution. Please explain to me in detail. Thanks.","['trigonometry', 'approximation']"
414130,Rearrangements of absolutely convergent series,"Accounts of absolute and conditional convergence always say that
$$
\sum_{n=0}^\infty a_n = \sum_{n=0}^\infty a_{\sigma(n)}
$$
if the series converges absolutely, if $\sigma$ is any bijection from the set of indices to itself. Fubini's theorem tells us that
$$
\sum_{n=0}^\infty\sum_{m=0}^\infty a_{n,m} = \sum_{m=0}^\infty\sum_{n=0}^\infty a_{n,m}
$$
if we have absolute convergence.  (Tonelli's theorem tells us that these are equal if all terms are nonnegative, regardless of whether the series converges or not.) But in this answer , I explained how to rearrange
$$
\sum_{n=0}^\infty\sum_{m=0}^\infty a_{n,m}
$$
into
$$
\sum_{n=0}^\infty \sum_{k=0}^n a_{k,n-k}.
$$
What known theorems apply to this case, and where is this case mentioned in the literature? How exotic does the class of rearrangements of series get?  What other kinds of rearrangements don't fit instantly into one of the cases covered by the two categories above that are covered by standard results? (I might post my own answer to this.)","['sequences-and-series', 'analysis']"
414144,The Fitting subgroup centralizes minimal normal subgroups in finite groups,"Let $G$ be a finite group:
If $N$ is a minimal normal subgroup of $G$, then $F(G) \leq C_G(N)$. Here $C_G(N)$ denotes the centralizer of $N$ in $G$, and
$F(G)$ denotes the Fitting subgroup of $G$.","['finite-groups', 'group-theory']"
414152,About the sum of the digits of $k^{105}$.,I read here that We cannot find an integer $k>2$ such that the sum of the digits of $k^{105}$ is $k$. Does anyone know a proof of this?,"['elementary-number-theory', 'number-theory']"
414162,Sheafification of singular cochains,Let $S^k$ be the presheaf on a space $X$ that assigns to every open set $U$ the abelian group $S^k(U)$ of singular k- cochains on $U$. This is clearly not a sheaf. Consider the sheafification $F^k$ of each $S^k$. These sheaves form an exact resolution of the constant sheaf of integers. We can take global sections on this sheaf resolution to obtain a cochain complex $F^*(X)$. Does the cohomology of this cochain complex coincides with ordinary singular cohomology?,"['sheaf-theory', 'algebraic-geometry', 'algebraic-topology']"
414168,Multiple Integral,"I'd like to know when exactly we have the right to inverse the order of the variables in a multiple integral. Which are the cases which cause problems. (When $\int_a^b \int_c^d \int_e^f f(x,y,z) \, \mathrm dx\, \mathrm dy \, \mathrm dz \neq \int_c^d \int_a^b \int_e^f f(x,y,z) \, \mathrm dx\, \mathrm dz \, \mathrm dy$ ??). And when we have the right to do it what changes we have to do in the function?","['definite-integrals', 'integration']"
414184,Algebra simplification in mathematical induction .,"I was proving some mathematical induction problems and came through an algebra expression that shows as follows: $$\frac{k(k+1)(2k+1)}{6}  + (k + 1)^2$$ The final answer is supposed to be: $$\frac{(k+1)(k+2)(2k+3)}{6}$$ I walked through every possible expansion; I combine like terms, simplify, factor, but never arrived at the answer. Could someone explain the steps?",['algebra-precalculus']
414185,"For $x, y, z \in \mathbb{R}$, $(x^y)^z = x^{yz}$?","Is it always true that for $x, y, z \in \mathbb{R}$, $(x^y)^z = x^{yz}$, whenever both expressions are defined?  Assume all are nonzero. I think this isn't true in general, because for instance $$-1 = (-1)^{2/2}$$ but $$((-1)^2)^{1/2} = 1^{1/2} = 1$$",['algebra-precalculus']
414188,How to define the canonical Godement resolution,"Good afternoon :
I whould like to know how to define the canonical Godement resolution of a flasque sheaf.
Thanks a lot.",['algebraic-geometry']
414203,Integral inequation,"In my statistics book Chebyshev's inequality is proven. In several steps this inequality is used: $$ \int_a^{+\infty} \phi(x) f_X(x)dx \quad \geq \quad \phi(a) \int_a^{+\infty} f_X(x)dx $$ and also: $$ \int_{-\infty}^{-a} \phi(x) f_X(x)dx \quad \geq \quad \phi(-a) \int_{-\infty}^{-a} f_X(x)dx $$ Here is $a \geq 0$, $\phi:\mathbb{R}\to\mathbb{R}^+$ a positive function, and $f_X$ a pdf. Why this is valid?","['statistics', 'inequality', 'calculus', 'integration']"
414232,Proving that $\omega(N)\neq4$ for an odd perfect number $N$ by hand,"Let $\omega(n)$ denote the number of distinct prime factors of a positive integer $n$, and let $N$ be an odd perfect number. It is not difficult to show that $\omega(N)\ge3$. In fact, Nocco already proved this in 1863. Showing that $\omega(N)\neq3$ requires a little more effort, but the proof is still fairly short. I will present some version of the proof below; the original one is due to Peirce in 1830 (which, interestingly, seems to have been published before Nocco's proof). The two key ideas here are the geometric series and the factor chain method. Let $N=\displaystyle\prod_{i=1}^k p_i^{e_i}$ be the prime factorization of $N$. Then it follows that $$\sigma(N)=\prod_{i=1}^k \sum_{j=0}^{e_i} p_i^j=\prod_{i=1}^k \frac{p_i^{e_i+1}-1}{p_i-1}.$$ This formula is useful, because each factor is necessarily greater than one when $e_i$ is positive, which is the case for all prime factors $p_i$. Hence $\sigma(N)\ge\sigma\left(\displaystyle\prod_{i\in{I}} p_i^{e_i}\right)$, where $I\subseteq\{1,2,\ldots,k\}$. The second idea is perhaps even more fundamental, because we have yet to use the property of perfectness. Since $\sigma(N)=2N$, every divisor of $\sigma(N)$ must also divide $2N$; the other way around is not as interesting. In particular, every factor $\frac{p_i^{e_i+1}-1}{p_i-1}$ must divide $2N$. This result is really powerful; for example, observing that $2^1||2N$ yields Euler's well-known form of an odd perfect number after some algebra. With these tools in our toolbox, the proof is almost immediate. Let $p^\alpha$, $q^\beta$, and $r^\gamma$ be three odd prime powers with $p<q<r$ and assume that $N=p^\alpha q^\beta r^\gamma$ is an odd perfect number. By the same token as above, we see that $$\begin{align*}\sigma(N)=\sigma(p^\alpha q^\beta r^\gamma) &= \frac{p^{\alpha+1}-1}{p-1} \cdot \frac{q^{\beta+1}-1}{q-1} \cdot \frac{r^{\gamma+1}-1}{r-1} < \frac{p^\alpha p}{p-1} \cdot \frac{q^\beta q}{q-1} \cdot \frac{r^\gamma r}{r-1}\\\implies& \frac{\sigma(N)}{N} = \frac{\sigma(p^\alpha q^\beta r^\gamma)}{p^\alpha q^\beta r^\gamma} < \frac{p}{p-1} \cdot \frac{q}{q-1} \cdot \frac{r}{r-1}.\end{align*}$$ Suppose that $p=5$. Then $\frac{\sigma(N)}{N}<\frac{5}{4}\cdot\frac{7}{6}\cdot\frac{11}{10}=\frac{77}{48}<2$, which is impossible. Hence $p=3$. Suppose that $q=7$. Then $\frac{\sigma(N)}{N}<\frac{3}{2}\cdot\frac{7}{6}\cdot\frac{11}{10}=\frac{77}{40}<2$, which is impossible. Hence $q=5$. Suppose that $r=17$. Then $\frac{\sigma(N)}{N}<\frac{3}{2}\cdot\frac{5}{4}\cdot\frac{17}{16}=\frac{255}{128}<2$, which is impossible. Hence $r \le 13$. In consequence, we have three possible cases to consider: $r=7$, $r=11$, and $r=13$. In the first case, we have $N=3^\alpha 5^\beta 7^\gamma$. By the factor chain method, $3^1||N$ implies $4|2N$ and $7^1||N$ implies $8|2N$, neither of which is possible. Hence $\alpha\ge2$ and $\gamma\ge2$. It follows that $$\frac{\sigma(N)}{N} \ge \frac{\sigma(3^2\cdot5\cdot7^2)}{3^2\cdot5\cdot7^2} = \left(1 + \frac{1}{3} + \frac{1}{3^2}\right)\left(1 + \frac{1}{5}\right)\left(1 + \frac{1}{7} + \frac{1}{7^2}\right)=\frac{494}{245}>2,$$ which is impossible, but we already knew that $105=3\cdot5\cdot7$ cannot divide an odd perfect number. In the second case, we have $N=3^\alpha 5^\beta 11^\gamma$. Suppose that $\beta=1$. It follows that $$\frac{\sigma(N)}{N} = \frac{\sigma(3^\alpha\cdot5\cdot11^\gamma)}{3^\alpha\cdot5\cdot11^\gamma} < \frac{3}{2} \cdot \frac{6}{5} \cdot \frac{11}{10} = \frac{99}{50} < 2,$$ which is impossible ( could we know that beforehand? ). Hence $\beta\ge2$. By the factor chain method, $\alpha\ge4$ and $\gamma\ge4$. It follows that $$\frac{\sigma(N)}{N} \ge \frac{\sigma(3^4\cdot5^2\cdot11^4)}{3^4\cdot5^2\cdot11^4} = \left(1 + \frac{1}{3} + \frac{1}{3^2} + \frac{1}{3^3} + \frac{1}{3^4}\right)\left(1 + \frac{1}{5} + \frac{1}{5^2}\right)\left(1 + \frac{1}{11} + \frac{1}{11^2} + \frac{1}{11^3} + \frac{1}{11^4}\right)=\frac{99851}{49005}>2,$$ which is impossible, but we already knew that $825=3\cdot5^2\cdot11$ cannot divide an odd perfect number. In the third case, we have $N=3^\alpha 5^\beta 13^\gamma$. $\beta=1$ implies deficiency, so $\beta\ge2$. Now, $\alpha=2$ also implies deficiency, so $\alpha\ge4$. By the factor chain method, we must have $\gamma\ge2$, which this time implies abundance. Hence the assumption leads to a contradiction; furthermore, $8775=3^3\cdot5^2\cdot13$ cannot divide an odd perfect number. We are finally done. Unfortunately, proving that $\omega(N)\neq4$ is not this easy by hand. We can similarly show that $p=3$, but then we already have two possible choices for $q$. Of course, one could just write a program and loop through all the possibilities, but Sylvester did it successfully in 1888, unlikely by the aid of computers. Hence I wonder if this algorithm can be significantly improved, or if there are other more efficient techniques that achieve the same goal.","['arithmetic-functions', 'number-theory']"
414248,Why does $\arctan(x)= \frac{1}{2i}\log \left( \frac{x-i}{x+i}\right)+k$?,"Letting $x=\tan(u)$,
$$\int\frac{1}{1+x^2} \, dx=\int\frac{1}{1+\tan(u)^2}\sec^2(u) \, du=u+k=\arctan(x)+k$$
Also, 
$$\int\frac{1}{1+x^2} \, dx=\int\frac{1}{(x-i)(x+i)} \, dx=\frac{1}{2i}\int\frac{1}{(x-i)}-\frac{1}{(x+i)} \, dx$$
$$=\frac{1}{2i}\left(\ln(x-i)-\ln(x+i)\right)+c$$
$$=\frac{1}{2i}\ln \left(\frac{x-i}{x+i} \right)+c$$
Giving
$$\arctan(x)=\frac{1}{2i}\ln \left(\frac{x-i}{x+i} \right)+q$$ Why is this correct? What is the nature of $q$ (is it 'flexible' so the equality doesn't really mean much)? I think it probably has something to do with the relationship between $\log(z)$ and $\arg(z)$, but $\arg(z\pm i)$ is hard to calculate neatly.",['integration']
414254,How many Jordan normal forms are there for this characteristic polynomial?,"Given the characteristic polynomial of a matrix $A \in \mathbb{C}^{6x6}$ with $p(A)=(\lambda-2)^2(\lambda-1)^4$, we were supposed to determine all Jordan normal forms that have this characteristic polynomial. I determined 10 (is this correct?) and was wondering whether this is a general way to compute the number of them for an arbitrary characteristic polynomial.","['linear-algebra', 'abstract-algebra']"
414258,"If each subset of $L$ with an upper bound has a least upper bound, then each subset with a lower bound a a greatest lower bound","Proposition: Let $L$ be a lattice in which every subset with an upper bound has a least upper bound. Then every subset with a lower bound has a greatest lower bound. Attempt Definition: A lattice, $L$, is a partially ordered set where given any two elements of $L$, $a$ and $b$, the set $\{ a,b \}$ has a least upper bound and a greatest lower bound. Denote a subset of $L$ by $S$. If $S$ has an upper bound, then $S$ has a least upper bound, or more precisely, given $u \in L$, $\forall s \in S$, $s \le u$ and given any upper bound, $v$, of $S$, $u \le v$. Suppose $S$ has a lower bound, $w$. Then $\forall s \in S$, $w \le s$. My question From here, I think I need to rely on the definition of a lattice. However, the definition only applies to a two element subset, where the proposition provides any subset. Two candidates I thought that may lead to progression is the transitivity axiom for a partially ordered set, or a previous proposition I provided that any chain is a lattice. Presently, I am unsure on how to figure these in. I would appreciate some assistance on what I need to do in order to complete this proof. Source: Kaplansky, I. (1972). Set Theory and Metric Spaces.","['elementary-set-theory', 'order-theory']"
