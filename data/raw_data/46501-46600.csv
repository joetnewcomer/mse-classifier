question_id,title,body,tags
466757,Why can we interchange summations?,"Suppose we have the following $$ \sum_{i=1}^{\infty}\sum_{j=1}^{\infty}a_{ij}$$ where all the $a_{ij}$ are non-negative. We know that we can interchange the order of summations here. My interpretation of why this is true is that both this iterated sums are rearrangements of the same series and hence converge to the same value, or diverge to infinity (as convergence and absolute convergence are same here and all the rearrangements of an absolutely convergent series converge to the same value as the series). Is this interpretation correct. Or can some one offer some more insightful interpretation of this result? Please note that I am not asking for a proof but interpretations, although an insightful proof would be appreciated.","['sequences-and-series', 'real-analysis']"
466765,Realizing a list of varieties as the toric variety of a fan,"The locus of the following curves define affine varieties. $xy-z^m=0.$ $x^m+xy^2+z^2=0.$ $x^4+y^2+z^2=0.$ $x^2+y^3+z^2=0.$ $x^5+y^3+z^2=0.$ In Fulton's ""Toric Varieties"" book he constructs toric varieties from a fan (a collection of cones satisfying some properties). I am trying to construct the above listed varieties as toric varieties i.e. I am trying to find fans whose associated toric varieties are isomorphic to the affine varieties in the list. I know how to do the first one. We take the lattice $N= \mathbb{Z}^2$ and let $\sigma$ be the cone generated by $(0,1)$ and $(m,-1).$ Then $\sigma^{\vee}\cap M$ (where $\sigma^{\vee}, M$ are the dual cone and dual lattice) is generated by $(1,0), (1,1), (1,2), \ldots, (1,m).$ Therefore the fan that consists of this cone and all of its faces has the associated toric variety with coordinate ring $\mathbb{C}[X,XY,\cdots, XY^m] \cong \dfrac{ \mathbb{C}[U,V,W] }{(W^m - UV)}$ as required. Affine varieties must come from a fan of the previous form: A cone and all of its faces. I also know that the resulting varieties from such fans must always be defined by monomial equations i.e. intersections of curves of the form $X_1^{a_1} X_2^{a_2} \ldots X_k^{a_k} = X_1^{b_1} X_2^{b_2} \ldots X_k^{b_k}$ for nonnegative integers $a_i, b_i.$ Varieties 2-5 don't seem to look like this, so I am stuck. Can someone please help me do the other ones, or refer me to relevant books/papers? Thank you.","['algebraic-geometry', 'toric-geometry']"
466809,Solving a set of equations with Newton-Raphson,"I want to solve this set of equations with Newton-Raphson.
Can anybody help me? $$ \cos(x_1)+\cos(x_2)+\cos(x_3)= \frac{3}{5} $$
$$ \cos(3x_1)+\cos(3x_2)+\cos(3x_3)=0 $$
$$ \cos(5x_1)+\cos(5x_2)+\cos(5x_3)=0 $$ Best regards.","['trigonometry', 'systems-of-equations', 'newton-raphson', 'numerical-methods']"
466823,polynomials over finite field with irreducible factors of odd degrees,It is well-known that the number of monic $n$-degree polynomials over a finite field of size $q$ is $q^n$. How many such degree-$n$ polynomials can be completely factored into only irreducible polynomials of odd degree? Does anyone know of any related literature?,"['finite-fields', 'discrete-mathematics', 'polynomials']"
466826,A good book that provides context for abstract algebra,"One of my problems with Abstract Algebra was that it was well... abstract. I could infer from doing problems ""Oh this is useful for doing math with objects I'm not typically used to working with"". However, most of what I did felt irrelevant and almost boring. Is there a good book that provides abstract algebra with some context? For example, one that incorporates the problems that mathematicians were trying to solve when developing it?","['reference-request', 'abstract-algebra']"
466828,What the rest of the division $5^{21}$ by $127$?,What the rest of the division $5^{21}$ by $127$?,"['congruences', 'number-theory']"
466834,Power towers: to infinity and all the way back,"In the following, let $n$ be a positive integer, all other variables be real (furthermore, $a>1$), all functions be real-valued, and logarithms of negative arguments be undefined. Let $\log^n(x)$ denote the iterated natural logarithm (base $e$), with $x$ in the innermost position, $\operatorname{pow}_a^n(x)$ denote the iterated exponentiation (base $a$), with $x$ in the innermost position, where the superscript ${}^n$ to the right of a function name denotes the number of iterations of the function (not raising its result to a power). More precisely, $\hspace{.2in}\begin{cases}
\log^1(x) = \ln x \\
\log^{n+1}(x) = \log^n(\ln x)
\end{cases}$ $\hspace{.2in}\begin{cases}
\operatorname{pow}_a^1(x) = a^x \\
\operatorname{pow}_a^{n+1}(x) = \operatorname{pow}_a^n(a^x)
\end{cases}$ For example, $\log^3(x) = \ln \ln \ln x$, and $\operatorname{pow}_a^2(x) = a^{a^x}$. Now define $$\boxed{\phantom{\Bigg|}\hspace{0.2in} 
f_a(x) = \lim\limits_{n\to\infty} \log^n(\operatorname{pow}_a^n(x))
\hspace{0.25in}}$$
In other words, $f_a(x)$ is the limit of the sequence $\{\ln a^x,\ \ln \ln a^{a^x},\ \ln \ln \ln a^{a^{a^x}},\ \dots\}$. Note that the first several elements of the sequence can be simplified, but next ones will end up with a repeated logarithm of a sum with the rest of the power tower sitting inside: $\{x \ln a,\ x \ln a+\ln \ln a,\ \ln\left(a^x \ln a+\ln \ln a\right),\ \ln \ln\left(a^{a^x}\ln a+\ln \ln a\right),\ \dots\}$. Obviously, $f_e(x)=x$. The behavior of the function for other values of $a$ is more interesting. Questions: Can any non-trivial ($a \ne e$) value of $f_a(x)$ with closed-form arguments be expressed in a closed form in terms of elementary functions, any known special functions, and any known mathematical constants? What is the domain of $f_a(1)$? Is $f_a(1)$ an analytic function within its domain? What is the domain of $f_2(x)$? Is $f_2(x)$ an analytic function within its domain? What it the range of $f_3(x)$? What is the value of $\lim\limits_{x \to \infty} \frac{f_2(x)}{x}$, if it exists? What is the asymptotic behavior of $f_2(x)$ as $x \to \infty$? What is the value of $\lim\limits_{x \to -\infty} f_3(x)$, if it exists? What is the asymptotic behavior of $f_3(x)$ as $x \to -\infty$? What is the Taylor expansion of $f_a(1)$ near $a=e$?","['sequences-and-series', 'logarithms', 'asymptotics', 'real-analysis', 'limits']"
466842,Negative self intersection and section of the conormal sheaf for a singular complex curve,"Let $M$ be a complex $2$-dimensional manifold and $C$ be a compact complex curve in $M$ (possibly singular).
Let us suppose that there exists a holomorphic function $f\in\mathcal{O}(M)$ such that $f$ is non constant $\{f=0\}=C\cup A$, with $A$ a complex analytic set of dimension $1$ there is no neighborhood $V$ of $C$ and no function $g\in\mathcal{O}(V)$ such that $C=\{g=0\}$. I would like to conclude that $C\cdot C<0$. If $C$ is smooth, then $f$ gives me a nontrivial section of the conormal bundle: let $\{F_j\}$ be local equations for $C$, then $\{f/F_j\}_j$ gives a section of $[-C]\vert_C=N^*_{C,M}$ (the conormal bundle of $C$ in $M$), hence $\deg N_{C,M}<0$, therefore $C\cdot C<0$. What if $C$ is singular? NOTE: I posted the same question on MathOverflow ( https://mathoverflow.net/questions/139686/negative-self-intersection-and-section-of-the-conormal-sheaf-for-a-singular-comp ).","['intersection-theory', 'algebraic-geometry', 'complex-geometry']"
466843,Variance of n Bernoulli Trials,"Count the variance of n Bernoulli trials with each probability of success is p. Let random variable $X_i$ be $1$ if trial is success, or $0$ if trial fails. Then expected value $E(X_i) = 1 \times p + 0 \times (1 - p) = p$. By linearity of expectation $E(X) = p_1 + p_2 + ... + p_n = np$. To count the variance, I use this formula $V(X) = E(X^2) - E(X)^2$. where $E(X_i^2) = 1^2 \times p + 0^2 \times (1 - p) = p$ then, $E(X^2) = p_1 + p_2 + ... + p_n = np$. So, I got variance $V(X) = np - (np)^2 = np(1 - np)$. But in wiki , 
it says that the correct variance is $np(1 - p)$. Where did I do wrong? Thanks a lot for the help.","['discrete-mathematics', 'probability']"
466873,"If $K$ is finite, then every subset of $\mathbb A^n(K)$ is algebraic","I'm trying to prove that if $K$ is a finite field, then every subset of $\mathbb A^n(K)$ is algebraic. I know that if $K$ is finite, then every element of $K$ is algebraic, i.e., for every $a\in K$ there is a polynomial $f\in K$ such that $f(a)=0$, but this didn't help me to solve the question. I almost sure that we have to use this to solve this question. I need help. Thanks in advance.",['algebraic-geometry']
466879,Prove that Every Vector Space Has a Basis,"My textbook extended the following proof to show that every vector space, including the infinite-dimensional case, has a basis. Condition: $S$ is a linearly independent subset of a vector space $V$. Theorem:  There is a maximal linearly independent subset of $V$ that contains $S$. Proof. Let $F$ be the family of all linearly independent subsets of $V$ that contains $S$.  If $C$ is a chain in $F$ and there exists a member $U \in F$ that contains each member of $C$, by the maximal principle, $U$ is the maximal element of $F$, the family of all linearly independent subsets of $V$.  As a result, $U$ is the maximal linearly independent subset of $V$.  So $U$ is the basis of $V$. Let $U$ be the union of the elements of $C$.  Clearly $U$ contains each element of $C$.  To show that $U$ is a linearly independent subset of $V$, first note that $S \subset U$.  Let $u_1, u_2, \ldots, u_n$ be vectors in $U$ and $c_1, c_2 ... c_n$ be scalars such that $0 = \sum_{i=1}^{n} {c_i}{u_i}$.  Because $u_i \in U$ for all $i$, there exist sets $A_i$ in $C$ such that $u_i \in A_i$.  Since $C$ is a chain, there is one set, say $A_k$, that contains all the others.  So $u_1, u_2,\ldots, u_n \in A_k$.  But since $A_k$ is linearly independent, $c_i = 0$ for all $i$.  Therefore, $U$ is linearly independent.  By the maximal principle, $U$ is the maximal element of $F$. $\square$ My questions are as follows: Is the author arguing that since each vector space has a basis, the infinite-dimensional vector space also has a basis?  This is similar to saying that $\lim_{n \rightarrow \infty} a_n = 0$ if $a_n = 0$ for all $n$. How come the author is checking one chain $C \in F$ only?  I thought that the maximal principle requires that the maximal element contains all members of each chains. I am still not sure of how $u_1, u_2, \ldots, u_n$ are picked out.  The greatest number of vectors in a linearly independent subset cannot exceed $\dim(V)$, but that is assuming that $V$ has a basis.  So, how does the author know what the finite number $n$ is? When the author is assigning $u_i$ to $A_i$, the set $\{A_i\}$ is not yet a chain.  But the $A_i$ can be rearranged to form a chain.  For example, $u_1 \in B_1$, $u_1, u_2 \in B_2,\ldots,$ and $u_1, u_2,\ldots, u_n \in B_n$.","['vector-spaces', 'linear-algebra', 'axiom-of-choice']"
466883,Are electrodynamic problems in the complex plane relevant to real life?,"I have been reading Tristan Needham's excellent Visual Complex Analysis. The end of the book deals almost entirely with physics, using symmetries of conformal mappings to generalise the famous method of images technique in electrodynamics. The method of images is used in finding the electric field due to a charge when a grounded surface (such as a sphere or plane) is nearby. See http://en.wikipedia.org/wiki/Method_of_image_charges However, the problems seem to have very little ""real life"" applications to me, the main problem being that the complex plane is two dimensional, whereas we live in a 3 dimensional world. To see this problem concretely, the electrostatic force is goes like $F\sim \frac{1}{r^2}$ because the surface area of a ball of radius $r$ centred at the charge is proportional to $r^2$. However since the complex plane is 2 dimensional, a charge in the complex plane produces a field which goes like $\frac1r$. So any solution we find to a problem of this kind in the complex plane isn't relevant in 3d. And this is my question, is there any physical application of this technique? Or is it completely irrelevant?","['physics', 'complex-analysis']"
466885,"$\mathbb{Q}[X,Y]/(Y^2-X^3)$ is not a UFD","I'm trying to show that $R = \mathbb{Q}[X,Y]/(Y^2-X^3)$ is not a UFD, but I got stuck. To prove this, I could try to find two ""different"" factorisations for one element, but I am not familiar with this, so I tried to use a lemma and one of the previous exercises.
If my syllabus is right, in every UFD counts
$$ x \ \text{is irreducible} \quad \iff \quad x \ \text{is prime}$$
My syllabus also states that the elements $\bar{X}, \bar{Y} \in R$ are irreducible.
So I tried to show that at least one of the elements $\bar{X}, \bar{Y} \in R$ does not generate a prime ideal. This would mean that I should find two polynomials $f,g \in \mathbb{Q}[X,Y]$, such that 
$$\exists p \in \mathbb{Q}[X,Y], \quad fg - pX \in (Y^2-X^3)$$
and $$\forall q \in \mathbb{Q}[X,Y], \quad f-qX \notin (Y^2-X^3) \ \wedge \ g-qX \notin(Y^2-X^3)$$ or the same thing but then for $Y$. I hope that you can tell me if this approach is correct, and provide me a hint. I'd appreciate it if you told me the solution, but please start your answer with a hint, clearly separated from the rest.","['ring-theory', 'abstract-algebra']"
466889,Isomorphism between the space of linear operator and matrices for finite dimensional spaces,"Prove that $\operatorname{Lin}(U,V)$ is isomorphic to the space of $m$ by $n$ matrices, where $\dim(U)=n$ and $\dim(V)=m$. Thanks so much for your enlightment.","['vector-spaces', 'matrices', 'linear-algebra', 'abstract-algebra']"
466918,Kernels in $\mathbf{Top}$,"There is a following well-known theorem for abelian categories (at least the ones I know, Ab , $R$- mod and so on... not so familiar with categorical language to be honest) which states the following : If $X,Y,Z$ are objects and $f : X \to Y$, $g : X \to Z$ morphisms with $g$ surjective, then there exists a unique morphism $h : Z \to Y$ such that the diagram commutes if and only if $\ker g \subseteq \ker f$. (Draw the diagram, won't do it here :D ) Now I was getting started doing algebraic topology in Allen Hatcher's book and some question wanted me to work out homotopies and I realized I implicitly used the following. If $X,Y,Z$ are topological spaces and $f : X \to Y$, $g : X \to Z$ continuous maps with $g$ being a surjective quotient map (quotient map means $U \subseteq Z$ is open if and only if $g^{-1}(U)$ is open in $X$), then there exists a unique continuous map $h : Z \to Y$ such that the diagram commutes if and only if 
$$
\ker g \overset{def}= \{ (x_1,x_2) \in X^2 \, | \, g(x_1) = g(x_2) \} \subseteq \{ (x_1,x_2) \in X^2 \, | \, f(x_1) = f(x_2) \} \overset{def}= \ker f.
$$ 
(The map $h$ is obviously defined by $f \circ g^{-1}$ and the condition makes sure that everything works out. I am not sure how to prove that $f \circ g^{-1}$ will be continuous in general or what conditions precisely should be added, I did it in the case of a projection (i.e. $g$ was just a map that ""glued points together"" and $Z$ was $X / \sim$ for some equivalence relation that glued points). Maybe this is not as general as one could wish. ) My question is : I feel like I didn't totally imagine this notion of kernel in Top , I think I've read it somewhere but I am not sure and I have no idea how to look it up online, since ""kernel"" redirects to the well-known notion and not to this one. Anyone knows if this kind of kernel is useful in a more general setting, or if some results that are true in Ab also hold in Top with this tweak in a similar way that I did?","['general-topology', 'category-theory', 'group-theory']"
466925,what path reduces magnetic field strength,"I'm having trouble solving this particular problem in Colley's Vector Calculus.  I believe my trouble lies in not being able to set up a differential equation.  Here is the problem; Igor, the inchworm, is crawling along graph paper in a magnetic field.  The intensitiy of the field at the point $(x,y)$ is given by $M(x,y)=3x^2+y^2+5000$.  If Igor is at the point $(8,6)$, describe the curve along which he should travel if he wishes to reduce the field as rapidly as possible. So, the section this is in is Directional Derivatives and the Gradient, and so this is a gradient problem.  Since we are minimizing magnetic field strength, we are looking for $-\nabla{M(x,y)}$ and we can easily find this at any point.  In this case, $(8,6)$.  But how do we go about doing this starting at a point and following the path for the entire magnetic field? EDIT:  If it isn't necessary, please don't give me the answer.  Guidance would be much more appreciated, since I want to understand what is happening here.","['multivariable-calculus', 'partial-derivative']"
466927,"independent, identically distributed (IID) random variables [closed]","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 5 years ago . Improve this question I am having trouble understanding IID random variables. I've tried reading http://scipp.ucsc.edu/~haber/ph116C/iid.pdf , http://www.math.ntu.edu.tw/~hchen/teaching/StatInference/notes/lecture32.pdf , and http://www-inst.eecs.berkeley.edu/%7Ecs70/sp13/notes/n17.sp13.pdf but I don't get it. Would someone explain in simple terms what IID random variables are and give me an example?","['probability-theory', 'probability', 'random-variables', 'independence']"
466936,Seperation of variables differnetial equation $t^2 \frac{dy}{dt} - t = 1 + y + ty$,"$$t^2 \frac{dy}{dt} - t = 1 + y + ty$$ Obviously this problem is meant to trick you, I am sure there is some simple solution but after 20 minutes I don't know. How do you approach something like this>","['ordinary-differential-equations', 'calculus']"
466938,Upper bound for smallest eigenvalue,"I am looking for a (simple) upper bound for the smallest eigenvalue of an $n\times n$ matrix, involving determinant or trace or something else that can be easily computed. I've got an upper bound from the $nth$-root of the determinant, but need a little improved bound. In the original post, I forgot to say that the matrix is symmetric and positive definite. Any ideas would be welcome, Thanks","['matrices', 'linear-algebra']"
466944,Evaluate the series $\sum_{k\geq 1} \frac{1}{2^k k^2}$,"How to prove that $$\sum_{k\geq 1} \frac{1}{2^k k^2}=\frac{\pi^2}{12}-\frac{1}{2}\log(2)^2$$ without using the well-known $\operatorname{Li}_2\left( \frac{1}{2} \right)$ ? Edited : Thanks for L.F , but I should have made it clear that I want an answer using only series manipulations .",['sequences-and-series']
466950,Characteristic polynomial divides minimal polynomial if and only if all eigenspaces are one-dimensional [duplicate],"This question already has answers here : When are minimal and characteristic polynomials the same? (4 answers) Closed 10 years ago . Prove that characteristic polynomial of a complex matrix $A$ divides its minimal polynomial if and only if all eigenspaces of $A$ are one-dimensional. As far as I can see I the only possible case is when minimal polynomial equals characteristic one. All distinct eigenvalues with multiplicity 1 grant us that the eigenspaces would be one-dimensional, I thought that this is the key to the solution, however we have the theorem stating that on the other side, eigenspace dimension could be less then or equal to its eigenvalue algebraic multiplicity.
Everything now mixed up, will be thankful for any help.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
466952,"Urysohn's Lemma needn't hold in the absence of choice. Alternate terminology for inequivalent definitions of ""normal"" spaces?","A topological space $\langle X,\tau\rangle$ is said to be normal if any two disjoint closed subsets are separated by open sets, meaning that for disjoint $E,F\subseteq X$ with $X\setminus E,X\setminus F\in\tau,$ there are disjoint sets $U,V\in\tau$ such that $E\subseteq U$ and $F\subseteq V.$ We say that $A,B\subseteq X$ are separated by a continuous function if there is a continuous function $f:X\to\Bbb R$ (with $\Bbb R$ considered in the usual topology) such that $A\subseteq f^{-1}\bigl[\{0\}\bigr]$ and $B\subseteq f^{-1}\bigl[\{1\}\bigr]$ Urysohn's Lemma says that a topological space is normal if and only if any two disjoint closed sets are separated by a continuous function. All well and good, but in a setting without (sufficiently strong) Choice principles, Urysohn's Lemma may fail to hold, as shown in this paper , by Good and Tree. Has anyone encountered any other name for spaces in which disjoint closed sets are separated by continuous functions? Incidentally, I know that if sets are separated by continuous functions, then they are separated by open sets, so such spaces will be normal. I contemplated calling such spaces ""completely normal,"" but this might lead to confusion , as hereditarily normal spaces (spaces such that every subspace is normal) are often referred to as completely normal. Any alternate suggestions?","['general-topology', 'separation-axioms', 'terminology']"
466964,Show that the Fourier transform of a radial function $ L^1 (\mathbb{R}) $ is also radial,How do I prove that the Fourier transform of a radial function $ f \in L^1 (\mathbb{R}) $ is also radial function? I tried by polar coordinates but I dont got.,"['fourier-analysis', 'real-analysis', 'analysis']"
466988,"$\mathbb{Z^2}/\langle(x, y)\rangle$ as a direct sum of cyclic group","For each $(x,y)\in \mathbb{Z}^2$, let $\langle(x, y)\rangle$denote the subgroup of $\mathbb{Z}^2$ generated by $(x,y)$. Express $\mathbb{Z}^2/\langle(x, y)\rangle$ as a direct sum of cyclic group. Note $\mathbb{Z}^2/\langle(x, y)\rangle$ has at most two generators, so $\mathbb{Z}^2/\langle(x, y)\rangle\cong \mathbb{Z}^2$, $\mathbb{Z}\oplus \mathbb{Z}_n$, $\mathbb{Z}_m\oplus \mathbb{Z}_n$, $ \mathbb{Z}_n$ or $\mathbb{Z}$. I think it should be the second case. But I don't know how to figure it out. Any suggestion? Thanks","['group-theory', 'abstract-algebra']"
467000,What is the field $\mathbb{Q}(\pi)$?,"I'm having a hard time understanding section 29,30,31 of Fraleigh. In 29.16 example, what is the field $\mathbb{Q}(\pi)$? and why is it isomorphic to the field $\mathbb{Q}(x)$ of rational functions over $\mathbb{Q}$? (According to the definition, the field $\mathbb{Q}(\pi)$ is the smallest subfield of $E$ (extension field of $\mathbb{Q}$) containing $\mathbb{Q}$ and $\pi$.) Thank you!","['abstract-algebra', 'field-theory']"
467002,prove $\sum\limits_{n\geq 1} (-1)^{n+1}\frac{H_{\lfloor n/2\rfloor}}{n^3} = \zeta^2(2)/2-\frac{7}{4}\zeta(3)\log(2)$,Prove the following $$\sum\limits_{n\geq 1}(-1)^{n+1}\frac{H_{\lfloor n/2\rfloor}}{n^3} = \frac{1}{2}\zeta(2)^2-\frac{7}{4}\zeta(3)\log(2)$$ I was able to prove the formula above and interested in what approach you would take .,['sequences-and-series']
467014,Relationships between a few strong separation axioms without Choice,"Disambiguation : Let $\langle X,\tau\rangle$ be a topological space. I will say that two subsets $A,B$ of $X$ are separated if they are disjoint from each other's closures (their closures needn't be disjoint). I say that $\langle X,\tau\rangle$ is normal if for any two disjoint closed subsets $E,F$ of $X$ there exist disjoint open sets $U,V$ such that $E\subseteq U$ and $F\subseteq V$. I will say that $\langle X,\tau\rangle$ is completely normal if for any two disjoint closed subsets $E,F$ of $X$ there exists a continuous function $f:X\to\Bbb R$ such that $E\subseteq f^{-1}\bigl[\{0\}\bigr]$ and $F\subseteq f^{-1}\bigl[\{1\}\bigr]$. I will say that $\langle X,\tau\rangle$ is hereditarily normal if for any two separated subsets $A,B$ of $X$ there exist disjoint open sets $U,V$ such that $A\subseteq U$ and $B\subseteq V$. I will say that $\langle X,\tau\rangle$ is perfectly normal if for any two disjoint closed subsets $E,F$ of $X$ there exists a continuous function $f:X\to\Bbb R$ such that $E=f^{-1}\bigl[\{0\}\bigr]$ and $F=f^{-1}\bigl[\{1\}\bigr]$. As mentioned in my earlier post , completely normal spaces are always normal, and the converse holds with sufficient Choice, but may fail to hold without it. Since disjoint closed sets are separated, then hereditarily normal spaces are normal, and it is readily apparent by definition that perfectly normal spaces are completely normal. I'm given to understand ( i.e. : Wikipedia says) that perfectly normal spaces are hereditarily normal, but I believe that we may need some Choice in proving this. Does anyone know whether perfectly normal spaces are necessarily hereditarily normal in $\mathsf{ZF}$? Also, need a hereditarily normal space be completely normal in $\mathsf{ZF}$?","['general-topology', 'separation-axioms', 'axiom-of-choice']"
467039,Is there any value of zeta that is an integer?,Is there any value which we can substitute for $s$ in $\zeta (s)$ such that $$\sum_{n=1}^{\infty }n^{-s}\in \mathbb{Z}$$,"['sequences-and-series', 'riemann-zeta', 'analysis']"
467047,Does this quantity have a name in statistics?,I'm interested to know if there is some known statistical context for the following quantity $Q$: $$Q = \text{Mean} + \sqrt{(n-1)\cdot\text{Variance}}$$ where as usual $$\text{Mean} = \frac{\sum_{k=1}^n x_k}n$$ $$\text{Variance} =\frac{\sum_{k=1}^n (x_k - \text{Mean})^2}n$$ My co-worker says that $Q$ looks vaguely familiar from somewhere. Is $Q$ a known statistical quantity?,"['statistics', 'reference-request']"
467064,Definition of $\Omega$-group and $\Omega$-composition series,What are the definitions of $\Omega$-group and $\Omega$-composition series? No luck searching on the internet..,"['definition', 'group-theory', 'finite-groups', 'p-groups', 'terminology']"
467076,Evaluating the limit of an integral,"I am trying to solve this problem from a past exam. Let $f:[0,1]\rightarrow\mathbb R$ be a continuous function such that $f(0)=0$ and $f(1)=1$. Evaluate the limit
  $$
\lim_{n\rightarrow\infty}n\int_0^1f(x)x^{2n}dx.
$$ Since $nf(x)x^{2n}$ is not uniformly convergent on [0,1] (even on [0,1)), I cannot swap $\lim$ and $\int$. I could use integration by parts, but I would get a horrendous alternating sum that involves repeated antiderivatives. I would appreciate if you could give a clue to this problem. EDIT:  While Peter Tamaroff's answer works and is elegant, I am also looking forward for a solution that one can easily come up with.","['calculus', 'integration']"
467088,explict form of the equation of elliptic curve,"Let $E(\mathbb{F}_{q^2})$ is elliptic curve with #$E(\mathbb{F}_{q^2}) =q^2 + q + 1$.
Can we write equation of this curve in the explicit form?","['algebraic-geometry', 'elliptic-curves', 'algebraic-curves', 'number-theory']"
467089,"$O(n,\mathbb R)$ of all orthogonal matrices is a closed subset of $M(n,\mathbb R).$","Let $M(n,\mathbb R)$ be endowed with the norm $(a_{ij})_{n\times n}\mapsto\sqrt{\sum_{i,j}|a_{ij}|^2}.$ Then the set $O(n,\mathbb R)$ of all orthogonal matrices is a closed subset of $M(n,\mathbb R).$ My Attempt: Let $f:M(n,\mathbb R)\to M(n,\mathbb R):A\mapsto AA^t.$ Choose a sequence $\{A_k=(a^k_{ij})\}\subset M(n,\mathbb R)$ such that $A_k\to A=(a_{ij})$ for chosen $A\in M(n,\mathbb R).$ Then $\forall~i,j,$ $a_{ij}^k\to a_{ij}$ in $\mathbb R.$ Now $A_kA_k^t=(\sum_{p=1}^n a_{ip}^ka_{jp}^k)~\forall~k\in\mathbb Z^+.$ Choose $i,j\in\{1,2,...,n\}.$ Then for $p=1,2,...,n;~a_{ip}^k\to a_{ip},~a_{jp}^k\to a_{jp}$ in $\mathbb R\implies \sum_{p=1}^n a_{ip}^ka_{jp}^k\to \sum_{p=1}^n a_{ip}a_{jp}$ in $\mathbb R.$ So $(\sum_{p=1}^n a_{ip}^ka_{jp}^k)\to (\sum_{p=1}^n a_{ip}a_{jp})\implies A_kA_k^t\to AA^t.$ So $f$ is continuous on $M(n,\mathbb R).$ Now $O(n,\mathbb R)=f^{-1}(\{I\}).$ The singleton set $\{I\}$ being closed in $M(n,\mathbb R),$ $O(n,\mathbb R)$ is closed in $M(n,\mathbb R).$ I'm not absolutely sure about the steps. Is't a correct attempt?","['general-topology', 'metric-spaces', 'continuity', 'proof-verification']"
467095,Problem 2-7 in Spivak,"One is asked to show that $ \sum\limits_{i=1}^{n} k^{p}$ (typo on $i$?) can always be written in the form $$\frac{n^{p+1}}{p+1}+An^{p}+Bn^{p-1}+Cn^{p-2}+\cdots.$$ The solution states: The proof is by complete induction on $p$. The statement is true for $p=1$, since
  $$\sum\limits_{k=1}^{n} k= \frac{n(n+1)}{2}= \frac{n^{2}}{2}+n.$$
  Suppose that the statement is true for all natural numbers $\leq p$. The binomial theorem yield the equations
  $$(k+1)^{(p+1)}-k^{p+1}=(p+1)k^{p}+ \textrm{terms involving lower powers of }k.$$
  Adding for $k=1,\dots, n,$ we obtain
  $$\frac{(n+1)^{p+1}}{p+1}=\sum\limits_{k=1}^{n} k^{p} + \textrm{terms involving} \sum\limits_{k=1}^{n} k^{r} \textrm{ for } r<p.$$
  By assumption we can write each $\sum\limits_{k=1}^{n} k^{r}$ as an expression involving powers $n^{s}$ with $s\leq p$. It follows that
  $$\sum\limits_{k=1}^{n} k^{p}=\frac{(n+1)^{p+1}}{p+1} + \textrm{ terms involving powers of }n \textrm{ less than } p+1.$$ What I tryed based on it and more explicitly: $$\begin{align}(k+1)^{p+1} &={p+1 \choose p+1}k^{p+1}+{p+1 \choose p}k^{p}+ \cdots +{p+1 \choose 1}k + {p+1 \choose 0}k^{0}\\
(k+1)^{p+1}&= 1\cdot k^{p+1}+{p+1 \choose p}k^{p}+ \cdots +{p+1 \choose 1}k + {p+1 \choose 0}k^{0}\\
(k+1)^{p+1} -k^{p+1} &= (p+1)k^{p}+ \cdots +(p+1)k + 1\cdot k^{0}\\
 \end{align}$$ Adding for $k=1,\dots, n,$ is something like $$\begin{align}
{2^{p+1}} -1^{p+1} &= (p+1)1^{p}+ \cdots +(p+1)1+ 1\cdot 1^{0}\\
{3^{p+1}} - {2^{p+1}} &= (p+1)2^{p}+ \cdots +(p+1)2+ 1\cdot 2^{0}\\
                 & \vdots\\
(n+1)^{p+1} -{n^{p+1}} &= (p+1)n^{p}+ \cdots +(p+1)n+ 1\cdot n^{0}\\
\hline & \hline\\
(n+1)^{p+1} &= (p+1)\sum\limits_{k=1}^{n} k^{p}+ \cdots +(p+1)\sum\limits_{k=1}^{n}  k^{1}+ \sum\limits_{k=1}^{n}  k^{0} + k^{0}\\
\frac{(n+1)^{p+1}}{(p+1)} &= \sum\limits_{k=1}^{n} k^{p}+ \frac{{p+1 \choose p-1}}{(p+1)}\sum\limits_{k=1}^{n}k^{p-1} + \cdots +\frac{(p+1)}{(p+1)}\sum\limits_{k=1}^{n}  k^{1}+ \frac{1}{(p+1)}(\sum\limits_{k=1}^{n}  k^{0} + k^{0})\\
\end{align}$$ And assuming the proposition as true for $p-1$ we could write $$\begin{align}
\frac{(n+1)^{p+1}}{(p+1)} &= \sum\limits_{k=1}^{n} k^{p}+ \textrm{terms involving powers of } n\leq p.\\
\sum\limits_{k=1}^{n} k^{p} &= \frac{(n+1)^{p+1}}{(p+1)}+ \textrm{terms involving powers of } n\leq p.\\
\end{align}$$ The question is: How do $(n+1)^{p+1}$ instead of $n^{p+1}$ in the result still makes the proof valid?",['algebra-precalculus']
467112,Properties of $\bigcap_{p > 1} \ell_p$,"Consider the following space of sequences $$\left\{a=(a_n)_{n\in\mathbb{N}}:a\in\bigcap_{p>1}\ell_p, a_n\in\mathbb{R}\right\}$$ What are some of its properties? What is its relation to $\ell_1$ and $\ell_\infty$?","['sequences-and-series', 'lp-spaces', 'real-analysis']"
467117,Range of variance,"If you have a random variable which takes on values in the range $[a, b]$, is it necessary that the variance be in the range $[a, b]$? What is the range of variance in general? I feel like this is important to understanding it intuitively as a measure of ``how spread out the data is"".","['probability-distributions', 'probability']"
467125,Please list a few topological groups that I should learn about.,"I'm going through Munkres' Topology book and there's a lot about topological groups.   For fear that I'll forget the theorems on them I'd like to connect each thing I prove with a real-world example.  Please list some topological groups or rings that are interesting besides the obvious ones like $(\mathbb{C}, +, \cdot)$, and give a reason why they're interesting.  Thanks.","['general-topology', 'topological-groups', 'abstract-algebra']"
467131,"How to ""properly"" integrate a derivative, and undoing the product rule","I ran into a confusing issue regarding the product rule and un-doing it. Given that $y$ is a function of $t$, taking the derivative of $e^{t/2}y$ yields the following:
$$\frac{d}{dt}(e^{t/2}y)$$
$$e^{t/2}\frac{dy}{dt}+\frac{1}{2}e^{t/2}y$$ this is all well and good by the product rule, but if you try to integrate it again something strange happens:
$$\int{(e^{t/2}\frac{dy}{dt}+\frac{1}{2}e^{t/2}y)}{dt}$$
$$\int{(e^{t/2}\frac{dy}{dt}){dt}+\int{(\frac{1}{2}e^{t/2}y)}{dt}}$$
$$\int{e^{t/2}}{dy}+e^{t/2}y+C$$
$$e^{t/2}y+e^{t/2}y + C$$
$$2e^{t/2}+C$$
$$2e^{t/2}y\mathrel{{=}\llap{/}}e^{t/2}y  $$ so what gives? is there something illegal about where I cancel the $dt$'s and integrate with respect to $y$? I can't think of anything else that would cause the product rule to be unreversible...","['ordinary-differential-equations', 'calculus', 'integration']"
467135,Are there any other interesting functions such as $e^x$ whose derivative and integral are the same?,"$e^x$ is interesting, but does anybody know if there are other functions that behave in an interesting way when taking the derivative/integral?","['ordinary-differential-equations', 'calculus', 'soft-question']"
467142,Function many to one,"Recently I come across this definition of function.
""A function F is a set of ordered pairs $( x , y)$, no two of which have
the same first member. That is, if $(x, y) \in F$ and $(x, z) \in F$, then $y = z$."" It made me confused because as far as i understood that it suggests we can't have one to many function like $\sqrt{x}$. But why this is so?","['intuition', 'elementary-set-theory', 'functions']"
467145,"If $x,y,z \in \mathbb{Z}$ such that $x^4+y^4+z^4 \equiv 0 \pmod{29}$, prove that $x^4+y^4+z^4 \equiv 0 \pmod{29^4}$","If $x,y,z \in \mathbb{Z}$ such that $x^4+y^4+z^4 \equiv 0 \pmod{29}$, prove that $x^4+y^4+z^4 \equiv 0 \pmod{29^4}$. I have no idea where to start, but this is my abstract algebra homework, so I think we have to use machinery from abstract algebra. Thanks in advance.","['number-theory', 'abstract-algebra', 'finite-groups', 'diophantine-equations', 'group-theory']"
467159,Question about a particular linear operator,"Let A be a linear operator. $A: L^2(0,1) \rightarrow L^2(0,1)$ given by $Ag(a) = \int_0^a(a-x)g(x)dx$ where $a \in (0,1)$. This is the integral operator, and we know ||A|| < 1 which is easy to check. We want to show $A^kg(a) = \int_0^a\frac{(a-x)^{2k-1}}{(2k-1)!}g(x)dx$ where $a \in (0,1)$. Induction seems like an obvious way to approach this: Base case k = 1: $(2k-1)! = 1 $ and $(2k-1) = 1$ hence $A^1g(a)$ is same as given. Induction hypothesis: Assume $A^ng(a) = \int_0^a\frac{(a-x)^{2n-1}}{(2n-1)!}g(x)dx$ holds for n = k. Induction step: Apply the linear operator $A$ to $A^ng(a)$, having a bit trouble with this, would we get double integrals? After we have shown $A^kg(a)$ as above, then we will use that to find $g(a):$ $f \in L^2(0,1)$ given $g \in L^2(0,1)$ and $g(a) = f(a) + \int_0^a(a-x)g(x)dx$, from this we can find $g = (I - A)^{-1}f = \sum_{i=0}^\infty A^if = \sum_{i=0}^\infty \int_0^a\frac{(a-x)^{2i-1}}{(2i-1)!}f $ now we need to try simplify this somehow and find g without summations.","['operator-theory', 'functional-analysis', 'analysis']"
467164,How to proceed solving this problem?,"I'm working on the problem ""soundwaves under the water"" (page 16 in the document is in English) from a numerical analysis book. I've got the following problem that is taken from the numerical analysis book
by Kahaner-Moler-Nash (P8-15). I've made the plot of the data point and the approximation model function: z=[0:500:4000 5000:1000:12000];
data=[5050 4980 4930 4890 4870 4865 4860 4860 4865 4875 4885 4905 4920 4935 4950 4970 4990];
fun=@(p)(4800 + p(1))*ones(size(z)) +p(2)/1000*z+p(3)*exp(p(4)/1000*z)-data;
x0=[0 0 0 -1];
opt = optimset('MaxFunEvals',1000);
p=lsqnonlin(fun,x0,[],[],opt);
fitf=@(t)(4800 + p(1))*ones(size(t)) + p(2)/1000*t+ p(3)*exp(p(4)/1000*t);
tt=linspace(0,12000,1000);
plot(z,data,'r-',tt,fitf(tt),'b-'); Since the sound speed varies with depth, sound rays will travel
  in curved paths. A ﬁxed underwater point emits rays in all directions.
  Given a particular point and initial direction we would like to follow
  the ray path. Thus letting x be the horizontal coordinate we know the
  initial values: x = 0, z = z0, dz=dx = tan 0, where 0 denotes the
  angle between the horizontal line z = z0 and the ray in the start
  point. The ray path z(x) is described by the following second order
  diﬀerential equation $\displaystyle\frac{d^2z}{dx^2}= \frac{-q_0c'(z)}{c(z)^3}$ where $\displaystyle q_0 = \left(\frac{c(z_0)}{\cos b_0}\right)^2$ Use the Runge-Kutta method (or ode45) to trace the ray beginning at z0
  = 2000 feet and b0 = 7.8 degrees. Follow the ray for 25 nautical miles (1 nautical mile is 6076 feet). Plot the curve z(x). You should
  ﬁnd that the depth at xf = 25 nautical miles is close to 2500 feet. Now suppose that a sound source at a depth of 2000 feet transmits to a
  receiver 25 miles away at a depth of 2500 feet. The above calculation
  shows that one of the rays from the source to the receiver leaves the
  source at an angle close to 7.8 degrees. Because of the nonlinearity
  of the equation there may be other rays leaving at diﬀerent angles
  that reach the same receiver. Run your program for b0 in the range
  from 10 up to 14 degrees, plot the ray paths and print a table of the
  values z(xf). We are interested in ﬁnding values of 0 for which z(xf) = 2500. Use
  an eﬃcient algorithm to determine the rays which pass through the
  receiver. Discuss the accuracy of your results. So how should I proceed with solving this? I should study the methods, I think I know RK4 already in theory but I dont' know how to do it in matlab and the non-linear least squares is done above. Can you help me?","['ordinary-differential-equations', 'matlab', 'numerical-methods']"
467197,Examples of $\mathcal{O}_X$-modules that are not quasi-coherent sheaves,"Let $X = \operatorname{Spec} k[x]_{(x)}$ which consists of two elements, the generic point $\zeta$ corresponding to the zero ideal and the closed point $(x)$. Define an $\mathcal{O}_X$-module $\mathcal{F}$ by setting $\mathcal{F}(X)  = \{0\}$ and $\mathcal{F}(\zeta) = k(x).$ Now $\mathcal{F}$ is not a quasi-coherent sheaf because if $\mathcal{F}|_{\operatorname{Spec} k[x]_{(x)}} = \mathcal{F}$ is isomorphic to $\widetilde{M}$ for some $A$-module $M$, $\mathcal{F}(X) = 0$ implies that $\widetilde{M}(X) = M = 0$. But now $\mathcal{F}(\zeta)$ cannot be isomorphic to $\widetilde{M}(\zeta)$ because one is non-zero while the other is zero. Thus $\mathcal{F} \notin \operatorname{QCoh}(X)$. Are there any other examples of $\mathcal{O}_X$-modules that are not quasi-coherent sheaves?","['algebraic-geometry', 'big-list']"
467218,What exactly is standard basis?,I am confused about the difference between coordinates and basis. My confusion is following: Let $e_i$ denote the standard basis and $v_i$ denote a non-standard basis of a finite $n$-dimensional vector space $V$. Then $e_i = (\delta_{ij})$ (all entries zero except $i$-th). But: the coordinates of $v_i$  with respect to basis $v_i$ also are $(\delta_{ij})$. Now the definition of standard basis becomes circular: it is supposed to be the basis with vectors $(\delta_{ij})$ but every basis vector has these coordinates with respect to itself. So what exactly is standard basis?,['linear-algebra']
467282,Markov chain transition matrix,"if $P$ and $Q$ are $n \times n$ transition matrices for two Markov chain, 
then product $R=PQ$ is also a transition matrix. is this true ? why is it ? looks like product of transition matrix means transition $P$ and $Q$.","['statistics', 'markov-chains']"
467318,Triangle with integral side lengths and $\angle A=3\angle B$,"$ABC$ is a triangle with integral side lengths. Given that $\angle A=3\angle B$ , find the minimum possible perimeter of $ABC$ . I got this problem from an old book (which did not provide even a hint). I can think of some approaches, but all of them result in complicated Diophantine equations that would not be solvable without the help of a computer. Any suggestions?","['geometry', 'triangles', 'trigonometry', 'number-theory']"
467322,Prove that $T: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ is a bijection,"I have to prove that the following is a bijection: $ T: \mathbb{R}^2 \rightarrow \mathbb{R}^2 $ , with $T(x,y)=  \left(
\begin{array}{c} 
  5x + \sin(y)\\
  5y + \arctan(x)
\end{array}
\right)$ Now, to prove it is surjective I composed it with $x = \tan(z)$ obtaining: $ T^1\colon \left]-\pi /2, \pi /2 \right[\times \mathbb{R} \rightarrow \mathbb{R}^2 $ , with $T^1(z,y)=  \left(
\begin{array}{c} 
  5\tan(z) + \sin(y)\\
  5y + z
\end{array}
\right)
$ Then, if we consider a generic $(z_0,y_0)$ we have $5y+z=y_0 \Rightarrow z = y_0 - 5y$ and $5 \tan(y_0 - 5y) + \sin(y)=g(y)$ . Considering the limits for $g(y)$ at the inf and sup of its domain are $+ \infty$ and $-\infty$ and the continuity of $g(y)$ we prove the existence of $Y$ such that $g(Y) = z_0$ and then $Z = y_0 - 5Y$ and we've found a couple $(Y,Z)$ such that $T^1(Y,Z)=(z_0,y_0)$ . As for the injectivity I've noticed that, using the fact that sin and arctan are limited functions, we get $T(x,y)=T(x',y') \Rightarrow |x-x'|< \frac{2}{5}$ and $|y-y'|< \frac{2 \pi}{5}$ but I can't do any better. My questions are: 1) Is there an easier or better proof of surjectivity? (given that mine is correct...if not please point out where I did wrong) 2) Can somebody give me hints to prove the injectivity? Thank you very much in advance!",['functions']
467341,Question about connection between Poisson and Gamma distributions,"Assuming $X\sim\mathcal{P}(\lambda)$ and $Y\sim\Gamma(w,1)$ prove that $P(X\ge w)=P(Y\le \lambda)$. How this fact is lead from the connection between the poisson and exponential distributions? I don't know from where to start. poisson is defined only for discrete situations but the exponential is only for continious situation. How can I prove the fact ? EDIT : for gamma distribution I wrote that $f_Y(y)=\frac{y^{w-1}e^{-y}}{\Gamma(w)}$, but I have problem with integrating it. About Poisson: its function is $\displaystyle \sum _{w_i=0}^w P(X=w_i)$ which I don't know how to sum into a final expression. How can I continue?","['probability-distributions', 'probability']"
467354,"Number theory problem, 3rd degree diophantine equation","How many positive integers are there that can be written in the form
$$\frac{m^3+n^3}{m^2+n^2+m+n+1}$$
where $m$ and $n$ are positive integers. I invented this problem and was stuck with it for a long time. It is really interesting to know if there is a solution for this problem.","['diophantine-equations', 'number-theory']"
467358,Weak sequential completeness,It is obvious that reflexive spaces are weakly sequentially complete. Can we have a kind of a converse to this fact? Is there a non-reflexive Banach space $X$ such that both $X$ and $X^*$ are weakly sequentially complete? Note that $X$ cannot be a Banach lattice.,"['functional-analysis', 'banach-spaces']"
467384,Eigenvalues and eigenvectors computation (in infinite dimension),"Let $T$ be the backward shift operator: $Tv = T(v_1,v_2,....) = (v_2,v_3,....)$. I would like to determine all the eigenvectors and eigenvalues. So far I have the following: It is evident that $(\alpha, 0,0,....)$ is an eigenvector for the eigenvalue $0$. It is also easy to see that $(\alpha, \alpha, \alpha, ...)$ is an eigenvector for the eigenvalue $1$. Finally I observed that if $\lambda$ is any scalar in the underlying field then $(1,\lambda, \lambda^2, \lambda^3,...) , (\lambda, \lambda^2, \lambda^3,...)$ etc. are all eigenvectors for the eigenvalue $\lambda$. Now I need to either argue why these are all eigenvectors or find more. But although I think these are all I don't know how to prove it. How to proceed from here?",['linear-algebra']
467407,number of points on two circles,"(sorry I don't know how to add pictures) Two friends argue if larger circles have more points than smaller circles Friend number 1 (a well known argument) Say the circles are concentric. you cannot draw a line from the centre that cuts the bigger circle while that doesn't cut the inner circle so they have the same amounts of points. Friend number 2 ( a dissenting voice) Ok lets take concentric circles, he draws a line to the centre ( say along the x axis) adds another line parallel to this line it cuts both circles 2 times) adds another (cuts both circles 2 times)
and so on two parallel lines are only tangent to the smaller circle while still cuting the bigger at two points.
and some paralel lines only cut the larger cirle. Therefore all points on the smaller circle are related to some point on the bigger one, but some points on the bigger one are not related to point on the smaller one. So the larger circle has more points. Which friend is right or how do you convince them that they are both right?","['geometry', 'recreational-mathematics', 'fake-proofs']"
467420,surfaces $F$ and $G$ are tangent if and only if $\nabla{F}\times{\nabla{G}}=\mathbf{0}$,"Suppose that two surfaces are given by the equations $F(x,y,z)=c$ and $G(x,y,z)=k$.  Moreover, suppose that these surfaces intersect at the point $(x_0,y_0,z_0)$.  Show that the surfaces are tangent at $(x_0,y_0,z_z)$ if and only if
$$\nabla{F}\times\nabla{G}=\mathbf{0}$$
Here's my attempt... $\Rightarrow$
Since the surfaces are tangent, they have the same tangent plane.  These tangent planes can be represented by different equations, but must only differ by a scalar.  Let $\mathbf{x}_0 = (x_0,y_0,z_0), a,b \in\mathbb{R}$. Thus
$$a[F_x(\mathbf{x_0})(x-x_o)+F_y(\mathbf{x_0})(y-y_o)+F_z(\mathbf{x_0})(z-z_o)]=b[G_x(\mathbf{x_0})(x-x_o)+G_y(\mathbf{x_0})(y-y_o)+G_z(\mathbf{x_0})(z-z_o)]$$
Which implies 
$$F_i(\mathbf{x}_0)=\frac{b}{a}G_i(\mathbf{x}_0), i=x,y,z.$$
Since these partial derivatives only differ by a scalar, they are linearly dependent and thus parallel.  Since they are parallel, $\nabla{F}\times\nabla{G}=\mathbf{0}$ Now the other way is where I'm having trouble $\Leftarrow$  Suppose $\nabla{F}\times\nabla{G}=\mathbf{0}$.  This implies three things; either $\nabla{F}=\mathbf{0}, \nabla{G}=\mathbf{0}$ (or both), or $\nabla{F}||\nabla{G}$.  If either $\nabla{F}$ or $\nabla{G}=\mathbf{0}$, the surface represented by $F$ or $G$ is a plane.  It is from here I get lost as to where to go.  If I assume that they are parallel, I feel as though my only path is the reverse of $\Rightarrow$, which I don't believe is sufficient.","['multivariable-calculus', 'partial-derivative']"
467429,Euclidean geometry prerequisites,"I have used enrolled in a introduction to Euclidean geometry course, but I have very little experience with geometry, almost none. I have an engineering background so I have taken calculus, linear algebra and differential equations. I have acquired ""Geometry Revisited"" by Coxeter. Shall I just start working through the book or is there some more elementary material I should work through first? Thanks!","['geometry', 'euclidean-geometry']"
467441,closed epigraphs equivalence,Is there a way to prove that the epigraph of any real function $f$ is closed iff $f$ is lower semi-continuous without using limit superior or inferior?,"['general-topology', 'convex-analysis', 'real-analysis']"
467459,Finding the length of chord of a circle.,I'm trying to solve the following problem: The ﬁgure below shows that a circle of radius $r = 1$ is inscribed in quarter circular region $OPQ$. Find the length of the chord $AB$. I thought about it a lot but still couldn't do anything. Is there some theorem I'm missing ? Edit : There are some answers to this question but I don't really understand them . Can anyone please post a easy to understand ( possibly with a figure ) answer ?,"['geometry', 'circles']"
467461,"How to evaluate this expression $\sum_{n = 1}^\infty {\left( {\frac{1}{n} -\frac{1}{{n + x}}}\right)}$ where $x$ is a real number,$0\le x\le1$","evaluate the expression [1]: $$\sum_{n = 1}^\infty  {\left( {\frac{1}{n} - \frac{1}{{n + x}}} \right)} $$ where $x$ is a real number, $0\le x\le1$ , and $x$ is rounded to 3 digits. For example, when $x=0.500$ , the expression is [2]: $$\left(\frac11 -\frac1{1.5}\right)+\left(\frac12 -\frac1{2.5}\right)+\left(\frac13 -\frac 1{3.5}\right) + ...$$ For a given $x$ , how can I evaluate it?
The answer must be rounded to more than 12 digits.","['sequences-and-series', 'calculus']"
467466,Surjectivity of the trace operator in Sobolev spaces,"Suppose $U$ is an open bounded set with $C^1$ boundary. It is a well-known result in the theory of Sobolev spaces $W^{1,p}$ that there is a continuous linear operator $T:W^{1,p}(U)\rightarrow L^p(\partial U )$ that equals ordinary restriction on continuous functions. Wikipedia tells me that this operator is in general not surjective. I know that one way to prove this is to show that functions in the image are actually more regular than your general $L^p$-function, and I have somewhat understood the proof for that.
However, I feel that there should be some elementary counterexample. In fact, any function that is a trace of some $u\in W^{1,p}(U)$ is a limit of a Cauchy sequence of functions in $C^{\infty}(\bar{U})$ (and vice versa), and that could be exploited to exhibit some example where $T$ is not surjective. Does anyone have a good example?","['trace', 'sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
467469,Area ratio in triangle?,"Given: $\triangle ABC$. In the side $AB$, we choose point $D$. From this point $D$, we draw a line $DF$ such that intersect side $AC$ and line $DE$ such that intersect side $BC$. If $DF\parallel BC$, $DE\parallel AC$, and the area of $\triangle BDE = p$ times area of $\triangle$ADF, what is the ratio of area $\triangle CEF$ and $\triangle ABC$ ?","['geometry', 'triangles', 'area']"
467511,P(tomorrow is the end of the world) =?,"Here we have $3$ prophets alpha, beta, gamma, they all predict that tomorrow is the end of the world. It's known that the accuracy of alpha's and beta's prediction is $90\%$, while that of gamma's is $4\%$. What is the probability that tomorrow is the end of the world? Here's my calculations. Let $A, B, C$ be alpha's, beta's and gamma's predictions. P(tomorrow is the end of the world) $= P(A) + P(B) + P(C) - P(AB) - P(BC) - P(AC) + P(ABC)$ $= 0.9 + 0.9 + 0.04 - 0.81 - 0.036 - 0.036 + 0.0324$ $= 0.9904$ But this seems a bit too high, is my calculation correct? Thanks.",['probability']
467513,How the ring of algebraic numbers looks like?,"Suppose I have an algebraic number field $K = \mathbb Q(\alpha)$ for some $\alpha \in O_K$, ring of algebraic integers. Is there a criterion that tells us when $O_K =\mathbb Z[\alpha]$ by any chance? For example, if $\alpha^3 - \alpha - 1 = 0$, then $O_K =\mathbb Z[\alpha]$. I was wondering if there is an easy way to see this. Thanks!","['algebraic-number-theory', 'abstract-algebra']"
467526,Probabilities associated with negatively marked questions,"First of all: not a native english speaker, and not a mathematician. Please explain as you would to your 10 years old son. I have 120 questions to answer True or False For each right answer, i score 1 point For each wrong answer, i lose 1 point Not answering a question does not affect the score (=0) I don't know if the T/F is evenly distributed, so it could be 50/50, 85/15, etc (%) I don't know the answer for any of them, so i'll just guess them all Given the above, can i say that: I have 50% chance of getting each question right? I have 50% chance of getting all questions right? Answering all is better than answering just some of the questions? I have to score a minimum of 70 points, but only know the correct answer for 50 questions; how many others would be ""safe"" to guess? Only 20? The remaining 70? Or something in between? Feel free to edit the question (or the title) if i wrote something wrong.","['statistics', 'education', 'recreational-mathematics', 'probability']"
467564,Show that the upper envelope of a bounded function is upper semi continuous directly,"Definition 1: A real valued function $f$ is said to be upper semicontinuous at a point $p$ if: $$f(p) \geq \limsup_{x \rightarrow p} f(x) $$ Definition 2: Let $f$ be a bounded real valued function on $[a,b]$ . Define the upper envelope $h$ of $f$ as: $$ h(y) = \inf_{\delta >0} \sup_{|x-y|<\delta} f(x)$$ The question: If $f$ is a real valued bounded function on $[a,b]$ , show that the upper envelope of $f$ is upper semicontinuous. Background: This is a sample qualifying exam question. In the past, this question is sometimes asked with a part a which says that a function is upper semicontinuous iff the sets $\{x: f(x) < \lambda\}$ are open for each $\lambda \in \mathbb{R}$ . This characterization is not too difficult to prove. Also, the desired result is not too difficult to deduce from this characterization. For example, see: Upper semi-continuity and lower semi-continuity of particular functions However, this approach is unsatisfactory. In particular, this problem has shown up sans part a before on the qualifying exam. I'm looking for a proof that takes a bounded real valued function $f$ , and from Definition 2 deduces Definition 1 directly. Every attempt I make, I get lost in chasing infs and sups through inequalities. Any help would be much appreciated.","['measure-theory', 'continuity', 'real-analysis']"
467574,"Using permutation or otherwise, prove that $\frac{(n^2)!}{(n!)^n}$ is an integer,where $n$ is a positive integer. [duplicate]","This question already has answers here : prove that $\frac{(2n)!}{(n!)^2}$ is even if $n$ is a positive integer (7 answers) Closed 6 years ago . Using permutation or otherwise, prove that $\displaystyle \frac{(n^2)!}{(n!)^n}$ is an integer,where $n$ is a positive integer. I have no idea how to prove this..!!I am not able to even start this Can u give some hints or the solution.!cheers.!!","['elementary-number-theory', 'inequality', 'algebra-precalculus', 'combinatorics']"
467575,Should I put number combinations like 1111111 onto my lottery ticket?,"Suppose the winning combination consists of $7$ digits, each digit randomly ranging from $0$ to $9$. So the probability of $1111111$, $3141592$ and $8174249$ are the same. But $1111111$ seems (to me) far less likely to be the lucky number than $8174249$. Is my intuition simply wrong or is it correct in some sense?","['lotteries', 'probability', 'gambling']"
467602,Show that if $A$ is positive definite then $A + A^{-1} - 2I$ is positive semidefinite,"Let $A$ be a real symmetric positive definite matrix. Show that $$A + A^{-1} -2I$$ is positive semidefinite. I found that $A^{-1}$ is a positive definite matrix, thus $A + A^{-1}$ is also a positive definite matrix, moreover I know the form of the $z^TIz$ is as follows $(a^2 + b^2 + ... )$, where $a,b, ...$ are the components of vector $z$. 
I don't know what to do next...","['positive-semidefinite', 'matrices', 'linear-algebra']"
467607,Sum of radicals greater than 1,"Prove that for every $n,m \in \Bbb N $
$$ \frac{1}{\sqrt[n]{1+m}} + \frac{1}{\sqrt[m]{1+n}} \ge 1 $$","['inequality', 'calculus']"
467609,Evaluate $\int _0 ^ \pi \frac{x}{1+\sin^2(x)} dx $,"Find the value of
  $$\int _0 ^ \pi \dfrac{x}{1+\sin^2(x)} dx $$ I have tried using $\int_a ^bf(x) dx=\int_a^b f(a+b-x)dx$ $\displaystyle \int _0 ^ \pi \dfrac{x}{1+\sin^2(x)} dx=\int _0 ^ \pi \dfrac{\pi-x}{1+\sin^2(x)} dx=I$ I couldn't go any further with that!","['definite-integrals', 'integration']"
467653,On a PID that is not an Euclidean domain,"Let $\omega = \frac{1 + \sqrt{19}i}{2}$ . The article here claims to prove that $\mathbb{Z}[\omega]$ is an example of a PID which is not a Euclidean domain. To prove that it is a PID, it takes an ideal $I$ and chooses a nonzero $b \in I$ as to minimize $|b|$ (the usual norm in $\mathbb{C}$ ). Then he supposes $a \in I \setminus (b)$ to obtain a contradiction. According to him, it suffices to obtain $p, q \in \mathbb{Z}[\omega]$ such that $|ap - bq| < |b|$ to obtain a contradiction; but he neglects the case that $|ap - bq| = 0$ , or $ap = bq$ . Analyzing the proof, eventually he finds an integer $j \in \mathbb{Z}$ such that $|\frac{2a}{b} - \omega - j| < 1$ , and multiplying by $|b|$ we get $|2a - b(\omega + j)| < |b|$ . Hence by the minimality of $|b|$ we get $2a = b(\omega + j)$ , but I cannot find a contradiction in this. We can see this implies $\frac{a}{b} = \frac{\omega + j}{2}$ , and so $\operatorname{Im}(\frac{a}{b}) = \frac{\sqrt{19}}{4}$ , and we chose $\frac{a}{b}$ for its imaginary part to lie in $[-\frac{\sqrt{19}}{4}, \frac{\sqrt{19}}{4}]$ but I cannot seem to deal away with these extremities. Is there any simple way to fix this proof?","['euclidean-domain', 'abstract-algebra', 'principal-ideal-domains', 'algebraic-number-theory', 'commutative-algebra']"
467680,Jensen's inequality and Averaging of Coefficients,"I am using Jensen's inequality and conditional expectation to prove the following inequality: Let $\lambda_i$ be real for $i\in \{1,2,...,M\}$ and $\bar{\lambda}=\frac{\sum_{i=1}^M\lambda_i}{M}$. Let $X_i$, $i\in \{1,2,...,M\}$ be a set of real i.i.d random variables, then we have
\begin{align}
\mathbb{E}\left(f\left(\sum_{i=1}^M \bar{\lambda} X_i\right)\right) \le \mathbb{E}\left(f\left(\sum_{i=1}^M \lambda_i X_i\right)\right),
\end{align}
where $f(\cdot)$ is a convex function. The equal sign holds when $\lambda_{i}=\bar{\lambda}$ for all $i\in \{1,2,...,M\}$. And my proof is given as: Let
\begin{align}
X=\sum_{i=1}^M\bar{\lambda}X_i,
\end{align}
\begin{align}
W=\sum_{i=1}^M\lambda_iX_i,
\end{align}
and
\begin{align}
Z=X-W.
\end{align}
By the symmetric property of $X$, the conditional random variables $X_i|X$, $i\in \{1,...,M\}$, are identically distributed, which implies
\begin{align}
\mathbb{E}(X_1|X)=\mathbb{E}(X_2|X)= \cdots = \mathbb{E}(X_M|X).
\end{align}
Therefore
\begin{align}
\mathbb{E}(Z|X)&=\sum_{i=1}^M \bar{\lambda}\mathbb{E}(X_i|X)-\sum_{i=1}^M \lambda_{i}\mathbb{E}(X_i|X)\\
      &=\mathbb{E}(X_1|X)\left(\sum_{i=1}^M \bar{\lambda}-\sum_{i=1}^M \lambda_{i}\right)=0.
\end{align}
Since $f(\cdot)$ is convex, by Jensen's inequality we have
\begin{align}
\mathbb{E}(f(X-Z)|X)
&\ge f(\mathbb{E}((X-Z)|X)) \\
&=f(X-0)=f(X)
\end{align}
Therefore
\begin{align}
\mathbb{E}(f(W))=\mathbb{E}(\mathbb{E}(f(X-Z)|X))\ge \mathbb{E}(f(X)).
\end{align} I think the proof is right, but not 100% sure, can someone give me a judgement of this proof? Thanks!","['statistics', 'inequality', 'probability']"
467694,Why is $\infty-\infty$ undefined in measure theory?,"Some additions to the title: I stumbled over this problem going through
my measure theory lecture notes; the author explicitly mentions that
he leaves $\infty-\infty$ undefined. I would like to know what goes
wrong, if I would define $l:=\infty-\infty$ for $l\in\overline{\mathbb{R}}$. I tried to derive contradictions by playing with arithmetical rules
in $\overline{\mathbb{R}}$ but couldn't obtain a contradiction. Here's an example where I merely try to obtain a contradiction by
  assuming that $r:=\infty-\infty\in\mathbb{R}$ (as opposed to
  $\overline{\mathbb{R}}$). \begin{eqnarray*}  & \infty=\infty\\ \Rightarrow & \infty=\infty+2\\
> \Rightarrow &
> \infty+\left(-\infty\right)=\left(\infty+2\right)+\left(-\infty\right)
> \end{eqnarray*} an here the attempt breaks down, since this extended
  addition doesn't have to be associative, so one can't conclude
  \begin{eqnarray*} \Rightarrow & r=r+2\\ \Rightarrow & 0=2.
 \end{eqnarray*} EDIT A lot of people gave me answers in which they motivated why $\infty-\infty$ doesn't make sense. This is not what I'm looking for! Motivations are nice, but only a concrete contradiction gives certainty that it absolutely makes no sense to assign a number, or $\pm \infty$ to the above expression.","['measure-theory', 'definition']"
467727,Existence of smooth elliptic curves with complex multiplication,"this is my first question ever on a platform like this so please forgive me any kind of unintended misbehaving. In Kudla, Rapoport and Yang ""On the derivative of an Eisenstein series of weight one"" the authors define a (fine) moduli stack $\mathfrak{M}(1,0)$ of elliptic curves with complex multiplication by $\mathcal{O}_K$ where $K$ is the reflex field. This is a stack over $\operatorname{Spec}(\mathcal{O}_K)$. My question is now the following. What is known about the existence of smooth elliptic curves with such a complex multiplication over the scheme $\operatorname{Spec}(\mathcal{O}_K)$ itself? Thank you!","['arithmetic-geometry', 'algebraic-geometry', 'algebraic-topology', 'number-theory']"
467733,How many non-isomorphic ways a convex polygon with $n + 2$ sides can be cut into triangles?,"From Wikipedia: The Catalan number $C_n$ is the number of different ways a convex polygon with $n + 2$ sides can be cut into triangles by connecting vertices with straight lines (a form of Polygon triangulation). The following hexagons illustrate the case $n = 4$: $\hskip0.7in$ Combining triangulations that only differ by rotation or mirroring, how many non-isomorphic ways a convex polygon with $n + 2$ sides can be cut into triangles do we get then? I currently got: $(1),1,1,3,4$ for $n=1$ to $5$, but I'm unsure how to count the triangle ($n=1$) and if I got all cases for the heptagon ($n=5$).","['graph-theory', 'extremal-combinatorics', 'combinatorics']"
467736,Taylor Polynomial in Multivariable Case,"I am doing Problem 9.30 in Rudin's Principles of Mathematical Analysis and have done part (a) and (b) but got stuck on part(c). In part (b) I have finished the proof that: $$f(\mathbf a+\mathbf x)=\sum_{k=0}^{m-1}{1 \over{k!}}\sum (D_{i_1 \dots i_k}f)(\mathbf a)x_{i_1}\dots x_{i_k}+r(\mathbf x),(*)$$ where $$\lim_{x\to 0}{{r(\mathbf x)}\over{|\mathbf x|^{m-1}}}=0.$$ Now I need to show that the equation ($*$) is in fact equivalent to $$\sum{{(D_1^{s_1}\dots D_n^{s_n}f)(\mathbf a)}\over{s_1 !\dots s_n !}}x_1^{s_1}\dots x_n^{s_n}, $$where the summation extends over all ordered $n$-tuples $(s_1,\dots,s_n)$ such that each $s_i$ is a nonnegative integer and $s_1+\dots+s_n \le m-1$. Thanks in advance.","['multivariable-calculus', 'real-analysis', 'taylor-expansion']"
467757,Determine the winner of a tic tac toe board with a single matrix expression?,"Assume a tic-tac-toe board's state is stored in a matrix. 
$$
S=\begin{bmatrix}
-1 & 0 & 1 \\
1 & -1 & 0 \\
1 & 0 & -1 \\
\end{bmatrix}
$$ Here, $X$ is mapped to $1$, $O$ is mapped to $-1$ and an empty state is mapped to zero, but any other numeric mapping will do if there is one more suitable for solving the problem. Is it possible to create some single expression involving the matrix $S$ which will indicate whether the board is in a winning state?  For the above matrix, the expression should show a win for $O$. I recognize that there are more direct programmatic approaches to this, so this is more of an academic question. Edit: I have been asked what to do if the board shows two winners.  You could either: Assume only valid board states. Since gameplay would stop after once side wins, it is not possible to have a board with two winners. Alternatively (or equivalently?), your expression could arbitrarily pick a winner in a board that has two.","['matrices', 'game-theory']"
467758,"$V(f)\subset V(f,g)$?","I didn't understand this part in this proof: For me, we have to have the contrary $V(f,g)\subset V(g)$. Maybe the author made a mistake. Thanks in advance.",['algebraic-geometry']
467779,Inconsistency between two definitions of closure.,"I'm currently taking a course on analysis over $\mathbb{R}^n$ and the book used defines that a point $p \in \mathbb{R}^n$ is a limit point of a set $X\subset \mathbb{R}^n$ if $p$ is the limit of some sequence of points of $X$. Now, because of this the author says ""well, any point of $X$ is the limit of the constant sequence with every element equal to the point, so that any point of $X$ is a limit point of $X$"". After that the author defines the closure of a set $X$ as the set $\overline{X}$ of all limit points of $X$ and the author states that $X\subset \overline{X}$. Now, in the same time I am studying metric spaces on Rudin's Principle of Mathematical Analysis. In this book, the author defines that in a metric space $M$, a point $p \in M$ is a limit point of a subset $X\subset M$ if every open ball with center at $p$ contains some point $q \in X$ with $p \neq q$. Then with this definition of limit point the author defines closure again as the set of all limit points. In truth the first author gives the name ""adherent"" points for limit points, but it seems that they are talking about the same things (since the only difference is the definition of limit point, the definition of closure, closed set and so on are the same). The only problem is that with the second definition, $X\nsubseteq \overline{X}$ because $X$ can have isolated points. It suffices to consider $S^1 \cup \{(0,0)\}$. The point $(0,0)$ is in the closure according to the first definition, but not in the closure according to the second one (every open ball with radius $< 1$ misses points of $S^1$). Are these notions different, is there some mistake made by some of the authors, or I am not really understanding that we are working with different situations? Thanks a lot in advance for the help!","['general-topology', 'metric-spaces', 'real-analysis']"
467780,Can someone explain this trigonometric limit?,"I have
$$\lim \limits_{x\to 0}  \frac {\tan(2x)}{\sin(x)}$$ and in my case the result is $\frac{2}{1}$ =2 not whether it is right. This is my procedure. $$\lim \limits_{x\to 0}  \frac{\frac {\sin(2x)}{\cos(2x)}}{\frac{\sin(x)}{1}}= \lim \limits_{x\to 0}  {\dfrac {\sin(2x)}{(\cos(2x))(\sin(x))}}=\dfrac{2x\frac {\sin(2x)}{2x}}{\cos(2x)\frac{x\sin(x)}{x}}$$ I separate the limit. $$\frac{\left(\lim \limits_{x\to 0}2x\right) \cdot \left(\lim \limits_{x\to 0}\frac {\sin(2x)}{2x}\right)}{\lim \limits_{x\to 0}\left(\cos(2x)\right)\cdot\left(\lim \limits_{x\to 0}\frac{x\sin(x)}{x}\right)} = \lim \limits_{x\to 0} \dfrac{2x}{x}=\frac{2}{1} =2$$",['limits']
467795,Average value using triple integrals,"Find the average value of the function $f(x,y,z)=xyz$ over the tetrahedron with vertices, $(0,0,0),(1,0,0), (1,1,0), \text{and }(1,1,1)$",['multivariable-calculus']
467804,Solution to over-damped harmonic spring,"(A kind soul at physics.stackexchange suggested I post here as well, sorry if out of bounds.) I'm trying to programmatically model a damped harmonic spring for use in mobile UI animations ( physics mathematics isn't my background, please pardon any misconceptions). Having derived the parameters for the general case equation, I can iteratively calculate values until I reach a suitable threshold, though because this is bound to ""simple"" trigonometric and $e^{x}$ functions on the CPU, the 4000-some-odd steps can cause about 0.25 seconds lag on slow devices while it calculates. I'd like to speed this up using my platform's super-optimized vector and BLAS/LAPACK variants. The requirement for doing this is precalculating the number of steps necessary to reach my threshold value. In the underdamped case, where the roots of the characteristic function of the differential equation are non-real, I can use algebraic tricks to get my values: $$x(t) = c_{1}e^{r_{1}}\cos(i_{1}t) + c_{2}e^{r_{2}}\sin(i_{2}t)$$ (Given $r_{1}$, $i_{1}$, $r_{2}$, and $i_{2}$ are the real and irrational components of my two roots, respectively.) Knowing that $r_{1} = r_{2}$ and $i_{1} = -i_{2}$, I can simplify to: $$x(t) = c_{1}e^{r_{1}}\cos(i_{1}t)$$ And get my desired value of $t$ for my threshold $a$: $$t = \arccos(a / c_{1} / e^{r_{1}}) / i_{1}$$ When the roots are real, the equation looks a lot simpler: $$x(t) = c_{1}e^{r_{1}} + c_{2}e^{r_{2}}$$ However, I don't have my trig functions floating around to help me solve it (even if I did, the irrational components being 0 would cause problems, of course). Take the concrete example on pages 3-4 of this document (my bible during this process), since they at least solve cleanly: $$x(t) = 1.5e^{-t} - 0.5e^{-3t}$$ I know how I would solve for $t$ to get my for when $x(t) = a$ on paper, by setting $x=e^{t}$, solving, and back substituting, but I don't have that luxury here. I can make a few assumptions: the roots and constants are all real. I'm always going to be looking for the smallest, first, positive value of $t$. Obviously, the iterative solution is the simplest for this case, but in the end that would involve more steps and therefore be slower no matter what my other optimizations would be. How, then, would I go about solving for my threshold value algorithmically in this (supposedly) simplified case? Addendum The underdamped solution presents an extra requirement. The motion curve will oscillate back and forth a few times across the endpoint. Therefore, ""first and lowest"" $t$ requirement is not necessarily true. In my current, iterative code, the threshold value is both checked against the distance from the current $x(t)$ to the endpoint, as well as to the distance from the previous $x(t)$ as well to allow for a number of oscillations. This might make a more efficient solution nearly impossible.","['ordinary-differential-equations', 'physics']"
467809,Some identities with the Riemann zeta function,"Can someone either help derive or give a reference to the identities in Appendix B, page 27 of this, http://arxiv.org/pdf/1111.6290v2.pdf Here is a reproduction of Appendix B from Klebanov, Pufu, Sachdev and Safdi's $2012$ preprint (v2) 'Renyi Entropies for Free Field Theories' (from the source at arxiv.org and hoping there is no problem citing it here...(RM)). B Useful mathematical formulae In this section we present some useful mathematical formulae.  We begin with zeta function identities. For $0 < a \leq 1$ we have the identity
$$\tag{B.1}  \zeta(z, a) = \frac{2 \Gamma(1 - z)}{(2 \pi)^{1-z}} \left[\sin \frac{z \pi}{2} \sum_{n=1}^\infty \frac{\cos 2 \pi a n}{n^{1-z}}
   + \cos \frac{z \pi}{2} \sum_{n=1}^\infty \frac{\sin 2 \pi a n}{n^{1-z}} \right] \,$$ Taking derivatives at $z=0, -1, -2$ gives \begin{align}
\zeta'(-2, a) &= - \frac{1}{4 \pi^2} \sum_{n=1}^\infty \frac{\cos 2 \pi a n}{n^3}
   - \frac{1}{4 \pi^3} \sum_{n=1}^\infty \frac{(2 \log (2 \pi n) + 2 \gamma - 3) \sin 2 \pi a n}{n^3} \,, \\
  \tag{B.2}\zeta'(-1, a) &= \frac{1}{4 \pi} \sum_{n=1}^\infty \frac{\sin 2 \pi q n}{n^2}
   - \frac{1}{2 \pi^2} \sum_{n=1}^\infty \frac{(\log (2 \pi n) + \gamma - 1) \cos 2 \pi a n}{n^2} \,, \\
  \zeta'(0, a) &= \frac{1}{2} \sum_{n=1}^\infty \frac{\cos 2 \pi a n}{n}
   + \frac{1}{\pi} \sum_{n=1}^\infty \frac{(\log (2 \pi n) + \gamma) \sin 2 \pi a n}{n} \,.
\end{align} Two other useful identities are the regularized sums
\begin{align}
   \tag{B.3}\sum_{n \in \mathbb{Z}} \log \left( \frac{n^2}{q^2} + a^2 \right)
   &=  2 \log \left[2 \sinh (\pi q |a|) \right] \,, \\
   \sum_{n \in \mathbb{Z} + \frac 12} \log \left(\frac{n^2}{q^2} + a^2 \right)
   &=  2 \log \left[2 \cosh (\pi q |a|) \right] \,.
\end{align} These sums follow from the more general formula $$\tag{B.4}\sum_{n \in \mathbb{Z}} \log \left( \frac{(n + \alpha)^2}{q^2} + a^2 \right)
   =  \log \left[2 \cosh (2 \pi q |a|) - 2 \cos (2 \pi \alpha)  \right] \,.$$ This relation in turn follows from the Poisson summation formula
$$\tag{B.5} \frac{1}{ 2 \pi q} \sum_{n \in \mathbb{Z}} \hat f \left( \frac{n + \alpha}{q} \right) =\sum_{k \in \mathbb{Z}} e^{-i 2 \pi k \alpha} f(2 \pi q k)  \,$$
applied to
$$\tag{B.6}\hat f(\omega)  = \log \left( \omega^2 + a^2 \right) \,.$$
For $t \neq 0$ one can simply calculate the inverse Fourier transform of $\hat f$:
$$\tag{B.7}f(t) = \int_{-\infty}^\infty \frac{d\omega}{2 \pi} e^{-i \omega t} \log \left(\omega^2 +a^2 \right) = - \frac{e^{-|a|\;|t|}}{|t|}  \,.$$ The case $t=0$ requires special care because the expression for $f(0)$ is divergent and requires regularization:
$$\tag{B.8}f(0) = \int_{-\infty}^\infty \frac{d\omega}{2 \pi} \log \left(\omega^2 +a^2 \right)
   = -\frac{d}{ds} \int \frac{d\omega}{2 \pi} \frac{1}{\left(\omega^2 +a^2 \right)^s} \Biggr\rvert_{s=0}
    = |a| \,.$$
Using $(B.6)-(B.8)$ one can show that $(B.5)$ reduces to $(B.4)$.","['analytic-number-theory', 'fourier-analysis', 'riemann-zeta', 'number-theory']"
467819,"Extend a linear functional on ""nice"" functions to an integral","I have a positive linear functional $h$ defined on a set of Lesbesgue-measurable functions of ""moderate growth"" on $\mathbb{R}^2$–call this set $MG(\mathbb{R}^2)$. (A function $f$ is positive if $f(x)\ge 0$ for all $x \in \mathbb{R}^2$.)  I want to ensure that there is a unique measure $\mu$ such that
$$ h(f) = \int f\, \mathrm{d} \mu \quad\text{for all} \quad f \in MG(\mathbb{R}^2).$$ Let me describe a line of attack. Let $C_c(\mathbb{R}^2)$ be the set of continuous, compactly supported functions on $\mathbb{R}^2$. The Reisz–Markov–Kakutani representation theorem ensures that there exists a unique measure $\mu$ on $\mathbb{R}^2$ such that $$ h(f) = \int f\, \mathrm{d} \mu \quad\text{for all} \quad f \in C_c(\mathbb{R}^2)\subset MG(\mathbb{R}^2).$$ To what extent can I extend this representation to all of $MG(\mathbb{R}^2)$? Is there some general result that ensures positive linear functionals have a unique integral representation for a larger class than just $C_c(\mathbb{R}^2)$? If you have a specific reference, that would be immensely helpful. Finally, if it helps to have a concrete example in mind, I can take $MG(\mathbb{R}^2)$ to be the set of all measurable functions that grow no faster than $O(\exp(x^2+y^2))$ as $x^2+y^2\to \infty$.","['reference-request', 'measure-theory', 'functional-analysis', 'banach-spaces']"
467832,Every neighborhood of identity in a topological group contains the product of a symmetric neighborhood of identity.,"Let $(G,\cdot)$ be a topological group and $U$ be a neighborhood of $1$.  Then there exists a symmetric neighborhood of $1$, $V^{-1} = V$, such that $V\cdot V \subset U$.  Having a hard time proving this.  $V^{-1} = \{v^{-1}: v \in V\}$.  I know that an open set times any set is also open.  And a hint is that $VV^{-1}$ is symmetric and an open neighborhood of $1$ when $V$ is an open neighborhood of $1$ contained in $U$, but showing $VV^{-1}$ or an expression involving it is a subset of $U$ or $V$ requires something else.","['general-topology', 'topological-groups']"
467840,Pfister's 16-Square Identity and the norm of sedenions,"Consider the sequence of numbers: complex numbers $\Bbb C$, quaternions $\Bbb H$, octonions $\Bbb O$, and sedenions $\Bbb S$. The Brahmagupta-Fibonacci 2-Square identity implies that the norm of the product of two complex numbers $a,b$ equals the product of their norms, $$||ab|| = ||a||\,||b||\tag{1}$$ Analogous identities ( Euler's 4-Square and Degen's 8-Square ) do the same for $\Bbb H$ and $\Bbb O$. Question : Does Pfister's 16-Square Identity imply that two sedenions $a,b$ will obey $(1)$ as well?","['complex-numbers', 'octonions', 'quaternions', 'abstract-algebra']"
467842,Describe all holomorphic functions.,"Problem: Describe the class of all holomorphic functions on $\mathbb{C}-\{0\}$ such that $$\sup_{(x,y)\neq (0,0)}\frac{|f(x+iy)|}{|\log(x^2+y^2)|}<\infty.$$ Attempt at a solution: Let $z=x+iy$, then we have: $$\frac{|f(z)|}{|\log|z|^2|}\leq c$$.
 So, $|f(z)|\leq c|\log|z|^2|.$ For large enough $z$, we have $|\log|z|^2|\leq |z|^2$ so we get: $$|f(z)|\leq c|z|^2.$$ Now by extented Liouville's Theorem, $f(z)$ must reduce to a polynomial of degree at most two. Is this correct? Thanks!","['complex-analysis', 'analysis']"
467876,How can I prove that such sequence exists?,"Let $f: \mathbb{R} \to \mathbb{R}$ be defined by $f(x)=x\sin(x)$. Prove that, for all c $\in \mathbb{R}$, there is a sequence $x_n$ $\in \mathbb{R}$ with $\displaystyle \lim_{n \to \infty}x_n = \infty$ and $\displaystyle \lim_{n \to \infty}f(x_n) = c$. It's a problem of a book I was using... Actually, I didn't understand how such sequence can exist... I thought that, in this case, if $\displaystyle \lim_{n \to \infty}x_n = \infty$, so $\displaystyle \lim_{n \to \infty}f(x_n) = \infty$. Apparently, I was wrong... Can someone help?","['functions', 'analysis']"
467888,Is probability and the Law of Large Numbers a huge circular argument?,"I've always been confused on this part of probability. My (naïve?) definition of probability seems to be $Pr(X=x)=p$ meaning on average, $X$ would equal $x$ in a proportion $p$ of the time, as the number of trials goes to infinity. However, this seems to be what the Law of Large Numbers says, and that Law is a theorem, not an axiom or definition of probability. What actually is probability, if not a restatement of the Law of Large Numbers? This always bothers me - probability seems to be one huge circular argument. Where am I wrong?","['statistics', 'probability']"
467889,Quadirlogarithm value $\operatorname{Li}_4 \left( \frac{1}{2}\right)$,"Is there a known closed form for the following $$\operatorname{Li}_4 \left( \frac{1}{2}\right)$$ I know that we can derive the closed of $\operatorname{Li}_1 \left( \frac{1}{2}\right),\operatorname{Li}_2 \left( \frac{1}{2}\right),\operatorname{Li}_3 \left( \frac{1}{2}\right)$ To put it in an integral representation, the problem asks to solve $$\int^1_0 \frac{\log(x)^3}{2-x}\, dx$$","['definite-integrals', 'polylogarithm', 'integration']"
467910,How to change order of integration in a double integral?,"How would you go about changing the order of integration in a function say ; $$\int_0^8\int_\sqrt[3]{y}^2 f(x,y)~dx~dy$$",['integration']
467922,Question on sufficient statistics,"Let ${\bf X}=(X_1,\dots,X_n)$ be a random sample from the pdf $$f(x\mid\mu,\sigma)=\frac{1}{\sigma}e^{\frac{-(x-\mu)}{\sigma}}\;\;
,\;\; \mu<x<\infty\;,\;0<\sigma<\infty.$$ Find a two-dimensional sufficient statistic for $(\mu,\sigma)$. The Factorization Theorem says that I should be able to find $T_1({\bf x})$ and $T_2({\bf x})$ such that we have the decomposition $$\hat{f}({\bf x}\mid\mu,\sigma)=g(T_1({\bf x}),T_2({\bf x})\mid\mu,\sigma)\cdot h({\bf x}).$$ Where $\hat{f}$ is the joint distribution for $\bf X$. I just want to make sure I'm not missing something obvious, since by independence I can write $\hat{f}$ as $$\hat{f}({\bf x}\mid\mu,\sigma)=\hat{f}(x_1,\dots,x_n\mid\mu,\sigma)=\left(\frac{e^{\mu/\sigma}}{\sigma}\right)^ne^{(-1/\sigma)\sum_{k=1}^nx_k}\cdot 1.$$ It appears that just setting $T_1({\bf x})=\sum_{k=1}^nx_k$ is a statistic sufficient to determine both $\mu$ and $\sigma$.  Which worries me since why would the book ask specifically for a two dimensional statistic if a one dimensional one was all that was necessary to obtain sufficiency with regard to both parameters.","['statistics', 'probability']"
467930,Evaluate the integral $\int_{0}^{+\infty}\frac{dx}{1 + x^{1000}} $,"Evaluate the integral
  \begin{equation}
\int\limits_{0}^{+\infty}\frac{dx}{1 + x^{1000}}
\end{equation} I tried using the change of variable, integration by parts, even wolframalpha... Nothing helped. Theoretically speaking, it can be solved by using residue calculus, but we have 500 residues in the upper half-plane. I would be grateful for just a hint.","['calculus', 'complex-analysis']"
467931,Is there a name for this observation involving single-variable limit to infinity?,"Obviously, $$\lim_{n\to \infty} \sqrt{n^2 +1} = \infty$$ However, the following (I am sure) is true: $$\lim_{n\to \infty} \sqrt{n^2 +1} = n$$ Is there a name for this kind of behavior in limits? Such as a general rule or variable specific rule?","['algebra-precalculus', 'limits']"
467941,$10^n+1$ is never prime? [duplicate],"This question already has answers here : Are there infinitely many primes and non primes of the form $10^n+1$? (2 answers) Closed 10 years ago . I tested a few numbers of the form $10^n+1$ (i.e. $100000001$) besides $11$ and $101$ and they were all composite. Clearly some of them if we have an even number of $0$'s in between are multiples of $11$, but is it just a coincidence that the ones with odd number of $0$'s are also composite?",['number-theory']
467952,equilateral triangle; $3(a^4 + b^4 + c^4 + d^4) = (a^2 + b^2 + c^2 + d^2)^2.$,"In equilateral triangle ABC of side length d, if P is an internal point with PA = a, PB = b, and PC = c, the following pleasingly symmetrical relationship holds:
$3(a^4 + b^4 + c^4 + d^4) = (a^2 + b^2 + c^2 + d^2)^2.$
Please prove this identity.
source: http://www.qbyte.org/puzzles/p117s.html","['geometry', 'algebra-precalculus', 'contest-math', 'triangles', 'symmetry']"
467973,Why does $\operatorname{tr}(A^k)=\operatorname{tr}(B^k)$ imply $\operatorname{Spec}(A)=\operatorname{Spec}(B)$?,"Suppose $A$ and $B$ are two square $n\times n$ matrices over some field. Why do the $n$ equations $$\operatorname{tr}(A^k)=\operatorname{tr}(B^k)\text{ for } 1\leq k\leq n$$
imply that $A$ and $B$ have the same spectra? If $\operatorname{Spec}(A)=\{\lambda_1,\dots,\lambda_p\}$ and $\operatorname{Spec}(B)=\{\mu_1,\dots,\mu_r\}$, then I know $\operatorname{Spec}(A^k)=\{\lambda_1^k,\dots,\lambda_p^k\}$ and $\operatorname{Spec}(B^k)=\{\mu_1^k,\dots,\mu_r^k\}$, (some of these new eigenvalues may not be distinct). Since the trace is the sum of the eigenvalues, this would give a new set of equations
$$
\sum \lambda_i^k=\sum \mu_i^k
$$
but since these aren't linear I don't think it'll be possible to solve these and show the set of eigenvalues for $A$ and $B$ are the same.","['matrices', 'eigenvalues-eigenvectors']"
467976,Uniform convergence and weak convergence,"Assume $F_{n},F$ are distribution functions of r.v.$X_{n}$ and $X$, $F_{n}$ weakly converge to $F$. If $F$ is pointwise continuous in the interval $[a,b]\subset\mathbb{R}$, show that
$$\sup_{x\in[a,b]}|F_{n}(x)-F(x)|\rightarrow 0,n\rightarrow \infty.$$Thanks.","['probability-theory', 'weak-convergence', 'uniform-convergence', 'real-analysis']"
467984,Help with this proof in Fulton book,"I'm really confused with the definitions of coordinate rings and field of rational functions. I'm trying to understand this proof which I was stuck in the very beginning: First I didn't understand the definition of $J_f$. we have $\overline G=G+I(V)$ and $f=f_1+I(V)$, where $f_1$ is the residue of $f$ in $\Gamma(V)$. The $\overline Gf=\bigg(g+I(V)\bigg)\bigg(f_1+I(V)\bigg)=\bigg(gf_1+I(V)\bigg)$, so this multiplication is not always in $\Gamma(V)$, since $\Gamma(V)$ is by definition $k[x_1,...,x_n]/I(V)$? Second I didn't understand why the points of $V(I_f)$ are exactly those points where $f$ is not defined. I really need help to understand this proof. Thanks in advance.",['algebraic-geometry']
468007,"Solve the equation for x, y and z: $\sqrt{x-y+z}=\sqrt x - \sqrt y + \sqrt z$","I am having some trouble with this problem, Solve for $x,y,$ and $z$.
  $$\sqrt{x-y+z}=\sqrt x - \sqrt y + \sqrt z$$ Here is my work so far, $$x - y +z = x+y+z-2\sqrt{xy} + 2\sqrt{xz}- 2\sqrt{zy}$$
$$2y-2\sqrt{xy} + 2\sqrt{xz}- 2\sqrt{zy} = 0 $$
$$2(y-\sqrt{xy} + \sqrt{xz} - \sqrt{zy}) = 0 $$
$$y-\sqrt{xy} + \sqrt{xz} - \sqrt{zy} = 0$$",['algebra-precalculus']
468019,Evaluating an improper integral using complex analysis,"I am trying to evaluate the improper integral $I:=\int_{-\infty}^\infty f(x)dx$, where
$$
f(z) := \frac{\exp((1+i)z)}{(1+\exp z)^2}.
$$ I tried to do this by using complex integration. Let $L,L^\prime>0$ be real numbers, and $C_1, C_2, C_3, C_4$ be the line segments that go from $-L^\prime$ to $L$, from $L$ to $L+2\pi i$, from $L + 2\pi i$ to $-L^\prime+2\pi i$ and from $-L^\prime+2\pi i$ to $-L^\prime$, respectively.  Let $C = C_1 + C_2 + C_3 + C_4$. Here we have (for sufficiently large $L$ and $L^\prime$)
$$
\int_{C_2}f(z) dz \le \int_0^{2\pi}\left|\frac{\exp((1+i)(L+iy))}{(\exp(L+iy)+1)}i\right| dy \le \int\frac{1}{(1-e^{-L})(e^L - 1)}dy\rightarrow0\quad(L\rightarrow\infty),
$$
$$
\int_{C_4}f(z)dz\le\int_0^{2\pi}\left|\frac{\exp((1+i)(-L^\prime+iy))}{(\exp(-L^\prime + iy) + 1))^2}(-i)\right|dy\le\int\frac{e^{-L^\prime}}{(1-e^{-L})^2}dy\rightarrow 0\quad(L^\prime\rightarrow\infty),
$$
and
$$
\int_{C_3}f(z)dz = e^{-2\pi}\int_{C_1}f(z)dz.
$$
Thus $$I = \lim_{L,L^\prime\rightarrow\infty}\frac{1}{ (1 + e^{-2\pi})}\oint_Cf(z)dz.$$ Within the perimeter $C$ of the rectangle, 
$f$ has only one pole: $z = \pi i$.  Around this point, $f$ has the expansion
$$
f(z) = \frac{O(1)}{(-(z-\pi i)(1 + O(z-\pi i)))^2} =\frac{O(1)(1+O(z-\pi i))^2}{(z-\pi i)^2} = \frac{1}{(z-\pi i)^2} + O((z-\pi i)^{-1}),
$$
and thus the order of the pole is 2.  Its residue is
$$
\frac{1}{(2-1)!}\frac{d}{dz}\Big|_{z=\pi i}(z-\pi i)^2f(z) = -\pi \exp(i\pi^2)
$$
(after a long calculation) and we have finally $I=-\exp(i\pi^2)/2i(1+\exp(-2\pi))$. My question is whether this derivation is correct.  I would also like to know if there are easier ways to do this (especially, those of calculating the residue).
I would appreciate if you could help me work on this problem.","['improper-integrals', 'integration', 'complex-analysis']"
