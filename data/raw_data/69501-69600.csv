question_id,title,body,tags
843664,Limit points of $\cos n$.,Find the limit point of the sequence $\{s_n\}$ given by $s_n=\cos n $. I know by this post Limit of sequence $s_n = \cos(n)$ that the sequence does not converge. But I don't know how to search those points.,"['real-analysis', 'limits']"
843669,Infinite Sum of algebraic expression,Prove that $$\sum_{i=1}^{\infty} \frac{1}{i(2i+3)} = \frac89 -\frac23\ln2$$ I tried using integration but failed miserably. Hints please.,"['sequences-and-series', 'summation', 'calculus']"
843677,Eigenvalues of a $4\times 4$ parameters matrix,"Let $a,b,c,d\in\Bbb{C}$ and $B =\begin{bmatrix}
    a & b & c & d\\
    d & a & b & c\\
    c & d & a & b\\
    b & c & d & a\\
  \end{bmatrix}$ I know that $t=a+b+c+d$ is an eigenvalue because every row's sum is $t$ (and every column) and I also know that the sum of the eigenvalues is $4a$ (because it equals the trace of $B$).
However I don't know how to continue.. and calculating the chracteristic polynomial of $B$ seems not very pleasant. Any ideas? thanks","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors', 'diagonalization']"
843684,Prove an inequality (Using Taylor expansion),"Prove: $\frac{x}{1+x} < \ln(1+x) < x$. I thought a good practice would be to prove it using Taylor Expansion. Here's my try: $$\ln(1+x) = x - \frac{x^2}{2} + \frac{x^3}{3}...$$ The n=1 Taylor polynomial is:
$$T_1(x) = x$$
and 
$$ ln(1+x) = T_1(x) +  R_1(x)$$ Lets evaluate $R_1(x)$ by Cauchy's remainder formula: $$R_1(x) = \frac{f^{(2)}(\xi)}{2!}\cdot x^2 = \frac{\frac{-1}{(\xi+1)^2}}{2!}\cdot x^2 = \frac{-x^2}{2(\xi+1)^2} < 0$$ Now, it does prove the right-hand side because $x + R_1(x) < x$ ($R_1(x)$ is negative).
I'm not so sure what should I do for the left-hand side. I'd also like to get general critique for my current work. Thanks!","['calculus', 'polynomials', 'real-analysis', 'derivatives', 'taylor-expansion']"
843721,Prevent Alice from building a tower of height k,"Alice and Bob take turns playing the tower of babel game, with Alice starting. In this game Alice has $m$ parcels of land. In each of  Alice's turns she receives $n$ blocks and decides to distribute them between her parcels to make the towers on each tower taller (at the beginning the towers have a height of $0$ blocks. In each of Bob's turns he can choose to destroy a tower and render that parcel of land unusable for the rest of the game, for what values of $m,n,k$ does Bob win and for which does Alice win? Alice wins if at any point in time there is a tower of height $k$ on the field. Here is what I have done up to now: Suppose the game is different, in this game Alice tries to build the highest tower possible. What is the highest tower Alice can build if both players play optimally? denote this number by $h(n,m)$ The best strategy for bob is clearly to remove the highest tower in each of his turns. the best strategy for Alice is to first make sure all towers are of size $1$, then of size $2$ and so on. Why? The tower will achieve its highest point when it is the last tower standing. The height of that tower will be $(m-1)n$ minus the number of blocks on the destroyed towers, by using the aforementioned strategy Alice can minimize that sum. So now all we have to do is calculate $t(n,m)$, we already know $t(n,m)=(m-1)n-d$ where $d$ is the number of blocks on the destroyed towers.","['game-theory', 'combinatorics']"
843724,Finite Group with Nilpotent Subgroup of Prime Power Index is Solvable,"Let $G$ be a finite group, and assume that $H$ is a nilpotent subgroup whose index is a prime power. WLOG, we can say that the index of $H$ is the highest power of $p$ which divides the order of $G$. I want to show that $G$ is solvable, and I'm allowed to use Burnside's $p^aq^b$ theorem, as well as Hall's Theorem (which states that if every Sylow-$p$ subgroup has a complement, then $G$ is solvable). So say $|G|=p^aq_1^{\alpha_1}\cdots q_n^{\alpha_n}$. Then since $H$ is nilpotent, it's the direct product of its Sylow subgroups, so $H=Q_1\times\cdots\times Q_n$. $H$ is obviously a complement for $G$'s Sylow-$p$ subgroup $P$, so I'll be done if I can show there's a complement to $Q_i$, the Sylow-$q_i$. Now, if we let $H_1=H/Q_i$, my first idea is to consider $PH_i$, which has the desired order, but of course there's no guarantee that this is a subgroup, since neither of the two subgroups need to be normal. I also tried assuming that $G$ is a minimal counterexample and thus simple and showing that some nontrivial proper subgroup is normal, but since $p$ does not have to be the largest prime, I can't argue that the action of $P$ on the $Q_i$'s by conjugation is trivial. Are either of these avenues fruitful, or should I try something else?","['group-theory', 'abstract-algebra']"
843728,Tool that draws Venn diagram from subset relation,"Is there a tool (LaTeX, JavaScript, Mathematica..) that allows one to draw Venn diagram automatically from subsets relations, e.g. $$A\subset A+B$$ $$A\subset C$$ $$C\subset C+D$$ $$B \not\subset C$$ woud yield ------------------------------------------------
|                      C+D                     |
|                                              |
|  ------------------------------------------  |
|  |         A+B       |          C         |  |
|  |                   |                    |  |
|  |                   |                    |  |
|  |  ------------------------------------  |  |
|  |  |                                  |  |  |
|  |  |                A                 |  |  |
|  |  |                                  |  |  |
|  |  ------------------------------------  |  |
------------------------------------------------ (Sorry for the pitiful Ascii drawing)","['elementary-set-theory', 'math-software']"
843763,"For $x\in\mathbb R\setminus\mathbb Q$, the set $\{nx-\lfloor nx\rfloor: n\in \mathbb{N}\}$ is dense on $[0,1)$","Let $x\in \mathbb{R}$ an irrational number. Define $X=\{nx-\lfloor nx\rfloor: n\in \mathbb{N}\}$. Prove that $X$ is dense on $[0,1)$. Can anyone give some hint to solve this problem? I tried contradiction but could not reach a proof. I spend part of the day studying this question Positive integer multiples of an irrational mod 1 are dense and its answers. Only one answer is clear and give clues to solve the problem. This answer is the first one. However, this answer does not answer the question nor directly, nor the proof follows from this answer. This answer has some mistakes, he use that $[(k_1-k_2)\alpha]=[k_1\alpha]-[k_2\alpha]$ which is not true. Consider $k_1=3, k_2=1, \alpha=\sqrt{2}$ we have $[(k_1-k_2)\alpha]=2\not= 3=[k_1\alpha]-[k_2\alpha] $. We only can assure that $[k_2\alpha]-[k_1\alpha]-1\leq [(k_2-k_1)\alpha]\leq[k_2\alpha]-[k_1\alpha]$. Who answered said something interesting about additive subgroups of $\mathbb{R}$, but unfortunately the set $X=\{nx-[nx] : n\in \mathbb{N} \}$ is not a subgroup. Considering the additive subgroup $G=\langle X \rangle$, if we prove the part (a) of the link, we get that indeed $G$ is dense on $\mathbb{R}$ but we can not conclude that $X$ is dense on $[0,1)$. I think this problem has not been solved. Thanks!","['fractional-part', 'irrational-numbers', 'real-analysis', 'ceiling-and-floor-functions']"
843829,"$f'$ is bounded and isn't continuous on $(a,b)$, so there's a point $y\in(a,b)$ such that $\lim_{x\to y}f'$ does not exist","Prove/disprove: $f$ has a bounded derivative and $f'$ isn't continuous on $(a,b)$, so there's a point $y\in(a,b)$ such that $\displaystyle\lim_{x\to y}f'$ does not exist. I think that if $f'$ isn't continuous on the interval, then maybe we could have two disjoint sub-intervals, like for example $(a,c), (d,b)$ such that $d-c=\dfrac {a+b} 3$ so there's a substantial gap in the interval $(a,b)$ where $f'$ isn't defined so it follows that it won't have a limit there, for example: on $\dfrac {c+d}2$.","['calculus', 'proof-verification', 'functions', 'analysis']"
843834,Trying to understand formula for counting regions of hyperplane arrangements in $\mathbb{R}^2$,"There are up to $\binom{n}{2} + n + 1$ regions created by a hyperplane arrangement in $\mathbb{R}^2$ containing $n$ hyperplanes. I want to understand this in a demonstrative way. Each hyperplane splits each region it passes in two regions. A newly added hyperplane therefore creates a new region each time it crosses another hyplerplane or the plane. So the number of regions should be $1$ (plane) $+ \binom{n}{2}$ (number of intersections of $n$ lines). But as I know the answer, I know that I am missing $n$ regions. Do you know where my mistake is? Why do I have to add the number of lines to get the max. number of regions?","['geometry', 'combinatorics']"
843845,Find the Mean for Non-Negative Integer-Valued Random Variable,"Let $X$ be a non-negative integer-valued random variable with finite mean.
Show that
$$E(X)=\sum^\infty_{n=0}P(X>n)$$ This is the hint from my lecturer. ""Start with the definition $E(X)=\sum^\infty_{x=1}xP(X=x)$. Rewrite the series as double sum."" For my opinion. I think the double sum have the form of $\sum\sum f(x)$, but how to get this form? And how to continue?","['faq', 'expected-value', 'probability', 'random-variables']"
843851,ACC on principal ideals implies factorization into irreducibles. Does $R$ have to be a domain?,"I am following an argument in chapter zero of Eisenbud's Commutative Algebra book.  It is not clear whether or not he is assuming that $R$ is a domain.  If I start the proof assuming $R$ is not necessarily a domain this is what I get: Suppose that $R$ (commutative ring with identity) satisfies ACC on principal ideals but there exists a non-unit $a_1\in R$ such that $a_1$ does not admit a factorization into irreducibles.  As $a_1$ is not irreducible, $a_1=bc$, with both $b$ and $c$ non-units. Both $b$ and $c$ cannot have factorization into irreducibles since in that case we would have a factorization into irreducibles of $a_1$.  So WLoG, assume that $b$ has no factorization into irreducibles. Set $a_2=b$. Then we have $(a_1)\subsetneq (a_2)$. This is where I am stuck.  It is clear that $(a_1)\subset (a_2)$, since $a_1=a_2 c$.  But I get stuck showing that $(a_1)\neq (a_2)$.  What is frustrating me is that I can show with ease that $(a_1)\neq (a_2)$ if $R$ is a domain (or even if $a_1$ is not a zero divisor) but not otherwise. The rest of the argument is straight forward.  Continue picking the $a_i$ inductively and get a non-terminating ascending chain of principal ideals; contradicting ACC.","['commutative-algebra', 'ring-theory', 'abstract-algebra']"
843852,Evaluate by contour integration $\int_0^1\frac{dx}{(x^2-x^3)^{1/3}}$,Evaluate by contour integration [i am learning complex analysis - calculus of residues] $$\int_0^1\frac{dx}{(x^2-x^3)^{1/3}}$$ I tried by taking $x^3$ out from the denominator but that didnt work.,"['residue-calculus', 'integration', 'complex-analysis']"
843855,Simplest form of $h'(y)$ given $h(y)= (1-3y^2)^5 \cdot ( y^2 + 2)^6$,Find $h'(y)$ in the simplest form if the $$h(y)= (1-3y^2)^5 \cdot ( y^2 + 2)^6$$ My answer was: $$-30y(1-3y^2)^4 \cdot (y^2+2)^6 + 12y(y^2+2)^5 \cdot (1-3y^2)^5$$ But according to wolfram alpha the answer was $$ -30y(1-3y^2)^4 \cdot (y^2+2)^6 $$ only. which makes it weird that they did not differentiate the second term my answer was different. I posted it again because I did not get an answer.,"['calculus', 'derivatives']"
843858,Radius of convergence of entire function,"Let $f$ be an entire function on the complex plane. Is the radius of convergence of $f$ around any point $z_0$ infinite? If so, why? Thank you.","['power-series', 'complex-analysis']"
843874,What is the manifold structure of $U(n)$?,"A Lie group is simultaneously a differentiable manifold. As I understand it, the Lie group is generated via exponentiation of the generators of the Lie algebra. It is intuitively clear to me that the Lie group $U(1)$ is isomorphic to the manifold of the circle. Are $SU(2)$ and $SO(3)$ isomorphic to the two-sphere? Furthermore, what is the manifold structure of $U(n)$ in general? Furthermore, can anything be said about the manifold structure of the infinite-dimensional Unitary group? (This group occurs all the time in applications in quantum physics when the Hilbert space is infinite-dimensional).","['lie-groups', 'group-theory']"
843909,Prove that the inverse image of an open set is open,"Let $ X \subset \mathbb{R}$ be a non-empty, open set and let $f: X \rightarrow \mathbb{R}$ be a continuous function. Show that the inverse image of an open set is open under f, i.e. show: If $M \subset \mathbb{R}$ is open, then $f^{-1}(M)$ is open as well. I think that this should basically follow from the definitions, but I'm still having some troubles with the proof. Suppose $M \subset \mathbb{R}$ is open, then it follows that $\forall z \in M, \exists r > 0: K_r(z) \subseteq M$ Since f is continuous it follows for each $x_0 \in X$ that for each $\epsilon > 0 ,\exists \delta > 0 : |f(x)-f(x_0)|< \epsilon, \forall x \in X: |x-x_0|<\delta$ Now I need to show that $f^{-1}(M)$ is open, so that for each $z \in M, \exists r>0: K_r(f^{-1}(z_0)) \subseteq f^{-1}(M)$ I'm not sure how to prove this. I guess since $z = f(x)$ and since M is open we have that $\exists r>0:\{z:|z-z_0|<r\}\subseteq M$. And since f is continuous: $|f(x)-f(x_0)| = |z-z_0|< \epsilon$ for all $|x-x_0|<\delta$, but since $|x-x_0|=|f^{-1}(z)-f^{-1}(z_0)|<\delta$ it somehow follows from that that $f^{-1}(M)$ is open?! Which is just horrible and probably completely wrong. But I'm really confused from all the definitions right now and need some help please.","['continuity', 'real-analysis']"
843918,Arcwise connected but not connected?,"In his book ""Geometry, Topology and Physics"", Nakahara makes the following claim with regard to topological spaces: With a few pathological exceptions, arcwise connectedness is practically equivalent to connectedness. Could somebody please give me examples of such exceptions? Where can I read more about these pathologies? To make my question more precise: are there topological spaces which are arcwise-connected, but not connected?","['general-topology', 'connectedness']"
843924,Premises of the Mean Value Theorem,"Why does the statement of the mean value theorem requires that: (1)The function $f$ be continuous on the closed interval $[a,b]$ (2)Differentiable on the open interval $(a,b)$. Couldn't we just require (2) and the the first premise will be met because of the fact that differientiability implies continuity ?",['calculus']
843932,Understanding vector projection,"I'm learning about vector projection. I understand how to perform it, but I still can't understand what it actually means and what it gives me. Here is a common definition: Vector projection of a onto b , gives the component
  of a that is in the same direction of b . What does this mean? Vectors are straight lines. a can't have a part of it in the direction of b and a part of it that isn't. A vector has one direction, it's a straight line. I just can't understand this. I hope with some help here it'll finally click. Thanks","['analytic-geometry', 'linear-algebra']"
843943,Show that $\sqrt{8-4\sqrt3} =\sqrt[6]2\:\! {\sqrt[3]{12\sqrt3-20}}$,"This was the result of evaluating an integral by two different methods. The RHS was obtained by making a substitution, the LHS was obtained using trigonometric identity's and partial fractions. Now I know that these two are equal, but I just can't prove it. I tried writing the LHS in terms of powers of $2$, but can't get any further to the desired result.","['radicals', 'algebra-precalculus']"
843950,Algebraic proof of Ehrhart's theorem,"Let $P \subset \mathbb{R}^d$ be a $d$-dimensional polytope, where all vertices lie on integral coordinates, and let $L(P,n)$ denote the number of integral lattice points contained in the scaled polytope $n \cdot P$, i.e. $L(P,n) := \# ((n \cdot P) \cap \mathbb{Z}^d)$. Then we know by a theorem of Ehrhart: The generating function $E(P,t) := \sum_{n=0}^\infty L(P,n) \cdot t^n$ is a rational function of the form $E(P,t) = \frac{h(t)}{(1-t)^{d+1}}$, where $h$ is a polynomial with $h(1) \neq 0$. $L(P,n)$ is a polynomial in $n$ for all positive integers. I wonder if these results can also be obtained by the following algebraic approach:
Let $k$ be an arbitrary field and $M := \text{Cone}(P \times \{1\}) \cap \mathbb{Z}^{d+1}$ considered as submonoid of $\mathbb{R}^{d+1}$. Then the Noetherian monoid algebra $k[M]$ is $\mathbb{Z}$-graded with respect to the $(d+1)$-th coordinate, and the corresponding Hilbert series of $k[M]$ coincides with $E(P,t)$. By the Hilbert-Serre theorem this series is a rational function of the form $E(P,t) = \frac{f(t)}{\prod_i 1-t^{e_i}}$. It is also clear that if we can show that all $e_i$ can be chosen to be $1$, it follows that $L(P,n)$ is a polynomial function for all sufficiently large $n$. Is there an elegant way to proceed with this approach to get the same results as above?","['geometry', 'integer-lattices', 'abstract-algebra', 'discrete-geometry', 'commutative-algebra']"
843966,The homophonic group: a mathematical diversion,"By definition, English words have the same pronunciation if their phonetic spellings in the dictionary are the same. The homophonic group $H$ is generated by the letters of the alphabet, subject to the following relations: English words with the same pronunciation represent equal elements of the group. Thus $be = bee$, and since $H$ is a group, we can conclude that $e = 1$ (why?). Try to determine the group $H$. Is it satisfied if I select some special words and use the relations on pronunciation to prove that every letter in the alphabet equal to $1$ so that $H$ is the trivial group?","['gap', 'free-groups', 'group-theory', 'abstract-algebra']"
843994,Limit of a matrix multiplication,How can I calculate this limit: $\displaystyle\lim_{n\to\infty}\begin{bmatrix}0.9 & 0.2\\0.1 & 0.8\end{bmatrix}^n$ What is the tool that i need to aply? eigenvalues and eigenvectors? diagonalization? canonical form? (This came in a contest and was the only problem i cannont have an idea for solve it).,['linear-algebra']
844010,Let X be an exponential random variable with P(X < 1/3) = 0.75. What is E(X)?,Let X be an exponential random variable with P(X < 1/3) = 0.75. What is E(X)? I don't get this. Please help.,"['statistics', 'probability', 'random-variables']"
844013,Additive functional inequality,"The function $f:R_+\to R_+$ is continuously differentiable and
 increasing. Also, $f(0)=0$ and $f(\infty)=\infty$.   Continuity and
 differentiability of higher orders can be assumed if necessary.   The
 proposition on hand is the following: If for all integers $t>0$ and
    for all  $x> 0$, $f((t+1)x)<f(tx)+f(x)$, then for all
    integers $m,n>0$, $f(mx)+f(nx)\geq f(mx+nx)$. Does there exist a proof or a counter example?","['functions', 'puzzle', 'real-analysis', 'functional-equations']"
844041,prove that there infinitely many primes of the form $8k-1$,"Using the fact that $$\left ( \frac{2}{p} \right )=(-1)^{\frac{p^2-1}{8}}$$
for each prime $p>2$,prove that there infinitely many primes of the form $8k-1$. I thought that we could I assume that there is a finite number of primes of the form $8k-1$: $p_1,p_2 \dots ,p_k$ Could we maybe set $N=8p_1p_2 \cdots p_k-1 >1$ Then $N$ has a prime divisor $p$.$p$ can be of the form $8n+1,8n+3,8n+5 \text{ or } 8n+7$.. How could I continue?? Also...how can I use this: $\left ( \frac{2}{p} \right )=(-1)^{\frac{p^2-1}{8}}$ ?",['number-theory']
844046,"Proving that $\gamma = \int_{0}^{1} \!\!\int_{0}^{1} \!\frac{x - 1}{(1 - x y) \log(x y)} \, \mathrm{d}{x} \, \mathrm{d}{y} $.","In 2005, J. Sondow found a surprising formula for the Euler-Mascheroni constant $ \gamma $. The formula is
$$
  \gamma
= \int_{0}^{1} \int_{0}^{1} \frac{x - 1}{(1 - x y) \log(x y)}
  ~ \mathrm{d}{x} ~ \mathrm{d}{y}.
$$
Now, the definition of $ \gamma $ is
$$
\gamma
\stackrel{\text{def}}{=}
\lim_{n \to \infty} \left[ \sum_{k = 1}^{n} \frac{1}{k} - \log(n) \right].
$$
I have tried using the geometric series
$$
\frac{1}{1 - x y} = \sum_{n = 0}^{\infty} x^{n} y^{n}
$$
to obtain a proof, but it would not work. Thanks for any help.","['improper-integrals', 'summation', 'calculus', 'integration']"
844053,In a uniformly convex Banach space $x_n\stackrel{w}\to x$ and $||x_n||\to ||x||$ implies $||x_n-x||\to 0$,In a uniformly convex Banach space $$x_n\stackrel{w}\to x  \ \ \text{and} \ \ ||x_n||\to ||x||  \ \ \text{implies}  \ ||x_n-x||\to 0.$$ Can you  help me to solve it? Thanks in advance.,"['functional-analysis', 'banach-spaces']"
844113,Set intersection theory,"$W = \{a,b,c\}, Z = \{W,\emptyset\}$ What is $Z\cap W$? I'm not sure how to work this out as my thoughts would be
$$Z = \{W,\emptyset\}  = \{\{a,b,c\},\emptyset\}$$
Which means $Z \cap W = \{a,b,c,\{a,b,c\},\emptyset\}$ Or should it just be
$$Z = \{W,\emptyset\} = \{a,b,c,\emptyset\}$$
Which means $Z \cap W = \{a,b,c,\emptyset\}$ Or should it just be 
$$Z = \{W,\emptyset\}$$
Which means $Z\cap W = \{W,\emptyset,a,b,c\}$ Any thoughts would be appreciated!",['elementary-set-theory']
844131,Adjoint Functor Theorem,"The Freyd's Adjoint Theorem states that given a complete locally small category $\mathcal{C}$, a continuous functor $G: \mathcal{C} \to \mathcal{D}$ has a left adjoint if and only if it satisfies a certain condition (which is called a Solution Set Condition in Maclane's book), which is equivalent, under our assumptions, to say that for each $X \in \mathcal{D}$ the category $(X \downarrow G)$ has an initial object. This theorem seems to be central in classical Category Theory, since it allow us to show the existence of a left adjoint for $G$ by checking the given Solution Set Condition. However, this condition seems to be difficult to check, except in some easy cases. Question 1. Is there any fundamental result in which Freyd's Adjoint Theorem plays a crucial role to show the existence of a left adjoint? Question 2 . It is frequently asked (in Maclane's book) to construct a left adjoint functor in some special cases, using Freyd's Adjoint Theorem. However, except these special cases, I do not see how this result allows the explicit construction a left adjoint.","['category-theory', 'abstract-algebra', 'adjoint-functors']"
844134,Using continuity to evaluate limits,"I hope you guys are enjoying your weekend. I have a question about limits. This homework problem asks me to use continuity to evaluate this limit, I would like to double-check that I have following the right procedure. The problem is as follows: $$\lim_{x\to \pi}\sin(x + \sin x)$$ I break the problem up into two seperate limits: $$\lim_{x\to \pi}\sin x + \lim_{x\to \pi}\sin(\sin x)$$ Because $\sin x$ is continuous in its domain and its domain includes all real numbers, both limits are continuous and have a domain that includes all real numbers. I can therefore plug in $\pi$ and conclude that the limit is $0$. Is my methodology correct or am I making a mistake? Thanks!","['calculus', 'algebra-precalculus', 'limits']"
844150,Method of Variation of Parameters - Assigning zero works?,"I have yet to find a decent answer on this, and so I don't think this question is inappropriate. Also, this question is mainly meant for people that are very familiar with this method. In the method of variation of parameters method for solving the non-homogeneous (heterogeneous?) part of a second order linear differential equation - that is, one in the form $$y''(t)+a(t)y'(t)+b(t)y(t)=g(t)$$I'm still boggled with the exact purpose of setting parts of the first derivative of the particular solution equal to solution. I will explain what I'm talking about here. Suppose we have a $2^{nd}$ order linear non-homogeneous ODE,  $$y''(t)+a(t)y'(t)+b(t)y(t)=g(t)$$
Also, suppose we've already obtained a general solution for the homogeneous version of the ODE, $y''(t)+a(t)y'(t)+b(t)y(t)=0$, that's in the nice form $$y_h=c_1y_1+c_2y_2$$ To get the particular solution for the non-homogeneous part, we start off with the weird (but successful) method of variation of parameters - change the $c_1$ and $c_2$ to $u_1(t)$ and $u_2(t)$ respectively (hence, variation of parameters), and call that $y_p$. $$y_p=u_1(t)y_1+u_2(t)y_2$$ The goal is to find out $u_1(t)$ and $u_2(t)$, and so we now get the $1^{st}$ and $2^{nd}$ derivatives of $y_p$ so we can slap them into the original ODE and hopefully solve for $u_1(t)$ and $u_2(t)$. The first derivative follows by chain rule: $$y'_p = u'_1(t)y_1 + u_1(t)y'_1 + u'_2(t)y_2 + u_2(t)y'_2$$ Here is the part I don't understand. In every textbook I've seen this in, the next step goes basically as follows: For no reason and no motivation (as far as we're concerned right now), we now set the following:
  $$u'_1(t)y_1 + u'_2(t)y_2 = 0$$
  This will turn out to work in the end very nicely, and it will also make our computations much more simple. I've seen full well that this does work out nicely, and that it does make the computations much more simple, but my question is why is this done, and why does it work out so nicely? Why does that equation $$u'_1(t)y_1 + u'_2(t)y_2 = 0$$ always have to be satisfied for particular solutions to $2^{nd}$ order linear non-homogeneous ODE's of this form? .","['ordinary-differential-equations', 'intuition']"
844159,"The integral on $[0,1]\times[0,1]$","Here I have a problem. $p$ and $q$ are positive numbers. the integral $$\int_0^1\int_0^1 \frac{1}{x^p+y^q}\;dx\;dy< \infty \Longleftrightarrow \frac{1}{p}+\frac{1}{q}>1$$ Here is my try, maybe we can change variable. When $p>1:$ $$\int_0^1\int_0^1 \frac{1}{x^p+y^q}dxdy=\int_0^1\int_0^1 \frac{1}{(\frac{x}{y^{\frac{q}{p}}})^p+1}\cdot \frac{1}{y^q}dxdy=\int_0^1\int_0^{y^{-\frac{q}{p}}} \frac{y^{\frac{q}{p}-q}}{t^p+1}dtdy$$ So when $p>1,$ integrable$\Longleftrightarrow \frac{q}{p}-q>-1\Longleftrightarrow \frac{1}{p}+\frac{1}{q}>1 $ When $0<p \leq 1, \ \text{we have}\frac{1}{x^p}\geq \frac{1}{x^p+y^q}\geq \frac{1}{(x+y^\frac{q}{p})^p}$ So integrable$\Longleftrightarrow \frac{1}{p}+\frac{1}{q}>1$","['convergence-divergence', 'integration', 'real-analysis']"
844193,Optimization of parallelepiped inside an ellipsoid,"Let $K \in R^3$  the ellipsoid given by the equation $ \frac{x^2}{a^2} + \frac{y^2}{b^2} + \frac{z^2}{c^2} = 1 $ with $a,b,c > 0$ , let $(x,y,z) \in K$ on the first octant, consider the parallelepiped of vertices $(\pm x,\pm y,\pm z)$ inscribed on $K$  with volume $V = 8xyz$. How can I find the maximum possible value of $V$? I stuck with this hard problem for me i tried to find the explicit equation and then get the maximum values : Let $P=(x,y,z)$ be a point on the ellipsoid with $x,y,z\gt 0$.Then i took the eight different points with $P_i (\pm x,\pm y,\pm z)$  the vertices of a parallelepiped with the side length $2x , 2y$ and $2z$. Then, the volume parallelepiped is $V = 2x\cdot 2y\cdot 2z = 8 xyz$ and i remembered that $V$ is maximum if and only if $V^2$ is maximum . Some help please.","['optimization', 'multivariable-calculus', 'volume', 'derivatives']"
844195,An inequality between integrals of series of characteristic functions of cubes,"Let $1\leq p<\infty$. Prove that there exists $C>0$ such that 
$$
\left(\int\left|\sum_{i=1}^\infty a_i\chi_{2Q_i}\right|^p \, dx\right)^{1/p} \leq  C\left(\int\left|\sum_{i=1}^\infty |a_i|\chi_{Q_i}\right|^p \, dx\right)^{1/p}.
$$
Here $\{a_i\}$ is a sequence of real numbers and $\{Q_i\}$ is a sequence of cubes in $\mathbb{R}^n$,  $2Q_i$ is the cube with the same center as $Q_i$ but twice its length. How to prove this? Thanks.","['sequences-and-series', 'integration', 'measure-theory', 'harmonic-analysis', 'real-analysis']"
844198,Find $\lim\frac{1}{\sqrt{n}}\left(\frac{1}{\sqrt{1}+\sqrt{3}}+\frac{1}{\sqrt{3}+\sqrt{5}}+\ldots+\frac{1}{\sqrt{2n-1}+\sqrt{2n+1}}\right)$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Find $$\lim_{n\rightarrow\infty}\frac{1}{\sqrt{n}}\left(\frac{1}{\sqrt{1}+\sqrt{3}}+\frac{1}{\sqrt{3}+\sqrt{5}}+\ldots+\frac{1}{\sqrt{2n-1}+\sqrt{2n+1}}\right)$$",['limits']
844202,What is the difference between a calculus and an algebra? [duplicate],"This question already has answers here : What do Algebra and Calculus mean? (4 answers) Closed 10 years ago . You can have a lambda calculus , the calculus of the real numbers or a logical calculus but on the other hand you could also have an algebra of sets, a Lie algebra , or a linear algebra . Is there any convention which dictates whether something is an algebra or a calculus ? From my understanding, a calculus seems to give you information about objects you might encounter within a space, while an algebra gives you information about the interactions and structure within the space as a whole. Is this correct?","['algebras', 'calculus', 'terminology', 'soft-question']"
844203,Is this correct and sufficient to show limit does not exist?,"Find limit or show that it does not exist: $$\lim_{(x,y) \to (0,0)} \frac{ 2x^{2}y^{3/2} }{y^{2}+x^{8}}$$
using the path  $x=m y^{1/4}$: $$\lim_{(my^{1/4},y) \to (0,0)} \frac{ 2m^{2}y^{1/2}y^{3/2}}{y^{2}+m^{8}y^{2}}$$ $$\lim_{(my^{1/4},y) \to (0,0)} \frac{ 2m^{2}y^{2}}{y^{2}(1+m^{8})}$$ $$\lim_{(my^{1/4},y) \to (0,0)} \frac{ 2m^{2}}{1+m^{8}}$$ Does not exist, because limit is path dependent. I am asking because I have a test in a couple days.  I want to make sure I'm not committing some mortal math sin. Also, the Latex tutorial is great, I think I just wasted 20 minutes making that mess.","['multivariable-calculus', 'limits']"
844204,Prove that $\det(xI_m-AB)=x^{m-n}\det(xI_n-BA)$,"I want to prove that $$\det \left( x I_m - A B \right) = x^{m-n} \det \left( x I_n - B A \right)$$ where $A \in \mathbb{F}^{m \times n}$ and $B \in \mathbb{F}^{n\times m}$ . It is easy to show that $0$ has algebraic multiplicity of at least $m-n$ for $AB$ , but how can I show that the other eigenvalues of $AB$ are actually eigenvalues of $BA$ ? I know that the sum of eigenvalues of $AB$ and $BA$ are the same, because $\operatorname{trace}(AB)=\operatorname{trace}(BA)$ , but ... I appreciate any help, thanks ! ${{{}}}$","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors', 'determinant']"
844216,Proving that $\int_0^\infty\Big(\sqrt[n]{1+x^n}-x\Big)dx~=~\frac12\cdot{-1/n\choose+1/n}^{-1}$,"How can we prove, without employing the aid of residues or various transforms, that, for $n>2$ $$\int_0^\infty\Big(\sqrt[n]{1+x^n}-x\Big)dx~=~\frac12\cdot{-1/n\choose+1/n}^{-1}$$ Motivation: In my previous question , thanks to Will Jagy's simple but brilliant answer, I was able to express the area of the superellipse $x^n+y^n=r^n$, for odd values of $n=2k+1$, with $k\in\mathbb N^*$, as $A_n=r^2\displaystyle\cdot{2/n\choose1/n}^{-1}+r^2\cdot{-1/n\choose+1/n}^{-1}$, where the first term, representing the surface inside the first sector or quadrant, comes from a simple evaluation of the beta function . My fruitless efforts and endeavors: $\big(1\big).$ Breaking up the integration interval into $(0,1)$ and $(1,\infty)$, expanding the integrand into an appropriate binomial series for each of the two cases, and then switching the order of summation and integration. In the end, this made me rewrite the initial question in terms of an infinite series, but led me no closer to finding an answer: $$2a\sum_{k=1}^\infty{a\choose k}\Bigg(\frac1{k+a}+\frac1{k-2a}\Bigg)={-a\choose+a}^{-1}-1.$$ $\big(2\big).$ Letting $x=\sqrt[n]{\sinh^2t~}$. Needless to say, that did not get me very far either. $\big(3\big).$ Letting $x^n=u$, we are able to obtain an expression in terms of incomplete beta functions .","['closed-form', 'calculus', 'integration', 'definite-integrals', 'beta-function']"
844235,"Calculate $\int_D x^3y\ dx\,dy$","Let $D$ the bounded region by the $y$-axis  and the parable $x= -4y^2 + 3$. How can I calculate the integral $$\int_D x^3y\ dx\,dy$$ I am stuck with this problem some help to solve this please.","['definite-integrals', 'multivariable-calculus', 'calculus', 'integration']"
844289,Why diagonal matrix SVD sorted from largest to smallest value?,"Why diagonal matrix SVD sorted from largest to smallest value? D is diagonal matrix, $D=(d_1 \ge ,d_2 \ge ,..., \ge d_L)$. Whether there is a journal that could explain this?","['matrices', 'linear-algebra', 'svd']"
844306,How to prove $ \lim_{n \to \infty} e^n \cdot \left( \sum_{k=0}^{n-1} ({k-n \over e})^k/k! \right)- 2 \cdot n = \frac 23$?,"I observed for the function 
$$ f(n)= e^n \sum_{k=0}^{n-1}\left(\dfrac{k - n}{e}\right)^k \cdot \dfrac{1}{k!} \tag 1$$ with small $n$ that n  sum
 -------------
  1  2.7182818
  2  4.6707743
  3  6.6665656
  4  8.6666045
  5  10.666662
  6  12.666667
  7  14.666667
  8  16.666667 So an obvious hypothesis is
$$ \lim_{n \to \infty} \bigl(f(n)-2n\bigr) = \frac 23 \tag 2$$ However, I have no idea, how to prove this but would like to understand how I can approach such a proof (I'll have then some similar ones with likely the same or related logic) So I would like to understand ... Q: how I could prove that assumed limit (2).","['sequences-and-series', 'exponential-function', 'calculus']"
844317,Problem on number of elements in sets,"This question in my text book chapter named ""Permutation, Combination and Probability"". But I am stuck with Permutation, Combination and probability. All things are seems same to me. As I am new in these. Question is:
There are 53 students taking Chemistry and Physics or both, 38 students taking chemistry, and 40 students taking physics.
(i) How many students are taking both Chemistry and Physics?
(ii) How many students are taking Chemistry but not Physics?
(iii) How many students are taking Physics but not Chemistry? Can any one help me out.",['elementary-set-theory']
844321,"Does every ""balloon"" (dragon, tadpole, canoe paddle) admit a graceful labeling?","8/18/14 Edit: If anyone has a copy of a related reference, then I would be happy to see it. For now, I am accepting the answer below and considering the question answered in the affirmative: Yes . Earlier Edit: It appears that the answer is ""yes,"" either by an already existent publication or by combining the Guo reference mentioned below with the answer here (and a remark on cycles admitting graceful labelings). But I have not been able to track down an accessible reference, and hope that someone can find one! Note: Perry Iverson points out that the graphs described below go by different names, and suggests an answer already exists in the literature. I am adding a reference-request tag in the hopes that someone can find a proof of the full characterization. According to Gallian's A Dynamic Survey of Graph Labeling ( pdf ), there is some work due to Wenfu Guo, who (from the citation below) is using notation similar to mine - even if they are called dragons rather than balloons . However , it is clear that the proof alluded to below is not bidirectional (or is mis-stated) since it discusses only the cases when the cycle is congruent to $1$ or $2$ (mod $4$), yet Leen Droogendijk's approach can be extended to gracefully label $B(n,k)$ whenever $n \equiv 0$ or $3$ (mod $4$); precisely the complementary cases! Moreover, the image from Wikipedia clearly shows a graceful labeling in which the cycle is congruent to $3$ (mod $4$). I will gladly accept an answer with an accessible version of the work by Guo (or by anyone else who has managed a characterization of such graphs). The wikipage on graceful labelings includes the following diagram: Quoting from the page: In graph theory, a graceful labeling of a graph with $m$ edges is a labeling of its vertices with some subset of the integers between $0$ and $m$ inclusive, such that no two vertices share a label, and such that each edge is uniquely identified by the positive, or absolute difference between its endpoints. Let us call a graph a balloon if it consists of an $n$-cycle with a single strand ( string ) emanating from one of the vertices in the aforementioned cycle. Furthermore, let us require the balloon component to have $n \geq 3$ vertices and the string component to have an additional $k \geq 1$ vertices; in such a case, we denote the balloon as $B(n,k)$. For example, the diagram above depicts $B(3,2)$, i.e.,  a balloon with a $3$-cycle (the vertices labeled $0, 4, 5$ make up the balloon component) and a length $2$ string (emanating from the vertex $0$). Fact: For all $k \geq 1$, the balloon $B(3,k)$ admits a graceful labeling. ( Proof: Left to reader.) Question: Which balloons admit graceful labelings? For example, can anyone prove that $B(4,k)$ admits a graceful labeling for all $k \geq 1$? Alternatively, can anyone come up with an $n \geq 3$ and $k \geq 1$ for which $B(n,k)$ does not admit a graceful labeling? A word of caution: The conjecture that all trees admit graceful labelings is a notoriously difficult open problem. (For a related MSE post, see here .) Ideally, I would wish for a full characterization of the gracefulness of balloons; however, I will certainly up-vote responses with non-trivial contributions (and may simply ""accept"" one, particularly if the question here can be transformed into one that implies the conjecture for trees).","['discrete-mathematics', 'trees', 'graph-theory', 'reference-request', 'problem-solving']"
844323,Basic Trigonometry Question,"If $\cos{(A-B)}=\frac{3}{5}$ and $\sin{(A+B)}=\frac{12}{13}$, then find $\cos{(2B)}$.
Correct answer = 63/65.
 I tried all identities I know but I have no idea how to proceed.",['trigonometry']
844380,distributivity of tensor product and direct sum for Hilbert spaces,"Before I ask my actual question about direct sums and tensor products of Hilbert spaces, let's first talk about direct sums and tensor products of vector spaces. We might define direct sums of vector spaces by the corresponding universal mapping property, but for later, it's more useful to work with a constructive definition. For a family $\{V_i\}_{i \in I}$ of vector spaces, we may define the direct sum $\bigoplus_{i \in I} V_i$ to be the set of all sequences $(v_i)_{i \in I}$ for which $v_i \in V_i$ for all $i \in I$ and $v_i = 0$ for all but finitely many $i \in I$, endowed with the component-wise vector addition $(v_i)_{i \in I} + (w_i)_{i \in I} = (v_i + w_i)_{i \in I}$ and the scalar multiplication $\alpha (v_i)_{i \in I} = (\alpha v_i)_{i \in I}$. I won't repeat the definition of the tensor product of vector spaces here. For the direct sum and the tensor product of vector spaces, it holds that the they are distributive in the sense that there is a canonical isomorphism 
\begin{align*}
  W \otimes \bigoplus_{i \in I} V_i \simeq \bigoplus_{i \in I} (W \otimes V_i) \,,
\end{align*}
where $w \otimes (v_i)_{i \in I} \mapsto (w \otimes v_i)_{i \in I}$, as explained, for example, in Theorem 5.4 in this document about tensor products . For Hilbert spaces, the direct sum explained above does not lead necessarily lead to Hilbert spaces since the (vector space) direct sum of infinitely many Hilbert spaces is not complete. Thus, for Hilbert spaces, one usually defines the direct sum as follows. For a family $\{H_i\}_{i \in I}$ of Hilbert spaces, we may define the direct sum $\bigoplus_{i \in I} H_i$ to be the set of all sequences $(v_i)_{i \in I}$ for which $v_i \in H_i$ for all $i \in I$, $v_i = 0$ for all but countably many $i \in I$ and $\sum_{i \in I} \Vert v_i \Vert^2 < \infty$, endowed with the component-wise vector addition $(v_i)_{i \in I} + (w_i)_{i \in I} = (v_i + w_i)_{i \in I}$ and the scalar multiplication $\alpha (v_i)_{i \in I} = (\alpha v_i)_{i \in I}$. The inner product on this space is given by $\langle (v_i)_{i \in I}, (w_i)_{i \in I} \rangle = \sum_{i \in I} \langle v_i, w_i \rangle$. For Hilbert spaces, the (vector space) tensor product does not necessarily lead to Hilbert spaces since the tensor product of infinite-dimensional Hilbert spaces is not complete. However, one may define the tensor product of two Hilbert spaces $H$ and $K$ to be the metric completion of the vector space tensor product with respect to the inner product $\langle v_1 \otimes w_1, v_2 \otimes w_2 \rangle = \langle v_1, v_2 \rangle \langle w_1, w_2 \rangle$ on $H \otimes K$. (See the Wikipedia article on tensor products of Hilbert spaces .) My question: For this ""Hilbert space direct sum"" and ""Hilbert space tensor product"", is there also a canonical isomorphism
\begin{align*}
  K \otimes \bigoplus_{i \in I} H_i \simeq \bigoplus_{i \in I} (K \otimes H_i)?
\end{align*} I know that the tensor product for Hilbert spaces fails to have the universal property (at least for continuous linear functions). Hence, if this would be needed in the proof of the distributivity, then distributivity fails.","['tensor-products', 'hilbert-spaces', 'functional-analysis', 'direct-sum']"
844426,True or False: The circumradius of a triangle is twice its inradius if and only if the triangle is equilateral.,"Let $R$ be the circumradius and $r$ be the inradius. The if part is clear to me. For an equilateral triangle, the circumcentre, the incentre and the centroid are the same point. So, by property of cebntroid $AG:GD=2:1\Rightarrow AG=2GD$. Thus $R=2r$. But is the converse true? Whether $R=2r$ implies that the triangle must be equilateral ? We know some relations involving circumradius and inradius, like $R=\dfrac{abc}{4\Delta}, r=\dfrac{\Delta}{s}$, where $\Delta$ is the area of the triangle and $s$ is its semi-perimeter i.e. $s=\dfrac{a+b+c}{2}$. But then how to show that the triangle is equilateral if $R=2r$. I would be thankful if anyone can help me.","['geometry', 'circles']"
844436,$\left(\sqrt{8}+\sqrt{2}\right)^2$ = 18 why??,"I would like to now why $$\left(\sqrt{8}+\sqrt{2}\right)^2$$ is equal to $18$? Please provide me
the proccess. Thank you.","['arithmetic', 'algebra-precalculus']"
844464,Interpretation of $p$-forms,"Let $M$ be a smooth manifold, let $C^{\infty}(M)$ be set of all smooth functions from $M$ to $\mathbb R$ and let $Vec(M)$ denote the set of all vector fields on $M$. A $1$-form on $M$ is a $C^{\infty}(M)$-module homomorphism from $Vec(M)$ to $C^{\infty}(M)$. Let us denote the set of all $1$-forms on $M$ by $\Omega^1(M)$. Then a $p$-form is defined to be an element of  $\bigwedge^p \Omega^1(M)$. What is the correct mathematically interpretation for the elements of $\bigwedge^p \Omega^1(M)$? The elements of  $\Omega^1(M)$ are just functions from $Vec(M)$ to $C^{\infty}(M)$. Are elements of $\bigwedge^p \Omega^1(M)$ also funtions? If what is their domain and codomains?","['differential-topology', 'differential-forms', 'differential-geometry']"
844468,How do I find this limit without using L'Hôpital's rule?,"Finding this limit using  L'Hôpital's rule is easy, but how to do it without using L'Hôpital's rule? $$\lim_{x \rightarrow 0} \frac{(1+\sin x)^{\csc x}-e^{x+1}}{\sin (3x)}$$","['calculus', 'limits']"
844471,Integral: $\int_0^\infty \tan^{-1}\left(\frac{2ax}{x^2+c^2} \right)\sin(bx) \; dx$,"Please help me in proving the following result: $$\displaystyle \int_0^\infty \tan^{-1}\left(\frac{2ax}{x^2+c^2} \right)\sin(bx) \; dx=\frac{\pi}{b}e^{-b\sqrt{a^2+c^2}}\sinh (ab)$$ I found this integral from here: http://integralsandseries.prophpbb.com/post2652.html?sid=d6641d4d4a3726f1b27bbb4b98ca840a and the solution uses contour integration. I am wondering if there is a way to solve it without using contour integration. I tried differentiating wrt $a$ and $c$ but in both cases, the resulting expression was dirty which made me reluctant to proceed further. I am out of ideas for this one. Any help is appreciated. Thanks!","['definite-integrals', 'calculus', 'integration']"
844478,Is the sequence $x_{n+1} = \frac{x_n + \alpha}{x_n + 1}$ convergent?,"Fix $\alpha > 1$, and consider the sequence $(x_n)_n \geq 0$ defined by $x_0 >  \sqrt \alpha$ and $$x_{n+1} = \frac{x_n + \alpha}{x_n + 1}, n = 0, 1, 2, \dots$$
  Does this sequence converge, and if, to what? I tried to get the difference between $x_n$ and $x_{n+1}$, it didn't work out. How do I go about solving it?","['recurrence-relations', 'calculus']"
844483,Drawing a nested epicycloid,"I would like to learn how to draw this kind of pictures (possibly with Mathematica, as it is the only language I would be comfortable to code such a thing in): There is something similar on the Wolfram website, involving nested ipo cycloids, but I would like to see the math involved in setting up the problem, not just the code. I have no idea what's the most intelligent way to proceed. Can you help me?","['geometry', 'fractals']"
844490,Spivak's Calculus - Chapter 5 Problem 8,"(For making things simple - everywhere where I've written ""$\lim f(x)$"" I meant $\lim_{x\to a} f(x)$) I'm trying to do this excercise: And apparently the answers in the answer book are yes, yes, no, no. I have not read explanations yet but I came to a different conclusion and need info whether my logic is flawed. So let's assume $f(x)$ is defined everywhere ""near"" $a$ and $g(x)$ is not (numbers near $a$ are not in the domain). That means $\lim g(x)$ does not exist. Then, clearly $\lim [f(x)+g(x)]$ exists and it's the same as $\lim f(x)$, same for $\lim f(x)g(x)$. So following this logic the answers should be yes, no, yes, no. But I think I might have done something that is not allowed when trying to solve the problem this way. Am I right?","['calculus', 'functions', 'limits']"
844507,Finitely many singular points of an irreducible polynomial,"let $k$ be a field, and consider an irreducible polynomial $f∈k[x,y]$. Let $S(f)$ denote the singular points of $f$ (points that are simultaneously zero on $f$, the $x$-derivative of $f$, and the $y$-derivative of $f$.) If $k$ is algebraically closed, How can I prove that $S(f)$ is finite? Thanks,
Alex",['algebraic-geometry']
844522,The index of the Core of a group,"I have to prove the following: Let $G$ be a group and $U$ be a subgroup of $G$. Then it holds:
If $U$ has finite index, then $\text{Core}_G(U):=\bigcap\limits_{g\in G}gUg^{-1}$ has also finite index. Would be nice if someone could give me some tips. Thanks!","['group-theory', 'group-actions']"
844524,How to prove this integral inequality?,"Here is a problem: Let $B_r=\{ (x_1,x_2,\cdots,x_n)\in \mathbb{R}^n: x_1^2+x_2^2+\cdots+x_n^2<r^2\}.$ Let $f$ be a $C^1$ real function on $B_2$. Prove that $$\inf_{a\in R}\int_{B_2} |f(x)-a|^2dx\leq C\sum_{j=1}^n \int_{B_2}\left|\frac{\partial f}{\partial x_j}\right|^2 dx\ \ \ \ (1)$$ for a constant $C$ independent of $f$. I think we can choose $a=f(0)$. If $$\int_{B_2} |f(x)-f(0)|^2dx\leq C\sum_{j=1}^n \int_{B_2}\left|\frac{\partial f}{\partial x_j}\right|^2 dx\ \ \ \ \  (2)$$ then we are done. But how to prove (2), I want to use mean value theorem, but failed.","['inequality', 'integration', 'partial-differential-equations', 'integral-inequality', 'real-analysis']"
844543,Where is my mistake $\iint_{Q} (x+y)^{2013}dxdy$,"I'm preparing for a calculus exam, and I tried to solve the following question. $Q$ is square $[-1,1]^2 \subset \mathbb R^2$ We are asked to evaluate $\iint_Q (x+y)^{2013}dxdy$ Here is what I did: $$\iint_Q (x+y)^{2013}dxdy = \int_{-1}^{1} \int_{-1}^{1} (x+y)^{2013}dxdy=\int_{-1}^{1}\frac{(x+y)^{2014}}{2014} |_{x=-1}^{1}dy$$ so overall after finishing with $dx$ we have: $$\frac{1}{2014} \int_{-1}^{1}(y+1)^{2014}-(y-1)^{2014}dy=\frac{(y+1)^{2015}-(y-1)^{2015}}{2015*2014} |_{y=-1}^{1} $$ But note that $$2^{2015}-0^{2015}-0^{2015}+(-2)^{2015}=2^{2015}-2^{2015}=0$$ so the entire double integral is equal to zero. However, when I check my answer in wolfram alpha, wolfram says that this integral is equal to $9.27057*10^{599}$ I'm just wondering where is my mistake? Or perhaps wolfram alpha gave the wrong answer because of a numerical error.","['multivariable-calculus', 'calculus', 'integration']"
844555,Find $\lim_{n\to\infty}\left(1+\dfrac{1}{n}\right)\left(1+\dfrac{1}{2n}\right)\ldots\left(1+\dfrac{1}{2^{n-1}n}\right)$,Find $\displaystyle\lim_{n\to\infty}\left(1+\dfrac{1}{n}\right)\left(1+\dfrac{1}{2n}\right)\left(1+\dfrac{1}{4n}\right)\ldots\left(1+\dfrac{1}{2^{n-1}n}\right)$. (This is not my homework. One of my friends gave this to me.),['calculus']
844570,Poisson equation on a square,"Studying PDEs from the notes of my professor, and there's a part I don't understand about seeking a solution for the Poisson equation on a square. Let's start from the beginning though. We want to solve the problem 
$$\begin{cases}
 &\nabla^2u=F(x,y) \\ 
 &u(x,0)=a(x) \\ 
 &u(\pi,y)=b(y) \\ 
 &u(x,\pi)=c(x) \\ 
 &u(0,y)=d(y) 
\end{cases}$$
By linearity, we can solve 5 problems distinctly. Among these 5 problems, there's the ""seeking a solution for the nonhomogeneous equation"". At one point, it says on the notes: We can write $F(x,y)$ as $\sum F_n(y)X_n(x)$, where $X_n(x)$ satisfies the equation $X_n''(x)=-\lambda X_n(x)$. I know he wants to solve it using Lagrange's method, but I don't quite understand why $F(x,y)$ can be written that way. Anyone?","['poissons-equation', 'multivariable-calculus', 'partial-differential-equations', 'real-analysis']"
844575,Epic-monic factorisation in $\mathbf{Set}$.,"I'm stuck on Exercise 5.2.1 of Goldblatt's "" Topoi: A Categorial Analysis of Logic "": Given a function $f:A\to B$ , if $h\circ g: A\twoheadrightarrow C\rightarrowtail B$ and $h'\circ g': A\twoheadrightarrow C'\rightarrowtail B$ are two different epic-monic factorisations of $f$ (i.e. $f=h\circ g=h'\circ g'$ ), then there exists a unique $k:C\to C'$ such that commutes, and furthermore $k$ is iso in $\mathbf{Set}$ . The rest of the section seems okay. It gives a categorical proof in any topos. However, I'd like a set-theoretic proof please . I've tried defining $k: C\to C'$ by way of equivalence classes; namely, by letting $k(c)=g'(\gamma)$ for some $\gamma$ with $c=g(\gamma)$ , so that since $g$ in onto, I can iron out any ambiguity by saying $\gamma\sim_{g}\delta$ iff $g(\gamma)=g(\delta)$ , then go from there. (Do you see what I mean?) I can't get it to work. Please help :)","['alternative-proof', 'category-theory', 'elementary-set-theory']"
844576,Topological Vector Space: $\dim V=n\implies V\cong\mathbb{K}^n$,"Let $V$ be a finite dimensional Hausdorff topological vector space. Prove that it is is isomorphic to the Euclidean vector space of the same dimension:
$$\dim V=n\implies V\cong\mathbb{K}^n$$","['topological-vector-spaces', 'functional-analysis']"
844577,Axiom of Pairing,"Axiom of Pairing states that if $a,b$ are sets, $\exists$ a set $A$ such that $A=\{{a,b\}}$. My question is that why we can't use Axiom of specification to define $A=\{x|x=a \vee x=b\}$?","['axioms', 'elementary-set-theory']"
844591,Topology of test functions $\mathcal{D}(\mathbb R)$,"(My motivation for the following question is to understand the distribution theory) The space of test functions : $\mathcal{D}(\mathbb R)= \{\phi:\mathbb R \to \mathbb R : \phi \in C^{\infty}(\mathbb R), \ \text{and support of }\  \phi \ \text{is compact} \}.$
Let us introduce the norms,
$$\|\phi\|_{N}=\text{max} \{|D^{\alpha}\phi(x)|: x\in \mathbb R, |\alpha| \leq N \}$$
for $\phi \in \mathcal{D}(\mathbb R)$ and $N=0,1,2,...$. My Question : (1) How to use these norms to define locally convex metrizable topology on $\mathcal{D}(\mathbb R)$ ? (2) This topology is not complete; but I don't understand the reason; Pick $\phi \in \mathcal{D}(\mathbb R)$ with support in $[0,1], \phi>0$ in $(0,1),$ and 
  define, 
  $$\psi_{m}(x)=\phi(x-1)+\frac{1}{2}\phi(x-2) +...+\frac{1}{m}\phi(x-m);$$
  so, my sub-question is:
  (a) How to verify $\{\psi_{m}\}$ is a Cauchy sequence in $\mathcal{D}(\mathbb R)$ ? (b) How to verify $\lim \psi_{m}$ does not have a compact support ? I want to add one more question to it i.e. If $\Omega\subset_{open} \mathbb R^n$ and the norms are defined by
$$\|\phi\|_{N}=\text{max} \{|D^{\alpha}\phi(x)|: x\in \mathbb \Omega, |\alpha| \leq N \}$$ for $\phi\in\text D(\Omega) \ \text{instead of}\ \text D(\mathbb R)$ then how to show that the metrizable topology on $\text D(\Omega)$ is not complete. Thanks.","['distribution-theory', 'functional-analysis', 'proof-verification', 'analysis']"
844601,"Solution to Schrödinger equation $ \partial_t f(x,t) = -\partial_x^2 f(x,t) + \delta(t)V(x)f(x,t).$","I want to solve 
$$ i\partial_t f(x,t) = -\partial_x^2 f(x,t) + \delta(t-t_0)V(x)f(x,t),$$ for any $V \in C^{\infty}[-1,1]$ and $f: [-1,1] \times \mathbb{R_{\ge 0}} \rightarrow \mathbb{C}$. I would consider this to be solved if I have one/two ODEs that just depend on either $x$ or $t$ (or an integral transform etc.). My boundary conditions shall be taken such, that I specify a $f(.,0)$ for some $t_0 \in \mathbb{R}$. and look how this solution propagates under this ODE. The other boundary conditions shall be time-independent. I also noticed that this equation is similar to many diffusion equations and found a similar differential operator here at http://en.wikipedia.org/wiki/Green%27s_function#Table_of_Green.27s_functions This question is a particular example of my unsolved question here: https://math.stackexchange.com/questions/843106/solve-pde-by-getting-two-odes","['ordinary-differential-equations', 'partial-differential-equations', 'real-analysis']"
844603,Show that $\lim_{x \rightarrow 1} \frac{x^4-2x+1}{x-1} + \sqrt{x} =3$,"Show that $\lim_{x \rightarrow 1} \frac{x^4-2x+1}{x-1} + \sqrt{x} =3$ from the definition (using $\epsilon-\delta$) Why can't I do something like this? We want: $|\frac{x^4-2x+1}{x-1} + \sqrt{x}-3| = |\frac{x^4-2x+1}{x-1} + \frac{x-9}{\sqrt{x}+3}| \le |\frac{x^4-2x+1}{x-1}| + |\frac{x-9}{\sqrt{x}+3}| \le |x^3+x^2+x-1| + |x-9| \le |x|^3 + |x|^2+|x-1| + |x-9| < \epsilon$ Now suppose $|x-1| < 1$, then $|x|\le 2$ and $|x-9| \le 9$, so $$|x|^3 + |x|^2+|x-1| + |x-9| < 2^3+2^2+9+|x-1| < \epsilon$$ Now take $\delta = \min\{1, \epsilon -21\}$. But this clearly is wrong because $\delta$ needs to be positive for every $\epsilon>0$, what part of my working is incorrect? (I know how to get the answer properly, just wondering why this way is incorrect, I'm quite new to $\epsilon-\delta$ proofs)","['self-learning', 'real-analysis', 'limits']"
844622,Dirac delta distribution and measure?,"Of course the Dirac delta is not a function. Despite, I think the concept of a measure is much easier than that of a distribution. Therefore, I was wondering: In what sense is the concept of a Dirac distribution equivalent to the Dirac measure? Are you (in principle) able to prove all the properties of the distribution if you are using the concept of a measure? Or is the only thing that the Dirac delta measure is good for to say: $$\int_{\mathbb{R}} f(x)\delta(x-x_0) d\mu(x):= \int_{\mathbb{R}} f(x)d\delta_{x_0}=f(x_0)?$$ Or differently: Would this definition be an appropriate definition? Or do we have to refer to the theory of distributions to prove all the properties that the Dirac-delta has?","['measure-theory', 'distribution-theory', 'real-analysis', 'lebesgue-measure', 'functional-analysis']"
844706,Is there a(n elementary) function whose derivative we cannot integrate?,"Say, for example, I take a reasonably-complicated function $f(x)=\tanh[\ln(x^x)]$, and differentiate it to get $$f'(x)=\frac{4x^{2x}
[1+\ln(x)]}{(x^{2x}+1)^2}.$$ Now, to integrate this, I imagine, would be very difficult and time-consuming. My question is: does there exist a function $f$ whose derivative $f'$ we can't integrate (without differentiating $f$ in the first place), using substitution, parts and/or partial fractions (or other integration methods)? My motivation for this is that it's very easy to differentiate even a ridiculously-complicated function (using the chain and/or product rule), but I've often wondered whether we could get back to the original function by integrating this derivative. If I'm not articulating myself clearly enough, please ask me to explain further. Thanks! Edit I know, from the Fundamental Theorem of Calculus, that such a function can be integrated, but, other than knowing the fact that this is the derivative of a suitable function, could it be impossible to reverse-engineer the problem, to get $f'$ back to $f$ (using only methods of integration)?","['calculus', 'soft-question']"
844748,Notation for matrix and sum of matrix rows,"I have a table that describes the influence of sources (columns) on sinks (rows)
where rows=$(A,B,C)$ and columns=$(A,B,C,D,E)$. So my table looks like: | A | B | C |
A | 1 | 2 | 4 |
B | 2 | 1 | 1 |
C | 2 | 3 | 1 |
D | 1 | 4 | 2 |
E | 1 | 1 | 1 | If I would like to describe that table in matrix terminology how would I do that?
And how are the columns and rows called? What is the correct notation if I
want to describe the sum of rows (like the first row $A$ which is $7$). I'd also like
to find a way to describe (sum of row)-(autoinfluence where i=j, main diagonal) e.g. row $A$ - (cell $AA$). As a very unprofessional start: $$\text{Matrix: } X = (x_{ij})$$
$$\text{where } i = (A,B,C,D,E) \text{ and } j=(A,B,C)$$
$$\text{row sum: } R = \sum_{i=1}^{N}(x_{ij}) = (1,1,...,1)X$$
$$\text{my value: } V = (1,1,...,1)X - X \text{ (where } i=j) = (1,1,...,1)X \text{ (where } i\neq j) $$ I need to describe that table and these desired values in professional looking way in 'ij' or matrix terminology for a scientific paper.","['notation', 'matrices']"
844756,History of $p$-adic numbers,"I'm interested in learning about the historical motivation and development of $p$-adic numbers. I haven't been able to find any books on the topic. I'd appreciate any references, including to more general history books which include coverage of the $p$-adics. Alternatively, if anyone has any knowledge about the history of $p$-adic numbers, feel free to post a summary here, particularly if you can highlight any names, papers and keywords that I could use to do more research on my own. I'm not looking for a simplified overview, I want to really dig into the details, but any amount of information that could get me started is appreciated.","['p-adic-number-theory', 'math-history', 'reference-request', 'number-theory']"
844757,Show that $Y$ is not path-connected,"Let $\mathbb{R}^2$ with the usual topology and let $$ Y = A_0 \cup (\bigcup_{n \in \mathbb{N}} A_n) \cup (\bigcup_{n \in \mathbb{N}}L_n)$$ where $$ A_0 = \{ 0 \} \times [0,1] \qquad A_n =  \{ {\dfrac{1}{n}} \} \times [0,1]  \qquad \textrm{and $L_n$ is the segment between $(\dfrac{1}{n},1)$ and $(\dfrac{1}{n+1},0)$}$$ I need to show that $Y$ is not path-connected. My intuition is that there cannot be any continuous function $f:[0,1] \to Y$ such that (for example) $f(0) = (0,0)$ and $f(1) = (1,1)$ because it is not going to be continuous at $(0,0)$ , but I cannot prove that formally.","['general-topology', 'connectedness', 'continuity', 'path-connected']"
844796,Why does this determinant have a continuous density at zero?,"This question is a simplification of my previous question . I think this is easy, but I don't have a strong enough background in probability. Let $A$ be a random $n\times n$ real matrix that satisfies the following rules: All entries $A_{ij}$ are standard Gaussians, with mean $0$ and variance $1$. Furthermore, they are jointly normally distributed. The matrix is symmetric, that is $A_{ij} = A_{ji}$. Any two entries on the diagonal, $A_{ii}$ and $A_{jj}$ (where $i \ne j$), are correlated, and their covariance is positive and constant (that is, the same for any pair $i, j$). Any two entries in the matrix that weren't covered by the previous two rules are uncorrelated. Since they are jointly normal, the above rules describe the distribution of $A$ completely (am I correct?). My question concerns the distribution of the determinant, $\det A$: I need to prove it has a bounded density near $0$. That is, for all small enough $\epsilon>0$, $$\mathbb{P}\left\{|\det A| \le \epsilon\right\} \le M\epsilon$$ for some constant $M$. (For example, if $n=2$ and $A = \left(\begin{smallmatrix}X&X\\X&X\end{smallmatrix}\right)$ where $X$ is a standard Gaussian then this would be false. But this example violates the 4th rule.) Any help will be appreciated!","['normal-distribution', 'random-matrices', 'probability']"
844818,Is the sum of all natural numbers countable?,"I do not even know if the question makes sense. The point is rather simply. If I have the sum of all natural numbers, $$\sum_{n\in \mathbb{N}}n$$ this is clearly ""equal to infinity"". But since almost a century ago, we know that there are (a lot of) different ""infinities"". So, is this sum equal to something countable or something bigger? I tried to look for references, but couldn't find anything and, since I am not an expert in Logic, Set Theory or Foundations of Mathematics, I thought that it would be good to ask here. Thanks in advance,
Davide PS: This question is about sum of cardinals. It is not about Calculus.","['cardinals', 'elementary-set-theory']"
844885,Problem I.3.18 in Hartshorne,"Problem I.3.18b-c in Hartshorne is concerned with the surface $Y$ of $\mathbb{P}^3$ given parametrically by $(x,y,z,w) = (t^4,t^3u,tu^3,u^4)$. In particular, part c asks to prove that $Y$ is isomorphic to $\mathbb{P}^1$. I did check two different solutions available online, and they both claim that $Y$ is the image of the $4$-tuple embedding of $\mathbb{P}^1$. However, the $4$-tuple embedding takes $\mathbb{P}^1$ into $\mathbb{P}^4$ and not $\mathbb{P}^3$. This is not the case with $Y$, since there is one monomial term missing, i.e. $t^2u^2$. So i wonder what is a rigorous argument for showing that $Y$ is isomorphic to $\mathbb{P}^1$.",['algebraic-geometry']
844886,Blocks in permutation group theory (D&F),"I want to solve the following exercise from Dummit & Foote's Abstract Algebra text: Let $G$ be a transitive permutation group on the finite set $A$. $A$ block is a nonempty subset $B$ of $A$ such that for all $\sigma \in G$ either $\sigma(B)=B$ or $\sigma(B) \cap B= \emptyset$ (here $\sigma(B)$ is the set $\{\sigma(b)\, |\,b \in B\} $). (a) Prove that if $B$ is a block containing the element $a$ of $A$, then the set $G_B$ defined by $G_B=\{\sigma \in G\, | \, \sigma(B)=B\}$ is a subgroup of $G$ containing $G_a$. (b) Show that if $B$ is a block and $\sigma_1(B),\sigma_2(B),\dots,\sigma_n(B)$ are all the distinct images of $B$ under the elements of $G$, then these form a partition of $A$. (c) A (transitive) group $G$ on a set $A$ is said to be primitive if the only blocks in $A$ are the trivial ones: the sets of size 1 and $A$ itself. Show that $S_4$ is primitive on $A=\{1,2,3,4\}$. Show that $D_8$ is not primitive as a permutation group on the four vertices of a square (d) Prove that the transitive group $G$ is primitive on $A$ if and only if for each $a \in A$, the only subgroups of $G$ containing $G_a$ are $G_a$ and $G$ (i.e., $G_a$ is a maximal subgroup of $G$, cf. Exercise 16, Section 2.4). [Use part (a).] This is my attempt: (a) Suppose $\sigma,\tau \in G_B$, the equality $\sigma(B)=B$ gives $B=\sigma^{-1}(B)$, and acting on this by $\tau$ gives 
\begin{equation}
B=\tau(B)=\tau(\sigma^{-1}(B))=(\tau \circ \sigma^{-1})(B),
\end{equation}
so $G_B \leq G$. Moreover, if $\sigma \in G_a$ fixes $a \in B$ then $\sigma(B) \cap B \supseteq \{a\}$. Since $B$ is a block the only option is $\sigma(B)=B$. This gives $G_a \subseteq G_B$. (b) We first prove that the images $\sigma_i(B)$ are disjoint. For suppose $\sigma_i(B) \cap \sigma_j(B)$ is nonempty for $i \neq j$. Acting on this with $\sigma_i^{-1}$ gives that the intersection $B \cap (\sigma_i^{-1} \circ \sigma_j)(B)$ is nonempty. Since $B$ is a block we must have that $(\sigma_i^{-1} \circ \sigma_j)(B)=B$. Acting on this with $\sigma_i$ gives $\sigma_i(B)=\sigma_j(B)$ which is a contradiction, since the images are known to be distinct. We also need to show that the union of these images is $A$. Suppose by way of contradiction that there is some $a \in A$ with $a \notin \bigcup_{i=1}^n \sigma_i(B)=\bigcup_{\sigma \in G} \sigma(B)$. Since $G$ is transitive, we can find a permutation sending some $b \in B$ to $a$. It follows that $\sigma_0(B) \supseteq \sigma_0(\{b\})=\{a\}$, which is a contradiction. (c) We prove that there are no blocks $B$ of order 2. Suppose $B=\{i,j\}$ is such a block (and the remaining elements are $k,l$). The permutation $(i \; k)$ shows $B$ is not a block. We also prove that there are no blocks of order 3. Suppose $B=\{i,j,k\}$ is such a block. The permutation $(i \; l)$ shows that $B$ is not a block. Thus the only possible orders for a block $B \subseteq A=\{1,2,3,4\}$ are 1 or 4, and $S_4$ is primitive on $A$. Since $D_8$ acts on the set of unordered pairs of opposite vertices, we have that such a pair (for example $B=\{1,3\}$) is a block. This is because for any $g \in D_8$ we either have $g \cdot \{1,3\}=\{1,3\}=B$ or $g \cdot \{1,3\}=\{2,4\}$ is disjoint with $B$. (d) We prove both implications: Suppose for each $a \in A$, the only subgroups of $G$ containing $G_a$ are $G_a$ and $G$, and let $B \subseteq A$ be a block, and let $b$ be a point in that block. Part (a) establishes $G_B$ as a supergroup of $G_b$, and hence gives two possible cases: $G_B=G$. In that case, we claim that $B=A$, for if $B \subsetneq A$ there is some $b' \in B \setminus A$. Since $G$ is transitive, there is some permutation $\sigma \in G$ sending $b$ to $b'$. But that permutation doesn't fix $B$, which is a contradiction. $G_B=G_b$. In that case I don't know what to do... The reverse implication should be here someday... I now have several questions: Is my proof of parts (a),(b),(c) correct? Is it necessary that the set $A$ is finite? So far I didn't have to use that even once. Could anyone please help me fill in the rest? I found a solution here , but the third section from the end seems flawed to me... Thank you!","['permutations', 'group-theory', 'abstract-algebra']"
844917,Will antiderivative always be differentiable?,"Suppose f(x) is continuous on [0,1]. Obviously, such a function will be integrable. Will antiderivative be always differentiable on (0,1)? The answer is ""Yes"" by the Fundamental Theorem of Calculus. But what if f(x) is not continuous, can it still be integrable but have non-differentiable antiderivative? What confuses me is that I always thought about integrand as the derivative of an antiderivative. So if we find a non-differentiable antiderivative, how can we relate it back to the integrand?","['derivatives', 'integration', 'real-analysis']"
844929,Determining a group $G$ by looking at the number of homomorphisms $H\to G$,"I read somewhere that, given a finite group $G$, its structure is completely determined
from the knowledge of the values of $|\{H\to G\}|$ (the number of homomorphisms from $H$ to $G$) as $H$ varies over all finite groups. This has a nice corollary: if $G\times G\cong G'\times G'$ then $G\cong G'$. How does one prove the first assertion? If the proof is not hard, I'd prefer an answer in form of a (series of) hint(s).","['finite-groups', 'group-theory']"
844973,Why is $L_A$ not $\mathbb K$ linear (I can prove that it is),"Let $\mathbb K$ denote the skew field of quaternions and $A \in M^{n \times n}(\mathbb K)$ and $X\in M^{1\times n}(\mathbb K)$. Let $L_A : \mathbb K^n \to \mathbb K^n$ be defined as $L_A(X) = (AX^T)^T$. $L_A$ is supposedly not $\mathbb K$ linear. But I can prove that it is. Like so: $$ \begin{align}L_A(aX + bY) &= (A(aX + bY)^T)^T =(A(aX^T + bY^T))^T\\
&=(aX^T + bY^T)^TA^T = (aX + bY)A^T \\
&= aXA^T + bYA^T = a(AX^T)^T + b(AY^T)^T \\
&= aL_A(X) + bL_A(Y)
\end{align}$$ Why is this proof wrong?","['matrices', 'linear-algebra']"
844987,In a tournament $n$ players take part in a series of duels,"I've recently been thinking about this problem and I think I solved it correctly. However, I was using a rather peculiar method with lots of algebra. I'll post my solution as an answer below. Is there a better (or just different) way of solving this problem? Problem In a tournament $n$ players take part in a series of duels in which both players have equal chances of winning. After each duel the winner plays against the player, that hasn't played for the longest time (or in the beginning someone that hasn't played yet). The first player to beat all other players in consecutive duels wins the tournament. What is the probability that a player wins the tournament given that he takes part in the first duel? An example with $n=3$ Alice and Bob start and Colin sits out first.
Alice beats Bob, Colin beats Alice, Bob beats Colin, Bob beats Alice. Bob wins the tournament. Here Alice, Bob and Colin had winning probabilities $\frac{5}{14}$, $\frac{5}{14}$, $\frac{4}{14}$ respectively. EDIT: Only 3 days left for the bounty. We don't want those points to disappear into nirvana, do we? :(","['markov-chains', 'probability']"
844995,Inequality for harmonic means,"Prove that for real numbers $a_1 ,a_2 ,...,a_n >0$ the following inequality holds
$$\frac{1}{a_1 } +\frac{2}{a_1 +a_2 } +...+\frac{n}{a_1 +a_2 +...+a_n }\leq 4\cdot \left(\frac{1}{a_1} +\frac{1}{a_2 } +...+\frac{1}{a_n} \right).$$","['inequality', 'real-analysis']"
845018,Which sets occur as boundaries of other sets in topological spaces?,"Which sets occur as boundaries of other sets in topological spaces? Of course the boundary of a set is closed. But is every closed set in a topological space, the boundary of some set in that space? It is tempting to assert that boundaries have empty interiors, but this is not true, as is shown by the fact that the boundary of $\mathbb{Q}$ in $\mathbb{R}$ is $\mathbb{R}$. In fact it can be seen in general that the boundary of a dense set with empty interior is the whole space. Thus the only boundary in an indiscrete space is the whole set. (This is sort of complementary to the comment of Daniel Fischer below.) However the intuitive feeling comes right for open sets (and then for closed sets as well): The boundary of an open set cannot contain an open set. This question concerns all subsets of a topological space. An alternative question shall be to characterise all topological spaces in which every closed set occurs as a boundary. Note: I have now asked this on MathOverflow.",['general-topology']
845031,Functional equation and fixed points,"Let $f$ be strictly increasing and such that $f(x)+f^{-1}(x)+1=e^x$. Is it true that $f$ has at most one fixed point? I am told the answer is yes, but I am having trouble proving it. It's obvious that it must have at most two, but why can it not have two?","['calculus', 'real-analysis', 'functional-equations']"
845035,How to solve $\frac{dy}{dx} = \frac{x^2-y^2}{x^2(y^2+1)}$,I tried to solve this using the solution of a first order differential equation but I don't think this can be reduced to that form. How to approach this problem and find $y$? Please help.,['ordinary-differential-equations']
845043,What is the probability of a specific sequence of 11 digits occurring in a random sequence of one billion digits?,"This isn't homework, I'm actually (please don't ask me why) wondering how likely it is that any particular 11-digit telephone number will occur in the first billion digits of pi. My probability course was way too long ago, and the idea of creating a monte carlo simulation to figure this out seems a little extreme! (And I realize that pi is not a random number, I'm just assuming that the digits are sequenced in a randomlike way.)","['pi', 'probability', 'random']"
845054,Taking product of cofactor with different row,"Given a matrix $A=(a_{ij})_{n\times n}$, let $C_{i,j}$ be the cofactor in position $(i,j)$. By the determinant formula, we have $$\det A=\sum_{i=1}^n a_{i,1}C_{i,1}.$$ What about if we take a different column for the cofactors, that is $$\sum_{i=1}^n a_{i,1}C_{i,2}$$ Must this evaluate to zero?","['linear-algebra', 'determinant']"
845124,Find $f$ such that $\frac{\mathrm d^2}{\mathrm dx^2}f(x)=f\left(\sqrt{x}\right)$.,"Which non-constant functions $f$ (if any) satisfy $\dfrac{\mathrm d^2}{\mathrm dx^2}f(x)=f\left(\sqrt{x}\right)$ for $x>0$ ? I suspect there is no $f$ which satisfies the differential equation, but I cannot prove this.","['ordinary-differential-equations', 'calculus', 'functional-equations']"
845133,"Show independence of $(aX,bX^2)$, $\,X\sim N(0,\sigma^2)$?","How can we proof that $aX,bX^2$ are independent iff $b\cdot a=0$, when $\,X\sim N(0,\sigma^2)$? I found that $X^2$ is Chi-Square distributed, and the correlation is: $$\rho(bX,aX^2)=ba\rho(X,X^2)=ba\dfrac{\mathrm{Cov}(X,X^2)}{ \sigma_X \sigma_{X^2}} =ba\dfrac{E[(X-\mu_X)(X^2-\mu_{X^2})]}{ \sigma_X\sigma_{X^2}}\stackrel{!}{=}0$$
So we have $\rho=0$ when $ba=0$, but as we know, $\rho=0$ does not directly imply independence in general. We may need to argue why it does here, or use some other dependence measure to show independence.",['probability-theory']
845143,27 lines on a smooth cubic surface,"It is known that every smooth cubic surface with coefficients in $\mathbb{Q}$
has $27$ lines defined over a number field extension of $\mathbb{Q}$ of degree at most $51840$ as the group $\operatorname{Gal}(\overline{\mathbb{Q}}/\mathbb{Q})$ acting on the lines is a subgroup of the Weyl group $W(E_6)$ which has order $51840$. I was wondering if a similar argument can prove the existence of an absolute constant $c$ such that whenever a smooth cubic surface has coefficients in a number field $K$ then all $27$ lines are defined in a number field extension $L$ of $K$ of degree at most $[L:K]\leq c.$","['algebraic-geometry', 'algebraic-number-theory', 'number-theory']"
845166,Evaluate the limit $\lim_{t\rightarrow\infty}\left(te^t\int_t^{\infty}\frac{e^{-s}}{s}\text{d}s\right)$,"$$\lim_{t\rightarrow\infty}\left(te^t\int_t^{\infty}\frac{e^{-s}}{s}\text{d}s\right)$$
I have no idea where to start. Any help will be appreciated!","['indefinite-integrals', 'real-analysis', 'limits']"
845196,Geometric interpretation of Laplace's formula for determinants,"Coming from the geometric point of view, the determinant of an $n \times n$-Matrix computes the volume of an parallelepiped spanned by the columns of the matrix. In context of this question, let the determinant be defined by Laplace's formula and let us assume that we use the Laplace expansion along the first column of the matrix. In case of a $2\times 2$-matrix of the form $M=\begin{pmatrix} a & c\\ b & d\end{pmatrix}$, the expansion is quite intuitive: One takes $a$ - which can be seen as the projection of the vektor $\begin{pmatrix} a \\ b \end{pmatrix}$ onto the $e_1$-axis - and multiplies it with $d$, which can be seen as the projection of the vector $\begin{pmatrix} c \\ d \end{pmatrix}$ onto the $e_2$-axis. So it's the base $\times$ height-formula which would be correct if $b=0$. If $b \neq 0$, the error which is made is exactly $c \cdot d$, again by a base $\times$ height-formula, which one can check with the help of a figure by Salomon Golomb, which I found here: Why determinant of a 2 by 2 matrix is the area of a parallelogram? I hoped to transfer this principle to $3 \times 3$-matrices.
I considered the parallelogram spanned by the 2nd and the 3rd column of a $3 \times 3$-matrix. Keeping Laplace's formula in mind, the first entry of the first column is multiplied with the area of the projection of the parallelogram onto the $e_2$-$e_3$-plane, the second entry is multiplied with the area of the projection onto the $e_1$-$e_3$-plane and the third entry is multiplied with the area of the projection onto the $e_1$-$e_2$-plane. (That is, $\det(a,b,c)= c\cdot (a\times b)$). I tried to give an geometric sense to this calculations mimicking what was done in Golomb's figure but I failed. Sure, there is a way to rearrange the three sets to conclude that actually the volume of the parallelepiped was computed but again I would not understand why. Is the anyone who knows a way to interprete Laplace's formula geometrically? I think there might be a way which uses the projections of the parallelogram which I mentioned above... I would be very thankful for all other (geometric) interpretations, too! Ole","['geometry', 'linear-algebra', 'differential-geometry']"
845203,Differentiation of a function $f:\mathbb{Q}\to \mathbb{Q}$(Rational Calculus),"Assume that $f:\mathbb{Q}\to \mathbb{Q}$ is  given such that $\forall   a\in \mathbb{Q}$ the following limit, exists \begin{equation}
\lim_{x\to a}  \frac{f(x)-f(a)}{x-a}\in \mathbb{R}
\end{equation} Is it true  to say that the above limit is  a rational number?","['calculus', 'derivatives', 'functions', 'rational-numbers']"
845207,Linear algebra calculus trick.,"I have a matrix and a vector:
$$
A=\begin{bmatrix}
a &b\\
c&d
\end{bmatrix},
$$ $$
\vec v=\begin{bmatrix}
a+b\\
c+d
\end{bmatrix}
$$ Is there an algebraic operation that produce the following matrix: $$
B=\begin{bmatrix}
\dfrac{a}{a+b} &\dfrac{b}{a+b}\\
\dfrac{c}{c+d} &\dfrac{d}{c+d}
\end{bmatrix}?
$$","['matrices', 'linear-algebra', 'algebra-precalculus']"
845222,Cross ratio and symmetric points exercise,"Problem Let $C$ be a circle or a line belonging to $\overline{\mathbb C}$ and let $z_2,z_3,z_4$. Two points $z$ and $z^*$ are said to be symmetric with respecto to $C$ if $\overline{(z,z_2,z_3,z_4)}=(z^*,z_2,z_3,z_4)$. $(i)$ Prove that the previous definition doesn't depend on the chosen points $z_2,z_3,z_4 \in C$ but of $C$. $(ii)$ Prove that for each $z \in \overline{\mathbb C}$ there is a unique symmetric point $z^*$ with respect to $C$. The function that assigns to each $z$ its correspondent $z^*$ with respect to $C$ is called symmetry with respect to $C$. Show that for each Möbius transformation $T$ which maps $\overline{\mathbb R}$ to $C$, the function $$T \circ \overline{T^{-1}}:\overline{\mathbb C} \to \overline{\mathbb C}$$ is the symmetry with respect to $C$. My attempt $(i)$ Let $C$ be a circle centered at $c$ of radius $R$ Using invariance of cross ratio under Möbius transformations, and using that $z_i-c=R$ for $i=2,3,4$ and $z\overline{z}=|z|^2$ we get $$\overline{(z,z_2,z_3,z_4)}=\overline{(z-c,z_2-c,z_3-c,z_4-c)}=(\overline{z}-\overline{c},\overline{z_2-c},\overline{z_3-c},\overline{z_4-c})=(\overline{z}-\overline{c},\dfrac{R^2}{z_2-c},\dfrac{R^2}{z_3-c},\dfrac{R^2}{z_4-c})=(\dfrac{R^2}{\overline{z}-\overline{c}},z_2-c,z_3-c,z_4-c)=(\dfrac{R^2}{\overline{z}-\overline{c}}+c,z_2,z_3,z_4)$$ So if $C$ is a circle, from this equation one deduces the dependence only on $C$. $(ii)$ If $C$ is a circle, from the formula $z^*=\dfrac{R^2}{\overline{z}-\overline{c}}+c$ it follows the uniqueness of $z^*$. I need help to show $(i)$ and uniqueness of $C$ if $C$ is a line. I also don't know what to do to show that $T \circ \overline{T^{-1}}:\overline{\mathbb C} \to \overline{\mathbb C}$ is the symmetry with respect to $C$, I would appreciate any suggestions.","['complex-numbers', 'complex-analysis']"
845257,Determinant and trace as conjugations?,"For real matrices $A$ it holds that $$\det\,\big(e^A\big)=e^{\mathrm{tr}\,A}$$ so we can write $$\mathrm{tr}=(\exp)^{-1}\circ \;\det\;\circ\;(\exp).$$ Is this interpretation of trace as the ""conjugate"" of the determinant under the exponential map used anywhere, or useful for anything? It seems neat but I have not come across it before. Edit: note that the $(\exp)$ on the left (of which an inverse is taken) is the natural logarithm $\ln$ for real numbers, not for matrices (I think!) because it is applied after finding the determinant.","['trace', 'matrices', 'linear-algebra', 'determinant']"
845265,"What is the distribution of $|X-Y|$ if both $X$ and $Y$ are $U(0,1)$?","I am trying to find the distribution of $Z = |X-Y|$ if both $X$ and $Y$ are uniform over $(0, 1)$ and independent. The answer I am getting is very close to the one given but I can't figure out why they're different at all. My method is as follows: $$
Z = \left\{\begin{aligned}
&X-Y &&\text{if }  X \ge Y \\
&Y-X &&\text{if }  X \lt Y \\
\end{aligned}
\right.$$ If $Z = X - Y$ then $Y = X-Z$ and so $$f_z = \int_a^bf_x(x)f_y(x-z)dx $$ To determine $a$ and $b$:
$$0 \le x \le 1 \text{ and } z \le x \le 1+z$$ Since $Z$ is always bigger  than 0, the bounds for the integral are $z$ and $1$. $$f_z = \int_z^1dx = 1-z$$ Repeating the same process for $Z = Y-X$, $$f_z = \int_a^bf_x(x)f_y(x+z)dx$$
$$0\le x \le 1 \text{ and }-z \le x \le 1-z $$ Again since $Z$ is always positive, the integral becomes $$f_z = \int_0^{1-z}dx = 1-z$$ Putting everything together, $$
f_z = \left\{\begin{aligned}
&1-z &&\text{if }  X \ge Y \\
&1-z &&\text{if }  X \lt Y \\
\end{aligned}
\right.$$ ...or just $1-z$. However the answer provided states that $f_z = -2(z-1)$, which is just $2$ times what I have. Where did I go wrong? Thanks!","['statistics', 'probability']"
845271,is it necessary that curl of 2d vector is perpendicular to the plane.,"I am just confused, help me guys. The question comes up, because we say that curl is either clockwise or anti-clockwise at a point.","['calculus', 'vectors', 'physics', 'curl', 'vector-analysis']"
845278,Series of sequence with terms over series.,"Prove or give a counterexample to disprove the following statement about series of real numbers: If $a_k > 0,
s_k = a_1 + \cdots + a_k$ and $b_k = a_k/s_k$ then $\sum a_k$ and $\sum b_k$ either both converge or both diverge.","['sequences-and-series', 'real-analysis']"
845284,"If $g \circ f$ is injective, so is $g$","If $g \circ f$ is injective, so is $g$ I don't think this is true. I think that $f$ has to be surjective. So I am going to try to prove that: If $g \circ f$ is injective, and $f$ is surjective, then $g$ is injective. First off, $g \circ f$ means that $(g \circ f)(a) = (g \circ f)(b)$ then $a=b$. And $f$ being surjective means that $\forall b \in B, \exists a\in A$ such that $f(a)=b$ Proof Suppose that $g$ was not injective. $g(f(a))= g(f'(a))$ and $f(a)\ne f'(a)$ But $g(f(a)) = g(f(b)) \to a=b$
$g(f(a))= g(f(b)) \to f(a)=f(b) \to a=b$
Hence contradiction, since $g$ is not injective. So $g$ is injective. Is this an acceptable proof, I think my logic is iffy around the second last paragraph.","['proof-verification', 'functions', 'function-and-relation-composition']"
