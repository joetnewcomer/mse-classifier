question_id,title,body,tags
95922,How do I find the volume of this sliced cylinder?,"This is hard to explain but I'll do my best.  I hope I'm clear. Imagine you have a donut.  You want to find the volume of it and the method you want to use is to imagine slicing one side of that donut and opening it out into a cylinder.  Only, it's not exactly a cylinder as it has two pointed ends: one side of the cylinder has the length of the inner circumference of the donut, the other side has the length of the outer circumference. The 'middle part' is a simple cylinder. I want to find the volume of each end part. There's an easy trick to it, but that's not the solution I'm looking for; the easy trick being putting the two end parts together to make a smaller cylinder. But, how I want to do this is to find the volume of one of these pointy cylindrical endparts with an integral.  However, I can't seem to hit the right answer. Let's say my stretched out donut has a left side of length $2\pi(R-r)$ and a right side of length $2\pi(R+r)$ and a radius of $r$.  Let's say I slice the top and bottom pointed end parts off.  I now have the middle part, a cylinder with a radius of $r$ and a height of $2\pi(R-r)$ and two pointed endparts.  Each endpart has a radius of $r$, and a height of $2\pi r$. If I cut an endpart into triangle wedge-shaped cross sections, each wedge will have a length of $2\sqrt{r^2-y^2}$, a height of $2\pi\sqrt{r^2-y^2}$ and a depth of $dy$.  So the volume of each wedge is $2\pi(r^2-y^2)dy$ If I integrate this with limits $-r$ and $r$ I get $2\pi\int_{-r}^r (r^2-y^2)dy = 2\pi (4r^3/3)$ Assuming that's right, I can double that and add it to the volume of my cylinder to get the donut volume.  So: $4\pi (\frac{4r^3}{3}) + 2\pi^2r^2(R-r) = \frac{16\pi r^3}{3} + 2\pi^2 r^2(R-r)$ The volume of the donut is actually $2\pi^2 r^2R$ (using the solid of revolution approach) so looks like I picked up some extra dough somewhere... $16\pi \frac{r^3}{3} - 2\pi^2 r^3$ cubic units of extra dough to be precise. Is my arithmetic wrong?  Is my method wrong?  Can you spot what I messed up? Sketch:","['multivariable-calculus', 'calculus', 'integration']"
95931,The shortest distance between two parallel lines,"I was working on a set of problems involving finding the shortest distance between two skew lines, which was fine, but then parallel lines showed up. In essence this should be much easier to solve since I do not need to do any cross products. However I quickly got stuck. Two lines are defined by the following parametric equations: $x=6t$, $y=3+8t$, $z=-1+2t$ and $x=2+3s$, $y=4s$, $z=1+s$ which can be represented as $\vec{a}=\begin{pmatrix} 6t \\ 8t+3 \\2t-1 \end{pmatrix}$ and $\vec{b}=\begin{pmatrix} 2+3s \\ 4s \\1+s \end{pmatrix}$ respectively. Therefore the line between the two is defined by the vector $$\vec{c}=\begin{pmatrix} 6t-3s-2 \\ 8t-4s+3 \\2t-s-2 \end{pmatrix}$$ Since the shortest line between the two lines is perpendicular to both, $\vec a \cdot\vec c=\vec b \cdot\vec c=0$. However , I have tried this and it seems overly complicated for such an easy problem. My initial thought was to find the distance between the initial coordinates of the parametric equations, but those points could be any points on the line. Does anyone have any suggestion on how to continue?","['vector-spaces', 'geometry']"
95937,Confusion about the Proof of Dieudonné's Criterion - Why doesn't it hold for analytic functions?,"The following theorem is due to Dieudonné: Let $p(z) = a_0 + a_1 z + \cdots + a_n z^n$, a complex polynomial. $p$ is univalent on $D$, the unit disk, if and only if $f_\theta(z) = \sum_{k=1}^n a_k \dfrac{\sin(k\theta)}{\sin(\theta)} z^{k-1}$ has no zeros in $D$. ($\theta \in (0, \dfrac{\pi}{2}]$). The idea of the proof is as follows: 1) $p$ is univalent on $D$ if and only if $t\mapsto p(re^{it})$ is injective on $t\in [0,2\pi)$ for each $0< r < 1$. 2) $f_\theta$ has no zero in $D$ for $\theta \in (0,\dfrac{\pi}{2}]$ if and only if $p(re^{i(t+\theta)}) \ne p(re^{i(t-\theta)})$ for $t \in [0,2\pi)$, $0<r<1$ and $\theta \in (0,\dfrac{\pi}{2}]$. The second pars of 1) and 2) are saying the exact same thing, so this would prove the theorem. What (I think) I don't really get is is the statement 1). It seems like the proof for $p$ polynomial should work for any analytic function. So it seems like the theorem should be true for a general analytic function, where the sum becomes an infinite sum. What am I missing? EDIT: Basically, it seems like nowhere in the proof of Dieudonné the fact that $p$ is a polynomial is used.",['complex-analysis']
95964,Why does the Continuum Hypothesis make an ideal measure on $\mathbb R$ impossible?,"On the page 43 of Real Analysis by H.L. Royden (1st Edition) we read: ""(Ideally) we should like $m$ (the measure function) to have the following properties: $m(E)$ is defined for each subset $E$ of real numbers. For an interval $I$, $m(I) = l(I)$ (the length of $I$). If $\{E_n\}$ is a sequence of disjoint sets (for which $m$ is defined),
$m(\bigcup E_n)= \sum m (E_n)$."" Then at the end of page 44 we read : ""If we assume the Continuum Hypothesis (that every non countable set of real numbers can be put in one to one correspondence with the set of all real numbers) then such a measure is impossible,"" and no more explanation was given. Now assuming the Continuum Hypothesis I am not able to see why such a measure is not possible.  Would you be kind enough to help me?","['measure-theory', 'examples-counterexamples', 'real-analysis']"
95968,"Odds of guessing suit from a deck of cards, with perfect memory","While teaching my daughter why drawing to an inside straight is almost always a bad idea, we stumbled upon what I think is a far more difficult problem: You have a standard 52-card deck with 4 suits and I ask you to guess the suit of the top card. The odds of guessing the correct suit are obviously 1 in 4. You then guess again, but the first card is not returned to the deck. You guess a suit other than the first drawn and the odds are 13/51, somewhat better than 1 in 4. Continuing through the deck your odds continually change (never worse than 1 in 4, definitely 100% for the last card) what are your overall odds for any given draw over the course of 52 picks? Can this be calculated? Or do you need to devise a strategy and write a computer program to determine the answer? Do these type of problems have a name? Dad and to a much less extent daughter, await your thoughts!","['statistics', 'probability']"
95979,"Proving $a^2+b^2=c^2$ where $a,b,c$ are side lengths of a right triangle.","Proving $a^2+b^2=c^2$ where $a,b,c$ are side lengths of a right triangle. First, I have never done a proof before, sorry I am so poor here. I have spent many hours but my actions have mostly used wrong ideas. I will only say what I have done that I think is right. If you need my other writing I can write it out but it was mostly about fitting shapes inside the triangles and I think the big mistake is that if the equal statement $a^2+b^2=c^2$ were to be wrong then anything about the inside triangles cannot prove the statement to be wrong because  the algebra is connected to the geometry of the triangle and the shapes are inside the geometry of the triangle. Start: I started by drawing a square with sides $d,e,f,g$ all the same as a. 
The biggest possible right triangle has two sides the same length. This square can fit at least two right triangles inside it both no smaller than the other with one side equal to a. That is true because if you made one smaller than the other and pushed it into one corner of the square then the bigger triangle touching it would overlap the corners of the square which is wrong. So then the sum $d+e+f+g=4a$ is more than $a+b+c$ where $a,b,c$ are the side lengths of one of the triangles and $4a>a+b+c$. Then I square $$\begin{eqnarray*} 16a^2&>& (a+b+c)^2\\
&=&a^2+b^2+c^2+2(ab+bc+ac)\\
\end{eqnarray*}$$ The only thing I can do here is use the equation at the top so if $a^2+b^2=c^2$ isn’t true for the triangle then it’s $a^2+b^2=c^2+z$ for some $z$. But I subtracted that from the expression and it wasn’t wrong which I thought it would have to be since I added the $z$. I guess the extra $z$ can’t show the equation is wrong since any number could be equal to it including those like zero which it is not really equal to atleast if the equation were wrong. But if there is a rule that $z$ isn’t zero included somehow there should be a way to conclude having $z$ not be zero is wrong. But then I checked and found $a,b,c,z$ with $z$ not zero so that the inequality holds so I’m very confused. Maybe the squares are too simple and I should have chosen a rectangle or put squares around the outside of the triangle. I know a book that proves this but I want just some clues whether my actions are appropriate to solving this and otherwise a clue for a new way since I don’t care about it for a class I just like to think about the question. Edit. I have corrected (a+b+c)^2 I think. I am also grateful for the answer below which gives a good clue and just as much as I wished for. It is certainly an interesting choice of shapes and different from what I was doing in that there are no gaps between the shapes. It helps clarify that as I am asking about ways that work I am also asking if an approach using gaps between shapes and estimations rather than exactness could work as an approach (perhaps just because I have spent some hours and wish to recover some value). Is that known? Or perhaps the notion of grouping proofs into approaches is just because the mind is simple and we can't talk about the correctness of approaches only whether one proof we are handed is right or wrong.","['geometry', 'triangles', 'trigonometry']"
95980,How many terms in a series expansion,"General:
If $f \in C^1$ is a periodic function defined over some multi-dimensional space, then it should be possible to express $f$ as a FINITE fourier series. is this true of any periodic basis? is there a way to determine the number of terms in this finite series? Specific:
I have a function that is smooth and continuous and is defined on the unit hypersphere.  I want to know: is it possible to represent this function as a FINITE series in the hyperspherical harmonic basis? how many terms will it take?","['fourier-series', 'fourier-analysis', 'group-theory', 'differential-geometry']"
95981,Is there a unique solution for this quadratic matrix equation?,"Here is the quadratic matrix equation I've been looking at lately: $$ Q_{r,r}=A_{r,r}X_{r,r}^2+B_{r,r}X_{r,r}+C_{r,r}=0_{r,r} $$ Note that $A, B, C,$ and $X$ are $r \times r$ matrices. $A$ contains known elements, $B$ contains known elements, $C$ contains known elements, and $X$ contains the unknown elements that you are solving for. $ 0_{r,r} $ is just the $r \times r$ null matrix. Is there any solution for $X$ in terms of $A, B,$ and $C$ (making no easy assumptions)? (e.g. $X$ is a diagonal matrix, $A=B=C$, or anything of that sort.) I have tried to solve this and nothing has worked out. I attempted solving it generally by manipulating the matrices in variable form (i.e. actually writing out the matrices $A, B, C,$ and $X$ in variables) and finding a unique solution for all of the elements of $X$ in terms of the elements of $A, B,$ and $C$. That didn't work out beyond the case of $r=1$. Trying to solve it by looking at $r$ at different values did not work out either; I ended up with very abysmal equations at just $r=2$. I don't know exactly how to make this appealing to the denizens of math.stackexchange, but it (as far as I know) isn't a heavily studied problem. There is a very high possibility that I've just been doing elementary techniques and nothing of note, so I hope someone or a group of people could shed light on this.","['matrix-equations', 'matrices', 'linear-algebra']"
95998,How to prove that polynomials with integer coefficients generically have full Galois group,"Based on the graphic in the MathWorld article on the quintic equation it seems very likely that following statement is either true or trivially false in a way that can be easily remedied by adding an additional hypothesis: Let $A_N$ be the set of degree $n$ polynomials $f(x)$ with integer coefficients $a_0, a_1, ... a_n$ such that $|a_i| < N$. Let $S_N$ be the fraction of these that have Galois group $S_n$. Then as $N \rightarrow \infty$ , $S_N \rightarrow 1$. It also seems likely that this result follows from well known results: how does one prove it?",['number-theory']
96030,Probability of an odd number in 10/20 lotto,"Say you have a lotto game 10/20, which means that 10 balls are drawn from 20. How can I calculate what are the odds that the lowest drawn number is odd (and also how can I calculate the odds if it's even)? So a detailed explanation:
we have numbers 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19 and 20 and the drawn numbers were for example 3, 5, 8, 11, 12, 13, 14, 15, 18 and 19 so, we see now that lowest number is 3 and he is an odd number. So, as stated above, can you help me in finding out how to calculate such probability?",['probability']
96042,Can the Fourier transform be defined as an integration over $\mathbb C$ instead of $\mathbb R$?,"Can the Fourier transform of a whole function $f:\mathbb R\mapsto\mathbb C$ be defined as integration over $\mathbb C$ instead of $\mathbb R$ as well, such that 
  $$\tilde f(k) = \frac{\mathcal N}{2\pi} \int_{\mathbb C}f(x) e^{-ikx}\,dx,$$ and (if so) what is the correct value of the normalization $\mathcal N$ for consistency with the $\mathbb R$-integration? Given a whole function $f:\mathbb R\mapsto\mathbb C$, its Fourier transform $$ \tilde f(k) = \frac1{2\pi}\int_{-\infty}^\infty f(x)e^{-ikx}\,dx$$ can be determined by other integration paths as well by using Cauchy's Residue Theorem, for example by shifting $x$ by an imaginary constant $ic$. Assuming a sufficiently fast decaying function for $\Re(x)\to\pm\infty$ (and using the fact that a whole function has no residues), this results in simply adding that constant to the integration boundaries, i.e. $$ \tilde f(k) = \frac1{2\pi}\int_{-\infty+ic}^{\infty+ic} f(x)e^{-ikx}\,dx,$$ which can be expressed by substitution as well: $$ \tilde f(k) = \frac1{2\pi}\int_{-\infty}^{\infty} f(x-ic)e^{-ik(x-ic)}\,dx.$$ One can then average over different values of $c$ to obtain $$ \tilde f(k) = \frac1{2\pi\cdot 2T}\int_{-T}^{T}\int_{-\infty}^{\infty} f(x-ic)e^{-ik(x-ic)}\,dx\,dc.$$ Now my question boils down to 1) Since infinity is involved, is this equivalent to $$ \tilde f(k) = \frac1{4\pi T}\int_{\mathbb R\times[-iT,iT]} f(x_1+x_2)e^{-ik(x_1+x_2)}\,d^2x,$$ 2) Can the limit $T\to\infty$ be taken such that $\mathbb R\times[-iT,iT]\to\mathbb C$ and 3) What would the correct normalization be?","['fourier-analysis', 'complex-analysis', 'analysis']"
96049,A question about homeomorphisms,"If f is a real-valued function defined on a connected open set of real numbers, and f is injective and continuous, is the inverse of f continuous? I realize that in general the inverse is not necessarily continuous, but I believe that in this case it is.",['general-topology']
96051,"Stone–Čech compactification of $\mathbb{N}, \mathbb{Q}$ and $\mathbb{R}$","I'm trying to find connections between Stone–Čech compactifications of $\mathbb{N}, \mathbb{Q}$ and $\mathbb{R}$, all with the euclidean topology. So, are there any ? e.g. is $\beta \mathbb{Q} = \beta \mathbb{R}$ ? I know that the cardinality of $\beta \mathbb{N} = \beta \mathbb{Q} =  \beta \mathbb{R}$ thanks to Wikipedia, but how does one prove it ?","['general-topology', 'compactness']"
96065,Whats the rule for putting up a plus-minus sign when taking under root?,"Given a simple equation.... $\ (x+1)^2 =21 $ if we take the under root of both sides , we get $\ x+1 = \pm \sqrt{21} $ why dont we get a $ \pm $ on the left hand side ?",['algebra-precalculus']
96084,Where is the flaw in evaluating the following integral?,"I was trying to evaluate a complicated integral by substitution and along the way I got stuck in nonsensical answer. Surprisingly enough the point I wanted to discuss can be demonstrated using the following primitive integral: $\displaystyle\int_0^\pi \sin\theta d\theta=-\cos\theta|_0^\pi=-\cos\pi+\cos 0=1+1=2$ Now Imagine we are trying to do the same integral in another way, by substitution. If we take $\sin\theta\equiv y$  then the limits of the integral will change accordingly from $0$ to $\pi$ to from $0$ to $0$,
which will kill the integral instantly and give us $0$! So either there is a flaw in my solution that I cannot find, or that there are conditions under which one can (or cannot) use integration by substitution that I am not aware of (at least I have never seen it in college level calculus).","['calculus', 'integration', 'fake-proofs']"
96093,Subsets with equal sums,"I have a problem to solve but I am in need of your help. Subjects with equal sums: Prove that for every set $A$ which consists of $10$ double digit natural numbers( numbers among $10, \ldots, 99$), there are always two different subsets of $A$ that its elements have the same sum. Thank you very much","['pigeonhole-principle', 'discrete-mathematics']"
96115,A characterisation of nowhere dense sets,"Can you give me a hint, why the following characterisation of a nowhere dense set $A$ (where my definition of n.d. is $ \textrm{Int(cl}(A))=\emptyset$) should hold: For all nonempty open set $U$ there exists an open set $V$, such that $V \subseteq U$ and $A\cap V = \emptyset$ (I found this characterisation on the French Wikipedia article for n.d. sets).",['general-topology']
96125,What is a field?,"I've always wondered about what a field is meant to represent. For example, group automorphisns naturally represent symmetry in many areas. I'm not looking for a solid answer, just an idea.","['soft-question', 'abstract-algebra', 'field-theory']"
96129,Deriving the formula for the Möbius function?,"There is a rich and beautiful theory in combinatorics which deals with the Möbius functions of posets and arrives at the ""Classical"" formula of the Möbius function. Let's forget all about it, since I'm hoping to find an elementary solution. I wish to arrive at the formula for the classical Möbius function $\mu$ (which is defined as $1$ on $1$, $0$ on non square-free numbers, and as $(-1)^k$ for square-free numbers with exactly $k$ prime divisors) from the following formula: $$\sum_{d|n}\mu(d)=\cases{1, & n=1;\\ 0, & n>1.}$$ So let's assume I'm given this formula and nothing else (especially not a pre-hand knowledge of the definition of $\mu$) - is there a simple way to derive the standard definition, without using deeper theory or ""insight""?","['elementary-number-theory', 'combinatorics']"
96151,"Do ""imaginary"" and ""complex"" angles exist?","During some experimentation with sines and cosines, its inverses, and complex numbers, I came across these results that I found quite interesting: $ \sin ^ {-1} ( 2 ) \approx 1.57 - 1.32 i $ $ \sin ( 1 + i ) \approx 1.30 + 0.63 i $ Does this mean that there is such a thing as ""imaginary"" or ""complex"" angles, and if they do, what practical use do they serve?","['trigonometry', 'complex-numbers']"
96168,how to find mid point of an arc?,"I have start point $(x_1,y_1)$ and an end point $(x_2,y_2)$ and radius of arc. How to calculate the co-ordinates of mid-poing of arc? The arc is the part of a circle. Known Values length of AD // that is radius
B(x,y)
C(x,y) Needs to find D(x,y)  // D is the mid-point of arc BC",['trigonometry']
96170,Straightedge-only constructions,"I know Poncelet-Steiner tells us that given a circle and its center, straightedge alone is equivalent to straightedge and compass. My question is, what can we construct with purely straightedge? We certainly can't construct any square roots in a finite number of steps. Given a segment of unit length, is it possible to construct any rational number? Thanks in advance. I wanted to know because I wanted to show that you can construct any square root with straightedge alone in an infinite number of steps. EDIT: What would you need to construct every rational? Would some manner of constructing parallel lines suffice? Would a segment of length 2 in addition to the unit segment suffice?","['geometry', 'geometric-construction']"
96184,What's the most concise way to refer to this shape?,"What would you call this shape? Not the shape in green, I mean the entire object.","['geometry', 'terminology']"
96186,Continuous function and limit,"Let's suppose $f$ a continuous function where
$$\lim_{x\to+\infty} { f(x+1)- f(x)}=l.$$
How to prove that 
$$\lim_{x\to +\infty}\frac{f(x)}{x}=l\,?$$ I've already proove by Cesaro theorem that 
$$\lim_{n\to +\infty}\frac{f(n) 
        }{n}=l,$$
where $n$ is an integer.
How to continue it?","['calculus', 'functions', 'limits']"
96188,Classifications of finite nilpotent groups,"I would like to understand the concept of classification in the context finite groups. For finite abelian groups and finite simple groups, it's clear to me what is meant by classification. However, these are the cases where a ""perfect classification"" turns out to work fine. Because I have a pretty good understanding of nilpotent groups, I asked myself how the generalization of the classification of finite abelian groups to finite nilpotent groups would look like. In a certain sense, the statement ""Every finite nilpotent group is the direct product of p-groups"" contains the classification of finite abelian groups as a special case. So at least the classification of finite nilpotent groups is now reduced to the classification of finite (indecomposable) p-groups . But even so the structure of p-groups is ""relatively simple"" and well understood, trying to enumerate the isomorphism classes is challenging and doesn't seem to add much value. Would an acceptable solution for the classification problem of finite nilpotent groups necessarily include the possibility for an enumeration of the isomorphism classes? Or are ""more practical"" solutions also acceptable? For example, would it be sufficient to give both an ""efficient"" algorithm for constructing at least one representative of each isomorphism class of a given order, and an ""efficient"" algorithm for deciding whether two representatives corresponds to the same isomorphism class? What would be the role/importance (with respect to the classification problem) of characteristic numbers that only depend on the isomorphism class?","['finite-groups', 'abstract-algebra']"
96206,Newton's method and trig functions on a computer,"I'm trying to use Newton's method to find roots for the function $A \cos(\Theta_2 - \Theta_1) + B \sin(\Theta_1)$.  (That is, iterate $x_{i+1} = x_i - f(x_i) / f'(x_i)$).  I've got a working implementation and everything's great, except that I'm not getting all the precision I'd expect. I'm using 64 bit floating point numbers (doubles) throughout, and I'm expecting effective precision to be at least $1e^{-10}$, but I'm getting only maybe $1e^{-9}$.  I traced the problem to the fact that $\cos(\frac{\Pi}{2}) \approx 1e^{-9}$ on my machine.  Which means when I evaluate my function it returns 0 at a place that isn't exactly a root of my function. This isn't entirely unexpected.  I'm well aware of numeric issues on machines.  I think most modern CPUs use CORDIC for trig evaluations, which interpolate between table lookup values.  Some numeric noise on the least significant bits is sort of par for the course. I'm just wondering if there's some known method to get around the limitations of the machine implementation of sine and cosine for root finding with Newton's Method?  Is there some way to maybe transform my initial equation in some way that will give me a function with the same roots in some given neighborhood but better numerical behavior?  Taylor series approximations come to mind but they don't always have great numerical behavior (although I don't have a lot of experience in that regard so I might be wrong). Really any general advice about numeric root finding with trig functions would be helpful. UPDATE I was slightly wrong.  The real problem is that: $\cos(3.141592650897981) = -1$ on my machine.  That angle value is roughly $2.69e^{-9}$ off from actual $\Pi$.  You can reproduce this with google, actually.  Try googling ""cos(3.141592650897981)"" and ""PI - 3.141592650897981"" to see what I mean.","['trigonometry', 'roots', 'numerical-methods']"
96211,Equicontinuity and modulus of continuity,"A modulus of continuity for a function $f$ is a continuous increasing function $\alpha$ such that $\alpha(0) = 0$ and $|f(x) - f(y)| < \alpha(|x-y|)$ for all $x$ and $y$. I am trying to prove that an equicontinuous family $\mathcal F$ of functions has a common modulus of continuity. This seems intuitively obvious, but I am having difficulty proving continuity. So far, I have defined $\alpha(\delta) = \sup\{|f(x) - f(y)| :  d(x,y) \leq \delta, f\in \mathcal F\} $. I want to show that this function is continuous in $\delta$. Any suggestions?",['real-analysis']
96247,Chance of selecting a duplicate?,"When you select things at random repeatedly (with replacement or whatever) out of a field of N possible things, how do you calculate the probability that something has been chosen X times after Y choices were made? For example, if there are 64 DotA 2 heroes and I choose a random one 9 times, what's the chance that I get Skeleton King 5 of those times?","['statistics', 'probability']"
96249,Intuition for induced bundle.,"If $X$ is a manifold, $G$ a compact Lie group, $E$ a principal $G$-bundle over $X$ and $V$ be a vector space on which $G$ acts. Then one can form the vector bundle $E \times_{G} V$ over $X$. What is the intuition for this bundle?
Do you know any good picture to have in mind, how this bundle looks like?","['fiber-bundles', 'algebraic-topology', 'differential-geometry']"
96253,Does measurability/continuity of a mapping follow that of its sections?,"Suppose  $\{ (G_i, \mathcal{G}_i), i=1,2 \}$ are measurable spaces. Their product measurable space is $(\prod_{i=1}^2 G_i, \prod_{i=1}^2 \mathcal{G}_i)$. $(F, \mathcal{F})$ is another measurable space. $g:\prod_{i=1}^2 G_i \rightarrow F $ is a mapping. Define sections of $g$ on each component space $G_i$ as follows $\forall x_1 \in G_1$ define $g_{x_1}:
    G_2 \rightarrow F$ as $g_{x_1}(x_2) := g(x_1,x_2)$; $\forall x_2 \in G_2$ define $g_{x_2}:
    G_1 \rightarrow F$ as $g_{x_2}(x_1) := g(x_1,x_2)$. Similar to Theorem 18.1 of Probability and Measure by Billingsley, it can be
shown that if $g$ is measurable, then its sections are all
measurable. I was wondering if the converse is also true, i.e. if
its sections are all measurable, is $g$ also measurable? If it is true, will it still be true for arbitrarily many $\{ (G_i,
    \mathcal{G}_i), i=I \}$? I am also wondering about the same questions when replacing
measurable spaces with topological spaces, and measurability of a
mapping by continuity of a mapping? (I will move this topological
case to another post if the answers are not essentially based on the same idea.) Thanks and regards!","['general-topology', 'measure-theory']"
96257,Maximum of sum of finite modulus of analytic function.,"Let $f_1,f_2,\ldots,f_n $ be  analytic complex functions in domain $D$. and $f = \sum_{k=1}^n|f_k|$ is not constant. Can I show the  maximum of $f$ only appears on boundary of $D\,$?",['complex-analysis']
96265,Differentiating an Inner Product,"If $(V, \langle \cdot, \cdot \rangle)$ is a finite-dimensional inner product space and $f,g : \mathbb{R} \longrightarrow V$ are differentiable functions, a straightforward calculation with components shows that $$
\frac{d}{dt} \langle f, g \rangle = \langle f(t), g^{\prime}(t) \rangle + \langle f^{\prime}(t), g(t) \rangle
$$ This approach is not very satisfying. However, attempting to apply the definition of the derivative directly doesn't seem to work for me. Is there a slick, perhaps intrinsic way, to prove this that doesn't involve working in coordinates?","['derivatives', 'inner-products', 'functional-analysis', 'real-analysis']"
96270,What is 'zero of multiplicity' and 'counting multiplicity'?,"What is a 'zero of multiplicity' and and 'counting multiplicity'? I looked up this definition on Mathwords.com : How many times a particular number is a zero for a given polynomial. For example, in the polynomial function $f(x) = (x – 3)^4(x – 5)(x – 8)^2$ , the zero 3 has multiplicity 4, 5 has multiplicity 1, and 8 has multiplicity 2. Although this polynomial has only three zeros, we say that it has seven zeros counting multiplicity. What is a 'zero of multiplicity' and where do the ""seven zeros"" come from (I know the ""7"" comes from adding the three exponents, ""4"", the hidden ""1"", and ""2"" in the equation, but why call them zeroes ?)? As in, I don't understand where the zero part of the term comes in... (bold emphasis mine).","['roots', 'algebra-precalculus', 'terminology', 'polynomials']"
96292,Using a laplace type expansion to get bounds on an integral arising in the study of Brownian motion,"Let $ 0 < r < 1$, fix $x > 1$ and consider the integral $$ I_{r}(x) = \int_{1}^{\infty} \exp\left( - \frac{x^2}{2y^{2r}} - \frac{y^2}{2}\right) \frac{dy}{y^r}.$$ In the investigation of iterating two Brownian motions the integral above arises in some form or another in the paper titled ""Iterated Random Walk"" L. Turban 2004 Europhys. Lett. 65 627.  or a more recent paper ""Fractional diffusion equations and processes with randomly varying time"" Enzo Orsingher, Luisa Beghin http://arxiv.org/abs/1102.4729 . The result we have been trying to prove below can be thought of as an analysis of localizing around the maximum of the function $f(y) = \frac{x^2}{2y^{2r}} + \frac{y^2}{2}$ in the exponential of the integrand and then applying appropriate estimates along with integration by parts.  I have always thought of this as a localization similar to what is used in Laplace's method but my advisor has explained to me that from a probabilistic perspective we are just applying a standard idea from large deviations and with that in mind much of our analysis has assumed that we are taking $x \gg 1$ much larger than one. Question 1: Suppose that $p(x),q(x)>0$ are polynomials, $k(r)$ a constant depending on $r$ and that $c(r) = \frac{(r^{-\frac{r}{r+1}} +r^\frac{1}{r+1}) }{2}$ then is it true that $I_r (x)  \leq k(r) \frac{p(x)}{q(x)} 
\exp(-c(r) x^{\frac{2}{1+r}}) $ We have a proof of this result under more strict hypothesis that is rather boring (in the sense it only uses calculus) and involves essentially integration by parts applied to the integral rewritten as $I_r(x) = \int_{1}^{\infty} \frac{y^{-r}}{f'(y)} f'(y) \exp(-f(y)) dy$.  The draw back of our proof is it is not uniform in the sense that it only holds for all $x > x_0$ for some $x_0(r) \gg 1$ some constant much greater than $1$.  We would like to relax this assumption and try to find a proof that hold for any $x>1$.","['probability-theory', 'brownian-motion', 'real-analysis', 'analysis']"
96316,About finding the function such that $f(xy)=f(x)f(y)-f(x+y)+1$ [duplicate],"This question already has answers here : Solve the functional equation $f(xy) = f(x)f(y) - f(x + y) + 1$ and $f(1) = 2$ (2 answers) Closed 3 years ago . Define a function $f\colon\mathbb{R}\to\mathbb{R}$ which satisfies $$f(xy)=f(x)f(y)-f(x+y)+1$$
for all $x,y\in\mathbb Q$. With a supp condition $f(1)=2$. (I didn't notice that.) How to show that $f(x)=x+1$ for all $x$ that belong to $\mathbb{Q}$?","['functions', 'functional-equations']"
96318,Spectrum of a quasi-coherent algebra on an algebraic stack,"Let $X$ be an algebraic stack and $\mathcal{A}$ a quasi-coherent $\mathcal{O}_X$-algebra. Define the stack $\mathrm{Spec}(\mathcal{A})$  by $\mathrm{Spec}(\mathcal{A})(T) := \{(f,h) : f \in X(T), h \in \hom_{\mathrm{Alg}(\mathcal{O}_T)}(f^* \mathcal{A},\mathcal{O}_T)\}$ and the obvious restriction maps. Is it true that $\mathrm{Spec}(\mathcal{A})$ is an algebraic stack? Do you know a reference? I cannot even prove that the diagonal is representable. Perhaps first the case of an algebraic space has to be done. Note that if $X$ is a scheme, this coincides with the usual definition of the spectrum as in EGA I.",['algebraic-geometry']
96321,Complete statistic: Poisson Distribution,"Context I am having difficulty trying to understand a step of a proof which relies on a property of series. Proof Suppose that $X_1, X_2, \ldots , X_n$ is a random sample of size $n$ from a Poisson distribution with parameter $\lambda > 0$. The goal is to show that $T = \sum_{i=1}^n X_i$ is a complete statistic. Since we know that $T =  \sum_{i=1}^n X_i \sim \mathrm{Poisson}(n\lambda)$: $$
\mathbb{E}(h(T)) = \sum_{k=0}^{\infty} h(k) \, e^{-n\lambda} \, \frac{(n\lambda)^k}{k!} = 0\Longrightarrow \sum_{k=0}^{\infty} h(k)  \, \frac{(n\lambda)^k}{k!} = 0 
$$ The textbook I am using and some others sources I've found argue that: $$
\boxed{\displaystyle\sum_{k=0}^{\infty} h(k)  \, \frac{(n\lambda)^k}{k!} = 0 \Longrightarrow h(k)  \, \frac{(n\lambda)^k}{k!}  = 0 \qquad \forall k}
$$ It probably is an obvious result from calculus, but I am unable to prove it. If $ h(k) \, (n\lambda)^k/k!  = 0$ for all $k$ then $T$ is a complete statistic because $\lambda$ is nonnegative and then $h(k) = 0$ for all $k$ .","['statistics', 'calculus']"
96324,What's wrong with this definition of continuity?,"Consider this definitions: A function $f:X \to Y$ is continuous at $x\in X$ iff for any open neighborhood $V_{f(x)}$ of $f(x)$ there is an open neighborhood $U_{x}$ of $x$ that gets mapped by $f$ into $V_{f(x)}$ (or, in other words, there is an open neighborhood $U_{x}$ of $x$ such that $f[U_x]\subseteq V_{f(x)}$). A function $f:X \to Y$ is continuous iff it is continuous at all $x \in X$. This definition of continuity seems to me equivalent to the ""standard"" definition in terms of inverse images (namely $f:X\to Y\;$ is continuous iff for any open set $V\subseteq Y$, the set $f^{-1}(V)\subseteq X$ is open). Am I wrong? Assuming that I'm correct, I am baffled by the prevalence of the currently standard definition, since the one above looks to me far more natural.  It is certainly more obviously a generalization of the $\epsilon$-$\delta$ definition of continuity in metric spaces (just replace $V_{f(x)}$ and $U_{x}$ by open balls $B(f(x), \epsilon)$ and $B(x, \delta)$, respectively), which, in turn, is an obvious generalization of the $\epsilon$-$\delta$ definition of continuity for functions $\mathbb{R}\to\mathbb{R}$ (just replace the open balls $B(f(x), \epsilon)$ and $B(x, \delta)$ by open intervals $(f(x) - \epsilon, f(x) + \epsilon)$ and $(x-\delta, x+\delta)$, respectively). Given these considerations, why is the standard definition the generally preferred one? Edit: the replies I've gotten so far have focused on the fact that the alternative definition depends on an auxiliary definition of continuity at a point, but this is a very minor aspect of the alternative definition.  I chose this two-part approach only to make the wording of the definition of continuity slightly less awkward, but it is not required.  I could have just as well written: A function $f:X \to Y$ is continuous iff for all $x \in X$ and any open neighborhood $V_{f(x)}$ of $f(x)$ there is an open neighborhood $U_{x}$ of $x$ such that $f[U_{x}]\subseteq V_{f(x)}$. Also, these replies suggest that, when it comes to defining terms, brevity trumps clarity.  I find this hard to take: a definition, by definition , is introducing a concept, so its intended audience is one that will appreciate clarity over brevity.  An equivalent characterization of the same concept whose only advantage is greater brevity should be relegated to a theorem, IMO.","['general-topology', 'calculus', 'real-analysis', 'metric-spaces']"
96331,"In Russian roulette, is it best to go first?","Assume that we are playing a game of Russian roulette (6 chambers) and that there is no shuffling after the shot is fired. I was wondering if you have an advantage in going first? If so, how big of an advantage? I was just debating this with friends, and I wouldn't know what probability to use to prove it. I'm thinking binomial distribution or something like that. If $n=2$ , then there's no advantage. Just $50/50$ if the person survives or dies. If $n=3$ , then maybe the other guy has an advantage. The person who goes second should have an advantage. Or maybe I'm wrong.",['probability']
96356,Localizing a quotient ring $A/ \mathfrak{p}$,"Let's assume $A$ is a commutative ring with $1$ and $\mathfrak{p} \subset A$ is a prime ideal. We shall consider $A/ \mathfrak{p}$ as an $A$-module, so there is a localization $(A/ \mathfrak{p})_\mathfrak{p}$. What can we say about this? I know it is isomorphic to $A_\mathfrak{p} \otimes _A A/\mathfrak{p}$, but I was hoping to somehow directly relate it to a quotient of the $A$-module $A_\mathfrak{p}$ (if this is even possible).","['commutative-algebra', 'abstract-algebra']"
96358,Am I thinking about infinitesimals correctly?,"I was all set to begin Calculus 2 when I thought, ""I should have a more intuitive sense of what's happening with differentials before I move on."" I want to tell you what I've learned and ask you all to help me put it together more cohesively than I have done.  I'm just going to list what I know.  Please point out my inconsistencies.  And please forgive me if the following seems to ramble, I'm just sharing my thought process and I want it to have more rigour. I've seen Qiaochu Yuan saying a few times that $dy$ and $dx$ are not numbers.  I didn't know what he meant.  So, I read elsewhere, and learned about infinitesimals.  I read that an infinitesimal is a concept similar to zero, but not.  It is a small, unmeasurable value.  That there is no value you can multiply an infinitesimal by to get any real number.  Yet, it's not zero.  I read that this is an important distinction. So, when I read $\frac{dy}{dx}$, this is not a fraction: it should be read as one symbol, and interpreted as shorthand for $\lim\limits_{\delta x \to 0}\frac{\delta y}{\delta x}$. A problem I still have, though, and it's surprising even to me that I don't get this yet, is this: if I'm finding the gradient of a curve at a point, then I'm finding the gradient of the tangent line at that point.  I do this by setting up the quotient $\frac{\delta y}{\delta x}$ where both $\delta y$ and $\delta x$ are measureable values, real numbers.  as soon as I write $\lim\limits_{\delta x \to 0}$ in front of the quotient, I'm saying that the quotient coupled with the limit is not a quotient.  So $\delta y$ and $\delta x$ are still real numbers, but $\frac{dy}{dx}$ is a symbol that means the tangent, the limit, or $f'(x)$. So two things I'm not sure of at this point:  it seems that if $\frac{dy}{dx}$ is a symbol in its own right, then $dy$ and $dx$ are not independent symbols.  And if they are, I don't know what they mean.  I will guess that $dy = \lim\limits_{\delta x \to 0}\delta y$ and $dx = \lim\limits_{\delta x \to 0}\delta x$.  To say that $dx$ is infinitesimally small is to say that it is infinitely close to zero but not zero. But, if two points are infinitely close to one another, where the distance between them is an infinitesimal, they are still two points aren't they?  They can only be the same point if the distance between them is zero, and an infinitesimal is not zero.  And so, how can I find the gradient of the tangent line when the tangent is really a secant? I know this is important to understand, and at some point I thought I understood it intuitively.  But my understanding has slipped and I'm here.  I can tell myself ""it just is"" but it's not much of an argument and it's not satisfying.  I want to understand everything as much as I'm capable of doing so, and take nothing on faith. Once I understand this, I will be able to write the chain rule without multiplying by infinitesimals, then the same with the substitution rule, then I move onto Calculus 2.  Until I understand this, I can't move on. I'm guessing my problem comes from a lack of rigor in some textbooks, and that makes my overall understanding weakened.  If I try to solve my own problem, I might say that $\frac{dy}{dx}$ is not, in fact, the gradient of the tangent at all.  It is the gradient of the secant, but it is the value that is infinitely close to the tangent. It ""approaches"" the tangent.  But it still comes down to this: if two values are not the same, and their difference is infinitely small, what does that mean?  Sometimes they are considered the same, sometimes they are not.  Which is it?  If something is infinitely small, it has a value greater than zero, but it's not zero, it can't accumulate to become any real number. It's not a number.  It's a concept with the above properties and that's all there is to it.  Is that the answer? I understand the idea is to be able to get infinitely close to a value while avoiding a division by zero.  And knowing that is almost enough for me to move on.  But I think there's more for me to understand here, and a lot rests on it. Thanks for reading this far, if you did.  I appreciate your feedback. Also: another question.  If I have $dx$ and $du$ and they are both infinitesimals, then $1+dx = 1+du$, right?  Yet, $du$ and $dx$ are not the same, right?  In an integral, I can't just switch out a $dx$ for a $du$, yet they both represent the same concept.","['calculus', 'infinity']"
96360,Can non-unital rings be replaced by R-algebras?,"While working through some lecture notes on semigroups, it seemed to me like a semigroup doesn't buy you much generality over a monoid. But I wondered whether the situation is different for non-unital versus (unital) rings. Then I worked through the following reasons against non-unital rings , which made the point that all naturally occurring non-unital (sub)rings actually have important additional structures, giving ideals and R-algebras as examples. But the author of that paper later later agreed to most of the reasons for non-unital rings . Let $A$ be a ring (possibly non-unital) and $\tilde{A}=\mathbb Z\oplus A$ as abelian group. I wondered what Martin Brandenburg meant by the ""obvious"" multiplication so that $A\subseteq \tilde{A}$ is an ideal and $1\in\mathbb Z$ is the identity. After some trying, I came up with
$$ (r,a)\cdot(s,b)=(rs,rb+sa+ab)$$
I haven't checked associativity, but at least the above two conditions are satisfied. Now I wonder what would happen if I replace $\mathbb Z$ by an arbitrary commutative ring $R$ with identity $1$, and assume that I'm also given a scalar multiplication $R \times A \mapsto A$ denoted by $(r, a) \mapsto ra$. Would the above multiplication turn $R\oplus A$ into an (unital) ring, if $A$ is an $R$-algebra? And would conversely $A$ be an $R$-algebra, whenever $R\oplus A$ happens to be an (unital) ring under the above multiplication?","['ring-theory', 'abstract-algebra']"
96361,"Relationships among the terms ""slope"", ""parameter"", and ""coefficient""?","In $y=mx$, is $m$, are there different implications of referring to $m$ as a ""slope"", a ""coefficient"", a ""parameter""? Or perhaps the ""slope coefficient"" or ""slope parameter""? For context, I am describing a the process of parameterizing a linear model (as opposed to trying to interpret a description). As I understand, slope is a type of parameter, but it is not clear if there is a difference between parameter and coefficient.","['algebra-precalculus', 'terminology', 'definition']"
96368,Does locally compact separable Hausdorff imply $\sigma$-compact?,Is it true that every locally compact separable Hausdorff space is $\sigma$-compact?,"['general-topology', 'separable-spaces', 'compactness']"
96370,Cayley-Hamilton theorem on square matrices,"Can anyone help me by giving the proof of the Cayley-Hamilton theorem? It states that every square matrix $A$ satisfies its own characteristic equation: $$p_{A}(A) = 0$$ I could prove it when $A$ has distinct eigenvalues, because then it will have $n$ linearly independent eigenvectors, but I couldn't prove the general case.","['matrices', 'linear-algebra', 'cayley-hamilton']"
96372,How to calculate percentage of comment lines in a code?,I have a file within which I have 6 lines of code and 8 lines of comment. What's the formula to calculate how much percent of the whole file comments have?,"['fractions', 'arithmetic', 'algebra-precalculus']"
96392,First-order vs. set-theoretic group theory,"I have two definitions from Wikipedia: The usual set-theoretic definition of a group at: http://en.wikipedia.org/wiki/Glossary_of_group_theory The first-order definition of a group at: http://en.wikipedia.org/wiki/List_of_first-order_theories#Groups No domain of quantification is given in 2. Was this deliberate? Are the quantifiers there, as some have suggested to me, truly unbounded? Are they really talking there about an operator defined on every real and imagined object in the universe? Is first order group theory a separate field of study from set-theoretic group theory? If so, are there any important results in first order group theory than cannot be obtained in set-theoretic group theory.","['logic', 'group-theory']"
96395,Generators of the ring of sections of a line bundle,"This is probably a really simple question, but I never really studied classical algebraic geometry, and so I don't know where to start looking. Suppose $X$ is a smooth projective algebraic curve over a field $k$, and $\mathcal{L}$ a line bundle on $X$. Then I can consider the graded ring of sections $R(\mathcal{L}) = \bigoplus_{n \ge 0}H^0(X, \mathcal{L}^{\otimes n})$. How can I determine (in terms of $\mathcal{L}$) an $N$ such that $R(\mathcal{L})$ is generated as a $k$-algebra by elements of degree $\le N$? Also, what if $X$ is a smooth proper curve over $\mathbb{Z}_p$, and we ask instead for $\mathbb{Z}_p$-generators of the ring of sections?",['algebraic-geometry']
96400,"$\mathbb{Q}[x,y]/\langle x^2+y^2-1 \rangle$ is an integral domain, and its field of fractions is isomorphic to $\mathbb Q(t)$ [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question How can I prove that $\mathbb{Q}[x,y]/\langle x^2+y^2-1 \rangle$ is an integral domain? Also, I need to prove that its field of fractions is isomorphic to the field of rational functions $\mathbb{Q}(t)$ ? (The question is taken from UC Berkeley Preliminary Exam, Fall 1995. )","['commutative-algebra', 'ring-theory', 'irreducible-polynomials', 'abstract-algebra']"
96414,Computing contractions of ideals in Macaulay2,"Does Macaulay2 compute contractions of ideals under ring homomorphisms. Specifically, if $R\subseteq S$ is a ring extension (say polynomial rings over $\mathbb{Q}$ which can be specified in M2) and $I$ is an ideal in $S$ given by generators, is there a command to compute $I\cap R$? EDIT: The eliminate command is supposed to do what I want, except when I use it the output is an ideal in the original ring.","['macaulay2', 'symbolic-computation', 'abstract-algebra', 'math-software', 'commutative-algebra']"
96416,What is the relationship between the Poisson Distribution and the Monte Carlo Fallacy?,"Gravity's Rainbow has this long passage about the Poisson distribution. Since Pynchon's education included a serious dose of mathematics, and his novels include many references to mathematics, I assume what the characters are saying to each other must make some sort of sense, i.e. must have a formulation in mathematical language. But what exactly are they describing? What is the Monte Carlo Fallacy, and what does it have to do with the Poisson Distribution? The two characters are looking at a grid which represents London. Places where bombs have hit are marked on the grid. Further up in the dialogue, the grid is compared to a sieve the Romans would have used for fortune-telling. ""Can't you . . . tell,"" Pointsman offering Mexico one of his Kyprinos
Orients, which he guards in secret fag fobs sewn inside all his lab
coats, ""from your map here, which places would be safest to go into,
safest from attack?"" ""No."" ""But surely!"" ""Every square is just as
likely to get hit again. The hits aren't clustering. Mean density is
constant."" Nothing on the map to the contrary. Only a classical
Poisson distribution, quietly neatly sifting among the squares exactly
as it should . . . growing to its predicted shape. . . . ""But squares
that have already had several hits, I mean!"" ""I'm sorry. That's the
Monte Carlo Fallacy. No matter how many have fallen inside a
particular square, the odds remain the same as they always were. Each
hit is independent of all the others. Bombs are not dogs. No link. No
memory. No conditioning.""","['statistics', 'monte-carlo', 'popular-math']"
96420,Why is this limit said to equal some value rather than approach that value?,"I have rewritten this entire question, since what I've learned since asking it requires me to restate it.  I want to get rid of the obfuscating revisions. Let's say that f is a continuous function. $f(x)$ approaches L as x approaches a. So $\lim\limits_{x \to a}f(x) = L$ When it's said that the gradient of a tangent line to a curve at some particular point has some particular value, this is the same as saying f(a)=L.  But without explicitly evaluating at that point, you can't say as much.  All you can say is what happens as you approach that value.  In other words, you can only say what value $f(x)$ approaches as $x$ approaches $a$, you can't say what $f(a)$ is. Is that true? Some textbooks will just say that the value of $f(a)=L$.  Sal Khan's explanation does this.  He says, about the function as it approaches the limit, ""this is the gradient of the tangent.""  I'm saying that it should be said that, ""the derivative approaches the gradient of the tangent to the curve.""  I think ""approaches"" and ""is"" are very different. If there is a way to prove that the $f(a)=L$ then I'd like to see it.  I don't know how to do this yet.","['calculus', 'derivatives', 'limits']"
96423,Cycle attack on RSA,"Let $p$ and $q$ be large primes, $n=pq$ and $e : 0<e<\phi(n), \space gcd(e, \phi(n))=1$ the public encyption exponent, $d : ed \equiv 1 \space (mod \space \phi(n)) $ the private decription exponent, and $m \in \mathbb{Z_n}$ the plaintext, in an $RSA$ cryptosystem. Suppose Eve wants to read the ciphertext $\mu= m^e$ (suppose she can tell when an element of $\mathbb{Z_n}$ is the plaintext), she comes up with the following attack: compute $m^{e} \left(\mod n \right)$, $m^{e^2} (\mod\space n)...$ and so on untill, for some $k: \space$ $m^{e^k} = m$ Notice that such $k$ exists, as $e$ can be considered an element of the multiplicative group $\mathbb{Z_{\phi(n)}}^\times$ and therefore $e^{-1}\in<e>\leq\mathbb{Z_{\phi(n)}}^\times$. I found this attack to be called the cycle attack but it isn't mentioned in any cryptography textbooks I know of, and therefore I'm guessing it isn't much of a a threat to $RSA$. Having said this, my questions are: How can we justify that the attack is computationally infeasible, even when $e$ is chosen at random? We know $k=|e|$ , and that $|e|$  divides $ |\mathbb{Z_{\phi(n)}}^{\times}|=$$\phi(\phi(n))=\phi((p-1)(q-1))$ , but do we know anything about the expected value for $|e|$ (for example, by deducing it from the structure, and in particular from the distribution of orders of elements of $\mathbb{Z_{\phi(n)}}^{\times}$)? Is there an efficient algorithm to chose $e$ such that its order in $\mathbb{Z_{\phi(n)}}^{\times}$ is sufficiently large (although this doesn't seem to be necessary)? I also posted this thread in the cryptography section, you can view it here","['group-theory', 'cryptography']"
96429,Matrix Representation of Octonions,"Since quaternions $\mathbb{H}$ have a matrix representation as elements of $\text{SU}(2,\mathbb{C})$ as the following $$   1 \mapsto \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix},\quad \mathrm i \mapsto \begin{pmatrix} \mathrm i_{\mathbb C} & 0 \\ 0 & -\mathrm i_{\mathbb C} \end{pmatrix},\quad \mathrm j \mapsto \begin{pmatrix} 0 & 1 \\ -1 & 0 \end{pmatrix},\quad \mathrm k \mapsto \begin{pmatrix} 0 & \mathrm i_{\mathbb C} \\ \mathrm i_{\mathbb C} & 0 \end{pmatrix}, 
$$
I always wondered if there is also matrix representation of the octonions? How is the non-associativity realised with matrices?","['matrices', 'quaternions', 'octonions', 'representation-theory']"
96436,Prove that for any infinite poset there is an infinite subset which is either linearly ordered or antichain.,"Let $(X, \leq)$ be an infinite poset. Prove that there is an infinite $X' \subset X$ for which holds one of the following: 1) Induced order on $X'$ is linear. 2) $(X', \leq_\mathrm{ind})$ is antichain. (Every two elements in $X'$ are incomparable) My attempt: Let's start trying to construct a linearly ordered set $(X', \leq_\mathrm{ind})$ element by element. First we take some element $x_1 \in X$, then we take another $x_2 \in X$ such as $x_1 \leq x_2$ or $x_2 \leq x_1$. Basically, we take an element from $X$, if it is ""good"" we put it in our chain, otherwise we throw it away. We continue constructing the chain that way. If we do not stop at some finite step, then we are done, we have constructed linearly ordered subset. If we do stop at some $x_n$ that means that we have finite amount of comparable elements, which means that $X \setminus X'$ is an antichain. a) I am not sure about the soundness in the last step, could somebody please check it? b) Can this be proved without a choice function?","['axiom-of-choice', 'elementary-set-theory', 'order-theory']"
96437,Erdős and the limiting ratio of consecutive prime numbers,"The following is a piece of math lore from the late forties, which was described in an Intelligencer article entitled ""The Elementary Proof of the Prime Number Theorem"" . It reads: Turán, who was eager to catch up with the mathematical developments that had occurred during the war, talked with Selberg about his sieve method and his now famous inequality.He tried to talk Selberg into providing a seminar, showing the power of his inequality by giving an elementary proof of Dirichlet’s Theorem on primes in arithmetic progressions; but Selberg, who was busy with other research and was also looking for a permanent academic position, declined. He suggested that Turán present the seminar, using the notes he had made for himself from
  his conversations with Selberg. Turán went through with this and afterwards, much to everyone's apparent incredulity, Erdős remarked ""I think you can also derive $\frac{p_{n+1}}{p_n} \to 1$, referring to the aforementioned inequality of Selberg."" (And, lo and behold, Erdős was able to do just that) Two questions: (1) what inequality exactly is being referred to here?, and (2) how is Erdős's result deduced? ADDENDUM:
Here was the reason for my confusion. The formula (Selberg's identity) appears very early on in the paper. Then, several pages later we have ""...talked with Selberg about his sieve method and now famous inequality"" and then in the next paragraph Erdős claims to be able to derive the result from ""the inequality"". This suggested to me that the referenced inequality had nothing to do with the first identity, but it was instead some well-known sieve-theoretic namesake of Selberg. (Forgive my complete lack of knowledge of sieve theory, but it seemed as if there was nothing sieve-like about the identity, which is why I did not make the connection.)","['prime-numbers', 'analytic-number-theory', 'sieve-theory', 'number-theory']"
96438,Can a limit exist if there are paths to the limit point where the function is not defined?,"For example, does the limit of $f(x,y) = \frac{bxy}{xy}$ for any constant $b$ exist for $(x,y) \to (0,0)$? Does the fact that for $x=0$ and $y=0$ you have a problem with deviding by zero imply that there is no limit?
Or could you extend the definition of a limit with ""for all $x$ and $y$ in the domain of $f$...""? In fact, this question arose from the following question: For which constants $a$, $b$ and $c$ does the limit $(x,y) \to (0,0)$ exist for $f(x,y) = \frac{ax^2+bxy+cy^2}{xy}$? When approaching $(0,0)$ through lines $y=mx$, it turns out that the limit depends on $m$ if not both $a$ and $c$ are $0$. So the first condition for the existing of a limit is that both $a$ and $c$ are $0$. That leaves the question for which $b$ the limit $(x,y) \to (0,0)$ exist for $f(x,y) = \frac{bxy}{xy}$. And this is where we started doubting the solution. We found 3 approaches, which we don't know is the right one. Can you simply say: Hey, $f(x,y) = \frac{bxy}{xy}$ simply results to $b$, so the limit exists for every $b$ (and equals $b$)? Or should you say: $f(x,y) = b$ for $x \ne 0$ and $y \ne 0$, and $f(x,y)$ is undefined for $x = 0$ or $y = 0$. And this makes the limit nonexistent, because for pairs $(x,y)$, even though close to $(0,0)$, you cannot guarantee anything about $|f(x,y)-b|$ because if either $x = 0$ or $y = 0$ the function isn't even defined properly.  Or is it the case that: $f(x,y) = b$ for $x \ne 0$ and $y \ne 0$, and $f(x,y)$ is undefined for $x = 0$ or $y = 0$. And this is no problem, the limit still exists for every $b$ (and is $b$)?",['limits']
96451,How to calculate the expectation of $XY$?,"Suppose I am given the joint pdf of $X$, $Y$, and I am asked to find the $\operatorname{cov}(X,Y)$. I know that $\operatorname{cov}(X,Y)=E(XY)-E(X)E(Y)$ and I know how to find $E(X)$ and $E(Y)$. My questions are: What is the definition of $E(XY)$? Is it always equal to $$\int_{R\times R} xyf_X(x)f_Y(y)dxdy\,?$$ 
Or only if $X$, $Y$ are independent?(from the answer I have, the solution I have did not check the independence of $X$ and $Y$, and the answer $\operatorname{cov}(X,Y)$ is not zero, which proves $X$, $Y$ are not independent.) I remember, but not very clearly, that if the joint pdf of $X$, $Y$ $f_{X,Y}(x,y)$ can be written as $$f_{X,Y}(x,y)=g(x)h(y),$$
then $X$ and $Y$ are independent. Is it always true or need some conditions? I mean, suppose the region is not, say, $[0,1]\times[0,1]$, but, say, $0<x<1,x<y<2x$, is that saying still true? Thank you so much!",['probability']
96459,Finding limit for the function,"I have problem with showing that the limit of the following function $$\frac{
 \sqrt{\frac{3 \pi}{2n}} -
 \int_0^{\sqrt 6}(
 1-\frac{x^2}{6}
 +\frac{x^4}{120})^ndx}{\frac{3}{20}\frac 1n \sqrt{\frac{3 \pi}{2n}}}$$ equal to $1$, with $n \to \infty$.","['calculus', 'limits']"
96467,What is the Bruhat decomposition of the affine Grassmannian?,"We define the affine Grassmannian to be the quotient $Gr = GL_n(\mathbb{C}((t)))/GL_n(\mathbb{C}[[t]])$ where $\mathbb{C}((t))$ is the field of formal Laurent series and $\mathbb{C}[[t]]$ is the ring of formal power series. (The affine Grassmannian can be defined more generally, but here we restrict to a special case.) If we let $B$ be the Borel subgroup of upper triangular matrices in $GL_n(\mathbb{C})$, $T$ a maximal torus, then the Weyl group $W=N(T)/T$ is just $S_n$. Let $\widetilde{W} = \mathbb{Z}^{n-1}  \rtimes W$ denote the affine Weyl group. Then for $i = 1, 2,...,n-1$ the affine permutations in $\widetilde{W}$ correspond to the usual permutation matrices in $GL_n(\mathbb{C})$, namely the identity matrix with columns $i$ and $i+1$ interchanged. The matrix for the affine permutation $s_0$ has ones along the diagonal in rows $2, 3, ..., n-1$, has $t$ in the right hand corner, and $t^{-1}$  in the bottom left corner. Let $I$ denote the Iwahori subgroup, that is, the inverse image of $B$ under the reduction map $GL_n(\mathbb{C}((t))) \rightarrow GL_n(\mathbb{C})$. Then $I$ is the set of upper triangular matrices mod $t$. I read somewhere that $GL_n(\mathbb{C}((t)))$ has a decomposition $GL_n(\mathbb{C}((t))) = \cup IwGL_n(\mathbb{C}[[t]])$ where $w$ varies across the affine permutation matrices. This decomposition is supposed to induce the Bruhat decomposition of the affine Grassmannian into Schubert cells. Now something here is wrong. Since $I \subset GL_n(\mathbb{C}[[t]])$, and the determinant of any affine permutation matrix is 1 or -1, we have that for any $w \in \widetilde{W}$ the determinant of any matrix in $IwGL_n(\mathbb{C}[[t]])$ has power series determinant, but the matrix $\left(\begin{array}{cc}
t^{-1} & 0 \\

0   & t^{-1} \\
\end{array}\right)$ is in $GL_n(\mathbb{C}((t)))$ with determinant $t^{-2}$ and inverse $\left(\begin{array}{cc}
t &  0 \\

0 & t \\
\end{array}\right).$ So, my question is, what is wrong here? What is the correct decomposition and indexing set?","['schubert-calculus', 'algebraic-geometry', 'combinatorics']"
96481,Motivation for a particular integration substitution,"In an old Italian calculus problem book, there is an example presented: $$\int\frac{dx}{x\sqrt{2x-1}}$$ The solution given uses the strange substitution $$x=\frac{1}{1-u}$$ Some preliminary work in trying to determine the motivation as to why one would come up with such an odd substitution yielded a right triangle with hypotenuse $x$ and leg $x-1;$ determining the other leg gives $\sqrt{2x-1}.$  Conveniently, this triangle contains all of the ""important"" parts of our integrand, except in a non-convenient manner. So, my question is two-fold: (1)  Does anyone see why one would be motivated to make such a substitution? (2)  Does anyone see how to extend the work involving the right triangle to get at the solution?",['calculus']
96497,How do we justify certain steps in the solution to gambler's ruin?,"The problem of gambler's ruin asks the following: suppose a player begins with $k$ units of money, $0<k<N$. Each turn he flips a coin and either gains a unit of money with probability $p$ or loses a unit of money with probability $1-p$. The game ends when he reaches $N$ and wins or $0$ in which case he loses the game. What is the probability of losing? The usual solution, which you can find for example on http://en.wikipedia.org/wiki/Gambler%27s_ruin or in Grimmett & Stirzaker - Probability and Random processes, page 17, proceeds by constructing a linear difference equation using the fact (using the notation from wikipedia) that $P(R_n|H)=P(R_{n+1})$ where $R_n$ is the event ""that the player is ruined having started with $n$ units of money"" and $H$ is the event ""of winning the first flip"". What event exactly is $R_n$? Is it correct to consider $H$ to be a single event or should we take a separate event for every coin flip? The approach taken by Grimmett and Stirzaker seems conceptually the same, but instead of using a single probability measure, they use $P_k$ - the probabilities calculated relative to the starting point $k$. Then they use the equation $P_k(A) = P_k(A|B)P(B) + P_k(A|B^C)P(B^C)$, where A is the event of losing the game and B is the event of winning the first flip. I am not completely sure what they mean by $P$, my best guess is that because the probability of $B$ is independent of $k$, they just drop the index. Next they use the fact that $P_k(A|B) = P_{k+1}(A)$ which looks essentially as expressing the same relation as the equation with $R_n$ before. Anyway, I haven't been able to completely justify this relation theoretically, so here comes my main question: How exactly do we justify $P(R_n|H)=P(R_{n+1})$ and $P_k(A|B) = P_{k+1}(A)$? I have tried translating this problem to a more familiar measure-theoretical language, using $\Omega = \lbrace-1,1\rbrace^\mathbb{N}$ as the underlying sample space and defining $M:\lbrace-1,1\rbrace^\mathbb{N}\times\mathbb{Z}\to\mathbb{N}\cup\lbrace\infty\rbrace,$ $M(f,k) = \min\lbrace m\in\mathbb{N}|\sum_{i=1}^m f(i) = k \rbrace$ (where $\min\emptyset := \infty$), which then enables us to define $R_n = \lbrace f\in\Omega|M(f,-n) < M(f,N-n)\rbrace$ and $H = \lbrace f\in\Omega|f(1) = 1\rbrace,$ but this hasn't given me any new intuition and may not even be the correct formalization. It seems increasingly likely that I am missing some implicit assumption in the statement of the problem that is obvious to probabilists but not so much to me ... In this case: What exactly is this assumption?","['measure-theory', 'probability']"
96518,How to justify this differential manipulation while integrating?,"Some time ago I had a physics test where I had the following integral: $\int y'' \  \mathrm{d}y$. The idea is that I had a differential equation, and I had acceleration (that is, $y''$) given as a function of position ($y$). The integral was actually equal to something else, but that's not the point. I needed to somehow solve that. I can't integrate acceleration with respect to position, so here's what I did: $$
\int y'' \ \mathrm{d}y = 
\int \frac{\mathrm{d}y'}{\mathrm{d}t} \ \mathrm{d}y = 
\int \mathrm{d}y' \frac{\mathrm{d}y}{\mathrm{d}t} = 
\int y' \ \mathrm{d}y' = \frac1{2}y'^2 + C
$$ My professor said this was correct and it makes sense, but doing weird stuff with differentials and such never completely satisfies me. Is there a substitution that justifies this procedure?","['calculus', 'integration', 'physics']"
96541,Connected metric spaces with at least 2 points are uncountable.,"That's a problem I proved (quite a while back) in tiny Rudin. However, I don't really get it. The other questions were actually useful results - I don't think I've ever come near using this result. Surely it's going to be close to apparent that you're working in an uncountable set? For instance, examples where this result could be applied but it is hard otherwise to tell that the space is uncountable?","['general-topology', 'connectedness', 'metric-spaces', 'examples-counterexamples']"
96549,Factorial division using Pascal's triangle.,"I want to get values of factorial divisions such as 100!/(2!5!60!) (the numbers in the denominator will all be smaller than the numerator, and the sum of the denominators(numbers without factorial) can be at max 100) etc. I read in a forum that a Pascal's triangle can be used for calculating such results, but a lot of searching didn't tell me how to do so. It is actually for a programming problem, and I tried using the lgamma function to calculate the value, but that gives an error as I need a lot of precision. So what could be used to calculate such factorial divisions?","['factorial', 'spoj', 'binomial-coefficients', 'combinatorics']"
96563,Error When Using Mathematica To Solve Differential Equation,"I have a concern of why mathematica does not like/except the independent variable x . When it is used it gives the following error: In[1]:= DSolve[{2 x''[t] + $6$ x'[t] + 5 x[t] == 0, x[0] == 10, x'[0] == 0}, x[t], t] Gives DSolve::deqn : $\hspace{0.2cm}$ Equation or list of equations expected instead of True in the first argument $\hspace{0.9cm}$ {$11$x[t]+$2$x''[t] == $0,~$ x[$0$]==$10,~$True}. Out[1]= DSolve[{$11$x[t]+$2$x''[t]==$0,~$ x[$0$]==$10,~$ True}, x[t],$\:$ t] But when the variable is switched out for another, you obtain the solution as expected like so: In[2]:= DSolve[{2 s''[t] + 6 s[t] + 5 s[t] == 0, s[0] == 10, s'[0] == 0}, s[t], t] Out[2]= $\Bigl\{\Bigl\{s\Bigl[t\Bigr] \rightarrow \text{10 Cos}\left[\sqrt{\dfrac{11}{2}}t \right]\Bigr\}\Bigr\}$ What could be the cause of this? Note: I also cleared the variable from memory just to be on the safe side.","['ordinary-differential-equations', 'mathematica']"
96567,Nails and strings and paintings,"This question is based on the ""Picture proof"" challenges from Rankk.org ... IDEA: You want to hold up a painting using nails on a wall and string. The string is attached to the left and right sides of the painting and the nails are in between (let's say in a horizontal straight line for simplicity). QUESTION: The object is to find ways of doing this to satisfy various requirements. For example, so that if any one nail is taken out, it will fall. Or so that if any two nails (but not one) are taken out it will fall. In particular, I want to find short solutions or even a method to construct all possible solutions. Basically, what exactly is the mathematical structure and what are the main results or whatever. VISUALS: Here I use capitals for the inverses. THEORY: First nomenclature. Let's say we have three nails: $a$, $b$ and $c$. If we pass over the first nail rightwards, we call that $a$, but if we go over it leftwards, we call that $a^{-1}$. Then if we conatenate or multiply them, it means we do one after another. So for example, $abc$ corresponds to the string going across over the top of all the three nails from left to right. In that case, all three nails would need to be removed before the painting fell. Something like $aba^{-1}$ means it's looped around $b$ but sort of hanging on $a$ as well. Only $b$ needs to be removed for it to fall. Obviously $aa^{-1}$ cancels out. And $a^5$ means a bunch of loops. Removing a nail simply means removing all of its appearances in the formula. The painting will fall if the whole thing reduces to the identity. Eg) $bca^{-1}cac$ becomes $bc^3$ if the $a$ nail is taken out. Perhaps the most powerful tool I've found is that you can use a kind of conjugation as an ""or"" operator. It entangles the two parts. For example, $aba^{-1}b^{-1}$ will fall if either $a$ or $b$ are removed. The complement ""and"" operator is just multiplication. So $abcb^{-1}a^{-1}c^{-1}$ is $ab$ conjugated with $c$ and will fall if $c$ is removed or both $a$ and $b$. As a starting point, who can find a short string for four nails that falls if any two are taken out? PS. I can give more examples...","['algebraic-topology', 'group-theory']"
96571,Find a sum of appropriate values of $\cos$ and $\sin$ to determine the value of a series,"The task is to find a sum of multiple values $\cos$ and $\sin$ to determine the value of 
$$\sum_{n=1}^\infty (-1)^n \frac{n}{(2n+2)!}$$ Since I had no clue how to approach this I consulted Wolfram|Alpha which returned this result: $$\sum_{n=1}^\infty (-1)^n \frac{n}{(2n+2)!} = \frac{\sin(1)}{2} + \cos(1) - \cos(0)$$ So I wrote down the partial sums of the given series and $\sin(1)$ and $\cos(1)$: $$
\qquad\qquad\quad\sum_{n=1}^\infty (-1)^n \frac{n}{(2n+2)!} = \quad - \frac{1}{4!} + \frac{2}{6!} - \frac{3}{8!} \cdots
$$ $$
\;\;\sin(1) = \sum_{n=0}^\infty (-1)^n \frac{1^{2n+1}}{(2n+1)!} = 1 - \frac{1}{3!} + \frac{1}{5!} - \frac{1}{7!} \cdots
$$ $$
\cos(1) = \sum_{n=0}^\infty (-1)^n \frac{1^{2n}}{(2n \qquad)!} = 1 - \frac{1}{2!} + \frac{1}{4!} - \frac{1}{6!} \cdots
$$ Looking at the numbers I can see that Wolfram|Alpha's result is correct: $\frac{1}{2}1 -  \frac{1}{2!} = 0$ and $\frac{1}{2}\frac{-1}{3!} + \frac{1}{4!} = \frac{1}{4!}$, so the $\cos(1)$-series is shifted by $1$ since there is no $1$ at the beginning of the given series, so it needs to be subtracted from $\cos(1)$: $-cos(0)=-1$. But how do I get here without Wolfram|Alpha?",['sequences-and-series']
96583,What is the sum of the series $\sum \limits_{k=0}^\infty q^{2^k}$ if $|q|\lt1$,"I wonder if anybody knows how to calculate the series below?
$\sum \limits_{k=0}^\infty q^{2^k}$ if $|q|\lt1$? Thanks a lot for answers.","['sequences-and-series', 'complex-analysis']"
96591,solving equation of circles,"I have two points on a circle from which I want to find the center of the circle. I also know the radius $r$ . I am trying to solve two equations but not able to find the centre $(C_x,C_y)$ . Can someone check what I am doing wrong? $(A_x - C_x)^2 + (A_y - C_y)^2 = r^2$ $(B_x - C_x)^2 + (B_y - C_y)^2 = r^2$ Solving 1 first, I got $-C_x^2 = r^2 - A_x^2 - A_y^2 + C_y^2$ Putting this value in eq. 2, I got nothing ... how to find $C_x$ and $C_y$ then? $B_x^2 - A_x^2 - A_y^2 + B_y^2 = 0$ these are the values I already know...","['geometry', 'algebra-precalculus', 'solution-verification', 'analytic-geometry', 'circles']"
96593,Idempotency of difference of two idempotent matrices,"Define $$
\mathbf{H}=\mathbf{X}\left(\mathbf{X}^{\prime}\mathbf{X}\right)^{-1}\mathbf{X}^{\prime}
$$ where $\mathbf{X}$ is of order $n \times k$ and $$
\overline{\mathbf{J}}=\frac{1}{n}\mathbf{J}=\frac{1}{n}\mathbf{1}\mathbf{1}^{\prime}
$$ where $\mathbf{1}$ is a unit vector of order $n \times 1$. Now
$$
\mathbf{H}\mathbf{H}=\mathbf{H}
$$ and $$
\overline{\mathbf{J}}\overline{\mathbf{J}}=\overline{\mathbf{J}}
$$ Thus both $\mathbf{H}$ and $\overline{\mathbf{J}}$ are idempotent matrices. My question is whether $\mathbf{H}-\overline{\mathbf{J}}$ would be idempotent. If so then $$
\left(\mathbf{H}-\mathbf{\overline{\mathbf{J}}}\right)\mathbf{\left(\mathbf{H}-\mathbf{\overline{\mathbf{J}}}\right)}=\mathbf{H}-\mathbf{H\overline{\mathbf{J}}-\overline{\mathbf{J}}H}+\overline{\mathbf{J}}=\mathbf{H}-\mathbf{\overline{\mathbf{J}}-\overline{\mathbf{J}}}+\overline{\mathbf{J}}=\mathbf{H}-\overline{\mathbf{J}}
$$ But I'm not able to show that $$
\mathbf{H\overline{\mathbf{J}}=\overline{\mathbf{J}}H}=\overline{\mathbf{J}}
$$ I'd highly appreciate if you guide me to figure this. Thanks for your time and help.","['matrices', 'linear-algebra']"
96599,Scalar Product for Vector Space of Monomial Symmetric Functions,"Suppose a multinomial $P(X_1, X_2,\ldots, X_n)$, that is given as a sum of monomials $m_\lambda$ with coefficients $c_k$:
$$
P(\vec{X})=P(X_1, X_2,\ldots, X_n) = \sum_k c_k m_{\lambda_k} .
$$ Since the monomials form a basis of the vector space of multinomials, there is also a scalar product 
$$
c_k=\frac{1}{N}\langle m_{\lambda_k} \mid P\rangle,
$$
where $N=\langle m_{\lambda_k}\mid m_{\lambda_k}\rangle$ would be a normalization constant. My question is: Does the Scalar Product, such that the $m_λ$ are mutually orthogonal or better orthonormal, have an elementary expression? An application could allow calculation of Kostka number, since 
$$
s_{\lambda} = \sum K_{\lambda\mu} m_\mu,
$$ 
where $s_\lambda$ is a Schur polynomial. If this is an efficient way or not, is a different question. First I thought that I had to deal with something like square integrable functions , but then I found what I posted below $\dots$","['vector-spaces', 'multivariable-calculus', 'inner-products', 'symmetric-functions', 'polynomials']"
96606,How to prove $\lim\limits_{n \to \infty} (1+\frac1n)^n = e$?,"How to prove the following limit?
  $$\lim_{n \to \infty} (1+1/n)^n = e$$ 
  I can only observe that the limit should be a very large number! Thanks.","['exponential-function', 'calculus', 'real-analysis', 'limits']"
96613,Computing a volume (area) of intersections,"The task should be very common, what are the best and easiest to implement algorithms to compute the volume of union/intersection of given bodies? Or union/intersection area for 2D figures. I don't mean straightforward integration to get the volume, it shouldn't be very convenient. I was thinking about some kind of naive Monte Carlo (the ratio of hit to thrown points), but it has very poor convergence. Or maybe approximating bodies as unions of simpler ones, for which the intersections are known, though it's (a bit) complex.","['geometry', 'computational-geometry', 'numerical-methods']"
96616,how many smaller circles(radius is equal) I can fit within a larger circle,"then the question is,the larger radius D,the small radius d,get the largest number of small circle put in the larger?","['geometry', 'packing-problem']"
96620,An hermitian operator problem,"It is possible to have two hermitian operators $A$ et $B$, with : $B^2 = \mathbb{I}d$ $[A,B] = i * \mathbb{I}d$ where $i$ is the usual (complex) square root of $(-1)$, and $\mathbb{I}d$ is the identity operator ? (I think that A is necessarily not bounded, due to the last condition) If it is possible, may we exhibit a explicit representation of these operators $A$ and $B$ ?","['representation-theory', 'operator-theory', 'linear-algebra', 'spectral-theory', 'functional-analysis']"
96628,How to get sine / cosine value out of tangens,I know that: $\tan(\alpha) = 1/2$. How can I get clean values for sine / cosine without the calculator ? Is there a relationship? I know that $\sin(\arctan(1/2))$ is a way ... But I hope you get the point. Thank you!,['trigonometry']
96629,Implementation of the Baum-Welch algorithm for HMM parameter estimation,"In order to learn HMM thoroughly, I am implementing (in Matlab) the various algorithms for the basic questions of HMM. I've implemented the Viterbi, posterior-decoding, and the forward-backward algorithms successfully, but I have one question regarding the Baum-Welch algorithm for the estimation of the HMM parameters. In the classic paper by Rabiner , the re-estimation of the transition probabilities matrix is given in equation (95), in terms of the scaled forward ($\hat\alpha$) and backward ($\hat\beta$) variables. The numerator is
$$
\sum_{t=1}^{T-1}\hat\alpha_t(i)a_{ij}b_j(O_{t+1})\hat\beta_{t+1}(j)
$$
where $a$ is the transition matrix, $b$ the observation matrix, and $O$ the observation sequence. However, in this HMM project guide , section 4.4, (also by Rabiner), as well is in the implementation in Matlab's function hmmtrain.m (from the statistics toolbox), there is an extra factor of $1/c_{t+1}$ in the numerator, where $c_t$ is the scaling factor of time step $t$. I followed the algebra of the definition of the re-estimation of $a$, and I still fail to understand where this factor is coming from. Any help is appreciated.","['machine-learning', 'probability', 'algorithms']"
96632,Do the digits of $\pi$ contain every possible finite-length digit sequence? [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: Prove there are no hidden messages in Pi This is not a practical problem. I am asking out of curiosity.  Any links/references are most welcome. Say, we write the digits of $\pi$ in base $10$.  Does this sequence of digits contain every possible finite length digit sequence?  What about $e$, $\sqrt{2}$ or some other commonly known irrational numbers? Is this property of numbers independent of base?  If a number has this property when written in base $10$, will it also have it in base $2$, $3$ and all other bases?","['pi', 'decimal-expansion', 'sequences-and-series']"
96644,quadratic reciprocity,"happy new year I have this statement:
""By quadratic reciprocity there are the integers $a$ and $b$ such that $(a,b)=1$, $(a-1,b)=2$, and all prime $p$ with $p\equiv a$ (mod $b$) splits in $K$ (where $K$ is a real quadratic field)"". I have tried with many properties of quadratic reciprocity but couldn't even get to the first conclusion. Thank you very much in advance, for any idea or advice for approach the problem","['quadratic-reciprocity', 'elementary-number-theory', 'number-theory']"
96646,What's the connection between derivatives and boundaries?,"The (second) fundamental theorem of calculus says that $$\int_a^b f'(x) dx = f(b) - f(a)$$ which can also be stated, if one knows enough about what's coming next, as: The integral of the derivative of a function over an interval is the same as the function evaluated at the (signed) boundary of the interval. where I had to insert the word 'signed' to make it clear that there's an implicit multiplication by $-1$ when you evaluate the function at the 'bottom' end of the integral. If we wrote the right-hand side of the expression as $$f(b) + (-1) f(a)$$ then even a high-school student could probably be persuaded that this is the same as 'integrating' $f$ over the two points $b$ and $a$, with a multiplication by $-1$ attached to the evaluation at $a$. The generalization of this is the generalized Stokes theorem: $$\int_C dw = \int_{\partial C} w$$ where $w$ is a differential form , $d$ is the exterior derivative , $C$ is a manifold on which $dw$ is defined, and $\partial$ is the boundary operator, which maps a manifold $C$ to its boundary. This can be made to look pretty suggestive by writing integration of a form over a manifold using inner product notation: $$\langle C, w \rangle \equiv \int_Cw$$ in which case Stokes' theorem becomes $$\langle C, dw \rangle = \langle \partial C, w \rangle$$ which looks suspiciously like $\partial$ is the Hermitian adjoint of $d$. But is that really the case? Differential forms and manifolds seem pretty different to me. If they are, in fact, related in this way, is there a theory which expounds upon this relation, generalizes it, or puts it in context with other areas of mathematics?","['calculus', 'differential-geometry', 'manifolds', 'exterior-algebra', 'intuition']"
96649,How to cover an open subset of $\mathbb{R}^n$ with balls?,"I am trying to solve the following exercise: If $U$ is an open subset of $\mathbb{R}^n$, show that there exists an increasing sequence $\{A_k\}^\infty_1$ of compact contented sets such that $U=\bigcup^\infty_{k=1}\ \mathrm{int}\ A_k$. Hint: Each point of $U$ is contained in some closed ball which lies in $U$. Pick the sequence in such a way that $A_k$ is the union of $k$ closed balls. It seems ""increasing sequence"" means that $A_k \subset A_{k+1}$ for all $k$. Now, I think the hint says that $A_{k+1}$ should be $A_k \cup B_{k+1}$ for some suitable ball $B_{k+1}$, starting with $A_1 := B_1$. But I don't see a way to choose those balls so that eventually all points of $U$ are covered?",['general-topology']
96657,Continuous extension of a uniformly continuous function from a dense subset.,"I'm trying to understand an alternative proof of the idea that if $E$ is a dense subset of a metric space $X$, and $f\colon E\to\mathbb{R}$ is uniformly continuous, then $f$ has a uniform continuous extension to $X$. I think I know how to do this using Cauchy sequences, but there is this suggested alternative. For each $p\in X$, let $V_n(p)$ be the set of $q\in E$ such that $d(p,q)<\frac{1}{n}$. Then prove that the intersections of the closures
$$
A=\bigcap_{n=1}^\infty\overline{f(V_n(p))}
$$
consists of a single point, $g(p)$, and so $g$ is the desired continuous extension of $f$. Why is this intersection a single point, and why is $g$ continuous? This is what I did so far. Since $f$ is uniformly continuous, for given $\epsilon>0$, there is $\delta>0$ such that $\text{diam }f(V)<\epsilon$ whenever $\text{diam }V<\delta$. Since $V_n(p)$ has diameter at most $\frac{2}{n}$, taking $n>2/\delta$ would imply 
$$
\text{diam }f(V_n(p))=\text{diam }\overline{f(V_n(p))}<\epsilon
$$
So I think $\lim_{n\to\infty}\text{diam }\overline{f(V_n(p))}=0$, which would imply $A$ consists of at most one point. I noticed that the closures form a descending sequence of closed sets, but I couldn't tell if they are bounded since $X$ is an arbitrary metric space, in order to conclude that the intersection is nonempty, and hence a single point. Lastly, why is $g$ continuous at points $p\in X\setminus E$? I was trying to think of an argument with sequences converging to $p$ since $p$ is a limit point of $E$, but got stumping on how to show $g$ is actually continuous. Thanks.","['metric-spaces', 'real-analysis']"
96662,Augmented Reality Transformation Matrix Optimization,"i am a software developer, i'm working on an Augmented Reality system. I'd like to receive some advice in order to optimize my math model. My program has to be slim and fast. Here's the situation : This is a photo of my marker: I want to find the transformation matrix that ""normalize"" the photo in order to get this: I have 4 angles coordinates of the marker: $$P{1} = (352; 90)$$
$$P{2} = (93; 384)$$
$$P{3} = (852; 283)$$
$$P{4} = (663; 677)$$ Equation to find a generic projective transformation of a point P(x,y): $$\left[\begin{array}{c}
 x' \\
 y' \\
 z' \\
 \end{array}\right]=
\left[\begin{array}{ccc}
 h_{1,1} & h_{1,2} & h_{1,3} \\
 h_{2,1} & h_{2,2} & h_{2,3} \\
 h_{3,1} & h_{3,2} & h_{3,3}
 \end{array}\right]*
\left[\begin{array}{c}
 x \\
 y \\
 1 \\
 \end{array}\right]$$ In algebric form (we don't need z' and it is divided in x' and y'):
$$x' = \frac{h_{11}x + h_{12}y + h_{13}}{h_{31}x + h_{32}y + h_{33}}$$ $$y' = \frac{h_{21}x + h_{22}y + h_{23}}{h_{31}x + h_{32}y + h_{33}}$$ Supposing that H(3,3) is 1, I can find H by solving this 8 equation by 8 variables system:
$$\left[\begin{array}{cccccccc}
 x_{1} & y_{1} & 1 & 0 & 0 & 0 & -x_{1}*x'_{1} & -y_{1}*x'_{1} \\
 x_{2} & y_{2} & 1 & 0 & 0 & 0 & -x_{2}*x'_{2} & -y_{2}*x'_{2} \\
 x_{3} & y_{3} & 1 & 0 & 0 & 0 & -x_{3}*x'_{3} & -y_{3}*x'_{3} \\
 x_{4} & y_{4} & 1 & 0 & 0 & 0 & -x_{4}*x'_{4} & -y_{4}*x'_{4} \\
 0 & 0 & 0 & x_{1} & y_{1} & 1 & -x_{1}*y'_{1} & -y_{1}*y'_{1} \\
 0 & 0 & 0 & x_{2} & y_{2} & 1 & -x_{2}*y'_{2} & -y_{2}*y'_{2} \\
 0 & 0 & 0 & x_{3} & y_{3} & 1 & -x_{3}*y'_{3} & -y_{3}*y'_{3} \\
 0 & 0 & 0 & x_{4} & y_{4} & 1 & -x_{4}*y'_{4} & -y_{4}*y'_{4}
 \end{array}\right]*
\left[\begin{array}{c}
 h_{1,1} \\
 h_{1,2} \\
 h_{1,3} \\
 h_{2,1} \\
 h_{2,2} \\
 h_{2,3} \\
 h_{3,1} \\
 h_{3,2}
 \end{array}\right]=
\left[\begin{array}{c}
 x'_{1} \\
 x'_{2} \\
 x'_{3} \\
 x'_{4} \\
 y'_{1} \\
 y'_{2} \\
 y'_{3} \\
 y'_{4}
 \end{array}\right]$$ Considering that the final marker will have mx as width and my as height, the transformations of my 4 initial points will be:
$$P'{1} = (0; 0)$$
$$P'{2} = (0; my)$$
$$P'{3} = (mx; 0)$$
$$P'{4} = (mx; my)$$ So the system, in my case, become:
$$\left[\begin{array}{cccccccc}
 x_{1} & y_{1} & 1 & 0 & 0 & 0 & 0 & 0 \\
 x_{2} & y_{2} & 1 & 0 & 0 & 0 & 0 & 0 \\
 x_{3} & y_{3} & 1 & 0 & 0 & 0 & -x_{3}*mx & -y_{3}*mx \\
 x_{4} & y_{4} & 1 & 0 & 0 & 0 & -x_{4}*mx & -y_{4}*mx \\
 0 & 0 & 0 & x_{1} & y_{1} & 1 & 0 & 0 \\
 0 & 0 & 0 & x_{2} & y_{2} & 1 & -x_{2}*my & -y_{2}*my \\
 0 & 0 & 0 & x_{3} & y_{3} & 1 & 0 & 0 \\
 0 & 0 & 0 & x_{4} & y_{4} & 1 & -x_{4}*my & -y_{4}*my
 \end{array}\right]*
\left[\begin{array}{c}
 h_{1,1} \\
 h_{1,2} \\
 h_{1,3} \\
 h_{2,1} \\
 h_{2,2} \\
 h_{2,3} \\
 h_{3,1} \\
 h_{3,2}
 \end{array}\right]=
\left[\begin{array}{c}
 0 \\
 0 \\
 mx \\
 mx \\
 0 \\
 my \\
 0 \\
 my
 \end{array}\right]$$ This model works: i tried in Matlab and Java. My question is: could it be simplified or optimized? This system has a lot of zeros, and that means that it has little ""information""... Should I change something? (I could consider mx and my equals to 1, in order to semplify the system even more. but i'd like to reduce the number of equations if it's possible)","['optimization', 'projective-geometry', 'matrices', 'linear-algebra', 'numerical-linear-algebra']"
96664,Complete space as a disjoint countable union of closed sets,"It is a consequence of Baire's theorem that a connected, locally connected complete space cannot be written
$$ X = \bigcup_{n \geq 1}\ F_n$$
where the $F_n$ are nonempty, pairwise disjoint closed sets. Does anyone know of a counter-example to this if we don't assume the space to be locally connected?","['examples-counterexamples', 'baire-category', 'general-topology', 'connectedness', 'metric-spaces']"
96666,"If $\sum_{1}^{\infty}(a_n)^3$ diverges, does $\sum_{1}^{\infty}(a_n)$?","Per the title, if $\sum_{1}^{\infty}(a_n)^3$ diverges, does this imply that $\sum_{1}^{\infty}(a_n)$ diverges? I'd appreciate hints (!) for dealing with this excercise. EDIT Per the contrapositive, it is not given that $a_n$ converges absolutely, or that it is nonnegative for all $n$. Thank you!","['divergent-series', 'sequences-and-series']"
96677,Linear span of functions,"Maybe this is something basic but I am not familiar with the term ""linear span"" and in one question it mentions the linear span of the functions $f_n(t) = e^{nt}$, $n = 0,1,2,...$ $t \in [a,b]$ What I understood is linear span is the set of linear combination of all elements but I am still unable to understand what that set is. Thank you very much.",['linear-algebra']
96689,Asymptotic behavior of a sequence given by a recurrence relation,"Original problem is to determine asymptotic behavior of ${a_i}\left( t \right)$ as $t \to \infty $ given by recurrence relations ${a_1}\left( 0 \right) = 1$ ${a_1}\left( t \right) = \frac{{2t + 1}}{{2t}}{a_1}\left( {t - 1} \right)$ ${a_i}\left( t \right) = \frac{{2t + 1}}{{2t}}{a_i}\left( {t - 1} \right) + \frac{1}{{2t}}{a_{i - 1}}\left( {t - 1} \right)$ for $i \in \mathbb{N}$. My attempt at solution: Generating function for ${a_i}$ is $\displaystyle{F_i}\left( x \right) = \frac{{{{\left( {1 - x} \right)}^{ - \frac{3}
{2}}}{{\ln }^{i - 1}}\frac{1}
{{1 - x}}}}
{{\left( {2i - 2} \right)!!}}$. If we rewrite recurrence relations in a different way: ${a_1}\left( t \right) - {a_1}\left( {t - 1} \right) = \frac{1}
{{2t}}{a_1}\left( {t - 1} \right)$ ${a_i}\left( t \right) - {a_i}\left( {t - 1} \right) = \frac{1}
{{2t}}{a_i}\left( {t - 1} \right) + \frac{1}
{{2t}}{a_{i - 1}}\left( {t - 1} \right)$ And then pretend that difference operator is differential operator ${a_1}^\prime \left( t \right) = \frac{1}
{{2t}}{a_1}\left( t \right)$ ${a_i}^\prime \left( t \right) = \frac{1}
{{2t}}{a_i}\left( t \right) + \frac{1}
{{2t}}{a_{i - 1}}\left( t \right)$ by solving a system of differential equations, we get ${a_i}\left( t \right) = \frac{{\sqrt {1 + t} {{\ln }^{i - 1}}\left( {1 + t} \right)}}
{{\left( {2i - 2} \right)!!}}$. Now we define ${G_i} = \sum\limits_{t = 0}^\infty  {\frac{{\sqrt {1 + t} {{\ln }^{i - 1}}\left( {1 + t} \right)}}
{{\left( {2i - 2} \right)!!}}{x^t}} $. It turns out that (see http://www.math.upenn.edu/~pemantle/papers/twenty.pdf , page 210-211) if ${L_i} = \frac{{{G_i}\left( x \right)}}
{{{F_i}\left( x \right)}} = \mathop {\lim }\limits_{x \to 1 - } \frac{{\sum\limits_{t = 1}^\infty  {\sqrt t {x^t}{{\ln }^{i - 1}}t} }}
{{x{{\left( {1 - x} \right)}^{ - \frac{3}
{2}}}{{\ln }^{i - 1}}\frac{1}
{{1 - x}}}} = \mathop {\lim }\limits_{x \to 1 - } \frac{{{{\left( {1 - x} \right)}^{\frac{3}
{2}}}\sum\limits_{k = 1}^\infty  {\sqrt k {x^k}{{\ln }^{i - 1}}k} }}
{{{{\ln }^{i - 1}}\frac{1}
{{1 - x}}}}$ exists and is nonzero, then $\displaystyle\mathop {\lim }\limits_{t \to  + \infty } {a_i}\left( t \right) \cdot \frac{{\left( {2i - 2} \right)!! \cdot {L_i}}}
{{\sqrt {t + 1} {{\ln }^{i - 1}}\left( {t + 1} \right)}} = 1$. For several values of ${L_i}$ this seems to be true, which strikes me as unexpected. For $i = 1$ wolfram's mathematica returns ${L_1} = \frac{{\sqrt \pi  }}{2}$, but can not evaluate other expressions. However, they are around 0.9 and rising as $i$ rises. My question is how to analytically evaluate ${L_i}$, or alternatively, disregarding the previous arguments, how to determine asymptotic behavior of a sequence ${a_i}\left( t \right)$? More generally, is it usual that the solutions of difference and corresponding differential equation (given by replacing difference operator with differential operator) have the same asymptotic behavior up to a multiplicative constant? If that is the case and such behavior is well understood, are there any textbooks about it?","['ordinary-differential-equations', 'sequences-and-series', 'asymptotics', 'generating-functions', 'limits']"
96718,number of permutations in which no two consecutive numbers are adjacent,"In how many ways can the natural numbers from 1 to 10 be arranged so that no two consecutive numbers are adjacent to each other, and how is the formula arrived at?",['combinatorics']
96722,What is the general context for entropy (information theory)?,"From Wikipedia : Let $X$ be a random variable with a probability density function $f$
  whose support is a set $\mathbb{X}$. The differential entropy $h(f)$ is defined as $$
     h(f) = -\int_\mathbb{X} f(x)\log f(x)\,dx \quad \text{i.e.} \quad \mathrm{E}_f(-\log f(X)).  $$ The discrete entropy of a discrete probability measure is also defined as $\mathrm{E}_p (-\log p(X))$, where $p$ is the mass probability function, which can be viewed as the density function with respect to the counting measure on the discrete sample space. Am I right that the concept of entropy depends on the underlying measure of the sample space, since the integrand is the density function wrt some underlying measure? If yes, what is the underlying measure on the sample space for differential entropy that Wiki refers to in the above quote? What is the/some general structure(s) defined on the sample space  for it to be meaningful to discuss entropy, more than $\mathbb{R}^n$ with Lebesgue measure being the underlying measure? Thanks and regards!","['probability-theory', 'information-theory']"
96732,Finding elements in a group ring,"Suppose we have a discrete group $G$, finite or infinite, on which we form the group algebra $\mathbb{F}_2[G]$. Suppose also that we have a map $S$: $$S : \mathbb{F}_2[G] \to \mathbb{F}_2[G]: \sum{a_g \cdot g} \to \sum{a_g \cdot g^{-1}}$$ The problem I'm trying to solve is the following : given an element $x \in \mathbb{F}_2[G]$, find all $y \in \mathbb{F}_2[G]$ such that $y \cdot S(y) = x$. For small groups $G$, we can write down a system of equations on the $a_g$ but I cannot find a general way... any help or lead appreciated !","['group-theory', 'group-rings']"
96737,"If $f: \mathbb R^n \to \mathbb R^n$ is a contraction, then $x-f(x)$ is a homeomorphism","I am stuck in following homework question. Let $f : \mathbb R^n \to \mathbb R^n$ be a uniform contraction and $g(x) = x - f(x)$. Investigate whether $g : \mathbb R^n \to \mathbb R^n$ is a homeomorphism or not. The definition of uniform contraction is as follows: $(X,d)$ is metric space. $f: X \to X$ is uniform contraction if there exists $0 <\alpha <1$ such that $d(f(x),f(y)) \leq \alpha d(x,y)$. I proved that $f$ and $g$ are continuous. But I do not have any idea about inverse of $g$. By invariance of domain, one could conclude that a bijective continuous function $h: \mathbb R^n \to \mathbb R^n$ is homeomorphism. But I do not know how I can see $g$ is bijective or not. I do not have any other idea to prove homeomorphism. Maybe it is not a homeomorphism but I can't think of any counterexample. Thank you in advance.","['fixed-point-theorems', 'real-analysis']"
96739,Do continuous linear functions between Banach spaces extend?,"Just wondering... Let $E$, $G$ be Banach spaces, let $U\subset E$ be a subset of $E$, and let $f:U\rightarrow G$ be a continuous linear function. Can $f$ be extended to a continuous linear function on $E$, $F:E\rightarrow G$? For which cases does this happen?","['general-topology', 'topological-vector-spaces', 'banach-spaces', 'analysis']"
96741,Can I multiply *into* limits?,I learned a lot yesterday and it requires me to overhaul the way I think about derivatives.  So I have something worked out but it relies on the answer to this question. EDIT : Basically I need a simple proof that says $b \cdot [\lim_{h \to a} g(h)] = \lim_{h \to a} [b\cdot g(h)]$,"['calculus', 'derivatives', 'limits']"
96746,Is a norm a continuous function?,"Is a norm on a set a continuous function with respect to the topology induced by the norm? Is a topology on the set that can make the norm continuous (i.e. the topology that is compatible with the norm) not unique? Is it a superset of the unique topology induced by the norm? I am asking this question, because I heard (I am also not sure if it is correct) that a topology that can make an inner product continuous is not unique (such a topology is called weak topology on the inner product space?), and is a superset of the topology induced by the inner product. Thanks and regards! Pointers to some references are appreciated!","['general-topology', 'normed-spaces', 'inner-products']"
96753,When a prime ideal is a maximal ideal [duplicate],"This question already has answers here : If every prime ideal is maximal, what can we say about the ring? (5 answers) Closed 9 years ago . In a commutative ring with unit every maximal ideal is prime. Under what conditions does the converse occur?","['ring-theory', 'abstract-algebra']"
96754,Fixed points of $e^z$,"How would one find the fixed points of $e^z$, where $z$ is complex (if there are any)? I feel this problem probably has a really obvious answer, and for some reason, I'm just not getting it. Thanks.","['complex-numbers', 'functions', 'exponentiation']"
96772,Introduction to topological manifolds?,"I'm searching for a freely available text that introduces topological and smooth manifolds. I don't need much, just their basic properties and a bit more motivation than the wikipedia articles offers. Maybe course notes of some course that covered them. (Background: I skipped the classes where topological manifolds were introduced, and now I can't solve any problem where they appear, and I would like to change this before the exam ;)","['general-topology', 'online-resources']"
96776,dissection of a $1\times 5$ rectangle to a square,I've been thinking about the following problem: We have a $1\times 5$ rectangle: how to cut it and reassemble it such that it forms a square? Thanks a lot!,['geometry']
96789,Can you verify my ideas here with the chain rule using limits?,"I've been working on understanding limits thoroughly, so I'm rewriting how I understand the chain rule.  Please help me fill in my gaps in understanding. $f$ is some function. Then $f'(x) = \lim\limits_{h \to 0}\frac{f(x+h)-f(x)}{h}$ Now I might want to evaluate something like $$\left(f(g(x))\right)' = \lim\limits_{h \to 0}\frac{f(g(x+h))-f(g(x))}{h}$$ Evaluating this is tricky, so we need a way to do it. $\left(f(g(x))\right)' = (\lim\limits_{h \to 0}\frac{f(g(x+h))-f(g(x))}{g(x+h)-g(x)}\cdot\frac{g(x+h)-g(x)}{h}$) $\left(f(g(x))\right)' = (\lim\limits_{h \to 0}\frac{f(g(x+h))-f(g(x))}{g(x+h)-g(x)})\cdot\lim\limits_{h \to 0}(\frac{g(x+h)-g(x)}{h})$ if $k=g(x+h)-g(x)$, then $g(x+h)=k+g(x)$, so $\left(f(g(x))\right)' = (\lim\limits_{h \to 0}\frac{f(g(x)+k)-f(g(x))}{k})\cdot(\lim\limits_{h \to 0}\frac{g(x+h)-g(x)}{h})$ and, assuming I can go ahead and just change the limit variable on the left term, then $=(\lim\limits_{k \to 0}\frac{f(g(x)+k)-f(g(x))}{k}) \cdot (\lim\limits_{h \to 0}\frac{g(x+h)-g(x)}{h})$ $=f'(g(x))\cdot g'(x)$ Which is easier to figure out, and is also the chain rule. Is that correct?","['calculus', 'derivatives', 'limits']"
