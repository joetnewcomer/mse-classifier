question_id,title,body,tags
4115719,A drunkard flipping switches in a dark room,"There are $n$ switches in a dark room controlling a single light; all the switches must be on for the light to be on. Initially all the switches are off. A drunkard left in the room wakes up from a hangover and repeatedly picks a switch uniformly at random and flips it. What is the expected number of flips the drunkard takes to turn on the light ? I answered the $n=4$ case here , but the weird result of $\frac{64}3$ enticed me to generalise the problem, for which I have rewritten the setting. If $E_k$ is the expected number of flips needed with $k$ switches on, the $E_k$ satisfy the following tridiagonal system: $$\begin{bmatrix}1&-1&0&\dots&0&0\\-\frac1n&1&\frac1n-1&\dots&0&0\\0&-\frac2n&1&\dots&0&0\\\vdots&\vdots&\vdots&\ddots&\vdots&\vdots\\0&0&0&\dots&1&-\frac2n\\0&0&0&\dots&\frac1n-1&1\end{bmatrix}\begin{bmatrix}E_0\\E_1\\E_2\\\vdots\\E_{n-2}\\E_{n-1}\end{bmatrix}=\begin{bmatrix}1\\1\\1\\\vdots\\1\\1\end{bmatrix}$$ The $(i,j)$ entry of the square matrix is $1$ if $i=j$ , $-\frac jn$ if $i=j+1$ , $\frac{i-1}n-1$ if $i=j-1$ and $0$ otherwise. The answer to the problem proper is then $E_0$ , the first few values of which are (starting from $n=1$ ) $$1,4,10,\frac{64}3,\frac{128}3,\frac{416}5,\frac{2416}{15},\frac{32768}{105},\frac{21248}{35},\frac{74752}{63}$$ After nosing around and actually solving the tridiagonal system using a dedicated algorithm I found a formula for $E_0$ at any $n$ : $$E_0(n)=2^{n-1}F(n-1)\text{ where }F(n)=\sum_{k=0}^n\frac1{\binom nk}\tag1$$ Now $F$ has been discussed at length on this site, including here , here and here , and is A048625 / A048626 in the OEIS. Hence the generating function for $E_0$ may be obtained: $$\sum_{n=0}^\infty E_0(n)z^n=z\left(\frac{\log(1-2z)}{2(z-1)}\right)'$$ The appearance of $F(n)$ was a pleasant surprise for me, and now I have no proof because this was all numerical experimentation. How can $(1)$ be proved? I found $(1)$ by tracing the variables in the tridiagonal matrix algorithm applied to the above square matrix turned upside-down. I found that at the end (using the notation on Wikipedia) $d_n=2^{n-1}$ and $b_n=\frac1{F(n-1)}$ , but trying to expand everything symbolically only produces a huge tree of fractions.","['summation', 'random-walk', 'expected-value', 'binomial-coefficients', 'probability']"
4115738,Extending injection in Hausdorff spaces,"Let $f : X \to Y$ be a continous locally injective map. Then, if $f$ is injective in a compact subset, it is injective in a neighborhood of that compact. This result was proved here when $X, Y$ are $\mathbb{R}^{n}$ . As far as I see, the result uses only metric properties, no specific property of $\mathbb{R}^{n}$ is used. Can this result be generalized to arbitrary Hausdorff spaces $X$ , $Y$ , by using a proof that doesn't require metric properties? I have tried to extract a cover from the locally injective neighbourhoods, but I'm not having any progress in proving global injectivity. May any of the extension theorems (Tietze like) be useful here? Thanks in advance! Edit: A map $f$ is locally injective in $X$ if for every point $x$ in $X$ there exists a neighborhood $U$ (a set containing an open set that contains $x$ ) such that $f$ is injective in $U$ . Edit2: I have started a bounty. I would be grateful if the answer (if there is any) avoids the concepts of filter and net, since those concepts are completely unfamiliar to me.",['general-topology']
4115754,Why can I do prime decomposition if m contains several primes but not if it contains just one prime?,Why can I $\ {2^{32}\pmod {30} }$ decomposite in $x \equiv{2^{32}\pmod {5} }$ $x \equiv{2^{32}\pmod {3} }$ $x \equiv{2^{32}\pmod {2} }$ $\ {2^{32}\pmod {30} = x }$ but not $\ {2^{32}\pmod {25} }$ in $x \equiv{2^{32}\pmod {5} }$ ? $\ {2^{32}\pmod {25} ≠ x }$ Both m are decomposite into primes. Thanks in advance. I appreciate your help.,"['modular-arithmetic', 'discrete-mathematics']"
4115757,Geometry problem proving that all lines $DE$ passes through one point,"Let $I$ is the incenter of $\triangle ABC$ . Let $K$ be the circumcircle of $ABC$ . Let $D$ be a variable point on arc $AB$ on $K$ not containing $C$ . Let $E$ be a point on line segment $BC$ such that $\angle ADI = \angle IEC$ . Prove that as $D$ varies on arc $AB$ , the line $DE$ passes through one point. First after testing a couple cases i found the point is the midpoint of arc $BC$ . I've tried direct proof and reverse reconstructing the problem, but nothing worked. Can anyone help?
(edit: I reflected $E'$ in the bisector of $C$ and created a cyclic quadrilateral $ADIE'$ . Maybe it is a useful property...)
(edit 2: I suspect inversion might be involved...)","['contest-math', 'euclidean-geometry', 'locus', 'geometry', 'geometric-transformation']"
4115770,Prove $P(z)=z^4+2z^3+3z^2+z+2$ has exactly two zeros in the right half plane,"NOTE: The answer found here is not what I'm looking for. The question is:
Prove $P(z)=z^4+2z^3+3z^2+z+2$ has exactly two zeros in the right half plane. [Hint: Write $P(iy)=(y^2-2)(y^2-1)+iy(1-2y^2)$ , and show that $\lim_{R\to\infty}arg\{P(iy)\}\Biggr|_{-R}^{R}=0$ .] I need to prove this (preferably using Rouche's theorem. Any other method involving the hint may also be accepted). Now, this can be shown to be true by taking two functions $f(z)=(z-1)^2(z+2)^2$ and $h(z)=z^4+2z^3-3z^2-4z+4$ which are analytic on and inside a closed semi-circular contour (radius $R$ ) encapsulating the right half-plane, and by showing that $|f(z)|>|h(z)|$ on the boundary of it. Then by Rouche's theorem, it is easy to verify that $P(z)$ has only 2 zeros (same as $f(z)$ ) in the right half-plane. What I'm looking for is a solution involving the Hint! I know the Hint says that the imaginary axis of the domain gets mapped to the right half-plane (more precisely to the positive real numbers as $R\to\infty$ ). But I'm not sure how to use it in getting a solution. Thanks in advance.","['singularity', 'complex-analysis', 'rouches-theorem', 'complex-integration', 'complex-numbers']"
4115799,Trouble with this one step involving arcsin,"So I'm solving a very basic trigonometric equation and after substituting the function for u and solving the quadratic equation, I ended up with $\sin\left(2x+\frac{\pi}{3}\right)=\frac{1}{4}$ . I need to take the arcsin of both sides if I'm not mistaken, but after inputting the original equation into a graph, it gives me a different solution than $2x+\frac{\pi}{3}=\arcsin\left(\frac{1}{4}\right)$ So 100% I'm missing a rule regarding cancelling out a function. I would appreciate an elaboration :)","['algebra-precalculus', 'trigonometry']"
4115831,Limits of indicators of sets.,"Suppose $A_n$ is a sequence of sets such that $\lim_{n\to\infty}A_n = A$ where we make no assumption on the $A_n$ being increasing or decreasing. Is $\lim_{n\to \infty}\chi_{A_n} = \chi_{A}$ ? For example consider a sequence  in the reals $x_n$ that has limit $x$ then define $A_n = [0,x_n]$ . Is it true that $\lim_{n\to\infty} \chi_{[0,x_n]} = \chi_{[0,x]}$ ? If the example given does not hold what are some conditions such that it does? Thanks :) When I say $\chi_S$ I mean the indicator of set $S$ , maybe you have seen it as $\mathbb{1}_S$ :)","['limits', 'measure-theory', 'real-analysis']"
4115852,"Is the real part of a complex solution to a linear differential equation always a solution? If so, why?",So the general solution $f(t)$ to a linear differential equation with real coefficients can be written as $$f(t)=a_1e^{A_1t}+a_2e^{A_2t}+a_3e^{A_3t}+...$$ Would $\text{Im}(f(t))$ and $\text{Re}(f(t))$ also be solutions? That's the idea I'm getting from the following questions: What is the meaning of having imaginary solutions to a differential equation Imaginey and real part of Answer of differential equation although I can't quite understand why this works.,['ordinary-differential-equations']
4115922,Limit definition of the osculating circle,"Let $I$ be an interval and $c:I \to \mathbb{R}^2$ a smooth curve with $c' \neq 0$ everywhere. I am currently trying to figure out how to define the osculating circle at a point $c(t_0)$ , $t_0 \in I$ , without assuming that the curvature has previously been defined (which could for example be done via the Frenet frame). One way to define it might be the following way using a limit: Assume that locally around the point $c(t_0)$ the curve is not a straight line. Consider a value $h>0$ with $t_0 \pm h \in I$ such that the three points $c(t_0-h)$ , $c(t_0)$ and $c(t_0+h)$ are not located on a straight line. Let $M(t_0,h)$ be the center of the circle defined by those three points. The osculating circle at $c(t_0)$ might then be defined as being the circle with center $M$ and radius $r$ where these values are given by $$M:=\lim_{h \to 0} M(t_0,h)\phantom{aaa}\text{and}\phantom{aaa}r:=\Vert M-c(t_0) \Vert$$ The limit runs only over those values of $h$ for which the three points $c(t_0-h)$ , $c(t_0)$ and $c(t_0+h)$ are not located on a straight line. (This is not really a restriction. Since $c$ is not a straight line around $c(t_0)$ , just choose $h$ small enough.) My question: How to show that the limit from the above definition exists? Or is there something wrong with the definition? Some background: A similar definition for the osculating circle is indicated in the book ""Modern Differential Geometry of Curves and Surfaces with Mathematica"" by Gray et al. in section 4.4. However, they do not explain why the limit should exist or least I do not understand this. Addendum : Finally, I learned that there must be a ""mistake"" in the definition. Since this is not mentioned in any of the answers, I decided to explain it here: The condition that $c$ is not a straight line locally around $c(t_0)$ is not sufficient for the osculating circle to exist. Under this condition, it may still happen that for every sufficiently small $h>0$ , you can find a straight line through the points $c(t_0-h)$ , $c(t_0)$ and $c(t_0+h)$ . Take for example $c(t)=(t,t^3)$ , $-1/2 < t < 1/2$ and $t_0=0$ . Therefore: No osculating circle at $c(t_0)$ in that case. The points $M(t_0,h)$ are not well-defined because they don't exist. So, currently I am wondering what the ""correct"" condition on $c$ might be guaranteeing that the points $M(t_0,h)$ exist for sufficiently small $h$ ...","['curves', 'osculating-circle', 'geometry', 'curvature', 'differential-geometry']"
4115926,Conditional expectation of $X$ given $X+Y=5$ of a bivariate normal distribution,"Random variables X and Y have a bivariate normal distribution. If the parameters are $\sigma_x,\sigma_y,\mu_x, \mu_y, \rho$ , how do we express $E(X|X+Y=5)$ using those parameters? The conditional expectation is given by $\mathbb{E}[X|Z=z]=\mu_X+\sigma_X\rho(\frac{\displaystyle z-\mu_Z}{\displaystyle \sigma_Z})$ . Maybe we can let $Z=X+Y$ but then our expression would not have the parameters in terms of Y.","['bivariate-distributions', 'statistics', 'conditional-expectation', 'probability']"
4115939,Two questions re. Cantor's diagonalization argument [duplicate],"This question already has answers here : Why does Cantor's diagonal argument not work for rational numbers? (2 answers) Closed 3 years ago . I was watching a YouTube video on Banach-Tarski, which has a preamble section about Cantor's diagonalization argument and Hilbert's Hotel. My question is about this preamble material. At c . 04:30 ff., the author presents Cantor's argument as follows. Consider numbering off the natural numbers with real numbers in $\left(0,1\right)$ , e.g. $$
\begin{array}{c|lcr}
n \\
\hline
1 & 0.\color{red}50321642239817 \ldots \\
2 & 0.0\color{red}7829136011205 \ldots \\
3 & 0.31\color{red}11370055629 \ldots \\
4 & 0.999\color{red}9261457682 \ldots \\
5 & 0.0001\color{red}042507334 \ldots \\
\vdots & \vdots
\end{array}
$$ Then you could form a new real in $\left(0,1\right)$ not already in the list, e.g. $0.\color{red}{68281} \ldots$ . Hence there are more reals than naturals. I have two questions about this: Couldn't you run exactly the same argument (erroneously) for rational numbers in $\left(0,1\right)$ ? E.g. say I choose powers of $\frac{1}{2}$ , giving: $$
\begin{array}{c|lcr}
n \\
\hline
1 & 0.\color{red}4999999999999 \ldots \\
2 & 0.2\color{red}499999999999 \ldots \\
3 & 0.12\color{red}49999999999 \ldots \\
4 & 0.062\color{red}4999999999 \ldots \\
5 & 0.0312\color{red}499999999 \ldots \\
\vdots & \vdots
\end{array}
$$ So $0.\color{red}{55555} \ldots$ is not in the list, suggesting that the cardinality of the rationals is greater than that of the naturals. But a different argument shows that their cardinalities are the same. So there seems to be something wrong with the diagonal argument itself? As a separate objection, going back to the original example, couldn't the new, diagonalized entry, $0.68281 \ldots$ , be treated as a new ""guest"" in Hilbert's Hotel, as the author later puts it ( c . 06:50 ff.), and all entries in column 2 moved down one row, creating room? Admittedly, you could diagonalize this expanded list again; but then you could also move the guests down again. So the argument does not seem to show that there's any fundamental problem, i.e. that you can't continue pairing off the reals with the naturals forever?",['elementary-set-theory']
4116012,What exactly is an implicitly defined function?.,"So I've just started to get into some calculus and I recently came across the topic of implicit differentiation.
I am extremely confused on what implicit functions are and there is very little information on what exactly implicitly  defined functions really are but instead lots of defintions on how to implicitly differentiate. I became even more confused from this definition  proofwiki provides  which defines an implicit function as follows. Consider a (real) function of two independent variables $z=f(x,y).$ Let a relation between $x$ and $y$ be expressed in the form $f(x,y)=0$ defined on some interval $I$ . If there exists a function: $y=g(x)$ defined on $I$ such that: $∀x∈I:f(x,g(x))=0$ then the relation $f(x,y)=0$ defines $y$ as an implicit function of $x$ . I can't seem to wrap this definition i am familiar with how a function is a special kind of binary relation but when we state that let a relation between $ x, y$ be expressed in the form $f(x,y)=0$ what exactly do we mean by this for example how is $x^2 +y^2=1$ a relation in that form.
a simple example would be greatly appreciated. I hope this question is not too vague to be answered or too silly to be even considered thanks in advance.","['implicit-function', 'calculus', 'implicit-differentiation', 'derivatives']"
4116033,Size of the largest disk not intersecting N random points on the 2D torus,"Consider $N$ points generated uniformly at random on the 2d torus (ie. unit square after identifying right/left and up/down). I am interested in estimating the size (eg. diameter) of the largest disk that does not intersect any of these N points. Even estimating the rate of decay of the expected diameter would be a good start! In 1D (ie. a circle), this is quite well-known and has been discussed several times on this form. The 2D case seems more complicated. PS: the torus is the simplest 2D object I could think of (ie. no boundary effects). If this makes things easier to work on the unit square, I would also be very interested!","['geometric-probability', 'geometry', 'probability']"
4116081,Counting the number of $3\times 4$ matrices with all entries either $0$ or $1$ such that no row/column contains all $0$'s,"Problem: How many $3\times 4$ matrices are there with all entries either $0$ or $1$ such that there is no row or column which contains all $0$ 's? I have tried the problem using inclusion-exclusion principle but it is becoming very complicated. I started with $2^{12}$ total possibilities, then while subtracting the terms, it is becoming complicated. Any help would be appreciated!","['inclusion-exclusion', 'combinatorics', 'discrete-mathematics']"
4116084,Fermat's Last Theorem ($n=4$) using the Gaussian integers,"I'm doing the second part of the following exercise in Miles Reid's Undergraduate Commutative Algebra : Exercise 0.18 : Prove the cases $n=3$ and $n=4$ of Fermat's last theorem. I would like to know: Is my proof correct? Is there a simpler way to prove the result using the Gaussian integers? (I'm aware of the proof that uses infinite descent, over the integers, so I would like to know if there is a very short proof using the power of the Gaussian integers) Here is my attempt: Let $$x^4+y^4=z^4$$ with $x,y,z\in\Bbb N$ . We can assume that $x,y,z$ has no common factor, otherwise we could divide through by that factor. If $z$ is even, then $x^4+y^4\equiv_4 0$ , which is only possible if $x^4,y^4\equiv_4 0$ , but then $x,y,z$ all have a common factor. So assume that $x$ is even. Write $$(x^2+iy^2)(x^2-iy^2)=z^4$$ Let $\pi\in\Bbb Z[i]$ be a prime such that $\pi\mid x^2+iy^2, x^2-iy^2$ . Then, $\pi\mid 2x^2,2y^2$ . If $\pi=1-i$ then $N(\pi)=2\mid z$ . Contradiction. Therefore $x^2+iy^2,x^2-iy^2$ are relatively prime. We can write $x^2+iy^2=i^k\alpha^4=i^k(a+bi)^4$ , and we get $$x^2+y^2i=i^k(a^4-6a^2b^2+b^4+i4ab(a^2-b^2))$$ $k=0,2$ is impossible, since this implies that $y$ is even, so $k=1,3$ . Therefore $$\begin{align}x^2&=\pm 4ab(a^2-b^2)\\y^2&=\mp (a^4-6a^2b^2+b^4)\end{align}$$ Since $y$ is odd, we must have that $a,b$ have different parities. If $k=3$ we get a contradiction no matter which of $a,b$ we assume to be even, since then $y^2\equiv_4 -a^4$ or $y^2\equiv_4 -b^4$ , which is impossible. Therefore $k=1$ , and so $$\begin{align}x^2&=4ab(b^2-a^2)\\y^2&=a^4-6a^2b^2+b^4=(b^2-2ab-a^2)(b^2+2ab-a^2)\end{align}$$ The factors of $b^2-2ab-a^2,b^2+2ab-a^2$ are relatively prime so they must both be odd squares. To see this, let $d\mid b^2-2ab-a^2,b^2+2ab-a^2$ . Then $d\mid b^2-a^2, ab$ , in particular $d\mid a^2b^2-a^2,b^4-a^2b^2$ . Let therefore $$C^2=b^2-2ab-a^2$$ solving for $b$ yields $$b=1\pm\sqrt{2+\frac{C^2}{a^2}}$$ which implies that $a\mid C\Rightarrow a\mid y$ . Hence both $x,y$ have an even factor of $a$ . This is only possible if $a=0$ .","['gaussian-integers', 'abstract-algebra', 'solution-verification', 'commutative-algebra']"
4116122,Why do we ask for *absolute* convergence of a series to define the mean of a discrete random variable?,"If $X$ is a discrete random variable that can take the values $x_1, x_2, \dots $ and with probability mass function $f_X$ , then we define
its mean by the number $$\sum x_i f_X(x_i) $$ (1)
when the series above is absolutely convergent . That's the definition of mean value of a discrete r.v. I've encountered in my books ( Introduction to the Theory of Statistics by Mood A., Probability and Statistics by DeGroot M.). I know that if a series is absolute convergent then it is convergent, but why do we need to ask for the series (1) to converge absolutely, instead of just asking it to converge? I'm taking my introductory courses of probabilty and so far I haven't found a situation that forces us restrict ourselves this way. Any comments about the subject are appreciated.","['probability-distributions', 'conditional-convergence', 'absolute-convergence', 'convergence-divergence', 'probability']"
4116149,Show that $X\times Y$ has cardinality $c$,"This is problem 5 from section 1.4. of the book Real Analysis and Probability by R.M. Dudley: Let $X$ be a nonempty set of cardinality less than $c$ ( $c$ is defined as the cardinality of $2^\mathbb{N}$ ), and let $Y$ have cardinality $c$ . Show that $X\times Y$ has cardinality $c$ . Hint : Reduce to the case where $X$ has cardinality $c$ . I proved the reduced case by showing that $2^\mathbb{N}\times 2^\mathbb{N}$ has the same cardinality as $2^\mathbb{N}$ , by considering the sequence $(z_n)$ formed by alternating the terms of two sequences $(x_n)$ and $(y_n)$ . But I can't figure out how to reduce the original problem to this case. Any ideas?","['elementary-set-theory', 'cardinals']"
4116190,Homomorphisms $\phi\colon G\longrightarrow \operatorname{Aut}(H)$ and group actions.,"Let $G,H$ be groups. A homomorphism $\phi\colon G\longrightarrow \operatorname{Aut}(H)$ is an action such that: $$\operatorname{Fix}(g)\le H, \forall g\in G \tag 1$$ where $\operatorname{Fix}(g):=\{h\in H\mid \phi_g(h)=h\}$$^{\dagger}$ . If $G$ and $H$ are both finite, say $G=\{g_1,\dots,g_{|G|}\}$ and $H=\{h_1,\dots,h_{|H|}\}$ , then: $$\sum_{i=1}^{|H|}|\operatorname{Stab}(h_i)|=\sum_{j=1}^{|G|}|\operatorname{Fix}(g_j)| \space\space\space\text{and (from Burnside's Lemma)}\space\space\space |G|\mid \sum_{j=1}^{|G|}|\operatorname{Fix}(g_j)| \tag 2$$ As an entry test  for the possible utilization of $(2)$ , let's take $G=C_p$ and $H=C_q$ , where $p$ and $q$ are distinct primes. If a nontrivial homomorphism exists, then $|\operatorname{Fix}(g_{\bar j})|=1$ and $|\operatorname{Stab}(h_{\bar i})|=1$ , for some $\bar j\in \{1,\dots,p\}$ , $\bar i\in\{1,\dots,q\}$ . Then $(2)$ yields: $$[\space k+(q-k)p=l+(p-l)q\Longrightarrow k(p-1)=l(q-1)\space]\wedge [\space p\mid pq-l(q-1)\space ] \tag 3$$ for some $1\le k\le q$ and $1\le l\le p$ . Now: if $p>q$ , then from $(3)$ -2nd term of the "" $\wedge$ "": $p\mid pq-l(q-1)\Longrightarrow$ $p\mid l \Longrightarrow$ $l=p\Longrightarrow$ $k(p-1)=p(q-1)\Longrightarrow$ $k=\frac{p}{p-1}(q-1)>q-1\Longrightarrow$ $k=q$ ; but $(k,l)=(q,p)$ is not a solution of $(3)$ -1st term of the "" $\wedge$ "": so, for $p>q$ , there are no nontrivial homomorphisms $\phi\colon C_p\longrightarrow\operatorname{Aut}(C_q)$ ; if $p<q$ and $p\nmid q-1$ , then from $(3)$ -2nd term of the "" $\wedge$ "": $p\mid pq-l(q-1)\Longrightarrow$ $p\mid l$ , and we fall back into the previous case. Therefore, if $p\nmid q-1$ , there are no nontrivial homomorphisms $\phi\colon C_p\longrightarrow\operatorname{Aut}(C_q)$ . This hasn't used any knowledge about the isomorphism class of the group $\operatorname{Aut}(C_q)$ . (Incidentally, that for $p\mid q-1$ there is actually a nontrivial homomorphism $\phi$ , it is shown e.g. here .) Can $(2)$ / $(3)$ ""framework"" be used to exhibit other pairs $(G,H)$ such that only the trivial $\phi$ exists? Edit . Let's now assume $G=C_p$ and $|H|=q^2$ , still with $p,q$ distinct primes. If a nontrivial homomorphism exists, then $(2)$ yields: $$[\space k+(q^2-k)p=l_0+l_1q+(p-l_0-l_1)q^2\space]\wedge [\space p\mid k\space ] \tag 4$$ for some $1\le k\le q^2$ and $1\le l_0+l_1\le p$ . Since $p\mid k\Longrightarrow p\le k\le q^2$ , for $p>q^2$ there are no nontrivial homomorphisms $\phi$ . This suffices to give a different proof to, e.g. , this question (and the conclusion doesn't change with $\Bbb Z_2\times \Bbb Z_2$ in place of $\Bbb Z_4$ ). $^{\dagger}$ In fact, for every $g\in G$ , $\phi_g(1_H)=1_H$ , whence $1_H\in\operatorname{Fix}(g)\ne\emptyset$ ; moreover, by definition, $\operatorname{Fix}(g)\subseteq H$ ; finally, for every $g\in G$ and $h_1,h_2\in\operatorname{Fix}(g)$ , $\phi_g(h_1h_2^{-1})=\phi_g(h_1)\phi_g(h_2^{-1})=\phi_g(h_1)\phi_g(h_2)^{-1}=h_1h_2^{-1}$ , whence $h_1h_2^{-1}\in\operatorname{Fix}(g)$ .","['group-homomorphism', 'automorphism-group', 'abstract-algebra', 'group-theory', 'group-actions']"
4116201,$\sigma$-algebra generated by function,I have no idea how to calculate $\sigma$ -algebra generated by $Y=\sin(\pi x)$ . I'm looking for hints and suggestions to calculating the $\sigma$ -algebra.,['measure-theory']
4116229,Cohen-Macaulayness and regularity of $A/p$,"This question claimed (and proved) that if $p$ is a prime ideal of $A=k[x_1,\ldots,x_n]$ with $\operatorname{ht}(p) \in \{0,1,n-1,n\}$ , then $A/p$ is Cohen-Macaulay. Now, let $A$ be a (Noetherian) UFD of Krull dimension $n$ which is Cohen-Macaulay,
and let $p$ be a prime ideal of $A$ with $\operatorname{ht}(p) \in \{0,1,n-1,n \}$ . Question 1: Is it true that $A/p$ is Cohen-Macaulay? My answer: Yes, it is true that $A/p$ is CM, and the same proof holds. More elaborately: If $\operatorname{ht}(p)=0$ then $p=(0)$ , so trivially $A/p=A/0=A$ is CM. If $\operatorname{ht}(p)=1$ , then $p$ is principal, since a height one prime in a UFD is principal, see wikipedia (11). Then by the nice proposition in this answer, $A/p$ is CM. If $\operatorname{ht}(p)=n−1$ , then $\dim A/p=1$ , and one-dimensional integral domains are CM, see wikipedia or MSE . If $\operatorname{ht}(p)=n$ , then $\dim A/p=0$ , hence $A/p$ is a field, and fields are CM. Let us concentrate on $A=k[x_1,\ldots,x_n]$ and $p$ a prime ideal of $A=k[x_1,\ldots,x_n]$ with $\operatorname{ht}(p)=1$ . Now again $p$ is principal, but $A/p$ is not necessarily regular. Indeed, $(x^2-y^3)$ is a height one prime of $k[x,y]$ and $k[x,y]/(x^2-y^3)=k[z^2,z^3]$ is CM but not regular (since regular implies normal, but $k[z^2,z^3]$ is not normal, namely, not integrally closed in its field of fractions $k(z)$ ). Question 2: What happens if $\operatorname{ht}(p)=n-1$ ? In that case we have a one-dimensional integral domain $A/p$ ; is it necessarily regular?. Question 3: More generally: Could one guarantee regularity of a quotient of $A=k[x_1,\ldots,x_n]$ by a prime ideal $p$ of height different then $\{0,n\}$ ? Maybe adding assumptions would help? Thank you very much!","['cohen-macaulay', 'regular-rings', 'algebraic-geometry', 'local-rings', 'commutative-algebra']"
4116252,Proving the following inequality (positive def. matrix),"I'm trying to prove (or disprove) the following: $$ \sum_{i=1}^{N} \sum_{j=1}^{N} c_i c_j K_{ij}  \geq  0$$ where $c \in \mathbb{R}^N$ , and $K_{ij}$ is referring to a kernel matrix : $$K_{ij} = K(x_i,x_j) = \frac{\sum_{k=1}^{N} \min(x_{ik}, x_{jk})}{\sum_{k=1}^{N} \max(x_{ik}, x_{jk})}$$ Here, $x \in \mathbb{R}^N \geq 0$ . I'm basically trying to prove that $K_{ij}$ is a positive definite matrix, so I can use it as a Kernel, but I'm really stuck trying to work with $\max$ Edit: the function I'm refering to is: $$K(u,v) = \frac{\sum_{k=1}^{N} \min(u_{k}, v_{k})}{\sum_{k=1}^{N} \max(u_{k}, v_{k})}$$ where $u, v \in \mathbb{R}^N \geq 0$","['linear-algebra', 'positive-definite', 'reproducing-kernel-hilbert-spaces']"
4116277,Singular Value Decomposition Theorem: Corollary,"In a linear algebra and analysis course [it's a hybrid course between the two], we recently had the SVD (singular value decomposition) theorem, and the prof. told us (due to lack of time without proof): Corollary 2.39 : Let $A = U\Sigma V^{T}$ be the singular value decomposition of $A\in \mathbb R^{m\times n}$ , where the singular values $\sigma_1 \geq \dots \geq \sigma_p \geq 0$ , where $p = \min\left\{ m, n\right\}$ . Further, for $k<p$ , define $$A_{k} = U\Sigma_{k}V^{T},$$ where $$\Sigma_{k} = \begin{pmatrix} \sigma_1 \qquad\qquad\qquad 0 \\ \qquad \ddots \qquad \\ \quad\quad\quad\sigma_{k}  \\ 0 \qquad\qquad\qquad 0  \end{pmatrix} \in \mathbb R^{m\times n},$$ with $k < p$ . It holds that: $$A_k = \arg\min_{\text{rank}\left( B \right) = k}\left|\left| A - B\right|\right|_{2} = \arg\min_{\text{rank}\left( B\right) = k}\left|\left| A - B\right|\right|_{F}.$$ Upon question on a hint of the proof the lecturer said that one might want to use the following relations: $$\text{Tr}\left( AB^{T} \right) \leq \sum_{j=1}^{p} \sigma_{j}\gamma_{j},$$ where $\gamma_{1} \geq \dots \geq \gamma_{p} \geq 0$ denote the singular values of $B\in\mathbb R^{m\times n}$ . I also proved the following two relations: $$\left|\left| A - A_{k} \right|\right|_{2} = \sigma_{k+1}, \qquad \left|\left| A - A_{k} \right|\right|_{F} = \left( \sum_{j = k+1}^{p} \sigma_{j}^{2} \right)^{1/2} \qquad $$ IDEA : I tried several things, one of them being: $$\left|\left| A - B\right|\right|_{2} \leq \left|\left| A - A_{k} \right|\right|_{2} + \left|\left| B - A_{k} \right|\right|_{2} = \sigma_{k+1} + \left|\left| B - A_{k} \right|\right|_{2}$$ But then, I am not sure how to continue. We already know from the Corollary that $A_k = U\Sigma_k V^{T}$ [by definition], and $B = \tilde{U}\tilde{\Sigma}\tilde{V^{T}}$ [by the SVD Theorem], i.e. $\left|\left| B - A_{k} \right|\right|_{2} = \left|\left| \tilde{U}\tilde{\Sigma}\tilde{V^{T}} -  U\Sigma_k V^{T}\right|\right|_{2}$ . Could anybody help out, please, on how to continue?","['svd', 'linear-algebra', 'analysis']"
4116375,Not quite cardinal characteristics of the continuum,"We work in $\mathsf{ZFC}$ : Given an ideal $\mathcal{I}$ of subsets of $\omega^\omega$ , let $\kappa_\mathcal{I}$ be the smallest cardinality of a collection $\mathfrak{C}$ of $\mathcal{I}$ -positive (= not in $\mathcal{I}$ ) sets such that every $\mathcal{I}$ -positive set contains an element of $\mathfrak{C}$ as a subset. Note that we don't restrict attention to ""tame"" sets of reals here . The ideals I'm interested in are: the null and meager ideals $\mathcal{N}$ and $\mathcal{M}$ (for the former, note that we can identify $\omega^\omega$ with the irrationals), the dominatable ideal $\mathcal{D}$ of sets of functions which can be dominated by a single function, and the escapable ideal $\mathcal{E}$ of sets of functions which can be escaped by a single function. It's not hard to show that for each $\mathcal{I}\in\{\mathcal{M,N,D,E}\}$ we have $\aleph_1<\kappa_\mathcal{I}\le 2^{2^{\aleph_0}}$ . The upper bound is trivial and the lower bound following from a quick transfinite recursion argument: Since every countable set is in $\mathcal{I}$ , given $\mathcal{I}$ -positive sets $(A_i)_{i<\omega_1}$ we can recursively build disjoint $B,C$ which each meet each $A_i$ . Since $\omega^\omega\not\in\mathcal{I}$ , at least one of $\omega^\omega\setminus B$ and $\omega^\omega\setminus C$ must be $\mathcal{I}$ -positive, and by the previous bulletpoint neither $\omega^\omega\setminus B$ nor $\omega^\omega\setminus C$ contains any of the $A_i$ s. More generally, if $\mathcal{J}$ is any ideal such that $\omega^\omega\not\in\mathcal{J}$ and every set of size $<\mu$ is in $\mathcal{J}$ we have $\kappa_\mathcal{J}>\mu$ . Beyond that, however, I don't see anything interesting. My general question is, ""What can we say about the $\kappa_\mathcal{I}$ s of these ideals?"" This is a bit open ended, so let me focus on the point my ignorance about which is most embarrassing: For which such $\mathcal{I}\in\{\mathcal{N,M,D,E}\}$ is it consistent with $\mathsf{ZFC}$ that $\kappa_\mathcal{I}\le 2^{\aleph_0}$ ? I suspect the answer is ""none,"" and I strongly suspect the answer is ""none"" if we replace $\le$ by $<$ . However, I can't prove any of this. A big obstacle is that it's consistent that there can be an $\mathcal{I}$ -positive set of cardinality much less than the continuum; this breaks all the relevant recursions I can think of. Re: the title, while they have a similar flavor at first sip the $\kappa_\mathcal{I}$ s are not genuine cardinal characteristics: cardinal characteristics necessarily live between $\aleph_1$ and $2^{\aleph_0}$ , and the $\kappa_\mathcal{I}$ s don't. That said, it is very plausible to me that there is a connection between the two topics. Note that the observation beginning with ""more generally"" above connects $\kappa_\mathcal{I}$ with a genuine cardinal characteristic associated to $\mathcal{I}$ , namely the smallest cardinality of an $\mathcal{I}$ -positive set.","['measure-theory', 'descriptive-set-theory', 'logic', 'general-topology', 'set-theory']"
4116381,Find all integer solutions to $n^2 - n = c\cdot 2^{J+1}$,"I am trying to construct a matrix with dimensions such that the number of unique off-diagonal elements (i.e. the number of elements in the upper or lower triangle) is proportional to a power of 2.  By simplifying the expression somewhat, this essentially boils down to solving for all positive integer solutions to: $$n^2 - n = c2^{J+1}\tag{1}$$ If I decide to include the diagonal elements of the matrix, the equation is then: $$n^2 + n = c2^{J+1}\tag{2}$$ In both cases, $n$ , $c$ and $J$ are integers. Solve for equation (1), I get: $$n = \frac{1 + \sqrt{1+c2^{J+3}}}{2}$$ Solve for equation (2), I get: $$n = \frac{-1 + \sqrt{1+c2^{J+3}}}{2}$$ I'm a statistician working in the field of bioinformatics.  The number theory methods needed to solve for $n$ are beyond me.  Can anyone help me with an approach to solve either/both of these expressions?","['number-theory', 'discrete-mathematics', 'elementary-number-theory', 'diophantine-equations']"
4116397,Fun Equilateral Triangle Problem,"$\Delta ABC$ is an equilateral triangle with a side length of $4$ units. $\: $$\: $ $\angle CAF = \angle EBC =\angle FAB$ . $\: $$\: $ $D \in \left | AF \right |\: ,\: E \in \left | CD \right |\: ,\: F \in \left | BE \right | $ $\: $ Find the length of $\left | AD \right |$ By given angles, its easy to see that $\Delta DEF$ is an equilateral triangle and by similarity, $\left | EF \right |$ is $2$ . Area of $\Delta ABC = 4S = 4\sqrt3 \Rightarrow S = \sqrt{3} $ .
I couldn't get any further from this point","['euclidean-geometry', 'triangles', 'area', 'geometry']"
4116435,Reducing complex arithmetic to a three-variable polynomial,"This was not the question I wanted to ask originally - I've asked the right version here . This is a very small special case of this question of Gregory Nisbet . Say that a polynomial $p$ with complex coefficients captures the complex field iff addition and multiplication of complex numbers are first-order definable in the structure $(\mathbb{C};p)$ . For example, the polynomial $$q(x,y,z,w)=(x+y)z-w$$ captures the complex field: We can define $0$ as the unique $t$ such that for all $x,y$ we have $q(x,y,t,t)=t$ . We can then define multiplication as $ab=q(a,0,b,0)$ . We can define $1$ as the unique $s$ such that for all $x$ we have $q(x,0,s,0)=x$ . Finally, this lets us define addition as $a+b=q(a,b,1,0)$ . Following Gregory Nisbet's above-linked question, I'm curious if we can do better, at least as far as the number of variables is concerned: Is there a polynomial in $3$ variables which captures the complex field? I've removed some embarrassingly silly guesswork; see the edit history if curious.","['universal-algebra', 'logic', 'ring-theory', 'algebraic-geometry', 'complex-numbers']"
4116465,"how can I define uniform convergence in topological spaces, and also the concept of convergent series without talking about nets?","I have been in conflict with myself because of a confusion about the point convergence of sequences of functions and the uniform convergence over an arbitrary topological space. In metric spaces this concept is clear and can be defined in terms of $\epsilon$ and $\delta$ . On the other hand, point convergence in topological spaces is stated in Munkres' book as follows: A sequence $x_1, x_2, \ldots$ of points in a space $X$ converges to a point $x \in X$ if
for each neighborhood $U$ of $x$ , $\exists N$ such that $\forall n \geqslant N$ , $x_n \in U$ . But how can I define uniform convergence in topological spaces,
and also the concept of convergent series without talking about nets? I would greatly appreciate an answer on this topic.","['general-topology', 'pointwise-convergence', 'uniform-convergence']"
4116508,Is there a two-variable polynomial capturing complex arithmetic?,"My question is whether there is a polynomial in two variables which, in a precise sense, encodes the ring structure of $\mathbb{C}$ : Is there a two-variable complex polynomial $p(x,y)$ such that complex addition and multiplication are each first-order definable in the structure $(\mathbb{C}; p)$ ? This is related to this question of Gregory Nisbet . I earlier asked the three -variable version of this question ... because counting is hard and I didn't realize that a three -variable function corresponds to a four -ary relation. This was the question I meant to ask.","['universal-algebra', 'logic', 'field-theory', 'algebraic-geometry', 'complex-numbers']"
4116523,Is every Wolstenholme number greater than or equal to its index?,"Background This question was inspired by this code golf post , and I've taken some of this background explanation from there. Consider the generalised harmonic numbers of order 2: $$H_{n,2} = \sum^n_{k=1} \frac 1 {k^2}$$ This sequence begins: $$1, \frac 5 4, \frac {49} {36}, \frac {205} {144}, \dots\ \text{and converges to } \frac {\pi^2} 6\ \text{as } n \to \infty$$ However, the numerators of this sequence form another sequence known as the Wolstenholme numbers ( A007406 ): $$1, 5, 49, 205, 5269, 5369, 266681, 1077749, 9778141, ...$$ Question Let $i$ be the index and $w(i)$ the Wolstenholme number at index $i$ . So $w(2) = 5$ , $w(3) = 49$ , and so on. Is it the case that $w(i)$ is always greater than or equal to $i$ ? The initial terms suggest the answer is yes, but it might be possible that, when reduced to lowest terms, the fraction producing $w(i)$ collapses down so much that its numerator is less than its index $i$ . Is there an argument to demonstrate that this cannot happen?",['sequences-and-series']
4116536,"Munkres, Analysis on Manifolds, Problem 38-5","I am having trouble doing this problem. I know that we need to use Stokes' Theorem. $D_3$ is easy. The problem is I can't seem to picture a shape whose boundary is $D_1$ and $C_1$ and/or $D_1$ and $C_2$ (the way the lines are drawn seems to make a connected smooth surface impossible). Similarly, creating a smooth surface that has $D_2$ and $C_1$ and/or $D_2$ and $C_2$ as boundaries also seems impossible. Question: Let S be the subset of $\mathbb{R^3}$ consisting of the union of: i) the z-axis ii) the unit circle $x^2+y^2=1, z=0$ iii) the points $(0, y, 0)$ with $y \geq 1$ Let $A$ be the open set $\mathbb{R}^3-S$ of $\mathbb{R}^3$ . Let $C_1, C_2, D_1, D_2, D_3$ be the oriented 1-manifolds in $A$ that are pictured in Figure 38.3. Suppose that $F$ is a vector field in $A$ , with $curl F = 0$ in $A$ that $\int_{C_1} \langle F,T \rangle ds = 3$ and $\int_{C_2} \langle F,T \rangle ds = 7$ . What can you say about the integral $\int_{D_i} \langle F,T \rangle ds$ for $i=1,2,3$ ? Justify your answers.","['vector-analysis', 'analysis']"
4116603,When is $E(X-\mu)^2 \ne E(X^2)-\mu^2$?,"Consider the probability density function $$f(x)=\frac{x}{18}, \quad x \in [0,18]$$ Find $E(x)$ and $Var(x)$ . Solution : a.) \begin{align*}
E(x)
&=\int_{-\infty}^{\infty} x f(x) dx \\
&=\int_{0}^{18} x \left(\frac{x}{18}\right) dx \\
&=\frac{1}{18} \int_0^{18} x^2 dx \\
&=108
\end{align*} b.) Method 1: \begin{align*}
Var(x)
&=E(x-\mu)^2 \\
&=\int_{-\infty}^{\infty} (x-\mu) f(x) dx \\
&=\int_{0}^{18} (x-108)^2 \left(\frac{x}{18}\right) dx \\
&=83106
\end{align*} Method 2: \begin{align*}
Var(x)
&=E(x^2)-\mu^2 \\
&=\int_{-\infty}^{\infty} x^2 f(x) dx - (108)^2 \\
&=\int_{0}^{18} x^2 \left(\frac{x}{18}\right) dx - (108)^2\\
&=\frac{1}{18}\int_{0}^{18} x^3 dx - (108)^2\\
&=-10206
\end{align*} Clearly the second method is wrong, since a variance cannot be negative. But I cannot find the error. Can someone explain why the two methods yield different values? Is it not always the case that $E(X-\mu)^2 \ne E(X^2)-\mu^2$ ?","['integration', 'statistics', 'calculus', 'probability', 'random-variables']"
4116624,"Two fair dice tossed simultaneously till combination $(4,3)$ is obtained. Obtain the probability that number of tosses required is atmost $2$.","Original Question: Two fair dice are tossed simultaneously till a combination $(4,3)$ is obtained. Obtain the probability that the number of tosses required is atmost $2$ . My Reasoning : The dice are thrown simultaneously. One can't determine or distinguish between the two die. Thus, the combination of $(4,3)$ will include the outcomes $(4,3)$ as well as $(3,4)$ .  With that reasoning, I came up with following solution: $$x : \text{Number of tosses required to obtain the combination} $$ $$x ~ \text{~ Geometric distribution}\left(p=\frac{2}{36}=\frac{1}{18}\right)  $$ $$P(x < 3) = P(x = 1) + P(x = 2)  = \left(1-\frac{1}{18}\right)^0*\left(\frac{1}{18}\right) + \left(1-\frac{1}{18}\right)^1*\left(\frac{1}{18}\right) = 0.108025$$ But this answer was not accepted. Can someone please point out how is the reasoning wrong? The answer expected was $0.0547839$ with p = $\frac{1}{36}$ . Does order matters?","['probability-distributions', 'dice', 'game-theory', 'probability-theory', 'probability']"
4116632,Do we always get the same dimension regardless of the manifold/topological structure?,"Note: I ask this motivated by this other question: Are manifold subsets that are immersed submanifolds (regular/embedded) submanifolds? Maybe a weird question, but: Let $A$ be a set s.t. it is possible to endow $A$ with 2 different smooth (or topological or $C^k$ or possibly even holomorphic/complex/Kähler or whatever) manifold structures. Endow $A$ with 2 different smooth manifold structures $\mathscr F$ and $\mathscr G$ to get, resp, $(A,\mathscr F)$ and $(A,\mathscr G)$ . If $(A,\mathscr F)$ and $(A,\mathscr G)$ have respective dimensions $f$ and $g$ , then is $f=g$ ? Edit: Note: Oh right so I really mean that $A$ is a set and not a topological manifold, so the way $(A,\mathscr F)$ and $(A,\mathscr G)$ are topological manifolds in the 1st place are that they are based on the same topological structure i.e. they are based on the same topology that makes the set $A$ into a topological space (and then this topological space is indeed a topological manifold). What I have in mind: So, like, there are many smooth (or whatever) manifold structures on $\mathbb R^n$ , but I'm wondering if they all make $\mathbb R^n$ a smooth $n$ -manifold. Perhaps there's some wild smooth manifold structure to make $\mathbb R^n$ locally $\mathbb R^{n-1}$ (i guess in the 1st place, such structure would be s.t. the topological structure makes $\mathbb R^n$ locally $\mathbb R^{n-1}$ ). I think of something like $\mathbb R^n$ and $\mathbb R^{n-1}$ as diffeomorphic/homeomorphic, but then it's not under the standard manifold or even topological structures. I believe there's a rule that says for $(A,\mathscr F)$ to be a smooth $f$ -manifold, we must have $f$ equal to the same dimension $h$ that allows us to say in the 1st place $(A,\mathscr F)$ is a topological $h$ -manifold. But here...I'm not sure but I think I recall that the creation of a smooth manifold begins with a topological manifold and then this creation relies on same dimension. $f=g$ if $(A,\mathscr F)$ and $(A,\mathscr G)$ are diffeomorphic/homeomorphic, but I recall $(A,\mathscr F)$ and $(A,\mathscr G)$ need not be diffeomorphic/homeomorphic.","['submanifold', 'manifolds', 'general-topology', 'differential-topology', 'differential-geometry']"
4116637,Metric that induces topology distinct from product topology,"Find a metric on $\mathbb{R}^n$ that does not induce the same topology as the product topology.My effort: Consider the metric $$d(\textbf{u},\textbf{w})=\begin{cases}  1   &\text{ if } p \neq q\\
0  &\text{ if } p=q\end{cases}$$ and the open ball $\mathcal{B}_{\frac{1}{2}}(\textbf{u})$ for any $\textbf{u} \in \mathbb{R}^n$ . Then $\mathcal{B}_{\frac{1}{2}}(\textbf{u})=\{\textbf{u}\}$ and since each basis element $(w_1,v_1) \times \cdots \times (w_n,v_n)$ in the product topology contains more than one point, there is no basis element in the product topology, contained in $\mathcal{B}_{\frac{1}{2}}(\textbf{u})$ so the topology on $\mathbb{R}^n$ induced by each metric is different.",['general-topology']
4116654,How to evaluate integrals of complex valued functions of a real variable,"I'm trying to calculate the integral $\int_{-\infty}^{\infty}e^{-(1-i)x^2} dx$ , without invoking some sort of complex integral identify such as erf (ie as elementarily as possible) I'm thinking to solve this similarly to solving $\int_{-\infty}^{\infty}e^{x^2} dx$ , where we can call in a second variable $y$ , convert to polar, and take the square root of the result to get $\sqrt \pi$ . My attempt at this is to consider $\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}e^{-(1-i)(x^2+y^2)} dxdy = \int_{0}^{\infty}\int_{0}^{2\pi}e^{(1-i)(-r^2)} d\theta dr$ . Normally, as in the case of $e^{-x^2}$ , the limit is easy to compute, and we simply get something in terms of area of the unit circle. However, in this case, I'm not sure what to do with the imaginary term. Am I on the right track? How can I continue?","['integration', 'complex-integration', 'real-analysis']"
4116677,"Do these mathematical functions have a name? $f(x)=x^x$, $f(x, a)=x^{ax}$, $f(x,a,b)=x^{ax+b}$, $f(x,a,b,c)=x^{ax^2+bx+c}$","When I run into algebraic patterns in my engineering / physics modeling multiple times, I usually go see what the smart mathematicians have learned about that, and often discover something useful that improves my modeling.  For example, the $w e^w$ pattern… once you realize that’s the “Lambert W” function, then you learn all kinds of very useful stuff. However, my searches for this pattern haven’t turned up anything.  Maybe it's not really a common pattern.  So, I figured this group would know one way or the other… do any of these functions (or generalizations) have names: $$\begin{align}
f(x) &= x^x \\
f(x, a) &= x^{a x} \\
f(x, a, b) &= x^{a x + b} \\
f(x, a, b, c) &= x^{a x^2 + b x + c} \\ 
&= x^{\operatorname{quadratic}(x, a, b, c)}
\end{align}$$ If not, if you were a mathematician capturing the properties of these, what would you name these?  (What search terms might turn up properties and/or typical uses?) (Or if you were providing some optimized code to compute these in your modeling, what would you name these?)","['functions', 'special-functions']"
4116683,Does non-Euclidian geometries induce euclidian geometry locally?,"This is essentially a soft question. We know the world is a sphere, following spherical geometry, yet at local levels, we can observe euclidian geometry. This brings me to my question, Does non-Euclidian geometries induce euclidian geometry locally?","['euclidean-geometry', 'noneuclidean-geometry', 'soft-question', 'geometry']"
4116753,Complex Analytic Subset vs. Complex Analytic Set,"In my complex geometry class we have introduced two concepts of analytic sets. Let $M$ be a complex manifold. A subset $A\subset M$ is called complex analytic subset , if for each $p\in M$ there exists an open neighborhood $U\subset M$ of $p$ and finitely many holomorphic functions $f_{1},...,f_{k}:U\rightarrow \mathbb{C}$ such that $$
A\cap U = \{ q\in U \mid f_{1}(q)=...=f_{k}(q)=0 \}. 
$$ A subset $A\subset M$ is called complex analytic set , if for each $p\in A$ (!!!) there exists an open neighborhood $U\subset M$ of $p$ and finitely many holomorphic functions $f_{1},...,f_{k}:U\rightarrow \mathbb{C}$ such that $$
A\cap U = \{ q\in U \mid f_{1}(q)=...=f_{k}(q)=0 \}. 
$$ I do not understand the difference. Moreover, I do not understand the following implication: A domain $D\subset \mathbb{C}^{n}$ (open connected subset) is a complex analytic set but not a complex analytic subset. If it were a complex analytic subset then we necessary have that $D=\mathbb{C}^{n}$ . This I do not understand. Would be thankfull for explication. Greetings,
Nina","['complex-analysis', 'complex-geometry', 'general-topology', 'algebraic-geometry']"
4116875,Prove the function f is zero function. [duplicate],"This question already has answers here : If f is continous and exist real numbers show that $f(x)=0$ (3 answers) Closed 3 years ago . Let f : [a, b] → R be continuous. Assume that there exist constants α and β
such that ∀c ∈ [a, b], we have α $\int_a^c$ f(x) dx + β $\int_c^b$ f(x) dx = 0.
Show that f = 0. I guess there is a mistake in the question since if α and β = 0 , then the condition is satisfied but the fuction need not be zero function. If α $\ne$ 0 and β $\ne$ 0, I think f = 0. But I can't prove it. Please give a hint","['continuity', 'calculus', 'functions', 'real-analysis']"
4116889,How am I supposed to expand $\sin^2 A + \sin^4 A = 1$ into $1 + \sin^2A = \tan^2A$?,"My question is how can i expand $$\sin^2 A + \sin^4 A = 1$$ into: $$1 + \sin^2A = \tan^2A$$ I tried quite a few ways I know but all of them kinda felt random. i am not sure how to share my trials here. I am quite beginner in trigonometry. it is one of the extra test question from my textbook. I don't need it but cant control curiosity. so pls help me. Thanks in advance! EDIT: found the solution, dropping it here, \begin{align}
\sin^2 A + \sin^4 A & = 1 \\
\sin^4 A & = 1 - sin^2 A \\
\sin^2 A . \sin^2 A & = cos^2 A \\
\sin^2 A . (1 - \cos^2 A) & = cos^2 A \\
\sin^2 A - \sin^2 A.\cos^2 A & = cos^2 A \\
\sin^2 A & = cos^2 A + \sin^2 A.\cos^2 A \\
\sin^2 A & = \cos^2 A(1 + \sin^2 A) \\
1 + \sin^2 A & = \cfrac{\sin^2 A}{\cos^2 A} \\
1 + \sin^2 A & = \tan^2 A \\
\end{align}",['trigonometry']
4116897,"Does the image of a moving square under the map $(r,\theta) \mapsto (r,\theta +\log r)$ converges?","Let $\phi:\mathbb{R}^2 \setminus\{0\} \to \mathbb{R}^2 \setminus\{0\}$ be defined in polar coordinates by $$ \phi:(r,\theta) \mapsto (r,\theta +\log r).$$ Let $S_n=[n-1,n+1]^2$ be a square of edge length $2$ centered around $(n,n)$ . Does $\phi(S_n)$ converges to a parallelogram when $n \to \infty$ w.r.t the Hausdorff distance (up to a translation and rotation which depend on $n$ )? If so, what are the edge-lengths/angles of that parallelogram? If not, does it converge to something else? Can we characterize the limit somehow? Note that $\phi$ is area-preserving. It is the one-time flow of the divergence-free vector field $\log(r)\, \partial_{\theta}$ . Heuristically, when $n$ is very large, $r$ and $\theta$ are approximately constant along the square $S_n$ . I am not sure how to use this formally though. Note that the corner $C=(x_n,y_n)=(n+1,n+1)""=""(r_n,\theta_n)=(\sqrt 2(n+1),\pi/4)$ of $S_n$ is mapped into $$
\tilde C=(\tilde r_n,\tilde  \theta_n)=\big(\sqrt 2(n+1),\pi/4+\log (\sqrt 2(n+1))\big).
$$ and the corner $B=(x_n,y_n)=(n+1,n-1)""=""(r_n,\theta_n)=(\sqrt 2\sqrt{n^2+1},\arctan{\frac{n-1}{n+1}})$ is mapped into $$
\tilde B=(\tilde r_n,\tilde  \theta_n)=\big(\sqrt 2\sqrt{n^2+1},\arctan{\frac{n-1}{n+1}}+\log (\sqrt 2\sqrt{n^2+1})\big).
$$ Thus, I guess we first need to decide whether the images of the four corners converge (up to translations) to the vertices of a parallelogram. The  difference of angles of $\tilde B,\tilde C$ diverges, since $$
\log\big( \frac{n+1}{\sqrt{n^2+1}}\big)\to -\infty
$$ when $n \to \infty$ . I am not sure  if this has any relevance though. Below are pictures of $\operatorname{Image}(\phi)=\phi(S_n)$ for different values of $n$ : $n=2$ : $n=80$ : $n=800$ :","['hausdorff-distance', 'real-analysis', 'multivariable-calculus', 'symmetry', 'differential-geometry']"
4116915,Addition law for non mutually exclusive events,The addition law for non mutually exclusive events is given in my textbook as $P(A \space \text{or} \space B)=P(A \space\cup \space B)= P(A)+P(B)-P(A \space \cap \space B)$ I understand the logic behind this and would be fine if it were written as $P(A \space \text{or} \space B)=P(A)+P(B)-P(A \space \cap \space B)$ however I am fairly certain that in this case it is incorrect to say that $P(A \space \text{or} \space B)=P(A \space\cup \space B)$ Here is a diagram to further elaborate From the diagram would it not be true that $P(A \space \cup \space B)=P(A \space \text{or} \space B) + P(A \space \text{and} \space B)$ ? Is there a mistake in my textbook or am I missing something crucial?,"['elementary-set-theory', 'statistics', 'probability']"
4116976,sum of two random variable converges in distribution,"It's simple question. $\{X_n\}, X, Y$ are random variables such that $X_n + cY$ converges to $X+cY$ in distribution for each $c >0$ . How can I show that $X_n$ converges to $X$ in distribution?? I know that $X_n$ converges in distribution to $X$ if and only if $P(X_n \leq x) \rightarrow P(X \leq x)$ at every $x$ where $F_X$ is continuous. But cdfs do not seem to help with this problem. I also tried showing that $E[f(X_n)] \to E[f(X)]$ where $f$ is bounded and continuous, but this leads to double limits ( $n\to \infty$ and $c\to 0$ ).","['measure-theory', 'probability-theory', 'weak-convergence']"
4117030,Are the exercises about finding domain of functions ill-posed questions?,"In the definition of a function, we need to specify its domain and codomain. But now I'm puzzled by the fact that many  exercises will state: Find the domain of the function [insert random function here]. But those are not functions since their domain is not specified. How can we modify the exercises so that they actually make sense?","['functions', 'real-analysis']"
4117074,For what $p$ is there a $d$ where $x^3+d$ is Hamiltonian in ${\mathbb Z}/p$?,"Definitions Let $p$ be a prime, and let $f:{\mathbb Z}/p\to{\mathbb Z}/p$ be a function. Then we say that $f$ is Hamiltonian in ${\mathbb Z}/p$ if the directed graph of $f$ is just one cycle --- a Hamiltonian cycle. To be explicit, let $G$ be the directed graph whose nodes are the residues modulo $p$ , and whose arcs are $x\to f(x)$ . Then we say that $f$ is Hamiltonian in ${\mathbb Z}/p$ if $G$ is just a Hamiltonian directed cycle. Question So, for which prime $p$ is there a $d\in{\mathbb Z}/p$ where $f(x)=x^3+d$ is Hamiltonian in ${\mathbb Z}/p$ ? My thoughts $p=1\mod 6$ is no good, because only a third of the non-zero residues modulo $p$ are cubes. Such cubics exist for the simple cases $p=2, 3$ . So for any chance of such $d$ existing with $p>3$ , $p=-1\mod 6$ . I note that $x^3-d$ is Hamiltonian iff $x^3+d$ is, so only half the residues modulo $p$ need be tested as values for $d$ . Examples: $p=2, 3, 11, 47, 59, 71, 83, 131, 167, 251, 311, 347, 443, 467,\dots$ (not in OEIS). I note from brute force search that if $p=5\mod 12$ , there are no such $d$ . ( $p\leqslant 31121$ checked so far.) How come? Such a $p$ is the sum of two squares but I don't see how that would imply my observed result. The nearest approaches I've found are when $f$ is a $p-1$ -cycle and a fixed point; this happens when $(p, \pm d)=(29, 2), (29, 7), (41, 11), (41, 19)$ . Broadening the scope to cubics $f(x)=ax^3+d$ might be useful. Fix $p$ , and suppose $f(x)=a_0x^3+d_0$ is Hamiltonian. Then, by replacing each element $x$ in the cycle by $kx$ for some non-zero constant $k$ , we get the function $g(x)=a_0 k^{-2}x^3+kd_0$ . This shows that if such cubics exist, their respective values for $a$ are either the squares or the non-squares modulo $p$ . Every non-zero residue is a possible value for $d$ ; for example, by taking $k=d_0^{-1}$ we get $g(x)=a_0 d_0^2+1$ . Now for some prime $p=5\mod 12$ some cubics $f(x)=ax^3+d$ are Hamiltonian, but in every case I've found, the values of $a$ are the non-squares modulo $p$ . Examples: $p=5, 29, 101, 137, 149, 173, 197, 233, 257, 269,\dots$ (not in OEIS). That is, the $(p,a)$ where $ax^3+d$ is Hamiltonian modulo $p$ for some $d$ are in two classes: $p=-1\mod 12$ so $-1$ is not a square modulo $p$ ; $a$ is a square modulo $p$ $p=5\mod 12$ so $-1$ is a square modulo $p$ ; $a$ is not a square modulo $p$ So in each case if $ax^3+d$ is Hamiltonian, $-a$ is not a square modulo $p$ . Alternatively (if this is conceptually better) if $-a$ is a square modulo $p$ , $ax^3+d$ as a permutation is not Hamiltonian but has two or more cycles. The parity of the number of cycles of $f$ Denote the number of cycles of $f$ by $C(f)$ . After some testing I make the following conjecture. For given prime $p=5\mod 6$ , and given $a$ , as $d$ varies, with $f(x)=ax^3+d$ , the parity of $C(f)$ is invariant. The value of $C(f)$ might be different for different $d$ , but the parity is the same. For given $p$ and $a$ , $C(x\to ax^3+d)$ being odd doesn't guarantee a $d$ where $C(x\to ax^3+d)=1$ , but if $C(x\to ax^3+d)$ is even for any $d$ , then, for every $d$ , it is not 1. A cycle of length $l$ is $l-1$ transpositions. So, if $f$ is a $p$ -element permutation consisting of $C(f)$ cycles, then $f$ is $p-C(f)$ transpositions. So, if $p$ is odd, then $f$ and $C(f)$ have opposite parity. So we have Hamiltonian $f$ only if we have odd $C(f)$ and thus even $f$ . It turns out that the conditions determining this parity are easily stated (though I have no proof): If $p=-1\mod 6$ , and $f(x)=ax^3+d$ , then $C(f)$ is even iff $-a$ is a square modulo $p$ . This is independent of $d$ . $f$ is Hamiltonian only if $C(f)$ is odd, but I don't know of sufficient, or further necessary, preconditions. Iterates of $f$ ; any use? Because I'm only considering primes $p$ as moduli, $f$ is Hamiltonian iff $f(0)\ne0$ and $f^p(0)=0$ , where $f^p$ means $p$ iterations of $f$ . But I can't see how to exploit this given that $f(x)$ is more complicated than $ax+b$ or $ax^k$ . Literature? I haven't found any published literature on such functions. Perhaps I am not using the correct word? I have borrowed the term ""Hamiltonian cycle'' from graph theory. What is the corresponding term in the theory of permutations or permutation functions? ""Cycle'' and "" cyclic permutation '' do not restrict to cycles which involve all the elements in the permutation set. Or perhaps Hamiltonian functions are just not distinctive among permutation functions, so whether or not one is Hamiltonian is as unpredictable as, say, whether or not a prime is a Mersenne prime's exponent? I have used key words such as ""permutation cubic function modulo cycle'' in OEIS, but with no luck.","['number-theory', 'modular-arithmetic', 'prime-numbers', 'permutation-cycles']"
4117167,Prime factors of power sum of roots,"Say I have a polynomial $x^2 + a x + b$ , where $a, b \in \mathbb{Z}$ , which has two real roots. Denote these roots $\alpha, \beta$ . Then Newton's identities tell us that $\alpha^k + \beta^k \in \mathbb{Z}$ for every integer $k \geq 1$ . My question is, what can we say about the value of $\alpha^k + \beta^k$ as $k$ varies? In particular, could we relate (some) of its prime factors to (the prime factors of) $a, b$ say?","['number-theory', 'symmetric-polynomials', 'elementary-number-theory']"
4117193,How to show that a given set is an vector space?,"I have the following set: $$
\mathcal{V} = \left\{f: \int_{-\infty}^{\infty}f(x)^2 e^{-x^2}\,dx < \infty\right\}
$$ To show it is a vector space I need to show that: addition and subtraction are defined The set is closed under linear combinations There is a zero vector. However, I'm not sure how to show these properties with an integral.","['functions', 'improper-integrals', 'vector-spaces']"
4117289,"Calculating $\lim_{(x,y)\rightarrow (\infty,\infty)}(x^2+y^2)e^{-(x+y)}$","Please help me calculate the: $$\lim_{(x,y)\rightarrow (\infty,\infty)}(x^2+y^2)e^{-(x+y)}$$ My attempt is: First method: for $t>0$ we have $e^t\geq \frac{t^3}{3}$ now i have: $$(x^2+y^2)e^{-(x+y)}\leq\frac{3(x^2+y^2)}{(x+y)}\rightarrow 0, (x,y)\rightarrow(\infty,\infty)$$ but i dint know how to continue second method:the polar coord $$\lim_{(x,y)\rightarrow (\infty,\infty)}(x^2+y^2)e^{-(x+y)}=\lim_{r\rightarrow \infty}(r^2)e^{-r(cos\theta+sin\theta)}=\lim_{r\rightarrow \infty}\frac{r^2}{e^{r(cos\theta+sin\theta)}}=\frac{1}{cos\theta+\sin\theta}\lim_{r\rightarrow \infty}\frac{2r}{e^r}=\frac{2}{cos\theta+\sin\theta}\lim_{r\rightarrow \infty}\frac{1}{e^r}=\frac{2}{cos\theta+\sin\theta}\cdot0=0$$ i use the L'Hopital rule,but i dint know its correct","['limits', 'analysis']"
4117304,Example of a separated variety which is not quasi-projective,"I am following Kempf's book on algebraic varieties. A variety there is defined to be a space with functions having a finite affine open cover. Call a variety $X$ separated if its diagonal $$\mathrm{diag} (X)=\{ (x,x)\mid x\in X\}$$ is closed in $X\times X$ . In Lemma 3.3.2, Kempf proves that quasi-projective varieties are separated. My question is: does there exist an example of a separated variety which is non-quasi-projective? PS: This is my first time posting a question here. Please feel free to suggest ways to make it better.","['algebraic-geometry', 'separation-axioms']"
4117351,Infinitely Many Disjoint Balls Contained In Unit Ball,"I am trying to solve a portion Problem 16 of Chapter 2 from Methods of Modern Mathematical Physics by Simon and Reed. The task is to show that the unit ball in an infinite dimensional Hilbert space contains infinitely many disjoint balls of radius $\sqrt{2}/4$ . My approach is shown below. By Theorem 2.5, I know that every Hilbert space contains an orthonormal basis $\{a_n\}_{n = 1}^{\infty}$ . I define the sequence of balls $\{B_n\}_{n=1}^{\infty}$ such that $$B_n = \{x\ :\ \|x - a_n/2\| < \sqrt{2}/4\}.$$ If $a \in B_n$ , we observe that $$\|a\| \leq \|a - a_n/2\| + \|a_n/2\| < \sqrt{2}/4 + 1/2 < 1.$$ Thus, $B_n$ is contained in the unit ball. For $m \neq n$ , we can observe that $$\|a_m/2 - a_n/2\| \leq \|x - a_m/2\| + \|x - a_n/2\| < \sqrt{2}/4 + \sqrt{2}/4 = \sqrt{2}/2.$$ However, this last inequality does not guarantee that $B_m \cap B_n = \emptyset$ . Are there any suggestions for how to ensure that $B_m \cap B_n = \emptyset$ ?","['hilbert-spaces', 'normed-spaces', 'functional-analysis', 'analysis']"
4117370,$f(x)=a\sin x + b \cos x\equiv 0$,"Let $$f(x)=a\sin x + b \cos x$$ where a,b are some constants. Let there are exists $x_1, x_2$ such that $$f(x_1)=f(x_2)=0$$ $x_1-x_2\not =\pi k, k \in \mathbb Z $ . Prove that $f(x)=0$ for all $x\in \mathbb R$ . And is it $a=b=0$ in this case or not? ###My work I see that $f(x_1)=f(x_2)=0$ . $$a\sin x_1 + b \cos x_1=0 \Rightarrow \tan x_1=-\frac ba $$ $$a\sin x_2 + b \cos x_2=0 \Rightarrow \tan x_2=-\frac ba $$ Hence, $\tan x_1-\tan x_2=0$ . Then $\sin(x_1- x_2)=0 \Rightarrow x_1-x_2=\pi k$ . But $x_1-x_2\not =\pi k$ . Where my mistake? How I need continue to solve my problem?","['trigonometry', 'functions']"
4117376,Does the Doob inequality hold for local martingales?,"Let $M$ be a real-valued continuous local martingale with $M_0=0$ , and  fix $t_0\geq 0$ . Do we then have the inequality $$\mathbb{E}[~\sup_{t\leq t_0} M_t^2~]\leq C\cdot \mathbb{E}[M_{t_0}^2],$$ where $C$ is a universal constant (i.e. not depending on $t_0$ or $M$ )? The inequality is trivial in case $M_{t_0}\notin L^2$ , so we may assume $\mathbb{E}[M_{t_0}^2]<\infty$ .  This inequality holds when $M$ is a true martingale and $C=4$ , in which case it is known as the Doob inequality. If we localize the inequality and let the stopping times tend to infinity, the left hand side is a monotone limit, but it's not clear what to do with the limit of the right hand side. If somehow the assumption $\mathbb{E}[M_{t_0}^2]<\infty$ implied that $\mathbb{E}[\langle M, M \rangle _{t_0}]<\infty$ (as it would if $M^2-\langle M, M \rangle$ were a true martingale rather than just a local martingale), then it is a theorem that $M_{t\wedge t_0}$ is a true martingale and the normal Doob inequality would apply.","['stochastic-processes', 'analysis']"
4117377,How do we know that the Cauchy principal value gives the right answer in a calculation of $\int_{-\infty}^\infty\frac{\sin x}{x}dx$?,"In calculating the integral $$\int_{-\infty}^{\infty} \frac{\sin x}{x}dx$$ by contour integration, we use $$\int_{-\infty}^{\infty} \frac{\sin x}{x}dx = \int_{-\infty}^{\infty} \frac{\operatorname{Im}(e^{ix})}{x}dx =\operatorname{Im}\left(\int_{-\infty}^{\infty} \frac{e^{ix}}{x}dx \right)$$ but in the process, we have gone from an integral which is well-defined with no real singularities to one with a real singularity which in fact is just undefined as an improper integral. Therefore, in the source I am reading, we take the cauchy principal value (CPV) of the integral on the RHS instead of treating it as an improper integral. This principal value is calculated by use of the Residue Theorem. My question: There are different ways to treat singularities in integrals. How do we know that this one (the CPV) will give us the correct result for $\int_{-\infty}^{\infty} \frac{\sin x}{x}dx$ ? Of course, knowing the answer by other methods, we can compare and see it was correct, but I'm looking to understand why the reasoning is valid. Response to 1st answer : Simply saying that the integral converges is not enough. We need some way to know that in particular the CPV is the correct notion of integration for the exponential integral. Clearly, not any notion of integration which converges must give the correct result. Response to 2nd answer : The question I ask is: by what reasoning is the notion of CPV in $\int_{-\infty}^{\infty} \frac{\sin x}{x}dx =\operatorname{Im}\left(CPV\int_{-\infty}^{\infty} \frac{e^{ix}}{x}dx \right)$ justified. Of course the first integral is the same as an improper integral or CPV, this just doesn't answer the question.","['integration', 'complex-analysis', 'residue-calculus', 'cauchy-principal-value']"
4117414,"Prove that $E(X) = \int_{0}^{a} (1-F_X(x))\,dx$ [duplicate]","This question already has answers here : Explain why $E(X) = \int_0^\infty (1-F_X (t)) \, dt$ for every nonnegative random variable $X$ (3 answers) Closed 3 years ago . Let $X$ be a continuous non-negative random variable on $(0,a)$ . Prove that $$E(X) = \int_{0}^{a} (1-F_X(x))\,dx$$ where $F_X(x)$ is the CDF for $X$ . I know that by definition: $$F_X(x) = P(X \leq x) => 1 - F_X(x) = P(X>x)$$ So i can easily go to the next step.
But what should I do in this case? $$
\mathbb{P}(0 < X < a) = \int_0^a f_X(x)dx
$$ Thank you","['expected-value', 'statistics', 'probability', 'random-variables']"
4117496,On the Topological Properties of a Solution Set of Equations,"The following is from some qualifying exam. Let $f(x,y,z)=2x^{2}-2xy+5y^{2}+z^{4}-6$ and $g(x,y,z)=xyz-1$ , is the set \begin{align*}
S=\{(x,y,z)\in\mathbb{R}^{3}:f(x,y,z)=g(x,y,z)=0\}
\end{align*} closed, compact, connected? To tackle this problem, I let $h(x,y,z)=f(x,y,z)-g(x,y,z)$ , then $S=h^{-1}(\{0\})\cap g^{-1}(\{0\})$ . While both $h$ and $g$ are continuous, so $S$ is closed. But I cannot determine if $S$ is compact or connected. For the compactness, one may try to determine if $S$ is a bounded set, but how?","['general-topology', 'analysis']"
4117499,Rearranging a $10 \times 10$ matrix of naturals $1\le n\le 100$ s.t. the sum of every two neighbouring numbers is composite in max. 35 steps,"We are given a $10 \times 10$ matrix which contains every natural number between $1$ and $100$ in arbitrary order. We are to prove that it is always possible to rearrange the matrix by swapping any two entries of choice in at most 35 steps, such that in the resulting matrix every two neighbouring (horizontally or vertically, not diagonally) entries' sum is composite. Naturally, one should begin with showing that such an arrangement is possible in the first place. A very simple example that sprang to mind is constructing the matrix s.t. the first 50 entries are occupied by odd numbers and the last 50 by even numbers. Then, the sum of every two odd entries is even and thus composite and the sum of every two even entries is also even and thus composite. We then need to ensure that the rows in the middle contain even-odd pairs that give composite numers, e.g. $2+7,5+10,12+9,14+11,24+3,20+13,18+17,16+23,37+8,43+6$ . It is therefore possible to construct such a matrix. However, I had some trouble proving that this can be achived by transforming any matrix in maximum 35 swappings. Can you transform any matrix to the configuration I have described in maximum 35 steps or do you need to construct a different configuration within the limits for that? Does one actually need to demonstrate the procedure or can we prove this indirectly? Thank you for your help.","['matrices', 'elementary-number-theory', 'parity']"
4117519,Proving $\mathbb{N} \times \mathbb{N} \cong \mathbb{N}$ when $\mathbb{N}$ includes $0$ [duplicate],"This question already has answers here : Inverting the Cantor pairing function (3 answers) Explicit bijection between $\mathbb N$ and $\mathbb N \times \mathbb N$ [duplicate] (1 answer) Closed 3 years ago . I am struggling to find an explicit bijection $\mathbb{N} \times \mathbb{N} \to \mathbb{N}$ when $\mathbb{N}$ , by definition, includes $0$ . If $\mathbb{N}$ were to exclude $0$ , I could note that any positive integer can be written uniquely in the form $2^{a-1} (2b - 1)$ and then map $(a,b) \to n$ . Including $0$ , I have to change $a - 1$ to $a$ and $2b - 1$ to $2b + 1$ , but I still run into the issue of what to map to $0$ . I can't map $(0,0)$ to $0$ , for example, because $2^{0} (2(0) - 1) = 1$ is the unique element of the form $2^{a-1} (2b - 1)$ mapping to $1$ . Does anyone have any tips for how to repair this bijection?","['elementary-set-theory', 'proof-explanation']"
4117528,Determining complex $c$ for which $\tan^{-1}(e^{\pi/c})+\cot^{-1}(e^{\pi /c})$ yields $\frac\pi2$ or $-\frac\pi2$,"This expression $$\tan^{-1}\left(e^{\pi/c}\right)+\cot^{-1}\left(e^{\pi /c}\right)$$ is equal to $\frac{\pi}{2}$ for real $c$ . But when $c\in\mathbb C$ , it gives either $\frac{\pi}{2}$ or $-\frac{\pi}{2}$ . For an example, for $c=\frac{1}{2}-\frac{i}{2}$ , it gives $-
\frac{\pi}{2}$ ; and for $c=1-i$ , it gives $\frac{\pi}{2}$ . I am trying to find the ranges for values that give two of these answers. How do I find that?","['trigonometry', 'functions', 'algebra-precalculus', 'problem-solving', 'complex-numbers']"
4117533,Find all the varieties of abelian groups (in the sense of universal algebra),"This is Exercise 2.3.6 of Robinson's ""A Course in the Theory of Groups (Second Edition)"" . According to Approach0 , it is new to MSE. (Note: Here ""abelian variety"" is not, at least a priori, in the sense given in this Wikipedia article . See below for details.) The Details: These are essentially the same as in the previous exercise of Robinson's book. Since definitions vary, on page 15, ibid. , paraphrased, it states that A subgroup $N$ of $G$ is normal in $G$ if one of the following equivalent statements is satisfied: (i) $xN=Nx$ for all $x\in G$ . (ii) $x^{-1}Nx=N$ for all $x\in G$ . (iii) $x^{-1}nx\in N$ for all $x\in G, n\in N$ . On page 56, ibid. , Let $F$ be a free group on a countably infinite set $\{x_1,x_2,\dots\}$ and let $W$ be a nonempty subset of $F$ . If $w=x_{i_1}^{l_1}\dots x_{i_r}^{l_r}\in W$ and $g_1,\dots, g_r$ are elements of a group $G$ , we define the value of the word $w$ at $(g_1,\dots,g_r)$ to be $w(g_1,\dots,g_r)=g_1^{l_1}\dots g_{r}^{l_r}$ . The subgroup of $G$ generated by all values in $G$ of words in $W$ is called the verbal subgroup of $G$ determined by $W$ , $$W(G)=\langle w(g_1,g_2,\dots) \mid g_i\in G, w\in W\rangle.$$ On page 57, ibid. , If $W$ is a set of words in $x_1, x_2, \dots$ and $G$ is any group, a normal subgroup $N$ is said to be $W$ -marginal in $G$ if $$w(g_1,\dots, g_{i-1}, g_ia, g_{i+1},\dots, g_r)=w(g_1,\dots, g_{i-1}, g_i, g_{i+1},\dots, g_r)$$ for all $g_i\in G, a\in N$ and all $w(x_1,x_2,\dots,x_r)$ in $W$ . This is equivalent to the requirement: $g_i\equiv h_i \mod N, (1\le i\le r)$ , always implies that $w(g_1,\dots, g_r)=w(h_1,\dots, h_r)$ . [The] $W$ -marginal subgroups of $G$ generate a normal subgroup which is also $W$ -marginal. This is called the $W$ -marginal of $G$ and is written $$W^*(G).$$ On page 58, ibid. , If $W$ is a set of words in $x_1, x_2, \dots $ , the class of all groups $G$ such that $W(G)=1$ , or equivalently $W^*(G)=G$ , is called the variety $\mathfrak{B}(W)$ determined by $W$ . The Question: A variety is said to be abelian if all its members are abelian. Find all the abelian varieties. Thoughts: It occurred to me to consider two extremes first: where the variety $\mathfrak{W}$ is just the class containing only (the isomorphic copies of) the trivial group and where the variety $\mathfrak{W}$ is the class of all abelian groups. I guess I could get at least one of these extremes by considering $$\mathfrak{W}=\mathfrak{B}(\{\varepsilon\}),\tag{1}$$ where $\varepsilon$ is the empty word; but something tells me that $(1)$ includes any & all groups, not just abelian ones; I don't know - I'm not particularly confident in calculating it. Another thought I have is whether an abelian variety might correspond to $$\mathfrak{W}=\mathfrak{B}(\{ [x_1, x_2]\}),\tag{2}$$ where $[x_1,x_2]=x_1^{-1}x_2^{-1}x_1x_2$ is the commutator of the abstract symbols $x_1,x_2$ . Again, I don't know. Please help :)","['group-theory', 'abelian-groups']"
4117539,An elementary function with asymptotic $f'(x)\sim2f(2x)$ for $x\to0^+$,"We want to find an elementary function $f(x)$ that is smooth and strictly increasing on some interval $x\in(0,\epsilon)$ , satisfying $\lim\limits_{\,x\to0^+}f(x)=0$ , whose asymptotic for $x\to0^+$ is $f'(x)\sim2f(2x)$ , that is, $\lim\limits_{\,x\to0^+}\frac{f'(x)}{2f(2x)} = 1$ . By a lengthy series of trial and error I found a solution. You can click “Reveal spoiler” below to see it, unless you want to ponder on this problem on your own for a while before looking at my version. $\displaystyle\quad f(x)=\exp\left(-\left(\frac12+\frac1{\ln2}\right)\cdot\ln x-\frac1{\ln4}\cdot\ln^2\left(-\frac{\ln x}{x\cdot\ln2}\right)\right)$ Its derivative is rather cumbersome, but Mathematica says the limit $\lim\limits_{\,x\to0^+}\frac{f'(x)}{2f(2x)}$ is indeed $1$ , which is also confirmed by manual calculations. The solution is not unique, there are possible variations — I picked one that looked more readable. If we only impose a weaker condition $f'(x)=\mathcal O\left(f(2x)\right)$ , then the solution becomes simpler: $\displaystyle\quad f(x)=2^{\large-\frac{1}{2} \log _2^2\left(-\frac{\log_2\!x}{x}\right)}$ Questions: Is there a systematic approach to finding a solution to this problem? Is there a simpler elementary function with required properties?","['asymptotics', 'real-analysis', 'calculus', 'elementary-functions', 'limits']"
4117555,Is the connecting homomorphism unique?,"Theorem : Given an exact sequence $$0 \longrightarrow A
 \longrightarrow B \longrightarrow C \longrightarrow  0$$ of
chain/cochain exists a connecting homomorphism $\omega : H(C)
 \longrightarrow H(A)$ of degree $1$ or $-1$ which induces a long exact
sequence in homology or cohomology. The construction of $\omega$ is quite explicit, in fact $\omega[\gamma] = \alpha$ where $\alpha$ is a preimage of $\partial \beta$ , where $\beta$ is the element such that $\beta \longmapsto \gamma \in C_n$ . Since in the proof one proves that doesn't depend on the choice of the $\gamma$ representing $[\gamma]$ and $\beta$ which goes to $\alpha$ , could I conclude that whenever I find an explicit function, such that respect those requirements for specific elements, that function is $\omega$ indeed since in homology they are the same function ? The question arises from the connecting homomorphism of the $Cf$ complex, where for the first time I noticed this kind of ""uniqueness"" to assert that in that scenario, the long exact sequence has $\omega = f_*$ as connecting homomorphism. Any clarification or help would be appreciated.","['homological-algebra', 'abstract-algebra', 'homology-cohomology', 'algebraic-topology']"
4117556,Proving that a function is not a contraction,"I am solving the following problem and its parts. Let (C[0,1], $d_\infty$ ) be the metric space of continuous functions on [0,1] where the distance function is defined by $d_\infty(f,g)=\sup_{x∈[0,1]}|f(x)−g(x)|. $ Let $T : (C[0, 1], d_\infty)\to (C[0, 1],d_\infty$ ) be defined by $(Tf)(x)=\int_0^xf(t)dt$ Prove that: T is not a contraction, i.e. there does not exist 0 < K <    1 such that $d_\infty(T f, T g)\leq K · d_\infty(f, g)$ holds for any $f,g ∈ C[0,1]$ . Ive tried an example but I haven't really got anywhere. My work is as follows: $$f'(t)=\int_0^xtdt=\frac{x^2}{2}=F(x)-F(0)$$ so we pick $t$ & $t^2$ such that $d$ ( $t$ , $t^2$ )=sup[ $t$ - $t^2$ ] with max value = $\frac{1}{4}$ and $d$ (T $t$ ,T $t^2$ )=sup[ $\frac{t^2}{2}-\frac{t^3}{3}$ ] with max value =.167",['analysis']
4117579,Solve the equation $\frac{x-13}{x-14}-\frac{x-15}{x-16}=-\frac{1}{12}$,Solve the equation $$\dfrac{x-13}{x-14}-\dfrac{x-15}{x-16}=-\dfrac{1}{12}.$$ For $x\ne14$ and $x\ne 16$ by multiplying the whole equation by $$12(x-14)(x-16)$$ we get: $$12(x-16)(x-13)-12(x-14)(x-15)=-(x-14)(x-16).$$ This doesn't look very nice. Can we do something else at the beginning? $$x-14=(x-13)-1\\x-15=(x-14)-1\\..?$$,['algebra-precalculus']
4117660,Why does field theory still work with generalized field extensions (embeddings)?,"When $E/F$ is a field extension, I've always assumed that $E \supseteq F$ . However, there is a more general definition that $E/F$ is a field extension iff $E, F$ are fields and there is an embedding $i : F \to E$ . For example, with $\omega := e^{2 \pi i/3}$ , $\mathbb{Q}(\sqrt[3]{2}) \cong \mathbb{Q}(\omega \sqrt[3]{2})$ since we are adjoining roots of the same minimal polynomial $X^3 - 2$ , so $\mathbb{Q}(\sqrt{\sqrt[3]{2}}) \subseteq \mathbb{R}$ can be viewed as an extension not only of $\mathbb{Q}(\sqrt[3]{2})$ , but also of $\mathbb{Q}(\omega \sqrt[3]{2})$ . Suppose that $E_1, E_2$ are fields with embeddings $i_1 : F \to E_1$ , $i_2 : F \to E_2$ , so that $E_1/F$ , $E_2/F$ are extensions. Define an $F$ -homomorphism as a ring homomorphism $\phi : E_1 \to E_2$ such that $\phi \circ i_1 = i_2$ . This definition agrees with the usual notion of field extensions as supersets, where an $F$ -homomorphism restricts to the identity on $F$ . This new definition troubles me because I don't know if theorems I've proved using the old definition will still hold true for this generalized definition. If a proof assumes field extensions are supersets, how can I translate it to a proof where the extensions are embeddings? For instance, Brian Conrad proves here that if $E/F$ is algebraic, then there is an $F$ -homomorphism $\phi : E \to \overline{F}$ embedding $E$ in the algebraic closure $\overline{F}$ . Throughout this proof, I assumed $\overline{F} \supseteq F$ . Is there a change in perspective that makes the proof hold with $F$ merely embedding in $\overline{F}$ ? As a corollary, if $E'/E$ is an algebraic extension (in the superset sense), then there is an $F$ -homomorphism $E' \to \overline{F}$ extending $\phi$ . Proof: $E$ embeds in $\overline{F}$ , so $\overline{F}$ is an extension (under the general definition) of $E$ that is an algebraic closure $\overline{E}$ , so there is an $E$ -homomorphism $\psi : E' \to \overline{E}$ , which by definition says $\psi|_E = \psi \circ \mathrm{Id}_E = \phi$ since $\phi$ is the embedding of $E$ in $\overline{E}$ . It feels like there are a lot of moving parts to keep track of; I'm looking for a way to simplify my reasoning.","['field-theory', 'abstract-algebra', 'ring-homomorphism', 'extension-field']"
4117664,"If AB is diagonalisable, then so is $(BA)^2$","I have shown that the minimal polynomials of $XY$ and $YX$ differ by at most a factor of $t$ for any square complex matrices $X$ and $Y$ and that their characteristic polynomials are equal. Using this, I argued as follows: $AB$ diagonalisable so $(AB)^2$ diagonalisable so we can write down its minimal polynomial. $(BA)^2=B(ABA)$ so the minimal polynomial of $(BA)^2$ differs from the minimal polynomial of $(AB)^2$ by at most a factor of $t$ . So if $t$ doesn't divide $m_{AB}(t)$ then we're done since $m_{(BA)^2}$ then a product of distinct linear factors. I'm having trouble figuring out what to do if $t$ divides $m_{AB}$ , in other words if $AB$ has $0$ as an eigenvalue. If $m_{(BA)^2}$ drops the factor of $t$ or is $m_{(AB)^2}$ then we're done, but how can I show it doesn't gain a factor of $t$ ?","['matrices', 'minimal-polynomials', 'linear-algebra', 'eigenvalues-eigenvectors']"
4117678,Dudley's integral convergence for stationary gaussian process,"I am now studying ""Gaussian processes"" course at my university and i've faced a difficult problem for me:
Imagine we have a Gaussian stationary process with expectation equal to zero, variance equal to $1$ , correlation function of this process is monotonic in the right neighbourhood of zero and it looks like: $r(t) = 1 - |t|^\delta\cdot(1 + o(1))$ , $\delta > 0$ , $t \rightarrow 0$ . The question is: does the Dudley's integral of this process converge?
I have tried to build a Delone set for $(-\infty, \infty)$ using metric which is generated by this correlation function and after that my assumption is that this integral diverges, but i am really not sure if it is right.","['probability-theory', 'correlation']"
4117742,Probability that a $d$-dimensional Brownian bridge is greater than a given parameter,"Let $(W_t)_{t\in[0,T]}$ be a Brownian bridge such that $W_0=a$ and $W_T=b$ , the probability that $\forall t\in[0,T],W_t\geqslant x$ given the parameter $x\leqslant\min(a,b)$ is well known : $$ \mathbb{P}(\forall t\in[0,T],W_t\geqslant x)=1-e^{\frac{2(x-a)(b-x)}{T}} $$ (see https://mathoverflow.net/questions/269096/probability-of-general-brownian-or-non-bridge-to-be-higher-than-given-paramete for a proof). My question is : Is there a generalization of this result for $d$ -dimensional Brownian bridges ? That is, if $(W_t)_{t\in[0,T]}$ is a $d$ -dimensional Brownian bridge such that $W_0=a\in\mathbb{R}^d$ and $W_T=b\in\mathbb{R}^d$ , what is the probability that for all $t\in [0,T],\|W_t\|\geqslant x$ where $x>0$ , for a convenient norm $\|\cdot\|$ whether it is $\|\cdot\|_2$ , $\|\cdot\|_{\infty}$ or any norm that makes it possible to compute/approximate. In addition, if we know enough about $\mathbb{P}(\forall t\in[0,T],\|W_t\|\geqslant x)$ , what about $\mathbb{E}[\mu\left(\{t\in[0,T],\|W_t\|\geqslant x\}\right)]$ which is the average time spent above $x$ ?","['stochastic-processes', 'brownian-bridge', 'brownian-motion', 'probability-theory']"
4117788,MLE of power $2$,"Suppose $X$ and $Y$ are random variables and let $x_1, ..., x_n$ be observed values from a random sample of $X$ . Assume that $Y_i = \alpha x_i^2 + \beta_i$ where $\alpha$ is unknown and $\beta_1, ..., \beta_n$ are iid. $N(0, \sigma^2)$ with $\sigma^2$ being unknown (Equivalently assume that the conditional expectation of $Y$ depends quadratically on $X$ and is $0$ when $X$ is $0$ ). (i) Determine the maximum likelihood estimators for $\alpha$ and $\sigma^2$ . (ii) Consider the diagrams below of the regression curve $y = x^2$ . Which set of data has a larger $\hat{\sigma}^2$ ? Why? My attempt: (i) I used this likelihood function $$L(\alpha, \sigma^2) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi \sigma^2}} exp(\sum_{i=1}^{n}\frac{-(y_i - \alpha x_i^2)^2}{2\sigma^2})$$ The negative of the natural log of this is $$-ln(L(\alpha, \sigma^2)) = \frac{n}{2}\ln(2\pi \sigma^2) + \sum_{i=1}^{n}\frac{(y_i - \alpha x_i^2)^2}{2\sigma^2}$$ We let the latter half of the RHS be another function $G$ so that: $$G(\alpha) = \sum_{i=1}^{n}\frac{(y_i - \alpha x_i^2)^2}{2\sigma^2}$$ Minimizing this w.r.t. $\alpha$ gives $$G' = \sum_{i=1}^{n} 2y_ix_i^2 + 2\alpha x_i^4 = 0$$ And so the MLE for $\alpha$ is $$\hat{\alpha} =  \frac{\sum_{i = 1}^{n}Y_ix_i^2}{\sum_{i = 1}^{n}x_i^4}$$ Now, minimizing $-\ln(L)$ w.r.t. $\sigma^2$ gives $$-ln(L(\alpha, \sigma^2))' = \frac{n}{2\sigma^2} - \frac{1}{2\sigma^4}\sum_{i=1}^{n}(y_i - \alpha x_i^2)^2 = 0$$ And so the MLE for $\sigma^2$ is $$\hat{\sigma}^2 =  \frac{1}{n}\sum_{i = 1}^{n} (y_i - \alpha x_i^2)^2$$ (ii) Clearly, diagram 2 has a more widespread set of data, which implies that it has a larger variance. My guess is that diagram 2 has a larger value for $\hat{\sigma}^2$ . Is what I have done correct? Is there any way to justify (ii)? Any assistance is appreciated.","['statistics', 'regression', 'parameter-estimation', 'solution-verification', 'maximum-likelihood']"
4117835,Find all the possible laurent expansions of $f(z)=\frac{1}{\sqrt{1-z^2}}$,"I'm trying to find all the possible laurent expansions of $f(z)=\frac{1}{\sqrt{1-z^2}}$ . In this case, there're two poles of the function at $\pm1$ , but I'm not pretty sure how many cases I need to consider here? Is there only one case? Also, I'm told that I may use that the nth derivative of $\frac{1}{\sqrt{1-x^2}}$ at $x=0$ is $\frac{(2n-1)!!}{2^n}$ , how can I use this identity? Thanks a lot for the help:)","['complex-analysis', 'laurent-series']"
4117926,Proving that a solid is a ball if all plane sections of it are circles,"All plane sections of a solid are circles. Prove that the solid is a ball. Got this from Arthur Engel’s book. The incomplete solution given was as follows; Consider the largest chord of the solid. Any section through this cord is a circle whose diameter is the chord. Otherwise the circle and the solid would have a larger chord. Thus the solid is a ball and one of its diameters is the selected chord. Engels does admit that the proof is not complete, citing that the proof did not address whether a longer chord exists, and that In fact, if the surface of the solid did not belong to the solid, a longer chord would not exist. So we assume that the solid is a closed and bounded set. Then we can apply the theorem of Weierstraβ: A continuous function defined on a closed and bounded set always assumes its global maximum and minimum . He finally closes by stating that “ There are also elementary proofs which are slightly longer (see HMO 1954) ”. My query is whether anyone is able to find elementary proofs to this question, as well as to explain Engel’s solution. I suspect it can be easily(?) resolved with the use of integration and Riemann sums, but I would much prefer a purer proof of the question.","['recreational-mathematics', 'geometry', 'real-analysis']"
4117936,Application of Rankin-Selberg theory,"Let $f$ be a Hecke-Maass form for $SL(2)$ , and its L-function defined by the Fourier coefficients $\lambda_f(n)$ , i.e. $$L(s,f) = \sum_{n=1}^\infty \frac{\lambda_f(n)}{n^s}$$ I would like to understand the proof of the bound on average $$\sum_{n < X} |\lambda_f(n)|^2 \ll X$$ I read that it is an easy consequence of ""Rankin-Selberg theory"". I know Rankin-Selberg integral representations, but what is the relation with this bound and how to deduce it?",['number-theory']
4117986,Is there an analytic continuation at $z=R$?,"Assume $f(z)$ is analytic in $D_R(0)$ (in other words, the corresponding power series $\sum_{k=0}^{\infty}a_kz^k$ has the convergence radius equal to R). Suppose we make an analytic continuation to a point $z = r + i\ 0$ with $r < R$ (see the diagram below) and consider the power series representation for f(z) centered at $z = r$ . If it happens that the corresponding power series has the convergence radius exactly $R − r$ (the blue circle), In this case, can we claim that no analytic continuation exists at the point $z = R$ ? Thanks","['complex-analysis', 'analytic-continuation']"
4117991,Taylor's theorem and estimating $|f'(x)|$ using $f$ and $f''$,"I found a different solution to a problem about Taylor theorem, which is differ from the one introduced in my textbook. And I guess my solution is simpler than the one on the textbook, so I want to check whether there is a flaw on my work. The problem is: A function $f:[0, 2]\to \Bbb R$ is twice differentiable, $|f(x)|\leq 1$ and $|f''(x)|<1$ for all $x\in[0, 2]$ . Show that $|f'(x)|<2$ for all $x\in [0, 2]$ . And this is my work: For any $x\in [0, 2]$ and $y(\neq x)\in [0, 2]$ , by Taylor theorem, $$f(y)=f(x)+f'(x)(y-x)+\frac{f''(c)}{2}(y-x)^2$$ for some $c$ between $x$ and $y$ . By hypothesis, $|f(x)|\leq1, \, |f(y)|\leq 1$ and $|f''(c)|<1$ and hence $$\begin{align} |f'(x)|&=\left|\frac{f(y)-f(x)}{y-x}-\frac{f''(c)}{2}(y-x)\right|\\[.4em] &\leq |f(y)-f(x)|\cdot \frac{1}{|y-x|}+\frac{|f''(c)|}{2}|y-x| \\[.4em] &<\frac{2}{|y-x|}+\frac{|y-x|}{2} \end{align}$$ From AM-GM inequality the latter one has the minimum value $2$ when $|y-x|=1$ , and such $y$ exists for every $x\in [0, 2]$ thus $$|f'(x)|<\min\left\{\frac{2}{|y-x|}+\frac{|y-x|}{2}: x,\, y\in [0, 2], \; x\neq y\right\}=2,$$ which shows the requried result. ■ Thanks.","['taylor-expansion', 'analysis', 'real-analysis']"
4118060,Is there a name for generalized manifolds?,"A topological manifold is a topological space which locally resembles real $n$ -dimensional Euclidean space. Here I consider removing `Euclidean' from manifold: Suppose that $X$ is a topological space, and $M$ is a topological space which locally resembles $X$ , i.e. for each $p\in M$ , there is an open neighborhood $U$ of $p$ in $M$ , an open set $V$ in $X$ , and a homeomorphism $\varphi: U\rightarrow V$ . Is there a name for $M$ ? And is there a book about orbifolds for beginners? I only know some basic concepts of differential manifolds.","['noneuclidean-geometry', 'differential-geometry']"
4118083,On the Wigner semicircle distribution,"Question Let $(X, Y)$ be a jointly continuous pair of random variables such that the marginal density of $X$ is $$f_X(x) = \frac 1 {2\pi} \sqrt{4 - x^2}, \quad -2 < x < 2$$ (also known as the Wigner semicircle distribution) and such that the the conditional distribution of $Y$ given $X = x$ is uniform on the interval $[-\sqrt{4 - x^2}, \sqrt{4 - x^2}]$ . $(a)\quad$ Give a simplified expression for the joint density of $X$ and $Y$ , specifying clearly the set of $x$ and $y$ values for which the joint density is non-zero. $(b)\quad$ How would you describe this joint distribution in words? $(c)\quad$ Hence, or otherwise, show that $Y$ has the same distribution as $X$ . My working $(a)$ $$f_{Y \mid X}(y \mid x) = \frac 1 {2\sqrt{4 - x^2}}$$ $$\begin{aligned}
\implies f_{X, Y}(x, y) & = f_{Y \mid X}(y \mid x)f_X(x)
\\[1 mm] & = \left(\frac 1 {2\sqrt{4 - x^2}}\right)\left(\frac 1 {2\pi} \sqrt{4 - x^2}\right)
\\[1 mm] & = \frac 1 {4\pi}, \quad -2 < x < 2\ \mathrm{and}\ -\sqrt{4 - x^2} < y < \sqrt{4 - x^2}
\end{aligned}$$ $(b)\quad$ I would say that “the joint distribution maps being in a circle of radius $2$ about the origin with probability $\frac 1 {4\pi}$ ”, but I am not sure if this is mathematically correct. $(c)\quad$ I would say that ""since the joint distribution of $X$ and $Y$ maps a full circle of radius $2$ about the origin and the marginal distribution of $X$ maps a semicircle of radius $2$ about the origin, it follows that the marginal distribution of $Y$ also maps a semicircle of radius $2$ about the origin, implying that $Y$ has the same distribution as $X$ "", but again I am not sure if this is entirely correct. If I am wrong anywhere, please do point it out and explain why :)","['statistics', 'random-variables', 'probability-distributions', 'probability', 'density-function']"
4118094,"If $f$ is a surjective normal endomorphism of group $G$, then $f=1_G+g$ where $g$ send $G$ to its center.","This is a question from Jacobson's BA 2. Explanation: An endomorphism of a group is normal if it commutes with every inner-automorphism of a group $G$ wrt the composition of functions. In following context, $1_G$ is identity endomorphism. And for any two endomorphism of G, say $f,g$ set $f+g:x\mapsto f(x)g(x)$ (p.s. I don't really like this notation why it uses plus sign even though it is not necessarily commutative) Anyway, I try to prove: If $f$ is a surjective normal endomorphism of group $G$ , then $f=1_G+g$ where $g$ send $G$ to its center Update: I have already proved the above proposition.
I thought maybe some people do the same question(or homework) in the future and may be confused once as I do, so I leave my answer here rather than delete the post. if it can be proved that $f$ is idempotent on the derived group $G'$ of group G(i.e. the group generated by the commutator of $G$ ), then $f\circ f=1_G\circ f $ forall $x$ in $G'$ . Due to $f$ is surjective, It would be apparent that $f=1_G$ when $x\in f(G')=G'$ (to see $f(G')=G'$ , since $f(G')\subseteq G'$ , and let $f^{-1}$ be a choice function, then for any $xyx^{-1}y^{-1}=f(f^{-1}(x)f^{-1}(y)(f^{-1}(x))^{-1}(f^{-1}(y))^{-1})$ , there element acted by $f$ is apparently in $G'$ so $f(G')\supseteq G'$ ) Having that, it became much easier since forall $x,y\in G$ we have $$ xyx^{-1}y^{-1}=f(xyx^{-1}y^{-1})\\ xyx^{-1}y^{-1}f(y)=f(xyx^{-1})=xf(y)x^{-1}
\implies x^{-1}y^{-1}f(y)=y^{-1}x^{-1}xf(y)x^{-1}\\\implies x^{-1}(y^{-1}f(y))x=y^{-1}f(y) $$ The fact that $f$ is idempotent on $G'$ (or all commutators of $G$ ) relies on $f$ being normal and being homomorphism: $$ f(xyx^{-1}y^{-1})=f(x)f(y)f(x^{-1})f(y^{})^{-1}=f(x)f(f(y)x^{-1}f(y^{-1}))=f(x)f^2(y)f(x)^{-1}f^2(y^{-1})
\\
=f(f(x)f(y)f(x)^{-1})f^2(y^{-1})=f^2(xyx^{-1}y^{-1})
 $$","['group-homomorphism', 'group-theory', 'abstract-algebra']"
4118101,On radially symmetric distributions,"Question Let $X_1, \ldots, X_n$ be independent and identically distributed continuous random variables with a positive continuous joint density function $f(x_1, \dots, x_n)$ . Suppose that the distribution of $X_1, \ldots, X_n$ is radially symmetric about the origin, which means that the joint probability density function $f$ satisfies $$f(x_1, \ldots, x_n) = f(y_1, \ldots, y_n)\quad \mathrm{whenever}\quad x_1^2 + \ldots + x_n^2 = y_1^2 + \ldots + y_n^2.$$ What are all possible distributions of $X_1$ ? My working The motivation here is to find a function that turns multiplication into addition, so the exponential function comes to mind. However, as the functions represent probability densities, they must also have finite area over the interval $(-\infty, \infty)$ . Thus, the inverse exponential function is required. $\implies f_{X_1}(x_1) = ce^{-x_1^2}$ , where $c$ is a constant. Is my reasoning for deducing the possible distributions of $X_1$ correct? If not, how should I approach the question and what should the possible distributions be? This is my first time encountering radially symmetric distributions, so any intuitive explanations will be greatly appreciated :)","['statistics', 'independence', 'probability-distributions', 'symmetry', 'probability']"
4118104,About the derivative of the absolute value function,"For this question, let $f(x) = |x|$ . I found this answer saying that the derivative of the absolute value function is the signum function. In symbols, $$\frac{d}{dx}|x| = \mathrm{sgn}(x).$$ I know that $$f'(x) = \frac{x}{|x|}$$ using the chain rule. Notice that this is well-defined for $x \neq 0$ . However, the definition of the signum function is $$\mathrm{sgn}\,x = \begin{cases}-1 && \text{for } x< 0 \\ 0 &&\text{for }x = 0 \\ 1 && \text{for } x > 0\end{cases}.$$ This will be my question: Are $x/|x|$ and $\mathrm{sgn}\,x$ the same derivative of $|x|$ ?","['calculus', 'derivatives', 'absolute-value']"
4118112,"Prove that $\frac{\sin A}{\sin B}+\frac{\sin B}{\sin A} \leq \frac{A}{B}+\frac{B}{A}$ for acute angles, $A$ and $B$.","Prove that $\frac{\sin A}{\sin B}+\frac{\sin B}{\sin A} \leq \frac{A}{B}+\frac{B}{A}$ for acute angles, $A$ and $B$ . I'm confused about how to do this since we can't say $\frac{\sin A}{\sin B}\leq \frac{A}{B}$ . So I simplified and got $$\frac{\sin^2 A+ \sin^2 B}{\sin A \sin B} \leq \frac{A^2+B^2}{AB}$$ Using $\sin x \leq x$ we can say $\sin^2 A+ \sin^2 B \le A^2+B^2$ but since we cannot divide, this doesn't work either.","['trigonometry', 'inequality']"
4118120,Pattern with $\begin{bmatrix}0&1\\-1&3\end{bmatrix}^k$. How can I prove what corner element will be?,"The matrix $$B= \begin{bmatrix}0&1\\-1&3\end{bmatrix}$$ Is inspired by this matrix which generates the Fibonacci sequence . Upon calculating a few powers of $B$ , I noticed that $({B^k})_{2,2}$ seems to be ${F_{2(k+1)}} - {F_{2k}}$ but I lack an idea of how to prove it. What would be a fruitful approach to do it?","['fibonacci-numbers', 'integers', 'matrices', 'linear-algebra', 'soft-question']"
4118159,Does this algebraic relation between the functions imply linear dependence?,"While working on a geometric problem, I reached to the following uniqueness question: Let $s(t),\tilde s(t), b(t),\tilde b(t)$ be continuous* real-valued functions, and suppose that $$
\bigg(\frac{\tilde s}{s}\bigg)^2+\bigg(\frac{s}{\tilde s}\bigg)^2+\bigg( \frac{\tilde b}{s}-\frac{b}{\tilde  s}+\frac{c}{s}\bigg)^2
$$ is independent of $t$ , where $c \in \mathbb{R}$ is some given non-zero constant. Is it true that $\tilde b = \alpha b, \tilde s = \frac{1}{\alpha} s$ for some constant scalar $\alpha$ ? If this is the case, then one easily sees that $s(t)$ must be constant. *I am fine with assuming higher regularity of the functions, i.e. that all the functions are $C^1$ . I guess we could differentiate the equation, but this doesn't look too simple.","['symmetry', 'systems-of-equations', 'ordinary-differential-equations', 'real-analysis']"
4118171,"Solution verification of the improper integral $\int_1^{+\infty}\frac{\cos^2{t}}{t}\,dt$","Study $$\int_1^{+\infty}\frac{\cos^2{t}}{t}\,dt$$ I have thought the following: I consider the fact $\frac{\cos^2{t}}{t}\leq \frac{1}{t}$ this is not useful since $\int_1^{+\infty}\frac{1}{t}\, dt$ is divergent but this is not helpful to affirm that $\int_1^{+\infty}\frac{\cos^2{t}}{t}\,dt$ is convergent. I want to try to prove that the integral is divergent. To do this I have thought: $$\int_1^{+\infty}\frac{\cos^2{t}}{t}\,dt=\int_1^{\pi}\frac{\cos^2{t}}{t}\,dt+\sum_{k=1}^{\infty}\int_{k\pi}^{(k+1)\pi} \frac{\cos^2{t}}{t}\,dt$$ From this for the reason why $\frac{\cos^2{t}}{t}\geq 0$ in $[1,\pi]$ then $\int_1^{k\pi}\frac{\cos^2{t}}{t}\,dt\geq 0$ and it is not an improper integral, so: $$\int_1^{\pi}\frac{\cos^2{t}}{t}\,dt+\sum_{k=1}^{\infty}\int_{k\pi}^{(k+1)\pi} \frac{\cos^2{t}}{t}\,dt\geq \sum_{k=1}^{\infty}\int_{k\pi}^{(k+1)\pi} \frac{\cos^2{t}}{(k+1)\pi}\,dt= \sum_{k=1}^{\infty}\frac{\pi}{2}\frac{1}{(k+1)\pi}\,dt$$ Now since $ \frac{1}{k+1}\sim \frac{1}{k}$ then the series is divergent and so the integral is divergent. $\textbf{Request:}$ I would be so grateful if you can tell me if my work (so not only the conclusion on the fact that the integral is divergent), described at 2), is right or there are some mistakes and in this case how can I correct them? Thanks a lot in advance.","['improper-integrals', 'real-analysis', 'trigonometric-integrals', 'solution-verification', 'trigonometry']"
4118242,Evaluate the integral $\int\limits_{-\infty}^{\infty} \frac{e^{ax}}{1 + e^x}dx\;$ where $\;0<a<1\;.$,I have to evaluate : $\displaystyle\int_{-\infty}^{\infty} \frac{e^{ax}}{1 +  e^x}dx\;$ where $\;0<a<1\;.$ I know that we have : $\displaystyle\int_{-\infty}^{\infty} \frac{e^{ax}}{1 +  e^x}dx =\lim\limits_{R \to \infty}\int_{-R}^{R} \frac{e^{ax}}{1 +  e^x}dx =$ $\displaystyle\quad=\lim\limits_{R \to \infty}\int_{\gamma_R} \frac{e^{ax}}{1 +  e^x}dx - \int_{C_R} \frac{e^{ax}}{1 +  e^x}dx$ For C $_R$ half-circle runs $R$ from $-R$ and $\gamma_R$ a closed contour. I have a hint: try other closures than C $_R\;.$,"['integration', 'complex-analysis', 'proof-writing']"
4118414,Let $H$ a separable Hilbert Space with a ortonormal base $\{e_n: n \in\mathbb{N}\}$. Prove that $\exists ! T\in \mathcal{B}(H): T(e_n)=d_ne_n.$,"Let a contable and bounded subset $D=\{d_n:n\in \mathbb{N}\}\subset \mathbb{C}$ . Show that exists a unique $T\in \mathcal{B}(H)$ such that $$T(e_n)=d_n e_n,\forall n\in\mathbb{N}. $$ I know that if we had a normal operator $T\in \mathcal{B}(H)$ , the autovectors form a ortonormal base from $H$ . I think that this exercise it is the reciprocal of this fact, but I am not getting a way to prove the existence of such an operator.","['operator-theory', 'orthonormal', 'compact-operators', 'functional-analysis']"
4118446,Maximum likelihood estimator doesn't exist,"I was reading a paper, and the last paragraph it says For example, consider the density function $$p_{(\theta,\sigma)}(x)=\frac{1}{2\sqrt{2\pi}}e^{\large{-\frac{1}{2}(x-\theta)^2}} + \frac{1}{2\sqrt{2\pi} \sigma}e^{\large{-\frac{1}{2\sigma^2}(x-\theta)^2}} $$ of the sequence of independent and identically distributed chance variable $X_1,X_2, \dots$ Here $\theta \in \mathbb{R}$ and $\sigma > 0$ . It is easy to see that the supremum of the likelihood function is almost always infinite , no MLE exists [...] So, the likelihood function would be $\prod_{i=1}^np_{(\theta,\sigma)}(x_i)$ by the i.i.d. condition, but I don't see why this wouldn't have maximum. Even the case where $\theta$ is fixed and $\sigma$ is near to $0$ , the function is close to $0$ . Can I get some insights please?","['statistics', 'log-likelihood', 'probability', 'maximum-likelihood']"
4118484,"If $A$, $B$ idempotent and $AB=0$, then $A+B$ idempotent.","We know that if $A,B$ idempotent then we have (see edit) $$(A+B)^2=A+B\implies AB=0,$$ and I'm wondering whether the converse, i.e. that if $A,B$ idempotent and $AB=0$ then $A+B$ idempotent is true. Expanding we get $$(A+B)^2=A^2+AB+BA+B^2=A+B+BA$$ so we just need to show that $BA=0$ . It certainly isn't true in general that $AB=0\implies BA=0$ , but I couldn't think of an example where $A$ and $B$ are idempotent. For orthogonal projections at least I think that the statement is true (by thinking geometrically), but I need to consider general projections. My intuition is that this statement probably is true. Is this correct, and if so how can I show this? Edit: $(A+B)^2=A+B\implies AB=-BA$ , but then $BAB=-BA$ and $AB=-BAB$ , so $AB=BA$ and therefore $AB=BA=0$ .","['matrices', 'linear-algebra', 'idempotents']"
4118500,"Probability of convergence of $\int_{1}^{\infty} \frac{B_s}{s^{3/2}} \, \mathrm d s$","I'm trying to find out whether the integral $$\int_{1}^{\infty} \frac{B_s}{s^{3/2}} \, \mathrm d s,$$ where $B_s$ is a standard Brownian motion, converges with non-zero probability/almost surely as an improper integral. In the Lebesgue sense, this definitely diverges with nonzero probability (and I'd guess almost surely), because $\Bbb E[|B_t|] = \sqrt{\frac{2t}{\pi}}$ . In the improper/Riemann-sense, it's not quite clear to me though, since I'd think one gets something akin of an alternating sequence, and since the law of the iterated logarithm makes $\frac{B_s}{s^{1/2+\varepsilon}}$ vanish. Thanks! Edit: With a substitution $t = \frac{1}{s}$ I get $$\int_{1}^{\infty} \frac{B_s}{s^{3/2}} \, \mathrm d s = \int_0^1 \frac{1}{t^{3/2}} t B_{1/t} \, \mathrm d t \overset{d}{=} \int_0^1  \frac{1}{t^{3/2}}\tilde B_t \, \mathrm dt,$$ where $\tilde B_t$ is a Brownian motion as well, by the time inversion identity. This looks more like a divergent integral to me, but this must have infinitely many zeros as well in the interval $[0,1]$ so I can't conclude that this is not convergent alternating series. Edit2: The convergence set of the integral $\int_0^1  \frac{1}{t^{3/2}}\tilde B_t \, \mathrm dt$ should be measurable with respect to the germ-sigma-algebra $\mathcal F_0^+$ , I think, and thus have measure $0$ or $1$ by Blumenthal's 0-1-law.","['stochastic-analysis', 'stochastic-processes', 'riemann-integration', 'probability-theory']"
4118515,"Verification of my attempt to calculate $\lim_{x\to \infty} \frac{1}{x}\int_{2}^{x}(1-\frac{\cos^2{t}}{t})\, dt$","For calculating $$\lim_{x\to \infty} \frac{1}{x}\int_{2}^{x}\left(1-\frac{\cos^2{t}}{t}\right)\, dt$$ I have thought to apply the mean value theorem. In fact thanks to the continuity of $1-\frac{\cos^2{t}}{t}$ I can say that $\exists c\in[2, x]:$ $\int_{2}^{x}\left(1-\frac{\cos^2{t}}{t}\right)\, dt=f(c)(x-2)$ .
So $$\lim_{x\to \infty} \frac{1}{x}\int_{2}^{x}\left(1-\frac{\cos^2{t}}{t}\right)\, dt=\lim_{x\to \infty} \frac{1}{x}f(c)(x-2)=1$$ since $f(c)=(1-\frac{\cos^2{c}}{c})=1$ because $c\to \infty$ when $x\to\infty$ . Is it right my work?","['integration', 'limits', 'solution-verification', 'real-analysis']"
4118543,If a manifold admits a real analytic structure then the manifold is analytic?,I have been reading the notion of real analytic space in nLab and found a statement that puzzles me. That Whitney embedding theorem shows that every paracompact smooth manifold admits a real analytic structure. Whitney embedding theorem shows that a differentiable manifold $M$ can be embedded in $\mathbb{R}^n$ for a $n$ sufficient large. We know that $\mathbb{R}^n$ is an analytic manifold but it is not clear for me from this that $M$ admits an analytic structure. Does it mean that $M$ is an analytic manifold? If the answer to this question is true then there is a contradiction since there are smooth functions $f:\mathbb{R} \to \mathbb{R}$ whose graphs are embedded in $\mathbb{R}^2$ that are not analytic e.g. the bump function.,['differential-geometry']
4118578,On two special kind of invertible similar matrices with rational entries,"Let $A,B \in GL(n, \mathbb Q)$ be two similar matrices i.e. there exists $X \in GL(n, \mathbb Q)$ with $XAX^{-1}=B.$ If there is an integer $s$ such that $A^{s+1}B=BA^s$ , then how to prove that $A,B$ are identity matrices?","['matrices', 'similar-matrices', 'linear-algebra', 'linear-transformations']"
4118584,Optimal strategy to maximize cumulative sum of dice rolls but the sum cannot be a square number [duplicate],"This question already has an answer here : Toss a fair die until the cumulative sum is a perfect square-Expected Value (1 answer) Closed 3 years ago . The rule of the game is as follows:
The player rolls a fair six-sided dice repetitively until the game is over. After each roll, if the cumulative sum of all the rolls so far is a square number (1, 4, 9...), then the game is over, and the player gets nothing. If the cumulative sum of all the rolls is NOT a square number, the player can choose to either stop rolling and get paid the current cumulative sum amount of dollars; or she can choose to continue the game and roll again. For example, let's say Alice plays this game and rolls a ""2"". It's not a square number. Alice chooses to continue the game. She rolls a ""6"" this time. Now the cumulative sum is 8. She can choose to keep rolling, or she can end the game and keep 8$ as her winning. Let's say she chooses to roll again and rolls a ""1"", then the cumulative sum becomes 9, a square number. The game ends and she gets no money. My question is: what is the optimal strategy for this game, and what is the expectation of winnings if you play the optimal strategy? Or in other words, if you charge a ticket price to play this game, it should be at least how much? My thoughts: let $E_k$ denote your expected payoff if the current cumulative sum is $k$ . $E_k=0  $ if $k=n^2$ where $n=1,2,...$ The ticket price would be $E_0=\frac{1}{6}(E_1+E_2+E_3+E_4+E_5+E_6)=\frac{1}{6}(E_2+E_3+E_5+E_6)$ And we have $E_2=max(2,\frac{1}{6}\sum^{i=6}_{i=1}E_{2+i}), E_3=max(3,\frac{1}{6}\sum^{i=6}_{i=1}E_{3+i}),...$ etc. To me this looks like a dynamic programming problem, but I cannot find a termination point. At what cumulative sum should I stop rolling? Let's say $N$ is a large integer, then for any cumulative sum $s$ where $(N-1)^2<s<N^2-6$ , we would absolutely choose to roll again. But if we get cumulative sum $N^2-6\leq s<N^2$ , do we also choose to roll gain? For example, $s=N^2-1$ , how do I know if $E_s=max(s,\frac{1}{6}\sum^{i=6}_{i=1}E_{s+i})=s>\frac{1}{6}\sum^{i=6}_{i=1}E_{s+i}?$","['expected-value', 'dice', 'dynamic-programming', 'game-theory', 'probability']"
4118591,Show that there is no differentiable function $f :\Bbb R \to\Bbb R$ such that $f(0) = 1$ and $f'(x) ≥ (f(x))^2\space\forall x\in\Bbb R$,"Show that there is no differentiable function $f :\Bbb R \to\Bbb R$ such that $f(0) = 1$ and $f'(x) ≥ (f(x))^2\space\forall x\in\Bbb R$ . My attempt: Suppose there is a differentiable function such that the above statement holds true. Then, as the function is differentiable so it will satisfy the mean value theorem. $$f(x)-f(0)=f'(c)(x-0),x>0,c \in (0,x)$$ $$f(x)-1=f'(c)x$$ $$f(x)-1 \ge (f(c))^2 x$$ $$f(x)-(f(c))^2 x -1 \ge 0$$ If we let $h(x) = f(x)-(f(c))^2.x-1$ then $h'(x) \ge 0$ then $f'(x)-(f(c))^2 \ge 0$ . How do I proceed after this and obtain a contradiction.","['problem-solving', 'analysis', 'real-analysis']"
4118596,"What are the smooth, compact hypersurfaces of the euclidean space whose interior is contractible?","Let $S$ be a smooth, compact hypersurface (without boundary) of the euclidean space $\mathbb R^N$ . In addition assume that the interior region of $S$ ( i.e., the bounded connected component of $\mathbb R^N\backslash S$ ) is contractible. Does it imply that $S$ is diffeomorphic to the sphere? Of course, this is true for $N=2$ . I do not know whether it still holds in higher dimensions $N\geq 3$ .","['differential-topology', 'algebraic-topology', 'differential-geometry']"
4118622,Show that $f$ is an order isomorphism from $\mathbb{N}$ to $I_{\omega}$,"Am reading Folland's Real Analysis book, and on page 10 he introduces the set $\Omega$ of countable ordinals. This set is the unique (up to order isomorphism) uncountable well ordered set such that each initial segment $I_x$ of $\Omega$ is countable (proposition 0.18). This set has the property that every countable subset of $\Omega$ has an upper bound (proposition 0.19). Folland writes : The set $\mathbb{N}$ can be identified with a subset of $\Omega$ as follows. Set $f(1)=\min\Omega$ , and proceeding inductively set $f(n)=\min \big(\Omega\setminus\{f(1),\dots,f(n-1)\}\big )$ . The reader may verify that $f$ is an order isomorphism from $\mathbb{N}$ to $I_{\omega}$ , where $\omega$ is the smallest element of $\Omega$ such that $I_\omega$ is infinite. Is this proof correct? First we need to show the existence of $\omega$ by showing that the set $\{x\in\Omega: I_x \text{ is infinite}\}$ is nonempty. Since $\Omega$ is uncountable there exist a countably infinite subset $A\subset\Omega$ , and by proposition 0.19 $A$ has an upper bound $\alpha$ in $\Omega$ . Then $A\subset I_{\alpha}\cup\{\alpha\}$ and since $A$ is infinite so is $I_{\alpha}$ . Second we show that $f:\mathbb{N}\to I_{\omega}$ is an order isomorphism. From the definition of $f$ we have $f(n)<f(n+1)$ and $I_{f(n)}=\{f(1),\dots,f(n-1)\}$ for each $n$ , and so the range of $f$ is indeed a subset of $I_{\omega}$ . To show that $f$ is surjective, let $x\in I_\omega$ . If $I_x=\emptyset$ then $x=f(1)=\min \Omega$ . Otherwise let $x_1<x_2<\dots<x_m$ denote the elements of $I_x$ ( $m\geq1$ ). It is clear that $x_1=f(1)=\min \Omega$ . Assuming $x_k=f(k)$ for all $k=1,\dots,n<m$ , it follows that $x_{n+1}$ is the smallest element of $\Omega\setminus\{f(1),\dots,f(n)\}$ , that is $x_{n+1}=f(n+1)$ . By strong induction it follows that $x_k=f(k)$ for all $k=1,\dots, m$ , which in turn implies $x=f(m+1)$ . This shows that $f$ is surjective. Finally an induction on $n-m$ shows that $n<m$ implies $f(n)<f(m)$ , and so $f$ is order preserving and injective. Altogether we get that $f$ is an order isomorphism. Any feedback is very appreciated.","['elementary-set-theory', 'solution-verification', 'well-orders', 'real-analysis']"
4118642,Operator targeting $\ell^2$-direct sum of Hilbert spaces continuous if all its projections are continuous?,"Let $(U, \|\cdot\|_U)$ be a Banach space, $(H_k, \|\cdot\|_k)_{k\in\mathbb{N}}$ be a sequence of Hilbert spaces and denote by $$\tag{1}H:=\bigoplus_{k=1}^\infty H_k \equiv \left\{h=(h_k)\ \middle| \ h_k \in H_k, \,\forall k\in\mathbb{N} \quad \text{and} \quad \|h\|_H^2:=\sum_{k=1}^\infty\|h_k\|_k^2 < \infty \right\}$$ the $\ell^2$ -direct sum of these spaces (which is known to be a Hilbert space itself). Let further $\pi_k : H \rightarrow H_k$ , $\pi_k((h_k)) := h_k$ , be the projection of $H$ onto its $k^{\mathrm{th}}$ -component. Question: Is it true, then, that a (not necessarily linear) map $T : U \rightarrow H$ is $\textit{continuous}$ if its projections $$\tag{2}T_k := \pi_k\circ T \quad \text{are continuous} \quad \text{for each } \ k\in\mathbb{N}?$$ Remark: If necessary, it may be assumed that each of the $H_k$ are finite-dimensional. Any references, hints or proofs (or indeed counterexamples) that cover this are appreciated! (This is not a homework question.)","['operator-algebras', 'operator-theory', 'hilbert-spaces', 'continuity', 'functional-analysis']"
4118653,"Where do those ""drops"" get created in the plot of $\sin x+\sin y=\frac{y^2}x$?","If you try to plot this graph: $$\sin x+\sin y=\frac{y^2}x$$ You will get an odd-looking shape: But if you zoom out a little you can see a kind of cycle with squashed ""squares"": But one of them has a ""drop"" ""falling"" from it, it seems to start around $\pm13.053$ If we zoom out a little more we discover a cycle of drops and furthermore, we see a new cycle of drops starts, this starts around $\pm32.334$ Where exactly do those ""drops"" create and why?","['trigonometry', 'functions', 'graphing-functions']"
4118654,Bounded in Probability and smaller order in probability,"I wanted to prove that if $X_n$ is bounded in probability and $Y_n = o_p(X_n)$ , then $Y_n \rightarrow 0$ in probability I  know the following definitions that is $X_n$ is bounded in probability meaning that $P(|X_n|<M)>1-\epsilon$ and I know that $Y_n = o_p(X_n)$ implies that $Y_n/X_n \rightarrow0$ in probability","['statistics', 'probability-theory', 'asymptotics']"
4118697,Number of connected components of zero set of polynomial with bounded number of terms,"Suppose $f:\mathbb{R}^d\to\mathbb{R}$ is a polynomial of degree $\ell$ . Then, the number of connected components of its zero set $\{a\in\mathbb{R}^d : f(a) = 0\}$ is bounded by roughly $\ell^{d}$ . I've seen this result attributed to Warren, Milnor-Thom, and stated to be a consequence of Bezout's theorem (a concrete reference would be much appreciated, especially one that derives this using Bezout's theorem). Onto my main question: suppose $f$ is known to only have $k$ terms. Is there a better bound on the number of connected components of the zero set of $f$ that depends on $k$ ? I suspect that there might be a reference that answers this, but I don't know much about this area and would appreciate any suggestions on where to look. Thanks in advance!","['algebraic-curves', 'reference-request', 'algebraic-geometry', 'polynomials', 'real-algebraic-geometry']"
4118742,Gateaux derivative of the following operator,"Let $f \colon \mathbb{R}  \to \mathbb{R}$ be $\mathcal{C}^1[a,b]$ with bounded derivative.
Let $H=L^2[a,b]$ and consider the Nemytskii operator $F\colon H \to H$ defined by $$F(x)(\psi)=f(x(\psi))$$ for $\psi \in [a,b]$ .
Then I need to show that the Gateaux derivative $DF \colon H \to \mathcal{L}(H)$ of F is $$DF(x) h =\frac{\partial f}{\partial x} (x) h$$ for $h \in H$ being the direction. With the last inequality i mean that $$DF(x) h (\psi) =\frac{\partial f}{\partial x} (x(\psi)) h(\psi)$$ for every $\psi \in [a,b]$ so that $DF(x)h$ is the Nemystkii operator associated with the derivative of $f$ . I take $\psi \in [a,b]$ fixed and I compute $$\lim_{\alpha \to 0}\frac{F(x+\alpha h) - F(x)}{\alpha} (\psi)=\lim_{\alpha \to 0}\frac{f(x(\psi)+\alpha h(\psi)) - f(x(\psi))}{\alpha}= \frac{\partial f}{\partial x} (x(\psi))h(\psi)$$ for every $\psi$ . Then can I conclude that if I define a Nemitskii operator $DF(x)h$ by $DF(x) h (\psi)=\frac{\partial f}{\partial x} (x(\psi))$ this is the Gateaux derivative of $F$ in direction $h$ ? I mean by the previous equality the following $$\lim_{\alpha \to 0}\frac{F(x+\alpha h) - F(x)}{\alpha} $$ is a Nemistkii operator
and its action on $\psi$ is the same as $DF(x)h$ so that $$\lim_{\alpha \to 0}\frac{F(x+\alpha h) - F(x)}{\alpha} =DF(x)h$$ and then $DF(x)h$ is the Gateaux derivative.","['gateaux-derivative', 'solution-verification', 'derivatives', 'functional-analysis']"
4118843,Number of hypercubes intersected by a hyperplane in a uniform partitioned hypercube,"Suppose I have a $d$ -dimensional unit hypercube $[0,1]^d$ . I partition each dimension uniformly into $k$ intervals. Now the unit hypercube is partitioned into $k^d$ small hypercubes. I'm wondering how many of these hypercubes can a hyperplane intersect as $k$ goes to infinity. My conjecture is that this number can be bounded by $C\cdot k^{d-1}$ where $C$ is independent of $k$ . But I cannot come up with a proof. Any suggestions on what I should be looking for?
Thanks in advance.","['euclidean-geometry', 'algebraic-geometry', 'geometry']"
