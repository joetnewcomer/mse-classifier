question_id,title,body,tags
654231,Integrating $I(\alpha)=\int^{\infty}_{0} \frac{x^{\alpha}}{x^4+1}dx$,"Here is the question: Let $P(x)$ be a polynomial of degree $d>1$ with $P(x)>0$ for all $x>0$. For what values of $\alpha \in \mathbb{R}$ does the integral $I(\alpha)=\int^{\infty}_{0} \frac{x^{\alpha}}{P(x)}dx$ converge? Give a formula for $I(\alpha)$ in terms of residues. Compute $I({\alpha})$ for $P(x)=1+x^4$. I'm definitely a bit rusty...So far I have tried an integration technique from $[0, \infty)$, around a large circle, and back onto $[0, \infty)$. The last part should be shifted by an analytic continuation of $x^{\alpha}$. Now we need only consider our poles at $z=-1$ which are given by $\zeta_{8}$, $\zeta^{3}_{8}$, $\zeta^{5}_{8}$, and $\zeta^{7}_{8}$. Now can I just go ahead and sum the residues? Is anything strange happening here? Thanks very much!","['complex-integration', 'complex-analysis']"
654244,Drunk problem involving probability of being in a circle.,"This is the typical drunk problem wherein the person is confined to moving either to the North, South, East, or West but never diagonally with just one step. A step has a length $L$. What is the probability that the drunk will never leave a circle of radius $2L$ after $N$ steps? Obviously, the probability is zero for $N=1$ and $N=2$. For $N=3$, I got it to be $3/4$ although I am not sure whether this is correct. For $N>3$, I am just lost.","['random-walk', 'probability']"
654263,Please recommend a nice and concise math book on probability theory.,"My intention is neither to learn basic probability concepts, nor to learn applications of the theory. My background is at the graduate level of having completed all engineering courses in probability/statistics -- mostly oriented toward the applications without much emphasis on mathematical rigor. Now I am very interested in learning the core logic and mathematical framework of probability theory, as a math branch. More specifically, I would like to learn answers to the following questions: (1) What are the necessary axioms from which we can build probability theory? (2) What are the core theorems and results in the mathematical theory of probability? (3) What are the derived rules for reasoning/inference, based on the theorems/results in probability theory? So I am seeking a book that covers the ""heart"" of mathematical probability theory -- not needing much on applications, or discussion on extended topics. I would like to appreciate your patience for reading my post and any informative responses. Regards,
user36125","['reference-request', 'axioms', 'probability']"
654275,Homography between ellipses,This is a spin-off from a comment on Stack Overflow . How can I find a homography between two ellipses in the plane?,"['geometry', 'conic-sections', 'projective-geometry']"
654279,$211!$ or $106^{211}$:Which is greater?,"A BdMO question: Let $a=211!$ and $b=106^{211}$. Show which is greater with proper logic. By matching term by term,it is pretty easy to note that $106!<106^{106}$ $106^{105}<107\cdot 108\cdot 109...........211$ However I am at a loss to see how this will help.The solution must something along the lines of this one but I am unable to see so.I also factorized 106 but it complicated matters further.A hint will be appreciated.","['inequality', 'algebra-precalculus', 'contest-math', 'number-comparison', 'factorial']"
654314,How to solve the six elements equations below?,"How to get the exact or numerical solutions of the six elements equations below?
$$\begin{cases}
\frac{c_1}{1-x_1}+\frac{c_2}{1-x_2}+\frac{c_3}{1-x_3}=0\\
\frac{c_1}{1-x_4}+\frac{c_2}{1-x_5}+\frac{c_3}{1-x_6}=0\\
c_1\ln{\frac{x_1}{1-x_1}}+c_2\ln{\frac{x_2}{1-x_2}} +c_3\ln{\frac{x_3}{1-x_3}}=0\\
c_1\ln{\frac{x_4}{1-x_4}}+c_2\ln{\frac{x_5}{1-x_5}} +c_3\ln{\frac{x_6}{1-x_6}}=0\\
\frac{x_1(1-x_1)}{x_4(1-x_4)}=\frac{x_2(1-x_2)}{x_5(1-x_5)}=\frac{x_3(1-x_3)}{x_6(1-x_6)}
\end{cases}$$
where $ c_1,c_2,c_3 $ are constants, and $x_i\in(0,1), i=1,2,3,4,5,6$. Using $y_i=1-x_i$ instead of $x_i$ makes the equations a little more succinct
$$\begin{cases}
\frac{c_1}{y_1}+\frac{c_2}{y_2}+\frac{c_3}{y_3}=0\\
\frac{c_1}{y_4}+\frac{c_2}{y_5}+\frac{c_3}{y_6}=0\\
c_1\ln{\frac{1-y_1}{y_1}}+c_2\ln{\frac{1-y_2}{y_2}} +c_3\ln{\frac{1-y_3}{y_3}}=0\\
c_1\ln{\frac{1-y_4}{y_4}}+c_2\ln{\frac{1-y_5}{y_5}} +c_3\ln{\frac{1-y_6}{y_6}}=0\\
\frac{y_1(1-y_1)}{y_4(1-y_4)}=\frac{y_2(1-y_2)}{y_5(1-y_5)}=\frac{y_3(1-y_3)}{y_6(1-y_6)}
\end{cases}$$","['linear-algebra', 'algebra-precalculus', 'systems-of-equations', 'numerical-methods']"
654315,How to convert a dot product of two vectors to the angle between the vectors.,"I am currently learning to use normalized vectors in the computer games I'm creating. I've learned that in order to know ""the angle"" between two vectors, I need to use Dot Product. This gives me a value between $1$ and $-1$. $1$ means they're parallel to each other, facing same direction (aka the angle between them is $0^\circ$). $-1$ means they're parallel and facing opposite directions ($180^\circ$). And $0$ means the angle between them is $90^\circ$. But I want to know, how to convert the dot product of two vectors, to an actual angle in degrees. For example, if the dot product of two vectors is $0.28$. How can I convert it to an actual angle, between $0^\circ$ to $360^\circ$? Thank you","['geometry', 'vectors']"
654320,Fundamental group of Poincaré sphere,"Do the two presentations below, $$G=\langle d,v \mid dv^2d=vdv, dv^3d=v^2 \rangle$$ and $$\langle r,s,t \mid r^2=s^3=t^5=rst \rangle = \langle s,t \mid (st)^2=s^3=t^5 \rangle,$$ define the same group? Motivation: I am working on Poincaré homology sphere $X$, constructed by identifying the opposite faces of a dodecahedron using the minimal clockwise twist to line up the faces. I was able to verify that its homology groups are the same as the 3-sphere, and now I would like to compute its fundamental group. Using van Kampen theorem, I found the first presentation for $\pi_1(X)$; however, I did not succeed in identifying it with the binary icosahedral group (hoping I computed correctly the fundamental group), given by the second presentation. Nota Bene: Using a mathematical software, I checked that $G$ has order $120$.","['algebraic-topology', 'group-theory', 'group-presentation', 'fundamental-groups']"
654324,Determinant (and invertibility) of generalized Vandermonde matrix,"I have stumbled upon the following generalization of Vandermonde
matrix when solving some problem in linear algebra related to Jordan normal form. Let us consider some number $\lambda$ and we assign to this number an
$n\times m$ matrix $V_m(\lambda)$ such that the first column is of the
form $(1,\lambda,\lambda^2,\dots,\lambda^{n-1})^T$, the second column is
of the form $(0,1,2\lambda,\dots,(n-1)\lambda^{n-2})^T$ etc. I.e., the
$m$-th column will be
$(0,\dots,0,1,\binom{m}{m-1}\lambda,\dots,\binom{n-1}{m-1}\lambda^{n-m})$,
i.e.
$$V_m(\lambda)=
\begin{pmatrix}
1             & 0                  & 0                        & \ldots & 0 \\
\lambda       & 1                  & 0                        & \ldots & 0 \\
\lambda^2     & 2\lambda           & 1                        & \ldots & 0 \\
\lambda^3     & 3\lambda^2         & 3\lambda                 & \ldots & 0 \\
\vdots        & \vdots             & \vdots                   &        & \vdots \\
\lambda^{n-1} & (n-1)\lambda^{n-2} & \binom{n-1}2\lambda^{n-3}  & \ldots &
\binom{n-1}{m-1}\lambda^{n-m}
\end{pmatrix}$$
In the other words, the entry in $k$-th row and $l$-th column is $\binom{k-1}{l-1}x^{k-l}$. Now if we have some numbers $m_1,\dots,m_k$ such that
$m_1+\dots+m_k=n$, we can define an $n\times n$-matrix
$$V_{m_1,\dots,m_k}(\lambda_1,\dots,\lambda_k)=
\begin{pmatrix}V_{m_1}(\lambda_1) & V_{m_2}(\lambda_2) & \dots &
V_{m_k}(\lambda_k) \end{pmatrix}.$$ For example, $$V_{3,2}(x,y)=
\begin{pmatrix}
  1 & 0 & 0 & 1 & 0 \\
  x & 1 & 0 & y & 1 \\
  x^2 & 2x & 1 & y^2 & 2y \\
  x^3 & 3x^2 & 3x & y^3 & 3y^2 \\
  x^4 & 4x^3 & 6x & y^4 & 4y^3
\end{pmatrix}
$$ Such matrix is indeed called generalized Vandermonde matrix by some
authors, for example here or here .
(Although the term generalized Vandermonde
matrix is also used in different meanings, for example here .) The determinant of generalized Vandermonde matrix is $$\prod_{i<j}
(\lambda_j-\lambda_i)^{m_im_j}.$$ We already have at this site several questions about the usual
Vandermonde matrix, for example Vandermonde Determinant , Vandermonde determinant by induction , Proof determinant of transpose Vandermonde matrix is $\prod_{1\le i\lt j\le n}(\alpha_i-\alpha_j)$ , Why are Vandermonde matrices invertible? Various derivations of determinant of Vandermonde matrix and also some
proofs of the fact that it is invertible (for distinct $\lambda_i$'s)
are given in those questions. I am wondering about the same question
for generalized Vandermonde matrix. How can we show that generalized Vandermonde matrix is invertible when $\lambda_i\ne\lambda_j$? How can we evaluate the determinant of generalized Vandermonde matrix?","['linear-algebra', 'determinant']"
654330,Eigenvalues of a matrix satisfying a polynomial,"The theorem of Cayley-Hamilton says that a matrix satisfies it's characteristic polynomial. But can we also make a statement about the eigenvalues if a matrix satisfies a monic polynomial in general? So let's say that we have a matrix $A \in \mathbb{C}^{m,m}$ and a monic polynomial $p$ of degree $n$ (with $n<m$) for which $p(A)=0$. What can be said about the eigenvalues of $A$ with this information?","['linear-algebra', 'eigenvalues-eigenvectors']"
654333,Prerequisites for reading Automorphic Forms on Adele Groups,"I'm interested in reading Gelbart's book ""Automorphic Forms on Adele Groups"". I have a solid background knowledge at the first-year graduate level (I've passed quals), but I don't know what the prerequisites for Gelbart's book are. I've browsed through the book. To be a bit more descriptive about my background: I haven't taken a course in representation theory (beyond representations of finite groups) and would be interested in knowing where I can get the required representation theory background before reading the book. In addition, I am unfamiliar with terms like the ""spectrum"" of the space of cusp forms, for instance.","['soft-question', 'number-theory']"
654344,"$f$ differentiable, $f(x)$ rational if $x$ rational; $f(x)$ irrational if $x$ irrational. Is $f$ a linear function?",Let $f$ be an everywhere differentiable function whose domain consists of all real numbers. Assume that $f(x)$ is rational for rational $x$ and irrational for irrational $x$. Can we conclude that $f$ is a linear function?,"['functions', 'rational-functions', 'irrational-numbers', 'real-analysis']"
654354,German exercises for Abitur. Translate into english,"Please help me to translate into English the last three questions(f,g,h) from this photo. Can you give me some ideea to solve this problems? Can you recommend me some math, physics dictionary? Thanks!","['translation-request', 'functions', 'mathematical-german']"
654360,"The dimension of the subvariety of matrices of rank 3 in M(n, m)","Consider the space $M(m, n)$ of matrices of size $m \times n$ over field $K$. Let $X \subset M(m, n)$ be the subset of matrices of rank $3$. Show that $X$ is an algebraic subvariety of $M(m, n)$. Compute the dimension of the variety $X$.","['matrices', 'algebraic-geometry']"
654401,A problem on limit superior,"Let $A_n$ be the square $[(x,y) : |x|\leq 1, |y|\leq 1]$ rotated through the angle $2\pi n\theta$. I need to find the geometric description of $lim sup_n A_n$ when $\theta$ irrational. I understand intuitively from the fact that the set $\{ frac(n \theta) : n \in \Bbb N\}$  ($frac(x)$ is fractional part of $x$) is dense in $[0,1]$ that lim sup will be the outer open circle of the unit square aligned with the axes. But how to formally write it i.e. given $k$ and a point $(p,q)$ how to find $n \gt k$ and $(x,y)$ in the original square (aligned with the $X$ and $Y$ axes) such that $(p,q)$ is the transformed version of $(x,y)$ in $A_n$","['probability-theory', 'real-analysis']"
654408,Volume form on S^1,"I know that the volume form on $S^1$ is $\omega= ydx-xdy$. But how I can derive that? The only things that I know are the definition of differential q-form, and the fact that the vector field $v= y \frac{\partial}{\partial x}-x\frac{\partial}{\partial y}$ never vanishes on $S^1$.",['differential-geometry']
654436,condition number after scaling matrix,"Maybe a well-known question. Let $\Sigma$ represent a real symmetric positive definite matrix, i.e. a covariance matrix. Which diagonal matrix $D$ with positive diagonal minimizes the condition number $\frac{\lambda_{\max}(D\Sigma D)}{\lambda_{\min}(D\Sigma D)}$? In contrast to some other literature on preconditioners, the pre- and post multiply matrix $D$ are the same here. There could be a clue here if the pre- en post-D would be allowed to differ. Unfortunately, I have no access to eq. (A.74). Numerical experiments suggest that the identity matrix is always optimal if $\Sigma$ is two dimensional. For larger dimensions, the optimum is nontrivial.","['matrices', 'numerical-linear-algebra', 'numerical-methods']"
654451,for any ring $A$ the matrix ring $M_n(A)$ is simple if and only if $A$ is simple,"Let integer $n\geq 1$. I have obtained that for any field $k$, the matrix ring $M_n(k)$ is simple, i.e., $M_n(k)$ contains no nonzero proper two sided ideals. Now I want to prove that: for any ring $A$ (not necessarily commutative), the matrix ring $M_n(A)$ is simple if and only if $A$ is simple. How to prove?","['noncommutative-algebra', 'ring-theory', 'abstract-algebra', 'matrices', 'modules']"
654454,"if $A^\times $ is a commutative group, does $A$ necessarily be a commutative ring?","Let $A$ be a ring and $A^\times$ be the collection of unit elements of $A$. If $A$ is a commutative ring, then $A^\times$ is a commutative group. Conversely, if $A^\times $ is a commutative group, does $A$ necessarily be a commutative ring? Is there any counterexample?","['noncommutative-algebra', 'ring-theory', 'abstract-algebra', 'commutative-algebra', 'group-theory']"
654461,How to find all polynomials P(x) such that $P(x^2-2)=P(x)^2 -2$?,"I am trying the fallowing exercise :
Solve $P(X^2 -2)=P(X)^2 -2$ with P a monic polynomial (non-constant) My attempt : Let P satisfying $P(X^2-2) = (P(X))^2-2$ Then $Q(X)=P(X^2-2) = (P(X))^2-2$ Therefore,  $$Q(X^2-2) = (P(X^2-2))^2-2 = (P(X)^2-2)^2-2 = Q^2-2$$ As X is a solution, by defining the sequence: $(P_n)_{n \geq 1}$ with $P_1 = X$ and for all $n \geq 1, P_{n+1} = P_n^2-2$ We obtain a sequence of polynomials which are solutions. But I don't know how to prove it's the only one. If someone have an idea to prove it or an another method to solve the problem ? Thank you in advance for your time.","['calculus', 'functional-equations', 'real-analysis', 'polynomials']"
654465,Do all square matrices have eigenvectors?,I came across a video lecture in which the professor stated that there may or may not be any eigenvectors for a given linear transformation. But I had previously thought every square matrix has eigenvectors.,"['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
654478,Calculate Limit 0f nested square roots,It is an interesting task to try finding the limit of nested square root expressions. $$\lim_{n \to \infty}\left( 1 + \sqrt{2 + \sqrt{3+ ... + \sqrt {n + \sqrt{n+1}}}}\right)$$ How to solve this one?,"['nested-radicals', 'limits']"
654507,"Numerically calculate the second ""left hand"" derivative","The Problem I have a series of measurements for which I have to calculate the first and second derivative numerically in a ""live"" fashion, i.e. using only previous data. This is easy for the first derivative: $f'(x) \approx \frac{f(x) - f(x-h)}{h}$ For the second derivative I use this formula: $f''(x) \approx \frac{f(x) - 2f(x-h) + f(x-2h) }{h^2}$ The problem I have is that the results are a good estimate only for ""previous"" values of $x$. I.e. $f'(x)$ yields a good estimate for $x-\frac12 h$ and 
 $f''(x)$ yields a good estimate for $x-h$. This is because the formulae I use are indeed the central formulae at these points, 
e.g. $f'(x + \frac12 h) = \frac{f(x+\frac h2)-f(x-\frac h2)}{2 \frac h2}$ The question Is there a way to create a better estimate for the second derivation but still stick to using only ""previous"" points? Comparison of approaches so far I visualized the three approaches so far, using $f(x) = \operatorname{sin}(2x)$ as an example and $h = 0.16$: orange diamond: based on $f''(x) \approx \frac{f(x) - 2f(x-h) + f(x-2h) }{h^2}$ pink cross: The points from orange diamond translated by $(-h,0)$ green circle: Using 4 points for approximation yielding $f''(x)\approx \frac{2 f(x) - 5f(x-h) + 4 f(x-2h)- f(x-3h)}{h^2}$  as suggested by gammatester Note: If you do a linear extrapolation of $f''(x-2h)$ and $f''(x-h)$ (using a central differential approach) like $f''(x) = 2 f''(x-h) - f''(x-2h)$ as suggested by Hagen von Eitzen , you'll end up with the same formula as proposed by gammatester. It seems to me that adding more points to the formulae not necessarily decreases the error, especially if the ""scanning distance"" $h$ is quite large. The same function with $h = 0.06$: The solution I did take me some time but after I tested the higher accuracy formulae the wikipedia page gammatester mentioned, I found a formula that is quite accurate and only uses previously gathered data. $f''(x) \approx \frac{ \frac{469}{90} f(x-0h) −\frac{223}{10} f(x-1h) + \frac{879}{20} f(x-2h) −\frac{949}{18} f(x-3h) + 41 f(x-4h) −\frac{201}{10} f(x-5h) +\frac{1019}{180} f(x-6h)− \frac{7}{10} f(x-7h)}{h^2} $","['derivatives', 'numerical-methods']"
654519,Corresponding analytic function?,"I have found a general harmonic function of form $a x^3 - 3dx^2 y - 3axy^2 + dy^3$ and it's harmonic conjugate $v = 3ax^2y - 3dxy^2 + ay^3 + dx^3 + K$ where k is constant. I now am asked to find the corresponding analytic function $f(z) $ expressed in terms of $z$, and to check up to an imaginary constant $f(z) = 2u(\frac{1}{2}z, \frac{1}{2i}z) - u(0,0)$. I know that an function $f(z)$ is analytic if its derivative is continuous at $z$, and it should be of form (I imagine) $u(x,y) + iv(x,y)$, but not how to find such a function. If I could have some pointers that would be great. Update: Substituting $f(z) =  u(x,y) + iv(x,y)$ I have managed to find $f(z) = z^3(a + di)$ but I still don't understand the last part?","['analyticity', 'complex-analysis']"
654532,Finding the widest angle to shoot a soccer ball from the sideline using optimization,"I'm trying to do an independent project for my Math class, but I was stuck and couldn't figure out how to use optimization to find position along the sideline that gives the widest angle to shoot. As in the picture, A and C demonstrate positions that provide smaller angle to shoot, while B provides a wider angle to shoot.  I tried using law of cosine, but because both sides of triangles change every times I didn't know how to apply optimization to it :( if anyone know, please help, any suggestion would be appreciate","['optimization', 'trigonometry']"
654548,How find this sum $\sum_{k=1}^{n}\frac{(a_{k}+1)(b_{k}+1)}{a_{k}+b_{k}+3}$,"let sequence $\{a_{n}\},\{b_{n}\}$ such
$$a_{1}=2,b_{1}=1$$ and
$$a_{n+1}=\dfrac{a_{n}+1}{a_{n}+b_{n}+3},b_{n+1}=\dfrac{b_{n}+1}{a_{n}+b_{n}+3}$$ find the 
$$\sum_{k=1}^{n}\dfrac{(a_{k}+1)(b_{k}+1)}{a_{k}+b_{k}+3}$$ my idea: since
$$a_{n+1}+b_{n+1}=\dfrac{a_{n}+b_{n}+2}{a_{n}+b_{n}+3}$$
$$\dfrac{a_{n+1}}{b_{n+1}}=\dfrac{a_{n}+1}{b_{n}+1}$$ maybe  we can note this 
$$a+b+ab+1=(a+1)(b+1)?$$ then I can't ,Thank you","['summation', 'sequences-and-series']"
654560,no morphism between curves of different genus,"Let $C_1,C_2$ be two smooth irreducible curves of genus 4,3 resp.
  Prove there is no morphism $\phi: C_1 \to C_2$. Well, the tool of treating genera is Hurwitz's theorem, which says here that
$6=4+\sum (n(x)-1)$, for $x$ the ramification points of $\phi$ in $C_1$, and we can replace the $n(x)-1$ with $\deg \phi -k(y)$, where k is the number of points mapped by $\phi$ to the branching point $y$.
Perhaps being a morphism somehow constricts the behavior of ramification points, but I should still use the irreducibility, and don't have a clue how.","['algebraic-geometry', 'algebraic-curves']"
654581,"Is this set $\{(x,y) \in \mathbb R^2 : |x|+|y|\leq 1\}$ compact?","Is this set $\{(x,y) \in \mathbb R^2 : |x|+|y|\leq 1\}$ compact?
I know that is closed and bounded so compact but I don't know how to show it is closed and bounded mathematically.
This is the graph of $|x|+|y|\leq 1$","['general-topology', 'metric-spaces', 'compactness', 'analysis']"
654587,Is the product of $3$ positive semidefinite matrices positive semidefinite?,"Is the product of $3$ positive semidefinite (PSD) matrices positive semidefinite if the product is symmetric? If so, any proof or reference, please? Eugene P. Wigner, On weakly positive matrices , Canadian Journal of Mathematics, Volume 15, 1963. states that the product of three positive definite matrices is positive definite iff the product is symmetric, but it doesn't extend the statement to the case of PSD.","['symmetric-matrices', 'matrices', 'linear-algebra', 'reference-request', 'positive-semidefinite']"
654616,"convergence of $\int _1^{\infty} \sin\big(\mathrm{e}^x(x-2)\big)\,dx$","Question: $$\int _1^{\infty} \sin\big(\mathrm{e}^x(x-2)\big)\,dx$$ does this converge?
Wolfram|Alpha doesn't have an answer, and I would really know. We tried to use Dirichlet and substituting with $t=e^x$. But couldn't continue","['improper-integrals', 'calculus']"
654617,whats the difference between $|v|$ and $||v||$?,"$v$ being a vector.
I never understood what they mean and haven't found online resources. Just a quick question. Thought it was absolute and magnitude respectively when regarding vectors. need confirmation","['notation', 'multivariable-calculus', 'normed-spaces']"
654659,Real Analysis : uniform convergence of sequence,"I was working on a real-analysis problem, but I got stuck,
so could anybody please help me with this question? Give an example of a sequence of continuous functions $\{f_n\}_{n\in\mathbb{N}}$ on the interval $[0,1]$ such that $f_n(x)\xrightarrow[n\to\infty]{}0$ for all $x\in[0,1]$, but the supremum of $f_n(x)$ is $1$ for all $n\in\mathbb{N}$.","['convergence-divergence', 'real-analysis', 'uniform-convergence']"
654662,Why is it trivial that $\left(1+\frac{2\ln3}{3}\right)^{-3/2}\leq\frac{2}{3}$?,Can someone tell me why $$\left(1+\dfrac{2\ln3}{3}\right)^{-3/2}\leq\dfrac{2}{3}$$ is trivial because for me its not and I will need to do the calculation to see it.,"['inequality', 'logarithms', 'calculus']"
654676,Locally closed immersions are locally of finite type,"I am writing the proof that locally closed immersions are of finite type but I am stuck at minor detail. I would like that either (1) preimages of open affines by open immersions be quasicompact or (2) that given an affine $Spec\, A$ in the source of a closed immersion it would be possible to find an affine in the target whose preimage is exactly $Spec \, A$. Here is why: To show that the locally closed immersion $Z\overset{\rho}{\rightarrow} W\overset{\tau}{\rightarrow} X$ is of finite type, where $\rho$ is closed and $\tau$ is open, by definition, we must show that for any open affine $Spec\,C$ in the target and open affine $Spec\,A$ in the preimage the induced map of structure sheaves $(\tau\rho)^\#:C\rightarrow A$ makes $A$ into a finitely generated $C$-algebra. Now, what I need is to get my hands on an open affine $Spec\,B \subset \tau^{-1}(Spec\,C)$ such that $\rho^{-1} (Spec\, B) = Spec\, A$. If this were true, then it would follow trivially from $A\rightarrow B$ being a surjection that $A$ is a finitely generated $B$-algebra. Since $Spec\,B$ is quasicompact, we would be able to cover it by finitely many distinguished open sets $D(f_i)$ such that $\tau (\bigcup D(f_i)) = \bigcup D(\tau^\# (f_i)) = A_{\prod f_i}\Rightarrow B=A_{\prod f_i}$, so that $A$ is clearly a finitely generated $C$ algebra. But how do fill the gap in my argument?",['algebraic-geometry']
654684,Reference request for stochastic process and applications,"I am looking for a text book that will cover the following topics I hope someone could suggest me a good text book that will provide me a good guidance regarding the following; Generating functions, Convolution, Compounding, Random walks, Recurrent events, Discrete parameter Markov Chains, Continuous parameter Markov Chains, Birth and Death processes, Queuing processes. I have no idea of stochastic processes yet so any book with good explanations will be very useful. Thank you.","['statistics', 'stochastic-processes', 'reference-request', 'probability-theory']"
654688,Local integrability of two functions,Why $\log|x|$ is a locally integrable function and $1/|x|$ is not? Id know how their graphs look like but I don't know what is the exact difference causing local integrability of the first one.,['integration']
654746,"If $a_1,\ldots,a_n>0$ and $a_1+\cdots+a_n<\frac{1}{2}$, then $(1+a_1)\cdots(1+a_n)<2$.","Assume that $a_1,a_2,\ldots,a_n>0$ and $a_1+a_2+\cdots+a_n<\frac{1}{2}$, and prove that $$(1+a_1)(1+a_2)\cdots(1+a_n)<2$$ I've tried Hölder's inequality (the same result can easily be derived using AM-GM). I've found out that it's sufficient to prove that 
$$
\left(\frac{2n+1}{2n}\right)^n<2.
$$ (I've created this sign for myself to use informally while searching for a proof. Proving that one of the signs holds will prove my inequality). Does anyone see how one could prove this (if it holds, of course)? However, there must be a way to prove the inequality by using induction at first rather than the Holder's inequality or AM-GM. Thanks. And I'm sorry. But I'd forgotten to add that neither logs nor calculus can be used.","['inequality', 'calculus', 'exponential-function', 'analysis', 'induction']"
654765,Sum of polynomial,"If $p(x)$ is a polynomial of degree $m$, does the polynomial $q(x)$ of degree $m+1$ exist so that $\sum_{i=0}^{n}p(i)=q(n)$? And if so, is there an algorithm to find the expression for $q(x)$?",['sequences-and-series']
654811,Fractional Sobolev embedding into $L^\infty$,"Are there any $t\in(0,1)$, $p\in[1,\infty)$ such that $W^{t,p}(\mathbb{R})$ is continuously embedded into $L^\infty(\mathbb{R})$?  I have been looking several literatures, but I have not yet found this out. Also, I am not familiar with proofs for Sobolev spaces. Can anyone give a reference on whether it can or cannot be done? Thank you.","['sobolev-spaces', 'functional-analysis', 'lp-spaces']"
654817,Convexity of a complicated function,"Let $\mathbb{S}$ be a $2$ -D convex set in the positive quadrant. Let us define \begin{align}
y_L=\min_{(x,y)\in\mathbb{S} }y \\
y_R=\max_{(x,y)\in\mathbb{S} }y 
\end{align} For any positive number $p\in[p_L,p_R]$ where $p_L=\frac{1}{y_R}$ and $p_R=\frac{1}{y_L}$ , define the function \begin{align}
f(p)=\min_{(x,y)\in\mathbb{S} }px~,~\text{s.t.}~~py\geq 1
\end{align} where s.t. means ""subject to"" . What is the nature of $f(p)$ ? Is it convex or concave?","['convex-analysis', 'real-analysis']"
654820,"Find all bijections $\,\,f:[0,1]\rightarrow[0,1],\,$ which satisfy $\,\,f\big(2x-f(x)\big)=x$.","A friend of mine gave me the following problem: Find all functions $f:[0,1]\to[0,1]$, which are one-to-one and onto and satisfy the following functional relation:
$$
f\big(2x-f(x)\big)=x, \tag{1}
$$
for all $x\in [0,1]$. Clearly, the identity function $f(x)=x$ is one such function. Also, as $f$ is a bijection $f^{-1}$ exists, and by $(1)$ we have
$$
f^{-1}(x)=2x-f(x), \tag{2}
$$
but I have no idea that how should I continue. It will be great if someone can give me some hints. Thanks in advance.","['calculus', 'contest-math', 'recursion', 'functional-equations', 'recreational-mathematics']"
654824,"""Easy"" (maybe not) question about dual spaces (Lineal Algebra).","Hi everyone is my first time reading about dual spaces and in one part of the notes that I read, says: The dual of the quotient space $V/U$ is naturally a subspace of $V$, namely the annihilators of $U$ in $V$. I have doubt about this when says a naturally subspace does not actually mean which there is a natural identification of $(V/U)^*$ to the set of all the annihilators $U$ in $V$ under a map more than a subspace? Clearly exists an epimorphism $f:  V \twoheadrightarrow V/U $ and we can associate the map $f^t: (V/U)^* \rightarrow V^*$ by $h\mapsto h\circ f$, where $h\in (V/U)^*$, so $f^t[\,(V/U)^*]= \{\text{the annihilators of U in V} \}$, or there exist a natural identification of  $(V/U)^*$ to the set of all the annihilators $U$ in $V$ under $f^t$?  Am I completely off track or my intuition is correct? Claim:  Let $f, f^t$ as define above then  $f^t[\,(V/U)^*]= \{\text{the annihilators of U in V} \}$ Proof of claim: ($\Rightarrow$)  $T\in f^t[\,(V/U)^*]$, so $T=h\circ f$ for some $h\in (V/U)^*$, i.e., $h: V/U \rightarrow \mathbb{F}$. If $x\in U$, so $f(x)= x+U= U$ and then $h(f(x))= h(U)=0$. ($\Leftarrow$) Let $T\in \{\text{the annihilators of U in V} \}$, i.e., $T(x)=0$ whenever $x\in U$. Let define $\overline{T}:  V/U \rightarrow \mathbb{F}$ by the formula $\overline{T}(x+U)=T(x)$, we claim that $\overline{T}\circ f=T$, let $x\in V$ so $(\overline{T}\circ f) (x)=\overline{T}(f(x))=\overline{T}(x+U)=T(x)$. Then $\overline{T}\circ f= f^t(\overline{T})=T$, i.e., $T\in f^t[\,(V/U)^*]$. One more thing is very natural in the literature read that if $V$ is a vector space (a finite dimensional vector space) then is the dual of other space, that doesn't really mean that $V$ is isomorphic to the dual of other space instead of is the dual of some other space because not all the vector spaces are the set of linear functionals? Thanks in advance. Edit: If $U$ is a subspace of $V$ (and $V$ is finite dimensional vector space), clearly we have $V= U \oplus U'$  and $U'\cong V/U$ ($U'\hookrightarrow V \twoheadrightarrow V/U$) then we can conclude that  $(V/U)^* \cong (U')^*$ and is not difficult to show that $(U')^*$  contain all the annihilators of $U$ in $V$ is in that way in which  as says in the book ""the dual of the quotient space $V/U$ is naturally a subspace of $V$, namely the annihilators of $U$ in $V$"" because we can identified naturally with $(U')^*$? Edit: Other thing: In other part says 'If we choose a basis of $V$, and use it to identify elements of V with “column vectors” of length n, then elements of $V^*$ correspond to “row vectors” of the same length'. Why is this true? Clearly if we set $\mathcal{B}= \{v_1,..v_n\}$ be a basis for $V$, any element of $V$, says $v\in V$ can be expresses uniquely as $v=\sum_i a_i v_i$, so we can associate $v\mapsto [V]^\mathcal{B}$ which is the vector column. Now if $\mathcal{B^*}= \{v_1^*..v_n^*\}$ is the dual basis for $V^*$, so for any $f\in V^*$ we have $f= \sum_i f(v_i)v_i^*$  but I can't see in which sense we can associate it to a row vector $[f]_{B^*}$, naturally? Any comment it would be great. Thanks :)","['linear-algebra', 'self-learning', 'intuition', 'soft-question']"
654829,Local minimum global,"Let $f:(a,b)\to\Bbb R$ be continuous. Assume that $f$ has a local minimum at some point $x_0$. Further assume that this is the only point where $f$ has a local extremum. Does it follow that $f$ has a global minimum at $x_0$.
Thanks","['functions', 'optimization', 'real-analysis', 'analysis']"
654839,Proving that $\frac{e^x + e^{-x}}2 \le e^{x^2/2}$,"Prove the following inequality:
  $$\dfrac{e^x + e^{-x}}2 \le e^{\frac{x^2}{2}}$$ This should be solved using Taylor series. I tried expanding the left to the 5th degree and the right site to the 3rd degree, but it didn't help. Any tips?","['inequality', 'exponential-function', 'calculus', 'taylor-expansion']"
654840,Soft Question: Inequalities like this,"I am studying signed and complex measure and at a point in a proof the following lemma is being used: Lemma. If $z_1,...,z_n$ are complex numbers, then there exists a subset $S\subset\{1,2,...,n\}$ such that $$\left|\sum_{k\in S}z_k \right| \geq \frac{1}{\pi}\sum_{k=1}^n|z_k|.$$ Does this equality have some name, or do similar kind of inequalities exist? Can the constant appearing ($1/\pi$) be sharpened?","['soft-question', 'inequality', 'complex-analysis', 'analysis']"
654843,Problem involving an infinite lattice grid,"I'm stuck on this problem for Intro to Point-Set Topology.... I'm given that a submarine starts somewhere in $\mathbb{R}^2$ and moves in a straight line at constant velocity, in such a way that at every hour it is at a point whose coordinates are integers. At every hour, I am able to drop one bomb at one point in $\mathbb{R}^2$ whose coordinates are integers. My task is to show that I can drop bombs in such a way that I will eventually hit the submarine. My work so far:
I know that $\mathbb{Z} \times \mathbb{Z}$ is countable, and since the set of integer-lattice points intersected by the submarine is a subset of $\mathbb{Z}\times \mathbb{Z}$, this set is also countable. I also know I can parametrize the path of the submarine as follows, where $k_1, k_2, m_1, m_2 \in \mathbb{Z}$ and $m_1, m_2 \neq 0$.
\begin{align*}
x & = k_1 + m_1 t \\
y & = k_2 + m_2 t
\end{align*}
where $t$ is the time in hours. I also can come up with ways to count all of $\mathbb{Z}\times \mathbb{Z}$, and hence the path of the submarine. For example, I could start at $(0,0)$, then go to $(0,1)$, then $(-1,1)$, then $(-1,0)$, then $(-1, -1)$, then $(0,-1)$, and continue in a sort of square spiral. I know that this spiral will eventually hit every point on the path of the submarine as time goes to infinity. But...how do I guarantee that I actually hit the submarine itself???","['general-topology', 'elementary-set-theory']"
654859,If a function has no critical points then how can I find where the function is increasing or decreasing?,"Recently, I have discovered some problems that have no critical points i.e. $$f'(x) \not = 0$$ For example, if we have the exponential $e^x$ divided by some other function squared i.e. $(x+2)^2$. Then this function will never equal zero. So how can I find where the function is increasing/decreasing? Thanks!","['calculus', 'derivatives']"
654869,Derive Fourier transform from what it should do?,"I was wondering about the following: Imagine you want to figure out whether there is a transform that exchanges differentiation with multiplication and convoution with pairwise transformation for $L^2$ functions. Is there an analytical way to derive from this the Fourier transform? Why am I asking this? In many practical examples, you want to have a transform that has certain properties like: get rid of differentiation. But in mostly all books, the Fourier transform is just introduced and the properties are derived afterwards. Is it a posteriori possible to derive an integral transform just by looking for something with these properties?","['fourier-analysis', 'real-analysis', 'analysis', 'hilbert-spaces', 'functional-analysis']"
654872,Embeddings (how to prove them exactly),"For which of the following sets is the statement: '$A$ can be embedded in $B$' true? I can try to decide this intuitively but don't know if I'm right, and surely don't know how to formally prove it. (i) $A = S^1 \times \mathbb{R}$, $B = \mathbb{R^2}$ $S^1$ with a point removed is homeomorphic to $\mathbb{R}$, so for a $x \in S^1$ we have $(S^1 - \{x\}) \times \mathbb{R}$ is homeomorphic to $\mathbb{R^2}$. Therefore it seems $A$ is to 'large' to be embedded in $R^2$, so I think this is false . (ii) $A = S^1 \times S^1 \times S^1$, $B = \mathbb{R^4}$ Because $A$ is a compact topological manifold it can be embedded in $\mathbb{R}^N$ for some $N$. $A$ is the product of the torus and $S^1$, and because the torus can be embedded in $\mathbb{R}^3$ it feels like $A$ can be embedded in $\mathbb{R}^4$ so I think this is true . (iii) $A = S^2$, $B = S^1$ I can remove two antipodal points from $A$ and it stays connected, but when I do that in $B$ it loses the topological property of connectedness. This then also needs to hold for the image of $A$ in $B$ so I think this is false . (iv) $A = M$, $B = P^2$ (Where $M$ is the Möbius strip and $P^2$ is the real projective space of dimension $2$)
The projective space of dimension two holds half the 'data' of the 2-sphere. When I think of the Möbius strip in $\mathbb{R}^3$ it seems to hold more data than the 2-sphere so I think this is false. (v) $A = P^3$, $B = \mathbb{R}^6$ The space of all lines through the origin in $\mathbb{R}^4$ can be embedded in $\mathbb{R}^4$ itself, so then it must also be possible to embed it in $\mathbb{R}^6$ so I think this is true . I'm sorry for the lack of rigor and hope someone can give some general advice to prove this formally.","['general-topology', 'manifolds']"
654888,Maximum Likelihood Function for uniformly distributed points,"I am currently trying to solve Exercise 22.10 from David MacKay's Book ""Information theory, inference, and learning algorithms"" I have absolutely no idea on how to approach this task, and would highly appreciate if someone could point me to the right direction.","['statistics', 'probability']"
654889,painted cube brain teaser. Alternative solutions,"You’ve got a 10 x 10 x 10 cube made up of 1 x 1 x 1 smaller cubes. The outside of the larger cube is completely painted red. On how many of the smaller cubes is there any red paint? The easiest way for me to answer this is this way:
There are 8*8*8 cubes not painted = 512 cubes not painted. So 1-512 = 488 cubes painted. Done. 2nd way:
there are 2 10*10 faces that are painted + 2 10*8 faces that are painted + 2 8*8 faces that are painted =
2(100) + 2(80) + 2(64) = 200 + 160 + 128 = 360 + 128 = 488 3rd way that I'm having trouble with:
I'm trying to add up the outside surfaces together and then subtract the ones that I've double counted. How do I do this?
10*10*6 = 600
600 - double counted ones.
600 - (top part of the cube that was double counted + cubes along the height + cubes on the bottom) 600 - (36 + 32 + 36) = 104
600 - 104 = 496. Aragh. What am I doing wrong in the third method?",['geometry']
654890,Example Of a Proper noncyclic Subgroup of rationals,"We know the set of rational numbers forms a group under addition. My question is :does there exist a proper subgroup of rationals which is not cyclic? If yes, how can we construct it?","['examples-counterexamples', 'group-theory', 'abstract-algebra', 'rational-numbers']"
654895,Is the Hausdorff condition redundant here?,"This is a question in Algebraic Topology by Hatcher, Chapter 0: 21) If $X$ is a connected Hausdorff space that is a union of a finite number of 2 spheres,
  any two of which intersect in at most one point, show that $X$ is homotopy equivalent
  to a wedge sum of $S^1$’s and $S^2$’s. Is it necessary that Hatcher requires $X$ to be Hausdorff here?  Is it possible to have a space $X$ as a finite disjoint union of spaces homeomorphic to $S^2$ where we identify at most one point of each pair and $X$ not be Hausdorff.  It seems pretty obvious to me that this is not possible but maybe I'm overlooking something.","['general-topology', 'algebraic-topology']"
654907,Compact kernel operator on $L^p$ space,"Let $\displaystyle U_1 \subset \mathbb R^{n_1}$ and $\displaystyle U_2
 \subset \mathbb R^{n_2} $ measurable sets, $\displaystyle 1 < p,q <
 \infty $ and consider the measurable function $\displaystyle K:U_1
 \times U_2 \to \mathbb R $ with $$\displaystyle \|K\|= \left(
 \int_{U_1} \Big( \int_{U_2} |\,K(x,y) |^{p^{'}} dy  \Big)^{q/p^{'}}
dx \right)^{1/q} < \infty ,$$  where $\displaystyle \frac{1}{p} +
 \frac{1}{p^{'}} =1$. Prove that the operator $T:\displaystyle L^p (U_2) \to L^q (U_1) $, with
  $\displaystyle (Tf)(x)= \int_{U_2} K(x,y) f(y) dy $,  is compact. I tried to prove it by the definition of the compact operator but I didn't made it. Is there some other way to do it?","['functional-analysis', 'compact-operators', 'operator-theory', 'real-analysis', 'lp-spaces']"
654911,Calculating eigenvectors and eigenvalues of a 2x2 complex matrix,"I've previously asked elsewhere, https://stackoverflow.com/questions/21118820/non-trivial-eigenvectors-of-a-22-matrix-in-code , how to calculate the eigenvectors and eigenvalues of a 2x2 matrix in a programming language. I am still working with a 2x2 matrix ($A$) but it's now complex, and takes the form:
$$
        A = \begin{bmatrix}
        a+jb & c + jd \\
        e + jf & g +jh \\
        \end{bmatrix}
$$
where $j$ is the square root of $-1$. Do the equations in http://www.math.harvard.edu/archive/21b_fall_04/exhibits/2dmatrices/index.html (which is used as a part of the solution in the previous link) still hold?","['matrix-equations', 'matrices', 'computational-mathematics', 'eigenvalues-eigenvectors']"
654918,"3 trams are coming every 10, 15 and 15 minutes. On average, how long do I have to wait for any tram to come?","3 trams are coming to the stop every 10, 15 and 15 minutes. On average, how long do I have to wait for any tram to come? It's a practical problem, not some kind of a riddle for which I have a surprising magic trick or an answer. I really don't know. I was waiting for a tram when this question come to my mind. So, if you ask me for example ""how the trams are driving?"" my answer will be I don't know, I have the same (or lesser) tram knowledge as you. Assume some accurate (probably probabilistic;) model and present the answer, for example ""5 minutes"" + showing how you obtain this result. Perfect answer will generalize the problem, answering how long do we have to wait when the trams come every $x_1, x_2, x_3...$ minutes. But even the basic problem is not as easy as it is looking, so feel warned.","['average', 'puzzle', 'probability']"
654923,How do I start from a 10% discount and find the original price?,"I have a database of prices that already have a 10% discount. For example a product could be $100 after a 10% discount.  Is there a reusable formula I can use to determine what the original price was of all the 10% discounted prices in the database? Edit: Thank you for the fast responses.  Is there any way to account for rounding errors?  A real example is a product with a discounted price of \$129.00  Using the X/.9 formula, I get \$143.33 as the original price, which does not actually work out.  To have had \$129.00 as the discount price, the original price would have needed to have been \$143.34.",['algebra-precalculus']
654953,Why does f' = 0 gives the min or max?,"I understand how to calculate it, but I am just curious, why actually it works? Do we have a proof that it always works?",['derivatives']
654965,Why is the image of a compact operator separable?,"Let $A$ and $B$ be normed vector spaces and let $S\in \mathscr{K}(A,B)$ be a compact operator. Question: How does it follow that the image of $S$ is separable? Thanks for the help.","['operator-theory', 'normed-spaces', 'compactness', 'functional-analysis']"
654973,Fibrations in algebraic geometry,"Suppose that $f:X\rightarrow Y$ is a morphism of finite type schemes over an algebraically closed field $k$. Assume that for every closed point $y\in Y$ the fiber $X_y$ of $f$ in is isomorphic to $\mathbb{P}^n_k$. Now let $y_0\in Y$ be any(nonclosed) point. Is it true that:
$X_{y_0}\cong \mathbb{P}^n_{k(y_0)}$? Suppose now that $\Gamma$ is a scheme over $\mathrm{Spec} (\mathbb{Z})$. For any field $L$ let $\Gamma_L$ be its base change to $L$. How about the previous question with $\mathbb{P}^n$ replaced by $\Gamma$?",['algebraic-geometry']
654979,Eigenvectors Trajectories,"I got stuck with a problem while studying for a control systems exam. It goes as following: ""Look at the picture of trajectories of a linear, time-invariant system with the form: $\frac{d\mathbf{x}}{dt}=\mathbf{A}x$ . The Eigenvalues of the matrix $A$ are $s_1=-1$ and $s_2=-2$ . Find the Eigenvectors $p_1$ and $p_2$ considering the given Eigenvalues."" How can I calculate the Eigenvectors with just knowing the Eigenvalues and the trajectories? Thanks in advance","['control-theory', 'systems-of-equations', 'linear-algebra', 'ordinary-differential-equations']"
654996,"Prove $\int_0^x \frac{f(u)(x-u)^n}{n!}du=\int_0^x ( \int_0^{u_n}( \dotsb ( \int_0^{u_1}f(t)\,dt ) du_1 ) \dotsb )du_n$ via IBP","Problem 18-22 on p. 327 of Michael Spivak's Calculus (first edition) is Use induction and integration by parts to show that $$\int_0^x
 \frac{f(u)(x-u)^n}{n!}du=\int_0^x \left( \int_0^{u_n}\left( \dotsb
 \left(  \int_0^{u_1}f(t)\,dt \right) du_1 \right) \dotsb \right)du_n$$ Previous exercises (14-5 and 14-6) have asked us to prove essentially the same thing by induction and by noting that both sides have the same derivative with respect to $x$ and the same value at zero. So I can see how to do the problem that way. When I try to solve by integration by parts, I'm getting something funny. The $n=1$ case works out OK. When I try to do $n=2$, for instance, let me show you what I'm getting. I want to show $$\int_0^x \frac{f(u)(x-u)^2}{2!}du = \int_0^x \int_0^{u_2}\int_0^{u_1}f(t)\,dt\,du_1\,du_2.$$
If I substitute into the right hand side, using the $n=1$ case, I get that it suffices to show $$\int_0^x \frac{f(u)(x-u)^2}{2!}du =\int_0^x \left(  \int_0^{u_2}f(u_1)(u_2-u_1)\,du_1 \right)du_2.$$ And if I integrate the LHS by parts, I get that it suffices to show $$\int_0^x \int_0^u f(t)(x-u)\,dt\,du =\int_0^x \left(  \int_0^{u_2}f(u_1)(u_2-u_1)\,du_1 \right)du_2.$$ But note these expressions are not the same. I could always expand, etc. and show that it comes out right, but I'm trying to find the way  by simple integration by parts (that is what the author wants me to see). I know I'm just missing something simple!","['calculus', 'integration']"
655030,Inverse of a symmetric tridiagonal matrix.,"Hello, everyone! I am trying to find the inverse of an $N\times N$ matrix with ones on the diagonal and $-\frac{1}{2}$ in all entries of the subdiagonal and superdiagonal.  For example, with $N=3$, $$A = \left(\begin{array}{ccc}1 & -1/2 & 0 \\ -1/2 & 1 & -1/2 \\ 0 & -1/2 & 1 \end{array}\right);\,\,A^{-1} = \left(\begin{array}{ccc}3/2 & 1 & 1/2 \\ 1 & 2 & 1 \\ 1/2 & 1 & 3/2 \end{array}\right).$$
In fact, I really only need to determine the value of the first entry.  I believe that it should be $\frac{2N}{N+1}$, but that is only by a heuristic method, when I'm really hoping for a proof by induction. Thanks in advance for any assistance. -Jason","['matrices', 'linear-algebra']"
655055,Flowing a vector along a vector field $X$ using the pushforward of the flow of $X$,"On the three-sphere $S^3$, I'm given three vector fields $X$, $Y$ and $Z$, such that at each point $p\in S^3$, the tangent vectors $X_p$, $Y_p$ and $Z_p$ form an orthogonal basis of the tangent space $T_pS^3$. I denote by $X^t:S^3\rightarrow S^3$ the flow of the vector field $X$, so $X^0(p)=p$ and $\frac{d}{dt}X^t(p)=X_{X^t(p)}$. Its pushforward at the point $p$ is denoted $(X^t)_{*,p}$, so this is a map from $T_pS^3$ to $T_{X^t(p)}S^3$. Now let $v$ be an arbitrary tangent vector in $T_pS^3$. We can write $v=v_xX_p+v_yY_p+v_zZ_p$. I want to prove the following: $(X^t)_{*,p}(v)=v_x X_{X^t(p)}+...$. Here the dots denote other terms in the span of $Y_{X^t(p)}$ and $Z_{X^t(p)}$, but it's only the $X_{X^t(p)}$ component I care about (plus I don't know the other components). Is this maybe immediate from the definition of the flow? I tried using the defining equation $\frac{d}{dt}X^t(p)=X_{X^t(p)}$ of the flow of $X$, but I don't know how I can relate the time derivative with the pushforward... Edit: so I think I can visualize my question as follows. Starting with a tangent vector $v$ at $p$, flowing this vector along $X$ (using the pushforward of the flow) does not change the component of $v$ along $X$. Sounds plausible...","['manifolds', 'vector-fields', 'differential-geometry']"
655058,Calculate an integral using complex integration,"came across this one
$$\int_0^{\pi / 2} \ln (\sin x)\;dx$$ I wanted to find it using the residues, but, I don't thing they are isolated ones","['calculus', 'integration', 'complex-analysis']"
655077,An isosceles trapezoid $ABCD$ function of $AB$,"Ok so i have an isosceles trapezoid $ABCD(AD=BC)$ with bigger base $AB$ and let $O$ be the point of the crossed diagonals and let $OH$ be perpendicular to $AB$.
I want to find a function for $AB$ with variables $AD$, $BC$, $DC$, and $OH$. $f(AD,BC,DC,OH) = AB$ $f = ???$","['geometry', 'functions']"
655086,any help with how to do equations like this or what I can read is greatly appreciated,"$$A_f=\frac{A_o}{1+\beta A_o}$$        rearranging for $\beta $ I get $A_f(1+\beta A_o)=A_o$ $A_f+A_f\beta A_o=A_o$ $A_f\beta A_o=A_o-A_f$ $$\beta = \frac{A_o-A_f}{A_oA_f}$$ The book shows, I don't see how they get this? $$\beta=\frac{(A_o/A_f)-1}{A_o}$$",['algebra-precalculus']
655095,Discrete math library homework,"I am working on a homework question and I am not sure if I am going about the correct way of getting to the correct answer. I feel as this is a trick question. Here is the question: In order to keep track of circulation numbers, the library asks you to note on a form, when you leave the library, which combinations of $15$ subject areas and of $8$ types of material (books, current journals, databases, bound journals, videotapes, microﬁlm, microﬁche, DVDs) you used. How many possible ways are there to ﬁll in a line on the form? I was thinking of multiplying $15 \cdot 8 = 120$. But for some reason that did not seem correct. I was also thinking of doing $15^8$. But that number seemed too large.",['discrete-mathematics']
655102,"$A+A^T=I$, $\lambda$ is an eigenvalue of $A$, show that $\lambda=\frac{1}{2}+\alpha i$","I tried to solve it but I got $\lambda =\frac{1}{2}$ without the complex part, I'd like to know where my logic is flawed. Assume $v$ is the eigenvector associated with lambda, then: $(A+A^T)v=Iv$ which quickly implies that $2\lambda v=v$ and so $(2\lambda -1)v=0$. since $v$ isn't the zero vector (zero can't be an eigenvector by definiotion), we get $2\lambda =1 $ and so $\lambda=\frac{1}{2}$. I don't see where the imaginary part comes in.","['matrices', 'complex-numbers', 'linear-algebra', 'eigenvalues-eigenvectors']"
655104,Parabola $\sqrt {x}+\sqrt {y}=1 $,"How do I prove that the equation $\sqrt {x}+\sqrt {y}=1 $ is part of parabola. 
My attempt:rotation in 45 degrees brings the equation to $ -2a^2=1-2\sqrt {2}b $ when $ x= \frac {a-b} {\sqrt {2} } $ and $ y= \frac {a+b} {\sqrt {2} } $. It is a parabola, why is it only part of it? (also for $\sqrt {x}-\sqrt {y}=1 $)",['algebra-precalculus']
655142,The difference of two consecutive perfect squares is always odd,I am working on another homework assignment about proofs. The question is: Prove or find counterexample: the difference of two consecutive perfect squares is odd? There is no counterexample correct? I am thinking this is always true. If I were to do 7^2-6^2 the answer is odd. I am unsure of how to start the proof though. I am new to proofs and not sure what to really do,"['elementary-number-theory', 'divisibility', 'discrete-mathematics']"
655143,"How many permutations of {1,2,..., 9} are there that do not start or end with an even number?","How many permutations of $$1,2,..., 9$$ are there that do not start or end with an even number? This is my attempt Condition 1 [Starts with even] => $$4 * 8!$$
Condition 2 [Ends with even] => $$4 * 8! $$
Condition 3 [Starts with even and Ends with even] => $$4*3*7!$$ Therefore, $$9! - (Condition1 +Condition2 -Condition 3)$$ Is this the right answer?","['permutations', 'inclusion-exclusion', 'discrete-mathematics', 'combinatorics']"
655182,"If $A^T=-A$, then A is not invertible","Let $n \in \mathbb{N}$ be odd and $A \in$Mat$(n,\mathbb{R})$ with $A^T=-A$. Show that $A$ is not invertible. I have no idea how to start this...","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors', 'determinant']"
655186,"In a non-commutative monoid, is the left inverse of an element also the right inverse?","Assume there is an element $a\in M$ , where $M$ is a non-commutative monoid. If there exists $a b\in M$ such that $a * b = n$ , where $n$ is the neutral, does it follow that $b * a = n$ ? I want to say no, because the axioms which define a group shouldn't be redundant ( $a * b = b * a = n$ is the 4th axiom). But the following logic seems to prove that the inverse is automatically commutative: $b * n = b$ $b * (a * b) = b$ $(b*a) * b = b$ Thus for the last line to be true, $b*a$ has to evaluate to $n$ .","['abstract-algebra', 'monoid']"
655191,"Two non-homeomorphic connected, hausdorff, locally compact spaces whose one-point compactifications are homeomorphic","I'm looking for two non-homeomorphic connected, Hausdorff, locally compact spaces whose one-point compactifications are homeomorphic. Without the connectedness property this is easy, for example: $[0,1) \cup (1,2]$ and $[0,2)$. I was thinking that I could maybe find two connected spaces which are locally compact but not compact where on loses the connectedness property when removing a point, and the other doesn't, but I can't seem to find such a space. Can anyone give an example of two such spaces?","['general-topology', 'examples-counterexamples']"
655204,Ratios of binomial coefficients,"Trillian has $n$ mice, of which $w$ are white. She chooses four at random. The probability that two are white is equal to the probability none are white. This gives an equation in binomial coefficients $$ {w \choose 2} { n-w \choose 2 } = {n-w \choose 4} $$ I know of one solution: $n=8, w=2$. Is it unique?",['combinatorics']
655208,Show that $F_1 + F_2 +\dots+ F_n = F_{n+2} -1$,Let $(F_n)_{n\in\mathbb{N}}$ be the Fibonacci sequence. Show that $$F_1 + F_2 +\dots+ F_n = F_{n+2} -1 $$ for every positive integer $n$ by induction. This is what I have done so far $$S(k)$$ $$F_k = F_{k+2} -1 $$ $$S(k+1)$$ $$F_{k+1} =F_{((k+1)+2)} -1$$ $$F_{k+1} + F_{k+2}-1$$ I get confused with the $-1 $ .,"['fibonacci-numbers', 'induction', 'discrete-mathematics']"
655216,Ring of entire functions is integrally closed or not?,"Is the ring $\mathscr{O}(\mathbf{C})$ of entire functions integrally closed (in its field of fractions, the meromorphic functions)? I know it's not factorial, but this doesn't exclude the possibility of it being integrally closed.","['commutative-algebra', 'ring-theory', 'abstract-algebra']"
655222,The ring of integers of $\mathbf{Q}[i]$,"Is there a relatively ""simple"" (in the sense that it does not require knowledge of algebraic number theory) proof that the ring of integers of the algebraic number field $\mathbf{Q}[i]$ is $\mathbf{Z}[i]$? One can assume a one year course in algebra, covering the usual topics on ring and field theory, e.g. Gauss's lemma etc","['ring-theory', 'algebraic-number-theory', 'abstract-algebra', 'field-theory']"
655236,"Why are particular combinations of algebraic properties ""richer"" than others?","Pedagogically, when students are exposed to algebraic structures it seems standard for the major emphasis, if not all the emphasis, to be on groups, rings, R-modules, and categories. These are rich structures with interesting properties, but in the big picture, I have wondered why some defining properties make for a rich structure, while other properties gives less interesting structures , or nothing worth teaching at all. As a motivating example, a set (or class, whatever) that is closed under some operation seems necessary to talk about anything meaningful; however, why is the particular combination of Having inverse elements Having an identity element Associativity more rich (a group) than simply replacing associativity with commutativity (a structure I don't even know a name for)? I have also wondered why associativity is much more prevalent than commutativity. As another motivating example, we teach much about groups and rings but why not loops, monoids, semilattices, and near-rings? What makes the former set either richer in structure or more pedagogically sound to teach? Even in category theory I can ask what makes the specific combination of defining properties of a category so great. —why associativity and not commutativity? —why categories and not semi categories? I wonder why its particular combination of defining properties is more ""powerful"", deep, and pervasive than another combination of properties.","['soft-question', 'category-theory', 'abstract-algebra', 'universal-algebra']"
655240,Convergence of series involving in iterated logarithms $\sum \frac{1}{n(\log n)^{\alpha_1}\cdots (\log^k(n))^{\alpha_k} }$,"What is the quickest way to show when $$ S(\alpha_1,\alpha_2,\cdots,\alpha_k) = \sum\limits_{n=3}^\infty
 \frac{1}{n (\log n)^{\alpha_1}\cdots (\log^k(n))^{\alpha_k}} $$ converges, where $\log^k(n)$ is the $k$-th iteration of natural logarithm?",['sequences-and-series']
655253,Hermitian positive semi-definite matrix is a Gram matrix,"I showed that every Gram matrix, i.e. a $n \times n$ matrix $A$ with $A_{ij} = \langle x_i,x_j\rangle$ where $x_1,...,x_n$ are vectors in an inner product vector space $V$ , is Hermitian and positive semi-definite. But how to show the converse: For every Hermitian positive semi-definite matrix there is a inner product space $V$ and vectors $x_1,...,x_n$ such that $\langle  x_i,x_j\rangle = A_{ij}$ ? Any help is appreciated.","['matrices', 'inner-products']"
655259,Closed range assumption in definition of Fredholm operators,"There are two definitions of Fredholm operators (on a Hilbert space) that are commonly used. The first is that $\dim\ker T<\infty$ and $\dim\,\mathrm{coker} T<\infty$. An argument using the open mapping theorem then shows that the range of $T$ is closed. The other definition is that $\dim\ker T<\infty$, $\dim\ker T^{*}<\infty$ and the range of $T$ is closed. I am trying to find an example where $T\in B(H)$ satisfies $\dim\ker T<\infty$ and $\dim\ker T^{*}<\infty$ but does not have closed range. I considered the following: $H=\ell^{2}(\mathbb{N})$ and $T$ is defined on basis elements $e_{n}$ by $Te_{n}=\frac{1}{n}e_{n}$. It seems to me that $T$ is injective, self-adjoint, and its range is not closed because the sequence $T(1,0,0,0,\ldots), T(1,1,0,0,\ldots), T(1,1,1,0,\ldots)$ converges in $H$ to $(1,\frac{1}{2},\frac{1}{3},\ldots)$, which is not in the range of $T$. I hope someone can check the example, or perhaps give a simpler example (or a correct one in the event that mine is wrong).","['operator-theory', 'functional-analysis']"
655276,Definition of Door Space,"Every reference I can find regarding (topological) door spaces gives the following definition almost verbatim: A door space is one in which every subset is either open or closed. [emphasis mine] I can think of two interpretations of this definition. Which is the correct one? A door space is one in which every subset is open, closed, or both. A door space is one in which every nonempty proper subset is either open or closed, but not both. The former seems plausible because no reference mentions the obvious caveat that the empty set and the entire set are clopen in every topology. The latter seems plausible based on the fact that every definition uses the word ""either"" (which, to me, connotes exclusive or) and that physical doors cannot be clopen.","['general-topology', 'definition']"
655280,How to solve $\mathrm{diag}(x) \; A \; x = \mathbf{1}$ for $x\in\mathbb{R}^n$ with $A\in\mathbb{R}^{n \times n}$?,"I would like to solve the following equation for $x\in\mathbb{R}^{n}$
$$\mathrm{diag}(x) \; A \; x = \mathbf{1}, \quad \text{with $A\in\mathbb{R}^{n\times n}$},$$
where $\mathrm{diag}(x)$ is a diagonal matrix whose diagonal elements are the elements of $x$ and $\mathbf{1}$ is a vector whose elements are equal to 1. I will already be very happy to find a solution if $A$ is a positive definite and symmetric. Ideally I would like to find a closed-form solution for this quadratic equation. Any ideas (or solution ;-) would be greatly appreciated. Other formulation Another way to formulate this equation is as follows
$$A \; x = 1./x, \quad \text{with $A\in\mathbb{R}^{n\times n}$},$$
where $1./x$ denotes the ""element-wise inverse of the vector $x$"". Solution for the 1-dimensional case The solution for the 1-dimensional case is straightforward
$$ x = \frac{1}{\sqrt{A}} .$$","['algebra-precalculus', 'vector-analysis']"
655299,Trigonometric inequality,"Solve inequality per x:
$$\sin(x)+\cos(x)+\sin(2x)>1$$ I need some start, I tried to factor but i can't get something easier to solve, for example:
$$\sin(x)+\cos(x)>1-\sin(2x)$$
$$\sin(x)+\cos(x)>\sin^2(x)+\cos^2(x)-2\sin(x)\cos(x)$$
$$\sin(x)+\cos(x)>(\sin(x)+\cos(x))^2$$
What now?","['trigonometry', 'inequality']"
655302,Gamma Distribution out of sum of exponential random variables,"I have a sequence $T_1,T_2,\ldots$ of independent exponential random variables with paramter $\lambda$. I take the sum $S=\sum_{i=1}^n T_i$ and now I would like to calculate the probability density function. Well, I know that $P(T_i>t)=e^{-\lambda t}$ and therefore $f_{T_i}(t)=\lambda e^{-\lambda t}$ so I need to find $P(T_1+\cdots+T_n>t)$ and take the derivative. But I cannot expand the probability term, you have any ideas?","['density-function', 'gamma-distribution', 'exponential-distribution', 'probability-distributions', 'probability']"
655352,What is probability? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 10 years ago . Improve this question I tried to understand the most fundamental foundation of the mathematical definition of probability in the most natural/human way. (At first, I thought I may have found a proper understanding like this:) First, we need to abstract the events as set . And we assign some real number to the set by measuring these sets. We assign number because it is human nature to quantify things. Let's denote the measure as m . Then it is 
  also instinct/natural for human to
  use the ratio of m(part for E) / m(total) to measure the probability of event E. In short, probability is nothing but the ratio of the measurement between part and total. With this sense, probability is only meaningful in a relative context . We can use arbitrary m as it fits. And the P(S) is always 1 since m(S)/m(S) is always 1. And also, it's easy to understand why we use division to define the conditional probability as below. P(A|B)=P(AB)/P(B), because it is actually this: $$
P(A\mid B) = \frac{m(AB)}{m(B)} = \frac{m(AB)/m(S)}{m(B)/m(S)} = \frac{P(AB)}{P(B)}
$$ I really want to know if there's any flaw of this understanding. (But after having discussions here, I came to the following ADDs which is specific to the Mathematical Theory of Probability .) ADD 1 Is there any authoritative definition of what probability is ? I found almost all books define the probability based on the 3 famous axioms . But those axioms don't define what probability is. They merely say how probability should behave. ADD 2 On a second thought, I think I need to add some clarification. We must differentiate between mathematical probability and the interpretation of natural probability .  What I mentioned above is my attempt to explain the rational behind the mathematical probability . The natural probability is just a vague concept without precise quantification. In order to make it mathematically operational , we have to do some construction . And the above is what we have done. ADD 3 As I read the book "" Probability and Statistics "". It says: ...Almost all work in the mathematical theory of probability...has
  been related to the following two problems: (i) methods for
  determining the probabilities of certain events from the specified probabilities of each possible outcome of an experiment and (ii) methods for revising the probabilities of events when
  additional relevant information is obtained. So, it occurs to me that ""mathematical theory of probability"" cannot provide us with the initial probabilities of all outcomes, these initial probabilities have to be specified in some other ways which may come from different interpretations of probability or practical choice or even subjective initiatives . They are represented as various p.d.f/p.f, some of which are quite obscure. What ""mathematical theory of probability"" can provide is just methods to calculate the probability of events of interest based on the foundation of those initial probabilities. So it is once again proved the ideology of mathematics that it doesn't care about what a mathematical object is . But cares about how to manipulate it. But, despite that the concept of probability is highly controversial and there're so many in-compatible operational interpretations for it, it is very interesting why all authorities agree on a single mathematical theory of probability as the method of mathematical manipulation . Are they out of options? Here 's another question about the justification of mathematical theory of probability.","['probability-theory', 'probability']"
655364,Fundamental solution to Laplace equation on arbitrary Riemann surfaces,"So, I've seen in a few places this method of calculating the heat kernel on a manifold given the kernel of its universal cover, through a so-called 'tiling method' as in section five of this paper ( http://arxiv.org/pdf/1007.5467.pdf ). Basically, you end up getting: $$
\begin{equation}
   K_M(\textbf{x}, \textbf{y}, t) = \sum\limits_{g \in G} K_\tilde{M}( \tilde{\textbf{x}}, g \cdot \tilde{\textbf{y}}, t) 
\end{equation}
$$ where $\tilde{M}$ is the universal cover of $M$ and $G$ is the covering group. I'm wondering if you can do a similar thing with a fundamental solution of the Laplace equation, which I'd really like to calculate for arbitrary Riemann surfaces (actually, compact hyperbolic surfaces).","['differential-geometry', 'hyperbolic-geometry', 'covering-spaces', 'manifolds', 'riemann-surfaces']"
655367,Equivalence and Order Relations,"I have the following problem: Provide an example of a set $S$ and a relation $\sim$ on $S$ such that $\sim$ is both an equivalence relation and an order relation.  Conjecture for which sets and this is possible, and prove your conjecture. Below is the example I came up with but I don't know how to prove my conjecture and I don't even know if I am correct, I would really appreciate some help! The only set that satisfies the reflexive property of an equivalence relation and the nonreflexive property of an order relation is the $\emptyset$.  For any relation on that set, it is vacuously true that is is both an equivalence relation and an order relation.","['equivalence-relations', 'elementary-set-theory']"
655369,Coordinate of intersection between line and square,"TL;DR given a square and a point $p$, I need the intersection between the perimeter of the square and a ray cast from the center of the square through point $p$. This is my approach so far, but I will also accept correct answers that use a totally different approach. I’m writing an iPad app where there is a square on the screen. The user drags their finger around the screen. Imagine an ray starting at the center of the square and passing through the point where their finger is touching. I need to do stuff on the screen at the intersection between that line and the center of the square. The way I am doing this currently is by using the parametric equation of a square that I found at this answer : $$\begin{align*}x&=p\left(|\cos\,t|\cos\,t+|\sin\,t|\sin\,t\right)\\y&=q\left(|\cos\,t|\cos\,t-|\sin\,t|\sin\,t\right)\end{align*}$$ And for $t$, I am using the angle of the ray formed by the person’s finger. I am placing a small dot at the point given by that equation, just so I can see what I’m working with. I have to multiply that angle by $-1$ and add $\pi\over4$ so that the angles match up. My problem is that the equation of a square does not vary at the same rate as the angle. For any given value of $t$, a ray cast from the center of the square to the user’s finger does not pass through the square at the point given by the above equation, except at the centers of the sides and at the exact corners. The effect is that the dot I am putting on the screen lags or ahead of the user’s finger. Is there any way to get the point returned by the above equation to be collinear with the line from the center to the user’s finger? Here’s an illustration I put together in the OS X Grapher application so you can see what I mean. If you have a Mac, you can also download the file and play with it yourself.","['geometry', 'trigonometry', 'parametric']"
655387,Proof of integral,"Is there an analytical method to show that
$$
\int_{-a}^a\exp\left(\frac{-1}{1-(x/a)^2}\right)\,\mathrm{d}x=ka,
$$
for $a>0$.
I have confirmed this result numerically for a range of values of $a$. This numerical investigation gave $k\approx0.439938161681\pm5\times10^{-13}$. This integral arose while attempting to approximate a function. I originally planned to just evaluate this integral numerically until I came across the above relationship. Applying Leibniz rule for differentiation w.r.t. $a$ under the integral didn't lead to any obvious simplifications. Is there a technique that can be used to confirm this relationship? Or is it just a coincidence?","['integration', 'proof-verification', 'numerical-methods']"
655446,Definition of discrete and continuous spectrum,"I am reading about automorphic forms for $GL(2)$ and I am having trouble understand the definition of ""spectrum."" For instance, in Goldfeld and Hundley's book on automorphic representations they write, ""The continuous spectrum of $\Delta_k$ (the Laplace operator) is spanned by the Eisenstein series $E_\frak{a}$. However, in the references I have consulted (e.g. these notes by Garrett: http://www.math.umn.edu/~garrett/m/fun/notes_2012-13/06_ops_hsp.pdf ), the spectrum of an operator is defined to be a certain set of the complex numbers. In Bump's book on automorphic forms, he says that the Laplacian on $L^2(\mathbb{R})$ has a continuous spectrum, but doesn't define the term ""continuous spectrum."" It seems from context that an operator has a discrete spectrum if its eigenvalues form a discrete subset of the complex numbers, while it has a continuous spectrum if its eigenfunctions can be parametrized by a continuous subset of $\mathbb{R}$, but I am almost certain that this is wrong. So, my question is ""What is the definition of spectrum, discrete spectrum, and continuous spectrum"" in this context?","['automorphic-forms', 'functional-analysis']"
655460,Totally Ordered Set successor and predecessor unique,"I'm trying to prove that, in a totally ordered set, an element can have at most one successor and at most one predecessor. I know that if $x < y$ and there is no $z\in X$ with $x < z < y$ then $x$ is a predecessor of $y$ and $y$ is a successor of $x$. I know that the successor and predecessor are unique but don't know how to establish it in a proof. Any advice would be greatly appreciated.","['proof-writing', 'elementary-set-theory']"
655462,Prove this matrix is invertible for $n < m-1$,"Prove this $(n+1)\times (n+1)$ matrix $\bf{A}$ is invertible for $n < m-1$ and the $x_k$ distinct, \begin{bmatrix}
m &\sum_{k=1}^mx_k  &\sum_{k=1}^mx_k^2  &\cdots &\sum_{k=1}^mx_k^n \\\\ 
\sum_{k=1}^mx_k &\sum_{k=1}^mx_k^2  & \cdots &\cdots&\sum_{k=1}^mx_k^{n+1} \\\\ 
\vdots &\vdots  &\ddots  &&\vdots \\ 
 &  &  & &&\\\\
\sum_{k=1}^mx_k^n&\sum_{k=1}^mx_k^{n+1}&\cdots&\cdots&\sum_{k=1}^mx_k^{2n}
\end{bmatrix} I'm sure many of you recognize this as the normal matrix for polynomial least squares. The hint in the book is as follows: Suppose $\bf{A}$ is singular and that $\bf{c}\neq\bf{0}$ is such that
  $\bf{c}$$^\text{T}$$\bf{Ac}$$\;=0$.  Show that the $n$th-degree
  polynomial whose coefficients are the coordinates of $\bf{c}$ has more
  than $n$ roots, and use this to establish a contradiction. I worked on this for quite a while to no avail.  First off I can't figure out why the matrix is multiplied on the left by the transpose of $\bf{c}$, I'm assuming $\bf{c}$ is chosen because it's a non-trivial element in the kernel, but that doesn't require its transpose on the left. Second, things get pretty complicated once you start messing with the series, so I was hoping for something that avoided messy computations.  It's the product of the Vandermonde matrix and its transpose, but they're not square so that seemed useless. The closest I could get to even relating this to the polynomial $c_0+c_1t+...+c_nt^n$ was to consider the rows of the vector $\bf{A\cdot c}$.  By that I mean consider the first row (set equal to zero), then dividing by $m$ we get:
$$c_0 + c_1\frac{\sum_{k=1}^mx_k}{m}+...+c_n\frac{\sum_{k=1}^mx_k^n}{m}=0.$$ If the various $\frac{\sum_{k=1}^mx_k^r}{m}$ were powers of $\frac{\sum_{k=1}^mx_k}{m}$, then that would be a root, but they're clearly not.  Or instead of dividing by $m$ you could split it into $m>n+1$ expressions of the form
$$c_0 + c_1x_k + ... + c_nx_k^n\; ,$$
such that their sum is equal to zero, but that certainly doesn't imply they all have to be zero individually. Anyways as you can see I'm stumped. **Also note that while $n=m-1$ will most of the time be invertible, if one of the data points is zero, then it won't be.","['numerical-linear-algebra', 'matrices', 'linear-algebra', 'least-squares']"
655492,Showing summation is bounded,I'm currently taking a Comp Sci class that is reviewing Calculus 2. I have a question: Show that the summation $\sum_{i=1}^{n}\frac{1}{i^2}$ is bounded above by a constant I realize that this question is already answered here Showing that the sum $\sum_{k=1}^n \frac1{k^2}$ is bounded by a constant Could anyone explain it to me further? I believe I'm supposed to use p-series test or integral test to complete,"['sequences-and-series', 'calculus']"
655512,Estimating integrals involving $\pi(x)$,"While solving an exercise in analytic number theory, I ran into difficulty of estimating an integral of the form $\displaystyle\int_{1}^{x} \frac{\pi(t)}{t} dt$ where $\pi(x)$ is the prime counting function. I am interested in understanding how to estimate this integral (as a function of $x$ of course), whether it is a big Oh estimate, or something more precise. Any references are appreciated. Similarly, how would one estimate $\displaystyle\int_{1}^{x} \frac{\pi(t)}{t^2} dt$  as a function of $x$? Thanks!","['number-theory', 'definite-integrals', 'asymptotics', 'analytic-number-theory', 'real-analysis']"
655518,Proof $e^x = \exp(x)$?,"Define $$\ln (x) = \int^{x}_{1}\frac{1}{t}$$ Assume I have proven that $\ln x$ is one-to-one and therefore has an inverse $\exp (x)$. Define $e$ as: $\ln e = 1$ Now, if you have no other notion of exponentials, or logarithms, how could define what $e^x$ means and show that its the inverse of $\ln x$? You are allowed to assume the logarithmic product and quotient property. Thanks for the help.","['calculus', 'integration', 'definite-integrals', 'exponential-function', 'logarithms']"
655537,Number of functions with some property,"A function $f$ is defined on the set $\{0,1,2,3,…,n-1\}$ to itself. This is a function such that if you take any $k$ from the set $\{0,1,2,3,…,n-1\}$ then $f^m (k)=0$ for some natural number $m$. Question is how many such $f$ exist? My strong conviction about the answer is $n^{n-1}$. If it is, how can we prove this. I need the proof.","['functions', 'graph-theory', 'abstract-algebra', 'combinatorics']"
655568,Inverse of $(e^x - e^{-x})/2$,What is the inverse of the function $f(x)=\frac{e^x - e^{-x}}2$? I tried replacing $e^x$ by a variable but I still can't get it.,"['inverse', 'algebra-precalculus', 'hyperbolic-functions']"
