question_id,title,body,tags
1739654,Prove $f(x)=\|x\|$ differentiable everywhere but in $\{0\}$,"I have the function $f: \mathbb R ^n \to \mathbb R$ where $f(x)=\|x\|$. I have to prove that $f$ is differentiable on $E$, where $E=\mathbb R^n \setminus \{0\} $, and show its derivative (for $x \ne 0 $, of course). I'm not able to split this function up in different parts, because $x$ is here a vector $x=(x_1,x_2,x_3,\ldots)$ I assume. I do not really know how to prove differentiability in this case.","['multivariable-calculus', 'normed-spaces', 'continuity', 'derivatives']"
1739666,Looking for function $f$ such that $f'<0$ and $(xf)'>0$,"I'm looking for a function $f(x)$ with the following properties for $x\ge 0$:
$$0\le f(x)\le 1$$
$$f(0)=1$$
$$f'(x)\le 0$$
$$f(x)+xf'(x)\ge 0$$
$$\lim_{x\to\infty} xf(x)=L$$
where $L$ is a positive constant. Essentially I want $xf(x)$ to initially approximate $x$ and then level off at $L$. Candidates include:
$$f(x)={1\over 1+x/L}$$
$$f(x)={\tanh (x/L) \over x/L}$$
but neither of these have an extra parameter that allows me to control how quickly $xf(x)$ approaches $L$ while keeping the initial slope of $xf(x)$ equal to $1$. This is what I would like, ideally. The motivation for this: $f(x)$ can be thought of as an efficiency with $x$ the input and $xf(x)$ the output. The system is perfectly efficient at zero input and decreases in efficiency with increasing input, but you never get less output from more input. Thanks for your responses.","['calculus', 'functions']"
1739683,"Equivalence of parallel transport, connection and covariant derivative","Here by connection I mean the horizontal distribution. I hear about these three notions are equivalent, i.e. given one we can recover another. In the textbook of Riemannian geometry I have read, usually the existence of covariant derivative is proved to be exist, and then parallel transport. But there is nothing about horizontal distribution. So I would like to know whether there is any reference shows these three notions are equivalent(thoroughly). Thanks!",['differential-geometry']
1739706,How to evaluate $\lim _{x\to \infty }\:\frac{\left(\sqrt{1+\frac{x^3}{x+1}}-x\right)\ln x}{x\left(x^{\frac{1}{x}}-1\right)+\sqrt{x}\ln^2x}$?,"I have a problem with this limit, I have no idea how to compute it. Can you explain the method and the steps used(without L'Hopital if is possible)? Thanks
$$\lim _{x\to \infty }\:\frac{\left(\sqrt{1+\frac{x^3}{x+1}}-x\right)\ln x}{x\left(x^{\frac{1}{x}}-1\right)+\sqrt{x}\ln^2x}$$
The result should be $-\frac{1}{2}$, but wolfram says that is $0$","['real-analysis', 'calculus', 'limits']"
1739710,"Are $XZ$ and $YZ$ independent if $X$, $Y$ and $Z$ are all independent?","Let $X$ and $Y$ be independent random variables. Let $Z$ be a random variable such that $Z$ and $X$ are independent, $Z$ and $Y$ are independent. Are random variables $XZ$ and $YZ$ independent?","['independence', 'probability-theory', 'probability']"
1739713,How to calculate the radius of a Arc Segment given only the Arc Length and the Height of the arc segment?,"Most of the calculations I know and can find can solve for the radius if the cord length is known or the angle is known along with the height of the arc segment.  However I cannot find, nor figure out how to calculate the radius if only the arc segment and the height of the segment is known. I have looked up several different methods on this and other site and the following are similar but not exactly what I am looking for. Calculate the radius of a circle given the chord length and height of a segment Calculating the height of a circular segment at all points provided only chord and arc lengths ) In CAD I can draw a arc like what is shown at ( http://mathworld.wolfram.com/CircularSegment.html ).  If I fix the mid point at (0,0), the set the cord horizontal, then add a dimension the segment height (i.e. h=2"") and then dimension the arc length (i.e. s=10""), the geometry is fully constrained.  So I know there is a way to solve this. If I reversed the inputs and had the arc length (s) known and the radius (R) known I can calculate the segment height but I am having trouble reversing the equation.","['trigonometry', 'geometry']"
1739718,Matrix Calculus Question: a scalar-by-matrix derivative,"I have the following scalar-by-matrix derivative that I have completely no clue how to solve: $f(\mathbf{R},\mathbf{S}) = \mathbf{y}^{\top}\bigg(\mathbf{1}\otimes\mathbf{R}+\mathbf{\Phi}\otimes\mathbf{S}\bigg)^{-1}\mathbf{y}$ where $f(\mathbf{R},\mathbf{S})$ is a scalar function, $\mathbf{y}$ is column vector. Is there a closed form solution to $\dfrac{df(\mathbf{R},\mathbf{S})} {d\mathbf{R}}$ and $\dfrac{df(\mathbf{R},\mathbf{S})} {d\mathbf{S}}$? Any guidance will be helpful. Many thanks!","['matrices', 'matrix-calculus', 'derivatives']"
1739756,solve $\sin 2x + \sin x = 0 $ using addition formula,"$\sin 2x + \sin x = 0 $ Using the addition formula, I know that $\sin 2x = 2\sin x \cos x$ => $2\sin x \cos x + \sin x = 0$ => $\sin x(2\cos x + 1) = 0$ => $\sin x = 0$ and $\cos x = -\frac{1}2 $ I know that $\sin x = 0$ in first and second quadrant so $x = 0$ and $x = 180$ What I do not know is what to do with $\cos x = -\frac{1}2$ and which quadrants this applies to. The book I got the question from gives the following answer which does not make sense to me: 0, 120, 180, 240, 360",['trigonometry']
1739776,References for actions of infinite-dimensional Banach-Lie groups on infinite-dimensional Banach manifolds,"I am starting to study infinite-dimensional manifolds, specifically, Banach manifolds.
I found some interesting introductory texts in which the mathematical background is developed with some detail.
However, I am not able to find some organic treatment of the differential geometry of the orbits of a smooth (analytic) action of an infinite-dimensional Banach-Lie group $\mathcal{G}$ on Banach manifolds $\mathcal{M}$.
I am particularly interested in the case of non-proper actions, and I would like to know if and under what assumptions the orbits are Banach manifolds. Are there articles/books developing the subject? Thank You. EDIT Here and in ""Bourbaki: Lie groups and Lie algebras, chapters 2 and 3"", I found that, whenever the isotropy subgroup $\mathcal{G}_{m}$ at $m\in\mathcal{M}$ is a split Lie subgroup of $\mathcal{G}$ (that is, a subgroup which is a Lie group in the subspace topology), then $\mathcal{G}/\mathcal{G}_{m}$ is an analytic Banach manifold, and $\pi\colon\mathcal{G}\rightarrow\mathcal{G}_{m}$ is a submersion.
Clearly, there is a bijection $\gamma$ from $\mathcal{G}/\mathcal{G}_{m}$ to the orbit $\mathcal{G}\cdot m$ through $m\in\mathcal{M}$.
What do I have to do to ensure that the bijection $\gamma$ turns $\mathcal{G}\cdot m$ into a Banach manifold?","['reference-request', 'banach-spaces', 'differential-geometry', 'lie-groups']"
1739777,Surface area from indicator function,"I know that the volume and the surface area of a sphere of radius $R$ are related by a derivative: 
$$V(R)=\frac{4}{3}\pi R^3$$
$$A(R)=4\pi R^2=\frac{\partial V(R)}{\partial R}$$
I am asking if an analogous relation, in the sense that it allows to know the value of the surface from the value of the volume, exists for the indicator functions.
I know the indicator function of a set $\Omega\in\mathbb{R}^n $ and $\vec{x}\in\mathbb{R}^n$ is a generic point :
$$
\chi_{\Omega}(\vec{x})=
\begin{cases} 
      \hfill 1 \text{ if } \vec{x}\in \Omega \\
      \hfill 0 \text{ if } \vec{x}\notin \Omega \\
  \end{cases}
$$
the volume of $\Omega$ is easily computed: $$V(\Omega)=\iiint_{\mathbb{R}^n} \chi_{\Omega}(\vec{x})d\vec{x} $$ Is it possible to compute the value of the surface area $A(\Omega)$ from the knowledge of $\chi(\Omega)$?
Taking the derivative of  $\chi_{\Omega}(\vec{x})$ I expect to have something related to the delta function. 
From an intuitive point of view, I expect the integral:
\begin{equation}
\iiint_{\mathbb{R}^3} ||\nabla \chi_{\Omega}(\vec{x})|| d\vec{x} 
\tag{*}\label{*}
\end{equation}
to be related to the surface area and this makes me think about a certain relationship.
I also had a look online and in the book ''Shapes and Geometries Metrics, Analysis, Differential Calculus, and Optimization'' but I have not find anithing which solves my problem directtly.
I have also thougt to use the divergence theorem but that would mean to find a field $\vec{F}$ whose divergence is $\chi$ and this is the countrary of what I am looking for by analaogy (something which allows me to compute the area from the derivative (gradient) of the volume). Is my ""intuition correct"" and if yes could you give me a detailed answer or/and a good book/reference which attacks that problem directly? ---------------EDIT--------------- I reasoned a bit more on my question and I think I have found something.
In particular, https://en.wikipedia.org/wiki/Surface_area remembered me that ''While for piecewise smooth surfaces there is a unique natural notion of surface area, if a surface is very irregular, or rough, then it may not be possible to assign an area to it at all.'' Then assuming to deal with a voulume $\Omega \in \mathbb{R}^n$ whose boundary $\partial \Omega$ is regular enough to have a well defined surface area, I reasoned as follow:
the indicartor function is used to compute approximatively the surface area by implicitly assuming it to be smooth and calculating its derivative (which are nonvanishing only on the smooth-assumed boundary).
This post Smooth approximation of characteristic function of a bounded open set gave me the idea:
By seeing the indicator function $\chi_{\Omega}(\vec{x})$ as the limit of the following succession of functions:
\begin{equation}
	f_n(\vec{x})=\frac{n^3}{\pi^{\frac{3}{2}}}e^{-(n{\vec{x}})^2}
\end{equation}
which has integral $1$ and approaches the Dirac delta function as $n\to \infty$. 
The convolution $\chi_{\Omega}*f_n$ is smooth  $\forall n$ since $f_n$ is smooth and it converges everywhere to $\chi_{\Omega}$:
\begin{equation}
	[\chi_{\Omega}*f_n](\vec{x})=\int_{\mathbb R^3}\chi_{\Omega}(\vec{y})f_n(\vec{x}-\vec{y})d\vec{y}
\end{equation}
\begin{equation}
	\nabla^k_{\vec{x}}[\chi_{\Omega}*f_n](\vec{x})=\int_{\mathbb R^3}\chi_{\Omega}(\vec{y})\nabla^k_{\vec{x}}f_n(\vec{x}-\vec{y})d\vec{y}
\end{equation}
Therefore, using this formalism, we can define the implicit equation for the surface as:
\begin{equation}
	h_n(\vec{x})=[\chi_{\Omega}*f_n](\vec{x})-0.5
\end{equation} \begin{equation}
 \chi_{\Omega}(\vec{x})=\theta(h_n(\vec{x}))
\tag{**}\label{**}
\end{equation} Given a 3D surface defined implicitly by $h_n(x,y,z)=0$ the normal versor to it is defined by:
\begin{equation}
	\hat{N}_n=\frac{\nabla h_n}{||\nabla h_n||}
\end{equation} For finite $n$, the vector field $\hat{N}_n$ defined here is continuous and differentiable, hence we can apply the divergence theorem using $\hat{N}_n$ as a vector field:
\begin{equation}
	\iiint_V( \nabla\cdot\hat{N_n}) \;\text{d}\tau=\iint_{\partial V} (\hat{N_n}\cdot\hat{N_n})\;\text{dS}=\iint_{\partial V} \text{dS}= A
\tag{***}\label{***}
\end{equation}
Therefore we are able to compute the surface area integrating over the volume the divergence of the vector field defined by the normal to the surface. The vector field $\hat{N}_n$ defined here is continuous and differentiable in the region around the border of V for finite $n$, but as $n\to\infty$ it becomes ill defined Therefore, up to now I think that my method allows to have an approximate estimation of the area of the surface for $n$ finite, but in the limir $n\to\infty$ we have that the vector field $\hat{N}_n$ becomes ill defined and so I cannot say anything about the convergence of the area to the real value... I am now trying to show that \ref{***} becomes \ref{*} in the limit $n\to\infty$...intuitively this seems possible... Recalling \ref{*}, we have that, using \ref{**}:
\begin{equation}
\nabla \chi_{\Omega}(\vec{x})=\delta(h_n(\vec{x}))\nabla h_n(\vec{x})
\end{equation}
Hence \ref{*} becomes:
\begin{equation}
\iiint_{\mathbb{R}^3} \delta(h_n(\vec{x})) ||\nabla h_n(\vec{x})|| d\vec{x}
\end{equation} Now, using the coarea formula from geometric measure theory ( https://en.wikipedia.org/wiki/Dirac_delta_function ):
$$\int_{\mathbf{R}^n} f(\mathbf{x}) \, \delta(g(\mathbf{x})) \, d\mathbf{x} = \int_{g^{-1}(0)}\frac{f(\mathbf{x})}{|\mathbf{\nabla}g|}\,d\sigma(\mathbf{x}) $$
we have:
\begin{equation}
\iiint_{\mathbb{R}^3} \delta(h_n(\vec{x})) ||\nabla h_n(\vec{x})|| d\vec{x}=\iint_{h_n^{-1}(0)} \frac{||\nabla h_n(\vec{x})||}{||\nabla h_n(\vec{x})||}dS=\iint_{h_n^{-1}(0)} dS
\end{equation} Therefore I have proved that \ref{*} is a good definition of the surface area. Now the question is how well \ref{***} approximates the area","['riemannian-geometry', 'geometric-measure-theory', 'measure-theory', 'geometry', 'differential-geometry']"
1739817,Martingale convergence for UI martingales,"I started reading this paper (Lamb, Charles W.. “ Shorter Notes: A Short Proof of the Martingale Convergence Theorem ”. Proceedings of the American Mathematical Society 38.1 (1973): 215–217) today. In paragraph 2 the author says The martingale $(X_n,\mathscr{F}_n:n\geq{0})$ is called
   complete if there exists a random variable $X$ with $\mathbb{E}[X|\mathscr{F}_n] = X_n$ for $n\geq 0$.
   There is no loss of generality in assuming that $X$ is $\mathscr{F}_\infty$-measurable where
   $\mathscr{F}_\infty$ is the $\sigma$-field generated by $\bigcup \mathscr{F}_n$. It is an elementary exercise to show
   that a martingale is complete if and only if it is uniformly integrable. We
   remark only that the necessity is proved by defining a set function $\mu(A)=
 \lim \mathbb{E}[X_n: A]$ on the field $\bigcup \mathscr{F}_n$, proving from the uniform integrability
   that $\mu$ is a finite signed measure on $\bigcup \mathscr{F}_n$ [...] I can see why $\mu$ is a well defined set function and why it is finitely additive on $\bigcup \mathscr{F}_n$, but I didn't manage to prove countable additivity. This is my approach: let $(A_k)$ be a collection of disjoint elements of $\bigcup \mathscr{F}_n$ such that $A\equiv\bigcup_k A_k \in \bigcup_n \mathscr{F}_n$, then I can show by the Monotone Convergence Theorem that for all $m\geq 0$, $\mu(A)=\lim_{m\to \infty} \sum_k \mathbb{E}[X_m:A_k]$, but I don't see how to exchange the limit and the infinite sum. I guess this has to do with the fact that $X$ is uniformly integrable, but I don't understand how.","['martingales', 'measure-theory', 'uniform-integrability']"
1739861,List of $n$-bit strings that approximately preserves Hamming distance,"If $x$ and $y$ are both $n$-bit strings then their Hamming distance $d_H(x,y)$ is the number of positions in which they differ. Suppose we write out the set of all $n$-bit strings in some order $s_1, \ldots, s_{2^n}$. Now define the distance of two strings with respect to this order as $d_S(s_i,s_j) = \min \{ i-j \bmod 2^n, j-i \bmod 2^n \}$. I consider the ordering to be cyclic. I would like an ordering of strings that approximately preserves Hamming distances in the following way: There is a ""small"" function $f$ such that, for all $n$-bit strings $x,y$, $d_S(x,y) \le f( d_H(x,y) )$. In other words, strings of Hamming distance $\delta$ are within $f(\delta)$ distance in the ordering. I want $f$ to be as small as possible. I am also fine if this bound only holds for small $\delta$. I have found some results on ""distance-preserving Gray codes"" which have a similar property (one such paper cited below), but it's closer to the converse of what I want. These gray codes have the property that if $d_S(x,y) \le \delta$ then $d_H(x,y) = d_S(x,y)$. In other words, nearby strings in the gray code are nearby in Hamming space, but it doesn't guarantee that all nearby points in Hamming space are also nearby in the gray code. Binary gray codes with long bit runs : Luis Goddyn, Pavol Gvozdjak. Elect. J of Comb. 2003","['coding-theory', 'combinatorics', 'graph-theory']"
1739884,Occurence of number $1$ in the sequence $a_n=2^n$,"So I was just calculating the terms of the sequence $a_n=2^n$ for $n=1,2,...50$ and discovered that among the first fifty terms there is $31$ term that has number $1$ in itself (in base $10$, of course). It seems that as we go further in the sequence that the terms that contain $1$ in itself become more and more common. Let us denote by $m(n)$ the number of numbers in the set $\{2^1,...,2^n\}$ that contain number $1$ when written in base $10$ (so I calculated that $m(50)=31$). Can someone evaluate the limit $\lim_{n \to \infty} \frac {m(n)}{n}$?","['elementary-number-theory', 'limits']"
1739885,Marginal independence v.s. joint independence,"Suppose that $X$ is independent with $Y$ and is also independent with $Z$. No further assumption is made about the joint distribution of $Y$ and $Z$. Does it follow that $X$ is independent with $(Y,Z)$? I know the reverse direction is true and I suspect the direction is above is not true but I don't have a counterexample.","['independence', 'probability-theory', 'probability']"
1739887,Let $f(x) = x^{2}$ for all $x \in \Bbb R$. Show that $f[\Bbb Q] \subset \Bbb Q$,"Let $f(x) = x^{2}$ for all $x \in \Bbb R$. Show that $f[\Bbb Q] \subset \Bbb Q$ We know that $f[\Bbb Q]$ is the set of all values that $f$ takes on given points in $\Bbb Q$, i.e. $f[\Bbb Q] = \{f(x):x\in \Bbb Q\}$. But how do I show that every $f(x)$ is in $\Bbb Q$? Thanks!",['functions']
1739896,"Apparent violation of fundamental theorem of ODEs, how to resolve?","Consider, in the $(x, y)$-plane, the family of curves given by $y = (x - c)^3$, for the various possible values of the number $c$. Denote by $v$ the unit vector field everywhere tangent to this family of curves. Then it would seem that there are two integral curves of this $v$ beginning at the origin, namely, the one that goes along the $x$-axis, and the one that goes along the curve $y = x^4$. Thus, we apparently have a violation of the fundamental theorem of ordinary differential equations. How do we resolve this?","['multivariable-calculus', 'real-analysis', 'ordinary-differential-equations', 'manifolds']"
1739903,The Heuristic Gauss-Kronrod Based Error Estimator in Quadpack,"I'm trying to understand the local error estimate that Quadpack (and subsequently other libraries such as GSL, quadpack++, cubature, etc.) uses for it's general adaptive quadrature subroutine QAG. The integration procedure is a Gauss-Kronrod rule and Quadpack uses a heuristic error estimate that I struggle to make sense of. The error estimate can be found on page 67 in the Quadpack book or on page 11 in this excellent (and free) review of Error Estimation in Adaptive Quadrature . Or in the Quadpack source code for that matter. It states: Let $G_n[a, b]$ is the n-point Gauss quadrature rule of degree $2n−1$ and $K_{2n+1}[a, b]$ is the $2n+1$ point Gauss-Kronrod extension of degree $3n+1$ which is in turn used as the approximation to the integral. The local error estimate is: $$\varepsilon_k = \tilde{I}_k \min \left\{ 1,  \left(200\frac{\left|G_n[a_k, b_k]-K_{2n+1}[a_k, b_k]\right|}{ \tilde{I}_k} \right)^{3/2} \right\} $$ where $$ \tilde{I}_k = \int_{a_k}^{b_k}\left| f(x) - \frac{K_{2n+1}[a_k, b_k]}{b_k-a_k} \right| dx$$ which is also evaluated numerically using the $K_{2n+1}[a,b]$ rule. The power $3/2$ has been chosen experimentally in such a way that the error scales exponentially with a break-even point at approximately relative machine
precision for single floating point arithmetic. This means that the error estimate is less pessimistic for small values of $\left|G_n[a_k, b_k]-K_{2n+1}[a_k, b_k]\right|$ and more reliable for large values. Indeed this is verified by plotting (letting $\tilde{I}_k = 1$): Furthermore Quadpack also evaluates 
$$ \hat{I}_k = \int_{a_k}^{b_k}| f(x) | dx$$
using the $K_{2n+1}[a,b]$ rule. Denote by $f_{min}$ and $\varepsilon_{mac}$ the minimum floating point number and the floating point machine precision respectively (these number depends on single or double precision). Finally Quadpack checks if 
$$\hat{I}_k > \frac{f_{min}}{50 \varepsilon_{mac}}$$ holds true and in this case they set $$\varepsilon_k = \max \left\{50 \varepsilon_{mac} \hat{I}_k, \varepsilon_k \right\}$$ which will be used as the final error estimation of the integral on $[a_k,b_k]$. Question 1: What is the reason for doing the last step with the absolute value integrand. I do not under stand the point of it at all. Question 2: Is there a particular reason why they choose the approximate single precision machine epsilon as the break even point, or is it just an arbitrary small number? Why not use the double precision machine epsilon? Thanks in advance!","['numerical-methods', 'integration']"
1739907,How do you define a sample space with rigor?,"I was reading First Course on Probability by Sheldon Ross and I came across a problem which went like this: ""A customer visiting the suit department of a certain store will purchase a suit with probability $.22$,
a shirt with probability $.30$, and a tie with probability $.28$. The customer will purchase both a suit
and a shirt with probability $ .11$, both a suit and a
tie with probability $.14$, and both a shirt and a tie
with probability $.10$. A customer will purchase all $ 3$
items with probability $.06$. What is the probability
that a customer purchases
(a) none of these items?
(b) exactly $1$ of these items?"" Problem a) is easy to solve, what confuses me is part b). Ross solves it in the following way: The probability that two or more items are purchased is
$P(AB ∪ AC ∪ BC) = .11 + .14 + .10 − .06 − .06 − .06 + .06 = .23$
Hence, the probability that exactly $1$ item is purchased is $.51 − .23 = .28.$ Intuitively, I understand why he subtracts the probability of buying two or more things from the probability of buying anything at all. What I do not understand is the rigor behind it. Why am I justified in subtracting one probability from the other? What I tried to do in order to justify this was saying $P( \mathrm {buying \ 2 \ or \ more \ things)} + P(\mathrm {buying \ 1 \ thing}) + P(\mathrm {buying \ nothing})=1$ since a customer must buy a shirt, or a tie, or a suit, or nothing, therefore the three terms above must add up to the probability of the sample space which equals one. A sample space is the set of all the outcomes of an experiment, the event space is a set of subsets of the sample space and an event is an element of the event space. I know that $P$ maps events to the unit interval, the only problem I have is how do I define the previous events (namely $\{ \mathrm {buying \ 2 \ or \ more \ things} \}$, $\{ \mathrm {buying \ 1 \ thing} \}$, $\{\mathrm {buying \ nothing}  \}$). If I defined the sample space as $\{\mathrm {shirt, \ suit , \ tie , \ nothing} \}$, then the sets $\{ \mathrm {buying \ 2 \ or \ more \ things} \}$ and $\{ \mathrm {buying \ 1 \ thing} \}$ would not be disjoint and I would not be able to add them together like I did. So if I were asked to write those events explicitly, how would I go about doing it? Am I defining the sample space wrong? I need some clarification on exactly how to define sample spaces such that, if I wanted to, I could write them down explicitly.","['probability-theory', 'probability']"
1739918,Use induction to prove that that $8^{n} | (4n)!$ for all positive integers $n$,"Use induction to prove that that $8^{n} | (4n)!$ for all positive integers $n$ So far I have:
Base case (n = 1)
= $8^{1} | (4(1))!$ = $8 | 24$ which is true. Induction Step: $8^{n + 1} | (4(n + 1))!$ $8^{n + 1} | (4n + 4)!$ A bit confused as to how to close this proof out, also wanted to make sure my current progress is correct as well. Any help is appreciated.","['divisibility', 'induction', 'elementary-number-theory', 'factorial', 'discrete-mathematics']"
1739921,Proving $(A\times B)^- = A^-\times B^-$ (closure of cartesian product),"My proof, for: $$(A\times B)^- = A^-\times B^-$$
using the metric $$d''((a_1,a_2),(b_1,b_2)) = max\{d_1(a_1,b_1),d_2(a_2,b_2)\}$$ $\rightarrow$ Well, if $a = (a_1,a_2)\in (A\times B)^-$ then: $$d''((a_1,a_2), A\times B) = 0 \implies d''((a_1,a_2),(a_a,a_b))=0 \implies d_1(a_1,a_a)=0, d_2(a_2,a_b)=0$$ for all $a_a\in A$ and $a_b\in B\implies a_1\in A^-$ and $a_2\in B^-$, therefore $a\in (A\times B)^-$ $\leftarrow$ $$a\in A^- \times B^ \implies (a_1,a_2)\in A^- \times B^- \implies a_1\in A^-, a_2\in B^-\implies d_1(a_1,a_a)=0 \ \  \forall a_a\in A, \\d_2(a_2,a_b)=0 \ \ \forall a_b\in B \implies d''((a_1,a_2),(a_a,a_b))=0, \ \ \forall a_a\in A, a_b\in B\implies d''(a,A\times B)=0\implies a\in (A\times B)^-$$","['product-space', 'general-topology', 'metric-spaces', 'proof-verification']"
1739924,"Let $f(z)$ be analytic in the unit disc,","Let $f(z)$ be analytic in the unit disc, $Rf(z) \ge 1$, and $f(0)>0$. Show that $$f(0) \cdot \frac{1-|z|}{1+|z|} \le |f(z)| \le f(0) \cdot \frac{1+|z|}{1-|z|} \quad z \in D $$ This looks like something I would have to prove using cases. I tired to throw some numbers in there to see what was going on but I am still not seeing how to prove this. I think I am missing or forgetting a concept to use. I have attempted the Schwartz lemma as suggested below and assumed $f(0)=1$ I am not sure if this is the right path to take?","['complex-analysis', 'real-analysis']"
1739927,Would an infinite random sequence of real numbers contain repetitions?,"If random real numbers are selected from the set of all real numbers, for an infinite number of iterations, what is the likelihood of repetitions occurring?","['infinity', 'sequences-and-series']"
1739941,"Verify that $(a^2 + b^2)(c^2 + d^2)$ = $(ac - bd)^2 + (ad + bc)^2$ for any integer $a$,$b$,$c$,$d$","Part 1 - Verify that $(a^2 + b^2)(c^2 + d^2)$ = $(ac - bd)^2 + (ad + bc)^2$ for any integer $a$,$b$,$c$,$d$ Part 2 - Write 25988 as the sum of the two squares (of integers). A bit confused with this question, we covered Norm today in class, and I took the formula below from my notes because it seemed helpful with this problem. $N((a + bi)(c + di))$ = $N((a + bi) * N(c + di)$ $(a + bi)(c + di)$ = $(ac - bd) + (ad + bc)$ $(a - bi)(c - di)$ = $(ac - bd) - (ad + bc)$ This formula goes on to multiply together, but I am not sure if this useful or as to how I would use the answer for part 2 of the problem. Any help is greatly appreciated.","['number-theory', 'normed-spaces', 'discrete-mathematics']"
1739974,Showing reducibility of a polynomial in a Discrete Valuation Ring,Let $R$ be a complete discrete valuation ring with uniformiser $\pi$. I would like to show that a polynomial $f$ in $R[X]$ is reducible. Does it suffice to show that $f$ is reducible in $\frac{R}{\pi^i}[X]$ for all $i\in\mathbb{Z}_{\geq{1}}$? Thoughts: I think it does because $R$ complete means it is the inverse limit of the  $\frac{R}{\pi^i}$'s. Moreover each factorisation of $f$ in $\frac{R}{\pi^i}[X]$ passes down to $j\leq i$. But I kind of need to pass down from $i$ equal to infinity to make this work. I feel like I've seen something like this before somewhere else as well where it was made to work but I can't remember the argument... The example I'm interested in is when $R$ is a $\mathbb{Z}_p$ and $\pi=p$ where $p$ is a rational prime.,"['polynomials', 'abstract-algebra', 'algebraic-number-theory', 'ring-theory', 'dedekind-domain']"
1739995,$\int_{\bigcup_{n=1}^{\infty}E_n}f=\sum_{n=1}^{\infty}\int_{E_n}f$ given $f$ positive and measurable,"I'm learning about measure theory (specifically Lebesgue intregation) and need help with the following problem: Let $f:\mathbb{R}\rightarrow[0,+\infty)$ be measurable and let $\{E_n\}$ be a collection of pairwise disjoint measurable sets. Prove that $\int_{\bigcup_{n=1}^{\infty}E_n}f=\sum_{n=1}^{\infty}\int_{E_n}f.$ For convenience I set $E=\bigcup_{n=1}^{\infty}E_n$. This problem looks like an application of the monotone convergence theorem but I'm having a hard time applying it. I need to find a sequence of functions that is positive an nondecreasing but I don't know how to define it.","['lebesgue-measure', 'lebesgue-integral', 'measure-theory']"
1740032,Is basis change ever useful in practical linear algebra?,"In layman's terms, why would anyone ever want to change basis? Do eigenvalues have to do with changing basis?","['change-of-basis', 'linear-algebra', 'soft-question']"
1740052,"How many strings of length 8, from 4 letter alphabet, using each letter twice. There is to be exactly one pair of same letters next to each other.","The question - how many strings of length 8, from 4 letter alphabet, using each letter twice. There is to be exactly one pair of same letters next to each other (example of valid string: AABCDBCD). I tried to check how this develops by drawing a tree, but it seems that this gets really unwieldy really fast. What counting technique can be used here to make it easier?","['combinatorics', 'discrete-mathematics']"
1740054,Show that $\int_{0}^{\infty} \frac{\cosh(ax)}{\cosh(\pi x)} dx=\frac{1}{2}\sec(\frac{a}{2})$ using Residue Calculus,"Show that the following expression is true $$\int_{0}^{\infty} \frac{\cosh(ax)}{\cosh(\pi x)} dx=\frac{1}{2}\sec(\frac{a}{2})$$ Edit: I forgot to mention that $|a|<\pi$ Specifically, 
using Residue Calculus and a rectangular contour with corners at $\pm R$ and $\pm R+i$ However, I'm unsure how to approach this given the bound from $(0,\infty)$, where I usually see the bound $(- \infty, \infty )$. How does this change the problem, and how should I begin to approach it from here? Edit: Given the tip that the integrand is an even function, I can use the following relation: $$\int_{0}^{\infty} \frac{\cosh(ax)}{\cosh(\pi x)} dx= \frac{1}{2} \int_{- \infty}^{\infty} \frac{\cosh(ax)}{\cosh(\pi x)} dx$$ Next I proceed by the standard procedure $$\oint_C f(z) \,dz=(\int_{C_{R}}^{}+\int_{C_{T}}^{}+\int_{C_{L}}^{}+\int_{C_{B}}^{})f(z)dz=2 \pi i \sum_{j}\text{Res}(f(z);z_j)$$ where $f(z)=\frac{\cosh(az)}{\cosh(\pi z)}$ and R, T, L, and B denote the right, top, left, and bottom sides of the rectangular contour. Furthermore, I can bound each $C_i$ integral and determine what happens as R approaches $\infty$ to ultimately simplify the above expression. In fact, the side contour integrals do disappear as R approaches $\infty$, and the bottom integral becomes our integral of interest. $$\oint_C f(z) \,dz=(\int_{C_{T}}^{}+\int_{C_{B}}^{})f(z)dz=2 \pi i \sum_{j}^{}\text{Res}(f(z);z_j)$$ However, I am left clueless as to how to deal with the top integral.","['hyperbolic-functions', 'complex-analysis', 'residue-calculus', 'complex-integration']"
1740124,Morphism whose fibers are finite and reduced is unramified,"Definition : Let $f: X \to Y$ be a morphism of finite type of locally Noetherian schemes, $x \in X, y = f(x) \in Y$ . Say that $f$ is unramified at $x$ if the map on stalks satisfies $m_y \mathcal{O}_{X,x} = m_x$ and the extension $k(y) \to k(x)$ is separable. Proposition: If $f$ is as above, and for every $y \in Y$ , the fibers $X_y$ are finite, reduced, and $k(x)/k(y)$ is separable, then $f$ is unramified. I observe that the quotient $\mathcal{O}_{X,x} / m_y \mathcal{O}_{X,x}$ is the same when replacing $X$ with fiber $X_y$ . Evidently this implies the above proposition. Taking the observation, it seems we want to show that $\mathcal{O}_{X_y,x} / m_y \mathcal{O}_{X_y,x} = k(x)$ , the residue field at $x$ . Since $X_y$ is finite (although it doesn't specify, I'm assuming it means over $\text{Spec } k(y)$ ), then I know that it is a finite dimensional vector space over $k(y)$ . Reduced tells me that there are no nilpotent elements in $\mathcal{O}_{X_y,x}$ . Since the question is stalk-wise, I'm not sure how to apply finite. Should I take an open affine neighborhood of $y$ and then pull back to an open affine neighborhood cut out by a finite module? But this doesn't seem to help in showing that the maximal ideal in the local ring coincide. My current idea is to look at the map $X_y \to X$ . The map on stalks is then given by $\mathcal{O}_{X,x} \to \mathcal{O}_{X,x} \otimes k(y) = \mathcal{O}_{X_y,x}$ and try to show that this map has kernel $m_x$ . Furthermore, this is a local homomorphism so the contraction of the maximal ideal in the fiber is $m_x$ . My problem is that I'm not seeing where any of the assumptions will come into play or how to proceed further.",['algebraic-geometry']
1740147,"$\forall x\in R,$find the range of the function $f(x)=\cos x(\sin x+\sqrt{\sin^2x+\sin^2\alpha});\alpha\in[0,\pi]$","$\forall x\in R,$find the range of the function $f(x)=\cos x(\sin x+\sqrt{\sin^2x+\sin^2\alpha});\alpha\in[0,\pi]$ $f(x)=\cos x(\sin x+\sqrt{\sin^2x+\sin^2\alpha});\alpha\in[0,\pi]$ $f'(x)=\cos x(\cos x+\frac{\sin x\cos x}{\sqrt{\sin^2x+\sin^2\alpha}})-\sin x(\sin x+\sqrt{\sin^2x+\sin^2\alpha})$ I am stuck here and could not find the minimum and maximum values of $f(x),$The answer given is $-\sqrt{1+\sin^2\alpha}\leq f(x)\leq\sqrt{1+\sin^2\alpha}$.","['trigonometry', 'calculus']"
1740154,Different arrows in set theory: $\rightarrow$ and $\mapsto$ [duplicate],This question already has answers here : What does the function f: x ↦ y mean? (4 answers) Difference of mapsto and right arrow (3 answers) Closed 8 years ago . Can someone explain the difference between symbols: $\rightarrow$ and $\mapsto$ Thanks.,"['elementary-set-theory', 'notation', 'functions']"
1740178,Show that $3x^2 - 7y^2 = 1$ has no integer solutions,"Show that $3x^2 - 7y^2 = 1$ has no integer solutions A bit confused with this problem, my professor gave me a hint saying that I would need to use a ""good mod"" although I am not sure how to go about this, any help is greatly appreciated, I looked over a few similar posts on stack and still don't quite understand. Thank you in advance.","['number-theory', 'modular-arithmetic']"
1740179,Differential of the multiplication and inverse maps on a Lie group,"I'm trying to solve the following two problems: Let $G$ be a Lie group with multiplication map $\mu\colon G\times G\to G$, and let $\ell_a\colon G\to G$ and $r_b\colon G\to G$ be left and right multiplication by $a$ and $b$ in $G$, respectively.
      Show that the differential of $\mu$ at $(a,b)\in G\times G$ is
      $$
\mu_{*, (a,b)}(X_a,Y_b)
= (r_b)_*(X_a) + (\ell_a)_*(Y_b)
\quad \text{for } X_a\in T_aG,\ Y_b\in T_bG.
$$ and Let $G$ be a Lie group with multiplication map $\mu\colon G\times G\to G$, inverse map $\iota\colon G\to G$, and identity element $e$.
      Show that the differential of the inverse map at $a\in G$,
      $$
\iota_{*,a} \colon T_aG \to T_{a^{-1}}G,
$$
      is given by
      $$
\iota_{*,a}(Y_a) = -(r_{a^{-1}})_* (\ell_{a^{-1}})_* Y_a,
$$
      where $(r_{a^{-1}})_* = (r_{a^{-1}})_{*,e}$ and $(\ell_{a^{-1}})_* = (\ell_{a^{-1}})_{*,a}$. I am wondering if I should try to find curves through these points, or just apply either side to functions in $C^\infty(G)$? It looks like there are some questions on here about the differential of multiplication and inversion at the identity, but I'm trying to evaluate these at arbitrary points... the author (Tu) talks about the matrix exponential in this section but should I use that here? These Lie groups don't necessarily contain matrices.","['manifolds', 'differential-geometry', 'differential-topology', 'lie-groups']"
1740229,Visualizing sections of nontrivial vector bundles,"My question is simply: how does one think about sections of nontrivial vector bundles on a smooth manifold, for example? The canonical example I think of is a vector field, i.e. a section of the tangent bundle, or even a differential form (section of the cotangent bundle; slightly harder to visualize as literally as tangent vectors, but still somewhat concrete). I know that the Mobius strip gives a nontrivial bundle over the circle, which is perhaps the only one I can see clearly because of the low dimension, and even then the sections seem not so intuitive. However, when it comes to an arbitrary vector bundle, I have no idea how to imagine the sections. My motivation is that I'm trying to learn algebraic geometry and sheaf theory, which is explained to me as trying to generalize vector bundles (by just declaring the sections on an open set), but I'm having trouble how to think of these if they're not just trying to emulate vector fields/differential forms (or of course, ""smooth functions"" on a space in the case of the trivial bundle, which I like as motivation for the structure sheaf on a scheme). Any examples from (beginner) algebraic geometry would be appreciated too. Thanks.","['differential-topology', 'algebraic-geometry']"
1740285,Question about idempotent matrices. [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let $E$ be the $m \times m$ matrix that extracts the ""even part"" of an $m$-vector $Ex = (x+Fx)/2$, where $F$ is the $m\times m$ matrix that flips $[x_1,\dotsc ,x_m]^{T}$ to $[x_m,\dotsc ,x_1]^T$. Is $E$ idempotent?","['matrices', 'idempotents']"
1740317,How do I find the limit of this function?,This is a question from my calculus text. It says $$\lim\limits_{x\to1}\left(\frac{p}{1-x^p}-\frac{q}{1-x^q}\right)$$ where $p$ and $q$ are natural numbers. I know this is an infinity-infinity indeterminant form which can be converted to a $0/0$ form. I tried substituting $x=1+h$ where $h\to0$. But it is not working. What should I do?,['limits']
1740359,Calculating the differential of the inverse of matrix exp?,"Let $A(t)$ and $B(t)$ be two matrix-valued smooth function satisfying the equation, $B(t) = e^{A(t)}$. I need to express $\frac{dA(t)}{dt}$ in terms of $B(t)$. I know that there is a formula of Wilcox, namely
$$ \frac{d}{dt} e^{A(t)} = \int_0^1 e^{s A(t) } \frac{dA(t)}{dt}  e^{(1-s) A(t) } ds.$$
But I need something of the opposite direction. Does anyone know if there is such a formula or a general method to calculate that?","['matrices', 'matrix-calculus', 'differential-geometry', 'lie-groups']"
1740425,How to show some random variables are multivariate normal?,"I've got several series of random data, which can be denoted as x1,x2,...,xn.
How do I show that they are subjected to multivariate normal distribution? I refered to statistics textbooks but only got definations and properties. Do I have to estimate their density functions? Or is there any other necessary conditions? Thanks in advance!",['statistics']
1740458,Finding $\int \frac{dx}{a+b \cos x}$ without Weierstrass substitution.,"I saw somewhere on Math Stack that there was a way of finding integrals in the form $$\int \frac{dx}{a+b \cos x}$$ without using Weierstrass substitution, which is the usual technique. When $a,b=1$ we can just multiply the numerator and denominator by $1-\cos x$ and that solves the problem nicely. But I remember that the technique I saw was a nice way of evaluating these even when $a,b\neq 1$.","['integration', 'alternative-proof']"
1740477,Prove that $\lim_{\ r\ \to \ \infty} \dfrac{r! r^x}{x(x+1)(x+2) \dots (x+r)} = \int_{0}^{\infty} t^{x-1} e^{-t} dt $,"From Havil & Dyson, ""Gamma: Exploring Euler's Constant"", section 6.1 I can't prove the following Euler's theorem : ... on 13 October 1729, Euler had already proposed to Goldbach the 
  definition $$\Gamma (x) = \lim_{r\ \to \ \infty} \Gamma_r (x)
$$ where $$\Gamma_r (x) = \dfrac{r! r^x}{x(x+1)(x+2) \dots (x+r)}$$ [which is valid whenever $x$ is not zero or negative integer]. After 1 hours and 40 minutes of attempt I can't turn $\lim_{r\ \to \ \infty} \Gamma_r (x)$ to the following definition of $\Gamma (x)$ that I know, i.e. $$\Gamma (x) = \int_{0}^{\infty} t^{x-1} e^{-t} dt, \ \ \ x>0. $$ So why $$\lim_{r\ \to \ \infty} \dfrac{r^x}{x(1+ \frac{x}{1})(1+\frac{x}{2}) \dots (1+\frac{x}{r})} = \int_{0}^{\infty} t^{x-1} e^{-t} dt , \ \ \ x>0 \ \text{?} $$ EDIT : For the special case when $x$ is a positive integer we will have the problem of showing $$\lim_{r\ \to \ \infty} \dfrac{r!r^n}{(n+r)!} =1 $$ to be valid.","['improper-integrals', 'infinite-product', 'gamma-function', 'limits']"
1740505,Solve $x^2 = 2^n + 3^n + 6^n$ over positive integers.,"Solve $x^2 = 2^n + 3^n + 6^n$ over positive integers. I have found the solution $(x, n) = (7, 2)$. I have tried all $n$'s till $6$ and no other seem to be there. Taking $\pmod{10}$, I have been able to prove that if $4|n$ that this proposition does not hold. Can you give me some hints on how to proceed with this problem? Thanks.","['number-theory', 'diophantine-equations', 'elementary-number-theory']"
1740507,Prove that the determinant of an invertible matrix $A$ is equal to $±1$ when all of the entries of $A$ and $A^{−1}$ are integers.,"Prove that the determinant of an invertible matrix $A$ is equal to $±1$ when all of the entries of $A$ and $A^{−1}$ are integers. I can explain the answer but would like help translating it into a concise proof with equations. My explanation: The fact that $\det(A) = ±1$ implies that when we perform Gaussian
elimination on $A$, we never have to multiply rows by scalars. This means
that for each column, the pivot entry is created by the previous column’s
row operations and can be brought into place by swapping rows.
(And the first column must already contain a $1$). Therefore, we never need to
multiply by a non-integral value to perform Gaussian elimination.","['alternative-proof', 'linear-algebra', 'proof-verification', 'determinant']"
1740539,Normal closure of $\mathbb{Q}(\sqrt{11+3\sqrt{13}})$ over $\mathbb{Q}$,"The following is a question from an undergrad course in Galois theory: Find a normal closure $L$ of $K=\mathbb{Q}(\sqrt{11+3\sqrt{13}})$ over $\mathbb{Q}$ I know that normal extensions are splitting fields Let: $X=\sqrt{11+3\sqrt{13}} \implies X^2=11+3\sqrt{13} \implies X^2-11=3\sqrt{13}\implies ({\frac{X^2-11}{3}})^2-13=0 $ Is this related to the splitting field? Would the normal closure look something like: $\mathbb{Q}(\sqrt{11}, \sqrt{13})$ since $\sqrt{11}, \sqrt{13} \notin \mathbb{Q}$? I am guessing not since we have the weird embedded square root I have not really got my head aruond these questions so would very much appreciate your guidance","['galois-theory', 'splitting-field', 'abstract-algebra', 'group-theory', 'field-theory']"
1740616,Complexity of Gaussian Process algorithms is $\mathcal{O}(n^3)$,"It is often quoted that the complexity of Gaussian Process algorithms is $\mathcal{O}(n^3)$ due to the need to invert an $n \times n$ matrix, where $n$ is the number of data points. But as far as I can find online, matrix multiplication is also $\mathcal{O}(n^3)$. So would the complexity of GP algorithms still be $\mathcal{O}(n^3)$ if we no longer needed to invert matrices? Or have I missed something.","['regression', 'machine-learning', 'algorithms', 'neural-networks', 'probability']"
1740673,How to prove that my polynomial has distinct roots?,"I want to prove that the polynomial $$
f_p(x) = x^{2p+2} - abx^{2p} - 2x^{p+1} +1
$$ has distinct roots. Here $a$, $b$ are positive real numbers and $p>0$ is an odd integer. How can I prove that this polynomial has distinct roots for any arbitrary $a$,$b$ and $p$. Thanks in advance.","['complex-analysis', 'polynomials', 'analysis']"
1740703,Show that a function has bounded support,"Definition in my book: A function $f:\mathbb{R}^n \rightarrow \mathbb{R}$ has bounded support if there exists a closed interval $I$ in $\mathbb{R}^n$ such that $f(x)=0$ if $x \notin I$. Now I have to show that if $f$ and $g$ have bounded support (in $\mathbb{R}^n$) and $c \in \mathbb{R}$, then $f+g$ and $cf$ have bounded support too. This is what I did:
Since $f$ and $g$ have bounded support, there exist $I_1$ and $I_2$ such that $supp(f)=I_1$ and $supp(g)=I_2$. Then I can state $supp(f+g) \subseteq I_1 \cup I_2$ and $supp(cf) \subseteq I_1$, but that doesn't prove that $f+g$ and $cf$ have bounded support, does it? I believe it only shows that if a bounded support exists, it would a subset of $I_1 \cup I_2$ or more important it would be finite. Any thoughts on the matter? Can the bounded support be an empty set?",['multivariable-calculus']
1740706,Proving a result in infinite products: $\prod (1+a_n)$ converges (to a non zero element) iff the series $\sum a_n$ converges,"We assume that $\sum |a_n|^{2}$ converges, then I want to conclude that $\prod (1+a_n)$ converges to a non zero element $\iff$ the series $\sum a_n$ converges. My attempt If $\prod (1+a_n)$ converges to a non zero element then we can write $$\prod (1+a_n)= \prod \exp(\ln(1+a_n))= \exp(\sum \ln (1+a_n)) \le \exp(\sum |\ln (1+a_n)|)$$ Then using that $\sum |a_n|^{2}$ converges we can choose $n$ such that $|a_n|^2 < \frac{1}{4}$ and we know that $|ln(1+z)|\le 2 |z|$ if $|z|< \frac{1}{2}$ using the series expansion, we get that $$\exp(\sum |\ln (1+a_n)|) \le \exp(\sum 2|a_n|)$$ For the converse I want to use the result that says that if $\sum |a_n|$ converges then $\prod (1+a_n)$ converges so since we have that $\sum |a_n|^{2}$ converges then $\sum |a_n|$ converges and  $\prod (1+a_n)$ does too. Questions But from here I don't know if I am right, how to conclude and solve the converse part to say that we have a non zero limit, and another thing Can someone provide explicit examples of a sequence of complex numbers $\{a_n\}$ such that  $\sum a_n$ converges but $\prod (1+a_n)$ diverges and the other way around (This is $\prod (1+a_n)$ converges but $\sum a_n$ diverges )? Thanks a lot in advance.","['complex-analysis', 'infinite-product', 'sequences-and-series']"
1740714,Integrate 2-Form over surface,"Problem: Calculate $\int_S dx \wedge dy + dy \wedge dz$, where $S$ is the surface given by $S = \{(x,y,z) : x = z^2 +y^2 -1, x < 0\}$. Wikipedia says: Let
$$ \omega=f_{z}\, \mathrm dx \wedge \mathrm dy + f_{x}\, \mathrm dy \wedge \mathrm dz + f_{y}\, \mathrm dz  \wedge \mathrm dx $$
be a 2-form on a surface with parametrization 
$$\mathbf{x} (s,t)=( x(s,t), y(s,t), z(s,t))\!$$ defined on some domain $D.$ Then, the surface integral of the two-form on the surface $S$ is given by $$  \int_{S} \omega = \int_D \left[ f_{z} ( \mathbf{x} (s,t)) \frac{\partial(x,y)}{\partial(s,t)} + f_{x} ( \mathbf{x} (s,t))\frac{\partial(y,z)}{\partial(s,t)} + f_{y} ( \mathbf{x} (s,t))\frac{\partial(z,x)}{\partial(s,t)} \right]\, \mathrm ds\, \mathrm dt$$. I'm hoping someone can help me with the process of calculating these integrals.  I think I need to parametrize S somehow, and the do that final computation accordingly? Any help would be greatly appreciated!","['multivariable-calculus', 'surface-integrals', 'differential-forms', 'manifolds']"
1740777,the intersection of an empty family of sets; what's wrong with this proof?,"I have an exercise which says Prove $\bigcap S$ exists for all $S\neq\emptyset$. Where is the
  asssumption that $S\neq\emptyset$ used in the proof? The definition of intersection is $x\in\bigcap S\iff x\in A$ for every $A\in S$ I HAVE read some of the other discussions where it is explained that $\bigcap\emptyset$ is the set of all sets. What I want to ask about is why my ""proof"" fails, because it seems like I can say $\bigcap\emptyset$ exists, which shouldn't be the case. Something should be stopping me? Proof: My axiom schema of comprehension says that for any property $P(x)$ and for any set $A$, there exists a set $B$ such that $x\in B \iff [x\in A$ and $P(x)]$. Well given any set $S$, the union $U=\bigcup S$ exists (axiom of union). Let $P(x,S)$ be the property ""$x\in A$ for every $A\in S$"". Then there exists a set $I$ such that $x\in I\iff [x\in U\text{ and }P(x,S)]$. I've constructed a set $I$, now I just have to argue that it has the property of $\bigcap S$. If $x\in I$, then $P(x,S)$ holds, so $x\in A$ for every $A\in S$. If $x\in A$ for every $A\in S$, then $x\in A$ for some $A\in S$ (so $x\in U$). So $x\in U$ and $P(x,S) \Rightarrow$ $x\in I$. This proves $x\in I \iff x\in A$ for every $A\in S$. Therefore there exists a set satisfying the definition given above. Therefore $I=\bigcap S$ exists for any set $S$.",['elementary-set-theory']
1740786,Hilbert scheme of $n$ points on a smooth curve,"If $C$ is a smooth curve over a field $k$, then from lots of references, e.g. Janos Kollar, Rational Curves on Algebraic Varieties, exercise 1.4.1, that the Hilbert scheme of $n$ points is
\begin{equation}
\text{Hilb}^n(C)=\text{Sym}^n(C)
\end{equation}
where $\text{Sym}^n(C):=C \times \cdots \times C/S_n$. First, I do not know how to show $\text{Sym}^n(C)$ is smooth, I only know how to show $\text{Sym}^n(\mathbb{A}^1)$ is smooth. Second, how to show $\text{Sym}^n(C)$ is actually the Hilbert scheme of $n$ points?","['complex-geometry', 'algebraic-geometry']"
1740821,"Simplify $E(\max(X_1+Y_1, X_2+Y_2))$ when $X_1, Y_1, X_2$, and $Y_2$ are exponentially distributed","The time until A arrives is exponentially distributed with rate $\lambda_1$, and the time until B arrives is exponentially distributed with rate $\lambda_2$. Once they arrive, they will spend exponentially distributed times, with respective rates $\mu_1$ and $\mu_2$ before departing. What is the expected time of the last departure? (Try) I tried to Simplify $E(\max(X_1+Y_1, X_2+Y_2))$ when $X_1,Y_1,X_2$, and $Y_2$ are exponentially distributed with rate $\lambda_1$, $\mu_1$, $\lambda_2$, and $\mu_2$ respectively. Let $L$ be the time of the last departure. Let $A$ be the additional time. \begin{align*}
E(\max(X_1+Y_1, X_2+Y_2))
 = E(L)
&= E(\max(X_1,Y_1)) \\
&\hspace{2em} + E(A \mid \text{A arrives first}) P(\text{A arrives first}) \\
&\hspace{2em} + E(A \mid \text{B arrives first}) P(\text{B arrives first}).
\end{align*} I got the result of $E(\max(X_1,Y_1))$ by using calculus, but I don't know how to get the two conditional expectations: $E(A \mid \text{A arrives first})$ and $E(A \mid \text{B arrives first})$.
I need some hep. 
I'm also curious to know that is there a better way to get $E(\max(X_1+Y_1, X_2+Y_2))$.",['probability-theory']
1740893,Does every set with at least two or more elements admit a fixed-point free self-bijection?,"Assume $X$ is a set with at least two elements. Is there a bijection from $X$ to $X$ such that for every $x\in X$ , $f(x) \ne x$ ?",['elementary-set-theory']
1740925,$\lim_{y\rightarrow 0^{+}}(f(x+iy)-f(x-iy))$,"I was trying to solve this exercize.
Let $\varphi:[0,1]\rightarrow\mathbb{C}$ be a continuous function and 
$$f(z)=\int_{0}^1 \dfrac{\varphi(t)}{t-z} dt, z\in\mathbb{C}\setminus[0,1].$$ I was able to prove that $f$ is holomorphic and $$f^{(k)}(z)=k!\int_{0}^1 \dfrac{\varphi(t)}{(t-z)^{k+1}} dt$$ I want to find $$\lim_{y\rightarrow 0^{+}}(f(x+iy)-f(x-iy)),$$ for $x\in[0,1]$. I guess that the limit should be an expression of $\varphi(x)$, but apart from that I have no idea even how to start. Any ideas?",['complex-analysis']
1741002,Question about two ways to induce an inner product on $S^2V$,"$\newcommand{\til}{\tilde}$ Let $(V,g)$ be an $n$-dimensional inner product space, and let $S^2V^*$ be the symmetric algebra. I am familiar with a natural way to endow $S^2V^*$ with an inner product via $g$. In the paper The Riemannian Manifold of all Riemannian Metrics (by Gil-Medrano, Michor) a different way of endowing $S^2V^*$ with a product is described and I suspect it amounts to the same product I am familiar with. Question: Are these inner products identical (maybe up to a scalar multiple)?  (I will now describe the two approaches) Approach 1: We can think of $S^2V^*$ as the vector space of symmetric bilinear maps $V \times V \to \mathbb{R}$. As such, it is a subspace of $W:=\{T:V \times V \to \mathbb{R}| \, T \text{ is bilinear} \}  \cong V^* \otimes V^*$ (The isomorphism is canonical). The inner ptoduct $g$ induces an inner product on $V^*$ which in turn induces a product on $W$. Now $S^2V^*$ inherits the inner product from $W$. Approach 2 (from the paper): Let $B \in S^2V^*=\{T:V \times V \to \mathbb{R}| \, T \text{ is bilinear and symmetric} \}$. $B$ induces a (linear) map $T_B:V \to V^*$ via $T_B(v)(\til v)=B(v,\til v)$. If $B$ is non-degenerate then $T_B$ is invertible. (In particular this is true for $T_g$). Now, given $h,k \in S^2V^*$ , we define $\langle h,k \rangle_g =\operatorname{tr}(T_g^{-1}\circ T_h \circ T_g^{-1} \circ T_k)$ Note that $(T_g^{-1}\circ T_h \circ T_g^{-1} \circ T_k)$ is a linear map $V \to V$ so its trace is defined.","['tensor-products', 'riemannian-geometry', 'inner-products', 'differential-geometry', 'linear-algebra']"
1741005,Confusion about covariant derivative in $\mathbb R^n$,"The Levi-civita connection on $\mathbb R^n$ corresponds to the usual directional derivative. In this sense I expect the following to hold:
$$
\left(\nabla_{\partial_i}\partial_j\right)f=\partial_{ij}f.
$$
On the other hand: $\nabla_{\partial_i}\partial_j=\Gamma_{ij}^k\partial_k=0$. These results are contradictory (of course) and I'd be happy to get some clarification.",['differential-geometry']
1741081,Gelfand transform on functions,"The Gelfand transformation identifies function spaces $C_0(X)$ for locally compact Haussdorff $X$ with commutative $C^*$ Algebras. Additionally there is a statement that if $f: X \to Y$ is a proper and continuous map, this induces a $*$-morphism $f_*: C_0(Y) \to C_0(X)$ via $f_*(g) = g \circ f$. The condition that the map be proper is needed for the induced map to be well defined, for example if $X$ is not compact then a constant map $f: X \to Y$ will not send $C_0$ functions to $C_0$ functions. On the other hand the proof that $f_*(g)$ is in $C_0(X)$ if $g \in C_0(Y)$ is rather easy: if $\epsilon >0$, $K$ compact so that $g(Y-K)\subset B_\epsilon(0)$ then $f^{-1}(K)$ is compact and
$$f_*(g)(X-f^{-1}(K))=(g\circ f)(X-f^{-1}(K))\subset g(Y-K) \subset B_\epsilon(0)$$ There is another direction, given two commutative $C^*$ Algebras $A, B$ so that $A \cong C_0(X)$ and $B \cong C_0(Y)$ there is a statement that a proper $*$-morphism $\varphi: A \to B$ induces a proper continuous map $\varphi_*: Y \to X$. A $*$-morphism is called proper if it maps approximate identities to approximate identities. Can somebody tell me how this map can be constructed (and why proper-ness is needed)? Also can somebody show me an example of a non-proper $*$-morphism that isn't trivial (the zero map)?","['functional-analysis', 'c-star-algebras', 'gelfand-representation', 'banach-algebras']"
1741089,"Closed form of $\int_0^{\pi/2} \frac{\arctan^2 (\sin^2 \theta)}{\sin^2 \theta}\,d\theta$","I'm trying to evaluate the closed form of: $$I =\int_0^{\pi/2} \frac{\arctan^2 (\sin^2 \theta)}{\sin^2 \theta}\,d\theta$$ So far I've tried introducing a parameters, $\displaystyle I(a,b) = \int_0^{\pi/2} \frac{\arctan (a\sin^2 \theta)\arctan (b\sin^2 \theta)}{\sin^2 \theta}\,d\theta$ but that doesn't lead to an integral I can manage. Expanding the series for $\arctan^2 x$ leads to the sum: $$I = \frac{\pi}{2}\sum\limits_{n=0}^{\infty}\frac{(-1)^n}{(n+1)4^{2n+1}}\binom{4n+2}{2n+1}\left(\sum\limits_{k=0}^{n}\frac{1}{2k+1}\right)$$ and using $\displaystyle \int_0^1 x^{n-\frac{1}{2}}\log (1-x)\,dx = \frac{-2\log 2 + 2\sum\limits_{k=0}^{n}\dfrac{1}{2k+1}}{n+\frac{1}{2}}$ leads to an even uglier integral: $\displaystyle \Im \int_{0}^{1} \frac{1}{1+\sqrt{1-i\sqrt{x}}}\frac{\log(1-x)}{x}\,dx$ among others. I got the non-square version, which seems to have a nice closed form $\displaystyle \int_0^{\pi/2} \frac{\arctan (\sin^2 \theta)}{\sin^2 \theta}\,d\theta = \frac{\pi}{\sqrt{2}\sqrt{1+\sqrt{2}}}$ but the squared version seems difficult. Any help is appreciated. (P.S. - I'm not familiar with Hypergeometric identities, so it would be very helpful if a proof or a reference to a proof was provided, should the need arise to use them.)","['integration', 'definite-integrals', 'calculus']"
1741096,Convergence of a compound sequence,"let $a_n=\frac{1}{2}\sqrt{n}+\sum_{k=1}^n(\sqrt{k}-\sqrt{k+\frac{1}{2}})$ be a sequence.
Is this sequence convergent?","['sequences-and-series', 'calculus', 'limits']"
1741098,Geometric quantization: not understanding the curvature form and Weil's theorem,"I am reading a bit about geometric quantization. The texts that I am following are N.M.J. Woodhouse's ""Geometric Quantization"" and an article from arXiv . I am having troubles understanding the prequantization step. First, everybody cites 1958 Weil's theorem about the existence of Hermitian line bundles with prescribed curvature, but nobody provides its exact statement. Could anyone help me with it? In particular, do I prescribe just the curvature form, or a connection and its associated curvature form? Second, one tries to produce Hermitian line bundles $L$ over a symplectic manifold $(M, \omega)$ having $\omega$ as the curvature form $R$ of $L$. I'm lost: how can we relate these two forms? $R$ takes values in $\operatorname{End} _{\Bbb C} (L)$, which $\omega$ doesn't, so how can I identify them? Had $L$ been trivial, it would have been elementary, but how to do it in general? Or is this an abuse of terminology?","['quantum-mechanics', 'curvature', 'symplectic-geometry', 'vector-bundles', 'differential-geometry']"
1741119,Intuition behind Contraction Mapping Theorem,"I understand that this theorem works for complete metric spaces, but I have been studying this purely for normed vector spaces. I want to check my heuristic understanding of the theorem and proof: Statement of theorem: Let $(V, ||.||)$ be a complete normed vector space and $U \subset V$ a closed subset of the space. Let $f: U \rightarrow U$ be a contraction mapping such that $\exists K \in (0,1)$ such that $\forall u, v \in V, ||f(u) - f(v)|| \leq K||u-v||$ . Then there is a unique $w \in U$ such that $f(w) = w$ The proof constructs a sequence by taking any $u_0 \in U$ and doing $f(u_n) = u_{n+1}$. My understanding: Since $K <1$ and we are mapping each time between $U$, we are mapping a 'smaller' and 'smaller' such that eventually $f(u_n)$ will just map to itself thus reaching a fixed point. And this limit exists because this sequence $u_n$ is Cauchy and in a Banach space all Cauchy sequences will converge to some limit. My questions Why are we free to take any $u_0 \in U$? Does our choice of $u_0$ affect the convergence rate? Why is it necessarily the case that the limit is unique? And how is this affected by the map $f?$ Does the theorem still apply for $K =1?$ What applications are there to this theorem?","['functional-analysis', 'analysis']"
1741157,How to estimate a specific infinite sum,"Let $M$ be an $n$ by $n$ matrix with each diagonal element equal to $k$ and each non-diagonal element equal to $k-1$ where $n$ and $k$ are positive integers. Let $k < n$ and we can assume both $k$ and $n$ are large. What is $$S_{M,k} = \sum_{x \in \mathbb{Z}^n} e^{-x^T M x}\;?$$ Is there some way to estimate this sum? Update April 21 2016 Hajo argues below that $S_{M,k} \leq S_{M,1} = (\sum_{x=-\infty}^{\infty} e^{-x^2})^n$.  This bound may however be loose when $k \gg 1$.","['summation', 'linear-algebra', 'theta-functions']"
1741161,Covariance of a random vector,"If $Y_1,..Y_n$ are independent random variables, how do I work out cov$\begin{pmatrix}Y_1\\.\\.\\.\\Y_n \end{pmatrix}$? The covariance of the vector",['statistics']
1741188,"Alternative ""Fibonacci"" sequences and ratio convergence","So the well known Fibonacci sequence is 
$$
F=\{1,1,2,3,5,8,13,21,\ldots\}  
$$
where $f_1=f_2=1$ and $f_k=f_{k-1}+f_{k-2}$ for $k>2$.  The ratio of $f_k:f_{k-1}$ approaches the Golden Ratio the further you go:
$$\lim_{k \rightarrow \infty} \frac{f_k}{f_{k-1}} =\phi \approx 1.618$$ Let's define a class of similar sequences $F_n$ where each $f_k$ is the sum of the previous $n$ numbers, $f_k=f_{k-1} + f_{k-2} + \dots + f_{k-n}$ so that the traditional Fibonacci sequence would be $F_2$ but we can talk about alternatives such as 
$$F_3 = \{1,1,1,3,5,9,17,\dots \}$$
where we initialized the values $f_1$ through $f_3$ to be $1$ and we can show that in this case 
$$
\lim_{k \rightarrow \infty} \frac{f_k}{f_{k-1}} \approx 1.839286755
$$
The following table gives some convergences for various values of $n$:
$$
\begin{matrix}
F_n & \text{Converges to} \\ \hline
F_2 & \phi \\ 
F_3 & 1.839286755 \\
F_4 & 1.927561975 \\ 
F_5 & 1.965948237  \\
F_{6} & 1.983582843 \\
F_{10} & 1.999018626
\end{matrix}
$$
Just by inspection, it seems that the convergence values are converging toward $2$ as $n \rightarrow \infty$. So my primary question is:
What is the proof that the convergence converges to 2 (assuming it does).","['fibonacci-numbers', 'sequences-and-series']"
1741228,Integral of $\frac{1}{x\sqrt{x^2-1}}$,"I am very confused by this. I know that the derivative of $\text{arcsec}(x)$ is $\dfrac{1}{|x|\sqrt{x^2-1}}$. However, if you plug in the integral of $\dfrac{1}{x\sqrt{x^2-1}}$ into wolfram alpha it gives some other answer with an inverse tangent:
$$ \int \dfrac{1}{x\sqrt{x^2-1}}dx = - \tan^{-1}\Bigg(\frac{1}{\sqrt{x^2-1}} \Bigg) +C $$ I was just wondering why this is, or why wolfram is giving something totally different.  Are they equivalent?","['indefinite-integrals', 'integration', 'calculus', 'wolfram-alpha']"
1741264,Index of a differential operator,"Let's consider an operator $D: C^{m+n}[a, b] \rightarrow C^{m}[a, b]$, defined as $D(y(t)) = y^{(n)}+a_{n-1}y^{(n-1)}+\ldots+a_{1}y'+a_{0}$, $a_{k} \in C^{m}[a, b]$. I would like to prove that it is a Fredholm operator and evaluate its index. First, it's not so sophisticated to find the dimension of its kernel, according to the statement from ODEs theory -- any solution can be uniquely described as $C_{1}e^{\alpha_{1}t}+C_{2}e^{\alpha_{2}t}+ \ldots C_{n} e^{\alpha_{n}t}$, $\alpha_{n}$ are the roots of the characteristic polynomial, so the dimension equal $n$. What goes about dimension of cokernel -- by establishing it's precise dimension we can prove that the operator is Fredholm. Let's fix a basis $\{e^{inx} \}_{n \in \mathbb{N}}$ -- since we know that trigonometric polynomials are dence in $C^{q}[a,b]$, the exponent can be written as a linear combination of the form $P(\cos(bx), \sin(bx))$. How to find the dimension of an image? (the first step on the road to cokernel). Probably, the idea is to consider the Fouirer series of $y(t)$ with respect to the fixed basis and obtain the exact formula for the derivatives but this does not seem to be very benefitial. Are there any hints that might help? Any help would be much appreciated.","['functional-analysis', 'ordinary-differential-equations', 'operator-theory']"
1741273,How can I know the analytic continuation exists in certain cases?,"As pointed in Does the analytic continuation always exists? we know it doesn't always exist. But: take the $\Gamma$ function: the first definition everyone meet is the integral one:
$$
z\mapsto\int_{0}^{+\infty}t^{z-1}e^{-t}\,dt
$$
which defines an holomorphic function on the half plane $\{\Re z>0\}$.
Moreover we immediately get the functional equation:
$$
\Gamma(z+1)=z\Gamma(z)\;,\;\;\;\forall\; \Re z>0.
$$
This equation is used to extend the function on the whole complex plane (minus the negative integers)... but: WHY CAN WE DO THIS?! We know that there is an holomorphic function $\Gamma$ which can be expressed as the integral on that half plane. Why are we allowed to write
$$
\Gamma\left(\frac12\right)=-\frac12\Gamma\left(-\frac12\right)
$$
for example? LHS is defined, RHS, NOT!!! But where's the problem? Simply let's define $\Gamma\left(-\frac12\right)$ in such a way... but why can we do this? How can I know that this function I named $\Gamma$ which is holomorphic on the above half plane admits an extension?","['complex-analysis', 'analytic-continuation']"
1741274,Convergence of the series $\sum_{n = 1}^{+\infty}{\left(n\sin{\frac{1}{n}}\right)^n}$,"I have to study the convergence of the series $$
\sum_{n = 1}^{+\infty}{\left(n\sin{\frac{1}{n}}\right)^n}
$$ and $$
\sum_{n = 1}^{+\infty}{\left(\left(n\sin{\frac{1}{n}}\right)^n - 1\right)}.
$$ I know I should study the limit $$
\lim_{n\to +\infty}{\left(n\sin{\frac{1}{n}}\right)^n}
$$ and that $$
\lim_{n\to +\infty}{n\sin{\frac{1}{n}}} = 1
$$ but I don't see how it helps. Any ideas ? Thank you in advance !",['sequences-and-series']
1741286,Derivative of $(\lambda I - A)^{-1}$ with respect to $\lambda$,Is need to work with $\frac{d}{d\lambda} (1 - v^{T}(\lambda I - A)^{-1}u)$. Is it true that:  $$\frac{d}{d\lambda} (1 - v^{T}(\lambda I - A)^{-1}u) = -v^{T}\frac{d}{d\lambda}(\lambda I - A)^{-1}u$$ Then from $(\lambda I - A)^{-1}(\lambda I - A) = I$ differentiating both sides with respect to $\lambda$ one obtains: $$ \frac{d}{d\lambda} (\lambda I - A)^{-1} (\lambda I - A) + (\lambda I -A)^{-1} I = O$$ hence $$ \frac{d}{d\lambda}(\lambda I - A)^{-1} = - ((\lambda I - A)^{-1})^{2}$$ In general  $$ \frac{d^{k}}{d\lambda^{k}} (\lambda I - A)^{-1} = (-1)^{k} k!((\lambda I - A)^{-1})^{k+1}$$ similar to the scalar case $\frac{1}{\lambda - a}$ ?,"['matrices', 'inverse', 'derivatives']"
1741315,Confused on surface integral problem,"I am asked to evaluate $$\iint_{S} [ \nabla \phi \times \nabla \psi] \bullet n dS$$ where $\phi=(x+y+z)^2$ and $\psi=x^2-y^2+z^2$ where S is the curved surface of the hemisphere $x^2+y^2+z^2=1$ , $z \ge 0$. My attempts: I tried using that if$ \bar A= \phi \nabla \psi$ then $\nabla \times \bar A = \nabla \phi \times \nabla \psi$ So I calculated $$\phi \nabla \psi=(2x(x+y+z)^2,-2y(x+y+z)^2,2z(x+y+z)^2)$$ So essentially according to above this is what I need to integrate over S. For my normal I thought this would be obtained by writing $$G(x,y,z)=1-x^2-y^2-z^2$$ and solving for the gradient and dividing by its norm. Doing this i get that $$\hat n=\frac{(x)i+(y)j+(z)k}{x^2+y^2+z^2}$$ For the dS, I thought if it is of the form $z=f(x,y)$ then we can obtain the dS as $\sqrt{1+f_{x}^2+f_{y}^2}$ ie $dS=\frac{1}{\sqrt{x^2+y^2}}$ But I have no clue if I am on the right path. I feel like I am not confident on it. Can anyone help? Any advice would be appreciated, I have been trying for several hours with no progress","['multivariable-calculus', 'surface-integrals', 'calculus', 'vector-analysis']"
1741369,Why is the double angle formula not used in this solution?,solve $\sin 2x = 0.5$ I am looking at the answer to this question and it does not use the double angle formula to make this: $\sin 2x = 2\sin x \cos x$ And instead use $2x = \arcsin 0.5$ Why is the double angle formula not used in this situation?,['trigonometry']
1741414,Interval is homeomorphic to a circumference less a point,"Let $f:\left(-1,1\right)\longrightarrow \Bbb S$ \ $\lbrace-1\rbrace$ be a map defined by $t\mapsto e^{i\pi t}$ where $\Bbb S=\lbrace z\in\Bbb C: \|z\| = 1\rbrace$ Is $f$ an homeomorphism? I proved that $f$ is continuous function and bijective and  $f^{-1}:\Bbb S$ \ $\lbrace-1\rbrace\longrightarrow\left(-1,1\right)$ it´s $$f^{-1}\left(z\right)=f^{-1}\left(e^{i\theta}\right)=\frac{\theta}{\pi} \text{ if } \theta\in\left[0,\pi\right) \text{ or } \frac{\theta-2\pi}{\pi} \text{ if } \theta\in \left(\pi,2\pi\right)$$ Can You help me please?","['general-topology', 'real-analysis', 'analysis']"
1741423,"What's the point of ""trigonometric proofs/identities"" in introductory calculus/pre-calculus?","I remember back in high school at some point delving into worksheet after worksheet of trigonometric ""identities"", the vast majority of which are basically restatements of $\sin^2(x) + \cos^2(x) = 1$ (the remainder use variations of $\sin(x+y)$), e.g. (ignoring domain restrictions): $$\csc(x) = \frac{\sin(x)}{1+\cos(x)}+\cot(x)$$ $$\frac{1+\sin(x)}{\cos(x)}=\frac{\cos(x)}{1-\sin(x)}$$ The list seems truly never-ending, and while some of them may be pretty to look at due to symmetry, it seems very few are of practical use. I understand a few are helpful for understanding integrals which may come up in, e.g., physics::harmonic motion (e.g., the double angle formulas), but why not cross that bridge when we get to it? I must be missing something -- is there a reason why we spend such an outsized chunk of time in such beginning courses devoted to these exercises in algebraic manipulation?","['algebra-precalculus', 'trigonometry']"
1741424,"Find monotonic functions going from $0$ to $+\infty$ for $x \in (-\infty,+\infty)$ (similar to $e^x$)","How can we find functions on $\mathbb{R}$ with exponential-like properties, namely: $f(x)$ is infinitely differentiable; $f(x)$ and all its derivatives are monotonic; $f(x)$ and all its derivatives obey the following limits: $$\lim_{x \to -\infty}f(x)=0$$ $$\lim_{x \to +\infty}f(x)=+\infty$$ One such function is obviously the exponent itself ( $a,b$ - real positive constants): $$f(x)=ae^{bx}$$ Another function which seems to have these properties (I don't know how to prove it) is the 'Sophomore's function': $$s(x)=\int_0^1 u^{-u~x} du=\sum_{k=1}^{\infty} \frac{x^{k-1}}{k^k}$$ For the proof of the integral formula see this answer by Sangchul Lee. The derivatives are easy to find (both for the series and the integral formula) and they all seem to obey the above properties: How can we find other such functions? And (related) how to prove that $s(x)$ has these properties?","['special-functions', 'exponential-function', 'functions']"
1741436,Orthonormal Basis Question: Linear Algebra,"I've been staring at this proof for a long time so any suggestions would be of great help!
Prove that for any $m\times n$ matrix $A$ there is an orthonormal Basis $B =\{ v_1,\ldots,v_n\}$ of $\mathbb R^n$ such that the vectors $A v_1,\ldots,A v_n$ are orthogonal. Note that some of the vectors $A v_i$ may be zero.","['matrices', 'orthonormal', 'linear-algebra', 'proof-explanation']"
1741529,Cauchy-Schwarz inequality for dual pairing?,"Suppose we have a Hilbert space $X$ and its dual $X^*$. Given a dual pairing $$_{X^*}\langle x,y\rangle_X,$$ does there exist a sort of Cauchy-Schwarz inequality so that $|\langle x, y\rangle|\leq ||x||_{X^*}||y||_{X}$?",['functional-analysis']
1741572,Subgroups of the Semi-Direct Product $\mathbb{Z}/7\mathbb{Z} \rtimes (\mathbb{Z}/7\mathbb{Z})^{\times}$,"I want to list all the subgroups of the semi-direct product $\mathbb{Z}/7\mathbb{Z} \rtimes (\mathbb{Z}/7\mathbb{Z})^{\times}$ , under the homomorphism $\theta: (\mathbb{Z}/7\mathbb{Z})^{\times} \rightarrow \mathrm{Aut}(\mathbb{Z}/7\mathbb{Z})$ , $\theta: a \mapsto \theta_{a}$ where $\theta_{a}(i)=ai$ . Until now, I know that the subgroups of $(\mathbb{Z}/7\mathbb{Z})^{\times}$ will be of orders $1, 2, 3$ or $6$ and moreover they will be unique (similarly, the cyclic group with $7$ elements only has the trivial subgroups). I was thinking that the subgroups of the semi-direct product would be semi-direct products of the subgroups of $\mathbb{Z}/7\mathbb{Z}$ and $(\mathbb{Z}/7\mathbb{Z})^{\times}$ . Is my claim correct? If not, what would be a way to compute those subgroups?","['abstract-algebra', 'semidirect-product', 'group-theory', 'cyclic-groups']"
1741626,How to choose the point at which we want to calculate residue?,"Suppose I have to calculate the following integral using residue calculus - $$\int_ {-\infty}^{\infty} \! \frac{e^{-ix}}{x^2 + 1 } \, \mathrm{d}x. $$ Now my approach is to construct a contour in the complex plane. So I make semicircles in upper half plane and lower half plane each of radius $R$ . Now I need to calculate $$\lim_{R \rightarrow \infty} \int_ {-R}^{+R} \! \frac{e^{-iz}}{z^2 + 1 } \, \mathrm{d}z.$$
There are two poles $i$ and $-i$ of the above integrand. One is in the upper half plane and the other is in the lower half plane. Now I am supposed to calculate the residue but I am not sure whether to calculate it at $i$ or $-i$. Can someone please explain this to me? In general, What is the idea behind choosing the points at which residue needs to be calculated in case there are more than one poles?","['complex-analysis', 'definite-integrals', 'residue-calculus']"
1741664,What happens if I repeatedly alternately normalize the rows and columns of a matrix?,"Here is an algorithm: input matrix M (in-place) divide each row of M by its norm divide each column of M by its norm repeat What will M look like after this has been repeated many times?
Can we say anything about what this process does?","['matrices', 'convergence-divergence']"
1741679,Combinatorial identity / expected distance of random walk,"I am struggling to verify the following identity. $$\binom{2m}{m} \frac{m}{2} = \sum_{j=1}^m j \binom{2m}{m+j}$$ I've tried induction, but I run into issues inside the sum. I can't see a combinatorial interpretation either. I've noted the right-hand side can be rewritten as $\frac{1}{2}\sum_{j=-m}^m |j| \binom{2m}{m+j}$, but this seems more complicated. Any hints would be appreciated! Aside: my goal is actually to compute the equality in this answer (expected distance of a one-dimensional random walk). Is there a more direct way to verify this?","['combinatorics', 'binomial-coefficients']"
1741686,Imaginary exponent of Fourier transforms,"I'm reading about Fourier transforms.  I'm curious why the imaginary unit is needed in exponent.  Why not instead define it as: $$
\hat f(t)=\int_xe^{-tx}f(x) \, dx
$$ I'm looking at the proofs of some of the basic properties and I don't see why the above definition wouldn't suffice.","['functional-analysis', 'fourier-transform']"
1741696,How many integers are multiples between a specific set?,"I have a question that I have tried, but it doesn't have an answer and I can't check my work. The question is: Find out how many integers are in [100, 999] that are multiples of 2, 3, or 5. The first thing I did was subtract 999 with 100 to get 899. I denoted 2 as P, 3 as Q and 5 as R. I made this inclusion/exclusion formula to get the answer: N(P $\cup$ Q $\cup$ R) = N(P) + N(Q) + N(R) - N(P $\cap$ Q) - N(Q $\cap$ R) - N(P $\cap$ R) + N(P $\cap$ Q $\cap$ R) For P, I found there to be 449 integers that divide by 2. For Q, I found there to be 299 integers that divide by 3. For R, I found there to be 179 integers that divide by 5. Combining all of these numbers, I came up with 927. For N(P $\cap$ Q), the number I found was 149. For N(Q $\cap$ R), I found the number to be 59. For N(P $\cap$ R), I found the number to be 89. I subtracted the total of these numbers with 927 to get (927 - 297) to get 630. Did I do this correctly?","['combinatorics', 'probability', 'discrete-mathematics']"
1741812,Is there a (not so) generalized version of Hilbert's Theorem 90?,"I'm sorry if my following question doesn't make any sense. We know that if $L/k$ is a finite Galois extension then $H^{1}(\mathrm{Gal}(L/k),L^{*})=0$ (Hilbert's theorem 90). However I would like to know if there is some generalized version involving some field extension $M/L$ such that $H^{1}(\mathrm{Gal}(L/k),M^{*})=0$? Here note that $L$ and $M$ are not the same as in the usual version $H^{1}(\mathrm{Gal}(L/k),L^{*})$=0. Also I'm assuming that $M$ is already a $\mathrm{Gal}(L/k)$-module. (Edit: If $M/k$ is a Galois extension and $\sigma\in{\mathrm{Gal}(L/k)}$, then choose an automorphism $\tilde{\sigma}:M\rightarrow{M}$ extending $\sigma$ and define $\sigma\cdot{m}:=\tilde{\sigma}(m)$ for all $m\in{M}$. This could give $M$ a structure of $\mathrm{Gal}(L/k)$-module but I'm not sure!) The motivation of this question is a proof regarding divisors on a smooth curve that I'm trying to understand. In that proof the author says that he will use a generalized version of Hilbert's theorem 90 but he doesn't say what version is. The context is a smooth curve $C/k$ with a generic point $\xi$, a finite Galois extension $L/k$ and a 1-cocycle $f:\mathrm{Gal}(L/k)\rightarrow{L(\xi)^{*}}$ and then the author says ""by a generalization of Hilbert's theorem 90 this 1-cocycle is a 1-coboundary"", so I'm assuming that the version is something like $H^{1}(\mathrm{Gal}(L/k),L(\xi)^{*})=0$ (whereas the usual version only implies $H^{1}(\mathrm{Gal}(L/k),L^{*})=0$). Could anyone tell me what this generalization could be? I know that there is a generalization involving étale cohomology but I don't think it should be that complicated. Any help is appreciated.","['algebraic-geometry', 'abstract-algebra', 'number-theory', 'field-theory', 'galois-cohomology']"
1741820,Axioms of Geometry?,"I have taken the generic low level undergraduate classes, such as Calculus 1-3, Differential Equations, and Linear algebra. Since I never learned Geometry past a basic high school level, I thought it would be cool for me to start from the axioms of Euclidean Geometry and try to prove/discover some geometry on my own. I did a little googling and found Euclid's $5$ postulates. However, other sources were talking about the existence additional axioms/postulates, such as the transitive property of equality, the partition axiom, etc. My question is, where is a good place for me to start? Should I just start with Euclid's $5$ postulates and assume the common rules I know from algebra (commutative property, etc.)? Are there more of these smaller axioms/postulates that are not generally talked about in ""normal"" math classes (calculus, etc.) that I should know about?","['axioms', 'euclidean-geometry', 'soft-question', 'axiomatic-geometry', 'geometry']"
1741853,Equality in generalized triangle inequality,"The problem is to show that if $z_1,\dots,z_n$ are complex numbers then  $$|z_1+\cdots+z_n|=\sum |z_i|$$ if and only if $$\mbox{arg}(z_i)\equiv \mbox{arg}(z_j)\mod 2\pi$$ for all $i,j$. I can establish the case $n=2$. I thought of using induction to prove the general case but didn't get anywhere. Following the hint in this question I tried proceeding as follows: Assume $|z_1+\cdots+z_n|=\sum |z_i|$. Squaring both sides yields $\sum_{i\ne j}z_i\overline{z_j}=\sum_{i\ne j}|z_i||z_j|$. Since all $z_i\ne 0$ for otherwise we may use induction so we have 
$$\frac{\sum_{i\ne j}z_i\overline{z_j}}{\sum_{i\ne j}{|z_i||z_j|}}=1.$$ At this point I cannot think of anything else to do.","['complex-analysis', 'complex-numbers']"
1741859,Solve $\cos 2x - 3\sin x - 1 = 0$ using addition formula,"Solve $\cos 2x - 3\sin x - 1 = 0, \quad 0^{\circ} \le x \le 360^{\circ}$ \begin{align} \cos 2x - 3\sin x - 1 = 0
 &\iff 1 - 2\sin^2 x - 3\sin x - 1 = 0 \\
 &\iff- 2\sin^2 x - 3\sin x = 0 \\
 &\iff2\sin^2 x + 3\sin x =0\\
 &\iff\sin x(2\sin x + 3) =0 \\
 &\iff\sin x = 0 \lor  2 \sin x + 3= 0
\end{align}
I could go on but the book gives the answer, $0^{\circ}, 180^{\circ}, 360^{\circ}$ and I am mystified as to where these answers have come from.",['trigonometry']
1741885,Does a tensor field acting on vector fields and covector fields give a function?,"If I have a $(p,q)$ tensor field that acts on $p$ covector fields and $q$ vector fields then does $T\left(X_1,\dots,X_p,Y_1,\dots,Y_q\right)$ return a function $f$ defined on the manifold by $$f\left(x\right)=T_x\left(X_1\left(x\right),\dots,X_p\left(x\right),Y_1\left(x\right),\dots,Y_q\left(x\right)\right)?$$ $T_x$ is now a $\left(p,q\right)$ tensor and $X_i\left(x\right)$ and $Y_j\left(x\right)$ are now covectors and tangent vectors respectively so this seems to make sense.","['manifolds', 'tensors', 'differential-geometry']"
1741891,Index of a derivative operator on a circle,"Let $D: C^{1}(S^{1}) \rightarrow C(S^{1})$ be an operator defined as $D(f)=f'$. I would like to find its index (on the road proving that it's a Fredholm operator). First, if $f \in ker(D)$, then $f$ is constant almost everywhere on a circle. What goes about cokernel, its dimension equal the dimension of a kernel of an adjoint operator, by Riez-Markov-Kakutani theorem, the adjoint is $T(f(x)) = \int_{S^{1}}{f'(x) \mu(dx))}$, $\mu$ is some Radon measure. The claim is that the index equals 0, the both the $ker(D)$ and $ker(D^{*})$ have the same dimension. It's clear that $ker(D) \subset ker(D^{*})$, but also it is true that there is no inverse inclusion -- but still this does not affect the dimension property. Probably, the idea is to use the Fourier expansion on the cirlce, $$f(x) = \sum_{n \in \mathbb{Z}}{c_{n} e^{inz}}$$ then $$f'(x) = \sum_{n \in \mathbb{Z}}{in c_{n} e^{inz}}$$ but this no seems to be very benefitial so far. What are the possible approaches to pose the problem? Any sort of help would be much appreciated.","['functional-analysis', 'fourier-series', 'operator-theory']"
1741898,Forcing Bijectivity,"I'm working out of the Nakahara text in mathematical physics, and I'm presented with a map $f: \mathbb{R} \rightarrow \mathbb{R}$ defined by $ f:x \mapsto \sin(x) $, and told that it is neither injective nor surjective, and to restrict the domain and range to make the mapping bijective. Redfining the map in more general terms: $$ X,Y \subseteq  \mathbb{R} \,\, | \,\, f: X \rightarrow Y $$ I first sought to investigate how this mapping fails to be injective. Knowing the definition of injectivity, I immediately see that there exists more than one possible inverse value for every value of the range. In other words, I can draw a line of constant $y$ on the graph of this function and strike the function more than one time, and in fact infinitely many times as $x$ is allowed to run to infinity. This leads me to believe I need to put a restriction involving the periodicity of $\sin(x)$ on the domain for sure. Secondly, I checked how the mapping fails to be surjective. I know the domain runs from negative infinity to infinity, whereas the range only runs from $-1$ to $1$. Surjectivity requires that for every $ y \in Y $, there exists at least one $ x \in X$ such that $ f(x) = y$. If $ Y$ is the entire real line and the range of $f$ is $[-1,1]$, then any $y$ outside of that interval will fail to have an inverse image, which contradicts surjectivity.(?) To achieve injectivity, I considered the fact that $sin(x)$ is periodic, with a first maximum at $\frac{\pi}{2}$. Immediately after that, we start seeing repeated $y$ values for different $x$ values. I also noticed that we can extend this towards negative $x$ out to the same value. For surjectivity, and thus bijectivity, I noted that we need every value in both the domain and range to be utilized in the mapping. We explicitly have the required range. Using the aforementioned reasoning, I conclude that the mapping with restrictions should look like this: $$ X = [-\frac{\pi}{2},\frac{\pi}{2}] \,\, , \,\, Y = [-1,1]$$ $$ f: X \rightarrow Y \,\, | \,\, f: x \mapsto \sin(x) $$ Is all that rationale provided above sufficient to make this map bijective?","['trigonometry', 'functions', 'proof-verification']"
1741901,"If $x+y+z=0$, prove that $\frac{x^2}{2x^2+yz}+\frac{y^2}{2y^2+zx}+\frac{z^2}{2z^2+xy}=1$","A problem in my homework had asked me: When $x+y+z=0$, evaluate$$\frac{x^2}{2x^2+yz}+\frac{y^2}{2y^2+zx}+\frac{z^2}{2z^2+xy}$$ Without too much difficulty, one can see that the value should be $1$ using $(x,y,z)=(1,0,-1)$. I decided to use $x=-y-z$, which turned out not to be as difficult as initially thought.  However, would someone care to enlighten me to some other methods of doing this?","['algebra-precalculus', 'fractions']"
1741918,Why does equating one of the brackets in $(x+1)(x+3)=0$ to zero valid?,"When we want to solve an equation like the one given above, we set either $(x+1)$ or $(x+3)$ equal to $0$ to get $x = -1$ or $x = -3$. However, when we put one of those values in the equation, what we end up doing is multiplying the LHS by zero. How is that a valid operation?",['algebra-precalculus']
1741923,Dense Subspaces: Intersection,"Hilbert Space: $\mathcal{H}$ Dense Subspaces:
$$\mathcal{D},\mathcal{D}'\leq\mathcal{H}:\quad\overline{\mathcal{D}},\overline{\mathcal{D}'}=\mathcal{H}\not\Rightarrow\mathcal{D}\cap\mathcal{D}'\neq\{0\}$$ (Counterexample?)","['functional-analysis', 'hilbert-spaces']"
1741924,Solve the equation $\sqrt{1-x}=2x^2-1+2x\sqrt{1-x^2}$,Solve the following equation: $\sqrt{1-x}=2x^2-1+2x\sqrt{1-x^2}$ Unfortunately I have no idea.,['algebra-precalculus']
1741965,Ring with spectrum homeomorphic to a given topological space,"I would like to ask whether given a topological space $X$, we can find a commutative ring with unity $R$ such that $\operatorname{Spec} R$ (together with the Zariski topology) is homeomorphic to $X$. Since the spectrum is a compact space, this is obviously only possible if $X$ is compact. Furthermore, from this answer we obtain that for spectra, $T_1$ already implies Hausdorff. How many more restrictions must we impose? Can we give a characterisation of when a topological space is a spectrum of a ring?","['zariski-topology', 'general-topology', 'commutative-algebra']"
1741986,Computing dimension of a smooth scheme,I'm having trouble finding enough reference to show the following seemingly true statement. Let $K$ be a local field with ring of integer $\mathcal{O}_K$. Assume that $X$ is a smooth $\mathcal{O}_K$-scheme such that $X_K$ has dimension $n$. Then $X$ has dimension $n+1$. Could someone point me to some references to general statements that leads to this result ?,"['krull-dimension', 'algebraic-geometry']"
1742085,"Proof verification: $\frac{d(\nu_1\times \nu_2)}{d(\nu_1 \times \nu_2)}(x_1,x_2)=\frac{d\nu_1}{d\mu_1)}(x_1)\frac{d\nu_2}{d\mu_2}(x_2).$","This is exercise 3.12 from Folland's Real Analysis. It took me a long times to come up with a solution to this problem, and I'd appreciate it if anyone could verify if my answer is correct. For $j=1,2,$ let $\mu_j, \nu_j$ be $\sigma$-finite measures on $(X_j,\mathcal{M}_j)$ such that $\nu_j \ll \nu_j$. Then $\nu_1 \times \nu_2 \ll \mu_1 \times \mu_2$ and $$\frac{d(\nu_1\times \nu_2)}{d(\mu_1 \times \mu_2)}(x_1,x_2)=\frac{d\nu_1}{d\mu_1}(x_1)\frac{d\nu_2}{d\mu_2}(x_2).$$ The theorems I used from the text are captured at the bottom. Proof: First, assume that $\mu_1 \times \mu_2(E)=0.$ Then $\mu_1 \times \mu_2 (E)=\int \mu_1(E^{x_2})d\mu_2=0$. So $\mu_1(E^{x_2})=0$ $\mu_2$-a.e. Since $\nu_1 \ll \mu_1$, for a.e. on $X_2$, $\nu_1(E^{x_2})=0$, and hence $\nu_1 \times \nu_2 (E)=\int \nu_1(E^{x_2})d\nu_2=0$, which shows that $\nu_1 \times \nu_2 \ll \mu_1 \times \mu_2$. To prove the second part, by definition of the Radon-Nikodym derivative and its a.e.-uniqueness, it will suffice to show that for all $E \in \mathcal{M}\otimes \mathcal{N}$, we have $$\int_E \frac{d(\nu_1\times \nu_2)}{d(\mu_1 \times \mu_2)}d(\mu_1 \times \mu_2)=\nu_1 \times \nu_2 (E)=\int_E \frac{d\nu_1}{d\mu_1}(x_1)\frac{d\nu_2}{d\mu_2}(x_2)d(\mu_1 \times \mu_2).$$ To show this I need to use the Tonelli's theorem restricted on a measurable set. Namely, $\int_E f d(\mu \times \nu)=\int f\chi_E d(\mu \times \nu)=\int [\int f_x \chi_{E_x}d\nu]d\mu=\int[\int_{E_x} f_x d\nu] d\mu$. (I believe this is correct and my proof hinges on it, so tell me if it's wrong). Finally, we have $\nu_1 \times \nu_2(E)=\int \nu_2(E_{x_1})d\nu_1=\int \nu_2(E_{x_1})\frac{d\nu_1}{d\mu_1} d\mu_1=\int \int_{E_{x_1}}\frac{d\nu_2}{d\mu_2}d\mu_2 \frac{d\nu_1}{d\mu_1} d\mu_1 $. where the third equality follows from Prop 3.9(a) and the last equality follows from the definition of $d\nu_2/d\mu_2$. Also, $\int_E \frac{d\nu_1}{d\mu_1}(x_1)\frac{d\nu_2}{d\mu_2}(x_2) d(\mu_1 \times \mu_2)=\int \int_{E_{x_1}}\frac{d\nu_1}{d\mu_1}(x_1)\frac{d\nu_2}{d\mu_2}(x_2) d\mu_2(x_2) d\mu_1(x_1) $, from the Tonelli's theorem I've derived above. Now we have the desired equality and so the two derivatives are equal a.e. The problem doesn't state the equality in terms of a.e., but I believe it is just omitted. I'd appreciate any comments on this.","['derivatives', 'real-analysis', 'proof-verification', 'measure-theory', 'analysis']"
1742096,costruction of brownian motion on sphere?,"i am trying to construct a brownian motion on the sphere using the method given in Price and williams paper.$\partial$ represents the SDE of stratonovich type which is converted to ito form in last expression   $$\partial X=n(X) \times   \partial B $$ where the $\times$ is a vector product and $n(X)$ is a unit normal vector on the surface the 
 $$n(X)=\begin{pmatrix} -\cos(\theta)\cos(\phi) &&0&&0 \\ 0&& \sin(\theta)\sin(\phi) && 0\\0&& 0&& -\cos(\phi)\end {pmatrix}$$ equation that i formed is $$\partial \begin{pmatrix}\cos(\theta)\sin(\phi)\\\sin(\theta)\sin(\phi)\\\cos (\phi)\end{pmatrix} =\begin{pmatrix} -\cos(\theta)\cos(\phi) &&0&&0 \\ 0&& \sin(\theta)\sin(\phi) && 0\\0&& 0&& -\cos(\phi)\end {pmatrix}\times \begin {pmatrix} \partial B_1\\\partial B_2\\\partial B_3\end {pmatrix}$$
and subsequently changing the equation back to ito form i get $$d\phi=\cot(\phi)dB_3+\frac{1}{2}dt $$
but the result in the book is given by $$d\phi=dB_3+\frac{1}{2}\cot(\phi) dt $$ i cant find where i am wrong please help the text i am referring is this","['stochastic-calculus', 'differential-geometry', 'stochastic-differential-equations']"
1742137,Lebesgue measure 0 set which is not Borel,"Let $A$ be an uncountable Borel subset of $\mathbb{R}^n$, and consider the Lebesgue measure on $\mathbb{R}^n$.
Assume the axiom of choice (if you need it). Does there exist a Lebesgue measurable set $B \subset A$, which has zero Lebesgue measure and is not Borel? I have no idea of the answer. I know Lebsegue measure theory, and more generally, abstract measure theory, but not the the theory of Polish spaces and analytic sets (the so called descriptive set theory, which could be the key to answer the question). Any help is welcome.","['real-analysis', 'lebesgue-measure', 'measure-theory', 'analysis']"
1742138,Set measurable with respect to one product measure but not with respect to another,"For $p \in (0,1)$, let $\mu_p$ be the measure on $\{0,1\}$ given by $\mu_p(\{1\}) = 1 - \mu_p(\{0\}) = p$. We can extend $\mu_p$ to a product measure on the countably infinite product $\{0,1\}^\omega$, which we also denote by $\mu_p$. Is there a subset of $\{0,1\}^\omega$ which is measurable with respect to $\mu_p$ but not with respect to $\mu_q$, for some $p,q \in (0,1)$? And a follow up question, in case the answer to the preceding question is affirmative: Which subsets of $\{0,1\}^\omega$ are measurable with respect to all $\mu_p$ measures?","['probability-theory', 'measure-theory']"
1742147,Deriving the round metric,"I want to derive the round metric $g=d\theta^{\,2}+\sin\left(\theta\right)^2d\phi^{\,2}$ but I cannot get the correct answer. I know that the metric in cartesian coordinates is $g=dx^2+dy^2$. I've used the formula $dx=\frac{dx}{d\theta}d\theta+\frac{dx}{d\phi}d\phi$ and $dy=\frac{dy}{d\theta}d\theta+\frac{dy}{d\phi}d\phi$. From $x=\sin\left(\theta\right)\cos\left(\phi\right)$ and $y=\sin\left(\theta\right)\sin\left(\phi\right)$, I find that $\frac{dx}{d\theta}=\cos\left(\theta\right)\cos\left(\phi\right)$, $\frac{dx}{d\phi}=-\sin\left(\theta\right)\sin\left(\phi\right)$, $\frac{dy}{d\theta}=\cos\left(\theta\right)\sin\left(\phi\right)$, $\frac{dy}{d\phi}=\sin\left(\theta\right)\cos\left(\phi\right)$. This leads to $g=dx^2+dy^2=\cos\left(\theta\right)^2d\theta^{\,2}+\sin\left(\theta\right)^2d\phi^{\,2}$ which is not correct. edit: metric was typed incorrectly",['differential-geometry']
1742150,Probability of three dice falling in the same quadrant of a box,"This is surely really basic for most people here but it's tripping me up. You get a box and draw lines to split it up into 4 parts. 
I got asked what the probability was that when rolling three dice, all three dices would end up in the same quadrant. My first take on this was a 1/4 chance of die 1 in quadrant x a 1/4 chance of die 2 in same quadrant x a 1/4 chance of die 3 in same quadrant x
=> 1/4*1/4*1/4 = 1/64 chance My second take on this was that the first die doesn't matter at all so all that's left is a 1/4 chance of die 2 in same quadrant a 1/4 chance of die 3 in same quadrant
=> 1/4*1/4 = 1/16 chance But I have been given a solution where all possible combinations are drawn out and as there are 20 possible combinations, the odds are 1/20. What is correct (if any) and why ?","['combinatorics', 'probability', 'dice']"
