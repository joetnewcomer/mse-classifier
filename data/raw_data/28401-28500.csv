question_id,title,body,tags
263876,Bound on the number of p-groups for fixed exponent,"It's well-known that for each prime number $p$ there are exactly two groups of order $p^2$, five of order $p^3$, and fifteen of order $p^4$ (at least when $p>3$). I know that the classification of $p$-groups gets much harder for higher exponents. But I wonder if $p$-groups with higher dimensions are still structured enough that they would at least theoretically allow a classification. In particular: Is there, for every natural $n$, a prime $p_0(n)$ and a number $m(n)$ such that for every $p \ge p_0(n)$ the number of groups of order $p^n$ equals $m(n)$? (For example, $m(2)=2,m(3)=5,m(4)=15$ for $p_0(2)=p_0(3)=2$ $p_0(4)=5$.)","['finite-groups', 'group-theory', 'p-groups']"
263879,Why does the set $\{ x \in \mathbb{Q} \mid x^2 \le 5\}$ not have a greatest element?,"I have just learned what the definition is of a supremum, and I am confused to something my textbooks says: Subsets with a supremum don't have to have a greatest element, for example: $$(0,3):  = \{x \in \mathbb{R} \mid 0 < x < 3\}$$ and $$\{ x \in \mathbb{Q} \mid x^2 \le 5\}$$ I understand the first example since we know that the supremum is $3$ but the subset doesn't have a greatest element since it must be less than $3$ . I however do not understand the second one. If we solve $x^2 \le 5$ I believe we get $-\sqrt{5} \le x \le \sqrt{5}$ . Wouldn't this mean that $\sqrt{5}$ is the greatest element in this subset?","['algebra-precalculus', 'elementary-set-theory', 'supremum-and-infimum', 'maxima-minima']"
263885,Constructions of the smallest nonabelian group of odd order,"I write $|X|$ for the number of elements in a finite set $X$ .  Recall some basic facts: If $p$ is a prime number, then any group $G$ of order $p^2$ is abelian. Sketch of proof: Fix a prime $p$ and such a group $G$ .  The center $Z(G)$ of $G$ must be nontrivial by the class equation, and hence have order $p$ or $p^2$ .  So $G/Z(G)$ has order $p$ or $1$ .  So $G/Z(G)$ is cyclic.  So $G$ is abelian. If $p < q$ are prime numbers, then there is a nonabelian group of order $pq$ if and only if $q \equiv 1 \pmod{p}$ , and in this case there is only one such nonabelian group (up to isomorphism). Sketch of proof: Fix primes $p < q$ and a group $G$ of order $pq$ .  Use Sylow theory to conclude that $G$ has a unique (and hence normal) subgroup $H_q$ of order $q$ , and a subgroup $H_p$ of order $p$ , and use elementary observations to verify that $H_q \cap H_p = \{1\}$ and $G = H_q H_p$ so that $G$ is some semidirect product $H_q \rtimes H_p$ .  Since $H_q$ is cyclic, $|\operatorname{Aut}(H_q)| = q-1$ , and so when $q \not\equiv 1 \pmod{p}$ , Lagrange's theorem shows that there are no nontrivial homomorphisms $H_p \to \operatorname{Aut}(H_q)$ , implying that $G$ is abelian in this case.  When $q = 1 \pmod{p}$ , the existence of a nontrivial homomorphisms $H_p \to \operatorname{Aut}(H_q)$ and the independence of the structure of the resulting semidirect product on the choice of nontrivial homomorphism are discussed in this math.SE post . Together, these facts imply: There are no nonabelian groups of odd order less than $21$ . (The only odd numbers less than $21$ besides $1$ and primes to worry about are $9$ and $15$ , which are covered by the above general results.) There is a unique nonabelian group of order $21$ , and it can be realized by choosing any nontrivial homomorphism $\mathbb{Z}/3\mathbb{Z} \to \operatorname{Aut}(\mathbb{Z}/7\mathbb{Z})$ and forming the corresponding semidirect product.  For example (taken from the above math.SE post), one could use the unique homomorphism sending $1$ to ""multiplication by $2$ "".) Now for my slightly subjective question: Are there ""less technical"" or ""more insightful"" constructions of the nonabelian group of order $21$ ? To be clearer about my kind of fuzzy requirements: I don't care if a construction doesn't shed any light on the nonexistence of nonabelian groups of smaller order. I do want it to be possible to define the group, and see that it is nonabelian, and of order 21, without drawing on too much group theoretical machinery. Ideally, the construction should minimize computation.  One could, for example, exhibit two permutations of a small finite set that generate the group--- but verifying that the group they generate has 21 elements and is nonabelian is entirely computational.  And even if the computations are well organized, this approach gives little idea of where such a group might ""come from"".  (If a specific presentation came with a geometrical insight making clear why the resulting group would have order $21$ without computation, that would be awesome.) To explain the motivation behind my question: I was teaching algebra, and was asked in office hours if nonabelian groups of odd order even existed .  ""Of course they do,"" I said.  Then I realized that it was rather difficult to exhibit one, given where we were in the class.  We had the basic homomorphism theorems, but: We hadn't done the Sylow theorems or semidirect products. We didn't know about finite fields yet. All of the members of the ""families of groups"" we had discussed up to that point--- symmetric groups, alternating groups, dihedral groups--- when nonabelian, have even order. All nonabelian groups of order less than $21$ , whether or not they into the families just mentioned, have even order. FWIW: the ""most elementary"" example of a small nonabelian group of odd order that I can think of is the set of all $3 \times 3$ matrices with entries in the field with $3$ elements that are both (a) upper triangular and (b) have all $1$ s down the diagonal.  (This is pretty clearly a nonabelian group, and just as clearly has $27$ elements.)  This happens to be the next smallest nonabelian group of odd order.","['finite-groups', 'group-theory']"
263888,Proving $\phi$ is essentially bounded,"This is one of the past qual question. Suppose $\phi$ is a real valued measurable function on $\mathbb{R}$ such that, for any $f$ in $L^{1} (\mathbb{R})$, the product $f\phi$ is also in $L^{1} (\mathbb{R})$. To prove $\phi$ is essentially bounded. Seriously, I do not know where to start. I kind of thought approaching the problem by contradiction.  It seem I am going nowhere from there.","['measure-theory', 'real-analysis']"
263890,definit integral of Airy function [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question How can I evaluate this definite integral $$ \int_0^\infty \frac{\operatorname{Ai}^2(z+a_n)}{z^2}dz $$
where $a_n$ are the zeroes of the Airy function.","['definite-integrals', 'airy-functions', 'integration']"
263897,Kosniowski's exercise,"I'm having troubles solving the following exercise, proposed in Kosniowski's ""A first course in Algebraic Topology"", and any help would be appreciated! Consider the topological space $X:=(\mathbb{R}, \mathcal{T})$, where $\mathcal{T}=\{\emptyset\}\cup \{\mathbb{R}\} \cup \{(-\infty, t):t \in \mathbb{R}\}$. Prove that a function $f: X \to X$ is continuous if and only if it is non-decreasing (that is, if $x > x'$, then $f(x)\ge f(x')$) and continuous on the right (that is, $\forall x \in \mathbb{R}$ and all $\epsilon > 0$ there exists $\delta > 0$ such that if $x' \in [x, x + \delta)$, then $|f(x) - f(x')| < \epsilon$).",['general-topology']
263908,"When to create transcendental function to solve ""unsolvable problem""?","$\int \frac{1}{x} dx$ is an unsolvable problem using standard laws of Calculus (power rule) without the use of the function $f(x) = \ln x$ which was handcrafted by mathematicians to solve such problems. If we go back even further, the function $f(x) = \sin x$ was also a transcendental function used to describe the changing relationship between the arc and chord of a circle - it was not until 1682 that Leibniz proved that $\sin x$ was indeed not expressible as an algebraic function. Today, we still have expressions that can't be evaluated precisely such as $\int x^x dx$ because it cannot really be expressed as a function using the standard toolkit of algebraic and transcendental functions that we currently have. This begs the question, when is it appropriate for mathematicians to come up with new transcendental functions as solutions to ""unsolvable problems"" including but certainly not limited to the integral expression presented above?","['soft-question', 'calculus', 'functions']"
263911,Calculation of the total curvature of Jordan curves,"I am looking for direct proofs that the total curvature $\int_0^{L_\gamma} \! \gamma''(s) \, \mathrm{d} s$ of any Jordan curve $\gamma$ resp. $\int_0^{L_\gamma} \! |\gamma''(s)| \, \mathrm{d} s$ of a convex Jordan curve equals $2\pi$. Direct proof means: a calculation and not a special case of the theorem of Gauss-Bonnet or of I have no idea even how to show that the integral $$\int_0^1 \frac{\mathrm{d} x}{(1-(1-b^2)x^2)^{3/2}}$$ evaluates to $\frac{1}{b}$ which would prove the above at least for ellipses with major axis $a=1$ and minor axis $b$. Let alone for arbitrary (convex) curves/functions.",['differential-geometry']
263914,What is the formula for this curve?,"Three years of calculus in college have served me nothing, apparently, since I can't for the life of me remember even the basics. I'm working on a small software project where I have a table with say 20 cells, and I want the cells' opacity to go down as the index goes up. Currently, I'm doing it linearly with $\textrm{opacity} = 1 - (\textrm{index}/20)$, or $y = 1-x$. The curve I'm going for is something where at the beginning I have a high value for the opacity, 1, but then it starts dropping like a roller-coaster, non-linearly. The best I can describe it is it looks like half of a 'C' draw on the positive xy axis. The closest I got was $y =  e^x$ , but that plot goes up. Can anyone tell me the name of what I'm looking for? Edit: Ok it turns out what I'm looking for is a hyperbola, $y = 1/x$. However, since this is a opacity value, the range needs to be from $0$ to $1$, while the domain is also $0$ to $1$. But I'm getting some large values for small inputs.",['algebra-precalculus']
263926,Proving $f$ is Absolutely Continuous,"Let $\{f_{n}\}_{n}$ be a sequence of absolutely continuous function defined on $[0,1]$ such that $f_{n}(0)=0$ for all $n$. Assume that the sequence of derivatives $\{f_{n}^{`}\}_{n}$ is Cauchy in $L_{1}[0,1]$. Prove that the $\{f_{n}\}_{n}$ converges uniformly to a function $f$, and that $f$ is absolutely continuous in $[0,1]$. Seriously, I have no idea where to start. This is one of the past qual question. Any help will be much appreciated.","['measure-theory', 'real-analysis']"
263930,Draw graph of $\frac{1}{f(x)}$ from graph of $f(x)$,"If I know the graph of $f(x)$, how do I draw the graph of $\frac{1}{f(x)}$?","['graphing-functions', 'functions']"
263942,Linear Algebra munkres analysis on manifolds question.,"If $A$ is an $n$ by $m$ matrix and $B$ is an $m$ by $p$ matrix, then $$ |AB| \leq m|A||B|$$
where $|A| = \max\{|a_{ij}| : i = 1,\ldots,n \text{ and} j = 1,\ldots,m\}$ Attempt: $ |AB| = \max\{| \sum_{j=1}^{m}a_{ij}b_{jk} |: i = 1,\ldots,n \text{ and } k = 1,\ldots,p\} \leq \max\{ \sum_{j=1}^{m}|a_{ij}b_{jk}| : i = 1,\ldots,n \text{ and } k = 1,\ldots,p\}  \leq m\max\{|a_ij|\}\max\{|b_{jk}|\} = m|A||B| $ Is this correct?","['matrices', 'normed-spaces', 'linear-algebra']"
263945,"Number of acyclic digraphs on $[n]$ with $k$ edges and each indegree, outdegree $\leq 1$","How many (labelled) acyclic digraphs are there on the vertex set $[n]$ with exactly $k$ edges and each indegree, outdegree $\leq 1$?  The answer is $${n \choose k} {n-1 \choose k} k!.$$  Is there a bijective proof?  I imagine the ${ n \choose k}$ would represent choosing the set of vertices that have outdegree one, and the $k!$ could represent putting an ordering or cycle structure on these vertices, but I'm not sure what the other factor might represent.","['graph-theory', 'binomial-coefficients', 'combinatorics']"
263950,"Centralizer, Normalizer and Stabilizer - intuition",What is the motivation/intuition behind these concepts? What notion/property of a group do they capture? Or what is the scenario of application. Thanks.,"['intuition', 'group-theory', 'abstract-algebra']"
263954,why do successive eigenfunctions have more oscillation?,"I was told the following argument as to why successive eigenfunctions tend to
have more oscillations: Suppose (without worrying about why) that the first eigenfunction has the least oscillation. The second eigenfunction is orthogonal to the first, thus it must have both positive and negative parts on the region where the 1st eigenfunction is positive, and similarly for the     region corresponding to the negative part of the 1st eigenfunction (if any). Thus each eigenfunction has more oscillations than the previous. Although I certainly believe the conclusion is true, I do not quite see that
this is a solid argument. Suppose the first eigenfunction is $\sin(x)$.
Then the second eigenfunction can be $-\sin(x)$, which is orthogonal to the first.
So, one can find an orthogonal function without using step 2 in the argument,
so (to me) the argument fails.  [Edit: a big error here-- I don't know how I was thinking that sin, -sin are orthogonal, they certainly are not] Is there a better intuitive argument for ``successive eigenfunctions have 
more oscillation''? (Or, point out the flaw in my thinking or description)","['eigenvalues-eigenvectors', 'functional-analysis']"
263957,Why is the identity the only symmetric $0$-$1$ matrix with all eigenvalues positive?,"While thinking about this question I managed to convince myself that the identity is the only symmetric $0$-$1$ matrix with all eigenvalues positive.  However, the argument is rather low-level.  It does not give much insight into why, out of all symmetric matrices, $0$-$1$ matrices, and matrices with all eigenvalues positive, the identity is the only matrix that simultaneously has all three properties. So my question is Can someone give an intuitive explanation for why the identity is the only symmetric $0$-$1$ matrix with all eigenvalues positive? Such an explanation might entail a bigger-picture argument than the one I came up with. For reference, here's my argument.  Let $A$ be a symmetric $0$-$1$ matrix with all eigenvalues positive. Symmetric and all eigenvalues positive implies $A$ is positive definite. $A$ must have all $1$'s on its diagonal.  This is because $a_{jj} = 0 \implies {\bf e}_j^T A {\bf e}_j = 0$, which contradicts positive definite. $A$ must have all $0$'s for its off-diagonal elements.  This is because $A$ is symmetric implies $a_{ij} = a_{ji}$, and $a_{ij} = a_{ji} = 1 \implies ({\bf e}_i - {\bf e}_j)^T A ({\bf e}_i - {\bf e}_j) = 0$, which contradicts positive definite. Thus $A$ is the identity. For clarification : I am looking for an answer along these lines: ""A symmetric matrix implies or is equivalent to $X$ about the underlying linear transformation.  A $0$-$1$ matrix implies or is equivalent to $Y$ about the underlying linear transformation.  All eigenvalues positive implies or is equivalent to $Z$ about the underlying linear transformation.  ($X$, $Y$, and $Z$ are all big-picture properties.)  [Insert argument here.]  Thus the only matrix that simultaneously satisfies $X$, $Y$, and $Z$ is the identity."" Robert Israel's answer, while nice, is not the kind of thing I'm hoping for.  I view it as a more elegant version of my own low-level argument about what form the entries of the matrix have to take, not what kind of linear transformation has these three properties.","['matrices', 'linear-algebra']"
263961,Applications of model theory to analysis,"Some of the more organic theories considered in model theory (other than set theory, which, from what I've seen, seems to be quite distinct from ""mainstream"" model theory) are those which arise from algebraic structures (theories of abstract groups, rings, fields) and real and complex analysis (theories of expansions of real and complex fields, and sometimes both). While relationships with algebra seem quite apparent, I wonder what are some interesting results in real and complex analysis that have nice model-theoretical proofs (or better yet, only model-theoretical proofs are known!)? Of course, there's nonstandard analysis, but I hope to see some different examples. That said, I wouldn't mind seeing a particularly interesting application of nonstandard analysis. :) I hope the question is at least a little interesting. I have only the very basic knowledge of model theory of that type (and the same applies to nonstandard analysis), so it may seem a little naive, but I got curious, hence the question.","['applications', 'model-theory', 'soft-question', 'real-analysis', 'complex-analysis']"
263965,Kernel density estimation for heavy-tailed distributions using the champernowne transformation,"I am trying to follow this paper to estimate the density for a heavy-tailed distributions using the champernowne transformation. Alternative link to the paper Another alternative link to the paper However, I do not understand the final step to transform the kernel density estimate of the transformed data back to the untransformed data set. An outline of the procedure is below: Firstly, the data, X, is transformed: Where T() is a modified Champernowne CDF. The parameter alpha, M and c have already been estimated. Then a Kernel Density Estimate, with a Gaussian kernel is done on the transformed data. However, the data must lie in the interval (0,1), so we only take the that part of the estimated density and then divide by the integral of that part of the density. The final step, which I don't understand is the formula below. What does the denominator mean? I understand that the numerator is the estimate of the transformed data set. I can also see the transformered data set in the denominator, T(), but what is T'? The authors of the paper then write the following expression for the density estimator of the untransformed dataset:","['statistics', 'probability-distributions', 'probability-theory', 'transformation', 'probability']"
263974,Sums of two probability density functions [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . This post was edited and submitted for review 2 years ago and failed to reopen the post: Original close reason(s) were not resolved Improve this question If the weighted sum of 2 probability density functions is also a probability density function, then what is the relationship between the random variables of these 3 probability density functions.",['probability']
263991,Proving $f$ has at least one zero inside unit disk,"Let $f$ be a non-constant and analytic on a neighborhood of closure of the unit disk such that $|f(z)|=\text{constant}$ for $|z|=1$. Prove $f$ has at least one zero inside unit disk. I thought of using Rouche's somehow. Using $f(z)-z$, and taking constant is less than $1$, I can actually conclude from Rouche's theorem that the equation $f(z)-z=0$ have a fixed point inside the unit disk. I am stuck for other constants greater than equals to one and exactly zero.
I hope there should be a little trick I am missing here. It will be awesome to see if maximum principle can be applied to conclude the result.",['complex-analysis']
263998,Generate a random pair of integers whose product is less than or equal to x?,"Ideally, the distribution over the acceptable pairs would be close to uniform. x and the pair are all positive integers (This is for code, so I need a constructive solution) Thanks!",['statistics']
264011,Probability question involving a dice,"You roll a dice $6$ times. What is the probability of rolling at least one $5$ AND at least one $6$? The answer in the book is $1 - (5/6)^6 - (5/6)^6 + (4/6)^6$. 
Would someone please explain why that is? $(1 - (5/6)^6 - (5/6)^6)$ : This is the probability of rolling a $5$ OR $6$ for six rolls of the dice. Correct? What is $(+ (4/6)^6)$? Isn't that the probability of not rolling a $5$ or $6$? Why do I need to add it.",['statistics']
264013,A function over the integers and its fixed points,"Define $f:\mathbb{N}\rightarrow\mathbb{N}$ as follows, $f(n)$ is the number of times the digit ""1"" is needed if we were to write all integers between 1 and $n$ (inclusive) in base 10. So for example $f(1)=1$ $f(2)=1$ $f(3)=1$ ... $f(9)=1$ $f(10)=2$ $f(11)=4$ $f(12)=5$ ... $f(99)=20$ and so on. Clearly $f(1)=1$ is a fixed point. The original question was to find the next fixed point. I immediately established the recursive relation $$f(10^k-1)=10\cdot f(10^{k-1}-1)+10^{k-1}$$ with $f(9)=1$. Then I got the explicit relation $$f(10^k-1)=k\cdot 10^{k-1}.$$ So we see that after $n=1$, $f(n)<n$ until we get to $f(9,999,999,999)=10,000,000,000$ so the fixed point must be between one billion and ten billion. Then after carefully counting and keeping track of what I was doing I got the fixed point to be $$f(1,111,111,110)=1,111,111,110.$$ Now my questions are Does anyone know the origin of this problem? Like is it a Putnam/IMO/etc... challenge problem? I originally heard this problem way long ago when starting my undergrad and I just randomly remembered it again a few days ago. Is there an elegant or an easier way of doing this analytically? Since I don't know how I heard of this problem...and it is a data retrieval nightmare (like when I try to google it), I have no idea if my solution is right or not. Can someone perhaps verify it? I can't tell if I made a mistake counting or not. Is it possible to code this efficiently so that I can get an answer by a simulation? From what I remember I tried MATLAB and Mathematica but it just took so frigging long I had to kill them without knowing the answer and go back to paper and a pencil. I didn't try C++ or FORTRAN. In Mathematica I did try to ""optimize"" it as much as I could using its built-in functions but too slow. For MATLAB, I couldn't see how to vectorize it so just had to write a loop which is of course a bad idea. Any efficient algorithms? Any ideas? More of a theoretical question, is there any way to prove that another fixed after $n=1$ even exists over $\mathbb{N}$? Using the recursive relation above we see that $f(999,999,999)=900,000,000$ and $f(9,999,99,999)=10,000,000,000$ so $f(n)>n$ and then I just narrow the interval until I get $f(n)=n$. If we considered the smooth continuation of $f(x)$ over $\mathbb{R^+}$ then yes the intermediate value theorem guarantees us the fixed point ($f(x)-x$ has an $x$-intercept because it switches sign). But how do we know, how can we prove that the fixed point is EXACTLY on an integer? I mean I know the answer must exist because the question was posed but frankly I am a little surprised that there is another integer after one where the integer exactly equals the number of times ""1"" is needed to get there. 6.Can we say anything about the long term behavior of $f$? Like will $f(n)$ be always greater than $n$ after the second fixed point or will it oscillate going above and below $n$ arbitrarily many times as $n$ tends to infinity? Are there any other fixed points? Are there any other fixed points over the natural numbers? Any way to find them all? Does the smooth continuation of $f$ to the reals have a closed form expression? What would it be? Thanks!","['fixed-point-theorems', 'discrete-mathematics', 'combinatorics']"
264041,Prove $\sum_{m=1}^{\infty}\sum_{n=1}^{\infty} \frac{1}{n(m^2+n^2)}=\sum_{m=1}^{\infty}\sum_{n=1}^{\infty} \frac{1}{n^2(m^2+n^2)}=\frac{\pi^4}{72}$,"How may I prove that
$$\sum_{m=1}^{\infty}\sum_{n=1}^{\infty} \frac{1}{n(m^2+n^2)}=\sum_{m=1}^{\infty}\sum_{n=1}^{\infty} \frac{1}{n^2(m^2+n^2)}=\frac{\pi^4}{72}?$$
I also discussed the problem in the chat, but no solution so far.  Some hints? Thanks!","['sequences-and-series', 'calculus', 'real-analysis']"
264048,How to expand $x \sqrt{4 - x}$ to Maclaurin series?,"Here is the task: using standard expansions , expand $f(x) = x \sqrt{4-x}$ to Maclaurin's series. I calculated derivatives up to $f^{(5)}(x)$, and got some results. Fortunately, in Maclaurin's expansion I need to calcalate $f^{(n)}(0)$, which simplifies the task a little. Here is what I've got: $d(n) = 1 \times 3 \times 5 \times \ldots \times (2n-1) = \frac{(2n)!}{2^nn!}$ (a function for calculating product of first n odd numbers) $r(n)=
\begin{cases}
(2(n - 2) - 1) \times (r(n-1) + d(n-3)),&\text{if $n > 3$;}\\
3,&\text{if $n = 3$.}
\end{cases}
$ $r(n)$ is calculated iteratively or recursively, and it frightens me. However, factorial function is iterative/recursive too, so my $r(n)$ is not worse, but I still somewhat displeased by it. What about derivatives, $f^{(n)}(0)=
\begin{cases}
0,&\text{if $n = 0$;}\\
2,&\text{if $n = 1$;}\\
-1/2,&\text{if $n = 2$;}\\
-r(n) \times 2^{n-2},&\text{if $n \geq 3$.}
\end{cases}
$ ($f^{(0)}(x) = f(x)$, if this is confusing) And it seems to work. I just calculated derivatives and noticed how next derivative is produced from previous. How the series is written down is obvious. But I didn't use any ""standard expansions"". Could this task be done easier and could the $f^{(n)}(0)$ formula be more beautiful?","['calculus', 'derivatives', 'taylor-expansion']"
264049,Prove that every bounded sequence in $\Bbb{R}$ has a convergent subsequence [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . The community reviewed whether to reopen this question 1 year ago and left it closed: Original close reason(s) were not resolved Improve this question I am to prove that every bounded sequence in $\Bbb{R}$ has a convergent subsequence. I am stuck not knowing how and where to start.","['sequences-and-series', 'proof-writing', 'limits']"
264061,expected value calculation for squared normal distribution,"I need help with the following problem. Suppose $Z=N(0,s)$ i.e. normally distributed random variable with standard deviation $\sqrt{s}$. I need to calculate $E[Z^2]$. My attempt is to do something like
\begin{align}
E[Z^2]=&\int_0^{+\infty} y \cdot Pr(Z^2=y)dy\\
=& \int_0^{+\infty}y\frac{1}{\sqrt{2\pi s}}e^{-\frac y{2s}}dy\\
=&\frac{1}{\sqrt{2\pi s}}\int_0^{\infty}ye^{-\frac y{2s}}dy.
\end{align} By using integration by parts we get $$\int_0^{\infty}ye^{-\frac y{2s}}dy=\int_0^{+\infty}2se^{-\frac y{2s}}dy=4s^2.$$ Hence $E[Z^2]=\frac{2s\sqrt{2s}}{\sqrt{\pi}},$ which does not coincide with the answer in the text. Can someone point the mistake?","['probability-distributions', 'probability']"
264067,Covariance of Brownian Bridge?,"I am confused by this question. We all know that Brownian Bridge can also be expressed as: $$Y_t=bt+(1âˆ’t)\int_a^b \! \frac{1}{1-s} \, \mathrm{d} B_s $$ Where the Brownian motion will end at b at $t = 1$ almost surely. Hence I can write it as: $$Y_t = bt + I(t)$$ where $I(t)$ is a stochastic integral, and in this case it is a martingale. Since it is a martingale, the co-variance can be calculated as: \begin{array} {lcl} E[Y_t Y_s] & = & b^2 ts + E(I(t)I(s)] \\ & = & b^2 ts + E\{(I(t)-I(s))* I(s) \} + E [I(s)^2] \\& =&b^2 ts + Var[I(s)] + b^2s^2 \\ & = & b^2 ts + b^2 s^2 + s(1-s)   \end{array} Hence the variance is just $ b^2 s^2 + s(1-s)$. However I read online, the co-variance of the Brownian Bridge should be $s(1-t)$. I am relaly confused. Please advise. Thanks so much!","['probability-theory', 'stochastic-integrals', 'brownian-motion']"
264069,Number of representable as sum of 2 squares,"How to find asymptotically (or some reasonable bound, at least $ o(n) $) number of numbers, representable as a sum of squares of 2 numbers? (in case of bound I am interested in both: lower and upper bounds) I know how to find explicitly the number of ways to represent given number in such a way. (can be found here ) Thank you! P.S. For one lower bound you can use this problem, it'll give you somewhat $ \Omega (n^{\frac{3}{4}}) $.","['asymptotics', 'analytic-number-theory', 'number-theory']"
264081,prove $x \mapsto x^2$ is continuous,"I am to show the continuity of this function with the help of $\epsilon$-$\delta$ argument. The function is: $g: \Bbb{R} \rightarrow \Bbb{R}$, $x \mapsto x^2$. Given the $\epsilon$-$\delta$ definition of limit, I tried as follows: We must have: $|f(x)-f(x_0)|<\epsilon$, so then $|x^2-x_0^2|=|(x-x_0)(x+x_0)|=|(x-x_0)||(x+x_0)|$, so $|x-x_0|<\frac{\epsilon}{|x+x_0|}$. So now I will choose $\delta=\frac{\epsilon}{|x+x_0|}$. Is it enough? I am writing this sentences like a machine, but I am not understanding intuitively.","['continuity', 'proof-writing', 'functions']"
264088,"Calculating $\int_{\mathcal{S}}x_1^r \, \mathrm dx_1\ldots \, \mathrm dx_n$ [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I need help with the calculation of the following integral $$
\int_{\mathcal{S}}x_1^r \, \mathrm dx_1\ldots  \, \mathrm dx_n
$$
where $r>0$ and
$$
\mathcal{S} = \left\{(x_1,\ldots,x_n):a-\epsilon\leq x_1+\ldots+x_n\leq a,\;x_1\ldots,x_n\geq0\right\}
$$
for $a>0$ and $a-\epsilon>0$. Thank you","['definite-integrals', 'multivariable-calculus', 'integration']"
264106,Inequality involving partial sums of $\frac{|\sin{kx}|}{k}$,"How to prove that $\forall x \in \mathbb{R}$, $n \in \mathbb{N}$, we have
  \begin{align}
\sum_{k=1}^{n}\frac{|\sin{kx}|}{k}\ge |\sin{nx}| ?
\end{align} I know that this partial sum will diverge for $x\not = m\pi$, but I don't know how to prove this inequality. I have tried Abel summation, but it doesn't work because I can't give a lower bound for $\sum |\sin{kx}|$. Thanks for your attention.","['inequality', 'sequences-and-series', 'real-analysis', 'analysis']"
264116,CDF of a sum of independent random variables,"Let $X,Y$ be two independent (and identically distributed) random variables. Let $Z:=X+Y$. It's easy to check that the moment generating function $\phi_Z(t):=\mathbb{E}[\,e^{itZ}\,]$ can be expressed as $\phi_Z=\phi_X\cdot\phi_Y$. Is there a way to express the cumulative distribution function $F_Z(z):=\mathbb{P}(Z\leq z)$ using the cumulative distribution functions of $X$ and $Y$ ? Edit: note I don't assume that $X$ and $Y$ have a density.",['probability-theory']
264117,Infinite series $\sum_{n=0}^\infty \frac{(-3)^n}{n!}$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question I can show that the sum $\displaystyle \sum\limits_{n=0}^\infty \frac{(-3)^n}{n!}\;$ converges. But I do not see why the limit should be $\dfrac{1}{e^3}$. How do I calculate the limit?",['sequences-and-series']
264122,Gradient descent for the Thomson problem,"I'm trying to solve the Thomson Problem, i.e we have $N$ repelling point charges on a (hyper)sphere of dimension $m$ and we want to determine which configuration gives the lowest energy. We thus want to minimize $E=\sum_{i<j} ||x_i-x_j||^{-s} $ where $s$ is an integer, (generally taken to be equal to 1), and $x_i$ is the $i$th point. I want to apply gradient descent to it (as part of a local optimization routien in a  genetic algorithm), so I need the gradient of $E$, however $E$ depends on $N$ points, and each point has $m-1$ (hyper)spherical components.
How could I calculate $\nabla E$ ?","['optimization', 'multivariable-calculus']"
264131,Is the complement of an ample divisor always affine,"Let $X$ be a projective variety and let $D$ be an ample divisor. Is the complement of the support of $D$ in $X$ affine? We can suppose $D$ is very ample. (Just replace it with a multiple.) I'm trying to reduce to the case of a hyperplane on projective space, but I can't do it.","['algebraic-geometry', 'algebraic-curves']"
264137,Proof for an identity involving a sum of binomial coefficients,"I am moving through a On The Average Height of Planted Plane Trees by Knuth, de Bruijn and Rice, 1972), and I would like to trade a weaker result for simpler mathematical tools, because my skills are not up for the task. I would simply like to prove  that the average height $h_n$ of a tree with $n$ nodes (i.e. the maximum number of nodes from the root to a leaf) satisfies $h_n \sim \sqrt{\pi n}$. The outline from the article is as follows and may be skipped. Let $A_{nh}$ be the number of trees with height less than or equal to $h$ (with the convention $A_{nh} = A_{nn}$ for all $h \geqslant n$) and $B_{nh}$ the number of trees of $n$ nodes with height greater than or equal to $h+1$ (that is, $B_{nh} = A_{nn} - A_{nh}$). Then $h_n = S_n/A_{nn}$, where $S_n$ is the finite sum
$$
S_n = \sum_{h \geqslant 1} h(A_{nh} - A_{n,h-1}) = \sum_{h \geqslant 1} h(B_{n,h-1} - B_{nh}) = \sum_{h \geqslant 0} B_{nh}.
$$
It is well known that $A_{nn} = \frac{1}{n}\binom{2n-2}{n-1}$, for the set of general trees with $n$ nodes is in bijection with the set of binary trees with $n-1$ nodes, counted by the Catalan numbers. Thus, the first step is to find $B_{nh}$ and then the main term in the asymptotic expansion of $S_n$. At this point the authors use analytical combinatorics (three pages) to derive
$$
B_{n+1,h-1} = \sum_{k \geqslant 1} \left[\binom{2n}{n+1-kh} - 2\binom{2n}{n-kh} + \binom{2n}{n-1-kh}\right].
$$ Then they say that
$$
S_{n+1} = \sum_{k \geqslant 1}d(k) \cdot \left[\binom{2n}{n+1-k} - 2\binom{2n}{n-k} + \binom{2n}{n-1-k}\right],
$$
where $d(k)$ is the number of positive divisors of $k$. If I am not mistaken, this boils down to prove
\begin{gather*}
\sum_{h \geqslant 0}\left[\binom{2n}{(n-k)+1-kh} - 2\binom{2n}{(n-k)-kh} + \binom{2n}{(n-k)-1-kh}\right] =\\
 d(k) \cdot \left[\binom{2n}{n+1-k} - 2\binom{2n}{n - k} + \binom{2n}{n-1-k}\right].
\end{gather*}
How would you approach this identity without using complex analysis?","['summation', 'binomial-coefficients', 'combinatorics']"
264139,A convergent sequence that is defined recursively,"I would like to get a hint on how to establish the convergence of the following sequence: $$a_{n+1}= a_n + \frac{\sqrt{\vert a_n \vert }}{n^2}$$ where $a_1$ is arbitrary. This is an increasing sequence, so if I could show that it was bounded above I would be done.  I cannot figure out how to do that. Any help would be appreciated.","['sequences-and-series', 'real-analysis']"
264140,Determinant of $n\times n$ matrix,"How can I calculate the determinant of the following $n\times n$ matrix, where $n$ is a multiple of $3$ ?
$$\begin{pmatrix}
0 & 0 & 1 & & & & & & &\\
& & & 0 & 0 & 1 & & & &\\
& & & & & &\ddots\\
& & & & & & & 0 & 0 & 1\\
0 & 1 & 0 & & & & & & &\\
& & & 0 & 1 & 0 & & & &\\
& & & & & &\ddots\\
& & & & & & & 0 & 1 & 0\\
1 & 0 & 0 & & & & & & &\\
& & & 1 & 0 & 0 & & & &\\
& & & & & &\ddots\\
& & & & & & & 1 & 0 & 0
\end{pmatrix}$$","['matrices', 'linear-algebra', 'determinant']"
264148,Why does the definition of limits of a function have strict inequality?,"Definition (As written in Michael Spivak's Calculus) The function $f$ approaches a limit $l$ near $a$ means: for every $\epsilon >0$ there is some $\delta > 0$ such that, for all $x$, if $0<|x-a|<\delta$, then $|f(x)-l|<\epsilon$. my question is: why can't it be: $$0<|x-a|\leq \delta,|f(x)-l|\leq \epsilon$$
After looking at limits of functions for a long time just to grasp it's meaning and using the definition quite a lot solving homework I realized I keep writing the same inequality without really understanding why. The only explanation given in Spivak's book for this part of the definition goes over it without explaining the inequality. I tried looking for an explanation myself but wasn't really able to find anything wrong with it. Is it also possible to write the definition like that or is there a problem with that? (first non-homework related question :p)","['calculus', 'definition']"
264169,determinants of matrices of minors,"Let $A$ be an $n \times n$ matrix and fix an integer $k$ with $1 \leq k \leq n$. Define a new matrix $\text{minor}_k(A)$ whose entries are the $k \times k$ minors of $A$. This new matrix will be $\binom{n}{k} \times \binom{n}{k}$. Theorem? Let $D$ be the determinant of $A$. The determinant of $\text{minor}_k(A)$ is $D^\binom{n-1}{k-1}$. Is this right? Can anyone provide a reference or proof? (If you want to be more precise in the definition of $\text{minor}_k(A)$, put an ordering on the cardinality $k$ subsets of $\{1, 2, \dots, n\}$, and index the rows and columns of $\text{minor}_k(A)$ using that ordering. The $(i,j)$ entry is then the determinant of the matrix obtained by keeping only the rows of $A$ indexed by the $i$th subset, and the columns of $A$ indexed by the $j$ subset. Changing the ordering shouldn't affect the determinant of the matrix of minors.)",['linear-algebra']
264172,Integrating $\int_0^{\infty} u^n e^{-u} du $,"I have to work out the integral of $$
I(n):=\int_0^{\infty} u^n e^{-u} du
$$ Somehow, the answer goes to $$
I(n) = nI(n - 1)$$ and then using the Gamma function, this gives $I(n) = n!$ What I do is this: $$
I(n) = \int_0^{\infty} u^n e^{-u} du
$$ Integrating by parts gives $$
I(n) =  -u^ne^{-u} + n \int u^{n - 1}e^{-u} $$ Clearly the stuff in the last bit of the integral is now $I(n - 1)$, but I don't see how using the limits gives you the answer. I get this $$
I(n) = \left( \frac{-(\infty)^n}{e^{\infty}} + nI(n - 1) \right) - \left( \frac{-(0)^n}{e^{0}} + nI(n - 1) \right)
$$ As exponential is ""better"" than powers, or whatever its called, I get $$
I(n) = (0 + I(n - 1)) + ( 0 + nI(n - 1)) = 2nI(n - 1)$$ Does the constant just not matter in this case? Also, I do I use the Gamma function from here? How do I notice that it comes into play? Nothing tells me that $\Gamma(n) = (n - 1)!$, or does it?","['gamma-function', 'integration']"
264180,Limit with square and cube root difference $\lim_{n \to \infty} \left(\sqrt{n^2 + n} - \sqrt[3]{n^3 + n^2}\right)$,"I've been banging my head at this one for the last hour and I can't seem to find the solution. I've read through almost all of the limit problems that were asked to be solved here and the tricks used just don't work on this one, or maybe I'm just not seeing it. $\lim_{n \to \infty} \left(\sqrt{n^2 + n} - \sqrt[3]{n^3 + n^2}\right)$ Of course the solution has to be done without using the L'Hospital's rule or series expansion. I've used the $a^3 - b^3 = (a - b)(a^2 + ab + b^2)$ identity and $a^2 - b^2 = (a + b)(a - b)$ and got nowhere near the solution -> $\frac{1}{6}$. I even tried using the $(1 + \frac{1}{n})^n$ and played with exponents but got a solution -> $\dfrac{1 - e^{2/3}}{2}$ which told me I'm definitely doing something wrong.","['radicals', 'calculus', 'limits']"
264184,"Proving that one can split a convergent series into a (countably) sum of ""subseries""","Let $I\subseteq \mathbb{N}$, $\left(A_{i}\right)_{i\in I}$ be a sequence of disjoint subsets of $\mathbb{N}$. If $a:\bigcup_{i\in I}A_{i}\rightarrow\mathbb{R}^{+}$ is a sequence of positive real numbers in $\bigcup_{i\in I}A_{i}$ such that $\sum_{n\in\bigcup_{i\in I}A_{i}}a_{n}$ converges, does then the equality  $$ \sum_{n\in\bigcup_{i\in I}A_{i}}a_{n}=\sum_{i\in I}\,\sum_{n\in A_{i}}a_{n} $$ hold ? 
 If $I$ is finite I managed to prove it (by using the fact that a sum $\sum_{i\in I} A_i$ can be represented as $\sup\{\sum_{i\in F} \mid F\subseteq I, F \ \text{finite}\}$), but for countable $I$ I don't know what to do.","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
264194,$X+Y\in L^1$ implies $X \in L^1$ given $X$ and $Y$ are independent random variables,"This problem can be found here , which is a previous prelim exam problem of UT Austin. Let $X$ and $Y$ be two independent random variables with $X+Y \in L^1$. Show that $X\in L^1$. Generally, in real analysis, $f+g\in L^1$ does not imply $f\in L^1$, so I guess this must have something to do with their independence. I guess it might be something like $EX=E(X+Y|Y=y)-y$, but I'm not sure whether I can write like that without knowing $X\in L^1$ or $Y\in L^1$ first. Or, it should be proved in another way? Could you please help? Thanks.","['probability-theory', 'probability']"
264198,Convergence of empirical distribution,"Let $Z_1 , Z_2 , \ldots$ be iid with $E(|Z_i|) < \infty$. Let $\theta$ be independent of the $Z_i$ with $E(|\theta|) < \infty$. Let $Y_i = \theta + Z_i$. I am trying to show that the conditional expectations $E(\theta\mid Y_1 ,\ldots, Y_n)$ converge a.s. to $\theta$. I know that $E(\theta\mid Y_1 ,\ldots , Y_n) \rightarrow E(\theta \mid \sigma(Y_1, Y_2 , \ldots))$ a.s. as $n\rightarrow \infty$, so it will suffice to show that $E(\theta \mid \sigma(Y_1, Y_2 , \ldots)) = \theta$. (here $\sigma(Y_1 , Y_2 , \ldots)$ is the $\sigma$ algebra generated by the $Y_i$) However, I do not see a way to do this. Any suggestions?","['probability-theory', 'probability']"
264207,Value of an integral related to Stirling's formula,"Consider the following improper integral :
$$
I = \int_1^\infty  \left(\{t\}-\frac{1}{2}\right)\frac{dt}{t}.
$$ Comparing with Stirling's formula, we can see that $I = \ln(\sqrt{2\pi}) - 1$. Is there a more direct way to compute this ? Edit : I have split my two questions : the other part is here .","['integration', 'real-analysis']"
264222,Invariants in a second order equation,"For $Ax^2+2Bxy+Cy^2+2Dx+2Ey+F=0$, why are $\begin{vmatrix}
A &B \\ 
B &C 
\end{vmatrix}$ and $\begin{vmatrix} A & B & D\\  B & C & E\\  D & E & F \end{vmatrix}$ invariant under an orthogonal transformation? I was considering simply convincing myself of its self-evidence by through looking at the mechanics of the possible transformations, but the fact that 2 invariants are expressible in determinant form makes it look as if there's a far more elegant scheme underneath. What is the 'book proof' of their invariance (if there is an elegant one beyond mechanics), and how is it proved that they (and $A+C$) are the only possible invariants for a second order equation (for orthogonal transformations)? The answer to the following will probably be implicit in the main answer, but how would this proof be extendable into an $n$-ordered equation?","['linear-transformations', 'quadratic-forms', 'linear-algebra', 'determinant', 'invariance']"
264223,"Finding $\lim_{x\to \pm\infty}f(x)$ where $a,b>0$","I found this problem interesting to be here: If $a,b>0$ then find the following limit: $$\lim_{x\to\pm\infty}\left(\frac{a^{\frac{1}{x}}+b^{\frac{1}{x}}}{2}\right)^x$$ Thanks!","['calculus', 'limits']"
264237,Limit of a function and its derivative,"Do there exist functions $f$, where $\lim_{x \rightarrow \infty} f(x) = 0$ and $\lim_{x \rightarrow \infty} \frac{df(x)}{dx} \neq 0$?","['calculus', 'functions', 'limits']"
264238,Limit of an integral (remainder term of a Euler-Maclaurin expansion),"For every $x > 0$, define $$I(x) = \int_1^\infty \left(\{t\} - \frac{1}{2}\right)\frac{x}{e^{xt}-1}\,dt.$$
where $\{x\} = x - \lfloor x\rfloor$ denotes the fractional part of $x$. How to justify that $I(x)$ converges to the improper integral
$$
\int_1^\infty  \left(\{t\}-\frac{1}{2}\right)\frac{dt}{t}
$$
when $x \searrow 0$ ? Of course $\dfrac{x}{e^{tx}-1}$ converges to $\dfrac{1}{t}$ for every $t$, but since
$$
\int_1^\infty \left|\{t\} - \frac{1}{2}\right|\frac{dt}{t} = \sum_{n=1}^\infty \int_{-1/2}^{1/2} \frac{|u|\,du}{n+\frac{1}{2}+u} \geq \left(\sum_{n=2}^\infty \frac{1}{n}\right)\int_{-1/2}^{1/2}|u|\,du =  +\infty,
$$
there is no hope to apply Lebesgue's theorem. I noticed that this is some type of Abelian-like result. Here is a proof. Let $f(t)=\left(\{t\}-\dfrac{1}{2}\right)\dfrac{1}{t}$. It is known that $F(T) = \int_1^T f(t)\,dt$ converges to $\ell = \dfrac{1}{2}\ln(2\pi)-1$ as $T$ tends to $+\infty$. Using the following integration by parts formula: $$\int_T^\infty f(t)\frac{tx}{e^{tx}-1}\,dt = -(F(T)-\ell)\frac{Tx}{e^{Tx}-1}-\int_T^\infty (F(t)-\ell)\frac{d}{dt}\frac{tx}{e^{tx}-1}\,dt$$ 
where $\dfrac{d}{dt}\dfrac{tx}{e^{tx}-1}=\dfrac{xe^{tx}(1-tx-e^{-tx})}{(e^{tx}-1)} \leq 0$, we get
$$
\left|\int_T^\infty f(t)\dfrac{tx}{e^{tx}-1}\,dt\right| \leq 2\sup_{t\geq T}|F(t)-\ell|\dfrac{Tx}{e^{Tx}-1}\leq 2 \sup_{t\geq T}|F(t)-\ell|.
$$ Hence, for every $T > 1$ and $x >0$,
$$
\left|\int_1^\infty f(t)\dfrac{xt}{e^{xt}-1}\,dt - \ell\right| \leq \left|\int_1^T f(t)\left(1-\dfrac{xt}{e^{xt}-1}\right)\,dt\right| + 3\sup_{t\geq T}|F(t)-\ell|.
$$
The result easily follows from this inequality.","['integration', 'real-analysis', 'limits']"
264241,"Drawing a graph that is flat, but then spikes","I'm trying to create a function that makes a graph like this: |
|
|           -
|          - -
|         -   -
|        -     -
|--------       --------
|----------------------- I'm stuck with: $1/((x-1.5)^2)$ Any help?","['graphing-functions', 'functions']"
264252,The way into set theory,"Given that I am going through Munkres's book on topology , I had to give a glance at the topics included in the first chapter like that of Axiom of choice, The maximum principle, the equivalence of the former and the later etc. Given all this I doubt that I know enough of set theory , or more precisely and suiting to my business , Lack a good deal of rigor in my ingredients. I wanted to know whether research is conducted on set theory as an independent branch. Is there any book that covers all about set theory, like the axioms, the axiom of choice and other advanced topics in  it. I have heard about the Bourbaki book, but am helpless at getting any soft copy of that book.","['reference-request', 'book-recommendation', 'elementary-set-theory', 'soft-question']"
264256,Curious property of monotonic functions,"If $f:\mathbb{R}\to\mathbb{R}$ is continuous and monotonically increasing on the interval $[1,\infty]$ with $f'(x)\leq\frac{1}{x}$ on the interval $[1,\infty]$ then is it true that: $$\lim_{n \rightarrow \infty}  \frac{1}{nf(n)}\sum_{k=1}^n  f(k)=1$$ This is by no means a theorem also, its just a guess I made after experimenting with sums of the natural logarithm. It makes intuitive sense to me, because any monotonic function $f(x)$ with a derivative that isn't monotonic results in that function increasing as $x$ increases, but the rate at which it increases is decreasing, therefore in a sense its sort of approaching a constant value, ie 'increaseing at a very slow rate', making all terms slightly less then $f(x)$ , ie $f(x-1), f(x-2),\ldots$ etc, all very close in value to $f(x)$. Meaning the summands towards the end of the summation should all be very close in value, while the smaller ones like $f(1),f(2),\ldots$ etc are neglible. So athough clearly $\sum_{k=1}^n  f(k)<nf(n)$, 
 I still find it reasonable that
 $\lim_{n \rightarrow \infty}  \frac{1}{nf(n)}\sum_{k=1}^n  f(k)=1$ A disproof/proof of the theorem would be nice, but in addition some background intuition would also be greatly appreciated.","['sequences-and-series', 'functions']"
264257,Subgroup of a soluble group is soluble,"I'm trying to show that if $G$ is a soluble group with $H$ some subgroup then $H$ is also soluble. My argument is as follows: As $G$ is soluble then we have the subnormal series: $\{e\}\triangleleft G_1 \triangleleft..... \triangleleft G_n=G$. If we now intersect $H$ with this series we get: $$\{e\}\triangleleft G_1\cap H \triangleleft G_2\cap H..... \triangleleft  G_i\cap H\triangleleft H\cap G_i=H$$ So we now need to show the normality and that each factor is abelian. To see the normality we need to prove that given $A,B,H$ subgroups of $G$ such that $A\triangleleft B$ we have $A\cap H \triangleleft B\cap H$. So take $g\in A\cap H$ and $h\in B\cap H$ and consider $hgh^{-1}$. Now as $h\in B$ and $g\in A$ we have $hgh^{-1}\in A$ also as $h\in H$ and $g\in H$ then $hgh^{-1}\in H$ and so we have that $hgh^{-1}\in A\cap H$ and this is normal. Now we need to show that each factor is abelian. So we need to show that given $A,B,H$ subgroups of $G$ such that $A\triangleleft B$ we have: If $B/A$ is abelian then $(B\cap H) / (A \cap H)$ is abelian. To see this we need to show that $(B\cap H) / (A \cap H)$ is a subgroup of $B/A$. So I am claiming that: $$(B\cap H) / (A \cap H)\cong A(B\cap H)/A$$ Which is a subgroup of $B/ A$ Now we have the following, that $A\triangleleft B$ and $B\cap H < A$. So we apply the second isomorphism theorem to get: $$A(B\cap H)/A\cong (B\cap H)/ (A\cap H \cap B)=A(B\cap H)/A\cong (B\cap H)/ (A\cap H )$$ as $A\cap B=A$ Is this correct, I am a bit worried about the last part. Thanks very much any help","['finite-groups', 'group-theory', 'abstract-algebra']"
264265,Suppose that $a_k$ are positive and decreasing. Prove that $\sum_{k=1}^{\infty}(a_k)$ if and only if $\sum_{k=1}^{\infty}{2^ka_{2^k}}$ converges. [duplicate],This question already has answers here : Closed 11 years ago . Possible Duplicate: proving cauchy condensation test Suppose that $a_k$ are positive and decreasing. Prove that $\sum_{k=1}^{\infty}(a_k)$ if and only if $\sum_{k=1}^{\infty}{2^ka_{2^k}}$ converges. By using decreasing how can I prove this?,"['sequences-and-series', 'convergence-divergence', 'calculus', 'real-analysis']"
264270,Calculating $\mathbb{P}(A \mid B)$.,"To confirm the formula for probabilities, given that an event has occured, I wonder if it is true that: $\mathbb{P}(A \mid B)=1-\mathbb{P}(A^{C} \mid B)$ where $\mathbb{P}(A)+\mathbb{P}(A^{C})=1$. $A$ and $B$ are events.",['probability']
264290,Division into $x(x-1)$,"All variables involved are nonnegative integers. Given a variable $g$, what is the largest $x$ where $g$ cleanly divides $x(x-1)$ and $x\lt g$? Do I only need prime factors of $g$?",['number-theory']
264306,limits calculus,"I am having trouble understanding part of the solution to this simple problem. $\lim_{x \to 2} (x^2 + 3x) = 10$ Solution: Let $\epsilon > 0$ $| x - 2 | < \delta$  and $| x^2 +3x -10 | < \epsilon$ since $x^2 +3x -10 = (x - 2)^2 + 7x -14 = (x - 2)^2 + 7x -14 = ( x -2 )^2 +7(x-2)$ $|(x-2)^2 +7(x-2)| \leq |(x-2)|^2 +7|(x-2)|$ $\delta^2 + 7\delta < \epsilon$ let $\delta$ be the minimum of $1$ and $\epsilon/8$, $\delta^2 \leq \delta$. then $8\delta < \epsilon$ $\delta < \epsilon/8$. My Question: I worked my way through the question down to $\delta^2 + 7\delta < \epsilon$ I then got confused by the end of this statement Let $\delta$ be the minimum of $1$ and $\epsilon/8$, $\delta^2 \leq \delta$. and in particular $\delta^2 \leq \delta$. I see how this allows me to prove the limit but I cannot make sense out of $\delta^2 \leq \delta$. Could anyone explain this to me?",['limits']
264318,Functional Prime Sums,"Let $ f: \mathbb{N} \to \mathbb{N} $ be a number-theoretic function satisfying $ f(xy) = f(x) + f(y) $ whenever $ \gcd(x,y) = 1 $. How can I prove that
$$
\sum_{\substack{p ~ \text{prime}; \\ p \leq n}} f(p) \frac{p}{n} \bigg\lceil \frac{n}{p} \bigg\rceil \left\{ \frac{n}{p} \right\} \sim \frac{1}{2} \sum_{\substack{p ~ \text{prime}; \\ p \leq n}} f(p),
$$
i.e., the ratio of these two sums, as $ n $ tends to $ \infty $, is equal to $ 1 $? Notation: $ \lceil \cdot \rceil $ denotes the ceiling function, and $ \{ \cdot \} $ the fractional-part function. If someone could just simplify the problem, not even necessarily prove it, I would greatly appreciate it. Also, I don't know if the following relations might help in a proof/simplification:
\begin{align}
\lim_{n \to \infty} \frac{1}{n} \sum_{k=1}^{n} \frac{k}{n} \bigg\lceil \frac{n}{k} \bigg\rceil \left\{ \frac{n}{k} \right\} &= \frac{1}{2}, \\
\lim_{n \to \infty} \frac{1}{n} \sum_{\substack{p ~ \text{prime}; \\ p \leq n}} \frac{p}{n} \bigg\lceil \frac{n}{p} \bigg\rceil \left\{ \frac{n}{p} \right\} &= \frac{1}{2}.
\end{align}","['prime-numbers', 'fractional-part', 'functions', 'number-theory']"
264321,Elementary proof of a bound on the order of the partition function,"I am interested in the asymptotic order of the partition function $p(n)$. The paper Asymptotic Formulae in Combinatory Analysis proves there are constants $A$,$B$ such that $e^{A\sqrt{n}} < p(n) < e^{B\sqrt{n}}$ by elementary means. Here is the argument for one side of the inequality, it is just the inductive step which I have not understood: I assume that $p_r(n)$ is defined to be $0$ for negative $n$, then the inequalty (2.22) does not hold for these $n$. In which case the sum $\{n^{s-1} + (n-s-1)^{s-1} + (n-2s-2)^{s-1} + \ldots\}$ must be finite, ending before $n-ks-k$ becomes negative. On the other hand the use of telescoping down to $n^s$ suggests that the sum is infinite, otherwise we would end up with $n^s - (n-ks-k)^{s-1}$ and are unable to throw away the $k$ term. Thank you to anyone who will help me understand this argument.","['integer-partitions', 'number-theory']"
264324,"Why do my algebra proofs seem like ""magic""? Is this related to category theory?","$\newcommand{Ab}{\operatorname{Ab}} \newcommand{Id}{\operatorname{Id}}$I'm self-studying Introduction to Topological Manifolds by John M. Lee, which includes quite a few exercises like this: 9-4(b) Let $S_1$ and $S_2$ be disjoint sets, and let $R_i$ be a subset of the free group $F(S_i)$ for $i=1,2$. Prove that $\langle S_1 \cup S_2 \mid R_1 \cup R_2 \rangle$ is a presentation of the free product group $\langle S_1 \mid R_1 \rangle * \langle S_2 \mid R_2 \rangle$. 10-17. For any groups $G_1$ and $G_2$, show that $\Ab(G_1*G_2) \cong \Ab(G_1) \oplus \Ab(G_2)$. 10-19. For any set $S$, show that the abelianization of the free group $F(S)$ is isomorphic to the free abelian group $\mathbb{Z}S$. ($*$ is free product, $\Ab$ is abelianization.) Here is my tedious proof of 10-17: For $i=1,2$, let 
  \begin{align*}
\alpha_{i}:G_{i} & \to\Ab(G_{i}),\\
\alpha:G_{1}*G_{2} & \to\Ab(G_{1}*G_{2}),\\
j_{i}:\Ab(G_{i}) & \to\Ab(G_{1})\oplus\Ab(G_{2}),\\
k_{i}:G_{i} & \to G_{1}*G_{2}
\end{align*}
   be the canonical maps. There exists a homomorphism $\ell:G_{1}*G_{2}\to\Ab(G_{1})\oplus\Ab(G_{2})$
  satisfying $\ell\circ k_{i}=j_{i}\circ\alpha_{i}$, and there exists
  a homomorphism $\varphi:\Ab(G_{1}*G_{2})\to\Ab(G_{1})\oplus\Ab(G_{2})$
  satisfying $\varphi\circ\alpha=\ell$. Also, there exist homomorphisms
  $m_{i}:\Ab(G_{i})\to\Ab(G_{1}*G_{2})$ satisfying $m_{i}\circ\alpha_{i}=\alpha\circ k_{i}$,
  so there exists a homomorphism $\psi:\Ab(G_{1})\oplus\Ab(G_{2})\to\Ab(G_{1}*G_{2})$
  satisfying $\psi\circ j_{i}=m_{i}$. Now 
  $$
\varphi\circ\psi\circ j_{i}\circ\alpha_{i}=\varphi\circ m_{i}\circ\alpha_{i}=\varphi\circ\alpha\circ k_{i}=\ell\circ k_{i}=j_{i}\circ\alpha_{i},
$$
   so $\varphi\circ\psi=\Id_{\Ab(G_{1})\oplus\Ab(G_{2})}$ by uniqueness.
  Similarly, 
  $$
\psi\circ\varphi\circ\alpha\circ k_{i}=\psi\circ\ell\circ k_{i}=\psi\circ j_{i}\circ\alpha_{i}=m_{i}\circ\alpha_{i}=\alpha\circ k_{i},
$$
   so $\psi\circ\varphi=\Id_{\Ab(G_{1}*G_{2})}$ by uniqueness. This is just one example - there are many other proofs which seem to follow the same pattern - use the universal properties to derive homomorphisms, compose a bunch of them together, simplify, and prove that you have isomorphisms. My questions are: Is there a name for this kind of proof? How can I understand what I'm doing? I feel like I'm just moving symbols around right now, matching up domains/codomains. Can these proofs be made less tedious? The reason I say these proofs are like ""magic"" is that everything seems to fit together perfectly when I'm composing the maps. Why does this happen?",['abstract-algebra']
264331,Recommending books for introductory differential geometry [duplicate],"This question already has answers here : Teaching myself differential topology and differential geometry (10 answers) Closed 5 years ago . I was wondering if anyone could recommend some books for studying topics such as abstract manifolds, differential forms on manifolds, integration of differential forms, Stokes' theorem, de Rham cohomology, Hodge star operator? Our text is A Comprehensive Introduction to Differential Geometry by Spivak, but I think this book is very difficult for a beginner to learn. Thanks in advance.","['book-recommendation', 'reference-request', 'differential-geometry']"
264347,Why can't you take the limit of a 2-D function in every direction and call that the limit if they're equal?,"In my second-year calculus class this term, one of the thing that the professor insisted was wrong was that the limit of a two-dimensional function as the input approached a certain point could not be calculated simply by taking the limit of the function in every direction and verifying that they were all equal. I've taken her word for it, but why is this not true? Is there a counterexample to this proposition, and if so, what general principle does it violate?","['multivariable-calculus', 'limits']"
264350,Proving $f$ is a constant function,Let $f$ be a $2\pi$ periodic entire function satisfying $|f(z)|\leq 1+|{\rm Im}\; z|$. I am trying to show $f$ is constant. Initially I thought it is very easy that I can apply  Louiville's Theorem. But I realized proving $f$ is bounded is not straight forward. This has to do something with that period of the function. I do not see what I can do with that.,['complex-analysis']
264355,Forecasting Lottery,"I do understand that all lottery has a negative mathematical expectation but I am wondering, if we have a set of historical data of the winning numbers, is it possible to increase the winning chance? I also do understand that each round is a independent event but according to this theory where you roll a dice $n$ times, you each side should get $n/6$ times as $n \to \infty$. So my questions is, does such a function exist to increase the winning chances of a lottery?","['statistics', 'probability']"
264362,Checking if a System of Polynomial Equations is Consistent,"I'm trying to determine whether any solutions exist to a system of $(n+1)$ polynomial equations in $n$ unknowns.
For example:
$$
\begin{align*}
xy&=-2\\
x^2-1&=0\\
y^3-3y^2+2y&=0
\end{align*}
$$
This is an accurate simplification of my actual system in that the first equation contains mixed terms with all variables represented and the remaining $n$ equations are univariate, and that the maximum degree of any term (say, $D$) is in the low single digits.
The actual system is very large ($n$ is $10^3$ to $10^4$), but with similar $D$.
It also typically has many terms in the first equation. In this example, the system is in fact consistent ($x=-1; y=2$).
Were the first equation altered, however, to $xy=-3$, the system would be inconsistent.
My naive approach is to find the solutions to the last $n$ equations (here $x\in\{-1,1\},y\in\{0,1,2\}$) and try all combinations thereof until one satisfies the first equation or I exhaust the combinations, but this requires roughly $D^n$ checks, which isn't feasible for large systems.
It's also not necessary to find a solution, just prove whether one exists. I've spent some time looking for appropriate algorithms, and I'll summarise my current understanding.  I don't have a very strong background in this kind of math, so please correct any misconceptions I have here. As per Wikipedia, consistency can be checked via computation of the Grobner basis.
It seems like I would need to know a priori the order $y>x$ to compute the basis, which I do not.
Also, one of the papers I read on the topic seems to indicate that this method gets exponentially slower with increasing $n$. There is a numerical method called `homotopy continuation' for finding solutions given a similar set of equations with known solutions, but since the number of solutions is unknown (which is the point after all) I couldn't see how/if I could apply it.  It involves varying a parameter $t$ from 0 to 1 and formulating the equations such that at $t=0$ you recover the known case and at $t=1$ you recover the desired case, using Newton's method.  My attempt failed because it is possible that no solutions exist for some intermediate $t$ even though the system is consistent at both $t=0$ and $t=1$. It is possible to state the equations as rational functions in a single variable using a technique called `rational univariate representation'.  I don't properly understand how to get this representation of the system other than by trial and error, although I do understand how it would allow me to determine the consistency of the system if I did find it. I believe that due to the form of the system, I won't ever have infinite solutions, but I may have more than one. I can accept having to use methods that are exponential in $D$ due to it never getting large, but not in $n$.
If a suitable algorithm to check consistency relies upon the assumption of integer solutions, I would consider that an acceptable drawback.
Can any of the above methods serve, or how else might I go about this?
Thank you very much for your patience in reading this, and for any assistance you can provide.","['algebraic-geometry', 'systems-of-equations', 'polynomials']"
264387,"What is rank of $f(A)$, where $f$ is the minimal polynomial of $A$?","If $f(x)$ is minimal polynomial of the $4\times 4$ matrix
$$A=\begin{pmatrix}
0 &0 &0& 1\\
1 &0 &0 &0\\	
0 &1 &0 &0\\
0 &0 &1 &0	
\end{pmatrix}$$ Then what is rank of $f(A)$? I think $f(A)$ will be a zero matrix so its rank is 0. Am I right?",['linear-algebra']
264395,Convergence to an exponential,"Suppose that $(c_{j, n})$ is a real infinite dimensional triangular array where $1 \leq j \leq n$ with the properties that $\max\limits_{1 \leq j \leq n } |c_{j, n}| \rightarrow 0$ and $\sum\limits_{j=1}^n c_{j, n} \rightarrow \lambda$ when $n\rightarrow\infty$, and $\sup\limits_{n\in\mathbb{N}} \sum_{j=1}^n |c_{j, n}|<\infty.$ Please help me to prove that therefore $\prod\limits_{j=1}^n(1+c_{j, n})\rightarrow e^\lambda$.","['convergence-divergence', 'real-analysis', 'analysis']"
264401,Additive functor over a short split exact sequence.,"$0\to A'\stackrel{f}{\longrightarrow} A \stackrel{g}{\longrightarrow} A''\to 0$ is a short split exact sequence, where $A'$, $A$, $A''$ are $R$-modules, and $T$ is an additive functor from $R$-$\mathsf{mod}$ to $\mathsf{Ab}$. Then we have the sequence $0\to TA'\stackrel{T(f)}{\longrightarrow} TA \stackrel{T(g)}{\longrightarrow} TA''\to 0$ is a split exact sequence again. I know that the second sequence is split. That $T(f)$ is injective and $T(g)$ is surjective is also clear for me too. My question is why $\ker T(g)=\mathrm{im}T(f)$. 1. Some comments I found from the Internet told that an additive functor preserves binary direct sum.Does it help here? I know very few about module theory.I don't know whether this is  the reason why I get stuck here. 2.I have checked from this math.SE post . But the answer there seems to be not suitable for my question. Thanks in advance.","['modules', 'homological-algebra', 'category-theory', 'abstract-algebra']"
264403,When does the adjacency or incidence matrix of a graph have consecutive ones property?,"Given a graph, what are some sufficient (and necessary) conditions to tell if its adjacency matrix has the consecutive ones property? Similar question for its incidence matrix? Note that a $\{0,1\}$-valued matrix is said to have the consecutive ones property,  if there exists a column permutation such that the ones in each row of the resulting matrix are consecutive. Or the roles of rows and columns can be exchanged in the definition. Thanks and regards!","['permutations', 'matrices', 'graph-theory', 'finite-groups', 'combinatorics']"
264405,metric in the Wasserstein space of gaussian measures,"I am reading the paper "" Wasserstein Geometry of Gaussian measures "" by Asuka Takatsu (section 3 is of interest to me) and I have difficulties understanding how the metric is used. In particular, I am wondering the following : if I take the square root of the covariance matrices of my gaussians, does the space become Euclidean ? I feel this should be the case as the metric $tr(XY)$ for $X$ and $Y$ two symmetric matrices allow to recover than $\frac{d}{dt}\langle\dot\gamma,\dot\gamma\rangle=0$ if $\gamma^2$ is a geodesic in the space of covariance matrices (if $\gamma^2(t)$ is a geodesic, it can be written $\gamma(t)=A+tT$, so differentiating by $T$ gives the tangent vector which is independant of the time). However, if this space was Euclidean, wouldn't it mean that an interpolation between a covariance matrix $V$ and another covariance matrix $U$ necessarily be given by $C(t) = (V^{\frac{1}{2}} + t (U^{\frac{1}{2}}-V^{\frac{1}{2}}))^2$ ? This is not the case as geodesics are given by $C(t) = (V^{\frac{1}{2}}+t(U^{\frac{1}{2}}(U^{\frac{1}{2}}VU^{\frac{1}{2}})^{-\frac{1}{2}}U^{\frac{1}{2}}V^{\frac{1}{2}} - V^{\frac{1}{2}}))^2$ (except in 1D where these are equivalent) In which space is the metric $g_V(X,Y)=tr(XVY)$ used ? I thought it was directly in the space of covariance matrices but this doesn't seem to be the case. For instance $\frac{d}{dt}g(\dot\gamma,\dot\gamma)\neq0$ : if $\gamma$ is a geodesic in the space of covariance matrices, then $\gamma(t) = (A+tT)^2$ and then $\dot\gamma = TA+AT+2tTT$ and $\frac{d}{dt}g(\dot\gamma,\dot\gamma)\neq 0$ Thanks!","['statistics', 'information-theory', 'riemannian-geometry', 'differential-geometry']"
264408,Probability each of six different numbers will appear at least once?,"If seven balanced dice are rolled, what is the probability that each of the six different numbers will appear at least once? My solution is $\frac{6 \cdot 7!}{6^7}$. Is this correct? How would I implement a solution using multinomial coefficients?",['probability']
264413,Analytic continuation of a power series 2,"Another Qual question here, 
For the function $$\sum_{n=0}^\infty z^{2^n}$$, 
Prove the following: i) $f$ converges to a function analytic in the open unit disk $D$, ii) $f(z) =z+f(z^2)$ and iii) $f(z)$ can not be analytically continued past any point on the unit circle. I can even see (ii) very easily, but I can not see how can I prove rigorously (i) and  (iii). Help please.",['complex-analysis']
264434,Proving that $\left(1+\frac{z_{1}}{z_{2}}\right)\left(1+\frac{z_{2}}{z_{3}}\right)...\left(1+\frac{z_{n}}{z_{1}}\right)\in\mathbb R$,"I need to prove that $\left(1+\frac{z_{1}}{z_{2}}\right)\left(1+\frac{z_{2}}{z_{3}}\right)...\left(1+\frac{z_{n}}{z_{1}}\right)\in\mathbb R$ where $|z_{1}|=|z_{2}|=...=|z_{n}|=1$. This can be done relatively easily by induction, but I'm looking for  more elegant solution. Any ideas? Thanks!",['complex-analysis']
264458,Help in proving $ \left( 1 + \frac{1}{n} \right)^{n} \leq \sum\limits_{k=0}^{n} \frac{1}{k!} < 3 $.,"I am trying to prove this statement for all $ n \geq 1 $ using induction:
$$
\left( 1 + \frac{1}{n} \right)^{n} \leq \sum_{k=0}^{n} \frac{1}{k!} < 3.
$$ I said: Base case $ n = 1 $:
$$
  \left( 1 + \frac{1}{1} \right)^{1} \leq \sum_{k=0}^{1} \frac{1}{k!} < 3,
  $$
which is okay. Induction step: Suppose that $ \displaystyle \left( 1 + \frac{1}{n}
  \right)^{n} \leq \sum_{k=0}^{n} \frac{1}{k!} < 3 $ for a given $ n \in
  \mathbb{N} $. Transition from $ n \to n + 1 $:
$$
    \displaystyle \left( 1 + \frac{1}{n + 1} \right)^{n+1}
  = \left( 1 + \frac{1}{n + 1} \right)^{n} \left( 1 + \frac{1}{n + 1} \right)
  = \ldots \text{Help} \ldots
  < 3.
  $$ I need some guidance for proof-writing (-thinking) in orders.","['inequality', 'sequences-and-series', 'induction', 'summation', 'proof-writing']"
264486,Is there something in between the law of large numbers and CLT?,"Suppose we are given random variables $X_1, X_2, \dots$ , which are i.i.d., in $L^2$ and such that $\mathrm{E}[X_i]=0$ , $\mathrm{Var}[X_i] = 1$ , say. Let $S_n = \sum_{i=1}^n X_i$ . It is well-known that in this case, we have the following convergence theorems: Law of large numbers: $\frac{S_n}n \to 0$ almost surely. Central limit theorem: $\frac{S_n}{\sqrt{n}}$ converges to a $\sim \mathcal N(0,1)$ random variable in distribution. Does anything interesting happen, if we normalize $S_n$ differently? For instance, is it possible to normalize in a way that we obtain convergence of $\frac{S_n}{c_n}$ to a non-constant random variable (with $\sqrt{n} \ll c_n\ll n$ , I'd imagine) or something like that? This really is just a random thought... If there is a fundamental reason for why we really only care about the above two normalizations, then I'd be happy to know what these reasons are (apart from the fact that these normalizations are particularly natural).","['probability-theory', 'convergence-divergence', 'probability-distributions']"
264491,Probability of Picking the Same Password from a $k$ letter alphabet,"John and Mary both pick passwords at random from a $k$ letter alphabet.  There are up to $n$ letters allowed in the password.  Repetitions are allowed.  What is the probability that they pick the same password? There are $\sum _{i=1}^{n}k^i$ possible passwords, and $\frac{1}{\sum _{i=1}^{n}k^i}$ probability of picking any particular password. I'm not sure how to set the problem up from here.  I know that the answer is either John or Mary picks a password and then the probability of the other picking the same password is $\frac{1}{\sum _{i=1}^{n}k^i}$, but I'm not sure why.  I initially thought it would be $(\frac{1}{\sum _{i=1}^{n}k^i})^2$","['probability', 'combinatorics']"
264504,Finding range of $\frac{x}{(1-x)^2}$,"I'm working though some exercises. One of them is asking to find the range of $f(x) = \frac{x}{(1-x)^2}$. The chapter this exercise belongs to is after the one where the differentiation power rule is introduced, but before the one where the quotient rule is introduced. My approach was to draw a table of values, but this was getting cumbersome and I got frustrated with the approach before finding the answer. My question is, are there simple analytical ways of finding the range that doesn't rely upon the quotient rule? I suspect there must be because of where the question was located. All the existing fraction-related examples in the book have been easily manipulated so that they are $\frac{number}{f(x)}$. This one is $\frac{f(x)}{g(x)}$ and my attempts at making it simpler are failing.","['algebra-precalculus', 'functions']"
264544,How to find number of prime numbers up to to N?,Is there any way or function to find out the number of primes numbers up to any number? (Say $10^7$ or $10^{30}$ or $200$ or $300$?),"['prime-numbers', 'number-theory']"
264554,divisors and powers of line bundles,"Can anyone help me with the following question? Let $X$ be a smooth, projective algebraic variety. Let $D$ be an effective divisor on $X$ and $m$ an integer. Under which conditions there exists a line bundle $L$ such that $\mathcal{O}_X(D)=L^m$? There is of course the obvious one: $m$ should divide de degree of $D$. Is that sufficient? You can assume that $D$ has normal crossings but I don't think that matters for this particular question. Thanks! (and Merry Christmas)",['algebraic-geometry']
264591,what is the best book for Pre-Calculus?,"I was good at maths, but I have missed precalculus knowledge at my school. Now, I am a computer science student, and I am feeling bad in maths, so I am looking for the best precalculus book. I love maths; I need the right well of precalculus books.","['algebra-precalculus', 'reference-request']"
264596,How to prove $\zeta'(0)/\zeta(0)=\log(2\pi)$?,"How do I prove that $\zeta'(0)/\zeta(0)=\log(2\pi)$ ? I can get $\zeta(0)=-\frac{1}{2}$, but I don't know how to calculate $\zeta'(0)=-\frac{1}{2}\log(2\pi)$ ? Can you help me ? Here $\zeta(s)$ is Riemann zeta function:
$$\zeta(s):=\sum_{n=1}^{\infty}\frac{1}{n^s}. $$","['calculus', 'riemann-zeta']"
264644,Representation of holomorphic function on punctured unit disk [duplicate],This question already has an answer here : Closed 11 years ago . Possible Duplicate: Non zero analytic functions on annulus Let $f$ be holomorphic on the punctured unit disk $\{z\in\mathbb{C}:0<|z|<1\}$ and suppose $f$ has no zeros. I want to show that there exist an integer $m$ and a function $g$ holomorphic on the punctured unit disk such that $f(z)=z^{m}e^{g(z)}$ for all $z$ in the punctured disk. I'm not sure how to even start. I thought about considering the Laurent series expansion of $f$ but I didn't get far.,"['analyticity', 'complex-analysis']"
264647,Nonabelian $p$-groups all of whose proper subgroups are abelian.,"Theorem. Let $G$ be a finite, non-abelian $p$-group all of whose proper subgroups are abelian. Then $|G'|=p$. Take a counterexample of minimal order. Assume that exist a $H$  such that $1<H<G'$. Then (by $G'\leq \Phi (G) \leq Z(G)$) $H\vartriangleleft G$. From this we deduce we can assume $|G'|\leq p^2$. Then? How am I supposed to continue? Edit Additional infos $G'$ is elementary abelian since $G$ is Frattini-in-center.","['p-groups', 'finite-groups', 'group-theory', 'abstract-algebra']"
264668,Must $f$ be measurable if each $f^{-1}(c)$ is?,"Suppose $f$ is a real-valued function on $\mathbb R$ such that $f^{âˆ’1}(c)$ is measurable for each number $c$. 
Is $f$ necessarily measurable?","['lebesgue-integral', 'measure-theory', 'real-analysis']"
264678,the dimension of continuous functions on a compact set is finite [duplicate],"This question already has an answer here : Closed 11 years ago . Possible Duplicate: vector space of continuous functions on compact Hausdorff space This is a problem  am trying to solve.  Suppose the dimension of $C(X)$ is finite where $X$ is compact and Hausdorff.  Why is $X$ finite? I was able to show that if $X$ is finite, then the dimension of $C(X)$ is finite.  I am having trouble proving the converse.","['functional-analysis', 'analysis']"
264686,How to find the 3D coordinates on a celestial sphere's surface?,"With celestial I don't mean a normal sphere, but I mean one that uses the altitude and an azimuth angle system. This is what I mean for example: (the star in the image represents an example of a point I'm trying to find) So I have a sphere with known radius, origin and x and y angles (altitude & azimuth). How do I find the 3D coordinate on the surface of that celestial sphere with the information above? I already know how to find coordinates on a normal sphere by converting to spherical coordinates, I've asked that before, but now I need to be able to do it with the celestial coordinate system (so with azimuth and altitude). My attempt which still doesn't produce good results
(the x,y,z variables are the new coordinates on the sphere's surface. rotation.x = altitude angle, rotation.y = azimuth angle) x=origin.x+radius*cos(rotation.y)*cos(rotation.x)
y=origin.y+radius*sin(rotation.x)
z=origin.z+radius*sin(rotation.y)*cos(rotation.x) These formula's are supposed to work with my 3D camera, which contains an azimuth angle, an altitude angle and a 3D position (the origin). I want a 3D coordinate to be projected a distance (radius) away from the origin. So even when all camera angles are changing constantly, the coordinate changes too but it should look like it's not moving and stay still when looking at your screen. So the point is like rotating with your camera, that's why I thought of an imaginary sphere around my camera to represent the orbit the point falls on. Maybe my whole sphere concept is wrong, I have no idea, but it's just my way to visualize the problem. Please tell me how I could visualize it differently if I'm wrong.
Maybe I could rephrase the question as: ""how to find the point at the end of a 3D vector"",
so I got a vector with a 3D position, direction (azimuth and altitude, if that's even possible) and a length (the ""radius""). Am I thinking too complicated? My formulas ONLY work if you fill in the camera's angles (so then the point is in the centre of your screen), but it doesn't work when I add an offset to the angles (like: cos(camera_angle.x+OFFSET), then the point's position isn't right anymore at all. If for example the camera is looking in front towards the horizon, the altitude angle is 0Â°. when looking down towards the ground, it's -90Â° (or 270Â°). When looking up it's +90Â°. The azimuth angle has a range from 0-360Â°. 
I need to get the right combination of multiplying sin and cos together in order to get the new coordinate on the sphere. But my formulas give me the wrong location of the point.
Please help and ask me more details if you need them.","['trigonometry', 'spherical-coordinates']"
264688,Interpreting a limit as a derivative,"I am being stumped by the following question: Evaluate the limit by interpreting each as a derivative: $$\lim_{x\,\to\tfrac{\pi}{6}} \frac{\cos(2x) - \frac{1}{2}}{x - \frac{\pi}{6}}$$ The only way I can think to solve this is using L'Hopital's rule. I have done that and got the correct answer $-\sqrt{3}$. But, I can not figure out how to do it the was it is described. Any help would be greatly appreciated.","['calculus', 'limits']"
264698,asymptotics of the expected number of edges of a random acyclic digraph with indegree and outdegree at most one,"A recent discussion, which may be found here , examined the problem of counting the number of acyclic digraphs on $n$ labelled nodes and having $k$ edges and indegree and outdegree at most one. It was established that the bivariate mixed generating function of this class $\mathcal{G}$ of graphs on $n$ nodes and with $k$ edges is
$$ G(z, u) = \exp \left(\frac{z}{1-uz} \right).$$
This immediately implies that the expected number of edges of a random graph from $\mathcal{G}$ is
$$\epsilon_n = [z^n]\left. \frac{d}{du} G(z,u) \right|_{u=1}.$$
Evaluating this quantity we obtain
$$ \left. \exp \left(\frac{z}{1-uz} \right) z (-1)\frac{1}{(1-uz)^2} (-z)\right|_{u=1}
= \left. \exp \left(\frac{z}{1-uz} \right) \frac{z^2}{(1-uz)^2} \right|_{u=1}
= \exp \left(\frac{z}{1-z}\right) \left(\frac{z}{1-z}\right)^2$$
Continuing with this calculation we find
$$ \epsilon_n = [z^n] \sum_{m\ge 0} \frac{1}{m!}  \left(\frac{z}{1-z}\right)^{m+2} =
\sum_{m=0}^{n-2} \frac{1}{m!} [z^n]  \left(\frac{z}{1-z}\right)^{m+2} =
\sum_{m=0}^{n-2} \frac{1}{m!} [z^{n-m-2}] \left(\frac{1}{1-z}\right)^{m+2} =
\sum_{m=0}^{n-2} \frac{1}{m!} \binom{n-m-2+m+1}{m+1} =
\sum_{m=0}^{n-2} \frac{1}{m!} \binom{n-1}{m+1}.$$
This closed form is actually quite nice, but it does not answer the question that is the most obvious one for this problem, namely Is there an asymptotic expansion of $\epsilon_n$ and if yes, what is the first term?","['graph-theory', 'random-graphs', 'binomial-coefficients', 'combinatorics']"
264699,Can I solve the Frenet-Serret formulas with the only assumption that the cirvature-torsion of the curve are constant?,"I am trying to find the general  equation for space curves which have constant curvatures throughout their length. In general I am interested for curves of more than 3 dimensions. Assuming that all curvatures are constant for the entire length of the space curve, can I use the frenet serret formulae to derive the most general representation of such a curve?",['differential-geometry']
264711,Help me solve this olympiad challenge?,"Given:
$$p(x) = x^4 - 5773x^3 - 46464x^2 - 5773x + 46$$ What is the sum of all arctan of all the roots of $p(x)$?","['trigonometry', 'contest-math', 'polynomials']"
264721,Convergence in $L^1$ space,"Suppose that $f_{n}$ is a sequence of measurable functions, in a finite measure space, $f_{n}\to f $ in $m$-measure and that there exists $g$ in $L^1$ such that $\vert f_n\vert \le g$.
  Prove that 
  $$
\lim_{n\to +\infty}\Vert f_n-f\Vert_{L^1}=0.
$$ What I obviously thought of doing was splitting the difference $|f_n-f|$  to the less than and greater than $\epsilon$ and bound the greater part by $2g$. I am stuck right there, I can show it is finite but can not show it is less than epsilon. Next I thought of using the R. Fisher's argument of getting the subsequence of $f_n$ which converges a.e, and finiteness of space give you a. uniform by Egoroff). But that way I can only show result will be good for the case of subsequence. I am not sure if I can conclude from there though( by arguing that original sequence and its subsequence goes to the same limit).
I am sure I am missing something here. I would love to get out of this confusion. Help please.","['measure-theory', 'convergence-divergence', 'lp-spaces', 'real-analysis']"
264736,Find area of pentagon using determinants,"Find the area of the pentagon of the five vertices $(1,2), (4,1), (5,3), (3,7),  (2,6)$ . Please, use the way of using determinant. My idea is to cut the pentagon into some triangles, then calculate each triangle, then sum them. I wonder if there is some other way to directly calculate it using a bigger matrix calculating its determinant?",['linear-algebra']
264739,Synthetic division via the greedy strategy,I was looking at the expanded synthetic division within Wikipedia. I was stumped by how to come up with and perform the 'compactified' version of synthetic division. Does anyone know how to do it?,"['algebra-precalculus', 'polynomials']"
264745,"Rigorous Definition of ""Function of""","When I was learning statistics I noticed that a lot of things in the textbook I was using were phrased in vague terms of ""this is a function of that"" e.g. a statistic is a function of a sample from a distribution. I realized that while I know the definition of a function as a relation and I have an intuitive notion of what ""function of"" means, it's unclear to me how you transform this into a rigorous definition of ""function of"". So what is the actual definition of ""function of""?",['functions']
264746,Prove the Wallis formula form $\left(4^{\zeta{(0)}} \cdot e^{-\zeta'{(0)}}\right)^2=\frac{\pi}{2}$,"How would you prove the following Wallis formula form
$$ \left(4^{\zeta{(0)}} \cdot e^{-\zeta'{(0)}}\right)^2=\frac{\pi}{2}?$$
Thanks in advance!","['calculus', 'riemann-zeta', 'real-analysis']"
264747,Group Action - Permutation on the Polynomial,"I'm trying to check the permutation on the polynomial is a Group Action, but I'm not getting the second axiom. I'm following my lecturer's work --- Examples 2.1 and 2.6 on page 5 on http://www.math.uconn.edu/~kconrad/blurbs/grouptheory/gpaction.pdf --- I post this first. Can someone please spot the mistake? Thanks. Lecturer did: For $p \in S_n$ and $ \textbf{v} = (c_1,c_2,\cdots,c_n) \in \mathbb{R^n}$,
define $ p \cdot \textbf{v} := (c_{p(1)},,\cdots,c_{p(n)}) $. Check $$ p_2 \cdot (\color{green}{p_1 \cdot (v)}) \overset{?}{\mathop{=}}\ (p_2 \cdot p_1)(v)  \tag{$\spadesuit$}$$ LHS = $ \color{maroon}{p_2} \cdot \color{green}{(c_{p_1(1)},,\cdots,c_{p_1(n)})} = \color{green}{{(c_{p_1(\color{maroon}{{p_2}(1)})}}},\cdots,\color{green}{{c_{p_1(\color{maroon}{{p_2}(n)})})} = (c_{(p_1{{p_2})(1)}},\cdots,c_{(p_1{{p_2})(n)}})} $ $\text{since $S_n$ is a group so has associativity.} $ $ = (p_1 \cdot p_2)(v) \neq RHS $. Hence above is NOT a group action. I tried: Define $ p \cdot f(x_1, \cdots,x_n) := f(x_{p(1)},,\cdots,x_{p(n)}) $. Check this is a group action. LHS of $ (\spadesuit) = \color{maroon}{p_2} \cdot \color{green}{(x_{p_1(1)},,\cdots,c_{x_1(n)})} = \color{green}{{f(x_{p_1(\color{maroon}{{p_2}(1)})}}},\cdots,\color{green}{{x_{p_1(\color{maroon}{{p_2}(n)})})} = f(x_{(p_1{{p_2})(1)}},\cdots,x_{(p_1{{p_2})(n)}})}  = (p_1 \cdot p_2)(v) \neq RHS $ Hence the above is NOT a group action?","['permutations', 'group-actions', 'group-theory', 'symmetric-groups']"
264754,Tensor product and exterior algebra,"I want to show that there is a unique $R$-module isomorphism $M\otimes_{R}N\cong N\otimes_{R}M$, which sends $m\otimes n $ to $n\otimes m$. My idea is to show the map is onto and injective, then how to show its uniqueness? The second question is that $R$ is an integral domain and $F$ its fraction field, consider $F$ as $R$-module. Show that $\bigwedge^{2}F=0$. Also, I am confused about the universal properties when I learn the tensor product and exterior algebra, can anyone give me an example of how to calculate the exterior algebra? Here is another question, the countable direct product of Z is not free. Can anyone give me some hint about how to prove this?",['abstract-algebra']
264759,Method to find an analytical or semi-analytical solution for this diferential equation,"$a(Î·)[S/Î·^2 +FÎ·^2+GÎ·^4+HÎ·^6+J]+a'(Î·) [K/Î·+Î·Z+Î·^3 C]+a''(Î·) [Î·^2 L+P]=0$ where S,F,G,H,J,K,Z,C,L and P are constants
and a(Î·) is the function that's being sought. This equation comes from the eigenvalue problem of the  graphene nano-ring with spin-orbit interaction and magnectic field using the mexican-hat potential. To solve this equation I tried the Froebenius method (it didn't work), and the Maple software (it didn't work either). The group has found a numerical solution using the Runge-Kunta method, but it's necessary to have an analytical or semi-analytical solution to comprehend the real influence of spin-orbit interaction in graphene. I would like to add that this is not homework. In fact, this is an ongoing work with my adviser and after more than one month trying to obtain this solution I decided that I should ask for some help. I appreciate any reference or some hint that could help me with solving this problem.",['ordinary-differential-equations']
