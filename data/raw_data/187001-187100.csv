question_id,title,body,tags
3473221,What is the $B^{-1}$ if $B^2 -5B + I = 0$ [duplicate],This question already has an answer here : Proving Invertibility and Eigenvalues (1 answer) Closed 4 years ago . I think how I did it was that I did $B (B -5I) = -I$ and then divided both sides by $-1$ to get $B (-B+5BI) = I$ and then said $(-B+5I) = B^{-1}$ . Is this correct or is there a better way of doing it/answer?,"['matrices', 'linear-algebra']"
3473234,Calculating Expected Value with Combinatorics,"A company has 100 employees. For a Christmas team-building exercise, they divide the 100 employees into 25 teams of 4. Randomly and independently, they give an award to 20 employees. -- Find the expected value of the number of awards given to the employees on any given team. What type of distribution is this? So far, I have that there are 100!/(4!^25)*25! combinations for the teams, but don't know where to go from there","['expected-value', 'statistics', 'combinatorics']"
3473300,Please correct if there a mistake on my Explicit formula of 7th Steps Adam-Bashforth-Moulton,"I'm searching in the internet, and i can't find about the formula (Sadly). But if you know or found the amazing sites that gives some formula of Explicit Adam-Bashforth for any higer order (including 7th) in formal equation or code please share it to me. And for my final choice, finally i found the formula by myself. I derive it manually with lagrange interpolation of order 6. (It's true isn't it? Because ABM 7th needs 7 points to constructs its formula) . Here is my formula. Predictor of 7th ABM : $$y^*(x_{n+1})=y_n+\frac{h}{60480}(198721f_n-894576 f_{n-1} +705549 f_{n-2}-688256 f_{n-3}+407139 f_{n-4}-134472 f_{n-5}+19087 f_{n-6})$$ Corrector of 7th ABM : $$y(x_{n+1})=y_n+\frac{h}{60480}(65112 f_n-92922 f_{n-1} +37504 f_{n-2}-20211 f_{n-3}+6312 f_{n-4}-863 f_{n-5}-863 f_{n+1}^*)$$ Please verify my formula if there is a mistake. (On some numbers or anything). Anyway, is it true when i'm using 6th Lagrange Interpolation with 7 points to construct the 7th Order (p=7) Adam-Bashforth-Moulton? Thank in advance!","['numerical-methods', 'ordinary-differential-equations', 'reference-request']"
3473338,CDF of ratio of independent standard normal distributions,"Question; Given two independent standard normally distributed random variables $X,Y,$ find the cumulative density function of $\frac{X}{Y}.$ My attempt: Note that \begin{align*}
F(x) & = P(\frac{X}{Y}\leq x) \\
& = P(\frac{X}{Y}\leq x | Y >0)P(Y>0) + P(\frac{X}{Y}\leq x | Y<0) P(Y<0) \\
& = \frac{1}{2} \left[ P(X\leq xY | Y >0) + P(X\geq xY | Y<0) \right].
\end{align*} However, I have trouble evaluating $P(X\leq xY | Y >0).$ I know the final answer is that the distribution of $\frac{X}{Y}$ is Cauchy. I am trying to prove it by considering CDF and then differentiating CDF to obtain PDF.","['cumulative-distribution-functions', 'statistics', 'normal-distribution', 'probability']"
3473363,Is there any relationship between Simple Group and Field?,"I have studied definition of simple group. I know the fact that concept of normal subgroup is analogous to ideal in ring theory. 
A field is a ring which do not have any nontrivial ideal.
A simple group do not have any nontrivial normal subgroup. So, I have 2 questions
1) Is field and simple group are 2 equivalent concepts?
2) Does every field is a simple group under addition?","['field-theory', 'simple-groups', 'abstract-algebra', 'ideals', 'group-theory']"
3473453,Frenet-Serret and Vector Fields,"The well-known Frenet-Serret equations, $\dot T(s) = \kappa N(s), \tag 1$ $\dot N(s) = -\kappa(s) T(s) + \tau(s) B(s), \tag 2$ $\dot B(s) = -\tau(s) N(s), \tag 3$ where $T = \dot \alpha(s), \tag 4$ $\alpha(s)$ being a unit speed curve in $\Bbb R^3$ with arc-length $s$ , are most often applied to discover and describe properties of such space curves . Given an open set $U \subset \Bbb R^3, \tag 5$ and a vector field $X \in C^\infty(U, \Bbb R^3) \tag 6$ on $U$ , we may of course consider the flow $\phi_X(x, t)$ of $X$ ; the reader will recall it is defined as, more or less, the entire family of integral curves of the vector field $X$ in the sense that $\phi_X(x, 0) = x, \; \forall x \in U, \tag 7$ and $\dfrac{d}{dt}\phi(x, t) = X(\phi(x, t)). \tag 8$ A somewhat natural area of inquiry based upon these two concepts, the Frenet-Serret apparatus and vector fields and their flows, is the relationship 'twixt the Frenet-Serret formulas and the integral curves of $X$ ; that is, finding the expressions for $T(s)$ , $N(s)$ , $B(s)$ , $\kappa(s)$ and $\tau(s)$ in terms of $X$ and related quantities such as its magnitude $\vert X \vert = \langle X, X \rangle^{1/2}$ and its derivatives $\nabla X$ etc. The Question then becomes: Given a (sufficiently smooth) vector field $X$ on an open set $U \subset \Bbb R^3$ , find the vector fields $T(s)$ , $N(s)$ , and $B(s)$ and the scalar quantities $\kappa(s)$ and $\tau(s)$ associated with the integral curves of $X$ , expressed in terms of $X$ and it's associated quantities such as $\vert X \vert$ and so forth. A Few Observations: Given such an open set $U$ and vector field $X$ , of course it is true that the flow $\phi_X(x, t)$ may not exist for all values of $t$ , but this is of no consequence here since all calculations are local in nature.  Indeed, for all $x \in U$ the flow $\phi_X(x, t)$ is defined for sufficiently small values of $t$ , and this is sufficient for the present purposes. A Useful Starting Point may be the observation that $X/\vert X \vert$ is a unit vector field , and that in fact $T(s) = \dfrac{X(\alpha(s))}{\vert X(\alpha(s))\vert} \tag 9$ along the arc-length parametrized integral curve $\alpha(s)$ of $X/ \vert X \vert$ .  Of course, we may also adopt and employ the given parametrization of the integral curves of $X$ by $t$ , as in (7), (8); in fact we have $\dfrac{ds}{dt} = \vert X(\alpha(t)) \vert, \; \dfrac{dt}{ds} = \vert X(\alpha(s)) \vert^{-1}, \tag{10}$ which allow the conversion 'twixt $t$ and $s$ via integration: $s - s_0 = \displaystyle \int_{t_0}^t  \vert X(\alpha(u)) \vert \; du, \; t - t_0 = \displaystyle \int_{s_0}^s  \vert X(\alpha(u)) \vert^{-1} \; du. \tag{11}$ We can also express the unit tangent vector $T$ in terms of the parameter $t$ : $T(t) = \dfrac{X(\alpha(t))}{\vert X(\alpha(t))\vert}. \tag{12}$ In these formulas the reader will recognize that $\alpha(t)$ and $\alpha(s)$ represent the same curves in the geometrical sense, that is, he same paths in $\Bbb R^3$ , though they are differently parametrized.","['vector-fields', 'frenet-frame', 'differential-geometry']"
3473478,Gamma-Distribution-like integral,"I have numerically checked this result and although it doesn't hold to a significant number of decimal places I believe this result is true: $$\Large \int_0^\infty \frac{x^x e^{-x}}{\Gamma(x+2)}\text{d}x = 1$$ This only vaguely resembles a Gamma Distribution, so I do not see how to explain it using distributions. I would imagine complex analysis is the way to go with such an integral but I have no idea where to even begin. I tried using Stirling's (Convergent) Approximation but given how complicated the product expansion is in terms of exponentiated inverted rising factorials, I don't think that is a very nice method.","['integration', 'complex-integration', 'improper-integrals', 'gamma-function']"
3473479,proof there are exactly $\mathfrak c$ open sets in $\mathbb R$,"There are exactly $\mathfrak c$ open sets in $\mathbb R$ In the proof of the above theorem, there is one line stating that let $\mathcal I$ be the sets of all open intervals in $\mathbb R$ , then $|\mathcal I|=\mathfrak c$ . The proof I am reading does not provide the details for the above statement. I am trying to prove it. Is my argument below right? Since all the open intervals are in one of the following form: $$(-\infty,a),(a,\infty),or\ (a,b)$$ So the total number of such intervals correspondes to $2$ times the number of ways to choose one number from $\mathbb R$ plus the number of ways to choose two number from $\mathbb R$ Therefore, $$|\mathcal I|=2{\mathfrak c \choose 1}+{\mathfrak c \choose 2}=2\mathfrak c+ \frac {\mathfrak c(\mathfrak c -1)}2 = \mathfrak c$$ This looks very native, is it correct anyway? Could you provide a rigorous way to prove this?","['elementary-set-theory', 'cardinals']"
3473505,Is this notion of an eigenvector for an $r$-tuple of matrices known?,"Given $r$ complex matrices $A_1,\ldots,A_r$ , each of size $m$ -by- $n$ , we say that a nonzero $x \in \mathbb{C}^n$ is a generalized eigenvector of $(A_1,\ldots,A_r)$ if $$A_1x \wedge \cdots \wedge A_rx = \mathbf{0},$$ that is to say, if there is a non-trivial linear relation between $A_1x,\ldots,A_rx$ . One recovers the usual notion of eigenvector if $r=2$ , $m=n$ , $A_1 = A$ ( $A$ is a complex $n$ -by- $n$ matrix) and $A_2 = I$ . I have seen this generalization if $r=2$ , and $m=n$ . Has it been studied if $r>2$ by any chance? If so, does anyone have some references please? If $V=\mathbb{C}^n$ and $W=\mathbb{C}^m$ , then an $r$ -tuple of $m$ -by- $n$ matrices $(A_1,\ldots,A_r)$ defines an $r$ -tuple $(s_1,\ldots,s_r)$ , where $$s_i \in H^0(\mathbb{P}(V), \mathcal{O}(1) \otimes W),$$ ( $1 \leq i \leq n$ ) corresponds to $A_i$ . Thus for a generic $(A_1,\ldots,A_r)$ , the algebraic set $$s_1 \wedge \cdots \wedge s_r = \mathbb{0}$$ is a representative of $H_{2r}(\mathbb{P}(V),\mathbb{C})$ which is dual to $$c_{r}(\mathcal{O}(1) \otimes W, \mathbb{C}) \in H^{2r}(\mathbb{P}(V),\mathbb{C})$$ via Poincare duality. I owe K. K-M. for the remark on the link with Chern classes.","['generalized-eigenvector', 'algebraic-geometry', 'linear-algebra', 'eigenvalues-eigenvectors']"
3473544,Representability of a functor in the category of schemes,I have read in some places that a functor of points of a scheme is representable if its defined by locally closed or open conditions. I would like to ask for some references about this fact. I don´t know exactly what closed or open conditions are.,"['algebraic-geometry', 'schemes', 'category-theory', 'representable-functor']"
3473552,Krull dimension of the adele ring,"Let $k$ be a number field and $\mathbf{A}_k$ the adele ring of $k$ . What can be said about the Krull dimension of $\mathbf{A}_k$ ? More generally, I do not know if something can be said about the Krull dimension of an infinite product of rings: is it possible to bound it above by the supremum of the dimensions of the rings?","['algebraic-number-theory', 'number-theory', 'adeles', 'krull-dimension', 'commutative-algebra']"
3473553,Prove $x^2+\frac{1}{x^2}=2\cos(2\theta)$,"Prove $x^2+\frac{1}{x^2}=2\cos(2\theta)$ and $x^3+\frac{1}{x^3}=2\cos(3\theta)$ knowing that there exist a number $x$ given angle $\theta$ such that $x+\frac{1}{x}=2\cos(\theta)$ Doesn't really know how to start this problem, thought that I would some how need to use the double angle identities","['algebra-precalculus', 'trigonometry']"
3473585,Equivalent norms on Sobolev spaces. Only function and last derivative needed to define the norm.,"Equip $W_n^{p}[0,1]$ with the norm $$\left\|f\right\|_{W_n^{p}} = \sum_{k=0}^{n}\left\|f^{(k)}\right\|_{L^p}.$$ I want to prove that this norm is equivalent to the norm $$\left\|f\right\|_2 = \left\|f\right\|_{L^p}+\left\|f^{(n)}\right\|_{L^p}.$$ It is obvious that $\left\|f\right\|_2\leq \left\|f\right\|_{W_n^p}$ so I want to find a constant $C>0$ such that $\left\|f\right\|_{W_n^p}\leq C\left\|f\right\|_2$ . I've managed to solve this in the case $n=2$ but I don't know how to generalize this to the case $n>2$ . Solution in the case $n=2$ : Let $f\in W^{2}_p[0,1]$ . Let $\xi_{\mathrm{min}}$ and $\xi_{\mathrm{min}}'$ be points which minimizes $|f|$ and $|f'|$ respectively. Note that these functions are continuous so these points exists. Now Hölder's inequality implies that \begin{align*}
		|f'(x)|& = \left|f'(\xi_{\mathrm{min}}')+\int_{\xi_{\mathrm{min}}'}^{x}f''(t)\, dt\right| \\
		& \leq |f'(\xi_{\mathrm{min}}')|+\int_{0}^{1}|f''(t)|\, dt \\ 
		& \leq |f'(\xi_{\mathrm{min}}')|+\left(\int_{0}^{1}|f''(t)|^{p}\,dt\right)^{1/p}
	\end{align*} and by the mean-value theorem \begin{align*}
		2|f(x)|\geq |f(x)-f(\xi_{\mathrm{min}})|=|f'(\xi)||x-\xi_{\mathrm{min}}|\geq |f'(\xi_{\mathrm{min}})||x-\xi_{\mathrm{min}}|
	\end{align*} for some $\xi$ between $x$ and $\xi_{\mathrm{min}}$ . Integrating this inequality yields \begin{equation*}
		\frac{|f'(\xi_{\mathrm{min}}')|}{2} = \int_{0}^{1}|f'(\xi_{\mathrm{min}}')||x-\xi_{\mathrm{min}}|\, dx\leq 2\int_{0}^{1}|f(x)|\, dx \leq 2\|f\|_{L^p}
	\end{equation*} why \begin{equation*}
		|f'(x)|\leq 4\|f\|_{L^p}+\|f''\|_{L^p} \Rightarrow \|f'\|_{L^p}\leq 4\|f\|_{L^p}+\|f''\|_{L^p}	 \leq 4\|f\|_2
	\end{equation*} Now I don't see a way to generalise this method to the case $n>2$ using induction. For instance if we consider the case $n=3$ then applying the method to $f'$ we obtain $$\|f'\|_{L^p} \leq 4\|f\|_{L^p}+\|f''\|_{L^p}$$ but when we do the same estimate on $f''$ we again get a term containing $f'$ so this reasoning becomes circular. This question has been previously asked in Sobolev space and equivalence of norms .
The answer there however seems to be incomplete as it assumes that $f^{(k)}(0) = 0$ for every $k$ and the above calculation in the case that $n=2$ can be seen as a way to get around this fact using calculus.","['sobolev-spaces', 'functional-analysis']"
3473637,Continuity of the distance from one dimensional subspaces in Banach spaces,"Let $X$ be a Banach space, call $S_X$ its unit sphere and let $x\in X$ be fixed. Is it true that the function $f:S_X\rightarrow\mathbb{R}$ given by $y\mapsto\Vert x+\langle y\rangle\Vert$ (i.e. the distance of $x$ from the subspace spanned by $y$ ) is continuous? So far I only managed to prove its upper semicontinuity. If $\{y_n\} \subset S_X$ is a sequence of vectors converging to some $y\in S_X$ , observe that for each $n$ and each scalar $t$ one has $\Vert x+\langle y_n\rangle\Vert\leq\Vert x-ty_n\Vert$ . Passing to the limit on both sides one gets: $$ \limsup_{n\to+\infty}\Vert x+\langle y_n\rangle\Vert\leq\Vert x-ty\Vert $$ Finally, taking the infimum on the right side over all scalars $t$ leads to the formula: $$ \limsup_{n\to+\infty}\Vert x+\langle y_n\rangle\Vert\leq\Vert x+\langle y\rangle \Vert $$ Which proves the upper semicontinuity. What about lower semicontinuity? Any suggestion or help is much appreciated.","['banach-spaces', 'normed-spaces', 'functional-analysis', 'quotient-spaces']"
3473653,Sum of logarithm reciprocals,"I am looking for an exact formula for the sum : $$\sum_{1<n\leq x}\frac{1}{\log n}$$ My attempt :
Using the Perron's formula for partial Dirichlet series, we have : $$\sum_{1<n\leq x}\frac{1}{n^{s}}=\frac{1}{2\pi i }\int_{c-i\infty}^{c+i\infty}(\zeta(s+\omega)-1)\frac{x^{\omega}}{\omega}d\omega$$ $$=\frac{1}{2\pi i }\int_{c^{'}-i\infty}^{c^{'}+i\infty}(\zeta(z)-1)\frac{x^{z-s}}{z-s}dz$$ Now, we have : $$\sum_{1<n\leq x}\frac{1}{\log n}=\int_{0}^{\infty}\sum_{1<n\leq x}\frac{1}{n^{s}}ds=\frac{1}{2\pi i }\int_{c^{'}-i\infty}^{c^{'}+i\infty}\left(\zeta(z)-1\right)\text{Ei}(z\log x)dz$$ $\text{Ei}(\cdot)$ being the exponential integral function. By the residue theorem, the smooth part of this sum is given by : $$\text{Ei}(\log x)=\text{li}(x)$$ $\text{li}(\cdot)$ being the logarithmic integral function. My question is about the oscillatory part. How does one find an exact formula for this  oscillatory part ?","['complex-analysis', 'number-theory', 'analytic-number-theory']"
3473692,Unbounded operator such that $P^2=P$,"Does there exist an Unbounded operator $P$ on some Banach space $X$ such that $Dom(P)=X$ and $P^2=P$ ? If we don’t require $Dom(P)=X$ , we can easily construct a Unbounded operator on $L^2[0,2π]$ by define $P$ which act on bases as $P\exp(in\theta)=|n|+1$ for all integers $n$ . Any help will be appreciated, thanks.","['projection', 'functional-analysis', 'unbounded-operators', 'closed-graph']"
3473748,Finding the area enclosed by the locus of the vertex of the rectangle at which the normals meet.,"Let a and b be the lengths of the semimajor and semiminor axes of an ellipse respectively. Draw a rectangle whose two sides are tangent to the ellipse and the other two are normal to the ellipse. I want to find the area enclosed by the locus of the vertex of the rectangle at which the normals meet. Solution:- My attempt:- We are required to find the locus of point $(h,k)$ from which two perpendicular lines can be drawn which are normal to the ellipse. Normal to the ellipse at the point $(a \cos{\theta}, b\sin{\theta})$ is given by $ax\sec{\theta}-by\csc{\theta}=a^2-b^2$ and the slope of this normal is given by $m=\frac{a}{b}\tan{\theta}$ Now how to proceed futher? Now by putting $x=h, y=k$ how to eliminate $\theta$ and write the equation in m? And how to arrive at the final answer? If any member knows the correct answer may reply with correct answer. The graph of the vertex of the rectangle at which the normals meet provided to me is as follows Answer provided to me for the required area is $(a-b)^2\pi$ I tried to plot the equation provided in the comment section, in www.wolframalpha.com but it failed. see Here","['self-learning', 'area', 'rectangles', 'conic-sections', 'trigonometry']"
3473749,Proving that $\int_{0}^{1}x^{n-1}(1-x)^n \mathrm dx =\frac{1}{n {2n\choose n}}$,I am working on the following problem and I've arrived at an integral which I need to show equals the proposition. Prove that $\displaystyle \sum_{k=0}^{k=n}\dfrac{(-1)^{k}{n\choose k}}{n+k}=\dfrac{1}{n{2n\choose n}}$ . My Attempt : Let us consider for the sake of convenience the notation ${n\choose k}=\text{C}_k$ $$\begin{aligned}(1-x)^n&=\text{C}_0-\text{C}_1x+\text{C}_2x^2-\text{C}_3x^3+\ldots+(-1)^{n}\text{C}_nx^n\\ \int _{0}^{1}x^{n-1}(1-x)^n \mathrm dx&=\int_{0}^{1}\text{C}_0x^{n-1}-\text{C}_1x^n+\text{C}_2x^{n+1}+\ldots+(-1)^{n}\text{C}_nx^{2n-1}\mathrm dx\\ \int_{0}^{1}x^{n-1}(1-x)^n \mathrm dx&=\sum_{k=0}^{k=n}\dfrac{(-1)^{n}\text{C}_k}{n+k}\end{aligned}$$ I now need  to prove that the integral equals $\left[{2n\choose n}\right]^{-1}$ . But I am unclear on how to proceed with simplifying the integral. I would appreciate any hints apart from usage of Integration by Parts technique. Thanks,"['integration', 'summation', 'binomial-coefficients', 'binomial-theorem']"
3473751,What's the smallest difference in a group?,"In the additive group $\Bbb Z$ we can fairly unambiguously say $1$ is the smallest difference between two elements. I guess a more rigorous statement might be to give $\Bbb Z$ its topology as a subspace of $\Bbb R$ and then to say that the pair $\{1,-1\}$ are the set that share the smallest absolute value: $\{1,-1\}=\{x\in \Bbb Z:\lvert x\rvert=\min\{\lvert x\rvert:x\in \Bbb Z\}\}$ . Is there a general form for the smallest interval in a group?  Does it equal the smallest nonzero element in general?","['group-theory', 'topological-groups']"
3473752,Showing that space of absolutely continuous functions is Banach space,"Let $AC([a, b])$ denote space of absolutely continuous functions $f:[a, b] \to \mathbb{R}$ .
Let's define a norm on this space in the following way $$\lvert\lvert f \rvert \rvert = \int \limits_{a}^{b} \lvert f(x) \rvert + \lvert f'(x) \rvert \, dx. $$ I would like to show that $AC([a, b], \lvert\lvert \cdot \rvert \rvert)$ is a Banach space. Searching for a candidate for the limit of a Cauchy's sequence Let $f_n$ be a Cauchy sequence in $AC([a, b])$ and fix $\epsilon > 0$ . Thus for each $x \in [a, b]$ we do have $\lvert f_n(x) - f_m(x) \rvert < \epsilon$ and $\lvert f_n'(x) - f_m'(x) \rvert < \epsilon$ for $m, n > N_0$ . Because $\mathbb{R}$ is complete thus $f_n(x)$ is pointwise convergent to $f(x)$ and $f_n'(x)$ is pointwise convergent to $f'(x)$ . So we found our candidate. Convergence in norm Let $N_1$ be such that $\lvert f(x) - f_n(x) \rvert < \frac{\epsilon}{2(b-a)}$ and for $N_2$ we have $\lvert f'(x) - f_n'(x) \rvert < \frac{\epsilon}{2(b-a)}$ . Let $N_0 = \max\{N_1, N_2 \}$ and it's obvious that $\lvert\lvert f - f_n \rvert \rvert < \epsilon$ . Now we have to show that $f \in AC([a, b])$ $$\sum \limits_{k = 1}^{N} \lvert f(x_k) - f(y_k) \lvert \le \sum \limits_{k = 1}^{N} \big( \lvert f(x_k) - f_n(x_k) \lvert + \lvert f_n(x_k) - f_n(y_k) \lvert + \lvert f(y_k) - f_n(y_k) \lvert \big) < \epsilon$$ Now we can go with $N \to \infty$ and we do have what we wanted. The same for derivatives. Is my proof true? I'm not sure whether everything I did with derivatives is done correctly. I would appreciate any comments, hints or tips.","['banach-spaces', 'absolute-continuity', 'functional-analysis']"
3473761,Differentiate expressions involving symmetric matrix $\mathbf{D}=\mathrm{diag}(\tau)\Omega\mathrm{diag}(\tau)$ with respect to element of $\tau$,"I have a square $q$ by $q$ symmetric matrix $\mathbf{D}=\operatorname{diag}(\tau)\Omega\operatorname{diag}(\tau)$ where $\Omega$ is a square $q$ by $q$ matrix, and $\tau$ is a vector of length $q$ . Basically $\mathbf{D}$ is a covariance matrix that I am decomposing into a correlation matrix $\Omega$ and a scale vector $\tau$ . I need to differentiate various functions that contain $\mathbf{D}$ with respect to $\tau_g$ , for $g$ in $1, \ldots, q$ .  Specifically I need to find: $$\frac{d(\log(|\mathbf{D}|)}{d\tau_g} $$ and $$\frac{d(\mathbf{b}^T\mathbf{D}^{-1}\mathbf{b})}{d\tau_g} $$ I've been following the matrix cook book ( https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf ) but it mentions under the section for derivatives of matrices, that many of the derivaties don't apply in general for matrices with structure (e.g symmetric matrices such as $\mathbf{D}$ ). Based on that, how would I go about finding the above two derivatives with respect to $\tau_g$ of an expression involving $\mathbf{D}$ ?  Any pointers / tips / useful identities would be appreciated.","['derivatives', 'multivariable-calculus', 'linear-algebra', 'symmetric-matrices']"
3473846,Why is there a preference to use the cumulative distribution function to characterise a random variable instead of the probability density function?,"Perhaps this is but a subtlety but I've noticed that in quite a few definitions in statistics and probability, definitions regarding the distribution of a variable or a sample of data choose to use the cumulative distribution function to characterise random variables as following a specific distribution as opposed to using the probability density function. E.g with the Kolmogorov Smirnov test, we look at the difference between cdfs and not pdfs. Is there a specific reason for this ?","['statistics', 'probability-distributions', 'probability']"
3473865,"Prove that, if $p$ is an odd prime number, then ${f(p)}=\binom{2p-1}{p-1}-1$ is divisible by $p^2$","Prove that, if $p$ is an odd prime number, then ${f(p)}=\binom{2p-1}{p-1}-1$ is divisible by $p^2$ . This is a question that was asked to me in a Permutations and Combinations test. I don't know how to solve it.I have heard that a combinatorial argument can be used to prove this. I would appreciate such an argument as well. [Bill D: to aid search: this is attributed to Babbage. A stronger version is Wolstenholme's theorem ]","['elementary-number-theory', 'combinatorics', 'divisibility']"
3473874,Given three chords on a circle which form an interior triangle what is the area of the triangle formed?,"Using an argument similar to this one, the probability of a triangle being formed is $\frac{1}{15}$ since the number of ways six points on the circumference of a circle can be grouped into three sets of two is $\frac{6!}{2!^33!}=15$ and only one of these ways to group forms a triangle. Another way to think about this is forming all chords from six points and looking at $\triangle GKL$ , the interior triangle formed . Given a triangle is formed by three chords of a circle, what is the area of the triangle in terms of the location of the six points on the circle? I am looking run a simulation of the expected area given three random chords but having a hard time simply solving for the area of the triangle. For simplicity I think we can assume that the circle is a unit circle of radius one?","['trigonometry', 'geometry', 'geometric-probability']"
3473892,Choosing $\alpha$ and $\beta$ so that $f(x) = \frac{\sin (x + \alpha) \sin (x + \beta)}{\cos (x + \alpha)\cos (x + \beta)}$ is independent of $x$,"Consider the function: $$f(x) = \frac{\sin (x + \alpha) \sin (x + \beta)}{\cos (x + \alpha)\cos (x + \beta)}$$ Choose the parameters $\alpha$ and $\beta$ such that $f(x)$ does not
  depend on $x$ . Using Werner's formulas , I obtained: $$f(x) = \frac{\cos(\alpha - \beta) - \cos(2x + \alpha + \beta)}{\cos(2x + \alpha + \beta) + \cos(\alpha - \beta)}$$ If $\alpha = \beta \pm \frac{\pi}{2}$ , $f(x) = -1$ . Is this the only way to obtain a constant value from $f(x)$ ? I can't figure out if there are some alternatives, neither I am able to prove that there are not.","['calculus', 'trigonometry', 'parametric', 'real-analysis']"
3473894,To find number of real roots,"Consider the equation $x^5-5x=c$ where c is a real number. Determine all c such that this equation has exactly 3 real roots. I know that between consecutive real roots of $f$ there is a real root of $f'$ .
Now $f'$ in this case is $5x^4-5$ which always has two real roots. So the claim should be true for all c. But I KNOW IT IS NOT TRUE. Where am I messing up?","['calculus', 'derivatives', 'polynomials', 'real-analysis']"
3473928,Basis for span of tensor power of permutation matrices?,"Set $$
P^{(r)}=\{\sigma ^{\otimes r}\,|\,\sigma\,\, \textrm{ is an $n\times n$ permutation matrix}\}
$$ We know that for $r=1$ $\mathbb{F}P^{(r)}$ is the space of all matrices over $\mathbb{F}$ with constant column and row sum. We can also show that this space is of dimension $(n-1)^2+1$ over any field, and compute an explixit basis for it. Namely $$
\{E_{11}+E_{ij}-E_{1j}-E_{i1}\,|\,1<i,\,j\leq n\}\cup\{\mathbb{I}\}
$$ where $E_{ij}$ is the matrix with $ij$ entry $1$ and $0$ elsewhere and $\mathbb{I}$ is the identity matrix. Is there a similar result for $P^{(r)}$ defined as above, that is, an explicit closed form for its basis for any $r\in \mathbb{N}$ ? And is there a closed form for the dimension of $\mathbb{F}P^{(r)}$ ? I suppose one could use representation theoretic arguments by decomposing $\mathbb{F}P^{(r)}$ whenever it is semisimple, but I'm just wondering if things were as simple as the case where $r=1$ .","['permutation-matrices', 'representation-theory', 'matrices', 'abstract-algebra', 'linear-algebra']"
3474023,"Does $E_{\sigma}[\|\sum_{i=1}^{m}\sigma_ix_i\|_2]\le\sqrt{E_{\sigma}[\sum_{i=1}^{m}\|x_i\|_2]}$ hold, where $|\sigma_i | = 1$?","Let $\sigma := (\sigma_i)_{i = 1}^{m}$ and each $\sigma_i$ be a random variable, taking the values $\pm1$ (precisely they are Rademacher distributed, but that shouldn't matter) and $x_k \in \mathbb{R}^d$ .
In out lecture the professor wrote $$ \tag{1}
E_{\sigma}\left[\left\|\sum_{i=1}^{m}\sigma_ix_i\right\|_2\right]\le\left(E_{\sigma}\left[\sum_{i=1}^{m}\|x_i\|_2\right]\right)^{\frac{1}{2}},
$$ justifying the inequality with Hölders inequality. I fail to see how this holds.
If $$ \tag{2}
\left\|\sum_{i=1}^{m}\sigma_ix_i\right\|_2
\le \left(\sum_{i=1}^{m}\|x_i\|_2 \right)^{\frac{1}{2}}
$$ would hold, the inequality (1) would follow as for concave functions, such as $f := \sqrt{\cdot}$ we have $\mathbb{E}[f(X)] \le f(\mathbb{E}[X])$ by Jensens inequality for a random variable $X$ . I know that by the triangle inequality for the norm $\| \cdot \|_2$ I can get $$ \tag{3}
\left\|\sum_{i=1}^{m}\sigma_ix_i\right\|_2
\le \sum_{i=1}^{m}\|x_i\|_2,
$$ but that is to much in this case.
Also when I choose $m = d = 1$ I get $\| a \|_2 = | a | \le \sqrt{|a|}  \le \| a \|_2^{\frac{1}{2}}$ , which is false for every $a \in \mathbb{R}^{d = 1}$ except $\pm1$ .
If this inequality is wrong as I suspect, what could be meant instead? Maybe $\|x_i\|_2^2$ instead of $\| x_i \|_2$ ? Then next bound in (1) is $\le \sqrt{m} \max\limits_{k = 1}^{m}\| x_k \|_2$ , which makes sense.","['inequality', 'proof-verification', 'probability-theory', 'real-analysis']"
3474104,Is there a geometric interpretation to the Brahmagupta–Fibonacci identity?,"The Brahmagupta–Fibonacci identity says that, for integers $a,b,p,q$ : $(a^2+b^2)(p^2+q^2)=(ap+bq)^2+(aq-bp)^2$ Is there an intuitive geometric way to interpret this? Thanks!","['elementary-number-theory', 'analytic-geometry', 'geometry', 'intuition']"
3474107,"How to find the analytic function $f=u(x,y)+iv(x,y)$","How to find $u$ and $v$ such that $f=u(x,y)+iv(x,y)$ is analytic, knowing that $\cfrac{v}{u}=\phi(y)$ . I tried writing $v(x,y)=u(x,y)\phi(y)$ and then calculating the partial derivatives with respect to $x$ and $y$ : a) $\cfrac{\partial{v}}{\partial{x}}=\cfrac{\partial{u}}{\partial{x}}\phi(y)$ ; b) $\cfrac{\partial{v}}{\partial{y}}=\cfrac{\partial{u}}{\partial{y}}\phi(y)+u(x,y)\phi'(y)$ From the first equation, after replacing $\frac{\partial{v}}{\partial{x}}$ by $-\frac{\partial{u}}{\partial{y}}$ from the Cauchy-Riemann equations, I find that $$u(x,y)=-\int{\phi(y)\frac{\partial{u}}{\partial{x}}dy}$$ Now how should I calculate this integral? Is there another way to find $u$ and $v$ ?","['integration', 'complex-analysis', 'indefinite-integrals', 'partial-derivative']"
3474116,Does sum of real and imaginary part being bounded imply constant,"Let f be a entire function with sum of real and imaginary parts bounded. Is f constant?
(I know Liouville's theorem but can't apply in this situation)","['complex-analysis', 'calculus', 'complex-numbers']"
3474189,Evaluating the limit $\lim_{x\to0}\frac{1}{x^3}\int_{0}^{x}\sin(\sin(t^2))dt$,"$$\lim_{x\to0}\frac{1}{x^3}\int_{0}^{x}\sin(\sin(t^2))dt$$ This is a compound question from me. I don't know how to begin evaluating this limit. My guess would be that I would have to find the value of this Riemann's integral and then plug the result into the limit. Is this the right direction to head? Which brings me to... I am also stuck trying to resolve the integral. I tried integrating by substitution, trying with both $u = t^2$ and $u = \sin(t^2)$ , but both have lead me to finding that $t$ or $dt$ popping back into the equation sooner or later and I'm not quite sure how to handle that. Any hints as to how I can integrate that function? Thank you.","['limits', 'calculus', 'riemann-integration', 'real-analysis']"
3474217,Induction on summation with two variables,"Through simple induction, I would like to prove the following: $\forall x \in \mathbb{N^{>1}}, \forall y \in \mathbb{N^{>0}}, \sum\limits_{i=0}^{y}x^i = \frac{x^{y+1} - 1}{x -1}$ Let $P(y, x)$ represent $ \sum\limits_{i=0}^{y}x^i = \frac{x^{y+1} - 1}{x -1}$ Base Case: $P(y=1, x=2)$ $\sum\limits_{i=0}^{1}2^i = \frac{2^{1+1} - 1}{2 -1}$ $3=3$ Therefore the base case holds Inductive Step: ? I believe this type of problem is called multidimensional induction, and I tried reading some websites about this topic, but I can't comprehend the inductive step. If someone could guide me in the right direction, that would be good. Thanks","['summation', 'induction', 'discrete-mathematics']"
3474241,"Prove that $\bigcap\limits_{x\in\Bbb R}[3-x^2, 5+x^2]=[3,5]$. Where have I gone wrong?","Prove that $\bigcap\limits_{x\in\Bbb R}[3-x^2, 5+x^2]=[3,5]$ . Assume $[a,b]\in\bigcap\limits_{x\in\Bbb R}[3-x^2,5+x^2]$ . Note that $\vert x\vert\ge 0$ . If $x=0$ , then $[a,b]=[3,5]$ . If $\vert x\vert\gt 0$ , then $a\lt 3$ and $b\gt 5$ . This shows that $[3,5]$ must be contained within $[a,b]$ . Therefore it must follow that $\bigcap\limits_{x\in\Bbb R}[3-x^2, 5+x^2]=[3,5]$ . $\blacksquare$ Given sets $A$ and $B$ , I know that the general approach to show that $A=B$ is to demonstrate that $A\subseteq B\wedge B\subseteq A$ . However, I'm a bit confused how that would work in this case. Is this a valid proof? If not, where have I gone wrong?","['elementary-set-theory', 'proof-explanation', 'proof-writing', 'proof-verification']"
3474266,Proving that $\int_{0}^{\infty} \frac{\log(x) }{(1+x^2)^2}dx =- \frac{\pi}{4}$ using residues.,"I need to prove that $\displaystyle\int_{0}^{\infty} \frac{\log(x) }{(1+x^2)^2}\,dx = -\frac{\pi}{4}$ using the Residue theorem. I'm trying to solve using the function $f(z)=\dfrac{\log(z)}{(1+z^2)^2}$ (branch of $\log(z)$ with argument between $-\pi/2$ and $3\pi/2$ )  and integrate over the curve $\gamma=[-R,-r] + \gamma_r +[r,R] + \gamma_R$ , where $\gamma_r(t)=re^{-it}, t\in (0,\pi)$ and $\gamma_R(t)=Re^{it}, t\in (0,\pi)$ . And I've already computed that $\operatorname{Res}(f,i)= -\pi/2 -\pi^2/4$ . Also I think that limit when $R$ goes to $\infty$ , the integral over $\gamma_R$ goes to $0$ . My big problem is the integral over $\gamma_r$ .","['integration', 'complex-analysis', 'contour-integration', 'residue-calculus', 'analytic-functions']"
3474326,Motivations for and applications of Matroid Theory?,"I have taken an interest in this topic recently. If one is unfamiliar with matroids, I will give the definition here. Let $M=(E,\mathcal I)$ where $E$ is a finite set called the ground set and $\mathcal I$ is a collection of subsets of $E$ called the independent sets satisfying three properties: The empty set is independent, i.e. $\varnothing \in \mathcal I$ . Every subset of an independent set is independent, i.e. if $I\in\mathcal I$ and $J\subset I$ , then $J\in\mathcal I$ . If $I,J\in\mathcal I$ such that $|I|>|J|$ , there exists an element $x\in I$ such that $J\cup\{x\}\in\mathcal I$ . The third property is known as the augmentation or exchange property and of course what makes this definition interesting. Matroids are a structure that abstracts and generalizes the notion of linear independence in vector spaces. Now, I am interested in the general theory of matroids, and am using these video lectures as well as Oxley's Matroid Theory to study the topic. However, I am having some difficulty finding motivation as to why these objects are interesting and how they can be applied to other fields of mathematics. My understanding is that this is largely a combinatorial topic, which is one of my weaker areas in mathematics (I am strongest in analysis and topology). I would appreciate it if someone could provide motivation as to why matroids are an interesting topic to study, as well as ways they can be linked and applied to other fields of mathematics, especially topology. I would also appreciate other references, as it seems this topic is not as widely studied as, say, graph theory or enumerative combinatorics.","['matroids', 'motivation', 'applications', 'reference-request', 'combinatorics']"
3474329,a.s. convergence with CLT,"Let's say I have $S_n = \sum_{i=1}^n X_i$ , where $X_{i} = 1$ with probability $p$ and $X_i=0$ with probability $1-p.$ $$\operatorname E(X_1) =p, \quad \operatorname{Var}(X_1)= p-p^2. $$ By the central limit theorem, $\frac{S_n-pn}{\sqrt{n}} \rightarrow Z \sim N(0,p-p^2)$ in distribution. Can it also be said that this convergence is almost sure?",['probability-theory']
3474342,"$T:X \to Y$ linear, $J:Y \to Z$ linear, injective and bounded such that $JT:X\to Z$ is bounded, too. Prove $T$ is bounded.","Let $X,Y,Z$ be real Banach spaces. Let $T:X \to Y$ linear, $J:Y \to Z$ be linear, injective and bounded such that $JT:X\to Z$ is also bounded, too. Prove that T is bounded. My idea was to write $T=J^{-1}(JT)$ and use the closed graph theorem. Since $JT$ is linear and bounded it is closed (has a closed graph). Moreover $J$ is closed. For unbounded operators I found if $J$ injective and closed $J^{-1}$ is closed (see my post If a linear operator $A$ is closed and injective, then its inverse $A^{-1}$ is also closed ) but this doesn't apply here. If I would have surjectivity of $J$ I could use the inverse mapping theorem to show the inverse is linear and bounded and hence closed but I don't think $J$ is surjective.
Anyhow, if I would have $J$ is closed then since a composition of a bounded and closed operator is closed (see Composition of continuous and closed operators is closed ) $T$ would be closed and hence bounded.","['banach-spaces', 'operator-theory', 'functional-analysis']"
3474460,Mathematical Induction Proofs,I've really been struggling with mathematical induction. I've been trying to follow my book the best I can. I feel like my proofs are correct. But then again I have my doubts. If anyone can give me some insight on weather I am doing it correctly or not that would be awesome. I don't want these answered for me I just want some good feedback.,"['induction', 'proof-writing', 'discrete-mathematics']"
3474604,"How do you evaluate $\int_{0}^{1} \frac{(3x^3-x^2+2x-4)}{\sqrt{x^2-3x+2}} \, dx$? [duplicate]","This question already has answers here : How to integrate the product of two or more polynomials raised to some powers, not necessarily integral (5 answers) Problem about evaluating $\int_0^1 {3x^3 -x^2 +2x -4\over \sqrt {x^2-3x+2} } \; dx $ [duplicate] (2 answers) Closed 4 years ago . Saw this problem on a FaceBook meme that said the pin code to his ATM debit card is the solution to the following problem: $$\int_{0}^{1} \frac{(3x^3-x^2+2x-4)}{\sqrt{x^2-3x+2}} \, dx$$ I was trying to see how we could break this up into an easier integrals but nothing comes to mind at first glance. Perhaps complex integration is possible?","['integration', 'complex-analysis', 'calculus', 'definite-integrals']"
3474606,Limit of integral $\lim_{x\rightarrow 0}\frac{\int_{\cos x}^{1}{}\arctan t ^2\ \mathrm dt}{\tan^2 x}$,"$$\lim_{x\rightarrow 0}\frac{\int_{\cos x}^{1}{}\arctan t
^2\ \mathrm dt}{\tan^2 x}$$ There is a part of the answer written as $$\lim_{x\rightarrow 0}\int_{\cos x}^{1}{}\arctan t
^2\ \mathrm dt=\lim_{x\rightarrow 0}\tan^2 x=0$$ How do you even come to this conclusion?","['integration', 'limits', 'calculus']"
3474624,Almost surely convergence for independent random variables and bounded real sequence,"Stumbled upon an exercise in my probability course which was given a couple of years ago as an assignment problem and was trying to solve it. However, I am struggling a bit with probability theory (especially the convergence part and characteristic functions part of the course) and thus I have no idea how to solve this. Problem. Suppose we have $X_{2}, X_{3}, \ldots$ independent random variables and $E[X_{1}] = 1$ . Let $y_{n}$ be a bounded sequence of real numbers. Show that we have $\frac{1}{n} \sum^{n}_{j = 1} y_{j} \longrightarrow{} 1$ if and only if $\frac{1}{n} \sum^{n}_{j = 2} y_{j} X_{j} \longrightarrow 1,$ a.s.","['convergence-divergence', 'probability-theory', 'sequences-and-series']"
3474633,Analytically minimize sum of products,"I am having the following function of 2 variables which I would like to minimize. $$ f(x,y)={\left(n_{1}\right)\left(1- x\left(1-x\right)^{k_{1}}\left(1-y\right)^{k_{2}}\right)^{T}} + {\left(n_{2}\right)\left(1- y\left(1-x\right)^{k_{1}}\left(1-y\right)^{k_{2}}\right)^{T}}$$ Note that $x \in [0,1]$ and $y \in [0,1]$ . In fact, $x$ and $y$ are probability values. T is a positive integer. (T actually denotes number of tests in my actual problem.) $n_1$ and $n_2$ are also positive integers but much larger than T. ( $n_1$ and $n_2$ represents number of members in  2 classes in my actual problem setup). $k_1$ and $k_2$ represents number of defective members in the two classes containing $n_1$ and $n_2$ members each. Thus, $T$ can be viewed as the number of tests made to identify the defective members. The only way I can think of is take the partial derivatives w.r.t $x$ and $y$ and equate them to zero and solve simultaneously. I tried this, but I don't see any ways of solving the resulting 2 equations as they are not analytically simple atleast for me. I also notice that, there is some sort of symmetry in $f(x,y)$ with respect to $x$ and $y$ . My hunch is that this could be made use of to find a minimum. Can someone suggest a possible way of solving it? One more question: Is there any computer software package or online tools that I can use to minimize this function while keeping the generic letter constants as such?","['optimization', 'maxima-minima', 'functions', 'derivatives']"
3474643,Coupon collector's variation with unequal probabilities and uneven number of items required,"I am not sure about this being a negative binomial distribution problem or a variation of Coupon collector's problem. Here's the problem,
Suppose, you want to build a house and I told you that you need certain type and certain number of items to build it. Let's consider you need Bricks $- ~4$ , Cement $-~ 1$ , Metal $- ~1$ , Gravel $- \ 1$ , Wood $-\ 2$ Now, in order to get these items, you need to open a locker and every time you open it you get only one item. Also, know that the locker contains an item that you don't need at all - Feathers. The following are their probabilities (Let's use their initials for the sake of simplicity) B - 30% C - 5% F - 10% G - 10% M - 35% W - 10% The question here is what's the average number of times you will have to open the locker if you want to build a house? The way I thought about solving this is by first multiplying the no of items required for a type by its expected number which is $\frac{1}{probability}$ for that item (for ex. $3.33$ times for Bricks multiplied by the number we want which is $4$ ) and then adding together for all the type of materials we want. I am not so good at this type of problems so please guide me.","['statistics', 'coupon-collector', 'probability']"
3474692,Proving DeMorgan's Rules $\overline{A\cup B} = \overline{A}\cap\overline{B}$,"I need help in checking if my proofs have any logical faults or disconnects.
I am trying to prove that $\overline{A\cup B} = \overline{A}\cap\overline{B}$ I am using the 2 part approach where we show $l.h.s \subset r.h.s$ and $r.h.s \subset l.h.s$ Part 1 Consider $x \in \overline{A\cup B}$ .
This implies $x \notin A\cup B$ .
Which means $x \notin A$ as well as $x \notin B$ .
Above statement can be rephrased as $x \in \overline{A}$ as well as $x \in \overline{B}$ and written as $x \in \overline{A}\cap\overline{B}$ .
This proves that $\overline{A\cup B} \subset \overline{A}\cap\overline{B}$ . Part 2 Consider $x \in \overline{A}\cap\overline{B}$ .
This implies $x \notin A$ as well as $x \notin B$ .
It means $x \notin A\cup B$ .
And it follows that $x \in \overline{A\cup B}$ Hence $\overline{A\cup B} \subset \overline{A}\cap\overline{B}$ . However, I feel that Part2 is just an upside down version of Part1, and hence have a feeling that one of (or either) parts above is not sound. For Part 1, I have an alternate proof though as below:
Part 1a we start with the fact that $A \subset A\cup B$ .
By applying the law of complements reversing the inclusion order, $\overline{A\cup B} \subset \overline{A}$ .
Similarly we can show that $\overline{A\cup B} \subset \overline{B}$ The above two statements can be true only if $\overline{A\cup B} \subset \overline{A}\cap\overline{B}$ . Would really appreciate it if someone can kind of disillusion me here a bit.
Thank you!",['elementary-set-theory']
3474696,Computing $\gcd\{n^k - n^\ell : n \in \mathbb Z\}$,"Computationally, it is possible verify that $n^8 - n^2$ is divisible by $252\ (= 2^2\cdot3^2\cdot7)$ for every $n \in \mathbb Z$ . One crude way of doing so is by looking at the sequence $$
  (\underbrace{0^8-0^2}_0, \underbrace{1^8-1^2}_0, \underbrace{2^8-2^2}_{252}, \dots, 251^8-251^2)
$$ and checking that $252$ divides each term in the sequence (it does). However, is there a simpler way to tell that $n^8-n^2$ is divisible by $252$ ? Moreover, given some polynomial $p(n) = n^k - n^\ell$ (or better yet, given an arbitrary polynomial $p$ with coefficients in $\{1,0,-1\}$ ), is there a way to immediately see the largest $N$ such that $N$ divides $p(n)$ for all $n \in \mathbb Z$ ?","['number-theory', 'polynomials', 'modular-arithmetic']"
3474714,There is no continuous surjective multiplicative map from $M_n(\mathbb H)$ to $\mathbb H$,"Let $\mathbb H$ denote the field of quaternions. I would like to prove that there does not exist any function $f:M_n(\mathbb H)\rightarrow \mathbb H$ for $n\geq 2$ that is continous surjective and multiplicative. I have been thinking about this problem for a while but I can't find any contradiction assuming that such a function does exist. I tried considering preimages for $1,i,j,k$ and toying with them, I also tried infering the values of some specific matrices (the $\lambda I_n$ , the nilpotent matrices, etc...) but I couldn't reach any conclusion. Mostly, I fail to see how to make use of the continuity here. Would somebody have a hint as to how to proceed with this problem?","['matrices', 'linear-algebra', 'quaternions']"
3474727,"If $T(n) = 1 + \sum_{k=0}^{n-1} T(k),$ then $T(n) = 2^n.$ [duplicate]","This question already has answers here : Prove that the sequence with $T(0)=1$ and $T(n) = 1 + \sum_{j=0}^{n-1}T(j)$ is given by $T(n)=2^n$ [duplicate] (5 answers) Closed 4 years ago . Question: Let $T(n)$ be a running time that satisfies the recurrence $$T(n) = 1 + \sum_{k=0}^{n-1} T(k) \quad \text{and}\quad T(0) = 1.$$ Show that $T(n) = 2^n.$ The recurrence above can be obtained in CLRS's Introduction to Algorithms, $3$ rd edition, page $364,$ where the authors discuss rod-cutting problem using Recursive top-down implementation. Does anyone how to obtain the solution for the recurrence of $T(n)$ above?","['computational-complexity', 'recurrence-relations', 'discrete-mathematics']"
3474898,Solve $(D^2 + 3D + 2)y = e^{e^x}$ using method of variation of parameters?,"This question was asked in a test and I'm stuck while solving this using method of variation of parameters. Here's an screenshot of my solution, While finding particular integral I was not able to solve integration of e^e^x?
Can anyone please help me out a bit here. I was not able to understand how to solve it further.","['integration', 'derivatives', 'linear-algebra', 'ordinary-differential-equations']"
3474912,Convex maximization problem (existence and uniqueness),"Short summary: Let $n > k \geq 2$ . I am given an arbitrary full column rank $n \times k$ matrix $W$ whose rows sum up to $1$ . I am trying to find a square matrix $R$ such that $W R$ has certain properties: component-wise, it should be  non-negative and each of its rows should sum up to $1$ . $R$ maximizes the sum of column-wise variances of $W R$ . Does such an $R$ exist? If so, is it unique up to permutation of columns? Detailed statement of the problem: Let $W\in\mathbb{R}^{n \times k}$ (where $n > k$ ) be a full-rank matrix which fulfills $W\mathbb{1}_k = \mathbb{1}_n$ . 
Here, $\mathbb{1}_k$ is the vector of ones with length $k$ . Let $f_W: \mathbb{R}^{k\times k}\rightarrow \mathbb{R}$ be the sum of column-wise variances of $W R$ , i.e., $$f_W(R) = \sum\limits_{l=1}^k \frac{1}{n-1} \sum\limits_{i=1}^n \left(\left(W R\right)_{i,l} - \frac{1}{n} \sum\limits_{j=1}^n \left(W R\right)_{j,l}\right)^2 $$ If I calculated correctly, the Hessian of each of the $k$ summands of $f_W$ equals $2$ times the covariance matrix of $W$ , and therefore $f_W$ is convex as the sum of convex functions. I am wondering whether the optimization problem $$\begin{array}{ll} \text{maximize} & f_W(R)\\ \text{subject to} & R\mathbb{1}_k = \mathbb{1}_k\\ & W R \geq 0\end{array}$$ where the inequality is component-wise, has a solution and whether this solution is unique up to permutation of columns. I think the answer is ""yes"" if $k=2$ , but I have not been able to say much about the general case $k > 2$ .
Can anyone give me a hint on how to tackle this? Two other expressions for the objective function: We can also write $f_W$ as $$f_W(R) = \frac{1}{n-1} \left(\sum\limits_{i=1}^n \sum\limits_{l=1}^k \left(\left(WR\right)_{i,l} - \frac{1}{k}\right)^2 - n\sum\limits_{l=1}^k \left(\frac{1}{n} \sum\limits_{j=1}^n \left(W R\right)_{j,l} - \frac{1}{k}\right)^2\right).$$ So, to maximize $f_W$ , the entries of $WR$ should be as far from $\frac{1}{k}$ as possible under the constraints while its column means should be close to $\frac{1}{k}$ . Another expression for $f_W$ is $$f_W(R) = \frac{1}{n-1} \left(\|WR\|^2 - \frac{1}{n}\sum\limits_{l=1}^k \left(\sum\limits_{j=1}^n \left(WR\right)_{j,l}\right)^2\right) = \frac{1}{n-1} \left(\|WR\|^2 - \frac{1}{n} \|\mathbb{1}^\top_n WR\|^2\right),$$ where $\|\cdot\|$ denotes the Frobenius norm.","['matrices', 'optimization']"
3474926,Linear representation of special euclidean group as subgroup of GL2(C),"I came across this question: Find an isomorphism from the group of orientation preserving isometries of the plane to some subgroup of $GL_{2}(\mathbb C)$ . I'm having trouble with finding such isomorphism. Mainly, I'm having trouble with finding some representation of those isometries in a way that would respect the group structure. I know that you can represent any isometry of the plane using a $3\times 3$ real matrix, and I want to somehow use this representation in order to construct a new one (maybe since I'm looking at a smaller group and can also use complex numbers I can somehow use a smaller matrix), but I'm not entirely sure on how to do this. Any help would be appreciated - I'd like to know how one can approach such a problem. Thanks in advance","['representation-theory', 'geometry', 'geometric-group-theory', 'group-theory', 'isometry']"
3474942,"Solve $\operatorname{diag}(x) \nabla f(x)= A x, f(0)=0$","How to solve the following equation: $$
\operatorname{diag}(x)  \nabla f(x)= A x
$$ where $f: \mathbb{R}^n \to \mathbb{R}$ and $A \in \mathbb{R}^{n \times n}$ with condition $f(0)=0$ .  Assume column vectors are used.  Here $\operatorname{diag}(x)$ for a vector $x$ is a squared matrix where $x$ forms a main diagonal. $\nabla f(x)$ is a gradient of $f$ . Here is my approach. $$
\nabla f(x) = \operatorname{diag}^{-1}(x)  A x.
$$ Now using FTC and choosing $r(t)=(1-t)0+t*x$ \begin{align}
f(x)=f(r(1))&= \int_0^1  \nabla f(r(t)) \cdot r'(t) \,\mathrm dt\\
&= \int_0^1  x^T \operatorname{diag}^{-1}(tx)  A tx \,\mathrm dt\\
&= x^T \operatorname{diag}^{-1}(x)  A x\\
&= \mathbb{1}^TA x
\end{align} where $\mathbb{1}$ is a vector of of all ones. However, upon checking we have that $$
\nabla f(x)= \nabla  \mathbb{1}^TA x= A^T  \mathbb{1}
$$ and now checkign the differential equation $$
\operatorname{diag}(x)  A^T  \mathbb{1}= A x .
$$ However, I don't think the above equality is true.   I am not sure where I am making a mistake. Edit 2: From one of the answers, it appears that the solution exists only if, $A$ is a diagonal matrix.","['multivariable-calculus', 'linear-algebra', 'partial-differential-equations']"
3474978,Tubular Neighborhoods vs. Regular Neighborhoods,"I am trying to understand the difference between a tubular neighborhood and a regular neighborhood. I have a theorem I want to use that applies to regular neighborhoods, and I am unsure if it will still apply to a tubular neighborhood. Hudson's definition for a regular neighborhood is: Let $X$ be a polyhedron contained in the p.l. manifold $M$ , $N \subset M$ . $N$ is a regular neighborhood of $X$ in $M$ if:
1. $N$ is a closed neighborhood of $X$ in $M$ .
2. $N$ is an m-manifold
3. $N$ collapses to $X$ (From Hudson, Piecewise Linear Topology) Rolfsens definition for a tubular neighborhood is: The tubular neighborhood of a submanifold $M^m \subset N^n$ of another manifold $N^n$ is an embedding $t: M \times B^{n-m} \rightarrow N$ such that $t(x,0)=x$ whenever $x \in M$ (From Rolfsen, Knots and Links) My issue is that tubular neighborhoods are open, whereas regular neighborhoods are closed. My understanding is that the two concepts are the same and tubular neighborhoods are a special case of regular neighborhoods. For reference: I am working in a compact, orientable 3 manifold.","['knot-theory', 'general-topology', 'low-dimensional-topology']"
3475016,Looking for a proof for the value of the residue.,"Trying to simplify a calculation I have found by numerical experiments the following interesting result: $$
\underset{z=1}{\operatorname{Res}}\frac{z^{p-1}}{(z^n-1)^q}=
\frac qp\frac{\left(\frac pn\right)^{\underline{q}}}{q!}
\equiv\frac qp\binom{\frac pn}q,
$$ where $p,q,n$ are positive integers and $x^{\underline r}=x(x-1)\cdots(x-r+1)$ means the falling factorial. Is there a simple way to prove this?","['complex-analysis', 'residue-calculus', 'laurent-series']"
3475030,Solve functional equation $f(x)^2 = f(2x)$ if $f$ is not differentiable,"I'm trying to solve such task: Given a random variable 𝜉, 𝔼𝜉=1. It is known that 𝑃(𝜉>2𝑇|𝜉>𝑇)=𝑃(𝜉>𝑇) ∀𝑇>0. How to find 𝐹𝜉? During this I came to such functional equation: $f(x)^2 = f(2x)$ where $f(x) = 1 - F_\xi(x)$ I managed to find that if $f$ is differentiable than $f(x) = e^{-x}$ using derivatives and Taylor series, but what if $f$ is not differentiable? It's is possible to find same answer by solving functional equation, but I can't prove that it's the only answer. I also got a suggestion to research this functions in $0$ and in positive semi-neighborhood, but I have no idea how to use it. Can I get any help in proving that $e^{-x}$ is the only answer when $f(x)$ is not differentiable or proving that it's always differentiable? EDIT: Please consider facts, that: $F_\xi(x)$ is non-decreasing, ${\displaystyle \lim _{x\to -\infty }F_{\xi}(x)=0, \lim _{x\to +\infty }F_{\xi}(x)=1.}$ So $f(x)$ will be non-increasing, ${\displaystyle \lim _{x\to -\infty }f(x)=1, \lim _{x\to +\infty }f(x)=0.}$","['functional-equations', 'probability-theory']"
3475065,"How do I control only the ""second oscillations"" of a curve?","I have the following ""elastic out"" curve: $$f_b(t)=1+2^{-10t}\cdot \sin\left(\frac{(t-\frac{b}{4}) \cdot 2π}{b}\right)$$ I only need to use it in the interval $\left(0, 1\right)$ (values for $0$ and $1$ do not matter). It already describes the oscillation after ""getting to"" $y=1$ quite well, however, I am facing issues trying to design the dampening according to my needs and transforming this curve in general. Problem Above you can see what $b$ controls - I would say the dampening of the oscillation but also not really. What I want to have control over ideally is only the dampening about $1$ after the function comes back to $y=1$ for the first time, so I want to keep the initial bump past $y=1$ from say $b=0.4$ , but I want more overshoot past $y=1$ afterwards. This is a terrible sketch, but I hope that you see what I mean. The red graph would be what I have now with $b=0.4$ and the blue graph is what I am trying to achieve. I tried a bunch of edits to the equation, but nothing I did got me close to what I want. The graph should keep oscillating about $y=1$ after some time. Observations Changing the factor before the $sin$ will obviously allow me to stretch and compress the whole graph, but that is not what I want. Application The point of this curve is to describe motion from one place to another. An object is supposed to move from say $A$ to $B$ . $A$ is at $y=0$ and $B$ is at $y=1$ . $y=1.1$ would mean that the object moved past the destination (past $B$ ), which is why this is ""elastic"". My goal is to keep the intial elasticity of the bounce, i.e. the overshoot past $B$ , but I also want to have more bounciness when the object oscillates about point $B$ after going beyond it initially.","['curves', 'algebra-precalculus', 'functions', 'graphing-functions']"
3475068,binomial identity: elementary proof possible?,"For any $z \in D(0,1) \subseteq \mathbb{C}$ , the series identity $$(1-z)^{1/2} = \sum_{n=0}^\infty {1/2 \choose n} (-z)^n = 1-\sum_{n=1}^\infty \left|{1/2 \choose n}\right|z^n$$ holds. Letting $z \to 1-$ along the real axis, we deduce (aided by the monotone convergence theorem, or an ad hoc argument) that $$\sum_{n=1}^\infty \left|{1/2 \choose n}\right| = 1.$$ Can this identity be proven in an elementary (e.g. combinatorial) way?","['complex-analysis', 'binomial-coefficients', 'combinatorics']"
3475110,Determine if this statement about Big O notation is true or not.,"$f(n) = n^2 + n^{0.5}$ $g(n) = [g(n-1)]^2 + [g(n-2)]^2$ for $n \geq 3$ , where $g(1) = 1$ and $g(2) = 2$ The statement: $2^{2^{f(n)} }= Ω(g(n))$ The $\lim_{n \rightarrow \infty} \frac{2^{2^{f(n)} }}{g(n)}$ can't be computed easily since $g(n)$ has a recurrence relation. How do I approach it?","['asymptotics', 'discrete-mathematics']"
3475279,Expected exit time of ball of Brownian motion,"I want to do the following exercise of Durrett - Brownian motion and Martingales in Analysis : Im pretty sure that we have to use the optional stopping theorem for the martingale $M_t= |B_t|^2-td$ . If we could use the OST, we would have $$E^x[M_T] =E^x[M_0]$$ which would give us the claim. But to use the OST in that way we need that either $M_t$ is uniformly integrable or that $T$ is bounded. Well, $T$ is not bounded and I don't think that $M_t$ is uniformly integrable either. So what to do here?","['martingales', 'stopping-times', 'brownian-motion', 'probability-theory']"
3475285,Isn't 1 congruent to -1?,"I have read something about Wilson's theorem , but I found that $$(n-1)!\ \equiv\ -1 \pmod n$$ I thought, that $-1\equiv 1\pmod x$ , but in all literature, I only found upper theorem. My reason why I am asking this is that $-1$ gives the same remainder as $1$ when dividing with some number. (Remainder can't be negative.) Example : $$-1\div5=0 \text{ (remainder = 1)}$$ $$1\div 5=0\text{ (remainder = 1)}$$ Question: Is it true, that $-1\equiv 1 \pmod x$ ? Thank you in advance! P.S. We can rewrite the title of the question into ""Why is true $(n-1)!\ \equiv\ -1 \pmod n$ and not $(n-1)!\ \equiv\ 1 \pmod n$ ?""","['number-theory', 'modular-arithmetic']"
3475304,"Prove that the series $\sum_{x∈X}(f(x) + g(x))$ is absolutely convergent, and $ \sum_{x∈X}(f(x) + g(x)) = \sum_{x∈X}f(x) + \sum_{x∈X}g(x)$","Let $X$ be an arbitrary set (possibly uncountable), and let $f:X → R$ and $g: X → R$ be functions such that the series $\sum_{x∈X} f(x)$ and $\sum_{x∈X} g(x)$ are both absolutely convergent.
  Prove: The series $\sum_{x∈X}(f(x) + g(x))$ is absolutely convergent, and $$ \sum_{x∈X}(f(x) + g(x)) = \sum_{x∈X}f(x) + \sum_{x∈X}g(x)$$ . If the set $X$ is finite then I have the result. If it is countable, then $h: N \to X$ is a bijection and $\sum_{n=0}^{\infty} (f+g)(h(n))$ is absolutely convergent by definition. In other words, $\sum_{n=0}^{\infty} |f(h(n)+g(h(n))| = L$ . Since it is known that $\sum_{x∈X} f(x)$ and $\sum_{x∈X} g(x)$ are both absolutely convergent then $\sum_{x∈X} |f(x)| = M$ and $\sum_{x∈X} |g(x)|=K$ . I don't know how to proceed. It seems to me I found a solution for the uncountable case here Proving Proposition 8.2.6 from Terence Tao's Analysis I but still I got the problem with the countable one.(Frankly speaking I am not entirly getting the uncountable either).","['elementary-set-theory', 'sequences-and-series', 'analysis', 'real-analysis']"
3475330,Set of values of $x$ for which $1+\log x<x$,"Find the set of values of $x$ for which $$1+\log x<x$$ $$
x>0\\
f(x)=\log x+1-x<0\\
f(1)=0\\
f'(x)=\frac{1}{x}-1\\
x>1\implies f'(x)<0\\
0<x<1\implies f'(x)>0\\
\implies x\in(1,\infty)
$$ But, my reference gives the solution $x\in(0,1)\cup(1,\infty)$ , why am I missing the additional domain ?","['inequality', 'derivatives', 'logarithms']"
3475333,"How many rectangles, whose boundary equals or exceeds that of a $3{\times}3$ square, can fit into a $9{\times}9$ square.","I want to know how many rectangles can fit inside a $9$ by $9$ square. However, I want to exclude any rectangles that are not greater than or equal to a $3$ by $3$ square. By this, I mean excluding rectangles such as $(2*3),(3*2),(3*1),(3*1),(2*2)$ ...and so on because the are not equal to, or can be fully surrounded by, a $3*3$ square. I have arrived at a figure of $784$ by visualizing the problem and crunching the numbers, but I would like a sounder theoretical approach that makes sense.","['combinatorics', 'geometry']"
3475342,Néron-Tate height pairing induces positive definite quadratic form,"Let $E$ be an elliptic curve. Let $\langle \cdot , \cdot \rangle$ be the canonical height paring: $\langle P , Q \rangle = 1/2(\hat{h}(P + Q) − \hat{h}(P ) − \hat{h}(Q))$ Let $P_1 , . . . P_n$ be a basis for $E(\Bbb Q)/{\rm Torsion}(E(\Bbb Q))$ I try to prove that the quadratic form $F=\sum_{1\le i,j\le n}  \langle P_i , P_j \rangle x_ix_j$ is definite positive. For $n=2$ it is easy to prove it using $\langle P , Q \rangle \le \sqrt[]{\hat{h}(P )\hat{h}(Q)}$ , but how to generalize for any $n\ge 1$ ? Matricial approach didn't help as it gets complicated to compute the determinant. Thanks in advance for any hints of help.","['positive-definite', 'number-theory', 'elliptic-curves', 'quadratic-forms']"
3475357,Inequality for the matrix infinity norm,"Consider the matrix $\ell_{\infty} \to \ell_{\infty}$ operator norm for some
matrix $A \in \mathbb{R}^{m \times n}$ , given by $$
\| A \|_{\infty} := \sup_{x: \| x \|_{\infty} = 1} \| A x \|_{\infty} :=
\max_{j \in [m]} \| A_{i, :} \|_1.
$$ Question : Prove (or disprove via counterexample) the following inequality: $$
\left\| V \begin{bmatrix} I_{k_1} & 0 \\ 0 & -I_{k_2} \end{bmatrix}V^\top \right\|_{\infty} \leq C \| V V^\top \|_{\infty},
$$ for $V$ satisfying $V^\top V = I$ and $V \in \mathbb{R}^{n \times k}$ , with $k_1 + k_2 = k$ . This is not a homework problem, and I have been unable to come up with a counterexample (for randomly generated $V$ , I find $C < 2$ ). I'm looking for
some $C$ which is ideally in the range $o(\sqrt{k})$ .","['normed-spaces', 'matrices', 'linear-algebra', 'matrix-norms', 'inequality']"
3475364,Can Collatz conjecture be formulated as totality problem for a 2-tag system?,"I have just read about Terence Tao's approaches to Collatz conjecture, and I have a stupid question. If binary representations of numbers in the hailstone sequence for Collatz conjecture can be written as a $2$ -tag system ( $a \to bc$ , $b \to a$ , $c \to aaa$ ), and $m$ -tag systems are Turing complete for $m>1$ , and Collatz conjecture is a sort of halting problem in this framework (there is a halting criterion), and ""deciding whether a particular algorithm for Turing machine will/won't halt on every input"" is a totality problem, which is also undecidable — can a proof of undecidability of Collatz conjecture be approached this way? 
What is the major problem with this line of thought?","['collatz-conjecture', 'number-theory', 'decidability']"
3475397,Finding number of zeros of $f(z) = z^{2019} + 8z + 7$ inside the unit disk.,"I'm trying to find the number of zeros of $f(z) = z^{2019} + 8z + 7$ inside the unit disk. I've tried to apply Rouche's Theorem, but no combination of terms seems to work. Also, the Argument Principle seems to fail because when I was computing the winding number of $f(\gamma)$ around the origin, I realized $f$ has a zero on the unit disk. Any help on this problem would be greatly appreciated!",['complex-analysis']
3475431,Embedding of $U(n)$ in $SO(2n)$,"I want to study the embedding of $U(n)$ in $SO(2n)$ . I write $Z=X+iY\in U(n)$ and use the realification map \begin{align*}
\varphi:C^n\rightarrow R^{2n}:X+iY\mapsto\begin{bmatrix}
X &-Y\\
Y & X
\end{bmatrix}.
\end{align*} I note that \begin{align*}
\begin{bmatrix}
X & -Y\\
Y & X
\end{bmatrix}^T\begin{bmatrix}
X & -Y\\
Y & X
\end{bmatrix}=\begin{bmatrix}
X^TX+Y^TY & -X^TY+Y^TX\\
-Y^TX+X^TY & Y^TY+X^TX
\end{bmatrix}=\begin{bmatrix}
I & 0\\
0 & I
\end{bmatrix}
\end{align*} since $Z^*Z=(X^T-iY^T)(X+iY)=X^TX+iX^TY-iY^TX+Y^TY=I$ . My question is: how to determine the orthogonal projection operator $\pi$ of any $A\in R^{2n\times 2n}$ on the tangent space of $\varphi U(n)$ at $\varphi Z$ ? Attempt: I note that any element of the tangent space of $\varphi U(n)$ at $\varphi Z$ must be on the form \begin{bmatrix}
A & -B\\
B & A
\end{bmatrix} and must satisfy $A^TX+X^TA+B^TY+Y^TB=0$ and $-A^TY+X^TB+B^TX+Y^TA=0$ . The last relations are from the time derivatives of the matrix equations above. I am stuck here. How to orthogonally project an arbitrary matrix on \begin{align}
\left\{\begin{bmatrix}
A & -B\\
B & A
\end{bmatrix}\in R^{2n\times 2n}\,|\, A^TX+X^TA+B^TY+Y^TB=0,-A^TY+X^TB+B^TX+Y^TA=0\right\}?
\end{align}","['lie-groups', 'differential-geometry']"
3475496,Heuristics of counting twin primes,"I was reading on counting the number of twin primes and I found this heuristic explanation on the Hardy-Littlewood conjecture, which states that $$\pi_2(x)\sim 2\Pi_2 \frac{x}{\log^2(x)},$$ where $\pi_2$ denotes the number of twin primes smaller than $x\in[0,\infty)$ and $$\Pi_2=\prod_{p\geq 3}\left(1-\frac{1}{p}\right)^{-2}\frac{p-2}{p}.$$ The explanation given goes as follows: The prime number theorem states that $\pi(x)\sim\frac{x}{\log(x)}$ where $\pi(x)$ denotes the number of primes smaller than $x\in[0,\infty)$ . Then, we say that the probability that an integer $a\in[1,n]$ is $\frac{1}{\log(n)}$ . Assuming that $a$ and $a+2$ being prime are independent events, the probability of both of them being prime is $\frac{1}{\log^2(n)}$ . However, this is obviously not true since (for example) if $a$ is prime, $a+2$ is more likely to be prime, since it is not divisible by $2$ . We refine this model as follows: given a ""small"" integer $w>0$ we say that the probabily of an integer $a\in[1,n]$ being prime is $0$ if some prime $p\leq w$ divides $a$ and $$\prod_{p\leq w} \left(1-\frac{1}{p}\right)^{-1}\frac{1}{\log(n)}$$ otherwise.
Then, we count the number of twin primes smaller than $n$ using this model to get $$2\prod_{p\leq w,\ p\neq 2}\left(1-\frac{1}{p}\right)^{-2}\frac{p-2}{p}\frac{n}{\log^2(n)}.$$ Letting $w\to\infty$ we get the result in the conjecture. What I don't understand is the final counting part. According to my source, the $2$ appears because if $a$ is prime, $a+2$ is odd, and the factor $\frac{p-2}{p}$ appears because out of $p$ numbers, only $p-2$ can be the biggest of a twin prime because the ones congruent to $0$ or $2$ modulus $p$ cannot be. I understant this facts but I don't know how to apply them to calculate the estimated number of twin primes smaller than $n$ . Any insight would be appreciated.","['twin-primes', 'prime-numbers', 'number-theory', 'analytic-number-theory', 'probability']"
3475524,Why is $\frac{1}{10}\left(\frac{9}{10}+\frac{8}{9}+\dots+\frac{1}{2}\right)\approx \frac{\sqrt{2}}{2}$?,"When doing a stochastics problem recently I noticed that \begin{equation*}
\frac{1}{10}\sum\limits_{k=1}^9 \frac{k}{k+1}=\frac{1}{10}\left(\frac{9}{10}+\frac{8}{9}+\dots+\frac{1}{2}\right)=0.7071031746
\end{equation*} while \begin{equation*}
\frac{\sqrt{2}}{2}=0.7071067812\dots
\end{equation*} These two quantities are amazingly close to each other (in fact, the discrepancy is only about $5\cdot 10^{-4}\%$ ) and thus, I wondered if there is any deeper reason behind this. Is there some relationship between those two quantities that explains why they are so close to each other or is it just ""pure luck""?","['number-theory', 'approximation']"
3475538,How to draw the trajectories of the solutions in the canonical basis?,"I'm trying to understand the steps to solve this exercise: Consider the following differential system $$\begin{cases}{x'=-2 x-y} \\ {y'=3 x+y}\end{cases}$$ Draw the trajectories of the solutions in the canonical basis. Here is the solution given by my professor: In the basis $\left \{\begin{pmatrix}2 \\ -3 \\ \end{pmatrix}, \begin{pmatrix}0 \\ \sqrt 3 \\ \end{pmatrix} \right \}$ , we have to solve $$\begin{bmatrix}f' \\ g' \\ \end{bmatrix} = \begin{bmatrix} -\dfrac{1}{2} & \dfrac{\sqrt 3}{2} \\ -\dfrac{\sqrt 3}{2} & -\dfrac{1}{2} \\ \end{bmatrix} \begin{bmatrix}f \\ g \\ \end{bmatrix}$$ Setting $z = f + i g$ , we have to solve $$z' = \left  (-\frac{1}{2} - i \frac{\sqrt 3}{2} \right)z$$ We have $$\begin{bmatrix}x' \\ y' \\ \end{bmatrix} = \begin{bmatrix} -2 & -1 \\ 3 & 1 \\ \end{bmatrix} \begin{bmatrix}x \\ y \\ \end{bmatrix}$$ The characteristic polynomial has two complex roots $$\lambda = -\frac{1}{2} \pm i \frac{\sqrt 3}{2}$$ Could you please explain how to come up with the basis $\left \{\begin{pmatrix}2 \\ -3 \\ \end{pmatrix}, \begin{pmatrix}0 \\ \sqrt 3 \\ \end{pmatrix} \right \}$ ? Thank you so much for your help! Update: I include the screenshot of solution.","['proof-explanation', 'linear-algebra', 'ordinary-differential-equations', 'eigenvalues-eigenvectors']"
3475552,Does Khinchin's constant have an analog for nested radicals?,"Edit: as multiple users have pointed out, the premise of my question assumes some canonical representation of real numbers as infinite nested radicals. There does not seem to be any such representation. Khinchin's constant is the peculiar number $K$ such that for almost any real number $x$ , if we write out $x$ 's continued fraction representation $$x = a_0+\frac1{a_1+\frac1{\ddots}}$$ Then we have $$\lim_{n\to\infty}\sqrt[n]{a_1a_2\dots a_n} = K$$ My question begins with the fact that any real number $x$ may be written as $$x = b_0+\sqrt{b_1 + \sqrt{b_2+\dots}}$$ And, given the similarity between continued fractions and nested radicals as iterated function systems/contractions, I would think there must be some number $S$ and non-trivial function $f$ such that for almost all $x$ we have $$\lim_{n \to\infty}f(b_0,b_1 \dots b_n) = S$$ Where $f$ is probably defined independent of $b_0$ . I nervously tag this post ergodic-theory because I know Khinchin relied on it in the proof for his constant.","['nested-radicals', 'ergodic-theory', 'real-analysis', 'iterated-function-system', 'continued-fractions']"
3475587,What is the expected distance between endpoints of $n$ line segments of length 1 connected at random angles?,"Start at the origin and take n line segments and connect them end to end each at random angles. What is the expected distance of the endpoint from the origin of the resulting path? Clearly when $n=1$ the expected distance is $1$ . When $n=2$ we can find the expected distance by integrating $$\frac{1}{2\pi} \int^{2\pi}_0 2 \sin \left(\frac{x}{2} \right) dx = \frac{4}{\pi}$$ For $n=3$ , it is easy to simulate and find the distance is approximately $1.58$ . For $n=4$ the simulated distance is $1.82$ and for $n=5$ we get approximately $2.02$ . Can one find a general formula for any $n$ ?","['geometric-probability', 'random-walk', 'geometry', 'multiple-integral', 'trigonometry']"
3475629,Find volumes of a unit sphere separated by plane $\frac{x}{\sqrt 2}$ $+$ $y + \frac {z}{\sqrt 2} = 1$,"I'm having some trouble figuring out how to compute this answer.  The problem is as follows: The plane $\frac{x}{\sqrt 2}$ $+$ $y + \frac {z}{\sqrt 2}$ $ = 1$ cuts a unit sphere centered at the origin into 2 pieces.  Find the volume of both parts. I tried to solve this problem using cylindrical coordinates and a triple integral, but the issue is I don't know the projection of the plane intersection on the xy plane so it is difficult to see what r goes from.  My $\theta$ goes from $0$ to $2\pi$ and z is the difference of the unit sphere minus the plane equation.",['multivariable-calculus']
3475643,What is the right way to calculate $ \partial_z\frac{1}{\bar{z}} $?,"In the appendix B of a physics paper arXiv: 1902.01434, it says $$ \partial_z\frac{1}{\bar{z}}=\partial_{\bar{z}}\frac{1}{z}=2\pi\delta(z)\delta(\bar{z}), $$ same as 2-dimensional delta function (complex plane) and A puzzle with derivative of delta-functions .
However, from the definition of Wirtinger derivatives, one can also get $$ \partial_z\frac{1}{\bar{z}}=0, $$ such as What is $\partial_z \frac{1}{\bar{z}}$? .
So, my question is, which is the right way to do the calculation? For example, we know $\partial_{z}\bar{z}$ is not differentiable, but we can still have $$ \partial_z\bar{z}=\partial_z \frac{1}{\frac{1}{\bar{z}}}=-2\pi\bar{z}^2\delta(z)\delta(\bar{z}), $$ what is wrong here? What about $\partial_z\frac{\bar{z}-a}{\bar{z}-b}$ ? I'm really confused here, thank you for any help.","['complex-analysis', 'derivatives', 'dirac-delta']"
3475645,Conditional Expectation in Poisson Distribution,"So I am currently in the process of learning basic distributions of random variables and I have been trying to understand the following scenario (distilled for sake of brevity): The number of people who enter an elevator on the ground floor is a Poisson random variable with mean $10$ . If there are $N$ floors above the ground floor and if each person is equally likely to get off at any one of these $N$ floors, independently of where the others get off, compute the expected number of stops that the elevator will make before discharging all of its passengers. So, my thought process is as follows. Let $X=$ number of people who enter the elevator. $X \sim Poisson(10)$ . Let $Y=$ the number of stops it takes in total. I define the indicator variable $I_n$ such that it equals $1$ if the elevator stops at a given floor and $0$ otherwise. Then, $Y = I_1 + ... + I_N$ . From what I understand, the goal is to find $E[Y]$ since this essentially gives the expected number of times the elevator will stop. Now, $E[Y] = \sum_{n=1}^N E[I_n] = NE[I_n]$ . Thus, I need to find $I_n$ but this is where I am stuck. I have attempted to condition on $X$ (the number of people who entered the elevator) since naturally, the number of stops it takes depends on the number of people that entered to begin with, but then I am not sure how to go after defining $I_n$ in terms of the conditional expectation: $E[I_n] = E[E[I_n | X = m]]$ . I know that I need to find $E[I_n | X = m]$ somehow, but I am not sure how to do so. This is not a homework question and I am really trying to understand the properties of expectation and how to work with distributions on a deeper level rather than just memorizing a strategy for solving these problems and I would greatly appreciate any help.","['statistics', 'probability-distributions', 'conditional-expectation', 'probability']"
3475704,"Define $f\colon\mathbb R\times \mathbb R\to\mathbb R$ by $f(a,b)=a-b$. Is $f$ associative?","I have 3 questions about this question. First of all I'm confused about the notation. My understanding is that the first part( $f\colon\mathbb R\times \mathbb R\to\mathbb R$ )  means that for any combination of 2 real number $(a,b)$ , it will map to one single Real number.  The second part ( $f(a,b)=a-b$ ) means that the mapping of $(a,b)$ will be ( $a-b$ ).  Am I correct? Second of all, I'm confuse about what this question is even asking.  What does define mean? How do you define a function? Isn't the function already defined in the question Lastly, I know for example that $a-b-c$ is not associative since $(a-b)-c$ is not the same thing as $a-(b-c)$ , however when we only have 1 subtraction, wouldn't it be associative by default since there is only one way to add parentheses to the function (ex.// $(a-b)$ ).","['functions', 'associativity', 'discrete-mathematics']"
3475708,"If $m$ and $n$ are integers, show that $\left|\sqrt{3}-\frac{m}{n}\right| \ge \frac{1}{5n^{2}}$","If $m$ and $n$ are integers, show that $\biggl|\sqrt{3}-\dfrac{m}{n}\biggr| \ge \dfrac{1}{5n^{2}}$ . Since $\biggl|\sqrt{3}-\dfrac{m}{n}\biggr|$ is equivalent to $\biggl|\dfrac{ \sqrt{3}n-m}{n}\biggr|$ So I performed the following operation $\biggl|\dfrac{\sqrt{3}n-m}{n}\biggr|\cdot \biggl|\dfrac{\sqrt{3}n+m}{\sqrt{3}n+m}\biggr|$ to get $$\biggl|\dfrac{3n^{2}-m^{2}}{\sqrt{3}n^{2}+mn}\biggr|$$ Since $n,m \ne 0$ , we have that $|3n^{2}-m^{2}| \ge 1$ . Now for the denominator, we have $$ |\sqrt{3}n^{2}+mn| \le |\sqrt{3n^{2}}| + |mn| $$ Thus it follows that $$\dfrac{1}{|\sqrt{3}n^{2}+mn|} \ge \dfrac{1}{|\sqrt{3}n^{2}| + |mn|}$$ Would I have to work in cases where $m<n$ , for example? Then we have $$|\sqrt{3}n^{2}| + |mn| < |\sqrt{3}n^{2}| + n^{2} < 3n^{2} + n^{2} < 5n^{2}$$ which gives us the desired result. Although, the same method doesn't work when $n >m$ .","['number-theory', 'diophantine-approximation']"
3475722,Two uncountable subsets of real numbers without any interval and two relations,"Are there two uncountable subsets $A, B$ of real numbers such that: (1) $(A-A)\cap (B-B)=\{ 0\}$ , (2) $(A-A)+B=\mathbb{R}$ or $(B-B)+A=\mathbb{R}$ ? We know that if one of them contains an interval, then the condition (1) is impossible, since every uncountable subset has an accumulation point. Also, $B=\mathbb{Z}$ and $A=(0,1)$ satisfy (1) and (2) but the
condition (1) does not hold and $\mathbb{Z}$ is countable (see Subsets of real numbers satisfying the two conditions ).
Note that $B-B=\{ b-\beta:b,\beta\in B\}$ , $A+B=\{a+b:a\in A,b\in B\}$ .","['real-numbers', 'abstract-algebra', 'elementary-set-theory', 'sumset', 'abelian-groups']"
3475751,Convergence in $\mathcal{S}'$,"In a course I am taking, we discussed the Schwartz space $\mathcal{S}=\mathcal{S}(\mathbb{R}^d)$ and its (topological) dual $\mathcal{S}'$ . When it came to the discussion of the topology on $\mathcal{S}'$ , however, the professor only wrote We say that a sequence $\{u_j\}_{j=1}^{\infty}$ converges to $u\in\mathcal S'$ if $\langle u_j,\varphi\rangle\to\langle u,\varphi\rangle$ for all $\varphi\in\mathcal S$ ; A map $\mathcal{S}'\to\mathcal{S}'$ is said to be continuous if it takes every convergent sequence to a convergent sequence; and did not give a precise description of the topology on $\mathcal{S}'$ . Judging from the definition 1, I believe that he was giving $\mathcal{S}'$ the weak* topology . However, I am having a hard time proving that the definition of continuity defined as above matches the continuity in terms of the weak $^*$ topology. If the weak* topology were first countable, the answer would be yes, but unfortunately this is not the case . I asked the professor this question but he said he didn't know the answer. So my question is: What topology, if any, do we usually give $\mathcal{S}'$ ? Is the continuity defined as above the same as the weak* continuity; that is, does sequential continuity of a map $F:\mathcal{S}'\to \mathcal{S}'$ imply the continuity of $F$ when we endow $\mathcal{S}'$ with the weak* topology? Any help is appreciated. Thanks in advance!","['weak-convergence', 'topological-vector-spaces', 'distribution-theory', 'functional-analysis', 'general-topology']"
3475808,"What does the comma do in the formula ""$v_i = A_{i,i},\ i=\{1,2,\dotsc,\min(m,n)\}$""?",I am looking at the following formula that defines the vector that contains the diagonal elements of a matrix: $v$ is a vector and $A$ is a matrix (rectangular or square). I understand every symbol used in the formula except the comma indicated by the red arrow. My best guess is that it is to separate the formula from the definition of the numbers contained in $i$ . Is that so?,"['matrices', 'linear-algebra']"
3475819,What is a valid function definition?,"Consider the famous Collatz sequence $$
x_{n+1} = c(x_n) = \left\{ \matrix{x_n/2  & {\rm if \; x_n \; even} \hfil \cr
                          3x_n+1 & {\rm if \; x_n \; odd} \hfil \cr }
          \right.
$$ and define $f: ℕ-\{0\}→\{0, 1\}$ $$
f(x) = \left\{ \matrix{
  0 & {\rm if} \; \exists n : c^n(x) = 1 \hfil\cr
  1 & {\rm otherwise}\hfil\cr
}\right.
$$ Is that a valid definition for a function? Is it a constant function? What if we replace Collatz conjecture with a true proposition that however cannot be proved with current set of axioms (Gödel incompleteness)? What if it's replaced by something that can only be decided with a new axiom? For any given $x\in ℕ$ , I would say that $f(x)$ is a well defined number, but if that's true does it mean that for example well defined functions from naturals to $\{0, 1\}$ are either: non-constant functions provably constant functions functions that are constant but that cannot be proved constant functions for which cannot be decided if they're constant or not (this to me sounds pretty crazy)","['incompleteness', 'functions', 'logic', 'natural-numbers']"
3475837,"Verify $JJ' = 1$, given $x = e^u \cos v$, $y = e^u \sin v$.","I was trying to solve this jacobian problem but I'm not getting the required solution i.e $JJ' = 1$ I'm getting $J = e^{2u}$ and $J' = \frac{x^2 - y^2}{x^2 + y^2}$ So multiplying both $J*J'$ will not return 1 in my case. What am I doing wrong? Here's my solution,","['partial-derivative', 'jacobian', 'calculus', 'derivatives']"
3475852,triangle inside triangle// with ratio 2:1,"I found this problem in some recreational mathematics textbook. The given problem is as follows find the ratio of the colored triangle and entire triangle. [The number states the ratio] The textbook simply states and compute the area by counting triangles. I realize in the process they treat following without proof. i.e., the half of length of CD is one side of triangle. From Geogebra manipulation I realized they are indeed same(marked length), but How one can prove this mathematically?","['triangles', 'area', 'geometry', 'recreational-mathematics']"
3475873,Prove the limit of $\lim_{x \to 0^+}e^{\frac{1}{x}}$ and $\lim_{x \to 0^-}e^{\frac{1}{x}}$,"I have been given the following task: Determine whether a limit exists and if so determine it. I need to analyze the following two functions. $$(1) \lim_{x \to 0^+}e^{\frac{1}{x}}$$ $$(2) \lim_{x \to 0^-}e^{\frac{1}{x}}$$ I know for a fact that a limit for the first function does not exist because for very small positiv values the term $\frac{1}{x}$ approaches infinity. For the second function a limit does exist. As x approaches very small negative values the term $\frac{1}{x}$ approaches negative infinity. So it follows that $\lim_{x \to 0^-}e^{\frac{1}{x}} = e^{-\infty} = 0.$ However all of these statements are based on intuition and are not formal. 
I tried to use the epsilon-delta proof in order to show a limit does or doesn't exist. For the first function I tried using a contradiction in order to show a limit does not exist. So suppose a limit $L$ does exist and $L > 0$ . If $L > 0$ than there exists a $\delta > 0$ , so that $0 < |x - x_0| < \delta \Leftrightarrow 0 < |x - 0| < \delta \Leftrightarrow 0 < x < \delta$ with $|f(x) - L| < \epsilon$ . But I don't know how to continue from here. Because normally in an epsilon-delta proof I would now try to find a $\delta$ starting with the term $|f(x) - L| < \epsilon$ and by using equivalent transformation getting to the term $|x - 0| < \delta$ . However I don't know if this is even the right approach in this case. For the second function I get stuck at the same point. Is it suggestive to even use the epsilon-delta proof for these kind of functions or is there some completely different solution path that is more suitable.","['limits', 'functions', 'epsilon-delta', 'real-analysis']"
3475924,Problem involving slope of a plane,"I want to solve parts  (ii) and  (iii) of this problem without using vectors In the region of 3 fixed buoys A, B and C at sea there is a plane stratum of oil-bearing rock. The depths of the rock below A, B and C are 900m, 800m and 1,000m respectively. B is 600m due east of A and the bearings of C from A and B are 190° and 235° respectively. Calculate (i) the distance BC (ii) the direction of the horizontal projection of the line of greatest slope of the plane (iii) the angle this plane makes with the horizontal (It May be helpful to consider a horizontal plane at depth 900 m) This is my diagram for the problem: where D, E and F are the oil-bearing rocks under A, B & C respectively.
Using the sine and cosine rules I have worked out the lengths of the sides of $\triangle$ ABC and $\triangle$ DEF but it is parts (ii) and (iii) I cannot do.",['trigonometry']
3476022,A polynomial is completely determined by any part of it,"I was watching this Mathologer video ( https://youtu.be/YuIIjLr6vUA?t=1652 ) and he says at 27:32 First, suppose that our initial chunk is part of a parabola, or if you like a cubic, or any polynomial. If I then tell you that my mystery function is a polynomial, there's always going to be exactly one polynomial that continues our initial chunk . In other words, a polynomial is completely determined by any part of it. [...] Again, just relax if all this seems a little bit too much. So he didn't give a proof of the theorem in bold text – I think this is very important. I understand that there always exists a polynomial of degree $n$ that passes through a set of $n+1$ points (i.e. there are finitely many custom points to be passed by, the chunk has to be discrete, like $(1,1),(2,2),(3,3),(4,5)$ ). But there also exists some polynomial of degree $m$ ( $m\ne n$ ) that passes through the same set of points. But how do I prove that there exists one and only one polynomial that passes through a set of infinitely many points?","['complex-analysis', 'interpolation', 'polynomials']"
3476049,"In modular representation theory, what is a block?","In modular representation theory, the blocks are defined to be indecomposable two-sided ideals of a ring $R$ with unity element and we can write \begin{equation}
\displaystyle R=\bigoplus_{i=1}^r B_i
\end{equation} for the unique decomposition of $R$ into a direct sum of indecomposable nonzero ideals (the blocks) of $R$ . Another definition by Walter Feit is the following: If $\{e_i\}$ is the set of all centrally primitive idempotents of a ring $R$ , then a block $B=B(e)$ associated with $e$ is the set (Feit says the category) of all finitely generated $R$ -modules $V$ satisfying $Ve=V$ . I can't see why the two definitions are equivalent. 
Are $R$ -modules with the above condition and two-sided indecomposable ideals of a ring the same thing ?
I thank you for any suggestions.","['representation-theory', 'group-theory', 'finite-groups']"
3476067,Proof of geodesic has constant speed,"So I'm working with differential geometry. So my book claim that ""any geodesic has constant speed"" . And the proof is left as an exercise and I found the exercise in the book. Exercise: ""Prove that any geodesic has constant speed and so a very simple unit-speed reparametrization."" I know the definition of geodesic, but I don't know how to work it out. Thanks in advance Edit: The definition, ""Let $\gamma$ be a curve on a surface $\textbf{S}$ . Then the curve is called a $\textit{geodesic}$ if $\ddot{\gamma}$ is zero or orthogonal to the tangent plane of the surface at the point $\gamma$ .""","['curves', 'geodesic', 'differential-geometry']"
3476097,"Example of a relation which is reflexive, transitive, but not symmetric and not antisymmetric","I'm trying to think of a simple example of a two coordinate $(a,b)\in R$ relation which is reflexive, transitive, but not symmetric and not antisymmetric over $\mathbb{N}$ (meaning $R\subseteq\mathbb{N}\times\mathbb{N}$ ). I can't seem to think of one. I would be glad to see some suggestions without actually proving them. I just struggling to think of an example.","['elementary-set-theory', 'relations']"
3476169,Finding the new region after changing variables for a double integral.,"I would like to solve the following double integral using the transformation: $u=x+y$ , $v=x/y$ $$\int _0^1\int _y^2\frac{\left(x+y\right)}{x^2}\:e^{\left(x+y\right)}dxdy$$ What I've reached so far: $$J=-\frac{u}{\left(v+1\right)^2}$$ , $$x=\frac{uv}{v+1}$$ , $$y=\frac{u}{v+1}$$ the only problem I'm facing now is to find the new region so I can set up my double integral, but what I get is: $$u=0,u=v+1,uv=2\left(v+1\right),v=1 $$ which doesn't look like a region that I can integrate over. Final note: I know that the integral doesn't converge anyway , and I'm not the one who chose this substitution (homework problem)","['multivariable-calculus', 'calculus', 'change-of-variable', 'multiple-integral']"
3476176,Is there an infinite set of finite strings such that no element is a subsequence of another?,"Of course, this is meant to be over a finite alphabet. My intuition is that this doesn't exist over any such alphabet, so that's what I'd want to know how to prove. I'm also interested in questions like ""can such a set be computably enumerable"" and ""can such a set be computable"".","['discrete-mathematics', 'computer-science']"
3476244,Represent $f(x)$ with $g(x)$ when the taylor expension has specific dependency,If I have $f(x)$ and $g(x)$ like that: $$f(x)=\sum_{n=1}^{\infty} a_nx^n$$ $$g(x)=\sum_{n=1}^{\infty} \frac {a_nx^n} {n}$$ How can I find u(x) such: $f(u(x))=g(x)$ ? I also know that the series $(a_n)$ is convergent.,"['functions', 'taylor-expansion', 'formal-power-series', 'power-series', 'sequences-and-series']"
3476268,"How to manipulate the expression $16b^3a^2(6ab^4)(ab)^3$ to the form $2^m3^na^rb^s$ (Serge Lange Basic Mathematics, Chap 1 $3)","So this chapter has gone over the basic properties of multiplication, but I don't have a great example of how to arrive at the solution in the text for this problem. Given solution: $2^{10}3^3a^6b^{10}$ I'm not sure how to start it. It's easy for me to keep track of the powers of a and b, but I don't see the steps to reach $2^{10}$ and $3^3$ ? In another example $8a^2b^3(27a^4)(2^5ab)$ I tried to simplify it down as much as possible and arrived at $6912a^7b^4$ , which is 'correct' but not in the specified form. Was that the right approach? Should I have then tried to break 6912 into $2^x3^x$ ? If yes, how do you do that?",['algebra-precalculus']
3476289,Risk of AIDS Infection - Overestimation?,"As an example of a probability misunderstanding, the book ""Mathematics Statistics and Data Analysis"" by John A. Rice gives the following quote from the Los Angeles Times: ""Several studies of sexual partners of people infected with the virus show that a single act of unprotected vaginal intercourse has a surprisingly low risk of infecting the uninfected partner--perhaps one in 100 to one in 1,000. For an average, consider the risk to be one in 500. If there are 100 acts of intercourse with an infected partner, the odds of infection increase to one in five. Statistically, 500 acts of intercourse with one infected partner or 100 acts with five different infected partners lead to a 100% probability of infection (statistically, not necessarily in reality)."" The full article is here . Rice explains that this is flawed by considering just two acts of intercourse: if we let $A_1$ denote the event that infection occurs on the first act and $A_2$ the event infection occurs on the second, then the event that infection occurs is $B = A_1\cup A_2$ and $$P(B) = P(A_1) + P(A_2) - P(A_1\cap A_2) \leq P(A_1) + P(A_2) = {2 \over 500}$$ But I'm still confused: I understand that the above is trying to show that the article is overestimating, but surely the probability of $A_1 \cap A_2$ is $0$ ? You can only be infected with AIDS once... as far as I know. And even if it is not $0$ , what's stopping us from exceeding the $P = 1$ threshold eventually if we take enough events (which clearly seems nonsensical since its intuitively its clear that someone might avoid AIDS indefinitely)? Just to clarify, I'm not disagreeing that the article is flawed, I'm just struggling to locate the exact flaw. Many thanks.",['probability']
3476305,Find $m$ if $f(x)=x^m\sin\frac{1}{x}$ is continuous and is not differentiable,"If $f(x)=\begin{cases}
x^m\sin\dfrac{1}{x}, & x\ne 0 \\
0, & x=0		 
\end{cases}$ . Find $m$ if $f(x)$ is continuous and is not differentiable My attempt is as follows:- Let's find the condition of continuity $$\lim_{x\to0^{+}}x^m\sin\dfrac{1}{x}$$ As $x\rightarrow 0^{+}, \dfrac{1}{x}\rightarrow \infty,\sin\dfrac{1}{x} \text { oscillates in }  [-1,1]$ $$m>0$$ $$\lim_{x\to0^{-}}x^m\sin\dfrac{1}{x}$$ As we have the negative base $$m>0 \cap m\notin \left\{\dfrac{p}{q} | p,q \text { are coprime and } q \text { is even }\right\}\tag{1}$$ Let's find the condition of non-differentiability $\lim_{h\to 0}\dfrac{h^m\sin\dfrac{1}{h}}{h}$ should not exist $$\lim_{h\to 0^{+}}h^{m-1}\sin\dfrac{1}{h}$$ $$m\le0$$ $$\lim_{h\to 0^{-}}h^{m-1}\sin\dfrac{1}{h}$$ $$m-1\le 0 \cup m-1\in\left\{\dfrac{p}{q} | p,q \text { are coprime and } q \text { is even }\right\}$$ $$m\le 1 \cup m\in\left\{\dfrac{p+q}{q} | p,q \text { are coprime and } q \text { is even }\right\}\tag{2}$$ Taking intersection of equations $(1)$ and $(2)$ $$\left(m\in(0,1] \cap m\notin \left\{\dfrac{p}{q} | p,q \text { are coprime and } q \text { is even }\right\}\right) \cup  \left(m>0 \cap m\notin \left\{\dfrac{p}{q} | p,q \text { are coprime and } q \text { is even }\right\} \cap m\in\left\{\dfrac{p+q}{q} | p,q \text { are coprime and } q \text { is even }\right\}\right)$$ But actual answer is simply $m\in(0,1]$","['limits', 'calculus', 'derivatives']"
3476308,Is there a coordinate-free proof of this Lie derivative identity?,"Wikipedia mentions ( here and here ) that the Lie derivative has the following appealing commutator: $$[\mathcal{L}_X,\iota_Y]=\iota_{[X,Y]}$$ The only way I know to demonstrate this identity relies on coordinate-based manipulations, which are summarized (with a mistake) in this problem .  I would like a coordinate-free (purely algebraic, one might say) proof of the same result. Here's one possible route to a proof, but I can't seem to stick the landing.  Let $\phi_t$ be the diffeomorphisms infinitesimally generated by $X$ and recall that $\mathcal{L}_X\omega=\left.\partial_t(\phi_t^*\omega)\right|_{t=0}$ .  Similarly, $[X,Y]=\mathcal{L}_XY=\left.\partial_t(\phi_{-t}^*Y)\right|_{t=0}$ . Now $\iota_{(\cdot_1)}(\cdot_2)$ is bilinear and smooth, so it commutes with the (Gateaux) time derivative when the equation is interpreted sufficiently weakly.  So it suffices to show that $$\left.\partial_t\left([\phi_t^*,\iota_Y]-\iota_{\phi_{-t}^*Y}\right)\right|_{t=0}=0$$ But, applying LHS to a test form, I don't see how to deduce the result. This answer suggests that it should be obvious from the Leibniz rule, but I don't see why the contraction operator $C$ in that answer should commute with $\mathcal{L}_X$ (as it does, moving from the first to second line). How can I prove the commutator claim in a coordinate-independent manner?","['tensors', 'lie-derivative', 'differential-geometry']"
3476344,Find limit of $\frac{|x|^3 y^2+|x|y^4}{(x^2+y^2)^2}$,I have to show that $\lim_{{x\choose y}\to { 0 \choose 0}} \frac{|x|^3 y^2+|x|y^4}{(x^2+y^2)^2} = 0$ . But I cannot figure out the trick you need to find an upper estimation which goes to $0$ . Do you have any hints? EDIT : I think I got it: $\lim_{{x\choose y}\to { 0 \choose 0}} \frac{|x|^3 y^2+|x|y^4}{(x^2+y^2)^2} =  \lim_{{x\choose y}\to { 0 \choose 0}} \frac{|x|^3 y^2}{(x^4+2x^2 y^2 +y^4)} +\lim_{{x\choose y}\to { 0 \choose 0}} \frac{|x|y^4}{(x^4+2x^2 y^2 +y^4)}\leq \lim_{{x\choose y}\to { 0 \choose 0}} \frac{|x|^3 y^2}{x^2 y^2}+\lim_{{x\choose y}\to { 0 \choose 0}} \frac{|x|y^4}{y^4}=\lim_{{x\choose y}\to { 0 \choose 0}} |x|+ \lim_{{x\choose y}\to { 0 \choose 0}} |x|=0.$ What do you think?,"['limits', 'multivariable-calculus']"
3476356,How to prove $\forall k \exists y \forall x (x < y \Leftrightarrow \forall n (n < x \Rightarrow n < k))$?,I'd like to prove that $\forall k \exists y \forall x (x < y \Leftrightarrow \forall n (n < x \Rightarrow n < k))$ holds for first order arithmetic but I'm not sure where to start. I should probably do that inductively but it contains universal quantifier inside. What to do in such cases?,"['elementary-set-theory', 'induction', 'logic', 'arithmetic']"
3476365,Prove $\sum_{\text{cyc}}^{}\sqrt[3] {1+2ac} \le 3\sqrt [3] {3}$ for $ a+b+c+abc=4$,"The presented solution of the following problem on Art of Problem Solving using Jensen's inequality is wrong, since the function $f(x):=\sqrt[3]{1+\frac{2t}{x}} $ is convex rather than concave. How would one prove this inequality, correctly? Let $a, b ,c $ be positive real numbers such that $ a+b+c+abc=4$ . Prove that : $$\sum_{\text{cyc}}^{}\sqrt[3] {1+2ac} \le 3\sqrt [3] {3}.$$","['algebra-precalculus', 'inequality']"
