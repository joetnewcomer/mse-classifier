question_id,title,body,tags
2930589,$\frac{d}{dx}x^n=nx^{n-1}$ proof by induction,Problem Proof following statement with induction: $$ \frac{d}{dx}x ^n=nx^{n-1} : \forall n \in \mathbb{Z}_+ $$ Attempt to solve Base case $$ \frac{d}{dx}x^1=1\cdot x^{0}=1 $$ which holds true Induction step $$ \frac{d}{dx}x\cdot x^n =_{\text{ind. hyp}} nx^{n-1}:\forall n \in \mathbb{Z}_+ $$ $$\frac{d}{dx}x^{n+1}=(n+1)x^{n}$$ It is known that product rule holds: $$ \frac{d}{dx}f(x)g(x)=\frac{df}{dx}g(x)+f(x)\frac{dg}{dx} $$ then $$ \frac{d}{dx}x^{n+1}=\frac{d}{dx}x\cdot x^n =(\frac{d}{dx}x)\cdot x^n + x \cdot (\frac{d}{dx}x^n)=x^n+x(nx^{n-1})=x^n+nx^{1-1+1} $$ $$ = x^n+nx^n=(n+1)x^n \tag*{$\square$}  $$ I would like to have some feedback if my solution seems correct and  or not.,"['induction', 'proof-verification', 'derivatives']"
2930593,What is the sum of the binomial coefficients ${n\choose p}$ over prime numbers?,"What is known about the asymptotic order and/or lower and upper bound of the sum of the binomial coefficients $$
S_n = {n\choose 2} + {n\choose 3} + {n\choose 5} + \cdots + {n\choose p}
$$ where the sum runs over all primes $\le n$ ? Update 12-Aug-2019 : Sungjin Kim has shown that almost for all $n$ , $$
S_n \sim \frac{2^n}{\log(n/2)}
$$ In the previous version we had $\log n$ in the denominator which has not been corrected. Actual values: My calculation gave the following asymptotic order of $n$ and the ratio $r_n = s_n/(2^n/\log n)$ . (100000, 1.13766407097665)
(110000, 1.00289966767667)
(120000, 0.97497422941139)
(130000, 1.07297773163979)
(140000, 1.09130325488627)
(150000, 1.03493135205282)
(160000, 1.09228831426585)
(170000, 1.02437859352022)
(180000, 1.18789309596329)
(190000, 1.11814470079054)
(200000, 1.00572021128112)
(210000, 1.03114155491856)
(220000, 0.95835641265769)
(230000, 1.03176200981585)
(240000, 1.10141025102049)
(250000, 1.04435554152951)
(260000, 1.02244981941248)
(270000, 1.03103959797895)
(280000, 1.05303304022584)
(290000, 1.00915670279005)
(300000, 1.08798558856723)
(310000, 1.05106334090960)
(320000, 1.07582903038813)
(330000, 0.920056638088384)
(340000, 1.13576974339066)
(350000, 0.923576122540866)
(360000, 1.15321376273496)
(370000, 1.08344303929811)
(380000, 1.02063510069254)
(390000, 1.08363394859595)
(400000, 1.05463839543006)
(410000, 1.04986600633135)","['summation', 'number-theory', 'binomial-coefficients', 'combinatorics', 'prime-numbers']"
2930594,The minimum value of perimeter of the triangle,"Let there be $\triangle ABC$ having integral side lengths such that angle $$ \angle A=3 \angle B $$ Then find the minimum value of its perimeter. I did this with trigonometry and got an equation as: $$ 2p = 4b[2\cos^3( \theta) + \cos^2(\theta) - \cos(\theta)] $$ where $b$ = side opposite to $\angle B$, $\theta$ is the $\angle B $ and $p$ is half of the perimeter. How should I proceed? Also show any other appropriate method.","['number-theory', 'elementary-number-theory', 'geometry', 'diophantine-equations', 'trigonometry']"
2930619,Non-linear second order ODE,"I have to solve $$ y''(x)+(y'(x))^2=y'(x). $$ Using $ y'(x)=z $ , I can write $$\int \frac{1}{z-z^2}dz=\int dx $$ So: $$\frac{1}{z(1-z)}=\frac{A}{z}+\frac{B}{1-z}$$ leads to $$ \int \frac{1}{z(1-z)}dz=\int \frac{1}{z}dz+\int \frac{1}{1-z}dz= \ln(z)-\ln(1-z)$$ $$\Rightarrow \ln\left(\frac{z}{1-z}\right)=x+c $$ $$\Rightarrow z=\frac{e^{x+c}}{1+e^{x+c}}=y'$$ $$\Rightarrow y=\int \frac{e^{x+c}}{1+e^{x+c}}dx $$ Now, calling $e^{x+c}=t$ : $$y=\int\frac{t}{1+t}\cdot\frac{dt}{t}=\ln(1+t)\Rightarrow \ln(1+e^{x+c})$$ I checked the calculations and i thought was right but WolframAlpha says that the result is $\ln(c_1+e^x)+c_2$ . What am I doing wrong? Thanks for any help!","['ordinary-differential-equations', 'logarithms', 'indefinite-integrals', 'substitution', 'exponential-function']"
2930728,"Is it true that $\frac{1}{\pi^{2n+1}} \int_0^{\theta} \ln^{2n}\left(\frac{\sin x}{\sin\left(\theta-x\right)}\right)\,dx$ is a rational...","I was trying to evaluate $\displaystyle \int_0^{\frac{\pi}{6}}\ln^2\left(2\sin x\right)\,dx$ in an elementary way (no complex variable) so i have considered: $\displaystyle \int_0^{\frac{\pi}{6}} \ln^2\left(\frac{\sin x}{\sin\left(\frac{\pi}{6}-x\right)}\right)\,dx$ . Using lindep a function in PARI GP i have conjectured that this integral is equal to a rational times $\pi^3$ *.
Then i have considered: $\displaystyle \frac{1}{\pi^5}\int_0^{\frac{\pi}{6}} \ln^4\left(\frac{\sin x}{\sin\left(\frac{\pi}{6}-x\right)}\right)\,dx,\frac{1}{\pi^7} \int_0^{\frac{\pi}{6}} \ln^6\left(\frac{\sin x}{\sin\left(\frac{\pi}{6}-x\right)}\right)\,dx$ and it seems that these integrals are rational numbers. then i have considered: $\displaystyle \frac{1}{\pi^5}\int_0^{\frac{\pi}{7}} \ln^4\left(\frac{\sin x}{\sin\left(\frac{\pi}{7}-x\right)}\right)\,dx,\frac{1}{\pi^7} \int_0^{\frac{\pi}{7}} \ln^6\left(\frac{\sin x}{\sin\left(\frac{\pi}{7}-x\right)}\right)\,dx$ same things happen. Then i have considered: $\displaystyle \frac{1}{\pi^3}\int_0^{\sqrt{2}} \ln^2\left(\frac{\sin x}{\sin\left(\sqrt{2}-x\right)}\right)\,dx$ . and lindep doesn't show that this number is rational. (it's not a proof). i have tested much more values ( $\frac{\pi}{7}+\frac{1}{10000}$ for example) My question: is it true that: $0< \theta <\pi$ , a real for all $n$ , natural integer $\displaystyle \frac{1}{\pi^{2n+1}} \int_0^{\theta} \ln^{2n}\left(\frac{\sin x}{\sin\left(\theta-x\right)}\right)\,dx$ is a rational if only if $\theta=r\pi$ , $0< r<1$ a rational. *: i think i have a proof for this. PS: The idea of this came after reading: Evaluation of $\int_0^{\pi/3} \ln^2\left(\frac{\sin x }{\sin (x+\pi/3)}\right)\,\mathrm{d}x$","['integration', 'definite-integrals']"
2930758,Find the probability that the card number 18 is the second jack that you deal.,"You deal from a well-shuffled $52$ -card deck, one card at a time. Find the probability that the card number 18 is the second jack that you deal. Include at least $4$ digits after the decimal point in your answer. I have tried this numerous different ways, but I cant seem to get it. I've tried $$\frac{\dbinom{48}{16} \cdot \dfrac{4}{52}}{\dbinom{52}{16} \cdot \dfrac{3}{35}}$$ and I don't know why this doesn't work.","['combinatorics', 'probability']"
2930780,Finding a geometric series for $\frac{1}{(1 + x)^2}$,"I'm asked to find a geometric series for $f(x) = \frac{1}{(1 + x)^2}$ , I integrate it first and I get $F(x) = \int{\frac{1}{(1 + x)^2}dx} = \frac{1}{-2(1 - (-x))}$ Since $\frac1{1-x} = \sum_{n=0}^\infty x^n$ , $F(x) = \frac{-1}2\sum_{n=0}^\infty (-x)^n = \sum_{n=0}^\infty \frac{(-1)^{n+1}}{2}x^n$ If I derive that, $f(x) = \sum_{n=0}^\infty\frac{(-1)^{n+1} n x^{n-1}}{2} = \sum_{n=1}^\infty\frac{(-1)^n (n + 1) x^n}{2}$ But my textbook says that $f(x) = \sum_{n=0}^\infty (-1)^n (n + 1) x^n$ Obviously those 2 things are pretty different (notice the index). What did I get wrong?","['power-series', 'geometric-series', 'ordinary-differential-equations']"
2930789,Similarity transform with respect to a metric?,"Does this type of matrix expression have a name? $$D'S=CDC^{-1}$$ All the matrices are $n\times n$ and $S$ is a matrix consisting of the inner products of the basis vectors of $D'$ , so $D'$ is in general defined with respect to a nonorthonormal basis. Obviously, the matrix $D'S=E$ is a similar matrix to $D$ and if $S=\mathbf{1}$ (ie $D'$ is in an orthonormal basis) then $D'$ itself is just a similarity transform of $D$ , but is there terminology for the general case, something akin to "" $D'$ is similar to $D$ with respect to the metric $S$ ."" As a matter of context, I was trying to answer a question on Chem SE  about the relationship between atomic and molecular basis density matrices , when I arrived at an expression similar to the one above. I was hoping to find a way to describe how the bases of $D'$ and $D$ are related, as in the physical context they describe very similar properties. It seems to have something to do with nonorthogonality of the basis of the matrix $D'$ .","['matrices', 'mathematical-physics', 'chemistry', 'linear-transformations']"
2930800,"Why is ""jump"" between two primes (almost) always prime or 1 up to 1000?","While looking at prime numbers between 1 to 1000 I noticed that the number of non-primes between prime numbers are almost always also prime or 1. In other words, if we take the prime gap, $$
g_n=p_{n+1}-p_n,
$$ for prime numbers larger than 2, and subtract 1 from it, we almost always get a prime number or 1. In the cases (between 1 to 1000) where $g_n-1$ is not equal to a prime number or 1 it is instead equal to 9. Below is a figure I made to better explain: What is the reason that the ""jump length"" (i.e. numbers in red or blue above) between primes are either 1, 9 or also prime when looking at 1 to 1000?","['number-theory', 'prime-numbers']"
2930821,A simple mathematics riddle that has me batty.,"I'm looking to confirm an answer I came up with. I'm pretty sure this is going to seem really silly to many of you because it's probably very easy for you to understand, but I can't wrap my head around it. Problem: You have 23 lights, each with its own switch. 
Each switch functions like almost all light switches, each switch is either, ""ON"" or ""OFF.""
How many unique combinations of the lights being ""ON"" or ""OFF"" are possible? Example: switch #1 is on, all other switches off, is one unique combo.
switch #1 and #2 are on, all others off is another unique combo. My thoughts: So I'm thinking since each switch has only 2 settings, the way to come up with the total possible combos is $2^{23}$ . So this comes out to a total of $\color{red}{8,388,608}$ ! This number seems incredibly high to me. Looking at these 23 switches in front of me (for my kid's school project) I just can't believe there are nearly 8.4 million combos possible. Any help or confirmatiin is greatly appreciated.
Thx in advance.
Charles",['algebra-precalculus']
2930825,What is more historically correct?,"I was wondering what was formally correct, when resolving an integral by substitution, use as a new variable $t$ or $u$ ? I noticed that here in Italy we use $t$ , while I saw that abroad (e.g USA) use $u$ .
When was this variable method of integration designed? I am aware that I can use any variable and that the result would be the same but I'm curious to know originally what was used by Newton, Leibniz, etc. I hope someone knows how to answer, it is an unresolved doubt that I have for some time.","['integration', 'notation', 'calculus', 'substitution', 'math-history']"
2930886,Dependence of operator topologies in a $C^*$ algebra on the representation,"Let $A$ be a $C^*$ algebra. Given a faithful representation $\pi:A\to \mathcal{B}(H)$ , we can define the weak operator topology with respect to $\pi$ as initial with respect to the maps $a\mapsto \langle \pi(a) x,y\rangle$ for each $x,y\in\mathcal{H}$ . However, this definition depends on our representation $\pi$ . Are these operator topologies intrinsic to $A$ , or can different faithful representations induce different weak operator, strong operator, etc. topologies?","['c-star-algebras', 'functional-analysis', 'operator-algebras']"
2930974,Continuous on the unit ball – odd on the unit sphere – does it have a fixed point?,"For $n\in\mathbb N$ , let \begin{align*}
B^n\equiv&\;\{\mathbf x\in\mathbb R^n\,|\,\lVert \mathbf x\rVert\leq 1\}\text{ and}\\
S^{n-1}\equiv&\;\{\mathbf x\in\mathbb R^n\,|\,\lVert \mathbf x\rVert= 1\}
\end{align*} denote the unit ball and the unit sphere, respectively, where $\lVert\cdot\rVert$ is the standard Euclidean norm. Suppose that $F:B^n\to\mathbb R^n$ is a continuous function satisfying $F(-\mathbf x)=-F(\mathbf x)$ for every $\mathbf x\in S^{n-1}$ . That is, $F|_{S^{n-1}}$ is an odd function. Claim: The function $F$ has a fixed point, that is, some $\mathbf x^*\in B^n$ satisfying $F(\mathbf x^*)=\mathbf x^*$ . (The case $n=1$ is an immediate consequence of the intermediate-value theorem.) (Disclosure: I spent the better half of this afternoon trying to construct a counterexample for $n=2$ , in vain.) Note: The function $F$ does not necessarily map into $B^n$ , so Brouwer’s fixed-point theorem doesn’t apply directly. That said, upon defining the projection function $\mathsf p:\mathbb R^n\to B^n$ as \begin{align*}
\mathsf p(\mathbf x)\equiv\frac{1}{\max\{\lVert\mathbf x\rVert,1\}}\mathbf x\quad\text{for each $\mathbf x\in\mathbb R^n$},
\end{align*} the composite function $\mathsf p\circ F:B^n\to B^n$ is guaranteed to have a fixed point. Yet, it is unclear to me whether and how this observation helps prove that $F$ has a fixed point. (I would like to avoid using the Borsuk–Ulam theorem and heavy-duty algebraic-topology arguments if possible. Brouwer’s level is as high as I’d like to preferably reach.) Any suggestions would be appreciated.","['general-topology', 'fixed-point-theorems', 'real-analysis']"
2930977,Use of X and x in probability.,"I just came back to school and started taking mathematical probability. It has been a while since I have studied distributions and am having trouble understanding some of the notations. Would someone be kind enough to explain to me when to use capital X and lowercase x? For example, I know that $$ Pr[X=x]=p^xq^{1-x}$$ is the probability of a Bernoulli $(p)$ distribution and X is a random variable where x is the value of that random variable, but currently I am studying MLEs and expressions such as $$ E[\hat\theta] = E[\frac{1}{n}\sum_{i=1}^{n} X_i]$$ gets me a bit confused.  I feel as though $X_i$ should be $x_i$ since $$\bar{x} = \frac{1}{n}\sum_{i=1}^{n} x_i$$ If I am wrong I apologize, but at least would like to know the convention of the use of X and x since I come from a pure math back ground and haven't studied statistics much.",['probability-theory']
2930989,Is the family of equivalent norms a locally compact space?,"Consider an infinite dimensional Banach space $(X,||\cdot||)$ . Let $\mathcal{P}$ be the family of all equivalent norms in $X$ . That is $p\in \mathcal{P}$ iff $p$ is equivalent to $||\cdot||$ , i.e. there exists two constants $c_1,c_2>0$ such that $c_1||x||\leq p(x)\leq c_2||x||$ for all $x\in X$ . $\mathcal{P}$ is a metric space endowed with the following metric $\rho$ : $$\rho(p,q)=\sup_{||x||\leq 1} \lbrace |p(x)-q(x)|\rbrace$$ $\mathcal{P}$ is a Baire space, seen as an open subset of the space of all continuous semi-norms in $(X,||\cdot||)$ with the same metric $\rho$ . This last space is a complete metric space, so by the Baire category theorem it is a Baire space. Is $\mathcal{P}$ a locally compact space? - We can't use Riesz Lemma, as this space is not a linear space, to argue against the locally compactness.","['general-topology', 'locally-compact-groups', 'analysis']"
2930995,Algebraic extensions are isomorphic if the same polynomials have roots,"I want to solve the following excercise. Let $K$ be a (perfect) field and $L_1, L_2$ be two algebraic
  extensions of $K$ . Then $L_1$ and $L_2$ are isomorphic if every
  polynomial $f\in K[X]$ which has a root in $L_1$ has a root in $L_2$ and vice versa. The hint is to use either the Compactness Theorem to reduce to the case of finitely generated subfields of $L_1, L_2$ or to use König's Lemma from Graph Theory. For the finitely generated case let $F=K(a_1,\dots,a_n)$ for some $a_1,\dots,a_n\in L_1$ . By the Primitive Element Theorem we have $F=K(a)$ for some $a\in L_1$ and by assumption the minimal polynomial $\mathfrak{m}_a$ of $a$ over $K$ has a root $b\in L_2$ . Then clearly $K(a)\cong K(b)$ . My problem is that I'm not really sure how I can use the compactness theorem to reduce to this case. It is probably easy, but I think my problem is that I am used to applying the Compactness Theorem to build structures with certain properties and not maps between structures. Question: How can this proof be finished off by the compactness theorem? Are there any general techniques how compactness can be used to build isomorphisms between structures rather than structures? I would also like to see a proof using the König's Lemma approach (because afaik König's Lemma is strictly weaker than the Compactenss Theorem over $\mathrm{ZF}$ (?)) but I dont know how to build the tree in this case. (Maybe we have to assume that $K$ is countable?) Question: Can we prove the above statement (under some reasonable additional assumptions) in $\mathrm{ZF}+$ König's Lemma?","['field-theory', 'model-theory', 'abstract-algebra', 'axiom-of-choice']"
2931000,Probability density function of sum of uniform random variables,"Let $X$ and $Y$ be independent random variables with density functions $f_X(a) 
\begin{cases}
1\over2   & -1\le a\le1 \\
0 & \text{otherwise}
\end{cases}$ $f_Y(a) 
\begin{cases}
1\over2   & 3\le a\le5 \\
0 & \text{otherwise}
\end{cases}$ Find the probability density function of $X + Y$ I have been trying to do this without convolution, but with using the standard double integral method of finding the CDF and then the PDF (as opposed to using a purely geometrical method) and I have been successful in the case of $2 \le a \le 4$ by using an integral of ${1\over 4}\int_3^a \int_{-1}^{a-y}dxdy$ However I have been having trouble in the other case of $4 \le a \le 6$ .
My attempt was this: $${1\over 4}\int_3^5 \int_{-1}^{min \{1, a-y\}}\ dx \ dy$$ $${1\over 4}\left (\int_3^5 ({min \{1, a-y\}} +1) \ dy \right)$$ $${1\over 4}\left (\int_3^5 ({min \{1, a-y\}}\ dy+ \int_3^5 1\ dy \right)$$ At this point I said that since the minimum function depends on whether $y>a-1$ or $y<a-1$ , therefore there are two cases and thus $${1\over 4}\left (\int_3^{a-1}1 \ dy +\int_{a-1}^{5} \ y \ dy+ \int_3^5 1\ dy \right)$$ $${1\over 4}\left (a-4-\dfrac{a^2-2a-24}{2}+ 2\right)$$ Taking the derivative of this CDF yields ${1\over2} - {a\over4}$ , whereas the true solution is ${3\over2} - {a\over4}$ . Where am I going wrong?","['statistics', 'probability-distributions', 'probability']"
2931082,Solve the differential equation $(4+t^2) \frac{dy}{dt} + 2ty = 4t$,Solve the differential equation $$(4+t^2) \frac{dy}{dt} + 2ty = 4t$$ Solution: $$(4+t^2) \frac{dy}{dt} + 2ty = \frac{d}{dt}[(4+t^2)y]$$ How? Here's what I did: $$\frac{d}{dt}[(4+t^2)y] = 4t$$ Then we integrate both side: $$(4+t^2)y = 2t^2 + c$$ $$y = \frac{2t^2+c}{4+t^2}$$ I don't get the first step,['ordinary-differential-equations']
2931226,Need to create a weird ODE,"Given $\epsilon>0$ , I need to create a first order ODE that is defined everywhere on $\mathbb{R}$ , such that all solutions to this ODE are only defined on an interval of length $\leq \epsilon$ . My attempt: $$x'(t) = \frac{1}{\log(10)}\left(\frac{1}{\epsilon/t -1}\right)\frac{\epsilon}{t}.$$ This has solutions $$ x(t) = \log_{10}\left( \frac{\epsilon}{t}-1 \right) + c $$ for $c\in\mathbb{R}$ . The problem is that my ODE and solutions are only defined on the interval $(0,\epsilon)$ , not all of $\mathbb{R}$ . My professor said that I was close, but my ODE should be autonomous so it is defined everywhere. There is no way that I can see how to extend my example to be what is desired. I do not think I am close at all. Any hints or help would be appreciated.","['analysis', 'ordinary-differential-equations', 'real-analysis']"
2931242,Integral of Hermite Polynomials.,"Let $f \in L^2(\mathbb{R}, (1/\sqrt{2 \pi})\exp(-x^2/2))$ be such that $0 \leq f(x) \leq 1$ .
We know that the (normalized) Hermite polynomials are a complete orthonormal basis for this space.  Therefore we let \begin{equation}
f_n(x) = \sum_{i=0}^n \langle f, H_i\rangle\ H_i(x) = \sum_{i=0}^n c_i H_i(x),
\end{equation} where \begin{equation}
c_i = \langle f, H_i \rangle = \int H_i(x) f(x) \frac{1}{\sqrt{2 \pi}} \exp(-x^2/2)\ \mathrm{d} x = 
\int H_i(x) f(x)\ \phi(x) \mathrm{d} x,
\end{equation} where $\phi(x) = (1/\sqrt{2 \pi}) \exp(-x^2/2)$ .
Consider now the integral \begin{equation}
d_i = \int H_i(x) f(x)\ \phi(x-\mu) \mathrm{d} x
\end{equation} $d_i$ is the Hermite coefficient with respect to a translated Gaussian. Question:
  Is there an upper bound for $|c_i - d_i|$ ? Ideally it would be something in 
  the form $|c_i - d_i| \leq A c_i$ . My guess would be that 
there should exist some fixed constant $A$ such that \begin{equation}
|c_i - d_i| \leq A |c_i| \exp(\mu^2).
\end{equation} I know that this question could be formulated only in terms of integrals
but I thought that providing more context could be helpful. Any pointers to relevant literature are welcome.","['fourier-analysis', 'analysis', 'reference-request', 'real-analysis', 'hermite-polynomials']"
2931336,Evaluate the integral with and without Green's theorem,"Evaluate the line integral $\oint_C y^2dx + xdy$ when $C$ has the vector equation $\alpha(t)=(2\cos^3t)i+(2\sin^3t)j$ , $0 \leq t \leq 2\pi$ . My attempt BY USING GREEN's THEOREM, i.e., $P=y^2$ , $Q=x$ we get $\iint_c 1-2y dxdy$ Now putting $x=r\cos^3t$ and $y=r\sin^3t$ we get $dxdy=Jdrdt$ , where $J=3r \sin^2t \cos^2t$ hence $dxdy=3r \sin^2t \cos^2t drdt$ Hence the required integral is, $\int_0^{2\pi} \int_0^2 (1-2r \sin^3t)(3r \sin^2t \cos^2t)drdt$ which is equal to $\pi /4$ But the answer given in APOSTOL's is $3 \pi /2$ NOW BY NORMAL METHOD put $x=2 \cos^3t$ and $y=2 \sin^3t$ $dx=-6 \cos^2t \sin t dt$ and $dy=6 \sin^2t cost dt$ , Hence the integral becomes $-24 \int_0^{2 \pi} \sin^7t \cos^2t dt + 12 \int_0^{2 \pi} \cos^4t \sin^2t dt$ which is equal to ZERO. WHAT MISTAKE AM I DOING AND THE CORRECT ANSWER IS $3 \pi /2$ ?",['multivariable-calculus']
2931339,First order differential equation solution check.,I have an equation: $\frac{dy}{y}=(0.0001x^2+0.005x)dx$ $y=ce^{(0.00003x+0.0025)x^2}$ Now I try to substitute $y$ in the euqation and I am getting $(\frac{1}{ce^{(0.00003x+0.0025)x^2}})'=0.0001x^2+0.005x$ $(\frac{1}{ce^{(0.00003x+0.0025)x^2}})'=(\frac{1}{c}e^{(-0.00003x-0.0025)x^2})'=(\frac{1}{c}e^{(-0.00003x-0.0025)x^2})(-0.0001x^2-0.005x)$ But $(\frac{1}{c}e^{(-0.00003x-0.0025)x^2})(-0.0001x^2-0.005x) \neq 0.0001x^2+0.005x$ What am I missing here while checking the solution?,"['proof-verification', 'ordinary-differential-equations']"
2931345,"Questions about the system $x+c_1\equiv y \pmod z$ and $d=y+c_2$ for integers $x$, $y$, $z$, $c_1$, $c_2$","Let $x, y, z \in \mathbb Z$ and $c_1, c_2$ be two arbitrary constants (not necessarily equal). Given that $x + c_1 \equiv y \pmod z$ and $d = y+c_2$ , My queries are, Can I find a general solution for $x$ ? If yes, then how? Consider another case, If $x$ lies between $ 0 \le x \le 256 $ and $z$ is a Constant . Then, looking at a set of values for $y$ , What is the probability of predicting $x$ correctly? ( The term Predicting stands for : Consider among all the possible values of $x$ , only 1 value of $x$ is considered as required. Say, if in a case where, $x \in {1,2,3} $ . But One wants only '2' from it. Thus the probability of predicting $x$ correctly will be : $1/3$ ) I am new here (Posting my first question) . Please help. EDIT : Let me explain with an example, Suppose, $x + c_1 \equiv y \pmod 2$ . As we can see, The value of $x$ is either Even or Odd. If, it's Even, then Depending on some $c_1$ , the resultant value will be either Even or Odd. Right?
Now, obviously $y\in {0,1} $ . Given some $y$ , can I ever have probability to predict the $x$ correctly? i.e $ (4 + 13) \equiv 1 \pmod 2$ , and $ (5 + 13) \equiv 0 \pmod 2$ . Given, $y = {0,1}$ what will be the probability for finding $x={4,5}$ respectively ? Motivation : I want to know how hard it would be to find the $x$ or there exists some formal mathematical way to obtain such a solution. Instead of $y$ , if $d$ is given. What would be it's impact on this problem? Will it be harder to solve?","['modular-arithmetic', 'number-theory', 'cryptography', 'discrete-mathematics', 'congruence-relations']"
2931352,Intuition of a smooth vector field,"I read the following statement in pg180, of John Lee's smooth manifold. I am not having much intuition. Let $M$ be a smooth manifold, $X:M \rightarrow TM$ be a rough vector field (i.e. it does not have to be smooth map). Then the following are equivalent: $X$ is smooth. For every $f \in C^\infty(M)$ the map $Xf$ is also smooth on $M$ . I understand the proof. But what is the geometric meaning/ significance of this statement? Is there an analogue somewhere else?","['vector-fields', 'smooth-manifolds', 'vector-bundles', 'intuition', 'differential-geometry']"
2931353,Convergence of integrals of all smooth functions implies weak convergence of measures,"Let $\mu$ be a Borel probability measure on $\mathbb{R}^d$ and and let $(\mu_n : n \in \mathbb{N})$ be a sequence of such measures. Suppose that $\mu_n(f) \to \mu(f)$ for all smooth $f$ of compact support. How can I show that $\mu_n$ converges weakly to $\mu$ on $\mathbb{R}^d$ ? I have tried to prove this result by contradiction and directly, however I am unable to make any serious progress on it. I know that if for any continuous bounded $g$ I could find smooth $f_k$ of compact support converging uniformly to $g$ then for any $\varepsilon > 0$ I have $$|\mu(g)-\mu_i(g)| \leq |\mu(g)-\mu(f_k)|+|\mu(f_k)-\mu_i(f_k)|+|\mu_i(f_k)-\mu_i(g)| $$ $$ \leq \varepsilon +|\mu(f_k)-\mu_i(f_k)|+\varepsilon$$ by uniform convergence and the fact that $\mu_i$ are probability measures so we can find some $k$ such that $\|g-f_k\|_\infty \leq \varepsilon$ . Then we use the fact that $\mu_i(f_k) \to \mu(f_k)$ to get $|\mu(g)-\mu_i(g)| \leq 3\varepsilon$ for all large enough $i$ , giving us weak convergence. However I don't believe that there exist smooth $f_k$ of compact support converging uniformly to $g$ for this to work (or at least I can't prove it). I know the result is true if we had a compact subset of $\mathbb{R}^d$ by the Stone-Weierstrass theorem but that does not generalise to this case which leaves me stumped as I can't find any other way to attack the problem. How should I proceed on this question?","['lebesgue-integral', 'measure-theory', 'convergence-divergence', 'weak-convergence']"
2931354,Find the value of $\int\limits_0^{+\infty} \frac{(\coth x-1)(x\coth x-1)}{x} dx$,"Recently I went across an interesting integral $$\int\limits_0^{+\infty} \frac{(\coth x-1)(x\coth x-1)}{x} dx,$$ which numerically seems to equal $1+\gamma-\ln(2\pi)$ . How can we prove it? I tried using the expansion $$\coth x=\frac1x+\sum_{n=1}^\infty\frac{2x}{x^2+\pi^2n^2},$$ but didn't succeed. Any other ways to approach this?","['integration', 'closed-form']"
2931370,Why is the dot product of two vectors a scalar value?,"I'm having some trouble seeing why dot products are said to give scalar values. As a far as I can see, it just gives another vector that is projected onto one of the 2 original vectors. How, then, is the result a scalar quantity. Can someone please explain this to me? Thank you.","['linear-algebra', 'vectors', 'intuition']"
2931388,Integration of $\ln\sin x$ from 0 to $ \frac{\pi}{2}$ by DUIS,"How can we evaluate the integration $$
\int_{0}^{\pi/2}\ln\left(\sin\left(x\right)\right)
\,{\rm d}x
$$ by using DUIS ( differentiation under the integral sign ) ?. This question popped into my head when I read an article about DUIS as $\ln\left(\left\vert\sin\left(x\right)\right\vert\right)$ is the integral of $\cot\left(x\right)$ . Although I am in $12$ th Standard, I am keen to learn new and exciting concepts and techniques, so please tell me if you have any questions related to this. Thanks !.","['integration', 'improper-integrals', 'calculus', 'definite-integrals']"
2931409,Finding limit $\ \lim_{x \to 2} \frac{\cos \frac{\pi}{x}}{x-2}$ without l'hopital's,"Find limit of $$\ \lim_{x \to 2} \frac{\cos \frac{\pi}{x}}{x-2} $$ by using $\ t = \frac{\pi}{2} - \frac{\pi}{x} $ $$\ \lim_{x \to 2} \frac{\cos \frac{\pi}{x}}{x-2} = \lim_{t \to 0} \frac{\cos( \frac{\pi}{2}-t)}{-\frac{\pi}{t}} = \lim_{t \to 0} -\frac{t \cdot \cos(\frac{\pi}{2} - t)}{\pi} = \frac{0 \cdot \cos \frac{\pi}{2}}{\pi} = \frac{0}{\pi}$$ Not sure what am I missing here as the correct answer is $\ \frac{\pi}{4} $ according to wolframalpha. This is exactly the same question, yet even using the way suggested there I didn't get to the answer. Please if you can show solution using the $\ t$ value I gave here and trig identities. I guess there are other ways using l'hopital's rule or something but that's not my intent.","['limits', 'calculus']"
2931428,Teaching a differential equations course to computer science majors,"I am currently teaching an undergraduate course on elementary differential equations in a mixed class of natural science (physics, chemistry, biology, etc) and computer science majors. Since none of the students are mathematics majors, I wanted to tailorfit the course by providing a good balance between theory and applications. In the case of physics, chemistry and biology, the applications are readily available in most differential equations texts. Unfortunately, computer science majors seem to be left out, and when I was asked by students on the use of the course in their field, I was unable to provide a satisfactory answer. I did some search on Google, with a hunch on the existence of applications in the study of algorithms and machine learning. I quickly realized that I am entering unfamiliar territory since I have very little background on computer science myself. I found several research papers but no satisfactory text that uses the undergraduate level concepts directly, compared to, say, applications in physics such as spring vibration and escape velocity that directly use and illuminate the concepts. I think my question is already obvious without stating, but are there any applications of elementary differential equations to computer science that I can use in an undergraduate class? The applications I'm looking for should satisfy the following: Use linear, preferably first or second order ODEs. Do not require a lot of background to explain. Appropriate for inclusion in a written exam.","['education', 'ordinary-differential-equations']"
2931433,Problem in Hythothesis of a given problem,"Let $f$ be a meromorphic function in a neighborhood of the closed unit disk $\bar{\mathbb{D}}$ . Suppose that $f$ is holomorphic in $\mathbb{D}$ and $$ f(z) = \sum_{n=0}^\infty a_n z^n $$ for $z \in \mathbb{D}$ . Prove that if $f$ has a pole on the unit circle $\mathbb{T}$ then the above power series diverges at any $z \in \mathbb{T}$ . This question has been posted before and has a solution.
My question is what if I don't assume that $f$ be a meromorphic function in a neighborhood of the closed unit disk $\bar{\mathbb{D}}$ . The solution posted also does not use this hypothesis. Can I assume that the statement is redundant? How does it affect the problem?","['complex-analysis', 'singularity']"
2931449,Solve $\sin^{3}x+\cos^{3}x=1$,Solve for $x\\ \sin^{3}x+\cos^{3}x=1$ $\sin^{3}x+\cos^{3}x=1\\(\sin x+\cos x)(\sin^{2}x-\sin x\cdot\cos x+\cos^{2}x)=1\\(\sin x+\cos x)(1-\sin x\cdot\cos x)=1$ What should I do next?,['trigonometry']
2931461,Does $\dfrac{d}{dx} f(x) = 0 \Rightarrow f(x)$ is a constant function?,"I've heard this claim many times, that when the derivative of a function is $0$ everywhere in its domain , then that function is a constant function. But what about functions like the following two: $$f : (4,6)\cup (6,7) \to \mathbb{R}$$ $$f(x) = \begin{cases} 2, \, x \in (4,6) \\ \\ 7, \, x \in (6,7) \end{cases} $$ Here, $ f'(x) = 0, \, \forall x \in D_f$ , where $D_f$ stands for domain of $f$ . I'm writing this after I read the proof of something similar to it in this question here: If the derivative of a function is zero, is the function a constant function?","['limits', 'calculus']"
2931479,Does the sequence lemma hold for Hausdorff?,"Munkres Topology: Sequence Lemma Let $X$ be a topological space; let $A \subset X$ . If there is a sequence of points of $A$ converging to $x$ , then $x \in \overline{A}$ ; the converse holds if $X$ is metrizable. This lemma has been asked about before. Lemma 21.2 in Munkres' TOPOLOGY, 2nd ed: The Sequence Lemma My question is about changing ""metrizable"" with ""Hausdorff"". I found a class where in a homework problem set , it says ""This is an example of a non-Hausdorff space in which the sequence lemma holds."" The saying says to me that the class has a version of the sequence lemma that holds for Hausdorff and then there's an example where the sequence lemma holds for something they would not expect, which is non-Hausdorff. (Another explanation is that the example is non-metrizable and then it is additionally pointed out that the example is also non-Hausdorff.) I hope that the version is exactly the same as the one above except for changing ""metrizable"" with ""Hausdorff"". (I cannot find anything of the sort in Week 4 or Notes for whole class.) I have attempted a proof but it has some resemblance to the proof for metrizable spaces. I am choosing to not type up this proof fearing it is wrong because I have somehow assumed metrization.","['continuity', 'general-topology', 'metric-spaces', 'sequences-and-series']"
2931515,Understanding $A=\mathbb{R}^2\setminus(\mathbb{Q}\times \mathbb{Q}^c)$,"How to understand the set complement? I need to understand it as I am working with this set on some topology problem. $$A=\mathbb{R}^2\setminus(\mathbb{Q}\times \mathbb{Q}^c)$$ I can imagine what is going on but is there a proper set theoretic approach to write it. My efforts $A$ is the complement of points like $$\{(a,b)\;|\;a\in \mathbb{Q}, b\in \mathbb{Q}^c\}$$ So complement should look some thing like $\{(a,b)\;|\;a\in \mathbb{Q}^c, b\in \mathbb{R}\}\cup \{(a,b)\;|\;a\in \mathbb{R}, b\in \mathbb{Q}\}$","['elementary-set-theory', 'general-topology']"
2931537,Solve $7^x+x^4+47=y^2$,"Solve $$7^x+x^4+47=y^2$$ where $x, y \in \mathbb{N}^*$ If $x$ is odd then the left term is congruent with $3$ mod $4$ so it couldn't be a perfect square, so we deduce that $x=2a$ and the relation becomes $$49^a+16a^4+47=y^2$$ and it is easy to see that the left term is divisible by $16$ so we obtain that $y=4b$ , so we have to find $a$ and $b$ such that $$49^a+16a^4+47=16b^2$$ From this point I was completely stuck. I think that there are no solutions but how can I prove it?","['number-theory', 'elementary-number-theory']"
2931542,"Clarification of Textbook Explanation of Hessian Matrix, Directional Second Derivative, and Eigenvalues/Eigenvectors","My machine learning textbook has the following section on the Hessian matrix : When our function has multiple input dimensions, there are many second derivatives. These derivatives can be collected together into a matrix called the Hessian matrix . The Hessian matrix $\mathbf{H}(f)(\mathbf{x})$ is defined such that $$\mathbf{H}(f)(\mathbf{x})_{i, j} = \dfrac{\partial^2}{\partial{x_i}\partial{x_j}} f(\mathbf{x}).$$ Equivalently, the Hessian is the Jacobian of the gradient. Anywhere that the second partial derivatives are continuous, the differential operators are commutative; that is, their order can be swapped: $$\dfrac{\partial^2}{\partial{x_i}\partial{x_j}} f(\mathbf{x}) = \dfrac{\partial^2}{\partial{x_j}\partial{x_i}} f(\mathbf{x}) $$ This implies that $\mathbf{H}_{i, j} = \mathbf{H}_{j, i}$ , so the Hessian matrix is symmetric at such points. Most of the functions we encounter in the context of deep learning have a symmetric Hessian almost everywhere. Because the Hessian matrix is real and symmetric, we can decompose it into a set of real eigenvalues and an orthogonal basis of eigenvectors. The second derivative in a specific direction represented by a unit vector $\mathbf{d}$ is given by $\mathbf{d}^T \mathbf{H} \mathbf{d}$ . When $\mathbf{d}$ is an eigenvector of $\mathbf{H}$ , the second derivative in that direction is given by the corresponding eigenvalue. For other directions of $\mathbf{d}$ , the directional second derivative is a weighted average of all the eigenvalues, with weights between $0$ and $1$ , and eigenvectors that have a smaller angle with $\mathbf{d}$ receiving more weight. The maximum eigenvalue determines the maximum second derivative, and the minimum eigenvalue determines the minimum second derivative. Goodfellow, Ian; Bengio, Yoshua; Courville, Aaron. Deep Learning (Page 84). I understood everything until this part: For other directions of $\mathbf{d}$ , the directional second derivative is a weighted average of all the eigenvalues, with weights between $0$ and $1$ , and eigenvectors that have a smaller angle with $\mathbf{d}$ receiving more weight. The maximum eigenvalue determines the maximum second derivative, and the minimum eigenvalue determines the minimum second derivative. None of this makes any sense to me. For instance, what does it mean by ""other directions of $\mathbf{d}$ ""? $\mathbf{d}$ is a unit vector and therefore inherently has a direction. So to say ""other directions of $\mathbf{d}$ "" makes no sense? Also, why does the maximum eigenvalue determines the maximum second derivative, and the minimum eigenvalue determines the minimum second derivative? I've studied elementary linear algebra (including an introduction to eigenvalues and eigenvectors), but this part is not clear to me. I would greatly appreciate it if people could please take the time to clarify this section.","['eigenvalues-eigenvectors', 'machine-learning', 'multivariable-calculus', 'vector-analysis', 'hessian-matrix']"
2931545,Hartshorne II Prop. 6.8 (last step).,"I am having trouble understanding the last line in the proof of this proposition. I have seen this question once on Math.SE and another time in MO, but I couldn't find in either case a clear solution to my doubt. Here is the situation and the claim that Hartshorne does: Let $f\colon X\to Y$ be a morphism between $X$ a complete nonsingular curve and $Y$ any curve such that $f(X)=Y$. We know then that $Y$ is also complete (but may be singular) and that $f$ induces a finite field extension $K(Y)\subseteq K(X)$ between the fraction fields. Goal: $f$ is a finite morphism, i.e. the preimage of an affine open $\operatorname{Spec}{B}$ is an affine open $\operatorname{Spec}{A}$ such that the induced ring morphism makes $A$ a finite $B$-module. So let $V=\operatorname{Spec}{B}$ be an affine open of $Y$ (potentially with some singularities). Regard $B$ as a subring of $K(X)$ (via the identification with $f$) and let $A$ be the integral closure of $B$ in $K(X)$. Then $A$ is a Dedekind domain, finite $B$-module, with fraction field $K(X)$. $U=\operatorname{Spec}{A}$ is a nonsingular curve with fraction field $K(X)$, hence canonically an open subscheme of $X$ (because complete nonsingular curves are canonically isomorphic to the abstract complete nonsingular curve, whose closed points are the dvr's in the corresponding field). Hartshorne claims then that clearly $f^{-1}(V)=U$, but I fail to see why, let alone why this is at all so clear. My attempt: the valuation rings of a field containing a Dedekind domain are precisely the localization of this Dedekind domain at the different non-zero prime ideals. Hence a closed point $P\in X$ is a non-zero prime ideal of $A$ if and only if $\mathcal{O}_{X,P}\supseteq A$, and since $A$ is the integral closure of $B$ in $K(X)$, this is the case if and only if $\mathcal{O}_{X,P}\supseteq B$. But this means precisely that the prime $P$ lies over some prime of $B$ under the identification done via $f$, hence that $P\in f^{-1}(V)$. Is this proof correct? It is far too handwavy for my taste, but I don't know how to write a more formal proof. What would be the right way to write down a complete formal proof of this? Edit: (in an attempt to make my doubt more precise) Why is the image under $f$ of the isomorphic image of $\operatorname{Spec}{A}$ in $X$ contained in $\operatorname{Spec}{B}$? And why is the restriction of $f$ to this isomorphic image the same as the map induced by the inclusion of rigns? I suspect this to be true because we are using $f$ to identify $B$ as a subring of $K(X)$, but I fail to see how to write down an easy formal proof of this. Moreover, since Hartshorne writes ""clearly"", I am afraid that the answer is actually easy and it may follow directly from some of the things I wrote above. But I don't see how. Any help is appreciated, thanks.","['algebraic-curves', 'algebraic-geometry', 'proof-verification']"
2931552,Finding the minimal value of a $4\times 4$ determinant,"The question. Let $\xi=(\xi_1,\xi_2,\xi_3,\xi_4)\in\mathbb R^4$ be a vector with irrational coordinates. I am interested in finding the minimal value $\mu_\xi$ of $$\left\vert \det \begin{pmatrix} a_1 & a_2 & 0 & 1 \\ b_1 & b_2 & 1 & 0 \\ c_1 & c_2 & \xi_1 & \xi_3 \\ d_1 & d_2 & \xi_2 & \xi_4 \end{pmatrix} \right\vert,$$ for $a_1,b_1,c_1,d_1,a_2,b_2,c_2,d_2\in\mathbb Z$ , in terms of the area of the parallelepiped formed by the two vectors $X_i:=(a_i,b_i,c_i,d_i)$ , $i=1,2$ (which I assume linearly independent), in $\mathbb R^4$ . Let's call this area $D(X_1,X_2)$ . I know we have $$\begin{align*} D(X_1,X_2)^2 &= \Vert X_1\Vert^2\Vert X_2\Vert^2-(X_1\cdot X_2)^2 \end{align*},$$ but I have no clue on how to proceed from here. The conjecture. My hope (which would help the construction of another proof a lot) would be that if we chose the $\xi_i$ properly, we can show that the minimal value verifies \begin{equation}
\mu_\xi\geqslant \frac c{D(X_1,X_2)^2}\qquad\qquad (1)
\end{equation} where $c$ is a constant (it may depends on $\xi$ ). Final remarks. Despite the fact that I strongly believe that $(1)$ is true, any proof that would show that $$\mu_\xi\geqslant \frac c{D(X_1,X_2)^\gamma}$$ for a $\gamma<4$ would be of great interest.","['determinant', 'diophantine-approximation', 'real-analysis', 'matrices', 'maxima-minima']"
2931578,What is an example of a non-simple finite extension $K/F$ such that the purely inseparable closure of $F$ in $K$ is simple?,"The standard example of a finite extension that is not simple is to take $k$ to be a field of characteristic $p > 0$ and consider $k(x,y)$ over $k(x^p,y^p)$ . In this case, the extension is purely inseparable too. I was wondering the following: Is it possible to construct a finite extension of fields $K/F$ which is not simple and such that the purely inseparable closure of $F$ in $K$ is simple? The purely inseparable closure of $F$ in $K$ , denoted $I$ , is defined to be the set of all $\alpha \in K$ that are purely inseparable over $F$ . Similarly, the separable closure of $F$ in $K$ is denoted $S$ and is defined to be the set of all $\alpha \in K$ that are separable over $F$ . One can show that $I$ and $S$ are subfields of $K$ containing $F$ . Can anyone give me a hint on how to construct, or even search for, such an extension? I know that we cannot have $SI = K$ , because we can show from the hypotheses that $SI$ is a simple extension of $F$ . In particular, $K$ cannot be normal over $F$ (see Proposition V.6.11 in Lang's Algebra , page 251, third edition). Moreover, $F$ cannot be perfect because every algebraic extension of a perfect field is separable (see Corollary V.6.12 in Lang's Algebra , page 252, third edition), so in particular $F$ cannot be a finite field or have characteristic $0$ . Moreover, this answer by @KConrad on MathOverflow shows that every finite extension of $\Bbb{F}_p(x)$ is simple, so these are also ruled out as candidates for $F$ . I haven't been able to make any progress beyond this, though. I've tried fiddling around with the above standard example of $k(x,y)/k(x^p,y^p)$ , but no matter how I make $K/F$ non-simple I end up with a non-simple purely inseparable closure. Maybe it's because the only example I know of a non-simple extension is the one mentioned at the beginning that I don't know how to create new examples. I spent a bit of time trying to prove that no such extension could exist, but could not make any progress there either. Any help is appreciated. This question is inspired by the problem asked here: A finite extension is simple iff the purely inseparable closure is simple? . Any such example of extension fields $K/F$ would provide a counter-example to the claim in the title of the linked question.","['separable-extension', 'field-theory', 'galois-theory', 'abstract-algebra', 'extension-field']"
2931622,How can I prove this statement about subsets?,"Let $A$ , $B$ , $C$ be sets. Prove that if $A \subseteq C$ and $B \subseteq C$ then $A \cup B \subseteq C$ . This is an exercise in mathematical logic. My attempt to progress forward: This statement can be written as $$
(A \subseteq C) \land (B \subseteq C) → A \cup B \subseteq C\\
(x \in A → x \in C) \land (x \in B → x \in C) → A \cup B \subseteq C
$$ But I am not even sure that is how I am supposed to do it so I am a bit stuck. Can anyone explain to me how to get through this proof? Thanks in advance.","['elementary-set-theory', 'logic']"
2931657,Showing that the sum of two sets of sequences is dense in the sequence space $\ell^1$,"I'm trying to solve the following problem. It's a part of problem 1.14 in Brezies' book on functional analysis. Let $E=\ell^1$ . Consider $$X=\{x=(x_n)_{n\geq1}\in E:x_{2n}=0\ \forall n\geq1\}$$ and $$Y=\{y=(y_n)_{n\geq1}\in E:y_{2n}=\frac{1}{2^n}y_{2n-1}\ \forall n\geq1\}.$$ Show that $\overline{X+Y}=E$ . Here, $\ell^1=\{x:\|x\|_1<\infty\}$ and $$\|x\|_1:=\sum_{k=1}^\infty|x_k|.$$ We have that $\overline{X+Y}\subseteq E$ as $E$ is the ambient space of $X+Y$ , but I'm unsure on how to prove that $E\subseteq\overline{X+Y}$ . Maybe an argument by contradiction would be useful. That is, assume that there exists a $z\in E$ such that $z\notin\overline{X+Y}$ and then arrive to some contradiction. The problem to continue here is that I don't really know what the closure $\overline{X+Y}$ would be. Thus, I don't really know how to proceed with the other part either. I know that we're working in a sequence space, so every element is a sequence. The sequences may have infinitely many elements, so we're in an infinite dimensional space. I know how the norm $$\|(x_n)_{n\in\Bbb{N}}-(y_n)_{n\in\Bbb{N}}\|:=\sum_{k=1}^\infty|x_k-y_k|$$ works, but not really what the sets of the intersection of closed sets would look like, or how they would influence the outcome of the closure. Here, both $X$ and $Y$ are closed. I'm also a bit curious on how addition of sets consisting of sequences works. Is the resulting set such that every sequence point in every sequence is the sum of the sequences in the initial sets $X$ and $Y$ ?","['general-topology', 'functional-analysis', 'sequences-and-series']"
2931690,"Proper notation for ""unpacking"" n-tuples from a set","(I will begin by saying I am unsure if ""unpacking"", as mentioned in the title, is the correct term for what I am about to describe; I use it since it is the correct term for extracting values from a tuple in programming languages.) Consider a set of 2-tuples $A = \{(a_0, b_0), (a_1, b_1), \ldots, (a_n, b_n)\}$ . What is the proper way to write an expression which references the two elements of any tuple in $A$ ? For example, would $$
(\text{some expression involving $x$ and $y$}) \forall (x,y)\in A
$$ be syntactically correct?",['elementary-set-theory']
2931716,Is there are similar conjecture like this??,"Talking with my friend, my friend suggest impressive conjecture that For $i\in\mathbb{N}$, there are always exist natural number $r$ that satisfies
  $$\sum_{n=1}^{i} \frac{1}{n^r}=\frac{p}{q} , \gcd(p,q)=1$$ and $p+q$ is a prime number. For example, $$\sum_{n=1}^{2} \frac{1}{n}=\frac{3}{2}$$ and $3+2=5$. And  $i=3$,  $$\sum_{n=1}^{3} \frac{1}{n^4}=\frac{1393}{1296}$$ and $1393+1296=2689$. $$\sum_{n=1}^{4} \frac{1}{n^2}=\frac{205}{144}$$ and $205+144=349$ which is 70th prime number. In $i=5$
 $$\sum_{n=1}^{5} \frac{1}{n^3}=\frac{256103}{216000}$$ and $256103+216000=472103$. Also  $$\sum_{n=1}^{6} \frac{1}{n^3}=\frac{28567}{24000}$$ and $24000+28567=52567$. There are similer like this? If not, What about your think, is it true? Or false.... I would glad you guys to think about this thing and share opinions for me and my friend's curiosity. Note : ID:metamorphy suggest that 
the sequence of the smallest values of $r$ begins with $1, 1, 1, 1, 1, 2, 1, 3, 1, 1, 1, 2, 34, 1, 1, 5, \ldots$. (There are full comment in bellow with more comments.)","['number-theory', 'conjectures', 'prime-numbers']"
2931723,Volume after transformation.,"Consider $$ \Omega:\{ (x, y, z): x^2+y^2\leq 1, 0\leq z\leq 2 \} $$ and the transform $$ T:(x, y, z)\to(x, y+\tan(\alpha z), z) ,$$ where $ \alpha\in (0, \pi) $ . What is the volume of $ T(\Omega) $ ? My attempt: I am trying to convert to the cylindrical coordinate system, but I can't find the region where I should integrate since it is transformed.","['integration', 'multivariable-calculus', 'calculus']"
2931734,Sufficient statistics for $\lambda$ poisson distribution.,"I have the following question out of a book. I even have the solution from solutions manual that I cannot  really follow either, so I thought I would ask here to see if someone could dumb it down for me. Let $Y_!, Y_2, ..., Y_n$ denote a random sample from a Poisson distribution with parameter $\lambda$ . Show by conditioning that $\sum_{i=1}^{n}Y_i$ is sufficient for $\lambda$ So that is the question. From the solution I can see that they are using the conditional probability, but from the chapter that this question is from you are taught that you show sufficiency by using the likelihood. So what does it mean by ""show by conditioning""? What does the act of conditioning do in this instance? Why would we use conditioning instead of likelihood? Also, just how would you do this question?",['statistics']
2931762,"Finding $f(9999)$ if $f(1) = 2$ and $f(mn) = f(m) \, f(n) - f(m+n) + 1001$ for $m$ or $n$ equal to $1$","Given a function $f$ is defined for integers $m$ and $n$ as given: $$f(mn) = f(m)\,f(n) - f(m+n) + 1001$$ where either $m$ or $n$ is equal to $1$ , and $f(1) = 2$ . The problem itself is to prove that $$f(x) = f(x-1) + 1001$$ in order to find the value of $f(9999)$ . As such, what I've already tried is: Replacing $n$ as $1$ and $m$ as $x$ , and trying to solve from there. $$f(x) = f(1) * f(x) - f(x+1) + 1001$$ $$f(x) = 2 * f(x) - f(x+1) + 1001,$$ Although I'm not sure how I should continue from here, it did occur that the negative sign could be manipulated in some way, but I'm fairly certain that $-f(x+1)$ , cannot be rewritten as $f(-x-1)$ , or anything of the sorts. So if anyone has any thoughts or insight as how I should proceed, it would be greatly appreciated.","['functional-equations', 'induction', 'functions', 'algebra-precalculus', 'problem-solving']"
2931806,"Prob. 8, Sec. 26, in Munkres' TOPOLOGY, 2nd ed: A map into a compact Hausdorff space is continuous iff its graph is closed","Here is Prob. 8, Sec. 26, in the book Topology by James R. Munkres, 2nd edition: Theorem. Let $f \colon X \to Y$ ; let $Y$ be compact Hausdorff. Then $f$ is continuous if and only if the graph of $f$ , $$ G_f = \{ \ x \times f(x) \ \vert \ x \in X \ \}, $$ is closed in $X \times Y$ . [ Hint: If $G_f$ is closed and $V$ is a neighborhood of $f \left( x_0 \right)$ , then the intersection of $G_f$ and $X \times (Y-V)$ is closed. Apply Exercise 7.] And, here is Prob. 7, Sec. 26, in Munkres' Topology , 2nd edition: Show that if $Y$ is compact, then the projection $\pi_1 \colon X \times Y \to X$ is a closed map. Here is a solution to this problem. My Attempt: I think I can slightly generalize Prob. 8, Sec. 26, in Munkres as follows: Let $X$ and $Y$ be topological spaces, and let $f \colon X \to Y$ be a function. (a) If $Y$ is Hausdorff and if $f$ is continuous, then the graph $G_f$ of $f$ is a closed set in the product space $X \times Y$ . (b) If $Y$ is compact and if the graph $G_f$ of $f$ is closed in the product space $X \times Y$ , then the function $f$ is continuous. Am I right? Proof (a): Suppose that $Y$ is a Hausdorff space, and suppose also that the map $f \colon X \to Y$ is continuous. We need to show that the graph $G_f$ of $f$ is closed in the product space $X \times Y$ . For this we show that $(X \times Y) - G_f$ is open in $X \times Y$ . Let $x_0 \times y_0$ be a point of $X \times Y$ such that $x_0 \times y_0 \not\in G_f$ . Then $x_0 \in X$ , $y_0 \in Y$ , but $f \left( x_0 \right) \neq y_0$ . Thus $f \left( x_0 \right)$ and $y_0$ are two distinct points in the Hausdorff space $Y$ . So there exist open sets $U_0$ and $V_0$ in $Y$ such that $$ f \left( x_0 \right) \in U_0, \qquad y_0 \in V_0, \qquad \mbox{ and } \qquad U_0 \cap V_0 = \emptyset. \tag{1} $$ As $f \left( x_0 \right) \in U_0$ , so $x_0 \in f^{-1} \left( U_0 \right)$ , where $$ f^{-1} \left( U_0 \right) \colon= \left\{ \ x \in X \ \colon \ f(x) \in U_0 \ \right\}. $$ And, as $U_0$ is an open set in $Y$ and as $f \colon X \to Y$ is continuous, so the set $f^{-1} \left( U_0 \right)$ is an open set in $X$ . Thus $f^{-1} \left( U_0 \right)$ is a neighborhood of $x_0$ in $X$ . As $x_0 \in f^{-1} \left( U_0 \right)$ and as $y_0 \in V_0$ [Refer to (1) above.], so we can conclude that $x_0 \times y_0 \in f^{-1} \left( U_0 \right) \times V_0$ . And, as $f^{-1} \left( U_0 \right)$ is open in $X$ and $V_0$ is open in $Y$ , so $f^{-1} \left( U_0 \right) \times V_0$ is open in $X \times Y$ ; in fact, the set $f^{-1} \left( U_0 \right) \times V_0$ is a basis element for the product topology on $X \times Y$ . We now show that $$ f^{-1} \left( U_0 \right) \times V_0 \ \subset \ \big(X \times Y \big) - G_f.$$ For this, let $x \times y$ be any point in the set $f^{-1} \left( U_0 \right) \times V_0$ . Then $x \in f^{-1} \left( U_0 \right)$ and $y \in V_0$ , and so $x \in X$ such that $f(x) \in U_0$ and $y \in V_0$ . Now as $f(x) \in U_0$ and $y \in V_0$ and as $U_0 \cap V_0 = \emptyset$ [Refer to (1) above.], so $f(x) \neq y$ , and thus $x \times y \not\in G_f$ . But of course $x \times y \in X \times Y$ . Thus $x \times y \in (X \times Y) - G_f$ . Therefore we can conclude that $$ f^{-1} \left( U_0 \right) \times V_0 \subset (X \times Y) - G_f. $$ Thus we have shown that, for every point $x_0 \times y_0$ in $(X \times Y) - G_f$ , there exists a basis element $f^{-1} \left( U_0 \right) \times V_0$ for the product topology on $X \times Y$ such that $$ x_0 \times y_0 \in f^{-1} \left( U_0 \right) \times V_0 \subset (X \times Y) - G_f. $$ So the set $(X \times Y) - G_f$ is open in the product space $X \times Y$ . Hence $G_f$ is closed in $X \times Y$ . Is this proof correct and clear enough? Proof (b): Suppose that $Y$ is compact, and suppose also that the graph $G_f$ of $f$ is closed in the product space $X \times Y$ . We need to show that the map $f \colon X \to Y$ is continuous. For this we will have to show that the inverse image $f^{-1}(V)$ is open in $X$ for any open set $V$ in $Y$ . Let $V$ be an open set in $Y$ . If $f^{-1}(V)$ is empty, then it is trivially open in $X$ . So we assume that $f^{-1}(V)$ is non-empty. As $V$ is open in $Y$ , so $Y-V$ is closed in $Y$ . And, as $X$ is closed in $X$ and $Y-V$ is closed in $Y$ , so $X \times (Y-V)$ is closed in the product space $X \times Y$ , by Prob. 3, Sec. 17, in Munkres, to which here is a solution. Now as the graph $G_f$ of $f$ is closed in $X \times Y$ by our hypothesis and as $X \times (Y-V)$ is closed in $X \times Y$ , so is the intersection $G_f \cap \big( X \times (Y-V) \big)$ . But we note that $$ 
\begin{align}
 G_f \bigcap \big( X \times (Y-V) \big) &= \{\  x \times y \in X \times Y \ \colon \ y = f(x), \ y \not\in V \ \} \\
& = \{ \ x \times f(x) \ \colon \ x \in X, \ f(x) \not\in V \ \}.  \end{align} \tag{2} $$ Now as the topological space $Y$ is compact, so the projection map $\pi_1 \colon X \times Y \to X$ , defined by $$ \pi_1(x\times y) \colon= x \ \mbox{ for all } x \times y \in X \times Y, \tag{3} $$ is a closed map, by Prob. 7, Sec. 26. And, as the set $G_f \bigcap \big( X \times (Y-V) \big)$ is closed in the product space $X \times Y$ and as the projection map $\pi_1 \colon X \times Y \to X$ , defined by (3) above is a closed map, so the set $$ \pi_1 \left( G_f \bigcap \big( X \times (Y-V) \big)  \right) \colon= \left\{ \ \pi_1 (x \times y) \ \colon \ x \times y \in G_f \bigcap \big( X \times (Y-V) \big) \ \right\}$$ is a closed set in the topological space $X$ . But using the definition of the map $\pi_1$ in (3) above we can write $$ \pi_1 \left( G_f \bigcap \big( X \times (Y-V) \big)  \right)   = \left\{ \ x \in X \ \colon \ x \times y \in G_f \bigcap \big( X \times (Y-V) \big) \mbox{ for some } y \in Y \ \right\}. \tag{4} $$ Thus from (2) and (4) above we can conclude that $$ \pi_1 \left( G_f \bigcap \big( X \times (Y-V) \big)  \right) = \{ \ x \in X \ \colon \ f(x) \not\in V \ \} = X - f^{-1}(V), $$ using the familiar properties of the inverse images of subsets of the range / codomain of a map between sets. Thus we can conclude that $X - f^{-1}(V)$ is closed in $X$ , which implies that $V$ is open in $X$ , as required. Is this proof correct and clear enough also? Are both parts of my proof correct in each and every step? If so, then is it clearly worded and neatly arranged too? If not, then where are the issues? This and this are a couple of posts of mine here on Mathematics Stack Exchange on a similar problem.","['proof-verification', 'closed-map', 'continuity', 'general-topology', 'compactness']"
2931820,Maximum number of weeks that can elapse without having the same four individuals who have served together with the same committee chair,"""Each week, a subcommittee of four individuals is formed from among the
  members of a committee comprising seven individuals. Two subcommittee
  members are then assigned to lead the subcommittee, one as chair and the
  other as secretary. Calculate the maximum number of consecutive weeks that can elapse without
  having the subcommittee contain four individuals who have previously served
  together with the same subcommittee chair."" According to the solutions manual, the answer should be $140$ weeks, however I'm getting $836$ weeks. My approach was: (1) compute binomial coefficients for both segments ( $\binom{7}{4}$ , and $\binom{4}{2}$ ) (2) compute their product (i.e. Fundamental Principle of Counting) and I get $210$ (3) Therefore, unique $4$ -person combo occurs once in $210$ weeks, i.e. number of elapsed weeks between re-occurrences $= 210-1 = 209$ (4) within that unique group, probability of a particular member becoming Chair is $1/4$ , therefore it will take FOUR times as long to see a re-occurrence of that same person as Chair (5) $209$ weeks $\cdot 4 = 836$ weeks Does anybody have any ideas how to solve this problem?","['combinations', 'combinatorics']"
2931833,"Fields with Differential identity, and Amitsur-like results","Let $(K,\partial)$ be an algebraically closed field of characteristic $0$ with $\partial:K\rightarrow K$ a derivation with algebraically closed field of constants $C$ . Question. Is it possible that $K$ satisfy a non-trivial one-variable differential identity (involving $+,\times,\partial$ )? Note that the answer is no for linear identities, i.e. of the for $$\sum_{i=0}^n a_i\delta^i(x)=0,$$ since the zero set of such an identity is of finite dimension over $C$ . Tries. (1) The question seems close to results like ""rings with non-trivial PI-identities have finite dimension over their centre"". An attempt of a proof is to consider the skew law $x*y:=\partial(x)y$ and apply Amitsur's result to the non commutative ring $(K,+,*)$ , but $*$ is non-associative, neither alternative... (2) If $K$ satisfies a nontrivial univariate differential identity, it also satisfies a nontrivial multivariate differential identies that is linear in every variable.","['field-theory', 'ring-theory', 'ordinary-differential-equations']"
2931909,Normal of a point on the surface of an ellipsoid,"Given an ellipsoid in the form: $$ \frac{x^2}{a^2} + \frac{y^2}{b^2} + \frac{z^2}{c^2} = 1$$ and an arbitrary point $p$ on the surface of the ellipsoid, how can I compute the normal vector of the surface in that point? I never learned about the $\nabla$ operator, therefore I'd prefer an explanation that only makes use of basic geometry. Background: I want to model a light source shining on a Go stone , including diffusion and reflection. I think of the stone as an ellipsoid, and I want to place the light source at an arbitrary place, as well as the observer. For that, I plan to use Lambertian reflectance , and for its $\cos \alpha$ I thought I'd take the deviation from the reflected angle and put that into the $\cos \alpha$ formula. I know that this question exists, but I didn't understand it, and it covered only one specific case, not the general case.","['reflection', 'orthogonality', 'geometry']"
2931926,Trace of a Matrix: when to use? what is trace trick?,"On calculating log-likelihood function for some multivariate distributions, such as multivariate Normal, I see some examples where the matrices are suddenly changed to trace, even when the matrix is not diagonal. I searched online to find a plausible explanation for this ""trace trick"" without success. What is it all about? Can someone clarify the usage of trace in this situation? Bellow a slide with an example where you can find this usage of trace.","['statistics', 'matrices', 'matrix-calculus', 'linear-algebra', 'maximum-likelihood']"
2931949,A probability concerning the maximum and minimum of a simple random walk,"Let $X_i$ be i.i.d. such that $\mathbb P(X_i = 1 )=\mathbb P(X_i=-1) =\frac1 2$ . Let $a\in \{1,2,....\}$ , now define the random walk, $S_0=a$ and $$S_n = a+\sum_{i=1}^n X_i$$ Now define the maximum and minimum of the random walk until time index $n$ as follows, $$M_n := \sup_{0\leq j \leq n } S_j,\ \ \ \ m_n:=\inf_{0\leq j\leq n} S_j$$ Let $b\in\mathbb N \backslash \{0\}$ and define $k\in\mathbb N$ such that $0<a,b<k$ . My question: how can I find $$\mathbb P(S_n=b, m_n\leq 0, M_n\geq k)$$ Trials. I wanted to use the reflection principle, so I first considered the cases where the maximum occurred first and where the minimum occured first. I know that both boil down to the same thing, by the duality theorem. So we can as well consider $$u:=\mathbb P(S_n=b, m_n\leq 0, M_n\geq k, \text{ minimum occurred first})$$ See Random walk example for the visualization of random walk I had in mind. So, I start with the blue path. It should cross zero, so I reflected there and got the red path.  Then next I should cross the level $-k$ , but when I get there I reflect again to get the green path. I finnally conclude $$u=\mathbb P(S_n = b-2k)$$ The problem is that I think that this is wrong. Because this finally lead to $$\mathbb P(S_n=b, m_n\leq 0, M_n\geq k)> \mathbb P(S_n=b,  M_n\geq k)$$ which is completely nonsense. Sorry I skipped the calculations, but this is the reason I think it is wrong. If people really want the calculations for $\mathbb P(S_n=b,  M_n\geq k)$ then I can also write it, but I'm afraid it is too much.","['random-walk', 'markov-chains', 'stochastic-processes', 'maxima-minima', 'probability-theory']"
2931966,Showing $Tr_{L/K} \circ Tr_{M/L} = Tr_{M/K}$ where $K \subseteq L \subseteq M$ is a tower of field extensions - *Algebraic Number Theory* by Neukerich,"I'm reading Algebraic Number Theory by Neukirch and I'm having trouble the proof for the statement: (2.7) Corollary: I a tower of finite field extensions $K \subseteq L \subseteq M$ , one has $$Tr_{L/K} \circ Tr_{M/L} = Tr_{M/K}, \qquad N_{L/K} \circ N_{M/L} = N_{M/K}.$$ Here we assume $M/K$ is separable. The part of the proof im having trouble with is the identity $$Tr_{M/K}(x) = \sum_{i = 1}^{m}\sum_{\sigma \sim \sigma_{i}}\sigma(x) = \sum_{i = 1}^{m}Tr_{\sigma_{i}M/\sigma_{i}L}(\sigma_{i}(x)) = \sum_{i = 1}^{m}\sigma_{i}Tr_{M/L}(x) = Tr_{L/K}(Tr_{M/L}(x))$$ where $m = [L:K]$ and the $\sigma_{i}$ are representatives for equivalence classes under the relation $\sigma \sim \tau \iff \sigma|_{L} = \tau|_{L}$ . I believe the first equality, but I don't see how the second and third hold. I understand the $\sigma:M \rightarrow \overline{K}$ in $[\sigma_{i}]$ are $K$ -embeddings, and hence restricted to $L$ are also $K$ -embeddings, but I dont see how the inner sum corresponds to $Tr_{\sigma_{i}M/\sigma_{i}L}(\sigma_{i}(x))$ . We can express $Tr_{\sigma_{i}M/\sigma_{i}L}(\sigma_{i}(x))$ as a sum of $\sigma_{i}L$ embeddings from $\sigma_{i}M$ into $\overline{\sigma_{i}L}$ evaluated at $\sigma_{i}(x)$ but these aren't the $\sigma$ in $\sigma_{i}$ above, are they? They certainly don't look like them as maps. Also what justification do we have to factor the $\sigma_{i}$ out in the third equality? I think these two questions have trivial answers, but I just cant see it. Any help is appreciated!","['algebraic-number-theory', 'trace', 'field-theory', 'abstract-algebra', 'extension-field']"
2932012,Strict Epimorphism of Schemes,"I am reading Milne's Etale Cohomology and ran across this problem which has so-far eluded me. According to Milne, in any category with fiber products, we say that a morphism $f:Y \to X$ is a strict epimorphism if the sequence of sets $$\operatorname{Hom}(X,Z) \overset{f^*}{\to} \operatorname{Hom}(Y,Z) \underset{p_2^*}{\overset{p_1^*}{\rightrightarrows}} \operatorname{Hom}(Y \times_X Y,Z) $$ is exact for all objects $Z$ , that is, an equaliser in the category. Now fix our category to be schemes over a field $k$ , and consider the morphism $\operatorname{Spec}(k[t]) \to \operatorname{Spec}(k[t^3,t^5])$ . The question is to show that this is an epimorphism that is not strict. The map on underlying rings is injective, and easily seen to be surjective on spectra, so this is certainly an epimorphism in Sch/ $k$ , yet I am seemingly unable to produce a scheme $Z$ which makes the above diagram fail. One thought was to regard $\operatorname{Spec}(k[t^3,t^5])$ as a cuspidal curve $y^3-x^5$ in affine 2-space, and then blow up at the origin. The exceptional divisor of the strict transform would then be a triple point (nilpotent), and so hopefully this would mess things up appropriately. Yet I cannot seem to find a section. The blow up comes with a natural map down to the original curve, but I am struggling to find one upwards.","['etale-cohomology', 'algebraic-geometry', 'epimorphisms', 'category-theory']"
2932076,"Find all values of a,b,c such that a-b = c, a,b,c are three digit numbers and the digits are distinct.","Hello everyone this is my first question on here. What is the relation between a and b when a-b=c | a,b,c ∈ Z | 123 ≤ a,b,c ≤ 987 and a,b,c have distinct digits 1-9. For example one possible value of a and b are: a = 459, b = 173, c = a-b = 286. This works as no digit repeats, it is a three digit number, 0 is not used and a is greater than b. I've gone through every possibility with a computer which gives 336 possible combinations of a and b. Obviously though a-b=c and a-c=b are both true so every combination has a ""duplicate"". I have not yet found a way of deriving these numbers with a mathematical rule, as it doesn't fit with any standard formulas. If anyone could find one i'd be very interested. Here's the list of possible values of a (left-column) and b if it can be of aid: 459    :  173, 176, 183, 186, 273, 276, 283, 286 468    :  173, 175, 193, 195, 273, 275, 293, 295 486    :  127, 129, 157, 159, 327, 329, 357, 359 495    :  127, 128, 167, 168, 327, 328, 367, 368 549    :  162, 167, 182, 187, 362, 367, 382, 387 567    :  128, 129, 138, 139, 218, 219, 248, 249, 318, 319, 348, 349, 428, 429, 438, 439 576    :  182, 184, 192, 194, 382, 384, 392, 394 594    :  216, 218, 276, 278, 316, 318, 376, 378 639    :  152, 157, 182, 187, 452, 457, 482, 487 648    :  251, 257, 291, 297, 351, 357, 391, 397 657    :  218, 219, 238, 239, 418, 419, 438, 439 675    :  182, 183, 192, 193, 281, 284, 291, 294, 381, 384, 391, 394, 482, 483, 492, 493 693    :  215, 218, 275, 278, 415, 418, 475, 478 729    :  143, 146, 183, 186, 543, 546, 583, 586 738    :  142, 146, 192, 196, 542, 546, 592, 596 783    :  124, 129, 154, 159, 214, 219, 264, 269, 514, 519, 564, 569, 624, 629, 654, 659 792    :  134, 138, 154, 158, 634, 638, 654, 658 819    :  243, 246, 273, 276, 352, 357, 362, 367, 452, 457, 462, 467, 543, 546, 573, 576 837    :  142, 145, 192, 195, 241, 246, 291, 296, 541, 546, 591, 596, 642, 645, 692, 695 846    :  317, 319, 327, 329, 517, 519, 527, 529 864    :  125, 129, 135, 139, 271, 273, 291, 293, 571, 573, 591, 593, 725, 729, 735, 739 873    :  214, 219, 254, 259, 614, 619, 654, 659 891    :  234, 237, 254, 257, 324, 327, 364, 367, 524, 527, 564, 567, 634, 637, 654, 657 918    :  243, 245, 273, 275, 342, 346, 372, 376, 542, 546, 572, 576, 643, 645, 673, 675 927    :  341, 346, 381, 386, 541, 546, 581, 586 936    :  152, 154, 182, 184, 752, 754, 782, 784 945    :  162, 163, 182, 183, 317, 318, 327, 328, 617, 618, 627, 628, 762, 763, 782, 783 954    :  216, 218, 236, 238, 271, 273, 281, 283, 671, 673, 681, 683, 716, 718, 736, 738 963    :  215, 218, 245, 248, 715, 718, 745, 748 972    :  314, 318, 354, 358, 614, 618, 654, 658 981    :  235, 236, 245, 246, 324, 327, 354, 357, 624, 627, 654, 657, 735, 736, 745, 746 Also, I've noticed the sum of every ""a"" value is 18, this may be significant. A sub question that I have aswell is why the number of possibilities is 336. I noticed it is equal to $8*7*6$ but why I don’t know. Thankyou for taking the time to read this question.",['combinatorics']
2932125,Integral of Binomial Coefficient,"We all know the famous theorem that: $$\sum_{i=1}^n\binom{n}{i}=2^n$$ This theorem got me wondering about a similar formula - the properties of the following function: $$I(n)=\int_{0}^{n} \binom{n}{k}\,\,\mathrm{d}k$$ where $n$ is any positive integer and the definition of binomial coefficient is ""extended"" by way of gamma functions (i.e the integrand is really $\frac{\Gamma(n+1)}{\Gamma(k+1)\Gamma(n-k+1)}$ ). 
What I found, experimentally, is pretty cool. It seems that the following is true: $$I(n)=\frac{2}{\pi} \sum_{i=1}^n \binom{n}{i}\operatorname{SinInt}(\pi i)$$ Where $\operatorname{SinInt}(x)$ is the Sine Integral , or $\int_0^x \frac{\sin t}{t}dt$ . To me, this is quite interesting as the Sine Integral tends to $\pi/2$ so the above formula will tend to $2^n$ , so the integral is just the sum with some error term. But how would I go about proving it?","['integration', 'calculus', 'definite-integrals']"
2932196,Why the equation $3\cdot0=0$ needs to be proven,"In Algebra by Gelfand Page 21 ( for anyone owning the book). He tries to prove that: $3\cdot(-5) + 15 = 0$ . Here's his proof: $3\cdot(-5) + 15 = 3\cdot(-5) + 3\cdot5 = 3\cdot(-5+5) = 3\cdot0 = 0$ . After that he said: The careful reader will asky why $3\cdot0 = 0$ . Why does this equation need to be proven ? I asked somewhere and was told that $a\cdot0=0$ is an axiom which maybe Gelfand didn't assume was true during his proof. But why does it need to be an axiom, it's provable: In the second step of his proof he converted 15 to $3\cdot5$ so multiplication was defined so $a\cdot0 = (0 + 0 + \cdots)$ x times $= 0$ . I'm aware multiplication is defined as repeated addition only for integers, but 3 is an integer so this definition works in my example. In case my question wasn't clear it can be summed up as: Why he takes $3\cdot5=15$ for granted but thinks $3\cdot0=0$ needs an explanation?",['algebra-precalculus']
2932269,"Calculating the probability of a specific event knowing only the expected value, without distribution","I'm having some trouble with the following exercise question. An office parking lot provides 12 parking spots. There are 14 employees. On average, 10 employees arrive by car. What is the probability that parking space is sufficient on a given working day? My attempt so far: As I understand, ""on average"" is equivalent to the expected value. Let $X$ denote the number of employees arriving on a day. Then, $$E (X) = \sum_{i=0}^{14} p_i x_i = 10$$ So the distribution isn't uniform, since then the expected value would be 7. Also, this implies $P(X \leq 10) = P(X \geq 10)$ , although I don't see how that's useful. What I need to calculate is $$P(X \leq 12) = \sum_{i=0}^{12} p_i x_i = 1- \sum_{i=13}^{14} p_i x_i$$ Now, without knowing the distribution, I'd say there is no way to obtain the correct solution. For instance, it could be that $p_{10} = 1$ and then $P(X \leq 12) = 1$ . It could also be that $p_{6} = p_{7} = p_{13} = p_{14} = 0.25$ and then $P(X \leq 12) = 0.5$ I also don't see any point in assuming a normal distribution in this case. If it were centered on the median value, the expectation would be 7 cars instead of 10 per day. If it were centered on 10, the expectation would be less then 10, because $p_i = 0$ for $i > 14$ . It could work if it were centered somewhere between 10 and 14, but what sense does that make? Am I missing something?","['statistics', 'probability-distributions', 'discrete-mathematics', 'probability-theory', 'probability']"
2932360,Any idea how to find $\lim_{x\to 0} \frac{\sqrt{1-\cos(x^2)}}{1-\cos(x)}$?,"$$\lim_{x\to 0} \frac{\sqrt{1-\cos(x^2)}}{1-\cos(x)}$$ I am trying to solve this limit for 2 days, but still cant find the solution which is $\sqrt{2}$ (that's what is written in the solution sheet) I tried multiplying with the conjugate, tried with some identities but nothing much because of that $x^2$ in the $\cos$ .
Then i tried L'Hopital because it is $\frac{0}{0}$ and still that $\cos$ in the square root is doing problems. I tried on symbolab  calculator but it  can't solve it. So can someone help me how to solve this?
Thank you.","['limits', 'real-analysis']"
2932482,Probability that sheepdog performs at least one task successfuly - Am I doing this problem right?,"What is the probability that a sheepdog performs at least $1$ of these tasks successfully? My approach is to subtract the probability of performing at most $1$ of these tasks successfully from the probability of performing all $4$ tasks successfully. $P(\text{fetch})=.9, P(\text{drive})=.7, P(\text{herd})=.84, P(\text{separate})=.75$ . The complement of these four probabilities is, $.1,.3,.16,$ and $,.25$ , respectively. So the probability that the sheepdog performs all four tasks successfully is simply, $(.9)(.7)(.84)(.75)$ . The probability that the sheepdog performs at most $1$ task successfully can be split into $4$ cases. Either the sheepdog performs the fetch task (and not the other 3) successfully, performs the drive task, performs the herd task, or performs the separate task. This would look like: $(.9)(.3)(.16)(.25)+(.1)(.7)(.16)(.25)+(.1)(.3)(.84)(.25)+(.1)(.3)(.16)(.75)$ Subtracting this from the case in which the sheepdog performs all four tasks would yield: $(.9)(.7)(.84)(.75)-[(.9)(.3)(.16)(.25)+(.1)(.7)(.16)(.25)+(.1)(.3)(.84)(.25)+(.1)(.3)(.16)(.75)]$ . Is this correct?","['combinatorics', 'probability']"
2932511,"Connected components of $PGL(n, \mathbb{R})$ ond $PGL(n, \mathbb{C})$","I know that the $PGL(n, \mathbb{R})$ or $PGL(n, \mathbb{C})$ is Lie group, because $PGL(n, F) = GL(n, F) / Z(n, F)$ , where $Z(n, F)$ - scalar transformation and $F$ is $\mathbb{C}$ or $\mathbb{R}$ . I think, that $PGL(n, \mathbb{C})$ is connected because $GL(n, \mathbb{C})$ is connected and $Z(n, F)$ is set of constant. I want to say that the path from $GL(n, \mathbb{C})$ descends to the quotient - $PGL(n, \mathbb{C})$ . (or we can use that projection $P: GL(n, \mathbb{C}) \rightarrow GL(n, \mathbb{C}) / Z(n, \mathbb{C})$ is continuous map, and the image of connected space is also connected) But what to do in the case of $\mathbb{R}$ and how to find all the connected components? Thank you so much!","['general-topology', 'topological-groups', 'lie-groups', 'connectedness']"
2932516,Taylor Series Method for a DE,"I'm going through a practice exam which has solutions and I'm a bit confused about this question: Write down the third order Taylor series method for the differential equation $y'(x)=-y+x+1, \ \ 0\le x\le1, \ \ y(0)=1.$ Compute three steps using $h=0.1$ . The solutions computes derivatives as $ \displaystyle f(x,y)=-y+x+1, \frac{d}{dx}f(x,y)=y-x,\frac{d^2}{dx^2}f(x,y)=-y+x.$ I don't understand how on earth this was achieved. Is there a different type of differentiation at play here? When I did it I obtained $ \displaystyle f(x,y)=-y+x+1, \frac{d}{dx}f(x,y)=-y'+1,\frac{d^2}{dx^2}f(x,y)=-y''$ . What am I missing here?","['numerical-methods', 'taylor-expansion', 'ordinary-differential-equations']"
2932541,How is $(x+y)^p \equiv x^p + y^p$ mod $p$ for any prime number $p$?,"I'm currently studying for an exam and on the practice test given to us (with solutions), there is a problem that states the following: Notice that for all $x,y \in \Bbb Z$ , $(x+y)^2 = x^2 + 2xy + y^2 \equiv x^2 + y^2$ mod $2$ $(x+y)^3 = x^3 + 3x^2y + 3xy^2 + y^3 \equiv x^3 + y^3$ mod $3$ $(x+y)^5 = x^5 + 5x^4y + 10x^3y^2 + 10x^2y^3 + 5xy^4 + y^5 \equiv x^5+y^5$ mod $5$ Prove that if $p$ is any prime number then for all $x,y \in \Bbb Z$ we have $(x+y)^p  \equiv x^p + y^p$ mod $p$ . Here is the proof that was provided to us in the solutions: Let $p$ be a prime number. If $k$ is an integer satisfying $1 \leq k \leq p-1$ , then $k! = 1\cdot2\cdot3\cdot\cdot\cdot k$ is a product of positive integeres smaller than $p$ , and therefore $k!$ is not divisible by $p$ . For the same reason, if $1 \leq k \leq p-1$ then $(p-k)! = 1\cdot2\cdot3\cdot\cdot\cdot (p-k)$ is not divisible by $p$ . Since $p!$ obviously is divisible by $p$ , we infer that $\binom{p}{k} = \frac{p!}{k!(p-k)!} \equiv 0$ mod $p$ whenever $1 \leq k \leq p-1$ . Therefore $(x + y)^p = x^p + y^p +\sum_{k=1}^{p-1} \binom{p}{k}x^k y^{p-k} \equiv x^p +y^p$ mod $p$ . Q.E.D. I'm having trouble understanding a few things about this theorem and proof. First, I'm not quite seeing the congruence (if that makes any sense). Like, I'm not seeing how $(x+y)^2 = x^2 + 2xy + y^2 \equiv x^2 + y^2$ mod $2$ , or rather just in general for any power $p$ , not just $2$ . I recall that we say $a \mid b$ if there exists some $c$ such that $ac = b$ , and that we say if $a,b \in \Bbb Z$ and $n \in \Bbb N$ , $a$ is congruent to $b$ modulo $n$ if and only if $n\mid (b-a)$ . This is written as $a \equiv b$ (mod $n$ ) where $n$ is called the modulus, and from this we get residue classes $r$ that are all the sets of numbers of the form $a = bn + r$ where $r \in \{0,1,2,\cdot\cdot\cdot, n-1\}$ . I'm not quite sure how to phrase that but I can picture what it's supposed to be in my head. I saw that in an answer listed here Proving $(a+b)^{p} \equiv a^{p} + b^{p} \pmod{p}$ for prime $p$ that someone says ""because nothing in the denominator divides $n$ . So all of the middle terms in the expansion of $(a+b)^p$ vanish modulo $p$ , and you're left with the two ends: $a^p+b^p$ ."" But it still isn't making sense to me. How is it that because the denominator doesn't divide the numerator, all the messy middle terms disappear? The next question I have is why go about proving it this way? What is the motivation for the techniques used to prove this statement? When I first saw this problem, admittedly I didn't know where to start. Part of me thought about induction but that was quickly ruled out based on the fact we're only considering prime powers. I did however immediately recognize that we're using binomial expansion and pascal's triangle, but that's about it. I apologize for the long winded post and lots of questions, but this problem currently isn't making a lot of sense to me, so I would be incredibly grateful if somebody could explain this proof and its ideas to me. Thank you!","['number-theory', 'congruence-relations', 'abstract-algebra', 'modular-arithmetic']"
2932552,image of polynomial map is not an algebraic set,"I am doing an exercise about algebraic geometry, where the exercise  tell us to provide example of the image of polynomial map $f:\mathbb{C}^{m}\rightarrow \mathbb{C}^{n}$ that is not an algebraic set. But I am thinking that the image of every polynomial is $\mathbb{C}$ thus every polynomial map is surjective. What have I misunderstand?",['algebraic-geometry']
2932553,Simply this expression $\frac{\log_a(\log_b(a))}{\log_b(\log_a(b))}$,"How do I evaluate this $$\frac{\log_a(\log_b(a))}{\log_b(\log_a(b))}\tag{1}$$ My Efforts I know this identity $$\log_a(b)=\frac{\log_d(b)}{\log_{d}(b)}\tag{2} $$ Let us fix a base say $e$ and  I will call $\log$ to base $e$ simply as $\ln$ So let us see what numerator evaluates to Using $(2)$ once we get, $$\log_a(\log_b(a))=\frac{\ln(\log_b(a))}{\ln(a)}$$ Again using $(2)$ $$\log_a(\log_b(a))=\frac{\ln\left(
\frac{\ln(a)}{\ln(b)}\right)}{\ln(a)}\tag{3}$$ Similarly denominator evaluates to $$\log_b(\log_a(b))=\frac{\ln\left(
\frac{\ln(b)}{\ln(a)}\right)}{\ln(b)}\tag{4}$$ Using $(3)$ and $(4)$ in $(1)$ , we get $$\log_a(b)=\frac{\log_d(b)}{\log_{d}(b)}\tag{5}= \frac{\frac{\ln\left(
\frac{\ln(a)}{\ln(b)}\right)}{\ln(a)}}{\frac{\ln\left(
\frac{\ln(b)}{\ln(a)}\right)}{\ln(b)}}$$ which further evaluates to $$-\frac{\ln(b)}{\ln(a)}$$ which is equal to $$-\log_a(b)$$ Am I correct?","['algebra-precalculus', 'proof-verification', 'logarithms']"
2932605,Calculating the value of the limit,"$$\lim_{(x,y)\to(1,2)}(\sin(y)-\sin(x))$$ My try: I got as $$\sin(2)-\sin(1)$$ But I cannot calculate the exact value of the given limit. Can anyone please explain this.","['limits', 'multivariable-calculus']"
2932608,"Discontinuity of $f(x,y)=\frac{2(x^3+y^3)}{x^2+2y}$ at $(x,y) = (0,0)$","Let $f(x,y)=\frac{2(x^3+y^3)}{x^2+2y}$ , when $(x,y) \neq (0,0)$ and $f(x,y)=0 $ when $(x,y)=(0,0)$ We are required to prove the discontinuity of this function at $(0,0)$ .
So, I put $y=mx$ where $x \rightarrow 0$ , to get the limit to be $0$ .
But I can't find another instance where the limiti is different.
Can you guys help?
Thanks","['multivariable-calculus', 'calculus', 'continuity', 'real-analysis']"
2932631,Algebra: Can you think of each side of the equation as a term?,"For example with the equation $$5x-4 = 2x +5$$ Is the accepted theory that you think of this equation in terms of: $(5x-4) = (2x+5)$ when you are doing an operation to both sides.
Lets say I wanted to multiply by $3$ , I would do: $$3(5x-4) = 3(2x+5)$$ Is there ever a scenario that would break the rule of thinking of equations in a matter of each side being a whole term? Is this the accepted way of solving equations?",['algebra-precalculus']
2932656,People's preferences assigning them to a group using Excel,"I would love some assistance with the following problem. Each year for school camps we take the students preferences 1-6 of who they'd like to bunk in with for the week. We usually sort this out manually, but there has to be a much quicker way to do it using Excel.
(Is this a marriage problem?- I just read about it on this site) +Each student should have at least one preference
+The problem is that some students aren't chosen by anyone else, but they must still be placed with another student of their choosing.
+There are rooms for 4, 6 and 8 students to a room.
+Although the image shows 26 possibilities of the preferences as given by students, there are actually 104 students. Using mathematics and excel are a personal interest of mine, but i am in the beginning stages of my skills so please explain your thoughts in layman's terms. If anyone can give an example of how to do it in Excel I'd be so grateful. Cheers","['recreational-mathematics', 'combinatorics']"
2932698,Compute the number of 7-digit sequences that contain a 5-digit consecutive substring,"Let say any 7-digit sequence, even 0000000 is a valid number. Compute the number of sequences that contain a 5-digit consecutive substring. For example “23456” and “12345”? Approached it as (where X can be (0-9)) :
Which gives me a total as 1800, however the answer is 1700. Can you please point out what I over-counted and share a wise way to approach similar question ? 0 1 2 3 4 X X 
 1 2 3 4 5 X X
 2 3 4 5 6 X X
 3 4 5 6 7 X X
 4 5 6 7 8 X X
 5 6 7 8 9 X X 

 X 0 1 2 3 4 X  
 X 1 2 3 4 5 X 
 X 2 3 4 5 6 X 
 X 3 4 5 6 7 X 
 X 4 5 6 7 8 X 
 X 5 6 7 8 9 X

 X X 0 1 2 3 4  
 X X 1 2 3 4 5 
 X X 2 3 4 5 6 
 X X 3 4 5 6 7 
 X X 4 5 6 7 8 
 X X 5 6 7 8 9","['permutations', 'combinations', 'combinatorics']"
2932729,"Boxed lottery tickets, rencontres numbers and number of degree-$n$ permutations of order exactly $d$","This is a question that I encountered at work that I am trying to get a deeper understanding of. We sell tickets in a lottery where you guess $4$ numbers out of range of $36$ (the range is irrelevant to this problem) in an order. Four numbers are drawn. If your first guessed number matches the first drawn number it is considered a match, likewise for the second, third and fourth draws. You get different prizes for how many numbers you get matched.  Matching all four gets you an $S4$ prize, matching three gets you an $S3$ prize and so on. However we also offer a ""boxed"" ticket, which is equivalent to buying all $24$ permutations of the $4$ numbers you selected. You can determine how many prizes of each class you will win for the count of matching numbers from this table: $$\begin{array}{ |c | c | c | c | c | } \hline
\text{Matching Numbers} & S4 & S3 & S2 & S1 \\
4 & 1 & 0 & 6 & 8 \\
3 & 0 & 1 & 3 & 9 \\
2 & 0 & 0 & 2 & 8 \\
1 & 0 & 0 & 0 & 6 \\
\hline
\end{array} $$ Now the "" $4$ "" matching row is the number of permutations of $4$ with $4$ , $3$ , $2$ , $1$ fixed points, i.e. the rencontres numbers $n=4$ . This naturally falls out of the problem description and I understand this. By use of the OEIS database I was able to work out that $3$ matching number row corresponds to number of degree- $n$ permutations of order exactly $2$ . Row 2 matching number row corresponds to number of degree- $n$ permutations of order exactly $3$ . I am unsure if this is a genuine correspondence or if it is a coincidence. I am wondering if there is a general way to generate this table, for example for a lottery with n selected numbers.","['permutations', 'combinatorics', 'lotteries']"
2932733,Can a Cartesian product of nonelements of Sigma Algebras be in the Product Sigma Algebra?,"If $F$ and $G$ are sigma algebras, then $F\times G$ , i.e. the set of all Cartesian products of elements of $F$ and elements of $G$ , is not a sigma algebra.  But it is possible to define a product sigma algebra of $F$ and $G$ , namely by finding the sigma algebra generated by $F\times G$ .  It consists of way more than just Cartesian products of elements of $F$ and $G$ . My question is, can the product sigma algebra of $F$ and $G$ contain a Cartesian product of two sets which are not elements of $F$ and $G$ ?  Can it contain the Cartesian product of an element of $F$ with a non-element of $G$ , or vice verse?","['direct-product', 'measure-theory']"
2932746,How to solve following integral,"I am trying to solve following integral. $$=\int_0^\infty\frac{x}{x^n+(\epsilon+\sigma)}dx$$ I started by assuming that $a = \epsilon + \sigma$ and $$\implies x^n = A\tan^2(\theta)$$ Then, $$\implies x = a^{1/n}\tan^{2/n}(\theta)$$ $$\implies dx = \frac{2a^{1/n}}{n} (\tan(\theta))^{2/n-1}\sec^2(\theta)\text{ d}\theta$$ Using $\tan^2(\theta)+1 = \sec^2(\theta)$ and substituing above equations, we can write Eq. 1 as: $$=\frac{\frac{2a^{2/n}}{n}(\tan(\theta))^{4/n-1}\sec^2(\theta)\text{ d}\theta}{\sec^2(\theta)}$$ $$=\int_0^{\pi/2}\frac{2a^{2/n}}{n}(\tan(\theta))^{4/n-1} \text{ d}\theta$$ let $B = \frac{2a^{2/n}}{n}$ , then $$=\int_0^{\pi/2}B(\tan(\theta))^{4/n-1} \text{ d}\theta$$ Now, I don't know how to proceed forward The Final answer by authors is: $\large \frac{\pi\sigma(\epsilon+\sigma)^{2/n-1}}{n\sin(\frac{2\pi}{n})}$","['integration', 'improper-integrals', 'definite-integrals']"
2932756,Understanding Conditional Probability (Math is Fun),"I have trouble understanding a simple concept from Math is Fun . STATEMENT: 70% of your friends like Chocolate, and 35% like Chocolate AND like Strawberry. What percent of those who like Chocolate also like Strawberry? SOLUTION: P(Strawberry|Chocolate) = P(Chocolate and Strawberry) / P(Chocolate) 0.35 / 0.7 = 50% . Hence 50% of your friends who like Chocolate also like Strawberry WHAT I CAN'T UNDERSTAND: What is the difference between the statements that ""35% of friends like both Chocolate and Strawberry"" and ""friends who like Chocolate also like Strawberry"". Just a play of words, practically they seem exact same to me. Am I missing something ?",['probability']
2932838,Why must subbundle be an embedded submanifold?,"In John Lee's smooth manifold, pg 264, or 199 in this version , he defines Let $\pi:E \rightarrow M$ be a vector smooth bundle. A subbundle $\pi|_D:D \rightarrow M$ is called a smooth subbundle if it is smooth vector bundle and an embedded submanifold with or without boundary. Being embedded in Lee's definition has two conditions: It is a topological embedding. It is a smooth immersion. That is $di_p :T_pD \rightarrow T_pE$ is injective for all $p \in D$ . $D$ can be given  subspace topology. 1. is then satisfied. But why do we require in the definition that it is a smooth immersion? Is this condition additonal? Or could actually be deduced?","['definition', 'differential-topology', 'smooth-manifolds', 'differential-geometry']"
2932845,Proving formula sum of product of binomial coefficients,"I have to proof the following formula
\begin{align}
\sum_{k=0}^{n/2} {n\choose2k} {2k\choose k} 2^{n-2k} = {2n\choose n}
\end{align} I tried to use the fact that ${2n\choose n} = \sum_{k=0}^{n} {n\choose k}^2$, but I don't get any conclusion. Any suggestions? Thanks in advance!","['binomial-coefficients', 'combinatorics', 'combinatorial-proofs', 'probability']"
2932869,$a-b$ divides $a^n-b^n$,"I wish to prove that for integers $a,b$ it is always true that $a-b$ divides $a^n-b^n$ . I want to do this via induction. For our base case $n=1$ it holds that $a-b|a-b$ . Our hypthesis would be that for some $k$ we know $a-b|a^k-b^k$ or equivalently for some integer l: $$a^k-b^k =l (a-b) $$ How would I use this to prove that: $$a^{k+1}-b^{k+1} =l' (a-b) $$ I was thinking I could use some clever factoring or something like the binomial theorem, but not quite sure. Could someone provide a tiny hint?","['number-theory', 'induction', 'divisibility']"
2932942,How much time elapses by which time a thief has a $50\%$ chance of success in opening a combination lock?,"So I am not entirely sure I have approach the question correctly and at first I thought it to be pretty straight forward but there is something in the wording of the question that make me think there is more to it. A safety lock on a brief case has a keypad. It is unlocked by pressing four digits each in the range $0$ to $9$ inclusive in succession. Mechanical restrictions imply that no single digit features more than once in the code and the order of pressing of the four digits is irrelevant. How many distinct combinations can there be? A thief has stolen the brief case and is attempting to open it by trying different combinations. It takes $5$ seconds for him to key in one combination. If he does this systematically
  using a prepared list of numbers, What is the maximum time elapsed before he must succeed? What is the time elapsed by which he has a $50\%$ chance of success? So my solutions are as follows: For the number of combinations we are essentially looking at $10\times 9 \times 8=720$ possible combinations. For 1. I believe it would take him an hour to crack open the case as, the last set of numbers of the prepared could be the combination he looking for. So my calculation $720\times5=3600~\text{s}=1~\text{hr}$ Question 2 is the part that tripping me up as, he has $50\%$ chance of success, so originally I thought well this is half the number of combinations which mean that he would then only take $30$ min to crack the case. But thinking a little more I can't help but think this is wrong, but I don't really have a solid justification way it more a intuition telling me something not quite right, if I am incorrect could some maybe give me a nudge in the right direction.","['word-problem', 'combinatorics', 'discrete-mathematics']"
2933000,What is the difference between a Savitzky-Golay filter and LOESS?,"I don't fully understand the difference between these two smoothing algorithms. It seems like they both take a window, fit a polynomial, sample from the fit, and move on. I would guess maybe the difference lies in the weighting function used by LOESS but not by the Savitzky-Golay filter, but I'm not sure exactly how this works or what the ultimate effects on the fit would be. I'm particularly interested in the differences and relative advantages/disadvantages to each for fitting data that is not evenly sampled. I understand there's a generalized Savitzky-Golay filter that works for non-evenly sampled data, albeit much less efficiently.","['regression', 'statistics']"
2933039,Computing quotient by dividing formally in $p$-adic number system,"From Gouvea's p-adic Numbers : To pass from positive integers to positive rationals, we simply do
  exactly as in the other case, that is we expand both numerator and
  denominator in powers of p, and then divide formally . The only thing
  one has to be careful with is that one may have to 'carry.' The sum of
  two of our $a_i,$ for example, may be larger than p, and one has to do
  the obvious thing. It's probably easier to go straight to an example. Here is his example: Let's take $p = 3$ and consider the rational number 24/17. Then we
  have $ a = 24 = 0 + 2 \times 3 + 1 \times 3^2 = 2p + 2p^2$ and $ b = 17 = 2 + 2 \times 3 + 1 \times 3^2 = 2+ 2p + p^2$ (Though of course $p = 3$ it's probably less confusing to write $p$ ,
  because one is less tempted to ""add it all up."" The point is to
  operate formally with our expansions.) Then we get $\frac{a}{b} = \frac{24}{17} = \frac{2p + 2p^2}{2 + 2p + p^2} = p + p^3 + 2p^ 5 + p^7 + p^8 + 2p^9 + ...$ I'm having trouble understanding what this formal division involves, and my attempt to perform conventional polynomial division hasn't yielded this series. I had more success when I rewrote the numerator and denominator ( $\frac{2p + 2p^2}{2 + 2p + p^2} = \frac{p^3-p}{2p^2 -1}$ ) and then performed something like conventional polynomial division (dividing the lowest power into the lower power). This is fine, but I can't figure out why this would work, or how I should ""divide formally"" in general. Any help, please?","['number-theory', 'p-adic-number-theory', 'polynomials', 'valuation-theory', 'formal-power-series']"
2933094,Matrix differentiation: $\frac{\partial{w}}{\alpha}$ for $w=(X^\top X + \alpha \textbf{I})^{-1}X^\top y$,"What is $\frac{\partial{w}}{\partial{\alpha}}$ for $w=(X^\top X + \alpha \boldsymbol{I})^{-1} X^\top y$ where X is an $N \times D$ matrix, y is an N dimensional vector, $\boldsymbol{I}$ is an identity matrix of size $D \times D$ and $\alpha$ is a scalar? edit:
Actually I was trying to differentiate $\mathcal{F} (\hat{w}(\alpha)) = (\boldsymbol{y}-X\hat{\boldsymbol{w}})^\top (\boldsymbol{y}-X\hat{\boldsymbol{w}})+ \alpha (||{\hat{\boldsymbol{w}}||}^2 - c^2)$ w.r.t $\alpha$ .
Can I do $\dfrac{\partial{\mathcal{F} (\hat{w}(\alpha))}}{\partial{\alpha}}= \dfrac{\partial{\mathcal{F} (\hat{w}(\alpha))}}{\partial{\hat{w}}}\times  \dfrac{\partial{\hat{w}}}{\partial{\alpha}}$ ? if I do so, then $\dfrac{\partial{\mathcal{F} (\hat{w}(\alpha))}}{\partial{\alpha}}= (-2X^\top y + 2X^\top X \hat{w} )\dfrac{\partial{\hat{w}}}{\partial{\alpha}} + (||{\hat{\boldsymbol{w}}||}^2 - c^2)+ (2\alpha\hat{w}) \dfrac{\partial{\hat{w}}}{\partial{\alpha}} $ But the dimension of $\dfrac{\partial{\hat{w}}}{\partial{\alpha}}$ is $D \times 1$ since its expression is $-(X^\top X +\alpha \boldsymbol{I})^{-1}\boldsymbol{\hat{w}}$ and that of $\boldsymbol{\hat{w}}$ is also $D \times 1$ so they can't be multiplied in the order seen in the third term. Is there a problem with the chain rule?","['matrices', 'matrix-calculus', 'derivatives']"
2933095,A Topology containing every infinite subset of a an infinite set is discrete.,"Is the following proof correct? Proposition. Let $X$ be an infinite set and $\tau$ be a topology on $X$ . If every infinite subset of $X$ is in $\tau$ , prove that $\tau$ is a discrete topology. Proof. Assume $x\in X$ , since $X$ is infinite, surely there must exist an $a_1\in X$ such that $a_1\not\in\{x\}$ , and by the same reasoning a $b_1\in X$ such that $b_1\not\in\{x,a_1\}$ , continuing in this manner, we affirm that there exist $a_1,b_1,a_2,b_2,\dots,a_k,b_k,\dots$ in $X$ such that $$
\begin{cases}
a_1\not\in\{x\}\\
b_1\not\in\{x\}\cup\{a_1\}\\
a_2\not\in\{x\}\cup\{a_1\}\cup\{b_1\}\\
b_2\not\in\{x\}\cup\{a_1,a_2\}\cup\{b_1\}\\
\vdots
\\
a_k\not\in\{x\}\cup\{a_1,a_2\dots,a_{k-1}\}\cup\{b_1,b_2,\dots,b_{k-1}\}\\
b_k\not\in\{x\}\cup\{a_1,a_2\dots,a_{k-1},a_{k}\}\cup\{b_1,b_2,\dots,b_{k-1}\}
\end{cases}
$$ Now define $A = \bigcup_{r=1}^{\infty}\{a_r\}\cup\{x\}$ and $B = \bigcup_{r=1}^{\infty}\{b_r\}\cup\{x\}$ , from hypothesis $A,B\in\tau$ and since $\tau$ is a topology on $X$ , we have $A\cap B\in\tau$ as well, but from the above construction, it is evident that $\bigcup_{r=1}^{\infty}\{a_r\}\cap \bigcup_{r=1}^{\infty}\{b_r\} = \varnothing$ , consequently $A\cap B = \{x\}$ . In summary every $\{x\}\in\tau,\forall x\in X$ , appealing to proposition $1.1.9$ $\blacksquare$ Note: $1.1.9$ is the result that any topology $\tau$ on a set $X$ containing $\{x\}\in\tau,\forall x\in X$ , is a discrete topology.","['general-topology', 'proof-verification']"
2933101,Is the integral of a continuous map always a Radon measure?,"Let $U\subseteq \mathbb{R}^d$ be an open set, and let $g:U\rightarrow [0,\infty)$ be a continuous map. It seems that the Borel measure defined by: $\nu(E):=\int_E g(x)d\lambda_d$ for $E\subseteq U$ , would have to be a Radon meausre, but I'm having trouble verifying outer regularity of this measure. Is it necessarily true that such a Borel measure is indeed Radon? The definition for a Radon measure which I'm using is as follows: Given a topological space $(X,\tau)$ , a Borel measure $\mu:\mathcal{B}_X\rightarrow [0,\infty]$ is called a Radon measure if: (1) $\mu(K)<\infty$ for all compact $K\subseteq X$ . (2) $\mu(U)=\sup \Big\{\mu(K): K\subseteq U, K \; \text{is compact}  \Big\}$ for all $U\subseteq X$ open. (3) $\mu(E)=\inf \Big\{\mu(V): E\subseteq V, V \; \text{is open}  \Big\}$ for  all $E\in \mathcal{B}_X$ .",['measure-theory']
2933152,What is the expected number of boys?,"If the probability that a child is a boy is $p$ ,  find the expected number of boys in a family with $n$ children given that there is at least one boy? My answer: My friend says the answer is $np+q$ but my answer is $np/(1-q^n)$ . I found my answer through conditional probability by finding the $P(X=k/X>0)$ . My friend tells that we can find the answer by finding the expected number of boys for $n-1$ children and then add $1$ to the expectation.  Which one is right?",['probability']
2933188,Matching problem of slightly different chessboard,"I try to prove that it is impossible to cover figure 1 with tiles of size $1\times 2$ and $2 \times 1$ . When I abstract figure 1 as a graph I realize that it is a bipartite graph.  I think this equation might help me. $\sum_{a \in X} \deg(a) = \sum_{a \in Y} \deg(a)$ where $X$ and $Y$ are the bipartition of the graph.( I already proved this formula)
Unfortunately, I don't see how I could argue any further now. modified chessboard","['graph-theory', 'chessboard', 'bipartite-graphs', 'discrete-mathematics']"
2933206,Dirac measure as an image of pushforward map,"Let $X, Y$ be two compact spaces and let $Q: X\times Y \to X$ be the canonical projection map. Denote by $Q_*: M(X\times Y)\to M(X)$ the pushforward map, where $M(\cdot)$ is the space of probability Radon measures. Let $Z$ be a subset of $M(X\times Y)$ and assume that $\delta_x\in Q_*(Z)$ , where $\delta_x$ denotes the point mass measure. Then, I want to show that there exists a measure $\nu\in M(Y)$ s.t. $\delta_x\otimes \nu\in Z$ . I am not sure how to do it since I know that not every measure on a product space is given by a product of measures. Thanks!","['measure-theory', 'probability']"
2933236,"Tricks to find a closed form $x_n$ of recurrence relation $x_{n+1} = \frac{1}{1+x_n}$ where $x_1 = a > 0$, $n \in \mathbb N$","With the help of you guys I've been able to learn how to solve various recurrence equations, but today I came across one I couldn't handle: Find a closed form of the sequence $\{x_n\}$ of recurrence relation (where $n \in \mathbb N$ ): $$
\begin{cases} x_1 = a > 0\\x_{n+1} = \dfrac{1}{1+x_n}\end{cases}
$$ I've already made several attempts which include: Trying to infer the pattern by expanding the continuous fraction from bottom up. No result Expressing $x_{n+2}$ and multiply/add/subtract/divide expressions for $x_{n+1}$ and $x_{n+2}$ . No result Suppose that $x_{n}$ has a rational form $k_n \over p_n$ and playing with the equations in different ways. No result I believe there should be some clever trick to untangle this, but apparently i'm too dumb to see it. The answer is known to be a fraction involving the Golden Ratio $\frac{\sqrt5 - 1}{2}$ so maybe this may help. Update Using @AnotherJohnDoe's hint we may perform the following transformation: Let $x_n = \frac{t_n}{t_{n+1}}$ , then: $$
\frac{t_{n+1}}{t_{n+2}} = \frac{1}{1+\frac{t_n}{t_{n+1}}} = \frac{t_{n+1}}{t_n + t_{n+1}}
$$ Which defines a recurrence relation in terms of $t$ : $$
t_{n+2} - t_{n+1} - t_n = 0
$$ The characteristic equation for this recurrence has two root so the closed form of $\{t_n\}$ is: $$
t_n = C_1\cdot\left({1+\sqrt5\over 2}\right)^n + C_2 \cdot \left({1-\sqrt5 \over 2}\right)^n
$$ Let $\phi_1 = \frac{1+\sqrt5}{2}$ and $\phi_2 = \frac{1-\sqrt5}{2}$ : $$
t_n = C_1\cdot \phi_1^n + C_2\cdot\phi_2^n \\
t_{n+1} = C_1\cdot \phi_1^{n+1} + C_2\cdot\phi_2^{n+1}
$$ Then: $$
x_n = \frac{t_n}{t_{n+1}} \\
x_n = \frac{C_1\cdot \phi_1^n + C_2\cdot\phi_2^n}{C_1\cdot \phi_1^{n+1} + C_2\cdot\phi_2^{n+1}}
$$ So using the initial conditions $x_1 = a$ and $x_2 = {1\over 1+a}$ : $$
\begin{align}
a &= \frac{C_1\cdot \phi_1 + C_2\cdot\phi_2}{C_1\cdot \phi_1^2 + C_2\cdot\phi_2^2} \\
{1\over 1+a} &= \frac{C_1\cdot \phi_1^2 + C_2\cdot\phi_2^2}{C_1\cdot \phi_1^3 + C_2\cdot\phi_2^3}
\end{align}
$$ But this system doesn't seem to have solutions.","['algebra-precalculus', 'recurrence-relations']"
2933238,Basic Mathematics. Problem with polynomial function proof,"Let $f$ be a polynomial of degree $\leqslant n$ and let $c$ be a root. Then there exists a polynomial $g$ of degree $\leqslant n-1$ such that for numbers $x$ we have $$
f(x)=(x-c)g(x)$$ Proof: Write $$ f(x)=a_{0}+a_{1}x+a_{2}x^{2}+ ... + a_{n}x^{n} $$ Then substitute the value $$ x = (x-c) + c$$ for each x. Here is the point where I get stuck, as after substituting $x$ , the author derives $$ f(x)=b_{0}+b_{1}(x-c)+b_{2}(x-c)^{2}+ ... + b_{n}(x-c)^{n} $$ I cannot understand how he gets the above function as it looks like that he keeps only the term $(x-c)^n$ of every expansion $ ((x-c) + c)^n$ . Any hints?","['algebra-precalculus', 'polynomials']"
2933239,"If $ f > 0 $, $g\ge0$, and $ \int_a^b g > 0 $, then $ \int_a^b fg > 0 $?","Let $ f:[a,b] \rightarrow \mathbb{R} $ be continuous on $ [a,b] $ and $ f > 0 $ on $ (a,b) $ , and let $ g:[a,b] \rightarrow \mathbb{R} $ be non-negative and integrable on $ [a,b] $ . 
If $ f > 0 $ , and $$ \int_a^b g > 0 \,, $$ then is it true that $$ \int_a^b fg > 0 \,? $$ The integrals are Riemann integrals.","['integration', 'analysis', 'real-analysis']"
2933370,Do we need 'such that' after qualifiers?,"Alright this is driving me crazy. I'm trying to figure out when we actually need to use 'such that' in math/logical expressions. There seems to be quite a bit of inconsistency but I wanted to check to be sure. I've seen 3 ways of doing it... My discrete mathematics professor IIRC always used a 'such that' after an existential qualifier but not after a universal qualifier... so he'd use ∃x ∈ N: x > 1, but then also ∀x ∈ N, x > 0 (I think he'd use a comma here) These guys and a couple others I've seen online use no punctuation unless indicating parentheses: What does a period in between quantifiers mean? But others still use 'such that' (:) before all qualifiers: Does order of qualifiers matter in FOL formula? I believe my math professor did what he did because it translated cleanly to English. Since you'd say ""There exists an x such that x > 3"" but you could also say ""For all x, x=x"". But I'm trying to figure out what the 'such that' symbol actually means in math, because I don't think the way it works in English necessarily makes sense. Wolfram Alpha defines the 'such that' symbol as 'indicating a condition in the definition of a mathematical object', and this make sense but they introduce yet another convention of qualifiers after a such that since q∈Z ≡ ∀q∈Z. And of course this convention makes no sense when translated to English in the case when for example when we'd say ""x > 3: ∃x ∈ N"" which translates to ""x is greater than three such that there exists an x in naturals"". So anyways my question is what are you actually supposed to do? It looks like there are multiple conventions so which is best and most commonly used? 10/9/18 EDIT: The Root of the Problem: I've realized that the source of all this inconsistency has to do with the way that we read an existential qualifier. We read it as ""there exists a blank [in something] [such that...]"", and still call it a qualifier while technically this 'qualifier' is actually an (English) statement . We could similarly distort a universal qualifier to be a statement that is post-qualified with a ""such that"", if we read it as ""All blank [in something] have a property [such that...]"". If we truly want to call an existential qualifier a qualifier we need to read it as ""For at least one blank [in something], [something is true]"" . When we do this the need for 'such that' disappears.","['logic', 'discrete-mathematics']"
2933377,Closed form of $\int_0^\infty \left(\frac{\arctan x}{x}\right)^ndx$,"I know that for $n=1$ the integral is divergent and that for $n=2$ the integral has a closed form. However, I wonder if the general expression has a closed form. My attempt : \begin{align}
\int_{0}^{\infty}\left[\frac{\arctan\left(x\right)}{x}\right]^{n}\,{\rm d}x & =
\frac{n}{1 - n}\int_{0}^{\infty}
\frac{\arctan^{n - 1}\left(x\right)}
{x^{n - 1}\left(x^{2} + 1\right)}{\rm d}x
\\[3mm] & =
\frac{n}{1 - n}\int_{0}^{\left(\pi/2\right)^{n - 1}}
u^{n - 1}\cot^{n-1}\left(u^{1/\left[n - 1\right]}\right){\rm d}u
\end{align} I don't know if I'm on the right track here or not but I do not know through what methods to evaluate the last integral. Any help is appreciated.","['integration', 'improper-integrals', 'definite-integrals']"
2933382,"Is the closed immersion of a smooth subscheme of a smooth scheme, a smooth morphism?","Let $X$ be a smooth scheme over a (perfect if you want) field $k$ . Let $Y$ be a closed subscheme of $X$ that is also smooth over $k$ . 
Is the canonical closed immersion $i:Y \to X$ a smooth morphism?",['algebraic-geometry']
2933433,Find the marginal distribution given the mean and the covariance matrix,"If we have a vector of normally distributed random variables $x^T = (x_1,x_2)$ with mean $\mathbf{\mu}^T = (10, 14)$ and a covariance matrix $$S_1 =\begin{bmatrix}13 & 12\\12 & 13\end{bmatrix}.$$ I would first like to calculate the marginal distribution My Thoughts The random variables are normally distributed, so the distributions are simply: $x_1 \sim N(10,13)$ and $x_2 \sim N(14, 13)$ ? Is this correct? It seems to simple, don't I need to use the covariance? Suppose now that we assume that $x_1$ and $x_2$ are returns to financial assets, we need to calculate the distribution of the portfolio that gives equal weight to both assets My thoughts I'm not quite sure what to do here? Any thoughts? Do they mean that for every $x_2$ we need $\frac{14}{10}$ assets of $x_2$ to get the same amount of money? Any help is must appreciated.","['statistics', 'marginal-distribution', 'normal-distribution']"
2933451,Determinant of matrix formed from blocks of a $2 \times 2$ block partitioned symplectic matrix.,"While working on a problem in quantum optics, I came across the following determinant of a complex matrix of size $n \times n$ : $$\mathbb{G}=\det\left[\mathcal{U}_{11}^{}+\mathcal{U}_{12}^{}\mathcal{D}_{S}^{}\right]$$ where $\mathcal{U}_{xy}^{}$ are blocks of a $2 \times 2$ block partitioned complex Symplectic matrix defined as, $$\begin{pmatrix}\mathcal{U}_{11}^{} & \mathcal{U}_{12}^{} \\ \mathcal{U}_{21}^{} & \mathcal{U}_{22}^{}\end{pmatrix}:=\mathcal{U}_{2n \times 2n}^{}=e_{}^{-\mathcal{H}^{}\Sigma_{}^{}}$$ with $\mathcal{H}^{}\Sigma_{}^{}$ being a complex Hamiltonian matrix expressed as a product of complex $2 \times 2$ block partitioned symmetric matrix $$\mathcal{H}^{}=\begin{pmatrix}\mathcal{A}_{n \times n}^{}=\mathcal{A}_{n \times n}^{T} & \mathcal{B}_{n \times n}^{} \\ \mathcal{B}_{n \times n}^{T} & \mathcal{D}_{n \times n}^{}=\mathcal{D}_{n \times n}^{T}\end{pmatrix}$$ and the standard symplectic matrix $$\Sigma_{}^{}=\begin{pmatrix}\mathbb{O}_{n \times n}^{} & \mathbb{I}_{n \times n}^{} \\ -\mathbb{I}_{n \times n}^{} & \mathbb{O}_{n \times n}^{}\end{pmatrix}.$$ Further $\mathcal{D}_{S}^{}$ is a $n \times n$ complex symmetric matrix and . $\mathbb{O}_{n \times n}^{}$ , $\mathbb{I}_{n \times n}^{}$ are respectively null and identity matrices of dimension $n \times n$ . $\mathbf{Question :}$ Is it possible to express $\mathbb{G}$ in terms of expression involving traces or determinants of sums of products of $\mathcal{A}_{n \times n}^{}$ , $\mathcal{B}_{n \times n}^{}$ , $\mathcal{D}_{n \times n}^{}$ , $\mathcal{D}_{S}^{}$ matrices and eigenvalues of the symplectic matrix $\mathcal{H}^{}\Sigma_{}^{}$ without explicit computation of $\mathcal{U}_{2n \times 2n}^{}$ , in an elegant general form? (I could do this for $n=2$ case using combination of Cayley–Hamilton theorem and Faddeev-Leverrier algorithm . For general case of $n$ , I am not able to achieve this task. Without any rigorous reasoning, I suspect some elegant expression for $\mathbb{G}$ can be given. Is this feasible?)","['matrices', 'symplectic-linear-algebra', 'linear-algebra', 'symmetric-matrices']"
2933452,Finding coefficients in polynomials,"Find $p$ and $q$ , if $x^3-2x^2+p+q$ is divided by $x^2+x-2$ .
I have found $x =-2$ and $x=1$ however when placed into polynomial I am unable to find a value for $p$ and $q$ .","['algebra-precalculus', 'polynomials']"
2933511,Evaluation of $\frac{1}{2\pi i }\int_{c-i\infty}^{c+i\infty}\frac{\log(s)^{n}\log(1-s)^{m}}{s(1-s)}ds$,"I am having trouble trying to evaluate the integral : $$\frac{1}{2\pi i }\int_{c-i\infty}^{c+i\infty}\frac{\log(s)^{n}\log(1-s)^{m}}{s(1-s)}ds$$ Where $0<c<1$ and $n,m$ are positive integers. The integrand has two branch cuts : $(-\infty,0]$ and $[1,\infty)$ , so shifting the line of integration doesn't work. I tried bending the line of integration so it lies just above and just below one of the branch cuts, but that didn't work either, or i have made a mistake. any insight is appreciated. EDIT : After a couple of transformations, i obtained : $$\frac{1}{2\pi i }\int_{c-i\infty}^{c+i\infty}\frac{\log(s)^{n}\log(1-s)^{m}}{s(1-s)}ds=$$ $$\frac{1}{2\pi i }\int_{-\infty}^{\infty}\frac{\log(is)^{n}\log(1-is)^{m}}{s(1-is)}ds=-\Re\left[\frac{1}{\pi i }\int_{0}^{\infty}\frac{y ^{n}\log(1-e^{y})^{m}}{1-e^{y}}dy \right ]$$ Still, i have no idea on how to evaluate the integral !!","['complex-analysis', 'contour-integration']"
2933553,Elementary number theory in sets,"I'm back again
So there's another problem that I can't get to prove If we take 21 numbers randomly from $1, 2, 3, ..., 40$ then between those $21$ numbers we will be able to find two numbers, of which the smaller one will divide the bigger one I've been reading james hein ""discrete structures, logic and computability"" but still can't get to think logically myself.
I would be very grateful if I could get some directions/tips/hints or anything, thanks in advance","['divisibility', 'elementary-number-theory', 'pigeonhole-principle', 'combinatorics', 'discrete-mathematics']"
2933593,Continuity implies $\mu$-strongly measurability?,"In view of the definitions below (That can be found in Infinite Dimensional Analysis: A Hitchhiker's Guide, of ALIPRANTIS and BORDER): Definition 1. Suppose $\Omega$ is a set equipped with an álgebra $\mathcal{A}$ . Also, let $X$ be a vector space. As in the real case, a function $\varphi: \Omega \longrightarrow X $ thah assumes only a finite number of values, say $x_1,x_2,\cdots, x_n$ is called X-simple function if $A_i=\varphi^{-1}(\{x_i\}) \in \mathcal{A}$ , for each $i=1,\cdots,n.$ Definition 2. Let $(\Omega, \Sigma, \mu)$ be a measure space, and let $ f:\Omega \longrightarrow X$ be a vector function. We say that $f$ is strongly $\mathbf{\mu}$ - measureble if there exists a sequence $\{\varphi_n\}_{n\in\mathbb{N}}$ of X-simple functions such thath $\displaystyle \lim_{n \rightarrow \infty} ||f(\omega)-\varphi_n(\omega)||=0$ for almost all $\omega \in \Omega$ . If $f $ is continuous then $f $ is $\mu$ -strongly measurability? I could not prove (or give a example) because I could not even relate all these concepts. Is that true?","['continuity', 'measure-theory', 'simple-functions', 'vector-spaces']"
2933632,How to show that Group of order $2376$ is not simple,"How to show that Group of order $2376$ is not simple, Now I know that $2376=2^3.3^3.11$ So, $n_{11}=1,12$ (Are there any other possibilities? According to my calculation; these are the all) Now if I have $12$ Sylow-11 subgroups then counting the elements would not help me. Even if I consider $2$ Sylow-11 subgroups say $H,K$ then their intersection will contain $1$ element only. So their normalizer is the whole group so this way will also not work. Now I was thinking that here $N_G(H)/C_G(H) \cong Aut(H) \cong \Bbb Z_{10} $ could that help as if I can show that $N_G(H)=G$ then I am done. Here $N_G(H)$ is the normalizer of the group $H$ in $G$ , $C_G(H)$ is the centralizer of the group $H$ in $G$ . I would like to know if there would be any other way as well.","['group-theory', 'simple-groups', 'finite-groups']"
