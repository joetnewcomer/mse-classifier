question_id,title,body,tags
1780822,Equality of power towers : $a\uparrow\uparrow m=b\uparrow \uparrow n$,"Suppose, $a,m,b,n$ are natural numbers greater than $1$ . If we have $$a\uparrow\uparrow m=b\uparrow\uparrow n$$ can we conclude $a=b$ and $m=n$ ? $a\uparrow \uparrow m$ is a powertower of $m$ $a's$ and $b\uparrow\uparrow n$ a power tower of $n$ $b's$ . I proved $b^b\ne a^{a^a}$ for natural numbers $a,b>1$ . This is my proof : Set $s:=\frac{ln(b)}{ln(a)}$ . So, we have $a^s=b$ . Therefore, we have $$a^{a^a}=(a^s)^{(a^s)}=a^{sa^s}$$ , so $a^a=sa^s=sb$ , we can conclude that $s$ is rational. If $s\ge a$ , then $sa^s\ge aa^a>a^a$ . If $s\le a-1$ , then $sa^s=(a-1)a^{a-1}<aa^{a-1}=a^a$ Hence, we can conclude $a-1<s<a$ implying that $s$ is not an integer. Finally, assume $s=\frac{m}{n}$ with coprime $m$ and $n$ . Then, we have $$(\frac{m}{n})^na^{s\ n}=a^{an}$$ , implying $$(\frac{m}{n})^n=a^{an-m}$$ Because of $a>s$ we have $an-m>sn-m=0$ . Therefore, the left side of the last equation is not an integer, while the right side is an integer. This contradiction finally proves the claim. Questions: Is this proof correct ? Is there an easier proof that $a^{a^a}=b^b$ cannot hold for natural numbers $a,b>1$ ? (For example, using the $p$ -adic value of $a^{a^a}$ and $b^b$ ) ? Is there a proof that we can extend to show the more general initial claim ?","['number-theory', 'tetration', 'proof-verification']"
1780861,Integral involving inverse of a function,"If $f(x)=x^3-x^2+x$, evaluate $$\lim_{n \to \infty} \int _{n}^{2n}\frac{dx}{(f^{-1}(x))^3+f^{-1}(x)}$$ I substituted $x=f(t)$  but was unable to convert it back to $x$ and I think there would be a better approach. Some hints please. Thanks.","['integration', 'calculus', 'limits']"
1780864,"Why do these ""equal"" logarithms give different answers",This came across a discussion amongst Algebra 2 teachers at my school. We know $a\log x= \log x^a$ Say $2\log x=5$ $\log x^2 =5$ When $\log x=\log_{10} x$ Solving the first equation yields $x=10^{5/2}$ while the second equation yields $x=\pm\sqrt{10^5}$. Which solution is correct or does it depend on the equation?,"['algebra-precalculus', 'logarithms']"
1780875,To prove that an ideal cannot be generated by two elements [duplicate],"This question already has answers here : Height and minimal number of generators of an ideal (4 answers) Closed 8 years ago . Let $k$ be an algebraically closed field and let $\ Y\subset \mathbb{A}^n(k)$ be the curve given parametrically by $x=t^3, y=t^4,z=t^5$ I want to show (i) $I(Y)$ is a prime ideal of height 2 (ii) $I(Y)$ cannot be generated by 2 elements Since $I(Y)$ is kernel of the homomorphism sending $x\mapsto t^3,y\mapsto t^4,z\mapsto t^5$ into the integral domain $k[t]$, $I(Y)$ must be prime. And since we can consider $k\subset k[x,y,z]/I(Y)\subset k[t]$, by considering transcendence degree we have $\dim(k[x,y]/I(Y))=1$ and hence the height of $I(Y)$ equals 2. Now I want to prove the second statement. I guess $I(Y)=\left<x^4-y^3,x^5-z^3,y^5-z^4\right>$, but I don't know how to prove it (although one inclusion is obvious), and I don't know how to use this ""result"" to prove (ii). Any help or hints are appreciated, thank you!","['algebraic-geometry', 'commutative-algebra']"
1780904,Schauder bases of subspaces of the sequence space $\ell^p(\mathbb{N})$,"Consider the canonical Schauder basis $\{e_i:i\in \mathbb{N}\}$ for $\ell^p(\mathbb{N})$, where $e_i(j)=\delta_{ij}$. Let $M$ be a subspace of $\ell^p(\mathbb{N})$. Is it right that $\{e_i:i\in \mathbb{N}\}\cap M$ is a basis for $M$? For example, if we take the subspaces $$M_1=\{(\cdots,0, 0, x_1,x_2,x_3,0,0,\cdots)\}$$ or $$M_2=\{\{x_i\}:x_i=0 \text{ if } i \text{ is even }  \}$$
Then the answer is clearly yes. However, what about the general cases? If the answer is no, is there any condition to be added such that the question has a positive answer?","['functional-analysis', 'schauder-basis', 'lp-spaces', 'banach-spaces']"
1780909,Is there a bijective function $f: \mathbb{R}\to\mathbb{R}$ that is discontinuous?,Is there a bijective function that is discontinuous?,['functions']
1780956,Mean and Variance Geometric Brownian Motion with not constant drift and volatility,"I have to derive the Geometric Brownian motion (with not constant drift and volatility), and to find the mean and variance of the solution. $\quad \left\{\begin{aligned}
& d X_t = \mu(t) X_t d t + \sigma(t) X_t d W_t \\
& X_0 = \xi
\end{aligned}\right.$ The solution can be obtained in a classical manner by Ito's Lemma: $X_t = \xi e^{\int_0^t \left(\mu(s) - \frac{\sigma^2(s)}{2}\right) d s + \int_0^t \sigma(s) d W_s}$ And we can find the mean and variance: $\mathbb{E}[X_t] = \xi e^{\int_0^t \left(\mu(s) - \frac{\sigma^2(s)}{2}\right) ds} \mathbb{E}\left[e^{\int_0^t \sigma(s) dW_s}\right]$ $Var(X_t) = \xi^2 e^{\int_0^t \left(2\mu(s) - \sigma^2(s)\right) d s} \left(\mathbb{E}\left[e^{2 \int_0^t \sigma(s) d W_s}\right] - \mathbb{E}\left[e^{\int_0^t \sigma(s) d W_s}\right]^2\right)\\$ These expression are not really simple, as they are when $\mu$ and $\sigma$ are constant. Does someone know if we have a general expression for the expectation of the exponential of an Itô's Integral? (in this case of a deterministic function). I.e: $\mathbb{E}\left[e^{\int_0^t \sigma(s) dW_s}\right]$ Thanks.","['expectation', 'probability', 'brownian-motion', 'stochastic-integrals']"
1780973,What is the 'meaning' of nowhere dense set?,"In some books, nowhere dense set is defined to be $int(\bar A)=\emptyset$ but meanwhile is defined to be $int(A)=\emptyset$ in some books(e.g. Munkres). So what is the 'meaning' (i.e motivation, intuitive/geometric meaning etc.) of nowhere dense set? Thank you.","['general-topology', 'baire-category', 'soft-question', 'motivation']"
1780975,Applying equivalence of norms on $\mathbb R^n$ .,"Let $\|\cdot\|$ be any norm on $\mathbb R^n$. Prove that a sequance on $\mathbb R^n$ converges  to an element $x \in \mathbb R^n$ under the $\|\cdot\|_2$ norm if and only if the sequance converges to $x$ under the $\|\cdot\|$ norm. I want to say that $c\|\cdot\| \leq \|\cdot\|_2 \leq d\|\cdot\|$ given $c,d \in \mathbb R$ since $\mathbb R^n$ is a closed space and than to show c=d. is that a correct way? how can i show d=c?","['functional-analysis', 'normed-spaces', 'notation']"
1781010,Proof of indexed family set,"I am stuck at the following exercise in Velleman's How To Prove it: Suppose $\{A_i\mid i \in I\}$ is a family of sets. Prove that if $\mathscr P\left(\bigcup_{i\in I}A_i\right) \subseteq \bigcup_{i\in I}\mathscr P(A_i) $, then there is some $i\in I$ such that $\forall j\in I(A_j\subseteq A_i) $. ($\mathscr P$ means powerset.) I tried expanding this into its logical form and proceed, but its logical form has too many variables and too complicated of a structure that I couldn't get my head around it, so I turned to the solution: i) Suppose $\mathscr P\left(\bigcup_{i\in I}A_i\right) \subseteq \bigcup_{i\in I}\mathscr P(A_i) $. ii). Clearly $\bigcup_{i\in I}A_i \subseteq \bigcup_{i\in I}A_i$, so $\bigcup_{i\in I}A_i \in \mathscr P\left(\bigcup_{i\in I}A_i\right)$, and therefore $\bigcup_{i\in I}A_i \in \bigcup_{i\in I}\mathscr P(A_i)$. I don't see how $\bigcup_{i\in I}A_i \in \mathscr P\left(\bigcup_{i\in I}A_i\right)$ leads to $\bigcup_{i\in I}A_i \in \bigcup_{i\in I}\mathscr P(A_i)$; in fact despite knowing its logical form $\exists i\in I\, \forall y(y\in x \to y\in A_i) $, I don't even know how to explain $\bigcup_{i\in I}\mathscr P(A_i)$ in ordinary language! But even if I am to ignore this, there are further trouble ahead: iii. By the definition of union of a family, this means that there is some $i \in I$ such that $\bigcup_{i\in I}A_i \subseteq A_i$. Does this mean $\exists i\in I \left(\bigcup_{i\in I}A_i \subseteq A_i\right)$? But where is this coming from?! It seems that the subset comes from the definition of powerset, but I don't see how $\bigcup_{i\in I}\mathscr P(A_i)$ will yield this. iv. Now let $j\in I$ be arbitrary. Then it is not hard to see that $A_j \subseteq \bigcup_{i\in I}A_i$, so $A_j \subseteq A_i$. For me it is vacuously true that 'it's not hard', because I can't even understand what he was doing in the prior steps. I am a self-teaching student so I am really grateful for any help on this, thank you so much!","['elementary-set-theory', 'proof-explanation']"
1781068,irreducible components of subscheme,"Let $f : X \to Y$ be a closed immersion of (noetherian) schemes. Is there any ""general"" result on $f$ out there ensuring that $X$ has the same number of irreducible components as $Y$ ?","['reference-request', 'algebraic-geometry']"
1781090,converse to the jordan curve theorem,"Suppose $K\subset \mathbb{R}^2$ is compact and locally connected, and does not contain 0. Let $A$ be the component of $\mathbb{R}^2-K$ containing 0, and let $B$ be the unbounded component. Assume that $A\neq B$. If $\partial A = \partial B$, does it follow that $K$ is a Jordan curve? As a first step, it even true that $\partial A= \partial B=K$?","['complex-analysis', 'general-topology', 'plane-curves']"
1781107,"Show that $\forall n\in\mathbb{N}$, $14^n$ can be represented as a sum of three perfect squares.","Show that $\forall n\in\mathbb{N}$, $14^n$ can be represented as a sum of three perfect squares. I checked $(\mod 7)$ and deduced that the three squares can be $1,4,2(\mod 7) $ or all divisible by $7$ and for $n \ge 2$ they must be all divisible by $4$. But I am stuck here.","['number-theory', 'sums-of-squares']"
1781117,Prove that $\prod_{n=2}^∞ \left( 1 - \frac{1}{n^4} \right) = \frac{e^π - e^{-π}}{8π}$,"The question Prove that:
$$\prod_{n=2}^∞ \left( 1 - \frac{1}{n^4} \right) = \frac{e^π - e^{-π}}{8π}$$ What I've tried Knowing that:
$$\sin(πz) = πz \prod_{n=1}^∞ \left( 1 - \frac{z^2}{n^2} \right)$$
evaluating at $z=i$ gives
$$ \frac{e^π - e^{-π}}{2i} = \sin(πi) = πi \prod_{n=1}^∞ \left( 1 + \frac{1}{n^2} \right)$$
so:
$$ \prod_{n=1}^∞ \left( 1 + \frac{1}{n^2} \right) = \frac{e^π - e^{-π}}{2π}$$ I'm stucked up and don't know how to continue, any help?","['complex-analysis', 'infinite-product']"
1781180,Is the product of closed subgroups in topological group closed?,"Just out of curiosity: If $G$ is a topological group and $H, K$ are closed subgroups, is $H\cdot K$ a closed subgroup? Thanks!","['abstract-algebra', 'general-topology', 'topological-groups', 'group-theory']"
1781193,Understanding the $\sigma$-algebra of a sum of random variables,"I've been studying discrete martingale theory and I have been wondering about the relationship between $\sigma\{X+Y\}$, and $\sigma\{X\}$ and $\sigma\{Y\}$ for two random variables X and Y. Is it equal to $\sigma\{X,Y\}$? Is it generated by the union $\sigma\{X\}\cup\sigma\{Y\}$? I find working with $\sigma$-algebras quite taxing and it would be great if someone could shed some light on this.","['martingales', 'measure-theory']"
1781208,Why is $\frac{1}{2\pi i}\int_{\gamma}\frac{f'(z)}{f(z)}dz$ an integer?,"Let $f$ be holomorphic in an open $\Omega \subset \mathbb{C}$ and $\gamma$ a closed curve in $\text{int}(\Omega)$ , along which $f$ is never zero. Are these hypotheses enough to claim $\frac{1}{2\pi i}\int_{\gamma}\frac{f'(z)}{f(z)}dz$ is an integer? If not, what are the necessary and sufficient conditions for that? I can prove that's an integer for some particular cases, for example when $\Omega$ is convex and $\gamma$ is a circle. But I've seen people claming this in many other contexts, like when $\Omega$ is an annulus around $0$ and $\gamma $ is an arbitrary curve inside it. This isn't obvious to me at all. Thanks!","['complex-analysis', 'complex-integration']"
1781216,How does the sum of the absolute values of the diagonal entries of a matrix change when the matrix is written in a random basis?,"The set-up is as follows: I have a complex, Hermitian matrix $H$ with $\mbox{Tr }H=0$, and such that the trace norm $\|H\|_1=1$ (i.e. the sum of the singular values $=1$). Let me define the functiona $\mbox{TrAbs}$ to ojcemp am the sum of the absolute values of the diagonal entries of a matrix (which is clearly dependent on the basis), i.e. $$ \mbox{TrAbs }H = \sum_{i=1}^n |(H)_{ii}| $$ where $n$ is the dimension of the matrix. My question is to understand the following: Given $\epsilon$, if I write $H$ in a randomly chosen orthonormal basis and call it $H^\prime$, what is the probability that $\mbox{TrAbs }H^\prime>\epsilon$? To clarify a couple of things: I'm looking for a lower bound on the probability---the exact value is not particularly relevant. ""randomly"" choosing a basis is quite vague. Perhaps this could be done by conjugating with a Haar random unitary, but if there are other ways of choosing a basis randomly that yield a more straightforward bound, I'm sure those would be fine too. What I know already: $\mbox{TrAbs }H^\prime \geq |\mbox{Tr }H|=0$. If $H^\prime$ is in its diagonal basis, then clearly $\mbox{TrAbs }H^\prime=\|H\|_1=1$. It is then easy to show that $0 \leq \mbox{TrAbs }H^\prime \leq 1$. I intuitively feel that the probability ought to approach $1$ as the dimension of $H$ tends to $\infty$ (because it seems like there would be so many more bases that give a $\mbox{TrAbs}$ value of $\frac{1}{2}$, say, than would give $0$), but can't show it. So I feel like there should be a way of giving a lower bound that only involves $\epsilon$, and not $n$. If I can provide any other information about this question, please let me know. I really appreciate any help you can provide.","['random-matrices', 'matrices', 'measure-theory', 'representation-theory', 'linear-algebra']"
1781258,Is $3$ prime in the ring of integers of the field $\mathbb{Q}(\sqrt{2\sqrt{2}-1})$?,"I am trying to determine if the number $3$ stays prime in the ring of integers of the quartic field $K=\mathbb{Q}(\sqrt{2\sqrt{2}-1})$, or rather adjoin a real root of $X^4+2X^2-7$. I do know that $3$ stays prime in the ring of integers for the quadratic subfield $\mathbb{Q}(\sqrt{2})$ and that $3$ is not ramified in $O_K$. I am a topologist working on my thesis, and any algebraic ideas on how to think about this question are welcome.","['abstract-algebra', 'algebraic-number-theory']"
1781269,How to find the slope of curves at origin if the derivative becomes indeterminate,"What's the general method to find the slope of a curve at the origin if the derivative at the origin becomes indeterminate. For Eg-- What is the slope of the curve $x^3 + y^3= 3axy$ at origin and how to find it because after following the process of implicit differentiation and plugging in $x=0$ and $y=0$ in the derivative we get $0/0$ . Actually this question has been asked by me before and a sort of satisfactory answer that I got was "" For small $x$ and $y$ , the values of $x^3$ and $y^3$ will be much smaller than $3axy$ , so the zeroes of the function will be approximately where the zeroes of $0=3axy$ are -- that is, near the origin the curve will look like the solutions to that, which is just the two coordinate axes. So the curve will cross itself at the origin, passing through the origin once horizontally and once vertically.
(This is also why implicit differentiation can't work at the origin -- the solution set simply doesn't look like a straight line there under any magnification)."" Edit If I approximate the function by saying that at (0,0) , the behavior is dominated be 3axy term as x^3 and y^3 are very small and then 3axy=0 and then tangents are x=0 and y=0 . Is doing so (saying x=0 and y=0) linear Approximation only. Because I am approximating the curve with a straight line at origin . But linear Approximation is  1st derivative (1st term of Taylor series) . This cannot be right because Taylor series can't be formed where derivative doesn't exist*. And if this is right then the function is approximately given by 3axy=0 at (0,0). But how does this give the tangent at (0,0).How shall I go about ? Edit: Is the answer give  right because the solpe does exist.","['derivatives', 'slope', 'tangent-line', 'implicit-differentiation']"
1781286,On the definition of principal Cartier divisors,"In Liu's Algebraic Geometry and Arithmetic Curves, Definition 7.1.17, a few lines after the definition of principal Cartier divisor (as one in the image of $\Gamma (X,K_X^*) \to \Gamma (X,K_X^*/ \mathcal{O} _X^*)$), we read (for an arbitrary scheme $X$): [A Cartier divisor] is principal if it can be represented by a system {$(X,f)$}. I understand that this is only an ""if"" and not an ""if and only if"" in general. Am I right?
(if $X$ is integral or affine noetherian we have an ""only if"").","['schemes', 'algebraic-geometry']"
1781353,Must the number of people...,"Must the number of people at the party who do not know an odd number of people be even? Describe a graph model and then answers the question. I'm confused because I do not understand the question. For example if we take people to be a vertex, then if there is an edge between them it means that people know each other, 
and the formula is $$\sum d(v) = 2*e$$ $\Rightarrow$ the sum of degrees of all vertices should be even so it means that there should be an even number of vertices. But why in the question is ""people who do not know an odd number of other people be even""..?","['combinatorics', 'graph-theory', 'combinatorial-proofs']"
1781363,Reference Quest: Measure Theoretic and Functional Analytic Intro to Stochastic Processes,"Does anyone have any recommendations for a good book which introduces and cleanly and rigorously explains the measure theory and functional analysis implicit in and relevant to stochastic processes, and then from that knowledge base proceeds to introduce stochastic processes? I elaborate unnecessarily much below if you don't understand why I would ask for that. Background: I have tried several times to understand stochastic processes (e.g. Brownian motion, semi-groups of Markov processes, continuous time martingales, SDEs, Levy processes). Seemingly it should be nothing more complicated than applying measure theory to infinite dimensional function spaces, yet no text seems to take this approach. I thought I was a very good intuitive thinker, but the approach of most texts, which seem to approach the field through a combination of seemingly unmotivated inequalities and hand-wavy appeals to ""probabilistic intuition"" instead of trying to explain the conceptual nuances required to understand probability measures/distributions on uncountable spaces, has not worked well for me. For instance, much of the study of Brownian motion or of stochastic integration seems to rely on calculations using Wiener measure, yet I still have not found a good explanation or definition of Wiener measure (somehow in my class I'm supposed to write proofs using Ito's Formula despite the fact that we never received a precise definition of Wiener measure). Or when studying semi-groups as related to Markov processes, the resolvent is clearly the ""Laplace transform of an operator"", but this is rarely if ever pointed out nor ever explicitly/rigorously defined so that I can feel confident performing calculations with the object. Every textbook I have read so far has had this problem, but the worst offender by far is Feller. I don't feel like I really ""got"" probability theory at all until I started to understand it rigorously in terms of measure theory (e.g. Borel-Cantelli, Dynkin's Pi-Lambda theorem, the motivation behind using algebras and then sigma-algebras, random variables as measurable functions, etc.). But for some reason, despite the fact that the measure theory is much more complicated (as is the analysis) for stochastic processes as compared to probability theory, no one seems to treat it with care, unlike with measure theory for probability. All of the textbook authors seem so excited about the topics that they learned twenty years ago that they just jump into discussions of them without providing the reader the machinery necessary to really understand. I don't generally understand what it means for a stochastic process to be measurable, since I usually can't figure out what the relevant sigma algebra or measure is supposed to be. I don't understand the difference between a version or a modification of a stochastic process, or why the finite dimensional distributions don't ""determine a process"" (since clearly here a more specific definition/idea of stochastic process is implied than the ""uncountable set of random variables""). I don't understand how to rigorously define Wiener measure or how to use it for any calculations, especially with regards to optional stopping or stochastic integrals. I don't understand the idea of a random measure or a probability kernel or a conditional distribution or a regular conditional distribution, or how a regular conditional distribution corresponds to a compact operator (or to a completely continuous operator). I don't understand how to apply any of my knowledge of functional analysis to the study of stochastic processes, despite the fact that it is obviously very relevant. I don't understand how to think of Markov processes in terms of operator theory or how to justify that the semigroup and the generator commute, or that the resolvent commutes with the generator, or how or why any operator commutes with another. The field seems very interesting, and I don't want to give up on it, but right now I feel that I am at an impasse, and hence would greatly appreciate any and all suggestions or ideas for help.","['reference-request', 'functional-analysis', 'measure-theory', 'soft-question', 'stochastic-analysis']"
1781413,Finding a representative cocycle for a given group extension,"Suppose we have a group extension
$$0 \to N \stackrel{\iota}{\to} E \stackrel{\pi}{\to} G \to 1$$
where $N$ is abelian. How to find a representative 2-cocycle that produces this extension? Or more generally, given $H^2(G,N)$ with $N$ abelian, how can we find a representative cocycle for each element of the cohomology group (=a group extension that is associated with this element)?","['group-cohomology', 'group-theory']"
1781433,Relationship Between Basis for Topology and Generating Set?,"So there is the notion of the basis for a topology $\tau$ on $X$ which is a set $\mathcal{B}$ of open sets such that every element of $\tau$ can be written as the union of some elements of $\mathcal{B}$. There another notion which is more akin to a free group, which is the topology generated by a set e.g. given a set $S \subset \mathcal{P}(X)$ the topology generated by $S$ is the smallest topology on $X$ such that the elements of $S$ are open sets. Obviously, a generating set is not always a basis for the topology generated by it because a topology must contain the entire space and there is no guarantee that an arbitrary set of generators will cover the space. So my question is: under what conditions is a set $S$ also a basis for the topology generated by $S$ ?",['general-topology']
1781443,Suppose that for each $a\in \mathbb{C}$ at least one coefficient of the Taylor's series $f$ about $a$ is zero. Show that $f$ is a polynomial.,Let $f:\mathbb{C}\rightarrow\mathbb{C}$ be a holomorphic function. Suppose that for each $a\in \mathbb{C}$ at least one coefficient of the Taylor's series $f$ about $a$ is zero. Show that $f$ is  a polynomial.,"['complex-analysis', 'complex-integration']"
1781448,subaddivity of VaR,"It is known that the VaR (Value at risk) doesn't fulfill subadditivity, i.e. $VaR(X)+VaR(Y) \le VaR(X+Y)$. But for elliptical distributions subadditivity is true. 
Questions: (1) Which distributions are elliptical? I guess its the (multi)normal and t-distributions...Are stable and hyperbolic distributions elliptical,too? (2) Is subadditvity only fulfilled for elliptical distributions? Are there any other conditions (e.g. correlation) which have an impact on subadditivity of VaR.","['probability-theory', 'finance', 'probability', 'statistics']"
1781455,Application of calculus in real life,"I'm no mathematician, so bear with simplicity of what I'm asking. My calculus course(post-Soviet country, a while ago) was utter trash. I've recently decided to approach the topic for self eduction. I'd like to know how all of it is being applied IRL. 
The textbook examples on differentiation and integration use convenient incomes to be typical and easy to solve. But how would I start with computing intergal of a real-life function, with 'non-textbook' equivalents? How do I compute derivative from speed change graph of real-life wehicle which stops, speeds up in 'undeterministic' manner?","['derivatives', 'soft-question', 'calculus']"
1781486,Showing that the primary component $G_p$ is a subgroup of $G$,"For a finite abelian group $G$ and a prime number $p$ with $p \mid |G|$, we define $G_p$ as the subset of $G$ that contains all elements of $G$ with order $p^k$ for a $k \in \mathbb{N}_0$. We call $G_p$ the $p$-primary component of $G$. I now want to show that $G_p$ is a subgroup of $G$. We have that $G_p ≠ \emptyset$, because $ord(e_G) = p^0 = 1$. I also already know that for any $g \in G_p$, $g^{-1} \in G_p$ (because the inverse has the same order for each element of the group, which I have already shown). The only thing I'm still struggling with is showing that for $g, h \in G_p$, $g h \in G_p$. I can see that if $ord(g) = p^k, ord(h) = p^l$, then $ord(g h) ≤ p^{k + l}$. However, I've been sitting here for several minutes and just couldn't figure out why $ord(gh)$ is of the shape $p^m$ for any $m \in \mathbb{N}_0$ itself. (For all I know, it could be that $ord(g h) = q^m$ for some $q \mid |G|, q ≠ p$, since $|G|$ can have more than one prime factor.) There is probably a simple argument I'm missing for why that's the case, but I can't see it.","['finite-groups', 'abelian-groups', 'group-theory']"
1781529,The cone of a topological space is always path-connected,"I'm having trouble proving that if $X$ is a topological space, then $C(X)$ (defined as $X \times [0,1] /\sim$ where $(x_1,t_1)\sim (x_2,t_2)$ iff they are equal or $t_1=0=t_2$) is path-connected. I understand the definition and I know I must take two different points in the cone and construct a function from $[0,1]$ to $C(X)$. The problem is that because $C(X)$ is a quotient, then I don't quite see how points look like and how to join them with a path. Thank you.",['general-topology']
1781565,"Show that if a convex polygon is entirely inside another convex polygon, then the outer polygon has perimeter greater than or equal to the inner one.","Can anyone help me out with proving this statment? ""Show that if a convex polygon is entirely inside another convex polygon, then the outer polygon has perimeter greater than or equal to the inner one.""","['euclidean-geometry', 'geometry']"
1781577,Covering Torus by torus,"This question concerns example 1.41 in Hatcher's Algebraic topology. There he constructs a covering for the genus 3 surface by the genus 11 surface by shaping it like a star with 5 arms with two holes in each arm and one at the center. Then he quotients the 11 genus surface by $\mathbb{Z}_5$ to get the genus 3 surface (I am sorry I dont know how to include pictures. Now because this cover space is normal, the group of deck transformations, that is $\mathbb{Z}_5$, is isomorphic to the fundamental group of the surface of genus 3 over the subgroup the induced by the image of the cover space. So that we conclude the fundamental group of the genus 11 surface is a subgroup of the fundamental group of the genus 3 surface and has index 5. Now my question is this.. If I replace the arms of the 11 holed surface by arms with no holes, I will get something homeomorphic to the torus. Doing exactly the same procedure as before, the cover space is still normal the deck transformations are again $\mathbb{Z}_5$, I am going to end up concluding that the fundamental group of the torus contains itself as a subgroup of index 5... but this seems weird, can someone please explain what I am not thinking right??","['algebraic-topology', 'general-topology', 'geometry']"
1781580,Difficulties on proving the continuity part of a homeomorphism,"I am trying to prove that the open unitary disk $\mathbb{D}^n$ is homeomorphic to $\mathbb{R}^n$, so the way i am doing it is by showing that the function $$f(x)=\frac{1}{1-|x|}x$$ where $x$ is a vector in $\mathbb{D}^n$ and $|x|$ is its norm, is bijective, continuous and has inverse continuous. To prove it's bijective it suffies to give its inverse function $f^{-1}(y)= \frac{1}{1+|y|}y$ but I'm kind of lost with the continuity part. Using the definition i guess i should manipulate this expression: $$|\frac{1}{1-|x|}x - \frac{1}{1-|y|}y|< \epsilon$$ to get $$|x-y|< \delta$$ where $x$ and $y$ belong to $\mathbb{R}^n$ and $\delta$ issomething that depends on $\epsilon$ and $x$. I've tried some algebraic  manipulation but didn't get anything useful, perphaps there is some more direct way of doing it. Any help would be much appreciated","['multivariable-calculus', 'general-topology', 'continuity']"
1781642,The problem of instant velocity,"The concept of velocity is by definition the movement divided by the interval of time between initial position and final position. If $f(t)$ is the position of a particle at time $t$; the velocity in the interval $[t_0;t_1]$ is $\dfrac{f(t_1)-f(t_0)}{t_1-t_0}$ The problem is that in a single instant there is no movement and the time is not changed; so no velocity. I can consider $\lim_{t_1 \to t_0} \dfrac{f(t_1)-f(t_0)}{t_1-t_0}$, but mathematically it is only the limit of average velocity function and doesn't represent velocity at instant $t_0$ What are your views about this problem ?","['intuition', 'soft-question', 'calculus', 'philosophy']"
1781660,Showing $S^2/{\sim}$ (real projective plane) is Hausdorff,"Let $\pi:\;S^2\to S^2/{\sim}$ be the projection map where the relation on $S^2$ is $a\sim b\iff a =\pm b$. I am trying to show $S^2/{\sim}$ is Hausdorff. So take $\alpha,\beta\in S^2/{\sim}$ then $\pi^{-1}(\alpha)=\{\pm a\},\pi^{-1}(\beta)=\{\pm b\}$. Take $\varepsilon<\frac{1}{2}\min\left\{\|a-b\|, \|a+b\|\right\}$ then $A=B_\varepsilon(a)\cap S^2, B=B_\varepsilon(b)\cap S^2$ are disjoint open neighbourhoods of $a,b$ (and $-A,-B$ for $-a,-b$). Now $\pi(A)\cap\pi(B)=\emptyset$ since $\pi(u)=\pi(v)\iff u=\pm v$ and $A,B$ disjoint. But I can't see how to properly show that $\pi(A),\pi(B)$ are open? I know that not all projection maps are open maps so it's not immediate...","['general-topology', 'metric-spaces', 'quotient-spaces']"
1781677,Existence of Banach Limits,"Just want to check everything is good. $\textbf{Theorem:}$ Define $T: l_{\infty}(\mathbb{R}) \to l_{\infty}(\mathbb{R})$ by $$T(x_1,x_2,x_3,...)=(x_2,x_3,x_4,...),$$ $$M=\{x-Tx:x \in l_{\infty}(\mathbb{R})\},$$ and $e=(1,1,1,...)$. Then $(a)$ $T \in \mathcal{L}(l_{\infty}(\mathbb{R}))$ ($T$ is both continuous and linear) and $\Vert T \Vert = 1$; $(b)$ $M \leq l_{\infty}$ and $d(e,M)=1$; $(c)$ There exists $f \in l_{\infty}(\mathbb{R})'$ such that $(1)$ $\Vert f \Vert = 1$, $(2)$ for each $x \in l_{\infty}(\mathbb{R})$ we have $f(x)=f(T(x))$ and $(3)$ for each $(x_n) \in c(\mathbb{R})$ we have $f((x_n))=\lim_{n \to \infty}x_n$, $(4)$ for each $(x_n) \in l_{\infty}(\mathbb{R})$ such that for each $n \in \mathbb{N}$, $x_n \geq 0$, we have $f((x_n)) \geq 0$. $\textbf{Proof}:$ It's easy to check $T \in \mathcal{L}(l_{\infty}(\mathbb{R}))$ and $M \leq l_{\infty}$. Since $0_{l_{\infty}(\mathbb{R})} \in M$, $d(e,M) \leq 1$. Let $x=(x_n) \in l_{\infty}(\mathbb{R})$. If for some $n \in \mathbb{N}$, $x_n-x_{n+1} \leq 0$, then $$1 \leq \vert 1-(x_n-x_{n+1}) \vert \leq \Vert e-(x-T(x)) \Vert;$$ if on the other hand for each $n \in \mathbb{N}$, $x_n-x_{n+1} \geq 0$, that is, $x_{n+1} \leq x_n$, then $\lim_{n \to \infty}x_n$ exists, so that $\lim_{n \to \infty}x_n-x_{n+1}=0$ and we have $$1 \leq \Vert e-(x-T(x)) \Vert.$$ We conclude $d(e,M) \geq 1$, and in fact, $d(e,M)=1$. By (a certain consequence of) the Hahn-Banach Theorem, we can find $f \in l_{\infty}(\mathbb{R})'$ such that $\Vert f \Vert = 1$, $f(e)=1$ and for each $x \in M$, $f(x)=0$, that is, for each $x \in l_{\infty}(\mathbb{R})$, $$f(x)-f(T(x))=f(x-T(x))=0.$$ Suppose now $x = (x_n) \in c_0(\mathbb{R})$. For each $n \in \mathbb{N}$ we have $$T^{n}(x)-x=[T^{n}(x)-T^{n-1}(x)]+...+[T(x)-x] \in M,$$ so that $f(x)=f(T^{n}(x))$; then if $\epsilon \in \mathbb{R}_{>0}$ and $n \in \mathbb{N}$ is such that $m \in \mathbb{N}_{>n}$ implies $\vert x_m \vert < \epsilon$ we have $$\vert f(x) \vert = \vert f(T^n(x)) \vert \leq \Vert T^n(x) \Vert < \epsilon,$$ and therefore $x \in \ker f$, that is, $$f(x)=0=\lim_{n \to \infty}x_n.$$ It follows that if $x=(x_n) \in c(\mathbb{R})$, we have $f(x)=\lim_{n \to \infty}x_n$. Finally, suppose there exists $x = (x_n) \in l_{\infty}(\mathbb{R})$ such that for each $n \in \mathbb{N}$, $x_n \geq 0$ and $f(x)<0$. Define $\overline{x} = x / \Vert x \Vert$. Then for each $n \in \mathbb{N}$ we have $$0 \leq \overline{x}_n \leq 1 \ \text{and} \ f(\overline{x})<0$$ and therefore $$\Vert e-\overline{x} \Vert \leq 1 \ \text{and} \ f(e-\overline{x})=1-f(\overline{x})>1,$$ which is absurd since $\Vert f \Vert = 1$.","['functional-analysis', 'proof-verification']"
1781691,"if $A_n$ weakly converges to $A$, does $|A_n| \rightarrow _{wo} |A|$?","Suppose that $A_n,A$ are self-adjoint operators in $B(H)$. If $A_n$ weakly converges to $A$, does $|A_n| \rightarrow _{wo} |A|$? From Proposition. 2.3.2 of Pederson'book, I know the result holds in the strong case.","['functional-analysis', 'operator-algebras', 'von-neumann-algebras']"
1781692,What is the probability of selecting five of the winning balls and one of the supplementary balls?,"So I'm just doing a bit of probability questions and wanted to make sure I got it right. I have $50$ balls numbered $1-50$, and we pick $6$ winning balls and $2$ supplementary without replacement. So the chance to get the $6$ winning balls would simply be: $$\frac{6}{50} \cdot \frac{5}{49} \cdot \frac{4}{48} \cdot \frac{3}{47} \cdot \frac{2}{46} \cdot \frac{1}{45} = \frac{1}{15890700}$$ and for $5$ winning balls it would be, same process as above: $$\frac{3}{1059380}$$ Now the part that confuses me is $5$ winning, $1$ supplementary. Would this be given by: $$\frac{6}{50} \cdot \frac{5}{49} \cdot \frac{4}{48} \cdot \frac{3}{47} \cdot \frac{2}{46} \cdot \frac{44}{45} \cdot \frac{2}{44} = \frac{1}{7945350}?$$ Can someone please check if I did this right, I have a sense that I did not, but not sure where I went wrong.",['probability']
1781695,Can any presentation of a finitely presented group be reduced to a finite one?,"Suppose $G = \langle x_1, \ldots, x_n \mid p_1, \ldots, p_m \rangle$ is a finitely presented group, and let $\langle A \mid R \rangle$ be another presentation of $G$, with $A$ and $R$ possibly infinite.  Do there always exist finite subsets $A' \subset A$, $R' \subset R$ such that $G = \langle A' \mid R' \rangle$? I feel like the answer should be ""yes.""  Here's my idea: we can write each $x_i$ as a product of finitely many $a \in A$ (and their inverses); denote by $A_i$ this finite set of $a$'s.  Then the finite set $A_1 \cup \cdots \cup A_n$ generates $G$. Similarly, each relator $p_i$ can be derived from a finite set of relators $R_i \subset R$.  Here's my problem, though: how do I know that any relator $w$ in the letters $A_1 \cup \cdots \cup A_n$ can be reduced using these $R_i$?  Not every such $w$ blocks off into $x_i$-chunks.",['group-theory']
1781701,Method to find the extremal values of $xyz$ subject to $x^2+2y^2+3z^2=a$,"This question has been asked before but I want to lay out my method and get feedback on reasoning and process this took me a long to put together as I am new to the formatting: Let the function $f$ be defined as
$f$($x$,$y$,$z$) $=$ $x$$y$$z$ find the maximum and minimum values subject to the constraint:
$g$($x$,$y$,$z$) $=$ $x^2$+2$y^2$+3$z^2$ Equation 1 $=$ $\nabla$$f_x$ $=$ $\lambda$ $\nabla$$g_x$ $=$ [ $yz$ $=$ $\lambda$2$x$] Equation 2 $=$ $\nabla$$f_y$ $=$ $\lambda$ $\nabla$$g_y$ $=$ [ $xz$ $=$ $\lambda$4$y$] Equation 3 $=$ $\nabla$$f_z$ $=$ $\lambda$ $\nabla$$g_z$ $=$ [ $yx$ $=$ $\lambda$6$z$] It is my understanding that to solve these equations really just amounts to solving the relationship between values $x,y,z$ (and then plug into constraint) or the values themselves if there is an easy way to do so. My basic instinct was to solve Equation 1 for $x$, obtaining:
$x$ $=$ $\frac{yz}{2\lambda}$ Since Equation 3 consists of $x,y,z$ and I have x in terms of $y$ and $z$, then plugging $x$ into Equation 3 would get me the relationship of $y$ to $z$, giving me: $\frac{yz}{2\lambda}$$\frac{y}{1}$ $=$ $\frac{\lambda6z}{1}$ Simplifying I then get:
12$z$$\lambda^2$ $=$ $y^2$$z$
Then Subtracting the right side over to the left and factoring out $z$ gives:
$z$(12$\lambda^2$-$y^2$) $=$ 0 Giving me:
$z$ $=$ 0 and 12$\lambda^2$ $-$ $y^2$ $=$ 0 $\lambda$ $\neq$ 0 because that would imply that $x=y=z=0$ which does not hold true in the constraint. Now following from the above observation $z$ $\neq$ 0 because that would imply that $x=y=z=0$ which does not hold true in the constraint. This leaves 12$\lambda^2$ $-$ $y^2$ $=$ 0 for me to obtain values from. Solving for $y$ I get:
$y$ $=$ $\pm$ 2$\lambda$$\sqrt{3}$ I then plugged $y$ into the $x$ value I solved for in my first step: $x$ $=$ $\frac{yz}{2\lambda}$ and obtained: $x$ $=$ $\pm$ $\sqrt{3}z$ From here I am lost. I can't seem to do anything to get the rest of the values and get numerical values. I would like my process addressed first and then suggestions, and by that I mean answering the question is there a way to proceed down the same route that I am going or was my process flawed from the start? The book gives the answer exactly as follows:  maximum $\frac{2}{\sqrt{3}}$, minimum $\frac{-2}{\sqrt{3}}$. What does that even mean when checking my answers I am used to $f$($x,y,z$) $=$ $c$. I'm guessing that in this instance they are just giving me c. Thank you","['multivariable-calculus', 'optimization', 'lagrange-multiplier']"
1781707,"Equivalence between Minimality Conidition, Well-Founded Property, Descending-Chain-Condition, and Noertherin Induction","Let $(M, \preceq)$ denote a partially ordered set $M$ along with a partial order $\preceq$ on it. Proof of the equivalence between: A : Descending Chain Condition
If ($\mathcal{C}$ is a decresasing chain in M) $\rightarrow$ ($\mathcal{C}$ is finite)
More formally: For any chain  $a_o  \succeq a_1 \succeq ... a_i \succeq ...$, there exists a number n such that $a_n = a_{n+1} =...$ B: Well-Founded-Property: There does not exist an infinite strictly decreasing chain in M C : Minimality Property: Every non-empty subset in M has a minimal element condition 1) P(x) is true for all minimal elements x $\in$ M 
condition 2) If P(z) is true $\forall$ z $\in$ M such that z $<$ y, for some y $\in$ M $\rightarrow$ P(y) D : Noertherian Induction Property: (condition1 $\wedge$ condition2) $\rightarrow$ P(a) $\forall a \in M$ We will first prove $A \rightarrow B$
Proof by contradiction Assume $A$ $ \wedge \neg B$ Then we are assuming A, as well as the existence of an infinite
  descending chain in M. Let us call this chain $\mathcal{C}$ But by A,
  since $\mathcal{C}$ is a descending chain it should be finite, but by
  our assumption of $\neg B$ we are assuming otherwise. Contradiction proof of $B \rightarrow C$
 Proof by contradiction Assume $B$ $\wedge \neg C$ Let $\mathcal{C}$ be a non-empty subset of M such that there is no
  minimal element in $\mathcal{C}$. This set exists by assumption of
  $\neg C$. Since $\mathcal{C}$ is not empty, there exists an $a_0 \in
\mathcal{C}$. If there does not exist a second element $a_1 \in \mathcal{C}$, then
  $a_0$ would constitute a minimal element (w.r.t $\mathcal{C}$).  This
  would contradict assumption $C$. Then $\mathcal{C}$ must contain more than one element. Since  $\mathcal{C}$ does not contain a minimal element, there must
  exist $a_1$ in $\mathcal{C}$ such that $a_o  \succ a_1$ Since $a_1$
  cannot be a minimal element there must exist $a_2$ in $\mathcal{C}$
  such that  $a_o  \succ a_1 \succ a_2 $ If there exists an $a_k$ in $\mathcal{C}$ such that $a_0  \succ a_1
 \succ   a_2 \succ ... \succ a_k$, for all $a_i \neq a_k \in
 \mathcal{C}$,then $a_k$ would constitue a minimal element. This
  would contradict assumption $B$. Therefore, $\mathcal{C}$ does not have a minimal element, yet
  constitues an infinite strictly descending chain. This is our final contradiction, as this contradicts assumption $B$. We want to now prove $ C \rightarrow D$ Proof by contradiction Assume $C \wedge \neg D $ Then we are assuming $C$ $ \wedge $
  [condition1 $\wedge$ condition2] $\wedge$ $ [\exists  a \in  M$ such
  that $\neg$P(a)] Let  $P(x)$ be a propositional function that satisfies conditions 1
  and 2 Let $ \mathcal{X} = \{ x \in M \, | \, \neg P(x) \}.$ Our assumption of $\neg D$ assumes that $ \mathcal{X}$ is not empty Then by assumption $C$, every non-empty set has a minimal element.
  Thus there exists a minimal element, $x_0$ in $\mathcal{X}$ Since we are assuming condition1, P($x_0$) must hold. This yields a contradiction as P($x_0$) holds, yet $x_0$ is in 
  $\mathcal{X}$ which is defined to be such that $\neg$ P($x$) holds for
  all elements which are members. The contradiction is that P($x_0$) and $\neg$ P($x_0$) cannot both
  hold. Therefore, $\mathcal{X}$ cannot be non-empty, and therefore is empty.
  Thus, our condition of  $\neg D $, that of: [condition1 $\wedge$
  condition2] $\wedge$ $ [\exists  a \in  M$ such that $\neg$P(a)], is
  contradicted We want to now prove $ D \rightarrow A$
Proof by contradiction Assume $D \wedge \neg A $ Then we are assuming the Noertherian
  Induction Property as well as the negation of the Descending Chain
  Condition That is, we are assuming the Noertherian Induction Property
  and If ($\mathcal{C}$ is a decresasing chain in M) $\rightarrow$
  ($\mathcal{C}$ is finite) I am stuck for this last part of the proof. So is what I have so far ok, and also can anyone help with the remaining piece?
Thanks","['logic', 'elementary-set-theory', 'proof-verification']"
1781722,Prove that $2^x = 3 \cdot 9^m+5$ has no positive integer solutions for $m \geq 2$,"Prove that $2^x = 3 \cdot 9^m+5$ has no positive integer solutions for $m \geq 2$. I noticed that $x \equiv 5 \bmod 6$ and thus $2^x \equiv 4 \bmod 7$, but that doesn't seem to help me since $3 \cdot 9^4 +5 \equiv 4 \bmod 7$. Pretty much any other mod I use doesn't seem to work so I think proof by contradiction or something may work better.",['number-theory']
1781730,What is $\sum\limits_{n=0}^\infty \binom{2n}{n}\frac{1}{x^n}$ for $x > 4$.,"What is $\sum\limits_{n=0}^\infty \binom{2n}{n}\frac{1}{x^n}$ for $x > 4$. Here is what I got so far (using Cauchy's integral formula) :
$$\sum\limits_{n=0}^\infty \binom{2n}{n}\frac{1}{x^n} ~=~ \sum\limits_{n=0}^\infty \left(\frac{1}{2\pi i}\int_\mathbb{T} \frac{(1+z)^{2n}}{z^{n+1}}\; dz\right) \cdot \frac{1}{x^n} \\=~ \frac{1}{2\pi i}\sum\limits_{n=0}^\infty   \frac{1}{x^n}\int_{\mathbb{T}} \frac{1}{z}\cdot \left( \frac{(1+z)^2}{z}\right)^n \; dz \\=~ \frac{1}{2\pi i}  \int_{\mathbb{T}} \frac{1}{z} \sum\limits_{n=0}^\infty \left( \frac{(1+z)^2}{xz}\right)^n \; dz \\=~ \frac{1}{2\pi i}\int_\mathbb{T} \frac{1}{z} \cdot \left( \frac{1}{1- \left(\frac{(1+z)^2}{xz}\right)}\right) \; dz  \\=~ \frac{1}{2\pi i}\int_\mathbb{T} \frac{1}{z} \cdot \left(\frac{xz}{xz- (1+z)^2}\right) \; dz \\=~ \frac{1}{2\pi i}\int_\mathbb{T} \frac{x}{xz- (1+z)^2} \; dz \\=~ \frac{1}{2\pi i}\int_\mathbb{T} \frac{x}{-1 + (x-2)z- z^2} \; dz$$ According to Wolframalpha I should get $\sqrt{\frac{x}{x-4}}$. Where did I commit a sin ? I'm expecting to use the Residue theorem or Cauchy's integral formula at some point but I feel something is fishy.","['cauchy-integral-formula', 'complex-analysis', 'binomial-coefficients']"
1781733,Proof that the Period of $\sin(x)$ is $2\pi$.,"As I was walking through campus today, I had an interesting question pop into my head: How can we prove that the period of $\tan(x)$ is $\pi$ rather than $2\pi$? The answer to this was extremely straightforward: We start off with $$\tan(x) = \tan(x + T) = {\tan(x) + \tan(T) \over 1 - \tan(x) \tan(T)}$$ to give us $$-\tan^2(x)\tan(T) = \tan(T)$$ $$0 = \tan(T) + \tan^2(x)\tan(T)$$ $$0 = \tan(T)[1 + \tan^2(x)]$$ $$\implies \tan(T) = 0\;\;\;\;\;\text{and}\;\;\;\;1 + \tan^2(x) = 0 \implies \text{No real solution for any $x\in\mathbb{R}$}$$ Which for $\tan(T) = 0 \implies {\sin(T) \over \cos(T)} = 0 \implies \sin(T) = 0$, we have $T = 0, \pi  \implies T = \pi$ to show that the period of $\tan(x)$ is $\pi$ if we desire a nontrivial answer. But I got stuck trying to do the same with $\sin(x)$. I tried: $$\sin(x) = \sin(x + T) = \sin(x)\cos(T) + \sin(T)\cos(x)$$ $$\implies \sin(x)[1 - \cos(T)] = \sin(T)\cos(x)$$ $$\implies \tan(x) = {\sin(T) \over 1 - \cos(T)}$$ But I got stuck here. I'm not sure how to isolate a single trig function in terms of $T$. I Googled this proof, but everyone either uses Taylor Expansions, Euler's Formula, or calculus. But I'm looking for an argument I could present to someone with knowledge of trigonometry and no more. Any ideas?","['algebra-precalculus', 'proof-writing', 'trigonometry']"
1781739,Maximizing sum of logarithms (Z-channel capacity),"In the context of information theory, I am trying to maximize the following function (mutual information of the Z-channel's input and output) with respect to $p$ in order to derive Z-channel's capacity:
$$I(X;Y)=\mathit{H}(ap)-\mathit{H}(1-a)p$$
where $\mathit{H}(x)=-xlog_2(x)-(1-x)log_2(1-x)$, $0<x<1$ is known as the binary entropy function.
So the function is:
$$I(X;Y)=-aplog_2(ap)-(1-ap)log_2(1-ap)-\mathit{H}(1-a)p$$
Differentiating with respect to $p$ I get:
\begin{eqnarray*}
\frac{\partial I(X;Y)}{\partial p}&=&-alog_2(ap)-ap\frac{1}{pln2}+alog_2(1-ap)-(1-ap)\frac{a}{ln2(ap-1)}-\mathit{H}(1-a)\\
&=&log_2((ap)^{-a}e^{-a}(1-ap)^{-a}e^aa^a(1-a)^{1-a})\\
&=&log_2((ap)^{-a}(1-ap)^{-a}a^a(1-a)^{1-a})
\end{eqnarray*}
Then:
\begin{eqnarray*}
\frac{\partial I(X;Y)}{\partial p}=0&\Rightarrow &log_2((ap)^{-a}(1-ap)^{-a}a^a(1-a)^{1-a})=0\\
&\Rightarrow &(ap)^{-a}(1-ap)^{-a}a^a(1-a)^{1-a}=1\\
\end{eqnarray*}
I can't solve this. Eventually, I am trying to prove that the value of $p$ that maximizes the function is:
$$p=\frac{1}{a(1+2^{\mathit{H}(1-a)/a})}$$
More information on the Z-channel can be found here , but I am using different notation regarding the probabilities.","['derivatives', 'logarithms', 'functions', 'information-theory', 'probability']"
1781759,"How to take the ""gradient"" of a matrix?","I want to find $(D^2 F)$ where $\vec{F}(\vec{x}) = \frac{\vec{x}}{\|\vec{x}\|}$ ($F$ is a row vector and $Du$ is a ""column vector"", where $u\in \mathbb{R}$ ). I know that $$(DF)_{ij} = \frac{\delta_{ij}\|x\|^2 - 2 x_ix_j}{\|x\|^4}\qquad\rightarrow\qquad (DF) = \frac{I}{\|x\|^2} - \frac{2xx^T}{\|x\|^4}.$$ How exactly do I find $(D^2F)$? I tried reading the section on wikipedia and it hasn't been productive so far.","['multivariable-calculus', 'linear-algebra', 'calculus', 'partial-differential-equations']"
1781775,An intuitive way to understand the Jacobi's formula.,"Suppose that $\mathbf A=\mathbf A(t)$ is a matrix whose entries are parametrized by a variable $t$. The Jacobi's formular states that
$$
\frac d{dt}\left( \det \mathbf A\right)= \text{Tr}\left( \text{adj} (\mathbf A ) \frac{d\mathbf A}{dt} \right)\ ,
$$
where $\text{adj}(\mathbf A)$ is the adjugate (or adjoint) of $\mathbf A$. There is a proof of that in this wikipedia article . Another closely related identity, which appears to go by the same name, is
$$
\det\left( e^{\mathbf A} \right) = e^{\text{Tr}(\mathbf A)}\ .
$$
I want to understand the reason why these formulas are true, especially the second one. In particularly, what is the interpretations of $\det\left( e^{\mathbf A} \right)$ and $\text{Tr}(\mathbf A)$, when $\mathbf A$ is considered as a linear operator? These are some related links that I have found about the question: Derivative of a determinant of a matrix field Proof for the derivative of the determinant of a matrix Exponential of a matrix and related derivative","['real-analysis', 'matrices', 'calculus', 'linear-algebra', 'lie-groups']"
1781796,Interior of a set is the largest open subset - proof verification,"I want to prove the following: Let $(X, \mathcal{T})$ be a topological space. Let $A \subset X$ be a subset. Then $\mathrm{int}A$ is the largest open subset of $A$. Our definition is $\mathrm{int}A = \{x \in A : \exists \text{ neighbourhood } N \text{ of } x \text{ such that } N \subset A\}$ I'm not sure if my proof is correct and would appreciate a check of it: We have already previously shown that $\mathrm{int}A$ is open (this was a previous proposition). Let $U \subset A$ be open. Let $x \in U$. Then $\exists$ neighbourhood $N$ of $x$ such that $N \subset U$ (since $U$ is open). But $N \subset U \subset A$, i.e. $x \in \mathrm{int}A$, and we have shown that $U \subset \mathrm{int}A$.","['general-topology', 'proof-verification']"
1781797,de Rham cohomology on finitely smooth manifolds,"In all of the places I've looked, de Rham cohomology is defined on $\mathcal{C}^\infty$ manifolds with $\mathcal{C}^\infty$ differential forms. What about de Rham cohomology on $\mathcal{C}^r$ manifolds with $\mathcal{C}^r$ differential forms? Can de Rham cohomology still be defined? If a $\mathcal{C}^r$ manifold is homeomorphic to a $\mathcal{C}^\infty$ manifold, are the de Rham cohomologies isomorphic? Specific question I am interested in The first de Rham cohomology of $S^1 \subset \mathbb{R}^2$ is isomorphic to $\mathbb{R}$. This means that any closed differential 1-form on $S^1$ is of the form $c \cdot \theta + d V$ where $c \in \mathbb{R}$, $\theta$ represents a basis element (e.g., the angle 1-form), and $V$ is a $\mathcal{C}^\infty$ function. Now, what if I have a space which is only $\mathcal{C}^r$ diffeomorphic to $S^1$. Is it true that any $\mathcal{C}^{r-1}$ closed differential 1-form is of the form $c\cdot \theta + dV$, where $\theta$ is $\mathcal{C}^{r-1}$ and $V$ is $\mathcal{C}^r$? Update: As pointed out by Najib Idrissi, any $\mathcal{C}^r$ manifold $M$ is $\mathcal{C}^r$ diffeomorphic to a $\mathcal{C}^\infty$ manifold $N$. One could then define the de Rham cohomology of $M$ to be the de Rham cohomology of $N$. This certainly yields information about the topology of $M$ -- but I am interested in information about what types of closed differential forms may exist on $M$. I think this is a relevant question: Do there exist closed $\mathcal{C}^r$ differential forms on $N$ which do not differ from some closed $\mathcal{C}^\infty$ form by an exact form?","['algebraic-topology', 'differential-geometry', 'differential-topology']"
1781848,How many distinct flat connections are there on a flat bundle?,"Given a flat smooth vector bundle (i.e. with constant transition functions), how many distinct flat connections could we put on it? If the flat connection is not unique, is it unique up to gauge equivalence (i.e. automorphism of bundles with connection)?","['connections', 'vector-bundles', 'differential-geometry']"
1781911,Give a graph model for a permutation problem,"Describe a graph model for solving the following problem: Can the permutations of $\{1,2,\ldots,n\}$ be arranged in a sequence so that the adjacent permutations $$p:p_1,\ldots,p_n \text{ and }  q:q_1,\ldots,q_n$$ satisfy $p_i\neq q_i$ for all $i$? I have problem understanding what the exercise asks. What does ""adjacent permutation"" mean? Also, in a follow-up question, it says that the statement is true for $n\geq 5$.","['graph-theory', 'discrete-mathematics']"
1781924,How to solve this double integral involving trig substitution (using tangent function)?,"This is a question I came across and I cannot find the answer. By using a substitution involving the tangent function, show that $$\int_0^1\int_0^1\frac{x^2-y^2}{(x^2+y^2)^2}\,dy\,dx=\frac{\pi}{4}$$ My attempt I use trig substitution, by saying
$$\tan(\theta)=\frac{y}{x}$$ which means 
$$x\sec^2(\theta)\,d\theta=dy$$
Also, it should be noted that because of this 
$$x\sec(\theta)=\sqrt{x^2+y^2}$$
$$x^4\sec^4(\theta)=(x^2+y^2)^2
$$
Thus, when I substitute this information into the integral, I get
$$\int_0^1\int_{\theta=0}^{\arctan(\frac{1}{x})} \frac{x^2-(x^2\tan^2(\theta))}{x^4\sec^4(\theta)}{x\sec^2(\theta)} \, d\theta \,dx$$
Then, this simplifies to
$$\int_0^1\int_{\theta=0}^{\arctan(\frac{1}{x})} \frac{x^2(1-\tan^2(\theta))}{x^4\sec^4(\theta)}{x\sec^2(\theta)}\,d\theta \,dx$$
$$\int_0^1\int_{\theta=0}^{\arctan(\frac{1}{x})} \frac{x^2\sec^2(\theta)}{x^4\sec^4(\theta)}{x\sec^2(\theta)}\,d\theta \,dx=\int_0^1\int_{\theta=0}^{\arctan(\frac{1}{x})}{\frac{1}{x}}\,d\theta \,dx$$ which leads to
$$\int_0^1 \left[\frac \theta x \right]_0^{\arctan\left(\frac{1}{x}\right)} \,dx = \int_0^1 \frac{\arctan\left(\frac{1}{x}\right)}{x}                   \, dx_{(3)} $$
At this point I am stuck.  How do I evaluate this integral.  Am I on the right path?  Wolfram Alpha gives an answer other than $\frac{\pi}{4}$ for (3), so I am not sure where I am wrong.","['multivariable-calculus', 'integration']"
1781946,"When does a f.g. algebra over a field $F$ make it ""look like $F$ is algebraically closed?""","Let $F$ be a field, and let $A$ be a finitely generated algebra over $F$.  If $\mathfrak m$ is a maximal ideal of $A$, then $A/\mathfrak m$ is an algebraic extension of $F$, although it is in general not equal to $F$. Are there f.g. algebras $A$ for which $A/\mathfrak m = F$ for all maximal ideals $\mathfrak m$ of $A$? There is an obvious situation where this is true, when $A$ is a finite product of copies of $F$.  I was wondering whether there were some nontrivial examples and whether they were of interest to anyone. My motivation is as follows: If $B$ is another f.g. generated $F$-algebra, then there is an injection of $\textrm{Max } A \otimes_F B$ into $\textrm{Max } A \times \textrm{Max } B$, since every maximal ideal of $A \otimes_F B$ takes the form $\mathfrak m \otimes B + A \otimes \mathfrak n$ for $\mathfrak m, \mathfrak n$ maximal ideals of $A, B$.  Not all ideals of this form are maximal though, since $$(A \otimes_F B)/[\mathfrak m \otimes B + A \otimes \mathfrak n] \simeq A/\mathfrak m \otimes_F B/\mathfrak n$$ need not be a field.  So if $A,B$ satisfy the property above, then as in the algebraically closed case, the closed points of the scheme $\textrm{Spec } A \otimes_F B$ can be identified with the cartesian product of the closed points of $\textrm{Spec } A$ and $\textrm{Spec } B$.","['field-theory', 'algebraic-geometry', 'commutative-algebra']"
1781976,Textbook Recommentation: Discrete Differential Geometry,are there any good books that provide a good introduction to Discrete Differential Geometry to beginners? Thanks a lot.,"['discrete-geometry', 'geometry']"
1782031,Fourier transform of integral related to zeta function,"In this MO question here , I asked about the Fourier transform of the zeta function. The second answer lists the following as a representation for $\zeta(s)$, with $E(x)$ as the floor function: \begin{multline}
\zeta(\frac 1 2 +it)=-it\int_{1}^{+\infty}\bigl(x-E(x)\bigr)x^{-\frac3 2 -it }dx
-\frac 1 2\int_{1}^{+\infty}\bigl(x-E(x)\bigr)x^{-\frac3 2 -it }dx\\-\frac{1+2it}{1-2it},
\tag{$\ast$}
\end{multline} The idea is that by getting the Fourier transform of the expression $\int_{1}^{+\infty}\bigl(x-E(x)\bigr)x^{-\frac3 2 -it }dx$, we can essentially get the whole thing. To get this Fourier transform, we need to solve the double integral $F(\omega) = \int_{-\infty}^{\infty} \left[\int_{1}^{+\infty}\bigl(x-E(x)\bigr)x^{-\frac3 2 -it }dx \right] e^{-i\omega t} dt$ The answer then goes onto say: With the above formula, it is easy to find an explicit expression for the Fourier transform: in fact, we need only to calculate the Fourier transform of $t\mapsto e^{-it \ln x}$, which is $\delta_0(\tau+\frac{\ln x}{2π})$... As a result, the Fourier transform of the second term in $(\ast)$ is given by
  $$
\int_{1}^{+\infty}\bigl(x-E(x)\bigr)x^{-\frac3 2 }\delta_0(\tau+\frac{\ln x}{2π})dx,
$$ I am somewhat at a loss for how to arrive at this result. How do you go from the double integral to this? It doesn't seem like you can flip the order of the integrals here since there's that $e^{-i\omega t}$ on the outside.","['fourier-analysis', 'multiple-integral', 'calculus', 'integration', 'fourier-transform']"
1782032,Find $\sqrt{4+\sqrt[3]{4+\sqrt[4]{4+\sqrt[5]{4+\cdots}}}}$,"Find the value of $$\sqrt{4+\sqrt[3]{4+\sqrt[4]{4+\sqrt[5]{4+\cdots}}}}$$ I know how to solve when all surds are of the same order, but what if they are different? Technically, (as some users wanted to know exactly what is to be found), find: $$\lim_{n\to\infty}\sqrt{4+\sqrt[3]{4+\sqrt[4]{4+\sqrt[5]{4+\cdots+\sqrt[n]{4}}}}} $$","['recurrence-relations', 'nested-radicals', 'limits']"
1782042,List of matrix properties which are preserved after a change of basis,"Lately I encountered such a problem. Which of the properties of matrices are preserved after a change of basis ? ( orthogonal basis and square matrix are preferred in the first place ) Maybe it is a reasonable to make such a comprehensive list?
Wikipedia doesn't provide even a short list in Change of basis though it gives some answers in Matrix_similarity .
If someone knows however about such a list please give a pointer towards it. I need the list, not a bibliography. I would like additionally to divide properties into general and specific ones, where general properties are like symmetry, skew-symmetry, etc ( they can be or not associated with a given matrix - binary decision ) 
and 
specific properties are like
rank, determinant, trace etc.. ( they can be always characterized by a single number or a set of them ). So I will start. Also important is to list what is not preserved. What is preserved ? General properties: (if happens) Symmetry. Yes. Skew-Symmetry. Yes Orthogonality . Yes Diagonality (non-zero entries only on diagonal) No Positivness (all entries are positive) No . Specific properties: Trace. Yes . Rank. Yes . Determinant. Yes . What else can be added? ....","['big-list', 'linear-algebra']"
1782068,Covariance of stochastic integral,"I have a big problem with such a task: Calculate $\text{Cov} \, (X_t,X_r)$ where $X_t=\int_0^ts^3W_s \, dW_s$, $t \ge 0$. I've tried to do this in this way: setting up $t \le r$
$$\text{Cov} \, (X_t,X_r)=\text{Cov} \,  \left(\int_0^ts^3W_s \, dW_s,\int_0^rs^3W_s \, dW_s \right)=\int_0^t s^6 W^2_s \, ds$$
And I've stacked.","['probability-theory', 'covariance', 'brownian-motion', 'stochastic-integrals']"
1782069,In a triangle $ABC$ with side $AB=AC$ and $\measuredangle BAC=20 ^\circ $. $D $ is a point on side $AC$ and $BC = AD$. Find $ \measuredangle DBC$,Problem : In a triangle $ABC$ with side $AB=AC$ and $\measuredangle BAC=20 ^\circ $. $D $ is a point on side $AC$ and $BC = AD$. Find $ \measuredangle DBC$ Solution: $AB =AC$ So  $ \measuredangle ACB = \measuredangle ABC$ $ \measuredangle ACB = \measuredangle ABC=80^\circ$ (Using angle sum property) I am unable to continue from here. Any assistance is appreciated.,"['triangles', 'geometry']"
1782073,Why $\frac{\pi}{12}$ equals to $\frac{\pi}{3} - \frac{\pi}{4}$,"I'm going back to basic trigo for the sake of being able to help my kids and also being bad younger at it, I want to be able to overcome that lack of understanding and honestly, I hate unfinish business. So please bear with me if you feel my question  is really basic or stupid (and if you feel I should close it, please leave a comment) I was going through this book and at the 17th page, it said something like that: $$\frac{\pi}{12} = \frac{\pi}{3} - \frac{\pi}{4}$$ Looking on the net, it says something about angles in the triangle but the lack of precision is appaling and I could not get it. Your insights are more than welcomed",['trigonometry']
1782077,Does a limit at infinity exist?,"I use Stewart's ( Calculus , 8e) terminology. Infinite limits do not exist. For example we can write $$\lim_{x \rightarrow 0} \frac{1}{x^2} = \infty, $$ but at the same time say that $$\lim_{x \rightarrow 0} \frac{1}{x^2}$$ does not exist. Or at least this is what Stewart (89ff) insists. My question is this: Do limits at infinity exist? For example we can write $$\lim_{x \rightarrow \infty} \frac{1}{x^2} = 0.$$ But in this case, should we say that $$\lim_{x \rightarrow \infty} \frac{1}{x^2}$$ exists or does not exist? Stewart (126ff) doesn't seem to explicitly address this, which is why I'm asking. (Related: Why does an infinite limit not exist? --- here the reference is again Stewart, but there seems to be some confusion of the terms ""infinite limit"" and ""limit at infinity"".)",['calculus']
1782087,almost everywhere Vs. almost sure,"I'm reading a book about measure theory and probability (first chapter of Durret's  Probability book), and it's starting to switch between the terms ""a.e."" and ""a.s."" in different contexts. I'm becoming confused about their meanings. What's the difference between almost everywhere and almost sure?","['almost-everywhere', 'probability', 'measure-theory']"
1782104,Area of Convex hull,"For every point set $A \subset R^2$, prove that in general the sum of the coordinates of $\phi(T)$ is independent of a triangulation T and is associated to the area of the Convexv_Hull(A). We define vector $\phi(T) \subset R^n$, where $n$ is the number of points that we use in the triangulation * . Every $i-th$ coordinate of $\phi(T)$ is equal to the sum of areas of the triangles in T that contain $p_i$. That looks pretty straightforward to me (since no matter how we partition the space, the area is a constant value $ ), intuitively, but how to approach its proof? * we assume that a triangulation uses all points of a point set $ As the Cake By The Ocean song says: And no matter how you slice it...it's a piece of cake.","['trigonometry', 'triangulation', 'computational-geometry', 'geometry', 'area']"
1782189,Finding the orientation (Clockwise vs Anticlockwise) of a well-defined arc,"Given an arc, with two endpoints, a known radius, and a known center, is it possible to arbitrarily choose an endpoint as the start point, and determine if the motion of drawing the arc from that start point to the other endpoint is Clockwise or Anticlockwise. That's my general question, I'm working on writing a geometry program, and this program will take in the radius, end point, and start point of an arc. It will then determine the two (or one/zero in some cases) arcs that fit the givens. Finally, based on a Clockwise/Anticlockwise option, it will draw the appropriate arc. I've (with some help from another question here) already derived the formula for finding the center points, and now I just need the Clockwise versus Anticlockwise calculation. Unlike the center of the arc derivation, I have no idea where to begin. I think I've bitten of a bit more than I can chew, as I getting into topics that I've yet to learn in school. (I feel like any knowledge of calculus would make this indefinitely easier). Anyway, thanks for any help!",['geometry']
1782226,Conditions where $\mu$ is semifinite and where $\mu$ is $\sigma$-finite,"This comes out of the book Real Analysis by Folland: $\mu$ is semifinite if and only if $f(x) < \infty$ for every $x\in X$, and $\mu$ is $\sigma$-finite if and only if $\mu$ is semifinite and $\{x:f(x) > 0\}$ is countable. Attempted proof for first statement - Let $X$ be any nonempty set, $M = P(X)$, and $f$ be any function from $X$ to $[0,\infty]$. Then $f$ determines a measure $\mu$ on $M$ by the formula $$\mu(E) = \sum_{x\in E}f(x)$$ (note this is how Folland sets up the above problem that he states the reader can verify) Now suppose $\mu$ is semifinite then $E\in M$ with $\mu(E) = \infty$. So $$\mu(E) = \sum_{x\in E}f(x) = \infty$$ then $f(x) < \infty$ for every $x\in X$ (Not sure if this is true but seems to make sense to me). OTOH, suppose $f(x) < \infty$ for every $x\in X$... Not really sure where to go from here... any suggestions is greatly appreciated. Attempted proof for second statement - Let $\mu$ be $\sigma$-finite and let $\{E_j\}_{1}^{\infty}$ be a sequence of disjoint sets in $M$, and $\mu(E) = \infty$. Set $$F = \bigcup_{1}^{\infty} E_j \ \text{where} \ E_j\in M$$ Then there exists an $F\in M$ such that $F\subset E$ and $0 < \mu(F)\leq \mu(E) = \infty$ then $\mu$ is semifinite. Now define $$\sum_{x\in E'} f(x) := \sup\{\sum_{x\in E}f(x): E' \ \text{finite} \ , E' \subset E\}$$ Then observe that $\sum_{x\in E} f(x) < \infty$ which implies that $\{x\in E: f(x) > 0\}$ is countable. OTOH, suppose $\mu$ is semifinite and $\{x: f(x) > 0\}$ is countable then.... not really sure where to go from here... any suggestions is greatly appreciated. I would like to stick to how I set this proof up although if one would like to show me how they would prove it I would appreciate it.","['real-analysis', 'measure-theory']"
1782261,Degree $1$ map from torus to sphere,"I'm trying to find a smooth degree 1 map from the torus $T^2 = S^1 \times S^1$ to the $2$-sphere $S^2$. My first thought was to use the two coordinates $(\theta_1,\theta_2)$ to map onto the usual spherical polar coordinates on the sphere - however I can't quite get that to work because it seems that one of these coordinates would cover the sphere twice and so give a degree $2$ map? Alternatively I thought about using the winding number. So in general if we embed circles into $\mathbb{R}^3$ by the maps $f_1,f_2: S^1 \to \mathbb{R}^3$ we can then define a map $F:T^2 \to S^2$ by: $$F(\theta_1,\theta_2) = \frac{f_1(\theta_1) - f_2(\theta_2)}{\| f_1(\theta_1) - f_2(\theta_2) \|}$$ However I'm now struggling to make suitable choices for $f_1$ and $f_2$, my guess is that I'd want to make the circles cross over each other once but I'm struggling to visualise this and write down a map so I would appreciate any help.","['manifolds', 'smooth-manifolds', 'differential-geometry', 'differential-topology']"
1782267,The bundle of spin frames as an associated bundle,"$\DeclareMathOperator{\Spin}{Spin}$Let $X$ be an oriented smooth $n$-manifold with the frame bundle $\pi_{SO} \colon F_{SO} \to X$. Then the bundle of spin frames is a $\Spin(n)$-bundle $\pi_{\Spin} \colon F_{\Spin} \to X$ together with a $2$-fold equivariant covering $\pi \colon F_{\Spin} \to F_{SO}$ such that $\pi_{\Spin} = \pi_{SO} \circ \pi$. A bundle of spin frames can be considered as a group reduction of the bundle $\pi_{SO} \colon F_{SO} \to X$ along the covering homomorphism $\Spin(n) \to SO(n)$, which is, by definition, a bundle $\pi_{\Spin} \colon F_{\Spin} \to X$ together with an isomorphism of $SO(n)$-bundles $F_{\Spin} \times_{\Spin(n)} SO(n) \to F_{SO}$. My question is whether the second definition also implies the first one in the sense that any $\Spin(n)$-bundle associated to $F_{SO}$ via the covering projection $\Spin(n) \to SO(n)$ will define a spin structure (a bundle of spin frames)?","['principal-bundles', 'spin-geometry', 'differential-geometry']"
1782310,"If $f^*:\mathrm{Hom}(H, R) \to \mathrm{Hom}(G, R)$ is an iso for all $R$, is $f: G\to H$ an iso?","Let $G$, $H$ be abelian groups and $f: G\to H$ a homomorphism. Assume that $f^*: \mathrm{Hom}(H, R) \to \mathrm{Hom}(G, R)$ (as morphisms of abelian groups, taking $R$ with its additive group structure) is an isomorphism for all commutative rings (with 1) $R$. Is then $f$ an isomorphism as well? The question is motivated by a question on homological algebra, see here .",['abstract-algebra']
1782313,Unramified primes of splitting field,"I would like to show the following: Theorem : Let $K$ be a number field and and $L$ be the splitting field of a polynomial $f$ over $K$. If $f$ is separable modulo a prime $\lambda$ of $K$, then $L$ is unramified above $\lambda$. This should follow from the following theorem: Theorem : Let $L / K$ be a finite extension of number fields, and $B$ resp. $A$ the ring of integers of $L$ resp. $K$. Let $\mathfrak{p}$ be a prime of $K$ and $p$ the prime number lying under $\mathfrak{p}$. Let $\alpha \in B$. Let $f$ be the minimal polynomial of $\alpha$ over $K$, and let $\overline{f} = \overline{g_1}^{e_1} \cdots \overline{g_r}^{e_r}$ be the distinct irreducible factors of $f$ modulo $\mathfrak{p}$. If $p$ does not divide the order of $B / A[\alpha]$, then $\mathfrak{p}B = \mathfrak{P}_1^{e_1} \cdots \mathfrak{P_r}^{e_r}$. How can I do this? Thanks a lot!","['polynomials', 'abstract-algebra', 'algebraic-number-theory', 'commutative-algebra', 'field-theory']"
1782316,Series expansion of infinite series raised to the $n$th power,"So I know there is a well-known straightforward way to expand something like $$(a+b)^n$$ and that there are formulas which allow us to expand trinomials and multinomials in general. My question is, Is there any known way to expand something like $$\left[\sum_{k=0}^{\infty} a_k\right]^n$$ or at least to determine the first few terms?","['multinomial-coefficients', 'taylor-expansion', 'sequences-and-series']"
1782335,Abelian finite group [duplicate],"This question already has answers here : Group With an Endomorphism That is ""Almost"" Abelian is Abelian. (3 answers) Closed 8 years ago . This is a (maybe be simple) problem from Group Theory, but being a beginner, I am unable to take even a first step forward. Let $G$ be a finite group whose order is not divisible by $3$.Suppose that $(ab)^3=a^3b^3\ \ $ $\forall\  \ a,b\in G$. I am to prove that $G$ must be an abelian group. Please help.","['finite-groups', 'abelian-groups', 'group-theory']"
1782377,Show $\nabla^2g=-f$,"Let a continuous function $f(x,y,z)$ have first order partial derivatives $f_x,f_y,f_z$ exist at every point and the function and all its first order partial derivatives are absolutely integrable.
If for $x',y',z' \in R$ there is a non negative integrable function $h(x',y',z')$ such that for some measurable set $A \subset R^3$ with finite Lebesegue outer measure: $|f_x(x+x',y',z')|< h(x',y',z')$ almost everywhere in $A$ for some $m-\epsilon<x<m+\epsilon$ $|f_y(x',y+y',z')|< h(x',y',z')$ almost everywhere in $A$ for some $m-\epsilon<y<m+\epsilon$ $|f_z(x',y',z+z') |< h(x',y',z')$ almost everywhere in $A$ for some $m-\epsilon<z<m+\epsilon$ $ r'=\sqrt{|x-x'|^2+|y-y'|^2+|z-z'|^2}$ let: $$g(x,y,z)=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \frac {f(x',y',z')}{4\pi r'}dx'dy'dz',\ \ \text{s.t.}\ \ \nabla^2g= \frac {\partial^2g}{\partial x^2}+\frac {\partial^2g}{\partial y^2}+\frac {\partial^2g}{\partial z^2}$$ How to show that $\nabla^2g=-f$ ?","['real-analysis', 'poissons-equation', 'partial-differential-equations', 'proof-writing', 'ordinary-differential-equations']"
1782380,What applications does abstract algebra and algebraic geometry have in computer science and programming? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 8 years ago . The community reviewed whether to reopen this question 2 years ago and left it closed: Original close reason(s) were not resolved Improve this question I love math and programming. Abstract Algebra and algebraic geometry seems very pleasant to me. But I also would like to improve my skills as a programmer, but I would love to do so in the fiels that very related to 'real' math (combine my two passions). We also have a very strong algebraic school where I live, so it would be great to learn from those professors. But, as I've mentioned already, I would love to apply this to elaborate programming. So what fiels can I chose?","['abstract-algebra', 'soft-question', 'algebraic-geometry']"
1782383,How to prove the sum of combination is equal to $2^n - 1$,"One of the algorithm I learnt involve these steps: $1$. define a set $S$ of $n$ elements $2$. form a subset $S'$ of $k$ choice from $n$ elements of the set $S$ ($k$ starts with $1$), which is effectively the combination of $n$ choose $k$: $\frac{n!}{k!(n-k)!}$ $3$. repeat until $k = n$ So for example: $n=5, s = \{A,B,C,D,E\}$ 1st round: {A},{B},{C},{D},{E}

(k=1 => n!/k!(n-k)! = 5 outcomes) 2nd round: {A,B}, {A,C}, {A,D}, {A,E}, 
{B,C}, {B,D}, {B,E}
{C,D}, {C,E}
{D,E}

(k = 2 => n!/k!(n-k)! = 10 outcomes) 3rd round: {A,B,C}, {A,B,D}, {A,B,E}
{B,C,D}, {B,C,E}
{C,D,E}, {C,D,A}
{D,E,A}, {D,E,B}

(k = 3 => n!/k!(n-k)! = 10 outcomes) 4th round: {A,B,C,D}, {A,B,C,E}
{B,C,D,E}
{C,D,B,E}
{D,C,A,E}

(k = 4 => n!/k!(n-k)! = 5 outcomes) 5th round: {A,B,C,D,E}

(k = 5 => n!/k!(n-k)! = 1 outcomes) The total outcome $t = 5 + 10 + 10 + 5 + 1 = 31$ Which correspond to the formula $2^n - 1$ (predicted by the algorithm) So I was trying to prove that the sum of this series will result in $2^n - 1$ but did not succeed series s s = n!/1!(n-1)! + n!/2!(n-2)! + ... + n!/(n-2)(n-(n-2))! + n!/(n-1)(n-(n-1))! + n!/n!(n-n)!

    s = n!/1!(n-1)! + n!/2!(n-2)! + ... + n!/(n-2)2! + n!/(n-1)1! + n!/n!

    s = n!/1!(n-1)! + n!/2!(n-2)! + ... + n!/(n-2)2! + n!/(n-1)1! + 1 could we prove the series above = $2^n - 1$?
Or am I on the wrong side of the road?","['combinations', 'factorial', 'summation', 'sequences-and-series', 'exponentiation']"
1782432,How to prove that $\sum_{i=0}^n 2^i\binom{2n-i}{n} = 4^n$.,"So I've been struggling with this sum for some time and I just can't figure it out. I tried proving by induction that if the sum above is a $S_n$ then $S_{n+1} = 4S_n$, but I didn't really succeed so here I am. Thanks in advance.","['combinatorics', 'summation', 'binomial-coefficients', 'induction']"
1782444,An example calculated in Principles of Algebraic Geometry of Griffiths and Harris'.,"On page 413 they write: Example. We can now make a second computation for Chern classes of projective space. Let $X_0, \ldots , X_n$ be linear coordinates on $\mathbb{C}^{n+1}$, and let $\mathfrak{E}$ and $\pi_*$ be as in the Euler sequence above. Let $A=(\alpha_{ij})$ be an $(n+1)\times (n+1)$ matrix all of whose minors are distinct and nonzero, and consider the vector fields: $v_i = \mathfrak{E} (\alpha_{i0} X_0 , \ldots , \alpha_{in}X_n) = \pi_* \sum_j \alpha_{ij} X_i \frac{\partial}{\partial X_j}$. They write that: ... we see that $v_1$ vanishes at $X\in \mathbb{P}^n$ exactly when $[\alpha_{10}X_0 , \ldots , \alpha_{1n}X_n] = [ X_0 , \ldots , X_n ] $ I do not understand how did they derive the last part, if we write the last identity then $v_1 = \pi_* \lambda \sum_j X_1 \frac{\partial}{\partial X_j}$ where $\lambda \in \mathbb{C}$, how do I see that $v_1$ vanishes from that identity? Thanks in advance.","['projective-space', 'projective-geometry', 'algebraic-geometry']"
1782454,Characteristic function of discret random variable,"I try to show the following: Suppose $(X_n),n\geq1$ is a sequence of random variables with uniform distribution on $\{1/n,\dots,n/n \}$. Show that $(X_n)$ converges in distribution to a random variable $X\sim U(0,1)$ So I try to show that the characteristic function $\Phi_{X_n}(t)\to \Phi_{X}(t)$ which implies convergence in distribution. Since I have a discrete RV the characteristic function looks like this:
$$\Phi_{X_n}(t)=\sum\limits_{k=1}^n e^{itk} P(X_n=k)=\sum\limits_{k=1}^n e^{itk}\frac{1}{n}$$
And the characteristic function of the limit looks like this $$\Phi_{X_n}(t)=\int\limits_{0}^1 e^{itX}\mathrm{d}P=\frac{e^{ibt}-e^{iat}}{i(b-a)t}=\frac{e^{it}-1}{it}$$ Now I have to show that
$$\lim\limits_{n\to\infty}\sum\limits_{k=1}^n e^{itk}\frac{1}{n}=\frac{e^{it}-1}{it}$$ But how can I do this and is this possible with convergence of a discrete measure to a contrinuous..","['characteristic-functions', 'probability-theory', 'probability-distributions', 'probability', 'random-variables']"
1782455,Prove there are 3 points on the circle having same colour [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question All the points of a circle are randomly coloured red or blue. Prove there
  are 3 points on the circle having same colour, representing an
  isosceles triangle.","['contest-math', 'geometry']"
1782463,What is the closed form for $\int_{0}^{\infty}\frac{1}{1+x^2}\cdot\frac{x^{\pi}}{1+x^{\pi}}\cdot\frac{1}{1+x^ e}dx $?,On my previou page Jack D'Aurizio offered a concise elegant prove of Vladimir Reshetnikov's identity and a closed form for it. (1) $$\int_{0}^{\infty}\frac{1}{1+x^2}\cdot\frac{1}{1+x^{\pi}}dx=\int_{0}^{\infty}\frac{1}{1+x^2}\cdot\frac{1}{1+x^{e}}dx=\frac{\pi}{4}$$ Here we have another imitation of Vladimir Reshetnikov's identity (2) $$\int_{0}^{\infty}\frac{1}{1+x^2}\cdot\frac{x^{\pi}}{1+x^{\pi}}\cdot\frac{1}{1+x^e}dx =\int_{0}^{\infty}\frac{1}{1+x^2}\cdot\frac{x^e}{1+x^e}\cdot\frac{1}{1+x^{\pi}}dx$$ A closed form of (2) is unknown We ask if this identity (2) can be proven in the same way as (1) and with a closed form.,['integration']
1782468,Exact vs. conservative,"I'm having trouble understanding definitions. What's the difference between something being exact and being conservative? I understand both involve proving that a potential function $f$ exists such that
$$\vec{F}(x,y,z)=M\hat{i}+N\hat{j}+P\hat{k}=\frac{∂f}{∂x}\hat{i}+\frac{∂f}{∂y}\hat{j}+\frac{∂f}{∂z}\hat{k}$$
but I'm not understanding what makes something exact as opposed to conservative , or vice versa. Is it just that differential equations can be exact and vector fields can be conservative, or is there more to it? EDIT: Fixed a mistake.","['multivariable-calculus', 'differential-geometry']"
1782497,Largest root as exponent goes to $+\infty$,"Let $a\geq 1$ and consider 
$$
x^{a+2}-x^{a+1}-1.
$$
I am interested to see what is the largest root of this polynomial as $a\to +\infty$. In order to find a root, we surely have to have
$$
x^{a+2}-x^{a+1}=x^{a+1}(x-1)=1.
$$ Hence, I guess we have to look for which $x$ we have that
$$
x^{a+1}(x-1)\to 1\text{ as }a\to+\infty.
$$ Intuitively, if $x$ tends to some value larger than $1$ for $a\to\infty$, the whole thing should diverge. On the other side, if $x$ tends to some value smaller than $1$, then the whole expression should converge to $0$. Hence I guess that $x\to 1$ as $a\to\infty$ in order to get a root.","['real-analysis', 'roots']"
1782527,Flawed proof that the closure of a set is closed?,"So I'm reading baby Rudin's third edition and on page 35, he shows a proof that the closure of a set is closed. (I'm not questioning the result, but it seems to me the proof has a mistake and I'm curious if others agree with my statement) Let $X$ be a metric space with the usual topology and $E \subset X$. Now $E'$ is the set of all limit points of $E$. So we want to prove that $C = E' \cup E$ is closed. So here is the provided proof:
If $p \in X$ and $p \notin C$ then $p$ is neither a point of $E$ nor a limit point of $E$. Hence $p$ has a neighborhood which does not intersect $E$. The complement of $C$ is therefore open. Hence $C$ is closed. The problem I have with the above proof is this: What if every neighborhood of $p$ contains a point of $E'$ but not $E$? I see no statement in the proof which would exclude this possibility. Then the complement of $C$ is not open and so $C$ is not closed. In other words, the proof seems to be based on the assumption that $(E^c)^c=C$ which is not necessarily true. Again, to clarify, I'm not claiming the above is possible. I'm just trying to understand if my objection to the proof (not the theorem) is correct.","['general-topology', 'proof-verification', 'proof-explanation']"
1782533,"Given $\lim_{x \to 0} \frac{f(x)}{x} = 1$, find $f(0)$","This is a question taken out of one of MIT's Single Variable Calculus Exams in 2010 (Obtained via OCW) Problem : Find $f(0)$, given that $ f $ is continuous at $ x=0$ and $$\lim_{x \to 0} \frac{f(x)}{x} = 1$$ Solution: The official solution to this problem is quoted verbatim below : Since $\lim_{x \to 0} \frac{f(x)}{x} = 1$, $f(x) \to 0$ as $x \to 0$, so $f(0)=0$ However what this solution has done (at least to me it seems this way), is simply, directly substitute $x=0$, into $\frac{f(x)}{x}$, and then solve for $f(0)$, but the way in which it is done, doesn't seem very rigorous (at least to me it doesn't). This is essentially what the solution has done (at least it seems this way to me) \begin{aligned}
       & \lim_{x \to 0}\ \frac{f(x)}{x} = 1 \\
       & \implies \frac{f(0)}{0} = 1 & \text{(By direct substitution)} \\
& \implies f(0) = 0 \cdot 1 & \text{(Can we even do this?)}\\
       & \implies f(0) = 0\\ 
     \end{aligned} But is what is being done in the second and third steps even correct? I ask this because we have a denominator of $0$ on one side of the equation, and technically having $0$ as the denominator in one of the terms of an equation, makes the equation undefined, am I correct in saying this? Essentially my question boils down to the fact that division by $0$ is undefined, and I am asking whether algebraically manipulating an equation that has one term, with a denominator of $0$, is mathematically valid or not, and whether this is seen as a rigorous solution to the posed problem.","['proof-verification', 'real-analysis', 'calculus', 'limits']"
1782575,"Let $A,B,C$ be $n \times n$ square real matrices with $ABC=0$. What is the maximum rank of $CBA$?","Let $A,B,C$ be $n \times n$ square real matrices with $ABC=0$. What is the maximum rank of $CBA$? From an old written examination . I've looked at the kernel and range of each matrix for simple cases (like if $n=2$), but how can we generalize to any $n$?",['linear-algebra']
1782578,How can I verify logical equivalence without using Truth Table?,"I have an assignment and I need to prove the following logical equivalence using Laws of Logic and not using Truth Table: p → q ≡ ~q → ~p LAWS OF LOGIC: 1.Commutative Law: p ↔ q ≡ q ↔ p 2.Implication Laws: p →q ≡ ~p ∨ q
≡ ~(p ∧ ~q) 3.Exportation Law: (p ∧ q)→r ≡ p →(q →r) 4.Equivalence: p ↔ q ≡ (p →q)∧(q →p) 5.Reductio ad absurdum p →q ≡ (p ∧ ~q) →c Kindly help me solving it, need to present it in 24 hours. Thanks all",['discrete-mathematics']
1782580,Sample median of sample from uniform distribution.,"I'm trying to determine the distribution of the sample median of a sample of size $n$ from the uniform distribution (on the interval $(0,1)$). If $n$ is odd and $m=(n+1)/2$, then the sample median is just one of the order statistics and it has a beta distribution whose both parameters are $m$. But I am having some problems finding its distribution when the size of the sample is even. I proceeded in the obvious way: given a sample from a population with density $f$ and distribution $F$, the joint distribution of the order statistics $(X_{(j)},X_{(k)})$, $1\leq j<k\leq n$ is
$$
f_{X_{(j)},X_{(k)}}(x,y)=\frac{n!}{(j-1)!(k-j-1)!(n-k)!}[F(x)]^{j-1}[F(y)-F(x)]^{k-1-j}[1-F(y)]^{n-k}f(x)f(y),
$$
where $x<y$. If $m=n/2$, the sample median is given by $(X_{(m)},X_{(m+1)})/2$, and using the above formula, the density of the sample median must be given by
$$
g(z)=2\int_{-\infty}^{\infty}f_{X_{(m)},X_{(m+1)}}(2z-x,x)dx\\
=\frac{2n!}{(m-1)!^2}\int_{-\infty}^{\infty}(2z-x)^{m-1}(1-x)^{m-1}1_{(0,1)}(2z-x)1_{(0,1)}(x)1_{(0,x)}(2z-x)dx
$$
And, after some simplifications, I arrive to the following formula
$$
g(z)=\frac{2n!}{m(m-1)!^2}\Big(\frac{(1-z)^m}{2z-1}(z^m-(1-z)^m)\\-\frac{(1-\min{(1,2z)})^m}{2z-1}((2z-\min{(1,2z)})^m-(1-\min{(1,2z)})^m)\Big)1_{(0,1)}(z)
$$
But for $n=4$ this function integrates to 5, which clearly is not possible. I have checked this procedure twice and I keep getting the same formula. In my computations, I found that $1_{(0,1)}(2z-x)1_{(0,1)}(x)1_{(0,x)}(2z-x)=1_{(0,1)}(z)1_{(z,\min{(1,2z)})}(x)$ and I think this may be where I'm wrong, since everything else is just standard integration. Thanks for any any help in advance.","['statistics', 'probability']"
1782589,"Preimage of $[0,1]$ under $f:\mathbb{C}\rightarrow\mathbb{C}, z\mapsto \frac{-27(1+\frac{1}{x^{3}-3})^{2}}{x^{3}-3}$","I want to find
$$
f^{-1}([0,1])
$$
where
$$f:\mathbb{C}\rightarrow\mathbb{C}, z\mapsto \frac{-27(1+\frac{1}{x^{3}-3})^{2}}{x^{3}-3}.$$
I have to do this in order to find a dessins d'enfant associated to certain Riemann Surface, but I find very difficult to deal with this map.","['riemann-surfaces', 'complex-analysis', 'functions']"
1782600,"When A and B are of different order given the $\det(AB)$,then calculate $\det(BA)$","Let 'A' be a $2 \times 3$ matrix where as B be a $3 \times 2$ matrix if $\det(AB) = 4$ the find value of the $\det(BA)$ My attempt: I took A = 
$$
        \begin{bmatrix}
        2 & 0  &0\\
        0 & 0  &2\\
        \end{bmatrix}
$$ B=
$$
        \begin{bmatrix}
        1 & 0  \\
        0 & 0  \\
        0 & 1  \\
        \end{bmatrix}
$$ It satisfies given condition and I get $\det(BA)=0$ But I have not proved it How do I prove that it is always zero (background)I am 12th grader and I know about adjoint,inverse,determinant,rank of a matrix and the other basics. 
However I do NOT know about eigenvalues and eigenvectors.","['matrices', 'inverse', 'determinant']"
1782615,"Extremum of $f (x,y) := x^2+y^2$ subject to the equality constraint $x+y=3$","I had to find the extremum of $z=x^2+y^2$ subject to the constraint $x+y=3$. I used Lagrange multipliers to reach the conclusion that $(1.5,1.5)$ is an extremum point, but had no way of determining whether it's a maximum or a minimum (we did not study the Sylvester criteria). Regardless, intuitively, the most symmetric sum usually gives the largest result, and this is what I used as a justification for the point being a maximum. This is, of course, hardly a mathematical way of showing the correctness of a statement, which is why I ask here what way there is to show it's a maximum in a correct well defined orderly fashion?","['multivariable-calculus', 'lagrange-multiplier', 'calculus']"
1782686,Partial Derivative with product & chain rule,"I cannot for the life of me work out the answer to this partial derivative. $$\frac{\delta}{\delta x}\left(\frac{x^2}{(x+y)^2(x+z)^2}\right) $$ My first thought was: Split into two equations: $$\frac{\delta}{\delta x}\left(\frac{x}{(x+y)^2}\cdot \frac{x}{(x+z)^2}\right)$$ Apply chain rule to each side which gives me: $$\frac{1}{(x+y)^2}-\frac{2x}{(x+y)^3}$$ and $$ \frac{1}{(x+z)^2}-\frac{2x}{(x+z)^3} $$ I then try to use the product rule, so: $$ \left\lbrack\left(\frac{1}{(x+y)^2}-\frac{2x}{(x+y)^3}\right)\cdot \frac{x}{(x+z)^2}\right\rbrack + \left\lbrack\left(\frac{1}{(x+z)^2}-\frac{2x}{(x+z)^3}\right)\cdot \frac{x}{(x+y)^2}\right\rbrack $$ However I don't end up anywhere near an answer, let alone the right answer. Apparently the answer is: $$ -\frac{2(x^3-xyz)}{(x+y)^3(x+z)^3} $$ Is there an easier way to do this?","['derivatives', 'partial-derivative']"
1782695,Asymptotic analysis references,"I'm self studying asymptotic analysis with Bruijn (1981) - Asymptotic Methods in Analysis Bleistein and Handelsman (1986) - Asymptotic Expansions of Integrals but the texts are terse, without too many examples, and the exercises don't have solutions. Could you please recommend texts on the same topic that are perhaps a bit easier and/or come with solutions for exercises? I'm reading these so that I can understand better Laplace transforms and saddlepoint methods. I took real analysis, functional analysis and complex analysis as an undergrad and can fill in some gaps if necessary.","['complex-analysis', 'real-analysis', 'asymptotics', 'reference-request']"
1782698,How can we prove that the space of trace class operators on a Hilbert space $H$ is the closure of $H\otimes H$ with respect to the trace norm?,"Let $(H,\langle\;\cdot\;,\;\cdot\;\rangle)$ be a separable Hilbert space over $\mathbb R$ $\mathfrak L^1(H)$ be the space of trace class operators on $H$ and $$\operatorname{tr}L:=\sum_{n\in\mathbb N}\langle Le_n,e_n\rangle\;\;\;\text{for }L\in\mathfrak L^1(H)$$ for some orthonormal basis $(e_n)_{n\in\mathbb N}$ of $H$ As you know, $\operatorname{tr}L$ is called the trace of $L\in\mathfrak L(H)$ and its value is finite and independent of the choice of $(e_n)_{n\in\mathbb N}$. I've read that the closure of the tensor product $H\otimes H$ with respect to the trace norm $$\operatorname{tr}|L|:=\sum_{n\in\mathbb N}\langle\left(L^\ast L\right)^{\frac 12}e_n,e_n\rangle\;\;\;\text{for }L\in\mathfrak L^1(H)$$ equals $\mathfrak L^1(H)$. How can we prove this statement rigorously? I suppose there is some identification going on here, cause otherwise it wouldn't make much sense to talk about the trace norm of a tensor.","['functional-analysis', 'trace', 'operator-theory', 'hilbert-spaces']"
1782702,A non-Hausdorff space with unique limit,"Can I find a topological space $X$ such that every convergent sequence in $X$ has a unique limit in $X$, but $X$ is not Hausdorff?",['general-topology']
1782723,Give an example of a real function so that every rational is a strict local minimum,"Give an example of $f : \mathbb R → [0, \infty) $ so that every $r \in \mathbb Q$ is
  a strict local minimum for $f$. Strict local minimum means there is a vicinity $V$ of $r$ such that $f(y) > f(r) ,\ \forall y \in V-\{r\}$ My attempt So far, none. My feeling is there isn't such a function, mainly because of the density of $\mathbb Q$ in $\mathbb R$. Suppose I define $f$ like this: $f(x) = 0$ for $x \in \mathbb Q$ and $f(x) = 1$ for $x \not \in \mathbb Q$. Every rational $r$ does not map to a strict local minimum for $f$ only because of the other rationals present in every vicinity of $r$. So $f$ cannot be constant on $\mathbb Q$, but how to define it is beyond my imagination.","['functional-analysis', 'contest-math']"
1782724,Find a generating function for the number of strings,"The string $AAABBAAABB$ is a string of ten letters, each of which is $A$ or $B$, that does include the consecutive letters $ABBA$. Determine, with justification, the total number of strings of ten letters, each of which is $A$ or $B$, that do not include the consecutive letters $ABBA$. The conventional way of using casework is too simply and gives the right answer indeed but I am interested in getting the generating function. The generating function is $$F(x) = \left(1 - 2x + \frac{x^4}{1 + x^3}\right)^{-1}$$ which the coefficient of $x^{10}$ does give the right answer, but I am not sure how to get there. How do I start?","['generating-functions', 'combinatorics']"
1782731,Evaluation of $\sum_{n=1}^\infty \frac{(-1)^{n-1}\eta(n)}{n} $ without using the Wallis Product,"In THIS ANSWER , I showed that $$2\sum_{s=1}^{\infty}\frac{1-\beta(2s+1)}{2s+1}=\ln\left(\frac{\pi}{2}\right)-2+\frac{\pi}{2}$$ where $\beta(s)=\sum_{n=0}^\infty \frac{(-1)^n}{(2n+1)^s}$ is the Dirichlet Beta Function . In the development, it was noted that $$\begin{align}
\sum_{n=1}^\infty(-1)^{n-1}\log\left(\frac{n+1}{n}\right)&=\log\left(\frac21\cdot \frac23\cdot \frac43\cdot \frac45\cdots\right)\\\\
&=\log\left(\prod_{n=1}^\infty \frac{2n}{2n-1}\frac{2n}{2n+1}\right)\\\\
&=\log\left(\frac{\pi}{2}\right) \tag 1
\end{align}$$ where I used Wallis's Product for $\pi/2$. If instead of that approach, I had used the Taylor series for the logarithm function, then the analysis would have led to $$\sum_{n=1}^\infty(-1)^{n-1}\log\left(\frac{n+1}{n}\right)=\sum_{n=1}^\infty \frac{(-1)^{n-1}\eta(n)}{n} \tag 2$$ where $\eta(s)=\sum_{n=1}^\infty \frac{(-1)^{n-1}}{n^s}$ is the Dirichlet eta function. Given the series on the right-hand side of $(2)$ as a starting point, it is evident that we could simply reverse steps and arrive at $(1)$. But, what are some other distinct ways that one can take to evaluate the right-hand side of $(2)$? For example, one might try to use the integral representation $$\eta(s)=\frac{1}{\Gamma(s)}\int_0^\infty \frac{x^{s-1}}{1+e^x}\,dx$$ and arrive at $$\sum_{n=1}^\infty \frac{(-1)^{n-1}\eta(n)}{n} =\int_0^\infty \frac{1-e^{-x}}{x(1+e^x)}\,dx =\int_1^\infty \frac{x-1}{x^2(x+1)\log(x)}\,dx \tag 3$$ Yet, neither of these integrals is trivial to evaluate (without reversing the preceding steps). And what are some other ways to handle the integrals in $(3)$?","['real-analysis', 'definite-integrals', 'sequences-and-series']"
1782736,A smooth nowhere analytic function such that all derivatives are monotone,"Related questions that might provide some context: (1) (2) (3) (4) Let's restrict our attention to real-valued functions on an open unit interval $f:(0,1)\to\mathbb R$.
There are examples $\!^{[1]}$ $\!^{[2]}$ of smooth (class $C^\infty$) functions that are nowhere real-analytic . Is there a smooth nowhere analytic function such that the function itself and its derivatives of any order are monotone ?","['real-analysis', 'examples-counterexamples', 'monotone-functions', 'continuity', 'analyticity']"
1782772,"If A can either increase by 100% or decrease by 50% with equal probability, what will be the arithmetic mean return over n periods?","This is more of a finance related question but deals with some discrete probability and or combinations.  The question goes like this.  If you buy stock A, and it has a 50% chance of going up 100% in a period, or 50% chance of going down 50%, what is the arithmetic mean return over n periods? Some people are saying the answer is 25%.  But, I don't see how that works out beyond 1 period.  For illustration, consider all possible combination of returns over 1 and 2 periods.  One has the following, one period: 1 , 2 1 , 0.5 two periods: 1 , 2 , 1 1 , 0.5, 1 1 , 2 , 4 1 , 0.5 , 0.25 The total and arithmetic mean returns for each scenario are one period: 100%     100% -50%     -50% two periods: 0%         0% 0%         0% 300%     150% -75%   -37.5% So, averaging the first periods mean arithmetic returns, one gets 25%.  But, for two periods, averaging the mean arithmetic returns one gets a bit over 28%.  Maybe I'm not understanding the definitions of arithmetic returns, but can anyone here tell me what I'm doing wrong?  Hopefully someone has some finance knowledge and understands how to calculate arithmetic mean returns.","['finance', 'probability']"
1782781,Why not every integral is zero?,"if we start axioming area to be a mapping from a collection of points on a plane to the set of real numbers, this is: 
                                a: M → R
                                   S↦a(S), where S is the set of points as aforementioned and M is the collection of sets S (measurable sets..) . Stating the following axioms: (i) a(S) is non negative for every S (ii) if S and T are elements of M then S∪T and S∩T are also member of M and:
a(S∪T) = a(S) + a(T) - a(S∩T) (iii) Every retangule R is member of M and if h and k are sides of R then a(R)= k.h --> Finaly, with thiss if we want to measure a area of anything, namely a retangule, we need to define the set of all point that compose this thing, so for example if we integrate the area of retangule with sides h and k we define the set A={(x,y):(0≤x≤h ^ 0≤y≤k)} what by the axioms: a(A)=h.k but if we think that A as union of lines horizontal or vertical for example A being the reunion of all lines C={(x,t):0≤x≤h} where t obey 0≤t≤k and is diferent for each line, but thnking in this way lead us that a(A) is equal to the sum of all areas a(C) for all lines that compose A, but each area a(C) is equal to zero with implies that a(A)=0 what is clearly absurd! My question is where is the failure in this procedure?","['integration', 'calculus']"
1782811,"Let $(X_i)$ be i.i.d. exponential, is the set $\{X_1,X_2,\ldots\}$ almost surely dense in $(0,\infty)$?","To be clear, I'm asking if the range of the random sequence $(X_i)$ is dense in $(0,\infty)$ a.s. I thinks the answer is yes, because for any $0<a<b<\infty$, we have $$P(X_1 \notin (a,b), ..., X_n \notin (a,b)) = \alpha_{a,b}^n $$ for some $\alpha_{a,b}<1$, and this tends to zero as $n$ goes to infinity.","['probability-theory', 'random-variables']"
