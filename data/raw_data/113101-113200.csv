question_id,title,body,tags
1644022,Action via automorphism,"I want to ask what does it mean to say a group $A$ acts on $N$ via automorphisms . It is a notion used in M.Isaacs book and I am not familiar with. I tried to find how it is defined but a scanned e book is so hard to go through. Suppose $*: A\times N \to N$ is a group action of $A$ on $N$, thus we have homomorphism $\phi: A \to S_N$. Now what does action via automorphism mean. Thanks!","['finite-groups', 'group-theory']"
1644033,Number of solutions in a field of order $32$ [duplicate],"This question already has answers here : Number of solutions for the given equation in finite field of order 32. (2 answers) Closed 8 years ago . Let $F$ be a field of order $32$. Then find the number of non-zero solutions $(a,b)\in F\times F$ of the equation $x^2+xy+y^2=0$. As , $|F|=32$ , so $(F\setminus\{0\},.)$ forms a group of order $31$, which is prime. So , $F\setminus \{0\}\simeq\mathbb Z_{31}$. Then how I proceed ?","['finite-fields', 'abstract-algebra', 'field-theory']"
1644041,Familiar spaces in which every one point set is $G_\delta$ but space is not first countable,"In an exercise from Munkres-Topology Article 30 the author writes that there is a very familiar space which is NOT first countable but every point is a $G_\delta $ set. What is it? Though there are answers posted on this site to the above question, I don't find the spaces familiar to what has been taught in the book up to Article-30 I am not able to find examples either. Is any help possible on familiar examples?","['general-topology', 'examples-counterexamples', 'first-countable']"
1644044,"If $\sum\limits_n \sqrt{\mathrm{Var}(X_n)}$ converges, then $\sum\limits_n (X_n - E[X_n])$ converges in $L^2$","I have seen in a paper to claim the following: If $\sum\limits_n \sqrt{\mathrm{Var}(X_n)} < \infty$, then $\sum\limits_n (X_n - E[X_n])$ converges in $L^2$, for any sequence of random variables $\{X_n\}$. As $\{X_n\}$ need not be independent, there will be covariance term, not understanding how is it possible ? What about a.s. convergence?","['probability-theory', 'sequences-and-series']"
1644079,An irreducible polynomial in a subfield of $\mathbb{C}$ has no multiple roots in $\mathbb{C}$,"Let $K\subset \mathbb{C}$ be a subfield and $f\in K[t]$ an irreducible polynomial. Show that $f$ has no multiple roots in $\mathbb{C}$. If I understand this question correctly, I must show that there is no $a \in \mathbb{C}$ such that $(t-a)^n|f$ in $F[t]$ with $n>1$. So suppose $(t-a)^2|f$ and $f=(t-a)^2h$. Then we have $f'=2(t-a)h+(t-a)^2h' \Rightarrow (t-a)|f'$ so $\gcd(f,f'$) is not constant. Therefore $f$ is divisible by some square of non-constant polynomial in $F[t]$, which is a contradiction. Is my argument correct? Thank you.","['abstract-algebra', 'ring-theory']"
1644084,Probability theory with the hyperreals?,"Forgive the undoubted ignorance of this question. I am out of my element both in probability and in nonstandard analysis. A mathematically curious layperson friend recently had a conversation with me where he wanted a notion of ""pick a random integer"" (meaning uniformly random). I told him that there isn't room for this idea in the theory of probability as developed from the Kolmogorov axioms, because a countable probability space can't have atoms of equal probability, because $\sum 0 = 0$, but $\sum \alpha = \infty > 1$ for $\alpha >0$ by the archimedean principle. He asked, why couldn't the probability of picking an individual integer be $1/\infty$? ""I know infinity isn't a number but in this context it feels like it could be,"" he said. If you want $\infty$ and $1/\infty$ to be numbers, well, this is what nonstandard analysis was made for, right? So, my question is this: Has anybody tried to formulate probability theory with probabilities in a field of hyperreal numbers rather than in $\mathbb{R}$? If so, what issues come up? Does the theory have significant differences with the standard theory or does this notion not really change anything substantive? Basically, what was the outcome? If this has been done, I would be most interested in a sort of executive summary, but I would also accept a reference. Thanks in advance. Addendum: Just found this related question at MO.","['nonstandard-analysis', 'reference-request', 'probability-theory']"
1644089,How to Identify a Quotient of a Given Free Group,"$\newcommand{\Z}{\mathbf Z}$ Problem. Let $G$ be the free group generated by three symbols $a, b$ and $c$, and let denote $G$ by writing $F(a, b, c)$. Let $N$ be the normal subgroup of $G$ generated by the words $aba^{-1}b^{-1}$ and $cbc^{-1}b^{-1}$. I want to find out what is $F(a, b, c)/N$. I asked this of my friend and he said that his guess is
$$F(a, b, c)/N \cong \Z\times F(x, z)$$
where $F(x, z)$ denotes the free group generated by two symbols $x$ and $z$. I am not sure how he arrived at this guess, but this seemed promising when I considered the homomorphism $F(a, b, c)\to \Z\times F(x, z)$ which satisfies
$$a\mapsto (0, x),\quad b\mapsto (1,\epsilon),\quad c\mapsto (0, z)$$ Here $\epsilon$ is the empty word in $F(x, z)$. This is surjective homomorphism whose kernel $K$ contains $aba^{-1}b^{-1}$ and $cbc^{-1}b^{-1}$. Therefore $K$ contains $N$. So if I could show what $K=N$ then I am done. 
But I cannot see how to show this. How do I proceed?","['group-theory', 'free-groups']"
1644098,Symmetric Matrix with Positive Eigenvalues,"Not all matrix with positive eigenvalues is positive definite, i.e. $\mathbf{x}^\mathsf{T}A\mathbf{x}>0$ for all non zero vector $\mathbf{x}$. For example consider matrix $$A = \begin{bmatrix} 1 & -3 \\ 0 & 1 \end{bmatrix}.$$ How to prove that if we add symmetry into hypothesis then the assertion is true? That is, a symmetric matrix with positive eigenvalues is positive definite.","['matrices', 'linear-algebra']"
1644102,The space of continuous functions on an interval has a countable dense subset and a countable basis,"Give $\Bbb R^I$ the uniform metric, where $I = [0, 1]$. Let $C(I, \Bbb R)$ be the subspace consisting of continuous functions. Show that $C(I, \Bbb R)$ has a countable dense subset, and therefore a countable basis. (Source: Munkres Question 15 Article -30) My try : Consider the set of all polynomials $\mathscr{P}=\{a_0+a_1x+...+a_nx^n:a_i\in \Bbb Q;n\in \Bbb N\}$ on $[0,1]$. By the Weierstrass Approximation Theorem , for every continuous function $f$ there exists a sequence of polynomials $p_n \rightarrow f$ (uniformly).Hence $\scr P$ is dense in $C(I,\Bbb R)$. Also $C(I, \Bbb R)$ is metrizable and hence a countable dense subset and hence has a countable basis. Is my proof correct?","['general-topology', 'second-countable', 'separable-spaces', 'proof-verification']"
1644131,"Algebra of Linear differential operators, question on Commutativity and Association","The following is a discussion on the following second differential equation $$  \frac{dy^2}{dx} - y = 0 $$ So, let us introduce the following, convention and definition, represent the derivative operator by $$ D = \frac{d}{dx} $$ So that our first equation can be represented as $$ \left( D^2 - 1 \right) y(x) = 0 $$ My professor discussed on the idea, on ""factoring"" (The space on which the derivative acts?) the operators, his discussion lead to the apparent nonuniqueness of factoring as either $$ (D - \tanh(x))(D + \tanh(x)) y = 0 \quad \textrm{and } \quad (D - 1)(D + 1) = 0 $$ My first question is that how is that  $ (D - \tanh(x))(D + \tanh(x))  ``="" (D^2 - 1) $ and how is unfoiled?, because I think is not commutative because $$ f(x)\frac{d}{dx}y \neq \frac{d}{dx}f(x)y(x) $$ One is first derive something and multiply by $f$, and the other is derive the product. Second, my professor move to the general $$ y'' + a(x)y' + b(x) = 0 $$ or $$ \big(D^2 + a(x)D + b(x)\big)y(x) = 0 $$ and he wants to factor the above as $$ \big( D + A(x)\big)\big(D + B(x)\big)y(x) = 0 $$ So then he unfoils the above equation as: $$ \big( D^2 + AD + AB + B' + BD \big)y = 0 $$ and he argues that the terms $B'$ and $BD$ comes from the fact that either we take the derivative of $B$ or take the derivative and multiply by B (Why that doesn't apply to the terms $ AD  $ and we should add $ A'$ ? Also, do you happen to know where to find reference on solving ODEs by this approach? Thanks","['derivatives', 'ordinary-differential-equations', 'linear-algebra', 'operator-theory']"
1644165,"If X and Z are independent and Y and Z are independent random variables, is cov(XY, Z) = 0?","Let $X$, $Y,$ and $Z$ be random variables. (There are no restrictions on these variables, but you may assume that these are continuous random variables if you want.) Suppose that $X$ and $Z$ are independent, and also suppose that $Y$ and $Z$ are independent. Does it follow that $\mathrm{cov}(XY,Z)=0$? (I understand that $XY$ and $Z$ may not be independent, but this does not rule out the zero covariance.) Under the assumption that $X$ and $Z$ are independent and that $Y$ and $Z$ are independent, I am able to show that $$\mathrm{cov}(X,YZ) = \mathrm{cov}(Y,XZ) = \mathrm{cov}(XY,Z) + \mathrm{E}[Z]\cdot \mathrm{cov}(X,Y).$$ Showing this is fairly straightforward: $\mathrm{cov}(XY,Z)=\mathrm{E}[XYZ]-\mathrm{E}[XY]\cdot\mathrm{E}[Z]$; in addition, $\mathrm{cov}(X,YZ)=\mathrm{E}[XYZ]-\mathrm{E}[X]\cdot\mathrm{E}[YZ]=\mathrm{E}[XYZ]-\mathrm{E}[X]\cdot\mathrm{E}[Y]\cdot\mathrm{E}[Z]$, implying that $\mathrm{cov}(X,YZ)=\mathrm{cov}(XY,Z)+\mathrm{E}[XY]\cdot\mathrm{E}[Z]-\mathrm{E}[X]\cdot\mathrm{E}[Y]\cdot\mathrm{E}[Z]$, which is obviously equal to $\mathrm{cov}(XY,Z) + \mathrm{E}[Z]\cdot\mathrm{cov}(X,Y).$ And, of course, $\mathrm{cov}(X,YZ) = \mathrm{E}[XYZ]-\mathrm{E}[X]\cdot\mathrm{E}[Y]\cdot\mathrm{E}[Z]= \mathrm{cov}(Y,XZ)$, proving the above result. However, to proceed further, my intuition tells me that $\mathrm{cov}(XY,Z) = 0$ and thus that $\mathrm{cov}(X,YZ) = \mathrm{cov}(Y,XZ) = \mathrm{E}[Z]\cdot\mathrm{cov}(X,Y)$. Am I wrong in thinking that $\mathrm{cov}(XY,Z) = 0$? But if it is true that $\mathrm{cov}(XY,Z) = 0$, is there a simple proof that does not possibly involve measure theory? Thanks.","['statistics', 'probability']"
1644202,Show that $f_{n}^2(x)$ does not converge in $D^1({\Omega})$,"Let $$ f_n(x) = \left\{ \begin{array}{ll}
         n & \mbox{if $0 \lt x \lt \frac{1}{n}$};\\
        0 & \mbox{otherwise}.\end{array} \right. \ $$ I have to show that $\lim_{n \to \infty}f_n(x)$ exists in terms of distributions $\lim_{n \to \infty}f_n^2(x)$ doesn't exist in terms of distributions. $\lim_{n \to \infty}(f_n^2(x)-n\delta)$  exists in terms of distributions For $(1)$
$$n\int_{0}^{\frac{1}{n}}\phi(x) dx \to \phi(0) , \text{for},  n \to \infty$$ For $(2)$
$$n^2\int_{0}^{\frac{1}{n}}\phi(x) dx $$ Now there exists a $C^{\infty}$ cut off function such that $\phi(x) =1$ for $x \in (0,\frac{1}{n+1})$ and $\phi(x)=0, x \gt \frac{1}{n}$. For this particular choice of $\phi$ this integral goes to $\infty$. For $(3)$ This will be 
$$\int_{-n}^{\frac{1}{n}} -(n\delta)\phi(x) dx +(n^2-n\delta)\int_{0}^{\frac{1}{n}}\phi(x) dx+\int_{\frac{1}{n}}^{n} -(n\delta)\phi(x) dx $$ I am unable to see where this would converge. Thanks for the help!!","['functional-analysis', 'distribution-theory', 'limits']"
1644208,"If $y'+y=|x|$ and $y(-1)=0$, what is $y(1)$?","If $y'+y=|x|$ and $y(-1)=0$, what is $y(1)$? I calculated the integrating factor to be $e^x$. Then $e^x y'+ e^x y=e^x |x|$ hence $\frac {d(e^x y)}{dx}=e^x |x|$ hence $d(e^x y)=e^x|x|dx $ Integrating both sides, $e^xy=e^x \int |x|dx- \int [(\int |x|dx)(e^x)]dx +c.$ From here how to proceed? Can I write $\int |x|dx=-2 \int xdx, x \lt 0$? Then I will get the constant $c$ by using $y(-1)=0$. But how will it help me to calculate $y(1)$?","['problem-solving', 'indefinite-integrals', 'integration', 'boundary-value-problem', 'ordinary-differential-equations']"
1644214,Separation and Russell's paradox,"I just want to be sure that I understand the connection between ""Naive Comprehension"", the Axiom of Separation, Russell's Paradox, and the existence of a universal set.  Is the following correct? The Naive Comprehension Axiom has as an instance the following:
$$
\exists y\forall z(z\in y\leftrightarrow z\notin z)
$$
This entails: y is an element of y just in case y is not an element of y
(where ""just in case"" means ""iff"") which is a contradiction. By contrast, the Axiom of Separation has as an instance the following: $$
\forall x\exists y\forall z(z\in y\leftrightarrow (z\in x\land z\notin z)).
$$ The assumption that y is an element of y leads to contradiction.  But the assumption that y is not an element of y just entails that y is not an element of x.  So, we have shown that for every set, y, there is another not in it -- namely, y itself.  That is, there is no universal set. Is this correct?",['elementary-set-theory']
1644218,SLLN when the expectation in infinite,"In a Post I found it says: Whenever ${\rm E}(X)$ exists (finite or infinite), the strong law of large numbers holds. That is, if $X_1,X_2,\ldots$ is a sequence of i.i.d. random variables with finite or infinite expectation, letting $S_n = X_1+\cdots + X_n$, it holds $n^{-1}S_n \to {\rm E}(X_1)$ almost surely. The infinite expectation case follows from the finite case by the monotone convergence theorem. Can someone give a reference/answer to this question?
I want to prove that: If $EX^{+}_{k}=∞  $ and $EX^{-}_{k}<∞ $ then $n^{−1}S_{n}→∞$ a.s.","['law-of-large-numbers', 'probability-theory', 'expected-value']"
1644242,Preserving independence of random variables,"Suppose I have three random variables, $X,Y,Z$ with $X$ independent of $Z$, $Y$ independent of $Z$. Which transformation can I apply to $X,Y$ to that the result is again a random variable independent of $Z$? Or better, for which $f(x,y)$ is $f(X,Y)$ independent of $Z$? For example $f(x,y) = xy$ does not work because in general $XY$ is not independent of $Z$. Is there a general result?","['independence', 'probability-theory', 'probability', 'random-variables']"
1644264,Why is Laplace Transform used for ODEs,"This part is taken from differential equations with applications and historical George simmons. According to the given information , there are another integral transformation.I wonder why is the Laplace transform ($a=0 , b=\infty , K(p,x)=e^{-px}$) begin used for solving ODEs.Are there any advantages or other particular reasons for using this combination ?","['ordinary-differential-equations', 'laplace-transform']"
1644282,Taking derivative of energy of wave equation,"Consider the variable coefficient, real valued wave equation $$ u_{tt} - \nabla \cdot (c^2 \nabla u) + qu = 0, \quad u(x,0) = \phi(x), \quad u_t(x, 0) = \phi(x), $$
where $c, q \geq 0$ depend only on $x$. Then we define the total energy at time $f$ of a $C^2$ solution $u$ as $$ E(t) = \frac{1}{2}\int_\Omega (u_t^2 + c(x)^2|\nabla u|^2 + q(x)u^2) \, dx. $$ The goal is to show that the total energy is constant given some boundary conditions. To do this, we differentiate $E$ with respect to $t$, but I have some questions about the presented derivation. The notes I'm following claim that $$ \frac{dE}{dt}(t) = \frac{1}{2}\int_\Omega (u_tu_{tt} + c(x)^2 \nabla u \cdot \nabla u_t + q(x)uu_t)\, dx. $$ However, my calculations have that, e.g.: $$ \frac{d}{dt} u_t^2 = 2\left(\frac{d}{dt}u_t\right)\left(\frac{d}{dt}u\right) = 2u_{tt}u_t.$$ Where does the extra factor of $2$ appear in my derivation? With the $\nabla$ term, I'm having even more trouble recovering the solution's expression. I expand as: $
\begin{align*}
\frac{\partial}{\partial t}|\nabla u|^2 &= \frac{\partial}{\partial t}\left(\sum_{i=1}^n\left(\frac{\partial u}{\partial x_i}\right)^2 + \left(\frac{\partial u}{\partial t}\right)^2\right)\\
&= \sum_{i=1}^n 2\frac{\partial^2 u}{\partial t \partial x_i} \frac{\partial u}{\partial t} + 2 \frac{\partial^2 u}{\partial^2 t}\frac{\partial u}{\partial t} \\
\end{align*}
$ which isn't the form in the notes. Any guidance in how the notes get their final expression would be much appreciated.","['multivariable-calculus', 'wave-equation', 'partial-differential-equations']"
1644285,Proof of the existence of a reversible stationary distribution,"$p$ is a finite Markov chain where $p(i,j)>0$ for all $i,j$. Prove a reversible stationary distribution exists for $p$ if $p(i,j)p(j,k)p(k,i)=p(i,k)p(k,j)p(j,i)$ for all $i,j,k$ This question is from Durrett's Essentials of Stochastic Processes. There is a hint provided that says: Hint: fix $i$ and take $π_j = cp(i,j)/p(j,i)$ where $c$ is some constant. I am struggling to see how to apply this hint. I want to show $c$ is $π_i$ but don't know how to get there.","['stochastic-processes', 'markov-chains', 'statistics']"
1644288,Convergence of Sum of Random variable to another - Cantor function,"Let $(X_{n})_{n\geq1}$ be i.i.d. Ber$\left(\frac{1}{2}\right)$. I want to show that $$\sum_{{n\geq1}}\frac{2X_{n}}{3^{n}}$$ converges almost surely to a random variable $X$, without saying that this random variable distribution is Cantor-Distribution. I guess we should use Borel–Cantelli somehow - but I am not sure about it. Can you please help? Thanks.","['probability-theory', 'convergence-divergence', 'cantor-set', 'probability-distributions']"
1644291,Can the cardinality of a power set ever be odd? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Can the cardinality of a power set ever be odd? If it can, what conditions must be met?","['elementary-set-theory', 'discrete-mathematics']"
1644321,Remainder when ${45^{17}}^{17}$ is divided by 204,Find the remainder when ${45^{17^{17}}}$ is divided by 204 I tried using congruence modulo. But I am not able to express it in the form of $a\equiv b\pmod{204}$. $204=2^2\cdot 3\cdot 17$,"['number-theory', 'congruences', 'modular-arithmetic', 'divisibility']"
1644324,Generalisation of euclidean domains,"Recently I wondered how dependent the definition of euclidean domains is of the co-domain of the norm-function. To be precise: Let's define a semi-euclidean domain as a domain $R$  together with a norm $\delta : R \rightarrow \alpha$ for an ordinal $\alpha$ (or even the class of all ordinals) such that for $f,g \in R\ \exists\ q,r\in R$ such that $f=qg+r$ and $\delta(r)<\delta(g)$. With the same argument as for euclidean domains semi-euclidean domains are principal-ideal-domains. 
Are there any semi-euclidean-domains which are not euclidean? Thanks for your ideas, Takirion Edit: As the image of $\delta$ is well ordered (and as such isomorphic to an ordinal) we can assume that $\delta$ is surjective. Here is an idea that didn't work: 
$\mathbb{R}^{\alpha}$, the ""Polynomial Ring"" indexed by an limit ordinal $\alpha$ with $\delta (f)=\deg(f)$, because if $\omega_1\in \alpha$ we can't divide $x^{\omega_1}$ by $x^2$. Edit 2: Using Zorn's Lemma we can find a minimal norm in terms of the partial ordering $f\leq g \iff f(a)\leq g(a)\forall a\in R$ for two norms f and g. To show this let $(A, \leq)$ the partial ordered Set of all norms from $R$ in an ordinal $\alpha$ (note that to use Zorns Lemma here \alpha has to be an ordinal and can't be be class of all ordinals). Let $f_1\geq f_2\geq f_3\geq ...$ be a chain in $A$. Set $f(a)=min\lbrace f_n (a)|n\in \mathbb{N}\rbrace$. It's easy to see, that f is a norm on R and by definition it is a lower bound for all the $f_n$. So by Zorn's Lemma we find a minimal Element $\delta^*\in A.\square$ As $\delta^*$ is minimal obviously $\delta^*$ is surjective on an initialsegment of $\alpha$ (so we just assume it is surjective on $\alpha$). If $\alpha \leq \omega$ $R$ is euclidean and we are done. If not we find $x\in R$ with $\delta^*(x)=\omega$. But as $\delta^*$ is minimal this means, that for each $n\in \mathbb{N}$ we find $y\in R$ such that $y=q*x+r \implies \delta^*(r)>n$. At the moment i hope that it either will be possible to show that such a $x$ can't exist, or that this property of some elements gives hints on where to look for semi-euclidean but not euclidean rings. I found another interesting thing: Given that there is any euclidean function on the ring, we can construct $the$ minimal norm explicitely by transfinite induction. We define $\delta^{-1}(-\infty)=0$ and $\delta^{-1}(\alpha)=\lbrace x\in R\vert\forall y\in R \exists q,r\in R:y=q*x+r, \delta(r)<\alpha \rbrace$ for every ordinal $\alpha$. If we have any euclidean function $\mu$ we see immediately that every $x\in R$ gets assigned a value $\delta(x)<\mu(x)$ which shows both, that $\delta$ is defined on all elements of $R$ and that it is minimal. That it is indeed an euclidean function follows directly from the definition. 
By all the stuff above getting assigned a limit-ordinal is a property which belongs to an element and is essentialy independent of the euclidean function.
So I guess if there is a semiceulclidean not euclidean ring those elements will be interesting objects to be studied.","['abstract-algebra', 'ring-theory', 'euclidean-algorithm']"
1644366,"Find $\sum_{i=1}^{2000}\gcd(i,2000)\cos\left(\frac{2\pi\ i}{2000}\right)$","What is the value of the following sum? $$\sum_{i=1}^{2000}\gcd(i,2000)\cos\left(\frac{2\pi\ i}{2000}\right)$$ where $\gcd$ is the greatest common divisor.","['trigonometry', 'calculus', 'elementary-number-theory']"
1644391,Proving $\tan A=\frac{1-\cos B}{\sin B} \;\implies\; \tan 2A=\tan B$,"If $\tan A=\dfrac{1-\cos B}{\sin B}$, prove that $\tan 2A=\tan B$. My effort: Here $$\tan A=\frac{1-\cos B}{\sin B}$$
Now $$\begin{align}\text{L.H.S.} &=\tan 2A \\[4pt]
&=\frac{2\tan A}{1-\tan ^2A} \\[6pt]
&=\frac{(2-2\cos B)\over\sin B}{1-\frac{(1-\cos B)^2}{\sin^2 B}}
\end{align}$$ On simplification from here, I could not get the required R.H.S.",['trigonometry']
1644394,"What is the range of the derivative of $g(x) = f(x)/(x+1)$, where $f(x)$ is differentiable on $x\in[0,5]$?","Let $g(x) = f(x)/(x+1)$, where $f(x)$ is differentiable on $x\in[0,5]$, such that $f(0)=4$ and $f(5)=-1$. What is the range of values $g'(c)$ for a $c$ belonging to $[0,5]$? Considering values of $f(x_i)$, $f(x)$ must decrease at least once from $0$ to $5$. But that is all the information I can use here. Is there anything I am missing?","['derivatives', 'calculus']"
1644422,"Finding the formula for acceleration from $v=2s^3+5s$, where $s$ is the displacement at time $t$","This is the question: I first found $\frac{dv}{ds}=6s^2+5$, then I tried to find $\frac{ds}{dt}$ by messing about a little with implicit differentiation, but I had no luck and I therefore couldn't apply the chain rule (i.e. $a=\frac{dv}{dt}=\frac{ds}{dt}\frac{dv}{ds}$) to find acceleration. The back of my book tells me the answer is $(6s^2+5)(2s^3+5s)$, but I fail to see how this is true as it would imply that $\frac{ds}{dt}=v$, which I can't exactly understand. Can anyone tell me what I am doing wrong?","['derivatives', 'mathematical-physics', 'kinematics', 'calculus', 'applications']"
1644483,Analyticity of $\overline {f(\bar z)}$ given $f(z)$ is analytic [duplicate],"This question already has answers here : How do I rigorously show $f(z)$ is analytic if and only if $\overline{f(\bar{z})}$ is? (5 answers) Closed 8 years ago . Suppose $f$ is an analytic function on a domain $D$. Then I need to show that $\overline {f(\bar z)}$ is also analytic. 
Here is what I did - Suppose $f(z) = u(x,y) + iv(x,y)$ where $u$ and $v$ are real functions of $x$ and $y$ and $z = x + iy$. Now $f(\bar z) =  u(x,-y) + iv(x,-y) $ and then $\overline {f(\bar z)} = u(x,-y) - iv(x,-y) $. To show that a function is analytic, I need to verify that it satisfy Cauchy-Riemann Equations. I differentiated $\overline {f(\bar z)}$ and checked that it actually satisfies these equations. But here is my doubt - Being analytic means that the function if complex differentiable. Now here to check for analyticity, I am differentiating my function without proving that it's actually analytic. So is this the right way to do it?",['complex-analysis']
1644512,Minimum distance between the curves $f(x) =e^x$ and $g(x) =\ln x$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question What is the minimum distance between the curves $f(x) =e^x$ and $g(x) = \ln x$?
I didn't understand how to solve the problem. Please help me.","['derivatives', 'applications', 'curves', 'calculus']"
1644522,Is there any partial sums of harmonic series that is integer?,"is there any partial sums of harmonic series that add up to an integer? partial sums not as trivial as the first term only i.e. 1, or the powers of 2 i.e the infinite geometric series for 2. This might be trivially obvious for a subset of permutations of reciprocal of some integers. PS: there is already another solved problem that states $\sum_{k=1}^n \frac{1}{k}$ is not an integer for all $n$, but my question allows removing finite or infinite subsets of terms, excluding 1 and geometric series for 2.",['sequences-and-series']
1644523,$p = \sqrt{1+\sqrt{1+\sqrt{1 + \cdots}}}$; $\sum_{k=2}^{\infty}{\frac{\lfloor p^k \rceil}{2^k}} = ? $,Let $p = \sqrt{1+\sqrt{1+\sqrt{1 + \cdots}}}$ The sum $$\sum_{k=2}^{\infty}{\dfrac{\lfloor p^k \rceil}{2^k}}$$ Can be expressed as $\frac{a}{b}$. Where $\lfloor \cdot \rceil$ denotes the nearest integer function. Find $a+b$. My Work $p^2 = 1+p \implies p = \dfrac{1+\sqrt{5}}{2} = \phi$ And also $\phi^n = \dfrac{L_n + F_n\sqrt{5}}{2}$. Where $L_n$ is the $n-th$ Lucas-Number. What to do with the next part? Note : Problem Collected from Brilliant.org,"['sequences-and-series', 'quadratics']"
1644544,How do I show that the probability of the union of events is not larger than the sum of the individual probabilities?,"In numeric analysis class, we are supposed to show that
$$P\Bigl(\bigcup_{n\in\mathbb N}A_n\Bigr)\le\sum_{n\in\mathbb N}P(A_n).$$ This is easy to show using induction for a union of finitely many $A_n$, but I'm not sure how to prove this for the required union of countably infinite $A_n$. Indeed, it seems that the statement is questionable as the right hand side may not be finite. Can anybody help me out with the proof?",['probability-theory']
1644573,"$A \in SO(3,\mathbb R)\setminus\{I\}$ , then there are exactly two points in $S^2:=\{(x,y,z)\in \mathbb R^3:x^2+y^2+z^2=1\}$ which are fixed by $A$?","Let $A \in SO(3,\mathbb R)\setminus\{I\}$ , then is it true that there exist exactly two points in $$S^2:=\{(x,y,z)\in \mathbb R^3:x^2+y^2+z^2=1\}$$ which are fixed by $A$? Or equivalently we have to show that $1$ is an eigen-value of $A$ and there are exactly two distinct eigenvectors corresponding to it. Now I can show that $\det (A-I)=0 $ and $Ax=x$ implies $A\left(\dfrac x{||x||}\right)=\dfrac x{||x||} $ and $A \left(-\dfrac{x}{||x||}\right)=-\dfrac {x}{||x||}$ also; but how can I show that these are only two fixed points of $A$ on the unit sphere? Please help. Thanks in advance","['matrices', 'eigenvalues-eigenvectors', 'metric-spaces', 'linear-algebra']"
1644585,"There are 6 white balls and 9 black balls. Probability of drawing two white, then two black?","From A First Course in Probability (9th Edition) : 3.5 An urn contains 6 white and 9 black balls. If 4 balls are to be
  randomly selected without replacement, what is the probability that
  the first 2 selected are white and the last 2 black? This method is straightforward and results in the correct answer (according to the book):
$$\frac{6}{15} \cdot \frac{5}{14} \cdot \frac{9}{13} \cdot \frac{8}{12} = \frac{6}{91} $$ (This is just the multiplication principle and probability of drawing the color of that ball at that time) However, I want to understand this in terms of conditional probability. I don't understand why this doesn't work: $$P(E \mid F) = \frac{P(E \cap F)}{P(F)} ={\frac{{6 \choose{2}}{9 \choose 2}}{{15 \choose{2}}{13 \choose 2}}}÷{\frac{{6 \choose{2}}}{{15 \choose{2}}}} = {\frac{{9 \choose 2}}{{13 \choose 2}}} = \frac{6}{13} \ne \frac{6}{91}$$ $\frac{6}{13}$ is exactly 7 times more than the previous answer. Why does this method fail to work? What mistake have I made? I tried to use the exact same method used in question 3.3, where this resulted in the correct answer. Optional – About 3.3 3.3 Use Equation (2.1) to compute in a hand of bridge the conditional 
probability that East has 3 spades given taht North and South have a 
combined total of 8 spades. Here, we see that:
$$P(E \mid F) = \frac{P(E \cap F)}{P(F)} ={\frac{{13 \choose{8}}{39 \choose 18}{5 \choose 3}{21 \choose 10}}    {{52 \choose{26}}{26 \choose 13}}}÷{\frac{{13 \choose{8}}{39 \choose 18}}{{52 \choose{26}}}} = {\frac{{5 \choose 3}{21 \choose 10}}{{26 \choose 13}}} = \frac{29}{115} \approx 0.339$$ Which is the answer in the back of the book.",['probability']
1644612,"limit of form ""$∞ \cdot 0$""","I am trying to formally prove that limit of $2^n\sin(π/2^n)$ as $n$ approaches infinity is $π$. Generally I can tell limit of each term of product of $∞$ and $0$ respectively, but am little confused how to make use of these facts. Any suggestions?","['analysis', 'limits']"
1644638,An odd property of Egyptian fractions,"This question arose through a response to this post . For which integers $N>1$ does the fraction $\frac 1N$ appear in the Egyptian Fraction expansion of $\frac {N-1}{N}$ ? To specify: As such expansions are not unique, I should say which one I refer to. Here we consider the expansion obtained through the greedy algorithm. Thus $$\frac 12=\frac 12\;\;\&\;\;\frac 34=\frac 12+\frac 14\;\;\&\;\;\frac {11}{12}=\frac 12+\frac 13+\frac 1{12}$$ are easy examples. A quick search for $N<100$ yields $N=\{2,4,12,84\}$ as examples.  Taking that (short) list to OEIS leads to $[A053631][1]$ , the sequence $a_i$ starting with $a_1=2$ and having the property that, for $i>1$ , $\{a_{i-1}+1,a_i,a_i+1\}$ are a Pythagorean triple. That sequence continues from $84$ as $3612,\, 6526884,\, 21300113901612,\dots$ and it is easy to verify that those three, at least, are examples for the present question as well. Are these all examples?  Are there others? Edit:  as remarked in the comments, in each of the cases cited above, $\frac 1N$ appears as the final term in the expansion.",['number-theory']
1644645,"Find $\lim_{n \rightarrow \infty} \int_0^n (1+ \frac{x}{n})^{n+1} \exp(-2x) \, dx$","Find: $$\lim_{n \rightarrow \infty} \int_0^n \left(1+ \frac{x}{n}\right)^{n+1} \exp(-2x) \, dx$$ The sequence $\left(1+ \frac{x}{n}\right)^{n+1} \exp{(-2x)}$ converges pointwise to $\exp{(-x)}$. So if we could apply Lebesgue's monotone convergence theorem, we have: \begin{align}
\lim_{n \rightarrow \infty} \int_0^n \left(1+ \frac{x}{n}\right)^{n+1} \exp(-2x) \, dx &=\lim_{n \rightarrow \infty} \int_{\mathbb{R}} I_{(0,n)(x)} \left(1+ \frac{x}{n}\right)^{n+1} \exp(-2x) \, dx \\[10pt]
&= {} \int_{- \infty}^\infty \exp(-x) \, dx= +\infty
\end{align} Can someone help me to prove that the sequence of integrands is monotone?","['integration', 'lebesgue-integral', 'limits']"
1644648,Find root of the equation,"Find maximum root of the equation $$x - \frac{1000}{\log 2} \log x = 0$$
It locates between $13746$ and $13747$, but I want to find right solution not using graphing calculators. Thanks in advance.","['algebra-precalculus', 'logarithms']"
1644650,$\lim_{n \to \infty}(\frac{a_n}{\sqrt{a_n^2+1}})=\frac{1}{2}$ - show that $a_n$ is convergent sequence,"Problem:
Show that $a_n$ is convergent sequence and find a limit of $a_n$.
$$\lim_{n \to \infty}(\frac{a_n}{\sqrt{a_n^2+1}})=\frac{1}{2}$$
I tried to look at this as normal limit problem so I wrote this:
$$\lim_{n \to \infty}(\frac{a_n}{\sqrt{a_n^2+1}})=\lim_{n \to \infty}(\frac{1}{\sqrt{1+1}})=\frac{1}{2}$$
But I didn't get anything which can help me to solve a problem.","['sequences-and-series', 'calculus', 'limits']"
1644685,"E is measurable, then measure of E is the sum of the inner measure of a subset of E and the outer measure of the complement of the subset in E","If E is a measurable and A is any subset of E, show that $|E|=|A|_i+|E-A|_e$
where |E| is the measure of of E, $|A|_i$ is the inner measure of A, and $|E-A|_e$ is the outer measure of $E-A$. I have proved $|E|\geq|A|_i+|E-A|_e$, but I can't seem to figure out $\leq$ part of the proof. I just need hints. Please don't solve it for me. Thank you!","['real-analysis', 'measure-theory']"
1644710,Evaluating $\cos^{\pi}\pi$ via binomial expansion of $\left(\frac12(e^{xi}+e^{-xi})\right)^\pi$,"I was challenged to take $\cos^{\pi}(\pi)$ and expand it using binomial expansion and $\cos(x)=\frac{e^{xi}+e^{-xi}}2$, which I tried: $$\cos^{\pi}(\pi)=\left(\frac{e^{\pi i}+e^{-\pi i}}2\right)^{\pi}$$ $$=\frac{(e^{\pi i}+e^{-\pi i})^{\pi}}{2^{\pi}}$$ $$(2\cos(\pi))^{\pi}=S$$ $$S_1=\sum_{n=0}^{\infty}\frac{\pi!e^{\pi^2i-2n}}{n!(\pi-n)!}$$ $$S_2=\sum_{n=0}^{\infty}\frac{(\pi)!e^{-\pi^2i+2n}}{n!(\pi-n)!}$$ The difference between $S_1$ and $S_2$ is that I did binomial expansion starting with different terms, which we will see why in a moment. I note: $$S=\frac{S_1+S_2}{2}$$ $$S=\sum_{n=0}^{\infty}\frac{\pi!}{n!(\pi-n)!}\frac{e^{\pi^2i-2n}+e^{-\pi^2i-2n}}2$$ Now, reapplying the complex extension of the cosine function (which is why I had $S_1$ and $S_2$): $$S=\sum_{n=0}^{\infty}\frac{\pi!}{n!(\pi-n)!}\cos(\pi^2-2n)$$ So, we have: $$(2\cos(\pi))^{\pi}=\sum_{n=0}^{\infty}\frac{\pi!}{n!(\pi-n)!}\cos(\pi^2-2n)$$ And this simplifies to: $$(-2)^{\pi}=\sum_{n=0}^{\infty}\frac{\pi!}{n!(\pi-n)!}\cos(\pi^2-2n)$$ But we can clearly see the LHS is a complex number while the right side produces real numbers. So where did I go wrong?","['binomial-theorem', 'complex-numbers', 'trigonometry', 'algebra-precalculus', 'solution-verification']"
1644750,Find $\lim_{n \rightarrow \infty}\frac{1}{n} \int_{1}^{\infty} \frac{\mathrm dx}{x^2 \log{(1+ \frac{x}{n})}}$,"Find: $$\lim_{n \rightarrow \infty} \frac{1}{n} \int_{1}^{\infty} \frac{\mathrm dx}{x^2 \log{(1+ \frac{x}{n})}}$$ The sequence $\frac{1}{nx^2 \log{(1+ \frac{x}{n})}}=\frac{1}{x^3 \frac{\log{(1+ \frac{x}{n})}}{\frac{x}{n}}}$ converges pointwise to $\frac{1}{x^3}$ . So if we could apply Lebesgue's Dominated Convergence Theorem, we have: $\lim_{n \rightarrow \infty} \frac{1}{n} \int_{1}^{\infty} \frac{\mathrm dx}{x^2 \log{(1+ \frac{x}{n})}}=\lim_{n \rightarrow \infty} \int_{1}^{\infty} \frac{\mathrm dx}{x^3}=\frac{1}{2}$ I have a problem with finding a majorant. Could someone give me a hint?","['integration', 'lebesgue-integral', 'limits']"
1644761,A set containing more than half elements of a group [duplicate],"This question already has an answer here : If $|A| > \frac{|G|}{2} $ then $AA = G $ [closed] (1 answer) Closed 8 years ago . I wish to prove the exercise which states that for a set $A$ containing more than half elements of a group $G$, every element of $G$ is a product of two elements of $A$. My attempt: By Lagrange Theorem, subgroup generated by $A$ must coincide with $G$, so every element in $G$ is a product of elements from $A$. How can I prove that the product is of exactly two elements?",['group-theory']
1644774,Infinite expectation implies infinite random variable?,"Let $X$ be a nonnegative integer-valued random variable depending on a parameter $L$. Assume that $E[X] \rightarrow \infty$ as $L\rightarrow \infty$. 
Does this imply that for any $k$, $P(X > k)$ is going to 1 with $L$?","['probability-theory', 'expectation']"
1644794,Exploding (a.k.a open-ended) dice pool,"Say we role $n$ identical, fair dice, each with $d$ sides (every side comes up with the same probability $\frac{1}{d}$ ). On each die, the sides are numbered from $1$ to $d$ with no repeating number, as you would expect. So an ordinary $d$ sided die pool. Every dice in the outcome that shows a number equal or higher than the threshold number $t$ is said to show a hit. Every die that shows the maximum result of $d$ is rolled again, which we call ""exploding"". If the re-rolled dice show hits, the number of hits is added to the hit count. Dice that show the maximum after re-rolling are rolled again and their hits counted until none show a maximum result. Given the values of $$ d\ ...\ \text{Number of sides on each die}\ \ d>0 $$ $$ n\ ...\ \text{Number of dies rolled}\ \ n\ge 0$$ $$ h\ ...\ \text{Number of hits, we want the probability for}$$ $$ t\ ...\ \text{Threshold value for a die to roll a hit}\ \ 0 < t \le d$$ what is the probability to get exactly exactly $h$ hits? Lets call it: $$p^\text{exploding}(d,n,t,h) = p_{d,n,t,h}$$ Can you derive a formula for this probability? Example roll: We roll 7 six-sided dice and count those as hits that show a 5 or a 6 . In this example, $d=6$ , $n=7$ , $t=5$ . The outcome of such a roll may be 6 , 5 , 1 , 2 , 3 , 6 , 1 . That's three hits so far, but we have to roll the two sixes again (they explode). This time it's 6 , 2 . One more hit, and one more die to roll. We are at four hits at this point. The last die to be re-rolled shows 6 again, we re-roll it yet another time. On the last re-roll it shows a 4 - no more hits. That gives five hits in total and the roll is complete. So, for this roll $h=5$ . Simple case for just one die $n=1$ : If we roll only one die with the same threshold as above, so ( $d=6$ , $n=1$ , $t=5$ ), the probabilities can be easily calculated: $$ p_{6,1,5,0} = \frac{4}{6} \quad \text{(Probability for exactly 0 hits - roll 1-4 on the first roll, no explosion here)} $$ $$ p_{6,1,5,1} = \frac{1}{6} + \frac{1}{6} \cdot \frac{4}{6} \quad \text{(Probability for exactly 1 hit - roll either a 5 or a result of 1-4 after a 6)} $$ $$ p_{6,1,5,2} = \frac{1}{6} \cdot \frac{1}{6} + \frac{1}{6} \cdot \frac{1}{6} \cdot \frac{4}{6} \quad \text{(Probability for exactly 2 hits - either a 6 and 5 or two sixes and 1-4)} $$ $$ p_{d,1,t,h\ge 1} = \left(\frac{1}{d}\right)^{h-1}\frac{d-t}{d}  + \left( \frac{1}{d} \right)^h \cdot \frac{t-1}{d} \quad \text{(Probability for exactly $h\ge 1$ hits - either $h-1$ maximum rolls and non-maximal success or $h$ maximum rolls and a non-success )} $$ Without Explosion: For none-exploding dice the probability would just be binomially distributed : $$ p^\text{non-exploding}_{d,n,t,h} = \binom{n}{h} \left( \frac{d-t+1}{d} \right)^h \left( 1 - \frac{d-t+1}{d} \right)^{n-h} $$ $$ E^\text{non-exploding}_{d,n,t} = n \frac{d-t+1}{d}; \qquad V^\text{non-exploding}_{d,n,t} = n \frac{(d-1)(d-t+1))}{d^2} $$ Where $E_{d,n,t}$ is the expected number of hits, and $V_{d,n,t}$ its variance. Edit1: In the mean time I found Probability of rolling $n$ successes on an open-ended/exploding dice roll . However I'm afraid, I don't fully get the answer there. E.g. the author says $s = n^k + r$ , which does not hold for his examples. Also I'm not sure how to get $s$ , $k$ and $r$ from my input values stated above (which are $d$ , $n$ , $h$ and $s$ ). Edit2: If one had the probability for $b$ successes via explosions, given that the initial role had $l$ successes prior to the explosions, one could just subtract all those probabilities for all values of $b$ from the value for the pure binomial distributions with $l$ successes and add the respective value to the pure binomial probability of $b+l$ successes. Just an idea. I suppose this should be something like a combination of geometric and binomial distribution. Edit3: I accepted Brian Tung 's excellent answer, giving the formula: $$ p^\text{exploding}_{d,n,t,h} = \frac{(t-1)^n}{d^{n+h}}
             \sum_{k=0}^{\max\{h, n\}} \binom{n}{k} \binom{n+h-k-1}{h-k}
             \left[ \frac{d(d-t)}{t-1} \right]^k $$ $$ E^\text{exploding}_{d,n,t} = n\frac{d+1-t}{d-1}; \qquad V^\text{exploding}_{d,n,t} = E_{d,n,t} - n\frac{(d-t)^2-1}{(d-1)^2} $$ Here is a graph from a simulation ( html ) that illustrates the whole thing:","['probability', 'dice']"
1644813,"If there is a branch of $\sqrt{z}$ on an open set $U$ with $0 \notin U,$ then there is also a branch of $arg$ $z.$","Show that if there is a branch of $\sqrt{z}$ on an open set $U$ with $0 \notin U,$ then there is also a branch of $arg$ $z.$ I am unable to proceed any further in this and any help in this regard would be greatly appreciated.",['complex-analysis']
1644822,"The set of polynomials which ""cut out"" smooth subsets of projective space is open and dense","Let $k[x_0,x_1,...,x_n]_d$ be a space of all forms (in other words, homogenous polynomials) of degree $d$ of variables $x_0, x_1,...,x_n$ over algebraically closed field $k$. Let's think of $k[x_0,x_1,...,x_n]_d$ as an affine space. Of course, every such polynomial has a well defined zero-locus on a projective space $\mathbb P^n$, because it is homogenous. Let $X\subset k[x_0,x_1,...,x_n]_d$ be a subset of polynomials, whose zero-loci are smooth subets of $\mathbb P^n$. I would like to prove, that $X$ is open and dense subset of $k[x_0,x_1,...,x_n]_d$, but i have no idea how to do that. I guess it has something to do with the fact, that the set of smooth points of an algebraic set is dense and open, but i don't know how to use this fact in this setting.","['projective-geometry', 'algebraic-geometry']"
1644872,Solving $\int_0^{\pi/2} \sin^2\theta \sqrt{1-k^2\sin^2 \theta}d\theta $,"I have the following integration to solve. $$f(k) = \int_0^{\pi/2} \sin^2\theta \sqrt{1-k^2\sin^2 \theta}d\theta,\quad0<k<1$$ assuming $\sin\theta = t$ which results $d\theta = \frac{dt}{\sqrt{1-t^2}}$
and when $\theta = 0, t=0$ and $\theta=\frac{\pi}{2},t=1$
so above equation can be rewritten as, $$f(k) = \int_0^1{t^2\frac{\sqrt{1-k^2t^2}}{\sqrt{1-t^2}}}dt$$
I'm stuck in solving this further. 
Can somebody help me with some clues/solution to solve this further.","['integration', 'elliptic-integrals']"
1644877,Prove that $\lim\limits_{x\to\infty} f'(x)=0$,"Let $f$ be  a function in $(0,\infty)$ such that $f'(x)$ exists.
In addition, $\lim\limits_{x\to \infty} f'(x)=L$ ( finite ) and $f(n)=0$ for every $n \in \Bbb N$ . Prove that $\lim\limits_{x\to\infty} f'(x)=0$ I think Rolle's theorem might help here, but I don't know how to use it. Any hints are most welcome. Thanks!","['derivatives', 'real-analysis', 'calculus', 'limits']"
1644891,What is the significance of Coleman maps arising in Iwasawa theory?,"I have come across two instances of ""Coleman map"" Let $E$ be an elliptic curve defined over $\mathbb{Q}_p$. Let $k_\infty$ be the unique $\mathbb{Z}_p$ extension of $\mathbb{Q}_p$ contained in $\mathbb{Q}_p(\mu_{p^\infty})$ with Galois group $\Gamma = 1+p\mathbb{Z}_p \cong \mathbb{Z}_p$. Let $k_n$ be the $n$-th layer in this tower. Let $T=T_p(E)$ be the $p$-adic Tate module  of the elliptic curve $E$. Then the $\textit{Coleman map for E}$ is a map $$Col: \varprojlim_{n}  H^1(k_n, T^*(1)) \rightarrow \Lambda=\mathbb{Z}_p[[\Gamma]] $$
I am referring to page 572 of this paper where I learn that the power series $Col_z(x)$ equals the $p$-adic L-function of the elliptic curve E when $z$ is a special element discovered by Prof. Kato. There is another instance where I have come across a Coleman power series, as a power series that generates norm-coherent sequence of units in the tower $\mathbb{Q}_p(\mu_{p^ \infty})/\mathbb{Q}_p$. That is, if I have a sequence of units $\mathbb{u}=(u_n)_{n \geq 0} \in \varprojlim_{n \geq 0} \mathcal{O}^{\times}_{\mathbb{Q}_p(\mu_{p^n})}$ (the inverse limit on the right hand side is w.r.t. the norm map of fields $\mathbb{Q}_p(\mu_{p^m}) \rightarrow \mathbb{Q}_p(\mu_{p^n}),  m \geq n$), then $\exists!$ unique power series $Col_{\mathbb{u}}(x) \in \mathbb{Z}_p[[x]]$ such that $Col_{\mathbb{u}}(\zeta_{p^{1+n}}-1)=u_n, \forall n\geq 0$. How does the first Coleman map relate to the second? Or even more generally, are there other instances where Coleman maps arise, and what is  the general philosophy behind Coleman maps? Any thoughts and/or link to any articles/notes are welcome. Thank you!!","['number-theory', 'arithmetic-geometry', 'p-adic-number-theory']"
1644943,$f$ has a zero integral on every measurable set. Prove $f$ is zero almost everywhere,"I am trying to solve the following exercise: Let $f$ be integrable. Assume that $\int_A f d\mu = 0$ for every measurable set $A$. Prove that $f = 0$ a.e. [$\mu$]. I have the following proof but it seems to me too simple to be true. What is wrong with it? For any $a>0$, define $W_a:=\{w|f(w)\geq a\}$. Now we have:
$$\int_{W_a} fd\mu = 0 \geq \int_{W_a} ad\mu=a\mu(W_a)$$
and therefore $\mu(W_a)=0$. Same holds for the negative $a$'s. This completes my proof.","['probability-theory', 'lebesgue-integral', 'measure-theory']"
1645027,A non continuous linear map $A:\Bbb{R}[X]\rightarrow \Bbb{R}$ such that $A(P)=P(1).$,"I have a linear map $A:\Bbb{R}[X]\mapsto \Bbb{R}$ such that $A(P)=P(1)$, for the $p-$norm : $\Vert P\Vert=\bigl(\sum_{i=1}^n\vert a_i\vert^p\bigr)^{1/p}$ where $p\in[1,+\infty].$ For the cas where $p=1$ it's continuous (triangle inequality), anyway for the case $p>1$ I would like to prove that is not continuous. For that I can use the sequential characterization of continuity, if $p=\infty$, the following polynomial $P(X)=1+X+X^2+\cdots+X^n$ works, because $\Vert P\Vert_{\infty}=1$ but $\vert P(1)\vert=1+1+1+\cdots+1=n+1\rightarrow+\infty.$ Anyway, I am stuck for $1<p<\infty$,I get always the same result... Any idea ? EDIT : in fact my polynomial works for any $p$.","['functional-analysis', 'normed-spaces', 'general-topology', 'polynomials']"
1645039,Codomains and the definition of a function,"A function $f$ is defined as a set of ordered pairs $(x, y)$ such that $(x,b), (x,c) \in f \Longrightarrow b=c$. Since $y$ is determined uniquely by $x$, it is customarily denoted $f(x)$. One difficulty I am having with this definition is that it does not specify the codomain. In particular, $f:\mathbb{R} \rightarrow \mathbb{R}_{+}$  such that $f(x)=\exp(x)$ and $g:\mathbb{R} \rightarrow \mathbb{R}$ such that $g(x) = \exp(x)$ would be the same functions under this definition. But this is absurd. One is bijective, the other is not.","['functions', 'definition']"
1645061,Riesz-Type Representation Theorems for Convex Functionals,"It is well known that any positive linear functional $L$ on the spase $C_c([a,b])$ of functions continuous on an interval $[a,b]$ with compact support can be written as 
\begin{align*}
L(x)=\int_a^bx(t)d\mu(t),\qquad x\in C_c([a,b]),
\end{align*}
where $\mu$ is some proper Radon-measure. The question for me now arises, if there are any similar results, if $L$ is only a convex functional. To be precise, my questions are (1) Let $X$ be a real vector space of measurable functions $[a,b]\to\mathbb R$, and let $L:X\to[0,\infty)$ be a convex functional. Does there exist a convex function $\varphi:\mathbb R\to[0,\infty)$ and a Borel/Radon measure $\mu$ such that
\begin{align*}
    L(x)=\int_a^b\varphi(x(t))\mu(t),\qquad x\in X?
\end{align*}
(2) What conditions on $X$ and maybe on $L$ have to be added such that a representation of the aforementioned kind is possible? (3) If equality cannot be achieved, is it possible to estimate $L$ from above and below by integrals like those in (1)? Any help is highly appreciated, and any literature recommendations are very welcome. Thanks in advance!","['functional-analysis', 'integration', 'measure-theory']"
1645095,Variance of the random sum of a Poisson?,"We have that $N$ and $X_1, X_2, \dots$ are all independent. We also have $\operatorname{E} [X_j] = \mu$ and $\operatorname{Var}[X_j] = σ^2$. Then, we introduce an integer–valued random variable, $N$, which is the random sum such that:
$$Z = \sum_{j=1}^{N+1}X_j.$$
Assuming that $N$ is distributed $\sim\mathrm{Poisson}(\lambda)$, what is the first moment and what is the variance of $Z$? For a normal Poisson distribution, I know the variance is just $\lambda$, as is the mean. I'm having trouble understanding the implication of having the bounds be poisson distributed. Normally, I would just say ""variance of the sum is the sum of the variance,"" but I don't think that's how it works with random sums. Any hints/guidance appreciated.","['poisson-distribution', 'probability', 'random-variables']"
1645103,Show that an inverse of a bijective linear map is a linear map.,"So I've got a bijection. It clearly has an inverse, but how exactly do I prove that the inverse is a linear map as well? Suppose that the linear map $T:U\to V$ is a bijection. So $T$ has an inverse map $T^{-1}:V\to U$. Prove that $T^{-1}$ is a linear map.","['linear-algebra', 'functions', 'linear-transformations']"
1645111,$-1$ as the only negative prime.,"I was recently thinking about prime numbers, and at the time I didn't know that they had to be greater than $1$. This got me thinking about negative prime numbers though, and I soon realized that, for example, $-3$ could not be prime because $3 \cdot (-1) = -3$. In some sense $-1$ could be though because its only factors that are integers are $-1$ and $1$, and this is allowed for primes. Is there some way, by this logic, that $-1$ can be considered a prime then?","['number-theory', 'prime-numbers']"
1645130,Explicit bijection between $\mathbb{R}$ and $\mathcal{P}(\mathbb{N})$,"Is there any known explicit bijection between these two sets? I know it can be proved that such bijection exists using two injections and Schröder–Bernstein theorem, but I wanted to know whether some explicit bijection is known. I failed to find any except ones constructed awkwardly from the Schröder–Bernstein theorem.",['elementary-set-theory']
1645153,Vector-Valued Functions and Continuity,"Why is it that when a vector-valued function $r(t)$ is continuous at some time $t$ then $\|r(t)\|$ is also continuous at that time $t$, but the converse is not true? That if $\|r(t)\|$ is continuous at time $t$, then $r(t)$ is discontinuous at time $t$.","['vectors', 'calculus', 'functions']"
1645161,Proving $\frac{n}{n+1} < \frac{n+1}{n+2}$ by induction?,"I have the inequality $\frac{n}{n+1} < \frac{n+1}{n+2}$ I'm not sure how to go about proving it. I've started by testing with n = 1, which results in $\frac{1}{2} < \frac{2}{3}$ which is true I then assume true for n = k and have to prove that it is true for n = k + 1, but I don't know how to start manipulating $\frac{k}{k+1} < \frac{k+1}{k+2}$ to become $\frac{(k+1)}{(k+1)+1} < \frac{(k+1)+1}{(k+1)+2}$ How do I go about doing this?","['induction', 'inequality', 'proof-writing', 'discrete-mathematics']"
1645246,Proof of independence of $\bar{X}$ and $S^2$: Trouble understanding $n$-dimensional Jacobian Result,"I'm trying to work through the proof given here that the sample mean and sample variance of a random sample $X_1, X_2, ..., X_n \sim N(\mu,\sigma^2)$ are independent. The part I can't seem to follow is the assertion that the Jacobian of the transformations... $$
 Y_1 = \bar{X} \\
 Y_2 = X_2 - \bar{X} \\
 \vdots \\
 Y_n = X_n - \bar{X} \\
$$ is equal to $n$. I must be missing something simple, but when I create the matrix of partial derivatives, the determinant seems to always be one? $$
  \det\begin{bmatrix}
    \frac{dY_1}{d\bar{X}} & \frac{dY_1}{dX_2} & \dots & \frac{dY_1}{dX_n} \\
    \frac{dY_2}{d\bar{X}} & \frac{dY_2}{dX_2} & \dots & \frac{dY_2}{dX_n} \\
    \vdots & \vdots & \ddots & \vdots \\
    \frac{dY_n}{d\bar{X}} & \frac{dY_n}{dX_2} & \dots & \frac{dY_n}{dX_n} \\
  \end{bmatrix} = 
  \det\begin{bmatrix}
    1 & 0 & \dots & 0 \\
    -1 & 1 & \dots & 0 \\
    \vdots & \vdots & \ddots & \vdots \\
    -1 & 0 & \dots & 1 \\
  \end{bmatrix} = 1
$$ How am I setting up the Jacobian incorrectly? Thanks in advance!","['independence', 'statistics']"
1645295,Finding ranks and nullities of linear maps,"I am confused about ranks, nullities and bases of the kernel.
From what I understand the rank is the dimension of a vector space generated by a matrix. How would I do the following examples? Find the ranks and nullities of the following linear maps $T \colon U \to V$ , and find bases of the kernel and image of $T$ in each case. (i) $U = \mathbb{R}^4$ , $V = \mathbb{R}^4$ , $T(\alpha, \beta, \gamma, \delta) = (\alpha - \gamma, \gamma-\delta, \alpha-\beta, \beta-\delta)$ ; (ii) $U = \mathbb{R}[x]_{\leq 5}$ , $V = \mathbb{R}[x]_{\leq 5}$ (polynomials of degree at most $5$ over $\mathbb{R}$ ), $T(f) = f'''$ (third derivative of $f \in U$ ). ( Source )","['linear-algebra', 'functions', 'vector-spaces']"
1645347,"Choosing a combination of books, under given restrictions.","Mary has on her bookshelf 5 novels, 5 biographies, and 8 textbooks. Mary decides to take three novels and four non-fiction books with at least one of the non-fiction books a biography. How many ways are there to make such a selection? I thought that the answer would be obtained using multiplication of several combinations, as there are multiple object types. My working was: Three novels are selected from five, and
$$^5C_3 = {5 \choose 3} = 10$$
In terms of non-fiction, we have biographies and textbooks, four must be selected. One of these four must be chosen from the five biographies, so we have
$$^5C_1 = {5 \choose 1} = 5$$
The remaining three non-fiction choices can be either biographies or textbooks, one biography has already been selected so there are only twelve non-fiction books remaining, so the combination is
$$^{12}C_3 = {12 \choose 3} = 220$$
Using the multiplication principle, the number of combinations of non-fiction books is simply $5 \times 220 = 1100$. Again using this principle, the number of combinations for a selection of 3 novels and four non-fiction books containing at least one biography must be $10 \times 1100 = 11000.$ I entered this answer and it was marked incorrect. Any help would be appreciated.","['algebra-precalculus', 'combinations']"
1645353,Largest possible value of $P(A \cap B)$,"Suppose $A$ and $B$ are events with $P(A)+P(B)>1$. Show that the
  largest possible value of $P(A \cap B)$ is $  \min(P(A), P(B))$. I suspect I'm supposed to use $P(A \cap B) = P(A)+P(B) -P(A \cup B)$ but I've no idea how. I also understand that from this we get $P(A\cap B)\leq P(A)$. However, I don't know how to use that.","['probability-theory', 'probability', 'elementary-set-theory']"
1645369,Finding the minimum of $x^2+y^2$ for $(x^2y-xy^2)(x^3-y^3)=x^3+y^3$ and $xy>0$.,"If $x,y \in \mathbb {R}$, find the minimum of  $x^2+y^2$ when $(x^2y-xy^2)(x^3-y^3)=x^3+y^3$ and $xy>0$. This problem was inspired by a problem which asked if $x,y \in \mathbb {R}$ and $xy \neq 0$,  find the minimum of $x^2+y^2$ when $xy(x^2-y^2)=x^2+y^2$. By setting $x=a\sin\theta$, $y=a\cos\theta$, the equation can be simplified to $a^2=\frac{1}{\sin\theta\cos\theta(\sin\theta^2-\cos\theta^2)}$ However, notice that $\sin\theta\cos\theta=\frac{\sin2\theta}{2}$, $\sin\theta^2-\cos\theta^2=-\cos2\theta$. This implies that $a^2=\frac{2}{-\sin2\theta\cos2\theta}$, thus that $a^2=\frac{4}{-\sin4\theta}\ge 4$. Thus the minimum of $x^2+y^2$ is $4$, with the equality holding when $x=\sqrt{2-\sqrt{2}}$, $y=\sqrt{2+\sqrt{2}}$. However, since there are no formulas I know of where $\sin^3 x+\cos^3 x$, I did not know how to find the minimum of $x^2+y^2$ when $(x^2y-xy^2)(x^3-y^3)=x^3+y^3$. Graphing it seems to imply that such a minimum exists, but I am not aware of how to find it( and when such a minimum exists). Any help would be appreciated.","['inequality', 'optimization', 'calculus']"
1645371,Is it true that $\mathbb{Q}(\sqrt{2}) \cap \mathbb{Q}(i) = \mathbb{Q}$?,"Is it true that $\mathbb{Q}(\sqrt{2}) \cap \mathbb{Q}(i) = \mathbb{Q}$? I know that
\begin{align*}
 \mathbb{Q}(\sqrt{2}) &= \{a+b\sqrt{2} \mid a,b \in \mathbb{Q}\}, \\
 \mathbb{Q}(i) &= \{a+bi \mid a,b \in \mathbb{Q}\}
\end{align*} I tend to believe it is, since every element in $\mathbb{Q}(\sqrt{2})$ belongs to $\mathbb{Q}(i)$ iff $b=0$. Also, an element in $\mathbb{Q}(i)$ belongs to $\mathbb{Q}(\sqrt{2})$ iff $b = 0$. Is that enough for a formal proof?","['abstract-algebra', 'rational-numbers', 'field-theory', 'irrational-numbers']"
1645388,Let $f:\mathbb{R}\rightarrow\mathbb{R}$ be a function such that $f'(x)$ is continuous and $|f'(x)|\le|f(x)|$ for all $x\in\mathbb{R}$,"Let $f:\mathbb{R}\rightarrow\mathbb{R}$ be a function such that $f'(x)$ is continuous and $|f'(x)|\le|f(x)|$ for all $x\in\mathbb{R}$. If $f(0)=0$, find the maximum value of $f(5)$. $f'(x)=f(x)$ is true when $f(x)=ke^x$. $f(x)=0$ satisfies the condition. So $f(5)=0$ which is also the correct answer. But is there any method other than substitution?","['real-analysis', 'calculus']"
1645391,"What is the main purpose of learning about different spaces, like Hilbert, Banach, etc?","I just started to learn about functional analysis and have started to learn about various spaces, like $L^{p}$, Banach, and Hilbert spaces. However, right now my understanding is rather mechanical . That is, my understanding of say the Hilbert space is that it is a vector space with an inner product such that the norm defined by it turns into a complete metric space. Additionally, that generally vector spaces will fulfill certain criteria. Hence, my understanding is rather unmotivated by why they are defined a certain way. Is there a reason why certain vector spaces are defined the way they are? What is it about vector spaces having certain properties that makes it appealing to study? Does it allow us to do certain things on the spaces that makes it so that we must use it? Sorry if my understanding is rather weak, I just started to learn more advanced spaces from a purely mathematical point of view and have had a hard time getting an answer from professors. In summary, right now it seems that someone just gave a bunch of random conditions to define certain vector spaces and I really have no idea why they defined it that way, and why it couldn't be defined with other conditions.","['functional-analysis', 'soft-question']"
1645485,Do any mathematican still reserach about trigonometry?,"Do any mathematican still reserach about applied trigonometry? If so, what are the subject area called in the PhD level except fourier analysis? In many area, you could see a lot of trig and hyperbolic function including finance, physics etc... Please list some example of subject area of trigonometry that is alive or generalized.","['big-list', 'trigonometry']"
1645491,Series of video lectures on the subject of Complex Analysis,I am looking for a series of video lectures on the subject of complex analysis which follow Conway's text Functions of Complex Variable I . Any recommendations?,"['complex-analysis', 'online-resources']"
1645497,Confusion with Courant: Which of his two calculus books is THE one?,"Since I've worked my way through Spivak's Calculus book, I thought I'd give Courant's allegedly fantastic exposition of the subject a go as well. However, I've run into a problem. People in stackexchange threads always praise and suggest Courant's Calculus without specifying whether that's supposed to be his ""Differential and Integral Calculus"" or his ""Introduction to Calculus and Analysis"" book. So my question is: which one of these two is the ""famous"" and ""legendary"" Calculus book that everybody always talks about when the ""great three"" - Spivak, Apostol and Courant - are mentioned or recommended to people asking for a first course in calculus? Note: I'm a math major. I'm mostly interested in what the oft-mentioned calculus book by Courant is, and not which of his two books would suit my prior exposure to calculus (Spivak) best in terms of the follow-up level. That is not to say I wouldn't appreciate an informed opinion on that matter, I certainly would (and I hope some experienced readers will be able to enlighten me), but I'm primarily asking this question to find out which is the more canonical one.","['reference-request', 'calculus']"
1645532,Definition of Inverse in Linear and Abstract Algebra,"In a linear algebra text, the following is the definition of the inverse of a matrix An $n\times n$ matrix $A$ is invertible when there exists an $n \times n$ matrix $B$ such that $$AB = BA = I_n$$ And likewise in an abstract algebra textbook, the definition of the inverse of a group is Given that $G$ is a group with operation $*$, for each $a \in G$, there exists an element $a^{-1}$ such that $$a*a^{-1} = a^{-1}*a = e,$$ where $e$ is the identity element in $G$. Such element is called the inverse of $a$ in $G$. Unfortunately, the second semester of abstract algebra didn't quite finalize due to low enrollment, so I'm doing independent self-study of topics I missed in Linear Algebra (as mind preparation). Here's my question: Is it sufficient to show that $AB = I_n \;\;\implies \;\;B = A^{-1}$ and $A = B^{-1}$? Or must you check both that $AB = I_n$ and $BA = I_n$ to completely conclude that $A = B^{-1}$ and $B = A^{-1}$? I remember on an exam, I had to prove that for a group homomorphism $\phi: G\to H$, for any $a \in G$, $\phi(a^{-1}) = [\phi(a)]^{-1}$ which I proved by asking the reader to observe that $\phi(a)\phi(a^{-1}) = \phi(aa^{-1}) = \phi(e_G) = e_H$ which because $\phi(a)\phi(a^{-1}) = e_H$, this can only mean that $\phi(a)^{-1} = \phi(a^{-1})$ by definition of inverse. And I got full points for it, but it leaves me wondering: am I supposed to check both arrangements to create the strongest possible argument?","['abstract-algebra', 'proof-writing', 'linear-algebra', 'inverse']"
1645569,Prove that $u\cdot v = 1/4||u+v||^2 - 1/4||u-v||^2$ for all vectors $u$ and $v$ in $\mathbb{R}^n$,"I need some help figuring out how to work through this problem. Prove that $ u \cdot v  = 1/4 ||u + v||^2 - 1/4||u - v||^2$ for all vectors $u$ and $v$ in $\mathbb{R}^n$. Sorry, forgot to include my work so far: I decided to ignore the 1/4 and deal with it later once I had a better understanding of the question. $= ||u+v||^2 - ||u-v||^2$ $= (u+v)(u+v) - (u-v)(u-v)$ $= u(u+v) + v(u+v) - u(u-v) + v(u-v)$ $= uu + uv + uv + vv - uu + uv + uv - vv$ $u \cdot v= 3(uv)$ This is as far as I've gotten, not sure if I'm on the right track or where to go next.","['euclidean-geometry', 'linear-algebra']"
1645570,Show that if $\prod_\alpha X_\alpha$ is normal then so is $X_\alpha$.,"Show that if $\prod_\alpha X_\alpha$ is normal then so is $X_\alpha$. This a question of proof-verification.So please suggest the required edits and fault in the logic but please don't give a different proof all together. Proof : Let $A_\alpha,B_\alpha$ be disjoint closed subsets in $X_\alpha$.
Consider the projection map $\pi_\alpha :\prod_\beta X_\beta\to X_\alpha$
. Then since $\pi_\alpha$ is open and continuous so $\pi_\alpha^{-1}(A_\alpha) $ and $\pi_\alpha^{-1}(B_\alpha)$ is closed in $\prod_\alpha X_\alpha$ which is normal . So there exists two disjoint closed sets $U,V$ in $\prod_\alpha X_\alpha$ such that $\pi_\alpha^{-1}(A_\alpha) \subseteq U$ and $\pi_\alpha^{-1}(B_\alpha)\subseteq V$. Then $A_\alpha \subseteq \pi(U)$
and $B_\alpha \subseteq \pi(V)$ since $\pi$ is open and surjective.Obviously $\pi(U)\cap \pi(V)=\emptyset$ Looking forward to hear from you all.","['general-topology', 'proof-verification']"
1645590,"What is an example where we have convergence in distribution to a constant, but that doesn't imply convergence almost surely?","I have been trying to disprove that if I have a sequence of random variables $X_n$, that $X_n \to a$, where $a$ is a constant, in distribution doesn't imply $X_n \to a$ almost surely. One example I came up with was where $X_n \sim N(0, n)$. $X_n$ converges in distribution to $1/2$, but I am not sure how to show almost convergence fails here. Does anyone have a hint or know if this is a valid example? Thanks.","['probability-theory', 'convergence-divergence']"
1645612,Example of a Tensor Product of Modules with Non-Decomposable Elements,"Given a ring $R$ and $R$-modules $A_R$ and $_{R}B$, we define the tensor product $A \otimes_R B$ as the free abelian group on $A \times B$ modded out by the subgroup generated by the elements of the following form:
  $$
  (a+a',b)\!-\!(a,b)\!-\!(a',b) \quad\quad
  (a,b+b')\!-\!(a,b)\!-\!(a,b') \quad\quad
  (ar,b)\!-\!(a,rb)
$$
  Alternatively we can think of $A \otimes_R B$ as being generated by elements of the form $a \otimes b$ (which are called the decomposable elements) where $a \in A$ and $b \in B$, but not every element of $A \otimes_R B$ has to be a decomposable element that looks like $a \otimes b$. Are there good illustrative (concrete?) examples of modules $A$ and $B$ and a ring $R$ where $A \otimes_R B$ has non-decomposable elements? It seems like when working with concrete modules, for all the examples I've seen so far the tensor product is isomorphic to some nice group, which I think means that there are no non-decomposable elements to consider. Alternatively when working with tensor products abstractly you can treat the decomposable elements as a basis for $A \otimes_R B$ and not bother thinking about the non-decomposable elements. Either way, I'm missing an intuitive sense of what a tensor product with non-decomposable elements "" looks like .""","['abstract-algebra', 'modules', 'tensor-products']"
1645621,Solve the differential equation : $0.5 \frac{dy}{dx}=4.9-0.1y^2$,The question is to solve the differential equation : $$0.5 \frac{dy}{dx}=4.9-0.1y^2$$ What I have attempted: $$0.5 \frac{dy}{dx}=4.9-0.1y^2$$ $$ \frac{dy}{dx} = \frac{4.9-0.1y^2}{0.5} $$ $$ \frac{dy}{dx} = 9.8 - 0.2y^2 $$ $$ \int \frac{1}{9.8 - 0.2y^2} dy = \int 1 dx $$ $$ \int \frac{10}{98 - 2y^2} dy = \int 1 dx $$ $$ \int \frac{5}{49 - y^2} dy = \int 1 dx $$ $$ \int \frac{1}{49 - y^2} dy = \int \frac{1}{5} dx $$ How should I continue? EDIT Thanks @andrenicolas for the hint By using partial fractions $$ \int \frac{1}{(7-y)(7+y)} dy = \int \frac{1}{5} dx $$ $$ \frac{1}{14}\int \frac{1}{7-y} + \frac {1}{7+y} dy = \int \frac{1}{5} dx $$ $$ \frac{1}{14} [ ln |y+7| - ln|y-7| ] =  \frac{x}{5} + c$$ $$ [ ln |y+7| - ln|y-7| ] = \frac{14x}{5} + 14c $$ $$ ln\frac{y+7}{y-7} = \frac{14x}{5} + 14c $$ $$ \frac{y+7}{y-7} = Ae^{\frac{14x}{5}} $$ (Letting $A = 14c$ ) $$ y + 7 = yAe^{\frac{14x}{5}} - 7Ae^{\frac{14x}{5}} $$ $$ 7Ae^{\frac{14x}{5}} + 7 = yAe^{\frac{14x}{5}} - y $$ $$ 7Ae^{\frac{14x}{5}} + 7 = y(Ae^{\frac{14x}{5}} - 1) $$ $$ y = \frac{7Ae^{\frac{14x}{5}}}{(Ae^{\frac{14x}{5}} - 1)} $$,"['integration', 'ordinary-differential-equations']"
1645657,gradient of gradient is it Hessian?,"Say, I have a function $f(\vec{x}) = \cfrac{1}{2}\vec{x}^{T}Q\vec{x} - \vec{b}^T\vec{x}$, where $Q$ is Symmetric Positive Definite $\in R^{nxn}$. I want to find $\nabla f(\vec{x} - \nabla f(\vec{x}))$. So, am I solving this correctly like the following?
I know that,
\begin{equation}\nabla f(\vec{x}) = Q\vec{x}-\vec{b}\end{equation} 
So,
\begin{equation}\nabla f(\vec{x} - \nabla f(\vec{x})) = \end{equation}
\begin{equation}= (Q(\vec{x} - \nabla f(\vec{x})) - \vec{b})\nabla(\vec{x} - \nabla f(\vec{x})) = \end{equation}
\begin{equation}= (Q(\vec{x} - \nabla f(\vec{x})) - \vec{b})(\nabla\vec{x} - \nabla \nabla f(\vec{x})) = \end{equation}
\begin{equation}= (Q(\vec{x} - \nabla f(\vec{x})) - \vec{b})(\vec{1} - \nabla^2 f(\vec{x})) = \end{equation} So, can I say that $\nabla \vec{x} = \vec{1}\quad \text{and} \quad\nabla \nabla f(\vec{x}) = \nabla^2 f(\vec{x})$","['multivariable-calculus', 'matrix-calculus']"
1645661,Combinatorial proof of summation of $\sum_{k = 1}^{n-1} {n \choose k}= 2^1 + 2^2 + 2^3 +\ldots+ 2^{n-1}$,I am looking for a combinatorial proof for it. I know how to prove it mathematically. Expanding $(1+x)^n$ and replacing $x$ with $1$ will give me the result but I am not able to explain it combinatorially. Note: This is not a homework question. I am just curious.,"['combinations', 'combinatorics']"
1645742,Solving an exponential equation with different bases,"Solve the equation $2^x + 5^x = 3^x + 4^x$. I can figure out two special solutions $x=0$ and $x=1$, and I try to prove that they are the only two solutions. However, I find it hard to do so because I can't prove the monotony given there are also exponential in the derivative. Any hints to that?","['exponential-function', 'calculus']"
1645743,Trigonometric Function Simplification: $T_2 (x) = \cos (2 \arccos x)$,"Let $T_n (x) = \cos (n \arccos x)$ where $x$ is a real number, $x \in [–1, 1]$ and $n$ is a positive integer. Show that $$T_2 (x) = 2x^2 – 1.$$ My attempt: $T_2 (x) = \cos (2 \arccos x)$ Because an identity for $\cos(ab)$ doesn't exist, I do not how to simplify further to get to the solution.","['chebyshev-polynomials', 'trigonometry', 'calculus']"
1645747,Solution to $\frac{d}{d\frac{1}{x}} x$,"If I want to solve 
$$\frac{d}{d\frac{1}{x}} x$$
is my approach correct?
As
$$\begin{align*} \frac{d}{d\frac{1}{x}}x&=\\
\text{with }\frac{1}{x}&=y\\
\frac{d}{dy}\frac{1}{y}&=-\frac{1}{y^2}\\
&=-\frac{1}{\left(\frac{1}{x}\right)^2}\\
&=-x^2
\end{align*}$$
Is this approach correct, or did I miss something?","['derivatives', 'proof-verification']"
1645776,Evaluate $\sum_{n=1}^{\infty} \frac{n}{n^4+n^2+1}$,I am trying to re-learn some basic math and I realize I have forgotten most of it. Evaluate $$\sum_{n=1}^{\infty} \frac{n}{n^4+n^2+1}$$ Call the terms $S_n$ and the total sum $S$. $$S_n < \frac{1}{n^3} \Rightarrow \sum_{n=1}^{\infty} \frac{n}{n^4+n^2+1} = S <  \infty$$ $$S_n = \frac{n}{n^4+n^2+1} = \frac{n}{(n^2+1)^2-1}$$ It has been more than a few years since I did these things. I would like a hint about what method I should try to look for? Thanks.,"['real-analysis', 'sequences-and-series']"
1645809,"Find the Jordan normal form of a nilpotent matrix $N$ given the dimensions of the kernels of $N, N^2, N^3$","Let $N\in \text{Mat}(10 \times 10,\mathbb{C})$ be nilpotent. Furthermore let $\text{dim} \ker N =3 $, $\text{dim} \ker N^2=6$ and $\text{dim} \ker N^3=7$. What is the Jordan Normal Form? The only thing I know is that there have to be three blocks, since $\text{dim} \ker N = 3$. Thank you very much in advance for your help.","['matrices', 'jordan-normal-form', 'linear-algebra']"
1645825,"Calculate $P[A,B,C]$ from $P[A,B]$ and $P[B,C]$","I have 3 (not independent) events $A, B, C$ and I know everything about how any two of them correlate. For example, I know: $$ P[A], P[B], P[C], P[A,B], P[A,C], P[B,C], P[A|B], P[A|C], P[B|C], P[B|A], ...$$ Is there any way to use this information to calculate a correlation for the three of them, i.e. $$    P[A,B,C] \text{ or } P[A,B|C]  \text{ or } P[A|B,C] $$ A numerical algorithm would also be fine if there isn't an exact formula.
If it is not possible, is there a way to get a confidence interval for these values?","['statistics', 'probability', 'confidence-interval', 'correlation']"
1645878,Not all norms are equivalent in an infinite-dimensional space,"How to prove that not all norms are equivalent in an infinite-dimensional vector space? In particular, I would like to prove that for a space $X$ of continuous real-valued functions defined on interval $[0,1]$, every two norms $\|\ .\|_p$ ($p \in [1, \infty]$) are not equivalent.","['functional-analysis', 'normed-spaces']"
1645915,Find the limit $\lim_{n\to\infty}\left(\sqrt{n^2+n+1}-\left\lfloor\sqrt{n^2+n+1}\right\rfloor\right)$ [duplicate],"This question already has answers here : Evaluation of $\lim_{x\rightarrow \infty}\sqrt{x^2+x+1} -\lfloor \sqrt{x^2+x+1 }\rfloor\;,$ (4 answers) Closed 4 years ago . $$\lim_{n\to\infty}\left(\sqrt{n^2+n+1}-\left\lfloor\sqrt{n^2+n+1}\right\rfloor\right)\;=\;?\quad(n\in I) \\ \text{where $\lfloor\cdot\rfloor$ is the greatest integer function.}$$ This is what I did: Since $[x] = x - \{x\}$ we get our limit equal to
$$\lim_{n\to\infty}\left\{\sqrt{n^2+n+1}\right\}$$
Moving the limit inside the fractional part function and replacing $n=\frac 1h \; \text {where } h\to0^+$ we get
$$\left\{\lim_{h\to0^+} \frac{\sqrt{h^2+h+1}}h\right\}$$ Applying L'Hospital Rule, we get our limit equal to $\left\{\frac 12\right\}$ which is $0$. The problem: The answer in the answer key is $\frac12$. So here, the only problem I seem to find in my solution is that $n\in I$ and simply assuming $n = \frac 1h$ doesn't ensure our $n$ to be an integer. Can anyone provide a way to either correctly assume a new value for $n$ or any alternate way to solve this?","['radicals', 'limits', 'integers', 'sequences-and-series', 'ceiling-and-floor-functions']"
1645967,What do we actually prove using induction theorem?,"Here is the picture of the page of the book, I am reading: $$P_k: \qquad 1+3+5+\dots+(2k-1)=k^2$$
  Now we want to show that this assumption implies that $P_{k+1}$ is also a true statement:
  $$P_{k+1}: \qquad 1+3+5+\dots+(2k-1)+(2k+1)=(k+1)^2.$$
  Since we have assumed that $P_k$ is true, we can perform operations on this equation.
  Note that the left side of $P_{k+1}$ is the left side of $P_k$ plus $(2k+1)$.
  So we start by adding $(2k+1)$ to both sides of $P_k$:
  \begin{align*}
1+3+\dots+(2k-1) &= k^2  &P_k\\
1+3+\dots+(2k-1)+(2k+1) &= k^2+(2k+1) &\text{Add $(2k+1)$ to both sides.}
\end{align*}
  Factoring the right side of this equation, we have
  $$1+3+\dots+(2k-1)+(2k+1) =(k+1)^2 \qquad P_{k+1}$$
  But this last equation is $P_{k+1}$. 
  Thus, we have started with $P_k$, the statement we assumed true, and performed valid operations to produce $P_{k+1}$, the statement we want to be true. 
  In other words, we have shown that if $P_k$ is true, then $P_{k+1}$ is also true. 
  Since both conditions in Theorem 1 are satisfied, $P_n$ is true for all positive integers $n$. In the top line there is written that we have to show that 'the assumption $P_k$ is true implies $P_{k+1}$ is true'. And what I think is that: as long as we know that the state of a proposition being true for any positive integer $k$ after Base number implies that proposition is true for integer $k+1$, we have to show that $P_k$ is true. However I don't have an idea yet how to show the truth of $P_k$. So, my first question is that who is right? My book or me? And if I am right then how can I show the truth of $P_k$? 2) This may be taken as the second question but it is also bit annoying. In the second paragraph it is written, ""Since we have assumed that $P_k$ is true, we can perform operations on it"". Why is it necessary for an equation to be true for performing operations on it? Well, this is not much annoying as compared to the first question because whole the induction theory depends upon that.","['induction', 'discrete-mathematics']"
1645984,"How to compute $[\dot c, X]$ on a manifold?","Consider a smooth curve $c : [0,1] \to M$ and $X \in \mathcal X (M)$. How can one obtain an explicit formula for $[\dot c, X]$? I know the theoretical approach: for every $t \in [0,1]$ there exist a neighbourhood $U_t$ of $c(t)$ and a local tangent field $C_t \in \mathcal X (U_t)$ that extends $\dot c$, so one computes $[C_t, X]$ and then evaluates it at $c(t)$. Theory is nice, but putting it into practice does not look obvious; how should I do it? Concretely, the problem is that in local coordinates and choosing $X = \partial _i$ I would obtain $- \sum \limits _j (\partial _i C_t ^j) \partial _j$. How would I evaluate $\partial _i C_t ^j$ in $c(t)$? In other words, how do I compute $\partial _i \dot c ^j$?","['derivatives', 'lie-derivative', 'smooth-manifolds', 'curves', 'differential-geometry']"
1646008,Derivative of $l_1$ norm,"I want to compute the following derivative with respect to $n\times1$ vector $\mathbf x$. 
$$g = \left\lVert \mathbf x - A \mathbf x  \right\rVert_1 $$ My work: $$g = \left\lVert \mathbf x - A \mathbf x  \right\rVert_1  = \sum_{i=1}^{n} \lvert x_i - (A\mathbf x)_i\rvert = \sum_{i=1}^{n} \lvert x_i - A_i \cdot \mathbf x \rvert = \sum_{i=1}^{n} \lvert x_i - \sum_{j=1}^n a_{ij} x_j\rvert$$ 
So the $k$th element of derivative is: $$\frac{\partial g}{\partial x_k} = \frac{\partial }{\partial x_k}\sum_{i=1}^n \lvert x_i - \sum_{j=1}^n a_{ij} x_j\rvert $$
$$= \frac{\partial }{\partial x_k}\bigg(\lvert x_1 - \sum_{j=1}^n a_{1j} x_j\rvert +\cdots+ \lvert x_k - \sum_{j=1}^n a_{kj} x_j\rvert + \cdots\lvert x_n - \sum_{j=1}^n a_{nj} x_j\rvert  \bigg)$$
$$ =-a_{1k}sign(x_1 - \sum_{j=1}^n a_{1j} x_j)-\cdots+(1-a_{kk})sign(x_k - \sum_{j=1}^n a_{kj} x_j)-\cdots -a_{nk}sign(x_n - \sum_{j=1}^n a_{nj} x_j)$$ And my questions: Is this derivation correct? How I can represent the answer compactly? Can you introduce me a source to master this material? Thanks.","['normed-spaces', 'partial-derivative', 'linear-algebra']"
1646014,Upper bound for difference of Poisson random variables,"Let $X, Y$ be random variables with Poisson$(\lambda)$ and Poisson$(2\lambda)$ distributions, respectively.Then (i) If we assume that $X, Y$ are independent, $$\mathbb{P}(X \geq Y) \leq e^{-(3-\sqrt8)\lambda}.$$ (ii) Now, assume that $X, Y$ are not independent, then there exist $A, c >0$,  both not depending on $\lambda$, such that $$\mathbb{P}(X \geq Y) \leq Ae^{-c\lambda}.$$ I have no idea how to solve this problems. I try setting $Z = X - Y$, but I do not know how to find the upper bound, and how that $e^{-(3 - \sqrt8)\lambda}$ comes from. Note: $X$ has a Poisson$(\lambda)$ distribution if, for any integer $j\geq 0$, $$\mathbb{P}(X = j) = \frac{\lambda^je^{-j}}{j!}.$$","['probability-theory', 'probability', 'probability-distributions']"
1646020,subgroup having index $2$ of $R^*$,The question is to find all the subgroups of $R^*$ (non-zero reals under multiplication) of index $2$. The index can be found out for finite groups. How to find subgroups having certain index for an infinte group? The index is also the no. of distinct cosets(left/right). Is it the way to proceed to the answer? Please put light into it.,"['abstract-algebra', 'group-theory']"
1646096,"Is $\{\frac{m}{10^n}\mid m,n\in\mathbb Z,\ n\geq 0\}$ dense in $\mathbb R$?","The set $S$ of real numbers of the form $m/10^n$, $m,n$ integers and $n$ greater than or equal to $0$, is a dense subset of $\mathbb R$ or not?? I know dense means closure of $S$ in $\mathbb R$ is $\mathbb R$ then it will be dense. How to prove or disprove I have no idea.","['real-analysis', 'analysis']"
1646101,Distribution of the sum of $N$ loaded dice rolls,"I would like to calculate the probability distribution of the sum of all the faces of $N$ dice rolls. The face probabilities ${p_i}$ are know, but are not $1 \over 6$.
I have found answers for the case of a fair dice (i.e. $p_i={1 \over 6}$) here and here For large $N$ I could apply the central limit theorem and use a normal distribution, but I don't know how to proceed for small $N$. (In particular, $N=2,4, 20$)","['probability', 'integer-partitions', 'dice', 'probability-distributions']"
1646134,"What is the partial derivative of $f(x,y(x))$?","What is the total derivative of $f(x,y(x,z))$ with respect to $x$? Is it $$\frac{\partial f}{\partial x}+\frac{\partial f}{\partial y}\frac{\partial y}{\partial x}?$$
If this is correct, what is $\frac{\partial f}{\partial x}$? It seems to me that partial $f$ partial $x$ is equal to the derivative of $f$ with respect to $x$. What is the difference? I mean, suppose $f(x,y(x,z))=x^2+y(x,z)$ and $y(x,z)=x^2+z.$ So we have $f(x,y(x,z))=2x^2+z.$ Hence $\frac{\partial f}{\partial x}=4x.$ On the other hand, $\frac{df}{dx}=\frac{\partial f}{\partial x}+\frac{\partial f}{\partial y}\frac{\partial y}{\partial x}=4x+1\cdot 2x=6x.$ Am I making a mistake?","['derivatives', 'calculus']"
1646146,Intuition behind: Integral operator as generalization of matrix multiplication,"So I am teaching myself more in-depth about integral operators and every once and awhile I see this little 'factoid', that integral operators are generalizations of matrix multiplications. In particular, if: $$Lf(x) = \int_{X} k(x,y) f(y) du(y)$$ So then, naturally, if $\mathbf{A}$ is an $m,n$ matrix with entries $a_{ij}$ and $\mathbf{u} \in \mathcal{C}^{n}$, $\mathbf{A}\mathbf{u} \in \mathcal{C}^{m}$, we have: $(\mathbf{A}\mathbf{u})_{i} = \sum_{j=1}^{n} a_{ij} u_{j}, i=1 \ldots m$ So I always see something similar to the following statement: The entries $k(x,y)$ are analogous to the entries $a_{ij}$ of matrix $\mathbf{A}$ and the values $Lf(x)$ are analogous to the entries $(\mathbf{A}\mathbf{u})_{i}$ I have never seen any example or more detail regarding this statement. Can somebody make this a bit clearer? Here is my thought, the $x$ defines the 'row', while the $y$ defines the column. So then if we wanted to, we could define a sequence $\{x_{0}, x_{1}, \ldots\}$ to then 'sample' the output of the operator integral $L$. For instance, if $L$ mapped $f$ to a certain region $P$, we would want to define our sequence to exist only in this region $P$ in order to save computation. If in this region, the functions $Lf$ had significant norm/power only in a subspace or section of this region $P_{k}$, we could 'sample' this subspace only -- ie $\{x_{0}, x_{1}, \ldots\} \in P_{k}$ and still get a 'reasonable' approximation to the resulting function/signal $Lf$. Similarly, we could 'sample' $f$ on its domain with  $\{y_{0}, y_{1}, \ldots\}$ and reduce the computation even further, when the sequence captures 'most of the information' about $f$ that is.","['matrices', 'operator-theory', 'functional-analysis', 'integration', 'integral-operators']"
1646202,Calculating (co)limits of ringed spaces in $\mathbf{Top}$,"Let $\mathbf{Top}$ be the category of topological spaces, $\mathbf{RS}$ the category of ringed spaces and $\mathbf{LRS}$ the category of locally ringed spaces . There are forgetful functors
$$
U_{\mathbf{LRS}}: \mathbf{LRS} \to \mathbf{RS}
$$
(the inclusion of the (non-full) subcategory) and
$$
U_{\mathbf{RS}}: \mathbf{RS} \to \mathbf{Top}
$$
(forgetting the structure sheaf). All three categories have all (small) limits and colimits. Are $U_{\mathbf{LRS}}$ and $U_{\mathbf{RS}}$ (right?) adjoint functors? Do $U_{\mathbf{LRS}}$ and $U_{\mathbf{RS}}$ perserve pushouts? I am interested in these questions because I can think easier of topological spaces than of ringed (or locally ringed) spaces. For example, when I intuitively want to see what the pushout of two (locally) ringed spaces is, I want to see first what happens on topological spaces and afterwards think of what is going on with the structure sheaves. Am I allowed to do this?","['category-theory', 'limits-colimits', 'ringed-spaces', 'algebraic-geometry']"
1646205,Compact sets in the product of topological spaces.,"Let $G_1$ be a non-compact topological space and let $G_2$ be a generic topological space. What are the compact sets in the product $G_1\times G_2$?
Surely we can take the sets of the form $K_1\times K_2$ where $K_1$ and $K_2$ are respectively compact sets of $G_1$ and $G_2$. Is this right? What are the others?",['general-topology']
1646211,"$\iiint_V \ x^{2n} + y^{2n} + z^{2n} \,dx\,dy\,dz$","$$\iiint_V \ x^{2n} + y^{2n} + z^{2n} \,dx\,dy\,dz$$ where V is the unit sphere. No information is given about n but I assume it is an integral. All I could think to do was to convert to spherical co-ordinates and use reduction formulae, but I ended up with really messy answers. Any help would be brilliant.",['integration']
1646253,Prove by contradiction Irrational number,"I Need to prove this by contradiction : If $a$ is Irrational then  $\frac{2a-3}{2a+3}$ is Irrational. I did: Iff $p$ is Irrational, then  $\frac{2a-3}{2a+3}$ is Rational and a Rational number can be written as $\frac{p}{q}$ where p and q are integers and q is different than zero so, $\dfrac{2a-3}{2a+3}=\dfrac{p}{q}$ which is $$q(2a-3)=p(2a+3)=$$ $$2aq-3q=2ap+3p=$$ $$2aq-2ap=3p+3q=$$ $$a=\frac{3p+3q}{2q-2p},$$ therefore $a$ is rational and $2q-2p$ cannot be zero. So I proved it by contradiction. Am I doing it right? can anyone help me? Thanks",['discrete-mathematics']
