question_id,title,body,tags
3611312,Finding the triangle with the maximum area with a given perimeter,"Question: Of all triangles with a given perimeter, find the triangle with the maximum area. Justify your answer. My approach: Let us have any $\Delta ABC$ such that the sides opposite to $A$ is of length $a$ , the side opposite to $B$ is of length b and the side opposite to $C$ is of length $c$ . Now since the perimeter to $\Delta ABC$ is fixed, thus we must have $P=a+b+c$ to be constant. Now fix any side of the triangle, let us fix $BC$ . Therefore $b+c=P-a$ , which implies that $b+c$ is constant. Thus the locus of the point $A$ must be an ellipse having one of it's axis as the side $BC$ . Now let us select any point $A$ on the ellipse and drop a perpendicular to the axis $BC$ . Let it meet the major axis at $P$ . Now let $AP=h$ . Therefore, the area of the $\Delta ABC=\frac{1}{2}.h.BC=\frac{1}{2}.h.a.$ Now since $\frac{1}{2}a$ is constant, implies the area of $\Delta ABC$ can be maximized by maximizing $h$ . Now clearly $h$ attains it's maximum value when it coincides with the other axis of the ellipse under consideration, that is when $AB=AC$ . Thus $\Delta ABC$ must be isosceles with $AB=AC$ to get a maximum value of the area of $\Delta ABC$ . Thus it is clear that the triangle which will have the maximum area must be one of the isosceles triangles $ABC$ having $BC$ as the base. Thus in any such $\Delta ABC$ , we must have $a+b+c=a+2b \hspace{0.2 cm}(\because b=c)=P\implies b=\frac{1}{2}(P-a).$ Thus by Heron's formula we have $$|\Delta ABC|=\sqrt{\frac{P}{2}\left(\frac{P}{2}-a\right)\left(\frac{a}{2}\right)\left(\frac{a}{2}\right)}=\frac{a\sqrt{P}}{4}\sqrt{P-2a}.$$ Now to obtain the condition for maximizing $|\Delta ABC|$ we have to check when $\frac{d}{da}\frac{a\sqrt{P}}{4}\sqrt{P-2a}=0.$ Now $$\frac{d}{da}\frac{a\sqrt{P}}{4}\sqrt{P-2a}=0\\\iff (P-2a)^{1/2}-a(P-2a)^{-1/2}=0\\\iff P-2a=a\\\iff 3a=P\\\iff a=\frac{P}{3}.$$ Now note that $\frac{d^2}{da^2}|\Delta ABC|<0$ , which implies that $|\Delta ABC|$ attain it's maximum value when $a=\frac{P}{3}.$ This implies that $b=c=\frac{P}{3}$ . Thus we have $a=b=c=\frac{P}{3}$ . Therefore, $|\Delta ABC|$ is maximized if and only if $a=b=c$ , i.e, the triangle is equilateral. Can someone check if this solution is correct or not? And other solutions are welcomed. Please ensure that the solutions are based on geometry and one-variable calculus. This problem can be solved using Lagrange multipliers or multi-variable calculus, but I do not want a solution using the same.","['optimization', 'calculus', 'solution-verification', 'geometry']"
3611330,"The generality of ""neusis plus""","Consider the following progression of facts relating to geometric construction with a limited set of tools: With only a compass and unmarked straightedge, we can only construct numbers that lie in a tower of degree- $2$ field extensions of the rational numbers. We can only take square roots, and we cannot construct the heptagon. If we place two marks separated by a distance of $1$ on the straightedge, we obtain neusis. If we only place the marks on straight lines, the tower of extensions can now include degree- $3$ extensions . We can take cube roots, trisect the angle and construct the heptagon, but not the hendecagon. If we now allow placing the marks on a line and a circle or on two circles, degree- $5$ and $6$ extensions are available. We can construct the hendecagon. And so this question is about the logical next step in the progression. Suppose we can now transfer the distance between any two constructed points back onto the straightedge . Using this ""neusis plus"" system, can we construct all algebraic numbers? If not, what degrees of field extensions can we achieve? To illustrate the process of making new marks on the straightedge, suppose you have constructed two points separated by $\sqrt2$ . You can place the straightedge against those two points and, with a fine pencil, draw short lines from the points onto your straightedge. These marks are separated by exactly $\sqrt2$ and can be used for later neusis steps.","['polynomials', 'geometry', 'geometric-construction']"
3611376,Can you explain the difference between the sphere $S^5$ and the manifold $S^3 \times S^2$?,"If a cube is suspended in mid air with rubber wires inside a hollow glass sphere, its orientations realizes the sphere $S^3$ , also called SU(2), which is the the double cover of SO(3). (Is this correct?) If the glass sphere is swimming on water and rotating, the rotation axis of the glass sphere has two angles describing its orientation in space. Is this $S^5$ or is it $S^3 \times S^2$ ? How can I see the difference?",['differential-geometry']
3611468,Section continuity implies continuity,"We know that a function $f: R^2\to R$ that is section-continuous (that is each $x\mapsto f(x,y)$ and $ y\mapsto f(x,y)$ are continuous) need not be continuous. $f(x,y)=\frac{xy}{x^2+y^2}\chi_{\{0\}^c}$ is a counterexample for such a claim. However apparently if add the condition that $f$ maps compact sets to compact sets, then $f$ is continuous. Note the the converse is always true, that is continuous maps send compact sets to compact sets. I was wondering why that original condition is true? that is section continuous functions that send compact sets to compact sets must be continuous.","['continuity', 'general-topology', 'compactness']"
3611495,"Asymptotic distribution of U-statistic based ""log-likelihood""","This is question 4.2c from John Duchi's course Stats 300b at Stanford: http://web.stanford.edu/class/stats300b/Exercises/all-exercises.pdf Consider the U-statistic-based ""Log-likelihood"" type objective: $$L_n(\theta) = {n \choose 2}^{-1} \sum_{i,j}^n 1\{Y_i > Y_j\} \log P_{\theta}(Y_i > Y_j | x_i, x_j) $$ where we have $n$ samples of $(Y_i, x_i)$ such that: $$Y_i = x_i^T \theta + \epsilon_i$$ $$\epsilon_i ∼ N(0, 1)$$ $$E[x_i] = 0, Cov[x_i] = \Sigma$$ Let $\hat{\theta}_n = argmax_{\theta} L_n(\theta)$ and assuming that $\hat{\theta}_n$ is consistent for the true $\theta$ : Find the asymptotic distribution of $\hat{\theta}_n$ . My approach has been (using theorem 5.23 from Asymptotic Statistics by Van der Vaart) to seek the asymptotic distribution of $\sqrt{n}(\hat\theta_n - \theta)$ which under suitable regularity conditions is asymptotically normal with mean $0$ and variance: $$V_\theta^{-1}E[\nabla L_n \nabla L_n^T]V_\theta^{-1}$$ where $V_\theta^{-1} = E[\nabla^2L_n]$ and expectation is taken with respect to data and derivatives are taken with respect to $\theta$ . My difficulty has been in evaluating these expectations to determine the variance of this estimator. $\nabla L_n$ looks like a U-statistic with kernel $h(x_1, x_2) = 1\{Y_i > Y_j\}\nabla_\theta \log P_{\theta}(Y_1 > Y_2 | x_1, x_2)$ . So, $\sqrt{n}(\nabla L_n - E[\nabla L_n])$ is asymptotically $N(0, 2^2\xi_1)$ where $\xi_1$ is the variance of : $$\xi_1 = Cov(h(X, X_i), h(X, X_j)) = E(h(X, X_i)h(X, X_j)) - E(h(X, X_i)) E(h(X, X_j))$$ But I'm also having trouble evaluating this covariance. EDIT: A friend showed me a few tricks, but I dont seem much closer to having a neat closed form (if there is one). At a closer look, $L_N$ is not a log-likelihood, so let's go after $V_\theta$ and $E[\nabla L_n \nabla L_n^T]$ to apply theorem 5.23 directly. First, we have: $$\log P_{\theta}(Y_i > Y_j | x_i, x_j) = \log P_{\theta}(\epsilon_j - \epsilon_i < (x_i - x_j)^T\theta | x_i, x_j) = \log \Phi \bigg(\frac{(x_i-x_j)^T\theta}{\sqrt2}\bigg)$$ Evaluating $\xi_1$ we have for the first moment: $$E(h(X, X_i)) = E [1_i\frac{(X - X_i)\phi(\gamma_i)}{\Phi(\gamma_i)}]$$ where $\gamma_i = \frac{(X - X_i)^T\theta}{\sqrt{2}}$ and $1_i = 1\{Y > Y_i\}$ . By conditioning on the event in the indicator and applying the tower property of expectation: $$ = E [(X - X_i)\phi(\gamma_i)] $$ which is equal to $0$ by symmetry. So, $$\xi_1 = E [(1_i\frac{(X - X_i)\phi(\gamma_i)}{\Phi(\gamma_i)})(1_j\frac{(X - X_j)\phi(\gamma_j)}{\Phi(\gamma_j)})^T]$$ Simplifying as before: $$= E [\phi(\gamma_i)\phi(\gamma_j)(X - X_i)(X - X_i)^T$$ Which I cannot simplify any further. Applying similar simplifications to $\nabla^2 L_n(\theta)$ we have: $$\nabla^2 L_n(\theta) = -\frac{\phi(\gamma_{ij})^2}{\Phi(\gamma_{ij})}(X_i-X_j)(X_i-X_j)^T/2$$ where $\gamma = \frac{(X_i-X_j)^T\theta}{\sqrt2}$ . EDIT: Using this expression to simulate the asymptotic variance, we get what we expect intuitively, this estimator works better than the least-squares estimator when the variance of the noise term $\epsilon$ is smaller than that of the covariates $x_i$ . The following log-log plot shows the relationship for the 1-D case between the variance and $var(\epsilon)$ where $x$ is sampled from $N(0,1)$ . The relationship is even more dramatic when $x\sim  cauchy$ . An interesting followup question would be: can we find a variance stabilizing transform, such that the asymptotic variance no longer depends on the parameter in question?","['weak-convergence', 'statistics', 'probability-theory', 'asymptotics']"
3611517,What is the square root of the quadratic form $x^T A x$?,"If $x \in \mathbb R^N$ and $A \in \mathbb R^{N \times N}$ , is it possible to find a root of the quadratic form $x^T A x$ of the form $$\sqrt{x^T A x} = b^T x$$ for all $x \in \mathbb R^N$ , where $b \in \mathbb R^N$ ?","['matrices', 'radicals', 'quadratic-forms']"
3611608,Why is the one quadratic polynomial a perfect square more often than the other?,"I was solving problem 137 of Project Euler, which led me to find $n$ such that $5n^2+2n+1$ is a perfect square. But such numbers are very rare (the 13th is around 3 billions) so after decomposing into $(n+1)^2 + (2n)^2 = m^2$ and looking for Pythagorean triples and their $(a^2-b^2,2ab,a^2+b^2)$ generation, I ended up having to look for $k$ such that $5k^2+4$ is a perfect square. This is a much easier task, which retrospectively makes sense since every $k$ will lead to some $n=O(k^2)$ , so you only need to iterate to $10^5$ to find the $13$ th number. Question So we proved that there are more squares in $5n^2+4$ than in $5n^2+2n+1$ . Was there an easier way to spot this without pulling out the Pythagorean triple trick? Is there an intuitive reason or more generic underlying principle solely by looking at the equations?","['number-theory', 'pythagorean-triples', 'project-euler', 'elementary-number-theory']"
3611807,Application of Blumenthal's Zero-One Law to Brownian Motion,"Let $W_t$ be a Brownian motion.  I wish to show that the stopping time $\tau \equiv \inf\left\{t \ge 0 : W_t >0\right\} = 0$ almost surely. We have $$\{\tau = 0\} = \bigcap_{k=1}^\infty \quad\bigcup_{0 \leq t < \frac{1}{k}, t \in \mathbb{Q}} \{W_t > 0\} = \bigcap_{k=m}^\infty \quad \underbrace{\bigcup_{0 \leq t < \frac{1}{k}, t \in \mathbb{Q}} \{W_t > 0\}}_{\in \mathcal{F}_{1/m}^0 \forall m \in \mathbb{N}} \in \bigcap_{m=1}^\infty \mathcal{F}_{1/m}^0 = \mathcal{F}_0^+ $$ Thus by Blumenthal's zero one law, we have $P(\tau = 0) \in \{0, 1\}$ so it suffices to show that $P(\tau = 0) > 0$ but I find this impossible.  Please help if you can.","['stochastic-processes', 'stopping-times', 'brownian-motion', 'probability-theory']"
3611808,Why should we use the uniform boundedness principle here?,"Here is the question: Let $A = [a_{ij}]_{i,j = 1}^{\infty}$ be an infinite matrix of real numbers and suppose that, for any $x \in \ell^2,$ the sequence $Ax$ belongs to $\ell^2.$ Prove that the operator $T,$ defined by $T(x) = Ax,$ is a bounded operator on $\ell^2.$ My question is: I got a hint to use the uniform boundedness principle here but I do not know why, could anyone explain this to me, please? what makes me when I look at a problem to decide that it should be solved by UBP? EDIT: 1-I have taken this proposition: ""The series $\sum_{n =1}^{\infty} a_{n} b_{n}$ converges absolutely for every convergent sequence $\{b_{n}\}$ iff $\sum_{n =1}^{\infty} |a_{n}|$ converges."" will it be helpful here in our case? the problem is that here in our case we are in $l^2.$ 2-Also, Should it be better to use the uniform boundedness principle or the following theorem to solve the problem given above? Theorem: Let $X,Y$ be Banach spaces and let $\{T_{n}\}_{n=1}^{\infty}$ and $T$ be operators in $\mathcal{L}(X,Y).$ then $\lim_{n} T_{n}x = Tx,$ for all $x \in X,$ iff (a)the sequence $\{T_{n}\}$ is bounded; (b)lim_{n} T_{n}x exists on a dense subset of $X.$","['normed-spaces', 'functional-analysis', 'metric-spaces']"
3611846,Fuglede's theorem in finite-dimensional vector space,"Let $V$ be a finite dimensional vector space and $A$ be normal operator on $V$ and $B$ is an operator such that $AB=BA$ . Show that $BA^*=A^*B$ . I guess that this problem should not be so difficult. I have tried different approaches and I got some identities which do not lead to desired equality. So I would be thankful if you show the solution to this problem, please!",['linear-algebra']
3611850,Computing the binomial sum $\sum_{0\le i<j\le n}j\binom ni$,"Find the sum $$\sum_{0\le i<j\le n}j\binom ni.$$ My 1st attempt: replacing $j$ with $n-j$ . So the expression turns out to be $$S=\sum n\binom ni-\sum j\binom ni$$ So adding the original and the final expression we get simply $S=n2^{n-1}$ . My second attempt: considering 3 parts: Part 1: $i=j$ , $\sum_{i=j}i\binom ni= n2^{n-1}$ Part 2: $i<j$ and $i>j$ they are equivalent, so we get $2S$ Part 3 : taking $i\in[0..n]$ and $j=[0..n]$ which gives $\frac{n(n+1)}22^n$ Combining all the parts I get $n^22^{n-2}$ . But none of my answers match with the given answer.","['summation', 'binomial-coefficients', 'combinatorics', 'binomial-theorem']"
3611857,Finding homomorphism for a specific kernel,"I'm trying to find an homomorphism from $Z_{4} \times Z_{6}$ to $Z_{4} \times Z_{2}$ with kernel $\langle (0,2) \rangle$ . How can I show there exists such homomorphism and how do I actually find the homomorphism? I know $Z_{4} \times Z_{6}$ is abelian and $\langle (0,2) \rangle $ is a normal subgroup of $Z_{4} \times Z_{6}$ , but I'm pretty much stuck there...","['group-homomorphism', 'normal-subgroups', 'abstract-algebra', 'group-theory', 'abelian-groups']"
3611867,Showing a bijection between binary string sets.,"I am working on showing a bijection between two sets: $B^6$ and $E_{10}$ . Here is the problem: Let $B = {0, 1}$ . $B^n$ is the set of binary strings with $n$ bits. Define the set $E_n$ to be the set of binary strings with $n$ bits that have an even number of 1's. Note that zero is an even number, so a string with zero 1's (i.e., a string that is all 0's) has an even number of 1's. Show a bijection between $B^9$ and $E_{10}$ . Explain why your function is a bijection. Here is my answer: Suppose $x \in B^9$ . We know an odd number is the result of an even number plus an odd number. Since there are only 9 digits for each $x \in B^9$ , and 9 is an odd number, this means that if there are an odd number of 1’s in x then there will be an even number of 0’s in x. Further, if there are an even number of 1’s in x then there will be an odd number of 0’s in x. Therefore, each $x \in B^9$ will have either an odd or even amount of 1’s. We could write a function f to say that if x has an odd number of 1’s, then append a 1, which would give us an even number of 1’s. We could also say that if x has an even number of 1’s than append a 0, which would then keep the number of 1’s even. Assuming each $x \in B^9$ is unique, according to our function we will be adding either a 1 or a 0 to the end of the string, which would produce a new unique string with 10 bits. For example, $f(100011000)=1000110001$ . This means that the function is injective (one-to-one) function because each element in the domain is mapped to 1 distinct element in the codomain. We can also have an inverse function $f^{-1}$ which removes the last binary digit from each $y \in E_{10}$ . $E_{10}$ is defined to be the set where each element from $B^9$ has a 1 or 0 appended to it, and thus producing a distinct element. Removing the end 1 or 0 from this new string produces the distinct unique element that was in $B^9$ . For example, $f^{-1}(1000110001)=100011000$ . This means each element in $E_{10}$ can be mapped to at least one unique $x \in B^9$ , meaning the function is onto Since the function is both one-to-one and onto, then it is a bijection. I feel like there is a much simpler way of showing this, and not really sure if I made a good case in the first place. I was hoping someone could provide a different way to think about this problem or provide some insight so that I can formulate a better answer. Thank you all so much!",['discrete-mathematics']
3611893,What is the geometric significance of differentiable vs continuously differentiable?,"What is the geometric significance of differentiable vs continuously differentiable for functions (based on $\mathbb{R}$ )?  By 'geometric' i mean the appearance of the plot of such functions. Perhaps this question is best splilt into three categories: $\mathbb{R}$ to $\mathbb{R}^n$ , $\mathbb{R}^n$ to $\mathbb{R}$ , and $\mathbb{R}^n$ to $\mathbb{R}^m$ .","['analysis', 'real-analysis']"
3611922,Finite generation of a subset of an algebraic structure.,"Consider the set $\mathbb{N}^n$ of $n$ tuples of positive integers, with the following partially defined ""operations"" $\oplus_i$ . This operation takes in two vectors $A=(a_1,..a_i,...a_n)$ , $B=(b_1,..b_i,...b_n)$ , such that $a_j=b_j$ for $j\neq i$ and outputs $A\oplus_i B:=(a_1,...,a_i+b_i,...a_n)=(b_1,...,a_i+b_i,...b_n)$ . The question is then, given a subset $S$ of $\mathbb{N}^n$ , such that $S$ is closed under $\oplus_i$ for all $i$ , can we find finitely many elements $A_1,...A_m\in S$ such that $S$ is generated by these elements under the operations $\oplus_i$ ? This is not a (totally) arbitrary question to consider, it arises from writing the operation of concatenating (multidimensional) rectangles in a (multidimensional) grid, and asking whether any such set is generated by a finite number of rectangles. I'm not quite sure how to tag this question, so please add/remove tags if these aren't suitable.","['number-theory', 'combinatorics', 'discrete-mathematics']"
3611964,Evaluate $\sum _{n=1}^{\infty } \frac{1}{n^5 2^n \binom{3 n}{n}}$ in terms of elementary constants,"How can we evaluate $$\sum _{n=1}^{\infty } \frac{1}{n^5 2^n \binom{3 n}{n}}$$ Related: $\sum _{n=1}^{\infty } \frac{1}{n^4 2^n \binom{3 n}{n}}$ is solved recently (see here for the solution) by elementary method, so I wonder if a generalization to weight $5$ can be made.","['definite-integrals', 'harmonic-numbers', 'polylogarithm', 'closed-form', 'sequences-and-series']"
3611984,Compact and connected set in $\mathbb{R}^2$ which is locally path-connected at only one point?,"Given a compact and connected set $A$ in $\mathbb{R}^2$ . Can it be locally path-connected at only one point? And can it be locally path-connected at every point except one? My thought First I thought of the topological sine curve, which is compact and connected but not locally path-connected. But it doesn't solve the problems. Then I tried to construct a space that is locally path-connected at every point except one as $$
A=\{(t\cos x,t\sin x):\cos x\in \mathbb{Q} , t\in[0,1]\}
$$ But this is not compact. Do such spaces exist? Any hints would be highly appreciated.",['general-topology']
3612123,Different solutions with different results for an inequality,"Find m such that the following inequality: $$\left|4x-2m-\frac{1}{2}\right| > -x^2 +2x + \frac{1}{2} - m$$ is always true for $\forall x \in R$ . 1st solution: 1st case $$4x-2m-\frac{1}{2} > -x^2 + 2x +\frac{1}{2} -m$$ $$<=>x^2+2x-m-1>0$$ $$\Leftrightarrow 1^2+(m+1)< 0$$ $$\Leftrightarrow m<- 2$$ 2nd case $$4x-2m-\frac{1}{2}< -(-x^2 + 2x +\frac{1}{2} -m)$$ $$\Leftrightarrow x^2-6x+3m>0$$ $$\Leftrightarrow 3^2-3m<0$$ $$\Leftrightarrow m>3$$ 2nd solution: The inequality is the same as: $$(x-1)^2+|4x-2m-\frac{1}{2}|>\frac{3}{2}-m$$ Since the left-hand side is always positive, in order for the inequality to be always true, $\frac{3}{2}-m$ has to be negative, or $m > \frac{3}{2}$ The 2 solutions give different answers, so I was quite confused But I get more confused as Wolfram Alpha gives me the solution: $$m > \sqrt{3} - \frac{1}{4} \text{  or  } m < -\sqrt{3} - \frac{1}{4} $$ There's a high chance that Wolfram Alpha's solution is correct (after testing out some $m$ value). How do I approach their solution? (Or maybe if you believe that solution is wrong, then what's the exact solution to the problem?)","['inequality', 'absolute-value', 'solution-verification', 'algebra-precalculus', 'quadratics']"
3612150,"By definition of $\mathbb E(X\mid \sigma(Y))$ calculate $\mathbb E(X\mid Y=y)$ when $(X,Y)$ is absolutely continuous","By definition of $\mathbb E(X\mid \sigma(Y))$ , I want to show that $$\mathbb E(X\mid Y=y)=\int xf(x\mid Y=y) dx.$$ I want to know is my steps  right or no. It is important to me since in preliminary  probability books we define $\mathbb P(A\mid B)=\frac{\mathbb P(A\cap B)}{\mathbb P(B)}$ so if $\mathbb P(B)=0$ we can not use it to calculate some case $f(X\mid Y=y)$ , when $Y$ is continuous. I also want to find the new definition (based on conditional expectation with respect to sigma field) exactly same as old definition ( $\mathbb E(X\mid Y=y) =\int x f(x\mid y) dx$ ) By definition of $\mathbb E(X\mid\sigma(Y))$ , $\forall A\in \sigma(Y)$ , $$\mathbb E\big(\mathbb E(X\mid \sigma(Y))1_A \big)=\mathbb E(X\, 1_A )$$ I think $1_A$ is a function of $Y$ (??) since $A\in \sigma(Y)$ . So I think I can write $$\mathbb E\bigg(\mathbb E(X\mid \sigma(Y))1_B(Y) \bigg)=\mathbb E(X\,1_B(Y) )$$ Since $\mathbb E(X\mid \sigma(Y))$ is a function of $Y$ $$LHS=\mathbb E\bigg(\mathbb E(X\mid \sigma(Y))1_B(Y) \bigg)=\mathbb E(g(Y))=\int g(y)f_Y(y) dy\\
=\int \mathbb E(X\mid Y=y) 1_B(y) f_Y(y) dy=\int_B \mathbb E(X\mid Y=y)  f_Y(y) dy;\\
RHS=\mathbb E(X\,1_B(Y) )=\mathbb E(h(X,Y))=\int \int h(x,y) f(x,y) dx \, dy \\ =\int \int x\, 1_B(y) f(x,y) dx \, dy =\int_B \int x f(x,y) dx \, dy,$$ so as $RHS=LHS$ I think (since it is for all $B$ ??) $$\mathbb E(X\mid Y=y)  f_Y(y)=\int x f(x,y) dx \\
\\\Leftrightarrow\\
\mathbb E(X\mid Y=y)  =\frac{1}{f_Y(y)}\int x f(x,y) dx=\int x \frac{f(x,y)}{f_Y(y)} dx
=\int x f(x\mid y) dx.$$ Thanks in advance for any help you are able to provide or any clarification.","['measure-theory', 'conditional-expectation', 'real-analysis', 'expected-value', 'probability-theory']"
3612242,A geometric problem regarding collinearity,"Can somebody give a solution just with euclidean geometry to this problem? Here's the problem: If $A$ , $C$ , $E$ are collinear and $B$ , $D$ , $F$ are collinear (as you see in the picture) and if $$\frac{CE}{AC}=\frac{DF}{BD}=\lambda$$ prove that $M$ , $N$ , $P$ are collinear, where $M$ , $N$ , $P$ are the midpoints of the sides $AB$ , $CD$ , $EF$ , respectively. (The picture shows $\lambda=7/3$ .) A solution: Consider $M=(0,0)$ , $A=(-a,0)$ , $B=(a,0)$ . Let $C=(b,c)$ and $D=(e,g)$ ; then $N=(\frac12(b+e),\frac12(c+g))$ . Because $\overrightarrow{CE}=\lambda\overrightarrow{CA}$ , we have $E=((\lambda+1)b+\lambda a,(\lambda+1)c)$ . Similarly, because $\overrightarrow{DF}=\lambda \overrightarrow{BD}$ , we have $F=((\lambda+1)e-\lambda a,(\lambda+1)g)$ . Therefore, $P = ((\lambda+1)(b+e),(\lambda+1)(c+g))$ , so $\overrightarrow{MP}=(\lambda+1)\overrightarrow{MN}$ , showing $M$ , $N$ , $P$ collinear. $\square$ A solution only for $a=b$ Line segment $AB$ and points $D$ $F$ on the same side of $AB$ such that $AD=BF$ The extensions of $AD$ and $BF$ meet at a point $C$ . Draw the circle the goes through the points $A,B,C$ (Let's call it $Q$ ) .Let $M,N$ as the midpoints of the $AB,DF$ respectively. $Lemma$ :the perpendicular bisectors of AB and DF respectively meet at a point $P$ , $P\in(Q)$ :Proof $($ if the perpendicular bisector of $AB$ meets $Q$ at $P$ , the triangles $ADP$ and $BFP$ are equal to each other, $PD=PF$ so $PN$ is the perpendicular bisector of DF $)$ Let $PY,PT$ perpendicular to the lines $AC,BC$ , $T\in(lineAC)$ $Y\in(lineBC)$ . According to Simpsons theorem $M,N,Y$ are collinear. We will show that $N\in(MY)\iff{N\in(NY)}\iff{DFCP:inscribable}\iff{\angle{ACB}=\angle{DPF}}\iff{\angle{ACB}=\angle{WPV}}\iff{\stackrel\frown{AW}+\stackrel\frown{WB}=\stackrel\frown{WB}+\stackrel\frown{BV}}\iff{\stackrel\frown{AW}}=\stackrel\frown{BV}\iff{\angle{APD}=\angle{BPF}}$ which is true, because the are same angles of the equal triangles $ADP$ and $BPF$ (Note: $W=line(PD)\cap{Q}$ , $V=line(PF)\cap{Q}$ . Similarly we could prove that every point with similar properties to those, which described N, belong as well to MY, therefore are collinear. $\square$","['euclidean-geometry', 'trigonometry', 'geometry']"
3612276,Diagram of equivalences in modular representation theory,"Years ago I had found (and printed) a big list of all equivalences used in modular representation theory (and block theory), with arrows denoting the various implications (for instance, Morita equivalence -> Derived equivalence). At the top there were strong things like isomorphism of source algebras, and at the bottom ""Isomorphism of centers"" and "" $k(B)=k(C)$ "" (the number of ordinary characters in the block). It was a vertical diagram, with many ramifications and, I'd say, more than $20$ different properties listed. Sadly, due to the lockdown that diagram is now on the wall of my office in a building closed until further notice... and I was not able to find it again. Long shot, but does anyone know what I am talking about? I am 99% sure that it was part of a survey paper, or a survey chapter in a book. It was really detailed and well done.","['group-theory', 'abstract-algebra', 'representation-theory', 'reference-request']"
3612297,Compute the expected number of tiles needed filled to fill a row in a grid,"I want to compute the expected number of tiles I would have to fill to fill a row of $n$ tiles in a $n\times k$ -grid. No tiles can be filled more than once. In other words, if we fill a tile in a $n\times k$ -grid each turn with uniform probability and if $X$ is the number of turns needed to fill a row of $n$ tiles in the grid, what is $E[X]$ ? I have tried with some small examples. For example for a $2\times 3$ -grid, I reason as follows: 
It does not matter which tile we fill first.  Then it is a one in five chance to pick the same row as the first one, so the probability of filling a row in two turns is $\frac{1}{5}$ . To complete a row in three turns, we need to fill a tile in a different row, and then in one of the same. To complete a row in four turns, we need to fill a tile in each different row, then any tile we fill will complete a row. 
We get the following table: $$\begin{array}{c|c|} 
   & \text{Probability to fill a row in $x$ turns} \\ \hline
\text{P(X=2)} & \frac{1}{5} \\ \hline
\text{P(X=3)} & \frac{4}{5}\cdot\frac{2}{4} \\ \hline
\text{P(X=4)} & \frac{4}{5}\cdot\frac{2}{4}\cdot1
\end{array}$$ From here we can calculate the expected value as $E[X] = 2\cdot\frac{1}{5}+3\cdot\frac{2}{5}+4\cdot\frac{2}{5} = \frac{16}{5}$ , so we expect to complete a row in a little more than 3 turns. It quickly gets convoluted with larger examples though, and I can't find a pattern. I know factorials in the denominators are involved in probabilities, because the number of tiles to choose to fill decreases by one each time. I have not been able to find any similar sounding questions. In this question they answer something related, namely what the probability of filling a row of 10 after 20 turns in a $7\times10$ -grid. I feel like this might be of some help, but I am not able to generalize the solution provided there. Furthermore this does not answer what the expected number of turns to fill a row in a given grid is. It would also be interesting to see what kind of probability distribution this process has. Intuitively I think this shares some similarities with the geometric distribution, but not directly. I thought of this problem when doing a picture puzzle, and wondered how many puzzle pieces one would need to expect a row to be filled.","['puzzle', 'expected-value', 'combinatorics', 'recreational-mathematics', 'probability']"
3612325,Intuition behind tangent space to a point on a manifold,"Let $M$ be a smooth manifold and let $p \in M$ . We have a notion of a ""tangent space"" of $p$ , i.e. a vector space structure around $p$ to give us the idea, roughly, or ""directions we can travel in"" from $p$ , which an abstract manifold need not have inherently. I want to get a sense of the intuition behind what exactly a tangent vector is and how it's defined, and I break this up into four questions. 1) What is the purpose behind defining a tangent space? As I will write below, tangent vectors are defined in terms of directional derivative operators evaluated at $p$ . Is the only use behind tangent vectors to be able to take directional derivative? We might define a ""direction"" in our tangent space to be an operator that produces the directional derivative of a $C^{\infty}$ function in that ""direction"". Intuitively, this notion of direction doesn't look useful for doing anything other than taking directional derivatives; is that indeed the case? 2) Geometric Interpretation How would one visualize a tangent space? Say, for simplicity of picturing, that our manifold is actually a $k$ -submanifold in Euclidean space. In this case, isn't the tangent space every single vector in $\mathbb{R}^{k}$ ? How does this compare with visualizing the tangent space as a parallelepiped? 3) Definition 1: Smooth Curves We might define the tangent space as the equivalence class of all smooth curves $\gamma: \mathbb{R} \to M$ with $\gamma(0) = p$ , where two smooth curves $\gamma_{1}, \gamma_{2}$ are equivalent if $(\varphi \circ \gamma_{1})'(0) = (\varphi \circ \gamma_{2})'(0)$ . In this sense, each equivalence class defines a ""direction"" about $p$ , which helps us take directional derivatives. If $f: M \to \mathbb{R}$ is a smooth function, then $(f \circ \gamma)'(0)$ (differentiated in the ordinary sense, which makes sense here) is the directional derivative of $f$ in direction $\gamma$ . I again come back to my question of what use direction $\gamma$ is serving other than giving us directional derivatives. Now, I give the other definition, and want to know why these two definitions are exactly the same: 4) Definition 2: Directional Derivative Operator Note - This is often given in terms of ""derivations"" (linear maps that satisfy a generalized product rule, or Liebniz's rule): But a (non-trivial) result tells us that derivations are nothing but directional derivatives, so I stick to talking about directional derivatives here. Let $\mathcal{C}$ denote $C^{\infty}(M, \mathbb{R}$ ), i.e. smooth functions $M \to \mathbb{R}$ . Let $D_{\gamma}: \mathcal{C} \to \mathbb{R}$ be the operator s.t. $D_{\gamma}(f) = (f \circ \gamma)'(0)$ , where $\gamma: \mathbb{R} \to M$ is a smooth curve with $\gamma(0) = p$ , as above .We can define an equivalence relation (similar to what we did above) and define our tangent space to be all these ""directional derivative operators"" (that take a function and spit out its derivative in the direction of a smooth curve). In this sense, each ""direction"" in our tangent space is basically one of these operators. How is our notion of direction here same as the notion of direction we obtained in 3)? In one case, a curve (under equivalence relation) is our direction, while in this case, an operator (defined using a curve, but nevertheless different) is our direction. Further, this again brings me back to my question on whether direction and directional derivative can be used synonymously in this context. Thank you!","['tangent-spaces', 'differential-geometry', 'smooth-manifolds', 'real-analysis']"
3612364,Conditional probability; two queens attack each other,"Two queens are randomly placed on a chessboard. What is the probability that they attack each other? A: two queens randomly placed on a chessboard (condition) B: they attack each other I have 2016 ways to place two queens on a chessboard or $\binom{64}{2}$ . If I fix one queen on a chessboard I am left with 63 places to put second queen. After placing first one, no matter where I place it, I have 21 places to put second queen so that it attacks the first queen(7 for diagonal, vertical and horizontal places). Intuitively, the solution would be $\frac{\binom{21}{1}}{\binom{63}{1}}$ or $\frac{21}{63}\approx0.33$ . In my textbook the solution is $\frac{241}{672}\approx0.35$ . Since this is a question from conditional probability I know I have to use this formula P(B\A)= $\frac{P(AB)}{P(A)}$ .I know P(A)=2016, but I get confused when finding intersection AB because it is very similar to B\A, for me.","['conditional-probability', 'chessboard', 'probability']"
3612401,Exponential generating function for making password.,"There are special symbols $\{$ !,@,# $\} $ , three alphabet {a,b,c} and three numbers $\{1,2,3\}$ To make the $n$ -character password, the following rules are required. (A) Special symbol should be used only one time. (B) Alphabets should be used even times including the $0$ (C) The numbers should be used odd times Find the exponential generating function for making $n$ -character password. e.g.) when $n=4$ , $!123$ can be $4$ -character password that satisfying the above rules. Let's consider the exponential generating function, $f(x)$ . Then $f(x) = 3x(1+ {1\over2!}(3x)^2 + {1\over4!}(3x)^4+...)(3x+ {1\over3!}(3x)^3+{1\over5!}(5x)^5+...)$ $\therefore f(x) = 3x({e^{3x}+e^{-3x}\over2 })({e^{3x}-e^{-3x}\over2 })$ But In the solution sheet that my colleagues made said $f(x) = 3x({e^{x}+e^{-x}\over2 })^3({e^{x}-e^{-x}\over2 })^3$ I don't know why the answer should be like that. At least I believe his answer is not true.(It looks like mine is correct for me.) What do you think about that? Any help or solution would be appreciated.","['combinatorics', 'discrete-mathematics', 'generating-functions']"
3612482,"$\alpha,\beta,\gamma$ are the roots of the equation $x^3 − 9x + 9 = 0$. Find the value of $ \alpha^{-5}+\beta^{-5}+\gamma^{-5}$","I've simplified the expression to get $$\frac{(\alpha\beta)^5+(\beta\gamma)^5+(\gamma\alpha)^5}{(\alpha\beta\gamma)^5}.$$ Now all I need to find is $\sum (\alpha\beta)^5$ given that $\sum \alpha\beta=-9$ (by Vieta's relations). If it helps, I found that: $$\sum (\alpha\beta)^2=81,$$ and $$\sum (\alpha\beta)^3=-486.$$","['contest-math', 'roots', 'symmetric-polynomials', 'polynomials', 'algebra-precalculus']"
3612484,How do you calculate distance between two cylindrical coordinates?,"I can't figure out how to find the distance between these two points, expressed with cylindrical coordinates: $P1 = (9.5 m, 1.00531 rad, 18.2 m)$ $P2 = (9.75 m, 5.27788 rad, 18.2 m)$ What is the precise method to find the distance between these two points? What is the formula?
Thanks.","['cylindrical-coordinates', 'physics', 'geometry']"
3612546,Efficient algorithm for computing Vandermonde determinant,"The determinant of Vandermonde matrix $$V=\left[\begin{matrix}
1 & x_1 & x_1^2 & \cdots & x_1^{n-1} \\
1 & x_2 & x_2^2 & \cdots & x_2^{n-1} \\
1 & x_3 & x_3^2 & \cdots & x_3^{n-1} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & x_n & x_n^2 & \cdots & x_n^{n-1} \\
\end{matrix}\right]$$ can be represented as a product of pairwise differences between $x_i$ s: $$\det(V)=\prod_{i<j}x_j-x_i.$$ Is there an algorithm that computes this determinant more quickly than by trivially multiplying those $O(n^2)$ differences?","['matrices', 'numerical-linear-algebra', 'determinant', 'algorithms']"
3612579,What is wrong with this fake proof that any subset of a $T_1$ space is closed?,"Let $X$ be a $T_1$ space and let $A \subseteq X$ be any subset. Fake Proof: Since $X$ is $T_1$ we know that any singleton in $X$ is closed. So choose $a \in A$ , then $\{a\}$ is closed and $X \setminus \{a\}$ is open in $X$ . Now choose another $a' \in A$ such that $a' \neq a$ . Then again $\{a'\}$ is closed and $(X \setminus \{a\}) \setminus \{a'\} = X \setminus \{a, a'\}$ is open since it is the set difference of an open and closed set. Continue this process for all $a \in A$ and thus we've shown $X \setminus A$ is open and hence that $A$ is closed. $\square$ My guess is that when we say ""continue this process"" that's where some subtlety lies which would show that this proof is incorrect, but I can't say what that subtlety is. If $A$ was finite this proof would work fine I think. So my question is, what exactly is wrong with this proof?","['general-topology', 'fake-proofs']"
3612590,Does kernel regression preserve monotonicity?,"Consider the Kernel regression estimator: $$\hat{y}(x)=\frac{\sum_{i=1}^n{K(x-x_i)y_i}}{\sum_{i=1}^n{K(x-x_i)}},$$ where $x,x_1,\dots,x_n\in\mathbb{R}^d$ , $y_1,\dots,y_n\in\mathbb{R}$ , where $K:\mathbb{R}^d\rightarrow(0,\infty)$ is a strictly positive valued, differentiable kernel function, with a unique maximum at $0$ . Suppose further that for all $i,j\in\{1,\dots,n\}$ , if $x_i\le x_j$ then $y_i \le y_j$ . Is it the case that for all $x\in\mathbb{R}^d$ : $$\frac{\partial\hat{y}(x)}{\partial x} \ge 0?$$ It seems obvious in the $d=1$ case, but even there I haven't been able to prove it. It's unclear to me if it holds for $d>1$ . If it only holds under additional assumptions on $K$ I'd be interested in them. Notation: $\frac{\partial \hat{y}(x)}{\partial x}$ is the column vector of partial derivatives of $\hat{y}(x)$ , i.e. the (transposed) Jacobian. For vectors $a=[a_1,\dots,a_d]^\top$ and $b=[b_1,\dots,b_d]^\top$ , $a\le b$ if and only if $a_i \le b_i$ for all $i\in\{1,\dots,d\}$ .","['regression', 'inequality', 'derivatives', 'monotone-functions']"
3612647,"Subsets which are ""never closed"" under group operation","I am wondering if there are some specific properties of groups for which there exists nonempty subset, say $\exists X\ne\emptyset,X\subset G$ , s. t. $\forall g,h\in X$ , its product $gh$ does not belongs to $X$ . I didn't find any references where such pairs $(G,X)$ will be discussed. Under what name (in the literature) should I look for such subsets, or group which possesses them? I am interested in study properties of such objects (under additional assumptions) and looking for some references. As an example it will be interesting to know when such pairs can exists, how large $X$ can be, how many such $X$ s are possible for a given group $G$ , if $(G,X)$ is such a pair, for which subgroup $H$ of $G$ , $(H,X)$ also have this property etc. I will be grateful for any suggestion.","['group-theory', 'abstract-algebra', 'reference-request']"
3612717,Markov's inequality results negative,"$X$ is the midterm grade (out of $100$ points) of a randomly chosen student. If the
average grade is $40$ points, find an upper bound on $Pr[X < 10]$ using Markov's
inequality. (Hint: You may need to define a new non-negative random variable.) I encountered this question and applied Markov's inequality but it gave me $P(X < 10)>= 1-\left(\frac{40}{10}\right)$ and that gives us a negative bound. How can I resolve this problem ?","['markov-process', 'statistics', 'probability']"
3612772,How many ideals contain $(x^2+1)$ in $\mathbb{Z}_4[x]$?,"How many ideals in $\mathbb{Z}_4[x]$ contain $(x^2+1)$ ? I noticed that $x^2+1$ is irreducible in $\mathbb{Z}_4[x]$ . But $\mathbb{Z}_4[x]$ is not a PID, so $x^2+1$ need not be maximal in $\mathbb{Z}_4[x]$ . So I’m a bit stuck here. Can someone help me out? Thanks!","['ring-theory', 'abstract-algebra', 'polynomials']"
3612820,"Proof of Luzin's Theorem on Axler's Measure, Integration & Real Analysis","I would appreciate some help understanding a step on the proof of Luzin's Theorem on Sheldon Axler's Measure, Integration & Real Analysis (open access here , Theorem 2.91 pg 66). Basically, there is a finite collection of disjoint Borel sets $D_1, \dots, D_n$ , colsed sets $F_k \subset D_k$ and open sets $G_k\supset D_k$ Then, he defines a set $$F=\left(\bigcup_{k=1}^n F_k\right)\cup \left(\bigcap_{k=1}^n \mathbb{R}\setminus G_k\right)$$ And then claims that $\mathbb{R}\setminus F = \bigcup_{k=1}^n (G_k \setminus F_k)$ . I cannot see how this follows, unless $G_i \cap F_j= \emptyset$ for $i\neq j$ , and I don't see why this would be the case. Many thanks!","['elementary-set-theory', 'measure-theory', 'analysis']"
3612838,"Prove that $\int_a^\infty f(x)\sin(e^x) \, dx$ conditionally converges.","Let $f$ be a bounded and with a continuous derivative at the interval $[a,\infty)$ . The integral: $\displaystyle \int_a^\infty f(x) \, dx$ diverges. Also: $$
\exists t> a, \forall x>t: f'(x) < f(x)
$$ Prove that the $\displaystyle \int_a^\infty f(x) \sin(e^x) \, dx$ conditionally converges. What i tried: So i want to show that it diverges in its absolute value and converges in its ""normal"" value. For diverges in its absolute value We know that: $$
|\sin(e^x)| < 1
$$ Therefore we can write: $$
\int_a^\infty |f(x)| \leq \int_a^\infty |f(x)\sin(e^x)| \, dx
$$ But we know that the left integral diverges from the question, therefore, by comparison test: $$
\int_a^\infty |f(x)\sin(e^x)| \, dx
$$ diverges. Now the problem in proving converges for the ""normal"" function. I thought to use Dirichlet test, but i dont see how to say that $f(x)$ is decreasing monotonic or to talk about the limit. I must say it very sounds like drichlet test, but i cant see how it feets... Couldnt think of other functions for dirichle So i thought about the comparison test, yet couldn't think of a converging function that will fit. In the end, i am stuck. Those are my homework, so i prefer a hint than a solution. Thank you.","['integration', 'calculus', 'improper-integrals', 'real-analysis']"
3612850,Fourier-like operator on $L^2$ is compact,"For real numbers $a,b>0$ , consider the following continuous operator: $$ \mathcal{G}:=\mathcal{F}^{-1}\chi_{[-b,b]}\mathcal{F}\chi_{[-a,a]}: L^2(\mathbb{R})\to L^2(\mathbb{R}),$$ where the $\chi$ 's represent the multiplication operator that multiplies by the corresponding indicator function, and $\mathcal{F}$ is the Fourier transform. How could one prove that it is compact? Moreover, houw could we prove that the following similar-looking operator $$ \mathcal{F}^{-1}(1-\chi_{[-b,b]})\mathcal{F}\chi_{[-a,a]}: L^2(\mathbb{R})\to L^2(\mathbb{R})$$ isn't compact? For the latter I guess we must find a sequence of functions with bounded $L^2$ -norms such that no subsequence of their images converges in $L^2$ , and maybe $e^{\pi inx/a}$ would work (since they form an orthonormal basis for $L^2([-a,a])$ ), where $n\in\mathbb{Z}$ , but I'm having some trouble finishing the computations. For the former, a straightforward computation gives: $$\mathcal{G}f(x) = \frac{1}{\pi}\int_{-a}^a f(y)\frac{\sin(2\pi b(x-y))}{x-y} dy $$ (unless I'm making a mistake). So it is (up to the $1/\pi$ constant) an integral operator with kernel $$ K(x,y) = \frac{\sin(2\pi b(x-y))}{x-y} \chi_{|y|\le a}, $$ and I read somewhere that such an integral operator is compact if an only if its kernel is in $L^2$ . In this case, this would reduce the problem to proving that $$\int_{\mathbb{R}}\int_{-a}^a \bigg|\frac{\sin(2\pi b(x-y))}{x-y}\bigg|^2 dy dx <\infty,$$ but is this theorem I cited true? If so, how could one prove it? I couldn't find a proof online. Thank you so much for your help!","['compact-operators', 'fourier-analysis', 'real-analysis', 'functional-analysis', 'convergence-divergence']"
3612871,"If I reset after each run, how many times do I need to repeat an experiment to have a 75% chance of running it on all the subjects?","Suppose there is a bag with 100 marbles. And I can draw 5 marbles in one attempt. But after that draw I have to put the marbles back. In how many attempts do I have a 75% chance that I have drawn each marble at least once? I wrote a brute force program that calculated this: Marbles = 100. DRAW 5 at a time. Performing 100000 runs.
Runs completed = 10000
Runs completed = 20000
Runs completed = 30000
Runs completed = 40000
Runs completed = 50000
Runs completed = 60000
Runs completed = 70000
Runs completed = 80000
Runs completed = 90000
Runs completed = 100000
For 75% confidence you need 115 draws. But how can we mathematically arrive at the same answer?",['probability']
3612880,For what $x$ and $y$ polynomial has maximum value?,"For what $x,y\in\mathbb R$ does the polynomial $$-5x^2-2xy-2y^2+14x+10y-1$$ attain a maximum? My attempt: I called $\alpha$ maximum value. $$-5x^2-2xy-2y^2+14x+10y-1\leqslant\alpha$$ $$-5x^2-2xy-2y^2+14x+10y-1-\alpha\leqslant 0$$ $$5x^2+2xy+2y^2-14x-10y+1+\alpha\geqslant 0$$ $$(x+y)^2+(y-5)^2+3x^2+(x-7)^2-73+\alpha\geqslant0$$ $$\alpha\geqslant73$$ So the lowest maximum value turned out to be $73$ , but after checking answers I was wrong-maximum is $16$ , so my further plans to calculate from that $x$ and $y$ seemed purposless. I'd like to see solution using only high school knowledge. Ans: $x=1$ , $y=2$","['quadratic-programming', 'maxima-minima', 'polynomials', 'optimization', 'algebra-precalculus']"
3612908,Find $ \lim\limits_{x\to 0}{\frac{1-\sqrt{1+x}\sqrt[3]{1-x}\cdots\sqrt[2n+1]{1-x}}{x}} $ without using L'Hopital's rule.,Let $ n $ be a positive integer greater than $ 1 $ . Find : $$ \lim\limits_{x\to 0}{\frac{1-\sqrt{1+x}\sqrt[3]{1-x}\cdots\sqrt[2n+1]{1-x}}{x}} $$ Without L'Hopital's rule or series expansion. Here is What I did to solve the problem. \begin{aligned}\displaystyle\lim_{x\to 0}{\displaystyle\frac{1-\prod\limits_{k=2}^{2n+1}{\sqrt[k]{1+\left(-1\right)^{k}x}}}{x}}&=\displaystyle\lim_{x\to 0}{\displaystyle\sum_{k=2}^{2n+1}{\displaystyle\frac{\prod\limits_{i=2}^{k-1}{\sqrt[i]{1+\left(-1\right)^{i}x}}-\prod\limits_{i=2}^{k}{\sqrt[i]{1+\left(-1\right)^{i}x}}}{x}}}\\&=\displaystyle\lim_{x\to 0}{\displaystyle\sum_{k=2}^{2n+1}{\displaystyle\frac{1-\sqrt[k]{1+\left(-1\right)^{k}x}}{x}\displaystyle\prod\limits_{i=2}^{k-1}{\sqrt[i]{1+\left(-1\right)^{i}x}}}}\\ &=\displaystyle\lim_{x\to 0}{\displaystyle\sum_{k=2}^{2n+1}{\displaystyle\frac{\left(-1\right)^{k+1}}{\sum\limits_{j=0}^{k-1}{\sqrt[k]{1+\left(-1\right)^{k}x}^{j}}}\displaystyle\prod\limits_{i=2}^{k-1}{\sqrt[i]{1+\left(-1\right)^{i}x}}}}\\ &=\displaystyle\sum_{k=2}^{2n+1}{\displaystyle\frac{\left(-1\right)^{k+1}}{k}} \\ &=\displaystyle\sum_{k=1}^{n}{\displaystyle\frac{1}{2k+1}}-\displaystyle\sum_{k=1}^{n}{\displaystyle\frac{1}{2k}}\\ &=-1+\displaystyle\sum_{k=0}^{n}{\displaystyle\frac{1}{2k+1}}+\displaystyle\sum_{k=1}^{n}{\displaystyle\frac{1}{2k}}-\displaystyle\sum_{k=1}^{n}{\displaystyle\frac{1}{k}}\\ &=-1+\displaystyle\sum_{k=1}^{2n+1}{\displaystyle\frac{1}{k}}-\displaystyle\sum_{k=1}^{n}{\displaystyle\frac{1}{k}}\\ \displaystyle\lim_{x\to 0}{\displaystyle\frac{1-\prod\limits_{k=2}^{2n+1}{\sqrt[k]{1+\left(-1\right)^{k}x}}}{x}}&=H_{2n+1}-H_{n}-1 \end{aligned} What's your approach to solve the problem ?,"['limits', 'limits-without-lhopital', 'sequences-and-series']"
3612928,Solve $\sin 84^\circ \sin(54^\circ-x)=\sin 126^\circ \sin x$.,"Find $x$ in degrees, where $$\sin 84^\circ\cdot \sin(54^\circ-x)=\sin126^\circ\cdot \sin x\,.$$ I tried to use trigonometry identities to transform the product in sums, but I can't simplify moreover. I know the result is 30° since I solved it in a calculator, but there must be an algebraic way. For context, this equation comes from solving this problem: How can I solve this geometry problem without trigonometry?","['contest-math', 'euclidean-geometry', 'geometry', 'trigonometry', 'algebra-precalculus']"
3612936,Geometric interpretation of regular non-closed points,"Let $X$ be a variety (say, integral scheme of finite type) over an algebraically closed field $k$ . Consider an irreducible closed subset $Y\subseteq X$ and let $\eta$ be the generic point of $Y$ . I would like to know if the following is true. Question: The point $\eta$ is regular (i.e, $\mathcal{O}_{X,\eta}$ is a regular local ring) if and only if there is at least one closed point $x\in Y$ that is regular on $X$ . The if part of the question is true due to a theorem of Serre: The localization of a regular local ring is a regular local ring. Because, if the variety $Y$ is defined by the prime ideal $P$ inside an affine chart containing $x$ , then $(\mathcal{O}_{X,x})_{P\mathcal{O}_{X,x}}=\mathcal{O}_{X,\eta}$ . So I am interested in the only if part. Notice that any algebraic variety has at least one regular closed point (cf. the book of Liu, section 4.2 Lemma 2.21, where it is proved over any field under the assumption of $X$ being geometrically reduced). Hence, $Y$ has at least one closed point $x$ such that $\mathcal{O}_{Y,x}$ is regular. As we are assuming that $\mathcal{O}_{X,\eta}$ is regular as well maybe some kind of transitivity of the regular property (in the sense of this other question that I asked before) would imply that the point $x$ is regular in $X$ . Maybe the fact that the set of regular points in $Y$ is actually an open set (cf. Liu section 4.2 proposition 2.24) can be used to change the point $x$ in case some of them fails. If you find a nice proof of this it would be nice to clean the unnecessary hypothesis as well.","['algebraic-geometry', 'commutative-algebra']"
3612954,A possible solution to $\sqrt {5-x}=5-x^2$ (without taking square from both sides),"Problem: Solve $\sqrt{5-x}=5-x^2$ without taking square from both sides. The one who sent the problem to me claims that this is possible. I would like to know if the method I applied below really works. $\color{black}{\text{Method} \thinspace  1:}$ $$\begin{cases} 5-x\geq 0 \\5-x^2 \geq 0 \end {cases} \Longrightarrow   -\sqrt{5}\leq x \leq \sqrt{5}$$ $-\sqrt{5}$ and $\sqrt{5}$ are not solutions. Therefore, we have: $~$ $-\sqrt{5} < x < \sqrt{5}$ Let, $5-x=u$ and $5-x^2=v$ , we have : $$u-v=x^2-x \\ v^2-v =x^2-x \\v^2-v-x^2+x=0 \\ (x-v)(x+v)-(x-v)=0 \\ (x-v)(x+v-1)=0 \\ x_1=v, ~~~ x_2=1-v$$ Then, we have $$\begin{cases}x=5-x^2 \\ -\sqrt{5} < x < \sqrt{5} \end {cases} \Longrightarrow \begin{cases}x^2+x-5=0 \\ -\sqrt{5} < x < \sqrt{5} \end {cases} \Longrightarrow x=\dfrac{\sqrt {21}-1}{2}$$ $$\begin{cases}x=1-(5-x^2) \\ -\sqrt{5} < x < \sqrt{5} \end {cases} \Longrightarrow \begin{cases}x^2-x-4=0 \\ -\sqrt{5} < x < \sqrt{5} \end {cases} \Longrightarrow x=\dfrac{1- \sqrt {17}}{2}$$ So, we get: $$\color{red}{x= \left\{  \dfrac{\sqrt {21}-1}{2}, \dfrac{1- \sqrt {17}}{2} \right\}}$$ $\color{black}{\text{Method} \thinspace  2:}$ Actually a ""copy"" of Method $1$ . So, this is almost the same. $$ \underline {\color {blue} {x^2-x=5-x-\left(5-x^2 \right)}} \\ x^2-x =\left(5-x^2 \right)^2-\left(5-x^2 \right) \\ x^2-x-\left(5-x^2 \right)^2+\left(5-x^2 \right)=0 \\ \left(x-\left(5-x^2 \right) \right)\left(x+\left(5-x^2 \right) \right)+\left(5-x^2 \right)-x=0 \\ \left(x-\left(5-x^2 \right) \right)\left(x+\left(5-x^2 \right) \right)-\left(x-\left(5-x^2 \right) \right)=0 \\ \left(x-\left(5-x^2 \right) \right)\left(x+\left(5-x^2 \right)-1 \right)=0 \\\left(x^2+x-5 \right)\left(-x^2+x+4 \right)=0 \\ \left(x^2+x-5 \right)\left(x^2-x-4 \right)=0$$ Finally we have: $$\color{blue}{\begin{cases}\left(x^2+x-5 \right)\left(x^2-x-4 \right)=0\\ -\sqrt{5} < x < \sqrt{5} \end {cases} \Longrightarrow} \color{red} {\begin{cases} x_1=\dfrac{1- \sqrt {17}}{2} \\  x_2=\dfrac{-1+\sqrt {21}}{2} \end{cases}}$$ $\color{black}{\text{Method} \thinspace  3:}$ $$\displaystyle\sqrt {5-x}=5-x^2$$ $x=5-u^2$ $$|u|=5-\left( 5-u^2\right)^2 \\ |u|-|u|^2=5-|u|^2-\left( 5-|u|^2\right)^2$$ $|u|=v$ $$v-v^2=5-v^2-\left( 5-v^2\right)^2 \\ v^2-v =\left(5-v^2 \right)^2-\left(5-v^2 \right) \\ v^2-v-\left(5-v^2 \right)^2+\left(5-v^2 \right)=0 \\ \left(v-\left(5-v^2 \right) \right)\left(v+\left(5-v^2 \right) \right)+\left(5-v^2 \right)-x=0 \\ \left(v-\left(5-v^2 \right) \right)\left(v+\left(5-v^2 \right) \right)-\left(v-\left(5-v^2 \right) \right)=0 \\ \left(v-\left(5-v^2 \right) \right)\left(v+\left(5-v^2 \right)-1 \right)=0 \\ \left(v^2+v-5 \right)\left(v^2-v-4 \right)=0$$ $$x=5-u^2=5-|u|^2=5-v^2$$ where, $-\sqrt5 <x<\sqrt5.$ Finally, $$\color{red}{\begin{cases}\left(v^2+v-5 \right)\left(v^2-v-4 \right)=0\\ 5+\sqrt{5} > v^2 > 5-\sqrt{5} \end {cases} \Longrightarrow} \color{red}{\begin{cases} v_1=\dfrac{1+ \sqrt {17}}{2} \\  v_2=\dfrac{-1+\sqrt {21}}{2} \end{cases} \Longrightarrow} \color{blue} {\begin{cases} x_1=\dfrac{1- \sqrt {17}}{2} \\  x_2=\dfrac{-1+\sqrt {21}}{2}. \end{cases}}$$ Is there any completely different method besides these methods and what I do is true? Because, I am not sure that I fulfill the requirement of ""not taking square from both sides"". But, I think what I do is different from $$\sqrt {5-x}=5-x^2 \\ 5-x= \left(5-x^2 \right)^2 \\ 5-x=25-10x^2+x^4 \\ \cdots \cdots \cdots $$","['functional-equations', 'solution-verification', 'polynomials', 'radicals', 'algebra-precalculus']"
3612971,Why do we take into consideration the probability of the events that are more extreme than the observed value in hypothesis testing?,"I am currently learning about hypothesis testing and I really don't understand why do we take into consideration the probability of the events to the left and to the right of the observed value (or just to the left, or just to the right in the cases when we are interested if a parameter is only greater or smaller than the hypothesized value of the parameter). So it is clear enough that we take into consideration the probability of the observed value, but why do we also take into consideration the probability of the events that are more extreme than the observed value ? It seems to me that if we also take into consideration the events that are more extreme than the observed value, we are overestimating the p-value. I understand that we couldn't consider only the observed value if we are talking about a continuous distribution, since in that case we have to find the area under the curve to find the probability, and we would find the area of a line which would be $0$ . But we could consider a small interval or something like that. And in the case of a discrete distribution we wouldn't have this problem, but we still take into consideration the events that are more extreme than the observed value. So why does this work? I would really appreciate it if you could explain it like you would explain it to someone who is just starting with statistics, since that is the position that I am in.","['statistics', 'hypothesis-testing']"
3612983,How the partial fraction decomposition works for finding this Inverse Laplace Transform?,"I've been working to find inverse Laplace transform for the following : $$
\frac{A}{(s-a)(s-r_1)(s-r_2)}
$$ However, I'm getting stuck on the partial fraction decomposition. When I run the decomposition in Wolfram Alpha, it comes back as $$-\frac{A}{(s-r_1)(a - r_1)(r_1 - r_2)} -\frac{A}{(s - r_2)(a - r_2)(r_2 - r_1)} + \frac{A}{(a - r_1)(a - r_2)(s - a)}$$ Any thoughts on how this decomposition works? I can solve the inverse Laplace easily from this point but for the life of me I can't figure out how this partial fraction is working. Thanks for the help!","['partial-fractions', 'laplace-transform', 'ordinary-differential-equations']"
3613078,"What captures our intuitive notion of faces, edges, and vertices?","This answer suggests that laypeople's intuitive notion of the meaning of these words is consistent with the following claims: A cube has 6 faces, 12 edges, 8 vertices. A cylinder has 3 faces, 2 edges, 0 vertices. A cone has 2 faces, 1 edge, 1 vertex. A sphere has 1 face, 0 edges, 0 vertices. What formal, mathematical definition best captures this intuition and is consistent with the above claims? For example, the following was suggested in the comments: I think the definition of the tangent space at a point via equivalence
  classes of smooth curves works in this situation, and then I believe
  it's true that the naive count of faces, edges, etc. counts connected
  components of the subspaces of points whose tangent spaces have the
  relevant dimensions. Is this a good approach? If so, does it have an existing name and literature? Are there any other approaches?","['geometry', 'intuition', 'tangent-spaces']"
3613090,Understanding from where a recurrence of polynomials comes from,"In chapter $7$ of Principles of Mathematical Analysis ( $3$ rd edition) by Walter Rudin, the exercise $23$ says: Put $P_0=0$ , and define, for $n=0,1,2,\dots,$ $$P_{n+1}(x)=P_{n}(x)+\frac{x^2-P_{n}^2(x)}{2}.$$ Prove that $$\lim_{n\to \infty}P_{n}(x)=|x|,$$ uniformly on $[-1,1]$ . I am interested here in the origin of the polynomials (i.e. how Rudin came up with them) rather than a solution to the exercise.  My intuition is that the polynomials come as some sort of approximation of $\sqrt{x^2}$ , but I am unsure how to use an approximation of the square root function to derive the recurrence $P_0(x) = 0$ and $$P_{n+1}(x) = P_n(x) + \frac {x^2 - P_n^2(x)} 2$$ as an approximation of $\sqrt{x^2}$ .","['interpolation', 'analysis', 'real-analysis', 'polynomials', 'radicals']"
3613105,Probability that all red cards are assigned a number less than or equal to 15,"I have 10 red and 10 blue cards. I shuffle the cards and then label the cards based on their orders: I write the number one on the first card, the number two on the second card, and so on. What is the probability that a) All red cards are assigned numbers less than or equal to 15?
b) Exactly 8 red cards are assigned numbers less than or equal to 15? I know that the total number of ways to arrange 20 cards is $20!$ . How do I proceed further?","['self-learning', 'combinatorics', 'probability']"
3613192,"Shouldn't angular displacement be defined only on $[-\pi,\pi)$?","I'm used to displacement being a measure which ignores the path taken, like so: but when I read about angular displacement, it seems to be more like a distance than a displacement. For instance, in this NASA graphic it's given as $$\phi=\theta_1-\theta_0,\tag{1}$$ so, for instance, if $\theta_1=\frac{3\pi}{2}$ and $\theta_0=0$ , we have \begin{align}
\phi =\frac{3\pi}{2}-0 =\frac{3\pi}{2}.
\end{align} But the linear distance travelled is $\frac{3\pi}{2}r$ and the linear displacement is $\sqrt{2}r$ , so, by analogy, shouldn't we say the angular distance traveled is $\frac{3\pi}{2}$ and the angular displacement is $-\frac{\pi}{2}$ ?","['classical-mechanics', 'trigonometry', 'circles', 'vectors']"
3613195,When does the center of a set of points lie in the convex hull?,"Suppose we are given $n$ points $X_1,X_2\dots X_n$ in $d$ -dimensional Euclidean space $\mathbb{R}^d$ . I'm interested in understanding some properties of the ``center'' of $\{X_i\}_{i=1}^n$ w.r.t $L_p$ norm, for $p \geq 1$ $$
\min_{X} \sum_{i=1}^n\|X-X_i\|_p.
$$ For what values of $p$ does the minimizer of the above problem lie in the convex hull of $\{X_i\}_{i=1}^n$ ? PS: When $p=1$ , the solution to the above problem is the coordinatewise median. When $p=2$ the minimizer is called the geometric median.","['convex-optimization', 'convex-geometry', 'functional-analysis']"
3613227,How would one draw an embedding of $K_8$ on a 2-holed torus with no edges crossing?,"I understand that a 2-holed torus can be formed by connecting sides of an octagon, as shown in the included image, and the completely connected graph with 8 vertices, $K_8$ , can be embedded into the 2-holed torus, such that there are no crossings of edges. I am trying to use the octagon diagram and imagining the connections to be like the sides of a Pac-Man maze to draw the graph of $K_8$ , however, I have found much difficulty connecting opposite sides of the graph, where there isn't a convenient portal. How would one complete the embedding? I haven't found any such diagrams, at least that I understood.","['graph-theory', 'general-topology']"
3613276,How to evaluate a sum of square roots rounded to the nearest integer?,"This is (adapted from) Problem 11 from the 2007 AIME : For each positive integer $p$ , let $b(p)$ denote the unique positive integer $k$ such that $|k-\sqrt{p}|<\frac{1}{2}$ . For example, $b(6)=2$ and $b(23)=5$ . Find $S=\sum_{p=1}^{2007} b(p)$ . I started by noting that $$\left(k- \frac 12\right)^2=k^2-k+\frac 14\text{ and }\left(k+ \frac 12\right)^2=k^2+k+ \frac 14.$$ So, all numbers from $1-44$ will have the maximum value in the range. How should I continue, or approach the problem.","['contest-math', 'number-theory', 'ceiling-and-floor-functions', 'sequences-and-series']"
3613285,"Graph Theory: Find a $K_{3,3}$ subdivision to this graph","This is my first post here, so I apologise in advance if some formatting is wrong. In my graph theory class today we were challenged to find a $K_{3,3}$ (complete bipartite graph) homeomorphic to this . I've tried to redraw, subdivide edges, and smooth some out, but I can't seem to find it. I'd appreciate any guidance or hints regarding which part to look at.","['graph-theory', 'discrete-mathematics', 'planar-graphs']"
3613377,Separation of variables -- what to do about the case where we might be dividing by zero?,"In not a few textbooks, we have some version of this example of a falling body: Problem. Solve $\frac{dv}{dt} = a - bv$ with the initial condition $(t,v)=(0,0)$ . Solution. Rearrange to get $\frac{dt}{dv} \overset 1= \frac{1}{a - bv}.$ Integrating, $t=-\frac{1}{b}\ln|a-bv|+C_1$ . Rearranging, $e^{b(C_1-t)}=|a-bv|$ or $a-bv=\pm e^{b(C_1-t)}=C_2 e^{-bt}$ . Plug in the initial condition to get $C_2=a$ and $a-bv=ae^{-bt}$ . Now rearrange to get the solution: $v=\frac{a}{b}(1-e^{-bt}).$ My question is: At $\overset 1=$ , we assume $a-bv\neq0$ ---so, how do we handle the case where $a-bv=0$ ? (Do we for example simply assert that this never happens? How do we justify this assertion? Or is there some other more careful/precise way of dealing with $a-bv=0$ ?)",['ordinary-differential-equations']
3613402,"Is [7, 10) a subset of {7, 8, 9, 10}?","I'm learning elementary set theory and so, in an effort to understand my reasoning, I'd like some feedback. I apologise if it's too basic - I'm barely starting out and don't want to get my foundation wrong. I'm asked the following: Is it true that [7, 10) ⊆ {7, 8, 9, 10}? I've dubbed {7, 8 , 9, 10} = A for simplicity's sake. The interval [7, 10) is composed of the numbers 7 ≤ x < 10, which include 7.1, 7.11, 7.222, and an infinite amount of numbers before 10. Meanwhile, A is composed of only four elements: 7,8,9,10. Simultaneously, elements of A are also present in the interval: 7, 8, 9 are, indeed, part of [7, 10) and of A. Would this be enough to consider [7, 10) ⊆ {7, 8, 9, 10} as true, or does the presence of other numbers (like those I listed above) disqualify the interval from being a subset of A?",['elementary-set-theory']
3613467,What's the next base-ten non-pandigital factorial number after 41!?,"By pandigital number I mean a number for which each digit in a given base occurs at least once ( some definitions that state each digit must occur exactly once ), and since I looking for numbers that are not pandigital in base ten at least one of the digits from 0 through 9 should be missing. By a factorial number I mean a positive integer for which there exists a whole number $n$ such that the factorial number is equal to $n!$ . In set theoretic language, this question is considering elements in the intersection of these two sets of numbers. One can quickly generate and test (brute force) search for such values. Here's a quick-and-simple example of such an algorithm. from math import factorial

n = 0

while 1:
    f = factorial(n)
    if len(set(str(f))) != 10:
        print(n, f)
    n += 1 Which running this for even a few seconds will print the following before not printing anything after. For the $n$ as I use it in the definitions above (which is consistent with the Python script), I have exhaustively checked for values of $n$ from 0 to over 253817 without finding what the next non-pandigital factorial number is. I've spoken to a number theorist about this problem, and while he told me there is an infinite number of such numbers, he did not have an example of one higher than 41!. Note that in this question, I don't just want a higher non-pandigital factorial number, but the next one. 0 1
1 1
2 2
3 6
4 24
5 120
6 720
7 5040
8 40320
9 362880
10 3628800
11 39916800
12 479001600
13 6227020800
14 87178291200
15 1307674368000
16 20922789888000
17 355687428096000
18 6402373705728000
19 121645100408832000
20 2432902008176640000
21 51090942171709440000
22 1124000727777607680000
24 620448401733239439360000
25 15511210043330985984000000
26 403291461126605635584000000
28 304888344611713860501504000000
29 8841761993739701954543616000000
30 265252859812191058636308480000000
32 263130836933693530167218012160000000
38 523022617466601111760007224100074291200000000
41 33452526613163807108170062053440751665152000000000 Note that the last number of $n$ above that satisfies the criterion is 41, not 42. Douglas Adams will mock me for coming up short by unity! Here is a Rust implementation to continue the calculation. extern crate rug;

use rug::Integer;

fn main() {
    let mut n = Integer::from(0);

    loop {
        let f = factorial(&n);
        if count_unique_digits(&f.to_string()) != 10 {
            println!(""{} {}"", n, f);
        }
        n += 1;
    }
}

fn factorial(n: &Integer) -> Integer {
    if n == &Integer::from(0) {
        return Integer::from(1);
    }

    let mut result = Integer::from(1);
    for i in 1..=n.to_u64().unwrap() {
        result *= &Integer::from(i);
    }
    result
}

fn count_unique_digits(num_str: &str) -> usize {
    let mut digits = std::collections::HashSet::new();
    for ch in num_str.chars() {
        if ch.is_digit(10) {
            digits.insert(ch);
        }
    }
    digits.len()
}","['factorial', 'number-theory', 'elementary-number-theory', 'natural-numbers', 'decimal-expansion']"
3613486,What is the relationship between sheaf cohomology from different global sections functors,"Let $X$ be a ringed space, and $F$ be a sheaf of abelian groups on $X$ . Then $H^i(X, F)$ is the right derived functors of the global sections functor. However, there are at least three different global sections functors that we can take derived functors of: Forget the ringed space structure and just consider $X$ as a topological space and $F$ is a sheaf of abelian groups. Then, the global sections functor is $Ab(X) \rightarrow Ab$ . If $F$ has an $O_X$ -module structure, then we have another global sections functor $O_X-mod \rightarrow O_X(X)-mod$ . That is: the category of sheaves $O_X$ -modules to the category of $O_X(X)$ -modules We can also restrict (2) to the case where $F$ is quasicoherent. That is: we have a functor $QCoh(X) \rightarrow O_X(X)-mod$ . My question is: what is the relationship between them? Injective objects in the category of quasicoherent sheaves is not the same as injective objects in the category of sheaves of $O_X$ -modules, see here for an example. Hartshorne's proposition III.2.6 states that the derived functors $O_X-mod$ to $Ab$ coincide with the cohomology functor. Does this mean that (2) and (1) result in the same cohomology groups, after applying the forgetful functor? If $X$ is an affine scheme, then the global sections functor is exact. This would imply that the $H^i(X, F)$ for $i \geq 1$ is 0 for the third global sections functor. What about the first and second global sections functors?","['algebraic-geometry', 'homology-cohomology']"
3613520,Minimising the area between a line and an exponential curve,"We need to find a suitable k , for which the area between the two curves $y=e^x, y=k(x-1) + \frac{1}{2}(e^2+1)$ is minimum. The line passes through a fixed point $(\frac{1}{2}(e^2+1))$ , and has variable slope. But, I don""t think its possible to determine the intersection points of the two curves , so I had assumed them to be $\alpha$ and $\beta$ . I performed the integral $\int (k(x-1) + 1/2(e^2+1) -e^x)dx$ from $\alpha$ to $\beta$ , (the line lies above the curve for this interval) and tried to make use of the fact that : $e^\alpha= k(\alpha-1)+\frac{1}{2}(e^2+1)$ and likewise for $\beta$ , but was still unable to get the area explicitly in terms of $k$ . There might be a geometric argument that minimizes the area but the ways these curves are, I fail to realize it. Can we have generalized method to minimize/maximize the are enclosed by them? Without explicitly knowing their intersection points?","['integration', 'area', 'definite-integrals', 'maxima-minima', 'calculus']"
3613543,From where can i start studying ODE?,I'm a undergraduate student of physics and due of the new coronavirus outbreak i'm stuck at home and i like to begin my studies on ODE. And i like to know some bibliography to where a i can start my studies. To reference i studied until now about differentiation (normal and partial) and integration until line integral. I have studied too an introduction to linear algebra.,"['soft-question', 'ordinary-differential-equations', 'reference-request']"
3613591,Seeking alternative methods for $\int _0^1\frac{\ln \left(x^2-x+1\right)}{x\left(1-x\right)}\:dx$,"I've solved this one by first tackling, $$\int _0^{\infty }\frac{\ln \left(x^2-x+1\right)}{x\left(1-x\right)}\:dx$$ But i'd like to know other ways to solve it since the way i did it was a bit lengthy and not that straightforward.","['integration', 'calculus', 'definite-integrals']"
3613594,Binary operation on $\mathbb N$,Does there exist a binary operation such that set of all-natural numbers forms a group? I saw a similar question which specifically says it needs a binary operation on the set of natural numbers forms a commutative group. I was wondering if I can find a non-commutative Group of natural numbers. I tried defining an operation such that $a*b = a$ . But can't find an identity.,"['group-theory', 'abstract-algebra']"
3613610,Cambridge IGCSE Additional Mathematics Challenge Q,"This is a challenge question from my Cambridge IGCSE Additional Maths textbook. Bear with me on the drawing. The drawing consists of a square, circle, and quarter circle. The only measurement give is that the side length of the square is $10$ cm. Can someone help me find the area of the shaded region? I am looking for an explanation of the answer as well.","['area', 'circles', 'geometry']"
3613662,"Prove that $P[B_{\tau_2 } > B_{\tau_1 } | B_{\tau_1 } ] = \frac{B_{\tau_1 } - f_2(B_{\tau_1 } , -1 )}{f_2(B_{\tau_1 } ,1 ) - f_2(B_{\tau_1 } , -1 )}$","In what follows $B_t $ denotes a Brownian Motion. My first question concerns the boject $$P[B_{\tau_2 } > B_{\tau_1 }  | B_{\tau_1 } ]$$ What probabilistic object is this referring to? Some regular conditional distribution? For the main question the context is that we have a a stopping time $\tau_1 :=  \inf \{t>0 : \ B_t \in \{a, b\} \} $ and a measurable function $f_2: \ \mathbb R \times \{-1 , 1\}  \to \mathbb R$ and have defined [it is assumed that $f_2( \bullet , -1 ) < f_2( \bullet, 1 ) $ ] $$\tau_2 := \inf \{t>0 : \ B_t \in \{f_2(B_{\tau_1 }, -1), f_2(B_{\tau_1 } , 1) \} \} $$ Then it is claimed - referring to the Strong Markov property - that $$P[B_{\tau_2 } > B_{\tau_1 }  | B_{\tau_1 } ] = \frac{B_{\tau_1 } - f_2(B_{\tau_1 } , -1 )}{f_2(B_{\tau_1 } ,1 ) - f_2(B_{\tau_1 } , -1 )}$$ I think with some reference to the (known) fact that for $a < 0 < b $ and $\tau_{a, b } := \inf \{t>0 : B_t \in \{a, b \} \} $ $$P[B_{\tau_{a, b } }  = b  ]= \frac{a}{b-a}$$ How can I prove this? Any help would be much appreciated!","['stochastic-processes', 'stopping-times', 'brownian-motion', 'probability-theory']"
3613704,What is the matrix derivative of a symmetric bilinear form $\mathbf{a}^T X \mathbf{b}$ wrt $X$?,"What is the derivative of the symmetric bilinear form $$
f_X(\mathbf{a},\mathbf{b}) = \mathbf{a}^T X \mathbf{b}
$$ with respect to the (symmetric) matrix $X$ ? Following Wikipedia , and using the denominator layout, I would say $$
\frac{\partial f_X}{\partial X}(\mathbf{a},\mathbf{b}) = \mathbf{a}\mathbf{b}^T
$$ But since $f_X$ is symmetric, $f_X(\mathbf{a},\mathbf{b}) = f_X(\mathbf{b},\mathbf{a})$ . 
If I derive this equality I obtain $$
\frac{\partial f_X}{\partial X}(\mathbf{a},\mathbf{b}) = \frac{\partial f_X}{\partial X}(\mathbf{b},\mathbf{a}) \qquad\Rightarrow\qquad \mathbf{a}\mathbf{b}^T = \mathbf{b}\mathbf{a}^T
$$ which is wrong because $\mathbf{a}\mathbf{b}^T \neq \mathbf{b}\mathbf{a}^T$ Where am I wrong?","['bilinear-form', 'matrix-calculus', 'linear-algebra', 'symmetric-matrices', 'derivatives']"
3613719,17 definitions of algebraic K-theory of a ring. Which should I take?,"There are multiple definitions of algebraic K-theory, but I have trouble differentiating between them. Could someone help me out? Let $R$ be a commutative ring. I would like to define $K_n(R)$ , and for simplicity $n \geq 0$ is OK for me now. The plus construction gives us $B\operatorname{GL}(R)^+$ , whose homotopy groups give me $K_n(R)$ for all $n \geq 0$ . The Q-construction takes as input an exact category $\mathcal{C}$ . At this point we can pick the finitely generated $R$ -modules, or the projective finitely generated $R$ -modules, or the finitely generated free $R$ -modules, or the coherent $R$ -modules. This gives us four K-theory groups $K_n(R)$ for $n \geq 0$ . All the exact categories give Waldhausen categories, to which we can apply the S-construction, yielding four more K-groups. Segal's construction involving $\Gamma$ -spaces takes in a symmetric monoidal category $\mathcal{C}$ . We can take any of the above categories, along with two choices of monoidal structure, namely $\otimes$ or $\oplus$ , yielding another eight K-theory groups $K_n(R)$ for $n \geq 0$ . Ideally, I'd like to see these definitions compared to modern ones. I've been told that one should think of algebraic K-theory as an $\infty$ -group completion procedure, but I have yet to find a readable reference on this.","['algebraic-k-theory', 'number-theory', 'algebraic-geometry', 'homotopy-theory']"
3613839,"Proving that $f(x)=x\arccos\left(1-p+p\cos\left(\frac{2\pi}{x}\right)\right)$ is increasing on $[2,\infty)$ with $0<p<1$","The function $$f(x)=x\arccos\left(1-p+p\cos\left(\frac{2\pi}{x}\right)\right)$$ on $[2,\infty)$ with $0<p<1$ is clearly increasing by looking at its graph. I calculated its derivative to be $$f'(x)=\arccos\left(1-p+p\cos\left(\frac{2\pi}{x}\right)\right)-\frac{2\pi p}{x}\frac{\sin\left(\frac{2\pi}{x}\right)}{\sqrt{1-\left(1-p+p\cos\left(\frac{2\pi}{x}\right)\right)^{2}}}$$ but couldn't prove that it is positive on the interval. I tried to prove the equivalent result $$\frac{x}{x+h} > \frac{\arccos\left(1-p+p\cos\left(\frac{2\pi}{x+h}\right)\right)}{\arccos\left(1-p+p\cos\left(\frac{2\pi}{x}\right)\right)} $$ for all $x\ge2$ and $h>0$ but couldn't deal with the $\arccos$ terms. I also calculated the limit of $f(x)$ at infinity to be $2\pi \sqrt{p}$ if this can help somehow.","['calculus', 'derivatives', 'monotone-functions']"
3613868,Should we teach congruences from the start rather than normal subgroups in group theory? [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 4 years ago . Improve this question Many students have difficulty initially with the idea of a quotient group, and why a normal subgroup is defined as it is. I think this is potentially made worse by the slightly obscure logic of the subject as presented via normal subgroups. Could we not teach it more naturally by beginning with the notion of a congruence on a group $G$ , i.e. an equivalence relation $\sim$ on $G$ such that if $g\sim g'$ and $h\sim h'$ then $gh\sim g'h'$ . It seems to me much clearer that the equivalence classes of a congruence form a group $G/\sim$ than the fact that the cosets of a normal subgroup do. We could then show that every equivalence class of a congruence is the coset of a particular associated normal subgroup. I'm wondering what people's thoughts are on the pros and cons of this presentation? *See the bottom answer here for the kind of explanation I'm talking about Is there any intuitive understanding of normal subgroup? *Depending on your position, this might not seem like an advantage, but in monoids (or semigroups) the equivalence between congruences and 'normal' submonoids is false, and we have to work with congruences. However, quotients in less algebraic contexts as well, e.g. topology, require an equivalence relation, rather than a subobject.","['group-theory', 'normal-subgroups', 'congruence-relations', 'education']"
3613930,What is the range of the function $\frac{3}{2-x^2}$,"I'm so, so very confused about finding the ranges of real functions, no concept in Mathematics has yet confused me more than this, please tell me what's wrong in my solution for finding the range of the function : $\dfrac{3}{2-x^2}$ Here's how I do it and get a partial answer, please check it out... $x^2 \geq 0$ $-x^2 \leq 0$ $2 - x^2 \leq 2$ $\dfrac {1}{2 - x^2} \geq \dfrac{1}{2}$ So, $\dfrac {3}{2 - x^2} \geq \dfrac{3}{2}$ So, $f(x) \geq \dfrac{3}{2}$ By this, $Range(f) = [\dfrac{3}{2}, ∞)$ But as per my textbook, the answer is $(-∞,0)∪[\dfrac {3}{2},∞)$ , which is (obviously) correct What my main question here is : How can I add the proof of the negative values in the range in my proof? I would be very, very grateful to you if you help (no exaggeration, I would be so very thankful cause this topic is frustrating me) Also, this is a general question : Am I the only one so confused about finding domains and ranges? I mean did you, when you began, also face problems with this concept? Thanks","['elementary-set-theory', 'algebra-precalculus', 'functions']"
3613961,"Given $4$ variables and $5$ pairwise products, find the $6$th pairwise product?","Consider four positive numbers (not necessarily integers). The pairwise products are $2$ , $3$ , $4$ , $5$ , $6$ , plus one more number. What is the 6th product? What are the numbers? I found this from Quora and I would be interested in a nice solution! If we name the four numbers $x_1, x_2, x_3, x_4$ and the missing product $p_6$ , then all of the possible products are: $$x_1 x_2,\quad
x_1 x_3,\quad
x_1 x_4,\quad
x_2 x_3,\quad
x_2 x_4,\quad\text{and}\quad
x_3 x_4$$ There are six equations and five unknowns, but I don't know how to assign the six different numbers to each of them. I understand that the partial products which do not share a common factor (for example, $x_1 x_2$ and $x_3 x_4$ ) should not be assigned to numbers which do have a common factor, for example $2$ and $4$ , or $2$ and $6$ , or $3$ and $6$ .","['algebra-precalculus', 'arithmetic']"
3614000,Is every group $G$ a subgroup of index $2$ of some $\tilde G$?,"Let $(G,f)$ be a group (so $f$ stands for the group operation), $H\lneq G$ and $\complement_GH:=G\setminus H$ . Then: \begin{alignat}{1}
&f(H,H)\subseteq H \\
&f(H,\complement_GH)\subseteq\complement_GH \\
&f(\complement_GH,H)\subseteq\complement_GH \\
&[G:H]=2 \Rightarrow f(\complement_GH,\complement_GH)\subseteq H \\
\tag 1
\end{alignat} Reminiscent of this fact, I wonder whether a supergroup of $G$ can be built up, say $\tilde G$ , such that $[\tilde G:G]=2$ . Namely: Is every group $G$ a subgroup of index $2$ of some $\tilde G$ ? I think that's true, based on the following. Let $G$ be a group and $X_G$ a set such that: $X_G\cap G=\emptyset$ ; there is a bijection $\alpha\colon X_G\to G$ . Let's define $\tilde G:=G\cup X_G$ and $\cdot : \tilde G\times\tilde G \to \tilde G$ by: \begin{alignat}{1}
&a)\space g\cdot h:=gh, \space\forall g,h \in G \\
&b)\space g\cdot x:=\alpha^{-1}(g\alpha(x)), \space\forall g \in G, x\in X_G \\
&c)\space x\cdot g:=\alpha^{-1}(\alpha(x)g), \space\forall g \in G, x\in X_G \\
&d)\space x\cdot y:=\alpha(x)\alpha(y), \space\forall x,y\in X_G \\
\tag 2
\end{alignat} Associativity It holds in $G$ by definition. Besides, $\forall g,h \in G, \forall x \in X_G$ : \begin{alignat}{1}
(g\cdot h)\cdot x &= (gh)\cdot x \\
&= \alpha^{-1}(gh\alpha(x)) \\
\end{alignat} and \begin{alignat}{1}
g\cdot (h\cdot x) &= \alpha^{-1}(g\alpha(h\cdot x)) \\
&= \alpha^{-1}(g\alpha(\alpha^{-1}(h\alpha(x)))) \\
&= \alpha^{-1}(gh\alpha(x)) \\
\end{alignat} whence: $$g\cdot (h\cdot x) = (g\cdot h)\cdot x \tag 3$$ Likewise, $\forall g,h \in G, \forall x \in X_G$ : \begin{alignat}{1}
(g\cdot x)\cdot h &= \alpha^{-1}(\alpha(g\cdot x)h) \\
&= \alpha^{-1}(\alpha(\alpha^{-1}(g\alpha(x)))h) \\
&= \alpha^{-1}(g\alpha(x)h) \\
\end{alignat} and \begin{alignat}{1}
g\cdot (x\cdot h) &= \alpha^{-1}(g\alpha(x\cdot h)) \\
&= \alpha^{-1}(g\alpha(\alpha^{-1}(\alpha(x)h))) \\
&= \alpha^{-1}(g\alpha(x)h) \\
\end{alignat} whence: $$g\cdot (x\cdot h) = (g\cdot x)\cdot h \tag 4$$ Furthermore, $\forall g \in G, \forall x,y \in X_G$ : \begin{alignat}{1}
(g\cdot x)\cdot y &= \alpha(g\cdot x)\alpha(y)\\
&= \alpha(\alpha^{-1}(g\alpha(x)))\alpha(y)\\
&= g\alpha(x)\alpha(y)\\
&= g(\alpha(x)\alpha(y))\\
&= g\cdot(\alpha(x)\alpha(y))\\
&= g\cdot(x\cdot y)\\
\tag 5
\end{alignat} Finally, $\forall x,y,z \in X_G$ : \begin{alignat}{1}
(x\cdot y)\cdot z &= (\alpha(x)\alpha(y))\alpha(z)\\
&= \alpha(x)(\alpha(y)\alpha(z)) \\
&= x\cdot(y\cdot z) \\
\tag 6
\end{alignat} Unit Note that: by $(2$ - $b)$ : $\space$ $e\cdot x=\alpha^{-1}(e\alpha(x))=\alpha^{-1}(\alpha(x))=x, \space\forall x \in X_G$ by $(2$ - $c)$ : $\space$ $x\cdot e=\alpha^{-1}(\alpha(x)e)=\alpha^{-1}(\alpha(x))=x, \space\forall x \in X_G$ and $e$ serves as unit throughout $\tilde G$ . Inverses Let's define: $$x^{-1}:= \alpha^{-1}(\alpha(x)^{-1}), \forall x \in X_G \tag 7$$ Therefore, by $(2$ - $d)$ and $(7)$ : $\space$ $x\cdot x^{-1}=\alpha(x)\alpha(x^{-1})=\alpha(x)\alpha(\alpha^{-1}(\alpha(x)^{-1}))=\alpha(x)\alpha(x)^{-1}=e, \space\forall x \in X_G$ and $x^{-1}$ serves as inverse of the element $x \in X_G$ . Seemingly, $\tilde G$ , endowed with the operation $(2)$ , is indeed a group, and $[\tilde G:G]=2$ .","['group-theory', 'abstract-algebra', 'solution-verification']"
3614026,Is a normal subgroup normal in a normal group?,"Let $G$ be a normal ( $T_4$ ) topological group, that is, every two disjoint closed sets of $G$ have disjoint open neighborhoods. Let $H$ be a subgroup of $G$ that is normal too ( $T_4$ ) with the induced subspace topology. Is $H$ a normal subgroup of $G$ ? That is, $\forall g \in H \, $ , $ \, gH=Hg \ \ $ ? This question came up as a pun and evolved into a sincere question to which I did not get a definitive answer.","['general-topology', 'normal-subgroups', 'topological-groups', 'group-theory']"
3614036,Prove that $A \vartriangle B \subseteq C$ iff $A \cup C = B \cup C$.,"This is an exercise from Velleman's ""How To Prove It"". The end of chapter questions have escalated in difficulty, so I just want to make sure that I am on the right track. Suppose $A$ , $B$ , and $C$ are sets. Prove that $A \vartriangle B \subseteq C$ iff $A \cup C = B \cup C$ . Proof: Suppose $A \vartriangle B \subseteq C$ . Let $x$ be arbitrary. Suppose $x \in A \cup C$ , then either $x \in A$ or $x \in C$ . We consider these two cases: Case 1. $x \in A$ . Suppose $x \notin B \cup C$ . So $x \notin B$ and $x \notin C$ . Since $x \in A$ and $x \notin B$ , $x \in A\setminus B$ . It follows that $x \in A \setminus B \cup B \setminus A$ , so $x \in A \vartriangle B$ . Since $A \vartriangle B \subseteq C$ and $x \in A \vartriangle B $ , $x \in C$ . But then we have $x \in C$ and $x \notin C$ , which is a contradiction. Thus, $x \in B \cup C$ Case 2. $x \in C$ . It immediately follows that $x \in B \cup C$ . In every case, we have shown that $x \in B \cup C$ . The proof of $x \in B \cup C \implies x \in A \cup C$ will be similar, but with the roles of $A$ and $B$ switched. Therefore, $A \cup C = B \cup C$ . Now suppose $A \cup C = B \cup C$ . Let $x \in A \vartriangle B$ be arbitrary. Then $x \in A \setminus B \cup B \setminus A$ , which means that $x \in A \setminus B$ or $x \in B \setminus A$ . We consider these two cases: Case 1. $x \in A \setminus B$ . Then $x \in A$ and $x \notin B$ . Suppose $x \notin C$ . Then since $x \notin B$ and $x \notin C$ , $x \notin B \cup C$ . Since $x \in A$ , $x \in A \cup C$ . Then since $A \cup C = B \cup C$ , $x \in B \cup C$ . But then we have $x \in B \cup C$ and $x \notin B \cup C$ , which is a contradiction. Thus, $x \in C$ . Case 2. $x \in B \setminus A$ . By similar reasoning as case 1 with $A$ and $B$ switched, we also find that $x \in C$ . In every case, we have shown that $x \in C$ . Since $x$ was arbitrary, it follows that $A \vartriangle B \subseteq C$ . Therefore, $A \vartriangle B \subseteq C$ iff $A \cup C = B \cup C$ . $\square$","['elementary-set-theory', 'proof-writing', 'solution-verification']"
3614107,How do you create a custom probability density function from a discrete distribution?,"I have some data that follows some unknown probability function. I would like to roughly extract that probability function. My approach is to plot the data in a histogram and smooth it out using LOWESS . I implemented this following this post. I then use interpolation to create my cumulative distribution function (or at least I think so). But here I am stuck. I know I have to normalize the distribution somehow, but simply dividing by the number of data points does not seem to do the trick (read: something is completely wrong). How do I do this? Is there a better approach? I would like to implement all of this in Python. Here is my code so far: import numpy as np
from scipy import interpolate, integrate
from scipy.stats import rv_continuous
import statsmodels.api as sm
import matplotlib.pyplot as plt


class CustomDistribution(rv_continuous):
    def __init__(self, custom_cdf):
        super().__init__()
        self.custom_cdf = custom_cdf

    def _pdf(self, x, *args):
        return self.custom_cdf(x)

    # def _ppf(self, q, **kwargs):
    #     return


# create some normally distributed values and make a histogram
a = np.random.normal(size=10000)
counts, bins = np.histogram(a, bins=100, density=True)
bin_widths = np.diff(bins)
bin_centers = bins[:-1] + bin_widths

# roughly try to fit some distribution
lowess = sm.nonparametric.lowess(counts, bin_centers, frac=0.1)
fit = interpolate.interp1d(
    lowess[:, 0], lowess[:, 1], kind='cubic', fill_value=0,
    bounds_error=False
)

# integral = integrate.quad(fit, -np.inf, np.inf)[0]
# print(integral)
distr = CustomDistribution(fit)
# print(distr.rvs(size=1))

plt.hist(a, 100, density=True, label='original data')
plt.plot(bin_centers, fit(bin_centers), label='fit')
plt.hist(distr.rvs(size=100), 100, density=True, label='data from fit')
plt.legend()
plt.show() In order to be able to draw random variates from this distribution later on, I also need to implement the inverse cdf / _ppf() , according to the rv_continuous documentation . EDIT So I have been able to draw some random variates from the fit, but it takes incredibly long. The main reason seems to be that in order to draw the variates, I need to have a properly implemented inverse cdf / _ppf() . From the documentation of rv_continuous : The default method _rvs relies on the inverse of the cdf, _ppf, applied to a uniform random variate. In order to generate random variates efficiently, either the default _ppf needs to be overwritten (e.g. if the inverse cdf can expressed in an explicit form) or a sampling method needs to be implemented in a custom _rvs method. Because I don't have that, the cdf is created by integrating over the pdf, but for some reason, the integral does not seem to converge: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.
  If increasing the limit yields no improvement it is advised to analyze 
  the integrand in order to determine the difficulties.  If the position of a 
  local difficulty can be determined (singularity, discontinuity) one will 
  probably gain from splitting up the interval and calling the integrator 
  on the subranges.  Perhaps a special-purpose integrator should be used. So I guess I need a good way to create my own implementation of at least the cdf, but better yet of the inverse cdf.","['python', 'statistics', 'probability-distributions']"
3614136,Limits on locally convex spaces,"A curve on a locally convex space is a function $\gamma : I \to F$ where $F$ is a locally convex space and $I \subseteq \mathbb{R}$ is an interval. The curve is differentiable if the following limit exists: $$ \gamma'(x) := \lim_{t \to 0}\frac{\gamma(x+t)-\gamma(x)}{t} $$ but what does this limit mean? I mean...elements $\gamma(x+t)$ and $\gamma(x)$ are in a lcs and this is not (necessarily) a normed space. I'm really stuck at this definition. If $F$ is locally convex, then it is a topological vector space (with, say, a topology given by a family of seminorms). The notion of a limit is replaced by the following. Definition: Let $f: I \subseteq \mathbb{R} \to F$ . We write $\lim_{x \to a}f(x) = L$ if for every neighborhood $V$ of the origin there exists $\delta > 0$ such that $0 \lt |x-a| \lt \delta$ implies $f(x) - L \in V$ . Is this the right definition?","['locally-convex-spaces', 'functional-analysis', 'analysis']"
3614150,Wasserstein distance of conditional measures,"Suppose I have two measures $\mu,\nu$ defined on a common measurable space. 
Let $A$ be an event in the common sigma-field. Let $\mu^A(C) = \frac{\mu(A\cap C)}{\mu(A)}$ and $\nu^A(C) = \frac{\nu(A\cap C)}{\nu(A)}$ be the corresponding conditional measures. 
Is there a way of relating the Wasserstein distance $W_p(\mu^A,\nu^A)$ to $W_p(\mu,\nu)$ ? 
Can we say something on the optimal coupling of $\mu^A,\nu^A$ if we know the optimal coupling of $\mu,\nu$ ? $W_p(\mu^A,\nu^A)$ seems to be larger, since, denoting with $\pi^*$ the optimal coupling between $\mu^A,\nu^A$ : $$ \int_\cal{X}\int_\cal{\tilde{X}} d(x,\tilde{x})d\pi^*(x,\tilde{x})= \frac{1}{\mu(A)}\int_A\int_\cal{\tilde{X}} d(x,\tilde{x})d\mu(x)\pi^*(\tilde{x}|x), $$ but I have no idea what I could say about the disintegration $\pi^*(\tilde{x}|x)$ once we take the ""marginal"" $d\mu^A$ out, could it compensate for the extra $\frac{1}{\mu(A)}$ ?","['measure-theory', 'optimal-transport', 'probability-theory']"
3614247,What is symplectic geometry? [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 4 years ago . Improve this question EDIT: Much thanks for answers. As was pointed out, the question as it stands is a little too broad. Nevertheless, I don't want to delete it, because I think that such introduction-style questions can be answered without writing a book, rather something more like an introduction to a book and fits here. Moreover, commenters have linked to great resources, and this question might help someone else. I made a follow up strictly narrower question instead. First some background, so that you know where I came from. But the question in the title stands as it is, if you want to answer without appealing to what is below, please do. I am currently learning about Lie groups. One of the first things that I've seen are the classical groups , and the classical group that I want to talk about today is the symplectic group $\mathrm{Sp}(n,\mathbb{F})$ . The definition of $\mathrm{Sp}(n,\mathbb{F})$ I am familiar with is as follows: Let $\omega$ be an skew-symmetric bilinear form on $\mathbb{F}^{2n}$ , which is unique up to change of basis. It is given by the formula $$\omega(\mathbf{x},\mathbf{y}) = \sum_{i=1}^n{x_iy_{i+n}-y_ix_{i+n}}$$ Why is this symplectic form important? We can then write out the definition $$\mathrm{Sp}(n,\mathbb{F}) = \left\{ A: \mathbb{F}^{2n} \to \mathbb{F}^{2n} \mid \omega(A\mathbf{x},A\mathbf{y}) = \omega(\mathbf{x},\mathbf{y}) \text{ for all } \mathbf{x,y} \in \mathbb{F}^{2n}\right\}$$ I can see the analogue of $O(n,\mathbb{F})$ . We also have some bilinear form that needs to be preserved, namely the inner product $\langle \cdot,\cdot\rangle$ . But more importantly, elements of $O(n,\mathbb{F})$ are really easy to visualize, because I intuitively know what a rigid transformation is. So the important question for me is How to visualize symplectic transformations? And I tried to research this question, and I stumbled upon the topic of symplectic linear spaces and symplectic manifolds . A symplectic vector space is defined analogous to Euclidean vector space, but the inner product is again substituted by symplectic form. What is a symplectic vector space, intuitively? I saw that the intuition behind these things should be that $\mathbb{R}^{2n}$ should be treated as a space of positions and velocities , a phase space . And I don't understand it. But I feel that physical intuition would be really helpful. What is the connection of classical mechanics with symplectic geometry? I don't know classical mechanics, sadly, so a quick mathematical rundown would be appreciated. All the questions that I've asked above could be summarized to one question: What is symplectic geometry?","['symplectic-geometry', 'classical-mechanics', 'linear-algebra', 'symplectic-linear-algebra', 'lie-groups']"
3614250,The Hodge diamond of a Calabi-Yau Fourfold,"I am studying the String Theory book by Becker, Becker, and Schwarz, and I decided to verify the Hodge diamonds for a CY3 and a CY4. These can be found on page 365 and they are eq.(9.14) and (9.16). It was very easy for me to derive the precise form of the Hodge diamond following what they mention in the book. A problem arose when I tried to repeat the computation for the case of a CY4. Let me first state the problem/question. Why for a CY4 the Hodge number $h^{2,0}$ is equal to zero? This is not obvious to me from the relations they give in the book. Allow me to show you how I have worked out the rest of the elements of the Hodge diamond. Let me write here the properties the book gives for the Hodge numbers. For a Calabi-Yau n-fold we have that -these are eq.(9.10)-(9.12) in the book $\begin{equation}
\begin{split}
h^{p,0} &= h^{n-p,0} \\
h^{p,q} &= h^{q,p} \\
h^{p,q} &= h^{n-q,n-p}
\end{split}
\end{equation}$ and we know that for a simply connected manifold $h^{1,0}=h^{0,1}=0$ and that a compact connected Kahler manifold has $h^{0,0}=1$ . From the first of the above properties, we have the following relations $\begin{equation}
\begin{split}
&h^{4,3} = h^{3,4}, \qquad h^{4,2} = h^{2,4}, \qquad h^{4,1} = h^{1,4}, \qquad h^{4,0} = h^{0,4}, \qquad \qquad h^{3,2} = h^{2,3}, \qquad h^{3,1} = h^{1,3}, \\
&h^{3,0} = h^{0,3}, \qquad h^{2,1} = h^{1,2}, \qquad h^{2,0} = h^{0,2}, \qquad h^{1,0} = h^{0,1}
\end{split}
\end{equation}$ From the second property we have $\begin{equation}
h^{4,0} = h^{0,0} \qquad h^{3,0} = h^{1,0}
\end{equation}$ And finally, from the third one we obtain $\begin{equation} 
h^{4,4} = h^{0,0}, \qquad h^{4,3} = h^{1,0}, \qquad h^{4,2} = h^{2,0}, \qquad h^{4,1} = h^{1,0}, \qquad h^{3,3} = h^{1,1}, \qquad h^{3,2} = h^{2,1}.
\end{equation}$ The undetermined $h^{2,2}$ is given by -see eq.(9.17) $\begin{equation}
h^{2,2} = 2 (22+2h^{1,1}+2h^{1,3}-h^{1,2})
\end{equation}$ If we impose all of the above to the Hodge diamond we get precisely what is shown in the book with the only difference that in the book they seem to have that $h^{2,0}=0$ which I cannot obtain.","['algebraic-geometry', 'homology-cohomology', 'de-rham-cohomology', 'differential-geometry']"
3614323,Has anyone tried relating the projective plane to the Riemann Zeta function?,"I have a very vague intuitive idea which I have been struggling to give a meaningful definition to, and was wondering if this idea I am working on has been tried before.  I apologize if I am unable to formulate these abstract intuitive idea's better than this; I am trying to work on my exposition for this type of question, so any advice is much appreciated. I want to treat the analytic continuation of the zeta-function as some kind of conformal mapping between two regions, $A$ $B$ of the complex plane, with $\zeta : A \rightarrow B$ , which satisfy the following two properties Neither $A$ nor $B$ are the entire complex plane One or both of $A$ or $B$ are not simply connected One of the guiding principles I have is that the singularity at $z=1$ somehow represents ""the point at infinity in the Riemann sphere"" and to ""treat the entire complex plane as a projective plane in the sense of projective geometry"", and that the critical region between $z=0$ and $z=1$ is somehow related to ""the topology of the projective plane"" Intuitively, at least for me, the projective plane is a ""twisted up 2 dimensional space where you cover a watermelon with cellophane and then twist it off at the top and glue it back together in a non-realistic non-physical way"" More rigorously, we can represent the topology of the projective plane as a square, or so-called ""fundamental rectangle"", where the sides of the square are ""glued together"" in a specific way as shown in this picture I just had the most strange idea which is to try and make the singularity of the zeta-function at $z=1$ a point at infinity in the projective plane, and to try and map the critical strip to the so-called ""twist off"" section of the projective plane which results from ""gluing together"" the fundamental rectangle in the described way There are many reasons I was led to this kind of approach, but at this time I have no idea if anyone has ever tried this before, or if this is a very bad/silly idea that won't work.  I will only provide one more piece of information about the motivation at this time, feel free to ask if you are curious in the comments. The basic idea is to figure out if it's possible to show that the critical line, $Im(z)=\frac{1}{2}$ , corresponds somehow to the ""line at infinity"" in the projective plane (EDIT: Here is one way to view the complex plane as a projective plane: consider a 3-dimensional real space and imagine a unit sphere centered at the origin. Construct the projective plane using the standard definition of the set of all lines passing through the origin. Project all points of 3-d space onto the surface of this sphere with this construction in a 2-1 way; then project all the  points on the surface of this sphere (except for one) onto the complex plane using the Riemann sphere projection.)","['riemann-zeta', 'general-topology', 'projective-geometry', 'projective-space']"
3614341,A weird differential equation with some unknown trick?,"Here is the differential equation I need to solve: $$y=xy'+k\cdot \frac{y'}{y'-1}$$ (Here $k$ is a given constant). What I have thought initially is to rewrite $\frac{y'}{y'-1}$ as $\left(1+\frac{1}{y'-1}\right)$ . But I don't think it helps that much. Hope someone could give me a hint. Also, in the question, we are asked to consider $k>0$ and $k<0$ separately. There is definitely a reason why behind this, but I have not figured that out. Thanks :))",['ordinary-differential-equations']
3614692,The relationship between different cohomology theories of varieties and manifolds.,"I am reading some books about etale cohomology theory. I found there are some theorems which are very similar with the topological theorems. For example, there are Poincare Duality theorems for both schemes and manifolds. So my first question is if there are relationships between the theorems of schemes and manifolds. We know that for general topological spaces, we could consider the sheaf cohomology. So I wonder if we could consider etale coholomgy theories for manifolds? In other words, could we generalize etale cohomology for manifolds? Now, when we consider the varieties over $\mathbb{C}$ , we have three different cohomology theories: singular cohomology, sheaf cohomology and etale cohomology. I feel they are all equivalent, although I can not describe what the equivalence exactly means. So my next question is if there is any method to describe the equivalence between these three cohomology theory for complex varieties. I also notice for manifolds we have singular homology theories. However, when I study algebraic geometry, there are all cohomology theories, such as sheaf cohomology, Cech cohomology, etale cohomology, etc. I wonder if there are some homology theories for schemes? Why we do not consider homology for schemes? I think these are soft problems and may do not have exact answers. So could you explain some ideas  or recommend some books for me to read? Thank you very much for your help.","['etale-cohomology', 'soft-question', 'algebraic-geometry', 'homology-cohomology', 'algebraic-topology']"
3614722,Deducing $f(x)=f(x_0)+f'(x_0)(x-x_0)+\frac12(x-x_0)^TH_f(x_0)(x-x_0)+o(\lVert x-x_0\rVert^2)$,This was a task that gave $9$ points in an exam I failed. Since our professor doesn't provide solutions I thought I'd ask here. Let $f:\mathbb{R^2} \to \mathbb{R}$ be twice continuous partially differentiable and $x_0 \in \mathbb{R^2}$ random. Deduce the following formula for $x \in \mathbb{R^2}$ using Taylor's theorem: $$f(x)=f(x_0)+f'(x_0)(x-x_0)+\frac{1}{2}(x-x_0)^TH_f(x_0)(x-x_0)+o(\lVert x-x_0 \rVert^2).$$ Complete the remainder of the second order and show that for the remaining terms $T$ it holds that $$\lim_{x \to x_0} \frac{T(x)}{\lVert x-x_0 \rVert^2} = 0$$ Can someone tell us how to do this? The total derivate is defined as: $$\lim_{x \to \alpha} \frac{\lVert f(x)-f(a)- df_a(x-a)\rVert}{\lVert x-a \rVert} = 0$$ I think from this one can get the difference of the norm which was given an estimate of in the task...,"['multivariable-calculus', 'taylor-expansion']"
3614761,Is there a generating function for any finite sequence of random numbers?,"hypothesis: for any finite sequence of random positive integers exists a generating function. If the hypothesis is true, is there a structured way of finding a generating function for a finite sequence of random positive integers? Here is what I understand from the past 2 days of reading: A generating function for Fibonacci numbers - eventhough it doesn't have much to do with my question - is: \begin{eqnarray*}
\frac{1}{1− (x + x ^ 2)}
\end{eqnarray*} where: \begin{eqnarray*}
\frac{1}{1− (x + x ^ 2)} =1 + x + 2  x ^ 2 + 3  x ^ 3 + 5  x ^ 4 + 8  x ^ 5+ \cdots 
\end{eqnarray*} The coefficients are Fibonacci numbers, i.e. the sequence {1,1,2,3,5,8,13,21, ...}. But if I have a finite sequence of random numbers, for example {4,5,0,9,1,5}
Is there a method of finding its generating function?","['integration', 'calculus', 'functions', 'discrete-mathematics', 'generating-functions']"
3614793,How do I solve this integral equation?,"Case 1: We will look at an easier problem first. Let $|\alpha|, |\beta| \leq \alpha_c, \alpha_c \leq \pi$ . I want to solve for $\rho(\beta)$ in the following equation, where $P$ denotes the principal value of the integral: $$\frac{2\sin{\alpha}}{\lambda} = P\int_{-\alpha_c}^{\alpha_c} d\beta \, \rho(\beta) \, \cot{\frac{\alpha -\beta}{2}}$$ Note here that $\rho(\beta)$ satisfies the following constraint:
. $$\int_{-\alpha_c}^{\alpha_c}d\beta \, \rho(\beta) =1, \quad  \rho(\beta) \geq 0$$ As given from eqns 23 - 30 in Gross and Witten's paper, there are two separate analytic functions which solve this integral equation for $\lambda \geq 2$ , and $\lambda \leq 2$ . The physical input which helps in solving this equation is that for very large $\lambda$ , $\rho(\beta)$ is constant and is spread over the whole circle $(-\pi, \pi)$ . They find a solution using this which is valid till $\lambda =2$ , after which they construct a different solution for $\lambda \leq 2$ . The solution $\rho(\alpha)$ is given by: \begin{align}
\rho(\alpha) & =\frac{2}{\pi \lambda} \cos{\frac{\alpha}{2}} \left( \frac{\lambda}{2} - \sin^2 \frac{\alpha}{2}\right)^{1/2}, \quad \lambda \leq 2 \quad \text{with} \quad |\alpha| < 2 \sin^{-1}\left( \frac{\lambda}{2}\right)^{1/2}\\
             & = \frac{1}{2\pi} \left( 1 + \frac{2}{\lambda}\cos{\alpha}\right), \quad \lambda \geq 2\quad |\alpha| \leq \pi.
\end{align} Case 2: Here's my problem. Let $|\alpha|, |\beta| \leq \alpha_c, \alpha_c \leq \pi$ . I want to solve for $\rho(\beta)$ in the following equation, where $P$ denotes the principal value of the integral: $$\frac{2\sin{\alpha}}{\lambda} = P \,k\int_{-\alpha_c}^{\alpha_c} d\beta \, \rho(\beta) \, \frac{\cot{\frac{\alpha -\beta}{2}}}{\left(\sin{\frac{\alpha -\beta}{2}}\right)^k} $$ Here $k \in \mathbb{N}$ . As before, again $\rho(\beta)$ satisfies the following constraint:
. $$\int_{-\alpha_c}^{\alpha_c}d\beta \, \rho(\beta) =1, \quad  \rho(\beta) \geq 0$$ Note that here also for very large $\lambda$ , $\rho(\beta)$ should become  constant and go to $1/{2\pi}$ . How do I solve this?","['integration', 'trigonometric-series', 'integral-equations']"
3614800,isolated point of spectrum of compact self-adjoint linear operator on infinite-dimensional separable Hilbert space.,"Let $H$ be an infinite-dimensional separable Hilbert space over $\mathbb{R}$ , and let $K : H \to H$ be
a compact self-adjoint linear operator. Prove that if $0$ is an isolated point of the spectrum of $K$ , then $0$ is an eigenvalue of $K$ with infinite-dimensional eigenspace. My attempt: since $K$ is compact operator on  an infinite dimensional hilber space we have that $0\in \sigma(K)$ and $\sigma(K)=\sigma_p(K) \cup\{0\}$ .  Suppose that $0 \notin \sigma_p(K)$ , then it must be that there exists some sequence $(\lambda_j)_{j\ge 1}\in \sigma_p(K)$ such that $\lim_{j\to \infty}\lambda_j = 0 $ . But since $0$ is an isolated point of the spectrum , such sequence cannot exists. Hence , $0\in \sigma_p(K)$ . Also, Since $H$ is separable let $(e_n)_{n\ge 1}$ be the orthonormal basis then since $\lambda =0$ is an eigenvalue of $K$ , we have that $\forall e_n \implies K(e_n)=0(e_n)$ , so all basis vectors (which are countably infinite) can be the eigenvectors for the eigenvalue $0$ , so dimension of the eigenspace is also infinite.","['compact-operators', 'analysis', 'solution-verification', 'functional-analysis', 'spectral-theory']"
3614824,"The degree-2 curves through three points is given by $\gamma L_1L_2+\lambda L_2L_3+\mu L_3L_1=0$, where the $L_i$ are the lines joining those points","I came across this equation while reading on conics and circles. The family of degree- $2$ curves passing through three points is given by $$\gamma L_1L_2 + \lambda L_2L_3 + \mu L_3L_1 = 0$$ where $L_1$ , $L_2$ , and $L_3$ are the equations of lines joining the three points, and $\lambda$ , $\mu$ and $\gamma$ are parameters. I can see that the three points definitely satisfy this equation , but I am unable to say much about rest of the points. How would you prove this relation? Explain, please. :-)","['coordinate-systems', 'conic-sections', 'geometry']"
3614836,Flow and flow rate... Halp!,"I'm so confused... 
I think I got the meaning of flux, it's a scalar that indicates the ""quantity of a vector field (of field lines)"" that crosses a surface of a given area.
So no time relation implied right? First: is flow and flux the same thing in English when talking about physics? (in Italian we just refer to it with the word ""flusso"") Why I often read, about fluid flow (flux?) :
it's the quantity that measures volume that crosses a surface per unit time? Is this a misunderstanding? is this the definition of flow rate? Is flow rate and flow the same thing in the field of velocity of a fluid? Is the mass ( or volume) of the fluid bond to the vectorial field in a fluid, or I can just pick the velocity of a point in the fluid without considering the mass? Is flow rate the dual of current for an electromagnetic field? How is current related to flux? Maybe the key is the divergence theorem... I need some sleep +.+ It's a lot of questions but they are strictly related to each other, I guess, the point is that I studied those things separately, I can't build an organic connection in my head.","['multivariable-calculus', 'electromagnetism', 'fluid-dynamics']"
3614864,Why are most natural phenomena described using differential equations?,"I noticed that most equations that I've encountered in physics and engineering classes are formulated as differential equations. Some examples I can think of on top of my head are Newton's 2nd law, the wave equation, Maxwell's equations, etc. My question is, what's so special about differential equations that make them the optimal tool to model natural phenomena?",['ordinary-differential-equations']
3614873,"What does $A\iff B$ mean with respect to ""sufficiency"" and ""necessity""?","If I have $A \iff B,$ does that means $A$ is sufficient for $B$ to occurs and $B$ is necessary for $A$ to occurs? I am confused about the direction of meaning sufficient and meaning necessary, I usually say $\implies$ this direction means the premises is sufficient for the result i.e. $A \implies B$ means $A$ is sufficient for $B$ to occur. And $\Longleftarrow $ means the premises is sufficient for the result i.e. $B \impliedby A$ means $B$ is necessary for $A$ to occur. But I have seen some people not sticking to this and taking reverse directions for necessary and sufficient. Could anyone explains this for me please?","['elementary-set-theory', 'logic']"
3614888,"$\forall x,y \in \mathbb{R^n}: x,y \in U => \left\lVert f(x) - f(y) \right\rVert \geq c \left\lVert x - y \right\rVert$ globally invertible","Let $f:U \subset \mathbb{R^n} \to \mathbb{R}^n$ be totally differentiable and there exists a constant $c > 0$ , so that $$\forall x,y \in \mathbb{R^n}: x,y \in U => \left\lVert f(x) - f(y) \right\rVert \geq c \left\lVert x - y \right\rVert$$ Prove that $f:U \to f(U)$ is globally invertible. Choose an random but constant $x$ or $y$ in $U$ .
Rewrite $f(x) - f(y)$ and use the fact that a linear function of $\mathbb{R^n}$ to $\mathbb{R}^n$ is injective iff only the zero vector maps to the zero vector. I know that a function $f$ is globally invertible if $f$ is bijective. This must imply that one has to prove that the function is injective and surjective. This requires the inverse function and my guess is that the implicit function theorem can prove what is asked for above, but I don't know how to apply the theorem in this case. Can someone show how it's done?","['proof-writing', 'inverse-function', 'calculus', 'implicit-function-theorem', 'derivatives']"
3614895,Finding a closed form for $\sum_{k=0}^n (k^3-k-3)$ using generating functions,"I have been given a few hints. first of all I've been told to use the formula (for general series $a_n,b_n$ ): $$\sum_{n=0}^\infty\left(\sum_{k=0}^n a_k b_{n-k}\right)x^n=\left(\sum_{i=0}^\infty a_i x^i\right)\left(\sum_{i=0}^\infty b_i x^i \right)$$ The direction I'm going with is simplifying the generating function of the series $\sum_{n=0}^\infty\left(\sum_{k=0}^n k^3-k-3 \right)x^n$ such that we set $a_k=k^3-k-3,b_k=1$ and thus get: $$\left(\sum_{n=0}^\infty \left(k^3-k-3\right)x^n\right)\left(\sum_{n=0}^\infty x^n\right)$$ After simplifying A lot I finally got to the form $\frac{3x^{3}-3x^{2}+9x-3}{\left(-x+1\right)^{5}}$ . I know this is not the intended way to do it because I have no idea how to get the coefficients from this. any help would be apperciated.","['generating-functions', 'combinatorics', 'discrete-mathematics', 'sequences-and-series']"
3614896,Does there exist a formal set-theoretic definition of a matrix?,"In mathematics, there are many objects that can be defined purely in terms of sets (e.g. $(a,b)=\{\{a\},\{a,b\}\}$ for ordered pairs, among others). I was wondering if there is a purely set-theoretic definition of a matrices. For example, how could one define the matrix $$\begin{bmatrix}1 & 3 &\pi \\ \cos{(3)} & 33 &0\end{bmatrix}$$ purely in terms of sets? Many thanks.","['matrices', 'recreational-mathematics', 'elementary-set-theory']"
3614938,"Finding the critical points of $f(x,y) = \sin(x)\sin(y)$","I am attempting to find the critical points of a function for local max min purposes and have gotten stuck. The function is $$f(x,y) = \sin(x)\sin(y)$$ Bounded by $-\pi < x < \pi$ and $-\pi < y < \pi$ . I have the partial derivative wrt to $x$ as: \begin{equation}
\frac{\partial f}{\partial x} = \cos(x)\sin(y)
\end{equation} and the partial derivate wrt to $y$ as: \begin{equation}
\frac{\partial f}{\partial y} = \cos(y)\sin(x)
\end{equation} I now want $$\cos(y)\sin(x) = 0 = \sin(x)\cos(y)$$ For \begin{equation}
\frac{\partial f}{\partial x} = 0
\end{equation} Then $\sin(x) = 0$ when $x = 0$ , OR $\cos(y) = 0$ when $y = -\pi/2$ and $\pi/2$ . For \begin{equation}
\frac{\partial f}{\partial y} = 0
\end{equation} then $\sin(y) = 0$ when $y = 0$ , OR $\cos(x) = 0$ when $x = -\pi/2$ and $\pi/2$ . My question is how do I actually arrange these values into critical points properly?","['maxima-minima', 'multivariable-calculus', 'trigonometry']"
3614968,Solve $4y(y')^2-4x(y')^3-2(y')^2-1=0$,"I recently came across the following differential equation: $$4y(y')^2-4x(y')^3-2(y')^2-1=0$$ I am not completely sure how to approach a general solution to such an equation, since I am only familiary with simple linear differential equations. I nevertheless attempted to fit the form $y=ax^n+b$ to the equation. This resulted in the following equation: $$4(ax^n+b)(anx^{n-1})^2-4x(anx^{n-1})^3-2(anx^{n-1})^2-1=0$$ $$4a^3n^2x^{3n-2}(1-n)+2a^2n^2x^{2n-2}(2b-1)=1$$ I then deduced that either $3n-2=0$ or $2n-2=0$ , since we have a constant term on the right hand side. Splitting into cases, this gives the equation $2a^2(2b-1)=1$ for $n=1$ and the solution $y=(\frac{27}{16})^{\frac{1}{3}}x^{\frac{2}{3}}+\frac{1}{2}$ for $n=\frac{2}{3}$ . Is my work thus far correct and valid for the situation, especially assuming that one of the exponents of $x$ had to be $0$ ? Also, this does not necessarily find all possible solutions, since it assumes that $y$ is a power law type function. How could I find other solutions?",['ordinary-differential-equations']
3615061,"Give an example, with proof, of a function differentiable at a point, whose derivative is non-differentiable that point.","This question was labeled as either prove or disprove. I think that this is impossible, here is my reasoning: Any function $f(x)$ with asymptotic behavior at some point $x=a$ will hold this asymptotic behavior in the function $F(x)=\int f(x) \, dx$ . We have not yet covered any technical terms with integration, only differentiation. Help greatly appreciated!","['derivatives', 'real-analysis']"
3615097,Good way of explaining how to find all solutions to $\sin\theta+a=0$,"I'm not sure exactly how to properly describe this trigonometry problem, so I will just write it out. It is less of a ""problem"" and more of a ""I can't find a really good way to explain it"". We want to find a value $\theta$ such that $$\sin\theta + a = 0,$$ where $|a| < 1$ . Subtracting $a$ from both sides gives us $\sin\theta = -a$ , and one solution is easily seen to be $\theta = \arcsin(-a)$ . However, because $-1 < -a < 1$ , there should be two possible values of $\theta$ that give $\sin\theta = -a$ . I'll call the one we already found $\theta_1$ , and the one we are looking for $\theta_2$ . The best explanation I could think of is, when looking at the unit circle, $\sin\theta_1$ is considered the $y$ coordinate on the circle, while $\cos\theta_1$ is the corresponding $x$ coordinate. However, if you reflected across the $y$ axis, that other angle will also satisfy $\sin\theta_2 = -a$ . This reflection across the $y$ axis corresponds to $\theta_2 = \pi - \theta_1$ , and this is correct, because $$\sin\theta_2 = \sin(\pi - \theta_1) = \sin\pi + \sin\theta_1 = 0 -a = -a.$$ So we have our two solutions: $$\theta_1 = \arcsin(-a) \\ \theta_2 = \pi - \arcsin(-a).$$ My problem is I feel like my solution is too ""wordy"" and not elegant enough. Maybe it's not possible, but is there a better, more analytic way of deriving this result? Since $|\arctan x| \le \pi/2$ , I feel like it would be impossible to easily derive $\theta_2$ like we did $\theta_1$ , since $|\theta_2| \ge \pi/2$ , so there is no way for $\arctan x$ to ever map to that value.",['trigonometry']
3615132,Understanding an application of the Cauchy–Schwarz inequality,"Here is the link to the solution: Why should we use the uniform boundedness principle here? And here is the solution: First let's show a simpler version (1-dimensional): If $\sum_i a_i x_i < \infty$ all for $x\in\ell^2$ , then $a\in \ell^2$ . You can prove this claim using uniform boundedness principle, or you can just use Riesz Representation Theorem. See [this post][1]. Now, let's go back to your problem. It follows from the claim above that each row of $A$ is in $\ell_2$ . Define $T_N$ to be the restriction of $A$ onto the first $N$ rows, that is, $$T_N x = \left(\sum_j a_{1j}x_j,\sum_j a_{2j}x_j,\dots,\sum_j a_{Nj}x_j,0,0,\dots,\right).$$ We claim that $\|T_N\| < \infty$ . Note that $$\|T_Nx\|_2^2 = \sum_{i=1}^N \left|\sum_j a_{ij}x_j\right|^2 \leq \sum_{i=1}^N\left(\sum_j |a_{ij}|^2 \right)\left(\sum_j |x_j|^2 \right) \leq \|x\|_2^2\cdot \sum_{i=1}^N\sum_{j=1}^\infty |a_{ij}|^2,$$ thus $$\|T_N\| \leq \left(\sum_{i=1}^N\sum_{j=1}^\infty |a_{ij}|^2\right)^{1/2}.$$ (Note that the infinite sum over $j$ is finite because of the claim at the beginning.) Now, for each fixed $x$ , observe that $\|T_Nx\|_2$ is uniformly bounded by $\|Ax\|_2$ (since $\|T_Nx\|_2$ is just part of the sum for $\|Ax\|_2<\infty$ ). It follows from the uniform boundedness principle that $\sup_N \|T_N\|<\infty$ . Note that $\|Ax\|_2 = \lim_{N\to\infty} \|T_Nx\|_2 \leq (\sup_N \|T_N\|)\|x\|$ , which implies that $A$ is bounded and $\|A\| \leq \sup_N \|T_N\|$ . But I do not understand this step: $\sum_{i=1}^N \left|\sum_j a_{ij}x_j\right|^2 \leq \sum_{i=1}^N\left(\sum_j |a_{ij}|^2 \right)\left(\sum_j |x_j|^2 \right)$ I know that this is by Cauchy-Schwartz, but should not $a_{ij}x_j$ be inside an absolute value to apply Cauchy Schwartz?","['proof-explanation', 'analysis', 'real-analysis', 'cauchy-schwarz-inequality', 'functional-analysis']"
3615172,Value bound for integrable periodic function,"Let $f:\mathbb R\to\mathbb R_{\geqslant0}$ be an integrable function with period $1$ such that $\displaystyle\int_0^1 f(x)\,\mathrm dx = 1$ and define $$A:=\left\{y\in[0,1]:\int_y^{y+0.6}f(t)\,\mathrm dt\geqslant0.6\right\}.$$ What is the smallest possible Lebesgue measure of $A$ ? If $f(x)=2$ for $0\leqslant x\leqslant 0.5$ and $f(x)=0$ for $0.5\leqslant x\leqslant 1$ , then $A=[0,0.2]\cup[0.7,1]$ , which has size $0.5$ . So the answer is at most $0.5$ . If we change $0.6$ to $0.5$ in the problem (in both places), then a quick argument shows that $0.5$ is the right answer. I suspect $0.5$ is also the right answer here, but a different proof method is needed.","['optimization', 'inequality', 'real-analysis']"
3615274,Countability of removable discontinuities,"I saw a problem of proving that number of removable discontinuities in a function is countable. I was not able to prove it and tried many things. Can anyone do it? 
Thanks in advance.","['continuity', 'analysis', 'real-analysis']"
3615385,Explain how can we graph the equation $y+|y|=x+|x|$.( Relation involving absolute values),"According to my answer it's graph would be $x=y$ when $x,y\ge0$ and the whole third quadrant including $x=0$ and $y=0$ , when $y$ is not a function of $x$ . When it is a function of $x$ then the graph is $x=y$ when $x,y\ge0$ and the negative $x$ -axis. According to a graphing utility (like Desmos) my answer is wrong. Please can someone correct me? I would be thankful.","['algebra-precalculus', 'graphing-functions', 'absolute-value', 'relations']"
3615463,Calculate the integral $\int_0^{2\pi}\sum_{k=n}^{\infty}\frac{e^{i(k-m)\theta}}{k+1}d\theta$,"I would like to calculate this integral: $$\int_0^{2\pi}\sum_{k=n}^{\infty}\frac{e^{i(k-m)\theta}}{k+1}d\theta$$ where $n$ and $m$ belong to $\mathbb{N}$ . My attempt: Instead of considering an infinite sum, I will consider a finite one. Let $l>n$ , we have: \begin{alignat*}{2}
		\int_0^{2\pi}\sum_{k=n}^{l}\frac{e^{i(k-m)\theta}}{k+1}d\theta=\sum_{k=n}^{l}\frac{1}{k+1}\int_0^{2\pi}e^{i(k-m)\theta}d\theta
	\end{alignat*} Taking the limit when $l$ tends to $\infty$ , we have: $$\lim_{l\to\infty}\int_0^{2\pi}\sum_{k=n}^{l}\frac{e^{i(k-m)\theta}}{k+1}d\theta=\left \{
   \begin{array}{l c r}
     \frac{2\pi}{m+1}  & \text{if} & m\geq n \\
     0 & \text{if} & m<n
   \end{array}
   \right. $$ In this case, do we have: $$\lim_{l\to\infty}\int_0^{2\pi}\sum_{k=n}^{l}\frac{e^{i(k-m)\theta}}{k+1}d\theta=\int_0^{2\pi}\sum_{k=n}^{\infty}\frac{e^{i(k-m)\theta}}{k+1}d\theta\quad?$$ Many thank's in advance.","['integration', 'complex-analysis', 'calculus', 'contour-integration', 'exponential-sum']"
3615510,Discrete valuation on an algebraic function field,"Let $f=y^2-(x^3+2x^2+1)\in \mathbb{Q}[x,y]$ and $L=\mathbb{Q}(\alpha,\beta)$ is an algebraic function field given by $f(\alpha,\beta)=0$ , where $\alpha=x+(f),\beta=y+(f)\in \mathbb{Q}[\alpha,\beta]\subset L$ . Suppose $\nu$ is a normalised discrete valuation on $L$ , such that $\nu(\mathbb{Q}\setminus\{0\})=0$ , $\nu(\alpha-1)>0$ , $\nu(\beta-2)>0$ . Find all $(l_0,l_1,l_2)\in \mathbb{Q}^3$ , such that $$\nu(l_0+l_1\alpha+l_2\beta)=1,\ 2,\ 3,$$ respectively. I have no idea how to solve the problem. But I notice that $(1,2)\in V_f(\mathbb{Q})$ is a zero of $f$ , and $f$ is smooth at $(1,2)$ , since $$\nabla(f)=(-3x^2-4x,2y)$$ does not vanish there. By definition, if $\nu$ is a normalised discrete valuation, then $\exists M\in \mathbb{P}_{L/\mathbb{Q}}$ a place of the algebraic function field $L$ , such that $M=(t)$ and $\nu=\nu_t$ , where $$\mathbb{P}_{L/\mathbb{Q}}:=\{M\subset L\mid \exists R \ \text{valuation ring of}\ L:\mathbb{Q}\subset R\subset L, M\ \text{maximal ideal of}\ R\},$$ and $\nu_t(a):=\max\{j\ge 0\mid p^j\vert a\}$ is the normalised valuation of $t$ . Thank you very much in advance for your help!","['field-theory', 'algebraic-geometry', 'abstract-algebra', 'valuation-theory', 'extension-field']"
