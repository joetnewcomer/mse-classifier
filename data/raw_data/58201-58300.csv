question_id,title,body,tags
639629,Find all stationary points of multivariable function,"$$f(x,y) = \left(y^2 + y -16\right)\sin(x)$$ Find ALL stationary points of $f$ and classify each as local max, min or saddle point. My working so far is $f_x = \left(y^2 + y -16\right)\cos x$ $f_y = \left(2y + 1\right)\sin x$ $f_{xx} = -\left(y^2 + y - 16\right)\sin x$ $f_{yy}= 2\sin x$ $f_{xy}= \left(2y + 1\right)\cos x$ For stationary points I need $f_x=0$ and $f_y=0$ For $\left(2y+1\right)\sin(x) = 0$ need either $y=-\dfrac{1}{2}$ or $x=0$. Now have I made a mistake somewhere because when I put into the other equation to find stationary points when $x = 0$, $y = \dfrac{-1 \pm \sqrt{65}}{2}$
which is fine but when I use $y=-\dfrac{1}{2}$ there is no $x$ value Thanks in advance!","['multivariable-calculus', 'trigonometry']"
639635,Convolution of integrable function with bounded function,"Let $K$ Lebesgue integrable. Let $f$ be measurable and bounded on $\mathbb{R}$ with $\lim_{\left|x\right|\rightarrow \pm \infty}f(x)=0$ . Let $F(x)=K\ast f=\int_{\mathbb{R}} K(x-s)f(s) \, ds$ be the convolution. To show that $\lim_{\left|x\right|\rightarrow \pm \infty}F(x)=0$ . I have that $K(x-s)f(s)$ tends to $0$ when you let $s$ go to $\pm \infty$ since it obviously holds for all simple functions.
After this result I tried to deduce from the definition of the integral that it must then also hold for $F(x)$ , but this limit is taken over $x$ which shifts $f(s)$ in relation to $K(x-s)$ . My spider sense is telling me Fubini should be applied. Any hints (w.r.t. Fubini)?","['convolution', 'measure-theory']"
639647,How to determine the group structure of $E(\mathbb{R})$ for an elliptic curve $E/\mathbb{R}$,"Using Weierstrass' $\wp$ function it can be proved that the group of complex points on an elliptic curve $E /\mathbb{C}: y^2 = x^3 + ax + b$ satisfies $E(\mathbb{C}) \cong \mathbb{R}/\mathbb{Z} \oplus \mathbb{R}/\mathbb{Z}$. Now, suppose that $E$ is defined over $\mathbb{R}$. Is there a way to prove directly from the isomorphism above that the group of real points on $E$ is $$
E(\mathbb{R}) \cong \begin{cases}
\mathbb{R}/\mathbb{Z} \quad \text{if $x^3 + ax +b$ has one real root,}\\
\mathbb{Z}/2\mathbb{Z} \oplus \mathbb{R}/\mathbb{Z} \quad \text{if $x^3 + ax +b$ has three real roots}
\end{cases}
$$ I have seen some arguments that use results from the theory of Lie groups to prove this, but I was wondering if it can be proved from the ""torus"" description of $E(\mathbb{C})$. Thanks a lot for any help.","['algebraic-geometry', 'elliptic-curves']"
639648,Understanding the Gamma function? [duplicate],"This question already has answers here : Intuition for the definition of the Gamma function? (8 answers) Closed 10 years ago . I'm working my way through a probability textbook, and i have encountered the Gamma function through the Gamma distribution. I understand that the Gamma function is an interpolating function that can give pretty accurate values of factorials across the entire Reals, in between the Natural numbers that factorials typically work for, but HOW was this function even conceived? I want to see the thought process behind this function. How did Euler decide that the Gamma function described factorial 'curve' one can draw between the discrete factorial function? He didn't just pull this function outta nowhere, there has to be a reasoning behind it, i take it?","['probability-theory', 'gamma-function']"
639668,Solving a differential equation with natural log,"I am given: $x\dfrac{dy}{dx}=\dfrac{1}{y^3}$ After separating and integrating, I have: $y^4/4=\ln x+C$ I am supposed to solve this equation, but I'm stuck here.  Should I solve explicitly so I can keep $C$? EDIT: A solution I came up with last night was: $y=(4\ln x+C)^{1/4}$",['ordinary-differential-equations']
639674,Differentiable function has measurable derivative?,"Let $f:[0,T] \to \mathbb{R}$ be a differentiable function. Is it true that $f'$ is measurable? If so, is this also true if $f$ is differentiable almost everywhere? Sorry for lack of effort but I don't have any clue about the answer.","['measure-theory', 'derivatives', 'real-analysis']"
639688,Skyscrapers sheaf's global sections,"I'm reading a book written by Serre and, even though he's one of the best math writer ever, there's a step I don't understand. This may imply that I'm one of the worst math reader ever! :-) So, we are dealing with a sheaf $S$ on a projective curve $X$ and we can prove that, given a nonzero local section $s$ defined in a neighborhood of a point $P$, there always exists a smaller neighborhood $U$ of $P$ such that $s$ is vanishes on the whole $U\setminus P$. Then the claim is that
$$ H^0(X, S) = \bigoplus_{P\in X} \;S_P $$
i.e. the space of global sections coincides with the direct sum of the stalks. This is intuitively clear for me: from the above we know that the set of points $P$ where a global section $s$ is not trivial is discrete. Moreover, it is closed inside a compact space, thus itself compact. Since a discrete set is compact iff it is finite, we see that $s$ is not trivial only on a finite number of points, and this motivates the presence of $\bigoplus$ in place of $\prod$. Is my reasoning correct? Is there a better/faster/cleaner way to see it? Further, is this a general fact, or does it depend on the particular nature (which I didn't describe here) of the sheaf $S$ ? In other words, is it true that if a sheaf $F$ is a skyscrapers sheaf (meaning it's support lies in a finite number of points) on a projective variety, then the above formula for its global sections holds?","['sheaf-theory', 'algebraic-geometry']"
639700,Proposition 4.3.9 in Liu: flatness by domination,"Proposition 4.3.9 in Liu says: Let $Y$ be a Dedeking scheme. Let $f:X\to Y$ be a morphism with $X$ reduced. Then $f$ is flat if and only if every irreducible component of $X$ dominates $Y$. I don't understand details in the proof: the proof is going so Suppose every irreducible component of $X$ dominates $Y$. Let $x\in X$ and $y=f(x)$ First the case $y$ generic point of $Y$ we deduced $\mathcal{O}_{X,x}$ flat over $\mathcal{O}_{Y,y}$: ok Then suppose $y$ closed and $\pi$ uniformising parameter for $\mathcal{O}_{Y,y}$ (Discret Valuation Ring because $Y$ Dedeking). Then $\pi$ does not belong to any minimal prime ideal of $\mathcal{O}_{X,x}$, that is with notation $f^\sharp_x:\mathcal{O}_{Y,y}\to\mathcal{O}_{X,x}$, $f^\sharp_x(\pi)$ does not belong to any prime ideal of $\mathcal{O}_{X,x}$: I don't understand why (question °1) As $X$ reduced then $\pi$ is not a zero divisor, then $\mathcal{O}_{X,x}$ flat over $\mathcal{O}_{Y,y}$: ok Conclusion: ok (but I don't see the necessity of the generic point case... maybe just a remark) The converse: one know from a preceeding lemma that if $f:X\to Y$ is flat, $Y$ irreducible and $X$ has only a finite number of irreducible components, then every one of them dominates $Y$. Question n°2: But I don't see how we can use this lemma because we don't have the finitness of number of irreducible component for $X$ which is only reduced.",['algebraic-geometry']
639720,Identify $\sum(-1)^{n-k}2^{2k}\binom{n+k}{2k}$,"Does anybody know what the following sum evaluates to?
$$
\sum_{k=0}^n{(-1)^{n-k}}2^{2k}\binom{n+k}{2k}
$$","['discrete-mathematics', 'binomial-coefficients', 'combinatorics']"
639721,Would like help with a contour integral.,"Disclaimer: the knowledge I have about contour integration is solely from the book ""Mathematical Methods in the Physical Sciences"" by Mary L. Boas. I am trying to understand how the following function is derived:
\begin{equation}
\displaystyle\lim_{\epsilon \to 0^+} \int\limits^\infty_{-\infty} \frac{e^{-ixt}}{x+i \epsilon} \; \mathrm{d} x = - 2 \pi i \Theta(t)
\end{equation}
where $\Theta(t)$ denotes the unit step function. In order to do this, I start by considering the integral:
\begin{equation}
\int\limits_{-\infty}^\infty \frac{e^{-i x t}}{x + i \epsilon} \; \mathrm{d} x
\end{equation}
where $t>0$. In order to evaluate this integral I believe we can use the ``contour integration'' technique and thus I consider:
\begin{equation}
\oint_C \frac{e^{-i z t}}{z + i \epsilon} \; \mathrm{d} z \tag{1}
\end{equation}
where $C$ is the (clockwise) contour as shown in the figure: Clearly, there is a simple pole at $z= -i \epsilon$ and the residue can be easily found:
\begin{equation}
\mathrm{Res}(-i \epsilon) = \displaystyle\lim_{z \to -i \epsilon}\left\{ (z+i \epsilon) \frac{e^{-i z t}}{z + i \epsilon} \right\}= e^{-\epsilon t}
\end{equation}
Therefore, by the residue theorem, we can evaluate equation $(1)$ as:
\begin{equation}
\oint_C \frac{e^{-i z t}}{z + i \epsilon} \; \mathrm{d} z = - 2 \pi i e^{-\epsilon t}
\end{equation}
where the minus sign is due to the fact that the contour is clockwise. Subsequently, by taking $\epsilon$ to be a very small positive constant this becomes:
\begin{equation}
\oint_C \frac{e^{-i z t}}{z + i \epsilon} \; \mathrm{d} z = - 2 \pi i
\end{equation}
Letting $z=\rho e^{i \theta}$, we can write:
\begin{equation}
\oint_C \frac{e^{-i z t}}{z + i \epsilon} \; \mathrm{d} z = \int\limits^\rho_{-\rho} \frac{e^{-i x t}}{x + i \epsilon} \; \mathrm{d} x + \int\limits^{-\pi}_{0} \frac{e^{-i z t}}{\rho e^{i \theta} + i \epsilon} \rho i e^{i \theta} \; \mathrm{d} \theta \tag{2}
\end{equation}
At this point I am stuck. I believe the second term on the right-hand side of the above equation should tend to zero as $\rho \rightarrow \infty$, however I do not see why this would be true. Any help would be much appreciated.","['residue-calculus', 'integration', 'complex-integration', 'complex-analysis', 'contour-integration']"
639722,Is there a real continuous function of a Cube?,"Sorry if this seems like a basic question, but I'm having troubles finding an answer in my research. I'm looking for a function that if given a test point (x, y, z) will return a real value describing whether the given point is On the surface of the shape
$$f(x) = 0$$ Inside the volume of the shape
$$f(x) > 0$$ Or outside the volume of the shape
$$f(x) < 0$$ I've found such equations for a sphere and other shapes but cubic, and in general faceted shapes have eluded me. Unfortunately I'm a novice in this space with no formal training so any source or in depth explanations would be greatly appreciated. Edit: As added bonus, is there an equation that handles rectangular cuboids?","['analytic-geometry', 'geometry']"
639733,Discrete math. Solve the equation in the set of natural numbers.,I have to solve the equation $$m^4-n^4=5(m^3+n^3)$$ in the set of natural numbers. I wrote a simple code in java and i solved the equation. Only solution in the set of natural numbers is $m = 6$ and $n = 3$. I have been trying to get this solution mathematically for at least 3-4 hours and i am stuck. I really hope that there is someone who could show me how to solve this equation? Thank you!,"['discrete-mathematics', 'diophantine-equations']"
639749,"Precise connection between complexification of $\mathfrak{su}(2)$, $\mathfrak{so}(1,3)$ and $\mathfrak{sl}(2, \mathbb{C})$","I'm desperatly confused by notations and formulations so if someone could clarify the following things a little Í would be deeply grateful. The Lie algebra $\mathfrak{so}(1,3)_+^{\uparrow}$ of the proper orthochronous Lorentz group $SO(1,3)_+^{\uparrow}$ is given by \begin{equation} [J_i,J_j]=i \epsilon_{ijk} J_k \end{equation} \begin{equation} [J_i,K_j]=i \epsilon_{ijk} K_k \end{equation} \begin{equation} [K_i,K_j]=- i \epsilon_{ijk} J_k \end{equation} We can now define new generators with the old ones $N^{\pm}_i= \frac{1}{2}(J_i \pm i K_i)$ which satisfy \begin{equation} [N^{+}_i,N^{+}_j] = i \epsilon_{ijk} N^{+}_k ,\end{equation} \begin{equation} [N^{-}_i,N^{-}_j] = i \epsilon_{ijk} N^{-}_k ,\end{equation} \begin{equation} [N^{+}_i,N^{-}_j] = 0. \end{equation} where we can see that $N^{+}_i$ and $N^{-}_i$ make up a copy of the Lie algebra $\mathfrak{su}(2)$ each. My problem is to get what is going one here mathematically precise. Are the following statements correct and if not why: When we build the new operators from the old generators we complexified $\mathfrak{so}(1,3)_+^{\uparrow}$ \begin{equation}(\mathfrak{so}(1,3)_+^{\uparrow})_\mathbb{C} = \mathfrak{so}(1,3)_+^{\uparrow}\otimes \mathbb{C} \end{equation} We saw that $\mathfrak{so}(1,3)_+^{\uparrow})_\mathbb{C}$ is isomorph to two copies of the complexified Lie algebra of $\mathfrak{su(2)}$ : $(\mathfrak{so}(1,3)_+^{\uparrow})_\mathbb{C} \simeq \mathfrak{su(2)}_{\mathbb{C}} \oplus \mathfrak{su(2)}_{\mathbb{C}} $ . Where exactly did we need that $\mathfrak{su(2)}$ is complexified here? The Lie algebras defined by $N^{\pm}_i$ are exactly those of $\mathfrak{su(2)}$ and we never use complex linear combination of $N^{\pm}_i$ or am I wrong here? $\mathfrak{su(2)}_{\mathbb{C}}$ is isomorph to $(\mathfrak{sl}(2,\mathbb{C}))_\mathbb{C}$ : \begin{equation}\mathfrak{su(2)}_{\mathbb{C}} \simeq (\mathfrak{sl}(2,\mathbb{C}))_\mathbb{C} \end{equation} Here $(\mathfrak{sl}(2, \mathbb{C}))_\mathbb{C}$ denotes the complexified Lie algebra of $SL(2,\mathbb{C})$ Is $(\mathfrak{so}(1,3)_+^{\uparrow})_\mathbb{C} \simeq (\mathfrak{sl}(2, \mathbb{C}))_\mathbb{R}$ correct?  Here $(\mathfrak{sl}(2, \mathbb{C}))_\mathbb{R}$ denotes the real Lie algebra of $SL(2,\mathbb{C})$ Is $(\mathfrak{so}(1,3)_+^{\uparrow})_\mathbb{C} \simeq (\mathfrak{sl}(2, \mathbb{C}))_\mathbb{C} \oplus (\mathfrak{sl}(2, \mathbb{C}))_\mathbb{C}$ correct? I looked this topic up in different books and each seemed to state something different. One book even used three differrent versions of $\mathfrak{sl}(2,\mathbb{C}) $ namely: $\mathfrak{sl}(2,\mathbb{C}) $ , $(\mathfrak{sl}(2,\mathbb{C}))_\mathbb{C}$ and $(\mathfrak{sl}(2,\mathbb{C}))_\mathbb{R}$ . Wikipedia states simply that $\mathfrak{sl}(2,\mathbb{C}) $ is the complexification of $\mathfrak{su(2)}$ without making any reference to $SL(2,\mathbb{C})$ which does not help me either. Any help would be great.","['lie-groups', 'lie-algebras', 'group-theory']"
639806,How to find 2x2 matrix with non zero elements and repeated eigenvalues?,"I need to find a 2x2 matrix with non zero elements that has eigenvalue = 1 repeated (double). How can i do that?
Thanks!","['eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'numerical-methods', 'numerical-linear-algebra']"
639834,Existence of a sequence that converges to a polynomial,Let $P\in \mathbb{R}[X]$ Is there a norm $\|\cdot\|$ such that the sequence $(X^n)_{n\in \mathbb{N}}$ which converges to $P$? Thank you,"['general-topology', 'sequences-and-series', 'polynomials']"
639835,Line bundle corresponding to the Segre embedding,"I am trying to understand the theorem that characterizes morphisms to projective space as equivalent to the data of a line bundle together with global sections generating it. I tried to find the corresponding line bundle associated with the Serge embedding, say from $\mathbb{P}^{1} \times \mathbb{P}^{1}$ to $\mathbb{P}^3$. But working directly with the definitions Hartshorne gives looks impractical. I don't know how to compute explicitly the global sections of the pullback of the twisting sheaf on $\mathbb{P}^3$. Is there any technique to compute the pullback of a line bundle, or more generally of any quasi coherent module in practice?",['algebraic-geometry']
639861,$M\cong N$ iff $[M:N]_R$ is a principal fractional ideal,"Let $R$ be a Dedekind ring, $K$ its field of fractions, $U$ a finite vector space over $K$, and $M,N$ finitely generated $R$-modules that span $U$, i.e. contain a basis of $U$. For every $\mathfrak p \subset R$, define $[M:N]_{\mathfrak p} = (\det \phi_{\mathfrak p})$, where $\phi_{\mathfrak p}$ is a linear transformation that takes $M_{\mathfrak p}$ onto $N_{\mathfrak p}$. Recall here $R_{\mathfrak p}$ is a principal ideal domain $\Rightarrow$ $M_{\mathfrak p},N_{\mathfrak p}$ are free and one can indeed find such a transformation. Now define $[M:N]_R := \prod_i \mathfrak p_i^{v_{\mathfrak p_i}([M:N]_{\mathfrak p_i})}$. According to Froehlich, one can show that $M\cong N$ iff $[M:N]_R$ is a principal fractional ideal. One direction is easy. If we have a general linear transformation $\Psi$ of $U$ such that $\Psi (M)=N$, then $(\det \phi_{\mathfrak p_i}) = (\det \Psi_{\mathfrak p_i})$ for every $i$, so that $[M:N]_R =\prod_i \mathfrak p_i^{v_{\mathfrak p_i}([M:N]_{\mathfrak p_i})} = (\det \Psi)$, which is a principal fractional ideal. But how do I get the other direction?","['commutative-algebra', 'linear-algebra', 'algebraic-number-theory']"
639878,"Asymptotics of partitions in at most n parts, bounded by r","For every positive integers $n,r,w$  define
$$ p_w(n,r)=\#\{ (i_1,...,i_r) | \, 0\leq i_1 \leq \dots \leq i_r\leq n, \, i_1+\dots+i_r=w\} $$
as the number of partitions of $w$ in at most $r$ piece bounded by $r$. Equivalently, this is the number of Young tableaux for $w$ that can be inscribed into an $r\times n$ rectangle. Suppose now that $r=2s$ for a certain positive integer $s$. Then, for every fixed $s$ and $n$, I think that the the biggest of the numbers $p_w(n,2s)$ is $p_{ns}(n,2s)$, even if I have not proven this. What I would like to know, then, would be the limit $$ \lim_{n\to +\infty} \frac{\sum_{w=0}^{2ns}p_w(n,2s)}{p_{ns}(n,2s)} $$ i.e. the ratio between the total numbers of partitions and the biggest number of partitions. Even better would be to know the asymptotic behaviour of
$$ \sum_{w=0}^{2ns}p_w(n,2s) \qquad p_{ns}(n,2s)  $$
as $n\to +\infty$. What I have tried: I know that the generating function for the numbers $p_w(n,2s)$ is the Gaussian polynomial $$ G_{n+2s,2s}(t)=\frac{(1-t^{n+2s})\dots(1-t^{n+1})}{(1-t^{2s})\dots(1-t)} $$ and from this, at least in the case that $n$ is divided by all numbers $1,\dots,2s$ it can be seen that $$ G_{n+2s,2s}(t)=\prod_{k=1}^{2s} P_k(t)$$ where $P_k(t)=\frac{t^{n+k}-1}{t^k-1}=\sum_{h=0}^{\frac{n}{k}}t^{hk}$. So that $$ \sum_{w=0}^{2s}p_w(n,2s) = G_{n+2s,2s}(1) = \prod_{k=1}^{2s}(\frac{n}{k}+1)\sim \frac{n^{2s}}{(2s)!} $$ But now to know $p_{ns}(n,2s)$ I should know something about the $ns$th-derivative of $G_{n+2s,2s}(t)$.","['asymptotics', 'integer-partitions', 'combinatorics']"
639882,Topological space in which there are no close and compacts subsets (except for the empty set),"Any example of those topological spaces? I cant think of no one :S I think it must be infinite and it must not be T2, but no idea how to find one.","['general-topology', 'examples-counterexamples', 'compactness']"
639887,Help with finding the region where the function has an antiderivate...,"I'm having trouble in finding the region on wich $f(z) = \exp(1/z)$ has an antiderivative, by making this region as large as i can. And i want to know how that will compare with the real function $f(x) = \exp(1/x)$. Any help would be appreciated. Thanks.",['complex-analysis']
639890,minimum value of $\cos(A-B)+\cos(B-C) +\cos(C-A)$ is $-3/2$,How to prove that the minimum value of $\cos(A-B)+\cos(B-C) +\cos(C-A)$ is $-3/2$,"['trigonometry', 'inequality']"
639935,"For continuous function $ f:\mathbb S^1 \to \mathbb R$ there exists uncountably many distinct points $x,y$ such that $f(x)=f(y)$","Let $\mathbb S^1$ denote the unit circle in $\mathbb R^2$. Then prove that for every  continuous function $f:\mathbb S^1 \to \mathbb R$, there exist uncountably many pairs of distinct points $x, y$ in $S^1$, such that $f(x)=f(y)$.","['general-topology', 'real-analysis']"
639938,Given X and Y are correlated and Y and Z are correlated what is the range of correlation between X and Z?,"How can I calculate the range of correlation of two variables X and Z given I have the correlations of X and Y, and Y and Z? I've found a few resources around, namely this , but I'd like a research paper (if any). Thanks!","['statistics', 'correlation', 'random-variables']"
639952,Relation of Between inseparable morphisms and tangent lines,"$X$ be a projective curve of $\mathbb{P}^n$, $P$ is not $X$ and let $f:X\rightarrow \mathbb{P}^{n-1}$ be the projection from $P$.
When I read Hartshorne book, I see that if $f$ is insepable (i.e the function field of $X$ is inseparable extension of the function field of image), then for any $Q$ in $X$, the tangent line $L_Q$ at $X$ passes through $P$. But I can't understnad this fact....
Help me...",['algebraic-geometry']
639954,"Statistics：How to prove that one variable's change is influenced by another variable,that is to say ,they are related?","I major in Bioinformatics. Now,I am in a problem: we all know that temperature changes during a year , I find that a disease incidence is really high when temperature is relatively high , while it becomes really low when the temperature is relatively low , that is to say ,they are related. So ,I want to find out a way to prove that they are related ,not just intuitively feel that they are related. So, any suggestions?",['statistics']
639955,Exercise in well-ordered sets,"Definitions : Given a subset $A$ of a non-empty well-ordered set $X$ we define the supremum as follows:  $\text{sup(A)}:=\text{min}\bigg(\big\{\,y\in X \oplus\{ +\infty\}: \forall x\in A \;(x\le y)\, \big \} \bigg)$. If $x\in X$ we define the successor of $x$ by the formula: $\text{succ}(x):= \text{min}\big( ( x, +\infty ]\big)$ Exercise: If $x$ is an element of a well-ordered set $X$ show that exactly one of the following statements hold: 1.- (Limit Case) $x=\text{sup} \big( \,[\text{min}(X),x)\, \big)$ 2.- (Successor case) $x=\text{succ}(y)$ for some $y$. Hi everyone I have trouble with the above exercise. I'd like to put my attempt but  everything I've tried is wrong (Basically my idea is split the proof in two cases one to show that at most one case hold assuming by contradiction the opposite, and the other  which shows that at least one hold ). Also I don't have a real intuition about what the limit case really is, I mean,  with the successor case is easy only thinking in the natural numbers. But what about the limit case. (This is what I have so far) Sketch proof: We have to show that at most (1) or (2) hold. Suppose for the sake of contradiction that both cases occurs simultaneously. Let $P(x)$ be the statement ""$x$ is such that (1) and (2)  holds at the same time"". We set $\{x\in X: \,P(x)\,  \}$, then by hypothesis is a non-empty subset of $X$ which is well-ordered, then it has a minimum element $x$. Thus for all $x'< x$ either (1) or (2) holds but not both. We already know that $x= \text{min} ((y, +\infty])$, then $x$ is the least such that $x>y$. Thus $y$ is either in (1) or (2) but not at the same time. If $y$ is in (1). This means that $y= \text{sup} ([\text{min}(X),y)$, i.e., $y$ is the least such as $y\ge w$ for all $w\in [\text{min}(X),y)$. Also we have that $y\in [\text{min}(X),x)$. We claim that $[\text{min}(X),x)=[\text{min}(X),y) \cup \{y\}$. Let $z\in [\text{min}(X),x)$, i.e., $\text{min}(X)\le z<x$, we have to check the case when $y\le z< x $ if were some $z\not= y$ contradicts that $x$ is the successor of $y$, hence $z=y$, the case when $z<y$ is trivially true. Hence $[\text{min}(X),x)\subset [\text{min}(X),y) \cup \{y\}$ the other inclusion is trivially true. Therefore $y$ is indeed an upper bound for  $[\text{min}(X),x)$ and also is the least, i.e., $y = \text{sup} ( \,[\text{min}(X),x)\,)$ and $y\not= x$ a contradiction. If $y$ is in (2), $y= \text{succ}(z)$. Then $y\ge w$ for all $w\in [\text{min}(X),y)= [\text{min}(X),z\,]$. Then $y$ is the least which would imply $y=\text{sup} ( \,[\text{min}(X),y)\, )$ and contradicts the minimality of $x$. For the other case, I'm not sure of how prove that at least one always hold? Any suggestion, please? Thanks","['self-learning', 'elementary-set-theory', 'order-theory']"
639974,Maximal ideal not containing the set of powers of an element is prime,"In the midst of attempting to prove that for a commutative ring $A$ with identity, and an ideal $I$ of $A$, $I = \operatorname{rad}(I)$, where $\operatorname{rad}(I) = \{x: x^m \in I, m >0\}$, implies that $I$ is an intersection of prime ideals, I've run into a little bit of confusion. An answer to another question on this site, this one to be exact , indicates a strategy that I am attempting to use. I know that if $x$ is an element of $A\setminus I$, then so too is $x^m$ for any positive integer $m$. I use this fact to consider a subset $X = \{x^m : m > 0\}$, which is closed under multiplication, and use Zorn's lemma to find an ideal of $A$ containing $I$ maximal with respect to the constraint that said ideal, $J$, is disjoint from X. I want to prove $J$ is prime by contradiction. I suppose that $J$ were not prime; this also means that $J$ is not maximal in $A$. Then there would exist two elements, $f$ and $g$, of $A$ so that $fg$ is in $J$, but neither $f$ nor $g$ is in $J$. Following the prompting of the aforementioned answer, I know that $J + \langle a\rangle$ and $J + \langle b\rangle$ would be ideals strictly containing $J$, and since J is the maximal ideal disjoint from $X$, both $J + 
\langle a\rangle$ and $J + \langle b\rangle$ contain at least some elements of $X$ (I am tempted to say all of them, but I'm not entirely sure that's true, in case for example $\langle a\rangle$ started containing powers of $x$ at $x^2$, in which case it isn't necessarily true that $\langle a\rangle$ contains $x$ itself), and so both $\langle a\rangle$ and $\langle b\rangle$ must themselves contain elements of $X$. And this is where I am stuck. I feel like there is something I should know about multiplicative subsets of rings that would help me arrive at the desired contradiction, but I can't remember what it might be.","['commutative-algebra', 'ring-theory', 'ideals', 'abstract-algebra']"
639976,What is a Cantor-style proof of $2^n > n^k$?,"Cantor's diagonalization argument shows that no function from an $n$-element set to its set of subsets hits every element.  This is one way to see that $2^n > n$ for every $n$.  The classic application is when $n$ is an infinite cardinal, but in this question I'm interested in finite $n$. $2^n$ grows much faster than $n$.  In fact it grows faster than any polynomial function in $n$.  Can this be proved ""in the spirit of Cantor""?  That is, fix $k$.  Given a function $f:S \times \stackrel{k}{\cdots} \times S \to 2^S$, can you construct an explicit element of $2^S$ not in its image?  (Of course, the set $S$ cannot be too small relative to $k$, hopefully this restriction occurs naturally in the construction?)","['set-theory', 'combinatorics']"
639983,"Proof of $(x+y)^2<\operatorname{rad}\bigl[xy(x+y)(x^2+xy+y^2)\bigr]$ for coprime integers $x,y$","An ancient statement, and I once read an elementary proof but I don't recall. Who can help me? The origin of the inequality is a regular magazine for high school teachers issued by P. Noordhoff since 1914 ( Nieuw Tijdschrift voor Wiskunde ). I considered various methods to prove the statement above. For instance using the fact that integers $n$ which are of the form $x^2+xy+y^2$ for two relatively prime integers $x,y$, are precisely those positive integers occurring as divisors of $m^2+m+1$ for some integer $m$. Another approach I tried is to consider the general solutions $x,y$ of $n=x^2+xy+y^2.$ An integer $n$ can be uniquely written as $n=sz^2$ with $s$ squarefree. Let $$\begin{align*}
s=f^2+fg+g^2,&\quad z=m^2+mn+n^2;\\
x=(f+g)n^2+2gmn-fm^2,&\quad y=-gn^2+2fnm+(f+g)m^2\,.
\end{align*}$$ Then we have $x^2+xy+y^2=(f^2 + fg + g^2)(m^2 + mn + n^2)^2$. The radical of $xy(x+y)(x^2+xy+y^2)$ has the form $xy(x+y)sz$, which leads to the (interesting) identity $$\bigl(xy(x+y)\bigr)sz\bigl(fg(f+g)\bigr)=sz\prod_{i=1}^3{(u_i^2-sn^2)}\,,$$ where $u_1=gn-fm$, $u_2=(f+g)m+fn$, and $u_3=gm+(f+g)n$. I also tried to use the following summation identity: let  $e>0$  be an integer and  $w=(-1)^e$. Choose $r=\frac{1}{3}(2^e-w)$ which is an integer. For $f,g,m,n$ define $$x=\frac14\sum_{i=0}^r\sum_{j=0}^2\binom{2^e}{3i+j}n^jm^{-j}(-1)^in^{3i}m^{2^e-3i}\,\times\\
\bigr[(f+(f + 2g)w)j^2+(-f + 2g +(-5f - 4g)w)j -2f - 2g +(2f - 2g)w\bigl]\,,$$ $$y=\frac14\sum_{i=0}^r\sum_{j=0}^2\binom{2^e}{3i+j}n^jm^{-j}(-1)^in^{3i}m^{2^e-3i}\,\times\\
\bigr[(-f-g-(-f+g)w)j^2+(3f+g -(-f - 5g)w)j + 2g -(4f+2g)w\bigl]\,.$$ Then the equality $x^2+xy+y^2=(f^2+fg+g^2)(m^2+mn+n^2)^{2^e}$ holds, which enable us to find all solutions with $s_i$ square-free of the form $s_0\prod_k{s_k^{2k}}$. N.B.: Please note that the transformation $x\mapsto x+y,y\mapsto-y$ yields the same value for $x^2+xy+y^2$. Why of interest? A corollary of $(x+y)^2<\operatorname{rad}\bigl[xy(x+y)(x^2+xy+y^2)\bigr]$ is that for $ABC$ triples with $A+B=C$ and $\operatorname{rad}(ABC)<C$, we have $A^2+AB+B^2=C^2-AB$. Thus, $$\operatorname{rad}(C^2-AB)<\leq C^2-AB\operatorname{rad}(ABC)\operatorname{rad}(C^2-AB)-AB<C\operatorname{rad}(C^2-AB)-AB\,,$$ which implies $AB<(C-1)\operatorname{rad}(C^2-AB)\,.$ We can also conclude that $C=A+B<\operatorname{rad}(C^2-AB)$, and thus for small values of $\operatorname{rad}(C^2-AB)=3,7,13,19,21\dots$ (OEIS sequence A034017) there are only a limited number of ABC triples.",['number-theory']
639986,"Why study $\mathcal{C}[0,1]$","I know this is probably a naive question here on this site, but I don't do a lot of higher math.  The group $\mathcal{C}[0,1]$ seems to be an important set within the framework of many mathematical texts.  I have not studied this outright, save for my Calc classes and very basic analysis.  I know there are segues into linear algebra with it as well, but why study this set of continuous functions?  What can groups of functions between the unit interval tell us about anything?  What behavior can be identified by studying them?  Is the most important framework for theory of measures and probability, considering the importance of the unit interval in the context of probability?","['group-theory', 'functions', 'analysis']"
639988,On compactness of the space of probability measures,"Let $X$ be a complete metric space, and denote by $\mathcal{P}(X)$ the set of probability measures on $X$. I am interested in proving that if $X$ is compact then $
\mathcal{P}(X)$ must be compact in the weak-* topology, which is induced by the convergence against $C_b(X)$, that is, the bounded continuous functions. Since $\mathcal{P}(X) \subset (C_b(X))^*$, and the unit ball of $(C_b(X))^*$ is compact in the weak-* topology (by Banach-Alaoglu), all that is left to do is prove that $\mathcal{P}(X)$ is weak-* closed. This should be easy, but I'm stuck: where does the compacity of $X$ come in? (The result is obviously false for non-compact $X$: consider a sequence of delta measures $\delta_{x_n}$ and $x_n \in \mathbb{R}, x_n \to \infty$.)","['probability-theory', 'measure-theory', 'compactness']"
640078,"Maximum number of monic polynomials $f(x)$ such that for some real $a$, $x(f(x+a) - f(x)) = nf(x)$ for a fixed $n<1000$?","This was a problem that I did from a while ago that I am revisiting. I remember getting the answer as the maximum divisors of an $n < 1000$, which would be $n = 840 \rightarrow 32$ divisors and polynomials, but I can't remember how I came to that result. Anyone mind giving me a hand?","['algebra-precalculus', 'number-theory']"
640081,"Why is it called an ""orthocenter""? What is the orthocircle?","We know that the orthocenter of a triangle is the place where the triangle's three altitudes intersect. But why is it called that? The *in*center - the intersection of the triangle's three angle bisectors - is the center of the *in*scribed circle. The *circum*center - the intersection of the triangle's three perpendicular bisectors - is the center of the *circum*scribed circle. But what is an ""orthocircle"" (if such exists)? This document says that two circles could be orthogonal. Well gee, whiz! This one says an orthocircle has the given center and is orthogonal to the given circle. That doesn't help, because I can make an orthogonal circle to the triangle from many points (maybe even all of them). And according to Wolframalpha , the name ""orthocenter"" was invented by people named Besant and Ferrers. But that page doesn't indicate why how came up with it. And that is literally everything I could find on the word ""orthocircle"" or on ""why is it called orthocenter?"". So why is it called ""orthocenter""? And what is the ""orthocircle""? P.S. And how do I italicize part of a word?","['geometry', 'triangles']"
640088,Seeking an analytic solution to a first order nonlinear ordinary differential equation,Does anyone have suggestions on how to tackle the following equation: $$\left(\frac{dy}{dx}\right)^2 = B(\sin(y(x)))^2 - C\sin(y(x)) + D $$ The constants are real and nonzero,['ordinary-differential-equations']
640110,Clarification Regarding evaluation of $\lim_{n\rightarrow \infty} n\sin(2\pi e n!)$- NBHM-$2009$,"Question is to evaluate $$\lim_{n\rightarrow \infty} n\sin(2\pi e n!)$$ We have $e = 1 + \dfrac1{1!} + \dfrac1{2!} + \dfrac1{3!} + \cdots + \dfrac1{n!} + \dfrac1{(n+1)!} + \dfrac1{(n+2)!} + \cdots$ $$n!e=n!(1 + \dfrac1{1!} + \dfrac1{2!} + \dfrac1{3!} + \cdots + \dfrac1{n!} + \dfrac1{(n+1)!} + \dfrac1{(n+2)!} + \cdots)$$ $$=M+\dfrac1{n+1} + \dfrac1{(n+1)(n+2)} + \dfrac1{(n+1)(n+2)(n+3)} + \cdots$$
 for some integer $M$. Now, for $2\pi e n!$ we have : $$2\pi e n!=2\pi (M+\dfrac1{n+1} + \dfrac1{(n+1)(n+2)} + \dfrac1{(n+1)(n+2)(n+3)} + \cdots)$$ $$=(2\pi M+\dfrac{2\pi}{n+1} + \dfrac{2\pi}{(n+1)(n+2)} + \dfrac{2\pi}{(n+1)(n+2)(n+3)} + \cdots)$$ For $\sin(2\pi e n!)$ We have : $$\sin(2\pi e n!)=\sin(2\pi M+\dfrac{2\pi}{n+1} + \dfrac{2\pi}{(n+1)(n+2)} + \dfrac{2\pi}{(n+1)(n+2)(n+3)} + \cdots)$$ $$=\sin(\dfrac{2\pi}{n+1} + \dfrac{2\pi}{(n+1)(n+2)} + \dfrac{2\pi}{(n+1)(n+2)(n+3)} + \cdots)$$ For $n\sin(2\pi e n!)$ we have : $$n\sin(2\pi e n!)=n\sin(\dfrac{2\pi}{n+1} + \dfrac{2\pi}{(n+1)(n+2)} + \dfrac{2\pi}{(n+1)(n+2)(n+3)} + \cdots)$$ For large $n$ we would have $$\sin(\dfrac{2\pi}{n+1} + \dfrac{2\pi}{(n+1)(n+2)} + \dfrac{2\pi}{(n+1)(n+2)(n+3)} + \cdots)$$ $$=\dfrac{2\pi}{n+1} + \dfrac{2\pi}{(n+1)(n+2)} + \dfrac{2\pi}{(n+1)(n+2)(n+3)} + \cdots$$ I hope I can say that for large $n$ $$n\sin(2\pi e n!)=n(\dfrac{2\pi}{n+1} + \dfrac{2\pi}{(n+1)(n+2)} + \dfrac{2\pi}{(n+1)(n+2)(n+3)} + \cdots)$$ $$=\frac{2\pi}{1+\frac{1}{n}}+\dfrac{2\pi}{(1+\frac{1}{n})(n+2)} + \dfrac{2\pi}{(1+\frac{1}{n})(n+2)(n+3)} + \cdots)$$ As $n\rightarrow \infty$ we would have : $$\frac{2\pi}{1+0}+0+0+0+\dots=2\pi$$ So, $$\lim_{n\rightarrow \infty} n\sin(2\pi e n!)=2\pi$$ I would be thankful if some one can check what i have done is reasonably sufficient.... Thank you :)","['real-analysis', 'limits']"
640157,Standard Deviation greater than mean implies no normal distribution?,"I understand that the mean $\mu \pm \sigma$ gives a better approximation of the measurements. But how is it related to the normal distribution? Is it because since $\sigma > \mu$ so the normal curve won't have a maximum at the middle anymore? Anyway, the question is as follows, if it helps in any way: According to the Environmental Protection Agency, chlorofoam, which in its gaseous form is suspected to be a cancer-causing agent, is present in small quantities in all the country's 240,000 public water sources. If the mean and standard deviation of the amounts of chlorofoam present in water sources are 34 and 53 micrograms per liter ($\mu g / L$) respectively, explain why chlorofoam amounts do not have a normal distribution. Thanks in advance!","['statistics', 'probability-theory', 'normal-distribution', 'probability-distributions', 'probability']"
640193,Particular solutions for a linear 2nd order ODE,"Say we had $$y'' +2y' -8y = xe^{-x}.$$ For the particular solution, would it be wise to try $$y_p(x) = (c_1 + c_2x)e^{-x}\quad or\quad y_p(x) = c_1xe^{-x}?$$ Similarly, we had $y'' +2y' -8y = x^2e^{-x}$ or $ y'' +2y' -8y = x^2cos(x)$ would it be wise to try $y_p(x) = (c_1 + c_2x + c_3x^2)e^{-x} $ and $y_p(x) = (c_1 + c_2x + c_2x^2)(\sin(x) + \cos(x))$?","['exponential-function', 'ordinary-differential-equations', 'calculus']"
640217,How to solve this inequality.,"Let $\alpha$, $\beta$, $\gamma$ be the angles of a triangle. Show that 
$\sin\frac{\alpha}{2}.\sin\frac{\beta}{2}.\sin\frac{\gamma}{2}<{\frac{1}{4}}$","['trigonometry', 'inequality']"
640257,Question regarding assumptions in Morera's theorem and conditions for existence of antiderivative.,"Morera's Theorem as it is phrased in Wikipedia states that if $\Omega\subseteq\mathbb{C}$
  is a simply connected open set in the plain and $f:\Omega\to\mathbb{C}$
  is a continuous function such that for every closed piece-wise $C^{1}$
  curve in $\Omega$
  the following equality holds: $$\left(\star\right)\;\oint_{\gamma}f\left(z\right)dz=0$$
Then $f$ is holomorphic in $\Omega$. The proof in this case follows by constructing an anti-derivative of $f$ in $\Omega$ and deducing that $f$
  is holomorphic as the derivative of a holomorphic function. My question is this: Suppose we omit the assumption that $\Omega$
  is simply connected (but remains connected) and assume $f$
  is a function such that for every aforementioned $\gamma$
  the equality $\left(\star\right)$
  holds. Pick any $z_{0}\in\Omega$
  and define: $$F\left(z\right)=\int\limits _{z_{0}}^{z}f\left(\omega\right)d\omega$$
 Wouldn't it follow that $F$
  is an antiderivative of $f$
  in $\Omega$
 ? I believe the definition would be independent of the choice of path of integration from $z_{0}$
  to $z$  from the assumption $\left(\star\right)$
  holds.",['complex-analysis']
640272,"Reason for thinking of vector as ""row"" and ""column"" vectors in linear algebra","Consider the $n$-tuple $(x_1,\ldots,x_n)$ with entries in some field $K$. What is the reason for perceiving this tuple either as a row vector, $$ [x_1,\ldots,x_n]$$or as a column vector $$\left[\begin{array}{c}x_1\\\vdots\\x_n\end{array}\right]$$? To clarify further: All the answers on this site, that I looked up, like this , this or this one deal with the question, which objects should be thought of as row respectively column vectors - opposed to that is what I'm asking: What's reason for making this distinction in the first place ? Because the thing is, I could define matrix multiplication, like this $$ \left[\begin{array}{cc} a & b  \\ c & d   \end{array}\right](x_1,x_2):=(ax_1+bx_2,cx_1+dx_2), $$so I only ever need to deal with ""tuple-vectors"", not row or column vectors; no need to ever talk about row or column vectors. So the thing is, that everything related to coordinates could be done, in the case of vectors, in row or column terms. So if that is possible, why is nobody doing it like that ? The only benefit that I see from making the row-column distinction - in contrast to using tuples $(x_1,\ldots,x_n)$ which are neither ""row"" nor ""column""-type - is to be gained on a notational level , so that it is easier to remember, for example, how to do matrix-vector multiplication, by ""moving"" along the rows of the matrix while ""moving"" along the  column of vector. But that seems a shallow reason, to put up with distinguishing between ""row"" and ""column""-vectors all the time. I hope there's something deeper than that.",['linear-algebra']
640286,Relative extrema standard,"In a national level exam for university admissions, we were asked to find the number and location(s) of the local minima of $\sin(x)$ , in $[\pi/4,7\pi/4]$ . $3\pi/2$ is surely one point of local minima, as points about $3\pi/2$ have larger values for $\sin(x)$. However, there seems to be a confusion for $\pi/4$ . Some definitions of local minima say that they cannot occur at the endpoints of the domain considered, while other definitions say that endpoints also qualify for  having the local extrema. In this case, values of $\sin(x)$ to the immediate right of $x = \pi/4$ are bigger. In this particular exam, the accepted answer was $\pi/4$ and $3\pi/2$ (2 points), which means endpoints were considered. Is there an agreed upon definition for this? Different authors have different opinions about this. Can someone clarify this?","['calculus', 'functions']"
640287,"A theorem in the paper ""Noncommuting Random Products"" by Furstenberg","I have a question concerning the proof of theorem 2.5 at page 395 of the paper Noncommuting Random Products, by H. Furstenberg, Trans. Amer. Math. Soc., 1963. The statement is as follows: Let $\mu$ be a probability measure on a group $G$. Let $M$ be a locally compact $G$-space, which does not admit a stationary measure for $\mu$, that is, there is no $\nu$ on $M$ such that $\mu*\nu=\nu$. Let $Z_n$ be a $\mu$-process on $M$, that is $Z_i$ are $M$ valued random variables such that the conditional distribution of $Z_{n+1}$ given $Z_{n},\dots,Z_0$ is $\mu*\delta_{Z_n}$. Let $\Delta\subset M$ be compact. Define $n(k)$ as the index $n$ for which $Z_n\in\Delta$ for the $k$-th time. Then $n(k)/k\to\infty$ with probability $1$. The proof starts with stating that it is enough to show that for each compactly supported $\psi$ we have that with probability $1$
\begin{equation}
\frac{1}{n}\sum_0^{n-1}\psi(Z_k)\to 0
\end{equation}
This I do understand. However, Furstenberg proceeds to say that if this formula does not hold for some $\psi'$, then there exists a subsequence $n_i$ such that
\begin{equation}
\frac{1}{n_i}\sum_0^{n_i-1}\psi'(Z_k)\to \alpha\neq 0,
\end{equation}
and he seems to assume in what follows that neither $n_i$ nor $\alpha$ are random. **
Question:
**
How is it that the second equation is the negation of the first? Is Furstenberg implicitly using here some ""strong law of large numbers""?","['probability-theory', 'markov-process', 'group-theory']"
640290,Cotangent bundle of complex manifold is Calabi-Yau manifold,"We say that a complex manifold $M$ is Calabi-Yau if the canonical bunlde is trivial $K_M=0$. How can we prove that the total space of the cotangent bundle of a compact complex manifold $N$ is Calabi-Yau $2n$-fold, where $n$ is the dimension of $N$?","['algebraic-geometry', 'complex-geometry']"
640316,Surface integral- getting different result using two methods,"I'm doing my homework and I came to conclusion I'm not sure is right. I need to find $$\iint_S x dydz+y^2dxdz+z^2dxdy$$ where $S$ is outer side of surface $x=z^2$, and $1\le y \le3$ and $x\le9$. Now, since for calculating first part of integral ($xdydz$) I need to project surface on plane $x=0$ I will have integral equal $0$. And I get same conclusion for two other parts of integral. Am I right? In the end integral equals $0$? UPDATE:
But using divergence theorem I get:
$I=\int_1^3 dy \int_{-3}^3 dz \int_{z^2}^9 (1+2y+2z) dx = 360$. I'm not sure which part I'm doing wrong?","['multivariable-calculus', 'integration']"
640326,conditions on $\{a_n\}$ that imply convergence of $\sum_{n=1}^{\infty} a_n$ (NBHM 2011),"Question is : For a sequence $\{a_n\}$  of positive terms, Pick out the cases which imply convergence  of $\sum_{n=1}^{\infty} a_n$. $\lim_{n\rightarrow \infty} n^{\frac{3}{2}}a_n=\frac{3}{2}$ $\sum_{n=1}^{\infty} n^2a_n^2<\infty$ $\dfrac{a_{n+1}}{a_n}< (\frac{n}{n+1})^2$ For the first case $\lim_{n\rightarrow \infty} n^{\frac{3}{2}}a_n=\frac{3}{2}$ : Suppose $a_n > \frac{3}{2}. (\frac{1}{n})^{\frac{3}{2}}$ for all $n\in \mathbb{N}$ then we would have : $n^{\frac{3}{2}}a_n > \frac{3}{2}.n^{\frac{3}{2}} (\frac{1}{n})^{\frac{3}{2}}=\frac{3}{2}$ but then $n^{\frac{3}{2}}a_n$ would not converge to $\frac{3}{2}$ So, for large $n$ we should have $$a_n \leq\frac{3}{2}. \frac{1}{n^{\frac{3}{2}}}\Rightarrow \sum_{n=1}^{\infty}a_n \leq \sum_{n=1}^{\infty} \frac{3}{2}. \frac{1}{n^{\frac{3}{2}}}=\frac{3}{2}\sum_{n=1}^{\infty}  \frac{1}{n^{\frac{3}{2}}}$$ Right hand side converges and by comparison test $\sum_{n=1}^{\infty}a_n$ should converge. For the second case $\sum_{n=1}^{\infty} n^2a_n^2<\infty$ : Suppose that $na_n> \dfrac{1}{\sqrt{n}}$ for all $n$ then we would have $$n^2a_n^2> \dfrac{1}{n}$$ but then it is given that $\sum_{n=1}^{\infty} n^2a_n^2$ which would imply that $\sum_{n=1}^{\infty}\dfrac{1}{n}$ converges which is a contradiction. Thus we should have $na_n\leq \dfrac{1}{\sqrt{n}}$ i.e., $a_n\leq \frac{1}{n\sqrt{n}}=\frac{1}{n^{\frac{3}{2}}}$ for all $n$ large. So, We have $$\sum_{n=1}^{\infty}a_n\leq\sum_{n=1}^{\infty}\frac{1}{n^{\frac{3}{2}}}$$ right hand side is convergent so by comparison test $\sum_{n=1}^{\infty}a_n$ converges. For third case $\dfrac{a_{n+1}}{a_n}< (\frac{n}{n+1})^2$ : we would have $\lim_{n\rightarrow \infty} \dfrac{a_{n+1}}{a_n} <\lim_{n\rightarrow \infty} (\frac{n}{n+1})^2=1$ Thus, by ration test, $\sum_{n=1}^{\infty} a_n$ Converges absolutely and so is convergent. My choice of bounds : $a_n > \frac{3}{2}. (\frac{1}{n})^{\frac{3}{2}}$ for all $n$ in first case $na_n> \dfrac{1}{\sqrt{n}}$ for all $n$ in second case All these came to me just by choice and i would like to know if there is some sense behind this choice. Please help me to clear this and make this solution a bit more clear. Please do not give an alternative solution
 until this problem is fully verified. Thank you.","['sequences-and-series', 'real-analysis', 'limits']"
640374,Krull-Schmidt-Remak for vector bundles,"I'm reading Nori's paper The fundamental group scheme , and I have some problems in certain passages of the proofs. This one is from chapter 1, 2.3. Let $X$ be a complete connected reduced $k$-scheme. We have that $\operatorname{H}^0(X, \operatorname{end}V)$ is of finite dimension for all finite vector bundles $V$, and Nori states that this implies that Krull-Schmidt-Remak holds: for all finite vector bundles there is a unique decomposition (up to reorder blah blah blah...) in a direct sum of indecomposable subbundles ($V$ is indecomposable if $V=V_1\oplus V_2\Rightarrow V=V_1\vee V=V_2$). Why?","['algebraic-geometry', 'vector-bundles']"
640388,Some questions on Hartshorne III Ex 6.8,"I have been looking at Hartshorne III exercise 6.8 for nearly a week now and I don't seem to have a clue as to how to do it. In particular, I am stuck on part (a) which boils down to showing the following. Let $X$ be integral, separated and locally factorial. Let $U$ be any open neighbourhood of a closed point $x$. Suppose that $Z := X- U$ is irreducible with generic point $\zeta$. Then there is a line bundle $\mathcal{L}$ and $s \in H^0(X,\mathcal{L})$ with $x \in X_s \subseteq U$. Now I have convinced myself using separatedness of $X$ that we may choose a rational function $f$ with the property that $f \in \mathcal{O}_{X,x}$ and $f \notin \mathcal{O}_{X,\zeta}$. With this, we immediately deduce that for any $z \in Z$, $f \notin \mathcal{O}_{X,z}$ because we have an injection $$ \mathcal{O}_{X,z} \hookrightarrow \mathcal{O}_{X,\zeta}.$$ Edit: Ok here is an argument which I think works. It is not hard to see that $$H^0(X,\mathcal{L}(D)) = \{ f \in K(X)^\ast : div(f) + D \geq 0\} \cup \{0\},$$ i.e. all rational functions whose poles are no worse than $D$. Sitting inside of this is the canonical rational section $s$ corresponding to $1 \in K(X)^\ast$. Now I want to say that this $s$ has zeros wherever $f$ has a pole. When I look at a concrete example I can see this is true. If I look at $\Bbb{A}^1$ and $D= (f)_{\infty}$ for $f = 1/(x-1)(x-2)$, then 
$$\mathcal{L}(D) = \frac{1}{(x-1)(x-2)} \mathcal{O}_X$$ and the canonical section $1$ corresponds to $\frac{1}{(x-1)(x-2)} \times (x-1)(x-2).$ This ""shows"" wherever $f$ has a pole, $s$ has a zero. This is enough to conclude that $Z \subseteq V(s)$ because $f \notin \mathcal{O}_{X,z}$ for all $z \in Z$. But now we are on an arbitrary scheme satisfying the conditions in the beginning, so: My question is: How can we make rigorous the idea that wherever $f$ has a pole $s$ has a zero? Also, where do we use the locally factorial hypothesis? Is it just to make that $\mathcal{L}(D)$ be invertible? Added: Can someone elaborate on what exactly this ""canonical section"" $1 \in H^0(X,\mathcal{L}(D))$ is?",['algebraic-geometry']
640397,what is the derivative of $\ln(2x^2)$,"In finding the derivative of $\ln(2x^2),\;$ I have applied the chain rule and obtained $2x / x^2.\;$ Is this correct? If not could some please explain how to do it?","['calculus', 'derivatives']"
640398,Pointwise Ergodic Theorem - one particular estimate,"I am struggling with an estimate in a proof of the pointwise ergodic theorem discussed in T. Ward and M. Einsiedler: Ergodic Theory with a view towards Number Theory, which is left as an exercise. I will first give a description of the proof in order to clarify notation, then point out the estimate which is giving me troubles and then state what I have ``found out'' up to now (which is not so much unfortunately): Pointwise Ergodic Theorem: Let $(X,\mathscr{B},\mu)$ be a probability space, $T:(X,\mathscr{B})\to(X,\mathscr{B})$ measue-preserving, $f:X\to\mathbb{C}$ an integrable, measureable function, i.e. $\int_{X}|f|\operatorname{d}\mu<\infty$. Let $$A_{N}(f)(x):=\frac{1}{N}\sum_{n=0}^{N-1}f(T^{n}(x))\quad \forall x\in X, \forall N\geq 1$$ Then there exists an integrable function $f^{\ast}$ such that the sequence $(A_{N}(f))_{N\in\mathbb{N}}$ converges to $f^{\ast}$ pointwise almost everywhere. Let's quickly discuss the structure of the proof, which tells us what we know already and which estimate is giving me trouble. The proof: We start by assuming that $f$ is almost surely bounded . Once we have checked this case, we will use density of $L_{\mu}^{\infty}(X,\mathscr{B})$ in $L_{\mu}^{1}(X,\mathscr{B})$ to deduce the general case. We know from the mean ergodic theorem (which does not yet require the boundedness of $f$), that we can find an almost surely $T$-invariant, integrable function $F$ such that:
  $$F={\lim_{N\to\infty}}^{L_{\mu}^{1}}A_{N}(f)$$
  i.e. $\lVert F-A_{N}(f)\rVert_{1}\stackrel{N\to\infty}{\longrightarrow}0$. The claim hence becomes: let $F$ be a representative of the $L_{\mu}^{1}\cap L_{\mu}^{\infty}$-limit of $(A_{N}(f))$, then $A_{N}(f)$ converges to $F$ pointwise almost surely.
  This claim is formalized as follows: 
  $$\mu(\{x\in X; \lim\sup_{N\to\infty}|F(x)-A_{N}(f)(x)|>0\})=0$$
  Note that the claim would follow from:
  $$\mu(\{x\in X; \lim\sup_{N\to\infty}|F(x)-A_{N}(f)(x)|>\epsilon\})<2\epsilon \quad\forall\epsilon>0$$ by some standard argumentation (here my estimate is a bit weaker than in the original reference but this should not affect the result). Fix $M\in\mathbb{N}$ and $\epsilon>0$, then we know from the maximal ergodic theorem applied to the functions $g_{1}:=F-A_{M}(f)$ and $g_{2}:=A_{M}(f)-F$ (this is why the 2 pops up in my discussion) that:
  $$\mu(\{x\in X;\sup_{n\geq 1}|A_{N}(F-A_{M}(f))|>\epsilon\})<2\epsilon$$ Now comes the critical estimate: The authors state that for fixed $M\in\mathbb{N}$ holds:
  $$\begin{equation}\exists N_{0}\in\mathbb{N}\exists C_{M}>0:\quad N\geq N_{0}\Rightarrow|A_{N}(f)-A_{N}(A_{M}(f))|\leq C_{M}\frac{\lVert f\rVert_{\infty}}{N}\end{equation}$$
  Given the critical estimate and $A_{N}$-invariance of $F$, we find:
  $$\begin{align}\{x\in X;\lim\sup_{N\to\infty}|F(x)-A_{N}(f)(x)|>\epsilon\}=&\{x\in X;\lim\sup_{N\to\infty}|F(x)-A_{N}(A_{M}(f))|>\epsilon\}\\
\stackrel{\mu}{=}&\{x\in X;\lim\sup_{N\to\infty}|A_{N}(F-A_{M}(f))(x)|>\epsilon\}\\
\subseteq & \{x\in X;\sup_{N\geq1}|A_{N}(F-A_{M}(f))(x)|\}\end{align}$$
  where for $A,B\in\mathscr{B}$ holds $A\stackrel{\mu}{=}B$ if $\mu(A\Delta B)=0$. This readily proves the claim. I turn to you for the critical estimate: I do not manage to get the $N$ in the denominator. My idea was to do the following: I was about to check that $A_{N}(A_{M}(f))\to F$ in $L_{\mu}^{1}$ which sounds quite intuitive, i.e. both sequences have the same limit. This sounds quite obvious as the limit is $T$-invariant. Then I intended to use boundedness of $f$ to find a uniform estimate for the difference. But I always have the problem that the summation over $n$ and $N^{-1}$ cancel each other. Furthermore all those estimates are but almost surely. Could you please given me a hint on why the critical estimate holds? Note that I am particularly interested in getting this proof to work, not in any proof of the Pointwise Convergence Theorem. Detailed Estimate: Thanks to @Davide Giraudo, I think I managed to prove it if $f$ is honestly bounded. In what follows let $\xi:=(\xi_{n})_{n\in\mathbb{N}}$ be a bounded sequence and $U_{N}(\xi):=\sum_{n=0}^{N-1}\xi_{n}$. Using his idea, we get:
  $$U_{N}(U_{M}(\xi))=\sum_{n=0}^{N-1}\sum_{m=n}^{M+n-1}\xi_{m}$$
  A little drawing and induction shows that for fixed $M\in\mathbb{N}$ and $N\in\mathbb{N}$ way larger than $M$, we get:
  $$\begin{align}U_{N}(U_{M}(\xi))=&\sum_{m=0}^{M-1}(m+1)\xi_{m}+M\sum_{m=M}^{N-1}\xi_{m}+\sum_{m=N}^{M+N-2}(M+N-1-m)\xi_{m}\\
=&U_{N}(\xi)+\sum_{m=0}^{M-1}m\xi_{m}+(M-1)\sum_{m=M}^{N-1}\xi_{m}+\sum_{m=N}^{M+N-2}(M+N-1-m)\xi_{m}\end{align}$$
  so that:
  $$U_{N}(U_{M}(\xi))-MU_{N}(\xi)=\sum_{m=0}^{M-1}(m+1-M)\xi_{m}+\sum_{m=N}^{M+N-2}(M+N-1-m)\xi_{m}$$
  As $|m+1-M|\leq M$ for $m\in\{0,\ldots,M-1\}$ and $|M+N-1-m|\leq M+|N-m|\leq 2M$ for $m\in\{N,\ldots,M+N-2\}$, we find that for $x\equiv (f(T^{n}(x)))_{n\in\mathbb{N}}$ holds:
  $$\begin{align}|A_{N}(A_{M}(x))-A_{N}(x)|=&\frac{1}{NM}|U_{N}(U_{M}(x))-MU_{N}(x)|\\
\leq &\frac{1}{NM}\left\{\sum_{m=0}^{M-1}2M\lVert f\rVert_{\infty}+\sum_{m=N}^{M+N-2}2M\lVert f\rVert_{\infty}\right\}\leq\frac{2M}{N}\lVert f\rVert_{\infty}\end{align}$$ It remains for me to ensure that if $f$ is almost surely bounded, the estimate still holds almost everywhere. Range of validity of the estimate: This is in fact easy. Let $f$ lmost surely bounded, then there exists $B\subseteq\mathscr{B}$ with $\mu(B)=1$ and $f|_{B}$ bounded by $\lVert f\rVert_{\infty}$. Look at $B':=\cap_{n\geq 0}T^{-n}(B)$, then $\mu(B')=1$ as its complement is a countable union of nullsets and the estimate clearly holds on $B'$. But this requires us to change to:
  $$\{x\in X;\lim\sup_{N\to\infty}|F(x)-A_{N}(f)(x)|>\epsilon\}\stackrel{\mu}{=}\{x\in X;\lim\sup_{N\to\infty}|F(x)-A_{N}(A_{M}(f))|\}$$
  instead of a strict equality. But this doesn't pose any problems.","['probability-theory', 'ergodic-theory', 'functional-analysis']"
640416,What is the importance of localization in algebraic geometry?,"It is often asserted in commutative algebra texts that localization is important in algebraic geometry . I would appreciate some precise examples which show the utility of the concept in this context. Although I have some knowledge of algebraic geometry, I am not an expert, so I would like the examples to be relatively simple if possible.","['localization', 'ring-theory', 'algebraic-geometry']"
640448,What are the generators of $\text{U}(3)$?,"How can I find the (nine) generators of $\text{U}(3)$? I have started out by considering $\text{SU}(3)$, which is an 8-dimensional subgroup of $\text{U}(3)$. The generators of $\text{SU}(3)$ that are often used by particle physicists are the Gell-Mann matrices $\lambda^a$ (for $a = 1,2,\ldots,8$), given by:
\begin{alignat*}{4}
\lambda^1 &= \left( \begin{array}{ccc}
0 & 1 & 0 \\
1 & 0 & 0 \\
0 & 0 & 0
\end{array} \right) \,, \quad &\lambda^2 &= \left( \begin{array}{ccc}
0 & -i & 0 \\
i & 0 & 0 \\
0 & 0 & 0
\end{array} \right) \,, \quad &\lambda^3 &= \left( \begin{array}{ccc}
1 & 0 & 0 \\
0 & -1 & 0 \\
0 & 0 & 0
\end{array} \right) \\
\lambda^4 &= \left( \begin{array}{ccc}
0 & 0 & 1 \\
0 & 0 & 0 \\
1 & 0 & 0
\end{array} \right) \,, \quad &\lambda^5 &= \left( \begin{array}{ccc}
0 & 0 & -i \\
0 & 0 & 0 \\
i & 0 & 0
\end{array} \right) \,, \quad &\lambda^6 &= \left( \begin{array}{ccc}
0 & 0 & 0 \\
0 & 0 & 1 \\
0 & 1 & 0
\end{array} \right) \\
\lambda^7 &= \left( \begin{array}{ccc}
0 & 0 & 0 \\
0 & 0 & -i \\
0 & i & 0
\end{array} \right) \,, \quad &\lambda^8 &= \frac{1}{\sqrt{3}} \left( \begin{array}{ccc}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & -2
\end{array} \right) \,,
\end{alignat*}
and satisfying the commutation relation
\begin{equation*}
[\lambda^a,\lambda^b] = 2 i f^{abc} \lambda^c \,,
\end{equation*}
where $f^{abc}$ are the completely antisymmetric structure constants of $\text{SU}(3)$. Each element of $\text{SU}(3)$ can be written as $\exp (i \theta^j \lambda^j/2)$, where $\theta^j$ are real numbers and a sum over the index $j$ is implied. Furthermore, the Gell-Mann matrices are traceless, Hermitian, and obey the relation $\text{Tr}(\lambda^i \lambda^j) = 2\delta^{ij}$. As the Gell-Mann matrices have nice properties, I would like to extend this set to obtain a full set of generators for $\text{U}(3)$. But how can I find this 'ninth' generator? Any help would be appreciated.","['lie-groups', 'group-theory']"
640449,Differential calculus: word problem,"The derivation of $$y=xy^2$$ is $$\frac{\mathrm dy}{\mathrm dx} =  y^2 + x\cdot 2y \frac{\mathrm dy}{\mathrm dx}.$$
Why we are are putting $\frac{\mathrm dy}{\mathrm dx}$ if we have already derived $y^2$ and its power becomes its coefficient then why $\frac{\mathrm dy}{\mathrm dx}$?
can any one explain it.","['calculus', 'derivatives']"
640460,"In the equation $y = ax^2 + bx + c$ of a parabola, what do ""$a$"", ""$b$"", ""$c$"" represent?","I have trouble grasping some basic things about parabolas. (This should be easily found on Google, but for some reason I couldn't find an answer that helped me). I know one simple standard equation for a parabola: $$y = ax^2 + bx + c$$ My problem is: I'm not sure what the following letters represent: $a$ , $b$ , and $c$ . Please try to explain to me what each of these letters represent in the equation, in a simple manner so I will understand, since I have very basic knowledge in math. Thank you","['geometry', 'conic-sections']"
640488,Showing $P(A\cap C)\geq P(A)P(C)$ from $A \cap B \subset C \subset A \cup B$ without using the independence of $A$ and $B$,"Here is the problem I came across: Let $A,B,C$ be events in some probability space. Show that if $A$ and $B$ are independent and $A \cap B \subset C \subset A \cup B$ then $P(A\cap C)\geq P(A)P(C)$. My text gives a relatively lengthy solution using both of the givens. I came up with the following solution which doesn't make use of the independence of $A$ and $B$: \begin{align} 
P(A)P(C) & = P\Big((A\setminus C)\cup (A \cap C)\Big)P\Big((C\setminus A)\cup (A \cap C)\Big)
\\ & = P(A\setminus C)P(A \cap C)P(C\setminus A)P(A \cap C)
\\ & \leq P(A \cap C)
\end{align} Clearly, not using some of the given is mostly a huge red flag. Yet I don't see what's wrong with my solution. Any hints are very appreciated.","['elementary-set-theory', 'probability']"
640489,Convergence from $L^p$ to $L^\infty$ [duplicate],"This question already has answers here : Limit of $L^p$ norm (4 answers) Closed 10 years ago . If $f$ is a function such that $f \in L^\infty \cap L^ {p_0}$ where $L^\infty$ is the space of essentially bounded functions and $ 0 < p_0 < \infty$. Show that $ || f|| _{L^p} \to ||f || _{L^\infty} $ as $ p \to \infty$. Where $|| f||_{L^\infty} $ is the least $M \in R$ such that $|f(x)| \le M$ for almost every $x \in X$. The hint says to use the monotone convergence theorem, but i can't even see any pointwise convergence of functions.
Any help is appreciated.","['measure-theory', 'real-analysis']"
640491,"Every open subset $O$ of $\Bbb R^d,d \geq 1$, can be written as a countable union of almost disjoint closed cubes.","After the usual construction as explained in press.princeton.edu/chapters/s8008.pdf (page 8) I did not understand the argument why the union is all of $O$. ""We note that given $x \in O$ there exists a cube of side length $2^{-N}$ (obtained from successive bisections of the original grid) that contains $x$ and that is entirely contained in $O$"" (page 8 line 4). How can this cube be rejected ? it is entirely contained in $O$. 
‎",['measure-theory']
640493,Why can infinite series be summed different ways to get different results? [duplicate],"This question already has answers here : absolutely convergent series and conditionally convergent series rearrangement (2 answers) Closed 10 years ago . $$S = 1 - \frac12 + \frac13 - \frac14 + \frac15 - \frac16 + \frac17 - \frac18 + \frac19 - \frac1{10} + \frac1{11} - \frac1{12}\ldots\text{(to infinity)}$$ Rearranged, this series looks like:
$$S = \left(1 - \frac12\right) - \left(\frac14\right) + \left(\frac13 - \frac16\right) - \left(\frac18\right) + \left(\frac15 - \frac1{10}\right) - \left(\frac1{12}\right) + \left(\frac17 - \frac1{14}\right) \ldots\text{(to infinity)}\\
 S = \left(\frac12\right) - \left(\frac14\right) + \left(\frac16\right) - \left(\frac18\right) + \left(\frac1{10}\right) - \left(\frac1{12}\right) + \left(\frac1{14}\right) \ldots\text{(to infinity)}$$ This rearranged infinite series contains every number that the original infinite series had. Further, $$ 2S = 1 - \frac12 + \frac13 - \frac14 + \frac15 - \frac16 + \frac17 - \frac18 + \frac19 - \frac1{10} + \frac1{11} - \frac1{12} \ldots\text{(to infinity)}$$
Thus: $2S = S$ $2 = 1$ Mathematics disproven.  Sorry. Jokes aside, I know that infinite series can be calculated in different ways to get different results.  My question is: Why? While it makes sense with Grandi's and similar series, it doesn't make sense to me for a series whose final term is $\frac1\infty = 0$.",['sequences-and-series']
640497,Are there functions so that $f(n) \notin \mathcal{O}(g(n))$ and $g(n) \notin \mathcal{O}(f(n))$?,"Note that the functions should be $\mathbb{N}_0 \rightarrow \mathbb{N}_0$. So I was thinking about something like $$f(x) = 1 + \sin(\frac{\pi x}{2})$$
$$g(x) = 1 + \cos(\frac{\pi x}{2})$$ 
which would work I guess. However, would it still be possible if both functions had to be monotonic increasing (not necessary strictly!)?","['asymptotics', 'functions']"
640553,Unique combination of sets,"We start with a finite number of $N$ sets, $\boldsymbol{X}_1,\ldots,\boldsymbol{X}_N$, each containing a finite number of integers. The sets do not in general have the same number of elements. The goal is to find all possible unique combination that you can get by taking the union of some of these sets. All sets need to be used. Example for $N = 4$ the possible combinations are: $\boldsymbol{X}_1,\boldsymbol{X}_2,\boldsymbol{X}_3, \boldsymbol{X}_4$ ($\boldsymbol{X}_1\bigcup\boldsymbol{X}_2),\boldsymbol{X}_3, \boldsymbol{X}_4$ ($\boldsymbol{X}_1\bigcup\boldsymbol{X}_2),(\boldsymbol{X}_3 \bigcup\boldsymbol{X}_4)$ $\boldsymbol{X}_1,\boldsymbol{X}_2,(\boldsymbol{X}_3 \bigcup\boldsymbol{X}_4)$ ($\boldsymbol{X}_1\bigcup\boldsymbol{X}_3),\boldsymbol{X}_2,\boldsymbol{X}_4$ ($\boldsymbol{X}_1\bigcup\boldsymbol{X}_3),(\boldsymbol{X}_2\bigcup\boldsymbol{X}_4)$ $\boldsymbol{X}_1,\boldsymbol{X}_3,(\boldsymbol{X}_2\bigcup\boldsymbol{X}_4)$ ($\boldsymbol{X}_1\bigcup\boldsymbol{X}_4),\boldsymbol{X}_2,\boldsymbol{X}_3$ ($\boldsymbol{X}_1\bigcup\boldsymbol{X}_4),(\boldsymbol{X}_2\bigcup\boldsymbol{X}_3)$ $\boldsymbol{X}_1,\boldsymbol{X}_4,(\boldsymbol{X}_2\bigcup\boldsymbol{X}_3)$ ($\boldsymbol{X}_1\bigcup\boldsymbol{X}_2\bigcup\boldsymbol{X}_3),\boldsymbol{X}_4$ ($\boldsymbol{X}_1\bigcup\boldsymbol{X}_2\bigcup\boldsymbol{X}_4),\boldsymbol{X}_3$ ($\boldsymbol{X}_1\bigcup\boldsymbol{X}_3\bigcup\boldsymbol{X}_4),\boldsymbol{X}_2$ $\boldsymbol{X}_1,(\boldsymbol{X}_2\bigcup\boldsymbol{X}_3\bigcup\boldsymbol{X}_1)$ ($\boldsymbol{X}_1\bigcup\boldsymbol{X}_2\bigcup\boldsymbol{X}_3\bigcup\boldsymbol{X}_1$) This could be encoded in a matrix as: $\begin{bmatrix}0,0,0,0\\1,1,0,0\\1,1,2,2\\0,0,1,1\\1,0,1,0\\1,2,1,2\\0,1,0,1\\1,0,0,1\\1,2,2,1\\0,1,1,0\\1,1,1,0\\1,1,0,1\\1,0,1,1\\0,1,1,1\\1,1,1,1\end{bmatrix}$, where each column corresponds with a set and each row with a combination; a $0$ indicates that the set is not combined with any other set and $1$, $2$, etc. indicates a union of the sets with the same number. How do I generate this sequence in general (for my particular application I expect $N<20$). Can anyone point me in the right direction?","['elementary-set-theory', 'algorithms', 'combinatorics']"
640554,Set of Linear equation has no solution or unique solution or infinite solution?,"For the system 
$$
\left\{
\begin{array}{rcrcrcr}
 x &+ &3y &-  &z &= &-4 \\
4x &-  &y &+ &2z &= &3 \\
2x &-  &y &- &3z &= &1
\end{array}
\right. 
$$
what is the condition to determine if there is no solution or unique solution or infinite solution? Thank you!","['linear-algebra', 'systems-of-equations', 'determinant']"
640558,How many ways can N elements be partitioned into subsets of size K?,"Let's have $2$ numbers, $N$ and $K$ , where $K$ divides $N$ . The number of $K$ -combinations from a given set $S$ of $N$ elements is a well-known formula. Let's concatenate $N/K$ groups (resulting in $N$ elements) such that the resulting set is $N$ . How many possibilities are there, i.e. what's the formula? For instance: $N=4$ , and $K=2$ , gives $\binom{4}{2} = 6$ $\{1,2\}$ , $\{1,3\}$ , $\{1,4\}$ , $\{2,3\}$ , $\{2,4\}$ , $\{3,4\}$ The $3$ possibilities are: $\{1,2\}$ , $\{3,4\}$ $\{1,3\}$ , $\{2,4\}$ $\{1,4\}$ , $\{2,3\}$ I generated these combinations and I think the number goes like this: $$
\begin{align}
(4, 2)&: 3 \\
(6, 3)&: 10 \\
(6, 2)&: 15 \\
(10, 5)&: 126 \\
(9, 3)&: 280 \\
(10, 2)&: 945 \\
(14, 7)&: 1716 \\ 
(12, 4)&: 5775 \\ 
(15, 5)&: 126126 \\
(15, 3)&: 1401400
\end{align}
$$ Apparently, the result always divides with $(N-1)$ .","['set-partition', 'combinatorics']"
640585,"Show that $\int_0^{\pi/3} \big((\sqrt{3}\cos x-\sin x)\sin x\big)^{1/2}\cos x \,dx =\frac{\pi\sqrt{3}}{8\sqrt{2}}. $","I have run a FORTRAN code and I have obtained strong evidence that
$$\int_0^{\pi/3} \!\!
\big((\sqrt{3}\cos\vartheta-\sin\vartheta)\sin\vartheta\big)^{\!1/2}\!\cos\vartheta \,d\vartheta
=\frac{\pi\sqrt{3}}{8\sqrt{2}}. 
$$
In fact, it looks like my numerical integration method (the trapezoid rule) converges to the value $\dfrac{\pi\sqrt{3}}{8\sqrt{2}}$, with at least $12$ significant digits. Any ideas how to prove this result analytically?","['residue-calculus', 'calculus', 'integration', 'definite-integrals', 'analysis']"
640596,How to solve this problem with trigonometry and by using vectors?,"In an assignment I'm asked this: A boat needs to sail to a port that is on a bearing of 065°. The boat sails in still water at a speed of 35km/h.
  There is a current, moving the water at a speed of 3 km/h on a bearing of 320°.
  What heading should the boat take in order to reach the port?
  You may find it easier to solve this question using trigonometry rather than Cartesian components. You will get the greatest benefit if you try both. I tried doing the vector part first, where I  found that the boat needs to go at 35.89 km/h in the direction of 69.64 degrees. However, then I realized it's about a sail boat, so you can't choose a speed at random over. I thought first I needed to find the vector for where the boat has to sail to end up going at 35 km/h in the direction of 65 degrees when taking the current into consideration, but now I'm guessing I'm actually supposed to at what angle does a boat sailing at 35 km/h need to be heading to end up going in a direction of 65 degrees after being pushed by a 320-degree 3km/h current. So I'm a bit stuck as to how I can solve this now. Both in terms of using vector calculations and trigonometry.","['trigonometry', 'vectors', 'physics']"
640612,Product property for reversing coefficients for polynomials,"Given a polynomial $$P(x)=a_0+a_1x+\cdots+a_nx^n,$$ define $$f(P(x))=a_n+a_{n-1}x+\ldots+a_0x^n.$$ How can we prove that $$f(P(x))f(Q(x))=f(P(x)Q(x))?$$ Expanding out the expression should be possible, but seems like a big pain.","['ring-theory', 'algebra-precalculus', 'abstract-algebra', 'polynomials']"
640619,In how many ways can you arrange a circle of partners so that no partners are touching?,"There are a lot of similar questions to this but none that is quite the same so I figured I would ask a new question. The problem is you have a group of people that came in pairs, in how many ways can the $N$ people be arranged in a circle such that no person in the circle is holding hands with the partner they came with. I have worked out by hand that for two couples(four people) the answer is $2$ ways For three couples ($6$ people) the answer is $32$ ways Also it should be noted that a rotated circle is not counted as a different arrangement. If the answer posted below is correct the OEIS sequence is http://oeis.org/A129348 Can any one else confirm that this is correct?","['discrete-mathematics', 'combinatorics']"
640652,Painting a circle that is divided into $6$ pieces,"Given is a circle that is divided into $6$ identical pieces and we have $4$ different colours. How many ways can we paint it under the condition that no adjacent pieces have the same colour? You can use all $4$ colours: But you don't have to: However, the second one is NOT considered as a different case because it's only rotated: I thought the answer was $4\cdot3\cdot3\cdot3\cdot3\cdot2$ at first but it should be less since we can rotate it.",['combinatorics']
640659,The only element of $S_{\large{n \ge 3}}$ satisfying $\sigma y = y\sigma$ for all $y \in S_n$ is the identity permutation - Fraleigh p. 86 8.47,"I don't want to type Greek letters hence I replaced $\gamma$ by $y$. Microsoft didn't replace them all. Call the identity permutation $id$. 
Prove the contraposition: $\sigma \neq id \implies \exists \, y \in S_n : \sigma y \neq y\sigma.$ Suppose $\sigma \neq id.$ Then for some $1 \le x_1 \neq x_2 \le n, \; \color{brown}{\sigma(x_i) = x_2}$. Because $n \ge 3$, hence there exists a third element $x_3 \neq x_2$ such that $y(x_2) = x_3$ and $\color{magenta}{y(x_1) = x_1}$. Then $(σγ)(x_1) = σ(\color{magenta}{γ(x_1)}) = σ(\color{magenta}{x_1}) = x_2$ while $(γσ)(x_1) = γ(\color{brown}{σ(x_1)}) = γ(\color{brown}{x_2}) = x_3$, so $σγ \neq γσ.$ (1.) How and why does $n \ge 3$  imply  there exists $y \in S_n$ such that $y(x_2) = x_3$ and $\color{magenta}{y(x_1) = x_1}$ ? (2.) How do you predestine, preordain to prove this by contraposition? (3.) What's the intuition? Update Fev. 4 2014: clem wrote $\color{darkred}σ: x_3 \mapsto i$. Shouldn't this be $\color{darkred}{(γσ)^{−1} =σ^{−1}γ^{−1}} : x_3 \longmapsto i$ ? Hence I apply $γ^{−1}$ first to sally forth from $x_3 \to i$?","['intuition', 'group-theory', 'symmetric-groups']"
640674,"Show that for any $f\in L^1$ and $g \in L^p(\mathbb R)$, $\lVert f ∗ g\rVert_p \leqslant \lVert f\rVert_1\lVert g\rVert_p$.","I write the exact statement of the problem: Show that for any $g \in L^1$ and $f ∈ L^p(\mathbb{R})$, p $\in (1, \infty)$, the integral for f ∗g converges absolutely almost everywhere and that $∥f ∗ g∥_p ≤ ∥g∥_1∥f∥_p$. I've tried to show that the convolution is well defined for f,g $\in L^1$ in this way: $$\int_{\mathbb{R^d}}f*gdx=\int_{\mathbb{R^d}}\int_{\mathbb{R^d}}f(x-y)g(y)dydx\le\int_{\mathbb{R^d}}\int_{\mathbb{R^d}}|f(x-y)||g(y)|dydx$$ I've used Tonelli's theorem since the function is non-negative $$\int_{\mathbb{R^d}}|g(y)|\int_{\mathbb{R^d}}|f(x-y)|dxdy=∥f∥_1∥g∥_1$$ Now I've thought that since $L^1 \subset L^p$ this is true also for f $\in L^p$ (can I do it? ) I've tried with some colleagues something with Hölder's inequality. I've chosen a q $\in$ (1,$\infty$) such that $\frac{1}{p}+\frac{1}{q}=1$ $$∥f ∗ g∥_p^p=\int_{\mathbb{R^d}}|\int_{\mathbb{R^d}}f(x-y)g(y)dy \space |^pdx=\int_{\mathbb{R^d}}\space |\int_{\mathbb{R^d}}f(x-y)g(y)^{\frac1p}g(y)^{\frac1q}dy\space |^pdx$$ $$\le\int_{\mathbb{R^d}}\space \int_{\mathbb{R^d}}|f(x-y)g(y)^{\frac1p}g(y)^{\frac1q} \space |^pdy\space dx=\int_{\mathbb{R^d}}\space \int_{\mathbb{R^d}}|f(x-y)^pg(y)g(y)^{\frac{p}{q}}|\space dy\space dx$$ $$\int_{\mathbb{R^d}}\space \int_{\mathbb{R^d}}|f(x-y)^pg(y)g(y)^{\frac{p}{q}}| \space dy\space dx=\int_{\mathbb{R^d}}\space \int_{\mathbb{R^d}}|f(x-y)^pg(y)^p| \space dy\space dx$$ $$= \int_{\mathbb{R^d}}\space \int_{\mathbb{R^d}}|f(x-y)^pg(y)^p| \space dx\space dy=∥g∥_1^p∥f∥_p^p \implies ∥f ∗ g∥_p ≤ ∥g∥_1∥f∥_p$$ This works is it not?","['convolution', 'measure-theory', 'integration', 'lp-spaces']"
640688,Proving that a particular restriction of a projection is a quotient map,"I was hoping somebody could help me with the following problem: Let $\pi: \mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}$ be the
  projection onto the first coordinate, and let $p=\pi|_X$, where
  $X=(\mathbb{R}_{\geq0} \times \mathbb{R}) \cup (
 \mathbb{R} \times \{0\})$ (so $X$ should be the x-axis union everything to the
  right of, and including, the y-axis...right?). Show that $p$ is a
  quotient map, but $p$ is not an open map or a closed map. Using a property of the subspace topology (namely that we can restrict the codomain of a continuous function and still retain continuity) $p$ must be continuous. Surjectivity is also apparent. However, I'm not sure how to prove that $p$ is a quotient map, and that it is neither open nor closed. I feel like examining neighborhoods of the origin might give a clue towards a solution, but I've tried a handful of examples of such neighborhoods and gotten nowhere. Any help is appreciated, thanks!",['general-topology']
640698,"Again, improper integrals involving $\ln(1+x^2)$","How can I check for which values of $\alpha $ this integral $$\int_{0}^{\infty} \frac{\ln(1+x^2)}{x^\alpha}\,dx $$ converges? I managed to do this in $0$ because I know $\ln(1+x)\sim x$ near 0. I have no idea how to do this in $\infty$ where nothing is known about $\ln(x)$ . Will someone help me ? Thanks!","['improper-integrals', 'convergence-divergence', 'calculus']"
640725,"If $f$ and $g$ satisfy the sine/cosine addition formulae, then what is $g'(0)$?","The question is: Question. Let $f,g:\mathbb R\to\mathbb R$ be two functions that satisfy $$f(x-y)=f(x)\cdot g(y)-f(y)\cdot g(x)$$ and $$g(x-y)=g(x)\cdot g(y)+f(x)\cdot f(y)$$ for all $x,y \in \mathbb{R} $ . If the right hand derivative at $x=0$ exists for $f(x)$ , then what is $g'(0)$ ? My try: By some simple substitutions I figured out that $f(0)=0$ and $g(0)=1$ . If in the second equation, we put $x=y$ , it will give $g(0)=(g(x))^2+(f(x))^2$ . If $g(0)=0$ , sum of the two squares becomes $0$ which implies the squares themselves are zero, I neglected $g(x)=f(x)=0$ as a trivial solution and hence took $g(0)=1$ . But how do I proceed after this?","['derivatives', 'functional-equations']"
640759,Tricky Differential Equation Problem,"I am unsure of how to tackle the following differential equation: $$ dx+ x\,dy = e^{-y}\sec^2y\,dy$$ I have done the following so far: $$dx + x\,dy = e^{-y} \sec^2y \, dy$$ $$=>dx = e^{-y} \sec^2y \, dy - x \, dy$$ $$=>dx = (e^{-y} \sec^2y - x) \, dy$$ $$=>dx/dy = (e^{-y}) \sec^2y - x $$ Is this the correct approach? How can the problem be solved after this? (Not homework: preparing for a test)","['multivariable-calculus', 'ordinary-differential-equations', 'calculus', 'integration']"
640767,Show that $f(x)=0$ for all $x\geq0$,"I have been struggling with this problem.. Q. Let $f(x)$, $x\geq 0$, be a non-negative continuous function, and let $F(x)=\int_0^x f(t) dt$, $x\geq0$. If for some $c>0$, $f(x)\leq cF(x)$ for all $x\geq 0$, then show that $f(x)=0$ for all  $x\geq0$ . I have tried everything in my ability, but in vain. I get a feeling that this can be solved using Mean Value theorem. Any ideas? Please help!!","['inequality', 'calculus', 'functions']"
640780,Probability every hyperplane contains at most $m/2$ vectors,"I pick $m \geq n$ vectors drawn uniformly from  $\{-1,1\}^n$, and call the set of vectors  $X$.  What is the probability that for every non-zero $v \in \mathbb{R}^n$ there exist at least $m/2$ vectors in $X$ which are not orthogonal to $v$? If an exact probability is not possible, can bounds be found?","['linear-algebra', 'probability']"
640782,Dividing Decimals.. But remainders?,"So, I understand how to do long division with decimals. So let's consider this problem: $10.5$ divided by $5.5$ (I chose this problem because it will OBVIOUSLY have a remainder) So we will look at is as $105$ div'd by $55$ We will get $1$ with the remainder of $50$... Now time to convert this back to decimals Okay so Answer was 0.01 but how should I convert the remainder to a decimal? Sorry, I'm in 5th grade, and this is my first time posting at StackOverflow's Math area (Is it different from StackOverflow Programming? How so?) Sorry and thanks! Also, couldn't find the right tag.. Sorry!","['decimal-expansion', 'algebra-precalculus']"
640786,Show identity between product-$\sigma$-algebra and a set,"Let $T$ be any index set and $(\Omega_i,\mathcal{A}_i)_{i\in T}$ a family of measurable spaces and $\mathcal{A}:=\bigotimes_{i\in T}\mathcal{A}_i$. Show that
    $$
\mathcal{A}=\left\{A\subset  \times_{i\in T}\Omega_i | \exists R\subset T\text{ countable} : A\in\pi_R^{-1}\left(\bigotimes_{i\in R}\mathcal{A}_i\right)\right\}=:\mathcal{B},
$$
    whereat 
    $$
\pi_R\colon \times_{i\in T}\Omega_i\to\times_{i\in R}\Omega_i, (\omega_i)_{i\in T}\mapsto (\omega_i)_{i\in R}.
$$ (Sorry,  I do not know how to write the big times here so I used the small \times.) Hello! $\subseteq$: My assumption is that $\mathcal{B}$ is a $\sigma$-algebra, is that right? ( Iwas not able to show it yet.) Let $\mathcal{F}(T)$ be the set of the finite subsets of $T$. Then in our lecture we had, that
$\mathcal{A}$ is generated by
$$
\mathcal{Z}=\mathcal{Z}(\mathcal{A}_t: t\in T):=\bigcup_{S\in\mathcal{F}(T)}\mathcal{Z}_S,~~~\mathcal{Z}_S:=\pi_S^{-1}\left(\bigotimes_{t\in S}\mathcal{A}_t\right),
$$
so $\sigma(\mathcal{Z})=\mathcal{A}$. When I see it right, then $\mathcal{Z}\subset \mathcal{B}$. If my assumption that $\mathcal{B}$ is a $\sigma$-Algebra is right, then it follows $\mathcal{A}=\sigma(\mathcal{Z})\subset \mathcal{B}$. $\supseteq$: Consider $A\in \mathcal{B}$. Then there exists a countable $R\subset T$ so that $A\in\pi_R^{-1}\left(\bigotimes_{i\in R}\mathcal{A}_i\right)$. Now I think one has to distinguish (i) $R$ is finite and (ii) $R$ is countably infinite. Case (i): Then $A\in\mathcal{Z}_{R}\subset\mathcal{Z}\subset\sigma(\mathcal{Z})=\mathcal{A}$. I am not able to handle case (ii). Would be great if you could help me.","['measure-theory', 'elementary-set-theory', 'solution-verification']"
640832,Borel-Cantelli lemma problem [duplicate],"This question already has answers here : Probability of $\limsup$ of a sequence of sets (Borel-Cantelli lemma) (3 answers) Closed 8 years ago . Practice problem for exam: Let ${A_n}$ satisfy $\sum\limits_{n=1}^\infty P(A_n \cap A^c_{n+1}) < \infty$ and $\lim\limits_{n\to \infty} P(A_n) = 0$.  Show that $P(\lim \sup A_n) = 0$. I can see that it is sufficient to show that $P\left(\sum\limits_{n=1}^\infty A_n\right) < \infty$ and then apply the Borel-Cantelli lemma, but I am having trouble showing this from the information given.  I see an almost identical problem here: A variation of Borel Cantelli Lemma , however the hint there is not enough for me to make headway, and this problem is also different in which term gets the complement inside the first sum.","['probability-theory', 'borel-cantelli-lemmas', 'measure-theory', 'limsup-and-liminf']"
640904,best constant in quasi triangle inequality for $L^p$ spaces with $0 < p \le 1$,"Currently doing a problem that ask me to prove the best constant $C$ (depending on $p$) such that the quasi triangle inequality $||f+ g||_p \le C (||f||_p + ||g||_p)$ for $L^p $ spaces holds, where $0< p \le 1$, is $2^{1/p -1 } $. My approach is I already proved $||f+g||_p^p \le ||f||_p^p + ||g|| _p ^p$. So it will be suffices to show that $(||f||_p^p + ||g|| _p^p ) ^{1/p} \le 2^{1/p -1} ( ||f||_p + ||g||_p)$. But I have no idea how to proceed this. Any help is appreciated.","['measure-theory', 'inequality']"
640914,Find maximum of a double integral over a region,"I have a region given by $$R = |{ax}|+|{by}| \le 1$$ and $$f(x,y) = \iint\limits_{R}{(ax-by)^2 \ \cdot \ (3ab^3+12a^3b-6a^3b^2) \ \cdot \ \sin^2({\pi ax + \pi by}})dxdy$$ I need to find the values of $a$ and $b$ that maximize $f$ and I have no idea where to start.","['optimization', 'multivariable-calculus', 'lagrange-multiplier']"
640938,Position and nature of singularities of an algebraic function (Ahlfors),"I want to solve the following exercise, from Ahlfors' Complex Analysis text, page 306: Determine the position and nature of the singularities of the algebraic function defined by $w^3-3wz+2z^3=0.$ Here is my solution attempt. I would appreciate your opinion (is it true?) The critical points $\{c_k\}$ are the zeros of the leading coefficients as well as the zeros of the discriminant of the polynomial above, which I'll denote by $P(w,z)$ from now on. Since the leading coefficient $a_0(z)=1$ is non-vanishing, the critical points can only occur as zeros of the discriminant of $P(w,z)$ (which is the resultant of $P$ and $P_w)$. According to my calculations (i.e. obtaining the resultant by a sequence of polynomial divisions, starting with $P$ divided by $P_w$)  the discriminant is $3z^4-3z$
. It has zeros whenever $z_0=0$ or $z_k=\exp(2\pi ik/3)$ for $k \in \{1,2,3\}$. According to the analysis on page 304, all points $\{z_k \}_{k=0}^3$ are ordinary algebraic singularities. We are left with examining the point $z=\infty$. Unfortunately, the book only finds a bound on the degree of the pole at infinity. Moreover, it is not even guarantee that it is a pole (apparently, it could also be an ordinary point). I have no idea how to determine the nature of the singular point at $\infty.$ To sum up, I have two questions: Is the part regarding the zeros of the discriminant true? How can I determine the nature at $z=\infty$? Thanks.","['algebraic-geometry', 'complex-analysis']"
640940,A Banach space is reflexive if a closed subspace and its quotient space are both reflexive,"Let $X$ be a Banach space. Let $Y$ be a closed subspace. Suppose that the normed spaces (in fact Banach spaces) $Y$ and $X/Y$ are both reflexive. I need to show that $X$ is reflexive. I cannot show this but I feel that I could use the fact that a Banach space is reflexive if and only if its closed unit ball is weakly compact. So in this case we know $B_Y$ and $B_{X/Y}$ are weakly compact. Let $\mathcal{U}$ be a weakly open cover for $B_X$. I feel that a finite subcover can be obtained by considering the sets of the form $a+Y\cap B_X\subset X$, which are certainly compact, as $a+Y\cap B_X\subset a+nB_Y\cap B_X$, which is w-closed in the weakly compact set $a+nB_Y$ for some sufficiently large $n$, and the corresponding $a+Y\in X/Y$. Could anybody suggest anything? Thanks.","['functional-analysis', 'banach-spaces']"
640941,Least greedy square,"There are $n$ squares of $m$ different colors. Squares of the same color are interior disjoint, but squares of different colors may intersect. For every square, define its ""greed"" as the maximum number of squares of a single color that it intersects. For example, in the figure below, the top-left red square has a greed of 1 because it intersects 1 green square; the bottom-right red square has a greed of 4 becaues it intersects 4 green squres (in addition to 1 blue square); the other two red squares have a greed of 2. MY QUESTION IS: What is the minimum greed that a single square can have, in the worst case? 4 is an upper bound, because the smallest of all squares has a greed of at most 4. This is because, when a square intersects a larger square, at least one corner of the smaller square must be covered. Since a square has 4 corners, it can intersect at most 4 larger squares that are disjoint, i.e., at most 4 squares per color. 2 is a lower bound, as shown by the construction below, where all squares have a greed of 2: So, the question is whether there is always a square with a greed of at most 2? Or at most 3?","['geometry', 'rectangles']"
640961,How to calculate projected value?,"I am trying to figure out how to calculate a projected value for our goals. Each of our sales persons is assigned an annual goal for 2014, say 60 units. Let's say, as of today, one sales person has sold 5 units. How would I calculate, assuming everything trends the way it currently is, their projected actual value for year end? I'd like to show them how they are trending.",['statistics']
641023,Given a triangle find the length of BC,"Given an ABC triangle , if $AB+AD=4$, find the length of BC.","['geometry', 'euclidean-geometry']"
641032,$K$ is a normal subgroup of a finite group $G$ and $S$ is a Sylow $p$-subgroup of $G$. Prove that $K \cap S$ is a Sylow $p$-subgroup of $K$.,"(This is my first post here, so please excuse me if I'm not following proper etiquette.) First, I noted that both $K$ and $S$ are subgroups, thus their intersection is a subgroup. We can write that $|G| = p^km$ and $|S| = p^k$ where $p$ is a prime and $m$ has no factors of $p$ . By Lagrange's theorem, since the intersection is a subgroup of $S$ , then the cardinality of the intersection must be of the form $p^l$ where $l \leq k$ . We can write $K$ as $p^rn$ where $r \leq k$ and $n$ has no factors of $p$ . If I can show that $l=r$ , then it seems that would be enough to show that the intersection is a sylow $p$ -subgroup of $K$ , but I can't seem to get anywhere else with anything. I recall a theorem that states that since $K$ is normal, then the intersection of $K$ and $S$ is normal in $S$ but I don't know if that helps me much. There is the corollary of Sylow's 3rd theorem in my book that states that ""A Sylow $p$ -subgroup of a finite group $G$ is a normal subgroup of $G$ if and only if it is the only Sylow $p$ -subgroup of $G$ "" which seems like I could use that somehow, but I'm not too sure.","['sylow-theory', 'group-theory', 'abstract-algebra']"
641047,Expected value of measurements associated to die rolls,"Suppose that we throw a die four times. Let $M$ be the smallest of the four rolls and let $S$ be the sum of the largest three rolls. What is $E\;[M]$ and $E\;[S]$? For $E\;[M]$ I suppose I could try and compute the distribution of $M$ and find the expected value directly, but there has to be an easier way. As for $E\;[S]$ I'm lost.","['probability', 'expectation']"
641057,Infinite Sum of factorial denominator and exponential numerator,"I've been trying to find the sum of the following infinite series:
$$
\sum\limits_{n=1}^\infty \frac{x^n}{n!2^n} 
$$ I've rewritten it as $$\sum\limits_{n=1}^\infty \frac{y^n}{n!}, y=\frac{x}{2}$$
which I know from looking at a table has the solution $$ S_\infty = e^y - 1$$ Edit: I need to be able to show this without already knowing the answer However, I don't know how to get from the summation to the solution in order to show work. I tried taking a look at this solution to a similar problem , but I couldn't find a way to properly apply the concepts to this one. I'd appreciate a push in the right direction for this problem.","['factorial', 'sequences-and-series']"
641093,graphing $f(x)=x \ln \left(1+\frac{1}{x}\right)$,I was assigned to draw the graph of this function $f(x)$ = $x\ln(1+{1\over x})$ . When I calculate $\lim_{x\to \infty} f(x)$ I get $1$ but the teacher said it's not correct even though its graph on the internet shows that $\lim_{x\to \infty}f(x)=1$ . Please tell me where did I  go wrong?,"['logarithms', 'functions', 'limits']"
641113,Nilpotent matrix and basis for $F^n$,"Let $A \in Mat_{n \times n}(F)$ a matrix which satisfies $A^n=0$ and $A^{n-1} \ne 0$ for some positive integer $n$. Let $v \in F^n$ be such that $A^{n-1}v \ne 0$.  Prove that $\{v, Av, A^2v,...,A^{n-1}v\}$ is a basis for $F^n$. So, from definition of $A$, I know that $A^iv \ne 0$ for all $0\le i \le n-1$. I know I need to prove the set is linearly independent and span $F^n$ to prove it's a basis, but I just don't know how.","['matrices', 'linear-algebra']"
641126,Is $\sqrt{2}\in{\Bbb Z}[\sqrt{2}+\sqrt{3}]$ true?,"Motivated by the positive answer to the following question: Is $\mathbf{Q}(\sqrt{2}, \sqrt{3}) = \mathbf{Q}(\sqrt{2}+\sqrt{3})$? I'm curious about whether ${\Bbb Z}[\sqrt{2}+\sqrt{3}]=\Bbb{Z}[\sqrt{2},\sqrt{3}]$ is also true, where ${\Bbb Z}[\alpha]$ denotes the smallest subring of ${\Bbb C}$ which contains $\alpha\in{\Bbb C}$. It suffices to know whether $\sqrt{2}\in{\Bbb Z}[\sqrt{2}+\sqrt{3}]$ is true or not. With some manipulation one can get
$$
2\sqrt{2}\in {\Bbb Z}[\sqrt{2}+\sqrt{3}]. 
$$
It seems no hope to get $f(x)\in\Bbb{Z}[x]$ such that
$$
f(\sqrt{2}+\sqrt{3})=\sqrt{2},
$$
which is equivalent to $\sqrt{2}\in{\Bbb Z}[\sqrt{2}+\sqrt{3}]$. But I don't have a proof. How should I go on?","['ring-theory', 'abstract-algebra']"
641127,Why does $\frac{d}{dx}\sin(x) = \cos (x)$?,Why? Can someone give me a link or explain below. Thanks,"['trigonometry', 'calculus']"
641137,The Empty Relation?,"In elementary set theory, a relation on sets $A,B$ is usually defined as a subset of $A\times B$. We know that there are $2^{|A\times B|}$ subsets of $|A\times B|$. One of these subsets is the empty set. Do we include the empty set as a relation on $A$ and $B$? In other words, is the number of relations between two sets simply $2^{|A\times B|}$? (Additionally, is 'the empty relation' the correct term for what I am describing?)","['terminology', 'elementary-set-theory', 'abstract-algebra']"
641159,"If $x\notin\mathbb{Q}$, then $\left|x-\frac{p}{q}\right|<\frac{1}{q^{2+\epsilon}}$ for infinitely many $\frac{p}{q}$?","This appears on Problem 1 of Chapter 1 in Stein & Shakarchi's Real Analysis: Given an irrational $x$, one can show (using the pigeon-hole principle, for example) that there are infinitely many fractions $p/q$, with relatively prime integers $p$ and $q$ such that $$\left|x-\frac{p}{q}\right|\leq\frac{1}{q^2}.$$
  However, prove that the set of all $x\in\mathbb R$ such that there exist infinitely many fractions $p/q$, with relatively prime integers $p$ and $q$ such that $$\left|x-\frac{p}{q}\right|\leq\frac{1}{q^{3}} \text{ (or} \leq 1/q^{\epsilon+2})$$ is a set of measure zero. By the hint, I am trying to prove this using the Borel-Cantelli lemma. As my family of countable sets, I'm considering $E_{q} = \{x : \exists p. |x - p/q| < 1/q^{2+\epsilon} \}$. I'm having trouble showing that the sum of the measures of $E_{q}$ converges. I can show that $E_q$ is the union of intervals of length $2/q^{2 + \epsilon}$, but I can't put a bound on the total number of intervals because the problem statement says $x \in \mathbb{R}$ so $p$ could be arbitrarily large. I found a similar problem statement in this question, but there the bound comes from the fact that $x \in [0,1]$. Am I considering the wrong family of sets for this problem, mis-interpreting the problem statement, or encountering some other issue?","['measure-theory', 'real-analysis']"
641169,Can we classify commuting pairs of matrices up to conjugacy?,"Recall that two $n\times n$ matrices over $\mathbb{C}$ are conjugate if and only if they have the same Jordan canonical form . Question. Is there a similar classification for commuting pairs of matrices? To be precise, a commuting pair of matrices is an ordered pair $(A,B)$ of $n\times n$ matrices over $\mathbb{C}$ for which $AB=BA$. Two commuting pairs $(A,B)$ and $(A',B\,')$ are conjugate if there exists a nonsingular matrix $P$ so that
$$
PAP^{-1} = A'\qquad\text{and}\qquad PBP^{-1} = B\,'.
$$
What are the equivalence classes under this relation?  Can we enumerate them?  Can we check whether two pairs are in the same class? A few notes: If $A$ and $B$ are diagonalizable, they can be simultaneously diagonalized, and the resulting pair of diagonal matrices determines the conjugacy class. According to this answer , a commuting pair of matrices cannot in general be  simultaneously Jordanized. According to this Wikipedia article , a commuting pair of matrices can be simultaneously triangularized, but of course the pair of triangular matrices is not uniquely determined. By the way, this question is equivalent to asking for a classification of indecomposable modules over $\mathbb{C}[x,y]$ with finite dimension over $\mathbb{C}$.","['modules', 'matrices', 'linear-algebra']"
641173,A domain on a sphere is simply connected if and only if its complement is connected,I think the statement that a domain (open connected set) in a sphere is simply connected if and only if its complement is connected is a standard result. But how can one prove it? Is it possible to prove this without algebraic topology?,"['general-topology', 'riemann-sphere']"
641193,Solving exercise with Leibniz rule,"I'm asked to prove that if $f(x) = \left(\displaystyle\int_0^x e^{-t^2}dt \right)^2$ and $g(x) = \displaystyle\int_0^1 \displaystyle\frac{e^{-x^2(t^2+1)}}{t^2+1}dt$ then $f'(x)+g'(x)=0$ and conclude that $f(x)+g(x)=\displaystyle\frac{\pi}{4}$. I'm having some problems proving the first equality, but here's what I tried: For $f$ I just applied the chain rule: $\displaystyle\frac{d}{dx}\left(\displaystyle\int_0^x e^{-t^2}dt \right)^2 = 2\left(\displaystyle\int_0^x e^{-t^2}dt \right)\left(\displaystyle\frac{d}{dx}\displaystyle\int_0^x e^{-t^2}dt\right) = 2\left(\displaystyle\int_0^x e^{-t^2}dt \right)\left(e^{-x^2}\right) = 2e^{-x^2}\displaystyle\int_0^x e^{-t^2}dt$. And for $g$ I used Leibniz's Rule  $\displaystyle\frac{d}{dx}\displaystyle\int_0^1 \displaystyle\frac{e^{-x^2(t^2+1)}}{t^2+1}dt = \displaystyle\int_0^1 \displaystyle\frac{\partial}{\partial x}\left(\displaystyle\frac{e^{-x^2(t^2+1)}}{t^2+1}\right)dt $
$= \displaystyle\int_0^1 \displaystyle\frac{-2x(t^2+1)e^{-x^2(t^2+1)}}{t^2+1}dt = -2x\displaystyle\int_0^1 e^{-x^2(t^2+1)}dt$. Now, how can I prove that $f'+g'=0$?. I can't add the former integrals, to do so I should have both integrals from 0 to 1, which I tried to do as follows: Considering the first integral, taking the change of variables $u=\displaystyle\frac{t}{x}$ I'll have $\displaystyle\frac{du}{dx} =-\displaystyle\frac{t}{x^2}=-\displaystyle\frac{u}{x}$ and then for the first integral I'd have considering the change of variables $2e^{-x^2}\displaystyle\int_0^x e^{-t^2} dt= 2e^{-x^2}\displaystyle\int_0^1 e^{-u^2x^2}\left(-\displaystyle\frac{u}{x}\right)du$. But the latter one it seems to me that it isn't closer at all to an integral that I could add to the second one and have zero as a result. Did I mess up with the derivatives?, or the way I'm trying to solve the problem isn't the way at all? Thanks.","['definite-integrals', 'multivariable-calculus']"
641236,Logic and set theory textbook for high school,"Do you have any advice for a textbook or a book for high schools students which completely adresses basics of logic (proposition, implication, and, or, quantifiers) and set theory (intersection, inclusion,...)? The book is for freshmen in a high school for science and maths gifted students so it can be a bit theoritical (involving some maths notation). I have no idea of which book to use so any advice is welcome :). My only thought for the moment is to write the course notes myself, and use some books of Smullyan for examples and make it more entertaining. Thank in advance.","['book-recommendation', 'reference-request', 'logic', 'elementary-set-theory']"
641244,Lebesgue measure question,"A quick question. Let $X \subset \mathbb R$ be a Lebesgue measurable set. Is it true that the set $2X = \{2 x : x \in X\}$ has measure $m(2X) = 2\ m(X)$? It is easy to prove it if for example if $X$ is an open set, but is it true in general? Thanks",['measure-theory']
641252,Equilibrium solutions of differential equations,Find the equilibrium solutions of the following differential equation: $$\dfrac{dy}{dt} = \dfrac{(t^2 - 1)(y^2 - 2)}{(y^2 -4)}$$ I'm not sure how to go about doing this since t appears explicitly on the right hand side. Would $y = \sqrt{2}$ or $-\sqrt{2}$ be solutions?,['ordinary-differential-equations']
641279,History of incenter and Euler line,"It is easy to see that if a triangle is isosceles, then its incenter lies on its Euler line. Who first proved the converse of this result and what technique was used? (See the post "" The incenter and Euler line ."")","['geometry', 'triangles', 'math-history']"
