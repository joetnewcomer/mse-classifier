question_id,title,body,tags
3831591,Why does variation of parameters work?,"I was looking at the variation of parameters method, and to be sincere, when I took my differential equations course I felt like too much of it was Hocus Pocus. For example, there is this https://tutorial.math.lamar.edu/Classes/DE/VariationofParameters.aspx I don't know where does (3) comes out from. It says: ""Now, there is no reason ahead of time to believe that this can be done. However, we will see that this will work out."" My differential equations professor didn't explain it. It wasn't outrageous so I used, simply as a recipe. I would like to have some intuition, some idea behind it. When you solve some equations in which you need to integrate from both sides, for example $$
\int f(t) dt = \int g(t) dt
$$ Then you have $F(t)+c_{1}=G(t)+c_{2}$ , but you only write $F(t)=G(t)+c$ because $c_{1}$ and $c_{2}$ don't matter, only their difference. I guess something similar is going on there, there are a lots of ways to write that with different functions and you're not interested on the $u_{1}(t)$ and the $u_{2}(t)$ but on a relationship between them, so you choose them accordingly in order to simplify the equation as the relationship will hold. But I would love to hear some idea, some intuition behind it, as each time that someone ask me for help with differential equations I want to tell them that I know nothing about them, because that's how I really feel. Thank you for your time.","['soft-question', 'ordinary-differential-equations']"
3831642,Showing that every finite $T_1$-space is discrete [duplicate],"This question already has answers here : Show that any finite $T_1$-space $X$ is discrete. (2 answers) Closed 3 years ago . Here's an exercise I'm trying to solve as I'm studying topology. Please let me know if my proof convinces you and feel free to otherwise criticise it. Proposition 1. Every finite $T_1$ -space is discrete. To be fully precise, let me fix the definitions here. Definition . A topological space $X$ is called $T_1$ iff given any two distinct points $x, y \in X$ , both have neighbourhoods that do not contain each other i.e. there exist open sets $U$ and $V$ such that $x \in U$ , $y \in V$ , $y \notin U$ , and $x \notin V$ . Definition. A space $X$ is called discrete iff all of its subsets are open. I will also assume the following lemmata. Lemma 1. A space $X$ is $T_1$ iff all of its singleton subsets are closed. Lemma 2. Finite unions of closed sets are closed. Proof attempt for Prop. 1 . Let $X$ be a finite $T_1$ -space and let $U \subseteq X$ be an arbitrary subset. We need to show that $U$ is open i.e. that the complement of $U$ (which we denote $U^c$ ) is closed. As $X$ is finite, $U^c$ must have finitely many elements and must therefore be the union of finitely many singleton sets. By Lemma 1 , we know that each of these singleton sets are closed as $X$ is a $T_1$ -space. By the closure of closed sets under finite unions ( Lemma 2 ), $U^c$ must be closed.","['general-topology', 'solution-verification']"
3831720,"Are these permutation groups, defined by asymptotic properties, isomorphic?","For a permutation $\sigma : \mathbb{N} \to \mathbb{N}$ , let $c_{\sigma}(n) = |\{k \in [n] \mid \sigma(k) \ne k\}|$ , and for a function $f : \mathbb{N} \to \mathbb{R}$ , let $G_f = \{\sigma \in S_{\mathbb{N}} \mid \lim_{n \to \infty} c_\sigma(n)/f(n) = 0 \}.$ For example, if $f(n) = n$ , then $G_f$ is just the permutations of $\mathbb{N}$ that fix almost everything, and if $f(n) = n^2$ (or something else that grows much faster than $n$ ) then $G_f$ is just all permutations of $\mathbb{N}$ . My question is are the groups $\{ G_{x^r} \mid r \in (0,1]\}$ all isomorphic? Isomorphic to all permutations of $\mathbb{N}$ ? I'm able to see that they mutually contain each other, but that isn't enough to resolve this. Have people studied groups that are defined in such ways? This question is inspired by Is there a natural family of nonisomorphic groups parametrized by $\mathbb{R}$? , as showing my groups aren't isomorphic would resolve that question nicely. If my groups are isomorphic, I'm also curious if there are computably isomorphic in the sense that given a list of what my input permutation does I can access sequentially, I can begin to compute what the permutation it maps to does. edit: Ycor's answer below shows that if they are isomorphic, they are conjugate, but I'm still very curious about the outcome: as mentioned in that answer, being conjugate would require a permutation with pretty surprising properties, and ruling out the existence of such a thing (or showing there is one!) seems a worthy problem in its own right. Note (as mentioned in a comment) Ycor's partial result rules out any of these groups being isomorphic to all permutations of $\mathbb{N}$","['permutations', 'group-theory', 'abstract-algebra', 'group-isomorphism']"
3831753,An elementary proof of $\sum_{l=0}^{n-1} \cos(\frac{2\pi kl}{n})^2=\frac{n}{2}$? (without character theory),"Recently I have stumbled upon the following identity: if $n>2$ and $1\leq k\leq\lfloor\frac{n-1}{2}\rfloor$ , then $\sum_{l=0}^{n-1}\cos(\frac{2\pi kl}{n})^2=\frac{n}{2}$ . There is a lovely proof of this using character theory: let $D_{2n}$ be the dihedral group $\langle r, s\space|\space r^n=1, s^2=1, rs=sr^{-1}\rangle$ . We define the complex representation $\rho_k:D_{2n}\rightarrow\text{GL}_2(\mathbb{C})$ by $s\mapsto\begin{bmatrix}0&1\\1&0\end{bmatrix}$ and $r\mapsto\begin{bmatrix}\cos(\frac{2\pi k}{n})&\sin(\frac{2\pi k}{n})\\-\sin(\frac{2\pi k}{n})&\cos(\frac{2\pi k}{n})\end{bmatrix}$ . Clearly $\rho_k$ is irreducible; indeed, given $(z_1, z_2)^{tr}\in\mathbb{C}^2\setminus\{(0,0)^{tr}\}$ , because $0<\frac{2\pi k}{n}<\pi$ we have that $\rho_k(r) (z_1, z_2)^{tr}$ and $(z_1, z_2)^{tr}$ are linearly independent, and hence together form a basis for $\mathbb{C}^2$ . Now, let $\langle\cdot|\cdot\rangle$ be the canonical inner product on the vector space of class functions on $D_{2n}$ , so that if $\chi_1,\chi_2:D_{2n}\rightarrow\mathbb{C}$ are class functions then $\langle\chi_1|\chi_2\rangle=\frac{1}{|G|}\sum_{g\in D_{2n}}\chi_1(g^{-1})\chi_2(g)$ . Recall that the irreducible characters of $D_{2n}$ form an orthonormal basis for the space of class functions, and so in particular we must have $\langle\chi_{\rho_k}|\chi_{\rho_k}\rangle=1$ . The elements of $D_{2n}$ are of course all of the form $r^l$ and $sr^l$ , $0\leq l\leq n-1$ . We have $\rho_k(r^l)=\begin{bmatrix}\cos(\frac{2\pi kl}{n})&\sin(\frac{2\pi kl}{n})\\-\sin(\frac{2\pi kl}{n})&\cos(\frac{2\pi kl}{n})\end{bmatrix}$ , so $\chi_{\rho_k}(r^l)=2\cos(\frac{2\pi kl}{n})$ , and likewise $\rho_k(sr^l)=\begin{bmatrix}\sin(\frac{2\pi kl}{n})&\cos(\frac{2\pi kl}{n})\\\cos(\frac{2\pi kl}{n})&-\sin(\frac{2\pi kl}{n})\end{bmatrix}$ , so $\chi_{\rho_k}(sr^l)=0$ . Because $\cos$ is even we additionally have $\chi_{\rho_k}(r^l)=\chi_{\rho_k}(r^{-l})$ . Combining these facts gives $1=\langle\chi_{\rho_k}|\chi_{\rho_k}\rangle=\frac{1}{|G|}\sum_{g\in D_{2n}}\chi_{\rho_k}(g^{-1})\chi_{\rho_k}(g)=\frac{1}{2n}\sum_{l=0}^{n-1}(2\cos(\frac{2\pi kl}{n}))^2$ , whence we obtain the desired equality. This is in my view quite a nice application of representation theory to an identity not immediately obviously related to it. However, I am wondering whether this is in fact the simplest proof. Can anyone find a more elementary way of deducing of this identity?","['trigonometry', 'representation-theory', 'characters', 'modules']"
3831760,Solving a first order ODE with absolute value,"In my class on differential equations, I have encountered the following initial value problem \begin{gather}
	y' = 1 + |y-1| \\
	y(0) = 0
\end{gather} I cannot solve this. The ODE is first order, but the absolute value confuses me as I cannot integrate or do anything like that with it, the equation is nonlinear and has me stuck. How would one find the solution to this? I know existence and uniqueness applies even though the absolute value is not smooth, but because it is Lipschitz continuous I know a smooth solution must exist which I cannot seem to find. Can anyone show me how to solve this? I thank all helpers.","['integration', 'absolute-value', 'ordinary-differential-equations', 'initial-value-problems', 'derivatives']"
3831772,How do we justify functions on the Ordinals,"In ZFC there seem to be two ways to define a function, as an ordered triple of domain, codomain and the set of ordered pairs that make its graph, or a relation over the two sets. Whichever we use doesn't matter, but this seems to present a certain problem. Both are defined over sets, but no-one seems to have any problem defining functions on the ordinals like Hartog's function giving the minimum ordinal that doesn't have an injective function on to the given ordinal. I know we want to be able to obviously, but how are we supposed to justify this, because the definitions of functions don't seem to include classes. Or is there a nicer definition I've missed?","['ordinals', 'functions', 'set-theory']"
3831823,Is the law of unconscious statistician always true?,"Let $X$ be a discrete random variable, and $f(x)$ its pmf. Assume that $g(X)$ is a random variable. Then the law of unconscious statistician says $$E[g(X)]=\sum_xg(x)f(x).$$ Should I interpret this as follows? $E[g(X)]$ exists if and only if the sum on the right exists, and in this case they are equal. By the ""sum,"" I don't mean the limit of partial sums, but the difference of positive and negative parts like in Lebesgue integral: $$\sum_xg(x)f(x)=\sum_{g(x)>0}g(x)f(x)+\sum_{g(x)<0}g(x)f(x)$$","['expected-value', 'probability-theory', 'random-variables']"
3831846,Lattice-theoretic complement of the Euclidean topology,"It is known that the class of topologies $Top(X)$ of a given set $X$ is a bounded complete lattice (least element is the indiscrete topology and greatest element is the discrete topology, whilst the meet of any family of topologies is the intersection of such family). In the case $X=\mathbb R$ , what can be said about lattice-theoretic complements of the Euclidean topology? Do they even exist? Can one of them be constructed?","['general-topology', 'lattice-orders']"
3831862,Exploring a Sangaku problem: proving a dilated circle is circumcircle,"$$\Delta ABC \text{ is an equilateral triangle with } D \text{ being the midpoint of } BC \text{. } \Delta DEF \text{ is also an } \\ \text{equilateral triangle such that } E, F \text{ are on minor arc } BC \text{ of the circumcircle of } \Delta ABC \text{ with } \\ DE \parallel AB \text{ & } DF \parallel AC \text{. } \Delta BDG \text{ is equilateral } \text{such that } E \text{ lies on } DG\text{. } \text{ Let } H \text{ be the point on the } \\ \text{circumcircle of } \Delta DEF \text{ such that } HF \text{ is the diameter} \text{. Prove that } H \text{ is the circumcenter of } \Delta BGF.$$ The original Sangaku problem is to find the ratio of the sides of triangles ABC and DEF. It is not hard. I already have one  using Pythagoras etc essentially summarized here (pastebin image) . The ratio is curiously twice the golden ratio. I got stuck with this configuration looking for some novel solutions making that coincidence more obvious EDIT So here's more context. I wish to arrive at the golden ratio bit via this, not prove that first and then this result as a corollary. How?
So if we prove this, $$\text{ Now we know that } G \text{ lies on a 2x dilation } \text{ of the circumcircle of } \Delta DEF \text{ with dilation center } F \text{. }\\
\therefore FG \text{ meets the circumcircle of } \Delta DEF \text{ at } G' \text{ which bisects } FG \text{. Denote midpoint of } EF \text{ by } E'\text{. }\\
\text{We have by midpoint theorem, } E'G' \parallel EG \text{ and } EG = 2E'G'. \text{ If we call the process of going }\\
\text{ from } \Delta ABC \text{ to } \Delta DEF \textit{ shrinking,} \text{ then } G' \text{ is the vertex of the triangle on }\textit{shrinking }\Delta DEF.\\
\text{If we denote length of the edge of this twice }\textit{shrunken}\text{ triangle i.e. } \overline{E'G'} \text{ by } x \text{ and reciprocal}\\
\text{factor of }\textit{shrinking}\text{ by } 2\cdot \phi > 1\text{, then we have:}\\
\overline{EG}=2\cdot\overline{E'G'} = 2x\text{, }\quad \overline{DE} = x\cdot 2\phi\text{, }\quad \overline{DG} = \frac{\overline{BC}}{2} = \frac{x\cdot 4\phi^2}{2} = x\cdot 2\phi^2\\
\overline{DG} = \overline{DE} + \overline{EG} \implies \phi^2 = \phi + 1$$ Thus the ratio was twice the golden ratio","['contest-math', 'homothety', 'geometry', 'sangaku']"
3831874,Vocabulary: Functions whose values would not change if the variables were interchanged,"Consider the function $$f(x,y,z):= \sqrt{1+x^2+y^2+z^2}.$$ Then $f(x,y,z) = f(x,z,y) = \cdots = f(z,y,x)$ Do functions such as $f,$ whose values would not change for any possible permutation of the variables, have a specific name? I only care because it seems convenient to be able to refer to these functions by a name.","['algebra-precalculus', 'functions', 'terminology']"
3831931,Natural Deduction Proof With Quantifiers,"Here is a natural deduction proof where my answers are in the red. I have questions on the following lines: Line 8: Could we introduce an $\lor$ operator here? We have $\exists xQ(x)$ so with $\lor$ introduction we can say have it or anything right, because it is already true? Line 12 and 13: We eliminate $\exists x (P(x) \rightarrow Q(x))$ on line 1 because there is more than one element in this statement. And we introduce $\exists$ on 13 because we proved that there is only one element that satisfies this. Anything else in the red look incorrect? Does the above sound correct? I am struggling with the $\exists$ part of this kind of proofs.","['predicate-logic', 'logic', 'solution-verification', 'discrete-mathematics', 'natural-deduction']"
3831949,Prove that $n$ is a power of 2 in the following sets of sums,"Let $\{a_1,...,a_n\}$ and $\{b_1,...,b_n\}$ be two distinct sets of positive integers such that the sets of sums $\{a_i+a_j | 1 \leq i < j \leq n \}$ and $\{b_i+b_j | 1 \leq i < j \leq n \}$ are the same, with the same number of repetitions, eventually. Prove that $n$ is a power of $2$ . This problem came from the polynomials unit in a summer course for the IMO. I've been looking around but haven't been able to find any insights. I tried to force polynomials such as $P(x) = (x-a_2)...(x-a_n)$ , hoping to find anything that would be helpful but had no luck with these attempts. Looking at it again, I would think that the part of the question talking about repetitions would relate to the multiplicities of a polynomial. But then I hit a wall and don't know what to do with that information.","['contest-math', 'combinatorics']"
3832001,How to determine the nature of two functions from their composite function?,"The following question was asked in an examination: Let $f$ and $g$ be two functions with domain and codomain equal to the set of real numbers. If, $$g\circ f(x) =
\begin{cases}
x^2,  & \text{if $x\geq0$} \\
e^x-1, & \text{if $x<0$}
\end{cases}
$$ Then choose the correct option out of the following: (a) $f$ is one-one (b) $f$ is onto (c) $g$ is one-one (d) $g$ is onto Here, we have been asked to find whether the functions $f$ and $g$ are injective or surjective from their composite function $g\circ f$ . Since, I didn't find any way out, I assumed $f(x)=x$ and $g(x)=x^2$ when $x\geq0$ and $g(x)=e^x-1$ when $x<0$ . This assumption also satisfies the condition given in the question. Clearly, $f$ is both one-one and onto. On constructing the graph of $g$ it can be seen that it's one-one but not onto. Based on this, options (a), (b) as well as (c) are correct. But the question clearly states only one of the options is correct. So, it would be helpful if someone could explain the reason for the fallacy of my argument. Also, in general, how can we determine the nature of two functions from their composite function? The only way I could think of is to decompose the composite function into component functions. But I don't think it's a good approach as it can lead to more than one set of functions.","['algebra-precalculus', 'functions', 'function-and-relation-composition']"
3832009,Existence of multivariable function whos limit exists agrees for all paths that are functions but fails otherwise.,"Consider $\lim_{(x, y) \to (a, b)} f(x, y)$ . We know the limit for this function exists if for all paths, $\lim_{(x, y) \to (a, b)} f(x, y) = L$ . In addition, if we want to show that $\lim_{(x, y) \to (a, b)} f(x, y)$ does not exist, we can take $y=g(x)$ and y= $m(x)$ s.t. $\lim_{(x, y) \to (a, b)} f(x, g(x)) = T$ and $\lim_{(x, y) \to (a, b)} f(x, m(x)) = S$ with $S \neq T$ to conclude that the limit does not exist. My questions is if for all functions $y=g(x)$ , the limit $\lim_{(x, y) \to (a, b)} f(x, g(x)) = L$ agrees and is equal to $L$ , does that allow us to conclude that $\lim_{(x, y) \to (a, b)} f(x, y) = L$ ? I would imagine that it is not enough since some paths do not need to be functions, but I can't imagine a pathological counter example that could have its limit agree for every well defined function but fail otherwise.","['limits', 'multivariable-calculus']"
3832017,"How many positive integer solutions exist for $[\frac{x}{19}]=[\frac{x}{20}]$, where $[x]$ denotes the Greatest integer function","Question How many positive integer solutions exist for $[\frac{x}{19}]=[\frac{x}{20}]$ , where $[x]$ denotes the Greatest integer function What I tried I took the following cases one by one, CASE $1$ $$[\frac{x}{19}]=[\frac{x}{20}]=1$$ All numbers from $20$ till $37$ should work for this, thus a total of 18 solution in this case. CASE $2$ $$[\frac{x}{19}]=[\frac{x}{20}]=2$$ All numbers from $40$ to $56$ should work for this, thus a total of $17$ solutions in this case. Upon continuing this process, we reach the case where there is only one possible solution. Thus the number of cases is $18+17+16+...+2+1$ which is equal to $171$ There is also the case of $$[\frac{x}{19}]=[\frac{x}{20}]=0$$ This case will have $18$ solutions, from $1$ till $18$ .
Thus the total number of solutions is $171+18$ which is $189$ I am not sure if my answer is correct (maybe I am missing a few cases). What I am looking for is a verfication of my method and answer, and maybe a more concrete solution which will work in cases where $[\frac{x}{m}]=[\frac{x}{n}]$ where m and n are not consecutive natural numbers. Thank you so much in advance! Regards","['algebra-precalculus', 'ceiling-and-floor-functions']"
3832052,"Why does $\min(X,Y)$ and $|X-Y|$ have the same distribution when $X,Y\sim U(0,1)$?","Say $X,Y \sim U(0,1)$ be two independent uniform random variables, and $T=|X-Y|$ . I would like to find the CDF of $M=\max(X,Y)$ , $L=\min(X,Y)$ , and $T$ . I find the CDF of $M$ and $L$ as $$P(M\leq t ) = P(X\leq t)P(Y \leq t) =t^2$$ $$P(L \leq t) = 1-P(X\geq t ) P(Y\geq t) = 1-(1-t)^2$$ To find the CDF of $T$ , I draw a rectangle with unit length and width, and compute the area within the region $|X-Y| \leq t$ , which turns out to be $1-(1-t)^2$ . My question is how come the CDF of $L$ and $T$ are the same when one is the minimum of two uniform r.vs and the other is the absolute difference of two uniform r.vs? Is there something wrong with my computation?
Thanks.","['probability-distributions', 'uniform-distribution', 'probability']"
3832055,Show whether composition is identity mapping,"Let $F:\mathbb{N} \rightarrow \mathbb{N}$ be the mapping defined by $F(n)=n+1$ for all $n \in \mathbb{N}=\{0,1,2,3, . . .\}$ and let $I:\mathbb{N}\rightarrow \mathbb{N}$ be the
identity mapping defined by $I(n) =n$ for all $n \in \mathbb{N}$ . (a) Show that there does not exist any mapping $G:\mathbb{N} \rightarrow \mathbb{N}$ which satisfies $F\circ G=I$ . (b) Construct one example (or several examples) of mapping $H:\mathbb{N} \rightarrow \mathbb{N}$ which satisfies $H\circ F=I$ For (a), is it correct that there will be no mapping $G$ that satisfies the requirement because if I let $n=0$ , we cannot map $0$ to $-1$ ? And for (b), can I say that $H(n)= n-1$ is one of the examples?","['proof-writing', 'functions', 'solution-verification', 'discrete-mathematics', 'elementary-set-theory']"
3832097,"Interesting change of variable for a ""simple"" ODE","I'm working on a dynamical system governed by the following ODE in $\mathbb{R}^n$ : $$ \dot{x}(t) = f(A(t)x(t)+b). $$ Here $t\rightarrow A(t)\in\mathbb{R}^{n\times n}$ is a smooth (enough) matrix valued function and $b\in\mathbb{R}^n$ and $f:\mathbb{R}^n\rightarrow\mathbb{R}^n$ is smooth (enough) too. So in general the dynamics is just given by the composition between a non-linear transformation and an affine one. My question is if there is some famous/interesting change of variable which allows to rewrite this system in some useful way, i.e. to Hamiltonian system or gradient vector field or something more manageable. You can even tell me that something is a good choice when $A$ satisfies some particular property, it would still be very helpful. I see it is a quite general question and I am not saying what are my aims but, at the moment, I just want to see if in this setting there is some ""standard"" way to proceed. The easiest transformation, i.e. $z(t)=A(t)x(t)+b$ , does not seem to bring anywhere: $$ \dot{z}(t) = \dot{A}(t)A^{-1}(t)(z(t)-b)+A(t)f(z(t)),$$ assuming the invertibility of $A$ .","['change-of-variable', 'linear-algebra', 'ordinary-differential-equations', 'dynamical-systems']"
3832109,Intuition behind Non-Trivial Tangent Bundle,"I am fairly new to the notion of tangent bundle and vector bundles in general , and as a first glance intuitively I though that well for any manifold $M$ we would have that $TM\cong M\times \mathbb{R}^m$ . As I looked more into the matter I found cases were this is not true however I can't have a good intuition behind the fact as to why this is not true . I would appreciate if someone could enlighten me on what can fail so that we dot not have that diffeomorphism without using very heavy machinery . I am just trying to understand the idea behind why this cannot be true in general .I guess the problem is that we only know that locally the tangent space at a point is the same as $\mathbb{R}^m$ and the problem would to do this globally but I am having trouble seeing where it fails. Thanks in advance.","['tangent-bundle', 'differential-geometry']"
3832111,"Show $\mathbb{Q}( \sqrt{5},\sqrt{7} ) = \mathbb{Q}( \sqrt{5} + \sqrt{7} )$","The problem : find the minimal polynomial of $\sqrt{5} + \sqrt{7}$ what is the degree of $ [ \mathbb{Q}( \sqrt{5},\sqrt{7} ) : \mathbb{Q} ] $ conclude $\mathbb{Q}( \sqrt{5},\sqrt{7} ) = \mathbb{Q}( \sqrt{5} + \sqrt{7} )$ My question and my works I found 1., I found that the minimal polynomial of $\sqrt{5} + \sqrt{7}$ is $P : X \mapsto X^4 - 24X^2 + 4 $ I know that $\deg P = [ \mathbb{Q}( \sqrt{5} + \sqrt{7} ): \mathbb{Q} ]$ where $P$ is the min. polynomial of $\sqrt{5} + \sqrt{7}$ over $\mathbb{Q}$ . But, how can i calculate $ [ \mathbb{Q}( \sqrt{5},\sqrt{7} ) : \mathbb{Q} ] $ with 1. ? I found 3., by showing each inclusion, without using 2... Thanks you","['field-theory', 'minimal-polynomials', 'abstract-algebra', 'extension-field']"
3832119,Prove that the Distribution of Marginal Vectors are also multivariate normal,"I'm told that $\mathbf{\Sigma}$ is a positive definite matrix and also that it's the variance of $\mathbf{X}$ where $\mathbf{X}=\bf{\mu}+BZ$ such that $\mathbf{\mu},\mathbf{Z}\in\mathbb{R}^n$ and $Z_1,\dots,Z_n\sim_{\mathrm{iid}}\mathcal{N}(0,1)$ . In addition, I'm to partition the matrix $\bf\Sigma$ in the following way: $$ \bf \Sigma= \begin{pmatrix} \bf \Sigma_p & \bf \Sigma_r \\ \bf \Sigma_r^{\top} & \bf \Sigma_q    \end{pmatrix}. $$ So the question is to prove that the marginal vectors $\mathbf{X}_p$ and $\mathbf{X}_q$ are also multivariate normal, with $ \mathbf{X}_p\sim\mathcal{N}(\mu_p,\mathbf{\Sigma}_p)$ and $ \mathbf{X}_q\sim\mathcal{N}(\mu_q,\mathbf{\Sigma}_q)$ . I've tried to simply rewrite the expression for $\bf X$ in terms of the marginal vectors and use matrix multiplication to equate components but it seems to be a dead end because I can't simplify anything down or at least I dont know how to simplify everything. In addition I've tried showing that the MGF of the marginal vectors will have be the one for the multivariate gaussian but my working unfortunately seems to not go anywhere. Any help would be appreciated, thank you.","['statistics', 'probability-distributions', 'normal-distribution']"
3832143,Find the sum of infinite series $\cos{\frac{\pi}{3}}+\frac{\cos{\frac{2\pi}{3}}}{2}+..$,"Find the sum of infinite series $$\cos{\dfrac{\pi}{3}}+\dfrac{\cos{\dfrac{2\pi}{3}}}{2}+\dfrac{\cos{\dfrac{3\pi}{3}}}{3}+\dfrac{\cos{\dfrac{4\pi}{3}}}{4}+\dots$$ I tried to convert it to $\mathrm{cis}$ form, and tried to convert to to integration of something, but nothing proved to be helpful, any hint?","['summation', 'trigonometry', 'sequences-and-series', 'algebra-precalculus', 'complex-numbers']"
3832210,"Does there exist a natural number pair $(a,b)$ such that $a^2b+a+5$ divide $ab^2+a+b$?","I tried that if I can show $\gcd(a^2b+a+5,ab^2+a+b) = 1$ , then there is no solution. Am I true? Any hints /idea?
I can't factorize them out such that each is multiple of each other.",['number-theory']
3832244,Angles enclosed in parallel lines,"I am not sure of the best way to answer this question. We have to find $a + b + c$ . I have got the answer of $210$ by drawing in parallel lines to split the angles $a$ , $90$ , $b$ and $60$ , but then that is quite demanding for younger students. So I was wondering if there was a quicker solution?","['contest-math', 'euclidean-geometry', 'angle', 'geometry']"
3832284,Show that the limit of $u_{n+d} = \frac{u_n + \cdots + u_{n+d-1}}{d}$ is $\frac{2}{d(d+1)}(u_0 + 2u_1 +\dots + du_{d-1})$,"Let $u_0,\ldots,u_{d-1} \in \Bbb R$ . We define $(u_n)$ by the recursive relation: $$
u_{n+d} = \frac{u_n + \cdots + u_{n+d-1}}{d}
$$ Show that $$\lim_{n\to +\infty} u_n = \frac{2}{d(d+1)}(u_0 + 2u_1 + \cdots + du_{d-1})$$ I solved it for $d=2$ by looking at $u_{n+2}-u_{n+1}$ but I think the generalization is trickier.
I don't really know where to start. Edit: I read the solution proposed by the first comment. But I'm looking for another type of solution. I found this question in an exam for students that ask as a preliminary question to prove Gauss-Lucas theorem. I really wonder where is the link between both questions? Edit 2: Edit 3: Since: $$
|u_{n+d}| \leq \frac{|u_n| + \cdots + |u_{n+d-1}|}{d} \leq \max\{|u_n|;\cdots |u_{n+d-1}|\}
$$ it is easy to show by recurrence that $\forall n, |u_n|\leq \max \{|u_0|;\cdots |u_{d-1}|\}$ . Thus, $u_n$ is bounded. However, if $P$ denotes the characteristic polynomial, $d \times P = d X^d - X^{d-1} - ... - 1$ .
And $P(z) = 0 \implies |z|^d \leq (1/d) (|z|^0 + ... + |z|^{d-1}$ . Thus, we easily get that $|z|\leq 1$ and $|z| = 1 \iff z = 1$ (since $-1$ cannot be a root). Thus, if $u_n = \sum_{\lambda ; P(\lambda)=0} \alpha_{\lambda,n}\lambda^n$ is the solution of the reccurence, as $n\to \infty$ , $u_n \sim \alpha_{1,n}$ . But $\alpha_{1,n}$ is polynomial in $n$ and $u_n$ is bounded. Thus $\alpha_{1,n}$ is a constant and is the limit.","['limits', 'sequences-and-series', 'real-analysis']"
3832322,The shortest curve that divides the unit sphere into two regions of equal area,"How to prove that if a simple closed curve $\gamma$ divides the unit sphere into two regions of same
area, then its length is not smaller than $2\pi$ . The hint is to consider a reflection of the sphere,
then to show that must intersection with its reflection. But I don't know what to do.","['curves', 'differential-geometry']"
3832354,How to use the chain rule (multivariable) to find an expression for the second derivative,"More specifically, I’m thinking about how to find a nice expression for $\frac{\partial^2 f}{\partial x^2}$ where we have an $f$ of the form $f(r(x,y), \varphi(x,y))$ . If anyone could help me with this it would be greatly appreciated.","['partial-derivative', 'multivariable-calculus', 'chain-rule']"
3832371,Trying to understand a set inclusion,"I got stuck while reading a proof from Michael Field's Essential Real Analysis . Here is the difficult part of his text: ""Choose $\varepsilon>0$ . Since $(X_n)$ is Cauchy, there exists $N_1\in\mathbb{N}$ such that $h(X_n,X_m)<\varepsilon$ , for all $n,m\geq N_1$ . Since $X_m\subset X_n(\varepsilon)$ , for all $n,m\geq N_1$ and $\Lambda=\bigcap_{n\geq p}\overline{\bigcup_{m\geq n}X_m}$ , all $p\geq 1$ , we certainly have $\Lambda\subset X_n(\varepsilon)$ , $n\geq N_1$ ."" What I don't get is how ""... we certainly have $\Lambda\subset X_n(\varepsilon)$ , $n\geq N_1$ ."" $h(X_n,X_m)<\varepsilon\Rightarrow X_m\subset X_n(\varepsilon)$ follows from a lemma and $\Lambda$ is defined earlier as $\Lambda=\bigcap_{n\geq 1}\overline{\bigcup_{m\geq n}X_m}$ . I can't catch what Field means with switching "" $1$ "" to "" $p$ "" and with ""all $p\geq 1$ "". $h$ is a metric so $h(X_n,X_m)=h(X_m,X_n)$ and $X_n\subset X_m(\varepsilon)$ also. The sets $X_n$ that constitute the sequence $(X_n)$ are compact subsets of $\mathbb{R}^n$ , thus they are closed and bounded. $X_n(\varepsilon)$ is an open neighbourhood of $X_n$ . That means all the points within $\varepsilon$ of $X_n$ . I've tried to figure this out for the whole day and I'd appreciate help a lot.
EDIT: I added a few points to make the question clearer.","['elementary-set-theory', 'proof-explanation', 'cauchy-sequences', 'real-analysis']"
3832383,Show a set must be measurable,"Below is a problem I found, however, after many attemps I can not seem to get a solution. Problem: Let $E \subset [0,1]$ . Show that if $m^*(E) + m^*([0,1] \setminus E) = 1$ , then $E$ is measurable. (my attempted) Solution: Notice, the following is true $[0,1] \setminus E = [0,1] \cap E^c$ . Therefore, we can rewrite the given equations as $$m^*(E) + m^*([0,1] \cap E^c) = 1. \quad (i)$$ Also, notice that $E = [0,1] \cap E$ , hence, we can rewrite $(i)$ as the following $$m^*([0,1] \cap E) + m^*([0,1] \cap E^c) = 1. \quad (ii)$$ Since $m^*([0,1]) = 1$ we can, again, rewrite $(ii)$ as follows $$m^*([0,1] \cap E) + m^*([0,1] \cap E^c) = m^*([0,1]). \quad (iii)$$ For this path, this is where I get stuck. In other words, obviously if $[0,1]$ could be replaced by any set $A \subseteq \mathbb{R}$ then, sure, $E$ is measurable. Therefore, I do not think this is the ""correct path"" to take. I feel like one way is, possibly, to show that for any $\epsilon > 0$ , there exists a closed set F, such that, $E \subseteq F$ and $m^*(F \setminus E) < \epsilon$ . Taking $F = [0,1]$ , we have $E \subset F$ and $m^*(F \setminus E) < 1 - m^*(E)$ . Hence, if I take $\epsilon = 1 - m^*(E)$ can I conclude the proof?","['measure-theory', 'lebesgue-measure', 'real-analysis']"
3832421,Partial derivatives of a complex function?,"In real algebra, if I have a differentiable function $f:\mathbb{R}^2 \rightarrow \mathbb{R}^2$ , say $f(x,y)=[u,v]$ , I can calculate four different partial derivatives $\frac{\partial u}{\partial x},\frac{\partial u}{\partial y},\frac{\partial v}{\partial x},\frac{\partial v}{\partial y}$ . If I interpret $x$ and $y$ as spatial coordinates, I could  - for example - create two separate quiver plots : one illustrating the partial derivatives of $u$ and one illustrating the partial derivatives of $v$ . In complex algebra, it seems like we should encounter a similar behaviour: Assume that I have $z=x+iy$ and $w=u+iv$ , and that my function $f:\mathbb{C}\rightarrow \mathbb{C}$ is (say) a Mobius transformation $$M(z)=\frac{az+b}{cz+d}$$ whose derivative is: $$\frac{\partial w}{\partial z}=\frac{\partial M(z)}{\partial z}=\frac{ad-bc}{(cz+d)^2}$$ Now here is my question: The derivative I obtain will be a single complex number. Is it possible to extract the partial derivatives $\frac{\partial u}{\partial x},\frac{\partial u}{\partial y},\frac{\partial v}{\partial x},\frac{\partial v}{\partial y}$ ? If yes, how would I go about this?","['complex-analysis', 'derivatives', 'partial-derivative', 'mobius-transformation']"
3832426,Automorphism group of finite $k$-algebra as an affine variety,"Let $k$ be an algebraically closed field. Let $A$ be a finite dimensional $k$ -algebra, not necessarily commutative. Let $G = \text{Aut}(A)$ be the group of $k$ -algebra automorphisms of $A$ . I want to show that $G$ can be an affine variety in a suitable space $k^n$ .","['algebraic-geometry', 'commutative-algebra']"
3832444,Giving the range in the natural numbers,"When I have three variables $x$ , $y$ , and $z$ and I know that all three are natural numbers that are bigger or equal to $3$ , can I write that like this?: $$x\space\wedge\space y\space\wedge\space z\in\mathbb{N}_3$$ It has to be $x\in\mathbb{N}_3\space\wedge\space y\in\mathbb{N}_3\space\wedge\space z\in\mathbb{N}_3$ . It is for a poster, so I want to write it symbolically instead of in words. How can I write it symbolically?","['notation', 'number-theory', 'natural-numbers']"
3832450,Integer valued functions satisfying the functional equation $f(2x+1)=f(x)+1$,"We are trying to find all functions $f:\mathbb{R}\setminus\{-1\}\to \mathbb{Z}$ satisfying the functional equation $$f(2x+1)=f(x)+1\text.$$ Note. It is easy to check that every function $f(x)$ of the form $\left\lfloor T_1\left(\frac{\ln|x+1|}{\ln 2}\right)+\frac{\ln|x+1|}{\ln 2}\right\rfloor$ , where $T_1$ is $1$ -periodic, is a solution. Also, we can find an integer constant such that $f(1)=1+c$ , $f(3)=2+c$ , $f(7)=3+c$ , $\dots$ (analogously for $f(-3)$ , $f(-5)$ , $f(-9)$ , $\dots$ ). Any idea?","['functional-equations', 'calculus', 'functions']"
3832479,Restrictions on laws,"I'm wondering about the restrictions, my doubt is for example at $\log_a(b)=c\implies a^c=b$ , how would anyone add the restrictions for this? I know the argument and the base of a log have to be >0 excluding 1, hence $a,b\in (0,+\infty)\setminus \{1\}$ but wouldn't that mean that $1^1=b$ is not valid? while it is obviously valid for b=1? I don't know i'm just confused, hopefully someone shines a light on everything, and if it's not much to ask, please tell me how to express restrictions on such complex situations? Another example would be $x^y=0$ the restrictions in my head would be $x,y>0$ because we want to avoid cases like $0^0$ or $0^{-2}$ BUT, according to what i wrote x can't be 0, but for example when x=0, $0^y=0$ is true for y>0, but WE SAID that x couldn't be 0! So i'm just in general confused by all this, hopefully the 2 examples i gave, helps to visualise the confusion i'm having better.","['indeterminate-forms', 'exponentiation', 'algebra-precalculus', 'logarithms']"
3832496,Best method for proving that $7\times11^{2n+1}-3^{4n-1}$ is divisible by $10$,"I am asked to prove by induction that $7\times11^{2n+1}-3^{4n-1}$ is divisible by $10$ . I wonder whether there is a more direct method, for example factorizing by $10$ .
If an expression is divisible by $10$ , does this mean that I can factorize it by $10$ ? Thanks in advance","['elementary-number-theory', 'divisibility', 'sequences-and-series']"
3832522,"Are $3^6-6^3$ and $4^8-8^4$ the only sums of four $a^b-b^a,1\lt a\lt b$ numbers?","Question How many numbers of form $a_0^{b_0}-b_0^{a_0}$ are a ""nontrivial"" sum of four such numbers $a_i^{b_i}-b_i^{a_i}$ ? The ""nontrivial"" means: all unordered pairs $\{a_i,b_i\}$ are distinct, $a_i^{b_i}\ne b_i^{a_i}$ and $1 \lt a_i\lt b_i$ . This implies that such summands are positive ( are in OEIS A045575 ), except $2^3-3^2 = -1$ . The only ""nontrivial"" examples I could find are: $$\begin{align}
(2^5-5^2) + (2^6-6^2) + (2^7-7^2) + (4^5-5^4) &= (3^6-6^3)  \\
(2^8-8^2)+ (4^5-5^4) + (4^6-6^4) + (3^{10}-10^3)  &= (4^8-8^4)
\end{align}$$ Are these two the only such numbers? For comparison, I suspect such sums with less than four summands do not exist, and that there are infinitely many such sums with more than four summands. With four summands exactly, I have only these two examples, hence this question. Are there any other references ( than ones listed in OEIS A045575 ) on problems related to $x^y-y^x$ numbers? Background These two numbers correspond to the following two Base-Exponent Invariant numbers: $$\begin{array}{}
1464 &=& 2^5 + 2^6 + 2^7 + 4^5 + 6^3 &=& 5^2 + 6^2 + 7^2 + 5^4 + 3^6 \\
68521 &=& 2^8 + 4^5 + 4^6 + 3^{10} + 8^4 &=& 8^2 + 5^4 + 6^4 + 10^3 + 4^8
\end{array}$$ That is, these numbers are a special case of the ""Base-Exponent Invariant"" numbers. I call these ""Order- $5$ Genus- $1$ "" Base-Exponent Invariant numbers $1464,68521\in G^{(5)}_1$ . In general, I have found only $14$ examples ( see ""short examples"" in this answer ) of ""Order- $5$ Base-Exponent Invariant numbers"". The largest known example is around $6\cdot 10^6$ , while the next one, if it exists, is larger than $10^{16}$ . General near examples I've searched for smallest ""error"" $e(n)$ such that ""some elements plus the error"" are a sum of the ""other elements"" from the ""best"" 5-subset of A045575 among ""nontrivial"" 5-subsets whose largest element is the $n$ th nonzero term of A045575 . If $e(n)=0$ (and $n\ge 5$ ) then we have general examples(s) and $(n,0)$ is colored blue (or green if corresponding example is also ""Genus- $1$ ""). If $e(n)=\pm 1$ we have a ""near example"" (colored red ). Else, we have a black point $(n,\log e(n))$ . For $n$ up to $100$ , we have the log plot of errors: Notice that for $n\gt 43$ , we have no general examples, and for $n\gt 25$ we have no ""Genus- $1$ "" examples ( the examples I'm asking about in this question ), so far. It would seem that new examples are very large and rare or do not exist. However, notice the far right ""near example"" ( red point) at $n=83$ , which gives us hope $$
(2^8-8^2) + (2^{16}-16^2) + (4^{16}-16^4) + (2^{32}-32^2)  =  (2^{33}-33^2) \color{red}{+1}
$$ that maybe a large example could exist. Do there exist any larger general examples, Genus-1 examples or near examples?","['number-theory', 'elementary-number-theory', 'examples-counterexamples', 'reference-request', 'recreational-mathematics']"
3832536,Are these hyperplanes close to each other?,"Let $X$ be a real Banach space and $f:X\to\mathbb{R}$ be continuous and linear. Suppose that $(r_n)$ is a sequence of real numbers converging to some $r>0$ . Let $$H=\{x\in X:f(x)=r\},$$ $$H_n=\{x\in X:f(x)=r_n\}.$$ In essence, I would like it if these hyperplanes were close to each other to prove something else. So, my question is: Let $z\in H$ . Is it true that $d(z,H_n)\to 0$ ? To me, this is something that ""should"" happen as in $\mathbb{R}^n$ it is quite obvious that these planes are getting close to each other but I'm unable to prove it yet. If $x\in H_n$ , how can I find out how small $\left\|{x-z}\right\|$ is? Do we maybe need some stronger hypothesis? Thank you.","['functional-analysis', 'real-analysis']"
3832573,"Group law of $\operatorname{Spec} \mathbb{Z}[x,x^{-1}]$","I'm trying to understand the group scheme $\mathbb{G}_m= \operatorname{Spec} \mathbb{Z}[x, x^{-1}]$ but I don't have much knowledge of algebraic geometry, so I thought that I should try to write everything down concretely to see what's going on. I started by computing spectrum of $\mathbb{Z}[x, x^{-1}],$ and I have found the following: Denote by $S$ be the multiplicative set $\{ x^{n} \mid  n \in \mathbb{Z} \},$ then $\mathbb{Z}[x, x^{-1}] = \mathbb{Z}[x]_S,$ and we have a classification of prime ideals of $\mathbb{Z}[X]$ here: Classification of prime ideals of $\mathbb{Z}[X]$ . Now let $\mathcal{p}$ be a prime ideal of $\mathbb{Z}[x]$ such that $\mathcal{p} \cap S $ is empty,   then $\mathcal{p} \mathbb{Z}[x, x^{-1}]$ is a prime ideal of $\mathbb{Z}[x, x^{-1}].$ If I'm not missing something, I think this should give us all prime ideals of $\mathbb{Z}[x,x^{-1}].$ Now my question is the following: Is it possible to write down explicitly what the group law on $\operatorname{Spec}\mathbb{Z}[x,x^{-1}]$ is?
For example: what is the product of the two prime ideals $(x-2)$ and $(2x-1)?$ Thanks in advance.","['algebraic-geometry', 'commutative-algebra']"
3832587,Natural Deduction Proof with Quantifiers Proof Validation,"Only using natural deduction prove: $$\frac{\forall x P(x) \\ \forall x \lnot Q(x) \lor \forall yQ(y) \\ \exists x [P(x) \rightarrow \lnot Q(x)]}{\therefore \forall x \lnot Q}$$ My solution: $1. \space \forall x P(x) \qquad \qquad \qquad premise\\ 2. \space \forall x \lnot Q(x) \lor \forall y Q(y) \qquad premise\\ 3. \space \exists x [P(x) \rightarrow \lnot Q(x)] \qquad premise \\ \boxed{4. \space x_o \qquad \qquad \qquad \qquad arbitrary \\ \boxed{5. \space y_o \space P(y_o) \rightarrow Q(y_o) \qquad assumption \\ 6. \space \lnot Q(x_o) \ \lor \forall yQ(y) \qquad \forall-elim(2,4) \\ 7. \space \lnot Q(x_o) \lor Q(y_o) \qquad \forall-elim(2,5) \\ \boxed{8.\space y_o\space Q(y_o) \qquad\qquad assumption \\ 9.\space \lnot Q(y_o) \qquad \qquad \rightarrow-elim(5)\\ 10. \space F \qquad \qquad \lnot-elim(8-9)\\ 11. \space \lnot Q(x_o) \qquad \qquad F-elim (10)}\\ \boxed{12. \space \lnot P(x_o) \qquad \qquad assumption \\ 13. \space P(x_o) \qquad \qquad \forall-elim(1,4) \\ 14. \space F \qquad \qquad \lnot-elim(12-13) \\ 15.\space \lnot Q(x_o) \qquad \qquad F-elim(15)}\\ 16. \space \lnot Q(x_o) \qquad \qquad \lor-elim (8-11,12-15)}\\17. \space \lnot Q(x_o) \qquad \qquad \exists-elim(3,5-16)} \\ 18. \forall x\lnot Q(x_o) \qquad \qquad \forall-intro(4-17)$ From the last version I changed the domain on the variables to be seen easier. Question 1: I think I can change the domain to the second premise because they are two different domains, right? Question 2: Lines 12 - 15, is this valid? Question 3: For lines 4 - 7, I said $x_o$ is arbitrary so it can cancel out the for all statement. Is it valid to do it like I did for 6 and 7?","['propositional-calculus', 'quantifiers', 'solution-verification', 'discrete-mathematics', 'natural-deduction']"
3832602,Intuition of characteristic property of the free group,"Here is a theorem about characteristic property of the free group: Theorem (Lee TM). Let $S$ be a set. For
any group $H$ and any map $f:S\to H$ , there exists a unique homomorphism $g:F(S)\to H$ extending $f$ . Here $F(S)$ is free group on $S$ . I know what it says but I don't know why it should be useful. i.e. What is the strategy of such theorems? How it can help to understand $F(S)$ ? Can anyone enlighten it by a simple example?","['group-theory', 'free-groups', 'free-product', 'category-theory']"
3832655,Application of Cayley’s theorem in Sylow’s theorem,I’ve just started reading Sylow’s theorems. I have heard that Cayley’s theorems are applied in Sylow’s theorem. Can someone exactly point out where in the three Sylow’s theorem is Cayley’s theorem explicitly  used?,"['group-theory', 'abstract-algebra', 'sylow-theory', 'cayley-graphs']"
3832672,Prove With Three Real Numbers Prove That We Can Pick Two And Their Product is Non Negative,"Consider three real numbers $a$ , $b$ , and $c$ . Prove that we can pick two of them such that their product is non-negative. My Proof: Using proof by cases: Case 1: $a >0,\space b>0,\space c>0$ Above, we can see that if we pick ANY two pairs that their product is alway positive. Ex: $$a\cdot b = ab \qquad (ab>0)$$ Case 2: Lets say $a <0, b<0,c>0$ There is only one way to get a positive product out of this group. You need to pick two variables that have the same ""sign""(The variables must both be positive or negative). If the two variables are not the same sign then their product will always be negative. Ex: $$a \cdot b = ab \qquad (ab>0, a<0, b<0)$$ $$a \cdot c = ac \qquad (ac <0, a<0, b >0)$$ $\therefore$ You can pick two variables with like signs from this group and their producgt will always be positive. $\square$ My Question: Is this the correct way to go about this proof? I don't see another way with the small set of proof methods we have. I don't know if this is enough to prove this though. It seems too simple... Any thoughts?","['proof-writing', 'solution-verification', 'discrete-mathematics']"
3832684,Square root inequality $\sqrt {x-z} \geq \sqrt x -\sqrt{z} $,"Does the following inequality hold? $$\sqrt {x-z} \geq \sqrt x -\sqrt{z} \  , $$ for all $x \geq z \geq 0$ . My justification \begin{equation}
z \leq x \Rightarrow \\ \sqrt z \leq \sqrt {x} \Rightarrow \\ 2\sqrt z \sqrt z \leq 2\sqrt z\sqrt {x} \Rightarrow \\ 2 z \leq 2\sqrt z\sqrt {x} \Rightarrow  \\ z - 2\sqrt z\sqrt {x} + x \leq x - z  \Rightarrow  \\  (\sqrt x -\sqrt z )^2 \leq x - z \Rightarrow  \\ \sqrt x -\sqrt z \leq \sqrt {x - z}
\end{equation}",['algebra-precalculus']
3832708,Why does the blowup of a curve at a singular point decreases the arithmetic genus?,"In Beauville's Complex Algebraic Surfaces , problem II.20 we are asked to show that an irreducible curve $C$ in a smooth surface $S$ becomes smooth after a finite number of blowups. He says that a way to do this is to show that the arithmetic genus decreases everytime we blowup $C$ at a singular point. There is a proof of this in Barth, Hulek, Peters, Van de Ven's Compact Complex Surfaces using the following idea (I'll paraphrase): Consider the case when $C$ has only one singular point $P$ . Let $x,y$ be local coordinates for $S$ in a neighbourhood $U$ of $P$ , so that the blowup is described as the subvariety of $U\times\Bbb{P}^1$ given by $sy=tx$ . We will assume that $y=0$ is the only tangent direction of $C$ at $P$ and that the multiplicity of $\widetilde{C}$ at the corresponding point is the same (in the other cases, the multiplicity clearly decreases). Then $C$ is described locally by the power series $$f=ay^m+\sum_{i+i> m}a_{ij}x^iy^j.$$ Restricting to the open set $V_s=\{s\neq 0\}$ and writing $t$ instead of $\frac{t}{s}$ for simplicity, we get that the strict transform $\widetilde{C}$ is given by $$\widetilde{f}=at^m+\sum_{i+j>m}a_{ij}x^{i+j-m}t^j$$ Then we observe that the order with which $\widetilde{f}(x,0)$ vanishes at the origin is strictly less than the order with which $f(x,0)$ does, which shows that the process will eventually terminate. I understand all that, but I still can't see how this relates to the arithmetic genus $p_a=h^1(C,\mathcal{O}_C)$","['algebraic-geometry', 'blowup', 'singularity']"
3832722,"Do finitely additive measures solve the ""problem of measure""?","Does there exist a unique function $\mu$ satisfying the following properties? $\mu:\mathcal P(\mathbb R)\to [0,\infty]$ $\mu(A+x)=\mu(A) \qquad\qquad$ for all $A\in\mathcal P(\mathbb R),x\in\mathbb R$ $\mu([a,b])=b-a\qquad\qquad\,$ for all $a<b\in\mathbb R$ $\mu\big(⨃_{i=1}^N A_i\big)=\sum_{i=1}^N \mu(A_i)\;\,$ for all finite pairwise-disjoint families $(A_i)$ with each $A_i\in\mathcal P(\mathbb R)$ If (4) is strengthened to include countably infinite disjoint unions, such a function famously does not exist (which Terrence Tao has called the ""problem of measure,"" hence the question title). The standard solution is to replace every occurence of $\mathcal P(\mathbb R)$ above with $\mathcal B(\mathbb R)$ ; then Borel measure is the unique function on $\mathcal B(\mathbb R)$ that satisfies the above conditions (with 4 strengthened to countable additivity). I'm curious whether this alternative approach (using only finitely additive measures) would work instead.","['measure-theory', 'lebesgue-measure', 'borel-measures']"
3832741,Show that a complex function is identically zero. [duplicate],"This question already has answers here : Showing that $f$ is identically $0$ on $\mathbb{D}$ (1 answer) Prove that $ f(z) = 0 $ for all $ z \in \overline{D}(0,1) $. (2 answers) Closed 3 years ago . Show that if $f:\{z : |z| < 1\} \to \mathbb{C}$ is analytic, bounded, and for some $0<a<b<2 \pi$ $$\lim_{r \to 1^-} \sup_{a \leq \theta \leq b} |f(re^{i\theta})| = 0 , $$ then $f=0.$ I tried to use Maximum modulus theorem of Liouville theorem, but we do not know whether $f$ is analytic on unit circle.","['complex-analysis', 'analytic-functions']"
3832744,Uniform bound for derivatives of holomorphic function on compact set,"I am trying to prove the following statement. Given $U \subseteq \mathbb{C}$ open, a compact set $K \subset U$ , and $j \in \mathbb{N}$ , show that there exists a constant $C > 0$ such that for any holomorphic $f : U \to \mathbb{C}$ and $z \in K$ we have \begin{equation*}
	\lvert f^{(j)}(z) \rvert \leq C \sup_{w \in U} \lvert f(w) \rvert.
\end{equation*} Here is my attempt. In what follows, $D(P,r)$ and $\overline{D(P, r)}$ will denote the open and closed disks of radius $r$ centered at $P$ , respectively. Proof attempt. Let $z \in K \subset U$ . Since $U$ is open, we can find $r_z > 0$ such that $\overline{D(z, r_z)} \subseteq U$ . Cover $K$ with $\{D(z, r_z) \mid z \in K\}$ ; since $K$ is compact, we can find finitely many $z_i \in K$ such that $\{D(z_i, r_i) \mid 1 \leq i \leq n, r_i := r_{z_i}\}$ covers $K$ . Now let $f : U \to \mathbb{C}$ be holomorphic and let $z \in K$ . Then $z \in D(z_i, r_i)$ for some $1 \leq i \leq n$ , so by Cauchy's integral formula and a bound on the path integral we have \begin{equation*}
	\lvert f^{(j)}(z) \vert = \left \vert \frac{j!}{2 \pi i} \oint_{\partial D(z_i, r_i)} \frac{f(w) \ dw}{(w - z)^{j + 1}} \right \vert \leq \frac{j!}{2 \pi} \sup_{w \in \partial D(z_i, r_i)} \left \vert \frac{f(w)}{(w - z)^{j+1}} \right \vert \cdot 2 \pi r_i.
\end{equation*} We get \begin{equation*}
	\left \vert w - z \right \vert = \vert (w - z_i) - (z - z_i) \vert \geq \vert \vert w - z_i \vert - \vert z_i - z \vert \vert = \vert r_i - \vert z_i - z \vert \vert
\end{equation*} for $w \in \partial D(z_i, r_i)$ , so \begin{equation*}
	\vert f^{(j)}(z) \vert \leq r_i \cdot j! \sup_{w \in \partial D(z_i, r_i)} \left \vert \frac{f(w)}{(w - z)^{j+1}} \right \vert \leq r_i j! \frac{\sup_{w \in \partial D(z_i, r_i)} \left \vert f(w) \right \vert}{\vert r_i - \vert z_i - z \vert \vert^{j+1}} \leq \frac{j!}{r_i^j} \frac{1}{\left \vert 1 - \frac{\left \vert z_i - z\right \vert}{r_i}\right \vert^{j+1}} \sup_{w \in U} \vert f(w) \vert.
\end{equation*} This is as far as I could go. The triangle inequality and the bound I have on $z_i - z$ work against me: I can bound it above by $r_i$ and below by $0$ , and both are useless with the reciprocal. If I could get a bound $M_{i,j}$ for \begin{equation*}
	\frac{1}{\left \vert 1 - \frac{\left \vert z_i - z \right \vert}{r_i}\right \vert^{j+1}}
\end{equation*} that did not depend on $z$ then I could take $C = \max \{M_{i,j} \cdot j!/r_i^j \mid 1 \leq i \leq n\}$ and the statement would follow. However, I see no way of getting a useful bound. Any suggestion or hint would be greatly appreciated.","['complex-analysis', 'derivatives', 'upper-lower-bounds', 'cauchy-integral-formula']"
3832757,The Verification of a Logical Statement in Jaynes' Book,"Could you please help me with the following question, posed in the first chapter of Jaynes' Probability Theory ? Take $$C\equiv(A+\bar B)(\bar A+A\bar B)+\bar AB(A+B)$$ The verification of $$C=(B \Rightarrow \bar A)$$ is left to the reader to show that these two are the same. I started by using the basic identities: $$C\equiv A\bar A+A\bar B+\bar A\bar B+A\bar A\bar B+\bar AB$$ I am a beginner, but I know the first and the fourth terms are always false, and based on the passage, $B \Rightarrow \bar A$ means only that the propositions $B$ and $B \bar A$ have the same truth value. I analyzed all the four possible points of true and false for both the first and second expressions of C . However, they yield different results. I simply don't know how to proceed.","['boolean-algebra', 'propositional-calculus', 'logic', 'discrete-mathematics', 'probability-theory']"
3832800,Variance of $\log ( \exp(A) + \exp(B) )$,"If $A, B$ are real valued (not necessarily independent) random variables with finite means and variances, what do we know about the variance of $\log ( \exp(A) + \exp(B) )$ , in terms of the variances of $A, B$ ? In particular, if the latter are small, will the former be small? Here's my best upper bound so far: \begin{eqnarray*}
\operatorname{VAR}[ \log ( \exp(A) + \exp(B) ) ] &\leq& \operatorname{VAR}[ A ] + \operatorname{VAR}[ B ]  +  (2 \log 2) \sqrt{\operatorname{VAR}[A] + \operatorname{VAR}[B] } + (\log 2)^2
\end{eqnarray*} With the bound above, it is not enough for $\operatorname{VAR}[A], \operatorname{VAR}[B]$ to be small for $\operatorname{VAR}\left[ \log\left( \exp(A) + \exp(B) \right) \right]$ to be small because of the $(\log 2)^2$ term. If $A$ , $B$ are concentrated each on a single point, then clearly $\operatorname{VAR}[ \log ( \exp(A) + \exp(B) ) ] = 0$ . So the bound can be improved, but how? Also, can the bound be improved if we know that $A$ and $B$ are in fact dependent? Here's how to derive the current bound: \begin{eqnarray}
\operatorname{VAR}[ \log ( \exp(A) + \exp(B) ) ] &=& \operatorname{VAR}[ \log( \exp( \max\{A,B\} ) + \exp(\min\{A,B\} )) ] \\
&=& \operatorname{VAR}[ \log( \exp( \max\{A,B\} ) ( 1 + \exp(\min\{A,B\} - \max\{A,B\})]\\
&=& \operatorname{VAR}[ \max\{A,B\} ] \\
& & + \operatorname{VAR}[ \log( 1 + \exp(\min\{A,B\} - \max\{A,B\}))] \\
& & + 2 \operatorname{COV}[ \max\{A,B\} , \log( 1 + \exp(\min\{A,B\} - \max\{A,B\})) ]
\end{eqnarray} For the first term, we will use \begin{eqnarray}
\operatorname{VAR}[ \max\{A,B\} ] \leq \operatorname{VAR}[ A ] + \operatorname{VAR}[ B ]
\end{eqnarray} (see https://stats.stackexchange.com/q/48093 ).
Define \begin{eqnarray}
C \stackrel{\Delta}{=} \log(1+ \exp(\min\{A,B\} - \max\{A,B\}) )
\end{eqnarray} and note that $0 \leq C \leq \log 2$ . The second term is bounded this way: \begin{eqnarray}
\operatorname{VAR}[ C ] &=& E C^2 - (E C)^2 \leq E C^2 \leq (\log 2)^2
\end{eqnarray} Finally, for the third term \begin{eqnarray*}
\operatorname{COV}[ \max\{A,B\} , C ] &\leq & \sqrt{ \operatorname{VAR}[\max\{A,B\}] \operatorname{VAR}[C]} \\
&\leq & \sqrt{ (\operatorname{VAR}[A] + \operatorname{VAR}[B] ) (\log 2)^2} \\
&=&(\log 2) \sqrt{\operatorname{VAR}[A] + \operatorname{VAR}[B] } 
\end{eqnarray*} Putting everything together, this currently reads: \begin{eqnarray*}
\operatorname{VAR}[ \log ( \exp(A) + \exp(B) ) ] &\leq& \operatorname{VAR}[ A ] + \operatorname{VAR}[ B ]  +  (2 \log 2) \sqrt{\operatorname{VAR}[A] + \operatorname{VAR}[B] } + (\log 2)^2
\end{eqnarray*} P.S. The idea works more generally: \begin{eqnarray*}
\operatorname{VAR}\left[ \log\left( \sum_{i=1}^n \exp(X_i) \right) \right] \leq \sum_{i=1}^n \operatorname{VAR}[ X_i ] + (2 \log n) \sqrt{\sum_{i=1}^n \operatorname{VAR}[X_i]} + (\log n)^2
\end{eqnarray*} by observing that if $Y_1, \cdots, Y_n$ are ordered versions of $X_1,\cdots,X_n$ , (largest to smallest) \begin{eqnarray*}
\sum_{i=1}^n \exp(X_i) &=& \sum_{i=1}^n \exp(Y_i) \\
&=& \exp(Y_1) \left( 1 + \sum_{i=2}^n \exp(Y_i - Y_1) \right)
\end{eqnarray*}","['variance', 'probability', 'logarithms']"
3832810,Line integral in polar coordinates vs change of variables,"Assume we have a two-dimensional force field: $$F(r, \theta) = -4\sin(\theta)i + 4\sin(\theta)j$$ Compute the work done in moving a particle from the point $(1, 0)$ to the origin along the spiral whose polar equation is $r = e^{-\theta}$ . I know how to compute the answer in general. We need to represent the path $\alpha(\theta) = (e^{-\theta}\cos(\theta), e^{-\theta}\sin(\theta))$ as such, and then take a line integral to infinity. However, I also first made a mistake by trying the following integral: $$\int_0^{+\infty} F(r, \theta) \cdot \frac{\partial (e^{-\theta}, \theta)}{\partial \theta} d\theta$$ which of course gives an incorrect result. The problem I cannot figure is how do we do the variable change here? In particular, where do the respective coordinate systems (Cartesian vs polar) come along and which should be transformed into which? I justify the correct answer by noticing, that $F(r, \theta)$ is a vector in $R^2$ , while the path $\alpha(\theta) = (e^{-\theta}, \theta)$ is a path in some space which is NOT an $R^2$ . As such, no inner product can be formed. Why the incorrect path not working? In short, why do we need to use $\alpha(\theta) = (e^{-\theta}\cos(\theta), e^{-\theta}\sin(\theta))$ instead of $\alpha(\theta) = (e^{-\theta}, \theta)$ If the vector field $F$ is already parameterized by $\theta$ , where does $\sin(\theta)$ and $\cos(\theta)$ come from in its definition, given that the path should be described as $(e^{-\theta}\cos(\theta), e^{-\theta}\sin(\theta))$ How can I use the path $\alpha(\theta) = (e^{-\theta}, \theta)$ in whatever space it is defined?","['coordinate-systems', 'multivariable-calculus', 'polar-coordinates', 'change-of-variable', 'line-integrals']"
3832899,"Ring theory conventions - Zero ring, local homomorphisms","Just wondering about conventions dealing with the zero ring and the zero scheme. Does the category of schemes have an inital object? Is the zero ring considered local? For the purposes of scheme theory, is a map of sheaves that induces on stalks a map of the form $\mathcal{O}_{X,P}\to 0$ considered a ""local"" homomorphism on stalks? https://en.wikipedia.org/wiki/Zero_ring Wikipedia says that the zero ring is not local. I am wondering how to square this with certain conventions in scheme theory. If $0$ is the zero ring, then conventionally (say in Hartshorne Chapter II, exercise 2.6) the category of schemes has $Spec(0)$ for an initial object; whose underlying space is $\emptyset$ and whose associated sheaf is the constant sheaf at zero. The direct image of this sheaf along the canonical map $\emptyset \to X$ would be, again, the constant zero sheaf, so the canonical natural transformation $\mathcal{O_X}\to 0$ would send every stalk to zero. It seems like this shouldn't count as a map of locally ringed spaces.","['commutative-algebra', 'algebraic-geometry', 'ringed-spaces', 'convention', 'schemes']"
3832935,In how many ways can 4 cards be drawn randomly from a pack of 52 cards such that there are at least 2 kings and at least 1 queen among them?,"So i tried this question in two ways (i)In my first method I made different possible arrangements and then find the number of ways So, the different possibilities are: 2 kings and 1 queen and 1 other card Or, 3 kings and 1 queen Or, 2 kings and 2 queens Total ways possible = $${4\choose2}{4\choose1}{44\choose1}+{4\choose3}{4\choose1}+{4\choose2}{4\choose2} = 1056 + 16 + 36
= 1108
$$ Total ways possible = 1108
And this is the correct answer. (ii) In order to shorten the above method, I did this We need at least 2 kings and 1 queen, so total ways possible = $${4\choose2}{4\choose1}{49\choose1}=1176$$ (49 because I subtracted the 3 cards from the deck of 52 cards). So what's the problem with second method? Why I'm getting additional 68 ways (1176 - 1108= 68)? And Is there any way to solve this question without making cases? Thanks and stay safe.","['permutations', 'combinations', 'combinatorics']"
3832947,Talagrand's functional and Dudley's sum (Vershynin 8.5.2),"Looking at Exercise 8.5.2 in Vershynin's book High-Dimensional Probability, page 207 Consider the set $T\subset\mathbb{R}^n$ with $T=\left\{\frac{e_k}{\sqrt{1+\log n}}\,,\,k=1,\ldots,n\right\}$ . If $T_k\subset T$ with $|T_k|\le2^{2^k}$ , then: (a) Show that the $\gamma_2$ -functional of $T$ (with respect to the Euclidean metric) is bounded, i.e. $$\gamma_2(T,d)=\inf_{T_k}\sup_{t\in T}\sum_{k=0}^\infty 2^{k/2}d(t,T_k)\le C.
$$ (b) Check that Dudley's sum is bounded, i.e. $$\inf_{T_k}\sum_{k=0}^\infty2^{k/2}\sup_{t\in T}d(t,T_k)\rightarrow\infty$$ as $n\rightarrow \infty$ . ================= I believe the natural approach would be to set $T_k$ to be the first $2^{2^k}$ elements of $T$ , in which case $d(t,T_k)=\sqrt{\frac{2}{1+\log n}}$ for each $k<\log\log n$ . But then aren't both quantities at most $2\sqrt{\log n}\cdot\sqrt{\frac{2}{1+\log n}}<C$ ? Why does Dudley's sum diverge?","['stochastic-processes', 'probability-theory']"
3832958,Is there a way to compute $\sum_{n=0}^\infty 1/(1+n!)$?,"Is there a way to compute the exact value of the following series? \begin{equation}
\sum_{n=0}^\infty\frac{1}{1+n!}
\end{equation} I know that it converges to a number less than $e$ , since $e=\sum_{n=0}^\infty 1/n!$ . I also know that the approximated value is $1.52607$ . But can I express the exact value using known constants or functions, such as $e, \pi, \Gamma$ ?","['sequences-and-series', 'real-analysis']"
3833000,Second countability of compact open topology,"Let $X, Y$ be topological spaces and $C(X,Y)$ the set of continuous functions with the compact open topology defined as having the subbasis consisting of all subsets $C(K, U)$ of functions $f$ for which $f(K) \subseteq U$ , where $K$ is compact and $U$ is open. My question has two aspects: I am particularly interested in the case where $X,Y$ are both second countable, locally euclidian and Hausdorff. Is then $C(X,Y)$ second countable, or at least first countable? Are there any known weaker sufficient conditions on $X$ and $Y$ such that $C(X,Y)$ is second countable or at least first countable? Regarding 1., I'm thinking $X$ being locally euclidian is useful because given a basis, the sets in it which are relatively compact form a subbasis. But before I can get to that, I am already stuck at the fact that, if $U$ is open in $Y$ , $\left\{ U_i \right\}$ is a countable basis and $U=\cup_{i \in I_U} U_i$ , one only has $\cup_{i \in I_U} C(K, U_i) \subseteq C(K, U)$ , but not necessarily equality.","['general-topology', 'second-countable']"
3833042,Intuition behind sub-Gaussian and sub-exponential random variables,"As I was reading about Gaussian random variable (RV) and Chernoff Bounds, I came across sub-Gaussian & sub-exponential RVs. After much analysis, I still couldn't figure what purpose sub-Gaussian & sub-exponential serve in the broader realm of statistics. So my question is: How do sub-Gaussian & sub-exponential RVs relate to Gaussian RV in an intuitive sense? How should I decide when sub-Gaussian/sub-exponential RVs are suitable for a particular scenario? An answer combining intuition and mathematics would be helpful.","['statistics', 'concentration-of-measure', 'probability-theory', 'probability', 'random-variables']"
3833043,A constant related to distances from a point on the circumsphere of regular polyhedron to the vertices,"I was interested in problem 3 of STEP3 2013(I have shortened the original description): The four vertices $P_{i}(i=1,2,3,4)$ of a regular tetrahedron lie on the surface of a sphere with center at $O $ .  Let $X$ be any point on the surface of the sphere, and let $ X P_{i}$ denote the distance between X and $ P_{i}$ . Show that (i) $\sum_{i=1}^{4}\left(X P_{i}\right)^{2}$ (ii) $\sum_{i=1}^{4}\left(X P_{i}\right)^{4}$ are both independent of the position of X. (i) could be easily proven using vectors. To prove (ii), I have to use the coordinates and expanding: \begin{aligned}
&\sum_{i=1}^{4}\left(X P_{i}\right)^{4}=16R^2+4\left(z^{2}+\left(\frac{2 \sqrt{2}}{3} x-\frac{1}{3} z\right)^{2}+\left(-\frac{\sqrt{2}}{3} x+\frac{\sqrt{2}}{\sqrt{3}} y-\frac{1}{3} z\right)^{2}+\left(-\frac{\sqrt{2}}{3} x-\frac{\sqrt{2}}{\sqrt{3}} y-\frac{1}{3} z\right)^{2}\right)\\
&=16R^2+4\left(\frac{4}{3} x^{2}+\frac{4}{3} y^{2}+\frac{4}{3} z^{2}\right)=\frac{64}{3} R^2
\end{aligned} I find some similar results: $X$ is a point on the circumsphere of a regular polyhedron of $n$ faces with edge length 1, and let $S(k)$ denote the sum of the $2k$ th power of the distances between $X$ and the vertices. n=4,S(1)=3,S(2)=3,S(3) is not constant. n=6,S(1)=12,S(2)=24,S(3)=54,but S(4) is not constant. n=8,S(1)=6, S(2)=8,S(3)=12, but S(4) is not constant. n=12,S(1)= $45+15\sqrt5$ ,S(2)= $210+90\sqrt5$ , $S(3)=1215+540\sqrt5$ , S(4) $= 7614 + 3402\sqrt5$ ,S(5) $=49815 + 22275\sqrt5$ ,but S(6) is not constant. n=20,S(1)= $15+3\sqrt5$ ,S(2)= $30+10\sqrt5$ ,S(3)= $75+30\sqrt5$ ,S(4)= $210+90\sqrt5$ , S(5)= $625+275\sqrt5$ , but S(6) is not constant. (I also noticed that the cases for dual polyhedron is similar) Is there a better proof of these results than just expanding expressions?","['euclidean-geometry', 'polyhedra', 'linear-algebra', 'geometry']"
3833080,Is there a smooth surjective map from a connected manifold onto a manifold with higher dimension?,"By Sard’s theorem, there is no smooth surjective map from a second-countable manifold onto a manifold with higher dimension. However, without second-countability, the identity map from ( $ \mathbb{R} $ , discrete) onto ( $ \mathbb{R} $ , usual) is a counterexample. Question. What if we require connectedness instead of second-countability? i.e., is there a smooth surjective map from a connected manifold onto a manifold with higher dimension? Since a connected paracompact manifold is second-countable, a counterexample must be non-paracompact (if exsits). I have no idea how to construct such a manifold, or how to prove non-existence.","['manifolds', 'general-topology', 'differential-topology', 'differential-geometry']"
3833114,Exercise 2.3.5 in Vershynin's HDP book,"Let $X_i$ be independent Bernoulli random variables with parameters $p_i$ . Consider their sum $S_N=\sum_{i=1}^N X_i$ and denote its mean by $\mu=\mathsf{E} S_N$ . Then, for $\delta\in (0,1]$ , prove that $$\mathsf{P}\{|S_N-\mu|\geqslant \delta\mu\}\leqslant 2e^{-c\mu\delta^2}$$ where $c>0$ is an absolute constant. This is the Exercise 2.3.5 in Vershynin's HDP book. My idea and problem are as following: ============================ My Solution ============================ I use the following two inequalities: 1.[Chenoff's inequality] $$\mathsf{P}\{S_N\geqslant t\}\leqslant e^{-\mu}\left(\frac{e\mu}{t}\right)^t,\qquad (t>\mu)$$ 2.[Extension of Chernoff's inequality, see Exercise 2.3.2 in Vershynin's HDP book] $$\mathsf{P}\{S_N\leqslant t\}\leqslant e^{-\mu}\left(\frac{e\mu}{t}\right)^t,\qquad (t<\mu)$$ Then I get $$
\begin{aligned}
\mathsf{P}\{|S_N-\mu|\geqslant \delta\mu\}&\leqslant \mathsf{P}\{S_N-\mu\geqslant \delta\mu\} + \mathsf{P}\{\mu-S_N\geqslant \delta\mu\}\\[0.5em]
&=\mathsf{P}\{S_N\geqslant (1+\delta)\mu\}+\mathsf{P}\{S_N\leqslant (1-\delta)\mu\}\\[1em]
&\leqslant e^{-\mu} \left\{\left(\frac{e}{1+\delta}\right)^{(1+\delta)\mu}+\left(\frac{e}{1-\delta}\right)^{(1-\delta)\mu}\right\}.\qquad[\text{use ineq. 1 & 2 above}]
\end{aligned}
$$ ============================ My Problem ============================
However, I cannot prove that $$
e^{-\mu} \left\{\left(\frac{e}{1+\delta}\right)^{(1+\delta)\mu}+\left(\frac{e}{1-\delta}\right)^{(1-\delta)\mu}\right\} \leqslant 2e^{-c\mu\delta^2}.\tag{*}
$$ Is the ineq. (*) true?","['inequality', 'probability']"
3833145,Maximize functional with dot product in it,"I have to find a function that maximizes some functional. This function can be divided into multiple functionals - as a first step, I wanted to find a function that maximizes only one of these (for which the correct solution can easily be seen even w/o calculus of variaton), to make sure I got the theory of calculus of variation still right. The functional I am interested in has the form $$
F[h] = \int_{S \times S} L(x, y, h(x), h(y)) dx dy= \int_{S \times S} g(x, y) h(x)^Th(y) dx dy,
$$ with $h:S \to S$ and $g: X \times Y \to R$ and $g$ is symmetrical in its arguments, i.e. $g(x, y) = g(y, x)$ and $S \subseteq R^n$ Now I'd like to find the $h$ that maximizes said functional, i.e. the function $h$ that solves $$
\frac{\delta F}{\delta h} = 0.
$$ For this, I tried two things: I used the Euler-Lagrange equation $\frac{\partial F}{\partial h} - \frac{d}{dx}\frac{\partial L}{\partial h'}$ , and $\frac{\delta F}{\delta h} = g(x, y)(h(x) + h(y))$ , but then I got confused because $h$ is evaluated for two different arguments in $L$ . How should I continue from here? I tried to calculate the derivate directly by applying the definition of the functional derivative $$
\frac{\delta F}{\delta h} = \lim_{\epsilon \to 0} \frac{F[h + \epsilon \eta] - F[h]}{\epsilon}. 
$$ For this I got $$
\lim_{\epsilon \to 0} \int_{S \times S} g(x, y)[(h(x) + \epsilon \eta(x))^T(h(y) + \epsilon \eta(y))] \\
= \int_{S \times S} g(x, y)[\eta(x)^Th(y) + \eta(y)^Tg(x)] \\
= \int_{S \times S} g(x, y)\eta(x)^Th(y) + \int_{S \times S} g(y, x)\eta(y)^Th(x) \\
= \int_{S \times S} 2 g(x, y)h(x)^T\eta(x),
$$ from which I concluded $\frac{\delta F}{\delta h} = 2 g(x, y)h(x)^T$ as the expression above must hold true for all test functions $\eta$ . Now I am wondering: Does any of the two approaches make sense and give the correct
result How to explain the difference in their results. Is the latter just because I haven't used the symmetry property of $g$ yet? Both expressions I ended up with equal $0$ when $h = const = 0$ , which is the global minimum of the functional; how can I find the maximum of it (which should be $h = const = max_S$ ? I assume the problem here is that I haven't yet used that $h$ should also map to $S$ ; is that correct? If so, how can I do this?","['calculus', 'derivatives', 'functional-calculus', 'calculus-of-variations']"
3833252,Generating (almost?) all odd numbers for the 3n + 1 problem [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed last year . Improve this question The 3n + 1 problem The $3n + 1$ problem can be described as a set of simple rules. For any positive integer apply the following two rules: If the number is even: divide by 2 If the number is odd: multiply by 3 and add 1 Here is an example: 7 -> 22 -> 11 -> 34 -> 17 -> 52 -> 26 -> 13 -> 40 -> 20 -> 10 -> 5 -> 16 -> 8 -> 4 -> 2 -> 1 -> 4 ... Collatz conjecture One thing to notice in the example above is that the pattern ends in a 1 -> 4 -> 2 -> 1 cycle. Collatz has conjectured this will always happen, for each positive starting integer. Proving/disproving Collatz To prove or disprove this conjecture someone will need to: Find a counter example: a number grows forever or another cycle. Prove that a cycle can't exist. Prove that all odd numbers can be generated by other numbers working backwards. People have been using super computers to crunch numbers to find a counter example to the Collatz conjecture. As of 2020 people have checked up to $2^{68}$ , and all examples end up in the same 1 -> 4 -> 2 -> 1 cycle. We could state that, for a second cycle to exist, there has to be some specific properties of the numbers inside the cycle. For example, every cycle has one lowest number in it; and for any repeating cycle it can't have $6n + 3$ numbers in it (more on that later). This lowest number in a cycle might have some very specific properties that only $1$ has, thus making a second cycle impossible. Generating numbers (working backwards) A final way to prove the Collatz conjecture is to show that all other numbers can be created by starting at $1$ . Lets take a closer look at all the numbers involved. Even numbers can easily be ignored, they will (in a cycle) always get divided down to an odd number. Because every even number is an odd number multiplied by a power of two. For example $80$ comes down to 80 -> 40 -> 20 -> 10 -> 5 . Because of this we can just focus on the odd numbers in the $3n + 1$ problem. Splitting the odd numbers The numbers that we need to focus on are: $$2n + 1$$ These are all the odd numbers. Let's split these numbers into three equal groups: $$a = 6n + 1$$ $$b = 6n + 3$$ $$c = 6n + 5$$ We can show that these groups all uniquely contain the odd numbers: $$a [1, 7,  13, 19, 27...]$$ $$b [3, 9,  15, 21, 29...]$$ $$c [5, 11, 17, 23, 31...]$$ Going a single ""Collatz"" step back from an odd number means multiplying by 2, this creates new even numbers: $$a_1 = 12n + 2$$ $$b_1 = 12n + 6$$ $$c_1 = 12n + 10$$ $a_1 - 1$ and $b_1 - 1$ are not divisible by three and have no odd predecessor at this depth. $c_1 - 1$ is divisible by three and it creates a pattern: $4n + 3$ This implies that from every number in the form $6n + 5$ , going one step back in the Collatz sequence, we can generate all $4n + 3$ formed numbers. When multiplying $a_1$ , $b_1$ and $c_1$ again by two (going a deeper step back) we get: $$a_2 = 24n + 4$$ $$b_2 = 24n + 12$$ $$c_2 = 24n + 20$$ $b_2 - 1$ and $c_2 - 1$ are not divisible by three thus have no odd predecessor at this depth. $a_2 - 1$ is divisible, and reveals pattern: $8n + 1$ Special case: 6n + 3 Because b is in the form $6n + 3$ , multiplying by two will never result in a number that minus one is divisible by three. This means that odd numbers of form $6n + 3$ have no odd numbers preceding them. This allows us to focus completely on $6n + 1$ and $6n + 5$ form numbers. Pattern equations For a and c we can come up with the following equations: $$a = \frac{2^{2k} (6n + 1) - 1}{3}$$ $$c = \frac{2^{2 k + 1} (6 n + 5) - 1}{3}$$ Depth $k$ determines how deep we travel backwards (multiplying by two).
The values for $k$ from the equations are: \begin{array}{|c|c|c|}
\hline
    k & a & c \\ \hline
    1 & 8n + 1 & 4n + 3 \\ \hline
    2 & 32n + 5 & 16n + 13 \\ \hline
    3 & 128n + 21 & 64n + 53 \\ \hline
    4 & 512n + 85 & 256n + 213 \\ \hline
    5 & ... & ... \\ \hline
\end{array} All the odd numbers that could be in a repeating cycle now have a method to calculate all their preceding odd numbers at different depths of $k$ . At a depth of $k=1$ we get the following information as mentioned above: $6n + 1$ and $6n + 5$ numbers will generate patterns: $8n + 1$ and $4n + 3$ This means all numbers in the forms: $8n + 1$ , $8n + 3$ and $8n + 7$ can be generated. After $k=1$ we just miss the numbers in the form $8n + 5$ . Next we look at $k=2$ , the new additions are: $32n + 5$ and $16n + 13$ . Scaling everything to $32n$ we can see that we can now form all odd numbers except in the form $32n + 21$ . One level deeper again and the patterns added are: $128n + 21$ and $64n + 53$ . This means that we can now form all odd numbers except those in the form $128n + 85$ . If this process is repeated, we can see that all odd numbers can be generated starting from just $6n + 1$ and $6n + 5$ . Density The amount of odd numbers that can be calculated are: $$\frac{4^k-1}{4^k}$$ The largest number that, at depth $k$ , can't yet be created is equal to: $$ 2 \cdot 4^{k+1}n + \frac{4^{k+2}-1}{3}$$ This results in the following table for small values of $k$ : \begin{array}{|l|l|l|l|}
\hline
        k & Missing & Density & Percentage \\ \hline
        1 & 8n + 5 & \frac{3}{4} & 0.75 \\ \hline
        2 & 32n + 21 & \frac{15}{16} & 0.9375 \\ \hline
        3 & 128n + 85 & \frac{63}{64} & 0.984375 \\ \hline
        4 & 512n + 341 & \frac{255}{256} & 0.99609375 \\ \hline
        5 & 2048n + 1365 & \frac{1023}{1024} & 0.9990234375 \\ \hline
        6 & 2 \cdot 4^6n + 5461 & \frac{4095}{4096} & 0.9997.. \\ \hline
        7 & 2 \cdot 4^7n + 21845 & \frac{16383}{16384} & 0.99993.. \\ \hline
        8 & 2 \cdot 4^8n + 87381 & \frac{65535}{65536} & 0.99998.. \\ \hline
        9 & 2 \cdot 4^9n + 349.525 & \frac{262143}{262144} & 0.999996.. \\ \hline
        10 & 2 \cdot 4^{10} n + 1398101 & \frac{1048575}{1048576} & 0.99999904... \\ \hline
        .. &  &  &  \\ \hline
        100 & 2 \cdot 4^{100} n + 214..... &  & 0.9999999999... \\ \hline
         & 2 \cdot 4^{k+1}n + \frac{4^{k+2}-1}{3} & \frac{4^k-1}{4^k} &  \\ \hline
\end{array} After just $k=10$ steps we can generate $\frac{1048575}{1048576}$ of all existing odd numbers from the starting values $6n + 1$ and $6n + 5$ . The lowest number we can't create is $2 \cdot 4^{10}n + 1398101$ . And after $k=100$ steps we're up to: $$0.9999999999999999999999999999999999999999999999999999999999993777$$ Update : Does this ""prove"" the Collatz conjecture? Sadly: No. There is one problem: We did show that each odd number can be made from $6n+1$ and $6n+5$ . We haven't shown that this all happens from the number 1. Update 2 : Suppose a second cycle exists. That cycle will have to have a lowest number, that is larger than 1 (obviously). Can we prove this cycle doesn't exist? We can try. First of all, we can still rule out any numbers in the form $6n+3$ , these numbers have no preceding odd numbers and can therefor never be created in a cycle. Now we have two options left, $6n+1$ ( a ) or $6n+5$ ( c ). Let's look at the numbers in c . They are in the form $6n+5$ , and have smaller predecessors in the form $4n+3$ . These are the only numbers that can make a cycle grow exist and odd numbers grow larger when running Collatz forward: \begin{array}{|l|l|l|}
\hline
        n & 4n + 3 \\ \hline
        0 & 6 \cdot 0 + 3 \\ \hline
        1 & 6 \cdot 1 + 1 \\ \hline
        2 & 6 \cdot 1 + 5 \\ \hline
        3 & 6 \cdot 2 + 3 \\ \hline
        4 & 6 \cdot 3 + 1 \\ \hline
        5 & 6 \cdot 3 + 5 \\ \hline
        6 & 6 \cdot 4 + 3 \\ \hline
        7 & 6 \cdot 5 + 1 \\ \hline
        8 & 6 \cdot 5 + 5 \\ \hline
        9 & 6 \cdot 6 + 3 \\ \hline
        10 & 6 \cdot 7 + 1 \\ \hline
        11 & 6 \cdot 7 + 5 \\ \hline
\end{array} From this we can conclude that we either: The smaller odd number before $4n+3$ is a smaller $6n+1$ The smaller odd number before $4n+3$ has the form $6n+3$ , a dead end The smaller odd number before $4n+3$ is a smaller $6n+5$ , continue until (1) or (2) are reached (will happen by deduction). This means that the only possible smallest odd number in a cycle can be in the form $6n+1$ , a number from group a . Suppose we again split a into two groups a1 and a2 : $$a1 = 12n + 1$$ $$a2 = 12n + 7$$ These groups contain all $6n+1$ numbers, split equally. If we now follow the sequence forward from our hypothetical lowest number in the cycle we get: $$((12n + 1) * 3)+1 = 36n + 4$$ $$((12n + 7) * 3)+1 = 36n + 22$$ Next we divide the even numbers by two (according to the $3n+1$ rule) and get: $$(36n + 4)/2/2 = 9n + 1$$ $$(36n + 22)/2 = 18n + 11$$ This shows that a number in form a1 ( $12n + 1$ ) is not the lowest number of the hypothetical Collatz cycle because $9n + 1$ follows and is smaller. So the lowest number in an hypothetical cycle must be $12n + 7$ . What next? One could dive deeper into these $4n+3$ numbers; those are very special and allow a number to grow before going down to 1. One could try to come up with a set of finite sub-trees that create the fractal like pattern the $3n+1$ problem has? I'm giving up (for now) :)","['collatz-conjecture', 'recreational-mathematics', 'solution-verification', 'sequences-and-series']"
3833276,"If $P(x)$ is any polynomial of degree less than $n$, show that $\sum_{j=0}^n (-1)^j\binom{n}{j}P(j)=0$. [duplicate]","This question already has answers here : Summation of series involving binomial coefficients and polynomial of degree at most n-1 (3 answers) Closed 3 years ago . If $P(x)$ is any polynomial of degree less than $n$ , then prove that $$\sum_{j=0}^n (-1)^j\binom{n}{j}P(j)=0$$ My approach was to try and prove this separately for $j^k\ \ \forall\ \ k<n$ , instead of $P(j)$ , since $P(x)$ can be written as $a_{n-1}x^{n-1}+a_{n-2}x^{n-2}+...+a_0$ . However, I could not get anywhere. It would be much appreciated if someone could provide a rigorous solution for this or any key insights. Thanks a lot","['summation', 'binomial-coefficients', 'combinatorics', 'polynomials']"
3833281,"Does $(\operatorname{div}fX)(a)=\langle\nabla f(a),X(a)\rangle+f(a)(\text{div}X)(a)$ hold for a scalar field $f$ and vector field $M$ on a manifold?","Let $d\in\mathbb N$ , $k\in\{1,\ldots,d\}$ and $M$ be a $k$ -dimensional embedded $C^1$ -submanifold of $\mathbb R^d$ with boundary. Can we prove the usual identity (in the case, where $M$ is an open subset of $\mathbb R^d$ ) for the divergence of the product of a scalar field and a vector field on $M$ ? To be precise, if $N\supseteq M$ is an embedded $C^1$ -submanifold with boundary, $\operatorname P_N(a)$ is the orthogonal projection of $\mathbb R^d$ onto $T_a\:N\supseteq T_a\:M$ for $a\in N$ , $E$ is a $\mathbb R$ -Banach space and $f:N\to E$ is $C^1$ -differentiable at $a\in M$ , define $${\rm D}_Mf(a):=T_a(f)\circ\operatorname P_M(a)\tag4.$$ If $E=\mathbb R$ , define $$\langle\nabla f,v\rangle:=T_a(f)v\;\;\;\text{for }v\in T_a\:N\tag5$$ and $^1$ $$\nabla_Mf(a):=\operatorname P_M\nabla f(a)\tag6.$$ And if $E=\mathbb R^d$ , define $$(\operatorname{div}f)(a)=\operatorname{tr}T_a(f)\;\;\;\text{for all }a\in M\tag7$$ and $$(\operatorname{div}_Mf)(a):=\operatorname{tr}{\rm D}_Mf(a)\tag8.$$ Now let $f:M\to\mathbb R$ and $X:M\to\mathbb R^d$ both be $C^1$ -differentiable at $a\in M$ and $(\tau_1,\ldots,\tau_k)$ be an orthonormal basis of $T_a\:M$ . Then we should have $$(\operatorname{div}fX)(a)=\sum_{i=1}^k\langle T_a(fX)\tau_i,\tau_i\rangle=\langle\nabla f(a),\operatorname P_M(a)X(a)\rangle+f(a)(\operatorname{div}X)(a)\tag9,$$ where $$\langle\nabla f(a),\operatorname P_M(a)X(a)\rangle=\langle\nabla f(a),X(a)\rangle\tag{10}.$$ So, the usual formula $$(\operatorname{div}fX)(a)=\langle\nabla f(a),X(a)\rangle+f(a)(\operatorname{div}X)(a)\tag{11}$$ should actually hold. What's worrying me is that I've read that we would need to assume $X(a)\in T_a\:M$ for that, but I don't see why we should need this assumption since $X(a)$ should automatically be projected onto $T_a\:M$ by $\langle\nabla f(a),X(a)\rangle$ anyways. $^1$ Note that $${\rm D}_Nf(a)v=\langle\nabla_Nf(a),v\rangle\;\;\;\text{for all }v\in\mathbb R^d\tag{6'}.$$ Moreover, if $M=N$ , then $\nabla f_N(a)=\nabla f(a)$ . $^2$ Note that if $M=N$ , then $(\operatorname{div}_Mf)(a)=(\operatorname{div}f)(a)$ .","['divergence-operator', 'submanifold', 'manifolds-with-boundary', 'smooth-manifolds', 'differential-geometry']"
3833290,Dimension of Hilbert space tensor product,"Let $H_1, H_2$ be Hilbert spaces and consider their Hilbert space tensor product $$H_1 \hat{\otimes} H_2$$ which is the completion of the algebraic tensor product $H_1 \otimes H_2$ with respect to the unique inner product on $H_1 \otimes H_2$ satisfying $$\langle x \otimes y, x' \otimes y'\rangle = \langle x , x' \rangle \langle y, y'\rangle$$ If $E_1$ is an orthonormal basis for $H_1$ and $E_2$ is an orthonormal basis for $H_2$ , I proved that $$E_1 \otimes E_2:= \{x \otimes y: x \in E_1, y\in E_2\}$$ is an orthonormal basis for $H_1 \hat{\otimes} H_2$ . From this, I want to deduce that $$\dim(H_1 \hat{\otimes} H_2 ) = \dim (H_1) \dim (H_2)$$ (product of cardinal numbers). I see that it suffices to check that the map $$E_1 \times E_2 \to E_1 \otimes E_2: (x,y) \mapsto x \otimes y$$ is injective, but I can't see why this holds: $$x \otimes y = x' \otimes y' \implies x= x', y = y'$$ must not be true for general pure tensors, but maybe because we have the orthogonality we can say something more?","['orthogonality', 'hilbert-spaces', 'abstract-algebra', 'tensor-products', 'functional-analysis']"
3833320,Why is the domain of a parametrised curve given by an open interval?,"This is my first question on the math stack exchange. I am currently a second-year undergraduate student taking an elementary course on Curves and Surfaces. My question is as follows. In the parametrization $γ : (−2π, 2π) \to\Bbb R^2$ given by $γ(t) = (\cos t − \sin t, \cos t + \sin t)$ , why is the domain of $t$ given by the open interval $(−2π, 2π)$ and not $[−2π, 2π]$ . Isn't $t$ clearly defined at $−2π$ and $2π?$ In other words why is an open interval taken to describe a parametric curve? Any help would be highly appreciated.","['curves', 'differential-topology', 'parametrization', 'differential-geometry']"
3833331,Probability of randomly selecting a number in the set ${2^n}$ from positive natural numbers?,"From substituting up to the first $m$ natural numbers I found that the probability of an integer being in the set of integers $2^n$ is approximately $\frac{\ln(m)}{m\ln(2)}$ . For example, for the first 10 natural numbers (1,2,3,...,10 where $m=10$ ), the probability of randomly selecting a integer in $2^n$ (there are three here – 2,4,8) is $\frac{3}{10}$ or 0.3. The approximation defined this as 0.332. However, I don't know the intuition behind this approximation (i.e. if it will work for all $m$ ) and I can't seem to find an exact form of this. I would be grateful for any help (btw, my main issue is finding an exact form of the problem).","['statistics', 'approximation', 'probability', 'logarithms']"
3833391,Cartesian product set notation,"Say I have the set $A=\{1,2\}.$ Now if I take the cartesian product $2$ times (of $A$ ) I get $$A\times A=\{(1,1),(1,2),(2,1),(2,2)\}.$$ We can see that half (2) of the sets have an even number of 1s Now, how do I specify that I want all the sets for which there are an even number of $1$ ’s for the set $B=\{1,2\}^n.$ The size of the set B is = ${2^n}/2 = 2^{n-1}$ All the subsets minus all the subsets that do not have an even number of ones (i.e half)",['elementary-set-theory']
3833395,Finding a compact set contained in a measurable set,"I'm reading a proof of Steinhauss theorem: Let $A \subset \mathbb{R}^n$ be a measurable set and $m(A)>0$ , where $m$ is the Lebesgue measure.
Then, $A-A = \{ x-y: x,y\in A\}$ contains an oper neighbourhood of the origin. And it uses the following result to prove it: (1) Let $A \subset \mathbb{R}^n$ be a measurable set then $m(A) = \sup{\{m(F):F\subset A}$ and $F$ closed $\} $ The proof starts taking a compact set $K\subset A$ with $m(K) >0$ . This is possible because if $A$ is bounded, we can use (1) to find a close, bounded set, and therefore a compact one. If $A$ is not bounded, we can guarantee that at least one of these disjoint sets $A \cap (B(0,k) - B(0, k-1))$ for $k \geq 1$ must have a measure greater than $0$ and using (1) again we can guarantee the existence of K. My problem is in that last paragraph. I think get why it works ( $B(0,k) - B(0, k-1)$ is a partition of $\mathbb{R}^n$ , but why not using simply $B(0,k)$ , of increasing size? Is it important that the sets are disjoint? The proof doesnt use that $K$ has that ""shape"". It only uses that $K$ is a compact set contained in $A$ . I think I might not fully understand what measurable sets are. Thanks for your help!","['measurable-sets', 'measure-theory', 'lebesgue-measure']"
3833398,Proof of relationship $S^2−S(a+b+c+d+e)+ab+bc+cd+de+ea=0$ between areas connected to a pentagon,"So recently I've been looking around at some other problems to see if they could help me solve an ongoing problem, and I found a theorem that was mentioned that I feel that might be useful to my attempt at solving the ongoing problem. The problem goes a little something like this: The area of a convex pentagon $ABCDE$ is denoted by $S$ . Let $a$ , $b$ , $c$ , $d$ , $e$ be the areas of $ΔABC$ , $ΔBCD$ , $ΔCDE$ , $ΔDEA$ , $ΔEAB$ ; then prove that $S^2−S(a+b+c+d+e)+ab+bc+cd+de+ea=0$ . Now there wasn't a proof mentioned in that post for this theorem mentioned, and I looked around the web a bit for some context on this theorem, but I couldn't find who made or how to prove it, even after a few hours of searching. I figured I could ask for a bit of help here on solving this, as I haven't been able to make much progress on this problem yet. I initially was trying to find the area of each triangle in terms of two segments and then tried relating that back to the pentagon's area, but I just couldn't make much progress going that way. I would really appreciate it if anyone could give some ideas on proving this problem.","['euclidean-geometry', 'triangles', 'area', 'geometry']"
3833511,How to Evaluate $ \sum_{n=1}^{\infty} \frac{(-1)^n}{n} \sum_{k=1}^{n}\frac{1}{4k-1} $,"How can I evaluate $$ \sum_{n=1}^{\infty} \frac{(-1)^n}{n} \sum_{k=1}^{n}\frac{1}{4k-1} \approx - 0.198909 $$ The Sum can be given also as $$ \frac{1}{2} \int_{0}^{1} \frac{1}{(x+1)\sqrt[4]{(-x)^{3}}}\,\left(\,\tan^{-1}\left(\sqrt[4]{-x}\right)-\tanh^{-1}\left(\sqrt[4]{-x}\right)\,\right) $$ Unfortunately i have not been able to evaluate either the Sum or the Integral using methods I know. Mathematica gives really weird results for the integral. Is there a closed form for this Sum/Integral? Thank you kindly for your help and time. EDIT For those of you that still care about the question i was able to find the following closed form. I will let the above $ sum = S $ and as such $$ S =  C-\frac{\pi^2}{16}+\frac{\ln^2(\sqrt{2}-1)}{4}+\frac{\pi \ln (\sqrt{2}-1)}{4} $$ Where $C$ denotes Catalan's constant. Thank you very much once again to those who provided answers! EDIT #2 (Proof as Requested ) I will not show this one (too much typing) but , $$S= \sum_{n=1}^{\infty} \frac{(-1)^n}{n} \sum_{k=1}^{n}\frac{1}{4k-1} = 4 \sum_{n=1}^{\infty} (-1)^n \sum_{k=0}^{\infty} \frac{1}{(4k+3)} \frac{1}{(4k+(4n+3))} $$ next expand the terms on the RHS into a Matrix as such : $$
\begin{matrix} 
\color{red}{+(\frac13\times\frac13)} & -(\frac13\times\frac17)& +(\frac13\times\frac1{11})& -(\frac13\times\frac1{15}) \\
\color{blue}{-(\frac17\times\frac13)} & \color{red}{+(\frac17\times\frac17)} & -(\frac17\times\frac1{11}) & +(\frac17\times\frac1{15})\\
\color{blue}{+(\frac1{11}\times\frac13)} & \color{blue}{-(\frac1{11}\times\frac17)}&\color{red}{+(\frac1{11}\times\frac1{11})}&-(\frac1{11}\times\frac1{15})\\ 
\end{matrix}
$$ The black terms x 4 are our desired sum I then added the red and blue terms to  ""complete""  the
matrix One can then see that the matrix (complete) may be given as $$ \left(\frac13-\frac17+\frac1{11}...\right)\left(\frac13-\frac17+\frac1{11}...\right) $$ which is just $$P= \left(\sum_{n=0}^{\infty} \frac{(-1)^n}{4n+3}\right)^{2} = \left(\frac{\pi}{4 \sqrt{2}}+\frac{\ln(\sqrt{2}-1)}{2 \sqrt{2}}\right)^2 $$ So $$ P = \color{red}{\sum_{n=1}^{\infty} \frac{1}{(4n-1)^2}} + \color{blue}{\text{Blue terms}} + \text{Black terms} $$ but one can see that $ \color{blue}{\text{Blue terms}} = \text{Black terms} $ Therefore : $$ P = \frac{\pi^2}{16}-\frac{C}{2}+\frac{S}{2} $$ Solve for S to find : $$ S =  C-\frac{\pi^2}{16}+\frac{\ln^2(\sqrt{2}-1)}{4}+\frac{\pi \ln (\sqrt{2}-1)}{4} $$ where $C$ denotes Catalan's Constant.","['integration', 'catalans-constant', 'sequences-and-series']"
3833518,"Understand part of a proof to show that if K is normal in G, then K is the kernel of a homomorphism","Let $K$ be a normal subgroup of $G$ . Then we can show that $K$ is the kernel of a homomorphism with domain group $G$ . I found a proof for this, but I don't fully get it yet. The proof works like this: Define a mapping $\phi$ , such as: \begin{align*}
\phi: (G, \circ) &\rightarrow (G/K, \cdot) \\
               x &\rightarrow xK
\end{align*} Where $G$ is the domain group and $G/K$ is the codomain group with set composition as binary operation. We know $G/K$ exists, since $K$ is normal in $G$ . Then we need to show that $\phi$ is indeed a homomorphism. That part is clear, so I skip it. Assuming $\phi$ is a homomorphism, we now need to show that $Ker \phi = K$ , as claimed. Now in the book this is done like so: \begin{align*}
Ker \phi &= \{ x \in G : \phi(x) = K \} \\
         &= \{ x \in G : xK = K \} \\
         &= K
\end{align*} I don't fully grok why $\{ x \in G : xK = K \} = K$ . I think this is because of the closure property of the subgroup $K$ of $G$ ? Because if there would be a $x \in G$ such that $xK \ne K$ , then $x \not \in K$ . Otherwise, if $x \in K$ , but for some $k \in K$ we find $xk \not \in K$ , then $K$ can't be closed under its binary operation. Is that understanding correct?","['proof-explanation', 'group-theory', 'abstract-algebra', 'normal-subgroups']"
3833635,Limit related to $ f(x) = \prod_{i = 1}^x \left( \sin\left( i \frac{\pi}{n}\right) + \frac{5}{4}\right) $?,"Let $n$ be a positive integer.
Let $b = 2 n - 1$ .
Let $x$ be a positive integer. Define $f(x)$ as : $$ f(x) = \prod_{i = 1}^x \left( \sin\left( i \frac{\pi}{n}\right) + \frac{5}{4}\right) $$ Then it appears that $$ f(b) = \frac{4}{5} + C(n)$$ And $C(n)$ is close to zero. In fact $$ \lim_{n \to \infty} C(n) = 0 $$ How do we prove this ??","['asymptotics', 'real-analysis', 'products', 'limits', 'trigonometry']"
3833699,"Prove that $x^3$ is irrational, then $x$ is irrational.","Above seems to be a very simple proof but I want to verify that by doing by contraposition is of the many right ways to go about it. This question is in the form $p \rightarrow q$ . Definition of a rational number is $a \in \mathbb Z, b \in \mathbb Z_{\ge0}, \space$ and $\space (a \neq b)$ then $\frac{a}{b}$ Proof by Contrapositive: Contrapostive ( $\lnot q \rightarrow \lnot p)$ $\lnot q \equiv$ $x$ is rational, and $\lnot p \equiv$ $x^3$ is rational. By stating $x$ is rational then $x = \frac{a}{b}$ , then $x^3 = \frac{a^3}{b^3}$ , meaning $x$ and $x^3$ are both rational. Taking the contrapositive of this statement we conclude that if $x$ is irrational then $x^3$ is irrational. $\square$ My question: Is this the right way to go about proving this statement by this method?","['algebra-precalculus', 'solution-verification']"
3833734,Cardinality of Two Sets with Empty Sets,"I know cardinality is counting the number of elements in a set. $\{ \emptyset, \{ \emptyset\}\}$ - I said that the cardinality of the set above was $2$ because $\emptyset$ is one element, and $\{\emptyset\}$ is another. $\{ \emptyset, \{\emptyset\}, \{\emptyset, \{\emptyset\}\}\}$ - With this set I said the cardinality was $4$ because there is four elements. $2$ from what I previously stated and the other $2$ from $\{\emptyset, \{\emptyset\}\}$ , it being two elements. I don't understand cardinality with $\emptyset$ well. I know an empty set can be a set of its self and that the first one is the power set of a power set of an empty set, $P(P(\emptyset))$ . Is my understanding flawed with cardinality? My logic for coming to my conclusions valid?","['elementary-set-theory', 'discrete-mathematics']"
3833778,"Given a positive integer $n$, some straight lines and lattice points such... Prove that the number of the lines is at least $n(n+3)$.","Given a positive integer $n$ and some straight lines in the plane
such that none of the lines passes through $(0,0)$ , and such that every lattice point $(a,b)$ , where $ 0\leq a,b\leq n$ are integers and $a+b>0$ , is contained
by at least $a+b+1$ of the lines. Prove that the number of the lines is at
least $n(n+3)$ . Solution: Let us count the number of pairs $({\bf line},{\bf point})$ on two ways. Say we have $l$ lines and each can pass at most $n+1$ points. Say $k$ of them pass through $n+1$ points, then $k\leq 2n+1$ . So all of them pass at most through $$k(n+1)+n(l-k) \leq (l+2)n+1$$ points, so we have at most $(l+2)n+1$ pairs $({\bf line},{\bf point})$ . On the other hand all points pass at least thorugh $$\sum_{a=0}^n\sum_{b=0}^n (a+b+1)-1 = n^3+3n^2+3n  $$ lines, so we have at list that many pairs $({\bf line},{\bf point})$ . So we have $$n^3+3n^2+3n\leq (l+2)n+1\implies l\geq n(n+3)$$ and thus a conclusion. Is there a polynomial aproach to this problem? (Like defining some polynomials which wanish on some set of points...)","['contest-math', 'alternative-proof', 'combinatorics', 'algebraic-combinatorics']"
3833782,Why is $\lim_{x\rightarrow 1} \sin (x^2 - 1) / (x^2 - 1) = \lim_{x\rightarrow 0} \sin(x)/x$?,"I'm confused how to prove that $\lim_{x\rightarrow 1} \sin (x^2 - 1)  / (x^2 - 1) = \lim_{x\rightarrow 0} \sin(x)/x$ . Assuming $\lim_{x\rightarrow 1} \sin (x^2 - 1)  / (x^2 - 1) = l$ , then there's $\delta > 0$ s.t. for all $x$ , if $0 < |x - 1| < \delta$ implies that $ | \sin (x^2 - 1)  / (x^2 - 1) - l| < \epsilon $ for all $\epsilon > 0$ . My approach: if we take $|x| < \delta$ , then $| (x + 1) - 1| < \delta$ this implies that $| \sin (x^2 - 2x)  / (x^2 - 2x) - l| < \epsilon$ , which probably isn't the route I need to take. Intuitively it makes sense, since $x^2 - 1$ approaches $0$ , then we should be able to replace it with its limit.","['limits', 'calculus', 'limits-without-lhopital']"
3833819,"Write $\cos(5x)$ as a function of $\cos(x)$, answer with a polynomial.","Write $\cos(5x)$ as a function of $\cos(x)$ , answer with a polynomial. $$e^{i\cdot5x} = \cos(5x) + i\sin(5x)$$ $$\cos(5x) + i\sin(5x) = (\cos(x) + i\sin(x))^5$$ and using the binomial theorem I think the answer is the real part of the expansion but I fail to see it. The answer is $16x^5-20x^3+5x$ .",['trigonometry']
3833874,Proving that $\sin{2y}(\tan{x}+\tan{y}) = 1$ implies $y=\frac{\pi}{2}-\frac{x}{2}$,"How can I show manipulate the first equation to get the second (when $0\leq x\leq \frac{\pi}{2}$ and $0\leq y\leq \frac{\pi}{2}$ )? $$\sin{2y}(\tan{x}+\tan{y}) = 1$$ $$y=\frac{\pi}{2}-\frac{x}{2}$$ The equations are equal, by the way ( https://www.desmos.com/calculator/xwr9c33o3a ).","['trigonometry', 'calculus', 'algebra-precalculus']"
3833902,Discover the reason why two iterated integrals with different orders are not equal,"Consider on $[0,1]^{2}$ the function defined by $$f(x,y):=\dfrac{x^{2}-y^{2}}{(x^{2}+y^{2})^{2}}.$$ I have computed out the iterated integrals are not the same if we swap the order of the integral. That is, $$\int_{0}^{1}\Big(\int_{0}^{1}f(x,y)dx\Big)dy\neq \int_{0}^{1}\Big(\int_{0}^{1}f(x,y)dy\Big)dx.$$ Indeed, we could see that $$LHS=-\dfrac{\pi}{4}\ \text{while}\ RHS=\dfrac{\pi}{4}.$$ However, I want to figure out why they are not equal in the sense of measure theory. That is, there must be something that violates Fubini theorem. I tried to figure it out in the following way: Firstly we can see that $f(x,y)$ is continuous in $y$ and $x$ , and thus is measurable with respect to $x-$ region (if treating $y$ as a constant) and vice versa. So the only thing left is that $f(x,y)$ is not integrable with the product measure on $[0,1]\times [0,1]$ . I tried to show $$\int_{[0,1]\times [0,1]}|f(x,y)|dxdy=\infty,$$ in the following way. Firstly, we replace $x:=r\cos\theta$ and $y:=r\sin\theta$ , so that \begin{align*}
\int_{[0,1]\times [0,1]}|f(x,y)|dxdy&=\int_{0}^{2\pi}\int_{0}^{1}\dfrac{|\cos^{2}(\theta)-\sin^{2}(\theta)|}{r^{2}}rdrd\theta\\
&=\int_{0}^{2\pi}|\cos^{2}(\theta)-\sin^{2}(\theta)|d\theta\int_{0}^{1}\dfrac{1}{r}dr
\end{align*} Now the problem comes, $\int_{0}^{1}\dfrac{1}{r}dr=\infty$ , and thus the whole integral is $\infty$ . Is my proof correct? Thank you!","['measure-theory', 'solution-verification', 'lebesgue-integral', 'fubini-tonelli-theorems']"
3833921,$F(n)$ is number of ways to partition set of $n$ without singleton blocks. Prove that $B(n) = F(n) + F(n+1)$,"In this case $B(n)$ is $n$ -th Bell number. To be honest, I would really love to know if there is a combinatorial proof for that. If there is not, other proofs are appreciated too.","['set-partition', 'bell-numbers', 'combinatorics', 'combinatorial-proofs']"
3833956,Estimating $|\int_{\beta}\exp(iz^2)\ dz|$,"Let $R > 0$ and consider a curve $$\beta(t) = R\exp(it), \ \ \ \ \ \ \ \ \ 0 \leq t \leq \pi/4.$$ I need to show that $$\left|\int_{\beta}\exp(iz^2)\ dz \right| \leq \frac{\pi(1-\exp(-R^2))}{4R}.$$ Attempt:
Well, I thought I will just use the ML-estimate, but I got stuck. I have calculated the length of the arc of the curve $\beta$ : $$l(\beta) = \int_0^{\pi/4}|\beta^{\prime}(t)|dt = \int_0^{\pi/4}|iR\exp(it)|\ dt = \int_0^{\pi/4}R^2\ dt = \frac{\pi R^2}{4}.$$ Now I would like to find an $M > 0$ such that $|\exp(iz^2)|$ for any $z \in \ \text{Image}\ \beta $ . We have $|\exp(iz^2)| = \exp(-R^2\sin(2t))$ . Using $\sin(2t) \geq \frac{4}{\pi}t$ (which I dont understand how that is true), for any $t \in [0, \pi/4]$ , it yields that $$|\exp(iz^2)| \leq \exp\left(-R^2\frac{4}{\pi}t\right).$$ From here, I don't know how to proceed.","['complex-analysis', 'complex-integration']"
3833959,An equation for Killing vector fields,"Let $(M,g)$ be Riemannian manifold with Levi-Civita Connection $\nabla$ . We know that a vector field $X$ is a Killing vector field if and only if it satisfies the Killing equation (written in abstract index notation) \begin{equation}
    \nabla_{\mu}X_{\nu} + \nabla_{\nu}X_{\mu} = 0
\end{equation} Now I'd like to show that $X$ also satisfies the equation \begin{equation*}
\Delta_{g}X^{\mu} + {R^{\mu}}_{\nu}X^{\nu} = 0 \tag{$\heartsuit$}
\end{equation*} where $\Delta_{g} = \nabla^{\mu}\nabla_{\mu}$ is the Laplace-Beltrami operator and $R_{\mu \nu}$ is the Ricci tensor. The derivation should be straightforward. Indeed, if we apply $g^{\lambda \nu} \nabla^{\mu}$ to both sides of the Killing equation, we can commute the order of covariant differentiation and get \begin{align*}
g^{\lambda \nu}\nabla^{\mu}\nabla_{\mu}X_{\nu} + g^{\lambda \nu}\nabla^{\mu}\nabla_{\nu}X_{\mu} &= \Delta_{g}X^{\lambda} + \nabla^{\mu}\nabla^{\lambda}X_{\mu}\\
& = \Delta_{g}X^{\lambda} + \nabla^{\lambda}\nabla^{\mu}X_{\mu} + {R^{\mu \lambda}}_{\mu \nu}X^{\nu}\\
& = \Delta_{g}X^{\lambda}+ \nabla^{\lambda}\text{div}X + {R^{\lambda}}_{\nu}X^{\nu}\\
& = \Delta_{g}X^{\lambda}+ {R^{\lambda}}_{\nu}X^{\nu}\\
& = 0
\end{align*} where the second to last equality follows from the fact that a Killing vector field is divergence free. However, I'm not sure about the third equality, that \begin{equation}
 \nabla^{\lambda}\nabla^{\mu}X_{\mu} =  \nabla^{\lambda}(\nabla^{\mu}X_{\mu}) = \nabla^{\lambda}\text{div}X
\end{equation} The main confusion comes from whether we can evaluate the term $\nabla^{\mu}X_{\mu}$ first, and then apply  the outer convariant differentiation. On the other hand, I'm pretty sure $(\heartsuit)$ holds, since it will serve as a key step to prove the fact that $\Delta_{g}$ commutes with Killing vector fields on Riemannian manifolds.","['riemannian-geometry', 'differential-geometry']"
3834037,From disintegration to conditioning,"There is a paper ""Conditioning as disintegration"" by J. T. Chang and D. Pollard , which seems to construct the regular conditional probability from the disintegration . In particular, from Definition 1, Theorem 1 and Theorem 2.(iii) in that paper, we can summarize a theorem as follows: Theorem. Let $\Omega$ be a Polish space, $\mathcal F = \mathcal B(\Omega)$ be the Borel $\sigma$ -field for $\Omega$ , and $\mathbf P$ be a probability measure on $(\Omega,\mathcal F)$ . Let $(E,\mathcal E)$ be a measurable space, with $\mathcal E$ countably generated and containing all the singleton sets. Let $X:(\Omega,\mathcal F) \to (E,\mathcal E)$ be a random element. Denote by $P_X := X_*\mathbf P = \mathbf P\circ X^{-1}$ the pushforward measure of $X$ on $(E,\mathcal E)$ . Then there is a family $\{\mathbf P^x\}_{x\in E}$ of probability measures on $(\Omega,\mathcal F)$ , such that: For every $x\in E$ , the probability measure $\mathbf P^x$ concentrates on the event $\{X = x\}$ . For all $A\in\mathcal F$ , the mapping $\mathbf P^\cdot(A): (E,\mathcal E)\to [0,1]$ is measurable. For all $A\in\mathcal F$ and $B\in\mathcal E$ , \begin{equation}
  \mathbf P\left(A\cap X^{-1}(B)\right) = \int_B \mathbf P^x(A) P_X (dx).
\end{equation} Moreover, the family $\{\mathbf P^x\}_{x\in E}$ is uniquely determined up to an almost sure equivalence: if $\{\mathbf Q^x\}_{x\in E}$ is another family of probability measure on $(\Omega,\mathcal F)$ that satisfies above conditions, then \begin{equation*}
  P_X\{x\in E: \mathbf P^x \ne \mathbf Q^x\} = 0.
\end{equation*} Here is the problem . Consider the special case that $E=\Omega$ and $\mathcal E$ is a sub- $\sigma$ -field of $\mathcal F$ that contains all singletons. Since $\Omega$ is second countable, its Borel $\sigma$ -field $\mathcal F$ must be countably generated and contain all singletons . As a sub- $\sigma$ -field of $\mathcal F$ , $\mathcal E$ is also countably generated. Let $X = \mathrm{Id}$ . Then $P_\mathrm{Id} = \mathbf P$ and $\sigma(\mathrm{Id}) = \mathcal E$ . Now all assumptions in the theorem are fulfilled. Hence, we get a $\mathbf P$ -a.s. unique family of probability measures $\{\mathbf P^\omega\}_{\omega\in\Omega}$ on $(\Omega,\mathcal F)$ satisfying: For every $\omega\in\Omega$ , the probability measure $\mathbf P^\omega$ concentrates on the singleton $\{\omega\}$ . For all $A\in\mathcal F$ , the mapping $\mathbf P^\cdot(A): (\Omega,\mathcal E)\to [0,1]$ is measurable. For all $A\in\mathcal F$ and $B\in\mathcal E$ , \begin{equation}
  \mathbf P\left(A\cap B\right) = \int_B \mathbf P^\omega(A) \mathbf P (dx).
\end{equation} The statements 2 and 3 are completely the same as the formulation of conditional probability , that is, $\mathbf P^\omega(A) = \mathbf P(A\mid \mathcal E)(\omega)$ . However, if we combine them with the statement 1, then there are something quite strange. Indeed, since $\mathbf P^\omega$ concentrates on $\{\omega\}$ , we have $\mathbf P^\omega(A) = \mathrm{1}_A(\omega)$ for all $A\in\mathcal F$ , while this should hold only for $A\in\mathcal E$ since $\mathbf P^\omega$ is the conditional probability by statement 3. Besides, the mapping $\mathbf P^\cdot(A) = \mathrm{1}_A: (\Omega,\mathcal E)\to [0,1]$ is measurable only for $A\in\mathcal E$ , but not for all $A\in\mathcal F$ claimed in statement 2. So where does it go wrong? Any comments or hints will be appreciated. TIA... EDIT: Here are some further remarks: I just claimed that ""as a sub- $\sigma$ -field of $\mathcal F$ , $\mathcal E$ is also countably generated"". This is wrong. See e.g., here for a counterexample. Thanks to the comment by @aduh, the problem reduce to whether it must be $\mathcal E = \mathcal F$ ? Or does there exist a proper sub- $\sigma$ -field of $\mathcal F$ that is countably generated and contains all singletons? I post this as another question in Math.SE . Conclusion: Under my assumptions, $\mathcal E$ must coincide with $\mathcal F$ . So the problem is trivial. See the accepted answer given by @GEdgar in the ""another question"" I mentioned for details.","['measure-theory', 'conditional-probability', 'conditional-expectation', 'probability-theory', 'probability']"
3834051,Taylor expansion for curve in $\mathbb{R}^3$,"Let $\gamma:I\rightarrow\mathbb{R}^3$ be a curve parametrised by arclength. I want to calculate the taylor expansion using the curvature $$\kappa_\gamma:=\| \ddot\gamma \|$$ and torsion $$\tau_\gamma:=\langle \dot\eta_\gamma,b_\gamma\rangle$$ I'd be very happy, if someone could look over it and tell, if I've done following correct. First of all, $$\Big(\dot\gamma,\frac{\ddot\gamma}{\|\ddot\gamma\|},\dot\gamma\times\frac{\ddot\gamma}{\|\ddot\gamma\|}\Big)=\Big(\dot\gamma,\eta_\gamma,b_\gamma\Big)$$ is a positive oriented orthonormal basis of $\mathbb{R}^3$ . The taylor expansion is $$\gamma(t)=\gamma(t_0)+(t-t_0)\dot\gamma(t_0)+\frac{1}{2}(t-t_0)^2\ddot\gamma(t_0)+\frac{1}{6}(t-t_0)^3\dddot\gamma(t_0)+(t-t_0)^4 o(t-t_0)$$ I find $$\ddot\gamma=\kappa_\gamma\eta_\gamma$$ and therefore $$\dddot\gamma=\dot\kappa_\gamma\eta_\gamma+\kappa_\gamma\dot\eta_\gamma$$ Using the orthonormal basis I find $$
\dddot\gamma=\langle\kappa_\gamma\dot\eta_\gamma,\dot\gamma\rangle\dot\gamma+\langle\dot\kappa_\gamma\eta_\gamma,\eta_\gamma\rangle\eta_\gamma+\langle\kappa_\gamma\dot\eta_\gamma,b_\gamma\rangle b_\gamma=-\kappa_\gamma^2\dot\gamma+\dot\kappa_\gamma\eta_\gamma+\kappa_\gamma\tau_\gamma b_\gamma
$$ Therefore the taylor expansion of $\gamma$ in $t_0$ is $$\gamma(t)=\gamma(t_0)+(t-t_0)\dot\gamma(t_0)+\frac{1}{2}(t-t_0)^2\Big(\kappa_\gamma\eta_\gamma\Big)(t_0)+\frac{1}{6}(t-t_0)^3\Big(-\kappa_\gamma^2\dot\gamma+\dot\kappa_\gamma\eta_\gamma+\kappa_\gamma\tau_\gamma b_\gamma\Big)(t_0)+(t-t_0)^4 o(t-t_0)$$ Thanks for your attention!","['curves', 'curvature', 'differential-geometry']"
3834085,Question posed in Spivak Chapter 14 that $f$ cannot be a derivative,"I'm having trouble working out the reasoning behind a question posed in Spivak's Calculus Chapter 14, where he discusses the Fundamental Theorem of Calculus. The excerpt where this is from is as follows: ... A function $f$ may be integrable without being the derivative of another function. For example, if $f(x) = 0$ for $x \ne 1$ and $f(1) = 1$ , then $f$ is integrable, but $f$ cannot be a derivative (why not?) I tried working it out to verify whether $f$ is differentiable by using the definition of a derivative, but realised that the statement was that $f$ cannot be a derivative, not that $f$ is not differentiable (unless there's something I'm missing out here?). Any insights would be greatly appreciated!","['integration', 'calculus', 'derivatives']"
3834095,Is Accuracy differentiable for neural network models?,"I saw many classifiers aim to obtain a high accuracy in deep learning. And people use different kinds of loss functions, like cross-entropy, L1, or L2 loss. The accuracy is defined as $$ Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$$ Is it possible to directly maximize the accuracy as loss function?  Can we solve $$ max_\theta \qquad \text{Accuracy}(y, y')$$ directly? Here $y$ is the true label and $y'$ is the predicted value.","['optimization', 'functions', 'derivatives', 'neural-networks']"
3834100,The relation between uniform integrability and dominated convergence theorem in the case of counting measure,"I want to discover the analog between uniform integrability (UI) and the dominated convergence theorem (DCT) for infinite series. An infinite series is an integral with respect to counting measure. That is, $\sum_{k=0}^{\infty}f(k)=\int_{\mathbb{Z}_{\geq 0}}f(k)\mu(dk),$ where $\mu$ is the counting measure.  We can then say a function $f$ is integrable with respect to the counting measure if $\sum_{k=0}^{\infty}|f(k)|=\int_{\mathbb{Z}_{\geq 0}}|f(k)|\mu(dk)<\infty.$ My first step is to reformulate DCT and UI. For DCT, we are consider a sequence of $\mu-$ integrable function $f_{n}(k)$ such that $f_{n}(k)\longrightarrow f(k)$ as $n\rightarrow\infty$ , and for each $n$ , $|f_{n}(k)|\leq g(k)$ for some $\mu-$ integrable $g(k)$ . Then, $$\lim_{n\rightarrow\infty}\sum_{k=0}^{\infty}f_{n}(k)=\sum_{k=0}^{\infty}\lim_{n\rightarrow\infty}f_{n}(k)=\sum_{k=0}^{\infty}f(k).$$ However, I don't know how to formulate the UI. The definition UI I have is that: A family $\{f_{\alpha\}}$ of integrable function is uniform integrable if for any $\epsilon>0$ , there is a $\delta>0$ such that whenever $\lambda(A)<\delta$ , $\sup_{\alpha}\int_{A}|f_{\alpha}|\lambda(dx)<\epsilon,$ where $\lambda$ here is a general measure. I can reformulate this without problem, but I don't understand what does it mean for $\mu(A)<\delta$ when $\mu$ is a counting measure. I read some online notes saying that DCT is a consequence of UI and Egoroff Theorem, I understand this, since Egoroff will give you a set $A$ on which the convergence is uniform and UI can make the integral on $A^{c}$ to be negligible. But this requires the measure space to be finite. I am not sure if we can apply this to counting measure, i.e. is $(\mathbb{N},\mathcal{P}(\mathbb{N}),\mu)$ a finite measure space? Even I can answer this question, I don't want to stop here.I believe that  there must be something special in the case of counting measure, since $\mu(A)<\delta$ in the case of counting measure is still mysterious to me, but for now I don't know where to continue. Thank you! Edit: Example Okay, I worked some examples, but I still don't quite understand what fails. For example, consider the sequence $f_{n}(x)$ on the integer $X:=\{1,2,3,\cdots\}$ , defined by $$f_{n}(x)=\left\{
  \begin{array}{ll}
\frac{1}{n},\ \ \text{if}\ \ x=1,2,\cdots, n\\
0,\ \ \text{if}\ \ x\geq n+1.
\end{array}
\right.$$ Note that $\sum_{k=1}^{\infty}f_{n}(x)=1$ for every $n$ , but $\lim_{n\rightarrow\infty}f_{n}(x)=0$ for every $x$ , so we cannot interchange the limit and summation. As suggested by the comment, uniform integrability is guaranteed in the case of counting measure, so What fails here? Edit: Potential Answer As Rivers Mcforge said, the example above does not satisfy the boundedness requirement in DCT. Along with the comment of Lorenzo, I found a connection between the boundedness requirement and tightness. As Lorenzo suggested, the sequence in above example is not $\mu-$ tight, and since we are over an infinite measure space, the Vitali convergence theorem needs the tightness. (The uniform integrability was given to us for free over our space, as suggested by both answers below). Eventually, I found that in the case of our counting measure space, a sequence that satisfies DCT will also satisfy Vitali. In other words, we can use Vitali to prove DCT (in the case of our counting measure space $(\mathbb{N},\mathcal{P}(\mathbb{N}),\mu)$ ). Indeed, recall that for any measure $\lambda$ and any measurable set $E$ (not necessarily of finite measure), if $f$ is $\lambda-$ integrable over $E$ , then for each $\epsilon>0$ , there is a set of finite measure $E_{0}$ for which $$\int_{E\setminus E_{0}}|f(x)|\lambda(dx)<\epsilon.$$ Now, suppose $f_{n}(x)$ is an sequence of functions on $X$ that converges $\mu-$ almost surely to $f(x)$ . It is for free that $f_{n}(x)$ is uniformly integrable. If $|f_{n}(x)|\leq g(x)$ for all $n$ and $x$ , where $g(x)$ is $\mu-$ integrable, then by the above recalled fact, for each $\epsilon>0$ , there is a subset $X_{0}$ of $X$ of finite measure for which $$\int_{E\setminus E_{0}}|f_{n}(x)|\mu(dx)\leq \int_{E\setminus E_{0}}|g(x)|\mu(dx)<\epsilon,\ \text{for all}\ n.$$ Hence, the family $\{f_{n}(x)\}$ is tight. Then, it follows from Vitali that we can interchange the summation (the $\mu-$ integral) with the limit of $n\rightarrow\infty.$ Thus, the confusion of DCT follows. I am not sure if tightness can conversely imply the boundedness requirement in DCT.","['lebesgue-integral', 'measure-theory', 'sequences-and-series', 'real-analysis']"
3834161,"Given a self-map $h$ of a (closed?) manifold, is there a vector field $\xi$ with flow $\Phi_t$ such that $h = \Phi_1$?","Given a (closed?) connected Riemannian manifold $M^n$ and a self-diffeomorphism $h: M \to M$ , is it necessarily the case that there is a differential equation/smooth, tangent vector field $\xi$ on $M$ so that the flow $\Phi_t$ of $\xi$ has $h = \Phi_1$ ? That is, can we always extend a discrete-time dynamical system to a continuous-time one? Thanks in advance. EDIT: Here is a follow-up question: Follow-Up to given a self-map $h$ of a (closed?) manifold, is there a vector field $\xi$ with flow $\Phi_t$ such that $h=\Phi_1$?","['vector-fields', 'differential-topology', 'ordinary-differential-equations', 'dynamical-systems']"
3834190,colouring edges of an icosahedron in a certain way,"Find the number of ways to colour the 30 edges of an icosahedron with three colours so that for any triangular face, two edges are the same colour and the other is a different colour. I think the answer is $2^{20}3^{10},$ but I'm not sure how to show this. Let $v$ and $w$ be antipodal vertices on the icosahedron. Let $S_v$ be the set of edges coincident with $v$ and $T_v$ be the set of edges coincident with the opposite end of two edges in $S_v$ that form a pentagon around $v.$ Define $S_w$ and $T_w$ similarly. Let $U$ be the set of $10$ remaining edges. There are $3^{10}$ ways to colour the edges of $U.$ Also, for each possible way, there are $2^{10}$ ways to colour the edges of $T_v$ and $T_w$ ; given an edge in $T_v \cup T_w,$ it forms a triangle with $2$ other edges in $U.$ This triangle may have two edges of the same colour, in which case we choose one of the $2$ remaining colours, and if the two edges are different colours, we choose one of the $2$ colours. However, I'm not sure how to show that there are $2^{10}$ ways to colour the edges of $S_v\cup S_w$ .","['graph-theory', 'combinatorics']"
3834198,How to extracting formula from a number sequence,"I have following sequence: | Term  | Value |
|-------+-------+
| 0     | 0     |
| 1     | 1     |
| 2     | 2     |
| 3     | 2     |
| 4     | 3     |
| 5     | 3     |
| 6     | 3     |
| 7     | 3     | and so on... which the relation is T(n)=T(floor(n/2))+1, T(0)=0 , I am wondering how to extract the exact function of it.","['functions', 'recurrence-relations']"
3834230,Interpretation of Gisarnovs theorem,"Ive found a statement of Girsarnovs theorem that looks as follows ""Every $P$ -semimartingale is a $Q$ semimartingale, in particular if $M$ is a local martingale then $\hat{M}_{t}=M_{t}-D_{t}^{-1}[M,D]_{t}$ is a $Q$ local martingale. Let $A_{t}=D_{t}^{-1}[M,D]_{t}$ Lets say $X=M_{1}+B$ is the semimartingale decomposition w.r.t $P$ , do we just add and remove the above $A$ , to get $X=M_{1}-A+A+B$ to get a $Q$ semimartingale? How is X written as a $Q$ semimartingale? Or how do we see that it is a $Q$ semimartingale?","['stochastic-analysis', 'stochastic-processes', 'probability-theory', 'local-martingales']"
3834291,Can we find $ \lim_{n \to \infty } n\left ( \frac{1}{n} - \frac{1}{n+1} + \frac{1}{n+2} - \frac{1}{n+3} + ... \right ) $?,"I have got one method, If we consider $ a_{n} = \int_{0}^{1} \frac{nx^{n-1}}{1+x} \ dx $ Then, $ \lim_{n \to \infty } n\left ( \frac{1}{n} - \frac{1}{n+1} + \frac{1}{n+2} - \frac{1}{n+3} + ... \right ) = \lim_{n \to \infty }a_{n} = \frac{1}{2} $ But can anyone attack this problem in a different & more standard way?","['sequences-and-series', 'real-analysis']"
3834312,Does any undirected graph admits a doubly stochastic matrix?,"Given an undirected graph, can we always find a way to assign weights to every edge so that the adjacent matrix is double stochastic matrix? (edit: We allow the matrix has positive element on (i,i), so strictly speaking, it is not an adjacent matrix) The background is about distributed optimization. We can see each node as a computer, and they want to exchange information(like gradients or parameters) via edges in the connected graph to solve an optimization problem, for example, a machine learning problem. So, there is a weight matrix W, whose (i,j) element is the weight of information sent from node i to node j. Because node i can use its own information, so diagonal elements of W should be positive. The question is can we always find a doubly stochastic matrix W.","['matrices', 'graph-theory']"
3834318,If $f(x)=\frac{x^3}{2}+1-x\int_0^x g(t) dt$ and $g(x)=x-\int_0^1f(u) du $ then the minimum distance between $f(x)$ and $g(x)$ is?,The way I thought to solve this problem is to find $f(x)$ and $g(x)$ . So $$f(x)=\frac{x^3}{2}+1-x\left[\int_0 ^x\left(x-\int_0^1 f(u) du\right)\right]$$ This gives $$f(x)=1-x^2\int_0^1 f(u) du$$ Now dividing both sides by $x^2$ and differentiating we get $$f'(x)-\frac2 x f(x)=-\frac 2 x$$ Solving this we get $$f(x)= 1+Cx^2$$ where $C$ is a constant. Now my question is how do I find $C$ ? I do not have a initial condition. or maybe $C$ isn't required after all? It seems I cannot solve for minimum distance without $C$,"['integration', 'derivatives', 'real-analysis']"
3834412,Fundamental group of quotient of subspace of $\mathbb{R}^3\times\mathbb{R}^3$,"This is exercise 12-6 from J. Lee's Introduction to Topological Manifolds. Let $E=\{(x,y)\in\mathbb{R}^3\times\mathbb{R}^3:x\neq y\}$ , and define an equivalence relation by $(x,y)\sim(y,x)$ for all $(x,y)\in E$ . Compute the fundamental group of $E/\sim$ . This is the first time I'm asked to compute the fundamental group of something that I can't seem to visualise, and I am not sure how to approach it. Seifert-van Kampen does not seem useful for such a space. What I think I want to do is find a group $G$ such that $q:F\to F/G=E/\sim$ is a covering map for a simply connected $F$ , so that the fundamental group is isomorphic to $Aut_q(F)=G$ . But even then, I am not quite sure how to do this. Can this space be visualised somehow? If not, how would one generally approach such a problem where one's visualisation is insufficient, as I guess it is in most worthwhile problems? I would appreciate some advice on this.","['general-topology', 'fundamental-groups', 'algebraic-topology']"
3834425,Differentiate with Kronecker product,"Acutually,
I have a function that : $$\operatorname{tr}(\mathbf{M}(\mathbf{B}\otimes\mathbf{A}))$$ where $M$ and $B$ are constant matrix while $A$ is my variable. I want to have this : $$d \operatorname{tr}(\mathbf{M}(\mathbf{B}\otimes\mathbf{A})) = \operatorname{tr}(\mathbf{G}d\mathbf{A})$$ So, How to solve $\mathbf{G}$ ?","['kronecker-product', 'derivatives', 'differential-geometry']"
3834441,how to show $\frac{\cos (3(x - \frac{\pi}{4}))}{\cos(x - \frac{\pi}{4})} = \frac{\sin 3x - \cos 3x}{\sin x + \cos x}$,"$$\frac{\cos \left(3(x - \frac{\pi}{4})\right)}{\cos(x - \frac{\pi}{4})} = \frac{\sin 3x - \cos 3x}{\sin x + \cos x}$$ My attempt: \begin{align}
LHS &=\frac{\cos \left(3(x - \frac{\pi}{4})\right)}{\cos(x - \frac{\pi}{4})} \\
&= 4\cos^2 (x - \frac{\pi}{4}) - 3 \\
&= 4(\cos x \cos\frac \pi 4 + \sin  \frac \pi 4\sin x )^2 - 3 \\
&=-1 + 4\sin x \cos x \\
RHS &= \frac{\sin 3x - \cos 3x}{\sin x + \cos x} \\
&= \frac{2\sin x - 4\sin^3x - 4\cos^3x + 3\cos x}{\sin x + \cos x} \\
&= -1 + 4\sin x\cos x
\end{align} But it seems that there is a way to show it more efficiently, but I am not sure how.","['alternative-proof', 'trigonometry']"
3834469,Calculating the size of a password search space,"I'm writing something where a character needs to crack a file. Brute force is the only option, and restricting the search space is the only way not to spend eternity on it. The problem Our hero does not know $l$ , the length of the password, but he estimates that it's at least 12 characters long. The alphabet of the search space is uppercase English letters (26), lowercase English letters (26), digits (10), and special characters (33), for a total size of 95 characters. Our hero assumes the password isn't stupid, so he rules out all passwords that do not : contain at least an uppercase character contain at least a lowercase character contain at least a digit contain at least a special character Also, our hero can reasonably guess $k<l$ different characters of the passwords. He knows they are letters, but they can be either upper- or lowercase, and he does not know where they are in the password. The reasons don't matter here, but I need to show the password in the novel; this means that I'd rather be careful with its length, the number of known characters, and to an extent, the speed of the computer used to decrypt the file. This is sci-fi we're talking about, so I do have quite some wiggle room in terms of computing speed (whatever it is, it's gonna be faster than any real supercomputer), but if I'm not careful I might still pick a password that would require a ridiculously fast computer to crack in the short time I need (days); that's why I need to calculate the size of the search space I outlined above, so I can tweak $k$ (known characters) and $l$ (password length) to establish a reasonable computing speed even for fiction. Here's my math. I don't trust myself very much on it so I'd like a sanity check. As said, our hero will check all passwords of length 12 and above. For a generic password of length $l$ with an alphabet of size 95, the search space $N$ should be $$N = 95^l,$$ because each and every of the $l$ characters can take any of the 95 possible values. However, since our hero is checking all passwords of length 12 and above, the search space gets larger: $$N = \sum_{n = 12}^{l} 95^n$$ However, our hero knows that $k$ characters of the password are for sure six different English letters, either uppercase or lower case, though he doesn't know where they are in the password. This means that, of the $l$ characters of the password, only $l-k$ can take any of the 95 values of the alphabet; the remaining $k$ characters can take only fewer. The first of these $k$ characters can have any of 12 values (6 letters $\times$ 2 formats, upper or lowercase); the second can have only 10 (one letter in both its variants has already been chosen), the third only 8, and so on. This parameter depends on $k$ , and we call it $\gamma_k$ : $$\gamma_k = \prod_{n = 0}^{k-1} (l-2n)$$ So, for a password of fixed-length $l$ with $k$ known characters, you'd expect the search space to be $$N_k =  \gamma_k\sum_{n = 12 - k}^{l-k} 95^n,$$ but that doesn't take into account the fact that the $k$ known characters could be placed anywhere in the password. The first one could be placed in $l$ different ways; the second in $l-1$ , and so on, meaning that the actual search space should be $$N_k =  \gamma_k\sum_{n = 12 - k}^{l-k}\frac{(n+k)!}{n!} 95^n.$$ This space is HUGE, but our hero can still reduce it down to $N_k^R < N_k$ thanks to the rules outlined above. To compute $N_k^R$ , I reasoned as follows. The way $N_k$ has been built, at least 6 characters are letters; this means that it's not accounting for any passwords made only of digits, of symbols, or a combination of the two; this kind of password is excluded from the search as per our rules, but we don't need to worry about them because $N_k$ already excludes them. However, we do need to rule out passwords that are purely alphabetical, or alphanumeric without special characters, or ""alphaspecial"" without digits. We also need to rule out passwords where  letters are all lowercase or all uppercase. The number of purely alphabetic passwords given that we known $k$ characters should be $$A_k =  \gamma_k\sum_{n = 12 - k}^{l-k}\frac{(n+k)!}{n!} 54^n,$$ where 54 is 26 + 26, that is an alphabet of only uppercase and lowercase letters. $A_k$ is also accounting for any purely alphabetic passwords that are all uppercase or all lowercase. but not for passwords that include upper- or lowercase letters AND digits or special characters. To account for the latter, we can compute the number of passwords such that: If they contain letters, they're all uppercase Can contain digits or special characters. This number should be $$U_k^M = k!\sum_{n = 12 - k}^{l-k}\frac{(n+k)!}{n!} 69^n,$$ where $k!$ replaces $\gamma_k$ because the $k$ known letters can only be uppercase, and hence the first can be chosen in $k$ different ways, the second in $k-1$ , etc; the remaining letters can't be uppercase, and hence the alphabet they're drawn from consists of only 69 characters rather than 95. The size of the set of passwords such that they can contain digits or special characters, and if they contain letters these are all lowercase, is identical, but we denote it as $L_k^M$ for clarity. Now, we can shrink $N_k$ by subtracting these numbers from it, but there's a small issue: among the passwords that $U_k^M$ and $L_k^M$ are counting, there also are passwords that are purely alphabetical, which are already accounted for by $A_k$ , so we need to add them back lest subtracting them twice. These passwords are $$U_k = L_k = k!\sum_{n = 12 - k}^{l-k}\frac{(n+k)!}{n!} 26^n,$$ that is, purely alphabetical passwords where all characters are either uppercase ( $U_k$ ) or lowercase ( $L_k$ ). Ultimately, I think the reduced space should be $$N_k^R = N_k - L_k^M - U_k^M - A_k + L_k + U_k.$$ Questions Do you agree this is how you compute what I need? Am I leaving anything out\doing anything wrong? I implemented this thing in JavaScript to figure out the best values for $k$ and $l$ (as well as the speed of the decrypting computer). Somehow , it turns out that the larger k is, the longer it takes to decrypt the file , i.e. the more characters you know, the more difficult it is to find the right password, which sounds absurd. This might be because: My implementation is wrong somewhere. My math is wrong somewhere. Knowing what characters are in the password without knowing where they are is effectively worse than not knowing them, because even though $k$ characters have fewer possible values, you need to try them in every possible place and this might end up requiring more attempts than just traditional brute-force. What I'd need from you guys is help determining whether this a math issue or not--if it's not, it's a code problem and I will deal with that on a different SE.","['combinations', 'combinatorics']"
3834480,"$\exists$ countably generated $\mathcal F$, s.t. $\sigma(\{ \{\omega \}: \omega\in\Omega \}) \subsetneqq \mathcal F \subsetneqq \mathcal B(\Omega)$?","Does there exist a countably generated $\sigma$ -field $\mathcal F$ on a second countable space $\Omega$ such that \begin{equation*}
  \sigma(\{ \{\omega \}: \omega\in\Omega \}) \subsetneqq \mathcal F \subsetneqq \mathcal B(\Omega)?
\end{equation*} Here is the motivation, also some clues. One the one hand, since $\Omega$ is second countable, its Borel $\sigma$ -field $\mathcal B(\Omega)$ is clearly countably generated (by a countable topological base). But the $\sigma$ -field generated by singletons $\sigma(\{ \{\omega \}: \omega\in\Omega \})$ is just the countable co-countable $\sigma$ -field, which is not countably generated in general, say e.g., when $\Omega=\mathbb R$ . On the other hand, $\sigma(\{ \{\omega \}: \omega\in\Omega \})$ is countably generated if and only if $\Omega$ is itself a countable set . In this case, $\sigma(\{ \{\omega \}: \omega\in\Omega \})$ coincides with $\mathcal B(\Omega)$ , and there is no such intermediate $\mathcal F$ . So does such intermediate $\mathcal F$ exist in some general cases? Or it definitely does not exist whenever the second countable space $\Omega$ is? Any comments or hints will be appreciated. TIA... EDIT: There should be some appropriate examples for the intermediate $\mathcal F$ , as shown in the comment by @bof and the answer by @Henno Brandsma. But what happens if we force $\Omega$ to be a Polish space , which is stronger and more commonly used in measure theory than second countable space? I think then there will be no such intermediate $\mathcal F$ , but I don't know how to prove it...","['measure-theory', 'descriptive-set-theory', 'general-topology', 'probability-theory', 'probability']"
3834491,Can a triangle ABC be made if $\frac{\cos A}{2}=\frac{\cos B}{3}=\frac{\cos C}{7}$,"I would like to know the simplest approach to find out whether a triangle ABC will be made if $$\frac{\cos A}{2}=\frac{\cos B}{3}=\frac{\cos C}{7}$$ The counterpart questions for sine and tangent can be handled as follows: If $\dfrac{\sin A}{2}=\dfrac{\sin B}{3}=\dfrac{\sin C}{7}$ , we can rule out triangle because by the Sine Rule $a=2k$ , $b=3k$ , $c=7k \implies a+b <c.$ If $\dfrac{\tan A}{2}=\dfrac{\tan B}{3}=\dfrac{\tan C}{7}$ , we can see that a triangle will be made as $\tan A=2k, \tan B =3k,\tan C=7k$ , when inserted in the identity $\tan A+ \tan B+ \tan C= \tan A \tan B \tan C \implies k=\sqrt{2/7}$ .","['trigonometry', 'triangles']"
