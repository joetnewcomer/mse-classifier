question_id,title,body,tags
810246,Show Wright-Fisher Model is a martingale,"Consider successive generations of a population of genes of fixed population size M.
Each gene can be just one of two alleles, type a or A. Let $Y_n \in S = \{0,1,\dots,M\}$ denote the number of type A alleles in generation n under the standard Wright-Fisher model. You may assume that $\{Y_n : n = 0,1,2,\dots\}$ is a Markov chain with finite sample space S and stationary transition probabilities $$p_{ij} = P(Y_{i + 1} = j|Y_n = i) = {M \choose j} \left( \frac{i}{M} \right) ^j \left( 1 - \frac{i}{M} \right) ^ {M - j}$$ I have shown $E(|Y_n|) < \infty$, and need help showing $E(Y_{n+1} | Y_n, \dots, Y_0) = Y_n$. I have attempted: $$E(Y_{n+1} | Y_n, \dots, Y_0) = \sum_{k=1}^M k{M \choose k} \left( \frac{Y_n}{M} \right) ^k \left( 1 - \frac{Y_n}{M} \right) ^ {M - k}$$ and messing around with it but haven't come out with the result. I have an exam (tomorrow actually) and am just doing some last minute revision. Any help will be appreciated. Thanks.","['martingales', 'probability']"
810277,A unsolved puzzle from Number Theory/ Functional inequalities,"The function $g:[0,1]\to[0,1]$ is continuously differentiable and
  increasing. Also, $g(0)=0$ and $g(1)=1$.   Continuity and
  differentiability of higher orders can be assumed if necessary.   The
  proposition on hand is the following: If for all integers $t>0$ and
    for all $r\in(0,1)$, $g(r^{t+1})>g(r)\cdot g(r^t)$, then for all
    $p,q\in(0,1)$, $g(pq)\geq g(p)g(q)$.","['inequality', 'number-theory', 'functional-inequalities', 'functional-equations', 'multiplicative-function']"
810313,Lemma about extra special group of order $p^3$,"I am trying to understand the proof of the following lemma: Assume $P$ is a nonabelian group of order $p^3$ where $p$ is an odd prime. Assume also that $P$ has exponent $p^2$. Then $O_p(\text{Out}(P)) \in \text{Syl}_p(\text{Out}(P))$. I can follow most of the steps in the proof: first you realize that $P$ contains a unique subgroup $Q<P$ where $Q \cong C_p\times C_p$. So $Q$ is characteristic in $P$. Also you can see that $\Phi(P) = [P, P] = Z(P) \le Q$ and $[P, P] \cong C_p$. then one considers the homomorphism $\varphi: \text{Aut}(P)\rightarrow \text{Aut}(P/Q)\times \text{Aut}(Q/[P, P]) \cong C_{p-1}\times C_{p-1}$ and then I have another lemma saying that $\ker{\varphi}$ is a normal $p$-subgroup of $\text{Aut}(P)$, so $\ker{\varphi} \subseteq O_p(\text{Aut}(P))$. You can also argue the converse, that $O_p(\text{Aut}(P)) \subseteq \ker{\varphi}$. And then the proof of the lemma stops. What I don't understand is why $\ker{\varphi} = O_p(\text{Aut}(P))$ leads to the fact that $O_p(\text{Out}(P)) \in \text{Syl}_p(\text{Out}(P))$. Also, I am not sure how $\varphi$ is actually defined.","['p-groups', 'finite-groups', 'group-theory', 'abstract-algebra']"
810318,"Show that $M = \left(\begin{smallmatrix} A & 0 \\ 0 & A^{-1} \\ \end{smallmatrix}\right)$ is a product of elementary matrices, where $A \in GL_n(R)$.","If $A\in GL_n(R)$ , where $R$ is a commutative ring with identity, I would like to prove $$
         M=\begin{pmatrix}
          A & 0 \\
          0 & A^{-1} \\
         \end{pmatrix}\in E_{2n}(R),
$$ i.e., $M$ is a product of elementary matrices, where by elementary matrices I mean the matrices obtained by performing elementary row and column operations on the identity matrix $I$ which are defined by $L_j \mapsto \lambda L_i+L_j$ for $L_j$ a column or a row. I'm trying to solve this question by brute force, making these operations on this matrix and showing this matrix is equivalent to the identity one. I would like to know if there is a simpler and more elegant method to solve this question. Thanks in advance.","['matrices', 'linear-algebra', 'abstract-algebra']"
810363,Can a group with exactly five subgroups be nonabelian?,"I was wondering if there is an example of a nonabelian group $G$ with exactly five subgroups. Let $G$ be a such group, and let $a,b\in G$ be such that $ab\ne ba$. Let us concentrate on the subgroups $\langle a\rangle, \langle b\rangle, \langle ab\rangle$ and $\langle ba\rangle$. If $a$ commute with $ab$ or $ba$, then $a$ would commute with $b$, and similarly for $b$ instead of $a$. Therefore the only possible inclusion between our cyclic subgroups is between $\langle ab\rangle$ and $\langle ba\rangle$; in particular none of the considered cyclic subgroups can be equal to $\{e\}$ or $G$. Thus, the three nontrivial proper subgroups of $G$ are $\langle a\rangle, \langle b\rangle$ and $\langle ab\rangle=\langle ba\rangle$, and $G=\langle a,b\rangle$. Each one of these three subgroups must have prime order and they intersect trivially. Finally, $G$ must be finite (every group with finitely many cyclic subgroups is finite; prove it!) and $|G|$ is multiple of at most three primes. Any ideas to ""concretize"" this hypothetical group?","['finite-groups', 'group-theory']"
810379,Is every unitary representation a direct sum of irreducible subprepresentations?,"I've read that any unitary representation of a compact group decomposes as a Hilbert space direct sum of irreducible representations. In the book I'm reading this is stated as a prong of the Peter-Weyl theorem.  It seems to me that this should just be a straighforward application of Zorn's lemma and trans finite induction since the intersection of a nested sequence of closed invariant subspaces is again closed and invariant (edit: it just occurred to me that this intersection may be trivial).  This doesn't seem to use compactness of G. Is this right or am I missing something? If such an argument doesn't work, can I derive this fact for compact G from the other parts of the Peter Weyl theorem, namely that $L^2(G)$ is a Hilbert space direct sum of the irreducible unitary representations of G (which are finite dimensional)?","['harmonic-analysis', 'representation-theory', 'functional-analysis']"
810391,Mean and Variance of Correct Answers for various ways of Multiple Choice Questions,"I picked this question out of the blue while thinking about multiple choice questions. Consider I set, say $8$ multiple choice questions. Now, I want to find out, out of the three methods below, what is the mean and variance of correct answers the student will get correct, considering that the student selects an answer at random for each question Each question has $5$ possible answers and only $1$ of them is correct. There is a pool of $30$ possible answers, of which $8$ of them are the right answers to each question. The student is notified that no two questions share the same answer. There is a pool of $20$ possible answers. Each question has only one correct answer out of the pool of $20$. However, the student is notified that each answer could be the right answer to up to $2$ questions. The first one is obviously binomial so the mean is $1.6$ and the variance is $1.28$. For the second one, I am thinking of enumerating all possible permutations of $8$ answers, but am not sure how to proceed from there. For the third one, I am not even sure how to begin. Any ideas?","['permutations', 'probability']"
810394,How come the function and the inverse of the function are the same?,What is the inverse of the function: $$f(x)=\frac{x+2}{5x-1}$$ ? Answer: $$f^{-1}(x)=\frac{x+2}{5x-1}$$ Can one of you explain how the inverse is the same exact thing as the original equation?,"['inverse', 'calculus', 'algebra-precalculus']"
810398,Series Question: $\sum_{n=1}^{\infty}\frac{n^2}{(4n^2-1)^3}$,"How to compute the following series: $$\sum_{n=1}^{\infty}\frac{n^2}{(4n^2-1)^3}$$ I tried to use partial fraction $$\begin{align}\frac{n^2}{(4n^2-1)^3}&=\frac{1}{64(2n+1)}-\frac{1}{64(2n-1)}+\frac{1}{64(2n+1)^2}+\frac{1}{64(2n-1)^2}\\&-\frac{1}{32(2n+1)^3}+\frac{1}{32(2n-1)^3}\end{align}$$ I can compute $$\sum_{n=1}^{\infty}\left[\frac{1}{64(2n+1)}-\frac{1}{64(2n-1)}\right]=-\frac{1}{64}$$ using telescoping series, but I cannot compute the rest. I believe there's a better way than this. Any help would be appreciated. Thanks in advance.","['sequences-and-series', 'algebra-precalculus']"
810414,"Secretary Problem - What is the solution for $n=3,4,5$?","I have been reading this page for a few days and still cannot understand the solution to the Secretary Problem. In particular, I cannot understand parts 2 and 4 It goes like this. Given the assumptions of the Secretary Problem, let $n$ be the number of candidates and let the ""let $k$ go by"" strategy be as follows: We let $k-1$ candidates go by, and then select the first candidate who is better than all previous candidates. If the candidate exists, select her. Else, select the last candidate. 
$k$ can take the value of $\{ 1, 2, ... n\}$. Given this strategy, we compute the probability of success $p_n(k)$, using ""let $k$ go by"" with $n$ candidates. Here is where my question comes in: When $n=3$, we permuate $\{x_1,x_2,x_3\}$ (the smaller the number, the better the candidate) I understand why $p_3(1)=\frac 26$ and $p_3(3)=\frac 26$ because of the $6$ permutations, $x_1$ could come into the interview first in $2$ permutations. Similarly, $x_1$ could come into the interview last in $2$ permutations. However, why is it that $p_3(2)=\frac 36$? In fact, there is another confusing point. Formally, my questions are: Is it true that by counting the permutations, we find out the numerator of $p_i(k)$ for $i=1, \cdots, n$? If so, then why is it that $\sum_i^n p_i(k) \neq 1$? Also, how did the author arrive at the $\frac 36$ for $p_2(k)$? This question, of course extends to the case where $n=4$ and $n=5$. Maybe consider $n=4$ and $n=5$ and someone could derive the expressions for $p_i(k)$: $n=4$
\begin{matrix}
k & 1 & 2 & 3 & 4 \\
p_4(k) & \frac {6}{24} & \frac {11}{24} & \frac {10}{24} & \frac {6}{24}
\end{matrix} $n=5$
\begin{matrix}
k & 1 & 2 & 3 & 4 & 5\\
p_5(k) & \frac {24}{120} & \frac {50}{120} & \frac {52}{120} & \frac {42}{120} & \frac {24}{120}
\end{matrix}","['probability-theory', 'probability']"
810425,Can $C(\mathbb R)$ be reflexive?,"As in title, I was wondering whether $C(\mathbb R)$ was reflexive (here $C(\mathbb R)$ is meant as the space of continuous functions on $\mathbb R$, without any other condition). This question is generated by the following well-known result: Proposition. $(C(K), \| \, \|_\infty)$, $K$ infinite compact metric space, is nonreflexive. This a simple consequence of the James' theorem. But what if we dropped compactness assumption? My considerations. In order to exploit usual ""positive"" (Kakutani's theorem) and ""negative"" (James' theorem) characterizations of reflexivity, we have to endow $C(\mathbb R)$ with a norm that makes it a Banach space. Now, if I'm not wrong, any linear space has at least one norm. On the other hand, not all linear spaces can be endowed with a norm that makes them Banach: the space of polynomials on $[0,1]$ is a counterexample. Given a norm, even without showing completeness, another possibility is to determine the dual of $C(\mathbb R)$ and then consider that a Banach space $X$ is reflexive if and only if its dual $X'$ is. Iterating, if $X'$ is reflexive, then $X''$ is such (and viceversa), and $X''$ is automatically complete, being a dual space. So $X$ is Banach reflexive. Whether this program is succesfull or not, it depends on who the dual space is. (it could be equally or more difficult show it is reflexive or not.) Remark. It could be the context has to move from that of Banach spaces into that of locally convex topological vector spaces. The point is that I'm not able to establish any of preceeding conditions. Does anyone know whether such program can be worked out? And, first of all, whether the question in the title has an answer (in the affermative or in the negative)?",['functional-analysis']
810453,How to prove: prove $\frac{1+\tan^2\theta}{1+\cot^2\theta} = \tan^2\theta$,"I need to prove that $\frac{1+\tan^2\theta}{1+\cot^2\theta}= \tan^2\theta.$ 
I know that $1+\tan^2\theta=\sec^2\theta$ and that $1+\cot^2\theta=\csc^2\theta$, making it now $$\frac{\sec^2\theta}{\csc^2\theta,}$$ but I don't know how to get it down to $ \tan^2\theta.$ HELP!!!! I also need help proving that $\tan\theta + \cot\theta = \sec\theta\cdot\csc\theta.$","['trigonometry', 'algebra-precalculus']"
810454,optimal way to approximate second derivative,"Suppose there is a function $f: \mathbb R\to \mathbb R$ and that we only know $f(0),f(h),f'(h),f(2h)$ for some $h>0$. and we can't know the value of $f$ with $100$% accuracy at any other point. What is the optimal way of approximating $f''(0)$ with the given data? I'd say that $f''(0)=\frac{f'(h)-f'(0)}{h}+O(h)$ and $f'(0)=\frac{f(h)-f(0)}{h}+O(h)$, therefor we get $$f''(0)=\frac{f'(h)-\frac{f(h)-f(0)}{h}}{h}+O(h)$$ But that can't be the optimal way since we know $f(2h)$ and i didn't use it at all. Could someone shed some light?","['calculus', 'derivatives', 'numerical-methods']"
810460,How exactly is $i=\sqrt{-1}$ related to $\mathbb{C}$ being a closed algebraic field?,"There are many known proofs of why $\mathbb{C}$ (field of complex numbers) is algebraically closed (for example Cauchy's proof ) However: how does introducing the solution to the equation $x^2 + 1 = 0$ (imaginary
  number $i$) makes this possible or is intimatelly related to it? Thanx","['complex-analysis', 'field-theory']"
810463,Series Question: $\sum_{n=1}^{\infty}\frac{1}{16n^2-1}$,"How to compute the following series: $$\sum_{n=1}^{\infty}\frac{1}{16n^2-1}$$ I tried to use partial fraction $$\frac{1}{16n^2-1}=\frac{1}{(4n-1)(4n+1)}=\frac{1}{2}\left[\frac{1}{4n-1}-\frac{1}{4n+1}\right]$$ I thought it will form telescoping series, but it is not. Any help would be appreciated. Thanks in advance.","['sequences-and-series', 'calculus', 'algebra-precalculus']"
810479,Showing that every path can be well-divided?,"Let $\gamma: [0,1] \rightarrow S^1$ be a path. We'll say that $\gamma$ is well-divided if there are $a_1,...a_n$ such that: $a_1=0$, $a_n=1$ $\forall_{1\leq i < n}: a_i<a_{i+1}$ $\forall_{i\neq j} : \gamma(a_i)\neq \gamma(a_j) $ $\forall_{1\leq i < n}:||\gamma(a_i) - \gamma(a_{i+1}) ||<1$ I would like to show that every non-constant path is well-divided. I'm not really sure on where to begin in here..and why isn't it correct on a constant path? is it just because of condition #3? without it, it just seems trivial, but correct.","['general-topology', 'topological-groups']"
810483,Configuration scheme of $n$ points,"If $X$ is a space, the configuration space of $n$ (distinct) points in $X$ is $C_n(X)=F_n(X)/\Sigma_n$, where $F_n(X) = \{x \in X^n : \forall i,j (i \neq j \Rightarrow x_i \neq x_j)\}$ is the configuration space of $n$ distinct ordered points. I would like to make such a construction if $X$ is a scheme. Here is my naive idea: Let's assume that $X$ is separated (i.e. the diagonal $\Delta : X \to X \times X$ is closed), hence $U:=(X \times X) \setminus \Delta(X) \hookrightarrow X \times X$ is open. For all $i \neq j$ we have a morphism $(p_i,p_j) : X^n \to X \times X$. The preimage of $U$ is an open subscheme of $X^n$. Let $F_n(X)$ be the intersection of all these open subschemes. The action of $\Sigma_n$ on $X^n$ restricts to an action on $F_n(X)$. Let us define the scheme $C_n(X):=F_n(X)/\Sigma_n$ provided that this scheme quotient exists. For example, there is a general result showing that this is the case when $X$ is quasi-projective. (Or does this specific quotient always exist?) Now my question is: How can we describe the functor of points of $C_n(X)$? That is, if $T$ is a scheme, how can we describe $\hom(T,C_n(X))$ in terms of $\hom(T,X)$? Then $\hom(T,F_n(X))$ is the set of those $f \in \hom(T,X)^n$  which are not only pairwise distinct, but rather ""disjoint"", i.e. for $i \neq j$ we have $\mathrm{eq}(f_i,f_j)=\emptyset$, where $\mathrm{eq}$ denotes the equalizer in the category of schemes. But how to describe morphisms into a quotient? There is a natural map
$$\hom(T,F_n(X))/\Sigma_n \to \hom(T,F_n(X)/\Sigma_n),$$
but it doesn't seem to be an isomorphism. In fact, the left hand side doesn't seem to be a sheaf in $X$. So perhaps $\hom(-,C_n(X))$ is the sheaf associated to the presheaf $\hom(T,F_n(-))/\Sigma_n$? Also, is anything known about quasi-coherent sheaves on $C_n(X)$? I am also interested in variants of this construction. For example, we may also allow equal points and consider $X^n / \Sigma_n$.","['algebraic-geometry', 'moduli-space']"
810490,Constructing groups with a given subgroup,"I have a finite group $H$ and a number $n$ and would like to construct all groups $G$ of order $n$ such that $H$ is a subgroup of $G$. (In fact, I would prefer to construct only those which have $H\mathrel{\unlhd}G$ if this is possible—otherwise I'll just filter out the ones that aren't normal subgroups.) I don't know if this is simple enough to do by hand but if not I have GAP . My motivation is that I'm looking for groups with a particular property but there are too many groups of order $2^k$ to reasonably search through them all. Edit: I was asked to give an example. I have several groups $H$ of interest; here is $H_1$ in the format generated by GAP's GapInputPcGroup : H:=function()
    local g1,g2,g3,g4,g5,g6,g7,g8,r,f,g,rws,x;
    f:=FreeGroup(IsSyllableWordsFamily,8);
    g:=GeneratorsOfGroup(f);
    g1:=g[1];
    g2:=g[2];
    g3:=g[3];
    g4:=g[4];
    g5:=g[5];
    g6:=g[6];
    g7:=g[7];
    g8:=g[8];
    rws:=SingleCollector(f,[ 2, 3, 2, 2, 2, 3, 3, 3 ]);
    r:=[
        [2,g8^2],
        [3,g5],
        [4,g5],
    ];
    for x in r do SetPower(rws,x[1],x[2]);od;
    r:=[
        [2,1,g2*g8],
        [3,1,g4],
        [4,1,g5],
        [6,1,g6*g7*g8],
        [7,1,g8],
        [8,1,g8],
        [3,2,g3*g4*g5],
        [4,2,g3],
        [6,2,g7],
        [4,3,g5],
        [6,3,g6^2*g7^2],
        [7,3,g6*g7^2],
        [6,4,g6*g7*g8^2],
        [7,4,g6],
        [6,5,g6*g8],
        [7,5,g7*g8^2],
        [7,6,g8^2],
    ];
    for x in r do SetCommutator(rws,x[1],x[2],x[3]);od;
    return GroupByRwsNC(rws);
end;
H1:=H(); $H_1$ (like $H_2$ and $H_3$) has order 1296 and I am interested in $n$ which are small multiples of this order. Its StructureDescription is $((((C_3\times C_3) : C_3) : Q_8) : C_3) : C_2$ but this does not uniquely define it—in fact $H_3$ has the same StructureDescription .","['abstract-algebra', 'normal-subgroups', 'finite-groups', 'gap', 'group-theory']"
810503,"Operators such that $\langle Ax,x \rangle=-\langle x,Ax \rangle$","Let $X$ be a Banach space. We consider the differential equation:
$$x'(t)=Ax(t), \ \ \ t\in\mathbb{R}$$
where $A$ is a bounded operator on $X$. If $X$ is a Hilbert space, and  $x(t)$ is a solution of the differential equation, then 
$$\frac{d}{dt}\|x(t)\|^2=\langle Ax(t),x(t) \rangle+\langle x(t),Ax(t) \rangle$$
If the operator $A$ has the property $\langle Ax,x \rangle=-\langle x,Ax \rangle$, then we will get 
$$\frac{d}{dt}\|x(t)\|^2=0,$$
which means $|x(t)|$ is constant. So the condition $\langle Ax,x \rangle=-\langle x,Ax \rangle$ makes $|x(t)|$ constant for every $x(t)$ solution. Can we find a weaker property on $A$ which will make $|x(t)|$ constant only for the bounded solutions on $\mathbb{R}$? Is there any reference which deals with these problems ? Note: I am not looking for evident conditions like: The only bounded solution is $0$.","['ordinary-differential-equations', 'operator-theory', 'reference-request', 'hilbert-spaces', 'functional-analysis']"
810514,Series Question: $\sum_{n=1}^{\infty}\frac{n+1}{2^nn^2}$,"How to compute the following series: $$\sum_{n=1}^{\infty}\frac{n+1}{2^nn^2}$$ I tried $$\frac{n+1}{2^nn^2}=\frac{1}{2^nn}+\frac{1}{2^nn^2}$$ The idea is using Riemann zeta function $$\zeta(s)=\sum_{n=1}^{\infty}\frac{1}{n^s}$$ but the term $2^n$ makes complicated. I know that
$$\sum_{n=1}^{\infty}\frac{1}{2^n}=1$$
using geometric series but I don't know how to use those series to answer the question. Any help would be appreciated. Thanks in advance.","['sequences-and-series', 'calculus', 'algebra-precalculus']"
810537,How to calculate the integration $\int_{0}^{\pi}\frac{dx}{(2-\cos{x})^2}$ [duplicate],"This question already has answers here : Evaluating the integral with trigonometric integrand (6 answers) Closed 10 years ago . Given that 
$$
\int_{0}^{\pi}\frac{dx}{2-\cos{x}}=\frac{\pi}{\sqrt{a^2-1}}
$$ How to calculate the integral
$$
\int_{0}^{\pi}\frac{dx}{(2-\cos{x})^2}
$$","['definite-integrals', 'calculus', 'integration', 'analysis']"
810540,Halmos on Definability and Luzin on Division by 0,"For a successful introduction of a new symbol (e.g. ' $\emptyset$ ') into a mathematical discourse it is necessary and sufficient that the symbol refer to something (e.g. Existence + Specification in ZF) and to nothing else (e.g. Extensionality). I learned of this notion of definability from Halmos (1960). Luzin (1961) has an introductory section (§8) explaining why division by $0$ isn't allowed. His argument seems new to me so I just want to ask whether I understood it properly. He doesn't say this explicitly, but it seems that he relies on the notion of definability described above. Consider: $$a\over 0 \tag 1$$ We know that $(1)$ denotes the unique number $b$ s.t. $b \cdot 0 = a$ . Now, either $a=0$ or $a \ne 0$ . If $a = 0$ , then according to that definition, $(1)$ denotes the unique number $b$ that satisfies the equation $b \cdot 0 = 0$ . But all numbers satisfy that equation, so while there is such a number $b$ , there is no unique root of that equation, so by the definition of definability, $(1)$ fails to denote a number when $a =0$ . If $a \ne 0$ , then according to that same definition, $(1)$ denotes the unique number $b$ that satisfies the equation $b \cdot0 =a$ , where $a$ by hypothesis differs from $0$ . But no $b$ different from $0$ satisfies that equation, so by the definition of definability, $(1)$ fails to denote a number when $a \ne 0$ . Since in both cases $(1)$ fails to denote a unique number, $(1)$ is said to be ill-defined. That's my reconstruction of Luzin's argument - is it entirely correct? References Halmos, P. (1960) Naive Set Theory . Luzin, N.N. (1961) Differential Calculus .","['calculus', 'algebra-precalculus', 'definition', 'elementary-set-theory', 'arithmetic']"
810551,"If $n$ vectors are linearly independent, is their span $\mathbb{R}^n$?","Have $n$ vectors in $\mathbb{R}^n$. If the $n$ vectors are linearly independent, can we conclude that their span is $\mathbb{R}^n$?","['geometry', 'linear-algebra', 'vectors']"
810556,"Integral $\iint \limits_{{x,y \ \in \ [0,1]}} \frac{\log(1-x)\log(1-y)}{1-xy}dx\,dy=\frac{17\pi^4}{360}$","Hi I am trying to integrate $$
\mathcal{I}:=\iint \limits_{{x,y \ \in \ [0,1]}} \frac{\log(1-x)\log(1-y)}{1-xy}dx\,dy=\int_0^1\int_0^1 \frac{\log(1-x)\log(1-y)}{1-xy}dx \,dy
$$
A closed form does exist. I tried to write
\begin{align}
\mathcal{I} &=\int_0^1 \log(1-y)dy\int_0^1 \log(1-x)\frac{dx}{1-xy} \\
&= \int_0^1\log(1-y)dy \ \int_0^1 \sum_{n\geq0}(xy)^n\, \ln(1-x) \ dx \\
&= \sum_{n\geq 0}\frac{1}{n+1}\int_0^1 \log(1-y) y^n\, dy \\
&= \sum_{n\geq 0}\frac{1}{n+1}\int_0^1 \log(1-y)y^n\, dy = ?
\end{align}
I was able to realize that 
$$
\mathcal{I}=\sum_{n\geq 1}\left(\frac{H_n}{n}\right)^2=\frac{17\zeta_4}{4}=\frac{17\pi^4}{360},\qquad \zeta_4=\sum_{n\geq 1} n^{-4} 
$$
however this does not help me solve the problem.  How can we calculate $\mathcal{I}$? Thanks.","['calculus', 'integration', 'definite-integrals', 'real-analysis', 'complex-analysis']"
810562,Divergence Proof,"I'm not sure where to start on this proof...also, my book didn't give any clarification as to what $f$ and $\textbf{F}$ are. Usually $F$ is a scalar function, and $\textbf{f}$ is the vector field $f_1\textbf{i}+f_2\textbf{j}+f_3\textbf{k}$. But in this question the $\textbf{F}$ is a vector field because it's bold? Also, can you take the divergence of a scalar function? I thought it was just vector fields... Thanks in advance.",['multivariable-calculus']
810565,How do I differentiate to what they have given?,"Given that  $y = \dfrac{x^3 - 5x}{\sqrt{x}}$, show that $\dfrac{dy}{dx}$= $\dfrac{5(x^2 - 1)}{2 \sqrt{x}}$ (Posted from ``answer'' below: I get as far as  $\dfrac{dy}{dx}= \dfrac {5}{2}x^\frac {3}{2}  - \dfrac {5}{2}x^\frac{-1}{2}$  but struggling with the first fraction.) I am just getting to grips with the formatting so hope that is clear! 
Many thanks","['calculus', 'derivatives']"
810586,"An expression for $U_{h,0}$ given $U_{n,k}=\frac{c^n}{c^n-1}(U_{n-1,k+1})-\frac{1}{c^n-1}(U_{n-1,k})$","Let $c\in\mathbb{R}\setminus\{ 1\}$, $c>0$. Let $U_i = \left\lbrace U_{i, 0}, U_{i, 1}, \dots \right\rbrace$, $U_i\in\mathbb{R}^\mathbb{N}$. We know that $U_{n+1,k}=\frac{c^{n+1}}{c^{n+1}-1}U_{n,k+1}-\frac{1}{c^{n+1}-1}U_{n,k}$. (As @TedShifrin pointed out, it can also be written $U_{n+1,k}=U_{n,k+1}+\frac{1}{c^{n+1}-1}\left(U_{n,k+1}-U_{n,k}\right)$) (obviously it implies that if $\lvert U_k \rvert=n$ then $\lvert U_{k+1}\rvert=n-1$ etc) Here is what I conjectured: $$\forall h\in\mathbb{N}, 
U_{h,0}=\sum\limits_{p=0}^h\frac{c^{\frac{p^2+p}{2}}}{\left(\prod\limits_{i=1}^p\left(c^i-1\right)\right)\prod\limits_{i=1}^{h-p}\left(1-c^i\right)}U_{0,p}$$ I tested it for some values ($0,1,3,4$) and it seemed to work.
Mathematica also verified it up to at least 10. What do you think? If it IS true, how can I prove it? Example with $c=4$, $h=2$ : $U_{1,0}=\frac{4}{3}U_{0,1}-\frac{1}{3}U_{0,0}$, $U_{1,1}=\frac{4}{3}U_{0,2}-\frac{1}{3}U_{0,1}$ $U_{2,0}=\frac{16}{15}U_{1,1}-\frac{1}{15}U_{1,0}$ Therefore $U_{2,0}=\frac{16}{15}\left(\frac{4}{3}U_{0,2}-\frac{1}{3}U_{0,1}\right)-\frac{1}{15}\left(\frac{4}{3}U_{0,1}-\frac{1}{3}U_{0,0}\right)$ $U_{2,0}=U_{0,0}\left(\frac{1}{15\times 3}\right)-U_{0,1}\left(\frac{16}{15\times 3}+\frac{4}{15\times 3}\right)+U_{0,2}\left(\frac{16\times 4}{15\times 3}\right)$ $U_{2,0}=U_{0,0}\left(\frac{1}{45}\right)-U_{0,1}\left(\frac{4}{9}\right)+U_{0,2}\left(\frac{64}{45}\right)$ The formula gives us : $U_{2,0}=U_{0,0}\left(\frac{4^0}{(1-4)(1-16)}\right)+U_{0,1}\left(\frac{4^1}{(4-1)(1-4)}\right)+U_{0,2}\left(\frac{4^3}{(16-1)(4-1)}\right)$ $U_{2,0}=U_{0,0}\left(\frac{1}{45}\right)+U_{0,1}\left(\frac{-4}{9}\right)+U_{0,2}\left(\frac{64}{45}\right)$","['q-series', 'combinatorics']"
810602,"What $\alpha$ such that if $xy=\alpha$, then $e^{-x}+e^{-y}\geq 2e^{-\sqrt \alpha} $?","For every $ x,y \gt 0$, if $ xy=\alpha$, then we have $$e^{-x}+e^{-y}\geq 2e^{-\sqrt \alpha} $$ What are the possible values of   $\alpha$? $2 < e^{1/(n+1)} + e^{-1/n}$ led to  this problem. so, $\alpha=1$  is allowed. The problem is difficult, if not very:  $e^{-x}+e^{-\frac1x}\geq 2e^{-1}$ is not easy to prove. P.S.: 1)  $\quad e^{-\sqrt \alpha}\geq e^{\dfrac{-x-y}2}$ 2) $\quad e^{-x}+e^{-y}\geq 2e^{-\sqrt {xy}} $ does not hold for all $x,y\gt0$! Just think $x=1,y\to0$ Any help will be appreciated!","['exponential-function', 'inequality', 'real-analysis', 'analysis']"
810632,Fit a rectangle inside a square while maintaining aspect ratio,"I'm trying to scale down a rectangular screenshot to fit inside a smaller square. The rectangle is 640x352, and I want to fit it within a 200x200 square, while being as wide as possible (so its long side will be 200 also). And I want to retain its aspect ratio. I came across this formula on Stack Overflow: Given you have two images with sizes (w1, h1) and (w2, h2) and you
  want to scale the second image to the same area as the first while
  maintaining the aspect ratio, then A = w1 * h1
new_w2 = sqrt(A * (w2 / h2))
new_h2 = A / new_w2 and it seems to be close to what I want, but since it actually creates another rectangle with matching area , it doesn't fit inside the square. It actually gives me a new rectangle with sides of 269.679944985 by 148.323969742 (which indeed comes out to 40000, the same as 200x200). I feel like I'm close but, for a programmer, I am really terrible at math. Any ideas will be appreciated. In fact I'm so bad at math that I don't even know what to tag this. I'll go with trigonometry and edit once someone corrects me.","['trigonometry', 'algebra-precalculus']"
810639,An alternating decimal sequence: Does its average have a limit?,"Define a sequence of decimals $x_n$ by alternating the digits $1,2,\ldots,n$ left and
right, as follows:
$$x_1 = .1$$
$$x_2 = .21$$
$$x_3 = .213$$
$$x_4 = .4213$$
$$x_5 = .42135$$
$$x_6 = .642135$$
$$\cdots$$
$$x_{14}=.1412108642135791113$$
$$\cdots$$
Define $a_n$ as the average of the sequence up to $x_n$:
$$a_n = (x_1+x_2+ \cdots x_n)/n$$ Q . Does $a_n$ approach a limit as $n\to \infty$? Addendum . Resolved by Thomas Andrews: the sequence has no limit!
However, Paul Hurst conjectures that $\lim \sup_{n \to \infty} = 0.55$. The same question can be asked in any base $b$.
Especially interesting is $b=2$, e.g., $x_3=.10111$ (i.e.,$10{-}1{-}11$), $x_7=.11010010111101111$ (i.e.,$110{-}100{-}x_3{-}101{-}111$), etc.","['sequences-and-series', 'recreational-mathematics']"
810670,Continuity of matrix inversion,"Show that the set $U \subset \mathbb{R}^{n^{2}}$ of matrices $A$ with $\det(A) \neq 0$ is open. Let $A^{-1}$ be the inverse of the matrix $A$ . Show that the mapping $A \mapsto A^{-1}$ is continuous from $U$ to $U$ . My solution to the first part is that $\det(A)$ can be expressed as a polynomial in the entries of $A$ , and since polynomial functions are continuous we have that the determinant function is continuous from which we can say the given set is indeed open. Any thoughts on the next part?","['matrices', 'linear-algebra', 'continuity', 'inverse', 'analysis']"
810673,Is the Frobenius norm minimizer the same as the $2$-norm minimizer?,"Given matrices $A \in \mathbb{R}^{n \times m}$ and $B \in \mathbb{R}^{n \times k}$ , consider the least-squares minimizer $$\arg \min_{X \in \mathbb{R}^{m \times k}} \| AX - B \|_{\text{F}}$$ where $\| M \|_{\text{F}} := \left( \sum_i \sum_j M_{ij}^2 \right)^{1/2}$ denotes the Frobenius norm. I was wondering if this is identical to the minimizer $$\arg \min_{X \in \mathbb{R}^{m \times k}} \| AX - B \|_2$$ where $\| M \|_2 := \sigma_1 (M)$ denotes the matrix $2$ -norm. Since $$\sqrt{\operatorname{rank}(M)} \cdot \| M \|_2 \geq \| M \|_F \geq \| M \|_2$$ I feel there must be a simple argument to show these minimizers are identical. If it is not so, can you please describe what assumptions on matrices $A$ and $B$ are necessary for the minimizers to be identical?","['optimization', 'least-squares', 'matrices', 'linear-algebra', 'spectral-norm']"
810695,A snappy proof of Fatou's lemma,"I'm studying basic real analysis and stumbled across three big results (Fatou's lemma, Lebesgue's Dominated Convergence theorem, and the Monotone Convergence theorem) in the theory of Lebesgue integration. I've seen short and slick proofs of the LDCT and MCT from scratch (in Bogachev's Measure Theory and Bass' Graduate Real Analysis/Rudin's Real and Complex Analysis, respectively). However, I was wondering if such a proof exists for Fatou's lemma. I've seen a couple of proofs that rely on neither the MCT nor the LDCT (in particular, in Royden and Fitzpatrick's Real Analysis, and on the Wikipedia page for Fatou's lemma), and while these proofs aren't too tricky or difficult to understand, they seem considerably longer than the proofs of the other two theorems. So to summarize: Can someone supply me with a short and slick proof, perhaps even an outline of a proof for me to work through, of Fatou's lemma that does not rely on LDCT or MCT? Thank you!","['measure-theory', 'reference-request', 'real-analysis', 'alternative-proof', 'lebesgue-integral']"
810718,why not the Ricci tensor is the contraction of first and second indices of Riemann tensor,"Why the Ricci tensor is defined the contraction of first and third indices of Riemann tensor? I guess it is more natural to define it as to contract the first and the second indices?
Since from Wiki :
$$R_{\sigma \mu \nu}^\rho = dx^\rho(R(\partial_\mu,\partial_\nu)\partial_\sigma)$$
To do a contraction, I guess it should be done on $\rho $ and $\sigma$ so that $$R_{\mu \nu} = R_{\sigma \mu \nu}^ \sigma$$ but why the definition is 
$$R_{\mu \nu} = R_{\mu \sigma  \nu}^ \sigma$$",['differential-geometry']
810728,Curl Proof Question,"Prove the given formula. So far I have $f\textbf{F}=(f\textbf{F}_1, f\textbf{F}_2, f\textbf{F}_3)$, but I'm not sure where to go from there. Could anyone give me some pointers? Thank you.",['multivariable-calculus']
810738,Semialgebra logical error,"I was following a proof on Rosenthal's, A first look at rigorous probability theory book, but I believe that one step flawed. Let me set up: $\mathcal{J}$ is a semialgebra of subsets of $\Omega$. Meaning that: $\emptyset, \Omega \in \mathcal{J}$. $\mathcal{J}$ is closed under intersections. If $A \in \mathcal{J}$ then $A^C$ is a finite disjoint union of elements of $\mathcal{J}$. Then let $\{A_i\}$ be a countable family of elements of $\mathcal{J}$ such that $\bigcup_i A_i \in \mathcal{J}$. For the purpose of the proof, he need a disjoint family to apply Additivity, hence he construct a family $\{D_i\}$ with $D_1 = A_1$ and
$$ D_n = A_n - \left( \bigcup_{i=1}^{n-1}A_i\right) = A_n \cap \left( \bigcap_{i=1}^{n-1}A_i^C\right)$$ Now by construction $\{D_i\}$ are disjoint and $\bigcup_i D_i = \bigcup_i A_1$.
So far I got it, but then he says: Furthermore, since $\mathcal{J}$ is a semialgebra, each $D_n$ can be written as a finite disjoint union of elements of $\mathcal{J}$. For that to apply, $D_n^C$ have to be in $\mathcal{J}$, but that does not seem to be the case, as
$$ D_n^C = \left( A_n \cap \left( \bigcap_{i=1}^{n-1}A_i^C\right) \right)^C$$
$$ = A_n^C \cup \left( \bigcup_{i=1}^{n-1}A_i\right) $$ As $A_i \in \mathcal{J}$, the closest that I got is that $D_i^C$ is a finite union of elements of $\mathcal{J}$, but as a semialgebra may not be closed under unions. It's not clear to me that $D_n^C$ is in $\mathcal{J}$ so $(D_n^C)^C = D_n$ can be written as a finite disjoint union in $\mathcal{J}$. Any light in whether I'm missing something or if his reasoning is really flawed or not will be appreciated.","['measure-theory', 'elementary-set-theory']"
810745,Outer measure is countably subadditive,"Working on the proof that outer measure is countably subadditive in Royden For a set $A \subset X$ we define the outer measure: $$\mu^{*}(A) = \inf\left\{ \sum_{n=1}^{\infty} \tau(T_n): \space T_n \in \mathcal{T}, \space A \subset \bigcup_{n=1}^{\infty} T_n \right\} $$ We want to prove that $\mu^{*}$ has the property of subadditivity: for a sequence $\{ A_n\}_{n=1}^{\infty}$ the following is true: $$\mu^{*}\left( \bigcup_{n=1}^{\infty} A_n \right) \le \sum_{n=1}^{\infty} \mu^{*}(A_n)$$ $\mathbf{Proof}$: The first step is that there exists $(n,j)$ such that $A_n \subset \bigcup_{j=1}^{\infty} T_{(n,j)}$ and $ \sum_{j=1}^{\infty} \tau(T_{(n,j)}) \le \mu^*(A_n)+\frac{\epsilon}{2^n}$ ~~~~~~~~~~~~~~~~~~~~~~~~~~ I'm confused as to how we know that such an open cover $T_{(n,j)}$ exists, especially subject to the condition that $ \sum_{j=1}^{\infty} \tau(T_{(n,j)}) \le \mu^*(A_n)+\frac{\epsilon}{2^n}$ How would such an open cover be constructed? If anyone could help me develop some intuition for this step, that would be great","['measure-theory', 'real-analysis']"
810753,Prove that every odd prime number can be written as a difference of two squares.,"Prove that every odd prime number can be written as a difference of two squares. Prove also that this presentation is unique. Is such presentation possible if p is just an odd natural number? Can 2 be represented this way? Answers \3. Yes the presentation (i.e. odd numbers being written as differences of two squares) is possible for all odd natural number however the presentation may not be unique. For example, $57=11^2-8^2=29^2-28^2$. \4. 2 can't be written as a difference of two squares because 4-1=3 and 1-1=0 and the difference of squares grows to integers larger that 3. Can I get some help in proving questions 1 and 2?",['number-theory']
810762,Question about Sylow $p$-subgroups,"If a group $H$ has order $255$ then the Sylow theorems tell us that it must have a Sylow $p$-subgroup of order $5$ and there are either $1$ or $51$ of them, also there is either $1$ Sylow $p$-subgroup of order $3$ or $85$ Sylow p-subgroups of order $3$. How can I show that it is not the case that there are both $51$ order $5$ Sylow $p$-subgroups and $85$ order $3$ Sylow p-subgroups? In general what is the best way to deal with these cases?","['sylow-theory', 'finite-groups', 'group-theory', 'abstract-algebra']"
810823,"$f(x,y)$ is such that partial derivative w.r.t $x$ is zero, but$ f$ still depends on $x$?","I have a problem where it seems like I should be able to visualize an answer, but I can't.  Perhaps I need to take a more formal approach. ""Let $A$ be a non-empty open convex subset of $\mathbb{R}^2$, and suppose that $f: A \rightarrow \mathbb{R}$ satisfies that $\frac{\partial f}{\partial x} = 0$ at all points in $A$.  Prove that there is a function $g$ of one variable such that $f(x,y) = g(y)$.  Show that this conclusion may fail if convexity is replaced by connectedness."" For the first part, maybe I can do something like the following: When $A$ is convex, I can take any points $\boldsymbol{a_0}, \boldsymbol{a_1} \in A$, where $\boldsymbol{a_0} = (x_0, y_0), \boldsymbol{a_1} = (x_0 + h, y_0)$, and have the line segment connecting them be in $A$. Since $\frac{\partial f}{\partial x} = 0$ everywhere on this line segment, some mean value business shows that $f(\boldsymbol{a_0}) = f(\boldsymbol{a_1})$, regardless of the value of $h$.  Therefore, at any given $y=y_0$, $f$ does not depend on $x$, so $f(x,y) = g(y)$ only. Obviously I used convexity of $A$ to show this, but I can't seem to find a counterexample that makes it fail when $A$ is connected but not convex.  If $A$ were not even not connected, so it was separable into disjoint open sets $A_1$ and $A_2$, it would be easy to see that $f$ could have different constant values w.r.t. $x$ in each separate region.  This separation could allow $f$ to depend on $x$ overall even though $\frac{\partial f}{\partial x} = 0$ where ever $f$ is defined. It's the connected but not convex case that's troublesome. The more I think about it, the less sensible it sounds. If we want to show that $f(x,y)$ is not just a function of $y$, we should be able to find some $\boldsymbol{a_0}, \boldsymbol{a_1} \in A$, as above (having the same $y$ values but different $x$ values) such that $f(\boldsymbol{a_0}) \neq f(\boldsymbol{a_1})$.  We suppose $A$ is connected.  Since $\frac{\partial f}{\partial x} = 0$ everywhere in $A$, it seems like any curve in $f(A)$ that connects those points has to lie in a plane parallel to the $xy$ plane, else $f$ would change with changing $x$.  But if that were so, how could we have $f(\boldsymbol{a_0}) \neq f(\boldsymbol{a_1})$? Clearly my intuition is failing me here.  Could somebody set me straight? This is my first post on Math Exchange, please let me know if I'm doing something wrong.  Thanks!",['real-analysis']
810860,A question on harmonic two-forms,"Let $(M^4,g)$ be a closed Riemannian four-manifold with $b_2^+>0$ and $b_2^->0$, is it possible to find two harmonic two-forms $\alpha\in H^2_+(M)$ and $\beta\in H^2_-(M)$, such that
\begin{equation*}
|\alpha(x)|^2=|\beta(x)|^2\quad\text{for all } x\in M ?
\end{equation*}
Thank you.","['differential-topology', 'differential-forms', 'differential-geometry', 'hodge-theory']"
810874,Trigonometry Problem. Help me! [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question Simplify
 $$\frac{\cos^{2}a-\cot^{2}a +1}{\sin^{2}a + \tan^{2} a -1}$$ Please help me solve this problem",['trigonometry']
810896,"calculating $P(X_n=\max(X_1,X_2,\ldots, X_n))$","Suppose $X_1,X_2,\ldots X_{n-1}\sim U(0,1)$ , $X_n\sim \exp(\frac{1}{2})$ . Else, suppose $X_1,X_2\ldots, X_n$ are independent. How can I calculate $P(X_n=\max(X_1,X_2\ldots, X_n))$",['statistics']
810907,Proving $||\vec{a}+\vec{b}|| = ||\vec{a}-\vec{b}|| \iff \vec{a} \perp \vec{b}$,"Have some  non-null $\vec{a}$ and $\vec{b}$. I am trying to prove this to no avail: $$||\vec{a}+\vec{b}|| = ||\vec{a}-\vec{b}|| \iff \vec{a} \perp \vec{b}$$ If we start with $$||\vec{a}+\vec{b}|| = ||\vec{a}-\vec{b}|| \implies \vec{a} \perp \vec{b}$$ Our hypothesis is $$||\vec{a}+\vec{b}|| = ||\vec{a}-\vec{b}||$$ Which tells us that both horizontal sides of this triangle have the same length, so we got an isosceles triangle. Not sure what to make out of that though. Anyway, the hypothesis is equivalent to $$\sqrt{(\vec{a} + \vec{b})\cdot (\vec{a} + \vec{b})} = \sqrt{(\vec{a} - \vec{b})\cdot (\vec{a} - \vec{b})}$$ I can't make much out of that. A hint to begin tackling this problem would be appreciated.","['geometry', 'vectors']"
810916,Any infinite set partitioned into a set of countably infinite sets?,"Prove that if $s$ is infinite, then it can be partitioned into a set of countably infinite sets $\mathcal{A}$ . That is: $\bigcup \mathcal{A}=s$ $\forall a\in \mathcal{A}, a$ is countably infinite $\forall a_1, a_2 \in \mathcal{A},\quad a_1=a_2 \implies a_1 \cap a_2 = \emptyset$ I'm not sure how to get going on this one. I'm under the presumption that I should use Zorn's lemma, though I'm not entirely sure how... Is it true that $\mathcal{A}$ should have the same cardinality as $s$ ? Any help appreciated.","['cardinals', 'elementary-set-theory']"
810956,"find p,q to the expression A does not depend on x? [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question Find $p,q$ to the expression $A = p (\cos^{8}x-\sin^{8}x) + 4(\cos^{6}x-2\sin^{6}x) + q\sin^{4}x$ does not depend upon $x$",['trigonometry']
810967,"Prove that if $f$ is uniformly continuous on a bounded set $S$, then $f$ is bounded on S","Prove that if $f$ is uniformly continuous on a bounded set $S$, then $f$ is bounded on $S$. Here's my proof. Can someone please verify it? Suppose $f$ is not bounded on $S$. Then, $\forall n \in \mathbb{N}$, there corresponds an $f(x_n)$ such that $|f(x_n)|>n$, where $x_n \in S$. Pick a convergent subsequence $(x_{n_k})$ of $(x_n)$. Then, $(x_{n_k})$ is cauchy. Since $f$ is uniformly continuous on $S$, this implies that $f(x_{n_k})$ is cauchy. However, this cannot be the case, since $f(x_{n_k})$ clearly diverges. Therefore, it must be the case that $f$ is bounded on $S$.","['proof-verification', 'real-analysis']"
810971,Continuity of a function in two variables,"Function $f(x,y)$ is continuous in each variable separately. Prove that there exists a point where it is continuous in two variables. I do not quite understand how to act here. I know the definition of continuity. But how to use them, I do not know. This is my homework on mathematical analysis.","['multivariable-calculus', 'continuity', 'real-analysis']"
810978,When is a companion matrix diagonalizable and what does this say about the associated field extension?,"Consider the $n\times n$ matrix
$$
M=\begin{pmatrix}
0 & 0 & 0 & \cdots & 0 & 0 & -c_0\\
1 & 0 & 0 & \cdots & 0 & 0 & -c_1\\
0 & 1 & 0 & \cdots & 0 & 0 & -c_2\\
\vdots & \vdots & \vdots & \ddots & \vdots &\vdots & \vdots\\
0 & 0 & 0 & \cdots & 1 & 0 & -c_{n-2}\\
0 & 0 & 0 & \cdots & 0 & 1 & -c_{n-1}\\
\end{pmatrix}
$$
with rational entries. It is called the companion matrix of its charateristic polynomial $p_M$ which equals its minimal polynomial. Assume that $p_M$ is irreducible over $\mathbb{Q}$. By considering $p_M$ over the extension $\mathbb{C}\supset\mathbb{Q}$, it splits as
$$
p_m(x)=(x-a_1)^{e_1}\cdots (x-a_k)^{e_k},
$$
but according to Wikipedia , $M$ does not have to be diagonalizable in general. What is an example of an $M$ (such that $p_M$ is irreducible over $\mathbb{Q}$) that is not diagonalizable over the complex numbers? As $p_M$ is irreducible over $\mathbb{Q}$, the matrix $M$ defines an algebraic field extension $L=\mathbb{Q}[x]/(p_M)$ over $\mathbb{Q}$ of degree $n$. How is the property that $M$ is diagonalizable over $\mathbb{C}$ reflected in properties of the field extension? Edit Sorry, I want to assume that $p_M$ is irreducible over $\mathbb{Q}$, of course.","['abstract-algebra', 'matrices', 'linear-algebra', 'companion-matrices', 'field-theory']"
811011,Difference between Euclidean space and inner product space?,Is it that Inner product space can have infinite dimensions?,"['linear-algebra', 'inner-products']"
811024,what is and how to generate a Net representation for a given polyhedron?,The so called Net representation for a Tetrahedron is depicted in the following image ( link to wolfram ) : What is this for ? How to reason about this and how to generate this very same representation for any polyhedron ? There is an algorithm or a formula for that ?,"['geometry', 'network', 'polyhedra']"
811025,"Differentiability of ""positive part"" function","Let the positive part function be defined as $\max(0,x)$; this function is obviously not differentiable in $x=0$. But what about the (more smooth) function $\big( \max(0,x) \big)^{2}$. I suspect the latter isn't differentiable in $x=0$ either, but it's not very clear.","['differential-geometry', 'derivatives', 'real-analysis']"
811049,What is the derivative of a skew symmetric matrix?,"I'm trying to work out some Jacobians and I ran across a problem. If I have a function of a vector making it a skew symmetric matrix, like below, what is the derivative $f'$? $$ f(\boldsymbol{\omega}) = \lfloor \boldsymbol{\omega} \, \times \rfloor =
\left( \begin{array}{ccc}
0 & -\omega_3 & \omega_2 \\
\omega_3 & 0 & -\omega_1 \\
-\omega_2 & \omega_1 & 0
\end{array} \right)
$$","['matrices', 'matrix-calculus', 'skew-symmetric-matrices', 'derivatives']"
811051,How can expected value be infinite?,"My book as well as Wikipedia gives this definition of expected value: $\mathbb E(X)=\sum _x xf(x).$ But, $\mathbb E(X)$ is said to exist if and only if that equation is absolute convergent. But, I see that many places do not follw this def., e.g. here $${\mathbb E} X = \sum_{n=1}^\infty 2^{-n} \cdot 2^n = \sum_{n=1}^\infty 1 = \infty,$$ though we can see that absolute convergence test is failed. So, can expected value be infinity or negative infinity?","['probability', 'random-variables']"
811052,"Definition of ""Order of a group ""","According to Wikipedia , the order of a group $G$ is its cardinality, i.e., the number of elements in its set and denoted by $|G|$. The definition given in the book Robinson, ""A course in the theory of group"", Page 2, is also same. But according to this book , page 5, the definition is as follows: The order of a group $G$ is the cardinality $|G|$, either a positive integer or $\infty$. So according to this book, the order of any infinite group is same and it is $\infty$. Is this CORRECT? If not then i would like to know the order of groups $\mathbb{Z}$, $\mathbb{R}$ and $\mathbb{C}$. Thanks for any help in this regard.","['group-theory', 'abstract-algebra']"
811117,Counting the number of orbits for the group action,"I have have to find the number of orbits for the group action given by the set of all real $2\times 2$ invertible matrices acting on $\mathbb{R^2}$ by matrix multiplication. I know that if a group $G$ acts on a set $X$ then for each $x\in X$, 
$orbit(x) = \{gx: g\in G\}$, where $g$ runs over all the elements of the group $G$. Thus here for any $x\in \mathbb{R^2}$ its orbit is given by set $\{Ax : A \in G\}$ and I have to keep in mind that orbits partition the set $X = \mathbb{R^2} $. My confusion: Here both group $G$ and set $X$ are of infinite order. So, how to find orbit of all the infinite elements of $\mathbb{R^2}$. Do I have to look at the basis elements of $\mathbb{R^2}$? I am learning to find the orbits of a set. Any help and basic idea to solve such kind of problem would be very helpful to me. Thank you very much for your kind consideration.","['group-theory', 'abstract-algebra']"
811130,Function for diagonalizing a vector.,"I was playing around whith the idea of what operation (function) should I perform (apply) over a vector $\mathbf{a} = (a_1,a_2, \ldots, a_N)^T \in \mathbb{R}^N$ to come up with the following matrix : $$ A = 
\left( \begin{array}{ccc}
a_1 & 0 & \cdots & 0 \\
0  & a_2 & \cdots &  0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & a_N
\end{array} \right)?
$$ i.e, how can I diagonalize my vector $\mathbf{a}$. This is my approach, but first I must apologize for my very rusty linear-applications-knowhow. That being said, I was wondering that, if there exist the following relation between $\mathbf{a}$ and $A$ : $$ A \, \mathbf{1}  = \mathbf{a},$$ where $\mathbf{1}$ is a $n \times 1$ column vector filled with ones in its entries, then I can trivially solve for $A$ in terms of the pseudoinverse of $\mathbf{a}$ as follows: $$ A = \left[ \mathbf{1} \, \mathbf{a}^T \, (\mathbf{a} \, \mathbf{a}^T)^{-1} \right]^{-1}, $$ so this would become my desired $A = f(\mathbf{a})$. Unfortunately, Matlab has wisely warned me that $\det{(\mathbf{a}\, \mathbf{a}^T)} = 0$ (which I can't formally see why), so the above formula makes no sense. I'm run out of ideas right now. Someone can help me? Thanks in advance and Cheers! Edit 1 : of course, I should have mentioned that I'm aware of the existence of the command diag in Matlab.","['vector-spaces', 'matrices', 'algebra-precalculus']"
811131,A definite integral with tanh and sin,"In an old textbook, Thomas John I'Anson Bromwich asks the reader to use the expansion $$ \tanh \left(\frac{\pi x}{2} \right) = 1 + 2 \sum_{n=1}^{\infty} (-1)^{n} e^{-n \pi x}$$ to show $$\lim_{t \to 0^{+}} \int_{0}^{\infty} e^{-tx} \tanh \left(\frac{\pi x}{2} \right) \sin (ax) \, dx = \text{csch}(a).$$ The reader is then supposed to assign this value to the divergent integral $$\int_{0}^{\infty} \tanh \left(\frac{\pi x}{2} \right) \sin (ax) \, dx $$ and deduce $$\int_{0}^{\infty}\frac{\tanh(\frac{\pi x}{2})\sin(ax)}{x^{2}+1} \, dx= \frac{1}{2} \left[e^{-a}\log(e^{2a}-1)-e^{a}\log(1-e^{-2a})\right] \tag{1}.$$ This approach seems quite unusual and not easy to justify. Can we prove $(1)$ in another way?","['definite-integrals', 'integration']"
811136,Notation for choosing the k smallest elements from a set of integer,"Is there any specific notation for picking $k$ elements from a set which are the smallest? Ex:
{$1,3,5,7,9,11$} with $k = 3 \Rightarrow$ We want $1,3,5$","['notation', 'elementary-set-theory']"
811137,Similarity between two probability distribution,"I am not sure how to put the question. I am not even sure if this question makes sense at all. I know that the similarity of two discrete (or continuous) distributions can be quantified by Kullback–Leibler distance. However, I wonder if it makes sense to quantify the Kullback–Leibler distance between two random variables which one is discrete and the other one is continuous? Is there any probabilistic measure for quantifying the similarity of continuos distribution with a discrete one.","['stochastic-processes', 'probability-theory', 'information-theory', 'probability-distributions', 'probability']"
811160,$AB-BA=A$ implies $A$ is singular and $A$ is nilpotent. [duplicate],"This question already has answers here : If $A=AB-BA$, is $A$ nilpotent? [duplicate] (5 answers) Closed 10 years ago . Let $A$ and $B$ be two real $n\times n$ matrices such that $AB-BA=A$ Prove that $A$ is not invertible and that $A$ is nilpotent. My attempt is the following. It holds that $AB=(B+I)A$ If $A$ were invertible, $B=A^{-1}(B+I)A$ . Taking trace on both sides yields $tr(B)=tr(B)+n$ , hence $n=0$ , which is a contradiction. I can't prove that $A$ is nilpotent though.","['matrices', 'linear-algebra']"
811186,Unique solution for parametric system of two equations,"The system is: $$x - 2y + z = 2\alpha \\
3(xy + xz + yz) = 3\alpha - 4$$ I have to find for which values of $\alpha$, the system has an unique solution. I've tried to simplify both expressions, set $x,y,z$ to some special values, and even apply some well-known inequalities to check for validity. Any hint will be greatly appreciated!",['multivariable-calculus']
811191,Monotonic function satisfying darboux property $\Rightarrow$ continuous,"Assume $f : I \rightarrow \mathbb{R}$ is a non-decreasing on an open interval $I$ and that $f$ satisfies the Intermediate value property or Darboux's property on $I$ (that is, for any $a < b$ in $I$ and any $L$ between $f(a)$ and $f(b)$ , there exists $c \in [a, b]$ such that $ f (c) = L)$ . Then, prove that $f$ is continuous. However, I know that a function can be discontinuous and also satisfy the IVT at the same time.
Could someone point me in the right direction?","['functions', 'continuity', 'real-analysis']"
811196,Countable basis but uncountably many connected components,"Looking for some guidance on two topology  questions: (a) Show that a locally connected space with a countable basis, has at most
countably many connected components. (b) Give an example when X has countable basis but it has uncountable many
connected components. Mainly stuck on (b). I think I understand why this is the case for (a) along the lines that for $d$ in a set $D$ (with a countable basis), given $C_{d}$ a connected component for $d$, the intersection between the set of such countable components, $C$, and $D$ is non-empty i.e. $C \cap D \neq \emptyset$, but this means that, by the countability of $D$'s basis, we cannot have uncountably many connected components (elements in the intersection). For (b) I've been casting about and have seen some references in texts to sets $B_{\rho,\theta}$ which have uncountably many connected components but countably many components that are copies of the Mandelbrot set...but suspect this may be over-complicating.","['examples-counterexamples', 'general-topology', 'second-countable', 'connectedness', 'locally-connected']"
811251,limit of the integrations of a sequence of integrable functions,"Let $(f_n)^\infty_{n=1}$ be a sequence of Lebesgue integrable functions on $[0,1]$ such that $f_n$ converges to $f$ almost everywhere in $[0,1]$. Suppose further (a). $\sup_n\int_0^1|f_n|d\mu<\infty$; (b). for any $\epsilon>0$, there exists $\delta>0$ such that for any measurable subset $E$ of $[0,1]$ with $\mu(E)<\delta$, $\sup_n\int_E|f_n|d\mu<\epsilon$. Prove that $f$ is integrable on $[0,1]$ and $\int_0^1fd\mu=\lim_{n\to\infty}\int_0^1f_nd\mu$. How to prove this? I confronted with some difficulties. My idea: Let 
\begin{eqnarray*}
f_n^N=\max \{\min\{f_n,N\},-N\},\\
f^N=\max \{\min\{f,N\},-N\}.
\end{eqnarray*}
Then for any $x\in[0,1]$, $|f_n(x)|\leq N$, $|f(x)|\leq N$. By Lebesgue Dominated Convergence Theorem, for each $N\in\mathbb{N}$, 
\begin{eqnarray*}
\lim_{n\to\infty}\int f_n^Nd\mu=\int\lim_{n\to\infty}f_n^Nd\mu
=\int f^Nd\mu.
\end{eqnarray*}
Since $|f_n^N|\leq |f|$, by Lebesgue Dominated Convergence Theorem, for each $n\in\mathbb{N}$,
\begin{eqnarray*}
\lim_{N\to\infty}\int f_n^Nd\mu=\int\lim_{N\to\infty}f_n^Nd\mu=\int f_nd\mu.
\end{eqnarray*}
By Levi's monotone convergence theorem,
\begin{eqnarray*}
\int fd\mu&=&\int f^+d\mu-\int f^-d\mu\\
&=&\int\lim_{N\to\infty}f^{N+}d\mu-\int\lim_{N\to\infty}f^{N-}d\mu\\
&=&\lim_{N\to\infty}\int f^{N+}d\mu-\lim_{N\to\infty}\int f^{N-}d\mu\\
&=&\lim_{N\to\infty}\int f^Nd\mu.
\end{eqnarray*}
Letting $N\to\infty$ in the first equality, \begin{eqnarray*}
\int fd\mu&=&\lim_{N\to\infty}\int f^N d\mu\\
&=&\lim_{N\to\infty}\lim_{n\to\infty}\int f^N_n d\mu\\
&=&\lim_{n\to\infty}\lim_{N\to\infty}\int f^N_n d\mu \\
&  &\text{ (need to prove the order of two limits can be exchanged)}\\
&=& \lim_{n\to\infty}\int f_nd\mu. 
\end{eqnarray*} To prove that the order of the two limits can be reversed, we only need to prove: (1). $\lim_{n\to\infty,N\to\infty}f^N_nd\mu$ exists; (2). for any $n\in\mathbb{N}$, $\lim \int f^N_nd\mu$ exists; (3). for any $N\in\mathbb{N}$, $\lim_{n\to\infty}\int f^N_n d\mu$ exists. (2) is obtained by Lebesgue dominated convergence theorem. (3) is obtained by Egoroff theorem: for any $\delta>0$, there exists $E\subseteq [0,1]$, $\mu(E)<\delta$ such that $f_n^N\to^n f^N$ uniformly on $[0,1]\setminus E$. Hence for any $\epsilon >0$, there exists $n_0$ such that for any $n\geq n_0$,  $|f^N_n-f^N|<\epsilon$. Thus 
\begin{eqnarray*}
|\int_{[0,1]\setminus E} f^N_n d\mu-\int_{[0,1]\setminus E} f^N d\mu|<\epsilon.
\end{eqnarray*}
Let $N$ be fixed. Choose $\epsilon=2N\delta$. Then
\begin{eqnarray*}
|\int_{E} f^N_n d\mu-\int_{E} f^N d\mu|\leq \int_E |f^N_n-f^N|d\mu\leq 2N\mu(E)<\epsilon.
\end{eqnarray*}
Hence for all $n\geq n_0$, 
\begin{eqnarray*}
|\int f^N_n d\mu-\int f^N d\mu|
&\leq&|\int_{E} f^N_n d\mu-\int_{E} f^N d\mu|+|\int_{[0,1]\setminus E} f^N_n d\mu-\int_{[0,1]\setminus E} f^N d\mu|\\
&<& 2\epsilon.
\end{eqnarray*}
Since $\delta>0$ is arbitrary, $\epsilon=2N\delta$ is also arbitrary. Hence we obtain (3). But I do not know how to prove (1). Until now, I have not used the given conditions (a), (b). How to prove the double limit exists by applying (a) and (b)? Without (a) or (b), the double limit in (1) may not exist?","['convergence-divergence', 'integration', 'measure-theory', 'real-analysis', 'analysis']"
811285,"Show there are $b, c \in \mathbb{R}$ such that $f(x)= {a\over 2}x^2 + bx + c$","Given $f:I\rightarrow \mathbb{R}$ and $f''(x) = a.\forall x\in I$.
  Show there are $b, c \in \mathbb{R}$ such that $f(x)= {a\over 2}x^2  + bx + c$. If we define $g(x) = ax + b$, then $g'(x) = f''(x) = a$. Therefore, $f'(x)$ and $g(x)$ are equal (maybe differ by a constant). Hence, $f'(x)$ has to have the form: $f'(x) = ax + b$ I've been told to use Lagrange's Mean Value Thm but I'm not sure why the above alone isn't sufficient. P.S I wrote ""Therefore, $f'(x)$ and $g(x)$ are equal (maybe differ by a constant)"". How should I write it in a more professional/mathematical way?","['calculus', 'derivatives', 'real-analysis']"
811286,Divergence of the sequence $\sin(n!)$,"Does the sequence $\sin(n!)$ diverge(converge)? It seems the sequence diverges. I tried for a contradiction but with no success.
Thanks for your cooperation.",['analysis']
811299,Geometric proof : infinite dissimilar right triangles with integral sides,"Wha is the proof that there are infinitely many right angled (non-similar) triangles whose sides have integral lengths? I know that this is equivalent to showing that there are infinite pythagorean triples, which can be proven easily, but I would like to know about any purely geometrical proof.",['geometry']
811349,"Procedure for evaluating $\int_{x=\ -1}^1\int_{y=\ -\sqrt{1-x^2}}^{\sqrt{1-x^2}}\frac{x^2+y^2}{\sqrt{{1-x^2-y^2}}}\,dy\,dx$","While solving another problem I have come across this integral which I am unable to evaluate. Can someone please evaluate the following integral? Thank you. $$\int_{x=\ -1}^1\int_{\large y=\ -\sqrt{1-x^2}}^{\large\sqrt{1-x^2}}\frac{x^2+y^2}{\sqrt{{1-x^2-y^2}}}\,dy\,dx.$$ I know the answer is $\dfrac{4\pi}3$, but I am more interested in the procedure followed to get to this answer.","['definite-integrals', 'multivariable-calculus', 'calculus', 'integration']"
811352,Find all entire functions such that $|f(z)|\leq |z^2-1|$ for all $z\in\mathbb C$.,Find all entire functions such that $|f(z)|\leq |z^2-1|$ for all $z\in\mathbb C$. For large $z$ we have $$|f(z)|\leq 2|z|^2$$ so $f$ is a polynomial of degree $\leq 2$. But how to continue? Could someone give me a hint?,['complex-analysis']
811355,About a spectrum of a C*-algebra,"Let $A$ be an unital commutative C*-algebra.
Show that the spectrum of $A$ is disconnected iff there is a projection $p \in A$ not trivial.","['c-star-algebras', 'functional-analysis']"
811357,Differential equation $y''=e^y $,"Is there a quick way of finding $y(t)$ which satisfies the following equation:$$y''=e^y \ ?$$ Usually when given equation $ax''+bx'+cx=0$ I looked for roots of characteristic polynomial, but in this case I'm not sure how to proceed.",['ordinary-differential-equations']
811358,What are the prerequisites for reading SGA 1?,"My question concerns, basically, scheme theory. If there is someone who has actually read SGA 1, I would really like to hear what their opinion is on that. For example, is EGA in its entirety a prerequisite for SGA 1? And if not, what is really required for understanding this piece of work of Grothendieck?","['category-theory', 'algebraic-geometry', 'book-recommendation', 'reference-request']"
811363,What is a substitute for $\textrm{Sym}^n(X)$ when $X$ is not quasi-projective?,"If $X$ is a quasi-projective variety, then for each integer $n\geq 0$ one can define the symmetric product to be the scheme quotient $$\textrm{Sym}^n(X)=X^n/S_n,$$ where $S_n$ is the symmetric group and $X^n$ is $n$-fold power of copies of $X$ over the base field. I am not sure, but I think one can also characterize $\textrm{Sym}^n(X)$ as the scheme representing the functor of ""unordered $n$-tuples of points"" in $X$, which I should probably refer to as effective zero cycles of degree $n$. I heard that the construction of $\textrm{Sym}^n(X)$ does not work if $X$ is not necessarily quasi-projective. I suppose this means (both) that there is no scheme quotient $X^n/S_n$ as above, and that the above functor is not representable. Question . Is there a geometric object (maybe not a scheme anymore) that replaces $\textrm{Sym}^n(X)$ when $X$ is not quasi-projective? Thank you in advance.",['algebraic-geometry']
811376,Hessian of a square root of a quadratic form,"What is the Hessian matrix of the square root of a quadratic form: $\left(w^T H w\right)^{0.5}$? Got the gradient, $0.5  \left(w^T H w\right)^{-0.5}   ( 2   H   w)$, which gives numerically correct results, but I fail with classical differentiation rules in calculating the Hessian.","['multivariable-calculus', 'linear-algebra', 'partial-derivative']"
811387,Characterization of positive definite matrix with principal minors,"A symmetric matrix $A$ is positive definite if $x^TAx>0$ for all $x\not=0$. However, such matrices can also be characterized by the positivity of the principal minors. A statement and proof can, for example, be found on wikipedia: http://en.wikipedia.org/wiki/Sylvester%27s_criterion However, the proof, as in most books I have seen, is very long and involved. This makes sense in a book where you wanted to prove the other theorems anyway. But there has to be a much better way to prove it. What is the ""proof from the book"" that positive definite matrices are characterized by their $n$ positive principal minors?","['positive-definite', 'matrices', 'linear-algebra', 'alternative-proof', 'determinant']"
811391,"$f_n(x):=nx(1-x)^n$ Determine whether the sequence $(f_n)$ converges uniformly on $[0,1]$","I am having a bit of trouble on this revision question. To determine pointwise convergence: $\lim_{n\rightarrow\infty} = nx(1-x)^n $. For $x=0, x=1$, it's clear that the limit is $0$. How can I determine the limit for $0 \le x \le 1$? (My limit finding skills are rusty). I'm quite sure it is $0$ as well, but how do I go about showing this properly? Supposing this is true, then to determine uniform convergence, let $d_n(x):= |f_n(x)-f(x)|= nx(1-x)^n - 0$ Then $$ d_n'(x)= n(1-x)^n - n^2(1-x)x = 0$$ if $x=1$. So the maximum of $f_n(x)$ occurs at $x=1$. It follows that: $$0 \le d_n(x)= |f_n(x)-f(x)|< d_n(1) = 0$$ So $(f_n)$ converges uniformly 
on $[0,1]$. Would this be correct? Thanks for the help in advance!","['analysis', 'sequences-and-series', 'uniform-convergence', 'limits']"
811392,"If $P(x) = ax^2 + bx + c$ and $Q(x) = -ax^2 + dx + c$, then prove that $P(x) \cdot Q(x) = 0$ has at least two real roots?","How should i solve the same? I assumed the roots be $ \alpha, \beta $ for $ P(x) $ and $ \gamma, \delta $ for $ Q(x) $. Product of roots turn out to be of the opposite signs, being $$ \alpha \cdot \beta = \dfrac{c}{a} \\ \gamma \cdot \delta = - \dfrac{c}{a} $$ Thus if I multiply the equation, I should get 4 solutions to the equation.
So I equated the quadratic formula giving solutions for $ P(x) $ with $ Q(x) $ and cancelled out the common term $ 2a $ Now if I multiply the 4 terms left over together, I should get $ c^2 $ shouldn't I? Since I am multiplying the roots and I already cancelled out $ 2a $ when I multiplied it? I do not understand how to proceed, or if any of my assumptions above are correct. Kindly comment on the same and possibly guide me through it?","['quadratics', 'algebra-precalculus']"
811393,Find all entire functions such that $|f(z)|\leq |\sin(z)|$ for all $z\in\mathbb C$.,"Find all entire functions such that $|f(z)|\leq |\sin(z)|$ for all $z\in\mathbb C$. Half an hour ago I asked the same question for $|f(z)|\leq |z^2-1|$ here but this time I cannot say something like
$$|f(z)|\leq M|z|^m$$
so I don't know how to start. The problem is that
$$
\sin(z) = \frac{e^{iz}-e^{-iz}}{2i}
$$
gets really large if $z$ gets large.",['complex-analysis']
811444,How to integrate $\int_0^\pi \frac{1}{\sqrt{1+k^2\sin^2\phi}} d \phi$?,"I am currently dealing with the integral
$$\int_{0}^{\large\pi}\frac{{\rm d}\phi}
{\,\sqrt{\vphantom{\Large A}\,1 + k^{2}\sin^{2} \phi \,}\,}
$$ I know that if I had a minus sign in the denominator, then this would be similar to an elliptic integral, but in this case, I don't really know what this is.","['definite-integrals', 'calculus', 'integration', 'real-analysis']"
811451,Can we find this infinite root in term of elementary function? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let $f(x)=\left(x+f(x+1)\right)^\frac{1}{x}$. What is the value of $f(2)$ ?
More precisely,  how to find the value of $$\sqrt{2+\sqrt[3]{3+\sqrt[4]{4+\cdots}}}~?$$ Thank you.","['nested-radicals', 'calculus', 'algebra-precalculus', 'real-analysis', 'analysis']"
811467,Explanation of differential forms and notation,"I'm doing multivariable calculus and I'd love if someone could shed some light on things that confuse me. When we did integrals of real functions with real variables, the $dx$ that was in every integral wasn't really explained. It basically only had syntactical meaning. Now, it seems like the semantic meaning is what I'm having trouble with. What does $da$ where $a$ is any symbol actually mean? Sometimes it looks like it's the differential of a functions (if $a$ is a function), sometimes it's just a projector to a specific coordinate and sometimes it looks like it's just syntax and it's ignored. For example, when we did integrals like $\int xdx+x^2ydy$ and looked for a functions that produced that differential form we treated $xdx$ as, ""when we calculate the partial derivative over $x$ of function $f$ we get $x$"" (might not be correct due to bad English translation) but then when we looked at the ""change in angle form"" we treated $dx$ and $dy$ as something we need to calculate. Also, where does the $\partial$ symbol come into play? People usually read it as just $d$ so I'm wondering how related are those? I know this seems like I'm asking many question but what I'd really like to know is some intuitive explanation of the whole concept. Maybe someone else that was in my shoes before but ""gets it"" now can provide some tips?","['multivariable-calculus', 'differential-forms']"
811480,Can any function on naturals be interpolated to a smooth function on reals?,"Let $f : \mathbb{N} \rightarrow \mathbb{N}$ be an arbitrary function from naturals to naturals. Is it always possible to find a function $g : \mathbb{R} \rightarrow \mathbb{R}$ such that for any $n \in \mathbb{N}$ , we have $f(n) = g(n)$ , and $g \in C^\infty$ ? I'm asking because I was trying to prove a result about the ratios of functions from naturals to naturals and it occurred to me that if I could always interpolate to get back smooth functions from integers to integers, I could conceivably use l'Hopital's rule to resolve the limits. Thanks!","['interpolation', 'derivatives', 'functions']"
811533,Trigonometric Question: $\sqrt2\sin10 (\sec5+\frac{2\cos 40}{\sin5}-4\sin35)=...$,"How to compute the following trigonometric question
$$\sqrt2\sin10 (\sec5+\frac{2\cos 40}{\sin5}-4\sin35)=...$$
I am having problem to solve this trigonometric question. I tried to use identity $\sin10=2\sin5\cos5,\cos40=\cos(45-5), and \sin35=\sin(30+5)$ but it became complicated and I cannot simplify into a simpler term. I checked on Wolfram Alpha and it seemed the answer is 4 but I cannot get it. Could anyone here help me? Any help would be appreciated. Thanks in advance.",['trigonometry']
811535,Every prime power $p^k$ that divides $\binom{2m}{m}$ is smaller than or equal to $2m$,"I want to show that every prime power $p^k$ that divides $\binom{2m}{m}$ is smaller than or equal to $2m$. As a first step, I looked at
$$\binom{2m}{m}
= \frac{(2m)!}{(m!)^2}
= \frac{2m(2m-1) \ldots (m+2)(m+1)}{m!} \, .$$
Here I'm essentially stuck. I can apply the prime factorization to numerator and denominator, then I can cancel and I know that $p^k$ is left over in the numerator. But I cannot conclude $p^k \leq 2m$. I feel that some vital ingredient is missing here, but I don't know what it is. (Post edited with respect to the helpful comment.)",['number-theory']
811552,If $(A\times B) \cap (C\times D)=\varnothing$ then either $A\cap C=\varnothing$ or $B\cap D=\varnothing$.,"Prove that for any sets A, B, C, and D, if A × B and C × D are disjoint,
then either A and C are disjoint or B and D are disjoint. Proof(someones). Suppose (A X B) and (C X D) are disjoint. Let (x,y) be an arbitrary ordered pair of (A X B), it follows that $(x,y) \notin (C X D)$. So either $x \notin C$ or $y \notin D$. Since x,y are arbitrary, Thus either A and C are disjoint or B and D are disjoint. I think the above proof is wrong since it assumes (x,y) is an arbitrary ordered pair of (A X B) without any logical justification(no existential instantination). My Proof.(Contrapositive) Suppose $A\cap C \ne \emptyset $ and $B\cap D \ne \emptyset$. It follows that there exist an element $a\in A\cap C$ and $b\in B\cap D$. Since $a\in A$ and $b\in B$ then $(a,b)\in A× B$ and since $a\in C$ and $b\in D$ then $(a,b)\in C×D$. So $(a,b)\in A×B \cap C×D$. So A × B and C × D not disjoint. As for the first proof I can understand the ""Suppose (A X B) and (C X D) are disjoint"" part. But I cant understand the logical justification of assuming an element (x,y) in AXB since by making this assumption you are also assuming that A or B are not $\emptyset$ which makes the proof invalid as you are assuming something not given. Also A,B,C,D are supposed to be arbitrary sets. My questions here are: 1) Is the first one correct ? If it is what is its logical justification. 2)Is my proof correct ? If not, what is my mistake ?","['elementary-set-theory', 'proof-verification', 'fake-proofs']"
811596,"Let $F_1,F_2:\bf R^2 \to R$ be functions such that....","I am stuck with the following problem : Let $F_1,F_2:\bf R^2 \to R$ be functions such that $$\begin{align*} F_1(x_1,x_2)=\frac{-x_2}{x_1^2+x_2^2} \\ F_1(x_1,x_2)=\frac{x_1}{x_1^2+x_2^2}\end{align*}$$ Then which of the following  ARE  correct? $\displaystyle \frac{\partial{F_1}}{\partial{x_2}}=\frac{\partial{F_2}}{\partial{x_1}}$ $\exists\,\,$ a function $f \colon \bf R^2 \backslash \{(0,0)\} \to R$ such that 
  $\displaystyle \frac{\partial{f}}{\partial{x_1}}=F_1$ and $\displaystyle \frac{\partial{f}}{\partial{x_2}}=F_2$ $\nexists \,\,$ a function $f \colon \bf R^2 \backslash \{(0,0)\} \to R$ such that 
  $\displaystyle \frac{\partial{f}}{\partial{x_1}}=F_1$ and $\displaystyle \frac{\partial{f}}{\partial{x_2}}=F_2$ $\exists$ a function $f \colon \bf D \to R$ where $\bf D$ is the open disc of radius $1$ centered at $(2,0)$ which satisfies $\displaystyle \frac{\partial{f}}{\partial{x_1}}=F_1$ and $\displaystyle \frac{\partial{f}}{\partial{x_2}}=F_2$ I have only been able to show that option 1 is true and $\displaystyle \frac{\partial{F_1}}{\partial{x_2}}= \frac{\partial{F_2}}{\partial{x_1}}=\frac{-x_1^2+x_2^2}{(x_1^2+x_2^2)^2}$  . But I am not sure about other options .Clearly, only one of the options 2,3 can hold (I do not know how to prove it.) Abou option 3, I have no idea. Can someone please clarify by giving a detailed explanations . Thank you very much.","['partial-derivative', 'calculus', 'functions']"
811603,A maximal subalgebra of $E_6$ !?,"I'm puzzeled by the following sentence in one of Baez's posts : The Lie algebra $E_6$ has a subalgebra of maximal rank isomorphic to $\mathfrak{so}(10)\oplus \mathfrak{u}(1)$. However, I thought that the maximal subalgebras of a Lie algebra were obtained by deleting a dot in the $extended$ Dynkin diagram: But I can only obtain $\mathfrak{so}(10)\oplus \mathfrak{u}(1)$ by deleting a dot in the (normal) Dynkin diagram of $E_6$...???","['lie-groups', 'lie-algebras', 'group-theory']"
811642,How to explain tie-correction for Spearman's Rank Correlation?,In Mathematics at my college we are being taught correlation in which when there are ties in ranks we take average rank for all of the ties and then total correction factor is added summation of square of difference in ranks. The formula for correction factor is $$\frac{m(m^2 - 1)}{12}.$$ Where did this correction factor formula came from ? How is it derived? I can't get my mind around it.,"['statistics', 'correlation']"
811647,Expectation Involving Two Values of Geometric Brownian Motion,"Not sure this is the best place to ask for verification, but I can't seem to find a derivation anywhere else.  I want to calculate $\mathbb{E}[e^{\sigma(W_t + W_s)}]$, where $W_t$ and $W_s$ are two values of a standard Brownian motion and $\sigma$ is some positive constant.  WLOG assume $s < t$ and let $\mathcal{F}$ be the filtration generated by the Brownian motion.  Then using standard results I get $$
\begin{align*}
\mathbb{E}[e^{\sigma(W_t + W_s)}] & = \mathbb{E}[\mathbb{E}[e^{\sigma(W_t - W_s)}e^{2\sigma W_s}| \mathcal{F}_s]] \\ 
& = \mathbb{E}[\mathbb{E}[e^{\sigma(W_t - W_s)}]e^{2\sigma W_s}] \\
& = \mathbb{E}[e^{2\sigma W_s}]e^{\frac{1}{2}\sigma^2(t-s)} \\
& = e^{2\sigma^2 s + \frac{1}{2}\sigma^2(t-s)} \\
& = e^{\frac{1}{2}\sigma^2(3s + t)}.
\end{align*}
$$ Thanks!","['stochastic-processes', 'probability', 'brownian-motion']"
811666,How to show that two multivariate normal distributed random variables are independent?,"Let $X\sim N(\mu_1,V_1),~~Y\sim N(\mu_2,V_2)$. How can I show that $X$ and $Y$ are independent? I am wondering how I can show this. I only know the following case: $Z=(Z_1,\ldots,Z_n)\sim N(\mu_3,V_3)$: Then $Z_i$ are independent if $\text{cov}(Z_i,Z_j)$ for all $i\neq j$. But here the situation is different, because $X$ and $Y$ are both multivariate normal distributed. Indeed I do not know how to show the independence in this case. Can you help me?",['statistics']
811703,Countable sum of atomic measures is atomic?,"Let $(X,\Sigma)$ be a measurable space and $(\mu_n)$ a sequence of atomic measures defined on this space. Recall that a measure $\mu$ is atomic if for any measurable $A$ of measure $\mu(A)>0$ there is some measurable $E \subset A$ that is an atom, which means that $\mu(E)>0$ , and for any measurable $F\in X$ , either $\mu(E\cap F)$ or $\mu(E-F)=0$ .
Consider the measure $\mu=\sum_{n\in \mathbb{N}} \mu_n$ . Is it true that $\mu$ must be atomic? This question is raised (but not answered) here . EDIT: The answer below by @George reflects the question (here) when it was previously required that the measure not take on infinite value.  This is not the correct definition, and does not reflect the original question of Roy A. Johnson.",['measure-theory']
811717,Does the sequence $\{\sin^n(n)\}$ converge?,Does the sequence $\{\sin^n(n)\}$ converge? Does the series $\sum\limits_{n=1}^\infty \sin^n(n)$ converge?,"['convergence-divergence', 'sequences-and-series', 'real-analysis', 'diophantine-approximation']"
811759,Sum of product partitions of divisors,"Let $M(n)$ be the the set of the multiplicative partitions of $n$, and let $D(n)$ be the set of the sum of the multiplicative partitions of the divisors of $n$. eg $M(30)=\{\{30\},\{2,15\},\{3, 10\}, \{5, 6\}, \{2, 3, 5\}\}$ and $D(30)=\{30,17,13,11,10\}$ This can be normalised and plotted by pairing up the ordered set $\log D$ with $x=\{1,2,3\dots\}$, which in this case would yield the plot points $\{\{1,\log10\},\{2,\log11\},\{3,\log13\},\{4,\log17\},\{5,\log30\}\}$. It appears that  these points are normally distributed: (plot of $\log F(6\ 469\ 693\ 230)$), which is fairly obvious intuitively. Is this an incarnation of the Erdős–Kac theorem ? Likely proving this would be difficult? Notes Mathematica code for primorials (which are easiest to compute for large $n$): << Combinatorica`
primorial = 10;
a = Range[primorial];
b = Thread[a -> Prime[a]];
c = Apply[Times, SetPartitions[a] /. b, {2}];
ListLinePlot[Log[Sort[Map[Total[c[[#]]] &, Range[Length[c]]]]]] General code for any $n$: n = 1000;
α[1, r_] := α[1, r] = 1;  α[n_, r_] := α[n, r] = 
Module[{s, i}, s = Select[Divisors[n], 1 < # <= r &];
Sum[α[n/s[[i]], s[[i]]], {i, 1, Length[s]}]]; β[n_]:= α[n, n]; γ[lst_, p_] := 
Module[{t, i, j}, Union[Flatten[Table[t = lst[[i]]; t[[j]] = p*t[[j]];
Sort[t], {i, Length[lst]}, {j, Length[lst[[i]]]}], 1], 
Table[Sort[Append[lst[[i]], p]], {i, Length[lst]}]]];
δ[n_] := Module[{i, j, p, e, lst = {{}}},{p, e} = Transpose[FactorInteger[n]];
Do[lst = γ[lst, p[[i]]], {i, Length[p]}, {j, e[[i]]}]; lst];
ListLinePlot[Log[Sort[Map[Total[δ[n][[#]]] &, Range[β[n]]]]], 
InterpolationOrder -> 0] Colossally abundant numbers also produce relatively smooth plots: \[NumberSign][n_] := Times @@ Prime[Range[n]];
n = 2^3 3^1 \[NumberSign][5];","['prime-numbers', 'number-theory', 'probability', 'combinatorics']"
811765,Counterexamples for L1-convergence not implying L2-convergence and vice versa,"I am trying to find counterexamples for the following statements. Let $\{f_n\}$ be a sequence in $L^1(\mathbb{R}^d) \cap L^2(\mathbb{R}^d)$ , and let $f$ also be in $L^1(\mathbb{R}^d) \cap L^2(\mathbb{R}^d)$ . $f_n \stackrel{L^1}{\longrightarrow} f$ implies $f_n \stackrel{L^2}{\longrightarrow} f$ $f_n \stackrel{L^2}{\longrightarrow} f$ implies $f_n \stackrel{L^1}{\longrightarrow} f$ A counterexample for the first statement would be $f_n:= \sqrt{n}\cdot \chi_{[0,1/n]}$ and $f\equiv 0$ . However, I am having trouble figuring out a counterexample for the second statement. I originally thought it was true but apparently it is not... Any hints for a counterexample would be appreciated. I would also like to know if there are any extra conditions that would make the second statement true.","['convergence-divergence', 'examples-counterexamples', 'measure-theory', 'lebesgue-integral', 'functional-analysis']"
811806,Proof that frobenius norm is a norm [duplicate],"This question already has answers here : Frobenius Norm Triangle Inequality (2 answers) Closed 10 years ago . It's pretty basic and I'm sure I'm missing something dumb here, but I'd like to know why $||A+B||_F \leq ||A||_F+||B||_F$ The way I understand it, $||A+B||^2_F=tr((A+B)^T(A+B))=tr((A^T+B^T)(A+B))=tr(A^TA+A^TB+B^TA+B^TB)$ Now using the property the trace is linear: $tr(A^TA+A^TB+B^TA+B^TB) = tr(A^TA)+tr(B^TB)+tr(A^TB+B^TA)=||A||^2_F+||B||^2_F+tr(A^TB+B^TA)$ Now if we were to prove that $2||A||_F||B||_F \geq tr(A^TB+B^TA)$ that would solve the question. But I don't see how that's trivial, and generally multiplying $\sum$s together is something I avoid like the plague. Is this indeed the way? would someone help me with this last step?","['trace', 'matrices', 'normed-spaces', 'linear-algebra']"
811815,Lampshade Geometry Problem,"Today, I encountered a rather interesting problem in a waiting room: $\qquad \qquad \qquad \qquad$ Notice how the light is being cast on the wall?  There is a curve that defines the boundary between light and shadow.  In my response below, I will prove, algebraically, that this curve is a hyperbola.  I'm also interested in seeing a variety of other solutions, so please feel free to post your own.","['analytic-geometry', 'geometry', 'conic-sections', 'proof-verification']"
811834,Topological definition of continuity and its application to epsilon-delta definition? [duplicate],"This question already has answers here : How is the epsilon-delta definition of continuity equivalent to the following statement? (4 answers) Closed 2 years ago . So I am beginning Munkres' textbook on topology. The topological definition of continuity reads: $f:X\rightarrow Y$ is continuous if for each open subset $V\subset Y$, $f^{-1}(V)$ is an open subset of $X$. Of course, it does fit the epsilon-delta definition of continuity since in $\forall\epsilon\exists\delta,|x-x_0|<\delta\Rightarrow|f(x)-f(x_0)|<\epsilon$ $|x-x_0|<\delta$ and $|f(x)-f(x_0)|<\epsilon$ are both open. Also, since openess of a set means closeness of that set's complement, the following epsilon-delta definition (which is valid) also agree with the topological definition: $\forall\epsilon\exists\delta,|x-x_0|\le\delta\Rightarrow|f(x)-f(x_0)|\le\epsilon$ Yet my question is, how about the following epsilon-delta definition? $\forall\epsilon\exists\delta,|x-x_0|\le\delta\Rightarrow|f(x)-f(x_0)|<\epsilon$ 1.) Is it a valid definition of continuity of $\mathbb{R}^n$ regardless of the topological definition? 2.) If yes, does it agree with the topological definition of continuity?","['general-topology', 'continuity', 'real-analysis']"
811849,How to convert data points into an equation,"Very often, I can easily see that my data has a ""pattern"". This pattern usually resembles something as simple as multiplying the previous point by 1.2 or 1.3. But it can also appear to be exponential or parabolic. The problem is when I know that there ""should be one"" but I'm not smart enough to extract it mathematically. Is there a way to convert data into an equation? For instance, I'm stumped: 3, 3000
5, 1000 = 0.333
7, 500 = 0.5
9, 300 = 0.6
11, 200 = 0.6667
13, 140 = 0.7
15, 105 = 0.75
17, 81.67 = 0.7778
19, 65.33 = 0.8
21, 53.35 = 0.816667 I ""know"" I should be seeing a pattern here.
But, what is it? And, how can I get it?
I do not know.",['functions']
811862,Gaussian Matrix Integral,"I need your help to solve this exercise : Let $S$ be a symmetric Hermitian matrix $N\times N$ : $S=(s_{ij})$ with $s_{ij}=s_{ji}$. When $\langle s_{ij}s_{kl}\rangle\neq 0$ What $$\int Tr(S^{2n})\;d\mu(s)$$ counts? Calculate the moments of the matrix trace given by $$
\int Tr(S^2) dS,\quad \int Tr(S^4) dS
$$
where S is a real symmetric matrix satisfying $S_{ij}=S_{ji}$. We are supposed to use The Wick Theorem to solve it. any idea on how to calculate this, thank you.","['integration', 'definite-integrals', 'measure-theory', 'matrices', 'linear-algebra']"
