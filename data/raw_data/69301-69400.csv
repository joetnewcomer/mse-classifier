question_id,title,body,tags
839419,if $f$ is differentiable at $x_0$ then the limit exists,"Let $f$ differentiable at $x_0$. Show that the following limit exists $$ \lim_{h\rightarrow0} \frac{f(x_0+h)-f(x_0-h)}{h}$$ If $f$ is differetiable at $x_0$ then it's one-sided derivative exists and equal. Hence, $$ \lim_{h\rightarrow0^+} \frac{f(x_0 +h)-f(x_0)}{h} = \lim_{h\rightarrow0^-} \frac{f(x_0 
+h)-f(x_0)}{h} $$ Now, technically if I do a simple arithmetic I can get the answer (move the right limit and ""join"" them). Moreover, the limit exists and equals $0$. But, I cannot just join them because they're not the same. What should I do?","['calculus', 'derivatives', 'real-analysis', 'limits']"
839423,A generalized combinatorial identity for a sum of products of binomial coefficients,"I have the following question. For given natural numbers $n$ and $d$, let $a_1,a_2,..., a_r$ be fixed integers such that $a_1+\cdots+a_r=d$. Let $A=\{(i_1,..,i_r)~|~0\le i_j\le n~ \text{and}~ i_1+\cdots+i_r=n\}$. $$\underset {(i_1,...,i_r)\in A} \sum {i_1\choose a_1}{i_2\choose a_2}\cdots{i_r\choose a_r}= {n+r-1\choose d+r-1}$$ Is the above combinatorial identity true ? 
I know that this is true when $r$ is $2$.","['discrete-mathematics', 'binomial-coefficients', 'combinatorics']"
839426,How do I evaluate the integral $\int_0^{\infty}\frac{x^5\sin(x)}{(1+x^2)^3}dx$?,"I have no idea how to start, it looks like integration by parts won't work. $$\int_0^{\infty}\frac{x^5\sin(x)}{(1+x^2)^3}dx$$ If someone could shed some light on this I'd be very thankful.","['definite-integrals', 'improper-integrals', 'calculus', 'integration']"
839500,Is it true that every eigenvalue has at least one eigenvector?,"As mentioned above: Is it true that every eigenvalue has at least one eigenvector? Or is it possible that while trying to find the basis of a specific eigenspace, i will get only the zero vector (means there are no eigenvectors corresponding to this eigenvalue)? Thank you","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
839536,Roots of derivative of q-expontial function,"Let the q-deformation of the exponential function be defined by $$
e_q(z)=\sum_{n=0}^\infty{\frac{z^n}{[n]_q!}}.
$$ Eq. (1.8) of this paper provides the product representation $$
e_q(z)=\prod_{k=0}^\infty{\left[1+z q^{-k}\left(1-\frac1q\right)\right]}.\tag{*}
$$ This formula shows that the roots of $z\mapsto e_q(-z)$ are given by $$
z_k=\frac{q^{k+1}}{q-1}.
$$ Question : Are there similarly simple formulas for the roots of the derivative(s)
  of the q-exponential function? Many thanks. Edit 1 : Computing the logarithmic derivative of the product (*) we find that the zeros of the derivative of $e_q(-z)$ are the same as the zeros of $$
\sum_{n=1}^\infty{\frac{1}{z-\frac{q^n}{q-1}}},\tag{**}
$$ which can be evaluated in terms of the q-digamma function. Taking $q=2$, which is indeed the case I am most interested in, this becomes
$$
\sum_{n=1}^\infty{\frac{1}{z-2^n}}.
$$ The numerical value of the first root $z_0\approx2.83643\; 10564\; 48581\; 92032\; 21153\; 61015$ (thank you @AntonioVargas) is not recognized by any of the inverse symbolic calculators. Edit 2 : Inspired by this paper I was able to compute that, for $|z|<q/(q-1)$, $({}^{**})$ can be written as
$$
\frac{1}{z(q-1)}\log_q\left(1-z(q-1)\right),
$$
where
$$
\log_q(1-z)=-\sum_{n=1}^\infty{\frac{z^n}{[n]_q}}
$$
is a series representation of the the q-logarithm. Unfortunately, the smallest zero of $({}^{**})$ is larger than $q/(q-1)$, so this is not very helpful. Question 2 : Does there exist a similar reformulation of $({^{**}})$ that is valid for $q^k/(q-1)<z<q^{k+1}/(q-1)$ for
  $k\geqslant 2$? The answer to this question is 'yes'. More precisely, for each integer $K\geq 1$ and $q>1$ we have
$$
\sum_{n=1}^\infty{\frac{1}{z-\frac{q^n}{q-1}}}=\sum_{k=1}^K{\frac{1}{z-\frac{q^k}{q-1}}}+\frac{1}{z(q-1)}\log_q\left(1-z\frac{q-1}{q^K}\right),\quad |z|<\frac{q^{K+1}}{q-1}.
$$ In particular, setting $K=1$ and $q=2$, the zero $z_0\in[2,4]$ that I am after satisfies
$$
\frac{1}{1-\frac{2}{z_0}}+\log_2\left(1-\frac {z_0}{2}\right)=0.
$$","['sequences-and-series', 'roots', 'exponential-function', 'q-analogs', 'derivatives']"
839542,Integrating powers of linear and quadratic functions,"How can I integrate function such as $(x+9)^3$? I obviously know that I can expand the function and integrate it normally. However, that is possible and feasible only as it is of third degree. What if the function is more like: $(x^2-9x+5)^7$? How could I integrate this function?","['calculus', 'integration', 'indefinite-integrals']"
839550,Linear continuum is convex,"Definition. A simply ordered set $L$ having more than one element is called a linear continuum if the following hold: (1) $L$ has the least upper bound property (2) If $x < y$, there exists $z$ such that $x < z < y$. A subspace $Y$ of $L$ is said to be convex if for every pair of points $a, b$ of $Y$ with $a < b$, the entire interval $[a,b]$ of points of $L$ lies in $Y$. I'm trying to prove the obvious fact that a linear continuum in the order topology is a convex space. I've been trying to prove this by way of contradiction using the above two properties, but have been unsuccessful so far. Can anyone help me out?",['general-topology']
839554,$\exists x_0$ such that $f(f(x_0))=x_0$ prove that $f$ has a fixed point,"Let $f:\mathbb R\to \mathbb R$ be coninuous. Suppose there exists $x_0$ such that $f(f(x_0))=x_0$. Prove that $f$ has a fixed point or in other words: $\exists c\in\mathbb R: f(c)=c$ . Suppose $f(x_0)\neq x_0$ and there's some $x_1$ such that $f(x_1)=x_0$. Then: $f(f(x_1))=f(x_0)\neq x_0$ and, $f(f(x_0))=f(x_2)=x_0$ but $f(x_1)=x_0$ and since the function is continuous there can't be $x_1\neq x_2: f(x_1)=f(x_2)$ so there's a contradiction.","['calculus', 'proof-verification', 'functions']"
839628,What is a fair game?,"Suppose $X_n$ is the fortune of a gambler after $n$ th game. Then the game is called fair (Breiman 1968) if $$E[X_{n+1} \mid X_1, \dots, X_n] = X_n \forall n$$ My question is why a fair game is not defined as the following $$E[X_{n+1}] = E[X_n] \forall n$$ i.e. $$E[X_{n+1}- X_n]=0$$. This should be the proper definition as a fair game is where avg. gain is zero. Nothing conditioning should be there.","['probability-theory', 'martingales', 'conditional-probability']"
839657,How to find the following limit? $\lim\limits_{t \to {\pi}/{2}}\frac{ \int_{\sin t}^{1}e^{x^2\sin t}dx}{\int_{\cos t}^{0}e^{x^2 \cos t}dx}.$,"I am trying to solve the limit $$\lim\limits_{t \to \pi/2}\frac{ \int_{\sin t}^{1}e^{x^2\sin t}dx}{\int_{\cos t}^{0}e^{x^2 \cos t}dx}$$ My first method was to try with L'Hopital, i derived using Leibniz rule: $$\eqalign{\frac{\partial}{\partial t} \left(\int_{\sin t}^{1}e^{x^2\sin t}dx\right)&=\int_{\sin t}^{1}e^{x^2 \sin t}x^2 \cos tdx-e^{\sin ^3 t}\cos t\\
&= \cos t\left(\int_{\sin t}^{1}x^2e^{x^2 \sin t}dx-e^{ \sin ^3 t}\right).\\}$$ In the same manner, we can see that $$\frac{\partial}{\partial t} \left(\int_{\cos t}^{0}e^{x^2 \cos t}dx\right) = -\sin t\left(\int_{\cos t}^{0}x^2e^{x^2 \cos t}dx-e^{\cos ^3 t}\right).$$ So overall we have: $$\lim\limits_{t \to \pi/2}\frac{ \int_{\sin t}^{1}e^{x^2\sin t}dx}{\int_{\cos t}^{0}e^{x^2 \cos t}dx} = \lim\limits_{t \to { \pi}/{2}} \frac{\cos t\left(\int_{\sin t}^{1}x^2e^{x^2 \sin t}dx-e^{ \sin ^3 t}\right)}{-\sin t\left(\int_{\cos t}^{0}x^2e^{x^2 \cos t}dx-e^{\cos ^3 t}\right)}.$$ But where do we go from here? Could we say that because $\lim\limits_{t \to \pi/2} \frac{\cos t}{\sin t} =0$ then the entire limit goes to $0$? I don't think we can... Would appreciate any input. Perhaps L'Hopital was not the way.","['multivariable-calculus', 'calculus', 'integration', 'limits']"
839659,"If $A$, $B$, $A-B$ and $I+A$ are invertible $n×n$ matrices then prove the following",i. $(A-B)^{-1} = A^{-1} + A^{-1}(B^{-1} - A^{-1})^{-1}$ ii. $(I+A)^{-1} = I-(A^{-1} + I)^{-1}$ iii. $tr((I+A)^{-1}) + tr((A^{-1} + I)^{-1}) = n$ I'm stuck on these. So far I only thought about taking the second half of each equation and try to find the first half but I had no success.,"['matrices', 'linear-algebra']"
839673,Validity of a trigonometric proof that $2 = 0$.,I can't find where this proof goes wrong. We know $$\tan(A - B)  = \frac{\tan A - \tan B}{1 + \tan A\cdot\tan B}$$ so $$\begin{align} \tan(90^\circ-45^\circ) &=  \frac{\tan 90^\circ -\tan 45^\circ}{1+\tan90^\circ\cdot\tan 45^\circ}\\[.3cm] \tan45^\circ &=\frac {\tan 90^\circ -\tan 45^\circ}{1+\tan90^\circ\cdot\tan45^\circ}\\[.3cm]1 &=\frac{\tan 90^\circ - 1}{1+\tan90^\circ}\\[.3cm] 1+\tan90^\circ &= \tan 90^\circ - 1 \\[.3cm]2 &= 0\end{align}$$ Where is the error?,"['trigonometry', 'fake-proofs']"
839693,Problem manipulating algebra in covariance formulas,"I've seen $\text{cov}(x,y)$ expressed as $$\dfrac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{n} \tag{1}$$ and also as $E[xy] - E[x]E[y]$. The latter expands to $$\frac{\sum_{i=1}^nx_iy_i}{n} - \left(\frac{\sum_{i=1}^nx_i}{n}\right)\left(\frac{\sum_{i=1}^ny_i}{n}\right) \tag{2}$$ Despite lots of effort trying to manipulate $(1)$ to become $(2)$ I've failed and would like some help. I started by expanding $(1)$ into $$\dfrac{\sum_{i=1}^nx_iy_i}{n} + \bar{x}\bar{y} - \dfrac{\sum_{i=1}^nx_i\bar{y}}{n} - \dfrac{\sum_{i=1}^ny_i\bar{x}}{n}$$ then eyeballing that with $(2)$ to get $$\bar{x}\bar{y} - \dfrac{\sum_{i=1}^nx_i\bar{y}}{n} - \dfrac{\sum_{i=1}^ny_i\bar{x}}{n} = -\left(\frac{\sum_{i=1}^nx_i}{n}\right)\left(\frac{\sum_{i=1}^ny_i}{n}\right) \tag{3}$$ I would like to be shown how to manipulate the LHS of $(3)$ to be the RHS.",['algebra-precalculus']
839699,"MLE of MVN($\mu, \Sigma$)","I'm trying to find MLE of MVN( $\mu, \Sigma$ ), i.e $N_k(\mu, \Sigma)$ with random sample $X_i, 1\le i \le n$ . It was easy to get $\widehat{\mu}= \bar{X}$ and $\hat{\Sigma} = \frac{1}{n} \sum_i (X_i - \bar{X})(X_i - \bar{X})'$ by using matrix differentiation. However, to be rigorous I need to explain the followings. log likelihood function is continuous and differentiable with respect to the parameters, i.e $(\mu, \Sigma)$ . Log-likelihood function goes to $-\infty$ as the parameter goes to its boundary. As far as I know, second derivative of log-likelihood(observed information) is negative definite and #2 are sufficient conditions for existence of unique MLE. Here's my opinion. About #1: Since log likelihood function has quadratic terms of $\mu$ , log likelihood function is continuous and differntiable w.r.t $\mu$ . Meanwhile, I can't explain why determinant of covariance matrix, which appears in log likelihood function, is continous and differentiable w.r.t $\Sigma$ . About #2: I also understand this relating to $\mu$ , but not $\Sigma$ . In other words, I wonder how to show $-\frac{n}{2}\log|\Sigma|-\frac{1}{2}\sum_i (X_i-\bar{X})'\Sigma^{-1}(X_i-\bar{X})$ , this function has diminishing boundary as parameters of $\Sigma$ goes to its boundary. Thanks for any comment in advance.","['statistics', 'normal-distribution']"
839700,properties of certain semigroup action on $\mathbb{Z}/p\mathbb{Z}$,"Suppose we have a polynomial $f \in \mathbb{Z}/p\mathbb{Z}[x]$, $f(x) = x^2 - x$. We are interested in elements  $n \in \mathbb{Z}/p\mathbb{Z}$ such that after repeated application of f they eventually hit 0. Can we characterize them nicely depending on $p$?","['dynamical-systems', 'p-adic-number-theory', 'number-theory']"
839715,How to evaluate the following integral? $\int \ln(e^x + c)~\mathrm dx$,"I can't seem to find an answer for this kind of integration, and I'd like to know if there is an answer for it, and if yes what is it. $$\int \ln(e^x + {c})~\mathrm dx\,,$$
where $c$ is a constant.
My teacher keeps avoiding me after I asked him, so I appreciate any help because I've tried everything I know.","['calculus', 'integration', 'indefinite-integrals']"
839716,Bernoulli Differential Equation of Second Order,"How one can solve a Bernoulli differential equation of second order?
i.e., solve the DE
\begin{align}
\frac{{d^2 y}}{{dx^2 }} + p\left( x \right)\frac{{dy}}{{dx}} 
+ q \left( x \right)y = g\left( x \right)y^n 
\end{align}
where $p$, $q$ and $g$ are continuous functions in an interval $(a,b)$ and $n$ is a real number.",['ordinary-differential-equations']
839721,relationship between complex numbers,Consider the following: Two equilateral triangles inscribed in a circle. The vertices of the large triangle are the geometric images of the three cubic roots of $z$ (a complex number). The small triangle vertices are the midpoints of the sides of the larger triangle. The vertices of the small triangle are the geometric images of the three cubic roots of $w$ (another complex number). What is the relationship between $w$ and $z$?,"['geometry', 'complex-numbers']"
839745,question from a test,"prove or find counterexample for the following theorem: $\forall x_1,x_2 \in (0,\frac{\pi }{2}):$$x_1<x_2 \Rightarrow  \frac{\sin x_2}{x_2}< \frac{\sin x_1}{x_1}$ Since I can't find any counterexample, it's probably a proof I need to give. So, I thought about declare a new function $f$ such that $f$:$[0,\pi/2]\to\mathbb R$, $f\left(x\right)\:=\:\frac{\sin x}{x}$ and show what the theorem want, but I'm stuck. Can someone help me here?","['trigonometry', 'calculus']"
839764,"If A, B, and C are set and $A \subset B ,B \subset C \rightarrow A \subset C$","I am wondering how to show the following proposition If A, B, and C are set and $A \subset  B ,B \subset C \rightarrow A \subset C$ My proof Let x be any integer. If $x\in A$ then $x\in B$ because all element of A are in B.  If $x \in B \rightarrow x\in C$ because all element of B are in C. Since B contains A and C contains B, then C contains A logically. the end",['elementary-set-theory']
839774,From a vector bundle to a Koszul complex,"Let $k = \mathbb C$. Given a commutative $k$-algebra $A$, an $A$-module $M$ and a homomorphism of $A$-modules $s:M \to A$, we can construct the Koszul dg algebra.
$$K(A,M,s) = \wedge^{-\!*}_A(M)$$
(Here the complex concentrate in nonpositive degrees.) According to Toen , given a vector bundle $V$ over $X (:=\mathrm{Spec}A)$ and a section $s:X \to V$, we can construct a Koszul complex $K(A,M,s)$, where $M=\Gamma(X,V)$. But the section does not seem to give any homomorphism $s:M \to A$ unless we choose a metric on $V$. Question: how can we naturally define a homomorphism $\Gamma(X,V) \to A$ from a sction of $V$?","['homological-algebra', 'commutative-algebra', 'algebraic-geometry']"
839836,Finding Fixed Points for Coupled ODE,"I have two coupled equations $$\frac{dx}{dt}=\gamma x\left(1 - \frac{\alpha x+\beta y}{N}\right)$$ $$\frac{dy}{dt}=\theta y\left(1 - \frac{\alpha x+\beta y}{N}\right)$$ where $\gamma , \alpha , \beta , \theta \space and \space N$ are constants Next, after I nondimensionalise them by setting $$t=\frac{\tau}{\gamma}, \quad \alpha x = X, \space \beta y = Y$$ I get $$\frac{dX}{d\tau}=X\left(1 - \frac{X+Y}{N}\right)$$ $$\frac{dY}{d\tau}=\kappa Y\left(1 - \frac{X+Y}{N}\right)$$ Now I attempt to find the fixed point by setting both ODEs = $0$ I get $X = 0 \text{ or } X = N - Y $ from the first ODE. And when I attempt to substitute $ X  = N - Y $ into the second ODE so that I solve them simuteneously, I get $\kappa Y(1-1) = 0 $. So I have difficulty finding the fixed point at $ X  = N - Y $ Is there another method someone could recommend? Or is there a problem in my nondimensionalization methods?",['ordinary-differential-equations']
839844,Showing $A \subset B \Leftrightarrow A-B=\emptyset$,"How can one justify this proposition. Propostion $A \subset B \Leftrightarrow A-B=\emptyset$ My proof $A-B$ means all element that appear in A but not in B. So $x\in A,x \notin B$. However if $A-B$ is the empty set then all element of $A$ are in $B$. And this is the definition of
$A\subset B$ Second part If $A \subset B$ then there will no element that is in $A$ but not in $B$.",['elementary-set-theory']
839884,Count swap permutations,"Given an array A = [1, 2, 3, ..., n]: How many sequences (S1) can you get after exact k adjacent swaps on A?
How many sequences (S2) can you get after at most k swaps on A? An adjacent swap can be made between two elements of the Array A, A[i] and A[i+1] or A[i] and A[i-1]. A swap otherwise can be between any two elements of the array A[i] and A[j] ∀ 1 ≤ i, j ≤ N, i ≠ j. So, I need to find S1 and S2. Example : We are given N=3 and k=2 then here S1=3 and S2=6 Explanation : Original array: [1, 2, 3] After 2 adjacent swaps:
We can get [1, 2, 3], [2, 3, 1], [3, 1, 2] ==> S1 == 3 After at most 2 swaps: 1) After 0 swap: [1, 2, 3] 2) After 1 swap: [2, 1, 3], [3, 2, 1], [1, 3, 2]. 3) After 2 swaps: [1, 2, 3], [2, 3, 1], [3, 1, 2]
==> S2 == 6","['permutations', 'algorithms', 'combinatorics']"
839891,Expected total number of balls in all bins after throwing balls uniformly randomly to bins that have limited capacity,"Consider throwing $n$ balls uniformly randomly to $L$ bins. Each bin has capacity $G$, meaning that if a ball is threw to a bin that already has $G$ balls in it, the ball is discarded. Is that possible to determine the expected total number of balls in all bins after throwing $n$ balls?","['balls-in-bins', 'probability', 'combinatorics']"
839934,The number of dominating sets of a bipartite graph is not exactly divisible by $2$,here is a cute problem I created from another cute problem. Prove the number of dominating sets of a bipartite graph is never exactly divisible by $2$. A dominating set of a graph is a set of vertices $D$ such that every vertex not in $D$ is adjacent to at least one vertex in $D$ Regards.,"['graph-theory', 'combinatorics']"
839940,Proof of Pearson's chi squared test,"i was reading proof of this theorem on http://ocw.mit.edu/courses/mathematics/18-443-statistics-for-applications-fall-2003/lecture-notes/lec23.pdf They showed, that $\frac{v_j-np_j}{\sqrt{np_j}} \stackrel{D}{\longrightarrow} N(0,1-p_j)$. I don't understand however why $\sum_{j=1}^r \frac{(v_j-np_j)^2}{np_j} \stackrel{D}{\longrightarrow} \sum_{i=1}^r Z_i^2$ holds? I know that if $X_n \stackrel{D}{\longrightarrow} X$, then for every continuous function $f$ we have $f(X_n) \stackrel{D}{\longrightarrow} f(X)$, so $\frac{(v_j-np_j)^2}{np_j} \stackrel{D}{\longrightarrow} Z_j^2$. But I know as well, that it's not true that $X_n \stackrel{D}{\longrightarrow} X$ and $Y_n \stackrel{D}{\longrightarrow} Y$ imply $X_n+Y_n \stackrel{D}{\longrightarrow} X+Y$.","['statistics', 'weak-convergence', 'probability', 'probability-theory']"
839944,"Integrate $\int_0^1 \ln(x)\ln(b-x)\,\mathrm{d}x$, for $b>1$?","Let $b>1$. What's the analytical expression for the following integral? $$\int_0^1 \ln(x)\ln(b-x)\,\mathrm{d}x$$ Mathematica returns the following answer: $$2-\frac{\pi^{2}}{3}b+\left(b-1\right)\ln\left(b-1\right)-b\ln b+\mathrm{i}b\pi\ln b+\frac{1}{2}b\ln^{2}b+b\mathrm{Li}_{2}\left(b\right)$$ which contains the imaginary term $\mathrm{i}b\pi\ln b$. But the actual answer is real, so this term should cancel somehow with the dilogarithm function. But I don't know how to do this.","['definite-integrals', 'calculus', 'integration']"
839951,Real-analytic periodic $f(z)$ that has more than 50 % of the derivatives positive?,"Im looking for a real-analytic function $f(z)$ such that for any $z$ $1) $$f(z+p) =f(z)$ With $p$ a nonzero real number and where $z$ is close to , or onto the real line such that  $z$ is in the domain of analyticity. $2)$ $f(z)= 0 + a_1 z + a_2 z^2 + a_3 z^3 + ...$ where more than $50$ % of the nonzero (signs of the) $a_n$ are positive. Thus let $f_n(z)$ be the truncated Taylor expansion of $f(z)$ of degree $n$.
Let $T(n)$ be the amount of nonzero (signs in the) coefficients of the polynomial $f_n(z)$. Let $v(n)$ be the amount of strict positive ($>0$) coefficients of $f_n(z)$. Then $\lim_{n ->  +\infty} v(n)/T(n) > 1/2$. $3)$ $f(z)$ is nonconstant. Also I prefer $f(z)$ to be entire if possible. Is such a function $f(z)$ possible ? Related : Real-analytic $f(z)=f(\sqrt z) + f(-\sqrt z)$?","['calculus', 'periodic-functions', 'real-analysis', 'taylor-expansion']"
839954,What does the rotation group of $\mathbb{\bar{Q}}^n$ look like?,"There's a structural difference between the rotation groups of $\mathbb{Q}^n$ and $\mathbb{R}^n$; in some abstract sense the former is 'small' (discrete?) while the latter is 'large'.  I suspect that part of the root of this is what might be called distance-closure: the distance between any two elements of $\mathbb{R}^n$ is an element of $\mathbb{R}$, whereas distances between two elements of $\mathbb{Q}^n$ aren't necessarily in $\mathbb{Q}$; in essence, rotations in $\mathbb{R}^n$ are transitive on $\mathbb{RP}^{n-1}$, whereas rotations in $\mathbb{Q}^n$ aren't transitive on $\mathbb{QP}^{n-1}$ (for instance, there's no rotation of $\mathbb{Q^2}$ mapping the line $\langle t,0\rangle$ onto the line $\langle t,t\rangle$). But there are intermediate fields between $\mathbb{Q}$ and $\mathbb{R}$ that are still distance-closed; in particular, the (real) algebraic closure of the rationals $\mathbb{\bar{Q}}\cap\mathbb{R}$ (I'm going to call this guy $\mathbb{\hat{Q}}$ in lieu of any better symbol) is.  Virtually all of classical geometry translates directly to $\mathbb{\hat{Q}}^n$, and we get the transitivity of rotations on $\mathbb{\hat{Q}P}^{n-1}$ mentioned above.  Is anything known about this group of rotations, and in particular — while it's obviously not as topologically nice as $O(n)$ since $\mathbb{\hat{Q}}$ isn't complete — is there a good structural sense in which it's 'larger' than the rotation group of $\mathbb{Q}^n$, beyond just the transitivity I mentioned above?","['geometry', 'rotations']"
839957,Prove g is Lebesgue intergrable,"Let $f$ be Lebesgue integrable on $(0, 1)$. For $0 < x < 1$ deﬁne
g(x) = $\int_x^1t^{-1}f(t)dt$ Prove that $g$ is Lebesgue integrable on $(0, 1)$. $\int^1_0g(x)dx=\int^1_0f(x)dx.$ I am not really getting idea from where should i start. I tried supposing f(x) as characteristics function then simple function and approximating f(x) by the simple function. I don't think this is the right idea.
Could anyone give me some hint how to start up.","['lebesgue-integral', 'measure-theory', 'real-analysis']"
839966,Real-analytic $f(z)=f\left(\sqrt z\right) + f\left(-\sqrt z\right)$?,"Are there nonconstant real-analytic functions $f(z)$ such that $$ f(z)=f\left(\sqrt z\right) + f\left(-\sqrt z\right)$$ is satisfied near the real line? Also can such functions be entire?
And/Or can they be periodic with a real period $p>0$ ? Does the set of equations $$ f(z)=f\left(\sqrt z\right) + f\left(-\sqrt z\right)$$ $$ f(z)=f(z+p)$$ $$ f ' (0) > 0$$ imply that $f(z)= 0 + a_1 z + a_2 z^2 + a_3 z^3 + \dots$ , where more than $50\%$ of the nonzero signs of the $a_n$ are positive? Related: Real-analytic periodic $f(z)$ that has more than 50 % of the derivatives positive?","['power-series', 'analyticity', 'real-analysis', 'functional-equations']"
839984,Prove that $\sigma_k$ is a multiplicative function,"For each real $k$,we define: $$\sigma_k(n)=\sum_{d \mid n} d^k$$ $$\text{Prove that } \sigma_k \text{ is a multiplicative function.}$$ That's what I have tried: $$\sigma_k(1)=\sum_{d \mid 1} d^k=1$$ Now,we have to show that if $(m,n)=1$,then we have $\sigma_k(m \cdot n)=\sigma_k(m) \sigma_k(n)$
At the case when one of $m,n$ is $1$,it is obvious.
Let $m,n>1$: $$\text{We know that if } (m,n)=1 , d_1 \text{ goes through all the positive divisors of  } m \text{ and } d_2 \text{ goes through all the positive divisors of } n, \text{ then } d_1 \cdot d_2 \text{ goes throught the positive divisors of } mn.$$ So, $$\sigma_k(mn)=\sum_{d_1 \mid m , d_2 \mid n} (d_1 d_2)^k=\sum_{d_1 \mid m} d_1^k \cdot \sum_{d_2 \mid n} d_2^k=\sigma_k(m) \sigma_k(n)$$ Therefore,the function is multiplicative. Could you tell me if it is right?",['number-theory']
839994,Count Number of Sequences,"The question is: Given a sequence of positive integers A={1,2,3,...,N} . Count the number of sequences you can get after making K swaps between adjacent element on it for a given N ? My approach: My algorithm to solve such a programming question is very naive. I could only think of making all the possible k swaps and then count the sequences. Can anyone help me out with a better algorithm?","['permutations', 'discrete-mathematics', 'algorithms', 'combinatorics']"
840008,Finding the centralizer of a permutation,"I need to find the centralizer of the permutation $\sigma=(1 2 3 ... n)\in S_n$. I know that: $C_{S_n}(\sigma)=\left\{\tau \in S_n|\text{ } \tau\sigma\tau^{-1}=\sigma\right\}$ In other words, that the centralizer is the set of all the elements that commute with $\sigma$, and I also know that if two permutations have disjoint cycles it implies that they commute, but the thing is; there are no $\tau\in S_n$ s.t. $\tau$ and $\sigma$ have disjoint cycles, since $\sigma=(1 2 3...n)$. So can I conclude that $\sigma$ does not commute with any other $\tau$ in $S_n$ (besides $id$ of course)? I guess my question reduces to: is the second direction of the implication mentioned above also true? meaning, if two permutation commute, does it imply that they have disjoint cycles? If the answer is no, how else can I find the $C_{S_n}(\sigma)$? By the way, on related subject, I noticed that if an element $g$ of a group $G$ is alone it its conjugacy class, it commutes with all elements in $G$. What does it mean, intuitively, for an element to share its conjugacy class with another element? does it mean it ""almost"" commute with everyone in the group? Is it true that the bigger the conjugacy class, the lesser its members commutes with others in the group?","['permutations', 'group-theory']"
840015,Local minimum implies local convexity?,"Consider a real function $f$, and suppose it has a local minimum at $a\in \mathbb R$. It typically looks like What hypotheses can be added to $f$ so that there is some $\epsilon >0$ such that $f$ is convex over $(a-\epsilon,a+\epsilon)$ ? The motivation for this question is intuition, but I can't find any valid criterion.","['optimization', 'derivatives', 'real-analysis']"
840019,Proving $ C \subset A$ and $D \subset B \rightarrow C\cap D\subset A \cap B$,How would I show the following? Proposition $C \subset A$ and $D \subset B \rightarrow C\cap D\subset A \cap B$ Attempt: Let x any object. $x\in C \rightarrow x \in A$ As A contain C $x \in D \rightarrow x\in B$ As B contains D. if $x \in  C\cap D$ Then x is in C and x is in D. And since A contain C. B contain D. $x\in C\cap D$ then $x \in A \cap B$,['elementary-set-theory']
840036,Why integration operator has no eigen values?,"Let $V$ be the vector space of all functions from $\mathbb R$ into $\mathbb R$ which are continuous. Let $T$ be the linear operator on $V$ defined by
  $$(Tf)(x) = \int_0^x f(t) dt$$
  Prove that $T$ has no eigen values. All those who are going to differentiate in the middle, please consider, there are functions which are continuous, but nowhere differentiable. Ex: Weirstrauss function. So, you can't differentiate anywhere in between.","['eigenvalues-eigenvectors', 'calculus', 'matrices', 'linear-algebra', 'eigenfunctions']"
840121,Graphs without nontrivial automorphism,"I'm trying to solve two problems about graph automorphisms. I want to construct a bipartite graph without a nontrivial automorphism. I want to find the smallest possible number of nodes for a graph without a nontrivial automorphism. For 1, I basically tried a brute-force approach: I started with two disjoint sets of nodes of unequal size and drew edges where nodes were easily exchangable. However, it didn't really work. At least for $(2,3)$-graphs I wasn't able to come up with the desired property and I have no idea how many nodes I should use. (More than the answer to problem 2 of course...)
What would be a clever approach, other than try and error? [edit]
Does this one have a nontrivial automorphism? For 2, I wasn't more creative than that. I tried a lot of examples to develop some intuition. I'm pretty confident that a graph without nontrivial automorphisms has to have at least $5$ nodes and I think I've found a counter-example for $6$ nodes: This one has no nontrivial automorphism, right? However, I'm unsure whether there is also a counter-example for $5$ nodes and if not, how could I prove that there is none?
Sadly, it's also not a bipartite graph.","['graph-theory', 'discrete-mathematics']"
840122,Finding limit of cube root [duplicate],"This question already has answers here : Finding derivative of $\sqrt[3]{x}$ using only limits (5 answers) Closed 10 years ago . I'm trying to evaluate this limit, but I don't think it's coming out correctly. Could someone please offer me some assistance? Evaluate limit analytically
  $$\lim_{h\to 0}\frac{\sqrt[3]{x + h} - \sqrt[3]{x}}{h}.$$ What I did was multiply $(x+h)^{2/3} + x^{2/3}$ top and bottom to get $$\lim_{h\to 0}\frac{(x+h)-x}{h((x+h)^{2/3} + x^{2/3})}.$$ I end up getting $\dfrac{1}{2x^{2/3}}$. The reason why I don't think I did this write is because isn't the limit above the definition of a derivative? And if so, then isn't the derivative of $\sqrt[3]{x}$ equal to $\dfrac{1}{3x^{2/3}}$? I would really appreciate any kind of help. Thanks.","['derivatives', 'limits']"
840130,2D Heat Equation with special initial condition,"I want to solve the 2 dimensional heat equation on a square $\Omega = \{ (x,y) : 0 < x < \pi, 0 < y < 2\pi \}$ with the Fourier Method
\begin{align*}
 \partial_t u - \Delta u & = 0 & \quad \mbox{ on } \Omega \times (0,T) \\
 u(x,y, t) & = 0 & \quad \mbox{for } (x,y) \in \partial \Omega, t \in [0,T], \\
 u(x,y, 0) & = x(\pi - x)(\pi - |y - \pi|) & \quad \mbox{for } (x,y) \in \Omega.
\end{align*}
With separation of variables I found
$$
 u(x,y,t) = \psi(x,y) \varphi(t)
$$
with
$$
 \psi(x,y) = \left( \sum_k A_k \sin(k x) \right) \cdot \left( \sum_l B_l \sin(l/2 y) \right)
$$
and
$$
 \varphi(t) = C e^{-2t}.
$$
But I have no idea how to incorporate the initial condition
$$
 u(x,y,0) = x(\pi - x)(\pi - |y - \pi|).
$$
So how to handle such an initial conditions?","['ordinary-differential-equations', 'partial-differential-equations', 'heat-equation', 'analysis', 'functional-analysis']"
840140,What is the Laplacian Matrix used for?,"You can turn graphs into several matrix forms depending on what data you want to focus on.  Does the Laplacian form have any uses on its own, or does it need to be paired with other things as some intermediary to be of use? just wondering.","['matrices', 'graph-theory', 'graph-laplacian']"
840159,Infinite sum of prime reciprocals,"Let $\mathbb D$ be the set of all real numbers that can be expressed as a sum of distinct prime reciprocals, i.e. $\mathbb D = \{ d \in \mathbb R \mid d = \sum_{k \in \mathbb K} \frac 1k $ for some (possibly infinite) subset $\mathbb K$ of the prime numbers $\mathbb K \subset \mathbb P \}$. I'm not a mathematician, and I have only a very vague idea of infinite sums, but intuitively, it seems to me that most real numbers are not in $\mathbb D$. Is that true? Is there any way to decide whether a given real number is in $\mathbb D$, e.g. is $\pi \in \mathbb D$?","['prime-numbers', 'sequences-and-series']"
840164,Why does $\int_{-\infty}^{\infty} f(x) dx \ne \lim\limits_{t \to \infty} \int_{-t}^{t} f(x) dx$?,I just get this is in my head. How come LHS is not equal to RHS.,"['definite-integrals', 'calculus', 'integration', 'limits']"
840177,"Prove that if product of matrices is singular, one of the matrices is singular.","I'm having trouble with this proof, it would be much easier to work out the other way it seems. Let $A$ and $B$ be square matrices of equal size. Prove that if $\det(AB) = 0 =C$ then either $A$ or $B$ must be singular. I claimed that because $AB$, denoted $C$, is zero then by rule of matrix product that one has to be zero. This is obviously not a real proof","['matrices', 'linear-algebra', 'proof-writing']"
840192,Analytic continuation of a real function,"I know that for $U \subset _{open} \mathbb{C}$, if a function $f$ is analytic on $U$ and if $f$ can be extended to the whole complex plane, this extension is unique. Now i am wondering if this is true for real functions. I mean, if $f: \mathbb{R} \to \mathbb{R}$, when is it true that there is an analytic $g$ whose restriction to $\mathbb{R}$ coincides with $f$ and also when is $g$ unique. Surely $f$ needs to be differentiable but this might not be sufficient for existance of such $g$. edit: I mean, is it easy to see that there is and extension of sine cosine and exponential real functions? Thanks a lot.","['analyticity', 'complex-analysis']"
840205,"Smooth Manifold, covered by 2 Charts is orientable if the Intersection is Connected","I came across this Question: Atlas on a smooth manifold that contains 2 charts in which Professor Lee commented that this Proposition is true only if the Intersection of the two Maps is connected, so I've been trying to prove the following: Let $M$ be a smooth Manifold, covered by an Atlas $\mathcal{A}$ containing two charts $\phi,\psi$ and $M= U_\phi \cup V_\psi$. Show that $M$ is orientable if $U_\phi \cap V_\psi$ is connected. So in other words I will have to prove that,for $\tau = \phi \circ \psi^{-1}$, the following holds:
$det(Jac(\tau))>0$. First of all I tried showing that $det(Jac(\tau)) > 0 \vee det(Jac(\tau)) < 0$ holds. I reasoned : Since $M$ is smooth it follows that $\tau$ is a Diffeomorphism, which implies $\tau$ is continuous. Suppose $\tau$  would take values both bigger and smaller than $0$, this would imply that there is a point at which $\tau$ becomes $0$ and therefore would no longer be a Diffeomorphism. The next step would be to show that $det(Jac(\tau))> 0$ however I do not see why this is indeed the case. Is my reasoning so far correct and if so how do I continue?","['differential-geometry', 'smooth-manifolds', 'real-analysis']"
840207,Equivalent Definitions of Negative Order Sobolev Spaces,"Ignoring fractional sobolev spaces, if we restrict ourselves to $k>0$ when $k$ is an integer, then the Sobolev space of order $k$, for $W^{k,p}(\mathbb{R})$ is the space of functions $f$ such that $\|f\|_{W^{k,p}(\Omega)} \asymp \|f\|_{p} + \|f^{(k)}\|_{p}$ is finite. A standard way of defining Sobolev spaces when $k<0$ is to say that if $1/p + 1/p^\prime = 1$, then $W^{-k,p^\prime}(\mathbb{R})$ is the dual space of $W^{k,p}(\Omega)$. In particular, when $p = 2$, we get a Hilbert space. For the rest of this question, we will assume $p=2$ My $\textbf{Question}$ is that there seems to be a lot of literature that considers defining a Hilbert Scale to be a sequence of embedded spaces, $H_{k+1} \subset H_k$, such that $H_k = \{f : \int (1+t^2)^k|\hat f(t)|^2dt <\infty \}$ where $\hat f$ is the Fourier transform of $f$. Naturally, when $k>0$ in this case, $H_k$ matches up with the Sobolev spaces $W^{k,p}(\mathbb{R})$, but I am not sure when $k<0$. When $k<0$, do the definitions of the spaces $H_k$ and $W^{-k,2}(\mathbb{R})$ coincide?","['definition', 'sobolev-spaces', 'hilbert-spaces', 'analysis']"
840248,Show the inequality $P[|S_n-mn| \ge n \epsilon] \le \frac{ σ ^2}{n \epsilon^2}$,"Show the inequality $P[|S_n-mn| \ge n \epsilon ] \le \frac{ σ ^2}{n \epsilon ^2}$ for every $ \epsilon>0$ where $S_n = X_1+...+X_n$ and $X_i$ are independant random variables under the same law. Also $m=E[X]$, $σ=Var[X]$ I think that i need to apply Chebyshev's inequality but i am not sure how...","['statistics', 'probability']"
840270,How to sum $\frac{1}{9} + \frac{1}{18}+\frac{1}{30}+\frac{1}{45} + ......$,How to sum this series : $\frac{1}{9} + \frac{1}{18}+\frac{1}{30}+\frac{1}{45} + \frac{1}{65}......$ I am not getting any clue only a hint will be suffice please help. thanks..,"['sequences-and-series', 'algebra-precalculus']"
840271,Nonlinear first order ODE with quadratic in the derivative,"This equation shouldn't be so hard, and yet I'm stymied. $$
\left( \frac{dw}{dz} \right )^2 + \alpha \frac{dw}{dz} + w \beta = 0
$$
with $w(0) = w_0>0$ $w(L) = 0$ for some known L and $\alpha(z)>0$ and $\beta(z)>0$ known. $\alpha$ and $\beta$ actually begin life as functions of known $w$, so I dont worry about existence of solution, what I want to prove is that I can invert back from $\alpha$ and $\beta$ to give unique $w$. $d \alpha / dz = \beta + C$ for some constant $C$ if it helps. I can solve for some special cases but I'm interested in a general expression, or at least to prove uniqueness. Interestingly, those special cases are not unique if I just put constraint at $z=0$ but become so with the $z=L$ constraint.","['quadratics', 'ordinary-differential-equations', 'nonlinear-system']"
840274,Square Integrable and Continuous,"I have come across the notation $L^2(\Omega) \cap C(\Omega)$; while I believe understand the resulting behavior, I can't get my head around the machinery.  When I think about $f \in C(\Omega)$ I am thinking out a single continuous function. However, for $f \in L^2(\Omega)$ I really mean a representative in an equivalence class. The upshot: $C(\Omega)$ seems like a collection of functions (maybe this is my flaw) $L^2(\Omega)$ is  a collection of equivalence classes because of this I am have a hard time understanding the meaning of $L^2(\Omega) \cap C(\Omega)$ and as a result what it means for $f \in L^2(\Omega) \cap C(\Omega)$. Can someone help shed some light on how to think of this? Thanks!","['lebesgue-integral', 'lebesgue-measure', 'analysis']"
840286,Can every positive real be written as the sum of a subsequence of dot dot dot,"I answered this thing Infinite sum of prime reciprocals and now wonder what happens if we do not have such a strong condition as Bertrand's postulate. i have been fiddling with this, not sure either way. Given a sequence $a_1 > a_2 > a_3 \cdots$ of strictly decreasing positive reals such that
$$ a_i \rightarrow 0 \; \; \; \mbox{but} \; \; \sum a_i = \infty,  $$
can every positive real number be expressed as the sum of a subsequence of the $a_i?$ The main thing is that we are not given any upper bound on $a_n / a_{n+1}.$ For the reciprocals of the primes, we had an upper bound of $2.$ Note that this is subtler than the thing about rearranging a strictly alternating conditionally convergent series to get anything you specify. That is a matter of overshooting with positive terms, then undershooting with negative terms, back and forth. This one is a little different. I think what I want is a careful proof of this: given two positive real numbers $B<C,$ we can find a finite subsequence of the $a_n$ with sum between $B$ and $C.$","['sequences-and-series', 'analysis']"
840320,$4^x+6^x=9^x$ $\implies$ $x \notin \mathbb Q$?,Does there exist any rational number $x$ such that  $4^x+6^x=9^x$ ?,"['algebra-precalculus', 'number-theory']"
840344,Lowest possible value of a function with derivative greater than 2,"I have the following two problems, and want to attempt to solve them with Mathematical rigour(which I don't yet possess): Suppose that $f$ is differentiable on $[1,4]$ and is such that $f(1) = 10$ and $f' \geq 2$ on $[0,4]$. Find the lowest possible value of $f(4)$ Logic: $f(1) = 10$ and $f' \geq 2$, so we have an increase of minimum $6$ hence, $f(4)\geq 16$ Rigour: $f(1) = 10$ and $f' \geq 2$, so  to have minimum increase, we have the take the lowest possible $f'$, hence $f' = 2$ and $f(x) = 2x + 8$, so $f(4) = 16$. Not sure if this is even close to rigourous. Give a function $f$ which is differentiable on $\mathbb{R}$ and which has the following three properties, or explain why such a function cannot exist: $f(0) = -1, f(2) = 4$ and $f'(x) \leq 2$ for all $x$ Logic: It isn't possible as we are increasing by $5y$ in $2x$ which has a greater derivative than 2, thus breaking property three. Rigour: $f(0) = -1$ has $y = kx+c$ at $(0,-1)$ we have $-1=c$ and with $(2,4)$ we obtain $4 = 2k - 1$, $k = 2.5$ and therefore $f(x) = 2.5x - 1$ and thus $f'(x) = 2.5$, since $2.5 \not\leq 2$, no such function exists. Could either of these answers be accepted as rigorous?","['functions', 'proof-writing', 'real-analysis']"
840367,Why should $f(z)=\sqrt{z}$ be limited on $\mathbb{C}-\{z:\Re(z)\leq0\}$ to be considered as an analytic function?,"A multivalued function $f(z)$ can be analytic on an open set $\Omega$ where $f(z)$ has an unique value and is differentiable on every point. If $f(z)=\sqrt{z}$, I think $\Omega$ can be defined as $\mathbb{C}$, instead of $\mathbb{C}-\{z:\Re(z)\leq0\}$, which is the condition usually required for this function. If $z=r e^{i\theta}$ with $-\pi<\theta\leq \pi$, then $\sqrt{z}=\sqrt{r}e^{i\theta/2}$. Thus, $\sqrt{z}$ is clearly a single-valued function on $\mathbb{C}$. Could you tell me why $\Omega = \mathbb{C}-\{z:\Re(z)\leq0\}$ instead of $\Omega=\mathbb{C}$? Is it because of continuity or differentiability of $f(z)$ on negative real line?","['branch-cuts', 'multivalued-functions', 'complex-analysis']"
840408,"Whether or not $X_1$,...,$X_n$ are independent and exchangeable","For some n = 1,2,..., let $Y_1$,...,$Y_{n+1}$ denote iid real-valued random variables. Define $X_j$ = $Y_j$$Y_{j+1}$, $\hspace{10mm}$j=1,...,n a) Are $X_1$,$X_2$,...,$X_n$ independent? b) Are $X_1$,$X_2$,...,$X_n$ exchangeable? Attempts: a) No. Counterexample: Let Y be a Bernoulli (0,1) distribution, with p = 1/2, where $Y_1$ = 0 and $Y_2$ = 1. Then $X_1$ = $Y_1$$Y_{2}$ Now $E(Y_1*Y_2)%$ = $E(0*1)$ = $E(0)$ = 1/2 However, $E(Y_1)%$$E(Y_2)%$ = 1/2*1/2 = 1/4 Since $E(Y_1*Y_2)%$ $\neq$ $E(Y_1)%$$E(Y_2)%$, the $X_i$'s are not independent. b) Not sure.","['statistics', 'statistical-inference']"
840436,Recovering a group action from sizes of orbits of individual elements,"Let $G$ be a group (say, finite) and let it act on a set $X$ (say, also finite). For every element $g \in G$, we can consider its action on $X$. My rather vague question is What information about the sizes of orbits of $X$ under $G$, can we recover only from knowing $G$ and the sizes of orbits of $X$ under $g$ for each $g\in G$? Perhaps a better phrasing is what information we can't recover if any. An example of two actions, that shows we can't recover everything will be a good start. One simple observation is that Burnside's lemma shows that $|X/G|$ is the average of the number of fixed points of $g \in G$. Hence, this piece of information can be recovered (even without knowing the group structure, which is available to us). The question is, what else. I am mainly interested in $X^G$, the number of fixed points of $X$ under the whole of $G$. One last remark. What I described amounts to saying that we know the action of every cyclic subgroup of $G$ and we want to recover (as much as possible from) the action of $G$. Perhaps we should look at a slightly bigger family of subgroups for this.","['finite-groups', 'group-theory', 'group-actions']"
840445,Stirling numbers of the second kind with constraints,"Stirling number of the second kind is the number of ways to partition a set of n objects into k non-empty subsets - S(n,k). I want to restrict/constrain this partition so I can count the ways to partition a set of n objects into k non-empty subsets while at least p subsets out of k will have size r. When p=k the answer is the associated Stirling of the second kind Sr(n,k) , but I was wondering whether there is a general expression for any p. In case there isn't I will be glad to find an expression for p=1 and r=1. Thank you. An example: the number of partitions of 4 objects into 2 subsets is S(4,2)=7. I want to count only the partitions that contain at least p=1 subset in the size of r=1. So in this case the answer is 4 because I don't want to count {1 2 | 3 4}, {1 3 | 3 2} and {1 4 | 2 4}.","['combinations', 'combinatorics']"
840484,differentiability check,"$$f(x)=\frac{1}{x-2}$$ number of points where $f$ is not differentiable? I know that the domain of the function is $\mathbb{R}\setminus\{2\}$
and differentiability is checked only in the domain of the function
so according to me the answer should be 0, But my teacher is saying that as the function is not continuous at $x=2$, it must be non-differentiable also. please help by solving this confusion.","['calculus', 'derivatives']"
840485,What is a natural homomorphism from $G$ to $G\times H$?,"Let $G$ and $H$ be two groups. What would a ""natural homomorphism"" from $G$ to $G\times H$ look like? My book mentions that one may assign natural homomorphisms from $G$ and $H$ to $G\times H$, but I don't understand the statement. Does it mean I map $g\to (g,e_H)$?",['abstract-algebra']
840490,Question about Logistic Regression - 4,"I am currently studying on logistic regression. So I have found a document on the Internet explaining about it. Somehow, it explains Bernoulli distribution in the beginning and I am having a problem to understand the equation below. I can refer to the variance explanation in wikipedia, it is still not clear for me to understand. I am new to this, and reading the paper line by line. If you think you can give me an explanation, I will be really grateful. I hope I have provided enough information for you to give me an explanation. Thank you.","['statistics', 'descriptive-statistics', 'statistical-inference']"
840522,Need explanation for simple differential equation,"I can't figure out this really simple linear equation: $$x'=x$$ I know that the result should be an exponential function with $t$ in the exponent, but I can't really say why. I tried integrating both sides but it doesn't seem to work. I know this is shameful noob question, but I would be grateful for any hints.","['ordinary-differential-equations', 'exponential-function']"
840542,Convex Hull of discrete points,"If i was to give an $n \times n$ grid with each grid point having probability $p$ of being selected, would it be difficult to calculate distributions of various measures regarding the convex hull of all selected points? I.e the distribution of the number of extreme points or total area covered (assuming this is defined appropriately). I've seen a lot of stuff on convex hulls in a continuous setting but not much in a discrete setting, if anyone could mention any interesting things they may know, that would be much appreciated.","['probability-theory', 'discrete-mathematics', 'probability', 'combinatorics']"
840544,"Mapping from $\{1,\ldots,n!\}$ to the symmetric group $S_n$","Is there an easy known bijective mapping formula between the set $\{1,\ldots,n!\}$ and the symmetric group $S_n$? I want to pick a number $k \in \{1,\ldots ,n!\}$ and assign a unique permutation of $(1,\ldots, n)$ to it. Numbering the transpositions generating $S_n$ doesn't help, since they can occur multiple times and don't commute. Maybe the permutation matrices (in every column and row exactly one 1 and 0 elsewhere) could give a hint, but I don't see the solution. Context: I want to simulate a certain probability distribution on the symmetric group. It's easy to pick random integer numbers. So easy mapping a random number to a permutation is left.","['finite-groups', 'group-theory']"
840590,Spherical-Coordinate Reference Frame,"my problem looks apparently easy but I can figure out a solution. I'm going through a paper about the Boltzmann equation and I got stuck with this change of coordinates. The original formula for Q (it's the collision integral but that is not relevant at the moment) is the following: $$
Q(f,f)(v) = \int\limits_{x\in{B_{R}}} \;\int\limits_{y\in{B_{R}}} \delta(x\cdot{y}) K(|x|,|y|)[f(v+x)f(v+y)-f(v+x+y)f(v)]dxdy\,.
$$ Just to let you know, f is a probability distribution and $K$ is the so-called kernel. $ \delta $ is the Dirac delta as one might guess. $ B_{R} $ is the ball of radius $R$ centered in the origin, $d$ is the dimension of $x$ and $y$. By a change of coordinates, namely $ x=\rho e $ and $ y=\rho' e' $, I ""should"" get $$
Q(f,f)(v) = \frac{1}{4} \int\limits_{e\in{\Bbb S^{d-1}}} \; \int\limits_{e'\in{\Bbb S^{d-1}}} \int_{-R}^{R} \int_{-R}^{R} \rho^{d-2} \rho'^{d-2} \delta(e\cdot{e'}) K(\rho,\rho')[f(v+\rho'e')f(v+\rho e)-f(v+\rho e+\rho'e')f(v)]d\rho d\rho'dede'\,.
$$ Here $ \Bbb S^{d-1} $ denotes the sphere of unitary radius centered in the origin of dimension $d-1$. The integral makes perfectly sense and I tried to compute it directly in one case and the two expressions yield the very same result. By applying the usual change of coordinates for an $n$-sphere (same formula as the one given by Wikipedia on the $n$-sphere article) and by substituting the angles by the surface element after having computed the determinant of the Jacobian, I get the same result except for the exponent of $ \rho $. I get $ \rho^{d-1} \rho'^{d-1} $ instead of $ \rho^{d-2} \rho'^{d-2} $. Then I tried to solve the problem by considering a single vector made up by the two column vectors $x$ and $y$ (the dimension of the problem is doubled) to see whether I could get the right exponent but I couldn't. Could you please suggest a strategy to get that formula (or a reference)? Thank you anyway.","['multivariable-calculus', 'differential-geometry', 'spherical-coordinates']"
840591,Probability Of a 4 sided die,"A fair $4$-sided die is rolled twice and we assume that all sixteen
possible outcomes are equally likely. Let $X$ and $Y$ be the result of the $1^{\large\text{st}}$ and the
$2^{\large\text{nd}}$ roll, respectively. We wish to determine the conditional probability $P(A|B)$
where
$A = \max(X,Y)=m$
and
$B= \min(X,Y)=2,\quad m\in\{1,2,3,4\}$. Can somebody first explain me this question and then explain its answer. I'm having trouble in approaching it.",['probability']
840637,Proving commutativity of addition for vector spaces,"I'm trying to prove commutativity of addition for vector spaces, using the axioms for vector spaces. Apparently commutativity can be proven! Im having trouble getting a good feel for what is allowed and what is not. Here's my work so far: $u+v+u+v = 2(u+v) = 2u + 2v = u+u+v+v = u+(u+v)+v$ Here I just wanna claim that $u+(v+u)+v = u+(u+v)+v$ $\Rightarrow -u+u+(v+u)+v+(-v) = -u+u+(u+v)+v+(-v)$ : here im just adding -u to the right, and -v to the left. Question: is this ""adding to both sides"" really legit in this context? Why? Quick help proof: $-v+v = (-1)v+(1)v = (-1+1)v = 0v = 0 = v-v$ And another: $ 0+v = v+(-v) + v = (1)v + (-1)v + v = (1-1)v + v = v = v+0$ We have $0 + (u+v) + 0 = 0+(v+u)+0 \Rightarrow u+v = v+u$ This feels ugly and not at all elegant, especially the great leap ""add -u to both sides"" feels completely out of place. Do I need more lemmas? Is there a more elegant way? //not homework or anything, just for my own pleasure, feel free to provide theory, as it is more insightful than solutions. :)
Thanks! EDIT: corrected notation a little.","['linear-algebra', 'proof-verification']"
840675,Relations from a set to set.,"Let $X = \{1, 2, 3, 4\}$ be a set. Let $Y = \{5, 6, 7, 8\}$ be another set. Define relation $R$ as $R = \{(2, 8), (4, 7), (1, 5)\}$. Then $2 R 8$, $4 R 7$, $1 R 5$. Here $R$ is both a relation between the components of ordered pairs and the set of ordered pairs related under a certain operation. Am I understanding it correctly? What's $R$, actually? Why is it used differently in differnt contexts?",['elementary-set-theory']
840702,Question about Tangent vectors and coordinate change on manifolds,"We can describe a vector on a manifold $M$ of dimension $n$ as follows: Let $p:I\rightarrow M$ with $I$ open interval in $\mathbb{R}$ be a curve in $M$. Now look to $p_0=p(0)$. Locally we can find a coordinate system $(U,x_U)$ around $p_0$ such that we can describe $p(t)$ by $(x_U^1(t),\ldots,x_U^n(t))$. Now we can desribe $p'(0)$ be the $n$-tuple $(\frac{dx_U^1(0)}{dt},\ldots,\frac{dx_U^n(0)}{dt})$ (i hope that i write down this correctly. My question is now the following: Suppose $p_0$ lies also in the coordinate system $(V,x_V)$, then we have a diffeomorphism on the overlap, namely $x_{UV}:x_U^{-1}\circ x_V:x_U(U\cap V)\rightarrow x_V(U\cap V)$. Moreover we have that we can describe $p'(0)$ by the $n$-tuple $(\frac{dx_V^1(0)}{dt},\ldots,\frac{dx_V^n(0)}{dt})$ (locally). My qeustion is know how to get the relation between $\frac{dx_V(0)}{dt}$ and $\frac{dx_U(t)}{dt}$ on $U\cap V$?. My idea was the following: Since we have the overlap map $x_{UV}$ we can say the following: $$(x_V^1(0),\ldots,x_V^n(0))=x_{UV}(x_U^1(0),\ldots,x_U^n(0))$$ Now it should be possible to differentiate with repsct to $t$ to get an expression for $\frac{dx_v^i(0)}{dt}$ for all $1\leq i\leq n$ depending op $x_U^i$. I think you have to use the chain rule, but i don't get on the right way. Can someone help me with this. I get the inspirations from ""The Geometry of Physics - An Introduction"". Thanks a lot.",['differential-geometry']
840709,Integrating over an area,"I need to integrate $f(x,y):=x^2y^2$ over an area $B\subset\mathbb R^2$that is restricted by the following 4 functions: $$y=\frac x9;\;y=\frac x4;\;y=\frac 1x;\;y=\frac4x;$$
Of course due to the symmetry we can integrate just over the area in the positive $x$-$y$ region and then multiply the result by two. I am confused by choosing the boundaries for integration. On the one hand it could be $$\frac x9 \leq y\leq \frac x4,\;2\leq x\leq6$$ 
or alternatively $$\frac 1x \leq y\leq \frac 4x,\;2\leq x\leq6$$ So how do I choose the boundaries to calculate $\int_Bx^2y^2d\mu(x,y)?$","['calculus', 'integration', 'real-analysis']"
840715,About the Schur's lemma,"In modules we have the following result: If $M$ is a simple $R$-module then $End_R M$ is a division ring. This theorem is known as Schur lemma and its proof is not difficult. Usually in ungraduate courses the only division ring mentioned is the quaternion ring. The Shur lemma is a ""machine"" to produce division ring but nothing assure me that the divison ring we get from a simple module is not a field. I have the following question about this topic: How do I calcule the $End_R M$. For example $End_\mathbb{Z} \mathbb{Z}$ Is there a simple $R$-module $M$ such that $End_R M \cong \mathbb{H}$ the quaternion ring? Where can I find more examples about division ring wich are not fields. There existe any finite division ring? Thanks a lot!","['modules', 'abstract-algebra']"
840717,Derivative of rational function help.,"consider $$f(x)=\frac{1}{2x-4}$$ The derivative should be $\displaystyle -\frac{1}{2(2x-4)^2}$
However I get $\displaystyle -\frac{2}{(2x-4)^2}$ my workflow: 
$$\begin{array}{}
f'(x)&= &(2x-4)^{-1}  \\
&=&-1(2)(2x-4)^{-2}  \\
&=&-2(2x-4)^{-2} 
\end{array}$$ So why does the -2 multiply the denominator and not the numerator? After all, $\displaystyle 2\frac{1}{2}$ is 1 not $\displaystyle \frac{1}{4}$. I feel like I'm missing the obvious. Thanks all.","['rational-functions', 'calculus', 'derivatives']"
840719,A misconception about arbitary constant,"Given a function $f(x)$ from $\mathbb R$ to $\mathbb R$, If $f'(x)=0$ $\text{ for all } x\in \mathbb R$. Then $f(x)=C$.(This is my understanding) Question: I think that $C$ has to remain constant for $\text{ for all } x\in\mathbb R$. But this is not valid for $f(x)= $$\arctan x+\arctan\frac{1}{x}$. clearly $f'(x)=0$ but $C$ doesn't remain constant. For all real positive numbers its$\frac{\pi}{2}$ while for -ve real numbers its $\frac{-\pi}{2}$. I just don't understand it. Can anyone help me?","['constants', 'calculus', 'limits']"
840720,QM-AM-GM-HM proof help,"Out of interest, I am trying to proof QM-AM-GM-HM inequality. If you don't know it, it's something like this... Let there be $n$ numbers $x_1, x_2, x_3...x_n$, where $x_1, x_2, ...,x_n>0$. Proof that $$\sqrt{\frac{x_1^2+x_2^2...+x_n^2}{n}}\geqslant{\frac{x_1+x_2...+x_n}{n}}\geqslant{\sqrt[n]{x_1x_2...x_n}}\geqslant{\frac{n}{\frac{1}{x_1}+\frac{1}{x_2}...+\frac{1}{x_n}}}$$
I thought of using induction (for n). The base case was something that took me about 20 mins to solve. I used n=2 (n=1 was trivial) but I am stuck. Can anyone give me a hint to continue me? To be exact, I need help in apply the induction hypothesis to the induction step. The numbers/fractions are starting to get ... uh ... ugly...
Update 1: I don't want to see the answer. Just a hint...","['inequality', 'means', 'algebra-precalculus']"
840742,general solution of the equation $\frac{dy}{dx} =\exp(y/x)$,"How can i get the general solution of the equation a) $\frac{dy}{dx} = \exp(y/x)$ b) $\frac{dy}{dx} = \exp(x-y)$ and $y=2$ when $x = 0$ I tried b) first: This is a first-order nonlinear ordinary differential equation, which is separable. 
General solution: 
$y(x) = \ln(C+e^x)$ Finding C , we have that: $$2 = \ln(C + e^0)$$ $$ 2 = \ln(C + 1) $$ 
$$e^2 = C+1 $$ 
$$C = e^2 - 1 $$ 
Particular solution: 
$$y(x) = \ln(e^2 -1 + e^x)$$ Is that correct the solution for b)? , I stuck with a), some help please.","['ordinary-differential-equations', 'calculus', 'derivatives']"
840746,Rank of derivative polynomial map equals dimension image?,"I've been told that given a polynomial map $f:X\to Y$ in characteristic zero, there exists an open dense subset $U$ of $X$ such that for all points $x$ in $U$, the rank of the derivative of $f$ in $x$ equals the dimension of the image of $f$.
Could someone please explain to me why this is true, or direct me to some reference where this is explained?",['algebraic-geometry']
840759,Convergence proofs: why is it necessary to prove specifically for $\epsilon$?,"In most proofs of sequence convergence in real analysis (like here and here ) in order to prove that, for example 
$$
a_n + b_n \to_n a+b
$$
or 
$$
a_n b_n \to_n ab
$$
when $a_n \to_n a $ and $b_n \to_n b$ often it is often taken that $|a_n -a| < \frac{\epsilon}{2}$, which follows from the fact that (for a different $n$ of course) $|a_n -a|<\epsilon$. Or, for the product proof that $|a_n-a|<\frac{\epsilon}{2(1+a)}$. Once again, for a different $n$. After some algebra it is shown that the desirable quantity, say $a_n b_n$ is within an $\epsilon$ from $a+b$. Well here's my confusion (and question): why not just prove that (in the first case)
$$
|a_n +b_n -(a+b)| <2 \epsilon
$$
and this would imply that of course for some other $n$ it is less than $\epsilon$. And the same with other proofs. In short: why, if we are allowed to play around with discrepancies from the limit of other sequences, we absolutely must show that the desired one is strictly less than $\epsilon$ away?","['sequences-and-series', 'real-analysis']"
840771,"uniform continuity on $(a, b]$ implies limit at $a^+$ exists and finite","Let a uniformly continuous function $f$ on $(a, b]$. Prove that $\lim_{x\rightarrow a^+} f(x)$ exists and finite. What I did so far: from the definition of uniform continuity: $$\forall\varepsilon >0.\exists\delta>0.\forall x,y\in(a,b]:\left| x-y \right|<\delta \Rightarrow \left| f(x)-f(y) \right| < \varepsilon$$ In particular, the statement is true for the sequence $\varepsilon_n = \frac{1}{n}$ and the interval $(a,a+\delta)$ $$\forall\varepsilon_n.\exists\delta>0.\forall x,y\in (a,a+\delta).\left| f(x) - f(y) \right| < \frac{1}{n}$$ I'm kinda stuck at this point, though I think I'm on the right path. How to proceed? Thanks.","['calculus', 'limits', 'continuity', 'real-analysis', 'uniform-continuity']"
840794,Orientation double cover,"Let $M$ be a manifold and let $\bigwedge^\text{top}TM$ be the top exterior product of the tangent bundle. Then this becomes a line bundle. Let $g$ be any metric on $\bigwedge^\text{top}TM$ and define $\hat{M}:=\{x\in\bigwedge^\text{top}TM:g(x,x)=1\}$, thus $\hat{M}$ is the space of all unit vectors. My question is: Why is $\pi:\hat{M}\rightarrow M$ a smooth double cover which is independent of the choice of the metric and why $\hat{M}$ has a natural orientation. I thought that the independence is implied by the fact that we have a line bundle.
Moreover: $M$ is orientable iff $\hat{M}=M\coprod M$. Can someone help me, with this because i have no idea, how to start. Thanks.",['differential-geometry']
840822,Prove the computational formula of Anderson-Darling test statistic.,"The Anderson-Darling test statistic is defined as $$n\int_{-\infty}^\infty \frac{(F_n(x) - F(x))^2}{F(x)(1 - F(x))}dF(x)$$ and there is a computational formula $$A^2 = -n - S$$ where $$S = \sum_{k=1}^n\frac{2k-1}{n}\left(\ln F(Y_k) + \ln(1 - F(Y_{n+1-k}))\right)$$ $F_n(x)$ is the empirical distribution function and $F(x)$ is the cumulative distribution to which we are comparing the sample. $Y_k$ is the $k^\text{th}$ ranked element in the sample. Many books or journals I found all give these two formulas but don't give the reason and derivations. I tried to divide the integral into sub-intervals like $[Y_i, Y_{i+1}]$ to prove it, but I failed. So I want to how to prove it. Thanks!!",['statistics']
840855,Inverse of constant matrix plus diagonal matrix,"Is there an efficient way to calculate the inverse of an $N \times N$ diagonal matrix plus a constant matrix? I am looking at $N$ of around $40,000$. $$\left[\begin{array}{cccc}
a & b & \cdots & b\\
b & a &  & \vdots\\
\vdots &  & \ddots & b\\
b & \cdots & b & a
\end{array}\right]^{-1} = \,\,?$$ Putting this in to mathematica, for $N \in \{2, 3, 4\}$, the result is: $$\left[
\begin{array}{cc}
 a & b \\
 b & a \\
\end{array}
\right]^{-1}
=
\left[
\begin{array}{cc}
 \frac{a}{a^2-b^2} & -\frac{b}{a^2-b^2} \\
 -\frac{b}{a^2-b^2} & \frac{a}{a^2-b^2} \\
\end{array}
\right]$$ $$\left[
\begin{array}{ccc}
 a & b & b \\
 b & a & b \\
 b & b & a \\
\end{array}
\right]^{-1}
=
\left[
\begin{array}{ccc}
 \frac{a^2-b^2}{a^3-3 a b^2+2 b^3} & \frac{-a b+b^2}{a^3-3 a b^2+2 b^3} & \frac{-a b+b^2}{a^3-3 a b^2+2 b^3} \\
 \frac{-a b+b^2}{a^3-3 a b^2+2 b^3} & \frac{a^2-b^2}{a^3-3 a b^2+2 b^3} & \frac{-a b+b^2}{a^3-3 a b^2+2 b^3} \\
 \frac{-a b+b^2}{a^3-3 a b^2+2 b^3} & \frac{-a b+b^2}{a^3-3 a b^2+2 b^3} & \frac{a^2-b^2}{a^3-3 a b^2+2 b^3} \\
\end{array}
\right]$$ $$\left[
\begin{array}{cccc}
 a & b & b & b \\
 b & a & b & b \\
 b & b & a & b \\
 b & b & b & a \\
\end{array}
\right]^{-1}
=
\left[
\begin{array}{cccc}
 \frac{a^3-3 a b^2+2 b^3}{a^4-6 a^2 b^2+8 a b^3-3 b^4} & \frac{-a^2 b+2 a b^2-b^3}{a^4-6 a^2 b^2+8 a b^3-3 b^4} & \frac{-a^2 b+2 a b^2-b^3}{a^4-6
a^2 b^2+8 a b^3-3 b^4} & \frac{-a^2 b+2 a b^2-b^3}{a^4-6 a^2 b^2+8 a b^3-3 b^4} \\
 \frac{-a^2 b+2 a b^2-b^3}{a^4-6 a^2 b^2+8 a b^3-3 b^4} & \frac{a^3-3 a b^2+2 b^3}{a^4-6 a^2 b^2+8 a b^3-3 b^4} & \frac{-a^2 b+2 a b^2-b^3}{a^4-6
a^2 b^2+8 a b^3-3 b^4} & \frac{-a^2 b+2 a b^2-b^3}{a^4-6 a^2 b^2+8 a b^3-3 b^4} \\
 \frac{-a^2 b+2 a b^2-b^3}{a^4-6 a^2 b^2+8 a b^3-3 b^4} & \frac{-a^2 b+2 a b^2-b^3}{a^4-6 a^2 b^2+8 a b^3-3 b^4} & \frac{a^3-3 a b^2+2 b^3}{a^4-6
a^2 b^2+8 a b^3-3 b^4} & \frac{-a^2 b+2 a b^2-b^3}{a^4-6 a^2 b^2+8 a b^3-3 b^4} \\
 \frac{-a^2 b+2 a b^2-b^3}{a^4-6 a^2 b^2+8 a b^3-3 b^4} & \frac{-a^2 b+2 a b^2-b^3}{a^4-6 a^2 b^2+8 a b^3-3 b^4} & \frac{-a^2 b+2 a b^2-b^3}{a^4-6
a^2 b^2+8 a b^3-3 b^4} & \frac{a^3-3 a b^2+2 b^3}{a^4-6 a^2 b^2+8 a b^3-3 b^4} \\
\end{array}
\right]$$ It appears that there should be a formula but I am not sure how to derive it. In the end, I am looking for a numerical result.","['numerical-linear-algebra', 'matrices', 'linear-algebra', 'inverse']"
840871,Rotation matrices are similar if and only if their angles add up to 2 pi,"Let $\theta_0, \theta_1 \in [0, 2\pi)$ and $\theta_0 \ne \theta_1$. Consider the rotation matrices $$M_0 = \left[ \begin{matrix}\cos(\theta_0) & -\sin(\theta_0) \\
\sin(\theta_0) & \cos(\theta_0) \\
\end{matrix} \right],M_1 = \left[ \begin{matrix}\cos(\theta_1) & -\sin(\theta_1) \\
\sin(\theta_1) & \cos(\theta_1) \\
\end{matrix} \right] \in SO(2). $$
Prove that $M_0$ and $M_1$ are similar if and only if $\theta_0+\theta_1=2\pi$. I think I've proved the $""<=""$ direction. Using that $\sin(2\pi-\theta_0) = -\sin(\theta_0)$ and $\cos(2\pi-\theta_0) = \cos(\theta_0)$; and with $P:= \left[ \begin{matrix} 1&0\\0&-1  \end{matrix}\right]=P^{-1} $ I have found that
$$P^{-1}M_0P = M_1,$$so that $M_0$ and $M_1$ are similar.
However, for the $""=>""$ direction, I feel like I am missing something. What conclusions can we draw from the fact that $M_0$ and $M_1$ are similar? A hint would be much appreciated.",['matrices']
840875,Infinite number of poles and residue theorem,"I suppose a stupid question but I was wondering about it for a while: Can one apply the residue theorem to a function $f$ which is defined and holomorphic on $U-\{a_1,a_2,\dots\}$ where $U$ is simply connected open subset of the complex plane and $a_k$ for $k\geq 1$ are all simple poles of $f(z)$. In particular I am thinking about the case when $f(z)= \Gamma(z)$, the gamma function. It is known that it has simple poles at $z=-k$, $k=0,1,2,\dots$ with resdue $(-1)^k/k!$. I hope the question is clear. Excuse me in case it is to trivial. I am not an expert in complex analysis. The Wikipedia-article demands a finite number of points $a_k$. Will one get a problem with a suitable choosen closed contour? To be more precise I would like to calculate the following integral: $$\int_{-\infty}^{\infty} dx f(x)$$ I was wondering if the typical ""trick"" of constructing a closed half-circle in the upper-half plane would work too when the poles continue ad infinitum. EDIT: My initial motivation is to invert a Mellin transform using the Mellin inversion theorem, when the Mellin transform has an infinite number of isolated poles. For example: I am able to show (by using a  specific symmetry of my problem) that the Melin transform of a function $P(x)$ for $0\leq x\leq x_c$ fulfills the following equation: $$M(s) = \frac{2x_c^s}{s-2+x_c^s}$$ where $0<x_c<1$. Now when I try to apply the Mellin inversion theorem I need to know where the poles lie. Unfortunately I think there is an infinite number poles of $M(s)$.",['complex-analysis']
840895,Blowing up a Singular Point More Than Once.,"I am trying to understand how $I_n$-fibres appear in an elliptic surface by performing a sequence of blow-ups. To be concrete, I am looking at the following elliptic surface given in Weierstrass normal form:
$$y^2=x^3+x^2+t^3x+t^4$$ This surface has an $I_4$ fibre when $t=0$, according to Tate's algorithm, and I am trying to see this concretely. I feel like I understand how to do the first blow up: I cover the blow-up with two charts, the first of which is given by 
$$t=t,y=y_1t, x=x_1t$$ Substituting these into the equation above, I find that
$$t^2\left[y_1^2-tx_1^3-x_1^2-tx_1-t^2\right]=0$$ Thus, the strict transform of my surface is given by the equation in brackets, which is still singular. The $t=0$ fibre is the pair of lines $y_1=\pm x_1$ in this chart. This is what happens in another chart, if I use coordinates
$$t=x''t'',y=y''x'', x=x''$$
The strict transform works out to
$$y''^2=x''+1+x''^2t^3+t''^4x''^2$$ Analyzing the $t=t''x''=0$ fibre in this chart, we have two pieces:
$$t''=0, y''^2=x''+1$$
$$x''=0,\ y''^2=1$$ If I check how these all glue, then the pair of lines that I found in the first chart becomes the pair of lines here, and a similar thing happens with the last chart. In summary, I am convinced that at this point, the $t=0$-fibre on my current surface is three rational curves, arranged in a triangle. At this point, I know what I need to do, but I don't think I'm doing it right. The surface I just obtained is still singular at the point $(x_1,y_1,t)=(0,0,0)$, so I need to blow it up. My intuition is that this will ""separate"" the two lines by introducing one more rational component meeting them each once. In total, this leaves 4 rational components arranged in a polygon, which is exactly what I should be getting. However, that is not what happens: I perform another blow-up by looking at the following chart:
$$t=t, x_1=x_2t, y_1=y_2t$$
I find that the strict transform is 
$$y_2^2=t^2x_2^3+x_2^2+x_2t+1$$ This is now smooth, and the $t=0$ fibre here is
$$y_2^2=x_2^2+1,$$ which is a single rational component, as I had hoped. Now, the part that's not working is seeing how this component intersects the other three components that I found earlier. The pair of lines was given, in $(x_1,y_1,t)$ coordinates by $t=0,y_1=\pm x_1$. If I consider these equations in $(x_2,y_2,t)$ coordinates, I get $t=0, y_2=\pm x_2$. But neither of these lines intersect the rational component I found, so there's no way I can build an $I_4$ fibre from this! If anyone can tell me what I'm doing wrong/ what I'm not seeing about this picture, I would be very appreciative.","['blowup', 'algebraic-geometry', 'surfaces']"
840914,"Probability of drawing all ""socks"" of a given color from a drawer, given certain number of tries","Let's talk ""socks."" Say I have 7800 socks in a drawer (it's a big drawer), 800 of which are red and 7000 of which are black. If I randomly pull 1300 socks from the drawer, what is the probability that I will draw EVERY ONE of the 800 red socks? I realize there are a number of similar threads, and apologize if this is repetitive -- I have searched and failed to find a situation sufficiently similar to allow me to work through this on my own. Many thanks for any assistance!","['probability', 'combinatorics']"
840924,Prove that $\sum_{n=2}^\infty (\ln n)^{- \ln n}$ converges,"As the title suggests, I'd like to prove that the sum
$$
\sum_{n=2}^\infty (\ln n)^{- \ln n}
$$
is finite.  The root and ratio test both fail here, but WA suggests that there is a comparison that can be used to show convergence. The only thought I have is that it may help to write the terms as $e^{-\ln(n)\ln(\ln(n))}$, but this has not led me to any particular insight.  Any ideas are appreciated.","['sequences-and-series', 'real-analysis']"
840939,Limit of a sequence $a_1=1;a_{n+1}=(n+1)(1+a_n)$,"Let a sequence be $a_1=1;a_{n+1}=(n+1)(1+a_n)$
If $P_n=\prod_1^n(1+a_i^{-1})$
then $$\lim_{n\to\infty}P_n $$is ? I did:
$$P_n=\prod_1^n\frac{(1+a_i)}{a_i}
=\frac{a_{n+1}}{a_1}\prod1^{n-1}\frac{(1+a_i)}{a_{i+1}}
=\frac{a_{n+1}}{a_1}\prod_1^{n-1}\frac1{i+1}=\frac{a_{n+1}}{n!}$$
Now how do I find the limit?",['limits']
840942,"Prove $\sqrt{x}>\ln(x)$ in $[1,\infty)$","Well, i try to prove this statement. i choose to make function: $f\left(x\right)\:=\:\sqrt{x}-\ln x$ but the derivative is: $\dfrac{\sqrt{x}\:-\:2}{2\sqrt{x}}$ and it's not always greater than $ 0$. any ideas?","['calculus', 'derivatives']"
840948,Let X be a discrete random variable with expected value E(X)...,"Let $X$ be a discrete random variable with expected value $E(X)$. Further, suppose
there is a $1/4$ probability of $X$ being exactly $2$ units away from $E(X)$, a $1/4$ probability of $X$
being exactly $3$ units away from $E(X)$, and a $1/2$ probability of $X$ being exactly $5$ units away
from $E(X)$. What is $Var(X)$?",['statistics']
840957,How can this be proved $\lim_{x\to\infty}(f(x)+f'(x))=l$ [duplicate],"This question already has answers here : If $\lim\limits_{x\rightarrow\infty} (f'(x)+f(x)) =L<\infty$, does $\lim\limits_{x\rightarrow\infty} f(x) $ exist? (2 answers) Closed 4 months ago . If $$\lim_{x\to\infty}(f(x)+f'(x))=l$$
then prove that $$\lim_{x\to\infty}f(x)=l \text{ and } \lim_{x\to\infty}f'(x)=0 $$ I assume four cases
$$\begin{array}{c|c|c|c|} 
 & f(x) & f'(x) \\ \hline
\text{1} & \infty & -\infty \\ \hline
\text{2} & -\infty & \infty \\ \hline
\text{3} & l & 0 \\ \hline
\text{4} & 0 & l \\ \hline
\end{array}$$
and elimination(1,2,4) of not possible cases can give the answer(3). My work is not a correct/perfect or flaw proof.What would be a correct one or is this correct.",['limits']
840961,"Lottery, cumulative distribution function, variance","Suppose a lottery is played like this: You must pay $\$5$ to play. Then, you select three numbers from $\{0, 1, 2, ..., 9\}$, with each of the three numbers being diﬀerent (order does not matter). Let’s suppose that you choose the numbers $4, 7$, and $9$. The lottery organizers choose the winning numbers in the same manner (three non-repeating numbers), with each combination of three numbers being equally likely. Payouts are as follows: If your numbers match exactly one of the winning numbers, you get your $5$ dollars back. If you match exactly two of the winning numbers, you get your $5$ dollars back, plus an extra $5$ dollars. If you match all three numbers, you get the $5$ dollars plus an extra $50$ dollars. Let the  random variable $X$ represent your net winnings from this game (proﬁt minus cost), in dollars. (a) Give the cumulative distribution function of $X$. (b) Calculate $\mathrm{Var}(X)$.",['statistics']
840965,permutation combination [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Maya has six indentical pots, which she is planning to arrange in a straight line in her showcase. before that each of these pots is to be colored either red or yellow or green or blue, such that at least one pot is coloured with each of the four colours. In how many different ways can she arrange the pots in the showcase so that now two pots of the same colour are adjacent?",['combinatorics']
840967,Prove no existing a smooth function satisfying ... related to Morse Theory,"i) Show that there does not exist a smooth function $f:\mathbb{R} \rightarrow \mathbb{R}$, s.t. $f(x) \geq 0$, $\forall x \in \mathbb{R}$, $f$ has exactly two critical points , $x_1,x_2\in\mathbb{R}$ and $f(x_1)=f(x_2) = 0$. (This part is easy). ii) Show that there does not exist a smooth function $f:\mathbb{R}^2 \rightarrow \mathbb{R}$, s.t. $f(x,y) \geq 0$, $\forall (x,y) \in \mathbb{R}^2$, $f$ has exactly two critical points , $(x_1,y_1),(x_2,y_2)\in\mathbb{R}^2$ and $f(x_1,y_1)=f(x_2,y_2) = 0$. I have tried several methods, however, it does not work, could anybody help me out?","['differential-topology', 'morse-theory', 'calculus', 'analysis']"
840973,Real analysis with a non-standard topology,"I have recently undertaken a self study of topology and am using Munkres Topology 2nd edition as the primary text. My background(theoretical chemistry & physics) is almost entirely void of any formal training in proof writing. I hope this struggle with Munkres will result in some marked improvements. I have some general questions regarding the concept of topology: How does changing a topology affect other areas of analysis? For example, how would the study of calculus or real analysis change if I used the Sorgenfrey topology versus the standard topology on $\mathbb{R}$? Is my definition of derivative the same? Is there a ""correct"" topology for studying physical phenomena? For example, how would modifying a topology affect numerical simulations of a dynamical system? One of the topics in Munkres is a study of continuous functions on various topological spaces. Some functions are continuous in topology $\tau$ but not in $\tau'$. Does this help us ""do"" things like integrate over weird sets? Is it possible to choose some non-standard topology for a symplectic space that would allow the integration of a Hamiltonian over some chaotic domain. I suppose I am craving some feeling for what dividends will be paid for my time invested in general topology? Thx","['dynamical-systems', 'general-topology', 'soft-question', 'analysis', 'differential-topology']"
840981,Question about Qing Liu's Algebraic Geometry book,"I was just wondering what the real prerequisites are for reading Qing Liu's 'Algebraic Geometry and Arithmetic Curves' , and if it is a good first book on the subject. In his preface he states that the prerequisites are few and any graduate student possesses the background necessary to read it, but this being algebraic geometry I am reticent to believe him. For example, does he assume knowledge of Differential geometry? Algebraic Topology? I expect that he assumes commutative algebra, but at what level?  Anyways, for people that have read him, please share your thoughts/comments on this.","['arithmetic-geometry', 'geometry', 'algebraic-geometry', 'reference-request']"
840995,Kronecker product and matrix multiplication property,"Given two symmetric matrices, $A \in \mathbb{R}^{n \times n}$ and $B \in \mathbb{R}^{m \times m}$ , is there any property of the Kronecker product which relates to matrix multiplication? More specifically, what is $(A \otimes B)C$ ?  And what should the dimensions of $C$ be?","['kronecker-product', 'matrices', 'linear-algebra']"
841003,"Can every indefinite integral of a discontinuous function be written in a way that ""proves"" something false?","I just saw the following fake proof. $$\int \frac1x dx =\int 1\cdot \frac1x dx=x\frac1x+\int x \frac1{x^2} dx = 1+ \int \frac1x dx$$ Which would imply $1=0$, hence the fake proof tag. The explanation given was that there was a discontinuity in the function that we were in essence ""integrating over"", however the integral is indefinite so we are not explicitly integrating over anything (or maybe integrating over everything?). Will any function with a discontinuity be exploitable in this way? Could we actually solve the problem by converting the integral to a definite integral in a region there is no discontinuity? I think the trick used would still work, or am not sure why it would provide a result that make sense.","['calculus', 'fake-proofs']"
841014,Is there a function $f : D^2 \setminus 0 \to R$ such that $f(x) x \to 0$ but $f(x)$ not bounded near $0$?,"I just showed that, for $f$ holomorphic on the punctured disc, $zf(z) \to 0$ implies that $f$ has a removable singularity at $0$. This in turn implies that $|f(z)|$ is bounded near 0. (The other implication is obvious.) My argument relied heavily on a function $g(z)$ being itself holomorphic ($g(z) = zf(z)$ for $z \not = 0$, $g(z) = 0$ at $0$), which followed from the holomorphicity of $f(z)z$ on $D^2 \setminus 0$. Therefore, I am curious to know if there exists a non-holomorphic but real differentiable function on the punctured disc, $f : D^2 \setminus 0 \to R$ with the property that $xf(x) \to 0$, but $f(x)$ is not bounded near 0.","['complex-analysis', 'real-analysis']"
841024,Showing $A \subset B \iff A\cap B=A$,Showing $A \subset B \iff A\cap B=A$ How would I show this? My proof Assume i. $A \cap B \subset A$ ii.$A \subset A \cap B$ Let $x$ be any element. Assume $x \in A \cap B$. Then $x \in A$ and $ x \in B$. By hypthesis $x \in A \rightarrow x \in B$ Thus $x \in A$ ii. Let $ x \in A$ By hypthesis $x \in A \rightarrow x \in B$ thus $x \in A \cap B$. Part 2 $ A\cap B=A \rightarrow A \subset B$ But I find myself stuck here.,['elementary-set-theory']
