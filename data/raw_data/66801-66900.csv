question_id,title,body,tags
794393,Combination problem approach when at least one of one type must be included,"Question:In how many ways can 6 be chosen from 4 officers and 8 privates to include at least 1 officer? The correct answer is to consider all the cases in which at least 1 officer is chosen and then add them together. 1 officer + 5 private 2 officer + 4 private 3 officer + 3 private 4 officer + 2 private But what is wrong with the following approach (it gives wrong answer) 1 officer out of 4 can be chosen in $^4C_1$ ways and remaining 5 people out of 11 can be chosen in $^{11}C_5$ ways, so the total number of ways of selecting 6 people in which at least 1 officer is present = $^4C_1 * ^{11}C_5$","['algebra-precalculus', 'combinatorics']"
794412,deduce that $\frac{S_4}{V_4}$ is isomorphic to $S_3$,"I have managed to do part i and ii. In part ii, the number of left cosets of H is 4. I am stuck with part iii. I am guessing I will have to use first isomorphism theorem but not sure how. $V_4$ is the potential kernel as it is normal subgroup  (part i)
But now i am not sure on what to do next.
Do I have to find homomorphism from $S_4$ to some group such that that group has a subgroup $S_3$? But then how do I show that this is actually isomorphic to S4/V4 ? Thanks. I am confused about first isomorphism theorem.","['group-theory', 'abstract-algebra']"
794414,Show that $Var(\theta_1)>Var(\theta_2)$.,"I calculated that
    $$
Var(\theta_1)=\frac{2\sigma^2}{(x_n-x_1)^2},~~~~~Var(\theta_2)=\frac{\sigma^2}{\sum_{i=1}^{n}(x_i-\overline{x})^2}.
$$
    Now I have to show that for $\sigma^2 >0$ and $\overline{x}\neq\frac{(x_1+x_n)}{2}$ it is
    $$
Var(\theta_1) > Var(\theta_2).
$$ I have to show that it is
$$
\frac{2\sigma^2}{(x_n-x_1)^2} > \frac{\sigma^2}{\sum_{i=1}^{n}(x_i-\overline{x})^2}.
$$ Do you have an idea how to show that? Unfortunately, I have not. Edit: I've already tried to show that
$$
Var(\theta_2)/Var(\theta_1)<1,
$$
i.e. that
$$
\frac{(x_n-x_1)^2}{\sum_{i=1}^{n}(x_i-\overline{x})^2}=\frac{x_1^2+x_n^2-2x_1x_n}{\sum_{i=1}^{n}x_i^2-n\overline{x}^2}<1
$$
but with no success.",['statistics']
794435,A property of exponential of operators,"Let $X$ be a Banach space. $A\in B(X)$ is a bounded operator. we can define $e^{tA}$ by $$e^{tA}=\sum_{k=0}^{+\infty}\frac{t^kA^k}{k!}$$
I am interested in this property: If $x\in X$, such that the function $t\mapsto e^{tA}x$ is bounded on $\mathbb{R}$, then we have necessarily
$$\inf_{t\in \mathbb{R}}|e^{tA}x|>0 \ \ \ \ \ or \ \ \ \ e^{tA}x=0 \ \ (i.e. \ \ x=0).$$ This property is clear in the scalar case $A=a\in \mathbb{C}$. Because $t\mapsto e^{ta}x$ is bounded on $\mathbb{R}$ if and only if $Re(a)=0$, and then $\inf_{t\in \mathbb{R}}|e^{ta}x|=|x|$. This property is also true if $X$ is finite dimensional i.e if $A$ is a matrix, and was answered here in math stack exchange. So my question is: "" Does this property hold if $X$ is infinite dimensional ? ""","['banach-spaces', 'operator-theory', 'functional-calculus', 'harmonic-analysis', 'functional-analysis']"
794443,Galois Group of $x^{14}+x^7-1$ over $\mathbb{Q}$,"So consider the polynomial $f(x)=x^{14}+x^7-1$ defined over $\mathbb{Q}$. We want to determine its Galois Group. So let's look for the splitting field, $L$ say, to give us an idea of the size of the Galois Group. Note that letting $y=x^7$ we see that $y$ satisfies $y^2+y-1=0$ gives us that $y=\frac{1\pm \sqrt5}{2}$ as roots. Clearly these must be in the splitting field of $f$ since for any root of $f$ each of its powers must be in the splitting field and these are the seventh powers of the roots of $f$. So $\mathbb{Q}(\sqrt5) \subset L$ and thus $2| [L:\mathbb{Q}]$. Now I don't  know where to go from here. We see that $\alpha^7=\frac{1\pm \sqrt5}{2}$ for any root $\alpha$, but how do I work out the size of the extension $[L:\mathbb{Q}(\sqrt5)]$?","['galois-theory', 'abstract-algebra']"
794448,Uniqueness of tensor product,"The uniqueness property of tensor product $M ⊗ N$ of two $A-$modules $M$ and $N$ specifies the following: for sake of simplicity we will write $M⊗N$ as $T$. A tensor product of $M$ and $N$ is pair $(T,g)$ where $T$ is an $A-$module and $g:M × N → T$ is a bilinear map such that any bilinear map $f:M × N → P$ factors through an $A-$module homomorphism $h$ such that $f = h \circ g$. uniqueness says that if you have another pair $( T',g' )$  then $∃  \  j: T \to T' $ an isomorphism s.t $g' = j \circ g$. While proving this, 
we use the factoring property of tensor product for both $(T,g)$ and $(T' , g')$ to get maps $j$ and $j'$ s.t   $g' = j \circ g$ and $g = j' \circ g'$. Now to show $j$ is an $A-$module isomorphism,  since $g' = j \circ g ⇒ g' = j \circ (j' \circ g') ⇒ g' = (j \circ j') \circ g'$ ,hence  $j \circ j' =Id_{T'}$ and similarly,  $j' \circ j = Id_{T}$, hence $j$ is an isomorphism. my problem is with this statement  $g' =  j \circ (j' \circ g') ⇒ g' = (j \circ j') \circ g'$ how can we change the order of brackets when $g'$ is a bilinear map , $j  ∈ End_A(T,T')$ , $j' ∈ End_A(T' , T)$ and we do not know if associativity is valid for whatever algebraic object(if any) these together live in.","['commutative-algebra', 'abstract-algebra']"
794469,Let $f(x) = |\cos(x)|$. Prove the corresponding Fourier series converge point-wise or uniform and show identity.,"Consider $f(x) = |\cos(x)|$ for $x \in \mathbb R$. I've proved the n'th fourier coefficient $c_n = \int^{\pi}_{-\pi} f(y)e^{-iny} \ dy  = \frac 1 {2\pi} \frac {(-1)^{n-1}} {n^2-\frac 1 4}$. However, how can I determine whether the Fourier series $\sum^{\infty}_{-\infty} \frac 1 {2\pi} \frac {(-1)^{n-1}} {n^2-\frac 1 4} e^{inx}$ converge point-wise or uniformly ? Here the partial sum is given by $\sum_{|n| <N} \frac 1 {2\pi} \frac {(-1)^{n-1}} {n^2-\frac 1 4} e^{inx}$. How can I use this to prove $\sum^{\infty}_{-\infty} \frac {(-1)^{n-1}} {n^2-\frac 1 4} = 2 \pi$ and $\sum^{\infty}_{-\infty} \frac {1} {(n^2-\frac 1 4)^2} = 2\pi^2$ ?","['fourier-series', 'fourier-analysis', 'sequences-and-series']"
794470,What remainder does $34!$ leave when divided by $71$?,"What is the remainder of $34!$ when divided by $71$ ?
Is there an objective way of solving this? I came across a solution which straight away starts by stating that $69!$ mod $71$ equals $1$ and I lost it right there.","['algebra-precalculus', 'divisibility', 'elementary-number-theory', 'chinese-remainder-theorem', 'factorial']"
794514,q-Generating function for plane partitions,"If I include a variable $q_k$ in $\prod _k^n \frac{1}{\left(1-q_k x^k\right){}^k}$ and look at the coefficient of $x^n$, then I find that the polynomial in the $q_k$ can be read, term by term, as a partition of n : $q_1^2 q_3$ encodes the partition (311). I would like to understand what the integer coefficients of the $q_i^a q_j^b$.. count. Example for n=4, counting 13 plane partitions;
$4 q_4+3 q_3 q_1+3 q_2^2+2 q_2 q_1^2+q_1^4$ produces coefficients (in reverse lex order) [4,3,3,2,1]. If I try to relate these to the plane partitions, generated by row sum: row sum 4: 5 pp : ((4)) , ((31)) , ((22)) , ((211)) , ((1111)) row sum 31 : 3 pp : ((3)(1))  ,  ((21)(1)) , ((111)(1)) row sum 22 : 2 pp : ((2)(2)) , ((11)(11)) row sum 211 : 2 pp : ((2)(1)(1)) , ((11)(1)(1)) row sum 1111 : 1 pp : ((1)(1)(1)(1)) By what property are the coefficients $q_i^a q_j^b$.. grouped?",['combinatorics']
794532,Why does $A^2=I$ imply $nullity(A)=0$?,"$A$ is a square matrix, why does $A^2=I$ imply $nullity(A)=0$? This is the key step in the solution, which I can't get it. Please help",['matrices']
794538,Is there a vector field that is the complete opposite of a conservative one,"Is there a three-dimensional vector field such that for every non-selfintersecting closed curve (that is not just one point, to avoid degenerate cases) the respective line-integral on the curve becomes non-zero? If not, what if I know that every point of the curve has all its coordinates positive?","['multivariable-calculus', 'vector-analysis']"
794547,function $L_p$ iff $1\leq p<2$,"Let $X=<0,1>$, take the borel sigma algebra, and the lebesgue measure. Consider $g(x)=\dfrac{1}{x^{\frac{1}{2}}}$. Show that $g\in L_p$ iff $1\leq p<2$. I have done this: $\int_{<0,1>}\mid g\mid ^p d\mu = \mid x\mid ^{-\dfrac{p}{2}}.\mu(<0,1>)=\mid x\mid ^{-\dfrac{p}{2}}$. But why this is not $\infty$ iff $p<2$? I'll appreciate any help, thanks.","['measure-theory', 'lebesgue-measure', 'lp-spaces']"
794563,Banach fixed point theorem and Picard-Lindelöf applied to this equation (explanation needed),"Consider the following equation which holds for all $w$ in some space,
$$\langle v(t), w \rangle = \langle v(0), w \rangle - \int_0^t \langle F(s,v(s)), w \rangle$$
where $\langle F(s,v),w \rangle$ is locally Lipschitz continuous in $v$. This integral equation has a solution by help of Banach's fixed point theorem in analogy to the existence theorem of Picard-Lindelöf. I don't see how this is similar to the equation $y'(t) = f(t, y(t))$ or its integral, because we have the duality pairing $\langle v(t), w \rangle$ here. How to overcome this? Source is Section 2.1 of http://link.springer.com/article/10.1007%2Fs10492-012-0004-0 . edit : Maybe I put the integral inside the duality pairing and then apply the ODE existence theory to the first component of the duality pairing?? EDIT : some text from the paper: https://i.sstatic.net/8Tyh5.jpg https://i.sstatic.net/APkUp.jpg http://imgur.com/drlwRgv","['fixed-point-theorems', 'ordinary-differential-equations', 'functional-analysis']"
794578,Question about finite rank operators,"Let $X$ be a normed space, $\mathcal{F}(X)$ the algebra of all operators on $X$ with finite fank, then $\mathcal{F}(X)$ is the unique minimal ideal of $\mathcal{K}(X)$ the algebra of all compact operators on $X$. I want to show that any non-zero ideal $\cal{I}$ of $\mathcal{K}(X)$ necessarily contains all operators with rank one. But I can not show a rank one operator $P$ can be written as $AT$, where $T\in\cal{I}$, $A\in\mathcal{K}(X)$. Thanks a lot.","['operator-theory', 'operator-algebras', 'functional-analysis']"
794582,"What is linear, numerically and geometrically speaking?","For as simple as it is, I never fully grasped what mathematicians and physicists mean with linear . Intuitively anything that looks like a straight line is interpreted as linear, like something in the form $f(x) = mx + q$ or any other function that maps $R \rightarrow R$ resulting in a graph that looks like a line. Last time I had the chance to talk to a physicist, the guy made a ""meh, not really"" expression about this, meaning that I had the feeling that this is ""true"" at some conditions but it's not a rigorous and universally accepted definition. So, since we are talking about this, could you define the concept of linear from the geometric and numeric point-of-view ? So maybe I can really grasp what ""linear"" means everytime this adjective appears in the names of math topics like linear algebra, linear programming, and so on.","['geometry', 'terminology', 'number-theory']"
794639,Predicting final standings in combinatorics,"There are 10 athletes participating in a competition. How many possible final
  standings, in respect to the first three places, would one have to
  predtict to be sure that at least one of them: a) without taking
  order into account b) taking order into account is correct? So the answers for these in my notes are $3!+3\cdot2\cdot8+3\cdot9\cdot8$ for a) and ${3\choose1}{7\choose2}+{3\choose2}{7\choose1}+{3\choose3}$ for b). Why is that so? I mean - if we have to make a correct prediction without thinking about the order, don't we have to simply calculate ${10\choose3}$? And as for the prediction with order, why isn't the answer the same as the previous but multiplied by all the permutations of 3-element set so ${10\choose3}\cdot3!$ ? EDIT: OK, it seems the interpretation of the problem seems different cause the answer for b) in the notes gives the predictions we'd have to make to correctly predict exactly one, exactly two or exactly three of the people on the podium. The answer for a seems more mysterious to me so if someone could help me get it, it'd be great :)","['discrete-mathematics', 'combinatorics']"
794667,L2 norm and the Kullback distance,"Let $P$ and $Q$ be two probability measures with densities $p$ and $q$ with respect to the Lebesgue measure on [0,1] such that: $0<a\leq p(x)\leq b$, $0<a\leq q(x)\leq b$ $\forall x\in $[0,1] $a$,$b>0$ are constants. Show that the Kullback distance $K(P,Q)$ is equivalent to the squared $L^2$ distance between densities $p$ and $q$. this is what i did: I want to show there are two constants $\alpha$ and $\beta$ such that $\alpha||p-q||^{2}\leq K(P,Q)\leq \beta ||p-q||^{2}$
Using the Taylor theorem i have 
$K(P,Q)\leq \int(p-q) +\frac{1}{2a}(\frac{b}{a})^{2}\int(q-p)^2$ and i don't know how prove that $\int(p-q)=0$  to get a first inequality. Some help would be appreciated","['probability-theory', 'measure-theory']"
794680,Decoding of Gabidulin code,"Consider the space of matrices in $\mathbb{F}_q^{n \times m}$ where $\mathbb{F}_q$ is the finite field with $q$ elements. We can define a metric on this space, given by $d(A,B) := rank(A-B)$, called the rank-metric. This allows us to consider error-correcting codes in this space. One example of codes in this metric are Gabidulin codes, which are analogues of Reed-Solomon codes. Essentially, we consider the rows of an $n \times m$ matrix as elements of the extension field $\mathbb{F}_{q^m}$. So now we consider the space of linearized polynomials over $\mathbb{F}_{q^m}$ of q-degree k-1 as the set of messages, and to get a codeword, we evaluate such a polynomial at $n$ evaluation points $g_1, g_2, \dots, g_n \in \mathbb{F}_{q^m}$ which are linearly independent as vectors over the base field $\mathbb{F}_q$, giving a vector in $\mathbb{F}_{q^m}^n$ which we can then interpret again as a matrix in $\mathbb{F}_q^{n \times m}$. This code, just like Reed-Solomon codes, has distance $n-k+1$. Now consider the decoding of such codes. We shall consider the analogue of the Berlekamp-Welch decoder for Reed-Solomon codes. 
We are given a word $(y_1,y_2,\dots,y_n)^T$ within a distance (according to the rank-metric) of $t$ from a codeword corresponding to the linearized polynomial $f$ say, and our aim is to algorithmically find $f$ when $t$ is less than half of the distance. 
This is worked out in the following paper: http://perso.univ-rennes1.fr/pierre.loidreau/articles/wcc_2005/Welch_Berlekamp.pdf If you are familiar with the Berlekamp-Welch decoder, this paper should be easy enough to read through quickly. 
In the paper, consider proof of proposition 2 in section 4.
There, it claims that ""Now let us consider a non-zero solution $(V_0,P_0)$ of 1), then any solution $(V,N)$ of 2) satisfies the following system of equations: $$V_0[N(g_i)-V(P_0(g_i))]=0 $$
$\forall i=1,\dots,n$"" How is this equation obtained? The paper states it as if its obvious, but I am unable to prove this.
Any help would be appreciated.
Thanks.","['coding-theory', 'algorithms', 'linear-algebra', 'abstract-algebra']"
794709,Prove that if $ u \cdot v = u \cdot w $ then $v = w$,"I've tried putting it up as: $$ [u_1 v_1 + \ldots + u_n v_n] = [u_1 w_1 + \ldots + u_n w_n] $$ But this doesn't make it immediately clear...I can't simply divide by $u_1 + \ldots + u_n$ as these ($u$, $v$ and $w$) are vectors... Any hints?",['linear-algebra']
794713,determine type of probability distribution,"let us consider following  model $$y(t)=A_1 \sin(\omega_1 t+\phi_1) + A_2 \sin(\omega_2 t+\phi_2) + A_3 \sin(\omega_3 t+\phi_3)+ \ldots +A_p \sin(\omega_p t+\phi_p)+z(t)$$ we have  three parameter fixed,but unknown and also $z(t)$ is simple white noise, before i  will ask my question let us consider following situation,because parameters are fixed, that means that  sinusoidal components represents  deterministic model right?even more  if we know these parameters,then at some time $t=t_0$, we can consider  each model as scalar so we have  sum of scalars + random variable, because white noise are iid, does it means that sum also will be iid? let us consider following case,we have $p$ deterministic component,let us construct following  equation $\alpha_{11}+\alpha_{12}+\cdots+\alpha_{1p}+z(1)$ $\alpha_{21}+\alpha_{22}+\cdots+\alpha_{2p}+z(2)$ $\vdots$ $\alpha_{n1}+\alpha_{n2}+\cdots+\alpha_{np}+z(n)$ we can consider it as $$y_1,y_2,\ldots,y_n$$ now how can i estimate what is a probability distribution form of  $y_i$? let us suppose that original sinusoidal components are just harmonically related to each other,does it help us to determine distribution form of outcomes? what if they are not harmonically and ratio of two frequency can be irrational? i know there exist for example Markov process Lévy process A renewal process and so on. how can i find relevant model for this process? thanks in advance","['probability-theory', 'stochastic-processes', 'probability-distributions', 'probability']"
794716,The number of different ways to choose $k$ out of $n$ unique items,The number of different ways to choose $k$ out of $n$ unique items: Without repetition and without order-significance: $\binom{n}{k}=\frac{n!}{k!(n-k)!}$ Without repetition and with order-significance: $\binom{n}{k}\times k!=\frac{n!}{(n-k)!}$ With repetition and with order-significance: $n^k$ With repetition and without order-significance: $?$ Thank you!,['combinatorics']
794728,$g(x)$ is continuous on $\mathbb{R}$ st $g(x)=g(x^2)$. Prove that $g(x)$ is constant.,"For $x>0$ , $g(\sqrt{x})=g(x)$ and similarly $g(x^{\frac{1}{2^n}})=g(\sqrt{x})=g(x)$ for $n \in \mathbb{N}$ Thus taking $\lim_{n\to \infty}$ both sides we get g(1)=g(x) $\forall x>0$ and as $g(x)=g(-x)$ thus $g(x)=g(1) \forall x\in \mathbb{R}$ thus $g(x)$ is constant. Is this proof correct?","['continuity', 'real-analysis']"
794744,"How many positive integers smaller than $1000$ and non-divisible by either $2$, $3$ or $5$ are there?","I thought about calculating the ones that are divisible and then subtracting, but don't know if that's the best way to go here. We can calculate that there are $499$ integers divisible by $2$ and smaller than $1000$. Also, $333$ divisible by $3$ and $199$ divisible by $5$. But then we'd have to calculate the ones divisible by $2$ AND $3$, $2$ AND $5$, $3$ AND $5$, all three and so on. Is there a faster way for this?","['discrete-mathematics', 'combinatorics']"
794755,"Transcendental, Algebraic","I just want to know: If a certain number is transcendental, call it $n$, is it safe to say that $n^2$ or that multiples of $n$ are are also transcendental? For example, from $e$ is transcendental, can we deduce that $e^2$ is transcendental?",['abstract-algebra']
794764,Complex Analysis -- Uniform Convergence on Compact Sets,"I've taken a course Complex Analysis, but I don't understand why the phrase ""For Uniform Convergence on Compact Sets"" was used all the time. I always got the impression this was ""good enough"" for something. But for what? Why is it enough? Why do we care? When is it enough? When is it not enough? Did this same idea pop up somewhere in real analysis/measure theory? I really appreciate your exposition on this matter!","['uniform-convergence', 'complex-analysis']"
794770,Name of function,"I am sorry if this is a stupid question, but I am struggling to give the proper name to the following function: $$\ f(r) = \exp(f_1+f_2r+f_3r^2+f_4r^3+f_5r^4+f_6r^5)$$ I ask as it will be in a presentation I am giving next week! Thanks",['functions']
794771,Properties of Sigma Algebras of Information up to a stopping time,"first of all i want to ask whether given any two $\{\mathcal{F}_t\}$-stopping times $\sigma, \tau$ is the following properties true: (i) $\mathcal{F}_{\sigma \wedge \tau} = \mathcal{F}_{\sigma} \cap \mathcal{F}_{\tau}$ (ii) $\mathcal{F}_{\sigma \vee \tau} = \mathcal{F}_{\sigma} \cup \mathcal{F}_{\tau}$ where $\mathcal{F}_{\tau} = \{A \in \mathcal{F}: A \cap\{\tau \leq t \} \in \mathcal{F}_t  \forall t \}$ and $a \wedge b = min\{a,b\}, a \vee b = max\{a,b\}$ if yes please provide the simplest easy to understand proof. if not please correct the statements and provide a proof. My failed try was: $\mathcal{F}_{\sigma \wedge \tau}$
$= \{A \in \mathcal{F}: A \cap\{\sigma \wedge \tau \leq t \} \in \mathcal{F}_t  \forall t \}$ $= \{A \in \mathcal{F}: A \cap (\{\sigma \leq t \} \cup \{\tau \leq t \}) \in \mathcal{F}_t  \forall t \}$ $= \{A \in \mathcal{F}: (A \cap \{\sigma \leq t \}) \cup (A \cap \{\tau \leq t \}) \in \mathcal{F}_t  \forall t \}$ $? \ \{A \in \mathcal{F}: A \cap\{\sigma \leq t \} \in \mathcal{F}_t  \forall t \}$
$\cup \{A \in \mathcal{F}: A \cap\{\tau \leq t \} \in \mathcal{F}_t  \forall t \}$ $=\mathcal{F}_{\sigma} \cup \mathcal{F}_{\tau}$ $\ ...$ $\mathcal{F}_{\sigma \vee \tau}$
$= \{A \in \mathcal{F}: A \cap\{\sigma \vee \tau \leq t \} \in \mathcal{F}_t  \forall t \}$ $= \{A \in \mathcal{F}: A \cap (\{\sigma \leq t \} \cap \{\tau \leq t \}) \in \mathcal{F}_t  \forall t \}$ $= \{A \in \mathcal{F}: (A \cap \{\sigma \leq t \}) \cap (A \cap \{\tau \leq t \}) \in \mathcal{F}_t  \forall t \}$ $? \ \{A \in \mathcal{F}: A \cap\{\sigma \leq t \} \in \mathcal{F}_t  \forall t \}$
$\cap \{A \in \mathcal{F}: A \cap\{\tau \leq t \} \in \mathcal{F}_t  \forall t \}$ $=\mathcal{F}_{\sigma} \cap \mathcal{F}_{\tau}$ Note: these are not any homework but something i am doing for self-study. Thank You saz. I understand your proof but can you also suggest for the union case: What i tried was as follows: I have already proved the following results, (i) $σ∨τ$ is also $\{\mathcal{F}_t\}$-stopping time (ii) $\mathcal{F}_{stopping\ time}$ is a σ-algebra using (i) and (ii),
$\mathcal{F}_\sigma \cup \mathcal{F}_\tau \subseteq \mathcal{F}_{σ∨τ} \implies$
$σ(\mathcal{F}_\sigma \cup \mathcal{F}_\tau) \subseteq \mathcal{F}_{σ∨τ}$ and now i take $E \in \mathcal{F}_σ$ so $E \cap \{σ\leq t\} \in \mathcal{F}_t \ \forall t$ since $E \cap \{σ∨τ \leq t\} = (E\cap \{σ \leq t\}) \cap \{τ \leq t\} $ i have $E \cap \{σ∨τ\leq t\} \in \mathcal{F}_t \ \forall t$ now together with similar case for $E \in \mathcal{F}_\tau$ yields
$\mathcal{F}_\sigma \cup \mathcal{F}_\tau \subseteq \mathcal{F}_{σ∨τ}$ But now how i should prove
$\sigma(\mathcal{F}_\sigma \cup \mathcal{F}_\tau) \supseteq \mathcal{F}_{σ∨τ}$ ? I am sorry the answer might be very trivial, but i can't see it.","['probability-theory', 'measure-theory', 'stopping-times']"
794779,"Definite integral - closed form: $\int_{0}^{\infty}\cos\left(x^{4} + 1 \over x^{2}\right)\,{\rm d}x$","I'm struggling with this definite integral: $$ 
\int_{0}^{\infty}\cos\left(x^{4} + 1 \over x^{2}\right)\,{\rm d}x.
$$ Any help will be greatly appreciated.","['improper-integrals', 'closed-form', 'calculus', 'integration', 'definite-integrals']"
794791,Differential inequality implies inequality for points at distance pi.,"Given a function $f$ with $f+f''\ge 0$, show that $f(x)+f(x+\pi) \ge 0$ for all $x$. Note that for sine and cosine both inequalities become equations. It seems reasonable to look at $f+f''=g$, but the resulting expressions seem inconclusive.","['inequality', 'ordinary-differential-equations', 'calculus', 'real-analysis']"
794797,"There exist infinitely many positive integers $k>r!$, such that for any $j$ with $r!<j<k$ we have $\prod_{i=0}^{r-1}(j-i)\nmid\prod_{i=0}^{r-1}(k-i)$","Question: Let $r$ be a postive integer. Show that there exist infinitely many positive integers $k$ satisfying $k>r!$,such that for any positive integer $j$ satisfying $r!<j<k$ we have
  $$j(j-1)(j-2)\cdots(j-r+1)  \nmid k(k-1)(k-2)\cdots(k-r+1).$$ Maybe this is a Mathematical olympiad problem, and I can't prove it. Thank you. I think this problem can be solved by considering $v_{p}(a)$, the exponent of the prime number $p$ in
the prime decomposition of the product $a$ above.",['number-theory']
794799,"Is there a way in matrix math notation to show the 'flip up-down', and 'flip left-right' of a matrix?",Title says it all - is there an accepted mathematical way in matrix notation to show those operations on a matrix? Thanks.,"['notation', 'matrices', 'linear-algebra', 'terminology']"
794829,Subgroups of Symmetric Group $S_4$ and Isomorphism,"During my Algebra class we were given this exercise to solve at home, but I couldn't find any solution and I also did not really get the one our teacher gave us. So, the text was: Given G = S 4 = Sym({1, 2, 3, 4}). Then: Is there a subgroup of G of order 5? Motivate your answer. Give and example of two subgroups H 1 and H 2 so that |H 1 | = |H 2 | and H 1 $\ncong$ H 2 (H 1 not isomorphic to H 2 ) Part 1 of the question is fairly simple in fact thanks to Lagrange Theorem on subgroups, but the problems arise with Part 2. The given solution is: Let's consider as an example: H 1 = { id, (1,2), (3,4), (1,2)(3,4) } H 2 = { id, (1,2)(3,4), (1,3)(2,4), (1,4)(2,3) } In fact, H 1 elements are all of order 2 (apart from id = identity ) while (1,2,3,4) $\in$ H 2 has order 4. Thus H 1 $\ncong$ H 2 ( H 1 not isomorphic with H 2 ) I've tried my best, but given the fact that our teacher sometimes is very messy I still can not figure out why this is a valid proof, nor the steps needed to find it. This is my first time posting, so sorry in advance for any mistake. Thank you for your time!","['symmetric-groups', 'group-theory', 'abstract-algebra']"
794831,Proving $|X^{\mathbb{R}}| \lt |\mathbb{R}^X|$ for $X=\mathbb{R}^{\mathbb{R}}$,Let $X=\mathbb{R}^{\mathbb{R}}$. Claim: $|X^{\mathbb{R}}| \lt |\mathbb{R}^X|$ How can this be shown? Note: We are assuming AC and $A^B$ represents the set of functions from B into A,"['cardinals', 'elementary-set-theory']"
794832,Cartesian product of dense sets is dense?,"If $Q_i$ is dense in $X_i$, where $X_i$ is a topological space and $i \in I$ being an arbitrary family of indices. Does this imply that $\prod Q_i$ is dense in $\prod X_i$?","['general-topology', 'calculus', 'real-analysis']"
794851,Evaluating $\int_0^{\infty}\frac1{x^9+1}~\mathrm{d}x$,"How can we evaluate this integral?
$$\int_0^{\infty}\frac1{x^9+1}~\mathrm{d}x$$","['definite-integrals', 'integration']"
794857,Evaluate $\int_0^\infty e^{-b\left(\frac{r^2}{a^2}+1\right)^\frac{-\gamma}{2}}\left (\frac{r^2}{a^2}+1\right)^\frac{-\gamma}{2} r^2 dr $,"I'm working on research in astrophysics related to determining the ages of stellar nurseries. I've got the numerical solution, but need an analytic solution to the integral below in order to better illustrate the behavior of the key parameters. The problem is, after 3 days of trying, I'm no closer to a solution! Can anyone help me solve this? $$
\int_0^\infty e^{-b\left(\frac{r^2}{a^2}+1\right)^\frac{-\gamma}{2}} \left(\frac{r^2}{a^2}+1\right)^\frac{-\gamma}{2} r^2 dr
$$ where $a,b,\gamma$ are real, positive constants and $\gamma > 4$. $\gamma$ is the key here. I would love to have a solution for general values of $\gamma$, but it would be enough for me to just have solutions for some two specific values of $\gamma$ for comparison. If anyone can help, I'd appreciate it very much. Or if anyone can say with certainty that the integral is not solvable, then at least I can move on.","['calculus', 'integration']"
794869,Integrate $\int_1^\infty \frac{dx}{x\sqrt{x^2-1}}$,"$$
I=\int_1^\infty \frac{dx}{x\sqrt{x^2-1}}=?
$$ Thank you.  I don't know how to do it because the bounds on the integral, I feel like that is confusing me a lot more than it means to be.  I tried doing $x=\tan \theta$ but didn't work. What I got was $$
I=\int_1^\infty \frac{\sec^2\theta d\theta}{\tan \theta \sec\theta}=\int_1^\infty \frac{\sec \theta}{\tan \theta}d\theta=\int_1^\infty \frac{1}{\sin \theta}d\theta 
$$ but now I am stuck.  This can't be the the right way, also this integral Diverges...So I am not sure. Also $x=\sin\theta,\cos \theta$ didn't work.","['definite-integrals', 'calculus', 'integration']"
794907,A proof in naive set theory.,"I am trying to use naive set theory to figure out a proof of the following statement: $$(x = u \land y = v) \to 〈x, y〉 = 〈u, v〉$$. What propositions should i use to prove this?","['logic', 'elementary-set-theory']"
794911,Probability of even number of successes in a series of independent trials,Consider a series of independent trials at each of which there is a success of a failure with probabilities $p$ and $1-p$ respectively. I am finding it difficult to derive the probability of even number of successes occurring at the nth trial. Any assistance will be much appreciated. Thanks,"['generating-functions', 'probability']"
794912,Find a vector orthogonal to other two given and ends at a plane,"I am reviewing Calculus III using Mahavier, W. Ted's material and get stuck on one question in chapter 1. Here is the problem: Assume $\vec{u},\vec{v}\in \mathbb{R}^3$. Find a vector $\vec{x}=(x,y,z)$ so that $\vec{x}\perp\vec{u}$ and $\vec{x}\perp\vec{v}$ and $x+y+z=1$. My attempt:
From the last condition, I know that $\vec{x}$ ends at the plane intersecting the $x-,y-,z-$axis at $(1,0,0),(0,1,0)$ and $(0,0,1)$. From the orthogonal conditions, $\vec{x}$ is perpendicular to the plane formed by $\vec{u},\vec{v}$ if they are distinct, otherwise, any plane that contains $\vec{u},\vec{v}$. Am I on the right track? And how do I go from here? Thanks! Edit : Thanks for all who responded! I do remember cross product. However, at this point of the book, the definition of cross product has not been introduced yet. I wonder whether there are other means to attack this problem without invoking a to-be-introduced concept? Thanks again!","['multivariable-calculus', 'self-learning', 'calculus']"
794940,"lim cos(1/θ) = 0, when θ → 0. Why?","Let $f(x)=x^2\sin\left(\frac{1}{x}\right)$ for $x\ne0$ and $f(0)=0$. => If we use Lagrange's theorem: $\exists \theta \in (0;x)$ and $f(x) - f(0) = f′(\theta)(x-0)$ => $$x^2\sin\left(\frac{1}{x}\right) - 0 = \left(2x\sin\left(\frac{1}{\theta}\right) - \cos\left(\frac{1}{\theta}\right)\right)(x - 0)$$ => Because $x>0$, we can divide both parts of equality on it => $$x\sin\left(\frac{1}{x}\right) = 2x\sin\left(\frac{1}{\theta}\right) - \cos\left(\frac{1}{\theta}\right)$$ Also notice: if $x \to 0$, than obviously $\theta \to 0$ => $$\lim_{x\to 0}\sin\left(\frac{1}{x}\right) = \lim_{x\to 0}2x\sin\left(\frac{1}{\theta}\right) - \cos\left(\frac{1}{\theta}\right)$$ => $$0 = 0 - \lim_{x\to 0}\cos\left(\frac{1}{\theta}\right)$$ => $$\lim_{\theta \to 0}\cos\left(\frac{1}{\theta}\right) = 0$$ Why?","['limits', 'analysis']"
794942,Express one root of depressed cubic equation via another and square root of discriminant,"Given a cubic polynomial $f(x)=x^3+px+q, p,q\in \mathbb{Q}$ and one of its roots $x_1$, how to express another root $x_2$ in terms of $x_1$, square root of the discriminant $d=\sqrt{-4p^3-27q^2}$, and $p,q$? I am looking for an expression without radicals. Of course, one can solve $x_1+x_2+x_3=0, x_1 x_2 x_3=-q$ for $x_2,x_3$ and get $x_{2,3}=(-x_1\pm \sqrt{x_1^2+4q/x_1})/2$, but there should exist a relation without square root, because the splitting field of $f(x)$ is $\mathbb{Q}(x_1,x_2)=\mathbb{Q}(x_1,d)$, and hence $x_2$ is a linear combination $x_2=ax_1+bd$ with some $a,b\in \mathbb{Q}(x_1,x_2)$.","['cubics', 'abstract-algebra']"
794944,Functional equations problem 3,Find the functions that satisfy the relation $$f(x)f\left(\frac{1}{x}\right)=f(x)+f\left(\frac{1}{x}\right).$$ Did not get any idea how to do this.,['functions']
794956,"Evaluating the following integral: $\int\frac1{x^3+1}\,\mathrm{d}x$","How to integrate
$$\int\frac1{x^3+1}~\mathrm{d}x$$ Is it possible to use Taylor expansion?","['calculus', 'integration', 'indefinite-integrals']"
794974,Show a particular $f:S^{2n}\to S^{2n}$ must be antipodal map.,"The following is a question from a qualifying exam I am studying for: Let $G$ be a group of homeomorphisms acting freely on $S^{2n}$. Show if $G$ has order $2$, then the nontrivial element must be the antipodal map. Here is what I have so far. If $f$ is the nontrivial element, we know that $f\simeq \alpha$, and $f$ has degreee $(-1)^{2n+1}=-1$, and that $f$ and $\alpha$ must agree on some point of $S^{2n}$. I am skeptical that degree theory will be enough to tackle this problem.","['general-topology', 'algebraic-topology']"
794981,How Many Permutations of Die Rolls Add Up to a Fixed Total?,"I'm toying around with the idea of designing a board game. I like the idea of a hexagon-tile setup (a la Catan). There would be some number of different resource categories; I'm trying to determine how many. Each tile would have a number from 1 to 6 associated with each resource category, representing the number you'd have to meet or beat when rolling a D6 to acquire that resource. And you'd get one die roll per resource type. In the interest of fairness, I'd like each tile to have the same total value -- probably the floor of the expected roll value times the number of different resources. So, for example, if I only had one resource type (let's call it Resource A), then I'd want each tile to have a total value of 3, which trivially means that I'd have one unique type of tile, which had a value of 3 for Resource A. One die rolls that value in exactly one way. If I had two resource types, Resource A and Resource B, then I'd want the total value of each tile to be 7. Brute-forcing it, I know that there are 6 different permutations of 2D6 rolls that add up to 7 (1 & 6, 2 & 5, 3 & 4, 4 & 3, 5 & 2, 6 & 1). So in that case, I'd have 6 unique types of tiles. But what if I wanted three resource types, with a total value of 10? Or four dice rolls, with a total of 14? So I'm wondering, what is the formula for generalizing this? Specifically, the number of permutations for which n dice will add up to a total m. And explain it like I'm simple -- it's been a long while since I've done this kind of math. I'm curious for my own enrichment, as well as the (theoretically) practical application of determining how many unique tiles I could potentially include.","['dice', 'permutations', 'combinatorics']"
795028,A Question from Algebraic Geometry,"For any two disjoint closed subsets $Y_1$ and $Y_2$ of $ \mathbb A ^n$ show that there exists $g \in\mathbb C [x_1, x_2, ..., x_n]$ such that $g(Y_1)=0$ and $g(Y_2)=1$.","['commutative-algebra', 'algebraic-geometry']"
795070,Questions about Weierstrass's elliptic functions,"From the wikipedia: In terms of the two periods, Weierstrass's elliptic function is an elliptic function with periods $\omega_1$ and $\omega_2$ defined as $$\wp(z;\omega_1,\omega_2)=\frac{1}{z^2}+ \sum_{n^2+m^2 \ne 0} \left\{ \frac{1}{(z+m\omega_1+n\omega_2)^2}- \frac{1}{\left(m\omega_1+n\omega_2\right)^2} \right\}. $$ Then $\Lambda=\{m\omega_1+n\omega_2:m,n\in\mathbb{Z}\}$ are the points of the period lattice, so that $$ \wp(z;\Lambda)=\wp(z;\omega_1,\omega_2) $$ so I really like these elliptic functions. Much easier to understand than the jacobi ones, which I don't really get. Seems like such a nifty idea too. I don't get why these weren't the first ones that people thought of. Well, maybe they were but no one cared for them, because they didn't have applications like the jacobi ones. And it was only when people saw they had theoretical significance, that then they talked about them more. Or when they had to start teaching it, since these are easier to understand. Well my first question is, why the exponent has to be $2$ and not $4$ or $6$ or any of the other even powers. Won't those powers generate convergent nonzero elliptic functions too? Then why do we only give attention to the ones, where the exponent is $2$ ? The wikipedia says any elliptic function can be written in terms of the corresponding Weierstrass one, that has the same periods. So maybe that's why. But I just find that shocking. So you're saying that we don't even need to give the terms in the Weierstrass series their own coefficient, that just polynomials (or other functions?) of the appropriate Weierstrass elliptical function will span the space of all elliptical functions with those periods? (even the ones that look like Weisterass series except that they have higher even-powered exponents?). I think someone has some explaining to do. Secondly, why does no one mention the one dimensional analogues of Weierstrass elliptical functions. Those would be functions of one real variable, that are periodic. Why did we never study those kinds of periodic functions. Are they just not relevant to the theory of periodic functions of one real variable? Where unlike in the complex case, you can't generate all other periodic functions from those ones? I could see how you could get $\tan(x)$ out of those, maybe, since it is lucky enough to have poles at each period, but not the ones that don't have any poles (like $\sin$ and $\cos$ ).","['elliptic-functions', 'complex-analysis', 'periodic-functions']"
795102,Elementary approach to proving that a group of order 9 is Abelian,"The trick here is to provide an elementary solution; I'll explain what I mean. Prove that a group of order 9 must be Abelian.  The standard approach is to use the class equation to show that any $p$-group has a non-trivial center.  From that, it's easy to show that any group of order $p^2$ is Abelian.  If not, pick an element $a$ not in the center and look at its centralizer.  This includes the center and $a$, so it has at least $p+1$ elements; hence it's the whole group by Lagrange; hence $a$ is in the center, a contradiction. Okay, but the problem is given as an exercise very early in Herstein, before any of this is discussed.  Other than Lagrange and some easy consequences, all we really have to work with is the fundamental homomorphism theorem; in fact, the exercise is included in the set at the end of the section introducing the theorem.  So what I'm looking for is an approach that uses only very basic group properties and, especially, one that applies the homomorphism theorem.",['abstract-algebra']
795109,Bessel Differential Equation,I am doing an exercise which asks for the concentration distribution of a given bacteria. After several computations I reached the following differential equation: $$x^2y''-xy'+(1+x^2)y=0$$ which seem to be solved with Bessel but I have no idea how to do it. Could you help me please??,"['ordinary-differential-equations', 'bessel-functions']"
795112,limit notation syntax validity,"If you know $$\lim_{x \to \infty} f(x) = -\infty$$ and $$\lim_{x \to -\infty} f(x) = -\infty$$, is it valid syntax to write $$\lim_{x \to \pm \infty} f(x) = -\infty$$?","['notation', 'limits']"
795121,How to determine the general polar equation of a circle,How can you determine that the polar equation $r = a\cos(\theta)$ is a circle?,['geometry']
795135,"If $\sum\frac1{a_n}$ is convergent, then irrational?","$\{a_n\}$ is a  strictly increasing sequence of positive integers such that $$\lim_{n\to\infty}\frac{a_{n+1}}{ a_n}=1$$ If $\sum\limits_{n=1}^\infty\frac1{a_n}$ is convergent, can one conclude that $\sum\limits_{n=1}^\infty\frac1{a_n}$ is an irrational number? a transcendental  number? A special case is $\zeta(n)(n\geq2)$ . so, the question, if true, may be difficult. Does someone suggest a counter-example? Thanks a lot!","['irrational-numbers', 'real-analysis', 'number-theory']"
795138,Find the distribution of $X_1^2 + X_2^2$? [duplicate],"This question already has answers here : Let $X_1$ and $X_2$ are independent $N(0, \sigma^2)$ random variables. What is the distribution of $X_1^2 + X_2^2$? (3 answers) Closed 10 years ago . Let $X_1$ and $X_2$ are independent $N(0, \sigma^2)$ which means (mean = 0, variance = $\sigma^2$) random variables. What is the distribution of $X_1^2 + X_2^2$? My approach is that 
$X_1\sim N(0, \sigma^2)$ and $X_2\sim N(0, \sigma^2)$. Transforming $X_1$ and $X_2$ into standard normal,
$X_1/\sigma\sim N(0, 1)$ and $X_2/\sigma\sim N(0, 1)$. Then $X_1^2/\sigma$ and $X_2^2/\sigma$ have chi-squared distribution with 1 degree of freedom. Then I found the moment-generating function for $X_1^2$ and $X_2^2$;$$m_{X_1^2} = (1-2t)^{-1/2}$$ and $$m_{X_2^2} = (1-2t)^{-1/2}$$ So the moment generating function for $X_1^2 + X_2^2$ is $$m_{X_1^2}(t) m_{X_2^2}(t) = (1-2t)^{-2/2}$$ So $X_1^2 + X_2^2$ has a chi-squared distribution with 2 degrees of freedom. My question can I treat $X_1^2/\sigma$ + $X_2^2/\sigma$ as $X_1^2$ + $X_2^2$ like I did above?","['statistics', 'probability-distributions', 'probability', 'probability-theory']"
795148,Is group theory useful in any way to optimization?,"For what I have seen, optimization uses a lot of linear algebra and convex analysis, but I have not seen any group theory being used, so I was curious about it. Is group theory useful in any way to optimization?","['optimization', 'constraint-programming', 'convex-optimization', 'group-theory']"
795194,Contiguous edges of a cube (and other regular solids),"I had the desire to create a cube out of a single piece of string, where each edge is represented only once. Through experimentation it appears that this is impossible, and the closest you can get is to create a cube missing 3 of the 12 edges. A tetrahedron leaves 1 left over. An octahedron leaves none. Why is the limit 3 for a cube, and 1 and 0 for those? Is there a general rule that predicts this? What about an icosahedron, or a tesseract?",['geometry']
795235,What are some simple examples I can use to demonstrate the power of geometric algebra?,"What are some simple examples I can use to demonstrate the power of geometric algebra over ""everyday"" vector algebra? An alternative way of thinking of this question might be: what example demonstrates how geometric algebra simplifies a tedious problem in vector algebra?","['geometry', 'geometric-algebras', 'clifford-algebras']"
795241,Uniqueness of the ODE solutions,"Say we have a continuous function (perhaps not everywhere differentiable) that satisfies an ODE $y^\prime(x)=h(y(x),x)$ for almost all $x$ in $[0,1]$. Are the any references for that deal with basic ODE questions (existence, uniqueness) for these class of solutions? If so which ones you would recommend?","['ordinary-differential-equations', 'reference-request', 'analysis']"
795244,Help with proving that the transpose of the product of any number of matrices is equal to the product of their transposes in reverse,"Specifically I am trying to show that (A n ) T = (A T ) n where A is an mxm square matrix and n is a positive integer. This is where I'm stuck: To prove the theorem I would like to show that ((A n ) T ) ij = ((A T ) n ) ij for all ij . All I can think of is expanding the definition of matrix multiplication. Left side of equation: ((A n ) T ) ij = (A n ) ji = (a n-1 ) 1i a j1 + (a n-1 ) 2i a j2 +...+ (a n-1 ) mi a jm Right side of the equation: Let a' denote the ij th entry of A T ((A T ) n ) ij = (a' n-1 ) i1 a' 1j + (a' n-1 ) i2 a' 2j +...+ (a' n-1 ) im a' mj = (a n-1 ) 1i a j1 + (a n-1 ) 2i a j2 +...+ (a n-1 ) mi a jm Now the left and the right side of the equation are shown to be equal. In this proof, I mean for A n to represent the product AAA... up to n. So if n= 3, this would represent the matrix resulting from the product of (AAA). The problem I have with this is that with my proof,  determining the value in a specific position, say (AAA) ij , you must first determine the values of AA, and so on depending on the value of n. It just seems like there must be a better way of doing this proof. Can anyone help me out or show me why what I am doing is correct, or more likely, incorrect? I am teaching myself linear algebra from Howard Anton's Elementary Linear Algebra text and unfortunately there seems to be a lot of assumed prior knowledge. I could really use detailed to the point of redundant explanations at this point in my learning! Also, since I have no one to interact with in constructing my proofs, I fear that I am missing some common practices. So feel free to be very critical of my format, so that I can get on track.","['matrices', 'linear-algebra', 'transpose']"
795247,Stokes' Theorem Explanation,"Can someone explain what Stokes' Theorem is measuring? What would taking the integral of a vector on a surface give you? When would you use it? This is the only definition I have and I don't really understand what it's saying. Let $S$ be an oriented smooth surface that is bounded by a simple, closed, smooth boundary curve $C$ with positive orientation. Also let $\vec{F}$ be a vector field then, $$\int\limits_C \vec{F} \cdot d\vec{r} =
\iint\limits_S \mathrm{curl}\ \vec{F} \cdot d\vec{S}$$","['multivariable-calculus', 'calculus', 'intuition', 'definition']"
795264,"Prove $\lim\limits_{n \rightarrow \infty} \frac{1}{n} \int_0^n xg(x)\,dx=0$","If $g$ is a Lebesgue integrable function in $E=\lbrack 0,\infty)$ , prove that $$\lim_{n \rightarrow \infty}\frac{1}{n}\int_0^n xg(x)\,dx=0.$$ I want to use the absolute continuity of the Lebesgue integral, i.e, if $\epsilon >0$ there is $\delta > 0$ such as if $|E|<\delta$ (Lebesgue measure) then $\int_E g(x)\,dx<\epsilon.$ I would like to split the integral in the subsets $\lbrack 0 , n-\delta\rbrack$ and $\lbrack n-\delta, n)$ (the last one has measure $\delta$ ) but I think this is wrong.
Thank you very much for your help!","['lebesgue-integral', 'measure-theory', 'limits']"
795282,"Diophantine equations and Hilbert's 10th Problem, how did MRDP do it?","I'm having a bit of trouble understanding the Wiki explanation of MRDP's (Matiyasevich, Robinson, Davis, Putnam)'s Theorem, which explains that Hilbert's 10th problem is unsolvable. The MRDP theorem states that a set of integers is Diophantine if and only if it is computably enumerable . A set of integers $S$ is recursively enumerable if and only if there is an algorithm that, when given an integer, halts if that integer is a member of $S$ and runs forever otherwise. Source: http://en.wikipedia.org/wiki/Diophantine_set What exactly is the set $S$ in the case of Hilbert's 10th Problem? Is it the set of solutions $n$ for any ${x_1}^n+{x_2}^n+...+{x_{k-1}}^n={x_k}^n$ Diophantine equation? Also are we assuming that the $x_1,...,x_k$, are unchanging? That is, we choose this list of constants $(x_1,x_2,...,x_k)$, and we look for all the $n$ that make the equation true? MOST confusing to me: why does it matter if this set is c.e.? Sorry for so many questions, I've been sifting through Wiki pages and haven't been able to find a clear explanation for this.","['logic', 'computability', 'number-theory']"
795306,Find limit of this recursive sequence,"$$
a_0=0,\ a_1=2,\ a_{n+1}=\sqrt{2 - \frac{a_{n-1}}{a_n}} \\
\lim_{n\to\infty}2^na_n\ =\ ?
$$",['sequences-and-series']
795312,Finding the marginal density of $ce^{-x^2-y^2-xy-x}$,"In my probability class, we've started studying joint distrubutions and I've been tasked with the following problem: Let $(X,Y)$ have joint density $ce^{-x^2-y^2-xy-x}$, where $c>0$ is some constant. Find the marginal density of $X$. What this amounts to is evaluating $\int_{-\infty}^{\infty} ce^{-x^2-y^2-xy-x} dy$. I need some help evaluating this integral because nothing I've tried has worked so far. I began by breaking it up and bringing out the terms with $x$:
\begin{align*}
\int_{-\infty}^{\infty} ce^{-x^2-y^2-xy-x} dy & = ce^{-x^2-x}\int_{-\infty}^{\infty} e^{-y^2-xy} dy \\
\end{align*}
However this hasn't given me anything of worth, so maybe breaking it up like this isn't the best approach. I've also tried completing the square in the exponent for both $x^2$ and $y^2$ terms but that hasn't helped either. Any help is appreciated.","['statistics', 'calculus']"
795326,A matrix $M$ that commutes with any matrix is of the form $M=\alpha I$,I feel like this is probably a simple proof but I can't quite come up with it in an elegant way nor could I find it here. Prove that if a matrix $M$ commutes with any matrix then $M$ is of the form $M=\alpha I$. Proving the contrapositive seems like the natural way to go where we can logically transform $\lnot \forall A(MA = AM)$ into $\exists A (MA \neq AM)$ but assuming that $M \neq \alpha I$ immediately becomes messy. Is there a nice way out of this or is it inevitably going to get messy?,['linear-algebra']
795334,Iterated self-composition of arbitrary function,"Does there exist some notation that represents the iterative composition of a single-input, single-output function with itself? As in, say, $f_5(x)=f(f(f(f(f(x)))))$. In other words, going by the above (incorrect, I'm pretty sure) notation: $f(x)=x+1$, $f_n(m)=m+n$ I'm looking for the correct way to express the notion of ""$f_n(x)$"" for any $f$.","['notation', 'functions']"
795338,"What, fundamentally, is the reason for the shape of a sin curve?","Say we have a metal bar in space aligned horizontally and we start rotating it counter-clockwise about its left end. Then, the sin of the angle from between the horizontal and the bar is the y coordinate of the far end divided by the length of the bar. So, I understand that sin/cos are related to projections of things when you rotate them. Is this the fundamental idea? Why do sin curves look the way they do? Why is the slope most negative when sin(x) = 0? I'm looking for an intuitive answer, not just that the derivative of sin is cos.","['trigonometry', 'calculus', 'intuition']"
795342,Is it valid to write $\sin(x+iy)=\sin (x)\cos(iy)+\cos(x)\sin(iy)$,"I'm asked to sketch the set $\{z \in \mathbb{C}:\sin z$ is a real number $\}$ Here's what I did: $$
\sin(x + iy) = \sin(x) \cos(iy) + \cos(x) \sin(iy)
$$ But since we only want the real part, then this is equal $\cos x + \sin x$. Is this valid?","['trigonometry', 'complex-analysis']"
795350,Why are 'differential operators on manifolds' differential operators?,"It is clear what is meant by a differential operator on $\mathbb{R}^n$ (or some open subset). However, it is not clear to me why differential operators on smooth manifolds are defined the way they are, involving sections of smooth sections of vector bundles. Recall that if $E, F \to M$ are smooth vector bundles over a smooth manifold $M$, a differential operator $E \to F$ is a morphism between the sheaves of smooth sections of $E$ and $F$ such that over an affine chart $U$ trivialising both $E,F$, say with $E|_U \cong U \times \mathbb{R}^n$ and $F|_U \cong U \times \mathbb{R}^m$ , $C^{\infty}(U, \mathbb{R}^n) \cong \Gamma(U, E) \to \Gamma(U, F) \cong  C^{\infty}(U, \mathbb{R}^m)$ is given by a classical differential operator. Question: why is this is the right generalisation of differential operators to manifolds -- and what is the (geometric/physical) significance of the vector bundles here? After-thought :
Ah. I believe I was confused by the fact that differential operators over manifolds are labelled as differential operators on manifolds. Not being pedantic here. It's plain why one might want to consider how smooth assignments of directions vary in certain directions (that is, why one would want to partially differentiate sections of vector bundles). However, I was under the misconception that vector bundles were brought into the picture to facilitate the generalisation of partial derivatives directly on manifolds (which incidentally are just given by the theory over the trivial bundle). A bit silly on reflection.","['mathematical-physics', 'vector-bundles', 'smooth-manifolds', 'differential-geometry']"
795380,Distribution of suits in a 13 card hand,"Let's say you have 13 cards distributed from a standard deck, find the probability of this distribution of suits: 4, 4, 3, 2, (for instance 4 hearts, 4 clubs, 3 diamonds, 2 spades). My answer was: $$\frac{ 4*{13\choose 4} * 3*{13\choose 4} * 2*{13\choose 3} * 1 *{13\choose 2} }{52\choose 13}$$ My reasoning being that since there were 4 ways to choose the first suit, 3 ways to to choose the next etc... However the real answer was: $$\frac{\frac{4!}2 *{13\choose 4} * {13\choose 4} *2 * {13\choose 3} * {13\choose 2}}{52\choose 13}$$ Basically mine divided by 2, what I don't understand why the need to divide by 2. There are 4! ways the suits can be arranged, so why are they arranged in 4!/2 ways in the answer?","['probability-theory', 'combinatorics']"
795405,Find the linear-to-linear function whose graph passes through the given three points,"Find the linear-to-linear function whose graph passes through the points 
$(1, 1)$, $(4, 2)$ and $(30, 3)$. So by using the 
$$f(x)=\frac{ax +b}{x+d}$$ 
I got my final answer to be
$$f(x)=\frac{\frac{75}{23}x + \frac{64}{23}}{x + \frac{12}{23}}$$
and it is wrong. I have to do a bunch of problems like this and I can't seem to figure it out. I am off somewhere because I did $f(4)=(4a+b)/(4+d)= 2$ $f(30)= (30a+b)/(30+d) = 3$ and $f(1)= (1a+b)/(1 +d) = 1$ then went on the cancel out $d$ and get $a$ and $b$ then find $c$.","['interpolation', 'algebra-precalculus', 'functions']"
795411,Finding the equation for a sinusoidal cycle/function given points.,"We are given the population of a fictional animal at different years: $$\begin{array}{l|r}
\textrm{Year} & \textrm{Population}\\\hline
1945 & 347,0000\\
1955 & 76,000\\
1965 & 295,000\\
1975 & 84,000\\
1985 & 243,000\\
1995 & 92,000
\end{array}$$ We are asked to come up with a formula for the population over time. I am so lost. I can get a graph to go through the first 2 points, or I can get it to go through all of the maximums or all of the minimums, but I can't get it to go through all of the points in one go.","['trigonometry', 'algebra-precalculus', 'functions']"
795412,"no. of Digit in $x^y\;,$ where $x,y\in \mathbb{N}$","$(1)$:: Calculation of no. of Digits in $2^{100}$ .$(2)$:: Calculation of no. of Digits in $3^{100}$. If it is given that $\log_{10}(2)=0.3010$ and $\log_{10}(3) = 0.4771$ $\bf{My\; Try::}$ I have seen in book and it is given as :: $(1)$ no. of Digit in $\displaystyle 2^{100}$ is equal to $\displaystyle \lfloor \log_{10}(2)^{100}\rfloor +1\;,$ where $\lfloor x \rfloor = $ floor function of $x$. $(2)$ no. of Digit in $\displaystyle 3^{100}$ is equal to $\displaystyle \lfloor \log_{10}(3)^{100}\rfloor +1\;,$ where $\lfloor x \rfloor = $ floor function of $x$. But I did not Understand How can we prove .. no. of Digit in $(x)^y$ is equal to $\lfloor \log_{10}(x)^y\rfloor +1.$ plz explain me in Detail. Thanks",['algebra-precalculus']
795414,What are primitive roots modulo n?,"I'm trying to understand what primitive roots are for a given $\bmod\ n$. Wolfram's definition is as follows: A primitive root of a prime $p$ is an integer $g$ such that $g\ (\bmod\ p)$ has
  multiplicative order $p-1$ The main thing I'm confused about is what ""multiplicative order"" is. Also, for the notation $g\ (\bmod\ p)$, is it saying $g$ times $\bmod\ p$ or does it have something to do with its congruence? Sorry for the basic question, any clarification would be great!","['modular-arithmetic', 'primitive-roots', 'number-theory']"
795439,Primes in an Infinite Set,Let $S$ be the infinite set of positive integers whose members can be written with no digits except $0$ and $1$ and with no more than $1988$ $1s$. Show that some integer $n$ does not divide any member of $S$ (Tournament of the towns 1st half of 1989 Senior A level),"['prime-numbers', 'elementary-number-theory', 'number-theory']"
795460,Trig integral with sine and cosine,"What sort of formulas can I use to reduce this into something I can work with? $$3a^2\int_{0}^{2\pi} \sin^2(\theta)\cos^4(\theta) \, d\theta$$","['definite-integrals', 'trigonometry', 'calculus', 'integration']"
795493,Integral $\int_0^1 \log \frac{1+ax}{1-ax}\frac{dx}{x\sqrt{1-x^2}}=\pi\arcsin a$,"Hi I am trying to solve this integral $$
I:=\int_0^1 \log\left(\frac{1+ax}{1-ax}\right)\,\frac{{\rm d}x}{x\sqrt{1-x^2}}=\pi\arcsin\left(a\right),\qquad
\left\vert a\right\vert \leq 1.
$$ It gives beautiful result for $a = 1$ $$
\int_0^1 \log\left(\frac{1+ x}{1-x}\right)\,\frac{{\rm d}x}{x\sqrt{1-x^2}}
=\frac{\pi^2}{2}.
$$ I tried to write $$
I=\int_0^1 \frac{\log(1+ax)}{x\sqrt{1-x^2}}dx-\int_0^1 \frac{\log(1-ax)}{x\sqrt{1-x^2}}dx
$$ If we work with one of these integrals we can write $$
\sum_{n=1}^\infty \frac{(-1)^{n+1} a^n}{n}\int_0^1 \frac{x^{n-1}}{\sqrt{1-x^2}}dx-\sum_{n=1}^\infty \frac{a^n}{n}\int_0^1 \frac{x^{n-1}}{\sqrt{1-x^2}}dx,
$$ simplifying this I get an infinite sum of Gamma functions. which i'm not sure how to relate to the $\arcsin$ Thanks.","['calculus', 'integration', 'definite-integrals', 'real-analysis', 'complex-analysis']"
795504,Does this characterize the operator norm of the inverse?,"Let $A$ be an invertible operator (bounded with bounded inverse). Then
$$\frac{1}{\|A^{-1}\|} = \inf\left\{\frac{\|Av\|}{\|v\|} : v \neq 0\right\}$$ I believe I have a proof as follows, but I just want to double check $$\begin{eqnarray*}
\inf\left\{\frac{\|Av\|}{\|v\|} : v \neq 0\right\} &=& \inf\left\{\frac{\|u\|}{\|A^{-1}u\|} : u \neq 0\right\} \\
&=& 1 / \sup\{\left\{\frac{\|A^{-1} u\|}{\|u\|} : u \neq 0\right\} \\
&=& \frac{1}{\|A^{-1}\|} 
\end{eqnarray*}$$
Is this correct?","['linear-algebra', 'functional-analysis']"
795518,How can we prove $1>\sum_{k=1}^{n}\frac{\varphi{(k)}}{k}\ln{\frac{2^k}{2^k-1}}>1-\frac{1}{2^n}$,"Let $\varphi$ be Euler's totient function, where $\varphi{(1)}=1$. Prove that for any postive integer $n$ we have
  $$1>\sum_{k=1}^{n}\left(\dfrac{\varphi{(k)}}{k}\ln{\dfrac{2^k}{2^k-1}}\right)>1-\dfrac{1}{2^n}$$ Maybe this problem can be solved using integrals. $$\ln{\dfrac{2^k}{2^k-1}}=\ln{2^k}-\ln{(2^k-1)}$$ But then I don't know how to deal with this term: $$\dfrac{\varphi{(k)}}{k}$$","['inequality', 'number-theory']"
795527,Trying to understand how many functions there are from A to B.,"I'm trying to understand why there are $B^A$ functions from $A$ to $B$. If $A=${$a,b$} and $B=${$1,2,3$} then the functions from $A$ to $B$ are $f(a)=1$, $f(b)=1$, $f(a)=2$, $f(b)=2$, $f(a)=3$, $f(b)=3$. If this is correct then there are only 6 functions. Am I going about things incorrectly?","['discrete-mathematics', 'functions']"
795537,Notation for limit approaching from above/below,"Consider the equation $$f(x)=\frac{4x+8}{x-3}$$
It is known that $$\lim_{x \to \infty} f(x) = 4$$ from above and $$\lim_{x \to -\infty} f(x) = 4$$ from below.
How do you write the ""from above/below"" formally as part of the equation?","['notation', 'limits']"
795541,Involutions of $S_n$ [duplicate],"This question already has answers here : For a set with N members, what is the number of set partitions in which each subset is either of size 1 or 2? [duplicate] (3 answers) Closed 7 years ago . How am I able to find how many involutions are in $S_n$ for any nonnegative integer $n$ ? Let's say for $S_4$ . Is there an equation or anything that allows me to find this with ease?","['permutation-cycles', 'abstract-algebra', 'combinatorics']"
795543,"What is $\operatorname{Hom}_\mathbb{Z}(\mathbb{Q}/\mathbb{Z},\mathbb{Q}/\mathbb{Z})$?","Is $\operatorname{Hom}_\mathbb{Z}(\mathbb{Q}/\mathbb{Z},\mathbb{Q}/\mathbb{Z})$ isomorphic to any ""known"" group? I suppose what I mean is, is it isomorphic to a group that isn't a Hom group? If such an isomorphism is known, is there a reference which sketches it out? I know $\mathbb{Q}/\mathbb{Z}=\bigoplus_p\mathbb{Z}_{p^\infty}$, but using the various properties to pull direct sums out doesn't seem fruitful. My motivation is that I know $\operatorname{Ext}^0_\mathbb{Z}(A,B)$ is naturally isomorphic to $\operatorname{Hom}_\mathbb{Z}(A,B)$, and pairs like $\operatorname{Hom}(\mathbb{Z},\mathbb{Z})$, $\operatorname{Hom}(\mathbb{Q},\mathbb{Q})$, etc.,  come up frequently in algebraic topology/basic examples in homological algebra. Since $\mathbb{Q}/\mathbb{Z}$ shows up commonly in topology, I'm curious about that case as well.","['homological-algebra', 'reference-request', 'abstract-algebra']"
795600,Combinatorial proof of $k\binom{n}{k} = n\binom{n-1}{k-1}$ [duplicate],"This question already has answers here : Combinatorial argument for the identity $k\binom{n}{k} = n\binom{n-1}{k-1}$ (2 answers) Closed 10 years ago . I'm trying to prove this combinatorially. $$k\binom{n}{k} = n\binom{n-1}{k-1}$$
I know the first step is to relate a question to the equation. My question was if you have $n$ friends how many ways can you choose $k$ of them. I know this isn't correct because that would be the question if the left side wasn't being multiplied by k. Can anyone help me figure out what multiplying ${n \choose k}$ by $k$ means?","['combinatorial-proofs', 'binomial-coefficients', 'combinatorics']"
795609,determinant inequality $\det(A^2+AB+B^2)\geq\det(AB-BA)$,"$A,B$ are two $2\times 2$ real matrices, then 

$$\det(A^2+AB+B^2)\geq\det(AB-BA)$$ The inequality is  equivalent to the following problem: Let $X=A+\dfrac{B}{2},Y=-\dfrac{B}{2}$ $$\det[(X-Y)(X+Y)-2(X^2+Y^2)]≥4\det(XY-YX)$$ http://www.artofproblemsolving.com/Forum/viewtopic.php?f=353&t=588819","['linear-algebra', 'inequality', 'determinant']"
795610,Axis of symmetry of a binary image,"I want to calculate the axis of symmetry of a binary image. In other words I have an image that has a black irregular shaped object with a white background. I want to find the best approximation of the axis of symmetry that will divide the black part in such a way that if you fold it on that axis that it will have the least non overlap. I read an article that used moments, but I could not make out how they did this.
I also thought about maybe treating it as a optimization problem, but it also has its drawbacks. (Using a particle swarm for example will require me to test the overlap repeatedly and that would be dead slow) Edit: it does not have to be the fastest option, but I will be running this on 500 or so images.","['geometry', 'linear-algebra']"
795642,Maximum and Minimum value of an inverse function,Find the maximum and minimum value of $\arcsin \left(x\right)^3+\arccos \left(x\right)^3$. given that $-1\le x\le 1$ I have solved the problem but i am just curious to know if there are any other ways to solve this particular problem other than the method i used below. By using the fact that $\arcsin \left(x\right)+\arccos \left(x\right)$ =$\frac{\pi }{2}$ i found that $\arcsin \left(x\right)^3+\arccos \left(x\right)^3$=$3\left(\frac{\pi }{2}\right)^2\left(\left\{\arcsin \left(x\right)-\frac{\pi }{4}\right\}^2+\frac{\left(8\pi -3\pi ^2\right)}{48}\right)$ so it is minimum when $\left\{\arcsin \left(x\right)-\frac{\pi }{4}\right\}^2$$=0$ or $x=\sin \left(\frac{\pi }{4}\right)$ Therefore minimum value$=\frac{1}{32}\pi ^3$ and it is maximum when $\arcsin \left(x\right)=-\frac{\pi }{2}$ Therefore maximum value=$\frac{7}{8}\pi ^3$,['trigonometry']
795648,Checking Initial Values of an IVP,"Show that the solution of the initial value problem $$y''+p(t)y'+q(t)y=g(t),y(t_0)=y_0, y'(t_0)=y_0'$$ can be written as $y=u(t)+v(t)$, where $u$ and $v$ are solutions of the two initial value problems $$u''+p(t)u'+q(t)u=0, u(t_0)=y_0, u'(t_0)=y_0'$$
$$v''+p(t)v'+q(t)v=g(t), v(t_0)=0, v'(t_0)=0$$ respectively. Be sure to check the initial values. I was able to show that the solution to the IVP can be written as $y=u(t)+v(t)$ (I believe). $$(u+v)''+p(t)(u+v)'+q(u+v)=[u''(t)+v''(t)]+[p(t)(u'(t)+v'(t))]+[q(t)(u(t)+v(t))]$$
$$=(u''+pu'+qu)+(v''+pv'+qv)$$
$$=0+g(t)$$
$$=g(t)$$ The problem I am having is checking the initial values. Generally, when it's a simple
$$y''+y'-2y=2t, y(0)=0, y'(0)=1$$
type of problem, checking the initial values is very straightforward. For some reason or another, I can't quite seem to check the initial values on this one. I'm sure it is something silly that I'm having a mental block on because it looks different than normal. Note: this is problem #21 in section 3.7 from Elementary Differential Equations and Boundary Value Problems, Eighth Edition. Boyce, DiPrima.",['ordinary-differential-equations']
795694,Snake cube puzzle equation,"This is a Snake Cube Puzzle I am trying to understand the solution from mathematical point of view. Someone even wrote a solver: https://github.com/markfickett/snakepuzzle but I can't really read the code. I can imagine a solver that would iterate through all combinations until it finds one that is 3x3x3 in size but that is not really a ""solution"". What would be the equation and how would I approach solving it?","['permutations', 'puzzle', 'group-theory']"
795702,if $\frac{1}{1+x+f(y)}+\frac{1}{1+y+f(z)}+\frac{1}{1+z+f(x)}=1$ find the function $f(x)$,"Find all functions $f(x):(0,\infty)\to(0,\infty) $satisfying
$$\dfrac{1}{1+x+f(y)}+\dfrac{1}{1+y+f(z)}+\dfrac{1}{1+z+f(x)}=1$$ whenever $x,y,z$ are positive numbers and $xyz=1$ I know this if
$$xyz=1\Longrightarrow \dfrac{1}{1+x+xy}+\dfrac{1}{1+y+yz}+\dfrac{1}{1+z+zx}=1$$
because
\begin{align*}\dfrac{1}{1+x+xy}+\dfrac{1}{1+y+yz}+\dfrac{1}{1+z+zx}&=\dfrac{1}{1+x+xy}+\dfrac{x}{x+xy+xyz}+\dfrac{xy}{xy+xyz+x^2yz}\\
&=\dfrac{1+x+xy}{1+x+xy}\\
&=1
\end{align*}
so I guess
$$f(x)=\dfrac{1}{x}$$
But I can't prove it.Thank you",['analysis']
795732,This is about Sylow subgroups of Alternating group $A_n$ (Multiple choice),"This is a question from a competitive exam. For a positive integer $n\ge 4$ and a prime number $p\le n$ denote $U_{p,n}$ to be the union of all $p$-sylow subgroups of alterbating group $A_n$. Also let $K_{p,n}$ denote the subgroup of $A_n$ generated by $U_{p,n}$ and let $|K_{p,n}|$ denote the order of $K_{p,n}$.Then $|K_{2,4}|=12$ $|K_{2,4}|=4$ $|K_{2,5}|=60$ $|K_{3,5}|=30$ It may have more than one correct answer. I don't know how to start, I am completely stuck.Please help. Thnx in advance.","['sylow-theory', 'finite-groups', 'group-theory', 'abstract-algebra']"
795755,Suppose $A^n = 0$ matrix for some $n > 1$. Find an inverse for $I - A$.,"Source: Linear Algebra by Lay (4 edn 2011). p. 160. Chapter 2 Supplementary Exercise 4. Solution: From p. 160 Supplementary Exercise 3, the inverse of $I-A$ is probably $I+A+A^{2}+...+A^{n-1}$. To verify this, compute
  $ (I \color{orangered}{-A} )\color{forestgreen}{(I+A+\cdots+A^{n-1})}=I+A+\cdots+A^{n-1} \quad \color{orangered}{-A}(I+A+\cdots+A^{n-1})=I \color{orangered}{-A} A^{n-1}=I-A^{n}. \;[...] \; \blacksquare$ How can you divine that the inverse of $I-A$ is  $\color{forestgreen}{\sum_{0 \le i \le n - 1} A^{i}}$ ? The solution doesn't explain. I already understand that $ (I \color{orangered}{-A} )\color{forestgreen}{(I+A+\cdots+A^{n-1})}= ... =I-A^{n}. $","['matrices', 'linear-algebra', 'proof-explanation']"
795771,Probability of random walk returning to 0,"Given a symmetric 1-dimensional random walk starting at 0 -- what is the probability of the walk returning $k$ times to 0 after $2N$ steps? I know that the total number of paths it can take is $2^{2N}$. My problem is finding the total number of paths returning to 0. Also, since you can only return at even $k$'s, the no. of possible hitting points is $ {{N}\choose{k}}.  $","['random-walk', 'probability']"
795783,Show that $\sum_{n \geqslant 0} |a_n z^n|<1$ with $|z|<1/3$ .,"Assume that $\sum_{n \geqslant 0} a_n z^n$ converges for $|z|<1$ and $$\left|\sum_{n \geqslant 0} a_n z^n \right|<1$$ 
  Show that for all $z \in \mathbb{C}$, with $|z|<1/3$ we have $$\sum_{n \geqslant 0} |a_n z^n|<1$$ I am stuck with this exercise, could someone give me some hint please ?","['sequences-and-series', 'real-analysis']"
795797,Ornstein-Uhlenbeck process: increments,"I'm new to the forum so I hope this first question goes well. Let the Ornstein-Uhlenbeck process be defined as:
$$
dV_t = - \beta V_t dt + \sigma dW_t
$$ with $V_0 = v$, where $W_t$ is a Wiener Process (or Brownian Motion) started at $0$. I have spent quite a while trying to prove if this process has independent increments , i.e., $Cov(V_t - V_s, V_s - V_0) =0$. The result I'm obtaining is different than zero, which would imply that the increments are not independent, but I am unsure about the accuracy of my calculations. Intuitively , I would say I've gone wrong, because if the process is driven by a Brownian Motion, and the latter has independent increments, one could perhaps argue that then the O-U process must have independent increments too. This leads me to ask two questions: Is there an intuitive reasoning to argue if $V_t$ has (or has not) independent increments? Should we take the stationary distribution of $V_t$ (letting $t \rightarrow \infty$) such that $V_t \sim N\left(0, \frac{\sigma^2}{2\beta}\right)$, what would happen to the increments?. P.S: I can guess that if we consider the non-stationary distribution of $V_t$, the increments are non-stationary, given that $V_t \sim N\left(e^{-\beta t}v, \frac{\sigma^2}{2\beta}(1-e^{-2\beta t})\right)$ and thus they would always depend on $t$. Perhaps you can prove me wrong here too.","['probability-theory', 'stochastic-processes', 'stochastic-calculus', 'brownian-motion']"
795799,"Why study cardinals, ordinals and the like?","Why is the study of infinite cardinals, ordinals and the like so prevalent in set theory and logic? What's so interesting about infinite cardinals beyond $\aleph _0 $ and $\mathfrak{c} $? It seems like they're enough for all practical purposes and they don't seem to pop up in pure mathematics also.","['motivation', 'cardinals', 'elementary-set-theory', 'ordinals']"
795831,Closed points of a fibred product of k-schemes,"This question comes from Shafarevich, Chapter V.4, Let $X$ and $Y$ be schemes over an algebraically closed field $k$.
  Show that the correspondence  $ u \to (p_x(u),p_y(u)) $ establishes a
  1-1 map between closed points of $ X \times_k Y$ and the pairs
  $(x,y)$, where $x,y$ are closed points of $X$ and $Y$ respectively. I've been trying to tackle this in the case of affine schemes (I'm assuming the general case reduces to this), where $X = \mathrm{Spec }A$ and $Y = \mathrm{Spec }B$. In this case the fibred product is $\mathrm{Spec }A \otimes_k B$, where $A$ and $B$ have the structure of $k$-algebras. I can see how this works in the case of affine rings (i.e finitely generated, reduced k-algebras), but I don't really see why it should work in general. Why, for example, does the projection map (induced by $ a \to a \otimes 1$) send closed points to closed points?","['algebraic-geometry', 'schemes']"
795867,Evaluation of $\int_0^1 \frac{\log^2(1+x)}{x} \ dx$,"One of the ways to approach it lies in the area of the dilogarithm, but is it possible to evaluate it by other means of the real analysis (without using dilogarithm)? $$\int_0^1 \frac{\log^2(1+x)}{x} \ dx$$ EDIT : maybe you're aware of some easy way to do that. I'd appreciate it! Some words on the generalization case (by means of the real analysis again)? $$F(n)=\int_0^1 \frac{\log^n(1+x)}{x} \ dx, \space n\in \mathbb{N}$$","['calculus', 'integration', 'definite-integrals', 'harmonic-numbers', 'real-analysis']"
795919,$\mathbb Z_{mn}$ isomorphic to $\mathbb Z_m\times\mathbb Z_n$ whenever $m$ and $n$ are coprime,How to show that $\mathbb Z_{mn}$ is isomorphic to $\mathbb Z_m \times\mathbb Z_n$ when $m$ and $n$ are coprime? It is easy to show that the natural map from $\mathbb Z_{mn}$ to $\mathbb Z_m \times\mathbb Z_n$ is a ring homomorphism. How to show that it is bijective?,"['ring-theory', 'abstract-algebra']"
795949,Joint density of order statistics,"I need some help to understand the following proposition (mainly to understand how it is proven): Let $Y_1,Y_2...,Y_n$ be $n$ random variables which are independent, identically distributed random variables with probability density function $f$. The joint density of the order statistics $Y_{(1)},Y_{(2)},..,Y_{(n)}$ is given by: $\textbf{(1)}\quad$$f(y_1,y_2,...,y_n)= n!\prod\limits_{i=1}^{n}f(y_1) \qquad y_1 <y_2...<y_n$ $\textbf{(i)} \quad$the preceding follows since:
($Y_{(1)},Y_{(2)},..,Y_{(n)})$ will equal $(y_1,y_2...,y_n)$ if $(Y_1,Y_2,...Y_n)$ is equal to any of the $n!$ permutations of  $(y_1,y_2...,y_n)$ ** this part i get; they are saying that the ordered statistics is equal to the tuple $(y_1,y_2...,y_n)$ only if the unordered  $(Y_1,Y_2,...Y_n)$ is equal to a permutation of $(y_1,y_2...,y_n)$. But what does have for consequence in $\textbf{(1)} ??$ ** $\textbf{(ii)}\quad$ the probability density that $(Y_1,Y_2,...,Y_n)$ is equal to $y_{i_{1}},...,y_{i_{n}}$  is $\prod_{j=1}^{n}f(y_{i_{j}}) = \prod_{j=1}^{n}f(y_j)$ when $i_1,...i_n$ is a permutation of $1,2...,n$ ** here Iam completely lost;  the probability density that $(Y_1,Y_2,...,Y_n)$ is equal to $y_{i_{1}},...,y_{i_{n}}$ what do they mean? probability density (function)? I don't know what they mean at all with this statement","['statistics', 'stochastic-processes', 'probability']"
