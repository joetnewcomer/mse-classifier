question_id,title,body,tags
2753652,Surface optimization for a volume,"One of my children received this homework and we are a bit disoriented by the way the questions are asked (more than the calculation actually).
This is exactly the wording and layout of the homework: Consider an aluminum can: for example, a Coke can. Do such cans have
  the right dimensions? What does ""right"" mean? Why do other products
  come packed in containers of other shapes? Question: An ordinary can has a volume of 355 cm3. What shape will hold this volume of liquid using the least amount of aluminum (minimising
  surface area)? Demonstrate your conclusion by comparing 2 different shapes in addition to a cylinder. Consider defining suitable variables and stating any and all assumptions you make. Use differentiation to find the value of your variable that minimizes the volume of metal used to make the container. Is there
  another method you can use to justify your model? Are real containers this shape? Why or why not? Discuss which model best fits the actual container, giving reasons for any differences, if they exist. You are then informed that the circular top and bottom of your drink
  can has thichtess 0.2mm but that the curved surface has thiclvtess
  0.Imm. Nist Inc. would like to launch a new sized can that has a capacity of 200 ml. Using your model, find the dimensions of the can that would
  minimize the volume of metal used to make the can. Do you think that Nist Inc. would use these dimensions? Why or why not? First, keep in mind that they have only seen derivatives so far (no integrals yet).
Second, please understand that we are not native English speakers so decoding the sentences is part of the problem. Finding the optimal height and radius of the cylinder is quite trivial: Find the constraint equation (volume in terms of height) Find the optimizing equation (surface Area). Plug the height of the volume equation into the optimizing equation Derive that equation and make it equal to zero Solve it for the radius and plug the radius found in the height equation. The answer will provide you the ideal height and radius to optimize the surface area of the cylinder. So far so good, it seems that the actual cans are more or less optimal if simplified as pure cylinders (but the homework seems to consider there is another ""model"" that could be used. I went and check on the internet with no success. This model seems the obvious one). Now, does it have the ""right dimensions""? ""what does right mean""? and ""why do other products come packed in containers of other shapes""? 
It seems to be anything but pure math questions and it seems to be dependent on how you see things (storage, drinking convenience,..).
As I'm sure I'm wrong, I can't possibly understand what answers are expected here.
Maybe I'm missing the point to make it all clear, at once. The ""right"" dimensions? For a soda can, it's pretty close to the ideal measures yes but is it the expected answer? No clue. ""What does right mean""? Well... I don't know what this question is really asking. In terms of Maths? In terms of storage issues? In terms of practicality? In terms of costs? ""why do other products come packed in containers of other shapes"" Same here? Cubes are easier to store I guess? Flat tops and bottoms allow a more convenient way to stack things? But I'm pretty sure I just don't get it. Moreover, this is an intro text and a series of questions are coming just after. I just don't know if these questions in the intro text are rhetorical or if they are already meant to be answered. Which would be strange as there is no constraining data yet. Now come the actual questions: ""What shape will hold this volume of liquid
using the least amount of aluminum (minimising surface area)?"" That would be a sphere, with no doubt. But how to prove it in a trivial and absolute way? It's seems intense. ""Demonstrate your conclusion by comparing 2 different shapes in addition to a cylinder"". How a non comprehensive comparison would demonstrate anything? Here too, I don't get it. I could make the calculation for a cube and then a cylinder and then a sphere to show that it would decrease the surface area for a given volume but that wouldn't be a proof of anything, would it?
All I would be able to say is that ""it seems"" that the more we go towards a shape with an infinite amount of sides (perfect curvature), the more we will optimize the surface area. But that doesn't demonstrate anything, especially if we just take 2 other shapes to get to that conclusion. ""Is there another method you can use to justify your model?"" Besides using the derivative to find the optimal height and radius? I can't seem to find another. Are we talking about the sphere model or the cylinder model now? ""Are real containers this shape? Why or why not?"" Sphere or cylinder? What shape are we talking about now? ""Discuss which model best fits the actual container, giving reasons for any differences, if they exist."" Which model is there that is obvious, besides the derivative?
It feels like the questions are not specific enough. ""Do you think that Nist Inc. would use these dimensions? Why or why not?"" Here too, I'm lost. I can calculate the dimensions just fine but it seems that I have to go through the same reasoning than all the questions above...which are already confusing. My question is somewhere between a math question and an understanding question.
But if I go and ask on another forum dedicated to English, they might be unhelpful because of the math aspect of that homework. So, all in all, it seems to be the best place to ask the question.
I'm sure I just miss the point of that homework which makes all the questions quite obscure to me.
Maybe some hint will help deblocking the situation at once.
I feel like I'm missing something obvious.
That's what I'm asking for. I'm probably sure this post will make some people laugh and make a clown out of me but be assured that the language barrier doesn't help. Thanks in advance.","['optimization', 'volume', 'calculus', 'spheres', 'area']"
2753655,"symmetric $(2k)\times (2k)$ matrix, $k \geq 4$, consisting of $0$s and $1$s with exactly $k$ ones in each row and column","Let $k \geq 4$. Let $M=(m_{ij})_{1 \leq i,j\leq 2k}$ be a symmetric $(2k)\times (2k)$ matrix whose entries are either $0$s or $1$s and (1) All diagonal entries are zero, i.e., $m_{ii}=0$; (2) Every row and every column have precisely $k$ ones. (3) The total number of $1$s is $2k^2$. (4) Assume that 
$$M \neq  \begin{bmatrix}0^{k\times k} &1^{k\times k}\\1^{k\times k} &0^{k\times k}\end{bmatrix},
$$
or any matrix that consists of an elementary permutation of this matrix (I could not think of a better way to say this). Suppose that $M_1, \ldots, M_{2k}$ are the row vectors (also the column vectors by symmetry) of $M$. I want to prove the existence of two integers $1 \leq i<j \leq 2k$ such that $m_{ij}=m_{ji}=1$ and $M_i \cdot M_j^T\geq 2$. I cannot find a counterexample for smaller cases like $k=4$ and $k=5$. I wanted to try to prove this by contradiction: Suppose that for each $1\leq i<j\leq 2k$ such that $m_{ij}=m_{ji}=1$ and $M_i \cdot M_j^T\in \{0,1\}$. Here is where I hit a wall. Any suggestions? I will include the graph theory equivalent problem: Let $k \geq 4$. Given a $k$-regular graph on $2k$ vertices and $k^2$ edges such that $G \not \cong K_{k,k}$, show that there exists an edge $xy \in E(G)$ such that $|N(x)\cap N(y)|\geq 2$, i.e., $x$ and $y$ have at least two neighbors. This is equivalent to showing that $G$ must contain a subgraph isomorphic to $K_4-e$. If it is of any help, there is a theorem by Paul Erdős that says that such a graph, as described above, should have at least $k-1$ triangles. I want to show that there exist two triangles that share an edge.","['graph-theory', 'matrices', 'combinatorics', 'linear-algebra', 'discrete-mathematics']"
2753662,Inequality of $(|a|^{\ell-2}a- |b|^{\ell-2}b\Big)(a-b) $,"Letting $\epsilon\geq0$ be small, $a,b\in \mathbb{R}^N$ and $\ell >1$. 
Is the following inquality
$$\tag{E}\label{E} \Big((\sqrt{\epsilon^2+|a|^2})^{\ell-2}a- (\sqrt{\epsilon^2+|b|^2})^{\ell-2}b\Big)(a-b)\geq 0, $$
true? If $\epsilon=0$, \eqref{E} becomes 
$$(|a|^{\ell-2}a- |b|^{\ell-2}b\Big)(a-b)\geq 0, $$
which is true by using the following inequalities: 
\begin{align}
\left(|a|^{\ell-2}a-|b|^{\ell-2}b\right)\cdot (a-b)\geq 2^{-\ell}|a-b|^2,&\quad  \ell\geq 2,\\
\left(|a|^{\ell-2}a-|b|^{\ell-2}b\right)\cdot (a-b)\geq (\ell-1)|a-b|^2\left(|a|+|b|\right)^{\ell-2}  ,&\quad  1<\ell \leq 2.
\end{align}
 $a\cdot b$ denotes the usual inner product in $\mathbb{R}^N$. Can any one know if \eqref{E} is true or not? Here my try for the answer: Letting $\epsilon$ small. Denoting by $f$ the function defined as $$f(\mathbf{x})=\frac{1}{\ell}(\epsilon^2+|\mathbf{x}|^2)^{\ell/2}.$$
 $f$ is convexe in $\mathbf{x}$. Then, by the convexity proprity we have 
$$(f'(\mathbf{x})-f'(\mathbf{y}))\cdot (\mathbf{x}-\mathbf{y})\geq c\|\mathbf{x}-\mathbf{y}\|^2.$$
Then \eqref{E} holds. I don't know there is a mistake or not.","['functions', 'real-analysis', 'calculus', 'analysis']"
2753667,Creating a Power Series with Interval of Convergence Given an Interval,"So I know to determine an interval for a power series, we would use things like the ratio test and then some of the other tests to determine the endpoints but how would you go about doing the reverse? If we had any such interval like (a,b], [a,b], [a,b), or (a,b), how would you go about creating a power series that would have such an interval? An observation I was thinking of, since the general expression for a power series contains $(x-c)$ where the series is centered around $c$, we would have it so that $c$ = $(a+b)/2$ Is there a systematic way of doing such a thing?","['power-series', 'convergence-divergence', 'sequences-and-series', 'calculus']"
2753729,Probability not divisible by $k^2$,"My question is about this problem: Let $s > 1$ and $$\zeta(s) = \sum_{n = 1}^{\infty} n^{-s}.$$ Furthermore let $(\Omega, \mathcal{F}, \mathbb{P}$) be a probability space with $\Omega = \mathbb{N}$, $\mathcal{F} = 2^{\Omega}$ and 
$$\mathbb{P}({n}) = \frac{n^{-s}}{\zeta(s)}, n \in \mathbb{N}.$$ We define $\mathcal{P}_n = p$ is a prime number and $p \le n$ and $\mathcal{P}_\infty = \cup_{n \in \mathbb{N}} \mathcal{P}_n$. Prove the following :
$\mathbb{P}(n \in \mathbb{N} : k^2$ does not divide $n$ for all $k \ge 2$) means $$\prod_{p \in \mathcal{P}_\infty} (1 - p^{-2s})$$ I do not really how to start this, I am unable to find any link between the right-hand side and the left-hande of the equation.
I am grateful for any tip, suggestion and piece of advice","['number-theory', 'probability-theory', 'probability', 'prime-numbers']"
2753773,Showing curl curl of symmetric gradient is 0,"I am trying to show that $curl\,curl\,(\mathcal E)=0$, where $\mathcal E$ represents the symmetric gradient, i.e., for vector-valued function $u(x_1,x_2)=(u_1(x_1,x_2),u_2(x_1,x_2))$
$$
\mathcal E(u)=
\begin{bmatrix}
\partial_1 u_1 & \frac12(\partial_2 u_1+\partial_1 u_2)\\
\frac12(\partial_2 u_1+\partial_1 u_2) & \partial_2 u_2
\end{bmatrix}
$$
I know there is a formula sayinng that 
$$
curl\,curl\,= \nabla div - \Delta
$$
and I am tryinng to apply this formula. However, I got confused that, say $\mathcal E(u)$ is a 2 by 2 matrix, so $\Delta \mathcal E(u)$ should be a 2 by 1 vector. But $div(\mathcal E(u))$ is a 2 by 1 vector and $\nabla div \mathcal E(u)$ is then a 2 by 2 matrix... so their dimension does not match... where I am wrong? Also, I tried to explicitly write down the computation but they did not cancel to 0... update: for a reference I found, they write $\nabla div - \Delta$ as a 2 by 1 vector, but no explicit formula can be found there... Any help is really welcome!","['tensors', 'calculus', 'multivariable-calculus', 'differential-geometry', 'linear-algebra']"
2753779,Intermediate Value Theorem and Fundamental Theorem of Calculus question,"I received a question on a previous exam, but I had no clue how to go about doing it.  I know I'm supposed to use the MVT, IVT and FTC, but I'm not sure where.  The question is Suppose $f(x)$ is integrable on $[a,b]$, with $f(x)\geq0$ on $[a,b]$, and that $g(x)$ is continuous on $[a,b]$.  Assuming that $f(x)g(x)$ is integrable on $[a,b]$, show that $\exists c\in[a,b]$ so that $$\int^b_af(x)g(x)dx=g(c)\int^b_af(x)dx.$$ Thank you in advance.","['derivatives', 'integration', 'continuity', 'convex-analysis']"
2753786,Solve a trigonometric equation: $|1-2\sin^2 x|=|\cos x|$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I have difficulty in solving this equation: $$|1-2\sin^2 x|=\lvert\cos x\rvert.$$ What are the indications to solve the exercise correctly?","['algebra-precalculus', 'trigonometry']"
2753847,What am I doing wrong while finding the Laurent series of $\frac{1}{\sin(z)}$? [duplicate],"This question already has answers here : Calculate Laurent series for $1/ \sin(z)$ (4 answers) Closed 6 years ago . I'm trying to compute the Laurent series of $\frac{1}{\sin(z)}$ at $z_0=0$.
From what I've seen on the internet this is given as $f(z)=\frac{1}{z}+\frac{z}{3!}+\frac{7z^3}{360}+...$ My attempt: $f(z)=\frac{1}{\sin(z)}$ can be rewritten as $f(z)=\frac{1}{z}\frac{z}{\sin(z)}$ We can express $\sin(z)$ as $\sin(z)=z-\frac{z^2}{3!}+\frac{z^4}{5!}+...$ $\therefore \frac{z}{\sin(z)}=(\frac{\sin(z)}{z})^{-1}=(1-\frac{z}{3!}+\frac{z^3}{5!}+...)^{-1}$ To get this to equal what I know it should, then we should have $(\frac{\sin(z)}{z})^{-1}=(1+\frac{z}{3!}+\frac{7z^3}{360}+...)$ but how can this be what do I do with my negative sign and how do I obtain the $\frac{7}{360}$ coefficient?","['laurent-series', 'complex-analysis']"
2753852,Joint Proportionality,"Although I'm already in calculus and doing good, I don't understand joint variation! Given that $x$ is directly proportional with $y$ and inversely proportional with $z,$ we have that $$\dfrac xy = c_1\quad\text{and}\quad xz = c_2;$$ then why can we combine them to conclude that $$xz = ky \ ?$$ Doesn't $xz$ have a fixed value regardless of what $y$ is? For example, consider this typical problem: Given that $x$ is directly proportional with $y$ and inversely proportional with $z:$ if $x = 20, y = 10, z = 5,$ then $x = ? , y = 100, z = 18.$ The given answer: $x = 500/9.$ But $xz = 100$ in the first situation, and $xz = 1000$ in the second situation, and $xz$ is supposed to be a constant; so, how can this be?","['algebra-precalculus', 'terminology', 'functions']"
2753914,Limits of a product [duplicate],"This question already has answers here : How to calculate $\lim_{n\to\infty}(1+1/n^2)(1+2/n^2)\cdots(1+n/n^2)$? (4 answers) Closed 4 years ago . $N$ is a positive integer.
I want to calculate this limit, but i couldn't get anywhere when i tried. $$P[n]=\left(1+\frac {1}{n^2}\right)\left(1+\frac {2}{n^2}\right)\cdots\left(1+\frac {n-1}{n^2}\right)$$ as $n\to \infty$ I tried to apply $\ln()$ at both sides to transform into a sum etc..
tried to use functions to limit the superior and inferior intervals of the function like this:
$$\exp\left(\left(n-1\right)\ln\left(1+\frac1{n^2}\right)\right)<P[n]<\exp\left((n-1)\ln\left(1+\frac{n-1}{n^2}\right)\right)$$
The only thing I get is that:
$1<\lim(P[n])<e$ Can anyone help me to solve this?","['calculus', 'limits']"
2753958,what is the best approach to show that F is complex differentiable?,"Suppose that f is differentiable on an open set G and $z_0 ∈ G$. Let $F(z) = \frac{f(z)-f(z_0)}{z-z_0},$ $(z \neq z_0), F(z_0) = f
′
(z_0)$ Prove that F is differentiable on G. I wanted to use an argument which relied on the definition of differentiability to show that $F'(z)=lim_{h \to 0}\frac{F(z+h)-F(z)}{h}$. But apparently you can't use arguments like that here , because then it would imply that it is true for the reals also. Now I'm thinking that if f is differentiable it has a taylor series so if I can show that F(z) has a taylor series then this will imply that F is differentiable. Is this the right approach ? and if not is- there any suggestions as to what approach\proofs might prove more fruitful ?","['derivatives', 'complex-analysis', 'proof-verification']"
2753966,Recognize this power series?,"I've been doing some research in ergodic theory (on Perron-Frobenius operators on Banach spaces of analytic functions) and have been led to some power series that may have been studied in other contexts. The power series are
$$
\Phi_k(z)=
\sum_{m\text{ even}}\binom mk z^{m/2},
$$
where the sum is taken over those $m$'s such that $m\ge k$. I have played around with this and written it as a difference of two rational expressions in $\sqrt z$ (even though, of course $\Phi_k(z)$ is actually an analytic function of $z$ in the unit disk - the odd powers of $\sqrt z$ cancel). Are these functions known in some existing context? Are there other well-known examples (possibly series solutions of differential equations?) where one is led to a difference of power series in $\sqrt z$, where the half-integer powers all cancel?","['ordinary-differential-equations', 'power-series']"
2753976,"Two-complexes in Thurston's ""Conway's Tiling Groups""","I'm trying to read "" Conway's Tiling Groups "" by W.M. Thurston.  Frankly, I'm more interested in turning some of the algorithms into computer programs, just for my own amusement, than in understanding the math in complete detail, but I want to understand what's going on. Thurston starts by defining the (Cayley) graph $\Gamma(G)$ of a finitely- generated group $G$. If $G$ is a group, then its graph $\Gamma(G)$ with respect to generators $g_1,g_2,\dots,g_n$ is a directed graph whose vertices are the elements of the group.  For each vertex $v\in\Gamma(G),$ there will be $n$ outgoing edges, labeled by the generators, and $n$ incoming edges: the edge labeled $g_i$ connects $v$ to $vg_i.$ It is convenient to make a slight modification of this picture when a generator $g_i$ has order $2.$  In that case, instead of drawing an arrow from $v$ to $vg_i$ and another arrow from $vg_i$ back to $v,$ we draw a single undirected edge labeled $g_i.$ So far, so good.  My problem comes when he extends this graph to a $2-$complex. Whenever $R$ is a relator for the group, that is, a word in the generators which represents $1$, then if you start from $v\in\Gamma(G)$ and trace out $R,$ you get back to $v$ again.  If $G$ has presentation $$
G=\langle g_1,g_2,\dots,g_n|R_1=1,R_2=1,\dots,R_k=1\rangle
$$ the graph $\Gamma(G)$ extends to a $2-$complex $\Gamma^2(G)$: sew $k$ disks at each vertex of [sic] $v\in \Gamma(G),$ one for each relator $R_i$ so that its boundary traces out the word $R_i.$  An exception is made here for relations of the form $g_i^2=1$ since this relation is already incorporated in making $g_i$ an undirected edge. Thurston goes on to claim that $\Gamma^2(G)$ is simply connected.  Given a loop, the sequences of edges in the path is a word in the generators that represents the identity. He says, A proof that this word represents the identity by making substitutions using the relations $R_i$ can be translated geometrically into a homotopy of the path in $\Gamma^2(G).$ I don't understand at all how the $k$ disk are supposed to be sewn on, though Thurston seems to feel that this is obvious.  I'm thinking of the disk $R_i$ as a regular $m-$gon, where the are $m$ symbols in $R_i$ and the edges of the $m-$gon are labeled in sequence with the symbols of $R_i.$  Are these edges all supposed to be sewn to edges emanating from $v$?  That would seem to require self-intersection, at least in some cases, but later on, Thurston seems to imply that $\Gamma^2(G)$ is embedded in three-space.  (That may be a false impression.  I've only gone through the paper once quickly to determine that it interested me, and now I'm trying to understand it-- and I'm stuck on the first page!) I'm also wondering exactly what a $2-$complex is.  I'm thinking it's something like a simplicial complex of dimension $2$, but there you never get anything like self-intersection do you?  (It's been many years since I took algebraic topology, and what little I think I remember is probably wrong.)","['algebraic-topology', 'graph-theory', 'group-theory']"
2753983,Area of polygon on complex plane formed by complex roots of a polynomial,"Compute the area of the polygon whose vertices are the solutions in the complex plane to the polynomial $x^7+x^6+x^5+x^4+x^3+x^2+x+1=0$. What I did was find the complex numbers by factoring and then using Surveyor's formula. However, that required me to use synthetic or polynomial division. I was wondering if there was a way to find the numbers without directly using division or whether there's a geometric approach to this?","['algebra-precalculus', 'complex-numbers']"
2754047,A coin-tossing game with an unexpected expected value?,"Consider independent tosses of a rather biased coin that has $$\begin{align}
\Pr({\tt Head})&=1/G\\
\Pr({\tt Tail})&=1-\Pr({\tt Head}),\end{align}$$ 
where $G$ is Graham's Number . Let the first $100$ tosses establish a ""target"" pattern, then let $N$ be the number of additional tosses needed to get a repetition of that target pattern (allowing overlap). E.g., a sequence that begins with $101$ consecutive ${\tt Tail}$s would have $N=1$. Question : $\ \mathbb{E}(N)\ =\ ?\quad$ I'm posting in the spirit of this advice , and will eventually post the answer if no one else does so.","['combinatorics', 'probability']"
2754053,"Let $X,Y$ be independent RVs. If there exists $c \in \mathbb R $ s.t. $P(X+Y=c)=1$, then $X,Y$ are constants","I would like to show: Let $X,Y$ be independent RVs.
If there exists $c \in \mathbb R  $ s.t. $P(X+Y=c)=1$ , then $X,Y$ are constants a.s.. What I tried: Since X,Y are indep, $$1=P(X+Y=c)=\int 1_{x+y=c} \, d \mu _x  \, d \mu_y =  \int P(X=c-y) \, d \mu_y$$ but it gets nowhere from here.","['independence', 'probability-theory', 'variance', 'probability', 'random-variables']"
2754141,The derivative of the action functional and Lie derivative,"When computing the ""formal"" derivative of the action functional 
$$\mathcal{A}\colon C^{\infty}(S^1,M) \to \mathbb{R}$$
$$x \mapsto \int_{S^1}x^* \alpha $$
on a contact manifold $M$ with contact form $\alpha$, we pick a variation $x_s$ of $x$ with variational vector field $Y$ and aim to compute
$$\frac{d}{ds}\mathcal{A}(x_s).$$
In the computations I see, the first steps are 
\begin{align*}
\left(\frac{d}{ds}\mathcal{A}(x_s)\right)_{|_{s=0}}&=\left(\frac{d}{ds}\int_{S^1}x_s^* \alpha\right)_{|_{s=0}} \\
&= \int_{S^1} \left(\frac{\partial}{\partial s}x_s^* \alpha\right)_{|_{s=0}} \\
&\stackrel{!}{=} \int_{S^1} x^* \mathcal{L}_Y \alpha  \\
&=\cdots 
\end{align*}
 and from then on I can follow. However, I don't see why the Lie derivative appears here. The $x_s^*$ are pull-backs by maps of the circle. I don't see the derivative of the pull-back of a flow on $M$ , only the derivative of the pull-back of the maps $S^1 \to M$. In fact, I don't see the flow of $Y$ appearing. My question is: How do I see why the equation $(!)$ holds?","['symplectic-geometry', 'contact-topology', 'differential-geometry', 'differential-topology']"
2754170,Showing Bounded Derivative $\implies$ Lipschitz Function (Uniformly Continuous),"Let $I$ be an interval in $\mathbb{R}$ (bounded or unbounded). Let $f: I \rightarrow \mathbb{R}$ be differentiable, with the property that $|f'(x)| \le M,  \forall x \in I$ . Show that $|f(x) - f(y)| \le M |x - y|$ , for all $x \in I$ . Essentially, I need to show that a function whose derivative is bounded is uniformly continuous. I've seen the answer posted at Prove that a function whose derivative is bounded is uniformly continuous. , but it seems that answer assumes the conclusion I need to arrive at. I'm trying to understand the solution posted above, but I don't quite see how they assume the conclusion I need to arrive at. Is the case similar with my question, where we can simply use the Mean Value Theorem? If not, how should I approach this problem? A bounded derivative means that the rate of change for the function will decrease and decrease, which means the function itself must also be decreasing (monotonically?). Is my line of thinking correct, or on the right track? I can't seem to put these thoughts into a formal proof. Any help on this problem would be very helpful. Thank you!","['derivatives', 'real-analysis', 'continuity', 'uniform-continuity']"
2754189,Find greatest value of $a^2+b^2$,"If $f(x)=x^3+3x^2+4x+ a \sin x + b\cos x ~ \forall x \in \mathbb{R}$ is an injection then the greatest value of $a^2+b^2$ is _______? To ensure injection, we must ensure that there is no maxima/minima in any interval which is equivalent to $f'(x)\neq 0$. Note that $f'(x)=3x^2+6x+4+a \cos x - b \sin x \neq 0$. It can be observed that $3x^2+6x+4>0$ with its minimum value being $1$. So, our condition can be reduced to $a \cos x - b \sin x > -1$. Again, $a \cos x - b \sin x +1$ can be written as $\frac{a}{\sqrt {a^2+b^2}} \cos (-x) - \frac{b}{\sqrt{a^2+b^2}} \sin (-x) +1$ such that $\sin (\theta -x) + \frac{1}{\sqrt {a^2+b^2}} >0$. I couldn't proceed anymore!",['functions']
2754199,Local Convexity and Curvature (Do Carmo),"I find myself unable to start the following problem in Differential Geometry of Curves and Surfaces by Do Carmo, Section 3.3 Problem 24.a Edit: (Definition) (Local Convexity and Curvature). A surface $S \subset R^3$ is locally convex at
a point p ∈ S if there exists a neighborhood V ⊂ S of p such that V is
contained in one of the closed half-spaces determined by Tp(S) in R3. If,
in addition, V has only one common point with Tp(S), then S is called
strictly locally convex at p. ""Prove that S is strictly locally convex at $p$ if the principal curvatures of
  $S$ at $p$ are nonzero with the same sign (that is, the Gaussian curvature
  $K(p)$ satisfies $K(p) > 0$)."" I fail to see why this is strictly locally convex, in fact, I fail to see why this must be locally convex. What if we had a surface that was generated by revolving about the y axis a curve with infinitely many bumps as x approaches to 0 (with decreasing amplitude to bound its derivative)?, but also somehow makesure that this surface is elliptic at (x,y) = (0,0)? My guts tell me that this would not be a regular surface, but I am unable to prove it. I would appreciate any hints!",['differential-geometry']
2754209,The smallest distance between any point on a curve and the parabola $y=x^2$ is 1. What is the equation of the curve?,"Find the equation of the function $f(x)$, where: the optimal distance between any one point $P$ on the curve $y=f(x)$ and the parabola $y=x^2$ is always equal to $1$ $f(x)>x^2$ for all $x$ (looking for the solution curve above the parabola, not below) Here is a visual approximation of the construction on Desmos: https://www.desmos.com/calculator/pyomsrazo7 This problem arose when attempting to find the equation of motion of a ball with radius $1$ as it rolls along the concave side of the parabola $y=x^2$. Point $P$ is the center of the ball whose path of motion is the curve $y=f(x)$.","['conic-sections', 'curves', 'calculus']"
2754229,Cumulative sum over random numbers gives interesting results,"Recently, I encountered an interesting thing with numbers. I couldn't find a satisfactory explanation hence, I decided to post it here. So, basically say we generate 5 random numbers with mean = 0 and standard deviation = 1 and take a cumulative sum over it and take the index which gives us the max value. To explain this with an example : 5 random numbers with mean = 0 and sd = 1 1.8871962   -2.0479581   -0.7508212   -1.2745548    -0.7129499 Take cumulative sum over it which gives us 1.8871962   -0.1607619    -0.9115832     -2.1861380   -2.8990878 and now we take the index of the highest value which is : 1 in this case. Now I repeat this procedure for million observation and check what is the ratio of each index to occur and it gives me  this ratio : 1 -   0.273311
2 -   0.156218 
3 -   0.140228 
4 -   0.156293 
5 -   0.273950 I ran this simulation multiple times and this ratio stays more or less same. I find this weird. I expected the ratio to be more or less the same for all the indices. If you also observe the 1st and 5th index have same ratio, 2nd and 4th have same ratio. Instead of taking 5 random variables, I changed it to 10 and it changed the ratio numbers but it still holds the symmetry where 1st and 10th index have the highest value and are same, 2nd and 9th are second highest and same and so on. Do you know what is going on there? I don't know what this phenomenon is called so couldn't find appropriate words to google it as well. This is a reproducible R script with results, if that is of any help. generate_random_numbers <- function() {
   num = numeric()
   for (i in seq(1000000)) {
     vec = rnorm(5)
     num[i] = which.max(cumsum(vec))
 }
 table(num)/length(num)
}

generate_random_numbers()
#num
#       1        2        3        4        5 
#0.272608 0.156398 0.140701 0.156537 0.273756 

generate_random_numbers()
#num
#       1        2        3        4        5 
#0.273287 0.156035 0.140446 0.156400 0.273832","['linear-algebra', 'normal-distribution']"
2754234,Does a curve's genus depend on its base field?,"Let $C$ be a projective plane curve, defined by a polynomial in $Z[x,y]$, over a field $K$.  Does the geometric genus of $C$ depend on the choice of $K$? I think the answer to this question is obviously 'yes', since the genus can change when you reduce modulo a prime (i.e, change the base field from $Q$ to $F_p$), i.e. ""bad reduction"". I guess my real question is: can the genus change when I change the base field from from $Q$ to $\bar{Q}$ (algebraic closure of $Q$)? My first answer is still 'yes', because the genus-degree formula tells us that we can write the genus as $\frac{(d-1)(d-2)}{2} - \sum \delta_P$, where $\delta_P$ is the delta invariant at a singular point $P$, so I'm thinking that changing my base field from $Q$ to $\bar{Q}$ might introduce some new singularities. On the other hand, it might be possible that all of the singularities over $\bar{Q}$ are already present over $Q$. Anybody know for sure?","['algebraic-curves', 'algebraic-geometry']"
2754278,Binomial formula for matrices,"I have two matrices $A$ and $B$ that do not commute, i.e., $A B \neq B A$ . Thus, if I apply the binomial formula, I get $$ (A+B)^{n} \neq (B+A)^{n}$$ This is my own deduction. I haven't found any theorem about this property. Do you know if there exists one?","['matrices', 'binomial-theorem', 'linear-algebra']"
2754292,Finding the closed support of a probability measure,"Let $\mu$ be a probability measure on $(\mathbb R,\mathcal B)$ where $\mathcal B$ is the Borel $\sigma$-algebra on $\mathbb R$. Show that there is a unique closed set $C\subset \mathbb R$ such that $\mu(C)=1$ and for any closed set $D\subset C$, we would have $\mu(D)<1$. My attempt is as follows. Consider $C:=\cap\{A\subset\mathbb R|A\text{ closed},\mu(A)=1\}$. The intersection is non-empty since $\mathbb R$ is closed and $\mu(\mathbb R)=1$. Then $C$ being an arbitrary intersection of closed sets, is closed. Suppose $D\subset C$ is any closed set then if $\mu(D)=1$ then $C\subset D$ and thus $C=D$. How does one show that $\mu(C)=1$?",['measure-theory']
2754300,Proving an inequality based on the sum of uniform random variables.,"Let we have $X_{1},.....,X_{100}$ be iid random variable from $U(-0.5,0.5)$. Then, prove using the chebychev inequality $P(T^2\geq25)\leq\frac{1}{3}$ Where $T = X_{1}+....+X_{100}$ My approach The inequality can be written as: $1-P(T^2\leq25)\leq\frac{1}{3}$ implies that
$P(T^2\leq25)\geq\frac{2}{3}$
$P(-5\leq T\leq 5)\geq \frac{2}{3}$ I can make the T as sum of Uniform random variable with parameters $U(0,1)$. After that, we can use Irwin hall distribution of sum of iid $U(0,1)$ random variables. After adjusting terms, $P(-5-50\leq T-50\leq 5-50)\geq \frac{2}{3}$
$P(-55\leq T-50\leq -45)\geq \frac{2}{3}$ $T-50$ will be sum of 100 $U(0,1)$ iid random variables with mean $50$ and variance $\frac{100}{12}$. But now, chebychev inequality doesn't seems to be applicable. From here, I am not able to proceed. Any help?","['statistics', 'distribution-theory', 'probability-distributions']"
2754301,Minimization of functional using Euler-Lagrange,"We've recently started doing Calculus of Variations in my analysis class and we're applying it to minimizing/maximizing functions. So the way we generally were taught to tackle the problem is to first find the Euler-Lagrange equation, solve the differential equation, then check concavity/convexity to ensure uniqueness. I'm having some trouble on the following question: (note: y with the circle thing on top means y') Problem 4. Solve the minimization problem
  $$
\min \int_1^2 \left(y^2 + 2t\dot y y + 4 t^2 {\dot y}^2\right) dt , \; y(1) = 3, \; y(2)=2
$$ My attempt: I can't find where I'm going wrong because I'm ending up with a differential equation whose solutions (when I solve the characteristic equations) don't involve t at all, which is problematic. Any help at all would be great! :)","['euler-lagrange-equation', 'calculus-of-variations', 'ordinary-differential-equations', 'optimization']"
2754312,Is there a convex function tending to $\infty$ and bounded above by $(\log x)^2$?,"I know that there is no convex function $f$ on $(1,\infty)$ such that $f(x) \rightarrow \infty $ as $x \rightarrow \infty$ and at the same time $f(x)<\log x$ for all $x \in (1,\infty)$ because convex function is a supremum of some affine functions.
What I am wondering is: Can we extend this result to powers of logarithms? In particular, is there a convex function $g$ on $(1,\infty)$ such that $g(x) \rightarrow \infty$ as $x \rightarrow \infty$ and $g<\log ^2 $? Any hint would be really appreciated! Thanks and regards.","['real-analysis', 'limits', 'logarithms', 'asymptotics', 'convex-analysis']"
2754332,An implication concerning $\operatorname{range}T\cap\operatorname{null}T = \{0\}$,"Is the following argument correct? Proposition . Given a finite-dimensional vector space $V$ and a linear map $T:V\to V$ such that $\operatorname{rank}(T^2) = \operatorname{rank}(T)$ prove that $\operatorname{range}T\cap\operatorname{null}T = \{0\}$. Proof. Assume that there exists at least one non-zero vector $v\in\operatorname{range}T\cap\operatorname{null}T$ and let $U$ be the linear map formed by restricting the domain of $T$ to $\operatorname{range}T$ then the rank-nullity theorem implies 
$$\dim\operatorname{range}T = \dim\operatorname{null}U+\dim\operatorname{range}U = \dim \operatorname{null}U+\dim\operatorname{range}T^2$$
Now since $\operatorname{range}T\cap\operatorname{null}T\subseteq\operatorname{null}U$ it follows that $v\in\operatorname{null}U$ and thus $\dim\operatorname{null}U\ge1$ consequently $\dim\operatorname{range}T^2<\dim\operatorname{range}T$. $\blacksquare$","['linear-algebra', 'proof-verification', 'linear-transformations']"
2754342,Two cars start at the same time from the junction of two roads one on each road with the uniform speed of $v m/sec$.,"Two cars start at the same time from the junction of two roads one on each road with the uniform speed of $v m/sec$. If the roads are inclined at $120°$, show that the distance between them increases at the rate of $\sqrt {3}v m/s$ My Approach: Given:
$\dfrac {dx}{dt}=v m/s$ and $\dfrac {dy}{dt}=v m/s$ Using cosine law,
$$s^2=x^2+y^2-2xy\cos (120°)$$
$$s^2=x^2+y^2+xy$$
differentiating both sides w.r.t $t$
$$2s.\dfrac {ds}{dt}=2x.\dfrac {dx}{dt}+2y.\dfrac {dy}{dt}+x.\dfrac {dy}{dt}+y.\dfrac {dx}{dt}$$
$$2s\dfrac {ds}{dt}=3xv+3yv$$
$$2s.\dfrac {ds}{dt}=3v(x+y)$$ How do I proceed further?","['derivatives', 'calculus']"
2754347,Why is $(4x)' \neq 1$? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question My book says that $\left(x^r\right)'=rx^{r-1}$ so $\left(4x\right)'=1\cdot 4^{1-1}=4^{0}$, but $a^{0}=1$?",['derivatives']
2754366,geometric interpretation of element-wise vector multiplication,"Geometrically speaking, vector dot product is interpreted as a projection of one vector on the other, while vector cross product gives another vector that is orthogonal to the multiplied vectors(right?). I am wondering if element-wise vector multiplication has any geometric intuition. I am not a mathematician, so I would appreciate a lay-person friendly explanation.","['linear-algebra', 'algebraic-geometry']"
2754370,Is a number divided by $0$ an improper fraction?,"Improper fraction is a fraction with numerator greater or equal than the denominator. But what about $0$ denominator? For example, are the following fractions improper? $$ \frac{0}{0},\frac{2}{0},\frac{5}{0}$$","['number-theory', 'fractions']"
2754372,Why A.M.$\geq $ G.M. not works here. Find the minimum value of $f(x)= x^2+4x+(4/x)+(1/x^2)$ for $x>0$,The minimum value of given function $f(x)= x^2+4x+(4/x)+(1/x^2)$ where $x>0$ (A) 9.5 (B) 10 (C) 15 (D) 20 My try By A.M G.M inequality $\frac {x^2+4x+(4/x)+(1/x^2)}{4} \geq \left(x^2.4x. \frac {4}{x}. \frac{1}{x^2}\right)^\frac{1}{4} $ thus minimum value of $f(x)=8$ But by calculus approach the answer is 10. I am unable to find my mistake where am i doing wrong in A.M. G.M. inequality,"['maxima-minima', 'a.m.-g.m.-inequality', 'functions']"
2754383,Range of $k$ for which equation has positive roots,"Range of $k$ for which both the roots of the equation $(k-2)x^2+(2k-8)x+3k-17=0$ are positive. Try: if $\alpha,\beta>0$ be the roots of the equation. Then $$\alpha+\beta=\frac{8-2k}{k-2}>0\Rightarrow k\in(2,4)$$ And $$\frac{3k-17}{k-2}>0\Rightarrow k\in(-\infty,2)\cup \bigg(\frac{17}{3},\infty\bigg)$$ I have got $k=\phi$. I did not understand where i am wrong , please explain, Thanks",['algebra-precalculus']
2754405,how to define the divergence operator of a matrix?,"This question related to my previous question here For vector-valued function $u(x_1,x_2)=(u_1(x_1,x_2),u_2(x_1,x_2))$ we represents  the symmetric gradient $\mathcal E$ as follows
$$
\mathcal E(u)=
\begin{bmatrix}
\partial_1 u_1 & \frac12(\partial_2 u_1+\partial_1 u_2)\\
\frac12(\partial_2 u_1+\partial_1 u_2) & \partial_2 u_2
\end{bmatrix}
$$ my question: how to define the divergence of $\mathcal E(u)$? should $div(\mathcal E(u))$ be a 2 by 2 matrix or a 2 by 1 vector?","['multivariable-calculus', 'tensors', 'linear-algebra', 'vectors']"
2754409,Derivative of squared Frobenius norm of linear combination of rank-$1$ matrices with respect to their weights,"Let $${\bf A} := \sum_{i=1}^K w_i {\bf x}_i {\bf x}_i^\top$$ where $\{w_i\}_{i=1}^K$ are scalars, and ${\bf x}_i \in \mathbb{R}^d$. Let ${\bf w} := [w_1 \cdots w_K]^\top \in \mathbb{R}^K$. What is the derivative of the squared Frobenius norm $\|{\bf A}\|_\mathsf{F}^2$ with respect to ${\bf w}$?","['derivatives', 'matrices', 'matrix-calculus', 'multivariable-calculus', 'linear-algebra']"
2754426,"How to draw a simple graph with given vertices, edges and number of cycles?","The question in my assignment is “Draw a simple graph with $6$ vertices, and $8$ edges that contains exactly one cycle of length $4$ and two cycles of length $3$.” I can draw a simple graph with $6$ vertices and $8$ edges but it doesn’t contain exactly one $4$-cycle and two $3$-cycles, sometimes there is one $5$-cycle in the graph as well. Any ideas how can I construct a simple graph as the requirement said?
Thank you. Update So I attempted to draw a graph as presented below From what I noticed
A>B>F>E>A is a 4-cycle.
A>D>E>A and B>C>F>B are 3-cycles.
However, in the graph, A>B>C>F>E>A is a cycle of length 5 
and A>B>C>F>E>D>A is a cycle of length 6.
So, there are other cycles in the graph with cycle lengths are more than 3 and 4.
Am I understanding this in the correct concept or not?","['graph-theory', 'discrete-mathematics']"
2754428,Elementary doubt about differentiability of a two variables function,"Given the function
$$
g(x,y) = \begin{cases} \frac{xy^3}{2x^4+y^4}, \,\,\, \text{if}\,\, (x,y)\neq(0,0)\,\\
 0, \,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \text{else}
         \end{cases}
$$
check whether $g$ is continuous and differentiable at $(0,0)$ or not. Considering the two restrictions $y  = \pm x$, it is seen $g$ is not continuous at $(0,0)$. How about differentiability? Is it related to continuity? The two partial derivatives are both $0$ at $(0,0)$. Still I'm not sure $g$ is differentiable at $0$, since I should consider any directional derivative. Thanks for your patience and help.","['multivariable-calculus', 'limits']"
2754430,Showing $(a^{k_n})\to a^k$ whenever $(k_n)\to k$.,"If the sequence $(k_n)\to k$, is it possible to show $(a^{k_n})\to a^k$ without having to involve the theory of limits of functions. i.e., to show that $\forall\varepsilon > 0, \exists K\in\mathbb{N}$ s.t $\forall n\ge K$ we have $\mid a^{k_n}-a^k\mid < \varepsilon.$ Rudin uses this result in one of the examples in a chapter which comes before  concept of limits of functions.","['real-analysis', 'sequences-and-series', 'analysis']"
2754431,Finding probability for general cases,"For a student to qualify, he must pass at least two out of three exams. The probability that he will pass the 1st exam is $p$. If he fails in one of the exams then the probability of passing in the next exam is $p/2$ otherwise it remains the same. Find the probability that he will qualify.
My textbook answer reads  $2p^2 – p^3$.
This is possible if only the below cases are considered: He passes first and second exam. He passes first, fails in second but passes third exam. He fails in first, passes second and third exam. But I think this is wrong since at least two out of three exams means,passing in first, second  and third exam is inclusive.  Someone please solve this paradox.",['probability']
2754434,Arithmetic Sequence Problem I Can't Figure it Out,"$$\frac{1}{\sqrt a_1 + \sqrt a_2} + \frac{1}{\sqrt a_2 + \sqrt a_3} + \cdots + \frac{1}{\sqrt a_{n-1} + \sqrt a_n} = \frac{n-1}{\sqrt a_1 + \sqrt a_n}$$ I need to prove this; I don't know how to get from left side terms to the right side term? What should I do to figure this out? Please answer with detail as much as possible, thanks!",['algebra-precalculus']
2754437,Statistics: Hypothesis Testing,"Hypothesis Testing I have 4 groups of data for four different locations i.e. A, B, C and D (close to each other). In each group, there are 3 columns of data (x, y, z) showing the temperature at the location taken by thermometer at a different height i.e. 50, 100, 150 cm above ground at that location. How would I use Excel to write some hypotheses to investigate what differences there may be between the temperature measurements at the different locations and heights? I am thinking about descriptive statistics / T-testing.",['statistics']
2754457,Numerically stable simplification of sinc function,"I would like to know if there is an alternate, explicit (non-iterative) form of the sinc function which behaves in a numerically stable way for all real numbers. The definition I am aware of is: $$\texttt{sinc}(a) = \dfrac{\sin(a)}{a}$$ However, although this function is well-defined everywhere (even at 0) , this function presents problems when implemented in code and evaluated at 0. I would like to know if there is an alternate form involving simple functions which would avoid possible division by 0 when we try to implement this is code. Some programming packages (like numpy in python) provide a sinc function, presumably to sidestep this issue. But I would like to know generally if there is a better way of implementing it in an arbitrary language without resorting to some if statement. For instance, numpy simply checks if a=0 . If it is, then it replaces a with some small value $\neq 0$. Specifically: def sinc(x):
    y = pi * where(x == 0, 1.0e-20, x)
    return sin(y)/y EDIT As Sangchul Lee points out, you could consider the series form, but that representation will break down for large $a$. So the series form is essentially pushing the problem somewhere else (from a numerical point of view). Furthermore, you might consider switching between the two forms depending on whether $a$ is small, but that is introducing its own if statement, and I would like to avoid a piecewise solution. Note: I have no idea what tags to use here. So please update the tags to what you view as appropriate.","['real-analysis', 'geometry']"
2754504,Fibers and total spaces of vector bundles from sheaf theoretic approach.,"I am interested in sheaf theory and am slowly working towards familiarizing myself with it. This question is to further this understanding. Let $\pi:E\rightarrow M$ be a finite-rank real vector bundle over the smooth real manifold $M$. Let $$ \Gamma_E:U\in\tau_M\mapsto\Gamma(E|_U) $$denote the sheaf of smooth sections of $E$, and $\mathcal F_M:U\mapsto C^\infty(U)$ the sheaf of smooth functions. As far as I am aware most (or is it all?) information about the vector bundle is contained within $\Gamma_E$. Moreover, reading the wikipedia section about Étalé spaces and stalks , I get the impression that constructing the Étalé space from the stalks is very similar to constructing the total space of a fiber bundle from its fibers. However, the stalk of the sheaf $\Gamma_E$ at $p\in M$ is not $E_p$ but instead the germ of smooth sections of $E$ at $p$. The germs clearly contain more information, as they also contain information about the bundle on all infinitesimal neighborhoods of $p$, while the fibers only contain information about the bundle at $p$. So the questions are: Is there any sheaf-theoretic way to construct the fiber spaces $E_p$ from the sheaf $\Gamma_E$? How is the étalé space of $\Gamma_E$ related to the total space $E$ of the vector bundle?","['vector-bundles', 'sheaf-theory', 'differential-geometry', 'algebraic-geometry']"
2754545,Proving area under curve,"Hey guys I've been stuck on this problem for a while and I've still got no headway into how I'm supposed to do this. Any tips or guiding points would be helpful. Let $f$ be a differentiable function such that $f′$ is continuous on $[0,1]$, and $M$ the maximum value of $|f′(x)|$ on $[0,1]$. Prove that if $f(0) = f(1) = 0$, then $$\int_0^1 |f(x)| dx\leq\frac{M}{4}$$ I've come to a conclusion via Rolle's theorem that there exists a c between 0 and 1 where f'(c) = 0 and that would be a local extrema. But nothing past that other than the fact that the max value of M is 1.","['derivatives', 'real-analysis', 'calculus']"
2754546,Find $\lim\limits_{n\to \infty}x_{n}$ if for all $n\ge 1$ $\{x_n\}$denotes a sequence of real numbers where $x_{n+1}=\frac{1}{2}(x_n+\frac{5}{x_n})$,"Also given Let x be a positive number. $x_{1}=\dfrac{1}{2}(x+\dfrac{5}{x})$ , $x_{2}=\dfrac{1}{2}(x_1+\dfrac{5}{x_1})$ I have shown that for all $n\ge 1$ , $\dfrac{x_n-\sqrt{5}}{x_n+\sqrt{5}}={\bigg(\dfrac{x-\sqrt{5}}{x+\sqrt{5}}}\bigg)^{2^{n}}$ But from here I get $x_n=\dfrac{\sqrt{5}\cdot 2 \cdot \bigg({\bigg(\dfrac{x-\sqrt{5}}{x+\sqrt{5}}}\bigg)^{2^{n}}+1\bigg)}{1-{\bigg(\dfrac{x-\sqrt{5}}{x+\sqrt{5}}}\bigg)^{2^{n}}}$ But from here how do I get $lim_{n\to \infty}x_{n}$ L'Hospital does not help me here as I think. It is a GREAT GRAND SHAME ON MYSELF that I could not think of the problem in a simpler way. I should edit this: We know $x_{n}=\dfrac{1}{2}(x_{n-1}+\dfrac{5}{x_{n-1}})$ $\implies \dfrac{1}{2}(x_{n-1}+\dfrac{5}{x_{n-1}})\ge \bigg(x_{n-1}\cdot \dfrac{5}{x_{n-1}} \bigg)^{1/2}$ [By the A.M-G.M inequality] $\implies x_n \ge \sqrt{5}$ Thus $\lim\limits_{n\to \infty}x_{n}= \sqrt{5}$ Done!!I should die right now!!","['recursion', 'sequences-and-series', 'limits']"
2754604,Prove that $\overline{A\setminus B} \cap \left(\overline{A}\cup\overline{B}\right)=\overline{A}$,"Prove that $$\overline{A\setminus  B} \cap \left(\overline{A}\cup\overline{B}\right)=\overline{A}$$ My attempts: Let $x\in \overline{A\setminus  B} \cap \left(\overline{A}\cup\overline{B}\right)$ . Then $x\in \overline{A\setminus  B}$ and $x\in\overline{A}\cup\overline{B}$ . Then $x\in \overline{A}\cup B$ and $x\in\overline{A}\cup\overline{B}$ . Then $x\in\overline{A}\cup B\cup\overline{B} $ Then $x\in\overline{A}$ .
Hence, $$\overline{A\setminus  B} \cap \left(\overline{A}\cup\overline{B}\right)\subset \overline{A}$$ Is it correct? I need help to prove that $$\overline{A}\subset \overline{A\setminus  B} \cap \left(\overline{A}\cup\overline{B}\right)$$",['elementary-set-theory']
2754631,Extraneous and Missing Solution Confusion,"I came to a question in James Stewart's ""Calculus Early Transcendentals"" about implicit differentiation saying that: Find all points on the curve $x^2y^2+xy=2$ where the slope of the tangent line is $-1$ After implicit differentiation I came to $$y'x(2xy+1)+y(2xy+1)=0\tag{1}$$
$$(2xy+1)(y'x+y)=0$$
Then $xy=\frac{-1}{2}$ or $y'=\frac{-y}{x}$ But by pluging $xy=\frac{-1}{2}$ into the original equations we get $$x^2y^2+xy=\frac{1}{4}-\frac{1}{2}\ne2$$
So, we conclude that $xy=\frac{-1}{2}$ is an extraneous solution . Then what caused it to be so ?? Q1 Also, we could start from equation $(1)$ to reach that
$$y'=\frac{-y(2xy+1)}{x(2xy+1)} \tag{2}$$
We need the tangent to be $-1$. So we equate $y'=-1$
$$\frac{y(2xy+1)}{x(2xy+1)}=1$$
We now multiply by $x(2xy+1)$ to get $$y(2xy+1)=x(2xy+1)$$
I am now afraid to divide by $2xy+1$ in order not to get a missing solution .
[Is it wise not to divide ?? Q2 When to remove the common factor of the numerator and denominator and not afraid of missing solutions ?? Q3 ] So, I subtracted RHS-LHS to get
$$y(2xy+1)-x(2xy+1)=0$$
Factorizing by grouping
$$(y-x)(2xy+1)=0$$ Now we reached our result $y=x$. Sadly along with the extraneous solution . Is multiplying by the denominator of the rational equation $(2)$ is the cause of the second appearance of the extraneous solution ?? Q4","['algebra-precalculus', 'implicit-differentiation', 'calculus']"
2754649,"Show that random variables $X$ and $Y$ are not independent, but nevertheless Cov$[X,Y] = 0$","Let $Z$ be a random uniformly distributed variable on $[0,1]$. Show that the random variables $X = \sin 2\pi Z$ and $Y = \cos 2\pi Z$ are not independent, but nevertheless Cov$[X,Y]=0$. This is a homework assignment, but I'm a bit stuck. My thoughts We can see that $X$ and $Y$ are not independent, since both depend on $Z$. If we want to show this explicitly, then we need to show that $$f_{X,Y}(a,b) \neq f_X(a)\;f_Y(b),$$
where $f_{X,Y}(a,b)$ is the joint probability distribution function.
But how can I find the (joint) probability distribution function(s) $f_X, f_Y$ and $f_{X,Y}$? If I can find these functions, I can also solve the covariance problem. Is this the right way? Or is there a 'better' way to solve this problem?","['independence', 'probability', 'correlation', 'random-variables']"
2754659,Strong law of large numbers for function of random vector: can we apply it for a component only?,"Consider i.i.d. random variables $\{X_1,..., X_n\}$ with well defined first moment i.i.d. random variables $\{Y_1,..., Y_n\}$ with well defined first moment By the strong law of large numbers: 
$$
\frac{1}{n}\sum_{i=1}^n Y_i \rightarrow_{a.s.} E(Y_i) \text{ }\text{ as $n\rightarrow \infty$}
$$ Consider these three objects for any function $g: \mathbb{R}^2\rightarrow \mathbb{R}$ (take $Y_i$ discrete with support $\mathcal{Y}$ for simplicity) 1) for a given realisation $x$ of $X_k$,  $E(g(X_k, Y_i)| X_k=x)\equiv \sum_{y\in \mathcal{Y}} g(x, y)P(Y_i=y|X_k=x)$ which is a scalar 2) $E(g(X_k, Y_i)| X_k)\equiv \sum_{y\in \mathcal{Y}} g(X_k, y)P(Y_i=y|X_k)$ which is a random variable because $g(X_k,y)$ and $P(Y_i=y|X_k)$ are both functions of the random variable  $X_k$ 3) $F(X_k)\equiv\sum_{y\in \mathcal{Y}}g(X_k, y)\mathbb{P}(Y_i=y)$ which is a random variable because $g(X_k, y)$ is a function of $X_k$. When $X_k\perp Y_i$, then $(2)=(3)$. Question : 1) Is it true that $\forall k=1,...,n$
$$
\frac{1}{n}\sum_{i=1}^n g(X_k, Y_i) \rightarrow_{a.s.} F(X_k) \text{ }\text{ as $n\rightarrow \infty$}
$$
If yes, under which conditions? 2) Is it true that $\forall k=1,...,n$
$$
\frac{1}{n}\sum_{i=1}^n g(X_k, Y_i) \rightarrow_{a.s.} E(g(X_k, Y_i)|X_k) \text{ }\text{ as $n\rightarrow \infty$}
$$
If yes, under which conditions? EDIT : This question here is close to mine and includes also an answer. However it is for $g(X_k, Y_i)=Y_i\times X_k$","['law-of-large-numbers', 'expectation', 'probability']"
2754707,Question on speed.,"Speed of a bus is 45 km/h. If it stops for a few minutes in an hour
  then its average speed becomes 42 km/h. Find out the time duration it
  stops for in an hour. My attempt: Let Distance be D. Let the time duration for which it halts be x. $45=\frac{D}{1}$ $42=\frac{D}{1+x}$ Therefore, $45=42+42x$ $x=4\frac{2}{7} minuites$ What have I done wrong?",['algebra-precalculus']
2754758,Example of an invertible ideal which contains a zero divisor as one of its generators,"Let $R$ be a ring and let $I$ be an (integral) invertible ideal of $R$. Let $J = \{a_1,\ldots,a_r\}$ be a minimal ideal generating set of $I$ in the sense that any proper subset of $J$ will not generate $I$. I was wondering if it was possible that one of the $a_i$ was a zero divisor of $R$. Clearly, any invertible ideal does indeed contain at least one regular element and hence any principal invertible ideal won't provide such an example. Thanks a lot in advance!","['abstract-algebra', 'algebraic-geometry', 'commutative-algebra']"
2754796,Is the topological closure of a transitive relation itself transitive?,"Let $X$ be a topological space, and $R\subseteq X\times X$ a relation on $X$. 
Denote by $\bar{R}$ the topological closure of $R$. Suppose that $R$ is transitive. Then is $\bar R$ transitive? Can one prove similar statements with equivalence and order relations? Any reference would also be welcome.","['descriptive-set-theory', 'general-topology', 'relations']"
2754799,"Find the ""average"" discrete distribution for some summary statistics?","The new law requires companies to make summary statistics of salaries publicly available: Mean Standard deviation First quartile Median Third quartile For $n$ people working at a company the true values of wages is a list of $n$ elements that has exactly this summary statistics. However, the number of possible lists is obviously finite! Let's take this finite number of lists and order their elements. It is now possible to calculate the average of each $k$ -th ( $1 \le k \le n$ ) element. I think the list of average elements would be a very reasonable reconstruction of possible wages (I called it an ""average"" discrete distribution in the title). How should I approach this problem? Could you suggest some references?
Also, maybe there are more ways to reconstruct the sensible values easily? Edit: after more than a year, I'm still thinking about this problem.","['descriptive-statistics', 'statistics', 'average', 'probability-distributions']"
2754804,"Why is $\alpha(t)=(t^3,t^2)$ not an immersion?","$$\alpha: \mathbb{R}\to\mathbb{R}^2\quad \alpha(t)=(t^3,t^2)$$
The condition for an immersion is that $\alpha'(t)=(3t^2,2t)$ is injective for all $t\in\mathbb{R}$. The book seems to imply that there is a problem at $t=0$ but I don't understand why. At $t=0$ the tangent is undefined because if you take the limit from both sides you get opposite results. However that does not make $\alpha'$ non-injective. What am I missing?","['differential-topology', 'geometry', 'manifolds', 'general-topology', 'differential-geometry']"
2754833,Where is the step that caused the extraneous solution?,"$$x^{1/3}+x^{1/6}-2=0\iff (x^{1/6}-1)(x^{1/6}+2)=0$$
$\iff x^{1/6}=1$ or $x^{1/6}=-2$ $\implies x=1^6=1$ or $x=(-2)^6=64$ By checking when $x=64$:$\sqrt[3]{64}+\sqrt[6]{64}-2=4+2-2=4\ne0$ Which step caused the extraneous solution $x=64$ to appear",['algebra-precalculus']
2754853,Spivak Chapter 13 Problem 34 Proof $\lim_{x \to \infty} 1/x \int_{0}^{x}f(t) dt =a $,"The problem says: Suppose f is continuous and $\lim_{x \to \infty} f(x)=a$ . Prove that: $$\lim_{x \to \infty} \dfrac{1}{x} \int_{0}^{x}{f(t) dt}=a.$$ Indication: The condition $\lim_{x \to \infty} f(x)=a$ implies that $f(t)$ is close to $a$ for some $ t\geq N$ for some N. This means that $\int_{N}^{N+M} f(t) dt$ is close to $Ma$ . If $M$ is large in comparison to $N$ , then $Ma/(M+N)$ is close to $a$ I found a solution but it is very different compared to mine. Here is what I did:
Let $x= M+N$ , where $N$ is a constant. So the limit becomes $$\lim_{M \to \infty} \dfrac{1}{N+M} \int_{0}^{N+M}f(t)~ dt $$ The integral can be split as follows: $$\int_{0}^{N+M}f(t)~ dt=\int_{0}^{N}f(t)~ dt +\int_{N}^{N+M}f(t)~ dt  $$ We can go back to the limit: $$\lim_{M \to \infty} \dfrac{1}{N+M} \left[ \int_{0}^{N}f(t)~ dt +\int_{N}^{N+M}f(t)~ dt  \right] $$ As N is a constant, the integral $ \int_{0}^{N}f(t)~ dt$ is also a constant. Then: $$\lim_{M \to \infty} \dfrac{1}{N+M} \int_{0}^{N}f(t)~ dt = 0 $$ So our main limit is now: $$\lim_{x \to \infty} \dfrac{1}{x} \int_{0}^{x}{f(t) dt}=\lim_{M \to \infty} \dfrac{1}{N+M} \int_{N}^{N+M}f(t)~ dt$$ Then, it follows form the indications that: $$\lim_{x \to \infty} \dfrac{1}{x} \int_{0}^{x}{f(t) dt}=\lim_{M \to \infty} \dfrac{1}{N+M} \int_{N}^{N+M}f(t)~ dt = a$$ I would like to know if this is a valid approach. Especially if it is valid to change the limit with $x=N+M$ ;  and if it is right to cancel the integral from $0$ to $N$ , as $N$ is a constant.","['real-analysis', 'integration', 'calculus', 'proof-verification']"
2754868,"How do I solve $\frac{1}{2\pi}\int_{-\infty}^\infty \frac{e^{i(t-t')u}\,du}{-u^2 + \omega^2 -i\epsilon}$ to find Green's function?","I want to find the Green's function defined by the following equation: $$\left(\frac{d^2}{dt^2} + \omega^2 - i\epsilon \right)G(t,t') = \delta(t-t').$$ For this I performed the Fourier transform of both sides, using identities for the Fourier transform of a second derivative to get the algebraic equation: $$\left(-u^2 + \omega^2 -i\epsilon \right) \tilde{G}(u,t') = \frac{1}{\sqrt{2\pi}} e^{-it'u}.$$ We can solve this algebraically and perform the inverse Fourier transform: \begin{align}
G(t,t') &= \frac{1}{\sqrt{2\pi}} \int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}} \frac{e^{-it'u}}{-u^2 + \omega^2 -i\epsilon} \: e^{itu}\,du \\
&=  \frac{1}{2\pi}\int_{-\infty}^\infty \frac{e^{i(t-t')u}\,du}{-u^2 + \omega^2 -i\epsilon}
\end{align} I can solve this by identifying the poles and using the residue theorem, but it's not clear to me how to do this. Can someone explain? How do I identify the poles and what contour should I choose to get the result?","['complex-analysis', 'integration', 'greens-function']"
2754877,f-related vector field,"Here is the question: Let $M$ and $N$ be manifolds and let $f:M\rightarrow N$ be a smooth map. A vector field $X$ on $M$ and a vector field $Y$ on $N$ are said to be $f$ -related if $$df_p(X_p)=Y_{f(p)},\forall p\in M.$$ This means that for every function $$h:N\rightarrow R$$ $$X_p[h\circ f]=Y_{f(p)} h.$$ Suppose that $X$ is $f$ -related to $Z$ and $Y$ is $f$ -related to $W$ . Show that $[X,Y]$ is $f$ -related to $[Z,W]$ . I know I have to prove that $$df_p([x,y])=[df_p(x),df_p(y)]_{f(p)}$$ But that I can not figure out this calculation.","['manifolds', 'differential-geometry']"
2754902,Differential equation of first order,I have this simple differential equation: $y'=(\tan x)y.$ after integrating $\frac{y'}{y(x)}= \tan x$ i came up with $\log y(x)=-\log \cos(x)+1.$ now my question is this one:  why $ e^{-\log \cos(x)}=\sec(x)?$ thank you for your time,"['exponential-function', 'ordinary-differential-equations']"
2754995,"GEB: How to write ""b is a MIU-number"" in TNT notation","( NB: This question requires access to, and familiarity with, the book Gödel, Escher, Bach , by Douglas Hofstadter.  Unfortunately, I am not able to make the question entirely self-contained.  In any case, for a description of the MIU system, see here , and for one of TNT, see here .) This question refers to p. 263 of the latest American edition of Gödel, Escher, Bach . In that page, Hofstadter writes (my emphasis): ...I pointed out in Chapter VIII that even such a simple arithmetical predicate as "" b is a power of 10"" is very tricky to code into TNT-notation—and the predicate "" b is a MIU-number"" is a lot more complicated than that! Still it can be found , ... I emphasized the last sentence above because, in my opinion, the book's entire rendition of Gödel's proof (arguably its centerpiece) rests squarely on it .  If that assertion must be taken on faith, then the book's entire proof must be taken on faith. It's terribly disappointing that in a book of this size, one that makes such demands of its readers, and one that is filled with massive illustrations (such as the full sequence of a viral genome, on p. 176), the author chose not to provide explicitly such a crucial exhibit in the argument.  Yes, I know that the resulting TNT string would be huge (even before substituting SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS0 for every occurrence of b ), and basically incomprehensible (though I doubt it would be any more so than the genome alluded to earlier), but it is such an important bit of evidence that to have to take its existence on faith is, as I said, terribly disappointing. Therefore, as this question title says, I am looking for the translation of the predicate "" b is a MIU-number"" to TNT notation. I have searched online for this translation without success. As I already alluded to, I realize that the translation of this predicate to TNT notation could result in an enormous string, perhaps unmanageably so. In that case, the next best thing would be a scaffold written in a formal language L more expressive (hence more succinct) than TNT, but from which one could translate into TNT through a straightforward process of expansion (i.e. replacement of succinct L expressions by full-blown TNT expressions). For example, such a language L may include a symbol $\leq$ that could be translated to ""lax TNT"" by applying the following substitution:
$$a\leq b \to \exists c:(a+c)=b$$ ...or to ""austere TNT"": $$a\leq a^\prime \to \exists a^{\prime\prime}:(a+a^{\prime\prime})=a^\prime$$ Likewise, L could include a symbol $\lt$, that could be translated to TNT with the substitution: $$a \lt b \to \mathbf{S}a \le b \;,$$ or $$a \lt a^\prime \to \mathbf{S}a \le a^\prime\;.$$ The point here is that the LHSs above are considerably more succinct than the corresponding RHSs, and an expression containing the former can be translated ""mechanically"" to one consisting only of valid TNT symbols through relatively straightforward substitutions.  Therefore, L may be thought of as TNT augmented with a finite set of ""abbreviations"", like those exemplified by $\le$ and $\lt$ above. It's not hard to see that, with enough ""abbreviations"" of this sort, one may be able to translate the predicate "" b is a MIU-number"" to an L-string of manageable length, even if the corresponding TNT string is a couple of orders of magnitude larger. For what it's worth, I know that the predicate "" b is a MIU-number"" is equivalent to the following predicate: b is a number consisting of $3$ followed by $0$'s and $1$'s, where the number $n_1$ of $1$'s satisfies $n_1 \not \equiv 0 \pmod 3$. (See this answer by Eric Wofsey for a nice proof of this equivalence.) Therefore, to answer this question, it would suffice to translate this alternative, but equivalent, predicate to TNT notation. UPDATE Below are two versions of my rendition of "" b is a MIU-number"" (wrapped at 100-characters per line) using my interpretation of Y. Forman's answer. (The purpose of these print outs is only to get a sense of the actual size and composition of these strings.  It's not meant to be illuminating in any other way.) The first version (length = 1,497, including two occurrences of b ) deviates from austere TNT notation in two ways: Instead of, e.g., SSSSSSSSSS0 , I write 10 . Instead of primes ( ' ), I use numerical suffixes to generate variable names; thus, instead of a''''''''' , I use a9 . ∃a0:∃a1:∃a2:<∃a6:<a0=((S(a1·S0)·a6)+31)∧∃a7:(S31+a7)=S(a1·S0)>∧<∃a8:<a0=((S(a1·Sa2)·a8)+b)∧∃a9:(Sb+a
9)=S(a1·Sa2)>∧∀a3:∀a4:∀a5:<<∃a10:(Sa3+a10)=a2∧<∃a11:<a0=((S(a1·Sa3)·a11)+a4)∧∃a12:(Sa4+a12)=S(a1·Sa3
)>∧∃a13:<a0=((S(a1·SSa3)·a13)+a5)∧∃a14:(Sa5+a14)=S(a1·SSa3)>>>⊃<∃a15:<a4=((10·a15)+1)∧a5=(10·a4)>∨<∃
a16:∃a17:∃a18:<a4=((3·a18)+a16)∧<∃a19:∃a20:<∃a23:<a19=((S(a20·S0)·a23)+S0)∧∃a24:(SS0+a24)=S(a20·S0)>
∧<∃a25:<a19=((S(a20·Sa17)·a25)+a18)∧∃a26:(Sa18+a26)=S(a20·Sa17)>∧∀a21:∀a22:<<∃a27:(Sa21+a27)=a17∧∃a2
8:<a19=((S(a20·Sa21)·a28)+a22)∧∃a29:(Sa22+a29)=S(a20·Sa21)>>⊃∃a30:<a19=((S(a20·SSa21)·a30)+(10·a22))
∧∃a31:(S(10·a22)+a31)=S(a20·SSa21)>>>>∧<∃a32:(Sa16+a32)=a18∧a5=((a18·a4)+a16)>>>∨<∃a33:∃a34:∃a35:∃a3
6:<a4=((a36·(1000·a35))+((111·a35)+a33))∧<∃a37:∃a38:<∃a41:<a37=((S(a38·S0)·a41)+S0)∧∃a42:(SS0+a42)=S
(a38·S0)>∧<∃a43:<a37=((S(a38·Sa34)·a43)+a35)∧∃a44:(Sa35+a44)=S(a38·Sa34)>∧∀a39:∀a40:<<∃a45:(Sa39+a45
)=a34∧∃a46:<a37=((S(a38·Sa39)·a46)+a40)∧∃a47:(Sa40+a47)=S(a38·Sa39)>>⊃∃a48:<a37=((S(a38·SSa39)·a48)+
(10·a40))∧∃a49:(S(10·a40)+a49)=S(a38·SSa39)>>>>∧<∃a50:(Sa33+a50)=a35∧a5=((a36·(10·a35))+a33)>>>∨∃a51
:∃a52:∃a53:∃a54:<a4=((a54·(100·a53))+a51)∧<∃a55:∃a56:<∃a59:<a55=((S(a56·S0)·a59)+S0)∧∃a60:(SS0+a60)=
S(a56·S0)>∧<∃a61:<a55=((S(a56·Sa52)·a61)+a53)∧∃a62:(Sa53+a62)=S(a56·Sa52)>∧∀a57:∀a58:<<∃a63:(Sa57+a6
3)=a52∧∃a64:<a55=((S(a56·Sa57)·a64)+a58)∧∃a65:(Sa58+a65)=S(a56·Sa57)>>⊃∃a66:<a55=((S(a56·SSa57)·a66)
+(10·a58))∧∃a67:(S(10·a58)+a67)=S(a56·SSa57)>>>>∧<∃a68:(Sa51+a68)=a53∧a5=((a54·a53)+a51)>>>>>>>>> The second version (length = 10,088, including two occurrences of b ) follows austere TNT notation. ∃a:∃a':∃a'':<∃a'''''':<a=((S(a'·S0)·a'''''')+SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS0)∧∃a''''''':(SSSSSSSSSS
SSSSSSSSSSSSSSSSSSSSSS0+a''''''')=S(a'·S0)>∧<∃a'''''''':<a=((S(a'·Sa'')·a'''''''')+b)∧∃a''''''''':(S
b+a''''''''')=S(a'·Sa'')>∧∀a''':∀a'''':∀a''''':<<∃a'''''''''':(Sa'''+a'''''''''')=a''∧<∃a'''''''''''
:<a=((S(a'·Sa''')·a''''''''''')+a'''')∧∃a'''''''''''':(Sa''''+a'''''''''''')=S(a'·Sa''')>∧∃a''''''''
''''':<a=((S(a'·SSa''')·a''''''''''''')+a''''')∧∃a'''''''''''''':(Sa'''''+a'''''''''''''')=S(a'·SSa'
'')>>>⊃<∃a''''''''''''''':<a''''=((SSSSSSSSSS0·a''''''''''''''')+S0)∧a'''''=(SSSSSSSSSS0·a'''')>∨<∃a
'''''''''''''''':∃a''''''''''''''''':∃a'''''''''''''''''':<a''''=((SSS0·a'''''''''''''''''')+a''''''
'''''''''')∧<∃a''''''''''''''''''':∃a'''''''''''''''''''':<∃a''''''''''''''''''''''':<a'''''''''''''
''''''=((S(a''''''''''''''''''''·S0)·a''''''''''''''''''''''')+S0)∧∃a'''''''''''''''''''''''':(SS0+a
'''''''''''''''''''''''')=S(a''''''''''''''''''''·S0)>∧<∃a''''''''''''''''''''''''':<a''''''''''''''
'''''=((S(a''''''''''''''''''''·Sa''''''''''''''''')·a''''''''''''''''''''''''')+a''''''''''''''''''
)∧∃a'''''''''''''''''''''''''':(Sa''''''''''''''''''+a'''''''''''''''''''''''''')=S(a'''''''''''''''
'''''·Sa''''''''''''''''')>∧∀a''''''''''''''''''''':∀a'''''''''''''''''''''':<<∃a'''''''''''''''''''
'''''''':(Sa'''''''''''''''''''''+a''''''''''''''''''''''''''')=a'''''''''''''''''∧∃a'''''''''''''''
''''''''''''':<a'''''''''''''''''''=((S(a''''''''''''''''''''·Sa''''''''''''''''''''')·a''''''''''''
'''''''''''''''')+a'''''''''''''''''''''')∧∃a''''''''''''''''''''''''''''':(Sa''''''''''''''''''''''
+a''''''''''''''''''''''''''''')=S(a''''''''''''''''''''·Sa''''''''''''''''''''')>>⊃∃a''''''''''''''
'''''''''''''''':<a'''''''''''''''''''=((S(a''''''''''''''''''''·SSa''''''''''''''''''''')·a''''''''
'''''''''''''''''''''')+(SSSSSSSSSS0·a''''''''''''''''''''''))∧∃a''''''''''''''''''''''''''''''':(S(
SSSSSSSSSS0·a'''''''''''''''''''''')+a''''''''''''''''''''''''''''''')=S(a''''''''''''''''''''·SSa''
''''''''''''''''''')>>>>∧<∃a'''''''''''''''''''''''''''''''':(Sa''''''''''''''''+a''''''''''''''''''
'''''''''''''')=a''''''''''''''''''∧a'''''=((a''''''''''''''''''·a'''')+a'''''''''''''''')>>>∨<∃a'''
'''''''''''''''''''''''''''''':∃a'''''''''''''''''''''''''''''''''':∃a''''''''''''''''''''''''''''''
''''':∃a'''''''''''''''''''''''''''''''''''':<a''''=((a''''''''''''''''''''''''''''''''''''·(SSSSSSS
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS0·a''''
'''''''''''''''''''''''''''''''))+((SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS0·a''''''''''''''''''''''''''''''''''')+a''''''''''''
'''''''''''''''''''''))∧<∃a''''''''''''''''''''''''''''''''''''':∃a'''''''''''''''''''''''''''''''''
''''':<∃a''''''''''''''''''''''''''''''''''''''''':<a'''''''''''''''''''''''''''''''''''''=((S(a''''
''''''''''''''''''''''''''''''''''·S0)·a''''''''''''''''''''''''''''''''''''''''')+S0)∧∃a'''''''''''
''''''''''''''''''''''''''''''':(SS0+a'''''''''''''''''''''''''''''''''''''''''')=S(a'''''''''''''''
'''''''''''''''''''''''·S0)>∧<∃a''''''''''''''''''''''''''''''''''''''''''':<a''''''''''''''''''''''
'''''''''''''''=((S(a''''''''''''''''''''''''''''''''''''''·Sa'''''''''''''''''''''''''''''''''')·a'
'''''''''''''''''''''''''''''''''''''''''')+a''''''''''''''''''''''''''''''''''')∧∃a''''''''''''''''
'''''''''''''''''''''''''''':(Sa'''''''''''''''''''''''''''''''''''+a'''''''''''''''''''''''''''''''
''''''''''''')=S(a''''''''''''''''''''''''''''''''''''''·Sa'''''''''''''''''''''''''''''''''')>∧∀a''
''''''''''''''''''''''''''''''''''''':∀a'''''''''''''''''''''''''''''''''''''''':<<∃a'''''''''''''''
'''''''''''''''''''''''''''''':(Sa'''''''''''''''''''''''''''''''''''''''+a'''''''''''''''''''''''''
'''''''''''''''''''')=a''''''''''''''''''''''''''''''''''∧∃a''''''''''''''''''''''''''''''''''''''''
'''''':<a'''''''''''''''''''''''''''''''''''''=((S(a''''''''''''''''''''''''''''''''''''''·Sa'''''''
'''''''''''''''''''''''''''''''')·a'''''''''''''''''''''''''''''''''''''''''''''')+a''''''''''''''''
'''''''''''''''''''''''')∧∃a''''''''''''''''''''''''''''''''''''''''''''''':(Sa'''''''''''''''''''''
'''''''''''''''''''+a''''''''''''''''''''''''''''''''''''''''''''''')=S(a'''''''''''''''''''''''''''
'''''''''''·Sa''''''''''''''''''''''''''''''''''''''')>>⊃∃a'''''''''''''''''''''''''''''''''''''''''
''''''':<a'''''''''''''''''''''''''''''''''''''=((S(a''''''''''''''''''''''''''''''''''''''·SSa'''''
'''''''''''''''''''''''''''''''''')·a'''''''''''''''''''''''''''''''''''''''''''''''')+(SSSSSSSSSS0·
a''''''''''''''''''''''''''''''''''''''''))∧∃a''''''''''''''''''''''''''''''''''''''''''''''''':(S(S
SSSSSSSSS0·a'''''''''''''''''''''''''''''''''''''''')+a'''''''''''''''''''''''''''''''''''''''''''''
'''')=S(a''''''''''''''''''''''''''''''''''''''·SSa''''''''''''''''''''''''''''''''''''''')>>>>∧<∃a'
''''''''''''''''''''''''''''''''''''''''''''''''':(Sa'''''''''''''''''''''''''''''''''+a''''''''''''
'''''''''''''''''''''''''''''''''''''')=a'''''''''''''''''''''''''''''''''''∧a'''''=((a'''''''''''''
'''''''''''''''''''''''·(SSSSSSSSSS0·a'''''''''''''''''''''''''''''''''''))+a'''''''''''''''''''''''
'''''''''')>>>∨∃a''''''''''''''''''''''''''''''''''''''''''''''''''':∃a'''''''''''''''''''''''''''''
''''''''''''''''''''''':∃a''''''''''''''''''''''''''''''''''''''''''''''''''''':∃a''''''''''''''''''
'''''''''''''''''''''''''''''''''''':<a''''=((a'''''''''''''''''''''''''''''''''''''''''''''''''''''
'·(SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
SSS0·a'''''''''''''''''''''''''''''''''''''''''''''''''''''))+a'''''''''''''''''''''''''''''''''''''
'''''''''''''')∧<∃a''''''''''''''''''''''''''''''''''''''''''''''''''''''':∃a'''''''''''''''''''''''
''''''''''''''''''''''''''''''''':<∃a''''''''''''''''''''''''''''''''''''''''''''''''''''''''''':<a'
''''''''''''''''''''''''''''''''''''''''''''''''''''''=((S(a''''''''''''''''''''''''''''''''''''''''
''''''''''''''''·S0)·a''''''''''''''''''''''''''''''''''''''''''''''''''''''''''')+S0)∧∃a'''''''''''
''''''''''''''''''''''''''''''''''''''''''''''''':(SS0+a''''''''''''''''''''''''''''''''''''''''''''
'''''''''''''''')=S(a''''''''''''''''''''''''''''''''''''''''''''''''''''''''·S0)>∧<∃a''''''''''''''
''''''''''''''''''''''''''''''''''''''''''''''':<a''''''''''''''''''''''''''''''''''''''''''''''''''
'''''=((S(a''''''''''''''''''''''''''''''''''''''''''''''''''''''''·Sa''''''''''''''''''''''''''''''
'''''''''''''''''''''')·a''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''')+a'''''''''''
'''''''''''''''''''''''''''''''''''''''''')∧∃a''''''''''''''''''''''''''''''''''''''''''''''''''''''
'''''''':(Sa'''''''''''''''''''''''''''''''''''''''''''''''''''''+a'''''''''''''''''''''''''''''''''
''''''''''''''''''''''''''''')=S(a''''''''''''''''''''''''''''''''''''''''''''''''''''''''·Sa'''''''
''''''''''''''''''''''''''''''''''''''''''''')>∧∀a''''''''''''''''''''''''''''''''''''''''''''''''''
''''''':∀a'''''''''''''''''''''''''''''''''''''''''''''''''''''''''':<<∃a'''''''''''''''''''''''''''
'''''''''''''''''''''''''''''''''''':(Sa'''''''''''''''''''''''''''''''''''''''''''''''''''''''''+a'
'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''')=a'''''''''''''''''''''''''''''''''''
'''''''''''''''''∧∃a'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''':<a'''''''''''''
''''''''''''''''''''''''''''''''''''''''''=((S(a''''''''''''''''''''''''''''''''''''''''''''''''''''
''''·Sa''''''''''''''''''''''''''''''''''''''''''''''''''''''''')·a'''''''''''''''''''''''''''''''''
''''''''''''''''''''''''''''''')+a'''''''''''''''''''''''''''''''''''''''''''''''''''''''''')∧∃a''''
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''':(Sa'''''''''''''''''''''''''''''''''''
'''''''''''''''''''''''+a''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''')=S(a'''''
'''''''''''''''''''''''''''''''''''''''''''''''''''·Sa''''''''''''''''''''''''''''''''''''''''''''''
''''''''''')>>⊃∃a'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''':<a''''''''''''''
'''''''''''''''''''''''''''''''''''''''''=((S(a'''''''''''''''''''''''''''''''''''''''''''''''''''''
'''·SSa''''''''''''''''''''''''''''''''''''''''''''''''''''''''')·a'''''''''''''''''''''''''''''''''
''''''''''''''''''''''''''''''''')+(SSSSSSSSSS0·a'''''''''''''''''''''''''''''''''''''''''''''''''''
'''''''))∧∃a''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''':(S(SSSSSSSSSS0·a''''
'''''''''''''''''''''''''''''''''''''''''''''''''''''')+a'''''''''''''''''''''''''''''''''''''''''''
'''''''''''''''''''''''')=S(a''''''''''''''''''''''''''''''''''''''''''''''''''''''''·SSa'''''''''''
'''''''''''''''''''''''''''''''''''''''''''''')>>>>∧<∃a'''''''''''''''''''''''''''''''''''''''''''''
''''''''''''''''''''''':(Sa'''''''''''''''''''''''''''''''''''''''''''''''''''+a''''''''''''''''''''
'''''''''''''''''''''''''''''''''''''''''''''''')=a'''''''''''''''''''''''''''''''''''''''''''''''''
''''∧a'''''=((a''''''''''''''''''''''''''''''''''''''''''''''''''''''·a'''''''''''''''''''''''''''''
'''''''''''''''''''''''')+a''''''''''''''''''''''''''''''''''''''''''''''''''')>>>>>>>>>","['number-theory', 'formal-languages', 'logic']"
2755000,On Vector fields as differential operators.,"I am having trouble with a simple statement in some lecture notes, they say: take a vector field $\sum_{i=1}^n a_i(x) \frac{\partial}{\partial x_i}$. I do not know how this differential operator (?) represents a vector field (or is this meant to be a differential form? if it is a differential form I have studied them but never made the connection ). My naive understanding of a vector field is a vector valued function that assigns to each point of a plane a value in $\mathbb{R}^2$, as an example I have seen them described in a physics course as $$F(x,y) = x i + yj$$ Where $i,j$ represent the standard basis in $\mathbb{R}^2$. This is a very simple object that I know how to draw while I have no idea how to represent this vector field in the form $\sum_{i=1}^n a_i(x) \frac{\partial}{\partial x_i}$(how would this be done?).","['mathematical-physics', 'ordinary-differential-equations', 'differential-geometry']"
2755020,Arrangement of dimes to bring all heads,"Consider an arrangement of n dimes in a straight line. A move consists of taking a dime and turning it over (from head to tail or vice versa) and of doing the same to each of its neighbors. If the dime is at the end of the line, then it will have only one neighbor. For example, if the arrangement is HHTH and you choose the second dime, then your move would result in TTHH. The general question is this: Given any arrangement of n dimes, is it possible to find a sequence of moves to bring it to all heads?",['combinatorics']
2755021,smooth or differential version of Gelfand-Neimark theorem,"Using the Gelfand-Naimark theorem we can define an equivalence between the category of compact Hausdorff spaces and the category of commutative C*-algebras with unity (commC*-alg1). Someone knows if there exist a differential version? I mean, there exist an equivalence between the category of compact smooth manifolds and some subcategory of commC*-alg1?. If the answer is ""yes"", exactly, who is this subcategory?","['category-theory', 'general-topology', 'differential-geometry']"
2755031,Distribution of maximum of i.i.d. Chi-Square random variables with degree-of-freedom 2,"I wondering how the probability distribution of the maximum of i.i.d. Chi-square (two degrees-of-freedom) random variables $X_i \sim \chi^2(2)$ has the same distribution as $\sum_{i=1}^K \frac{X_i}{i}$, i.e.,
$$\max_{i=1,\ldots,K} X_i \ \stackrel{d}{=} \ \sum_{i=1}^K \frac{X_i}i .$$ Can anyone help me to prove this? Thank you","['probability-theory', 'probability', 'statistics', 'probability-distributions']"
2755042,What is wrong with my Laplace transformation with cover-up method?,"I have a two-compartment ODE system defined as: $\begin{cases} \frac{dC_1(t)}{dt}=\frac{Rate}{V_1}-\frac{Q\cdot C_1(t)}{V_1}+\frac{Q\cdot C_2(t)}{V_1}-\frac{CL\cdot C_1(t)}{V_1} \quad\quad...(1)\\
\frac{dC_2(t)}{dt}=\frac{Q\cdot C_1(t)}{V_2}-\frac{Q\cdot C_2(t)}{V_2}
\quad\quad...(2)\end{cases}$ 
  where $C_1(0)=C_2(0)=0$ I applied the Laplace transformation to each equation and got, respectively: $\begin{cases} s \cdot L_{C_1}(s)=\frac{Rate}{V_1 \cdot s}-\frac{Q\cdot L_{C_1}(s)}{V_1}+\frac{Q\cdot L_{C_2}(s)}{V_1}-\frac{CL\cdot L_{C_1}(s)}{V_1} \quad\quad...(3)\\
s \cdot L_{C_2}(s)=\frac{Q\cdot L_{C_1}(s)}{V_2}-\frac{Q\cdot L_{C_2}(s)}{V_2}
\quad\quad...(4)\end{cases}$ Solving (3) and (4) gives the following form for $C_1$: $L_{C_1}(s)=\frac{(Rate \cdot V_2 + V_1 \cdot Q)s+Rate \cdot Q}{s(s-\alpha)(s-\beta)}\quad\quad\quad...(5)$ where $\{\alpha,\beta\}=-\frac{1}{2}[\frac{Q}{V_2}+\frac{Q}{V_1}+\frac{CL}{V_1}\pm\sqrt{(\frac{Q}{V_2}+\frac{Q}{V_1}+\frac{CL}{V_1})^2-4 \frac{CL \cdot Q}{V_1 \cdot V_2}}]$ Using the cover-up method for (5) gives: $C_1(t)=\frac{Rate \cdot Q}{\alpha\beta}+\frac{(Rate \cdot V_2 + V_1 \cdot Q)\alpha+Rate\cdot Q}{\alpha(\alpha-\beta)}e^{\alpha t}+\frac{(Rate \cdot V_2 + V_1 \cdot Q)\beta+Rate\cdot Q}{\beta(\beta-\alpha)}e^{\beta t}\quad\quad...(6)$ However, when I compare the results of numerical estimation of $C_1(t)$ against the analytical solution for $C_1(t)$ that I derived (i.e. equation 6), my version consistently gives larger values that differs by a constant ratio of $V_1V_2$. Can anyone point out my mistake in the derivation? =========================================================== EDIT: I am able to reach $L_{C_{1}}(s)=\frac{\text{Rate}\,(Q+s V_2)}{s(CL(Q+s V_2)+s(s V_1 V_2+Q(V_1+V_2)))}$ On using the cover-up method, this time I got: $C_1(t)=Rate(\frac{Q}{\alpha\beta}+\frac{Q-V_2 \alpha}{\alpha(\alpha-\beta)}e^{- \alpha t}+\frac{Q-V_2 \beta}{\beta(\beta-\alpha)}e^{-\beta t})\quad\quad...(6)$ But it is giving me the same problem: The value is inflated than the expected values by a ratio of $V_1 V_2$... I rearrange the analytic solution from a reference source and confirm that this observation is correct - the solution in the reference contains the $\frac{1}{V_1 V_2}$ term which is missing from my equation. Anyway, let me put down the R codes that can illustrate the above discrepancies I have been describing: CL <- 5
V1 <- 19
Rate <- 1000
Q <- 0.05
V2 <- 5.263157895
time <- seq(0, 48, 1)

library(deSolve)
library(dplyr)

#deSolve function
comp2Inf <- function(t, state, parameters) {
  with(as.list(c(state, parameters)), {
    #Differential equations
    dC1 <- Rate/V1 - C1*(CL/V1) - C1*(Q/V1) + C2*(Q/V1)
    dC2 <- C1*(Q/V2) - C2*(Q/V2)
    #return rate of change
    list(c(dC1, dC2))
  })
}

ref_fcn <- function(times, Rate, CL, V1, Q, V2) {
  b = (Q/V1+Q/V2+CL/V1-sqrt((Q/V1+Q/V2+CL/V1)**2-4*Q*CL/V1/V2))/2
  a = Q*CL/V1/V2/b
  A = (a-Q/V2)/V1/(a-b)
  B = (b-Q/V2)/V1/(b-a)
  return(sapply(times, function(t) {
    Rate*(A/a*(1-exp(-a*t))+B/b*(1-exp(-b*t)))
  }))
}

my_fcn <- function(times, Rate, CL, V1, Q, V2) {
  a = (Q/V2+Q/V1+CL/V1-sqrt((Q/V2+Q/V1+CL/V1)**2-4*CL*Q/V1/V2))/2
  b = (Q/V2+Q/V1+CL/V1+sqrt((Q/V2+Q/V1+CL/V1)**2-4*CL*Q/V1/V2))/2
  return(sapply(times, function(t) {
    Rate*(Q/a/b+(Q-(V2*a))*exp(-a*t)/a/(a-b)+(Q-(V2*b))*exp(-b*t)/b/(b-a))
  }))
}

tab_deS <- ode(y = c(C1=0,C2=0), times = time, func = comp2Inf, parms = list(Rate=Rate, CL=CL, V1=V1, Q=Q, V2=V2)) %>% as.matrix
arr_ref <- ref_fcn(time, Rate, CL, V1, Q, V2)
arr_my <- my_fcn(time, Rate, CL, V1, Q, V2)

data.frame(time=time, deS=tab_deS[,2], ref=arr_ref, my=arr_my) In the code, I generated 3 arrays of values Using the numerical estimation solution by R package deSolve Using a reference source Using my derivation the code outputs a table for comparison.","['integration', 'ordinary-differential-equations', 'laplace-transform']"
2755059,Solving a differential equation in distribution/generalised functions.,I am stuck trying to solve the following differential equation in terms of distribution (theory). $$x\frac{du}{dx} - \lambda u = 0.$$ This is just for $\mathbb{R}$ and $\lambda \in \mathbb{C}$. I know the regular distribution corresponding to the function $f(x) = Ax^{\lambda}$ is a solution but the solution says that $c\delta$ is also a solution for some $c \in \mathbb{C}$ and I am not sure I can see how to derive this.,"['distribution-theory', 'ordinary-differential-equations']"
2755074,Self-dual connections and Einstein 4-manifolds,"I'm reading Besse's book on Einstein manifolds. Theorem 13.14 (due to Atiyah, Hitchin, and Singer) states that a Riemannian 4-manifold is Einstein iff the Levi-Civita connection on $\Lambda^+$ is self-dual. Here $\Lambda^2=\Lambda^+\oplus\Lambda^-$ is the space of two forms, which decomposes due to the fact that the Hodge star operator $\ast\in \mathrm{End}(\Lambda^2)$ is an involution ($\ast^2=1$) in dimension 4. Question: Does this theorem imply that an Einstein 4-manifold is self-dual  (i.e. $W^-=0$, where $W=W^++W^-$ is the Weyl tensor of the manifold)? If not, when is an Einstein 4-manifold self-dual?","['vector-bundles', 'differential-geometry']"
2755078,Set theory - Logic proof verification,"Prove that:
$$
\mathscr P(U_{i\in I}A_i)\subset U_{i\in I}\mathscr P(A_i) \rightarrow \exists i \in I\ \forall j \in I (A_j \subset A_i)
$$ Here are the definitions I've used to figure out how to prove it:
$$
U{i\in I} A_i = \{ k \text{ | }\exists i \in I(k\in A_i) \}\\
U{i\in I} \mathscr P(A_i) = \{ k \text{ | }\exists i \in I(k\in \mathscr P(A_i)) \} = \{ k \text{ | }\exists i \in I(k \subset A_i) \}
$$ Here's my proof. It's true that $\forall j \in I: A_j \subset U_{i\in I}A_i$, thus $A_j \in \mathscr P(U_{i\in I}A_i)$. Therefore $\forall j \in I:A_j \in U_{i\in I}\mathscr P(A_i)$ which is the same as $ \forall j \in I: \big( \exists i \in I (A_j \subset A_i) \big)$. But I want to prove that: 
$$
\exists i \in I: \big( \forall j \in I (A_j \subset  A_i) \big)
$$ So now I'll prove : $\forall j \in I: \big( \exists i \in I (A_j \subset  A_i) \big) \rightarrow \exists i \in I: \big( \forall j \in I (A_j \subset  A_i) \big)$ by contradiction. Let $i$ be an arbitrary element of $I$. Therefore $A_{j0} \not\subset  A_i$. That contradicts the fact that $ \forall j \in I: \big( \exists i \in I (A_j \subset  A_i) \big) $, hence $\exists i \in I: \big( \forall j \in I (A_j \subset  A_i) \big)$. I'm new to math formalism and I struggled to get this. Is everything correct? I know that I'm using a lot of logic symbols, but it's because it's still more clear to me to write a proof like that then write it using plain English. I'm open to constructive criticism, and hope for a help. Thanks!","['elementary-set-theory', 'proof-verification']"
2755083,Solve for $x$: $x^{x-1} - (x-1)^x = 1$,"If $x$ is a real number, then solve for $x$ wherever the below equation is defined:
$$x^{x-1} - (x-1)^x = 1$$ I viewed the answer to the question: $x^{x-1} = (x-1)^x $; but those methods won't work here because of the $1$ on RHS. Also by using a graph plotter, I found that the only solutions for $x \geq 1$ are $x = 1,2$ or $3$. How to prove this, and how to find the solutions for $x < 1$?","['calculus', 'functions']"
2755143,Number of integers satisfying $\left[\frac{x}{100}\left[\frac{x}{100}\right]\right]=5$,"Find Number of integers  satisfying $$\left[\frac{x}{100}\left[\frac{x}{100}\right]\right]=5$$ where $[.]$ is Floor function. I assumed $$x=100q+r$$ where $0 \le r \le 99$ Then we have $$\left[\left(q+\frac{r}{100}\right)q\right]=5$$ $\implies$ $$q^2+\left[\frac{rq}{100}\right]=5$$ Since $rq$ is an integer we have $$rq=100p+r_1$$ where $0 \le r_1 \le 99$ Then we have $$q^2+p+\left[\frac{r_1}{100}\right]=5$$ $\implies$ $$q^2+p=5$$ so the possible ordered pairs $(p,q)$ are $(1,2)$, $(1,-2)$, $(-4, 3)$ i am getting infinite pairs. How to proceed?","['euclidean-algorithm', 'functions', 'algebra-precalculus', 'number-theory', 'ceiling-and-floor-functions']"
2755250,"Distribution function of $ X(\omega):=\frac{1}{\lambda} \ln \frac{1}{1-\omega},$ in Lebesgue measure","I am having trouble in finding the right approach to this exercise: Define the probability space $(\Omega, \mathcal{A},P) =((0,1), \mathcal{B}, \mu)$ with $\mu$ as the Lebesgue measure and $ \mathcal{B}$ the Borel-$\sigma$-algebra. 
  Find the distribution function of the random variable $$ X(\omega):=\frac{1}{\lambda} \ln \frac{1}{1-\omega},$$
  where $\lambda$ is a positive parameter. I know that the definition of a distribution function is $P(X\leq x) $, but to be honest I'm a bit overwhelmed and don't know how to start. Does it have to do with Lebesgue integration? Because that's what we were doing last week in the lecture. Thanks in advance.","['exponential-distribution', 'probability-theory', 'random-variables', 'probability-distributions']"
2755255,$\sum \xi_n<\infty \;\text{a.e.}\; \rightarrow \sum \sigma_n^2 < \infty$ if $E(\xi_n)=0$ and $V(\xi_n)=\sigma_n^2<\infty$.,"Let $\xi_n$ be a random variable with zero mean and finite variances $\sigma_n^2$. If $|\xi_n|\le C$ for all $n\in \mathbb{N}$, show that we have $$\sum \xi_n<\infty \;\text{a.e.}\; \rightarrow \sum \sigma_n^2 < \infty.$$ I'm looking at the following solution where we define $M_n:= (\xi_1+\cdots +\xi_n)^2 - (\sigma_1^2 + \cdots + \sigma_n^2) =:S_n^2 - A_n$. However, at the bottom of the proof, I can't see why $P(\tau=\infty)=1$ for sufficiently large $\kappa$ since $\sum_j \xi_j$ converges almost surely. I would greatly appreciate any explanation on this.","['real-analysis', 'probability-theory', 'stopping-times', 'martingales', 'measure-theory']"
2755265,Show that every nontrivial solution to the differential equation has at most one zero,"Show that every nontrivial solution to the equation $y''-e^{x}y=0$ can have at most one zero on the interval $0<x<+\infty$. My idea is to compare it to the eq $y''-y=0$, then use the Sturm Comparison Theorem, but I'm unsure of how to execute this.",['ordinary-differential-equations']
2755314,Why do all the Platonic Solids exist?,"In three dimensions it is quite easy to prove that there exist at most five Platonic Solids. Each has to have at least three polygons meeting at each vertex, and the angles of these polygons have to add up to less than $2\pi$ . This narrows down the possibilities to three, four or five triangles, three squares or three pentagons. But the proof is not quite complete. One also has to show that each of these possibilities is actually realised. Of course it turns out that they all are. I've been wondering about how to prove this without having to construct each of them individually. After reading this answer , I've managed to reconstruct the following proof. I'm wondering if it's valid. Suppose we want a polyhedron where $m$ $n$ -gons meet at each vertex.
  Take any sphere. By Gauss-Bonnet we can draw a regular $n$ -gon on the
  sphere with angles $2\pi/m$ . Draw congruent $n$ -gons along each edge
  of this one, and continue to extend the tiling in this way. Because of
  our choice of angle these polygons must join up locally. We want to
  verify that they join up locally. Consider the topological space with one $n$ -gon for each $n$ -gon drawn
  on the sphere, joined along the edges whenever the corresponding $n$ -gons share that edge. Then this topological space is a covering
  space of the sphere. But the sphere is already simply connected, so
  our covering space must be the sphere itself. So we do have a regular
  tiling of the sphere. Now create an actual regular polyhedron by
  taking the convex hull of the vertices. If this argument does work, can it be simplified so that it could be understood by someone with no knowledge of algebraic topology? Below this line is an attempt by David Speyer to restate the question. I like simplicial complexes better than CW complexes, so I am going to subdivide the polygons in the original question. Instead of a spherical $m$ -gon with angles $2 \pi/n$ , I'm going to place a vertex in the center of the polygon and connect it to all the vertices and the midpoints of all the edges. So I have $2m$ spherical triangles with angles $\pi/m$ , $\pi/n$ and $\pi/2$ . So, here is my rephrasing. Let $(a,b,c)$ be positive integers with $1/a+1/b+1/c > 1$ (in our case, $(2,m,n)$ ). We form a two dimensional simplicial complex $\Delta$ whose vertices are colored amber, blue and crimson, with two triangles on each edge and $2a$ , $2b$ , $2c$ triangles around the amber, blue and crimson vertices respectively. One way to make this more precise is to define $W$ to be the group generated by $s_1$ , $s_2$ , $s_3$ subject to $s_1^2=s_2^2=s_3^2=(s_1 s_2)^a = (s_1 s_3)^b = (s_2 s_3)^c = 1$ . Our vertices correspond to cosets of the subgroups $H_a:=\langle s_1, s_2 \rangle$ , $H_b:=\langle s_1, s_3 \rangle$ and $H_c:=\langle s_2, s_3 \rangle$ , with vertices in the same triangle if they are 
of the form $(w H_a, w H_b, w H_c)$ . Then $\Delta$ maps to the $2$ -sphere, sending our base simplex to the spherical triangle $T$ with angles $(\pi/a, \pi/b, \pi/c)$ , and choosing the images of all the other vertices by making $s_1$ , $s_2$ , $s_3$ act by reflections over the sides of $T$ . Anyone who has taught a course on Coxeter groups knows it is true, but a pain to 
prove, that the abstractly defined $\Delta$ maps isomorphically to the sphere $S^2$ and, in particular, $W$ is finite. How much can we reduce the pain by knowing that $S^2$ is simply connected?","['platonic-solids', 'covering-spaces', 'proof-verification', 'geometry', 'algebraic-topology']"
2755323,Preimage of two-dimensional function,"We have the function $f:(\mathbb{R}^2,\|\cdot\|_2)\rightarrow (\mathbb{R},|\cdot |)$ with \begin{equation*}f(x,y)=\begin{cases}y-x & y\geq x^2 \\ 0 & y<x^2\end{cases}\end{equation*} How could we draw the preimage $f^{-1}((1,\infty))$ ? Could you give me a hint?",['functions']
2755330,Affine-local property that is not stalk-local,"From Vakil's foundations of algebraic geometry, page 158, 5.3.2"" We say such a property is affine-local: a property is affine-local if we can check
  it on any affine cover. (For example, reducedness is an affine-local property. Do
  you understand why?) Note that if U is an open subscheme of X, then U inherits
  any affine-local property of X. Note also that any property that is stalk-local (a
  scheme has property P if and only if all its stalks have property Q) is necessarily
  affine-local (a scheme has property P if and only if all of its affine open sets have
  property R, where an affine scheme has property R if and only if all its stalks have
  property Q). But it is sometimes not so obvious what the right definition of Q is;
  see for example the discussion of normality in the next section. He says stalk-local properties are necessarily affine local. I feel like the converse is not necessarily true but I can't come up with a counterexample. What is an affine local property that is not stalk-local?","['schemes', 'algebraic-geometry']"
2755338,"Exercises for Spivak's Vol 2 ""A comprehensive Introduction to differential geometry""","Looking through Spivak's Vol 2. of ""A Comprehensive Introduction to Differential geometry"", I don't think there are any exercises. Is there a good source of supplementary exercises for Spivak's Differential Geometry?","['reference-request', 'book-recommendation', 'differential-geometry']"
2755341,Why did not I find all the solutions to this equation? $\sin{3x}+\cos{2x}-\sin{x}=1$,"$x$ needs to be in $[0,\pi]$ What I tried $\sin{3x}+\cos{2x}-\sin{x}=1$ $\sin{3x}-\sin{x}=1-\cos{2x}$ $2\sin{x}\cos{2x}=1-(\cos^2{x}-\sin^2{x})$ $2\sin{x}\cos{2x}=\sin^2{x}+\cos^2{x}-\cos^2{x}+\sin^2{x}$ $2\sin{x}\cos{2x}=2\sin^2{x}$ $\cos{2x}=\sin{x}$ $\cos{2x}=\cos{\dfrac{\pi}{2}-x}~~\Longrightarrow~~2x=\dfrac{\pi}{2}-x+2k\pi~~\lor~~2x=x-\dfrac{\pi}{2}+2k\pi$ $x=\dfrac{\pi}{6}+\dfrac{2k\pi}{3}~~~~(k\in\mathbb{Z})~~(1)~\lor~x=-\dfrac{\pi}{2}+2k\pi~~~~(k\in\mathbb{Z})~~(2)$ $(1):~~k=0~\Longrightarrow~x=\dfrac{\pi}{6},~~~~~~k=1~\Longrightarrow~x=\dfrac{5\pi}{6}$ But $0$ and $\pi$ are solutions too. Why did not I find $0$ and $\pi$?",['trigonometry']
2755382,Discontinuity cumulative function of dirac,Let's say I have cumulative function of dirac measures $F_{\delta_{a_n}}(x)$ that converge pointwise to $F(x)$ for all $x$ such that $F$ is continuous (which is also a cumulative function). Now  $F_{\delta_{a_n}}(x)=0$ or $F_{\delta_{a_n}}(x)=1$ so that $F(x)=0$ or $F(x)=1.$ Does $F$ have only one discontinuous point ?,"['real-analysis', 'convergence-divergence', 'probability-theory']"
2755384,Bounds on the size of a set.,"Let $X\subseteq\mathbb{R}$ with $\left|X\right|=n$ and define $Y=\left\{ x+y\vert x,y\in X\right\}$. Prove that 
$$\left|Y\right|\geq2n-1$$",['combinatorics']
2755485,Every nonempty subset of $\mathbb{N}$ has a smallest element.,"Could someone please verify whether my proof is okay? Every nonempty subset of $\mathbb{N}$ has a smallest element. Let $S$ be a nonempty subset of $\mathbb{N}$. Base case: If $1 \in S$, then the proof is done, since $1$ is the smallest natural number. Inductive hypothesis: If $S$ contains an integer $k$ such that $1 \leq k \leq n$, then it must be that $S$ contains a smallest element. Inductive step: It remains to be shown that if $S$ contains an integer $k \leq n + 1$, then $S$ has a smallest element. If there is no such $k \leq n + 1$, then $n + 1$ is the smallest element. If there is such a $k$, since $S$ is nonempty, $S$ must contain an element $k - 1$ that is less than or equal to $n$. That element would then be less than or equal to $n + 1$. By induction, $S$ has a smallest element. I am not sure whether assuming the element is $k-1$ is correct. The last paragraph is hard for me to understand if I don't assume this...","['abstract-algebra', 'induction', 'elementary-set-theory', 'proof-verification']"
2755504,Non-linear Integral equation,Any ideas how to solve this integral equation? $$f\left(x\right)\int_{-\infty}^{x}f\left(y\right)dy=\int_{-\infty}^{x}\int_{-\infty}^{x}\left(x-y\right)\left(x-z\right)f\left(y\right)f\left(z\right)dydz$$,"['integration', 'ordinary-differential-equations']"
2755508,"Range of a function, with contradictory restriction","I have this function: $$f(x)=\frac{x}{x^2+1}$$ it's clear that the domain is all real numbers, because the denominator never become zero. I've done the following procedure to found the range of $f(x)$: $\operatorname{Rec} f=\left \{{y\in \mathbb{R}:\exists x\in \operatorname{Dom} f,y=f(x)}  \right \} \\
\operatorname{Rec} f=\left \{{y\in \mathbb{R}:\exists x\in \mathbb{R},y=\dfrac{x}{x^2+1}}  \right \} \\
\operatorname{Rec} f=\left \{{y\in \mathbb{R}:\exists x\in \mathbb{R},x=\dfrac{1\pm \sqrt{1-4y}}{2y}}  \right \} \\
\operatorname{Rec} f=\left \{{y\in \mathbb{R}:\left (1-4y^2  \right )\geq 0\, \wedge\, y\neq 0 }  \right \}\\
\operatorname{Rec} f=[-\tfrac{1}{2},\tfrac{1}{2}]-\left \{ 0 \right \}$ But, the function is zero when $x=0$ $(f(0)=0)$, and the range of the function is $[-\tfrac{1}{2}, \tfrac{1}{2}]$. So I don't know where is my error in the procedure.","['algebra-precalculus', 'functions']"
2755525,Cauchy differential equation,"I'm trying to resolve this cauchy problem: $ y'=2y+1$ such as $y(0)=1$ the general integral for the differential equation is $\frac{1}{2}(e^{2x+2c_1}-1)$ for $y(0)=1$ : $y(0)=\frac{1}{2}(e^{2c_1}-1)=1$ my doubt is about the fact that i don't know how to ""get down"" that $c_1$ and i can't resolve the problem, can you help me with this one? Thank you for your time.","['cauchy-problem', 'ordinary-differential-equations']"
2755534,Solid angle relation between sinθ dϕdθ and d(cos(θ))dϕ,"I am a bit confused with regards to the concept of solid angle. Why is the solid angle which is defined as $\sin \theta {\rm d}\phi\, {d\rm }\theta$ equal to $\sin\theta\,{\rm d}\theta {\rm d}\phi = {\rm d}\cos\theta{\rm d}\phi$","['derivatives', 'solid-angle', 'spherical-geometry', 'spherical-coordinates']"
2755581,"British Maths Olympiad (BMO) 2006 Round 1 Question 5, alternate solution possible?","The question states For positive real numbers $a,b,c$ prove that $(a^2 + b^2)^2 ≥ (a + b + c)(a + b − c)(b + c − a)(c + a − b)$ After some algebraic wrangling we can get to the point where: $(a^2 + b^2)^2 + (a + b)^2(a − b)^2 + c^4 ≥  2c^2(a^2 + b^2)$ At this point if we take the $LHS - RHS$ we can write the expression as the sum of squares proving the inequality. I was wondering, is it possible to divide both sides by $c^2(a^2 + b^2)$ and show somehow that $((a^2 + b^2)^2 + (a + b)^2(a − b)^2 + c^4)/(c^2(a^2 + b^2)) ≥  2$ I tried but was not able to.","['inequality', 'a.m.-g.m.-inequality', 'cauchy-schwarz-inequality', 'algebra-precalculus', 'contest-math']"
2755587,Proof verification in geometry proving that a quadrilateral is a parallelogram,"""Be $ABC$ an acute triangle with $\angle A=60º$ and $AB\ne AC$.
Be $O$ and $H$ the circumcenter and orthocenter respectively of $ABC$ and $E$ the middle point of the arc $BC$ which goes through $A$. Prove that $AHEO$ is a parallelogram."" This is a contest math problem. The official solution says this: ""If $\angle BAC = 60º$, then $\angle BOC=120º$. By the definition of $E$, we have that $\angle BOE = \angle COE = 120º$. $OB=OC=OE$, then $\triangle BCE$ is equilateral. Let $M$ be the point of intersection of the lines $BC$ and $OE$, then $M$ is the middle point of the segment $BC$ and $2\space OM=OE$. $AH  \perp BC$, and $OE \perp BC$, then $AH \parallel OE$ and also $AH= 2 \space OM = OE$. Then the sides $AH$ and $OE$ are parallel and congruent. Then $AEOH$ is a paralellogram. The step i didn't understand was ""...and also $AH= 2 \space OM = OE$"" Can anyone explain me this? Thanks you very much.","['contest-math', 'euclidean-geometry', 'geometry']"
2755654,Partial derivative of matrix product in neural network,"I'm reading a book about neural network. In the section about back-propagation of an Affine-layer of the network, the author provides a formula and omits the details. Say $$\mathbf{X}\cdot\mathbf{W}=\mathbf{Y},$$ which $\mathbf{X}$ is of dimension $(N, 2)$, $\mathbf{W}$ of $(2, 3)$ respectively. The loss function, say $L$, will do some modification to the $\mathbf{Y}$. Then the provided formula is: $$\begin{align}\\
\frac{\partial L}{\partial\mathbf{X}} &= \frac{\partial L}{\partial\mathbf{Y}}\cdot\mathbf{W}^\mathrm{T},\\
\frac{\partial L}{\partial\mathbf{W}} &= \mathbf{X}^\mathrm{T}\cdot\frac{\partial L}{\partial\mathbf{X}}.\\
\end{align}$$ What I really want to know first is that what's the dimension of $\Large\frac{\partial\mathbf{Y}}{\partial\mathbf{X}}$? Since $$\large y_{ij} = \sum^{2}x_{ik}\cdot w_{kj},$$ so for each $y_{ij}$ there are two related $x_{ik}$ to with respect to? I'm confused at this point. What's the definition of the partial derivative of a matrix multiplication/product? And I don't know why there come up with the transposes $\mathbf{W}^\mathrm{T}$ and $\mathbf{X}^\mathrm{T}$? I draw a picture about this process(and I omit the $\mathbf{B}$, which means bias but since it's out of concern here I assume it be zero matrix):","['matrices', 'matrix-calculus', 'calculus', 'neural-networks', 'linear-algebra']"
2755656,Showing that a regular curve is a pregeodesic,"I'm trying to prove the next: To show that a regular curve $\alpha$ with $\alpha^{'}$ and $\alpha^{''}$ collinear is a pregeodesic, write $\alpha^{''}(s)=f(s)\alpha^{'}(s)$ and prove that a) $\beta=\alpha\circ h$ is a geodesic if and only if $h''+ (f\circ h) (h')^2 = 0$. b) If  $\langle \alpha',\alpha'\rangle $ is never zero, then any constant speed reparametrization of $\alpha$ is a geodesic. Suposse $\beta$ has unit speed, so $\langle \beta''(s), \beta'(s)\rangle = 0$ for all $s.$ From here $h'(s) ( h''(s) + f( h(s)) (h'(s))^2) \langle \alpha'(s),\alpha'(s)\rangle = 0,$ because $\beta^{''}$ is as a) and $\beta^{'}=(\alpha^{'}\circ h)h^{'}.$ c)$\langle \alpha',\alpha'\rangle$ is always zero or never zero. To see this,  $\langle \alpha'(s),\alpha'(s)\rangle' = 2f(s)\langle \alpha'(s),\alpha'(s)\rangle$, then $\langle \alpha'(s),\alpha'(s)\rangle = Ce^{2\int f(s)\,{\rm d}s}$ for some integration constant $C.$ d) If $\langle \alpha',\alpha'\rangle$ is always zero, then $\alpha$ is pre-geodesic. I've proved a), b) and c). Such points follow by some computations with $\beta^{'}$ and $\beta^{''},$ the hypotesis that $\alpha$ is regular and the first at the proposition: $\alpha^{''}(s)=f(s)\alpha^{'}(s).$ My first doubt is: How is possible write  $\alpha^{''}(s)=f(s)\alpha^{'}(s)?$ I don't get how to prove this. It is part of the hypotesis? Also I'm stuck prove d). Second: Why the proof of the behind ensures $\alpha$ is pregeodesic? I think the next result ensures that, if the previous holds, then $\alpha$ is pregeodesic: Let $\gamma:I\rightarrow M$ be a nonconstant geodesic. A reparametrization $\gamma\circ h:J\rightarrow M$ is a geodesic if and only if $h$ has the form
$h(t)=at+b.$ If a curve has a reparametrization as a geodesic we call it pregeodesic. Any kind of help is thanked in advanced.","['semi-riemannian-geometry', 'differential-geometry']"
2755660,Computing $\cos^4 20^{\circ}+\cos^4 40^{\circ}+\cos^4 60^{\circ}+\cos^4 80^{\circ}$,"Compute $$\cos^4 20^{\circ}+\cos^4 40^{\circ}+\cos^4 60^{\circ}+\cos^4 80^{\circ}$$ Suppose that this is a scenario where calculator isn't allowed.
I want to say that this expression has something to do with this equation $\cos^2 20^{\circ}+\cos^2 40^{\circ}+\cos^2 60^{\circ}+\cos^2 80^{\circ}=\frac 74$ but I can't seem to find a method to solve this without relying on brute forcing every term to $\cos20^{\circ}$",['trigonometry']
2755661,Summation of logarithmic functions,"The sum of series $\frac{(\log3)^1}{1!}+\frac{(\log3)^3}{3!}+\frac{(\log 3)^5}{5!}+\cdots$ is what?
Is there a general algorithm to find the summation of logarithms?",['sequences-and-series']
2755681,Least number of rounds to find all hidden pairs,"In my country there's a TV reality show in which $n+1$ men and $n$ women live in a house and, over the course of the show, they have to, as a group, find out who their 'match' is. $($In the actual TV show, $n=10)$ .
Each man is assigned to a single woman such that every woman save for one has a single man assigned to her; this exceptional woman therefore has two men assigned to her. At the start of the game, no assignment is known to any player.
Each round lasts a week, and on each round the players assemble into pairs (hence, one man is left out).
Then, each pair that is a match is revealed to be a correct pair. The players win when $n$ correct pairs are assembled in a round.
What is the least number $r(n)$ of rounds that guarantees a win? More generally, what kind of theory/bibliography is available to deal with questions like this?
Information theory? Combinatorial group theory? I confess I'm at a loss here, and devising a winning strategy here by 'trial and error' seems like an approach whose feasibility decreases very fast as $n$ increases.","['information-theory', 'combinatorics', 'recreational-mathematics', 'combinatorial-group-theory']"
2755685,"Score Based On Number of Games Played, and Average Score for All Games Played","I have two data points X: Number of Games Played ( lowest: 1 highest: 1000) Y: Average of all game scores[ sum of all game scores / number of games played ] ( lowest: 4 highest: 6.5) I don't have record of the individual game scores, I only have the average. How can i generate a score based on these two variables, to make a good comparison mechanisms between multiple entities that have different x,y values? in a sense that when [x=1,y=6.5] is worse[has a lower score] than [x=5, y=6.1] or something similar","['statistics', 'scoring-algorithm']"
2755696,Relating the trace and norm in Galois theory with the trace and determinant of a certain matrix,"Suppose that $F$ is a finite dimensional extension field of $K$ (both subfields of $\mathbb{C}$). Given $u \in F$, let $g_u : F \to F$ be defined by $v \mapsto uv$. If $B$ is any ($K$-basis) for $F$ and $M = [g_u]_B$, then I would like to show that $\mbox{trace}(M) = \mbox{Tr}_{F/K}(u)$ and moreover $\mbox{det}(M) = \mbox{N}_{F/K}(u)$. I've been trying to prove that this at least holds in the case that $F = K(u)$ (where we would have a basis of the form $\{u^0, u^1, \dots u^n\}$) but haven't succeeded. I am using the Hungerford notion of trace and norm. In particular, let $\sigma_1, \dots, \sigma_t$ be all the distinct $K$-monomorphisms $F \to \mathbb{C}$. If $a \in F$, then $N_{F/K}(a) = \sigma_1(a)\sigma_2(a) \dots \sigma_r(a)$ and $\mbox{Tr}_{F/K}(u) = \sigma_1(a) + \dots + \sigma_r(a)$.","['abstract-algebra', 'galois-theory', 'field-theory', 'linear-algebra']"
2755706,First hitting locations of Brownian motion gets arbitrarily close,"Let $\Omega$ be an open topological disk. Let $\delta > 0$. I want to show that there exists $\epsilon > 0$ and $K_\epsilon \subseteq_c \Omega$, where $d(y,\partial \Omega) < \epsilon$ for all $y \in \partial K_\epsilon$, such that 
$\mathbb P(|B_T - B_{T_\epsilon}| \geq \delta) < \delta$, where $T$ and $T_\epsilon$ are the first hitting times of $\partial \Omega$ and $\partial K_\epsilon$, respectively. This argument looks intuitive. If $\epsilon$ decreases sufficiently small, $B_{T_\epsilon}$ gets very close to the boundary of $\Omega$, and thus $B_T$ is expected to be very close to $B_{T_\epsilon}$. But how do I put together a proof for this? I think I may be missing some property of Brownian motions so that I have a hard time doing it.","['stochastic-processes', 'brownian-motion', 'probability']"
2755709,Showing a dense curve in the torus is weakly embedded,"This is Lee's problem 5-11 in his smooth manifolds book. I want to show that a particular curve $C$ on the torus $T$ (a line with irrational slope in the square model of the torus) is weakly embedded. Weakly embedded here means that if there is any smooth map $f:M\mapsto T$, with $f(M)\subset C$, then the associated map $F:M\mapsto C$ is also smooth. In other words, it's always valid to restrict the range. I know it's enough to just show $F$ is continuous. But I don't see how to do that. I was hoping I could use connectivity (since an open subset of $T$ has a bunch of arcs from $C$), but I can't seem to make it work. Does anyone have a good hint (no full solution please)? EDIT: I think I can see the basic idea after looking at the proofs of Proposition 19.16 and Theorem 19.17 in Lee's book. We can take a small open set $U$ of $T$ around a point in $C$, and then $C$ inside $U$ looks like a countable collection of line segments. If we then take a small connected neighborhood in $M$, it has to be mapped into this countable collection, and so only ends up in one. So it seems my idea of using connectedness was correct.  It's probably more work to make this whole idea formal.","['manifolds', 'smooth-manifolds', 'differential-geometry']"
2755714,How to deduce general solution of DE using Mobius transform,"We are given a differential equation, say of the form $$y''(z)+\frac Azy'(z)+\frac B{z^2}y(z)=0$$
This is a differential equation with regular singular points at $0$ and $\infty$. Then we find the general solution to this equation is something like $y(z)=a_1 z^{k_1}+a_2 z^{k_2}$ (given $A$ and $B$ do not satisfy particular conditions which would give repeated roots of the indicial equation rather than distinct $k_i$'s). How can we now use a Mobius transform to find the general solution of a similar DE with regular singular points at generic point $x_1,x_2$ now? What is the general method? I can't find any similar questions on this site. An idea I had was, of course we want a Mobius transform which maps $0,\infty$ to $x_1,x_2$. This would be $$f(z)=\frac{x_2z+x_1t}{z+t}$$ where $t$ is a free parameter. The inverse Mobius transform of this is $$f^{-1}(\tilde z)=\frac{\tilde z-x_1}{x_2-\tilde z}t$$Now we could let $z=f^{-1}(\tilde z)$ in the differential equation above, and this the solution above. In this case, whenever $(x_1,x_2)=(0,\infty)$, (by choosing $t=x_2$), we get that $f^{-1}$ is the identity map, and so we have recovered the original solution. If $x_i$ are different, then the general solution is $$y(z)=a_1 \left(f^{-1}(z)\right)^{k_1}+a_2\left(f^{-1}(z)\right)^{k_2}$$
Is that correct? In particular I am unsure about the step where we ""let $t=x_2$"", and how valid that is - I'd expect that we wouldn't have needed to make a choice, and that this should work for any $t$. Did my derivation depend on the choice of $t$, and should it? These are my main concerns with my method.","['complex-analysis', 'ordinary-differential-equations', 'mobius-transformation']"
