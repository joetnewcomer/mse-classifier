question_id,title,body,tags
1993953,Closest points between two lines,"I have two arbitrary lines in 3D space, and I want to find the distance between them, as well as the two points on these lines that are closest to each other.  Naturally, this only concerns the skew case, since the parallel and intersecting cases are trivial. I know how to find the distance, as the question was asked before and answered here .  I haven't found a good explanation on how to find the two points that determine that distance, though. So specifically, given two lines $$L_1=P_1+t_1V_1$$
$$L_2=P_2+t_2V_2$$ I would like to find two points $X_1$ on $L_1$ and $X_2$ on $L_2$ such that the distance between $X_1$ and $X_2$ is minimal.",['geometry']
1993989,Arithmetic or Geometric sequence?,"Given a sequence: $$1, \frac12, \frac13, \frac14, \frac15,...$$ Its explicit formula can be given as: $a(n) = \frac1n$ where $n \ge 1$. I actually want to know is it a geometric sequence or an arithmetic one? I tried finding common ratio and the common difference in this sequence to see if it's either one of them but was not successful. My common ratio ($r$) and common difference ($d$) were some horrible values.","['arithmetic-progressions', 'sequences-and-series', 'geometric-series']"
1993996,A question about a simple combinatorial problem,"I am reading ""Introduction to Combinatorial Mathematics"" by C. L. Liu.
And I cannot understand the meaning of ""because of symmetry"" in the following sentences: p.7 Example 1-9 ""A binary sequence is a sequence of $0$'s and $1$'s. What is the number of $n$-digit binary sequences that contain an even number of $0$'s(zero is considered as an even number) ? The problem is immediately solved if we observe that because of symmetry half of the $2^n$ $n$-digit binary sequences contain an even number of $0$'s, and the other half of the sequences contain an odd number of $0$'s."" Liu says that ""because of symmetry"". In fact, if $n$ is an odd integer, the problem is immediately solved by symmetry as follows(but if $n$ is an even integer, the following argment doesn't work): If a sequence contains an even number of $0$'s, then the sequence contains an odd number of $1$'s.
If a sequence contains an odd number of $0$'s, then the sequence contains an even number of $1$'s. So, ""the number of sequeces which contain an even number of $0$'s"" is equal to ""the number of sequeces which contain an odd number of $1$'s"",
and, ""the number of sequeces which contain an odd number of $0$'s"" is equal to ""the number of sequeces which contain an even number of $1$'s"". Obviouly, ""the number of sequeces which contain an even number of $0$'s"" $+$ ""the number of sequeces which contain an odd number of $0$'s"" is equal to $2^n$. And, by symmetry, ""the number of sequeces which contain an even number of $0$'s"" is equal to ""the number of sequeces which contain an even number of $1$'s"". Finally, $2^n$ $=$ ""the number of sequeces which contain an even number of $0$'s"" $+$ ""the number of sequeces which contain an odd number of $0$'s"" $ = $ ""the number of sequeces which contain an even number of $0$'s"" $+$ ""the number of sequeces which contain an even number of $1$'s"" $ = $ ""the number of sequeces which contain an even number of $0$'s"" $\times 2$. So, ""the number of sequeces which contain an even number of $0$'s"" is equal to $2^{n-1}$.","['combinations', 'combinatorics', 'discrete-mathematics']"
1994015,find the limit of one sequence $\lim_{ n \to \infty } \cos(\frac{\pi}{2n + 1})\cos(\frac{2\pi}{2n + 1})...\cos(\frac{n\pi}{2n + 1}) $,"I want to find the limit of this below Sequence .
the first sentence of this sentence n approaches infinity they approaches to 1 but not same for last sentence. How can we solve it. $\lim_{ n \to \infty } \cos(\frac{\pi}{2n + 1})\cos(\frac{2\pi}{2n + 1})\cos(\frac{3\pi}{2n + 1})...\cos(\frac{n\pi}{2n + 1}) $ Is it possible to help me? I'm sorry for bad English. Thanks.","['integration', 'calculus', 'limits']"
1994021,How to show that following limit is zero?,"In one of the research article it is written that the following limit is equal to zero $$\lim_{x \to 0 }\frac{d}{2^{b+c/x}-1}\left[a2^{b+c/x}-a-a\frac{c\ln{(2)}2^{b+c/x}}{2x}-\frac{c\ln{(2)}}{2x^2}\frac{2^{b+c/x}}{\sqrt{2^{b+c/x}-1}}\right]\left(e^{-ax\sqrt{2^{b+c/x}-1}}\right)=0$$ where $a,b,c,d$ are all positive constants. I am unable to solve it. Please help me in getting there. Many thanks in advance.","['limits-without-lhopital', 'limits']"
1994067,Similar Triangles Problem (No corresponding sides),"This problem is from a Year 9 Oxford Maths textbook. I have tried to solve it since yesterday to no avail. Here are the questions - It is only (b/c) that I cannot solve, but I included the other questions since it gives us an idea of the methods that they want us to use: a) Using an understanding of angles and parallel lines, explain why the triangles on the right are similar. b) Match corresponding sides and find the scale factor between the two triangles. c) Find the length of the unknown sides I tried using the similar triangles method, but I'm not sure whether it is possible, because there are no corresponding sides, since the corresponding sides of 3, 2 and 7.5 are unknown. I have also tried rotating the smaller triangle into the bigger triangle, to form something like this: From there, I tried to see if I could find the missing variables from comparing the equations but that didn't work either. I found that ab = 15, ac = 22.5 and 2c = 3b, but that didn't help, as a and b had no corresponding sides and were lengths of different triangles. I couldn't find the length of the unknown sides ultimately because there were too many variables. I also tried using lines to cut the triangles in half to form 90 degree angles but that did not work either, because no angles were specified on the problem. I also tried using interior the interior angles of the triangles to try and find the exterior angles to form ""outside triangles"" between the two triangles but that didn't work. How do you solve this problem? I know that there is apparently a specific answer (as shown below), but since there are no corresponding sides, can't any value be placed in a and b, as long as they are to scale? Here are the answers (mouse over to see): a = 2.5, b = 6 I also tried this, but I'm not sure whether it can be proven to be possible. The answer I got by assuming that the height of the triangle was 3 was quite close to the scale factor... When I rounded the scale factor off into a whole number it gave the correct answer for some reason. Can this be proven possible/impossible: Triangles rotated into one big triangle I read the original question on the e-book, but I don't have it now. Here is the original picture of the problem. (very badly taken, question numbers are off the page): Original pic","['angle', 'trigonometry', 'triangles', 'geometry']"
1994108,Solving for $\sin(n \cdot\arcsin(x))$ when n takes on any integer value.,Solving for $\sin(n \cdot\arcsin(x))$ when n takes on any integer value. How would I go about tackling this question for large numbers of n? I was able to compute it by hand for values of $n$ up to $4$ but there has to be an easier way to solve it for numbers like $50$ etc...,['trigonometry']
1994136,"Alternative analytic continuation to zeta, not giving $-\frac{1}{12}$ for sum of integers","Apologies if this has been asked already. Inspired partly by this answer where an $n e^{-\epsilon n}$ rather than $n^s$ regularization was made in the 'evaluation' of $\sum\limits_{n=1}^{\infty}n$ and the number $-\frac{1}{12}$ appeared as the only constant in the answer, and partly by a conversation with a friend claiming that $-\frac{1}{12}$ is the only 'right' way of summing this series , I have the following question: Does anyone know of or can think of a function $p(s,n)$, $s\in\mathbb{C}$, $n\in\mathbb{N}$ such that $\exists s_0\in\mathbb{C}$ such that $p(s_0,n)=n$, $\forall n\in\mathbb{N}$, where $q(s)=\sum\limits_{n=1}^{\infty}p(s,n)$ is defined and analytic on some domain $D\in\mathbb{C}$ (not containing $s_0$ obviously) and such that $q(s)$ can be analytically continued to $Q(s)$ defined on some larger domain $D_0\supset D$ such that $s_0\in D_0$ and $Q(s_0)\ne-\frac{1}{12}$? I expect that finding such a function is probably simple, but I have not been successful so far, partly due to not having much familiarity with analytic continuations. (Note that I am not wishing to make any claims or have any arguments about the validity of $1+2+3+4+...\stackrel{?}{=}-\frac{1}{12}$).","['complex-analysis', 'analytic-continuation', 'sequences-and-series']"
1994137,How does a disease spread through a triangular network?,"Consider a population of nodes arranged in a triangular configuration as shown in the figure below, where each level $k$ has $k$ nodes. Each node, except the ones in the last level, is a parent node to two child nodes. Each node in levels $2$ and below has $1$ parent node if it is at the edge, and $2$ parent nodes otherwise. The single node in level $1$ is infected (red). With some probability $p_0$, it does not infect either of its child nodes in level $2$. With some probability $p_1$, it infects exactly one of its child nodes, with equal probability. With the remaining probability $p_2=1-p_0-p_1$, it infects both of its child nodes. Each infected node in level $2$ then acts in a similar manner on its two child nodes in level $3$, and so on down the levels. It makes no difference whether a node is inected by one or two parents nodes - it's still just infected. The figure below shows one possibility of how the disease may spread up to level $6$. The question is: what is the expected number of infected nodes at level $k$? Simulations suggest that this is (at least asymptotically) linear in $k$, i.e., $$
\mathbb{E}(\text{number of infected nodes in level } k) = \alpha k
$$ where $\alpha = f(p_0, p_1,p_2)$. This question arises out of a practical scenario in some research I'm doing. Unfortunately, the mathematics involved is beyond my current knowledge, so I'm kindly asking for your help. Pointers to relevant references are also appreciated. I asked a different version of this question some time ago, which did not have the possibility of a node not infecting either of its child nodes. It now turns out that in the system I'm looking at, the probability of this happening is not negligble.","['expectation', 'reference-request', 'statistics', 'probability', 'combinatorics']"
1994179,Behavior of a logarithmic derivative,"Suppose the function $f:(0,1] \to \mathbb{R}$ is differentiable and satisfies $f(x) \geqslant 0$ and $\lim_{x \to 0+}f(x) = 0$. One way demonstrate that the derivative of a function tends to behave worse than the function is as follows. Show that the logarithmic derivative $f'/f$ diverges to $\pm \infty$ as $ x \to 0+$ or is, at least, unbounded in a neighborhood of $x =0$. This is quite simple to show under more restrictive conditions. If we assume that that $f'/f$ is positive, bounded and integrable on $[\delta,1]$ for all $\delta > 0$, then, with a change of variable $y = f(x),$ we have $$\lim_{ \delta \to 0+}\int_{\delta}^{1}\frac{f'(x)}{f(x)}\,dx = \lim_{ \delta \to 0+}\int_{f(\delta)}^{f(1)} \frac{dy}{y} = \lim_{ \delta \to 0+}[\log f(1) - \log f(\delta)] = + \infty,$$ and this implies that $f'(x)/f(x) \to +\infty$ as $x \to 0+.$ The problem then is to show that, under the weaker conditions where $f'/f$ need not be integrable, etc., we have either divergence or unboundedness of $f'/f$ near $x =0$. I suspect this is true, but I am not sure that a divergent limit is always necessary.","['real-analysis', 'asymptotics']"
1994190,"Suppose that $X_i$ are independent random variables, with finite absolute moment. Then $Max(X_1, \ldots, X_n) / n \to 0$ a.s.?","Suppose that $X_i$ are i.i.d. random variables, with finite absolute moment: $E|X_1| < \infty$. Then $\max(X_1, \ldots, X_n) / n \to 0$ a.s. ? Let $M_n = \max(X_1, \ldots, X_n)$. I know that $M_n$ has a CDF which is $F_n(x) = F_1(x)^n$. I would like to apply Borel-Cantelli to the sets $A_n = \{ M_n > n \epsilon \}$. So I would like to show that $\Sigma P(A_n) < \infty$. I suspect that one can obtain a bound that is something like $\Sigma P(A_n) \leq E|X_1|$. However, because one doesn't have $\Sigma 1_{A_n} \leq X_1$, this is unlikely to be literally true. At some point one will need to use the independence. So I was trying to proceed by analyzing the product $\Pi ( 1 - P(A_n))$ instead. We would like this to converge to a nonzero limit. This means that we want $P( \cap A_n^c) > 0$, at least for small epsilon, because of the assumed independence. But the problem is that $P(A_1) = 0$ is already possible. I would appreciate a hint to set me on the right track. :)","['independence', 'probability-theory', 'probability', 'borel-cantelli-lemmas', 'random-variables']"
1994215,Prove that uniformly distributed variables satisfy Lindeberg's condition,"Given $A_1, A_2,\ldots $ are independent and $A_k \sim U[-a_k, a_k]$ where $0<a_k\leq 1$ for each $k$. Prove that $(A_k)$ satisfies Lindeberg's condition IFF $\sum_{k=1}^{\infty} a_k^2=\infty$. My attempt: $(\Leftarrow)$ I tried to use Lindeberg-Feller theorem. So we need to show $A_1, A_2,...$ is uniformly asymptotically negligibl e (u.a.n), which is: $\lim_{n\rightarrow \infty} \max_{k\leq n} \frac{\sigma_k^2}{\sum_{i=1}^n \sigma_{i}^2} = 0$. First, $A_k \sim U[-a_k, a_k]$, $\sigma_{k}^2 = \frac{a_k^2}{3}$. Thus by dividing both the numerator and denominator by $\max_{k\leq n} (\sigma_k^2)$, and since $\frac{1}{\sum_{i=1}^{n} \sigma_{i}^2}\geq \frac{1}{\frac{\sum_{i=1}^{n} \sigma_{i}^2}{\max_{k\leq n} (\sigma_k^2)}}\geq \frac{1}{n}$, by letting $n\rightarrow \infty$ and using the hypothesis, we get: $\lim_{n\rightarrow \infty} \max_{k\leq n} \frac{\sigma_k^2}{\sum_{i=1}^n \sigma_{i}^2} = 0$. Now, I would need to show $\frac{\sigma_{n}}{\sum_{i=1}^{n} \sigma_{i}^2}$ converges in distribution to $N(0,1)$. This is equivalent to show $$\phi_{\frac{\sigma_{n}}{\sum_{i=1}^{n} \sigma_{i}^2}}(t) = \prod_{i=1}^{n} \phi_ {\frac{a_k}{\sum_{i=1}^{n}}}(t) = \prod_{i=1}^{n} \frac{\sin\left(\frac{ta_k}{\sum_{i=1}^{n} \sigma_{i}^2}\right)}{\frac{ta_k}{\sum_{i=1}^{n} \sigma_{i}^2}}$$ (as $\phi_{a_k}(t) = \frac{\sin(ta_k)}{ta_{k}}$). But I could not show the last identity equal to $e^{\frac{-t^2}{2}}$, which is the characteristic function of $N(0,1)$ $(\Rightarrow)$ Assume $(A_k)$ satisfies the Lindeberg condition. By contradiction, assume $\sum_{k=1}^{\infty} a_k^2 < \infty$. This implies that $\lim_{n\rightarrow \infty} a_n^2 = 0$ (by the negation of nth term test for convergence). This means $\lim_{n\rightarrow \infty} \sigma_{n}^{2} = 0$, so $\max_{k\leq n} \sigma_{n}^2 = \sigma_{k_i}^2$ where $k_i$ is some finite number not depending on $n$. So by testing the uniformly asymptotically negligible, $\lim_{n\rightarrow \infty} \max_{k\leq n} \frac{\sigma_{k}^2}{\sum_{i=1}^{n} \sigma_{i}^2} = \lim_{n\rightarrow \infty} m$ where m is some positive number (since $\sum_{k=1}^{\infty} a_k^2 < \infty$, and $\max_{k\leq n} \sigma_{k}^2 = \frac{a_{k_i}^2}{3} > 0$. So the sequence $A_1, A_2,\ldots$ fails to be u.a.n, so it cannot satisfy Lindeberg condition (this is the contradiction). My question: Could anyone please help me complete the proof of convergence in distrubtion to $N(0,1)$ for the backward direction? Also, any thoughts about my proof above would be greatly appreciated. I don't find the proof for the forward direction quite nice though...","['probability-limit-theorems', 'probability-theory', 'central-limit-theorem', 'uniform-distribution', 'random-variables']"
1994217,Learning Algebraic Geometry by EGA,"Does it make sense to study algebraic geometry by Grothendieck's EGA? I know French and I want to know whether I can read a treatise Grothendieck to explore this area. I am familiar with the abstract algebra, commutative algebra, algebraic topology (in the amount of Bourbaki's books), and differential geometry.","['self-learning', 'soft-question', 'algebraic-geometry']"
1994234,"Show $\frac{\sum_{i=1}^{n} A_i}{\sqrt{\sum_{j=1}^{n} A_j^2}}\rightarrow N(0,1)$ in distribution.","Let $A_1, A_2, \ldots$ be i.i.d. with mean $0$ and variance $1$. Prove that $$\frac{\sum_{i=1}^{n} A_i}{\sqrt{\sum_{j=1}^{n} A_j^2}}\rightarrow N(0,1)$$ in distribution. My attempt: I was trying to modify the following result, but not successful at all: ""Given the same condition on $A_1, A_2,\ldots$, let $Y_n = \sum_{j=1}^{n} b_jA_j$ where $\left\{b_j\right\}$ is a sequence of constant. If $$\lim_{n\rightarrow \infty} \frac{\max_{j\leq n} b_j^2}{\sum_{j=1}^{n} c_j^2} = 0$$ then $\dfrac{Y_n}{\sqrt{\sum_{j=1}^{n} b_j^2}}\rightarrow N(0,1)$ in distribution."" So I could let $b_j = \frac{1}{N}$, and dividing both the numerator and denominator of our fraction by $N$ to obtain $Y_n$ in the numerator, but the denominator is still a variable, so I could not do anything here. Could anyone please help give some thoughts on this problem? It's quite difficult due to the ugly denominator. I'm seriously stuck on this problem for a while.",['probability-theory']
1994238,A function not constant on a connected set of critical points?,"I was looking for a function differentiable on a set, such that every point would be critical, and still the function would not be constant(everywhere). I found this reference If someone has access to this paper, I would greatly appreciate it. I think it's different from other question on this site, where they were allowing for zero derivative-a.e. functions, and I'm not... Any help would be appreciated.","['multivariable-calculus', 'real-analysis']"
1994258,$a_{n+1}=a_n+\frac{2a_{n-1}}{n+1}$ implies $a_n/n^2$ converges? [duplicate],"This question already has an answer here : How to calculate the limit of $\frac{a_n}{n^2}$ for the sequence $a_{n+1}=a_n+\frac{2 a_{n-1}}{n+1}$? (1 answer) Closed 7 years ago . Let $a_0=\pi$, $a_1=\pi^2$, $a_{n+1}=a_n+\frac{2a_{n-1}}{n+1}$ How can we prove that $a_n/n^2$ converges? It is easy to see that
$$a_n-a_1=\sum_{k=1}^{n-1}\frac{2a_{k-1}}{k+1}\geq 2a_0\sum_{k=1}^{n-1}\frac{1}{k+1}\to\infty.$$
Then how to do?",['limits']
1994263,Expected area of rectangle,"This question is taken from Rice - Mathematical statistics. A random rectangle is formed in the following way: The base, X, is chosen
to be a uniform [0, 1] random variable and after having generated the base,
the height is chosen to be uniform on [0, X]. Use the law of total expectation,
Theorem A of Section 4.4.1, to find the expected circumference and area of the
rectangle. I have trouble understanding the answer for finding the expected area of rectangle. Let H be the height of the rectangle. The area is XH, so $E(XH) = E(E(XH|X)) = E(XE(H|X)) = 1/2 E(X^2)$ Can someone kindly explain how do you derive the 3rd part from the 2nd part of the equation ?",['statistics']
1994277,"There is no $2$ dimensional, irreducible representation of $S_n.$","I am studying linear representation theory for finite groups and came across the claim in title. When $n\geq 5$, $S_n$ does not have an irreducible, $2$- dimensional representation.But I am not sure where to begin with. Although it seems that this result will follow from this as a special case, I am interested in a solution that is specific to this problem. The condition $n\geq 5$ seems to suggest that we need to use the fact that $A_n$ is simple for $n\geq 5$. I would appreciate any hint.","['abstract-algebra', 'representation-theory', 'symmetric-groups']"
1994291,An olympiad problem,"I was reading a book about olympiad problems and i encountered this exercise. Let $f:(0,\infty) \longrightarrow \mathbb{R} $ such that $\frac{f(x)+f(y)}{2} =f(\sqrt{xy})$. Prove that $\forall x,y,z>0$  $$\frac{f(x)+f(y)+f(z)}{3} =f(\sqrt[3]{xyz})$$ I only managed to prove it for an even number of values but i find difficulties to prove it for odd number of values. Also we can easily see that a function with this property is $f(x)=lnx$. Can someone give me a hint?? Thank you in advance!","['contest-math', 'recreational-mathematics', 'functions']"
1994300,Pointwise convergence of $X_n$ vs $X_nI_{\{|X_n|\leq c_n\}}$ and of $\sum X_n$ vs $\sum X_nI_{\{|X_n|\leq c_n\}}$,"Let $\{X_n,n\geq 1\}$ be a sequence of random variables, and $\{c_n,n\geq1\}$ a positive sequence. Let also $\sum_n P(|X_n|> c_n)<\infty$. Prove: If $Y_n=X_nI_{\{|X_n|\leq c_n\}}$ and $P\left( {\mathop {\lim }\limits_n {Y_n} = X} \right) = 1$, then $$P\left( {\mathop {\lim }\limits_n {X_n}} =X\right) = 1$$ $$P\left( {\sum\limits_n {{X_n}} } \,\text{converges}\,\right) = P\left( {\sum\limits_n {{X_n}{I_{\left\{ {\left| {{X_n}} \right| \le {c_n}} \right\}}}} } \,\text{converges}\,\right)$$ I have tried to prove it by the following method. First, by Borel-Cantelli Theorem, we have $$P\left( {\mathop {\lim \sup }\limits_n {\mkern 1mu} \left| {{X_n}} \right| > {c_n}} \right) = 0.$$
And$$0 \le P\left( {\mathop {\lim \inf }\limits_n {\mkern 1mu} \left| {{X_n}} \right| > {c_n}} \right) \le P\left( {\mathop {\lim \sup }\limits_n {\mkern 1mu} \left| {{X_n}} \right| > {c_n}} \right) = 0,$$then $$P\left( {\mathop {\lim \inf }\limits_n {\mkern 1mu} \left| {{X_n}} \right| > {c_n}} \right) = 0.$$
Since $P\left( {\mathop {\lim }\limits_n {Y_n} = X} \right) = 1$,we obtain $$P\left( {\mathop {\lim }\limits_n \left| {{X_n}} \right| \le {c_n}} \right) = 1.$$ Hence
$$P\left( {\mathop {\lim \inf }\limits_n {\mkern 1mu}  {{X_n}} } \right) = P\left( {\mathop {\lim \inf }\limits_n {\mkern 1mu} \left| {{X_n}} \right| > {c_n}} \right) + P\left( {\mathop {\lim \inf }\limits_n {\mkern 1mu} \left| {{X_n}} \right| \le {c_n}} \right) = 1.$$
Then $$1 = P\left( {\mathop {\lim \inf }\limits_n {\mkern 1mu} {X_n}} \right) \le P\left( {\mathop {\lim }\limits_n {\mkern 1mu} {X_n} = X} \right) \le 1,$$
which means $$P\left( {\mathop {\lim }\limits_n {X_n}} =X\right) = 1.$$ It seems something wrong! Thank everyone for good ideas!","['almost-everywhere', 'probability-theory', 'borel-cantelli-lemmas', 'convergence-divergence']"
1994314,Poisson process,"So this is a problem from the Essentials of Stochastic Processes ,by Richard Durrett. A policewoman on the evening shift writes a Poisson mean $6$ number of tickets per hour. Two-third’s of these are for speeding and cost $\$100$. One-third’s of these are for DWI and cost ${$}400$. (a) Find the mean and standard deviation for the total revenue from the tickets she writes in an hour. (b) What is the probability that between $2$ and $3$ AM she writes five tickets for speeding and one for DWI. (c) Let $A$ be the event that she writes no tickets between $1$ and $1:30$ AM, and $N$ be the number of tickets she writes between $1$ and $2$ AM. Which is larger $P(A)$ or $P(A\mid N = 5)?$ My try: (a) \begin{align}
E(X) & = 100\cdot(2/3)+400\cdot(1/3)=200\\[0.2cm] 
E(X^2) & = 100^2\cdot(2/3)+400^2\cdot(1/3)=60000 \\[0.2cm]
Var(X) & = E(X^2) - E(X)^2 = 20000\end{align} (b) $X_S \sim \text{Pois}(6\cdot(2/3)) = \text{Pois}(4)$ and $X_D\sim \text{Pois}(6\cdot(1/3)) = \text{Pois}(2)$. $\begin{align}P(X_D=1,X_S=5)~=~&\frac{e^{-\lambda P_{D}t} (\lambda P_Dt)^{X_D}}{X_D!}\frac{e^{-\lambda P_{S}t} (\lambda P_St)^{X_S}}{X_S!} \\~=~& \frac{e^{-2}(2)^1}{1!}\frac{e^{-4}(4)^5}{5!}\\~=~&2e^{-2}(128/15)e^{-4}\\~=~&256e^{-6}/15\end{align}$ But I am stuck on (c) , so how to compare those two possibilities?","['poisson-process', 'probability-theory', 'probability', 'statistics']"
1994338,Grid walk with restrictions,"Consider an ant that is walking on a Cartesian grid, starting at (0, 0) and ending at (20, 12). The ant always chooses to walk exactly one unit either up or to the right (towards his destination) whenever he arrives at a Lattice point. (A Lattice point is a point with integer coordinates.)
  Thus, from (0, 0) he either walks to (1, 0) or (0, 1). When doing a basic rectangle or a square like this, it's just the permutation of ups and rights total, so I found it to be
$$\frac{32!}{20!12!}$$
Heres where I'm getting a little confused. If the ant is not allowed to go to the points (10, 5) and (12, 8), how many different paths can he take on his walk? When asked to exclude certain points, do I have to subtract the total number of ways to get to each of these points from the total amount of ways to get to the end? Would that cause an overlap that I would have to add back in? How do I know when doing inclusion and exclusion problems when to add back?","['permutations', 'discrete-mathematics']"
1994348,"Is the set of prime pairs such that $gcd(p-1,q-1) = 2$ of positive density?","Is the set of prime pairs such that $gcd(p-1,q-1) = 2$ of positive density?
For example, for $p,q \leq 10^4$ the answer is approximately $1/2$. I was wondering if it were possible to use sieve methods and results such as the Siegel-Walfisz Theorem to give a good approximation of prime pairs of this form. The motivation for the question is for understanding the order of elements in the group $(\mathbb{Z}/pq\mathbb{Z})^*\simeq (\mathbb{Z}/p\mathbb{Z})^*\times (\mathbb{Z}/q\mathbb{Z})^*$.","['number-theory', 'analytic-number-theory', 'sieve-theory']"
1994358,Probability of getting all faces of a die an equal number of times,I have a question: A die is rolled 36 times. What is the probability of getting each number 6 times? I think the answer is: $6\cdot\left(\frac16\right)^6$ Am I wrong?,"['probability', 'dice']"
1994363,Ways to evaluate $\int_0^1 \int_0^1 \frac{1}{1-xy}dxdy = \frac{\pi^2}{6}$ [duplicate],"This question already has an answer here : How to evaluate $\int_0^1\int_0^1 \frac{1}{1-xy} \, dy \, dx$ to prove $\sum_{n=1}^{\infty} \frac{1}{n^2}=\frac{\pi^2}{6}$. (1 answer) Closed 7 years ago . A classmate told me this, but he didn't tell me how to evaluate the integral. $$\int_0^1 \int_0^1 \frac{1}{1-xy}dxdy=\int_0^1 \int_0^1\sum_{n=0}^\infty (xy)^n dxdy=\sum_{n=1}^\infty \frac{1}{n^2}=\zeta(2)$$ So if you can evaluate that integral this might be an easy way to solve the Basel problem. I tried substituting $\frac{1}{x}=v$ and $\frac{1}{y}=t$ to get $$\zeta(2)=\int_1^\infty\int_1^\infty\frac{1}{vt-1}-\frac{1}{vt}dvdt=\lim_{N\to\infty}\left(\int_1^N\int_1^N\frac{1}{vt-1}dvdt-\ln(N)^2\right)$$ The areas of the cross sections of $\frac{1}{vt-1}$ are going to be infinite near $(1,1)$ so this seems like a dead end.","['multivariable-calculus', 'riemann-zeta', 'integration', 'definite-integrals']"
1994463,What is the canonical meromorphic section $1_D$ of $\mathcal O_X(D)$?,"Let $X$ be a compact Riemann surface and let $D$ be a divisor on $X$. With $1_D$ one generally indicates a particular meromorphic section of the invertible sheaf  $\mathcal O_X(D)$ such that 
$$\operatorname{div }(1_D)=D$$ In other words $1_D$ is a collection of compatible meromorphic functions $\{f_\alpha\}$ on an open cover $\{V_\alpha\}$ of $X$ such that
$$\operatorname{ord}_x (f_\alpha)=\operatorname{ord}_x(D)$$ I believe that this ""collection"" of meromorphic functions exists but how to construct the apparently distinguished one $1_D$?  To be more precise: what is exactly $1_D$? Example: On the stacks project I've found this definition for the algebraic case and when $D$ is effective, but honestly it is not clear to me.","['riemann-surfaces', 'sheaf-theory', 'algebraic-geometry', 'divisors-algebraic-geometry', 'meromorphic-functions']"
1994468,"If $ a,b,c\in \left(0,\frac{\pi}{2}\right)\;,$ Then prove that $\frac{\sin (a+b+c)}{\sin a+\sin b+\sin c}<1$","If $\displaystyle a,b,c\in \left(0,\frac{\pi}{2}\right)\;,$ Then prove that $\displaystyle \frac{\sin (a+b+c)}{\sin a+\sin b+\sin c}<1$ $\bf{My\; Try::}$ Using $$\sin(a+\underbrace{b+c}) = \sin a\cdot \cos (b+c)+\cos a\cdot \sin (b+c)$$ $$ = \sin a\cdot (\cos b\cos c-\sin b\sin c)+\cos a(\sin b\cos c+\cos b\sin c)$$ $$ = \sin a\cos b\cos c-\sin a\sin b\sin c+\cos a \sin b\cos c+\cos a\cos b\sin c$$ Now how can i solve it after  that , Help required, Thanks",['trigonometry']
1994517,Upper bound for sum of binomial coefficients,"I need to provide a reasonable upper bound for the following sum for large $N$, and a given $c \in (0,1], q \in [0, 1]$:
$$
\sum_{n= [ c N ] }^{N} \binom{N}{n} q^n
$$
Is there a good formula for such an upper bound? It is not clear to me under which conditions on $c$ and $q$ it diverges to infinity with $N$ or it goes to 0 exponentially fast with $N$. Note that for any $q$ and $N$,
$$
\sum_{n= 0 }^{N} \binom{N}{n} q^n = ( 1 + q)^N.
$$","['combinatorics', 'binomial-coefficients', 'probability', 'sequences-and-series']"
1994588,"How many ways can a moving object reach the point $(m,n)$ with exactly $k$ changes in direction?","Assume that a moving object like $O$ is at the point $(0,0)$. ( We are talking in a $2$D-space ) In each step, $O$ can move from $(x,y)$ to $(x,y+1)$ or $(x+1,y)$.  ( So, $O$ can either go right or go up. ) Question : How many ways can $O$ reach the point $(m,n)$ with exactly $k$ changes in direction? Note 1 ( I know its simple but anyway ... ) : By ""change in direction"", I mean this : Assume that $O$ is going right and the next step is to go up.  When $O$ has taken the next step, we say that $O$ has changed its direction. Note 2 :  I think it's like that sum of  $k+1$ numbers are equal to $m+n$ but i'm not sure. Note 3 ( another way of looking at the question ) :  Assume that each move to right is a triangle and each move to up is a rectangle. We have $m$ triangles, $n$ rectangles and $k$ plus signs. We want to arrange these things such that no plus signs are next to each other. Also, if two shapes ( triangle and rectangle ) are next to each other, then these two shapes are the same. I mean, no rectangle and triangle are next to each other. How many ways can we arrange these rectangles, triangles and plus signs ? Thanks in advance.",['combinatorics']
1994610,Extending a basis to a symplectic basis,"Good afternoon! I tried to understand the following fact about symplectic linear algebra. Given a Lagrangian $L$ subspace of a symplectic vector space $(V,\Omega)$ , one can extend each basis of $L$ to a symplectic basis. I tried to do the proof by myself and by use of ""Ana Cannas da Silva-Lectures on Symplectic Geometry"" but I am still not sure whether it is ok. What do you think? The necessary condition that $\Omega(e_i, e_j)=0 ~\forall i,j=1,...,n$ is fullfilled bacause $L$ is a Lagrangian, meaning that $L = L^{\Omega} = \{v \in V: \Omega(v,l)=0~ \forall l \in L\}$ . Now we have to find $n$ elements ( $L$ Lagrangian, i.e. $\dim(V) = \frac{1}{2}\dim(L)$ ) $f_1, ..., f_n \in L^{\Omega}=L$ such that $\Omega(f_i, e_i) = 1$ , $\Omega(f_i, e_j) = 0$ and $\Omega(f_i, f_j)=0$ for all $i \neq j = 1,...,n$ . Let $\{e_1, ..., e_n\}$ be such a basis. (1) Define the set $W := span(e_2, e_3,...,e_n) \subset L$ . Since $\Omega$ is nondegenerate we can always find an element $\tilde{f}_1 \in W^{\Omega}=\{v \in V: \Omega(v,w)=0~ \forall w \in W\}$ with $\Omega(e_1, \tilde{f}_1) \neq 0$ . Take $f_1=\frac{\tilde{f}_1}{\Omega(e_1, \tilde{f}_1)}$ . Then $\Omega(f_1, e_1) = 1$ . Furthermore $\Omega(f_1,e_i)=0$ because $f_1 \in W^{\Omega}$ .
Note that $V_1 := \text{span}(e_1, f_1) \subset W^{\Omega}$ and with some effort one can show that $V = V_1 \bigoplus V_1^{\Omega}$ . If $V_1^{\Omega} =\emptyset$ , we are ready. (2) $e_2 \in V_1^{\Omega}$ . Analogue to above because of the nondegeneracy of $\Omega$ and $e_2 \neq 0$ there exists an element $\tilde{f_2} \in V_1^{\Omega}$ with $\Omega(e_2, \tilde{f_2}) \neq 0$ . Take $f_2=\frac{\tilde{f}_2}{\Omega(e_1, \tilde{f}_2)}$ . Then $\Omega(e_2, f_2) = 1$ and $\Omega(e_1, f_2) = 0 = \Omega(f_1, f_2)$ . Again one can show that $V = (V_1 \bigoplus V_2) \bigoplus (V_1 \bigoplus V_2)^{\Omega}$ . If $(V_1 \bigoplus V_2)^{\Omega} =\emptyset$ , we are ready. (3) Now because L was Lagrangian and a subset of a finite vector space, this procedure ends. Thanks to all who have looked at this!","['symplectic-linear-algebra', 'differential-geometry']"
1994619,$SO(n+1)/SO(n) \cong S^{n-1}$,"I am trying to prove this fact: $SO(n+1)/SO(n) \cong S^{n-1}$. I was told to use the map that sends an element of $g \in SO(n+1)$ to $gN$ where $N$ is the north pole. However I think this method might be wrong since the given map is not constant on the fibres of the quotient map if we consider the action of $SO(n)$ on $SO(n+1)$ as the left action, maybe instead I should use the map which sends $g$ to $Ng$. Am I right?","['algebraic-topology', 'general-topology']"
1994623,Derivatives of determinants and trace with respect a scalar parameter,"Consider the following two matrices, $A$ and $B.$ The dimension of both $A$
and $B$ are $n\times n,$ and all element of $A$ and $B$ depends on a scalar
parameter $\theta .$ Then what is derivatives of $\ln \left\vert
A\right\vert $ and $tr\left( AB\right) $ wrt to $\theta ?$ $\frac{\partial \ln \left\vert A\right\vert }{\partial \theta }$ and
$\frac{\partial tr\left( AB\right) }{\partial \theta }$? Any reference? Thanks","['derivatives', 'trace', 'determinant']"
1994630,"Prob. 5, Sec. 20, in Munkres' TOPOLOGY, 2nd ed: What is the closure of $\mathbb{R}^\infty$ in $\mathbb{R}^\omega$ in the uniform topology?","Here's Prob. 5, Sec. 20 in the book Topology by James R. Munkres, 2nd edition: Let $\mathbb{R}^\infty$ be the subset of $\mathbb{R}^\omega$ consisting of all sequences that are eventually zero. What is the closure of $\mathbb{R}^\infty$ in $\mathbb{R}^\omega$ in the uniform topology? Justify your answer. My effort: Let $x = \left( x_1, x_2, x_3, \ldots \right)$ be an element of the closure of $\mathbb{R}^\infty$ in the uniform metric topology on $\mathbb{R}^\omega$ . Then, for any real number $\varepsilon \in (0, 1)$ , we can find a point $y = \left( y_1, y_2, y_3, \ldots \right)$ in $\mathbb{R}^\infty$ such that $\tilde{\rho}(x,y) < \varepsilon$ , where $$\tilde{\rho}(x,y) = \sup \left\{ \ \min \left\{ \ \left\vert x_n - y_n \right\vert,  \ 1 \ \right\} \ \colon \ n \in \mathbb{N} \ \right\}.$$ So, for each $n \in \mathbb{N}$ , we have $\left\vert x_n - y_n \right\vert  < \varepsilon$ . Now as $ y \in \mathbb{R}^\infty$ , so there exists a natural number $N$ such that $y_n = 0$ for all $n > N$ . So we can conclude that $\left\vert x_n \right\vert < \varepsilon$ for all $n > N$ , form which it follows that the sequence $x$ converges to the real number $0$ . Conversely, if $x = \left( x_1, x_2, x_3, \ldots \right)$ is a sequence of real numbers converging to $0$ , then, for any given real number $\varepsilon \in (0, 1)$ , we can find a natural number $N$ such that $\left\vert x_n \right\vert < \frac{\varepsilon}{2}$ for all $n > N$ . Now let $y = \left( x_1, \ldots, x_N, 0, 0, \ldots \right)$ . Then clearly $y \in \mathbb{R}^\infty$ and $\tilde{\rho}(x,y) \leq \frac{\varepsilon}{2}$ , thus showing that $x$ is in the closure of $\mathbb{R}^\infty$ . Thus, the closure of $\mathbb{R}^\infty$ in the uniform topology on $\mathbb{R}^\omega$ equals the set $c_0$ of all the sequences of real numbers which converge to $0$ , in the standard metric on $\mathbb{R}$ . Am I right?","['general-topology', 'metric-spaces']"
1994668,Checking positive semidefiniteness in MATLAB,"Let $\mathbf{A}$ be a $n\times n$ matrix. I want to check in MATLAB if it is PSD or not. Which tests, in MATLAB, should I do for this purpose? I know that if $\mathbf{A}$ is PSD then following holds eigenvalue decomposition: [V,lambda]=eig(A) , then $\lambda_i\geq 0 \hspace{2mm}\forall \hspace{2mm} i=1:n$ Cholesky decomposition: [R,p] = chol(A) then $p=0$ WHY: I am asking for a list because I am having an issue. I started with a matrix $\mathbf{X}$ that was supposed to be PSD because of the way I was constructing it. However, some of its eigen values were negative. It turned out that floating point arithmetic is to be blamed for this. Problem: I came across https://www.mathworks.com/matlabcentral/fileexchange/42885-nearestspd . According to this function, $\mathbf{A}$=nearestSPD($\mathbf{X}$), $\mathbf{A}$ is the nearest SPD to $\mathbf{X}$. In help section, author mentioned that [R,p]=chol(A) will return p=0 which proves that A is SPD. Now the problem is that after getting $\mathbf{A}$, I do get p=0 for chol($\mathbf{A}$), but I am still getting one or more negative eigen values. Although the magnitude of these negative eigen values is very small something like e-15 but still the sign is negative. So I don't understand why these tests are giving different results and what should one do in such a case.","['eigenvalues-eigenvectors', 'matrices', 'matrix-decomposition', 'matlab', 'positive-semidefinite']"
1994673,Pseudoinverse of the sum of matrices,"Similarly to the question posted here Inverse of the sum of matrices but in case of non-square matrices. If I want to compute the pseudoinverse of (A+B) and matrices A,B pinv(A) is known is there a way to compute (or make an approximation) of the new pseudoinverse?? Matrices A and B are full rank.","['matrices', 'pseudoinverse']"
1994690,quant interview question from 1996 at Banc One in Columbus Ohio,"During a quant interview with Banc One in 1996 post-physics doctorate, I choked on this interview question: What is the derivative $\frac{dy}{dx}$ of $y=x^{x^{x^{.^{.^{.}}}}}$",['derivatives']
1994727,Counting finite series with a given property,"Given a natural number $n$, I'm trying to count the number $f(n)$ of series $a_1+a_2\dots +a_k,$ unique up to reversal (so $a_1+\dots a_i \dots +a_k$ and $a_k+ \dots a_{k-i+1}+\dots a_1$ are considered the same series) such that $a_i \le \min(i,k-i+1)$.  So for instance with $n=7$ the (distinct) valid series would be $$1+1+1+1+1+1+1$$$$1+2+1+1+1+1$$$$1+1+2+1+1+1$$$$1+1+3+1+1$$$$1+2+2+1+1$$$$1+2+1+2+1$$ Unless I'm mistaken, this is the same as the number of trees on $n$ nodes such that no node has degree $\gt3$ and all nodes of degree $3$ lie on a single path of length $k$ where $k$ is the diameter of the tree. By ""a single path"", I mean that they all lie on the same path, not that such a path is necessarily unique. I'm also interested in related concepts such as $g(k)=$ the number of such series with length $k$, and $h(n)=$the number of such series where reversals are considered distinct, and so on. I've calculated initial values for all three of these, though I might be mistaken: $$\begin{array}{|c|c|c|c|}\hline n&f(n)&g(n)&h(n)\\\hline3&1&2&1
\\\hline 4&2&3&2\\
\hline5&2&9&3\\\hline6&4&24&5\\\hline7&6&96&9\\\hline8&11&378&17\\\hline9&16&1890&27\\\hline\end{array}$$ For even $n$, I have $$g(n)=\sum_{i=2}^{n\over 2}\left({{i+1}\choose 2}-1\right)\left(\frac {\frac n 2 !}{i!}\right)^2$$
and for odd $n$ $$g(n)=g(n-1){\frac {n+1}2}$$ but I'm looking for formulas for $f$ and $h$ (especially $f$). Edit : found OEIS A001224 which is related. It counts the number of such series for $n-2$ with the additional requirement that every term is $1$ or $2$. Of course for the case where reflections are considered distinct, the corresponding sequence is the Fibonacci sequence.","['combinatorics', 'graph-theory']"
1994773,"$\sum_{k\geq 1}\left(1-2k\,\text{arctanh}\frac{1}{2k}\right)=\frac{\log 2-1}{2}$ - looking for an elementary solution","As stated in the title, I am looking for the most elementary proof of the following identity: $$ \sum_{k\geq 1}\left(1-2k\,\text{arctanh}\frac{1}{2k}\right) =
 \frac{\log 2-1}{2}\tag{1}$$ I have a proof that exploits $2\,\text{arctanh}\frac{1}{2k}= \log(2k+1)-\log(2k-1)$, summation by parts and Stirling's inequality, but I have the strong feeling I am missing something quite trivial, maybe related with some Riemann sum or with
$$ \sum_{k\geq 1}\left(1-2k\,\text{arctanh}\frac{1}{2k}\right) = -\sum_{m\geq 1}\frac{\zeta(2m)}{4^m(2m+1)}. \tag{2}$$
Any help is appreciated, thanks in advance. I forgot to mention that I would like to avoid proving
$$\forall t\in(0,1),\qquad \sum_{k\geq 1}\frac{4t^2}{4k^2-t^2}=2-\pi t \cot\frac{\pi t}{2} \tag{3}$$
for first. That clearly allows us to compute the LHS of $(1)$ as an integral, but requires Herglotz trick or something similar (Weierstrass products, digamma function, whatever).","['taylor-expansion', 'definite-integrals', 'sequences-and-series']"
1994810,A ring in which the two operations are equal is {0},"Let R be a ring in which the two operations are equal, i.e., $ a + b = ab \mbox{  }\forall a,b \in R $. Prove that $R = \{0 \}$. I tried to prove that $R \subset \{0 \} $ and $ \{0 \} \subset R $. For the second inclusion, we have $ 0 + 0 = 0 = 0 \cdot 0 $. So $\{0 \} \subset R $.  However, I can't figure out a way of showing that $R \subset \{0 \} $. Any tips?","['abstract-algebra', 'ring-theory']"
1994860,Simple addition definition in ZFC,"I have to present about the Peano axioms and the ZFC for my introductory seminar. It's one of the first topics presented, so I can't refer to more advance topics like cardinality, the only things introduced are the ZFC-axioms, the peano axioms and how functions/tupels are defined (and russles antiome, but i don't see it being useful here ;) ). I would like to give an (impractical) practical example of how Von Neumann-Ordinals and functions work by defining an addition function (a set of ((x,y),z) representing x+y=z or +(x,y)=z). This is my first idea in predicate logic:$$\exists A:((\emptyset,\emptyset),\emptyset)\in A \wedge (\forall ((x,y),z) \in A:(S(x),y),S(z)) \in A \wedge (x,S(y)),S(z)) \in A)$$ My problem with this definition is that i don't know how i can demand that it's only containing the things i want it to. The Peano axioms eliminate this by having $$S(m)=S(n) \to m=n$$ (i think), but i don't see how i can provide a similar construct here. Ideally i would like to have a set-comprehension, but i am not able to find/create one that does not use the not formally introduced concepts like cardinality.","['elementary-set-theory', 'peano-axioms']"
1994926,Proving the countability of a set of polynomials [duplicate],"This question already has answers here : Show that the set of polynomials with rational coefficients is countable. (3 answers) Closed 7 years ago . I want to show that the set of all polynomials with rational coefficients is countable. I know that to prove this I need to find a mapping $f$ from the natural numbers to this set that is a bijection. But I'm struggling conceptually of how to think of this. In fact, my intuition is that this isn't even true since can't we plug in an uncountable set of numbers into our polynomial? It's because of this thought that I can't even think of what a bijection would be like. If anyone could help untangle these conceptual issues I'm having that would be good -- I don't necessarily need a proof of the claim, though that's fine too. Edit: not really a duplicate.",['elementary-set-theory']
1994941,In how many ways is possible to write a number as the ordered sum of $1$ and $2$,"In how many ways is possible to write a number as the ordered sum of $ 1$ and $2$. By looking at the first (positive) integers: $1: (1) \to 1\ \text{ways}$ $2: (1,1), (2) \to 2\ \text{ways}$ $3: (1,1,1), (2,1), (1,2) \to 3\ \text{ways}$ $4: (1,1,1,1), (2,1,1), (1,2,1), (1,1,2), (2,2) \to 5\ \text{ways}$ If $Q_n$ denotes the number we need to find the number of ordered sums of, then $$Q_n = F_{n+1}$$ Where $F_{n+1}$ denotes the $n+1$ term of the Fibonacci Sequence. Is there a proof of this? It is evident that if the number $m$ 2's and $r$ 1's will give ${m +r \choose m,r}$ different sums which give $Q_n$, but I have no idea how to connect this with Fibonacci or whether there is another way to prove it. Maybe I'm trying to reinvent the wheel.",['combinatorics']
1994952,How to prove easily that a generalized ellipse is $C^1$,"Consider the graphical representation below: It describes a generalized ellipse $(E)$ in the following sense: $$(E)=\{M \ \ | \ \ d(M,(S_1))+d(M,(S_2))=18 \}$$ where $(S_1)$ and $(S_2)$, playing a role of ""generalized foci"", are the squares centered in $F_1(-7,0)$ and $F_2(7,0)$ with sides' length 2, $d(M,(C))$ is the distance from a point $M$ to a convex set $(C)$ defined by $inf_{C \in (C)} d(M,C)$ where $d(.,.)$ is the usual (Euclidean) distance. $d(M,(C))$ being a continuous function of $M$ (see for example ( Distance to a closed set is continuous. )), generalized ellipse $(E)$ is piecewise continuous. I would like to show that it is more than that: that it is smooth, in a geometrical sense: (what is called sometimes $\Delta^1$) in each connection point of two arcs (see below) there is a common tangent (as a consequence, it will be possible to define a $C^1$ parameterization). Question: is there a simple mean to establish this ""smoothness"" ? My work: I have established this smoothness explicitly by first computing the equations of the different constituent arcs of $(E)$. then for each connecting point (such as $L, N, I$...), by computing the left and right derivative (when it exists) and checking that their values are equal or checking the presence of a vertical tangent. Due to $Ox$ and $Oy$ symmetries, it suffices to describe the first quadrant part of (E), or, in an equivalent form, the different parts of arc MLNIS. Here are the equations of the constituent arcs: $$\begin{cases}
\text{Arc ML:}\ &\text{line segment:} \ \ & x=10 & -1 \leq y \leq 1\\
\text{Arc LN:}\ &\text{ellipse with foci B and C:} \ \ & \frac{(x-1)^2}{81}+\frac{(y-1)^2}{32}=1& 8 \leq x \leq 10, 1 \leq y \leq \frac{41}{9}\\
\text{Arc NI:}\ &\text{parabola:} \ \ & y=- \frac{1}{36}(x+6)^2+10& 6 \leq x \leq 8, \frac{41}{9} \leq y \leq 6\\
\text{Arc IS:}\ &\text{ellipse with foci B and A:} \ \ & \frac{x^2}{81}+\frac{(y-1)^2}{45}=1& -6 \leq x \leq 6, 6 \leq y \leq 8
\end{cases}$$ But of course, it is very tedious... Moreover I would like to generalize this study to ""generalized foci"" that could be any polygonal shape, and even any convex curve.","['convex-geometry', 'conic-sections', 'calculus', 'geometry']"
1994976,Union of an intersection of an indexed family of sets,"I am looking at $A_{n,k} = \left[{n \over k}, nk\right], n,k \in \mathbb{N}\setminus \{0\}$ and trying to find $\bigcup\limits_{n=1}^{\infty} \bigcap\limits_{k=1}^{\infty} A_{n,k}$. I start off with $\bigcap\limits_{k=1}^{\infty} A_{n,k}$. The ""smallest"" set $\left[{n \over k}, nk\right]$ is $A_{n,1}=\{n\}$ and all the other sets defined that way ($n$ constant and $k$ chosen freely) include $n$. I conclude $\bigcap\limits_{k=1}^{\infty} A_{n,k} = \{n\}$. It immediately follows that $\bigcup\limits_{n=1}^{\infty} \{n\} = \mathbb{N}\setminus \{0\}$. I haven't had much experience with infinite unions and intersections of indexed families of sets, so I would appreciate any remarks on my approach.",['elementary-set-theory']
1995011,"Within a unit square, given n random uniform points, what is the average distance to the nearest k points?","Within a unit square, given n random uniform points, what is the average distance to the nearest k points?  To be precise: if k=2 we are averaging the distances of the 1st and 2nd nearest neighbors to point i. Here is a reference for the n=2 k=1 solution. Average distance between two randomly chosen points in unit square (without calculus) (for this question I assume calculus is needed) However, if you rather had n points and were interested in the average distance to the k nearest neighbors is this something that can be solved with an exact answer? I have produced results empirically for 10,000 iterations: n=2, k=1: 0.52 n=3, k=2: 0.52 <- intuitively identical to n=2,k=1 n=5, k=4: 0.52 <- intuitively identical to n=2,k=1 n=3, k=1: 0.39 n=5, k=1: 0.28 n=10, k=1: 0.18 n=10, k=2: 0.24 n=10, k=3: 0.28 n=100, k=5: 0.097","['statistics', 'probability', 'calculus', 'geometry']"
1995041,Two sets and functions that satisfy the following conditions,"I need to come up with two sets and functions called A , B that satisfy three conditions. The two functions are f: A ⇒ B and g: B ⇒ A . The three conditions are: (i) Both functions must be onto. (ii) f(g(x)) = x for all x in B (iii) There exists y in A such that g(f(y)) ≠ y . I'm thinking that the two sets should be the set of all positive integers and that only one of the functions should be one-to-one.",['discrete-mathematics']
1995049,Is there a relationship between germs and Taylor coefficients?,"For the definition of germ, please see below. I am having some difficulty internalizing the  concept of germ due to an inability to think of concrete examples, which led to me having the following questions: 1. Are the germs of holomorphic functions (at a point $p$ ) simply single-element equivalence classes, because the Identity theorem implies that any two holomorphic functions which agree identically on a neighborhood are identical on their entire domains of definition? 2. Can one describe the members of the equivalence class of a smooth germ explicitly for simple enough examples? E.g. Let $M=\mathbb{R}$ , and let $f(x)=x$ , then is the germ of $x$ at $0$ just $$[x]_p=\{g\in C^{\infty}: g(0)=0, g'(0)=1,g^{(r)}(0)=0\ \forall\ r \ge 1  \}? $$ 3. Do similar results hold for the members of the equivalence class of a $C^k$ germ, e.g. $$[x]_p = \{ g \in C^k: g(0)=0, g'(0)=1, g^{(r)}(0)=0\ \forall\ 1 \le r \le k \}? $$ 4. Two distinct (real or complex) analytic functions cannot coincide on a neighborhood of a point -- is this the smallest class of functions for which this holds? (I.e. are germs non-trivial precisely for classes of functions which do not always coincide with their Taylor series, and are the equivalence classes simply the functions with the same Taylor series up to a certain order?) My conjectures are motivated by the idea of derivatives being ""infinitesimal"" or local approximations of functions, as well as the fact that the standard example of a non-analytic smooth function is the only function I can think of which belongs to the germ of another function, but other than this intuition I have no reason to think that the germs of analytic, smooth, or differentiable functions can be described in the manner above. That and this comment in Lee (on p.72): The germ definition has a number of advantages. One of the most significant is that it makes the local nature of the tangent space clearer, without requiring the use of bump functions. Because there do not exist analytic bump functions, the germ definition of tangent vectors is the only one available on real-analytic or complex-analytic manifolds. The only reason I might suspect that these are false is that they would lead to a much simpler definition (in my opinion) then the one given in the book. On the other hand, a definition of germs based on equality of Taylor coefficients would not generalize very well to classes of continuous functions and the like, which is perhaps the intent. Definition: (taken from p.71 of Introduction to Smooth Manifolds by John Lee): A smooth function element on [a smooth manifold] $M$ is an ordered pair $(f,U)$ , where $U$ is an open subset of $M$ and $f: U \to \mathbb{R}$ is a smooth function. Given a point $p \in M$ , let us define an equivalence relation on the set of all smooth function elements whose domains contain $p$ by setting $(f,U) \sim (g,V)$ if $f \equiv g$ on some neighborhood of $p$ . The equivalence class of a function element $(f,U)$ is called the germ of $f$ at $p$ . The set of all germs of smooth functions at $p$ is denoted by $C_p^{\infty}(M)$ ... Let us denote the germ at $p$ of the function element $(f,U)$ simply by $[f]_p$ ; there is no need to include the domain of $U$ in the notation, because the same germ is represented by the restriction of $f$ to any neighborhood of $p$ . To say that two germs $[f]_p$ and $[g]_p$ are equal is simply to say that $f \equiv g$ on some neighborhood of $p$ , however small. Related questions (in which I could not find the answer): (1) (2) (3) (4) (5) (6) (7) (8) (9)","['intuition', 'smooth-manifolds', 'germs', 'analyticity', 'differential-geometry']"
1995100,When irreducible elements of a UFD remain irreducible in a ring extension,"Let $U$ be a Noetherian UFD and let $D$ be a Noetherian integral domain (not known to be a UFD) such that $U \subseteq D$ .
Further assume that $U$ and $D$ have the same finite Krull dimension. Of course, generally, an irreducible (=prime) element of $U$ may become reducible in $D$ . What can be said about such pairs of domains with the additional property that every irreducible element of $U$ remains irreducible in $D$ ? An example: $U=\mathbb{C}[x^2]$ , $D=\mathbb{C}[x^2][x^3]$ ; if I am not wrong, every irreducible element of $\mathbb{C}[x^2]$ remains irreducible in $D=\mathbb{C}[x^2][x^3]$ (though not prime). Edit: If my above question is too general, then I wish to ask the following question: Given an irreducible element $u \in U$ , can one find a ""nice"" criterion which guarantees that $u$ remains irreducible in $D$ ? New edit: Another question: If we further assume that $U \subseteq D$ is etale, then is it true that every irreducible element of $U$ remains irrdducible in $D$ ? or
  is it true that every prime element of $U$ remains prime in $D$ ? Please see this recent question. Thank you very much!","['algebraic-geometry', 'abstract-algebra', 'unique-factorization-domains', 'ring-theory', 'commutative-algebra']"
1995185,How to derive the coordinate expression of the Hodge dual?,"I'm trying to obtain the coordinate expression of the Hodge dual. A possible definition of the Hodge dual of a $r$-form $w$, given a metric $g$, is the unique $n-r$-form such that $$  v \wedge \star w = \langle v,w\rangle \omega \tag1$$ for any $r$-form $v$. I should obtain that the components of the Hodge dual are $$\star w_{\mu_{r+1}\ \ ...\mu_n}=g_{\mu_{r+1}\ \ \nu_{r+1}}\ \dots g_{\mu_{n}\nu_{n}} \frac{\epsilon^{\nu_{r+1}\ \ ...\nu_n \sigma_1...\sigma_r}}{\sqrt g} w_{\sigma_1...\sigma_r} \tag2$$ I tried substituting  $\omega=\sqrt g dx^1\wedge...\wedge dx^n$ and
$$v\wedge \star w = v_{\alpha_1...\alpha_r} \star \omega_{\mu_{r+1}\ \ ...\mu_n} \epsilon^{\alpha_1...\alpha_r\mu_{r+1}\ \ ...\mu_n} \ dx^1\wedge ...\wedge dx^n \tag3$$ but I don't know how to expand $\langle v,w\rangle$. I only know it involves the scalar product and the determinant. So, what is the precise expression of $\langle v,w\rangle$?","['differential-forms', 'differential-geometry']"
1995207,"If two Riemannian manifolds can be isometrically immersed in each other, are they isometric?","Let $M,N$ be smooth compact oriented Riemannian manifolds with boundary. Suppose that both $M,N$ can be isometrically immersed in each other. Must $M,N$ be isometric? Does anything change if we also assume $\operatorname{Vol}(M)=\operatorname{Vol}(N)$ ? Note: I assume $M,N$ are connected (Otherwise, as mentioned by Del, we can take $N$ to be two disjoint copies of $M$ ). Of course, if both manifolds can be isometrically embedded in each other, then they are isometric. This follows from volume considerations: Suppose $i:M \to N,j:N \to M$ are isometric embeddings. Then, $i(M),M$ are isometric, hence $\operatorname{Vol}(M)=\operatorname{Vol}(i(M))\le \operatorname{Vol}(N)$ . Similarly, $\operatorname{Vol}(N)\le \operatorname{Vol}(M)$ . Thus, $\operatorname{Vol}(i(M))=\operatorname{Vol}(N)$ . Since $i(M)$ is compact, it is a closed subset of $N$ . Thus, if $i(M) \neq N$ , then $N\setminus i(M)$ is open, and so has a positive volume, contradicting $\operatorname{Vol}(i(M))=\operatorname{Vol}(N)$ . This shows $i,j$ are surjective, thus isometries. Updades and Remarks: $(1) \,$ If $M$ , $N$ have no boundaries, the answer is positive . This follows easily from a metric argument. Let $i:M \to N, j:N \to M$ be the given isometric immersions. Then $i(M)$ is clopen in $N$ , hence $i$ is surjective. Similarly, $j$ is surjective. A possible generalization to the case with boundaries: Assuming that every smooth orientation preserving isometric immersion maps boundary into boundary (see this question ) , we know that $j \circ i(\partial M) \subseteq \partial M$ , so we can imitate the above argument to this case: First, we note $i(\partial M) \subseteq \partial N$ (since $j(N^0) \subseteq M^0$ ). It follows $i(M^o)$ is clopen in $N^o$ , hence $i(M^o)=N^o$ .
Since $i(M)$ is closed in $N$ , and contains the dense subset $N^o$ , $i$ is surjective, and moreover $i(\partial M) = \partial N , i(M^o)= N^o$ . By symmetry, $j$ is surjective, and the same argument in the previous case imply $j \circ i:M \to M $ is a surjective nonexpanding map, hence a metric isometry. Then, the $1$ -Lipschitzity of $i,j$ implies $i$ is a metric isometry. So, by the positive answer to this question $i$ is a smooth Riemannian isometry. $(2)$ It is enough to prove that an orientation-preserving isometric immersion $M \to M$ is a Riemannian isometry. (and in particular maps $\partial M$ onto $\partial M$ ). Indeed, let $i:M \to N, j:N \to M$ be the given immersions and assume the above statement holds. Then $j \circ i:M \to M$ is an isometry, and so $j \circ i(\partial M) = \partial M$ . This implies that $i(\partial M) \subseteq \partial N$ (since $j(N^0) \subseteq M^0$ ). Also, $j \circ i:M \to M$ is an isometry $\Rightarrow$ $i$ is injective and $j$ is surjective. By symmetry, $i,j$ are bijections. Since we know that $i(\partial M) \subseteq \partial N , i(M^o)\subseteq N^o$ , and $i$ is surjective it follows that $i(\partial M) = \partial N , i(M^o)= N^o$ . Since $i$ is in particular a metric isometry, the positive answer to this question , shows $i^{-1}$ is smooth, hence $i$ is a Riemannian isometry.","['smooth-manifolds', 'isometry', 'riemannian-geometry', 'differential-geometry']"
1995216,Relationship between linear dependence/convergence,"Suppose I have two convergent sequences ${\{X_m}\}$ and ${\{Y_m}\}$ with limits $X$ and $Y$ in $\mathbb{R}^n$. How do I go about proving/disproving the following: a) If for every $m$, the two vectors $X_m$ and $Y_m$ are linearly dependent, then $X$ and $Y$ are linearly dependent. Similarly, b) If for every $m$, the two vectors $X_m$ and $Y_m$ are linearly independent, then $X$ and $Y$ are linearly independent. Would the following work for b? Say b is false. Let $X_m = {\{1/m,sin(m)/m}\}$, and $Y_m = {\{sin(m)/m,1/m}\}$, then the vectors $X_m$ and $Y_m$ are always linearly independent and both sequences converge to $(0,0)$, thus they're dependent.","['real-analysis', 'limits', 'convergence-divergence', 'linear-algebra', 'vector-spaces']"
1995220,Geometric meaning of complex integration,"In multivariable real calculus, if we want to calculate $\iint  (x^2 + y^2) dx dy $ over a region R, this is a number that represents the volume under the surface given by $ (x^2 + y^2) $ and the xy- plane only above the region R. So, the geometric meaning of this operation is a volume. If we wanna evalaute the intregral of a function $ f: \Bbb C \to \Bbb R $, over a path, for example, $f: \Bbb C\to \Bbb R$ with $ f(z) = Re(z^2) $ along a path I believe that, along that path, one is taking some alture and visualizing this we are making that operation to take the area between the path $\gamma $ in $\Bbb C$ and the ""image path"" of $\gamma$ in the ""alture coordinate"". But if we have that $f(z) = z^2$ and we integrate alonge the same $\gamma$ path, what kind of geometric element is that? And, what if we integrate the same function $f(z) = z^2$ but along the $\gamma $ path, indeed, what if we integrate $f(z) = z^2$ for example over all the closed unit circle region? What kind of geometric element is this?","['complex-analysis', 'geometric-construction', 'complex-integration']"
1995226,behavior of differentials under pullback via ramified maps,"A rather famous person said to me today something to the order of: Given a ramified map of curves $f : X\rightarrow Y$ of degree $d$ (say, over $\mathbb{C}$), the sheaf of holomorphic differentials $\Omega^1_Y$ becomes $(\Omega^1_Y)^d$ on $X$, or something to that effect. I can't seem to make sense of this statement. It seems to me that pullback of a differential 1-form on $Y$ also gives you a differential 1-form on $X$. In what sense is the above true? (Of course at the time I didn't want to ask him to clarify for fear of embarrassing myself, but now I'm suffering the consequences...)",['algebraic-geometry']
1995257,Closest point on a plane to a surface. And vice versa.,"Find the point on $z=1-2x^2-y^2$ closest to $2x+3y+z=12$ using Lagrange multipliers. Point on surface closest to a plane using Lagrange multipliers Although the methods used in the answers are helpful and do work, my professor told me that the way he wants us to do this problem is to recognize that the distance will be minimized when the normal vector to one point on the surface is parallel to the normal vector of the plane. To find the normal vector to the surface at a point $(x,y,z)$ we write our function implicitly and take the gradient of the new function (gradient is parallel to level curve): $$G(x,y,z,)=z+2x^2+y^2=1$$ $$\nabla G=\langle4x,2y,1\rangle$$ The normal vector of the plane is, $$\langle 2,3,1 \rangle$$ Hence we have, $$\langle 4x,2y,1 \rangle=\lambda \langle 2,3,1 \rangle$$ And that, $$z+2x^2+y^2=1$$ Question $1$: The part I don't understand is the claim that the distance will be minimized when the normals are parallel. And how is this using Lagrange multipliers, May someone please explain. Question $2$ Find the point on $2x+3y+z=12$ closest to $z=1-2x^2-y^2$ using Lagrange multipliers. I suppose we have use the fact that the normal of the plane is $\langle 2,3,1 \rangle$ with the fact that the point closest to the plane on the surface is $(\frac{1}{2},\frac{3}{2},-\frac{7}{4})$  to come up with the equation of the line that goes through our two closest points in terms of $t$ and then substitute values of $x$, $y$, $z$ into our plane equation to come up with the point on the plane. But again, I don't see where Lagrange multipliers comes into play.",['multivariable-calculus']
1995278,Mathematical Induction for Recurrence Relation,I have solved the following recurrence relationship: $T(1) = 1$ $T(n) = T(n-1) + n + 2$ so $T(n) = \frac{1}{2}n^2+\frac{5}{2}n -2$ I am now trying to perform mathematical induction to prove this. $Basis:$ $T(1)=1=3-2=\frac{1}{2} + \frac{5}{2} - 2 $ $Induction:$ $T(k+1) = T(k) + k+1 + 2$ $= \frac{1}{2}k^2 + \frac{5}{2}k -2 + k+1 +2$ $= \frac{1}{2}k^2 + \frac{7}{2}k +1$ What can I do next?,"['induction', 'recurrence-relations', 'discrete-mathematics']"
1995289,How to determine if conditional expectations with respect to different measures are equal a.s.?,"Let $(\Omega, \mathcal{F}, P)$ be a probability space and let $\mathcal{A}$ be a sub-$\sigma$-algebra of $\mathcal{F}$. Let $Q_{\mathcal{A}}$ be a probability measure on $(\Omega, \mathcal{A})$ and define, for all $P$-integrable $f$,
$$Q(f) := \int E_P(f \mid \mathcal{A})dQ_{\mathcal{A}}.$$ Note that $E_P(f \mid \mathcal{A})$ is the conditional expectation with respect to $P$. Also note that $Q$ defines a measure on $(\Omega, \mathcal{F})$ by taking $f$ to be an indicator function (we abuse notation by writing $Q(A)$ for $A \in \mathcal{F}$). Motivation. The idea is that we start with a ""prior"" probability space $(\Omega, \mathcal{F}, P)$. This extends to a linear functional (expectation) on the space $L^1$ of $P$-integrable functions $f$. Then we ""learn"" something about the sub-algebra $\mathcal{A}$ and adopt the new probability $Q_{\mathcal{A}}$ defined on $\mathcal{A}$. The question arises: How to extend this new probability $Q_{\mathcal{A}}$ to all of $\mathcal{F}$ (and thereby $L^1$)? We consider the extension $Q$ defined above. Question. Does $E_P(f \mid \mathcal{A}) = E_Q(f \mid \mathcal{A})$ a.s. ($P$)? Added Question. Is $Q \ll P$? The a.s. equality would follow if I could show that $$\int_A E_Q(f \mid \mathcal{A}) dP = \int_A f dP$$
for all $A \in \mathcal{A}.$ But I'm not sure what can be said when integrating a $Q$-conditional expectation against the measure $P$. I believe I can show the result for the case where $\mathcal{A}$ is generated by a countable partition $\{A_i \}_{i \in I}$ with $P(A_i)>0$ and $Q_{\mathcal{A}}(A_i) > 0$ for all $i \in I$. In that case, we have
$$E_Q(f \mid \mathcal{A}) = \sum_i E_Q(f \mid A_i) \mathbf{1}_{A_i},$$
so it suffices to show that $E_Q(f \mid A_i) = E_P(f \mid A_i)$ for all $i \in I$. To that end we calculate (I abuse notation, writing $A_i = \mathbf{1}_{A_i}$)
$$\begin{align} E_Q(f \mid A_i) &= \frac{1}{Q(A_i)} \int_{A_i}fdQ \\
 &= \frac{1}{Q(A_i)} \int E_P(fA_i \mid \mathcal{A}) dQ_{\mathcal{A}} \\
 &= \frac{1}{Q(A_i)} \int \left(\sum_{j \in I} \mathbf{1}_{A_j} \frac{1}{P(A_j)} \int_{A_i}fA_j dP \right)dQ_{\mathcal{A}} \\
&= \frac{Q_{\mathcal{A}}(A_i)}{Q(A_i)} \frac{1}{P(A_i)} \int_{A_i} f dP \\
&= E_P(f \mid A_i).\end{align}$$ The problem with extending this to general $\mathcal{A}$ is that I can't say explicitly what the conditional expectations (almost surely) are.","['functional-analysis', 'probability-theory', 'conditional-expectation', 'measure-theory']"
1995311,Solving non linear congruence with a large mod,"Eg, solve $x^{11} \equiv 7 \pmod{61}$ The solution is $x \equiv 31 \pmod{61}$. But how do I get there? Brute checking every #, from $0 \to 60$ is very difficult?","['number-theory', 'modular-arithmetic', 'elementary-number-theory']"
1995321,"If $f \in L^1(\Bbb R)$, then $\{f(x+n)\}\rightarrow 0$ for almost every $x$ in $[0,1]$","If $f \in L^1(\Bbb R)$, then $\{f(x+n)\}\rightarrow 0$ for (Lebesgue) almost every $x$ in $[0,1]$ as $n \rightarrow \infty$. This comes out of Richard Bass's real analysis book. I'm preparing for a midterm so any hints are appreciated!","['real-analysis', 'measure-theory']"
1995331,positive elements in $M_n(A^+)$,"I have a (perhaps simple) question regarding positive elements in tensor products with matrix algebras. Let $A$ be $C^*$-algebra and $A\otimes M_n(\mathbb{C})$ the (minimal) tensor product of $A$ and $M_n(\mathbb{C})$. Let $A^+$ the unitization of $A$. Why does every positive element in $ A^+\otimes M_n(\mathbb{C})\cong M_n(A^+)$ look like $a+x\otimes 1_{A^+}$ with $a^*=a \in M_n(A)$ and $x\in M_n(\mathbb{C})$ with $x\ge 0$ (or sums of such $a+x\otimes 1_{A^+}$)? I understand if $a+x\otimes 1_{A^+} \in A^+\otimes M_n(\mathbb{C})$ is positive, it must be $a^*=a$ and $x\ge 0$. But I don't understand why every positive element in $M_n(A^+)$ looks like such an element $a+x\otimes 1_{A^+}$ (or sums of it). I appreciate your help.","['matrices', 'tensor-products', 'c-star-algebras', 'operator-algebras']"
1995349,Distinction of del pezzo surfaces and weak del pezzo surfaces,I am a bit confused about the definition of weak del pezzo surface. Can someone give an example that what kind of weak del pezzo surface is not a del pezzo surface?,"['surfaces', 'algebraic-geometry']"
1995384,"If $X$ and $Y$ are sets, their cartesian product $X\times Y$ is a set.","In ZFC set theory, every element object is a set. We know or feel that if $X$ and $Y$ are sets, their cartesian product $X\times Y$ is a set. My question is: Why if $X$ and $Y$ are sets, their cartesian product $X\times Y$ is a set?",['elementary-set-theory']
1995422,Sum of outer product of vectors in a basis,"If $\{|u_1\rangle, ..., |u_n\rangle \}$ are an orthonormal basis for $\mathbb{C}_n$, then $$ \sum_{j=1}^{n} |u_j\rangle\langle u_j| = I_n$$ I can see that this is true in the standard computational basis, but I'm having trouble seeing it intuitively when generalized to any basis, nor can I prove it. Can anyone help?","['quantum-computation', 'linear-algebra']"
1995430,How do I prove that it is an element?,"I'm trying to prove the transitive property in this proof. If $A,B$, and $C$ are sets such that $A \subseteq B$ and  $B \subseteq C$, then $A \subseteq C$. How do I show that every element in $A$ is in $C$? The following is what I have so far: Let $A, B$, and $C$ are be sets with $A \subseteq B$ and $B \subseteq C$. To show that $A \subseteq C$,
we must show that every element in $A$ is in $C$. To this end we note that if $x \in A$, then
$x \in B$ (because $A \subseteq B$) and therefore $x \in C$ (because $B \subseteq C$). Hence $A \subseteq C$.","['elementary-set-theory', 'proof-verification']"
1995471,Relationships between roots: How to solve a polynomial with a variable second coefficient?,"I'm trying to find all of the the roots to the following polynomial with a variable second coefficient:
$$P(x)=4x^3-px^2+5x+6$$
All of the roots are rational, and $p$ is too. It is also given that the difference of 2 roots equals the third, e.g. $r-s=t$. I would like to solve for the roots using relationships between roots & the rational roots theorem. I know from relationships between roots (Vieta's formula) that $p/4=r+s+t$, which can be reduced to $p/4=2r$ per the previous equation, and therefore $p/8$ is a root. However, I'm not sure where to go from here-- performing the substitution with the other coefficients does not seem to yield anything that lets me solve for a root or $p$. For example, we know from the coefficient of $x^0$ that
$$5/4=rs+rt+st=rs+(r+s)(r-s)$$
but there is no obvious substitution that can be made here that would put things in terms of one variable. How do I solve for the roots and $p$ using relationships between roots and the rational roots theorem here? Thanks!","['algebra-precalculus', 'roots', 'polynomials']"
1995512,Isn't probability a branch of combinatorics?,"I've heard it a lot that Probability is a branch of Statistics(which isn't a branch of mathematics) but as far as I know(High School) it appeals more as the branch of Combinatorics though. So, can you kindly explain the reasoning behind considering Probability as a branch of Statistics and not as Combinatorics(& Maths in general).","['combinatorics', 'statistics', 'probability']"
1995531,Projective cubic curve passing 9 points,"This is a problem from our school's algebraic curve course midterm exam. Let $p_1,\dots,p_9$ be nine distinct points on $\mathbb{CP}^{2}$ . None of 3 of them lie on same line, and none of 7 of them lie on same conic. (1) Prove that there exist a cubic $C$ containing all these 9 points. (2) Prove that $C$ is irreducible. (3) Is $C$ unique? Actually I proved (1)  (using 9 $\times$ 10 matrix) and (2) (using Bezout's theorem), but I can't solve (3). Intuitively, if we consider arbitrary two projective cubic curve, then they will meet at nine points and they will satisfy the condition of problem. But I cannot find explicit example. I also tried to show that such $C$ is unique. Suppose not, then we can find linearly inedependent homogeneous cubic polynomials $P,Q$ . Let $R=aP+bQ$ , then $R\neq 0$ for any $(a,b)\neq (0,0)$ and we can choose $a,b$ so that $Z(R)$ contains $p_i$ 's and $q$ which is different from $p_i$ 's. But I cannot find $q$ which gives contradiction. Is $C$ is unique or not? Thanks in advance.","['algebraic-curves', 'elliptic-curves', 'algebraic-geometry']"
1995549,Probability against winning a raffle,"""If there are 10000 raffle tickets, all of which are sold, and you purchased 20 of these tickets, what are the odds against you winning?"" This was a question I got wrong on a recent test which I plan to retake (as an altered version of the original), but I need help understanding how to go about solving this.  I originally thought that all I needed to was take 1 - the probability of winning, but that ended up being incorrect. Any help?",['probability']
1995560,Computing a tricky limit,$$ \lim_{n \to \infty} \frac{1^m + 2^m + 3^m + \cdots + (2n-1)^m }{n^{m+1}} $$ I am kind of stuck since I cannot make it look into a form that would involve the integral of certain function. I know somehow it would be easy if we can compare this limit to a Riemann sum. Any ideas?,['calculus']
1995611,Why isn't $D_\infty$ the set of symmetries of a circle?,"According to Wikipedia, ""the infinite dihedral group Dih∞ is an infinite group with properties analogous to those of the finite dihedral groups."" However, it doesn't appear that this has anything to do with the symmetries of the circle, which surprised me, because that seems like the most natural generalization of the finite-order dihedral groups, which are sets of symmetries of regular polygons. Put another way, since regular polygons ""approach"" becoming a circle as the number of vertices, $n\to\infty$, it seems like $D_\infty$ should be the symmetries of the circle. So what kinds of symmetries does $D_\infty$ represent, and why was this group chosen for extension of the finite dihedral groups over the symmetries of the circle? (Or are they related in some way I'm just not grasping?)","['abstract-algebra', 'group-theory']"
1995678,Determine if a sequence of independent rv's satisfies the Lindeberg condition,"Determine if the following sequences $\left\{A_k\right\}$ of independent r.vs satisfy the Lindeberg condition: $(a.)$ $A_k \sim \text{Poisson}\left(2^{-k}\right)$ $(b.)$ $P(A_k = 1) =  P(A_k = -1) = \dfrac{1-2^{-k}}{2};\quad 
    P(A_k = 2^k) = P(A_k = -2^k) = \dfrac{1}{2^{k+1}}$ My solution: For part $(a.)$: we would show that sequence $A_1, A_2,\ldots$ are NOT uniformly asymptotically negligible, so it does not satisfy Lindeberg condition. Note that since $A_k\sim \text{Poisson}\left(2^{-k}\right), $ $\sigma_{k}^2 = 2^{-k}$. This implies $\max_{k\leq n} \sigma_k^2 = 2^{-1}$. In addition $$\sum_{k=1}^{n} \sigma_k^2 = \sum_{k=1}^{n} 2^{-k} \approx \int_{1}^{n} \frac{1}{2^k} = \frac{-2^{-n}}{\ln2}$$ Therefore, $\displaystyle\lim_{n\rightarrow \infty} \dfrac{\max_{k\leq n} \sigma_k^2}{\sum_{k=1}^{n} \sigma_k^2} = \lim_{n\rightarrow \infty} -2^{n}\ln(2) = \infty > 0$. Thus we're done. For part $(b.)$: due to the given formulas of the discrete probability of $A_k$, $E(A_k) = 0$ for all $k=1,2,\ldots$ Thus 
$$E(A_k^2) = \sigma_k^2=\begin{cases}1,&k=1\\1-2^{-k}+2^k, &k\ge2\end{cases}$$ Thus, $\sum_{k=1}^{n} \sigma_k^2 = 1 +\ldots + (1-2^{-n}+2^n)$ and $\max_{k\leq n} \sigma_{k}^2 = 1 + 2^n - 2^{-n}.$ This implies $\displaystyle \lim_{n\rightarrow \infty} \dfrac{\max_{k\leq n} \sigma_{k}^2}{\sum_{i=1}^{n} \sigma_i^2} = 0$ by dividing both numerator and denominator by $1+2^n - 2^{-n}$, and note that this function is strictly increasing in $n$. Thus, the sequence $A_1, A_2,\ldots$ is uniformly asymptotically negligible. Finally, in order to apply Linderberg-Feller's theorem, it's sufficient to show $\dfrac{1-2^{-n}+2^{n}}{(1 +\ldots + 1-2^{-n}+2^n)^{1/2}}$ converges to $N(0,1)$ in distribution. But I'm getting stuck here. My question: Could someone please help complete my proof above? Otherwise, any inputs on my proof above would also be appreciated.",['probability-theory']
1995752,Understanding higher derivatives as multilinear mappings,"I'm trying to understand how to relate the higher derivatives to multilinear mappings. Let $f$ be a differentiable function. Then, since we have $Df:V\subset \mathbb{R}^n\rightarrow \text{Lin}(\mathbb{R}^n,\mathbb{R}^p) $, can I say that $Df\in \text{Lin}(\mathbb{R}^n,\text{Lin}(\mathbb{R}^n,\mathbb{R}^p))$? Also I'm trying to relate this new way - for me at least - of thinking of higher order derivatives with what I already know, for example calculating the hessian matrix by taking the usual partial derivatives.
The book I'm using has the following theorem to allow me to compute the derivatives of multilinear mappings. So, if I can think of $Df$ as in $\text{Lin}(\mathbb{R}^n\times\mathbb{R}^n,\mathbb{R}^p)$, then by the above theorem, we have $D(Df)(a_1,a_2)(h_1,h_2)=Df(h_1)(a_2)+Df(a_2)(h_2)$. However, I'm not seeing how this relates to the usual simpler calculation of the partial derivatives Any help would be appreciated.","['multivariable-calculus', 'differential-geometry', 'multilinear-algebra']"
1995855,Higher order corrections to saddle point approximation,"I'd like to ask for hints how to obtain higher order corrections to approximations obtained by the saddle point method. References will be also welcome. Unfortunately what comes up when googling is mostly just usual leading order approximation. Let me show my idea how to do it. Consider an integral $I(t)= \int_{\mathbb R} e^{tx^2 - x^4} dx$. I am interested in the limit $t \to \infty$ through complex values. My idea is to expand quartic in the exponential around its stationary point $x_0$ as $a+b(x-x_0)^2-x^4$ and replace $e^{-x^4}$ by $1-x^4$. The result is that I get correct leading order behaviour, but wrong next to leading order corection for some values of argument of $t$. I know that the next to leading order term is wrong because I know the exact form of this integral in terms of Bessel functions and asymptotics of these are known.","['integration', 'asymptotics', 'contour-integration', 'approximation']"
1995917,Recovering connection from parallel transport,"(doCarmo, Riemannian Geometry, p.56, Q2) I want to prove that the Levi-Civita connection $\nabla$ is given by $$ (\nabla_X Y)(p) = \frac{d}{dt} \Big(P_{c,t_0,t}^{-1}(Y(c(t)) \Big) \Big|_{t=t_0}, $$ where $p \in M$, $c \colon I \to M$ is an integral curve of $X$ through $p$, and $P_{c,t_0,t} \colon T_{c(t_0)}M \to T_{c(t)}M$ is the parallel transport along $c$, from $t_0$ to $t$. My approach is to use the uniqueness of the Levi-Civita connection (a theorem proved elsewhere in the textbook) and show that the RHS satisfies all of its properties, i.e. It is an affine connection, It is symmetric, It is compatible with the metric. However, for the first part, I am stuck on proving that $$ \nabla_{fX + gY}Z = f \nabla_X Z + g \nabla_Y Z. $$ So far, I have the following $$ f \nabla_X Z = f \Big( \frac{d}{dt} \Big( P_{c_X,t_0,t}^{-1}(Z(c_X(t)) \Big) \Big|_{t=t_0} \Big), $$ $$ g \nabla_Y Z = g \Big( \frac{d}{dt} \Big( P_{c_Y,t_0,t}^{-1}(Z(c_Y(t)) \Big) \Big|_{t=t_0}  \Big), $$ $$ \nabla_{fX + gY}Z =  \frac{d}{dt} \Big( P_{c,t_0,t}^{-1}(Z(c(t)) \Big) \Big|_{t=t_0}, $$
where $$ c_X (t_0) = c_Y (t_0) = c(t_0) = p, $$ $$ \frac{d c_X}{dt} = X(c_X(t)), $$ $$ \frac{d c_Y}{dt} = Y(c_Y(t)), $$ $$ \frac{d c}{dt} = fX(c(t)) + gY(c(t)). $$ I'm sure the solution is something simple like working in local coordinates but I'm having trouble so any direction would be appreciated.","['manifolds', 'connections', 'smooth-manifolds', 'differential-geometry']"
1995948,Probability that the first cell is empty,"There are three distinctive balls to distribute to 8 cells. Each cell can hold multiple balls. I'm trying to figure out the probability $P(A)$ that, after distribution, the first cell is empty. My thoughts: In total, there are $8^3$ possibilities to distribute the three distinctive balls to the cells, and there are $7^3$ possibilities to distribute the balls to all cells but the first. So $P(A) = 7^3/8^3.$ Is this correct? I'm confused since this could also be the probability of any one cell being empty.",['probability']
1995963,Do we have $\|A\|_F\leq \|B\|_F$ if $-B\preceq A\preceq B$?,"In the question, $A$ is a symmetric matrix, and $B$ is a positive semi-definite matrix. $A\preceq B$ means that $B-A$ is a positive semi-definite matrix. $\|\|_F$ means the Frobenius norm.","['matrices', 'linear-algebra', 'calculus']"
1995964,Convergence of $\frac{|Y_n|}{n}$,"Let $Y_1,Y_2,\dots$ iid r.v. Show that $\dfrac{|Y_n|}{n}\longrightarrow 0$ in probability. $\dfrac{|Y_n|}{n}\longrightarrow 0$ a.s. iff $\mathbb E\left[|Y_1|\right]<\infty .$ Attempt Let $\varepsilon>0$. Then, $$\mathbb P\left(\frac{|Y_n|}{n}>\varepsilon\right)=\mathbb P(|Y_n|>n\varepsilon)$$
Since $\{|Y_{n+1}|>(n+1)\varepsilon\}\subset \{|Y_n|>n\varepsilon\}$, we have that $$\lim_{n\to \infty }\mathbb P(|Y_n|>n\varepsilon)=\mathbb P(Y_\infty =\infty ),$$ Q1) Is $\mathbb P(Y_\infty =\infty )=0$ ? But what would be the sense of $Y_\infty $ ? I think I have to use the fact that $$\mathbb E[|Y_i|]=\int_0^\infty \mathbb P\{|Y_i|>y\}dy,$$ then $\displaystyle\int |Y_i|d\mathbb P<\infty,$
but I don't see how. Q2) any idea?","['independence', 'probability-theory']"
1996000,intersection of hypercube and hypersphere,"There is a number of similar questions already (e.g. this one ), but as far as I can see, none quite cuts it for me. In $n$-dimensional euclidean space, a hypercube $H$ with side lengths $2A$ is centered around the origin. So is a hypersphere $S$ with radius $x$. What is the fraction of volume of the hypercube $H$  that is also inside the hypersphere $S$, that is, what is the volume of $H\cap S$? As calculating the fraction with respect to the hypercube is trivial by just dividing by its volume in the end, it boils down to calculating the volume of the intersection. My first idea was to separate three different cases: If $x<A$ the hypersphere is fully contained in the hypercube. Then, the volume is simply the volume of the hypersphere, for which there are analytical formulae. If $x^2> n \cdot A^2$, the hypercube is fully contained in the hypersphere. In this case, the volume is simply that of the hypercube, that is, $(2A)^n$. For intermediate values of $x$, the intersection is given as the volume of the hypersphere minus $2n$ hyperspherical caps, for which there is also a closed form solution (e.g. here ) After my calculation consistently gave wrong results, I was forced to admit that the case (3) is more difficult than I thought, because as soon as the opening angle of the hypercaps is larger than $\pi/4$, they start to intersect along the edges of the hypercube, whereas the corners are still outside the intersection volume. For $n=3$, this can be seen in this graphic, which was generated by wolframalpha. Thus, the solution proposed in (3) double-counts these volumes. I can't seem to come up with general solution to calculate this, because counting (and calculating) the intersection areas is very tedious. Is there any closed-form, analytic solution available for this problem?","['volume', 'spheres', 'geometry']"
1996045,"Do there exist functions that grow faster than $ax+b$, slower than $a^x$ and still posses these nice congruence properties?","Functions like $f(x)=2x+3$ and $f(x)=3^x-8$ have some very nice properties if it comes to congruences. In particular, if you pick any $n\in\Bbb{N}$ and write down $f(x)\mod n$, you'll see that it's a repeating pattern, with no numbers occuring more than once in each cycle. A clearer, more formal definition due to Greg Martin: A function $h$ defined on the positive integers is called faithfully periodic with period $q$ if it has the property $h(m)=h(n)$ if and only if $n\equiv m\pmod q$. A function $f:\Bbb{N}\to\Bbb{Z}$ is now normal if for every modulus $k\geq 2$, the function $\pi_k\circ f$ is faithfully periodic, where $\pi_k:\Bbb{N}\to\Bbb{Z}/k\Bbb{Z}$ is the natural quotient map. Also, for every modulus $k\geq 2$, let $f_q(k)$ be the period of $\pi_k\circ f$. I have not been able to find any normal functions which grow faster than a linear function, but slower than an exponential function, In particular normal functions $f(n)=O(n^\alpha)$ with $\alpha>1$ Question: Do there exist any such functions? What I've proven so far 1) This is quite obvious, but if $f$ is a normal function with $f(0)=0$, then $\forall n,m\in\Bbb{Z}: f_q(n)\mid m\implies m\mid f(n)$ Proof: set $\pi_k\circ f=h_k$. cleary for all $k$, we have $h_k(0)=0$. Now $h_k(n)=0$ if and only if $f_q(k)\mid n$. Some Intuition about why linear and exponential functions are normal Short and simple: they can be defined as sequences $\{a_n\}_{n=1}^{\infty}$ in such a way that, for all $k\in\Bbb{N}$, we don't need to know the value of $n$ or $a_{n-1}$ to compute $a_n\pmod k$, we only need $a_{n-1}\pmod k$. To be clear, this is just my intuiton. I think it will be easy to prove that such functions are always normal, but not easy to prove that all normal functions 'look' like this.","['functions', 'number-theory', 'congruences', 'modular-arithmetic', 'elementary-number-theory']"
1996058,Two metric space with same Cauchy sequences,"Question: If d,e are equivalent metrics on X, then $\left ( X,d \right )$ and $\left ( X,e \right )$ have the same Cauchy sequences. I've first assumed to the contrary that the metric spaces have different Cauchy sequences. Any hint is appreciated.","['normed-spaces', 'general-topology', 'metric-spaces']"
1996063,Slightly changing the formal definition of continuity of $f: \mathbb{R} \to \mathbb{R}$?,"I'm curious for some perspectives on why it would be wrong to change the definition of continuity of $f: \Bbb R \to \Bbb R$ in the following way: Original definition. $f : \Bbb R \to \Bbb R$ is said to be continuous at $x \in \Bbb R$ if $\forall \epsilon > 0$ $\exists \delta > 0$ such that $|x - a| < \delta \implies |f(x) - f(a)| < \epsilon$ . Altered definition. $f : \Bbb R \to \Bbb R$ is said to be continuous at $x \in \Bbb R$ if $\forall \delta > 0$ $\exists \epsilon > 0$ such that $|x - a| < \delta \implies |f(x) - f(a)| < \epsilon$ . The altered definition is more in line with what I think when I think about continuity intuitively: nearby points are sent to nearby points.  It only makes sense to me to be able to choose ""nearness"" in the domain (i.e., $\forall \delta > 0$ ) and show there is nearness in the codomain (i.e., $\exists \epsilon > 0$ ) to prove intuitively that ""nearby points are sent to nearby points"". Similarly , if $X, Y$ are topological spaces, we say $f: X \to Y$ is continuous if the preimages of open sets are open.  What would be wrong about changing the definition to say that a map is continuous if the images of open sets are open (i.e., $f$ is continuous if it is an open map)?  This is more inline with the intuitive idea of ""nearby points being sent to nearby points"" -- you pick nearness in the domain (i.e., an arbitrary open set) an show nearness in the codomain (i.e., the image is open). Does anyone have any useful remarks?","['general-topology', 'real-analysis', 'continuity']"
1996116,Is $\Bbb C^* \times \Bbb Z$ isomorphic to a subgroup of $\Bbb C^*$?,"I would like to know if $\Bbb C^* \times \Bbb Z$ is isomorphic (as an abelian group) to a subgroup of $\Bbb C^*$. Of course, they are not isomorphic: one is divisible, while the other is not. We can't apply some version of Cantor-Schröder-Bernstein, because it is wrong for the category of abelian groups (see ex. 3.1. here ).
I know that $\Bbb C^* \cong S^1 \times \Bbb R_+^* \cong \Bbb R/\Bbb Z \times \Bbb R$, and that a morphism $f : \Bbb C^* \times \Bbb Z \to \Bbb C^*$ is determined by $f(a,1)$ and $f(a,0)$ for $a \in \Bbb C^*$, since $$f(re^{i\theta};n) = f(\sqrt[n]{r}e^{i\theta/n}\,;1)^n
\qquad (n \geq 1)$$ But I don't know how to go further, even if my problem may be very easy. Thank you very much for your help.","['abelian-groups', 'abstract-algebra', 'group-theory', 'group-isomorphism']"
1996125,Evaluate $\int_0^1 \frac{\log(1-z)\log(1-z^3)}{z^2}dz$,"Integrals of the kind $$\int_0^1 \frac{\log(1-z)\log(1-z^n)}{z^2}dz$$ where $n\geq 1$ is an integer, arises from a natural way when one apply Möbius inversion to get identities realated to $\zeta(2)$ (see my appendix if there are no mistakes), but how Question. Can you state a closed form for $$\int_0^1 \frac{\log(1-z)\log(1-z^3)}{z^2}dz?$$ I am asking for a detailed explanationabout how get the definite integral. Many thanks. I don't know if the general integral was in the literature but my trials with Wolfram Alpha, seems that is very difficult to get particular cases. See this Example. Other case of the indefinite integral, for example $n=5$ also is provided by Wolfram Alpha online calculator when one type integrate (log(1-x)log(1-x^5))/x^2 dx My idea was multiply both formulas of the first paragraph in page 77 from: Benito, Navas, Varona, Möbius inversion from the point of view of flows , Proceedings of the Segundas Jornadas de Teoría de Números, Biblioteca de la Revista Matemática Iberoamericana (2008), then integrating one gets $$\zeta(2)=\int_0^1\sum_{n=1}^\infty\frac{z^{n-1}}{n}dz=\int_0^1 \left(\frac{\log(1-z)}{z^2}\sum_{n=1}^\infty\frac{\mu(n)}{n}\log(1-z^n)\right)dz.$$ Here as you see $\zeta(s)$ is the Riemann's Zeta function and $\mu(n)$ is the Möbius function. And now from there one more time by absolute convergence, I've asked myself what's about these coefficients $$a_n=\int_0^1 \frac{\log(1-z)\log(1-z^n)}{z^2}dz,$$ that for integers $n\geq 1$ satisfy $$\zeta(2)=\sum_{n=1}^\infty\frac{\mu(n)}{n}a_n.$$","['logarithms', 'integration', 'definite-integrals', 'mobius-inversion']"
1996141,"If $f(f(x))=x^2-x+1$, what is $f(0)$?","Suppose that $f\colon\mathbb{R}\to\mathbb{R}$ without any further restriction. If $f(f(x))=x^2-x+1$ , how can one find $f(0)$ ? Thanks in advance.","['functions', 'functional-equations']"
1996165,When is $E[f(X)]=0$ for even functions,"Let $X$ be standard normal and $f$ a function that satisfies $f(0)=0$ $f$ is even $(x-{\rm sign}(x) \cdot a) \cdot x \le f(x) \le (x+{\rm sign}(x) \cdot a) \cdot  x$, for all $x$, and some fixed $a>0$.  Moreover, these bounds are asymptotcily tight. I am either trying to find and example of $f(x)$ such that
\begin{align}
E[f(X)]=0
\end{align}
or that to show that this can not happen. Thanks.","['probability-theory', 'expectation']"
1996217,Intuition about subbasis for a topology,"In general topology the idea of a basis is quite simple. The definition is: Let $X$ be a set, a set $B\subset \mathcal{P}(X)$ is said to be a basis for a topology on $X$ if: For each $x\in X$ there's $U\in B$ such that $x\in U$ . If $x\in U_1\cap U_2$ , with $U_1,U_2\in B$ , then there is $U_3\in B$ such that $x\in U_3$ and $U_3\subset U_1\cap U_2$ . With that, the topology $\tau$ generated by $B$ is defined so that $U\in \tau$ if for each $x\in U$ there's $U_x\in B$ with $x\in U_x\subset U$ . In other words, $\tau$ is the set of all unions of elements of $B$ . Then one proves that $\tau$ is indeed a topology. Obviously this is the natural extension of the open balls we use in metric spaces. It is quite simple to understand and to get some intuition about it. The other definition, I simply can't get any intuition about is the idea of subbasis. The definition is: Let $X$ be a set, a set $S\subset \mathcal{P}(X)$ is said to be a subbasis for a topology on $X$ if the union of all sets on $S$ equals $X$ . In that case, the set $$B = \left\{S_1\cap\dots\cap S_n : S_i\in S, n\in \mathbb{N}\right\},$$ is a basis for a topology $\tau$ in $X$ . In other words $\tau$ is the set of all unions of all finite intersections of elements in $S$ . If on the one hand the idea of basis is quite intuitive and simple to understand based on the simple example of open balls, the idea of subbasis seems quite different. I mean, I know it works. The proof that $\tau$ is a topology is quite simple. What is not simple is to understand the intuition. In that case: what is the intuition about subbasis? Why would anyone consider the object defined that way? Why is it relevant and how can we understand it properly to have some intuition on when we need to use it?","['intuition', 'general-topology', 'definition']"
1996220,Finding abelian extensions of $\mathbb{Q}_{p}$ (using Local Class Field Theory),"Here all the extensions are finite. In local class field theory, one learns that the abelian extensions $\mathbb{Q}_{p}(\zeta)/\mathbb{Q}_{p}$, where $\zeta$ is a $p^{n}$-th root of unity, are in bijective correspondence with the subgroups $(p)\times (1+p^{n}\mathbb{Z}_{p})$ of the multiplicative group $\mathbb{Q}_{p}^{\times}$. Do we know similar descriptions for other 'types' of extensions of $\mathbb{Q}_{p}$? For example, we can play around and wonder what kind of abelian extensions $L_{n}/\mathbb{Q}_{p}$ correspond to the subgroups
\begin{equation}
(p^{2})\times (1+p^{n}\mathbb{Z}_{p})
\end{equation}
and we can ask this for many other subgroups. Also, I wonder if we can detect ramification looking at the these subgroups. For example, it is known that the $p^{n}$-th cyclotomic extensions I mentioned above are totally ramified, and just so happens that the ""$(p)$""-part of the corresponding subgroup has exponent $1$. I did this for a couple of examples, and it looks like an extension corresponding to some subgroup of the form
\begin{equation}
(p^{f})\times H,
\end{equation}
for some subgroup $H$ of $\mathbb{Z}_{p}^{\times}$, has inertia degree $f$. Is this true in general? Thanks a lot.","['number-theory', 'class-field-theory', 'algebraic-number-theory']"
1996253,In what sense is the differential of a linear map is itself?,"Given $R^n$ and $R^k$ and $L$ is a linear map from $R^n$ to $R^k$. I was told that the differential of $L$ at $p$, $dL_p:T_pR^n \to T_{L(p)}R^k$ is $L$ itself. Here $dL_p(v)(g) = v(g\circ L)\  \forall v \in T_pR^n$. This is really confusing since $L$ and $dL_p$ does not even have the same source space. In what sense should they be ""equal""?","['differential-geometry', 'differential-topology']"
1996256,Relationship between areas of circles and spheres,How can the surface area of a sphere be exactly 4 times the area of it's cross-sectional area? This seems too clean; why 4? If I sliced 4 thin circles from the middle of a sphere and stuck them together (and was able to morph them)  would I end up with another hollow sphere?,"['circles', 'spheres', 'trigonometry', 'geometry']"
1996263,A question concerning the directional derivative of a function,"As I understand it, intuitively the directional derivative of a function $f$, at some point, describes its rate of change as one moves along a direction, specified by some vector $\mathbf{v}$, away from that point. With this in mind I am trying to understand the mathematical formalism a bit deeper, but I'm unsure if I am doing so correctly. This is my understanding so far (apologies for any abuse of notation): Let $f:\mathbb{R}^{n}\rightarrow\mathbb{R}$ be some smooth function, and let $c:\mathbb{R}\rightarrow\mathbb{R}^{n}$ be some smooth curve in $\mathbb{R}^{n}$, with coordinates $(x\circ c)(t)\equiv x(t)=(x^{1}(t),\ldots ,x^{n}(t))$. In a sufficiently small neighbourhood of a point $x(0)=a$ we can describe the curve linearly as $$x(t)=a+t\mathbf{v}$$ where $\mathbf{v}$ is the tangent vector to the curve $x(t)$ at the point $x(0)=a=(a^{1},\ldots ,a^{n})$. Given this, we can then determine the rate of change in the function $f$ along the direction defined by $\mathbf{v}$ by evaluating $f$ along the line segment of the curve, $x(t)=a+t\mathbf{v}$, such that $f=(f\circ x)(t)=f(x(t))$. In doing so, we can now consider $f$ as a composite function of $t$, such that, upon taking its derivative with respect to $t$ we will determine its rate of change along $\mathbf{v}$. Indeed, $$\frac{df(x(t))}{dt}\bigg\vert_{t=0}=\sum_{i=1}^{n}\frac{\partial f(x(t))}{\partial x^{i}}\frac{d x^{i}}{dt}\bigg\vert_{t=0}=\nabla f(a)\cdot\mathbf{v}$$ where $\nabla f=\left(\frac{\partial f(x(t))}{\partial x^{1}},\ldots,\frac{\partial f(x(t))}{\partial x^{n}}\right)$ is the gradient of $f$, and $v^{i}=\frac{d x^{i}}{dt}$ are the components of the tangent vector at the point $x(0)=a$. Would this be a correct understanding at all?","['multivariable-calculus', 'intuition', 'curves', 'derivatives']"
1996272,Is the Lebesgue measure of the unit circle $0$?,"I have a two-dimensional Lebesgue integral over $\partial D(0,1)$. I think it should be zero because the two-dimensional measure of the unit circle is $0$. But I'm not sure how to justify this. My idea is to cover the unit circle by countably many boxes of area $\epsilon/2^n$ but I'm not sure how to go about this. Can you please help?","['lebesgue-measure', 'measure-theory']"
1996297,Trace of product of three Pauli matrices,"Consider the four $2\times 2$ matrices $\{\sigma_\mu\}$, with $\mu = 0,1,2,3$, which are defined as follows
$$
\sigma_0 =\left( \begin{array}{cc} 1 & 0 \\ 0 & 1 \end{array}\right)
$$
$$
\sigma_1 =\left( \begin{array}{cc} 0 & 1 \\ 1 & 0 \end{array}\right)
$$
$$
\sigma_2 =\left( \begin{array}{cc} 0 & -i \\ i & 0 \end{array}\right)
$$
$$
\sigma_3 =\left( \begin{array}{cc} 1 & 0 \\ 0 & -1 \end{array}\right)
$$
i.e. the identity matrix and the three Pauli matrices. For the trace of the product of any two matrices $\sigma_\mu$ one has the identity $\text{tr}(\sigma_\mu \sigma_\nu)= 2 \delta_{\mu \nu}$. I was wondering if a similar identity can be derived for the product of three sigma matrices, 
$$
\text{tr}(\sigma_\mu \sigma_\nu \sigma_\lambda)= \;?
$$","['matrices', 'trace', 'linear-algebra']"
1996332,"Does boundedness of $\sigma(T)$ imply boundedness of $T$, $T$ an operator on a Banach space?","let $X$ be a Banach space and suppose $T$ is an operator on $X$. If $T$ is bounded, then clearly $\sigma(T)$ is also bounded in the sense that $r(T) := \sup_{\lambda\in \sigma(T)}|\lambda| < \infty.$ Does this follow the other way, viz. if $r(T) < \infty$ does it follow that $T$ is bounded? In the light of the counter-examples Tsemo and TrialAndError and Ben Wallis' comment, let us add the additional requirement that $r(T) > 0$ so operators with empty spectrum are not considered. I appreciate these answers and the people who wrote them, however we might agree that trivial cases are not generally the most interesting. The fault is mine for the imprecision.","['functional-analysis', 'banach-spaces', 'operator-theory', 'spectral-theory']"
1996353,Linear Algebra Proof $AB=0 \Longrightarrow \det(A)=0$,"Two squared matrices $A$ and $B$, with $B\neq0$, give $AB=0$. Prove that $\det(A)=0$. After trying with some examples, I believe that $A$ needs to have lines that are equal or can be made equal by scalar multiplication, B needs to have columns that are equal or can be made equal by scalar multiplication, like
$$ A=
        \begin{bmatrix}
        1 & 2 \\
        2 & 4 \\
        \end{bmatrix}
$$
and
$$ B=
        \begin{bmatrix}
        2 & 4 \\
        -1 & -2 \\
        \end{bmatrix}
$$ which would mean that $\det(A)=0$ and $\det(B)=0$.
But this is still far from being a proof of anything. Am I on the right track? What would be my next step?",['linear-algebra']
1996363,A problem related to projective plane,"Design 25 cubes so that each cube's six faces display integer numbers in the range 0,1,...,31 such that: On each cube, all the numbers are different. Any given two cubes share exactly one common number. Please give your answer as 25 lines of six numbers.
  Bonus question: Use as small a range of numbers as possible. After seeing the solution, I read that this can be solved using ""Projective plane"". So my questions are: How to solve such a question? (What is the strategy..) How can I decide that a given problem (like this) has a solution? For example, given 25 cubes and a set from 1 to 10.. Logically it's impossible to be solved. What field of maths does ""Projective plane"" belong to? I mean, what is (more general) topic in maths that I have to study to understand ""Projective plane""? Note: I don't know what tags do I have to choose for this question.","['soft-question', 'puzzle', 'combinatorics', 'recreational-mathematics', 'discrete-mathematics']"
1996370,Is limit of $\sin x$ at infinity finite?,"As $x$ tends to infinity, sin x oscillates rapidly between $1$ and $-1$. So we are not able to pinpoint exactly what the limit is. But whatever it is, can we say that it would be finite? Or do we always have to say that its limit doesn't exist or it's undefined?",['trigonometry']
1996465,"Prob. 7, Sec. 20 in Munkres' TOPOLOGY, 2nd ed: The coordinate-wise linear self-map of $\mathbb{R}^\omega$","Here's Prob. 7, Sec. 20 in the book Topology by James R. Munkres, 2nd edition: Consider the map $h \colon \mathbb{R}^\omega \to \mathbb{R}^\omega$ defined in Exercise 8 of Sec. 19; give $\mathbb{R}^\omega$ the uniform topology. Under what conditions on the numbers $a_i$ and $b_i$ is $h$ continuous? a homeomorphism? Now here is Exercise 8 of Sec. 19: Given sequences $\left( a_1, a_2, a_3, \ldots \right)$ and $\left( b_1, b_2, b_3, \ldots \right)$ of real numbers with $a_i > 0$ for all $i$, define $h \colon \mathbb{R}^\omega \to \mathbb{R}^\omega$ by the equation $$ h \left( \left( x_1, x_2, x_3, \ldots \right) \right) = \left( a_1 x_1 + b_1, a_2 x_2 + b_2, a_3 x_3 + b_3, \ldots \right).$$ Show that if $\mathbb{R}^\omega$ is given the product topology, $h$ is a homeomorphism of $\mathbb{R}^\omega$ with itself. What happens if $\mathbb{R}^\omega$ is given the box topology? My effort: For any $x, y \in \mathbb{R}^\omega$, we have $$ \tilde{\rho}(h(x), h(y) ) = \sup \left\{ \ \min \left\{ \ \left\vert a_n \right\vert \left\vert x_n - y_n \right\vert , 1 \right\} \ \colon \ n \in \mathbb{N} \ \right\}.$$ So if $\left\vert a_n \right\vert \leq 1$ for all $n \in \mathbb{N}$, then we obtain $$\tilde{\rho} ( h(x), h(y)) \leq \tilde{\rho}(x,y),$$ and so, given a real number $\varepsilon > 0$, if we take a real number $\delta$ such that $0 < \delta \leq \varepsilon$, then  $$\tilde{\rho} ( h(x), h(y)) < \varepsilon$$ for all $x, y \in \mathbb{R}^\omega$ such that $$ \tilde{\rho}(x,y) < \delta.$$ Hence $h$ is uniformly continuous on $\mathbb{R}^\omega$. Am I right? Now the inverse map $h^{-1} \colon \mathbb{R}^\omega \to \mathbb{R}^\omega$ is defined by $$ h^{-1}(x) = \left( \frac{x_1 - b_1}{a_1}, \frac{x_2 - b_2}{a_2}, \frac{x_3 - b_3}{a_3}, \ldots \right) $$ or $$ h^{-1}(x) = \left( \frac{1}{a_1} x_1 - \frac{b_1}{a_1}, \frac{1}{a_2} x_2 - \frac{b_2}{a_2}, \frac{1}{a_3} x_3 - \frac{b_3}{a_3}, \ldots \right)  \ \ \ \mbox{ for all } \ x \colon= \left( x_1, x_2, x_3, \ldots \right) \in \mathbb{R}^\omega.$$ So, using what we have shown for $h$, we can conclude that, if $\left\vert a_n \right\vert \geq 1$ for all $n \in \mathbb{N}$, then $h^{-1}$ is uniformly continuous on $\mathbb{R}^\omega$. Am I right? Therefore if $\left\vert a_n \right\vert = 1$ for all $n \in \mathbb{N}$, then $h$ is a homeomorphism. Am I right? If what I've derived so far is correct, then does the converse of the above hold as well? PS: Here is my latest insight: Suppose the sequence $\left( a_1, a_2, a_3, \ldots \right)$ is unbounded. Then for any natural number $k$, there is a natural number $n_k$ such that 
  $$ a_{n_k} > k. \tag{0} $$
  And, for any point 
  $$\mathbf{x} \colon= \left( x_n \right)_{n \in \mathbb{N} }, $$
  in $\mathbb{R}^\omega$, and, for any real number $\delta > 0$, if we put 
  $$\mathbf{y} \colon= \left( x_n + \frac{\delta}{2} \right)_{n \in \mathbb{N}}, \tag{1} $$ 
  then 
  $$
\begin{align} 
\bar{\rho} ( \mathbf{x}, \mathbf{y} ) &=  \sup \big\{ \ \min \left\{ \  \lvert x_n - y_n \rvert, \ 1 \ \right\} \ \colon \ n \in \mathbb{N} \  \big\} \\ 
&\leq \sup \big\{ \ \lvert x_n - y_n \rvert \ \colon \ n \in \mathbb{N} \  \big\} \\ 
&= \frac{\delta}{2} \\
&< \delta. 
\end{align} \tag{2}  
$$
  And, if $N$ is a natural number such that $N > 2/\delta$, then we have 
  $$ N \frac{\delta}{2} > 1, \tag{3} $$
  and we see that 
  $$
\begin{align}
\bar{\rho} \big( h \left( \mathbf{x} \right) ,  h \left( \mathbf{y} \right)  \big) &= \bar{\rho} \big( \left( a_n x_n + b_n \right)_{n \in \mathbb{N} },  \left( a_n x_n + b_n \right)_{n \in \mathbb{N} } \big) \\
&= \sup \big\{ \ \min \left\{ \ \left\lvert  \left( a_n x_n + b_n \right) - \left( a_n y_n + b_n \right)  \right\rvert, \ 1 \    \right\} \ \colon \ n \in \mathbb{N} \  \big\}  \\
&= \sup \big\{ \ \min \left\{ \ \left\lvert  a_n \right\rvert \left\lvert  x_n  - y_n \right\rvert , \  1 \    \right\} \ \colon \ n \in \mathbb{N} \  \big\} \\
&= \sup \big\{ \ \min \left\{ \ a_n  \left\lvert  x_n  - y_n \right\rvert , \  1 \    \right\} \ \colon \ n \in \mathbb{N} \  \big\} \qquad  \mbox{ [ because $a_n > 0$ for all $n$ ] } \\
&\geq \sup \big\{ \ \min \left\{ \ a_{n_k}  \left\lvert  x_{n_k}  - y_{n_k}  \right\rvert , \  1 \    \right\} \ \colon \ k \in \mathbb{N} \  \big\}  \\
&\geq \sup \big\{ \ \min \left\{ \ k  \left\lvert  x_{n_k}  - y_{n_k}  \right\rvert , \  1 \    \right\} \ \colon \ k \in \mathbb{N} \  \big\} \qquad  \mbox{ [ using (0) above ] } \\
&= \sup \left\{ \ \min \left\{ \ k \frac{\delta}{2} , \  1 \    \right\} \ \colon \ k \in \mathbb{N} \  \right\} \qquad \mbox{ [ using (1) above ] } \\ 
&\geq  \min \left\{ \ N \frac{\delta}{2} , \  1 \    \right\}  \\
&= 1 \qquad \mbox{ [ using (3) above ] } \\
&> \varepsilon  
\end{align} \tag{4} 
$$ 
  whenever $\varepsilon$ is any real number such that $0 < \varepsilon < 1$. Thus we have shown that if we take $\varepsilon \in (0, 1)$, then, for any real number $\delta > 0$, there is a point $\mathbf{y} \in \mathbb{R}^\omega$ such that 
  $$ \bar{\rho} ( \mathbf{x}, \mathbf{y} )  < \delta, $$
  but 
  $$ \bar{\rho} \big( h \left( \mathbf{x} \right) ,  h \left( \mathbf{y} \right)  \big) > \varepsilon.  $$ Thus if the sequence $\left( a_n \right)_{n \in \mathbb{N} }$ is unbounded (from above), then the function  $h$ cannot be continuous at any point $\mathbf{x}$ of $\mathbb{R}^\omega$. So let us assume that the sequence $\left( a_n \right)_{n \in \mathbb{N} } $ is bounded (above). Then there is a positive real number $M$ such that $a_n < M$ for all $n$. So, for any given real number $\varepsilon > 0$, if we take any real number  $\delta$ such that 
  $$ 0 < \delta < \min\left\{ \  \frac{\varepsilon}{2M}, \ 1 \  \right\}, $$
  then for any points $\mathbf{x}$, $\mathbf{y}$ in $\mathbb{R}^\omega$ which satisfy 
  $$ \bar{\rho}( \mathbf{x}, \mathbf{y} ) < \delta, $$
  we see that for each $n \in \mathbb{N}$, we have the inequality
  $$ \min \left\{ \ \left\lvert x_n - y_n \right\rvert, \ 1 \ \right\} \leq \bar{\rho}(\mathbf{x}, \mathbf{y} ) < \delta <  1, $$ 
  and so 
  $$ \min \left\{ \ \left\lvert x_n - y_n \right\rvert, \ 1 \ \right\}  = \left\lvert x_n - y_n \right\rvert, $$ 
  and hence 
  $$ \left\lvert x_n - y_n \right\rvert < \frac{\varepsilon}{2M}. $$
  Therefore, 
  $$ 
\begin{align}
\bar{\rho}\left( h(\mathbf{x}), h(\mathbf{y}) \right) &= \sup \left\{ \ \min \left\{ \ a_n \left\lvert x_n - y_n \right\rvert, \ 1 \ \right\} \ \colon \ n \in \mathbb{N} \ \right\} \\
&\leq \sup \left\{ \ \min \left\{ \ M \left\lvert x_n - y_n \right\rvert, \ 1 \ \right\} \ \colon \ n \in \mathbb{N} \ \right\} \\
&\leq M \sup \left\{ \ \min \left\{ \  \left\lvert x_n - y_n \right\rvert, \ 1 \ \right\} \ \colon \ n \in \mathbb{N} \ \right\} \\
&= M \sup \left\{ \ \left\lvert x_n - y_n \right\rvert \ \colon \ n \in \mathbb{N} \ \right\} \\
&\leq M  \frac{\varepsilon}{2M} \\
&= \frac{\varepsilon}{2} \\
&< \varepsilon.
\end{align} 
$$
  Hence $h$ is (uniformly) continuous (on all of $\mathbb{R}^\omega$). Is this proof correct. If so, then is each and every step in it correct and clear enough? If not, then where lies the problem?",['general-topology']
1996466,Find the last digit of $7^{7^{7^7}}$,"I was trying to solve this equation but I couldn't find a way to prove that this number ends with a 3 (my teacher has given me the answer).
Can someone explain me why? $7^{7^{7^{7}}}$",['discrete-mathematics']
1996515,Does Hodge-star commute with metric connections?,"Let $E $ be a smooth oriented vector bundle over a manifold $M$ . Suppose $E$ is equipped with a metric $\eta$ , and a compatible connection $\nabla$ . Denote the dimension of $E$ 's fibers by $d$ . Let $\Lambda_k(E)$ denote the exterior algebra bundle of $E$ of degree $k$ .
The orientation and metric on $E$ induce a Hodge-star operator: $ \star_k:\Lambda_k(E) \to \Lambda_{d-k}(E)$ . $\nabla$ induce a connection on $\Lambda_k(E)$ (which we also denote by $\nabla$ ). Note that this induced connection is compatible with the metric on $\Lambda_k(E)$ by $\eta$ . Question: Does $\star,\nabla$ commute? i.e, is it true that $ \star_k (\nabla_X  \beta)=\nabla_X (\star_k \beta)$ for every $\beta \in \Lambda_k(E),X \in \Gamma(TM)$ ? It can be shown that the answer is positive if and only if $\nabla_X (\star_0 1)=0$ (for every $X \in \Gamma(TM)$ ): Step I: We reduce the assertion to the case $k=0$ (see details below). Step II: Further reduction to $\nabla_X (\star_0 1)=0$ : I think I can verify $\nabla_X (\star_0 1)=0$ in the case where $\nabla$ is flat (See step III below). However, I am interested in the general case. Proof of Step II: Let $\beta \in  \Lambda_0(E)=C^{\infty}(M)$ . $$ (1) \, \, \star_0 (\nabla_X  \beta)=\star_0 \big((\nabla_X  \beta) \cdot 1\big) = (\nabla_X  \beta) \cdot (\star_0 1) $$ Also, $$ (2) \, \, \nabla_X (\star_0 \beta)= \nabla_X (\star_0 (\beta \cdot 1))=\nabla_X \big(\beta \cdot (\star_0   1)\big)=(\nabla_X \beta) \cdot (\star_0 1 )+ \beta \cdot \nabla _X (\star_0 1),$$ so by equations $(1),(2)$ above, $\star_0 (\nabla_X  \beta)=\nabla_X (\star_0 \beta)$ ,  if and only if $\nabla_X (\star_0 1)=0$ . Proof of the reduction to the case $k=0$ (Step I): Recall the Hodge-star is defined via $$ \star_0 \langle v,w \rangle= w \wedge \star_k v$$ for every $v,w \in \Lambda_k(E)$ . Let $v,w \in \Lambda_k(E)$ . Then, $$ (1)  \, \,\nabla_X (v \wedge \star_k w)=\nabla_X v \wedge \star_k w+ v \wedge \nabla_X(\star_k w)=\star_0  \langle \nabla_X v,w \rangle+v \wedge \nabla_X(\star_k w)$$ Moreover, $$ (2) \, \, \nabla_X (v \wedge \star_k w)=\nabla_X (\star_0 \langle v,w \rangle) \stackrel{(*)}{=} \star_0 \big(\nabla_X  \langle v,w \rangle\big)=\star_0 \big(  \langle \nabla_X v,w \rangle+  \langle v, \nabla_X w \rangle\big)=$$ $$ \star_0  \langle \nabla_X v,w \rangle + \star_0 \langle v, \nabla_X w \rangle$$ Where equality $(*)$ is exactly the statement for $k=0$ . Equalities $(1),(2)$ imply: $$  v \wedge \nabla_X(\star_k w)=\star_0 \langle v, \nabla_X w \rangle=v \wedge \star_k (\nabla_X w).$$ The uniqueness of the Hodge_star imply $\nabla_X(\star_k w) =  \star_k (\nabla_X w)$ . Proof of step III: $\nabla$ is flat $\Rightarrow$ $\nabla_X (\star_0 1)=0$ . We can work locally: Since $\nabla$ is flat, parallel transport is path-independent (see here ), so we can build a positively-oriented parallel orthonormal frame for $E$ over a small enough neighbourhood around each point in $M$ . Given such frame $E_i$ , we have $\nabla_X E_i=0$ . Thus, $$ \nabla_X (\star_0 1)=\nabla_X (E_1 \wedge \dots \wedge E_d )=\sum_i E_1 \wedge \dots \wedge \nabla_X E_i \wedge \dots \wedge E_d=0.$$","['vector-bundles', 'connections', 'riemannian-geometry', 'differential-geometry']"
1996516,Invariant measures of the doubling map on the closed interval,"Consider the doubling map $g\colon [0,1]\to [0,1]$ given by $g(x)=2x \, {\rm mod}\; 1$. It is clearly discontinuous at 1/2. However, its counterpart $G$ on the circle $G(e^{2\pi i \theta}) = e^{4\pi i \theta}$ ($\theta\in [0,1)$) is continuous therefore $G$ has many invariant measures. Very often it is claimed in ergodic theory books that one may remove discontinuity of $g$ by passing to the circle (by identifying the end-points of $[0,1]$). It is however not clear to me whether this operation affects the $g$-invariant measures or not. Is there a one-to-one correspondence between $g$-invariant measures on $[0,1]$ and $G$-invariant ones on the circle? It seems to me that this could be done if we took into account only those $g$-invariant measures whose probability distribution functions vanish at 0. Do I get this right? Layman's explanation concerning passing from the interval to the circle in the case of the doubling map would be highly appreciated.","['invariance', 'ergodic-theory', 'measure-theory']"
1996552,Any more cyclic quintics?,"Thursday, Novemeber 10, 2016: I found the method of Gauss written up in Galois Theory by David Cox , chapter 9, section 2. The method lends itself to computer programming, otherwise your eyes start to blur after a few of the calculations. I posted an answer with polynomials extending the primes up to 311. Gauss, clever guy. To save space, here are just the polynomials for primes $p \equiv 1 \pmod {10}$ up to $1000.$ =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

jagy@phobeusjunior:~$ ./quintic_cyclic_gauss_loop | grep exps
  x^5 + x^4 - 4 x^3 - 3 x^2 + 3 x + 1   p  11 p.root  2 exps 10^k  d  =  11^4
  x^5 + x^4 - 12 x^3 - 21 x^2 + 1 x + 5   p  31 p.root  3 exps 6^k  d  =  5^2 31^4
  x^5 + x^4 - 16 x^3 + 5 x^2 + 21 x - 9   p  41 p.root  6 exps 3^k  d  =  3^6 41^4
  x^5 + x^4 - 24 x^3 - 17 x^2 + 41 x - 13   p  61 p.root  2 exps 21^k  d  =  29^2 61^4
  x^5 + x^4 - 28 x^3 + 37 x^2 + 25 x + 1   p  71 p.root  7 exps 23^k  d  =  23^2 71^4
  x^5 + x^4 - 40 x^3 + 93 x^2 - 21 x - 17   p  101 p.root  2 exps 32^k  d  =  17^2 101^4
  x^5 + x^4 - 52 x^3 - 89 x^2 + 109 x + 193   p  131 p.root  2 exps 18^k  d  =  79^2 131^4
  x^5 + x^4 - 60 x^3 - 12 x^2 + 784 x + 128   p  151 p.root  6 exps 23^k  d  =  2^18 151^4
  x^5 + x^4 - 72 x^3 - 123 x^2 + 223 x - 49   p  181 p.root  2 exps 17^k  d  =  7^2 149^2 181^4
  x^5 + x^4 - 76 x^3 - 359 x^2 - 437 x - 155   p  191 p.root  19 exps 11^k  d  =  5^2 11^2 191^4
  x^5 + x^4 - 84 x^3 - 59 x^2 + 1661 x + 269   p  211 p.root  2 exps 26^k  d  =  31^2 67^2 211^4
  x^5 + x^4 - 96 x^3 - 212 x^2 + 1232 x + 512   p  241 p.root  7 exps 11^k  d  =  2^16 11^2 241^4
  x^5 + x^4 - 100 x^3 - 20 x^2 + 1504 x + 1024   p  251 p.root  6 exps 2^k  d  =  2^18 5^4 251^4
  x^5 + x^4 - 108 x^3 - 401 x^2 - 13 x + 845   p  271 p.root  6 exps 12^k  d  =  5^2 13^4 271^4
  x^5 + x^4 - 112 x^3 - 191 x^2 + 2257 x + 967   p  281 p.root  3 exps 6^k  d  =  193^2 281^4
  x^5 + x^4 - 124 x^3 + 535 x^2 - 413 x - 539   p  311 p.root  17 exps 11^k  d  =  7^4 13^2 311^4
  x^5 + x^4 - 132 x^3 - 887 x^2 - 1843 x - 1027   p  331 p.root  3 exps 13^k  d  =  13^2 31^2 331^4
  x^5 + x^4 - 160 x^3 + 369 x^2 + 879 x - 29   p  401 p.root  3 exps 26^k  d  =  29^2 401^4 433^2
  x^5 + x^4 - 168 x^3 + 219 x^2 + 3853 x - 3517   p  421 p.root  2 exps 32^k  d  =  223^2 239^2 421^4
  x^5 + x^4 - 172 x^3 - 724 x^2 + 1824 x + 1728   p  431 p.root  7 exps 47^k  d  =  2^20 3^4 431^4
  x^5 + x^4 - 184 x^3 - 129 x^2 + 4551 x + 5419   p  461 p.root  2 exps 13^k  d  =  163^2 461^4 491^2
  x^5 + x^4 - 196 x^3 + 59 x^2 + 2019 x + 1377   p  491 p.root  2 exps 32^k  d  =  3^4 17^2 229^2 491^4
  x^5 + x^4 - 208 x^3 - 771 x^2 + 4143 x + 2083   p  521 p.root  3 exps 24^k  d  =  61^2 521^4 577^2
  x^5 + x^4 - 216 x^3 + 1147 x^2 - 805 x - 2629   p  541 p.root  2 exps 11^k  d  =  11^2 311^2 541^4
  x^5 + x^4 - 228 x^3 + 868 x^2 + 3056 x - 7552   p  571 p.root  3 exps 2^k  d  =  2^22 31^2 571^4
  x^5 + x^4 - 240 x^3 + 1755 x^2 - 3731 x + 2399   p  601 p.root  7 exps 17^k  d  =  5^2 13^2 17^2 601^4
  x^5 + x^4 - 252 x^3 + 2095 x^2 - 5785 x + 5069   p  631 p.root  3 exps 24^k  d  =  89^2 631^4
  x^5 + x^4 - 256 x^3 - 564 x^2 + 5328 x - 5120   p  641 p.root  3 exps 21^k  d  =  2^16 5^2 61^2 641^4
  x^5 + x^4 - 264 x^3 - 185 x^2 + 16837 x + 4851   p  661 p.root  2 exps 32^k  d  =  3^16 7^2 661^4
  x^5 + x^4 - 276 x^3 - 1299 x^2 + 5329 x + 15581   p  691 p.root  3 exps 11^k  d  =  379^2 397^2 691^4
  x^5 + x^4 - 280 x^3 + 2047 x^2 - 3791 x + 1699   p  701 p.root  2 exps 23^k  d  =  17^2 19^2 23^2 701^4
  x^5 + x^4 - 300 x^3 - 2313 x^2 - 3761 x - 571   p  751 p.root  3 exps 11^k  d  =  41^2 631^2 751^4
  x^5 + x^4 - 304 x^3 + 2831 x^2 - 8925 x + 8775   p  761 p.root  6 exps 3^k  d  =  3^4 5^2 23^2 761^4
  x^5 + x^4 - 324 x^3 - 3471 x^2 - 12431 x - 13603   p  811 p.root  3 exps 12^k  d  =  7^4 47^2 811^4
  x^5 + x^4 - 328 x^3 - 1215 x^2 + 3573 x + 2179   p  821 p.root  2 exps 32^k  d  =  37^4 109^2 821^4
  x^5 + x^4 - 352 x^3 - 2361 x^2 + 4257 x + 9967   p  881 p.root  3 exps 29^k  d  =  29^2 881^4 953^2
  x^5 + x^4 - 364 x^3 - 2988 x^2 - 1392 x + 9856   p  911 p.root  17 exps 22^k  d  =  2^18 7^2 11^2 911^4
  x^5 + x^4 - 376 x^3 + 3877 x^2 - 13445 x + 15271   p  941 p.root  2 exps 12^k  d  =  191^2 941^4
  x^5 + x^4 - 388 x^3 + 1476 x^2 + 8304 x + 7168   p  971 p.root  6 exps 2^k  d  =  2^20 7^2 13^2 971^4
  x^5 + x^4 - 396 x^3 + 2101 x^2 + 8039 x - 1819   p  991 p.root  6 exps 30^k  d  =  107^2 991^4 1399^2

=============================================================================================================== ORIGINAL QUESTION: I should emphasize that I am interested in quintics with five real irrational roots, Galois group cyclic $\mathbb Z_5,$ such that the roots can be expressed as sums of roots of unity (in conjugate pairs), therefore as sums of cosines of rational multiples of $\pi.$ The wording at the wikipedia section on solvable cyclic quintics suggests that there is an infinite sequence of such examples as they display. However, they give no source for this sub-section. As you will see below, i had no trouble extending their recipe for primes $101$ and $131,$ but the items i found for prime $151$ have the wrong Galois groups. I have jumped to prime $181$ and bigger $p = 10 n + 1,$ we will see what happens. I have stuck with their recipe...note that, by a strict integer translation, it is reasonable to also consider $x^5 + 2 x^4 + more,$ or $x^5 + 3 x^4 + more,$ or $x^5 + 4 x^4 + more.$ There is plenty of literature on $x^5 + e x^3 + stuff.$ Oh, with $p = 10 n + 1$ prime, our polynomial is
$$ x^5 + x^4 - 4 n x^3 + a x^2 + b x + c $$ i have been assuming that we want the discriminant to be a square, in particular $w^2 p^4,$ where $w$ is not divisible by $p.$ The questions are: where did wikipedia find this material, also are there more. https://en.wikipedia.org/wiki/Quintic_function#Other_solvable_quintics How to solve a cyclic quintic in radicals? Solve this tough fifth degree equation. $$ x^5 + x^4 - 4  x^3 - 3  x^2 + 3  x + 1 $$ 
$$ \Delta =  11^4 $$
$$  $$
$$ x^5 + x^4 - 12  x^3 - 21  x^2 +  x + 5  $$ 
$$ \Delta = 5^2 \;  31^4 $$
$$  $$
$$   x^5 + x^4 - 16  x^3 + 5  x^2 + 21  x - 9   $$ 
$$ \Delta = 3^6 \;  41^4 $$
$$  $$
$$ x^5 + x^4 - 24  x^3 - 17  x^2 + 41  x - 13   $$ 
$$ \Delta = 29^2 \;  61^4 $$
$$  $$
$$ x^5 + x^4 - 28  x^3 + 37  x^2 + 25  x + 1  $$ 
$$ \Delta = 23^2 \;  71^4 $$
$$  $$
$$ x^5 + x^4 - 40  x^3 + 93  x^2 - 21  x - 17  $$ 
$$ \Delta = 17^2 \;  101^4 $$
$$  $$
$$  x^5 + x^4 - 52  x^3 - 89  x^2 + 109  x + 193  $$ $$ \Delta = 79^2 \;  131^4 $$
$$  $$
Tito(151)
$$ x^5 + x^4 -60  x^3    -12  x^2   + 784  x   + 128  $$ 
$$ \Delta =  2^{18} \;  151^4 $$
$$  $$
$$ x^5 + x^4 -72  x^3    -123  x^2   + 223  x     -49  $$ 
$$ \Delta = 7^2 \; 149^2 \;  181^4 $$
$$  $$
Emma Lehmer(191)
$$ x^5 + x^4 - 76  x^3    -359  x^2   - 437  x   - 155  $$ 
$$ \Delta =   5^2 \; 11^2   \;  191^4 $$
$$  $$ =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=","['number-theory', 'galois-theory']"
