question_id,title,body,tags
486434,"Normal space- equivalent condition: $\forall U, V$ - open $: U \cup V = X \ \ \ \exists F \subset U \ , G \subset V$ - closed $: F \cup G = X$","Could you help me prove that $X$ is normal $\iff$ for all open $U, V$such that $U \cup V = X$ there are closed $F \subset U,\ G \subset V,\ F \cup G = X?$ I've been trying to prove it using other equivalent condition for $X$ to be normal, namely that $\forall F \subset U,\ \ \ $ $F$-closed, $U$-open $\exists V$-open $F \subset V \subset \overline{V} \subset U$, but I keep failing. Could you help me with that?","['general-topology', 'separation-axioms']"
486476,Direct Sum of vector subspaces,"How is direct sum of two vector subspaces different from the sum of two vector subspaces i.e. how is $X\oplus Y$ different from $X + Y$, where $X, Y$ are subspaces.",['linear-algebra']
486484,Solving a radical equation $\sqrt{x+1} - \sqrt{x-1} = \sqrt{4x-1}$,"$$
\sqrt{x+1} - \sqrt{x-1} = \sqrt{4x-1}
$$ How many solutions does it have for $x \in \mathbb{R}$? I squared it once, then rearranges terms to isolate the radical, then squared again.
I got a linear equation, which yielded $x = \frac54$, but when I put that back in the equation, it did not satisfy. So I think there is no solution, but my book says there is 1. Can anyone confirm if there is a solution or not?","['radicals', 'algebra-precalculus']"
486487,"$v_1,v_2$ are eigenvectors of $A$. Is it true that $v_1-v_2$ is eigenvector of $A$?","Let $A \in \mathcal{M}_{12 \times 12}$ and let $v_1,v_2$ be eigenvectors of $A$ such that $Av_1 = v_1$ and $Av_2 = 2v_2$. Is it true that vector $v_1 - v_2$ is not eigenvector of $A$? My answer: We have $A(v_1 - v_2) = Av_1 - Av_2 = v_1 - 2v_2$. Let suppose that $v_1-v_2$ is eigenvector of $A$. So exists $\lambda \neq 0 \in \mathbb{R} $ such that $v_1 - 2v_2 = \lambda (v_1 - v_2)$ hence $(1- \lambda)v_1 + (\lambda - 2)v_2 = 0$. Of course, $v_1,v_2$ are linear independenc so $\lambda =1$ and $\lambda=2$. We have conflict, so the answer is FALSE. But answer in my book is TRUE. Could you tell me why?","['linear-algebra', 'eigenvalues-eigenvectors', 'solution-verification']"
486499,Transitiveness of set sizes,"Given that:
$$|A|\le|B|<|C|$$
Prove that:
$$|A|<|C|$$ I proved that:
$$|A|\le|C|$$
By showing a $1:1$ function from $A$ to $C$, in the following way:
$$\exists f:A\to B, \exists g:B\to C$$
$f$ and $g$ are $1:1$,
So their composition, $g \circ f$ is $1:1$ too. Now I need to show that no onto function exists from $A$ to $C$.","['discrete-mathematics', 'elementary-set-theory']"
486506,Representation of all numbers that bigger than $12$ by $3x+7y$ proof,"I found an exercise in my book that requested from me to proof that all numbers that bigger than $12$ can be represented by: $3x+7y$ They requested an induction proof,and i decided to share my answer with you,just to be sure about it. Answer: Base Case: we will check three base cases,$n=12,13,14$: 1.for $n=12$: $12=3x+7y \Rightarrow x=4,y=0$ 2.for $n=13$: $13=3x+7y \Rightarrow x=2 , y=1$ 3.for n=14: $14=3x+7y \Rightarrow x=0,y=2$ we can assume that: $n-1=3x+7y$ $∀n-1>11.$ Induction step: We know that modulus 3 divide all the numbers to three groups of numbers: $A=\{n|n≡0(\mod3)\}$ $B=\{n|n≡1(\mod3)\}$ $C=\{n|n≡2(\mod3)\}$ From the base case we can assume: $∀a ∈ A:∃ n=3x$ $∀b ∈ B:∃ n=3x+7y$ $∀c ∈ C:∃ n=3x+14$ From that we can assume that: if $n ∈ A$ and $n-1 > 11$ then $n-1 ∈ C$. if $n ∈ B$ and $n-1 > 11$ then $n-1 ∈ A$. if $n ∈ C$ and $n-1 > 11$ then $n-1 ∈ B$. Is there any mistakes? Is that a legit induction proof?","['induction', 'discrete-mathematics']"
486533,Calculating determinant with real number on diagonal and units everywhere else,"I'm solving a problem and I'm having difficulties in calculation of the determinants of two matrices. There is two $N\times N$ matrices: $$\left(
  \begin{array}{cccc}
    a & 1 & \ldots & 1 \\
   1 & a & \ldots & \vdots \\
    \vdots & \ldots & \ddots & 1 \\
    1 & \ldots & 1 & a \\
  \end{array}
\right)$$
where $a\in \mathbb{R}$ and
$$\left(
  \begin{array}{cccc}
    a_1 & 1 & \ldots & 1 \\
   1 & a_2 & \ldots & \vdots \\
    \vdots & \ldots & \ddots & 1 \\
    1 & \ldots & 1 & a_n \\
  \end{array}
\right)$$
where $a_1,\ldots,a_n\in \mathbb{R}$ I've tried to get recursive formula, but I have no result. If someone could help or give me any links I would be grateful.","['matrices', 'linear-algebra', 'determinant']"
486562,Minimum size of the generating set of a direct product of symmetric groups,"Let $m$ and $n$ be positive integers. Let $S_m$ and $S_n$ be the symmetric groups on the sets $\{1,\dots,m\}$ and $\{1,\dots,n\}$, respectively. What is the minimum size of a generating set for the direct product $S_m\times S_n$?","['permutations', 'group-theory', 'abstract-algebra']"
486568,How can evaluating the limit of function give a different result after rationalizing it?,"One of the examples in Calculus: A complete course is finding $\lim_{x\to \infty}  (\sqrt{x^2+x}-x)$. At first it seems to produce a meningless $\infty-\infty$, but by rationalizing it we eventually come up with $1\over2$. What I don't understand is how it is possible to derive different results depending on the form of the function, since from my understanding two equivalent functions should yield the same result.","['calculus', 'infinity', 'limits']"
486591,Every quotient of a number ring is finite,"Let $K$ be a number field, i.e. a subfield of $\mathbb{C}$ of finite degree over $\mathbb{Q}$. Let $\mathscr{O}_K$ be the ring of integers of $K$, i.e. algebraic integers which are in $K$. Let $I$ be an ideal of $\mathscr{O}_K$. I read many times that the quotient $\mathscr{O}_K/I$ is obviously/clearly a finite ring, but i've never seen a proof. Could someone suggest me how to see this?",['number-theory']
486596,Finding all alternating bilinear $T$ that preserve a certain group of isometries of $\mathbb{R}^{n+1}$,"Let $$G=\left\{\begin{pmatrix} H & 0 \\ 0 & 1\end{pmatrix} \ | \ H\in O(n), HJ=JH \right\}\subset \mathrm{Lin}(\mathbb{R}^{n+1},\mathbb{R}^{n+1}) $$ where: $n=2m$, $J$ is the standard complex structure on $\mathbb{R}^{2m}$ $\left(\text{that is}, J=\begin{pmatrix} 0 & 1 \\ -1 & 0\end{pmatrix}\right)$ and $O(n)$ is the orthogonal group. I need help with this: Find all antisymmetric bilinear $\mathbb{R}^{n+1}$-valued functions T on $\mathbb{R}^{n+1}\times \mathbb{R}^{n+1}$ such that $$g\circ T(u,v)=T(g(u),g(v))$$ for all $g\in G$, $u,v\in\mathbb{R}^{n+1}$. I tried a coordinate approach but it got too messy and I arrived at expressions that say nothing to me. I suspect that (for instance, if $m=1$ ($n=3$)), $T$ acts as a wedge product on pairs of vectors of the $xy$-plane, but that's all I've been able to tell. I'll appreciate any help.","['linear-algebra', 'multilinear-algebra', 'differential-geometry']"
486624,Question regard the notion of almost sure convergence,"Consider an $n\times m$ matrix with i.i.d. entries each having zero mean and variance $1/n$. Let $Y = X^TX$. By the strong law of large numbers, we know that the $(i,j)$ entry of $Y$ goes almost surely to $\delta_{i,j}$ (the Kronecker delta) for all $1\leq i,j\leq m$ as $n\to\infty$. Now, in some book the authors claim that the matrix $Y$ goes almost surely to the identity matrix when $m$ is fixed . My first question : What does it means that some matrix goes almost surely (or even in probability) to another matrix? Does it means that the union of all the events of deviations of each entry goes to zero (in case of convergence in probability)? My second question : Actually this question depends on the answer to the previous question, but, assuming that the notion of matrix convergence is as I ""described"" in my previous question, then I wonder why $m$ is must be fixed?","['random-variables', 'probability-theory', 'law-of-large-numbers', 'random-matrices', 'probability']"
486627,Proof of convolution,"I would like to know how I could prove the following convolution:
$$
D (f*g) =D f* g =f* Dg
$$","['convolution', 'derivatives']"
486636,Hausdorff space in which each point has a compact neighbourhood is locally compact,"Could you help me prove the following fact? I've been trying to prove it and I've searched for a hint in Englking's book, but I haven't come up with anything: If $X$ is a Hausdorff space and each $x \in X$ has at least one compact neighbourhood, then $X$ is locally compact. $U$ is a neighbourhood of $x \in X$ $\iff$ $\exists V$ - open $: x \in V \subset U$. $X$ is locally compact $\iff$ each $x \in X$ has a basis of compact neighbourhoods.","['general-topology', 'separation-axioms', 'compactness']"
486652,Induction question: $P(n): 2 + 4 + ... + 2n = (n + 2)(n - 1)$ for any integer $n \ge 2$.,"I have to find an error in an induction exercise and I believe the error is in the basic step. Here is what I have, $P(n): 2 + 4 + ... + 2n = (n + 2)(n - 1)$ for any integer $n \ge 2$. My steps: $P(2): 2n = (n + 2)(n - 1) \implies 2(2) = (2 + 2)(2 - 1) \implies 4 = 4,$ which is true $P(3): 2n = (n + 2)(n - 1) \implies 2(3) = (3 + 2)(3 - 1) \implies 6 = 10$, which is false. This is why I believe the basic step has an error. Is this correct? Thanks","['induction', 'discrete-mathematics']"
486662,"Find the values of $x$, where $x \in \Bbb C$, for which $x^4-1 =0$","Find the values of $x$, where $x \in \Bbb C$, for which $$x^4-1 =0$$ I can see that $x^4-1 = (x^2-1)(x^2+1)=0$ So one set of roots can be taken from $$x^2-1=0$$$$ \Rightarrow x=\pm1$$ However, for $$x^2+1=0 $$$$\Rightarrow x=\sqrt{-1}$$$$\Rightarrow x=i$$ So from where does the last given answer of $-i$ come? I thought $i=\sqrt{-1}$ and $i^3=-i$, so can you please explain in what way does $-i$ work as a solution?","['complex-numbers', 'algebra-precalculus']"
486667,"Proving that if $\bar{R}$ transitive (where $R$ equivalence relation), $|A/R|=1$",Let $A\neq\emptyset$ a set and $R\subseteq A\times A$ equivalence relation s.t the complementary relation $\bar{R}=(A\times A)\setminus R$ is transitive. Prove that $|A/R|=1$ (cardinality of quotient set is 1). There has to be a contradiction if the cardinality is bigger then 1 but I haven't found it yet. I'll be glad for any hint.,"['relations', 'equivalence-relations', 'discrete-mathematics', 'elementary-set-theory']"
486668,"$x^2 +y^2 + z^2$ is irreducible in $\mathbb C [x,y,z]$","Is $x^2 +y^2 + z^2$ irreducible in $\mathbb C [x,y,z]$? As $(x^2+y^2+z^2)= (x+y+z)^2- 2(xy+yz+zx)$, $$(x^2+y^2+z^2)=\left(x+y+z+\sqrt{2(xy+yz+zx)}\right)\left(x+y+z-\sqrt{2(xy+yz+zx)}\right).$$ But how to show that none of these factors belong to $\mathbb C [x,y,z]$?","['irreducible-polynomials', 'abstract-algebra', 'polynomials']"
486674,Need a thorough explanation of this combination problem,"From a group of 5 women and 7 men, how many different committees consisting of 2 women and 3 men can be formed? This one's easy. There's two experiments (ex 1 = committees of men)(ex 2 = committees of women) so it's just $5 \choose 2$$7 \choose 3$. But the next question is What if 2 of the men are feuding and refuse to serve on the committee together? I don't understand this question at all.",['combinatorics']
486681,Is $\sqrt{x^2}$ always $\pm x?$,"I am wondering if this holds in every single case:
 $$\sqrt{x^2} = \pm x$$ Specifically in this case: $$\sqrt{\left(\frac{1}{4}\right)^2}$$ In this one we know that the number is positive before squaring, so after removing the square and root shouldn't we just have: $$\frac{1}{4}$$ Also in a case such as this: $$\sqrt{(\sqrt{576})-8}$$  we have $$\sqrt{\pm24-8}$$ which is either $\sqrt{16}$ or $\sqrt{-32}$ but since we care about real, principal roots only, can't we say that $\sqrt{16}$ is actually $4$ but not $-4.$ Am I mistaken somewhere in my reasoning? Thanks!","['inverse', 'algebra-precalculus']"
486716,Determine the number of zero points of $z^8-5z^3+z-2$ within the open unit circle (Rouché?),"How many zero points does the polynomial $z^8-5z^3+z-2$ have within the open unit circle? Hello, consider
$$
\gamma\colon [0,2\pi]\to\mathbb{C}, \varphi\longmapsto\exp(i\varphi)
$$
and define the following functions
$$
f(z):=-5z^3,~~~~~~~~~~g(z):=z^8+z-2.
$$ This two functions are holomorphic and for all $z\in\mbox{rg}(\gamma)$ it is
$$
\lvert f(z)\rvert=5,~~~~~~~~~~\lvert g(z)\rvert\leq 4,
$$
so it is $\lvert g\rvert < \lvert f\rvert$ on $\mbox{rg}(\gamma)$. Concerning to the theorem of Rouché the number of zero points of $f+g$ is the same as that of $f$ and this number is given by
$$
\frac{1}{2\pi i}\int_{\gamma}\frac{f'(z)}{f(z)}\, dz.
$$
It is
$$
\frac{f'(z)}{f(z)}=\frac{3}{z},~~~~~~~~~~\frac{1}{2\pi i}\int_{\gamma}\frac{3}{z}\, dz=3
$$
So the given polynomial does have 3 zero points within the open unit circle. Would be great to get a confirmation whether my result is correct. With kindly regards! math12","['roots', 'complex-analysis']"
486741,why is it constant?,"$f$ is a function from $\Bbb R$ to  $\Bbb R$:
$\frac{f(x+y)}{(x+y)} - (x+y)^2 =  \frac{f(x-y)}{(x-y)} - (x-y)^2$ for all $x$ and $y$ the solution book just says ""Thus  $\frac{f(x)}{x} - x^2$ is a constant"" how did they conclude that ?","['algebra-precalculus', 'functional-equations', 'number-theory']"
486763,A countable and an uncountable set,"Let A and B be countable infinite sets. Being both countable, a one-to-one correspondence between the set’s elements can be established. A new correspondence can also be established between A and the union of all elements in A and B, since this is another countable set. Intuitively, it would seem even more obvious that the same would apply if A was uncountable. The larger set would still be uncountable. However, the countability is part of the proof in the first case, such as two car lanes merging into one. The same technique is not available in the second case. (I note the question: An uncountable set minus a countable set is still uncountable, but is that equivalent to my question? - It would be if there is a one-to-one correspondence between all uncountable sets, but I don't think this is obvious) How is such a proof delivered?","['logic', 'elementary-set-theory']"
486765,Integral $\int_0^{\infty}\frac{e^{-a x^2(x^2-\pi^2)}\cos(2\pi a x^3)}{\cosh x}dx$,"$$\int_0^{\infty}\frac{e^{-a x^2(x^2-\pi^2)}\cos(2\pi a x^3)}{\cosh x}dx=\frac{\pi}{2}e^{-\pi^4 a/16}.$$ Note the unusual appearance of $x^1,x^2,x^3,x^4$ .","['calculus', 'integration', 'contour-integration']"
486771,Change of basis (Gram-Schmidt),"I was wondering whether it is possible to write down explicitely the matrix that represents the change of basis from a basis $\{v_1,....,v_n\}$  to a basis $\{e_1,...,e_n\}$, where $e_i$ is the basis constructed from $\{v_1,....,v_n\}$ by the Gram-Schmidt process. Or if the inverse map would be easier, I would also be interested in this matrix.","['matrices', 'linear-algebra', 'orthonormal']"
486772,How to relate the valuation of x/y (For a minimal Weierstrass equation),"I'm reading an article about elliptic curves, but since I'm not very experienced on this subject, I ended up getting stuck. The problem starts as: ""Let $K/\mathbb{Q}$ be a number field and $E/K$ an elliptic curve defined over $K$. Let $v\in M_K$ be a finite place of good reduction for $E$, and fix a minimal Weierstrass equation for $E$ at $v$,
$$y^2+a_1xy+a_3y=x^3+a_2x^2+a_4x+a_6$$
Then..."" After this there are some equations concerning the local canonical height which the article wants to prove, but the problem I have is not really about this equations. Its all about the following statement made during the proof: $``$ The integrality of the Weierstrass equation implies EASILY that
\begin{equation}\tag{1}
v(x^{-1})<0 \iff v(x/y)<0   \quad""
\end{equation} After playing with the Weierstrass equation and it's integrality ($v(a_i)\ge 0$ for all the $i$'s), indeed I was able to conclude $$v(x)<0 \iff v(y)<0 \quad\text{and in this case }\quad 2v(y)=3v(x)$$
Thus $$v(x)<0 \Rightarrow v(y/x)<0$$
Hence $$v(x/y)\le0 \Rightarrow v(x^{-1})\le0$$ But this was the closest I could get to the statement $(1)$. I have already tried (without success) to work on the Weierstrass equation in a lots of different ways to explicit the $(x/y)$ and somehow manage to relate $v(x/y)$ and $v(x^{-1})$ as expected in $(1)$. At this point, due to the ""easily"" on the text and since I'm not very experienced, I'm starting to think it is some kind of standard trick or I'm missing something very obvious. I would appreciate so much any kind of help. I'm sorry for my English, it is not my native language. Thanks a lot!!","['algebraic-geometry', 'algebraic-number-theory', 'elliptic-curves']"
486783,Calculating Interest,"A person deposited $5000\$$ at $10\%$ simple interest for $2$ years. How much more money will she have in her account at the end of two years, if it is compounded semi-annually? $50/40/77.5/85.5$ My attempt: $\dfrac{5000*10*2}{100}=1000,$ so amount$=6000.$ $5000\left(1+\dfrac{10}{2*100}\right)^{2*2}=5000\left(\dfrac{21}{20}\right)^4=6077.5\$$. So, answers is $77.5\$$. My query: Can we have a quicker way to solve this question? In my approach, the calculation is lengthy. Multiplying $21$, $4$ times is time-consuming. P.S- It is actually a MCQ and one question should be solved in less than $1$ minute and calculator is not allowed.",['algebra-precalculus']
486796,Doubt in derivative problem,"I'm in trouble with the following problem: Give $f(x) = x^3 - 3x + 1$ and $g(x) = x^3 + ax^2 + b$, determine the values of $a$ and $b$ in such a way that both $f(x)$ and $g(x)$ have the same relative maximum and minimum. I already know that the relative maximum and minimum can be found though the roots of the derivative, so $f'(x) = 3x^2 - 3$ and $g'(x) = 3x^2 + 2ax$. As the roots of $f'(x)$ are both ${-1, 1}$, I imagined to build a system of equations to find $a$ and $b$, but I always end in two 'dummy' equations, do someone know a different way to solve this ? By the way, the dummy equations are when I substitute ${-1, 1}$ in $g(x)$. The equations are $a + b = 4$ and $a + b = -2$","['calculus', 'algebra-precalculus']"
486807,How much weight is on each person in a human pyramid?,"After participating in a human pyramid and learning that it's very uncomfortable to have a lot of weight on your back, I figured I'd try to write out a recurrence relation for the total amount of weight on each person in the pyramid so that I could see just how much weight I ended up carrying. There are many different kinds of human pyramids, but the sort of pyramid I'm referring to is one that looks like this: *
              / \
             *   *
            / \ / \
           *   *   *
          / \ / \ / \
         *   *   *   *
               ... Here, each star is a person and the lines represent how each person is supported. I'm going to make the unrealistic assumption that each person weighs the same amount, which I'll call $W$.  I'm also going to assume that each person evenly transmits their weight (plus the total weight on top of them) to the two people below them. Given these assumptions, I came up with a recurrence $w_{i, j}$ that says how much weight the $i$th person in row $j$ of the human pyramid carries on their back.  It ended up coming out like this: $w_{1, 1} = 0$.  The top person in the pyramid has no weight on them. $w_{1, n+1} = \frac{w_{1, n} + W}{2}$  The very first person on each row is shouldering half the weight of the person above them.  That weight is given by the weight of the person ($W$) plus the load that person carries ($w_{1, n}$). $w_{n+1, n+1} = \frac{w_{n, n} + W}{2}$.  The last person on each row shoulders half of the weight of the person above them. $w_{k+1, n+1} = \frac{w_{k+1, n} + w_{k, n} + 2W}{2}$.  Each person on a row other than the first or the last shoulders half the weight from each of the people above them.  The two people above them have $w_{k+1, n}$ and $w_{k, n}$ weight on them, and each one independently weighs $W$.  Half of each of these weights is transmitted to the person below. I was able to write a computer program that evaluated this recurrence and I was able to get values from it, but I have no idea how to find a closed-form expression for this recurrence.  It's somewhat similar to the recurrence for combinations - each term is expressed as a sum of the two terms above it - but there's some extra junk thrown in as well. Is there a standard approach for simplifying recurrences like this? Thanks!","['recurrence-relations', 'discrete-mathematics', 'recreational-mathematics']"
486815,Convolution of an $L^1$ function and a function that tends to $0$ results in a function that tends to $0$,"I'm trying to solve the following problem in review for a test, but have only partly succeeded: Let $K \in L^1(\mathbb{R})$ and $f$ be a bounded, measurable function on $\mathbb{R}$, with $\lim_{x\to\infty} f(x) = 0$. Let $F(x) = \int_{\mathbb{R}} K(x-t)f(t)\mathrm dt$. Prove that $F(x)$ is finite for every $x$ and $\lim_{x\to\infty} F(x) = 0$. Using Hölder's inequality it was straightfoward to show $F(x)$ finite for any $x$. Any suggestions on how one can show that $F(x) \to 0$ as $x \to \infty$?","['convolution', 'lebesgue-integral', 'measure-theory', 'real-analysis']"
486829,Contraction mapping proof question,"I'm reading Wendell Fleming's book Functions of Several Variables , and on page 144, he states the following lemma: Suppose $\phi: \mathbb{R}^n \to \mathbb{R}^n$ is continuous on some neighborhood $\Omega$ of $0$, and such that $$\|\phi (t)\| \leq c \|t\| \; \; \; \forall t \in \Omega, \text{ where }0<c<1.$$ Define $\Psi(t) := \sum_{i=0}^\infty \phi^{[i]}(t)$ and $\Psi_r(t) := \sum_{i=0}^r \phi^{[i]}(t)$, where $\phi^{[i]}(t):= \phi \circ \dotsb \circ \phi$ is the i-fold composition of $\phi$. Then $\|\Psi(t)\| \leq \frac{|t|}{1-c}$ $\Psi(t) - \phi[\Psi(t)]=t$. In proving the second part, he states: $$\Psi_r - \phi \circ \Psi_r = \sum_{i=0}^r \phi^{[i]} - \sum_{i=1}^{r+1} \phi^{[i]}= I - \phi^{[r+1]}.$$ I cannot figure out why $\Psi_r - \phi \circ \Psi_r = \sum_{i=0}^r \phi^{[i]} - \sum_{i=1}^{r+1} \phi^{[i]}$ holds. It seems it would be true for $\Psi_r - \Psi_r \circ \phi$. I'm sure I'm just missing something obvious, but I can't see why it is true. I checked to make sure Fleming's notation of function composition is the usual one, and it is. I checked to make sure it wasn't a typo...the rest of the proof proceeds the same way. What am I missing? Here is a scan of the page, if it helps: https://i.sstatic.net/Ufib4.jpg",['multivariable-calculus']
486830,"Prove that there is a bijection between the set of all subsets of $X$, $P(X)$, and the set of functions from $X$ to $\{0,1\}$.","Given any set $X$, let $P(X)$ be the set of all subsets of $X$, and let $\{0,1\}^X$ be the set of all functions $X \rightarrow \{0,1\}$. Construct a bijection (and its inverse) between P(X) and $\{0,1\}^X$. Let us define $f: P(X) \rightarrow \{0,1\}^X$ by $f(\alpha) = g_{\alpha}$ where $\alpha \in P(X)$ and $g_{\alpha} : X \rightarrow \{0,1\}$ is defined by $$g_{\alpha}(x) =\begin{cases} 
      1 & x \in \alpha \\
      0 & x \in X-\alpha 
   \end{cases}$$ We need to check if this function is well-defined. Let $\alpha, \beta \in P(X)$. If $\alpha=\beta$, then $\alpha$ and $\beta$ correspond to the same set, and so correspond to the same function since both $g_{\alpha}$ and $g_{\beta}$ send that set to 1 and the ($X-$that set) to 0. If we have a function $g_{\alpha} \in \{0,1\}$, then $\alpha$ is a set in $X$ that is sent to 1. But since $P(X)$ is the set of all sets of $X$, we must have $\alpha \in P(X)$. So the function is surjective. Finally, if $g_{\alpha}=g_{\beta}$ then both $g_{\alpha}$ and $g_{\beta}$ send the set $\alpha$ or $\beta$ to 1. So $\alpha$ and $\beta$ must be same set. In other words, the function is injective; and hence bijective. The inverse function is $f^{-1}: \{0,1\}^X \rightarrow P(X)$ where $f^{-1}(g_{\alpha}) = \alpha$. Another way to prove this is to first construct the inverse function, show that it is well defined, and then show that $ff^{-1}$ and $f^{-1}f$ are the identity functions, right? So if we let $g_{\alpha}=g_{\beta}$, then $\alpha=\beta$, because otherwise $g_{\alpha} (\beta)=0$ and $g_{\beta} (\beta)=1$; a contradiction. Now we have $f \circ f^{-1} (g_{\alpha}) = f(\alpha) = g_{\alpha}$ and $f^{-1} \circ f(\alpha) = f^{-1}(g_{\alpha}) = \alpha$ , and so $f$ and $f^{-1}$ must be bijective.","['elementary-set-theory', 'functions', 'solution-verification']"
486833,The Banach space $c_0$ is $C^{\infty}$-smooth.,"In this paper , J. Eells defines this notion of $C^r$ -smoothness for Banach spaces: A Banach space $E$ is $C^r$ -smooth, $r \geq 0$ , if there exists a nontrivial (that is, nonzero) $C^r$ function $\phi : E \rightarrow \mathbb{R}$ with bounded (not necessarily compact) support. He then claims that the Banach space $$c_0 = \{~(a_1, a_2, a_3, \ldots) : \lim a_n = 0~\},~~\|(a_n)\|_{c_0} = \sup_n |a_n|,$$ is $C^{\infty}$ -smooth. My question is: how do we construct the smooth function having bounded support here? Here's what I've been trying; take your favorite smooth function $\phi : \mathbb{R} \rightarrow \mathbb{R}$ having compact support and such that: $\phi \equiv 1$ on [-1/4, 1/4]; $\phi \equiv 0$ outside [-1, 1]. Now, given $(a_n)_{n \in \mathbb{N}}$ in $c_0$ , define: $$\Phi\big((a_n)_{n \in \mathbb{N}}\big) = \large\prod_{n = 1}^{\infty} \phi(a_n).$$ Note that the product is well-defined, since the terms $a_n$ are eventually all within $[-1/4, 1/4]$ , and hence almost all terms in the product are equal to $1$ . Moreover, this function has bounded support, since if $\|(a_n)\|_{c_0} > 1$ , then at least one $a_n$ has to be greater than $1$ in modulus, and then the whole product is zero. My problem is that I cannot show that this is differentiable, let alone smooth. Thank you for your input!","['functional-analysis', 'banach-spaces', 'analysis']"
486838,Integrate $u_t - \Delta u = 0$ to get $\frac12 \frac{d}{dt} \int_{\Omega} u^2 + \int_{\Omega}|\nabla u|^2 = 0$?,"In my PDE class, my instructor wrote the following notes: Consider equations $u_t - \Delta u = 0$ in $\Omega$, where $\Omega \subset \mathbb{R}^n$ is bounded. Suppose boundary conditions $u = u_0(x)$ at $t=0$, and $u=0$ at $\partial \Omega$. Multiplying the equation by $u$ and integrating by parts gives $$\frac12 \frac{d}{dt} \int_{\Omega} u^2 + \int_{\Omega}|\nabla u|^2 = 0$$ (with no boundary terms, using the bc). This already shows $$\frac{d}{dt} \int_{\Omega}u^2 \leq 0 \tag{1}$$ which gives uniqueness, since the problem is linear (so the difference of two solutions has initial data 0). My Questions: I'm not seeing the integration by parts here, can someone talk me through it? How are we deducing (1)? How does (1) show uniqueness? Thanks for your help, the details are eluding me here.","['multivariable-calculus', 'integration', 'partial-differential-equations', 'derivatives']"
486842,Problem with differentiation as a concept.,"I don't understand quiet good something here, for example if we want to find the derivative of the function $\displaystyle f'(x) = \lim_{h \to 0} \frac{f(x+h)-f(h)}{h} $ and if we compute it from the function: $ f(x) = 12 + 7x $
We get that the derivative of $f(x)$ is equal to $$\lim_{h \to 0} \frac{7h}{h}$$
But I thought that we can't divide by zero (here we cancel 0 over 0), I'm I wrong or $\displaystyle \frac{0}{0}$ equals 1?","['calculus', 'derivatives']"
486849,"Integrating $\cos^3 (x) \, dx$","I am wondering whether I integrated the following correctly. $\int \cos^3 x \, dx$ I did \begin{align}
\int \cos^3 x \, dx &= \int \cos(x)(1-\sin^{2}x) \, dx \\
&= \int \cos(x)-\sin^{2}x \cos x \, dx \\
&= \sin(x)-\frac{u^{3}}{3} + c, \quad(u=\sin(x)) \\
&= \sin(x)-\dfrac{\sin^{3}x}{3}+c
\end{align} 2. $\int \sin^{3}x \cos^{2}x\,dx$ \begin{align}
\int \sin^{3}x \cos^{2}x\,dx &= \int(1-\cos^2x)(\cos^2x)\sin(x)\,dx \\
&= \int \cos^2x\sin(x)-\cos^4x\sin(x)\,dx, \quad u=\cos(x) \\
&= \dfrac{u^3}{3}-\dfrac{u^5}{5}+c
\end{align} And plug in my u.","['trigonometry', 'calculus', 'integration']"
486864,Computing sums of divisors in $O(\sqrt n)$ time?,"I have a sequence: $1,3,5,8,10,14,16,20,23,27,\dots$ I know that the recursive relation is: $$p[i] := p[i-1] + \text{number of factors of $i$}, \quad \text{with $p[1]=1$.}$$ How do I solve this recursive relation in $O(n^{0.5})$ time? I have to write a program for it, and $n$ can be as large as $10^9$. So, some appropriate precomputation and prestorage is allowed, provided that they comply (memory and time wise) with the range of $n$.","['recursive-algorithms', 'sequences-and-series', 'number-theory']"
486865,What does it mean for a number to be in a set?,"Frustratingly my book gives me several examples of a number in a set but offers no explanation at all. Anyways what is going on here? According to the book $2$ is not an element of these sets: $$\{\{2\},\{\{2\}\}\}$$ $$\{\{2\},\{2,\{2\}\}\}$$ $$\{\{\{2\}\}\}$$ What is going on? Clearly $2$ is in all of those sets. Or are they saying that $2$ isn't in any of these sets but a set is in all these sets and in that set is $2$? Which really seems like a logical fallacy because $2$ is in those sets contained in a set means the set has $2$ even if it is behind a layer of sets. For example you wouldn't say that there are no cars in a neighborhood if all the cars in in a garage, so why does math take this approach?",['discrete-mathematics']
486877,Existence of a global minimum,"Let $S = \{(x, y, z) \in \mathbb{R}^{3}: x > 0, y >0, z > 0\}$ and consider $f(x, y, z) = xyz + \frac{1}{xyz}$. Why must $f$ attain a global minimum at some $p \in S$?","['multivariable-calculus', 'real-analysis', 'analysis']"
486888,Solve $10x+2x^2+x^3=20$ using only algebra and geometry?,"The cubic formula and modern math is not allowed, only algebra, geometry, and the like. Supposedly this problem was given to Fibonacci. Here is the whole paragraph I read: In Flos Fibonacci gives an accurate approximation to a root of $10x + 2x^2 + x^3 = 20$, one of the problems that he was challenged to solve by Johannes of Palermo. This problem was not made up by Johannes of Palermo, rather he took it from Omar Khayyam's algebra book where it is solved by means of the intersection of a circle and a hyperbola. Fibonacci proves that the root of the equation is neither an integer nor a fraction, nor the square root of a fraction. He then continues:- And because it was not possible to solve this equation in any other of the above ways, I worked to reduce the solution to an approximation.
  Without explaining his methods, Fibonacci then gives the approximate solution in sexagesimal notation as $1.22.7.42.33.4.40$ (this is written to base $60$, so it is $1 + 22/60 + 7/60^2 + 42/60^3 + \dots$). This converts to the decimal $1.3688081075$ which is correct to nine decimal places, a remarkable achievement. Source: : Leonardo Pisano Fibonacci (short biography) , School of Mathematics and Statistics, University of St Andrews, Scotland This is just out of curiosity, I have no idea how this problem could be solved in terms of a circle and a hyperbola.","['geometry', 'algebra-precalculus', 'euclidean-geometry']"
486892,Multiplying by an irrational number in combinatorial problems,"Everybody knows that the number of derangements of a set of size $n$ is the nearest integer to $n!/e$. It is also widely known that the $(n+1)$th Fibonacci number $F_{n+1}$ is the nearest integer to $(1+\sqrt{5})F_n/2$ where $F_n$ is the $n$th Fibonacci number (with the lone exception that $F_2=F_1$). It had escaped my attention until today, when I wrote this answer , that the number of sequences of distinct elements of a set of size $n$ (including those of length $0$) is the nearest integer to $n!e$.  ( Later note: Provided $n\ge2$.) How widespread is this operation of mulitplying by an irrational number and then rounding, in combinatorial problems?  Are there other standard examples?  Is there some general theory accounting for this? Postscript some hours later: If I'm not mistaken, the sequence whose $n$th term is the nearest integer to $n!e$ satifies the recurrence $x_{n+1} = (n+1)x_n + 1$.","['irrational-numbers', 'combinatorics']"
486893,Revisited$^2$: Why is $(-n)^2$ divergent? How can it be shown rigorously?,"Why is $(-n)^2$ divergent? How is this proven? I've tried using the $\epsilon$ definition of convergence to come to a contradiction, but I don't know that using the definition is the way to go. I get that $n^2-s\leq \frac{1}{n}$. Not sure where to go from here. A hint would be nice. Attempt1: Say $\lim_{n\rightarrow\infty}=(-n)^2=s$. Then given an $\epsilon>0$ we can find an $N\in\mathbb{N}$ so that $\lvert (-n)^2-s\rvert \leq \epsilon$ for every $n\geq N$. But if $n\geq N$, then we must have that
$$\lvert (-n)^2-s\rvert\leq \frac{1}{n}\leq\frac{1}{N},$$
but . . . hmm . . . I don't know that this is a fruitful approach. Attempt2: Assuming that the negation of convergence is $$\text{$\exists\epsilon\leq 0$ s.t. $\forall N\in\mathbb{N}$ $n>N$ so that $\lvert s_n-s\rvert \geq \epsilon$},$$ then if we let $\epsilon=0$, then $\lvert s_n-s\rvert \geq \epsilon\implies \lvert n^2-s\rvert \geq 0$, which means that $n^2\geq s$ and $s\geq n^2$, so $s=n^2$, which means $\lvert s_n-s\rvert \geq \epsilon$ holds as $0\geq 0$, right?","['inequality', 'sequences-and-series', 'real-analysis', 'limits']"
486908,Proving the max of a quadratic form ${\mathbf x}^T\mathbf A \mathbf x$ can be attained when $x$ is from $n$-dimensional hypercube,"updated : Maybe my original question is somewhat misleading. I rewrite some of the post. This is some research problem I'm working on. I have an $n\times n$ symmetric positive-definite matrix $\mathbf A$. I also have a set of $2^n$ vectors $\mathbf x_1,\cdots,\mathbf x_{2^n}$ from an $n$-dimensional hypercube $\gamma_n$ of $\{1, -1\}^n$. I already know the maximum of the [quadratic form](http://mathworld.wolfram.com/QuadraticForm.html) of the matrix $\mathbf A$ and vectors $\mathbf x\in\{1, -1\}^n$ is a known constant $c$: Using some kind of AM-GM like inequality, I know that the quadratic form is at most $c$ $$
\mathbf x^T \mathbf A \mathbf x \leq c
\quad\text{subject to $\mathbf x \in \{1,-1\}^n$} 
$$ In this case, I want to show that there exists a vector $\mathbf x\in\{1,-1\}^n$ that achieves $\mathbf x^T \mathbf A \mathbf x = c$, and if that's possible, I'd like to show that this maximizer can be computed efficiently . Some related problem is the '0-1 Positive-Definite Maximum Problem' from Girtzmann and Klee : Instance : a symmetric positive definite matrix $\mathbf B$ and an integer $\lambda$ Question : Does there exist a vector $\mathbf x\in\{0,1\}^n$ such that $\mathbf x^T \mathbf B \mathbf x \geq \lambda$? They showed that this problem is NP-Complete . I think my problem is different from '0-1 Positive-Definite Maximum Problem' because I already know the upper bound of the quadratic form and ask whether this upper bound can be achieved from a vector from a hypercube. My Question : Is there any trick for an existential proof that such a maximizer exists in my setting? One trick I can come up on top of my head right now is the Averaging Argument , but this seems too strong: I'm afraid the averaging argument works only when all the $2^n$ quadratic form values amount to the desired maximum $c$.","['matrices', 'quadratic-forms']"
486917,Simple approximation to a sum involving Stirling numbers?,"I have also posted this question at https://mathoverflow.net/questions/141552/simple-approximation-to-a-sum-involving-stirling-numbers#141552 . I have an exact answer to a problem, which is the function: $f(x,y)=\frac{1}{y^x}\sum_{i=1}^{x-1} [i\binom{y}{x-i}(x-i)!S(x,x-i)]$ where $S(x,x-i)$ is Stirling number of the second kind. Equivalently, $f(x,y)=\frac{1}{y^x}\sum_{i=1}^{x-1}{\{i\binom{y}{x-i}\sum_{j=0}^{x-i} [(-1)^{x-i-j}\binom{x-i}{j}j^x]}\}$. Equivalently, $f(x,y)=\frac{y!}{y^x}\sum_{i=1}^{x-1}{\{\frac{i}{(y-(x-i))!}\sum_{j=0}^{x-i} [\frac{(-1)^{x-i-j}j^x}{j!(x-i-j)!}]}\}$. I have noticed that the percent difference between $f(x,y)$ and $g(x,y)$ goes to $0$ for larger values of $x$ and $y$, where $g(x,y)$ is the far more elegant $x-y(1-e^{-\frac{x}{y}})$. How can $f(x,y)$ be approximated by $g(x,y)$? What approximations should be used to make this connection? I have tried approximations for $S(n,m)$ listed at http://dlmf.nist.gov/26.8#vii , to no avail.","['stirling-numbers', 'number-theory', 'approximation-theory', 'approximation', 'combinatorics']"
486939,What is a 2-sided inverse?,The text says: For every permutation $\sigma$ there is a 2-sided inverse function $\sigma^{-1}: \Omega \to \Omega$ satisfying $\sigma \circ \sigma^{-1} = 1$. So I am wondering - what is the 2-sided inverse function...?,['abstract-algebra']
486957,Why don't fractals have more differentiable symmetries?,"Some sets tend not to ""look"" very homogeneous, such as self-similar fractals. I'd like to know why! And there's a particular class of statements that I'm hoping can be made... Definition Let $A$ be a subset of $\mathbb R^n$. Consider two points of $A$ to be equivalent if they have similar neighborhoods up to a differentiable map. Concretely, for $x,y\in A$, write $x\sim y$ if there exists a map $f:A\to A$ and an invertible matrix $T\in\mathbb R^{n\times n}$ such that $f(x)=y$ and
$$\lim_{\Delta x\to 0}\frac{f(x+\Delta x) - f(x)-T\Delta x}{|\Delta x|}=0.$$ I require $T$ to be invertible so that infinitesimal neighborhoods of $x$ and $y$ look affinely equivalent. (If we allowed $T$ to be singular, then $f$ could be a constant map, which wouldn't be interesting.) For that matter, let's go ahead and require that $f$ itself is a bijection between a neighborhood of $x$ and a neighborhood of $y$. Example Consider the standard middle-third Cantor set $C\subset[0,1]\subset\mathbb R^1$. This set is topologically homogeneous in the sense that for all $x,y\in C$, there is a homeomorphism $h:C\to C$ such that $h(x)=y$. In fact, if we consider $C$ to be a subset of $\mathbb R^2$, we can find an $h$ that extends to a homeomorphism of all of $\mathbb R^2$, and we can even find an isotopy from the identity on $\mathbb R^2$. So topological methods alone don't seem to be enough to distinguish between points in $C$. Once we start considering differentiable maps, $C$ starts looking less homogeneous. In particular, $0\sim x$ if and only if $x$ has a finite ternary expansion. The equivalence class of $0$ is countable, whereas $C$ is uncountable, so there are relatively few points equivalent to $0$. I suspect that every equivalence class in $C$ is countable, although I've only proven the restricted case of this latter statement when $f$ is required to be an isometry with respect to the natural ultrametric on $C$. I'm looking for a more general theory... Questions Under what conditions on $A$ are we assured that: All points in $A$ are equivalent? For example, it suffices that $A$ is an open set, or that $A$ is an embedded differentiable manifold. All equivalence classes in $A$ are at most countable? I can prove this for sufficiently nice maps $f$ where $A$ is a sufficiently nice embedding of the $p$-adic integers, which is the set that I'm most interested in, but again I'm looking for more general results. Does it suffice that $A$ doesn't contain any differentiable curves? Or that $A$ is nowhere a differentiable image of a product $\mathbb R^k\times B$? At least one equivalence class in $A$ is at most countable? For example, it suffices for $A$ to contain a corner point, as it can only be equivalent to other corner points, and there are at most countably many corners in any subset of $\mathbb R^n$. This generalizes the example of $0\in C$ given above. But some sets in $\mathbb R^n$ for $n\geq2$ don't have corners; what about them? If necessary, you can assume that $A$ is closed, or even that $A$ is a Cantor set. You can also assume that the maps $f$ under consideration must be differentiable on a neighborhood of $x$, or even $C^1$, or that $f$ must be a bijection. A statement like ""If $A$ is a Cantor set then every equivalence class is at most countable"" would be a home run! Is this an easy problem or a hard problem? I don't know what kind of theory the question belongs to, hence the reference-request tag. I've heard of the study of ""analysis on Foo"" where Foo = closed sets, metric spaces, or fractals, but these topics seem to focus on different sorts of questions. Of course, if this is a hard problem, I can also consult MathOverflow. But for all I know, the problem is an easy consequence of Theorem-I've-Never-Heard-Of. (edited inline)","['reference-request', 'real-analysis']"
486959,Finding a vector that has 0 curl and 0 div,"SO as stated, I am trying to find a vector $\vec F$such that
$$\nabla \times \vec F=0$$
$$\nabla \cdot \vec F=0$$
The way I go about it is: Becasue curl is 0, we know that $\vec F=\nabla f$ so the divergence equation then becomes
$$\nabla ^2f=0$$
Which I then say $f=A(x)B(y)C(z)$, which results in me getting the following function f: $$f=\cos(x)\cosh(y)\cos(z)$$
so $\vec F=\nabla f$, 
Which has 0 curl, but nonzero div. Sad face",['multivariable-calculus']
486964,Does every continuous everywhere but differentiable nowhere curve have an infinite length?,"Given a curve $\!\,\gamma : [a, b] \rightarrow ℝ^2$ that is continuous everywhere but differentiable nowhere (or almost nowhere), is its length: $$\text{length} (\gamma)=\sup \left\{ \sum_{i=1}^n d(\gamma(t_i),\gamma(t_{i-1})) : n \in \mathbb{N} \text{ and } a = t_0 < t_1 < \cdots < t_n = b \right\}.$$ always infinite?","['plane-curves', 'real-analysis']"
486981,Proving statements by its contrapositive,"Prove the following statement by proving its contrapositive: “If $n^3 + 2n + 1$ is odd then n is even” Therefore: $\lnot q \rightarrow  \lnot p =$ ""if $n^3 + 2n + 1$ is even then $n$ is odd. So for this I began assuming that: $n=2k+1$ $(2k+1)^3 +2(2k+1)+1 = 8k^3+12k^2 +10k+4 = 2k(4k^2 +6k+5)+4$ The last statement: $2k$ is even, therefore $2k(4k^2 -6k+5)$ is also even and 4 is $2\cdot 2$ which is also even. Now, my question is, when proving the contrapositive, what's your final conclusion? If it works for the contrapositive, then your theorem holds? Or is there something else?",['discrete-mathematics']
486995,Solve the equation for $X$,$$X^3-3X^2+3X=\frac{3R-10}{2}$$ How can i solve it for $X$ ? I tried to do : $$\Rightarrow X(X^2-3X+3)=\frac{3R-10}{2}$$ ???,"['algebra-precalculus', 'roots']"
487011,Showing that a homomorphism between groups of units is surjective. [duplicate],"This question already has answers here : Why does the natural ring homomorphism induce a surjective group homomorphism of units? (3 answers) Closed 7 years ago . Let $n$ be a positive integer and let $d$ be some divisor of $n$. Consider the group of units modulo $n$, which we shall denote by $U(n)$. Likewise, denote the group of units modulo $d$ by $U(d)$. Consider the homomorphism $f:\ U(n)\rightarrow U(d)$ given by reducing modulo $d$,
$$f(u) = u \pmod{d}$$
I wish to show that this map is surjective. Can anyone supply a simple proof of this fact? Alternatively, it is sufficient to prove that the set
$$S = \left\{u\in U(n) \mid u\equiv 1 \pmod{d} \right\}$$
has cardinality $|S| = \phi(n)/\phi(d)$ where $\phi$ is the totient function.","['elementary-number-theory', 'group-theory']"
487017,What's a non-zero (column) vector?,"This is a basic question, but I can't find the definition on wikipedia, google, or math.stackexchange, because I only find examples of it being used in problems. Therefore, I want to clarify: Does a non-zero vector have at least one non-zero entry or must all the entries be non-zero? Example from wikipedia: ""M is said to be positive definite if z'Mz is positive for any non-zero column vector z of n real numbers""",['linear-algebra']
487032,Subgroups of $S_n$ of index $n$ are isomorphic to $ S_{n-1}$,"I am trying to show that the subgroups of $S_n$ of index $n$ are isomorphic to $ S_{n-1}$, if $n\ge 2$. I tried to do this as follows: Let $G < S_n$ be a subgroup of index $n$, and let it act on a set of cosets $S_n/G \setminus 1\cdot G$ by multiplication from left. (It is easy to check this is indeed an action.)  Then this action defines a homomorphism $\phi:G\rightarrow\mathrm{Aut}_{\mathrm{Set}}(S_n/G \setminus 1\cdot G) \cong S_{n-1}$. One needs to show $\phi$ is isomorphic, and indeed, by counting argument, it suffices to show it is injective or surjective. This is where I am stuck.  To show that the kernel of $\phi$ is trivial, it would suffice to prove the triviality of $\bigcap_{x\in S_n\setminus G} xGx^{-1}$, but I do not know why this is true.  I do not have any idea how to show the surjectivity of $\phi$, either.  I have not yet used specific properties of symmetric groups, so I believe I need to use them here. I would be grateful if you could provide a clue.","['finite-groups', 'group-theory', 'symmetric-groups']"
487065,"If a function $f$ satisfies $f(2x+3)=x^2$, how to find $f(0)$?","If a function satisfies $f(2x+3)=x^2$, what is $f(0)$? Explain how you figured it out, please.","['algebra-precalculus', 'functions']"
487068,Counter-examples of right-continuous filtrations,"A filtration $(\mathcal{F}_t)$ is said to be right continuous if $\mathcal{F}_t =
\bigcap\limits_{h > 0} \mathcal{F}_{t + h}$.  (A filtration $( \mathcal{F}_t)$ is a collection such that
each $\mathcal{F}_t$ is a $\sigma$-algebra and that $\mathcal{F}_s \subset
\mathcal{F}_t$ if $s \leqslant t$). What are some counter-examples about filtrations failing to be right
continuous?","['probability-theory', 'stochastic-processes', 'measure-theory']"
487070,Let $f$ be a homomorphism from the reals under addition to the nonzero complex numbers under multiplication. Find the image of $f$.,"If $f$ is as given in the problem statement, then how do I determine its image? My book says that the image of $f$ = {$z$ in the nonzero complex numbers under multiplication such that $z=f(x)$ for some $x$ in the reals under addition}. SO could I take $x=3$ and then $f(x)=e^{ix}=3$, so image of $f$ equals 3? This problem is so frustrating.",['functions']
487084,Does every group whose order is a power of a prime p contain an element of order p?,I need to know if every group whose order is a power of a prime $p$ contains an element of order $p$? Should I proceed by picking an element $g$ of the group and proving that there is an element in $\langle g \rangle$ that has order $p$?,"['finite-groups', 'group-theory', 'p-groups']"
487100,Composition of two reflections is a rotation,"I have this problem that says: Prove that in the plane, every rotation about the origin is composition of two reflections in axis on the origin. First I have to say that this is a translation, off my own, about a problem written in spanish, second, this is the first time I write a geometry question in english. I don't know how to prove this, so I made a few drawings, but I believe I got more confused. I put a point P in the plane and then rotate it $\theta$ from the X axis and got $P_\theta$, I assume that what the problem wants is to get from P to the same $P_\theta$ but with two reflections, this is what I don't understand, why do we need two? if we bisect the angle that P and $P_\theta$ formed then we get an axis that works as the axis of reflection, then we don't need two, but one to get the same point. Please tell me what's going on here. I know that we can see rotations and reflections as matrix, should I try to multiply two reflections with different angles and then see if I can rewrite the result as a rotation?","['geometry', 'linear-algebra', 'euclidean-geometry']"
487102,Why is the map: $GL_n(K)\times GL_n(K) \to GL_n(K)$ regular?,Let $K$ be a field and $GL_n(K)$ the set of all invertible $n$ by $n$ matrices over $K$. Let $m: GL_n(K)\times GL_n(K) \to GL_n(K)$ be the usual multiplication of matrices. Why the map $m$ is regular? Thank you very much.,"['algebraic-geometry', 'algebraic-groups']"
487117,Is a subgroup $H$ of a group $G$ normal if $g^2 \in H$ for all $g \in G$? [duplicate],"This question already has answers here : Let $H$ be a subgroup of a group $G$ such that $x^2 \in H$ , $\forall x\in G$ . Prove that $H$ is a normal subgroup of $G$ (2 answers) Closed 6 years ago . Suppose $G$ is a group, $H\leq G$, and for all $g\in G$ we have $g^2\in H$. Is $H$ a normal subgroup of $G$?","['group-theory', 'abstract-algebra', 'normal-subgroups']"
487121,Proving a point inside a triangle is no further away than the longest side divided by $\sqrt{3}$,"Problem: In a triangle $T$ , all the angles are less than 90 degrees, and the longest side has length $s$ . Show that for every point $p$ in $T$ we can pick a corner $h$ in $T$ such that the distance from $p$ to $h$ is less than or equal to $s/\sqrt{3}$ . Source: Problem 2 in http://abelkonkurransen.no/problems/abel_1213_f_prob_en.pdf Here's my try: If $p$ is on any of the edges of $T$ , it can't be further away than $s/2$ . Then I thought that the point furthest away from any $h$ would be a point equidistant to all the vertices. I also know that the equidistant point has to be inside the triangle because no angle is obtuse. I am assuming an equilateral triangle (I'm not sure if I can). It has no longest side, therefore all must be of length $s$ . Let $h_1,h_2,h_3$ be the vertices, and $z=h_1e=h_2e=h_3e$ . To find the equidistant point $e$ , I could half all the angles. By trigonometry I will get that, $\cos 30^\circ=\frac{\sqrt{3}}{2}=\frac{s/2}{z} \implies z=\frac{s}{\sqrt{3}}$ . Since this is the length from the closest corner to the equidistant point it cannot be further away. I am not sure if I can rightly assume the triangle is equilateral without loss of generality, probably not. However this is the closest I've gotten to proving this. Could you explain a better approach? PS. Calculators would not be allowed.","['geometry', 'triangles', 'trigonometry', 'combinatorial-geometry']"
487123,How to find $\lim_{n\to\infty}\frac{1!+2!+\cdots+n!}{n!}$?,"How to evaluate the following limit?
$$\lim_{n\to\infty}\dfrac{1!+2!+\cdots+n!}{n!}$$ For this problem I have two methods. But I'd like to know if there are better methods. My solution 1: Using Stolz-Cesaro Theorem, we have
$$\lim_{n\to\infty}\dfrac{1!+2!+\cdots+n!}{n!}=\lim_{n\to\infty}\dfrac{n!}{n!-(n-1)!}=\lim_{n\to\infty}\dfrac{n}{n-1}=1$$ My solution 2: $$1=\dfrac{n!}{n!}<\dfrac{1!+2!+\cdots+n!}{n!}<\dfrac{(n-2)(n-2)!+(n-1)!+n!}{n!}=\dfrac{n-2}{n(n-1)}+\dfrac{1}{n}+1$$","['factorial', 'limits']"
487128,"Prove that a group generated by two elements of order $2$, $x$ and $y$, is isomorphic to $D_{2n}$, where $n = |xy|.$","I am completely stuck at the question Let $G$ be a finite group and let $x$ and $y$ be distinct elements of order 2 in $G$ that generate $G$. Prove that $G \cong D_{2n}$, where $n = |xy|.$ I have proved that Let $x$ and $y$ be elements of order 2 in any group $G$. If $t = xy$ then $tx = xt^{-1}$. Can I get some hints?","['dihedral-groups', 'finite-groups', 'group-theory', 'abstract-algebra']"
487129,The Principle of Mathematical Induction,"The question is Let $( F_0, F_1, F_2,... )$ be the Fibonacci sequence defined by $F_0=0,\, F_1=1, and F_{n+1}=F_n+F_{n-1}$, n greater than or equal to 1. Prove the following identities. 
$$\begin{bmatrix}
1 & 1\\ 
1 & 0
\end{bmatrix}^n =\begin{bmatrix}
F_{n+1} &F_n \\ 
F_n &F_{n-1} 
\end{bmatrix}$$
This is what I tried. Proof: 
Base case: If $n=1$ the formula says
$$\begin{bmatrix}
1 & 1\\ 
 1& 0
\end{bmatrix}^{1}=\begin{bmatrix}
F_{1+1} & F_1\\ 
F_1 &F_0 
\end{bmatrix}=\begin{bmatrix}
1+0 & 1\\ 
1 & 0
\end{bmatrix}=\begin{bmatrix}
1 & 1\\ 
1 & 0
\end{bmatrix}$$ which is true. Inductive Step: Suppose the formula holds for $n=k$ i.e. that
$$\begin{bmatrix}
1 & 1\\ 
 1& 0
\end{bmatrix}^{k}=\begin{bmatrix}
F_{k+1} &F_k\\ 
F_k &F_{k-1} 
\end{bmatrix}$$ is true. We have to show that the formula holds for $n=k+1$ that is
$$\begin{bmatrix}
1 &1 \\ 
 1&0 
\end{bmatrix}^{k+1}= \begin{bmatrix}
F_{k+2} & F_{k+1} \\ 
 F_{k+1}&F_k 
\end{bmatrix}$$ is true. Adding $\begin{bmatrix}
1 & 1\\ 
1 & 0
\end{bmatrix}^{k+1}$ both sides give
$$\begin{bmatrix}
1 & 1\\ 
1 & 0
\end{bmatrix}^k + \begin{bmatrix}
1 & 1\\ 
1 & 0
\end{bmatrix}^{k+1}= \begin{bmatrix}
F_{k+1} &F_k\\ 
F_k &F_{k-1} 
\end{bmatrix} + \begin{bmatrix}
1 & 1\\ 
1 & 0
\end{bmatrix}^{k+1}$$
This is where I'm stuck. From here I don't know how to proceed. Please let me know if I'm in the right direction.","['fibonacci-numbers', 'matrices', 'solution-verification', 'problem-solving']"
487168,Separation axioms in uniform spaces,"I have some problems understanding the proof of the following lemma: Lemma: Let $x \in X, \ \ \ U, W \in \mathcal{U}, \ \ \ \mathcal{T(U)}$ is the topology on $X$. If there exists $V \in \mathcal{U}$ such that $U \circ V \subset W$, then $U[x] \subset intW[x]$ and $\overline{U[x]} \subset W[x]$. $\mathcal{U}$ is a uniform structure on $X$ $\mathcal{U} \subset 2^{X \times X}$ is a uniform structure on $X$. It is a filter on $X \times X$ satisfying: $(1) \ \forall U \in \mathcal{U}: \Delta(X) \subset U, \\ (2) \ \forall U \in \mathcal{U}: \ U^{-1} \in U, \\(3) \ U \in \mathcal{U} \Rightarrow \exists V \in \mathcal{U} : \ V \circ V \subset U $. $U[x] = \{ y \in X \ | \ (x,y) \in U\} $ If $\mathcal{B}$ is a basis of $\mathcal{U} \ \ \ \ $ ($ \  \forall U \in \mathcal{U} \ \exists B \in \mathcal{B} : \ B \subset U \ $), then $ \mathcal{B_x}: = \{U[x] \ | \ U \in \mathcal{B}\}$ satisfies all conditions of basis for the neighbourhood system of $x \in X$ and $\mathcal{T(U)}$ mentioned above is a topology for which $ \mathcal\{{B_x}\}_{x \in X}$ is a basis for the neighbourhood system in this topology. I hope my question is clear now. Could you help me understand the proof of this lemma? My problem is that I don't have a clear picture of what int$W[x]$ or $ \overline{U[x]}$ should be. Here is the proof: Let $y \in U[x], \ z \in V[y]$. Then $(x,z) \in U \circ V$, so $(x,z) \in W$. Thus $U[x] \subset intW[x]$. Let $y \in \overline{U[x]}$. Then $\forall Z \in \mathcal{U} \ \ \exists x_Z \in U[x] \cap Z[y]$, which means that $(x, x_Z) \in U, \ (y, x_Z) \in Z$. We choose $Z$ such that $Z = Z^{-1}$ and $Z \subset V$. Then $(x,y) \in U \circ Z \subset W$.","['general-topology', 'separation-axioms', 'uniform-spaces']"
487187,How every element of a group generates a cyclic subgroup?,"It is given that every element of a group generates a cyclic subgroup. I am not able to see how. If, let's say, $H=\langle a \rangle, a\in G$ then, $H={\{...,-a^{-2},-a^{-1},a^0,a^1,a^2,...\}}$. Then how is $H$ necessarily a subset of $G$ ? And further, a subgroup ?","['finite-groups', 'group-theory', 'abstract-algebra']"
487195,Is there a bijective continuous function $f: \Bbb R \to \Bbb R$ whose inverse $f^{-1}$ is not continuous? [duplicate],"This question already has answers here : Functions which are Continuous, but not Bicontinuous (6 answers) Closed 10 years ago . Looking at the definition of an homeomorphism, this question came to my mind.",['general-topology']
487207,How many ways to choose $k$ out of $n$ numbers with exactly/at least $m$ consecutive numbers?,"How many ways to choose $k$ out of $n$ numbers is a standard problem in undergraduate probability theory that has the binomial coefficient as its solution. An example would be lottery games were you have $13983816$ ways to choose $6$ numbers out of $49$. My question is: How many ways are there to choose $k$ out of $n$ numbers with exactly/at least $m$ consecutive numbers? An example would be how many ways are there to choose $6$ out of $49$ numbers with exactly/at least $5$ consecutive numbers, e.g. $\{2,3,4,5,6,26\}$? I read that the answer here is $1936$ ways for the ""at least""-case. I would like to have a general formula and if possible a derivation of it. Good references are also welcome. Thank you.","['binomial-coefficients', 'probability', 'combinatorics']"
487225,show that the group of $2\times 2$ invertible matrices is isomorphic to $S_{3}$,"1)
Show that the set of 2x2 matrices with non zero determinat together with multiplication form a group  $(H,*)$ where 
$$H=\left.\left\{\begin{pmatrix} a&b\\c&d\end{pmatrix}\right|\; a,b,c,d\in \mathbb{Z}_2, ad-bc\neq 0 \right\}$$
Show that this group  is isomorphic to $S_{3}$ 2) identify elements of order 2 and show they are characterized by their traces Hint show that the group acts naturally on the vector space $\mathbb{Z_{2}}\oplus \mathbb{Z_{2}}$ and permutes the non-zero elements. part 1 is very simple. I showed that the multiplications is an operation on this set, the associativity is inherited from the 2x2 matrices, the id element is just the id matrix and the set is closed under taking inverses. How to do the part 2)? How to create such isomorphism?  What does it mean that the elements of order 2 are characterized by their traces???","['group-theory', 'abstract-algebra']"
487243,Weak form of Berry-Esséen theorem,"Let $X$ (a real random variable) have mean zero, unit variance and finite third moment. Let $Z_{n}:=(X_{1}+...+X_{n})/\sqrt{n}$, where $X_{1}, ... X_{n}$ are iid copies of $X$. According to the Berry-Esséen theorem we have: ${\bf{P}}(Z_{n}<a )={\bf{P}}(G<a)+O(\frac{1}{\sqrt{n}}(E|X|^3))$ uniformly for all $a\in\mathbb{R}$, where $G\equiv N(0,1)_{\mathbb{R}}$, and the implied constant is absolute. From this I want to deduce the following weak form of the Berry-Esséen theorem: Let $\phi$ be smooth with uniformly bounded derivatives up to third order. Let $X,X_{n}, Z_{n}$ be as above. Then: ${\bf{E}}\phi(Z_{n})={\bf{E}}\phi(G)+O\left(\frac{1}{\sqrt{n}}(E|X|^3)\displaystyle \sup_{x\in\mathbb{R}}|\phi'''(x)|\right)$. According to my textbook this deduction is easily seen by integration by parts. Unfortunately I do not manage ti see how to do this...","['probability-theory', 'random-variables', 'integration', 'real-analysis']"
487250,How find this nice limit,"It is well kown this following
$$\lim_{x\to+\infty}\left(\dfrac{a^{\frac{1}{x}}+b^{\frac{1}{x}}}{2}\right)^x=\sqrt{ab}(a,b>0)$$
and also kown this general
$$\lim_{x\to+\infty}\left(\dfrac{a_{1}^{\frac{1}{x}}+a_{2}^{\frac{1}{x}}+\cdots+a^{\frac{1}{x}}_{n}}{n}\right)^x=\sqrt[n]{a_{1}a_{2}\cdots a_{n}},(a_{i}>0,i=1,2,\cdots,n)$$ and some hours ago,I found this nice and Hard limit $$\lim_{x\to+\infty}x\left[\left(\dfrac{a^{\frac{1}{x}}+b^{\frac{1}{x}}}{2}\right)^x-\sqrt{ab}\right]=\dfrac{\sqrt{ab}}{8}\left(\ln{a}-\ln{b}\right)^2$$ my proof $$a^{\frac{1}{x}}+b^{\frac{1}{x}}=e^{\frac{1}{x}\ln{a}}+e^{\frac{1}{x}\ln{b}}=1+\dfrac{1}{x}\ln{a}+\dfrac{1}{2x^2}\ln^2{a}+1+\dfrac{1}{x}\ln{b}+\dfrac{1}{2x^2}\ln^2{b}+o(1/x^2)$$ then \begin{align*}
\left(\dfrac{a^{\frac{1}{x}}+b^{\frac{1}{x}}}{2}\right)^x&=\left[1+\dfrac{1}{2x}\ln{ab}+\dfrac{1}{4x^2}\left(\ln^2{a}+\ln^2{b}\right)+o(\frac{1}{x^2})\right]^x\\
&\approx e^{x\ln{\left(1+\dfrac{1}{2x}\ln{ab}+\dfrac{1}{4x^2}\left(\ln^2{a}+\ln^2{b}\right)\right)}}\\
&\approx e^{x\left(\dfrac{1}{2x}\ln{ab}+\dfrac{1}{4x^2}\left(\ln^2{a}+\ln^2{b}\right)\right)}\\
&=\cdots\cdots\\
&\approx \sqrt{ab}\left(1+\dfrac{1}{8x}\left(2\ln^2{a}+2\ln^2{b}-\ln^2{(ab)}\right)\right)
\end{align*}
so $$\lim_{x\to+\infty}x\left[\left(\dfrac{a^{\frac{1}{x}}+b^{\frac{1}{x}}}{2}\right)^x-\sqrt{ab}\right]=\dfrac{\sqrt{ab}}{8}\left(\ln{a}-\ln{b}\right)^2$$ My question: $$\lim_{x\to+\infty}x\left[\left(\dfrac{a_{1}^{\frac{1}{x}}+a_{2}^{\frac{1}{x}}+\cdots+a^{\frac{1}{x}}_{n}}{n}\right)^x-\sqrt{a_{1}a_{2}\cdots a_{n}}\right]=?$$",['limits']
487254,Find the second derivative of the given function,"If $$x=a(\cos \theta + \theta \sin \theta) $$$$ y=a(\sin \theta- \theta \cos \theta) $$ prove that $$\frac{d^2y}{dx^2}= \frac{\sec^3 \theta}{a \theta}$$ Can you solve this for me? I tried finding $\frac{dy}{dx} $ by dividing $\frac{dy}{dt} $ by $\frac{dx}{dt} $ but failed to get the required answer $$\frac{\frac{d}{d \theta} \frac{ \cos \theta + \theta \sin \theta}{\theta \cos \theta - \sin \theta}}{\frac{dx}{d \theta}}=\frac{1+\theta^2}{a(\theta \cos \theta- \sin \theta)}$$
I am stuck here Please offer your assistance. :)",['derivatives']
487273,Where can I learn to apply the *theory* of differential equations in order to solve problems rigorously?,"I'm having trouble solving ordinary differential equations (DE's), because I don't understand the underlying theory, nor how to apply it. For example, suppose I am solving such a DE. My techniques allow me to find the general solution on an interval $(a,b),$ and also on an interval $(b,c).$ Under what circumstances can I, by gluing pairs of solutions, obtain the general solution on the larger interval $(a,c)$ ? In particular, under what circumstances can I conclude that all solutions on $(a,c)$ can be obtained in this way? Is there a book (article, lecture series etc.) that explains these kinds of things? Here's what I'm looking for in a book. Precisely stated definitions and theorems. Examples of how to apply them in order to solve problems rigorously . (By ""rigorous solution to a problem,"" let us mean a solution that not only gets the right answer, but also constitutes a proof that the answer is correct.) An author with a keen sense for the difference between an argument that can easily be made rigorous, versus an argument that sounds convincing but which upon closer inspection is full of holes. Here's what I don't (currently) need. Formal proofs of the theorems. PDE's (yet!).","['ordinary-differential-equations', 'reference-request']"
487287,Interpreting the meaning of sampling distribution,"I have asked a couple of questions related to statistics recently as I just started to study the topic again (I ignored my university course on statistics and I now eat my fingers in anger). I asked this question recently, and even though I do appreciate all the answers that people made the effort to provide me with, I am still puzzled about the whole thing: Monte Carlo integration, expected value of the sample mean and expected value of f(x) I also studied this very good video and example from Khan Academy: http://www.khanacademy.org/math/probability/descriptive-statistics/variance_std_deviation/v/review-and-intuition-why-we-divide-by-n-1-for-the-unbiased-sample-variance I tried to interpret the data that are generated from the exercise (which you can see in the video). In short what the exercise does is generating a population (it creates groups of random size where each of the generated group holds a number between 1 to 20). The sum of the groups size gives the population size. From this population we can compute population mean and variance. All good. Then we sample the population X times where the sample size varies from 2 to 20. The sample mean and variance is computed for each sample, and then plotted (sample variance as a function of sample mean). Again this is all good. I would like to know if I interpret (intuitively) the data correctly: this exercise shows clearly to me the difference between ""estimation"" and ""approximation"". You can see that even with sample size whose size is small (say 2) we can get a good estimation of the population mean and variance. Of course this happens by ""chance"" but the probability that this happens exists. now the problem I am debating with a student friend of mine is this. I tell him that it is not because the ""size"" of the sample increases, that the probability of that the sample to give a ""better"" estimate (compared to a sample with a smaller size) increases accordingly! My argument is that, as the size of the sample increases, the results of the sample ""converge"" to the population's parameters due to the law of large numbers. But the probability that you get a value close to this population parameters because the sample size is either 2 or 20 doesn't really change. I feel I am be right and wrong at the same time. But I like this explanation because it seems to make it possible to explain 2 distinct phenomena from 1 single set of data. 1) that sample gives an estimate (and not an approximation) of the population's parameters. The less samples, the more likely the estimate is to be way off from the population parameters. That still suggests though that there's some relation between number of sample and probability of getting an estimate close to the population parameter. But I don't know which one I can establish and if it is accurate to say so? 2) however increasing the size of the samples, can't be seen as a guarantee of of getting a better estimate from a probability point of view. It gives us the guarantee though that we get an estimate that converges to the exact value because of the LLN (then this looks almost more like an approximation than an expectation to me). It would be great if someone could tell me if I am on the right path or not (and if not correct me). I would really like to understand 1) how to interpret the results 2) where is the line between estimators and the LLN. Thank you so much for your time and knowledge. EDIT: reading the Wikipedia page on the CLT. It says ""By the law of large numbers, the sample averages converge in probability and almost surely to the expected value µ as n → ∞."" So I assume this is where the relationship is. If it converges in probability it means the probability of getting the population parameters increases as n increases. Could someone please confirm this is right?","['statistics', 'law-of-large-numbers', 'sampling']"
487317,"""If $A^2-2AB+B^2=0$, then $(A-B)^2=0$"" is true. How about $n$-th degree case?","I've known the following question: Supposing that $A, B$ are the second degree square matrices whose elements are all complex numbers, then is the following true ? If $A^2-2AB+B^2=O,$ then $(A-B)^2=O$ where $O$ is a zero matrix. Surprisingly, the answer is Yes ! Proof : We'll use the fact that $\operatorname{trace} (AB)= \operatorname{trace}(BA)$. Letting $C=A-B$, then $B=A-C$.
So,
$$A^2-2AB+B^2=0\rightarrow C^2=CA-AC \tag{1}$$
Hence,
$$\operatorname{trace} (C^2) = \operatorname{trace} (CA)-\operatorname{trace} (AC)=0 \tag{2}$$ Here, supposing that there exists $C^{-1}$, then multiplying $C^{-1}$ to $(1)$ from both sides leads 
$$I=AC^{-1}-C^{-1}A$$
where $I$ is a unit matrix. Then trace $(I)=\operatorname{trace} (AC^{-1})- \operatorname{trace} (C^{-1}A)$ leads a contradiction $2=0$. Then, knowing that there doesn't exist $C^{-1}$, we get det$(C)=0$. By Cayley-Hamilton theorem,
$$C^2-\operatorname{trace}(C)C+\det (C)I=O\rightarrow C^2=\operatorname{trace}(C)C \tag{3}$$ Hence $(2)$ leads $0=\operatorname{trace}(C^2)=\operatorname{trace}(C)\times\operatorname{trace}(C)\rightarrow\operatorname{trace}(C)=0$.
Hence $(3)$ leads $C^2=O$. Now the proof is completed. Let us call the above question the $2$nd degree version question . I got interested in this question. So, I've been thinking the $3$rd degree version question. The $3$rd degree version question : Supposing that $A, B$ are the third degree square matrices whose elements are all complex numbers, then is the following true ? If $A^3-3A^2B-3AB^2-B^3=O,$ then $(A-B)^3=O$ where $O$ is a zero matrix. After struggling to solve this question, I got a counterexample. The answer for the $3$rd degree version question is NO . The following is the counterexample: $$A=\begin{pmatrix}
        0 & 0 & 0 \\
        1 & 0 & 0 \\
        0 & 0 & 0 \\
        \end{pmatrix}
,\ \ B=\begin{pmatrix}
        0 & 1 & 0 \\
        0 & 0 & 0 \\
        0 & 0 & 0 \\
        \end{pmatrix}.$$ I've tried to solve the $n$-th degree version question for $n\ge4$, but I'm facing difficulty. Then, here is my question. Question : Could you show me how to solve the $n$-th degree version question for $n\ge4$?",['matrices']
487319,Prove that sequence space $\ell_p(\mathbb R)$ is separable,"Problem: Prove that metric space $\left \langle \ell_p(\mathbb R), d_p(x,y)=(\sum_{i=1}^{\infty} |x_i|^p)^\frac{1}{p} \right \rangle$ is separable. Where $\ell_p(\mathbb R)=\left \{ (x_1,x_2,...,x_n,...):\sum_{i=1}^{\infty} |x_i|^p<\infty, p>1, x_i \in \mathbb R \right \}$ To show separability I need to find countable everywhere dense subset. I've already proved (with similar approach ) that $\ell_p(\mathbb Q)$ is everywhere dense. However, I can't find a way to show $\ell_p(\mathbb Q)$ is countable.","['separable-spaces', 'metric-spaces', 'functional-analysis', 'lp-spaces']"
487322,The unique closed orbit in GIT quotient fibers for polynomial actions of Gl,"The following reasoning must contain a flaw somewhere because I end up with something absurd, and I cannot figure out where the mistake is. I hope that someone can point it out to me. Let $M$ be the algebraic monoid of $n\times n$-matrices and $G$ its unit group, i.e. the subgroup of invertible matrices. Let $X$ be a $G$-variety. Since $G$ is reductive, we can consider the quotient $\pi:X\to\newcommand{\qq}{\mathop{/\hspace{-2.5pt}/}}X\qq G$. It is well-known (see, e.g., Proposition 27.5.3 in the book Lie algebras and algebraic groups by Tauvel and Yu) that for $x\in X$, the fiber $\pi^{-1}(\pi(x))$ contains a unique closed orbit $O$ and
$$\pi^{-1}(\pi(x)) = \{ y\in X \mid O\subseteq\overline{G.y} \}.$$ Now let us assume that the action of $G$ extends to an action of $M$ on $X$. For instance, this is the case when $X$ is a $G$-module on which $G$ acts polynomially. It is then easy to see that for any $x\in X,$ we have $G.x\subseteq M.x\subseteq \overline{G.x}$: Let $\alpha_x:M\to X$ be the action morphism $a\mapsto a.x$. Let $U:=\alpha_x^{-1}(G.x)$. We certainly have $G\subseteq U \subseteq M$. As $G$ is open in $M$ and $M$ is irreducible, $\overline{U}=M$. Furthermore, $\alpha_x^{-1}(\overline{G.x})$ is a closed set containing $U$. Thus, we must have $M=\alpha_x^{-1}(\overline{G.x})$. Now for any $x\in X$, we can consider $y:=0.x$, i.e. the image of $x$ under the action of the zero matrix. By the above, we have $y\in\overline{G.x}$. On the other hand, we have $G.y=\{y\}$, so $y$ is a closed $G$-orbit. Now I can think of many examples where $X$ is a linear space and $0.x=0$ for any $x\in X$. In this case, $0$ would be a closed $G$-orbit contained in the orbit closure of any point, so $\pi^{-1}(\pi(0))=X$. In other words, $X\qq G=\{\ast\}$. That is completely absurd. Where is my mistake? Edit. To clarify what I mean by the quotient $X\qq G$, let us assume $X$ to be affine throughout. Then, I define $X\qq G:=\mathrm{Spec}(\Bbbk[X]^G)$ as the spectrum of the ring of $G$-invariants of the coordinate ring of $X$. There is a fundamental result (by Hilbert, I believe) that states that $\Bbbk[X]^G$ is actually a finitely generated $\Bbbk$-algebra, so this is well-defined.","['geometric-invariant-theory', 'algebraic-geometry', 'representation-theory', 'group-actions', 'invariant-theory']"
487323,finite subgroups of SO(3),"As is well-known, all finite subgroups of $SO(3)$, except for cyclic and dihedral groups, are isomorphic to one of: $A_4$ $S_4$ $A_5$ The classical proof of this fact uses the geometry of regular polyhedra, their symmetries and rotations. Are there any algebraic proofs? (I mean any proofs that take $SO(3)$ as a group of matrices or operators, but not as a group of rotations of three-dimensional space.)","['finite-groups', 'group-theory', 'representation-theory']"
487335,Using the theorem of Rouché in order to show the fundamental theorem of algebra,"Infer from the theorem of Rouché that every non-constant polynomial does have a zero point in $\mathbb{C}$ ( Fundamental Theorem of Algebra ). Consider the polynomial $$
p(z)=\sum_{i=0}^{n}a_iz^i, a_i,z\in\mathbb{C}, a_i\neq 0.
$$ In order tu use Rouché, set $$
f(z):=a_nz^n,~~~~~~~~~~g(z):=\sum_{i=0}^{n-1}a_i z^i.
$$ Because of the holomorphism of polyniomials, these functions are holomorphic and for each $r>0$ it is $$
f(z)\neq 0~\forall z\in\mbox{rg}(\gamma_r),\\ \gamma_r\colon [0,2\pi]\to\mathbb{C}, t\longmapsto r\exp(it).
$$ Because of $$
\frac{\lvert z\rvert^i}{\lvert z\rvert^n}\to 0\mbox{ for }\lvert z\rvert\to\infty, i<n
$$ it follows that $$
\lim\limits_{\lvert z\rvert\to\infty}\frac{\lvert g(z)\rvert}{\lvert f(z)\rvert}\leq\lim\limits_{\lvert z\rvert\to\infty}\frac{\sum_{i=0}^{n-1}\lvert a_i\rvert\cdot\lvert z^i\rvert}{\lvert a_n\rvert\cdot\lvert z^n\rvert}=\frac{1}{\lvert a_n\rvert}\lim\limits_{\lvert z\rvert\to\infty}\sum_{i=0}^{n-1}\lvert a_i\rvert\cdot\lvert z\rvert^{i-n}=0.
$$ So there exists an $\varepsilon>0$ , so that $$
\frac{\lvert g(z)\rvert}{\lvert f(z)\rvert}<1~\forall z\in\mbox{rg}(\gamma_{\varepsilon}).
$$ So let $\gamma_{\varepsilon}$ be the curve tracing the open circular disk with radius $\varepsilon$ . The theorem of Rouché then says that the number of zero points of $p$ within that circular disk is the same as the number of zero points of $f$ within that circular disk. And within that disk, it is $f(z)=0$ for $z=0$ (and nowhere else). So $p$ indeed has a zero point in $\mathbb{C}$ . Do you agree? Is my proof okay?",['complex-analysis']
487360,"Solutions to $\sqrt{x}+y=6,x^2+y^2=90$","$$\begin{gather}
\sqrt{x}+y=6 \tag{1} \\
x^2 + y^2 = 90 \tag{2}
\end{gather}$$ WE have to solve for $x$ and $y$(Note that 9 is an obvious value of x) My friend asked me this question earlier today, which he said he had made up himself.  However, he himself has no idea how to solve for the two variables.  I used the method of substitution to finally obtain $x(x+1)=6(21-2y)$.  Then I figured that both sides must be non-negative, and hence the value of $y$ has to be less than $11$.  Then we test for values less than $11$ which makes $6(21-2y)$ a product of two consecutive numbers.  WE get $3$ as a value of $y$, and also $7$.  But putting $7$ in (1) does not work. But there is a flaw in my reasoning.  When I get to the 'consecutive' part, I start assuming $x$ and $y$ are integers.  Since the person who asked me is not familiar with complex numbers,  WE can assume that the solutions are real.  However, I am interested in extending the values of $x$ and $y$ beyond the reals, if there are any. NOTE: From (2), we get the value of $y^2$ in terms of $x$.  Then we figure out the value of $x$ in (1) and then substitute $y$ for $90-x^2$, which gives us $x(x+1)$.","['radicals', 'algebra-precalculus', 'systems-of-equations']"
487377,Expectation of square of random variable and their mean.,"The following easy proof is well known to all students of statistics. I studied it three years ago and at present I can not remember two steps of it. If you can help me a little. $$E({X_i}^2) = \mu^2 + \sigma^2$$
$$E(\bar{X}^2) = \mu^2 + \frac{\sigma^2}{n}$$ How to prove the above two results. You may give me some hints or the complete proof. I prefer the last one. The main result with it proofs is mentioned below. Thank you for your answer.",['statistics']
487380,Finding the kernel of an action on conjugate subgroups,"I'm trying to solve the following problem: Let $G$ be a group of order 12. Assume the 3-Sylow subgroups of $G$ are not normal.  Prove that $G\cong A_4$. Here's my attempt: let $\mathscr S$ be the set of 3-Sylow subgroups of $G$. Since the elements of $\mathscr S$ are not normal, by Sylow's theorem, $\# \mathscr S > 1$. Again by Sylow's theorem, $\#\mathscr S = 4$ and the elements of $\mathscr S$ are conjugate to each other.  Hence, one can define a group action of $G$ on $\mathscr S$ by conjugation, and this defines a homomorphism $\phi : G\rightarrow \mathrm{Sym}(\mathscr S)\cong S_4$.  Thus, it suffices to show that $\phi$ is injective and its image is $A_4$. But I'm stuck at this last step.  I tried to find the kernel of $\phi$ and found that $a\in\mathrm{Ker}\phi\Leftrightarrow \forall H\in\mathscr S\ aHa^{-1} = H$, but I do not understand what this leads to. I would be most grateful if you could provide a clue (not necessarily a complete solution).","['sylow-theory', 'finite-groups', 'group-theory', 'group-actions']"
487394,Confusing angle-chasing question,"AB = BC = CD = DE = EF = FG = GA Find angle GAB. 
Please, I want the correct answer. I know how to solve it, but I am getting confused by the number of triangles in it. I am getting different answer every time I solve it. Please tell the correct answer. Options: a. 180/5
b. 60
c. 20
d. 180/7","['geometry', 'triangles']"
487396,How to Enumerate of all simple connected labeled graphs with prescribed degree sequence?,"For v=4 vertices, there must be 7 possible graphic sequence (3,3,3,3)(3,3,2,2)(3,2,2,1)(3,1,1,1)(2,2,2,2)(2,2,1,1)(1,1,1,1).
From (3,3,3,3), one simple graph(complete) can be found.
From(3,3,2,2), 6 simple connected graphs are possible,From (2,2,1,1), 12 simple connected graphs are possible. Then how can I determine all simple connected labeled graphs for degree sequence $d_{i}= d_{1},d_{2},...,d_{n} \forall i=1,n $.
Is there any formula or equation exist for the same?","['discrete-mathematics', 'graph-theory', 'computer-science', 'combinatorics', 'algebraic-graph-theory']"
487455,"$f(x)=f(x^2+ 1/4)$ , $f$ is continuous from $\mathbb{R}$ to $\mathbb{R}$","Find all continous functions $f\colon\mathbb{R}\rightarrow\mathbb{R}$ satisfying  $f(x)=f(x^2+ 1/4)$ What I've tried so far: suppose that $f$ is one-one thus $x=x^2+1/4$ ... $x=1/2$ then $f(x)=f(1/2)$ is constant That's it, I'm stuck here.","['functions', 'real-analysis', 'functional-equations']"
487466,"What is the closure of the Laplacian on $L^2(0, \infty)$ with domain $D(\Delta):=C^\infty_0(0, \infty)$?","Let $\Delta$ be the operator on $L^2(0, \infty)$ defined as follows: $\Delta \phi:= \phi''$, with domain $D(\Delta):=C^\infty_0(0, \infty)$. Is $\Delta$ closed or closable? In the case, what is its closure?",['functional-analysis']
487472,Is a finitely generated torsion group finite in general?,"This is not a duplicate of Can a finitely generated group have infinitely many torsion elements? There he asks specifically about FC-groups. Is a finitely generated torsion group finite in general? Using Dietzmann's lemma allows you to prove this for FC-groups:
Dietzmann's lemma says:
Let G be a torsion group, and M a normal finite subset of G.
Then $\langle M \rangle $ (the subgroup generated by M) is finite. Now for a finitely generated group G, we take M to be the set of generators.
Then it is finite, but is it normal? If G is an FC-group then we know every generator in M has a finite conjugacy class (by definition of an ""FC group"").
And taking the union of the conjugacy classes of the generators gives us a finite union of finite sets, which is finite, and this set is normal because conjugating any element will take us to another element in its conjugacy class which is also in the set. My question is if there is a way to prove this without the FC-group requirement.
Or better yet, specify what is the required and sufficient condition for G to be finite assuming G is finitely generated and a torsio group. Some remarks:
In the question I linked to someone specifies that the infinite dihedral group represented by $\langle a,b : a^2 = b^2 = 1\rangle$ is finitely generated but not finite, $a$ and $b$ are torsion elements, but IMO the group is not a torsion group \ so this does not disprove what I am trying to prove. EDIT:
A correct answer was provided but I will leave the question open a bit in case someone knows a necessary and sufficient condition on G for it to be finite.","['finite-groups', 'group-theory']"
487482,Esséen concentration inequality,"I want to prove the following: Let $X$ be a random variable taking values in $\mathbb{R}^d$. Then for any $r>0, \epsilon >0$: $\displaystyle \sup_{x_{0}\in \mathbb{R}^d}{\bf{P}}(|X-x_{0}|\leq r)\leq C_{d,\epsilon} r^d\displaystyle\int_{t\in\mathbb{R}^d:|t|\leq\epsilon /r} |F_{X}(t)|dt $ for some constant $C_{d,\epsilon}$ depending only on $d$ and $\epsilon$. $F_{X}$ is here the charateristic function of $X$. The hint says to use the formula ${\bf{E}}\phi(X)=\int_{\mathbb{R}^d}\widehat{\phi} (t)F_{X}(t)dt$ for some Schwartz function $\phi$.I have tried for some indicator function (as a limit of Schwartz functions), but never get the $r^d$ on the RHS.","['inequality', 'measure-theory', 'probability-theory', 'real-analysis', 'analysis']"
487488,Finite Group generated by the union of its Sylow $p_i$-subgroups,"Let $\lbrace P_i : i\in I \rbrace $ be a set of Sylow subgroups of a finite group G, one for each prime divisor $p_i$ of $|G|$. Show that $G$ is generated by $\bigcup P_i$. from Rotman ""An Introduction to the theory of groups"" pag.81 n.4.10 my attempt was to demonstrate that $\langle P_1,\dots,P_j \rangle \cap P_{j+1} = 1_G$ but i know how,to prove this only in the ( trivial ) abelian case (in that case is easy to demonstrate the entire exercise) I tried by contradiction: let $b \in \langle P_1,\dots,P_j \rangle \cap P_{j+1} $ so the order of $b$ is a power of $p_{j+1}$ but in $ \langle P_1, \dots,P_j \rangle $ there are lots of elements and i don't found the way to get an absurd. Any hint will be appreciate, even different and more elegant solutions :)","['sylow-theory', 'finite-groups', 'group-theory']"
487508,French-to-English translation of paper,I am currently reading a mathematical paper in French and I am not sure how to translate the following sentence: On suppose que la premiere classe de Chern $c_1(N)$ est $p\alpha$ ou $p$ est un entier plus grand que un et $\alpha$ une classe entiere non divisible; Here is my best guess: Suppose the first Chern class $c_1(N)$ is $p\alpha$ where $p$ is an integer $>1$ and ... (?) Any help would be great! (Apologies for the missed out accents!),"['characteristic-classes', 'translation-request', 'algebraic-geometry', 'manifolds', 'mathematical-french']"
487509,General misconception about $\sqrt x$,"I noticed a large portion of general public (who knows what square root is) has a different concept regarding the surd of a positive number, $\sqrt\cdot$, or the principal square root function. It seems to me a lot of people would say, for example, $\sqrt 4 = \pm 2$, instead of $\sqrt 4 = 2$. People even would correct a statement of the latter form to one with a $\pm$ sign. Some also claim that, since $2^2 = 4$ and $(-2)^2 = 4$, $\sqrt 4 = \pm 2$. Some people continue to quote other ""evidences"" like the $y=x^2$ graph. While most people understand there are two square roots for a positive number, some seem to have confused this with the surd notation. From an educational viewpoint, what might be lacking when teaching students about surd forms? Is a lack of understanding to functions a reason for this misconception? Now I have noticed another recent question that hinted that poster was confused. Following @AndréNicolas's comment below, might these confusion really come from two different communities using the same symbol?","['arithmetic', 'education', 'algebra-precalculus', 'soft-question']"
487559,"Are cartesian coordinates ""more fundamental"" than other coordinates, and are they inherently tied to $\mathbb R^n$?","Are the Cartesian coordinates more ""fundamental"" than other coordinate systems?  When someone says $\mathbb R^n$ do we implicitly mean the set of points PLUS Cartesian coordinate system?  Sometimes I read ""Cartesian space"" for $\mathbb R^n$, but of course nobody is calling $\mathbb R^n$ ""polar space"" (You can see this in the Euclidean space wikipedia page). This example seems to suggest to me that Cartesian coordinates are the ""default"" system on $\mathbb R^n$: If you have a constant function $f=1$ from a subset $S$ of $\mathbb R^n$ into $\mathbb R$, and you do $\iint_{S}{1 \cdot dA}$, that is interpreted as the volume of a box with base area $S$ and height $1$.  This assumes that $S \subset \mathbb R^2$ is in Cartesian coordinates. Another thing that suggests that Cartesian coordinates are more fundamental:
$\mathbb R^2$ is the ""Cartesian product"" of $\mathbb R$ with itself.","['analytic-geometry', 'coordinate-systems', 'elementary-set-theory']"
487580,The identity component of an algebraic group is always parabolic,"Essentially I was wondering if the quotient of an algebraic group $G$ by its identity component $G^0$ is necessarily always parabolic. My argument: This seems right since $G^0$ is a closed subgroup of $G$, therefore the quotient $G/G^0$ makes sense. Moreover its points are the fibers above $G^0$ hence is a finite quasi-projective variety. Thus it must be isomorphic (as a variety) to $\sqcup_{\text{finite}} \mathbb{A}^0$. Note: The latter is complete?  Since, for any variety $X$, $\sqcup_{\text{finite}} \mathbb{A}^0 \times X \cong X$ (as varieties).","['geometry', 'algebraic-geometry', 'geometric-group-theory', 'abstract-algebra', 'algebraic-groups']"
487588,Simpler solution to a geometry problem,"In a set of geometry problems, I got this one: If in a triangle $ABC$ with segments $AB=8$ , $BC=4$ , and $3A+2B=180^{\circ}$ , calculate the side $AC$ My solution was Let $A=2\alpha$ , $B=90^{\circ}-3\alpha$ , where $\alpha<30$ , then the second condition is always met. So $$tan(2\alpha)=\frac{cos(3\alpha)}{2-sen(3\alpha)}$$ $$\frac{2sen(\alpha)cos(\alpha)}{cos(2\alpha)}=\frac{cos(\alpha)(2cos(2\alpha)-1)}{2-sen(\alpha)(2cos(2\alpha)+1)}$$ $$\frac{2sen(\alpha)}{cos(2\alpha)}=\frac{2cos(2\alpha)-1}{2-sen(\alpha)(2cos(2\alpha)+1)}$$ $$4sen(\alpha)-2sen^2(2cos(2\alpha)+1)=2cos^2(2\alpha)-cos(2\alpha)$$ $$4sen(\alpha)+(cos(2\alpha)-1)(2cos(2\alpha)+1)=2cos^2(2\alpha)-cos(2\alpha)$$ $$4sen(\alpha)+2cos^2(2\alpha)-cos(\alpha)-1=2cos^2(2\alpha)-cos(2\alpha)$$ $$sen(\alpha)=\frac{1}{4}$$ We now construct the altitude to $BC$ And since $sin(\alpha)=\frac{1}{4}$ we set $AC=4k$ , $CE=k$ , $AE=\sqrt{15}k$ Then it follows from pythagoras that $$(k+4)^2+15k^2=64$$ $$16k^2+8k-48=0$$ $$2k^2+k-6=0$$ $$(2k-3)(k+2)=0$$ Since $k$ is positive, $k=\frac{3}{2}\iff AC=4k=6$ But the $2,3,4$ (from the sides $4,6,8$ ) pattern makes me think there is an easier way, so it makes me think I missed something obvious. Any hints are ideas are greatly appreciated.","['trigonometry', 'euclidean-geometry']"
487599,Seeking for a proof on the relation between Euler totient and Möbius function,"Can someone help me prove the relation $\varphi\left(n\right)={\displaystyle \sum_{d|n}}d\mu\left(n/d\right)$,
where $\mu$ is the Möbius function defined by
$$
\mu\left(n\right)=\begin{cases}
1 & \mbox{if }n=1\\
\left(-1\right)^{t} & \mbox{if }n\mbox{ is a product of }t\mbox{ distinct primes}\\
0 & \mbox{if }p^{2}\mbox{ divides }n\mbox{ for some prime }p.
\end{cases}
$$","['mobius-inversion', 'number-theory']"
487626,The product of Hausdorff spaces is Hausdorff,"I'm confused how it can be true that the product of an infinite number of Hausdorff spaces $X_\alpha$ can be Hausdorff. If $\prod_{\alpha \in J} X_\alpha$ is a product space with product topology, the basis elements consists of of products $\prod_{\alpha \in J} U_{\alpha}$ where $U_{\alpha}$ would equal $X_{\alpha}$ for all but finitely many $\alpha$'s. If this is the case and we had two distinct points, $x$ and $y$, in $\prod_{\alpha \in J} X_{\alpha}$ and a basis element, $B_x$ containing $x$ then In looking for a basis element,$B_y$ that contains $y$ but is disjoint from $B_x$ then for every $\alpha$ such that the open set $U_\alpha$ of $B_x$ is equal to $X_\alpha$ the open set $U_\alpha$ for $B_y$ would have to be empty. But then it couldn't possibly contain $y$. (or any other point of $\prod_{\alpha \in J} X_\alpha$ for that matter). How then is it possible that $\prod_{\alpha \in J} X_\alpha$ is Hausdorff in the product topology? What am I missing?","['general-topology', 'separation-axioms', 'product-space']"
487628,Slicker construction of the free product of groups,"The usual construction of the free product of groups $\{G_i\}_{i \in I}$ consists of taking the discriminated union $\coprod_{i \in I} G_i$ and taking the set of words satisfying a handful of conditions. Can this be done more slickly, i.e. without explicitly mentioning the words and reductions? Perhaps using the free functor? Suppose we define $ \ast_{i \in I} G_i$ to be the group given by the presentation $\langle \coprod_{i \in I} S_i | \coprod_{i \in I} R_i \rangle$ where, for each $i \in I$, $\langle S_i | R_i \rangle$ is a presentation for $G_i$. How can we show that this is indeed a coproduct? Specifically, how can we describe the canonical injections? To be clear, we may assume that free groups exist and that the forgetful functor has a left-adjoint.","['category-theory', 'free-groups', 'group-theory', 'abstract-algebra']"
487629,Column Space and SVD,"I was reading Gilbert Strang's book and he says that if $A=USV'$ be the SVD of A ( assume square for the moment) then the nullspace of A is given by the last $n-r$ columns of V and the column space by the first $r$ columns of $U$. I understand the null space part. If 
\begin{align}
A&=USV'\\
AV&=US\\
[Av_1 \;Av_2\cdots Av_r\cdots Av_n]&=[Us_1 \;Us_2\cdots Us_r\cdots Us_n]
\end{align}
The columns $Us_{r+1}\cdots Us_n$ are $0$ vectors and correspond to (applicatoin of A on) linearly independent vectors $v_{r+1}\cdots v_n$.
Thus, vectors $v_{r+1}\cdots v_n$ form the null space of A. How do I prove the statement on column space? I am not even able to start. This is not homework by the way. Just wanted to prove everything in Strang myself for fun. I feel it has to be inclusion proof where I show that any vector in the column space of A is in the column space of $\hat{U}$ and vice versa. ($\hat{U}$ is first r columns of $U$)","['matrices', 'linear-algebra', 'svd']"
487636,"For what $f$ is it true that $\lim_{n\to\infty}\sum_{k=0}^nf(n,k)=\sum_{k=0}^{\infty}\lim_{n\to\infty}f(n,k)$","Let $f:\mathbb{N_0}^2\to\mathbb{R}$. 
For what $f$ is it true that
$$\lim_{n\to\infty}\sum_{k=0}^nf(n,k)=\sum_{k=0}^{\infty}\lim_{n\to\infty}f(n,k):=\lim_{m\to\infty}\sum_{k=0}^m\lim_{n\to\infty}f(n,k)$$ . For example, if $f(n,k)=(1-k/n)^n$ satisfies this property, then
$$\lim_{n\to\infty}(1/n)^n+(2/n)^n+...+(n/n)^n=\lim_{n\to\infty}\sum_{k=0}^{n}(1-k/n)^n=\sum_{k=0}^{\infty}e^{-k}=e/(e-1)$$","['sequences-and-series', 'real-analysis', 'analysis', 'summation', 'limits']"
487660,Simple Composisitons,"I just need someone to check my work before I go on as I am just checking to make sure I am doing it right. $$g(t) = 2t^2 - 2t ,\ \ \ h(t) = 3t -1$$
$$g(2t^2 - 2t)$$
$$h(g(t)) = 3(2t^2 - 2t) - 1$$
simplified answer of $h(g(t)) = 6t^2 - 6t  - 3$ If anything seems off please let me know, Thanks.","['algebra-precalculus', 'function-and-relation-composition']"
