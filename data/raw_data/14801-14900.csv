question_id,title,body,tags
117702,"Orthogonal projections with $\sum P_i =I$, proving that $i\ne j \Rightarrow  P_{j}P_{i}=0$","I am reading Introduction to Quantum Computing by Kaye, Laflamme, and Mosca. As an exercise, they write ""Prove that if the operators $P_{i}$ satisfy $P_{i}^{*}=P_{i}$ and $P_{i}^{2}=P_{i}$ , then $P_{i}P_{j}=0$ for $i\ne j$.'' In the context of this problem, it has been assumed that $I=\sum_{i=1}^{n} P_{i}$, where I suppose that $n$ could be infinite. I have shown that this is true in the trivial case $n=2$, but the general case has been eluding me. How should I attack this?","['linear-algebra', 'quantum-mechanics']"
117704,uniform approximation by smooth functions,"Let $(M,g)$ be a closed, compact Riemannian manifold. Let $u \in C^{k}(M)$. Can I always find a sequence of $C^\infty$ functions $\{u_n\}$ such that $u_n$ converges to $u$ in $C^k$ norm?",['analysis']
117711,diffeomorphism-example,"Can anyone come up with a diffeomorphism of $\mathbb{R}^{2}$ onto the unit disc $\left \{ (x,y): x^{2}+y^{2}< 1 \right \}$? I tried the following example: $$F(x,y)=(\frac{x}{\sqrt{1+x^{2}+y^{2}}},\frac{y}{\sqrt{1+x^{2}+y^{2}}})$$, but I am not sure if this works out. In addition, it is very hard to prove that $Jf(x)\neq 0$.","['multivariable-calculus', 'real-analysis', 'analysis']"
117713,Closed form for a sequence related to divisibility,"If we consider intervals of the form $[1,p_k !! ]$ in which $p_k!! := 2\cdot3\cdots p_k$ we can ask about distribution of primes, near-primes, etc., on such intervals. A naive approach might be to note first that any interval of length $2n$ contains $n$ even and $n$ odd numbers. We label the evens [[2]] and the odds [[2']]. For the interval  $[1,3!!] = [1, 6] $, labeling numbers divisible by 3 as [[3]] and those not as [[3']], we have that 1/6 are even and divisible by 3, 2/6 are even but not divisible by 3, 1/6 are odd and divisible by 3, 2/6 are odd and not divisible by 3. More economically: $$D_3  = \frac{1}{3}\frac{1}{2} [[2,3]]+\frac{2}{3}\frac{1}{2}[[2,3']]+\frac{1}{3}\frac{1}{2}[[2',3]] + \frac{2}{3}\frac{1}{2}[[2',3']]$$ or $$D_3 = \frac{1}{6} [[2,3]]+\frac{2}{6}[[2,3']]+\frac{1}{6}[[2',3]] + \frac{2}{6}[[2',3']] $$ If we group according to the number of primes by which a number is divided, we get $$D_3 = \frac{1}{6}(2) + \frac{3}{6}(1) + \frac{2}{6}(0)$$ In words, there is one number on [1,6] divisible by both 2 and 3, there are three numbers divisible by either 2 or 3, and there are two numbers divisible by neither 2 nor 3 (i.e, 1,5). Going through the same process with 5 and 7: $$D_5 = \frac{1}{30}[[2,3,5]] + \frac{4}{30}[[2,3,5']] + \frac{2}{30}[[2,3'5]]+ \frac{8}{30}[[2,3',5']] + \frac{1}{30}[[2',3,5]] + \frac{4}{30}[[2',3,5']] + \frac{2}{30}[[2',3',5]]+ \frac{8}{30}[[2'3',5']]$$ and grouping, $$D_5 = \frac{1}{30}(3) + \frac{7}{30}(2) + \frac{14}{30}(1) + \frac{8}{30}(0).$$ Barring typos, etc., $$D_7 = \frac{1}{210}(4 ) +\frac{13}{210}(3) + \frac{56}{210}(2) + \frac{92}{210}(1) + \frac{48}{210}(0) $$ There are problems built into this approximation of divisibility. A number divisible only by $2$ may have repetitions of that factor--$4$, for example.  On $[1,30]$, $22$ has two factors, one of which is not in the set $\{2,3,5\}$. Likewise, on $[1,210]$, $121 = 11^2$, but with respect to $\{2,3,5,7\}$, $121$ is a ""prime.""  So the process doesn't exactly sort according to the number of divisors with repetition. In particular, the class of numbers in $D_{p_k} $ on $ [1, p_k!!] $ mutually prime to $\{ 2,3,\ldots,p_k\}$ is I think identical to $ P_k =  \prod_{n = 1}^k(1 - \frac{1}{p_k} )$ , a gross overestimate of the proportion of primes on these intervals. So much for motivation. Acknowledging the question is of limited interest, can anyone suggest a closed form for the sequence (omitting denominators): 1, 1 1, 3,  2 1, 7, 14, 8 1, 13, 56, 92, 48 ...etc.? Thanks.","['elementary-number-theory', 'sequences-and-series', 'probability', 'statistics']"
117714,Prove Taylor series converges to $f$.,"Let $f$ be an infinitely differentiable function on an interval $I$. If $a \in I$ and there are positive constants $C$, $R$ such that for every $x$ in a neighborhood of $a$ and every $k$ it holds that $|f^{(k)}(x)| \leq C  \frac{k!}{R^k}$ then prove that the Taylor series of $f$ about $a$ converges to $f(x)$. I think a good approach would be to estimate the error term. I'm not sure how to proceed exactly though. Thoughts?","['sequences-and-series', 'real-analysis']"
117717,How to show $f$ is continuous at $x$ IFF for any sequence ${x_n}$ in $X$ converging to $x$ the sequence $f(x_n)$ converges in $Y$ to $f(x)$,"Let $f : (X, d_X) \to (Y, d_Y )$ be a map between two metric spaces. Recall that $f$ is
called continuous at $x ∈ X$ if for any open ball $ B_f(x)(ϵ)$ of radius $ϵ$ around $f(x)$ there
exists a ball $B_x(δ)$ of radius $δ$ around $x$ such that $f(B_x(δ))⊂B_f(x)(ϵ)$. Show that
$f$ is continuous at $x$ if and only if for any sequence ${x_n}$ in $X$ converging to $x$ the
sequence $f(x_n)$ converges in $Y$ to $f(x)$. Hint: imitate the proof of the corresponding
statement for functions $R → R$.","['general-topology', 'metric-spaces', 'continuity']"
117719,Locus of the midpoint of a chord of an ellipse having a fixed length.,"Ellipse equation is $(\frac{x}{a})^2+(\frac{y}{b})^2=1$ and the length of line segment is $2k$, if we move the line segment all around of the ellipse while touching both ends to the ellipse. What is the path equation of middle point of the line segment that moved on ellipse? My sense says that the path equation is an ellipse but need to proof it and need to find what  the middle point path equation is. Thanks for answers and sorry if it was asked before. Note: If a=b  then the ellipse turns to a circle and the middle point path equation can be shown easily that ${x}^2+{y}^2=a^2-{k^2}$","['analytic-geometry', 'geometry', 'plane-curves', 'conic-sections']"
117727,Right versus left action,"In my algebraic topology course we have been studying covering spaces. There are two group actions on any fiber: the left action of the group of deck transformations and the right action of the fundamental group. There are various propositions proved about general group actions that will later be applied. In particular, Let $X$ be a transitive left $G$-set. If a subgroup $H$ of $G$ is the stabilizer of a point in $X$, then $X$ is $G$-isomorphic to the left-coset space of $H$, i.e., the collection of all left-cosets of $H$, where $G$ acts on a coset by left-translation. Here is my question: How do I translate this into a statement about right actions? Is it really so simple as flipping every occurence of 'left' to 'right'? Here is what I know: Given a right action of a group $G$ on a set $X$, we can define a left action as $gx := xg^{-1}.$ Also, any right action of $G$ on $X$ gives a left action of $G^{\text{op}}$ on $X$ and every group is isomorphic to its opposite via inversion. The Wiki article on group actions makes the claim that ""...only left actions can be considered without any loss of generality."" (Towards the bottom of the 'Definition' section.) This link seems to hint that the justification for such a claim lies in the fact that a group $G$ and its opposite are 'naturally' isomorphic. The problem is that I only have a vague idea as to what that means as I have only a very basic working knowledge of categories from my algebraic topology book. Though the 'rules for translation' that the latter link provides are helpful, I still feel like I don't have a very good understanding of what's going on. I realize what I'm looking for is a sort of theorem about theorems, which is strange. But can anybody offer some insight? If possible, can somebody elaborate on what this natural isomorphism has to do with anything? Basically, is the translation really so simple?",['group-theory']
117733,Fourier matrix - multiplicity of eigenvalues?,"This question is Miscellaneous Exercise M.10 in Chapter 8 ( Bilinear Forms ) of Artin's Algebra . (The sentences in italics are due to me.) The row and column indices in the $n \times n$ Fourier matrix $A$ run from $0$ to $n-1$, and the $i, j$ entry is $n^{-1/2}\;\zeta^{ij}$, with $\zeta = e^{2 \pi i / n} \;$. ( The author defined the matrix as $[\zeta^{ij}]$; I added the $n^{-1/2}$ factor for normalisation purposes. ) This matrix solves the following interpolation problem: Given complex numbers $b_0, \ldots, b_{n-1}$, find a complex polynomial $f(t) = c_0 + c_1 t + \cdots + c_{n-1} t^{n-1}$ such that $f(\zeta^{\nu}) = b_{\nu}$. (a) Explain how the matrix solves the problem. (b) Prove that $A$ is symmetric and normal, and compute $A^2$. (c) ( This part is marked with a star. ) Determine the eigenvalues of $A$. ( I presume that we are required to determine the multiplicity of eigenvalues as well. ) My work: (a) The interpolation problem boils down to solving a linear system $n^{1/2}Ac = b$ with $c = [c_\nu]$ and $b = [b_{\nu}]$. Since $A$ is unitary, the solution is given by $c = n^{-1/2} A^{\ast} b$. (b) Symmetry is obvious. A routine calculation shows that $A$ is unitary (hence normal). Also,
$$
A^2_{ij} = \frac{1}{n} \sum_{k} \zeta^{k(i+j)} = \begin{cases} 1, &\text{if } i+j=0 \pmod n, \\ 0, &\text{otherwise.} \end{cases}
$$
Thus $A^2$ is a permutation matrix, the permutation corresponding to which sends any index $i$ to the unique index $j$ such that $i + j \equiv 0 \pmod n$. This is a product of disjoint transpositions. (c) From the above description, it is easy to determine the spectrum of $A^2$: its eigenvalues are $\pm 1$, and the multiplicity of $-1$ is 
$$
\begin{cases}
\frac{n-1}{2}, &\text{odd } n, \\
\frac{n}{2} - 1, &\text{even } n.
\end{cases}
$$
(The corresponding eigenvectors are of the form $e_i + e_j$ and $e_i - e_j$, where $i + j = 0 \pmod n$.) Now, the eigenvalues of $A$ are in the set $\{ \pm 1, \pm i \}$, but I cannot determine the individual multiplicities. I appreciate any hints.","['matrices', 'linear-algebra', 'fourier-analysis', 'eigenvalues-eigenvectors']"
117734,Proof of greatest integer theorem: floor function is well-defined,"I have to prove that $$\forall x \in \mathbb{R},\exists !\,n \in \mathbb{Z} \text{ s.t. }n \leq x < n+1\;.$$ where $\exists !\,n $ means there exists a unique (exactly one) $n$ . I'm done with proving that there are at least one integers for the solution. I couldn't prove the ""uniqueness"" of the solution, and so I looked up the internet, and here's what I found: Let $\hspace{2mm}n,m \in \mathbb{Z} \text{ s.t. }n \leq x < n+1$ and $m \leq x < m+1$ . Since $n \leq x \text{ and } -(m+1) < -x$ , by adding both, $n + (-m-1) < (x-x) = 0$ . And (some steps here) likewise, $(x-x) < n+m+1$ . Now, can I add up inequalities like that, even when the book is about real analysis (and in which assumptions are supposed to be really minimal)? Or should I also prove those addition of inequalities? Thank you :D","['real-analysis', 'ceiling-and-floor-functions']"
117762,"If three dice are rolled, what is the probability that all three are the same number?",The dice are fair. You have a $1\over6$ chance of getting the first number. A $1\over6$ chance of the second and so on.  Is it just $({1\over6})^3$ (1/216) or is that not accounting for the second and third roll properly?,['probability']
117763,"Multiplying two averages, what to do with the deviations?","If I multiply the averages of two sets of data, then what can I conclude with the deviation of that data? That is, for a given average X1 and X2, both are different sets of data but related, I calculated a derived average X3 = X1 * X2. Both X1 and X2 also has their own standard deviation values, D1 and D2. How can I calculate the standard deviation value D3? My concrete sample problem to illustrate the use-case I have sample performance measurements of a computer operation, measured in miliseconds / invocation (the first data set) and invocations / day (the second data set). Both of these has a mean and a standard deviation value. I would like to get another measure that is in miliseconds / day . So I multiplied the first data with the second : X1 * X2 = X3
miliseconds / invocation * invocations / day = miliseconds / day The question is, how do I get the standard deviation value of X3 ? Thanks in advance.","['statistics', 'standard-deviation']"
117780,Proof by Induction: Solving $1+3+5+\cdots+(2n-1)$,"The question asks to verify that each equation is true for every positive integer n. The question is as follows: $$1+ 3 + 5 + \cdots + (2n - 1) = n^2$$ I have solved the base step which is where $n = 1$. However now once I proceed to the inductive step, I get a little lost on where to go next: Assuming that k is true (k = n), solve for k+1:

(2k - 1) + (2(k+1) - 1)
(2k - 1) + (2k+2 - 1)
(2k - 1) + (2k + 1) This is where I am stuck. Do I factor these further to obtain a polynomial of some sort? Or am I missing something?","['induction', 'summation', 'discrete-mathematics']"
117783,Limit of a Sequence involving $\frac {n^2} {\sqrt{n^{6}+k}}$,"I am stuck on this problem: Compute the limit of the sequence $(a_{n})_{n=1}^{\infty}$ defined by $$a_{n}:=\frac {n^2} {\sqrt{n^{6}+1}}+\frac {n^2} {\sqrt{n^{6}+2}}+\cdot \cdot \cdot + \frac {n^2} {\sqrt{n^{6}+n}}=\sum_{k=1}^{n} \frac {n^2} {\sqrt{n^{6}+k}}$$ So I am trying to find: $$\lim_{n \to \infty}\sum_{k=1}^{n} \frac {n^2} {\sqrt{n^{6}+k}}$$ In a situation like this should I be noting that the denominator is increasing in value faster than the numerator? My first thought was to do some manipulation.  I may have done something incorrectly. I began with the following. $$\frac {n^2} {\sqrt{n^6+k}}=\frac {n^2} {\sqrt{n^6(1+k/n^6)}}=\frac {n^2} {\sqrt{n^6}\sqrt{1+k/n^6}}=\frac {1} {n} \cdot \frac {1} {\sqrt {1+k/n^6}}$$ So I now have $$\lim_{n \to \infty} \frac {1} {n} \sum_{k=1}^{n} \frac {1} {\sqrt {1+k/n^6}}$$ Now, I am unsure about the following. It looks to me as if $k/n^6$ goes to zero as $n \to \infty $. That would result in $\sum_{k=1}^{n} \frac {1} {\sqrt {1+k/n^6}}=n$. So I would be left with $$\lim_{n \to \infty} \frac {n} {n}=1$$","['sequences-and-series', 'calculus']"
117788,Cauchy Criterion on the series $\frac{1}{n}$,"I have seen the statement a million times and I know it implies convergence but I've never actually seen how to use it. It seems much harder than proving a limit since there is an $m$ and an $n$. Can someone give an example, or even use this Criterion to show that $\frac{1}{n}$ is a convergent sequence? Suppose I have reduced the Cauchy Criterion inequality in a problem to
$\frac{n}{m}$, $m\gt n$, and $\frac{n}{m} > \epsilon$. If I want to find a lower bound for $n$, can I choose anything I want that will satisfy the above inequalities?","['sequences-and-series', 'real-analysis', 'analysis']"
117803,Name this paradox about most common first digits in numbers,"I remember hearing about a paradox (not a real paradox, more of a surprising oddity) about frequency of the first digit in a random number being most likely 1, second most likely 2, etc.  This was for measurements of seemingly random things, and it didn't work for uniformly generated pseudorandom numbers.  I also seem to recall there was a case in history of some sort of banking fraud being detected because the data, which was fudged, was not adhering to this law. It was also generalisable so that it didn't matter what base number system you used, the measurements would be distributed in an analagous way. I've googled for various things trying to identify it but I just can't find it because I don't know the right name to search for. I would like to read some more about this subject, so if anyone can tell me the magic terms to search for I'd be grateful, thanks!","['statistics', 'paradoxes', 'random']"
117807,Solve $ \sqrt{2-2\cos x}+\sqrt{10-6\cos x}=\sqrt{10-6 \cos 2x} $,"$$ \sqrt{2-2\cos x}+\sqrt{10-6\cos x}=\sqrt{10-6 \cos 2x} $$ I tried squaring and/or using $1-\cos x=2\sin^2{\frac{x}2}$, but no luck.",['trigonometry']
117818,Number of triplets of collinear points in a standard setting,"This might be a stupd inquiry, but I was working on something and stumbled upon this question: if say we are given $n$ points in plane that determine $k$ distinct lines, what is the number of triplets of collinear points? Any help would be really appreciated Sorry if it turns out to be too trivial or too hard to find some bounds. (I'm just tired of thinking about it without luck) Thanks!",['combinatorics']
117826,Find the range of the given expression?,"If p , q , r denotes the side of the triangle ,then the below expression will always lies between? $$\left(\frac{p}{q+r}\right) + \left(\frac{r}{q+p}\right) + \left(\frac{q}{p+r}\right)  $$ I tried to solve it by using the property that sum of length of 2 sides of triangle is always greater than 3rd side.
So p+q > r q+r > p r+q >p So the expression should be less than 3. But the answer in the book is : Range : 1.5 to 2 .
Thanks in advance.","['inequality', 'algebra-precalculus']"
117832,"Is there any trivial reason for $2$ is irreducible in $\mathbb{Z}[\omega],\omega=e^{\frac{2\pi i}{23}}$?","This naive question came as the last problem in my homework. The author asked me to use linear relations of the discriminant like $\operatorname{disc}(ra_{1},a_{2},...,a_{n})=r^{2}\operatorname{disc}(a_{1},...,a_{n})$, $\operatorname{disc}(a_{1}+\beta,a_{2},...,a_{n})=\operatorname{disc}(a_{1},...,a_{n})$ for $\beta$ a linear combination of $a_{i}$. I could not see how to make use of the hint or how to solve the problem in an easier way than taking the norm and evaluate, which is impractical since $46\times 23$ terms are involved.","['algebraic-number-theory', 'number-theory']"
117835,"How many sequence of integers ($j_1 , j_2 , . . . , j_k$) are there such that $0 ≤ j_1 ≤ j_2 ≤ . . . ≤ j_k ≤ n$?","I need to solve the problem, How many sequence of integers ($j_1 , j_2 , . . . , j_k$) are there
  such that $0 ≤ j_1 ≤ j_2 ≤ . . . ≤ j_k ≤ n$? I've been given a hint, (Hint: Reduce the problem to $0 < j_1 < j_2 < . . . < j_k < n)$. The answer will be in terms of k and n. First of all, I don't see how to reduce the problem, or what to do when it's reduced. Secondly, I feel bad about not having much to show for my effort, but I have been working on this problem for some time and I'm not sure where to start. If someone could give me a general outline of what method to use or something like that, I'd appreciate it.","['discrete-mathematics', 'inequality', 'combinatorics']"
117836,Is there a formula that can scale to find linear combinations that equal a sum?,"I'm not the best at math(but eager to learn) so please excuse me if I'm not explaining this problem correctly, I will try to add as much info to make it clear.  I basically receive 2 pieces of data,  one is a list of integers and the other is a target_sum, and I want to figure out all the ways I can use the list to equal the target sum. So for a list of [1,2,4] to a target_sum of 10 , I would get: 2 * 4 +  1 * 2 +  0 * 1
2 * 4 +  0 * 2 +  2 * 1
1 * 4 +  3 * 2 +  0 * 1
1 * 4 +  2 * 2 +  2 * 1
1 * 4 +  1 * 2 +  4 * 1
1 * 4 +  0 * 2 +  6 * 1
0 * 4 +  5 * 2 +  0 * 1
0 * 4 +  4 * 2 +  2 * 1
0 * 4 +  3 * 2 +  4 * 1
0 * 4 +  2 * 2 +  6 * 1
0 * 4 +  1 * 2 +  8 * 1
0 * 4 +  0 * 2 + 10 * 1 The current algorithm I'm using is two parts, one builds a look up table of what combinations are possible and the other builds the actual table:
Table building: for i = 1 to k
    for z = 0 to sum:
        for c = 1 to z / x_i:
            if T[z - c * x_i][i - 1] is true:
                set T[z][i] to true Possibility construction: function RecursivelyListAllThatWork(k, sum) // Using last k variables, make sum
    /* Base case: If we've assigned all the variables correctly, list this
     * solution.
     */
    if k == 0:
        print what we have so far
        return

    /* Recursive step: Try all coefficients, but only if they work. */
    for c = 0 to sum / x_k:
       if T[sum - c * x_k][k - 1] is true:
           mark the coefficient of x_k to be c
           call RecursivelyListAllThatWork(k - 1, sum - c * x_k)
           unmark the coefficient of x_k This is the basic idea, my actual code is a slightly different because I am using bounds to remove the possibility of infinite values(I say a single value cannot exceed the value of the sum). The problem is, the table building part does not scale. It is flawed in, at least two ways, one is its dependent on the previous number to be completed(thus I cannnot break it and run it individually for each number) and the second problem is it requires to read a table before it writes(I am learning about how to get around this technically but currently it makes the program very slow). Is there a more efficient way to do this that scales? Here's an approach I tried to take but failed(so far): create a large table full of all possible values.z to target_sum..
create another large table of T[z - c * x_i][i - 1] and compare if the values exist.
If they do exists, add  T[z][i] to a third table that contains the correct master I don't need code just the logic(if this is possible).  If it helps you(as it often helps me understand) here is some python code with my approach/examples: #data = [-2,10,5,50,20,25,40]
#target_sum = 100
data = [1,2,3,4,5,6,7,8,9,10]
target_sum = 10

# T[x, i] is True if 'x' can be solved
# by a linear combination of data[:i+1]
T = []           # all values are False by default
T.append([0, 0])                # base case

R=200 # Maximum size of any partial sum
max_percent=0.3 # Maximum weight of any term

for i, x in enumerate(data):    # i is index, x is data[i]
    for s in range(-R,R+1): #set the range of one higher than sum to include sum itself
        max_value = int(abs((target_sum * max_percent)/x))
        for c in range(max_value + 1):  
            if [s - c * x, i] in T:
                T.append([s, i+1])

coeff = [0]*len(data)
def RecursivelyListAllThatWork(k, sum): # Using last k variables, make sum
    # /* Base case: If we've assigned all the variables correctly, list this
    # * solution.
    # */
    if k == 0:
        # print what we have so far
        print(' + '.join(""%2s*%s"" % t for t in zip(coeff, data)))
        return
    x_k = data[k-1]
    # /* Recursive step: Try all coefficients, but only if they work. */
    max_value = int(abs((target_sum * max_percent)/x_k))
    for c in range(max_value + 1):
       if [sum - c * x_k, k - 1] in T:
           # mark the coefficient of x_k to be c
           coeff[k-1] = c
           RecursivelyListAllThatWork(k - 1, sum - c * x_k)
           # unmark the coefficient of x_k
           coeff[k-1] = 0

RecursivelyListAllThatWork(len(data), target_sum) Any help or suggestions would be appreciated. I have worked on this for a long time and all my experiments have failed.  I'm hoping to get the correct answer but even ideas of different approaches would be great so I can experiment with them. Thank you. p.s. I have asked a question on stackoverflow 2 days ago about improving my existing algo, but I got answers from posters who admitted to not fully understanding what I was asking for and because they have answered the question, I am unable to delete it to post here. I have flagged it for deletion. Update: Regarding some of the comments,I'm not looking for a fast way of doing this(although it would be nice), I'm looking for a scalable way..my method works but each loop is dependent on the last loop which causes it to be bound to a single process. The math is in such a way that it builds upon previous results. If I can somehow break the process up into independent parts then I can use more cpu/computers to handle the work. I know it'll take a long time, but if it takes 600 hours on one cpu, then two should cut it down a bit and so on..right now I can't use other computers so I'm forced to wait 600 hours(while everything else on the system is ideal). please help! Also the results are large but not infinite as I have bounds set so the number cannot exceed a certain percent of target_sum.","['linear-algebra', 'abstract-algebra', 'number-theory']"
117847,Proving that $\sum\limits_{i=1}^k i! \ne n^2$ for any $n$ [duplicate],This question already has answers here : Closed 12 years ago . Possible Duplicate: How to prove that the number 1!+2!+3!+…+n! is never square? Show that $\displaystyle\sum\limits_{i=1}^k  i!$ is never a perfect square for $k\ge4$ I could prove $k!$ is never a perfect square using Bertrand's Postulate. But this one seems to be an uphill task.,"['algebra-precalculus', 'number-theory']"
117853,Is it possible to formulate variational calculus geometrically?,"In textbooks I've seen differential geometry is done with finite-dimensional manifolds. Is it possible to generalise to banach manifolds so as to formulate the calculus of variations within it, or does this naive approach hit problems? And if so where?","['calculus', 'classical-mechanics', 'differential-geometry']"
117860,How to define sparseness of a vector?,"I would like to construct a measure to calculate the sparseness of a vector of length $k$. Let $X = [x_i]$ be a vector of length $k$ such that there exist an $x_i \neq 0$ . Assume $x_i \geq 0$ for all $i$. One such measure I came across is defined as $$\frac{\sqrt{k} - \frac{\|X\|_1}{{\|X\|_2}}} {\sqrt{k} -1}\;,$$ where $\|X\|_1$ is $L_1$ norm and $\|X\|_2$ is $L_2$ norm. Here, $\operatorname{Sparseness}(X) = 0$ whenever the vector is dense (all components are equal and non-zero) and $\operatorname{Sparseness}(X) = 1$ whenever the vector is sparse (only one component is non zero). This post only explains the when $0$ and $1$ achieved by the above mentioned measure. Is there any other function defining the sparseness of the vector.",['linear-algebra']
117864,Petri net analysis (attainability),"how to analyse safe petri net for attainability? 
(i need algorithm) I have an oriented multigraph $\mathbb{G}$. $A$ - adjacency matrix. $m$ - the count of input elements. $n$ - the count of vertices in $\mathbb{G}$ let numerate input elements $b_i,\; i\in\{1..m\}$ and vertexes $v_j,\; j\in\{1..n\}$ limitation $m \leq n$ (safe petri net) let make marker, which connect input element $b_i$ and vertex $v_j$, where it stand and define it like this: $(b_i,v_j)$ first state of petri net is $M_0$: $\{(b_i,v^0_j),i\in\{1..m\},\;j\in\{k_1..k_m\},\; k_i \in \{1..n\},\; k_i\not = k_j\}$ last state of petri net is $M_1$: $\{(b_i,v^1_j),i\in\{1..m\},\;j\in\{p_1..p_m\},\; p_i\in\{1..n\},\; p_i \not = p_j\}$","['optimization', 'discrete-mathematics', 'algorithms']"
117882,Measures on function spaces,"Assume I have a measurable space $(\Omega, \mathcal{F}, \mu)$ , $\mu$ being a finite measure ( $\mu(\Omega) < \infty$ , if needed). Let $L = \{F:L^1(\Omega, \mu) \mapsto \mathbb{R}\}$ ( $L$ is the set of not necessarily linear functionals on my measurable functions). My questions are: Can we define a $\sigma$ -algebra on $L$ ? I guess at least the power set should do Can we define a measure $\nu$ on $L$ ? I've started thinking of $\forall f \in L^1(\Omega, \mu),~\nu(\{f\}=\|f\|_{L^1(\Omega,\mu)})$ . But then I am pretty sure we lose the finiteness of the measure Do we have any results such as Hardy and littlewood inequalities ? They might be other ways of defining all this lot. And actually, I might forget an important part of the whole thing, please do tell me if there is anything completely stupid in there. And, of course, thanks for any help you can give!","['online-resources', 'measure-theory', 'functional-analysis']"
117886,The graph of a measurable function,How to prove that the graph of measurable function from $R^d\to R$ is of measure zero? I proved for a continuous function but for any measurable function is more subtle.,['measure-theory']
117887,Complex numbers and Nonstandard Analysis,"A finite hyperreal number $r$ is a number defined as a sum of a real number and an infinitesimal number $\omega$:
$$r=a+\omega$$
Do you know if is it possible (and useful) to define a complex number as $$c=a+i\omega\ ?$$ Thanks","['nonstandard-analysis', 'complex-analysis']"
117896,Differentiable at the orgin and plot of a function.,"My first question is: 1) Is $f(x,y)=\dfrac {xy(x^{2}-y^{2})}{{(x^{2}+y^{2})}^{3/2}}$ differntiable at $(0,0)$ ? Considering polar co-ordinates: $x=r\cos \theta$ and $y=r\sin \theta$ . $$\begin{align*}
\Rightarrow f(x,y) &= \frac {r\cos \theta r\sin \theta (r^{2}\cos ^{2}\theta-r^{2}\sin ^{2}\theta)}{{(r^{2}\cos ^{2}\theta+r^{2}\sin ^{2}\theta)}^{3/2}} \\
\\
&= \frac {r^{4}\cos\theta\sin\theta(\cos ^{2}\theta-\sin ^{2}\theta)}{r^{3}} \\
\\
&= r\cos\theta\sin\theta(\cos ^{2}\theta-\sin ^{2}\theta)
\end{align*}$$ Hence linear in $r$ . Therefore there doesn't exist a unique tangent plane at $(0,0)$ . Therefore $f(x,y)$ is not differentiable there. 2) Considering $$f(x,y)= \left\{\begin{array}{ll}
\dfrac {x^{3}y}{x^{6}+y^{2}} & \text{if }(x,y) \neq 0, \\
\\
0 & \text{if }(x,y)=(0,0).
\end{array}\right.$$ If you were to plot the function $\theta \mapsto f(r\cos\theta, r\sin\theta)$ for $\theta \in [0,2\pi]$ what might the plot look like. Justify your answer. I am bit unsure on what this plot would be and the reason. I'm guessing at the crinkle function? Many thanks in advance.","['multivariable-calculus', 'calculus']"
117917,Analytic in $\mathbb{C}$ implies $\left|\frac{f'(x)}{f(x)}\right|$ is bounded in $\mathbb{R}$?,"If $f(z)$ is an analytic function in the complex plane, $z=x+iy$, and $f(x)\neq 0$ for all $x\in \mathbb R$, does this imply that $\frac{f'(x)}{f(x)}$ is bounded on $\mathbb R$?i.e., $\big|\frac{f'(x)}{f(x)}\big|\leq C$, for some $C>0$.",['complex-analysis']
117924,Evaluate $\int_0^1 \frac{\ln(1+bx)}{1+x} dx $,"What is $ \displaystyle\int_0^1 \frac{\ln(1+bx)}{1+x} dx $? I call it $f(b)$ and differentiate with respect to be $b,$ a bit of partial fractions and the $x$ integral can be done. Then I integrate with respect to $b$ and get a bit lost. Can some of the terms be expressed in terms of dilogarithms? I get lost in the details! Could we avoid all this just go straight to dilogarithms (with a cunning substitution)?","['special-functions', 'calculus', 'integration']"
117926,Finding mode in Binomial distribution,"Suppose that $X$ has the Binomial distribution with parameters $n,p$ . How can I show that if $(n+1)p$ is integer then
$X$ has two mode that is $(n+1)p$ or $(n+1)p-1?$","['statistics', 'probability', 'binomial-distribution']"
117931,Existence of non-atomic probability measure,"The Question Let $X$ be a set. Let $\mathcal{F}\subseteq P(X)$ be a $\sigma$-algebra. (Or, if it makes a difference, let $X$ be a topological space and $\mathcal{F}$ the Borel sets.) When can we guarantee the existence of and how can we construct a non-atomic probability measure $\mu$ on $(X,\mathcal{F})$? (In addition to being a measure, we ask that $\mu(X) = 1$ and that if $F\in\mathcal{F}$ and $\mu(F) \neq 0$, there exists a proper measurable subset $E\subsetneq F$ such that $0 < \mu(E) < \mu(F)$.) Some remarks The result of Sierpinski guarantees that $\mu$ actually takes on a continuum of different values. So necessarily $\mathcal{F}$ needs to be uncountable and hence $P(X)$ has to be uncountable. This puts a lower bound on how many elements there can be in $X$. (And trivially one sees that if $X$ is finite any probability measure must have atoms.) I expect, however, that there may be other necessary conditions for the existence of a non-atomic probability measure. On the sufficient side, the only result I am familiar with that explicitly constructs a measure is the various constructions of the Lebesgue measure. This construction makes use of the local structure of Euclidean space and hence also works for, say, topological manifolds. (Okay, there's also the ultrafilter construction for additive measures, but while the constructed measures are probability, they have a lot of atoms.)","['probability-theory', 'set-theory', 'measure-theory', 'reference-request']"
117934,What is wrong with this solution to a combinatorial problem?,"In a pool game, there are 15 numbered balls, of which one is black and the other 14 consist of 7 colored pairs. For instance, balls 1 and 9 could be yellow, 2 and 10 blue, and so on. At the beginning of a game, the balls are arranged in an equilateral triangle. Assuming the arrangement is performed at random and uniformly, what is the probability that two of the balls placed in the triangle vertices will have the same color? The answer to the problem is 1/5, and the calculation is quite simple. However, my first (dull) attempt to solve it was to condition the arrangements on the position of the black ball, like the following: Consider events S = {arrangements with two vertices with the same color} and B = {arrangements with the black ball in one of the corners}. We have: $$
P(B) = 3/15 \\
P(S|B) = \frac{3 \times 7 \times 2 \times 12!}{15!} = \frac{1}{65}
$$ Explained: Ways to pick position of the black ball = 3, to pick a color = 7, to pick an ordering among the two balls with the same color = 2, to pick the other 12 balls = 12! For the event that the black ball is not in one of the corners, we have: $$
P(B^c) = 12/15 \\
P(S|B^c) = \frac{3 \times 7 \times 2 \times 12 \times 12!}{15!} = \frac{12}{65}
$$ Which is similar to the calculation of P(S|B), except that we have 12 possibilities to pick a third vertex (cannot be black). By applying the formula of conditional probabilities, we should get: $$
P(S \cap B) = P(S|B) \times P(B) = \frac{3}{975} \\
P(S \cap B^c) = P(S|B^c) \times P(B^c) = \frac{144}{975} \\
P(S) = P(S \cap B) + P(S \cap B^c) = \frac{147}{975} = \frac{49}{325}
$$ Which is clearly not 1/5. Why didn't this reasoning provide the correct answer? Thank you","['probability', 'combinatorics']"
117956,Proof of Taylor's series expansion with two terms,"I am looking for a simple direct proof of the fact that
$$
\frac{\frac{f(x + \Delta x) - f(x)}{\Delta x} -f'(x)}{\Delta x} \stackrel{\Delta x \to 0}{\to} \frac{1}{2}f''(x),
$$
or, equivalently,
$$
f(x+\Delta x) = f(x) + f'(x)\Delta x + \frac{1}{2}f''(x)\Delta x^2 + o(\Delta x^2).
$$ holds for a twice-differentiable $f(x)$. I remember there were times when I could derive this directly from the following definition of a derivative:
$$
f(x+\Delta x) = f(x) + f'(x)\Delta x + o(\Delta x)
$$
in a couple of simple lines. A long time has passed since then and now I need to either recollect this magical ""obvious"" proof of mine or find out I was wrong then and the actual proof is more involved.","['calculus', 'derivatives', 'taylor-expansion']"
117962,Jacobian matrix normalization,"I have a problem with normalization of the Jacobian matrix. There seems to be no clear method for doing it: in some literature, it has been normalized by using some characteristic length, which is mathematically correct, but the problem is what this characteristic length should be. (Mostly, in robotics, the characteristic length is the distance from the base coordinates to the platform (end effector) coordinates.) It is confusing. My Jacobian matrix is $6 \times 6$, with the first three columns having units of $\mathrm{rad}/\mathrm{L}$ and the last three columns being dimensionless. My question is, how can I make the entire Jacobian matrix dimensionless? Is there a way to normalize this matrix according to some mathematical relations (theory)?","['matrices', 'physics', 'coordinate-systems', 'multivariable-calculus']"
117963,(good) numerical inversion of an almost singular matrix: is it possible?,"Ok, so I know that if I have a system that looks like Ax=b it is foolish to solve it by solving for the inverse of A and one should instead use something like Gaussian elimination, or something like that. However, I am trying to calculate H(s) = B*(sI-A)^-1*C , where s is some scalar and A , B , C are matrices (of dimensions such that H(s) is a scalar too, if that helps). Now, this is a large system and I can't do this calculation symbolically, but when I try and plug in the s values that I am interested in, the (sI-A) matrix has really bad condition numbers (something like 10^10 ) and I highly doubt that my numeric results are in any way accurate --- it's not just the condition numbers, the answer comes out completely unlike what I would expect it to be. Do you have any ideas on either some algorithm that could help me out, or a math trick that would scale things in a such a way that inversion would not run into machine precision problems? Just so everyone knows, this comes up when trying to calculate a transfer function from the state space representation of a linear system.","['matrices', 'linear-algebra', 'inverse']"
117986,"Uniquely express a bounded linear functional on $C^k([0,1])$ as the sum of $k+1$ functionals?","Let $f$ be a function defined on a $J=[0,1]$, which is $k$-times differentiable on $J$; i.e. $f\in C^k(J)$. By the Riesz representation theorem we know that for any complex Radon measure $\mu$ on $J$ , we have the isometric vector space isomorphism between the space of complex Radon measures on $J$ and the space of bounded linear functionals, given by $$\mu\mapsto \int f \ d\mu.$$ Given a bounded linear functional $I$ (which we know is of the form $\int f\ d\nu$) on $C^k(J)$, I want to show that we can find a unique $\mu, a_0,\dots,a_{k-1}$ where $\mu$ is a complex Borel measure and the $a_i$ are constants, with $$I(f) = \int_{J} f\ d\nu = \int_J f^{(k)}\ d\mu + \sum_{i=0}^{k-1} a_i f^{(i)}(0)$$ This is also found as an exercise in Folland, 7.27, if that is helpful. Any guidance would be greatly appreciated.","['measure-theory', 'functional-analysis']"
117998,Finding the error in this proof that 1=2,"I have a ""proof"" that has an error in it and my goal is to figure out what this error is. The proof: If $x = y$, then $$
\begin{eqnarray}
x^2 &=& xy \nonumber \\
x^2 - y^2 &=& xy - y^2 \nonumber \\
(x + y)(x - y) &=& y(x-y) \nonumber \\
x + y &=& y \nonumber \\
2y &=& y \nonumber \\
2 &=& 1
\end{eqnarray}
$$ My best guess is that the error starts with the line $2y = y$. If we accept that $x + y = y$ is true, then $$
\begin{eqnarray}
x + y &=& y \\
x &=& y - y \\
x &=& y = 0
\end{eqnarray}
$$ Did I find the error? If not, am I close?","['fake-proofs', 'algebra-precalculus', 'solution-verification']"
118002,Find the derivative of the following equation..,"I have a question in my manual and I am not able to answer it, I'd appreciate some help please. Find $ \dfrac{dy}{dx} $  if  $ 2x^2y + 3xy^2 = 6 $ I'm confused with = 6.. Thanks !","['multivariable-calculus', 'implicit-differentiation', 'calculus', 'derivatives']"
118005,Closed image of locally compact space,"If $X$ is locally compact and $f : X \rightarrow Y$ is continuous closed and surjective, must $Y$ be locally compact? This seems like it should be relatively simply to answer, but I am unable to find either a proof or a counterexample. Any ideas?",['general-topology']
118014,"For curves, is being defined over a number field invariant under birational equivalence","Suppose that a (connected) Riemann surface $X$ is birational to a Riemann surface $Y$ which can be defined (algebraically) over the field of algebraic numbers. Does this imply that $X$ itself can be defined over the field of algebraic numbers? Basically, I'm asking if the property ""can be defined over the field of algebraic numbers"" is ""birationally  invariant"". Is this something that holds for general schemes?","['arithmetic-geometry', 'riemann-surfaces', 'algebraic-geometry', 'algebraic-curves']"
118021,Reference for the subgroup structure of $\rm{PSL}_2(q)$,"This material is covered in detail in Dickson's ""Linear Groups with an exposition of the Galois Field Theory"", chapter XXII and Huppert's ""Endliche Gruppen"", chapter II, paragraph 8. Since I don't speak german and Dickson's treatment often requires deciphering, I was wondering if there is a ""modern"" account of this somewhere.","['reference-request', 'finite-groups', 'group-theory']"
118030,Unitary orbit of the Jordan matrices,"Let $$
\mathcal{J}=\{A\in M_n(\mathbb{C}):\ A \text{ is a Jordan matrix}\}
$$ Then it is well-known that the similary orbit of $\mathcal{J}$ is all of $M_n(\mathbb{C})$ . What is the unitary orbit of $\mathcal{J}$ ? Is it dense? It cannot be all of $M_n(\mathbb{C})$ , because every matrix in $\mathcal{J}$ and its unitary conjugates have the property that eigenvectors corresponding to different eigenvalues are orthogonal to each other.","['linear-algebra', 'functional-analysis']"
118040,Connected components of a scheme are irreducible,"Update 2: I posted an answer to this question. Update 1: Problem is now solved because of the excellent hint by Qil. So, if someone wants to post an answer just for the sake of closing this question you are more than welcome. I will post an answer myself after I am back from a short vacation, if someone hasn't already left an answer by then. The following question is problem in Goertz and Wedhorn's Schemes With Examples : Let $X$ be a scheme. Then consider the following assertions: (i) Every connected component of $X$ is irreducible. (ii) $X$ is the disjoint union of its irreducible components. (iii) For all $x \in X$, the nilradical of $O_{X,x}$ is a prime ideal. Show that $(i) \Rightarrow (ii) \Rightarrow (iii)$. Show that all assertions are equivalent if the set of irreducible components of $X$ is locally finite (i.e. for all $x \in X$ there exists an open neighborhood of $x$ such that only finitely many irreducible components of $X$ pass through that open neighborhood). So, I have managed to prove $(i) \Rightarrow (ii)$ which is a topological property, $(ii) \Rightarrow (iii)$ which follows from the fact the the irreducible components of $Spec(O_{X,x})$ are in bijection with the irreducible components of $X$ pasing through $x$. In fact, you can even use this fact to prove $(iii) \Rightarrow (ii)$ (I have not used the fact that the irreducible components of $X$ are locally finite so far). However, I have no idea how to prove $(iii) \Rightarrow (i)$ or say $(ii) \Rightarrow (i)$ using the hypothesis that the irreducible components of $X$ are locally finite. I think I am missing something obvious, and any hint would be appreciated. I have been thinking about this problem for a while, and I would not like complete solutions, just hints to get me started in the right direction. If I am unsuccessful, then I will later edit this question and ask for a solution. Also, although this might sound like a homework problem, it is not.",['algebraic-geometry']
118045,Exercise: Continuity and Local Boundedness,"Consider function $f:\mathbb{R}^n \setminus \{0\} \times \mathbb{R}^n \rightarrow \mathbb{R}_{> 0}$ that is: continuous in the first argument; locally bounded in the second argument. Consider a sequence $\{x_i\}_{i=1}^{\infty}$ such that $x_i \in \mathbb{R}^n$, $x_i \rightarrow x$. Prove that $$ \limsup_{i \rightarrow \infty} \ f(x,x_i) - f(x_i,x_i) \ = \ 0. $$","['real-analysis', 'limits']"
118046,Exact Probability of Collision of Two Independent Random Walkers After N Steps,"Two drunks start together at the origin at $t=0$ and every second they move with equal probability either to the right or to the left, each drunk independently from the other. What is the probability that after $N$ seconds they meet again? I may be on something but I don't know how to write this sum in a close form: \begin{equation}
\sum_{n=0}^{[N/2]}\frac{N!}{n!n!(N-2n)!}\frac{1}{2^{N+2n}} 
\end{equation} Any hints?","['random-walk', 'probability']"
118062,The closure of $C^1$ in the  functions of bounded variation,"Consider the space $(BV[0,1];||.||)$ with the norm $$||f||=|f(0)|+V_{f}[0,1]$$
Where $V_{f}[0,1]$ is the variation of $f$. My questions what is the closure of $C^1[0,1]$ with respect to this norm? Another question is how to prove that this norm is Banach?","['measure-theory', 'functional-analysis', 'real-analysis']"
118074,Why is every holomorphic bijection of the Riemann sphere a Möbius transformation?,"Just based on some reading, I know that every Möbius transformation is a bijection from the Riemann sphere to itself. I'm curious about the converse. For any holomorphic bijection on the sphere, why is it necessarily a Möbius transformation? Is there a proof or reference of why this converse is true? Thanks. (I would appreciate an explanation at the level of someone whose just self-studying complex analysis for the first time.)","['riemann-surfaces', 'mobius-transformation', 'complex-analysis']"
118082,Application of Inverse function theorem,"I am stuck on the following problem, and I need any kind of help that leads to solve it: Let $L:\mathbb{R}^{n}\rightarrow \mathbb{R}^{n}$ be an isomorphism and let: $f(x)=L(x)+g(x)$, where: $\left \| g(x) \right \|\leq M\left \| x \right \|^{2}$ and $f\in C^{1}$. Show that $f$ is locally invertible near $0$ What I was trying to do is to show that $Jf(0)\neq 0$. Obviously: $f(0)=L(0)+g(0)=g(0)$ because $L(0)=0$. That's all what I could deduce. Any help?","['multivariable-calculus', 'real-analysis', 'analysis']"
118086,Graph and manifold,"I needed help to prove the following: Let $k, n, m$ be elements of the natural numbers  and $g : R^m \to R^n$. 
Prove that the graph of $g$ is an $m$-manifold of class $C^k$ if and only if $g$ is of class $C^k$ from munkres","['manifolds', 'differential-geometry', 'analysis']"
118095,Solving $x$ for $y= 3^x-2^x$,"Is there a way to solve for $x$ given the function: $$y= 3^x-2^x$$ in terms of $y$? I tried a lot of algebraic manipulations but I ended up nothing. Or, should we say it it impossible to do so?",['algebra-precalculus']
118108,How does a function acting on a random variable change the probability density function of that random variable?,"Given a random variable $X$ with probability density function $P(X)$, and given a transformation function $f(x)$, how does one determine the new resultant probability density function: $P(f(X))$? For example: Given random variable $X$ which is evenly distributed over the range $[0,2\pi ]$ such that $P(X) = \dfrac{1}{(2\pi)}$, what would be the probability density function of random variable $Y$ where $Y = \sin(X)$? This blog post, explains how to get the pdf for $\sin(X)$, but I'd like to know if there is a way to solve this problem in the general case for a transformation of $f(X)$.","['probability-distributions', 'probability']"
118148,Prove that $\int_0^1 \left| \frac{f^{''}(x)}{f(x)} \right| dx \geq4$.,"Let $f(x) \in C^2[0,1]$, with $f(0)=f(1)=0$, and $f(x)\neq 0$ when $x \in(0,1)$. Show that
$$\int_0^1 \left| \frac{f''(x)}{f(x)} \right| dx \geq 4.$$","['calculus', 'real-analysis']"
118165,Intuition behind growth rate of some functions,"This one really crushed my intuition. Let say a function $f$ grows faster than a function $g$ if $ \lim_{n \to \infty} \frac{f(n)}{g(n)} = \infty $ Which of the following functions grows the fastest : $2^{n/2}$ $3^{n/3}$ $5^{n/5}$ $1000^{1000/n}$ $10000^{10000/n}$ My bet would be on either function 1. or 5. but as it turns out, function 2. is growing the fastest. After doing some calculations I was able to assure myself that that is really so. But my main doubt is still there. Why is this obvious? How can one intuitively explain this behavior?","['asymptotics', 'intuition', 'soft-question', 'limits']"
118172,Does a function have to be continuously differentiable to be integrable,"Is the only requirement for a function to be integrable just for it to be continuous on an entire specified interval like $[a,b]$? The function $f(x)$ that I'm talking about is in the integrand and has the mapping $f:\mathbb{R} \rightarrow \mathbb{R}$ $$\int_a^b \! f(x) \, dx$$ What about for complex functions?","['calculus', 'analysis']"
118181,Uniform integrability definitions,"I am confused with the way uniform integrability is defined in the context of random variables. Keeping with the analysis idea, I had expected this definition: If $X$ is a random variable, given $\epsilon \ge 0$ and $A \subseteq \Omega$, there must be a $\delta$ such that $\int_{A} d\mu \le \delta$ and $\int_{A} X(\omega) d \omega \le \epsilon$. Instead this is what I find in most places including Wiki (when $K \subset L^1(\mu)$): $$\lim_{c \to \infty} \sup_{X \in K} \int_{|X|\ge c} |X| d \mu = 0$$ What is the reason for this different definition? Why does the bound on the value of $X$ even make an appearance?","['probability-theory', 'measure-theory']"
118186,Tori and metrics,"I have been doing some reading on tori. What I can make out of it is that a torus can be equipped with different metrics -- locally Euclidean or as an embedded surface. It is said however that the torus with the locally Euclidean metric cannot be realized as an embedded surface. Why is this true and what is the metric as an embedded surface like? Why would we want the latter metric, since it seems to me the former is more natural? Thanks.","['metric-spaces', 'differential-geometry']"
118190,Reference for general-topology,"Though there are several posts discussing the reference books for topology, for example best book for topology .
But as far as I looked up to, all of them are for the purpose of learning topology or rather on introductory level. I am wondering if there is a book or a set of books on topology like Rudin's analysis books, S.Lang's algebra, Halmos' measure (or to be more updated, Bogachev's measure theory), etc, serving as standard references. Probably, such a book should hold characteristics such as being self-contained, covering the most of classical results, and other good properties you can name. In the end, I only have the interest on general-topology (topological space, metrization, compactification...), and optionally differential topology (manifolds). So please don't divert into algebraic context. Cheers. ---------------------update----------------------- Thanks for all the delightful replies.
I will try to quickly check the books mentioned beneath.
And I may accept the answer which is most closed to my personal flavor. Sorry for others.
It's a pity no multiple acceptance can be made for such a ref-request question. Greetings.","['book-recommendation', 'general-topology', 'reference-works', 'reference-request', 'big-list']"
118198,Trying to prove that a group is not Cyclic,"Given the following Euler groups :
$$\begin{align*}
U_{12} &= \{1,5,7,11\}\\
U_{16} &= \{1,3,5,7,9,11,13,15\}
\end{align*}$$ I want to prove that they are not cyclic.
I used the following theorem : A group of order $n$ is cyclic if and only if it has an element of order $n$. Let's take for example $U_{12}$:  (I will use the notation of $o(x)$ to denote the order of the element $x\in G$) $$\begin{align*}
o(5)&\colon 5^2=25 \to 25\bmod 12 = 1\to o(5)=2\\
o(7)&\colon 7^2= 49 \to 49\bmod 12 = 1 \to o(7)=2\\
o(11) &\colon 11^2 = 121 \to 121\bmod 12=1 \to o(11)=2
\end{align*}
$$ Then by using the above theorem , this group is indeed not a cyclic group. Question : do I really have to check each element in the group for its order ? Regards","['finite-groups', 'group-theory']"
118207,Convergence of $\Gamma(p)$ for $0<p\leq 1$ and divergence for $p \leq0$.,"Can someone show me a proof or any clear resource about convergence of gamma function for values of $p$ less than zero. If possible I need proofs using integration by parts. My problem evaluating convergence is below. $\displaystyle\int^\infty_0 e^{-x} \hspace{1 mm}x^p \ dx$  and $p<0$ Why does this integral not converge for $p \le -1$, but converge for $-1<
p\le 0$ A proof using series or integrals (like an integral smaller than other convergent integral is convergent) would be appericiated.","['special-functions', 'gamma-function', 'convergence-divergence', 'integration']"
118212,interval sequences which contains infinite items of an arithmetic progression,"Here's a problem in real analysis which has bothered me and my friends for several days: For an arbitrary sequence of intervals $(a_i,b_i)$, $a_i$ and $b_i$ tend to infinity and the intersection of any two intervals is empty, must there be an arithmetic progression such that there are infinite items of the progression lying in the interval sequence? thank you",['analysis']
118221,What distinguishes measure theory and probability theory?,"It is clear that the theory of probability works primarily with limited measures on measurable spaces. On the other hand, there is a folklore that says that what distinguishes measure theory and probability theory is the conditional probability and conditional expectation. But conditional probabilities and conditional expectations are derived from the Radon–Nikodym theorem and a measure with respect to another measure. And the Radon–Nikodym theorem is a typical result of measure theory. Question 1: So we could see the theory of probability as a subdiscipline of measure theory? Question 2: Would be possible to give another basis for the theory of probability rather than through measure theory?","['probability-theory', 'measure-theory', 'soft-question']"
118226,How to prove that a linear system is *not* base point free?,"Assume I have a line bundle $\mathcal{L}$ on a projective, nonsingular variety $X$ over, say, an algebraically closed field (in fact, you may assume $\mathbb{C}$). Given global sections $s_0,\ldots,s_k\in\mathcal{L}(X)$, how to prove that they do not generate $\mathcal{L}$ globally? I'd think that this is best done by contradiction, but I can't think of any theorems that strongly rely on the assumption that a line bundle is globally generated by certain particular sections. Note that $\mathcal{L}$ may very well be globally generated (in fact, in my case, it most certainly is) - but I want to prove that certain sections do not generate it globally. So, what I am basically asking for, are results that include a base-point free linear system in their assumptions, so I can use that to produce a contradiction. My first impule was to consider the induced morphism $\phi:X\to\mathbb{P}^k$, but that's already where I get stuck. If it helps, the case $X=\mathbb{P}^n$ and $\mathcal{L}=\mathcal{O}_X(1)$ is already interesting to me, but it'd (of course) be better if the strategy works even in the more general setting.",['algebraic-geometry']
118230,On the closedness of $L^2$ under convolution,"It is a direct consequence of Fubini's theorem that if $f,g \in L^1(\mathbb{R})$, then the convolution $f *g$ is well defined almost everywhere and $f*g \in L^1(\mathbb{R})$. Thus, $L^1(\mathbb{R})$ is closed under convolution, and it is a Banach algebra without unit since we have the inequality $$\|f*g\|_{1} \leq \|f\|_1 \|g\|_1 \qquad (f,g \in L^1(\mathbb{R})).$$
Now, it follows from Hölder's inequality that if $f,g \in L^2(\mathbb{R})$, then $f*g$ is bounded. My question is the following : Does $f*g$ necessarily belongs to $L^2(\mathbb{R})$? In other words, is $L^2(\mathbb{R})$ closed under convolution? Since a quick google search seem to result in a negative answer, I also ask the following question : Can you give an explicit example of two functions $f, g \in L^2(\mathbb{R})$ such that $f*g \notin L^2(\mathbb{R})$? Thank you,
Malik","['convolution', 'real-analysis']"
118247,double integral with change of variables,"I try to understand change of variables for double integrals. For this reason I try to calculate $\int_0^{\pi/2}\int_0^{\pi/2}\cos\theta\cos{\phi}\,d\theta d\phi$ by using this change $\alpha=\theta+\phi$, $\beta=\theta-\phi$ and $\cos\theta\cos\phi=\frac{1}{2}(\cos\alpha+\cos\beta)$. I repeat I know how to calculate the first integral and this is just an exercise for me. I found that the Jacobian is $J=-\frac{1}{2}$ but I even don't found on which surface I have to integrate! Does somebody have an idea?","['multivariable-calculus', 'calculus', 'integration']"
118253,How to compute this integral of Bessel functions?,"I have $\alpha_\max$ a real number between $0$ and $\frac\pi2$. Furthermore $\zeta$ and $\xi$ are positive real numbers. Now I would like compute the integral $$\int_0^{\alpha_\max} \mathrm{e}^{i \zeta \cos \alpha} \cos^n \alpha \, \sin^m \alpha J_k(\xi \sin \alpha) \, \mathrm{d}\alpha$$
For positive integers $n, m$ and $k$. Of course, these mess things up, so I first want to try a particular case where $k = 1$, $n = 1$ and $m = 2$. So I want to find the value of $$\int_0^{\alpha_\max} \mathrm{e}^{i \zeta \cos \alpha} \cos \alpha \, \sin^2 \alpha J_1(\xi \sin \alpha) \, \mathrm{d}\alpha \tag{1}$$ Let's take the series expansion for our Bessel function
$$J_1(x) = \sum_{m=0}^\infty \frac{(-1)^m}{m! \, \Gamma(m+2)} {\left(\tfrac{1}{2}x\right)}^{2m+1}.$$ If we plug this in and pretend life is good we want to compute $$\int_0^{\alpha_\max} \mathrm{e}^{i \zeta \cos \alpha} \, \sin^{2(m + 1) + 1} \alpha \, \cos \alpha \, \mathrm{d}\alpha$$ We also know
$$\sin^{2(m + 1) + 1}\alpha = \frac{1}{4^{m + 1}} \sum_{k=0}^{m + 1} (-1)^{m - k + 1} \binom{2(m + 1) + 1}{k} \sin{((2(m - k + 1)\alpha)}$$ Alright! Let's just write this hideous integer in the $\sin$ as $m$ and we now want to compute $$\int_0^{\alpha_\max} \mathrm{e}^{i \zeta \cos \alpha} \, \sin(m \alpha) \, \cos \alpha \, \mathrm{d}\alpha$$ This looks quite friendly, doesn't it? We can simplify it even more using a trigonometric identity which is well known to those who know it well. I'll recycle $m$ again. So we want to compute $$\int_0^{\alpha_\max} \mathrm{e}^{i \zeta \cos \alpha} \, \sin(m \alpha) \, \mathrm{d}\alpha$$ Great! Messing a bit around with the integrand using Mathematica makes me suspect that the primitive is of the form $$\sum_{k = 0}^ {m - 1} c_k \mathrm{e}^{i \zeta \cos \alpha} \cos(k \alpha)$$ So let's compute its derivative shall we? $$\frac{\mathrm{d}}{\mathrm{d}\alpha}\sum_{k = 0}^ {m - 1} c_k \mathrm{e}^{i \zeta \cos \alpha} \cos(k \alpha) = \sum_{k = 0}^m [-k c_k - \frac{i \zeta}{2} c_{k - 1} + \frac{i \zeta}{2} c_{k + 1}] \sin(k \alpha) \mathrm{e}^{i \zeta \rho \cos \alpha}$$ So we can extract by equating the previous to the integrand:
$$\begin{align}
c_m &= 0;\\
-k c_k - \frac{i \zeta}{2} c_{k - 1} + \frac{i \zeta}{2} c_{k + 1} &= 0 \text{ for } 1 < k < m;\\
-\frac{i \zeta}{2} c_{m - 1} &= 1;\\
-c_1 + \frac{i \zeta}{2} c_2 - i \rho c_0 &= 0.
\end{align}$$ I have not the slightest clue how to solve this. Making a generating function gives a horrendous differential equation which would even make the devil cry. So, any suggestions on how to compute my dear integral $(1)$? Edit : I believe that: $$\newcommand{\d}{\, \mathrm{d}}\int J_1(\xi \sin\alpha) \d\alpha = \sum_{m = 0}^\infty \sum_{k = 0}^m \frac1{4^m} \frac{(-1)^m}{m!(m + 1)!} \frac{(-1)^{2m + 1 - k}}{2k + 1} {2m + 1 \choose m - k} \left(\frac{\xi}2 \right)^{2m + 1} \cos((2k + 1)\alpha).$$ Edit : It seems to be slightly off. I'll check again tomorrow it is past 2AM. Edit : Now it is correct.","['bessel-functions', 'special-functions', 'integration']"
118278,expectation and group of permutations,"Let $r_i, i=1,\ldots,m$ be random variables with $P(r_i=1)=P(r_i=-1)=1/2$. let $b_i, i=1,\ldots,m$ be real numbers. I should calculate $E\left(|\sum_{i=1}^m b_ir_i|^4| \sum_{i=1}^m r_i=0\right)$ using the following hint: Let $$X=\left\{r\in\{1, -1\}^m \quad | \quad r_i= \begin{cases}
1,&\quad \text{if} \quad i \quad\text{is in }Y\\[4mm]
-1,&\quad \text{if}\quad i \quad\text{is not in }Y \end{cases} \right\},$$
where $Y\subset\{1,\ldots,m\}, \operatorname{card}(Y)=m/2$. For $X$ we put into correspondence the group $\Pi_m$ of all permutations of the set $\{1,\ldots,m\}$ as follows
$$
\pi(\cdot)\longleftrightarrow r_i= \begin{cases}
1,&\quad \text{if} \quad \pi(i)\leq \frac m2\\[4mm]
-1,&\quad \text{if} \quad \pi(i)>\frac m2 \end{cases}.
$$ On the group $\Pi_m$ I consider the normalized counting measure $\mu_m(A)=\operatorname{card}(A)/m!$ for $A\subset \Pi_m$ and the normalized metric $d_m(\pi_1, \pi_2)=\frac 1m \#\{i:\pi_1(i)\neq \pi_2(i), \quad \pi_1, \pi_2 \in \Pi_m\}$. It is known that $\Pi_m$ is a normal Levy family and  for $A_\epsilon=\{\pi\quad| \exists \pi'\in A: d_m(\pi, \pi')\leq \epsilon\}$ we have
$$
\inf_{\mu_m(A)\geq 1/2}\mu_m(A_\epsilon)\geq 1-2\exp(-c\epsilon^2m), \quad \text{$c>0$ is a constant}.
$$
It is known that in a Levy family we have phenomenon of concentration of measure around one value of a function. So, if $f:\Pi_m\longrightarrow R$ is a function with modulus of continuity $\omega_f(\epsilon)=\sup_{d_m(\pi_1, \pi_2)}|f(\pi_1)-f(\pi_2)|$ and with median $M_f$, then
$$
\mu\left(|f-M_f|\leq \omega_f(\epsilon)\right)\geq 2\inf_{\mu_m(A)\geq 1/2}\mu_m(A_\epsilon)-1.
$$ But now I am confused with the next step. What can I say about expectation which I need to find? Thank you for your help.","['statistics', 'measure-theory', 'probability', 'combinatorics']"
118292,Clarkson type inequality,"Is it true that for $p\in (1,2)$ the following inequalities holds:
$$ 2^{p-1} (|x|^p+|y|^p)\leq |x+y|^p+|x-y|^p \leq 2 (|x|^p+|y|^p)$$
for $x, y \in \mathbb{R}$ ? Thanks.","['inequality', 'analysis']"
118300,An application of J.-L. Lion's Lemma,"Let $X,Y$ and $Z$ be three Banach spaces with norms $\|\cdot\|_X$, $\|\cdot\|_Y$,$\|\cdot\|_Z$. Assume that $X\subset Y$ with compact ""injection"" and that $Y\subset Z$ with continuous injection. Then $$\forall\epsilon>0, \exists  C_{\epsilon}\geq0  $$ Satisfying $$\|u\|_Y\leq \epsilon \|u\|_X+C_{\epsilon}\|u\|_Z \ \ \forall u \in X.$$ My question are I) Where can I find a proof of this result? II) As a consequence of that how to prove $$\max_{[0,1]}|u|\leq \epsilon\max_{[0,1]}|u'|+C_{\epsilon}\|u\|_{L^1{[0,1]}} \forall \in C^1({[0,1]})?$$","['functional-analysis', 'banach-spaces']"
118315,infinitely many units in $\mathbb{Z}[\sqrt{d}]$ for any $d>1$.,"I am working through Neukirch's Algebraic Number Theory on my own.  Exercise 6 in Section 1 (page 5) is to show that the ring $\mathbb{Z}[\sqrt{d}]$, for any squarefree rational integer $d>1$, has infinitely many units. I know that in $\mathbb{Z}[\sqrt 2]$ there are infinitely many units, because 
$(\sqrt{2} + 1)(\sqrt{2} - 1) = 1$ and then taking $n$th powers shows that $(\sqrt{2} + 1)^n$ is a unit for any $n\ge 1$. Similarly in $\mathbb{Z}[\sqrt{3}]$, we have $(2+\sqrt{3})(2-\sqrt{3}) = 1$, and then $(2+\sqrt{3})^n$ for $n\ge 1$ is an infinite family of units. I can find other ""fundamental units"" for other specific values of $d$. But it seems I have to show that the (Pell) equation $a^2 - db^2 = \pm 1$, for any $d>1$, has an integer solution $(a, b) \ne (\pm 1, 0)$, because I know if I can find one solution, then I can get infinitely many. But from my limited knowledge of Pell's equation this is a difficult problem (using techniques such as continued fractions.) Maybe there is a simpler nonconstructive proof that I'm missing.  Any hints or suggestions?",['number-theory']
118318,Finding unknown 3D vector given 2 known vectors and 2 known angles,"So I have a 3D vector math problem that I'm having difficulty solving. Basically I have two known vectors in the form (x,y,z), let's call them C and P, and I want to find a third unknown vector, let's call it A. I know the angle between C and A is 60 and the angle between P and A is 90. I also know that C and P are unit vectors already and that my unknown A is going to be a unit vector. I also know that I already have two solutions to the problem (as opposed to 0 or 1 possible solutions depending). I formulated it as follows and I think this is correct. So I have: C=(0, 0, 1) P=(0.61, 0.61, 0.5) A=(x, y, z) This gives me the following three equations which should allow me to find both solutions to my three variables but I'm not getting results that make any sense. $$
\cos(90) = 0.61x + 0.61y + 0.5z
$$
$$
\cos(60) = 0x + 0y + 1z
$$
$$
\sqrt{x^2 + y^2 + z^2 } = 1
$$ Finding z is easy as it must be 0.5 (which makes sense as z must be fixed for both solution in my problem). I've tried solving using substitution from here to find a quadratic equation for y, finding both y values, then using substitution again to find corresponding x values. I'm not getting any useful results however as the results aren't unit vectors and are therefore incorrect. For clarity sake I'm trying to find the intersection points between a great circle and small circle on a 3D sphere. P represents the normal vector to the plane that forms the great circle and N represents the centre of the 60 degree small circle on the sphere.","['analytic-geometry', 'trigonometry', 'euclidean-geometry']"
118330,Prove $\binom{n}{2k+1}=\sum_{i=1}^n{\binom{i-1}{k}\binom{n-i}{k}}$,"I have to prove the equality
$$\binom{n}{2k+1}=\sum_{i=1}^n{\binom{i-1}{k}\binom{n-i}{k}}$$ What I can see is that the left hand side is the number of ways to choose $2k+1$ elements from $n$ elements, while the right hand side is the sum of the ways you can choose k elements from one set, and k from another, effectively choosing $2k$ elements from a set of $n-1$ elements. This doesn't make sense to me. I would expect that the left hand side would be the sum of the ways to choose $2k+1$ elements from $n$ elements, choosing from two different sets. Can anyone help me with this?","['discrete-mathematics', 'combinatorics']"
118359,Canonical divisor of an abelian variety,"Let $A$ be an abelian variety over a field $k$ and let $K_A$ be its canonical divisor.  Then I'm almost certain that $K_A$ is trivial, but I can't seem to prove it, nor find a counter example, nor find any reference on abelian varieties that even mentions canonical divisors. Does anyone know a reference saying (or an idea for a short proof) that the canonical divisor on an abelian variety is trivial? I'd prefer not to assume anything about $k$, but a result with $\operatorname{char}(k) = 0$ would be better than nothing.","['abelian-varieties', 'algebraic-geometry']"
118383,convergence of $\sum \limits_{n=1}^{\infty }\bigl\{ \frac {1\cdot3 \cdots (2n-1)} {2\cdot 4\cdots (2n)}\cdot \frac {4n+3} {2n+2}\bigr\} ^{2}$,"I am investigating the convergence of
$$\begin{split}\sum _{n=1}^{\infty }\left\{ \dfrac {1\cdot 3\cdots (2n-1)} {2\cdot 4\cdots (2n)}\cdot \dfrac {4n+3} {2n+2}\right\} ^{2} &= \sum _{n=1}^{\infty }\left\{ \dfrac {\prod _{t=1}^n (2t-1)} {\prod _{t=1}^n (2t)}\cdot \dfrac {4n+3} {2n+2}\right\} ^{2} \\
&=\sum _{n=1}^{\infty }\left\{ \prod _{t=1}^n\left( 1-\dfrac {1} {2t}\right) \dfrac {4n+3} {2n+2}\right\} ^{2}
\end{split}$$
which after some manipulations I have reduced to
$$\sum _{n=1}^{\infty }e^ \left\{ 2\ln \left(2 -\dfrac {1} {2n+2}\right) +2\cdot \sum _{t=1}^{n}\ln \left( 1-\dfrac {1}{2t}\right) \right\} $$
and from an alternative approach I was able to reduce it to
$$\sum _{n=1}^{\infty } \dfrac{\left( 4n+3\right) ^{2}}{4\left(n+1\right)^{2}} \prod _{t=1}^n\left( 2+\dfrac{1}{2t^{2}}-\dfrac{2}{t}\right)$$ 
I am unsure how to proceed from here in either of the two cases. Any help would be much appreciated.","['convergence-divergence', 'sequences-and-series', 'real-analysis', 'limits']"
118391,"Conditions under which the Limit for ""Measure $\to 0$""  is $0$","Let $\mu$ be a probability measure on $X$, so that $\int_X \mu(dx) = 1$. Say under which conditions on the function $f:  X \rightarrow \mathbb{R}_{> 0} \ $  (that is measurable and integrable) we have that $$ \lim_{\mu(A) \rightarrow 0 } \int_A f(x) \mu(dx) = 0 $$","['probability-theory', 'measure-theory']"
118397,Check my solution to $x^2 + x + 1 > 0$,"I spent an hour or so yesterday trying to solve the inequality $x^2 + x + 1 > 0$. Since I'd spent so long on a problem didn't seem like it should be that difficult, I decided I'd call it a day and try it again later. I just had another look at it and this solution became immediately obvious: $$x^2 + x + 1 > 0 \ \ \forall \ \ x \in \mathbb{R}$$ I'd justify this by stating that $x^2 > x \ \ \forall \ \ x \in \mathbb{R}$. Because of this, even if $x < 0$, the right hand side of the inequality will always be positive. Am I correct?","['inequality', 'algebra-precalculus']"
118435,The Group of Homeomorphisms,"I have been looking at Topological Groups, and I recently read about the group $\operatorname{Homeo}(X)$ of all homeomorphisms of $X$ onto itself. In particular, when $X$ is a metric space. The subgroup $\operatorname{Is}(X)$ of all isometries of $X$ onto itself equipped it with the topology of pointwise convergence turns out to be a topological group. I verified that the multiplication and inverse operations are continuous. I've read that if $X$ is a normal space, then $\operatorname{Homeo}(X)$ equipped with the closed-base topology is a topological group. Also, if $X$ is a compact Hausdorff space, then $\operatorname{Homeo}(X)$ equipped with the compact-open topology is a topological group. My question is about what happens if we equip $\operatorname{Homeo}(X)$ (where $X$ is a metric space) with the topology of pointwise convergence. Is this still a topological group? Is there a specific space $X$ such that $\operatorname{Homeo}(X)$ equipped with the topology of pointwise convergence is not a topological group?","['general-topology', 'topological-groups']"
118436,"Proving divergence of a series, $\sum a_n/(z+n)$, $a_n=\pm1$, alternating $p+q$ negative terms with $p$ positive terms","We observe that the series $$\dfrac {1} {z} -\dfrac {1} {z+1}+\dfrac {1} {z+2}- \dfrac {1} {z+3}+\ldots $$ is conditionally convergent, except for certain exceptional values of $z$ ($z\in\mathbb{C}\setminus{{-\infty,\infty}}$ interpreted via ratio test), but the series $$\dfrac {1} {z}+\dfrac {1} {z+1}+\ldots +\dfrac {1} {z+p-1}-\dfrac {1} {z+p}-\dfrac {1} {z+p+1}-.\ldots -\dfrac {1} {z+2p+q-1}+\dfrac {1} {z+2p+ q} +\ldots $$ in which $(p + q)$ negative terms always follow $p$ positive terms, is divergent. The second series i think can be rewritten as $$\sum _{t=0}^{t=\infty }\left(\sum _{n=t\left( 2p+q\right)}^{n=t\left( 2p+q\right) + \left( p-1\right) }\dfrac {1} {z+n}-\sum _{n=t\left( 2p+q\right) + p}^{n=t\left( 2p+q\right) + \left(p+q-1\right) }\dfrac {1} {z+n}\right)$$ but i am not sure how to proceed forward to prove this statement from here. Any help would be much appreciated.","['convergence-divergence', 'sequences-and-series', 'real-analysis', 'limits']"
118439,"Show $\int_0^\infty x^{-\alpha}\sin x dx$ exists for $\alpha \in (0,2)$.","Show that $\int_0^\infty x^{-\alpha}\sin x dx$ exists for $\alpha \in (0,2)$. This is a real analysis class question.  I am not quite sure how to show this.  I tried a whole bunch of things like integration by parts, bounding sine, ... and nothing worked. Any hints, ideas, or solutions would be appreciated.",['real-analysis']
118446,Calculating probability with n choose k,"I'm trying to solve a problem two different ways, and I can'd seem to figure out where I'm going wrong. I have 4 buckets (A,B,C,D), and 4 identical marbles. Each marble has an equal chance of being put in any of the 4 buckets, and each is placed independently (each bucket can have 0-4 marbles placed in it, with a total of 4 across all buckets) I need to calculate the probability of bucket A being empty after the four marbles are placed. My intuition says I can calculate the probability of the marble being placed in to any bucket except A as $\frac{3}{4}$. Then I can multiply the probabilities together since they are independent. So I can do $\left(\frac{3}{4}\right)^ 4$, which seems right. But I think I should also be able to get the answer by calculating the number of ways that leaves A empty divided by the total number of ways the marbles can be placed in the 4 buckets. When I do that I get: total ways: 
$\left(\dbinom{4}{4}\right)$  $\longrightarrow$ $\dbinom{7}{4}$ $\longrightarrow$ 35 ways with A empty: $\left(\dbinom{3}{4}\right)$ $\longrightarrow$ $\dbinom{6}{4}$ $\longrightarrow$ 15 But that gives me $\frac{15}{35}$, which is not the same as $\left(\frac{3}{4}\right)^ 4$ I'm guessing I am over counting or something else dumb, but I'm really stumped. Thanks for the help!","['discrete-mathematics', 'probability', 'combinatorics']"
118466,Question about a closed mapping.,"We just learned about quotient mappings and various properties of the quotient topology. I'm curious about metrizability under these mappings. Namely, if $f: X \rightarrow Y$ is a closed continuous surjection and $X$ is metrizable, does it follow that $Y$ is metrizable?",['general-topology']
118467,A sequence of singular measures converging weakly* to a continuous measure,"Can anyone provide a sequence of singular (w.r.t. Lebesgue measure) measures $\in\mathcal{M}([0,1])=C[0,1]^*$ converging $weakly^*$ to an absolutely continuous (w.r.t. Lebesgue measure) measure?","['measure-theory', 'singular-measures', 'functional-analysis', 'real-analysis']"
118468,hadamard inequality,"It is given that: $\left |\det(A) \right |\leq n^{\frac{-n}{2}}\left \| A \right \|^{n}$ where $A$ is an $n$ by $n$ matrix, and $\left \| A \right \|$ is the Hilbert Schmidt norm 
(i.e: $\left \| A \right \|=\left ( \sum_{i,j=1}^{n}a_{ij}^{2} \right )^{\frac{1}{2}}$). Now, I want to prove the following inequality based on the above one: $$\left |\det(A) \right |\leq \prod_{j=1}^{n}\left ( \sum_{i=1}^n a_{ij}^2\right )^{\frac 12}.$$ Any help?","['multivariable-calculus', 'linear-algebra', 'real-analysis', 'analysis']"
118490,Holomorphic function of a matrix,"A statement is made below. The questions are: (a) Is the statement true? (b) If it is, does it appear in the literature? Here is the statement. For any matrix $A$ in $M_n(\mathbb C)$, write $\Lambda(A)$ for the set of eigenvalues of $A$. Recall that there is a unique continuous $\mathbb C[X]$-algebra morphism 
$$
\mathcal O(\Lambda(A))\to M_n(\mathbb C),
$$
where $\mathcal O(\Lambda(A))$ is the algebra of those functions which are holomorphic on (some open neighborhood of) $\Lambda(A)$. Recall also that this morphism is usually denoted by $f\mapsto f(A)$. (Here $X$ is an indeterminate.) Let $U$ be an open subset of $\mathbb C$, let $U'$ be the open subset of $M_n(\mathbb C)$ defined by the condition 
$$
\Lambda(A)\subset U,
$$
and let $f$ be holomorphic on $U$. (The fact the $U'$ is open follows from Rouché's Theorem .) STATEMENT. The map $A\mapsto f(A)$ from $U'$ to $M_n(\mathbb C)$ is holomorphic.","['several-complex-variables', 'polynomials', 'matrices', 'linear-algebra', 'reference-request']"
118503,A Problem of Counting Expectation of Inversions in a Half-Sorted List.,"Has any one got any idea about this problem? I found my formula is too complicated to get a closed form. Let $P_{2n}$ be the set of all $(2n)!$ permutations of $\{1,2,3,···,2n\}$. For any $\sigma = (a_1,a_2,···,a_{2n})$ in $P_{2n}$, a pair of positions $(i,j)$ such that $i < j$ is called an inversion in $\sigma$ if $a_i > a_j$. For example, in the permutation $(a_1,a_2,a_3,a_4) = (2,4,1,3)$, $(2,4)$ is an inversion as $a_2 = 4 > a_4 = 3$; in fact, in this case there are exactly $3$ inversions $(1, 3)$, $(2, 3)$, $(2, 4)$. For any $\sigma = (a_1,a_2,···,a_{2n})$ in $P_{2n}$, let $f(\sigma)$ be the permutation obtained from $\sigma$ by sorting the sublist of odd positions. That is, $f(\sigma) =(b_1,b_2,···,b_{2n}) \in P_{2n}$, where $b_{2k} = a_{2k}$ for $1\le k\le n$, and $b_1 < b_3 < b_5 < ··· < b_{2n-1} $ is the sorted list of $a_1,a_3,···,a_{2n−1}$. For example, for $\sigma = (3,8,2,5,6,7,1,4)$, $f(\sigma) = (1,8,2,5,3,7,6,4)$. For a random $\sigma $ uniformly chosen from $P_{2n}$, let $I_n$ be the random variable corresponding to the number of inversions in the permutation $f(\sigma)$.  Determine $E(I_n)$ and $\text{Var}(I_n)$.","['probability', 'combinatorics']"
118505,Solving a kind of differential equation,"Is it possible to solve the following differential equation: $g: \Bbb{R} \to \Bbb{R}$, $$ g'(a)=a\cdot g(a-1),\ g(0)=\frac{1}{2}$$ I can't find any method for ordinary differential equations which works here.",['ordinary-differential-equations']
118510,Affine scheme $X$ with $\dim(X)=0$ but infinitely many points,"As the title says, I'm looking for an affine scheme of dimension zero, but with infinitely many points. At first I doubted that something like this could exist, and I still can't think of an example, but I'm beginning to think there must be one. Such a scheme corresponds to a zero-dimensional ring $A$ of Krull dimension $0$, i.e. the only 'chains' of prime ideals in $A$ have to be the prime ideals themselves. If $k$ is a field, I could take $n$-fold product $k^n=k\times...\times k$. The prime ideals in $k^n$ are exactly those of the form $k\times...\times\langle0\rangle\times...\times k$, with the $\langle0\rangle$ at any position. Hence in $k^n$ there are no chains of prime ideals of length greater than $0$. But of course we only have finitely many (namely, $n$) points. Is it possible to carry this construction over to an infinite product of copies of $k$? Take for example $k^\mathbb{N}$, which is a countable product of copies of $k$. At first I thought this was just $k[[x]]$, but the ring structure is not the same. Wikipedia states that in such an infinite product there exist ideals which are not of the type $\prod_{n\in\mathbb{N}}I_n$. An example is the ideal $I$ of elements of $k^\mathbb{N}$ with only finitely many non-zero components. Although having an infinite indexing set, products of ideals of $k$ that contain only one factor $\langle 0\rangle$ are still prime, so we have infinitely many points in $\operatorname{Spec}(k^\mathbb{N})$. But what about the dimension? There exist other prime ideals, so I'm not sure how to go on about that. Does $k^\mathbb{N}$ work at all, or are there other - maybe simpler - examples? Or even none? EDIT: In case of an infinite product of rings $A_i$, does the spectrum of $\prod_i A_i$ still correspond to some disjoint union of schemes? In my case, geometrically thought: by taking one more copy of $k$ into the product, we are adding a new point to our affine scheme. So from my intuition, the construction of $k^\mathbb{N}$ as an affine scheme with inf. many points and dimension $0$ should be working. The rest of the exercise (Find examples or prove there are none. A short check if what I write is correct would be very kind): An affine scheme $X$ with $\dim(X)=1$ and exactly one point. An affine scheme $X$ with $\dim(X)=1$ and exactly two points. As for 1: This should not be possible, since exactly one point means there is just one prime ideal, so the dimension of $X$ will be $0$. 2: $k[[x]]$ should work here, as well as any discrete valuation ring (not a field). Thanks for reading this wall of text and for your help!","['commutative-algebra', 'algebraic-geometry', 'schemes']"
118518,Is the set of polynomial with coefficients on $\mathbb{Q}$ enumerable?,"Using the definition of enumerability of sets: A non-empty set B is enumerable iff there is a bijection $f:\mathbb{N}\supset L \rightarrow B$. So, I have to prove that the set of polynomial of one variable with coefficients on $\mathbb{Q}$ is enumerable. What I thought is that I can write every polynomial $p_0=A_0^0+A_1^0X+\dots +A_n^0X^n$ as $$p_0=(A_0^0,A_1^0,\dots ,A_n^0,\dots ),$$ where the $A_i's$ are 0 except for a finite number of them.
To say that this set is enumerable is the same that to say (denoting this set by B): $$B=\{p_1,p_2,\dots\}$$ Now define the polynomial $$ p=(x_0 \neq A_0^0, x_1 \neq A_1^1, \dots), $$ where every $x_i \neq A_i^i$. This polynomial is obviously not in the list B. My question is: my approach is right to conclude that the set B is non-enumerable?","['elementary-set-theory', 'real-analysis']"
118521,different concepts of abel summation?,"I have a little question concerning abel-summmation. In some books the n-th abel-mean of a sequence $(x_n) \subset \mathbb{K}$ is defined as:
$$ A_{n,r}[x_n] = (1 - r) \sum_{k=0}^{n} x_k r^k $$ In other books the abel-means are defined as:
$$ A_{n,r}[x_n] = \sum_{k=0}^{n} x_k r^k $$ In both sources it says, that $(x_n)$ converges to $x$ is the sense of abel if
$$ \lim_{r \nearrow 1}\lim_{n\to\infty}A_{n,r}[x_n] = x $$ Here is my question: Are these two concepts equivalent? Are the limits (if exist) in both cases the same? With best regards, Mat","['limits', 'ergodic-theory', 'analysis']"
118525,A sufficient condition for a function to be of class $C^2$ in the weak sense.,Let $f\colon\mathbb{R}\to\mathbb{R}$ be a continuous function with weak derivative (i.e. the derivative in the sense of distribution) in $C^1(\mathbb{R})$. Does this condition imply that $f$ is two times continuously differentiable (i.e. $f\in C^2(\mathbb{R}))$?,"['distribution-theory', 'real-analysis', 'analysis']"
118526,Fitting a sine wave of known frequency through three points,"We have a computationally expensive function of a large set of data and an angle, that is known to result in a sine wave: $$ f(\text{data}, \theta) \approx a \sin (\theta + b) + c$$ We want to find the constants $a$, $b$, and $c$, executing the function as few times as possible.",['statistics']
118545,Approximating the Irrationals by Compact Sets from below,"Let $P$ be the set of irrational numbers in $[0,1]$. The set $P$ has Lebesgue measure $1$ and by regularity, there is for every $\epsilon>0$ a compact set $C\subseteq P$ satisfying $\lambda(C)>1-\epsilon$. The proof I know for this fact gives no indication as to how the approximating compact sets might look like. This leaves a big gap in my intuition and I would therefore like to know: Is there an explicit way to construct for a given $\epsilon>0$ a
  compact set  $C$ of irrational numbers between $0$ and $1$ such that
  $\lambda(C)>1-\epsilon$?",['measure-theory']
118566,What equity is necessary to offer the doubling cube in Backgammon (dice game),"Edit: This question is a lot shorter than it is. Don't get intimidated. If you know backgammon, just skip to question 2. In Backgammon, each game is played for one point (or one dollar) between two players. There is a die, called the doubling cube , which has the numbers $2, 4, 8, ...$, in the middle of the board (it is not 'owned' by anyone). The players take turns rolling two regular dice (not the doubling cube) and moving. But before each roll, a player can 'offer the cube' (or 'offer to double', 'double', etc.) which is basically saying ""Hey, why don't we play this game for 2 points"". The other player can drop , or refuse the cube, and lose one point, or may accept , or take , the cube, in which case the game continues for twice as many points as before. A player's equity in the game is the probability that he'll win a cubeless game, where cubeless means neither player can offer the cube (or a one point game). (For backgammon players who know the rules, I'm ignoring gammons and backgammons, so the equity equals the probability of winning. Edit: As @Henning Makholm's first answer indicates, I also do not want to include the equity of owning the doubling cube. I have two questions, but I know the answer to the first one and I think I'm calculating it right. 1) What equity does the player receiving the cube require in order to accept it? Answer, I'm told, is $.25$? The receiving player will accept the double when the expected value of taking it is greater than the expected value of dropping (which automatically loses him $1$ point). $p$ is the probability (equals equity) of the receiving player winning (are you guys following all this?). $E(take) \ge E(drop) \\
2p-2(1-p) \ge -1 \\p > .25$ I'm nearly certain that's correct, so 2) What equity is required for a player to offer the cube (offer to double the game's stakes)? How is that calculated? We don't know whether the cube's recipient will accept or not. I start the same as question 1: The giver will double when his expected value of doubling is greater than his EV of not doubing (duh!). If $EV(rolling)$ is $p-(1-p)$, and $EV(doubling)$ is $2p-2(1-p)$, then $E(doubling) > E(rolling) \\
2p-2(1-p) > p-(1-p) \\
p > .5$ Which can't possibly be correct. While I'm not BG expert, I did used to play for (small amounts) of money in NYC. There is no way in heck that I would double with 51% chances. OK, that's all I got. How do we figure this out?
Thanks.","['dice', 'recreational-mathematics', 'probability']"
118569,Is there an upper bound to the number of rings that can be obtained from a semigroup with zero by defining an additive operation?,"Let $\mathscr S$ be the class of all semigroups with zero. For $(S,\times,0)\in\mathscr S,$ I want to count additive operations $+$ on $S$ such that $(S,+,\times,0)$ is a ring (possibly without unity). For $S\in\mathscr S,$ let $\Sigma_S$ be the set of all such additive operations on $S$. Let, for $+_1,+_2\in \Sigma_S,$ define  $+_1\sim +_2$ to mean that $$(S,+_1,\times,0)\cong (S,+_2,\times,0).$$ Let $$\Sigma'_S:=\Sigma_S/\sim.$$ Let $$\kappa_S:=\operatorname{card}(\Sigma_S)$$ and $$\kappa'_S:=\operatorname{card}(\Sigma'_S).$$ Are there upper bounds to the values of $\kappa_S$ and $\kappa'_S$ for $S\in \mathscr S?$ Do they admit all non-negative integer values? If not, which non-negative integer values do they admit? These questions are not similar to anything I know and I don't even know how to search for answers in literature. I'm especially curious what the behavior of $\kappa_S$ and $\kappa'_S$ is for finite semigroups $S.$ EDIT I have found this question on MO. Arturo Magidin gives an example there of two non-isomorphic rings having isomorphic multiplicative structures. If I understand correctly, this is proven by using the unique factorization property in polynomial rings over rings with the unique factorization property. So my question isn't trivial, which I didn't know at the time of asking: there is a semigroup with zero for which there are at least two additive operations making the semigroup two non-isomorphic rings. EDIT An answer to the following questions wouldn't be off-topic: Is there a semigroup $S$ with $0$ such that $\kappa_S$ is infinite? Is there a semigroup $S$ with $0$ such that $\kappa'_S$ is infinite? (If the answer is ""yes"", this doesn't answer any of my previous questions, but I would be interested in knowing it nonetheless.)","['ring-theory', 'semigroups', 'cardinals', 'abstract-algebra']"
118573,Solving an ordinary differential equation: $y'(t)+3y(t)=6t+5$,"Prove if $y'(t)+3y(t)=6t+5$, $y(0)=3$, then 
$y(t)=2e^{-3t}+2t+1$. I have no idea how to finish this problem.",['ordinary-differential-equations']
118576,21 sided regular polygon and its diagonals,"In a $21$ sides regular polygon, how many points inside it are
  intersection of its diagonal? I found that a polygon with $n$ sides has $\dfrac{n(n - 3)}{2}$ diagonals, but I feel this is not so useful to the problem solution. I've been trying for $3$ hours without success. What's the correct solution? This is part of a contest that is already finished (the solutions have not been released yet).","['geometry', 'combinatorics']"
118579,Eigenvalues of a matrix $A$ and $e^{A}$,"If I know the eigenvalues of $e^{A}$, what can I say about the eigenvalues of $A$ itself?","['matrices', 'linear-algebra']"
118592,Limit of measures is again a measure,"Given a sequence $(\mu_n)_{n\in \mathbb N}$ of finite measures on the measurable space $(\Omega, \mathcal A)$ such that for every $A \in \mathcal A$ the limit
  $$\mu(A) = \lim_{n\to \infty} \mu_n(A)$$
  exists. I want to show that $\mu$ is a measure on $\mathcal A$. What I managed to figure out: $\mu$ is monotone, additive and - if $\lim_n \mu_n(\Omega)$ is supposed to be taken in $\mathbb R$ - then $\mu$ is also finite (I'll assume this). Also $\mu(\varnothing) = 0$. So we can wlog assume that $\mu(\Omega) = 1$ and that $\mu_n(\Omega) \le 2$ for all $n$. Now what remains to be shown is that $\mu$ is $\sigma$-additive, or equivalently that for $A_n\downarrow \varnothing$, we have $\mu(A_n) \to 0$ (since $\mu$ is finite). All attempts at proving this have been futile so far. I don't seem to see the right approach. If possible, I would like to only receive a hint rather than a full answer. But of course, I'd be quite happy with a full answer, too; if a good hint is hard to find! Thanks a lot in advance for your help! =)",['measure-theory']
