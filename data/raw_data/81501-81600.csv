question_id,title,body,tags
1060172,Need to know why $\sum_{k=0}^{\infty}kr^{k} = \frac{r}{(1-r)^{2}}$,"Working on a Stat problem where I must find $E(x)$ of $f(x)=\left(\frac{1}{2}\right)^{x+1}$ for $x=0,1,2,\cdots$ I have, $$E(x)=\sum_{x=0}^{\infty}x\left(\frac{1}{2}\right)^{x+1}=\frac{1}{2}\sum_{x=0}^{\infty}x\left(\frac{1}{2}\right)^{x}$$ I'm pretty sure this is a geometric series, but it would defeat the purpose of doing this problem if I didn't know why the following sum converges: $$\sum_{k=0}^{\infty}kr^{k} = \frac{r}{(1-r)^{2}}$$ Can anyone explain why this is? I've tried using derivative but keep going in circles.","['statistics', 'summation', 'sequences-and-series']"
1060193,Dominant Rational Map,"Let $Y\subseteq \mathbb{A}_k^n$ be an affine variety and $X$ any other (quasi)-(projective) variety with $U$ an open-subset of $X$. If $\theta: A(Y) \to \mathcal{O}(U)$ is a $k$-algebra homomorphism we can define $\theta': U\to Y$ as a morphism by, 
$$ \theta'(p) = (\theta(x_1)(p), .... , \theta(x_n)(p) )$$ If $\theta$ is injective why does it follow that $(U,\theta')$ is dominant rational map in $\hom(X,Y)$? This construction is used by Hartshorne, AG, page 26.",['algebraic-geometry']
1060203,fixed points for the following system,"I'm trying to find the fixed point for the system (see document attached) but it seems so hard and I don't know what Im doing wrong . Can somebody help me with this. I need to find the to look for the value where the bifurcation occur (for that process i need to evaluate the jacobian matrix for the system on the fixed points and the looks for the delta, which is really easy) but this is the only part where I'm stuck. Please see document attached",['ordinary-differential-equations']
1060240,Integer inequality: $x + y +z> a + b + c$ does not imply $xyz > abc$,"Prove by contradiction that for any integers $x,y,z,a,b,c$ greater than $0$ such that $x+y>a+b$, it is not implied that $x\cdot y\cdot z>a\cdot b\cdot c$? Obviously this statement is true. Consider $9+1+1>3+2+2; 9<12$. But I cannot seem to prove it without falling back to examples. Also, would the outcome of the statement be different if I required that all integers be greater than $1$? If so, how do i go about formalizing that thought?","['arithmetic', 'discrete-mathematics', 'proof-writing', 'number-theory']"
1060241,Unique measure on positive Borel sets with following properties,"This is actually part (a) question asked previously. However, that person had solved part (a) and so no solution is available. I am trying to prove it myself but am running in to difficulties. $\textbf{Question}$ 
(a) Show that there is at most one measure $\nu$ on $\mathcal{B}_{(0,\infty)}$ which satisfies the following conditions: $\nu((1,e]) = 1$ $\nu(cA) = \nu(A)$ for every $c>0$ and $A \in \mathcal{B}_{(0,\infty)}$. I think that somehow $(1,e]$ will generate all of the sets in $B_{(0, \infty)}$ but I am having a hard time formalizing the proof.","['measure-theory', 'real-analysis']"
1060294,Physical Meaning of Minkowski Distance when p > 2,"Suppose we have two vectors in $u, v \in \mathbb{R}^d$. For $p \geq 1$, the Minkowski distance between these vectors is defined as $
\lVert u - v \rVert_p = \Bigl( \sum_{i=1}^d \lvert u_i - v_i \rvert^p \Bigr)^{1/p}.
$ This family of distances includes the familiar Euclidean distance ($p = 2$), and the less familiar, but still physically meaningful Manhattan distance ($p = 1$). When $1 < p < 2$, we can interpret the Minkowski distance as measuring (in a Euclidean sense) a path ""between"" the paths measured by the Manhattan and Euclidean distance, since $
\lVert u - v \rVert_2 \leq \lVert u - v \rVert_p \leq \lVert u - v \rVert_1.
$ Is there any physically meaningful or intuitive interpretation when $p > 2$? Note: I am aware of this less specific question .","['geometry', 'metric-spaces']"
1060327,"Prove that : $f(\sin x)+f(\cos x) \ge 196, \forall x\in\left(0;\frac{\pi}{2}\right)$","Given: $$f(\tan2x)=\tan^{4}x+\frac{1}{\tan^{4}x}, \forall x\in\left(0;\frac{\pi}{4}\right)$$ Prove that :$f(\sin x)+f(\cos x) \ge 196, \forall x\in\left(0;\frac{\pi}{2}\right)$ Could someone help me ?","['inequality', 'trigonometry', 'calculus']"
1060358,"Evaluating derivative of $\int^{3x}_{2x} \sin(t^3 + 1) \,\mathrm dt$","Maybe I'm not very good at my trig rules but I'm having a tough time finding derivative of $$\int^{3x}_{2x} \sin(t^3 + 1) \,\mathrm dt$$ I believe that $u = t^3 + 1$ and $du = 3t^2$, but I'm not sure how to get that to fit back into the integral? I can't just do $-\cos(3t^2)$ can I?","['definite-integrals', 'calculus', 'integration', 'derivatives']"
1060375,A function constant almost everywhere,"Q: Suppose $f:\mathbb{R}\rightarrow \mathbb{R}$ is measurable with respect to Lebesgue measure and $f(x)=f(x+1)=f(x+\pi)$ for almost every $x$. Prove that $f$ is constant almost everywhere. Proof attempt: Since the ratio of $1$ and $pi$ is irrational, given any real number $r$ we have there exist $m, n\in \mathbb{Z}$ such that $|r-(m+n \pi )|< \epsilon$, so that the set $P=\{m+n\pi : m, n\in \mathbb{Z}\}$ is everywhere dense. Now by Lusin's theorem take the interval $[a, b]$, so there is a compact set $E\subset [a,b]$ such that $\mu(E) > (b-a-\delta)$ for some arbitrarily small $\delta$ and so that $f|_{E}$ is continous. Pick a point $x$ like the one in the condition of the problem and any $y\in E$. By continuity of $f$ on $E$ and by the density of $P$ there will be a point such that $|f(x)-f(y)|=|f(x)-f(y)|=|C-f(y)|<\epsilon_{2}$. Taking the limit as $\delta \rightarrow 0$, $f$ is constant almost everywhere on the interval $[a, b]$, and since the interval is arbitrary we can say $f$ is constant almost everywhere. Does this look alright? Is there another way of doing this without invoking something like Lusin's theorem? Measurable functions can be very ugly, so are there any other results similar to Lusin's theorem that allow us to put some sort of regularity on measurable functions and gain some intuition about them? Thanks in advance!","['measure-theory', 'lebesgue-measure']"
1060397,Real roots of $p(x)=x^n+ax+b$,What can we say about the real roots of $p(x)$? My Work: If $n$ is odd I found that $p$ has at most $3$ real roots if $a<0$ and $p$ has at most $1$ real root if $a\geq 0$. How can I classify the roots of $p$ like this when $n$ is even? I got that when $n$ is even $p'(x)=nx^{n-1}+a$. Since $n-1$ is odd $p'(x)$ has exactly one real root. Then $p$ has either $1$ root or $2$ roots or no roots. But how can I classify it exactly? I am stuck. Can anyone please help me?,"['derivatives', 'real-analysis', 'polynomials']"
1060410,Solve differential equation $y'''(t)=y(t) y'(t)$.,"Solve following diferential equations
$$y'''(t)=y(t) y'(t)$$
I would appreciate some help with this problem. Thanks in advance.",['ordinary-differential-equations']
1060445,Is $f(x)x$ convex for increasing function $f$?,"Suppose that $f:(0,\infty)\to[0,1]$ is strictly increasing and infinitely differentiable. I have an intuition that 
$$
g(x)=f(x)x
$$ 
should be convex in $x$ (i.e. increasing at accelerating rate) because $g(x)$ can be interpreted as a proportion of a number both of which go up when the number goes up, but I can't prove it nor come up with a counterexample. I tried differentiating:
$$
g'(x)=xf'(x)+f(x)\implies g''(x)=xf''(x)+2\underbrace{f'(x)}_{>0}\overset{?}{>}0.
$$
Thank you for your help.","['convex-analysis', 'calculus', 'algebra-precalculus', 'real-analysis']"
1060466,Find an integral with fractions,How to find the integral $$\int_0^\infty \frac{e^{-x^2}}{(x^2+1/2)^2}dx?$$ I find it is difficult to do if I integrate by parts...What's the trick?,"['definite-integrals', 'calculus', 'integration']"
1060469,Prove that Either $T$ Is Diagonalizable or $T$ Is Nilpotent.,"(Linear Algebra - Hoffman, Kunze, 2nd Ed., Sec 6.8, Q6) Let $V$ be a finite-dimensional vector space over the field $\mathbb{F}$ , and let $T$ be a linear operator on $V$ such that $\textrm{rank}  (T) = 1$ . Prove that either $T$ is diagonalizable or $T$ is nilpotent, not both. Here's how I proceeded:
Let $\textrm{dim} V = n$ . By the $\textrm{rank}(T) + \textrm{null}(T) = \textrm{dim} V$ theorem, $\textrm{null} (T) = n-1$ . Now let $B = \{a_1, a_2,... , a_{n-1}, a_n\}$ be a basis for $V$ , with $B' = \{a_2,...,a_n\}$ a basis for $\ker(T)$ .
Now, let $$A = [T]_B= \left(\begin{array}[cccc]  
(c_1 & 0 & \cdots & 0\\
c_2 & 0 & \cdots & 0\\ 
\vdots & \vdots & \ddots & \vdots\\
c_n & 0 & \cdots & 0 \end{array}\right).$$ Where $T(a_1) = c_1(a_1) + c_2(a_2) + ... + c_n(a_n)$ Now I argue as follows: if $c_1 = 0$ , then $A$ (and $T$ ) is nilpotent with $A^2 = 0$ . Since the minimal polynomial is not a linear factor, $A$ (and $T$ ) is not diagonilazable. On the other hand, if $c_1\neq 0$ , then $A$ (and $T$ ) is diagonalizable, since the minimal polynomial = $x(x-c_1)$ . Is my solution correct?",['linear-algebra']
1060473,Find $\lim\limits_{n\to\infty} {\frac{n!}{n^n}}^\frac{1}{n} $,"The denominator dominates the numerator so the term $\displaystyle \frac {n!}{n^n}$ definitely tends to $0$, and so does the power $\displaystyle\frac {1}{n}$. So, overall it is $\displaystyle0 ^ 0$ form. I proceeded by taking its $log$ and then I got stuck because I found it difficult to solve by L' Hopital's rule.",['limits']
1060484,"If $\|X(t)\|\leq M$, does this imply that $det(X(t))$ is bounded?","I am wondering if the following is true: If you are given a matrix $X(t)$ (that depends on the positive real variable $t$)  which is bounded (i.e, $\|X(t)\|\leq M$ for all $t$. Can you conclude that $\det(X(t))$ is also bounded? Can you also conclude that $\lim_{t\to \infty}\det(X(t))$ is finite? Thanks!","['ordinary-differential-equations', 'matrices', 'matrix-calculus', 'linear-algebra', 'real-analysis']"
1060548,Is the cone over Grassmannian manifold $Gr_2(\mathbb{C}^n)$ an open set of a determinantal variety?,"Let $Gr_2(\mathbb{C}^n)$ the Grassmann manifold of the planes in $\mathbb{C}^n$. It is, via Plucker embedding, a projective variety. If we consider the cone $C$ over $Gr_2(\mathbb{C}^n)$, is it possible to prove that $C$ is an open set of a determinantal variety? If yes, how can I prove it? Thank you!","['grassmannian', 'algebraic-geometry', 'projective-geometry', 'affine-geometry', 'determinant']"
1060559,Is there a homomorphism from a full product of finite cyclic groups onto $\mathbb Z$?,"Trying to answer this question , I encountered the following question, the answer to which should be known but it is hard to Google, so I did not find it. Let $G=\prod_{n\in\mathbb N}\mathbb Z_n$ be a full product of finite cyclic groups $\mathbb Z_n=\mathbb Z/n\mathbb Z$. Exists there a homomorphism $f:G\to\mathbb Z$ such that $f((1,1,\dots))=1$? According to this question , my question should be equivalent to the following. Is the group $\{(m,m,\dots)\in G: m\in\mathbb Z\}$ a direct summand of the group $G$?","['abstract-algebra', 'group-theory', 'abelian-groups']"
1060574,Prove: the sum of two nilpotent and exchangable matrices is nipotent.,"If $A$ and $B$ are two $n\times n$ nilpotent matrices, and they are exchangable: $AB = BA$, it is said that the sum $A+B$ is also nilpotent. Could you pls give me some hint how to prove that?","['matrices', 'linear-algebra']"
1060583,"Permute ""aaaaabbbbbccccc"" so that no two identical letters are adjacent","This is a follow up question to Application of PIE . How many strings with the letters ""aaaaabbbbbccccc"" are there so that no two identical letters are adjacent?","['permutations', 'combinatorics']"
1060590,Can a sequence which decays more slowly still yield a converging series?,"In Bergman's companion notes to Rudin, he says that ""If a sequence of positive terms has convergent sum, so does every sequence of positive terms which decays more rapidly."" So given a sequence $\{a_n\}$ of positive terms such that $\sum_n a_n$ converges, if $\{b_n\}$ is such that
$$
\lim_{n\to\infty} \frac{a_n}{b_n} = +\infty,
$$ then $\sum_nb_n$ converges. I can prove this given $\{a_n\}$ and $\{b_n\}$. However, can we find $b_n$ which decays more slowly, i.e.
$$
\lim_{n\to\infty} \frac{b_n}{a_n} = +\infty
$$ such that $\sum_n b_n$ converges? Similarly, we have the claim ""if a sequence of positive terms has divergent sum, then so does every sequence of positive terms which decays more slowly.""","['sequences-and-series', 'real-analysis']"
1060598,Is it possible to have Logarithm with base 1 or 0?,I am wondering is there any definition that allows logarithm to have base 0 or 1 in real or complex fields (considering Euclidean space)?? Out-coming question is if you can define a logarithm with negative base??,"['complex-numbers', 'logarithms', 'complex-analysis']"
1060653,Area of rectangle.,I know that why we take area of a rectangle proportional to the product of its width and height. I also know why take area proportional to product. It is due to the theorem of Joint Variation. But it's really hard for me to make a visual concept or make sense of that how product of width and height give us the area of a rectangle?,['algebra-precalculus']
1060681,Calculate the result of the following sequence.,"I'm stuck with this sequence.I can't calculate the result. Any help would be greatly appreciated. $$A=\frac{1}{2} + \frac{2}{4} + \frac{3}{16} + \frac{4}{32} + ... $$ Please feel free to edit the tags if you wish.Thanks Please do not edit the question I'm sure I've written it correctly. EDIT:The nth number of this sequence is evaluated by the formula: 
$\displaystyle\frac{n}{2^{n- 2([\frac{n}{2}])+1}}$ if  i'm not mistaken.Because the denominator is multiplied by 2 at first and then by 4 and then again by 2 and ... goes on like that. EDIT2:I've made a big mistake!The denominator itself is evaluated by :
$\displaystyle d_n=2^{n- 2([\frac{n}{2}])+1} \times d_{n-1}$ where $d_i$ is the $i$ th denominator. EDIT3:Can anything be done using $2A-A=A$ ?I think this should get me somewhere but I can't figure it out.","['sequences-and-series', 'algebra-precalculus']"
1060710,Why is the derivative of $x^2$ not $2x+1$?,"If the derivative is the change of the function at each step, it could be expressed as: $$f(x)+f'(x)=f(x+1)$$ Therefore if $f(x)=c$ $$c+f'(x)=c \implies f'(x)=0$$ This is also correct for $f(x)=cx$ $$cx+f'(x)=c(x+1) \implies f'(x)=c$$ However, it doesn't work for $f(x)=x^2$ $$x^2+f'(x)=(x+1)^2=x^2+2x+1 \implies f'(x)=2x+1$$ Where am I wrong in my reasoning?","['calculus', 'derivatives']"
1060719,Confusion in the definition of set,"Which of  the following is the correct definition for set? 
Set is a well defined collection of objects. 
Set is a collection of well defined objects.","['elementary-set-theory', 'definition']"
1060731,Show that $(E\cup Z_1)\setminus Z_2$ has the form $E\cup Z$,"I'm trying to do an exercise as follows: Let $(X, {\mathbf X}, \mu)$ be a measure space and let ${\mathbf Z}=\{E\in {\mathbf X}:\mu(E)=0\}$. Let $\mathbf X'$ be the family of all subsets of $X$ of the form $(E\cup Z_1)\setminus Z_2, E\in \mathbf X$, where $Z_1$ and $Z_2$ are arbitrary subsets of sets belonging to $\mathbf Z$. Show that a set is in $\mathbf X'$ if and only if it has the form $E\cup Z$ where $E\in \mathbf X$ and $Z$ is a subset of a set in $\mathbf Z$. My proposed answer was if $Q=E\cup Z$ where $E\in \mathbf X$ and $Z\subset P\in\mathbf Z$ then $Q=E\cup Z\setminus(P\setminus Z)$ since $Z$ and $P\setminus Z$ are both subsets of $P\in \mathbf Z$. This seems to be wrong since it assumes $P\cap E=\emptyset$. Also, I cannot seem to work out how to go the other way around. I tried defining the set $R=\{x\in X:f(x)>0\}$. By the definition of sigma algebra, $R\in \mathbf X$. Then I tried taking intersections and complements with $R$. However I just keep getting messy expressions which never resolve to the required $E\cup Z$. Is this method with $R$ a good idea or did I miss something obvious? [This is part of exercise 3.L. of The Elements of Integration and Lebesgue Measure by R. G. Bartle.]",['measure-theory']
1060737,Solve $f\left(\frac{x-3}{x+1}\right)+f\left(\frac{x+3}{x+1}\right)=x$ $\forall x\neq -1$,"Given function $y=f(x)$
such that 
$$f\left(\frac{x-3}{x+1}\right)+f\left(\frac{x+3}{x+1}\right)=x \quad\forall x\neq -1$$
find $f(x)$ and $f(2007)$.","['algebra-precalculus', 'functional-equations']"
1060752,"A concave positive function on $[1,\infty)$ is uniformly continuous","Let $f$ be a concave positive function on $[1,\infty)$, then $f$ is uniformly continuous on $[1,\infty)$. This was a true or false problem that I couldn't prove to be true, so I'm thinking that maybe there is a counterexample. I know that for $f$ to be concave then $f''(x)\lt 0$ on $[1,\infty)$. Does $f(x)=\frac{1}{x-2}$ work as a counterexample? $f''(x)=-1\lt 0$ and at $x=2$ it is undefined so it wouldn't be uniformly continuous on the interval $[1,\infty)$, right? Uniformly Continuous: Let $E$ be a nonempty subset of $\mathbb R$ and $f:E\to \mathbb R$. The $f$ is uniformly continous on $E$ if and only if for every $\epsilon \gt 0$ there is a $\delta\gt 0$ such that $|x-a|\lt\delta$ and $x,a\in E$ imply $|f(x)-f(a)|\lt \epsilon$.","['examples-counterexamples', 'derivatives', 'real-analysis', 'uniform-continuity']"
1060762,A point in $ PGL(R) $ not in $ GL(R)/R^{\times} $,"A bit of notational background first. Let $k$ be a field and define $ PGL_{n} = Spec(k[x_{ij}]_{(det)}) $, where $i,j = 1,...,n$ and where $k[x_{ij}]_{(det)}$ denote the degree $0$ part of the graded ring $k[x_{ij}]_{det}$. One has an injective natural map $\phi_{R} : GL_{n}(R)/R^{\times}\hookrightarrow PGL_{n}(R) $, for all $k$-algebras $R$. Now, as the title says, the purpose is to find an $R$ such that $\phi_{R}$ is not surjective. In particular, I lack a characterization for $x\in PGL_{n}(R)$ to be in the image of $\phi_{R}$. Here is at least a sufficient condition : if $x(\frac f {det})$ is invertible in $R$ (where $f$ is a monomial of degree $n$ in $k[x_{ij}]$), then $x$ is in the image of $\phi_{R}$. As a remark, this sufficient condition is enough to show that $\phi_{R}$ is surjective whenever $R$ is a local ring. Also note that this condition is not necessary (for example, one could take $n=2$, $R = k[T]$, and the matrix $\left[\begin{array}{c}T&T+1\\T-1&T\end{array}\right]$) Finally, as stated in the first question of this homework sheet http://math.stanford.edu/~conrad/252Page/homework/hmwk3.pdf one can apparently hope to find an example when $n=2$ and $R$ is a Dedekind ring with a class group having 2-torsion. Brian Conrad gives the (mysterious to me) hint that $I \oplus I \simeq R^{2}$ when $I$ is 2-torsion. Could someone show how to use this hint to find a point in $ PGL_{2}(R) $ not in $ GL_{2}(R)/R^{\times} $ ? As a bonus, if someone is enthusiastic about explaining why $I \oplus I \simeq R^{2}$ when $I$ is 2-torsion, I would be interested to read it (but take into account that I know basically nothing about class group, appart from what is on Wikipedia).","['algebraic-geometry', 'algebraic-groups']"
1060769,Why it is not a function [duplicate],"This question already has answers here : Why $f(x) = \sqrt{x}$ is a function? (2 answers) Closed 9 years ago . This question is very basic one but at this moment I could not answer it. We know $y=\pm\sqrt{x}$ is not a function because one value of $x$ corresponds to more than one value of $y$. Again $y=x^2$ is a function. But we can get the first 
equation from the second one, so the first one should be a function, making contradiction. Could anyone please tell me what I am missing. Thanks in advance.",['real-analysis']
1060782,Probability of guessing the colors of a deck of cards correctly,"10 years ago when I was about 15 I sat down with a deck of shuffled cards and tried to guess if the next card in the deck would be red or black. In sequence I guessed 36 cards correctly as red or black, at that point my older bother came in and took told me what I was doing was stupid and I stopped being able to guess correctly. I would love to know what the probability of guessing 36 cards correctly in sequence is? Thank you",['probability-theory']
1060803,How to prove there exists $n_{1}a_{n_{0}}+n_{2}a_{n_{1}}+\cdots+n_{k}a_{n_{k-1}}<3(a_{1}+a_{2}+\cdots+a_{N})$,"Let $a_{1},a_{2},\cdots,a_{N}$ be nonnegative reals, not all $0$. Prove that there exists a sequence $$1=n_{0}<n_{1}<\cdots<n_{k}=N+1$$ of integers such that
  $$n_{1}a_{n_{0}}+n_{2}a_{n_{1}}+\cdots+n_{k}a_{n_{k-1}}<3(a_{1}+a_{2}+\cdots+a_{N})$$ I need to understand the problem here. and I fell it is Strange to use probability to can solve it. Can find other methods?","['inequality', 'sequences-and-series', 'contest-math', 'analysis']"
1060814,"If there exists $n>1$ such that $x^n=x$ for all $x$ in a ring, then there are no nonzero nilpotent elements.","Suppose that there is an integer $n> 1$ such that $x^n=x$ for all elements $x$ of some ring. If $m$ is a positive integer and $a^m= 0$ for some $a$ , show that $a = 0$ . I have an answer but don't know if it is correct. I made use of the division algorithm to conclude that there exists $q$ and $r$ such that $a^n = a^{mq}a^{r}$ which will yield $a=(a^m)^q a^r$ then $a=0a^r$ finally, $a=0$ . Is this right?","['ring-theory', 'abstract-algebra']"
1060834,Composition of two Riemann integrable functions,"Suppose $f,g$ are two Riemann  Integrable functions .Is it true that $f\circ g$ is also Riemann  Integrable? Trying this for a long time but not getting the answer",['real-analysis']
1060848,Hahn-Banach proof by extension of basis,"Hahn Banach Theorem states that given a linear continuous functional $f$ on a subspace $N$ of a normed space $M$, it can be extended to a linear functional $F$ on the whole space $M$ and the norm of the extension is the same as the one of $f$. Can someone tell me if something is wrong in the following lines: Fact 1: Every vector space has a basis (use axiom of choice if it is infinite dimensional). Fact 2: A linear map is defined if we give the image of a basis. Take $\{e_i\}_{i\in I}$ a basis of $M$ extending one of $N$, and define $F(e_i):=f(e_i)$ if $e_i$ is in $N$ and $0$ otherwise. This is clearly an extension of $f$, plus the norm of $F$ is the same as that of $f$ because sup $|F(x)|/||x||$ is $0$ for $x \in M \setminus N$ and $||f||$ if $x \in N$. In case is correct this seems like a very simple proof of this theorem!","['functional-analysis', 'analysis']"
1060886,Series representation of measurable functions,"I need to show that if a positive function $f$ on $E$, where $(E,\mathcal{E})$ is a measurable space, is $\mathcal{E}$-measurable then it has the form
$$f=\sum_{n=1}^{\infty}a_n1_{A_n},$$
for some sequence $(a_n)\subset \bar{\mathbb{R}}_{+}$ and some sequence $(A_n)\subset \mathcal{E}$ (not necessarily disjoint). Since $f$ is measurable and positive it is a pointwise limit of an increasing sequence of positive simple functions, that is
$$f(x)=\lim_{k\to\infty}\sum_{n=1}^ka_{n,k}1_{B_{n,k}}(x),\ \forall x\in E,$$
where for all $k$ we can assume $(B_{n,k})_{1\leq n\leq k}\subset \mathcal{E}$ are pairwise disjoint. I'm having trouble understanding what $a_n$'s and $A_n$'s should be since I think that $\lim_{k\to\infty}a_{n,k}$ need not exist (the sets $B_{n,k}$ and $B_{n,k+1}$ can be disjoint).","['measure-theory', 'real-analysis']"
1060893,"How find $a,b$ if $\int_{0}^{1}\frac{x^{n-1}}{1+x}dx=\frac{a}{n}+\frac{b}{n^2}+o(\frac{1}{n^2}),n\to \infty$","let
$$\int_{0}^{1}\dfrac{x^{n-1}}{1+x}dx=\dfrac{a}{n}+\dfrac{b}{n^2}+o(\dfrac{1}{n^2}),n\to \infty$$ Find the $a,b$ $$\dfrac{x^{n-1}}{1+x}=x^{n-1}(1-x+x^2-x^3+\cdots)=x^{n-1}-x^n+\cdots$$
so
$$\int_{0}^{1}\dfrac{x^{n-1}}{1+x}=\dfrac{1}{n}-\dfrac{1}{n+1}+\dfrac{1}{n+2}-\cdots$$
and note
$$\dfrac{1}{n+1}=\dfrac{1}{n}\left(\frac{1}{1+\dfrac{1}{n}}\right)=\dfrac{1}{n}-\dfrac{1}{n^2}+\dfrac{1}{n^3}+o(1/n^3)$$
and simaler
$$\dfrac{1}{n+2}=\dfrac{1}{n}-\dfrac{2}{n^2}+o(1/n^2)$$
$$\dfrac{1}{n+3}=\dfrac{1}{n}-\dfrac{3}{n^2}+o(1/n^2)$$
then which term end?",['integration']
1060906,Quotient of matrix group fails in GAP,"This is a question about quotients of matrix groups in GAP… The matrix group generated by a := [[1,1],[1,-1]]/Sqrt(2);
b := [[1,0],[0,E(4)]];
G := Group(a,b); contains multiples of the identity matrix, for example c := [[E(8),0],[0,E(8)]]; Clearly, the subgroup H := Subgroup(G,[c]); is normal, so Q := FactorGroup(G,H); should give me the quotient group. Can anyone tell me why I get the following error message instead? Error, I don't know how to find a natural homomorphism for <N> in <G> called from
oper( Parent( D ), D ) called from
attr( sub ) called from
NaturalHomomorphismByNormalSubgroupNCOrig( G, N ) called from
NaturalHomomorphismByNormalSubgroupNC( G, N ) called from
FactorGroupNC( G, N ) called from
…","['gap', 'group-theory']"
1060914,"In triangle ABC, find the range of sinAsinC.","In $\triangle$ABC, $\angle$B=$\frac{\pi}{3}$. Find the range of sinAsinC. I used C=120-A to  simplify the equation in sinC and then applied $-1<sinC<1$ but answer did not matched.",['trigonometry']
1060924,A group action proof without group actions?,"I am currently teaching an undergraduate abstract algebra course out of Saracino, Abstract Algebra: A First Course . Exercise 13.13 asks the following: Let $K$ be the subgroup $\{ e, (1, 2)(3, 4), (1, 3)(2, 4), (1, 4)(2, 3)\}$ in $S_4$. Prove that $K$ is normal in $S_4$ and that $S_4 / K \cong S_3$. The solution that naturally occurs to me is to consider the natural group action on the set consisting of unordered disjoint pairs of pairs of elements of {1, 2, 3, 4}, to prove that it is surjective, and to prove that the kernel of the action is $K$. However, Saracino has not yet introduced group actions in his book! It is possible to translate this proof out of the language of group actions, but this strikes me as a little bit clumsy. Is there any other proof he may have plausibly had in mind?","['finite-groups', 'group-theory', 'abstract-algebra']"
1060930,Formula for a periodic sequence of 1s and -1s with period 5,"I've been playing with periodic sequences of 1s and -1s lately. This is what I came up with:
\begin{eqnarray*}
-(-1)^n& = &1, -1, 1, -1,\ldots\quad\textrm{(Period 2)}\\
\left(-(-1)^n\right)^{\frac{n+2}{2}} & = &1, 1, 1, -1, 1, 1, 1, -1,\ldots\quad\textrm{(Period 4)}\\
 \left(\left(-(-1)^n\right)^{\frac{n+2}{2}}\right)^{\frac{n+4}{4}}& = &1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, \ldots\quad\textrm{(Period 8)}
\end{eqnarray*}
One can easily find a similar formula for a periodic sequence with period $ 2^n, n\in\mathbb{N} $.
I also found a formula:
$$
(-1)^{2 \sin\left(\frac{(2n-1)\pi}{6}\right)},
$$
which gives a sequence $ -1, 1, -1, -1, 1, -1,\ldots $ with period 3. My question is: Is there a formula for a periodic sequence of 1s and -1s with period 5? If there is, what is it? I know about this formula for a periodic zero and one sequence with period $ N $:
$$
\sum\limits_{k = 1}^N\cos\left(-2\pi\frac{n(k-1)}{N}\right)/N = 0, 0, 0, \ldots, 1.
$$
However, it requires to sum up $ N $ expressions to count the $ n\textrm{th} $ term, which is why I don't like it. I would also like the formula not to contain functions like floor or modulus.",['sequences-and-series']
1061010,Knots which are composed of several strands,"In a math textbook and this article in NRICH , some problems deal with a special kind of knots: those which are formed from several strands: The problems ask if a given knot can be formed from just one strand, and if not, how many strands are needed. What is the mathematics behind these problems?","['general-topology', 'connectedness', 'knot-theory']"
1061022,Differential equation,"$$x^2(x^2+1)y''-2x^3y'+2(x^2-1)y=0$$ Anyway my tutor assumes that one of the solutions must be $y=x^2$, yet I can't seem to prove this, I tried using $y=x^n$ but I can't seem to get an answer that cancels down. I know soon as I get this solution I can use Abel's forumla to get the other solution. Any help appreciated.",['ordinary-differential-equations']
1061047,Is $Spec(R_p)$ to $Spec(R)$ is an open immersion?,Let $R$ be a ring. $p$ be a prime ideal of $R$ . Let $R\rightarrow R_p$ be the canonical. Consider the map of schemes $Spec(R_p) \rightarrow Spec(R)$. Is it an open immersion. $Spec(R_p)$ is an open set in $Spec(R)$ is clear.,"['sheaf-theory', 'affine-schemes', 'algebraic-geometry', 'schemes']"
1061065,Evaluate $\sum_{n=1}^\infty \frac{x^n}{n}$,"Evaluate $$\sum_{n=1}^\infty \frac{x^{n}}{n}$$ Evaluation: $$\sum_{n=1}^\infty \frac{x^n}{n} = \sum_{n=1}^\infty \int_0^x t^{n-1} dt = \int_0^x \left(\sum_{n=1}^\infty t^{n-1}\right)dt = \int_0^x \frac{1}{1-t} dt= \log\left|1-x\right|$$ My question: Why is the integral being calculated on $[0,x]$?","['sequences-and-series', 'calculus', 'integration']"
1061083,Average time to fill boxes with balls,"Let's have n users with each having a ball and m boxes . The users put their ball in a random box. It takes exactly 10 seconds for all balls to be put in a random box (independently to the number of users). When the 10 seconds are passed, we remove the boxes with at least one ball and start the process again (each user get a new ball) until there is no boxes left. We know that each iteration takes exactly 10 seconds, hence: average_execution_time = average_iteration_count * 10 How can we calculate the average iteration count? Here I describe an analog problem but it will help modelling a distributed computing problem.","['probability', 'combinatorics']"
1061092,Evaluating the integral $\int_1^{\infty} \int_1^{\infty} \frac{\Gamma(x+1)\Gamma(y+1)}{x y \Gamma(x+y+2)} \ dx \ dy$,"During the study of some integrals I came across a very interesting integral, that is 
$$\int_1^{\infty} \int_1^{\infty} \frac{\Gamma(x+1)\Gamma(y+1)}{x y \Gamma(x+y+2)} \ dx \ dy$$ that is obtained by manipulating 
$$\int_0^1 \operatorname{li}(x) \operatorname{li}(1-x) \ dx$$
 Apparently nothing seems to work, but I bet you can do much more than me. So, what tools would you recommend me to try?","['definite-integrals', 'calculus', 'integration', 'real-analysis']"
1061105,I need help with a partial derivative,"I was given a function and I need to find a partial derivative of it. The result I got is different from the answer, and I don't know why. Here's the function: $$sin(\theta_{a}) = \frac{\sqrt{[R_Y\sin(a) - R_Z\cos(a)\cos(A)]^2 + [R_X\sin(a) + R_Z\sin(A)\cos(a)]^2 + [R_Y\sin(A)\cos(a) + R_X\cos(A)\cos(a)]^2}}{\mid R \mid}$$ where $$ R = \sqrt{R_X^2 + R_Y^2 + R_Z^2} $$ Here's what I need to do: $$ \frac{\partial \sin(\theta_{a})}{\partial R_Z} $$ The correct answer is: $$ \frac{\partial \sin(\theta_{a})}{\partial R_Z} = \frac{1}{2} \frac{1}{\mid R \mid} \frac{1}{\sqrt{...}}\big\{-2\cos(a)\sin(A)[R_Y\sin(a)-R_Z\cos(a)\cos(A)] + 2\sin(A)\cos(a)[R_X\sin(a)+R_Z\sin(A)\cos(a)]\big\}$$ Where $ \sqrt{...} $ is the numerator of the function. My result fallows this derivation principle: $$ \frac{f'(x) \cdot g(x) - f(x) \cdot g'(x)}{g(x)^2}$$ However the only way to get the result shown above is by not deriving the denominator $\mid R \mid $ by $ R_Z $ but considering it instead as constant.  Is there a reason why I shouldn't do it or am I mistaken somewhere?","['partial-derivative', 'derivatives']"
1061115,On the problem of polynomial bijection from $\mathbb Q\times\mathbb Q$ to $\mathbb Q$,"The question titled ""Polynomial bijection from $\mathbb Q\times\mathbb Q$ to $\mathbb Q$"" which was posed on MathOverflow attracted quite a lot of attention (and may be the question with most wrong answers ever asked on the website according to the comments of other users). I have gone through some of the comments and realized that this question is related to the "" abc conjecture"" as well as to the ""Bombieri-Lang conjecture"". Would you explain (in a way that is precise but accessible to an undergraduate student ) why is this problem so difficult and what its solution would imply; what are its relationships with the "" abc conjecture"" and the ""Bombieri-Lang conjecture""; and what are the major reference papers on the topic (have there been any major progresses recently in ideas and methods to tackle the question)? I see that it also not known if there is an injection . What are the differences between the problems in respect with the three points listed above?","['polynomials', 'conjectures', 'algebraic-geometry', 'number-theory']"
1061142,Evaluate $\lim_{x→0}\left(\frac{1+\tan x}{1+\sin x}\right)^{1/x^2} $,I have the following limit to evaluate: $$ \displaystyle \lim_{x→0}\left(\frac{1+\tan x}{1+\sin x}\right)^{1/x^2} $$ What's the trick here?,"['trigonometry', 'limits-without-lhopital', 'limits']"
1061171,Learning functional analysis and measure theory,"I have taken a first course in real analysis and I'm currently studying analysis in $\mathbb{R}^N$ on my own. I want to start functional analysis after this, and I also want to learn measure theory and Lebesgue integration. My question is: should I learn functional analysis first, without Lebesgue integration, using a text such as Kreyszig's introductory functional analysis, and then study Lebesgue integration later, or should I study Lebesgue theory first and then functional analysis, perhaps using using something like Lang's ""Real and Functional Analysis""?
If neither of these ways is good in your opinion, what would be the best way to go? I'm a grad student of mechanical engineering, and I ultimately want to understand PDEs properly.","['self-learning', 'functional-analysis']"
1061227,"Determine the diameter length (mm) of each circle shown using the given information. Geometry, trig and algebra only.",I have considered ratios of triangles as well constructing tangent and secants to compare sides of triangles. Neither has worked out for me. Also have considered moving small circle to center but that has not been advantageous.,['geometry']
1061230,"$A$: set of Alice's frieds, $B$: Bob's friends, $C$: all people. Find $P(A \subseteq B)$ and $P(A \cup B = C)$","(Introduction to Probability, Blitzstein and Nwang, p.80) Alice, Bob, and 100 other people live in a small town. Let C be the set consisting of the 100 other people, let A be the set of people in C who are friends with Alice, and let B be the set of people in C who are friends with Bob. Suppose that for each person in C, Alice is friends with that person with probability 1/2, and likewise for Bob, with all of these friendship statuses independent. (a) Let D $\subseteq$ C. Find P (A = D). (b) Find P (A $\subseteq$ B). (c) Find P (A $\cup$ B = C). My general approach to those problems was conditioning on the set sizes. Part b) must be certainly false. a) $P(A=D) = \sum_{k=0}^{100} P(A=D \mid |A|=k) * P(|A|=k)$ $P(|A|=k) = \binom{100}{k} \left(\frac{1}{2}\right)^{100}$ \begin{align} 
P(A=D \mid |A| = k) &= \sum_{j} P(A=D \mid |A| = k, |D|=j) * P(|D|=j)\\
&= P(A=D \mid |A|=|D|=k) * P(|D|=k)\\
&= \binom{100}{k}^{-1} * \frac{1}{101}
\end{align} \begin{align}
\sum_{k=0}^{100} \binom{100}{k}^{-1} * \frac{1}{101} * \binom{100}{k} * \left(\frac{1}{2}\right)^{100} = \left(\frac{1}{2}\right)^{100} \doteq 0
\end{align} b)
\begin{align}
P(A \subseteq B) &= \sum_{k\leq j} P(A \subseteq B \mid |A| = k, |B|=j) * P(|A| = k, |B|=j)\\
&= \sum_{k\leq j} \frac{\binom{k}{j}}{\binom{100}{k}\binom{100}{j}} * \binom{100}{j} \left(\frac{1}{2}\right)^{j} * \binom{100}{k} \left(\frac{1}{2}\right)^{k}\\
&= \sum_{k\leq j} \binom{k}{j} \left(\frac{1}{2}\right)^{k+j} = 4
\end{align} c) \begin{align}
P(A \cup B = C) &= \sum_{k=0}^{100} P(A \cup B = C \mid |A|=k, |B|=100-k) * P(|A|=k, |B|=100-k)\\
&= \sum_{k=0}^{100} \frac{1}{\binom{100}{k}} * \binom{100}{k} \left(\frac{1}{2}\right)^{100} * \binom{100}{100-k} \left(\frac{1}{2}\right)^{100}\\
&= \sum_{k=0}^{100} \binom{100}{k} \left(\frac{1}{2}\right)^{200} \doteq 0
\end{align} Am I principally doing the right thing? Any help with this?","['probability', 'combinatorics']"
1061245,Partial differentiation of a integral,"If I have:
$$f(x,y)=\int_{x}^{y}e^{-t^2}dt$$
To calculate that, I change the t to y and x to get:
$$e^{-y^2}(e^{-y^2})'-e^{-x^2}(e^{-x^2})$$
With the differentials being in respect to x and y for each partial derivative?","['partial-derivative', 'calculus', 'integration', 'derivatives']"
1061253,Equivalent norms and inner product,"It is not hard to give examples of normed spaces which are not inner product spaces. Now let $(V, \|\cdot\|)$ be a normed space. Is it always possible to construct an inner product on $V$ which gives the same topology on $V$ as before? (As pointed out in comments, in finite dimensional case it it always the case).","['linear-algebra', 'functional-analysis']"
1061288,"Verifying properties of events $A$, $B$ given $P(A)$, $P(B)$, $P(A\cup B)$: where is the error?",Given that: $P(A) = 0.5$ $P(B) = 0.7$ $P(A \cap B) = 0.3$ I have to choose one option that is true... However they all seem to be false which means I am possibly making a mistake.. The only option that is almost true is B it seems. Any help is appreciated. Here are the options followed by my work so far: A) $A$ and $B$ are independent If $A$ and $B$ are independent $P(A \cap B) = (0.5)(0.7) = 0.35$ ; so this is not true B) $A$ and $B$ are mutually exclusive If $A$ and $B$ are mutually exclusive then $P(A \cap B) = 0$ ; so this is not true C) $P(A \cup B) = 0.8$ $(0.5 + 0.7) - 0.3 = 0.9$ ; so this is not true D) $P(A|B) = 0.6$ $$P(A \mid B) = \frac{P (A \cap B)}{P(B)} = \frac{0.3}{0.7} = 0.42$$ so this is not true,"['probability-theory', 'probability', 'conditional-probability']"
1061322,Proof for $n<m$ iff $n\leq m$ and $n\ne m$,"It's a basic exrecise on Set Theory course. We constructed the natural numbers by $0=\emptyset$ and $n+1=n\cup \{n\}$. So basically the order relation defined by $m<n$ if $m\in n$, and $m\leq n$ if $m\subseteq n$. We need to prove (by induction? I guess..) that: $n\in m$ iff $n\subseteq m$ and $n\ne m$ I don't see how to even begin. please, help.",['elementary-set-theory']
1061349,Lower bound of Euler phi function times sum of divisors,"After some work, I got this nice inequality: $$
\frac{n^2}{2} < \phi(n)\cdot \sigma(n)
$$ where $\phi(n)$ is Euler's phi function and $\sigma(n)=  \sum_{d|n} d$. I know this is true because I'm aware that this can be further refined to $$
\frac{6 n^2}{\pi^2} < \phi(n)\cdot \sigma(n)
$$ However, I'm interested in the first one because I'm sure there is an elemental proof of it (which I can't find at the moment). Any ideas?","['totient-function', 'inequality', 'arithmetic-functions', 'number-theory']"
1061364,Why the Steinberg idempotent is idempotent?,"Consider the group $GL_n(\mathbb{F}_p)$. We have the following subgroups : -$\Sigma_n$ the symmetric group (permutation matrices) -$B_n$ the Borel subgroup (upper triangular matrices) -$U_n$ the unipotent subgroup (upper triangular matrices with all diagonal entries equal to $1$). Consider the ring $R=\mathbb{F}_p[GL_n(\mathbb{F}_p)]$. If $H$ is a subgroup of $GL_n(\mathbb{F}_p)$, we denote by $\overline{H}:=\sum_{h\in H}h\in R$ and if $H\subseteq \Sigma_n$, we denote by $\tilde{H}:=\sum_{h\in H} sign(h) h\in R$, where $sign:\Sigma_n\rightarrow\{\pm 1\}$ is the usual map. One defines the Steinberg idempotent as : $e_n=\overline{B}_n\tilde{\Sigma}_n/[GL_n(\mathbb{F}_p):U_n]\in R$. Here are my questions : (1) Why $e_n$ is idempotent in $R$ ? Is it possible to give a ""bear hand"" proof of this in this case? In the original paper of Steinberg, it isn't done explicitly. If an explanation is given by using Chevalley's group (which I have no knowledge of), can someone please state the properties which are used? (2) [Solved, it was an easy question] Why if $p=2$ we have $e_n=\overline{B}_n \overline{\Sigma}_n$ in $R$ ?","['lie-algebras', 'representation-theory', 'algebraic-topology', 'abstract-algebra']"
1061378,Evaluate the Cauchy Principal Value of $\int_{-\infty}^{\infty} \frac{\sin x}{x(x^2-2x+2)}dx$,"Evaluate the Cauchy Principal Value of  $\int_{-\infty}^\infty \frac{\sin x}{x(x^2-2x+2)}dx$ so far, i have deduced that there are poles at $z=0$ and $z=1+i$ if using the upper half plane. I am considering the contour integral $\int_C \frac{e^{iz}}{z(z^2-2z+2)}dz$ I dont know how to input graphs here but it would be intended at the origin with a bigger R, semi-circle surrounding that. So, I have four contour segments. $\int_{C_R}+\int_{-R}^{-r}+\int_{-C_r}+\int_r^R=2\pi i\operatorname{Res}[f(z)e^{iz}, 1+i]+\pi iRes[f(z)e^{iz},o]$ I think.   Ok, so here is where I get stuck. Im not sure how to calculate the residue here, its not a higher pole, so not using second derivatives, not Laurent series. Which method do I use here?","['residue-calculus', 'definite-integrals', 'cauchy-principal-value', 'complex-analysis', 'contour-integration']"
1061405,Getting a full house with exactly 3 suits represented,"How many ways can you make a full house with only 3 suits represented in the 5 card hand? My attempt: get the pair first:   $$ {13 \choose 1}{4 \choose 2}$$
this allows us to pick any $2$ suits from one of the $13$ ranks. get the triple: $$ {12 \choose 1}{3 \choose 1}^3$$
this allows us to pick one of the $12$ remaining ranks, but with only 3 possibly suits to choose from. this equals $$ {13 \choose 1}{4 \choose 2}{12 \choose 1}{3 \choose 1}^3 = 25,272$$ where the answer should only be $1872$ Where have I over counted?","['discrete-mathematics', 'probability', 'combinatorics']"
1061407,Showing that $f = 0$ a.e.,"Let $f$ be a real-valued, Borel measurable and integrable function on $[0,1]$. Suppose that $\int_A f = 0$ for all Borel subset $A$ of $[0,1]$ with measure $\frac12$. Prove that $f = 0$ a.e. This is fairly trivial when $f$ is non-negative as $\int_{[0,1]}f = \int_{(0,\frac12)}f+\int_{(\frac12,1)}f = 0$ so on $(0,\frac12)$ $f$ is 0 a.e. and the same with the other interval. Then the point sets have measure $0$ and that gives the result. I can't figure out how to get the desired result for generic $f$ however.","['measure-theory', 'real-analysis']"
1061450,Is it true that if $\lim a_n = g$ then $\lim |a_n| = |g|$?,The question is in the title. I'm trying to prove that if $\lim_{n\rightarrow\infty} a_n = g$ then $\lim_{n\rightarrow\infty} |a_n| = |g|$. Is the following proof correct? If $\lim_{n\rightarrow\infty} a_n = g$ that means that for all $\epsilon > 0$ we have $|a_n - g| < \epsilon$ for sufficiently large $n$. But it is also true that $||a_n|-|g||\leq|a_n-g|<\epsilon$ which means that $\lim_{n\rightarrow\infty} |a_n| = |g|$.,"['sequences-and-series', 'calculus', 'proof-verification', 'limits']"
1061454,Convergence of sequence of $L^{p}$ function,"Given that $\Omega \subset \mathbb{R}^{n}$ is bounded. If you are given that $u_{k} \rightarrow u$ in $L^{p- \epsilon}(\Omega)$ and a functions $f: \mathbb{R} \rightarrow \mathbb{R}$ where $\{f(u_{k})\}_{k \in \mathbb{N}}$ is bounded in $L^{p'+\epsilon}(\Omega)$, where $\epsilon > 0$ and $p' = \frac{p}{p-1}$. How does it follow that $$\int_{\Omega}f(u_{k})(u_{k}-u)dx \rightarrow 0$$
Given that $p-\epsilon > 1$ annd $p'+ \epsilon > 1$. Can anyone see how this follows?","['lp-spaces', 'functional-analysis', 'real-analysis']"
1061485,Is there a name for expressions that are invariant under the exchange of raw moments and cumulants?,"I'm interested in expressions that are invariant under the exchange of raw moments and cumulants. This is trivially true of all expressions written only in terms of first order moments but nontrivial expressions exist for higher orders. A couple of examples are as follows: $\kappa _{2,0}\kappa_{0,1}{}^2-\kappa _{0,2} \kappa
   _{1,0}{}^2=\mu'_{2,0}\mu'_{0,1}{}^2-\mu'_{0,2} \mu'_{1,0}{}^2$ $\kappa _{2,0}\kappa_{0,1}{}^2+\kappa _{0,2} \kappa
   _{1,0}{}^2-2\kappa_{1,1} \kappa_{1,0}\kappa_{0,1}=\mu'_{2,0}\mu'_{0,1}{}^2+\mu'_{0,2}
   \mu'_{1,0}{}^2-2\mu'_{1,1} \mu'_{1,0}\mu'_{0,1}$ Does anybody know if these have a specific name or know anything else about them? I'm looking for any material I can find in order to learn more about them. Thanks!","['statistics', 'probability-distributions', 'moment-generating-functions']"
1061508,Find the derivative of a piecewise function.,"I would just like to know if my proof here is valid. I know I left out some computational details, but I'm more concerned about the structure of the proof than those details.","['derivatives', 'limits']"
1061538,Question on regression,"So I've been given this formula For regression $R^2=1 - \sum \frac{{(y_i -  \hat{y}_i)}^2}{(y_1-\bar{y})^2}$ Now an obvious question that has come to me is why $R^2$ stays the same in certain scenarios, for example: so the regression formulas are: $$\mathrm{TESCO}= 0.2830 + 0.7160 \,\mathrm{FTSE100} $$ $R^2: 10.6% $ $$\mathrm{FTSE100} = 0.8530 + 0.1475 \, \mathrm{TESCO} $$ $R^2: 10.6% $ then why is the coefficient of determination is the same in both cases Any explanation on this would be great, thank you!","['statistics', 'regression']"
1061542,riddle that involves elementary geometry,"$3$ frogs are positioned at the vertices of an equilateral triangle whos sides are of length $1$. We have $1$ frog on each vertex. The frogs are able to ""leap"" one over another. When they do, they will land in the symmetric spot to where they jumped from as shown on this drawing. they can jump in any order they want and also any number of times they want. Is it possible to arrange the frogs such that they are on the vertices of an equialteral triangle whos sides are equal to $2$?","['geometry', 'puzzle']"
1061589,Formula for $1! \times 2! \times \cdots \times n!$?,"Are there any useful forms for the expression $1!\cdot 2!\cdot 3!\cdot ...\cdot n!$? I'm trying to solve a problem that involves this expression and thought it might help to find a more ""workable"" form for it, but I didn't get very far. Thanks","['factorial', 'reference-request', 'combinatorics']"
1061594,Signing $y''$ from $\log(\frac{x+y}{x})=x+y$,"Suppose that $x,y>0$ are positive reals such that $y$ is defined implicitly in terms of $x$ via:
  $$
\log\left(\frac{x+y}{x}\right)=x+y.\tag{$\star$}
$$
  I would like study the sign of $y''$. Attempt : Write ($\star$) as
$$
\log(x+y)-\log(x)=x+y.
$$
Differentiate both sides w.r.t. $x$ yields
$$
\frac{1+y'}{x+y}-\frac{1}{x}=1+y'\tag{$\star\star$}
$$
which can be solved to get 
$$
1+y'=\frac{x+y}{x(1-x-y)}\cdot
$$
Differentiate both sides of ($\star\star$) w.r.t. $x$ to get
$$
\frac{(x+y)y''-(1+y')^2}{(x+y)^2}+\frac{1}{x^2}=y''
$$
which, after feeding to Mathematica while using $1+y'$ found above, gives
$$
y''=\frac{(x+y-2) (x+y)^2}{x^2 (x+y-1)^3}
$$
which can clearly take on positive and negative values depending on $x+y$. Indeed, looking back at ($\star$), we can freely vary $x+y$: to have $x+y=r>0$, simply set
$$
x=e^{-r}r,\quad y=(1-e^{-r})r.
$$ Is my attempt here reasonable to you? The reason I'm not confident is that if I feed ($\star$) directly to Mathematica, I get
$$
y=-x-\text{ProductLog}[-x]
$$
where (according to Help File) $\text{ProductLog}[z]$ gives the principal solution for $w$ in $z=we^w$. Then I plotted
$$
\partial_x(\partial_x(-x-\text{ProductLog}[-x]))
$$
and saw something that is only positive: What is going on? Can someone please explain this seeming discrepancy?",['calculus']
1061607,Joint probability distribution of sum and product of two random variables,"Let $X$ and $Y$ be two discrete random variables. I know the joint probability distribution of the vector $(X,Y)$, namely $P(X = x, Y = y)$ for all $x$ and $y$ in the sample spaces $\Omega_X$ and $\Omega_Y$, respectively. Using the joint distribution, I discovered that $X$ and $Y$ are conditionally dependent. Now let $U := X + Y$ and $V := X \cdot Y$ be two random variables. I need to calculate the distribution of both $U$ and $V$. Is it correct to calculate the distribution of $U$ as
\begin{align}
  P(U = u) = \sum_{x \in \Omega_X, y \in \Omega_Y \text{ such that } x \cdot y = u} P(X = x, Y = y),
\end{align}
even though $X$ and $Y$ are conditionally dependent? Furthermore I need to calculate the joint distribution of the probabilty vector $(U,V)$. I know that the distribution can be calculated as
\begin{align}
  P(U = u, V = v) = P(U = u) \cdot P(V = v),
\end{align}
if $U$ and $V$ are conditionally independent. However, to show that $U$ and $V$ are conditionally independent, I would look at the joint distribution, which I have to calculate. How does one calculate the joint distribution of $(U,V)$, if the variables are conditionally dependent? Furthermore, is there any way to find out whether $U$ and $V$ are conditionally dependent or not, without using the joint probability distribution? Since $U$ and $V$ are defined as sum and product of two random variables (which are conditionally dependent), I have the feeling that $U$ and $V$ are conditionally dependent.","['probability-distributions', 'probability']"
1061646,Convolution integral problem,"In the process of solving a certain PDE, I've arrived at a convolution integral: $$\int_{\mathbb{R}^3} G(x-y) \nabla p(y) dy$$ where $x \in \mathbb{R}^3$, $G(z)=\frac{1}{\| z \|}$ and $p(z) = \frac{z_1}{\| z \|^3}$. Note that $G$ and $p$ both vanish at $\infty$. To avoid computing this gradient, I integrated by parts, moving the $y$ derivative over to $G$. Computing the appropriate derivatives and using the vanishing at $\infty$, I get $$\int_{\mathbb{R}^3} \frac{x-y}{\| x - y \|^3} \frac{y_1}{\| y \|^3} dy.$$ I'm not sure where to go from here. If it helps any, I already know the final result from another source which is using a different derivation that I don't understand. At the end I should get $$\frac{2 \pi x}{\| x \|^3} x_1.$$","['multivariable-calculus', 'partial-differential-equations', 'analysis']"
1061661,Square root of unbounded operator,"Let $T: \operatorname{dom}(T) \subset H \rightarrow H$ be a positive self-adjoint unbounded operator, then I want to define a UNIQUE(!) operator $A$ such that $A^{*}A = T$. Actually, this construction is nothing new, but I am uncertain about the DOMAIN(!) of $A$ in the case of unbounded operators. Therefore, I was wondering if anybody here knows a good reference that treats this ""polar decomposition"" also in the case of unbounded operators. Alternatively, if somebody wants to comment on this problem, I would highly appreciate this. I mean, one is somehow tempted to say $\operatorname{dom}(A) = \operatorname{dom}(T)$ and then it is necessary that $\{Ax:x \in \operatorname{dom}(T)\} \subseteq\operatorname{dom}(A^*)$, but how can I see this or is this completely wrong?","['operator-theory', 'spectral-theory', 'real-analysis', 'analysis', 'functional-analysis']"
1061668,An extension that is normal but not separable,I'm looking for an example of an normal extension but not separable; all I know is that $\mathbb{F}_p(t)$ is not separable since $X^p-t$ is not. Thank you for your time,['abstract-algebra']
1061683,Don't see the point of the Fundamental Theorem of Calculus.,"$$\frac{d}{dx}\int_a^xf(t)\,dt$$ I would love to to understand what exactly is the point of FTC.  I'm not interested in mechanically churning out solutions to problems.    It doesn't state anything that isn't already known.  Prior to reading about FTC, the integral is defined as the anti-derivative.  So, it's basically an operator.  ""Take the anti-derivative by figuring out whose derivative this is!""  Simple.  So, what is so ""fundamental"" about redundantly restating the very definition of the integral? (The derivative of the anti-derivative is the function).  This to me is like saying $-(-1) = +1$.  Not exactly earth shattering. Am I missing something with regard to the indefinite vs. definite integral? If we look at a simple example, 
$$\frac{d}{dx}\int_1^xt^2 \, dt = \cdots =x^2$$ Can we discuss what exactly this is representing? Why would you even write this? Why would you take the rate of change
of an area under the curve? Why would you want to take the
derivative of an integral? Or, is this just done to prove something
else?  When would you even come across this situation in Math?  Taking the rate of change of the area under a curve and/or total displacement?   (derivative of the definite integral) Also, what is the significance of using $t$ as a variable? Why would you integrate from a constant to a function in the first
place?   (take area under the curve or compute total displacement) I don't understand what exactly things FTC even allows anyone to do.  Without FTC, I can already evaluate definite integrals.  Without FTC, I can already take derivatives.  So, with FTC, I can take an integral then take a derivative?  So, what's even the point of FTC?  I really don't see anything ""fundamental"" whatsoever about this redundant self-evident ""theorem"". This is like taking the inverse of an inverse.  Right back to f(x), but that's simply a ""neat trick"" vs. a ""Fundamental Theorem of Algebra"".",['calculus']
1061696,Making triangles out of a triangular lattice?,"First off: Yes, I am well aware that this question has been posted before. However, the answer in that one was incorrect, so I decided to make another thread to gain more input, as well as provide what I have figured out on the problem so far. The problem asks: How many equilateral triangles in the plane have AT LEAST TWO of the points in the triangular lattice below as vertices? Using the formula found here: Link , I found out that the number of triangles with THREE vertices in the triangular lattice is 48. However, I am having trouble finding the number of triangles with TWO vertices in the triangular lattice. Would the two vertices in the triangular lattice come from the points bordering the triangular lattice? If so, I came up with 24. I am also worried about overcounting...and I also do not think I counted ALL of the possibilities. Can someone guide me in the right direction and provide me with some hints?",['probability']
1061705,"Evaluate $\int_0^{2\pi} \frac{\sin^2\theta}{5+4\cos\theta}\,\mathrm d\theta$","Evaluate $$\int_0^{2\pi} \frac{\sin^2\theta}{5+4\cos(\theta)}\mathrm d\theta$$ This is the final question on my review for my final exam tomorrow, and I will be honest and say that I have no clue how to begin problem. Any hints in the direction of how to solve this would be helpful. Following from @Adam Hughes, $-\dfrac{\pi}{2}[f'(0)+Res_2]$When I took the derivative of $f(z)=\dfrac{(z^2-1)^2}{2z^2+5z+2}$ and evaluated for 0, I got $-\dfrac{5}{4}$ Now, $Res_2$","['residue-calculus', 'integration', 'complex-analysis', 'contour-integration']"
1061735,Why do we focus so much in math on functions (as a subclass of relations)?,"Why is it that math so focuses on the subclass of relations known as functions? I.e. why is it so useful for us in nearly all branches of mathematics to focus on relations which are left-total and left-unique? Left- (or even right-) totality seem to be intuitive, since if an element doesn't appear in the domain, we might throw it out. But why left-uniqueness? I'm looking for something like a ""moral explanation"" of why they would be the most useful subclass of relations. My apologies if this is a previous question; I looked and didn't find much.","['philosophy', 'soft-question', 'functions', 'definition']"
1061767,"If $f$ and $g$ are continuous, then max(f, g) is continuous and differentiable","If $f$ and $g$ are continuous on $[a, b]$ and differentiable on $(a, b)$, then $\max(f, g)$ is continuous on $[a, b]$ and differentiable on $(a, b)$. I'm asked to either prove or disprove this statement.  So far I'm thinking that it's true because if a function is continuous and differentiable on an interval, it takes on it's max/min over the interval, but I don't know if this is correct, and if it is, I don't know how to prove it.  Any help would be appreciated.","['real-analysis', 'analysis']"
1061770,Showing a property of a curvature tensor in $S^2$,"Consider $S^2 \subset \mathbb{R}^3$. I need to show that if $$R_{ijkl} = -g(R(\partial_i,\partial_j)\partial_k,\partial_l)$$ is a curvature tensor in $S^2$ and $g$ is a metric also in $S^2$, then $$R_{ijkl} = k(g_{ik}g_{jl} - g_{il}g_{jk})$$ where $k$ is the curvature of $S^2$. Attempt: I managed to show that $R_{ijkl} = -R_{jikl}$ and $$R_{ijkl} + R_{jkil} + R_{kilj} = 0 $$ (Bianchi's First Identity) I couldn't figure out though how to get that identiy. I was thingking maybe use that $R_{ijkl} = g_{im}R^{m}_{ijk}$. Edit: I got one more step using the properties above $$R_{ijkl} = \frac{1}{2}\Big(R_{jkil}+R_{kilj}-R_{ikjl}-R_{kjli}\Big)$$ Any help, please? I've been searching and found that this could be derived from Bianchi's Identities.","['tensors', 'riemannian-geometry', 'curvature', 'differential-geometry']"
1061778,Galois theory reference request,I ran into the following description of Galois theory in Gelfand and Manin's Methods of Homological Algebra. But this looks like nothing like the Galois theory I know that deals with subgroups and field extensions. I wonder if there is any great self contained books that treats this topic thoroughly enough so that I can understand the following paragraphs? Thank you.,"['galois-theory', 'book-recommendation', 'reference-request', 'abstract-algebra']"
1061782,"There are 10 men, 10 women, and 10 rooms. Each person randomly goes into a room.","What is the expected number of rooms with at least one man and woman? Our prof. gave us the following solution however, I'm confused about the probability portion of the answer (especially the $(\frac{9}{10})^{10}$ part): $$10 \times \left(\!1 - \left(\! \frac{9}{10} \!\right)^{\!\!10}\hspace{1mu}\right)^2$$","['probability-distributions', 'discrete-mathematics']"
1061797,find the nullclines,"I don't know how to find the nullclines in the system (see picture attached) according to my professor (0,0) is one of them. I'm so confuse looking for it.",['ordinary-differential-equations']
1061822,"""Internal"" and ""external"" in maths, and also in vector spaces","I have looked at 3 books and it is clear that ""internal"" and ""external"" are two styles of defining something, I would like to know what they mean ""generally"" - that is very soft but it is clear to me that ""internally"" doing something is different from doing it ""externally"" even if the result is similar. I've read ahead and motivating examples or even uses of these definitions are not given, so if you have any examples that come to mind please do share. First it defines External direct sum using a $+$ inside a $\square$ of a finite number of vector spaces over the same field (I understand ""external"" might mean ""not considering them as subspaces of something"") $V=V_1+...+V_n$ is defined component wise (as vectors themselves) This is fine, I am happy with this. Direct product next and we have a family $\funky{F}=\{v_i|i\in K\}$ the direct product is: $\Pi_{i\in K}V_i=\{f:k\rightarrow\cup_{i\in K}V_i|f(i)\in V_i\}$ At first this seems horrible but really it's not too bad, $f$ is acting as a projection to coordinates really. This is a vector space itself and thinking about it I ask myself ""How is that not the external direct sum (provided the family is finite)"" This is not what I was taught for sum take the plane $x=0$ and the plane $y=0$ in $\mathbb{R}^3$, their union is just an extruded $+$ shape but what I was taught was the sum becomes all of $\mathbb{R}^3$ because the sum was defined as $\{u+v|u\in V_1 v \in V_2\}$ But anyway, that's direct product. External direct sum This time it is denoted not by a $+$ in a square but by a + in a circle with ""ext"" in superscript, due to lack of knowledge of the name of this symbol I must describe it to you. Anyway this sum is (on a family as above) $\{f:K\rightarrow\cup_{i\in K}V_i|f(i)\in V_i, f\text{ has finite support}\}$ finite support means $f(i)=0$ for all but a finite number of $i$ I dare not come up with examples because it's not finite. Lastly Internal direct sums This is written as a + with a circle around it, and it requires the following hold: The join of the family is V, that is: $V=\sum_{i\in K}S_i$ which is the more conventional sum I assume, and independence of the family, that is: $S_i\cap(\sum_{j\ne i}S_j)=\{0\}$ It notes that this second condition is stronger than pairwise disjoint, I cannot think of an example which shows this distinction and I'd like one. That's all the book does on these, unless they are used far later. What is going on here? Also what do ""internal"" and ""external"" mean, I can't think of an example but I think it refers to a style of definition, I've come across and gotten used to similar things before. The book is: Advanced Linear Algebra, Steven Roman, 3rd Edition, GTM # 135","['category-theory', 'linear-algebra', 'abstract-algebra']"
1061879,Solving an equation with exponentials,$$2^x+4^x+12=0$$ How exactly am I supposed to solve this? Am I supposed to get $x$ alone or solve it another way?,"['quadratics', 'exponentiation', 'algebra-precalculus']"
1061916,When to use Binomial Distribution vs. Poisson Distribution?,"A bike has probability of breaking down $p$, on any given day. In this case, to determine the number of times that a bike breaks down in a year, I have been told that it would be best modelled with a Poisson distribution, with $\lambda = 365\,p$. I am wondering why it would be incorrect to use a binomial distribution, with $n=365$. After all, isn't Poisson really an approximation of a sum of Bernoulli random variables? Thanks!","['poisson-distribution', 'probability-distributions', 'probability']"
1061927,"The differential equation $xu_{x}+yu_{y}=2u$ satisfying the initial condition $y=xg(x),u=f(x)$","I was thinking about the following problem : Find out which of the following option(s) is/are correct? The differential equation $xu_{x}+yu_{y}=2u$ satisfying the initial condition $y=xg(x),u=f(x)$ , with (a) $f(x)=2x,g(x)=1$ has no solution, (b) $f(x)=2x^2,g(x)=1$ has infinite number of solutions, (c) $f(x)=x^3,g(x)=x$ has a unique solution, (d) $f(x)=x^4,g(x)=x$ has a unique solution. My Attempt: Using lagrange's method, we see that $\frac{dx}{x}=\frac{dy}{y}=\frac{du}{2u} $ gives $y/x=c_1,$ and $y=\sqrt uc_2$ ,where $c_1,c_2$ being constants. Now we have to apply to the given initial conditions  and  check the given options.Here ,I observe that $y=xg(x)=x.1=x$ ,[as $g(x)=1$ ] and $u=f(x)=2x^2$ But,this relation does not satisfy $xu_{x}+yu_{y}=2u$ and so the choice""(a) $f(x)=2x,g(x)=1$ has no solution,"" is right. Now I am stuck here and could not progress further.Am i going in the right direction? Please help.Thanks in advance for your time.",['partial-differential-equations']
1061928,"If $\left(1+\sin \phi\right)\cdot \left(1+\cos \phi\right) = \frac{5}{4}\;,$ Then $\left(1-\sin \phi\right)\cdot \left(1-\cos \phi\right)$","If $\displaystyle \left(1+\sin \phi\right)\cdot \left(1+\cos \phi\right) = \frac{5}{4}\;,$ Then $\left(1-\sin \phi\right)\cdot \left(1-\cos \phi\right) = $ $\bf{My\; Try::}$ Given $\displaystyle \left(1+\sin \phi\right)\cdot \left(1+\cos \phi\right) = \frac{5}{4}\Rightarrow 1+\sin \phi\cdot \cos \phi+\sin \phi+\cos \phi = \frac{5}{4}.$ So $\displaystyle \sin \phi+\cos \phi+\sin \phi \cdot \cos \phi = \frac{1}{4}\Rightarrow \left(\sin \phi+\cos \phi\right) = \frac{1}{4}-\sin \phi \cdot \cos \phi.$ Now $\displaystyle \left(1-\sin \phi\right)\cdot \left(1-\cos \phi\right) = 1-\left(\sin \phi+\cos \phi\right)+\sin \phi \cdot \cos \phi =\frac{3}{4}+\sin 2\phi$ Now How can I calculate $\sin 2\phi.$ Help me, Thanks",['trigonometry']
1061973,chi-square test for uniform distribution,"So, i have a hash function which maps a set of possible inputs to a defined range of outputs. I want to test if the mapped outputs are uniformly distributed over the defined range. Wikipedia seems to suggest that the chi-square test can be used to measure the uniformity of the result - how would i go about doing this?","['statistics', 'probability']"
1061977,local maxima of weierstrass function,"Does the weierstrass function have uncountably many local maxima on (0,1)? I don't really know how to approach this problem at all, so any help is appreciated","['maxima-minima', 'analysis']"
1061992,Example of a ring in which square of every element is zero,"This is an exercise in a book ""Rings and Modules- Musili"": (in this book, ring may not have unity.) Give an example of a non-trivial commutative ring in which square of every element is zero. Here non-trivial means it is not the case that ""$xy=0$ for all $x,y$"". This also raises a natural question: Give an example of a non-trivial non-commutative ring in which square of every element is zero. I tried the following examples: $\mathbb{Z}/2\mathbb{Z}\times \mathbb{Z}/2\mathbb{Z}\times\mathbb{Z}/2\mathbb{Z}$, with point-wise addition and multiplication like well known  ""cross product"" in vector calculus in $\mathbb{R}^3$. But, this product is not associative. Another example, $M_2(\mathbb{Z}/2\mathbb{Z})$ with usual addition; but multiplication $*$ defined as $A*B=AB+BA$. But here also, associativity of $*$ fails.","['ring-theory', 'abstract-algebra']"
1062990,"Determine when the system has a) no solution, b) 1 solution and c) infinitely many solutions","This question is not for an assignment, it was on the midterm and I am interested in figuring out how to solve it before the final exam. cheers, Determine when the system has a) no solution, b) 1 solution and c) infinitely many solutions
Given the system
\begin{align*}
x + y + 7z & = -7\\
2x + 3y +17z & = -16\\
x +2y +(a^2+1)z & = 3a
\end{align*} Attempted Solution using matrix form $$\pmatrix{1&1&7&-7\cr2&3&17&-16\cr1&2&a^2+1&3a\cr}$$ using gaussian elimination to isolate eqn 3 for variable z (sorry about the missing a^2+1 up there html doesn't like me) line 1 - line 3 $$\pmatrix{1&1&7&-7\cr2&3&17&-16\cr 0&1&7-(a^2+1)&-7-3a\cr}$$ 2*line 1 - line 2 $$\pmatrix{1&1&7&-7\cr 0&-1&-3&2 \cr 0&-1&7-(a^2+1)&-7-3a\cr}$$ -1*line2 $$\pmatrix{1 & 1 &7 &-7\\ 0 & 1 & 3 & -2\\ 0 & -1 & 7 - (a^2 + 1) & -7 - 3a}$$ -1*line 2 + line 1 $$\pmatrix{1 & 0 & 4 & -5\\ 0 & 1 & 3 & -2\\ 0 & -1 & 7 - (a^2 + 1) & -7 - 3a}$$ line 2 + line 3 $$\pmatrix{1 & 0 & 4 & -5\\ 0 & 1 & 3 & -2\\ 0 & 0 & 10 - (a^2 + 1) & -9 - 3a}$$ so we get equation 3 $10-(a^2+1)z=-9-3a$ rearranging, $$(a^2+1)z=-19-3a \rightarrow$$ $$z=19/a^2+1 - 3a/a^2+1 \rightarrow $$ $$z=(19/a^2+1) - (-3/a+1)$$ $$z=19/a^2 + 1 - (-3/a) +1$$ $$z=19/a^2 + 2 + 3/a$$ multiply all terms by $a$ $$za=19/a + 2a + 3$$ $$za=(39/19)a + 3$$ $$za=3a+3$$ $$z=3+3/a$$ wut? I am unsure how to properly answer the question, please help stack exchange! My algebra skills are a little lacking, please point out helpfully where my thinking is wrong. I can solve for z but what does that prove","['algebra-precalculus', 'gaussian-elimination', 'matrices', 'linear-algebra', 'systems-of-equations']"
1062993,"Does ${(x,y)\in\mathbb{R}\times\mathbb{R}:x,y\in\mathbb{Z}}$ have cardinality $\aleph_0$ or $c$?","So here's my intuition. Letting $S=\{(x,y)\in\mathbb{R}\times\mathbb{R}:x,y\in\mathbb{Z}\}$, $\bar S=\aleph_0$ because $(x,y)\in\mathbb{Z}\times\mathbb{Z}$, which can be shown to be equivalent to $\mathbb{N}\times\mathbb{N}$, which in turn can be shown to be equivalent to $\mathbb{N}$ and thus is denumerable. I don't have to prove it, but I think I need to show a little more rigor in my explanation. Also, what would a function that constructs this set (i.e., f onto S) look like? This isn't part of the question I need to answer, just curious because my classmates and I couldn't picture it.","['cardinals', 'elementary-set-theory']"
1063013,Group of order $p^{n}$ has normal subgroups of order $p^{k}$,"Q: Prove that a subgroup of order $p^n$ has a normal subgroup of order $p^{k}$ for all $0\leq k \leq n$. Attempt at a proof: We proceed by Induction. This is obviously true for $n=1, 2$.
Suppose it is true for $m \leq n-1$. Now, take the group $G$ of order $p^{n}$. Since it is a $p$-group, it has a non-trivial center by the Conjugacy Class equation. This center then has a subgroup of $K$ order $p$ by Cauchy's theorem for example. Since this subgroup is contained in the center, it is normal in $G$. Take the quotient $G/K$ which now has order $p^{n-1}$ hence by the induction hypothesis has subgroups $\bar{H_{k}}$ of order $p^{k}$ for $0\leq k \leq n-1$, which are normal in $G/K$. By the lattice isomorphism theorem, the lattice of $G$ has corresponding groups $H_{k}$ which are normal in $G$. The index of each such subgroup is $|G:H_{k}|=|G/K: \bar{H_k}|=p^{n-1-k}$, hence $H_{k}$ has order $p^{k+1}$ in $G$ as desired. Does this look okay?","['abstract-algebra', 'sylow-theory', 'group-theory', 'finite-groups', 'p-groups']"
1063034,Solving the equation: $3\cos x - \sin 2x = \sqrt{3}(\cos 2x + \sin x)$,"Solving the equation:
$$3\cos x - \sin 2x = \sqrt{3}(\cos 2x + \sin x)\tag{1}$$ I tried to write $(1)$ becomes
$$\sqrt{3}\sin \left(\frac{\pi}{3}-x\right)=\sin \left(\frac{\pi}{3}+2x \right)$$ Now, I have stuck :( , can you help me? Thanks!","['trigonometry', 'algebra-precalculus']"
1063076,"Given two local parameterizations and corresponding fundamental forms, find a $2\times 2$ matrix that equates them.","Horridly written title, but please see the image below for the problem statement: I'm not sure how to use the chain rule to express the first differentials in terms of the second. I know the answer is some kind of Jacobian matrix but I don't see the derivation path in front of me. What am I missing here?","['geometry', 'differential-geometry']"
1063109,Continuous function positive at a point is positive in a neighborhood of that point,"Pretty much the problem asks if a function is continuous at the point $c$ and $f(c) > 0$ then there exists a $d > 0$ such that $\forall x$, $f(x) > 0$ with $|x-c| < d$. I can understand what the problem means. That if a function is positive at a point then there is another point that's really close that'll also be positive. I can not prove this in a formal way though. I've tried using the intermediate value theorem and I do not know hot to implement it. Any ideas?","['continuity', 'analysis']"
1063118,Help with resolving an n x n determinant?,"I'm still a beginner, and would appreciate any tips regarding this. (Full solution appreciated, but hints more so!) This is the problem. \begin{equation}{D_n} = \begin{vmatrix}
1+{a_1} & 1  & ... & 1 \ 
1& 1+{a_2} &... & \vdots \ 
\vdots &...  &\ddots  &1 \ 
1&1  & ... & 1+{a_n}
\end{vmatrix} So using elementary operations, I simply multipled the last row by -1 and added it to all other rows to get the below matrix, so we're left with two columns to expand. \begin{equation}{D_n} = \end{equation}
\begin{vmatrix}
{a_1} & 0  & ... & 0 & -{a_n} \\ 
0& {a_2} & 0 & ... & \vdots \\ 
\vdots &...  &\ddots  &... &\vdots \\ 
0 &...  &0  &{a_{n-1}} & -{a_n}\\ 
1&  ... & ... & 1& 1+{a_n}
\end{vmatrix} This is where I got stuck - if I expanded them, I would get \begin{equation}{a_1}\times cofactor(a_{11}) + (-1)^n \times -{a_n} \times cofactor(a_{1n})\end{equation} Both of which would turn into recursive formulae. Is there an alternative way of simplifying the original matrix to get a more easily calculable format? EDIT : Following Alex's tip, I expanded it further by multiplying each row by its negative reciprocal to cancel out the 1's in the last row, so the determinant is simply equal to the product of the diagonal cells. The final answer I got was \begin{equation}\prod_{k=1}^{n-1} {a_k} \times \left(1 + {a_n} + {a_n} \left( \frac{1}{a_1}+ \frac{1}{a_2} + \dots + \frac{1}{a_n}\right)\right)\end{equation}","['matrices', 'linear-algebra', 'determinant']"
1063182,XA+B=X will have a unique solution...,"I am currently stuck on this question: Let A and B be n x n matrices. Show that if none of the eigenvalues of A are equal to 1, then the matrix equation XA+B=X will have a unique solution. I've heard that if the eigenvalues of a matrix are not equal to 1, then it implies a unique solution. However, I'm confused how to take this one step further and prove that XA+B=X will have a unique solution.","['matrices', 'linear-algebra']"
