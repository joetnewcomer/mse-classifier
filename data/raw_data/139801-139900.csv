question_id,title,body,tags
2249619,"Prove that $\lim_{(x,y)\to (0.0)} \frac{4xy^2 - 3x^3}{x^2 - y^2}$ does not exist","I'm struggling with this limit. I have to approach using different curves and show that there is one curve wich prove that this limit does not exist , despite the fact that when trying with a lot of curves shows that the limit is 0. If someone helps me to find that curve I will be very pleased. Thanks! $$\lim_{(x,y)\to (0.0)} \frac{4xy^2 - 3x^3}{x^2 - y^2}$$","['analysis', 'limits']"
2249701,Why is the Hodge conjecture equivalent to the assertion that $ \mathcal{R}_{ \mathrm{Hodge} } $ is fully faithfull?,"On pages 17 and 18 of the following document: https://www.math.tifr.res.in/~sujatha/ihes.pdf , we find the following paragraph: Let $ \mathbb{Q} \mathrm{HS}$ be the category of pure Hodge structures over $\mathbb{Q}$.
  There is a functor:
  $$
\mathcal{R}_{ \mathrm{Hodge} }  \colon  \mathop{\mathrm{Mot}}^{ \bullet }_{ \mathrm{num} } ( k, \mathbb{Q} ) \to \mathbb{Q} \mathrm{HS} 
$$
  and the Hodge conjecture is equivalent to the assertion that $\mathcal{R}_{ \mathrm{Hodge} }$ is fully faithful. My questions are: How is the Hodge realization functor $ \mathcal{R}_{ \mathrm{Hodge} }$ explicitly defined? And how to prove explicitly that the Hodge conjecture is equivalent to the assertion that $\mathcal{R}_{\mathrm{Hodge}}$ is fully faithful? Thanks in advance for your help.","['category-theory', 'hodge-theory', 'algebraic-geometry']"
2249765,How to prove that $\mathbb{R}^n$ for every n > 4 has a unique smooth structure up to diffeomorphism?,"I have read Gauge Theory on Asymptotically Periodic 4-Manifolds by Clifford Henry Taubes where an uncountable family of diffeomorphism classes of oriented 4-manifolds which are homeomoprphic to $\mathbb{R}^4$ is constructed. Furthermore, I know that for 1-, 2-, and 3-manifolds homeomorphic manifolds are already diffeomorphic. Thus, all $\mathbb{R}^n$ with n < 4 have a unique smooth structure up to diffeomorphism. The same holdes for n > 4 as many textbooks and wikipedia claim without proof. Unfortunately, I have not any idea how to prove that $\mathbb{R}^n$ for every n > 4 has a unique smooth structure up to diffeomorphism. Does anybody know the proof or a paper where it has been proved?","['general-topology', 'differential-topology']"
2249830,Find the distribution of $R=\bar X / \bar Y$ where $X$ and $Y$ are exponentially distributed,"Find the distribution of $R=\bar X / \bar Y$ given that exponential
  distribution with mean parameter 2 is equivalent to Chi squared with 2
  dof. I'm given 2 samples $x_i$ and $y_i$ of sizes $n$ and $m$ respectevely such that 
$$f(x,\theta)=\frac{1}{\theta}e^{-x/\theta}$$ and $$f(y,\theta)=\frac{1}{\theta}e^{-y/\theta}$$ Construct confidence interval of $R$? I think it should also me exponentially distributed, but I'm struggling even starting this question. In particular, the different sizes of samples put me off doing $f(R,\theta)=f(x)/f(y)$ I though about about finding the mean $E(X)=\int^{\infty}_0 x f(x,\theta)dx$ and finding $E(R)=E(X)/E(Y)$","['exponential-distribution', 'statistics']"
2249887,Does proving $A ∪ (B ∩ C) ⊆ (A ∪ B) ∩ (A ∪ C)$ prove the distributive law of sets?,Does proving $A ∪ (B ∩ C) ⊆ (A ∪ B) ∩ (A ∪ C)$ prove the distributive law of sets? I know the proof for A ∪ (B ∩ C) ⊆ (A ∪ B) ∩ (A ∪ C) but not the distributive property of sets but I believe it satisfies the distributive law? Is it or is it not?,"['elementary-set-theory', 'discrete-mathematics']"
2249914,Solving for angles in a Tetrahedron,"I have a triangulation problem I'm trying to solve for a work project. It's been ages since I've taken a math class so assume that I've forgotten everything because I probably have. So here's the situation: I have a tetrahedron ($ABCD$). I know all three angles ($\angle ABC \angle ACB \angle BAC$) and the lengths of all three sides ($\overline{AB}$  $\overline{AC}$ $\overline{BC}$) of the base ($\triangle ABC$). I know all three angles around the peak ($D$) ($\angle ADB$ $\angle ADC$ $\angle BDC$). With that I can deduce the dihedral angles between three faces ($\triangle ABD$ to $\triangle ACD$, $\triangle ACD$ to $\triangle BCD$, $\triangle ABD$ to $\triangle BCD$). How can I solve for the lengths of any of the sides between the base and the peak ($\overline{AD}$ $\overline{BD}$ $\overline{CD}$), or any of the remaining angles ($\angle ABD$ $\angle BAD$ $\angle ACD$ $\angle CAD$ $\angle BCD$ $\angle CBD$)? It seems to me with a base having a fixed, known shape and size, and fixed angles around the fourth point, it should be possible to directly deduce the rest of the angles and side lengths. Thanks in advance. -Jon UPDATE: I feel like there's something lurking in the Law of Sines. Since I have one angle and its opposite side for faces $\triangle ABD$ $\triangle ACD$ and $\triangle BCD$, I know the ratio between the sines of the unknown angles and their opposite faces. Also, from the Law of Sines as applied to a tetrahedron I know the ratio between the sines of angles from adjacent faces opposite their shared side: $$\frac{\sin(\angle ABD)}{\sin(\angle ACD)}=\frac{\sin(\angle ADB)\cdot\sin(\angle ABC)}{\sin(\angle ADC)\cdot\sin(\angle ACB)}$$ To satisfy the ratios within both $\triangle ABD$ and $\triangle ACD$, AND the ratio between $\sin(\angle ABD)$ and $sin(\angle ACD)$ should force only one possibility for $\overline{AD}$, right?","['trigonometry', 'triangulation']"
2249931,"Finding $n\dim B$ linearly independent invertible matrices in $M(n,B)$?","I'm trying to solve the following exercise: If $A$ is a finite-dimensional $k$-algebra, then a minimal representation of $A$ is a representation of minimal $k$-dimension. Show that if $B$ is a finite-dimensional division algebra over $k$ and $A=M(n,B)$, then the action of $A$ on $B^n$ is a minimal representation. To show this, we need to show that if we have any representation $A\to\text{End}(V)$ for a $k$-space $V$, then $\dim V\ge n\dim B$. I will write this map as $E\mapsto\varphi_E$ for $E\in A$. Now, if I suppose that $A$ has $nm$ linearly independent invertible matrices $E_1,\dots,E_{nm}$, where $m=\dim B$ then I will be done. By taking some nonzero $v\in V$, I let $v_i=\varphi_{E_i}(v)$ then this is nonzero since $\varphi_{E_i}$ is invertible (since $E_i$ is), and I can show that $\{v_1,\dots,v_{nm}\}$ is linearly independent using the linear independence of $E_1,\dots,E_{nm}$ in $A$. So my problem just lies now in finding $nm$ linearly independent, invertible elements of $A$ (the latter of which is the same as having $\det E\neq0$ since $B$ is a division algebra). Does anybody have a suggestion on how to obtain these?","['representation-theory', 'abstract-algebra', 'linear-algebra']"
2249939,P-value of a One-sided One-sample t Test,"John claims that the typical lifetime of a car in his shop with 10 years warranty, is significantly more than 10 years. To test the claim, 9 cars are randomly selected, with lifetimes recorded. Sample mean lifetime is 13.5 years, and sample standard deviation is 3.2 years. Assuming the lifetime has a normal distribution, what conclusion can be drawn at 1% significant level? So I have several tables and formulas here, first I am looking to see if it's a one sample or two sample problem, it's one sample. Then I am looking to see of the sample is large or small, it's small, only 9. Then I am looking to see if the population variance or standard deviation is known, or unknown, and it's unknown. And lastly I am looking for normality, and it's normally distributed. So with this information, I'd assume we're using the T test looking for the mue (population mean) parameter. Which then follows: $H_0: \mu = 10$ $H_a: \mu > 10$ $T = (\bar X - \mu)/(S/\sqrt{n})$ Plugging our values in, I get 3.281 as a T-score. The rejection region is then defined by $T > T_\alpha(\nu)$ where $\nu = n - 1.$ So on the T-table, with degrees 8, and an alpha of .01, this would be the same as the $T > -T_1-\alpha$ so alpha would be now .99, and we can find the T-score of .99 from the table ensuring to make it negative as -2.896. Our P-value would also be $P(T > 3.281).$ Now since our test statistic which is 3.281, is greater than -2.896, it's in the rejection region and we can reject the null hypothesis. Which in turn then, we can also support John's claim. So if I did all this correct, great, but the options I am given for this problem are the following: a. Sufficient evidence at 1% to support the claim, and the p-value is equal to P(T > 3.355). b. Sufficient evidence at 1% to reject the claim, and the p-value is equal to P(T < -3.281). c. Insufficient evidence at 1% to support the claim, and the p-value is equal to P(Z > 2.896). d. Insufficient evidence at 1% to support the claim, and the p-value is equal to P(Z > 2.896). e. None of these answers Is the answer here really e? Did I do everything correct? Already seems kind of a funky question as one answer is repeated and we're not even using Z. And the answer could be a. but that t-score is if the alpha level was 0.005, and we have an alpha of 0.01, and it's not a two tail test, it's a one tail test. And then b. is wrong because it's not negative nor <.","['statistics', 'hypothesis-testing', 'statistical-inference']"
2249940,"Discrete math: forming a comittee from n men, n women, using 2 different approaches.","Prove that,
$$\sum_{k=1}^n k\binom{n}{k}^2 = n\binom{2n-1}{n-1}$$
by determining, in two different ways, the number of ways a committee can
be chosen from a group of $n$ men and $n$ women. Such a committee has a
woman as the chair and has $n − 1$ other members. Why is $k$ in $[1,n]$? Why is the binomial coefficient to the power $2$?","['combinatorics', 'discrete-mathematics']"
2249947,Abstract concept tying real numbers to elementary functions?,"Real numbers can be broken into two categories: rational vs. irrational. Irrational numbers can be approximated, but never fully represented by rational numbers. Analytic functions have Taylor polynomial representations. I know that polynomials have finite taylor expansions (trivially), while transcendental functions have infinite taylor expansions, which we truncate by necessity. So it seems again we have an easy-to-represent function (polynomials) with can be added infinitely to represent (or finitely-many times to approximate) an analytic function. Similarly, other functions have Laurent expansions, and I can categorize them as having finite vs. infinite expansions… I sense there’s a deeper abstraction here. Having read the first two chapters of an Abstract Algebra textbook, the word “isomorphism” comes to mind. From Analysis 1 I also know that these objects can be used to form metric spaces. Is there a deeper pattern here? For example: real numbers can be added or multiplied to obtain other reals, and polynomials can be added or multiplied to obtain other polynomials (and from there, transcendentals). This reminds me of the field properties…","['abstract-algebra', 'real-numbers', 'analysis', 'functions']"
2249949,Solving linear nonhomogenous system of differential equations,"I have a question, concerning one special solution of the following system.
First I will sum up my results, to give a context for my question. My question will be seperated by a line, if you want to skip the introduction. $\begin{equation}
\begin{aligned}
\mathrm{II:} \quad\\
\mathrm{III:} \quad\\
\end{aligned}
\begin{aligned}
\dot{x}_2 &=  a x_0 - b x_2 + cx_3 + g x_0 x_3\\
\dot{x}_3 &= -d y_2 x_3 + b x_2 - cx_3 \\
\end{aligned}
\end{equation}$ with the initial conditions $x_0 = x_1(0) \quad \rightarrow \quad x_2(0) = x_3(0) = x_4(0) = 0$ First I solved the homogenous part of the system:
\begin{equation}
\left(\begin{matrix}\dot{x}_2\\\dot{x}_3\end{matrix}\right) = \underbrace{\left[\begin{matrix}- b & g x_{0} + c\\b & -\left( d y_{2} +c \right)\end{matrix}\right]}_{\substack{\hat{A}}}\left(\begin{matrix}x_2\\x_3\end{matrix}\right) + \underbrace{\left(\begin{matrix}a x_0\\0\end{matrix}\right)}_{\substack{\textbf{b}}}
\end{equation} \begin{equation}
\begin{aligned}
\\
\lambda_1 &= -\frac{1}{2}\left[ b+ c+d y_{2} + \sqrt{\left(b + c + d y_2 \right)^2 - 4 b \left(d y_2 - g x_0 \right)} \right]\\
\\
\lambda_2 &=  -\frac{1}{2}\left[ b+ c+d y_{2} + \sqrt{\left(b + c + d y_2 \right)^2 - 4 b \left(d y_2 - g x_0 \right)} \right]
\\
\\
\end{aligned}
\begin{aligned}
v_1 &= \left(\begin{matrix}- \frac{2\left(c + g x_{0}\right)}{- b + c + d y_{2} +  \sqrt{\left(b + c + d y_2 \right)^2 - 4 b \left(d y_2 - g x_0 \right)}}\\1\end{matrix}\right) \\
v_2 &= \left(\begin{matrix}- \frac{2\left(c + g x_{0}\right)}{- b + c + d y_{2} - \sqrt{\left(b + c + d y_2 \right)^2 - 4 b \left(d y_2 - g x_0 \right)}}\\1\end{matrix}\right)\\
\end{aligned}
\label{eq::modell6_eigenwerte_und_vektoren}
\end{equation} which is given by
 \begin{equation}
\textbf{x}_h = c_1 \textbf{v}_1 e^{\lambda_1t} + c_2 \textbf{v}_2 e^{\lambda_2t} 
\label{eq::modell5_homogene_loesung}
\end{equation} I found the particular solution using the following approach \begin{equation}
x_p = \left(\begin{matrix}A_1\\A_2\end{matrix}\right) \quad \dot{\textbf{x}}_p = \hat{A} \textbf{x}_p + \textbf{b}
\end{equation} the solution of this equation is \begin{equation}
\textbf{x}_p = \frac{ax_0}{\left(d y_2 - g x_0 \right)}\left(\begin{matrix}\frac{d y_2 + c}{b}\\1\end{matrix}\right)
\end{equation} Adding homogenous and particular solution and using the initial conditions gave me the following general solution of the system. \begin{equation}
\begin{aligned}
x_1 &=  x_0\\
x_2 & =   \frac{ax_0}{\left(d y_2 - g x_0 \right)} \left[-\frac{\left(g x_{0} +c\right) \left(b + c + d y_{2} - \sqrt{\dots}\right)}{\sqrt{\dots}\left(- b + c + d y_{2} +  \sqrt{\dots} \right)}  e^{-\frac{1}{2} \left[b + c + d y_{2}+ \sqrt{\dots}\right]t} + \frac{\left(g x_{0} +c\right) \left(b + c + d y_{2} + \sqrt{\dots}\right)}{\sqrt{\dots}\left(- b + c + d y_{2} -  \sqrt{\dots} \right)}  e^{-\frac{1}{2} \left[b + c + d y_{2}- \sqrt{\dots}\right]t} + \frac{d y_2 + c}{b}\right]\\
x_3 &= \frac{ax_0}{\left(d y_2 - g x_0 \right)} \left[\frac{\left(b + c + d y_{2} - \sqrt{\dots}\right)}{2 \sqrt{\dots}}e^{-\frac{1}{2} \left[b + c + d y_{2} + \sqrt{\dots}\right]t}  - \frac{ \left(b + c + d y_{2} + \sqrt{\dots}\right)}{2  \sqrt{\dots}}e^{-\frac{1}{2} \left[b + c + d y_{2} - \sqrt{\dots}\right]t} + 1   \right]\\
x_4 &=\frac{d y_2 a x_0}{\left(d y_{2} - g x_{0}\right)}\left[-\frac{ \left(b + c + d y_{2} - \sqrt{\dots}\right)}{  \sqrt{\dots}\left[b + c + d y_{2} + \sqrt{\dots}\right]}e^{-\frac{1}{2} \left[b + c + d y_{2} + \sqrt{\dots}\right]t}+ \frac{ \left(b + c + d y_{2} + \sqrt{\dots}\right)}{  \sqrt{\dots}\left[b + c + d y_{2} - \sqrt{\dots}\right]}e^{-\frac{1}{2} \left[b + c + d y_{2} - \sqrt{\dots}\right]t} +  t  +\frac{ \left(b + c+  dy_2 \right)}{b\left(d y_{2} - g x_{0}\right)}\right]
\end{aligned}
\label{eq::modell6_loesung}
\end{equation}
with
\begin{equation}
\sqrt{\dots} = \sqrt{\left( b + c + d y_2 \right)^2 - 4b \left(dy_2 - g x_0 \right)}
\end{equation} --------------------------------------------- Now I want to analyze the special case $\left(d y_{2} - g x_{0}\right)$. This solution is very interesting because the exponent of the e function, switches from positive to negative at this transition.
As I get a zero-division error in my standard solution, I want to solve the system of equations again, with the new set of parameters.
\begin{equation}
\left(\begin{matrix}\dot{x}_2\\\dot{x}_3\end{matrix}\right) = \underbrace{\left[\begin{matrix}- b & c + d y_{2}\\b & - c - d y_{2}\end{matrix}\right]}_{\substack{\hat{A}}}\left(\begin{matrix}x_2\\x_3\end{matrix}\right) + \underbrace{\left(\begin{matrix}a x_0\\0\end{matrix}\right)}_{\substack{\textbf{b}}}
\end{equation} homogenous solution:
\begin{equation}
\begin{aligned}
\\
\lambda_1 &= 0\\
\\
\lambda_2 &=  - \left(b + c + d y_{2}\right)\\
\\
\end{aligned}
\begin{aligned}
v_1 &= \left(\begin{matrix}\frac{1}{b} \left(c + d y_{2}\right)\\1\end{matrix}\right)\\
v_2 &=  \left(\begin{matrix}-1\\1\end{matrix}\right)\\
\end{aligned}
\label{eq::modell6_eigenwerte_und_vektoren_spezialfall_1}
\end{equation}
 \begin{equation}
\textbf{x}_h = c_1 \textbf{v}_1 e^{\lambda_1t} + c_2 \textbf{v}_2 e^{\lambda_2t} 
\end{equation} And now I have a problem finding the particular solution.
I use the same approach 
\begin{equation}
x_p = \left(\begin{matrix}A_1\\A_2\end{matrix}\right) \quad \dot{\textbf{x}}_p = \hat{A} \textbf{x}_p + \textbf{b}
\end{equation}
which gives me the following set of equation
\begin{equation}
\begin{aligned}
\mathrm{I:} \quad\\
\mathrm{II:} \quad\\
\end{aligned}
\begin{aligned}
0 &=  -b A_1 + (d y_2 + c) A_2 + ax_0\\
0 &= b A_1 - (d y_2 + c) A_2 \\
\end{aligned}
\end{equation}
which gives the result $A_1 = \frac{d y_2 + c}{b} A_2$ if $ax_0 = 0$. Now I have a problem to interprete this solution because I didn't expected the condition $ax_0 = 0$ for my solution.
Is there only a solution of the system for $\left(d y_{2} - g x_{0}\right)$ if $ax_0 = 0$. Or is there a more general solution with $ax_0 \neq 0$?
Did I make a mistake during my calculation?",['ordinary-differential-equations']
2249954,Number of matrices,Find the number of $4 \times 4$ matrices such that its elements are $1$ and $-1$ and the sum of elements in each of its rows and columns is $0$. I am only able to make trivial progress that there are $6$ ways to  fill a row and $3$ ways to fill a column.I couldn't find a way to proceed further. Can this be generalised to a $n \times  n$ matrix under the same conditions?,"['matrices', 'combinatorics']"
2249959,Number of solutions of the diophantine equation $x_1 + x_2 + x_3 + x_4 + x_5 + x_6 = 14$,"I need to find how many solutions of the diophantine equation in the title of the question exist with two of the following conditions and am having major trouble: How many non-negative solutions it has so that all $x_i$ are even. How many non-negative solutions it has so that exactly one of the $x_i$ equals $0$. I used the repetitive combinations formula for the previous questions, but am stumped on how to precede here.","['diophantine-equations', 'linear-diophantine-equations', 'discrete-mathematics']"
2249987,Can I bring the variable of integration inside the integral?,"$\def\d{\mathrm{d}}$ My problem So I have coefficient of a certain general solution of a PDE that turns out to be $$A_n  =\frac{\displaystyle \int_{0}^1 g(x)J_0(\lambda_mx)x\,\d x}{\displaystyle \int_0^1J^2_0(\lambda_m x)x\,\d x}.$$
Now the book says that when we replace $f(x)$ by $1$ we should get $$A_n=\frac{2}{\lambda_n J_1(\lambda_n)},$$ however I couldn't get there so I thought that by plagging it in the solution $$Q(x,t)=\sum_{n=0}^\infty A_nJ_0(\lambda_n x)g(t),$$ where $g(t)$ is another function I just don't write. I could maybe bring the $J_0(x\lambda_n)$ inside the integral and use some sort of orthogonality or something else.","['real-analysis', 'integration', 'calculus']"
2249988,Closed form expressions for harmonic sums I.,"This question is a continuation of the topic in Closed form expressions for harmonic sums . By using the integral representation of harmonic numbers and by induction we have derived the following integral representation of an infinite harmonic sum. We have:
\begin{equation}
{\mathfrak S}^{(p)}_n(t):=\sum\limits_{m=0}^\infty H_m^p \cdot \frac{t^{m+1}}{(m+1)^n} = \int\limits_{[0,1]^p} \prod\limits_{\eta=0}^{p-1} \log\left(1-\xi_\eta\right) \cdot \frac{\left(\sum\limits_{l=0}^{p}(-1)^l \binom{p}{l} Li_{n-l}(t\prod\limits_{\eta=0}^{p-1} \xi_\eta )\right)}{\prod\limits_{\eta=0}^{p-1} \xi_\eta^2} \prod\limits_{\eta=0}^{p-1} d \xi_\eta
\end{equation}
Here $Li_n()$ are poly-logarithms, $p$ and $n$ are strictly positive integers and $t\in (-1,1)$. Now the question is how can we use the result above to calculate those sums at unity,i.e. how do we calculate ${\mathfrak S}^{(n)}_p(1)$ ? Does the result always depend only on certain values of the zeta function (as it does in case $p=1$ as shown in the question quoted above) or instead does it also depend on something else?","['sequences-and-series', 'discrete-mathematics']"
2250037,How to prove this integral $\iint_{D} \frac{\mathrm{d}\bar{z}\mathrm{d}z}{z-\zeta} = - 2{\pi}i{\bar{\zeta}} $,"I am reading this paper and there is an integral in it: $$\iint_{D} \frac{\mathrm{d}\bar{z}\mathrm{d}z}{z-\zeta} = - 2{\pi}i{\bar{\zeta}},$$ where $D$ is a disc of radius $R$ and $\zeta$ is a point in $D$. I write the left in definition. Let $\zeta = a+ i b$, then \begin{align*}\iint_{D} \frac{\mathrm{d}\bar{z}\mathrm{d}z}{z-\zeta} &=2i \iint_{D}\frac{\mathrm{d}x\mathrm{d}y}{(x+iy)-(a+ib)}  
\\&=2 \iint_{D}\frac{(y-b)\,\mathrm{d}x\mathrm{d}y}{(x-a)^2+(y-b)^2} +2i\iint_{D}\frac{(x-a)\,\mathrm{d}x\mathrm{d}y}{(x-a)^2+(y-b)^2},
\end{align*}
and it should be
$$\iint_{D}\frac{(x-a)\,\mathrm{d}x\mathrm{d}y}{(x-a)^2+(y-b)^2}=-{\pi}a.$$ Using polar coordinates and change variable to $t = \tan\frac{\theta}{2}$, \begin{align*}
&\mathrel{\phantom{=}}\iint_{D}\frac{(x-a)\,\mathrm{d}x\mathrm{d}y}{(x-a)^2+(y-b)^2}\\
&= \int^R_0\mathrm{d}r\int^{\pi}_{-\pi}\frac{r(r\cos\theta -a)}{(r\cos\theta-a)^2+(r\sin\theta - b)^2}\,\mathrm{d}\theta\\
&=\iint\frac{(r(\cos^2 \frac{\theta}{2}-\sin^2 \frac{\theta}{2})-a(\cos^2\frac{\theta}{2}+\sin^2\frac{\theta}{2}))\,\mathrm{d}\theta\mathrm{d}r}{(r^2+a^2+b^2)(\cos^2\frac{\theta}{2}+\sin^2\frac{\theta}{2})-2ra(\cos^2\frac{\theta}{2}-\sin^2\frac{\theta}{2}) -4rb\sin\frac{\theta}{2}\cos\frac{\theta}{2}}\\
&=\int^R_02r\,\mathrm{d}r\int^{+\infty}_{-\infty}\frac{r(1-t^2)-a(1+t^2)}{((r^2+a^2+b^2)(1+t^2)-2ra(1-t^2)-4rbt))(1+t^2)}\,\mathrm{d}t
\end{align*} and I don't know how to continue. Did I do something wrong? And I think the author use complex language for convenience. I calculate in real is the wrong way but I don't know how to do it in complex. Thank you!","['complex-analysis', 'integration']"
2250068,"How to evaluate this improper integral $\int_{0}^{\infty}\frac{1-x}{1-x^{n}}\,\mathrm dx$?","$\def\d{\mathrm{d}}$How to evaluate this improper integral? 
  $$\int_{0}^{\infty}\frac{1-x}{1-x^{n}}\,\d x.$$ What I tried is a substitution i.e $x^{n}=t$, but then things got complicated, and I'm stuck.","['improper-integrals', 'integration']"
2250109,Find the Maximum value of $\frac{x}{\sqrt{x+y}}+\frac{y}{\sqrt{y+z}}+\frac{z}{\sqrt{z+x}}$,"if $x$, $y$ and $z$ are positive real numbers such that $x+y+z=4$  Find the maximum value of $$S=\frac{x}{\sqrt{x+y}}+\frac{y}{\sqrt{y+z}}+\frac{z}{\sqrt{z+x}}$$ I tried as follows. The given expression can be rewritten as $$S=\sqrt{4-x}+\sqrt{4-y}+\sqrt{4-z}-\left(\frac{y}{\sqrt{x+y}}+\frac{z}{\sqrt{y+z}}+\frac{x}{\sqrt{z+x}}\right)$$ But by symmetry $$S=\left(\frac{y}{\sqrt{x+y}}+\frac{z}{\sqrt{y+z}}+\frac{x}{\sqrt{z+x}}\right)$$ so $$2S=\sqrt{4-x}+\sqrt{4-y}+\sqrt{4-z}$$  and by Cauchy Scwartz inequality $$2S \le \sqrt{4-x+4-y+4-z}\times \sqrt{3}$$ so $$2S \le \sqrt{24}$$ so $$S \le \sqrt{6}$$ Is this approach correct?","['inequality', 'optimization', 'cauchy-schwarz-inequality', 'algebra-precalculus', 'maxima-minima']"
2250122,Variance of Beta in the Normal Linear Regression Model,"Let $Y_1, Y_2, \ldots, Y_n$ represent response variables and let $x_1, x_2,\ldots, x_n$ be the associated explanatory variables. In the normal linear regression model, it's assumed that: $$Y_i \sim N(\alpha + \beta x_i, \sigma^2).$$ The maximum likelihood estimate for $\beta$ is $\hat \beta = \frac{S_{XY}}{S_{XX}}$ where $S_{XY} = \sum_{i=1}^{n} (x_i - \bar x )(Y_i - \bar Y)$ and $S_{XX} = \sum_{i=1}^{n} (x_i - \bar x )^2$. Clearly $\hat \beta$ is a normally distributed random variable (being a linear combination of normal random variables). I'm trying to show that it's variance is $\frac{\sigma^2}{S_{XX}}$ - but am really struggling. I would really appreciate any pointers, hints, or solutions. Thanks, Jack","['regression', 'statistics', 'linear-regression', 'statistical-inference']"
2250134,Gradient of distance function has modulus 1,"In this article of Wikipedia it is stated that, if $\Omega$ is a subset of $\mathbb{R}^n$ with smooth boundary, then $$f(x)=\begin{cases} d(x,\partial\Omega),\;\;x\in\Omega\\ -d(x,\partial\Omega),\;\;x\notin \Omega \end{cases}$$ satisfies $|\nabla f(x)|=1$ for all $x\in\mathbb{R}^n$. Could you give me an outline of the proof? I read an answer in this site solving in fact this question, but I do not understand it (maybe not enough details, maybe my level of geometry is not good...) Motivation: Coarea formula says that, if $g\in L^1(\Omega)$, $u\in C^1(\bar{\Omega})$ and $|\nabla u|>0$, then $\int_{\Omega} g\,dx=\int_{\mathbb{R}}\int_{\{u=\lambda\}} g/|\nabla u|\,d\sigma\,d\lambda$. In the particular case $u(x)=d(x,\partial\Omega)$, I read that $\int_{\Omega} g\,dx=\int_{\mathbb{R}}\int_{\{u=\lambda\}} g\,d\sigma\,d\lambda$.","['multivariable-calculus', 'differential-geometry']"
2250158,Find double derivative using implicit derivation - mulitvariable calculus,"Short question: $z(x,y)$ is a function that is implicitly defined by the equation $$4x+3y+5z+4\cos(4z)+3=0$$ in the neigbourhood of the point $p=(-5\pi/16, 1/3, \pi/4)$ I am going to calculate $\partial$ in $p$. $F$ differentiated with respect to $x$ is $4$ and with respect to $y$ is $3$. Differentiated with respect to $z$ is $5-16\sin(4z)$ Then we get $$\frac{\partial z}{\partial x}=-4/5$$ and $$\frac{\partial z}{\partial y}=-3/5 $$ by plugging in $z=\pi/4$ But now I don't know how to calculate $\frac{\partial^2z}{\partial x \partial y}$. Can somebody help me?","['multivariable-calculus', 'implicit-function-theorem', 'implicit-differentiation', 'derivatives']"
2250182,monotonicity of a univariate function,"I am considering the function
$$
f(x) = (a + e^x)^{-b} + (a + e^{-x})^{-b}
$$
where $a, b \in (0, \infty)$. What are the conditions on $a$ and $b$ that make $f(x)$ monotonic? Straightforward differentiation reduces it to showing that the transcendental equation
$$
{a y + y^2 \over a y + 1} = y^{2 \over 1 + b}
$$
has no solution on $(1, \infty)$. Any ideas? Thanks!","['real-analysis', 'monotone-functions', 'functions']"
2250218,Does $AA^T$ = I iff A is an orthogonal matrix?,"I know that if $A$ is an orthogonal matrix, then $AA^T = I$. However, is it possible to have a non orthogonal square matrix but $AA^T = I$ as well? A square matrix of size $n$ is orthogonal if the row spaces and column spaces form an orthogonal basis of ${\bf R} ^n$","['transpose', 'orthogonal-matrices', 'linear-algebra']"
2250230,"Solve the equation $\cos(x) + h\cos(hx) = 0$, where $h\in\mathbb{R}$",I have this equation: $$\cos(x) + h\cos(hx) = 0$$ where $h$ is a real constant. I want to find all $x$ for which this is true; but I don't know how to isolate $x$.,['trigonometry']
2250231,Six term exact sequence,"I'm trying to understand the proof of this corollary $5.4$ , but the proof itself is too short. It's based on theorem $5.1$ , which is: I'm trying to relate the $g$ from the corollary to the theorem. In the theorem, when $g$ is trivial, $f$ and $h$ are epimorphism and monomorphism. If at least $g$ were trivial, I'd have that it's at least an homomorphism. I'm trying to look the other way: supposing $f$ and $h$ are trivial, but then they're not mono neither epi, so this wouldn't help either... For $b\iff c$ , I think that $f$ and $h$ being trivial, then $\ker k = \{0\} \implies k$ mono. Now $f$ being trivial, $\ker f  = im d= 0$ , right? If the image is $0$ , how can it be epi? Something's wrong here.","['abstract-algebra', 'ring-theory', 'modules', 'exact-sequence']"
2250316,Proof by induction (summation formula),"I'm trying to prove by induction that: $\sum_{r=1}^{n} r^4 = \frac{1}{30}n(n+1)(2n+1)(3n^2+3n-1)$ This is how far I got: Let $n = 1$ $\sum_{r=1}^{n} r^4 = \frac{1}{30}(2)(3)(5) \implies 1 = 1$ End goal: $\sum_{r=1}^{k+1} r^4 = \frac{1}{30}(k+1)((k+1)+1)(2(k+1)+1)(3(k+1)^2+3(k+1)-1)$ So, $\sum_{r=1}^{k} r^4 + (k+1)^4 \\ = \frac{1}{30}k(k+1)(2k+1)(3k^2+3k-1) +(k+1)^4 \\ = \frac{1}{30}(k+1)[k(2k+1)(3k^2+3k-1) +30(k+1)^3]$ Now i'm stuck because I don't know where to go from here. I tried breaking all the brackets inside the big bracket but alas no luck in simplifying. Any help would be greatly appreciated. Thanks so much!","['induction', 'proof-writing', 'summation', 'discrete-mathematics']"
2250335,TDA - Persistence diagrams and Barcodes,"I am relatively new in the field of persistent homology and topological data analysis. I would like to use RIPSER, DIPHA or GUDHI to calculate barcodes which will give a persistence diagram. Here are my questions: 1.) How many data points are possible to analyze with such libraries with respect to an average computer? 2.) Which possible ways to analyze and compare two different persistence diagrams are there? For example I have heard of Wasserstein distance and bottleneck distance. Is there a library or software for analyzing two such diagrams? 3.) How can I interpretate persistence diagrams with many data points? I will get two different persistence diagrams, which should have no big differences. I would like to compare them and find the existing differences. EDIT: Ad question 1. The article ""A Roadmap for the Computation of Persistent Homology"" by Otter et al. gives an idea. The maximum size of the complex $K$ in the case of GUDHI and RIPSER is $3.4\cdot 10^9$, while the size of $K$ is $2^{\mathcal{O}(N)}$, where $N$ is the cardinality of the vertex set. They used in their experiments data sets up to $N=2000$. In the case of SimBa, data sets of $N\ge 250 000$ were used after some reduction by PCA (cf. ""SimBa: An Efficien Tool for Approximating Rips-filtration Persistence via Simplicial Batch-collapse"" by Dey, Shi and Wang). The size of the (sparsified VR) complex $K$, used by SimBa, is given by $\mathcal{O}(N)$.","['algebraic-topology', 'statistics', 'topological-data-analysis', 'homology-cohomology']"
2250336,Is low-rank factorization another name for low-rank approximation?,"I need to learn low-rank factorization and its application in machine learning and digital image processing. But I have two questions: Is low-rank factorization another name for low-rank approximation? If the answer is no, what is the main difference between them? Would you please introduce me several references from which I can learn low-rank factorization?","['matrices', 'reference-request', 'matrix-decomposition', 'linear-algebra']"
2250340,Why does the inverse of a mobius transform not get divided by the determinant?,for a mobius transform $\frac{az+b}{cz+d}$ it's inverse is given by $\frac{dw-b}{-cw+a}$ since this can be put into a matrix form why is there not a requirement for the inverse to be divided by the determinant?,"['complex-analysis', 'mobius-transformation']"
2250353,Placing m books on n shelves such that there is at least one book on each shelf,"Given $m \ge n \ge 1$, how many ways are there to place m books on n shelves, such that there is at least one book on each shelf? Placing the books on the shelves means that: • we specify for each book the shelf on which this book is placed, and • we specify for each shelf the order (left most, right most, or between other books) of the books that are
placed on that shelf. I solve this problem in the following way: If $m=n$, there are $m!$ or $n!$ ways to do it Else: Place $n$ books on $n$ shelves: $n!$ ways to do it Call the set of $m-n$ remaining books $T=\{t_1, t_2,..,t_{m-n}\}$ The procedure for placing books on shelves: choose a shelf, choose a position on the shelf We know choosing a shelf then place the book on the far left has $n$ ways For book $t_1$, there is a maximum of $1$ additional position (the far right). Thus there is $n+1$ ways to place book $t1$. For book $t2$, there is a maximum of $2$ additional positions. Thus there is $n+2$ ways for book $t_2$ ... For book $t_i$, there is a maximum of $i$ additional positions. Thus there is $n+i$ ways for book $t_i$ In placing $m-n$ books, we have $(n+1)(n+2)...(n+m-n)$ or $(n+1)(n+2)..m$ ways In total, we have $n!(n+1)(n+2)...m$ or $m!$ ways Is there any better solution to this problem?","['combinatorics', 'discrete-mathematics']"
2250408,What do I call a 2 dimensional surface bound by edges that are line segments or circular arcs?,"What do I call a 2d surface similar to a polygon, but more general in the sense that edges can be circular arcs as well? The generalized name should allow for: Arbitrary number of countable edges Edge lengths may vary Arcs and Lines can be used in any combination Surface may be concave",['geometry']
2250550,Partial fractions to find $A^n$,"I'm confused on how to evaluate the individual parts to get the values for $c_1, c_2$ Given the matrix $$A = \begin{bmatrix}2 & 3\\ 3 & 2 \end{bmatrix},$$ I know that $$\det(xI-A) = (x+1)(x-5).$$ Suppose $$\frac{x^n}{f(x)} = q(x)+\frac{c_1}{x+1}+\frac{c_2}{x-5},$$
the solution is shown as:
\begin{align*}
c_1 &= \left.\frac{x^n}{x-5}\right|_{x=-1} = \frac{1}{6} \cdot (-1)^{n+1},\\
c_2 &= \left.\frac{x^n}{x+1}\right|_{x=5} = \frac{1}{6} \cdot 5^{n}.
\end{align*} I'm not too sure why the first numerator goes to $(-1)^{n+1}$ and not just $(-1)^n$ so some clarification would be nice. Also if we had $(x-5)^2$ what would be the difference in evaluating that?","['matrices', 'linear-algebra']"
2250558,Recurrence relation in a Student Attendance problem,"I'm having trouble understanding the solution to a coding contest problem. Student Attendance Problem Suppose a student's attendance is recorded as a string, e.g. PPAPPPPLPPPLPPLLAPPPP where the letters represent Present, Late, and Absent. A reward is given to the student who satisfies the following criteria, No more than one absence. No triple consecutive lateness, e.g. LLL . Given an attendance record of length $n$ , then, how many rewardable records exist? For example, for $n=2$ , only AA fails to be rewarded, of $3^2$ possible strings, so the answer is $8$ . Official Solution The official solution attempts to build a recurrence relation, starting with this diagram: It explains: Let $f[n]$ represent the number of rewardable cases for a string of length $n$ . Let's divide into two cases, Strings ending with L . Strings ending with P . (I don't know why it says N in the diagram; typo, I think.) It's easy to see that the second case is rewardable as long as the piece preceding the P , $f[n-1]$ , is rewardable. However, the L case must be split into four pieces, as shown. There, the author claims that the only troublesome piece is the last, ending the string in LLL . His exact words are, Out of the four combinations possible at the end, the fourth combination, ending with a $LL$ at the end leads to an unrewardable string. But, since we've considered only rewardable strings of length $n-3$ , for the last string to be rewardable at length $n-3$ and unawardable at length $n-1$ , it must be preceded by a $PP$ before the $LL$ . Thus, accounting for the first string [left branch] again, all the rewardable strings of length $n-1$ , except the strings of length $n−4$ followed by $PLL$ , can contribute to a rewardable string of length $n$ . Thus, this string accounts for a factor of $f[n-1] - f[n-4]$ to $f[n]$ . Thus, the recurring relation becomes: $$f[n] = 2f[n-1] - f[n-4]$$ I was hoping someone could put this explanation in their own words, because I don't understand this author's. And he has made several typos in his explanation already, so I'm not sure I trust this explanation. Another thing I don't understand is why the first of the four cases isn't also problematic, since if the $n-5$ th and $n-4$ th characters were L , then we'd also have an unrewardable string. Any hints as to untangling the author's explanation would be appreciated. Thank you. P.S. The author is intentionally ignoring A at this stage, to be considered separately.","['combinatorics', 'recurrence-relations']"
2250577,What is meant by a mixed characteristic field?,"I noticed that in a lecture at the IHES , Peter Scholze seemed to refer to a ""mixed-characteristic field"". Now, I know what a mixed characteristic ring is – it's a ring $A$ such that the localizations at primes $\kappa(\mathfrak{p})$ vary from being characteristic $0$ to being characteristic $p>0$. However, with this definition, it makes no sense to talk about a ""mixed-characteristic field"". It seems like he is considering something of the sort $\mathbb{Q}_p(x)$ to be a mixed characteristic field, but I really can't see any intrinsic property of a field that fits the idea of ""mixed-characteristic"".","['abstract-algebra', 'field-theory']"
2250583,Are all solutions to an ordinary differential equation continuous solutions to the corresponding implied differential equation and vice versa? [duplicate],"This question already exists : Correlation between the weak solutions of a differential equation and implied differential equations Closed 6 years ago . Regarding the duplicate. Yes, I know the other one has a lot of shared text, but those were just definitions/setup and I was being lazy. The core questions are still different unless you believe derivatives are weak derivatives in which case you might need to read up on them. I don't know the exact definition, but I do know they aren't the same... Now I have to heavily emphasize the fact that I have never studied differential algebra or the concept of other types of differentiation (which is what I believe is the concept behind a differential algebra). So, if I am abusing the terminology a little bit, please forgive me. Let us define a differential algebra known as implied differentiation. It actually does not have a unique value. Let us denote the implied derivative operator as $I(f)$, where $f$ is any function being implied differentiated. This is of course, nonstandard terminology. We define the operator I to be $I(f)(x)(g)$ to be: $$I(f)(x)(g) := g(x) \left(\lim_{h\to 0^+} \frac{f(x+h)-f(x)}{h} \right) + (1-g(x)) \left(\lim_{h\to 0^-} \frac{f(x+h)-f(x)}{h} \right)$$ Where $g(x)$ is an arbitrary characteristic/indicator function. By this I mean that the evaluation of $I(f)$ at $x$ is either one of the one-sided limits and the choice of which one to pick comes from your particular choice of $g$. The general crux of this question is that I wish to determine whether or not the following statement is true. I'm pretty sure it is, though that's just intuition. Is a function a solution to an ordinary differential equation if and only if it is a continuous solution to the corresponding implied differential equation? By corresponding equations, I just mean that they are corresponding if they are the same except with all of the derivative operators replaced with the implied derivative operator. So, the equation $D(y) = e^x$ has a corresponding equation of $I(y) = e^x$. I do not know for sure whether or not anyone will actually be able to prove this statement. I think it is a bit tricky, but even just some advice on how to approach this or how to begin would be greatly appreciated. It isn't for homework or anything like that. It's just a statement and concept I've developed in my head over the years and I want to determine its truthfulness. Note: if something equivalent to this or very similar that just makes this a special case has been proven in the past feel free to use that as an answer. I'm going under the (possibly mistaken) impression that this hasn't actually been proven before. UPDATE: I believe that a possible route to proving this statement might come by proving the following propositions. The solution sets of sub-differential equations are a super set of the solution sets of the corresponding differential equations The solution sets of sub-differential equations are a super set of the solution sets of the corresponding implied differential equations If a solution to a sub-differential equation is continuous then it is a solution to the corresponding differential equation If a solution to a sub-differential equation is continuous then it is a solution to the corresponding implied differential equation I believe that the the first two propositions might follow trivially from the definition of the sub-derivative. The third one might have been proven in the past. I am unsure. The fourth one would then be the true meat and bones of the proof. The subderivative is defined here: https://en.wikipedia.org/wiki/Subderivative Reasons for wanting this statement proved: The implied differential operator is defined via the limits; however, the purpose of that is to emulate a differential algebra wherein all step functions have a derivative of 0 and all the other normal rules are preserved. If it wasn't apparent, because of this any implied differential equation involving step functions is trivial to solve (at least in terms of the step functions themselves providing difficulty). If the statement were true, it would provide a new avenue by which to attack differential equations, some of which might be made trivial to solve via this method.","['derivatives', 'ordinary-differential-equations', 'differential-algebra', 'limits']"
2250603,"Closed subspaces of $L^{\infty}[0,1]$","I would like to prove that $L^\infty[0,1]$ (bounded functions in $[0,1]$) has closed subspaces isomorphic to $c_0$ (space of sequences converging to zero). Do you have any ideas? Thanks in advance.","['functional-analysis', 'lp-spaces']"
2250604,Is there a better convolution method for deriving $\sum_{p\le x}\frac{1}{p}$ when $p$ is an almost prime?,"It's easy enough to derive an infinite sum for the logarithmic integral using the integral derived by Gauss through stepwise integration.  For example, in my review of calculus I found: $$ li(x) - li(b) = \int^x_b \frac{dt}{\log t} = \sum^{n}_{k=1}(k-1)!\bigg(\frac{x}{(\log x)^k} - \frac{b}{(\log b)^k}\bigg)$$ Further, G.J.O. Jameson makes the symbol $u_P$ for the characteristic function of primes, whereas Halmos might use the symbol $\chi_P$ for the function that is $1$ for primes and $0$ for composites (using Iverson brackets $[ p \in \mathbb{P} ]$ where Kowalski and Iwaniec use the double struck capital $\mathbb{P} \subset \mathbb{Z}^+$ to refer to the primes in positive integers.). Hardy and Wright only give an expression indicating that the series of inverse primes numbers is roughly asymptotic to the second nested logarithm.  Note that I'm not including error bounds. $$ \sum_{p\in {\mathbb{P}\cap [2,x]}} \frac{1}{p} \sim \log\log(x) - \log\log(2) + 1 $$ Because the Dirichlet convolution $u_P * u_P$ is the characteristic of the numbers with two prime divisors is it possible that there is a convolution operator for $li' \star li'$ since $u_P$ behaves like $\frac{1}{\log(x)}$ on average? I'm asking how to define the convolution operator ($\star$, see below).  I'm not really well versed, but it seems like there should be a smooth analogous operator to  the second Dirichlet Convolution of the characteristic function of primes constructed using logarithmic integral, such that $$ li'(x) = \frac{1}{\log x} \ , \ \ \ \ (li' \star li')(x) \sim \frac{x \log\log x }{\log x}$$ because Hardy/Wright makes it very clear that they mean the following $$ \frac{x \log \log x}{\log x} \sim li(x) \sum _{p\le x}{\frac{1}{p}}  $$ How do I find the operator$\ \star$ , where $$(li' \star li')(x) \sim li(x) \sum _{p\le x}{\frac{1}{p}}  $$ UPDATE There is this post on Math Overflow with answer by Lucia , but my study of the Zeta Function is only in an early stage -- I haven't much exposure to calculus in the complex space and I get easily lost with standard references on Sieve Theory.  H.E. Rose treats the topic in Chapter 3 of A Course on Number Theory and assigns the proof that $\sum_{p \le x}\frac{1}{p} \sim (\log \log x)^2 + O(\log\log x) $ for when $p$ is a semiprime as a problem. Answer this one for the bounty.","['number-theory', 'dirichlet-convolution', 'integration', 'convolution']"
2250613,What do you call a matrix that has at most one value in each row and each column?,"Is there a linear algebra terminology for matrices that are limited to at most one value in each row and column? For example:
This counts: $\pmatrix{0& 0 & 1 & 0\\ 0& 1& 0& 0 \\ 0& 0& 0& 1 \\ 1&0&0&0}$ While this is not: $\pmatrix{1& 0 & 0 & 0\\ 0& 1& 1& 1 \\ 1& 0& 0& 1 \\ 1&0&0&0}$ Thanks very much!","['matrices', 'linear-algebra', 'terminology']"
2250641,An object travelling on $x^2$,"I have an object traveling along the curve $y=x^2$. $z$ is the distance from the origin and $dz/{dt}=1$ is the rate it's increasing per unit time. At what rate are my $x$ and $y$'s moving at the point (2,4)? In other words what is $dy/dt$ and $dx/dt$. I've seen the geometry. Found $z$ as the hypotenuse of $x$ and $y$. Also, I infer that $dz=dt $ so they are interchangable. How do I solve this?","['algebra-precalculus', 'implicit-differentiation', 'calculus']"
2250665,"Quotient Rule, finding a special case",Quotient rule for functions is straightforward: $g(x)/h(x)$ Can I find a pair of functions not constant where the quotient of the derivative is the derivative of the quotient?,"['derivatives', 'ordinary-differential-equations', 'calculus']"
2250667,Prove that $\sum_{k=0}^\infty \cos(k^2t)$ diverges for all $t \geq 0$,"I think the series does not converge because the sequence $\cos(k^2t)$ doesn't converge to $0$. However, I cannot prove this last fact. I have tried looking for a subsequence of $k^2t$ such that for each $k$ there is an integer $z$ such that $z\pi-\frac{\pi}{4} \leq k^2t \leq z\pi+\frac{\pi}{4}$, but I haven't been able to show such a sequence exists. I have also tried some approaches using Chebyshev's formula, points in $\mathbb{R}^2$, and Taylor's expansion for $\cos(x)$, all unsuccessfuly.","['real-analysis', 'sequences-and-series']"
2250700,Constructing a Hamiltonian system with a given number of saddles and centers,"How can I construct a hamiltonian system with n saddles and 1 center? It is two dimensional system. I tried various polynomials, but none of it seemed to work. I always end up with at least two centers.",['ordinary-differential-equations']
2250716,Volume $2$ of Geometric Nonlinear Functional Analysis?,"Benyamini and Lindenstrauss published a book entitled 'Geometric Nonlinear Functional Analysis, Volume 1' in American Mathematical Society, Colloquium Publication. Since it is volume $1$, I believe it should have volume $2$, which is mentioned in the introduction of volume $1$. The authors even give an outline of what will be covered in volume $2$. However, I couldn't find volume 2 in AMS bookstore. I even googled the book online and it is nowhere to be found. Question: Does the author published volume $2$?","['functional-analysis', 'reference-request']"
2250734,Uniformly distributed points distance question,"$N$ points are placed randomly according to a uniform distribution in a $1 \times 1$ square. If $M$ is the number of points that have a distance more than $c/\sqrt{N}$ to others, then prove $\exists c,\alpha>0$ such that
  $$\lim\limits_{N\to \infty}\mathbb{P}(M>\alpha N)=1$$ Besides this question, please let me know if you can find the average of $M$. This is follow up question for this problem","['stochastic-processes', 'combinatorial-geometry', 'probability-theory', 'probability', 'combinatorics']"
2250739,An Intriguing Identity: $\cos(2x) \overset{?}{=} \log_{\cos(1)}\frac{\cos(\cos(x))}{\cos(\sin(x))}$,"I was playing around with Desmos and noticed that:
$$\cos(2x)=\log_{\cos(1)}\frac{\cos(\cos(x))}{\cos(\sin(x))}$$
I derived this from:
$$\int_{\cos(x)}^{\sin(x)} \tan(u)du$$
when I noticed it looked similar to a sine wave, $\ln(\cos(1))\cos(2x)$, did some algebra and came up with the identity. It seems to check out on a graphing calculator relatively well, except I have no idea why this works. This seems very intriguing to me because it includes nestled trig functions and the cosine of 1, which is very odd to equal a simple cosine function. If anybody can prove this, it could be interesting to see. I have a feeling this is slightly off, because of how much the complexities of the sides differ, so if anybody can disprove it, that would also be great. Thank you.","['logarithms', 'trigonometry', 'trigonometric-integrals', 'proof-verification']"
2250746,Reference for reading Dynkin diagrams in Lie theory?,"I have learned that given a Dynkin diagram corresponding to a Kac-Moody algebra, I should be able to use the diagram to read off the generators and relations of the Weyl group of that algebra. Each node should correspond to a generator of order 2, and the number of edges between nodes g and h (or a lack thereof) should tell me something about the order of gh. However, I can't seem to find a consistent answer about how to interpret the numbers of edges that I see. For example, Wikipedia has some edges marked with an infinity symbol, while Kac's Infinite Dimensional Lie Algebras doesn't seem to use this at all. I have come to the conclusion that maybe the conventions are different in Lie theory, but I'm not sure about this. If anyone can refer me to a book which explains how to use Dynkin diagrams to get the Weyl group, that would be amazing.","['dynkin-diagrams', 'group-theory', 'lie-algebras', 'coxeter-groups']"
2250753,Finding arrangements for DECIDED,"I am at a loss about how to do this How many ways are there to arrange the letters DECIDED so that at least one pair of
consecutive letters are the same (i.e. ‘3rd and 4th letter match’ or ‘5th and 6th letter
match’, etc.) I know that it would be 7!/3!2! for the total number of arrangements but that is over counting. I was thinking about doing there are 6 legal pairs (de ec ci id de ed) and therefore 6 spots. I was thinking of treating this like a married couple question. Pick one of the 6 pairs and lay it down in one of the six places. There is only 1 spot that is legal for it to go. Therefore there are five options for it to go somewhere else. I was thinking of using PIE to solve it Place one of the 6 pairs down in one of the 5 incorrect places, but then that would still be over counting which then it would 6 choose 2 and so on, but then I saw this wasnt going to work very well.","['combinations', 'combinatorics']"
2250763,Motivation for proof of Berry-Esséen Theorem,"The proof of the Berry-Esseen theorem found in Terence Tao's notes ( https://terrytao.wordpress.com/2010/01/05/254a-notes-2-the-central-limit-theorem/ , Theorem 37) starts by ""smoothing"" the cumulative distribution cutoff function, by convolving with a function whose fourier transform is compactly supported. First of all, what is the motivation for doing this? Secondly, why not smooth the function by convolving with a compactly supported test function instead? Any insights into the proof of Berry-Esseen would be appreciated.","['probability-theory', 'fourier-analysis', 'statistics']"
2250765,Two distinct tangents are drawn to cubic,"if from a point $(h,3-h)$ exactly two distinct tangents are drawn to $f(x)=x^3-9x^2-px+q$ find $p$ and $q$ Since two distinct tangents only are drawn Let them be $y=mx+c$ and $y=kx+c_1$ that is $$x^3-9x^2-px+q=mx+c$$ or $$x^3-9x^2-(p+m)x+q-c=0$$ and similarly $$x^3-9x^2-(p+k)x+q-c_1=0$$ so both these cubic should have double root... how to proceed further","['algebra-precalculus', 'polynomials', 'functions']"
2250790,show that $a^2-1$ is a quadratic nonresidue mod $p$ if and only if $p\equiv 6\pmod 7$,"Question : Let prime number $p>7$, for  positive integer $a,b,c$ such $1<a<b<c<p$, and
$$a+b+c\equiv a^3+b^3+c^3\equiv a^5+b^5+c^5\equiv\frac{p-1}{2}\pmod p$$ show that:
$a^2-1$ is a quadratic nonresidue mod $p$ if and only if $p\equiv 6\pmod 7$ I think following identity can work? $$a^3+b^3+c^3=(a+b+c)^3-3(a+b)(b+c)(c+a)$$
  and
  $$a^5+b^5+c^5=(a+b+c)^5-5(a+b)(b+c)(c+a)(a^2+b^2+c^2+ab+bc+ac)$$","['number-theory', 'contest-math']"
2250791,Generalizing Determinants Through Multilinear Algebra and Immanants,"Let $V$ and $W$ be $n$-dimensional vector spaces (over $\mathbb{C}$ say) and $A: V\to W$ a linear map. We define $\det(A):\bigwedge^nV\to \bigwedge^nW$ to be the map induced by $A$ on the exterior algebras. In the case $V=W$ then we have that $\det(A)$ is a scalar matching the traditional definition of a determinant. Naively, for a partition $\lambda$ of $n$ one is tempted to define the map $\det_{\lambda}(A): \mathbb{S}_\lambda(V)\to\mathbb{S}_\lambda(V)$ between the Schur functors of $V$ to be the map induced by $A$, which is not necessarily one-dimensional. However, we do have that $\det(A)=\det_{(1, \dots ,1)}(A)$. My first question is, is there any insight into these maps? Do they show up at all in the literature, or are they needless or ""incorrect"" generalizations? Since $\dim(\text{Sym}^n(V))\neq 1$ one immediate problem with this generalization is that it does not turn into the permanent by replacing the exterior powers with symmetric powers, regardless if we go so far as to use Schur functors or not. (Edit: But it is one-dimensional as a representation of $\mathfrak{S}_n$) Alternatively, there is the generalization of the determinant called the immanant given by
\begin{equation*}
\text{Imm}_{\lambda}(A)=\sum\limits_{\sigma\in\mathfrak{S}_n}\chi_{\lambda}(\sigma)a_{1\sigma(1)}\cdots a_{n\sigma(n)}
\end{equation*}
where $\chi_\lambda$ is the character of the irreducible representation of $\mathfrak{S}_n$ corresponding to the (conjugacy class corresponding to the) partition $\lambda$, which of course turns out to be $\mathbb{S}_\lambda(V)$. This definition is nice since for $\lambda=(1,\dots,1)$ it lines up with the determinant, and for $\lambda=(n)$ it lines up with the permanent. So my second question is, do these two generalizations line up somehow? Am I missing something where $\det_\lambda(A)$ turns into $\text{Imm}_\lambda(A)$ via the trace or something like this?","['abstract-algebra', 'multilinear-algebra', 'representation-theory', 'soft-question', 'linear-algebra']"
2250802,Truncated normal random variable [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Find the cdf and quantile function for the truncated (at a) normal random variable given that $$\frac{\varphi(x) I_{x>a}}{1-\Phi(a)}$$ where $\varphi(x)$ is the density for standard normal and $\Phi(x)$ is the cdf for standard normal distribution. Express answers in terms of $\varphi(x)$ and $\Phi(x)$. Appreciate your help, thank you!","['probability-theory', 'statistics']"
2250845,Hyperplane definition,"I am reading the Convex Optimization book from Stephen Boyd and I went back to hyperplane. I don't understand it's definition : A hyperplane is a set of the form $\{x ~|~a^Tx=b \},~a\in I\!R^n,~x \in I\!R^n,~ b \in I\!R$ Ok, why not. How can you get a plane from this ? If I refer to another definition of the hyperplane : Let $a_1,...,a_n$ be scalars not all equal to 0. Then the set S consisting of all vectors $\begin{align}
    X &= \begin{bmatrix}
           x_{1} \\
           x_{2} \\
           \vdots \\
           x_{n}
         \end{bmatrix}
  \end{align}$ in $I\!R^n$ such that $a_1x_1+...+a_nx_n = c$, for $c$ a constant, is a hyperplane. (I suppose that this is in fact a scalar product, or I don't get how you can have a constant). Comparing both definitions, I suppose that $a^Tx = b$ in Boyd is equivalent to $a_1x_1+...+a_nx_n = c$ in the other definition. But Boyd is also saying that $a$ is the normal vector of the hyperplane. How can $a$ be a normal vector if $a \in I\!R^n$ ? For example, if $a \in I\!R^2$, you will have $a = (x, y)$, where $x, y \in I\!R$, not $I\!R^2$. So how can you say that $a$ is a normal vector to the hyperplane if $a$ is only one point of $I\!R^n$ ? I am pretty sure I have misunderstand something, so if someone could explain it to me with a simple numercial example, it will be great. I will be able to answer to my questions after that. I am not able to find anything clear on the net about hyperplanes. Thanks a lot.","['convex-analysis', 'geometry']"
2250850,Find the locus of points $P$ such that $\Delta A_{1}B_{1}C_{1}\sim\Delta A_{2}B_{2}C_{2}$,"Let $ABC$ be an  triangle and let $P$ be a point in its interior. Let $A_1$, $B_1$, $C_1$ be projections of $P$ onto triangle sides $BC$, $CA$, $AB$, respectively. and $AP\cap BC=A_{2},BP\cap AC=B_{2},CP\cap AB=C_{2}$,Find the locus of points $P$ such that $\Delta A_{1}B_{1}C_{1}\sim\Delta A_{2}B_{2}C_{2}$ It is clear $P$ is orthocenter is hold,have other point?
 the simaler problem it help to solev Geomtry",['geometry']
2250861,Can separated schemes separate points.,"This question is related to a comment in Shafarevich's Basic Algebraic Geometry 2 . 
Shafarevich shows that the affine line with doubled origin is not separated by showing that the diagonal is not closed in the product $X\times_k X$. Moreover, he shows that a rational function which is regular at one origin is also regular at the other origin (which is equivalent to $\mathcal{O}_{X,x_0}=\mathcal{O}_{X,x_1}$). Then he says and I quote ""It can be shown that nonseparatedness is quite generally associated with this type of phenomenon"". So what is the general statement here. Naively one/I would think that he was saying something like this For an integral separated scheme $X$ and points $x,y\in X$ such that $x\neq y$, there exists $f,g\in K(X)$ such that $f\in \mathcal{O}_{X,x},g\in \mathcal{O}_{X,y}$ and $f\notin \mathcal{O}_{X,y},g\notin \mathcal{O}_{X,x}$. So what is it that Shafarevich was alluding to.",['algebraic-geometry']
2250918,Is it logically correct to differentiate and check continuity of derivative without knowing before hand if the function is differentiable or not?,"Suppose I want to check if a certain function is differentiable or not in a certain domain of $x$. For example, if $$f(x)=\int_{0}^{x} t \sin(\frac{1}{t})dt$$ in $(0,π)$ then is it okay to directly differentiate $f(x)$ and check if $f′(x)$ is continuous? Or it would be wrong to differentiate using Leibniz rule without knowing if $f(x)$ is differentiable ?","['derivatives', 'calculus']"
2250936,On reducing complex ODE's to Bessel's form using Kummer's series,"I am trying to reduce the following ODE to Bessel's ODE form and solve it:
$$x^{2}y''(x)+x(4x^{3}-3)y'(x)+(4x^{8}-5x^{2}+3)y(x)=0\tag{1} \, .$$ I tried to solve it via the standard method, i.e., by comparing it with a generalised ODE form and finding the solution from then on. The general form (as given in Mary L. Boas- Mathematical Methods in Physical Sciences ) is: $$y''(x)+\frac{1-2a}{x}y'(x)+\left((bcx^{c-1})^{2}+\frac{a^{2}-p^{2}c^{2}}{x^{2}}\right)y(x)=0\tag{2} \, ,$$
  and the solution:$$y(x)=x^{a}Z_{p}(bx^{c})\tag{3} \, .$$ But I am unable to get the answer via this method. The solution which is as follows:
$$y(x)=x^{2}e^{-\frac{x^{4}}{2}}[AI_{1}(\sqrt{5}x)+BK_{1}(\sqrt{5}x)]\tag{4}$$
Is obtained using comparison with another standard form which is given as follows: $$x^{2}y''(x)+x(a+2bx^{p})y'(x)+[c+dx^{2q}+b(a+p-1)x^{p}+b^{2}x^{2p})y(x)=0\tag{5} \, ,$$
  and the solution as:
  $$y(x)=x^{\alpha}e^{-\beta x^{p}}[AJ_{\nu}(\lambda x^{q})+BY_{\nu}(\lambda x^{q})]\tag{6} \, .$$ Where: $\alpha=\frac{1-a}{2}$, $\beta=\frac{b}{p}$, $\lambda=\frac{\sqrt{d}}{q}$, $\nu=\frac{\sqrt{(1-a)^{2}-4c)}}{2q}$ If I divide through the ode by $x^{2}$, I would get the Fuchasian form:
$$y''(x)+f(x)y'(x)+g(x)y(x)=0$$ The terms of $xf(x)$ and $x^{2}g(x)$ are expandable in convergent power series $\sum_{n=0}^{\infty}a_{n}x^{n}$, hence there exists a nonessential singularity at the origin.
But I am unable to solve via the Frobenius method. Hence, my question- How is the generalised form of equation $(5)$ arrived at and why can't I use $(2)$ instead?  Rather than bringing this ODE to a non-standard form as given in equation $(5)$, is there a way to derive the equation itself (and deduce the general solution)? Any help is appreciated. Edit: I found the following form in a book: $$x^{2}y''(x)+x(a+2bx^{p})y'(x)+[c+dx^{2q}+fx^{q}+b(a+p-1)x^{p}+b^{2}x^{2p})y(x)=0\tag{7} \, .$$ The only difference between the above and equation $(6)$ is the extra term:$fx^{q}$
Now if I substitute $y=we^{-\frac{bx^{p}}{p}}$ in equation $(7)$, it simplifies to the following linear equation: $$x^{2}w''(x)+axw'(x)+(dx^{2q}+fx^{q}+c)w(x)=0\tag{8}\,.$$ Now using the transformation $z=x^{q}$, and $y=wz^{k}$, where $k$ is the root of the following quadratic equation: $q^{2}k^{2}+q(a-1)k+c=0$; leads to a further simplified and linear form: $$q^{2}zy''(z)+[qbz+2kq^{2}+q(q-1+a)]y'(z)+(dz+kqb+f)y(z)=0\tag{9}\,.$$
  This equation has the solution: $y(x)=e^{kx}w(z)$, where $w(z)$ is the solution to the hypergeometric equation as given below Now, let a function $\Omega(b,a;x)$ be an arbitrary solution to the degenerate hypergeometric equation: $$xy''(x)+(a-x)y'(x)-by(x)=0\tag{10}\,.$$ And $Z_{\nu}(x)$ be an arbitrary solution of the Bessel equation.
Now in equation $(10)$, if $b\neq0,-1,-2,-3,...$, the solution is given by the Kummer's series as:
$$\Phi(b,a;x)=1+\sum_{k=1}^{\infty}\frac{(b)_{k}x^{k}}{(a)_{k}k!}$$
Where:$(b)_{k}=b(b+1)...(b+k-1)$
When $a$ is not an integer, the solution can be written as:
$$y=C_{1}\Phi(b,a;x)+C_{2}x^{1-a}\Phi(b-a+1,2-a;x)$$
Make the following replacements:
$b=2n$ and $a=n$
Now the series becomes: $$\Phi(n,2n;x)=\Gamma\left(n+\frac{1}{2}\right)e^{\frac{x}{2}}\left(\frac{x}{4}\right)^{(-n+\frac{1}{2})}I_{n-\frac{1}{2}}(\frac{x}{2})$$
  And
  $$\Phi(-n,-2n;x)=\frac{1}{\sqrt{\pi}}e^{\frac{x}{2}}\left(x\right)^{(-n+\frac{1}{2})}K_{n-\frac{1}{2}}(x)$$ Substituting the above in the solution of equation $(9)$, the general solution becomes:
$$y=e^{x(k+\frac{1}{2})}\left[C_{1}\Gamma\left(n+\frac{1}{2}\right)\left(\frac{x}{4}\right)^{(-n+\frac{1}{2})}I_{n+\frac{1}{2}}(x)+C_{2}\frac{1}{\sqrt{\pi}}\left(x\right)^{(-n+\frac{1}{2})}K_{n+\frac{1}{2}}(x)\right]$$
Which simplifies to: $$y(x)=\left(x\right)^{(-n+\frac{1}{2})}e^{x(k+\frac{1}{2})}\left[C_{1}\Gamma\left(n+\frac{1}{2}\right)\left(\frac{1}{4}\right)^{(-n+\frac{1}{2})}I_{n+\frac{1}{2}}(x)+C_{2}\frac{1}{\sqrt{\pi}}K_{n+\frac{1}{2}}(x)\right]$$ Which is the final solution. I tried to do the same for equation $(6)$, but did not get the solution. Any help is appreciated.","['bessel-functions', 'frobenius-method', 'hypergeometric-function', 'ordinary-differential-equations']"
2250967,Limit of trigonometric function $\lim_{x\to\pi/3} \frac{1 - 2\cos(x)}{\sin(x - \frac{\pi}{3})}$,"I want to compute this limit: $\displaystyle \lim_{x\to\pi/3} \frac{1 - 2\cos(x)}{\sin(x - \frac{\pi}{3})}$ Using L'Hopital, is easy to get the result, which is $\sqrt{3}$ I tried using linear approximation (making $u = x - \displaystyle \frac{\pi}{3}$) $\displaystyle \lim_{u\to 0} \frac{1 - 2\cos(u + \frac{\pi}{3})}{\sin(u)} = \lim_{u\to 0} \frac{1 - \cos(u) + \sqrt{3}\sin(u)}{u} \approx \lim_{u\to 0} \frac{1 - 1 + \sqrt{3}u}{u} = \sqrt{3}$ But it bothers me using that sort of linear approximation, I want to get the result in a more formal way. I have tried using double angle properties $$\cos(2x) = \cos^2(x) - \sin^2(x)$$
$$\sin(2x) = 2\sin(x)\cos(x)$$ But I reach to a point of nowhere, I cannot come up with a way of simplifying expressions to get the results: $\displaystyle\lim_{x\to\pi/3} 2\frac{3\sin^2(\frac{x}{2}) - \cos^2(\frac{x}{2})}{\sqrt{3}\sin(x) - \cos(x)}$ Is there a way of computing this limit without approximations and without L'Hopital?","['limits-without-lhopital', 'limits']"
2250983,Integral transform in finite range,"Fourier transform is an integral transform in infinite range, it can be used for solving constant coefficient linear differential equations defined in $(-\infty,+\infty)$. Laplace transform is an integral transform in semi-infinite range, it can be used for solving initial value problem (IVP) of constant coefficient linear differential equations defined in $[0,+\infty)$. Then does there exist integral transform(s) in finite range so I can use it for solving boundary value problem (BVP) of constant coefficient linear differential equations defined in e.g. $[a,b]$? To make the question more specific, can I solve the following BVP $$\frac{\partial ^2u(x,y)}{\partial x^2}+\frac{\partial ^2u(x,y)}{\partial y^2}=1$$
$$u(0,y)=0,\ u(1,y)=0$$ $$u(x,0)=0,\ u(x,2)=0$$ in $[0,1]×[0,2]$ with some kind of integral transform? (Yeah I don't want to use separation of variable. )","['integral-transforms', 'ordinary-differential-equations', 'partial-differential-equations']"
2250993,When the integral of products is the product of integrals.,"I'm self-studying and was doing the following integral: $$I = \int \frac{e^{\frac{1}{x}+\tan^{-1}x}}{x^2+x^4} dx $$ I solved it fine by letting $ u = \frac{1}{x} + \tan^{-1}x$. My question is about an alternative method I saw in which it seems the product rule was not applied: $$ I = \int \left(\frac { e^{\frac{1}{x}}} {x^2}\right) \left( \frac{e^{\tan^{-1}x}}{x^2+1}\right) dx $$ $$ = \int \frac {e^{\frac{1}{x}}}{x^2} dx \cdot \int \frac{e^{\tan^{-1}x}}{x^2+1}dx$$ Completing the work following this step leads to the same solution as I originally found. It is this step that has confused me. I have checked using Wolfram and the two statements are equivalent but I do not understand why. Why are we able to write the integral of products as the product of integrals here, and not apply the product rule? Thanks in advance.","['indefinite-integrals', 'integration', 'calculus']"
2251046,"How to show the following integral $\int_0^\frac{\pi}{2} \cot^{-1}{\sqrt{1+\csc{\theta}}}\,\mathrm d\theta =\frac{\pi^2}{12}$","This question was posted on I&S Prove the following $$\int_0^\frac{\pi}{2} \cot^{-1}{\sqrt{1+\csc{\theta}}}\,\mathrm d\theta
 =\frac{\pi^2}{12}$$ The numerical value of the integral seems to agree with the answer. Maybe someone could use that $$1+\csc \theta = \csc(\theta) (\cos(\theta/2) + \sin(\theta/2))^2$$ I am sure there is a smart substitution or some trigonometric properties that I fail to see.","['improper-integrals', 'integration', 'definite-integrals', 'calculus']"
2251115,bounded operator sends bounded set to bounded set,"How it follows from the title, the (supposet to be easy) exercise is to show that
$$\begin{Vmatrix} Tx\end{Vmatrix} \leq C \begin{Vmatrix} x\end{Vmatrix}\iff T\text{ sends bounded set to bounded set}$$ (we are talking about linear operator between normed spaces). Let $$A: = \{ y: \begin{Vmatrix} x - y\end{Vmatrix} \leq C_x \}$$ then $$ \begin{Vmatrix} Tx + Ty\end{Vmatrix} \leq \begin{Vmatrix} Tx\end{Vmatrix} + \begin{Vmatrix} Ty \end{Vmatrix} \leq C_1 \begin{Vmatrix} x \end{Vmatrix} + C_2 \begin{Vmatrix}  y\end{Vmatrix}$$ so the image  of $A$ is bounded. 
  Now I have a difficultes with the converse, it's the matter of notation, I'm sure it se more than easy using right notation.","['functional-analysis', 'operator-theory']"
2251116,Probability Distribution of a standard normal distribution with absolute value,"Z is a standard normal and we have to prove that \begin{equation} P(|z| \geq s) \leq {\sqrt{\frac{2}{\pi}}} {\frac{e^{\frac{-s^{2}}{2}}}{s}}\end{equation} As far as I understand I have to use the formula for distribution function of a standard normal random variable, but I do not know how to deal with the ≥ inequality in the probability function as I have only seen examples with the ≤  inequality.","['statistics', 'normal-distribution']"
2251130,Strengthening the notion of 'limit equivalence',"The notation $f \sim g$ is used to signify that two functions are asymptotically equivalent, either at $± \infty$ or near some real number $c$. For example, near $0$ we have $\sin x \sim x$. The formal definition is $$f \sim g \ \text{at} \ c \ \text{iff} \ \lim_{x \to c} \frac{f(x)}{g(x)} = 1$$ where $c \in \mathbb{R} \cup \{-\infty, +\infty\}$. However, this notion is somewhat imprecise, in my opinion. For 'equivalence' of functions, an important property we ought to have (in my opinion) is for any sufficiently well behaved (e.g., $C^{\infty}$ or even just $C^{1}$) function $h$, $f \sim g$ implies $h \circ f \sim h \circ g$. In other words, our notion of 'equivalence' should be such that composition should preserve 'equivalence'. However, this isn't necessarily true with the standard definition of equivalence. In particular, if $h$ varies or grows rapidly near $c$ (again, $|c|$ may be infinity), then the composition with $h$ may 'exacerbate' the otherwise small (relative) difference between $f$ and $g$. An example of this phenomenon is how $\sin x \sim x$ as $x \to 0$ but $$\lim_{x \to 0}\frac{\exp\left(-\exp\left(\frac{1}{(\sin x)^2}\right)\right)}{\exp\left(-\exp\left(\frac{1}{x^2}\right)\right)} = 0$$ Another example, this time as $x \to \infty$, is how $x^2 \sim x^2 + x$ but $\exp(x^2 + x)$ dominates $\exp(x^2)$. My question is, is there a stronger definition of 'asymptotic equivalence' which does not have this apparent weakness? In other words, can we strengthen the definition of $f \sim g$ such that $f \sim g$ implies $h \circ f \sim h \circ g$ for any smooth $h:\mathbb{R} \to \mathbb{R}$. It could be as strong as needed, but not so strong that the notion is rendered useless. For example, we could 'redefine' $f \sim g$ so that $f \sim g$ iff $f \equiv g$ in some neighbourhood of $c$ [or, in the case that $c=+\infty$ (resp. $-\infty$), for sufficiently large positive (resp. negative) $x$ we have $f \equiv g$] but this would be trivial and uninteresting. A valid answer to this question is that this is impossible. In other words, if $f$ and $g$ have the property that $f \sim g$ and $h \circ f \sim h \circ g$ for all smooth $h$, then $f \equiv g$ near $c$. Note that a related question is here .","['asymptotics', 'calculus']"
2251189,Snooker shot - does margin of error increase or decrease as the target angle increases?,"There is a perception (widely held) in snooker that a straight shot is more difficult than an angled shot. There are many forum discussion about this, and the reasons are usually accepted to be psychological. But I was wondering, is there a mathematical reason for it. Is the margin of error greater when the shot being taken is at an angle? Example - if the white ball was 1 degree off target on a straight shot, and one degree off target on an angled shot (same target for both shots), and each shot hit at the same speed, would the red ball travel off line to the same extent?",['geometry']
2251195,Completeness can be omitted from Banach Fixed Point Theorem?,"In Kreyszig's Functional Analysis, page no. 303, exercise no. 3 says that completeness cannot be omitted from Banach's Fixed Point Theorem. But if we take $f(x)=x^2$ from an incomplete metric space $(-1/3,1/3)$ to $(-1/3,1/3)$, here $f$ is a contraction and this $f$ has a unique fixed point $0$. Here I have omitted completeness but I am still getting a unique fixed point - where am I wrong? Banach's Fixed Point Theorem:
Consider a non-empty metric space $X = (X, d)$. Suppose that $X$ is
complete and let $T: X \to X$ be a contraction on $X$. Then $T$ has precisely
one fixed point.","['functional-analysis', 'real-analysis', 'metric-spaces', 'banach-fixed-point']"
2251229,Did Gauss and colleagues consider measuring the curvature of the universe?,"The interpretation usually given for Gauss' Theorema Egregium is that a being living on a surface with intrinsic curvature can detect that curvature just by walking around the surface and measuring angles and distances.  With the advent of general relativity many years later, it became evident that the our 3+1 dimensional universe need not be flat, and the Theorema Egregium is the basis for several experimental efforts to measure the curvature of the universe. Question: Did it ever occur to Gauss or other geometers of that era to measure the curvature of the universe? [ Bonus: If not, who was the first to propose that the universe might be curved?  Einstein?] I imagine there may have been a conceptual difficulty due to the fact that most differential geometry done in the early days was restricted to curves and surfaces, rather than 3-manifolds.  But even in lieu of the proper mathematical machinery, I imagine someone may have realized that an analogous sort of curvature to the Gauss curvature of surfaces should be available for 3D spaces.  Did anyone propose to measure such properties of space?","['math-history', 'differential-geometry', 'curvature', 'geometry']"
2251240,What is the first derivative and nth derivative of the following function $ y = \sqrt {2 +\sqrt {3 + \sqrt{x}}}$,"What is the first derivative and nth derivative of the following function $ y = \sqrt {2 +\sqrt {3 + \sqrt {x}}}$ I think taking the ln for both sides will remove the first square root only?
Could anyone give me a hint ?","['derivatives', 'calculus', 'analysis']"
2251270,"Let $X \sim N(0,1) $. Calculate the density function of $Y = \sqrt{\vert X \vert}$",Here is what I have done: $P(Y\le y) = P(\sqrt{\vert X \vert}\le y)=P(\vert X \vert \le y^2) =P(\pm X \le y^2)  $. $= P(x\le y^2) +P(-x \le y^2)=P(x \le y^2)+P(x\ge -y^2) = P(x\le y^2) +1-P(x\le -y^2)$ $ =2\phi(y^2)$. I am unable to get anywhere by this working. I think there has to be a better method. I am also unsure whether there is any error in the steps I have done. Any guidance is much appreciated,"['probability', 'probability-distributions']"
2251345,How many parties do I have to throw to detect potential couples?,"Given $n$ groups of people $P_1,\dots,P_n$. For simplicity assume that each group of people contains $k$ persons ($|P_i| = k$) and no person is in more than one group ($P_i \cap P_j = \emptyset$). Therefore we have $kn$ different persons. We would like to determine for each two persons from different groups whether they like each other. To do so we can throw a party and invite $n$ persons. Whenever two persons are at the same party we get to know whether they like each other. To make parties more interesting we decide that we always invite one person from each group. Since we have $n$ groups this means there will never be two persons from the same group at the same party. What is the minimal number $z$ of parties we have to throw in terms of $k$ and $n$ in order to answer this question? For example, if $n=k=2$ then $z=4$. Observe that there can be at most $k^n$ different parties (two parties are different if their guest lists are not identical) and therefore $z \leq k^n$. Also, we want to know $k^2 \cdot \binom{n}{2}$ bits of information and one party reveals at most $\binom{n}{2}$ bits. This means $k^2$ is a lower bound and therefore $k^2 \leq z \leq k^n$.","['combinatorics', 'graph-theory']"
2251351,"Where to start mathematics for Artificial Intelligence (Machine Learning, Probability, Robotics) [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 7 years ago . Improve this question A bit about myself: I am Dan. I am from the rural parts of Africa. I have no formal education what so ever (not even schooling) so please mind my English. I have moved to the great United States seven years ago. Currently I work as Software Engineer, I have self taught programming. My work is related to machine learning and making predictions on top of it. Having said that, I know the syntactical things, I heavily use scikit learn in python. But how algorithms work - I have no idea. I searched and asked around. People suggest a courses on Coursera / EDX. Those courses actually have a prerequisite. I do not understand their explanations. Somehow, those are not intuitive to me. I manage to complete the assignments as well with the help from forums and/or other co-students. At the end of it, I am still empty. One of my friend from (he is from India) told I need Mathematics. This is something I have heard a lot of times. While learning C programming, this came up. While learning numpy, scipy it came up. But if you ask me, it never stopped me from going ahead. As I understand correctly, for the mastery that I imagine, Maths is must. Hence, I started my research of where to start learning. And in short - I am way more confused than before beginning. Following are the paths I explored. People say Linear Algebra is must for Machine Learning. Whenever I pick up some highly recommended book, they have Calculus in it (most say it as a prerequisite). When I pick up Calculus books, they say Algebra is must. When I pick up algebra, they say basic familiarity to Calculus is must. I have no idea where to start. Since more than three months, I am moving from one source to another, and it does not seem to be going anywhere. I visited the a private college in my area. I visited the public libraries. I am talking to the so called experts in the field. People give me various suggestions: Start from Calculus Made Easy, by F.R.S. (1910 edition). As I started reading, the references given to 'officially called' are completely unknown to me. I google those -> keep on wandering Start from Mathematics for a Practicle Man, by George Howe. This is the only book I could keep up with, but only partially. I am having hard time what is going on once Geometry starts. My friend from India (He is an expert - PhD Machine Learning) suggested that I should start from Discrete Mathematics. He suggested two books Discrete Mathematics Proof, Structures and Applications, by Rowan Garnier and John Taylor and another one - Discrete Mathematics by Norman Biggs. I started reading the latter, but very difficult to follow the proofs. The math teacher at the private college then again suggested me that I must learn the proof systems. He suggested another book - How to prove it, by Danial Velleman. The fact that I never saw inside of any classroom is proving too costly for me. People on the internet (especially quora) are more vague. Someone says learn ""Metamathematics"" someone would say ""precalculus"", someone will say ""Predicate Logic is must"" and others outright deny me that I can learn now. My goal is very very clear. I want to learn Artificial Intelligence systems. In that, create a robot, put some intelligence on top of it. Other streams are quite easy to follow - especially Electronics, Operating Systems, Arduino. Can you guide me to learn Linear Algebra, Probability (may be statistics if this is different than Probability) and Calculus AFTER KNOWING THAT I KNOW ABSOLUTELY ZERO MATHEMATICS. Off course, I know the additions and multiplications, but the formal introduction to the things adds a lot of different perspectives to my brain. One, may be off topic from the main question, why almost every book focuses so much on the proofs? I initially think I would be interested in knowing the Whats' than Hows'. Just like a function in programming - input and output. Is this helpful to have this mindset? Why is pro's and cos's of knowing and not knowing the proofs? My friend pointed me to this site. He said mostly your question will be closed, as opinion based questions are not valid. My take is - Isn't there simple sequence of books? Why such a straight forward question should have different opinions? And if this question is not entertained, where should I asked? I am already out of resources as already told above. Edit I forgot to add. I cannot follow the formal path of schooling - undergrad - grad. I have people to feed. My job just makes us all survive. I like the idea of getting hold of their syllabus and doing it at night at home. But, the whole intention is to do specific study rather than generic. Further to this, if you think and believe it is best bet to start with school subjects, may I further ask - Are there public syllabus available? Or I need to travel to school? Again, I just hope there are no differences from one school to the other school. Otherwise I will be facing the same issue - which school syllabus to follow? Note: My friend has been kind enough to help me ask question correctly here.","['calculus', 'proof-verification', 'algebra-precalculus', 'probability', 'linear-algebra']"
2251364,Prove that $\Bbb{E}(|X-Y|) \le \Bbb{E}(|X+Y|)$ for i.i.d $X$ and $Y$,"Let $X$ and $Y$ be two independent identically distributed random
  variables with finite expectation $\Bbb{E}(X) = \Bbb{E}(Y) < \infty$. Prove that $$\Bbb{E}(|X-Y|) \le \Bbb{E}(|X+Y|)$$ I think that this inequality may follow somehow from Jensen's inequality , but I failed to use it here. Or maybe it is worth considering an expression $|x+y|-|x-y|$ and making use of some of its properties? I am interested to see a proof of this fact or some favorable ideas that may help here. Any suggestions would be greatly appreciated.","['probability-theory', 'inequality', 'expectation']"
2251374,Primes and square offsets,"For a prime $p$, define $\delta(p)$ to be the offset $d$, smallest
in absolute value, such that
$p \pm d = r^2$ for $d,r \in \mathbb{N}$. 
For example,
\begin{eqnarray}
\delta(11) & = & -2 \;:\; 11 -2 = 3^2 \\
\delta(29) & = & -4 \;:\; 29 - 4 = 5^2 \\
\delta(43) & = & 6 \;:\; 43 + 6 = 7^2 \\
\delta(191) & = & 5 \;:\; 191 + 5 = 14^2 
\end{eqnarray}
$\delta(p)$ is distributed as one might expect: For a particular $\delta=d$ value, define $\Delta(n,d)$ to be the number
of primes $p$ at most $n$ with $\delta(p) = +d$, minus the number with $\delta(p) = -d$. In other words, $\Delta$ records the cumulative prevalence of $+d$ over $-d$. For example, $\Delta(59,5)=1$ because there is one more $+5$ than $-5$ up to
$n=59$:
$$
\delta(31)=5 \;,\; \delta(41)=-5 \;,\; \delta(59)=5
$$
If one tracks out this $\Delta(n,5)$ bias for larger values of $n$,
by $n=44939$, $+5$ has occured $28$ times more than $-5$,
with little sign of becoming more balanced: Labels to the right are the $d$ values in $\Delta(n,d)$. Q .
  What explains these $\Delta(n,d)$ biases in favor of $+d$ over $-d$
  or the reverse? Can the $\pm$ bias be predicted for a given $d$?
  What is the growth rate of $\Delta(n,d)$?","['number-theory', 'prime-numbers']"
2251379,Is there a single symbol that represents plus-minus and includes the identity?,"Is there a single symbol that represents the set of $x\pm 1$ and $x$? Thus, if $x$ is 8, I'm looking for the most concise way to present the set of $\{7,8,9\}$. I apologize if this has been asked before; there are many questions on the plus-minus sign, but I couldn't find my answer elsewhere.",['elementary-set-theory']
2251412,"$p$ the smallest prime divisor of $|G|$ , $x\in G$ an element of order $p$ . Suppose $h\in G$ such that $hxh^{-1}=x^{10} $ . Show that $p=3 $ .","Let $G$ be a finite group , $p$ the smallest prime divisor of $|G|$ , $x\in G$ an element of order $p$ . Suppose $h\in G$ such that $hxh^{-1}=x^{10} $ . Show that $p=3 $ . My solution : let $|G|=d$ . Claim 1 : $(10, p)=1 $ . proof : Otherwise $p=2 $or $p=5 $  both of which contradict $hxh^{-1}=x^{10} $ . So $(10,p)=1$ . claim 2: $(d,p-1)=1 $ . proof : $(d,p-1)$ is not $1$ then it is divisible by a prime $q$ . So $q\leq p-1<p $ and $q|d $ . Hence contradicting the hypothesis  that $p$ is smallest a prime dividing $d$ . Back to the main proof : $x=h^d x h^{-d}= h^{d-1} x^{10} h^{-(d-1)} =..=x^{10^d}$ . So $ x^{10^d-1}=1$ . It gives $10^d=1(\mod p)$ . By claim 1 and Fermat's theorem $10^{p-1}=1 (\mod p)$ Now by claim 2 we have $s, t \in \mathbb{Z}$ such that $ds+(p-1)t=1 $ .
So $10=10^{ds+(p-1)t}=10^{ds}10^{(p-1)t}=1(\mod p)$ .So $p|9$ .But $p$ is prime . So $p=3 $ . QED . Please tell me if i'm missing out some cases or the solution is wrong .","['finite-groups', 'abstract-algebra', 'group-theory']"
2251495,Surjection of idèle class group onto class group of a number field $K$?,"EDIT : I learned with this question (and this observation answers it) that we can detect whether a fractional ideal is principal or not looking at its prime decomposition $\prod\mathfrak{p}^{v_\mathfrak{p}}$ and answering whether or not there is an element $a\in K^{\times}$ with $v_{\mathfrak{p}}(a)=v_{\mathfrak{p}}$ for all these $\mathfrak{p}$. If yes, then yes; If not, then no. I'm learning idèles through Neukirch's Algebraic Number Theory and got stuck in a claim. Let $I_{K}$ be the idèle group of $K$ and $J_{K}$ the group of fractional ideals of $K$. Let $(\:)\colon I_{K}\to J_{K}$ be the homomorphism taking an idèle $\alpha=(\alpha_{\mathfrak{p}})$ and gives the fractional ideal 
\begin{equation}
(\alpha)=\prod_{\mathfrak{p}\: \text{finite}}\mathfrak{p}^{v_{\mathfrak{p}}(\alpha_{\mathfrak{p}})}.
\end{equation}
It is obviously surjective and has kernel consisting of $I_{K}^{S_\infty}$, which is just the product of the various $\mathcal{O}_{\mathfrak{p}}^{\times}$, but with no restriction in the archimedean places. The claim is that this induces a surjective homomorphism $C_{K}\to C_{l_{K}}$, where $C_{K}=I_{K}/K^{\times}$ is the idèle class group of $K$ and $C_{l_{K}}$ is the usual class group of $K$. Now, how is this so? For this to be true we should have that the image of $K^{\times}$ via this map $(\:)$ is contained in the subgroup of principal ideals $P_{K}$ of $J_{K}$, but I don't think this is the case. I mean, for me is not obvious that we can detect whether or not some fractional ideal is principal only by looking at its prime decomposition. The equality $(\alpha)=\prod\mathfrak{p}^{v_{\mathfrak{p}}}$ seems like a definition, which may be taken also for elements of $\alpha\in K^{\times}$. While writing this question just now, I realized it could be that the above equality is a 'piece-wise' definition, considering the principal ideal in the case where the element belongs to $K^{\times}$, but then doesn't it becomes trickier and not so straightforward to show that it is a homomorphism? Thanks for any help.","['number-theory', 'class-field-theory', 'algebraic-number-theory']"
2251520,How are functions called which take arbitrary lists of numbers?,"Is there a name for functions like min , max , mean , sum which take $n$ numbers and maps them to one number? (In programming, they would probably be called variadic functions... I'm not too sure if this is the right term here)","['terminology', 'functions']"
2251543,Sum of infinite series $\sum_{n=50}^{\infty} \frac{1}{\binom{n}{50}}$,Find Sum of infinite series $$S=\sum_{n=50}^{\infty} \frac{1}{\binom{n}{50}}$$ My Try is : $$50S=\sum_{n=50}^{\infty} \frac{n-(n-50)}{\binom{n}{50}}$$ so $$50S=\sum_{n=50}^{\infty}\frac{n}{\binom{n}{50}}-\sum_{n=50}^{\infty}\frac{n-50}{\binom{n}{n-50}} $$ so $$50S=\sum_{n=50}^{\infty}\frac{n}{\binom{n}{50}}-\sum_{n=0}^{\infty}\frac{n}{{\binom{n+50}{50}}}$$ any clue further,"['combinatorics', 'binomial-coefficients']"
2251545,Notation for all sets with a given cardinality,"Is there a notation for the collection of all sets with cardinality $k$, for some integer $k$? This collection is not a set , but it is still a useful collection. For example, suppose this collection is denoted by $\mathcal{S}[k]$. Then, given a set-family $H$, we can write: $$H\cap \mathcal{S}[k]$$ to denote the elements of $H$ with cardinality $k$.","['notation', 'elementary-set-theory']"
2251555,Drawing approximated regular shapes on square grid,"I find myself often fooling around with pen and paper, preferably squared paper. So I began looking for ways to sketch geometric figures as precisely as possible without using compass and/or ruler. In particular I'm thinking of regular polygons and circles. I'm attaching a picture of my best findings, intentionally left handmade to show the kind of result I'm pursuing (following an answer I introduced a couple of digital adjustments). Explanations follow below. Let me start with regular polygons. The rule is simple: the vertices must lie at the grid crossings, that is their coordinates must be expressible as integer numbers. Apart from the square, it is not possible to get regular polygons with this restriction, so the intent is to obtain the closest approximations keeping the figures ""small"". I've explored different ways to quantitatively assess the ""precision"" of an approximation, starting from length uniformity of sides (satisfactory only for triangles) later combined with uniformity of angles, to the mean squared distance of vertices from the ideal ones not lying on the grid. I put no requirements about the center; should it happen to fall on or close to a crossing, even better. Moreover I tested different size factors to take into account the fact that getting better shape approximations with bigger figures is somewhat obvious and also less useful for sketching. Anyway I've found substantial agreement among different strategies. In fact, I didn't really find head-to-head confrontations whose ""winner"" depended on the scoring details, and even if I did I would have happily declared a tie and kept all the alternatives. So, the sheet of paper in the top-left corner of the figure collects my best results of this family. Next I'm relaxing the restriction: I'll let the vertices fall also on the middle points of the sides of paper squares. These can be located with satisfactory precision by eye, instead I'm not going to allow center points of paper squares. This new rule is equivalent to halving all the coordinates of a valid previous solution, provided that no point had both coordinates odd (one can horizontally and/or vertically translate the original figure by $1$ before attempting the division). I might also add that I don't like to see a line running parallel to the grid cutting squares in halves, but it's just a matter of taste. Obviously, at comparable dimensions, better approximations can be found with this additional freedom, and my best findings are represented in the top-right corner. I shall proceed to circles. They are different, in that they do not have a limited number of vertices and one can look for support points –that now can belong to the circle and lie exactly at grid intersections at the same time– with no a priori restrictions of position and amount. So the goal becomes to find as many of them, and as evenly distributed, as possible. Again I'm trying to keep the circles small, with similar considerations as before about loss of interest as size grows. With this in mind, my best circles are depicted in the bottom-left corner. Finally, again I soften the rules: support points on the grid can be approximations of exact circle points and/or they can be placed on middle points of square sides. My best findings of this kind are those in the bottom-right corner. I couldn't find any serious dissertation on this (indeed trivial) argument, the most closely related argument being this: Circle Lattice Points .
Is anyone aware of others? Or is anybody willing to find themselves other similar (or better, under any respect) figures? EDIT: I don't want to seem ungrateful to those who took care of my question, but I still haven't received the answer I was hoping for. The fact is that I'm looking for a way to discover whether I have ""missed"" some interesting figures in the described context. I exploited my (limited) programming skills to perform some automated searches, but I'm not sure that my algorithms guarantee not to miss any good solutions. I can describe and discuss these too, but I'd prefer to leave everyone free to use their original approach. Another chance would be to find some reference covering the topic, but I'm afraid that this is really too ""recreational"" to be dealt with in literature. Maybe something on the Internet? Someone who has done anything similar before me? I'm starting a bounty to find out! Thanks in advance!","['circles', 'polygons', 'diophantine-approximation', 'geometry', 'recreational-mathematics']"
2251570,Probability of original signal,"Signal which can be green or red with probability $4/5$ and $1/5$ respectively, is received by
station A and then transmitted to station B. The probability of each station receiving the signal
correctly $3/4$. If the Signal received at station B is green, then the probability that the original
signal was green is In this I think we have to use Bayes' theorem . but could not able to apply it .","['probability-theory', 'probability']"
2251616,Chess board probability problem.,"Three random squares are chosen from a regular chess board. Find the probability that they form the letter 'L'.
I cannot think about a general way to go about these type of questions. Need hints or solutions.","['combinatorics', 'probability']"
2251651,Double integral - transformation,"I'm trying to calculate $$\iint_{\Omega } e^{(x+y^2)^{3/2}} \,\mathrm{d}A,$$ where $$\Omega =\{x,y>0 : x+y\leq 2\}. $$ 
Not sure where to go with it. I need to find a transformation and then calculate the integral. Any pointers?","['multivariable-calculus', 'integration', 'definite-integrals']"
2251679,"Reference Request: A Tychonoff space $X$ where the game $\mathrm{G}_1(\Omega,\Omega)$ is undetermined","Given a Tychonoff space $X$, let $\Omega$ be the set of all $\omega$-coverings of $X$, where by $\omega$-cover we mean a collection $\mathcal{U}$ of open sets of $X$ such that for any $F\in[X]^{<\omega}$ there exists $U\in\mathcal{U}$ such that $F\subset U$. Now, let G$_1(\Omega,\Omega)$ be the game between Player I and Player II defined as follows: for every inning $n<\omega$, the Player I chooses an $\omega$-cover $\mathcal{U}_n$, and then Player II picks $U_n\in\mathcal{U}_n$; Player II wins iff $\{U_n:n\in\omega\}\in\Omega$. Clearly, if the Player II has a winning strategy in the game $\mathrm{G}_1(\Omega,\Omega)$, then the Player I does not have a winning strategy in the same game. I would like to know any references with examples of spaces where the game $\mathrm{G}_1(\Omega,\Omega)$ is undetermined, i.e., such that both players do not have winning strategies in the game $\mathrm{G}_1(\Omega,\Omega)$.","['general-topology', 'infinite-games', 'infinitary-combinatorics', 'combinatorial-game-theory']"
2251710,existence of closest point on boundary of domain to a point outside domain,"Let $D \subset \mathbb{R}^n$ (or $\mathbb{C}^n$) be a domain with $C^2$ boundary.  Why is there a neighborhood U of $\partial D$ such that for every $z \in U$, there is a unique point of $\partial D$ that is closest to $z$?","['differential-geometry', 'calculus', 'geometry']"
2251749,Limit superior from VJIMC 2016 T-shirt,"Previous year on VJIMC competition we got T-shirts with following problem Define $$f(\alpha):=\limsup\limits_{n\to\infty,\,n\in\mathbb{N}}(\sin(n))^{n^\alpha}.$$ Find $f(1)$ and $f(2)$. I found some topics dealing with $$\lim_{n\to\infty}(\sin(n))^n,$$ but that wasn't much helpful (or I just overlooked important parts). Any advice how to solve it?
Thx.","['contest-math', 'real-analysis', 'limsup-and-liminf', 'limits']"
2251798,Determining whether a vector field is conservative,"For a vector field $\vec{F}(x,y,z) = \langle F_1(x,y,z), F_2(x,y,z), F_3(x,y,z) \rangle$ in $\mathbb{R}^3$, how can I use mixed second-order partial derivatives of each of the components to determine whether it is conservative? Which partial derivatives should I compare?","['multivariable-calculus', 'vector-analysis']"
2251824,"An analysis proposition, true or false?","Suppose $(X,d)$ is a metric topological space with $|X|>=\aleph$ (Topological spaces such as $\mathbb{Q}$ , $\mathbb{Z}$ should not be considered). Prove or disprove:
If for every uncountable subset $S \subseteq X$ , $\mathop{\inf}\limits_{x \neq y,{x,y\in S}}d(x,y)=0$ , then $X$ satisfies $C_2$ axiom (or $X$ is separable since such two conceptions are equivalent when $X$ is a metric space).(*) Below is the remark: I want to verify it because its converse proposition is true. If an uncountable subset $S \subseteq X$ such that $\mathop{\inf}\limits_{x \neq y,{x,y\in S}}d(x,y)>0$ , then $X$ must not be $C_2$ . A typical example is $l_{\infty}$ , which is formed by bounded series. The subset $Binary$ which is formed by infinite $0-1$ strings is uncountable, and $\mathop{\inf}\limits_{x \neq y,{x,y\in Binary}}d(x,y)=1$ (here distance is induced by $l_{\infty}$ norm), and $l_{\infty}$ is not separable and not a $C_2$ space. To prove its converse proposition, we notice that： $X$ is a metric topological space $\rightarrow$ ( $X$ is $C_2$ $\leftrightarrow X$ is separable) is always true. So we only need to prove $X$ is not seperable. Suppose $S$ is an uncountable set and $m=\mathop{\inf}\limits_{x \neq y,{x,y\in S}}d(x,y)>0$ . We can pick neighborhoods $N=\{x \in S|B(x,\frac{m}{3})\}$ , those neighborhoods in $N$ do not intersect with each other so $N$ is uncountable. If $A$ is dense in $X$ , we assert that every neighborhood in $N$ contains at least one point in $A$ , so $|A| \geq |N|$ and $A$ can not be countable. I really appreciate your help if you prove or disprove (*). If you can prove it in some special cases, I will also thank you for your help.","['general-topology', 'real-analysis']"
2251863,Why define three elementary row operations? When one of them can be performed by the others?,"I'm learning about linear algebra and in the course we've defined three ""elementary row operations"" $$(1) \text{ Switching any two rows}$$
$$(2) \text{ Non-Zero scaling of any row}$$
$$(3) \text{ Adding a multiple of one row to a different row}$$ However it seems all these operations can be performed by the two simpler operations: $$(1) \text{ Non-Zero scaling of any row}$$
$$(2) \text{ Adding any two rows}$$ I mean why even have switching rows as an operation in the first place when it can be performed by the addition and scaling of rows? It just seems redundant, why add an extra operation that can already be performed by the other operations? Edit: Because someone in the comments asked how the swapping of rows could be performed with just non-zero scaling and adding rows. If you wanted to swap, say row $p$ with row $q$ you would: $$(1) \text{ Add row } q \text{ to row } p$$
$$(2) \text{ Multiply row } p \text{ by } -1$$
$$(3) \text{ Add row } p \text{ to row } q$$
$$(4) \text{ Multiply row } q \text{ by } -1$$
$$(5) \text{ Add row } q \text{ to row } p$$
$$(6) \text{ Multiply row } p \text{ by } -1$$",['linear-algebra']
2251877,Theorem 5.8 in Baby Rudin: Does the function have to be defined at the endpoints as well?,"Here is Theorem 5.8 in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: Let $f$ be defined on $[a, b]$; if $f$ has a local maximum at a point $x \in (a, b)$, and if $f^\prime(x)$ exists, then $f^\prime(x)=0$. The analogous statement for local minima is of course also true. And, here is Rudin's proof: Choose $\delta$ in accordance with Definition 5.7, so that $$ a < x-\delta < x < x+\delta < b.$$
  If $x-\delta < t < x$, then $$\frac{ f(t)-f(x)}{t-x} \geq 0.$$
  Letting $t \to x$, we see that $f^\prime(x) \geq 0$. If $x < t < x+\delta$, then $$ \frac{ f(t) - f(x) }{ t-x} \leq 0,$$
  which shows that $f^\prime(x) \leq 0$. Hence $f^\prime(x) = 0$. And, here is Definition 5.7 in Baby Rudin: Let $f$ be a real function defined on a metric space $X$. We say that $f$ has a local maximum at a point $p \in X$ if there exists $\delta > 0$ such that $f(q) \leq f(p)$ for all $q \in X$ with $d(p, q) < \delta$. Local minima are defined likewise. Now my question is, in Theorem 5.8, do we have to assume that the function $f$ is defined at the endpoints $a$ and $b$ as well? Or, is it sufficient for $f$ to be defined only in the segment $(a, b)$?","['derivatives', 'real-analysis', 'optimization', 'calculus', 'analysis']"
2251906,Differential equations solving,"The number of organisms in a population at time t is denoted by x. Treating x as a continuous variable, the differential equation satisfied by x and t is $$\frac{dx}{dt} = \frac {xe^{-t}}{k + e^{-t}}$$ where k is  a positive constant. $i)$ Given that x = 10 when t = 0, solve the differential equation, obtaining a relation between x, k and t. I'm mainly stuck in getting the $x$ to one side and $t$ on another, if you could help me there I think I can do the rest of the question.",['ordinary-differential-equations']
2251981,"If a roulette wheel receives $100$ spins per evening, what is the chance that $5$ consecutive reds will occur sometime during the evening?'","In roulette, there are $38$ slots the ball can fall into. $18$ are red, $18$ are black, and $2$ are green. If a roulette wheel receives $100$ spins per evening, what is the chance that $5$ consecutive reds will occur sometime during the evening?' Attempted Solution: I used the formula provided by Byron here: Probability for the length of the longest run in $n$ Bernoulli trials . I found that the probability is $.7295$. Intuitively, it sounds like this makes sense. However, I calculated this in excel, and excel stopped being able to compute the combinatorial portion of the formula due to extremely small values. For this reason I neglected those particular values. In order to make sure I answered this correctly, I was hoping someone knew another way to solve this, whether it be a programming language you know or if you know how to run a Monte Carlo simulation in excel. Neither of which I know how to do. Any help would be much appreciated.","['monte-carlo', 'statistics', 'probability']"
2251993,Reverse lookup: decimal to irrational,"Is there an online resource that lists irrationals close to given a decimal? For example, if $x=0.3740049$, a candidate solution would be $x_c = \left ( \frac{1+\sqrt{5}}{2} \right ) ^2 /7$. This would be something akin to the OEIS (Online Encyclopedia of Integer Sequences), which is a reverse lookup for integer sequences and various properties about them. While there are an infinite number of irrationals over any fixed range, a list of ""simple"" (operation depth, low coefficients, etc...) would be very useful.","['integers', 'sequences-and-series', 'irrational-numbers', 'approximation']"
2252016,Mathematical function that converges towards $7$?,"My friends and I are finishing High School in Denmark. We have to do a math poster for some school activity, where the poster needs to have something to do with the number $7$. So my question is: does someone know a cool mathematical function that converges towards $7$? 
We covered Calculus III, so we should be able to understand a little math!",['calculus']
2252021,A morphism of free modules that is an isomorphism upon dualization.,"Let $R$ be a commutative ring and let $M,N$ be free modules over $R$ and suppose we have a map $f: M \rightarrow N$ such that upon taking $\text{ Hom}(-,R)$ we get an isomorphism $f^* : N^* \rightarrow M^*.$ Must $f$ be an isomorphism as well? This is clear if $M,N$ are free and of finite dimension, since then double dualization can be applied. But in general, what is true? Edit. In the comments egreg has sketched an example which seems fine. This seems to involve cardinality issues, so what happens if I assume that $M$ and $N$ are both countably generated?","['abstract-algebra', 'modules', 'free-modules', 'commutative-algebra']"
2252022,$\lim_{x \to 0} \frac{\log \left(\cosh\left(x^2-xc\right) \right)}{x^2}=\frac{c^2}{2}$ without L'Hospital's rule,"How to show that without using L'Hospital's rule
\begin{align}
\lim_{x \to 0}  \frac{\log \left(\cosh\left(x^2-xc\right) \right)}{x^2}=\frac{c^2}{2}
\end{align} I was able to show the upper bound by using the bound $\cosh(x) \le e^{x^2/2}$
\begin{align}
\lim_{x \to 0} \frac{\log \left(\cosh\left(x^2-xc\right) \right)}{x^2} \le \lim_{x \to 0} \frac{\left(x^2-xc\right)^2}{2x^2}=\frac{c^2}{2}
\end{align} My question: How finish this argument.","['limits-without-lhopital', 'calculus', 'limits']"
2252072,Can anyone point me to a reference where the following is explained?,"I have got the following line from the Wikipedia cantor set: https://en.wikipedia.org/wiki/Cantor_set ""It can also be shown that the Haar measure is an image of any probability, making the Cantor set a universal probability space in some ways."" Can anyone show or refer to material where it is explained?","['functional-analysis', 'probability-theory', 'set-theory', 'soft-question']"
2252090,Sum of the zeroes of $x^4-7x^3+2x^2+5x-1=0$,"Someone posed this question to me on a forum, and I have yet to figure it out. If $a,b,c,d$ are the zeroes of: $$x^4-7x^3+2x^2+5x-1=0$$
Then what is the value of $$ \frac1a +\frac1b +\frac1c +\frac1d $$ I can figure out the zeroes, but they are wildly complex. I'm sure there must be an easier way.","['algebra-precalculus', 'polynomials', 'calculus']"
2252163,Doob–Dynkin lemma proof,"I have to prove the following lemma: Let $X:\Omega\to E$ be a r.v., $\sigma(X)$ the $\sigma$-algebra generated from $X$. For every $Y:\Omega\to \mathbf{R}$ ($\sigma(X)$-measurable) it exists $g:E\to \mathbf{R}$ measurable such that $Y=g\circ X $. The proof I read proves the lemma first for indicator functions, then for simple functions, then for a positive r.v $Y$ considering a sequence $(Y_n)$ of simple functions which converges increasing to $Y$. For each $n$ we could find a function $g_n$ that verifies the lemma. Unfortunately we cannot assume that the sequence $(g_n)$ is increasing but we have:
$$Y=\sup_n(Y_n)=\sup_n(g_n\circ X)=\limsup_n(g_n\circ X)=\limsup_n(g_n)\circ X.$$ At this point, my question is: why have we to pass to limsup? Is it not true that $\sup_n(g_n\circ X)=\sup_n(g_n)\circ X$ and that $\sup_n(g_n)$ is measurable?","['supremum-and-infimum', 'limsup-and-liminf', 'measure-theory', 'random-variables']"
2252186,"$ \lim_{ \|x\| \to 0 } \frac{E \left[ \log \left(1+ \left(\|x\|^2+ \langle x,Z \rangle \right)^2 \right) \right]}{\| x\|^2} = 1$","How to compute the limit
\begin{align}
\lim_{ \|x\| \to 0 } \frac{E \left[ \log \left(1+ \left(\|x\|^2+ \langle x,Z \rangle \right)^2 \right) \right]}{\| x\|^2} 
\end{align}
where $Z$ is i.i.d. Gaussian vector of lenght $n$. Upper bound: \begin{align}
\lim_{ \|x\| \to 0 } \frac{E \left[ \log \left(1+ \left(\|x\|^2+ \langle x,Z \rangle \right)^2 \right) \right]}{\| x\|^2}   \le  \lim_{ \|x\| \to 0 } \frac{E \left[  \left(\|x\|^2+ \langle x,Z \rangle \right)^2  \right]}{\| x\|^2} 
\end{align} here we used that $\log(x) \le x-1$ Next, observe that
\begin{align}
E[\langle x, Z \rangle]=0,\\ 
E[\langle x, Z \rangle^2 ]= \|x\|^2
\end{align}
where the last two stament follow from i.i.d. assumption. So, in conclusion, we have \begin{align}
\lim_{ \|x\| \to 0 } \frac{E \left[ \log \left(1+ \left(\|x\|^2+ \langle x,Z \rangle \right)^2 \right) \right]}{\| x\|^2}   \le  1.
\end{align} I am stuck with showing the other direction. For the lower bound one can use $\log(1+x) \ge \frac{x}{x+1}$ which result in 
\begin{align}
 \lim_{ \|x\| \to 0}\frac{1}{\|x\|}E \left[ \frac{\left(\|x\|^2+ \langle x,Z \rangle \right)^2 }{1+\left(\|x\|^2+ \langle x,Z \rangle \right)^2  } \right]
\end{align} However, not sure how to proceed next.","['probability-theory', 'probability', 'expectation']"
