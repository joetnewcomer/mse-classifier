question_id,title,body,tags
2465902,"If the image of an orthonormal basis is bounded, is the linear operator also bounded?","I am looking to either prove or disprove that if a linear operator is bounded on an orthonormal basis of a (separable) Hilbert space, the operator is itself bounded. Expanding each $x$ according to the orthonormal basis $\left\{e_{j}\right\}$ and using $\left\|Te_j \right\| \leq K, \forall j \in \mathbb{N} $  what I have got so far is \begin{align} \left\|Tx \right\|^2 = \left\| \sum_{i=1}^\infty \langle x,e_i \rangle Te_i \right\|^2 &= \sum_{i=1}^\infty \sum_{j=1}^\infty \langle x,e_j \rangle  \langle x,e_j \rangle \langle Te_i, Te_j \rangle \\ &\leq K^2 \left( \sum_{i=1}^\infty \langle x, e_i \rangle \right)^2  \end{align} but we would like to have is $\left\|T_x \right\|^2 \leq C \left\|x\right|^2$, where $\left\| x \right\|^2 = \sum_{i=1}^\infty | \langle x, e_i \rangle|^2 $ by Bessel's equality. I'm wondering then, is there another way to prove the statement or is it perhaps that the statement is untrue? Thank you in advance.","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
2465909,Calculating residue of $f(z) = \frac{(z^2 - 1)^4}{z^5}$ at $z=0$,"Calculate the residue of  $$f(z) = \frac{(z^2 - 1)^4}{z^5}$$ in $z = 0$ I let $g(z) = (z^2 - 1)^4.$ I'm using a theorem which states: Suppose $g$ is holomorphic around $z = \alpha$ and that $N$ is a
  positive integer, then $$RES_{z=\alpha}\frac{g(z)}{(z-\alpha)^N} =
 \frac{g^{(N-1)}(\alpha)}{(N-1)!}$$ and I get the correct answer (since $g(z) / (z-0)^5 = f(z))$, however, it is really annoying to have to differentiate that many times. Is there a smarter method?","['complex-analysis', 'residue-calculus']"
2465947,Does the existence of the Levi-Civita connection depend on whether or not we define a metric on our smooth manifold?,"The Christoffel symbols of the Levi-Civita connection are calculated through the metric, but does that necessarily mean that its existence depends on whether or not we have a metric? Specifically, the Levi-Civita connection offers a specific way to parallel transport a vector along a manifold, so if we don't have a metric on a manifold, does this particular way to parallel transport a vector along the manifold gets ""lost""? I mean, of course we need the metric to determine the Levi-Civita connection, but as a geometrical concept, it seems intuitive to me that as a way to transport vectors, its existence should not depend on whether on not we defined a metric on our manifold. Note that this question is motivated by the fact that we define connections before even talking about a metric. But in my Riemannian geometry course, we defined the Levi-Civita connection through the metric, but I wanted to know if this necessarily means that it can't be defined(as a concept) without a metric. Thanks in advance.","['riemannian-geometry', 'differential-geometry']"
2465976,Probability with Custom dice,"I have a question about probabilities with custom 6-sided dice (not the regular 1,2,3,4,5,6 dice we all know and love, but a dice like 0,0,1,1,2,3). Now imagine having 3 different custom dice (blue, red and green, all with different sides) and that 2 players roll 3 of those dice (Player A is rolling R+G+B, player B is rolling 2R+G). Now, I can calculate the probability of each result separately. For example, I know that Player A has a 68% to roll at least ""3"" with his chosen dice, while Player B has only 52% to roll ""3"" with his dice. Same for any other result. What I don't know is if it is possible (an algorithm or formula) to calculate the probability that Player A will win the roll regardless of the number of successes. So I am not looking for statements of the type 
""68% vs 52% to roll ""3"", 53% vs 40% to roll ""4"", etc"", 
but instead I am looking for the X in the following statement:
""When you roll R+G+B and the opponent is rolling 2R+G, you have a X% to roll higher"" (which equals winning the roll). Any ideas about how/if I can come up with an answer to this question? I can code this in a small app so that it makes all the calculations by itself, but I have no idea where to start when it comes to this type of complex probability result. I assume it is a purely mathematical/probability question, so I hope I posted this in the correct forum.","['probability', 'dice']"
2466004,When is the formal spectrum of a complete local Noetherian ring R algebraizable?,"My question, in the easiest case, is the following: given a complete local Noetherian $k$-algebra $\hat{A}$ with residue field $k$, when is $\text{Spf}(\hat{A})$ algebraizable? Or in other words, when does there exist a $k$-algebra $R$ of finite type and an ideal $I\subset R$ such that the $I$-adic completion of $R$ is isomorphic to $\hat{A}$? If this does not always hold, then what would be the easiest $\hat{A}$ which gives a counterexample? Furthermore, how is the situation if we do not assume anything on the residue field of $\hat{A}$? Some more context: by a result of Cohen, we know that $\hat{A}\cong k[[x_1,\ldots,x_n]]/J$, so it seems to me that my question (in the case of $k=\mathbb{C}$) is equivalent to asking when a germ of an analytic subset is (analytically) isomorphic to a germ of an algebraic one (using arguments of Artin). From what I've gathered so far, this is not an easy question in general. But maybe I am missing something here.","['algebraic-geometry', 'commutative-algebra']"
2466040,Stability analysis using the Jacobian,"I must find the steady states, the Jacobian, and the stability of each point. $x' =x^2 - y^2$
and $y' = x(1-y)$ Simply solving for when these equations equal zero, I found that $y=0,1$, after getting $y-yy=0$, as must x, as $x^2=y^2$. Thus I believe the steady states to be $(0,0)$ and $(1,1)$ but I don't understand the Jacobian matrix. I think it is: $
  \left[ {\begin{array}{cc}
   2x-y^2 & x^2-2y \\
   1-y & x-1 \\
  \end{array} } \right]
$ So for the state (0,0): $
  \left[ {\begin{array}{cc}
   0 & 0 \\
   1 & 1 \\
  \end{array} } \right]
$ So, the trace of the matrix is $1$ and the determinant is $0$. Is this neutral center? For (1,1): $
  \left[ {\begin{array}{cc}
   0 & 0 \\
   0 & 0\\
  \end{array} } \right]
$ So the trace and the determinant are both $0$ (how do we characterize this) Any help would be appreciated, as would work checking, am new to differential equations.","['stability-in-odes', 'ordinary-differential-equations', 'dynamical-systems', 'stability-theory']"
2466047,Showing the tautological and tangent bundles of $\mathbb{CP}^1$ are non-isomorphic,"I'm trying to show that the tangent and tautological bundle of $\mathbb{CP}^1$ are non-isomorphic. The hint I was given was to look at the fundamental group of the complement of the zero section. For the tangent bundle, I used that the bundle has local trivializations $U_1=\mathbb{CP}^1 - [0:1]$ and $U_2=\mathbb{CP}^1 - [1:0]$. I then applied the siefert van kampen theorem $$\pi_1 (TU_i-\sigma_0) \cong \pi_1 (U_i \times \mathbb{C}^*) \cong \pi_1 (U_i) \oplus \pi_1 (\mathbb{C}^*) \cong \mathbb{Z} a_i$$ $$\pi_1 (T(U_1 \cap U_2) - \sigma_0) \cong \pi_1 ((U_1 \cap U_2) \times \mathbb{C}^*) \cong \pi_1((U_1 \cap U_2)) \oplus \pi_1(\mathbb{C}^*) \cong \mathbb{Z}c \oplus \mathbb{Z}d$$ Then the fundamental group will be $\mathbb{Z}a_1 *\mathbb{Z}a_2$ quotiented by the images of c and d. c will be homotopic to a point and so the fundamental group will be $\mathbb{Z}a_1 *\mathbb{Z}a_2$ quotiented by the image of $\mathbb{Z}d$. Since the former has two generators and the latter only one, this cannot be trivial. What I have so far I believe is correct, please tell me otherwise if it is not. What remains is to show that the tautological bundle minus the zero section has trivial fundamental group. I think that this is because it can be deformation retracted onto the 3-sphere but I'm not sure how to show this. Any help would be greatly appreciated.","['algebraic-topology', 'vector-bundles', 'differential-geometry']"
2466082,Lie bracket of left-invariant vector fields is left-invariant,"Let $G$ be a Lie group and $l_g:G\rightarrow G$ be the left-multiplication map. Let $X$ be a left invariant vector field on $G$ , i.e., $X:G\rightarrow TG$ is such that $(l_g)_*X=X$ on $G$ where $(l_g)_*X$ is  defined as follows: $$((l_g)_*X)_{gh}=(l_g)_{*,h}(X_h)$$ where $(l_g)_{*,h}:T_hG\rightarrow T_{gh}G$ is the differential of $l_g$ at $h$ . So, supposing $X$ is a left-invariant vector field, we have $$(l_g)_{*,e}(X_e)=X_g.$$ I am trying to prove that the Lie bracket $[X,Y]$ is also a left-invariant vector field. $${[X,Y]_g(f)}={X_g(Y(f))-Y_g(X(f))}={(l_g)_{*,e}(X_e)(Y(f))-(l_g)_{*,e}(Y_e)(X(f))
}={X_e(Y(f)\circ l_g)-Y_e(X(f)\circ l_g)}={X_e(Y(f\circ l_g))-Y_e(X(f\circ l_g))}={[X,Y]_e(f\circ l_g)}={(l_g)_{*,e}([X,Y]_e)(f)}$$ This is true for all $f$ . So, we have $$(l_g)_{*,e}([X,Y]_e)=[X,Y]_g.$$ Using same idea, we can prove that $$(l_g)_{*,h}([X,Y]_h)=[X,Y]_{gh}$$ for all $h\in G$ which is same as saying that $[X,Y]$ is a left-invariant vector field. I am sure about all equalities except one, i.e., $Y(f\circ l_g)=Y(f)\circ l_g$ . I am sure this is correct but could not see. Any suggestions about the proof are welcome.","['differential-geometry', 'lie-groups']"
2466160,How many forms vanish on the singular locus of a hypersurface?,Let $X\subseteq\mathbb{P}^3$ be a hypersurface of degree $d$ and let $Y$ be its singular locus. We assume that $Y$ has dimension $1$. Now let $V$ be the vector space of all forms of degree $d$ that vanish on $Y$. Is there any lower bound known on the dimension of $V$? Clearly the product of any linear form with a derivative of the defining equation is in $V$. But I find it already hard to determine the dimension of the span of those.,"['algebraic-geometry', 'commutative-algebra']"
2466161,Solutions to the diophantine equation $x^3+y^3+z^3+w^3=1$,"What is known about the solutions $(x,y,z,w)\in \mathbb{Z}^4$
of the diophantine equation
$$x^3+y^3+z^3+w^3=1$$
Can you suggest me a book or a paper treating this problem?","['number-theory', 'diophantine-equations', 'elementary-number-theory']"
2466177,Proving that the Bayes optimal predictor is in fact optimal,"This is exercise 3.8(a) from Understanding Machine Learning: from Theory to Algorithms by Shalev-Shwartz and Ben-David. I am trying to figure the exercise out for a course, but it is not homework. (I have a decent mathematical background but less so in stochastics.) Consider a set $\mathcal X$, and joint random variables $(x,y)$ distributed according to probability distribution $\mathcal D$ on $\mathcal X \times \{0,1\}$. We think informally of the probability of $(x, 0)$ as that of finding an $x$ without a certain property, and of the probability of $(x, 1)$ as that of finding an $x$ with a certain property. Note that I'm not requiring that the distribution is discrete. We define $f: \mathcal X \to \{0,1\}$, the ""Bayes optimal predictor"", by 
$$
f(x) = 0 \iff \mathbb P(y = 0\mid x ) \geq \frac12.
$$
(I'm not 100% sure this definition even makes sense in the general case. Do we need a well-behaved distribution to speak about $\mathbb P(y = 0 \mid x)$?) Now I want to prove that $f$ is ""the best at predicting whether or not an $x$ has the property"". That is, for any $h : \mathcal X \to [0, 1]$ (note the codomain) we have that
$$
\mathbb P(f(x) \neq y) \leq \mathbb E[|h(x) - y|].
$$
Intuitively, this is totally obvious to me: $f$ always makes the ""best guess"", so even in the optimal scenario, $h$ should incur more loss. I've even proved it in the case that $h$ maps into $\{0,1\}$. However, I can't seem to be able to get the general case. I've tried to condition and split the expectation and probability into the right cases, but I keep getting stuck, partially on notation and partially on insight. I hope someone can point me in the right direction.","['conditional-expectation', 'probability', 'random-variables']"
2466195,How to check if a non-negative matrix is primitive (in the stochastic sense)?,"A square non-negative matrix $A$ is primitive if $A^k$ has all entries positive for some positive integer $k$. Is there an algorithm to do this check in practice? Given a non-negative square matrix $A$ of finite dimension $N$, can we determine if it is primitive? Note: By non-negative matrix $A$, I mean that all its entries are non-negative.","['matrices', 'stochastic-processes']"
2466203,Maximal function is not bounded on $L^1(\Bbb R^n)$,"Prove: There exists a constant $c_p,p>1$, with $c_p>{c}/{(p-1)}$, so that if $f$ in $L^p$ then $$\|Mf\|_P \ge c_p \|f\|_P$$. This is a problem in E.M stein's Harmonic analysis(8.14(b)). I can prove 8.14(a) that if $f$ is supported in a set of finite measure, then $Mf$ in $L_1$ iff $|f|log(1+|f|)$ in $L_1$. I prove 8.14(a) by using Calderon-Zygmund decomposition. I am not really sure where to begin with 8.14(b). Any help would be greatly appreciated.","['real-analysis', 'fourier-analysis', 'harmonic-analysis', 'functional-analysis', 'lp-spaces']"
2466217,Integrals involving three spherical harmonics and powers of trigonometric functions,"Does anyone know how to evaluate integrals of them following form: $$\int_{0}^{\pi} \int_{0}^{2 \pi} (\cos{\phi})^{n_1} (\sin{\phi})^{n_2} (\cos{\theta})^{n_3} (\sin{\theta})^{n_4}Y^m_l Y^p_q Y^i_j \sin{\theta}\; d\phi\; d\theta.$$ Where $Y_l^m$ is the spherical harmonic of degree $l$ and order $m$ . The
symbols $n_1$ , $n_2$ , $n_3$ , $n_4$ $l$ , $m$ , $q$ , $p$ , $i$ , and $j$ are
integers. For any given combination of these integers it is not hard to evaluate the integral, but I need to find all results for a large number of different values of these integers. So many in fact that even tools like Mathematica become to slow. My current idea is to make some kind of selection criteria for when the integral should be zero, based on symmetry considerations, and then evaluate the non-zero integrals by help of Mathematica. However, if anyone knows any result that would simplify my efforts that would be great.","['spherical-harmonics', 'integration', 'spherical-coordinates', 'calculus']"
2466261,$\sum\limits_{n=1}^\infty \log(1+a_n)$ converges absolutely $\iff\sum\limits_{n=1}^\infty a_n$ converges absolutely.,"$$\sum\limits_{n=1}^\infty \log(1+a_n) \text{ converges absolutely}
 \Leftrightarrow \sum_{n=1}^\infty a_n \text{ converges absolutely}.$$ How to prove this, Suppose $$\sum_{n=1}^\infty a_n \text{ converges absolutely}.$$ Let $u_{n}=a_{n}$ and $v_{n}=\log(1+a_n)$, then $$\lim_{n\to\infty} \frac{u_{n}}{v_{n}}=1>0 \implies\sum_{n=1}^\infty \log(1+ a_n) \text{ converges absolutely}.$$ How to prove the converse part?","['real-analysis', 'sequences-and-series']"
2466276,"Adding a ""point at infinity"" to $\mathcal{C}^{\alpha}$","In this paper, on page 5, it says We denote by $\bar{\mathcal{C}^{\alpha}}$ the space $\mathcal{C}^{\alpha}$ to which we add a “point at infinity” $\infty$ with neighbourhoods of the form $\{h : \|h\|_{\alpha} > R\} ∪ {∞}$, which turns $\bar{\mathcal{C}^{\alpha}}$ into a Polish space. The $\alpha$ semi-norm is defined as
$$\|f\|_{\alpha}:=\sup_{x\neq y} \frac{|f(x)-f(y)|}{|x-y|},$$
for $x,y$ in the domain (which here is $S^1$). The $\mathcal{C}^{\alpha}$ norm is defined to be
$$\|f\|_{\mathcal{C}^{\alpha}}=\|f\|_{\infty}+\|f\|_{\alpha}.$$ $\bar{\mathcal{C}^{\alpha}}$ is a space of functions, so what does it mean to add a point at infinity? Is it a function whose ${\alpha}$ norm is infinite? 
Also, what metric is $\bar{\mathcal{C}^{\alpha}}$ endowed with?","['functional-analysis', 'holder-spaces']"
2466284,"A sequence ${\bf x}_1,{\bf x}_2,{\bf x}_3,...$ converges geometrically in some norm, will it converge geometrically in any equivalent norm?","If a sequence ${\bf x}_1,{\bf x}_2,{\bf x}_3,...$ converges geometrically to a vector ${\bf u}$ in norm $\|\cdot\|_1$, i.e. $\|{\bf x}_i - {\bf u}\|_1 \le q\|{\bf x}_{i-1} - {\bf u}\|_1$ for some $q\in (0,1)$, will it converge geometrically in any norm $\|\cdot\|_2$ that is equivalent to $\|\cdot\|_1$? Suppose $c_1\|\cdot\|_2 \le \|\cdot\|_1 \le c_2\|\cdot\|_2$ for some $0<c_1 \le c_2$. I think ${\bf x}_1,{\bf x}_2,{\bf x}_3,...$ converges to $\bf u$ in $\|\cdot\|_2$, through a simple $\epsilon$-arugment. However, I cannot see the convergence is also geometric in $\|\cdot\|_2$. If it is indeed not, can anyone help give a counterexample? Thanks!","['functional-analysis', 'linear-algebra', 'operator-theory']"
2466324,What is general solution of the PDE $(x^2+y^2)u_x+2xyu_y=-u^2$?,"What is the general solution of the following PDE? $$(x^2+y^2)u_x+2xyu_y=-u^2.$$ If we write the characteristic equation
$$\frac{dx}{x^2+y^2}=\frac{dy}{2xy}=\frac{-du}{u^2}$$
then, we find $\frac{d(x+y)}{(x+y)^2}=\frac{-du}{u^2}$ and we have $c_1=1/u+1/(x+y)$. And then? Best regards.","['ordinary-differential-equations', 'partial-differential-equations']"
2466394,Prove ${{n+m+1}\brace m}=\sum_{k=0}^mk{{n+k}\brace k}$ via double-counting,"I want to show by a double-counting argument that$${{n+m+1}\brace m}=\sum_{k=0}^mk{{n+k}\brace k}$$for $m,n\in\Bbb N$ (where $0\in\Bbb N$). Note that ${{n}\brace k}$ is a Stirling number of the second kind (i.e. the number of partitions of $[n]:=\{1,2,\ldots,n\}$ into $k$ blocks). I am just starting to do double-counting proofs, so I just want to make sure I am doing this right. I would like some feedback on my proof: whether it is correct or not, what are some improvements I could make, etc. Here is my proof: We know that ${{n+m+1}\brace m}$ is the number of ways to partition $[n+m+1]$ into $m$ blocks. Now we focus on the $n+k+1$ element of $[n+m+1]$ for some $0\leq k\leq m$. Every element past $n+k+1$ we put in its own block in the partition, which accounts for $(n+m+1)-(n+k+1)=m-k$ of the blocks. We partition the first $n+k$ elements into the remaining $k$ blocks in ${{n}\brace k}$ ways. Then we stick the element $n+k+1$ into one of these $k$ blocks (which can be done in $k$ ways). Hence, there are $k{{n+k}\brace k}$ ways to partition the set with $m$ blocks with our choice of $k$. We sum over all possibilities of $k$ to account for all choices of the $n+k+1$ element to obtain ${{n+m+1}\brace m}=\sum_{k=0}^mk{{n+k}\brace k}$ total partitions of $[n+m+1]$ into $m$ blocks. Thanks in advance for any feedback. If you have another way to prove this I'd love to see that as well.","['combinatorics', 'proof-writing', 'proof-verification']"
2466399,Why do we have $\lim_nE(\inf_{k\geq n}X_k)\leq\liminf_nE(X_n)$?,Why do we have $\lim_nE(\inf_{k\geq n}X_k)\leq\liminf_nE(X_n)$? My try is that $\lim_nE(\inf_{k\geq n}X_k)= \liminf_nE(\inf_{k\geq n}X_k) \leq \liminf_nE(X_k) $. Am I correct? This is part of the proof for Fatou's lemma... Any help would be appreciated.,['measure-theory']
2466424,Using seperation of variables in Partial Differential Equations,"I am trying to use separation of variables method to solve $$ u_t = 9u_{xx}, \quad 0<x<1,\quad t>0$$ $$ u_x(0,t) = 0$$ $$u(1,t)=u(0,t) $$ $$u(x,0) = \sin\pi x, \quad 0 \leq x \le 1$$ and find an approximation (actual number) for large $t$. Here are my workings so far but I am running into some problems. Assume $u(x,t) = F(x)G(t)$ so that $$u_x = F'G, u_{xx} = F''G, u_t = FG'$$ Thus our equation PDE becomes, $$9F''G = FG' $$ Rearranging this equation yields, $$\frac{F''(x)}{F(x)} = \frac{G'(t)}{9G(t)} = \lambda$$ Thus we form two ODE'S, $$F''-\lambda F = 0$$
$$G'-9\lambda G = 0 $$ Using the B.C $u_x(0,t) = 0$ gives $F'(0) = 0 $ with $A\ne 0$ Thus we solve $F'' - \lambda F = 0$ using the above B Then if $\lambda = 0 $ then $F(x) = Ax + B$ and $F'(0) = 0 $ gives $A = 0$. But how do I use the other BC to determine $B?$ Then if $\lambda > 0 $ then the characteristic equation is $r^2 - \lambda = 0$ which has real, unequal roots $r = \pm \sqrt{\lambda }$. Then, $$F(x) = Ae^{\sqrt \lambda x } + B e^{-\sqrt \lambda x }$$ See that $F'(0) = 0 = \sqrt \lambda [Ae^0-Be^0]$ so $A=B$, but how do I use the other BC to determine $B$ Finally if $\lambda = -p^2<0$ then the characteristic eqn $r^2 - \lambda = r^2 - p^2 = 0 $ which has complex roots $r=\pm pi$. Thus $F(x) = A\cos px + B\sin px$. Then, $$F'(0) = 0 = -Ap\sin 0 + Bp\cos 0 = Bp$$
Then $B = 0$ But how do I use the other BC to determine $A$ After this I know I must do the same procedure for $G'-9 \lambda G = 0 $","['ordinary-differential-equations', 'partial-differential-equations']"
2466437,What is the derivative of the associated Legendre Polynomials at the end points?,"I have been searching for different solutions for the derivatives of associated Legendre polynomials at the end points. The associated Legendre polynomial is defined as:
$$P^m_l(x)=(-1)^m(1-x^2)^{m/2}\frac{d^m}{dx^m}P_n(x)$$ See matlab's link The derivative of the associated Legendre polynomials can be defined using a recurrence relationship where the derivative is defined by other polynomials within the associated Legendre polynomial family.  In this case I am trying to use the recurrence described on wikipedia's page : $$(x^2-1)\frac{d}{dx}P_l^m(x)=\sqrt{1-x^2}P_l^{m+1}(x)+mxP_l^m(x)$$ To solve for the derivative divide both sides by $(x^2-1)$ and you will see the function goes unbounded at $x= \pm 1$ which are the end points of the function also it can be undefined (i.e., $0/0$) for when $m = 0$ and $x=\pm 1$. How can I compute the derivative at these end points? L'Hopital's rule does not work here. I'm wondering If i can use something like a Laurent series or some kind of series to approximate it but with the end goal of implementing this into code eventually. As I continue my search for solutions has anyone had experience in computing the endpoints of the first derivative of the associated Legendre polynomials?","['derivatives', 'legendre-polynomials']"
2466491,Non-differentiability of a Markov diffusion process,"I was reading through these notes (link here) on Markov diffusion processes and I'm confused about one of the definitions and its properties. It is stated that the Markov diffusion process satisfies the continuity condition in that $P(|X_t - X_s | \ge \epsilon | X_s = x) = o(t-s)$. It then goes on to say that this condition implies that the sample paths of a diffusion process are not differentiable. I am confused by this statement. From what I understand, the $o$-notation here means that $\lim_{t\rightarrow s} \frac{o(t-s)}{t-s} = 0$. For example, we have that $x^5$ is $o(x)$ as $x\rightarrow 0$. This makes me think that if $f(x)$ is $o(x)$ as $x \rightarrow 0$, i.. the rate of decay of $f(x)$ compared to that of $x$ is faster as $x \rightarrow 0$. Hence, I do not understand why in the link it says: ""the sample paths of a diffusion process
are not differentiable : if
they where, then the right hand side of the above equation would
have to be 0 when  $t-s \ll 1$ "". Can anyone help me show (more rigorously) how this implies that $P(\frac{|X_t - X_s |}{t-s} \ge \epsilon | X_s = x) $ does not approach 0 as $t \rightarrow s$?","['stochastic-processes', 'probability-theory', 'probability', 'stochastic-analysis', 'stochastic-calculus']"
2466509,A continuous distribution function (in measure theory sense) can be used to define uniform distribution,"I am working on exercise from Probability: Theory and Examples by Durrett. If $F = P(X \le x)$ is continuous, then $Y=F(X)$ has a uniform distribution on $(0,1)$, that is if $y \in [0,1]$, $P(Y \le y) = y$. Following one idea appeared in the book, I suspect by letting $G(x) = \sup_{y} \{ y \colon F(y) \le x \}$ should lead to the result. Then
\begin{align*}
P( Y \le y ) = P( \{ \omega: F(X(\omega)) \le y \} ) = P( \{ \omega: X(\omega) \le G(y)\} ) = F \circ G(y).
\end{align*} It seems to me by definition $F \circ G(y) \le y$ and for every $\varepsilon > 0$, $F( G(y) + \varepsilon ) > y$, by right continuity I conclude $F\circ G (y) \ge y$. My argument should be flawed since I am not using the continuity of $F$ here. However I am too blind to see it. Could anyone please point me out? Thanks in advance. EDIT: I think I know where I was wrong. By definition, we could not conclude $F \circ G(y) \le y$. We need the continuity from left here. Since if $z \to G(y)^{-}$ from the left, and $F(z) \le y$, it does not necessarily have $F\circ G(y) \le y$ for it could have a jump at $G(y)$. Any validation to this thinking is welcome. Thanks.","['probability-theory', 'measure-theory', 'proof-verification']"
2466547,Minimal number of generators ideal in $\mathbb{Z}[x]$,"Let $\mathfrak{a}=(x^n,\ldots,p^{n-1}x,p^n)$ ideal in $\mathbb{Z}[x]$.
  Show that the minimal number of generators of $\mathfrak{a}$ is $n+1$. My strategy to prove this is to use one of the consequences of Nakayama Lemma; that is, to show that $\bar{x^n},\ldots,\bar{p^{n-1}x},\bar{p^n}$ is basis for the $\mathbb{Z}[x]/(x,p)\mathbb{Z}[x]$-module (vector space) $\mathfrak{a}/(x,p)\mathfrak{a}$. However, I was not able to show linear independence.","['abstract-algebra', 'commutative-algebra']"
2466569,Prove the following sequence always results in a perfect square. [duplicate],"This question already has answers here : Prove that the expression is a perfect square (2 answers) Closed 6 years ago . There's a problem statement: For each $m \in \mathbb{N}$, we construct a sequence $m_0$, $m_1$, $m_2,\dots$ denoted $S_m$, recursively via $m_0=m$ and $$m_{i+1} = m_i + \left\lfloor \sqrt{m_i} \right\rfloor$$ for all $i \ge 0$.
  Here, $\lfloor x \rfloor$ is the floor of $x$, the greatest integer less than or equal to $x$.
  Hence, we have $\left\lfloor \sqrt{10} \right\rfloor=3$ and $\left\lfloor \sqrt{29} \right\rfloor=5$. Show that for each positive integer $m$, the sequence $S_m$ contains the square of some integer. I'm pretty certain that this can be proved with induction. I am just not quite sure what to induct on. Examining examples shows that $S_m$ always results in a perfect square eventually, though I'm not sure how to prove it.","['real-analysis', 'number-theory', 'induction', 'sequences-and-series', 'ceiling-and-floor-functions']"
2466574,Is the square of a square root always non-negative? ($\sqrt{x}^2 = |x|?$),"I know that $\sqrt{x^2} = |x|.$ But does $\sqrt{x}^2 = |x|?$ It seems like it should, since
$$\sqrt{x}^2 = \sqrt{x} \cdot \sqrt{x}$$
and $\sqrt{x}$ is non-negative, so their product should be non-negative. But I haven't seen a rule like this, so I'm guessing it isn't the case, and am just wondering why.","['algebra-precalculus', 'radicals', 'absolute-value', 'exponentiation']"
2466606,Getting singular solution from parametric solutions of an ODE,"How to obtain the singular solution for this ODE $$y=2xy'+\frac{1}{y'}$$ After getting the general solution (by calling y' as p and differentiating the equation by x) , I tried to get the envelope but I failed because I got two parametric equations representing the general solution.
here are the equations: $$x=\frac{ln(p)}{p^2}+\frac{c}{p^2}$$ $$y=2\frac{ln(p)}{p}+\frac{2c+1}{p}$$ So which equation do I have to differentiate wrt c ?  If I differentiate any of them wrt c and equating by zero , I got 1=0 !","['singular-solution', 'ordinary-differential-equations']"
2466612,Solutions of a complex function with fractional powers,"Would anyone know how to calculate the values of the complex variable $s$ such as $(\frac{s}{\omega_b}+1)^n(\frac{s}{\omega_h}+1)^{1-n}=C_0$ with $\omega_b \in \mathbb{R}$, $\omega_h \in \mathbb{R}$, $\omega_b <\omega_h$ $n \in \mathbb{R}$  and  $0<n<1$ $C_0 \in \mathbb{C}$ Thank you very much for your kind help.",['complex-analysis']
2466682,A pointwise bound for $\frac{\partial}{\partial t}u=\Delta u+ au$,"In this question I asked whether the Dirichlet PDE:
 $$\frac{\partial}{\partial t}u=\Delta u+ au$$ over a bounded smooth open subset $\Omega \subset \mathbb{R}^N$ has a bound in the form
$$|u(t)|_{L^2(\Omega)}\leq Me^{\omega t}.$$
I wonder if we have a pointwise version of such an estimate. That is:
$$|u(t,x)|\leq M_x e^{\omega_xt}$$
where $M_x$ and $\omega_x$ are constants that may depend on $x$. I thought about using some comparison between $L^2$-norm and $L^\infty$-norm, but we only have  $$|.|_{L^2}\leq C|.|_{\infty}.$$
I don't know but I feel that only finding a closed form for the solution will solve the problem.","['lp-spaces', 'ordinary-differential-equations', 'partial-differential-equations']"
2466696,How to solve 2 tetrated 0.5 times? [duplicate],"This question already has answers here : How to evaluate fractional tetrations? (7 answers) Closed 8 months ago . I've been really interested in tetration lately. So I came up with a seemingly simple problem to solve, which is 2 tetrated 0.5 times, which I'll write as the following. 2^^0.5 To make sense of this notation, consider the following where A represents a real number: A^A = A^^2 A^A^A = A^^3 etc. Here's where my problem is. The answer I got and the one on Wikipedia are different. I'm assuming the answer on Wikipedia is the correct one, but I would like to know what I did wrong. So here's how I tried to solve this problem: First I say 2^^0.5 is the same as the ""super square root"" of 2 (I don't exactly know how to format this), which is equal to X. Next I tetrate or ""super square"" both sides by 2, so the ""super square root"" of 2 becomes 2, and X becomes X tetrated 2 times, which looks like the following: X^^2 = 2 Then I rewrite X tetrated 2 times as X to the power of X. X^X = 2 Finally I graphed Y = X^X and Y = 2 on my calculator and found the intersection point in the first quadrant, which should be the answer of 2^^0.5. And I got the following: X = 1.559610469 (approximately) However, the answer to 2^^0.5 on Wikpedia is approximately 1.45933. Does anyone know what I did wrong when trying to solve this problem? Any answers would be appreciated. Also, if you have any questions of what I did or what I'm asking, feel free to ask.","['algebra-precalculus', 'tetration', 'exponentiation']"
2466697,"$G$ is a group of odd order, show that $a^2=b^2 \Rightarrow a=b$","I've come across this question and I tried to prove it, but my solution seems a little stealthy to me, is it correct? Let $|G|=2k+1$, then we have: $a=ae=aa^{|G|}=a^{|G|+1}=a^{2k+2}=(a^2)^{k+1}=(b^2)^{k+1}=b^{2k+2}=b^{|G|+1}=eb=b$ I would like to know if I'm missing something","['finite-groups', 'abstract-algebra', 'group-theory', 'proof-verification']"
2466758,Proving that convergence in $L^p$ implies convergence in $L^q$ (with Hölder),"I would like to prove that convergence of a function $f \in L^p$ implies that $f$ converges in $L^q$, for $1\le q\le p < \infty$, where $\mu(X) < \infty$. I have already been able to prove this fact, by splitting the integral in two parts, where $|f| \geq 1$ and $|f| \le 1$. However, apparently you can prove this with Jensen's inequality or Hölder's inequality. If this is actually provable with the Hölder inequality, how could this be done?
What I have tried is using the inequality twice, once for $p$ and once for $q$, with $\frac {p}{p-1}$ or $\frac{q}{q-1}$ to fulfill the requirements. Then I would use $g := 1$ and I end up with: $$||f||_p \mu(X)^{\frac{p-1}{p}}-||f||_q\mu(X)^{\frac{q-1}{q}} \ge 0$$ but this does not generally prove the fact,  since $\frac{p-1}{p}$ is greater than $\frac{q-1}{q}$. Any help on how to fix this would be greatly appreciated!",['measure-theory']
2466759,Prove that if $P^{-1}AP=diag[\lambda_j]$ then $e^{At}=Pdiag[e^{\lambda_j t}]P^{-1}$,I'm stuck in this exercise. If $P^{-1}AP=diag[\lambda_j]$ then $e^{At}=Pdiag[e^{\lambda_j t}]P^{-1}$ This is what I've done: $$P^{-1}AP=diag[\lambda_j]$$ $$\implies AP=Pdiag[\lambda_j]$$ $$\implies A=Pdiag[\lambda_j]P^{-1}$$ $$\implies At=Pdiag[\lambda_jt]P^{-1}$$ $$\implies e^{At}=e^{Pdiag[\lambda_jt]P^{-1}}$$ And I need the last implication to be equal to $e^{At}=Pdiag[e^{\lambda_j t}P^{-1}]$ If anyone could help that would be great.,"['matrices', 'exponential-function', 'ordinary-differential-equations', 'linear-transformations']"
2466778,"$\frac{dz}{dt}$ where $z=f(x,y)$","I'm trying to differentiate the function $$z = x^3-y^3$$ where $$ x = \frac{1}{1+t}, \ \ \ \  y = \frac{t}{t+1}$$ I remember there being a proper way to do this using partial differentiation, but I decided to take a stab at it by expressing $x$ and $y$ in terms of $t$ and differentiating it explicitly. Prepare for some messy maths. Hopefully I didn't make any mistakes here, but the point is whether my approach is a valid one: $$\frac{dz}{dt} = \frac{d}{dt} [(\frac{1}{1+t})^3] - \frac{d}{dt}[ (\frac{t}{t+1})^3]$$ $$\frac{dz}{dt} = [3(\frac{1}{1+t})^2 * \frac{d}{dt}[(1+t)^{-1}]] - [3(\frac{t}{t+1})^2*\frac{d}{dt}[\frac{t}{t+1}]]$$ $$\frac{dz}{dt} = [-3(\frac{1}{1+t})^2*(\frac{1}{1+t})^{2}] - [3 (\frac{t}{t+1})^2 * (\frac{1}{t+1})^2]$$ Erm.. hopefully this isn't too hideous but this is what I have. Is this approach invalid or a poor idea, and if so, why?","['multivariable-calculus', 'chain-rule']"
2466792,There are $X_i$ independent identical random variables. Prove that $P(|X_i| \geq 2) \leq \frac{1}{4}$,"Let $X_1,X_2,..,X_{100}$ be independent identical distributed random
  variables with $E(X_i)=0$ and $Var(X_i)=1$ ($E$ means expected value
  and $Var$ means variance). Prove that $$P(|X_i| \geq 2) \leq \frac{1}{4}$$ I don't know what need to do... I try understand what notation is say but not sure: $|X_i|$ mean how many $X_1,X_2,..X_{100}$ we concentrate at. In example they say $|X_i| \geq 2$. This mean we have two or more of these $X_i$ where $i \in [1, 100]$. $P(|X_i| \geq 2)$ mean probability to have at least two of these $X_i$ is at least $\frac{1}{4}$. But then I still don't understanded what is task wanted from me? Pls you can explain task when my explanation is wrong and say what is wanted to do? But more important for me is understand what task say and how solved.","['probability-theory', 'probability', 'probability-distributions']"
2466793,Condition number for matrix of eigenvectors of a diagonally dominant matrix,"Let $A$ be a diagonalizable matrix, i.e., $A=X D X^{-1}$. Recall that columns of $X$ correspond to eigenvectors of $A$, and the diagonal entries of the diagonal matrix $D$ correspond to its eigenvalues. Suppose that $A$ is strictly row/column dominant. In particular assume that $A_{ii}\geq \sum_{j\neq i} |A_{ij}| + c$ for some $c>0$. Similarly for the column sums. Is it possible to choose $X$ such that  the condition number of $X$ is bounded, i.e., can we choose $X$ such that  $\kappa(X)= \|X\|_2 \times \|X^{-1}\|_2$ is bounded (e.g., in terms of $c$)?","['matrices', 'matrix-decomposition', 'eigenvalues-eigenvectors', 'linear-algebra']"
2466807,"Painting the plane, and finding points one unit apart","An old (rather easy) contest problem reads as follows: Each point in a plane is painted one of two colors. Prove that there exist two points exactly one unit apart that are the same color. This proof can be easily written by constructing an equilateral triangle of side length $1$ unit and asserting that it is impossible for the colors of all three vertices to be pairwise unequal. However, I was curious about the trickier problem Each point in a plane is painted one of three colors. Do there exist two points exactly one unit apart that are the same color? ...now, if this happened in $3$-space, I could construct a tetrahedron... but I can't do this in $2$-space. Does this not work with three colors, or is the proof just more complicated? If it doesn't work, how can I construct a counterexample?","['coordinate-systems', 'graph-theory', 'contest-math', 'geometry']"
2466808,Recurrence relations: cashier has no change,"A movie theater charges \$10 for a ticket. The cashier starts out with
  no change. Each customer either pays with a \$10 bill, or else pays
  with a $\$20$ bill and receives a $10 bill in change. One evening the
  cashier serves 2n customers. He is always able to provide change when
  required, but at the end of the evening has no \$10 bills left. Find a
  recurrence relation and initial conditions for the number of ways a(n)
  in which this can occur. My prof also added a note that this recurrence relation is non-linear, but since to my understanding, we have only focused on linear and homogeneous relations, I am not sure how to go about this problem. I'm not sure where to go from what I know so far: the cashier can only start by receiving \$10 and end his shift by receiving a $\$20$ bill the number of times he receives both types of bills must be equal to each other","['recurrence-relations', 'discrete-mathematics']"
2466818,Proving that the absolute value of x is greater then or equal to $0$,"My Question reads: Prove for all $x\in\mathbb{R}$, $|x|\geq\ 0$. This is for a set theory class where we know that $\mathbb{R}$ is the set of Dedekind cuts. For each $x\in\mathbb{R}$, we define $|x|$ = max{$x, −x$}
 = $x ∪ (−x)$ For any $x\in\mathbb{R}$, we define $−x$ = {$r\in\mathbb{Q} | (∃s > r) − s\notin\ x$}. We define the binary relation $<_\mathbb{R}$ on R by $x <_\mathbb{R} y$ iff $x\subset\ y$. I am not too sure where to start for this. Should we consider subsets instead? Is this saying that $0$ is a subset of $|x|$? A Dedekind Cut is a subset $x\subset\mathbb{Q}$ such that: $\emptyset\neq\ x\neq\mathbb{Q}$ $x$ is downwards closed, i.e. if $q\in\ x$ and $r<q$, then $r\in\ x$ $x$ has no largest element. Also, $0$ = {$r\in\mathbb{Q} | r < 0$}","['proof-writing', 'real-numbers', 'discrete-mathematics']"
2466836,Closed form of series with factorial-squared denominator?,"Does the following series have a closed-form expression: $$\sum_{k=0}^{\infty} \frac{z^k}{(k!)^2}$$ I know that it must converge because: $$\sum_{k=0}^{\infty} \frac{z^k}{k!} = e^z$$ and the $(k!)^2$ denominator obviously increases more quickly than the $k!$ denominator. This problem came up in computing the probability of a draw in a football match with each team's goal scoring modeled as a Poisson process. Thanks, John","['closed-form', 'factorial', 'summation', 'sequences-and-series', 'poisson-distribution']"
2466902,Define a topology on $\mathbb{Z}$ which is compact and Hausdorff,"I am struggling with this question... 'Suppose $f : \mathbb{Z} \rightarrow \mathbb{Z} $ is an arbitrary finite-to-one function such that $f(0) = 0$ and $f(1) = 1$ (ie $0$ and $1$ are fixed points). Define a topology on $\mathbb{Z} $ which is compact and Hausdorff, and with respect to which $f$ is continuous.' I have been able to define a bijection between $\mathbb{Z} $ and the one point compactification of $\mathbb{Z} $, ie
$$f: \mathbb{Z} \cup \{ \infty \} \rightarrow \mathbb{Z}$$ where
$$f(n) = \begin{cases} n+1, & \text{if } n \in \mathbb{Z}^+ \cup \{0\} \\ 0, & \text{if } n = \infty \\ n, & \text{if } n \in \mathbb{Z}^-\end{cases} $$ My lecturer has told me to think about this bijection as well as that $f(0) = 0$ in the question in order to come up with an answer but I am not sure how to think about this.","['continuity', 'general-topology', 'integers', 'compactness']"
2466910,Equivalence of hermitian forms under subgroups of $\textrm{GL}_n(\mathbb{C})$,"Let $X \in \textrm{GL}_n(\mathbb{C})$ be a hermitian matrix ($\space ^t \overline{X} = X$).  For another hermitian matrix $Y$, let's say that $X \sim Y$ if there exists a $g \in \textrm{GL}_n(\mathbb{C})$ such that $gX \space ^t \overline{g} = Y$. I was wondering if there is anything in the literature about modifying the equivalence relation $\sim$ to restrict the $g$ to certain subgroups of $\textrm{GL}_n(\mathbb{C})$.  Specifically, I want to know if a complete set of representatives for the equivalence classes are known if we restrict $g$ to be an upper triangular unipotent matrix. More generally, I'm interested in the following problem: let $\sigma$ be an automorphism of a field $E$ with $\sigma^2 = 1_E$.  Give a complete set of representatives for the equivalence classes of $\{ X \in \textrm{GL}_n(E) : \space ^t \overline{X} = X \}$ under the relation: $X \sim Y$ if and only if there exists an upper triangular unipotent matrix $g \in \textrm{GL}_n(E)$ such that $gX \space ^t \overline{g} = Y$. If the case $E = \mathbb{C}$ has been done before, understanding that may be a good start for an investigation into arbitrary fields. Special case $\textrm{GL}_2(\mathbb{C})$: Let $X = \begin{pmatrix} x & y \\ \overline{y} & w \end{pmatrix}$ be a Hermitian matrix.  So $x, w \in \mathbb{R}$ and $xw \neq |y|^2$.  For $a \in \mathbb{C}$, we have $$\begin{pmatrix} 1 & a \\ 0 & 1 \end{pmatrix} \begin{pmatrix} x & y \\ \overline{y} & w \end{pmatrix} \begin{pmatrix} 1 & 0 \\ \overline{a} & 1 \end{pmatrix} = \begin{pmatrix} x + 2 \textrm{Re}(ay) + w |a|^2 & y + aw \\ \overline{y + aw} & w \end{pmatrix}$$","['functional-analysis', 'bilinear-form', 'inner-products', 'algebraic-groups', 'linear-algebra']"
2466925,"$SL(2,\mathbb{C})$ action on $\mathbb{C} P^1$ induces action of Lie algebra by vector fields","I am in need of some assistance to solve problem 3.8 in Kirillov's An Introduction to Lie Groups and Lie Algebras . Copied below: Let $SL(2, \mathbb{C})$ act on $\mathbb{C} P^1$ in the usual way:
  $$\begin{pmatrix} a & b \\ c & d \end{pmatrix} [x:y] = [ax+by:cx+dy].$$ 
  This defines an action of $\mathfrak{g} = \mathfrak{sl}(2,\mathbb{C})$ 
  by vector fields on $\mathbb{C} P^1$. Write explicitly
  the vector fields corresponding to $h, e, f$ in terms of the
  coordinate $t = x/y$ on the open cell $\mathbb{C} \subset \mathbb{C} P^1$. I am aware that the action of $SL(2,\mathbb{C})$ on $\mathbb{C}P^1$ is equivalent to a map $\rho: SL(2,\mathbb{C}) \to \mathbb{C}P^1$, and further the pushforward $\rho_*$  defines the action of the Lie algebra. In terms of one-parameter subgroups, recalling $$ h = \begin{pmatrix}1&0\\ 0&-1\end{pmatrix},$$ $\exp(sh)$ is a curve in the Lie group with tangent vector $h$ at $s=0$, and so the action of $h$ on $\mathbb{C}P^1$ is defined to be  $$ \frac{d}{ds}\exp(sh)([x:y])|_{s=0} = \frac{d}{ds} [e^s x: e^{-s} y]|_{s=0}$$ at which point I'm a little confused. Edit: I should also add that this is a homework assignment, so hints are strongly preferred over full solutions.","['differential-geometry', 'lie-algebras', 'lie-groups']"
2466956,Intuition for nontrivial fiber bundles in terms of sections,"I understand the notion of a nontrivial fiber bundle with fiber $F$ over a base manifold $B$, as defined in terms of the projection map $\pi$: for any sufficiently small region $U \subset B$, the preimage $\pi^{-1}(U)$ is homeomorphic to the product space $U \times F$, but the preimage $\pi^{-1}(B)$ itself (the total space) is not homeomorphic to $B \times F$. The Mobius strip is a standard example for visual intuition. However, physicists like myself often think of a fiber bundle in terms of its sections rather than its projection map. Is there an equivalent definition of a nontrivial bundle formulated in terms of its sections $\sigma$ (the right-inverses of $\pi$)? I.e. a statement of the form ""a fiber bundle is nontrivial iff (some section $\sigma$ has)/(all sections $\sigma$ have) property $X$""? If not, is there any intuition for what the sections of a nontrivial bundle ""look like""? I know that a principle bundle is nontrivial iff it does not admit any global section, but I'm curious how things work for general fiber bundles.","['intuition', 'fiber-bundles', 'differential-geometry']"
2467086,Area bounded by three non concurrent straight lines,"To find the area of triangle formed by three straight lines 
  Given is combined equation of three straight lines 
  $$x^2 y -y^3-x^2+5y^2-8y+4=0$$ This can easily be factorized into three straight lines $y=1$ $y=x+2$ $y=2-x$ Now it will be easy to calculate intersection points and calculate the area as 1 sq units. However, I was wondering if it were possible to calculate the area from the combined equation of the lines without actually finding the equations of the straight lines by making use of the coeffecients of the terms in the combined equation.","['coordinate-systems', 'algebraic-geometry', 'geometry']"
2467098,To prove given function is constant function,"Suppose $f,g,h$ are functions from the set of positive real numbers into itself satisfying
$$f(x)g(y)=h\left(\sqrt {x^2+y^2} \right)\ \ \forall \ x,y\in (0,\infty )$$
Show that the three functions $\frac {f(x)}{g(x)},\frac{g(x)}{h(x)},\frac{h(x)}{f(x)}$ are all constants.
I only succeed in to show $f/g$ is constant function i,e, i got $f(x)=g(x)$.
Anyone can help me to prove that $g/h$ is constant.",['functions']
2467143,Is any closed set with two elements a group?,"Suppose you have a set $S = \{a,b\}$  that is closed under an associative operation $ * $, is S necessarily a group? I am having great difficulty trying to prove to myself that there exists a unique identity element. As S is closed by $*$, $ a*a=a$ or exclusively $a*a=b$. So far, my approach is to show that $a*a=a$ is equivalent to $b*b=a$, however I cannot seem to manipulate the equations to force that implication. Would anyone be able to shed some light? Many Thanks.","['abstract-algebra', 'group-theory']"
2467251,How to prove a cross is not locally homeomorphic to an euclidean space?,"Consider the subset $X = \{(x, 0) \mid -1 \lt x \lt 1\} \cup \{(0, y) \mid -1 \lt y \lt 1\} \subset \Bbb R^2$. It's just two open segments intersecting at $(0, 0)$. How do you show that $X$, equipped with the subspace topology of $(\Bbb R^2, \lvert \lvert \cdot \rvert \rvert_2)$, is not locally homeomorphic to an euclidean space because of the point $(0, 0)$ ?","['manifolds', 'general-topology']"
2467258,Subsets differing in at least two elements,"Does it have name or is it even researched. I was trying to calculate some combinatorial problems and ran into a problem. I do not know how to calculate (in general) the maximal number of k-element subsets, such that any pair of these subsets differs in at least two elements. For example, $3$-element subsets of $\{1,2,3,4,5\}$ with the above property are only $2$, for instance $\{1,2,3\}$ and $\{1,4,5\}$. I know it is going to be most likely complicated, because by my calculations  3-element subsets with this property for $n = 1 \text{ or } 3\mod 6$  turned out to be equal to $\frac {n \choose 2} 3$. And I know why (in case I am not wrong), and I guess it is due to its connection to that type of algebra I do not know the name of, where given two different elements, the result of the operation is the third one (please tell me how is it called). But this equality does not apply for other numbers in case of $3$-element subsets, because not every pair of elements determines some triplet. And more complication I guess arises in general case of k-element subsets. Is it something known and solvable, something known and not having a general way of computing it, or is it a not researched topic?","['combinatorics', 'extremal-combinatorics']"
2467299,Suppose that each of $n$ men at a party throws his hat into the center of the room...,Suppose that each of $n$ men at a party throws his hat into the center of the room. The hats are mixed up and then each man randomly selects a hat. What is the probability that at least one of the men selects his own hat?,"['probability', 'derangements']"
2467304,Implications of the difference between $\sigma$ algebra and topology?,"The definitions of $\sigma$ algebra and topology on a set are very similar. Basically the way I think about it is that the topology on $\mathbb R$ contains all the open intervals but not the closed ones, and the sigma algebra contains the closed intervals. My question is: what is the significance of this difference? What are the main implications of this difference? (I.e. the results that hold for topologies but not for sigma algebras).","['general-topology', 'probability-theory']"
2467426,Why doesn't $c_0$ admit a complement in $l^\infty$?,"The projection theorem shows that every closed linear subspace $ M $ of hilbert space $H$ has 
at least one complementry closed linear subspace namely $M^\perp$. But in some Banach spaces a closed subspace may fail to have complementry closed linear subspace; for instance, the closed subspace $c_0$ of banach space $l^\infty$ is not complemented in $l^\infty$. I wonder why $c_0$ have not a complemented linear subspace  in $l^\infty$.","['functional-analysis', 'banach-spaces']"
2467440,$\frac{1}{\sqrt n} \sum_{k=1}^n X_i$ cannot converge in probability,"Let $X_n$ be iid random variables such that $E(X_i)=0$ and $E(X_i^2)=\sigma^2$. Prove that $\left(\frac{1}{\sqrt n} \sum_{k=1}^n X_i\right)_n$ cannot converge in probability. I'm quite stumped with this problem. Since $\frac{1}{\sqrt n} \sum_{k=1}^n X_i = \sqrt n \left(\frac 1n \sum_{k=1}^n X_i\right)$, $\left(\frac{1}{\sqrt n} \sum_{k=1}^n X_i\right)_n$ converges in distribution to $\mathcal N(0,\sigma^2)$, so the question essentially asks to prove that convergence cannot be improved to convergence in probability. Supposing for the sake of contradiction that $\left(\frac{1}{\sqrt n} \sum_{k=1}^n X_i\right)_n$ converges to some $Y$ in probability, there exists a subsequence that converges to $Y$ almost surely. I haven't been able to derive anything useful from this... Any hint is welcome.","['probability-theory', 'convergence-divergence', 'central-limit-theorem']"
2467531,Why can any orthogonal matrix be written as $O=e^A$?,"I read in the book Quantum Field Theory in a Nutshell that any orthogonal real matrix $O$, can be written as $O=e^A$. I should clarify that 
$O \in \textrm{SO}(N)$, so $O^TO=1$ and $\det (O)=1$ I wonder why this is true and if there's a simple proof?","['matrices', 'orthogonal-matrices', 'matrix-exponential', 'rotations']"
2467541,proving that a function from $\Bbb R^2$ to $\Bbb R^2$ is surjective [duplicate],"This question already has answers here : $|x-f(x)|<5777$, Show that $f$ is surjective [closed] (2 answers) Closed 6 years ago . Let $f: \Bbb R^2 \to \Bbb R^2$ be a continuous function such that $|f(x) - x| < 2017 \space$ $\forall$ $x\in \Bbb R^2$. prove that $f$ is surjective. please help me prove this statement. thank you very much.","['algebraic-topology', 'general-topology']"
2467579,$Q(\pi)\neq \mathbb{R}$,"How cani demonstrate that $Q(\pi)\neq \mathbb{R}$, that is the field of rational functions of $Q(x)$ evaluated in $\pi$ is a strict subset of $\mathbb{R}$?","['number-theory', 'field-theory']"
2467596,Applying Karlin-Rubin,"I have trouble understanding how to apply Karlin-Rubin My situation: $X_1 ... X_5\sim Poisson(\lambda)$ independent. My hypothesis test is
$$H_0: \lambda \leq 3$$
$$H_1: \lambda > 3$$
I checked that $\sum_i x_i$ is a sufficient MLR statistic for Poisson. Find a UMP level $\alpha = 0.05$ test. Complementary data: \begin{matrix}
Observation: & 1 & 2 & 3 & 4 & 5 \\
Count:& 2 & 5 & 4 & 7 & 5
\end{matrix} Theorem: Consider testing $H_0:\theta \leq \theta_0$ vs. $H_1:\theta > \theta_0$ and consider $T$ to be a sufficient statistic for $\theta$ with MLR property on $\theta$. Then for any $t_0$, the test that rejects $H_0$ iff $T>t_0$ is a UMP level $\alpha$ test, where $\alpha = P_{\theta_0}(T>t_0)$ My attempt: I know $\sum x_i \sim Poisson(5\lambda)$ so I can write $$\alpha = 0.05  = \Pr_{\lambda = 3}\left(\sum x_i > t_0\right)$$
$$ = 1 - CDF_{poisson(15)}(t_0)$$ I don't really understand what $t_0$ is in the definition and how to arrive to the test. I know the CDF of poisson so that's not a problem. I just don't really understand what the last sentence of the theorem is saying and how to apply it. EDIT: From looking through some examples it seems like the test is just $I(\sum_i > t_0)$ where $1$ means to rejects $H_0$. And you just solve for $t_0$ above. Is that it?","['hypothesis-testing', 'maximum-likelihood', 'statistics', 'order-statistics', 'poisson-distribution']"
2467616,How to prove a polynomial can be written as Taylor-style?,"I know that by Taylor's theorem, a function $f$ under some assumptions, can be computed by $$f(x)=f(a)+f'(a)(x-a)+\cdots+\frac{f^{(n)}(a)}{n!}(x-a)^n+\frac{f^{(n+1)}(\xi)}{(n+1)!}(x-a)^{(n+1)}$$ If $f$ itself is a polynomial of degree $n$, then $$f(x)=f(a)+f'(a)(x-a)+\cdots+\frac{f^{(n)}(a)}{n!}(x-a)^n.$$ This can be directly deduced from Taylor's theorem as I mentioned. However, since this is a much simpler result, can we prove it without using that theorem? And is there intuitive understanding of the above equation?","['derivatives', 'real-analysis', 'taylor-expansion', 'calculus', 'power-series']"
2467677,"A set S is infinite, if and only if S can be put into a one-to-one correspondence with a proper subset of itself [duplicate]","This question already has answers here : A set is infinite iff there is a one-to-one correspondent with one of its proper subsets? (8 answers) Closed 5 years ago . I've had a look on the website but nothing seems to answer the particular question I have. (i) Let F be a finite set. Show that any injective (that is, one-to-one) map ψ :
F → F is surjective (that is, onto). (ii) (Paradox of Galileo) Give an example of an injective map ϕ : N → N that
is not surjective. (iii) Now let T be a countably infinite set. Deduce that T can be put in one-to-one
correspondence with some proper subset of itself; so that there exists an injective
map φ : T → T that is not surjective. (iv) Let S be an infinite set. Show that there exists a countably infinite subset T
of S. (v) Deduce from (i), (iii) and (iv) the Dedekind-Pierce Theorem: A set S
is infinite, if and only if S can be put into one-to-one correspondence with some
proper subset of itself. All the other parts of the question are fine, but i don't understand how to do part V. How do I use the other parts of the question to derive this fact. Help is much appreciated always. Thanks",['elementary-set-theory']
2467771,Vandermond matrix generalisation for non-integer degrees,"For a $n \times n$ Vandermonde matrix $$V:=\begin{bmatrix}1 & c_1 & c_1^2 & \cdots & c_1^{n-1} \\ 1 & c_2 & c_2^2 & \cdots & c_2^{n-1} \\ \vdots & \vdots & \vdots & \ddots & \vdots\\ 1 & c_n & c_n^2 & \cdots & c_n^{n-1}\end{bmatrix}$$ we know that it is nonsingular if and only if $c_i \ne c_j$ for $i\ne j$. I am curious if this property can be generalized for non-integer degrees. Suppose I am given a $n \times n$ matrix $$W:=\begin{bmatrix}c_1^{d_1} & c_1^{d_2} & c_1^{d_3} & \cdots & c_1^{d_n} \\ c_2^{d_1} & c_2^{d_2} & c_2^{d_3} & \cdots & c_2^{d_n} \\ \vdots & \vdots & \vdots & \ddots & \vdots\\ c_n^{d_1} & c_n^{d_2} & c_n^{d_3} & \cdots & c_n^{d_n}\end{bmatrix}.$$ Is it true that $W$ is nonsingular if and only if $c_i \ne c_j$ for $i\ne j$? If it matters, then I consider complex values for $c_i$ and real values for $d_i$. If (as I guess) it is something well-known, could you, please, give me a reference? Update: Obviously, I assume that $c_i \ne 0$ for all $i$. Let us also assume that $d_i \ne d_j$ for $i \ne j$. Update 2: I have tried the following condition: for all $d_k\ne 0$ we have $c_i^{d_k} \ne c_j^{d_k}$ for $i \ne j$. It does not work. Actually, for $n=2$ the condition is $c_1^{d_2-d_1} \ne c_2^{d_2-d_1}$. This is satisfied, particularly, for $|c_1| \ne |c_2|$. Update 3: I have the following intuition. Let $\Delta_{ij}:=d_i-d_j$. The hypothesis: if for all $i\ne j$ we have $c_k^{\Delta_{ij}} \ne c_l^{\Delta_{ij}}$ for $k\ne l$, then $\det{W} \ne 0$. For integer $d$ we have exactly the Vandermond condition.",['matrices']
2467830,What is the height of this rectangle?,"What I need is a formula that Given {X,W,Z,A,B,C,D,V} you can Find {Y} This is a problem that's stumped me for a while I wonder if any of you guys could solve it. Note. The top corners of the black rectangles are at the center of the orange and blue rectangles.","['trigonometry', 'geometry']"
2467833,Indeterminate forms limits,"Why did $∞^∞$ is not an indeterminate form ? 
We have seven indeterminate form $$0/0 $$
$$∞/∞$$
$$0\cdot∞$$ $$∞-∞$$ $$0^0$$ $$1^{\infty}$$ $$∞^0$$ but it does not have $$∞^∞ $$why",['limits']
2467874,A characterization of inner product spaces ?,"Let $X$ be a normed linear space over $\mathbb C$ such that $||x-y|| \ge \dfrac 12 (||x||+||y||)\bigg|\bigg| \dfrac x{||x||}- \dfrac y {||y||} \bigg|\bigg| , \forall 0\ne x, y \in X$ , then is it true that the norm on $X$ comes from an inner-product ? ( I can show that for a complex inner-product space , the inequality is true ) If not true in general , what if we moreover assume $X$ is Banach or finite dimensional ?","['functional-analysis', 'normed-spaces', 'inner-products']"
2467883,Why only two tangents can be drawn to a parabola from a point outside it?,"It's intuitively obvious to me that only two tangents can be drawn to a parabola from a point $(a,b)$ outside it but I want a mathematical pre-calculus proof of this.","['algebra-precalculus', 'proof-writing', 'analytic-geometry']"
2467929,"Jump of a cadlag process is indistinguishable from the zero process (Protter, Theorem I.7)","In Protter's Stochastic Integration, Chapter I, Theorem 7's proof says that if $X$ is adapted and cadlag, then you can use Theorem 4 to say $T(\omega):=\inf\{t>0:|\Delta X_t|>1/n\}$ is a stopping time. Here $\Delta X_t:=X_t-X_{t-}$ is the jump of the cadlag process. Although the fact $T(\omega)$ is a stopping time has been proven in many places, none of such proofs use Protter's Theorem 4 e.g. The jumping times of a càdlàg process are stopping times. and The jump of cadlag process is indistinguishable from the zero process . Protter's Theorem 4 says that if $\Lambda$ is a closed set, then $T(\omega):=\inf\{t>0:X_t(\omega)\in\Lambda\text{ or } X_{t-}\in\Lambda\}$ is a stopping time. Let me paraphrase Protter's proof: ""Restrict $X$ to $t\in[0,t_0]$. The set $\{t>0:|\Delta X_t|>1/n\}$ is finite a.s. Therefore, by Theorem 4, $T(\omega)$ [as defined above] is a stopping time."" Now, Protter doesn't give more details. My question is, how does he use Theorem 4? I need help but first this is an attempt at the proof: The fact that the set of discontinuities of a cadlag process is finite (when considering only $t\in[0,t_0]$) is very well known. While this is a statement about the time variable $t$, $\Lambda$ in Protter's Theorem 4 concerns the space of $X_t(\omega)$. However, notice that the a.s.-finiteness of $\{t>0:|\Delta X_t|>1/n\}$ implies $\{X_t:|\Delta X_t|>1/n\}$ and $\{X_{t-}:|\Delta X_t|>1/n\}$ are also finite, and hence closed, a.s. However, Theorem 4 requires closedness, not a.s.-closedness. How can I keep going?","['stochastic-processes', 'probability-theory', 'stochastic-analysis', 'stopping-times']"
2467939,Normal quadric surfaces in $\mathbb{P}^3$,"I'm trying to prove that the quadric surfaces $Q_1:xy-zw=0$ and $Q_2:z^2-xy=0$ are normal (exercise 3.17(b) from Hartshorne's Algebraic Geometry ). According to the exercise, $Y$ is normal when $\mathcal{O}_P$ is integrally closed for all $P\in Y$ . I have a feeling that using the definition directly is not a good plan,now I'm stuck because I can't think of anything else.","['quadratics', 'projective-geometry', 'algebraic-geometry', 'commutative-algebra']"
2467983,Is $63\times63$ the largest matrix with no rectangles that have an even number of each $0-9$ digit?,"I'm working on an algorithm that finds the largest rectangle with an even number of all 10 digits within a square matrix, e.g. for the 4×4 square on the left that would be this 3×2 rectangle: 4 8 6 5    - - - -
3 4 1 2    3 4 1 -
1 3 4 5    1 3 4 -
7 4 0 9    - - - - because it has two of the digits 1, 3 and 4. Now, if you run the algorithm on large squares with random values, the average number of rectangles you have to check before finding one with an even number of all digits is around C(10,0) + C(10,2) + C(10,4) + C(10,6) + C(10,8) + C(10,0) = 512 (because a large rectangle with random values will have a probability of around 1/2 of having an even number of any digit, but only an even number of digits can be present an even number of times in a rectangle with an even number of cells). The worst case, where you'd have to check all rectangles with an even number of cells, because none has an even number of each digit, quickly becomes huge: size            rectangles

   2 x    2                  5
   4 x    4                 64
   8 x    8                896
  16 x   16             13,312
  32 x   32            204,800
  64 x   64          3,211,264
 128 x  128         50,855,936
 256 x  256        809,500,672
 512 x  512     12,918,456,320
1024 x 1024    206,426,865,664 However, when running tests on random data, the highest number of rectangles I ever had to check for any size input was 13,862 for a 64×64 square, even after running the test 10 million times. So I started wondering whether a large square with no valid rectangles was actually possible, or whether there is a maximum size. When trying to construct worst-case input, I automatically ended up using the sequence: 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 ... which is made by taking the sequence so far, repeating it, and adding 1 to the last number ( OEIS A007814 ). The squares it produces (by copying the previous size square four times and then adding 1 to the right-most column and the bottom row) are: 0,1
1,2 0,1,0,2
1,2,1,3
0,1,0,2
2,3,2,4 0,1,0,2,0,1,0,3
1,2,1,3,1,2,1,4
0,1,0,2,0,1,0,3
2,3,2,4,2,3,2,5
0,1,0,2,0,1,0,3
1,2,1,3,1,2,1,4
0,1,0,2,0,1,0,3
3,4,3,5,3,4,3,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4
2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4
3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4
2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4
4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,8 At his point, if you repeat the 16×16 matrix to create a 32×32 matrix and add 1 to the right-most column and bottom row, the bottom-right cell would have the value 10; we can replace this with a 1 (but that's the only value that works): 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5
2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5
3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,8
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5
2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5
4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,8,4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,9
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5
2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5
3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,8
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5
2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5
5,6,5,7,5,6,5,8,5,6,5,7,5,6,5,9,5,6,5,7,5,6,5,8,5,6,5,7,5,6,5,1 Then, when going from 32×32 to 64×64, there are several cells in the right-most column and bottom row for which every value creates a rectangle with an even number of each digit. So the maximum-sized square without rectangles with an even number of all digits that you can construct with this method seems to be this 63×63 matrix: 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,8,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,8,4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,9,4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,8,4,5,4,6,4,5,4,7,4,5,4,6,4,5,4
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,8,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
5,6,5,7,5,6,5,8,5,6,5,7,5,6,5,9,5,6,5,7,5,6,5,8,5,6,5,7,5,6,5,1,5,6,5,7,5,6,5,8,5,6,5,7,5,6,5,9,5,6,5,7,5,6,5,8,5,6,5,7,5,6,5
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,8,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,8,4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,9,4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,8,4,5,4,6,4,5,4,7,4,5,4,6,4,5,4
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,8,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0
1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1
0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 Of course, I don't know whether this is the best or only way to construct squares with no rectangles with an even number of each digit, and I also don't know whether there could be non-systematic, more random solutions. So my question is: Can it be proven that 63×63 is the largest square which has no rectangles with an even number of each digit 0-9? And if not, is there a maximum size? And is there a way to construct larger squares? As Peter Taylor pointed out in a comment, a rectangle with height 1 is limited to width 1023, because there are only 2 10 = 1024 different even-ness signatures with 10 digits, so either one of them will be 0 (meaning there is a rectangle with an even number of all digits up to that point), or two will be the same (meaning there is a rectangle with an even number of all digits between them) . Using the same logic, you can prove that a rectangle with height 2 is limited to width 511. Trying this out with the sequence explained above gave these maximum widths: 1: 1023
  2 -    3:  511
  4 -   15:  255
 16 -   63:   63
 64 -  255:   15
256 -  511:    3
512 - 1023:    1 The 1×1023 and 2×511 limit are certain. The other limits may just be limits of the method I'm using to create the examples. (Please feel free to change the tags; I was unsure which ones to use.)","['elementary-number-theory', 'integers', 'combinatorics', 'sequences-and-series', 'discrete-mathematics']"
2467999,Integral of a smooth function along the fibers is smooth,"Let $\Phi : \mathbb{R}^n \to \mathbb{R}^k$ be a smooth map, with $n>k$ and let $f:\mathbb{R}^n \to \mathbb{R}$ be a smooth function. Let $J\Phi(x)$ be the Jacobian of $\Phi$ in $x$: it is defined as $\sqrt{\det(D\Phi(x)\cdot D\Phi(x)^t)}$ where $D\Phi(x)$ is the differential of $\Phi$ in $x$. Assume that $f\cdot(J\Phi)^{-1}$ is integrable. By the coarea formula, for almost all points $z \in \mathbb{R}^k$,
$$p(z)= \int_{\Phi^{-1}(\{z\})} f(x)(J\Phi(x))^{-1}d\mathcal{H}^{n-k}(x)$$
is well defined and defines a measurable function on $\mathbb{R}^k$. 
Is this function smooth as well ? If not, under what conditions is $p$ smooth? (For instance, $\mathbb{R}^n$ and $\mathbb{R}^k$ can be replaced by smooth compact manifolds if needed) Edit: definition of the Jacobian.","['geometric-measure-theory', 'smooth-manifolds', 'differential-geometry']"
2468067,Point of intersection of $f(x)$ and $f^{-1}(x)$,"Can we say that that if $f(x)$ and $f^{-1}(x)$ intersect, then at least one point of intersection will lie on  $y=x$? Also there are many function e.g. $f(x)=1-x^3$ where point of intersection exists outside $y=x$  There will be $5$(odd) point of intersection of  $f(x)=1-x^3$ and $f^{-1}(x)=(1-x)^{1/3}$ out of which one lie on $y=x$. Will there exist a function in which there will be even number of point of intersection but odd number of point of intersection will lie outside $y=x$? Also it is clear that in case of strictly increasing continuous function , point of intersection if exists will lie on $y=x$ but will also be true for 
strictly increasing discontinuous function?","['inverse-function', 'functions']"
2468073,Why do I get a converging result when pressing cosine multiple times on a calculator? [duplicate],"This question already has answers here : Convergence of cos, sin, tan functions (2 answers) Closed 6 years ago . I'm trying to comprehend the following: If I choose any starting value (e.g. 1) and keep clicking on cosine on the calculator (in radian mode), it gives me a result of about 0.739085...(I believe it's the result of cos(x) = x), but when I repeat the same procedure using sin and tan, I get something completely different (looks like for sin it's converging to 0 while for tan I get very wild results). Thanks for your help.","['numerical-methods', 'analysis']"
2468090,"Exists a complete metric on the space of smooth, compactly supported functions?","Let $\emptyset \neq U \subsetneq \mathbb{R}^n$ be an open set and denote by $C_c^\infty (U)$ the space of smooth functions with support contained in $U$. On this we have the following metric $$ d(f,g) = \sum_{k\geq 0} \frac{\Vert f - g \Vert_{C^k(U)}}{1+ \Vert f - g \Vert_{C^k(U)}} $$ where $$ \Vert f \Vert_{C^k(U)} = \sup_{\substack{\alpha\in \mathbb{N}^n: \ \vert \alpha\vert \leq k} \\ \quad x\in U} \vert \partial_x^\alpha f(x) \vert.$$ One can prove that $(C_c^\infty (U),d )$ is not a complete metric space (the support might accumulate at the boundary, preventing the limit to belong to $C_c^\infty (U)$). My question is the following: Does there exist a metric $\tilde{d}$ on $C_c^\infty (U)$ such that $(C_c^\infty (U), \tilde{d})$ is a complete metric space and such that the topology coincides with the one induced by $d$?","['functional-analysis', 'complete-spaces', 'metric-spaces']"
2468097,Calculating dimensions of a Pyramid to fit inside of a Cuboid,"I am trying to fit a pyramid inside of a cuboid, but maximize the dimensions of the pyramid while still remaining inside of the cuboid. Given the dimensions of the cuboid (length, width, height), how could I calculate the dimensions of the pyramid in order to maximize it's volume inside of the cuboid? I am looking to have the pyramid originate in the position shown in the photos below.  I think the angle of rotation of the pyramid is important too.  But I am not really sure how to perform the math for these calculations.",['geometry']
2468209,Prove identity in a triangle,"I want to show that if $ABC$ is a triangle then 
$$\sin^2(A/2)+ \sin^2(B/2) + \sin^2(C/2) =1-2\sin(A/2) \sin(B/2) \sin(C/2)$$ Well I eventually got it after much algebra, but I am looking for a shorter solution, or maybe even a geometric one?","['substitution', 'trigonometry', 'triangles', 'geometry']"
2468230,"Markov Chain, Doubly stochastic and Supremum","Suppose a Discrete-Time Markov Chain has a state space $S = \{0,1,2,\ldots\}$ and a  doubly stochastic transition matrix $P$ (i.e $\sum_{i \in S}P_{ij} = 1, \forall i \in S$) Let $\underline{a} = (a_0,a_1,\ldots)$ be a probability distribution and let $\underline{b} = \underline{a} P$. Prove that (1) $sup\{a_i : i = 0,1,\ldots\} \le sup\{b_i: i = 0,1,\ldots\}$ (2) Define $A:=\{i \in S: b_i =  sup\{b_i: i = 0,1,\ldots\}\}$ and $B := \{i : a_i < sup\{a_i : i = 0,1,\ldots\}\}$. Show that if the inequality in part (1) takes equality, then $A$ is not empty and $P_{ij} = 0$ for any $i \in B$ and $j \in A$ For (1) I know that $sup_{i \in S}(b_i) = sup_{i \in S} (\sum_{j \in S}a_j) P_{ji} \le \sum_{j \in S} sup_{j \in S}(a_j P_{ji}) = sup_{j \in S}(a_j)\sum_{j \in S}  P_{ji} = sup_{j \in S}(a_j)$ But how to show part (2), I think I should start with contradiction, thank you for your help!","['stochastic-processes', 'matrices', 'markov-chains', 'probability', 'analysis']"
2468266,A proof using Baire Category Theorem,"A Baire space is a topological space with the following property: for each countable collection of open dense sets ${\displaystyle \{U_{n}\}_{n=1}^{\infty }}$, their intersection ${\displaystyle \textstyle \bigcap _{n=1}^{\infty }U_{n}}$ is dense. The Baire Category Theorem states: Every complete metric space is a Baire space. How to prove that: Let $(X,d)$ be a complete metric space and $\{F_n\}_{n\in \mathbb{N}}$ a collection of closed subsets of $X$. With the help of Baire Category Theorem prove that if $Y\subset X$ is a closed subset and $X=\bigcup_{n=1}^\infty F_n$, then $U=\bigcup_{n=1}^\infty\operatorname{int}_Y (Y\cap F_n)$ is dense in $Y$.","['complete-spaces', 'general-topology', 'metric-spaces', 'baire-category']"
2468292,inverse of function $xe^x$,"Let W the Lambert function that is the inverse function of $xe^x$.Is true that if $c > 1$, then $w(cx)\leq cw(x)$ for $x\geq 0$? Can I apply the property $ln(x)-ln(ln(x))\leq W$ for $x\geq e$?","['real-analysis', 'exponential-function', 'functions', 'special-functions', 'analysis']"
2468313,Derivation of forward/backward/central difference methods from taylor series,"I'm trying to learn more about finite difference methods here. Theorically using the taylor series $u(x)=\sum_{n=0}^{\infty}\frac{(x-x_i)^n}{n!}(\frac{d^nu}{dx^n})_i $ you can get the forward/backward/central difference methods, which are: forward: $(\frac{du}{dx})_i\approx\frac{u_{i+1}-u_i}{\Delta x}$ backward: $(\frac{du}{dx})_i\approx\frac{u_{i}-u_{i-1}}{\Delta x}$ central: $(\frac{du}{dx})_i\approx\frac{u_{i+1}-u_{i-1}}{2\Delta x}$ But I'm having a rough time trying to understand how the above taylor series is being expanded to obtain the difference methods. The fact of not having very clear how taylor works and that subindex notation is confusing me. In the lecture says that $u_i \approx\ {u(x_i)}$ and $x_i=i\Delta x$ Also, the lecture I'm following introduces FDM saying that: $\frac{\delta u}{\delta x}(x)=\lim_{x\to 0} \frac{u(x+\Delta x) - u(x)}{\Delta x} = \lim_{x\to 0} \frac{u(x)-u(x-\Delta x)}{\Delta x} = \lim_{x\to 0} \frac{u(x+\Delta x)-u(x-\Delta x)}{2\Delta x} $ But how can i prove those equations are equals, any idea?","['numerical-methods', 'taylor-expansion', 'ordinary-differential-equations']"
2468336,Prove the existence of an analytic function,"Let $\Delta=\{z\in \mathbb C: |z| < 1\}$. Let $f: \Delta \rightarrow \mathbb C$ be a one-to-one analytic function fixing the origin. Prove that there is a one-to-one analytic function $g: \Delta \rightarrow \mathbb C$ such that $[g(z)]^2=f(z^2)$. Further, show that such a function is odd. The only idea which comes to my mind is the following (not sure whether it is the right direction though). Let $h: \Delta \rightarrow \Delta \rightarrow \mathbb C,\ z\mapsto z^2\mapsto f(z^2)$. Note that $h'(0)=0,\ h''(z)=2f'(z^2)+4z^3f''(z^2)$; since $f$ is one-to-one and analytic, its derivative never vanishes, so $h''(0)\ne 0$. So $h$ is an analytic function of $\Delta$ with a zero of order two at the origin. Then there is an analytic function $g$ defined in an open disc about the origin with a simple zero at the origin such that $[g(z)]^2=f(z^2)$. This is the only thing I came up with, but it seems to be a little bit irrelevant since I don't see any way of extending this $g$ to the whole $\Delta$, and also the injectivity and oddness of such a $g$ are unclear.","['complex-analysis', 'analytic-functions', 'holomorphic-functions']"
2468340,Differential operators as a quantization of functions on the cotangent bundle,"As the title states, I am trying to see differential operators as a quantization of functions on the cotangent bundle. Specifically, let's assume that $k$ is a field of characteristic $0$, and $X$ is a smooth affine $k$-scheme. Grothendieck gives an inductive description of differential operators as follows:
$$\text{Diff}_{\le 0}(\mathcal{O}(X)) := \text{End}_{\mathcal{O}(X)}(\mathcal{O}(X)),$$
$$\text{Diff}_{\le m}(\mathcal{O}(X)) := \{ \phi \in \text{End}_{k}(\mathcal{O}(X)) ~|~ [\phi,a] \in \text{Diff}_{\le m-1} \text{ for all } a \in \mathcal{O}(X)\}.$$ Then define
$$\text{Diff}(\mathcal{O}(X)) := \bigcup \text{Diff}_{\le m}.$$ I wish to show the associated graded algebra is isomorphic to functions on the cotangent bundle:
$$\text{grDiff}(\mathcal{O}(x)) \cong \text{Sym}_{\mathcal{O}(X)}(\text{Vect}(X)),$$
where $\text{Vect}(X) = \text{Der}_{k}(\mathcal{O}(X),\mathcal{O}(X)).$ I've boiled this down to showing that when $X$ is smooth, PBW generalizes to show that the universal enveloping algebroid is a quantization of functions of the cotangent bundle, and then that there is an isomorphism between the universal enveloping algebroid and $\text{Diff}(\mathcal{O}(X)).$ Specifically, can someone help me see how to show the latter of these two items:
$$\mathcal{U}_{\mathcal{O}(X)}\text{Vect}(X) \cong \text{Diff}(\mathcal{O}(X)).$$ I'm not that comfortable with Lie algebroids, so that is surely part of the trouble.",['algebraic-geometry']
2468342,How does calculus without Euler's number (e) look? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question I'm starting to study calculus and I've become very interested in Euler's number ($e$). I understand that the property of being its own derivative makes it the ""natural"" base to work on for studying rates of change. However, I was wondering what would happen if we pretended not to know about the existence of $e$. Would trying to find the derivative of something like $a^x$ lead us into finding the definition of $e$ or is it possible to avoid $e$ altogether? In this video it says that not using $e$ in calculus leads to some pretty crazy math. What does that math look like?","['exponential-function', 'calculus']"
2468353,A function whose (doubly) infinite sum equals its integral,"One of my favorite functions is $S(x)=\frac{\sin(x)}{x},$ where we set $S(0)=1$ (the continuous extension). This function solves the Basel Problem- with some assumptions- and does other cool stuff. I noticed it has the following property: $$\sum_{n=-\infty}^{\infty}S(n)=\int_{-\infty}^{\infty} S(x)dx=\pi.$$ You can prove the LHS using Fourier series and you can prove the RHS using the Residue Theorem, or some very clever methods . My question: Are there other nontrivial functions with this property? That is, aside from linear combinations of $S$ , are there other elementary functions $f$ that satisfy $$\sum_{n=-\infty}^{\infty}f(n)=\int_{-\infty}^{\infty} f(x)dx\;?$$","['improper-integrals', 'sequences-and-series', 'calculus']"
2468412,Redundancy in the statement of the Monotone Convergence Theorem,"Below is the common statement of the Monotone Convergence Theorem. Suppose $\{f_n\}$ is a sequence of non-negative measurable functions with $f_n(x) \leq f_{n+1}(x)$ a.e. and $\lim \limits_{n\rightarrow\infty} f_n(x) = f(x)$. Then $$\lim \limits_{n\rightarrow\infty} \int f_n = \int f$$ But proof requires only $f_n(x) \leq f(x)$ since it is sufficient to conclude that $\int f_n \leq \int f$ for all $n$ by monotonicity. So what is the value of the more restrictive statement than it could be (except that it leads to a nice name for the theorem). Edit: Proof. By Fatou's lemma $\int f \leq \lim \limits_{n\rightarrow\infty} \inf \int f_n$. Now, given $f_n(x) \leq f(x)$ it follows that $\int f_n \leq \int f$ for all $n$ by monotonicity. Hence $\lim \limits_{n\rightarrow\infty} \sup \int f_n \leq \int f$. Which combined with Fatou's lemma gives the desired result.","['real-analysis', 'lebesgue-integral']"
2468423,How to show a solution to an ODE system doesn't exist,"Show that each solution $(x(t), y(t))$ of the initial value problem
  $$
\left\{\begin{array}{cc}x' =&x^2+y \\ y' =&y^2+x \end{array}\right.\qquad
\left\{\begin{array}{cc}x(0) =&x_0 \\ y(0) =&y_0 \end{array}\right.
$$
  with $x_0>0$ and $y_0>0$ cannot exist on an interval of the form $[0,\infty)$. I have been learning about different theorems to show existence but I am not sure how I would show this DNE. I put it into matlab using this code and got no solutions but is there a way to show this algebraically or some other way? syms x(t) y(t) x0 y0

ode1 = diff(x) == x^2+y;
ode2 = diff(y) == y^2+x;
odes = [ode1; ode2]
S = dsolve(odes)

xSol(t) = S.x
ySol(t) = S.y

[xSol(t), ySol(t)] = dsolve(odes)

cond1 = x(0) == x0;
cond2 = y(0) == y0;
conds = [cond1; cond2];
[uSol(t), vSol(t)] = dsolve(odes,conds)

fplot(xSol)
hold on
fplot(ySol)
grid on
legend('xSol','ySol','Location','best')",['ordinary-differential-equations']
2468476,Diffeomorphism between open disk and open square and no diffeomorphism closed disk and closed square,"This is a very basic question. The diffeomorphism between open disk and open square exists. The closed square cannot be diffeomorphic to closed disk as the boundary is not smooth and the diffeomorphism will map boundary to boundary. So given any diffeomorphism between open disk and open square, I cannot extend it to the boundary, though they are homeo. Q1: What is the obstruction to the extension? Intuitive reason please. Q2: Clearly diffeomorphism open sets as above does not see angles on the boundary though there is. However Q1's extension issue does say those diffeomorphisms have some memory on the boundary information as you cannot further extend it. Is there a way to extract this remnant information as the morphism does carry the information about the boundary? Say $A$ is diffeo to $B$ as open sets and I want to check whether $\bar{A}$ diffeo to $\bar{B}$ where the closure is taken in some ambient space? Q3: Under what kind of condition, do I know there is possible extension?","['general-topology', 'differential-geometry', 'differential-topology']"
2468477,What's the probability of guessing a secret code if the attempts are limited and you stop at the first success?,"Some time ago I tried to answer a question on Security Stack Exchange, but I realised I'm not sure I got the maths right, and I'm here to ask for help. The scenario is as follows: somebody is trying to break into another user's account. That account is protected by a password and by a so-called ""second factor"" (like a code sent vis SMS, or generated by an app like Google Authenticator), and the hypothesis is that the attacker knows the password, so the only protection is given by this code. If it is a 3-digit code, there are 1000 possible codes, and with a single attempt the probability to guess it is $p = \frac{1}{1000}$. This is easy. The point where I'm stuck at is calculating the probability of guessing the right code if he has more than one attempt. For example, he can try at most 3 times, and after that the account is locked for protection, and it's game over. What's the probability of success, in that case? Here's what I tried. First of all, we have to establish whether the correct code is the same for all three attempts, or whether it changes every time. I've explored both cases. Case A: the code is always the same. I think this can be modelled with a hypergeometric variable. As Wikipedia says, it's ""the probability of k successes in n draws, without replacement, from a finite population of size N that contains exactly K successes, wherein each draw is either a success or a failure"". In our case, with N = 1000, K = 1, n = 3, k = 1, it's $$ \require{cancel}
P_{Code\,is\,guessed}
= \frac{\binom{1}{1} \binom{1000-1}{3-1}}{\binom{1000}{3}}
= \frac{\binom{999}{2}}{\binom{1000}{3}}
= \frac{\frac{999!}{2!\cdot\cancel{997!}}}{\frac{1000!}{3!\cdot\cancel{997!}}}
= \frac{\frac{\cancel{999!}}{\cancel{2}}}{\frac{1000\cdot\cancel{999!}}{3\cdot\cancel{2}\cdot1}}
= \frac{3}{1000}
$$ To confirm this, I've drawn a tree of the possible outcomes: at every node there's a guess. The green branch corresponds to guessing the right code, the red branch to not guessing it and proceeding to the next attempt (unless it's the last one): The probability of ending up at a certain leaf is the product of all the probabilities of the intermediate nodes, and the probability of reaching any of the ""green"" leaves is simply the sum, as they are independent events. Therefore, $$
P_{Code\,is\,guessed}
= \frac{1}{1000} + (\frac{\cancel{999}}{1000} \cdot \frac{1}{\cancel{999}}) + (\frac{\cancel{999}}{1000} \cdot \frac{\cancel{998}}{\cancel{999}} \cdot \frac{1}{\cancel{998}})
= \frac{1}{1000} + \frac{1}{1000} + \frac{1}{1000}
= \frac{3}{1000}
$$ This looks good, because it's the same result. I'm fairly confident it's correct. Is it right? Case B: the code changes every time I tried to apply the same reasoning to the case where the code changes at every failed attempt. Intuitively, the fact that the code changes every time means that for his second attempt the attacker can't restrict the range to 999 possible codes, but he has to consider, again, 1000. I think this corresponds to a binomial distribution where he tries to have k = 1 successes in n = 3 attempts, but I already have my doubts: if we guess the right code, we immediately stop, but I think the binomial assumes that we make 3 attempts in any case, that is, even if we guess the right code at the first attempt, the binomial assumes we try (and fail) 2 more times. Anyway, with $p=\frac{1}{1000}$, n=3, k=1, the probability is $$
P_{Code\,is\,guessed}
= \binom{n}{k} \cdot p^k \cdot (1-p)^{(n-k)}
= \binom{3}{1} \cdot \frac{1}{1000} \cdot (\frac{999}{1000})^{(3-1)}
= 3 \cdot \frac{1}{1000} \cdot (\frac{999}{1000})^2 = 0.002994003
$$ Again, to confirm the result I tried building the tree: And in this case, $$
P_{Code\,is\,guessed}
= \frac{1}{1000} + \frac{999}{1000} \cdot \frac{1}{1000}  + (\frac{999}{1000})^2 \cdot \frac{1}{1000}
= 0.002997001
$$ which is different from the previous result, the one that I got using the binomial! This means at least one of these calculations is wrong (and possibly both), but I'm not sure where the error is. Anyway the tree convinces me more, and as I said I suspect that the problem is that the binomial isn't the right choice here, because it assumes that the attacker always makes 3 attempts, and this is not realistic in this scenario. So, these are my questions: Are my calculations correct for case A (the code is always the same)? For case B, I'm sure there's an error. Where is it? I even tried simplifying the problem to rolling a die trying to get a certain face, and if the result is not the desired one, rolling one more time. I think the trick might be that if the first roll is successful we don't have to add the probability of guessing at the second roll, because there simply won't be a second roll. But, again, I'm confused.","['binomial-distribution', 'probability', 'probability-distributions']"
2468485,Homeomorphism between $\mathbb{S}^1$ and the spectrum of the Banach algebra of $2\pi$ periodic continuous functions,"I am trying to prove the following: Let $B=\{f:\mathbb R \rightarrow \mathbb C | \;\; f\; \mbox{ is continuous and } 2\pi - \mbox{periodic}\}$. Remember that $\widehat B = \{\varphi:B\longrightarrow \mathbb C|\;\; \varphi \;\mbox{ is an homomorphism} \}\setminus \{0\}$. Show that $\Psi: \mathbb S^1 \longrightarrow \widehat B$, given by: 
  $$\Psi (e^{it})(f):= f(t) \qquad \forall f\in B $$
  is a homeomorphism. What I have done so far: I have already proved that $\Psi$ is injective and continuous using standard arguments involving nets, existence of angle functions defined on connected open sets of $\mathbb S^1$, and the topology of pointwise convergence in $\widehat B$, i.e.:
$$ \varphi_\alpha \rightarrow \varphi \iff  \forall f\in B:\quad \varphi_\alpha(f) \rightarrow \varphi(f).$$ Since $\mathbb S^1$ is compact and $\widehat B$ is Hausdorff, it follows that $\Psi$ is a homeomorphism onto its image. My problem: I wasn't able to prove that $\Psi$ is surjective, since I don't know a natural way to find $z_0=e^{it_0}\in \mathbb S^1$, such that, for a given $\varphi \in \widehat B$:
$$\Psi(e^{it_0})(f) = f(t_0) = \varphi(f), \forall f \in B.$$","['functional-analysis', 'general-topology', 'c-star-algebras', 'banach-algebras']"
2468495,Lines lying in a projective algebraic set,"I want to find all lines lying entirely in the projective algebraic set $XY-ZW=0$ in $\mathbb{P}^3$, where $X, Y, Z, W$ are homogeneous coordinates. How can I do this?","['algebraic-geometry', 'quadrics', 'projective-geometry', 'geometry', 'surfaces']"
2468558,Why does Dominated Convergence Theorem fail in this example?,"Given a measure space, $(\Omega = [0,1], \mathcal{F} = \mathcal{B}[0,1], P)$, my professor said in class that the limit of the following expectation could not be evaluated using Dominating Convergence Theorem: for $n \ge 2$, $$\lim_{n \to \infty} E\left(\cfrac{n}{\log n} \mathbb{1}_{[0,\frac{1}{n}]}(w)\right).
$$ But does $\cfrac{n}{\log n} \mathbb{1}_{[0, \frac{1}{n}]}(w) \to 0$ as $n \to \infty$? Then should it be bounded by some variable in $L_1(P)$ and so DCT is applicable? Or am I missing anything?","['examples-counterexamples', 'measure-theory']"
2468583,A curve where all tangent lines are concurrent must be straight line,"I'm trying to solve this question in the classical Do Carmo's differential geometry book (page 23): A regular parametrized curve $\alpha$ has the property that all its tangent lines pass through a fixed point. Prove that the trace of $\alpha$ is a (segment of a) a straight line. My attempt Following the statement of the question, we have $\alpha(t)+\lambda(s)\alpha'(s)=const$. Taking the derivative of both sides we have $\alpha'(s)+\lambda'(s)\alpha'(s)+\lambda(s)\alpha''(s)=0$ which is equal to $(1+\lambda'(s))\alpha'(s)+\lambda(s)\alpha''(s)=0$. Since $\alpha'(s)$ and $\alpha''(s)$ are linearly independent, we have $\lambda'(s)=-1$ and $\lambda(s)=0$ for every $s$ which I found strange, since the derivative of the zero function is zero. I need a clarification at this point and a hand to finish my attempt of solution.",['differential-geometry']
2468587,Is the set of rational number discrete or continuous?,"If the set of real numbers $\Bbb{R}$ is continuous, and the set of integer $\Bbb{Z}$ is a discrete set, then is the set of rational number $\Bbb{Q}$ continuous or discrete? My question is stated in the context of analysis. Sorry if I can’t state my problem clear, this question just passed my mind. If it is just a nonsense question, please tell me right away. Thank you very much.","['general-topology', 'real-analysis']"
2468601,What is the intuitive meaning of Expected Value?,"What exactly does this number mean? I am aware on how to calculate the them given the variables. I have watched several videos and articles about it but no one seems to explain it. Maybe I am just missing something and it is just a meaningless number? I watched this example about a survey of students that rate their class overall satisfactions. 1 - very dissatisfied and 5 very satisfied. x = 1,2,3,4,5 and the count in the order of x is count - 5,10,11,44,38 = 108 After calculating the E(X) = 3.7 I noticed it is weighing more towards the very satisfied side. What exactly is this number telling us aside from being just an average?","['descriptive-statistics', 'statistics', 'probability', 'statistical-inference']"
2468650,"Proving that any element of $\text{SL}(2,\mathbb{R})$ can be expressed as $\pm\exp(z)$.","I would like to show that any element $N\in\text{SL}(2,\mathbb{R})$ can be represented in the following form
\begin{align}
N=\pm\exp(z)~~~~\text{ for } ~~~~~z\in\mathfrak{sl}(2,\mathbb{R}).
\end{align}
The Lie algebra $\mathfrak{sl}(2,\mathbb{R})$ of $\text{SL}(2,\mathbb{R})$ is that of real traceless $2\times 2$ matrices. I (for personal reasons) choose to use  the basis
\begin{align}
\tau_1=\begin{pmatrix}0&&-1\\-1&&0\end{pmatrix},~~~\tau_2=\begin{pmatrix}1&&0\\0&&-1\end{pmatrix},~~~\tau_3=\begin{pmatrix}0&&1\\-1&&0\end{pmatrix}.
\end{align}
Any element  $z\in\mathfrak{sl}(2,\mathbb{R})$ can then be expressed as a linear combination of these matrices; $z=z^m\tau_m$ with $z^m$ the local coordinates of $\text{SL}(2,\mathbb{R})$ and I have used the Einstein summation convention. Thus, in this basis an arbitrary $z$ is 
\begin{align}
z=\begin{pmatrix} z_2&&z_3-z_1\\-z_1-z_3&&-z_2\end{pmatrix}.
\end{align} To compute the exponential first observe that $z^2=\omega^2 I$ where $\omega^2:=z_1^2+z_2^2-z_3^2$ and $I$ is the $2\times 2$ identity. I think we should split it into three cases where $\omega^2=0, \omega^2<0$ and $\omega^2>0$. I will only do the case $\omega^2>0$ for brevity. Computing the exponential explicitly we have
\begin{align}
\exp(z)&=\exp\bigg(\begin{pmatrix} z_2&&z_3-z_1\\-z_1-z_3&&-z_2\end{pmatrix}\bigg)\\
&=I+z+\frac{1}{2!}\omega^2I+\frac{1}{3!}\omega^2z+\frac{1}{4!}\omega^4I+\frac{1}{5!}\omega^4z+\cdots\\
&=\sum_{n=0}^{\infty}\frac{\omega^{2n}}{(2n)!}I+\sum_{n=0}^{\infty}\frac{\omega^{2n}}{(2n+1)!}z\\
&=\cosh(\omega)I+\frac{1}{\omega}\sinh(\omega)z\\
&=\begin{pmatrix} \cosh(\omega)+\frac{z_2}{\omega}\sinh(\omega)&&\frac{z_3-z_1}{\omega}\sinh(\omega)\\\\-\frac{z_3+z_1}{\omega}\sinh(\omega)&&\cosh(\omega)-\frac{z_2}{\omega}\sinh(\omega)\end{pmatrix}\tag{1}.
\end{align}
Now I need to show that any $N$ can be written as $\pm(1)$ but I am not sure how to do this part. I thought I could try and write 
\begin{align}
N=\begin{pmatrix} a&&b\\c&&d\end{pmatrix} ,~~~~ ad-bc=1
\end{align}
and solve the resulting system of equations but I don't think this is how it is done.","['matrices', 'matrix-exponential', 'lie-algebras', 'lie-groups']"
2468754,Not sure about one step in the proof that closed immersions are affine (Hartshorne 3.11b),"This question is about showing that if $i: Y \longrightarrow X$ is a closed immersion of schemes with $X = \text{Spec }A$ affine, then $Y$ is affine. This question has had a lot of attention on this site already, particularly here and a question of my own here . I also wanted to ask about a different approach to this question, which is why I am hoping it's not considered a duplicate. First of all I should state the definition of closed immersion I am working with A morphism $i: Y \longrightarrow X$ is called a closed immersion if $i$ induces a homeomorphism between $Y$ and a closed subset of $X$, and the corresponding morphism of sheaves $i^{\#}: \mathcal{O}_{X} \longrightarrow i_{*}\mathcal{O}_{Y}$ is surjective. I have also proved the following result independently of this exercise, which actually subsumes one of the hints given. In particular, I have proven the following If $f: X \longrightarrow Y$ is an affine morphism, then for any affine open $\text{Spec }B \subseteq Y$, the preimage $f^{-1}(\text{Spec }B)$ is affine in $X$. Having already proved this, my task is drastically reduced. Here is what I know so far, which seems to be the standard approach to the problem. Let $p \in Y$ be a point and let $\text{Spec }B$ be an affine neighbourhood of $p$ in $Y$. Then by definition of the subspace topology on $Y$, there is an open set $U$ of $X$ with $\text{Spec }B = Y \cap U$. Since $U$ is open in $X = \text{Spec A}$, we can find an $g \in A$ so that $p \in Y \cap D(g)$. Since $i^{-1}(D(g)) = Y \cap D(g)$, my entire task is now reduced to showing that $D(g) \cap Y$ is affine in $Y$, since then I can apply the above result on affine morphisms to see that $Y$ itself is affine. This is where I am slightly confused. I have that $$ i|_{\text{Spec B}}: \text{Spec }B\longrightarrow \text{Spec A} $$
corresponds to a morphism of rings, say
$$   \phi: A \longrightarrow B .         $$
Now it seems ""obvious"" to me, that $D(g) \cap Y$ is given by the affine set $\text{Spec }B_{\phi(g)}$. It seems to me that this could be argued in the usual way, by taking the fibered product
$$
\text{Spec }B \times_{\text{Spec }A} D(g) \simeq \text{Spec }\left( B \otimes_{A} A_{g}  \right) \simeq \text{Spec }(B_{\phi(g)}).
$$
My concern is whether this is rigorous in this context. I am just uncomfortable about the fact that we seem to have ""cheated"" by restricting $i$ to $\text{Spec B}$. Now the pullback isn't actually along $i$, but along $i|_{\text{Spec B}}$. Is this argument still valid here? Is that really all I have to say to show that $D(g) \cap Y$ is affine? I also wanted to ask about how to see this in a potentially more general setting. Earlier in Hartshorne, in Exercise 2.16(a), we learn the following definition If $X$ is a scheme and $f \in \Gamma(X, \mathcal{O}_{X})$ is a global section, then we define
  $$ X_{f} = \{ p \in X : f_{p} \not \in \mathfrak{m}_{p}   \}. $$ The exercise there is to show that if $U = \text{Spec }B$ is affine in $X$, then $X_{f} \cap U = D\left( \tilde{f} \right)$, where $\tilde{f} \in \Gamma(\text{Spec }B, \mathcal{O}_{X})$ is the restriction of $f$ to $\text{Spec }B$. It was suggested to me that if we generalize this exercise to the case where $\text{Spec }B$ is not a subscheme of $X$, but rather just any affine scheme with a morphism $\text{Spec }B \longrightarrow X$, then this intersection can be viewed as a fibered product, and the result is much more useful for the exercise I was trying to do above. This seems at least reasonable to me, since if $U = \text{Spec }B \subseteq Y$ was my affine scheme of the closed subscheme $Y$ defined above, then wanting to show that $Y \cap D(g)$ is affine seems very reminiscent of this exercise, although I can't see the details of how this works. So my question can be summed up as follows If $i: Y \longrightarrow X$ is our closed immersion defined above, then to what extend can the statement that $D(g) \cap Y$ is affine be regarded as a generalization of exercise 2.16(a) where instead of $\text{Spec }B \hookrightarrow X$ being an immersion, it is an arbitrary morphism?","['algebraic-geometry', 'closed-map', 'proof-verification', 'schemes', 'affine-schemes']"
2468770,Convex function at four points,"Let $f:\mathbb{R}\rightarrow\mathbb{R}$ be a convex function. Is it true that for any $x<y$, $$f(x)+f(y)\leq f(x-1)+f(y+1)?$$ Looking at graphs of convex functions, this is always true. But I don't see how it can follow from the definition of convex function
$$f(tx+(1-t)y)\le tf(x)+(1-t)f(y)$$
for $0<t<1$.","['algebra-precalculus', 'functions']"
2468801,Trace permutation of product of symmetric matrices,"It is well known that the trace of a product of matrices is invariant under cyclic permutations. However, in general this is not true for arbitrary permutations.
So, if $A,B,C$ are $n \times n$ matrices then
$\mathrm{Tr}(ABC)$ is not necessarily equal to $\mathrm{Tr}(ACB)$. However, if we assume $A,B,C$ to also be symmetric, then using the fact that the trace is invariant to taking transpose (as well as cyclic permutations) we obtain
$$\mathrm{Tr}(A^TB^TC^T) = \mathrm{Tr}(A^T(CB)^T) = \mathrm{Tr}((CB)^TA^T) =\mathrm{Tr}((ACB)^T) = \mathrm{Tr}(ACB).$$
And, in fact, this allows us to show that the trace of a product of 3 matrices is preserved by taking any permutation of the product. For products of more than 4 matrices, some permutations will not preserve the trace. Still, when all matrices involved in the product are symmetric there are more permutations preserving the trace, than just the cyclic permutations. Is there a complete characterization for which permutations preserve the trace of a product of $n$ symmetric matrices?","['matrices', 'permutations']"
2468842,"If $n$ birds are sitting in circle, each pecks its left or right bird with equal probability. What is the distribution of number of pecked birds?","If n birds are sitting in circle, each pecks its left or right bird with equal probability. What is the distribution of number of pecked birds? Note at least $\frac{n}{2}$ birds get pecked, so it cannot be binomial. Also note that analysis for number of unpecked birds is $\frac{n}{4}$ for $n > 2$, which is actually just a coincidence if you assume binomial. For $n=1$ and $n=2$ all birds are necessarily pecked. Also if there are $5$ birds a,b,c,d,e in order, if c is not pecked then both a and e must be pecked, so treating them as independent events are also not correct. The distribution looks like this for various values of $n$. (Divide by $2^n$ as to get probability) 1   {1 -> 2}
2   {2 -> 4}
3   {2 -> 6, 3 -> 2}
4   {2 -> 4, 3 -> 8, 4 -> 4}
5   {3 -> 10, 4 -> 20, 5 -> 2}
6   {4 -> 36, 5 -> 24, 6 -> 4}
7   {4 -> 14, 5 -> 70, 6 -> 42, 7 -> 2}
8   {4 -> 4, 5 -> 48, 6 -> 152, 7 -> 48, 8 -> 4}
9   {5 -> 18, 6 -> 168, 7 -> 252, 8 -> 72, 9 -> 2}
10  {6 -> 100, 7 -> 400, 8 -> 440, 9 -> 80, 10 -> 4}
11  {6 -> 22, 7 -> 330, 8 -> 924, 9 -> 660, 10 -> 110, 11 -> 2}
12  {6 -> 4, 7 -> 120, 8 -> 1020, 9 -> 1808, 10 -> 1020, 11 -> 120, 12 -> 4}
13  {7 -> 26, 8 -> 572, 9 -> 2574, 10 -> 3432, 11 -> 1430, 12 -> 156, 13 -> 2}
14  {8 -> 196, 9 -> 1960, 10 -> 6076, 11 -> 5936, 12 -> 2044, 13 -> 168, 14 -> 4}
15  {8 -> 30, 9 -> 910, 10 -> 6006, 11 -> 12870, 12 -> 10010, 13 -> 2730, 14 -> 210, 15 -> 2}
16  {8 -> 4, 9 -> 224, 10 -> 3696, 11 -> 15904, 12 -> 25880, 13 -> 15904, 14 -> 3696, 15 -> 224, 16 -> 4}
17  {9 -> 34, 10 -> 1360, 11 -> 12376, 12 -> 38896, 13 -> 48620, 14 -> 24752, 15 -> 4760, 16 -> 272, 17 -> 2}
18  {10 -> 324, 11 -> 6048, 12 -> 37296, 13 -> 87264, 14 -> 87768, 15 -> 36960, 16 -> 6192, 17 -> 288, 18 -> 4}
19  {10 -> 38, 11 -> 1938, 12 -> 23256, 13 -> 100776, 14 -> 184756, 15 -> 151164, 16 -> 54264, 17 -> 7752, 18 -> 342, 19 -> 2}
20  {10 -> 4, 11 -> 360, 12 -> 9780, 13 -> 77280, 14 -> 252360, 15 -> 369008, 16 -> 252360, 17 -> 77280, 18 -> 9780, 19 -> 360, 20 -> 4}
21  {11 -> 42, 12 -> 2660, 13 -> 40698, 14 -> 232560, 15 -> 587860, 16 -> 705432, 17 -> 406980, 18 -> 108528, 19 -> 11970, 20 -> 420, 21 -> 2}
22  {12 -> 484, 13 -> 14520, 14 -> 149556, 15 -> 638880, 16 -> 1294216, 17 -> 1292368, 18 -> 640200, 19 -> 148896, 20 -> 14740, 21 -> 440, 22 -> 4}
23  {12 -> 46, 13 -> 3542, 14 -> 67298, 15 -> 490314, 16 -> 1634380, 17 -> 2704156, 18 -> 2288132, 19 -> 980628, 20 -> 201894, 21 -> 17710, 22 -> 506, 23 -> 2}
24  {12 -> 4, 13 -> 528, 14 -> 21384, 15 -> 268752, 16 -> 1471932, 17 -> 3920928, 18 -> 5410160, 19 -> 3920928, 20 -> 1471932, 21 -> 268752, 22 -> 21384, 23 -> 528, 24 -> 4}
25  {13 -> 50, 14 -> 4600, 15 -> 106260, 16 -> 961400, 17 -> 4085950, 18 -> 8914800, 19 -> 10400600, 20 -> 6537520, 21 -> 2163150, 22 -> 354200, 23 -> 25300, 24 -> 600, 25 -> 2}
26  {14 -> 676, 15 -> 29744, 16 -> 461032, 17 -> 3123120, 18 -> 10626044, 19 -> 19311968, 20 -> 19318832, 21 -> 10620896, 22 -> 3125980, 23 -> 459888, 24 -> 30056, 25 -> 624, 26 -> 4}
27  {14 -> 54, 15 -> 5850, 16 -> 161460, 17 -> 1776060, 18 -> 9373650, 19 -> 26075790, 20 -> 40116600, 21 -> 34767720, 22 -> 16872570, 23 -> 4440150, 24 -> 592020, 25 -> 35100, 26 -> 702, 27 -> 2}
28  {14 -> 4, 15 -> 728, 16 -> 41132, 17 -> 752752, 18 -> 6218212, 19 -> 26242216, 20 -> 60849516, 21 -> 80226336, 22 -> 60849516, 23 -> 26242216, 24 -> 6218212, 25 -> 752752, 26 -> 41132, 27 -> 728, 28 -> 4}
29  {15 -> 58, 16 -> 7308, 17 -> 237510, 18 -> 3121560, 19 -> 20030010, 20 -> 69194580, 21 -> 135727830, 22 -> 155117520, 23 -> 103791870, 24 -> 40060020, 25 -> 8584290, 26 -> 950040, 27 -> 47502, 28 -> 812, 29 -> 2}","['probability', 'probability-distributions']"
2468863,What is the integral of $e^{\cos x}$,"Question: Find out $\displaystyle{\int e^{\cos x}~dx}$ . My Attempt: Let $\cos x = y$ . Hence $-\sin x\ dx = dy$ or $$dx = \displaystyle{\frac{-dy}{\sin x}=\frac{-dy}{\sqrt{1-\cos^2x}}=\frac{-dy}{\sqrt{1-y^2}}}$$ So $$\begin{align}\int e^{\cos x}~dx &= \int e^y\left(\frac{-dy}{\sqrt{1-y^2}}\right)\\
&=-\int\frac{e^y}{\sqrt{1-y^2}}~dy
\end{align}$$ This integral is one I can't solve. I have been trying to do it for the last two days, but can't get success. I can't do it by parts because the new integral thus formed will be even more difficult to solve. I can't find out any substitution that I can make in this integral to make it simpler. Please help me solve it. Is the problem with my first substitution $y=\cos x$ or is there any other way to solve the integral $\displaystyle{\int\frac{e^y}{\sqrt{1-y^2}}~dy}$ ?","['indefinite-integrals', 'integration', 'calculus']"
2468873,"A countable dense set in $L^p[a,b]$","I know $L^p[a,b]$ is separable for $1\leq p< \infty$, but I am not able to find a countable dense set in it. Please give some example.","['functional-analysis', 'normed-spaces', 'lp-spaces', 'separable-spaces']"
2468878,"When are $L^1(X,{\mathcal X},\mu)$ and $L^\infty(X,{\mathcal X},\mu)$ reflexive?","Terence Tao's notes on ""Duality and the Hahn Banach theorem want me to show: Exercise 17: Show that any closed subspace of a reflexive space is again reflexive.   Also show that a Banach space $X$ is reflexive if and only if its dual is reflexive.  Conclude that if $(X,{\mathcal X}, \mu)$ is a measure space which contains a countably infinite sequence of disjoint sets of positive measure, then $L^1(X,{\mathcal X},\mu)$ and $L^\infty(X,{\mathcal X},\mu)$ are not reflexive.  (Hint: Reduce to the $\sigma$-finite case.  $L^\infty$ will contain an isometric copy of $\ell^\infty({\Bbb N})$.) My question is about the last part of the exercise. Actually, I have tried to construct a counterexample. Consider the real numbers with the borel sigma algebra. Endow the space with the measure $\mu$ such that $\mu(E)$ is zero if the $E$ does not contain an integer and is $\infty$ is $E$ contains an integer. We can see that this space contains countable many sets of positive measure, namely each singleton $\{n\}, n\in \Bbb Z$ has positive measure. Now, we consider $L^1$ on this space. Any $f\in L^1$ has to be identically zero on $\Bbb Z$ to remain integrable. Since, all the measure is concentrated on $\Bbb Z$, $f$ has to be zero almost everywhere. Hence, the only element of $L^1$ is the identically zero function (Functions equal almost everywhere represent the same element). Since $L^1=\{0\}$, $(L^1)^*=\{0\}$ and $(L^1)^{**}=\{0\}$. But now, $L^1$ is reflexive. What is the mistake here?","['banach-spaces', 'duality-theorems', 'functional-analysis', 'lp-spaces', 'measure-theory']"
