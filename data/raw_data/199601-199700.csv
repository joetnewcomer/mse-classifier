question_id,title,body,tags
3888916,Check on differentiability of a function,"I need a check on the following exercise: Consider the following function $$
f(x,y)=
\begin{cases}
\frac{x^3 y}{x^2 + y^4} \quad (x,y) \ne (0,0) \\
0\quad \quad (x,y)=(0,0)
\end{cases}
$$ determine where the function is differentiable. I checked the function is continuous over the whole $\mathbb{R}^2$ and that the derivatives $\partial_x f(0,0)=\partial_y f(0,0)=0$ . Differentiability: first of all, for any point $(x,y)\ne (0,0)$ the partial derivatives are continuous at $(x,y)$ and they exist in a neigbourhood of $(x,y)$ . The tricky part is for $(x,y)=(0,0)$ . There I know only the value of the derivatives at $(0,0)$ but I have no other information, therefore I have to study the following limit: $$\lim_{(h,k) \rightarrow (0,0)} \frac{f(h,k)}{\sqrt{h^2+k^2}}$$ I note that $$|\frac{h^3 k}{(h^2 + k^4) \sqrt{h^2+k^2}}| = |\frac{h^2 \cdot h k}{(h^2 + k^4) \sqrt{h^2+k^2}}| $$ and since $$|\frac{h^2}{h^2 + k^4}|<1$$ I have $$|\frac{h^2 \cdot h k}{(h^2 + k^4) \sqrt{h^2+k^2}}|<|\frac{hk}{\sqrt{h^2+k^2}}| < |\frac{hk}{|h|}| =_{\text{h} \ne 0} |k|$$ (if $h=0$ then the limit is identically $0$ ) Now, as $(h,k) \rightarrow (0,0)$ the r.h.s goes to $0$ and hence the limit is $0$ and the function is differentiable. Therefore the function is differentiable on the whole $\mathbb{R}^2$ , right? is everything correct","['multivariable-calculus', 'limits', 'calculus', 'derivatives']"
3889010,Expected number of maximum difference between heads and tails,"Let's say a fair coin is tossed $n$ times. Let $H(i)$ denote the total number of heads by the $i$ -th toss and $T(i)$ denote the total number of tails by the $i$ -th toss. Define $D(i) = |H(i) - T(i)|$ , the difference at $i$ -th toss. The maximum is defined as $M(n) = max^n_{i=1}D(i)$ . Now, what'd be an asymptotic bound for $E(M(n))$ ?","['random-walk', 'probability-theory', 'probability']"
3889038,How to get the jacobian of this change of variables?,"I am reading an article where we have $$\iint_{S^2\times\mathbb{R}^3}f(w,v)\,dw\,dv$$ where $w\in S^2$ and $v\in\mathbb{R}^3$ are variable vectors. A change of variable was done $(w,v)\mapsto(p,q)$ where $$p=(v\cdot w)w$$ and $$q=v-p=v-(v\cdot w)w.$$ That is, $p$ is the projection of $v$ on $w$ , and $q$ is the projection of $p$ on $w^\perp$ , where $w^\perp$ is the rotation of $w$ in the plane $\{w,v\}$ by $\pi/2$ . Then $p\in\mathbb{R}^3$ and $q\in\{p\}^\perp$ . They computed the Jacobian to be $$\,dw\,dv=\frac{2}{p^2\sin(p,p+q)}\,dp\,dq.$$ Does anyone have an idea how to compute this Jacobian explicitly? The article can be found here The part I am asking about is in page 12 proposition 5. It has to be related to spherical coordinate, but since $\omega$ is a vector I don't understand how they compute the Jacobian.","['jacobian', 'multivariable-calculus', 'change-of-variable', 'multiple-integral']"
3889072,What is the geometric meaning of this vector equality? $\vec{BC}\cdot\vec{AD}+\vec{CA}\cdot\vec{BD}+\vec{AB}\cdot\vec{CD}=0$,"I was doing some exercises for linear algebra. One of them was to prove that for any four points $A, B, C, D \in \mathbb{R}^3$ the following equality holds: $$\overrightarrow{BC} \cdot \overrightarrow{AD}\ +\ \overrightarrow{CA} \cdot \overrightarrow{BD}\ +\ \overrightarrow{AB} \cdot \overrightarrow{CD}\ = 0$$ The proof is easy; you just make three vectors starting in $A$ and then see that all the terms cancel out. My question is: what is the geometric interpretation of this equality? How can I visualize it or understand its deeper meaning? Does this equality have a name or where can I read more about it? I'm asking this because it turns out that it is not just a random equality and is rather useful. For example, if we want to prove the existence of orthocenter, we can do it surprisingly easily and quickly using this equality.","['vectors', 'linear-algebra', 'vector-spaces']"
3889145,"What's the mistake in the integration of $\int \sqrt{1+4t^2}\,dt $?","I am trying to solve the following irrational integral $I=\int \sqrt{1+4t^2}\,dt $ Doing the change: $ t=\frac{1}{2}\sinh(x)$ , $dt= \frac{1}{2}\cosh(x)$ $I=\int \sqrt{1+\sinh^2x}(\frac{1}{2}\cosh x)\,dx =\int \sqrt{\cosh^2x}(\frac{1} {2}\cosh x)\,dx = \frac{1}{2}\int{\cosh^2x}\,dx$ Doing $\cosh x=\frac{e^x+e^{-x}}{2}$ $I=\frac{1}{2}\int{ (\frac{e^x+e^{-x}}{2}})^2 \,dx$$=\frac{1}{8}\int{ (e^{2x}+e^{-2x}+2}) \,dx$ $=\frac{1}{16} (e^{2x}-e^{-2x}+4x)$ from $ t=\frac{1}{2}\sinh(x)$ -> $x= arcsinh(2t)$ and $4t=e^x-e^{-x}$ so $16t^2 +2=e^{2x}-e^{-2x}$ then
$I=\frac{1}{16} (e^{2x}-e^{-2x}+4x)=\frac{1}{16} (16t^2 +2+4arcsinh(2t))$$ I saw this solved somewhere else using another method, so I know the $16t^2 +2 $ part of the answer  is wrong, However I can't spot my mistake. Can you spot it?","['integration', 'indefinite-integrals', 'calculus']"
3889146,Riemann-Stieltjes integral of simple functions,"I quote Øksendal (2003) . Let us consider a probability space $\left(\Omega,\mathbb{P},\mathcal{A},\right)$ and a class of functions $f:\left[0,\infty\right]\times\Omega\mapsto\mathbb{R}$ . For $0\le
S<T$ , $\left(B(t)\right)_{t\ge0}$ a Brownian motion and $f(t,\omega)$ given, we want to define: $$\int_S^T f(t,\omega)dB(t)(\omega)$$ It is reasonable to start with a definition for a simple class of functions $f$ and then extend by some approximation procedure. First assume that $f$ has the form: $$\phi(t,\omega)=\sum_{j\ge0}e_j(\omega)\cdot1_{[j\cdot2^{-n}, (j+1)2^{-n})}(t)$$ where $1$ denotes the indicator function and $n$ is a natural number. For such functions, it is reasonable to define : $$\int_S^T\phi(t,\omega)dB_t(\omega)=\sum_{j\ge0}e_j(\omega)\left[B_{t_{j+1}}-B_{t_j}\right](\omega)\tag{1}$$ where : $$t_k=t_k^{(n)}=\begin{cases}k\cdot 2^{-n}\hspace{0.3cm}\text{if } S\le k\cdot 2^{-n}\le T\tag{2}\\ S\hspace{0.3cm}\text{if } k\cdot 2^{-n}<S\\
T\hspace{0.3cm}\text{if } k\cdot 2^{-n}>T
\end{cases}$$ My doubts concern the part in italics . Namely: Questions Why, according to $(1)$ : \begin{align}\int_S^T\phi(t,\omega)dB_t(\omega)&=\int_S^T\sum_{j\ge0}e_j(\omega)\cdot1_{[j\cdot2^{-n}, (j+1)2^{-n})}(t)dB_t(\omega)\\&=\sum_{j\ge0}e_j(\omega)\left[B_{t_{j+1}}-B_{t_j}\right](\omega)\end{align} ? Is that due to the fact that $\sum_{j\ge0}e_j(\omega)\cdot1_{[j\cdot2^{-n}, (j+1)2^{-n})}(t)$ do not depend on the variable of integration $B_{t}(\omega)$ , hence they go outside sign of integration and one has: \begin{align}\int_S^T\phi(t,\omega)dB_t(\omega)&=\int_S^T\sum_{j\ge0}e_j(\omega)\cdot1_{[j\cdot2^{-n}, (j+1)2^{-n})}(t)dB_t(\omega)\\&=\sum_{j\ge0}e_j(\omega)\left[B_{t_{j+1}}-B_{t_j}\right](\omega)\end{align} with $t_k$ as specified in $(2)$ and $\sum_{j\ge0}\left[B_{t_{j+1}}-B_{t_j}\right]=B_{T}-B_{S}$ ? Besides, could you please detail the reason why $(2)$ is defined that way? In particular, is there in place the choice of left-end point of every time interval? Why does the value $t_k$ depend on whether $k\cdot2^{-n}$ is positioned? What I would expect instead is something like: $$t_k=t_k^{(n)}=\begin{cases}t_k\hspace{0.4cm}\text{if } k\cdot 2^{-n}\le t_k \le (k+1)\cdot2^{-n}\tag{2.bis}\\ 0\hspace{0.5cm}\text{otherwise}
\end{cases}$$","['characteristic-functions', 'proof-explanation', 'simple-functions', 'riemann-integration', 'probability-theory']"
3889147,Proving $\mu$ is a measure on $A$ iff for every decreasing sequence in $A$ $\mu(\cap_{n=1}^{\infty} E_n)= \lim_{n\to \infty} \mu(E_n)$,"Let $(X,A)$ a measurable space. $\mu: A\to [0,\infty]$ satisfying: $\mu(X)<\infty$ $\mu(\emptyset)=0$ $\forall{E,F}\in{A}$ disjoint sets, $\mu(E\cup F)=\mu(E)+\mu(F)$ Prove: $\mu$ is a measure on $A$ iff
for every deceasing sequence $E_n$ in $A$ $\mu(\cap_{n=1}^{\infty} E_n)= \lim_{n\to \infty} \mu(E_n)$ . First: $\mu (\emptyset)=0$ (given).
The forward case is obvious since $\mu$ is a measure by assuming, and $\mu(X) < \infty$ implies that $\mu(E) <\infty$ for all $E\in{A}$ .
So using a theorem we finish it. The second condition is to show that for a sequence of disjoint sets $F_n \in{A}$ , $\mu(\cup_{n=1}^{\infty} F_n) =\sum_{n=1}^{\infty} \mu(F_n)$ . Let's define a new decreasing sequence $E_n$ . $E_n=X\setminus (\cup_{i=1}^{n} F_i)=\cap_{i=1}^{n} F_i
^{c}$ . $\mu(X)=\mu(E_n\cup E_n^{c})=(by 2)=\mu(E_n)+\mu(E_n^{c})$ . $\mu(E_n^{c})=\mu(\cup_{i=1}^{n} F_i)=\mu(X)-\mu(\cap_{i=1}^{n} F_i^{c})$ Now let n approaches infinity so: $\mu(\cup_{i=1}^{\infty} F_i)=\mu(X)-lim_{n\to \infty} \mu(\cap_{i=1}^{n} F_i^{c})=\mu(X)-lim_{n\to \infty} \mu(X\setminus \cup_{i=1}^{n} F_i)$ Then can I use that $\mu(lim)=lim(\mu)$ ? (Then I get $\mu(\cup_{i=1}^{\infty} F_i)=\mu(X)-\mu(lim_{n\to \infty} X\setminus {\cap_{i=1}^{n} F_i)}=\mu(X)-\mu(lim_{n\to \infty} \cup_{i=1}^{n}  F_i)$ . So I can reduce $\mu(X)$ with its limit since $\mu(X)$ is finite (by 2), and use 3 after it. Can someone help in this.","['measure-theory', 'functional-analysis', 'real-analysis']"
3889176,Necessary but not sufficient,"This question has already been asked here twice, namely here and here , but none of the answers address my specific question, except probably for this answer , which comes close. So, using the notation of the close answer, I don't understand why I have to rule out the tuples $(T,T)$ and $(F,F)$ . Let's call the sentence ""Q is necessary but not sufficient for P"" R. As for $(F,F)$ , if P is false when Q is also false, this should result in R = true; since Q is necessary for P, so the absence of Q should imply the absence of P. Why would I want R to be false in this case? And for $(T,T)$ , I will imagine a more complete picture. Let's say that P depends on Q and some other factors, collectively named W. Now, we should split the row $(T,T)$ into 2, one with W false, and another with W true. In the case with W true, R should evaluate to T, and in the case with W false, R should evaluate to false. On what basis, then, should we decide to rule out $(T,T)$ in the original statement! In my opinion, the row with $(T,T)$ should be undecidable. I would be grateful if someone could explain to my why the correct answer is $¬(¬r∧¬p)→¬q∧¬((¬r∧¬p)→q)$ in a way other that ""is necessary"" translates to so and so and ""is sufficient"" translates
to so and so, so the conjunction of the first with the negation of the
second gives the correct answer. Thanks","['propositional-calculus', 'predicate-logic', 'logic', 'discrete-mathematics']"
3889180,Singular Points of $\sin(x)y''+y=0$. Review my work,"I have to classify the singular points of the second order $$\sin(x)y´´+y=0$$ Where, in its standar form: $$y´´+\dfrac{1}{\sin(x)}y=0$$ With $$P(x)=0,  Q(x)=\dfrac{1}{\sin(x)}$$ As far as I can tell, the singular points are $$x_0=n\pi, \forall n\in \mathbb{Z}$$ So, there are infinite singular points? Which all of them are irregular since there is at most 1 power of $(x-x_0)$ in $P(x)$ (there is non) and there is not a power of 2 in $Q(x)$ . I other words, both $(x-x_0) P(x)$ remains finite as $x\to n\pi$ but $(x-x_0)^2 Q(x)$ doesn´t. $$\lim_{x\to n\pi}{(x-n\pi)P(x)}=\lim_{x\to n\pi}{0}=0$$ and $$\lim_{x\to n\pi}{(x-n\pi)^2Q(x)}=\lim_{x\to n\pi}{(x-n\pi)^2\dfrac{1}{\sin(x)}}$$ Does not exist.",['ordinary-differential-equations']
3889198,How do you define “independence” in combinatorics?,"I feel like most definitions of “independence” are circular. Consider how we count the number of cards in a standard deck of cards: $|S \times R| = |S||R|$ , where $S$ is the set of suits, and $R$ is the set of ranks. That is, $$S = \{\text{Hearts, Diamonds, Spades, Clubs}\}$$ and $$R = \{ 2,3,\dots,\text{King},\text{Ace} \}.$$ We know that $|S| = 4$ and $|R| = 13$ , so $|S \times R| = |S||R| = 4 \cdot 13 = 52.$ In such an example, we define that they are independent, because they are disjoint subsets. But do we know that? In this example, it is “obvious.” What about examples where it is not obvious?","['permutations', 'combinations', 'combinatorics', 'discrete-mathematics', 'probability']"
3889209,"Confused on proof that every group of order $p^2$, $p$ prime is isomorphic to $\mathbb{Z}_{p^2}$ or $\mathbb{Z}_{p}\oplus \mathbb{Z}_{p}$","Every group of order $p^2$ , $p$ prime is isomorphic to $\mathbb{Z}_{p^2}$ or $\mathbb{Z}_{p}\oplus \mathbb{Z}_{p}$ I am confused about two parts of this proof. Proof:Assume every nonidentity element of this group $G$ has order $p$ . Then $\langle a\rangle$ is normal otherwise there is an element $b$ in $G$ such that $bab^{-1} \notin \langle a\rangle$ Here is my first source of confusion. if $\langle a\rangle$ is not normal I would suspect there is an element $b$ in $G$ with $ba^{i}b^{-1} \notin \langle a\rangle,\text{for some}\space i \in \mathbb{Z}$ . Why does $bab^{-1} \notin \langle a\rangle$ necessarily hold with $a$ ? Next part of confusion
Since $\langle a\rangle \cap \langle bab^{-1}\rangle =\{1\}$ the distinct left cosets of $\langle bab^{-1}\rangle$ are $\langle bab^{-1}\rangle,a\langle bab^{-1}\rangle,...,a^{p-1}\langle bab^{-1}\rangle$ is this because there must be $p$ distinct cosets and there union must be $G$ , so this must be all of the cosets ?","['proof-explanation', 'group-theory', 'abstract-algebra', 'finite-groups']"
3889261,"Extending the action $S_5$ on $2$-subsets of $\{1,\cdots,5\}$ to an action of $S_6$.","The symmetric group $S_5$ acts on the set $\binom{5}{2}$ of ten $2$ -subsets of $[5]=\{1,\cdots,5\}$ . In The Finite Simple Groups (Wilson), problem 2.21 asks the reader to extend the group action $S_5\to S_{10}$ to an action $S_6\to S_{10}$ . There's probably a ""hands-on"" way to do this by writing down explicit cycle notations and relations and such, but is there a conceptual reason for this? Is this explained by some exceptional object, maybe like ${\rm Out}\,S_6$ somehow? (For comparison, problem 2.24 asks to show things about a group generated by a couple of given permutations in $S_8$ , without mentioning it's just ${\rm PSL}_2(\Bbb F_7)$ acting on the projective line $\Bbb F_7\Bbb P^1$ , so hiding the story behind a problem seems like something the text would do.)","['exceptional-isomorphisms', 'group-theory', 'group-actions', 'finite-groups']"
3889303,Solve the recurrence relation: $na_n = (n-4)a_{n-1} + 12n H_n$,"I want to solve $$ na_n = (n-4)a_{n-1} + 12n H_n,\quad n\geq 5,\quad a_0=a_1=a_2=a_3=a_4=0. $$ Does anyone have an idea, what could be substituted for $a_n$ to get an expression, which one could just sum up? We should use $$ \sum_{k=0}^n \binom{k}{m} H_k = \binom{n+1}{m+1} H_{n+1} - \frac{1}{m+1} \binom{n+1}{m+1} $$ to simplify the result.","['harmonic-numbers', 'recurrence-relations', 'discrete-mathematics', 'recursion']"
3889379,"Let $G$ be a finite abelian group, and let $n$ divide $|G|$. Let $m$ be the number of solutions of $x^n=1$. Prove that $n\mid m$.","Let $G$ be a finite abelian group, and let $n$ divide $|G|$ .  Let $m$ be the number of solutions of $x^n=1$ .  Prove that $n\mid m$ . My attempt It's tempting to find a way to use Lagrange's theorem.  Maybe something here is a subgroup of something else?  We can fix $n$ and take the subgroup of $G$ of all elements which solve $x^n=1$ .  Proof that this is a subgroup:  Inverses of solutions are always solutions.  Because the group is abelian, products of solutions are solutions.  QED. Great, so it's a subgroup, so $m$ divides the order of $G$ .  So does $n$ .  I'm not sure that this really got me anywhere.  It'd be nice if there were some relevant subgroup of order $n$ . Being finite and abelian then it has a representation as $G\cong C_{p_1^{n_1}}\times\dots\times C_{p_k^{n_k}}$ , a product of cyclic groups of prime power order.  The solutions are exactly the product of solutions ""in each factor"", i.e. solutions of the form $\langle e, \dots, e, x, e, \dots, e\rangle$ where $x\in C_{p_i^{k_i}}$ for some $i$ .  So perhaps something comes from thinking about the number of solutions to $x^n=1$ where $x$ is taken from $C_{p_i^{k_i}}$ . Again this is a subgroup so the number of solutions divides $p_i^{k_i}$ , and $p_i^{k_i}$ divides $|G|$ . And $n$ divides the order of $G$ .  But at this point I'm not sure whether I'm on a productive path, since these facts don't seem to be enough to show that $n|m$ . In fact the more that I think about how $n$ is so-to-speak missing factors from $|G|$ the more I think that finding numbers which divide $|G|$ just isn't a productive path.","['abelian-groups', 'group-theory', 'abstract-algebra', 'finite-groups']"
3889382,Bound on approximation error of Bernstein polynomial,"Consider a continuous function $f: [0,1] \to [0,1]$ . Let $B_n$ be its $n$ -th order Bernstein polynomial , $$
B_n(x) = \sum_{k=0}^n f\left(\frac{k}{n}\right) \binom{n}{k}x^k (1-x)^{n-k}.
$$ As is well known, $B_n(x) \rightarrow f(x)$ uniformly on $[0,1]$ as $n \rightarrow \infty$ . I am interested in bounding the approximation error $B_n(x)-f(x)$ . This reference , section 4, contains one such bound: $$
|B_n(x)-f(x)| \leq \left( 1 + \frac{1}{4n^2} \right) \omega(n^{-1/2})
$$ where $\omega$ is the modulus of continuity of $f$ , that is, $\omega(\delta) = \sup_{|x-x'|<\delta} |f(x)-f(x')|$ . My questions are Is there any reference or proof to that result? Are there any similar results that provide a bound on $|B_n(x)-f(x)|$ ?","['approximation-theory', 'reference-request', 'real-analysis', 'functions', 'polynomials']"
3889383,Example 11.27 in Lee's Introduction to Smooth Manifolds,"In Lee's ""Introduction to Smooth Manifolds"" there is the following quoted piece of text: Example 11.27: Let $F : \mathbb{R}^3 \to \mathbb{R}^2$ be the map given by $$(u, v) = F(x, y, z) = (x^2y, y\sin z)$$ and let $\omega \in \mathfrak{X}^*(\mathbb{R}^2) $ be the covector field $$\omega = u dv + v du$$ ... Now my interpretation of this is that the author is defining the function $u = \pi_1 \circ F : \mathbb{R}^3 \to \mathbb{R}$ where $\pi_1 : \mathbb{R}^2 \to \mathbb{R}$ is the standard projection function onto the first coordinate. And similar the author is defining $v = \pi_2 \circ F : \mathbb{R}^3 \to \mathbb{R}$ . So essentially the author is saying that $u$ and $v$ are the first and second component functions of $F$ respectively in my interpretation. But if my interpretation is correct then $du$ and $dv$ are covector fields on $\mathbb{R}^3$ and not on $\mathbb{R}^2$ . What is my mistake here and what is the correct interpretation of this piece of text?","['smooth-manifolds', 'differential-geometry']"
3889512,Can a triangle be divided into four similar triangles such that not all four of the triangles are congruent to each other?,"I understand that you can divide a triangle into four congruent triangles by connecting the midpoints of each side. Can ANY NON-EQUILATERAL triangle be divided into four similar triangles with the restriction that not all four triangles can be congruent to each other?
As I explore this question, I keep running into dead ends, and I ask if any of you can help. EDIT: You guys revealed that there are multiple ways to do this with right triangles. I've been experimenting with a general case and right triangles, but the closest I've gotten is splitting the triangle three times (on triangle ABC, drawing a line from Angle BAC that is perpendicular to Side BC, calling the point of intersection on Line BC Point D, then drawing lines from Angles ADB and ADC to be perpendicular with Lines AB and AC, respectively) yet I cannot prove that the triangles within ACD are similar to the triangles within ABD unless they are all within a right triangle. How to proceed?","['triangles', 'geometry']"
3889555,Find the coefficient of $x^n$ in the generating functions: $g(x) = \frac{x^3}{(1+x)^5 (1−x)^6}$,"One of the problems in my Discrete Math course states that we need to find the coefficient of $x^n$ in generating function $g(x) = \frac{x^3} {(1+x)^5 (1−x)^6}$ I separated $g(x) = \frac{x^3} {(1+x)^5 (1−x)^6}$ into $x^3$ * $\frac{1}{(1+x)^5}$ * $\frac{1}{(1-x)^6}$ Then got $f(x) = x^3 * \sum_{k=0}^\infty \binom{n+4}{4}(-1)^kx^k * \sum_{k=0}^\infty \binom{n+5}{5}x^k$ I dont know what to do from here, can you tell me what is the next step?","['discrete-mathematics', 'generating-functions']"
3889700,A second order ODE involving Jacobi elliptic functions,"I have recently got stuck on this ODE in my studies of rogue waves on elliptic backgrounds: $$
y'' + q(x) y' + w(x) y = 0
$$ where $$
q(x) = m \frac{sn(x|m)\,cn(x|m)}{dn(x|m)}, \\
w(x) = \left(\lambda^2 + dn(x|m)^2 - i m \lambda \frac{sn(x|m)\,cn(x|m)}{dn(x|m)} \right)
$$ The parameter $\lambda \in \mathbb{C}$ and $m \in [0,1]$ is the elliptic parameter of the Jacobi elliptic functions $\text{dn}(.|.), \, \text{cn}(.|.)$ and $\text{sn}(.|.)$ . I am only interested in $x \in \mathbb{R}$ . Note that (according to Mathematica), the period of $q(x)$ is $4K(m)$ where $K$ is the complete elliptic integral of the first kind. The real and imaginary parts of $w(x)$ have the same period as $q(x)$ . The initial value problem: $$
y(0) = 2i\sin(\alpha),\\
y'(0) = 2(\lambda i \sin(\alpha) + i \cos(\beta))
$$ where $\alpha, \beta \in \mathbb{C}$ are some parameters that depend on $\lambda$ in some complicated way. Are there any specific tricks to help me find an analytical solution for this ODE? Does anyone have any pointers? I have checked a few handbooks on Jacobi elliptic functions but haven't had much luck, I have no formal training in elliptic functions and not too much in ODEs. I have solved it numerically but I'm wondering if it's possible to solve it analytically for completeness. EDIT: I have taken a look at this paper but it's a little too complicated for me. However, based on the transformation they present in equation 15: $$
y(x) = \exp\left(-\frac{1}{2}\int q(x)  dx\right)
$$ we can reduce the first equation to: $$
u''(x) - r(x) u(x) = 0
$$ where $$
r(x) = \frac{1}{2} q'(x) + \frac{1}{4} q^2(x) - w(x)
$$ According to Mathematica: $$
r(x) = \frac{3 (m-1)+\text{dn}(x|m) \left(-\text{dn}(x|m) \left(3 \text{dn}(x|m)^2+4 \lambda ^2+m-2\right)+4 i m \text{cn}(x|m) \text{sn}(x|m)\right)}{4 \text{dn}(x|m)^2}
$$ I have expanded this in a Laurent series as suggested in the comments, but I am not sure how to properly manipulate the product of the series of $r(x) u(x)$ on the RHS of $u'' = r(x) u$ .","['elliptic-functions', 'ordinary-differential-equations']"
3889738,How to reduce to affine case to determine whether a given functor is representable,"[Definition] These are the contents of Gortz and Wedhorn , Algebraic Geometry. $\widehat{(Sch)}$ is the category of functors $(Sch)^{opp} \rightarrow (Sets)$ For scheme $X$ , define the functor $h_X := Hom(\_\_ , X)$ and identify $X$ with $h_X$ in $\widehat{(Sch)}$ A morphism $f : F \rightarrow G$ of functors in $\widehat{(Sch)}$ is called representable if for all schemes $X$ and all morphisms $g : X \rightarrow G$ in $\widehat{(Sch)}$ the functor $F \; {\times_G} X$ is representable An open subfunctor $F'$ of $F$ is a representable morphism $f:F' \rightarrow F$ that is an open immersion. A family $(f_i:F_i \rightarrow F)_{i \in I}$ of open subfunctors is called a Zariski open covering of $F$ if for every $S$ -scheme $X$ and every $S$ -morphism $g:X \rightarrow F$ the images of the $(f_i)_{(X)}$ form a covering of $X$ , where $(f_i)_{(X)} : F_i \; \times_F X \rightarrow X $ is the second projection map of fiber product. [Theorem 8.9] Let $S$ be a scheme and $F:(Sch/S)^{opp} \rightarrow (Sets)$ be a functor such that (i) $F$ is a sheaf for the Zariski topology (ii) $F$ has a Zariski open covering $(f_i:F_i \rightarrow F)_{i \in I}$ by representable functors $F_i$ . Then $F$ is representable. [Theorem 11.1] Let $X$ be a scheme and let $\mathscr{R}$ be a quasi-coherent $\mathscr{O}_{X}$ -algebra. Then there exsist an $X$ -scheme $\text{Spec}(\mathscr{R})$ which is represents the functor $$ F: (Sch/X)^{opp} \rightarrow (Sets), \hspace{1cm} (f:T \rightarrow X) \mapsto \text{Hom}_{(\mathscr{O}_X-Alg)}(\mathscr{R},f_{*}\mathscr{O}_T)$$ [Question] In the proof of the theorem 11.1 , they say that "" To show that $F$ is representable, by theorem 8.9 we may assume that $X=\text{Spec}{A}$ is affine."" I wonder how I can exactly take a family of open subfunctors $(f_i:F_i \rightarrow F)_{i \in I}$ so that we can assume $X$ is affine. Let $X = \bigcup U_i$ and $U_i = \text{Spec}A_i$ . $$ F_i: (Sch/X)^{opp} \rightarrow (Sets), \hspace{1cm} (f:T \rightarrow X) \mapsto \text{Hom}_{(\mathscr{O}_{U_i}-Alg)}(\mathscr{R}\vert_{U_i},f_{*}\mathscr{O}_T)$$ Then, are these $F_i$ open subfunctors of $F$ ? I can't prove this $(f_i:F_i \rightarrow F)_{i \in I}$ is a Zariski open covering of $F$","['zariski-topology', 'algebraic-geometry', 'representable-functor', 'sheaf-theory']"
3889744,Show that the rank of a symmetric matrix is the maximum order of a principal sub-matrix which is invertible,"The question is this- Show that the rank of a symmetric matrix is the maximum order of a principal sub-matrix which is invertible. I can show that there cannot exist a sub-matrix with rank more than the actual rank of the matrix. But I cannot show the other way around, i.e when the rank of the actual matrix is $r$ , then there exist a principal sub-matrix of the same rank (though I can prove that there exist a sub-matrix with rank $r$ ). I was thinking like this: if the rank of the matrix is $r$ , we can find r linearly independent rows of the matrix, say $a_1, a_2, ..., a_r$ -th rows are linearly independent. Then the corresposding columns $a_1^t, a_2^t, ..., a_r^t$ are also linearly independent. But how to show that the submatrix that they produce is of rank r? I hope my question is clear. Any hints or help would be highly appreciated.","['matrices', 'linear-algebra', 'symmetric-matrices']"
3889782,Can a D.E. still be defined even if terms are unbounded?,"$$(1 - x^2)y'' - 2xy' + l(l + 1)y = 0, -1 \leq x \leq 1$$ I want to go ahead and use the Sturm-Liouville theorem to prove that this equation's eigenstates are orthogonal, but it's not a given that $y'$ is bounded at $a$ or $b$ , only that the D.E. is defined over $[-1,1]$ . Is that sufficient?","['sturm-liouville', 'ordinary-differential-equations']"
3889784,Is Gower's Distance a metric?,"A novice here My previous question was closed due to inadequate details So here I've added more details A metric should basically satisfy 3 properties Distance is equal to zero if and only if $x$ is equal to $y$ ( $d(x,y)=0 ⇔ x=y$ )) Distance from $x$ to $y$ is the same as distance from $y$ to $x$ ( $d(x,y)=d(y,x)$ ) Distance should satisfy the triangular inequality ( $d(x,y)\leq d(x,z) +d(z,y)$ ) I already know that Gower's distance satisfy the first 2 properties to be a metric, but I want to know whether it satisfies the triangular inequality property. The reason I want to know this, is because all metric spaces are Hausdorff spaces, and I want use the Gowers distance in order to find the Hausdorff distance for 2 sets of points. In my case, a point contains data of mixed types (logical, categorical & numeral), and therefore I have to use the Gowers distance. Any help would be appreciated. Thank You! Edit: According to a suggestion on the comments, here is the formal definition of a metric A metric on a set X is a function (called the distance function or simply distance) $d : X × X → R$ (where R is the set of real numbers). For all $ x, y, z $ in $X$ , this function is required to satisfy the following conditions: $d(x, y) ≥ 0$ (non-negativity) $d(x, y) = 0$ if and only if $x = y $ $d(x, y) = d(y, x) $ (symmetry) $d(x, z) ≤ d(x, y) + d(y, z) $ Note that the first condition is implied by the others.","['statistics', 'mixing-variables', 'metric-spaces', 'hausdorff-distance']"
3889851,"Existential Notation: Is ""$\exists mn$"" the same as ""$\exists m\exists n$""?","I'm doing an exercise for Discrete Mathematics, chapter Logic, topic Quantifiers. However, I never seen this kind of notation: "" $\exists mn$ "". Is "" $\exists mn$ "" same as "" $\exists m \exists n$ ""?","['notation', 'quantifiers', 'discrete-mathematics']"
3889856,"Prove or disprove: $(A-B)-C=(A-C)- B$ for sets $A$, $B$, $C$","Prove or disprove: For sets $A$ , $B$ , $C$ , $$(A-B)-C=(A-C)- B$$ Now my attempt is $$(x\in A \;\text{and}\; x\notin B) \;\text{and}\; x\notin C \tag1$$ We can write it as $$(x\in A  \;\text{and}\; x\notin C)  \;\text{and}\; x\notin B \tag2$$ which proves the statement. Is it right?","['elementary-set-theory', 'proof-writing', 'solution-verification']"
3889873,"Sum with two indices, how to handle the condition $i\neq j$?","I'm given $$
\sum_{i,j=1, i \neq j}^{N} ij \tag 1
$$ I assume this is a short hand for $$
\sum_{i=1}^{N}
\Bigg (
\sum_{j=1}^{N} ij 
\Bigg ) 
\qquad? \tag 2
$$ But where does $i\neq j$ belong, to the inner or outer sum? Example with $N=2$ and $i\neq j$ in the inner sum: \begin{align}
\sum_{i,j=1 \\i\neq j}^{2} ij
&=
\sum_{i=1}^{2}
\Bigg (
\sum_{j=1, i \neq j}^{2} ij 
\Bigg ) 
\tag 3
\\
&=\sum_{i=1}^{2}
\Bigg (
i1+i2
\Bigg )
\tag 4
\\
&=
(11+12 + 21 + 22)
\tag 5
\\
&\text{\{Now discard 11 och 22\}}\\
&=23
\end{align} I guess the end result is correct, but I don't think my approach is correct (""Now discard""). How should I handle the condition $i\neq j$ ?","['calculus', 'summation', 'discrete-mathematics']"
3889986,If $A\subseteq B\cup C$ then $A\subseteq B$ or $A\subseteq C$.,"The question is to prove or disprove If $A\subseteq B\cup C$ then $A\subseteq B$ or $A\subseteq C$ . I know that this is wrong and can easily be disproved with an example, but I tried to prove it and I actually came up with proof that I know is wrong but I don't know why it's wrong, I started by converting it to this: $$x\in A\implies x\in B\cup C$$ $$x\notin A\lor x\in B\lor x\in C$$ $$(P\lor P\equiv A,A\lor B\equiv B\lor A)\text{ so}$$ $$x\notin A\lor x\in B\lor x\notin A\lor x\in C$$ $$(x\in A\implies x\in B)\lor(x\in A\implies x\in C)$$ $$A\subseteq B\lor A\subseteq C$$ and I want to know why this proof is wrong and where exactly is my mistake.","['elementary-set-theory', 'fake-proofs']"
3890092,Why using fewer terms of Taylor series doesn't give $0/0$ but gives a wrong answer? [duplicate],"This question already has answers here : Is it okay to ""ignore"" small numbers in limits where $x$ approaches infinity? (6 answers) Closed 3 years ago . I was reading a Calculus book and I saw this problem which looks easy: $$\lim _{x \rightarrow 0} \frac{2 x \cos x- \sin 2x}{x^3} = ?$$ It's a 0/0 limit and it's using some of the Taylor series of $\sin$ and $\cos$ expressions to solve the problem. I know that the First and Second way should be correct because it's using more expressions of the Taylor series around 0.
What I can't figure out is WHY using fewer expressions of the Taylor series in the Third way doesn't give 0/0 but gives a wrong answer? First way: $$\lim _{x \rightarrow 0} \frac{2 x \cos x-2 \sin x \cos x}{x^3}=\lim _{x \rightarrow 0} \frac{2 \cos x(x-\sin x)}{x^3}=\lim _{x \rightarrow 0} \frac{2 \cos x\left(x-x+\frac{x^3}{6}\right)}{x^3}=\lim _{x \rightarrow 0} \frac{2 \cos x\left(\frac{x^3}{6}\right)}{x^3}=\frac{1}{3}$$ Second way: $$\lim _{x \rightarrow 0} \frac{2x(1-\frac{x^2}{2})-(2x-\frac{8x^3}{6})}{x^3}=\lim _{x \rightarrow 0} \frac{2x-x^3-2x+\frac{8x^3}{6}}{x^3}=\lim _{x \rightarrow 0} \frac{\frac{x^3}{3}}{x^3}=\frac{1}{3}$$ Third way: $$\lim _{x \rightarrow 0} \frac{2 x \cos x- \sin 2x}{x^3} =\lim _{x \rightarrow 0} \frac{2 x \cos x-2x}{x^3}=\lim _{x \rightarrow 0} \frac{2x(\cos x -1)}{x^3}=\lim _{x \rightarrow 0} \frac{2x(-\frac{x^2}{2})}{x^3}=-1$$","['limits', 'calculus', 'solution-verification', 'taylor-expansion']"
3890116,Maximal solution and its domain of $x'(t) = x(t)^{x(t)}$.,"How can I proof that the maximal solution to \begin{align}
x'(t) = x(t)^{x(t)}, \quad x(0) = x_0,
\end{align} where $x_0 > 0$ and $t \geq 0$ , is not (globally) defined on $\mathbb{R}_{0}^{+}$ ? I am given the hint that it might help to first look at $x_0 > 1$ . Unfortunately, that does not help. I am close to giving up on this one so any help is appreciated.","['initial-value-problems', 'ordinary-differential-equations']"
3890138,Average density of a continuous random variable,"Suppose, $X$ is a continuous random variable on $[0; 1]$ , and $p_X$ is its PDF. Suppose $E[X] = \lambda$ . What is the smallest possible value of $E[p_X(X)]$ ? I managed to prove the following bound: $$E[p_X(X)] \geq 3 \lambda^2$$ Indeed, $$\lambda = E[X] = \int_0^1 t p_X(t) dt \leq \sqrt{(\int_0^1 p_X(t)^2 dt)(\int_0^1 t^2 dt)} = \sqrt{\frac{E[p_X(X)]}{3}}$$ by Hoelder inequality. However, I do not know, whether this bound is tight…","['expected-value', 'probability-theory', 'probability']"
3890146,"Conditon for $f(x)$ such that $f(d(x, y))$ induces the same topology with $d(x, y)$","On Munkres' Topology, Sec 20, Q 11, for $f(x)=\frac{x}{1+x}$ , $f(d(x, y))$ induces the same topology with $d(x, y)$ . And I have some question here : what conditions for $f(x)$ could make same result? My attempt : If $f(x)$ satisfies $f(a+b) \leq f(a)+f(b)$ , $f(0)=0$ , and $0< f(x) \leq 1$ for $0 < x$ edit) Maybe, latter of condition 2) can be replaced by "" $f$ is bounded""! But, I can't prove that it induces the same topology. Does it need some specified condition?",['general-topology']
3890197,Conformal mapping to upper half plane,"I need to find conformal mapping of $U = \{z \in \mathbb{C}:Im(z) >0\}\setminus\{ it:t\in [1;\infty)\}$ to upper half plane. I tried to square $U$ and then use inverse of $w = \frac{1}{2}(z + \frac{1}{z})$ and on paper it seems like i am on the right way, but cannot understand what's wrong. Any hints?","['complex-analysis', 'complex-numbers']"
3890231,Confusion on the proofs of convolution theorem of Fourier Transform.,"The convolution theorem of Fourier transform is stated as follows: Define $h(x):=f(x)*g(x)$ , then we have $$\hat{h}(k)=\hat{f}(k)\hat{g}(k).$$ I have a confusion of the proofs of this theorem. Most proofs go in the following way: Define $h(x):=f(x)*g(x)$ .  By definition, we have $$\hat{h}(k)=\int_{-\infty}^{\infty}h(x)e^{-ikx}dx.$$ Then, plugging in the integral expression of $f*g$ into the above integral yields us \begin{align*}
\hat{h}(k)&=\int_{-\infty}^{\infty}h(x)e^{-ikx}dx\\
&=\int_{-\infty}^{\infty}\Big(\int_{-\infty}^{\infty}f(x-s)g(s)ds\Big)e^{-ikx}dx\\
&=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}f(x-s)g(s)e^{-ikx}dsdx.\ \ \ \ \ \ (*)
\end{align*} Then, most proofs directly change integral order in the question $(*)$ , so that \begin{align*}
\hat{h}(k)&=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}f(x-s)g(s)e^{-ikx}dsdx\\
&=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}f(x-s)g(s)e^{-ikx}dxds\\
&=\int_{-\infty}^{\infty}\Big(\int_{-\infty}^{\infty}f(x-s)e^{-ikx}dx\Big)g(s)ds.
\end{align*} What remains is standard: note that by the shifting property, the inner integral is $$\int_{-\infty}^{\infty}f(x-s)e^{-ikx}dx=\hat{f}(k)e^{-iks},$$ and thus \begin{align*}
\hat{h}(k)&=\int_{-\infty}^{\infty}\Big(\int_{-\infty}^{\infty}f(x-s)e^{-ikx}dx\Big)g(s)ds\\
&=\hat{f}(k)\int_{-\infty}^{\infty}g(s)e^{-iks}ds\\
&=\hat{f}(k)\hat{g}(k),
\end{align*} where the last equality was obtained by definition. The proof is concluded. However, why could we change the integral order of (*) in the first place? Don't we need Fubini? I tried to use Fubini as follows: $$\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}|f(x-s)g(s)e^{-ikx}|dsdx=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}|f(x-s)g(s)|dsdx$$ but I do not know how to proceed further. I had expected that I can split the integral so that I would have two $L^{1}-$ norm, but since the first integral is $ds$ , I could not split the integral.. Do we directly assume the function is nice enough so that we can interchange the integral order? If so, what type of functions do we assume? Thank you!","['fourier-analysis', 'proof-explanation', 'fourier-transform', 'analysis', 'real-analysis']"
3890259,"$4$ points in order $A,B,C,D$ lie on a circle with the extension of $AB$ meeting the extension of $DC$ at $E$ and that of $AD$ and $BC$ at $F$.","$4$ points in order $A,B,C,D$ lie on a circle with the extension of $AB$ meeting the extension of $DC$ at $E$ and that of $AD$ and $BC$ at $F$ . Let $EP$ and $FQ$ be tangents to this circle with points of tangency $P$ and $Q$ respectively. Suppose $EP = 60$ , $FQ = 63$ . Find $EF$ . What I Tried : Here's a picture :- Used Power of a Point to get :- $$EA * EB = ED * EC = 3600$$ $$FA * FD = FB * FC = 3969$$ Yet this does not help to proceed and neither finds the value of $EF$ . I thought of Pythagoras Theorem once. Join OP and OQ and let them be $x$ each . Then we can find $OE$ and $OF$ in terms of $x$ . Not sure if that helps in the problem though. Can anyone help me? Thank You.","['power-of-the-point', 'triangles', 'problem-solving', 'geometry']"
3890470,To prove $EA = FB$ or that $CQ'$ is radical axis,"Given disjoint circles $c_1 = \odot(P,PA), c_2 = \odot(O,OB)$ such that $B$ and $A$ are in the same half-plane wrt $OP$ and that $PA \parallel OB \perp OP$ . Line $CDQ$ is the perpendicular bisector of $AB$ , $D \in AB,Q \in OP$ . Point $Q'$ is the reflection of $Q$ wrt to $M$ , the midpoint of $OP$ . Point $C$ on line perpendicular to $OP$ in $Q'$ . $E = CA \cap c_1, F = CB \cap c_2$ . I want to prove $EA = FB$ . We know that $DC = DQ$ because $DM$ is midsegment of trapezium $OBAP$ .","['euclidean-geometry', 'homothety', 'geometry', 'power-of-the-point', 'geometric-transformation']"
3890494,How could someone conceive of using this inequality for this proof?,"In James Stewart's Calculus: Early Transcendentals ( $8$ e), problem $90$ of Section $11.1$ asks us to prove that the sequence $$a_n=\left(1+\frac{1}{n}\right)^n$$ has a limit. It is divided into five sub-problems, the first of which asks us to show that if $a$ and $b$ are real numbers with $0\leq a<b$ , then $$\frac{b^{n+1}-a^{n+1}}{b-a}<(n+1)b^n$$ After completing all five sub-problems, I can see why proving this inequality was one of them: it's useful for proving that $a_n$ satisfies the hypotheses of the Monotonic Sequence theorem. What I don't see is how one could conceive of using this particular inequality in this proof. Let's say I wanted to prove that $a_n$ has a limit, but didn't have the guidance of the book. Are there any at-a-glance properties possessed by the sequence that would lead me to consider using the above inequality in my proof? If not, how could I guide my thinking in that direction?","['calculus', 'sequences-and-series', 'real-analysis']"
3890524,Question about connection between Poisson and Gamma distributions,"Assuming $X\sim\mathcal{P}(\lambda)$ and $Y\sim\Gamma(w,1)$ prove that $P(X\ge w)=P(Y\le \lambda)$. How this fact is lead from the connection between the poisson and exponential distributions? I don't know from where to start. poisson is defined only for discrete situations but the exponential is only for continious situation. How can I prove the fact ? EDIT : for gamma distribution I wrote that $f_Y(y)=\frac{y^{w-1}e^{-y}}{\Gamma(w)}$, but I have problem with integrating it. About Poisson: its function is $\displaystyle \sum _{w_i=0}^w P(X=w_i)$ which I don't know how to sum into a final expression. How can I continue?","['probability-distributions', 'probability']"
3890534,$||E[X]|| \leq E[||X||]$,"Let $X$ be a r.v. taking values in $\mathbb{R}^d,$ such that $X \in L^1.$ $||.||$ is an arbitrary norm on $\mathbb{R}^d.$ Prove that $$||E[X]||\leq E[||X||].$$ When $d=1,$ then letting $\theta=\frac{E[X]}{|E[X]|},$ $|E[X]|=\frac{1}{\theta}E[X] \leq E[\frac{1}{|\theta|}|X|]\leq E [|X|].$ Having problems with $d>1,$ what do suggest to do? Is there a way to prove it using the above argument?","['integration', 'measure-theory', 'probability-theory', 'inequality']"
3890546,gluing ideals together,"While pondering basic facts about closed subschemes the following claim occurred to me . I think it must be true but I have trouble proving it algebraically. Let $ R$ be a commutative ring with 1.  Let $f_1,...,f_k\in R$ with $ (f_1,...,f_k)=R$ and let $I_1\subset R_{f_1}, ..., I_k\subset R_{f_k}$ be ideals. Suppose that for each $i,j$ , the ideal generated by the image of $I_i$ in $ R_{f_if_j}$ is the same as the ideal generated by the image of $I_j$ in $ R_{f_if_j}$ .  Then there exists a unique ideal $I\subset R$ whose image in each $R_{f_i}$ generates $I_i$ .","['algebraic-geometry', 'abstract-algebra', 'commutative-algebra']"
3890549,"For every integer a, b, c, if 3c is not divisible by a, then b is not divisible by a or 3c is not divisible by b","I can't seem to figure this proof out. How would I prove this by contradiction and contraposition? I tried doing it by saying $3c=bk=(ak)k=a(kk)$ since $b=ak$ , $3c=bk$ for some interger $k$ $3c=a(kk)$ contradicts ""3c is not divisible by a""
contraposition would follow suit since we prove that $3c=a(kk)$ What am I doing wrong?",['discrete-mathematics']
3890575,Proving $6+12+18+24+...+6n=3n(n+1)$ by induction,"I'm learning prove by induction, but for some reason I just can't figure out the following example. I'll just work out the example and tell you guys where I'm stuck. prove the following by induction $$6+12+18+24+...+6n=3n(n+1)$$ prove basis step (n=1). $$
6 = 6*1 = 3*1(1+1) = 6
$$ induction step, assume Sk is true, n = k $$
6 + 12 + 18 + 24 + ... + 6k = 3k(k+1)
$$ induction step n = k + 1 $$
6 + 12 + 18 + 24 + ... + 6(k+1) = 3(k+1)(k+2)
$$ bring Sk to both sides $$
3k(k+1)+6(k+1) = 3(k+1)(k+2)
$$ Simplify, I really have no idea how these equal eachother, what are the simplifying steps taken in this example? Any help would be greatly appreciated!","['induction', 'discrete-mathematics']"
3890577,Name and layperson's explanation for an E8 group diagram.,"I am taking a risk here, but hoping it will not ignite wrath in the reader. In trying to get an intuition of Lie theory this diagram is all but impossible to ignore: Unfortunately, there are many youtube videos on the group E8 and its applications to subatomic particles and such. Yet, the actual diagram is not clearly addressed. So, knowing fully well that the math behind it is at this point beyond my level, I would like to ask for: What is the specific name of this diagram? Is it a Dynkin diagram ? Does it have any other names? What is the name and/or layperson's idea of what the color coding, nodes and edges represent?","['group-theory', 'lie-algebras', 'lie-groups']"
3890581,Integral of a function times a Fourier transform is zero,"This comes from Hall's Quantum Theory for Mathematicians , Lemma 9.33. I'm having trouble with one of the arguments in the proof. I believe it boils down to the following: Let $f\colon \mathbb{R}^n \to \mathbb{R}$ such that $\int f(x) \hat g(x) \,\mathrm{d}x = 0$ for all smooth $g$ with compact support, where $\hat g$ denotes the Fourier transform of $g$ . I then want to show that $f = 0$ . In the proof $f$ is a difference of an $L^2$ -function and an $L^2$ -function times a coordinate function. Hall cites the Stone-Weierstrass theorem and the theorem about density of continuous functions with compact support in $L^p$ , but he's not super clear. (He also starts talking about the functions as if they are defined on $\mathbb{R}$ , so I don't know what is going on.) Also, do feel free to change the title to something more descriptive, I wasn't sure how to title my question.","['fourier-analysis', 'functional-analysis']"
3890587,Density of Lebesgue measurable set,"I am looking to show that if we have a Lebesgue measurable set $E \subseteq \mathbb{R}$ with a density  1 at every element in $E$ and a density of 0 at every element of $\mathbb{R} \backslash E$ . Then it must be that $E = \mathbb{R}$ or $E = \emptyset$ . I am working through Axlers book on measure theory and we have defined the density of $E$ at a number $b \in \mathbb{R}$ to be $\lim _{t \downarrow 0} \frac{|E \cap(b-t, b+t)|}{2 t}$ . From the Lebesgue Density Theorem I know that for a Lebesgue measurable set $E \subset \mathbb{R}$ , the density of $E$ is 1 at
almost every element of $E$ and is 0 at almost every element of $\mathbb{R} \backslash E$ . So the difference to this case is that we are saying its true everywhere as opposed to almost everywhere. So so far I have that: For all $b \in E$ we have $\lim _{t \downarrow 0} \frac{|E \cap(b-t, b+t)|}{2 t} = 1$ For all $b \in \mathbb{R} \backslash E$ we have $\lim _{t \downarrow 0} \frac{|E \cap(b-t, b+t)|}{2 t}=0$ Intuitively it makes sense why only $\mathbb{R}$ and $\emptyset$ work but I am having trouble putting it into a complete proof. Any help is greatly appreciated. Thanks in advance!","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'real-analysis']"
3890594,Curves admitting Belyi maps are defined over $\overline{\mathbb{Q}}$.,"Belyi's theorem states that a complex algebraic curve $X$ admits a model over $\overline{\mathbb{Q}}$ if and only if it admits a map to $\mathbb{P}^1$ which is ramified over at most three points. In fact, Belyi proves that if the curve X admits such a model, then there is a map to $\mathbb{P}^1$ . The converse, which was previously known, follows from the existence of the étale fundamental group. I have to admit that I don't see why the converse is true just from knowing basic facts about the étale fundamental group, and the references I've found all approach it obliquely, with a summary more or less like what I said in the two paragraphs above. Would someone mind writing the argument out carefully?","['number-theory', 'algebraic-geometry', 'arithmetic-geometry']"
3890642,Non-homogeneous Poisson process first occurrence distribution,"I am trying to do the following problem in order to prepare for my Stochastic Processes exam: Problem statement: Consider $N(t)$ to be a non homogeneous Poisson process with rate $\lambda(t)$ over the interval [0, a].
Let $T_{1}$ denote the time for the first event to occur. Find the distribution of $T_{1}$ given that $N(a) = 1$ . Here, $N(t)$ denotes the number of occurrences up until time t. -> What have i tried so far? I started by investigating the following: $$P(T_{1} > t) = P(N(T_{1})=0)$$ Which, since we have a non homogeneous Poisson process, turns out to be: $$\frac{\left[\int_{0}^{T_{1}} \lambda(s) d s)\right]^{0}e^{-\int_{0}^{T_{1}} \lambda(s)ds}}{0 {\displaystyle !\,}} = e^{-\int_{0}^{T_{1}} \lambda(s)ds}$$ Finally: $$P\left(N\left(T_{1}\right)=0\right) = e^{-\int_{0}^{T_{1}} \lambda(s) d s}$$ Now, i tried to use the remaining information to finish the problem. However, i got stuck . I don't know how to proceed in regards to conditioning the variables ( I dont know if that is indeed the path to solve the problem ). I tried doing: $$P\left(N\left(T_{1}\right)=0 \mid N(a)=1\right) = \frac{P\left(N\left(T_{1}\right)=0, N(a)=1\right)}{P(N(a)=1)}$$ Now, i tried a few things, but i dont know if that is indeed correct. Knowing that $N(T) = 0$ and $N(a) = 1$ , one can infer that $T \le a$ , otherwise $N(T)$ would not equal zero, as one event would have ocurred. This information can be translated into: $$P(N(a)=1) = e^{-\int_{a}^{T_{1}} \lambda(s) d s}$$ Now, if i could expand the below term: $$P\left(N\left(T_{1}\right)=0, N(a)=1\right)$$ into something useful, i could start manipulating some terms. What do you guys think of my approach? Any help is appreciated. Thanks in advance!","['statistics', 'poisson-distribution', 'stochastic-processes', 'poisson-process', 'probability']"
3890671,Why does separation of variable gives the general solution to a PDE,"I was reading about physics and came across the method of using separation of variables to solve specific PDEs, but I can't figure out why the specific solutions give rise to the general solution (the book didn't give any explanation for all these). The specific example in the book was the Laplace Equation in $2$ variables: $$\frac {\partial^2 V}{\partial x^2}+\frac {\partial^2 V}{\partial y^2}=0$$ For the above example, separation of variable is essentially solving for the eigen-vectors of the operator $\frac {\partial^2 }{\partial x^2}$ and $\frac {\partial^2 }{\partial y^2}$ , which are Hermitian and commutes with each other. I know that in the finite dimensional case, such operators are simultaneously diagonalizable, then solving for the eigen-vectors will give all the solution, but I'm not sure does this work for infinite dimension. I'm also not sure does this approach works in the general case, for other PDEs that can be solved by separation of variable. All the other post I find on here are all explaining how or when separation of variable work, instead of why such techniques will give the general solutions. Another side question is: What kind of classes will cover these topics? The only undergraduate class that seems relevant at my university is Linear Analysis, which doesn't cover this. The graduate PDE sequence have graduate Real Analysis sequence as pre-requisite, which I don't think I'll be able to take soon.","['partial-differential-equations', 'linear-algebra', 'functional-analysis', 'real-analysis']"
3890761,"How can I show that $F(x,y)$ is not continuous?","I want to show $F(x,y)=\frac{xy}{x^2+y^2}$ is not continuous at the origin. Here is my attempt: Choose a path $y=mx$ . Then, $F(x,mx)=\dfrac{xmx}{x^2+m^2x^2}=\dfrac{mx^2}{x^2(1+m^2)}=\dfrac{m^2}{1+m^2}$ if $(x,mx)\neq0$ . Thus, $\lim_\limits{(x,y)\to(0,0)}F(x,y)$ does not exist, so $F$ is not continuous.","['multivariable-calculus', 'calculus', 'continuity']"
3890856,Substitution of variable in a second order differential equation [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I am trying to make a substitution of a new variable into a second order differential equation. However, I am not sure how to do this, I have seen examples online but they do not seem to be applicable to my case. I would like to know the procedure followed in order to have my original equation be written in terms of t instead of r. Here is the equation: This is the new variable I would like the equation to be in terms of:","['calculus', 'derivatives', 'ordinary-differential-equations']"
3890880,Probability of breast cancer,"I'm having trouble with a probability problem I've been trying to solve for a while. It's about the accuracy of breast cancer testing. Relevant probabilities are listed below, where: "" $\text{cancer}$ "" is the event ""has breast cancer"". "" $+$ "" is the event ""tests positive for breast cancer"". $P(\text{cancer}) = \frac{12}{1000}$ $P(+|\text{cancer}) = \frac{11}{12}$ $P(+) = \frac{31}{1000}$ $P(\text{cancer}|+) = 0.355$ This last line is a result from a previous problem. The next part involves updating the probability of having cancer, but I'm having trouble figuring out what the answer is. In the next part of the question, there's a woman who has tested positive and her doctor says she's part of a population for which there's a 40% chance of breast cancer. I need to find the probability that the woman has cancer. I am confused by this update to the cancer probability, but i will assume that this means $P(\text{cancer})$ has changed. I also assume this means I need to find a new value for $P(\text{cancer}|+)$ , but I'm not getting this right. $P(+ | \text{cancer}) = \frac{11}{12} = \frac{P(\text{cancer} | +)\cdot P(+)}{P(\text{cancer})} = \frac{P(\text{cancer} | +) \cdot \frac{31}{1000}}{0.40}$ $P(\text{cancer} | +) = \frac{11}{12} \cdot 0.40 \cdot \frac{1000}{31} = 11.828$ The result can't be correct because it's way over 1. How can i fix this? Thank you in advance for any insight.","['conditional-probability', 'bayes-theorem', 'probability']"
3890943,What is the difference between a random variable and an event?,"In layman terms, what is the difference between a random variable and an event? To my understanding a random variable is a function outputting a real number. And an event is an outcome or a set of outcomes.","['statistics', 'probability', 'random-variables']"
3890957,Show that orbitally equivalent autonomous systems do have same orbits,"According to Wikipedia , Two dynamical systems on the same state space, defined by $\dot {x}=f(x)$ and $\dot {x}=g(x)$ , are said to be orbitally equivalent if there is a positive function, $\mu :X\to \mathbb {R}$ , such that $g(x)=\mu (x)f(x)$ . Orbitally equivalent system differ only in the time parametrization. I wonder why do orbitally equivalent have same orbits. Intuitively, the two systems would have the same ""direction of velocity"" at any given point, but this is not a mathematical proof, right? I can not found any relating information except this question where lhf implicitly uses this property.","['equivalence-relations', 'ordinary-differential-equations', 'dynamical-systems']"
3891045,Can information-theory quantify deviations from bijectivity?,"There are basic ways to qualitatively classify deviations from bijectivity of a function $f: x \to y$ , e.g. non-injective, non-surjective, non-existence of an inverse: more generally non-monomorphic, non-epimorphic. Are there two ""natural"" quantitative measures of  deviation from injectivity and surjectivity? Is there one natural quantitative measure of ""total deviation"" from bijectivity (combining both injective/surjectivity violation)? And from isomorphic? Brain storm: Relative entropy of $\{f^{-1}(y) \}$ , i.e. the preimages of $f$ , seems one relevant to measuring relative injectivity? Relative measure or cardinality $|Im(f)/Cod(f)|$ seems one way to measure surjectivity? These both invoke additional concepts, e.g. probability or measure. I am sure mathematicians will have clearer and better ways that I can't think of. Any ideas or references will be most welcome. The above mostly relates to functions between sets. How does one ask and answer the corresponding questions for structure-preserving functions, i.e. functorial functions, such as monotone, equivariant, homomorphic, continuous? (Apologies if this latter is asking too much in one question!). Thanks!","['elementary-set-theory', 'functions', 'entropy', 'information-theory']"
3891095,Equivalent definitions of Brownian local time,"To keep this question simple, we only consider the local time of a standard Brownian motion $B_t$ at zero, we denote it as $L_t^0$ . Generally, we define $$\tag{1} L_t^0(B)=\lim_{\varepsilon\to\infty}\dfrac{1}{2\varepsilon}\int_0^t1_{(-\varepsilon,\varepsilon)}(B_s)\,ds. $$ Another definition is given by $$L_t^0(B)= |B_t|-\int_0^t\text{sgn}(B_s)\,dB_s\tag{2}.$$ We can approximate $|B_t|$ pointwise by $\sqrt{\varepsilon+B_t^2}$ by taking $\varepsilon\to0$ . Applying Ito formula to $\sqrt{\varepsilon+B_t^2}$ we get, $$\sqrt{\varepsilon+B_t^2}=\sqrt{\varepsilon}+\int_0^t\dfrac{B_s}{\sqrt{\varepsilon+B_s^2}}\,dB_s+\dfrac{1}{2}\int_0^t\dfrac{\varepsilon}{(\varepsilon+B_s^2)^{3/2}}\,ds. $$ If we take the limit, the above formula suggests that $$L_t^0(B)=\lim_{\varepsilon\to0}\dfrac{1}{2}\int_0^t\dfrac{\varepsilon}{(\varepsilon+B_s^2)^{3/2}}\,ds\tag{3}.$$ My question is can we show that by direct computation that equation (3) and (1) are the same?","['stochastic-calculus', 'stochastic-processes', 'brownian-motion', 'probability-theory', 'probability']"
3891126,"If $f:M\to \Bbb R$ is smooth and $f^{-1}(0)$ is a compact regular level set, then each $t\in (-\epsilon,\epsilon)$ is a regular value of $f$","Let $M$ be a smooth manifold and $f:M\to \Bbb R$ a smooth function. Suppose $0\in \Bbb R$ is a regular value of $f$ , so that $f^{-1}(0)$ is an embedded submanifold of $M$ . Also suppose that $f^{-1}(0)$ is compact. My goal is to show that $t$ is a regular value of $f$ for sufficiently small $|t|$ . My attempt: For each point $p\in f^{-1}(0)$ , $f$ is a submersion at $p$ , so $f$ is a submersion in a neighborhood $U_p\subset M$ of $p$ . Now $\{U_p\}_{p\in f^{-1}(0)}$ is an open cover of the compact set $f^{-1}(0)$ , so there must exist finitely many points $p_1,\dots,p_n\in f^{-1}(0)$ so that $f^{-1}(0)\subset U_{p_1}\cup \cdots \cup U_{p_n}=:U$ . Also $f$ is a submersion in $U$ . I would be done if I can show that $U$ contains $f^{-1}(-\epsilon,\epsilon)$ for some $\epsilon>0$ , but I can't show this. Should I need a different approach? Thanks in advance.","['smooth-functions', 'smooth-manifolds', 'differential-geometry']"
3891149,Abelian Varieties and Neron Models over local fields: Quotient of points of k mod valuation ring is finite,"I am working on a paper and I am not sure why the following fact is true. Suppose A/k is an abelian variety over a nn-archimedean local field k and $N/\mathcal{O}$ should be the Neron model. Then let $N^0$ be the connected component of the Neron Model, ie the normal open subgroup scheme, which is fibrewise the connected component of the identity. We are in the situation $N^0 \neq N$ . Now they state that the quotient $N^0(k)/N^0(\mathcal{O})$ is finite.
I am wondering, why this is true.
Maybe this has something to do with the reduction map, ie. the map $N(\mathcal{O}) \rightarrow N(\kappa)$ , $\kappa$ the residue field, which is surjective? I would be happy for an answer :)","['local-field', 'arithmetic-geometry', 'algebraic-geometry', 'schemes']"
3891180,Normal generation of the kernel of a surjection of free groups,"Suppose that $\phi : F_n \to F_m$ is a surjective homomorphism between free groups of rank $n$ and $m$ , respectively.  Is the kernel necessarily finitely normally generated?  If so, can we say anything about the number of normal generators that are needed in terms of $n$ and $m$ ?","['group-theory', 'free-groups']"
3891191,How many people at a party if everyone knows 22 other people and any two who don't know each other have exactly 6 mutual friends?,"You are in a strange party where everyone knows exactly 22 other person and any two who don’t know each other have exactly 6 mutual friends. How many are there in the party? Source 40- Strange Party My research: I know that the adjacency matrix $M$ is symmetrical and if $M[i,j] = 0$ then i-th and j-th rows have 6 times 1 at the same index position. I am thinking about encoding problem into SAT formulae and trying to brute force SAT solver with different number of literals (elements of upper triangle matrix of adjacency matrix). I have read some articles about Moore graphs and it seems that the upper limit for the vertices is $22^2 + 1 = 485$ . Do you have any hints to the solution?","['graph-theory', 'discrete-mathematics']"
3891202,Q: Find all values of $z such that cos(z) is purely imaginary,"I haven't got a memo for the answer of this question. So I just wanted to find out if my approach and answer is correct and sufficient.
Thank you. Let $b\in \mathbb{R}\backslash\{0\}$ $$\begin{align}cos(z)=ib\\
\frac{1}{2}(e^{iz}+e^{-iz})=ib\\
e^{iz}+e^{-iz}=2ib
\end{align}$$ Let $w=e^{iz}$ , then $$\begin{align}
w+w^{-1}=2ib\\
w^2 -2ibw + 1=0
\end{align}$$ $w=\frac{2ib \pm \sqrt{(-2ib)^2 -4(1)(1)}}{2(1)}=ib \pm\frac{\sqrt{-4b^2-4}}{2}=ib \pm\frac{2i\sqrt{b^2+1}}{2}=i(b\pm\sqrt{b^2+1})$ For $w=e^{iz}=i(b+\sqrt{b^2+1})$ $$\begin{align}
e^{iz}=i(b+\sqrt{b^2+1})\\
e^{ix}e^{-y}=e^{i\frac{\pi}{2}}(b+\sqrt{b^2+1})\\
\end{align}$$ Thus, $x=\frac{\pi}{2}+2n\pi$ , $\forall n\in \mathbb{Z}$ , and $y=-ln(b+\sqrt{b^2+1})$ For $w=e^{iz}=i(b-\sqrt{b^2+1})$ $$\begin{align}
e^{iz}=-i(-b+\sqrt{b^2+1})\\
e^{ix}e^{-y}=e^{-i\frac{\pi}{2}}(-b+\sqrt{b^2+1})\\
\end{align}$$ Thus, $x=-\frac{\pi}{2}+2n\pi$ , $\forall n\in \mathbb{Z}$ , and $y=-ln(-b+\sqrt{b^2+1})$ Therefore $cos(z)$ is purely imaginary when $\\$ $z=\frac{\pi}{2}+2n\pi+i(-ln(b+\sqrt{b^2+1}))$ or, when $z=-\frac{\pi}{2}+2n\pi+i(-ln(-b+\sqrt{b^2+1}))$ $\forall n\in \mathbb{Z},b\in \mathbb{R}\backslash\{0\}$","['complex-analysis', 'complex-numbers']"
3891232,Solution of differential Equation using frobenius method,"How to calculate the two linearly independent solutions of the differential equation x(x − 1)y'' + (3x−1)y'+ y = 0? My approach was by using the Frobenius method as x=0 and x=1 are regular singular points and then finding the roots of the indicial equation and then by seeing the difference of the roots I got the solution to be 1/(1-x), and by using the method of reduction the second one turns out to be log_e(x)/(1-x), but the second solution does not seem to satisfy the equation when I put it back in the DE. Where am I going wrong here?","['frobenius-method', 'ordinary-differential-equations']"
3891245,"Does $C^0$ convergence imply ""eventually homotopic""?","Consider a sequence of continuous mappings $f_n:M\to N$ for $n \in \mathbb{N}$ , where $M$ and $N$ are compact smooth manifolds, or in general, compact and Hausdorff metric spaces. Suppose that $f_n \to f$ in the $C^0$ topology, which in this case reduces simply to uniform convergence. Is it true that $f_n$ is homotopic to $f$ for every $n$ sufficiently large? I believe that this is true because of the following: in our case, the property of two mappings $f$ and $g$ being homotopic is equivalent to being in the same path-connected component of the function space $C(M,N)$ in the $C^0$ topology, i.e., just the uniform convergence topology. And, if $f_n\to f$ in this topology, I believe it should be contained in the path connected component of $f$ for sufficiently large $n$ (but I don't know how to prove it). My goal is to use this fact to argue that $deg(f_n) = deg(f)$ for all sufficiently large $n$ .","['general-topology', 'differential-topology', 'homotopy-theory']"
3891303,Gaining an intuition for how changes to the inputs of an equation affect the output,"I am currently taking General Chemistry 2 and Physics 2. I have been doing very well, but I am not just preparing to do well in these classes. I also want to do well on the Medical School Admissions Test or MCAT. On the MCAT, you cannot use a calculator. I have spoken with a few people who performed very well on the test, and they told me that an intuition for algebraic equations is a major factor in a good score. However, I have noticed that I do not possess this. What I mean by an intuition for algebraic equations is the ability to look at an algebraic equation and know how the output will be affected as a result of an input changing. An example is using the Gibbs Free Energy Equation. If some inputs are negative or positive it automatically changes the output/answer. I don't know how to go about learning this skill. Is this just a matter of going back to Algebra and learning it more deeply?","['algebra-precalculus', 'intuition']"
3891424,Prove or disprove that the set S is countable,"Define set $S$ as follows $$S = \left\{ f \in \{0,1\}^{\mathbb{N}} \middle| \forall x \in \mathbb{N} \ \exists y \in \mathbb{N}: x < y \land f(x) = f(y) \right\},$$ where $\{0,1\}^\mathbb{N}$ denotes the set of boolean functions defined on $\mathbb{N}$ . Prove or disprove that the set $S$ is countable. I know that the first part before the |-symbol itself is uncountable, but I don't understand the whole $x$ , $y$ , $f(x)$ , and $f(y)$ part, and how it would change the fact that it's already not countable. Could it not just be ignored? I'd be happy about any help.",['elementary-set-theory']
3891437,What is an interpretation of the rank of a probability matrix?,"Let $X$ and $Y$ be random variables taking values in the finite sets $\mathcal X=\{1,\dots,m\}$ , $\mathcal Y=\{1,\dots,n\}$ . Without loss of generality assume $m \ge n$ . Let $$p_{ij} = \Pr(X=i, Y=j)$$ be the joint probability mass function of $X$ and $Y$ and assume that $p_{ij} > 0$ for all $i \in \mathcal X, j \in \mathcal Y$ . Consider the matrix $P = (p_{ij}) \in \mathbb R^{m \times n}$ . Question: Is there an interpretation for $\operatorname{rank}P$ ? I'm especially interested in an interpretation of $P$ being of full rank. If one of $n$ or $m$ equals 2 then $P$ is of full rank iff $X$ and $Y$ are independent (suppose $m \ge n = 2$ . Divide the columns of $P$ by their sums. This leaves the rank of the resulting matrix unchanged at 1. Hence its two columns are identical. But the first column contains $\Pr(X=\cdot\mid Y=1)$ and the second column $\Pr(X=\cdot\mid Y=2)$ . Thus $X$ and $Y$ are independent). But what about the case $m \ge n \ge 3$ ? Is there an interpretation for $P$ being of full rank in that case?","['combinatorics', 'linear-algebra', 'discrete-mathematics', 'probability-theory', 'probability']"
3891505,Interpreting derivative questions in context,"I have these two questions and I am able to approximate $S''(10)$ like this: $\frac{S'(12)-S'(8)}{12-8}=-0.05$ I am just unsure how to interpret the meaning of $S''(x)$ in context. I know that the second derivative tells you whether your graph is concave up or concave down, which tells you whether or not the the first derivative (slope of the tangent line) is increasing or decreasing. So would an adequate explanation be: $S''(x)$ shows the change in rate of snow deposition with respect to time? For the second problem, I have the same question. I have $D'(t) = \frac{92}{40}e^{-t/40}$ and $D'(10)\approx 1.79$ cm/hr Is the correct interpretation: $D'(10)$ is the rate that the snow is depositing in centimeters per hour at $t=10$ hours.","['calculus', 'derivatives']"
3891510,Prove curvature and torsion of these two curves are equal using Frenet frame,"I have the following problem. Let $\alpha,\beta:I\rightarrow\mathbb{R}^3$ 2-regular curves (curvature $k\not=0$ for all $t\in I$ ), arc-length parametrized. Let $(t_\alpha, n_\alpha, b_\alpha)$ and $(t_\beta, n_\beta, b_\beta)$ be the Frenet frames of $\alpha$ and $\beta$ , respectively. Suppose we have $$t_\alpha(u)+b_\alpha(u)=t_\beta(u)+b_\beta(u) \quad \text{for all } u\in I$$ and suppose that $k_\alpha(u)\not=\tau_\alpha(u)$ for all $u\in I$ , where $k$ represents the curvature and $\tau$ the torsion of each curve. Prove that it exists a vector $v\in\mathbb{R}^3$ such that $\beta(u)=v+\alpha(u)$ for all $u\in I$ . My idea was to show that $k_\alpha=k_\beta$ and $\tau_\alpha=\tau_\beta$ in order to use Fundamental theorem of curves, which would prove the statement. I used the given equality $t_\alpha+b_\alpha=t_\beta+b_\beta$ and the Frenet-Serret formulas to show that $|n_\alpha| = |n_\beta| = 1$ and have the same direction. This gives us two cases: For $n_\alpha=n_\beta$ , I could check that $k_\alpha=k_\beta$ and $\tau_\alpha=\tau_\beta$ , thus we get to the solution. However, I'm struggling to solve the case $n_\alpha=-n_\beta$ . I would really appreciate help with this.","['curves', 'frenet-frame', 'geometry', 'curvature', 'differential-geometry']"
3891527,Finding $\lim_{x \to 0} \left( \frac{\sin(x)-3\sinh(x)+2x}{x^2(\tanh(2x)+ \sin(x))} \right)$,"I am trying to evaluate the following limit: $$L=\lim_{x \to 0} \left( \frac{\sin(x)-3\sinh(x)+2x}{x^2(\tanh(2x)+\sin(x))} \right)$$ Begin by rewriting the limit as: $$L=\frac{\lim\limits_{x \to 0}\left(\cfrac{\sin(x)-3\sinh(x)+2x}{x^2} \right)}{\lim\limits_{x \to 0}(\tanh(2x)+\sin(x))} \tag{1}$$ Applying L'Hospital's Rule to the numerator only: $$L=\frac{\lim\limits_{x \to 0}\left(\cfrac{\cos(x)-3\cosh(x)+2}{2x} \right)}{\lim\limits_{x \to 0}(\tanh(2x)+\sin(x))} \tag{2}$$ The numerator is still in an indeterminate form, applying L'Hopital to the numerator again: $$L=\frac{\lim\limits_{x \to 0}\left(\cfrac{-\sin(x)-3\sinh(x)}{2} \right)}{\lim\limits_{x \to 0}(\tanh(2x)+\sin(x))} \tag{3}$$ Rewriting as a single limit: $$L=-\frac{1}{2}\lim_{x \to 0}\frac{\sin(x)+3\sinh(x)}{\tanh(2x)+\sin(x)} \tag{4}$$ And applying  L'Hospital's Rule... $$L=-\frac{1}{2}\lim_{x \to 0}\left(\frac{\cos(x)+3\cosh(x)}{2\operatorname{sech}^2(2x)+\cos(x)} \right)=-\frac{2}{3} \tag{5}$$ But according to Wolfram Alpha, $L=-\frac{2}{9}$ So something must be wrong in my calculation (I guess it's the limit of a product bit)?","['limits', 'calculus', 'derivatives']"
3891695,Evaluating $\lim_{x\to0} \frac{\sin(\pi\sqrt{\cos x})} x$,"I don't know how can this be solved: $$
\lim_{x\to0} \frac{\sin(\pi\sqrt{\cos x})} x
$$ I've tried to multiply by $\pi\sqrt{\cos x}$ : $$
\lim_{x\to0} \frac{\sin(\pi\sqrt{\cos x})}{x\pi\sqrt{\cos x}}
$$ but we have here a hard problem $\lim_{x\to0}(1/x)$ . You think about the limit on the right and on the left but the exercise supposed to be solved by the limit in $0$ and not on the right or the left of it.","['limits', 'calculus']"
3891724,Probability and the first uncountable ordinal number,"Let's suppose we can put a probability measure on the set of countable ordinals. (which is the same as the first uncountable ordinal). Let's now play a game. I pick a countable ordinal, say $\alpha$ . Now you pick one. (Clearly our choices are independent). But $\alpha$ has countably many ordinals less than it and for you the number of choices greater than $\alpha$ are uncountable. So with a large probability, possibly one, your choice is bigger than mine. But the choices were independent!  How to explain? Of course, you could take this as a proof that no such measure exists but intuitively it seems to make sense that such a game could exist.","['set-theory', 'paradoxes', 'probability']"
3891732,Sum of recipocals of number of divisors,"I wrote a math problem that went like this: Alice writes out all integers from 1 to $n$ on a blackboard. Each round, if there are still numbers on the board, Alice chooses a number on the board at random and erases that number and all multiples of that number. What is the expected number of rounds until there are no numbers left on the blackboard. I had a somewhat closed form solution of: We do a classical double counting argument, we calculate the probability that any integer $k$ is chosen. The probability that $k$ is chosen is $\frac{1}{d(k)}$ where $d(k)$ is the number of divisors of $k$ .
This is true because it is equally likely that $k$ or any of it's divisors is chosen. By linearity of expectation, we can take the sum of the expected values that each individual integer is chosen.
This evaluates to $\sum_{k=1}^{n} \frac{1}{d(k)}$ Now, I'm curious if there's a way to further condense/bound this final sum. We can use HM-AM to bound it since the sum of divisors from $1$ to $n$ is well known, however I ran a program and the ratio between the HM and AM is ~ $1.9$ for $n=100,000$ . Any help is appreciated. Thanks !","['divisor-counting-function', 'summation', 'combinatorics', 'discrete-mathematics']"
3891748,Find the sum of the series $\displaystyle \sum_{n \ge 0} \frac{2^{3n}}{5^{n-1}}$ and specify if it is convergent or divergent.,"I have to find the sum of the following series and specify if it is convergent or divergent: $$\sum_{n \ge 0} \frac{2^{3n}}{5^{n-1}}$$ This is what I have so far: $$\sum_{n \ge 0} \frac{2^{3n}}{5^{n-1}}
= \sum_{n \ge 0} \frac{5 \cdot 2^{3n}}{5^{n}}
= \sum_{n \ge 0} \frac{5 \cdot (2^{3})^{n}}{5^{n}}
= 5 \cdot \sum_{n \ge 0} \bigg (\frac{8}{5} \bigg )^n$$ From here I said that: $$\frac{8}{5} > 1 \Rightarrow \bigg (\frac{8}{5} \bigg) ^ {n} \rightarrow \infty \text{ as } n \rightarrow \infty$$ And because of this I concluded that the sum of the series is $\infty$ , thus the series is divergent. However, I am not very satisfied with this last part. It doesn't feel right to jump from $$\bigg (\frac{8}{5} \bigg) ^ {n} \rightarrow \infty \text{ as } n \rightarrow \infty$$ to $$\sum_{n = 0}^{\infty} \frac{2^{3n}}{5^{n-1}} = \infty$$ What extra steps am I missing?","['real-analysis', 'solution-verification', 'sequences-and-series', 'limits', 'convergence-divergence']"
3891785,Why is the function $\mu(E)=\sum_{k=1}^{\infty}(1/2^k)\delta_{q_k}(E)$ a probability measure over $\mathbb{Q}$?,"In this question , the OP asks how to construct a probability measure $\mu(k):[\mathbb{Q},\mathcal{F},P]\to\mathbb{R}$ over the set $\mathbb{Q}$ of Rational numbers, where $[\mathbb{Q},\mathcal{F},P]$ is a probability space. One of the answers suggests to let $\{q_n\}_{n=1}^\infty$ be an enumeration over $\mathbb{Q}$ and then defines the measure \begin{gather}
    \mu(E)=\sum_{k=1}^{\infty}\frac{1}{2^k}\delta_{q_k}(E),
\end{gather} for each subset $E\subset\mathbb{Q}$ , where $\delta_{q_k}(E)$ is the point mass (i.e., Dirac delta). The answer does not provide much context, and it does not explain why such a measure satisfies countable additivity nor why it returns results in the unit interval $[0, 1]\cap\mathbb{R}$ , returning $0$ for the empty set and $1$ for the entire space. Could anybody please explain why such a measure is a probability measure over $\mathbb{Q}$ ? BONUS QUESTION : Since the Cartesian product of any two countable spaces is also countable, could such a measure be extended to the $n$ -dimensional set $\mathbb{Q}^N$ ? Thank you all for your help.","['measure-theory', 'solution-verification', 'probability-theory']"
3891850,Proving that $\int_1^\infty \big(\frac{\sin x}{x}\big)^n d x\leq e^{-n/6}$,"How to prove that, for $n\geq 1$ $$\int_1^\infty \big(\frac{\sin x}{x}\big)^n d x\leq e^{-n/6}$$ I could check the case $n=1,2$ by computation using wolfram. I don't have any concrete proof.","['integration', 'trigonometry', 'sequences-and-series', 'real-analysis']"
3891930,Disprove $\mathcal{P}(A\Delta B) \setminus \{\emptyset\} = \mathcal{P}(A) \Delta\mathcal{P}(B) $. Is my proof good?,"Proof that the following equality is wrong: $$\mathcal{P}(A\Delta B) \setminus \{\emptyset\} = \mathcal{P}(A) \Delta\mathcal{P}(B) $$ I choose elements of sets $A$ and $B$ so that they are separate. $A = \{1, 2\}$ $ \mathcal{P}(A) = \{\{1\}, \{2\}, \{1, 2\}, \emptyset\}$ $B = \{3, 4\}$ $\mathcal{P}(B) = \{\{3\}, \{4\}, \{3, 4\}, \emptyset\}$ $A\cup B = \{1, 2, 3, 4\}$ $A\cap B = \emptyset$ Now I see that: On the left side : $\mathcal{P}(A\Delta B) = \mathcal{P}((A\cup B) \setminus (A\cap B)) = \mathcal{P}((A\cup B) $ $ \mathcal{P}((A\cup B) =\{\{1\}, \{2\}, \{3\}, \{4\}, \{1, 2\}, \{1, 3\}, \{1, 4\}, \{2, 3\}, \{2, 4\}, \{3, 4\}, \{1, 2, 3\}, \{1, 2, 4\}, \{1, 3, 4\}, \{2, 3, 4\}, \{1, 2, 3, 4\},\emptyset \} $ $ \mathcal{P}((A\cup B) \setminus \{\emptyset\} =\{\{1\}, \{2\}, \{3\}, \{4\}, \{1, 2\}, \{1, 3\}, \{1, 4\}, \{2, 3\}, \{2, 4\}, \{3, 4\}, \{1, 2, 3\}, \{1, 2, 4\}, \{1, 3, 4\}, \{2, 3, 4\}, \{1, 2, 3, 4\}\} $ On the right side : $\mathcal{P}(A) \Delta\mathcal{P}(B) = (\mathcal{P}(A) \cup \mathcal{P}(B)) \setminus (\mathcal{P}(A) \cap \mathcal{P}(B)) = \{ \{1\}, \{2\}, \{3\}, \{4\}, \{1, 2\}, \{3, 4\} \} $ Therefore: $\{\{1\}, \{2\}, \{3\}, \{4\}, \{1, 2\}, \{1, 3\}, \{1, 4\}, \{2, 3\}, \{2, 4\}, \{3, 4\}, \{1, 2, 3\}, \{1, 2, 4\}, \{1, 3, 4\}, \{2, 3, 4\}, \{1, 2, 3, 4\}\} \neq \{ \{1\}, \{2\}, \{3\}, \{4\}, \{1, 2\}, \{3, 4\} \} $ i.e. $\mathcal{P}(A \,\Delta\,B) \setminus \{\emptyset\} \neq \mathcal{P}(A) \Delta\mathcal{P}(B)$ . Is my proof valid? Are there any errors? I could take smaller $A$ and $B$ sets but I was scared that it wouldn't be so obvious that way.","['proof-writing', 'examples-counterexamples', 'solution-verification', 'discrete-mathematics', 'elementary-set-theory']"
3891936,Compact set in the order topology,"Let $(X, \leq)$ be a linearly ordered set and let $\mathcal{T}$ denote the order topology on $X$ . Prove that $(X, \mathcal{T})$ is compact if and only if every nonempty subset of $X$ has a greatest lower bound and a least upper bound in $X$ . I don't know how to apply the definition of compactness in this topology. Can anyone give an idea?","['order-theory', 'general-topology', 'compactness']"
3891942,Find all integer polynomials $f(p)$ that divide $2^p–2$ for every prime $p>2$,"Find all polynomials $f(p)$ with integer coefficients that divide $2^p–2$ for every prime $p>2$ From Fermat's little theorem we can find $2p, p, -2p, -p$ (and per comments, some constant polynomials). But are there others, or can we prove higher degrees won't work?","['number-theory', 'polynomials', 'elementary-number-theory']"
3891977,How many ways to distribute these balls?,"There is a box of balls containing six different colors of balls. More precisely there are
nine, eight, five, seven, two, and four of the various colors for a total of 35 balls. If eight people
take balls from the box, in how many ways can the balls be distributed? (There are no restrictions how many balls one person can get, so one person can get all 35 and the others get nothing). Is it correct that there are $8^{35}$ ways to distribute the balls? The balls are distinct, but there are different numbers of each color, so that's what is getting me. I think the answer might involve n choose k but I'm not sure how to apply it.","['combinations', 'combinatorics', 'discrete-mathematics']"
3892051,Question regarding a proof of the chain rule.,"One can derive $(5)$ by letting $$v(s)=\frac{g(s)-g(y)}{s-y}-g'(y)$$ for $s\neq y$ . The problem I have is in letting $s=f(t)$ . It is not obvious to me that the expression still holds, particularly because $s-y=f(t)-y$ might equal $0$ and there is no guarantee that the expression is well defined around $y=f(x)$ .","['proof-explanation', 'derivatives', 'chain-rule', 'real-analysis']"
3892069,Not following this formula for coincidence rate among 'simultaneous' Gaussian distributions?,"I'm reading this paper, which  describes (among other things) the ""triggering"" system for a peice instrumentation used in the detection of subatomic particles in an astroparticle physics experiment. The experiment is subject to thermal noise, which can be modeled as a Gaussian with $\mu = 0$ and $\sigma = V_{rms}$ . So, given some sampling rate, a waveform can be simulated by making a random pick from the Gaussian for each sample. The instrument in question has $n$ channels, and a ""triggering"" system which is designed to record every time $k$ channels have an excursion over some threshold within a duration $\tau$ . So, for example, a trigger may be defined as $3$ channels having an excursion over $5$ within $10$ nanosecond of the first such excursion. The paper then describes a method to determine this trigger rate, which really confounds me: To determine the expected accidental rate, RL1, of $k$ -fold coincidences among the $n$ = 8 channels, consider a trial event,
defined by a hit in any one of the $n$ channels, which then triggers a
logic transition out of the discriminator to the logic TRUE state for
a duration τ. Then consider the probability during this trial that $k
> −1$ or more (k = 3 for [this experiment]) additional sub-band
discriminator logic signals arrive while the first is still in TRUE
state, corresponding to a hit above threshold for that channel. The
rate of TRUE states per channel is $r$ . We do not for now assume $rτ
 << 1$ . The probability to observe exactly $k − 1$ out of $n − 1$ additional channels in the TRUE state after one channel has changed
its state is given by the binomial (e.g., the $k$ out of n ‘coin
toss’) probability: $P(k-1 : n-1) = \frac{(n-1)!}{(k-1)!(n-k)!}p^{k-1}(1-p)^{n-k}$ The single channel ‘coin-toss’ probability p is just given by the
fractional occupancy of the TRUE state per second per channel: $p =
> rτ$ . The probability per trial to observe greater than $k − 1$ out of $n − 1$ channels is then just the cumulative probability density of
the binomial distribution times the observation interval: $P(\geq k-1 : n-1) = \sum_{j=k-1}^{n-1}
 \frac{(n-1)!}{(j)!(n-1-j)!}(r\tau)^j[1-r\tau]^{n-1}dt$ For $rτ << 1$ as it often is in practice, this simplifies to: $P(\geq k-1 : n-1) \approx \frac{(n-1)!}{(k-1)!(n-k)!}(r\tau)^{k-1}$ ...since only the leading term in the sum contributes significantly
and the term $1−rτ ≃ 1$ . The rate is then determined by multiplying
the single-trial probability by the number of ensemble trials per
second, which is just equal to the total number of channels times the
singles rate per channel. The singles rate per channel is given simply
by $r$ , and the total singles rate across all channels is $nr$ . Thus
the total rate in the limit of $rτ << 1$ , is: $\text{rate (RL1)} = nrP(\geq k-1:n-1) \approx
 n\frac{(n-1)!}{(k-1)!(n-k)!}r^k\tau^{k-1} =
 \frac{(n)!}{(k)!(n-k)!}kr^k\tau^{k-1}$ I can follow most of the logic (the first equation is (as stated) just the binomial probability formula, the second follows trivially from the first), however some of this seems ""pulled out of thin air"" to me (namely, the line involving the summation, and everything after).","['probability', 'probability-distributions', 'physics', 'probability-theory', 'mathematical-physics']"
3892071,prove that $f$ is nowhere differentiable,"$$f(x)=\sum_{j=1}^\infty \left({\frac{3}{4}}\right)^{j}\sin(4^jx)$$ How can I prove that $f$ is nowhere differentiable? I know that the $j$ th summands are all continuous and bounded by $\left({\frac{3}{4}}\right)^{j}$ so by Weierstrass test, $f$ converges uniformly and therefore $f$ is continuous.","['derivatives', 'real-analysis']"
3892128,Does the sequence $v_{n+1} = T(v_n)/|T(v_n)|$ converge to an eigenvector?,"Let $\varphi:[-1,1]\times \mathbb{R}\to\mathbb{R}$ the map $\varphi(x,w)=2\omega +1$ and $\mathcal{C}^0([-1,1])=\{f:[-1,1]\to\mathbb{R};\ f \ \text{is continuous}\}$ . I am interested in studying the following bounded linear map \begin{align*}
T:\left(\mathcal{C}^0([-1,1]),\|\cdot\|_\infty\right)&\to \left(\mathcal{C}^0([-1,1]),\|\cdot\|_\infty\right)\\
f&\mapsto \left(x\mapsto \frac{1}{2}\int_{-1}^1 f(2x+\omega)\cdot\mathbf{1}_{[-1,1]}(2x+\omega) \ \mathrm{d}\omega \right),
\end{align*} where $\mathbf{1}_{[-1,1]}$ is the indicator function of the interval $[-1,1]$ . Using the same techniques used in the links Proving that there exists only one non-negative eigenfuction for the following operator. , Is possible to show that the linear operator $T(\varphi)(x) = \int_{V_x\cap M} \varphi(y)\text{d}y$ has spectral radius $>0$. , and Krein-Rutman theorem we can ""easily"" conclude that $T$ is a compact linear map. $T$ has positive radius (actually, $r(T) =1/2$ ). $T$ has a unique eigenvector on the cone $\mathcal{C}^0_+([-1,1]) =\{f:[-1,1]\to\mathbb{R};\ f \ \text{is continuous and }f\geq 0\}$ and its eigenvalue is equal to $1/2$ . I have done some numerical simulations and I think that the sequence the recursive sequence: \begin{align*}
v_0 &= 1\\
v_n&= \frac{T(v_{n-1})}{\|T(v_{n-1})\|_{\infty}},
\end{align*} converges to the unique eigenvector. This believe comes in light of some numerical simulations. In the picture below the red line represents the function $T(1)$ , the green line $T^2(1)$ , the orange one $T^3(1)$ and, finally, the blue one is $T^4(1)$ . My Question: Does anyone know if $\{v_n\}_{n\in\mathbb{N}}$ (or a subsequence of $\{v_n\}_{n\in\mathbb{N}}$ )  converges to an eigenvalue? Moreover (this is just out of curiosity the important question is the first one), is there some well-known theorem that gives conditions to the sequence $\{v_n\}$ converges to an eigenvalue in the infinite-dimensional case? It is worth mentioning that this paper gives us a result that under the ""strong"" Krein-Rutman theorem assumptions: The sequence $\{v_n\}_n$ converges to an eigenvector. But, I was looking for a theorem that I could apply in my linear operator. Can anyone please help me?","['banach-spaces', 'compact-operators', 'eigenvalues-eigenvectors', 'linear-algebra', 'functional-analysis']"
3892195,What does $\leq ^{-1}$ mean?,"Just came across a question on my homework assignment. The only thing it says is: What is $\leq ^{-1}$ ? It is on chapter for relations . I'm guessing it means: $R \leq R^{-1}$ , for $R$ being a relations, then having $R$ factored out on each sides?? If it helps, the book I'm using is Mathematics: A Discrete Introduction , Chapter 14, exercise 14.12","['definition', 'relations', 'discrete-mathematics']"
3892211,Construction of a connection on a vector bundle $E\to M$ with trivial determinant bundle,"I read the following statement, and I am trying to see why it is true. Let $E\to M$ be a rank 2 complex vector bundle over a smooth manifold $M$ , such that the determinant bundle $\det(E)=\Lambda^2(E)$ is the trivial line bundle over $M$ , with trivialization $\phi:\det(E)\to M\times \mathbb{C}$ . Then there exists a connection $\nabla^E$ on $E$ which induces the trivial connection on $\det(E)$ , under $\phi$ . I wanted to construct $\nabla^E$ by defining local connections, which I then glue together by a partition of unity. Let $\{U_\alpha\}$ be a trivializing open cover of $M$ . Over each $U_\alpha$ , I have a local frame $\{e_1^\alpha,e_2^\alpha\}$ such that $e_1^\alpha\wedge e_2^\alpha$ corresponds to 1 under the diffeomorphism $\phi$ . On each $U_\alpha$ , I can define a flat connection $\nabla^\alpha$ (so by declaring the sections $e^\alpha_i$ to be flat). If $(\rho_\alpha)$ is a partition of unity subordinated to the trivializing open cover, I define $\nabla^E(s)=\sum\limits_\alpha \nabla^\alpha(\rho_\alpha s)$ , which is indeed a connection. Next, I want to check that it induces the trivial connection on $\det(E)$ under $\phi$ . Note that $\phi^{-1}(1)=\sum\limits_\alpha \rho_\alpha e_1^\alpha\wedge e_2^\alpha.$ Then \begin{align*}
\nabla^{\det(E)}\big(\sum_\alpha \rho_\alpha e_1^\alpha\wedge e_2^\alpha\big)&=\sum_\alpha \nabla^{\det(E)}\big(\rho_\alpha e_1^\alpha\wedge e_2^\alpha)\\&=\sum_\alpha \nabla^E(\rho_\alpha e^\alpha_1)\wedge e_2^\alpha+\rho_\alpha e_1^\alpha\wedge \nabla^E(e_2^\alpha)\\&=\sum_\alpha \rho_\alpha\big(\nabla^E(e_1^\alpha)\wedge e_2^\alpha+e_1^\alpha\wedge \nabla^E(e_2^\alpha)\big).
\end{align*} I want this to be zero, but the problem I encounter is that $\nabla^E(e_i^\alpha)\neq\nabla^\alpha(e_i^\alpha)=0$ . Nevertheless, is this the correct approach to take and how can I fix it? Does summing over all $\alpha$ make sure it is correct again? EDIT: This question seems to have been partially asked here: Connections on Bundles with Trivial Determinant But it seems that an answer is missing and I am very curious, it seems to take a different approach, by introducing a Hermitean metric on $E$ .","['connections', 'vector-bundles', 'linear-algebra', 'manifolds', 'differential-geometry']"
3892242,How many regions can be selected in a chess board?,"How many regions can be selected in a 8 by 8 chess board? Definition of region: A region is a set of cells that are all connected together(by edge). i.e. a possible region: I want to run(or do complexity analysis for) a backtrack algorithm, and need to know the number of possible regions.","['chessboard', 'polyomino', 'combinatorics']"
3892285,"Could someone please explain sin, cos, and tan in a simple way?","I haven't taken this in school yet but I love math and physics and join lots of competitions. I have a problem with sine, cosine, and tangent, that I really need a SIMPLE explanation along with an example. I know for a first that they are related to angles and are used in physics, so how are they calculated and how are they used? Thanks in advance","['physics', 'geometry']"
3892308,Variation of Birthday problem - Group of n people,"I know this has been posted several times and I have gone through most of the relevant posts.
Here is one which I am having a difficult time to solve: There are 450 people in a room; (1) how many of them are expected to have the same birthday with some other person in the room, (2) with at least 2 other people in the room and (3) with at least 3. (1) is easy - by the pigeonhole principle, 450-365 (or 366) = 85 people are expected to have the same birthday. How do we do (2) and (3)? I am thinking that in 85 people we have $\frac {85*84} {2} = 3570$ possible pairs so the probability for a 3rd person to share one of their birthdays is $1-\frac {364}{365}^{85}$ . And then how do we find the expected number of people for each case? Any help is greatly appreciated! Thank you!","['combinatorics', 'birthday', 'probability']"
3892422,Estimating $|\mu_1 - \mu_2|$ in a mixture of two Gaussians with known variance.,"Consider $n$ samples denoted with $X^n = X_1, \ldots, X_n$ from mixture of two Gaussians with equal variance and equal mixture proportions: $X^n \sim 1/2 \mathcal{N}(\mu_1, 1) + 1/2 \mathcal{N}(\mu_2, 1)$ . Now the goal is to estimate the difference in means $|\mu_1 - \mu_2|$ from this $n$ samples. One idea is to rank them from lowest to highest, and take the difference between the 1/4th highest and lowest sample point. But how accurate is this estimate, and is there a better way?","['statistics', 'gaussian', 'order-statistics']"
3892435,Estimate on complex path integral,"I came across the question in this post , where I wrote a partial answer. The question is to show that, for some constant $k>0$ , we have $$
\left|\int_{[-1,i]}(1+z+z^2+z^3)^n dz\right| \leq  k \left(\frac{4}{3 \sqrt{3}} \right)^n.
$$ What I did: We can easily  compute the integral up to a certain point, obtaining \begin{align*}
\int_{[-1,i]} (1+z+z^2+z^3)^n dz= &\int_{[-1,i]}(1+z)^n(1+z^2)^n \\
= & \int_0^1 (1+i) (t(1+i)^n)(2(1-t)-2t(1-t)i)^ndt\\
=& (1+i)^{n+1} 2^n \int_0^1 t^n(1-t)^n(1-ti)^n dt
\end{align*} and so, $$
\left| \int_{[-1,i]} f(z)^n dz \right|\leq \sqrt{2} (2\sqrt{2})^n \int_0^1 t^n (1-t)^n \left(\sqrt{1+t^2}\right)^n dt
$$ Although it is true that this upper bound is smaller than $\left(\frac{4}{3 \sqrt{3}}\right)^n$ , and the result follows with $k=1$ , I feel that there must be some simpler approach and would appreciate some ideas. In particular, nothing in my calculations gave any hint on the origin or motivation for the ratio $\frac{4}{3 \sqrt{3}}$ .","['integration', 'complex-analysis']"
3892495,Construction of QR decomposition for a singular matrix,"Consider a matrix $A \in \mathbb{C}^{n \times n}$ . Suppose it's non-singular. Then it's columns $a_1, a_2, ..., a_n$ form a basis in $\mathbb{C}^n$ . Let's apply Gram-Schmidt process to them. We will obtain some basis $q_1, q_2, ..., q_n$ . The transition matrix $S$ from the basis $a$ to the basis $q$ is upper-triangular(by construction).
Now, consider the matrix $Q=\big[ q_1|q_2|...|q_n \big]$ . It's columns are orthonormal $\implies$ $Q$ is unitary. And now we know that the matrix $A$ can be represented as: $$
AS=Q \\
A=QS^{-1}
$$ $S$ is invertible since it is a transition matrix. $S$ is upper-triangular $\implies$ $S^{-1}$ is upper-triangular as well. E.g. we have shown that each non-degenerate matrix $A$ can be represented as a product of unitary and upper-triangular matrices. But what if $A$ is singular? I've tried the following: Let's select a basis of column space of $A$ : $a_1, ..., a_r$ (they are columns of $A$ ). And also let's reorder columns of $A$ s.t. these linearly independent vectors $a_1, ..., a_r$ are the first $r$ vectors of the matrix. So, we've done permutation of columns of $A$ . This operation can be represented by right-multiplication of A with some matrix $P$ : $A \rightarrow AP$ . Now we apply Gram-Schmidt to the basis of column space(vectors $a_1,...,a_r$ ), and after extend the resulting basis to an ONB of $\mathbb{C}^n$ : $$q_1,q_2, ..., q_n$$ We have constructed matrix $Q=\big[ q_1 | q_2 | ... | q_n \big]$ that is unitary(since it's columns form an ONB).
The matrix $S$ s.t. $AP=QS$ is upper-triangular. Moreover, it looks like: $$
\begin{bmatrix}
s_{11} & s_{12} & s_{13} & ... & s_{1r} & ... & s_{1n} \\
0 & s_{22} & s_{23} & ... & s_{2r} & ... & s_{2n} \\
0 & 0 & s_{33} & ... & s_{3r} & ... & s_{3n} \\
... & ... & ... & ... & .... & ... & ... \\
0 & 0 & 0 & ... & s_{rr} & ... & s_{rn} \\
0 & 0 & 0 & ... & 0 & ...  & 0\\
0 & 0 & 0 & ... & 0 & ...  & 0\\
... & ... & ... & ... & .... & ... & ... \\
0 & 0 & 0 & ... & 0 & ...  & 0\\
\end{bmatrix}
$$ But how to show now that the matrix $SP^{-1}$ is upper-triangular? For me, it seems like it's not. Can you see a mistake in my thoughts? Maybe, you have other suggestions for construction of $QR$ -decomposition in case of singular matrix? I'm stuck with this issue for a week now and I have no ideas what to do. Thanks!","['matrices', 'unitary-matrices', 'matrix-decomposition']"
3892506,Proving line is tangent to circle.,"Let $W_1$ be a circumcircle of triangle $ABC$ . $D$ be any point on segment $AC$ . And $W_2$ be a circle which is tangent to $BD$ , $AD$ and circle $W_1$ . $M$ be a tangent point on $AD$ . Then prove that the line parallel to $BD$ that passes through the point $M$ is tangent to incircle of $ABC$ . My try: If we take the point which is the intersect of 2 circles as point $E$ . With homotethy we achieve that $F$ is the midpoint of the arc $AC$ . (Whereas $F$ is intersection of $W_1$ and $EM$ ). So $BF$ is angle bisector of angle $ABC$ . And if we take the line that is parallel to $BD$ as $l$ . Intersection of $l$ and $AB$ is $K$ . Since angle $DNM$ $DMN$ and $KMN$ are equal. $MN$ is angle bisector of $KMD$ . (WHEREAS $N$ is tangent point on $BD$ ).Now if we can prove angle bisector of $BCA$ or $BAC$ passes through the point where $BF$ and $MN$ intersected we will achieve that quadrilateral $BKMC$ is tangential one.","['circles', 'geometry']"
3892507,"What happens to the Stone-Cech compactification if you change ""compact Hausdorff"" to ""compact""?",Here if in the diagram below Universal property and functoriality we take a modification that any continuous map $f:X\to K$ where $K$ is compact but not necessarily Hausdorff what would be our $\beta X$ (if $X$ is discrete) in this case instead of all ultrafilters over $X$ ? Would it always exist?,"['filters', 'general-topology', 'universal-property', 'compactness']"
3892553,"Example on coherent scheme but not noetherian, $\mathrm{Spec}\underset{n \in \mathbb{N}}{\cup}k[[t^{\frac{1}{n}}]]$.","In class, my teacher gave an example of coherent scheme that is not noetherian, namely $\mathrm{Spec}\underset{n \in \mathbb{N}}{\cup}k[[t^{\frac{1}{n}}]]$ . The definition, of a coherent sheaf of module over a scheme $(X,\mathcal{O}_X)$ , is a sheaf of $\mathcal{O}_X$ -module locally (on $\mathrm{Spec}{A} \subset X$ ) being $\tilde{M}$ with $M$ a finitely generated $A$ -module, and every kernel of arbitrary $A^{\oplus n} \rightarrow M$ is finitely generated. Going back to the example. $k[[t^{\frac{1}{n}}]]:=A$ is obviously not noetherian. But I don't know how to show that kernel of arbitrary $A^{\oplus n} \rightarrow A$ is finitely generated.","['coherent-sheaves', 'algebraic-geometry', 'schemes', 'sheaf-theory']"
3892563,Finding anti difference for a given expression,"I am given: $$ a_n = \frac{1}{n^2 +3n+2}$$ And am asked to find the anti difference (i.e: quantity which when differences over gives the expression) So, I started by partial fractions $$ a_n = \frac{1}{n+1} + \frac{-1}{n+2} $$ Now the answer to this is: $$ -\Delta \frac{1}{n+1}$$ But its wrong for some reason ( doesn't match with given answers).. Options:",['discrete-mathematics']
3892583,Example where an inverse function does not equal the elements,"I'm trying to find an example of a function $f: A \to B$ and $X \subset A$ so that $f^{-1}(f(X)) \ne X$ , and similarly where $Y \subset B$ so that $f(f^{-1}(Y)) \ne Y$ . I thought to have $f = x^2$ , which has no inverse, thus making it vacuously true that $f^{-1}(f(X)) \ne X$ and $f(f^{-1}(Y)) \ne Y$ , but that seems like a copout. Any help is greatly appreciated.","['elementary-set-theory', 'functions', 'discrete-mathematics', 'inverse-function']"
3892593,"Calculate $ \lim_{\left(x,y\right)\to\left(0,0\right)}\frac{\sin\left(x^{3}+y^{3}\right)}{\sin\left(x^{2}+y^{2}\right)} $","I have to calculate $ \lim_{\left(x,y\right)\to\left(0,0\right)}\frac{\sin\left(x^{3}+y^{3}\right)}{\sin\left(x^{2}+y^{2}\right)} $ From wolfram calculator I know the limit is $ 0 $ . The onl way I cant think of proving it is switch to polar, and to show that $ \lim_{r\to0}\frac{\sin\left(r^{3}\left(\cos^{3}\theta+\sin^{3}\theta\right)\right)}{\sin\left(r^{2}\right)} $ is $ 0$ . If I'll treat $ \theta $ as a constant and I'll get that the limit is zero, is that mean that from any direction that the function getting closer to zero, the limit is zero? If so, I could show it using l'Hospital's rule and I guess it would be easy, but I'm not sure its legit. Thanks in advance","['limits', 'multivariable-calculus']"
3892595,Name or notation for a function f(n) that equals 1 if n = 1 and 0 if n > 1,"While solving number theory problems I sometimes I have to use a function that can be defined as $$
f(n) =
\begin{cases}
1 & \text{ if } n = 1, \\
0 & \text{ if } n > 1.
\end{cases}
$$ where $ n $ is a positive integer. For example, using this function, we can define Euler's totient function as $$ \varphi(n) = \sum_{k=1}^n f(\gcd(k, n))$$ where $ n $ is a positive integer. Is there a name or notation for such a function already? I just want to make sure that I do not create my own notation for something that already has a popular name or notation in mathematics.","['notation', 'functions']"
3892668,"Find the extreme values of $f(x,y)=x^2y$ in $D=\{x^2+8y^2\leq24\}$","Find the extreme values of $f(x,y)=x^2y$ in $D=\{x^2+8y^2\leq24\}$ It was easy to find using Lagrange multipliers the local extreme values on $\partial{D}$ since we have the condition $x^2+8y^2=24.$ I found that $(-4,1),(-4,-1),(4,1)$ are critical points. Now I have to find the extreme values inside $D$ . $\nabla f(x,y)=(2xy,x^2)=(0,0)$ gives me that every $(0,y)$ is a critical point. However, I'm not sure how to get extremes from here, since I cannot use the determinant test. Would be a possibility to use the monotony of $x^2$ depending the sign of $y$ ?","['multivariable-calculus', 'real-analysis']"
3892674,How many times harder is to think in 3D as compared with 2D?,"I'm a chemist, currently going through a course about molecular symmetry and group theory applied to Chemistry. This subject is very demanding in terms of visualization in 3D space. To really grasp the subject, one must be able to see, for example, how the orbitals around a given nucleus transform when subjected to the different symmetry operations in space. I'm stumped by the sheer difficulty I have at it, specially given I deem myself good at reasoning with geometric concepts in the 2D plane. Add just one dimension and now it feels like to be in a quagmire. That makes me wonder, can you put hard numbers in this increased overhead when going from 2D to 3D? How much more processing power is necessary to reason about 3D space? A linear scaling can be surely ruled out as, at least for me, 3D doesn't feel like just 50% more difficult. It feels like a several fold increase in complexity. Could be the case it scales like area or volume, as a power of the number of dimensions, say, n³? What about a generalization to higher dimensions? How much more difficult a 4D being would have reasoning about 4D as compared with 3D? I would not be surprised if grasping something like a 4D were very difficult or even impossible for us, as we don't experience 4D spatial dimensions. But we do live in 3D space, and yet thinking in 3D can be very hard.","['group-theory', 'symmetry', 'geometry', 'dimension-theory-algebra']"
3892727,How to check continuity of this multivariable function,"Here's the function: $$f(x,y)=\begin{cases}{y+{1\over y}\arctan({x^2y})} & y\neq 0\\ 0 & y=0\end{cases}$$ I need to study it's continuity and I've got a hard time understanding exactly how to rigorously formulate my findings (because I don't understand everything that well), so I would like to know if my reasoning is correct. Firstly what I found was that in $f(x,y)=(0,0)$ the function is continuous in $(0,0)$ because the limit of this function for $(x,y)\to(0,0)$ is indeed $0$ . Secondly, the function isn't continuous in $f(x,y)=(x,0)$ if $x$ isn't zero because the limit of f when $y\to 0 $ and $x$ is ""fixed"" is $1$ . Is this reasoning correct and complete ?","['multivariable-calculus', 'calculus', 'continuity']"
3892782,If $\int {yy''dx} = 3xy$ is it possible to find y'?,"So one of the people I know on discord gave me this problem to solve for fun.
I've tried using integration by parts on the left side and it didn't do anything.
The integral transforms into the ODE $yy''- (3xy)'=0$ but it's non-linear and I have no idea how to solve that. Would a series solution work?
Notice that I'm looking for y' not y so maybe there's some trick there?
Any help is appreciated. Thank you for reading.
Here, $y'$ and $y''$ denote the first and second order derivatives of $y$ w.r.t. $x$ .","['integration', 'calculus', 'ordinary-differential-equations']"
