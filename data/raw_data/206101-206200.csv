question_id,title,body,tags
4109207,How come the genus of algebraic curve can be any natural number?,"One the one hand, any topological surface has a complex structure, so for any natural number $g$ , there exists a complex curve with genus $g$ . On the other hand, we have a Chow's theorem, which says that any complex analytic variety is algebraic. This means that there exists a non-singular algebraic curve with genus $g$ . But algebraic curves have a well-defined degree $d$ which connect to the notion of genus using the formula $g=(d-1)(d-2)/2$ . This suggests that $g$ cannot be any natural number. Obviously this argument has a flaw, but where?","['algebraic-curves', 'algebraic-geometry']"
4109251,"How do I show that if the product of idempotents is idempotent, then idempotents commute with other elements?","I was not able to prove the following theorem. I would appreciate some help regarding it: If the product of each two idempotent elements in a unity ring is an idempotent element itself, prove that the product of idempotent and a specifically non-idempotent element is commutative. (The ring $R$ is a unity ring).  In notation: $$\forall a \in R \forall x \in R (a^2=a \land x^2 \neq x \longrightarrow xa=ax).$$ I'm very new to group theory in general, so I can't properly find an example to demonstrate my point. I'm not even aware exactly of terms such as ""ideals"" etc. I will however state the original theorem which this was a derivative of: For a unity ring $R$ , prove that if the product of two idempotent elements is also idempotent, then all idempotent elements of the ring are an element of its center. Since one has to prove that for all elements of the ring $R$ multiplied by an arbitrary idempotent element such as $a$ have the commutative property, I divided the case for the arbitrary element $x$ in two cases: for $x$ which is idempotent, and for $x$ which is not. I was able to prove that if $x$ is idempotent, the commutative property holds for its product with $a$ (the arbitrary idempotent element of $a$ ), but I wasn't able to do it for when $x$ is strictly non-idempotent; and that's why I stated the theorem above. I'll be thankful if you provide a solution for the first theorem and not a different method to prove the original theorem in a different way.","['ring-theory', 'abstract-algebra', 'idempotents']"
4109312,Parallel second fundamental form,"I wonder if the following statement is true: If $M^n$ is a smooth complete submanifold of $\mathbb R^{n+p}$ with $\nabla A=0,$ where $A$ is the second fundamental form of $M,$ then $M=S^k\times\mathbb R^{n-k}$ for some $k.$ By Lawson's theorem in $\textit{Local Rigidity Theorems for Minimal Hypersurfaces},$ we know that the statement is true when $M$ is a hypersurface (i.e., $p=1$ ), but I am not sure if it is true in the higher codimension case. Any ideas or comments are appreciated!","['curvature', 'riemannian-geometry', 'differential-geometry']"
4109315,Improving my understanding of arc length in relation to 1-forms,"I apologies in advance if this question is so trivial, I had read some textbook on Riemannian geometry and I dont have some things clear. This is the thing: I saw some questions about the arc length showing that it can't be a differential form in the ambient space and I would like to clarify some points. So these are my questions: Let a regular curve $C$ in $\mathbb{R}^n$ , then in view of the comments of this question using recursively the interior multiplication over the canonical volume form in $\mathbb{R}^n$ I can get an induced volume form $\omega$ in $C$ , so What exactly mean the integral of this induced volume form? There is a relation with the arc length $ds$ , maybe something like $\|\omega \|_2=ds$ ? Thank you in advance.","['arc-length', 'riemannian-geometry', 'differential-geometry']"
4109344,"Differentiability of $f : \mathbb{R}^n \rightarrow \mathbb{R}^n$, where $|x-y - (f(x) -f(y))| \leq \frac{1}{2}|x-y|$","Question: If $f : \mathbb{R}^n \rightarrow \mathbb{R}^n$ is a continuous function that satifies $|x-y - (f(x) -f(y))| \leq \frac{1}{2}|x-y|$ for all $x,y \in \mathbb{R}^n$ , prove that $f$ is differentiable at 0. My attempt: Let $y=0$ . Then $|(f(x)-f(0)) - x| \leq \frac{1}{2}|x|$ . Then $\frac{|(f(x)-f(0)) - x|}{|x|} \leq \frac{1}{2}$ I know I need to show that $\frac{|(f(x)-f(0)) - Mx|}{|x|} \rightarrow 0$ for some linear transformation $M$ , but I'm at a loss as to how to use the condition. In particular, the $\frac{1}{2}$ is fixed, so I don't see how to proceed.","['multivariable-calculus', 'derivatives']"
4109375,Introduction to Hardy spaces,"What text would you recommend for a (not too long) introduction to Hardy spaces? I am specially interested in real Hardy spaces but I also want to learn about complex ones. I'm a graduate student with some background in harmonic, complex and functional analysis.","['reference-request', 'harmonic-analysis', 'functional-analysis', 'real-analysis']"
4109407,"If $B \subsetneq A$ and $ f : A \rightarrow B $ is injective, then $ f[B] \subsetneq B $","Problem : Let $ A,B $ be sets such that if $B \subsetneq A$ and $ f : A \rightarrow B $ is injective, then $ f[B] \subsetneq B $ . Attempt: Suppose $B \subsetneq A$ and $ f \in A \rightarrow B $ is injective. Let $ y  $ be arbitrary. Suppose $ y \in f[B] $ . Hence there exists $ h \in B $ ( since $ f[B] = \{ f(h) | h\in B \}  $ ) s.t. $ f(h) = y \in B.  $ Hence $ y \in B $ . Since $ y $ was arbitrary we showed $ f[B] \subseteq B $ . Now we'll show $ B \nsubseteq f[B]$ ( this will prove $ f[B] \neq B  $ ). [ I tried supposing $ B \subseteq f[B]$ and to reach a contradicition but I wasn't able to show this ]. Difficulty: Naively looking at my attempt, there are several things to be noted: I'm not using the assumption that $ f $ is injective, in addition, I'm not refering to the fact that $B \subsetneq A$ and so my attempt just feels wrong like I've neglected important details but not aware how exactly refer to them. Can you please give me a guidance?","['elementary-set-theory', 'functions', 'discrete-mathematics']"
4109452,"Calculate $\lim_{n\rightarrow \infty }\int_{0}^{\pi /2}\sqrt[n]{\sin^nx+\cos^nx}\,dx$","I solved an interesting limit sometime, maybe someone will suggest a simpler solution, perhaps through the Lebesgue measure. \begin{align*}
\lim_{n\rightarrow \infty }\int_{0}^{\pi /2}\sqrt[n]{\sin^nx+\cos^nx}\,dx&=\lim_{n\rightarrow \infty }\left [\int_{0}^{\pi /4}\sqrt[n]{\sin^nx+\cos^nx}\,dx+\int_{\pi /4}^{\pi /2}\sqrt[n]{\sin^nx+\cos^nx} \,dx\right ]\\
&=\lim_{n\rightarrow \infty} \left [ \int_{0}^{\pi /4}\sqrt[n]{\sin^nx+\cos^nx}\,dx+\int_{-\pi /4}^{0}\sqrt[n]{\cos^nx+\left ( -\sin x \right )^n} \,dx\right]\\&
=2\lim_{n\rightarrow \infty }\int_{0}^{\pi /4}\sqrt[n]{\sin^nx+\cos^nx}\,dx
\\
&=2\lim_{n\rightarrow \infty }\int_{0}^{\pi /4}\cos x\sqrt[n]{\tan^nx+1}\,dx\\
&=\sqrt{2}
\end{align*} $$\int_{0}^{\pi /4}\cos x\,dx<\int_{0}^{\pi /4}\operatorname{cos}x\sqrt[n]{\tan^nx+1}\,dx<\sqrt[n]{2}\int_{0}^{\pi /4}\cos x\,dx$$","['integration', 'calculus', 'real-analysis']"
4109486,Example of function satisfying the growth condition: $\phi\big(\theta \frac{s}{t}\big) \leq \frac{\phi(s)}{\phi(t)}$,"I am barely looking for example(s) of invertible convex functions $\phi: [0,\infty)\to [0, \infty)$ such that $\phi(0)=0$ and there exists $\theta>0$ and for all $s\leq t$ we have \begin{align}\label{EqI}\tag{I}
\phi\big(\theta \frac{s}{t}\big)	\leq \frac{\phi(s)}{\phi(t)} \qquad\text{or equaly}  \qquad  \theta  \leq \phi^{-1}\big(\frac{s}{t}\big)\frac{\phi^{-1}(t)}{\phi^{-1}(s)}
\end{align} The most simple class consists of polynomial functions of the form $\phi(t)= ct^p$ with $c>0$ and $p>0$ . Question: Are there other possible non-polynomial examples satisfying $\eqref{EqI}$ ? I have tried without success with $\phi(t)= e^{t^\alpha}-1$ , $\alpha>0$ .","['examples-counterexamples', 'real-analysis', 'calculus', 'functions', 'convex-analysis']"
4109493,What is the density of numbers which have at least two divisors whose sum is a perfect square?,"Update : Posted in MO since it is unanswered in MSE after 2 years. A positive integer is said to have square-sum divisors if it has at least two divisors whose sum is a perfect square. $6$ has square-sum divisors because its divisors are $(1,2,3,6)$ and $1 + 3 = 2^2$ . Also $3 + 6 = 3^2$ $10$ has no square-sum divisors since no two of its divisors $(1,2,5,10)$ add up to a square Trivially, all multiples of $3, 8, 14, 20, 34, 35, 46, 55, 62, 94, 95, 130, 142, 143, 155, 158, ...$ have square-sum divisors. Question : Let $f(n)$ be the number of positive integers $\le n$ which have square-sum divisors. What is the limiting value $$
\lim_{n \to \infty}\frac{f(n)}{n}
$$ Update 14-Jun-2021 : For $n = 1.3 \times 10^{10}$ , the ratio is $0.571284$ showing that the growth rate is extremely slow since the ratio had reached $0.57$ by $n = 4 \times 10^5$ . Sagemath code using extended skip list suggested by Mees de Vries. n = f = 0
step = 10^5
target = f

skip = [3, 8, 14, 20, 34, 35, 46, 55, 62, 94, 95, 130, 142, 143, 155, 158,
        194, 203, 254, 295, 299, 323, 334, 395, 398, 418, 430, 446, 473, 482]

while n < 10^30:
    d = divisors(n)
    l = len(d)
    c = i = 0
    stop = False
    
    while i < l and stop == False:
        j = i + 1
        while j < l and stop == False:
            if (d[i] + d[j])^0.5 %1 == 0:
                c = 1
                stop = True
            j = j + 1
        i = i + 1
        
    if c == 0:
        f = f + 1 
        
    if f >= target:
        print(f,n,1 - f/n.n())
        target = target + step

    found = False
    while found == False:
        n = n + 1
        if all(n%x != 0 for x in skip):
            found = True","['divisibility', 'number-theory', 'elementary-number-theory', 'asymptotics', 'analytic-number-theory']"
4109524,Inequality $\Gamma\left(\sin\left(\frac{1}{x}\right)\right)-\Gamma\left(\sin^2\left(\frac{1}{x}\right)\right)-x+x^2+\frac{1}{3}\geq 0$,Problem found with the help of Desmos and my imagination . Let $x\geq 1$ then we have : $$\Gamma\left(\sin\left(\frac{1}{x}\right)\right)-\Gamma\left(\sin^2\left(\frac{1}{x}\right)\right)-x+x^2+\frac{1}{3}\geq 0$$ Some informations : We have the limits : $$\lim_{x\to \infty}\Gamma\left(\sin\left(\frac{1}{x}\right)\right)-x=-\gamma$$ And : $$\lim_{x\to \infty}\Gamma\left(\sin^2\left(\frac{1}{x}\right)\right)-x^2=-\gamma+\frac{1}{3}$$ It doesn't work with higher degree like $3$ .It seems to be a little  mysterious . The derivative is very complicated and I don't expose it here . How to show the inequality ?,"['gamma-function', 'trigonometry', 'inequality']"
4109557,"Is $\emptyset$ a finite union-closed family of finite sets, other than the family containing only the empty set or not","I am very weak in logic. In Wikipedia, there is the following article: In combinatorics, the union-closed sets conjecture is an elementary problem, posed by Péter Frankl in 1979 and still open. A family of sets is said to be union-closed if the union of any two sets from the family remains in the family. The conjecture states: For every finite union-closed family of finite sets, other than the family containing only the empty set, there exists an element that belongs to at least half of the sets in the family. I wonder if $\emptyset$ is a finite union-closed family of finite sets, ohter than the family containing only the empty set or not. If so, I wonder if there exists an element that belongs to at least half of the sets in $\emptyset$ or not. Proposition 1: $\emptyset$ is a finite union-closed family of finite sets and is not equal to $\{\emptyset\}$ . Proposition 2: There exists an element that belongs to at least half of the sets in $\emptyset$ . Is Proposition 1 true or false? Is Proposition 2 true or false? My attempt is the following: About Proposition 1: No object belongs to $\emptyset$ , but $\emptyset$ belongs to $\{\emptyset\}$ . So, $\emptyset \neq \{\emptyset\}$ . $\emptyset$ is a finite set. (this fact is famous.) Since $\emptyset\ni S$ is always false, so ""if $\emptyset \ni S$ , then $S$ is a finite set"" is true. So, $\emptyset$ is a family of finite sets. Since $\emptyset\ni S, T$ is always false, so ""if $\emptyset\ni S, T$ , then $S \cup T\in\emptyset$ "" is true. So, $\emptyset$ is a finite union-closed family of finite sets and is not equal to $\{\emptyset\}$ . About Proposition 2: I guess this proposition is false. There is no set which belongs to $\emptyset$ . So, there is no element that belongs to a set which belongs to $\emptyset$ . I cannot express Proposition 2 by using logical symbols. How to express Proposition 2 by using logical symbols?","['logic', 'combinatorics']"
4109670,"I throw a coin 10 times, and I get all heads, what is strange here? [duplicate]","This question already has answers here : Why is observing 100 heads for a fair coin flips surprising? (10 answers) Closed 3 years ago . I take a coin and with the assumption that it is a fair coin. I throw it 10 times and I get a sequence of 10 consecutive heads. I feel something is unusual and strange, may be the coin is not fair. But the outcome I got is as likely as any other sequences of heads and tails. However there is something really strange here, the probability of getting no tails in 10 throws of a fair coin is really small. So indeed there is something strange here. And common sense says the coin is probably not fair. But isn't ""containing no tails"" just an arbitrary property of my outcome? May be my outcome is not unusual considering lots of other properties? Or may be you can come by an unusual property for any sequence of heads and tails? My question is why seeing no tails in 10 throws is a good reason to doubt fairness of the coin? P.S.:
To abide with the laws of stackexchange my formal question is what I stated above. But my real question is something more general and vague: when we see something strange on what grounds we can say what we saw is just a low probability result of the way I think the world works or I should change my view about how the world works? Are there certain things that I should check before changing my view? I would be grateful if you can help me with my real question too.",['probability']
4109701,Find $S = a + b$ such that for $\forall m \in \left[a\sqrt{\frac{15}{7}} + b\sqrt{\frac{7}{15}}; 2\right)$ then $2x^2 + 2x - mf(x) + 5 = 0$ has root,"Let $f(x)$ be continuos on $\mathbb R$ satisfy $f(0) = 2\sqrt{2}$ and $f(x) > 0, \forall x \in \mathbb R$ and $f(x) f'(x) = (2x+1)\sqrt{1+f^2(x)}$ .
For all $m \in \left[a\sqrt{\dfrac{15}{7}} + b\sqrt{\dfrac{7}{15}}; 2\right)$ , then $2x^2 + 2x - mf(x) + 5 = 0$ has at least a root. Find $S = a + b$ Here is what I did so far $$f(x) f'(x) = (2x+1)\sqrt{1+f^2(x)}$$ $$\implies \dfrac{f(x) f'(x)}{\sqrt{1+f^2(x)}} = 2x+1$$ $$\implies \int \dfrac{f(x) f'(x)}{\sqrt{1+f^2(x)}} \,dx = \int2x+1 \,dx = x^2 + x + C$$ Let $t = f^2(x) + 1 \implies dt = 2f'(x)f(x) dx$ . Therefore: $$\int \dfrac{1}{2\sqrt{t}} \,dx = x^2 + x + C$$ $$\implies \sqrt{t} = x^2 + x + C$$ $$\implies \sqrt{1 + f^2(x)} = x^2 + x + C \, (2)$$ Since $f(0) = 2\sqrt{2}$ , plug in $(2)$ we get $C = 3 \implies f(x) = \sqrt{(x^2+x+3)^2 - 1}$ I can't proceed further from here","['integration', 'calculus', 'derivatives', 'polynomials']"
4109751,Relation between $Y$ and $Y^{\perp}$ in a Banach space,"Given any normed linear space $X$ let $Y$ be a subspace of $X$ . Define $$Y^\perp:=\{f\in X^* :~ f(y)=0~\forall~y\in Y\}.$$ I have stuck in a problem which asks to show that if $Y$ is closed, then $$Y=\bigcap\limits_{g\in Y^\perp} \ker g.$$ As a hint: it says apply geometric Hahn-Banach Theorem or Mazur's separation Theorem. I do not know, how to proceed. EDIT I did the forward $\subseteq$ part in the comment. I am trying the reverse part following the comment of UmbertoP. Let $W=\bigcap\limits_{g\in Y^\perp} \ker g$ and let $x\in W\setminus Y$ . Then due to the closedness of $Y$ and compactness of $\{y\}$ , we can find a convex neighborhood about the zero vector say $V$ such that $$(Y+V)\cap (x+V)=\emptyset.$$ In particular, $Y$ is disjoint from a convex open set $(x+V)$ . By Mazur's Theorem, there exists a closed hyperplane $H$ containing $Y$ and disjoint from $(x+V)$ . Consider a linear functional $h$ with $\ker h=H$ . Then this $h$ is continuous, annihilates $Y$ . So, $h\in Y^\perp$ but $x\notin \ker h$ , a contradiction. Please help me regarding this.","['functional-analysis', 'real-analysis']"
4109782,Using $|\sin\theta|=\frac{2}{\pi}-\frac4\pi\sum_{m=1}^\infty\frac{\cos(2m\theta)}{4m^2-1}$ to calculate $\sum_{m=1}^\infty\frac1{16m^2-1}$ [duplicate],"This question already has answers here : Solve $\sum_{k=0}^{\infty}\frac{1}{1-16k^2}$ (3 answers) Closed 2 months ago . By the equation $|\sin(\theta)|=\frac{2}{\pi}-\frac{4}{\pi} \cdot \sum_{m=1}^{\infty}\frac{\cos(2m\theta)}{4m^2-1}$ , how can I get the value of $\sum_{m=1}^{\infty}\frac{1}{16m^2-1}$ ? If I substitute $\theta=\frac{\pi}{2}$ , $|\sin(\frac{\pi}{2})|=\frac{2}{\pi}-\frac{4}{\pi} \cdot \sum_{m=1}^{\infty}\frac{\cos(m.\pi)}{4m^2-1}=1$ . For odd $m$ , $\cos(m.\pi)=-1$ and, for even $m$ , $\cos(m.\pi)=1$ . The sum of even $m$ is $\sum_{m=1}^{\infty}\frac{1}{4.(2.n)^2-1}=\sum_{m=1}^{\infty}\frac{1}{16.n^2-1}$ , the sum that I want to know the value, but how can I represent the sum of odd $m$ ? Solution, after receiving @OlivierOloa's answer below : If I substitute $\theta=\frac{\pi}{2}$ , $|\sin(\frac{\pi}{2})|=\frac{2}{\pi}-\frac{4}{\pi} \cdot \sum_{m=1}^{\infty}\frac{\cos(m.\pi)}{4m^2-1}=1$ . For odd $m$ , $\cos(m\pi)=-1$ and, for even $m$ , $\cos(m\pi)=1$ . If I substitute $\theta=0$ , $|\sin(0)|=\frac{2}{\pi}-\frac{4}{\pi} \cdot \sum_{m=1}^{\infty}\frac{1}{4m^2-1}=0$ . $$\begin{align}\left|\sin\frac\pi2\right|+|\sin0|&=\frac4\pi-\frac4\pi\sum_{m=1}^{\infty}\frac{1+\cos(m\pi)}{4m^2-1}=1\\&\Rightarrow\frac4\pi\left(1-2\sum_{n=1}^\infty\frac1{4(2n)^2-1}\right)=1\\&\Rightarrow1-2\sum_{n=1}^{\infty}\frac1{16n^2-1}=\frac\pi4\\&\Rightarrow -2\sum_{n=1}^\infty\frac1{16n^2-1}=\frac{\pi-4}4\\&\Rightarrow\sum_{n=1}^\infty\frac1{16n^2-1}=\frac{4-\pi}8.\end{align}$$","['fourier-series', 'sequences-and-series']"
4109786,Last step in the proof of second derivative test,"I came across a problem studying the proof of the Second Derivative Test theorem from Spivak's Calculus (Chapter 11, Theorem 5, p199, 3rd edition): Suppose $\operatorname{f}^\prime(a) = 0$ . If $\operatorname{f}^{\prime\prime}(a) > 0$ , then $\operatorname{f}$ has a local minimum at $a$ . I'm able to follow the proof until the very last point, where the author concludes after observing the sign of $\operatorname{f}^\prime$ around $a$ , that since $\operatorname{f}$ is increasing in some interval to the right of $a$ and decreasing in some interval to the left of $a$ , [...] f has a local minimum at a. The way I understood this, is that $\operatorname{f}$ decreases on $(a-h, a)$ and increases on $(a, a+h)$ for some $h > 0$ , but there is nothing said about the point $a$ itself. I managed to come up with two proofs, none of them seems straightforward enough just to be omitted from the book, so I have the impression that I'm missing a point. For any $b \in (a-\delta, a)$ consider $c = \frac{b + a}2$ . $\operatorname{f}$ is decreasing, so $ \epsilon = \frac{\operatorname{f}(b) -\operatorname{f}(c)}{2} > 0 $ . From the (left-)continuity of $\operatorname{f}$ at $a$ for this $\epsilon$ there is some $\delta > 0$ such that $\forall x: 0 \le a - x \lt \delta : \left| \operatorname{f}(x) - \operatorname{f}(a) \right| < \epsilon \Leftrightarrow \operatorname{f}(x) - \epsilon < \operatorname{f}(a) < \operatorname{f}(x) + \epsilon $ . For any $x$ that satisfies both $0 \le a - x \lt \delta \text{ and } c < x $ , we get from the previous inequality together with the fact that f is decreasing: $\operatorname{f}(a) < \operatorname{f}(x) + \epsilon < \operatorname{f}(c) + \epsilon < \operatorname{f}(c) + \frac{\operatorname{f}(b) -\operatorname{f}(c)}{2} < \frac{\operatorname{f}(b) +\operatorname{f}(c)}{2} < \operatorname{f}(b)$ . The proof that $\operatorname{f}(a) < \operatorname{f}(b)$ for all $b \in (a, a+\delta)$ is similar. I know, that if $\operatorname{f}$ was continuous on some $(a-\delta, a+\delta)$ interval, then there would be a closed interval inside this open interval (e.g $ [a-\frac{\delta}{2}, a+\frac{\delta}{2}]$ ), where f takes on its minimum value at some point $b$ . By way of contradiction we can see that $b = a$ , otherwise $\operatorname{f}(\frac{a + b}{2}) < \operatorname{f}(b)$ would contradict the conclusion that $b$ is a minimum place. Since $\exists \lim_{h\to 0} \frac{\operatorname{f}^\prime(a + h) - \operatorname{f}^\prime(a)}{h}  = \operatorname{f}^{\prime\prime}(a)$ , $\operatorname{f}^\prime(x)$ must exist $\forall x \in (a-\delta, a+\delta)$ for some small $\delta > 0$ , thus f is continuous on $(a-\delta, a+\delta)$ , thus the first part of this proof holds. My questions: Are these proofs correct? Is there a more direct way to conclude from the last part of the proof provided in the book that $\operatorname{f}$ has a local minimum at $a$ ?","['continuity', 'derivatives', 'real-analysis']"
4109797,When is the heat semigroup Gibbs?,"Defining the Laplacian on a region $\Omega$ of $\mathbb{R}^{d}$ with Dirichlet boundary conditions, under what conditions on the region (or other possible assumptions) is the semigroup it generates Gibbs, i.e. trace-class? For example, if $\Omega$ has finite volume, this is the case, and the book ""Heat Kernels and Spectral Theory"" by E. Brian Davies (where this question is inspired from) provides one other set of conditions (involving strongly regular regions). Are there other references that study this question?","['operator-theory', 'functional-analysis', 'reference-request']"
4109814,What distinguished the Möbius strip from the cylinder as fibre bundles?,"I'm a physicist trying to understand fibre bundles, and I think I'm pretty happy with the wikipedia definition ""a space that is locally a product space, but globally may have a different topological structure"" . I think I also have a grasp, in the general and tangent cases, on the different objects in the fibre bundle: $(E, \pi, M, F, G)$ taken singularly and abstractly. However, I'm having trouble seeking what tells apart two fibre bundles $E$ , the Möbius strip and the cylinder. Both have base $M=S^1$ and fibre $F=$ (a segment), so what's different in the two of them? Is it the projection $\pi$ , the structure group $G$ or maybe trivially just the total space $E$ ?","['general-topology', 'algebraic-topology', 'fiber-bundles']"
4109827,Multivariable Calculus and Differentiability,"$$f(x,y)=\begin{cases}\dfrac{y^3}{x^2+y^2} &(x,y) \neq \ \mathbb{(0,0)}\\ 0 &  (x,y)=(0,0) \\ \end{cases}$$ Evaluate $f_x(0,0)$ and $f_y(0,0)$ and $D_\overrightarrow{u}f(0,0)$ I tried directly taking the derivative to no avail (obviously) so then I tried to use the definition of partial derivative which also left me without a correct solution. Also I have proved that it is continuous (Sertoz Theorem) but how would I prove that it is also differentiable at $(0,0)$ ?","['multivariable-calculus', 'derivatives', 'piecewise-continuity']"
4109870,Generalization of consequence of law of cosine,"There is the immediate consequence of the law of cosine stating that when fixing two sidelengths of a triangle and increasing the third, the vertex angle opposite of the third side increases as well. Moreover, this increase of the third side causes the adjacent angles to decrease. I feel like the following generalization of this should hold: Let $a,b,c$ and $a',b',c$ be the sidelengths of two triangles and let $\gamma$ and $\gamma'$ be the vertex angles opposite of the side $c$ (which has the same length in both triangles). If $a+b \leq a'+b'$ , then $\gamma \geq \gamma'$ . Simply put, if the sum of the lengths of the adjacent sides of an angle increases (and the opposite length is kept fixed) then this angle decreases.
Ideally, this should hold not only in the plane but in any space where the law of cosine holds, specifically I am thinking of the sphere and hyperbolic space. I am having trouble proving this but my gut tells me this has to be true (I did not find anything online, although admittedly I am unsure how to search for this). Intuitively, since $c \leq a+b \leq a'+b'$ , the detour through $A$ is ""closer"" to the shortest connection from $C$ to $D$ than the detour through $B$ , so $A$ is closer to the segment $CD$ than $B$ is. This should somehow imply that the angle at $A$ is larger than the angle at $B$ (the angle increases when approaching a segment, with the extreme case of an angle of $\pi$ if the point is on the segment). I am grateful for any further information!","['euclidean-geometry', 'metric-geometry', 'monotone-functions', 'geometry', 'trigonometry']"
4109874,Find the limit using Riemann sum,"Find the limit: $
\lim\limits_{n\to\infty}\sqrt[n]{\left(\dfrac{1 + n}{n^2} \right)\left(\dfrac{4 + 2n}{n^2} \right)...\left(\dfrac{n^2 + n^2}{n^2} \right)}
$ I tried simplifying this limit and the one I get to is: $
\lim\limits_{n\to\infty}\dfrac{1}{n^2}\bigg(\big(2n\big)!\bigg)^{\dfrac{1}{n}}
$ I have an instruction to write the limit as a definite integral and then calculate its value. I think that there should be a way to represent the last limit as a Riemann sum and then calculate it with the integral. But I'm not sure how to get to the Riemann sum. Looking forward for any ideas!",['integration']
4109880,Conditional expectation of controlled diffusion process with respect to a trajectory of the control,"Suppose $a_t$ is the solution to an SDE controlled by the process $b_t$ (both processes are defined on the same probability space) \begin{align*}
    a_t &= a_0 + \int_0^t f_a(a_s, b_s)ds + \int_0^t \sigma_a(a_s, b_s) dW_s \\
    %b_t &=b_0 + \int_0^t f_b(a_s, b_s)ds + \int_0^t \sigma_b dW^b_s
\end{align*} Let $b_{0\leq s\leq t}$ denote a trajectory of the process $b$ up to time $t$ and consider the conditional expectation \begin{align*}
  \textbf a_t :=  \mathbb E[a_t \mid b_{0\leq s\leq t}]
\end{align*} Question: given a trajectory $b_{\leq t}$ does $\textbf a_t$ solve the SDE \begin{align*}
   \textbf a_t &= \textbf a_0 + \int_0^t f_a(\textbf a_s, b_s)ds
\end{align*} ? What if $f_a$ is linear or when $\sigma_a$ is constant? This sounds plausible by taking the conditional expectation of the initial SDE and using the fact that Ito stochastic integrals are martingales so should vanish in expectation, however, I am not able to prove it rigorously. Maybe with a generalization of Ito's lemma for stochastic processes? Any help or pointers to references (books, papers) that could help me solve this would be really appreciated.","['conditional-expectation', 'control-theory', 'stochastic-processes', 'stochastic-differential-equations', 'probability']"
4109882,Kummer theory as an equivalence of categories,"The main theorem of Galois theory (in the finite case, for convenience) says that Theorem 1: Let $L/k$ be a finite Galois extension with Galois group $G$ . The maps $$M\mapsto \operatorname{Aut}(L|M)\qquad\text{and}\qquad H\mapsto L^H$$ yield an inclusion-reversing bijection between subfields $k\subset M\subset L$ and subgroups $H\subset G$ . This result can be generalized into an equivalence of categories which is known as Grothendieck's Galois theory : Theorem 2: Let $k$ be a field and fix a separable closure $k_s$ . The functor mapping a finite étale $k$ -algebra $A$ to the finite set $\hom_k(A,k_s)$ gives an anti-equivalence between the category of finite étale $k$ -algebras and the category of finite sets with continuous left $\operatorname{Gal}(k)$ -action. Now, the main theorem of Kummer theory is very similar in style to our Theorem 1. For that, we will say that a finite Galois extension $L/k$ is $n$ -Kummer if $k$ contains a primitive $n$ -th root of unity and if $\operatorname{Gal}(L/k)$ is abelian of exponent dividing $n$ . Theorem 3: Let $n\geq 1$ , $k$ be a field and fix and algebraic closure $\bar{k}$ . The maps $$M\mapsto k^\times \cap M^{\times n}/k^{\times n}\qquad\text{and}\qquad A\to k[\sqrt[n]{a}:[a]\in A]$$ yield an inclusion-preserving bijection between the $n$ -Kummer extensions $M/k$ contained in $\bar{k}$ and the finite subgroups $A$ os $k^\times/k^{\times n}$ . I wonder if we can write our theorem 3 as an equivalence of categories similar to the one in theorem 2.","['field-theory', 'number-theory', 'abstract-algebra']"
4109895,"Given any compact surface in $\mathbb{R}^3 $, there is a point with positive Gaussian Curvature","So if we have a compact surface $S \subset \mathbb{R}^3 $ then the function $f:S\rightarrow \mathbb{R}_{\geq 0 },\  x \mapsto ||x|| $ has a maximum value say $R >0$ at $p \in S$ . Then we must have the surface $S$ fully enclosed by the sphere of radius $R$ as otherwise $f(p)$ is not the maximum value. This means that the curvature $\kappa $ at $p$ must be at least $1/R \ $ for any curve on $S$ passing through $p.$ This next part is what I don't understand So every normal curvature is at least $1/R$ so $K(p)\geq 1/R^2 >0 $ . Why must every normal curvature be at least $1/R$ and why should that then mean $K(p)\geq 1/R^2 $ ?
For the final part I suspect it is because the Gaussian curvature is the product of the principal curvatures, but why should they be at least $1/R$ ?","['surfaces', 'curvature', 'differential-geometry']"
4109913,Combinatorial Necklaces & Strips of $n$ Beads and $k$ Colours,"Say I have $n$ indistinguishable beads and $k$ different colours. Suppose here and for the rest of the writeup that $k \mid n$ unless otherwise stated. I want to colour all the $n$ beads using exactly $k$ colours, such that each colour is used exactly $n \over k$ times. For the purpose of this question, rotations that result from the same initial configuration are considered the same, whereas reflections are considered distinct. In how many ways can this be done if I am to form a strip ? In how many ways can this be done if I am to form a necklace ? It is more of a general question, but is there any rule of thumb / way of thinking / mathematical formulation, that transforms a combinatorial ""line"" question to a ""loop"" question? I.E, asking questions 1 & 2, with same rule of rotations/reflections, but about a different set of configurations. My progress so far: The initial textbook question was formatted differently, but imagining it as necklaces and beads finally led me to search the right keywords and I found what I believe to be the correct approach to this problem. This wikipedia page seems to be talking exactly about that. The $N_k(n)$ , $L_k(n)$ , $B_k(n)$ are different countings of the necklaces under slightly different rules. Formulas are given for each, using common number-theoretical functions. All $3$ functions allow $k \nmid n$ cases. $B_k(n)$ uses PET  to count reflections as equivalent as well, and thus isn't what I am looking for. To my understanding, $N_k(n)$ allows any number of colours up to $k$ to be used, again not quite my goal. But The $L_k(n)$ formula seems promising, as it counts the configurations using exactly $k$ colours. The difference is that $L_k(n)$ counts $1$ red bead, $2$ yellow beads and $3$ green beads as a valid configuration (because it uses 3 colours), whereas my question deems it invalid, as it uses each colour a different number of times. I believe a modification to it can answer my original question but I cannot see how exactly and I also might be wrong. Fortunately, the wikipedia page lists 2 examples with pictures that comply with my question rules. The $n=6 , k = 3$ case yields $16$ results. The $n=6 , k = 2$ yields $4$ results. Also useful to watch and take results from is this page , listing results and configurations of $N_k(n)$ and $B_k(n)$ for arbitrary values of $n$ and $k$ .","['number-theory', 'combinatorics', 'necklace-and-bracelets', 'discrete-mathematics', 'elementary-set-theory']"
4109949,Interesting Integral including $\ln x$,"I would like to evaluate this integral: $$\int_0^1  \frac{\sin(\ln(x))}{\ln(x)}\,dx$$ I tried a lot, started by integral uv formula [ integration-by-parts? ] and it went quite lengthy and never ending. Then, thought may be expansion of $\sin x$ but it didn't made any sense, it's a infinite series and there's no way here that it will end.. It is highly appreciated if you give some hints to solve it. I am a high school student,so I expect it to be simple but tricky:-)","['integration', 'definite-integrals', 'derivatives']"
4109981,Is there an algebraic characterization of disjoint support in some group action?,"Let $\phi:G\hookrightarrow \text{Sym}(X)$ be a faithful $G$ -action on a set $X$ . Consider $g,h\in G$ s.t. $\text{supp}(\phi(g))\cap\text{supp}(\phi(h))=\varnothing$ . It is easy to show that $\phi(g)$ and $\phi(h)$ commute and $\langle \phi(g)\rangle\cap\langle\phi(h)\rangle=\{\text{id}_X\}$ . These are purely algebraic properties that can be brought back by $\phi^{-1}$ so $g$ and $h$ must commute and $\langle g\rangle\cap\langle h\rangle=\{e\}$ . So we took a particular $G$ -action and learned purely algebraic information about $G$ by looking at the support. My question is whether we can go the other way and define a purely algebraic conditions on elements $g,h$ for there being a faithful $G$ -action s.t. $g$ and $h$ 's action on the set have disjoint support. It's obvious not the case that if this holds for one faithful action, then it holds for all faithful actions, e.g. the only pairs of elements with disjoint support in the faithful action of $G$ on itself by left multiplication is the identity with some other element. My intuition is that $g$ and $h$ commuting and $\langle g\rangle\cap\langle h\rangle=\{e\}$ is a necessary and sufficient condition for there being a faithful $G$ -action s.t. $g$ $h$ have disjoint support. My reasoning is that this implies that $\langle g,h\rangle$ is the internal direct sum of $\langle g\rangle$ and $\langle h\rangle$ . In my mind, this means that $g$ and $h$ are independent in some sense. However, I have not had any luck constructing a specific $G$ -action given elements $g$ and $h$ that meet my criteria. Is there some way to prove this or am I missing a condition? Also, is there any literature related to this topic?","['symmetric-groups', 'group-theory', 'group-actions']"
4110063,Proving $\lim\limits_{x\to0}{\frac{\sin(\frac{1}{x})}{\sin(\frac{1}{x})}}=1$,"I am relatively new to calculus and I'm trying to understand it rigorously. For this question, assume that I only consider the functions to have purely real domains and ranges. I have seen that $\lim\limits_{x\to0}{\frac{\sin(\frac{1}{x})}{\sin(\frac{1}{x})}}=1$ is considered true. This is what my calculator and an online limit solver gave, so unless they are wrong, there must be a flaw in my reasoning. I do not understand it or know how to prove it using epsilon and delta. Here's what I've thought so far: For any function f, $\frac{f(x)} {f(x)}=1$ if f is nonzero and defined at x. If these conditions are met when $|x-c|\in(0, \delta)$ , the quotient is one, so any epsilon satisfies the condition. This means that to prove $\lim\limits_{x\to c}{\frac{f(x)}{f(x)}}=1$ , you just need to show that f is nonzero and defined when $|x-c|\in(0, \delta)$ . I don't believe this can be shown for $f(x)=\sin(\frac{1}{x})$ , since it has infinitely many x-intercepts within any $\delta$ . Have I made a mistake anywhere or failed to consider something? How would this be normally demonstrated?","['limits', 'calculus', 'epsilon-delta']"
4110074,evaluating limit of $\lim_{x \to 0}\frac{1-\cos(x)}{\sin(x)(e^x-1)}$,"This is for evaluating limit of $\lim_{x \to 0}\frac{1-\cos(x)}{\sin(x)(e^x-1)}$ . It's easy with evaluating using L'Hôpital's Rule, but I want to use Taylor series. I can see here $\cos(x)=\sum_{n=0}^{\infty}\frac{(-1)^nx^{2n}}{(2n)!}$ , $\sin(x)=\sum_{n=0}^{\infty}\frac{(-1)^nx^{2n+1}}{(2n+1)!}$ , also $e^x=\sum_{n=0}^{\infty}\frac{x^n}{n!}$ . So I use these to find it. What to do next?","['limits', 'calculus', 'taylor-expansion']"
4110114,Let $ G $ be a tree and $ V_0 = \left \lbrace v \in V(G) | deg (v) = 1 \right \rbrace $. Show that $ G \setminus V_0 $ is a tree.,"Let $ G $ be a tree and $ V_0 = \left \lbrace v \in V(G) | deg (v) = 1 \right \rbrace $ . Show that $ G \setminus V_0 $ is a tree. To see that this is true, to demonstrate: $ G \setminus V_0 $ is acyclic. Suppose $ G \setminus V_0 $ contains a cycle $ C = (u_1, \: \ldots, \: u_n) $ , but $ G \setminus V_0 $ is a subplot of $ G $ , then $ C \subset G $ , which is a contradiction. Therefore $ G \setminus V_0 $ is acyclic. $ G \setminus V_0 $ is connected. Let $ u, \: v \in V (G \setminus V_0) $ , since $ G $ is connected then there is $ T $ a $ uv-$ path in $ G $ . Let $ T = (u = x_0, \: \ldots, \: x_k = v) $ , but $ deg (x_i) \geq 2 $ for all $ i = 1, \: \ldots, \: k-1 $ so $ T $ is contained in $ G \setminus V_0 $ so there is a $ uv-$ path. For this, we must use what we know, $ G $ is connected, but I still have doubts...","['graph-theory', 'trees', 'discrete-mathematics']"
4110137,Understanding Lang's Proof of Fubini's Theorem,"This question concerns the proof of Theorem 8.4 (Fubini's Theorem part 1) on page 162 in Lang's real and functional analysis book. To understand the proof I need to give following background from the book: Let $f:X\to E$ be a function defined on a measure space $(X,\mathcal{M},\mu)$ and taking values in a Banach space $E$ . First we consider step maps of the form $f=\sum_{k=1}^n v_k1_{A_k}$ with $v_k\in E$ , $A_k\in \mathcal{M}$ and $\mu(A_k)<\infty$ , and define the integral of such maps to be $\int_X f d\mu := \sum_{k=1}^n v_k\mu(A_k)\in E$ (we check that this definition does not depend on the step map representation of $f$ ). The vector space of step maps is denoted by $S(\mu,E)$ and we check that the integral is linear on this space. $S(\mu,E)$ is made into a seminormed  space by introducing the $L^1$ -seminorm $\|f\|_1:=\int_X |f|d\mu$ .  Next we define the space $\mathcal{L}(\mu,E)$ of maps $f:X\to E$ such that there exist a sequence $(f_n)\subset S(\mu,E)$ such that $(f_n)$ is $L^1$ -Cauchy $f_n\to f$ for almost every $x\in X$ and we define the integral of such $f$ to be $\int_X fd\mu:=\lim_{n\to \infty}\int_X f_n d\mu$ (we check that this limit exists and is independent of the chosen sequence $(f_n)$ ). The integral is shown to be a linear map on the vector space $\mathcal{L}(\mu,E)$ . $\mathcal{L}(\mu,E)$ is made into a seminormed space by extending the $L^1$ -seminorm $\|f\|_1:=\int_X |f|d\mu$ for $f\in \mathcal{L}(\mu,E)$ . Ok now I can give the statement and proof of Fubini's Theorem on page 162. The set-up is two $\sigma$ -finite measure spaces $(X,\mathcal{M},\mu)$ and $(Y,\mathcal{N},\nu)$ with product space $(X\times Y,\mathcal{M}\otimes\mathcal{N},\mu\otimes\nu)$ . Theorem 8.4 (Fubini's Theorem, part 1). Let $f\in \mathcal{L}(\mu\otimes\nu,E)$ . Then the map $f_x$ ( $x$ section of $f$ ) is in $\mathcal{L}(\nu,E)$ for almost all $x\in X$ , the map given by $x\mapsto \int_Y f_x d\nu$ for almost all $x$ (and defined arbitrarily for other $x$ ) is in $\mathcal{L}(\mu,E)$ , and we have $\int_{X\times Y} f d\mu\otimes\nu=\int_X \int_Y f_x d\nu d\mu$ . Proof (with added details of mine). Let $\mathcal{A}$ , $\mathcal{B}$ denote the rings of sets of finite measure in $\mathcal{M},\mathcal{N}$ respectively. Then $\mathcal{M}\otimes\mathcal{N}=\sigma(\mathcal{A}\times \mathcal{B})$ where $\mathcal{A}\times \mathcal{B}$ is the ring of finite disjoint unions of rectangles $A\times B$ with $A\in\mathcal{A}$ and $B\in\mathcal{B}$ . Moreover $X\times Y$ is $\sigma$ -finite with repect to $\mathcal{A}\times \mathcal{B}$ . By Theorem 6.3 on page 150 of the book, it follows that the space $S(\mathcal{A}\times \mathcal{B},E)$ is $L^1$ -dense in $\mathcal{L}(\mu\otimes\nu,E)$ . Hence given $f\in \mathcal{L}(\mu\otimes\nu,E)$ there exist a sequence $(f_n)\subset S(\mathcal{A}\times \mathcal{B},E)$ such that $(f_n)$ is $L^1$ -convergent to $f$ , and is in particular $L^1$ -Cauchy. Using Theorem 5.2 on page 138 we may also assume that $f_n\to f$ almost everywhere (by considering a subsequence). Let $Z\in \mathcal{M}\otimes\mathcal{N}$ be a $\mu\otimes\nu$ -null set outside of which $f_n\to f$ holds pointwise. Then from Lemma 8.3 on page 161 we have that $\nu(Z_x)=0$ for almost all $x$ , where $Z_x$ denotes the $x$ section of $Z$ . Let $S\in\mathcal{M}$ be a $\mu$ -null set outside of which $\nu(Z_x)=0$ . Note that we have $(f_n)_x\to f_x$ $\nu$ -almost everywhere for all $x\in X\setminus S$ , where $f_x$ denotes the $x$ section of $f$ . Now, for each $n$ consider the map $\Phi_n:X\to S(\mathcal{B},E)\subset \mathcal{L}(\nu,E)$ defined by $\Phi_n(x)=(f_n)_x$ . We note that $\Phi_n \in S(X,\mathcal{L}(\nu,E))$ , i.e. $\Phi_n$ is a step map taking values in the seminormed space $\mathcal{L}(\nu,E)$ . Indeed if $f=\sum_{k=1}^n v_k1_{A_k\times B_k}$ is a step map in $S(\mathcal{A}\times \mathcal{B},E)$ then $$f_x=\sum_{k=1}^n v_k 1_{B_k} 1_{A_k}(x) \hspace{0.5cm} \text{with } \hspace{0.5cm}   v_k 1_{B_k}\in S(\mathcal{B},E) $$ We note also that $(\Phi_n)$ is $L^1$ -Cauchy since $$\|\Phi_n-\Phi_m\|_1=\int_X |\Phi_n-\Phi_m| d\mu=\int_X\int_Y|(f_n)_x-(f_m)_x|d\nu d\mu=\int_{X\times Y} |f_n-f_m|d(\mu\otimes\nu) = \|f_n-f_m\|_1\to 0$$ as $n,m\to\infty$ , where the third equality is because $|f_n-f_m|\in S(\mathcal{A}\times \mathcal{B},\mathbb{R})$ and Fubini's Theorem is easily verified to hold in this case. By the ""fundamental lemma 3.1"" on page 129 we may assume that $\Phi_n$ converges for almost every $x$ (using a subsequence if necessary). Let $T\in\mathcal{M}$ be a $\mu$ -null set outside of which $(\Phi_n)$ converges. Then in particular we have that $x\in X\setminus T$ implies $\Phi_n(x)$ Cauchy, that is $(f_n)_x$ is $L^1$ -Cauchy with respect to $\nu$ . Fundamental lemma 3.1 .(page 129) Let $(f_n)\subset S(\mu,E)$ by an $L^1$ -Cauchy sequence of step maps. Then there exist a subsequence converging almost everywhere. Question 1. Here we apply the fundamental lemma to a sequence of step maps $(\Phi_n)$ taking values in a seminormed space (rather than a normed space). Is the fundamental lemma still valid in this case? If $x\in X\setminus (S\cup T)$ , then combining both previous parts we get that $(f_n)_x\to f_x$ $\nu$ -almost everywhere with $(f_n)_x$ $L^1$ -Cauchy. Lang's then write: ""By Corollary 5.10 we conclude that $f_x \in \mathcal{L}(\nu,E)$ and that $(f_n)_x$ is $L^1$ convergent to $f_x$ for all $x\in X \setminus (S\cup T)$ , so that $\int_Y(f_n)_xd\nu$ converges to $\int_Y f_x d\nu$ "". Corollary 5.10. (page 142) Let $(f_n)\subset  \mathcal{L}(\mu,E)$ with $f_n\to f$ almost everywhere for some map $f:X\to E$ . If there exist $C\geq0$ such that $\|f_n\|_1\leq C$ for all $n$ , then $f\in \mathcal{L}(\mu,E)$ and $\|f\|_1\leq C$ . Question 2. I don't understand why this corollary is needed. To me it seems that $f_x \in \mathcal{L}(\nu,E)$ for all $x\in X \setminus (S\cup T)$ by definition of the integral, since for such $x$ we have $(f_n)_x \subset S(\mathcal{B},E)$ $L^1$ -Cauchy and $(f_n)_x\to f_x$ $\nu$ -almost everywhere. Hence by definition $\int_Y f_x d\nu=\lim_{n\to\infty}\int_Y (f_n)_x d\nu$ for all $x\in X \setminus (S\cup T)$ . Now note that the map $\Psi_n:X\to E$ defined by $x\mapsto \int_Y(f_n)_x$ is a step map in $S(\mathcal{A},E)$ , since it is the composition of $\Phi_n$ and the integral $\int_Y d\nu$ . Lang's writes: ""One sees by repeating the argument above that $(\Psi_n)$ is $L^1$ -Cauchy"" Question 3. Is the following calculation showing that $(\Psi_n)$ is $L^1$ -Cauchy correct? $$\|\Psi_n-\Psi_m\|_1=\int_X |\Psi_n-\Psi_m| d\mu=\int_X\bigg|\int_Y(f_n)_x-(f_m)_xd\nu\bigg| d\mu\leq \int_X\int_Y |(f_n)_x-(f_m)_x| d\nu d\mu$$ $$= \int_{X\times Y} |f_n-f_m|d(\mu\otimes\nu) = \|f_n-f_m\|_1\to 0 \text{ as } n,m\to\infty$$ where I used the inequality $|\int_Xfd\mu|\leq \|f\|_1$ valid for $f\in\mathcal{L}(\mu,E)$ . Hence if we define $\Psi(x)$ to be $\int_Y f_x d\nu$ for $x\in X\setminus(S\cup T)$ and arbitrarily elsewhere we get $\Psi_n\to\Psi$ for almost every $x$ with $(\Psi_n)$ $L^1$ _Cauchy. It follows (by definition of the integral) that $\Psi \in \mathcal{L}(\mu,E)$ and $\int_X \Psi d\mu=\lim_{n\to\infty}\int_X \Psi_n d\mu$ , that is $$\int_X \int_Y f_x d\nu d\mu=\lim_{n\to\infty}\int_X \int_Y (f_n)_x d\nu d\mu=\lim_{n\to\infty}\int_{X\times Y} f_n d(\mu\otimes \nu)=\int_{X\times Y} f d(\mu\otimes \nu)$$ where the last equality is because $(f_n)$ was initially chosen to be $L^1$ -convergent to $f$ . Is anybody familiar with this Fubini's proof in Lang's book? Any help on this is very appreciated.","['banach-spaces', 'measure-theory', 'real-analysis', 'functional-analysis', 'fubini-tonelli-theorems']"
4110138,Is the quotient map locally bi-Lipschitz?,"Suppose $G$ is a Lie group of matrices with a subgroup $H$ and a metric $d_G$ , and then define the induced metric on $G/H$ as $d_H(g_1 H, g_2 H) = \inf_{h_1, h_2 \in H} d_G(g_1h_1, g_2h_2)$ . I've seen in sources online that the quotient map $\pi: G \to G/H; g \mapsto gH$ is differentiable. I want to know if it is locally bi-Lipschitz. It would be enough (I think) to show that the derivative is bounded on compact sets, but I can't find any information on how to practically compute the derivative of this map. Any help would be appreciated.","['matrices', 'derivatives', 'linear-algebra', 'lie-groups']"
4110194,"How to prove that ""$\forall x(P(x)\vee Q(x))$” and ""$\forall xP(x)\vee\forall xQ(x)$” are not equivalent?",How to prove that $”\forall x (P(x)\lor Q(x))”$ and $”\forall xP(x)\lor\forall xQ(x)”$ are not equivalent? How to prove it? I don't even know how to start.,['discrete-mathematics']
4110282,Alternatives to the classical pendulum ODE,"The classical (undamped) pendulum ODE is $$\ddot \theta = -\frac{g}{\ell} \sin(\theta)$$ Defining state ${\bf x} := (\theta, \dot \theta)$ , we have a system of $2$ ODEs, $\dot {\bf x} = {\bf f} ({\bf x})$ , where ${\bf f} : \Bbb R^2 \to \Bbb R^2$ . Consider the change of coordinates ${\bf y} = {\bf \Phi} ({\bf x})$ , where vector field ${\bf \Phi} : \Bbb R^2 \to \Bbb R^2$ is a diffeomorphism . Differentiating with respect to time, $$\dot {\bf y} = \left(\left({\bf D \, \Phi} \cdot {\bf f} \right) \circ {\bf \Phi}^{-1} \right) ({\bf y})$$ where ${\bf D \, \Phi}$ denotes the Jacobian of vector field ${\bf \Phi}$ , $\cdot$ denotes multiplication, $\circ$ denotes composition and ${\bf \Phi}^{-1}$ denotes the inverse of ${\bf \Phi}$ . Are there ""nice"" choices of vector field ${\bf \Phi}$ that make vector field $$\color{blue}{\left( {\bf D \, \Phi} \cdot {\bf f} \right) \circ {\bf \Phi}^{-1}}$$ ""nice"" in some sense? What is ""nice""? For example, polynomial and rational functions are nice. All elementary functions are nice. Anything of relatively ""low"" descriptive complexity would be nice. In fact, any alternative to the classical pendulum ODE would be nice, even if highly contrived. My work The only idea I had was to rewrite the pendulum ODE in Cartesian coordinates, which led to $$\begin{aligned} (\ddot x - g) y  - x \ddot y &= 0\\ x^2 + y^2 &= \ell^2 \end{aligned}$$ which isn't really a system of ODEs. Rather, it is a system of differential-algebraic equations (DAEs). Nothing else occurred to me. I am not familiarized with diffeomorphisms. Ideas are most welcome.","['differential-geometry', 'diffeomorphism', 'ordinary-differential-equations', 'classical-mechanics', 'dynamical-systems']"
4110285,the curvature as a function of $t$,"let $r,c>$ some real numbers, and $X(t)=\langle r\cos t, r\sin t, ct \rangle$ is a curve. Find the curvature as a function of $t$ I think that the curvature of a curve is $$\left\lVert\frac{dT}{ds}\right\rVert=\frac{\left\lVert T'(t)\right\rVert}{\left\lVert X'(t)\right\rVert}\text{ Where }T=\frac{X'(t)}{\left\lVert X'(t) \right\rVert}$$ Since $$X'(t)=\langle -r\sin t, r\cos t, c\rangle $$ and $$T(t)=\frac{1} {\sqrt{r^2+c^2}}\langle -r\sin t, r\cos t,c \rangle$$ It follows that $$T'(t)=\frac{1} {\sqrt{r^2+c^2}}\langle -r\cos t, -r\sin t, 0\rangle$$ Hence $$\left\lVert\frac{dT}{ds}\right\rVert=\frac{r}{\sqrt{r^2+c^2}}\frac{1}{\sqrt{r^2+c^2}}=\frac{r}{r^2+c^2}$$ But apparently, this is not a function of $t$ , Does this mean that the curvature is constant?","['multivariable-calculus', 'vectors', 'curvature']"
4110305,"Covariance of [$X_{(1)}$, $X_{(n)}$] from $\operatorname{Unif}(a,b)$","I would like to know how to calculate the Covariance between the minimum and maximum order statistics from an arbitrary uniform distribution. I am trying to fill in a gap between the answers here: Question 1 and here: Question 2 by taking the approach of finding $E[XY]-E[X]E[Y]$ where $X=X_{(1)},Y=X_{(n)}$ . I have already determined $E[X]=\frac{na+b}{b-a}$ and $E[Y]=\frac{a+nb}{b-a}$ . I am using the following to calculate $E[XY]$ : $$E[XY]=\int_a^b\int_a^bxyf_{X,Y}(x,y)dxdy$$ Using the above formula with i=1 and j=n, $$f_{X,Y}(x,y)=\frac{n!}{(n-2)!}f_X(x)f_X(y)[F_X(y)-F_X(x)]^{n-2}$$ Now $f_X(x)=\frac{1}{b-a}$ and $F_X(x)=\frac{x-a}{b-a},a<x<b$ . This gives: $$E[XY]=\int_a^b\int_a^bxy\frac{1}{(b-a)^2}[\frac{y-x}{b-a}]^{n-2}dxdy$$ $$=\int_a^b\int_a^bxy(b-a)^{-n}[y-x]^{n-2}dxdy$$ Calculating this double integral is where I am stuck. In the $\operatorname{Unif}(0,1)$ case I have seen Beta functions used to solve it, but I am not well-versed enough to do so outside of the standard uniform. Any advice is welcome, thank you!","['integration', 'statistics', 'probability-distributions']"
4110307,Calculate the integral ...,We need to find the integral $$\iiiint\limits_{x^2+y^2+u^2+v^2\leq 1}e^{x^2+y^2-u^2-v^2}dxdydudv$$ I was only able to get to this point ... $$\iiiint\limits_{x^2+y^2+u^2+v^2\leq 1}e^{x^2+y^2-u^2-v^2}dxdydudv=\iint\limits_{x^2+y^2\leq 1}e^{x^2+y^2}\left ( \iint\limits_{u^2+v^2\leq 1-x^2-y^2}\frac{dudv}{e^{u^2+v^2}} \right )dxdy$$ I don’t know how to solve it further ...,"['calculus', 'real-analysis']"
4110318,Finding sum of the roots of $(\sin x+\cos x)^{(1+\sin 2x)}=2$,"What is sum of the roots of the equation $(\sin x+\cos x)^{(1+\sin 2x)}=2\quad$ where $x\in[-2\pi,4\pi]$ ? We have $1+\sin 2x=\sin^2 x+\cos^2x+2\sin x\cos x=(\sin x+\cos x)^2$ . so the equation is $$(\sin x+\cos x)^{(\sin x+\cos x)^2}=2$$ By taking $\sin x+\cos x=u$ we have $$u^{u^2}=2$$ By try and error I realized that $u=\pm\sqrt2$ are the answers , but I don't know how to solve the above equation mathematically to find out whether it has other answers or not.","['algebra-precalculus', 'trigonometry']"
4110330,Is the group of outer class-preserving automorphisms of a finite group soluble?,"This came from an old idea of mine from when I was an undergraduate for how to approach the Schreier conjecture. I (obviously) never gave it much serious thought, but wondered if much was known about it. Let $G$ be a finite group. The group $\mathrm{Out}(G)$ has a normal subgroup $\mathrm{Out}_c(G)$ of class-preserving outer automorphisms, i.e., the group $\mathrm{Aut}_c(G)/\mathrm{Inn}(G)$ , where $\mathrm{Aut}_c(G)$ is the subset of $\mathrm{Aut}(G)$ that leave invariant each conjugacy class of $G$ . Note that all primes dividing $|\mathrm{Out}_c(G)|$ divide $|G|$ , and if $G$ is simple then $\mathrm{Out}_c(G)=1$ (Feit-Seitz). One approach to Schreier without CFSG is to slice $\mathrm{Out}(G)$ into two, and prove that $\mathrm{Out}_c(G)$ and $\mathrm{Out}(G)/\mathrm{Out}_c(G)$ are both soluble. Each of these looks hard, but the obvious question, even with CFSG, is: Is $\mathrm{Out}_c(G)$ soluble for any finite group $G$ ? The obvious candidates for groups with non-inner class-preserving automorphisms are $p$ -groups, where this statement clearly holds. So perhaps it has a chance of being true generally. I couldn't find much progress at all on class-preserving automorphisms, so perhaps this question is too far out of reach at the moment.","['automorphism-group', 'group-theory', 'simple-groups', 'finite-groups']"
4110358,"Why do we call a limit that evaluates to $\displaystyle\pm\infty$ a particular instance of ""The Limit Does Not Exist""","The $\epsilon$ - $\delta$ definition of a limit is stated as: $\displaystyle \lim_{x \to a}f(x)=L \iff \forall \epsilon \gt 0\  \exists\delta \gt 0 \text{ s.t. } \forall x \in \mathbb R \big [ 0\lt \lvert x -a \rvert \lt \delta \rightarrow\lvert f(x) - L \rvert \lt \epsilon \big ] \quad \dagger$ More generally, one would state: $$\displaystyle \lim_{x \to a}f(x) \text{ exists} \iff \exists L \in \mathbb R \text{ s.t. }  \forall \epsilon \gt 0\  \exists\delta \gt 0 \text{ s.t. } \forall x \in \mathbb R \big [ 0\lt \lvert x -a \rvert \lt \delta \rightarrow\lvert f(x) - L \rvert \lt \epsilon \big ] $$ The corresponding negation of $\dagger$ is: $\displaystyle \lim_{x \to a}f(x)\neq L \iff \exists\epsilon \gt 0\  \text{ s.t. }  \forall\delta \gt 0 \ \exists x \in \mathbb R  \text{ s.t. }\big [ 0\lt \lvert x -a \rvert \lt \delta \land \lvert f(x) - L \rvert \geq \epsilon \big ] $ More generally, one would state: $$\displaystyle \lim_{x \to a}f(x) \text{ does not exist} \iff \forall L \in \mathbb R\   \exists\epsilon \gt 0\  \text{ s.t. }  \forall\delta \gt 0 \ \exists x \in \mathbb R  \text{ s.t. } \big [ 0\lt \lvert x -a \rvert \lt \delta \land \lvert f(x) - L \rvert \geq \epsilon \big ] \quad \dagger \dagger$$ Given the above definitions , consider what one means for a limit evaluating to $\displaystyle \pm \infty$ : $\displaystyle\lim_{x\to a} f(x) = +\infty \iff \forall M \gt 0 \ \exists \delta \gt 0 \text{ s.t. } \forall x \in \mathbb R \big [0 \lt \lvert x-a \rvert \lt \delta \rightarrow f(x) \gt M \big ]$ or $\displaystyle\lim_{x\to a} f(x) = -\infty \iff \forall N \lt 0 \ \exists \delta \gt 0 \text{ s.t. } \forall x \in \mathbb R \big [0 \lt \lvert x-a \rvert \lt \delta \rightarrow f(x) \lt N \big ]$ Within the analysis community, when one claims "" $\displaystyle\lim_{x\to a} f(x) = \displaystyle  +\infty$ "" (or $- \infty$ ), I have seen that it is acceptable to claim "" The limit does not exist "". Based on the negated expression described in $\dagger \dagger$ , I am having difficulties seeing why this is justified. Could someone explain what is meant by ""the limit does not exist"" in the context of infinities? It appears to me that the first order logics do not match .","['limits', 'first-order-logic']"
4110359,Prerequisites for non-standard analysis,"Today my real analysis teacher mentioned the existence of ""non-standard analysis"" and explained on a very basic level what it studies and it immediately caught my attention. After that he mentioned that it is an advanced subject and that got my wondering: what are the necessary prerequisites to be able to learn non-standard analysis up to an intermediate/advanced level? Is real analysis and a little bit of abstract algebra enough?","['nonstandard-analysis', 'analysis']"
4110395,When are two paths in $\mathbb{C}$ equivalent?,"In studying complex analysis, I've come across the notion of equivalent paths. Specifically, we say that smooth (by which I mean their derivatives are continuous) paths $\gamma: [a,b] \to \mathbb{C}$ and $\sigma: [c,d] \to \mathbb{C}$ are equivalent if there is an increasing, continuous function $\varphi: [a,b] \to [c,d]$ such that $\gamma = \sigma \circ \varphi$ . I was wondering if there were any necessary and sufficient conditions for two paths being equivalent by this definition. I've proved that if $\gamma: [a,b] \to \mathbb{C}$ and $\sigma: [c,d] \to \mathbb{C}$ are equivalent smooth paths, then $\gamma(a) = \sigma(c)$ , $\gamma(b) = \sigma(d)$ $\{\gamma\} = \{\sigma\}$ , where $\{\gamma\}$ is the trace of $\gamma$ , $\{\gamma\} = \gamma([a,b])$ . $V(\gamma) = V(\sigma)$ , where $V(\gamma)$ is the total variation of $\gamma$ and is defined as \begin{equation*}
V(\gamma) = \int_a^b |\gamma'(t)| \; dt.
\end{equation*} Intuitively, I think that 1 says that $\gamma$ and $\sigma$ start and end at the same points, 2 says that they trace out the same path in $\mathbb{C}$ , and 3 says that they have the same length. In other words, I've proved that 1, 2, and 3 are necessary conditions for $\gamma$ and $\sigma$ to be equivalent, but are they sufficient? I'm not sure how to define $\varphi$ that ensures it is increasing and continuous, and so that $\gamma = \sigma \circ \varphi$ . My idea so far has been to define it like this: For $t \in [a,b]$ , define $\varphi(t)$ to be the point in $[c,d]$ so that $\gamma(t) = \sigma(\varphi(t))$ . We know that such a point exists given 2, but not that it is unique, so that this definition does not uniquely defined a function $\varphi: [a,b] \to [c,d]$ . In my book (Conway's Function of One Complex Variable), this question really came up for rectifiable paths, but I figured I'd ask this for smooth paths instead, since that, along with piecewise smooth paths, are what I'm more interested in.",['complex-analysis']
4110426,Lebesgue decomposition $\nu =\nu_{cont}+\require{cancel} \cancel{\nu _{sing}}+\nu_{pp}$,"While reading about the Lebesgue decomposition theorem I learned that we can decompose a measure (with respect to the Lebesgue measure I guess) $$\,\nu =\nu _{{{\mathrm {cont}}}}+\nu _{{{\mathrm {sing}}}}+\nu _{{{\mathrm {pp}}}}$$ where $ν_{cont}$ is the absolutely continuous part ( $\nu_{cont}<<\lambda$ ) $ν_{sing}$ is the singular continuous part (""singular"" meaning $\nu\perp\lambda$ and ""continuous"" meaning $\mu\{x\}=0$ for any $x\in\mathbb{R}^d$ (I am not sure about this one)) $ν_{pp}$ is the pure point part (a discrete measure) (meaning $\nu_{pp}=\sum\limits_{i=1}^{\infty}\delta_{x_i}$ ) An example of singular continuous measure is the Cantor measure (the probability measure on the real line whose cumulative distribution function is the Cantor function). As I understand, singular continuous measures are pathological and I was wondering what condition we could impose on the original measure in order not to have any singular continuous terms in the decomposition. I think that asking that the original measure is Radon is not enough right? PS : A relevant discussion here","['measure-theory', 'real-analysis']"
4110448,Two seemingly non-isomorphic elliptic curves over a finite field which have the same cardinality,"Let $p$ be a prime number such that $p \equiv 3 \bmod 4$ . Now consider the elliptic curves $$
E/\mathbb{F}_{p^2}: \quad y^2 = x^3 - ax \quad \text{and} \quad E'/\mathbb{F}_{p^2}: \quad y^2 = x^3 - a^{-1}x
$$ where $a$ is an element generating $\mathbb{F}_{p^2}^*$ . The curve itself depends on the choice of $a$ : the curves $E$ and $E'$ are not isomorphic in general, see MAGMA code below (for my computed cases, they are all not isomorphic to each other). But what I noticed is that in every case I computed, it is $|E(\mathbb{F}_{p^2})| = |E'(\mathbb{F}_{p^2})|$ . Question : Is this a general observation or is it just mere coincidence? Below is the MAGMA code I used: for p in [ x : x in [3 .. 100] | IsPrime(x) and x mod 4 eq 3 ] do
    print """";
    K := GF(p^2);
    a := PrimitiveElement(K);
    R<x> := PolynomialRing(K);
    f := x^3 - a*x;
    g := x^3 - 1/a*x;
    E := EllipticCurve(f);
    Eprime := EllipticCurve(g);
    print ""Are both curves isomorphic?"";
    IsIsomorphic(E,Eprime);
    print ""Do both curves have the same cardinality?"";
    #E eq #Eprime;
end for;","['algebraic-number-theory', 'elliptic-curves', 'finite-fields', 'algebraic-geometry', 'abstract-algebra']"
4110471,$E[|X|\ln(1+|X|)]<+\infty \implies \lim_k E[X|\mathcal{G}_k]=0$ a.s,"$X$ is a random variable such that $E[X]=0,$ $E[|X|\ln(1+|X|)]<+\infty.$ If $(\mathcal{G}_k)_k$ is a sequence of independent $\sigma$ -algebras of events, then prove that $E[X|\mathcal{G}_k]$ converges a.s to $0$ . Any suggestions how to relate the result with the assumption?","['measure-theory', 'stochastic-processes', 'martingales', 'probability-theory', 'stochastic-calculus']"
4110505,"Is any proof of ""If $f:[a,b] \to \mathbb{Q}$ is a continuous function then it is constant"" that appeals to the Intermediate Value Theorem incorrect?","It seems to me that any proof of If $I\subseteq \mathbb{R}$ is an interval and $h:I\to\mathbb{Q}$ is continuous, then it is constant $\hspace{4mm}$ ( $\ast$ ) or variants thereof that invokes the Intermediate Value Theorem (IVT) is incorrect because (as far as I'm aware) the proofs I've seen of the IVT relies on the fact that the image of $f$ must be connected. However if the codomain of $f$ is already restricted to $\mathbb{Q}$ (or if we stipulate the image of $f$ to only rational values) then we cannot apply the IVT. Is it just me or am I missing something here? The highest voted answers for these questions below uses the IVT where the first question has been an accepted as an answer. Prove that if $f: \mathbb{R} \to \mathbb{Q}$ is continuous then $f$ is constant Is a rational-valued continuous function $f\colon[0,1]\to\mathbb{R}$ constant? Addendum: Statement of the IVT that I am using: Let $I$ be an interval and suppose $f:I\to\mathbb{R}$ is continuous. If $a,b\in I$ and $y\in\mathbb{R}$ satisfies $f(a)<y<f(b)$ then there is a $c\in (a,b)$ such that $f(c)=y$ I have resolved my confusion and it comes down to the assumption of $f$ having codomain $\mathbb{R}$ in the statement of the IVT. I was thinking that if we had a function, say the one in ( $\ast$ ) where the codomain is $\mathbb{Q}$ then we cannot apply the IVT because it does not meet the assumptions of the theorem, so then I had to look at the proof of the theorem to see if the codomain really had to be $\mathbb{R}$ . In all the proofs I have seen (and I'm sure that almost every proof of the IVT would have this step) there is this step where we suppose that "" $y\in \mathbb{R}$ such that $f(a) < y < f(b)$ "" that caused me to conclude that the codomain had to be $\mathbb{R}$ in order for the IVT to work because $y$ can be irrational, and if $f:I\to\mathbb{Q}$ then how can we conclude that there is a $c\in (a,b)$ such that $f(c)=y$ because $f$ can only take rational values? That erroneously caused me to conclude that the assumption that the function has codomain $\mathbb{R}$ had to be the case. However, this is exactly the flaw in my thinking because as stated in the comments, the codomain does not exactly have to be $\mathbb{R}$ but as long as it is a subset of $\mathbb{R}$ . Thus, the IVT should really be of the form Let $I$ be an interval and $S\subseteq \mathbb{R}$ . Suppose $f:I\to S$ is continuous. If $a,b\in I$ and $y\in\mathbb{R}$ satisfies $f(a)<y<f(b)$ then there is a $c\in (a,b)$ such that $f(c)=y$ . Hence, $S$ is just some arbitrary subset of $\mathbb{R}$ and in proving the theorem we conclude that $S$ had to in fact be an interval. That's why I had my qualm as to why we can use the IVT to prove ( $\ast$ ) since $h$ does not meet the assumptions of the theorem since the codomain of $h$ is $\mathbb{Q}$ . Now some may ask, but since $\mathbb{Q} \subseteq \mathbb{R}$ then surely the IVT can still be applied to any function who's codomain is a subset of $\mathbb{R}$ . I'm not sure if in general we can do this even though in the case of the IVT it happens to be fine?","['continuity', 'connectedness', 'functions', 'real-analysis']"
4110572,"Probability that there exists a person who will ""only flip heads"" or ""only flip tails"" in their lifetime?","My question has two parts: Am I approaching the problem correctly, resulting in a reasonable formula? How do I do the final calculation for numbers as large and as small as these. I put my formula into google and it just gives an answer of ""1"", which surely isn't the right answer. My approach: Lets start with an assumption, that the average person experiences
225 coin flips in a lifetime (3/year for 75 years) The odds of an individual having the extraordinary results of ""only
heads"" or ""only tails"" for all 225 of their flips would be 0.5^224
(the first flip can be either so we only say 224). Then we can say that the odds that someone goes through life without
these extraordinary results would be 1-(0.5^224). The odds then of nobody experiencing these extraordinary results will
be to take the previous calculation multiplied by itself for each
member of the human population, so we raise it all to the power of
7.8 billion. The final formula for this calculation is then
(1-(0.5^224))^7800000000. Edit: Given the insight from Stacker's answer its clear that I missed a step, I only ""calculated the probability that everyone will not have such an extraordinary event in their lifetime. To find the probability that at least one person will, subtract that number from 1 (the complement rule)."" The final formula for this calculation is actually 1-((1-(0.5^224))^7800000000) P.S. If your interested in some context, I'm trying to do this calculation to explore the idea of perspective. To better understand how likely it is that there are people that will experience the world in a way that is entirely different from reality.",['probability']
4110636,Why normal equation can have infinite solutions?,"The normal equation is $$
X^Ty = X^TX\hat{\beta}.
$$ If $X^TX$ is invertible, then $\hat{\beta}$ has an unique solution which is $$
\hat{\beta} = (X^TX)^{-1}X^Ty.
$$ However, if $X^TX$ is non-invertible, then $X^TX$ is a singular matrix, which means that $rank(X^TX) = r < p$ where $X$ is a $n \times p$ matrix. By the dimension theorem, we know that $$
rank(X^TX) = rank(X) = r < p.
$$ And then we need to show that the $ker(X^TX) = ker(X)$ , and this can be proved by suppose $y \in ker(X^TX)$ $$
X^TXy = 0 \implies y^TX^TXy = 0 \implies ||Xy||^2 = 0 \implies Xy = 0.
$$ Therefore, $ker(X^TX) = ker(X)$ . Then we know that there are $p-r$ linealy dependent columns in $X$ and $X$ and $X^TX$ can not span the whole column space of $X$ . However, I can't figure out that the above can finish the proof of why a normal equation can have infinite solutions?","['statistics', 'linear-algebra']"
4110654,"Generalized Understanding of ""Switch"" Problem [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Lets assume you have a room of 10 switches that are all turned off. You also have 10 robots named 1-10. Starting with robot #1, it goes over and flips all of the switches divisible by its name. When I said flip, I mean it flips the switch in the opposite direction it is currently in (on or off). So, robot #1 would flip all switches on. Then, robot #2 comes over and flips all of the switches divisible by its name. So robot #2 would flip every even switch. Then robot #3 comes over and flips all of the switches divisible by its name. So robot #3 would flip every 3rd switch in the series. This continues on until the last robot, #10, has finished it's turn. By the end of this process, how can we determine how many switches will be ""ON""? Is there generalized process to figure out this sort of problem? I don't necessarily want the answer, I just am curious how you would go about figuring this out.","['number-theory', 'discrete-mathematics']"
4110692,Relation between $\rm{Diff}(\mathbb{R}^n) \times \rm{Diff}(\mathbb{R}^m)$ and $\rm{Diff}(\mathbb{R}^n \times \mathbb{R}^m)$,"I am wondering if there is a relation between a map $(\varphi, \psi) \in \rm{Diff}(\mathbb{R}^n) \times \rm{Diff}(\mathbb{R}^m)$ and a map $\Psi \in \rm{Diff}(\mathbb{R}^n \times \mathbb{R}^m)$ . To be clear: Here I only mean local diffeomorphisms at $(0,0)$ . Is there an embedding of $\rm{Diff}(\mathbb{R}^n) \times \rm{Diff}(\mathbb{R}^m)$ into $\rm{Diff}(\mathbb{R}^n \times \mathbb{R}^m)$ , since maps $(\varphi, \psi)\in \rm{Diff}(\mathbb{R}^n) \times \rm{Diff}(\mathbb{R}^m)$ are of the form $(x,y) \mapsto (\varphi(x),\psi(y))$ and a map $\Psi \in \rm{Diff}(\mathbb{R}^n \times \mathbb{R}^m)$ is of the form $\Psi(x,y) = (\Psi_1(x,y), \Psi_2(x,y))$ . Can I understand the map $\Psi_1$ as a parametrized diffeomorphism, i.e. for all $y \in \mathbb R^m$ the map $x \mapsto \Psi_1(x,y)$ is a diffeomorphism in $\mathbb R^n$ and vice versa for $\Psi_2$ ? Thanks in advance, any help is appreciated. EDIT: So I figured that $\rm{Diff}(\mathbb{R}^n) \times \rm{Diff}(\mathbb{R}^m)$ is embedded in $\rm{Diff}(\mathbb{R}^n \times \mathbb{R}^m)$ .
As for $(\varphi, \psi) \in \rm{Diff}(\mathbb{R}^n) \times \rm{Diff}(\mathbb{R}^m)$ , the map $\iota:(\varphi, \psi) \mapsto (\varphi \times \psi)$ is clearly injective and continuous, therefore an embedding and $(\varphi \times \psi)\in \rm{Diff}(\mathbb{R}^n \times \mathbb{R}^m)$ . Is this correct or am I missing something?","['diffeomorphism', 'analysis']"
4110709,Homeomorphic to a vector space but not itself a vector space,"In Nash & Sen p.162, they show that the space of all positive definite symmetric matrices $C$ , while not a vector space itself, is homeomorphic to the space of all symmetric matrices $S$ (which is a vector space), via the map $$ s \rightarrow e^s \in C, s \in  S $$ My question: can I not make $C$ into a vector space by defining addition of two elements as first adding the elements in $S$ and then exponentiating, i.e. $ e^a + e^b \equiv e^{a + b}$ ? Note this is not the usual multiplication of matrices. It seems to me that we then have an inverse ( $e^{-a}$ ) and an identity element ( $e^0$ ), that we inherit commutativity etc. from $S$ , and we can define scalar multiplication in the usual way. More generally, why is something homeomorphic to a vector space not itself a vector space? Can someone tell me where I'm going wrong?","['vector-spaces', 'differential-geometry']"
4110717,Infinite product probability v.s. Kolmogorov's extension theorem,"Let $ (\Omega_i, \mathcal{F}_i, \mu_i), i \in I $ be a family of probability spaces, where the index set may be infinite or even uncountable. For subsets $ K \subseteq J \subseteq I $ , define the projection map $ \pi_{J \to K}: \Omega_J \to \Omega_K $ by $ \pi_{J \to K}( (x_i)_{i \in J} ) = (x_i)_{i \in K} $ . Abbreviate $ \pi_{I \to \{i\}} $ as $ \pi_i $ . It is a fact that we can always construct a unique product probability space $ ( \prod_i \Omega_i, \bigotimes_i \mathcal{F}_i, \bigotimes_i \mu_i) $ , where $ \bigotimes_i \mathcal{F}_i $ is the $\sigma$ -algebra generated by the projection maps $ \pi_i $ , and the probability measure $ \bigotimes_i \mu_i $ satisfies $$ \left( \bigotimes \mu_i \right) \left( \prod_{i \in J} A_i \times \Omega_{I \setminus J} \right)
= \prod_{i \in J} \mu_i(A_i) $$ where $J$ is a finite subset of $I$ and $ A_i \in \mathcal{F}_i $ for $i \in J$ . Basically it means $ \bigotimes_i \mu_i $ behaves as a finite product measure on product cylinders. Next consider a more general problem. Suppose we have not only a probability measure $\mu_i$ for each $i \in I$ but also a probability measure $\mu_J$ on $(\Omega_J, \mathcal{F}_J)$ for each finite subset $J \subseteq I$ , and the $\mu_J$ 's satisfy the consistency condition : $$ (\pi_{J \to K})_*\mu_J = \mu_K \quad \text{for any finite subsets } K \subseteq J \subseteq I $$ The problem is, can we construct a probability measure $\mu$ on $ (\prod_i \Omega_i, \bigotimes_i \mathcal{F}_i) $ that also satisfies the consistency condition: $$ (\pi_{I \to J})_*\mu = \mu_J \quad \text{for any finite subset } J \subseteq I \text{ ?} $$ The famous Kolmogorov's extension theorem guarantees the existence of such a probability measure under some regularity conditions. At minimum, we require the followings: for each $i \in I$ , the space $\Omega_i$ is a Hausdorff topological space for each $i \in I$ , the $\sigma$ -algebra $\mathcal{F}_i$ is the Borel $\sigma$ -algebra $\mathcal{B}(\Omega_i)$ for each finite subset $J \subseteq I$ , the probability measure $\mu_J$ is an tight Borel measure, i.e. for any Borel set $ E \in \mathcal{B}(\Omega_J) $ , $$ \mu_J(E) = \sup\{ \mu_J(K) : K \subseteq E, K \text{ compact} \} $$ Questions: Why do we need tightness in Kolmogorov's extension theorem while the product probability does not require any condition? Could you pinpoint the exact step where tightness is used in the proof of Kolmogorov's extension theorem? Could you give an example that the Kolmogorov's extension fails to exist?","['stochastic-processes', 'measure-theory', 'probability-theory', 'probability']"
4110851,"$\forall\delta, \sigma \in F$ where $\delta \land \sigma$ are contrad., $\exists\theta$ so that $\delta\land\neg\theta$ & $\sigma\land\theta$ contrad.","I'm in my first logic class ever and I'm trying to wrap my head around this obscure question... Show that for all pairs $\delta, \sigma \in F$ , where $\delta, \sigma$ contradict themselves there exists a $\theta \in F$ with $\tau(\theta) \subseteq \tau(\delta) \cap \tau(\sigma)$ , so that $(\delta\land\neg\theta)$ contradict themselves as well as $(\sigma\land\theta)$ contradict themselves, where $F$ are all propositional logic formulas, and $\tau(X)$ is the set of all actual propositional variables in X. So the only thing I know is here that contradicting in this case means that $\delta \land \sigma$ is unsatisfiable. But I really don't know how to continue. I've thought about maybe constructing $\theta$ by formulas of $\delta[\overline{\alpha}/\overline{\beta}]$ (meaning that every occurence of $\alpha_{i}$ is replaced with $\beta_{i}$ ) where $\overline{\alpha}:=\tau(\delta)\setminus \tau(\sigma)$ with $\overline{\beta} \in \{0,1\}^{|\overline{\alpha}|}$ as a possible allocation for $\overline{\alpha}$ . Could anyone help me on this? Would really appreciate it!! :)","['propositional-calculus', 'logic', 'discrete-mathematics']"
4110942,Conformality of a map f is invariant under parametric transform [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Let S, S * be parametric surfaces given by parametrizations $\overrightarrow{r}$ : U $\rightarrow$ S and $\overrightarrow{r*}$ : U * $\rightarrow$ S *.
Is the conformality of a map f : S $\rightarrow$ S * invariant under a proper parametric transform   ( $\phi(\hat{u},\hat{v})$ , $\psi(\hat{u},\hat{v})$ ) of $\overrightarrow{r}$ from $\hat{U}$ to U ?
Prove or disprove?","['parametrization', 'differential-geometry']"
4110944,"Show that for all integers 𝑛: If 𝑑 is an integer such that 𝑑|𝑛+7 and 𝑑|𝑛2+9, then 𝑑|58.","This is the working out I have so far. Any checks to see if it is sufficient would be highly appreciated! Since $𝑑|𝑛+7$ , $𝑑| (n+7)^2= n^2+14n+49.$ By adding $(n^2+9)$ , we get: $n^2+14n+49 +(n^2+9)$ $=2n^2+14n+58$ $=2n(n+7)+58.$ Therefore, $𝑑| (n+7)^2 + (n^2+9) -2n(n+7)=58.$ My tutor has told me to add more insightful explanations and fix my last line however i don't really know what that means. Thanks for the help!","['calculus', 'discrete-mathematics']"
4110966,Why the number of linearly independent columns of a matrix doesn't change by if we apply Row operations,Can anyone please tell me why the number of linearly independent columns of a matrix doesn't change even if we apply row operations on the matrix? The column space does change by row operations but I don't understand why the number of independent columns remains the same.,"['matrices', 'gaussian-elimination', 'linear-algebra']"
4110986,Open affine subscheme of affine scheme with different underlying set is non-isomorphic,"If I have an affine scheme $X=\operatorname{Spec}A$ , and an open subscheme $Y=\operatorname{Spec}B$ which is also affine and whose topological space is different from $X$ , does it follow that $X$ and $Y$ are non-isomorphic? But if $X$ and $Y$ would be isomorphic, then we'd have $A\cong B$ and hence $Y$ and $X$ must actually be the same as subsets of $X$ , because the prime ideals of $A$ are $1:1$ to the prime ideals in $B$ . I think I'm confused here in this situation about the interplay of ""being the same"" and ""being isomorphic"".","['affine-schemes', 'algebraic-geometry']"
4110995,Calculate the definite integral,"Calculate the following integral: $$
 	\int^3_{-3}\left(\frac{\arctan(\sqrt{|x|})}{1 + (1+x^2)^x} \right)dx 
$$ I know that each function can be represented as a sum of even and odd function such that: $$
f(x)=\frac{f(x) + f(-x)}{2} +\frac{f(x) - f(-x)}{2} 
$$ I tried using this approach and separate the function but I'm mainly confused with the evenness and oddness of the numerator of the function.
If my approaches is correct, how can I properly separate the function?",['integration']
4111056,"Prove that $\lim_{n\rightarrow\infty} \langle S_{k_n}u,x\rangle=\langle u,y\rangle$ using Banach-Alaoglu Throrem","Let $\mathscr{H}$ be separable Hilbert space and let $\{S_n\}\subseteq B(\mathscr{H})$ satisfy $\sup_n\|S_n\|_{\mathscr{H}\rightarrow\mathscr{H}}=M<\infty$ . Fix $x\in \mathscr{H}$ . Prove that there exists $y\in\mathscr{H}$ and subsequence $\{S_{k_n}\}$ of $\{S_n\}$ such that for any $u\in\mathscr{H}$ we have $$\lim_{n\rightarrow\infty} \langle S_{k_n}u,x\rangle=\langle u,y\rangle$$ using Banach-Alaoglu Throrem I've read the theorem multiple times, but I'm having trouble proving this.",['functional-analysis']
4111071,Convergence in Distribution of a random variable with an upper bound implies convergence of higher moments.,"Let $k\in \mathbb{N}$ and $\{X_n\}_{n \in \mathbb{N}}$ be random variables such that they converge in distribution to some $X$ and $|{X_n}|\leq Y$ , where $Y$ is a random variable with $\mathbb{E}\left[Y^k\right]<\infty$ . I am asked to show that $$
\mathbb{E}\left[X_n^i\right]\to \mathbb{E}\left[X^i\right]
\quad \forall i=1,2,\dots,k
$$ Now my idea was to just use $Y$ and $Y^i$ as integrable upper bounds and use the dominated convergence theorem. However since convergence in distribution is given, I was wondering if I could use it as well or if I even have to use it.","['expected-value', 'convergence-divergence', 'probability-theory', 'weak-convergence']"
4111072,The set of all rational points in the plane is a countable set,"From Kolmogorov's Introductory Real Analysis. I am doing some self-study and would like some feedback on whether my proof is correct. I am using that the set of rational numbers is countable as given, and I am invoking the following Theorem which is proved in the book. Theorem 2 . The union of a finite or countable number of countable sets $A_1, A_2, \ldots$ is itself countable. Claim . The set of all rational points in the plane (points with rational coordinates) is countable. Proof . Since $\mathbb{Q}$ is a countable set, we can write $\mathbb{Q} = \{q_1, q_2, q_3, \ldots\}$ . If we fix $q_1$ we can define the following set: $$
Q_1 = \{(q_1, q)\;|\; q\in\mathbb{Q}\},
$$ which are all the rational points in the plane with $q_1$ in the $x$ position. We can create a one-to-one correspondence with $\mathbb{Q}$ by simply setting $p\leftrightarrow (q_1, p)$ for each $p\in\mathbb{Q}$ , which shows
that $Q_1$ is countable. We can now define the following union which includes all rational points in the plane: $$
\mathcal{Q} = \bigcup_{n=1}^\infty Q_n,
$$ which is a countable union of countable sets. By Theorem 2, $\mathcal{Q}$ is a countable set.
■","['elementary-set-theory', 'proof-writing', 'solution-verification', 'real-analysis']"
4111114,"If $Y$ is a normal random variable and $E[Y\mid X]$ is also a normal random variable, does it mean that $X$ is a normal random variable?","Let $(\Omega,\mathcal F, \mathbb P)$ be a probability space. If $Y$ is a (non-degenerate) normal random variable and $E[Y\mid X]$ is also a (non-degenerate) normal random variable, does it mean that $X$ is necessarily a normal random variable ? How would one show that ?","['measure-theory', 'probability-distributions', 'conditional-expectation', 'normal-distribution', 'probability-theory']"
4111124,"Test whether the given sequence of function is uniform convergence in $(0,\infty)$","Check the uniform convergence of the sequence of functions $f_n(x)=n\ln \left(\frac{1+nx}{nx}\right)$ on $(0,\infty)$ . I have found that the pointwise limit of the sequence of functions is $f(x)=\frac 1x$ . I'm stuck proving uniform convergence. I am unable to find $\displaystyle M_n=\sup_{x\in (0,\infty)}\left|n\ln \left(\frac{1+nx}{nx}\right)-\frac 1x\right|$ . Any hints, please?","['sequence-of-function', 'analysis', 'real-analysis', 'uniform-convergence', 'sequences-and-series']"
4111176,Show that these two definitions of a nilpotent group are equivalent.,"A group $G$ is nilpotent if there exists of a normal series $1 = G_0 \subseteq G_1 \subseteq G_2 \subseteq \dots \subseteq G_n = G$ such that $G_{i + 1}/G_i \subseteq Z(G/G_i)$ . But now I'm seeing another definition in this lecture video by Richard E. Borcherds. A group $G$ is nilpotent if you can ""kill"" it by repeatedly ""killing"" the center. That is, $G_0 = G, G_1 = G_0/Z(G_0), G_2 = G_1/Z(G_1), \dots, G_n = 1$ . Is it clear that these two definitions are equivalent? Does it help to look at the quotient maps $(G_0 = G) \to (G_1 = G_0/Z(G_0)) \to (G_2 = G_1/Z(G_1)) \to \dots \to (G_n = 1)$ to form a normal series by taking kernels $K_i$ of the maps $G \to G_i$ ? Maybe $K_{i + 1}/K_i = Z(G/K_i)$ ?","['nilpotent-groups', 'group-theory', 'abstract-algebra']"
4111236,"Partial derivative of the partial derivative of a function, with respect to the function itself","I'm trying to derive this partial derivative of a function $f$ with respect to $u_x$ and $u_y$ with the following form: $$
f(u_x, u_y) = \left(\frac{\partial u_x}{\partial x}\right)^2 + \left(\frac{\partial u_y}{\partial y} \right)^2
$$ where both $u_x$ and $u_y$ are functions of $x$ and $y$ , i.e. $u_x=u_x(x,y), u_y = u_y(x,y)$ .
A more compact way to think about this is $f$ is a scalar function with a two-dimensional vector field as input, with $u_x$ and $u_y$ the components of that vector field. And I got to the point where $$
\frac{\partial f}{\partial u_x} = 2 \frac{\partial u_x}{\partial x} \frac{\partial}{\partial u_x} \frac{\partial u_x}{\partial x}
$$ (similarly for partial w.r.t. $u_y$ ), Then I'm stuck on this partial derivative on the right $\frac{\partial}{\partial u_x} \frac{\partial u_x}{\partial x}$ , which seems to be the partial derivative of the partial derivative of the function, but with respect to the function itself. I don't really know how to proceed from here. Can anyone help with some pointers? Really appreciate the help.","['partial-derivative', 'vector-fields', 'derivatives']"
4111275,Law of tangents with an angle bisector without knowing angles,"""In $\triangle ABC$ , let D be a point on BC such that AD bisects $\angle A$ . If AD=6, BD=4, and DC=3, then find AB"" This problem is from the Mu Alpha Theta 1991 contest, it appears in volume 2 of AoPS and involves law of tangents. I have tried looking the possible cases where I can use law of tangents, but I don´t see clear the path to solve the problem. So I hope you can give me a hint to be able to solve this problem. Thanks in advance for your help.","['euclidean-geometry', 'trigonometry', 'geometry']"
4111276,Help with $ \lim \frac{n\pi}{4} - \left( \frac{n^2}{n^2+1^2} +\frac{n^2}{n^2+2^2} + \cdots + \frac{n^2}{n^2+n^2} \right) $,"I have proved that $$\lim_{n\to \infty} \left( \frac{n}{n^2+1^2} +\frac{n}{n^2+2^2} + \cdots + \frac{n}{n^2+n^2}  \right)  = \frac{\pi}{4},$$ by using the Riemann's sum of $\arctan$ on $[0,1]$ . Now I'm interested in computing the next limit $$ L=\lim_{n\to \infty} \left[ \frac{n\pi}{4} - \left( \frac{n^2}{n^2+1^2} +\frac{n^2}{n^2+2^2} + \cdots + \frac{n^2}{n^2+n^2}  \right) \right] $$ Note that $$ L= \lim n  \left[ \frac{\pi}{4} - \left( \frac{n}{n^2+1^2} +\frac{n}{n^2+2^2} + \cdots + \frac{n}{n^2+n^2}  \right) \right] =[\infty \cdot 0].$$ I can't manage to calculate $L$ . How can this indeterminate form be solved? Also, by using computer, I suspect that $L$ exists and is equal to $1/4$ . Any idea or hint is welcome! (Actually, I dont need a complete solution, just a good start point). Have a nice day you all!","['limits', 'riemann-sum', 'real-analysis']"
4111305,Number of patients in ICUs,During the past 50 days we observed the number of Covid patients in the city's hospitals and the records show a mean $μ = 710$ and $σ = 151$ . Calculate the probability to have more than 950 patients in ICUs. We want to find $P(X>950)$ . We calculate $Z = \frac{950-710}{\sqrt 151} = 19.53$ but I don't think it is correct. Any help? Thank you.,"['statistics', 'probability']"
4111319,"Compute Double Sum $\sum_{n,m=1}^{\infty}\frac{(-1)^{n-1}}{n^2+m^2}=\frac{\pi^2}{24}+\frac{\pi \ln(2)}{8}$","EDIT After a long search, it seems that the solution is related to Jacobi elliptical functions. For instance, if we try using this itegral representation $$\boxed{\frac{1}{m^2+ n^2}=\int_{0}^{\infty}e^{-(m^2+n^2)t}dt}$$ We end up with sums of the following form, which as far as I found, are related to Jacobi elliptical functions. $$\sum_{m=1}^{\infty}e^{-m^2t}$$ Another strategy would be starting with the following identity $$\boxed{\sum_{n=1}^{\infty}\frac{(-1)^n}{m^2+n^2}=\frac{\pi \mathrm{csch}(\pi m)}{2m}-\frac{1}{2m^2}}$$ Also leads to evaluate a sum of the form below, which also belongs to the elliptical functions family $$\sum_{m=1}^{\infty}\frac{1}{m \sinh(\pi m)}$$ Even the infinite product $$\prod_{k=1}^{\infty} \Big(1+e^{-\pi k2} \Big)$$ seems to be related to these special functions! First attempt $$\boxed{\sum_{n=1}^{\infty}\sum_{m=1}^{\infty}\frac{(-1)^{n-1}}{n^2+m^2}=\frac{\pi^2}{24}+\frac{\pi \ln(2)}{8}}$$ Consider $$S=\sum_{n,m=1}^{\infty}\frac{(-1)^{n-1}}{n^2+m^2}$$ $$S=-\sum_{n=1}^{\infty}(-1)^n\sum_{m=1}^{\infty}\frac{1}{n^2+m^2}$$ Recall $$\boxed{\sum_{m=1}^{\infty}\frac{1}{n^2+m^2}=\frac{\pi \coth(\pi n)}{2n}-\frac{1}{2n^2}}$$ $$S=-\sum_{n=1}^{\infty}(-1)^n\frac{\pi \coth(\pi n)}{2n}-\frac{1}{2}\sum_{n=1}^{\infty}\frac{(-1)^{n-1}}{n^2}$$ $$S=-\frac{\pi}{2}\sum_{n=1}^{\infty}(-1)^n\frac{ \coth(\pi n)}{n}-\frac{\pi^2}{24}$$ Also $$\boxed{\coth(\pi n)-1=\frac{2}{e^{2 \pi n}-1}}$$ $$S=-\frac{\pi}{2}\sum_{n=1}^{\infty}\frac{(-1)^n}{n} \bigg\{\frac{2}{e^{2 \pi n}-1}+1 \bigg\}-\frac{\pi^2}{24}$$ $$S=-{\pi}\sum_{n=1}^{\infty}\frac{(-1)^n}{n} \bigg\{\frac{1}{e^{2 \pi n}-1}\bigg\}-\frac{\pi}{2}\sum_{n=1}^{\infty}\frac{(-1)^n}{n}-\frac{\pi^2}{24}$$ $$S=-{\pi}\sum_{n=1}^{\infty}\frac{(-1)^n}{n} \bigg\{\frac{1}{e^{2 \pi n}-1}\bigg\}+\frac{\pi \ln(2)}{2}-\frac{\pi^2}{24}$$ $$S=-{\pi}\sum_{n=1}^{\infty}\frac{(-1)^ne^{-2 \pi n}}{n}\sum_{k=0}^{\infty}e^{-2 \pi n k} +\frac{\pi \ln(2)}{2}-\frac{\pi^2}{24}$$ $$S=-\pi\sum_{k=0}^{\infty}\sum_{n=1}^{\infty}\frac{(-1)^ne^{-2 \pi n(k+1)}}{n}+\frac{\pi \ln(2)}{2}-\frac{\pi^2}{24}$$ $$S=\pi\sum_{k=1}^{\infty}\ln(1+e^{-2\pi k})+\frac{\pi \ln(2)}{2}-\frac{\pi^2}{24}$$ $$S=\pi\ln(\prod_{k=1}^{\infty}1+\big(e^{-\pi k}\big)^2)+\frac{\pi \ln(2)}{2}-\frac{\pi^2}{24}$$ From this point on, I can´t finish. Any help is welcome. Second attempt I tried the method suggest bellow by @NoName, but I still missing one factor $\frac{1}{4}$ before the $\log(2)$ . I suspect that this method fails because $\sum_{m=1}^{\infty}\frac{1}{m}\sin(mt)=\frac{\pi}{2}-\frac{t}{2}$ is only valid betweem $0$ and $2 \pi$ . $$S=\sum_{n=1}^{\infty}(-1)^{n+1}\sum_{m=1}^{\infty}\frac{1}{n^2+m^2}$$ rewrite $$\frac{1}{n^2+m^2}=\frac{1}{m}\int_{0}^{\infty}\sin(mt)e^{-nt}dt$$ $$S=\sum_{n=1}^{\infty}(-1)^{n+1}\sum_{m=1}^{\infty}\frac{1}{m}\int_{0}^{\infty}\sin(mt)e^{-nt}dt$$ $$S=\int_{0}^{\infty}\sum_{n=1}^{\infty}(-1)^{n+1}e^{-nt} \Big\{\sum_{m=1}^{\infty}\frac{1}{m}\sin(mt) \Big \}dt$$ $$S=\int_{0}^{\infty}\sum_{n=1}^{\infty}(-1)^{n+1}e^{-nt} \Big\{ \frac{\pi}{2}-\frac{t}{2} \Big \}dt$$ $$S=\sum_{n=1}^{\infty}(-1)^{n+1}\int_{0}^{\infty}e^{-nt} \Big\{ \frac{\pi}{2}-\frac{t}{2} \Big \}dt$$ $$S=\sum_{n=1}^{\infty}(-1)^{n+1} \Big\{ \frac{\pi}{2n}-\frac{1}{2n^2}\Big \}$$ $$S=\frac{\pi}{2}\sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n}-\frac{1}{2}\sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n^2}$$ $$S=\frac{\pi \log(2)}{2}+ \frac{\pi^2}{24}$$","['integration', 'sequences-and-series']"
4111338,Synthetic geometry: stereographic projections of $\mathbb{C}$ on Riemann sphere $\Sigma$ are inversions in sphere $K$ centered on $\infty$ of $\Sigma$,"The complete statement is the following: Show that if $K$ is the sphere of radius $\sqrt{2}$ centered at the north pole ( $N=\infty$ ) of the Riemann sphere $\Sigma$ s.t. $K$ intersects $\Sigma$ about the unit circle $C$ of $\mathbb{C}$ : Then, for a point $a$ on $\mathbb{C}$ and its stereographic projection $\hat{a}$ on $\Sigma$ , $\hat{a}$ is the inversion in $K$ of $a$ , and $a$ is the inversion in $K$ of $\hat{a}$ . Notice that, on the image, the unit circle $C$ is represented by the line from $-1$ to $+1$ . I'm looking for a proof on this 2D graph with circles, using no algebraic property, i.e. pure synthetic geometry. Naturally this will trivially generalize to spheres. Here's what I've done up to now. First, remember the geometrical definition of circle inversion of $a$ in $K$ : Where $qI1\hat{a}$ and $qI2\hat{a}$ are right angles, and $I1\hat{a}, I2\hat{a}$ are tangents to $K$ . The theorem is very obvious if one constructs the two following machines where either $a$ or $\hat{a}$ is fixed on the line $\mathbb{C}$ : CASE 1. $a$ on the complex plane and within $C$ : CASE 2. $a$ off the complex plane: The problem is, of course, to produce the geometrical proof that these constructions do hold the property of necessarily making $\hat{a}$ the inversion in $K$ of $a$ , and $a$ the inversion in $K$ of $\hat{a}$ , no matter what point on $\mathbb{C}$ we might choose. This problem is from Needham's Visual Complex Analysis, p. 142-143; the author offers an algebraic solution while I'm looking for a geometrical one.","['complex-analysis', 'euclidean-geometry', 'stereographic-projections', 'geometry']"
4111339,WKB for a boundary value problem with two layers,"The equation $\epsilon y''-x^4y'-y=0,\ y(0)=y(1)=1$ , can be solved by boundary layer analysis and turns out it has two layers of size $O(\epsilon) $ and $O(\sqrt{\epsilon})$ at $1,0$ accordingly. Is possible to solve this with WKB method?
How do I deal with the fact that the coefficient of $y',\ q(x)=-x^4$ is $q(0)=0$ ? Boundary layer analysis: outter expansion : $\epsilon\rightarrow0 \implies -x^4y'-y=0\implies y_o(x)=Ce^{\frac{1}{3x^3}}$ Since $q(x)\leq0$ , we expect a boundary layer near $1$ . Substituting $X=\frac{(1-x)}{\delta(\epsilon)}\implies$ $\frac{\epsilon}{\delta^2(\epsilon)}Y''(X)+(1-\epsilon X)^4\frac{1}{\delta(\epsilon)}Y'(X)-Y(X)=0.$ Scaling $\delta(\epsilon)=O(\epsilon)$ as $\epsilon\rightarrow0\implies$ $Y''(X)+Y'(X)=0\implies Y_1(X)=A_0+B_0e^{-X}$ . $y(1)=1\implies Y(0)=1\implies A_0+B_0=1$ . From $y_o(x)$ we can see that as $x\rightarrow0,\ y_o(x)\rightarrow\infty$ unless $C=0$ thus $y_o(x)=0$ . Matching to outter solution $\lim_{X\rightarrow\infty}Y_1(X)=0\implies A_0=0\implies B_0=1$ and $Y_1(X)=e^{-X}.$ Then there is a boundary layer at $0$ obviously. Substituting $Z=\frac{x}{\delta(\epsilon)}\implies$ $\frac{\epsilon}{\delta^2(\epsilon)}Y''(Z)-(\delta(\epsilon)Z)^4\frac{1}{\delta(\epsilon)}Y'(Z)-Y(Z)=0$ . The only consistent scale is $\delta(\epsilon)=O(\sqrt{\epsilon})$ . $Y(Z)''-Y(Z)=0\implies Y_0(Z)=D_0e^Z+E_0e^{-Z}$ . $y(0)=1\implies D_0+E_0=1$ . Again, matching to the outer solution $\lim_{Z\rightarrow\infty}Y_0(Z)=0$ is only possible if $D_0=0$ . Thus $Y_0(Z)=e^{-Z}$ , and finally $y_{uniform}(x)=e^{\frac{x-1}{\epsilon}}+e^{-\frac{x}{\sqrt{\epsilon}}}$ .","['asymptotics', 'boundary-layer', 'ordinary-differential-equations', 'perturbation-theory']"
4111353,Two form surface integral over sphere,"I'm trying to compute $\int_M \omega$ with \begin{align*}
\omega &= x^4 dy \wedge dz + y^4 dz \wedge dx + z^4 dx \wedge dy, \\
M &: x^2 + y^2 + z^2 = R^2. 
\end{align*} I have done this in two ways: Stokes' theorem and direct computation of the wedge product via a spherical coordinate transformation. Using $\phi$ as azimuthal and $\theta$ as polar angle and applying Stokes I obtain \begin{align*}
4 \int_0^{2 \pi}\int_0^{\pi} (x^3 + y^3 + z^3) R^2 \sin \theta d\theta d\phi = 0,
\end{align*} where I used the standard \begin{align*}
x &= R \sin \theta \cos \phi \\
y &= R \sin \theta \sin \phi \\
z &= R \cos \theta.
\end{align*} By directly computing the wedge products and plugging them in I obtain \begin{align*}
dy \wedge dz &= R^2 \sin^2 \theta \cos \phi d\theta \wedge d\phi \\
dz \wedge dx &= R^2 \sin^2 \theta \sin \phi d\theta \wedge d\phi \\
dx \wedge dy &= R^2 \cos \theta \sin \theta d\theta \wedge d\phi \\
\int_M x^4 dy &\wedge dz + y^4 dz \wedge dx + z^4 dx \wedge dy = 0.
\end{align*} The solution given by my professor was $\frac{12}{5} \pi^2 R^5$ , which neither method agrees with. Then I repeat this procedure but instead of taking a sphere, I take a hemisphere. Changing the limits in the $\theta$ integrals to $[0, \frac{\pi}{2}]$ , the Stokes' method yields $2 \pi R^5$ and the direct wedge computation yields $\frac{\pi R^6}{3}$ . The solution given then is just $\frac{6}{5} \pi^2 R^5$ , which also does not agree with my solutions. Any help with my mistakes would be greatly appreciated.","['integration', 'calculus', 'spherical-coordinates', 'differential-forms']"
4111355,"Verification:if $I_n=[a_n,b_n]$ is sequence such that $\forall n\in\mathbb{N},I_{n+1}\subset I_n$. Show that $\bigcap_{n=0}^{+\infty}I_n\neq\emptyset$","I'd like a proof verification. I tend to forget/miss details. I hope it is right, if not I'd love to here what went wrong.
Also, if you know another way to show that statement, I'd be very curious to hear about it. Statement: Let $I_n=[a_n,b_n]$ be a sequence of intervals such that $\forall n\in\mathbb{N}, I_{n+1}\subset I_n$ . Show that $\bigcap_{n=0}^{+\infty}I_n\neq\emptyset$ Proof: If $I_{n+1}\subset I_n$ , then the sequence $(I_n)_{n\in\mathbb{N}}$ is decreassing. We notice that $I_{n+1}\subset I_n\iff[a_{n+1},b_{n+1}]\subset[a_n,b_n]$ , which implies that $(a_n)_{n\in\mathbb{N}}$ is increassing and $(b_n)_{n\in\mathbb{N}}$ decreasing. Because $\mathbb{R}$ is an ordered set, $a_n\leq b_n$ , which implies that $\exists(a,b)\in(\mathbb{R}\cap I_0)^2$ such that $a_n\leq a$ and $b_n\geq b,\forall n\in\mathbb{N}$ . As $(a_n)_{n\in\mathbb{N}}$ (resp. $(b_n)_{n\in\mathbb{N}}$ ) is increasing (resp. decreasing) and has an upperbound (resp. lowerbound), both $(a_n)_{n\in\mathbb{N}}$ and $(b_n)_{n\in\mathbb{N}}$ converge and $\bigcap_{n=0}^{+\infty}I_n=[a,b]$ , where $a=$ sup $\{a_n|n\in\mathbb{N}\}$ and $b=$ inf $\{b_n|n\in\mathbb{N}\}$ .
Also, if lim $_{n\rightarrow +\infty}(a_n-b_n)=0$ , then $a=b$","['solution-verification', 'analysis', 'real-analysis']"
4111452,Is an irreducible affine variety isomorphic to some affine hypersurface?,"I'm reading the basics of birational geometry in Shafarevich's ""Basic Algebraic Geometry, 1"" third edition. In theorem 1.8 he proves that Every irreducible affine variety $X\subseteq \mathbb{A}^n$ is
birationally equivalent to some hypersurface $Y\subseteq \mathbb{A}^m$ for some $m$ . ( In fact, $m=n+1$ ) I'm wondering whether the same statement still holds true or not if we replace ""birationally equivalent"" with ""isomorphic"". So, my question is: Is every irreducible affine variety $X\subseteq \mathbb{A}^n$ isomorphic to some affine hypersurface $Y\subseteq \mathbb{A}^m$ for some $m$ ? I don't think this is true (it seems ""too good to be true""), but I don't know how can I disprove such statement.
Can you provide me with an example of an affine variety which is never isomorphic to an affine hypersurface? (I can work out the details myself, I just can't think of an elementary way or example to do this).
I'd be surprised if the statement is true, if so, how could I prove it? (it should be an important result in such case) Related question: Any quasi-affine variety is isomorphic to a closed subvariety in $\mathbb{A}^n\setminus \mathbb{A}^m$ for some $m,n$. Regards","['reference-request', 'affine-varieties', 'algebraic-geometry', 'birational-geometry', 'soft-question']"
4111455,The Cantor distribution is singular (with respect to lebesgue measure),"If we define the Cantor distribution $\mu$ as the distribution that has $F=$ "" Cantor function "" as it's cumulative distribution function, how do we show that $\mu$ is singular with respect to the Lebesgue measure? If $\lambda$ is the Lebesgue measure I have to show that if $\lambda(A)=0$ then $\mu(A)=0$ . For a point-set $\{x\}\subset\mathbb{R}$ it does hold since $\lambda(\{x\})=0$ and $$\mu(\{x\})=\mu(\bigcap\limits_{n=1}^{\infty}(x-\frac1n,x])=\lim\limits_{N\to\infty}\mu(\bigcap\limits_{n=1}^{N}(x-\frac1n,x])=\lim\limits_{N\to\infty}\mu((x-\frac1N,x])\lim\limits_{N\to\infty}F(x)-F(x-\frac1N)=0$$ since $F$ is continuous. But how to show the property for a general $A$ $\lambda$ -measurable?","['measure-theory', 'real-analysis']"
4111594,Divergent integral,"Given $$
\int^\infty_0 \frac{\sin^\alpha \left(\frac{1}{x+1}\right)\arctan(x)}
                   {(x^2+1)^\beta \tan\left(\frac{1}{x^2+1}\right)}dx 
$$ find for which values of $\alpha$ and $\beta$ the integral is divergent. My approach to such integrals is to solve them by finding the correct asymptotic relations between the separate parts of it. In this particular integral, $\infty$ is surely a ""problem point"" so we get asymptotically equal functions as $x \to \infty$ such as: $\sin^\alpha\left(\frac{1}{x+1}\right) \sim \frac{1}{x+1} \sim \frac{1}{x}$ and so on with the rest. My problem here is that I'm not sure if $0$ is a ""problem point"" (such point that the function in it has ""undefined behavior"") and are there any other ""problem points"" in the $[0, \infty]$ interval?","['integration', 'convergence-divergence', 'trigonometric-integrals']"
4111599,Convergence of a random harmonic series with Poisson gaps,"The divergence of the harmonic series is familiar: the partial sums of positive integer reciprocals grow  without bound. A less familiar but still well-known result is Kempner's series: If we only use integers whose base-10 expansion contains a 9, then the sum of reciprocals converges. The intution this suggests is that the convergence of such sums depend on what fraction of the integers are excluded. As a demonstration of this, one can consider the following probabilistic version of the harmonic series. Let $\{X_n\}_{n=1}^\infty$ be a sequence of fair coin flips with values $\pm 1$ . Then we can ask whether or not the series $\sum_{n=1}^\infty X_n/n$ converges. The answer is provided by Kolmogorov's three-series theorem , which supplies conditions for the convergence of a random series $\sum_{n=1}^\infty X_n$ . As discussed in the linked Wikipedia article, the series converges almost surely. (By contrast, replacing $1/n\to 1/\sqrt{n}$ results in almost-sure divergence.) With that as background, I came up with a different variation on a 'probabilistic' harmonic series. We start with an infinite random sequence $\{X_n\}_{n=1}^\infty$ as before, but now each variable is an iid Poisson variable ( $X_n\sim \text{Pois}(\lambda)$ ). Furthermore, let $Y_n=\sum_{k=1}^n (1+X_k)$ . (Note that, beyond a minimum distance of $1$ , the gaps between successive integers in this sequence are Poisson-distributed.) Now consider the series $\sum_{n=1}^\infty Y_n^{-1}$ . In more elementary terms, we sum the reciprocals of an integer sequence for which the gaps are Poisson-distributed. What can be said about the probability of convergence for this series? Presumably it again hinges upon use of Kolmogorov's three-series theorem but I'm not familiar enough with such to tackle it myself. (I'd also be happy if references for this case exist.)","['convergence-divergence', 'probability-theory', 'sequences-and-series']"
4111615,Sine function and wave questions [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 3 years ago . Improve this question I have been doing research for a few weeks, and I was trying to learn more about sine. I learned how it was used in trigonometry for calculating angles. It is the same as the sine function, which is used in engineering, and it is the same as sound waves. I learned how the function is able to be written on a graph as a wave. I heard about the Taylor series. I think it’s an equation used for calculating the sine of an angle, and when it is plotted on a graph, it is the same as the wave. Q1 Is this a coincidence, or are they the same for a reason? Q2 why is sine related with PI? Q3 (This might be an obvious question) How are functions plotted on graphs. I have looked very far on the internet and couldn’t find an answer to these questions. I would really appreciate someone to help me. (Also, sorry that I jumbled a bunch of questions into one.)","['trigonometry', 'graphing-functions']"
4111727,The expectation of sum of squares of the arrival times in a Poisson process,"Question: Let $\{N(t)\}$ be rate $\lambda$ Poisson process, with arrival times $\{S_n,n=0,1,...\}$ . Evaluate the expected sum of squares of the
arrival times occuring before $t$ , $$E(t)=\mathbb{E}\left[\sum_{n=1}^{N(t)}S_n^2\right]$$ where we define $\sum_{n=1}^{0} S_n=0$ . There's a similar question here . However, in this question, we are looking for the expected sum of squares . I tried to understand the answer to the similar question in order to solve the problem on my own. However, I cannot even understand that. I am confused. I do not even know where to start. Is there a formula for $S_i$ 's?","['expected-value', 'stochastic-processes', 'statistics', 'poisson-process']"
4111803,"Find the conditional expectation $E(U\mid \min(U,1−U))$ where $U∼U[0,1]$","Assume that $U$ is a random variable on $(Ω,\mathcal{F},P)$ with $U∼U[0,1]$ . Let $Y= \min(U,1−U)$ . I am asked to find $E(U\mid Y)$ . I have figured out a proof for this and I want some sanity check. My train of thought for tackling this: First, by heuristic: Suppose $Y = y \in [0, 1/2]$ . What this mean is that $U = y$ or $U = 1-y$ with equal probability $1/2$ . Therefore, the conditional expectation of $U$ given $Y = y$ is then $$
E(U\mid Y=y) = y/2 + (1-y)/2 = 1/2.
$$ Since $y$ here is arbitrary, it should imply that $$
E(U\mid Y) = 1/2 \ \text{ a.s}.
$$ Now to prove this by definition, first note that $1/2$ is a constant and measurability w.r.t. $\sigma(Y)$ is trivial. Secondly, choose $A \in \sigma(Y)$ , we then have $$
\int_A 1/2\,dP  = P(A)/2.
$$ On the other hand, we have $$
\int_{A}U(\omega)\,dP(\omega) = \int_\Omega U(\omega)\boldsymbol{1}(\omega \in A)\,dP(\omega).
$$ Since $U$ is uniform $(0,1)$ R.V., it has a density of $1$ w.r.t. the Lebesgue measure. Furthermore, there is a $B \subset [0,1]$ s.t. $U^{-1}(B) = A$ . Hence, the above integral can be written as $$
\int_\Omega U(\omega)\boldsymbol{1}(\omega \in A)\,dP(\omega) = \int_{B}u\,du,
$$ where the integration on the RHS is w.r.t. the Lebesgue measure. Now consider the set $B$ , it is easy to see that it is an element of the sigma-algebra generated by the following sets: $$
[0,t]\cup[1-t,1], \ t\in[0,1/2],
$$ since $\sigma(Y)$ is generated by $\sigma(\{Y \leq t, \ t\in[0,1/2]\})$ and $Y \leq t$ is equivalent to $U \leq t$ or $U \geq 1-t$ . Now since $[0,t]\cup[1-t,1]$ is symmetric w.r.t. $1/2$ , then $B$ should also be a set that is symmetric w.r.t. $1/2$ . This implies that $$
\int_{B}u\,du = \lambda(B)/2 = P(A)/2,
$$ which concludes the proof. Does this proof work? Thanks a lot!","['conditional-probability', 'measure-theory', 'probability-theory', 'conditional-expectation']"
4111817,System of differential equations blow-up in finite time,"I have the following system of differential equations: $\begin{cases}y_1'=y_1(y_2-1)\\y_2'=y_2(y_1-1)\end{cases}$ with critical points $(0,0)$ and $(1,1)$ . We can obtain the orbits: $\dfrac{dy_1}{dy_2}=\dfrac{y_1}{y_2}\dfrac{y_2-1}{y_1-1}\Rightarrow \left(1-\dfrac{1}{y_1}\right)dy_1=\left(1-\dfrac{1}{y_2}\right)dy_2\Rightarrow y_1-\log(y_1)=y_2-\log(y_2)+C\Rightarrow $$y_1-\log(y_1)-1=y_2-\log(y_2)-1+C$ . Now we can define $h:(0,+\infty)\to\Bbb R$ as $h(t)=t-\log(t)-1$ , so each orbit is contained in a curve of the form $\{(y_1,y_2):h(y_1)-h(y_2)=C\}$ . $h$ attains a minimum, $h(1)=0$ , and it kind of behaves like a parabola, so we can define $h_1=h_{\mid (0,1)}$ and $h_2=h_{\mid (1,+\infty)}$ , and they both are invertible maps with range $(0,+\infty)$ . I'm interested in the case $C=0$ , which consists of a curve containing $(1,1)$ , and more specifically, when $y_1(0)=y_{10}>0, y_2(0)=y_{20}>0$ . In this case we have $y_2=h_2^{-1}(h(y_1))$ (or $y_1=h_2^{-1}(h(y_2))$ ). I've been told that there exists $0<\beta<+\infty$ such that $y_1(t),y_2(t)\xrightarrow{t\to\beta^-}+\infty$ , but why is $\beta<+\infty$ ? Any ideas on how to show this? The going-to-infinity part I think I can show: It's clear that $0<\beta\leq+\infty$ , and we have $y_1(t),y_2(t)>1\;\forall t\geq0$ , so both $y_1$ and $y_2$ are strictly increasing, and therefore $\exists\, a,b$ such that $\displaystyle\lim_{t\to\beta^-}y_1(t)=a\in(y_{10},+\infty)$ and $\displaystyle\lim_{t\to\beta^-}y_2(t)=b\in(y_{20},+\infty)$ . If we had $a<+\infty$ then $b=\displaystyle\lim_{t\to\beta^-}y_2(t)=\lim_{t\to\beta^-}h_2^{-1}(h(y_1(t)))=h_2^{-1}(h(a))=a$ (because $a>y_{10}>1$ ). But then, as a consequence of LaSalle's invariance principle, $(a,a)$ should be a critical point, which is absurd. Therefore, $y_1(t)\xrightarrow{t\to\beta^-}+\infty$ , and consequently, $y_2(t)\xrightarrow{t\to\beta^-}+\infty$ .",['ordinary-differential-equations']
4111840,How many $5$-digit numbers less than $43205$ do not contain any digits greater than $6$?,"I'm not sure how to solve this question. The only starting point I've thought of is $3 \times 7^4$ because one case would involve the first digit being either $1, 2$ or $3$ , and the remaining $4$ digits would each have $7$ number possibilities. Would someone be able to explain how to approach this question please?","['permutations', 'discrete-mathematics']"
4111852,Expected time to roll all $1$ through $6$ on a die,"What is the average number of times it would it take to roll a fair $6$ -sided die and get all numbers on the die?  The order in which the numbers appear does not matter. I had this questions explained to me by a professor (not math professor), but it was not clear in the explanation.  We were given the answer $(1-(\frac56)^n)^6 = .5$ or $n = 12.152$ Can someone please explain this to me, possibly with a link to a general topic?","['dice', 'coupon-collector', 'probability']"
4111860,Find the perimeter of a four-sided polygon that is formed between two triangles,"Problem Statement An acute triangle intersects with another triangle to form a four-sided polygon.  Given all angles, and given the distance of two sides of the polygon, find the other two sides of the polygon.  See image (not drawn to scale). The angles that form the acute triangle are: 11°, 81°, 88° The angles that form the other triangle are: 71°, 81°, 28° side a = 57 inches side b = 70.25 inches find side c & d Attempt The acute triangle is actually an isosceles triangle (11°, 84.5°, 84.5°) with an arbitrary line drawn through it.  I have used the Law of Sines and SOH CAH TOA to find the midpoints of the acute/isosceles triangle.  I thought I could use the same techniques to find sides c & d, but I can't seem to figure out how to create an equation that relates the two intersecting triangles.  My gut tells me that a calculation should be possible given the constraining angles and distances. Background I am building a tree-house, where the the four-sided polygon represents the main deck.  I need to figure out the correct spacing of joists that will lay between the legs of the isosceles triangle.  Because I am working in a live tree, nothing is square and true.  I expect I will need to install 6 joists, but I won't know for sure unless I lay it out.  Since it is such a pain in the neck to put even one joist down, I want to plan ahead.  I'd like to minimize the amount of time tying into my safety line, going up and down, measuring for length, measuring for angle, and test fitting, and so forth. I know if I carefully sketch it out, mechanical-drawing style, I could measure the distance on the paper, but that has its own challenges.  I've also attempted to sketch it out using computer software, which for me has a high learning curve.  Using a calculation allows me to keep squishy things in check, like material inconsistencies, flexing of fasteners, and movement of the tree itself.  It also gives me a better way to check my work.  Lastly, without having to use my Dad Voice , I want my kids to understand that there is more to math than just homework.","['systems-of-equations', 'triangulation', 'geometry', 'triangles', 'trigonometry']"
4111956,"A ``continuous'' family of measurable subsets of [0,1], each with a positive measure, admits a ``continuous'' subfamily with non-empty intersection?","Let $\{Y_x\}$ be a family of measurable subsets of [0,1] indexed by $x \in [0,1]$ , and such that each set $Y_x$ has a positive (Lebesgue) measure. Is there always a subset $X \subseteq [0,1]$ with positive measure and such that $\bigcap\limits_{x \in X} Y_x$ is nonempty? Intuitively it seems to be true, possibly under some mild extra assumptions (say compactness of $Y_x$ 's).","['measure-theory', 'set-theory']"
4111996,"Given $\sin{x} = \frac{1 + \sqrt{5}}{4}$, find $x$","If I have been given that $$\sin{x} = \frac{1 + \sqrt{5}}{4}$$ is there any way using which I can find out what the value of $x$ is? Sure I can remember the values, but I  was curious whether if I knew the values of $\sin{\frac{\pi}{2}}, \sin{\frac{\pi}{4}}, \sin{\frac{\pi}{3}}$ I could somehow figure out what $x$ would be? Is there any intuition behind it?",['trigonometry']
4112011,Show that $T$ is a topology on $X$.,"Let $f:X\rightarrow Y$ be a map and let $T'$ be a topology on $Y$ . Show that $$T=\{U\subseteq X \mid \exists V\in T' \text{ with }U=f^{-1}(V)\} $$ is a topology on $X$ . $T'$ is the coarsest topology on $X$ such that the map $f:(X, T) \rightarrow (Y, T') $ is continuous. $$$$ We have to show: 1.The set $X$ and the empty set are elements of $T$ . Any union of elements of $T$ belongs to $T$ . Any finite intersection of elements of $T$ belongs to $T$ . $$$$ Toshow these axioms, Ihave done the following: It holds that $X\subseteq X$ and $f(X)\in T'$ where $T'$ is a topology, and so we get $X\in T$ . We also have that $\emptyset\subseteq X$ and $f(\emptyset)\in T'$ where $T'$ is a topology, and so we get $\emptyset\in T$ . We consider the union $O = \bigcup\limits_{\alpha \in I} U_{\alpha}$ . This set is in $T$ iff theimage under $f$ is in $T'$ .
So we consider $f \left( O \right)$ . The union is well defined under images so we get \begin{equation*}f \left( O \right) = f \left( \bigcup\limits_{\alpha \in I} U_{\alpha} \right) = \bigcup\limits_{\alpha \in I} f \left( U_{\alpha} \right)\end{equation*} Since each $U_{\alpha}$ is in $T$ , the images $f\left( U_{\alpha} \right)$ are in $T'$ . Since $T'$ is a topology, is the union again in $T'$ and so we get that $O$ in $T$ . The respective argument of 2.for intersection. Is everything correct?","['general-topology', 'analysis']"
4112013,General deduction of expression $x^n + y^n + z^n $ provided some of its previous powers are known.,"If $x^3 -x +1 = 0$ and $\alpha$ , $\beta$ , $\gamma$ are its roots, find $\alpha^2+\beta^2+\gamma^2$ ; $\alpha^3+\beta^3+\gamma^3$ ; $\alpha^4+\beta^4+\gamma^4$ and $\alpha^5+\beta^5+\gamma^5$ My approach: 1. Find $\alpha^2+\beta^2+\gamma^2$ $$\alpha^2+\beta^2+\gamma^2 = (\alpha+\beta+\gamma)^2 - 2(\alpha\beta+\beta\gamma + \gamma\alpha)$$ Putting the values, we get $$\alpha^2+\beta^2+\gamma^2 = 2$$ 2. Find $\alpha^3+\beta^3+\gamma^3$ $$\alpha^3+\beta^3+\gamma^3 = (\alpha+\beta+\gamma)(\alpha^2+\beta^2+\gamma^2-\alpha\beta-\beta\gamma - \gamma\alpha) + 3\alpha\beta\gamma$$ Here we substitute the value of $\alpha^2+\beta^2+\gamma^2$ and get $\alpha^3+\beta^3+\gamma^3=3$ 3. Find $\alpha^4+\beta^4+\gamma^4$ $$\alpha^4+\beta^4+\gamma^4 = (\alpha^2+\beta^2+\gamma^2)^2 -2[(\alpha\beta+\beta\gamma + \gamma\alpha)^2 -2\alpha\beta\gamma(\alpha+\beta+\gamma)]$$ Here we substitute the value of $\alpha^2+\beta^2+\gamma^2$ and get $\alpha^4+\beta^4+\gamma^4=2$ But I am stuck at $\alpha^5+\beta^5+\gamma^5$ . How do I factorize/break it in terms of known expressions?
Moreover, is there any general algorithm for breaking down these expressions into known lower-level powers since those formulae are pretty hard to remember and also lengthy to derive by trial and error?","['cubics', 'algebra-precalculus']"
4112093,On the Evolution of Random Graph (Existence of Log-size Components),"Theorem: Let $ \mathbf c > 0, p \geq \frac{c}{n}.$ Prove that there exists $a>0$ such that with asymptotical probability 1, the size of the largest component of $G(n,p)$ is at least $a\ln n$ . What I tried: By Cayley's formula I know that there are exactly $k^{k-2}$ spanning trees on $k$ vertices. And let $X_k = $ number of tree components of size $k$ in the graph $G(n,p)$ . And the Expectation can be expressd as: $$E(X_k) = \binom{n}{k} k^{k-2}p^{k-1}(1-p)^{k(n-k)} \approx \frac{n^k e^k}{\sqrt{2\pi k}k^k}k^{k-1}(1-\frac{c}{n})^{k(n-k)} \approx \frac{n e^k c^{k-1}}{\sqrt{2\pi}k^{2.5}}(1-\frac{c}{n})^{kn} \approx \frac{n(e^{1-c}c)^k}{\sqrt{2\pi}k^{2.5}}$$ But I am stuck here. How do I prove this theorem? Any help would be appreciated.","['graph-theory', 'random-graphs', 'probability-theory']"
4112110,Need a pure geometric solution to a $20-30-130$ triangle question,"In $\triangle{ABC}$ , $\angle{ABC}=20^{\circ}$ , $\angle{ACB}=30^{\circ}$ , $D$ is a point inside the triangle and $\angle{ABD}=10^{\circ}$ , $\angle{ACD}=10^{\circ}$ , find $\angle{CAD}$ . Note: I have seen some very similar question with beautiful solution in pure geometric format. I know how to solve this problem in trigonometric format. But I think this problem deserves a beautiful geometric approach as solution, and that's why I post it here. As request, here is approach applying Ceva's theorem in trigonometric form, $$\begin{align*}
\frac{\sin130}{\cos130+2\cos10}&=\tan(x)\Longrightarrow \frac{\sin120\cos10+\cos120\sin10}{\cos120\cos10-\sin120\sin10+2\cos10}\\
&=\frac{\sqrt{3}\cos10-\sin10}{3\cos10-\sqrt{3}\sin10}.\\
&=\frac{1}{\sqrt{3}}\\
&=\tan30\Longrightarrow x\\
&=\boxed{30}\\
\end{align*}$$",['geometry']
4112211,When is the probability measure in de Finetti's theorem finitely supported?,"Let $(X_i)_{i=1}^\infty$ be an exchangeable infinite sequence of random variables taking values in $\{0,1\}$ . De Finetti's theorem states that there exists a unique probability measure $\mu$ on $[0,1]$ such that for any fixed sequence $(e_i)_{i=1}^\infty$ taking values in $\{0,1\}$ it holds that $$\Pr(X_1=e_1,\dots,X_n=e_n) = \int_0^1 p^k(1-p)^{n-k} d\mu(p),\tag{1}$$ where $k = \sum_{i=1}^n e_i$ . Thus, for each $n$ , the distribution of $(X_i)_{i=1}^n$ is a (possibly infinite) mixture of independent Bernoulli trials. Question: Under what conditions on $(X_i)_{i=1}^\infty$ does $\mu$ have finite support? That is, when does there exist $m\in \mathbb N$ , $p_1,\dots,p_m\in [0,1]$ and $\alpha_1,\dots,\alpha_m \ge 0$ with $\sum_{j=1}^m \alpha_j = 1$ such that for any fixed sequence $(e_i)_{i=1}^\infty$ taking values in $\{0,1\}$ : $$\Pr(X_1=e_1,\dots,X_n=e_n) = \sum_{j=1}^m p_j^k(1-p_j)^{n-k} \alpha_j,\tag{2}$$ where $k = \sum_{i=1}^n e_i$ ?","['measure-theory', 'statistics', 'real-analysis', 'probability-theory', 'probability']"
4112224,How are category theory and probability theory related?,"How are category theory and probability theory related ? Category theory seems very useful for understanding objects with definite relationships, whereas probability theory (particular Bayesian methods), can be applied to areas where there is uncertainty. My question is, what attempts have been made to combine these disciplines ? Are there areas of category theory which focus upon probabilistic situations ? Have there been approaches using Bayesian methods etc. to build category theoretic representations of data ? Are there applications of category theory to probabilistic programming ?","['statistical-inference', 'bayesian', 'category-theory', 'machine-learning', 'probability']"
4112232,Matrix Inverse of Outer Product of a vector with itself,"Suppose I have a vector $x \in \mathbb{R}^n$ and the matrix $$
A = \lambda x x^\top \qquad\lambda \in \mathbb{R}\backslash\{0\}
$$ I would like to find an expression for its inverse. Is there a simple expression?","['matrices', 'linear-algebra', 'inverse']"
4112244,Showing two metric spaces are not bi-Lipschitz equivalent but are uniformly isomorphic,"How would one go about generating examples of metric spaces that are uniformly isomorphic (i.e. there is a uniformly continuous bijection between them with uniformly continuous inverse), but also fail to be bi-Lipschitz equivalent (bi-Lipschitz equivalent meaning there is a Lipschitz bijection between them with a Lipschitz inverse)? Furthermore, how could this be shown from first principles i.e. definitions of Lipschitz and uniform continuity? I can think of examples e.g. R,d and R,f(d) where d is the Euclidean norm and f is not Lipschitz (or its inverse is not Lipschitz). However, I struggle to find a way to prove these spaces are not bi-Lipschitz equivalent i.e. there is no Lipschitz bijection with a Lipschitz inverse between them.","['lipschitz-functions', 'metric-spaces', 'analysis']"
4112275,Poisson distribution for arriving vehicles,"I'm interested to model the number of Electric Vehicles (EVs) which arrive to a charging station during one day and their Time-of-Arrivals (ToA). I read that the number of EVs arriving at a charging station during a time interval is considered to follow a Poisson distribution, which uses a parameter which is called $\lambda$ , which is determined by $λ=r \cdot t$ , where: $r$ is the ""arrival rate""; $t$ is the ""time duration"". Example: $r = 1 \space EV / hour$ $t = 24 \space hours$ I know that the probability with which n = 20 EVs arrive at the charging station during 24 hours is: $$ P(n=20) = \frac{e^{-r t} \cdot (r t)^n}{n!} = 0.0623 = 6.23 \% $$ but it's not what I'm looking for, because I'd like to obtain: number of Electric Vehicles (EVs) which arrive to a charging station during one day; and their Time-of-Arrivals (ToA); or, alternatively (if what I request above is not possible), could also be sufficient to obtain: the number of EVs which arrives at each hour of the day. Which could be a way to reach my goals?","['statistics', 'poisson-distribution', 'probability-distributions', 'poisson-process', 'random-variables']"
4112331,"Comparison of the Bounded Convergence Theorem (BCT), Monotone Convergence Theorem (MCT), and Dominated Convergence Theorem (DCT)","I'm trying to understand the relationship between the following theorems: Bounded Convergence Theorem (BCT) : For a uniformly bounded sequence $f_n \to f$ a.e. on a set $E$ of finite measure, we have $$ \lim_{n \to \infty} \int_E f_n = \int_E \lim_{n \to \infty} f_n $$ Monotone Convergence Theorem (MCT) : If $f_n \ge 0$ and $f_n \uparrow f$ a.e., then $$ \int f_n \to \int f $$ Dominated Convergence Theorem (DCT) : If $f_n \to f$ a.e., $|f_n| \le g$ , $\int g < \infty$ , then $$ \int \lim f_n = \lim \int f_n $$ I'm trying to understand how these convergence theorems are induced from uniform convergence, Egorov's theorem, and Fatou's lemma. Another topic I want to explore is if these convergence theorems have analogous relationships within sequence continuities (without the integrals), as well as if these convergence theorems involving integrals are subsets/supersets of each other. I would like to find out which cases are more general, and what types of specific cases make one convergence theorem equivalent to another.","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'real-analysis', 'convergence-divergence']"
4112333,"Finding $\lim_{n\to\infty} \int_0^{\infty}\frac{1}{(1+\frac{x}{n})^nx^{\frac{1}{n}}}\, d\lambda$","The question Compute the limit: $$\lim_{n\to\infty} \int_0^{\infty}\frac{1}{\displaystyle\left(1+\frac{x}{n}\right)^nx^{\frac{1}{n}}}\ \mathrm{d}\lambda$$ My attempt It is clear to see that point-wise the integrand has limit $e^{-x}$ however I am struggling to call upon the proper limit theorem. Since the integrand is decreasing. Also I cannot seem to bound it by an integrable function as neither $\frac{1}{x+x^2}, \frac{1}{x}$ or $\frac{1}{x^2}$ are integrable. Going forward I think this must use the dominated convergence theorem but I cannot seem to find a suitable function. I was considering $f_2(x)$ and then using a substitution $u = x^{\frac{1}{2}}$ but this becomes awfully complicated. Any help would be great.","['integration', 'limits', 'measure-theory', 'real-analysis']"
4112340,What is Representation of Surface Groups?,"I had a question in my mind for a month ago. Mainly I am interested in Hyperbolic Geometry. I found a topic named ""Representation Theory of Surface Groups"". Let me tell about what is a ""surface group"". We define a surface group to be the group defined by the presentation $$ \Gamma _{g} = \left\langle a_{1}, b_{1}, a_{2}, \cdots, a_{g}, b_{g} \bigg| \prod _{r = 1} ^{g} [a_{r}, b_{r}] \right\rangle$$ Moreover, this is a surface group of genus $g$ surface. The representation of surface groups is the representation spaces of surface groups into semi-simple Lie groups $G$ . In the subject, we define $\textbf{representation variety}$ of the fundamental group $\pi_{1}(S)$ of a closed connected surface $S$ of genus greater than $2$ , with values in a Lie group $G$ . The representation variety is defined as follows: $$\text{Rep} \big(\pi_{1} (S), G\big) := \hom \big(\pi_{1}(S), G\big) / G$$ where $G$ acts on $\hom (\pi_{1}(S), G)$ by conjugation. I heard that this topic also intersects with Hyperbolic Geometry when the target group $G  = \text{PSL}_{2} (\mathbb{R})$ or $\text{PSL}_{2} (\mathbb{C})$ . Also, I have heard that Classical Teichmüller theory may be viewed as a starting point of the subject. Now my question is how to study the topic? Does the topic intersect with the Representation Theory of Semi -Simple Lie Groups? Please advise me for a roadmap of the Representation Theory of Surface Groups. Sorry for my bad English. Please help me. Thanking you in advance.","['geometric-invariant-theory', 'moduli-space', 'teichmueller-theory', 'algebraic-geometry', 'hyperbolic-geometry']"
4112341,"Notation for sets A, B not subset of each other","Given two sets $A, B$ , is there a notation for $A \not\subseteq B \:\land\: A \not\supseteq B$ ? That is, $A, B$ are not necessarily disjoint, but are distinct in such a way that neither is a subset of the other.","['elementary-set-theory', 'notation']"
