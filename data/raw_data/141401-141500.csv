question_id,title,body,tags
2286929,Reasoning in an integration substitution,"Evaluate: $\displaystyle\int_{0}^{1}\frac{\ln(x+1)}{x^2+1}\,\mathrm{d}x$ So I did this a completely different way than what the answer key states. I used integration by parts and some symmetry tricks and got the correct answer. However the answer key says: Make the substitution $x=\frac{1-u}{1+u}$ The same solution was reached in about half the steps but still using symmetry, my questions are How would I know to do that? Is this a certain type of substitution? Is there something else that maybe I could use this for?","['substitution', 'integration', 'definite-integrals']"
2287043,Exponential Generating Function Transformation,Say we have an exponential generating function: $$F(x) = \sum_{n\geq 0} f_n \frac{x^n}{n!}.$$ Is there a simple transformation from $F(x)$ to $G(x)$ where $$G(x) = \sum_{n\geq 0} f_n \frac{x^{2n}}{(2n)!}?$$,"['generating-functions', 'combinatorics', 'discrete-mathematics']"
2287084,Is the occurence of $4653$ in both expressions a coincidence?,The smallest composite strong-probable prime to base $2$ greater than $10^5$ is $$10^5+4653$$ and the smallest composite strong-probable prime to base $2$ greater than $10^6$ is $$10^6+4653$$ Is it a coincidence that we have the number $4653$ in both expressions or is there an explanation ?,"['number-theory', 'pseudoprimes']"
2287092,How much worse is weak* convergence vs weak convergence in L1?,"Let's say we have a sequence of functions $f_n \in L^1(\Omega)$ for some nice bounded open set $\Omega \subset \mathbb{R}^N$. In general, even along a subsequence, we don't expect a weak limit (in the sense of testing against $L^{\infty}$ functions), so we often work with the weaker notion of weak$^*$ convergence, that is, a Radon measure $\mu$ such that $$ \int_{\Omega} f_n \phi dx \rightarrow \int_{\Omega} \phi d \mu$$ for every $\phi \in C_b (\Omega)$. My question is this: If we know through some other means that $\mu$ is absolutely continuous with respect to the Lebesgue measure and therefore given by some density $f \in L^1$, so that the above becomes $$ \int_{\Omega} f_n \phi dx \rightarrow \int_{\Omega} f \phi dx$$ then how far is this from being able to say that the $f_n$ are actually weakly converging to $f$? In other words, does the above hold with any $L^{\infty}$ test function, not just $C_b$? Obviously a simple density argument will not hold because $C_b(\Omega)$ is closed in the $L^{\infty}$ norm, but I am having trouble thinking of a counter-example. It seems to me that if we could show for any Borel set $E$ that $$ \int_{E} f_n dx \rightarrow \int_{E} f dx$$ then this would suffice- but obviously we do not have this in general for weak$^*$ convergence. Any thoughts?","['functional-analysis', 'calculus-of-variations', 'measure-theory', 'partial-differential-equations']"
2287121,A measure and the Fourier inverse transform of its Fourier transform,"Given a finite Borel measure $\mu$ on $\mathbb{R}^d$ , consider the Fourier inverse transform of its Fourier transform: $\mathcal{F}^{-1}(\mathcal{F}(\mu))$ , where $$
\mathcal{F}(\mu)(\xi) = \int \exp(-2\pi i x \cdot \xi) d\mu(x).
$$ and $$
\mathcal{F}^{-1}(g)(\xi) = \int \exp(2\pi i x \cdot \xi) g(x) dx.
$$ How is $\mu$ related to $\mathcal{F}^{-1}(\mathcal{F}(\mu))$ ? In particular, how are their supports related? For context, I know that if instead of a measure $\mu$ we had a function $f$ , we would have $$\mathcal{F}^{-1}(\mathcal{F}(f)) = f$$ (under suitable hypotheses, such as $f$ and $\mathcal{F}(f)$ in $L^1$ ). I don't expect anything like this to hold for measures. But I thought perhaps the supports of $\mathcal{F}^{-1}(\mathcal{F}(\mu))$ and $\mu$ might be related. For context, I know that if $\mathcal{\mu} \in L^1(\mathbb{R}^d)$ , then $\mu$ has a continuous density.","['real-analysis', 'fourier-analysis', 'harmonic-analysis', 'measure-theory', 'fourier-transform']"
2287161,Partial Sums of a Trignometric Series,"I'm attempting to show that the partial sums of $$f(x)=\sum_{n=1}^{\infty}\frac{(-1)^n\sin(nx)}{n}$$ are uniformly bounded on the interval $(-\pi,\pi).$ This expression $$S_N(x)=\sum_{k=1}^N\frac{(e^{ix})^k}{k}$$ comes up where $S_N(x)$ is not the partial sum of $f(x),$ just a piece of it, after using Euler's formula. Is there a closed form expression of $S_N(x)$ similar in spirit to Dirichlet's kernel?","['real-analysis', 'fourier-series', 'fourier-analysis', 'trigonometry', 'power-series']"
2287177,show $(1+\frac{a}{n})^{n-k}=e^a(1-\frac{a(a+k)}{2n})+o(\frac{1}{n})$ for a fixed nonnegative integer $k$ as $n\to\infty$?,"How to show $(1+\frac{a}{n})^{n-k}=e^a(1-\frac{a(a+k)}{2n})+o(\frac{1}{n})$ for a fixed nonnegative integer $k$ as $n\to\infty$? We already known that $(1+\frac{a}{n})^{n}\to e^a$ as $n\to\infty$, but I don't know how to deal with $(1+\frac{a}{n})^{-k}$. Could someone kindly help? Thanks. http://sites.stat.psu.edu/~dhunter/asymp/fall2004/lectures/edgeworth.pdf","['asymptotics', 'probability', 'calculus', 'approximation']"
2287211,Completion (!) of proof of VI.3.4 (completeness of L1) in Lang's Real and Functional Analysis,"Lang starts the proof that the $\mathcal{L}^1(\mu_X, E)$ - defined as the space of pointwise a.e. limits of Cauchy sequences of step maps (defined to vanish outside sets of finite measure) - is complete in the $L^1$-norm (functions $X \to E$, $E$ Banach) by using the fact that step functions are dense in $\mathcal{L}^1$.  This is obviously a true fact but I don't see how it follows from the three facts he has already proven (no monotone or dominated convergence): VI.3.1: A Cauchy sequence of step maps has a subsequence which both converges both pointwise a.e. and converges uniformly outside a set of arbitrarily small positive measure. VI.3.2: If $(f_n)$, $(g_n)$ are Cauchy sequences of step maps converging pointwise a.e. to $f$, $g$, then $\lim\int{f_n}$, $\lim\int{g_n}$ exist and are equal, and $||f_n - g_n||_1 \to 0$.  (Thus, $\int$ is well-defined.) VI.3.3: If $(f_n)$ is a Cauchy sequence of step maps and converges pointwise a.e. to $f$, then the same for $|f_n|$ and $|f|$.  (Thus, $||\cdot||_1$ is well-defined.) Essentially what we haven't proved is that Cauchy+p.w. a.e convergence of step maps implies $L^1$-convergence to the limit function ... is this an obvious fact that I'm missing (i.e., easier than proving later theorems directly and invoking them)?","['functional-analysis', 'real-analysis', 'measure-theory']"
2287213,Closure of interior of closed convex set,"Consider a closed convex set with non empty interior in a topological vector space (a vector space endowed with a topology that makes sum and scalar multiplication continuous). Show that the closure of its interior is the original set itself. I have already proved the case for normed spaces (if $x$ lies in the interior and $z$ is any other point, there is a “cone”, so to speak, whose base is a ball centres at $x$ and whose corner is $z$). But the proof doesn't translate (I am using triangle inequality in the normed case which I don't see how to translate). Any help is appreciated.","['functional-analysis', 'topological-vector-spaces']"
2287229,"Define $\rho(f,g):=\int \frac{|f-g|}{1+|f+g|}d\mu.$. Show that $f_{n}\rightarrow f$ in measure $\Longrightarrow$ $\rho(f_{n},f)\rightarrow 0$.","Let $(X,\mathcal{M},\mu)$  be a measurable space, suppose $\mu(X)<\infty$. If $f$ and $g$  measurable functions on $X$, define 
$$\rho(f,g):=\int \frac{|f-g|}{1+|f-g|}d\mu.$$ Let $(f_{n})_{n\in\mathbb{N}}$ be a sequence of measurable function. Show that $\rho(f_{n},f)\rightarrow 0$ iff  $f_{n}\rightarrow f$ in measure. My problem: Show that $f_{n}\rightarrow f$ in measure $\Longrightarrow$ $\rho(f_{n},f)\rightarrow 0$. My attempt: Since $f_{n}\rightarrow f$ in measure, then, in particular, for each $\varepsilon>0$ we have
$$\lim_{n\rightarrow \infty}\mu\left(\left\{x\in X \: \left|\: |f_{n}(x)-f(x)|\geq\frac{\varepsilon}{2\mu(X)}\right.   \right\}\right). $$ Therefore, there exists $N$ such that if $n\geq N$ then
$$\mu\left(\left\{x\in X \: \left|\: |f_{n}(x)-f(x)|\geq\frac{\varepsilon}{2\mu(X)}\right.   \right\}\right)<\frac{\varepsilon}{2}. \tag{1}$$
We called 
$$E_{\varepsilon}^{n}:=\left\{x\in X \: \left|\: |f_{n}(x)-f(x)|\geq \frac{\varepsilon}{2\mu(X)}\right.   \right\}.$$
Then we have
$$\mu(E_{\varepsilon}^{n})<\frac{\varepsilon}{2}. \tag{2}$$
Note that
$$\frac{|f-g|}{1+|f-g|}< \frac{\varepsilon}{2\mu(X)} \qquad \mbox{in }X\setminus E_{\varepsilon}^{n}.  $$ So, as $\frac{|fn-f|}{1+|f_{n}-f|}\leq 1$ we have
$$
\begin{array}{rcl}
\rho(f_{n},f) &=& \int \frac{|f_{n}-f|}{1+|f_{n}-f|}d\mu \\
&=&{\displaystyle \int_{X\setminus E_{\varepsilon}^{n}} \frac{|f_{n}-f|}{1+|f_{n}-f|}d\mu+\int_{E_{\varepsilon}^{n}} \frac{|f_{n}-f|}{1+|f_{n}-f|}d\mu  } \\
&\leq& {\displaystyle  \frac{\varepsilon}{2\mu(X)}\int_{X\setminus E_{\varepsilon}^{n}}d\mu + \int_{ E_{\varepsilon}^{n}} d\mu   } \\
&=& {\displaystyle  \frac{\varepsilon}{2\mu(X)} \mu(X\setminus E_{\varepsilon}^{n}) +\mu( E_{\varepsilon}^{n})   } \\
&\leq& {\displaystyle  \frac{\varepsilon}{2\mu(X)} \mu(X) +\mu( E_{\varepsilon}^{n})   }  \\
&<& {\displaystyle  \frac{\varepsilon}{2}  + \frac{\varepsilon}{2}   }  \\
&=& \varepsilon.
\end{array}  
$$ My Question: Is there any error in my attempt? The doubt is born because in this link (see pag 5) makes an impractical proof and this is the only demonstration I found on the internet.","['convergence-divergence', 'measure-theory', 'proof-verification']"
2287254,Convergence in distribution of conditional expectations,"I was just reading this question , which is about how the classical central limit theorem can be interpreted as giving a rate of convergence for the law of large numbers for iid random variables. I was wondering whether the same idea can be generalized to martingales. For example, let $X$ be integrable on $(\Omega, \mathcal{F}, P)$ and assume $\mathcal{F}_n \uparrow \mathcal{F}$. Then, 
$$E(X \mid \mathcal{F}_n) \to X \ \ \text{a.s.}$$
Is there a sequence $(a_n)_n$ and a non-zero $W$ such that, with $Y_n = E(X \mid \mathcal{F}_n) - X$, we have
$$\frac{Y_n}{a_n} \Rightarrow W?$$ 
(Here, $\Rightarrow$ denotes convergence in distribution.)","['probability-limit-theorems', 'reference-request', 'probability-theory', 'central-limit-theorem', 'martingales']"
2287304,Death probability in time interval,"I have the following question Given the anual death rate $r$ for a group of persons (units of deaths per $1,000$ individuals per year), what is the probability that any given individual will die within the next $x$ months? This is assuming that death is an IID event, and of course, which can only happen once. My problem is that I haven't been able to identify which probability distribution to use, nor which are the parameters given for such distribution. I'd really appreciate your help :)","['statistics', 'probability', 'probability-distributions']"
2287305,Approximating $\int_1^{10}x^x\mathrm dx$ to within 5% relative error,"I am working on a few problems from Arnold's trivium because I hate myself. My first and only idea is to try and approximate this by Riemann sums, but 
this is of course disgusting. For overestimate (right Riemann sum of increasing function) of $3$ points we have
$$
\sum_{n=1}^3 f(1+3n)\frac{1}{3}=\frac{1}{3}(4^4+7^7+10^{10})\approx 10^{9}
$$
Which I had to use a calculator to figure out (sorta defeating the point of the exercise, I guess) has relative error of 8%. Is there a more clever and less painful way to do this than bashing out crummy Riemann or trapezoidal approximations or something of the sort?","['integration', 'definite-integrals', 'calculus', 'approximation']"
2287312,"Counting Problem: How many ways to split 12 marbles between 3 people, with each person having at least one marble?","So the 12 marbles are distinct with each marble being a different color. Therefore I have to take into account, the different colors and different amount each person have. For example, person 1 can have 2 marbles, person 2 can have 7 marbles, and person 3 can have 3 marbles with each marble being a different color. At first, I thought it was: $$\binom{12}{1}\binom{11}{1}\binom{10}{1}$$ but I don't think it covers the case of each person having a different amount of marbles for each case.","['combinatorics', 'discrete-mathematics']"
2287340,Is there an analogue of convexity for geometric mean?,"Jensen's inequality implies that 
$$f(x/2 + y/2) \leq f(x)/2 + f(y)/2$$
for convex $f$, and the inequality reverses if $f$ is concave. Is there a class of functions such that similar inequalities hold for geometric means, that is,
$$f(\sqrt{xy}) \leq \sqrt{f(x)f(y)}$$
or
$$f(\sqrt{xy}) \geq \sqrt{f(x)f(y)}?$$","['algebra-precalculus', 'inequality']"
2287350,Evaluating $\frac{d^{100}}{dx^{100}}\left(\frac{p(x)}{x^3-x}\right)$,"I am given that $\dfrac{d^{100}}{dx^{100}}\left(\dfrac{p(x)}{x^3-x}\right) = \dfrac{f(x)}{g(x)}$ for some polynomials $f(x)$ and $g(x).$ $p(x)$ doesn't have the factor $x^3-x$ and I need to find the least possible degree of $f(x)$ . My Attempt: I am describing in short what I did. Used partial fraction to break up $\dfrac{1}{x^3-x}=\dfrac{A}{x+1}+\dfrac{B}{x}+\dfrac{C}{x-1}$ Now differentiating this $100$ times gave after simplification the denominator $[x(x+1)(x-1)]^{303}$ whle the numerator of Pairwise product of the factors of denominator. That is, $\dfrac{d^{100}}{dx^{100}}\left(\dfrac{p(x)}{x+1}\right) =-A(100)!\left( \dfrac{a_0+a_1 x+\cdots +a_m x^m}{(x+1)^{101}}\right)$ . where degree of $p(x)$ is $m$ . The other two factors also produced a similar result and adding them the final expression had in numerator degree of $101+101+m=202+m$ . Now the least possible degree is achieved if $m=0$ that is $p$ is a constant polynomial. So the answer is $202$ . I felt this solution was ok but I do need advices to make sure how much I would get out of 15. Thanks i Advance!","['algebra-precalculus', 'derivatives']"
2287359,Laurent series for $f (z)=\frac {\sin (2 \pi z)}{z (z^2 + 1)}$,"How Can find the Laurent series for this function valid for $0 <|z-i|<2$ $$f (z)=\frac {\sin (2 \pi z)}{z (z^2 +1)}$$ Let $g (z) = \sin (\pi z)$ $$\sin (\pi z ) = \sin( 2 \pi  (z - i)) \cos (2 \pi i) + \cos (2 \pi  (z-i)) \sin (2 \pi i )$$ And Let $h (z)= \frac {1}{z^2 + 1}$ $$\frac {1}{z (z^2 + 1)}= \frac {1}{i (1 -(-(z-i))}[\frac {1/2i}{z-i} +\frac {-1/2i}{2i (1-(-\frac {z-i}{2i}))}]$$ So it's easy to find expansion for $g (z)$ and $h (z)$ and then multiply the two expansions We notice that $ f $ has simple pole at $z = i$ So, we can get the principal part easily Or using this 
$$2 \pi i a_1 = \int_{|z-i|=1} f (z) dz$$ Is there a trick to find the Laurent series quickly ? This question was in my exam .I Calculated the principal part , but I didn't have enough time to calculate the exact form for the analytic part . Thank you","['laurent-series', 'complex-analysis']"
2287408,The Order of the Identity of a Group,"My lecture notes say that in a group $G$, the identity $e$ is the only element of $G$ which has order $1$. I would like to know why the order of $e$ is said to be $1$, when it could clearly be $0$ since the identity $e$ acted on itself zero times is just $e$. Is it valid to think about an element acting on itself zero times? So for example is it valid to even think about why $e^0 = e$? Cheers.","['group-theory', 'soft-question']"
2287417,Find the limiting value of $S=a^{\sqrt{1}}+a^{\sqrt{2}}+a^{\sqrt{3}}+a^{\sqrt{4}}+...$ for $0 \leq a < 1$,"Question How can I find the sum of the series
$$S=a^{\sqrt{1}}+a^{\sqrt{2} }+a^{\sqrt{3}}+a^{\sqrt{4}}+...$$ under the condition $0 \leq a < 1$ Short version I think the sum of the series should be about $$S=\frac{2} {(\ln a)^2}+c$$
where c is a correction term. So the question is how should I find the value of $c$? Long version My approach so far: The sum can be restated in terms of $y=f(x)$ where
$$y_1=\sum_{n=1}^{\left \lfloor{x}\right \rfloor}a^{\sqrt{n}}$$
so the problem now is to find the limiting value of $y_1$ as $x \rightarrow \infty$. Instead of finding the limit of $y_1(x)$ as defined now, I tried to find another function with a similar growth rate:
$$\frac{\mathrm{d} y_2}{\mathrm{d} x}=a^{\sqrt{x}}$$
$${\textrm{i.e.  }} y_2=\int a^{\sqrt{x}}{\mathrm{d} x} $$
which on solving yields
$$y_2=\frac{2 \sqrt{x} a^{\sqrt{x}}} {\ln a} - \frac{2a^{\sqrt{x}}} {(\ln a)^2}+\frac{2} {(\ln a)^2}$$
where the constant of integration is so chosen to make the curve pass through the origin. Now plotting both these functions on Desmos shows that $y_1$ and $y_2$ resemble each other closely. However $y_2$ has faster initial growth, and therefore it's limiting value is slightly larger than the limiting value of $y_1$ which is what I'm after. The limiting value of $y_2$ is
$$S_2=\lim_{x \rightarrow \infty}{y_2(x)} =\frac{2} {(\ln a)^2}$$
Therefore, I think the actual sum of the original series should be:
$$S=\frac{2} {(\ln a)^2}+c$$
where $c$ is a correction term, possibly depending on $a$. I'm stuck on how to find the correction term $c$ and what it's form should be. Is my approach so far correct? Any help would be appreciated.","['limits', 'calculus', 'integration', 'summation', 'sequences-and-series']"
2287445,Solutions to minimal surface equation by integration,"Recently I'm studying homogenization for PDE, and trying to generalize a result for Dirichlet problem to minimal surface equation. The key point for this paper is to use Green's integral representation, so I'm wondering if  there is some kind of integral representation for minimal surface equation. Or under what special assumptions does this kind of representation exists?
Thank you for your answer.","['partial-differential-equations', 'differential-geometry', 'curvature', 'geometry']"
2287447,Visualising the 5th dimension,"So I recently saw Visualizing the 4th dimension. and thought it was a very good question. But I already know how to see a 4D shape in 3D space. However, I was reading through this Wikipedia page and, being Wikipedia, it was written using language beyond my scope. So could someone please explain how to see a 5D equivalent of a cube?","['visualization', 'geometry']"
2287450,count the number of ways to partition a grid,"In a 10x10 grid, there are 100 cells. A partition in this grid is a contiguous collection of cells meaning any two cells of a partition are connected through a path of cells in the partition itself. In how many ways can 5 partitions be created in this grid? Needless to say this can be generalized. Suggesting simpler variants and their solutions are also helpful. A simple variant is when all partitions must share at least one cell on the boundary. No overlapping is allowed also. The partitions should add up to cover the entire grid. Each partition may have any non-zero number of cells. Suggestion of an algorithm however computationally inefficient so that counting is done by computer would also be good if a mathematical technique is difficult to come by.","['discrete-geometry', 'combinatorics', 'discrete-mathematics']"
2287459,Smooth function on product manifolds,"suppose $M, N$ are smooth manifolds and $f:M\times N\rightarrow \mathbb{ R }$ is a function such that $\forall y\in N$ the function $x\mapsto f (x, y)$ is smooth and $\forall x\in M$ the function $y\mapsto f (x, y)$ is smooth as well. Does this imply that $f$ is smooth jointly in x and y? The map should be differentiable as far as I know. But I can not see if the map is also differentiable of higher orders. I appreciate any help!","['multivariable-calculus', 'manifolds', 'analysis', 'smooth-manifolds']"
2287460,Prove that the product of the digits of the decimal representation of a natural number never exceeds the number itself.,"Here's my proof. Let $x$ be an arbitrary positive integer whose decimal expansion is $a_0 +\cdots+ a_n10^n$. Then, $x=a_0+ \cdots +a_n10^n \geq a_n10^n \geq a_n \cdots a_0$, since each $a_k$ is an  integer in $[0,9]$. This proof looks correct to me, but a popular resource for contest mathematics had a much longer inductive proof of this. I just want verification of my (considerably shorter) proof. Here's the resource: http://www.cheenta.com/2017/05/15/isi-entrance-2017-problem-no-5/ .","['number-theory', 'contest-math', 'decimal-expansion', 'elementary-number-theory']"
2287471,Change of variables in Einstein summation,"This should be trivial, but I am not able to work it out. How is the following equality true? $$ \frac{\partial}{\partial p^2} = \frac{1}{2p^2}p^\mu\frac{\partial}{\partial p^\mu} \,,$$ where $ p^2 = p^\mu p_\mu$. Basically, it involves calculating the partial derivative $$\frac{\partial p^\mu}{\partial p^2} = \Big(\frac{\partial p^2}{\partial p^\mu}\Big)^{-1}=\frac{1}{2}(p^\mu)^{-1} \,,$$ and showing that $$ \boxed{\color{blue}{(p^\mu)^{-1} = \frac{p^\mu}{p^2}}} \,. $$ I am not sure if what I have done above is rigorous at all. NOTE: I am not sure if the argument about multiplying and dividing $(p^\mu)^{-1}$ by a factor of $p^\mu$ works rigorously because there would be an implicit summation in the denominator.","['multivariable-calculus', 'proof-verification']"
2287519,"$ABCD$ is a quadrilateral and $P,Q$ are midpoints of $CD, AB.$...","$ABCD$ is a quadrilateral and $P,Q$ are midpoints of $CD, AB.$ $AP$ and $DQ$ meet at $X, BP$ and $CQ$ meet at $Y.$ Prove that $$|ADX|+|BCY|=|PXQY|$$ (here $|N|$ means area of the shape $N$) I have absolutely no idea how to solve this problem. Any help will be appreciated.","['quadrilateral', 'area', 'geometry']"
2287565,Question about field extension,"Which of the following are true? 1)  Given any positive integer $n$, there exists a field extension of $\mathbb{Q}$ of degree $n$. 2) Given any positive integer $n$, there exist fields $F$ and $K$ such that $F\subseteq K$ and $K$ is Galois over $F$ with $[K:F]=n$. 3) Let $K$ be Galois extension of $\mathbb{Q}$ with $[K:\mathbb{Q}]=4$. Then there is a field $L$ such that $\mathbb{Q} \subseteq L \subseteq K$, $[L:\mathbb{Q}]=2$ and $L$ is a Galois extension of $\mathbb{Q}$. 4) There is an algebraic extension $K$ of $\mathbb{Q}$ such that $[K:\mathbb{Q}]$ is not finite 1) is true, because    $\mathbb{Q} (2^{1/n})$ over $\mathbb{Q}$ is an example. 4) is also true ,as $[\mathbb{Q} (2^{1/2},2^{1/3},2^{1/4},...,) : \mathbb{Q}]$ is not finite. How to approach 2) and 3) ?","['abstract-algebra', 'extension-field', 'field-theory']"
2287584,Universal Donsker classes and bounded variation,"I just read in a paper A Donsker Theorem for Lévy Measures the following statement $BV$-balls are universal Donsker classes (page 7, Examples 3.2 - Compound Poisson Processes) $BV$ stands here for bounded variation.
Unfortunately there is no reference for this result. I was wondering, is this some sort of trivial? Does anyone know a reference?","['stochastic-processes', 'empirical-processes', 'statistics', 'bounded-variation']"
2287596,"If John is the talles in his group, what are the odds he is the tallest of the whole University? [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question There is a University with $r$ groups. Each group has $n$ students, students are randomly distributed within groups. From one of those groups, John is the tallest kid. Which is the expected ranking of John according to height in the whole University? In general, if a kid is ranked the $k-$th tallest kid in his group, in which position will he be in the whole University rank? For example, with two groups and two students, brute force calculations show that if John is the tallest in one group he will be in the 1.66 position in the general ranking. Thanks.","['combinatorics', 'statistics', 'probability']"
2287610,Pointwise Convergence of random variables (Normal divided by n),"I am doing a course in mathetmatical statistics ans the lecturer defined pointwise convergence as follows: Definition : A sequence $(X_{n})_{n \in \mathbb{N}}$ converges point wise to a random variable $X$ if: $lim_{n \rightarrow \infty} X_{n}(\omega) = X(\omega),\forall \omega \in \Omega$ After defning this convergence he gave the following example, which was not so clear to me. Example : Consider a sequence of i.i.d random variables $(X_{n})_{n \in \mathbb{N}}$ where $X_{n} \sim N(0,1)$ and let $Y_{n} = \frac{X_{n}}{n}$. The lecturer argued that $Y_{n}$ does not converge to a limit pointwise since, for example, the sequence $(1,-2,3,-4,...)$ is a legitimate realization of $(X_{n})_{n \in \mathbb{N}}$ and the corresponding realization would be $(1,-1,1,-1,...)$. Now I am confused because of this because I thought that  if $(X_{n})_{n \in \mathbb{N}}$ is iid, it also means  that for any  $\omega \in \Omega$ we have  $X_{n}(\omega) = X_{1}(\omega)$, for all $n \in \mathbb{N}$ , but this apparently not true (otherwise we would have pointwise convergence to $0$). So I guess my question is, can we say something about the random variable $X_{n}$ as a function from the probability space to the reals given that the sequence is iid? Can two random variables can have the same density function but as a function from the probability space to the reals be different functions? What's the connection of the density function to the random variable itself? I hope my questions are clear. Would appreciate any feedback. Thank you!",['probability-theory']
2287626,system set theory,"I got the following problem Let $A_1...A_n$ be n sets. A sequence $x_1...x_n$ is called representative of $A_1 ... A_n$ if $x_i \in A_i$ and $x_i \neq x_j$ Proof the following: A representative sequence exists if and only if the union of $m \in \{1,2,3...n \}$ sets of different $A_i$ has at least $m$ elements Let P be such a union  and $x_n$ be the representative sequence then $\{ x_{k_1},x_{k_2} ...x_{k_m} \} \subset P$ and hence $|P|\ge m$ However, I dont know how to show the other direction. Would appreciate any help","['sequences-and-series', 'elementary-set-theory']"
2287640,How to find the direction vector of a ball falling off an ellipsoid?,"A tiny ball is placed in top of an ellipsoid $3x^2+2y^2+z^2=9$ at $(1,1,2)$. Find the three-dimensional vector $\underline u$ in whose direction the ball will start moving after the ball is released. I feel this problem involves usage of gradients but not sure how to tackle it. EDIT the solution shouldn't use physics knowledge and has to be based on directional derivatives and/or gradients. EDIT 1 I've finally come up with the ""no physics solution"" however it is different from the accepted answer, I'd appreciate if other members confirm if the accepted answer is correct. One potential flaw with the accepted answer is that it's not using the $9$ from the original equation $3x^2+2y^2+z^2+\mathbf{9}=0$. Anyway this is my take: The $xy$ direction in which the ball will fall is $-\nabla f(1,1)$. $f_x=-\frac{3x}{\sqrt{9-3x^2-2y^2}}\stackrel{we.plug.in.x=1}{=}-\frac{3}{2}$. Similarly, $f_y=-1$ therefore $-\nabla f(1,1)=\langle 3/2,1 \rangle$. Let the 3d vector we're after be $d=\langle 3/2, 1, a \rangle$. Notice that $d$ is perpendicular to the normal vector of the tangential plane $n=\langle 6x,4x,-1 \rangle=\langle 6,4,-1 \rangle$ so $d\cdot n=0$ therefore $a=13$ so the final result is $d=\langle \frac{3}{2}, 1,13\rangle$.","['multivariable-calculus', 'partial-derivative', 'vectors']"
2287642,Prove by giving an example that completeness is significant in Banach-Steinhaus theorem.,"I need to give an example of space and family of operators to prove that completeness of space $X$ in Banach-Steinhaus (the uniform boundedness principle) is in fact needed. I guess space $c_{00}$ would be one of proper places to look for the needed operators, but it's my intuition.","['functional-analysis', 'banach-spaces']"
2287656,Distributional result in NIW model,"Suppose $$
\Sigma^{-1} \sim \text{Wishart}_p \left(\frac{\Sigma_0^{-1}}{d_0},d_0\right)
$$ That is $\Sigma$ has a inverse Wishart distribution. Furthermore $$
W \mid \Sigma \sim \operatorname{Wishart}_p(\Sigma, d)
$$ $$
Z \mid \Sigma \sim \mathcal{N}_p(0,\Sigma)
$$ and $W$ and $Z$ are conditionally independent given $\Sigma$. I want to prove (or disprove) that 
$$
\frac{Z^T\Sigma^{-1}Z}{Z^T(W+\Sigma_0d_0)^{-1}Z} \sim \chi^2(d+d_0-p+1).
$$ I can show that the result holds in a few special cases: Special case 1: p=1 When $p=1$ the Wishart distributions reduces to $\chi^2$ distributions:
$$\Sigma^{-1} \sim \frac{1}{d_0\Sigma_0}\chi^2(d_0)$$
$$ W \mid \Sigma \sim \Sigma\chi^2(d) $$
It now follows that $$
\begin{split}
\frac{Z^T\Sigma^{-1}Z}{Z^T(W+\Sigma_0d_0)^{-1}Z} &= 
\frac{W+\Sigma_0d_0}{\Sigma} \\ &= \frac{W}{\Sigma} + \Sigma_0d_0\Sigma^{-1} \\ &\sim \chi^2(d+d_0)
\end{split}
$$ since $\frac{W}{\Sigma}\sim \chi^2(d)$ and is independent of $\Sigma_0d_0\Sigma^{-1} \sim \chi^2(d_0)$ Special case 2: ""$d_0 = 0$"" If $V \sim \operatorname{Wishart}(\Sigma, d)$ then
$$
\frac{1}{(V^{-1})_{ii}} \sim \frac{1}{(\Sigma^{-1})_{ii}}\chi^2(d-p+1)
$$
see Inverse-Wishart . Now for any fixed vector $a$ of length $p$. Take an orthogonal matrix $B=\{b_{(1)},\ldots ,b_{(p-1)},\frac{a}{|a|}\}$. Then $B^TV^{-1}B \sim \text{Wishart}(B^T\Sigma^{-1}B,d)$. We now have
$$
\begin{split}
(B^TVB)^{-1} &= B^{-1}V^{-1}B^{T-1} = B^TV^{-1}B \\
(B^T\Sigma B)^{-1} &= B^T\Sigma^{-1}B \\
(B^T\Sigma^{-1}B)_{pp} &= \frac{1}{|a|^2}a^T\Sigma^{-1}a \\
(B^TV^{-1}B)_{pp} &= \frac{1}{|a|^2}a^TV^{-1}a
\end{split}
$$
Using the above result we have that for any $a$
$$
\frac{Z^T\Sigma^{-1}Z}{Z^TW^{-1}Z} \mid Z = a \sim \chi^2(d-p+1).
$$
Since the conditional distribution does not depend on $a$ it holds unconditionally as well.","['statistics', 'chi-squared', 'probability-distributions']"
2287657,Compact operator on a Hilbert space,"This is a homework problem that I'm having some trouble with, so any hints would be appreciated. Let $H$ be a Hilbert space with an orthonormal basis $\{e_n\}$. Consider the operator $F : H\rightarrow H$ defined by $$Fx = \sum_{n=1}^\infty \beta_n \langle x, e_n\rangle e_n,$$ where $\{\beta_n\}\subset \mathbb C$ Suppose that $F$ is compact. (That is, the image of any bounded sequence contains a convergent subsequence). Show that $\lim_{n\rightarrow\infty} \beta_n = 0$. The obvious approach is to choose a particular bounded sequence and try and get that to give me the result, and the first sequence I tried was obviously $\{e_n\}$. So the image of this sequence is $\{\beta_ne_n\}$, so this implies that there is a subsequence $\{\beta_{n_j}e_{n_j}\}$ which converges. But this doesn't help me and I can't see how else to approach the question.","['functional-analysis', 'compact-operators', 'hilbert-spaces']"
2287660,Understanding a computation of a surface integral on a cube,"Calculate the flow of the vector field $$\mathbf{A} = \nabla \dfrac{\mathbf{a}\cdot\mathbf{r}}{r^3}$$ from a cube with side length $1$, centered at origin and with one space diagonal parallel with the constant vector $\mathbf{a}$. Attempted solution Let the $z$-axis run parallel to $\mathbf{a}$ in a cartesian coordinate system. Introduce spherical coordinates so that $$\mathbf{A} = \nabla \dfrac{\mathbf{a}\cdot\mathbf{r}}{r^3} = \nabla \dfrac{a\cos\theta}{r^2} = \sum_{i} \dfrac{1}{h_i} \dfrac{\partial (\dfrac{a\cos\theta}{r^2})}{\partial u_i} \hat{e}_i = \dfrac{-2a\cos\theta}{r^3}\hat{e}_r - \dfrac{a\sin\theta}{r^3}\hat{e}_{\theta}$$ 
Now what my book does is saying that $\nabla \cdot\mathbf{A}=0$ for $r\neq0$ and that the flow out of the cube is the same as the flow out ofa sphere centered at origin. It then goes to show that $$\iint_{r=R}\mathbf{A}\cdot \hat{e}_r dS = -\dfrac{2a}{R}2\pi \int_{0}^{\pi}\cos\theta\sin\theta d\theta=0$$ I understand every step except for: 1) Why did they calculate the divergence? (If Gauss' theorem is applicable here (which it should be) then that would give the result instantly). 2) How can they claim the flow is the same for the cube as it is for some sphere with radius $R$?","['multivariable-calculus', 'surface-integrals', 'vector-analysis']"
2287664,"If I double my lottery tickets, do I double my chances of winning? [duplicate]","This question already has answers here : Probability of winning the lottery the more you play it? (4 answers) Closed last year . After I buy one lottery ticket with odds of $14M$ to one, if I buy another ticket with different numbers, does this slash the odds to $7M$ to one? If so, if I double my tickets again to $4$ Tickets, it will halve again to $3.5M$ to one? So $8$ tickets will be $1.75M$ to one? $16$ Tickets $\rightarrow.875M$ to one $32 \rightarrow .4475$ M to one $64 \rightarrow 218750$ to one $128 \rightarrow 109375$ to one $256 \rightarrow 54587$ to one Something seems wrong here?","['lotteries', 'probability']"
2287674,Does the reverse of Picard's great theorem hold?,"The Picard's great theorem says: Asume that $f$ is holomorph in a punctured neighborhood $\Omega$ of $c\in\mathbb C$. Furthermore assume that $f$ has a essential singularity at $c$, then for any neighborhood $U\subseteq\Omega$ of $c$ $\mathbb C\setminus f(U)$ has atmost one element. Does it hold if we reverse the second part? That is: Asume that $f$ is holomorph in a punctured neighborhood $\Omega$ of $c\in\mathbb C$. Furthermore assume that for every neighborhood $U\subseteq\Omega$ of $c$ $\mathbb C\setminus f(U)$ has at most one element, then $f$ has a essential singularity at $c$. If yes: how do I prove it? If no: is there a counter example?","['complex-analysis', 'singularity']"
2287675,"Evaluate $\lim_{n\to \infty}\{(1+\frac{2}{n})^n,(\sqrt{\frac{n+1}{4n-1}})\}$","$$\lim_{n\to \infty}\left\{\left(1+\frac{2}{n}\right)^n,\;\sqrt{\frac{n+1}{4n-1}}\right\}$$ $$\lim_{n\to \infty}\left(1+\frac{2}{n}\right)^n=\lim_{n\to \infty}\left(1+\frac{2}{n}\right)^{\frac{n}{2}\cdot 2}$$ $m=\frac{n}{2}$ $$\lim_{n\to \infty}(1+\frac{2}{n})^{\frac{n}{2}\cdot 2}=\lim_{n\to \infty}(1+\frac{1}{m})^{m\cdot 2}=\lim_{n\to \infty}(1+\frac{1}{m})^{{m}^{2}}=e^2$$ $$\lim_{n\to \infty}\sqrt{\frac{n+1}{4n-1}}=\lim_{n\to \infty}\sqrt{\frac{\frac{n}{n}+\frac{1}{n}}{\frac{4n}{n}-\frac{1}{n}}}$$ Because square root is a continuos function $$\sqrt {lim_{n\to \infty}{\frac{\frac{n}{n}+\frac{1}{n}}{\frac{4n}{n}-\frac{1}{n}}}}=\sqrt {{\frac{1+0}{4-0}}}=\sqrt{\frac{1}{4}}=\frac{1}{2}$$ So $$\lim_{n\to \infty}\{(1+\frac{2}{n})^n,(\sqrt{\frac{n+1}{4n-1}})\}=(e^{2},\frac{1}{2})$$ Are all the moves correct?",['multivariable-calculus']
2287686,how many ways of arranging given 7 two digit positive integers so that the sum of every four consecutive integer is divisible by 3?,"in how many ways can I arrange the numbers: 21,31,41,51,61,71,81 such that the sum of every four consecutive numbers is divisible by three? Though I am not an expert on modulo math, I do know that if we were to take MOD 3 on all of the numbers in the list, I would get the following in respective order: $0_{21}, 1_{31}, 2_{41}, 0_{51}, 1_{61}, 2_{71}, 0_{81}$ (the subscript correlates to what original number it represents) and clearly if we were to match the values so that the sum is a multiple of three, the numbers added up would also be a multiple of three. But upon realizing that the numbers must be consecutive and that if taking any four consecutive numbers in a set of 7 terms, I got stuck here and do not know how to proceed.","['combinatorics', 'contest-math', 'modular-arithmetic']"
2287713,How to plot the Julia Set of $z-z^2$,"Since I do not have any real knowledge of using matlab or maple, I do not really know how to get a nice printable version of the Julia set of $z-z^2$. The only things I find when I try to google julia set creator, are tools to plot the Mandelbrot set for various values $c$. I already tried wolframalpha, too ( https://www.wolframalpha.com/input/?i=julia+set+z-z%5E2 ), which gives only small picture. Furthermore, I do not know if only the boundary of this set is the julia set? I hope someone knows a good way to plot the Julia set of this function and can clear up my confusion. Thanks","['complex-analysis', 'complex-dynamics', 'graphing-functions']"
2287742,Combinatorics problem with repetitions,"I have been doing combinatorics problems and I have encountered a question that I can't really find an answer for. There are 2 sets - set of odd numbers {1;3;5;7;9} and set of even numbers {0;2;4;6;8}. The question is 'how many 4 digit numbers can you make out of 3 odd numbers and 1 even number (numbers can repeat)?'. If there were only a set of even numbers and numbers couldn't repeat, then I would use multiplication of variations in each position in the number (omitting 0 in 1st position), but that doesn't seem to work in this case as the number of possible elements in each position changes depending on the order of even & odd numbers. Also, how does one find out exact number of 4 digit numbers that begin with 0 so that I could exclude them from all possible results?",['combinatorics']
2287792,Reference request: Large deviations for a conditional probability,"Suppose a sequence of probability measures $(\mathbb P_n)_{n\in\mathbb N}$ on a Polish space $X$ satisfies the large deviations principle with a good rate function $I$ and rate $n$. Informally speaking (I'm very imprecise here!), this means that for a Borel set $A\subset X$, we have $$\mathbb P_n(A)\approx \exp\big(-n\inf_{x\in A} I(x)\big),
$$
and for two sets $B\subset A\subset X$, we have 
$$\frac{\mathbb P_n(B)}{\mathbb P_n(A)}\approx \exp\big(-n\,(\inf_{x\in B} I(x)-\inf_{x\in A} I(x))\big).
$$
The last equality looks very much like a new large deviations principle for measures conditioned on $A$. That is, the new Polish space is $A$, the new sequence of probability measures consists of $\mathbb Q_n(\cdot ):=\frac{\mathbb P_n(\cdot)}{\mathbb P_n(A)}$, and the new rate function is $$I_A(y):=I(y)-\inf_{x\in A} I(x).
$$ I'm pretty sure that one can make this construction rigorous, for example when $A$ is an $I$-continuous set. However, I'm also pretty sure that I am not the first to make this observation. My question is: has anybody seen a statement of this kind before? Does it have a name? Where can I read more about it?","['reference-request', 'probability-theory', 'probability', 'large-deviation-theory']"
2287798,A convex function over a Martingale is a Submartingale --- Proof,"$\left\{ Z_{n},n\geq1\right\} $ is a martingale, which means that $\forall n$,
it satisfies the below two conditions, 1) This is the uniformly bounded condition.
$$
E\left[\left|Z_{n}\right|\right]<\infty
$$ 2) Standard martingalge condition.
$$
E\left[\left.Z_{n+1}\right|Z_{1},\ldots,Z_{n}\right]=Z_{n}
$$ $f$ is a convex function, then the proof that,
$\left\{f\left(Z_{n}\right),n\geq1\right\} $ is a submartingale goes as below.
This is from the book Stochastic Processes, Second Edition, Sheldon Ross, Lemma 6.4.3, page 314. \begin{eqnarray*}
E\left[\left.f\left(Z_{n+1}\right)\right|Z_{1},\ldots,Z_{n}\right] & \geq & f\left(E\left[\left.Z_{n+1}\right|Z_{1},\ldots,Z_{n}\right]\right)\\
 & = & f\left(Z_{n}\right)
\end{eqnarray*} Question: How do we know that, $f\left(Z_{n}\right)$, is uniformly bounded for it to be a submartingale? That is, what extra assumption do we need to make or is there another result that gives the below? Please give full details and steps.
$$
E\left[\left| f\left(Z_{n}\right)\right|\right]<\infty
$$ If I am overlooking something basic, please point out.","['stochastic-processes', 'probability-theory', 'martingales']"
2287801,"Given $f(x,y,z)=xy^2z$ find the the max value such that the point $(x,y,z)$ is located in the part of the plane $x+y+z=4$","Given $f(x,y,z)=xy^2z$ find the the max value such that the point $(x,y,z)$ is located in the part of the plane $x+y+z=4$ which is in the first octant ($x>0, y>0, z>0$) of the coordinates. I think Lagrange multipliers can be used here. We can say that $x+y+z=4$ is the restriction. Let $g=x+y+z-4$. Then:
$$
\nabla f= \lambda\nabla g\\
\nabla f=\langle y^2z,2yxz,xy^2 \rangle\\
\nabla g=\langle 1,1,1 \rangle
$$
It follows that:
$$
\begin{cases}
y^2z=\lambda\\
2yxz=\lambda\\
xy^2=\lambda
\end{cases}
$$
Because $x>0, y>0, z>0$ we can solve the system and get:
$$
z=x,\quad y=2x
$$
Finally, we can rewrite the restriction as:
$$
x+2x+x=4 \Rightarrow x=1, y=2, z=1
$$ Is my usage of Lagrange method correct? Can this problem also be solved without Lagrange method by finding the max value using min/max theorems for functions with 2 variables?","['optimization', 'gradient-descent', 'multivariable-calculus', 'maxima-minima', 'lagrange-multiplier']"
2287838,Why are pointwise measurable functions not measurable?,"Let $(X,\mathcal{X})$, $(Y,\mathcal{Y})$ and $(Z,\mathcal{Z})$ be measurable spaces. Let $(X \times Y, \mathcal{X} \otimes \mathcal{Y})$ be the product of the two spaces, where $\mathcal{X} \otimes \mathcal{Y} := \sigma(\mathcal{X} \times \mathcal{Y})$. Let $f:X \times Y \to Z$ be a pointwise measurable function (my own term) in the sense that $\forall x \in X: f(x, \cdot):Y \to Z$ is measurable $\forall y \in Y: f(\cdot, y):X \to Z$ is measurable Sufficient conditions for separately measurable functions being jointly measurable. claims that $f:X \times Y \to Z$ is not necessarily measurable. Why? Is there a simple counter-example?","['measurable-functions', 'measure-theory']"
2287863,Does $e^{X} e^{Y} = e^{X + Y}$ imply that the operators $X$ and $Y$ commute?,"I am considering two self-adjoint, but unbounded operators $X$ and $Y$ on a Hilbert space. By the Baker-Campbell-Hausdorff formula, we know that
$$ [X, Y] = 0 \Rightarrow e^{X} e^{Y} = e^{X + Y}.$$
But is the converse also true? If I have the property $e^{X} e^{Y} = e^{X + Y}$, can I somehow prove that the operators must commute?","['functional-analysis', 'unbounded-operators']"
2287895,Are derivatives of the standard Gaussian density bounded?,"Suppose that $\varphi$ is the density of the standard Gaussian distribution given by
$$
\varphi(x)=\frac1{\sqrt{2\pi}}\exp(-x^2/2)
$$
for each $x\in\mathbb R$. The derivatives of $\varphi$ are given by the formula
$$
\varphi^{(n)}(x)=(-1)^n\mathit{He}_n(x)\varphi(x)
$$
for each $x\in\mathbb R$ and $n\ge0$, where $\mathit{He}_n$ is the $n$-th probabilists' Hermite polynomial . It is straightforward to see that $\varphi$ and its first two derivatives are bounded. We have that
\begin{align*}
|\phi(x)|&\le (2\pi)^{-1/2}\approx0.399\\
|\varphi'(x)|&\le\varphi(1)\approx0.242\\
|\varphi''(x)|&\le (2\pi)^{-1/2}\approx0.399
\end{align*}
for each $x\in\mathbb R$. Does there exist $c>0$ such that $|\varphi^{(n)}(x)|\le c$ for each $x\in\mathbb R$ and $n\ge0$? If not, are all derivatives of $\varphi$ bounded, i.e. does there exist a positive sequence $c_n$ such that $|\varphi^{(n)}(x)|\le c_n$ for each $x\in\mathbb R$ and $n\ge0$? Any help is much appreciated!","['derivatives', 'real-analysis', 'normal-distribution', 'probability-theory', 'hermite-polynomials']"
2287899,"Multivariable proof of $lim_{(x,y)\to(a,b)} \frac{sin(f(x,y))}{f(x,y)}=1$","I know the typical result when it's the limit in one variable, but I can't find a multivariable epsilon-delta proof to the following problem: Let $f:B_r(a,b) \rightarrow \Bbb R$ such that $f$ is defined over $B_r(a,b)-\{(a,b)\}$ and $lim_{(x,y)\to(a,b)} f(x,y) = 0$. Prove that
  $$lim_{(x,y)\to(a,b)} \frac{sin(f(x,y))}{f(x,y)}=1$$ $B_r(a,b)$ is the ball with radius $r$ and center $(a,b)$ I basically don't know how to take the known limit to an extra dimension. Where should I start? Also if you know of a book where I can find the proof or another website where it's explained it'll be helpful. Thanks a lot.","['trigonometry', 'multivariable-calculus', 'epsilon-delta', 'proof-writing', 'proof-explanation']"
2287907,Modeling random variation from partial information,"I am working on an optimization problem. Let's say we have a grid of bins where solid metal cubes could be placed. We have a number of colored metal cubes to be arranged in the bins. Each of these cubes weighs 1kg . But the weight could change slightly over time due to natural phenomena and becomes 1kg + delta(x,y) . We are interested in making sure the ratio between the total weight of one color to another remains same over time. Observations say that delta(x,y) is not completely random. It can be thought of as k0 + k1*x + k2*y + k3*x^2 + k4*y^2 + k5*x*y where the constants k0 k1 k2 ... are unknown at the time of arranging the cubes. But in all cases k0 > k1 > k3 > k5 and k0 > k2 > k4 > k5 We can assume k0/k1 as c1 , k1/k3 as c2 ... and cn > 1 for all n. k1 and k2 are unrelated. This observation lets us cancel out certain terms in delta(x, y) by arranging carefully. For example, if we arrange two red balls and two blue balls as R B B R , we can expect the linear terms to cancel. Take for example a grid of 3x3 . Initially, we have the empty grid: [ ]  [ ]  [ ]
[ ]  [ ]  [ ]
[ ]  [ ]  [ ] and a number of metal cubes to be placed. As an example, let's say we are to arrange one red cube , two blue cubes , four green cubes and two dummy cubes. Metal cubes to be placed: 1 x R
2 x B
4 x G
2 x * One possible arrangement could be: B * G
G R G
G * B Given a set of values for c1, c2 etc, there is one arrangement that must be the best. I am trying to model a cost function which indicates the expected variation between the two colors. Then choose the arrangement that has minimum cost by iterating through all possible arrangement. I am looking for some advice on how to model the expected variation between two colors. Also, any advice on reducing the search space.","['optimization', 'random-variables', 'discrete-mathematics']"
2287921,Find the general solution of recurrence relation of order four,"Find the general solution of the recurrence relation. $a_n = 4a_{n - 1} - 5a_{n - 2} + 4a_{n - 3} - 4a_{n - 4}$ I've found the roots, but I don't really understand how does general solution look like. $$r^n = 4r^{n - 1} - 5r^{n - 2} + 4r^{n - 3} - 4r^{n - 4} \iff r^4 - 4r^3 + 5r^2 - 4r + 4 = 0 \iff (r - 2)^2(r^2 + 1) = 0$$ $$\begin{cases}
r = 2\\
r = i\\
r = -i
\end{cases}$$ So far, I've only studied how to solve linear recurrences of second order(homogeneous/non-homogeneous) and I know there are three cases that depend whether the root is complex or not. If we have two complex roots the solution has the following form: $$a_n = c_1p^n\cos(nv) + c_2p^n(\sin nv)$$ ($v$ is an argument of $r_1, r_2$, $p$ also comes from exponentiation form of $r_1$, $r_2$) Two real roots: $$a_n = c_1 r_1^n + c_2 r_2^n$$ Finally, in case of one real root: $$a_n = c_1 r^n + c_2 n r^n$$ Here, from one side I have two complex roots, from the other there is real root with multiplicity 2. And that's why I don't understand the form of general solution. Is it possible to generalize the form of solution for recurrence relation of second order on other orders?","['recurrence-relations', 'discrete-mathematics']"
2287960,Cohomology of $SL_2(\mathbb Z)$ acting on rational functions,"Let $\Gamma = SL_2(\mathbb Z)$ acts on the abelian group $\mathbb C(z)^\times$ (the multiplicative group of the field of rational function in one variable $z$ over $\mathbb C$) by $\gamma \cdot f = f\left( \frac{az+b}{cz+d}\right)$ if $\gamma=\left(\begin{matrix} a&b \\ c &d \end{matrix}\right)$. (This is a right action, but you can make it left if you prefer by letting $\gamma$ act through $\gamma^{-1}$). Can we compute the cohomology group $H^1(\Gamma,\mathbb C(z)^\times)$? The only 1-cocycle I know is $\gamma \mapsto cz+d$ and its powers. But what else is it in that group? Same question if $\mathbb C(z)$ is replaced by the multiplicative group of non-vanishing holomorphic functions on the Poincaré Upper Half plane...","['number-theory', 'group-cohomology', 'group-theory']"
2288002,"Probability of rolling a 1 before you roll two 2's, three 3's, etc","This is a question my father-in-law asked. I found it interesting but haven't been able to answer it. Suppose you have an $N$ sided die. You conduct an experiment as follows: roll the die until the first time you have rolled one 1, two 2's, three 3's etc. For example, you roll 2,3,4,3,6,5,3 the experiment ends because you have rolled three 3's. Of course, the most times you can roll the die is $1+\sum_{k=1}^{N-1}k = 1 + \frac{(N-1)N}{2}$. This is because the maximum number of rolls you can do is to roll one 2, two 3's, three 4's and so on, and then one more roll to complete the experiment. In particular, the experiment always ends in a finite number of rolls. Observe that the experiment ends when you roll a $1$. If you have a one-sided die the experiment always ends after the first roll and so you end on $1$ with probability 1. If you have a two sided die (i.e. a coin) then the probability of rolling a $1$ on the first roll is $1/2$; the probability of rolling a 2 first and a 1 second is $1/4$ and so the probability of ending the experiment on a $1$ is $3/4$. Let $P_N$ be the probability that you end the experiment on a $1$. What is $\lim_{N\to\infty}P_N$? $P_N$ is decreasing and of course $0\leq P_N$ so the limit exists. I tried taking the limit along ``easy'' sequences like $2^N$ hoping the the extra structure would lend itself to easier analysis, but I couldn't. I imagine I am not the first to ask this question, but I couldn't find it on MSE any other place. Any references to similar questions are also appreciated.","['combinatorics', 'probability']"
2288008,Contour integration of $\frac{\log( x)}{x^2+a^2}$ [duplicate],"This question already has answers here : Evaluate $\int_0^{\infty} \frac{\log(x)dx}{x^2+a^2}$ using contour integration (5 answers) Closed 7 years ago . How do I intgrate $\int_0^{\infty}\frac{\log( x)}{x^2+a^2} \,dx$ using contour integration? Simple integration is easy but I can't understand contour integration. Please help!","['logarithms', 'complex-integration', 'complex-analysis', 'integration', 'contour-integration']"
2288019,A series for $\frac{355}{113}-\pi$,"Series for sums $\pi+\dfrac{p_n}{q_n}$ Lehmer's interesting series relating $\pi$ to its early convergents $3$, $\dfrac{22}{7}$ and $\dfrac{355}{113}$ may be written as follows. $$\begin{align}
\sum_{n=1}^\infty \dfrac{n2^n}{\dbinom{2 n}{n}}&=\pi+3\tag{A.1}\\
\dfrac{2}{7}\sum_{n=1}^\infty \dfrac{n^22^n}{\dbinom{2 n}{n}}&=\pi+\dfrac{22}{7}\tag{A.2}\\
\dfrac{2}{35}\sum_{n=1}^\infty \dfrac{n^32^n}{\dbinom{2 n}{n}}&=\pi+\dfrac{22}{7}\tag{A.3}\\
\dfrac{1}{113}\sum_{n=1}^\infty \dfrac{n^42^n}{\dbinom{2 n}{n}}&=\pi+\frac{355}{113}\tag{A.4}\\
\end{align}$$ Series for differences $\pi-\dfrac{p_n}{q_n}$ or $\dfrac{p_n}{q_n}-\pi$ Series that prove the sign of the error when approximating $\pi$ by its convergents include: $$\begin{align}
\pi-3&=4·24\sum_{k=0}^\infty \frac{(4k+1)!}{(4k+6)!}(k+1)\tag{B.1}\\
\frac{22}{7}-\pi&=4^2·240\sum_{k=0}^\infty \frac{(4k+3)!}{(4k+11)!}(k+1)(k+2)\tag{B.2}\\
\frac{22}{7}-\pi&=4^3·285120\sum_{k=0}^\infty \frac{(4k+1)!}{(4k+14)!}(k+1)(k+2)(k+3)\tag{B.3}\\
\end{align}$$ A series to prove $\frac{22}{7}-\pi>0$ Series and integrals for inequalities and approximations to $\pi$ Changing the initial value for summations leads to results as in A.1, A.2 and A.3. $$\begin{align}
\pi+3&=4·24\sum_{k=-1}^\infty \frac{(4k+1)!}{(4k+6)!}(k+1)\tag{C.1}\\
\frac{22}{7}+\pi&=-4^2·240\sum_{k=-3}^\infty \frac{(4k+3)!}{(4k+11)!}(k+1)(k+2)\tag{C.2}\\
\frac{22}{7}+\pi&=-4^3·285120\sum_{k=-3}^\infty \frac{(4k+1)!}{(4k+14)!}(k+1)(k+2)(k+3)\tag{C.3}\\
\end{align}$$ Let us assume there is a series for the fourth convergent $$\sum_{k=0}^\infty \frac{q}{\Pi_{i}(4k+d_i)}=\frac{355}{113}-\pi\tag{B.4}$$ for some positive rational $q$ and positive integers $d_i$. Question: Is there a technique to obtain the difference series (B.1, B.2, B.3) from their sum counterparts (A.1, A.2, A.3) that allows to determine B.4 from A.4?","['diophantine-approximation', 'pi', 'sequences-and-series', 'approximation']"
2288025,"Prob. 18, Chap. 5, in Baby Rudin: Another Form of Taylor's Theorem","Here is Prob. 18, Chap. 5, in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: Suppose $f$ is a real function on $[a, b]$ , $n$ is a positive integer, and $f^{(n-1)}$ exists for every $t \in [a, b]$ . Let $\alpha$ , $\beta$ , and $P$ be as in Taylor's theorem (5.15). Define $$ Q(t) = \frac{ f(t) - f(\beta) }{ t- \beta} $$ for $t \in [a, b]$ , $t \neq \beta$ , differentiate $$ f(t) - f(\beta) = (t-\beta) Q(t) $$ $n-1$ times at $t = \alpha$ , and derive the following version of Taylor's theorem: $$ f(\beta) = P(\beta) + \frac{Q^{(n-1)}(\alpha)}{(n-1)!} (\beta - \alpha)^n. $$ And, here is Theorem 5.15 in Baby Rudin, 3rd edition: Suppose $f$ is a real function on $[a, b]$ , $n$ is a positive integer, $f^{(n-1)}$ is continuous on $[a, b]$ , and $f^{(n)}(t)$ exists for every $t \in (a, b)$ . Let $\alpha$ , $\beta$ be distinct points of $[a, b]$ , and define $$ P(t) = \sum_{k=0}^{n-1} \frac{f^{(k)}(\alpha)}{k!} \left( t-\alpha \right)^k.$$ Then there exists a point $x$ between $\alpha$ and $\beta$ such that $$ f(\beta) = P(\beta) + \frac{f^{(n)}(x)}{n!} (\beta - \alpha )^n.$$ An Attempt: For all $t \in [a, b]$ , we have $$
\begin{align}
f(t) - f(\beta) &= ( t-\beta) Q(t),  \tag{1} \\
f^\prime(t) &= Q(t) + (t-\beta) Q^\prime(t), \tag{2} \\
f^{\prime\prime}(t) &= 2Q^\prime(t) + (t-\beta) Q^{\prime\prime}(t),  \tag{3} \\
f^{(3)}(t) &= 3 Q^{\prime\prime}(t) + (t-\beta)Q^{(3)}(t), \tag{4} \\
f^{(4)}(t) &= 4 Q^{(3)}(t) + (t-\beta) Q^{(4)}(t), \tag{5} \\ 
\cdots &= \cdots \\
f^{(n-1)}(t) &= (n-1) Q^{(n-2)}(t) + (t-\beta) Q^{(n-1)}(t). \tag{*} 
\end{align}
$$ So, for $t = \alpha$ , the above chain of equations yields $$ 
\begin{align}
& \qquad f(\beta) \\
&= f(\alpha) + Q(\alpha)  (\beta - \alpha )  \qquad \mbox{ [ using (1) ] } \\
&= f(\alpha) +  \left[ f^\prime(\alpha) + (\beta - \alpha) Q^\prime(\alpha) \right] (\beta - \alpha ) \\ 
& \qquad \qquad \mbox{ [ using (2) ] } \\
&= f(\alpha) + f^\prime(\alpha) (\beta - \alpha) +  Q^\prime(\alpha) (\beta - \alpha)^2  \\
&= f(\alpha) +  f^\prime(\alpha) (\beta - \alpha) \\ 
& \qquad +  \left[  \frac{1}{2} \left( f^{\prime\prime}(\alpha) + (\beta - \alpha) Q^{\prime\prime}(\alpha) \right) \right] (\beta - \alpha)^2 \\ 
& \qquad \qquad \mbox{ [ using (3) ] } \\
&= f(\alpha) +  \frac{f^\prime(\alpha)}{1!} (\beta - \alpha) + \frac{f^{\prime\prime}(\alpha)}{2!} (\beta - \alpha)^2 + \frac{Q^{\prime\prime}(\alpha)}{2!} (\beta - \alpha)^3 \\ 
&=  f(\alpha) +  f^\prime(\alpha) (\beta - \alpha) + \frac{f^{\prime\prime}(\alpha)}{2} (\beta - \alpha)^2 + \frac{\frac{1}{3} \left( f^{(3)}(\alpha) + (\beta - \alpha) Q^{(3)}(\alpha) \right) }{2} (\beta - \alpha)^3 \qquad \mbox{ [ using (4) ] } \\ 
&=  f(\alpha) +  \frac{f^\prime(\alpha)}{1!} (\beta - \alpha) + \frac{f^{\prime\prime}(\alpha)}{2!} (\beta - \alpha)^2 + \frac{f^{(3)}(\alpha)}{3!}(\beta-\alpha)^3 + \frac{Q^{(3)}(\alpha)}{3!} (\beta-\alpha)^4 \\ 
&=  f(\alpha) +  \frac{f^\prime(\alpha)}{1!} (\beta - \alpha) + \frac{f^{\prime\prime}(\alpha)}{2!} (\beta - \alpha)^2 + \frac{f^{(3)}(\alpha)}{3!}(\beta-\alpha)^3 + \frac{ \frac{1}{4} \left( f^{(4)}(\alpha) + (\beta - \alpha) Q^{(4)}(\alpha) \right)  }{3!}  (\beta-\alpha)^4 \\ 
& \qquad \qquad \mbox{ [ using (5) ] } \\
&= f(\alpha) +  \frac{f^\prime(\alpha)}{1!} (\beta - \alpha) + \frac{f^{\prime\prime}(\alpha)}{2!} (\beta - \alpha)^2 + \frac{f^{(3)}(\alpha)}{3!}(\beta-\alpha)^3 + \frac{f^{(4)}(\alpha)}{4!} (\beta - \alpha)^4 + \frac{Q^{(4)}(\alpha)}{4!} (\beta-\alpha)^5 \\
&= \cdots \\
&= f(\alpha) +  \frac{f^\prime(\alpha)}{1!} (\beta - \alpha) + \frac{f^{\prime\prime}(\alpha)}{2!} (\beta - \alpha)^2 \\ 
& \qquad + \frac{f^{(3)}(\alpha)}{3!}(\beta-\alpha)^3 + \frac{f^{(4)}(\alpha)}{4!} (\beta - \alpha)^4 + \cdots + \frac{f^{(n-1)}(\alpha)}{(n-1)!} (\beta-\alpha)^{n-1} + \frac{Q^{(n-1)}(\alpha)}{(n-1)!} (\beta - \alpha)^n \\
&= P(\beta) +  \frac{Q^{(n-1)}(\alpha)}{(n-1)!} (\beta - \alpha)^n, 
\end{align}
$$ as required. Is this proof correct? If so, then is it rigorous enough for Rudin as well?","['derivatives', 'real-analysis', 'taylor-expansion', 'calculus', 'analysis']"
2288040,limit of $ \lim_{x \rightarrow 1} \frac{ f_{n} (x)- f_{n-1} (x)}{ (1-x)^{n} }=? $,"Let $$ f_{n} (x)= x^{ x^{\scriptstyle\cdot^{\scriptstyle\cdot^{\scriptstyle\cdot^{\scriptstyle x}}}}}$$ Then $$
\lim_{x \rightarrow 1}  \frac{ f_{n} (x)- f_{n-1} (x)}{ (1-x)^{n} }={?}
$$ My try: \begin{align}
\lim_{x \rightarrow 1} \frac{f_n-f_{n-1}}{(1-x)^{n}}
&=\lim_{x \rightarrow 1}{ \frac{ e^{\ln f_{n} (x) } - e^{\ln f_{n-1} (x) } }{(1-x)^{n}} } \\[6px]
&=\lim_{x \rightarrow 1}{ \frac{ e^{f_{n-1} (x)\ln x } - e^{f_{n-2} (x)\ln x } }{(1-x)^{n}} } \\[6px]
&=\lim_{x \rightarrow 1} \frac{\ln x(f_{n-1} (x)-f_{n-2} (x))}{ (1-x)^{n} }
\end{align} Now?",['limits']
2288045,"Disprove the existence of $\lim_{(x,y,z) \to (0,0,0)} \frac{x+y+z}{x^2y^2z^2}$","I need to prove that the following limit does not exist in $\mathbb{R^3}$, but I cannot seem to find the solution to this problem. 
The limit is as follows: \begin{equation} 
\lim_{(x,y,z) \to (0,0,0)} \frac{x+y+z}{x^2y^2z^2}
\end{equation} Help is greatly appreciated!","['multivariable-calculus', 'real-analysis', 'limits']"
2288048,Why $U''(ξ) + 1/2\xi U' (\xi) + 1/2 U (\xi) = 0$ is invariant under $\xi = -\xi?$,Why $U''(ξ) + \frac{1}{2}\xi U' (\xi) + \frac{1}{2} U (\xi) = 0$ is invariant wrt to change of variables $\xi = -\xi?$ I think there is no additional information about $U.$,['ordinary-differential-equations']
2288067,Inverse of a symmetric positive definite matrix,"If a matrix is symmetric and positive definite, determine if it is invertible and if its inverse matrix is symmetric and positive definite. I know that ""if a matrix is symmetric and positive definite, then its inverse matrix is also positive definite"", based on a theorem. But I am not sure how to prove that the matrix even is invertible or that its inverse matrix is also symmetric. It would really help if someone explained this a bit. Thanks","['matrices', 'symmetric-matrices', 'positive-definite', 'linear-algebra']"
2288082,"Finding $\det(I+A^{100})$ where $A\in M_3(R)$ and eigenvalues of $A$ are $\{-1,0,1\}$","I have a matrix $A \in M_3(R)$ and it is known that $\sigma (A)=\{-1, 0, 1\}$, where $\sigma (A)$ is a set of eigenvalues of matrix $A$. I am now supposed to calculate $\det(I + A^{100})$. I know that $A^{100}$ could be calculated using a diagonal matrix which has the eigenvalues of $A$ on it's diagonal and using matrices which are formed using the eigenvectors of $A$, but I am not sure how to get there. Or it might not even be the right approach. I know there is a similar question, but I don't really understand the answer given there. It's not fully explained. So if anyone could help, that would be great. Thanks","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra', 'determinant']"
2288119,Evaluating the indefinite integral $\int \frac {x^7-1}{\log x}dx$ [duplicate],"This question already has answers here : What is $\int_0^1\frac{x^7-1}{\log(x)}\mathrm dx$? (7 answers) Closed 7 years ago . The integral to be evaluated is  $$\int \frac {x^7-1}{\log x}dx$$ The actual question was to find the definite integral of the above in the limits $0$ to $1$. I could not apply any of the usual tricks to find that integral, hence I thought finding the indefinite integral first and then applying the limits would be the best way to evaluate the same. I tried applying trigonometric substitution, which did'nt work. I also tried putting $x=e^t$, hoping to simplify the integral but that did not give me any results either. How should I proceed to evaluate this integral?","['indefinite-integrals', 'integration', 'calculus']"
2288154,Arrange 15 animals in 15 cages,"Five tigers, five lions and five cheetahs are going to be hosted in $15$ consecutive cages in the zoo. Due to some restrictions in the zoo regulations, we cannot put the tigers in the $5$ leftmost cages, the lions in the $5$ middle cages and the cheetahs in the $5$ rightmost cages. Can you calculate all possible arrangements? If all animals were the same, there would be $15!$ different ways. Now that we have $5$ of every kind, if there were no restrictions from the zoo regulations, we would have $\frac{15!}{5!5!5!}$. I don't know though how to apply the restrictions :(",['combinatorics']
2288169,Complex analysis (theorem related to properties of Cauchy product of complex series) - request for proof-explanation,"Theorem : Let: $\sum\limits_{n=1}^{+\infty}a_{n}$,  $\sum\limits_{n=1}^{+\infty}b_{n}$ - conditionally convergent complex series,   $\sum\limits_{n=1}^{+\infty}c_{n}$ - Cauchy product of $\sum a_n$, $\sum b_n$ such that $\sum c_n$ converges. Then: $\sum\limits_{n=1}^{+\infty}c_{n} = (\sum\limits_{n=1}^{+\infty}a_{n})(\sum\limits_{n=1}^{+\infty}b_{n})$ Proof : Let: $A_n$,$B_n$,$C_n$ - partial sums of $\sum a_n$, $\sum b_n$, $\sum c_n$ respectively, $A_n \to A$, $B_n \to B$,  $C_n \to C$. Define: $\alpha_{n}:=A_n-A$, $\beta_n:=B_n-B$, $p_n:=\frac{\sum\limits_{i=0}^{n}\alpha_i}{n}$,  $q_n:=\frac{\sum\limits_{i=0}^{n}\beta_i}{n}$ Algebraic manipulations imply: $\frac{\sum\limits_{i=0}^{n-1}C_i}{n}=AB+Aq_n+Bp_n+r_n$ (*) , where: $r_n:=\frac{\sum\limits_{i=0}^{n-1}\alpha_i\beta_{n-i}}{n}$ But: $\lim\limits_{n\to +\infty}(\alpha_n) = 0 \space \wedge \lim\limits_{n\to +\infty}(\beta_n) = 0 \implies \lim\limits_{n\to +\infty}(p_n) = 0 \space \wedge \lim\limits_{n\to +\infty}(q_n) = 0 \space \wedge \lim\limits_{n\to +\infty}(r_n) = 0$ 
Hence: right hand side of (*) tends to $AB$. Also: $\lim\limits_{n\to +\infty}(C_n) = C$. Therefore: $C=AB$ $\square$ What I do not understand in this proof : I completely do not know how to derive equation labelled (*). Method of direct substitution of alternative form of symbols completely fail. There must be some trick in order to obtain this equation, however I can't find it. I do not see why $\lim\limits_{n\to +\infty}(r_n) = 0$. I would be very thankful to anyone that would post explanation towards these 2 steps in the above proof. Apart from these issues, other parts of this proof are clear for me.","['complex-analysis', 'contest-math', 'analysis', 'proof-explanation']"
2288192,"Find all the points on the cone $z^2=x^2+4y^2$ that are the closest to the point $(0,0,c)$","From all the points on the cone $z^2=x^2+4y^2$ find the closest to the point $(0,0,c)$. State explicitly the minimal distance. $c$ is a constant. Lagrange multipliers can be used here. Let the constraint function $g=x^2+4y^2-z^2$. Let the minimization function $f=(x-0)^2+(y-0)^2+(z-c)^2$ as function of finding the distance in between 2 points ion 3d space. We're also going to keep $f$ in squares so we don't have to get the factor out $z$ from the ellipse equation. Then we have:
$$
\nabla g=\langle2x, 8y,-2z \rangle\\
\nabla f=\langle 2x, 2y,2(z-c)\rangle
$$ So:
$$
\begin{cases}
2x=k\cdot2x\\
2y=k\cdot 8y\\
2(z-c)=k\cdot(-2z)
\end{cases}
$$ We have that $k=\frac{1}{4}$ then $x=0$ and $z=\frac{4c}{5}$.
If we plug those values into the ellipse equation we get that:
$$
c^2=\frac{125y^2}{4}\Rightarrow c=\pm\frac{\sqrt{125}y}{2}
$$ So the points would be $(0,y,\frac{\sqrt{125}y}{2})$ and $(0,y,-\frac{\sqrt{125}y}{2})$. First I think something is wrong with my calculations (although I double checked it). Also I'm not sure what does this mean that we have 2 points and how am I supposed to know which one is the minimum.","['multivariable-calculus', 'qcqp', 'optimization', 'lagrange-multiplier']"
2288203,$\sum_{n=1}^{+\infty} a_n$ converges iff $\prod_{n=1}^{+\infty} (1 - a_n)$ converges to a non-zero number,"If, $0<a_n< 1, \forall n$, show that $\sum_{n=1}^{+\infty} a_n$ converges iff $\prod_{n=1}^{+\infty} (1 - a_n)$ converges to a non-zero number. As $1-x \leq e^{-x}$, we have that $\prod_{n=1}^N (1 - a_n) \leq \prod_{n=1}^N e^{-a_n} = e^{-\sum_{n=1}^N a_n}$. Then, by the Monotone Convergence Theorem, if $\sum_{n=1}^{+\infty}a_n$ converges, then $\prod_{n=1}^{+\infty} (1 - a_n)$ converges. I'm having some trouble to conclude the other direction. Thank you very much!","['real-analysis', 'sequences-and-series']"
2288207,Prove that an operator (with heat kernel) maps the space of $C^1$ functions with bounded derivatives to itself,"Let $K$ be the heat kernel . Does the operator 
$$g \mapsto\int_0^T\int_{\mathbb{R}^N} K(t-\xi,x-\zeta) \ \  f(\xi,\zeta,g(\xi,\zeta),\nabla g(\xi,\zeta)) \, d\xi \, d\zeta$$
map the space of $C^1([0,T]\times \mathbb{R}^N)$ (for any $T>0$) functions bounded and with bounded derivatives to itself if $f: [0,T]\times \mathbb{R}^N \times \mathbb{R} \times \mathbb{R}^N \to \mathbb{R}$ is sufficiently well-behaved (for instance $C^1$)? Does it do the same for the space of $C^2$ or $C^\infty$ functions with bounded derivatives? Here $\nabla$ is used to denote the gradient with respect to the space variable $x \in \mathbb{R}^N$.","['functional-analysis', 'real-analysis', 'calculus', 'partial-differential-equations']"
2288241,"Prob. 19, Chap. 5, in Baby Rudin: If $f$ is defined in $(-1, 1)$, $f^\prime(0)$ exists, $-1<\alpha_n<\beta_n<1$, and . . .","Here is Prob. 19, Chap. 5 in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: Suppose $f$ is defined in $(-1, 1)$ and $f^\prime(0)$ exists. Suppose $-1 < \alpha_n < \beta_n < 1$, $\alpha_n \to 0$, and $\beta \to 0$ as $n \to \infty$. Define the difference quotients $$ D_n = \frac{f\left(\beta_n\right)-f\left(\alpha_n\right)}{\beta_n-\alpha_n}.$$ 
  Prove the following statements: (a) If $\alpha_n < 0 < \beta_n$, then $\lim D_n = f^\prime(0)$. (b) If $0 < \alpha_n < \beta_n$ and $\left\{ \beta_n / (\beta_n-\alpha_n) \right\}$ is bounded, then $\lim D_n = f^\prime(0)$. (c) If $f^\prime$ is continuous in $(-1, 1)$, then $\lim D_n = f^\prime(0)$. Give an example in which $f$ is differentiable in $(-1, 1)$ (but $f^\prime$ is not continuous at $0$) and in which $\alpha_n$, $\beta_n$ tend to $0$ in such a way that $\lim D_n$ exists but is different from $f^\prime(0)$. My Attempt: Part (a): Since $$f^\prime(0) = \lim_{x \to 0} \frac{f(x) - f(0)}{x-0}$$ exists, so, given any real number $\varepsilon > 0$, we can find a real number $\delta > 0$ such that 
  $$ \left| \frac{f(x) - f(0)}{x-0} - f^\prime(0) \right| < \frac{\varepsilon}{4} \tag{1} $$
  for all $x \in (-1, 1)$ for which $0 < |x| < \delta$. Now as $\alpha_n \to 0$ and $\beta_n \to 0$ as $n \to \infty$, so we can find natural numbers $M$ and $N$ such that 
  $$ \left| \alpha_n \right| < \delta \ \mbox{ for all } n > M,$$ 
  and 
  $$ \left| \beta_n \right| < \delta  \ \mbox{ for all } n > N,$$ 
  So 
  $$ \left| \alpha_n \right| < \delta  \ \mbox{ and } \left| \beta_n \right| < \delta \ \mbox{ for all } n > \max \left\{ M, N \right\}. \tag{2} $$ As $\alpha_n < 0 < \beta_n$, so we have $0 < - \alpha_n < \beta_n - \alpha_n$ and $ 0 < \beta_n < \beta_n - \alpha_n$, which imply 
  $$ 0 < \frac{\beta_n }{ \beta_n - \alpha_n } < 1 \ \mbox{ and } \ 0 < \frac{ - \alpha_n }{ \beta_n - \alpha_n } < 1. \tag{3} $$ 
  Now $$
\begin{align}
D_n &=  \frac{ f\left( \beta_n \right) - f \left( \alpha_n \right) }{ \beta_n - \alpha_n } \\
&= \frac{ f\left( \beta_n \right) - f(0) + f(0) -  f \left( \alpha_n \right) }{ \beta_n - \alpha_n } \\
&= \frac{f\left( \beta_n \right) - f(0) }{ \beta_n - \alpha_n} + \frac{ f(0) -  f \left( \alpha_n \right)}{\beta_n - \alpha_n} \\
&= \frac{\beta_n }{ \beta_n - \alpha_n } \frac{ f\left( \beta_n \right) - f(0) }{ \beta_n } + \frac{ - \alpha_n }{ \beta_n - \alpha_n} \frac{ f \left( \alpha_n \right) - f(0) }{ \alpha_n }.
\end{align}
$$
  So, for all $n > \max \left\{ M, N \right\}$ [Refer to (2) above.], we obtain $$ 
\begin{align}
& \left| D_n - f^\prime(0) \right| \\
&= \left| \frac{ f\left( \beta_n \right) - f \left( \alpha_n \right) }{ \beta_n - \alpha_n } - f^\prime(0) \right| \\
&= \left| \frac{\beta_n }{ \beta_n - \alpha_n } \frac{ f\left( \beta_n \right) - f(0) }{ \beta_n } + \frac{ - \alpha_n }{ \beta_n - \alpha_n} \frac{ f \left( \alpha_n \right) - f(0) }{ \alpha_n } - f^\prime(0) \right| \\
&= \left| \frac{\beta_n }{ \beta_n - \alpha_n } \left[ \frac{ f\left( \beta_n \right) - f(0) }{ \beta_n } - f^\prime(0) \right]  +  \frac{ - \alpha_n }{ \beta_n - \alpha_n} \left[ \frac{ f \left( \alpha_n \right) - f(0) }{ \alpha_n } - f^\prime(0) \right] \right| \\
&\leq \frac{\beta_n }{ \beta_n - \alpha_n } \left| \frac{ f\left( \beta_n \right) - f(0) }{ \beta_n } - f^\prime(0) \right|  +  \frac{ - \alpha_n }{ \beta_n - \alpha_n} \left| \frac{ f \left( \alpha_n \right) - f(0) }{ \alpha_n } - f^\prime(0)  \right| \qquad \mbox{ [ using (3) ] } \\
&\leq \left| \frac{ f\left( \beta_n \right) - f(0) }{ \beta_n } - f^\prime(0) \right|  + \left| \frac{ f \left( \alpha_n \right) - f(0) }{ \alpha_n } - f^\prime(0)  \right| \qquad \mbox{ [ using (3) again ] }  \\
&= \frac{\varepsilon}{4} + \frac{\varepsilon}{4} \qquad \mbox{ [ using (1) and (2) ] } \\
&< \varepsilon. 
\end{align}
$$ 
  Thus, for every real number $\varepsilon > 0$, we can find a natural number $K \colon= \max\left\{ M, N \right\}$ such that $$ \left| D_n - f^\prime(0) \right| < \varepsilon $$ for all natural numbers $n > K$. Hence $$\lim_{n \to \infty} D_n = 0.$$ Am I right? Part (b): If $0 < \alpha_n < \beta_n$, then $$0 < \frac{\alpha_n}{\beta_n - \alpha_n} < \frac{\beta_n}{\beta_n - \alpha_n}; \tag{4}$$ furthermore if there is a real number $r > 0$ such that $$\frac{\beta_n }{\beta_n - \alpha_n } \leq r,$$ then we also have $$ \frac{\alpha_n }{\beta_n - \alpha_n } \leq r.$$
  Now as $f^\prime(0) = \lim_{x \to 0 } \frac{ f(x) - f(0) }{x-0}$ exists, so, for every real number $\varepsilon > 0$, we can find a real number $\delta > 0$ such that $$\left| \frac{ f(x) - f(0) }{x-0} - f^\prime(0) \right| < \frac{\varepsilon}{4r} \ \mbox{ for all real numbers } x \in (-1, 1) \ \mbox{ for which } \ 0 < | x | < \delta. \tag{5} $$ 
  And, since $\alpha_n \to 0$ and $\beta_n \to 0$ as $n \to \infty$, therefore we can find natural numbers $M$ and $N$ such that 
  $$ \left| \alpha_n \right| < \delta \ \mbox{ for all natural numbers } n > M, \tag{6} $$
  and 
  $$ \left| \beta_n \right| < \delta \ \mbox{ for all natural numbers } n > N. \tag{7} $$
  So, for all natural numbers $n > \max\left\{ M, N \right\}$, we see that 
  $$ 
\begin{align}
& \left| D_n - f^\prime(0) \right| \\
&= \left| \frac{\beta_n }{ \beta_n - \alpha_n } \left[ \frac{ f\left( \beta_n \right) - f(0) }{ \beta_n } - f^\prime(0) \right]  +  \frac{ - \alpha_n }{ \beta_n - \alpha_n} \left[ \frac{ f \left( \alpha_n \right) - f(0) }{ \alpha_n } - f^\prime(0) \right] \right| \\
&\leq \frac{\beta_n }{ \beta_n - \alpha_n } \left| \frac{ f\left( \beta_n \right) - f(0) }{ \beta_n } \right| + \frac{  \alpha_n }{ \beta_n - \alpha_n} 
\left| \frac{ f \left( \alpha_n \right) - f(0) }{ \alpha_n } - f^\prime(0) \right| \qquad \mbox{ [ using (4) ] } \\
&\leq r \left| \frac{ f\left( \beta_n \right) - f(0) }{ \beta_n } \right| + r \left| \frac{ f \left( \alpha_n \right) - f(0) }{ \alpha_n } - f^\prime(0) \right| \qquad \mbox{ [ using our hypothesis ] } \\
&< r \frac{\varepsilon}{4r} + r \frac{\varepsilon}{4r} \qquad \mbox{ [ using (5), (6), and (7) above ] } \\
&< \varepsilon.
\end{align} 
$$
  Since $\varepsilon$ was an arbitrary positive real number, therefore it follows that $$\lim_{n \to \infty} D_n = f^\prime(0),$$ 
  as required. Am I right? Part (c): For each $n \in \mathbb{N}$, as $-1 < \alpha_n < \beta_n < 1$ and as $f^\prime$ is continuous in $(-1, 1)$, so $f$ satisfies the hypothesis of the mean value theorem on the interval $\left[ \alpha_n, \beta_n \right]$. So, for every $n \in \mathbb{N}$, we can find a real number $\gamma_n \in \left( \alpha_n, \beta_n \right)$ such that $$ D_n = \frac{ f\left( \beta_n \right) - f \left( \alpha_n \right) }{ \beta_n - \alpha_n } = f^\prime\left(\gamma_n\right). $$
  Now as $\alpha_n < \gamma_n < \beta_n$ for all $n \in \mathbb{N}$ and as $\alpha_n \to 0$ and $\beta_n \to 0$ as $n \to \infty$, so by the sandwiching theorem we can conclude that $\gamma_n \to 0$ as $n \to \infty$, and since $f^\prime$ is continuous in $(-1, 1)$ and hence at $x=0$, therefore we can conclude that $f^\prime\left(\gamma_n\right) \to f^\prime(0)$ as $n \to \infty$; that is, $D_n \to f^\prime(0)$ as $n \to \infty$. Am I right? Let $f$ be defined on $(-1, 1)$ by $$ f(x) = \begin{cases} x^2 \sin \left( \frac{1}{x} \right) \ & \ (x \neq 0), \\ 0 \ & \ (x=0). \end{cases} $$ Let $$\alpha_n = \frac{1}{2\pi (n + 1/4)}, \qquad \beta_n = \frac{1}{2 \pi n}  \qquad \mbox{ for all } n \in \mathbb{N}.$$ 
  Then $$ f^\prime(x) = \begin{cases} 2x \sin \left( \frac{1}{x} \right) + x^2 \cos \left( \frac{1}{x} \right) \ & \ (x \neq 0), \\ 0 \ & \ (x=0). \end{cases} $$ 
  Moreover, $$0 < \alpha_n < \beta_n < 1 \ \mbox{ for all } n \in \mathbb{N},$$ and $$ \lim_{n \to \infty} \alpha_n = 0, \qquad \lim_{n \to \infty} \beta_n = 0.$$ 
  Now 
  $$
\begin{align}
D_n &= \frac{ f\left( \beta_n \right) - f\left( \alpha_n \right)   }{\beta_n - \alpha_n } \\ 
&= \frac{ - \frac{1}{4 \pi^2 (n+1/4)^2 } }{\frac{1}{2 \pi n}  -  \frac{1}{2\pi (n + 1/4)} } \\
&= - \frac{ 1}{2 \pi } \frac{  \frac{1}{(n+1/4)^2} }{ \frac{1}{n} - \frac{1}{n+1/4}  } \\
&= - \frac{ 1}{2 \pi } \frac{ \frac{1}{n+1/4} }{ \frac{1/4}{ n }  } \\
&= - \frac{ 1}{2 \pi }\frac{16 n}{4n + 1} \\
&= - \frac{ 8 }{ \pi } \frac{1}{ 4+1/n }.
\end{align}
$$
  So 
  $$\lim_{n \to \infty} D_n = - \frac{2}{\pi} \neq f^\prime(0).$$ Am I right? Are my proofs correct and rigorous enough for Rudin? If not, then where are the pitfalls? Is my example appropriate in the situation described by Rudin? If so, is my calculation correct also?","['derivatives', 'real-analysis', 'limits', 'calculus', 'analysis']"
2288243,Is $E\left(\frac{X}{X+Y}\right)=\frac12$ when $X$ and $Y$ follow the same probability distribution?,"I had an exercise regarding random variables, and I tried to figure if the following is true: If $X$ and $Y$ follow the same probability distribution, then $E(\frac{X}{X+Y})=E(\frac{1}{2})=\frac{1}{2}$. I'm skeptical about this, since I have tried to prove it and got nowhere.","['probability-theory', 'expectation']"
2288244,PDF of $\frac{X}{1+X^2}$ in terms of the PDF of $X$,"Given a r.v. $X$ with a know probability density $g$, I would like to find the probability density of $\frac{X}{1+X^2}$. Below I write my calculations: denote $f(X) := \frac{X}{1+X^2}$ Now $f$ is not monotone so we can't apply the known theorem, we proceed by finding the solutions to $\frac{X}{1+X^2} < c$ for the solutions to exist we need $-1/2<c < 1/2$ and the solutions to the associated quadratic equation will be $x_{1-2} = 1 \pm\sqrt{1-4c^2}/ (2c)$. I obtain that 
$$P(f(X) < c) = P( \{X <1 -\sqrt{1-4c^2}/ (2c)\} \cup \{ X > 1 +\sqrt{1-4c^2}/ (2c)  \}) = 1-P(X < 1 +\sqrt{1-4c^2}/ (2c)) + P(X <1 -\sqrt{1-4c^2}/ (2c))$$ So the resulting density of $\frac{X}{1+X^2}$ will be $$1+ \frac{ 4c/ \sqrt{1-4c^2} + 2(1+\sqrt{1-4c^2})}{4c^2}g(1 +\sqrt{1-4c^2}/ (2c)) + \frac{ 4c/ \sqrt{1-4c^2} - 2(1-\sqrt{1-4c^2})}{4c^2}g(1 -\sqrt{1-4c^2}/ (2c)$$
with the condition that $-1/2<c<1/2$. Is this the correct approach?","['probability-theory', 'probability-distributions']"
2288249,Prove that the expression is a perfect square,"Let $m$ be a natural number. Define $f(m) = m + \lfloor\sqrt{m}\rfloor$. Prove that at least one of the number among $m, f(m), f^2(m), \ldots$ is a perfect square. Here $f^k(m)$ denotes the composition of $f$ over itself $k$ times. I tried the question, but the greatest integer along with square root is creating trouble.","['algebra-precalculus', 'functions', 'elementary-number-theory']"
2288292,Help Finishing Proof ?!,"Let $AB$, $AC$, $AD$ be three chords in a circle. Denote $M, N, $ and $P$ the pairwise intersections of the circles of diameters $AB, AC$, and $AD$. Show that $M, N, P$ are collinear. I am attempting to approach the proof using angle chasing. So far I have: $DANP$ is a cyclic quadrilateral, so $\angle ADP + \angle ANP = 180^\circ$. Denote $\angle ADP = \theta$. Then $\angle ANP = 180^\circ - \theta$. If we can show that $\angle ANM = \theta = \angle ADP$, we are done. We also have that $AMBN$ is a cyclic quadrilateral so $\angle ANM = \angle ABM = \frac{1}{2}\text{arc}AM = \beta$. Now we must show that $\beta = \theta$. 
$AMCP$ is cylic I am having trouble with chasing the rest of the angles necessary to finish the proof.","['circles', 'euclidean-geometry', 'geometry']"
2288304,Breaking a stick twice - why are $Y$ and $\frac{X}{Y}$ are independent?,"A stick of length $L$ is broken at a point which is chosen according to a uniform distribution. We keep the left 'substick' of length $Y$. Then we, in turn, break this 'substick' and keep another left part which is $X$. The book says that r.v.'s $Y$ and $X/Y$ are independent, but I don't understand why. I could use the definition of independence but I can't find the necessary PDFs for that and the book doesn't do that either, just states the fact. Any help would be appreciated.","['independence', 'probability-theory', 'probability']"
2288308,Why non-trivial solution only if determinant is zero,The equation $(A−λI)x=0$ has a nontrivial solution (a solution where $x≠0$) if and only if  $det(A−λI)=0$. Why is that? How can this be proven?,"['linear-algebra', 'determinant']"
2288313,Why introduce the $p$-adic numbers?,"My current intuition about the p-adic numbers comes from the following three facts: You can describe $Gal(\overline{\mathbb{Q}}/\mathbb{Q})$ with the $Gal(\overline{\mathbb{Q}}_p/\mathbb{Q}_p)$ groups. Hensel's lemma We find that the p-adic integers are formal neighborhoods of closed points in $\mathbb{Z}$, so they naturally show up in the deformation theory of arithmetic objects (Schemes over $\mathbb{Z}$) What are other reasons to consider p-adic integers/numbers?","['big-picture', 'big-list', 'p-adic-number-theory', 'algebraic-geometry', 'schemes']"
2288322,Intuition behind the normal distribution,"The probability density of the normal distribution is : 
$$ f(x) = \frac{1}{\sqrt{2\pi}\sigma} \cdot e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2}$$ And for a random variable $X$ such that : $X \sim \mathcal N (0, 1)$ then we have :
$$f(x) = \frac{1}{\sqrt{2\pi}} \cdot e^{-\frac{1}{2}x^2}$$ Yet what is the intuition behind this formula ? Why is there the number $\pi$ and $e$ in the formula of the probability density of the normal distribution ? Moreover, in a lot of my exercices on the normal distribution it's always saying at the beginning of the exercice : Let $X$ be a random variable that follow a normal distribution. Yet, how can we know that a random variable follows a normal distribution ? For example let's say we are studying some process, and more spefically the behaviour of a random variable. Then how can we know, and from which properties of this random variable we can say that it follows a normal distribution ?","['intuition', 'normal-distribution', 'probability-theory', 'probability-distributions', 'probability']"
2288329,Probably incorrect method of integration gives the correct result. Why?,"I have just learned about the residue theorem so when I encountered the integral
$$
  I = \int_{0}^{+\infty} \frac{x^3}{e^x-1}dx
$$
I tried to evaluate it with this method, which failed but produced something interesting. Define the complex logarithm on $\mathbb C \setminus [0,+\infty)$ and consider the function
$$
  f(z) = \frac{z^3 \log z}{e^z-1}
$$
with the path $\gamma$ given by this drawing Provided that both $\oint_{C_\epsilon} fdz$ and $ \oint_{C_R}fdz$ goes to zero
as $R\to\infty$ and  $\epsilon \to 0$ the value of the original integral is given by the residue theorem $$
 I = -\frac{1}{2\pi i}\oint_\gamma fdz =
      -\sum_{k} \text{Res}(f, z_k)
$$ $f$ has simple poles for $e^z=1$, $z=2k\pi i$ where $k \in \mathbb Z$ so the residues are \begin{align*}
	\text{Res}(f, z_k) &= 0 && k=0  \\
	\text{Res}(f, z_k) &= z^3 \log{z} \big|_{z=2k\pi i}
	                   = (2k\pi)^3 \log (2k\pi i) && k\neq 0
\end{align*} The sum of the residue can be written as
$$
  \sum_{k=1}^{+\infty} (a_k + a_{(-k)})
$$ where
\begin{align*}
  a_k     &= i(2k\pi)^3\left(\log(2k\pi) + i\frac{\pi}{2}\right) \\
 a_{(-k)} &= i(2k\pi)^3\left(-\log(2k\pi) - i\frac{3\pi}{2}\right)
\end{align*} Cancelling the terms out
$$
  I = \sum_{k=1}^{+\infty} i(2\pi k)^3(-i\pi)
    = 8\pi^4 \sum_{k=1}^{+\infty} k^3
$$ which diverges. Clearly something is wrong: maybe the integral on the circumference is not zero? I'm not sure. However if I replace the infinite sum with $\zeta(-3)=\frac{1}{120}$ I actually get the correct result  $I = \frac{\pi^4}{15}$. Why does this work? P.S. I managed to evaluate it in a more familiar way without involving complex analysis.","['complex-analysis', 'improper-integrals', 'riemann-zeta', 'residue-calculus']"
2288352,Geodesics of manifold and geodesics of its submanifold with induced metric,"Suppose we have a riemmanian manifold $(\mathcal{M}, g)$. Let $\mathcal{N}$ be properly embedded submanifold of $\mathcal{M}$ with induced metric $\bar{g}$ from 
 $g$. ($\mathcal{N}$ is not necessarily totally geodesic manifold.) Let $a, b \in \mathcal{N} \subset \mathcal{M}$ be two distinct points. Say $\gamma(t)$ is unique geodesic curve on $\mathcal{M}$ with metric $g$ and $\bar{\gamma}(t)$ is also unique geodesic curve on $\mathcal{N}$ with metric $\bar{g}$ with $\gamma(0) = \bar{\gamma}(0) = a$ and $\gamma(1) = \bar{\gamma}(1) = b$. Question : If $c(t) \in \mathcal{N}$ is the closest point from $\gamma(t)\in\mathcal{M}$ to submanifold $\mathcal{N}$, then does $c(t)$ always belong to geodesic curve $\bar{\gamma}$? Actually, this is just my guess, since it holds true for $\mathcal{M} = R^{3}$, $\mathcal{N} = S^{2}$. Is it generally true? or for what condition does it hold true? Curious whether there is some relevant theorem regarding this...","['submanifold', 'riemannian-geometry', 'differential-geometry', 'geodesic']"
2288419,Does every smooth curve of genus $\ge 2$ lie in a family containing an integral stable nodal curve?,"Let $X$ be a smooth projective curve over an algebraically closed field $k$. Does there exist a Dedekind domain $A$ and a stable curve $\mathcal{X}/A$ such that at two closed points $x,y\in\text{Spec }A$, we have $\mathcal{X}_x = X$, and $\mathcal{X}_y$ is an integral stable nodal curve (ie, a stable curve with one irreducible component).",['algebraic-geometry']
2288438,Difference between $\mathbb{Z}/n\mathbb{Z}$ and $\mathbb{Z}_n$,"In every Modern Algebra book I've read, I've seen that the groups $\mathbb{Z}/n\mathbb{Z}$ and $\mathbb{Z}_n$ are isomorphic, but not equal. I understand the difference between ""isomorphic"" and ""equal,"" but this particular example raises a couple of questions for me. I know the first group consists of cosets $k + n\mathbb{Z}$, and the second group consists of equivalence classes $[k]_n$, but isn't it true that $k + n\mathbb{Z} = [k]_n$ for every integer $k$? (They are both sets containing the same elements from $\mathbb{Z}$.) And if so, then can't we say that $\mathbb{Z}/n\mathbb{Z} = \mathbb{Z}_n$? Thanks in advance!","['abstract-algebra', 'integers', 'group-isomorphism', 'quotient-group']"
2288472,On elementary proofs of Fermat's Last Theorem,"I came across this one of many claimed elementary proofs of FLT. It looked credible, and I felt surprised seeing that it wasn't drawing much attention from anyone. I investigated and I ended up finding this argument ruling out any chances for this kind of ""proofs"" to be correct. Now, my question shall be organized in three steps: I have a very basic understanding of the ""trick"". I get its underlying logic, but unluckily I have a ridiculous knowledge of rings and fields, and in particular I know almost nothing of $p$-adic numbers. Can you confirm that, reasoning in analogy with the familiar number sets, I can safely assume that having a solution in $Q_p$ would imply a counterpart in $Z_p$? Is there a way to make it comprehensible how a solution made of $p$-adic integers would look like? This is what I'm interested in most. Is it possible to understand, at least at an intuitive level, in lay-person's terms, what is the characteristic of the ring of familiar integers that makes it different from other factorial rings? In other words, what is (or are) the features typical only of our beloved usual numbers that make FLT hold for them? In further other words, what properties have been involved by the advanced mathematical tools used to prove FLT? Finally, if we can spot such a characteristic, and it necessarily requires the use of instruments that Fermat didn't have, isn't this definitive evidence that Fermat could not have a proof? Why is this still sometimes questioned? Did he have any chance to perform something that did not fall under the disproof of the ""trick"", something that wouldn't apply to other rings like that of $p$-adic integers?","['number-theory', 'fake-proofs', 'diophantine-equations', 'proof-explanation']"
2288481,Proving a set is a subset of another set,"Question: Let $S = [3] \times [3]$ (the Cartesian product of $\{1, 2, 3\}$ with itself). Let $T$ be the set of ordered pairs $(x,y) \in \mathbb{Z}\times\mathbb{Z}$ such that $0≤3x+y−4≤8$. Prove that $S ⊆ T$. Does equality hold? My attempt to prove that $S ⊆ T$: Attempt Could someone please tell me if this is the correct way to prove $S ⊆ T$? Also, in order to prove that equality holds, do I have to show that $T ⊆ S$ ?","['elementary-set-theory', 'proof-verification']"
2288488,"A new interesting pattern to $i\uparrow\uparrow n$ that looks cool (and $z\uparrow\uparrow x$ for $z\in\mathbb C,x\in\mathbb R$)","Many of you may recall "" An obvious pattern to $i\uparrow\uparrow n$ that is eluding us all? "", an old question of mine, and just recently, I saw this new question that poses a simple extension to tetration at non-integer values: $$a\uparrow\uparrow b=\begin{cases}a^b,&b\in[0,1]\\a^{a\uparrow\uparrow(b-1)},&b\in(1,+\infty)\\\log_a(a\uparrow\uparrow(b+1)),&b\in(-\infty,0)\end{cases}$$ Combining this with my old question, I made the following graph of $i\uparrow\uparrow x$ for $x\in(-2,9)$ , using $z=re^{i\theta},\theta\in[0,2\pi)$ : (x-axis is the real axis and y-axis is the imaginary axis) Is there anything special to be said about this? About how each look always connects to the previous 'branch' and then steps off the branch until it hits the next one.  Can we prove this is indeed the case? Prove or disprove that the tangent line at each interception is equivalent for the original branch and the branch coming out that heads towards the center. It also appears the branches connect perpendicularly. Are these shapes similar to one another? The pattern is rather intriguing, don't you think? It appears $(-1)\uparrow\uparrow x$ is likewise interesting to look at: Link to graph. It starts off how one might expect it to start off: It makes a loop: Then another loop: And then it blows up into a circular shape that reaches about 35 units away from the origin: Closer image: And then it goes on past $10^{30}$ : Closer image: Medium zoom: Another loop: Any explanation for why this is so much more 'chaotic' than $i\uparrow\uparrow x$ ?  Perhaps we can define chaotic or not as follows: \begin{align}\lim_{x\to\infty}a\uparrow\uparrow x\ \text{converges}\implies\text{stable/non-chaotic}\end{align} \begin{align}\lim_{x\to\infty}a\uparrow\uparrow x\ \text{diverges}\implies\text{unstable/chaotic}\end{align} Once again we see apparently perpendicular connections, though trivially all at $(-1,0)$ . There are new patterns though.  We get almost cardioids, but not quite.  We saw two interesting loop looking shapes as well.  Any idea what these are?  It appears these loops get really long and form the quasi-cardioids. Is it the case that these loops always connect back to $(-1,0)$ from the same direction from which they came? And is there a 4-turned patter?  The first line connecting to $(-1,0)$ came from above, the second line connecting to $(-1,0)$ came from the right, the third came from below, the fourth from the left, and if we keep graphing more of these, the fifth comes from above once again. Can we do an analysis to these different shapes?  My graphing calculator isn't the best, and I have to do these one by one...  Particularly, what can we say about $z\uparrow\uparrow x$ for $|z|=1$ and $x\in\mathbb R$ ? After quite a few graphs, I've come to the following conclusion that: When $|z|=1,\operatorname{arg}(z)=\theta\in(-,\pi]$ , then $\lim\limits_{x\to\infty}z\uparrow\uparrow x$ tends to exist for $\theta<\theta_0$ and diverges for $\theta>\theta_0$ .  What is this $\theta_0$ ?  And is my conclusion correct? It also appears that it may be far from trivial proving the lines in $i\uparrow\uparrow x$ actually connect.  Though they are close, I have found that $\sqrt i\uparrow\uparrow x$ clearly does not connect : Here is the general graph .  It appears as though $\theta_0=\pi/2$ .","['complex-numbers', 'algebra-precalculus', 'recreational-mathematics', 'tetration', 'power-towers']"
2288505,"$f:U\to\mathbb{R}^n$ is of class $C^1$. If for $a\in U$ ($U$ open), $f'(a)$ is injective, exists ball where $|f(x)-f(y)\ge c|x-y||$","$f:U\to\mathbb{R}^n$ is of class $C^1$ in the open $U\subset
 \mathbb{R}^m$. If for some $a\in U$,
  $f'(a):\mathbb{R}^m\to\mathbb{R}^n$ is injective, then there exists
  $\delta>0$ and $c>0$ such that $B = B(a,\delta)\subset U$ and, for any
  $x,y\in B$ we have  $|f(x)-f(y)\ge c|x-y||$. In particular, the
  restriction $f_{|_ B}$ is injective. Proof given by book: The function $u\to |f'(a)\cdot u|$ is positive in all the points $u$
  of the unit sphere $S^{m-1}$ (what - 1) , which is compact. By the Weiestrass
  theorem, there exists $c>0$ such that $|f'(a)\cdot u| \ge 2c$ for all
  $u\in S^{m-1}$ (what? - 2) . By linearity, follow that $|f'(a)\cdot
 v|\ge 2c\cdot |v|$ for all $v\in \mathbb{R}^m$ (what? - 3) . For all
  $x\in U$, we write: $$r(x) = f(x)-f(a) -f'(a)(x-a)$$ Then, for any $x,y\in U$ we have: $$f(x)-f(y) = f'(a)\cdot (x-y) + r(x)-r(y)$$ By $|u+v|\ge |u|-|v|$ follows: $$|f(x)-f(y)|\ge |f'(a)\cdot(x-y)|-|r(x)-r(y)|\ge\\ 2c\cdot
 |x-y|-|t(x)-r(y)|$$ Observe that $r$, as defined above, is of class $C^1$, with $r(a) =
> 0$. By the continuity of $r'$, there exists $\delta >0$ such that
  $|x-a|<\delta \implies x \in U $ and $|r'(x)|<c$. The mean value
  inequality applied in $r$ in the convex set $B = B(x,\delta)$ makes
  $x,y\in B \implies |f(x)-f(y)|\ge 2c|x-y|-|x-y|$, that is,
  $$|f(x)-f(y)|\ge c|x-y|$$ what - 1: couldn't it be $0$? what - 2: if it's already positive, then why do I need Weiertrass theorem? If it's positive then it's always greater than a $c$, I can just make it smaller so it's bigger than $2c$ what - 3: how linearity makes that possible? Also, which Weiertrass theorem is applied here? There are many.","['multivariable-calculus', 'real-analysis', 'calculus', 'functions']"
2288529,How many homomorphism from $S_3$ to $S_4$?,"How many homomorphism from  $S_3$ to $S_4$? Please find these using fundamental theorem. I think  if $f\colon G \rightarrow G'$ is a group homomorphism then $G/\ker f$ is isomorphic to a subgroup of  $G'$. For one choice of $\ker f$, the order of $G/\ker f$ is $k$ and $G'$ has $n$ subgroups of  order $k$ . Hence there are $n$ homomorphisms. But in case of $S_3$ to $S_4$,  if $S_3/\ker f$ is a subgroup of $S_4$ then we have three cases: $\ker f = \{\mathrm{id}\}$:  then $S_3$ is isomorphic to a subgroup of $S_4$.
There are 4 subgroups in $S_4$ isomorphic to $S_3$ so in this case we have 4 homomorphisms. $\ker f = A_3$ then $S_3/A_3$ is a subgroup of order 2 in $S_4$. Again, 9 subgroups in $S_4$  so 9 homomorphisms. $\ker f = S_3$ which gives 0 homomorphism. So in total 14 homomorphisms. Am I right ?","['finite-groups', 'abstract-algebra', 'group-theory', 'group-homomorphism']"
2288558,Use of multi-valued function in proving the equivalence of surjectivity and existence of a right inverse,"In Dummit and Foote's Abstract Algebra, the first two claims of Proposition 0.1 state that: Let $f: A \rightarrow B$ . If $A \neq \emptyset$ , the map $f$ is injective if and only if $f$ has a left inverse. The map $f$ is surjective if and only if $f$ has a right inverse. For $(1)$ , if $f$ is injective, then we can construct a function $g: B \rightarrow A$ such that $\forall f(a) = b \in B$ , we have the ""reverse"" mapping $$g(b) = a$$ and by appealing to the injectivity of $f$ , it follows that the composition map $g \circ f$ is in fact the identity map, so $f$ has a left inverse. Conversely, if we suppose that $f$ has a left inverse, then we can consider $a_1, a_2 \in A$ such that $a_1 = a_2$ . Since $f$ has a left inverse, we can write $g(f(a_1)) = a_1$ and $g(f(a_2))=a_2 \implies g(f(a_1)) = g(f(a_2)) \implies f(a_1) = f(a_2)$ due to the fact that $g$ is a function. In the case of $(2)$ , we suppose that $f$ is surjective and construct a function $h: B \rightarrow A$ such that $$h(b) \in \{a \in A : f(a) = b \}$$ i.e., considering reserve mapping of sorts where $h(b)$ can be any value $a$ where $f$ maps $a$ back to $b$ . Thus $f$ has a right inverse. In the other direction, it is easy to show that the existence of a right inverse guarantees that $\forall b \in B$ , $\exists a \in A$ such that $f(a) = b$ , namely, $a = h(b)$ , satisfying the definition of surjectivity. My main concern deals with the construction of the relation $h$ . By the set theoretic definition of function, we must have that no two ordered pairs in the relation $h$ have the same first element, but the very notion of having a multi-valued seems to contradict that definition. In other words, I am intuitively thinking of injectivity as an information preserving property, so one can have a reverse mapping without any ambiguities, but surjectivity is a property that results in information loss as multiple elements in $A$ could map to $b \in B$ , and there being no well-defined way to map back to the original $a$ from $b$ . I would like to verify if my reasoning above is correct, and by extension, if the proofs are rigorous enough in their current form.","['proof-verification', 'discrete-mathematics']"
2288576,"What is the Fourier Transform for $\mathscr{F} \left\{\frac{\partial^2 (x^2p(x,t))}{\partial x^2} \right\}$ w.r.t $x$?","What is the Fourier Transform for the following: $$
\mathscr{F} \left\{\frac{\partial^2 (x^2p(x,t))}{\partial x^2} \right\} = ?
$$ Here is my problem: Suppose we are given the diffusion
$$
dX(t)= \mu dt +  \sigma dW(t) \hspace{10mm}  (1)
\\ X(0)=x_0
$$ And a function 
$$
k(x)= \theta x^2 \hspace{10mm}  (2)
$$ Then by Ito Lemma 
$$
dk[X(t)]=(2 \mu  \theta x +  \theta  \sigma ^2)dt + (2 \sigma  \theta x)dW(t) \hspace{10mm}  (3)
\\ k[X(0)]=0
$$ And the Forward Kolmogorov to find the transition density $$
\frac{\partial p(x,t)}{\partial t}=- \frac{\partial ((2 \mu  \theta x+ \theta  \sigma^2 )p(x,t))}{\partial x} +  \frac{1}{2} \frac{\partial^2 ((2 \sigma  \theta x)^2p(x,t))}{\partial x^2} \hspace{10mm}  (4)   
\\ p(x,0)= \delta (x-x_0)
$$ So far so good Now, I need to convert the 2nd order pde to ordinary so I can solve it. This is why I need the Fourier Transform. List of properties: $
(a) \ \mathscr{F} \left\{ p(x,t) \right\}= \overline{p}(\xi,t)= \intop\nolimits_{-\infty}^{\infty} p(x,t) e^{-i2 \pi x \xi} dx
$ $
(b) \ \mathscr{F}^{-1} \{  \overline{p} (\xi,t) \}= p(x,t)= \intop\nolimits_{-\infty}^{\infty}  \overline{p} (\xi,t) e^{i2 \pi x \xi} d\xi
$ $
(c) \ \mathscr{F} \{ xp(x,t) \}= \frac{i}{-2 \pi} \frac{\partial  \overline{p} (\xi,t)}{\partial \xi} 
$ $
(d) \ \mathscr{F} \{ \frac{\partial^n p(x,t)}{\partial x^n} \}=(i2 \pi \xi)^n  \overline{p} (\xi,t)
$ $
(e) \ \mathscr{F} \{  \delta (x-x_0) \}= \intop\nolimits_{-\infty}^{\infty}  \delta (x-x_0) e^{-i2 \pi x \xi}dx = e^{-i2 \pi x_0 \xi } 
$ So now I can start to re-write (4) term by term: $$
\ \mathscr{F} \{ \frac{\partial p(x,t)}{\partial t} \}=   \frac{\partial  \overline{p} (\xi,t)}{\partial t} \hspace{10mm} (4-1)
$$ By $(f+g)'=f'+g'$ $$
\frac{\partial ((2 \mu  \theta x + \theta \sigma^2) p(x,t) )}{\partial x}= 2 \mu  \theta  \frac{\partial (xp(x,t))}{\partial x} +   \theta  \sigma^2 \frac{\partial p(x,t)}{\partial x}
$$ $$
 \ \mathscr{F} \left\{ 2 \mu  \theta  \frac{\partial (xp(x,t))}{\partial x} \right\} = (2 \mu  \theta) (i2 \pi \xi) \frac{i}{-2 \pi } \frac{\partial p(\xi,t)}{\partial \xi} \hspace{10mm} (4-2)
$$ $$
\ \mathscr{F} \left\{ \theta  \sigma^2 \frac{\partial p(x,t)}{\partial x} \right\} = (\theta  \sigma^2) (i2 \pi \xi)  \overline{p} (\xi,t) \hspace{10mm} (4-3)
$$ And I get stuck on the 2nd term of (4) $$
\ \mathscr{F} \left\{\frac{\partial^2 ((x)^2p(x,t))}{\partial x^2} \right\} =?  \hspace{10mm} (4-4)
$$ Any help/hint if I can re-write (4-4) in terms of the properties would be tremendous. Thank you! Additional stuff - 2nd derivative for $xp(x,t)$ $$
 \ \mathscr{F} \left\{ \frac{\partial^2 (xp(x,t))}{\partial x^2} \right\} = (i2 \pi \xi)^2 \frac{i}{-2 \pi } \frac{\partial p(\xi,t)}{\partial \xi}
$$","['derivatives', 'stochastic-processes', 'calculus', 'ordinary-differential-equations', 'fourier-transform']"
2288584,Evaluate $\lim_{x \to 0^+} x^{x^x}$,Evaluate $$\lim_{x \to 0^+} x^{x^x}$$ I have assumed $$L=\lim_{h \to 0}h^{(h^h)}$$ taking $x=0+h$ where $h$ is a very small positive real number. Now taking natural Log on both sides we get $$\ln L=\lim_{h \to 0}h^h \ln h$$ How to proceed further,"['algebra-precalculus', 'logarithms', 'calculus', 'limits']"
2288612,"Show, without invoking the Pythagorean theorem, that the $3-4-5$ triangle is right","The ancient Egyptians knew the $3-4-5$ triangle was a right triangle, but they did not possess the Pythagorean theorem or any equivalent theory.  Can it be shown that the $3-4-5$ triangle is a right triangle without using the Pythagorean theorem or any ideas related to it? This problem was shown to me by a fellow peer tutor a while ago.  I gave it some thought initially, but then I gave up trying when I realized it might not be doable.  What do you think?",['geometry']
2288648,Does the sum of reciprocals of all prime-prefix-free numbers converge?,"Call a positive integer $n$ prime-prefix-free if for all $k \ge 1$, $\lfloor \frac{n}{2^k} \rfloor$ is not an odd prime.  (Odd because otherwise the property is trivial, as every integer greater than $3$ has $10_2=2$ or $11_2=3$ as a proper binary prefix.) Does the sum of reciprocals of all prime-prefix-free numbers converge? I know that the sum of reciprocals of all prime prime-prefix-free numbers converges, using the Kraft-McMillan inequality and the fact that their binary representations form a prefix-free set. But this doesn't seem like much of a starting point for the whole problem, since a number being prime-prefix-free isn't related to whether its factors are (except when the other factor is a power of $2$).  I'm willing to assume Cramér's conjecture if that helps, limiting how many bits must be appended to make a number prime.","['number-theory', 'prime-numbers', 'convergence-divergence']"
2288671,Difficulty in linear algebra question.,"Let $a_{ij}=a_ia_j$ $1\leq i,j\leq n$ where $a_1,... a_n$ are real numbers. Let $A=(a_{ij})$ be the $n \times  n $ matrix . Then It is spoosible to choose $a_1,... a_n$ so as to mke A non singular. The matrix is positive definite if $(a_1,...,a_n)$ is a nonzero vector. The matrix A is positive definite for all $(a_1,...,a_n)$. For all $(a_1,...,a_n)$ zero is an eigen value of A. My attempt: Option 1 is false because if we choose $a_1=\frac{1}{\sqrt{2}} , 
  a_2=\sqrt{2}$ then $2\times 2$ matrix $A$ is singular. Option 2 is also false because if we take $a_1=1  \ a_2=2 $ then $2\times2$ matrix $A$ is not positive definite.
Option 3 is also false. But I am not getting option 4. Could you please help me? Thanks in advance.","['matrices', 'positive-definite', 'positive-semidefinite', 'linear-algebra']"
2288683,How to find the mirror image of a parabola with respect to a given line?,"In a question asked yesterday, the OP wanted to know the answer to the following question in JEE Advanced 2015 : Let the curve C be the mirror image of the parabola $y^2 = 4x$ with respect to the line $x + y + 4 = 0$. If $A$ and $B$ are the points of intersection of $C$ with the line $y = -5$, then what is the distance between $A$ and $B$? More specifically, the OP wanted to know how to find the equation of the mirror image of the given parabola. However, the question was initially unclear and the thread was put on hold. Since the OP is eager to know the answer and I already prepared a detailed explanation, I decided to create a new question, asking the following: How can we find the equation of the mirror image of the parabola $y^2=4x$ with respect to the line $x+y+4=0$?","['conic-sections', 'geometry']"
2288774,Why is the roll of a die considered random?,"I've been reading articles on pseudo-randomness in computing when generating a random value. They all state that the generated numbers are pseudo-random because we know all the factors that influence the outcome, and that the roll of a die is considered truly random. But I'm wondering why. Don't we know all the physical forces that influence the die when it's being rolled? Or is there too many of them?","['random', 'probability', 'random-variables']"
2288791,"$V(X_1,\ldots,X_n)$ has empty interior.","Let $A$ be a ring, $n\geq 1$ an integer and $Z=V(X_1,\ldots,X_n)\subset\mathbb{A}^n_A=\operatorname{Spec} A[X_1,\ldots,X_n]$. It is true that $\mathring Z=\emptyset$? Surely this is the case if $A$ is a field. (Reason: If $A$ is a field, then $(X_1,\ldots,X_n)$ is a closed point. But $\mathbb{A}^n_A$ is irreducible and therefore connected, so $Z=\{(X_1,\ldots,X_n)\}$ must have empty interior.)","['schemes', 'algebraic-geometry']"
2288810,Finitely generated free group has finite rank,"Initially I was trying to prove that the commutator subgroup of $F_2$ (=free group of rank $2$) is not finitely generated. It seems possible to prove that it is indeed free of infinite rank. To get to a contradiction I have to prove that if a free group is finitely generated then it has finite rank but I can't find a way, despite it seems trivial.","['combinatorial-group-theory', 'group-theory', 'free-groups']"
2288907,A space curve with constant curvature-torsion product,"How do we solve for  curve coordinates in terms of parameter $t$  in $\mathbb R^3$ having scalar property $$ \tau \cdot \kappa = const.?$$ The curve would be with infinite twist at straight portions and confined to plane at cusp points. EDITS (1-3): I.e., how to find a vector $r(t)$ so that $$  \tau\, \kappa =\dfrac{r^{'} \times r^{''}\cdot r^{'''}  }{||r^{'} \times r^{''}||^2 }  \dfrac{|r^{'} \times r^{''}|  }{|r^{'} |^3 } =1? $$ The above formulae are of Frenet-Serret vector triad $T,N,B$ and derivatives, textbook derived with respect to parameter $t$. BTW, is there a word for infinite torsion of a line?( By analogy of infinite normal curvature being a cusp) The following surface (rotation symmetry assumed) and arc are obtained numerically but not without an extra assumed arbitrary relation of arc angle to meridian and axis of symmetry . Central parts are asymptotic/infinite torsion and the ends have infinite curvature cusp edge/zero torsion just as expected. This singularity terminates numerical computation.","['ordinary-differential-equations', 'differential-geometry']"
2288950,Bayes' theorem - monty hall problem with five doors - incorrect final probabilities,"Consider the following revised five-door Monty Hall problem: Step 1, you choose two doors and your choice is: doors 1 and 2; Step 2, Monty Hall opens two doors (with no car behind them): doors 3 and 4; Step 3, Monty Hall asks you to decide which door among doors 1, 2, and 5 is your final choice. You will win the car if the car is behind the door you finally choose. Now apply Bayes’ theorem to calculate the probabilities that the car is behind doors 1, 2 and 5. (Note: you need to give detailed formulas and calculations step by step, rather than just present the final results). I know what the final answer should be from intuition,
p(car behind door 1) = 1/5
p(car behind door 2) = 1/5 
p(car behind door 5) = 3/5 I tried to work through the question but the correct probabilities are not gained. This is my working so far: p(car being behind door 1 | door 3 and 4 opened) = (2/3 * 1/5) / 2/3 
= 1/5 <-- correct p(car being behind door 1 | door 3 and 4 opened) = p (door 3 and 4 opened | car behind door 1) * p (car behind door 1) / p (Door 3 and 4 opened ) p(car being behind door 2 | door 3 and 4 opened) = (2/3 * 1/5) / 2/3
= 1/5 <-- correct p(car being behind door 2 | door 3 and 4 opened) = p (door 3 and 4 opened | car behind door 2) * p (car behind door 2) / p (Door 3 and 4 opened ) p(car being behind door 5 | door 3 and 4 opened) = (1 * 1/5) / 2/3
= 3/10 <-- incorrect p(car being behind door5 | door 3 and 4 opened) = p (door 3 and 4 opened | car behind door 5) * p (car behind door 5) / p (Door 3 and 4 opened ) I think p(door3 and door4) != 2/3 - this is where I am possibly going wrong, my calculations say it should be 1/3 so that p(car being behind door 5 | door 3 and 4 opened) = 3/5, but that does not make sense. etc. bayes equation used: p(A|B) = p(B|A)*p(A)/p(B) I am just not too sure. Please explain thanks","['bayes-theorem', 'probability-theory', 'bayesian', 'monty-hall', 'probability']"
2288959,Free group as semi-direct product,"Let $F$ be a free group of rank at least $2$. Of course then, $F$ can not be direct product of two subgroups (except the trivial decomposition $1\times F$). Q. Can $F$ be written as semi-direct product of two subgroups? If yes, can we choose the components in semi-direct product to be free (sub)groups of finite rank?","['abstract-algebra', 'semidirect-product', 'group-theory', 'free-groups']"
2288993,Determinants and $2\times 2$ minors,"I just proved that $$0=\left|\begin{array}{cccc}
	a_0 & a_1 & a_2 & a_3 \\
	b_0 & b_1 & b_2 & b_3 \\
	a_0 & a_1 & a_2 & a_3 \\
	b_0 & b_1 & b_2 & b_3
\end{array}\right|=2(\Delta_{01}\Delta_{23}-\Delta_{02}\Delta_{13}+\Delta_{03}\Delta_{12})$$
where 
$$\Delta_{ij}=\left|\begin{array}{cc}
a_i & a_j \\
b_i & b_j
\end{array}\right|$$
Is there any way of expressing the following determinant in a similar way? That is, is there any way of expanding the following determinant as a sum of products of minors of order $2\times 2$ of the form $\Delta_{ij}$? $$0=\left|\begin{array}{cccc}
	a_0 & a_1 & \cdots & a_n \\
	b_0 & b_1 & \cdots & b_n \\
	\vdots & \vdots & \cdots & \vdots \\
	a_0 & a_1 & \cdots & a_n \\
	b_0 & b_1 & \cdots & b_n 
\end{array}\right|$$
(of course, one must take into account the parity of $n$). I need it in order to find the set of zeroes that defines a projective algebraic variety.","['linear-algebra', 'determinant']"
2289000,split conjugacy class in $S_n$ into two equal size conjugacy classes in $A_n$,"Let $n>2$ and $\tau\in A_n$ and let $C=\{g\tau g^{-1}|g\in S_n\}$ be the conjugacy class of $\tau$ in $S_n$ . Suppose that there is no odd element $x\in S_n$ such that $\tau x=x\tau$ . Prove that $C$ is a  union of two disjoint conjugacy classes in $A_n$ . I managed to observe that if $\sigma_1\in S_n$ an even element and $\sigma_2\in S_n$ an odd element, then: $\sigma_1\tau\sigma_1^{-1}\neq\sigma_2\tau\sigma_2^{-1}$ otherwise we get that the odd element $x=\sigma_2^{-1}\sigma_1$ commutes with $\tau$ . So, I got one conjugacy class to be the conjugacy class of $\tau$ in $A_n$ , say $Q$ . It is now clear that it contains all the elements in $C$ of the form $g\tau g^{-1}$ for $g$ even. But I couldn't prove that $C\setminus Q$ can be generated by a conjugacy class in $A_n$ and moreover the sizes equivalence $|Q|=|C\setminus Q|$ .",['group-theory']
