question_id,title,body,tags
2666226,Find a generalized path cover of a square graph,"Given a directed $n\times n$ square graph as shown in the figure with $n^2$ nodes. Find a set of directed paths $\mathcal P$ from $s$ to $t$ with the minimum cardinality (i.e, minimum number of paths in $\mathcal P$) such that any pair of reachable vertices is contained in at least one path in $\mathcal P$. Two vertices is reachable if there exists an directed path between them. For example,
   if node $v$ is below and on the right node $u$, then $u$ and $v$ is reachable (see figure). I have solved this problem for small $n$ by trial and error but I have no idea to generalize it. Can anyone give me some hints? or tell me if this problem is NP-hard? Many thanks","['graph-theory', 'np-complete', 'discrete-optimization', 'discrete-mathematics']"
2666274,Are one-point sets always compact in any topological spaces?,"From the definition of compactness, I think one-point sets are always compact in any topological space. But, I am not sure about my judgement. Am I correct?","['general-topology', 'compactness']"
2666305,Standard Error of Median,"The following question is from Modern Mathematical Statistics (Devore). Consider the following observations:
0.83, 0.88, 0.88, 1.04, 1.09, 1.12, 1.29, 1.31, 1.48, 1.49, 1.59, 1.62, 1.65, 1.71, 1.76, 1.83 Assume that the distribution of the observations is normal. b. Calculate a point estimate of the median of the observations and state which estimator you used.
e. What is the estimated standard error of the estimator that you used in part (b). Here are my responses:
$$\\$$b. Given the assumption of normality, it is reasonable to use $\bar{x}$ as an estimate of the population median.In this case, $\bar{x}=1.3481$
$$\\$$e. Here I am unsure how to proceed. Is there a general formula for the standard error of a point estimate?",['statistics']
2666326,"Is it true that if $A^4 = I$, then $A^2 = \pm I$? [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question So for linear algebra, I either need to prove that, for all square matrices, if $A^4 = I$, then $A^2 = \pm I$, or find a counterexample of this statement. Can anyone help please? Thanks!","['matrices', 'linear-algebra']"
2666362,Binomial Coefficient deck of cards probability question,"A regular deck of 52 playing cards has 13 ranks in 4 suits. The ranks of Jack, Queen, King and Ace of each suit are top cards. Suppose you are randomly dealt seven cards. What is the probability of getting three top cards in the same suit and any four cards in another suit (but all
four in one suit)? This is what I was thinking of calculating but am completely unsure: $$
   { \begin{pmatrix}
    4 \\
    3 \\
    \end{pmatrix}
  × \begin{pmatrix}
    39 \\
    4 \\
    \end{pmatrix}  × \begin{pmatrix}
    9 \\
    4 \\
    \end{pmatrix} \over
\begin{pmatrix}
    52 \\
    7 \\
    \end{pmatrix} } =  0.30986...$$ Any help appreciated. Thanks.","['combinatorics', 'binomial-coefficients', 'probability']"
2666390,Proving that if $x>0$ then $\frac{x-(x^2+1)\arctan(x)}{x^2(x^2+1)}$ is less than $0$,"How do I show that for $x>0$:
$$\frac{x-(x^2+1)\arctan(x)}{x^2(x^2+1)} < 0$$ I tried to do it somehow using the fact that $$\frac{\arctan(x)}{x} < 1$$ but still didn't figure it out...","['inequality', 'trigonometry', 'calculus']"
2666393,Orthogonality of eigenvectors of a positive operator in the polar decomposition,"Let $T : H \rightarrow H$ be a compact operator ($H$: complex Hilbert space). Then $|T| = (T^* T)^{1/2}$ is a compact self-adjoint operator. If $\{x_j\}$ is an orthonormal basis of $(\ker |T|)^{\perp}$, is it true that $\langle Tx_i, x_j \rangle = 0$ for $i\neq j$? I tried to check this by using the polar decomposition of $T$, that is, $T = U|T|$ where $U$ is a partial isometry. One can obtain that $\langle Tx_i x_j \rangle = \lambda_i \langle Ux_i, x_j\rangle = \lambda_i \langle Ux_i, U^*Ux_j \rangle  = \lambda_i \langle U^2 x_i, Ux_j\rangle .$ From this, is it possible to deduce that $\langle Tx_i, x_j\rangle = 0$ for $i\neq j$? Any help will be appreciated!","['functional-analysis', 'eigenvalues-eigenvectors', 'orthogonality', 'hilbert-spaces']"
2666461,Use Stein's Identity to Calculate Variance of X Bar Squared,"Suppose that I have a random sample where each random variable is iid normally distributed with mean $\mu$ and variance $\sigma^2$.  Suppose I want to calculate the variance of $\bar{X}^2$ ""using Stein's idendity.""  I'm not quite sure that I understand how Stein's identity applies to this situation.  I know that the normal distribution is part of the linear exponential family, but I don't understand how that can help me find properties about $\bar{X}^2$.  Can somebody please show how this is supposed to work?  Thank you.","['normal-distribution', 'probability-theory', 'statistics', 'probability', 'parameter-estimation']"
2666484,Higher dimensional equivalent of complex numbers,"If complex numbers are in some sense 2 dimensional numbers, would it be useful or logical to extend the complex number system to a system of 3-dimensional or even n-dimensional numbers? If this does not make sense in general, why does it make sense only to extend from the 1st dimension to the 2nd dimension? What is special about 2-dimensional numbers that they are needed but n-dimensional numbers are not? I know that we have $R^k$, which is in some sense a field of $k$ dimensional numbers, but that is very different from the way in which complex numbers are constructed. So my question is could the complex numbers be extended to a 3rd dimension (or even an nth dimension) in the same way that the real numbers are extended to the complex numbers, in which the properties of complex numbers are preserved as a subset of this higher dimensional space?","['complex-analysis', 'real-analysis']"
2666489,Prove by induction $ 1+3+\dots+(2n-1)=n^2 \forall n\in \Bbb N_1 $,"I need help with this exercise.
What I've done so far is: 1st: Prove it with $n = 1$ (for example): $$ (2\times1-1) = 1^2 $$
  $$ 1 = 1 $$ which is true 2nd: if $P(n)$ is true, then $P(n+1)$ should be true as well.
So now I substitute $n$ for $m+1$ $$ n = m+1\\
\text{and}\\
P(n) \implies P(m+1) $$ Therefore: $$1+3+\dots+(2(m+1)-1) = (m+1)^2 \\
1+3+\dots+(2m+2-1) = (m+1)^2 \\
1+3+\dots+(2m+1) = m^2+1+2m $$ Now, the problem is that I don't know how to prove it/conclude the exercise.
Could someone help me please?
Thank you so much If something's not very clear, please let me know. I'll try to explain again","['induction', 'discrete-mathematics']"
2666546,Prove that $f(\limsup A_n)\subset \limsup f(A_n)$.,Prove that $f(\limsup A_n)\subset \limsup f(A_n)$. Give an example where $f(\limsup A_n)\neq \limsup f(A_n)$. I guess where I'm having trouble with this is what exactly does it mean to $f(\limsup A_n)$. I know what the $\limsup A_n$ but when it turns into a function then I dont know where to go from there.,"['real-analysis', 'elementary-set-theory']"
2666613,Is the area the integral of the perimeter?,"Let $A$ be a compact subset of the plane with piecewise smooth boundary. Define $A_r$ to be the set $\{x\in \mathbb{R}^2: dist(x,A)\leq r\}$, i.e. the points with distance at most $r$ from $A$. Motivate by the case of a circle, I was wondering if the following formula holds $$|A_r|=|A|+ \int_{0}^r L(\partial A_s) ds,$$
where $| |$ denotes the area and $L(\partial A_s)$ the perimeter of $A_s$. Does this formula hold in general? What if $A$ is a convex domain or perhaps a finite union of disks?","['convex-geometry', 'real-analysis', 'convex-analysis', 'geometry']"
2666623,Understanding cyclic groups with Cayley tables,"Question. Let $G = \{a,b,c,d,f\}$. Given that $(G, \cdot)$ is a cyclic group with $G=\langle d \rangle$ and Cayley table: \begin{array}{c|cc}
\cdot & a & b & c & d & f\\
\hline 
a&  c & a & f & b & d \\
b&  a & b & c  & d  &f  \\
c& f& c& d& a& b \\
d& b & d& a& f & c  \\
f& d& f& b& c & a
\end{array} I need to complete this table. I know that the generator will be all the powers of d such that $d^1 ... d^4 ∈ G$, where $n ∈ Z$. My understanding of that statement is each row and column of d will contain each element of G only once. I know cyclic groups are abelian, but I only used the commutative property thus far to fill in 2 cells. What else do I need to know in order to fill in the table? Thank you.","['abstract-algebra', 'group-theory', 'cyclic-groups', 'cayley-table']"
2666630,"Determining if following sets are closed, open, or compact","I'm doing some topology now and I'm honestly very confused on how to formally say that a set is open or closed or compact. Like especially with open sets, the proof for it (balls must exist of radius $r$) seems very arbitrary (since the radius can be as small as possible). It just makes more sense to me from a geometric standpoint (i.e drawing it out). Unfortunately, this doesn't suffice in my class so I'm asking for help for the following questions My thoughts for the following questions are such: 1a) already solved 1b) Take the point $(n,0)$. At $n=0$, the point is in $B$, but if you take the point as $n$ approaches infinity, the point alternates between being both in and not in $B$, so by convergence, the set is not closed. Then I'm completely confused on how to do the ball proof to show that it is/is not open. 1c) $C$ is neither closed nor open. If you choose the point $(0,1,1/n)$, then it does lie in $C$. But if you take the limit as $n$ approaches infinity, then the point converges to $(0,1,1)$, which is not in the set. So it is not closed. Then if you place a ball on $(0,1,1)$, some points will lie outside of $C$, so it is not open. 1d) For starters, $D$ is a parabolic cylinder (I think). I have no idea what to do here. I know a compact set is a set that is both bounded and closed. 2a) This set is bounded because of the squared terms and the equals sign. Since this set does contain its boundary points, this set must be closed? So it's compact? 2b) This set is an elliptic cone. I don't think it's bounded because it extends infinitely? And so it must not be closed either? Really confused here 2c) The left-hand side is unnecessary, since $e^x+e^y$ won't ever be zero or less than $0$. So if we take the point $(1/n,1/n)$, this exists in $C$, and the limit of the point as $n$ approaches infinity does also exist in $C$, so the set is closed. Then I think this set is also bounded (kind of more ""duh"" to me than any formal mathematical way to show it). So it's compact? Any help or tips on how to approach these problems would be greatly appreciated :)",['general-topology']
2666648,Why must it be true that approximating all the derivatives gives you the original function?,"I am trying to understand the intuition behind Taylor/Maclaurin series. You have some differentiable function $f(x)$ and you want to make a series $g(x)$ where $f^{n}(x) = g^{n}(x)$, i.e. the $n$th derivatives of each give you the same output for some input. Assuming we have this matching derivative output concept in place, how do we know this necessarily means $f(x)$ and $g(x)$ are equivalent representations of each other? Normally these approximations are made in the neighborhood of $x=0$ (and yes we could use $x=a$ but for simplicity I'd like to stick with $0$), so it makes sense that $f(x)$ and $g(x)$ are equal for any $n$th derivative you want to compute at $x=0$ since that is how we derived $g(x)$ in the first place. But what exactly lets us then take $g(x)$ and say ""This will also work for any other $x$, not just $0$, since it is an equivalent to $f(x)$""? In other words I don't see why it is obvious that through the method of creating the Taylor/Maclaurin series $g(x)$ we must necessarily have an equivalent for $f(x)$.","['derivatives', 'taylor-expansion', 'sequences-and-series', 'calculus']"
2666653,Can some proof that $\det(A) \ne 0$ be checked faster than matrix multiplication?,"We can compute a determinant of an $n \times n$ matrix in $O(n^3)$ operations in several ways, for example by LU decomposition. It's also known (see, e.g., Wikipedia ) that if we can multiply two $n \times n$ matrices in $M(n)$ steps, then we can compute the determinant in $O(M(n))$ steps as well. However (and this is the motivating observation here), as in this question , if $\det(A) = 0$, then I can find a vector $\mathbf x$ such that $A \mathbf x = \mathbf 0$, and tell you: ""$A$ is a singular matrix. Here is a vector $\mathbf x$ such that $A \mathbf x = \mathbf 0$"". I might have done lots of work to find $\mathbf x$, but you can check my work in only $O(n^2)$ steps by computing $A \mathbf x$: faster than you could compute $\det(A)$ without help. Is it possible, in a similar way, for me to take a matrix $A$ with $\det(A) \ne 0$, and write a proof of this fact which you can also check faster than computing $\det(A)$? (A perfect solution would check the proof in $O(n^2)$ steps; this is best possible, since we need that many steps to even read $A$.) Observations: A probabilistic argument exists based on Freivalds's algorithm : I give you $A^{-1}$, and leave you to check that $AA^{-1} = I$. As far as we know, this still needs $O(M(n))$ time to do deterministically, but a probabilistic algorithm can take $O(n^2)$ steps to achieve a one-sided error rate of $\frac12$: if $A^{-1}$ is correct, it will always say ""yes"", and if $A^{-1}$ is wrong, it will say ""no"" with probability at most $\frac12$. As a result, you can take $O(n^2\log n)$ steps to achieve  one-sided error rate of $n^{-k}$ for any $k$. More generally, we could ask for a proof that $\det(A) = x$ for any specific nonzero value of $x$. This was the original question, but there's no hope of solving that for general $x$ if we can't even solve the $\det(A) \ne 0$ case. (After all, a proof that $\det(A)$ has a specific nonzero value $x$ is in particular a proof that $\det(A)$ has some nonzero value.)","['matrices', 'computational-complexity', 'linear-algebra', 'determinant']"
2666659,Simplify $\frac{ae^{-\frac{a}{x}}+be^{-\frac{b}{x}}}{e^{-\frac{a}{x}}+e^{-\frac{b}{x}}}$,Do you guys have any way of simplifying: $$f(x) =\frac{ae^{-\frac{a}{x}}+be^{-\frac{b}{x}}}{e^{-\frac{a}{x}}+e^{-\frac{b}{x}}}?$$ I am having a hard time fining a way to visualize this function. Is there any way I could change the constants to make it a cosh?,['trigonometry']
2666678,Killing Flies with a Checkerboard Flyswatter,"Original Problem Six flies rest on a table. You have a swatter with a
checkerboard pattern, much larger than the table. Show that
there is always a way to position and orient the swatter to kill
at least five of the flies. Each fly is much smaller than a swatter
square and is killed if any portion of a black square hits any
part of the fly.
(Source: The 2017 UW Math Hour Olympiad ). My Problem Is it always possible to kill all $6$ flies? More generally, if there are $n$ flies on the table, how many can we guarantee to kill? Progress I haven't really made that much progress towards solving the stronger variant. The original problem can be proven in the following manner: Orient the flyswatter such that one of its ""edges"" (if the flyswatter is placed on the Cartesian coordinate plane with one black square being $0\leq x,y\leq 1$, the edges are the lines $x=n$ or $y=m$ for integer $m,n$) coincides with the line between flies $1$ and $2$. Now, ""slide"" it along this line so that fly $3$ is also on an edge. So, flies $1,2,$ and $3$ are now all killed. We need to kill two of the remaining $3$ flies. We now consider this orientation and placement with the flyswatter ""flipped"" so that black squares are now white and white are now black. Since each of the $3$ remaining flies is killed by one of these orientations, at least one of them must kill $2$ of the remaining flies, and $5$ total. This proof, when extended, shows that we can kill at least $$\left\lceil \frac{n+3}{2}\right\rceil$$ flies if we have $n$, but doesn't seem to be terribly extendable beyond there. I tried to prove that, for at least one of the $\binom{6}{2}\cdot 4$ choices of the original flyswatter configuration, all $3$ remaining flies are killed by the same orientation, but I was unsuccessful in relating any one configuration with another. The only idea I had was that it might be possible to prove that one can choose ""fly $3$"" in a smarter fashion to guarantee that all the remaining $3$ flies are killed by the same orientation, but I was unable to prove this and, even if proven, it is unlikely to generalize. I was also unable to construct a counterexample (or even one that looks like a counterexample without a proof that it is one).","['pigeonhole-principle', 'combinatorics', 'contest-math']"
2666770,What is the inverse of $\left[ \sum_{k=1}^{j} \left\lfloor \frac{i}{k} \right\rfloor \right]_{n \times n}$?,"For $n \in \mathbb{N}$, let $M_{n}$ denote the $n \times n$ integer matrix whereby the $(i, j)$-entry of $M_{n}$ is equal to $\sum_{k=1}^{j} \left\lfloor \frac{i}{k} \right\rfloor$, for all indices $i$ and $j$. For example, we have that:
 $$ M_{5} = \left(
\begin{array}{ccccc}
 1 & 1 & 1 & 1 & 1 \\
 2 & 3 & 3 & 3 & 3 \\
 3 & 4 & 5 & 5 & 5 \\
 4 & 6 & 7 & 8 & 8 \\
 5 & 7 & 8 & 9 & 10 \\
\end{array}
\right).$$ Since there are many important number-theoretic properties related to summations of the form $\sum_{k=1}^{n} \left\lfloor \frac{n}{k} \right\rfloor$ , it seems natural to consider generalizations and variants of such sums; this leads us to consider matrices of the form $M_{n} = \left[ \sum_{k=1}^{j} \left\lfloor \frac{i}{k} \right\rfloor \right]_{n \times n}$. Using elementary row operations inductively, it is easily seen that $M_{n}$ is invertible, and that the entries in $M_{n}^{-1}$ are in $\mathbb{Z}$. However, it is unclear as to how to construct an explicit formula for the entries of $M_{n}^{-1}$. It appears that the initial column in $M_{n}^{-1}$ may be evaluated in terms of the Möbius function , as indicated in the following proposition, which is given as a conjecture in the On-Line Encyclopedia of Integer Sequences entry labelled as A092155 . Proposition 1: For $n \in \mathbb{N}_{\geq 2}$, the first $n-1$ entries in the first column of $\left(-M_{n}\right)^{-1}$ are the same as the first $n-1$ entries in the sequence A092155 given by the first differences of
$$\left(\mu(n)- \mu\left(\frac{n}{2}\right) : n \in \mathbb{N} \right),$$ letting $\mu$ denote the Möbius function, adopting the convention whereby $\mu(q)$ vanishes for $q$ in $\mathbb{Q} \setminus \mathbb{Z}.$ Why does does the above property hold for all $n \in \mathbb{N}_{\geq 2}$? This is an intriguing question, in part because the sequence A092673 given by expressions of the form $\mu(n)- \mu\left(\frac{n}{2}\right)$ is known to have interesting connections with other number-theoretic sequences such as the ruler function . To illustrate the conjecture noted above concerning A092155 , we begin by computing the inverse of $-M_{5}$: $$\left( -M_{5} \right)^{-1} = \left(
\begin{array}{ccccc}
 -3 & 1 & 0 & 0 & 0 \\
 1 & -2 & 1 & 0 & 0 \\
 2 & 0 & -2 & 1 & 0 \\
 -2 & 1 & 1 & -2 & 1 \\
 1 & 0 & 0 & 1 & -1 \\
\end{array}
\right).$$
We thus observe that the first four entries along the first column of the above matrix are the same as the first four entries in A092155 , namely:  $-3$, $1$, $2$, and $-2$. Computing the inverse of 
$$-M_{10} = \left(
\begin{array}{cccccccccc}
 -1 & -1 & -1 & -1 & -1 & -1 & -1 & -1 & -1 & -1 \\
 -2 & -3 & -3 & -3 & -3 & -3 & -3 & -3 & -3 & -3 \\
 -3 & -4 & -5 & -5 & -5 & -5 & -5 & -5 & -5 & -5 \\
 -4 & -6 & -7 & -8 & -8 & -8 & -8 & -8 & -8 & -8 \\
 -5 & -7 & -8 & -9 & -10 & -10 & -10 & -10 & -10 & -10 \\
 -6 & -9 & -11 & -12 & -13 & -14 & -14 & -14 & -14 & -14 \\
 -7 & -10 & -12 & -13 & -14 & -15 & -16 & -16 & -16 & -16 \\
 -8 & -12 & -14 & -16 & -17 & -18 & -19 & -20 & -20 & -20 \\
 -9 & -13 & -16 & -18 & -19 & -20 & -21 & -22 & -23 & -23 \\
 -10 & -15 & -18 & -20 & -22 & -23 & -24 & -25 & -26 & -27 \\
\end{array}
\right),$$
we obtain the matrix
$$\left(-M_{10}\right)^{-1} = \left(
\begin{array}{cccccccccc}
 -3 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & -2 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 2 & 0 & -2 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
 -2 & 1 & 1 & -2 & 1 & 0 & 0 & 0 & 0 & 0 \\
 3 & 0 & -1 & 1 & -2 & 1 & 0 & 0 & 0 & 0 \\
 -3 & 0 & 1 & 0 & 1 & -2 & 1 & 0 & 0 & 0 \\
 1 & 0 & 1 & -1 & 0 & 1 & -2 & 1 & 0 & 0 \\
 0 & 1 & -2 & 1 & 0 & 0 & 1 & -2 & 1 & 0 \\
 2 & -2 & 1 & 1 & -1 & 0 & 0 & 1 & -2 & 1 \\
 -2 & 1 & 0 & -1 & 1 & 0 & 0 & 0 & 1 & -1 \\
\end{array}
\right),$$ 
 and we find that the first nine entries
  $$ -3, 1, 2, -2, 3, -3, 1, 0, 2$$
  are the same as the first nine entries of A092155 . Why are the entries of $M_{n}^{-1}$ above the super-diagonal all equal to $0$? It is not obvious why this would be true in general. What is the main diagonal of $M_{n}^{-1}$ of the form $3, 2, 2, ..., 2, 1$? It is not clear how this can be proven to be true for $\mathbb{N}_{\geq 3}$. A conjectured formula for the lower-left entry for $M_{n}^{-1}$ is given in A092673 . Proposition 2: The $(n, 1)$-entry of $M_{n}^{-1}$ is $\mu(n) - \mu\left(\frac{n}{2}\right)$ for $n \in \mathbb{N}$. How can we prove the above proposition, using known results concerning the Möbius function? It should be noted that there is a known formula for $\mu(n) - \mu\left(\frac{n}{2}\right)$ involving a summation containing the floor function, but it is not clear how this known identity can be used to attack the above propositions. In 2004, Jon Perry noted the following result on A092673 . Letting $x$ be an indeterminate and writing $s_{1} = x$, and letting
  $$s_{i} = \binom{i+1}{2} - \sum_{j=1}^{i-1} s_{j}
  \left\lfloor\frac{i}{j}\right\rfloor$$
  for indices $i$ in $\mathbb{N}_{\geq 2}$, we have that the coefficient 
   of $x$ in $s_{n}$ is equal to $\mu(n) - \mu\left(\frac{n}{2}\right)$. How is this result related to the above propositions? We conclude with the following questions. Question 1: What is $M_{n}^{-1}$? Question 2: How can we find an explicit number-theoretic formula for a given entry in $M_{n}^{-1}$? Question 3: Have matrices of the form $M_{n}^{-1}$ been studied previously? Thank you, John M. Campbell","['matrices', 'elementary-number-theory', 'mobius-function', 'sequences-and-series', 'ceiling-and-floor-functions']"
2666823,Roots of $f(x)=x^3-x^2-2x+1$,"We can prove using a monotony study that the function $f(x)=x^3-x^2-2x+1$ has three real roots. However, when I solve the equation $f(x)=0$ using Mathematica, I get
$$x_1=\frac{1}{3}+\frac{7^{2/3}}{3 \left(\frac{1}{2} \left(-1+3 i \sqrt{3}\right)\right)^{1/3}}+\frac{1}{3} \left(\frac{7}{2} \left(-1+3 i \sqrt{3}\right)\right)^{1/3}$$
$$x_2=\frac{1}{3}-\frac{\left(\frac{7}{2}\right)^{2/3} \left(1+i \sqrt{3}\right)}{3 \left(-1+3 i \sqrt{3}\right)^{1/3}}-\frac{1}{6} \left(1-i \sqrt{3}\right) \left(\frac{7}{2} \left(-1+3 i \sqrt{3}\right)\right)^{1/3}$$
$$x_3=\frac{1}{3}-\frac{\left(\frac{7}{2}\right)^{2/3} \left(1-i \sqrt{3}\right)}{3 \left(-1+3 i \sqrt{3}\right)^{1/3}}-\frac{1}{6} \left(1+i \sqrt{3}\right) \left(\frac{7}{2} \left(-1+3 i \sqrt{3}\right)\right)^{1/3}$$ Since those roots are real, then maybe there's a way to write them without using the complex number $i$?","['roots', 'polynomials', 'complex-numbers', 'analysis']"
2666832,Concrete Example: Subsheaf is not Quasi-Coherent,"In II.5.2.4 of Hartshorne (the example) Hartshorne remarks: If $Y$ is a closed subscheme of a scheme $X$, then the sheaf $\mathcal{O}_X| _Y$ is not in general quasi-coherent on $Y$. In fact, it is not even a sheaf of $\mathcal{O}_Y$ modules in general. I would like to see a concrete example of this. I know that such examples must exist, since we have the later proposition: Let $X$ be an affine scheme, $O \to \mathcal{F'} \to \mathcal{F} \to \mathcal{F''} \to 0$ an exact sequence of sheaves of $\mathcal{O}_X$ modules, and $\mathcal{F'}$ is quasi-coherent. Then the exact sequence $$0 \to \Gamma(X, \mathcal{F'}) \to \Gamma(X, \mathcal{F}) \to \Gamma(X, \mathcal{F''}) \to 0$$ is exact. I have examples where the contrapositive of this theorem holds (i.e. exactness fails to induce exactness on global sections) - in fact I think there are some exercises to previous sections that fashion us with such examples. However, I would like a concrete example illustrating the failure without the need of any additional tools. I suppose I could simply chase through a proof of the contrapositive with a particular example, but ideally I would an explicit calculation. This isn't homework - it's going in my notes for an oral exam on algebraic geometry, and I like to have concrete examples I can use to calculate, since my instructor likes to see explicit examples (and I do too).",['algebraic-geometry']
2666834,What is the Difference between Frequency and Density in a Histogram?,"I know count is simply the amount of times the observations occur in a single bin width, but what is density?",['statistics']
2666862,"Idea is correct, proof lacks rigor, coefficient of $t$ in $\det(I+tA)$","The goal of this exercise is to find the coefficient of $t$ in the polynomial $\det(I+tA)$ where $I, A \in Mat_n(\mathbb R)$. I've thought about this long and hard as I am combinatorically challenged (it's the most difficult branch of mathematics for certain) and I'm pretty sure I have a convincing argument, but it feels handwavey and lacks rigor. I'd like someone to review it and possibly suggest way to make it less verbal and more rigorous. My argument uses Laplace expansion, initially using the first column of $I+tA$. $\det(I+tA) = (1+ta_{1,1})\begin{vmatrix}1+ta_{2,2} & ta_{2,3} & \dots & ta_{2,n}\\ta_{3,2} & 1+ta_{3, 3} & \dots & ta_{3,n}\\ \vdots & \vdots & \dots & \vdots \\ ta_{n, 2} & ta_{n, 3} & \dots & 1+ta_{n,n}\end{vmatrix} -ta_{2,1}\det(B_2) + ta_{3,1}\det(B_3)-\dots+(-1)^{n+1}ta_{n, 1}\det(B_n)$ Where $B_i$ are some sub matrices with accordance to Laplace. Notice that since we used the first column in our original expansion, the first row of every $B_i$ is just $\begin{pmatrix}ta_{1,2} \dots ta_{1,n}\end{pmatrix} = t\begin{pmatrix}a_{1,2} \dots a_{1,n}\end{pmatrix} $ if we define $B_i'$ to be exactly the same as $B_i$ except the first row is divided by $t$, then by determinant rules $\det(B_i) = t\det(B_i')$, and so: $-ta_{2,1}\det(B_2) + ta_{3,1}\det(B_3)-\dots+(-1)^{n+1}ta_{n, 1}\det(B_n) = -t^2a_{2,1}\det(B_2') + t^2a_{3,1}\det(B_3')-\dots+(-1)^{n+1}t^2a_{n, 1}\det(B_n')$ and they only contain non linear terms of $t$. So they don't matter to us at all. We can just focus on the first determinant. But now we can just use the exact same argument on $\begin{vmatrix}1+ta_{2,2} & ta_{2,3} & \dots & ta_{2,n}\\ta_{3,2} & 1+ta_{3, 3} & \dots & ta_{3,n}\\ \vdots & \vdots & \dots & \vdots \\ ta_{n, 2} & ta_{n, 3} & \dots & 1+ta_{n,n}\end{vmatrix}$! The only thing that will matter is the first element and its leading minor. The others can be discarded as they are higher order of $t$. We will use it again and again until at the end we are only left with $\prod_{i=1}^{n}(1+ta_{i,i})$. The answer is hidden somewhere in this product. Since we are only interested in linear terms, we are not allowed to multiply $ta_{i,i}$ with $ta_{j,j}$. So every $ta_{i,i}$ can only be multiplied by $1$. So overall we should have $ta_{1,1} + ta_{2,2} + \dots ta_{n,n} = tTrace(A)$. Is this result correct? is this ""proof"" valid? It feels too wishy washy and verbal.","['proof-verification', 'determinant', 'proof-writing', 'trace', 'linear-algebra']"
2666905,How can I prove $\tau$ is a topology on $\mathbb{N}$,"Consider the set $X = \mathbb{N}$, and let $\tau$ be the collection of all subsets $A \subset \mathbb{N}$ for which $\mathbb{N}\setminus A$ is finite, along with the empty set. I want to show $\tau$ is a topology on $\mathbb{N}$. I know that the requirements for a set to be a topology is: $\emptyset$ and $X$ are in $\tau$ The union of the elements of any subcollection of $\tau$ is in $\tau$ The intersection of the elements of any finite subcollection of $\tau$ is in $\tau$. For this problem, I know that the first condition holds. Can someone please help me show that the other two conditions for a topology hold as well so that I can prove that $\tau$ is a topology on $\mathbb{N}$",['general-topology']
2666919,"Probability of throwing two dice twice, and getting a $7$ on the first throw","This one is pretty simple, but the textbook answer is way off from mine. Getting a $7$ on a $2$-dice throw is $\frac 6{36} =\frac16$, and since it doesn't care about the second throw it should be $\frac16$, right? The textbook says it's $\frac5{18}$, but I don't know from where.","['statistics', 'probability', 'dice']"
2666935,System of equations trigonometric in Reals,"Solve in Reals $$\begin{cases}
\cos x+\cos y=\frac{1}{2} \\ 
\tan x +\tan y=2\\
\text{I tried:}\\ 
\frac{\sin x}{\cos x}+\frac{\sin y}{\cos y}=2\rightarrow \sin x \cos y+\sin y\cos x=2\cos x\cos y\rightarrow \\
\frac{1}{2}[\sin(x-y)+\sin(x+y)]
+\frac{1}{2}[\sin(x+y)-\sin(x-y)]=2\cos x\cos y\\ 
\sin(x-y)+\sin(x+y)+\sin(x+y)-\sin(x-y)=4\cos x\cos y 
\rightarrow\\ 
2\sin(x-y) = 4\cos x\cos y\\
\sin(x-y)=2\cos x\cos y
\rightarrow \sin x\cos y-\cos x\sin y=2 \cos x\cos y
\\
\sin x\cos y-\cos x\sin y-2\cos x\cos y=0
\rightarrow \sin x\cos y-\cos x(\sin y+2\cos y)=0???
\end{cases}$$","['trigonometry', 'systems-of-equations']"
2666942,Subset of totally bounded set is totally bounded.,"Suppose  $(X,d)$ is a metric space where $A\subseteq X$ is totally covered i.e. $\forall \epsilon >0$ $\exists \{a_1,a_2,\ldots,a_m\}\in A $ s.t $A\subseteq \bigcup_{1,\ldots,m}B(a_i,\epsilon)$. Given that $B\subseteq A$ show that $B$ is totally covered. I can't seem to show  - with the given definition - that the centers of the balls would now come from $B.$","['general-topology', 'elementary-set-theory']"
2666990,Why should a physicist care about measurability of random variables?,"I'm working with some physicists at the moment, and I made the remark that random variables are, technically, defined as measurable functions on some ""background"" probability space, hence requiring the choice of two sets and two sigma algebras.   They immediately asked where the term ""measurable"" came from (I gave the brief history about measuring lengths and areas), and then asked if it had anything to do, in general, with whether or not something was ""measurable in a laboratory"" (I said I wasn't sure).  They then proceeded to say that it was nonsensical to consider any ""non-measurable"" random variables because such things are, almost by definition, not ""interesting"" to the physicist. So, how can I explain to my physicist colleagues that we actually do care about measurability?  Is there an example of a physical quantity which would otherwise be interesting but which turns out to be non-measurable (in the mathematical sense), and which might justify my mathematical nitpickiness to them?  I'm OK with examples from ordinary probability or stochastic process theory.","['probability', 'measure-theory']"
2667008,Probability that connecting two vertices in a dodecahedron will result in a segment inside the dodecahedron,"A regular dodecahedron is a convex polyhedron with 12 regular pentagonal faces and 20 vertices. If two distinct vertices are chosen at random, what is the probability that the line connecting them lies inside the dodecahedron? I know that when you connect to points in the dodecahedron, it cannot result in a segment outside of the dodecahedron. So we have $1-P(\text{Segment On Dodecahedron})=$ desired result. So in order for the segment to be on the dodecahedron, the two vertices have to be on the same face. I'm thinking that the denominator, in this case, would be $\binom{20}2$. However, I'm not sure how to find the numerator. Help is greatly appreciated.","['combinatorics', 'probability', 'geometry']"
2667014,Integrability condition implies boundedness and limit is zero,"I'm having trouble with the following problem. Suppose that $f$ is a uniformly continuous function on $(0,\infty)$ with derivative $f^\prime(x)$ satisfying, $$ \int_0^\infty xf^2(x)dx < \infty, \;\;\;\;\;\;\int_0^\infty x^3(f^\prime(x))^2dx < \infty$$ Prove that $\lim\limits_{x\rightarrow\infty}xf(x) = 0$ . I tried to prove by contradiction. I assumed that there exists $\epsilon > 0$ and a sequence $x_n \rightarrow \infty$ such that $|x_nf(x_n)| > \epsilon$ for all $n$ . Using uniform continuity, I showed that, $$ \int_{x_n-\delta}^{x_n+\delta}xf(x)dx > \epsilon\delta $$ where $\delta$ is the modulus of continuity. Therefore, $$ \int_0^\infty xf(x)dx \geq \sum\limits_{n=1}^\infty\int_{x_n-\delta}^{x_n+\delta}xf(x)dx > \infty $$ My initial reasoning for using this approach was to hopefully use the Cauchy-Schwarz inequality to arrive at the contradiction, $$ \int_0^\infty xf(x)dx \leq \left(\int_0^\infty xf^2(x)dx\right)^{1/2}\left(\int_0^\infty xdx\right)^{1/2} $$ However, obviously the second integral is not finite so this approach probably will not work. Is there a slight modification I can use?","['uniform-continuity', 'real-analysis', 'limits']"
2667019,"Proving that the unit square $\{(x,y) \in \mathbb{R^{2}} | 0<x,y<1\}$ is open in the metric topology on $\mathbb{R^{2}}$ [duplicate]","This question already has an answer here : Show that $(a,b)\times (c,d)$ is an open set in $\mathbb{R}^2$ with the Euclidian metric. (1 answer) Closed 6 years ago . Proving that the unit square $\{(x,y) \in \mathbb{R^{2}} | 0<x,y<1\}$ is open in the metric topology on $\mathbb{R^{2}}$ What I know so far is that for a Metric space with (X,d) where X is a set and d is the metric, the following properties must hold: i) $d(x,y) = 0$ ii) $d(x,y) = d(y,x)$ iii) $d(x,z)\leq d(x,y) + d(y,x)$ (which is the triangular inequality) I know that the metric topology is  the topology on X generated by the basis $\{B_{\epsilon,d}(x): \epsilon > 0, x \in X\}$ I know what all these things mean distinctly but I don't know how I would be able to start a proof like this. Can someone please help?",['general-topology']
2667024,Calculating the sample mean and sample standard deviation from confidence interval,"How to find the sample mean and sample standard deviation if only given the $n$ sample size and that the sample $95%$ confidence interval is $(x, y)$? 
If I was given one of them I would know how to find the other one, but what should I do if both of them are unknown?","['statistics', 'confidence-interval']"
2667082,Numbers written in both forms,"I have come across the OEIS series A031363 . It has this description: Positive numbers of the form $x^2+xy-y^2$; or, of the form $5x^2-y^2$. So it is saying that all numbers that can be written in the form $x^2+xy-y^2$ can be written as $5x^2-y^2$. I am a beginner at Number Theory, so any tips or hints on how to proof it would be great. EDIT: I have done a tiny computer search on it, and confirmed that all numbers (< 10000) that can be written in the first form can also be written in the second form. So it is saying that both form is identical.",['number-theory']
2667111,How do we derive the expression for $e^x$ from $e$?,"Trying to go in historical order here and begin with Bernoulli's formulation for $e$: $$e = \lim_{n \to \infty} (1 + 1/n)^n$$ How do we then make the jump to $$e^x = \lim_{n \to \infty} (1 + x/n)^n$$ I had tried doing this: $$e^x = (\lim_{n \to \infty} (1 + 1/n)^n)^x$$ $$e^x = \lim_{n \to \infty} (1 + 1/n)^{nx}$$ Let $m = nx$ so $n = m/x$. As $n$ goes to infinity, $m$ also goes to infinity, so: $$e^x = \lim_{m \to \infty} (1 + x/m)^{m}$$ (although we could relabel with $n=m$ I just use $m$ to use a different one) But I was told that I'm skipping many unproven assumptions doing this. Is there an easy way to prove what I am missing or is there an easier way to arrive at the result?","['exponential-function', 'proof-explanation', 'calculus', 'limits']"
2667170,Proof of spectral radius bound $\min_i \sum_j a_{ij} \le \rho(A) \le \max_i \sum_j a_{ij}$,"I was reading one of the theorem in Roger A. Horn's Matrix Analysis and yet failed to understand how to prove it. Let $A=[a_{ij}] \in M_n$ be nonnegative and $\rho(A)$ is spectral radius of $A$.  Then
$$\min_{1 \le i \le n} \sum_{j=1}^n a_{ij} \le \rho(A) \le \max_{1 \le i \le n} \sum_{j=1}^n a_{ij}$$
and
$$\min_{1 \le j \le n} \sum_{i=1}^n a_{ij} \le \rho(A) \le \max_{1 \le j \le n} \sum_{i=1}^n a_{ij}$$
Can anyone help me to give me brief explaination and detailed proof of this theorem?","['matrices', 'eigenvalues-eigenvectors', 'spectral-radius']"
2667176,Mathematical induction on Lucas sequence and Fibonacci sequence,"I'm trying to prove the following:
$$L_k^2-5F_k^2=4(-1)^k\qquad k\ge1$$ $L_k$ is the $k$th term of the Lucas numbers and $F_k$ is the $k$th term of the Fibonacci sequence. I've tried using mathematical induction, however it's not working out too well. I tried starting out by manipulating $L^2_{k+1}-5F^2_{k+1}$, but I can't prove that it equals $4(-1)^{k+1}$. Any help is greatly appreciated!","['induction', 'lucas-numbers', 'fibonacci-numbers', 'discrete-mathematics']"
2667267,The measurability of convolution in locally compact group,"Prove or disprove: Let $G$ be a locally compact Hausdorff topological group and $\mu$ be a left haar measure on $G$. $f\in L^1(G,\mu)$, $g\in L^{\infty}(G,\mu)$. Then $f*g$ is measurable with respect of $(G,\mu)$. (I can prove it when $(G,\mu)$ is $\sigma$-finite. But I don't know if it is true when $(G,\mu)$ isn't $\sigma$-finite.)","['fourier-analysis', 'harmonic-analysis', 'locally-compact-groups', 'convolution', 'measure-theory']"
2667285,A map is continuous if and only if the restrictions are,"I want to find out if the following statement is true or false, and prove why: Let $X$ be a topological space. Suppose $X=A \cup B$ and $f:X \rightarrow Y$ is a map whose restrictions to $A$ and $B$ are $f_A:A \rightarrow Y$ and $f_B:B \rightarrow Y$. Then $f$ is continuous if and only if $f_A$ and $f_B$ are continuous. I'm not really sure where to start with a proof on this. What's a good way to prove a map is continuous in this context?",['general-topology']
2667287,summing terms to the cardinality all possible subsets of a given set,"I am  facing the problem of computing the sum
$$\sum_{L\subset S}(-1)^{|S|-|L|},$$
where $|S|$ denotes the cardinality of a set $S$ is finite and $L$ is a proper subset of $S$.
Thank you!","['combinatorics', 'summation', 'cardinals']"
2667463,How to prove convergence in $p$-th power and in probability?,"$\def\e{\mathrm{e}}$Let $X_n$ be i.i.d Gaussian random variables. Prove convergence in probability and $p$-th power of any $p$ for the following sequence of random variables: 
  $$Y_{n} = \frac 1n\sum_{j=1}^\infty X_{j}.$$ The problem is that I do not know how to do it for the Gaussian measure in general because the exercises do not say for the real line. I know I would need to find the expectation of one of the $X_n$ and the variance, but I do not know even how to start. I am lost. Also, here is my teacher's proof: It suffices to consider $p$ even integers. The remaining cases will follow using Holder's inequality. We note that$$
E(X^{2k}) = \left. \left( \frac{\partial}{\partial t} \right)^{2k} E(\e^{tX}) \right|_{t = 0}.
$$
  For $\displaystyle X \equiv \frac{1}{n} \sum\limits_{j = 1}^n X_j$ with $X_j$ being i.i.d Gaussian r.v.'s with mean $0$ and variance $σ^2 \in (0, \infty)$, one has$$
E(\e^{tX}) = \left( E\left( \exp\left( \frac{1}{n} tX_1 \right) \right) \right)^n = \left( \exp\left( \frac{1}{n^2} t^2 σ^2 \right) \right)^n = \exp\left( \frac{1}{n} t^2 σ^2 \right).
$$
  Hence$$
\left. \left( \frac{\partial}{\partial t} \right)^{2k} E(\e^{tX}) \right|_{t = 0} = \left. \left( \frac{\partial}{\partial t} \right)^{2k} \exp\left( \frac{1}{n} t^2 σ^2 \right) \right|_{t = 0} = \left( \frac{σ^2}{n} \right)^k \left. \left( \frac{\partial}{\partial z} \right)^{2k} \e^{z^2} \right|_{z = 0}.
$$
  To complete the proof it is enough to notice (by induction w.r.t. $k$) that$$
\left. \left( \frac{\partial}{\partial z} \right)^{2k} \e^{z^2} \right|_{z = 0} > 0.
$$ Thank you so much for your help.","['probability-theory', 'convergence-divergence']"
2667501,Can ring homomorphisms be characterized as ring maps such that preimage of any ideal is an ideal?,"It's a well know fact that preimage of ideals by ring homomorphism are also ideals. Is the reciprocal true? I.e., let $f:R\to S$ be a map between the rings $R$ and $S$ s.t. $f^{-1}(I)\vartriangleleft R$ if $I\vartriangleleft S$. Then is $f$ a ring homomorphism?","['abstract-algebra', 'ring-theory', 'ring-homomorphism', 'ideals']"
2667566,Inverse of matrix after updating diagonal?,"Let $A$ be a real symmetric positive-definite matrix, with known inverse $A^{-1}$. Is there an efficient algorithm to compute $(A+R)^{-1}$, where $R$ is a real diagonal matrix? Assume that $A+R$ is also positive-definite. Failed idea with Cholesky decomposition I have read about the Cholesky decomposition and how it can be updated efficiently when the matrix changes by a rank-one modification. Since adding $R$ is the same as many rank-one modifications (one for each entry in the diagonal), in principle I could use this algoritm to compute the updated Cholesky decomposition. However this turns out to be $O(n^3)$ (where $n$ is the dimension of the matrices), no better than matrix inversion, because each rank-one update of the Cholesky decomposition is $O(n^2)$, and there are $n$ entries in the diagonal. Related This is closely related to Efficient diagonal update of matrix inverse . However in that question, the diagonal update is homogeneous. Here the diagonal entries $R_{nn}$ are in principle distinct for each $n$.","['matrices', 'positive-definite', 'linear-algebra', 'inverse']"
2667612,A Countable Basis and Countably Locally Finite Collections,"Show that if $X$ has a countable basis, a collection $\mathcal{A}$ of subsets of $X$ is countably locally finite if and only if it is countable. I am going to give my proof of the $\impliedby$ implication first. Suppose that $\mathcal{A}$ is a countable collection of subsets of $X$ . Then we can enumerate them by $\Bbb{N}$ likeso: $\mathcal{A} = \{A_n \mid n \in \Bbb{N}\}$ . But then $\mathcal{A} = \bigcup_{n=1}^\infty \{A_n\}$ , where $\{A_n\}$ is locally finite since any given open set can intersect at most one set in $\{A_n\}$ , and hence, intersect finitely many sets in $\{A_n\}$ . This means that $\mathcal{A}$ is countably locally finite. For the other direction, I am having a little trouble. A countably locally finite set can be written as a countable union of locally finite sets, so it seems that it suffices to show any locally finite collection is countable. Let $\mathcal{A}$ be any such collection. As with most arguments about cardinality, it seems that my best option is to construct a function $f : \mathcal{B} \to \mathcal{A}$ that is surjective. Here's an attempt. Assume that $A \in \mathcal{A}$ is not empty. Then there exists $a \in A$ , and since $\mathcal{B}$ is a basis $B \in \mathcal{B}$ such that $a \in B$ , so that $A \cap B \neq \emptyset$ . So we might define $f(B) = A$ such that $A \cap B \neq \emptyset$ (note: there could be may sets in $\mathcal{A}$ satisfying this, so perhaps this won't work...?) Is it well-defined? Well, if $B=B'$ , then $\emptyset \neq A \cap B = A \cap B'$ , which I guess means that $f(B) = f(B')$ (?). But by definition, this is surjective, so $|\Bbb{N}| = |\mathcal{B}| \ge |\mathcal{A}|$ , implying that $\mathcal{A}$ is countable. As the periodic question marks in the above paragraph indicate, I don't feel terribly comfortable with some parts of the proof. Another thing is, I don't seem to use $\mathcal{A}$ 's local finiteness anywheree. Is there a way of clarifying the proof? If it's incorrect, is there a way of fixing it? If not, I could use a hint on how to prove the theorem. EDIT: Hold on! I may have a proof. Just give me a few minutes to type it up. Okay. My proof is slightly inspired by Henno's answer given here , although I didn't read the entire proof until I came up with my own, because I wanted to try to solve the problem own my own as much as possible (indeed, the only thing I saw in the link was his definition of $I(n)$ ). Here is my second attempt at proving the "" $\implies$ "" implication, which is I believe is slightly different from Henno's since I don't do a proof by contradiction. First, let $\mathcal{A} = \{A_i \mid i \in I\}$ be some locally finite collection. We want to show that $I$ is countable. For each $n \in \Bbb{N}$ , define $I(n) = \{i \in I \mid A_i \cap B_n \neq \emptyset \}$ . Clearly the union of these sets is contained in $I$ . Suppose that $i \in I$ . Then given $A_i \neq \emptyset$ , there exists $a_i \in A_i$ ; and since $\mathcal{B} = \{B_n \mid n \in \Bbb{N}\}$ is a basis, there exists an $n \in \Bbb{N}$ such that $a_i \in B_n$ , which implies that $i \in I(n)$ . Hence $I = \bigcup_{n=1}^\infty I(n)$ , so that we need only prove that $I(n)$ is countable. To this end, let $n \in \Bbb{N}$ and let $x \in B_n$ . Since $\mathcal{A}$ is locally finite, there exists a basis element $B_{x_k}$ containing $x$ that intersects only finitely many elements in $\mathcal{A}$ . Hence, $\{B_{x_k}\}$ is a cover of $B_n$ , each of which intersects only finitely many sets in $\mathcal{A}$ ; moreover, since $\mathcal{B}$ is countable, $\{B_{k_x}\}$ must also be countable and hence can be enumerated likeso: $\{B_{\alpha_k} \mid k \in \Bbb{N} \}$ . Now, if $A_i \cap B_n \neq \emptyset$ , then it must also intersect a set in the cover of $B_n$ , which means that $I(n) \subseteq \bigcup_{k=1}^\infty I(\alpha_k)$ . Seeing as the latter set is a countable union of finite sets, which is makes it countable, $I(n)$ is als countable. How does this sound?","['general-topology', 'second-countable']"
2667648,Chi-square probabilities,"How are the values in chi-square distribution tables derived for different values of $\alpha$ and degrees of freedom, given the PDF? Any help appreciated.","['statistics', 'chi-squared', 'probability-distributions']"
2667695,Proof of the first equation of Slutsky's theorem.,"Suppose that random variables $\{X_n, n\geq 1\}$ and $\{Y_n, n\geq 1\}$ are all defined on a common probability space and that $X_n\Rightarrow X$ and $Y_n\Rightarrow c$, with $c$ a constant (here $\Rightarrow$ means convergence in distribution). Then $X_n + Y_n \Rightarrow X + c$. Exercise: Prove the above statement. You may use the following outline: a) An integer $n_\epsilon$ exists, such that $P(X_n\leq x)$ and $P(X\leq x)$ differ less than $\epsilon$ and also $P(\left|Y_n-c\right|\leq \epsilon)\geq 1-\epsilon$. b) Note the inclusion of events $$\{X_n\leq x\}\cap \{Y_n\leq c + \epsilon\}\subset\{X_n + Y_n\leq x + c\}\subset \{X_n\leq x + \epsilon\}\cup \{Y_n\leq c - \epsilon\}$$ c) Use the elementary inequalities $P(A\cap B)\geq P(A) - P(B^c)$ and $P(A\cup B)\leq P(A) + P(B)$ to derive a 'squeeze' on $P(X_n + Y_n\leq x +c)$. d) Letting $\epsilon \to 0$ then finishes it. What I've tried: There exists an integer such that $P(X_n\leq x)$ and $P(X\leq x)$ differ less than $\epsilon$. Yes, this is true, as $X_n\Rightarrow X$, so we know that $F_n^X(x)\to F^X(x)$ in probability. Furthermore, $F_n^Y\to c$ in probability, so it's also true that $P(\left|Y_n -c\right|\leq \epsilon)\geq 1-\epsilon$ (because this is equivalent to $P(\left|Y_n - c\right|>\epsilon)\to 0$). Using b), I think I should look at $P(P(X_n\leq x) - P(X\leq x))\cdot P(\left|Y_n - c\right|\leq \epsilon) \leq P(\left|F_n^X(x)-F^X(x)\right| + \left|Y_n - c\right|\leq \epsilon)$. Since I don't know how to break up this function I don't really know what to do next. I think that one of the reasons I don't know how to proceed is that I don't know how to handle the absolute value signs. Question: Could anyone give me a hint so that I can proceed in the right direction? Is my thinking up and until this part correct? Thanks!","['probability-theory', 'probability', 'probability-distributions']"
2667735,What exactly does the $\varepsilon$-$\delta$ definition of limits prove?,"e.g. Find the limit, $\lim\limits_{x \to 2} \ {\frac{2(x^2-4)}{x-2}}$, and prove it exists using the $\varepsilon$-$\delta$ definition of limits. This might be a stupid question, but I'm having a hard time wrapping my head around the $\varepsilon$-$\delta$ definition. To my understanding, the limit exists if I'm able to find it, and the $\varepsilon$-$\delta$ proof requires that I already know the limit. So, what exactly does the $\varepsilon$-$\delta$ definition prove ? Seems to me like it's about confirming the already-found-limit by showing the continuity of the limit's immediate surrounding. It seems unnecessary.","['calculus', 'limits']"
2667782,Reduction of second order differential equation $u''=2u^3$,"Given the differential equation $u''=2u^3$, what method of reduction can I use to make it easier to solve? The reduction order method requires a solution to be known and I am unsure on where to go from here.","['derivatives', 'ordinary-differential-equations']"
2667803,What's the difference between marginal distribution and conditional probability distribution?,"My understanding of both starts with this model: which has two random variables whose individual distributions are shown in red and blue, and their join distribution shown in green. I'm comfortable with the idea of using discrete math to take subsets of the tuples in the joint distribution, then using those subsets as the domain for various functions ( vis. functions that give probabilities and calculate statistics ). Then, amongst those functions we have two kinds in particular that have names: the marginal distribution functions and conditional probability distribution functions. My current understanding is that conditional probability distribution functions take a subset of tuples that range over both features of the tuple--x and y, say. You'll use conditional probability distribution functions to calculate probabilities given some subset of x and some subset of y. Then, my current understanding of marginal distribution functions is that they do the same thing as conditional probability distribution functions, but lock one of the features down to a specific value. Is that correct? I know I'm not using the standard set of jargon, but--I'm coming to statistics from pure math and computer science. So, forgive me while I try to connect one domain to another in my head.","['multivariable-calculus', 'statistics', 'probability', 'probability-distributions']"
2667846,"Prove $\frac{1}{x^2}$ is uniformly continuous on $[1,\infty)$ but not on $(0,1)$.","Prove $\frac{1}{x^2}$ is uniformly continuous on $[1,\infty)$ but not on $(0,1)$. Proof On $[1,\infty)$: $$\left|f(x) - f(y)\right| = \left| \frac{1}{x^2} - \frac{1}{y^2} \right| = \frac{(x+y)\left|x -y\right|}{x^2y^2} = \left(\frac{1}{xy^2} + \frac{1}{x^2y}\right)\left|x-y\right|\leq 2 \left|x-y\right| $$ Therefore $f$ is a Lipschitz function on $[1,\infty)$ which implies uniform continuity. On $(0,1)$ : Choose $\epsilon_0 = 1$ and consider the sequences defined by $x_n = \frac{1}{\sqrt{n}}$ and $y_n = \frac{1}{\sqrt{n+1}}$. We see that $\lim(x_n - y_n) = 0$ but $$\left|f(x_n) - f(y_n)\right| = \left|n - (n+1)\right| = 1$$ therefore $f$ is not uniformly continuous on $(0,1)$. Please comment on the validity, readability, and/or style. Thank you.",['real-analysis']
2667866,Show that $\int\limits_0^{\infty}\frac {dt}te^{\cos t}\sin\sin t=\frac {\pi}2(e-1)$,"How do you show that $$\int_{0}^{\infty}\frac{\mathrm{d}t}{t}\,\mathrm{e}^{\cos\left(t\right)}\,
\sin\left(\sin\left(t\right)\right) =
\frac{\pi}{2}\,\left(\,\mathrm{e} - 1\right)$$ I managed to get the left-hand side to equal the imaginary part of$$I=\int\limits_0^{\infty}\frac {dt}te^{e^{it}}$$But I’m not very sure what to do next. I’m thinking of a substitute $t\mapsto e^{it}$, but I’m not very sure how to evaluate the limit as $t\to\infty$. I also tried contour integration, but I’m not exactly sure what contour to draw.","['improper-integrals', 'integration']"
2667894,Evaluating the definite integral $\int_0^u \frac{\ln (ax)}{\sqrt{u-x}} \rm dx $,"So, the question asks to evaluate the following definite integral $$\int_0^u \frac{\ln (ax)}{\sqrt{u-x}} \rm dx $$ My approach is very close to getting the final answer, but I couldn't complete it. I assumed $$f(a) =\int_0^u \frac{\ln (ax)}{\sqrt{u-x}} \rm dx $$ Now we've $$f'(a)= \int_0^u \frac{1}{ax} \cdot \frac{ x}{\sqrt{u-x}} \rm dx \implies f'(a) = \frac 1a \int_0^u \frac{1}{\sqrt{u-x}} \rm dx$$ $$f'(a) =-\frac{2 \sqrt{u-x}}{a} \Bigg |_0^u=\frac{2\sqrt u} a$$ $$\implies f(a) = \int \frac{2\sqrt u}{a}  \rm da = 2\sqrt u (\ln (a)+C)$$ Here $C = g(u)$ is possible. But I can't find out a way to reach to the final answer. The given answer is $$\int_0^u \frac{\ln (ax)}{\sqrt{u-x}} \rm dx =2 \sqrt u ( \ln (4au)-2)$$ Can someone tell me how to proceed and/or can help evaluating this using any other method? Thanks.","['integration', 'definite-integrals']"
2667921,"Construct a square with vertices on a given point, line, and circle.","How to construct a square ABCD given point C, circle and a line so that point A lies on the line and point D lies on the circle?","['geometric-transformation', 'geometric-construction', 'geometry']"
2667926,Kernel of the diagonal homorphism $f:B\otimes_A B\rightarrow B$,"I'm studying Hartshorne's Algebraic Geometry book, and in the remark 8.9.2 I understood everything, besides one detail that is bothering me. He takes $U=SpecA\subset Y$, and $V=Spec B\subset X$, where $X$ and $Y$ are schemes, and a map $g:X\rightarrow Y$, such that $g(V)\subset U$. I know that $V\times_U V$ is isomorphic to $Spec(B\otimes_A B)$. But then he states that $\Delta(X)\cap (V\otimes_U V)$ is defined by the kernel of the diagonal morphism $f:B\otimes_A B\rightarrow B$, $f(b\otimes b')=bb'$, I can't see how to show this last part. I know that the kernel of this map is $kerf=\{\sum a_{ij}b_i\otimes b_j|\sum a_{ij}b_ib_j=0  \}$, but I can't see what happens in the Spec. Thanks in advance.",['algebraic-geometry']
2667938,What is the topology on the Grassmannian $G_n(\mathbb{R}^{n+k})$?,"If the real projective space $\mathbb{P}^n=\mathbb{R}^{n+1}/(x\sim \lambda x, \lambda\in\mathbb{R})$, then how does one define a real Grassmanian $G_n(\mathbb{R}^{n+k})=\{V\subset\mathbb{R}^{n+k}\mid \dim V=n\}$ as a quotient of $\mathbb{R}^{n+k}$? I saw on Wikipedia that its topology is given by the quotient topology, without specifically referring to what quotient. I am asking because in the definition of a tautological bundle over a Grassmannian, Wikipedia says that $G_n(\mathbb{R}^{n+k})$ is given a topology such that the map $G_n(\mathbb{R}^{n+k})\to \mathrm{End}(\mathbb{R}^{n+k})$, sending an $n$-plane $V$ to the orthogonal projection map $P_V$ onto that plane, is a homeomorphism onto its image. https://en.wikipedia.org/wiki/Tautological_bundle#cite_note-3 As a consequence, then the set $U_V$ containing all $n$-planes $X$ such that $P_V(X)\cong X$ by a linear isomorphism is open. Is this because it is a map onto the set of automorphisms which is open from the determinant function?","['algebraic-topology', 'general-topology', 'vector-bundles']"
2667943,Mean Value Theorem (another),"Does the mean value theorem also apply to lateral derivatives? Let $f: [a,b] \longrightarrow \mathbb{R}$ continuous and $f$ right differentiable in $(a,b)$, then, theres exists $c \in (a,b)$ such that 
  $$f'_{+}(c) = \frac{f(b)-f(a)}{b-a}$$ In the proof of the Means Value Theorem, based on Rolle's Theorem, it wasn't clear to me what would happen if we changed this hypothesis","['derivatives', 'real-analysis']"
2668002,"We square an integral, but why change a variable?","If we square an integral, we also change the integration variable in one of the integrals. But why is this actually correct? For example, say I have the following: Solve $\int_{-\infty}^\infty e^{-x^2} dx$. Let $I=\int_{-\infty}^\infty e^{-x^2} dx$, so \begin{align}
I^2 &=\bigg(\int_{-\infty}^\infty e^{-x^2} dx\bigg)^2\\
&= \bigg(\int_{-\infty}^\infty e^{-x^2} dx\bigg) \times 
\bigg(
\underbrace{
\int_{-\infty}^{\infty} e^{-y^2}dy
}_{\text{Why}?}
\bigg) 
\\
&=\int_{-\infty}^\infty\bigg(\int_{-\infty}^\infty e^{-(x^2+y^2)} dx\bigg)dy 
\end{align} But why is the following wrong:
\begin{align}
I^2 &=\bigg(\int_{-\infty}^\infty e^{-x^2} dx\bigg)^2\\
&= \bigg(\int_{-\infty}^\infty e^{-x^2} dx\bigg) \times \bigg(\int_{-\infty}^{\infty} e^{-x^2}dx\bigg) \\
&=\int_{-\infty}^\infty\bigg(\int_{-\infty}^\infty e^{-x^2-x^2} dx\bigg)dx \\
&=\int_{-\infty}^\infty\bigg(\int_{-\infty}^\infty e^{-2x^2} dx\bigg)dx \qquad ?
\end{align}","['real-analysis', 'calculus', 'improper-integrals', 'integration', 'analysis']"
2668042,Monster coefficients,"For three irreducible characters $\phi,\psi,\rho$ of a finite group $G$ define the Kronecker multiplicities as: 
$$g(\phi,\psi,\rho) = \langle \phi,\psi\cdot\rho\rangle
$$
where 
$$\langle \chi,\eta\rangle = \frac{1}{|G|}\sum_{x\in G} \chi(x)\,  \overline{\eta(x)}
$$
and $[\psi\cdot\rho] (x) = \psi(x) \rho(x)$ is the usual product. I am interested in Kronecker multiplicities for the Monster group $M$.  While the group is large, there are only 194 conjugacy classes. $$(1) \qquad \max_{\phi,\psi,\rho} g(\phi,\psi,\rho)$$ $$(2) \qquad \sum_{\phi,\psi,\rho} g(\phi,\psi,\rho)$$
$$(3) \qquad \sum_{\phi,\psi,\rho} g(\phi,\psi,\rho)^2$$ These sums are over all triples of irreducible characters, but because of the symmetries only about 1/6 of them need to be computed to get the answer.  If you can do this, I would also be curious about the specific characters maximizing (1). The computation is beyond my computer algebra skills, but I know that GAP has the whole character table of $M$ ready to use.","['finite-groups', 'characters', 'group-theory', 'computer-algebra-systems', 'gap']"
2668071,How do we know the Taylor expansion for $e^x$ works for all $x$? Or that it's analytic?,"Let's say I want to use Maclaurin series to get the series expansion $S(x)$ for $f(x) = e^x$ where $S(x) = c_0x^0 + c_1x^1 + c_2x^2 + c_3x^3 + ...$ $f(0) = S(0) = c_0 = e^0 = 1$ so that's fine. $f'(0) = S'(0) = c_1 = e^0 = 1$ again, fine. $f''(0) = S''(0) = 2c_2 = e^0 = 1$ so $c_2 = 1/2$, fine. $f'''(0) = S'''(0) = 6c_3 = e^0 = 1$ so $c_3 = 1/6$, fine. $f''''(0) = S''''(0) = 24c_4 = e^0 = 1$ so $c_4 = 1/24$, fine. And so on, so we conclude that $c_k = \frac{1}{k!}$ so then: $$S(x) = \sum_{k=0}^{\infty} \frac{x^k}{k!}$$ But now what I don't understand is what allows us to go ""Furthermore, $S(x) = f(x)$ for all $x$""! In fact what makes it valid for us to plug any other number other than $x=0$ into this? I see this equation used as a straight-up equivalent to $e^x$ even though we used $x=0$ and nothing else. So I thought I would try it with a neighborhood of $1$ instead to see what happens: $S(x) = c_0(x-1)^0 + c_1(x-1)^1 + c_2(x-1)^2 + c_3(x-1)^3 + ...$ $f(1) = S(1) = c_0 = e^1 = e$ so that's fine. $f'(1) = S'(1) = c_1 = e^1 = e$ again, fine. $f''(1) = S''(1) = 2c_2 = e^1 = e$ so $c_2 = e/2$, fine. $f'''(1) = S'''(1) = 6c_3 = e^1 = e$ so $c_3 = e/6$, fine. $f''''(1) = S''''(1) = 24c_4 = e^1 = e$ so $c_4 = e/24$, fine. Looks pretty similar: $$S(x) = \sum_{k=0}^{\infty} \frac{e(x-1)^k}{k!}$$ and, in fact, for a neighborhood of $x=a$: $$S(x) = \sum_{k=0}^{\infty} \frac{e^a(x-a)^k}{k!}$$ Now we have $e$ inside the function expansion for $e^x$ which seems a little circular? I guess my question is this: We created the function $S$ to have the same-valued $n$th derivatives as $f(x)$ but only at $x=0$ or $x=1$, or $x=a$, etc, but the series representations look different depending on which neighborhood I pick, and in some cases the expansions seem to include the very number we're trying to describe. How do we know which is ""right"" or that it is even ""right"" to use for all $x$? I know the usual response to this is that it's equivalent when $f(x)$ is analytic but that doesn't help me at all because it says the function is analytic when the Taylor series around $x_0$ converges to the function in a neighborhood around $x_0$ for all $x_0$ in the function's domain. But how do I know this? Yet again feels circular... just working through these two examples makes me wonder, how do I know these series converge to the function itself? How do I know they're equivalent representations? Am I supposed to avoid the self-referencing? I'm looking for some context behind how to make sense of these two Taylor series and how I am supposed to know that $e$ is analytic or that I can use $S(x)$ for any $x$ I want even if I only computed it for the neighborhood around $x=0$.","['taylor-expansion', 'exponential-function', 'calculus', 'analytic-functions', 'sequences-and-series']"
2668146,Complex power series property with real numbers,"I am trying to prove the following statement, seems clear to me but I am not able to give a formal proof. I have tried using the binomial expansion and Taylor's theorem for complex numbers. Let $f(z)= \sum\limits_{n=0}^\infty c_nz^n$, $z \in \mathbb{C}$  be a power series with radius of convergence $R_1=\infty$. Prove that $f(z-c), c \in \mathbb{R}$ can also be written as a power series $f(z-c)=\sum\limits_{n=0}^\infty b_nz^n$ with radius of convergence $R_2=\infty$. Thanks in advance!","['complex-analysis', 'power-series', 'convergence-divergence', 'complex-numbers']"
2668184,What statistical test should be used to evaluate the efficiency of some treatment?,"We have two group of people (one of $n$ people, the other of $m$ people) that go through the same entertainment experience (think about a day at the amusement park or something like that). One group gets a special treatment over the other group at some moment during the day (a free drink for example).
At the end of the day, each participant gives a satisfaction grade (an integer) $X_1, \cdots, X_n, Y_1, \cdots, Y_m$ that ranges from $0$ to $5$. We would like to know if the special treatment affects the overall satisfaction of the experience. I guess that we have to test if the means of the satisfaction of the two groups are equal ? What test should be used ?","['statistics', 'probability', 'hypothesis-testing']"
2668193,Prove by induction: $n! \ge 2^{(n-1)}$ for any $n \ge 1$ [duplicate],"This question already has answers here : Prove the inequality $n! \geq 2^n$ by induction (3 answers) Prove that $n! \geq 2^{n-1}$ for $ n\geq1$ [duplicate] (3 answers) Closed 6 years ago . I need help with this exercise.
What I've done so far is prove the exercise when $n=1$ . So: $$n=1$$ $$1!\ge2^{(1-1)}$$ $$1\ge2^0$$ $$1\ge1$$ Which is true Therefore, now that I assume that the assumption is correct, I want to prove that with $n+1$ , it will also be true. So, what I've done now is: $$P(n) \implies P(n+1) $$ $$n!+n+1\ge 2^{(n-1)}...$$ And my  problem is that I do not know how to add the $n+1$ in the right side of the equation, therefore I'm not been able to finish the exercise. Thank you so much for your help. If something's not very clear, please let me know. I'll try to be clearer next time :)","['induction', 'factorial', 'exponential-function', 'discrete-mathematics']"
2668265,"Solution of $ y''+5y'+6y=0$ with initial condition , $y(0)=2, y'(0)=3$ using laplace transform","The below equation $(1)$ is second-ordinary differential equation, I have got the solution of it using standard method which is :$y(x)=e^{-3x}(-7+9e^x)$ , now my question is to solve  equation  $(1)$ using laplace transform : $ y''+5y'+6y=0, y(0)=2, y'(0)=3\tag{1}$","['ordinary-differential-equations', 'laplace-transform']"
2668289,Is there another prime $p$ such that $S(p)$ is prime?,"Denote $$S(p):=2^2+3^3+5^5+\cdots +p^p$$ $S(p)$ is prime for $p=3,7,89$. Is there another prime $p$ such that $S(p)$ is prime ? Is the number of primes $p$ such that $S(p)$ is prime, finite ?","['number-theory', 'perfect-powers', 'summation', 'prime-numbers']"
2668291,Functions on Finite sets and combinatorics.,"Here's a simple combinatorics problem that gets me frustrated along with my attempts at an answer.
Consider the set $S=\{1,2,\ldots,2m\}$. Find the number of... a) Functions $f:S\rightarrow S$. b) Functions $f:S\rightarrow S$ such that $\forall y\in S \ \exists x\in S:f(x)=y$, with m=3. c) Functions $f:S\rightarrow S$ such that for $y\in \{2,4,6\} \ \exists x_1,x_2\in S:f(x_1)=f(x_2)=y$, with m=3. d) Functions $f:S\rightarrow S$ such that for $y\in \{3,6\} \ \exists x_1,x_2,x_3\in S:f(x_1)=f(x_2)=f(x_3)=y$, with m=3. a) Is fairly simple :) For the other questions, my thoughts are these: For b), what it says is that we need to find how many functions are onto.
For $1\in S$ there are $|S|$ options for $x$. For $2\in S$ there are $|S|-1$ options, etc. So there are $|S|!$ functions with this property. For c, if $y=1$ we have $\binom{|S|}{2}$ options, and for $y=2$ we have $\binom{|S|-2}{2}$ options, etc. Is this reasoning correct? For d, I don't seem to be able to count...","['combinatorics', 'functions']"
2668294,Vector-valued forms inside the first jet bundle,"On page 433 of ""Self-duality in four-dimensional Riemannian geometry"" by Atiyah, Hitchin and Singer, it is written that $p^*(E \otimes \Lambda^1) \subset p^*J_1(E)$, where $\Lambda^1 \to X$ is the bundle of $1$-forms, $p : E^* \to X$ is a vector bundle and $J_1(E) \to X$ is the first jet bundle of $E$. How exactly is this inclusion realized?","['global-analysis', 'gauge-theory', 'differential-geometry']"
2668303,Proving polynomial relationship using combinations,"Generalize the polynomial relationship $$(1+x)^n=\sum_{k=0}^n x^k {n \choose k}$$ for all positive integers $n$ to $$(a+x)^n$$ My work so far: I want to use proof by induction to prove this. I am trying to find a polynomial to plug in for $x$ so that this relationship is satisfied. Proving the base case, however, $n=0$ will yield always yield a result of $1=1$. So our base case is satisfied. Additionally, the case for $n=1$ will yield $x+a$, so I must find a polynomial raised to the first power plus one that will result in $x+a$. That polynomial is $x+a-1$. My goal now is to prove this equality. $$(a+x)^n=\sum_{k=0}^n (a+x-1)^k {n \choose k}.$$ I've already shown the base case is satisfied; now I will solve for the example for $n+1$ $$(a+x)^{n+1}=\sum_{k=0}^{n+1} (a+x-1)^k {n+1 \choose k}$$ $$(a+x)^n(a+x)=\sum_{k=0}^n (a+x-1)^k {n \choose k} + (a+x-1)^{n+1}{n+1 \choose k}$$. At this point, I get lost and don't know where to continue from here. I assume there's something I have to do with Pascal's rule, but I don't see where that will lead me.","['proof-writing', 'proof-explanation', 'discrete-mathematics']"
2668314,Multiplication of Moduli in Modular Congruences,"Lately it's come up in my discrete mathematics class that proving things for smaller congruences, namely those where the modulus is a prime is much easier than attempting to do so for larger congruences. For example, one such problem was to prove that $a^5 \equiv a \pmod{10}$ for $a$ $\varepsilon$ $\mathbb Z^+\ $This problem on its own becomes difficult only because we are not guaranteed that for every a $(a,10)=1$. The solution was to factorize 10 in terms of primes $p_1, p_2... p_n$ s.t for each prime $p_i$ $(a,p_i)=1$ for all $a \ \varepsilon \ \mathbb Z^+\ $, resulting in n congruences under modulo the given prime and then apply Euler's Theorem. In this case we find the following:
$$10 = 2 \cdot 5$$
so
$$a^{\phi(5)} \equiv 1 \pmod{5} \\ a^{\phi(2)} \equiv 1 \pmod{2}$$
since $\phi(5)=4, \phi(2)=1$ this becomes:
$$a^{4} \equiv 1 \pmod{5} \implies a^{5} \equiv a \pmod{5}\\ a^{1} \equiv 1 \pmod{2} \implies a^{5} \equiv a^4 \pmod{2} $$
but since a is its own inverse modulo 2, we can transform the 2nd congruence into:
 $$a^5 \equiv a \mod{2}$$
Then the part that I am unclear on occurs. It seems that we can just multiply the 2 moduli together and the desired congruence falls out that:
$$a^5 \equiv a \pmod{10}$$ So my question is whether or not $a \equiv b \pmod{n}$ and $a \equiv b \pmod{m}$ always$\implies$ $a \equiv b \pmod{mn}$. Edit (Extension): The answer to my question has been stated to be yes provided that $(m,n) = 1$ but I also noticed that if my 2 relations had been left stated as 
$$a^4 \equiv 1 \pmod{2}$$
$$a^4 \equiv 1 \pmod{5}$$
Applying the conjecture I made gives:
$$a^4 \equiv 1 \pmod{10}$$
which is demonstrably false given that $$2^4 \equiv 6 \pmod{10} \implies 2^4 \not\equiv 1 \pmod{10}$$
Why is this and what prevents this identity from being true as well? I see that 2 would then not be coprime to 10 but why does it work when I multiply both sides by a then?","['number-theory', 'chinese-remainder-theorem', 'elementary-number-theory']"
2668344,Showing that $f(x)$ is a probability density function,"I'm having trouble showing the following $f(x)$ is a probability density function. The following information is given: $$f(x) = \frac{1}{\sum_{k=x}^\infty {k-1\choose x-1}(1-p)^{k-x-1}}; x = 0, 1, 2, \ldots$$ I'm having trouble in particular getting the denominator to something that I can take the integral of. I've attempted to get it to be equal to a binomial series but I eventually end up with an integral of $p^x$ which is zero. Thanks for any help or tips.","['statistics', 'probability', 'probability-distributions']"
2668409,"Example of non-isomorphic sheaves, with isomorphic stalks at every point?","Basically what the title asks.  I'd like to see an example of two sheaves on a topological space which have the same (isomorphic) stalks at every point, but are not isomorphic as sheaves.","['algebraic-topology', 'general-topology', 'sheaf-theory', 'algebraic-geometry']"
2668455,Number of real $x$ satisfying the trigo equation $1+\sin 2x=\sin x+\sin^2 x$,"Number of real $x$ satisfying the trigo equation $1+\sin 2x=\sin x+\sin^2 x$ in $x\in(0,2\pi)$ solution i try $1+\sin 2x =\sin x+\sin^2 x$ $5+4\sin 2x=4\sin^2 x+4\sin x+1$ $5+\sin 2x=(2\sin x+1)^2$ How i solve it after that point",['trigonometry']
2668464,Can we axiomatize a field starting with the binary operations and only “equational” axioms?,"The usual field axioms include the existence of (additive and multiplicative) identities and inverses. Is there a set of field axioms where all axioms are purely equational (see below for what I mean)? The Wikipedia article on fields contained (and still contains, slightly rewritten) an intriguing section on “Alternative axiomatizations”: Because of the relations between the operations, one can alternatively axiomatize a field by explicitly assuming that there are four binary operations (add, subtract, multiply, divide) with axioms relating these, … This is something I'm interested in, and I wonder whether it's true: can I see an example of such a set of axioms? Or prove that one does not exist? Specifically (because whatever Wikipedia is talking about may turn out not to be the thing I want), I'm thinking of a definition something like the following: a field is a set $F$ along with four operations $(+, -, \times, \div)$ satisfying the following axioms (here $a, b, c, d$ denote any elements of $F$): $$\begin{align}
a + b &= b + a \\
a + (b + c) &= (a + b) + c \\
a + (b - c) &= (a + b) - c \\
a - (b - c) &= (a - b) + c \\
a + (b - b) &= a \quad \rlap{\text{(maybe we need something like this?)}} \\
a \times b &= b \times a \\
&\dots
\end{align}$$
where each axiom is simply an equation (or a term-rewriting rule: if we have an expression of the form on the left, then we can transform it to the one on the right, maybe do these transformations until we get a canonical form), with no axioms of the form “there exist…” (like assuming $0$ or $1$ or additive or multiplicative inverses). If such a system does not result in a field, what's missing? (I'm trying to see whether, by starting with four arbitrary operations defined on a set $S$ and introducing equational constraints on the operations—such as commutativity, associativity, etc.—whether we can finally reach a state where we know these are all the constraints. I know this axiomatization may seem weird, but there do exist weird ones like Tarski's axiomatization of the reals .)","['abstract-algebra', 'reference-request', 'axioms', 'universal-algebra', 'field-theory']"
2668470,"Questions on Prime Counting Functions, Explicit Formulas, and Related Zeta Functions","This question is related to the prime-counting functions defined in formulas (1) to (4) below $$A(x)=\sum\limits_{n=2}^x \frac{\Lambda(n)}{\log(n)^2}\tag{1}$$ $$\Pi(x)=\sum\limits_{n=2}^x \frac{\Lambda(n)}{\log(n)}\tag{2}$$ $$\psi(x)=\sum\limits_{n=1}^x\Lambda(n)\tag{3}$$ $$B(x)=\sum\limits_{n=1}^x\Lambda(n)\log(n)\tag{4}$$ where $\Pi(x)$ is Riemann's prime-power counting function and $\psi(x)$ is the second Chebyshev function. The prime-counting functions defined in (1) to (4) above are related via their first-order derivatives as follows. $$\Pi'(x)=\log(x)\,A'(x)\tag{5}$$ $$\psi'(x)=\log(x)\,\Pi'(x)\tag{6}$$ $$B'(x)=\log(x)\,\psi'(x)\tag{7}$$ The asymptotics for the prime counting functions defined in (1) to (4) above are as follows. $$A(x)\approx li(x)-\frac{x}{\log(x)}\tag{8}$$ $$\Pi(x)\approx li(x)\tag{9}$$ $$\psi(x)\approx x\tag{10}$$ $$B(x)\approx x\,(\log(x)-1)\tag{11}$$ I know the error bounds on $|\Pi(x)-li(x)|$ and $|\psi(x)-x|$ predicted by the Prime Number Theorem (PNT) and Riemann Hypothesis (RH) have been thoroughly researched and are well documented, but I'm wondering about $A(x)$ and $B(x)$ . Question (1) : What are the error bounds for $|A(x)-(li(x)-\frac{x}{\log(x)})|$ predicted by the PNT and RH? Question (2) : What are the error bounds for $|B(x)-(x\,(\log(x)-1))|$ predicted by the PNT and RH? Note the asymptotic $li(x)-\frac{x}{\log(x)}$ for the prime counting function $A(x)$ is the difference between the two most famous estimates for the asymptotic for the fundamental prime counting function $\pi(x)$ . The prime counting functions defined in (1) to (4) above are related the Riemann zeta function $\zeta(s)$ as follows. $$\int\log\zeta(s)\,ds=-s\int\limits_0^\infty A(x)\,x^{-s-1}\,ds=-\sum\limits_{n=2}^\infty\frac{\Lambda(n)}{\log(n)^2}\,n^{-s}\,,\quad\Re(s)>1\tag{12}$$ $$\log\zeta(s)=s\int\limits_0^\infty\Pi(x)\,x^{-s-1}\,ds=\sum\limits_{n=2}^\infty\frac{\Lambda(n)}{\log(n)}\,n^{-s}\,,\quad\Re(s)>1\tag{13}$$ $$\frac{\partial\,\log\zeta(s)}{\partial s}=-s\int\limits_0^\infty\psi(x)\,x^{-s-1}\,ds=-\sum\limits_{n=1}^\infty\Lambda(n)\,n^{-s}\,,\quad\Re(s)>1\tag{14}$$ $$\frac{\partial^2\,\log\zeta(s)}{\partial s^2}=s\int\limits_0^\infty B(x)\,x^{-s-1}\,ds=\sum\limits_{n=1}^\infty\Lambda(n)\log(n)\,n^{-s}\,,\quad\Re(s)>1\tag{15}$$ Question (3) : Is there a formula for $\int\log\zeta(s)\,ds$ that converges for $\Re(s)\le 1$ and if so, what is its definition? Riemann's explicit formulas for the prime-power counting function $\Pi(x)$ and von Mangloldt's explicit formula for the second Chebyshev function $\psi(x)$ are as follows. $$\Pi(x)=li(x)-\sum\limits_\rho Ei(\log\,(x)\,\rho)-\log(2)-\sum\limits_{n=1}^\infty Ei(-2\,n\,\log(x))\,,\quad x>1\tag{16a}$$ $$\Pi(x)=li(x)-\sum\limits_\rho Ei(\log(x)\,\rho)-\log (2)+\int_x^\infty\frac{1}{t\,\left(t^2-1\right)\log(t)}\,dt\,,\quad x>1\tag{16b}$$ $$\psi(x)=x-\sum\limits_\rho\frac{x^\rho}{\rho}-\log(2\,\pi)+\sum\limits_{n=1}^\infty\frac{x^{-2\,n}}{2\,n}\,,\quad x>1\tag{17a}$$ $$\psi(x)=x-\sum\limits_\rho\frac{x^\rho}{\rho}-\log(2\,\pi)-\frac{1}{2}\,\log\left(1-\frac{1}{x^2}\right)\,,\quad x>1\tag{17b}$$ I derived the following explicit formula for the prime counting function $B(x)$ where $Li_2$ is the polylogarithm function and $b\approx 0.63$ . $$B(x)=x\,(\log(x)-1)-\sum\limits_\rho\frac{x^\rho\,(\rho\,\log(x)-1)}{\rho^2}+b+$$ $$\sum\limits_{n=1}^\infty\frac{(2\,n\log(x)+1)\,x^{-2\,n}}{4\,n^2}\,,\quad x>1\tag{18a}$$ $$B(x)=x\,(\log(x)-1)-\sum\limits_\rho\frac{x^\rho\,(\rho\,\log(x)-1)}{\rho^2}+b+$$ $$\frac{1}{4}\left(Li_2\left(\frac{1}{x^2}\right)-2\,\log(x)\log\left(1-\frac{1}{x^2}\right)\right),\quad x>1\tag{18b}$$ The following plot illustrates the explicit formula for $B(x)$ defined in (18) above in orange and the reference function $B(x)$ defined in (4) above in blue. The explicit formula is evaluated over the first 100 pairs of zeta zeros with $b=0.63$ . $B(x)$ "" /> I originally derived the explicit formula for $B(x)$ defined in (18) above via two different approaches which are outlined in (19) and (20) below. Both approaches start with the first explicit formula for $\psi(x)$ defined in (17) above which uses the series representation of the final error term. Both approaches provide exactly the same result, but I'm not sure how to handle the derivation of the constant offset term $b$ for either approach. $B(x)=\int\log(x)\frac{\partial\,\psi(x)}{\partial\,x}\,dx\tag{19}$ $$B(x)=\frac{1}{2\,\pi\,\,i}\int\limits_{c-i\,\infty}^{c+i\,\infty}\frac{\partial}{\partial\,s}\left(-s\int\limits_0^\infty\psi(x)\,x^{-s-1}\,ds\right)\frac{x^s}{s}\,ds\tag{20}$$ The first approach outlined in (19) above leverages the relationship $B'(x)=\log(x)\,\psi'(x)$ from (7) above. The second approach outlined in (20) above takes advantage of the fact that all terms in the first formula for $\psi(x)$ illustrated in (17) above are of the form $a\, x^z$ and the Mellin transform of $x^z$ is $2\,\pi\,\delta(i\,(s+z))$ . I illustrated $\mathcal{M}_s^{-1}[2\,\pi\,\delta(i\,(s+z))](x)=x^z$ in the following answer I posted to a question on evaluation of $\delta(s)$ for $s\in \mathbb{C}$ . Answer to Question on Evaluation of $\delta(s)$ for $s\in \mathbb{C}$ I illustrated a single outer integral in approach 2 outlined in (20) above, but this is a bit of an oversimplification as each individual term requires a different value of $c$ for evaluation of its associated integral. Question (4) : What is the derivation and exact value for the constant offset term $b$ associated with the derived explicit formula for $B(x)$ defined in (18) above? I derived the following explicit formula for the prime counting function $A(x)$ . $$A(x)=li(x)-\frac{x}{\log(x)}+\sum\limits_\rho\left(\rho\, E_1\left(-\rho\, \log(x)\right)+\frac{x^{\rho}}{\log(x)}\right)+a+$$ $$\sum\limits_{n=1}^\infty\left(2\,n\, Ei(-2\,n\,\log(x))+\frac{x^{-2\,n}}{\log(x)}\right),\quad x>1\tag{21a}$$ $$A(x)=li(x)-\frac{x}{\log(x)}+\sum\limits_\rho\left(\rho\, E_1\left(-\rho\, \log(x)\right)+\frac{x^{\rho}}{\log(x)}\right)+a+$$ $$\sum\limits_{n=1}^\infty (2\,n\,Ei(-2\,n\,\log(x)))+\frac{1}{\left(x^2-1\right)\,\log(x)}\,,\quad x>1\tag{21b}$$ The following plot illustrates the explicit formula for $A(x)$ defined in (21) above in orange and the reference function $A(x)$ defined in (1) above in blue. The explicit formula is evaluated over the first 100 pairs of zeta zeros with $a=2.5$ . $A(x)$ "" /> I derived the explicit formula for $A(x)$ defined in (21) above via the approach which is outlined in (22) below. This approach starts with the first explicit formula for $\Pi(x)$ defined in (16) above which uses the series representation of the final error term. The approach outlined in (22) below leverages the relationship $\Pi'(x)=\log(x)\,A'(x)$ from (5) above. I'm not sure how to handle the derivation of the constant offset term $a$ for this approach. $A(x)=\int\frac{1}{log(x)}\frac{\partial\,\Pi(x)}{\partial\,x}\,dx\tag{22}$ Question (5) : What is the derivation and exact value for the constant offset term $a$ associated with the derived explicit formula for $A(x)$ defined in (21) above? March 17, 2018 Update: I believe I've determined the answer to question (4) above. I believe the constant offset term $b$ associated with the derived explicit formula for $B(x)$ defined in (18) above is $$b=\frac{\zeta''(0)}{\zeta(0)}-\frac{\zeta'(0)^2}{\zeta(0)^2}=\frac{\pi ^2}{12}-\gamma^2-2 \gamma_1=0.634921\tag{23}$$ which corresponds to the residue of $\frac{\partial^2\,\log\zeta(s)}{\partial s^2} \frac{x^s}{s}$ at $s=0$ . I more recently verified the remainder of the terms in formula (18) for $B(x)$ above are consistent with the residues of $\frac{\partial^2\,\log\zeta(s)}{\partial s^2} \frac{x^s}{s}$ at $s=1$ and the zeros of $\zeta(s)$ . In the explicit formulas defined above, the sums $\sum\limits_{\rho}\ (...)$ over the non-trivial zeta zeros are conditionally convergent and should be evaluated as $\underset{T\to\infty}{\text{lim}}\left(\sum\limits_{|\Im(\rho)|<T}\ (...)\right)$ .","['mellin-transform', 'number-theory', 'riemann-hypothesis', 'riemann-zeta', 'prime-numbers']"
2668488,Show F cannot be continued analytically past the unit disc.,"This question is from Stein's complex analysis. This question has 4 parts, I don't have question about the first part and the second part, but I have no idea about how to solve the third part. I think there is some question like this posting here, but I forgot how to get to that post, and that post did not help me when I read it. Let $F(z)=\sum_{n=1}^{\infty}d(n)z^{n}$, where $d(n)$ denotes the number of divisors of n. Observe that the radius of convergence of this series is 1. Part 1: Verify the identity $F(z)=\sum_{n=1}^{\infty}d(n)z^{n}=\sum_{n=1}^{\infty}\frac{z^{n}}{1-z^{n}}$. Part 2: Using this identity, show that if $z=r$ with $0<r<1$, then $\mid$$F(r)$$\mid$ $\geq$ $c$$\frac{1}{1-r}log(1/(1-r))$ as $r\rightarrow 1$. Part 3: Similarly, if $\theta=2\pi p/q$ where $p$ and $q$ are positive integers and $z=re^{i\theta}$, then $\mid$$F(re^{i\theta})$$\mid$ $\geq$ $c_{p/q}$$\frac{1}{1-r}$$log(1/(1-r))$. Part 4: Conclude that F cannot be continued analytically past the unit disc. Since I have solved part 1 and part 2, and part 3 told me it is similar, I have done something, but I cannot proceed further. $\mid F(z)\mid=\mid$$\sum_{n=1}^{\infty}\frac{z^{n}}{1-z^{n}}\mid$$=$$\mid$$\frac{1}{1-z}\sum_{n=1}^{\infty}\frac{z^{n}}{1+\cdots +z^{n-1}}\mid$$=$$\mid$$\frac{1}{1-z}$$\mid$$\mid$$z+\frac{z^{2}}{1+z}+\cdots +\frac{z^{n}}{1+\cdots +z^{n-1}}+\cdots$$\mid$ If this is part 2, I can expand $log(1/1-r)$ in power series and compare term by term, and will get some inequalities, but in this part I don't know how to proceed. Moreover, how to relate the constant C with $p/q$? I think that it may be related to some period in the unit circle, but I cannot write down anything about it. Part 4 follows part 3 immediately and I don't have problem with it. Any hints and detailed explanations are really really appreciated!!!!",['complex-analysis']
2668503,Understanding subspace topology,"In wiki article of ""compact spaces"", they state that the set $\mathbb{Q} ∩ [0,1]$ is not compact because the sets of rational numbers in the intervals $[0, \frac{1}{π} - \frac{1}{n}]$ and $[ \frac{1}{π}+ \frac{1}{n}, 1]$ covers all the rationals in $[0,1]$ but this cover does not have finite subcover; these sets are open in the subspace topology even though they are not open as subsets of $\mathbb{R}$ . I don't get it! How is $[0, \frac{1}{π} - \frac{1}{n}]$ open in subspace topology for each $n∈ \mathbb{N}$ ? In particular, I need to know what are the open sets under subspace topology? What are the closed sets in subspace topology? What are the compact sets in subspace topology?",['general-topology']
2668529,How can see if something is under a topology?,"X is defined as $\{a,b,c,d\}$ A topological space $X$ is called $T_{0}$ if for every pair of points $x,y \in X$, there is an open set $U$ that contains one of them and not the other. Is $XT_{0}$ is under your topology (which you must construct)  which is neither discrete nor trivial, and to prove it. For the first part, I defined my topology to be $\{\emptyset, X, \{a\},\{ab\},\{abc\}\}$ because this topology is neither discrete nor trivial. However, how can I show that $XT_{0}$ is under my topology?",['general-topology']
2668542,Why is the solution to this sum of two sines so complex?,"While working on a signal processing problem, I found I needed to solve a certain equation involving a sum of a sequence of sines. Since I wasn't really sure how to do this cleanly, I decided to ask WolframAlpha to solve a simplified version (the first two terms) and see if there was a general pattern I could extrapolate. To my utter surprise, the equation $$ \sin(a-x) + 2\sin(b-2x) = 0$$ produced this monstrosity (note that this is just one of two solutions!): What exactly is going on here? Why is the solution to this equation so absurdly complex? I ended up solving my problem another way, but I still would love to know what is with this particular equation.","['wolfram-alpha', 'trigonometry']"
2668562,Two diagonals of a regular nonagon (a $9$-sided polygon) are chosen. What is the probability that their intersection lies inside the nonagon?,"Two diagonals of a regular nonagon (a $9$-sided polygon) are chosen. What is the probability that their intersection lies inside the nonagon? This is similar to a previous problem that I posted about a dodecahedron. However, this provides more difficult, as a nonagon is  (in my opinion) more difficult to work with than a dodecahedron. A dodecahedron, in every sense of the object, is even (even edges, even vertices...). This cannot be said for the $2D$ Nonagon. Here is what I'm thinking. Draw a nonagon. Find all of the intersection points of the nonagon. A quick glance at online diagram of a nonagon (with diagonals drawn) shows that this method would fall flat quickly. Finding all of the intersection points can be found with $\binom{9}{4}=126$. This means that $126$ is the numerator. If only I could find the denominator.... Help is greatly appreciated!","['combinatorics', 'geometric-probability']"
2668593,Third Moment of Geometric Series?,"$\sum_{x=1}^{\infty}x(1-p)^{x-1} = \frac{1}{p^2}$ $\sum_{x=1}^{\infty}x^2(1-p)^{x-1} = \frac{2-p}{p^3}$ $\sum_{x=1}^{\infty}x^3(1-p)^{x-1} =$ ... ? The textbook gives the first 2 moments, but not the third one. I could not find the forumla on Google as well. I think it'll be useful in case I need to find $E(X^3)$ where $X$ is a geometric distribution.","['statistics', 'summation']"
2668599,What exactly are graph invariants?,"I came to know a new term in Graph Theory as Graph Invariant . According to Wikipedia ,  a graph property or graph invariant is a property of graphs that depends only on the abstract structure, not on graph representations such as particular labellings or drawings of the graph. Can anyone explain briefly what exactly graph invariants are? I am unable to grasp this concept. Thanks a lot for the help.","['terminology', 'combinatorics', 'graph-theory', 'discrete-mathematics']"
2668616,Solve the Initial Value Problem and Plot the Particular Solution with the direction field (MAPLE),"I am fairly new at MAPLE and I'm having some trouble solving this ODE. $$(t+1)\frac{dy}{dt}-2(t^2+t)y=\frac{e^{t^2}}{t+1}$$ My initial value problem is $$t>-1, y(0)=5$$ I put the equation in standard form and typed into maple However I am aware that when my initial value is $y(0)=5$ my equation becomes $4=0$ which is not possible. So I am confused on whether or not it is possible to find a general solution.","['ordinary-differential-equations', 'maple']"
2668640,"Will 75 element subset S of $\{1, 2, 3, .\ldots, 100\}$ must contain three consecutive integers?","Intuition says that it should be correct. Trying to see this from pigeonhole principle, I say that there are only 98 combinations of pair possible from (1,2,3) to (98,99,100) which will have to be in subset S. So I take those 98 pairs as pigeons and 75 elements of S as pigeons. I am not sure if my thinking is correct.","['combinatorics', 'pigeonhole-principle', 'discrete-mathematics']"
2668673,Is a proof using modular arithmetic in a question like this valid?,"It's been two years or so since I've finished my math undergrad (and I'm doing something non-math related now, unfortunately), so I apologize if what is to follow isn't a very good question! Prove that for all Integers $n$, $n(n + 1)(2n + 1)$ will always be divisible by 6. I can do that using induction, but I wanted to try a different way. Does it work to use modular arithmetic in the following way? Let $f(n) = n(n+1)(2n+1) = 2n^3 + 3n^2 + n$. All we need to show is that $f(n)$ is divisible by both $2$ and $3$ for any choice of $n$. Evaluate mod $2$. $f(n) = n(n+1)(2n+1) = n(n+1)(0 + 1)$ mod $2 = n(n+1)$ mod $2$. Two consecutive numbers; one of them must be even, and so $f(n)$ is divisible by $2$. Evaluate mod $3$ There are three possible residues for n modulo $3$: $0, 1,$ or $2$. If the residue is $0$, then $f(n)$ is divisible by $3$. If the residue is $1$, then $f(n) = n(n+1)(2n+1) = 1(1+1)(2*1+1) = 1(2)(3) = 0$ mod $3$. If the residue is $2$, then $f(n) = 2(2+1)(2*2+1) = 2(3)(2) = 0$ mod $3$. In any case, $f(n)$ is divisible by $3$. Since $f(n)$ is divisible by $2$ and by $3$, it is divisible by $6$. The result follows. Thank you!","['number-theory', 'modular-arithmetic', 'discrete-mathematics']"
2668722,"What is the derivative of the inverse of dot (inner) product? $\frac{\partial}{\partial t}\left(\langle A,\;A\rangle\right)^{-1}=?$","What is the derivative of the inverse of dot (inner) product? $$\frac{\partial}{\partial t}\left(\langle A,\;A\rangle\right)^{-1}=?$$ where $A$ is a vector.","['derivatives', 'partial-derivative', 'calculus']"
2668775,Software for computing geometirc data of parametric surfaces,Is there any (possibly free) software suitable for computing geometric quantities of parametric surfaces? Any suggestion will be very appreciated.,"['differential-geometry', 'math-software']"
2668779,Prove that $x^4 + y^4 - 3xy = 2$ is compact,"The exercise consists of showing that the function $f(x,y)=x^4 + y^4$ has a global minimum and maximum under the constraint $x^4 + y^4 - 2xy = 2$. In the solution to the exercise, it it follows that the constraint is compact if we can show that $\lim_{x^2 + y^2 \rightarrow \infty} x^4 + y^4 - 3xy - 2 \rightarrow \infty$.Why this is the case? My intuition tells me that this is because the $x^4$ and $y^4$ terms dominates the other two terms when $x$ and $y$ gets large. This would then imply that $x$ and $y$ cannot get arbitrarily big without violating the constraint. Does this imply that if the limit of the constraint was $0$, that the domain would not be compact? Is my reasoning valid? Many thanks,","['multivariable-calculus', 'optimization']"
2668788,"What is the algebraic structure that the rules of the ""Algebra"" hold for? Is it an ""Algebra""?","It is been some time since I studied abstract algebra. But I'm lately teaching some high school students ""Algebra"". On this level this basically means working with variables, and understanding that certain rules hold for those variables (which represent real numbers). For example: $$ 
(a+b)^2 = a^2 +2ab + b^2 \\
a^na^m = a^{n+m} \\
x^2+bx+c = (x+m)(x+n) \quad \text{if } m+n=b \text{ and } mn =c
$$ Now in those books that my highschool students read, they never mention for which kind of elements rules like these are true. They just state those rules. First, I was thinking that this was just sloppy. I would have written something like for real numbers $a,b$ the following rule hold: ... But then later I realized, wait, those rules are of course much more general. And I can also recall once having learned that there is something like an Algebra, which is some algebraic structure with some rules defined on it. I maybe see connections that are not really here. But is the subject ""Algebra"" on highschool called Algebra because the rules they learn are valid for any Algebra as an algebraic structure? Is that also the reason that they don't specify that the rules are valid for real numbers, because the rules are in fact much more general (but they haven't formally learned about those more general structures, so you can not specify it).","['algebra-precalculus', 'abstract-algebra']"
2668789,"Showing $f(a,a)\ne f(b,b) \forall a,b \in S, a\ne b$","Question: Let $S=\{1,2,3,...,n\}$ where n is an odd integer. Let $f$ be a function defined on $\{(i,j):i,j\in S\}$ with properties such that: a) $f(s,r)=f(r,s)$ b) $\{f(r,s):s\in S\}=S \space\forall\space r\in S$ Prove $\{f(r,r):r\in S\}=S$ I have concluded that we can make a table just like a Sudoku that is symmetric across the diagonal. Each row and column would hold each element in S exactly once. I feel like the fact that n is odd is important but I'm not able to bring it in play. Basically we need to show the diagonal has no repetition of elements Any help will be appreciated","['elementary-set-theory', 'functions']"
2668795,Bounded solution to general nonautonomous ODE,"Suppose that for each $t\in\mathbf{R}$ we have an $n\times n$ matrix $A(t)$ and that there exists an $m\geq 0$ in such a way that for each $|t|\geq m$ the matrix $A(t)$ is positive definite. The family of matrices $A$ depends continuously on the parameter $t$. Moreover, the matrix norm of $A(t)$ is bounded by some constant. Now consider the following ODE
$$\dot{x}(t)=A(t)x(t).$$
Then from the Cauchy-Lipschitz theorem, it follows that for each $y_0\in\mathbf{R}^n$ there exists a unique solution $x(t)$ of this ODE with $x(0)=y_0$. My question is: can I conclude that $x=0$ is the only bounded solution? For $A$ independent of $t$ this is true, as we can compute the solution exactly and just see that any non-trivial solution is unbounded. For $n=1$, it is also true: for some fixed $t>m$ we can look at any solution $x$ with $x(t)>0$ (if $x(t)<0$ just look at $-x$), then the equation and the positive definiteness implies $x'(t)>0$. Hence $x$ is increasing at that point, which means that it grows to infinity as $t\rightarrow\infty$. Since any non-trivial solution to this ODE is non-zero at some $t>m$ it follows that $x=0$ is the only bounded solution. However, in the general non-autonomous $n\times n$ case I do not see how this works precisely. I do not necessarily need a proof, a reference to a book or paper is fine as well. Update: Thanks to humanStampedist I discovered I at least need to assume that $A(t)\rightarrow A^{\pm}$ as $t\rightarrow\pm\infty$ for some positive definite matrices $A^{\pm}$. However, assuming this, I still do not know the solution, so more help is needed.",['ordinary-differential-equations']
2668820,Is it possible to evaluate this integral using beta and gamma functions?,"There was an integral posted on Brilliant the other day, which is:
$$
\int_{0}^{\infty}\ln\left(\frac{1 + x^{11}}{1 + x^{3}}\right)
\,{\mathrm{d}x \over \left(1 + x^{2}\right)\ln\left(x\right)}
$$ I have seen the solution, but I was wondering if we could take a different approach and use gamma and beta functions instead. Would that be possible? Would it be possible to use this result? $$\int_0^{\infty} \frac{t^{x-1}}{(1+t)^{x+y}}dt= \beta(x,y)$$ Edited: After giving it some thought, there is no connection between the property I wrote above and the integral. However, after searching I have found this property: -$$\int_0^{\infty} \frac{t^{x-1}\ln(1+t)}{(1+t)^{x+y}}=\frac {\partial}{\partial y} \beta(x,y)$$ But I am still not very sure of how to apply it in order to solve that integral, or whether there are other properties we could perhaps use.","['integration', 'gamma-function', 'beta-function']"
2668826,A quirky proof for a limit of an integral,"I am stuck on this result, which the professor wrote as ""trivial"", but I don't find a way out. I have the function $$f_{\alpha}(t) = \frac{1}{2\pi} \sum_{k = 1}^{+\infty} \frac{1}{k}\int_0^{\pi} (\alpha(p))^k \sin^{2k}(\epsilon(p) t)\ dp$$ and he told use that for $t\to +\infty$ we have: $$f_{\alpha}(t) = \frac{1}{2\pi} \sum_{k = 1}^{+\infty} \frac{1}{4^k k}\binom{2k}{k}\int_0^{\pi} (\alpha(p))^k\ dp$$ Now, it's all about the sine since it's the only term with a dependance on $t$. Yet I cannot find a way to send $$\sin^{2k}(\epsilon(p) t)$$ into $$\frac{1}{4^k}\binom{2k}{k}$$ Any help? Thank you so much. More Details $$\epsilon(p)$$ Is a positive, limited and continuous function. The ""true"" starting point was $$f_{\alpha}(t) = -\frac{1}{2\pi}\int_0^{\pi} \log\left(1 - \alpha(p)\sin^2(\epsilon(p)t)\right)\ dp$$ Then I thought I could have expanded the logarithm in series. Maybe I shouldn't had to...","['limits', 'asymptotics', 'trigonometry', 'integration', 'power-series']"
2668833,Transient terms in the solution of a linear differential equation,I know how to solve a linear differential equation. But question is that what does that mean transient terms in general solution.,['ordinary-differential-equations']
2668840,$a_{n+1}=\frac2{a_n+a_{n−1}}$ . Prove that this sequence has a limit. [duplicate],"This question already has answers here : sequence of positive numbers satisfying $a_{n+1}=\frac{2}{a_n+a_{n-1}}$, prove it converges (2 answers) Closed 6 years ago . The sequense $\{a_n\}$ such that $a_1>0, a_2>0$ and $$a_{n+1}=\frac2{a_n+a_{n−1}}$$ for $n≥2$. Prove that this sequence has a limit. I know I need to prove
 1) the sequence is monotone; 2) the sequence is bounded. But sequense is not monotone. Any hints?","['real-analysis', 'sequences-and-series', 'calculus', 'limits']"
2668858,$36 \leq 4(a^3+b^3+c^3+d^3) - (a^4+b^4+c^4+d^4)\leq4 8.$ [duplicate],"This question already has an answer here : $ a+b+c+d=6 , a^2+b^2+c^2+d^2=12$ $\implies$ $ 36 \leq 4(a^3+b^3+c^3+d^3)-(a^4+b^4+c^4+d^4) \leq48 $ (1 answer) Closed 6 years ago . Let $a,b,c,d \in \Bbb R$, $a+b+c+d=6$ and $a^2+b^2+c^2+d^2=12$. Then
$$36 \leq 4(a^3+b^3+c^3+d^3) - (a^4+b^4+c^4+d^4)\leq4
8.$$ I have found only two bounds: $216 \geq a^3+b^3+c^3+d^3$ and $144 \geq a^4+b^4+c^4+d^4$. How to prove this inequality?","['algebra-precalculus', 'inequality', 'polynomials']"
2668904,"If the Jacobian is the first derivative, the Hessian is the second derivative, what is the third derivative called?","I'm wondering about the following: If the Jacobian is the first derivative, the Hessian is the second derivative, what is the third derivative called?","['multivariable-calculus', 'matrix-calculus', 'terminology', 'derivatives']"
2668918,Covariance of two truncated random variables,"Assume that $X=(X_1,X_2)^T$ is a random vector that is multivariate normal with mean vector $\mu$ and variance-covariance matrix $\Sigma$. I.e. we have $$ X \sim N_2(\mu, \Sigma).$$ I am interested in the truncated version of this normal distribution and assume that $X_1$ and $X_2$ are smaller than some threshold $c$. Hence I am searching for $X^*=(X_1^*,X_2^*)^T$ that is jointly trucnated normal $$ X^*~\sim TN_2(\mu, \Sigma,c)$$
While there are formulas for the expectation and the variance of the univariate truncated normal I do not know how to compute the covariance of $X_1^*$ and $X_2^*$: $\operatorname{Cov}(X_1^*,X_2^*)= \operatorname{Cov}(X_1,X_2\mid X_1<c,X_2<c)$.","['statistics', 'covariance', 'normal-distribution']"
2668919,Can two different natural numbers raised to the same irrational power be integers? [duplicate],"This question already has an answer here : $n^a$ integral for all integer $n$ implies $a$ integral (1 answer) Closed 6 years ago . Is it possible to find an $\alpha\in\mathbb R$, $\alpha>0$ so that for all $n\in\mathbb N$, $n^\alpha\in\mathbb N$? A  stronger(restricted) problem: Can $2^\alpha$ and $3^\alpha$ be simultaneously integers?? Here $\alpha >0$. For the second one, I can only reduce to $\cfrac{\log 3}{\log 2} = \cfrac{\log s}{\log q}$ for integer solution $(s,q)$, and then no idea..... For the first one, we have excluded all $\alpha\in\mathbb Q$(which is easy). I tried to use large enough $n^\alpha\in\mathbb N$ and to show $(n+1)^\alpha$ fails to be an integer but I failed. I think there is more advanced number theoretic technique to be used.","['number-theory', 'transcendental-numbers', 'irrational-numbers']"
2668954,Boundary point & critical point of a function,Is it a must that all critical points are interior point for a function ?😕 My question is can a boundary point be critical point of a function??,"['derivatives', 'calculus']"
2669014,Are these functions linearly dependent?,"The Wronskian of two functions is $W(t) = t^2 - 4$. Are these functions linearly dependent? I don't think they are, since the Wronskian is only equal to zero when $t = 2$ or $t = -2$. I'm not sure though, since the Wronskian has thus far only been used in my class for functions of which we know they're solutions to a differential equation. Question: Can you conclude that these functions are linearly independent because their Wronskian is only equal to zero at a couple of points?","['ordinary-differential-equations', 'linear-algebra']"
2669051,"how to show that $C[0,1]$ is not a Hilbert space with respect to any inner product","Show that the space $C[0, 1]$ of real-valued continuous functions on the
unit interval $[0, 1]$ with the sup norm
$$
\|f\|=\sup\{|f(x)|:\ x\in[0,1]\}
$$
is not a Hilbert space  with respect to any  inner  product . My attempts:  as I have to find a Cauchy sequence  $(f_n)_n$ which converges to a function $f$ which is not continuous, but I can't construct such a sequence $(f_n)_n$.",['functional-analysis']
2669141,Number of roots of $z^4+z^3+4z^2+2z+3=0$ in each quadrants,"This question has been asked but I am stuck with my method. I have shown that the roots can not be on the real and imaginary axis. Since the coefficients are real and thus the roots must be in conjugate pairs. So If there is no root in first quadrant (or right half plane), then we have 2 roots in second quadrant and third quadrant respectively. (this is the answer to this question) So I am going to show that there is no root in right half plane. Consider the integral along the semi-circle in right half plane with radius $R$  $$\int_{C}\dfrac{f'}{f}dz=\int_{-Ri}^{Ri}+\int_{-\pi/2}^{\pi/2}\dfrac{4z^3+3z^2+8z+2}{z^4+z^3+4z^2+2z+3}dz$$ For the second part, $$\int_{-\pi/2}^{\pi/2}\dfrac{4z^3+3z^2+8z+2}{z^4+z^3+4z^2+2z+3}dz=i\int_{-\pi/2}^{\pi/2}\dfrac{4z^4+3z^3+8z^2+2z}{z^4+z^3+4z^2+2z+3}d\theta=4\pi i$$
as $R\rightarrow \infty$. For the first part,
\begin{align*}
&\int_{-Ri}^{Ri}\dfrac{4z^3+3z^2+8z+2}{z^4+z^3+4z^2+2z+3}dz\\
&=\int^R_{-R}\dfrac{3y^2-2+i(4y^3-8y)}{y^4-4y^2+3-i(y^3+2y)}idy\\
\\
&=\int^R_{-R}\dfrac{(3y^2-3)(y^4-4y^2+3)-(4y^3-8y)(y^3-2y)+i[(4y^3-8y)(y^4-4y^2+3)+(y^3-2y)(3y^2-2)]}{(y^4-4y^2+3)^2+(y^3+2y)^2}idy\\
&=\int^R_{-R} i(even \,\,part)-(odd \,\,part) dy\\
&=\int^R_{-R} i(even \,\,part) \,\,dy
\end{align*}
It is expected that $\int^R_{-R} i(even \,\,part) \,\,dy=-4\pi i$, then we are done, but how? Also is there any method using Rouche theorem?","['complex-analysis', 'roots']"
