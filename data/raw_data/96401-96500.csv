question_id,title,body,tags
1327268,"Find $a$, when $\tan a$ is given in terms of $\tan1^{\circ}$ and $\tan2^{\circ}$.","If $\tan\alpha = {(1+\tan1°)(1+\tan2°)-2 \over (1-\tan1°)(1-\tan2°) - 2}$ and $\alpha \in (0°, 90°)$ then $\alpha$ is equal to? This is task from my faculty entrance exam workbook. This is mostly high school level and I can only assume that I need to use addition trigonometry formulas or double angle, but I do not how, may someone give me some steps or hint how to do this? EDIT: I haven't done Componendo and Dividendo ever, is there any other way to solve this equation?",['trigonometry']
1327302,System of Equations: any solutions at all?,"I am looking for any complex number solutions to the system of equations: $$\begin{align}
|a|^2+|b|^2+|c|^2&=\frac13
\\ \bar{a}b+a\bar{c}+\bar{b}c&=\frac16 (2+\sqrt{3}i).
\end{align}$$ Note I put inequality in the tags as I imagine it is an inequality that shows that this has no solutions (as I suspect is the case). This is connected to my other question ... I have found that $(4,1,1)/6$ and $\mu=(2,2+\sqrt{3}i,2-\sqrt{3}i)/6$ are square roots of $(2,1,1)/4$ in $(\mathbb{C}\mathbb{Z}_3,\star)$ but am trying to understand why $\mu$ is not positive in the C*-algebra when, for example, $(14,-6+5i,-6-5i)$ is.","['systems-of-equations', 'algebra-precalculus', 'inequality']"
1327304,solving differential equation?,"I have encountered this set of equation in a book explaining the cycloid motion of particle in orthogonal magnetic and electric field. In usual coordinate system. $y''(t)=pz'(t)$ $z''(t)=p(q-y'(t))$ where p and q are constants and $y(t)$, $z(t)$ are position of particle in space at time t.Their general solution they written is $y(t)=C_1\cos(pt)+C_2\sin(pt)+qt+C_3$ $z(t)=C_2\cos(pt)-C_1\sin(pt)+C_4$ which i am unable to solve. Please help.",['ordinary-differential-equations']
1327361,what is the sup and inf of absolute value of $1+z+z^2+ ...+z^n$?,"What is the supremum and the infimum of the absolute value of $1+z+z^2+ \dots+z^n$ when $z$ is a complex number and $z$ is inside the unit circle on the complex plane, which means $zz^*<1$? I tried such as when $z \geq 1$ on $\mathbb{R}$ it seems to have the supremum $n+1$ and when $z \geq 0$ it seems to have the infimum $1$,
but I couldn't prove it.","['supremum-and-infimum', 'complex-analysis']"
1327370,Showing internal angles of a square are unaffected by a mapping,"I recently had an exam in complex analysis, and I am slightly confused by one of the questions, so I'd appreciate any clarification: The mapping from the complex $z$ plane to the complex $w$ plane is given by: $$f:z\mapsto w=e^{z}$$ Find the image in the $w$ complex plane of the map $f$ applied to the square in the $z$ complex plane with vertices at $0$, $a$, $a(1+i)$, and $ai$, where $0 < a < \pi/2$ is real. Show that the internal angles at the vertices of the square are unchanged by the mapping. I am unsure how this can possibly be true. If we map all of the points to the $w$-plane using $f(z)$, then we have: $$w_{1}=e^{0}=1,\: w_{2}=e^{a},\: w_{3} = e^{a(1+i)}=e^{a}(\cos(a)+i\sin(a)),\:w_{4} = e^{ai} = \cos(a) + i\sin(a)$$ If we plot this in the complex $w$ plane, for a reasonable value of $a$, for instance $a=\pi/4$, then we have something like the following: We can see that the top two vertices have their angles preserved, but the bottom two do not. Is the question wrong, or am I misunderstanding something fundamental?","['conformal-geometry', 'complex-analysis', 'complex-numbers', 'functions']"
1327379,What do $\bigcup_{n=1}^\infty S_n$ and $\bigcap_{n=1}^\infty S_n$ mean?,"In some cases, we will have to consider the union or the intersection of several, even infinitely many sets, defined in the obvious way. For example, if for every positive integer $n$, we are given a set $S_n$, then
  $$\bbox[border:1px solid red]{\bigcup_{n=1}^\infty S_n}=S_1\cup S_2\cup\cdots=\{x\mid x\in S_n\text{ for some }n\},$$
  and
  $$\bigcap_{n=1}^\infty S_n=S_1\cap S_2\cap\cdots=\{x\mid x\in S_n\text{ for all }n\}.$$
  Two sets are said to be disjoint if their intersection is empty. More generally, several sets are said to be disjoint if no two of them have a common element. A collection of sets is said to be a partition of a set $S$ if the sets in the collection are disjoint and their union is $S$. Normally what I know is that you can make a union or an intersection between only two sets. In this expression, there is a big union of sets. I'm asking about the meaning of this expression – what does it mean? What does the infinity sign do at the top? Things are even more complicated with De Morgan's laws, which use the same expression: Two particularly useful properties are given by De Morgan's laws which state that
  $$\left(\bigcup_nS_n\right)^c=\bigcap_nS_n^c,\quad\quad\quad\quad\left(\bigcap_nS_n\right)^c=\bigcup_nS_n^c.$$ Anyone who can explain to me the expression or De Morgan's laws would be much appreciated.","['notation', 'elementary-set-theory', 'probability', 'statistics']"
1327411,Matrix with non-negative eigenvalues (and additional assumption),"Let $A \in \mathbb{R}^{n \times n}$ be positive semi-definite ($A = A^\top \succcurlyeq 0$) and with positive diagonal elements ($A_{i,i} > 0$ for all $i$). Assume that both the column and the row sum of $A$ is $0$, i.e., for all $i$, $\sum_{j} A_{i,j} = 0$, and for all $j$, $\sum_{i} A_{i,j} = 0$. Also assume that $A$ has exactly one eigenvalue equal to $0$. Let $b, c \in \mathbb{R}^n$ be element-wise positive and non-negative vectors respectively, i.e., $b > 0$ and $c \geq 0$. Assume that $c^\top b > 0$. Prove that the $(n+1)$-dimensional matrix
$$ \left[ \begin{matrix} A & b \\ c^\top A & c^\top b\end{matrix} \right]$$
has eigenvalues with non-negative real part. Comments. Numerics show that the claim is true.
In here it is shown that $A \succcurlyeq 0$ is not enough for the claim to be true, thus the additional assumption on $A$ would be needed.","['eigenvalues-eigenvectors', 'linear-algebra', 'real-analysis', 'matrices']"
1327450,What are the bounds (upper and lower) for $|A+A|$?,"Let $A$ be a finite set of real (or complex) numbers. If I consider sets with small  sizes, we have that: If $A$ is the empty set, then $A+A$ is also empty. If $A$ is a singleton, then $A+A$ is also a singleton. If $|A|=2,$ then $|A+A|=3.$ If $|A|=3,$ then $|A+A|$ can be at most $6.$ The set $A=\{1, 2, 3\}$ shows we can have that $|A+A|=5,$ But we can not obtain $4.$ Obvious bounds for $A+A$ are $|A|\le |A+A|\le|A|^2.$
But for large $|A|$ values, it looks like that we can find more sharpe bounds for $|A+A|$ than above ones. MY QUESTION IS: How can I estimate the size of the set $A+A=\{a+b :a,b\in A\}$ using the size of $A$ ?","['asymptotics', 'estimation', 'elementary-set-theory', 'sumset']"
1327451,Trigonometry and Proportions,"Numbers are given $a = {\sin1\over \sin2}$, $b = {\sin2\over \sin3}$ and $c = {\sin3\over \sin4}$. Then: $a < b < c$ $c < b < a$ $c < a < b$ What is the solution and can someone explain me why or just give me a hint. This seems to me that I need to use addition formulas and double angle formulas but I do not know how to find that out?
NOTICE : Angles are not expressed in degrees!","['inequality', 'trigonometry']"
1327469,"Going from $f = u(x,y) +iv(x,y)$ to $f(z) = f(x+iy)$","Quick question: Quite often, when doing stuff in Complex Analysis, I'm asked to put something of the form $f = u+iv$ into the form $f(z)$. I HATE this step, because it always amounts to me just looking at it, and trying to sorta guess half way, and work backwards from the guess. It's time-consuming, tedious and clumsy. This will not do. I'm now looking for appropriate theory (in the ideal case, an algorithm), or some other simple approach that will remove much of the guess work, remove stuff like the 'magically noticing' obscure trig identities, and just make the whole thing a bit more palatable. What are some good tactics? Thanks in advance.",['complex-analysis']
1327470,Differences between a quotient map and a continuous function in topology,"Def. for a continuous function: Let $X$ and $Y$ be topological spaces. A function $f : X \rightarrow Y$ 
  is continuous if $f^{-1} (V)$ is open in $X$ for every open set $V \subseteq Y$. Def. for a quotient map: Let $X$ be a topological space and $A$ be a set (that is not 
  necessarily a subset of $X$). Let $p : X \rightarrow A$ be a surjective map. Define a subset $U$ of $A$ to be open in $A$ if and only if $p^{-1} (U)$ is open in $X$. The resultant collection of open sets in $A$ is called the quotient topology induced by $p$ , and the function $p$ is called a quotient map. In addition to surjectivity of a quotient map, are there any difference s between this two concepts? From many different examples in comparison, they seem to be different 'topics' but actually no other difference more than surjectivity in case of a quotient map (?) Also the book claims that a quotient map is always a continuous function.","['continuity', 'quotient-spaces', 'general-topology']"
1327543,Does the Euler product for the Dirichlet $\beta$-function converge for all $\Re(s)>\frac12$?,"The Dirichlet $\beta$-function is defined for $\Re(s)>0$ as: $$\beta(s) = \sum_{n=0}^\infty\frac{(-1)^n}{(2n+1)^s}$$ It has the following Euler product (I used that Dirichlet character $\chi_{4}(p)=\sin\left(\frac{p \,\pi}{2}\right)$): $$\prod_p \bigg(\frac {p^s}{p^s-\sin\left(\frac{p \,\pi}{2}\right)} \bigg)$$ Numerical evidence suggests that this Euler product also (slowly) converges for values $\Re(s)>\frac12$. Does convergence in the domain $\frac12 < \Re(s) \le 1$ indeed occur? If so, could this be proven (I guess a proof would also imply that all complex zeros of $\beta(s)$ must reside on the critical line)? P.S.: Just to share that by multiplying the Leibniz formula for $\pi$ ($\beta(1)=\frac{\pi}{4}$) and this formula (35) , gives the very elegant relationship: $$\prod_p \bigg(\frac{p-\sin\left(\frac{p \,\pi}{2}\right)}{{p+\sin\left(\frac{p \,\pi}{2}\right)}} \bigg)=2$$","['prime-numbers', 'number-theory', 'euler-product', 'dirichlet-series']"
1327544,How many triangles can be made from $n$ points on a line and not on a line,"We have a plane with $n$ points $(n\ge 34)$. $17$ points are on one line, and the rest are  positioned such that no three points are on one line. How many triangles can we make from the $n$ points? I tried a complete counting approach because I think it would be simpler then graphs, we also haven't seen much use of graph theory in combinatorial applications. My attempt: Define the 17 points that are on the line as $A$ and the rest as $B$. From the points in $B$ only: $\binom {n-17} 3$. Two points from $A$ and one from $B$: $\binom {17} 2 \binom {n-17} 1$. Two points from $B$ and one from $A$: $\binom {17} 1 \binom {n-17} 2$. So the answer would be $\binom {n-17} 3 + \binom {17} 2 \binom {n-17} 1 +\binom {17} 1 \binom {n-17} 2$. Is this alright? There's no double counting since the cases are foreign to each other right?","['discrete-mathematics', 'combinatorics']"
1327559,Meeting of people.,"In a group of k people, some are acquainted with each other and some are not. There are two rooms for dinner. Every person chooses to stay in that room, in which he has an even number of acquaintances. Prove that the number of different ways that people can be divided in these rooms is always a power of 2. I've tried to switch it in a graph problem, considering every person as a point and connecting each two points with an edge if they are acquainted. Then we know that the number of odd- degree points is even. But I don't know how to proceed. Any help would be appreciated. Thanks in advance.","['contest-math', 'graph-theory', 'combinatorics']"
1327574,"Discrete Math: Unions, Intersections, Complements","Are these answers correct? The union and intersection only include the elements in the universal set? $U = \{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\}$ (where $U$ is only a subset of the Universe) $A = \{2, 4, 6, 8, 10, 11, 12\}$ $B = \{0, 1, 2, 3, 4, 5, 6, 7, 8, 9\}$ $A \cup B = \{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\}$ $A \cap B = \{2, 4, 6, 8\}$ $(A \cap B)'= \{1, 3, 5, 7, 9, 10, 11, 12\}$ Here is the definition of union given in my book: $A \cup  B = \{ x \in S | x \in A \text{ or } x \in B\}$, where $A$ and $B$ are subsets of the universal set $S$.","['elementary-set-theory', 'discrete-mathematics']"
1327575,How to find $\lim _{ n\to \infty } \frac { ({ n!) }^{ 1\over n } }{ n } $? [duplicate],"This question already has answers here : Finding the limit of $\frac {n}{\sqrt[n]{n!}}$ (11 answers) Closed 9 years ago . How to find $\lim _{ n\to \infty  } \frac { ({ n!) }^{ 1\over n } }{ n } $ ?
I tried taking using logarithm to bring the expression to sum form and then tried L Hospital's Rule.But its not working.Please help! This is what wolfram alpha is showing,but its not providing the steps! BTW if someone can tell me a method without using integration, I'd love to know!","['factorial', 'limits']"
1327579,Solving the integral $\int x\sqrt{1+x}\ dx $ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question I need to solve the following indefinite integral by substitution $$\int x\sqrt{1+x}\  dx $$with $u=1+x$
Can anyone help me by showing me detailed step by step solution? Thanks in advance!","['substitution', 'integration']"
1327626,Sine of an obtuse angle,"In the figure above, $\angle MOP=\theta ,  \angle POP'=90^o$ $$\sin (90^o+\theta)=\sin \angle MOP'=\frac{M'P'}{OP'}(\text{how?})=\frac{OM}{OP}=\cos \theta$$ Sine is opposite side/hypotenuse, then in this case how does the author determine the sine of an obtuse angle? (Is it possible with elementary geometry? This topic is far before laws of sine and cosine)",['trigonometry']
1327630,blow-ups and fields of definition,"Let $X$ be a smooth variety over some field $k$, not necessarily algebraically closed. Let $Z$ be a closed subvariety of $X$ which is only defined over an extension of $k$ (e.g. a closed point which is not $k$-rational). Consider the blow-up $\mathrm{Bl}_Z X$ of $X$ along $Z$. Is $\mathrm{Bl}_Z X$ defined over $k$? I think this is the case but I would appreciate some help to understand what is going on.",['algebraic-geometry']
1327646,On the solvability of the negative Pell equation $x^2-2py^2 = -1$,"Given prime $p=8n+1$ . Then $$x^2-2py^2 = -1\tag1$$ is not solvable for, $$p_1= 17, 73, 89, 97, 193, 233, 241, 257, 281, 337, 353, 401, 433, 449, 577, 593,601, 617, 641,\dots$$ but is  solvable for, $$p_2= 41, 113, 137, 313, 409, 457, 521, 569, 761, 809, 857, 953, 1129, 1201, 1321, 1601,\dots$$ Compare to the primes of form $p=u^2+32v^2$ ( A105389 ): $$p_3 = 41, 113, 137, \color{brown}{257}, 313,  \color{brown}{337},  \color{brown}{353}, 409, 457, 521, 569,  \color{brown}{577},  \color{brown}{593}, 761, 809, 857,  \color{brown}{881}, 953, \dots$$ (Also, $p_3$ has class number $h(-p)$ divisible by 8.) Q:  Is $p_2$ a subset of $p_3$ ? (Equivalently, for $p=8n+1$ , is it true that a necessary but not sufficient condition such that $(1)$ is solvable is that $p = u^2+32v^2$ ?) I have checked that all solvable $p = 8n+1 \leq 18089$ has the form $u^2+32v^2$ , but I don't know if all solvable $p$ have that form. $\color{blue}{Edit}$ : (In response to Jagy's answer.) The primes of form $p=u^2+64v^2$ ( A014754 ) are, $$p_4 = 73, 89, 113, 233, 257, 281, 337, 353, 577, 593, 601, 617, 881, 937, 1033, 1049, 1097\dots$$ but neither $p_1$ nor $p_2$ is a subset of $p_4$ . However, the primes of form $p=u^2+64v^2=16n+9$ , $$p_5 = 73, 89, 233, 281, 601, 617, 937, 1033, 1049, 1097,\dots$$ as a result of Dirichlet, is unsolvable and so is a subset of $p_1$ .","['pell-type-equations', 'class-field-theory', 'number-theory', 'diophantine-equations']"
1327652,Is $A+uv^T$ invertible?,"Let $u, v \in \mathbb{R}^n$ and $A \in \mathbb{R}^{n\times n}$. For which condition(s) this matrix is invertible? $$A + uv^T$$ and find the inverse of this matrix. I tried to take elementary matrices, $I - \alpha xy^T$, to solve this problem, where $\alpha$ is a constant. $(I-\alpha xy^T)^{-1} = I - \beta xy^T$ iff $\beta = \frac{\alpha}{\alpha y^T x - 1}$ where $\alpha y^T x -1 \neq 0$. If we take $x=(0,0,\ldots, l_{i+1,i},\ldots,l_{n,i})^T$ and $y=e_i=(0,\ldots, 1,\ldots,0)^T$ then we can find a lower triangular matrix like below: $$L = \left[
\begin{array}{ccccc}
 1 & 0 & \cdots & 0 & 0 \\
 \ell _{2,1} & 1 & \cdots & 0 & 0 \\
 \vdots & \vdots & \ddots & \vdots & \vdots \\
 \ell _{n-1,1} & \ell _{n-1,2} &  & 1 & 0 \\
 \ell _{n,1} & \ell _{n,2} & \cdots & \ell _{n,n-1} & 1 \\
\end{array}
\right]=I+\ell_1e_1^T + \ldots + \ell_{n-1}e_{n-1}^T$$ But I don't know how to complete ?","['linear-algebra', 'matrices']"
1327665,Which law in probability theory states the following?,"Which law in probability theory states the following? If we have a large enough number of samples, their histogram function converges  their true probability density function. (for a continuous random variable) I know that ""In probability theory, the law of large numbers (LLN) is a theorem that describes the result of performing the same experiment a large number of times. According to the law, the average of the results obtained from a large number of trials should be close to the expected value, and will tend to become closer as more trials are performed."" But this law is just about expected value. It does not include variance or probability density function.","['probability-theory', 'probability', 'statistics']"
1327685,Continuous function from a compact space to a Hausdorff space is a closed function,"We have that $f\colon X\to Y$ is a continuous function, $X$ is a compact space and $Y$ is a Hausdorff space. Prove that $f$ is a closed function.","['closed-map', 'general-topology', 'compactness']"
1327696,Can this be a way to prove that $\Bbb{R}^2$ and $\Bbb{R}^3$ are not homeomorphic?,"The normal way I use to prove that $\Bbb{R}$ and $\Bbb{R}^2$ are not homeomorphic is by removing a point and then using path connectedness.
But this method doesn't seem to work for $\Bbb{R}^m$ and $\Bbb{R}^n$ and it ends up that its better if you use fundamental groups. But what if I remove a line instead of a point from both the topological spaces. Does the argument still fail or will it lead to a proof?",['general-topology']
1327700,Finding all accumulation points of the a set.,"I am working on homework for my intro to analysis class and I was assigned a problem to find all accumulation points of the set $S=\{x\mid x\in[0,1]$ and $x$ is rational$\}$. I hodge podged a solution but I feel like it may be incorrect. If anyone could let me know, mostly in that can I assume that the following approximation even exists? I feel like using the fact that $\mathbb{R}$ is ordered should work but I'm not sure. Let k
  be some number in the interval [0,1]
 . Then we can do the following, write an approxmation of k
  as $0.d_{1}$
  where $k-0.1<0.d_{1}<k$
  and $0\le d_{1}\le9$
  Which must be possible as $\mathbb{R}$
  is an ordered field. We know $0.d_{1}=\frac{d_{1}}{10}$
  which is rational. Then we can find a better approxmiation by writing $k$
  as $0.d_1 d_2$
  where $k-0.01<0.d_1 d_2<k$
  and $0\le d_1,d_2\le9$
 . Once again $0.d_1 d_2=\frac{d_1 d_2}{10^{2}}$
  which is rational. Continue by writing $k-10^{-n}<0.d_{1}d_{2}d_{3}\ldots d_{n}<k$
  where $\frac{d_1 d_2 d_3\ldots d_n}{10^n}$
  is obviously rational. Rewrite $ 0.d_1 d_2 d_3\cdots d_n$
  as $\sum_{i=1}^n 10^{-i}\ldots d_i$. Then, if we take the limits of the RHS and LHS of the inequality we get, $$\lim_{n\to\infty}k-10^{-n}=k\text{ and }\lim_{n\to\infty}k=k$$ which by the squeeze theorem says that $$\lim_{n\to\infty}\sum_{i=1}^{n}10^{-i}\cdot d_{i}=k$$
  Repeating this process with $k+0.1>0.d_{1}>k$
  gives the limits: $$\lim_{n\to\infty}k+10^{-n}=k\text{ and }\lim_{n\to\infty}k=k$$ which by the squeeze theorem says that $$\lim_{n\to\infty}\sum_{i=1}^{n}10^{-i}\cdot d_{i}=k.$$ Therefore this shows that every number in the range $[0,1]$
  is bounded above and below by an infinite sum of rational numbers. Which then implies that any number $k\in[0,1]$
  has infinitely many $x\in Q$
  within the range $\left\{ k-\epsilon,\:k+\epsilon\right\} $
  . Therefore the accumulation points of $S=\{x \mid x\in[0,1]$
  and x
  is rational}
 is all of $[0,1]$ Note: I don't actually know the answer to this question if my solution is wrong.",['analysis']
1327734,"Evaluate $\int_{-\infty}^{\infty}\frac{\sqrt{a+ix}}{a^2+x^2}\,dx$ using residue calculus","I'm asked to evaluate 
$$\int_{-\infty}^{\infty}\frac{\sqrt{a+ix}}{a^2+x^2}\,dx$$
$\mathbb{R}\ni a>0$, using residue calculus (where $\sqrt{\cdot}$ is the PV $\sqrt{}$). My approach is as follows: By solving $a+iz=-\alpha, \mathbb{R}\ni\alpha>0$ we find that the branch cut of $\sqrt{a+ix}$ is the line $ia+i\alpha$. Then we verify that $\lim_{R\to\infty}\max_{|z|=R}\frac{\sqrt{a+iz}}{a^2+z^2}R=0$ From these $2$ facts we can conclude that we can close the contour in the bottom half plane, and find
$$\int_{-\infty}^{\infty}\frac{\sqrt{a+ix}}{a^2+x^2}\,dx=-2\pi i\text{Res}_{z=-ai}\frac{\sqrt{a+ix}}{a^2+x^2}=\frac{\sqrt{2}\pi}{\sqrt{a}}$$ However, the problem is that when I try to verify this using Mathematica, it seems to be wrong: Integrate[Sqrt[a + I*x]/(a^2 + x^2), {x, -Infinity, Infinity}]
ConditionalExpression[-(1/(  8 Sqrt[2] Sqrt[a] \[Pi]^(   3/2)))(MeijerG[{{1/2, 3/4, 5/4}, {}}, {{0, 1/2, 1/2}, {}}, -1, 2] +     MeijerG[{{1/2, 3/4, 5/4}, {}}, {{0, 1/2, 1/2}, {}}, 1,      2]), (Re[a^2] >= 0 || a^2 \[NotElement] Reals) && Re[a] > 0] At first I thought this is just some way to complicated way of writing $\frac{\sqrt{2}\pi}{\sqrt{a}}$, but that does not seem to be the case. For example for $a=2$ my answer is $\pi$ while Mathematica's answers is $3.965.. +0.491...i$. Now I would think my answer is correct, since the imaginary part of the function is odd, so we would expect the integral to have imaginary part $0$. Any help would be much appreciated. I'm looking for either: the mistake in my answer, or an explanation for why Mathematica is giving the wrong answer. Thanks. Edit: I'm pretty sure this is a bug in Mathematica at this point, especially considering the following result: a = 2;
N[Integrate[Sqrt[a + I*x]/(a^2 + x^2), {x, -Infinity, Infinity}]]
NIntegrate[Sqrt[a + I*x]/(a^2 + x^2), {x, -Infinity, Infinity}]
3.96542 + 0.491097 I
3.14159 + 0. I So the numeric solver does agree with my answer, while the symbolic solver just seems to be wrong. Unfortunate; I didn't expect Mathematica to have bugs like this, although I think it's inevitable in an application that big.","['solution-verification', 'proof-verification', 'contour-integration', 'residue-calculus', 'complex-analysis']"
1327740,Prove that given graph consisting of vertices numbered with composite numbers is not eulerian,"We have the following graph definition: $$V(G_n)=\{1\leq m\leq n : m = pq\}$$ (so vetices of $G_n$ are composite numbers)
$$E(G_n)=\{\{i,j\}:i\perp j\}$$ (so vertices $i,j$ are connected if and only if they are realtively primes) The problem asks us to prove that $G_{1000}$ is not eulerian. So it seems easy - we only need to find two vertices, such that the parity of degree of first is different than that of the second (or - even simpler - find a vertex with odd degree). Unfortunately I've been struggling with finding such pair for quite some time now. Where should I look then?","['graph-theory', 'number-theory', 'discrete-mathematics']"
1327750,Significance of Sobolev spaces for numerical analysis & PDEs?,"I never had an option to take a Functional Analysis module. I am tied up with other work for the next two months so I won't get a chance to self-study it until September. So one thing I was wondering about is the significance of Sobolev spaces for the fields of numerical analysis and PDEs. I have been told on more than one occasion that they are very important in these fields. Having not taken Functional Analysis, I've never encountered Sobolev spaces before. Would someone be able to give me an overview of what is so significant about these spaces and why are they are so relevant to the above fields?","['sobolev-spaces', 'numerical-methods', 'functional-analysis', 'partial-differential-equations']"
1327752,Maximum a Posteriori (MAP) Estimator of Exponential Random Variable with Uniform Prior,"What would be the Maximum a Posteriori (MAP) estimator for $ \lambda $ for IID $ \left\{ {x}_{i} \right\}_{i = 1}^{N} $ where $ {x}_{i} \sim \exp \left( \lambda \right), \; \lambda \sim U \left[ {u}_{0}, {u}_{1} \right] $? One could assume that $u_0 > 0 $. The Exponential Distribution is given by: $$ f(x; \lambda) = \begin{cases}
\lambda {e}^{-\lambda x} & x \ge 0, \\
0 & x < 0.
\end{cases} $$","['probability-theory', 'probability-distributions', 'estimation', 'probability', 'parameter-estimation']"
1327755,Prove that the antipodal mapping is an isometry on $S^n$. Help understanding the proof.,"Prove that the antipodal mapping $A: S^n \to S^n$ given by $A(p)=-p$ is an isometry. I know that in order to prove that a map $f$ is an isometry of a smooth manifold $M$ it must hold true that
$$\langle v,u\rangle_p = \langle d_f v, d_fu \rangle_{f(p)}$$ Now I found online this document that proves this exercise (Exercise 1.1.). I cannot follow it though. It basically says that in order to prove this we first need to claim that $T_{p}S^n = T_{A(p)}S^n$ and for this it is enough to prove that $T_{p}S^n \subset T_{A(p)}S^n$. Why is this true? In order to show this they claim that $T_{A(p)}S^n \subset \subset T_{A \circ A(p)}S^n = T_pS^n$. What does the $\subset \subset$ mean and why the last relation holds true, i.e. why $T_{A(p)S^n}=T_pS^n$ since these tangent spaces are defined in different points? Finally, why they later claim that $dA_pv = -v$? I do not understand why this also holds true.","['spheres', 'differential-geometry', 'manifolds']"
1327777,Prerequisites for Random Graph Theory,"I would dearly love to know the prerequisites for self-studying Random Graph Theory and Percolation Theory in Probability. My knowledge currently involves: Basic probability concepts: the axioms, random variables, distributions. Limit theorems in probability Random Walk Are these enough or do I need anything extra? It would be great if you kindly pointwise write down ALL the prerequisites, along with a nice book on Random Graphs and Percolation Theory.","['probability-theory', 'book-recommendation', 'reference-request', 'random-graphs']"
1327782,Primitive $p^n$-th root of unity in $\bar{\mathbb{Q}}_p$.,"I am trying to solve the following exercise in Koblitz's "" $p$ -adic Numbers, $p$ -adic analysis, and Zeta-Functions"". Let $p$ be a prime. Let $a$ be a primitive $p^n$ -th root of unity in $\bar{\mathbb{Q}}_p$ . Find $|a-1|_p$ . Can you give me some hints? I was thinking about using the relation given by the irreducible polynomial of $a$ , but this does not seem useful.","['p-adic-number-theory', 'number-theory', 'roots-of-unity']"
1327812,Limit approach to finding $1+2+3+4+\ldots$,"When exploring the divergent series consisting of the sum of all natural numbers $$\sum_{k=1}^\infty k=1+2+3+4+\ldots$$ I came across the following identity involving a one-sided limit: $$\lim_{x\to0^-}\sum_{k=1}^\infty k\exp(kx)\cos(kx)=-\frac{1}{12}$$ Using zeta function regularization yields the same value: $$\sum_{k=1}^\infty k^{-s}=\zeta(s)$$ $$\zeta(-1)=-\frac{1}{12}$$ In general, I found that for $y\neq0$ and $n=1,5,9,13,\ldots$ (i.e. $4m+1$ where $m\in\mathbb{N}$ ), $$\lim_{x\to0^-}\sum_{k=1}^\infty k^n\exp(kxy)\cos(kxy)=\zeta(-n)$$ However, a similar limit did not exist for other powers of $k$ , e.g. $$\lim_{x\to 0^-}\sum_{k=1}^\infty k^2\exp(kx)\cos(kx)$$ $$\lim_{x\to 0^-}\sum_{k=1}^\infty k^3\exp(kx)\cos(kx)$$ The regularized values of the corresponding series are $\zeta(-2)=0$ and $\zeta(-3)=\frac{1}{120}$ . Given this information, I have the following questions: What is the connection between the limit approach and the zeta function approach? Why does the limit expression only seem to converge for $n=4m+1$ ? Can the limit approach be used to find the sum for other powers of $k$ ? If so, how? Here is a plot I made with Mathematica using the command Plot[Evaluate[Sum[k*Exp[x*k]*Cos[x*k], {k, 1, Infinity}]], {x, -16, 16}, PlotRange -> {-.25, .25}, AspectRatio -> 1] Notice how it approaches $-1/12\approx-0.08333$ as $x$ approaches $0$ . Further information: $$\sum_{k=1}^\infty k^n\exp(kx)=\mathrm{Li}_{-n}(\exp(x))=\frac{n!}{(-x)^{n+1}}+\zeta(-n)+O(x)$$ Edit: Based on Micah's answer, we seek an $f$ such that $f(s,0) = 1$ and \begin{align}
\int_0^\infty x^s f(s,x) \,\mathrm{d}x &= 0
\end{align} Let \begin{align}
f(s,x) &= \mathrm{e}^{-x}(1+ax)
\end{align} Then $f(s,0) = 1$ . Assuming $\mathrm{Re}(s) > -1$ , \begin{align}
0
&= \int_0^\infty x^s f(s,x) \,\mathrm{d}x \\
&= \int_0^\infty x^s \mathrm{e}^{-x}(1+ax) \,\mathrm{d}x \\
&= \int_0^\infty x^s \mathrm{e}^{-x} \,\mathrm{d}x + a \int_0^\infty x^{s+1} \mathrm{e}^{-x} \\
&= \Gamma(s+1) + a (s+1) \Gamma(s+1) \\
&= (1 + a(s+1)) \Gamma(s+1) \\
\Longrightarrow a &= -\frac{1}{s+1} \\
\Longrightarrow f(s,x) &= \mathrm{e}^{-x}\left( 1 - \frac{x}{s+1} \right)
\end{align} Thus \begin{align}
\zeta(-s)
&= \lim_{\varepsilon \rightarrow 0^+} \lim_{m \rightarrow \infty} \sum_{n=1}^m n^s f(s, n \varepsilon) \\
&\overset{\star}{=} \lim_{m \rightarrow \infty} \lim_{\varepsilon \rightarrow 0^+} \sum_{n=1}^m n^s f(s, n \varepsilon) \\
&= \lim_{m \rightarrow \infty} \sum_{n=1}^m n^s f(s, 0) \\
&= \lim_{m \rightarrow \infty} \sum_{n=1}^m n^s \\
&= \sum_{n=1}^\infty n^s
\end{align} where the star indicates the non-rigorous step of exchanging limits. In fact, this regulator seems to work for all $s \neq -1$ (see some plots for $s < -1$ below). Hence we can also regularize the harmonic series as follows: \begin{align}
\gamma
&= \frac{1}{2} \lim_{\varepsilon \rightarrow 0^+} (\zeta(1+\varepsilon) + \zeta(1-\varepsilon)) \\
&= \frac{1}{2} \lim_{\varepsilon \rightarrow 0^+} \left(\lim_{m \rightarrow \infty} \sum_{n=1}^m n^{-1-\varepsilon} f(-1-\varepsilon, n \varepsilon) + \lim_{m \rightarrow \infty} \sum_{n=1}^m n^{-1+\varepsilon} f(-1+\varepsilon, n \varepsilon) \right) \\
&= \frac{1}{2} \lim_{\varepsilon \rightarrow 0^+} \lim_{m \rightarrow \infty} \left(\sum_{n=1}^m n^{-1-\varepsilon} f(-1-\varepsilon, n \varepsilon) + \sum_{n=1}^m n^{-1+\varepsilon} f(-1+\varepsilon, n \varepsilon) \right) \\
&\overset{\star}{=} \frac{1}{2} \lim_{m \rightarrow \infty} \lim_{\varepsilon \rightarrow 0^+} \left(\sum_{n=1}^m n^{-1-\varepsilon} f(-1-\varepsilon, n \varepsilon) + \sum_{n=1}^m n^{-1+\varepsilon} f(-1+\varepsilon, n \varepsilon) \right) \\
&= \frac{1}{2} \lim_{m \rightarrow \infty} \left(\sum_{n=1}^m n^{-1} f(-1, 0) + \sum_{n=1}^m n^{-1} f(-1, 0) \right) \\
&= \frac{1}{2} \lim_{m \rightarrow \infty} \left(\sum_{n=1}^m n^{-1} + \sum_{n=1}^m n^{-1} \right) \\
&= \lim_{m \rightarrow \infty} \sum_{n=1}^m n^{-1} \\
&= \sum_{n=1}^\infty n^{-1} \\
\end{align} Here is the Mathematica code and its plots: f[s_, x_] := Exp[-x] (1 + a x)
g[s_, t_] := 
 Evaluate@Simplify[
   f[s, t] /. Solve[Integrate[x^s f[s, x], {x, 0, Infinity}] == 0, a],
    Assumptions -> Re[s] > -1]
g[s, t]
Table[{s, 
    Plot[{Zeta[-s], 
      Sum[n^s g[s, n \[Epsilon]], {n, 1, 1000}]}, {\[Epsilon], 0, 1}, 
     Evaluated -> True]}, {s, -4, 4, 1/2}] // TableForm // Quiet
Plot[{EulerGamma, 
  Sum[(n^(-1 + \[Epsilon]) g[-1 + \[Epsilon], n \[Epsilon]] + 
    n^(-1 - \[Epsilon]) g[-1 - \[Epsilon], n \[Epsilon]])/
   2, {n, 1, 1000}]}, {\[Epsilon], 0, 1}, Evaluated -> True]","['limits', 'riemann-zeta', 'divergent-series', 'laurent-series', 'sequences-and-series']"
1327834,The set of all matrix with rank $n-1$ is a hypersurface.,"Prove that the set $M$ of $n\times n$ matrices with rank $n-1$ is a hypersurface in $\mathbb{R}^{n²}$ and find the tangent space at $A=(a_{ij})$ where $a_{ij}=\begin{cases}
 \delta_{ij} \ \text{if} \ (i,j)\neq(n,n) \\ 
 0 \ \ \ \text{if} \  (i,j)=(n,n)
\end{cases}$ The teacher left this problem along with others to study for the test (a graduate course in multivariable calculus).  If I find a function $f:\mathbb{R}^{n²} \rightarrow \mathbb{R}\in C^1$ such that $M=f^{-1}(c)$ and $grad \ f(x)\neq 0 \  (\forall x;f(x)=c$) do the problem becomes a merely computation but I can't find such function.
Can anybody help me? Thanks in advance.","['smooth-manifolds', 'manifolds', 'multivariable-calculus', 'matrices']"
1327839,Is having $G^N = I$ enough to a matrix $G$ orthogonal?,"I have a matrix $G$ that is cyclic ($G^N = I$) and has determinant $\pm 1 $; is this enough to show that it is orthogonal? If not, what more could I add to make it so?","['orthogonality', 'linear-algebra', 'matrices']"
1327870,"A construction of sigma-algebras - surely not new, right?","I know no descriptive set theory. I've stumbled on something that must be well known, being so simple. But it contradicts something I've been told by smart people; the question is whether it's well known (or at least known). A complete version of this post would be a little long. It seems clear to me that anyone who knows the answer is going to understand what I mean by the standard this and the usual that; if not I can clarify. Context. Say $G$ is a group and $S\subset G$. There are at least three ways to say what $H$, the subgroup of $G$ generated by $S$, is: Let $S_0=S$, and let $S_{n+1}$ be $S_n$ together with all the $xy$ and $x^{-1}$ for $x,y\in S_n$. Then $H=\bigcup_{n=0}^\infty S_n$. (I call this the bottom-up construction.) $H$ is the set of all words in the elements of $S$. $H$ is the intersection of all the subgroups of $G$ containing $S$ (this I tend to think of as ""top-down"".) Not that anyone would ever use (1) in this context. But now let's say $S\subset P(X)$, the powerset of $X$, and we want to describe $A$, the sigma-algebra generated by $S$. The analogue of (3) is what you see in every book on measure theory; some books include the transfinite-recursion analogue of (1) when they want to show that the Borel sets on the line have cardinality $c$. For some time I've speculated on whether there was something like (2) here. There is. (2') The elements of $A$ are exactly the roots of the trees $T$ such that $T$ is well-founded, every node of $T$ is a subset of $X$, every terminal node is an element of $S$, and every other node has either one or countably many subnodes; if a node $E$ has one subsnode $F$ then $E$ is the comlement of $F$, while if $E$ has countably many subnodes it is the union of the subnodes. (Taking advantage of the arity to avoid coloring the nodes to say which operation we're using is probably in poor taste, sorry.) The proof that this works is totally elementary and straightforward from the definition of $A$ as the intersection of all sigma-algebras containing $S$ - no need to confuse the poor students with ordinals. And one can use it to show, for example, that the Borel sets on the line have cardinality $c$. I'd be certain that this was perfectly well known except that smart people have told be that the only way to show the Borel sets have cardinality $c$ is transfinite induction.  Hence the question: This actually is standard, those guys were just unaware of it as I was until yesterday, right?","['set-theory', 'descriptive-set-theory', 'measure-theory']"
1327890,Is there a closed-form expression for Shapley value of glove game?,"Suppose we have a coalition game with transferable utilities, with $m$ players having a right-handed glove and $n$ players having a left-handed glove. The value of a coalition is equal to the number of complete pairs of gloves in it. Then the Shapley value for a player with a right-handed glove is given by: $\frac1{(m+n)!}\sum_{i=1}^{m+n}\sum_{j=0}^{\lfloor i/2 \rfloor-1}(m+n-i)!(i-1)!\binom{m-1}{j}\binom{n}{i-j-1}$ Is there a simple (or at least easy to evaluate) closed-form expression for this? If not, perhaps an approximation for large m,n?","['closed-form', 'game-theory', 'combinatorics']"
1327911,The fundamental vector fields of a principal bundle are vertical.,"Let $p:P\to M$ be a principal $G$-bundle. To each $A$ in the Lie algebra of $G$ corresponds a fundamental vector field $A^*$ on $M$ defined by
$$A^*_u=\frac{d}{dt}|_{t=0} u(exp(tA))$$ How can we see that $A_u^*$ is a vertical vector? Idea: We need to verify that $p_*(A_u^*)=0$. None of the manipulations that I apply to the left hand side help. Supposedly, the statement is obvious from the fact that the action of $G$ takes each fiber to itself.","['principal-bundles', 'lie-groups', 'differential-topology', 'differential-geometry', 'lie-algebras']"
1327935,Find area bounded by $(\frac{x}{3}+\frac{y}{6})^3-9xy=0$,"$C = \{(x,y) \mid (\frac{x}{3}+\frac{y}{6})^3-9xy=0\}$.
I want to find the area bounded by $C$ in first quadrant. Can you tell me how to solve exercises like this?
I have no idea what integral I need to solve, because my curve is implicitly defined.",['integration']
1327962,Linear Recurrence Problem,"$f(0)=3, f(1)=1, f(n)=4f({n-1})+21f({n-2})$ Thought linear recurrence problems usually have subsets of things, and this seems like a new type for me. Can anyone help me out with hints?","['recurrence-relations', 'discrete-mathematics']"
1327976,Find the jacobian,"I'm been struggling with the problem for a quite some time now.
I need to find the jacobian for the following : $$u=x-y$$
$$v=xy$$ What I did : $$x=y+u\\x=\frac{v}{y}\\y=x-u\\y=\frac{v}{x}$$ \begin{vmatrix}
dx/du & dx/dv \\ 
dy/du & dy/dv 
\end{vmatrix} \begin{vmatrix}
1 & \frac{1}{y} \\ 
-1 & \frac{1}{x} 
\end{vmatrix} $$\frac{1}{x}+\frac{1}{y}$$ But for some reason the answer say I should get : $$\frac{1}{x+y}$$ The method they used in the book is to calculate $J^{-1}$ which is $x+y$ and use the law $J(x,y)*J(u,v)=1$ in order to get $J(u,v)=\frac{1}{x+y}$ I don't know, why I get different answer. Any idea? Any help will be appreciated, Thanks in advance!","['determinant', 'differential-geometry', 'multivariable-calculus', 'integration']"
1328000,Convert the given set into roster notation:,"Problems: Find $A$, where 1) $A = \{x \in \mathbb{R} \mid x^4 - 1 = 0\}$ 2) $A = \{x \in \mathbb{C} \mid x^4 - 1 = 0\}$ Attempt: Solving the equation: $x^4 - 1 = (x^2)^2 - 1^2 $ $= (x^2 - 1)(x^2 + 1) $ $= (x-1)(x+1)(x^2 + 1) $ $= (x - 1)(x + 1)(x^2 - i^2) $ $= (x-1)(x+1)(x-i)(x+i) $ 1) Since $x$ is defined as a real number in this case, $A= \{1,-1\}$. 2) Since $x$ is defined as a complex number in this case, $A= \{1,-1, i, -i\}$. Is my work correct?",['elementary-set-theory']
1328020,Help with proving that the torsion subgroup of $y^2=x^3+x$ is $E(\mathbb{Q})_{tors} \cong \mathbb{Z}/2\mathbb{Z}$,"Let $E: y^2= x^3 + x$ be an elliptic curve over $\mathbb{Q}$. I'm trying to prove that $E(\mathbb{Q})_{tors} \cong \mathbb{Z}/2\mathbb{Z}$. In order to do that, I've already shown that $|E(\mathbb{F}_p)| \equiv 0 \mod 4$ for every prime $p \geq 3$, but I'm lost on what I'm supposed to do next. Any help would be dearly appreciated. EDIT : I do know the Nagell-Lutz theorem but I don't think I'm allowed to use it (Nagell-Lutz is described in the following section of the notes, so this exercise shouldn't need it). I've looked at the injection map described by Álvaro, and now I've successfully computed that the order of the torsion group is either $1,2$ or $4$. Order $1$ is no good, as $(0,0)$ has order $2$. How do I rule out a torsion group of order $4$? EDIT $2$ : I've found a hint online which states that $2P=(0,0)$ (and so has order $4$) iff $1=4d^4$ for some $d$. This is impossible; so the torsion group has to have order $2$. However, they don't give any explanation where this result comes from. Any ideas? ATTEMPT : Is this correct? The point $(0,0)$ has order $2$, because the $y$-coordinate is zero. If $-1$ is a square, say $-1 = d^2$, then the equation takes the form $y^2 = x(x-d)(x+d)$ and there are three points of order two in $E(\mathbb{F}_p)$. Hence, if the index of $E(\mathbb{Q})$ is two (when it solely consists of $2$-torsion points), it is isomorphic $\mathbb{Z}/2\mathbb{Z} \oplus \mathbb{Z}/2\mathbb{Z}$ when $-1$ is a square and to $\mathbb{Z}/2\mathbb{Z}$ otherwise. Because $-1$ is a not a square in $\mathbb{Q}$, the result follows.","['elliptic-curves', 'torsion-groups', 'number-theory']"
1328021,Imaginary $\cos^{-1}$ value significance?,"When I was bored in AP Psych last year, I jokingly asked myself if there was a cosine inverse of $2$. Curious about it, I tried calculating it as follows:
$$
\begin{align*}
\cos (x) &= 2 \\
\sin (x) &= \sqrt{1 - \cos^2(x)} = \sqrt{1 - 4} = \pm i \sqrt{3} 
\end{align*}
$$
Then, by Euler's formula, you have
$$
\begin{align*}
e^{ix} &= \cos (x) + i \sin (x) \\
e^{ix} &= 2 \pm\sqrt{3} \\
ix  &= \ln (2 \pm  \sqrt{3}) \\
x &= \boxed{-i \ln (2 \pm  \sqrt{3})}
\end{align*}
$$ So, there was a way to calculate the inverse cosine of numbers whose magnitude is greater than $1$ (this was verified on Wolfram Alpha). To what extent is this kind of calculation valid? Does it have any interesting applications/implications in math, or any other subjects? Thanks. :) Edit I just realized this is very easily explained by $2\cos (x) = e^{ix} + e^{-ix}$, but I'm still curious if this has any significance/intuition.","['applications', 'complex-numbers', 'algebra-precalculus', 'trigonometry']"
1328024,Better proof that vector fields on submanifolds extend globally iff submanifold is closed,"I just finished my own proof of one of the problems in Lee's Smooth Manfolds , 2nd ed., but I wonder if anyone knows a better (less messy) solution. It's problem 8-15, the ""Extension Lemma for Vector Fields on Submanifolds."" Here's the part of the exercise which I had some trouble with: Let $S$ be an embedded submanifold with or without boundary of a manifold $M$. Every vector field $X \in \mathfrak{X}(S)$ extends to all of $M$ if and only if $S$ is properly embedded. I proved that if $S$ is properly embedded, then all vector fields extend globally easily. It's the reverse direction I had trouble with. My idea was that if $S$ is not closed in $M$, then take some point $p \in \overline{S} \setminus S$. I showed that one can find a smooth path $\gamma: (-\epsilon, \epsilon) \to M$ such that $\gamma$ is an embedding, $\gamma(0) = p$, $\gamma(-\epsilon, 0) \subset S$, and in some coordinate neighborhood of $p$, $|\gamma'(t)| = 1$. Then I defined the function $f: \gamma(-\epsilon, 0) \to \mathbb{R}$ as $f(x) = -1/\gamma^{-1}(x)$ (the idea is that this is a smooth function which blows up as $x \to p$). Finally I defined the vector field $f(x) \gamma'(\gamma^{-1}(x))$ on $\gamma[-\epsilon/2, 0)$. This is a smooth vector field on a closed subset of $S$, hence by the extension lemma proved earlier in the text, it extends to a smooth vector field on $S$. Clearly it does not extend to a smooth vector field on all of $M$ though, because in the local coordinate chart near $p$, its norm blows up. The above argument feels very messy to me. I don't like the process I went through to find a smooth function on $S$ which blows up near $p$; surely there's a simpler way to do this?","['differential-geometry', 'smooth-manifolds']"
1328050,Computing $\sum_{n\geq 0}n\frac{1}{4^n}$,"Can I compute the sum
$$
\sum_{n\geq 0}n\frac{1}{4^n}
$$
by use of some trick? First I thought of a geometrical series?","['sequences-and-series', 'real-analysis']"
1328052,Which functions solve autonomous ODEs?,"Fix an open set $U \subseteq \mathbb{R}$. What can be said about the set $a_n(U)$ of functions $f \in C^n(U, \mathbb{R})$ for which there exists a (sufficiently nice) nonzero function $g : \mathbb{R} \to \mathbb{R}$ such that $$g(f(x), f'(x), f''(x), \ldots, f^{(n)}(x)) = 0$$ for all $x \in U$? Or about the set
$$a(U) := \bigcup_n a_n$$
of functions that satisfy some autonomous equation of some order? For instance, are they known to contain or be contained in any well-known classes of functions? (Obviously this depends on what functions $g$ you deem ""sufficiently nice.""  Feel free to make it anything reasonable that gives an interesting result.)",['ordinary-differential-equations']
1328075,Fractional powers of positive self-adjoint operators,"Consider two positive unbounded operators $A$ and $B$ densely defined on a Hilbert space $H$ self-adjoint on a domain $\mathcal{D}(A) = \mathcal{D}(B) = H_1$. By the spectral theorem, we can define the fractional powers of $A$ and $B$ as self-adjoint linear operators on $H$. My question is, is $\mathcal{D}(A^{\alpha}) = \mathcal{D}(B^\alpha)$, where $\alpha \in (0, 1)$ necessarily? Is this part of the spectral theorem? If yes, where can I find such a statement?","['reference-request', 'operator-theory', 'functional-analysis']"
1328119,Induced homomorphism $\phi^*$ from $G/M \to H/N\ ?$,"Let $\phi : G \to H/N$ be a homomorphism where $G$ and $H$ are groups and let $M \unlhd G$ and $N \unlhd H$. Now when does $\phi$ induces a homomorphism $\phi^*$ from $G/M \to H/N\ ?$ When $M \subseteq \text{ker}(\phi)$ When $\text{ker}(\phi) \subseteq M$. or in both cases? In the both cases, induced homomorphism looks like $$\phi^*(g+M)=\phi(g)+N$$ So is it a homomorphism in both cases? If yes,  Why does it has to to satisfy a containment relation with $ker(\phi)$. What if $M$ is just some random subgroup of $G$?","['abstract-algebra', 'group-homomorphism', 'group-theory']"
1328131,Solution to Fibonacci Recursion Equations,"Let the sequence $(a_n)_{n\geq0}$ of the fibonacci numbers: $a_0 = a_1 = 1, a_{n+2} = a_{n+1} + a_n, n \geq 0$ Show that: i) $$a^2_n - a_{n+1}a_{n-1} = (-1)^n \text{ for }n\geq1$$ 
I try to show this with induction: $n=1:$ 
            \begin{align*}
				a^2_1 - a_{2}a_{0}&=1 - a_2a_0\\
				&= 1- (a_1 + a_0 )a_0\\
				&= 1-(1+1)1 = -1 = (-1)^1\\
			\end{align*}
Assume that: $a^2_n - a_{n+1}a_{n-1} = (-1)^n ,\forall n\geq1$ Inductive step:
            \begin{align*}
				a^2_{n+1} - a_{n+2}a_{n}
				&=(a_n + a_{n-1}) ^2 - (a_{n+1}+a_{n})(a_{n-1}-a_{n-2})\\ 
				&=a^2_{n}+2a_na_{n-1}+a^2_{n-1}-a_{n+1}a_{n-1}+a_{n+1}a_{n-2}-a_{n}a_{n-1}+a_{n}a_{n-2}\\
				&=(a^2_{n}-a_{n+1}a_{n-1})+(a^2_{n-1}-a_{n}a_{n-1})+2a_na_{n-1}+a_{n+1}a_{n-2}+a_{n}a_{n-2}\\
				&=\underbrace{(-1)^n + (-1)^{n-1}}_{=0}+2a_na_{n-1}+a_{n+1}a_{n-2}+a_{n}a_{n-2}\\
				&=2a_na_{n-1}+a_{n+1}a_{n-2}+a_{n}a_{n-2}\\
				&=??\\
			\end{align*} ii) $$\sum \limits_{i=0}^na_i=a_{n+2}-1 , n\geq0$$ iii) $$a^2_{n-1}+a^2_n=a_{2n} \text{ and } a_{n-1}a_n+a_na_{n+1}=a_{2n+1}, n\geq1$$ Thank you for any help","['induction', 'discrete-mathematics', 'recursion']"
1328151,Integral of $\sin (x^3)dx$,"$$\int \sin (x^3)dx$$
I have tried some substitutions, but I haven't reached the goal... Can you help me?","['derivatives', 'integration']"
1328167,"Evaluating $E[\max(X,Y)]$","Let X and Y be positive independent random variables, and
$$W=\max(X,Y)$$
Define the CDFs of X and Y as $F(x)$ and $G(y)$, respectively.
$$\Pr(W\le w)=\Pr(X\le w)\Pr(Y\le w)=F(w)G(w)$$ $$E[W]=\int_0^{\infty}wF(w)g(w)dw+\int_0^{\infty}wf(w)G(w)dw$$ In an earlier post the second answer says that ""if X and Y are independent with uniform distribution on $(0,1)$, then $E[W]=2/3$.""  I am having trouble seeing how this is so.  Please spell it out for me. In particular, I am having trouble seeing how an integral like $$\int_0^{\infty}wF(w)g(w)dw$$ can be evaluated since $F(w)$ is itself an integral.  If $F(w)$ is the normal CDF, for example, it is already intractable.  So it seems to me that integrating something with $F(w)$ in it must be super duper intractable.","['probability', 'statistics', 'probability-distributions']"
1328210,"Given $x^2 + 4x + 6$ as factor of $x^4 + ax^2 + b$, then $a + b$ is [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question I got this task two days ago, quite difficult for me, since I have not done applications of Vieta's formulas and Bezout's Theorem for a while. If can someone solve this and add exactly how I am supposed to use these two theorem's on this task, I would be thankful. Given $x^2 + 4x + 6$ as factor of $x^4 + ax^2 + b$, then $a + b$ is equal to?","['polynomials', 'factoring', 'algebra-precalculus']"
1328215,Every subset has first and last element -> set is finite,"Let $X$ be a partially ordered set, so that every non empty subset of $X$ has a first and a last element.
Show that $X$ is a finite set. And what if every subset only has a first element? Well, I proved it is a linear order, but now I'm stuck. Anyone ready to clear things up for me? Thanks a lot!",['elementary-set-theory']
1328217,get length of line connecting sector of a circle,"What is the formula for getting the length of a line (in this case the red one) connecting starting point and end point of an arc, given the circle's radius $R$ and $\angle A$?","['circles', 'trigonometry']"
1328232,"Basic question about the stochastic integral $\int \limits_{0}^{t} X(s) \,dM(s)$","Suppose $(X_{t})_{t \geq 0}$ and $(M_{t})_{t \geq 0 }$ are stochastic processes, where the index is continuous and the probability space is $(\Omega, \Sigma, P)$. We say for each fixed $\omega \in \Omega$ that the set $\{ X_{t}(\omega) \}_{t \geq 0 }$ is a path . I'm trying to understand the stochastic integral $\int \limits_{0}^{t} X(s) \,dM(s)$.  Specifically, it seems this integral is in some sense being integrated with respect to the continuous index.  In other words, if I define $h(t, \omega) := X_{t}(\omega)$ and $g(t, \omega) := M_{t}(\omega)$, then it seems like the stochastic integral is really just asking for the Riemann-Stieltjes integral: $\int \limits_{0}^{t} h(s, \omega) \,dg(s, \omega)$, where $\omega$ is a fixed value.  In other words, since $\omega$ is fixed, we can regard $h(t, \omega)$ as a function of $t$, i.e., $h(t)$, and similarly for $g(t, \omega)$. Then the stochastic integral is just the Riemann-Stieltjes integral $\int \limits_{0}^{t} h(s) \,dg(s)$. I don't think the explanation above is correct.  Can anyone tell me what I am wrong about?  Also, was I right that we are regarding $\omega$ as a fixed value when evaluating the integral?","['probability-theory', 'brownian-motion', 'stochastic-calculus', 'stochastic-processes']"
1328247,"Does there exist a sequence $\{a_{n}\}$, but $\lim_{n\to\infty}a_{n}\neq 0$","Does there exist a sequence $\{a_{n}\}$, such that
$$\lim_{n\to\infty}(a_{n+1}-a_{n})=0\ \ \ \text{and} \ \ \lim_{n\to\infty}\dfrac{a_{1}+a_{2}+\cdots+a_{n}}{n}=0$$
but
$$\lim_{n\to\infty}a_{n}\neq 0 \ ?$$","['examples-counterexamples', 'limits']"
1328252,"Choosing a surface that makes the flux of F maximal,","For a closed surface S in $R^3$, consider the flux of F, given by the usual flux integral.  For what choice of S will the flux be maximal ? So, I want to apply the divergence theorem and instead look at the triple integral of the divergence of the given vector field F (over a solid that is enclosed by S.) Since the flux integral = the divergence integral, I can aim to maximize the divergence integral. My computation of the divergence gives me -3($x^2 + y^2 + z^2 - \frac{5}{3}$), so this would be the integrand in the triple integral. It sounds reasonable that in order to maximize this triple integral, I should maximize the integrand.  How do I do that? My attempt was to make $x^2 + y^2 + z^2$  - $\frac{5}{3}$ < 0, since there's a factor of -3 to consider.  negative * negative will give me a positive integrand - which would be good for maximizing the flux of F. Then this tells me that I should choose a sphere of radius $\sqrt{(\frac{5}{3})}$. I carried out my work and it looks like I got the correct answer. But I feel like I chose my sphere ...by luck. How do I know for sure that I've maximized the integrand, simply by making $x^2 + y^2 + z^2$  - $\frac{5}{3}$ < 0?  Could I have done even better, achieving a better maximum?  I simply knew that this factor had to be < 0, since it was being multiplied by -3. Thanks,","['optimization', 'calculus', 'real-analysis', 'multivariable-calculus']"
1328260,"Prove that $x * y = \frac{x+y}{1+xy}$ is a stable part of $G=(-1, 1)$","I have to prove that the result of $x * y \in G$ so $\frac{x+y}{1+xy} \in (-1, 1)$. So $x > -1$ and $y > -1$ at the same time $x < 1$ and $y < 1$. If I multiply the first 2 expressions I obtain $xy < 1$ which is true, and if I sum up the last 2 I get $x + y < 2$. At this point I am not sure if I am doing well. How should I continue this problem?","['abstract-algebra', 'group-theory']"
1328271,Universal quantifier question: $(\forall x)[x < 0 \Rightarrow x^2 > 0]$,"Universal quantifier question: $(\forall x)[x < 0 \Rightarrow  x^2 > 0]$. 
Given the above expression, For all of $x$ [ if $x$ is less than zero, then $x^2$ is greater than zero]. Is that a true statement? The confusion: $p \Rightarrow q$, is true in all cases except when $p$ is true and $q$ is false. In the above problem, if $x < 0$  is true then $x^2 > 0$ will be true. But, when, $x = 0$, then, the premise $x < 0$ is false. But, according to definition, if premise is false, the expression is still considered true. Doesn't it contradict?","['logic', 'quantifiers', 'propositional-calculus', 'discrete-mathematics']"
1328282,The inverse Laplace transformation of $e^s$,"I am solving the differential equation: $$y'' + 3xy' -6y = 1, \ y(0) = y'(0) = 0$$ Using Laplace transformations. I arrived at: $$L(y)(s) = \frac{c}{s^3} e^{s^2 / 6} + \frac1{s^3}$$ Where $c$ is an arbitrary constant. I doubt that this is what it really is, though I ran through my calculations again and nothing seemed to be wrong. So I did: $$L(y - \frac{x^2}2 )(s) = \frac{c}{s^3} e^{s^2/6} = L(g \star h)$$ Where: $$L(g)(s) = \frac{c}{s^3}$$ $$L(h)(s) = e^{s^2/6}$$ Now, all I have to do is find $h$, which seems not easy at all (if possible). Not to mention that I'll have to find the convolution afterwards. Is there an inverse Laplace transformation for the function $u \rightarrow e^u$? How could it be found? Thank you.","['laplace-transform', 'ordinary-differential-equations']"
1328286,Difference between $(\exists z)[z > 0 ∧ z^2 = 2]$ and $(\exists z )[z > 0 \Rightarrow z^2 = 2]$,Existential quantifier confusion: what is the difference between $(\exists z)[z > 0 ∧ z^2 = 2]$ and  $(\exists z )[z > 0 \Rightarrow z^2 = 2]$? What are the differences between those two expressions and the expression $(\exists z > 0)[z^2 = 2]$?,"['logic', 'quantifiers', 'discrete-mathematics', 'predicate-logic']"
1328297,A bit confused about definition of set of mappings in Herstein's Algebra,"I have been just trying to start working with the books Topics in Algebra by I.N. Herstein, and I am having a bit of trouble understanding a definition. It is, Definition: If $S$ is a nonempty set then $A(S)$ is the set of all one-to-one mappings of $S$ onto itself. I think my problem is that I am just having trouble thinking of an example of what this is representing? I mean lets say we were considering $S=\{1,2\}$ for example, then does A(s) contain some functions say, f, g for example for which $f:S \to S$ is bijective and g is as well? My apologize if this is hard to understand my question, and it is possible my intuition is completely off, so I would really appreciate any explanations/insight about this. I am also curious if there is a more common name for this set $ A(S)$. Thanks all!","['abstract-algebra', 'elementary-set-theory']"
1328305,$f : \mathbb R \to \mathbb R $ be a differentiable and $f'(x) $ is bounded function then $f$ is unbounded.,"$f : \mathbb R \to \mathbb R $ be a differentiable function with $f(0) =0$. If for all $x \in \mathbb R , 1< f'(x) < 2$ then $f$ is unbounded. We know that when $f'(x) > 0$ then $f$ is increasing and when $f'(x)$ is bounded then $f$ is uniformly continuous. From there how can we conclude that $f$ is unbounded??","['continuity', 'real-analysis', 'functions']"
1328311,"Prove that $ a^2-4b \neq2$ if $ a,b \in \mathbb{ Z}$","My solution :
We suppose that is true. Then by contradiction: $a^2-4b-2=0$ $a^2=4b+2$ $a=2(b+1/2) ^{0.5}$ then $(b+1/2)$ is fraction and rooted by $0.5$ so the square root of any fraction $+$ any-Integer will give fraction so then $a$ must be fraction, not an integer. Contradiction. Then $a^2 -4b \neq 2$? Is that a good proof?",['discrete-mathematics']
1328320,"If I select two numbers $x_1,x_2$ from the interval $(0, 1) $, what is the probability $x_1 <x_2$?","The question is in the description. 
One of the answers I am getting is $\int_0^1 {x (1-x) }=1/6$. The other answer I am getting is there are only two possibilities: $x_1>x_2$ and $x_1<x_2$. Hence probability is 1/2 Any help would be great.",['probability']
1328364,How to prove it is a strictly stationary process?,"$ξ(t) = z*sin(ωt + θ)$ where $z$ is a random variable and its distribution is unknown and $θ$ is another random variable that is independent of $z$ and $θ$ is uniformly distributed on $(0, 2\pi)$. Besides, $ω$ is a constant greater than $0$. I've been asked to show $ξ(t)$ is a strictly stationary stochastic process using characteristic function or say $E(e^{jvξ(t)})$. I've tried but it seems that $E(e^{jvξ(t)})$ depends on the $t$ I choose, which means it is not a strictly stationary stochastic process. I think my answer can be wrong and how to prove it? One more question: I've got quite confused why a characteristic function of a stochastic process can be used to prove property of strictly stationary?
The definition of strictly stationary is $F_ξ(x_1, x_2, x_3,..., x_n; t_1, t_2, t_3,...,t_n) = F_ξ(x_1, x_2, x_3,..., x_n; t_1 + τ, t_2 + τ, t_3 + τ,...,t_n + τ)$ where capital $F$ denotes the probability distribution function(PDF) of ξ(t). My book never told me anything about relationship between characteristic function of a stochastic process and its PDF. So when this problem appeared, I think they want me to show $E(e^{jvξ(t)})$ does not depend on $t$ while forget to tell me why not depending on $t$ imply its strictly stationary?","['probability', 'statistics', 'random-variables', 'stochastic-processes']"
1328423,"How to compute $\int_0^\infty \frac{1}{(1+x^{\varphi})^{\varphi}}\,dx$?","How to compute the integral, $$\int_0^\infty \frac{1}{(1+x^{\varphi})^{\varphi}}\,dx$$ where, $\varphi = \dfrac{\sqrt{5}+1}{2}$ is the Golden Ratio?","['calculus', 'closed-form', 'definite-integrals', 'integration', 'golden-ratio']"
1328503,Trying to understand physical interpretation of outer product,"I am reading a book on Quantum computation and found the following expression: |ψ><ψ||ϕ> → |ψ>   <ψ|ϕ> =    <ψ|ϕ>|ψ> The book says that it means: That is, the operator |ψ><ψ| projects a vector |ϕ> in H to the
  1-dimensional subspace of H spanned by |ψ>. But I am not able to understand this meaning of the above expression. Please help me understand this. (I know inner product is projection)",['linear-algebra']
1328566,Slow decreasing function that exhibits asymptotic behaviour,"I am currently doing some work on modelling the effects of treated nets usage on mosquito populations. Nets do not retain their maximum efficacy forever. They lose their chemical efficacy after about three years and all that is left is the physical protection offered by the net which I estimate to be $20\%$ of the original efficacy. I am trying to model this behaviour. I need a continuous function over the interval $[0,1095]$ which decreases slowly  from 1 when $x=0$ and asymptotically approaches $0.2$ when $x \to 1095 $. I tried an ellipse of the form $y=\sqrt{1-\dfrac{x^2}{(1095)^2}}$, but I realized the function is equal to zero when $x=1095$, which is not what I want. Any help will be appreciated.","['asymptotics', 'calculus', 'special-functions']"
1328584,Failure of Newton-Leibniz formula,"Suppose that $f : \mathbb{R} \rightarrow \mathbb{R}$ is differentiable but  $f \notin C^1 ( \mathbb{R} )$ . It means that $f'$ exist but it is not continuous. Question 1 Is function $f'$ locally integrable. I.e. does there exist for every $a , b \in \mathbb{R}$ $$ \int_{a}^{b} f'(x) dx $$ I think, I should ask about existence of Lebesgue integral. Question 2 If it exist, does the Newton-Leibniz formula holds? $$ \int_{a}^{b} f'(x) dx = f(b) - f(a) $$ Comment . I am asking because I wanted to prove Cauchy's integral theorem using Stokes' theorem. One told me that I am not allowed to use Stokes' theorem if derivatives are not continuous.. So I wonder whether it is important. The simplest case of Stokes' theorem is Newton-Leibniz formula.","['analysis', 'lebesgue-integral', 'integration']"
1328608,Why is the support function $\mu_K$ differentiable iff $\mu_K(v)=v\cdot x$ for a unique $x\in K$?,"I am reading an economics book (for those who are interested, MWG Microeconomic Theory) and there's a theorem that was just given without proof, but I am interested in the proof - also because I cannot seem to get a good feel for the theorem and maybe the proof would help. Theorem: Let $K$ be a non-empty closed subset of $\mathbb{R}^n$ (not necessarily convex). Define the support function $\mu_K(\cdot):\mathbb{R}^n \to \mathbb{R}$ to be $\mu_K(v)=\inf\{v\cdot x : x\in K\}$. Then there is a unique $\tilde{x} \in K$ such that $\tilde{v}\cdot \tilde{x}=\mu_K(\tilde{v})$ if and only if $\mu_K(\cdot)$ is differentiable at $\tilde{v}$. Moreover, in this case, $\nabla \mu_K(\tilde{v})=\tilde{x}$. Further query: In order to get a better feel for the theorem, I thought about the example where $K$ is something like banana-shaped (can't help it, Minions) and $\tilde{v}$ is the direction where there would be two minimizing $\tilde{x}$. However, it is not intuitive to me why $\mu_K(\cdot)$ would not be differentiable at $\tilde{v}$. So as a bonus, does anyone have a good feel on why this is so? Another example I am interested in thinking is convex polygon and $\tilde{v}$ is perpendicular to one of the edges. These will help me get a better feel of the theorem in general.","['support-function', 'convex-analysis', 'multivariable-calculus']"
1328663,(Uniformly) Most Powerful test,"I'm having trouble to find a UMP test after finding a MP test. Consider one observation $X$ from CDF $F_\theta(x) = x^\theta$ where $x \in [0, 1]$ and $\theta > 0$. I found the MP test for testing $H_0: \theta = 1$ against $H_1: \theta = 2$ with significance level $\alpha=0.05$ using the Neyman Pearson lemma: $$\lambda_{\theta_0, \theta_1}(x) = \frac{f_{\theta_0}}{f_{\theta_1}}= \cdots = \frac{1}{2x}$$ Reject $H_0$ if $\lambda_{\theta_0, \theta_1}(x)\leq\frac{1}{c}$, hence if $X\geq \tilde{c}$, where $\tilde{c} = 0.95$. Now I'm asked to find the UMP test for testing $H_0: \theta \in [\frac{1}{2}, 1]$ against $H_1: \theta=2$ for significance level $\alpha = 0.05$. How to proceed?","['hypothesis-testing', 'statistics', 'statistical-inference']"
1328665,Is it a composite number? [duplicate],This question already has answers here : $19\cdot8^n+17$ is composite for all natural $n$ (covering congruences) (3 answers) Closed 9 years ago . How do I prove $19\cdot8^n+17$ is a composite number? Or is that number just a prime? So I tried to find a divisor in the cases $ n = 2k $ and $ n = 2k + 1 $. But I had no success. Do you have any ideas?,"['prime-numbers', 'number-theory']"
1328736,Solution of a quartic equation.,Suppose that the equation $x^4-2x^3+4x^2+6x-21=0$ is known to have two roots that are equal in magnitude but opposite in sign. Solve the equation. This is what I have been thinking. Suppose $\zeta_1$ $\zeta_2$ are roots. Such that $|\zeta_1|=|\zeta_2|$. Then $(x-\zeta_1)(x-\zeta_2)$ divides the polynomial. I don't know where to go from here. Any advice?,"['polynomials', 'complex-analysis', 'real-analysis', 'roots']"
1328774,Any hint in how to simplify a set theory expression: $(A \cap B) \cup (A \cap B \cap C' \cap D) \cup (A'\cap B)$,"I'm having trouble simplifying this set theory expression $$\begin{align}
(A \cap B) \cup (A \cap B \cap C' \cap D) \cup (A'\cap B)
& 
\end{align}
$$ In the books says that absorption law can help, but I do not understand why $$\begin{align}
(A \cup A') \cap B = U \cap B = B
& 
\end{align}
$$ Can someone guide me in how do this please, just a hint please? I am stuck",['elementary-set-theory']
1328798,Proving “The sum of $n$ consecutive cubes is equal to the square of the sum of the first $n$ numbers.”,"This site states: Example $\boldsymbol 3$ . The sum of consecutive cubes. Prove this remarkable fact of arithmetic: $$1^3 +2^3 +3^3 +\ldots +n^3 =(1 +2 +3 +\ldots +n)^2.$$ “The sum of $n$ consecutive cubes is equal to the square of the sum of the first $n$ numbers.” In other words, according to Example $1$ : $$1^3 +2^3 +3^3 +\ldots +n^3 = \frac{n^2 (n+1)^2}{4}.$$ Should: $$1^3 +2^3 +3^3 +\ldots +n^3 = \frac{n^2 (n+1)^2}{4}$$ not be: $$1^3 +2^3 +3^3 +\ldots +n^3 = \frac{n^3 +(n + 1)^3}{2^3}$$ as everything in the left-hand side is cubed?","['number-theory', 'induction']"
1328808,Notation for a function with multiple return values,"I want to define a function $f$ whose domain is given by the set $V$ whose return value is a subset of $C$. Please correct me if I am wrong, I assume that $f : V \rightarrow C$ would mean that the function returns a single value from the set $C$. My question is, how do I denote that the function returns a subset of values from $C$ for every value in $V$.","['notation', 'functions']"
1328850,Alternative way to count the number of solutions to the equation $x^2 + y^2 = -1$ over $\Bbb Z /p$,"$x^2 + y^2 = -1$ is a weird equation because it has no solutions over $\Bbb R$. I want to count the number of solutions it has over $\Bbb Z / p$ where $p$ is prime. If $p = 2$ then it has $p$ solutions. This is to do with the fact that squaring is a field automorphism. If $p \equiv 1 \pmod{4}$ then there is an $i$ such that $i^2 = -1$ so $$x^2 + y^2 = -1 \implies \left({x \over i}\right)^2 + \left({y \over i}\right)^2 = 1 \implies \left({x \over i} + y \right)\left({x \over i} - y \right) = 1$$ which has $p - 1$ solutions. If $p \equiv 3 \pmod{4}$ then the situation is more complicated. The thing I noticed is that $A = \{x \mid x^2 + y^2 = -1\}$ and $B = \{x \mid y^2 - x^2 = 1\}$ form a partition of $\Bbb Z/p$. Reason being that $x \not\in A \implies (-1 - x^2 \mid p) = -1 \implies (1 + x^2 \mid p) = 1 \implies (\exists y)\,1+x^2 = y^2 \implies x \in B$, and vice versa. Also notice that $A \cap B = \emptyset$. So we get $|A| = |\Bbb Z / p| - |B| = p - |B|$. To determine $|B|$, use the fact that for every $(x,y)$ for which $y^2 - x^2 = 1$, $(x,-y)$ also satisfies the equation, so $|B|$ is the number of solutions to $y^2 - x^2 = 1$ divided by $2$, which is $\frac{p-1}{2} \therefore \,|A| = {p + 1 \over 2}$. Now it's easy to see that the number of solutions to $x^2 + y^2 = -1$ is $2|A|$ which is $p+1$. Any quicker method?","['abstract-algebra', 'alternative-proof', 'elementary-number-theory', 'finite-fields']"
1328874,The rows of an orthogonal matrix form an orthonormal basis,"A matrix $A \in \operatorname{Mat}(n \times n, \Bbb R)$ is said to be orthogonal if its columns are orthonormal relative to the dot product on $\Bbb R^n$. By considering $A^TA$, show that $A$ is an orthogonal matrix if and only if $A^T = A^{−1}$. Deduce that the rows of any $n × n$ orthogonal matrix $A$ form an orthonormal basis for the space of $n$-component row vectors over $\Bbb R$. I am trying to do part 2. What I tried is that since we figured out that $A^T = A^{-1}$, and the inverse of $A$ is the left product of elementary matrices to $A$, the row space of $A^TA =$ row space of $A$. Also, since $A^TA = I$, a basis of the row space of $A$ is a basis of the row space of $I$. Since the columns of $I$ are the standard basis of $\Bbb R^n$ $(e_1, ..., e_n)$, and are orthonormal to each other, they form an orthonormal basis of $\Bbb R^n$. Something tells me this proof is wrong. Could someone give me some guidance?","['orthogonality', 'linear-algebra', 'matrices']"
1328921,A continuous surjection from irrational numbers to Cantor's set,"I wonder if there exists such a function that is continuous and surjective $$f:\mathbb{R} \setminus \mathbb{Q} \rightarrow C$$ where $C$ is the Cantor's set. When I did such an exercise but for $f:C \rightarrow \mathbb{R} \setminus \mathbb{Q}$, it wasn't that hard, because $\mathbb{R} \setminus \mathbb{Q}$ isn't a compact set then a continuous function from Cantor's set on it doesn't exist. A similar reason was for $f:C \rightarrow  \mathbb{Q}$. I tried to use compactness, connectedness or connected components (to show there is no such a function) but I got no results.","['cantor-set', 'general-topology']"
1328942,I need intuition as to how trig substitution works.,"Let's start with an example:
$$
\int \frac{1}{\sqrt{4-x^2}}dx;
$$
using a reference triangle, I find that $\sqrt{4-x^2}$ can be expressed as $2\cos\theta$ in polar coordinates. However, I don't understand how $dx$ can be replaced with $2\cos(\theta)d\theta$. It was to my understanding that if something is added to right side of the integral -> $2\cos(\theta)$ then it must also be added the the left side of the integral. The fact that $2\cos(\theta)$ contains a variable would not allow that. I understand that trig substitution like this does work. I just can't seem to understand how.","['trigonometry', 'integration']"
1328966,Proof that every field $F$ has an algebraic closure $\bar F$,"I am reading the book A First Course in Abstract Algebra written by Fraleigh and I do not really understand the proof of theorem 31.22, that every field $F$ has and algebraic closure $\bar F$. I notice that many people has asked this question before but I still don't understand. Basically, one need to construct a set $S$ that contains all algebraic extension fields of $F$ and use Zorn's Lemma to assure the maximal element $\bar F$. However we need to assure the set $S$ is a 'legal' set which won't fall into the trap of Russell paradox, as shown below (by Fraleigh): I am confused with the construction of $\Omega$. I assume that $A$ is the set of all zeros in $F[x]$ and $\Omega=P(A)$ which has $\it{cardinallity}$ strictly greater then $A$. Since every $\alpha\in F$ is a zero of the polynomial $f_\alpha=x-\alpha$, one has $\omega _{f_\alpha1}=\alpha$. I rename $\{\omega _{f_\alpha1}\}\in P(A)=\Omega$ as the element $\alpha$ so $F\subset \Omega$ would make sense. Then choose any $\gamma \in E$ and rename every element in $F(\gamma)$ with different $\omega\in \Omega\backslash F$. This is how I understand Fraleigh's proof. My question is: After assigning names to every element in $F(\gamma)$ by $F(\omega)$, then the 'remaining elements' in $\Omega$ would have the size $\Omega\backslash (F\cup F(\omega))$. How can one guarantee that it is still large enough to rename the other extension fields? Also, in the proof, $\gamma$ is get from $E$. What we know is all elements in $F(\gamma)$ is renamed and contained in $\Omega$. But it does not mean that $E\subset \Omega$. And thirdly, I suppose the construction is followed in this procedures: Find $\gamma_1$ and make $F(\gamma_1)$ into $\Omega$. Find another $\gamma_2$ and make $F(\gamma_2)$ into $\Omega$, and so on. This is a step by step procedures and I can only make $countably$ many $F(\gamma_i)$ into $\Omega$. How can I know $\Omega$ is actually large enough to contain maybe uncountably many extension fields?","['abstract-algebra', 'elementary-set-theory', 'field-theory', 'axiom-of-choice']"
1329008,matrix operator norm and inner product,"Is it true that $\Vert A\Vert:=\sup_{\Vert x\Vert=1}\Vert Ax\Vert=\sup_{\Vert x\Vert=\Vert y\Vert=1}\vert\langle y,Ax\rangle\vert$ for arbitrary matrices $A$?
Showing $""\geq""$ seems to be straightforward using Cauchy-Schwarz.","['linear-algebra', 'normed-spaces']"
1329097,Correct steps in rewriting expectation to a probability,"My knowledge of measure theory and probability spaces is limited, so please keep it relatively simple. Let $\{X(t), ~ t \ge 0\}$ be a Markov process on the countable state space $\mathbb{N}_0$ with initial condition $X(0) = 0$. Let $T_j$ be the first time the Markov process hits state $j$. Say I want to compute the expected time spent in state $i$ before I reach state $j$, i.e., \begin{equation}
\mathbb{E}\left[ \int_{t = 0}^\infty 1\{X(t) = i, T_j > t\} \,\mathrm{d}t \right], \tag 1
\end{equation} where $1\{\cdot\}$ is the indicator function. I would like to write that $(1)$ is equal to \begin{equation}
\int_{t = 0}^\infty \mathbb{P}(X(t) = i, T_j > t) \, \mathrm{d}t. \tag 2
\end{equation} However, I am unsure about what the correct mathematical steps are and what notation I should use. So, my question is, is the following correct and what notation should be improved upon? My attempt is as follows \begin{align}
\mathbb{E}\left[ \int_{t = 0}^\infty 1\{X(t) = i, T_j > t\} \,\mathrm{d}t \right] &= \int_{\omega \in \Omega} \int_{t = 0}^\infty 1\{X(t,\omega) = i, T_j(\omega) > t\} \,\mathrm{d}t \, \mathrm{d}\mathbb{P}(\omega) \\
&= \int_{t = 0}^\infty \int_{\omega \in \Omega} 1\{X(t,\omega) = i, T_j(\omega) > t\} \, \mathrm{d}\mathbb{P}(\omega)\,\mathrm{d}t \\
&= \int_{t = 0}^\infty \mathbb{P}(X(t) = i, T_j > t) \, \mathrm{d}t,
\end{align} where $\omega$ is an outcome,  $\Omega$ is the sample space and $\mathbb{P}(\omega)$ is the probability of outcome $\omega$ and I use Tonelli's theorem for the second equality. By outcome I mean a sample path of the Markov process.","['probability-theory', 'markov-process', 'proof-verification']"
1329130,What fraction of a sphere can an external observer see?,"Here is a geometry problem. Let there be a ball of radius R and let's call it the Moon . Let there be an external observer: A . A is at a distance d to (the surface of) the Moon. [Edit] A is a Cyclope, he has only one eye. Question: What fraction of the sphere can A see? I would like the solution with a demonstration. Thank you.","['area', 'geometry', 'spheres', 'recreational-mathematics', 'mathematical-astronomy']"
1329131,What does the dx mean in an integral? [duplicate],"This question already has answers here : What is $dx$ in integration? (12 answers) Closed 9 years ago . I know dy/dx for example means ""derivative of y with respect to x ,"" but there's another context that confuses me. You will generally just see a dx term sitting at the end of an integral equation and I just don't know exactly what it means or why it's there. For instance, if I put into Wolfram Alpha ""integral of 2x"", it writes out: That dx in there! I guess it's saying ""the integral of 2x with respect to x"" ? But why is that even necessary? Isn't it implied? It's annoying because it looks like multiplication, like it means ""2 * x * dx"" and it's just kind of misleading notation.","['calculus', 'integration']"
1329168,Applications of Principal Bundle Construction: Vague Question,"I recently read the principal $G$-bundle construction on a smooth manifold $M$, where $G$ is a Lie group. To understand them better, I am looking for some applications. Can the principal $G$-bundle help us get some usual bundle constructions, for example tensor product of two vector bundles, the pullback bundle etc? Right now, the constructions I have seen are specific to each type of construction. If I want the tensor product of two vector bundles $E$ and $F$ over a smooth manifold $M$, I start from scratch and consider the disjoint union $\bigsqcup_{p\in M} E_p\otimes F_p$ and put trivializations ""naturally"".
Similarly for the dual bundle. Is there a unified way to think of these constructions so that all the constructions are dealt with in one shot?","['principal-bundles', 'differential-geometry', 'smooth-manifolds']"
1329189,Maximal eigenvalue is a convex function. Why?,Let $A$ be a symmetric real matrix. Let $f(A)=\lambda_{\max}(A)$ be its largest eigenvalue. Why is $f$ convex?,"['convex-analysis', 'eigenvalues-eigenvectors', 'matrices']"
1329201,Exterior derivarive dependent only on point,"For any one-form (a linear form on the tangent space of each point) we have its exterior derivative $d\omega$ which is a two-form defined by $d\omega(X,Y)=D_X(\omega(Y))-D_Y(\omega(X))-\omega([X,Y])$ I'm trying to show that the value of $dw(X,Y)$ at a point $p$ is depndent only on the values of the vetcor fields $X,Y$ at that point. I've just started diving into this subject, and I really don't have a good direction. I tried to think of all the tools I have so I thought of decomposing $X,Y$ to some orthonoraml base, or maybe even decompose $\omega$ by $\sum_i\omega(X_i)\omega^i$ where $\omega^i$ is the linear form associated with $X_i$ i.e for any $i,j$: $\omega^i(X_j)=\delta_{ij}$ I will be very glad for some help! In addition, any general insight on this new definition of exterior derivative can be helpful. For now it seems quite peculiar. Thanks!","['differential-geometry', 'differential-forms']"
1329219,Show that $\{ x_n \} \overset{T}{\mapsto} \{ \sum_{k=1}^{\infty} a_{nk} x_k \}$ is compact,"Can someone help me with this question? Let $\ell^2$ be the space of complex sequences $\{ x_1, x_2, \ldots \}$ that $\sum_{n=1}^{\infty} \lvert x_n \rvert ^2 < \infty$. If $\mu$ be Counting Measure on $\mathbb{N}$, then $\ell^2$ is $L^2(\mathbb{N}, \mu)$, and thus a Hilbert space. Now suppose that $\{ a_{ij} \}$ is a complex multi index sequence such that $\sum_{i, j} \lvert a_{ij} \rvert ^2 < \infty$. Thus, we can define $T : \ell^2 \rightarrow \ell^2$
\begin{equation}
\{ x_n \}_{n=1}^{\infty} \overset{T}{\mapsto} \{ x'_n \}_{n=1}^{\infty}, \qquad x'_n = \sum_{k=1}^{\infty} a_{nk} x_k \ .
\end{equation}
Show that $T$ is well defined, means that we have $\{ x'_n \}_{n=1}^{\infty}$, $T$ is Bounded, and $T$ is Compact. Thanks in advance. Edit: I already proved number 1 and 2. For number 2, I proved that if $\sum_{n=1}^{\infty} \lvert x_n \rvert ^2 < 1$, then we have $\sum_{n=1}^{\infty} \lvert \sum_{k=1}^{\infty} a_{nk} x_k \rvert ^2 < \infty$. I couldn't prove number 3 with definition of compact operators, or other equivalent definitions, such as being limit of finite-rank operators.","['compact-operators', 'hilbert-spaces', 'functional-analysis']"
1329244,Confidence and proportion,"You wish to estimate,with $99\%$ confidence, the proportion of Canadian drivers who want the speed limit raised to $130$ kph. Your estimate must be accurate to within $5\%$. How many drivers must you survey,if your initial estimate of the proportion is $0.60$? I know that $99\%$ is $2.575$ but i dont know how to set up the problem. I don't think that $130$ kph even has anything to do with the problem. I think i am over thinking this question.",['statistics']
1329252,"Is $\max(0, x)$ a differentiable function?","It appears that $\max(x, y)$ isn't differentiable according to this question . However, the explanation is due to the fact that $\max(x, -x) = \lvert x\rvert$, and since there won't be the case $\max(0, -0)$, does this mean that this function is differentiable?",['derivatives']
1329255,"Show that $f \overset{T}{\rightarrow} \frac{1}{x} \int_0^x f(t) dt$ is Bounded, and is NOT Compact in $L^2(0, \infty)$","Can someone help me with this question? Let $f \in X = L^2(0, \infty)$, and define
\begin{equation}
(Tf)(x) = \frac{1}{x} \int_0^x f(t) dt \ .
\end{equation}
Show that $T$ is Bounded, and is NOT Compact. Thanks in advance. Edit: For boundedness, I tried:
\begin{eqnarray}
\| f \| \leq 1 \Rightarrow \| Tf \|^2 &=& \int_0^{\infty} \lvert (Tf)(x) \rvert ^2 \ dx \\
&=& \int_0^{\infty} \lvert \frac{1}{x} \int_0^x f(t) \ dt \rvert ^2 \ dx \\
&\leq& \int_0^{\infty} \frac{1}{x^2} \int_0^x \lvert f(t) \rvert ^2 \ dt \ dx \\
&\leq& \int_0^{\infty} \frac{1}{x^2} \| f \| ^2 \ dx \\
&=& \| f \| ^2 \int_0^{\infty} \frac{1}{x^2} \ dx \\
\end{eqnarray}
But the problem is that $\int_0^{\infty} \frac{1}{x^2} \ dx$ is NOT finite. To prove that $T$ is not compact, I think we should give a sequence of functions, $\{ f_n \}_{n=1}^{\infty}$, such that for every $n$, we have $\| f_n \| \leq 1$ and $\{ Tf_n \}$ has no Cauchy subsequence. But I can't find such sequence of functions.","['compact-operators', 'functional-analysis']"
1329263,Centroid of a Triangle on a inscribed circle,"$AB$ is the hypotenuse of the right $\Delta ABC$ and $AB = 1$. Given that the centroid of the triangle $G$ lies on the incircle of $\Delta ABC$, what is the perimeter of the triangle?","['centroid', 'geometry', 'circles']"
1329272,Groupoid of $G$ torsors over spectrum of a finite field: some clarifications,"I am trying to read Barghav Bhatt's online notes which show that if $f : X \to Y$ is a morphism of varieties over a finite field $\mathbb {F}_q$, then the generating function counting the image of the rational points in the image of $X$ is a rational function. At some point, some notation which is supposedly standard but unfamiliar to me is used. Namely let $X = \text{Spec}\mathbb{F}_q$, let $G$ be a finite group and let $B(G)(X)$ be the groupoid of $G$ torsors over $X$ in the etale topology. Then it is claimed that $B(G)(X)$ can be identified with the groupoid $\text{Map}(B(\mathbb{\hat{Z}}),B(G))$. However, the notation $B(G)$ is unfamiliar to me. Furthermore, it is claimed that, since $B(G)$ is $\mathbb{Q}$-acyclic, using the Lefschetz trace formula we have that $B(G)(\mathbb{F}_q)$ has groupoid cardinality $1$. I will be happy for an explanation about this too. Here is a link to the notes. The relevant parts to my question are Proposition 3.2 and Example 3.5. http://www-personal.umich.edu/~bhattb/math/imgpointcount.pdf",['algebraic-geometry']
1329287,Expected Value and Variance of a GBM Function,"What is the the expected value  of the process $Y = X^{3}$, where X satises the SDE 
$$
dXt = −X_tdt + σX_tdB_t
$$
$(σ > 0)$ and  $X_0 = 1$ I have two different answers:
1) I know that $X_t$ is a GBM with the following form $dX_t = \mu X_tdt + σX_tdB_t$ and i know it's $\mu$ and $\sigma$, so 
$$
X_t = e^{-(1+\frac{\sigma^2}{2})t + \sigma B_t}
$$
Because $Y = X^{3}$ I can find (Is is correct to do?):
$$
Y_t = e^{-3(1+\frac{\sigma^2}{2})t + 3\sigma B_t}
$$
With this result which is the variance and the mean of $Y_t$
2)Another way that opens in front of me is to apply the Ito's Lemma for $Y = X^{3}$, and I find:
$$
\frac{dY_t}{Y_t}=3(\sigma - 1)dt + 3\sigma dB_t
$$ 
So (if my computations are correct) I find a new $\mu$ and a new $\sigma$ compared to the standard form of a GBM, and are respectively $3(\sigma - 1)$ and $3\sigma$. So i must find the form of the process $Y_t$ in the same way of $X_t$ and I find:
$$
Y_t = e^{((3(\sigma - 1)) - \frac{9\sigma^2}{2}) + 3\sigma B_t}
$$
If this computation is correct now i need to find the expected value of $Y_t$ that is:
$$
E[Y_t] = e^{((3(\sigma - 1)) - \frac{9\sigma^2}{2})t}
$$ Please can you tell me which of this solutions is the right one? My professor helped me too much to increase the confusion on my head, i hope someone there could clear my mind a little. Thanks in advance.","['probability-theory', 'brownian-motion', 'stochastic-differential-equations', 'stochastic-analysis']"
1329309,"Prove that, $f'(0) \ge -\sqrt{2}$ for a function $f$ satisfying some conditions on $(-1,1)$. [duplicate]","This question already has answers here : If $f$ is twice differentiable and satisfies the following constraints, prove that $f'(0)\geq-\sqrt 2$. (2 answers) Closed 1 year ago . Let $f:(-1,1)\to \mathbb{R}$ be a twice differentiable function such that, $f(0)=1$, $f'(x)≤0$, $f(x)≥0$ and $f''(x)≤f(x)$ for all $x≥0$. Prove that, $f'(0)≥-\sqrt2$ Progress: I was able to prove $f'(0)≥-2$. For this I have applied Cauchy MVT for $f'$ and $g$ on $[0,x]$ for any $x\in (0,1)$ where $g: [0,x]\to\mathbb{R}$ is defined by, $g(x)=\sqrt{x+1}$. But, couldn't find another approach to get $-\sqrt{2}$.","['derivatives', 'calculus', 'inequality']"
1329323,Limit of a geometric series,"I am trying to practice for a Precalculus exam, but there's this black sheep that I just can't figure out. $$\lim_{n\to \infty} \dfrac{\sqrt[n]{e}+\sqrt[n]{e^2}+\sqrt[n]{e^3}+...+\sqrt[n]{e^n}}{n}$$ We use the standard sum of a geometric series usually to solve similar limits
$S_n = a_1 \dfrac{q^n-1}{q-1}$. I tried simplifying the series and got $\sqrt[n]{e+e^2+e^3+...+e^n}$. I tried to use the sum formula to end up with $e \dfrac {e^n-1}{e-1}$. But then I get stuck.","['geometric-series', 'calculus', 'limits', 'algebra-precalculus', 'sequences-and-series']"
1329338,Discriminant of Polynomials (Galois Theory),"So I'm reading Dummit and Foote and they define the discriminant of $x_{1},...,x_{n}$ by
$$D=\prod_{i<j}(x_{i}-x_{j})^2$$
and the discriminant of a polynomial to be the discriminant of the roots. They say that a permutation $\sigma \in S_{n}$ is in the alternating group $A_{n}$ iff $\sigma$ fixes the product $\sqrt{D}$. It follows by the Fundamental Theorem of Galois Theory that if $F$ has characterstic different from 2 then $\sqrt{D}$ generates the fixed field of $A_{n}$ and generates a quadratic extension of $K$. I am confused where characteristic $2$ comes into this.","['galois-theory', 'positive-characteristic', 'abstract-algebra', 'polynomials', 'finite-fields']"
