question_id,title,body,tags
424518,"Prove that $\dim(X,\succsim)\leq|X^2|$ - A starting point for a journey into order theory","During the last week I kept on thinking about what looked an easy problem at a first glance. Let $(X,\succsim)$ be a preordered set, and define $\mathcal{L}(\succsim)$ as the set of all complete preorders that extend $\succsim$. Define $\dim(X,\succsim)$ as the smallest positive integer $k$ such that $\succsim = R_1 \cap \cdots \cap R_k$ for some $R_i \in \mathcal{L}(\succsim)$, with $i=1,\cdots,k$. Show that $\dim(X,\succsim)\leq|X^2|$. In order to attack the problem, first of all I took a look at $\dim(X,X^2)$ and $\dim(X,\Delta_X)$, where $\Delta_X$ is the diagonal relation. In this question I got a feedback on my conclusions: indeed $\dim(X,X^2)=1$ and $\dim(X,\Delta_X)=2$. The interesting case is $\dim(X,\Delta_X)$, because this is the one that gave me a bit of intuition on how to attack the problem that I present now. Given a $\Delta_X$, we have that $\dim(X,\Delta_X)=2$, because we can imagine all the elements of the diagonal relation (let's call them $x_1,\cdots,x_n$) separated. I literally imagine $n$ loops, one for each element, that are all unrelated. This is a preorder. In order to make it a complete preorder we start to connect them. Now, we can have in the family of complete preorders that extend the original preorder two complete preorders: - one in which all the arrows move from $x_1$ to $x_n$, - and another in which the arrows move in the opposite direction. Here, the direction of the arrows is not such a big problem, so it is without loss of generality. Interestingly, if we intersect those two complete preorders we come up with the original preorder. Thus, $\dim(X,\Delta_X)=2$. Focusing now on the original problem of $\dim(X,\succsim)\leq|X^2|$, I think that I have two problems: 1) I am not sure what the question is really about. Indeed, I think that - stricly speaking - the question is all about proving the (probably) trivial result that in principle $\dim(X,\succsim)$ cannot be bigger than $|X^2|$. So we should prove it by contradiction, coming up with the fact that $|X^2|$ represents the biggest possible numbers of connection we can have on a finite set. [Not sure, if I expressed this idea properly, so feel free to correct me] However, another possible way of looking as this problem is that what we really have to prove is that $|X^2|$ is the upper bound of $\dim(X,\succsim)$. And here, part of my problems get serious... 2) ...because I cannot see how it can be that $\dim(X,\succsim)>2$. This is the case even if I found myself downloading most of the papers written on the topic during the last fifty years (yep, I am kinda perfectionist, so when I do not understand, I find myself trying to read every possible paper on a topic... this is the case also because I am basically self-taught). So, the point here is that I cannot see how $\dim(X,\succsim)>2$, because I can apply the procedure I used to come up with $\dim(X,\Delta_X)=2$ basically always. In other words, I can always find a relation that completes another with some arrows, and another that completes the very same relation with arrows of the opposite direction, coming up with the intersection of the two complete relation equal to the original incomplete relation. In the end, sorry for this long post, for a probably easy question. I guess that some of my problems can be related to my idea of extension of a preorder or a poset. Anyway, I am positive about the fact that with your help I will find what my problems are all about. Looking forward to any feedback. Thanks in advance. PS: I add the tag of ""Graph Theory"", because I tried to use a lot of that kind of intuition to figure out what the problem is all about, and I am sure that having a feedback from that point of view on this issue can be really helpful (both from a pedagogical and theoretical perspective). Edit: I added the following picture in order to show what is the problem I still have, beyond kind and comprehensive Brian M.Scott's answer. Let's say this is an Hasse diagram of a poset, so let's try to focus on the dimension of posets instead of preorders, like in my original problem. In order to make this poset complete (so, to come up with a linear extension of it) I can add a connection that moves from $b$ to $c$ ($bRc$) and another from $a$ to $c$ ($aRc$). Let's call this linear extension $R_1$. Now, let's come up with a new linear extension that moves from the same Hasse diagram, but that has connections that move in the opposite directions (which means that we have $cRa$ and $cRb$). Let's call this new linear extension $R_2$. If we intersect the two linear extension we built up, the result is the original poset. What seems to me is that we can come up with this trick almost always... however, Brian M.Scott pointed me out that I should see this doesn't work even from $n=4$, where $n$ is the cardinality of the poset. Exactly, what am I missing that should be really obvious? I am really sorry for this late edit and by this dumb question, but I don't see how to solve this problem.
Really thanks a lot for any feedback.","['graph-theory', 'elementary-set-theory', 'order-theory']"
424520,Interchange of partial derivative and limit,"Consider the following expression:
$$\frac{\partial}{\partial m} \lim_{T \rightarrow \infty} \gamma(T,m)$$
where $\gamma$ is a function of $T$ and $m$. My question is just: can I permute the partial derivative and the limit operators ? I suppose that I can, given that the concerned variable is different for each operator but I still need a confirmation.","['multivariable-calculus', 'partial-derivative', 'real-analysis', 'limits']"
424521,How useful are geometric aspects when studying finite groups?,"My newbie impression when studying finite group theory is that geometric aspects are not very prevalent. Cayley graphs play quite some role for visualising finite groups, but compared to the study of infinite groups in geometric group theory, geometric aspects seem to be marginal. I therefore wonder: (1) Why is geometry less interesting when studying finite groups (if this is really the case)? (2) Could it (nevertheless) be interesting to delve into geometric group theory when studying finite groups? I find GGT particularly interesting, but as I am currently working in finite group theory I am not sure how advisable it is to hope for connections. Finite groups are special cases of finitely generated infinite groups, but I am not sure if these are uninteresting cases from the GGT viewpoint. Thank you for any clarifications and hints!","['geometric-group-theory', 'finite-groups', 'group-theory']"
424530,Is this similarity to the Fourier transform of the von Mangoldt function real?,"Mathematica knows that the logarithm of $n$ is: $$\log(n) = \lim\limits_{s \rightarrow 1} \zeta(s)\left(1 - \frac{1}{n^{(s - 1)}}\right)$$ The von Mangoldt function should then be: $$\Lambda(n)=\lim\limits_{s \rightarrow 1} \zeta(s)\sum\limits_{d|n} \frac{\mu(d)}{d^{(s-1)}}.$$ Setting the first term of the von Mangoldt function $\Lambda(1)$ equal to the harmonic number $H_{\operatorname{scale}}$ where scale is equal to the scale of the Fourier transform matrix, one can calculate the Fourier transform of the von Mangoldt function with the Mathematica program at the link below: http://pastebin.com/ZNNYZ4F6 In the program I studied the function within the limit for the von Mangoldt function, and made some small changes to the function itself: $f(t)=\sum\limits_{n=1}^{n=k} \frac{1}{\log(k)} \frac{1}{n} \zeta(1/2+i \cdot t)\sum\limits_{d|n} \frac{\mu(d)}{d^{(1/2+i \cdot t-1)}}$
as $k$ goes to infinity. (Edit 20.9.2013: The function $f(t)$ had ""-1"" in the argument for the zeta function.) The plot of this function looks like this: While the plot of the Fourier transform of the von Mangoldt function with the program looks like this: There are some similarities but the Fourier transform converges faster towards smaller oscillations in between the spikes at zeta zeros and the scale factor is wrong. Will the function $f(t)$ above eventually converge to the Fourier transform of the von Mangoldt function, or is it only yet another meaningless plot? Now when I look at it I think the spikes at zeros comes from the zeta function itself and the spectrum like feature comes from the Möbius function which inverts the zeta function. In the Fourier transform the von Mangoldt function has this form: $$\log (\text{scale}) ,\log (2),\log (3),\log (2),\log (5),0,\log (7),\log (2),\log (3),0,\log (11),0,...,\Lambda(\text{scale})$$ $$scale = 1,2,3,4,5,6,7,8,9,10,...k$$ Or as latex: $$\Lambda(n) = \begin{cases} \log q & \text{if }n=1, \\\log p & \text{if }n=p^k \text{ for some prime } p \text{ and integer } k \ge 1, \\ 0 & \text{otherwise.} \end{cases}$$ $$n=1,2,3,4,5,...q$$ TableForm[Table[Table[If[n == 1, Log[q], MangoldtLambda[n]], {n, 1, q}],
{q, 1, 12}]] scale = 50; (*scale = 5000 gives the plot below*)
Print[""Counting to 60""]
Monitor[g1 = 
  ListLinePlot[
   Table[Re[
     Zeta[1/2 + I*k]*
      Total[Table[
        Total[MoebiusMu[Divisors[n]]/Divisors[n]^(1/2 + I*k - 1)]/(n*
           k), {n, 1, scale}]]], {k, 0 + 1/1000, 60, N[1/6]}], 
   DataRange -> {0, 60}, PlotRange -> {-0.15, 1.5}], Floor[k]] Dirichlet series: Clear[f];
scale = 100000;
f = ConstantArray[0, scale];
f[[1]] = N@HarmonicNumber[scale];
Monitor[Do[
  f[[i]] = N@MangoldtLambda[i] + f[[i - 1]], {i, 2, scale}], i]
xres = .002;
xlist = Exp[Range[0, Log[scale], xres]];
tmax = 60;
tres = .015;
Monitor[errList = 
   Table[(xlist^(1/2 + I k - 1).(f[[Floor[xlist]]] - xlist)), {k, 
     Range[0, 60, tres]}];, k]
ListLinePlot[Im[errList]/Length[xlist], DataRange -> {0, 60}, 
 PlotRange -> {-.01, .15}] Fourier transform: Matrix inverse: Clear[n, k, t, A, nn];
nn = 50;
A = Table[
   Table[If[Mod[n, k] == 0, 1/(n/k)^(1/2 + I*t - 1), 0], {k, 1, nn}], {n, 1,
     nn}];
MatrixForm[A];
ListLinePlot[
 Table[Total[
   1/Table[n*t, {n, 1, nn}]*
    Total[Transpose[Re[Inverse[A]*Zeta[1/2 + I*t]]]]], {t, 1/1000, 60,
    N[1/6]}], DataRange -> {0, 60}, PlotRange -> {-0.15, 1.5}] Clear[n, k, t, A, nn];
nnn = 12;
Show[Flatten[{Table[
    ListLinePlot[
     Table[Re[
       Total[1/Table[n*t, {n, 1, nn}]*
         Total[Transpose[
           Inverse[
             Table[Table[
               If[Mod[n, k] == 0, N[1/(n/k)^(1/2 + I*t - 1)], 0], {k, 
                1, nn}], {n, 1, nn}]]*Zeta[1/2 + I*t]]]]], {t, 1/1000,
        60, N[1/10]}], DataRange -> {0, 60}, 
     PlotRange -> {-0.15, 1.5}], {nn, 1, nnn}], 
   Table[ListLinePlot[
     Table[Re[
       Total[1/Table[n*t, {n, 1, nn}]*
         Total[Transpose[
           Inverse[
             Table[Table[
               If[Mod[n, k] == 0, N[1/(n/k)^(1/2 + I*t - 1)], 0], {k, 
                1, nn}], {n, 1, nn}]]*Zeta[1/2 + I*t]]]]], {t, 1/1000,
        60, N[1/10]}], DataRange -> {0, 60}, 
     PlotRange -> {-0.15, 1.5}, PlotStyle -> Red], {nn, nnn, nnn}]}]] 12 first curves together or partial sums: Clear[n, k, t, A, nn, dd];
dd = 220;
Print[""Counting to "", dd];
nn = 20;
A = Table[
   Table[If[Mod[n, k] == 0, 1/(n/k)^(1/2 + I*t - 1), 0], {k, 1, 
     nn}], {n, 1, nn}];
Monitor[g1 = 
   ListLinePlot[
    Table[Total[
      1/Table[n*t, {n, 1, nn}]*
       Total[Transpose[
         Re[Inverse[
           IdentityMatrix[nn] + (Inverse[A] - IdentityMatrix[nn])*
             Zeta[1/2 + I*t]]]]]], {t, 1/1000, dd, N[1/100]}], 
    DataRange -> {0, dd}, PlotRange -> {-7, 7}];, Floor[t]];
mm = N[2*Pi/Log[2], 20];
g2 = Graphics[
   Table[Style[Text[n, {mm*n, 1}], FontFamily -> ""Times New Roman"", 
     FontSize -> 14], {n, 1, 32}]];
Show[g1, g2, ImageSize -> Large]; Matrix Inverse of matrix inverse times zeta function (on critical line): Clear[n, k, t, A, nn, h];
nn = 60;
h = 2; (*h=2 gives log 2 operator, h=3 gives log 3 operator and so on*)
A = Table[
   Table[If[Mod[n, k] == 0, 
     If[Mod[n/k, h] == 0, 1 - h, 1]/(n/k)^(1/2 + I*t - 1), 0], {k, 1, 
     nn}], {n, 1, nn}];
MatrixForm[A];
g1 = ListLinePlot[
   Table[Total[
     1/Table[n*t, {n, 1, nn}]*
      Total[Transpose[Re[Inverse[A]*Zeta[1/2 + I*t]]]]], {t, 1/1000, 
     nn, N[1/6]}], DataRange -> {0, nn}, PlotRange -> {-3, 7}];
mm = N[2*Pi/Log[h], 12];
g2 = Graphics[
   Table[Style[Text[n*2*Pi/Log[h], {mm*n, 1}], 
     FontFamily -> ""Times New Roman"", FontSize -> 14], {n, 1, 32}]];
Show[g1, g2, ImageSize -> Large] Matrix inverse of Riemann zeta times log 2 operator: Jeffrey Stopple's code : Show[Graphics[
  RasterArray[
   Table[Hue[
     Mod[3 Pi/2 + Arg[Zeta[sigma + I t]], 2 Pi]/(2 Pi)], {t, -30, 
     30, .1}, {sigma, -30, 30, .1}]]], AspectRatio -> Automatic] Normal or usual zeta: Show[Graphics[
  RasterArray[
   Table[Hue[
     Mod[3 Pi/2 + 
        Arg[Sum[Zeta[sigma + I t]*
           Total[1/Divisors[n]^(sigma + I t - 1)*
              MoebiusMu[Divisors[n]]]/n, {n, 1, 30}]], 
       2 Pi]/(2 Pi)], {t, -30, 30, .1}, {sigma, -30, 30, .1}]]], 
 AspectRatio -> Automatic] Spectral zeta (30-th partial sum): Clear[n, k, t, A, nn, B];
nn = 60;
A = Table[
  Table[If[Mod[n, k] == 0, 1/(n/k)^(1/2 + I*t - 1), 0], {k, 1, 
    nn}], {n, 1, nn}]; MatrixForm[A];
B = FourierDCT[
   Table[Total[
     1/Table[n, {n, 1, nn}]*
      Total[Transpose[Re[Inverse[A]*Zeta[1/2 + I*t]]]]], {t, 1/1000, 
     600, N[1/6]}]];
g1 = ListLinePlot[B[[1 ;; 700]]*Table[Sqrt[n], {n, 1, 700}], 
   DataRange -> {0, 60}, PlotRange -> {-60, 600}];
mm = 11.35/Log[2];
g2 = Graphics[
   Table[Style[Text[n, {mm*Log[n], 100 + 20*(-1)^n}], 
     FontFamily -> ""Times New Roman"", FontSize -> 14], {n, 1, 16}]];
Show[g1, g2, ImageSize -> Large] Mobius function -> Dirichlet series -> Spectral Riemann zeta -> Fourier transform -> von Mangoldt function: Larger von Mangoldt function plot still wrong amplitude: https://i.sstatic.net/02A1p.jpg Clear[n, k, t, A, nn, B, g1, g2];
nn = 32;
A = Table[
   Table[If[Mod[n, k] == 0, 1/(n/k)^(1/2 + I*t - 1), 0], {k, 1, 
     nn}], {n, 1, nn}];
MatrixForm[A];
B = FourierDCT[
   Table[Total[
     1/Table[n, {n, 1, nn}]*
      Total[Transpose[Re[Inverse[A]*Zeta[1/2 + I*t]]]]], {t, 0, 2000, 
     N[1/6]}]];
g1 = ListLinePlot[B[[1 ;; 2000]], DataRange -> {0, 60}, 
   PlotRange -> {-5, 50}];
2*N[Length[B]/1500, 12];
mm = 13.25/Log[2];
g2 = Graphics[
   Table[Style[Text[n, {mm*Log[n], 7 + (-1)^n}], 
     FontFamily -> ""Times New Roman"", FontSize -> 14], {n, 1, 40}]];
Show[g1, g2, ImageSize -> Full] Plot from program above: https://i.sstatic.net/r6mTJ.jpg Partial sums of zeta function, use this one: Clear[n, k, t, A, nn, B];
nn = 80;
mm = 11.35/Log[2];
A = Table[
   Table[If[Mod[n, k] == 0, 1/(n/k)^(1/2 + I*t - 1), 0], {k, 1, 
     nn}], {n, 1, nn}];
MatrixForm[A];
B = Re[FourierDCT[
    Monitor[Table[
      Total[1/Table[
          n, {n, 1, nn}]*(Total[
           Transpose[Inverse[A]*Sum[1/j^(1/2 + I*t), {j, 1, nn}]]] - 
          1)], {t, 1/1000, 600, N[1/6]}], Floor[t]]]];
g1 = ListLinePlot[B[[1 ;; 700]], DataRange -> {0, 60/mm}, 
   PlotRange -> {-30, 30}];
g2 = Graphics[
   Table[Style[Text[n, {Log[n], 5 - (-1)^n}], 
     FontFamily -> ""Times New Roman"", FontSize -> 14], {n, 1, 32}]];
Show[g1, g2, ImageSize -> Full] Edit 17.1.2015: Clear[g1, g2, scale, xres, x, a, c, d, datapointsdisplayed];
scale = 1000000;
xres = .00001;
x = Exp[Range[0, Log[scale], xres]];
a = -FourierDCT[
    Log[x]*FourierDST[
      MangoldtLambda[Floor[x]]*(SawtoothWave[x] - 1)*(x)^(-1/2)]];
c = 62.357;
d = N[Im[ZetaZero[1]]];
datapointsdisplayed = 500000;
ymin = -1.5;
ymax = 3;
p = 0.013;
g1 = ListLinePlot[a[[1 ;; datapointsdisplayed]], 
   PlotRange -> {ymin, ymax}, 
   DataRange -> {0, N[Im[ZetaZero[1]]]/c*datapointsdisplayed}];
Show[g1, Graphics[
  Table[Style[Text[n, {22800*Log[n], -1/4*(-1)^n}], 
    FontFamily -> ""Times New Roman"", FontSize -> 14], {n, 1, 12}]], 
 ImageSize -> Large] Show[Graphics[
  RasterArray[
   Table[Hue[
     Mod[3 Pi/2 + 
        Arg[Sum[Zeta[sigma - I t]*
           Total[1/Divisors[n]^(sigma + I t)*MoebiusMu[Divisors[n]]]/
            n, {n, 1, 30}]], 2 Pi]/(2 Pi)], {t, -30, 
     30, .1}, {sigma, -30, 30, .1}]]], AspectRatio -> Automatic] The following is a relationship: Let $\mu(n)$ be the Möbius function, then: $$a(n) = \sum\limits_{d|n} d \cdot \mu(d)$$ $$T(n,k)=a(GCD(n,k))$$ $$T = \left(   \begin{array}{ccccccc}   +1&+1&+1&+1&+1&+1&+1&\cdots \\ +1&-1&+1&-1&+1&-1&+1 \\ +1&+1&-2&+1&+1&-2&+1 \\ +1&-1&+1&-1&+1&-1&+1 \\ +1&+1&+1&+1&-4&+1&+1 \\ +1&-1&-2&-1&+1&+2&+1 \\ +1&+1&+1&+1&+1&+1&-6 \\ \vdots&&&&&&&\ddots \end{array}   \right)$$ $$\sum\limits_{k=1}^{\infty}\sum\limits_{n=1}^{\infty} \frac{T(n,k)}{n^c \cdot k^z} = \sum\limits_{n=1}^{\infty} \frac{\lim\limits_{s \rightarrow z} \zeta(s)\sum\limits_{d|n} \frac{\mu(d)}{d^{(s-1)}}}{n^c} = \frac{\zeta(z) \cdot \zeta(c)}{\zeta(c + z - 1)}$$ which is part of the limit: $$\frac{\zeta '(s)}{\zeta (s)}=\lim_{c\to 1} \, \left(\zeta (c)-\frac{\zeta (c) \zeta (s)}{\zeta (c+s-1)}\right)$$","['fourier-analysis', 'number-theory']"
424551,Every maximal ideal is principal. Is $R$ principal?,"Let $R$ be a commutative ring with 1. If every maximal ideal of $R$ is principal, is $R$ a principal ideal ring?","['commutative-algebra', 'ring-theory', 'ideals', 'abstract-algebra']"
424552,What is the definition of a labeled function?,"I always see that people label their functions by giving an index. Specifically I have this example: $Theorem$: There is a unique binary operation $+:\mathbb{N}\times\mathbb{N}$ that satisfies the following two propierties for all $n,m\in N$ $1)$ $n+1=s(n)$ $2)$ $n+s(m)=s(n+m)$ Note: funcion $s$ is given $proof (existence):)$ Let $p\in \mathbb{N}$. By the theorem of recursion, there is a unique function $f_{p}: \mathbb{N}\longrightarrow \mathbb{N}$ such that $f_{p}(1)=s(p)$ and $f_{p}\circ s=s\circ f_{p}$. Let $+:\mathbb{N} \longrightarrow \mathbb{N}$ be defined by$ c+d=f_{c}(d)$ for all $c,d\in \mathbb{N}$. Let $n,m\in \mathbb {N}$. Then $n+1=f_{n}(1)=s(n)$, which is part $(1)$, and $n+s(m)=f_{n}(s(m))=(f_{n}\circ s)(m)=(s\circ f_{n}(m))=s(f_n(m))=s(n+m)$, which is part $(2)$ So, here I'm confused because I don't know what the subindex $p$ means. I can see it like 1) a name for the function ( and we are talking about a universal instantiation) or 2) I can see it like a parameter (and then $f_{p}:\mathbb{N}\longrightarrow \mathbb{N}$ stands for a particular case of $f:\mathbb{N}\times\mathbb{N}\longrightarrow \mathbb{N}$). I hope you can see my point. Another examples: ""Let $n\in \mathbb{N}$ and define for all $x\in \mathbb{R}$ $f_{n}(x)=(n+1)x^{2}$ "" Does this means $f:\mathbb{N}\times  \mathbb{R}\longrightarrow \mathbb{R}$?. Yet another example:  ""Let $X$ be a set. We talk about the identity function of $X$ to be defined as $I_{X}(y)=y$ for every $y\in X$"". In general, what is the definition of a labeled function?","['logic', 'proof-writing', 'elementary-set-theory']"
424558,How prove this $\lim_{n\to\infty}\int_{0}^{\frac{\pi}{2}}\sin{x^n}dx=0$,"show that
$$\lim_{n\to\infty}\int_{0}^{\dfrac{\pi}{2}}\sin{x^n}dx=0$$ I have see this similar problem
$$\lim_{n\to\infty}\int_{0}^{\dfrac{\pi}{2}}\sin^n{x}dx=0$$
poof:
$\forall \xi>0,0<\delta<\xi/2$,and there is $N$,such $0<\sin^n{\pi/2-\delta}<\xi/\pi(n\ge N)$
then we have
$$\int_{0}^{\pi/2}\sin^n{x}dx=\left(\int_{0}^{\pi/2-\delta}+\int_{\pi/2-\delta}^{\pi/2}\right)\sin^n{x}dx=I_{1}+I_{2}$$
then 
$$|I_{1}|\le\left(\sin{\pi/2-\delta}\right)^n(\pi/2-\delta)<\xi/\pi\cdot\pi/2=\xi/2$$
and
$$|I_{2}|\le\left(\pi/2-(\pi/2-\delta)\right)=\delta<\xi/2$$
and This problem have many other methods, But for this $$\lim_{n\to\infty}\int_{0}^{\dfrac{\pi}{2}}\sin{x^n}dx=0$$
I can't prove it,Thank you","['integration', 'limits']"
424573,Is it possible to calculate sine by hand? [duplicate],"This question already has answers here : Is there a way to get trig functions without a calculator? (8 answers) Closed 7 years ago . Without a calculator, how can I calculate the sine of an angle, for example 32(without drawing a triangle)?",['trigonometry']
424621,Confusing Trigonometry Problem,"Lets say at an intersection the words ""STOP HERE"" are painted on the road in red letters 2.5m high. It is important that drivers using this lane can read the letters. How can I find the angle subtended by the letters to the eyes of a driver 20m from the base of the letters and 1.25m above the road? Is it right to use tan, so tanθ=1.25/20? Or am I missing something?",['trigonometry']
424648,Is the product of non-separated schemes non-separated?,"My question is the title, but let me be more specific: for schemes $X$ and $Y$ over $S$, with at least one non-separated over $S$, is it true that the fibered product $X\times_S Y$ is also not separated over $S$? My instinct says ""no"" because of the remarks at the top of page 95 in Hartshorne: ""The rough idea is that in order for a schemes $X$ to be separated, it should not contain any subscheme which looks like a curve with a doubled point...""  So if $X$ is not separated, it contains such a subscheme, and thus so should the product $X\times_S Y$. I tried proving the claim using the valuative criterion, and I think I was able to do it. Unfortunately, I don't know how to typeset diagrams here (it seems xymatrix is not supported), but the idea is to take 2 of the different morphisms from $T$ to $X$ (using the notation of Hartshorne here in which $T = \text{Spec}(R)$ for a valuation ring $R$) and make them morphisms to the product. Unless I overlooked something, the proof was pretty simple. Is all this correct or are there counter-examples out there? EDIT : As pointed out by Martin Brandenburg below, in general, the product of non-separated schemes could be separated. However, I think it is true that if the schemes are all over some field $k$ then non-separated-ness is preserved under taking products. Is this true, and if so, how would one prove it?","['algebraic-geometry', 'schemes']"
424665,$f$ is holomorphic in $\Omega$ such that $|f|$ is harmonic; we need to show that $f$ is constant.,"$f$ is holomorphic in $\Omega$ such that $|f|$ is harmonic; we need to show that $f$ is constant. Let $$f=u(x,y)+iv(x,y)\Rightarrow |f|=\sqrt{u^2+v^2}\quad \rm{and}\quad \nabla^2|f|=0$$ right? Also I have $u_x=v_y, v_x = -u_y$ $$\nabla^2 = {\partial^2\over \partial x^2}+{\partial^2\over \partial y^2},$$ so as $ \nabla^2|f|=0 $ we get $$ u_{xx}+u_{yy}+v_{xx}+v_{yy}=0 $$ So now could any one show me how to proceed?",['complex-analysis']
424671,$E$ is closed $\iff\partial E$ (boundary of set $E$) $\subseteq E$,I am studying topology of euclidean space from William Wade's text book. I saw this question. But I cannot come up with any ideas. Please show me the solution in an instructive an clear way. Thank you for yourhelp. $E$ is closed $\iff\partial E$ (boundary of set $E$) $\subseteq E$,"['general-topology', 'real-analysis', 'analysis']"
424687,Property of the identity matrix,Is the identity the only matrix $A \in \mathbb R^{n \times n}$ with real positive eigenvalues that is equal to its inverse? Thanks.,['matrices']
424693,What's the meaning of computing an integral at a given point?,"Let $f$ be a function. If one finds $\displaystyle \frac{\mathrm d}{\mathrm dx}f$ and computes it at $x=a$, then one gets the rate of change of $f$ at $a$. That can be useful in some situations. But if one finds $\int f \space \mathrm dx$ and computes it at $x=a$, what information can we obtain about the function $f$?","['integration', 'indefinite-integrals']"
424695,Alternative unconditional form of $\sqrt{n -\sqrt{n -\sqrt{n -\cdots}}}$?,"Consider $a_n$, where $$\begin{align} a_n &=\small{\sqrt{n -\!\!\!\sqrt{n -\!\!\!\sqrt{n -\!\!\sqrt{n -\!\!\sqrt{n -\!\!\sqrt{n -\!\sqrt{n - \cdots}}}}}}}}\end{align}$$ Using a recursive solution, such that: $$a_n = f(n) = \sqrt{n - f(n)}$$ is too slow, while an iterated form don't fit my usage. Is there a unconditional form of $a_n$ which don't rely as heavily on self-reference or recursion? Maybe an approximation?","['sequences-and-series', 'recursion']"
424698,Is $\ln(x)$ uniformly continuous?,"Let $x\in[1,\infty)$. Is $\ln x$ uniformly continuous? I took this function to be continuous and wrote the following proof which I'm not entirely sure of. Let $\varepsilon>0 $, $x,y\in[1, ∞)$ and $x>y$. 
Then, $\ln x< x$ and $\ln y< y$ and this follows that $0<|\ln x-\ln y|<|x-y|$ since $x> y$.
Choose $δ=ϵ$. Now suppose $|x-y|< δ$. Then, $|\ln x-\ln y|<|x-y|<\varepsilon$ It would be much appreciated if someone could validate my proof","['uniform-continuity', 'continuity', 'real-analysis', 'analysis']"
424701,Compute this limit $\lim_{x\to0}\frac{\sin(x^2+\frac{1}{x})-\sin\frac{1}{x}}{x}$ using L'Hôpital's rule,"I have asked this problem before , but I can't understand the explanation, I couldn't understand how the sin multiply for cos, and too multiply for A + and - B: $$\sin(A)-\sin(B)=2\sin\left(\frac{A-B}{2}\right)\cos\left(\frac{A+B}{2}\right)$$ and I don't understand in this step how/why the $A-B$ and $A+B$ was replaced by $\frac{x^2}{2}$ and $\frac{x^2}{2}+\frac{1}{x}$ : $$\lim_{x\to0}\frac{\sin\left(x^2+\frac1x\right)-\sin\left(\frac1x\right)}{x}= \lim_{x\to0}\frac{2\sin\left(\frac{x^2}{2}\right)\cos\left(\frac{x^2}{2}+\frac1x\right)}{x}.$$","['calculus', 'limits']"
424723,Determinant in Line-Line Intersection,"Assume we have two equations of a line, $A_1 x + B_1y = C_1$ and $A_2 x + B_2y = C_2$ Now we multiply the first equation by $B_2$ and the second by $B_1$ to obtain (1) $A_1B_2x + B_1B_2y = C_1B_2$ and (2) $A_2B_1x + B_1B_2y = C_2B_1$ Now, if we do (1) - (2) we get $(A_1B_2 - A_2B_1)x = C_1B_2 - C_2B_1$ Then naturally we have, $x = \frac{C_1B_2 - C_2B_1}{A_1B_2 - A_2B_1}$ Note that, $A_1B_2 - A_2B_1$ is the determinant of $(A_1, B_1)$ and $(A_2, B_2)$ . What does this mean? Why does the determinant come in the equation when trying to solve line-line intersections? What is the intuition behind dividing the equation by the determinant? Assume the determinant is non-zero. Reference is here . ----------------Edit------------- I understand that if the determinant is 0, they are parallel. My question is more of what does the determinant stand for in $x = \frac{C_1B_2 - C_2B_1}{A_1B_2 - A_2B_1}$ Is it an area, a vector length, etcetc.  Why does the determinant end up in the denominator?",['geometry']
424725,Contour integration with branch cut,"This is an exercise in a course on complex analysis I am taking: Determine the function $f$ using complex contour integration:
$$\lim_{R\to\infty}\frac{1}{2\pi i}\int_{c-iR}^{c+iR}\frac{\exp(tz)}{(z-i)^{\frac{1}{2}}(z+i)^{\frac{1}{2}}} dz$$
Where $c>0$ and the branch cut for $z^\frac{1}{2}$ is to be chosen on $\{z;\Re z=0, \Im z \leq0\}$.
Make a distinction between:
$$t>0, \quad t=0, \quad t<0$$
I think I showed that for $t<0$, $f(t)=0$ by using Jordan's Lemma. For $t=0$ I think the answer must be $f(0)=\frac{1}{2}$. For $t>0$ however, I have no idea what contour I have to define, nor how I have to calculate the residues in $i$ and $-i$.","['complex-analysis', 'contour-integration']"
424728,"$ k x^2 +4x = n $, Algorithm or any other method needed","I want to find any $n < 10^{18} $ so that the equation below has at least two pairs of solutions $(k, x)$ $ k  x^2 +4 x  = n $ constraints: $x > 10^6; \; x > k ; \; k, x \in \mathbb{N}$ I can not solve this mathematically, nor I can think of any fast brute-force algorithm.
Is there any integer programming method which deals with such kind of problem?","['integer-programming', 'quadratic-programming', 'discrete-mathematics']"
424743,hard time with series convergence or divergence [duplicate],This question already has answers here : Convergence of $\sum_{n=1}^\infty \frac{\sin^2(n)}{n}$ (2 answers) Closed 11 years ago . I'm having real hard time with this series I can't prove that the series converges and also I can't prove that the series diverges: $$\sum_{k=1}^\infty\frac{\sin^2(n)}{n}.$$ any help would be appreciated.,"['divergent-series', 'convergence-divergence', 'sequences-and-series']"
424751,Can I always extend a selfadjoint Operator in $L^2$?,"Assume that we have a self-adjoint operator $T\colon D \to D$ where $D \subset L^2$ is some finite dimensional subspace. Can I conclude that than a self-adjoint operator $S \colon L^2 \to L^2$ exists with $S=T$ on $D$ ? Hope someone can help me.
Best regards,
Adam","['vector-spaces', 'adjoint-operators', 'functional-analysis', 'operator-theory']"
424775,Why does $(-2^2)^3$ equal $-64$ and not $64$?,"The title says it all. Why does $(-2^2)^3$ equal $-64$ and not $64$? This was on my algebra final, and I am completely stuck on how it works.","['exponentiation', 'algebra-precalculus']"
424789,An extension theorem in measure theory.,"I'm reading ""Real Analysis"" by Royden (4th ed). According to this text, a semiring $ S$ of subsets of $X$ is a nonempty collection of subsets of $X$ that is closed for finite intersections and such that, if $A,B \in S$, then $A\setminus B = \bigcup\limits_{k=1}^{n} C_{k}$, with the $C_k \in S$ and disjoint. Given a collection $S$ of subsets of $X$, a premeasure $\mu$ is a map $\mu :S \rightarrow \left [ 0, \infty  \right ]  $ for which $\mu\left (\bigcup\limits_{k=1}^{n} E_{k}  \right ) = \sum \limits_{k=1}^{n} \mu\left ( E_k \right )$ whenever the $E_k \in S$ are disjoint and $\bigcup\limits_{k=1}^{n} E_{k}  \in S$ and $\mu\left ( E \right ) \leqslant \sum \limits_{k=1}^{\infty} \mu\left ( E_k \right )$ whenever $E, E_k \in S$ with $ E \subseteq \bigcup\limits_{k=1}^{n} E_{k}   $ and for which $\mu\left(\emptyset\right ) = 0$ if $\emptyset \in S$ . Then, the following theorem gets proven (I get all that): Let $\mu :S \rightarrow \left [ 0, \infty  \right ]  $ be a premeasure on a semiring $S$ of subsets of $X$. Then the Carathéodory measure $\bar{\mu}$ induced by $\mu$ is an extension of $\mu$. Furthermore, if $\mu$ is $\sigma$-finite, then $\bar{\mu}$ is the unique measure on the $\sigma$-algebra of Carathéodory measurable sets that extends $\mu$. What I don't understand is why the following is a corollary of this theorem: Let $S$ be a semiring of subsets of $X$ and $\mathcal{B}$ the smallest $\sigma$-algebra of subsets of $X$ that contains $S$. Then two $\sigma$-finite measures on $\mathcal{B}$ are equal if and only if they agree on $S$ . What am I missing? Any thoughts anyone? Many thanks in advance.",['measure-theory']
424791,Is $\alpha + \omega$ limit ordinal,"If $\alpha$ is any ordinal number does $\alpha + \omega$ have to be limit ordina, where $\omega$ is ordinal number of $\mathbb{N}$? I know that $\omega+\alpha$ is not always limit ordinal since $\omega + 1$ is succesor of $\omega$.","['ordinals', 'elementary-set-theory']"
424795,Scheme over S and morphisms,"Quoting from Hartshorne Let $S$ be a fixed scheme. A scheme over $S$ is a scheme $X$, together with a morphism $X \to S$. If $X$ and $Y$ are schemes over $S$, a morphism of $X$ to $Y$ as schemes over $S$, (also called an $S$ morphism ) is a morphism $X \to Y$ which is compatible with the given morphisms to $S$. There are two things I don't understand.
a) What is meant by ""morphism $X \to Y$ which is compatible with the given morphisms to $S$"". I don't understand what condition needs to be satisfied for the required compatibility. Can anyone please tell me what actual conditions (in terms of maps) are required to be satisfied? b)What is the intuition behind this definition ?","['algebraic-geometry', 'schemes']"
424805,"Limit $\lim_{x\rightarrow x_0, x\in M} \int_{\partial M} \frac{1}{||y-x||} n_y \cdot \nabla_y \frac{-1}{||y-x||} dS_y$","Ok I had a question I think I can almost answer it but I miss one step: Let $\partial M$ be a closed surface in $\mathbb{R}^3$, $x_0 \in \partial M$ than show this limit:
  $$\lim_{\substack{x\rightarrow x_0 \\ x\in M}} \int_{\partial M} \frac{1}{||y-x||} n_y \cdot \nabla_y \frac{-1}{||y-x||} dS_y = \lim_{\substack{x\rightarrow x_0 \\ x\in M}} \int_{\partial M} \frac{n_y \cdot (y-x)}{||y-x||^4}   dS_y  = \infty$$ The condition on $\partial M$ is free to choose. So suppose that it is smooth as much as you need. But ideally I would like to prove it for piece wise $C^1$ surface. So has anybody idea how to show this limit? Edit: Ok my best shot when $\partial M$ is convex. But I can't prove it yet, I'm experiencing the same problem as when I show that $\int_0^1 \frac{1}{t^\alpha} dt$ diverge(for $\alpha > 1 $) by this technique: $$ \int_0^1 \frac{1}{t^\alpha} dt \geq \int_0^x \frac{1}{t^\alpha} dt \geq \frac{x}{x^\alpha} \rightarrow \infty$$ as $x$ goes to zero. But IT doesn't work for $\alpha =1$ yet the integral diverge. So here goes my try, I need two lemmas about convex surfaces. Lemma1: It is bound on how big can be angle between $n_y$ and $y-x$. Let $\partial M$ is convex surface in $\mathbb{R}^n$. Than for every $x$ in interior of $\partial M$ ie $x\in M$. This inequality holds:
  $$ \forall y\in \partial M: n_y\cdot \frac{y-x}{\|y-x\|} \geq \frac{\min_{z\in \partial M} \|x-z\|}{\max_{z\in \partial M} \|x-z\|}\geq \frac{\text{dist}(x,\partial M)}{\text{diam}(\partial M)}$$
  $n_y$ is outer normal at point $y$ This lemma is quite straight forward just draw a picture in 2d and you'll see it. Lemma2: This is bound on how small can get and surface area of convex surface at vicinity of some point $x$ Let $\partial M$ is convex surface in $\mathbb{R}^n$ and $x$ is point in interior of $\partial M$ ie $x\in M$. Denote $\rho = \text{dist}(x,\partial M) = \text{dist}(x,x_0)$ for some $x_0 \in \partial M$. Than:
  $$\int_{\partial M \cap B(x_0,2\rho)} 1 \, dS \geq \alpha_{n-1} \left(\frac{\sqrt{3}}{2} \rho \right)^{n-1} $$
  where $\alpha_n$ is volume of unit ball in $\mathbb{R}^n$. Again draw this in 2d and you'll see it. Maybe I will add pictures if I find out how. Now to the limit:"" denote $\rho = \text{dist}(x,\partial M)=\|x-x_0\|$, $D = \text{diam}(\partial M)$ $$ \int_{\partial M} \frac{1}{||y-x||} n_y \cdot \nabla_y \frac{-1}{||y-x||} dS_y  = \int_{\partial M} \frac{n_y \cdot (y-x)}{||y-x||^4}   dS_y  \geq$$ $$ \int_{\partial M} \frac{n_y \cdot (y-x)}{||y-x||^4}   dS_y  \geq \int_{\partial M} \frac{\rho  \|y-x\|}{D\|y-x\|^4}   dS_y \geq $$ $$ \int_{\partial M \cap B(x_0,2\rho)} \frac{\rho  \|y-x\|}{D\|y-x\|^4}   dS_y \geq \int_{\partial M \cap B(x_0,2\rho)} \frac{\rho^2}{D 2^4 \rho^4}   dS_y \geq$$ $$ \frac{\rho^2}{D 2^4 \rho^4} \int_{\partial M \cap B(x_0,2\rho)} dS_y \geq \frac{\rho^2}{D 2^4 \rho^4}  \pi \left(\frac{\sqrt{3}}{2} \rho \right)^{2} = \frac{1}{D 2^4 }  \pi \frac{3}{4}$$ But that does not got to infinity :(( I have one minor interesting observation. Let $\Gamma$ be any surface in $\mathbb{R}^3$. $\Gamma$ can be self intersecting for example: embedded Klein bottle in $\mathbb{R}^3$. Than I think that $$-\frac{1}{4\pi}\int_{\partial M}  n_y \cdot \nabla_y \frac{1}{||y-x||} dS_y$$ is something like winding number of $\Gamma$ around $x$. Can anybody elaborate on that? What number would I get if $\Gamma$ would be Klein bottle ? I think that Klein bottle doesn't have something like interior so is the integral zero everywhere? Therefore is it possible in 2D to have closed, regular $C^1$ curve that has empty interior?","['winding-number', 'integration', 'surfaces', 'limits']"
424807,Integral of polylogarithms and logs in closed form: $\int_0^1 \frac{du}{u}\text{Li}_2(u)^2(\log u)^2$,"Is it possible to evaluate this integral in closed form?
$$ \int_0^1 \frac{du}{u}\text{Li}_2(u)^2\log u \stackrel{?}{=} -\frac{\zeta(6)}{3}.$$
I found the possible closed form using an integer relation algorithm. I found several other possible forms for similar integrals, including
$$ \int_0^1 \frac{du}{u}\text{Li}_2(u)^2(\log u)^2 \stackrel{?}{=} -20\zeta(7)+12\zeta(2)\zeta(5).$$ There doesn't seem to be an equivalent form when the integrand contains $(\log u)^3$, at least not just in terms of $\zeta$. Does anybody know a trick for evaluating these integrals? Update. The derivation of the closed form for the second integral follows easily along the ideas O.L. used in the answer for the first integral. Introduce the functions
$$ I(a,b,c) = \int_0^1 \frac{du}{u}(\log u)^c \text{Li}_a(u)\text{Li}_b(u) $$
and
$$ S(a,b,c) = \sum_{n,m\geq1} \frac{1}{n^am^b(n+m)^c}. $$
Using integration by parts, the expansion of polylogarithms from their power series definition and also that
$$ \int_0^1 (\log u)^s u^{t-1}\,du = \frac{(-1)^s s!}{t^{s+1}},$$
check that
$$ I(2,2,2) = -\frac23 I(1,2,3) = 4S(1,2,4). $$ Now use binomial theorem and the fact that $S(a,b,c)=S(b,a,c)$ to write
$$ 6S(1,2,4) + 2S(3,0,4) = 3S(1,2,4) + 3S(2,1,4)+S(0,3,4)+S(3,0,4) = S(3,3,1). $$
Now, using Mathematica, 
$$ S(3,3,1) = \sum_{n,m\geq1}\frac{1}{n^3m^3(n+m)} = \sum_{m\geq1}\frac{H_m}{m^6} - \frac{\zeta(2)}{m^5} + \frac{\zeta(3)}{m^4}, $$
and
$$ \sum_{m\geq1}\frac{H_m}{m^6} = -\zeta(4)\zeta(3)-\zeta(2)\zeta(5)+4\zeta(7), $$
so
$$ S(3,3,1) = 4\zeta(7)-2\zeta(2)\zeta(5). $$ Also,
$$ S(0,3,4) = \zeta(3)\zeta(4) - \sum_{m\geq1} \frac{H_{n,4}}{m^3} = -17\zeta(7)+10\zeta(2)\zeta(5)+\zeta(3)\zeta(4), $$
from which it follows that
$$ I(2,2,2) = \frac23\left(S(3,3,1)-2S(0,3,4)\right) = -20\zeta(7)+12\zeta(2)\zeta(5). $$","['closed-form', 'sequences-and-series', 'integration', 'harmonic-numbers']"
424808,Do endomorphisms of quotients always lift?,"Let $H \to G$ be an injective homomorphism of Abelian groups and let $\varphi$ be an endomorphism of $H$. Must $\varphi$ extend to an endomorphism of $G$? The answer is no; a counterexample is the endomorphism of the subgroup $2\mathbb{Z} \times \mathbb{Z}_2$ of $\mathbb{Z} \times \mathbb{Z}_2$ given by $(2,0) \to (0,1)$ and $(0,1) \to (0,0)$. I am interested in the dual question. Let $G \to H$ be a surjective homomorphism of Abelian groups and let $\varphi$ be an endomorphism of $H$. Must $\varphi$ lift to an endomorphism of $G$? I strongly suspect the answer to be no, but I have not been able to find a counterexample. An easy counterexample like the one above would be ideal, although any would be good. Note that if the map $G \to H$ splits then $\varphi$ must be induced by an endomorphism of $G$ (and similarly in the dual case). The two questions make sense for other objects also, and so if there is anything interesting to be said on this matter in categorical terms then I would be happy to hear it.",['group-theory']
424825,Find all different integer exponents,"Find all different integers that satisfy the following equality: $m(\sin^{n}x + \cos^{n} x- 1) = n(\sin^{m}x + \cos^{m}x - 1), (\forall) x\in\mathbb{R}.$ Case1: $m$ is odd, $n$ is even, then put $x=180^0 => m=n=0 =>$ contradiction. Case2: $m$ and $n$ is odd, then put $x=180^0 => m=n =>$ contradiction. Case3: $m$ and $n$ is even $=> m=2a, n=2b$ there $a$, $b$ is integer. Then put $x=45^0 =>$ $2^{a-b}a(2^{b-1}-1)=b(2^{a-1}-1)$. Put $x=60^0$ then we have $4^{a-b}a(4^b-3^b-1)=b(4^a-3^a-1)$. How can I continue?",['trigonometry']
424828,$\sum_{n=1}^{\infty }\left(\frac{2n+5}{7n+6}\right)^{n\log(n+1)} $ converges or diverges?,"I am trying to determine whether this series converges or diverges: $\sum_{n=1}^{\infty }\left(\frac{2n+5}{7n+6}\right)^{n\log(n+1)}$. Here is my solution: I called: $a_{n}=\left(\frac{2n+5}{7n+6}\right)^{n\log(n+1)}$. Then, I used the root test as follows: $\lim_{n \to \infty  }\left | a_{n} \right |^{\frac{1}{n}}=\lim_{n \to \infty}\left(\frac{2n+5}{7n+6}\right)^{\log(n+1)}$. Then I called $x_{n}=(\frac{2n+5}{7n+6})^{\log(n+1)}$, Instead of computing $\lim_{n \to \infty}x_{n}$, I computed first $$\lim_{n \to \infty}\log(x_{n})=\lim_{n \to \infty}\log(n)\log\left(\frac{2n+5}{7n+6}\right)=\log(\frac{2}{7})\lim_{n \to \infty}\log(n)=-\infty,$$ therefore: $\lim_{n \to \infty}x_{n}=\lim_{n \to \infty}e^{\log(x_{n})}=0$. Therefore: $\lim_{n \to \infty  }\left | a_{n} \right |^{\frac{1}{n}}=0< 1$. So by the root test, the series converges. Can you please let me know whether my solution is correct (especially the last steps) or not? if there is a mistake, please let me know how I should fix it. Also, if you are aware of a better way of solving the problem , please do let me know. Thanks!","['sequences-and-series', 'convergence-divergence', 'calculus', 'real-analysis']"
424841,Algebraic structures whose Hilbert-Poincaré series are special functions,"Are there good examples of algebraic structures whose Hilbert-Poincaré series are that of special functions? I'm particularly interested in cases where complex analytic reasoning about those series sheds light on the algebraic structures in question. Is there a dictionary of algebraic structures whose Hilbert-Poincaré series correspond to special functions? Edit: I've heard of Monstrous Moonshine -- and I'm aware that there is a Mathieu Moonshine, but neither of those gets us outside of the territory of modular forms.","['special-functions', 'reference-request', 'abstract-algebra']"
424852,Is there an integral form of Newton's method?,"Warning : This seems like a silly sort of question, not the kind I'd ask out loud. The contraction mapping theorem is a basic tool for proving existence of, and finding solutions to, equations. Given an algebraic (read: not differential) equation $f(x)=0$ where $f : \mathbb{R} \rightarrow \mathbb{R}$ is sufficiently smooth, often it is possible prove that the mapping
\begin{equation}
\Phi_f(x) = x - \frac{f(x)}{f'(x)}
\end{equation} is a contraction on some complete metric space by restricting $x$ to an interval. This yields existence of a solution to the original equation. This is Newton's method , which has both theoretical and practical significance. Consider the ordinary differential equation $\dot{\mathbf{x}}=\mathbf{v}(\mathbf{x},t)$. The Picard mapping
\begin{equation*}
\Psi(\phi)(t) = \mathbf{x}_0 + \int_0^t \mathbf{v}(\phi(\tau),\tau) \; d\tau
\end{equation*}
is a contraction on a function space, under suitable conditions on $\mathbf{v}$ . This yields an existence result for the given ODE with data $\mathbf{x}_0$. A very similar map appears in the study of certain nonlinear partial differential equations (e.g. Duhamel's principle applied to semilinear equations). Contrasted with the numerical solution of an algebraic equation, the contraction in these cases isn't of much practical use. Clearly the derivative is useful for proving existence of algebraic equations, and similarly for the integral and differential equations. In line with the title, have I missed a theoretical application of the integral to solve algebraic equations or the derivative to solve differential equations? If not, is there a moral reason why we shouldn't expect to find such applications?","['soft-question', 'ordinary-differential-equations', 'partial-differential-equations', 'real-analysis']"
424853,Regular Pentagon is the Unique Largest Two-Distance Set in the Plane,"A two-distance set is a collection of points for which only two distinct distances appear among pairs of points. (That is, the distance between any pair of points is either $x$ or $y$, and these values may be whatever you want.) The unique (up to similarity) largest two-distance set in the plane is the regular pentagon. The result seems to have become folklore, and I cannot find a proof anywhere online. I am primarily interested in the bound of five on the size of the two-distance set, but a proof of uniqueness would be a welcome bonus.","['geometry', 'discrete-geometry']"
424854,$-1 = 0$ by integration by parts of $\tan(x)$,"I had a calculus final yesterday, and in a question we had to find a primitive of $\tan(x)$ in order to solve a differential equation. A friend of mine forgot that such a primitive could easily be found, tried to integrate $\tan(x)$ by parts... and then arrived to the result $0 = -1$. 
The kind of thing you're pretty satisfied to ""prove"", except during an important exam. :-° So afterwards I tried to do the same : $$\begin{align*}
\int \tan(x)dx &= \int \sin(x) \times \frac{1}{\cos(x)}dx \\[0.1in]
&= -\frac{\cos(x)}{\cos(x)} - \int - \frac{\cos(x) \times \sin(x)}{\cos(x)^2}dx \\[0.1in]
&= -1 + \int \tan(x)dx
\end{align*}$$ And therefore we get : $$ \int \tan(x)dx = -1 + \int \tan(x)dx \implies 0 = -1$$ What? The reasoning sounds about right to me.
Could someone explain where something went wrong? Thanks, 
Christophe.","['integration', 'indefinite-integrals', 'fake-proofs']"
424876,Weak topology on an infinite-dimensional normed vector space is not metrizable,"I've been pondering over this problem for a while now, but I can't come up with a proof or even a useful approach... Let $X$ be am infinite-dimensional normed vector space over $\mathbb{K}$ (that is either $\mathbb{R}$ or $\mathbb{C}$).
Then the weak topology $\sigma(X,X^*)$ is not metrizable, i.e. there is no metric $d$ such that the induced topology of $d$ coincides with $\sigma(X,X^*)$. Can anyone help me with this?","['normed-spaces', 'metric-spaces', 'functional-analysis', 'weak-topology']"
424877,Calculus Complicated Substitution Derivative,"When, $$y=6u^3+2u^2+5u-2 \ , \ u= \frac{1}{w^3+2} \ , \ w=\sin x -1 $$find what the derivative of $ \ y \ $equals when $ \ x = \pi \ . $ Tried it many times, still can't seem to get the right answer (81)","['calculus', 'derivatives']"
424884,Possible mistake in exercise in Hartshorne exercise II.2.18b,"I'm trying to solve Exercise II.2.18b in Hartshorne, and I've constructed what appears to be a counterexample to its statement.  Can someone tell me where I've gone wrong? The statement is as follows.  Let $\phi : A \rightarrow B$ be a ring homomorphism, let $X = \text{Spec } A$ and $Y = \text{Spec } B$, and let $f : Y \rightarrow X$ be the induced map.  Then $\phi$ is injective if and only if the map of sheaves $f^{\#} : \mathcal{O}_X \rightarrow f_{\ast} \mathcal{O}_Y$ is injective. My counterexample is as follows.  Let $A = k[x]$ and $B = k[x,y]/(xy)$, and let $\phi : A \hookrightarrow B$ be the obvious injection.  Then I claim that the associated map of sheaves is not injective.  Indeed, let $p = (x) \in \text{Spec } B$ (this is a prime ideal since $B/(x) \cong k[y]$ is a domain) and $q = (x) \in \text{Spec } A$.  Then $f(p) = q$.  But the induced map of stalks $A_q \rightarrow B_p$ is not injective; indeed, $\frac{x}{1} \in A_q$ is nonzero but $\frac{x}{1} \in B_p$ is zero since in $B_p$ we have $\frac{x}{1} = \frac{xy}{y} = 0$.",['algebraic-geometry']
424887,"In a random graph of $n$ vertices, what is the expected value of the number of simple paths?","I am very new to discrete probabilty and was asked this question: In a random graph $G$ on $n$ vertices (any edge can be in the graph with probabilty of $\frac{1}{2}$,) what is the expected value of the number of paths between a vertex $v$ and a vertex $u$? (The answer might be a summation). How do we exactly begin this? I know we have to define $f(u,v) = \text{number of simple paths between v and u}$, and we need to calculate $E[f(u,v)] = \sum_{u,v \in \omega} {f(u,v) \cdot Pr(u,v)}$. But what exactly is $f(u,v)$ here and what is our $\omega$?",['probability']
424892,"(Dummit's AA, 1.5, P3) Are these presentations of the Quarternion group equivalent?","For example, from wiki, we know that $$ \langle i, j \mid i^4 =1, i^2 = j^2, j^{-1}ij = i^{-1} \rangle = Q $$ where $Q$ denotes Quaternion group. And by my own inspection, I speculated that $$ \langle i,j \mid i^4 = j^4 = 1, ij = j^3i \rangle =Q $$ though I'm not really sure if it is correct. I've checked every relation that hold in $Q$ can be derived from the relations in the presentations. But finding the order of the groups generated by the above presentations, I couldn't do it rigorously nor systematically. (I've considered every element that can be formed by the generators in the form $i^a j^b$ with $0 \leq a, b \leq 3$ and relations in the second presentation and for everything I've checked which is equal to which. And for all the elements in that form, to prove which is not equal to which, I've supposed which is equal to which and derived a contradiction. But personally I think my method is just a mess.) Is there any effective, systematic way for proving this without checking everything? And please correct me if there is anything wrong.",['abstract-algebra']
424911,"Find closed form for $1, 2, 2, 3, 4, 4, 5, 6, 6, 7, 8, 8, 9, 10, 10, \ldots$","Is there any closed form for the following? $$1, 2, 2, 3, 4, 4, 5, 6, 6, 7, 8, 8, 9, 10, 10, \ldots$$ I tried to find one, but I failed. I saw solution on Wolfram Alpha , but I didn't understand it: Generating function: $$\mathcal G_n(a_n)(z)=\dfrac{z+1}{(z-1)^2(z^2+z+1)}$$ What does that function mean, and how does it give me the solution to my question?","['closed-form', 'sequences-and-series']"
424914,Lebesgue measure of a graph of continuous function is equal to $0$,"May somebody show me the proof of the theorem:
Lebesgue measure of a graph of continuous function is equal to $0$.
I will be really grateful.","['measure-theory', 'real-analysis']"
424922,"How do I compute ""AUC"" Area under the curve number, if all I have are my TPR and FPR values?","I am trying to rank my neural network, which is trained for binary classification.  That is, given a set of input signals, it outputs either a 1 or a 0. I have a training set, where I have the actual desired outcomes (of 1 or 0). After I train my network, I check the output to the input.  From this, I can easily see how many true positives (TP), false positives (FP), true negatives (TN) and false negatives (FN) I have. From the TP, FP, TN, FN, I can compute the TPR and the FPR (true and false positive rates). But I do not know how to compute the AUC score from this data. I would appreciate any help Thanks
Lyle","['statistics', 'neural-networks', 'signal-processing']"
424951,How to solve $a \frac{d^2 y}{d x}+b \frac{d y}{d x} = f(y)$?,"Let $a,b$ be real numbers and $y$ is a function of $x$.
$f$ is a given function. How to solve the ODE : $a \dfrac{d^2 y}{d x}+b \dfrac{d y}{d x} = f(y)$ ? Can it be done in closed form ?","['closed-form', 'ordinary-differential-equations']"
424955,On the vector spaces of Taylor Series and Fourier Series,"Taylor series expansion of function, $f$, is a vector in the vector space with basis: $\{(x-a)^0, (x-a)^1, (x-a)^3, \ldots, (x-a)^n, \ldots\}$. This vector space has a countably infinite dimension. When $f$ is expressed as linear combination of the basis vector the scalar multiple for the $n$-th basis vector is $\operatorname{Diff}_n{f}(a)/n!$ Fourier series expansion of function, $f$, is a vector in the vector space with basis: $\{\sin(1x), \cos(1x), \sin(2x), \cos(2x), \ldots, \sin(nx), \cos(nx), \ldots\}$. This vector space has a countably infinite dimension. When $f$ is expressed as linear combination of the basis vector the scalar multiple for the $n$-th basis vectors are $\operatorname{Int}\{f\cdot\sin(nx)\}$ and $\operatorname{Int}\{f\cdot\cos(nx)\}$. Questions: The vector space for the Fourier series has an inner product, $\operatorname{Int}\{f\cdot g\}$, and it's this inner product that provides the above expressions like $\operatorname{Int}\{f\cdot\sin(nx)\}$ and $\operatorname{Int}\{f\cdot\cos(nx)\}$. Is there a similar inner product based derivation of the scalar multiples for the vector space of spanned by the polynomial basis in Taylor series? What is the relationship, if any, between the vector space produced by Taylor Series and that of Fourier Series? E.g. is one a subspace of the other? When Fourier series is taught, why isn't Taylor Series re-explained in the vector space framework used for Fourier series? And would this approach not lead the discussion of the implication of the choice of basis (and perhaps the choice of inner product) for function spaces? Just as Fourier series get generalized to Fourier Transform (the summation of the series becomes an integral), is there something equivalent to Taylor series? Are there any recommended resources (books, courses, etc.) available which can help clarify my thinking regarding these issues?","['vector-spaces', 'fourier-series', 'fourier-analysis', 'functional-analysis', 'taylor-expansion']"
424958,Bounds for multi-dimensional Kloosterman Sums,"I'm looking for a general bound (in terms of $p$) for the Kloosterman sum, working in $\mathbb{F}_{p}$, $$\sum\limits_{x_{1} \dots \ x_{n} = a} \psi(x_{1} + \dots + x_{n})$$ for $\psi$ a nontrivial additive character. These are well studied, and I've found papers that discuss them which give bounds, but unfortunately I can't seem to find a single agreed upon answer and indeed in what I've found there appears to be contradictory information. Does someone know what the ""correct"" bound is, and/or know of a good source?","['characters', 'number-theory']"
424971,(1)Questions about differentiable functions,"1)The functions $f$ and $g$: $\mathbb{R} \rightarrow \mathbb{R} $ shall be 3-times differentiable. Calculate $(f \cdot g)^{(3)}$. 1) $(f \cdot g)'=(f'g+fg')$ $(f'g+fg')'= (f''g+f'g')+(f'g'+fg'')= f''g+2f'g'+fg''$ $(f''g+2f'g'+fg'')'=(f'''g+f''g')+2(f''g'+f'g'')+(f'g''+fg''')$ $=f'''g+3(f''g'+f'g'')+fg'''=(f \cdot g)^{(3)}$ 2)Find a function f:$\mathbb{R} \rightarrow \mathbb{R} $, which is 2-times differentiable on $\mathbb{R}$ 2)$f(x)=x^2$ $f'(x)=2x$ and $f''(x)=2$ Are my solutions correct or did I sth. wrong?",['analysis']
424975,Subset of Cantor set that isn't compact,"How to prove that the Cantor set has a subset that is not compact? Actually, I want to prove that every infinite set $X\subset\mathbb{R}^n$ has a subset $Y$ that is not compact. If $X$ isn't bounded, then $X$ has a unbounded subset $Y$ that is not compact. If $X$ is bounded and includes some ball, then $X$ includes a open ball $Y$ that is not compact. But if $X$ is bounded and includes no ball, like the Cantor set, I don't know. I think can be easier start by Cantor set, but I'm not sure. Can you help me? Thanks.","['real-analysis', 'analysis']"
424990,Weakly closed implies sequentially closed,"Another problem involving the weak topology: Let $X$ be a normed space and $A \subset X$ weakly closed. Then $A$ is sequentially closed, that is: If $(x_n) \subset A$ and $x_n \xrightarrow{w}x$, then $x \in A$. I know this characterisation is also used as definition of weakly closed. So I guess it should be easy to prove. Yet I have trouble doing so. ;( I tried proving it directly and towards a contradiction without success. I'm afraid my problem is a lack of understanding of weak closedness. I know how weakly open sets are generated, but this doesn't give me a concrete representation them, or of a weakly closed subset. However, I know that $A$ is also closed with respect to the norm of $X$. Weak convergence of $(x_n)$ to $x$ means $f(x_n) \rightarrow f(x)$ for every $f \in X^*$. But it doesn't give me any statement related to the norm convergence of $(x_n)$, at least not that I know of. So the norm-closedness of $A$ doesn't really help. I could also find out that norm closedness is not sufficient for closedness with respect to weak convergence - I think convexivity has to be added to make the implication valid, is that correct? So of course I have to fail if I weak convergence with norm convergence alone. I've tried to work with balls around $f(x)$, too (for a contradiction). But again, the continuousness of $f$ only gives me control over $|f(x_n)-f(x)|$ if I have some bound for $||x_n-x||$. And I want it the other way around. I have a feeling that this way is wrong because it would need some implication between weak and norm convergence that I know isn't there... It makes me mad that the proof should be rather simple, yet I'm not able to do it. Some hint please!? :(","['general-topology', 'normed-spaces', 'weak-convergence', 'functional-analysis']"
424991,"Can I derive $i^2 \neq 1$ from a presentation $\langle i, j \mid i^4 = j^4 = 1, ij = j^3 i\rangle$ of Quaternion group $Q$?","(This question is related to the previous post I've posted few hours ago: (Dummit's AA, 1.5, P3) Are these presentations of the Quarternion group equivalent? ) I was trying to prove that the presentation
$$\langle i, j \mid i^4 = j^4 = 1, ij = j^3 i\rangle
$$ generates Quaternion group. The only thing that I couldn't derive was that $i^2 \neq 1$. I tried to derive a contradiction from the supposition $i^2 =1$ but this didn't give me a contradiction (at least not yet) but rather it brought me to an Abelian group that consists of 4 elements with every element other than 1 having order 2. I'm not sure where I'm wrong. Does indeed the above presentation generate an Abelian group with its order 4? (I think this can't happen according to the previous post!!) Or $i^2 = 1$ is a indeed contradictory? If the latter is the case, would you please show me the derivation?",['abstract-algebra']
424995,What is the average weight of a minimal spanning tree of $n$ randomly selected points in the unit cube?,"Suppose we pick $n$ random points in the unit cube in $\mathbb{R}_3$, $p_1=\left(x_1,y_1,z_1\right),$ $p_2=\left(x_2,y_2,z_2\right),$ etc. (So, $x_i,y_i,z_i$ are $3n$ uniformly distributed random variables between $0$ and $1$.) Let $\Gamma$ be a complete graph on these $n$ points, and weight each edge $\{p_i,p_j\}$ by $$w_{ij}=\sqrt{\left(x_i-x_j\right)^2+\left(y_i-y_j\right)^2+\left(z_i-z_j\right)^2}.$$ Question: What is the expected value of the total weight of a minimal spanning tree of $\Gamma$? (Note: Here total weight means the sum of all edges in the minimal spanning tree.) A peripheral request: The answer is probably a function of $n$, but I don't have the computing power or a good implementation of Kruskall's algorithm to suggest what this should look like.  If someone could run a simulation to generate this average over many $n$, it might help towards a solution to see this data.","['trees', 'random-graphs', 'graph-theory', 'computational-mathematics', 'probability']"
425007,Union of connected subsets is connected if intersection is nonempty,"Let $\mathscr{F}$ be a collection of connected subsets of a metric space $M$ such that $\bigcap\mathscr{F}\ne\emptyset$. Prove that $\bigcup\mathscr{F}$ is connected. If $\bigcup\mathscr{F}$ is not connected, then it can be partitioned into two disjoint, non-empty subsets $A,B$. Let $x$ be a point in $\bigcap\mathscr{F}$. Then either $x\in A$ or $x\in B$. I don't know where to go from here.","['general-topology', 'connectedness']"
425008,"Tensor Product is associative, distributive, not commutative.","Tensor Product is associative, distributive, not commutative. Here is my attempt to show tensor product is associative, is it legit? If $T$ is a $p$-tensor and $S$ a $q$ tensor, then $T \otimes S$ is a $p+q$ tensor:
$$T \otimes S(v_1, \ldots, v_p, v_{p+1}, \ldots, v_{p+q}) = T(v_1, \ldots, v_p) \cdot S(v_{p+1}, \ldots, v_{p+q}).$$
Now consider a third tensor, a $r$-tensor $U$. Then 
\begin{eqnarray*}
& & (T \otimes S ) \otimes U (v_1, \ldots, v_p, v_{p+1}, \ldots, v_{p+q}, v_{p+q+1}, \ldots, v_{p+q+r})\\
&= &(T \otimes S (v_1, \ldots, v_{p+q})) \cdot U(v_{p+q+1}, \ldots, v_{p+q+r})\\
&= &T (v_1, \ldots, v_{p}) \cdot S(v_{p+1}, \ldots, v_{p+q}) \cdot U(v_{p+q+1}, \ldots, v_{p+q+r})\\
&= &T (v_1, \ldots, v_{p}) \cdot (S(v_{p+1}, \ldots, v_{p+q}) \cdot U(v_{p+q+1}, \ldots, v_{p+q+r}))\\
&= &T (v_1, \ldots, v_{p}) \cdot (S \otimes U (v_{p+1}, \ldots, v_{p+q+r}))\\
&= &T \otimes (S \otimes U)(v_1, \ldots, v_{p+q+r}).
\end{eqnarray*} Distributivity - is this proof legit? First note that tensor product distribute over addition. If $T$ is a $p$-tensor and $S, U$ a $q$ tensor. Then I need to show that
$$ T \otimes (S + U) = (T \otimes U) + (S \otimes U).$$ Then
\begin{eqnarray*}
&&T \otimes (S + U)(v_1, \ldots, v_p, v_{p+1}, \ldots, v_{p+q})\\
& =& T (v_1, \ldots, v_p) \cdot (S + U)(v_{p+1}, \ldots, v_{p+q})\\
& =& T (v_1, \ldots, v_p) \cdot (S (v_{p+1}, \ldots, v_{p+q}) + U(v_{p+1}, \ldots, v_{p+q}))\\
& =& T (v_1, \ldots, v_p) \cdot S (v_{p+1}, \ldots, v_{p+q}) +  T(v_1, \ldots, v_p) \cdot U(v_{p+1}, \ldots, v_{p+q})\\
& =& (T \otimes S) + (T \otimes U)
\end{eqnarray*} It is not commutative - is this legit? \begin{eqnarray*}
& & T \otimes S(v_1, \ldots, v_p, v_{p+1}, \ldots, v_{p+q})
 = T(v_1, \ldots, v_p) \cdot S(v_{p+1}, \ldots, v_{p+q})\\
&= &S(v_{p+1}, \ldots, v_{p+q}) \cdot T(v_1, \ldots, v_p) = S \otimes T(v_{p+1}, \ldots, v_{p+q}, v_{1}, \ldots, v_{p})\\
& \neq & S \otimes T(v_1, \ldots, v_p, v_{p+1}, \ldots, v_{p+q}).
\end{eqnarray*}","['tensor-products', 'linear-algebra']"
425033,"Show that any continuous $f:[0,1] \rightarrow [0,1]$ has a fixed point $\zeta$","Be a continuous function $f:[0,1] \rightarrow [0,1]$. Show that there is a $\zeta \in [0,1]$ with $f(\zeta)=\zeta$ ($\zeta$ is called fixed point). Consider the function $g:[0,1] \rightarrow [-1,1]$, $g(x):= f(x)-x$. $g$ is continuous. Because of $f(0),f(1) \in [0,1]$ is $g(0)\geq0$ and $g(1)\leq 0$. Because $f(0)$ has a value between $0$ and $1$, $f(0)\geq 0$. $g(0) = f(0)-0= f(0) \geq 0 - 0 = 0$. Because $f(1)$ has a value between $0$ and $1$, $ f(1) \leq 1 $. $g(1)=f(1)-1 \leq 1 - 1 = 0$ $\Leftrightarrow g(0)\geq 0$ and $g(1)\leq 0 $ After the IVT: $\exists \zeta \in [0,1]:g(\zeta)=0 \Leftrightarrow f(\zeta) = \zeta $ $\zeta$ is a fixed point of $f$. $\Box$ My questions are: Is this proof done in the correct way or have I missed something? Is there something I can improve?","['real-analysis', 'analysis']"
425036,Linear independence of $\cos(n\theta)$,"I was trying to see if the cosines of the (certain) integer multiples of a certain angle were linearly independent over $\mathbf{Q}$. In particular I was looking at when $\theta = \frac{2\pi}{p(p+1)}$ and when the numbers are $\cos((kp+k-p)\theta)$ where $k = 0,\ldots, p-1$ for prime $p$. I was looking at small cases, like when $p = 5$, but even then I wasn't able to come up with an efficient method to test whether or not they are linearly independent over the rationals.","['linear-algebra', 'number-theory']"
425059,How do I evaluate the limit $\large\lim_{x\to \infty }\frac{\ln(x)^{\ln(x)^{\ln(x)}}}{x^x}$?,"$$\large\lim_{x\to \infty }\frac{\ln(x)^{\ln(x)^{\ln(x)}}}{x^x}$$ As $x$ approaches infinity, both functions approach infinity. Therefore I should use the hopital rule, right? But it seems to complicate the answer.",['calculus']
425062,Can the semidirect product of two groups be abelian group?,"while I was working through the examples of semidirect products of Dummit and Foote, I thought that it's possible to show that any semdirect product of two groups can't be abelian if the this semidirect product is not the direct product. Here is my simple idea: Suppose $H,K$ are two groups and $H\rtimes K$ be the semidirect product of $H$ and $K$. Let $f:K \rightarrow Aut(H)$ be our homomorphism from $K$ into $Aut(H)$, now we know that $H \unlhd H\rtimes K$ but not necessarily $K$. If $H\rtimes K$  is abelian, then every subgroup of it is normal, so $K$ must be normal but if $K$ is normal then $f$ is the trivial homomorphism and so the semidirect product turns into the direct product, so the semdidirect product in this case is the direct product, which is a contradiction since we supposed that this semidirect product of $H,K$ is not their direct product. Is this true? Or have I made a mistake and there exists a counterexample?","['finite-groups', 'group-theory', 'abstract-algebra', 'abelian-groups']"
425071,Characterizing continuous exponential functions for a topological field,"Given a topological field $K$ that admits a non-trivial continuous exponential function $E$, must every non-trivial continuous exponential function $E'$ on $K$ be of the form $E'(x)=E(r\sigma (x))$ for some $r \in K$* and $\sigma \in Aut(K/\mathbb{Q})$? If not, for which fields other than $\mathbb{R}$ is this condition met? Thanks to Zev","['general-topology', 'exponentiation', 'field-theory']"
425084,"Generalization of $f: [0,1] \to [0, 1]$ has a fixed point?","If $f: [0,1] \to [0,1]$ is a continuous map, there exists $x \in [0, 1]$ such that $f(x) = x$.  This can be proven by applying IVT to $f(x) - x$.  Does this fact generalize to continuous maps $f: X \to X$ where $X$ is a compact topological space?","['general-topology', 'real-analysis']"
425092,"Prove that $\exp(x)=3x$ has at least one solution for $x\in [0,1]$","Prove that $\exp(x)=3x$ has at least one solution $x \in [0,1]$. $$e^x=3x$$ $$\Leftrightarrow e^x-3x=0$$ Let $$f(x) = e^x - 3x$$
$$f(0)=e^0 - 3 \cdot 0 = 1 > 0$$
$$f(1)= e^1-3 \cdot 1 = e - 3 < 0$$
Thus, since $f(1) < 0 < f(0) $, by the IVT: 
$$\exists \zeta \in [0,1]\text{ such that }f(\zeta)=0 \Leftrightarrow e^\zeta = 3\zeta$$
$\Box$ Is that correct? Is there something I can improve?","['real-analysis', 'analysis']"
425098,"Prove ""casting out nines"" of an integer is equivalent to that integer modulo 9","Let $s(x)$ be an abstraction for casting out nines of integer $x$. For all integers $x$, prove $s(x) \equiv x$ mod $9$ I'm not asking for an answer more of a way to attack this problem. Can't think of where to start","['modular-arithmetic', 'elementary-number-theory', 'discrete-mathematics']"
425101,Simple yet tricky trigonometry,"This might seem silly to ask, but how can I solve a trigonometry problem for the unknown $h$ in the form of: 
$x + 45 = h/\tan 30$ and 
$x = h/\tan 50$",['trigonometry']
425106,Range of $f(x) = \sin(\cos x)$,"Problem : Finding the maximum and minimum value of the function : $f(x) = \sin(\cos x)$ My approach : 
We know that if $f'(x) > 0 $ function attain maximum value by putting $f'(x) = 0$ and taking the second derivative test ie. $f''(x) >0$ then function is minimum and if $f''(x) <0$ function is maximum this can be obtained by putting the value of $x$ (derived from $f'(x) =0$) Now the given function is : $f(x) = \sin(\cos x)$ $f'(x) = -\sin x \cos(\cos x) $ How can we do this with the help of calculus?","['trigonometry', 'calculus', 'derivatives']"
425130,How find this arithmetic sequence of $n$,"if there exist positive integer sequence $a_{1},a_{2},a_{3},\cdots,a_{n}$,such  that
$$a_{1}a_{2},a_{2}a_{3},a_{3}a_{4},\cdots,a_{n-1}a_{n},a_{n}a_{1}$$ is arithmetic sequence,and the common difference $d=a_{i+1}a_{i+2}-a_{i}a_{i+1}\neq 0,i=1,\cdots,n-1.a_{n+1}=a_{1}$ find the value  $n$ I Think this problem is very nice,Thank you everyone. my idea: first, we have $n\ge 3$,and when $n=3$,then 
$$2a_{2}a_{3}=a_{1}a_{2}+a_{3}a_{1}$$
$$\Longrightarrow \dfrac{2}{a_{1}}=\dfrac{1}{a_{2}}+\dfrac{1}{a_{3}}$$ and
$$\dfrac{2}{5}=\dfrac{1}{3}+\dfrac{1}{15}$$ and when $n=4,5,\cdots,$? \
\ I think $n=2k-1$ is true,but I can't prove it",['sequences-and-series']
425138,Computing the Gaussian integral with step functions,"Say, we are interested in deriving $$\int_{-\infty}^{\infty}e^{-x^2}=\sqrt{\pi}\tag{1}$$ There are many well known ways to do it , for example: by polar coordinates via the gamma function, etc. After coming across this limit
$$\lim\limits_{n\to\infty} \frac{\sqrt{\pi n}}{2^{2n}}  \binom {2n} {n+\lfloor x\sqrt{n} \rfloor} = e^{-x^2}\tag{2}$$
I wonder how can we derive $(1)$ by using $(2)$ as an approximation via step functions. Here is a picture of $n=4$:","['normal-distribution', 'improper-integrals', 'integration', 'limits']"
425139,Find the axis and angle of a sphere rotation.,"A sphere is rotated a certain angle about some axis. Given two distinct points in a sphere, mark their original positions as $A$ and $B$, their positions after the rotation as $A'$ and $B'$. Using these four points, is it possible to figure out using only the ruler and compass the axis and angle in which the sphere is rotated? By ruler and compass in 3-dimensional space, I mean as usual you can only connect two specified points with a straight line or draw a circle by specifying a point as center and two points in the perimeter. The center of the sphere is given, (or not since you can figure it out yourself.)",['geometry']
425152,"How can I find a villain's hideout given a set of previous locations? (Or, how can I identify the centeroid of a cluster of datapoints?)","Imagine this... Batman has just retrieved a tracking device he placed on The Joker 150 days ago.  The good news is that it has 150 coordinates — one from each day.  The bad news is that all the data is randomly sorted — there's no way to tell when the coordinates were recorded, nor their sequence. Further, all the data was collected at random times during the day so we can't even be sure any of the points were actually taken at the hideout — it might very well be in between some of them.  How can we help Batman find the secret hideout? Here's a map of the dataset: http://batchgeo.com/map/c3676fe29985f00e1605cd4f86920179 Here's a pastebin of raw 150 geocodes: http://pastebin.com/grVsbgL9 In math terms, I'm looking for help identifying the centroid of a complex cluster of data. As you'll notice in this data set, there are several clusters (San Francisco, LA, Chicago and NYC) along with lots of noise throughout the rest.  I need to determine which cluster is primary, and identify the centroid of this cluster. Can you recommend a strategy?  Preferably one with some meat I can use to begin analyzing the data for the ""secret hideout""? ;)","['statistics', 'clustering', 'algorithms']"
425176,Real points of a complex curve,"Since the ""real points"" of a complex curve can mean a couple of different things, bear with me while I'm annoyingly formal here. Consider first a cubic curve $y^2 = x^3 + a x + b$.  Write $$S := \{ [x:y:z] \in \mathbb{C}P^2 \; | \; y^2 z = x^3 + a x z^2 + b z^3 \}$$ and $$C := \{ [x:y:z] \; | \; x, y, z \in \mathbb{R} \text{ and } [x:y:z] \in S \}.$$ For generic values of $a$ and $b$, we can regard $S$ and a real 2-manifold and $C$ as a one-dimensional submanifold of $C$.  Thus in particular $C$ determines an element of $H_1(S, \mathbb{Z})$.  Which element, and is there a nice way to see this? Follow-up question: What's the situation for an arbitrary smooth projective curve? Second follow-up question: What's the situation for an arbitrary complex projective hypersurface?  For an arbitrary complex projective variety? (Feel free to assume all these varieties are defined over $\mathbb{R}$ if it helps.)","['algebraic-geometry', 'complex-analysis']"
425188,Calculate the probability of two teams have been drawns,"If we know that team A had a $39\%$ chance of winning and team B $43\%$ chance of winning, how we can calculate the probability of the teams drawn? My textbook mention the answer but I cannot understand the logic behind it. The answer is $18\%$. As working is not shown I guess that this is how the find $18\%$ probability of two teams withdrawn: $$ (100\% - 39\%) - 43\% = 18\%$$ But I cannot understand the logic behind it. I appreciate if someone can explain it to me.",['statistics']
425189,"If I put $M$ balls into $N$ boxes at random, what is the average number of balls in the boxes that are not empty?","I have a very brief question: if I put $M$ balls into $N$ boxes at random, what is the average number of balls in the boxes that are not empty?","['average', 'combinatorics']"
425226,Finding the fallacy in this broken proof,"Today, a friend gave me a ""proof"" of $1=2$ and challenged me to find the fallacy. $1 = 1$ $1 = 1 + 0 + 0 + 0 ...$ $1 = 1 + 1 - 1 + 1 - 1 + 1 - 1 ...$ $1 = 2 - 1 + 1 - 1 + 1 - 1 ...$ $1 = 2 + 0 + 0 ...$ $1 = 2$ My answer was that once you turn the initial $1 + 1$ into a 2, everything is offset so a $-1$ is always left at the end no matter how many times it is repeated. This negative one balances out the $2$ at the beginning so $1=1$ still holds true. I.e. $$1 = 1 + 0 + 0 + 0 ... = 1 + (1 - 1) + (1 - 1) + (1 - 1) = 2 + (-1 + 1) + (-1 + 1) - 1$$ However, my friend claimed that my answer only applies if the $+ 1 - 1$ repeats for a finite number of times. He argues that because the sequence repeats infinitely and things work differently when working with infinity, my answer is not valid. Can anyone enlighten me to the true fallacy in this proof?","['divergent-series', 'sequences-and-series', 'fake-proofs']"
425256,On Applications of the Murnaghan-Nakayama rule,"The question is located below. In short, I am looking for an accessible explanation of the Murnaghan-Nakayama rule in relation to the following problem . Pardon the long setup. Let $Y$ be a standard Young tableau of shape $\lambda=(\lambda_1,\lambda_2,\ldots,\lambda_n)$. At the risk of being pedantic, standard here means $\lambda_1\geq\lambda_2\geq\ldots\lambda_n$ and the entries are strictly increasing rightward along rows and downard along columns (with each number occuring only once). Let $f_\lambda$ denote the number of standard Young tableau of shape $\lambda$. It is well known that $f_\lambda$ can be calculated via the Hook formula: $$f_\lambda=\frac{|\lambda|!}{\prod_{i,j}h(i,j)}.$$ Now suppose I remove some boxes on the outer edge of the tableau (i'll call this a pattern from now on), giving a shape $\delta_i$ (I'll explain the $i$ in a moment). Here's an example: let $\lambda$ be the triangular tableau $(n-1,n-2,\ldots,1)$. Now I want to remove three adjacent boxes in an ""L"" shape: Here I've indexed the location of the left box as $i$ which gives the $x$ coordinate of the box ($i=3$ in this example). Again, I'm calling the new tableau of shape $\delta_i$, and one easily finds $f_{\delta_i}/f_\lambda$ as the ratio of the particular hooks that change. I'm interested in the following. In the above example, I removed three adjacent boxes at location $i$. I want to evaluate sums of the form: $$\sum_{i=1}^{n-2}\frac{f_{\delta_i}}{f_\lambda}$$. In full generality, I am interested in removing any pattern of boxes indexed by $i$ (the sum's range changes appropriately depending on the pattern). Going along with my example, one can show that $$f_{\delta_i}/f_\lambda=\frac{1}{3N(N-1)(N-2)}a_ia_{n-i-1},$$ where $N:=\binom{n}{2}$ and $a_i:=\frac{(2i+1)!!}{(2i-2)!!}$. One can then evaluate the sum using relatively straightforward generating functions for $a_i$, giving a tidy answer of $1/N$. Question: I have heard that calculating $\sum_{i=1}^{n-2}\frac{f_{\delta_i}}{f_\lambda}$ can be done via the Murnaghan-Nakayama rule. In particular, I've been told my $L$ example gives $-\frac{\chi^{\lambda}(\pi)}{\chi^\lambda(\mbox{id})}$ where $\pi$ is a 3-cycle. Can someone provide an accessible reference for this rule in the context above? I am not an expert in representation theory and the usual references I've seen ( Enumerative Combinatorics, Vol II by Stanley) are somewhat beyond me at the moment (and in much greater generality). In short, I am looking for an accessible explanation of the Murnaghan-Nakayama rule.","['representation-theory', 'characters', 'integer-partitions', 'symmetric-groups', 'combinatorics']"
425270,A generalization of abelian categories including Grp,"The category of groups shares various properties with abelian categories. For example, the Five lemma and Nine lemma hold in Grp . Is there a weakened notion of abelian category which also includes Grp such that the 5- and 9- lemmas are still provable by arrow chasing?","['homological-algebra', 'category-theory', 'group-theory', 'abelian-categories']"
425276,Evaluating the derivative of a Cantor-Vitali function,"Let $\varphi \colon [0,1] \to \mathbb R$ a ""Cantor-Vitali function"", viz. take $x \in [0,1)$ and write it as
$$
x = \sum_{j=1}^{\infty} \frac{a_j}{3^j}, \quad a_j \in \{0,1,2\}
$$
with $a_j$ non definitely equal to 2. Then 
$$
\varphi (x) := \begin{cases}
\sum_{j=1}^{k-1}\frac{a_j}{2^{j+1}} & a_k=1 \text{ and } a_j \ne 1 \quad \forall j \in \{1,2, \ldots , k-1\} \\
\sum_{j=1}^{\infty}\frac{a_j}{2^{j+1}} & a_j \ne 1\quad \forall j \in \mathbb N 
\end{cases}
$$
Moreover, put $\varphi(1):=1$. Question . Evaluate $\varphi^{\prime}(x)$ for every $x \in [0,1]$. Well, I think it is not difficult to prove the existence (at least a.e.) of $\varphi^{\prime}$, since the function should be monotone (increasing?), hence differentiable a.e. by Lebesgue's theorem. The problem is that I cannot understand how to calculate $\varphi^{\prime}(x)$. Is it zero a.e.? How to prove this? How can I do? Thanks in advance.","['derivatives', 'real-analysis']"
425282,"Find the weak derivative of $u(x)=\begin{cases}|x|, & \text{if}\,\,\, x<1 \\ 1-x^2, & \text{if}\,\,\, x\ge1 \end{cases}$","Find a weak derivative of the function $u:(-1;2)\rightarrow \mathbb{R}$ defined as follows:
$$u(x)=\begin{cases}|x|, & \text{if}\,\,\, x<1 \\ 1-x^2, & \text{if}\,\,\, x\ge1 \end{cases}$$ I know that a weak derivative of $|x|$ is equal to $2\chi_{(0,1)}(x)-1$ and a weak derivative of $1-x^2$ is equal to $-2x$. Should I simply combine them? Can a weak derivative be not continous? Thanks in advance.","['sobolev-spaces', 'weak-derivatives', 'analysis']"
425303,Unprovability of $i^2 =1$ from $\langle i \mid i^4 =1\rangle$ and similar problems,"This question is related to Can I derive $i^2 \neq 1$ from a presentation $\langle i, j \mid i^4 = j^4 = 1, ij = j^3 i\rangle$ of Quaternion group $Q$? I know I'm going too far but let me just ask... 1) Is indeed $\langle i \mid i^4 =1\rangle$ a presentation for the cyclic group of order 4? 2) If so, then do we just assume that $i^2 =1$ or should we prove that $i^2 =1$ cannot be derived from $i^4 =1$, i.e., the unprovability of $i^2 =1$ from $i^4=1$? For the below questions I need answers only if the latter is the case in the above question 2. 3) Then how do we rigorously prove the unprovability? 4) As for 
$$\langle i, j \mid i^4 = j^4 = 1, ij = j^3 i\rangle = Q
$$
(Quaternion group), how do I prove unprovability of $i^2 =1$ from the given presentation? Or how do I even guess that $i^2 \neq 1$?","['group-presentation', 'group-theory', 'abstract-algebra']"
425306,Guess the birthday,"I've come across the following little quiz game problem, which I've failed to solve. Say we have $15$ people, each of them of different age, and you want to guess their actual birthday - not just their age. You are allowed to guess as many times as you want, but the guessing goes as follows: Choose $5$ random people from the group. Each of them gives you four distinct possible dates, which they have chosen before the quiz started (so they will not change their options later in the game). One of these is correct. When you have guessed on the date for all five, they will tell you how many correct guesses, you had. They will not tell you which guesses were correct. Now the questions are: What is the probability to guess one specific person's birthday in the first try? How many times would you expect, you have to guess to get one person's birthday right? How many times would you expect, you have to guess to get all $15$ people's birthday right? What is the probability to get one person's birthday right in less than $200$ guesses? What is the probability to get all the people's birthday right in less than $3000$ guesses? The first question was rather easy to answer. When you pick randomly, you have to pick the person, whose birthday you would like to know, the probability of this is $\dfrac{1}{3}$, since we pick $\dfrac{1}{3}$ of the people in the group. To know one person's birthday for sure in the first try, you will have to answer his question correct. But as you will not know which question, you answered correct, when you ask, unless you answered all of them correct, you will have to answer correct, which has the probability $\left(\dfrac{1}{4}\right)^5 = \dfrac{1}{1024}$.
So the answer to the first question is $\dfrac{1}{3072}$. To solve the next questions, I've tried to assume that we only have $5$ people, and that they are always chosen. This gives me a strategy to find one specific person's birthday, since I can just alter my answers to his question, and after maximum four guesses, I've guessed his birthday.
Unfortunately, I cannot be sure that he will come up every time, I ask. Actually, I cannot be sure that he will ever come up, but I ""only"" have to find the expected amount of guesses. And this is where I got stuck. Any help in tackle this question will be so much appreciated! Hints or even solutions, anything.
Thank you very much in advance!","['probability', 'combinatorics']"
425321,Proof of Galois' theorem that there exists a field of $p^n$ elements.,"From Galois Theory (Rotman): For every prime p and every positive integer n, there exists a field having exactly $p^n$ elements. Proof. If there were a field K with $|K| = p^n = q$ , then $K^* = K - \{0\}$ would be a multiplicative group of order q-1; by Lagrange's theorem $a^{q-1}=1$ for all $a \in K^*$ . It follows that every element of K would be a root of the polynomial $$g(x)=x^q - x.$$ We now begin the construction. By Kronecker's theorem, there is a field E containing $\Bbb{Z}_p$ over which g(x) splits. Define $F = \{\alpha \in E: g(\alpha)=0\}$ ; that is, F is the set of all the roots of g(x). Since the derivative $g'(x)=qx^{q-1} - 1 = -1$ (because $q=p^n$ and E has characteristic p), Lemma 32 shows that the gcd (g,g')=1, and so g(x) has no repeated roots; that is, $|F|=q=p^n$ . We claim that F is a field, which will complete the proof... I am a bit confused with this proof, because in order to show that F is a field with exactly $p^n$ elements, we are assuming that there exists a field K of order $p^n$ . But isn't that what we are supposed to prove in the first place? In other words, how can we assume that there exists a field K of order $p^n$ for every p and n? And if we are allowed to assume that, then isn't the proof already complete?","['galois-theory', 'finite-fields', 'extension-field', 'abstract-algebra']"
425323,Why do we use 'this' Gamma Function. [duplicate],"This question already has answers here : Why is Euler's Gamma function the ""best"" extension of the factorial function to the reals? (7 answers) Closed 11 years ago . The Gamma function is a generalization of the factorial defined by Euler as:
$$\Gamma(z)=\int\limits_{0}^{\infty}t^{z-1}e^{-t}\,dt$$
for $z\in\mathbb{C}$ with positive real part. It satisfies, $\Gamma(n)=(n-1)!$ for all $n\in\mathbb{N}$. My question is why we choose this particular function from all the functions that satisfy the previous property. And, how is the Gamma function deduced?","['gamma-function', 'real-analysis']"
425324,How can I approximate $\sum\limits_{k=4}^{\infty}\Pr(X=k)[{\Pr(X\le k)}^6 - {\Pr(X\le k-4)}^6]$ for $\lambda \to +\infty$?,"$X$ is a Poisson random variable and the probability mass function is given by:
$$\Pr(X = k) = e^{-\lambda}\frac{{\lambda}^k}{k!}$$ I’ve got a probability function $f(\lambda)$
$$f(\lambda) = \sum\limits_{k=4}^{\infty}\Pr(X=k)[{\Pr(X\le k)}^6 - {\Pr(X\le k-4)}^6]$$ To date, I only find that ${\Pr(X\le k)}^6 - {\Pr(X\le k-4)}^6$ can be factorized as 
\begin{align*}
&{\Pr(X\le k)}^6 - {\Pr(X\le k-4)}^6 \\&= [\Pr(X=k)+ \Pr(X=k-1) + \Pr(X=k-2) + \Pr(X=k-3)]\cdot[ {\Pr(X\le k)}^5+{\Pr(X\le k)}^4{\Pr(X\le k-4)}+…+ {\Pr(X\le k-4)}^5]
\end{align*}
But I have no idea what to do next… Can I assume that $\Pr(X=k) \approx \Pr(X=k-1)$ if $\lambda \to +\infty$? Are there any better approximation for $f(\lambda)$? If there is a simple expression for $ f(\lambda) $ about $\lambda \to +\infty$ that would be best, but I’m open to whatever can be suggested. Thank you in advance!","['asymptotics', 'probability', 'analysis']"
425339,Why is the category of coherent sheaves not grothendieck?,"Let $(X, \mathscr{O}_X)$ be a ringed space.  It is well-known that the category $\mathbf{Mod}(\mathscr{O}_X)$ of $\mathscr{O}_X$-modules is a grothendieck abelian category (see e.g. Grothendieck's Tohoku paper).  When $X$ is a scheme, the full subcategory $\mathbf{Qcoh}(\mathscr{O}_X)$ of quasi-coherent $\mathscr{O}_X$-modules is also grothendieck abelian (even if $X$ is not quasi-compact and quasi-separated, see here ). Now consider the full subcategory $\mathbf{Coh}(\mathscr{O}_X) \subset \mathbf{Mod}(\mathscr{O}_X)$ of coherent $\mathscr{O}_X$-modules.  This is an exact abelian subcategory but is not , in general, grothendieck.  My first question is: why not? Intuitively speaking, why is $\mathbf{Coh}(\mathscr{O}_X)$ not grothendieck abelian?  What goes wrong? Secondly, can the situation be rescued? Are there assumptions on $X$, e.g. noetherian, or proper over a noetherian base, etc., under which $\mathbf{Coh}(\mathscr{O}_X)$ is grothendieck abelian? Any reference that addresses these or related questions is very welcome.","['category-theory', 'sheaf-theory', 'algebraic-geometry', 'schemes']"
425362,The difference between inside and outside,"If I parameterise $\mathbb{R}^n$ with generalised polar coordinates $(r, \Theta)$ it is possible to partition $\mathbb{R}^n$ into three parts $$A = \{x \in \mathbb{R}^n \mid r < 1\}$$
$$B = \{x \in \mathbb{R}^n \mid r = 1\}$$
$$C = \{x \in \mathbb{R}^n \mid r > 1\}$$ $A$ is the inside and $C$ is the outside, of a sphere given by $B$. I can then define a function the maps most of the outside to the inside, for example: $$f: C\to A$$
$$f(r,\Theta) = (1/r, \Theta)$$ This function works almost everywhere except for where $x\in A$ is the origin. It would seem impossible to define a bijective function that completely maps $A$ to $C$ and that you'll always have a single point which is problematic. Basically, $C$ has a hole and $A$ does not. My question is, is the presence of this single point generally considered the basis on which inside and outside are different? Similarly, if we add a point at infinity to $\mathbb{R}^n$, what does this do to the notion of inside and outside, is there still a difference?",['general-topology']
425363,Find a number $A$ so that $\lfloor A^{3^n} \rfloor$ are always odd,"Find a  number $A$ so that (1) $\lfloor A^{3^n} \rfloor$ is always odd for $n\geq 1$ ;( $\lfloor x \rfloor$ is the largest integer not greater than $x.$ ) (2) $A>1$ and $A^{3^n}$ is never an integer for $n\geq 1$ ;(This is the place I have edited.) (3) There is a closed-form formula for $A.$ (Series and integral can also be seen as a closed form.) Mills' constant satisfies (1) and (2) but not (3) (so far). We can construct a number satisfies (1) and (2) more easily than Mills' constant: Let $a_1=1,a_{n+1}=a_n^3+2~(n\geq1).$ Denote $$A=\lim_{n\to \infty}a_n^{\frac{1}{3^n}}.$$ Then we can prove that $\lfloor A^{3^n} \rfloor=a_n,$ hence $A>1$ and $a_n$ is odd. The proof is very like to this . But I cannot find a closed-form formula for $A$ again. Thanks in advance !","['closed-form', 'number-theory']"
425366,Finding Intersection of an ellipse with another ellipse when both are rotated,Equation of first ellipse=> $$\dfrac {((x-xFirstEllipseCenterPoint)\cdot \cos(A)+(y-yFirstEllipseCenterPoint)\cdot \sin(A))^2}{(a_1^2)}+\dfrac{((x-xFirstEllipseCenterPoint)\cdot \sin(A)-(y-yFirstEllipseCenterPoint)\cdot \cos(A))^2}{(b_1^2)}=1$$ Equation of the second ellipse=> $$\dfrac {((x-xSecondEllipseCenterPoint)\cdot \cos(B)+(y-ySecondEllipseCenterPoint)\cdot \sin(B))^2}{(a_2^2)}+\dfrac{((x-xSecondEllipseCenterPoint)\cdot \sin(B)-(y-ySecondEllipseCenterPoint)\cdot \cos(B))^2}{(b_2^2)}=1$$ I know that the ellipse will intersect at One Point Two Point Three Point Four Point No intersection at all Is there a general set of equation to solve the same.,"['geometry', 'linear-algebra', 'conic-sections']"
425368,Does $\sum_{n=1}^{\infty} \frac{\ln(n)}{n^2+2}$ converge?,I'm trying to find out whether $$\sum_{n=1}^{\infty} \frac{\ln(n)}{n^2+2}$$ is convergent or divergent?,"['sequences-and-series', 'convergence-divergence', 'calculus']"
425371,complex analysis integration?,"I have to find $$\int_C \frac{2z-1}{z(z-1)} \,dz$$ where C is the circle |Z|=2
So,I thought about solving this by using Cauchy's formula.
That means I have  $f(x)=(2z-1)/z$ and then the integral = $2\pi\cdot i \cdot f(2)$ ...but how to continue this?",['complex-analysis']
425378,Showing that a root $x_0$ of a polynomial is bounded by $|x_0|<(n+1)\cdot c_{\rm max}/c_1$,"I have doubts about the following problem (Problem 3.21 from Sipser's ""Introduction to the Theory of Computation""): Let $c_1 x^n + c_2 x^{n-1} + \cdots + c_n x + c_{n+1}$ be a polynomial with a root at $x=x_0$ . Let $c_{\rm max}$ be the largest absolute value of a $c_i$ . Show that $$|x_0|<(n+1)\dfrac{c_{\rm max}}{c_1}.$$ Here is how I was able to approach it (I'm unsure that it's correct): Making the polynomial equal zero (in this case, $x=x_0$ ): $$c_1 x_0^n + c_2 x_0^{n-1} + \cdots + c_n x_0 + c_{n+1} = 0$$ Rearranging the terms: $$c_1 x_0^n = -(c_2 x_0^{n-1} + \cdots + c_n x_0 + c_{n+1})$$ Taking the absolute value of both sides: $$|c_1 x_0^n| = |c_2 x_0^{n-1} + \cdots + c_n x_0 + c_{n+1}|$$ Applying triangle inequality: $$|c_1 x_0^n| \leq |c_2 x_0^{n-1}| + \cdots + |c_n x_0| + |c_{n+1}|$$ The inequality above still holds if we substitute $c_{max}$ for all coefficients: $$|c_1 x_0^n| \leq |c_{max}| ( 1 + |x_0| + \cdots + |x_0^{n-1}| )$$ The inequality also holds if we substitute $n x_0^{n-1}$ for $1 + |x_0| + \cdots + |x_0^{n-1}|$ (because this sum has $n$ terms and $x_0^{n-1}$ is the largest one if $x_0>1$ ): $$|c_1 x_0^n| \leq |c_{\rm max}| n |x_0^{n-1}|$$ $$|x_0| \leq n \dfrac{|c_{\rm max}|}{|c_1|}$$ From the above result, it is true that: $$|x_0| < (n+1) \dfrac{|c_{\rm max}|}{|c_1|}$$ The above result is very close to the desired result, except that it should be $|x_0|<(n+1)\dfrac{c_{\rm max}}{c_1}$ (without the absolute bars). Is this approach correct? Edit : As pointed out in the comments, I also have to consider the case where $x_0\leq 1$ . If $x_0\leq 1$ then $\max(1, |x_0|,\cdots,|x_0|^{n-1}) = 1$ , so $|c_1x_0^n|\leq |c_{\rm max}|n$ , and $|x_0|\leq \left(n\dfrac{c_{\rm max}}{|c_1|}\right)^{1/n}$ . Since $c_{\rm max}\geq c_1$ : $|x_0| \leq \left(n\dfrac{c_{\rm max}}{|c_1|}\right)^{1/n}\leq n\dfrac{c_{\rm max}}{|c_1|} \leq (n+1) \dfrac{c_{\rm max}}{|c_1|}$ . Is this correct?","['discrete-mathematics', 'roots', 'polynomials']"
425379,Prove sequence is not convergent in a complete metric space,"I'm looking over some previous analysis exams and I've come across this question: Consider the set $\mathbb{R}$ of real numbers and the metric function
  defined as: $$d(x, y) = \begin{cases} 1 ~ \text{if} ~ x \ne y \\ 0 ~ \text{if} ~ x
= y \end{cases}$$ Is the sequence $(x_n)_{n = 1}^\infty$ defined by $x_n = \frac{1}{n}$ convergent in this metric space? Is this metric space complete? For part 1: Assume that $(x_n)_{n = 1}^\infty$ is convergent to a real $a$. Then, for every $\epsilon > 0$, there exists a $N \in \mathbb{N}$ such that: $$d(x_n, a) < \epsilon ~ ~ \text{for all} ~ ~ n \geq N$$ Let $\epsilon = \frac{1}{2}$. Then $d(x_n, a) < \frac{1}{2} ~ ~ \implies ~ ~ x_n = a ~ ~ \implies ~ ~ a = \frac{1}{n} ~ ~ \text{for all} ~ ~ n \geq N$. This is a contradiction, so $(x_n)_{n = 1}^\infty$ does not converge in this metric space. For part 2: A metric space is complete iff every Cauchy sequence is convergent. A Cauchy sequence is a sequence $(x_n)_{n = 1}^\infty$ such that for every $\epsilon > 0$, there exists an $N \in \mathbb{N}$ such that: $$d(x_n, x_m) < \epsilon ~ ~ \text{for all} ~ ~ n, m \geq N$$ Reusing part 1's approach, we let $\epsilon = \frac{1}{2}$. Then if $(x_n)_{n = 1}^\infty$ is a Cauchy sequence, it must follow that $x_n = x_m$ for all $n, m \geq N$. So the sequence is constant for $n \geq N$, and as such trivially converges. We have proved that if $(x_n)_{n = 1}^\infty$ is a Cauchy sequence in this metric space, then it must be convergent. Therefore this metric space is complete. Are these proofs valid? In particular, is the use of contradiction sound in part 1 and does the reasoning follow in part 2? I've learned to be careful with analysis arguments, so could someone check over my work? I am confident about part 1 but there's something about part 2 that confuses me. The completeness property only applies to Cauchy sequences, so if my results are correct then the sequence in part 1 is not Cauchy. So did I make a mistake or was $d$ carefully chosen to defy intuition?","['metric-spaces', 'real-analysis']"
425394,Riesz-Representation theorem for a special class of functions,"The original riesz representation theorem states Let $X$ be locally compact hausdorff space. Then for any nonnegative functional $\Lambda$ on $C_c(X)$, there is a unique regular borel measure $\mu$ on $X$ such that $$\Lambda(f)=\int f\mu(dx)$$ 
  for all $f\in C_c(X)$. Suppose there is a measured space $(\Omega,\mathcal{A},P)$. I define the space of measurable functions $L^0(P)$ is the equivalence class of measurable functions, which are $P$-a.s. equal. This is a vector space and often used in mathematical finance. If we suppose that $\Omega$ is finite, then we identify $L^0$ with $\mathbb{R}^n$ (for $Y\in L^0$, $Y(\omega_i):=y_i)$. I was able to prove that a given functional $\Gamma$ on $L^0$ is nonnegative. Can I use the Riesz-Representation theorem to conclude that $$\Gamma(Y)=\int Y R(dw)$$
for a measure $R$? The problem is the hyptothesis about $C_c(X)$. My notes say there is such a measure, but I'm not sure, why I can apply Riesz.","['probability-theory', 'riesz-representation-theorem', 'functional-analysis']"
425411,Which kind of additivity for measures is more natural,"To start with, I have almost no any experience in the theory of finitely additive (f.a.) measures, but I work a bit with countably additive (c.a.) ones and find the theory in the latter case amazingly beautiful. My concern is that at the moment measures have been introduced as an extension of such notions as area and volume, I can understand that the additivity property came alone naturally. However, I believe, that at that moment the choice f.a. vs. c.a. might not have any strong arguments. Later, it appeared that in many cases the space of c.a. (but not f.a.) measures is the dual of a corresponding space of all bounded continuous functions. Since the latter is a pretty ""natural"" object, I would say that its dual is ""natural"" as well. Would it be right to say that c.a. measures are more ""natural"" than f.a. ones, or that it appeared to be more successful/useful, and if so - why do we need the f.a. measures? I hope, that a bit loose formulation of the question still allows for an answer.","['measure-theory', 'functional-analysis']"
425417,What is the maximum possible value of determinant of a matrix whose entries either 0 or 1?,My question is simply the title: What is the maximum possible value of determinant of a matrix whose entries either 0 or 1 ?,"['optimization', 'matrices', 'determinant']"
425428,Finding a function with properties,"I am looking for a function $f(x)$ with the following properties: Positive for $x\in(-\infty, 0)$ but tangent to the x-axis at $x=-1$ A root at $x=0$ and negative for $x\in(0, 2)$ A root at $x=2$ and positive for $x\in(2, \infty)$ I thought $f(x)=x(x-2)(x+1)^2$ would do the trick but it does not. The graph I have drawn on paper has a ""w"" shape with a local minimum at $x=-1$, a local maximum between $x=-1$ and $x=0$ and a local minimum between $x=0$ and $x=2$. All help is greatly appreciated!","['graphing-functions', 'roots', 'functions']"
425431,Embedding torsion-free abelian groups into $\mathbb Q^n$?,"Glass' Partially Ordered Groups states without proof: Every torsion-free abelian group can be embedded into a rational vector space (as a group). Can someone link me to a proof of this? It seems to me like it's probably false: $\mathbb Q^n$ is countable, so how can an uncountable group be embedded (unless the space has uncountable dimension)? Does ""embedded as a group"" mean ""embedded in a way that doesn't preserve order""? I'm not sure what the ""as a group"" modifier indicates.","['vector-spaces', 'group-theory', 'abstract-algebra', 'abelian-groups']"
425442,intersection of two graph,"i would like to clarify some  questions from GRE,which  at first  seems a little difficult to understand,suppose that  we have  some function $f(x)=|2*x|+4$
and  graph of this function is given where is following question:
For which of the following functions g defined for all numbers x does the graph of g intersect the graph of f ? and 4  possible answers are A.g(x)=x-2
B.g(x)=x+3
C.g(x)=2*x-2
D.g(x)=2*x+3
E.g(x)=3*x-2 first what i did not understand what does mean For which of the following functions g defined for all numbers x does the graph of g intersect the graph of f ? 
does it means that which  g  intersect of f for all x or?answer is E,i have guessed that for  intersection we  should have
$|2*x|+4=g(x)$,clearly C and D no,because they are parallel lines with common slopes,so whe should have $|2*x|+4=x-2$ or
$|2*x|+4=x+3$ or
$|2*x|+4=3*x-2$ after  some calculation we will get
$|2*x|=x-6$ or
$|2*x|=x-3$ |2*x|=3*x-6 first can't be ,because $|2*x|>=x$
second also  using the same rule,only one left $|2*x|=3*x-6$
by using solving,for example if  $x>0$
$2*x=3*x-6$
$x=6$ if $x<0$ $-2*x=3*x-6$ $x=6/5$ is there any short way to solve it?","['absolute-value', 'algebra-precalculus']"
425474,Checking if a function is injective,"Let $\mathbb{C}$ be a small category, whose objects are thought of as ""admissible worlds"" and whose arrows as ""temporal admissible developments"". Let $X:\mathbb{C}^{\operatorname{op}}\rightarrow \operatorname{Sets}$ be a presheaf of sets defined on $\mathbb{C}$. Denote by $\sigma X$ the image of the world $\sigma$ via the functor $X$. An element $s\in\sigma X$ is called ""a person"" of $X$, living in the world $\sigma$. For every admissible temporal development $\pi:\rho\rightarrow\sigma$, denote by $\pi X:\rho X\gets\sigma X$ the image of $\pi$ via $X$, which is a function that associates to each person $s\in\sigma X$, living in $\sigma$, a person $\pi s\in\rho X$, living in $\rho$ ($\pi s$ is short notation for $(\pi X)(s)$). We'll think of $\pi s$ as the ancestor of $s$, with respect to the past temporal development $\pi:\rho\rightarrow \sigma$. To each person $s\in\sigma X$ we associate the whole family of ancestors of $s$, denoted by
$$ (-)\cdot s=\{\pi s\}_{\rho;\pi:\rho\rightarrow\sigma}$$
indexed by the set of arrows of $\mathbb{C}$, having codomain $\sigma$, the world where $s$ lives. I wish that this function were injective, meaning that $$(-)\cdot s=(-)\cdot s'\Rightarrow s=s'$$
but i can't prove it. Could someone help me?","['category-theory', 'functions']"
425479,Linear independence over rationals,"I am trying to figure out for what values of $n$, the numbers $\sin\left(\frac{2\pi k}{n}\right)$, for $k = 1,\dots,n-1$, are linearly independent over the rationals. Any thoughts on how I may want to approach this problem? It would be greatly appreciated.","['rational-numbers', 'number-theory']"
425488,"Cauchy-Riemann conditions, how to obtain them from arbitrary directions","If I have a function $f:\mathbb{C} \rightarrow \mathbb{C}$ which is differentiable in a neighbourhood of $z$, in a sense that 
$$f'(z)=\lim_{\Delta z \rightarrow 0} \frac{\Delta f}{\Delta z} = \lim_{(\Delta x + i \Delta y) \rightarrow 0} \frac{\Delta u(x,y) + i\Delta v(x,y)}{\Delta x + i \Delta y} $$ exists independent of the direction in which $\Delta z $ approaches $0$, then I can derive the C-R conditions by using two particular paths, namely ones parallel to the axes. But surely it must be possible to obtain the same result in a more complicated way, namely by using two arbitrary paths (straight lines), where $\frac{\Delta y}{\Delta x} = m_1$ and $\frac{\Delta y}{\Delta x} = m_2$. But so far, doing this computation has led me nowhere.",['complex-analysis']
425490,How would one work this out (surface integral of a function),"Given the definition of the surface integral: $$Area=\iint_{S}{\mathbf{F}\cdot d\mathbf{S}} = \iint_{D}{f(\mathbf{r}(u,v))\cdot \left |\mathbf{r_u} \times \mathbf{r_v}  \right |dA}$$ Where $\mathbf{r}(u,v)$ is a vector function to describe $\mathbf{S}$. (Note the bold typesetting indicates vectors for F, r, S). $\mathbf{r}_u$ means the partial differential of r with respect to u. Now the question given is: Evaluate the surface integral $\iint_{S}{x^2z^2}dS$
  S is the part of the cone $z^2 = x^2 + y^2$ that lies between the planes $z=1$ and $z = 2$ Now I tried this and came to a totally wrong solution. Looking up the solution in the solution manual gave me a different to approach the problem. The manual parameterized the function to $x,y$ by describing ""S is the part of the surface $z = \sqrt{x^2 + y^2}$ And then it used the standard approach of
$$\iint_{S}{\mathbf{F}\cdot d\mathbf{S}} = \iint_{D}{f(x,y,g(x,y))\sqrt{\left(\frac{\partial z}{\partial x}\right)^2+\left(\frac{\partial z}{\partial x}\right)^2+1}dA}$$
Which results in $\frac{384\sqrt{2}}{3}\pi$ I tried a complete different approach in my work around. Instead of parameterizing the surface by simply stating ""z"" I tried to parameterize it using the fact that z is a cone:
$$z = z, 1 < z < 3$$
$$x = \cos(\theta), 0 < \theta < 2\pi$$
$$y = \sin(\theta)$$
$$\mathbf{r}(z,\theta) = \cos(\theta)\mathbf{i}+\sin(\theta)\mathbf{j}+z\mathbf{k}$$ working the above problem out I could find
$$\left |\mathbf{r_z} \times \mathbf{r_\theta}  \right | = \sqrt{ z^2\cos^2(\theta) + z^2\cos^2(\theta)} = z$$
$$f(\mathbf{r}(z,\theta)) = \cos^2(\theta)z^2$$
$$A=\int\limits_0^{2\pi}{\int\limits_1^3{\cos^2(\theta)z^3}dz}d\theta= \int\limits_0^{2\pi}{\cos^2(\theta)}d\theta \int\limits_1^3{z^3}dz$$
$$A = 20 \int\limits_0^{2\pi}{\tfrac{1}{2} + \tfrac{1}{2}\cos(2\theta)}d\theta$$
$$A=20\left(\pi+\left[ \sin(4\pi)-\sin(0)\pi\right]\right)=20\pi$$ Which is a total different solution. What did I do wrong, where did I take the wrong decision in this answer?","['multivariable-calculus', 'integration']"
425494,Vorticity equation in index notation (curl of Navier-Stokes equation),"I am trying to derive the vorticity equation and I got stuck when trying to prove the following relation using index notation:
$$
{\rm curl}((\textbf{u}\cdot\nabla)\mathbf{u}) = (\mathbf{u}\cdot\nabla)\pmb\omega - ( \pmb\omega \cdot\nabla)\mathbf{u}
$$
considering that the fluid is incompressible $\nabla\cdot\mathbf{u} = 0 $, $\pmb \omega = {\rm curl}(\mathbf{u})$ and that $\nabla \cdot \pmb \omega = 0.$ Here follows what I've done so far:
$$
(\textbf{u}\cdot\nabla) \mathbf{u} = u_m\frac{\partial u_i}{\partial x_m} \mathbf{e}_i  = a_i  \mathbf{e}_i \\
{\rm curl}(\mathbf{a}) = \epsilon_{ijk} \frac{\partial a_k}{\partial x_j} \mathbf{e}_i = \epsilon_{ijk} \frac{\partial}{\partial x_j}\left( u_m\frac{\partial u_k}{\partial x_m} \right) \mathbf{e}_i = \\
= \epsilon_{ijk}\frac{\partial u_m}{\partial x_j}\frac{\partial u_k}{\partial x_m}  \mathbf{e}_i + \epsilon_{ijk}u_m \frac{\partial^2u_k}{\partial x_j \partial x_m} \mathbf{e}_i    \\
$$ the second term $\epsilon_{ijk}u_m \frac{\partial^2u_k}{\partial x_j \partial x_m} \mathbf{e}_i$ seems to be the first term ""$(\mathbf{u}\cdot\nabla)\pmb\omega$"" from the forementioned identity. Does anyone have an idea  how to get the second term?","['tensors', 'linear-algebra', 'fluid-dynamics']"
425522,Integral of wedge product of two one forms on a Riemann surface,"I'm having trouble verifying an elementary assertion made in this answer on MathOverflow.  It seems more like a math.stackexchange question, so I'm asking it here. Anyway, the assertion is as follows (mostly copied from the question) : ""Let $X$ be a genus $g$ surface, with $a_1$, ..., $a_g$, $b_1$, ..., $b_g$ a standard basis [for $H_1(X;\mathbb{Z})$]. Let $\omega$ and $\eta$ be two one-forms. Let $(u_1, u_2, \ldots, u_{2g})$ be the integrals $(\int_{a_1} \omega, \ldots, \int_{a_g} \omega, \int_{b_1} \omega, \ldots, \int_{b_g} \omega)$. Let $(v_1, \ldots, v_{2g})$ be the same integrals for $\eta$. Now, in terms of the $u$'s and the $v$'s, what is $\int_X \omega \wedge \eta$? The answer, which I leave for you to check, is $u_1 v_{g+1} + u_2 v_{g+2} + \cdots + u_g v_{2g} - u_{g+1} v_1 - u_{g+2} v_2 - \cdots - u_{2g} v_g$.""  Can anyone help me verify this? EDIT : On MathOverflow, David Speyer applies this to the case where $\omega$ and $\eta$ are holomorphic $1$-forms, and thus closed.  Maybe this condition is necessary?  It feels like one should somehow apply Stokes's theorem to the $4g$-gon obtained as a fundamental domain for the universal cover of $X$; the $a_i$ and $b_i$ will be the boundary components.  But I don't quite see how to do this. EDIT 2 : It's now been answered, but just in case someone comes across this later I thought I'd point out that the question as posed did not make any sense unless you assumed that $\omega$ and $\eta$ are closed -- otherwise, it would not make sense to integrate them along homology classes!","['surfaces', 'differential-forms', 'algebraic-geometry', 'differential-geometry']"
