question_id,title,body,tags
2672396,Show that if $\pm\lambda $ is an eigenvalue of $A$ then $\lambda^2$ is an eigenvalue of $A^TA$ and vice versa.,"Show that if $\pm\lambda $ is an eigenvalue of $A$ then $\lambda^2$ is an eigenvalue of $A^TA$ and vice versa. If $\pm\lambda $  is an eigenvalue of $A$ then $Av=\pm\lambda v\implies v^TA^T=\pm \lambda v^T\implies v^TA^TAv=a^2v^Tv  $ How to show that $a^2$ is an eigenvalue of $A^TA$ from above? Conversely $A^TAv=a^2v\implies v^TA^TAv=a^2 v^Tv\implies \langle Av,Av \rangle =a^2\langle v,v\rangle\implies ||Av||=a^2||v||\implies ||Av||=\pm a||v||$ How to show that $Av=\pm av$ from here?
Please help.","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2672434,Solution of Exact and Homogeneous differential equation,"Consider the equation
$(5y - 2x) (\dfrac{dy}{dx}) - 2y = 0$
This equation is Exact and Homgeneous differential equation. When i use the exact method then i get the following solution
$2xy -(5/2) y^2 = c$
And when I use the Homogeneous method of solution that is putting $y = vx$ in Homogeneous differential equation then I get the following solution
$ln (y) + \dfrac{2x}{5y} = c$.
Question is that are both right solutions. Im confused about different solution. Explain it please.",['ordinary-differential-equations']
2672497,"Compute the following limit, possibly using a Riemann Sum",$$\lim _{n\to \infty }\sum _{k=1}^n\frac{1}{n+k+\frac{k}{n^2}}$$ I unsuccessfully tried to find two different Riemann Sums converging to the same value close to the given sum so I could use the Squeeze Theorem. Is there any other way to solve this?,"['riemann-sum', 'calculus', 'limits']"
2672521,Convergence of $\sum (-1)^n \sin^2(n)/n$,"The series $\sum (-1)^n \frac{\sin^2(n)}{n}$ is a good example of something that fails the Alternating Series Test since the corresponding positive terms are not monotonic. The notes I took a couple years ago say ""It converges (conditionally) via clever trig identities."" But now I can't figure out how again.","['convergence-divergence', 'sequences-and-series', 'calculus']"
2672535,Show that no two eigenvectors of adjoint of right shift operator are orthogonal,"Let $$T:\ell^2 \to \ell^2$$ is unilateral shift operator, defined by $$T(x_1,x_2,x_3......)=(0,x_1,x_2,x_3.....),$$ then show that $T$ has no eigenvalue. But every $\lambda \in \mathbb{C}$ such that $|\lambda|<1$ is an eigenvalue of $T^{*}$ with multiplicity one. show that none of eigen vectors of $T^{*}$ are orthogonal to each other. I have found $$T^{*}(x_1,x_2,x_3......)=(x_2,x_3,x_4.....)$$ and eigenspace$\ E_{\lambda}$ corresponding to $\lambda$ equal to linear span of vector $$(1,\lambda,\lambda^2,\lambda^3....)$$ but I am stuck in the last part.how to show no two eigenvectors are orthogonal to each other. Any hint please?","['functional-analysis', 'banach-spaces', 'operator-theory', 'hilbert-spaces']"
2672556,Calculating the matrix exponential of rotation matrix,"I have the matrix: $$A=\begin {pmatrix}
0 &-1\\
1 & 0\\
\end{pmatrix}$$ And I want to try to calculate its exponential using this formula $$\ e^{M} = \sum_{k=0}^\infty \frac{1}{k!}\ M^{k}\\$$ I have worked out that $$A^{2} = -I$$ $$A^{3}=-A$$ and $$A^{4}=I$$ where $I$ is the identity matrix. I have then tried to use the fact that the sum will cycle through these matrices to separate the sum and then recombine it into one matrix. However what I get out cannot easily be expressed as a sum. Any help would be greatly appreciated!","['matrices', 'matrix-exponential', 'matrix-calculus']"
2672571,"How many different positive integers can be obtained as a sum of some or all off the numbers: $1,3,5,10,25$? [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question How many different positive integers can be obtained as a sum of some or all of the numbers:
$1,3,5,10,25$? I have just started discrete mathematics and I am having problems with some tasks. This is one of them. I don't really know what should be my starting approach. Could someone explain how to solve a problem like this one?","['combinatorics', 'discrete-mathematics']"
2672584,Finding action-angle variables for integrable Hamiltonian,"How to introduce action-angle variables in the following integrable 2 d.o.f. Hamiltonian system? $$H(q,p,x,y) = \frac{y^{2}}{2} - \frac{x^{2}}{2}\left(p^{2} + \omega^{2}q^{2}\right) + \frac{x^{4}}{4}$$ So $(q,p)$, $(x,y)$ are conjugated variables, and the first integrals are $F_{0}=H, F_{1} = p^{2} + \omega^{2}q^{2}$. Observe, for fixed $(q,p)$, the Hamiltonian has a saddle point in the $(x,y)$ plane, so one has to change $(q,p,x,y) \mapsto (\varphi, I, X, Y)$ where action-angle variables are $(\varphi, I)$ and $(X,Y)$ are a new canonically conjugate pair, i.e. we have $H(q,p,x,y)  = H(I, X, Y)$. So I need to find a generating function $S$. The question is, how to find this $S$? Note that if I take $F_{1}(q,p)$ as a ""Hamiltonian"" on its own, action-angle variables $(q,p) \mapsto (\varphi, I)$ are introduced through a generating function of the form $\tilde{S}(q, \varphi) = \frac{\omega q^{2} \cot 2\pi\varphi}{2}$. Can I use this function $\tilde{S}$ as an ""inspiration"" and modify it to take $S(q, \varphi, x, Y) = \tilde{S} + xY$ ? Or in such a setup, it is not as trivial?","['dynamical-systems', 'symplectic-geometry', 'hamilton-equations', 'classical-mechanics', 'ordinary-differential-equations']"
2672591,Examples of real $2\times2$ and complex $3\times3$ matrices with minimal polynomial $t^2+1$,"Consider the following corrolary (3.3.4 in Horn's and Johnson's Matrix Analysis book): For each $A\in\mathbb{C}^{n\times n}$, the minimal polynomial $q_A(t)$ divides the characteristic polynomial $p_A(t)$. Moreover, $q_A(\lambda)=0$ if and only if $\lambda$ is an eigenvalue of $A$, so every root of $p_A(t)=0$ is a root of $q_A(t)=0$. There is no real $3\times3$ matrix with minimal polynomial $t^2+1$ (proofs for that are here ). However, there is a real $2\times2$ matrix and a complex $3\times3$ matrix with minimal polynomial $q_A(t)=t^2+1$. I am trying to find such examples. For the $2\times2$ case consider
$$A=\begin{bmatrix}1&-1\\2&-1\end{bmatrix}$$
Its characteristic polynomial is 
$$p_A(t)=\det(tI-A)=\dots=t^2+1=(t-i)(t+i)$$
Then, by the above theorem and by the definition of the minimal polynomial (the unique monic polynomial of minimum degree, $q_A(t)$, that annihilates $A$ i.e. $q_A(A)=0$) we have 
$$q_A(t)|p_A(t)$$
and every eigenvalue is a root of $q_A(t)$. Thus, the minimal polynomial is indeed $q_A(t)=t^2+1$. For the $3\times3$ case consider
$$A=\begin{bmatrix}i&0&0\\0&1&-1\\0&2&-1\end{bmatrix}$$
Similarly, it is easy to see that 
$$p_A(t)=\det(tI-A)=\dots=(t-i)^2(t+i)$$
and among the two possibilities for the minimal polynomial
$$p_1(t)=(t-i)^2(t+i)\qquad\text{and}\qquad p_2(t)=(t-i)(t+i)$$
we see that $p_2(t)=t^2+1$ is the one with minimum degree that annihilates $A$ so that $q_A(t)=t^2+1$. Are the above examples correct? Any other examples, perhaps more interesting?","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra', 'minimal-polynomials']"
2672612,What does tell me this manifold is a circle?,"I was thinking about this: suppose we want to define an atlas on, for example, a circle $S^1$ to stay easy. Let's take the atlas made by the four charts $$(\{x>0\}, x);\ (\{x<0\}, x);\ (\{y>0\}, y);\ (\{y<0\}, y)$$ In few words: the left, right, north and south arcs with their respective projections on the axis as local coordinates. When I take a point on $S^1$ and I calculate the tangent space, since it's the vector space of the derivatives on the point and it has, as a basis, the derivatives with respect upon the local coordinates, if I take, for example, the right arc the coordinate function of which is $x$, a vector over the tangent space has an expression like $$b\frac{\partial}{\partial x}$$ and $b$ runs all over $\mathbb{R}$. Now the question: where is the information which tells me the manifold is actually a circle and not, say, an ellipse or something else? Where is in the usual sense, the slope of the straight line (that is the tangent space)? Is it seen only from the transition maps between different charts, or even from here?","['differential-topology', 'manifolds', 'geometric-topology', 'general-topology', 'differential-geometry']"
2672615,When you inscribe a triangle in a circle in a triangle in a circle in a triangle ...,"Here's a cute question I came up with. Start with a circle, and then choose three points $a$ , $b$ , and $c$ on the circle, and proceed as follows: Draw the triangle inside the circle with vertices $a$ , $b$ , and $c$ Draw the inscribed circle of that triangle, which is tangent to each of the three sides of triangle, and now label these three points of tangency as $a$ , $b$ , and $c$ (so we're updating which points we're calling points $a$ , $b$ , and $c$ ). Repeat from Step 1. This construction gives us a sequence of inscribed circles and triangles that telescope down to a point, a limit point , which is determined only by the initial choice of the points $a$ , $b$ , and $c$ . Which points in the interior of the circle are limit points of this construction? Also, if anyone has ideas for more interesting variations of this question, I'd like to hear them.","['general-topology', 'euclidean-geometry', 'geometry', 'recreational-mathematics', 'sequences-and-series']"
2672667,A More Symmetric Exponentiation,"Exponentiation is distributive over multiplication, but it isn't commutative or associative like addition and multiplication are. Is there a binary operation that is distributive over multiplication, and also commutative and/or associative? In order to find one such operation, I assumed that there is an identity element. An easier question than the one above is: Is the identity element $0$, $1$, or neither? If you find an operation that works, can you then find a commutative and/or associative operation that is distributive over that?","['algebra-precalculus', 'symmetry', 'binary-operations', 'associativity', 'exponentiation']"
2672668,Convergence by Vitali's theorem?,"Let $\Omega$ be a compact subset of $\Bbb R^3$, $\mu(\Omega)<\infty$. I want to show that 
$$
\int_{\Omega} |u_m-u|^2 (|\nabla u_m|+|\nabla u|)^4 d\mu \to 0
$$
as $m\to\infty$. It is given that $u,u_m\in L^{\infty}(\Omega)$ while $\nabla u,\nabla u_m\in L^4(\Omega)$. We also have $u_m\to u$ in $L^2$ (and almost everywhere) and $\nabla u_m\to\nabla u$ in $L^2$. Moreover, $\nabla u_m\overset{w}\to \nabla u$ weakly in $L^4$ so $||\nabla u_m||_{L^4}<C$ uniformly for some $C>0$. It appears that this follow somehow from Vitali's theorem but I don't see how. Any help is extremely appreciated. PS. The probability tag is from the fact that I often see Vitali's theorem used there, and this question can be interpreted in term of random variables if one wish.","['partial-differential-equations', 'sobolev-spaces', 'functional-analysis', 'probability', 'differential-geometry']"
2672727,Function value change with constrained arguments,"Suppose I have a function: $$f(a,b)=h(a)+g(b)$$ where $a+b=1$. I'm interested in the values of $a$ and $b$ that maximize $f(a,b)$. 
Without substitution (e.g. by using the fact that $b=1-a$), how could I find out whether $f(a,b)$ is increasing in $a$? My approach is as follows: since an increase in $a$ leads to a corresponding decrease in $b$, there are two effects of increasing $a$: $$\frac{dh(a)}{da};-\frac{dg(b)}{db}$$ Such that the net effect is positive iff $$\frac{dh(a)}{da}-\frac{dg(b)}{db}>0$$ Am I correct?","['derivatives', 'real-analysis', 'calculus']"
2672742,Can we calculate $ i\sqrt { i\sqrt { i\sqrt { \cdots } } }$?,"It might be obvious that $2\sqrt { 2\sqrt { 2\sqrt { 2\sqrt { 2\sqrt { 2\sqrt { \cdots } } } } } } $ equals $4.$ So what about $i\sqrt { i\sqrt { i\sqrt { i\sqrt { i\sqrt { i\sqrt { \cdots } } } } } } \text{ ?} $ The answer might be $-1$, but I'm not sure as $i$ is not a real number. Can anyone help?","['radicals', 'complex-numbers', 'algebra-precalculus', 'summation', 'geometric-progressions']"
2672761,Is the derivative directional?,"I was met with a surprising face when I assumed that a derivative is a directional change, i.e. that $$\frac{df(x)}{dx}$$ describes the change in $f(x)$ following an positive change in $x$. Moreover, the negative derivative describes the change in $f(x)$ following a negative change in $x$: $$-\frac{df(x)}{dx}$$ Am I mistaken?","['functional-analysis', 'calculus', 'derivatives']"
2672765,Summation of binomial coefficients upon $(r+2)$,"$$\sum^{50}_{r=0}(-1)^r \dfrac{\dbinom {50}r}{r+2}= ?$$ Attempt: $(1-x)^{50}= \sum (-1)^r \dbinom{50}r x^{n-r}$ Integrating both sides and then placing limits 0 to 1: $\dfrac{1}{51}= \displaystyle \sum_{r=0}^{50}\dfrac{(-1)^r \dbinom{50}r}{52-r}$ So the answer should be $\dfrac{1}{51}$
But answer given is $1/(51\times 52)$ Where have I gone wrong? Edit: I understood my mistake from the comment. 
Now I have:
$\dfrac{1}{51}= \displaystyle \sum_{r=0}^{50}\dfrac{(-1)^r \dbinom{50}r}{51-r}$ Is it possible to complete it from here ?","['combinatorics', 'binomial-theorem', 'binomial-coefficients']"
2672885,How Does Probability Recursion Work?,"I don't undstand how the textbook come up with recursive forumulas. For example, Consider the following gambling game for two players, Black and White. Black puts $b$ black balls and White puts $w$ white balls in a box. Black and White take turns at drawing at random from the box, with replacement between draws until either Black wins by drawing a black ball or White wins by drawing a white ball. Supposed black draws first. Calculate $P($ Black wins $)$ Textbook Answer: I'm not sure how they knew their equation encompasses all ways Black could win. I going to assume this is their reasoning: The first draw could only be be Black or White. $P($ Black wins $)$ $= P($ Black wins $|B)P(B) + P($ Black wins $|W)P(W)$ , obviously this encompasses all ways Black could win. $= P($ Black wins $|B)P(B) + ( P($ Black wins $|WW)P(WW) + P($ Black wins $|WB)P(WB) )$ $= P($ Black wins $|B)P(B)$ + ( 0 + $P($ Black wins $|WB)P(WB) )$ $= P($ Black wins $|B)P(B)$ + $P($ Black wins $|WB)P(WB)$ ? And how to set-up recursive probability equations in general + when to use them? Edit 1: I used everyone's feedback and came up with an in-depth solution. I think the logic is sound. For anyone that need it:",['statistics']
2672927,"Is the formula below for $S(n,k)$ correct?","$$S(n,k)=\sum_{i=1}^k \frac{i^n(-1)^{k-i}}{(k-i)!(i-1)!}$$
  Calculate $S(5,3)$ by using this formula and by listing all possible partitions of $\{1,2,3,4,5\}$ into $3$ blocks. Are they the same? By the formula I got $S(5,3)=90$ Now how am I going to list this number of partitions?  And next it says correct the formula.",['elementary-set-theory']
2672939,Generalization of an Integral Trick?,"There is an interesting trick that can be used to evaluate integrals in the form
$$I=\int_{-a}^a \frac{E(x)}{b^x+1}dx$$
where $E$ is an even function. Notice that, by substituting $x\to -x$,
$$I=\int_{-a}^a \frac{E(-x)}{b^{-x}+1}dx=\int_{-a}^a \frac{b^xE(x)}{b^{x}+1}dx$$
and so
$$I+I=\int_{-a}^a \frac{E(x)+b^xE(x)}{b^x+1}dx=\int_{-a}^a E(x)dx$$
and so
$$I=\frac{1}{2}\int_{-a}^a E(x)dx=\int_{0}^a E(x)dx$$
For example, this trick can be used to evaluate the intimidating integral
$$\int_{-1}^1 \frac{x^{100}}{e^x+1}dx=\frac{1}{101}$$ QUESTION: Is there some way to generalize this trick to integrals of the form
$$I=\int_{-a}^a \frac{E(x)}{(b^x+1)^2}dx$$
or will this type of integral just have to be done the hard way?","['integration', 'definite-integrals', 'even-and-odd-functions']"
2672960,Proving result of complex numbers,"Let $w,z$ be complex such that $wz\neq0$. Let $$t = 2- \left|\frac{w}{|w|} + \frac{z}{|z|}\right|.$$ Show that $0 \leq t \leq 2$, and that $$|w| + |z| - t\text{max}(|w|,|z|) \leq |w+z| \leq |w| + |z| - t\text{min}(|w|,|z|).$$ The first part I've shown, but the latter part I've struggled quite a bit with.","['complex-analysis', 'inequality']"
2672966,"On $\mathcal{C}([0,1])$, whether the operator $(\Lambda f)(x)=xf(x)$ is compact.","On the Banach space $\mathcal{C}([0,1])$, whether the operator 
$(\Lambda f)(x)=xf(x)$ is compact. We use the following definition of compact operator. A bounded linear operator $\Lambda:X \to Y$ is compact if, for every bounded sequence $(x_n)_{n\ge1}$ of points in $X$, there exists a subsequence $(x_{n_j})_{j \ge 1}$ such that $\Lambda x_{n_j}$ converges. Intuitively, I think it is not compact, but I cannot find a sequence as a counterexample. Can someone give a counterexample or some hints of the proof?","['functional-analysis', 'normed-spaces', 'banach-spaces', 'operator-theory']"
2672968,Why do continuous random variables have densities?,"In a basic probability course, there seems to be an implicit assumption that any continuous random variable has a density function, but I don't really see why this should be.  My intuition is that there's some probability space $(\Omega, \Sigma, P)$ and a measurable function $X : \Omega \to \mathbb{R}$, and you'd like to know the probability that $X$ takes on a value in some measurable $E \subseteq \mathbb{R}$.  The natural thing to do is look at the push-forward measure, $X_*P(E) = P(X^{-1}(E))$, but in any introductory probability book they make some claim that there's a density function $f$ such that this probability is $\int_E f(x) dx$, which seems to mean $X_*P$ is absolutely continuous with respect to Lebesgue measure, but I don't really see why this should be true in general. I suppose this should mean that if $E \subseteq \mathbb{R}$ has zero Lebesgue measure, then $X^{-1}(E)$ has has zero $P$-measure, but again I don't see why this needs to be true for an arbitrary measurable function $X$. Is this just an assumption that introductory books make, or is there something else going on that I'm not seeing?","['probability-theory', 'probability', 'measure-theory']"
2672978,"For Events $A$ and $B$, $A \subseteq B$ is equivalent to $A$ implies $B$? Seeking Clarification.","In my probability class, I was told that, if $A$ and $B$ are events, then $A \subseteq B$ is equivalent to $A$ implies $B$. So in other words, if the event A occurs, then this implies that the event B occurs, right? However, this claim was not justified, and I'm unsure as to how it is true. It seems to me that, If an event $A$ is a subset of an event $B$, then that does not necessarily imply $B$, since the event $B$ may have other outcomes in it. Indeed, it would seem to me that the converse would be true? In other words, the event $B$ occurring would imply that the event $A$ occurred? This is because, since all of the element in $A$ are also in $B$, then if $B$ occurs, then all of the outcomes that make up $A$ must also have occurred? I would greatly appreciate it if people could please help me understand this.","['probability-theory', 'elementary-set-theory']"
2673078,Monty Hall problem generalized to $n$ doors,"Generalize the Monty Hall problem where there are $n \geq 3$ doors, of
which Monty opens $m$ goat doors, with $1 \leq m \leq n$. Original Monty Hall Problem: There are $3$ doors, behind one of which there is a car (which you want), and behind the other two of which there are goats (which you don’t want). Initially, all possibilities are equally likely for where the car is. You choose a door, which for concreteness we assume is Door $1$. Monty Hall then opens a door to reveal a goat, and offers you the option of switching. Assume that Monty Hall knows which door has the car, will always open a goat door and offer the option of switching, and as above assume that if Monty Hall has a choice between opening Door $2$and Door $3$, he chooses Door $2$ and Door $3$ with equal probability . Find the probability that the strategy of always switching succeeds, given that Monty opens Door $2$. My approach: Let $C_i$ be the event that car is behind the door $i$,
$O_i$ be the event that Monty opened door $i$ and $X_i$ be the event that intially I chose door $i$. Here $i=1,2,3,...,n$. Let's start with case where I chose $X_1$. Then: $P(O_{j_1, j_2, ..., j_m}|C_1, X_1) = {{n-1}\choose{m}}(\frac{1}{n-1})^m$, here $j \in$ {$m$ doors out of $n-1$, i.e., exclude Door$1$ } $P(O_{k_1, k_2, ..., k_m}|C_t, X_1) = {{n-2}\choose{m}}(\frac{1}{n-2})^m$,
  here $k \in$ {$m$ doors out of $n-2$, i.e., exclude Door$1$ & Door$t$}, $t \in$ {$2,3, ..., n$} Also, $P(C_r|X_s) = \frac{1}{n}$, here $r,s \in$ {$1,2,...,n$} Probability of winning by switching is, $$P(C_3 | O_{k_1, k_2, ..., k_m}, X_1) = \frac{P(O_{k_1, k_2, ..., k_m}|C_3, X_1).P(C_3|X_1)}{P(O_{m-doors}|X_1)}$$ $$= \frac{P(O_{k_1, k_2, ..., k_m}|C_3, X_1).P(C_3|X_1)}{P(O_{j_1, j_2, ..., j_m}|C_1, X_1).P(C_1|X_1) + \sum_{t=2}^n(P(O_{k_1, k_2, ..., k_m}|C_t, X_1).P(C_t|X_1))}$$ $$ = \frac{{{n-2}\choose{m}}(\frac{1}{n-2})^m.\frac{1}{n}}{(\frac{1}{n}).({{n-1}\choose{m}}(\frac{1}{n-1})^m + {{n-2}\choose{m}}(\frac{1}{n-2})^m.(n-1))}$$ $$= \frac{(n-m-1)(n-1)^{m-1}}{(n-2)^m + (n-m-1)(n-1)^m}$$ However, the correct answer is $\frac{(n-1)}{(n-m-1).n}$. Any insights to what I have done wrong.","['monty-hall', 'probability']"
2673094,Probability of throwing exactly 100 sixes on an unfair dice.,"Suppose we have a dice with probabilities $\frac{1}{6}$ for rolling one, $\frac{1}{12}$ for rolling two, $\frac{1}{12}$ for three, $\frac{1}{6}$ for four, $\frac{1}{6}$ for five, and $\frac{1}{3}$ for six. What is the probability of rolling exactly 100  sixes from 250 rolls? I think I should use multinomial distribition in this case. My try: C(150,250)*(2/3)^150/6^250","['statistics', 'probability']"
2673132,A procedure for sampling paths in a directed acyclic graph,"Consider a directed acyclic graph $\mathcal{G} = (\mathcal{N},\mathcal{E})$. Assume that the graph is very large (on the order of 10000 nodes and edges). Let there be a set of nodes termed starting nodes denoted by $\mathcal{N}_s\subseteq\mathcal{N}$ and a set of nodes termed terminal nodes denoted by $\mathcal{N}_t\subseteq\mathcal{N}$. Consider the set of all paths that start from a node in $\mathcal{N}_s$ and end in a node in $\mathcal{N}_t$. Denote this set by $\mathcal{P}$. Goal : Derivation of a procedure that allows one to uniformly sample paths from the set $\mathcal{P}$ without having to construct $\mathcal{P}$ explicitly. Ideas: Of course, listing all such paths is computationally intractable preventing one from just being able to sample from a table of all paths. I am wondering if one can construct a procedure that involves sampling edges of the graph at random (without replacement) until one obtains a path that satisfies the condition that it starts in $\mathcal{N}_s$ and ends in $\mathcal{N}_t$ such that the procedure samples paths uniformly from $\mathcal{P}$. I've sketched out such a procedure for a small graph below. The top (green) nodes are the nodes $\mathcal{N}_s$ whereas the bottom (purple) nodes are the nodes $\mathcal{N}_t$. At each step of the procedure a single edge is sampled at random (denoted by the red edges). A check is done to see if it is a path that satisfies the condition, if not, sample a new edge (without replacement) and check again. Repeat until we find a path. If the addition of a single edge results in multiple paths, pick one at random. We add this path to our set of sampled paths, call it $\mathcal{\bar P}$, and repeat the process. Question : Does such a procedure result in uniformly sampled paths from $\mathcal{P}$? If not, are there procedures that do so without requiring one to construct $\mathcal{P}$?","['combinatorics', 'graph-theory', 'sampling', 'directed-graphs']"
2673185,Why would surgery theory require $5$ dimensions?,"In the Wikipedia page for geometric topology it says ""The Whitney trick requires $2+1$ dimensions, hence surgery theory requires $5$ dimensions"".  I am having trouble with understanding why surgical theory would have to require five dimensions and why it would not work with less dimensions.","['surgery-theory', 'geometric-topology', 'general-topology']"
2673239,"number of distinct solution $x\in[0,\pi]$ of the equation satisfy $8\cos x\cos 4x\cos 5x=1$","The number of distinct solution $x\in[0,\pi]$ of the equation which satisfy $8\cos x\cos 4x\cos 5x=1$ Try: $$4\bigg[\cos(6x)+\cos(4x)\bigg]\cos 4x=1$$ $$2\bigg[\cos(10x)+\cos(2x)+1+\cos (8x)\bigg]=1$$ So $$\bigg[\cos(10x)+\cos(8x)+\cos(2x)\bigg]=-1$$ Could some help me to solve it, Thanks","['polynomials', 'substitution', 'roots', 'trigonometry', 'factoring']"
2673375,Calculate distribution of mean and variance given Gaussian data points,"I was reading some basic texts on machine learning where you build a Gaussian model of a generative process from a vector of available data points. 
To give the contexts and the notations, assume $x_1, x_2, x_n\in\mathbb{R}$ are independent available data points from a Gaussian distribution. You have to estimate $\mu$ (the mean) and $\sigma>0$ (the standard deviation) from these known data points. Using some maximum likelihood estimator, we can say the problem is basically $$\max_{\mu, \sigma}\prod_{i=1}^nf_G(x_i)$$ where $f_G(x_i)$ is the Gaussian PDF with the mean and SD. The solution is easy, just the mean and SD of the data points give the optimum. But I am interested in a more general question where I calculate the joint probability density of $\mu$ and $\sigma$ given the data points? Is there any way to calculate $$f(\mu, \sigma \mid x_1, x_2, \cdots, x_n)=\frac{F(\mu, \sigma,x_1, x_2, \cdots, x_n)}{f(x_1, x_2, \cdots, x_n)}$$ Of course, we throughout assume that the underlying generative process is Gaussian, but I am stuck with the PDFs. Do I need any additional assumption to answer this question?","['maximum-likelihood', 'statistics', 'normal-distribution', 'probability-distributions']"
2673388,Book Supplement to Griffth and Harris Principle in Algebraic Geometry,There is a Chapter 0 (Foundation Level) in Principle in Algebraic Geometry. What are those good book supplement to this chapter ?,"['complex-geometry', 'algebraic-geometry']"
2673394,Linear model $Y= X\beta +\epsilon$. Show that the two subcomponents $\hat{\beta_1}$ and $\hat{\beta_2}$ of the BLUE $\hat{\beta}$ are independent.,"Suppose a linear model $Y= X\beta +\epsilon$ where $\epsilon \sim N(0,\sigma ^2I)$. Write $X=[X_1;X_2]$ where $X_1$ are the first $p_1$ columns of $X$ nad $X_2$ are the last $p_2$ columns. Similary split $\beta ^T =(\beta_1^T; \beta_2^T)$. If $X_1'X_2 =0$ show that the two subcomponents $\hat{\beta_1}$ and $\hat{\beta_2}$ of the BLUE $\hat{\beta}$ are independent. I know that $\hat{\beta_1}$ and $\hat{\beta_2}$ are normal because of $\epsilon$. I do not know how to start.","['independence', 'statistics', 'linear-algebra']"
2673448,What do we know about the geometry and topology of the space of Riemannian metrics with non negative scalar curvature on $\mathbb{R}^n$?,"In these days I was trying to minimize a Riemannian functional on the space of Riemannian metrics  with non negative scalar curvature over a manifold, and I suddenly realize that I don't know nothing about how this space looks like.
In particular I don't even know if it is a vector space, if it is convex, star shaped, path connected or connected. 
This led me to ask the following questions. Consider $\mathcal{M}_{\geq 0}(\mathbb{R}^n)$ the topological space of the Riemannian metrics on $\mathbb{R}^n$ that have non negative scalar curvature. We give to it the topology induced by the inclusion $\mathcal{M}_{\geq 0}(\mathbb{R}^n)\subset C^{\infty}(T^0_2 \mathbb{R}^n)$ in the space  of sections of (0,2)-tensors.  $C^{\infty}(T^0_2 \mathbb{R}^n)$ has the norm given by the usual inner product between (0,2) tensors integrated over the manifold. Is $\mathcal{M}_{\geq 0}(\mathbb{R}^n)$ connected? Path connected? $C^1$ path connected? Star shaped? Convex? Vector space? Is there any interesting dense subset? For example is the set of non negative sectional curvature a dense subset? What happens if instead of considering the scalar curvature, which is the first elementary symmetric function in the eigenvalues of the (2,2) type Riemann tensor we consider other elementary symmetric functions? If we consider a generic $n$-manifold, the space $\mathcal{M}_{\geq 0}(\mathbb{M}^n)$ can be empty, if not what remains true?","['riemannian-geometry', 'differential-geometry', 'curvature']"
2673462,Abelian subgroup contained in a normal subgroup; a trick about elements of order $3$,"Let $A$ be a normal subgroup of $G$. Suppose that every element in $G\,\backslash\, A$ has order $\bf 3$. Then $[B,B^x]=1$ for all Abelian subgroups $B\leq A$ and $x\in G\,\backslash\, A$. I have been told that my task must have something to do with Chapter VI, On the isomorphism of a Group with Itself , para 66. of the famous book—“Burnside, W.: Theory of Groups of Finite Order , 2nd edn., Cambridge 1911; Dover Publications, New York 1955”. [ It’s a trick about order $3$, which was mentioned in the comments and Derek Holt’s answer below. ] Although we‘ve made many attempts indeed and have made a breakthrough (Derek Holt’s answer), yet we haven’t been able to figure out how to use the normality of $A$ and abelianity of $ B$, on which I’m still struggling... It would be greatly appreciated if you are kind enough to provide a reasonable answer! PS: It’s exercise 1.5.6 of the book The Theory of Finite Groups, An Introduction . Berlin: Springer, 2004.","['abelian-groups', 'abstract-algebra', 'group-theory']"
2673467,Grid navigation,"Suppose you're on a 4 × 4 grid and want to go from the bottom left to the top left. How many different paths can you take? You are only allowed to move up-down-left-right (not diagonally) and MUST pass through every square only once. A thought: Let's say we move L, R, U, D. It must be L=R (since we end up in the same column) and also U-D=3, if this is of any help. Obviously the total number of moves must be 14. For example, LLLLLLRRRRRRUUU or RRRRLLLLUUUUDD in any order.
Then we have to apply the restrictions, that we can't have, for example, RLR or LRL or UDU or DUD because this way we would pass through the same square twice. I am stuck!",['combinatorics']
2673524,"A ""Geometric"" probability problem","n points are chosen randomly from a circumference of a circle. Find the probability that all points are on the same half of the circle. My intuition was that the probability is $1/2^{n-1}$ since if the first point is placed somewhere on the circumference, for each point there is probability of $1/2$ to be placed on the half to the right of it and $1/2$ to the left..but i feel i might be counting some probabilitys twice. Any ideas?","['probability-theory', 'probability', 'random-variables']"
2673542,An example of three probability events with certain property,"I am trying to find three events $A,B,C$ with the following properties \begin{gather}
P(A|B)>P(A),\\
P(A|C)>P(A),\\
P(A|B\cup C)<P(A).
\end{gather} I have not been able to come up with events satisfying all three, and would appreciate some help.",['probability']
2673590,Solving finite limit without L'Hôpital,"I have come across a problem which requires solving the following limit without L'Hôpital rule: $$\lim_{x\to\infty} x^2\cdot(e^\frac{1}{x-1}-e^\frac{1}{x})$$ It is obvious from the graphic plot (or using L'Hôpital rule) that the limit is 1. I have tried a few algebraic manipulations and changes of variable without success. Another approach that I tried was to ""sandwich"" this limit between two other different limits, one strictly greater and one strictly lesser than this one, that would be easier to work with than the difference of exponentials present in this one. As of now I haven't had any success, how would one go about solving it?","['real-analysis', 'limits', 'exponential-function', 'limits-without-lhopital', 'fractions']"
2673602,Convolution operator,"I'm trying to find the spectrum of the convolution operator and understand
$$T : L_2 \left[ -\pi, \pi \right] \longrightarrow L_2\left[ -\pi, \pi \right],$$
$$ f(t) \longmapsto \int_{-\pi}^\pi \sin^2(t-s)f(s) \, \mathrm{d}s. $$ I think the best option would be to go over to the Fourier transform $F$ due to this answer enter link description here . But the Fourier transformation is defined in space $L_2 (\mathbb{R}) $ (as a limit on the Schwarz class) ($F : L_2 (\mathbb{R}) \longrightarrow L_2 (\mathbb{R}) $). Then we know that $L_2\left[ -\pi, \pi \right] \subset L_2 (\mathbb{R}) $ and $F \circ T \circ F^{-1} : F \left( L_2\left[ -\pi, \pi \right] \right) \longrightarrow F \left( L_2\left[ -\pi, \pi \right] \right)$. In this case we get that the operator $F \circ T \circ F^{-1} $ is the multiplication operator $F \circ T \circ F^{-1} = M_{g}$, where 
$$g(x) = \int_{-\pi}^\pi \sin^2 (t) e^{-ixt } \, \mathrm{d}t$$ We know also that $\sigma(M_g) = \sigma \left(F \circ T \circ F^{-1} \right) =\sigma(T)$. But then we want to define spectrum of $T$. We know that in $ B \left(L_2 \left( \mathbb{R} \right) \right)$ spectrum of $M_g$ is essential range of $g$ (in this case is simply range). But our space is not all $L_2\left( \mathbb{R} \right)$, we only have a part $ \operatorname{Im}(F) = F \left( L_2\left[ -\pi, \pi \right] \right) $ and i don't know how to show that in $B(\operatorname{Im}(F))$ operator $M_g$ has the same spectrum. Sorry for my english and thank you very much!","['banach-algebras', 'compact-operators', 'operator-theory', 'functional-analysis', 'spectral-theory']"
2673609,On why $d/dz(\Re(z))$ does not exist,"Let $f(z)=\Re(z)\in\mathbb{C}$, $z=x+iy$ and $h=h_x+ih_y$, then $$f'(z)=\lim_{h\to0}\frac{f(z+h)-f(z)}{h}$$
$$= \lim_{h\to0}\frac{f(x+h_x+i(y+h_y))-f(x+iy)}{h}$$
$$= \lim_{h\to0}\frac{\Re(x+h_x+i(y+h_y))-\Re(x+iy)}{h}$$
$$= \lim_{h\to0}\frac{x+h_x-x}{h}$$
$$= \lim_{h\to0}\frac{\Re(h)}{h}$$
now, as we take the limit, it's worth considering how our expression behaves depending on where we take the limit from. If we consider what happens as we take the limit as $h\to0$ along the real axis, we have that $\Re(h)=h$, hence the ratio between $\Re(h)$ and $h$ is $1$, and the limit hence is $1$. However, if we repeat this process, but along the imaginary axis, we find that $\Re(h)=0$, and hence the ratio between $\Re(h)$ and $h$ is $0$, and our limit evaluates to $0$. We notice that already, the limit approaches different values as $h\to0$. My question, then, is whether or not it is therefore safe to say that the limit of the difference quotient does not exist, and that therefore, $f(z)$ is not differentiable, or are there other conditions that we need to check before we jump to such a conclusion?","['derivatives', 'complex-analysis', 'limits']"
2673647,Differential Equation-Separation of variables,"1) Solve the following differential equation by separation of variables (or otherwise) $$\frac{dy}{dx}-1=e^{x-y}$$. What I tried :-
Suppose $$z^2=e^{x-y}$$
        $$\Rightarrow 2z\frac{dz}{dx}=e^{x-y}(1-\frac{dy}{dx})$$
$$\Rightarrow 2z\frac{dz}{dx}=z^2(1-\frac{dy}{dx})$$
$$\Rightarrow 2\frac{dz}{dx}=z(1-\frac{dy}{dx})$$
$$\Rightarrow \frac{dy}{dx}=1-\frac{2dz}{zdx} \tag1$$ Again, $$\frac{dy}{dx}-1=e^{x-y}$$
$$\Rightarrow \frac{dy}{dx}=1+z^2 \tag2$$ Equating $(1)$ and $(2)$, $$1+z^2=1-\frac{2dz}{zdx}$$
$$\Rightarrow z^3dx=-2dz$$
$$\Rightarrow z^{-3}dz=-\frac{1}{2}dx$$
$$\Rightarrow \int z^{-3}dz=\int -\frac{1}{2}dx$$
$$\Rightarrow \frac{z^{-2}}{-2}=-\frac{1}{2} x+\frac{c}{2}$$
$$\Rightarrow -z^{-2}=-x+c$$
$$\Rightarrow z^{-2}-x+c=0$$ Am I correct ?","['ordinary-differential-equations', 'proof-verification']"
2673669,"Why haven't mathematicians come up with an efficient way of writing “sufficiently”, e.g. “for $n$ sufficiently large”","Consider a typical proof in an introductory analysis course: Claim: Let $(x_n)_\mathbb{N}$ and $(y_n)_\mathbb{N}$ be convergent sequences in $\mathbb{R}$ (or $\mathbb{C}$ ) and let $x,y$ be their respective limits. Then $(x_n+y_n)_\mathbb{N}$ is convergent and its limit is $x+y$ . Proof: Let $\varepsilon >0$ . There exists $n_1$ resp. $n_2$ such that $$\forall n \geq n_1, |x_n-x| < \varepsilon/2$$ resp. $$\forall n \geq n_2, |y_n - y| < \varepsilon/2.$$ Let $n_0 = \max(n_1,n_2).$ The triangle inequality implies that $$\forall n \geq n_0, |(x_n + y_n) - (x+y)| \leq |x_n - x| + |y_n - y| < \varepsilon/2 + \varepsilon/2 = \varepsilon.$$ This proves the claim. As a first-year student, this is a proof structure that comes up a lot . And yet, a significant portion of it seems redundant. Namely, the actual value of $n_0$ that I chose is of almost no significance. I could just as well have chosen $n_1 + n_2$ or $\max(n_1,n_2)+52.$ The only thing that's important is that $n_0$ be greater than both $n_1$ and $n_2$ , which is necessarily possible due to the fact that $\mathbb{N}$ is totally-ordered and not bounded above. This remark has led me to come up with a notation which I use extensively in my notes and saves me vast amounts of ink. This notation is the following: I define the notation $\mathbb{N}^\infty$ to mean “any set of the form $\mathbb{N}\setminus \left\{0,\ldots,n_0\right\}$ where $n_0 \in \mathbb{N}$ . (The $\infty$ -symbol is supposed to symbolise “sufficiently close to infinity”.) Like little-oh and big-oh notation, $\mathbb{N}^\infty$ does not refer to a specific object but rather a generic object with a certain property. However, $\mathbb{N}^\infty$ sets have the following useful property: any finite intersection of $\mathbb{N}^\infty$ sets is $\mathbb{N}^\infty$ . (This is kind of like how any finite sum of $o(f)$ functions is $o(f).$ ) The last property has the following consequence: Let $P_1,\ldots,P_k$ be predicates on $\mathbb{N}.$ Suppose that for all $i=1,\ldots,k$ we have $$\forall n \in \mathbb{N}^\infty,P_i(n) \textrm{ is true}.$$ Then $$\forall n \in \mathbb{N}^\infty, (P_1(n)\wedge\ldots\wedge \ P_k(n)) \textrm{ is true}$$ This is just a fancy way of saying “If, in a finite set of predicates, each predicate is true for sufficiently large $n$ , then for sufficiently large $n$ , each predicate is simultaneously true.” Note that this fails if the number of predicates is infinite. Using this notation, the definition of the limit can be written as follows: We say that $(x_n)_\mathbb{N}$ tends to some number $x$ iff for all $\varepsilon >0,$ $$\forall n \in \mathbb{N}^\infty, |x_n - x| < \varepsilon.$$ Using the property that I just stated, proof I gave above can also be rewritten: Proof: Let $\varepsilon >0$ . Then $$\forall n \in \mathbb{N}^\infty,|x_n - x| < \varepsilon/2$$ and $$\forall n \in \mathbb{N}^\infty,|y_n - y| < \varepsilon/2$$ hence by the triangle inequality, $$\forall n \in \mathbb{N}^\infty,|(x_n+y_n) - (x+y)| < \varepsilon.$$ Not only is this version more concise, but in my opinion it is better from a pedagogical point of view. When a student unfamiliar with analysis reads the first version (see above), there is some chance that we will be side-winded by the construction of $n_0$ (which as I said bears little to no importance), and he will be detracted from the actual crux of the proof which is the use of the triangle inequality. On the other, if the same student reads the second version, assuming that he understands the notation, he won't be side-winded by information that is not strictly necessary to his conceptual understanding of the proof. Finally, and perhaps most importantly, there is no loss in rigour in using the $\mathbb{N}^\infty$ notation provided that the “rules of the game” are well-understood. In a similar vein, for functional limits I use the notation $I^a$ (where $I$ is an interval and $a$ is in the closure of $I$ ) to signify “the intersection of $I$ with some open interval centred around $a$ ”. Here, the $a$ in the exponent is intended to symbolise “sufficiently close to $a$ ”. We again have the property that any finite intersection of $I^a$ sets is $I^a$ . In a way that is similar to the above, this notation allows us to simplify definitions and proofs in a way that is in my opinion non-negligeable and pedagogically fruitful. Finally, I would like to ask: Since the notions of “sufficiently large” and “sufficiently close to” are so ubiquitous in analysis, why haven't mathematicians come up with a way to convey them efficiently?","['education', 'real-analysis', 'soft-question']"
2673672,Find area of shaded region - is the information insufficient?,"This brain teaser turned out to be a brain boggler.
As I am the type of math need that dwells on a single problem until it gas been solved ( and understood ). I don't think there is enough information given to find the area of shaded region . I tried drawing lines to make congruent pieces of the shaded region in terms of a side of the square call it $x$. I was even attacking it with trig to see if angles given since there are many parallel sides,  but still no avail. Please help.","['algebra-precalculus', 'area', 'geometry']"
2673678,"Do $n=2m+1$ and $\big(2^m\bmod(m\cdot n)\big)\in\{n+1,3n-1\}$ imply $n$ prime?","Do $n=2m+1$ and $\big(2^m\bmod(m\cdot n)\big)\in\{n+1,3n-1\}$ imply $n$ prime? Equivalently, for $n=2m+1$, do $2^m\equiv\pm1\pmod n$ and $2^m\equiv2\pmod m$ imply $n$ prime? Note: equivalence follows from the Chinese Remainder Theorem for $m>2$, and examination otherwise. $2^m\equiv\pm1\pmod n$ is an Euler test for $n$. What if we add the stronger requirements that $2^{(m-1)/2}\equiv\pm1\pmod m$ ? That $m$ pass the strong pseudoprime test to base 2? The $n$ with $m$ prime that pass the test include all the safe primes (OEIS A005385 ) above $5$. The corresponding $m$ are Sophie Germain primes (OEIS A005384 ). Proof: safe primes $p=2q+1$ match $2^q\equiv\pm1\pmod p$ by Euler's criterion , and match $2^q\equiv2\pmod q$ by Fermat's little theorem . I fail to prove that conversely, the $n=2m+1$ with $m$ prime that pass the test include nothing but the safe primes . There are a few other $n$ that pass the test, dubbed pseudo-safe-primes , A300193 ; terms less than $2^{42}$ b300193 ; first ones: 683, 1123, 1291, 4931, 16963, 25603, 70667, 110491, 121403, 145771, 166667, 301703, 424843, 529547, 579883, 696323, 715523, 854467, 904103, 1112339, 1175723, 1234187, 1306667, 1444523, 2146043, 2651687, 2796203, 2882183, 3069083, 3216931, 4284283, 4325443, 4577323, 5493179, 5764531, 9949943, The smallest even $m$ are for $n=252\,435\,584\,573$, $1\,200\,060\,997\,853$, $2\,497\,199\,739\,653$, $453\,074\,558\,824\,253$... which are prime. Any such even $m$ is an even pseudoprime (OEIS A006935 ). All odd $m$ are pseudoprimes (OEIS A001567 ) passing a Fermat test , with the corresponding $n$ passing a strong pseudoprime test .","['number-theory', 'pseudoprimes']"
2673686,Conditions for Central limit Theorem for compound distribution,"Given a compound distribution
$$S:=\sum_{k=1}^{N} X_{i}$$ with $N$ is a discrete random variable with values in $\mathbb{N}$ with finite mean and variance. $X_{k}$ are non-negative iid random variables such that $\mathbb{E}\left[X_{i}\right]<\infty$ and $\sigma^{2}$:=Var($X_{i}$)<$\infty$. $N$ and $(X_{1},X_{2},\ldots)$ are independent. Then $$\mathbb{E}\left[ S\right]= \mathbb{E}\left[ N\right]\mathbb{E}\left[ X_{1}\right]$$ as well as
$$\text{Var}\left[ S\right]= \text{Var}\left[ N\right]\mathbb{E}\left[ X_{1}\right]^{2} + \mathbb{E}\left[ N\right]\text{Var}\left[ X_{1}\right].$$ 
Is there now a form of the central limit theorem applicable?
In particular, are there conditions under which we can use normal approximation, i.e. $$\frac{S-\mathbb{E}\left[S \right]}{\sqrt{\text{Var}\left[S \right]}}\approx \mathcal{N}(0,1)\; ?$$ $\mathbf{Update}$: Thanks a lot for the reference. 
Suppose that $\mathbb{E}\left[ X_{i}\right]=0$ and $N(t), t \geq  0$ is a family of positive, integer valued random variables, such that there is a $\theta >0$
$$  \frac{N(t)}{t}\stackrel{\mathbb{P}}{\rightarrow}\theta,\,\text{ as } t\to\infty. $$ According to Renyi's or Anscombe's Theorem, we then have
\begin{align*}
 	\frac{S_{N(t)}}{\sigma\sqrt{N(t)}} \xrightarrow[]{d} \mathcal{N}(0,1)\,\text{ as } t\to\infty \\
	 \frac{S_{N(t)}}{\sigma\sqrt{\theta\cdot t}} \xrightarrow[]{d} \mathcal{N}(0,1)\,\text{ as } t\to\infty, \\
\end{align*}
which is different from the above normal approximation (using Wald's identity). My question is now: Under which assumptions is the first/above normal approximation valid? What is the key difference between the two approximations respectively which one is preferrable? For example if $N(t)$ is a Poisson distribution?","['probability-theory', 'central-limit-theorem', 'probability-distributions']"
2673754,What happens to a variety defined over $\mathbb{C}$ if instead consider the equations over $\mathbb{F}_p$?,"Suppose I have $R$ polynomial equations $F_1, ..., F_R$ and say they all have integer coefficients. Let us denote $V_{\mathbb{C}}$ to be the affine variety defined by these polynomials over $\mathbb{C}$. Let $\mathbb{F}_p$ be the finite field of $p$ elements. 
Since the polynomials can be interpreted as polynomials over $\mathbb{F}_p$ (by reducing the coefficients) let us denote $V_{\bar{\mathbb{F}_p}}$ to be the affine variety defined by these equations over the algbraic closure of $\mathbb{F}_p$. I was wondering, are the quantities such as dimension, the number of irreducible components and degree of $V_{\mathbb{C}}$ and $V_{\bar{\mathbb{F}_p}}$ related somehow? I can see that for small $p$ they could be different, but maybe they will be the same once $p$ is sufficiently large or something? I would greatly appreciate any comments. Thank you very much. ps I have learned that these quantities can be bounded uniformly (in $p$) and I am interested in how one can prove this. Thank you!",['algebraic-geometry']
2673771,How to visualise positive and negative tangents,"A quick internet search of simple trigonometry methods returns a whole bunch of acronyms for remembering whether sin, cos and tan functions yield positive or negative results in the four quadrant of a circle. I find this rather unsatisfactory, since it makes no attempt to explain what's going on. To my mind, using a circle and lines (as below), it's fairly easy to see why, as the angle grows, the sine function returns positive results (red line) in the top half, and similarly the cosine (light blue line) goes negative in the left half of the circle and returns to positive as it comes back past 270°. When I was taught trigonometry it was a complete mystery how the tan function related to the geometric tangent (my teacher told me ""it was complicated""), and like everyone else simply memorised acronyms to get by. It now turns out its relationship is not complicated at all and a simple diagram like this goes a long way to explaining the mysteries of trig. However, the part of the puzzle I'm missing regards the + and - of the tangent function. I understand how is the ratio of the geometric tangent (always returning to the x axis) to the 'radius'. (I now notice that the diagram is rather badly drawn in that respect.) What's not clear is why the tan of, say, 120° should be regarded as negative, but 200° a positive. As with sine and cosine, is there a similarly simple way to visualise why it's negative in the top-left and bottom-right quadrants?","['tangent-line', 'visualization', 'trigonometry']"
2673913,Existence of a parallel vector field,"I came across the following sentence in a comment on this 
question: Local existence of parallel vector field ""the existence of a parallel vector field is equivalent to the condition that the metric splits locally into a Riemannian product of a one-dimensional manifold and an (n−1)-dimensional one. This implies, in particular, that the sectional curvatures of planes containing V are all zero."" and I want to know what the poster mean by the metric splitting locally into a Riemannian product and what that has to do with sectional curvatures.","['riemannian-geometry', 'differential-geometry']"
2673914,"Is the the $n \times n$ matrix $A_{ij} = (ij + 1)^m$, $m \geq n$ invertible?","Consider the $n \times n$ symmetric matrix A, whose $ij$-th entry is defined by $A_{ij} = (ij + 1)^m$ and $m \geq n$. Is this matrix invertible? Approaches I've tried: Numeric attempts to find a counterexample over a range of $n$ and $m$ have failed. These experiments did suggest that $A$ may be positive definite. A unisolvence theorem approach does not work, because the $n$ polynomials defining the rows or columns are of order $m$ and evaluated at $n \leq m$ points.","['matrices', 'linear-algebra', 'inverse']"
2673918,ODE with modulus sign,"How can I solve this ODE ?
$$\left|y'(x)\right| +\left|y(x)\right| =0.$$
I can easily solve it without the modulus signs. At present, $y(x)=0$ is the ony solution I can think of.",['ordinary-differential-equations']
2673922,Convolution of a function and a measure.,"Consider a locally compact group $\mathrm{G}$ and a left-invariant Haar measure $\lambda$ on it. Let $\mu$ be a probability measure. Suppose $f$ is a function continuous and bounded. Denote by $\Delta$ the modulus of the group $\mathrm{G}.$ I want to show that the function
$$(f \ast \mu)(x) = \int\limits_\mathrm{G} f(xs^{-1}) \Delta(s^{-1})\ d\mu(s)$$
is (1) defined everywhere , (2) continuous and (3) bounded. EDIT: I am looking at the integral on a locally compact space, the usual way they handle this is by means of the Daniell integral. So, I guess the measures here are called Radon measures. In particular, they are regular (both inner and outer) and finite on every compact set. Also, if $\mathscr{A}_\mu$ denotes the $\mu$-integrable sets, then $\mathscr{A}_\mu$ contains the topology of $\mathrm{X}$ (remark $\mu$ is a probability measure, so there are no issues of infinite measure here). In the main text the proof of the same statement is given for the convolution $\mu \ast f$ which is given by $$(\mu \ast f)(x) = \int\limits_\mathrm{G} f(s^{-1} x)\ d\mu(s).$$ I tried to immitate the proof, but the are problems that arise. The easiest way to illustrate this is when they show boundedness. For the case $\mu \ast f$ the author uses a well-known inequality and boundedness of $f$
$$|(\mu \ast f)(x)| \leq \int\limits_\mathrm{G} |f(s^{-1} x)|\ d\mu(s) \leq \|f\|,$$
since $\mu$ is a probability measure. Obviously, the same proof can't proceed for the convolution $f \ast \mu$ since one would get $$|(\mu \ast f)(x)| \leq \|f\| \int\limits_\mathrm{G} \Delta(s^{-1})\ d\mu(s)$$
and I don't think the modulus function is integrable. Any suggestions is greatly appreciated.","['locally-compact-groups', 'convolution', 'integration', 'measure-theory', 'haar-measure']"
2673937,Show that $|\det(A_n)|=n^{n/2}$,For k $\ge2$ we recursively define $A_{2^k}$ as $\begin{bmatrix} A_{2^{k-1}} & A_{2^{k-1}} \\ A_{2^{k-1}} & -A_{2^{k-1}} \end{bmatrix}$ and $A_1=[1]$ The problem is to show that $|\det(A_n)|=n^{n/2}$ My attempt: we do an induction on $k$ $|\det(A_2)|=2=2^{2/2}$. Induction hypothesis: $|\det(A_{n})|=n^{n/2}$ and we want to show that $|\det(A_{2n})|=(2n)^n$ using block matrix properties $|\det(A_{2n})|=|\det(\begin{bmatrix} A_{n} & A_{n} \\ A_{n} & -A_{n} \end{bmatrix})|=|\det(-A)\det(A+AA^{-1}A)|=|2^n\det(A_n)^2|=|2^nn^n|=(2n)^n$ Can somone confirm that there are no flaws in the reasoning please?,['matrices']
2673949,Infinitely Ramified Witt vectors,"The usual theory of ($p$-typical) Witt vectors gives an equivalence of categories $  \{ \text{strict $p$-rings} \} \to \{\text{perfect }\mathbb{F}_p \text{ algebras}  \}$.
Here a strict $p$-ring is a $\mathbb{Z}_p$ algebras $A$ that is $p$-torsion free, $p$-adically complete and such that $A/p$ is perfect. The functor is given by $A \mapsto A/p$ and the inverse functor is given by the Witt vectors $R \mapsto W(R)$. Now we can generalize this to the ramified case, we consider now $\mathbb{Z}[p^{1/p^n}]$-algebras $A$ such that $A/p^{1/p^n}$ is perfect (and $A$ is $p$-torsionfree and $p$-adically complete). Then there is an equivalence of categories $  \{ \text{strict $p^{1/p^n}$-rings} \} \to \{\text{perfect }\mathbb{F}_p \text{ algebras}  \}$. One direction is given by $A \mapsto A/p^{1/p^n}$ and the functor in the reverse direction is given by $R \mapsto W(R) \otimes_{\mathbb{Z}_p} \mathbb{Z}[p^{1/p^n}]$. My question is as follows: Can this be generalized to include the case $n=\infty$?. More precisely, consider the category $\mathcal{C}$ of $p$-adically complete and $p$-torsion free $\mathbb{Z}_p[p^{1/p^{\infty}}]^{\wedge}$ algebras $A$ such that $A/p^{1/p^{\infty}}$ is perfect. Is it then true that the reduction mod $p^{1/p^{\infty}}$ functor fully faithfull? The problem is defining a Teichmuller lift $[-]:A/p^{1/p^{\infty}} \to A$  (the usual construction is not well defined). Note that if we would have a Teichmuller lift then we could construct a map $W(A/p^{1/p^{\infty}}) \hat{\otimes}_{\mathbb{Z}_p} \mathbb{Z}_p[p^{1/p^{\infty}}]^{\wedge} \to A$, which is what I am actually interested in. PS: I am happy to assume that $A$ is in fact integral perfectoid. I know that in this case, tilting is the best way to go to perfect rings in characteristic $p$, but that doesn't seem to help me. I am trying to construct a section to the map $A/p \to A/p^{1/p^{\infty}}$, which is closely related to the above. A counterexample would be very interesting as well.","['algebraic-geometry', 'commutative-algebra']"
2673963,Find roots of a complex quadratic equation having one purely imaginary root,"Consider : $$P(z)= z^4 - 2z^3 + 6z^2 - 8z + 8$$ As the title says, find the roots of this complex quadratic equation having one purely imaginary root. I need help with this problem, i am new with the ''complex world''. 
This is what i thought: Given a complex number: $z= a + bi$ 
where $a,b\in\mathbb C$, we know $P(z)$ has a pure imaginary root, then:
 $$P(bi)= (bi)^4 - 2(bi)^3 + 6(bi)^2 - 8(bi) + 8= 0$$
But i am stuck in here, i dont know how to proceed or if reasoning was correct.
Any help would be helpful.","['complex-analysis', 'polynomials', 'complex-numbers']"
2673969,Does the interior angle for an optimized 2-field solution remain constant when going through N dimensions?,"This problem has been bugging me for literally a decade. I don't quite have the chops to solve it on my own. Let's start with the basic, 2-dimensional problem. You have 100 meters of fencing. You need to enclose two equal areas. What's the greatest area you can enclose? The trick is to realize that two squares aren't the answer, and the ""simple"" answer is a circle with a line through it. However, it turns out the ""Best"" answer is actually two partial circles fused together, creating a goggle-like effect. The interior angle for the part of the circle that's going to the fused middle line instead of circling around is 120 degrees. The math (It's been awhile, and I can't quite remember all of it) $$P = 2*R(Angle in Radians)+(R^2+R^2-2R^2Cos(Angle))$$
The perimeter of a partial circle, times 2, plus the length of the side, determined with the law of cosines. Formula isn't collapsed more to preserve the logic/ease of viewing. $$A= 2*(Area of two circles - area of a slice of circle + area of a triangle slice)$$ $$A= 2*(pi*R^2 - Angle/2*R^2 + area of a triangle slice)$$ When solving for 3 dimensions, you get 120 degrees again - two spheres fused with a circular plane between them. I've tried, and failed, quite a few times to generalize this solution into N-dimensions. I'm aware this is entirely impractical, but it's been driving me nuts for over 10 years at this point, and I'd love some help on it.","['circles', 'geometry']"
2673981,The exact value of an infinite sum $e^{-n^2}$,"Good morning! I'm having trouble with this problem... how can we find the exact value of
$$\sum_{n=0}^\infty e^{-n^2}.$$
Thank you in advance to anyone who can help.","['sequences-and-series', 'closed-form']"
2674012,Showing an identity between polynomials whose coefficients involve combinatorial identities,"I want to show that
$$
 \sum_{k=0}^{\lfloor n/2 \rfloor} \sum_{l=0}^{\lfloor \frac{n-2k}{2}\rfloor} (-1)^l \binom{n}{k} \binom{n-2k-l}{l} \frac{n-2k}{n-2k-l} x^{n-2k-2l} = x^n.
$$
If we ""compare coefficients"", then we get $x^n$ on the left if $k = l = 0$, hence 
$$
 \binom{n}{0} \binom{n}{0} \frac{n}{n} x^{n} = x^n
$$
is valid. But the other sums look quite messy...","['binomial-coefficients', 'polynomials', 'combinatorics', 'summation', 'discrete-mathematics']"
2674050,Why do all residues occur in this similar sequence?,"A formula similar to this coined in by Enzo Creti is gained as follows : Instead of concatenating the Mersenne numbers $M_n$ and $M_{n-1}$ , we do it in reverse. The formula for this sequence is $$f(n)=(2^{n-1}-1)\cdot 10^d+2^n-1$$ where $d$ is the number of digits in the decimal expansion of $2^n-1$ The first few $n$ giving a prime are $$[2, 3, 5, 6, 7, 9, 14, 26, 39, 41, 42, 46, 65, 161]$$ Now, if we note the residues of the primes modulo $7$ , all residues are present already (except $0$ of course). A coincidence ? Further primes occur for $n=342,662,959,1794,4211,8254$","['number-theory', 'prime-numbers', 'sequences-and-series', 'elementary-number-theory']"
2674071,"Name for the volume ""inside"" a torus?","If you have a standard ring torus, what's the name for the shape created by the empty space in the middle of the ring with the height equal to the height of the torus? For another explanation, it would be the resultant figure if you took a cube with height $h$, a cylinder with the diameter equal to $h$ and height equal to the circumference of a circle inscribed into one of the faces of the cube, and wrapped the cylinder around the cube such that the two faces of the cylinder touched. I apologize for the potentially confusing explanation, but any help is appreciated. EDIT: the planar figure to be rotated is basically this EDIT AGAIN: I believe the jelly donut metaphor is accurate, though I couldn't find any reference elsewhere to ""interior of solid torus"" Another Edit: After some more research, I have determined that it is possible a concave cylinder may appropriately describe it, but I'm not sure if it is plagued by the same issue as the hyperboloid (that is, the curves technically cannot perfectly fit the inside of a torus). Is this correct?","['terminology', 'general-topology', 'geometry']"
2674100,Can you place $15$ integers around a circle such that sum of every $4$ consecutive numbers is either $1 $ or $ 3$?,"I found this question in a Russian Olympiad book and has left me completely stupefied. Though I have done questions regarding abstract concepts like the Pigeon Hole principle, but still because I am new to such concepts I have been unable to even start thinking about the solution. The question goes like this: Can you place $15$ integers around a circle such that sum of every $4$ consecutive numbers is either $1 $ or $ 3$? The question puts no constraints over the distinctness of the integers and has been framed exactly in the same manner.","['combinatorics', 'pigeonhole-principle']"
2674102,$T$ has no eigenvalues,"Is the following Proof Correct? Given that $T\in\mathcal{L}(\mathbf{R}^2)$ defined by $T(x,y) =
 (-3y,x)$. $T$ has no eigenvalues. Proof. Let $\sigma_T$ denote the set of all eigenvalues of $T$ and assume that $\sigma_T\neq\varnothing$ then for some $\lambda\in\sigma_T$ we have $T(x,y) = \lambda(x,y) = (-3y,x)$ where $(x,y)\neq (0,0)$, equivalently $\lambda x = -3y\text{ and }\lambda y = x$. but then $\lambda(\lambda y) = -3y$ equivalently $y(\lambda^2+3) = 0$. The equation $\lambda^2+3 = 0$ has no solutions in $\mathbf{R}$ consequently $y=0$ and then by equation $\lambda y  = x$ it follows that $x=0$  thus $(x,y) = (0,0)$ contradicting the fact that $(x,y)\neq (0,0)$. $\blacksquare$","['eigenvalues-eigenvectors', 'linear-algebra', 'proof-verification']"
2674112,Is this an alternative definition of the Lebesgue integral?,"I am a complete beginner in measure theory and have only been reading Tao's notes on them for the past couple of days. Therefore what I say might be a triviality or just plain wrong. Anyway, Tao covers the Jordan measure, followed by the Lebesgue measure followed by the Lebesgue integral. His definition of the Lebesgue integral is stepwise, first defining it for simple functions and then approximating functions using these simple functions. This approach is a little complicated, for instance you have to show that the decomposition into simple functions is irrelevant and so on. However, given the definition of a Lebesgue measure, would the following also be a definition of the Lebesgue integral: For a function $f: \mathbb R^n \to \mathbb R$, define:
$$\int fd\mu = \mu(\overline\Gamma_+) - \mu(\overline\Gamma_-)$$
where:
$$\overline\Gamma_+ = \{(x,y) \in \mathbb R^n\times\mathbb R : y \in [0,f(x)], f(x) \geq 0\}$$
and similarly:
$$\overline\Gamma_- = \{(x,y) \in \mathbb R^n\times\mathbb R : y \in [0,f(x)], f(x) \leq 0\}$$ We will call $f$ Lebesgue integral if $\overline\Gamma$ is Lebesgue measurable. If $\mu$ is the Jordan measure, then it is not hard to see that this is simply the usual definition of the Riemann integral and is in fact, quite close to how we normally think about it. Is there any reason not to use this definition?","['lebesgue-measure', 'lebesgue-integral', 'measure-theory']"
2674130,Is this demonstration of Tubular Flow Theorem for Manifolds wrong?,"I'm studying Dynamical Systems using the book ""Geometric Theory of Dynamic Systems - J. Palis and W. de Melo"". On page 40, the author proposes to demonstrate the following theorem. Theorem (Tubular Flow) Let $M \subset \mathbb{R}^n$ be a $\mathcal{C}^{\infty}$-manifold of dimention $m$,   $X$ $\in$ $\mathcal{X}^r(M) = \{F: M \rightarrow \mathbb{R}^n$; $F(x)$ $\in$ $T_x M$ , $\forall x$ $\in$ $M$ and $F$ is a $\mathcal{C}^r$ function  $\}$, and $p$ $\in$ $M$ be a regular point of $X$ ( i.e. $X(p) \neq 0$). Let $C =  \{(x^1 , ..., x^m) \in \mathbb{R}^m; |x^i|<1 $ $\}$ and let $X_C$ be the vector field on $C$ definied by $X_c (x) = (1,0,...,0)$. Then there exists a $\mathcal{C}^r$ diffeomorphism $h: V_p \rightarrow C$, for some neighbourhood $V_p$ of $p$ in $M$, taking trajectories of $X$ to trajectories of $Xc$. Proof: My Doubt: Can someone explain to me why the function $h$ defined on the line underlined in red, take trajectories of $X$ to
  trajectories of $Xc$? I think that this is not true because $h^{-1} (t+x_1,x_2,...,x_m) = x^{-1} \circ \tilde{\psi} \circ f  (t +x_1, ... , x_m)$ is not a trajectory of $X$. In fact
\begin{align*}
\frac{d}{dt} h^{-1} (t + x_1 ,x_2 , ... ,x_m) &= \frac{d}{dt} \left(x^{-1} (\tilde{\psi} (f (t + x_1, x_2 ,...,x_m) ) \right)\\
&= D x^{-1}_{\tilde{\psi} (\varepsilon (t + x_1, x_2 ,...,x_m))} \cdot D \tilde{\psi}_{\varepsilon (t+ x_1, x_2 , ...,x_m)} \cdot \frac{d}{dt} f(t+x_1,x_2,...,x_m) \\
&=  D x^{-1}_{\tilde{\psi} (\varepsilon (t + x_1, x_2 ,...,x_m))} \cdot D \tilde{\psi}_{\varepsilon (t+ x_1, x_2 , ...,x_m)} \cdot (\varepsilon e_1) \\
&= \varepsilon D x^{-1}_{\tilde{\psi} (\varepsilon (t + x_1, x_2 ,...,x_m))}  \cdot \frac{d\tilde \psi}{dt} ( \varepsilon (t + x_1,x_2,...,x_m)\\
& = \varepsilon  D x^{-1}_{\tilde{\psi} (\varepsilon (t + x_1, x_2 ,...,x_m))}  \cdot x_* X(\tilde{\psi} ( \varepsilon(t+x_1,x_2,...,x_m)))\\
&= \varepsilon X(x^{-1} \circ \tilde{\psi} \circ f (t + x_1,x_2,...,x_m))\\
&= \varepsilon X( h^{-1} (t+x_1,x_2,...,x_m)) \neq X( h^{-1} (t+x_1,x_2,...,x_m)),\\
\end{align*}
where $x_* X(p) = Dx_{x^{-1} (p)} X(x^{-1}(p)).$ Keeping in mind the above calculation, why $h$ satisfies the conditions in the theorem?","['smooth-manifolds', 'ordinary-differential-equations', 'dynamical-systems']"
2674131,Differential equation solved by $y(x) = c_1e^x + c_2xe^x + c_3x^2e^x + c_4\cos(x) + c_5\sin(x)$,"Consider the following solution: $$y(x) = c_1e^x + c_2xe^x + c_3x^2e^x + c_4\cos(x) + c_5\sin(x)$$
  where all the $c_i$ are real constants ($c_i \in \Bbb R$).
  How to find a differential equation that have the previous solution? I re-wrote the solution to the following: $$y(x)=(c_1 + c_2x + c_3x^2)e^x + c_4\cos(x) + c_5\sin(x)$$ I can see that the solution looks like: $y(x) = Q(x)e^x + a\cos(x) + b\sin(x)$ where $Q$ is a second degree polynomial, but I don't really know how to take it from here.","['real-analysis', 'ordinary-differential-equations']"
2674164,Conditional Variance of the sum of two variables,"$\newcommand{\v}{\operatorname{Var}}\newcommand{\c}{\operatorname{Cov}}$I have a simple question that, after thinking for a while, got me confused and I cannot figure it out. Does the following statements hold? 1 $$ \v(A + B + C \mid \theta ) = \v(A \mid \theta) + \v(B + C \mid \theta) + 2 \c(A, B + C \mid \theta)$$ 2 $$ \c(A, B + C \mid \theta ) = \c(A, B \mid \theta) + \c(A, C \mid \theta)$$ I am not sure whether I can do these two steps above. Thanks","['statistics', 'probability', 'variance', 'covariance']"
2674205,What does this converge to and why?,"What does the below expression converge to and why?
  $$ \cfrac{2}{3 -\cfrac{2}{3-\cfrac{2}{3-\cfrac2\ddots}}}$$ Setting it equal to $ x $, you can rewrite the above as $ x = \dfrac{2}{3-x} $, which gives the quadratic equation $x^2 - 3x + 2 = 0 $, and the roots are $ 1 $ and $2 $, both positive. How do we know which to reject?","['roots', 'algebra-precalculus', 'continued-fractions', 'convergence-divergence', 'quadratics']"
2674263,Half quadratic splitting (alternating optimization with penalty),"Hello I'm working on an optimization problem: $$\hat{x}=\text{arg min}_{x} \frac{1}{2}\parallel y - Hx \parallel^{2} + \lambda \Phi (x), \quad x, y \in \mathbb{R}^{N\times M}.$$ where $H$ is a matrix and $\Phi$ an application. To solve this problem, my idea is to split in two subproblems like in ADMM ( http://stanford.edu/~boyd/papers/pdf/admm_distr_stats.pdf ). The problem of minimizating the before equation is equivalent to $$\hat{x}=\text{arg min} _{x} \frac{1}{2}\parallel y - Hx \parallel^{2} + \lambda \Phi (z)\quad \text{s.t.}\quad z=x, \qquad z, x \in \mathbb{R}^{N\times M}.$$ The method of HQS (half splitting quadratic) seeks to minizmize the following cost function: $$L_{\mu}(x,z) = \frac{1}{2}\parallel y-Hx\parallel^{2} +\lambda \Phi(z) + \frac{\mu}{2} \parallel z-x\parallel^{2}, \qquad z, x \in \mathbb{R}^{N\times M}, \mu\in\mathbb{R^{+}} .$$ And we apply the HQS method, that solves it iterativetely: \begin{equation}
 \left\{
 \begin{aligned}
 x_{k+1} &= \text{arg min} _{x} {\frac{1}{2}}\parallel {y-}Hx \parallel^{2} + \mu \parallel x-z_{k}\parallel^{2}, \\[1pt]
   z_{k+1} &= \text{arg min} _{z} \frac{\mu}{2} \parallel z-x_{k+1}\parallel^{2} + \lambda \Phi (z).
\end{aligned}
  \right.
\end{equation} My question is: Is this equivalent to the original problem? for convergence and obtaining a solution of the original problem, what do we have to supose about $\mu$? And the most important, which convergence results are there? Any textbook to learn this?","['functional-analysis', 'optimization', 'lagrange-multiplier']"
2674298,Constructing a function using the Schroeder-Bernstein Theorem,"I am trying to use the proof of the Schroeder-Bernstein theorem to construct a a bijection between $A = (0, 1)$ and $B = [0, 1]$. I need two injective functions to do so. 
My initial guess is that the bijective function, $h(x)$, will be a piecewise function. Looking at the proof, I think it's a good idea to trace the ancestry of  different numbers to attempt to construct a function. I'm given a hint suggesting me to trace the ancestry of $\frac{4}{9}$, and doing so, I get: $\frac{4}{9} = g(x) \rightarrow x = \frac{1}{3}$ $\frac{1}{3} = f(x) \rightarrow x = 0$ $0 = g(x) \rightarrow x = -3$, which is no longer in the interval, so I do not need to trace back any further. I am really unsure of how this helps me. I have the proof of the theorem, and I see the construction of the bijection say $h(a)$ equals $f(a)$ if $a$ has an oldest ancestor in $A$ or $a$ has no oldest ancestor, and $h(a) = b$ otherwise. I thought maybe finding two points and making a linear function could work, but I have no reason to think that $h(x)$ is linear. Any help is much appreciated.","['real-analysis', 'elementary-set-theory']"
2674317,Implications of the Borel-Cantelli Lemma,"I'm looking back at my book for my Real Analysis course, and the book (Royden & Fitzpatrick's Real Analysis , 4 ed.) gives the following for the definition of ""almost everywhere"" and the statement of the Borel-Cantelli Lemma, respectively: (1) For a measurable set $E$, we say that a property holds almost everywhere on $E$, or it holds for almost all $x\in E$, provided there is a subset $E_0$ of $E$ for which $m(E_0)=0$ and the property holds for all $x\in E \setminus E_0$. (2) The Borel-Cantelli Lemma $\quad$ Let $\{E_k\}_{k=1}^\infty$ be a countable collection of measurable sets for which $\sum_{k=1}^\infty m(E_k) \lt \infty$.  Then almost all $x\in\mathbb{R}$ belong to at most finitely many of the $E_k$'s. Now, my question is this:  Does this imply that, for instance, almost all $x\in\mathbb{R}$ belong to the interval $[0,1]$? I have reasoned as follows: Take $E_1 = [0,1]$ and $\{E_k\}_{k\ge2} = \emptyset$. Then $\sum_{k=1}^\infty m(E_k) = 1 + 0 + 0 + \cdots = 1 \lt \infty$. Thus the hypotheses of the Lemma are satisfied and we can conclude that almost all $x\in\mathbb{R}$ belong to $[0,1]$. However, I struggle to find an $E_0$ that satisfies the definition of almost all .  I mean that the property "" belongs to $[0,1]$ "" holds for almost all $x\in\mathbb{R}$ by the above, so by definition, there is a subset $E_0 \subseteq \mathbb{R}$ such that $m(E_0)=0$ and "" belongs to $[0,1]$ "" holds for all $x\in\mathbb{R}\setminus E_0$.  I also find this confusing because it would seem that in order for this to be true we would have to remove at least the set $(-\infty,0)\cup(1,\infty)$ from $\mathbb{R}$ to obtain a set of numbers contained in $[0,1]$, right? But then this set doesn't have Lebesgue measure zero, right?  Please let me know what I am missing here or what I am getting wrong. It seems that there is either something I am not understanding correctly or I have made a false statement somewhere.","['borel-cantelli-lemmas', 'real-analysis', 'lebesgue-measure', 'measure-theory']"
2674318,Uniform distribution Measure,"Assume $\mu$ is the $U([0,1]^2)$ defined by $$\mu([0,x]\times[0,y]=xy, \ (x,y) \in [0,1]^2$$ Show that $\mu$ assigns probability of $0$ to $\partial([0,1]^2)$ I tried to write each segment of the four segments of $\partial([0,1]^2)$ as a Cartesian product of two sets $[0,1]\times[0,1]$ to be able to use the definition?","['product-space', 'uniform-distribution', 'probability-theory', 'elementary-set-theory']"
2674323,Distribution of Conditional Bernoulli Random Variable,"Let $X_i\sim \mathcal{Poisson}(\lambda)$, where $X_i$ come from a random sample of size $n$ (so they're independent and identically distributed).  Let $T=I\lbrace X_1=0 \rbrace$ (indicator function); that is, $T\sim \mathcal{Bernoulli}(e^{-\lambda})$. Now define $B=\sum_{i=1}^nX_i$.  This implies $B\sim\mathcal{Poisson}(n\lambda)$.  Using this information, what is the distribution of the conditional random variable: $$T\mid_{B=b}$$ That is, what is the distribution of $T$ given that $B=b$?","['probability-theory', 'probability', 'statistics', 'probability-distributions']"
2674338,Proof of product rule for limits,"Let $$\lim_{x \to a} f(x) = L$$ $$\lim_{x \to a} g(x) = M$$ Where $L$ and $M$ are finite reals. Then I want to prove that $$\lim_{x \to a} f(x) g(x) = LM$$ Let $\epsilon > 0$. We need a $\delta > 0$ such that for all $x$ we have $0 < |x-a| < \delta$ implying $|f(x)g(x) - LM| < \epsilon$. Rearrange: $$\begin{align}|f(x)g(x)-LM|&=|f(x)g(x)-Lg(x)+Lg(x)-LM|\\
&=|g(x)(f(x)-L)+L(g(x)-M)|\\
&\le|g(x)||f(x)-L|+|L||g(x)-M| \\
&\lt|g(x)||f(x)-L|+(|L| + 1)|g(x)-M| < \epsilon\end{align}$$ Since the limits for $g(x)$ and $M$ approach the same value $M$, there exists a $\delta_1 > 0$ such that for all $x$, $0 < |x-a| < \delta_1$ implies $|g(x) - M| < \frac{\epsilon}{2(|L|+1)}$. Then: $$\begin{align}|f(x)g(x)-LM| &\lt |g(x)||f(x)-L|+(|L|+1)|g(x)-M|\\
&<|g(x)||f(x)-L|+(|L|+1)\frac{\epsilon}{2(|L|+1)}   \\
&=|g(x)||f(x)-L|+\frac{\epsilon}{2}  = \epsilon \\
\end{align}$$ Since the limits for $f(x)$ and $L$ approach the same value $L$, there exists a $\delta_2 > 0$ such that for all $x$, $0 < |x-a| < \delta_2$ implies $|f(x) - L| < \frac{\epsilon}{2(|M|+1)}$. Then: $$\begin{align}|f(x)g(x)-LM| &\lt |g(x)||f(x)-L|+\frac{\epsilon}{2} \\
&<|g(x)|\frac{\epsilon}{2(|M|+1)}+\frac{\epsilon}{2} = \epsilon \\
\end{align}$$ Now we prove $|g(x)| \leq |M|+1$: $$|g(x)| = |g(x) - M + M| \leq |g(x) - M| + |M| \leq |M|+1$$ Subtracting $|M|$ from both sides, we see that: $$|g(x) - M|  \leq 1$$ Since the limits for $g(x)$ and $M$ approach the same value $M$, there exists a $\delta_3$ such that for all $x$, $0 < |x-a| < \delta_3$ implies $|g(x) - M| < 1$. $$\begin{align}|f(x)g(x)-LM| &\lt |g(x)|\frac{\epsilon}{2(|M|+1)}+\frac{\epsilon}{2} \\
&< (|M|+1)\frac{\epsilon}{2(|M|+1)}+\frac{\epsilon}{2} \\
&= \frac{\epsilon}{2}+\frac{\epsilon}{2} = \epsilon \\
\end{align}$$ This is true granted that we set $\delta = \min(\delta_1, \delta_2, \delta_3)$. Is my proof correct and accurate? Have I actually proved the rule?","['limits', 'proof-verification', 'calculus', 'epsilon-delta', 'proof-writing']"
2674352,Proving the boundary of a disc is a circle,"As the title suggests, I already know that the boundary of a disk is the circle with the same radius, but what I'm interested in is actually proving that fact. I recently got around to the section of my topology book that deals with closure, interior, and boundaries of a subset and I've been having a great deal of trouble actually finding any of these for a given subset. I know what they are, but actually finding these things for a given subset is fairly difficult for me. I want to emphasize that when I say it's difficult, I don't mean that I have no idea what they are in reference to that subset, but that I don't know how to rigorously find them or prove one set is the closure/boundary/interior of the other. I used the disk with circular boundary mostly as a springboard example, if you know of another example which may elucidate this a little more, feel free to use that one. I'm aware there is no one process that will definitely find it every time, but if there is some way of thinking about the question that can help make it a little easier or some useful theorems to aid in finding these things then I'd be immensely grateful.","['examples-counterexamples', 'general-topology', 'proof-writing']"
2674370,Deck of 5 cards Shuffling Problem but only allowed to choose two adjacent cards,"Say I have a deck of 5 cards that are labeled 1, 2, 3, 4, 5. 1 being at the top and 5 being at the bottom. The rules of this game are as follows. You can take only take two adjacent cards (1 2, 2 3, 3 4, or 4 5) and insert them anywhere else in the stack. For example I could take the 1 2 out and put it in between 4 and 5 to make the deck look like 3 4 1 2 5. I cannot change the order of the two adjacent cards I take out and reinsert. With the deck 3 4 1 2 5, I can take for example, the 2 5 and move it to the front to make 2 5 3 4 1. The question is as follows: I use the above rule starting with the deck 1 2 3 4 5. If I use this ""shuffle"" maneuver as many times as I would like, is it possible to get to the deck 2 1 3 4 5. I ran a computer program and it said this isn't possible. In fact I noticed that there were 60 decks possible starting with 1 2 3 4 5. I can't seem prove this without blindly listing all decks. Is there a way to prove that 1 2 3 4 5 cant get to 2 1 3 4 5?","['permutations', 'combinatorics', 'card-games']"
2674385,Can $A^3=0$ imply $|I+A|=0$?,"Suppose $A$ is a non-zero matrix such that $A^3=0$ . Prove the following assertions or provide counter examples:- $(1) A^2$ is a zero matrix $(2) A+A^2$ can have zero trace $(3) A-A^2$ can have zero trace $(4) I+A$ is  singular. My Attempt :- I know if $A^3=0$ then $A^2=0$ can be true (though not always). I have no idea whether $tr(A+A^2)=0$ or $tr(A-A^2)=0$ is possible or not if $A^3=0$ . But when I looked closely at $|I+A|$ then I found that $$|I+A|=0$$ For $2\times2$ matrix, we have $$\Rightarrow |A|+tr(A)+1=0 $$ $$\Rightarrow \lambda_1\lambda_2+\lambda_1+\lambda_2+1=0 $$ where $\lambda_1$ and $\lambda_2$ are the two eigenvalues of $A$ $$\Rightarrow \lambda_1(\lambda_2+1)+1.(\lambda_2+1)=0 $$ $$\Rightarrow (\lambda_2+1)(\lambda_1+1)=0 $$ $$\Rightarrow \lambda_2=-1, \lambda_1=-1  \tag1$$ But we have $$A^3=0$$ $$\Rightarrow |A^3|=0$$ $$\Rightarrow |A|^3=0$$ $$\Rightarrow |A|=0$$ So,
either $\lambda_1=0$ or $\lambda_2=0$ (or both may be zero) which contradicts with equation $(1)$ . So, $I+A$ is non singular. Am I Correct ?","['matrices', 'linear-algebra', 'determinant']"
2674423,How to deal with the partial inverse of a two-variable function?,"Let $E$ be a Banach space consisting of some kinds of functions from $\mathbf R^n$ to $\mathbf R^m$. Given a two-variable function $f:\mathbf R^m\times\mathbf R^n\to\mathbf R^m$. Suppose that $f\in C(\mathbf R^m;E)$, and for any $y\in\mathbf R^n$, the function $f(\cdot,y):\mathbf R^m\to\mathbf R^m$ is bijective whose inverse is denoted as $g(x,y)=f(\cdot,y)^{-1}(x)$. Suppose also that for any $x\in\mathbf R^m$, $g(x,\cdot)\in E$. Question: Does $g$ also belong to $C(\mathbf R^m;E)$? I think the answer is negative in general. But does that hold true for some special cases such as $E=C^k(\mathbf R^n;\mathbf R^m)$ or $E=C^\alpha(\mathbf R^n;\mathbf R^m)$ or $E=L^p(\mathbf R^n;\mathbf R^m)$? Actually I have no idea to deal with the 'partial' inverse... Could anyone give some hints or comments? TIA...","['real-analysis', 'partial-differential-equations', 'calculus', 'functional-analysis', 'analysis']"
2674447,Is there any geometry behind the Basel problem?,"I could find many beautiful and rigorous proofs for Euler's solution to the Basel problem here Different methods to compute $\sum\limits_{k=1}^\infty \frac{1}{k^2}$ (Basel problem) But I am curious to know whether there are proofs by using geometry. If anyone has proofs by geometry, please do share it with us.","['big-list', 'algebraic-geometry', 'riemann-zeta', 'geometry', 'sequences-and-series']"
2674490,Prove that any nonempty open set of $\mathbb R$ is uncountable,"I am having a little trouble trying to prove that any nonempty open set in $\mathbb{R}$ is uncountable. Here is what I have so far: Let $A$ be a nonempty subset of $\mathbb{R}$. Then for each $x \in A$, there exists an open interval $I=(a,b)$ such that $x \in I \subseteq A$. ... Since I is uncountable and $I \subseteq A$, it follows that $A$ is uncountable. I am trying to fill in the ... by showing that the open interval $(a,b)$ is uncountable. I am familiar with Cantor diagonalization and I've used it to prove that $(0,1)$ is uncountable, but I am unsure of how to set up a Cantor diagonal when I don't know what the boundaries of the interval are. I've read suggestions on other questions to set up a bijection from $(0,1)$ to $(a,b)$ but I'm not sure how to go about that either.","['real-analysis', 'elementary-set-theory']"
2674504,"Any two complex square matrices are triangulable in the same basis, albeit perhaps in different orders","Let $E$ be a finite-dimensional vector-space on $\mathbb C$.
Take any $a$, $b$ endomorphisms of $E$. Show there exist a basis $(e_1, ... e_n)$ and a permutation $\sigma$
  such that the matrix of $a$ in $(e_1, ... e_n)$ and the matrix of $b$
  in $(e_{\sigma(1)}, ... ,e_{\sigma(n)})$ are upper-triangular. Here some thoughts. Induction does not seem appropriate. Let $(a_1, ... a_n)$ be a triangular basis for $a$ and $(b_1, ... b_n)$ be a triangular basis for $b$. The first step is easy: take $a_1$ as $e_1$ which is an eigen-vector of $a$ and $b_1$ an eigen-vector of $b$. One can choose $i$ such that $b_1 = e_i$ chossing $i \neq 1$ minimal. Then $Vect(e_1, a_2, ... , a_{i-1}, e_i) \cap Vect(b_2,...b_n) \neq$ $\{0_E\}$ So let $x$ in  this intersection. $x$ can be colinear to $e_1$ ...","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra', 'vector-spaces']"
2674539,What is the geometric intuition behind algebraic multiplicity?,"The algebraic multiplicity of an eigenvalue $\lambda$ is the number of times $\lambda$ appears as a root of the characteristic polynomial. The geometric multiplicity of an eigenvalue $\lambda$ is dimension of the eigenspace of the eigenvalue $\lambda$. Let us consider the linear transformation $T:\Bbb R^3 \to \Bbb R^3$ for simplicity. Suppose the characteristic polynomial of $T$ has the eigenvalue $\lambda$ as a repeated root, $2$ times. For example, if the eigenspace of the eigenvalue $\lambda$ were a line (one-dimensional), we could visualize $T$ as the transformation squishing or stretching all vectors on that line by an amount $\lambda$. But what is the geometric significance of the algebraic multiplicity $2$, in this case? Is there any underlying geometric intuition?","['linear-algebra', 'linear-transformations']"
2674544,Connectedness of the Graph of $\frac{1}{x}$ and the $y$-axis,"Consider the topological space $G \cup Y,$ where $G = \{(x, \frac{1}{x}) \,:\, \mathbb{R} - \{0 \} \}$ and $Y = \{(0,y) \,:\, y \in \mathbb{R} \}$ with the subspace topology inherited from $\mathbb{R}^2.$ I am interested in whether or not this space is connected. Earlier, I convinced myself -- with the help of two colleagues -- that this space is indeed connected; however, our professor provided this proof that it is not connected. Claim. $G \cup Y$ is not connected. Proof. Consider the subsets $P = \{(x,y) \,:\, xy < \frac{1}{2} \}$ and $Q = \{(x,y) \,:\, xy > \frac{1}{2} \}$ of $\mathbb{R}^2.$ We note that both $P$ and $Q$ are open in $\mathbb{R}^2.$ Furthermore, we have that $G \subset Q$ since $xy = 1$ in $G$ and $Y \subset P$ since $xy = 0$ in $Y.$ We have therefore that $G \cup Y = (Q \cap G) \cup (P \cap Y)$ gives a nontrivial decomposition of the space $G \cup Y$ into clopen subsets, hence $G \cup Y$ is not connected. But I cannot fathom why these intersections are clopen. From what I can tell, $Q \cap G$ is simply $G,$ and $P \cap Y$ is simply $Y.$ Furthermore, $G$ does not appear to be closed since it does not possess its limit points of $\pm \infty,$ and $Y$ does not appear to be open since its complement in $G \cup Y$ is not closed. Could someone provide some insight into whether or not this space is connected?","['general-topology', 'connectedness']"
2674547,chi squared divergence and Kullback Leibler divergence,"$\def\KL#1#2{\operatorname{KL}(#1 \| #2)}$ $\def\chisq#1#2{\operatorname{\chi^2}(#1 \| #2)}$ I am asked to prove that given two discrete random variables (or probability measures) $P \ll Q$ i.e. $P$ is absolutely continuous with respect to $Q$ (so that the Radon-Nikodym derivative is just $\frac{P(x)}{Q(x)}$ where defined. We will call this $g(x)$ ), we have $\KL P Q \leq \chisq P Q$ where both are defined. The definitions are: $\KL P Q  = \mathbb E_Q[g(x) \ln g(x)]$ , and $\chisq P Q = \mathbb E_Q[(g(x) - 1)^2]$ . Now, one way of proving the inequality is to show $(y-1)^2 \geq y \ln y$ everywhere on $[0,\infty)$ , since this is the range of $g$ . However, this is not true, for example with $y = 2$ . So this makes me wonder if what I have got is wrong. Is it not possible that I can find $P$ and $Q$ such that $g$ is supported in  the region where the inequality above does not hold, so that I can get a counterexample? I know I am doing something very wrong here, something very silly. I would like to be pointed out what I am doing incorrectly.","['probability-theory', 'probability']"
2674562,Prove $a^{\log_bc}=c^{\log_ba}$,"Can anyone prove
$$a^{\log_bc}=c^{\log_ba}$$
I've tried using algebra but I always get $a=a$ $c=c$ or $b=b$. Sometimes I get the same property but now flipped. Can anyone help?","['algebra-precalculus', 'logarithms', 'exponential-function']"
2674585,Sufficiency and Completeness of Gamma Random Variable for Normal Distribution,"Let $X\sim N(0,\theta)$ for $\theta>0$.  Show that $X^2$ is complete and sufficient for $\theta$.  I assume this is referring to $\theta$ as the variance of $X$. I'm unsure of how to show sufficiency in this context.  I assumed that I would take the likelihood function of $X$ and divide it by the PDF of $X^2$ (where $X^2\sim GAM(\frac{1}{2},2\theta)$), but when I take that ratio $\theta$ is still leftover in the expression, suggesting that $X^2$ is NOT sufficient; but since that's what I'm supposed to show, clearly I'm doing something wrong.  So I'm not sure how I'm supposed to show sufficiency.  I'm sure it's simple, but I'm just not seeing it.","['probability-distributions', 'statistics', 'probability', 'sufficient-statistics', 'random-variables']"
2674594,How to generate a matrix group with two generators?,"Let $\text{GL}(n,q)$ denote the group of all the invertible $n$ by $n$ matrices over finite field $\mathbb{F}_q$. $\text{GL}(n,q)$ be generated by two elements for all $n>2$. See here . Now my first question is: Given two elements $A$, $B$ in $\text{GL}(n,q)$, how to generate the
  group $G=\langle A, B \rangle$ ? Can we find out all the maximal subgroups of $\text{GL}(n,q)$ ? It seems this question may be to hard. See here . Thanks for provide any information about the first question. Then the second question is: Let $n=2$, $q=5$.  Denote $${\displaystyle A={\begin{pmatrix}1 & 3 \\
 3 & 0 \end{pmatrix}}}\in \text{GL}(n,q),  {\displaystyle
 B={\begin{pmatrix}4 & 4 \\ 1 & 0 \end{pmatrix}}}\in \text{GL}(n,q).$$
  Please compute all the elements in $\langle A, B \rangle$. By the computation in magma software, $|\langle A, B \rangle|=|\langle A \rangle| \times |\langle B \rangle|$, where $|\langle A \rangle|=6$ and $|\langle B \rangle|=3$. It's special case. So my third question is: Let $n=2$, $q=7$.  Denote $${\displaystyle C={\begin{pmatrix}6 & 6 \\
 1 & 0 \end{pmatrix}}}\in \text{GL}(n,q),  {\displaystyle
 D={\begin{pmatrix}4 & 4 \\ 0 & 2 \end{pmatrix}}}\in \text{GL}(n,q).$$
  Please compute all the elements in $\langle C, D \rangle$. In the third question, it has $|\langle C, D \rangle| \ne|\langle C \rangle| \times |\langle D \rangle|$. $|\langle C \rangle|=3$ and $|\langle D \rangle|=3$ while $|\langle C, D \rangle|=24$. Thanks for any replies.","['matrices', 'finite-fields', 'group-theory', 'finite-groups']"
2674598,Curvature of sub-bundles,"I'm confused by the following statement in complex differential geometry: Let $E$ be a holomorphic vector bundle and let $E'$ be a holomorphic sub-bundle. Fix a unitary connection $\nabla$ on $E$ associated to some hermitian metric. We can compare the curvature $F_{\nabla}$ on $E$ to the curvature of the connection $\nabla'$ on the sub-bundle obtained by orthogonal projection with respect to the metric. The statement I am confused by is that $F_{\nabla'} \leq F_{\nabla}.$  I.e. ""curvature decreases in holomorphic sub-bundles"".  This statement can be found in Griffiths and Harris, and in many other standard sources. I am confused for the following reason: Consider the inclusion of vector bundles on $\mathbb{C} P^1$: $0 \to O(1) \to O(1) \oplus O(-1).$ Since curvature is proportional to the first Chern class, and $c_1(O(1))> c(O(1) \oplus O(-1))=0,$ this seems to contradict the above principle. What am I misunderstanding? Note: I thought initially that my confusion was due to some normalization, but since one can also consider $0 \to O(-1) \to O(1) \oplus O(-1),$ it seems like my confusion is due to something else.","['complex-geometry', 'differential-geometry', 'algebraic-geometry']"
2674608,Use Rao-Blackwell Theorem to find the UMVUE,"Suppose that $X_1,X_2,...,X_n$ is a random sample from a normal distribution, $X_i\sim N(\mu,9)$. Find the UMVUE (uniformly minimum variance unbiased estimator) of $P(X\le c)$ where $c$ is a known constant.  Do this by finding the conditional distribution of $X_1$ given $\bar{X}={\bar{x}}$ and apply the Rao-Blackwell theorem with $T=u(X_1)$, where $u(x_1)=1$ if $x\le c$ and zero otherwise. So clearly the parameter that we're trying to estimate given the problem description can be written as $\Phi\left( \frac{c-\mu}{3} \right)$ where $\Phi$ represents the CDF of the standard normal distribution.  However, I get stuck when I need to try and find the conditional distribution.  Without knowing the joint distribution or the other conditional distribution, how can I possibly find the conditional distribution of $X_1$ given $\bar{X}={\bar{x}}$?","['statistical-inference', 'normal-distribution', 'statistics', 'probability', 'parameter-estimation']"
2674618,Why is it contradicting?,"Let $P$ and $Q$ be functions of $r$ and $r$ be a function of $(x,y,z)$. Also let $f$ be a function of $(x,y)$. If:
$$P(x,y,z) + f (x,y)= Q(x,y,z) \tag{1} $$
By $(1)$
$$\dfrac{\partial P}{\partial x}  \neq \dfrac{\partial Q}{\partial x} \Rightarrow \dfrac{dP}{dr} \dfrac{\partial r}{\partial x} \neq
\dfrac{dQ}{dr} \dfrac{\partial r}{\partial x}\Rightarrow \dfrac{dP}{dr} \neq \dfrac{dQ}{dr}  \tag{2} $$
Also by $(1)$
$$\dfrac{\partial P}{\partial z}  = \dfrac{\partial Q}{\partial z}\Rightarrow \dfrac{dP}{dr} \dfrac{\partial r}{\partial z} =
\dfrac{dQ}{dr} \dfrac{\partial r}{\partial z} \Rightarrow \dfrac{dP}{dr} =
\dfrac{dQ}{dr}  \tag{3}$$ $(2)$ and $(3)$ contradict. Why is this so?","['multivariable-calculus', 'partial-derivative', 'chain-rule', 'calculus']"
2674660,Learning a point on the sphere using signs of dot products,"An unknown point $x$ is fixed on the unit sphere in $\mathbb{R}^n$ and we iterate as follows: at each step, specify a unit vector $v\in \mathbb{R}^n$ and record $\mathrm{sign}(x\cdot v).$ The goal is to design a strategy for specifying $x$ to within the smallest ball with the fewest possible steps. With the first step you learn which of two hemispheres $x$ is in. The next step can get you to within a quarter, the next $1/8,$ and so on. With each step you are capable of cutting in half the region $x$ can be in. A natural strategy to get a well-localized region is to first fix an orthonormal basis for $\mathbb{R}^n$ and cycle through it, each step slicing the region along the corresponding basis element's direction.  After $\ell$ steps, $x$ will be known to within a simplex with area $\propto 2^{-\ell}$ . But what is the size of the ball for this strategy? Is there a better strategy?","['geometric-probability', 'spherical-geometry', 'linear-algebra', 'geometry']"
2674677,$|G|<\infty$ and $|X|<\infty$ a $G$-set $\Rightarrow \bigcap_{g \in G}Fix(g)\not= \emptyset$,"Question Let $G$ a finite group with $|G|=p^n$ for a prime $p$,and $|X|<\infty$ a $G$-set.If $p\not| |X|$ then show that $$\bigcap_{g \in G}Fix(g)\not= \emptyset$$ Attempt I know that the number of orbits of $G$ in $X$ are $$N=\dfrac{1}{|G|}\sum_{g\in G}|Fix(g)|$$ Also that $|G|=p^n \Rightarrow Z(G)\not=\{1_G\}$ but can't put them together.Any hints?","['finite-groups', 'abstract-algebra', 'group-theory', 'group-actions']"
2674684,Continuity of $T \mapsto \pi_{\operatorname{ker}T}$ w.r.t. the SOT,"I came across the following technical question, to which I could not - after some time of thinking - find an answer: Let $\mathcal{U},\mathcal{H}$ be two real (in general infinite dimensional) separable Hilbert spaces. For some linear subspace $\bar{U} \subseteq \mathcal{U}$, let $\Pi_U$ denote the orthogonal projection on this subspace. The question is: Is the mapping $T \mapsto \Pi_{\operatorname{ker}T}$ continuous from $L(\mathcal{U},\mathcal{H})$ to $L(\mathcal{U})$ when both spaces are endowed with the strong operator topology? Any hints and thoughts on this are more than appreciated!","['functional-analysis', 'continuity', 'operator-theory']"
2674702,Convex conjugate of a function?,"The conjugate of a function $f$ is
$$f^*(y)=\sup_{x\in \mathop{\rm dom} f} (\left< y,x\right> - f(x)).$$ Let $f(x)=\frac{1}{2}\left< Ax,x\right>+\left< b,x\right>+c$ on open set $\Omega$ of $\mathbb R^n$, where $A$ is a definite positif symmetric matrix. I showed that $f$ is convex function. Now, I would like compute the conjugate function $f^*(y)$ of $f$? For this, I will calculate the derivative of the function $$g(x)=\left< y,x\right> - f(x) = \left< y,x\right> -\frac{1}{2}\left< Ax,x\right>-\left< b,x\right>-c$$ with respect to $x$, for find its maximum.  So, the derivative of $\left< y,x\right>$ is $y$ and the derivative of $-\left< b,x\right>-c$ is $-b$, but what it the derivative of $\left< Ax,x\right>$ ? Remark: In a pdf I found that: $f^*(y)= \frac{1}{2} \left< y-b, A^{-1}(y-b)\right>-c$. Thank you in advance","['functional-analysis', 'real-analysis', 'convex-analysis']"
2674756,Charpit method: non-linear PDE,"I have a question: $$p^{2}x+q^{2}y = z.$$ I formed the Charpit auxiliary equation as follows $$ \frac{\mathrm{d}x}{2px} = \frac{\mathrm{d}y}{2py} = \frac{\mathrm{d}z}{2(p^2x + q^2y)} = \frac{\mathrm{d}p}{p-p^2} = \frac{\mathrm{d}q}{q-q^2}.$$ After forming the equation I was unable to solve further (I applied everything I was taught). So I did some research (checked several books, and on the website as well) and found the next step to be $$\frac{p^2\,\mathrm{d}x + 2px\,\mathrm{d}p}{p^2x} = \frac{q^2\,\mathrm{d}y + 2qy\,\mathrm{d}q}{q^2y}. \tag{1}$$ After which I was able to solve. But I can not understand how they derived the relation (1). Can someone explain what method they applied here? Disclaimer: The course we are being taught is engineering mathematics.","['characteristics', 'ordinary-differential-equations', 'nonlinear-system', 'partial-differential-equations']"
2674796,A natural transformation between the categories $\pi_1X$ and $\pi_1Y$,"Let $\mathscr{C}$ and $\mathscr{D}$ be categories and let $F_0,F_1$ be covariant functors $\mathscr{C}\to \mathscr{D}$. A natural transformation $\alpha:F_0\to F_1$ is a collection $\alpha=\left \{\alpha_A:A\in \text{obj } \left (\mathscr{C}\right )\right \}$ such that $\alpha_A\in \hom_{\mathscr{D}}\left (F_0A,F_1A\right )$ and for every $f\in \hom_{\mathscr{C}}\left (A,B\right )$ we have $F_1\left (f\right )\alpha_A=\alpha_BF_0\left (f\right )$. If $X$ is a topological space, then $\pi_1X$ is a grupoid. It is a category whose objects are the elements of $X$ and the morphisms between two objects $x,y\in X$ are the paths that join $x$ to $y$ modulo path homotopies. Therefore, every morphism is an equivalence. If $f:X\to Y$ is a continuous function, then $f_{\ast}:\pi_1X\to \pi_1Y$ is a functor which sends every $x\in X$ to $f\left (x\right )$ and every $\left [\alpha\right ] \in \hom_{\pi_1X}\left (x,y\right )=:\pi_1\left (X;x,y\right )$ to $\left [f\alpha\right ]\in \pi_1\left (Y;f\left (x\right ),f\left (y\right )\right )$. Observe that if $x=y$ then we have the usual group homomorphism $f_{\ast}:\pi_1\left (X,x\right )\to \pi_1\left (Y,f\left (x\right )\right )$. I have to prove the following assertion: Let $f_0,f_1:X\to Y$ be continuous functions and let $H:X\times I\to Y$ (where $I=\left [0,1\right ]$) be an homotopy between $f_0$ and $f_1$. In other words, $H$ is continuous and $H\left (x,i\right )=f_i\left (x\right )$ for every $i\in \left \{0,1\right \}$. Then $H$ induces a natural transformation $\left (f_0\right )_{\ast}\to \left (f_1\right )_{\ast}$. This is my attempt, it is not concluding: For every $x\in X$ define $H_x:I\to Y$ such that $H_x\left (t\right )=H\left (x,t\right )$. Then $H_x\left (i\right )=f_i\left (x\right )$ for every $i\in \left \{0,1\right \}$. Therefore $\left [H_x\right ]\in \pi_1\left (X;f_0\left (x\right ),f_1\left (x\right )\right )$. I want to prove that $\left \{\left [H_x\right ]:x\in X\right \}$ is our natural transformation. In order to prove that, we take $x,y\in X$ and $\left [\omega\right ]\in \pi_1\left (X;x,y\right )$. I would be done if I were able to prove that $H_x\ast f_1\omega$ is path homotopic to $f_0\omega \ast H_y$, but at this step I got stuck. How would you prove that those functions are path homotopic?","['algebraic-topology', 'category-theory', 'general-topology']"
2674811,Prove $f'(\frac{x_1+2x_2}3)<1-a$ for two zeros $x_1<x_2$ of $f(x)=\ln x+x-ax^2$,"Let $f(x) = \ln x + x - ax^2$, where $a > 0$. Suppose $x_1 < x_2$ are two zeros of $f(x)$, prove that$$
f'\left( \frac{x_1 + 2x_2}{3} \right) < 1 - a.
$$ My try: Denote $x_3 = \dfrac{x_1 + 2x_2}{3}$. From $f(x_1) = f(x_2) = 0$, there is$$
\frac{\ln x_1 + x_1}{x_1^2} = \frac{\ln x_2 + x_2}{x_2^2} = a.
$$
Also,$$
f'(x) = \frac{1}{x} + 1 - 2ax.
$$
Thus\begin{align*}
&\mathrel{\phantom{\Longleftrightarrow}} f'(x_3) < 1 - a \Longleftrightarrow 2ax_3^2 - ax_3 - 1 > 0 \Longleftrightarrow ax_3 (2x_3 - 1) > 1\\
&\Longleftrightarrow \left( \frac{1}{3} ax_1 + \frac{2}{3} ax_2 \right) \left( \frac{2}{3} x_1 + \frac{4}{3} x_2 - 1 \right) > 1\\
&\Longleftrightarrow \left( \frac{1}{3} \frac{\ln x_1 + x_1}{x_1} + \frac{2}{3} \frac{\ln x_2 + x_2}{x_2} \right) \left( \frac{2}{3} x_1 + \frac{4}{3} x_2 - 1 \right) > 1\\
&\Longleftrightarrow \left( \frac{\ln x_1}{x_1} + \frac{2\ln x_2}{x_2} + 3 \right) (2x_1 + 4x_2 - 3) > 9.
\end{align*} Then I tried to prove the last inequality for arbitrary $x_1 < x_2$, but the expression has gotten really complicated so far and the logarithm terms make it even worse to handle. Is there a better approach to this question? Thanks in advance. Edit: From the comment of @MartinR and some experiment with the graph of $f$, it seems promising to prove that $0 < a < 1$ and $f'\left( \dfrac{x_1 + 2x_2}{3} \right) < 0$. Furthermore, it also seems true that $f'\left( \dfrac{x_1 + x_2}{2} \right) < 0$, which is stronger than the original inequality to be proved in that $f'$ is decreasing. So it needs proving that$$
f'\left( \frac{x_1 + x_2}{2} \right) = \frac{2}{x_1 + x_2} + 1 - a(x_1 + x_2) < 0.
$$
Any ideas?","['derivatives', 'inequality']"
2674872,Significance of an interval for an ODE,"Question Find all the solutions for the equation 
$$y'(x)+y(x)=\int_0^x y(t) dt$$
defined on $[0,1]$. Attempt I have calculated the complete solution as 
$$y(x)=Ae^{\frac{-1+\sqrt5}{2}x}+Be^{\frac{-1-\sqrt5}{2}x}$$
However, I cannot figure out what to do with the provided interval since the equation make sense for all values of $x$ in $(-\infty,\infty)$. Can somebody explain what the question intends me to do with the interval? Edit As seen by answers below I have realised the interval acts provides the initial. Proceeding under the provided information, I got the answer as follows $$y'(0)=-y(0)$$
$$y(0)= Ae^{0}+Be^{0}=A+B$$ $$y'(0)= \frac{-1+\sqrt5}{2}Ae^{0}+\frac{-1-\sqrt5}{2}Be^{0}= \frac{-1+\sqrt5}{2}A+\frac{-1-\sqrt5}{2}B$$ $$-\left( \frac{-1+\sqrt5}{2}A+\frac{-1-\sqrt5}{2}B \right)=A+B$$ $$\frac{1-\sqrt5}{2}A+\frac{1+\sqrt5}{2}B =A+B$$ $$\frac{-1-\sqrt5}{2}A=\frac{1-\sqrt5}{2}B $$
$$\frac{1+\sqrt5}{2}A=\frac{-1+\sqrt5}{2}B $$
$$A=\frac{-1+\sqrt5}{1+\sqrt5}B $$ Inputting this in the final equation $$y(x)=\frac{-1+\sqrt5}{1+\sqrt5}Be^{\frac{-1+\sqrt5}{2}x}+Be^{\frac{-1-\sqrt5}{2}x} = B\left(\frac{-1+\sqrt5}{1+\sqrt5}e^{\frac{-1+\sqrt5}{2}x}+e^{\frac{-1-\sqrt5}{2}x} \right)$$ Is this correct?",['ordinary-differential-equations']
2674899,"In one roll of four standard six-sided dice, what is the probability of rolling exactly three different numbers?","In one roll of four standard six-sided dice, what is the probability of rolling exactly three different numbers? My answer: $6\cdot5\cdot4$ to get 3 numbers, then the 4th dice will have to be one of the previous 3 numbers, so it's $6\cdot5\cdot4\cdot3$; the total possibilities is $6^4$; the answer should then be $\frac{6\cdot5\cdot4\cdot3}{6^4}=\frac5{18}$. But the correct answer is $\frac59$, what did I miss? how should one think about resolving this kind of problem?","['combinatorics', 'probability']"
2674938,Find the base of the kernel of $L(y)=x^2y''-3xy'+3y.$,"Let $L:C^2(I)\rightarrow C(I), L(y)=x^2y''-3xy'+3y.$ Find the kernel of the linear transformation $L$. Can the solution of $L(y)=6$ be expressed in the form $y_H$+$y_L$, where $y_H$ is an arbitrary linear combination of the elements of ker L. What I have tried: Since ker L is subspace of $C^2(I)$ and dim $C^2(I)=2$, dim ker $L\leq 2$. Let $y(x)=x^r$. Then substituting gives $L(x^r)=x^rr^2-3rx^r+3x^r$, hence  $L(x^r)=0$ iff $x^rr^2-3rx^r+3x^r=0.$ $r$ can be solved using the quadratic formula. $$r=\frac{3+i\sqrt3}{2} \vee  r=\frac{3-i\sqrt3}{2}$$ $$y_1(x)=x^\frac{3+i\sqrt3}{2}, y_1(x)=x^\frac{3-i\sqrt3}{2} $$which are linearly independent(?). How would one show that $y_1$ and $y_2$ are LI ?","['ordinary-differential-equations', 'linear-algebra']"
2674955,"Given $A=\{(x,y)\in\mathbb{R}^2 \mid (x+m)^2-(y-m)^2=1\}$. Find $f(A)$ and $f^{-1}(A)$","The question: Given a bijection $f:\mathbb{R}^2\to\mathbb{R}^2,\, (x,y)\mapsto (2x+y-m, x-2y-m)$. Determine $f(A)$ and $f^{-1}(A)$ where $A=\{(x_1,x_2)\in\mathbb{R}^2 \mid (x_1+m)^2-(x_2-m)^2=1\}$. My attempt: So the condition of $A$ can be interpreted as:
$$
\begin{cases}
x=\sqrt{1+(y-m)^2}-m&\qquad&\text{if } x>-m\\
x=-m-\sqrt{1+(y-m)^2}&\qquad&\text{if } x\le -m\\
\end{cases}
$$
But then substitute into the bijection would make things ugly. Beside I feel that there is some logical flaw with such argument. Any suggestion on how to deal with this?","['abstract-algebra', 'functions']"
2674973,How to express $\theta$ in terms of $x$ where $3\sin(3\theta+x)=\frac{2.5}{\sin\theta}$?,"I tried to solve it by using compound angle formulas but in the end I could not leave $\theta$ alone. It goes like this: \begin{align}
& \frac{2.5}{3}=\sin(3\theta+x)\sin\theta \\[10pt]
& \sin(3\theta+x)=\sin(2\theta+\theta)\cos(x)+\sin(x)\cos(2\theta+\theta) \\[10pt]
= {} & [(\sin(2\theta)\cos(\theta)+\sin(\theta)\cos(2\theta))]\cos(x)+[(\cos(2\theta)\cos(\theta)-\sin(2\theta)\sin(\theta))]\sin(x)
\end{align} Then I did a couple more steps but I couldn't solve it this way, is there any other way to solve it algebraically?",['trigonometry']
