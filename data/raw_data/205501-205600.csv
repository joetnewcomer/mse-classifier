question_id,title,body,tags
4088640,"Why is an isomorphism of $\Bbb P^1$ fixing $[0:1]$, $[1:1]$, and $[1:0]$ the identity?","I'm reading the lecture notes of my algebraic geometry course and I'm stuck at an exercise: Let $\phi: \mathbb{P}^1\rightarrow \mathbb{P}^1$ be an isomorphism of algebraic varieties such that $\phi([0 : 1]) = [0 : 1], \phi([1 : 1]) = [1 : 1], \phi([1 : 0]) = [1 : 0]$ . Show that $\phi$ is the identity map. My attempt: I'm trying to prove that $\phi|_{U_i}$ , $i=0,1$ is identity and that they agree on $U_{01}=U_0\cap U_1$ .","['algebraic-geometry', 'abstract-algebra', 'projective-space']"
4088642,Calculating Upper Bounds for Probability when Extrapolating,"This question is from the MIT 6.042J 2005 Final exam.
The problem asks us to find an upper bound on the probability that a program runtime will be $\geq60$ seconds given that the expected runtime is 10 seconds. I know the answer to this is by using Markov's Bound: $$
\Pr(T\geq 60) \leq {E[T] \over 60} = \frac 16
$$ The follow up part then asks this: ""Suppose I decide to run the algorithm for 1 minute and if I don’t get an answer by that time, I stop what I am doing, and completely restart from scratch. Each time that I stop and restart the algorithm gives me an independent run of the algorithm. So, what is an upper bound on the probability that my algorithm takes longer than 5 minutes to get an answer?"" I'm not sure how to solve this part. The answer is $1 \over6^{5}$ , which I'm guessing has to do with the extension of Markov's Theorem: $$
\Pr(T\geq x) \leq {E[T^k] \over x^k}
$$ However, I'm not sure if this is correct, and I'm also not clear on how to use this formula in this context. In particular, my understanding is that we are trying to extrapolate the probability that runtime will be greater than $5 \times 60 = 300$ seconds given that the experiments are only going to 60 seconds, and this is something I haven't encountered before. Would anyone have an explanation for this question?","['expected-value', 'probability-limit-theorems', 'probability-theory', 'probability']"
4088666,Flajolet and Sedgewick generating function for Hertzsprung Problem,"The Hertzsprung Problem goes as follows: In how many can we place exactly $n$ non-attacking kings on a $n \times n$ chessboard such that there is exactly $1$ king in each row and column where $n \in \mathbb{N}$ . My main question is: How did Flajolet and Sedgewick get the below generating function for the Hertzsprung problem? $$\sum_{n=0}^\infty n! x^n \frac{(1-x)^n}{(1+x)^n}$$ Flajolet and Sedgewick discuss this generating function briefly and somewhat vaguely on page $373$ in Enumerative Combinatorics. They give a sketch of a sketch. However I'm totally not sure how they got the generating function. I have tried to extract the same generating function for a long time using restricted permutation, I mean the Hertzsprung problem reduces to finding number of permutations of $[n]$ such that no two adjacent digits in the permutation are consecutive. Moreover using the restricted permutations argument we get a nice closed form as follows $$n!+\sum_{k=1}^n {(-1)^k}(n-k)!\sum_{i=1}^k 2^{i} \binom{k-1}{i-1}\binom{n-k+1}{i}$$ by simply using Principle of inclusion-exclusion and stars and bars argument. However I don't know how Flajolet and Sedgewick got the generating function $$\sum_{n=0}^\infty n! x^n \frac{(1-x)^n}{(1+x)^n}$$ Any idea how to approach the problem for finding the generating function?  I have already searched all the references in (oeis.org/A002464) but no reference gives a proof on how they got the generating function. All the references just show or give an approach on how to get the closed form of the double sum which is very easy to get. Your help would be highly appreciated. Thanks.","['combinatorics', 'generating-functions']"
4088671,"Circles in $\mathrm{mod}\ 3$ ""XOR-triangles""","This question is about a slight generalization of ""XOR-triangles"", which is the name the OEIS gives to the construction discussed in the MathOverflow question "" Number triangle ."" The first line of the triangle is the binary representation (without any extra zeros padded). The next row of triangle is obtained by [... adding] two consecutive digits of above row [modulo $2$ ], and so on until completion. $$
1~~~~1~~~~0~~~~1~~~~0~~~~1\\
0~~~~1~~~~1~~~~1~~~~1\\
1~~~~0~~~~0~~~~0\\
1~~~~0~~~~0\\
1~~~~0\\
1
$$ If you color the $1$ s black and the $0$ s white, the rotationally symmetric XOR triangles look like this: from Michael De Vlieger on OEIS sequence A334556 ; click for a higher resolution image. Rotationally symmetric "" $\mathrm{mod}\ 3$ "" triangles. If we do the same construction only $\mathrm{mod}\ 3$ instead of $\mathrm{mod}\ 2$ , and where the top row can now have $0$ s, $1$ s, and $2$ s, with the $0$ s colored black and the $1$ s and $2$ s colored white, you get pictures like the following: These are with $401$ cells in the top row. The observation In the first, second, and fourth triangles, there appears to be patterns that look like circles if you squint. (I've drawn over them in red to help you see what I'm talking about.) As far as I can tell, these are ""real"" circles as opposed to graphics artifacts or optical illusions. Moreover, they don't appear to be hexagons, which wouldn't surprise me as much. Is there a nice explanation for why such accurate-looking circles appear from this construction?","['modular-arithmetic', 'combinatorics', 'geometry']"
4088748,Explanation of formula given on Wikipedia (for sign in half-angle formula for sine),"This Wikipedia article listing trigonometric identities, states the following identity under half angles : $$
\sin{\frac{\theta}{2}} = \text{sgn}\bigg(2\pi-\theta+4\pi\bigg\lfloor\frac{\theta}{4\pi}\bigg\rfloor \bigg)\sqrt{\frac{1-\cos{\theta}}{2}}
$$ where $\text{sgn}(x)$ is a function that returns $+1$ if $x>0$ and $-1$ if $x<0$ . I know and understand the part of the formula that says $\sqrt{\frac{1-\cos{\theta}}{2}}$ and understand the fact that the remaining part is to decide the $\pm$ sign in the formula.
From where , however, does the sign-deciding part of the expression come from? And why should it make sense?",['trigonometry']
4088750,On $\lim_{n\to\infty}b_n/a_n$ where $\exp(\sum_{n=1}^\infty a_n z^n)=1+\sum_{n=1}^\infty b_n z^n$,"Suppose that $(a_n)_{n>0}$ is a decreasing sequence of positive real numbers, the radius of convergence of $f(z)=\sum_{n=1}^\infty a_n z^n$ is equal to $1$ , and $f(1)=\sum_{n=1}^\infty a_n$ converges. Let $e^{f(z)}=1+\sum_{n=1}^\infty b_n z^n$ (it's easy to see that $b_n$ are positive, and the radius of convergence of this series is also equal to $1$ ). Does $\lim_{n\to\infty}b_n/a_n$ necessarily exist under these conditions? At first sight this looks too good to be true, but I can't find a counterexample, no matter what I try. The motivation is this answer , where I'm working with $f(z)=\operatorname{Li}_2(z)$ (i.e. $a_n=1/n^2$ ). The computation of $\lim_{n\to\infty}n^2 b_n$ , as seen there, would be much easier if the existence is established; without it, I (seem to) have to go a very tedious way. Update. The answer by @reuns indeed gives a counterexample (even a series of). Simplified a bit, let $a_n=4^{-k}$ for $2^k\leqslant n<2^{k+1}$ for each $k\geqslant 0$ ; then $$f(z)=\frac{w(z)}{1-z},\quad w(z)=z-3\sum_{k=1}^\infty 4^{-k}z^{2^k}$$ and then $g(z)=e^{f(z)}$ satisfies $$(1-z)^2 g'(z)=\big(w(z)+(1-z)w'(z)\big)g(z),$$ which, after substituting $g(z)=\sum_{n=0}^\infty b_n z^n$ , gives (for $n>1$ ) $$(n+1)b_{n+1}+(n-1)b_{n-1}-2nb_n=b_n+3\sum_{\substack{k>0\\2^k\leqslant n}}(2^{-k}-4^{-k})b_{n-2^k}-3\sum_{\substack{k>0\\2^k\leqslant n+1}}2^{-k}b_{n-2^k+1}.$$ Now, if $L:=\lim_{n\to\infty}(b_n/a_n)$ exists, then $L=L_d:=\lim_{m\to\infty}(b_{2^m+d}/a_{2^m+d})$ for each $d\in\mathbb{Z}$ . But the preceding equality (at $n=2^m+d$ , multiplied by $2^m$ , with $m\to\infty$ taken) implies $$L_0+4L_{-2}-8L_{-1}=-3,\quad L_1+4L_{-1}-2L_0=0,\quad\text{etc.}$$ The same way, the existence of $L_{-1}$ implies $L_d=L_{-1}$ for $d<0$ , and the values of $L_d$ for $d\geqslant 0$ can be computed just like above. Numerical experiments show that actually $L_{-1}=g(1)=e^2$ . I didn't prove the latter yet, and didn't consider generalisations ( $2^k$ replaced by $c_k$ with increasing $c_{k+1}-c_k$ , etc.) as well; I think these questions deserve to be dedicated follow-ups.","['real-analysis', 'complex-analysis', 'sequences-and-series', 'power-series', 'limits']"
4088764,A trick in Linear algebra,"Let $V$ denote a finite dimensional vector space with inner product $\langle\cdot, \cdot\rangle$ , and $\alpha_1,\alpha_2,\cdots,\alpha_r,\beta_1,\beta_2,\cdots,\beta_r\in V$ , Suppose there exists a nonzero $\alpha\in V$ , such that: $$
\sum_{i=1}^r \langle\alpha,\alpha_i\rangle \beta_i=0
$$ Then prove a very symmetric result: There exists a nonzero $\beta\in V$ ,such that: $$
\sum_{i=1}^r \langle\beta,\beta_i\rangle\alpha_i=0
$$ It’s obviously true from my instinct since in this problem $\alpha$ and $\beta$ has an equal position, and i think it may be use contradiction to prove this, but i have no ideal how to do exactly Thanks in advance for any help!","['inner-products', 'linear-algebra']"
4088848,Show that the set $X_s = \{A\in M_{m\times n}(\Bbb {R}) | rk(A) \leq s\}$ is closed,"A bit of background: I am trying to show that if $f\in C^1(\Bbb {R}^n,\Bbb{R}^m)$ then for every $a\in \Bbb{R}^n$ there exists a neighborrhood $U$ of $a$ s.t. for every $x\in U$ we have $rk(Df(x))\geq rk(Df(a))$ . I am trying to prove this by contradition,  suppose there isn't such a neighborrhood of $a$ with this property, then there is a sequence $x_k\to a$ s.t. $rk(Df(x_k))<rk(Df(a))$ for every $k$ . Since the degree only takes on finitely any values there is a sub-sequence $x_{k_l}\to a$ with $rk(Df(x_{k_l})) = s<rk(Df(a))$ Hence if $X_s = \{A\in M_{m\times n}(\Bbb {R}) | rk(A) \leq s\}$ is closed then we get a contradiction since then $Df(a)\in X_s$ which we assumed isent true. Here are a few of my attempts : I will denote $V = M_{m\times n}(\Bbb R)$ throughout this post. $\mathbf {Attempt}$ $\mathbf{one:}$ Induction on $s$ , for $s=0$ the statment is obvious since $X_0 = \{0\}$ which is closed.
now lets assume the statment is true for $s$ , every matrix in $X_{s+1}$ can be written as $A+B$ where $A\in X_s$ and $B\in X_1$ so: $$X_{s+1}\subseteq X_{s}+X_1$$ This is a sum of two closed sets in $V$ so we only need to show it is closed (which is not always true - there are closed subsets whose sum isn't).
Now if $A\in \partial ( X_{s}+X_1)$ then there is a sequence $B_k+C_k\to A$ s.t. $B_k\in  X_s$ and $C_k\in X_1$ $\mathbf {IF}$ $B_k\to B$ and $C_k\to C$ converege themselves then the statment is obvius since: $$A = lim_{k\to \infty} B_k+C_k = lim_{k\to \infty} B_k +lim_{k\to \infty} C_k =B+C\in X_s+X_1$$ since $B\in X_s$ and $C \in  X_1$ since they are closed by the induction hypothesis and so $A\in  X_s+X_1$ and we are done. However, it might be that $B_k$ and $C_k$ dont converge so we have a problem. In this case, my qeustions are: can we choose a two convergeing sequences $B_k,C_k$ s.t. $B_k\in X_s$ and $C_k \in X_1$ and $B_k+C_k\to A$ If not, can we show the sum is closed by some other method? $\mathbf{Attempt}$ $\mathbf{two:}$ Notice that Gaussian elimination is a linear (hence continuous) and preserves rank so if $A_k\to A$ where $A_k \in  X_s$ then by applying Gaussian elimination to $A$ we can bring it to the form $\varphi(A)=diag(a_1,...,a_u,0,...,0)$ and since $\varphi$ is continuous we have $\varphi(A_k)\to diag(a_1,...,a_u,0,...,0)$ hence $[\varphi(A_k)]_{ij}\to \delta_{i,j,\leq u} a_i$ where $\delta_{i,j,\leq u} = 1$ iff $i=j\leq u$ . Let us write: $$\varphi(A_k) = \begin{pmatrix}
(v_1)_k \\
\vdots \\
(v_s)_k \\
\sum_{i=0}^{s} x^k_{s+1,i} (v_i)_k \\
\vdots \\
\sum_{i=0}^{s} x^k_{m,i} (v_i)_k\\
\end{pmatrix}$$ So $(v_i)_k\to a_i\cdot e_i$ for each $1\leq i\leq s$ and $\sum_{i=0}^{s} x^k_{j,i} (v_i)_k \to 0 $ for each $s+1\leq j\leq m$ . Here I am pretty much stuck. any help would be much appreciated.","['multivariable-calculus', 'general-topology', 'linear-algebra', 'metric-spaces']"
4088866,Understanding the Euler sequence on $\mathbb{P}^n$,"I want to get an intuition for the Euler sequence by understanding the explicit construction of maps between terms.
I prefer to use this version: $$
0 
\longrightarrow \mathcal{O}_{\mathbb{P}^n}
\longrightarrow \mathcal{O}_{\mathbb{P}^n}(1)^{\oplus(n+1)}
\longrightarrow T\mathbb{P}^n 
\longrightarrow 0
$$ rather than its dual or any twisted version. Conventions : $[x_0 : x_1 : \dots :x_n]$ are projective coordinates on $\mathbb{P}^n$ . I will slightly abuse notation and describe sections of degree $d$ line bundles with the same notation, e.g. $x_0^d + 2x_1^{d-1}x_2$ is a section of $\mathcal{O}_{\mathbb{P}^n}(d)$ . First map If $c$ is a locally constant function on $\mathbb{P}^n$ , then $$
f: \mathcal{O}_{\mathbb{P}^n} \longrightarrow \mathcal{O}_{\mathbb{P}^n}(1)^{\oplus(n+1)},
\quad
c \mapsto (c\cdot x_0, c \cdot x_1, \dots,c\cdot x_n)
$$ i.e. multiplication of the linear monomials by $c$ (which is usually taken to be 1). Second map For a set of linear (homogeneous degree 1) functions $l_i(x)$ , $i=0,\dots,n$ on $\mathbb{P}^n$ , we have $$
g: \mathcal{O}_{\mathbb{P}^n}(1)^{\oplus(n+1)}
\longrightarrow T\mathbb{P}^n ,
\\
(l_0(x), l_1(x), \dots, l_n(x))
\longmapsto
l_0(x) \frac{\partial\,}{\partial x_0} + 
l_1(x) \frac{\partial\,}{\partial x_1} + \dots +
l_n(x) \frac{\partial\,}{\partial x_n}
$$ Showing $\mathrm{im}(f) = \mathrm{ker}(g)$ If we apply $(g\circ f)$ onto our locally constant $c$ , we arrive at the vector $$
c \cdot x_0 \frac{\partial\,}{\partial x_0} + 
c \cdot x_1 \frac{\partial\,}{\partial x_1} + \dots + 
c \cdot x_n \frac{\partial\,}{\partial x_n},
$$ which is known as the ""Euler vector field"" or EVF (or at least, it is $c$ times the usual definition of the EVF). It should be straightforward to see that the EVF acting on a homogeneous polynomial $q(x)$ of degree $d$ will return $d \cdot q(x)$ . In particular, if $q$ is homogeneous of degree $0$ , i.e. constant, then the EVF( $q$ ) returns 0. This is where my understanding gets a little shaky: The above makes sense, but the statement I see in the literature jumps from saying ""the EVF annihilates degree 0 functions"" to saying that ""the EVF is the kernel of $g$ "" and concluding the description. This is a little hard for me to parse because I feel $\mathrm{ker}(g)$ lies in $\mathcal{O}_{\mathbb{P}^n}(1)^{\oplus(n+1)}$ , but the EVF seems to lie in $T\mathbb{P}^n$ . Another point -- which may be central to the whole issue -- is if $\frac{\partial}{\partial x_i}$ are a proper set of basis vectors for $\mathbb{P}^n$ . The $x_i$ are homogeneous coordinates after all, so is the resolution to my question that: $$
x_j \frac{\partial}{\partial x_i} 
$$ (note the $j$ index, $j=1,\dots,n$ are a basis of $T\mathbb{P}^n$ , but the EVF $$
x_i \frac{\partial}{\partial x_i} 
$$ is actually the $\vec{\mathbf{0}}$ vector? Should we be working with affine coordinates on a patch, e.g. $y_i = x_i/x_0$ on the patch $x_0 \neq 0$ ? I hope to have a picture that intuitively maps $c$ to the zero vector field in $T\mathbb{P}^n$ , and the above steps don't quite get me there.","['projective-geometry', 'complex-geometry', 'exact-sequence', 'algebraic-geometry', 'projective-space']"
4088929,Solving $Ax= b$ for $A$,"I tried to solve this problem for A using the linearity of matrices, but I'm going nowhere. Can someone help-me with this question? Solve or give me a hint? Thanks! \begin{matrix}
 A \begin{bmatrix}
-1 \\
-2\\
-1\\
\end{bmatrix} = \begin{bmatrix}
-3 \\
-3 \\
-6\\
\end{bmatrix},\\ \\
\end{matrix} \begin{matrix}
 A \begin{bmatrix}
-1 \\
0\\
7\\
\end{bmatrix} = \begin{bmatrix}
2 \\
0 \\
0\\
\end{bmatrix},\\ \\
\end{matrix} \begin{matrix}
 A \begin{bmatrix}
-1 \\
-4\\
2\\
\end{bmatrix} = \begin{bmatrix}
-2 \\
-1 \\
-2\\
\end{bmatrix},\\ \\
\end{matrix}","['matrices', 'linear-algebra', 'vectors']"
4088930,Local extrema of the implicit function defined by $5x^2+5y^2+5z^2-2xy-2xz-2yz-72=0$,"A problem asked us to determine the local extrema of an implicit function $z=z(x,y)$ defined by the equation $5x^2+5y^2+5z^2-2xy-2xz-2yz-72=0$ . My instructor went about this as follows: Let $F:\mathbb{R}^3 \to \mathbb{R}, F(x, y, z)=5x^2+5y^2+5z^2-2xy-2xz-2yz-72$ . Then, $F$ defines explicitely the function $z=z(x,y)$ in the neighborhood of a point $(x_0, y_0, z_0) \in \mathbb{R}^3$ if $F(x_0, y_0, z_0)=0$ and $\frac{\partial F}{\partial z}(x_0, y_0, z_0) \ne 0$ (we wish to use the implicit function theorem, I forgot to mention that). After writing the conclusion of the implicit function theorem, he drew the conclusion that we need to solve the system $\begin{cases}
F(x,y,z)=0 \\
\frac{\partial F}{\partial z}(x, y, z)\ne 0 \\ 
\frac{\partial F}{\partial x}(x, y, z)=0 \\
\frac{\partial F}{\partial y}(x, y, z)=0 
\end{cases}
$ in order to find the critical points of our implicit function. I don't really understand how we get this system. I understand that the first two equations come from the fact that we are searching for those points $(x_0, y_0, z_0)$ where we can apply the implicit function theorem. My instructor said that the last two equations are there  because we want to have $\frac{\partial z}{\partial x}(x, y)=0$ and $\frac{\partial z}{\partial y}(x, y)=0$ , but I don't understand why this is the case (I know the formula for implicit differentiation, but I still don't get it). Furthermore, why should all these $4$ equations hold simultaneously? I don't understand why the point for which we apply the implicit function theorem should necessarily also be a critical point for our function $z(x, y)$ .","['proof-explanation', 'real-analysis', 'maxima-minima', 'multivariable-calculus', 'calculus']"
4088942,Detecting elements in a group using characters.,"It is well known that the trace of the regular representation $\rho$ of a group $G$ 'detects' the identity element of the group. More precisely, we have $$
Tr(\rho)(g) = \begin{cases}|G|&\mbox{if }g=e\\
0&\mbox{otherwise.}\end{cases}
$$ Now, if $G$ is Abelian, this can be used to detect arbitrary elements in $G$ as \begin{equation}\label{Equation 1}
Tr(\rho)(h^{-1}g) = \begin{cases}|G|&\mbox{if }g=h\\
0&\mbox{otherwise.}\end{cases}
\end{equation} The key here is that every irreducible representation of $G$ (in this case) is one dimensional so that $Tr(\rho)(h^{-1}g) = \rho(h^{-1}g)$ can be written as a linear combination of irreducible representations of $G$ . My question is the following. Is there an analogous way to detect arbitrary elements when $G$ is non Abelian EDIT: Let me add some context to why I am asking this question. The motivation comes from Artin $L$ functions (over $\mathbb{Q}$ for simplicity). Consider the Riemann zeta function $\zeta(s)$ and suppose, for a fixed $a,N\in \mathbb{N}$ with $GCD(a,N)=1$ , I am interested in the function $$
L(s):=\sum_{m\equiv a\mod N} \frac{1}{m^s}.
$$ Then it is well known (and in fact a consequence of the first of the two equations above) that $$
L(s) = \frac{1}{\varphi(N)}\sum_\chi \chi(a)^{-1}L(s,\chi)
$$ where $L(s,\chi)$ is the Dirichlet $L$ function of the character $\chi$ modulo $N$ , given by $$
L(s,\chi) = \sum_{n=1}^\infty \frac{\chi(n)}{n^s},
$$ and the summation runs over all characters of $(\mathbb{Z}/N\mathbb{Z})^\times$ . Something very similar can be done for other number fields as well (although I have not done the exact calculations, I think it should be possible to do the same for other Dirichlet/Hecke $L$ functions too). Now I am interested in replacing $\zeta(s)$ with Artin $L$ functions of representations of higher dimensions and see if something similar is possible. I hope this makes my question clear.","['representation-theory', 'group-theory', 'finite-groups', 'characters']"
4088943,"Find an explicit bijection between the spaces of sequences of $\{0, 1, 2, 3, 4, 5\}$ of sequences of $\{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11\}$.","We know there is a bijection between these two space. We even know there is a topological conjugacy if we consider adding machines on them. But I would like to see an explicit bijection between the space of sequences of the set $\{0, 1, 2, 3, 4, 5\}$ and the space of sequences of the set $\{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11\}$ . If we have, for example, spaces of sequences of sets $\{0, 1\}$ and $\{0, 1, 2, 3\}$ it is easy to find a bijection between these two spaces. Simply code numbers as follows: $$00 \mapsto 0, 10 \mapsto 1, 01 \mapsto 2, 11 \mapsto 3.$$ Hence for example the sequence $(001100110011\ldots) \mapsto (030303\ldots)$ . It is always easy to find this coding if we have sets of the forms $\{0, 1, \ldots, j - 1\}$ and $\{0, 1, \ldots, j^n - 1\}$ . But I don't know how to find it in more general cases. Edit: being equivalent means there is a bijection and it is important to explicitly find a bijection.","['elementary-set-theory', 'sequences-and-series']"
4089009,"Prove $x^x+y^y\ge x^2+y^2$ for $x,y>0$ and $x+y\le 2$.","We may prove the inequality for $x,y\in (0,1]$ . Note that, for $0<x\le 1$ , it holds that \begin{align*}
 x^x&=1+(x-1)+(x-1)^2+\frac{1}{2}(x-1)^3+\cdots\\
&\ge1+(x-1)+(x-1)^2+\frac{1}{2}(x-1)^3\\
&\ge x^2.
\end{align*} Similarily, for $y \in (0,1]$ , it holds that $$y^y\ge y^2.$$ Thus $$x^x+y^y\ge x^2+y^2.$$ But how to prove under the condition $x+y\in (0,2]$ ?","['calculus', 'inequality', 'real-analysis']"
4089042,What is the source of this derivative formula,"We have just proved the n-th derivative of $f(x)=e^{-x}p(x)$ , where $p(x)$ is a polynomial. We got: $$f(x)^{(n)}= e^{-x}(-1)^n\sum_{k=0}^{n}\binom{n}{k}(-1)^kp^{(k)}$$ Even though I do not completely understand the proof, I wonder, if there is a more general formula for expressions similar to this or if it has a name, so that I can look it up.","['calculus', 'derivatives', 'real-analysis']"
4089047,What is a minimum number of $1\times 3$ tiles that can be put on a table $5\times 5$ so that no more tiles $1\times 3$ can be put on it?,What is a minimum number of $1\times 3$ tiles that can be put on a table $5\times 5$ so that no more tiles $1\times 3$ can be put on it? It is 5 but I can not prove that if we put 4 tiles there is still room for one more. I think there must be some rigor proof using Hall marriage theorem.,"['tessellations', 'matching-theory', 'combinatorial-geometry', 'discrete-mathematics', 'tiling']"
4089050,Proving two lines have the same length,"Problem Given two circles $ \Gamma_1 $ and $ \Gamma_2 $ which intersect each other at point $ V $ . A line $ \ell $ intersects $ \Gamma_2 $ at point $ K $ and intersects $ \Gamma_1 $ at points $ A $ and $ B $ . If $ KV $ intersects $ \Gamma_1 $ again at point $ S $ , prove that $ SA = SB $ . My Attempt My approach was to extend the line segment $ AV $ and $ BV $ so that it intersects $ \Gamma_2 $ at $ F $ and $ H $ , respectively. I managed to prove that $ \triangle{ABS} $ and $ \triangle{KHF} $ are similar. If we can prove that $ KF \parallel AS $ , then $ SB \parallel KH $ and $ AB \parallel FH $ . Hence, $ \angle{BAS} = \angle{KFH} = \angle{AKF} = \angle{KHF} = \angle{SBA} $ and we proved that $ SB = SA $ . But I have a problem while proving $ KF \parallel AS $ . I have tried to prove it by the fact that $ \angle{AKF} = \angle{KHF} $ , but it doesn't seem to work. My question is, how is it supposed to prove $ AS \parallel KF $ (or maybe there is another way to attack this problem)? Thank you.","['circles', 'geometry']"
4089106,Prove $\sum_{n=1}^{\infty} \arctan\left(\frac{1}{F_n}\right) \arctan\left(\frac{1}{F_{n+1}}\right)=\frac{\pi^2}{8}$,"As the title states, I'm not sure how to prove $$\sum_{n=1}^{\infty} \arctan\left(\frac{1}{F_n}\right) \arctan\left(\frac{1}{F_{n+1}}\right)=\frac{\pi^2}{8}$$ where $F_n$ representes the $n$ -th fibonacci number ( $F_1=1, F_2=1, F_3=2$ , etc). This question comes from an Instagram post and WolframAlpha numerically verifies the series converges to $\frac{\pi^2}{8}$ for at least $60$ decimal points.  I have seen several infinite series involving arctangent and Fibonacci numbers that end up in a telescoping sum through arctangent angle addition/subtraction identities, but I'm not sure how to approach this series with the product of two arctangent functions. I'm looking for a solution that doesn't rely on knowing the series converges to $\frac{\pi^2}{8}$ .","['calculus', 'fibonacci-numbers', 'summation', 'sequences-and-series']"
4089130,A coin is tossed $10$ times. Find the probability that there exist $7$ consecutive coin tosses with at least $5$ out of the $7$ being heads.,"A coin is tossed $10$ times. Find the probability that there exist $7$ consecutive coin tosses with at least $5$ out of the $7$ being heads. So for example, $TTHHTHHTHH$ is one of the outcomes we want. I guess the best way to treat this is as a counting problem; finding the number of outcomes we want and then dividing by $2^{10}.$ $2^{10} = 1024,$ so listing all the outcomes is time-wise expensive. The events, ""The first consecutive $7$ tosses contain at least $5$ heads"", ""The second consecutive $7$ tosses contain at least $5$ heads"", etc. are not mutually exclusive and so the answer is not simply: $P$ (The first consecutive $7$ tosses contain at least $5$ heads) + $P$ (The second consecutive $7$ tosses contain at least $5$ heads) + ... . Similarly, the events, ""The first consecutive $7$ tosses does not contain at least $5$ heads"", ""The second consecutive $7$ tosses does not contain at least $5$ heads"", etc. are also not mutually exclusive and so the answer is not simply: $1 - $ $[P$ (The first consecutive $7$ tosses does not contain at least $5$ heads) + $P$ (The second consecutive $7$ tosses does not contain at least $5$ heads) + ... $]$ . Edit: What about reflecting the $10$ boxes down the middle? This could cut our work in half maybe? For example, $HTTHHTHTHH \equiv HHTHTHHTTH$ . Perhaps figuring out the symmetries is expensive too. I'm also interested in doing a similar problem with larger numbers, e.g.: A coin is tossed $10^{14}$ times. Find the probability that there exist $1000$ consecutive coin tosses with at least $650$ out of
the $1000$ being heads. This is probably impractical to calculate using binomial distributions, so how would you find an answer using the Normal distribution as an approximation, or is it not possible to do this? The reason I'm interested in this latter question is that it is the sort of calculation one might make if one wanted to gain statistical evidence that a poker site is rigged against them, although of course the latter question would not be enough evidence to prove a poker site is rigged against a particular player; it could be a reasonable starting point for further calculations. Also, it is not hard to imagine this calculation could have applications in other areas, statistical mechanics or mathematical biology for example.","['binomial-distribution', 'normal-distribution', 'inclusion-exclusion', 'combinatorics', 'probability']"
4089135,"Is there a characterization of fields $k$ such that, if $f\in k[x]$ splits over $k$, so does $f'$?","Is there a characterization of fields $k$ such that, if $f\in k[x]$ splits over $k$ , so does $f'$ ? This is trivially true is $k$ is algebraically closed, and the answer to this question show that it is true for real closed $k$ . I can see that it is also true for $k=GF(2)$ , since $f$ must be of the form $x^m(x-1)^n$ , which has derivative of the same form or equal to $0$ .  This is obvious unless $n$ and $m$ are both odd, but in that case $f'=x^{m-1}(x-1)^n+x^m(x-1)^{n-1}=x^{m-1}(x-1)^{n-1}(x-1+x)=x^{m-1}(x-1)^{n-1}$ . So this property hold for more than just real closed and algebraically closed fields. On the other hand, this property is not true for all fields.  In particular, it is not true for $k=\Bbb{Q}$ since $f=x^3-x=(x-1)(x-0)(x-(-1))$ splits over $\Bbb{Q}$ , but its derivative $f'=3x^2-1$ is irreducible over $\Bbb{Q}$ . So I'm curious whether there is a characterization of such $k$ . Generalization : More generally, consider a tower $R\le k\le F$ with $R$ an integral domain and $k$ and $F$ fields.  Is there a characterization of towers with the property that, if $f\in R[x]$ splits over $k$ , $f'$ splits over $F$ ?","['field-theory', 'splitting-field', 'abstract-algebra', 'polynomials']"
4089242,How to define trigonometry functions in a non unit circle?,I was reading trigonometry functions and how they are defined for non acute angles in a unit circle. My question is that in the unit circle definition the sine of the ray is said to be it's y axis coordinate. What if the circle is not unitary? Why do we even use unit circle? How to define sine in a circle which is not unitary but lets say its radius is r = 2 units. How to define sine in such scenario and show that it will still remain same no matter whatever the radius is Thanks,"['trigonometry', 'functions']"
4089255,Change in function's chord length depends on $|s-t|$,"I am stuck on this question and any help would go a long way. Show that if $\alpha : [a, b] \rightarrow \mathbb{R}$ is a regular smooth curve and $||α(s) − α(t)||$ depends only on $|s − t|$ , then $\alpha$ must be a subset of a circle or a line. I have shown that the speed of such a curve is constant, but I don't know where further to go. Also, the answer given here did not seem to help. Any help will be extremely appreciated. Thank you! EDIT As per the comment, I will elaborate on my answer and what I understood from the answer attached. I have understood that the speed of such a curve must be constant. With the speed being constant, and knowing the relation $\langle \alpha'(t)-\alpha'(s),\alpha(t)-\alpha(s)\rangle=0,$ which one can derive as the solution given does, we get that the angles formed by $\alpha'(t)$ and $\alpha'(s)$ with $\alpha(t)-\alpha(s)$ are equal. Now, the solution says that the directions of $\alpha'(t),\alpha'(s)$ are different... Why? Suppose this was true; then the solution says that one can see that the curve alpha must satisfy the equation $$r\frac{d\theta}{dr}=\tan \theta.$$ Why does this follow? Help with these doubts will be much appreciated. A different approach altogether also is be fantastic. Thank you.",['differential-geometry']
4089345,Extending an element in generating set for free abelian group,"Let $G$ be a finitely generated free abelian group and $S$ be a minimal generating set i.e. ${\rm rank}(G)=|S|$ . If $w$ is a word in $G$ then when it can be extended in a new minimal generating set for $G$ ? For example if $S=\{s_{1},s_{2}\}$ then $s^{n}$ can not be extended in a new generating set while $w=s^{3}_{1}s^{2}_{2}$ can. Intuitively, I would argue that we should be able to solve for one of the generators. Is this true?","['free-abelian-group', 'combinatorial-group-theory', 'finitely-generated', 'group-theory', 'abelian-groups']"
4089371,Ask George Casella textbook question 8.37 (a),"This is from George Casella textbook question 8.37 (a). Let $X_1,...,X_n$ be a random sample from a $n(\theta, \sigma^2)$ population. Consider testing $H_0:\theta\leq \theta_0$ versus $H_1:\theta> \theta_0$ .  If $\sigma^2$ is known, show that the test that rejects $H_0$ when $$\bar{X}>\theta_0+z_\alpha \sqrt{\sigma^2/n}$$ is a test of size $\alpha$ . Show that the test can be derived as an LRT. My understanding of this question is it contains 2 questions. First is to show the size of this test is $\alpha$ . The second question is to show this test can be derived as an LRT. I have both problems on these 2 questions. My attempt of the first question: to show the size is $\alpha$ . I show it based on the definition strictly. According to the definition 8.3.5, $\alpha=sup\beta(\theta)=supP(x\in R|H_0)=supP(x\in R|\theta\leq \theta_0)$ . Then I first get $P(x\in R)=P(\bar{X}>\theta_0+z_\alpha \sqrt{\sigma^2/n})=P(\bar{X}-\theta>\theta_0-\theta+z_\alpha \sqrt{\sigma^2/n})=P((\bar{X}-\theta)/\sqrt{\sigma^2/n}>(\theta_0-\theta)/\sqrt{\sigma^2/n}+z_\alpha)=P(Z>(\theta_0-\theta)/\sqrt{\sigma^2/n}+z_\alpha)$ . Then I find this probability is increasing in terms of $\theta$ , so the supremum under $H_0=\theta\leq \theta_0$ is reached at $\theta=\theta_0$ . So the above becomes $P(Z>z_\alpha)$ . It is exactly $\alpha$ . Then I finish my proof to show the size of this test is $\alpha$ . But the solution is very easy. I think the solution is wrong. Because it is not $Z=(\bar{X}-\theta_0)/\sqrt{\sigma^2/n}$ , it is $Z=(\bar{X}-\theta)/\sqrt{\sigma^2/n}$ . So I think the solution is wrong. But 8.37(a), 8.37(c) both use this solution. Am I correct? For the second question: to show this test can be derived as an LRT. Yes, I understand and get the step in the solution: it is equivalent  to rejecting if $(\bar{x}-\theta_0)/\sqrt{\sigma^2/n}>c'$ . Then we finished the proof? Shouldn't we derive the exact same form of $\bar{X}>\theta_0+z_\alpha \sqrt{\sigma^2/n}$ ? The solution is:","['statistical-inference', 'statistics', 'probability']"
4089384,Are $\Bbb Q/2 \Bbb Z$ and $\Bbb Q/5 \Bbb Z$ isomorphic as groups?,"Are $\Bbb Q/ 2 \Bbb Z$ and $\Bbb Q / 5 \Bbb Z$ isomorphic as groups? I take the map $\pi : \Bbb Q \longrightarrow \Bbb Q/5 \Bbb Z$ defined by $a \longmapsto \frac {5} {2} a + 5 \Bbb Z,\ a \in \Bbb Q.$ Then this map is clearly a surjective group homomorphism with kernel being $2 \Bbb Z.$ Hence by the first isomorphism theorem we have $\Bbb Q / 2 \Bbb Z \cong \Bbb Q / 5 \Bbb Z.$ Is my reasoning correct at all? Would anybody please verify it? Thanks for your time.","['group-theory', 'solution-verification', 'group-isomorphism']"
4089405,$E[|S_n - n \mu|^r] = O(n^{r/2})$ as $n \to \infty$. So is $E[|S_n|^r] = O(n^r)$?,"Let $S_n = X_1 + X_2  + \cdots + X_n$ where $X_1, x_2, \dots, X_n$ are iid random variables with mean $\mu$ and variance $\sigma^2$ . Then Theorem 5.1 in Gut's Probability - A Graduate Course book, says that if $E[X_i^4] < \infty$ and $r \ge 2$ , as $n \to \infty$ , $$
E\bigg[\bigg|\frac{S_n - n \mu}{\sigma \sqrt{n}}\bigg|^r\bigg] \to E[N(0,1)]^r,
$$ or equivalently $$
E[|S_n - n \mu|^r] \to \sigma^r n^{r/2} E[N(0,1)]^r.
$$ Does this allow us to say anything about the magnitude of $E[|S_n|^r]$ as $n \to \infty$ when $\mu \neq 0$ ? It seems it should be something like $E[|S_n|^r] = O(n^r)$ ?","['statistics', 'expected-value', 'convergence-divergence', 'probability-theory', 'random-variables']"
4089455,Areas in triangle,"In the above isosceles right triangle ABC, with its two sides $AB = AC = 1$ unit,  we take a random point D on the hypotenuse and draw perpendicular lines to the sides AB and AC, which intersect them at points E and F respectively.
Show that the maximum of the three areas AFDE, EBD and CDF is always $\geq \frac {2}{9}$ . If we set $EB = x$ then, area $EBD = \frac {x^2}{2}$ , $AFDE = (1-x)*x$ , $CDF = \frac {(1-x)^2}{2}$ . Also $AFDE + EBD + CDF = \frac {1}{2}$ . Clearly the 3 areas can't be equal.
We can only have 2 of them equal, when $x=0.5$ or $x=0.33$ or $x=0.66$ . When $x=0.33 = \frac {1}{3}$ then $EBD = \frac {x^2}{2} = \frac{1}{18}$ and $AFDE = CDF = \frac{1}{2}*(\frac{9}{18}-\frac{1}{18}) = \frac{2}{9}$ . But I don't know if this is a sufficient proof.",['geometry']
4089508,Intuition of the connection between the graph Laplacian and the Laplace operator,"In Physics SO the intuition of the Laplace operator (divergence of the gradient) is explained by resorting to the finite difference version: the Laplace equation is satisfied as long as the value at a vertex is the average of the surrounding values, akin to the explanation in Wikipedia of harmonic functions . Or the more enjoyable blog explanation , motivating them through minimal surfaces: soap bubbles, or the 3Blue1Brown video : Much like a minimum with a positive second derivative, a positive Laplacian in a 2D surface would indicate local minimum (concave up) in the way that the neighboring points on average are higher in value. Professor Strang gives a rather artistic impromptu intuition right here proposing a grid with unweighted edges, and noticing that for internal vertices, the degree would be $4,$ corresponding to second differences with the surrounding unit-value edges, but this is a bit shaky in what it is really happening in the example. Clearly the average of adjacent entries in a Laplacian matrix doesn't really work because of the embedded degree matrix in the diagonal: Others approach the graph Laplacian by noticing the connection to Newton's law of cooling . Is there a better ""visual"" to see the intuition of the graph Laplacian?","['graph-theory', 'laplacian', 'multivariable-calculus', 'intuition']"
4089578,Transform $\frac{-2}{\tan\frac{x}{2}+1}$ to $\tan x-\sec x$? [duplicate],"This question already has answers here : Integration of $\frac {1}{1+\sin x}$ (4 answers) Closed 3 years ago . I'm learning to integrate and was asked to integrate $\int\frac{1}{1+\sin x}dx$ I get the answer $-\frac{2}{\tan\frac{x}2+1}+c$ which Symbolab confirms is correct, but the textbook says the answer is $\tan x-\sec x+c$ . I can't seem to transform my answer to that one using trig identities. Any idea how/if one can get that result? Many thanks, Andrew","['calculus', 'trigonometry', 'trigonometric-integrals']"
4089694,Calculating the derivative of the map $T\to T^{-1}$,"Let $E$ be a banach space and $U$ be the set of all bounded invertible linear operator on $E$ with bounded inverse. Consider the map, $f:U\to U$ by $T\to T^{-1}$ Now we are interested in calculating the 2nd order  derivatives of this map.
For the first order derivative, I got that $D(f(T))(S)=-T^{-1}ST^{-1}=-M(S),$ where $M:BL(E)\to BL(E)$ given by, $M(S)=T^{-1}ST^{-1}$ Let, $A: BL(BL(E),BL(E))\to BL(E)$ denoted by, $A(T)=T(S)$ be the evaluation map at $S.$ So , we have, $ A(D(f(T)))=-M(S).$ Therefore by chain rule, we get, $$D^2(f(T))(S,W)=-DM(S)(W)=T^{-1}WT^{-1}.$$ It seems I am doing something wrong. Can anyone point it out? Edit: Calculating it simply using definition, I found that the answer will be, $D^2(f(T))(S,W)=T^{-1}ST^{-1}WT^{-1}+T^{-1}WT^{-1}ST^{-1}$ which is correct,I guess.","['multivariable-calculus', 'real-analysis']"
4089764,How to proceed solving $(7+4\sqrt3)^m+(7-4\sqrt3)^m=14$?,I have $$(7+4\sqrt3)^m+(7-4\sqrt3)^m=14$$ By noticing that $7+4\sqrt3=\frac1{7-4\sqrt3}$ one way to solve the equation is using substitution $(7+4\sqrt3)^m=t$ and solve for $t$ in $t+\frac1t=14$ . But I'm trying to use a little different approach: We have $7+4\sqrt3+7-4\sqrt3=14$ So by using the substitution $u=7+4\sqrt3$ we have : $$u^m+\frac1{u^m}=u+\frac1u$$ But from here how can I prove mathematically that the only answers are $m=1$ and $m=-1$ ?,['algebra-precalculus']
4089783,Which of the following statements are true for the elements in $\mathscr S\ $?,"Let $\mathscr S$ be the family of continuous real valued functions on $(0, \infty)$ defined by $$\mathscr S : = \left \{f : (0, \infty) \longrightarrow \Bbb R\ |\ f(x) = f(2x),\ \forall x \in (0, \infty) \right \}.$$ For each of the following statements, state whether it is true or false. $(a)$ Any element $f \in \mathscr S$ is bounded. $(b)$ Any element $f \in \mathscr S$ is uniformly continuous. $(c)$ Any element $f \in \mathscr S$ is differentiable. $(d)$ Any uniformly bounded sequence in $\mathscr S$ has a uniformly convergent subsequence. I have proved that $(a)$ is true because for any $x \in (0,\infty)$ there exists $n \in \Bbb Z$ such that $2^n x \in [1,2].$ Since $[1,2]$ is compact it follows that for any $f \in \mathscr S$ there exists $M_f \gt 0$ such that for all $y \in [1,2]$ we have $|f(y)| \leq M_f.$ But then by the given hypothesis $|f (x)| = |f(2^n x)| \leq M_f,$ as required. But I have no idea about $(b), (c)$ and $(d).$ I think $(b)$ and $(c)$ are false. But I am unable to construct an element $f \in \mathscr S$ which will work as a counter-example. Would anybody please help me in this regard? Thanks for your time.","['examples-counterexamples', 'real-analysis', 'continuity', 'uniform-convergence', 'derivatives']"
4089784,How to determine how evenly distributed numbers are on a set?,"I have a set of numbers and want to determine how evenly distributed these numbers are. E. g.: $E_1 = {2, 4, 6, 8, 10}$ $E_2 = {2, 3,6, 7,10}$ $E_1$ is more evenly distributed than $E_2$ as the differences between one element to its neighbors are always the same. My questions are: What is the correct mathematical term for this being evenly distributed respectively is there a dedicated part of mathematics that deals with this question? What is a canonical way of calculating this amount of being evenly distributed for simple cases like the one above or if my numbers are rational numbers?",['elementary-set-theory']
4089796,CDF of Binomial decreases with more trials.,"Let $X \sim Bin(n, \frac{c}{n})$ , and $Y \sim Bin(n+1, \frac{c}{n+1})$ . We know that $\mathbb{E}[X] = \mathbb{E}[Y] = c$ . I am curious to know whether $$
\Pr[Y \leq c] \leq \Pr[X \leq c].
$$ I tried confirming this numerically for some values of $c$ and $n$ , and it seems to hold, which suggests it would be true in general. However, I have no idea how to prove this. Any help or a counterexample would be greatly appreciated!","['binomial-distribution', 'probability-distributions', 'probability-theory', 'probability']"
4089817,Why is the answer for this problem 8 sq. units?,"If a unit sphere $(r = 1)$ circumscribes a cube, what is the surface area of the said cube? The answer for this problem is 8 sq. units. However, my solution is as follows: Diameter of sphere = Diagonal of Cube (through observation of cross section)
This means that through Pythagorean theorem: $$\begin{align}2s^2= (\sqrt{2})^2 = 2 \\ s^2 = 2\\ 6s^2 = 12 \end{align}$$ What is wrong with this solution? Am I missing something here?","['contest-math', 'geometry']"
4089841,Can we find $\lim_{N\to \infty} \frac{1}{\sqrt{N}} \sum_{n \le N} \mu(n)/\sqrt{n}$,"Here $\mu(n)$ is möbius function. Without assuming RH can we find if $\lim_{N \to \infty} \frac{1}{\sqrt{N}} \sum_{n=1}^N \frac{\mu(n)}{\sqrt{n}}$ exists, and if yes, what it may be. Calculations hint it may have a very small finite value or may go to zero. One approach I can think of is using partial sum which goes to zero as $N \to \infty$ : $$  \sum_{n \le N} \frac{\mu(n)}{n} =  \sum_{n \le N} \frac{\mu(n)}{\sqrt{n}} \frac{1}{\sqrt{n}} $$ $$ = \frac{1}{\sqrt{N}} \sum_{n \le N} \frac{\mu(n)}{\sqrt{n}} - \int_1^N \frac{-1}{2t\sqrt{t}} \sum_{n \le t} \frac{\mu(n)}{\sqrt{n}} dt $$","['riemann-zeta', 'number-theory', 'dirichlet-series']"
4089897,Prove $f'(x_n) \to f'(x)$,"Let $f: I \to R $ differentiable and $x \in I$ .
Prove that there exists a sequence { $x_n$ } in $I$ different from $x$ such that $f'(x_n) \to f'(x)$ So below is my approach to this problem:
Take an arbitrary sequence { $y_n$ } and apply the MVT, we have there exists a sequence { $x_n$ }  between { $y_n$ } and $x$ such that $\frac{f(y_n) - f(x)}{y_n - x} = f'(x_n)$ Then taking $\lim_{y_n\to x}$ and since $y_n$ is arbitrary, we have the desired result. Am I correct here? Thank you!","['derivatives', 'real-analysis']"
4089912,"Is this problem solvable? For real-valued $g(x,y)$ and analytic $f(z)=e^x\sin y+i g(x,y)$, where $z=x+iy$, evaluate $g(3,2)-g(1,2)$ [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question On an entrance exam where there is already a headache-giving typo , I encountered the following problem, which I suspect is also wrong: Let $g$ be a real and differentiable function of two variables, and let $f$ be a complex variable function, given by $$f(z)=e^x\sin(y)+ig(x,y),$$ where $z=x+iy$ . If $f$ is analytic in the complex plane, what is the value of $g(3,2)-g(1,2)$ ? a) $e^2$ b) $e^2\big(\sin(3)-\sin(1)\big)$ c) $e^2\big(\cos(3)-\cos(1)\big)$ d) $e-e^3\sin(2)$ e) $(e-e^3)\cos(2)$ I believe something is missing, can someone tell me if this problem is solvable?",['complex-analysis']
4089914,Calculus - Sequence and Function - hard exercise,"EDIT: With your help I have succeed to prove it! Thanks! I also have another question related to this one - written down here. Let $a,b \in \mathbb{R}$ such that $a<b$ and let $f:[a,b] \to [a,b]$ be a differentiable function, let $t \in [a,b]$ , and consider the sequence $(x_n)_{n=1}^{\infty}$ defined by: $$\left\{\begin{matrix}
x_1=t & \\ 
x_{n+1}=f(x_n) & \forall n\geq 1 
\end{matrix}\right.$$ Suppose that there exists a point $\alpha \in [a,b]$ such that $f(\alpha)=\alpha$ . Prove, while using MVT, that if there exists a $0 \le q <1$ such that $|f'(x)|\le q$ for every $x \in [a,b]$ , then $\lim_{n \to \infty}x_n=\alpha$ - I don't know how to use MVT here, since I don't know nothing about $\alpha$ and $x_n$ , I can't take the interval $[\alpha,x_n]$ or $[x_n,\alpha]$ , ( $\alpha$ and $x_n$ can be equal). Any help will be awesome! Thanks a lot! EDIT: Now I have a $y \in \mathbb{R}$ , and the sequence $(x_n)_{n=0}^{\infty}$ : $$x_0=y ~ ~ , ~ ~ x_{n+1}=cos(x_n), \forall n \ge 0$$ Prove thatt the sequence converge to a limit $0<\alpha<1$ . Any tips? Thanks again!","['calculus', 'functions', 'sequences-and-series']"
4089931,Does there exist a group that can be covered by conjugates of its proper subgroup? [duplicate],"This question already has answers here : Union of the conjugates of a proper subgroup (7 answers) Closed 3 years ago . Do there exist a group $G$ and its proper subgroup $H$ , such that $G$ is covered by conjugates of $H$ ? It is not hard to see, that if such $G$ and $H$ exist, then $|G:H| = \infty$ . Indeed, consider first the case, when $G$ is finite and $A \subset G$ is a left transversal of $H$ . Then $|\bigcup_{g \in G} gHg^{-1}| = |\bigcup_{a \in A} aHa^{-1}| \leq \sum_{a \in A}|aHa^{-1}| - |\bigcap_{g \in G} aHa^{-1}| = |A||H| - |\bigcap_{g \in G} aHa^{-1}| = |G| - |\bigcap_{g \in G} aHa^{-1}| \leq |G|-1$ . Now, suppose $|G:H| < \infty$ . Then $H$ contains a finite-index normal subgroup $N$ of $G$ . Then if $G$ is covered by conjugates of $H$ , then finite group $\frac{G}{N}$ is covered by conjugates of its proper subgroup $\frac{H}{N}$ , which is proved above to be impossible. However, I have no idea what to do about the case when $|G:H| = \infty$ .","['elementary-set-theory', 'group-theory', 'abstract-algebra', 'infinite-groups']"
4089936,"Why is reflexivity a feature of multi-step β-reduction, and not of β-reduction?","I understand the need to distinguish between two algorithms, even when one is enclosed in another. Transitivity as a feature of multi-step reduction makes perfect sense, since we literally need multiple steps of $\beta$ -reduction execute it. What about reflexivity? If I had to answer this question by myself, I would use a mathematician's point of view, saying that it is convenient to not have reflexivity in the definition of $\beta$ -reduction, in order to prove certain propositions without having to deal with the case of reflexivity. What would be the programmer's point of view? EDIT: I am referring to untyped $\lambda$ -calculus, sorry for not mentioning it.","['formal-languages', 'lambda-calculus', 'discrete-mathematics', 'computer-science']"
4089993,Characterization of geodesics by distance function,"Let $ M $ be a Riemannian manifold. The length of a piecewise smooth curve $ \gamma\colon [a, b] \to M $ is defined by $$
L(\gamma) = \int_a^b \lvert \gamma'(t) \rvert \,dt,
$$ and the distance function on $ M $ is defined by $$
d(p, q) = \inf \{L(\gamma) \mid \text{$ \gamma $ is a piecewise smooth curve from $ p $ to $ q $}\}
$$ for $ p $ , $ q \in M $ . Question. Let $ \gamma\colon [a, b] \to M $ be a (not necessarily smooth) map. If $ d(\gamma(s), \gamma(t)) = \lvert s - t \rvert $ for all $ s $ , $ t \in [a, b] $ , is $ \gamma $ a unit-speed geodesic? Background. I have read the proof that minimizing curves with constant speed are geodesics and that geodesics are locally minimizing in J. M. Lee’s Introduction to Riemannian Manifolds (2nd edition). Now I wonder if geodesics can be characterized using the distance function.","['riemannian-geometry', 'differential-geometry']"
4090039,Determine continuous function from piecewise derivative,"I'm having trouble solving this issue. Determine a continuous function $f$ on the interval $[-2,2]$ whose derived function on $[-2,2] \setminus \{0\}$ is known to be the function: $$
f(x)=
\left\lbrace
\begin{array}{lll}
\dfrac{x^2+4x+7}{2x^3-x^2+18x-9} & \text{ if} -2 \leq x < 0 \\ 
& \\
x^2 \sin^2 (x) & \text{ if } 0 < x \leq 2
\end{array}
\right.
$$ I tried to calculate the integral of the function in each definition interval, add a constant and impose conditions to determine the constant. I have the problem in the first interval. I can't integrate the function. How do I solve this problem? Thanks!","['integration', 'calculus', 'derivatives', 'piecewise-continuity']"
4090045,some questions about the Robba ring,"Notations and definitions Let $p$ be a prime integer, $k$ be a perfect field of characteristic $p$ and $W(k)$ its ring of Witt vectors. Definition 1 We put $$ \mathcal{R}_r=\bigg\{  \sum_{i\in \mathbf{Z}}a_iu^i: a_i\in W(k)[1/p],  \lim_{i\to \pm \infty} |a_i|\rho^i=0, \rho\in  {[} p^{-r}, 1{)}   \bigg\} $$ In other words, elements of $\mathcal{R}_{r}$ are Laurent series $ \sum_{i\in \mathbf{Z}}a_iu^i$ that satisfies $|a_i|\rho^i\to 0$ when $i\to +\infty$ for any $0<\rho<1$ , and $|a_i|\rho^i\to 0$ when $i\to -\infty$ for any $p^{-r} \leq \rho < 1$ . We define Robba ring to be $$ \mathcal{R}=\bigcup_{r>0}\mathcal{R}_r.  $$ In other words, elements of $\mathcal{R}$ are Laurent series $ \sum_{i\in \mathbf{Z}}a_iu^i$ that satisfies $|a_i|\rho^i\to 0$ when $i\to +\infty$ for any $0<\rho<1$ , and there exists some $r>0$ such that $|a_i|\rho^i\to 0$ when $i\to -\infty$ for any $p^{-r} \leq \rho < 1$ . Definition 2 For any $0< \rho < 1$ , we define the $r$ -Gauss norm over $\mathcal{R}$ as follows: $$  \bigg|   \sum_{i\in \mathbf{Z}}a_iu^i   \bigg|_{\rho}=\sup_i\{ |a_i|\rho^i \}.  $$ Definition 3 The ring $\mathcal{R}_r$ carries a Fréchet topology, in which a sequence converges if and only if it converges under the $\rho$ -Gauss norm for all $\rho \in {[}p^{-r}, 1{)}$ . (For this topology, $\mathcal{R}_{r}$ is complete.) The ring $\mathcal{R}$ carries a limit-of-Fréchet topology , or $LF$ topology. This topology is defined on $\mathcal{R}$ by taking the locally convex direct limit of the $\mathcal{R}_{r}$ (each equipped with the Fréchet topology). In particular, a sequence converges in $\mathcal{R}$ if it is a convergent sequence in $\mathcal{R}_r$ for some $r>0$ . Notations: Let $E(u)\in W(k)[u]$ be the Eisenstein polynomial of $\pi.$ $$\lambda:=\prod_{n=0}^{\infty}\varphi^n(E(u)/E(0))\in \mathcal{R}$$ (Recall that $\frac{E(u)}{E(0)}$ is of the form $1+a_1u+a_2u^2+\cdots +\frac{u^e}{p\cdot unit}$ with $v_p(a_i)\geq 0$ and we can write uniquely $\lambda=\sum_{i\geq 0}\lambda_i u^i$ with $\lambda_i\in W(k)$ .) Put $\mathcal{R}^{+}$ for the series of $\mathcal{R}$ with nonnegative powers of $u$ and $\mathcal{R}^{-}$ for the series with negative powers. The reason I care about $\lambda$ is because I care about the operator $-\lambda u\frac{d}{du}$ over the Robba ring, usually noted $N_{\nabla}$ in literature: for example in Kisin's article ""Crystalline representations and F-crystals."" ) Questions 1. (I gave a negative answer below) In brief, I want to know how big is the image of the operator $-\lambda u \frac{d}{du}$ over the Robba ring modulo $\mathcal{R}^{+}$ : can any element $x\in\mathcal{R}^{-}$ be written in
the form $x=-\lambda u\frac{d}{du}(x_1)+x_2$ with $x_1\in \mathcal{R}$ and $x_2\in \mathcal{R}^{+}$ ? If not, a counter example? Remark 1 The difficulty to describe $Im(-\lambda u \frac{d}{du})$ lies in the factor $\lambda$ : without $\lambda$ , $-u\frac{d}{du}$ is very well-behaved. In other words, multiplication by $\lambda$ is mysterious for me. The following questions are what I expect to help approaching an answer. Any remarks or references for any of the big or small questions below are welcomed. 1.opens For me, Robba ring $\mathcal{R}$ is more complicated than a metric space: you have to deal with a series of $r$ -Gauss norm where $r$ takes values in an interval. Is there a reasonable definition of ""(fundamental system of) open neighborhoods of $0$ "" in $\mathcal{R}$ ? Reasonablely, a series is close to $0$ when it is so under all $r$ -Gauss-norm where $r$ takes value in some interval. By the fact $\mathcal{R}_{r}$ is complete for the Fréchet topology, it is a good candidate of closed neighborhood of zero, and it gives a system when $r$ changes: $r_1>r_2$ implies that $R_{r_1}\subset R_{r_2}$ . 1.1 What should a continuous map over the Robba ring look like? 2.radius For a given element $x=\sum_{n\in\mathbf{Z}}a_nu^n\in \mathcal{R}$ , there exists a smallest $0<r<1$ such that for all $\rho\in (r, 1), \sum_{n\in\mathbf{Z}}a_n\rho^{n}$ converges (i.e. $a_n\rho^{n}\to 0$ when $n\to +\infty$ or $n\to -\infty$ ). I want to define $r$ the radius of $x$ . (Is this well-defined?) Now I want to study what operations can influence the radius of an element. For example: Frobenius map ( $\varphi: \sum_{n\in\mathbf{Z}}a_nu^n\mapsto \sum_{n\in\mathbf{Z}}\varphi(a_n)u^{np}$ ) and its inverse map $\psi$ (when it is well-defined) obviously changes the radius. How about other operations, like multiplication by an element? If $x$ has radius $r_1$ and $y$ has radius $r_2$ , can we have a formula for the radius of $xy$ ? Seems pessimistic as for example take any monimal $u^N$ for $N\in \mathbf{N}$ , having ""radius 0"" by our definition, but $u^N \cdot \sum_{n\in\mathbf{Z}}a_nu^n$ doesn't change the radius no matter how big $N$ is. (You really have to be able to change the power of $u^n$ for $n\gg 0$ to change the radius of $x=\sum_{n\in\mathbf{Z}}a_nu^n$ .) So: 2.1 (Less related) Are there results about how $\mathcal{R}_{r_1}\cdot \mathcal{R}_{r_2}\subset \mathcal{R}_{r_3}$ with a formula $r_3=f(r_1, r_2)$ ? (At least, $\mathcal{R}_{r_1}\cdot \mathcal{R}_{r_2}\subset \mathcal{R}_{r_2}$ when $\mathcal{R}_{r_1}\subset \mathcal{R}_{r_2}$ , since it is a ring. ) 2.2 How is $\lambda \cdot x$ changing the radius of $x$ ? 3.image of multiplication by $\lambda$ modulo $\mathcal{R}^{+}$ About the image of multiplication by $\lambda$ (hence more or less $-\lambda u \frac{d}{du}$ ) over the Robba ring: 2.2.1 (Main question) Can you determine what are the elements of $\mathcal{R}$ that can be written of the form $\lambda \cdot x$ for some $x\in\mathcal{R}$ ? 2.2.2 Is the multiplication by an element, for example $\lambda$ a continuous map? (Remark that for any fixed $r$ -Gauss norm it maps Cauchy sequence to Cauchy sequence.) 2.2.3 Does $Im(\cdot \lambda)$ modulo $\mathcal{R}^{+}$ contains an open neighborhood of $0$ ? Remark 2 By some computations, $Im(-\lambda u \frac{d}{du})$ contains $\mathcal{R}_{r}$ modulo $\mathcal{R}^{+}$ for some $r$ close to $1$ and also I see that any finite sum $\sum_{finite}a_nu^n$ is inside $Im(-\lambda u \frac{d}{du})$ modulo $\mathcal{R}^{+}$ . This implies, by a little more computation, that the image is dense inside $\mathcal{R}$ modulo $\mathcal{R}^{+}$ . Hence I expect also some approaches from functional analysis to tell me how big it is. As I observed my previous question has a negative answer, I now change the question as follows: Question 2: Can any element $x\in\mathcal{R}^{-}$ of the form $x=\sum_{i>0, p\nmid
> i}a_{-i}u^{-i}$ be written in the form $x=-\lambda
> u\frac{d}{du}(x_1)+x_2$ with $x_1\in \mathcal{R}$ and $x_2\in
> \mathcal{R}^{+}$ ? Question 3: https://mathoverflow.net/questions/390160/a-question-on-the-robba-ring","['galois-representations', 'number-theory', 'p-adic-number-theory', 'galois-cohomology', 'algebraic-geometry']"
4090102,How do you find the area of parallelogram from only the sides of a equation,"If you have 4 equation of the 4 sides of a parallelogram how do you find its area? lets suppose the equations as $$A1x+B1y+C1=0 -----(1)$$ $$A1x+B1y+C2=0 -----(2)$$ $$A2x+B2y+D1=0 -----(3)$$ $$A2x+B2y+D2=0 -----(4)$$ My thought process started from $$Area= b*h$$ we can easily find the height, say between (1) and (2) and take (3) or (4) as base $$h= \frac{\left(C1-C2\right)}{\sqrt{A^2+B^2}}$$ And as for the base maybe we could find the intersection of (1) and (2) with (3) taking (3) as the base
using the distance formula we should be able to find the length of the base and hence the area of the parallelogram But is there any elegant way? I hope this isn't a repost as there are a similar couple of question but based on vectors (i am alright with vectors being used, but introduce me like a 4-year-old, I have only a basic understanding, that too from physics.)","['coordinate-systems', 'area', 'geometry']"
4090126,"Prove that $f: \mathbb{R} \to \mathbb{R}, f(x) = x^\frac{1}{9}$ is not a differentiable function","Prove that the following function is not a differentiable function: $$f: \mathbb{R} \to \mathbb{R}, f(x) = x^\frac{1}{9}$$ I believe all I have to show is one point in the domain where the function is not differentiable: Hence I have the following proof: $$ f'(x) =\frac{1}{9x^\frac{8}{9}} $$ At $ x = 0$ , $f'(x)$ is undefined. Hence, $f(x)$ is not a differentiable function. Is this enough or do I need to show that the $\lim\limits_{h\to0} \frac{f(x_0 + h) - x_0}{h}$ does not exist in some other way.","['calculus', 'solution-verification', 'derivatives']"
4090199,Are all simple groups solvable?,"I came across a proof where it is assumed that a simple group is solvable, but I can't really understand how. Is this true? If yes, help to prove it would be very helpful. PS : Question was to prove that all groups of order < 50 are solvable.","['simple-groups', 'group-theory', 'abstract-algebra', 'solvable-groups']"
4090259,What's the relationship between linear transformations and systems of equations? [duplicate],"This question already has answers here : Why can a system of linear equations be represented as a linear combination of vectors? (7 answers) Closed 3 months ago . I began watching Gilbert Strang's lectures on Linear Algebra and soon realized that I lacked an intuitive understanding of matrices, especially as to why certain operations (e.g. matrix multiplication) are defined the way they are. Someone suggested to me 3Blue1Brown's video series ( https://youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab ) and it has helped immensely. However, it seems to me that they present matrices in completely different ways: 3Blue1Brown explains that they represent linear transformations, while Strang depicts matrices as systems of linear equations. What's the connection between these two different ideas? Furthermore, I understand why operations on matrices are defined the way they are when we think of them as linear maps, but this intuition breaks when matrices are thought of in different ways. Since matrices are used to represent all sorts of things (linear transformations, systems of equations, data, etc.), how come operations that are seemingly defined for use with linear maps the same across all these different contexts?","['matrices', 'systems-of-equations', 'linear-algebra', 'linear-transformations']"
4090272,Does there always exist a double transversal?,"Suppose $G$ is a group and $H$ is a subgroup of $G$ . Let's call $T \subset G$ a left/right transversal of $H$ iff it is a system of representatives of left/right cosets of $H$ respectively. Let's call $T$ a double transversal of $H$ iff it is both left and right transversal of $H$ simultaneously. Does a double transversal exist for every subgroup $H$ of $G$ ? In case when $H$ is finite, a double transversal for $H$ can be built the following way: Suppose $g \in G$ is an arbitrary element. Then the double coset $HgH$ can be represented as union of the right and left cosets from the collections $R = \{Hgh' | h' \in H\}$ and $L = \{hgH | h \in H\}$ respectively. Note, that because $\bigcup R = HgH = \bigcup L$ , we have $|L| = \frac{|HgH|}{|H|} = |R| = t$ . Suppose, $R = \{Hgh_i'\}_{i=1}^t$ and $L = \{h_igH\}_{i=1}^t$ Then $h_igh_i' \in Hgh_i \cap h_igH$ . That means, that $\{h_igh_i'\}_{i=1}^t$ is both a system of representatives from $R$ and a system of representatoives from $L$ . Since double cosets partition $G$ , we can repeat the process for all double cosets to form the double transversal we were trying to build. That case is easily generalised to the one when $H$ contains a finite index subgroup $N$ , which is normal in $G$ , by applying the previous result to quotients. However, I have no idea what to do in case when $H$ has no such subgroup.","['group-theory', 'abstract-algebra', 'infinite-groups']"
4090335,Non-unital $C^\star$ subalgebra of a unital $C^\star$ algebra,"Straightforward techniques exist for unitizing a given non-unital $C^\star$ algebra, that is, viewing it as a $C^\star$ subalgebra (in fact, a closed ideal) of a unital $C^\star$ algebra. I am trying to see if something of a similar sort can be done in the opposite direction. Given a unital $C^\star$ algebra $\mathcal{A}$ , when does it contain a $C^\star$ subalgebra (i.e., a norm closed subalgebra) $\mathcal{B}$ that is not unital? How to find such subalgebras, when they exist? Note: The subalgebra $\mathcal{B}$ might fail to contain the multiplicative identity of the full algebra $\mathcal{A}$ , $\mathbb{1}_\mathcal{A}$ , and still end up being unital. Some other element than $\mathbb{1}_\mathcal{A}$ , might end up serving as $\mathbb{1}_\mathcal{B}$ . Partial solution: Such subalgebras can never exist in finite dimensions. It is easy to see from several different arguments (eg, the Artin-Wedderburn theorem, compactness of the unit ball in finite dimensions), that every finite-dimensional $C^\star$ algebra is unital. In the infinite dimensional commutative case, consider $\mathcal{A}\cong C(X)$ for some compact Hausdorff space $X$ such that $X$ contains a limit point $x_0$ . Then $\hat{X}:= X \backslash \{x_0\}$ is a noncompact but locally compact Hausdorff space, and $C_0(\hat{X})$ is (isomorphic to) a closed proper ideal of $C(X)$ , and a non-unital $C^\star$ subalgebra. For $\mathcal{B(H)}$ , of course, $\mathcal{K(H)}$ comes to the rescue (for infinite dimensional $\mathcal{H}$ , $\mathcal{B(H)}$ is unital, while the closed subalgebra (ideal) of compact operators $\mathcal{K(H)}$ is non-unital). How should I proceed in the general case? Otherwise, how to proceed for a) infinite dimensional noncommutative $C^\star$ algebras? b) infinite dimensional commutative $C^\star$ algebras where the spectrum does not contain a limit point? I don't think GNS and step 3) from above will be of much help here, since I don't know if compactness passes on through $\star$ -homomorphisms in a natural way (I don't think it does, but I don't know, really...)","['c-star-algebras', 'functional-analysis', 'operator-algebras']"
4090363,$\mathbb E[Xf(X)] = \gamma \mathbb E[f(X+1)]$ for every $f: \mathbb Z^{\ge 0} \to \mathbb R \implies X$ has distribution $Po(\gamma)$,"If $f:= \mathbb 1_{k}$ for $k \in \mathbb Z^{>0}$ , then $$k\mathbb P(X=k) = \gamma \mathbb P(X = k-1).$$ I used Characteristic Root Technique by letting $\mathbb P(X=k) = t^k$ , but I do not think this can solve the problem. How to show that $\mathbb P(X=k) = \frac{\gamma^k}{k!} e^{-\gamma}$ ?","['poisson-distribution', 'proof-explanation', 'probability-theory', 'probability']"
4090385,Orthonormal Frames don't imply Orthnormal Coordinate Frames,"In Lee's Introduction to Riemannian Geometry he stats that the existence of local orthonormal frames does not imply the existence of a local orthonormal coordinate frame. I am struggling to understand this, so I must be confused about some of the definitions here. Using the 2-sphere as an example, if we have a chart function for the open set, $U$ where $x\gt0$ $$\varphi(x,y,z) = (y, z)$$ $$\varphi^{-1}(y,z) = (1 - \sqrt{y^2+z^2}, y, z)$$ Then we can define our metric, $g$ , on this chart using the typical Euclidean metric on $\mathbb{R}^2$ . Doesn't that automatically make the coordinate vector fields, $\partial_y$ and $\partial_z$ an orthonormal frame? I am obvioiusly missing something in the definitions here. Any help would be appreciated in clarifying.","['smooth-manifolds', 'riemannian-geometry', 'differential-geometry']"
4090408,Show that $A=\sqrt{\left|40\sqrt2-57\right|}-\sqrt{\left|40\sqrt2+57\right|}$ is a whole number,"Show that $A$ is a whole number: $$A=\sqrt{\left|40\sqrt2-57\right|}-\sqrt{\left|40\sqrt2+57\right|}.$$ I don't know if this is necessary, but we can compare $40\sqrt{2}$ and $57$ : $$40\sqrt{2}\Diamond57,\\1600\times2\Diamond 3249,\\3200\Diamond3249,\\3200<3249\Rightarrow 40\sqrt{2}<57.$$ Is this actually needed for the solution? So $$A=\sqrt{57-40\sqrt2}-\sqrt{40\sqrt2+57}.$$ What should I do next?","['algebra-precalculus', 'radicals']"
4090444,Vector space structure of the Zariski tangent space,"Let $X$ be a $k$ -scheme and $p\in X(k)$ . The Zariski tangent space $T_p X$ is usually defined as being the $k$ -vector space $\hom_k(\mathfrak{m}_p/\mathfrak{m}_p^2,k)$ . In general, this coincides as a set with $$\widetilde{T_p X}:=\{f\in X(k[\varepsilon])\:|\: f((x))=p\},$$ where $k[\varepsilon]$ is the ring of dual numbers. I wonder how can we describe the $k$ -vector space structure on $\widetilde{T_p X}$ inherited from $T_p X$ under this identification. The action of $k$ seems to arise in this way: the morphism $k[\varepsilon]\to k[\varepsilon]$ given by $\varepsilon\mapsto a\varepsilon$ , where $a\in k$ , induces a morphism $\operatorname{Spec}(k[\varepsilon])\to \operatorname{Spec}(k[\varepsilon])$ and so $a$ acts on $\widetilde{T_p X}$ by precomposition. Now, I'm not sure if this action coincides with the one inherited by $T_p X$ nor I know how to describe addition of tangent vectors. Also, if $X$ is a group scheme with identity $p$ , then we can describe $\widetilde{T_p X}$ set-theoretically as the kernel of the natural morphism (of groups) $X(k[\varepsilon])\to X(k)$ . Naturally, this kernel is a group. I wonder if the group operation coincides with the vector sum.",['algebraic-geometry']
4090447,"Define an operator $T\in B(C[0,1])$ such that: $(Tf)(x)=xf(x)$ for all $x\in [0,1]$ and $f\in C[0,1]$. Prove that $T$ has no eignvalues","Define an operator $T\in B(C[0,1])$ such that: $(Tf)(x)=xf(x)$ for all $x\in [0,1]$ and $f\in C[0,1]$ .
Prove that $T$ has no eignvalues and find $\sigma(T)$ . I think that what is meant is to show that there are no $\lambda\in C$ such that $Tf(x)=\lambda f(x)$ . By contradiction: $Tf(x)=\lambda f(x)$ = {by definition} = $xf(x)$ . However this equation is true iff $f(x)=0$ for all $x \in [0,1]$ , however we're given that $f\in C[0,1]$ . The spectrum of T is:
All the scalars $\lambda$ such that $\lambda*I-T$ is not invertible.
I am not sure if it is fine to connect that with the first part.
Since T has no eign-values so $T-I$ is not injective then not invertible.","['complex-analysis', 'continuity', 'operator-theory', 'real-analysis']"
4090458,Strongly measurable functions are weakly measurable?,"From Pettis measurability theorem , if $f:X\to B$ is a function on a measure space $(X,\Sigma,\mu)$ taking values in a Banach space $B$ , then $f$ strongly measurable should imply $f$ weakly measurable. $f$ strongly measurable means that there exist a sequence of simple functions $(f_n)$ converging almost everwhere to $f$ . If $g\in B^*$ , with $B^*$ denoting the continuous dual of $B$ , then $(g\circ f_n)$ is a sequence of measurable functions converging almost everywhere to $g\circ f$ . But in general the almost everywhere limit of a sequence measurable functions is not measurable unless the measure space is complete. Am I missing something? Thanks a lot for your help.","['measurable-functions', 'measure-theory', 'functional-analysis', 'real-analysis']"
4090462,Gronwall lemma for system of linear differential inequalities,"Let $u,v:[0,\infty)\to[0,\infty)$ satsfying the following system of differential inequalities: $$ u'(t)\leq a_1\,u(t) + a_2\,v(t) + a_0 \\[4pt]
v'(t)\leq b_1\,u(t) + b_2\,v(t) + b_0 $$ for suitable coefficients $a_0,a_1,a_2,b_0,b_1,b_2\in\mathbb R\,.$ In particular I have $a_1,b_2<0\,$ and $\,0<a_2<|a_1|\,$ , $0<b_1<|b_2|\,$ . Is there a Gronwall lemma for this system of linear differential inqualities? Namely an (optimal) inequality of type $$ u(t) \leq F(t) \\
v(t) \leq G(t)$$ where the functions $F,G:[0,\infty)\to[0,\infty)$ depend on $u,v$ only through their initial values $u(0),v(0)$ ? I remind that for a single differential inequality $$ u'(t) \leq a_1\,u(t) + a_0 $$ the Gronwall lemma guarantees that $$u(t)\leq\, u(0)\,e^{a_1 t} + \frac{a_0}{a_1}\, (e^{a_1t}-1) $$ and it can be proven for example by bounding the derivative of $U(t)\equiv u(t) e^{-a_1t}$ and integrating on the inverval $[0,t]$ . Notice also that the bound is the solution of the differential equation $y'(t)=a_1\,y(t)+a_0\,$ , $y(0)=u(0)\,$ .","['functional-inequalities', 'systems-of-equations', 'linear-algebra', 'ordinary-differential-equations']"
4090504,What does it mean that a functor preserves infinite limits?,"What does it mean that a functor preservers infinite limits?
Can you please give an example of a functor which preserves finite limits but not infinite ones?","['limits', 'limits-colimits', 'functors', 'category-theory']"
4090519,Calculating intersection multiplicities explicitly with Serre's formula,"Let's say I want to explicitly calculate the intersection multiplicity of two subvarieties of $\Bbb A^n_k$ using Serre's Tor-formula (involving as little homological algebra as possible). A typical example [Hartshorne, p.428] consists of two planes in $\Bbb A^4_k$ (we can assume $k$ algebraically closed, if needed) meeting at a point, $X=V(I)$ , with $$I=(x,y)\cap(z,w)=(x,y)(z,w)=(xz,xw,yz,yw)\subset R=k[x,y,z,w],$$ intersecting with a third plane $Y=V(J)$ , with $J=(x-z,y-w)$ . The ""naive"", scheme-theoretic intersection is given by $$\frac{R}{I+J}=\frac{k[x,y,z,w]}{(xz,xw,yz,yw,x-z,y-w)}\cong \frac{k[x,y]}{(x^2,xy,y^2)},$$ which has length 3 (while, clearly, we expect the intersection multiplicity to be 2). Serre's formula gives us the correct multiplicity by defining $$i(X,Y)=\sum_i (-1)^i \operatorname{length} \operatorname{Tor}^R_i(R/I,R/J).$$ We know that for $i=1$ , $\operatorname{Tor}^R_1(R/I,R/J)=(I\cap J)/{IJ}$ . How do we compute this quotient conveniently? (Embarassingly enough, I'm having some trouble calculating generators for $I\cap J$ .) What do we know about $\operatorname{Tor}_i$ for $i\geq 2$ ?","['homological-algebra', 'algebraic-geometry', 'abstract-algebra', 'intersection-theory']"
4090589,Looking for guide to topology of surfaces for non-topologists,"Somewhat related to this . I also understand this might be wishful thinking but I'm looking for a textbook/notes/video giving a simple/minimal framework of the topology of surfaces for nonspecialists more specifically graph theory/discrete optimization. Videos would be especially nice. Something like here are all surfaces up to... and a list of theorems you will likely use a kind of topological toolbox for non-topologists so to speak. Proofs are not really important here. e.g. making sense of and proving Euler's formula for a torus or higher genus surface. Classifying the types of cycles/curves of graphs embedded on a torus or higher genus. Given 2 cycles of the same ""type"" on a torus that intersect at two points and letting P1,P2 and Q1,Q2 be the two paths between the two points on each cycle, either P1,Q1 divide the torus into two regions or P1,Q2 do, further if P1,Q1 do then so do P2,Q2 and generalizations of this to higher genus. Another particular thing I would like to prove is  for a circle D on a torus and 5 loops (closed curves) that intersect D at 5 distinct points non of which divide the torus into two regions some 2 of the 5 loops intersect in at least 2 points.","['graph-theory', 'general-topology', 'surfaces', 'reference-request']"
4090607,Computing $n$-dimensional Lebesgue measure with Euclidean $n$-balls,"I am studying the coarea formula proof from Evans and Gariepy's Measure Theory and Fine Properties of Functions . At the start of lemma 3.5, the authors are assuming that we can compute the $n$ -dimensional Lebesgue measure from coverings of closed balls, namely, that the Lebesgue measure of a measurable set $A\subseteq\mathbb R^n$ equals $$\text{inf}\left\{\left.\sum_{i=1}^\infty\mathcal L^n(B_i)\,\right|A\subseteq\bigcup_{i=1}^\infty B_i,\,B_i\text{ closed ball in }\mathbb R^n\,\right\}$$ I don't think this assumption is obvious at all. I have searched for a while and I have not encountered yet a justification for this. In the only answer to this question , some corollary of the Vitali covering lemma is applied. However, no-one can guarantee that the disjoint closed balls that approximate the rectangles of any covering of $A$ are going to contain, in their union, the set $A$ we are interested in... Thanks in advance for your answers.","['measure-theory', 'lebesgue-measure', 'geometric-measure-theory']"
4090636,Probability calculation for two independent uniform random variables,"I want to calculate the probability $\mathbb{P}\left( \max \{ U, \frac{1}{2} \} \leq X\right) $ with $U, X \sim $ Unif $[0,1]$ and independent. I know that the result is $\frac{3}{8}$ , but do not really know how to get there. I tried \begin{align*}
\mathbb{P}\left( \max \{ U, \frac{1}{2} \} \leq X\right) = \mathbb{P}\left( U  \leq X \text{ and } \frac{1}{2} \leq X\right) \overset{(*)}{=} \underbrace{\mathbb{P}\left( U  \leq X \right)}_{= \frac{1}{2}} \cdot \underbrace{\mathbb{P}\left( \frac{1}{2} \leq X\right)}_{= \frac{1}{2}} = \frac{1}{4}.
\end{align*} At (*) I used the Independence of $X$ and $U$ . Obviously there must be a mistake at some point. Can anybody tell me how to get to $\frac{3}{8}$ ? It can't be that hard, but right now I do not know how to do it properly.","['uniform-distribution', 'probability-theory']"
4090706,Normal bundle $\oplus$ tangent bundle is a trivial bundle,I have the same question as in this post Sum of normal bundle and tangent bundle. I'm wondering how to prove that the sum of the normal bundle and the tangent of a submanifold $M \subset \mathbb{R}^n$ is trivial. The answer to this post didn't contain an explanation to the fact that their  direct sum is equal to the pullback of tangent bundle over $\mathbb{R}^n$ ? Could someone please explain why this is true or give another proof ? Thanks,"['vector-bundles', 'differential-geometry']"
4090758,Solving the definite integral $\int_{0}^{2} \sqrt{(1+x)\sqrt{4x+1}-3x+1}dx$,"I need to solve the definite integral: $$\int_{0}^{2} \sqrt{(1+x)\sqrt{4x+1}-3x+1}dx$$ The integral was proposed by my algebraic geometry professor as a warm up excercise, he hinted us to research about elliptic functions and curves, but I cannot find anything related to this integral. I tried substition and integration by parts, by I can't seem to reduce the problem. I already solved the integral already by proving the convergence of it Taylor Series around $x_0=2$ and integrating said power series. But, its only an approximation, since I can't integrate infinite terms. Is it possible to solve it analytically? What am I missing?","['integration', 'calculus', 'definite-integrals']"
4090774,Rearrangement of Countable Unions?,"Given a family of countable sets $\{ A_i \}$ ,
define $X = \cup_{i \geq 1} A_i$ . Under what conditions (with proof) on $A_i$ , is it possible to rearrange the sets in this countable union? An analogy with series leads us to the rearrangement theorem which says that a series can be rearranged iff it is absolutely convergent. Is there some other rearrangement theorem for unions? Source of this problem is $\sigma$ -algebras: Often when checking for the countable union is closed condition, we rearrange the union (without performing any check) - I was confused as to if this is always allowed?","['measure-theory', 'real-analysis']"
4090788,"Need a formula for the calculation of screen opacity where the starting point is at 0.1, and end point at 0.95","The title does not do it justice, but I have an app in which the screen opacity goes from 0.1 to 0.95 as you scroll down the page. It will be 0.1 when you are at the top, and 0.95 when you are at the bottom, regardless of the screen size. I have the following variables at my disposal: scrollTop: point which my scrollbar currently sits (changes as I scroll up and down, starts at 0) clientHeight (constant): height of the visible content scrollHeight (constant): height of all content, including what is not visible My initial formula was as follows: const variableOpacity = (0.95*clientHeight)/(scrollHeight - scrollTop) Where, 0.95 is the maximum opacity the page is able to achieve. However, the issue is when my scrollTop is 0, I need the opacity to be 0.1, which will not happen in this case, so the formula is flawed. Basically, I need a formula which will have a fixed start and end value of 0.1 and 0.95, respectively. Is this possible to be achieved? If so, what would it be. In case my question is a bit convoluted, I have linked a sample app of the calculation working in action with my current solution and an indication of what is wrong: https://fltrx.csb.app/ Full code sandbox if you want to see the code as well","['continuity', 'functions', 'linear-algebra']"
4090789,"If $A\subseteq\mathbb R^n$ is compact and $f:A\rightarrow\mathbb R^m$ is continuous, then $z\mapsto d(f^{-1}(y),f^{-1}(z))$ is continuous","I am working on a hard measure theory problem on which I'm stuck. I can solve it if I prove the following: let $A\subseteq\mathbb R^n$ a compact set, and let $f:A\rightarrow\mathbb R^m$ a continuous function. Then the map $$f(A)\rightarrow[0,\infty),\quad z\mapsto d(f^{-1}(y),f^{-1}(z))$$ for some fixed $y\in f(A)$ is continuous. Just to make some things clear; let's recall that a closed subset of a compact set is again compact, so for each $z\in f(A)\subset\mathbb R^m$ , $f^{-1}(z)$ will be compact on $A$ , and hence on $\mathbb R^n$ . Let's also recall that we can define the distance between two compact subsets $K$ and $L$ of $\mathbb R^n$ as $$d(K,L)=\text{inf}_{(k,l)\in K\times L}|k-l|$$ I am really stuck at this point. I want to write my function as a composition of continuous functions to conclude the result, but that seems out of my reach at this point. By the way , it may be posible that we require $f$ to be Lipschitz so that all this works out. I don't know if that hypothesis is needed (apparently it isn't), but I can use it freely. Thanks in advance for your answers.","['continuity', 'general-topology', 'metric-spaces', 'compactness']"
4090811,"6 random integers from the set $\{1, 2, 3, 4, 5, 6, 7, 8, 9, 10\}$, at least one pair will have an odd sum.","I would first like to say that I completely understand why and how this works. In the set $\{1, 2, 3, 4, 5, 6, 7, 8, 9, 10\}$ , there are 5 even numbers, and 5 odd numbers. Assuming we choose our first 5 numbers with the same parity, all of their sums are even. This is because $even + even = even$ and $odd + odd = even$ However, when we pick our sixth and last number, this number will have the opposite parity, meaning we have at least one odd sum, since $even + odd = odd$ . However, I am having trouble clearly defining what the pigeons and pigeonholes are. At first, I thought it was Pigeons: 6 integers, at least one will be opposite parity Pigeonholes : 5 ???s But after some thought, I think it is Pigeons : 1 remaining opposite-parity integer Pigeonholes : 0 acceptable spots for an opposite parity integer in order to maintain even sums However, this just seems wrong and kind of unintuitive. I would appreciate any help in explicitly defining the pigeons and pigeonholes.","['pigeonhole-principle', 'discrete-mathematics']"
4090904,Mapping continuously differentiable at a point,"I am reading Coleman's Calculus on Normed Vector Spaces. He defines what it means for a mapping $f: O \to F$ from an open subset $O$ of a normed vector space $E$ to a normed vector space $F$ to be differentiable at a point $x \in O$ . Also, such a mapping is differentiable if it is differentiable at every point in its domain. He than defines that such a mapping is continuously differentiable (or of class $C^1$ ) when it is differentiable and its differential mapping $f': O \to \mathcal{L}(E,F)$ is continuous. He does not define what it means for a mapping to be continuously differentiable at a point (at least I could not find a definition), so I am wondering what such definition would be like. This is what I first thought of: A mapping $f: O \to F$ is continuously differentiable at a point $x \in O$ if there is a neighborhood $N$ of $x$ such that $f$ is differentiable at $N$ and $f': N \to \mathcal{L}(E,F)$ is continuous at $x$ . My questions are: Is it true that a mapping is differentiable at $x$ if, and only if, it has all partial differentials defined at a neigborhood of $x$ and continuous at $x$ (but not necessarily continuous at a neighborhood of $x$ ? Is this definition useful in any other way? Is it necessary to have $f$ differentiable at a neighborhood to talk about continuity at $x$ ? This seemed more intuitive to me but I am not sure this is needed.","['differential', 'multivariable-calculus']"
4090944,Removing a null set from a Jordan-measurable set gives a Jordan-measurable set?,"Let $D$ be a Jordan-measurable subset of $\mathbb{R}^n$ and $S$ be a null set (By a null set I mean a set whose Lebesgue (outer) measure equals 0). In general $D\setminus S$ would not be Jordan-measurable, as the example $S=\mathbb{Q}$ shows. However, my textbook says that if we assume further that the set $D\setminus S$ is open, then $D\setminus S$ must be Jordan-measurable. The book does not give a detailed explanation so I tried to figure this out by myself. I would like to check if my argument is valid, and since my argument is somewhat lengthy, if shorter explanation is possible. We may assume $S\subset D$ . Since $S$ is a null set, its interior must be empty and we have $\overline{S}=\text{Int}(S)\cup\text{Bd}(S)=\text{Bd}(S)$ . Since $D\setminus S$ is open and disjoint from $S$ we have $(D\setminus S)\subset\text{Ext}(S)$ , in other words, $(D\setminus S)\cap\overline{S}=\varnothing$ . Let $p\in\overline{S}$ and assume that $p\notin S$ : If $p\in\text{Int}(D)$ then $p$ becomes a member of $D\setminus S$ but this is impossible since $(D\setminus S)\cap\overline{S}=\varnothing$ . Our assumption $S\subset D$ implies that $p\in\overline{S}\subset\overline{D}=\text{Int}(D)\cup\text{Bd}(D)$ , so we have $p\in\text{Bd}(D)$ . Thus if $p\in\overline{S}$ , then either $p\in S$ or $p\in\text{Bd}(D)$ : we have shown that $\overline{S}\subset S\cup\text{Bd}(D)$ . This implies $S\cup\text{Bd}(D)=\overline{S}\cup\text{Bd}(D)$ , and this last expression is a union of two compact sets. On the other hand, the expression $S\cup\text{Bd}(D)$ is a union of two null sets (since $D$ is Jordan-measurable, $\text{Bd}(D)$ is a null set), so this set is also a null set. Finally since $\text{Bd}(D\setminus S)\subset\text{Bd}(D)\cup\text{Bd}(S)=\text{Bd}(D)\cup\overline{S}$ , the set $\text{Bd}(D\setminus S)$ is a subset of a null set, hence is a null set on its own. Hence $D\setminus S$ is Jordan-measurable. Is the above argument valid?","['multivariable-calculus', 'lebesgue-measure', 'riemann-integration']"
4090954,Set Theory Problem (with Symmetric Differences),"I'm reading ""Shattering-extremal set systems of VC dimension at most 2"" by Tamás Mészáros and Lajos Rónyai, which is not about set theory, but uses a lot of set theory and shows none of its steps. I've been left to fill in the blanks, which I'm really struggling with! I'm trying to draw lots of Venn diagrams but I can't seem to get anywhere. Here is the information: $A\bigtriangleup B=\{x_1\},B\bigtriangleup C =\{x_2\}, D=B\bigtriangleup \{x_1,x_2\}, C\bigtriangleup D=\{x_1\},A\bigtriangleup D=\{x_2\}.$ They claim that the following sets will each be one of $\{A,B,C,D\}$ : $$B\cap D, (B\cap D)\cup \{x_1\},(B\cap D)\cup \{x_2\}, (B\cap D)\cup \{x_1,x_2\}.$$ I'm trying to use the definition of the symmetric difference, but my expressions get very messy very fast. Mészáros, Tamás; Rónyai, Lajos , Shattering-extremal set systems of VC dimension at most 2 , Electron. J. Comb. 21, No. 4, Research Paper P4.30, 17 p. (2014). ZBL1302.05201 .","['elementary-set-theory', 'discrete-mathematics']"
4091043,Transforming sum of random variables and conditional expectation,"Homework warning I've been having a lot of trouble with questions where we transform a random variable with a sum of other random variables. I'll give an example and what I've tried to do (this is not an actual question from my homework but is tangentially related). Say $$X=\begin{cases}-1 , \text{with probability of } \frac{1}{2} \\  1 , \text{with probability of } \frac{1}{2}\end{cases}$$ and $$Y = X + Z, Z \sim Uniform[-1,1],\text{ and } X\perp \!\!\! \perp Z$$ If I'm given $$Y=y$$ I'm completely lost on how I would find $$p(X \mid y) \text{ and similarly } E(X|y)$$ The method I used in the past would be $$F_{X \mid Y}(x \mid y) = P(X \leq x \mid y) = P(y - z \leq x \mid y) = P(z \leq y - x \mid y)=F_{Z \mid Y}(y-x \mid y) 
\\ \Rightarrow p_{X\mid Y}(x \mid y) = \frac{d}{dz}(F_{Z \mid Y}(y-x \mid y))$$ But at that point I get stuck as I don't know if it's correct to assume that $$F_{Z \mid Y}(y-x \mid y)) = F_Z(y-x)$$ or if there's another assumption I should make to transform this into the pdf I want or if that's even the correct method for finding the pdf I want.
I know this question seems like it's all over the place and I apologize in advance for that as I'm very lost at the moment in what route I should be taking. If there's anyway I can clarify things please comment and I'll try my best",['statistics']
4091056,"Finding field of fractions of $k[x,y,z]/(xz - (y^2 + 1))$","Let $k$ be a field and $k[x,y,z]$ be a polynomial ring in the indeterminates $x,y,z$ . Define the quotient ring $$R = k[x,y,z]/(xz - (y^2 + 1)).$$ I guess I was able to show that $R$ is an integral domain. Now, I want to find the field of fractions $F = \operatorname{frac}(R).$ I know that it should be $R(x,y,z)$ (is that correct?), but I am very confused how to find it exactly. Any help will be appreciated! EDIT I knew that the field of fraction of $R$ is $k(x,y)$ or $k(y,z)$ whether you inverted $x$ or $z.$ But now what I am really stuck in the step of the proof that $k(y,z) \subseteq F.$ What exactly should I write to show this inclusion? Any help is greatly appreciated!","['ring-isomorphism', 'field-theory', 'algebraic-geometry', 'abstract-algebra', 'commutative-algebra']"
4091084,"If $S_{n,m}=\sum_{k=1}^{n} k^m =\sum_{j=0}^{m-1} A_{n,j}(m) S_{n,j},$ what are $A_{n,j}(m)$","We know the sum of first $n$ natural numbers, their squares and cubes. sum of higher powers can be worked out using the differences: $k^m-(k-1)^{m}$ . However, these formulas are not remembered well. Recently, Dr. Mythili Subramanian and I  have started wondering if one can write $$S_{n,m}=\sum_{k=1}^{n} k^m =\sum_{j=0}^{m-1} A_{n,j}(m)~ S_{n,j} $$ then what are the expression/name for the coefficients: $A_{n,j}(m)?$ Interestingly, we know the asymptotic result that $$\sum_{k=1}^{n} k^m \sim \frac{n^{m+1}}{m+1}, ~\text{when $n$ is large}.$$ Any suggestion, information or help is welcome here. We are also trying to get it.","['summation-method', 'summation', 'sequences-and-series']"
4091138,On ${\Bbb Z}/m{\Bbb Z}$-torsors.,"I would like to know the explicit construction of ${\Bbb Z}/m{\Bbb Z}$ -torsor $Y$ 's over a scheme $X$ . It is explained that $X$ are classified by $H_{et}^1(X, {\Bbb Z}/m{\Bbb Z})$ , which is far from easy for me to understand. Moreover very recently, I found that I got confused about the difference of a torsor and a locally constant sheaf on a scheme $X$ . It seems that a torsor is not necessarily a sheaf. For instance, choose ${\Bbb Z}/2{\Bbb Z}$ -torsor $Y$ . As long as we consider the canonical isomorphism ${\Bbb Z}/2{\Bbb Z} \cong \mu_2$ , we have $H_{et}^1(X, {\Bbb Z}/2{\Bbb Z}) \cong H_{et}^1(X, \mu_2)$ . Especially for $X = {\mathrm{Spec}}\,k$ with a field $k$ , $H_{et}^1(X, \mu_2) \cong H_{et}^1(\pi_1({\mathrm{Spec}} \,k), \mu_2) \cong k^{*}/{k^{*}}^2$ . So for an element $a \in k^{*}/{k^{*}}^2$ , the corresponding torsor $Y$ is defined as \begin{equation}
Y \colon= {\mathrm{Spec}}\,k[X]/(X^2 - a) \phantom{A} \cdots \cdots \phantom{A}  (\lozenge),
\end{equation} which turns out to be isomorphic to ${\mathrm{Spec}}\,k[X]/(X^2 - 1) \cong \mu_2$ over $k(\sqrt{a})$ . On the other hand, constant group scheme ${\Bbb Z}/3{\Bbb Z}$ over ${\mathrm{Spec}}\,k$ is defined as follows $\colon$ \begin{equation*}
{\Bbb Z}/3{\Bbb Z} \,\colon= {\mathrm{Spec}}\,(k \epsilon_0 \oplus k \epsilon_1 \oplus k \epsilon_2)/(\epsilon_i^2 = \epsilon_i,{\phantom{i}} \epsilon_i \epsilon_j = 0 \phantom{i} {\mathrm{for}}\,i \not= j) \phantom{A} \cdots \cdots \phantom{A}  (\lozenge),
\end{equation*} where the comultiplication is given as $* \colon \epsilon_i \mapsto \underset{k + l = i}{\Sigma} \epsilon_k \otimes \epsilon_l$ . A ${\Bbb Z}/3{\Bbb Z}$ -torsor $Y$ over ${\mathrm{Spec}}\,k$ is clasisfied by $H_{et}^1({\mathrm{Spec}}\,k, {\Bbb Z}/3{\Bbb Z}) \cong H_{et}^1(\pi_1({\mathrm{Spec}} \,k), {\Bbb Z}/3{\Bbb Z}) \cong {\mathrm{Hom}}(\pi_1({\mathrm{Spec}}\,k), {\Bbb Z}/3{\Bbb Z})$ . Let us choose a character $\chi \colon \pi_1({\mathrm{Spec}}\,k) \to {\Bbb Z}/3{\Bbb Z}$ . Q. What is the explicit structure ring ${\cal O}_{\chi}$ which realise ${\Bbb Z}/3{\Bbb Z}$ -torsor $Y \colon= {\mathrm{Spec}}\,{\cal O}_{\chi}$ corresponding to $\chi$ like $(\lozenge)$ ?","['galois-representations', 'number-theory', 'galois-cohomology', 'algebraic-geometry', 'differential-geometry']"
4091188,Closed and open sets through a function between metric spaces,"My professor started an exercise in class with various points. He did not finish it though: he left some of the points as homework and said that he will finish the last one in class. I'm trying it and I would like to have some hints (not full answers, he is going to solve it anyway) and maybe some clarification. I shall write the previous point first, since the other starts from there: Let $(X, d_x)$ and $(\Bbb R, \vert \cdot \vert)$ be metric spaces where $\vert \cdot \vert $ is the absolute value function, let $f:X \to \Bbb R$ be a function between these two metric spaces.
Let $ A= \{(x,y)  \in X\times \Bbb R \mid y\gt f(x)\} $ and $ B=\{(x,y)  \in X\times \Bbb R \mid y\ge f(x) \} $ . Show that, if $f$ is continuous, then $A$ is open and $B$ is closed. I managed to prove this, and I'm interested in the next request. Show that, in general, the converse is not true I interpeted it as : ""give an example of a non continuous function such that $A$ is open and $B$ is closed, thus showing that the fact that $A$ is open and $B$ is closed does not imply that $f$ must be continuous"" However, I'm having some problems finding such a function. I tried choosing $X=\Bbb R$ , but it seems to me that the only good candidate would be a step-like function, and this kind fails to induce both the closed and the open set at the same time, only one of the two. This makes me think that with $(X,d_x)=(\Bbb R,d_x)$ the double implication holds, but I did not try to prove this: does it? If yes, where should I look for finding such function? If no, what am I doing wrong in $\Bbb R$ ? In general, is my approach correct or I should use something else? Thank you. Edit: As we all suspected, and as the user Jochen kindly showed in one of the replies, with the phrase ""show that in general the converse is not true"" he meant that we had to assume only one of the two hypothesis (i.e. assuming either that $A$ is open or that $B$ is closed, not both at the sames time), and in that case using the step function mentioned above it becomes trivial.","['continuity', 'functions', 'functional-analysis', 'metric-spaces']"
4091211,Is there a central limit theorem for $L^p$?,let $Y_i$ be a sequence of identically distributed independent random variables with mean 0 and variance 1.  If $X$ is independent and gaussian with the same mean and variance then does $\frac{1}{\sqrt{n}}(\sum_{i=1}^n Y_i)$ converge in $L^p$ to $X$ ?  The central limit theorem usually holds in distribution but I would like to know if there is a stronger convergence where the sum converges to a gaussian random variable.,"['statistics', 'probability-distributions', 'probability-theory', 'probability']"
4091235,Find the maximum value of $f(\theta)=\frac{\sin(\theta-a)\sin(\theta-b)}{\sin(\theta-c)\sin(\theta-d)}$,"Context : I am deriving the formula for active earth pressure for an inclined soil mass behind a retaining wall. The formula is given in a textbooks (page 25 of Theoretical Foundation Engineering by Braja M. Das ). I am restating the problem without any soil mechanics terminology. Problem : Find the maximum value of the following function $-$ $
f(\theta)=\dfrac{\sin(\theta-a)\sin(\theta-b)}{\sin(\theta-c)\sin(\theta-d)}
$ Solution : Maximum value of the function, as given in the book, is $-$ $
f_{max}=\dfrac{\sin^{2}(a-b)}{\left\{\sqrt{\sin(d-b)\sin(a-c)}+\sqrt{\sin(d-a)\sin(b-c)}\right\}^{2}}
$ My attempt : I tried deriving the above maxima by the following procedure $-$ Obtain the point of maxima, $\theta_{max}$ , by $\left.\dfrac{df(\theta)}{d\theta}\right|_{\theta=\theta_{max}}=0$ I get the following equation $-$ $$
\begin{aligned}
\sin(2\theta_{max}-a-b)\cos(d-c)-\sin(2\theta_{max}-c-d)\cos(a-b)=\sin(c+d-a-b)
\end{aligned}
$$ Which can also be written as $-$ $$
\sin(2\theta_{max}-a-b-c-d)\left[\cos(d+c)\cos(d-c)-\cos(a+b)\cos(a-b)\right]+\cos(2\theta_{max}-a-b-c-d)\left[\sin(d+c)\cos(d-c)-\sin(a+b)\cos(a-b)\right]=\sin(c+d-a-b)
$$ I can obtain $2\theta_{max}-a-b-c-d$ (by writing the above equation as a quadratic), but the equation becomes too complicated to simplify and put back in $f(\theta)$ . Please let me know if there is a better method or if I should go ahead with this method. Thanks PS: I have checked the accuracy of the solution by comparing with the optimum solution in Python. The solution is correct.","['calculus', 'trigonometry', 'real-analysis']"
4091243,Convergence of integral $\int_{17}^\infty \frac{(\ln{\ln{x})}\sin{(e^{ax}})}{x+e}$,"For which $a\in\mathbb{R}$ does the integral $\int_{17}^\infty \frac{(\ln{\ln{x})}\sin{(e^{ax}})}{x+e}$ converge?
I tried with substitution $t=e^{ax}$ , but don't know how to do the rest? Any help is welcome. Thanks in advance","['integration', 'definite-integrals', 'analysis']"
4091267,Is $\cos(2\theta)=\frac{2e^{i\theta}+2e^{-i\theta}}2$ a correct application of Euler's Formula?,"I know that using Euler's Formula we can write cosine like the first expression, but concerning the second expression, is it correct like that? $$\cos(\theta)=\frac{e^{i\theta}+e^{-i\theta}}2$$ $$\cos(2\theta)=\frac{2e^{i\theta}+2e^{-i\theta}}2$$",['trigonometry']
4091280,Is the definition of angular momentum $\vec{L} = \vec{r} \times \vec{p}$ rigorous?,"Let $\vec{r}$ be the position vector in $3\mathrm{D}$ Euclidean space $\mathbb{R}^3$ , and $\vec{p}$ the linear momentum of point mass at $P\in\mathbb{R}^3$ . The angular momentum $\vec{L}$ of that point mass with respect to the origin is defined to be $$\vec{L} = \vec{r}\times\vec{p} = m\vec{r}\times\vec{v}.$$ This feels weird to me, as $\vec{r}$ is a vector in $\mathbb{R}^3$ and $\vec{v}$ is a vector in $T_P\mathbb{R}^3$ ... aren't they? If so, we shouldn't be able to take their cross product, so how can this definition be fixed for the operations to make sense?","['physics', 'differential-geometry']"
4091287,Almost sure convergence of recursively defined Random Variables,"I have a sequence of Random variables that is recursively defined in the following way $$ Y_t = 1 + |Z_{t-1}|Y_{t-1} $$ Here the $Z_t$ are i.i.d. standard normal random variables.
I need to show almost sure convergence of the sequence $Y_t$ . I have managed to show convergence in mean by taking expectations on both sides and finding $$\lim_{t \rightarrow \infty} E[Y_t] = \frac{\sqrt{\pi}}{\sqrt{\pi}-\sqrt{2}}$$ Can I take the same approach by taking limits to conclude $$ Y_t \rightarrow \frac{1}{1-|Z|}=Y \quad \text{a.s.}$$ Where $Z$ a standard normal R.V.? Or does this need a more sophisticated argument, i.e. I've tried showing $\sum E|Y_t -Y| <\infty$ , but couldn't finish the argument","['recurrence-relations', 'almost-everywhere', 'sequences-and-series', 'convergence-divergence', 'probability-theory']"
4091348,Failing to understand some basic idea behind differentiation,"I just discovered I must have some big holes in my knowledge of basic calculus, and this is scary honestly. I have to compute some derivatives of the solution of a dynamical system: \begin{equation*}
\frac{\text d y(t)}{\text dt} = f(t,y(t)),\quad y(t_0) = y_0,\quad t_0\leq t\leq T.
\end{equation*} Say that I have to compute derivatives with respect to $t$ . Clearly, $\dfrac{\text d y(t)}{\text dt}$ is given. I want to compute $\dfrac{\text d y(t)}{\text du}$ with $u<t$ .
I write: \begin{equation*}
y(t) = y(u) +\int_u^t f(\tau,y(\tau))\text d \tau\therefore\dfrac{\text d y(t)}{\text du}=\dfrac{\text d y(u)}{\text du}+\dfrac{\text d}{\text du}\int_u^t f(\tau,y(\tau))\text d \tau=f(u,y(u))+?
\end{equation*} The question mark stays for the fact that I have some uncertainties in how to compute the derivative of the integral by Leibniz rule. I will not report here all my doubts, I could fill pages. I assume $\dfrac{\text d y(t)}{\text du}=0$ with $u>t$ for physical reasons (how can future influence past?), but is it actually true? If I unwind all the computation I will get by chain rule some terms like $\dfrac{\text d t}{\text du}$ . Intuitively, it should be zero, but since $\dfrac{\text d t}{\text du}=\left(\dfrac{\text d u}{\text dt}\right)^{-1}$ , then I would set it to 1. the specific case $\dfrac{\text d y(t)}{\text d t_0}$ is the funniest. I get different results when computing it as \begin{equation*}
\dfrac{\text d y(t)}{\text d t_0} = \dfrac{\text d}{\text d t_0}\left(y_0+\int_{t_0}^t f(\tau,y(\tau))\text d\tau\right) = -f(t_0,y_0)
\end{equation*} or \begin{equation*}
\dfrac{\text d y(t)}{\text d t_0} = \dfrac{\text d y(t)}{\text d t}\dfrac{\text d t}{\text d t_0} = f(t,y(t))
\end{equation*} what about $\dfrac{\text d y(u)}{\text d y(t)}$ with $t<u$ , by Leibniz rule? I obtain different results writing $y(u)=y(t)+\int_t^u f(\tau,y(\tau))\text d\tau$ or $y(u)=y_0+\int_0^u f(\tau,y(\tau))\text d\tau$ $\dfrac{\text d y(u)}{\text d y(t)}$ with $t>u$ would be 0 for physical reasons, or the inverse of what results in point 4, by algebra of differentials. How would you solve these doubts? I think I don't get completely the meaning of derivative ..","['integration', 'calculus', 'derivatives', 'chain-rule', 'leibniz-integral-rule']"
4091359,"If the geodesic curvature of a simple closed spherical curve is monotonic, then it is constant","Let $\gamma$ be a simple closed curve in the unit sphere $\mathbb{S}^{2} \subset \mathbb{R}^{3}$ . I wish to understand how the property of being simple and closed affects the geodesic curvature of $\gamma$ . Clearly, the geodesic curvature can be constant (e.g., geodesics are simple and closed). In general, I suppose that being simple and closed must result in a minimum number of critical points of the geodesic curvature. In fact, my question is the following. If the geodesic curvature $\kappa_{g}$ of $\gamma$ is nonconstant, does it then follow that its derivative $\kappa_{g}'$ changes sign at least once? Hints on how to prove/disprove this statement would also be helpful.","['curves', 'surfaces', 'riemannian-geometry', 'differential-geometry']"
4091361,Questions about a trick for solving quadratic equations quickly,"I just watched a video that teaches a trick to solve some quadratic equations faster: Suppose we have $3x^2-152x+100=0$ It takes a lot of time to solve it
by finding discriminant because we have to calculate $152^2$ and so on. we divide $3x^2$ by $3$ and multiply $100$ by $3$ and we get: $x^2-152x+300=0$ we can solve it easily by factoring $(x-150)(x-2)=0$ then we divide the roots by $3$ so the roots of
original quadratic are $\frac{150}3$ and $\frac23$ It is the first time I see this trick. so is it a known method? And How we can prove this method works mathematically?","['algebra-precalculus', 'quadratics', 'roots', 'factoring']"
4091425,How does this implication follow? (Differential equations),"For an exam I have later today I am studying an old exam question which is accompanied by a solution. The question, and solution, are as follows: Consider the following initial value problem: $$x'(t) = (t + 1)e^{-x(t)}, t \geq 0, \text{with } x(0) = 1.$$ Multiplying both sides with $e^{x(t)}$ yields $x'(t)e^{x(t)} = t + 1$ and hence: $$\int_0^t x'(s)e^{x(s)}ds + c = \int_0^t(s + 1)ds \implies e^{x(t)} = \frac{(t + 1)^2 - 1}{2} + e^{x(0)}$$ Therefore, the solution of the initial value problem is: $$x(t) = \ln\biggl(\frac{(t + 1)^2 - 1}{2}\biggr), \enspace t \geq 0$$ The part that I don't understand is the ' $\implies$ ' part. How does this integral imply this $e^{x(t)} =$ ... solution? I apologize if this question is very trivial, however my professor has uploaded no examples where more steps are shown, and I was unable to find a similar question here or on other websites. Thank you for your time in advance!",['ordinary-differential-equations']
4091428,"Under what conditions is it true that if $f(x) \sim g(x)$ as $x \rightarrow x_0$, then $f'(x) \sim g'(x)$ as $x \rightarrow x_0$?","So we say that two functions $f(x)$ and $g(x)$ of a real variable are asymptotic to each other as $x \rightarrow x_0$ ( $x_0$ need not be finite) if $$ \lim_{x \rightarrow x_0} \frac{f(x)}{g(x)} =1,$$ and in that case we write $f(x) \sim g(x)$ as $x \rightarrow x_0$ . It is also not true generally that if $f(x) \sim g(x)$ , then $f'(x) \sim g'(x)$ . To see this, consider the cases $f(x) = x + \sin(x)$ and $g(x) = x$ . In this cases it is true that $x + \sin(x) \sim x$ as $x \rightarrow \infty$ , yet it is not true $1 + \cos(x) \sim 1$ as $x \rightarrow \infty$ (in fact the latter limit does not even exist). My question is, under what conditions on $f(x)$ and $g(x)$ can we say that it is true that if $f(x) \sim g(x)$ , then $f'(x) \sim g'(x)$ as $x \rightarrow x_0$ .","['calculus', 'asymptotics', 'real-analysis']"
4091515,Every neighborhood of $x_{0}$ contains infinitely many points from a set $A \subset X$ iff $x_{0} \in X$ is a limit point of A.,"Let X be a topological space such that for every $x \in X$ , the set $\{x\} \subset X$ is closed. I have to prove that every neighborhood of $x_{0} \in X$ contains infinitely many different points from A $\subset$ X iff $x_{0} \in X$ is a limit point of A. $(\Rightarrow)$ Assume that every neighborhood of $x_{0} \in X$ contains infinitely many different points from A $\subset$ X. I think I have to pick a row in X. I think I can then say that $x_{0}$ is an accumulation point of X. But does this imply that $x_{0}$ is a limit point of A? $(\Leftarrow)$ Assume that $x_{0} \in X$ is a limit point of A. Then every neighborhood U of $x_{0}$ contains at least one point $x \in A$ with $x \neq x_{0}$ . But this is just one point and not infinitely many points. I don't know how to continue then. And since the set $\{x\} \subset X$ is closed, the set $X \setminus \{x\}$ is open. I get the feeling that I also need this?",['general-topology']
4091532,Derivatives of the geometric series to prove equality,"I have to show that $(1-p)^{-r} = \sum_{k=0}^{\infty} \binom{k+r-1}{k}p^k$ where $p \in (0,1)$ and $r \in \mathbb{N}_{\geq 1}$ . I got the hint that I have to consider the derivatives of the geometric series. Those would be: $\sum_{k=1}^{\infty} kx^{k-1}, \sum_{k=2}^{\infty}\frac{(n-1)n}{2}x^{n-2}, \dots$ I don't see the pattern to somehow connect this to prove my equality. SOLUTION We will prove the statement by induction. Base case: $r=1$ $(1-p)^{-1} = \sum_{k=0}^{\infty} p ^k$ (geometric series), hence base case is true Induction step: Assume $(1-p)^{-r} = \sum_{k=0}^{\infty} \binom{k+r-1}{k}p^k$ for some $r$ . We will show that it is true for $r+1$ . $(1-p)^{-(r+1)}= \sum_{k=0}^{\infty} \binom{k+r-1}{k}p^k \sum_{k=0}^{\infty}p^k$ Using the Cauchy-Product we get: $=\sum_{k=0}^{\infty} p^k\sum_{n=0}^k \binom{n+r-1}{n} $ Sub-Claim $\sum_{n=0}^k \binom{n+r-1}{n} = \binom{k+r}{k}$ Base-Case : $k=0$ is true Induction-step: Assume $\sum_{n=0}^k \binom{n+r-1}{n} = \binom{k+r}{k}$ for some $k$ . We will show it for $k+1$ . $\sum_{n=0}^{k+1}\binom{n+r-1}{n} = \binom{k+1+r-1}{k+1} + \binom{k+r}{k} = \binom{k+1+r}{k+1}$ $\implies $ Sub-claim is true. We will continue with our first induction: $=\sum_{k=0}^{\infty} p^k\sum_{n=0}^k \binom{n+r-1}{n} $ $=\sum_{k=0}^{\infty} p^k \binom{k+r}{k}$ $\implies$ Claim proven","['solution-verification', 'geometric-series', 'sequences-and-series']"
4091535,The existence of a local orthonormal frame,"Given a Riemannian manifold $(M, g)$ and $p \in M$ , is it possible to find a local orthonormal frame about $p$ ? i.e. in $U \ni p$ , there exists $v_1, \cdots, v_n \in TU$ such that $g(v_i, v_j) = \delta_{ij}$ . If I want to find a set of orthonormal tangent vectors $v_1|_p, \cdots, v_n|_p$ at $T_pM$ , then it is merely Gram-Schmidt. However, I am wondering if I can do the same in an arbitrarily small neighborhood. Is it possible to apply Gram-Schmidt on $U$ ?",['differential-geometry']
4091539,Proving for polynomial: $P (1)=0\implies|P'(1)|\leq \frac{\deg(P)}{2}\max_{|z|=1}|P(z)|$.,"I wonder if it is true that any polynomial $P(z):\mathbb C\to\mathbb C$ with $P (1)=0$ satisfies $$|P'(1)|\leq \frac{\deg(P)}{2}\max_{|z|=1}|P(z)|, $$ where the maximum is taken over the unit circle. At least numerically it seems to be the case and the extremizer seems to be $P(z)=z^n-1$ . If $\deg(P)=1$ , then $P(z)=z-1$ . Hence, $P'(1)=1$ and $\max_{|z|=1}|P(z)|=2$ .","['complex-analysis', 'inequality', 'polynomials']"
4091595,Self-similarity of Brownian motion,"I learned in class that Brownian motion is a 0.5-self similar process, which implies that $$(T^{0.5}B_{t_1},\dots,T^{0.5}B_{t_n})\sim (B_{Tt_1},\dots, B_{Tt_n})$$ for any $T>0$ . I am solving a problem and I got $\mathbb{E}(e^{\sigma B_t})$ . Does self-similarity imply that $$\mathbb{E}(e^{\sigma B_t})=\mathbb{E}(e^{B_{\sigma^2t}})?$$","['stochastic-processes', 'statistics', 'brownian-motion', 'probability-theory']"
4091642,Doubt in understanding Differentials,"I am studying smooth manifolds, and recently I got to know about tangent spaces and the differentials. Suppose $f:M \to N$ is a smooth map, then it induces a differential between the tangent spaces $df:T_cM \to T_{f(c)}N$ which is a linear transformation. This is what I read. Now I was trying some examples, and I am stuck here. If I consider $f:\mathbb{R} \to \mathbb{R}$ defined by $f(c)=3c^3$ , then the differential map at $x=c$ is $f'(c)=9c^2$ . Hence the constant map $9c^2:\mathbb{R} \to \mathbb{R}$ is a linear map, which is not the case. I cannot figure out where I am going wrong.","['smooth-functions', 'smooth-manifolds', 'differential-geometry']"
4091655,Total variation does not take into account large distances.,"Let $(X,\Sigma,\mu)$ be a measure space, then define $$|\mu |(E):=\sup\limits_{\pi }\sum _{A\in \pi }|\mu (A)|\qquad \forall E\in \Sigma $$ where the supremum is taken over all partitions $\pi$ of the set $E$ . I have two questions with respect to this total variation norm. First, I am not so  sure why for probability measure we are left with : $${\displaystyle |\mu -\nu |(X)=2\sup \left\{\,\left|\mu (A)-\nu (A)\right|:A\in \Sigma \,\right\}}$$ Second, I read that ""total variation does not take into account large distances"" but I don't really understand how to interpret this sentence.","['total-variation', 'probability-theory', 'intuition']"
4091658,Injectivity of a function of several variables,"Let $f: \Bbb{R}^n \rightarrow \Bbb{R}^n$ be defined as $f(x) = x||x||^2$ for $x \in \Bbb{R}^n$ . I need to prove or disprove the following statement: $f$ is one-one. I think it is a wrong statement as if I take $n = 2$ then determinant of $Df(0) = 0$ which means it is not one-one in any neighbourhood of $(0,0)$ . Hence the given statement is false. But the answer sheet of my book says it is correct. Please confirm","['functions', 'derivatives', 'real-analysis']"
4091689,Difference of the solution at two time instants,"Consider a nonlinear nonautonomous differential equation of the type $$ \dot{z}(t) = f(t,z(t)) $$ with $f:\mathbb{R}^+\times\mathbb{R}^n\rightarrow\mathbb{R}^n$ being a Lipschitz function. Is there some simple way to control the difference, in norm, of the solution at two time instants? For example given an $h>0$ and a $T>0$ , what can we say about $\|z(T+h)-z(T)\|$ , where by $\|\cdot\|$ we refer to the Euclidean norm? My approach was quite classical, i.e. to study $\frac{d}{dt}(\|z(T)-z(T+h)\|^2)$ and proceed aiming to use some Gronwall type inequality, however, I did not get something interesting.","['inequality', 'ordinary-differential-equations', 'dynamical-systems']"
4091735,"Bring the double integral to a single integral: $\iint\limits_{|x| + |y| \le 1} f(x + y) \, dx \, dy$","Bring the double integral to a single integral: $$\iint\limits_{|x| + |y| \le 1} f(x + y) \,dx \,dy$$ The substitution $u = x + y$ seems to be the only way since we should get rid of several variables in the function argument (also, I did $-x+y = v$ for the second variable). First, I split the integral into four: $$\iint\limits_{|x| + |y| \le 1} f(x + y) \,dx \,dy = 
\iint\limits_{0\le x+y\le1} f(x+y)\,dx\,dy +
\iint\limits_{-1\le x+y\le 0} f(x+y)\,dx\,dy + 
\iint\limits_{0\le -x+y\le1} f(x+y)\,dx\,dy + 
\iint\limits_{-1\le -x+y\le0} f(x+y)\,dx\,dy$$ Now, with the substitution, we can deal with the first two: $$\iint\limits_{0\le x+y\le1} f(x+y)\,dx\,dy + 
\iint\limits_{-1\le x+y\le 0} f(x+y)\,dx\,dy = 
\int_0^1 \frac 12 f(u)du + \int_{-1}^0 \frac 12 f(u)du = \frac 12 \int_{-1}^1 f(u)\,du$$ where $\frac{1}{2}$ is the Jacobian. I don't know if I'm going right and do not know how to deal with the next integrals.","['integration', 'multivariable-calculus', 'calculus', 'multiple-integral']"
4091756,Simple Calculation in Flat Cohomology,"Question : Let $R$ be a PID and let $n \geq 2$ be even. What is $H^0_{\operatorname{fppf}}(R,\operatorname{SL}_n/\mu_2)$ ? Attempt at an Answer : From the short exact sequence of algebraic groups $1 \to \mu_2 \to\operatorname{SL}_n\to\operatorname{SL}_n/\mu_2 \to 1$ , we obtain a long exact sequence in fppf cohomology given by $$1 \longrightarrow H^0_{\operatorname{fppf}}(R, \mu_2) = \{\pm 1\} \longrightarrow H^0_{\operatorname{fppf}}(R, \operatorname{SL}_n) = \operatorname{SL}_n(R) \longrightarrow H^0_{\operatorname{fppf}}(R,\operatorname{SL}_n/\mu_2) \longrightarrow H^1_{\operatorname{fppf}}(R,\mu_2) = R^\times/R^{\times 2} \longrightarrow H^1_{\operatorname{fppf}}(R,\operatorname{SL}_n) = 1.$$ Let $K$ be the fraction field of $R$ . From the above, I would guess that $H^0_{\operatorname{fppf}}(R,\operatorname{SL}_n/\mu_2)$ may be described as the subgroup of $\operatorname{SL}_n(\overline{K})/\{\pm 1\}$ consisting of matrices $M$ whose entries are units in a quadratic extension of $K$ such that the Galois-conjugate of $M$ is given by $-M$ . However, I do not know how to prove this. I guess I could try to show that this description is the sheafification of $\operatorname{SL}_n(R)/\{\pm 1\}$ , but that seems to require guessing the answer first, which is unsatisfying. I do know how to answer this question when $R$ is replaced by $K$ and fppf cohomology is replaced by Galois cohomology, but I'm not sure how to imitate that argument over $R$ . Edit : I had previously asked this question with $\mathbb{G}_m$ replacing $\operatorname{SL}_n$ ; as Mindlack pointed out in the comments, the group $H^0_{\operatorname{fppf}}(R,\mathbb{G}_m / \mu_2)$ can be easily computed using the Kummer sequence.","['etale-cohomology', 'number-theory', 'galois-cohomology', 'algebraic-groups']"
4091774,Proof Detail: Cauchy-Riemann Equations Imply Holomorphy,"I'm working through the proof of Theorem 2.4 in Chapter 1 of Stein/Shakarchi's Complex Analysis . I'm looking for clarification on where exactly we use the hypothesis that $u$ and $v$ are continuously differentiable. My guess is that it's used right away when writing $$u(x + h_1, y + h_2) - u(x,y) = \frac{\partial u}{\partial x}h_1 + \frac{\partial u}{\partial y}h_2 + |h|\psi(h)$$ and similarly for $v$ , since that equation comes from $u$ being differentiable as a map $\mathbb{R}^2 \to \mathbb{R}$ , which we can only say provided we know that the partials of $u$ are continuously differentiable. Is this correct?","['complex-analysis', 'cauchy-riemann-equations', 'derivatives']"
4091790,How do I create a permutation group from the Small Group Library? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 3 years ago . Improve this question If I wanted to take SmallGroup(63,3) and turn this into a permutation group, how would I do this? I am trying to confirm some results from a research paper, but am struggling at the first hurdle here.","['permutations', 'gap', 'group-theory']"
