question_id,title,body,tags
805104,Is $\mathbb{C}$ algebraically closed (in a strong sense)?,"Let  $p,q$ be polynomials in $\mathbb{C}[x,y]$ such that the ideal $(p,q)$ is a proper ideal of $\mathbb{C}[x,y]$. Does there exist complex numbers $z,w$ such that
$$p(z,w)=0,\,\,\,\,\,q(z,w)=0\ ?$$ Motivation: Let $K$ be a field and $f$ be a non-constant polynomial in $K[x]$ that does not have a root in $K$. One can choose a non-unit irreducible factor $p$ of $f$ and construct the field extension $K[x]/(p)$. The field resulting will contain an isomorphic copy of $K$ and have a root to $f$. Now if we try to do this for two variables. Again let $K$ be a field. Let $p,q$ be two polynomials in $K[x,y]$. Now if it happens that $(p,q)=K[x,y]$ then there is no hope of finding a field extension of $K$ that will contain solution to the similtaneous equations $p=0,q=0$ for obvious reasons (by considering the evaluation homomorphism). If $(p,q)$ is a proper ideal of $K[x,y]$ then one can choose a maximal ideal containing $(p,q)$. If we set $E=K[x,y]/I$, one can see easily that the field $E$ contains an isomorphic copy of $K$ and has solutions to the similtaneous equations $p=0,q=0$","['algebraic-geometry', 'abstract-algebra', 'polynomials']"
805119,Can we define the normal set without $G$ being a group?,"Let $X$ be a set in $G$ and $G$ be a group. A normal set is a set $X$ for which $gxg⁻¹∈X$ for every $x∈X,g∈G$. It's just like the normality condition for subgroups, except that $X$ doesn't have to be a subgroup. I hvae two questions : (1) Can we define the normal set without $G$ being a group? (2) The normal vector to a surface is a vector perpendicular to it. Does there is a relation between this notion and the notion of normal set?","['geometry', 'group-theory', 'terminology']"
805131,Proof that for every non empty $A \subset \mathbb{N}$ there's a $f:\mathbb{N} \rightarrow \mathbb{N}$ with $f \circ f =f$ and $f(N)=A$,"I need to prove that, for every non empty $A \subset \mathbb{N}$, there's a $f: \mathbb{N} \rightarrow \mathbb{N}$ with $f \circ f =f$ and $f(\mathbb{N})=A$ Unfortunately I have no idea where to start. I'm not even sure what exactly they want me to show, any kind of help would be great. I tried to show it by using $f(x)=2x$ as an example. I see that it works, but how to show the general case?","['proof-writing', 'analysis']"
805151,Best way to solve specific block-tridiagonal linear system (10000x10000 and larger),"To provide more context, this system came from energy balance equation on a mesh with (n,m) nodes in each direction. It's a linear system that looks like this (size of system in blocks n = 4, size of blocks m = 4, 'd' means 'some value'): $$
\left| \begin{array}{cccc|cccc|cccc|cccc}\hline
1 &   &   &   & d & d & d & d &  &  &  &  &  &  &  & \\
1 &-1 &   &   &   &   &   &   &  &  &  &  &  &  &  & \\
1 &   &-1 &   &   &   &   &   &  &  &  &  &  &  &  & \\
1 &   &   &-1 &   &   &   &   &  &  &  &  &  &  &  & \\
\hline
1 &   &   &   & d & d &   & d & d &  &  &  &  &  &  & \\
  & 1 &   &   & d & d & d &   &  & d &  &  &  &  &  & \\
  &   & 1 &   &   & d & d & d &  &  & d &  &  &  &  & \\
  &   &   & 1 & d &   & d & d &  &  &  & d &  &  &  & \\
\hline
&  &  &  & 1 &   &   &   & d & d &   & d & d &  &  &  \\
&  &  &  &   & 1 &   &   & d & d & d &   &  & d &  &  \\
&  &  &  &   &   & 1 &   &   & d & d & d &  &  & d &  \\
&  &  &  &   &   &   & 1 & d &   & d & d &  &  &  & d \\
\hline
&  &  &  &   &  &  &  & 1 &   &   &   & d & d &   & d \\
&  &  &  &   &  &  &  &   & 1 &   &   & d & d & d &   \\
&  &  &  &   &  &  &  &   &   & 1 &   &   & d & d & d \\
&  &  &  &   &  &  &  &   &   &   & 1 & d &   & d & d \\
\hline
\end{array} \right|
$$ [Part of Update 3: further down you may find a genius idea of an uninformed lunatic. The idea below ruins the diagonal dominance for the matrix, so while this New Revolutionary Elimination is significantly faster, it's useless.] By moving first m equations to the last line, i get almost-upper-triangular system: $$
\left| \begin{array}{cccc|cccc|cccc|cccc}\hline
1 &   &   &   & d & d &   & d & d &  &  &  &  &  &  & \\
  & 1 &   &   & d & d & d &   &  & d &  &  &  &  &  & \\
  &   & 1 &   &   & d & d & d &  &  & d &  &  &  &  & \\
  &   &   & 1 & d &   & d & d &  &  &  & d &  &  &  & \\
\hline
&  &  &  & 1 &   &   &   & d & d &   & d & d &  &  &  \\
&  &  &  &   & 1 &   &   & d & d & d &   &  & d &  &  \\
&  &  &  &   &   & 1 &   &   & d & d & d &  &  & d &  \\
&  &  &  &   &   &   & 1 & d &   & d & d &  &  &  & d \\
\hline
&  &  &  &   &  &  &  & 1 &   &   &   & d & d &   & d \\
&  &  &  &   &  &  &  &   & 1 &   &   & d & d & d &   \\
&  &  &  &   &  &  &  &   &   & 1 &   &   & d & d & d \\
&  &  &  &   &  &  &  &   &   &   & 1 & d &   & d & d \\
\hline
1 &   &   &   & d & d & d & d &  &  &  &  &  &  &  & \\
1 &-1 &   &   &   &   &   &   &  &  &  &  &  &  &  & \\
1 &   &-1 &   &   &   &   &   &  &  &  &  &  &  &  & \\
1 &   &   &-1 &   &   &   &   &  &  &  &  &  &  &  & \\
\hline
\end{array} \right|
$$ Using the gaussian eliminiation, i can upper-triangularize it in O(n m^2 + m^3) operations.
Other approach i've tested is to use matrix version of Thomas algorithm, but it costs O(n m^3) actions.
I really need this speed-up of gaussian elimination, as both n and m are going to be somewhat like 100-200-300, but gaussian elimination aggregates double rounding error tremendously fast. With N and M over 15, roots of such system calculated with the use of elimination already differ from ""true"" roots (calculated with the use of LU decomposition) by relative difference of 0.1. If i scale system to even larger M,N, the only thing that i get right with elimination is an order of magnitude of roots, and even that i wont get anymore around N=M=70.
Thomas algorithm works perfect, but i need this speed-up badly. So, the question is. Is there a way to solve such system in less time than O(n*m^3) without losing precision? Mathematically such thing is possible (gaussian elimination ftw), but is there a way i can get precise for at least 3-4-5 significant values roots fast? Update 1:
forgot to post some more info:
precision fall comes from pure gaussian elimination of last lower-right m-sized block. I could solve that last block as separate system with some precise algorithm, but that would complicate overall method a lot. Is there any other ways? Update 2:
Sadly, information in Update 1 is incomplete. Further test have shown that, while last block indeed causes most of error, the whole elimination process wrecks precision. If i do not triangularize last block and try to solve the entire system from this point with QR/LU, around N=M=50 i only get order of magnitude of roots correctly. Update 3:
Huh, wasn't expecting any answers after such a pause :D But @Armadillo Jim noticing this post means it still comes up on some searches, so i guess i can provide an update for everyone interested. Answering his question on why i don't use iterative solvers: The matrices are very badly conditioned. From time to time i have to solve batches of 100+ such systems corresponding to radiative transfer in different parts of spectrum, and noble gases' spectra are not the smoothest things that exist. This results in a ton of systems that only have their shape similar. That means if i am to use iterative solver, i have to recalculate preconditioner for every matrix each time i want to solve aforementioned batch of systems, and preconditioners are just wasted after that, as i am solving those systems exactly once for any given left part (A in AX=B). Of course i could use no preconditioner at all, but this results in thousands of iterations and outright diverging. If somebody is interested, possible ways of solving those systems on regular meshes efficiently are the family of O(N^1.5)..(N^2) Nested Dissection methods (Nested Dissection of a Regular Finite Element Mesh, Alan George, Siam J. on Numerical Analysis, vol. 10, #2, Apr. 1973, 345-363) and their somewhat descendant based on specific properties of hierarchicaly-blockseparable matrices (O(N), A.Gillman, Fast direct solvers for elliptic partial differential equations, phd thesis, 2011). Sadly i may have to move to adaptive meshes and cell-based approach, as now i have to add gas dynamics to the model and single test may run for a week straight on our department's cluster, and if that's the case, i can as well raise mesh resolution and use iterative solvers or what else is used for sparse matrices.","['numerical-linear-algebra', 'matrices', 'linear-algebra']"
805186,Can we solve this equation $\frac{\cos\theta}{\cos{\theta}^2}=k$,"I was in doubt that we can solve these type of Equation or not:
$\frac{\cos\theta}{\cos{\theta}^2}=k$     where $k$ is a given constant.",['trigonometry']
805204,"How can there exist an isomorphism between this group and the cyclic group $(\mathbb Z,+)$?","I have a group over $\mathbb Z$, defined by the binary operation $*$, such that $a*b:=a+b+2$. From the previous exercise, I have deduced that the identity-element is $-2$ and that it is an abelian group under $\mathbb Z$, but the next exercise wants me to prove that it is isomorphic to the cyclic group $(\mathbb Z,+)$. But I dont really know how to write the answer. In the cyclic group $(\mathbb Z,+)$, you have that $(a,b)=a+b$, and in $(\mathbb Z,*)$ you have that $(a,b)=a+b+2$. From my understaning, I must set up an homomorphism between those two groups $(\mathbb Z,+)$ which shows to be surjective and injective, but I'm a bit stuck. Help would be appreciated.","['group-theory', 'abstract-algebra']"
805213,"If $f$ is an anti-symmetric polynomial, then $f=g\prod_{1\leq i < j\leq n}(X_i-X_j)$ for some $g$ symmetric","So we have the situation that $f\in K[X_1,...,X_n]$ is anti-symmetric, which means that $\sigma (f)=\pm f$ where it is a plus if $\sigma$ is an even permutation on the $X_i$ and a minus if it is not an even permutation. Now I have to prove that there exists a $g$ which is symmetric such that $f=g\prod_{1\leq i < j\leq n}(X_i-X_j)$. This is what I thought I should do to prove the statement: If we have permutation $\sigma=(12)$ ,which sends $X_1\mapsto X_2$ and $X_2\mapsto X_1$, then $\sigma(f)=-f$. This implies that $X_1-X_2$ divides $f$ (this is the statement which I am not so sure of). Now we can do this for every permutation $\sigma=(ij)$ where $i\neq j$. Then we have that $\prod_{1\leq i < j\leq n}(X_i-X_j)$ divides $f$. It follows immediately that $g$ must be symmetric. Is this proof valid? Thanks for looking at it.","['symmetric-polynomials', 'abstract-algebra', 'polynomials']"
805248,How prove $a_{n}=[\sqrt{2}n]+[\sqrt{5}n]$ Contains infinitely even numbers.,"let sequence $$a_{n}=[\sqrt{2}n]+[\sqrt{5}n]$$ where $[x]$  is  the largest integer not greater than $x$ show that  $\{a_{n}\}$  Contains infinitely   even numbers. also I guess contains infinitely odd numbers. before I have ask this How prove this sequence $S_{n}=[2^n\cdot \sqrt{2}],n\in N$ contains infinitely many composite numbers I found :
 $$a_{2}=[2\sqrt{2}]+[2\sqrt{5}]=2+4=6$$
$$a_{3}=[3\sqrt{2}]+[3\sqrt{5}]=4+6=10$$
$$a_{5}=[5\sqrt{2}]+[5\sqrt{5}]=7+11=18$$
$$a_{7}=[7\sqrt{2}]+[7\sqrt{5}]=9+15=24$$
$$a_{8}=[8\sqrt{2}]+[8\sqrt{5}]=11+17=28$$
$$a_{9}=[9\sqrt{2}]+[9\sqrt{5}]=12+20=32$$
$$a_{10}=[10\sqrt{2}]+[10\sqrt{5}]=14+22=36$$
$$a_{12}=[12\sqrt{2}]+[12\sqrt{5}]=16+26=42$$
$$a_{14}=[14\sqrt{2}]+[14\sqrt{5}]=19+31=50$$
$$a_{15}=[15\sqrt{2}]+[15\sqrt{5}]=21+33=54$$ and so on
 this problem is my found it. It seem this is interesting problem,and How prove it? Thank you","['sequences-and-series', 'number-theory']"
805273,matrix inverse in tensor notation,"Suppose there is a matrix $A$ that transforms vectors,
$$
   Y = A x
$$
Now express this in some other coordinate system, with $x = B z, \,\, y = B w$, so
\begin{align*}
& Bw = A B z
\\
\Rightarrow & w = B^{-1} A B z
\end{align*}
So $A$ expressed in the other system is $B^{-1} A B$. What would be the equivalent in tensor notation, in particular of the $B^{-1}$?
Here's what I'm trying 
\begin{align*}
& y^i = A^i_j x_j
\\
& \quad\quad x^j = B^j_k z^k
\\
& \quad\quad y^i = B^i_m w^m
\\
\text{so}\quad & B^i_m w^m = A^i_j B^j_k z_k
\end{align*}
Now what is the tensor equivalent of premultiplying by $B^{-1}$ on the left,
in order to find what $A$ looks like in tensor notation in the new coordinate system?","['notation', 'linear-algebra', 'tensors']"
805281,Domain of the Function Square Root of 12th Degree Polynomial,Find the Domain of $$f(x)=\frac{1}{\sqrt{x^{12}-x^9+x^4-x+1}}$$ My Try: The Domain is given by $$x^{12}-x^9+x^4-x+1 \gt 0$$ $\implies$ $$x(x-1)(x^2+x+1)(x^8+1)+1 \gt 0$$ Please help me how to proceed further..,"['functions', 'calculus', 'real-analysis']"
805298,How to find $\int_{0}^{1}\dfrac{\ln^2{x}\ln^2{(1-x)}}{2-x}dx$,"How to find $$
I=\int_{0}^{1}{\ln^{2}\left(x\right)\ln^{2}\left(1 - x\right) \over 2 - x}
\,{\rm d}x
$$ My idea: Let $x=1-t$, then $$
I
=\int_{0}^{1}{\ln^{2}\left(1 - x\right)\ln^{2}\left(x\right) \over 1 + x}\,{\rm d}x
$$ I can't proceed any further. I can't remember that Math SE has this similar problem already posted. this integral problem is from This Euler Sums  :
$$\sum\limits_{n = 1}^\infty  {\frac{1}{{{n^2}}}} \left( {\sum\limits_{k = 1}^n {\frac{{{{\left( { - 1} \right)}^{k - 1}}}}{k}} } \right)\left( {\sum\limits_{k = 1}^n {\frac{{{{\left( { - 1} \right)}^{k - 1}}}}{{{k^2}}}} } \right) =  - \frac{{23}}{{1440}}{\pi ^4}\ln 2 + \frac{1}{{18}}{\pi ^2}{\ln ^3}2 - \frac{1}{{18}}{\ln ^5}2 - 4L{i_4}\left( {\frac{1}{2}} \right)\ln 2 - 8L{i_5}\left( {\frac{1}{2}} \right) + \frac{1}{{12}}{\pi ^2}\zeta \left( 3 \right) + \frac{{27}}{4}\zeta \left( 5 \right)$$ when I deal this series,then we must solve this integral . Thank you.","['calculus', 'integration', 'analysis']"
805316,Constructing The Cayley Graph and quasi-isometry to $\mathbb{Z}$,"If we have a group $G$ defined by: $G=\langle a,b\mid b^2=1\rangle$ then I first need to construct the cayley graph of this, now I think that this is going to look like the ""telephone pole"" metric space (the cayley graph of the group $F(a,b)$) but vertical it will always stop after one application of $b$ I now want to show that this is quasi-isometric to $\mathbb{Z}$. Can I just do this by mapping each vertex $ab^iab^j\cdots$ to $i+j$ in the graph of $\mathbb{Z}$ and sending $b$ to 0?","['geometry', 'general-topology', 'hyperbolic-geometry', 'geometric-group-theory', 'group-theory']"
805366,Optimal String Shape Problem,"So here is the problem I am working on, Given a curve of length L connecting the points (0,1) and (1,0) find an expression for the equation of the curve that minimizes the area underneath it. In other words, given that: $$ y(0) = 1, y(1) = 0$$
minimize $$ \int_0^1{y(x)} dx $$ subject to: $$ \int_0^1{\sqrt{1 + (y')^2} } dx = l $$ So my initial strategy was to do this problem using functional lagrange multipliers (I don't know if thats a real thing but my intuition is that it should work) whereas I make an optimization function $$ \omega = \int_0^1{y(x)} dx + \lambda(\int_0^1{\sqrt{1 + (y')^2} } dx - l) $$ Which can be rewritten as: $$ \omega = \int_0^1{[y(x) + \lambda \sqrt{1 + (y')^2} - \lambda l]} dx  $$ We now compute the functional gradient of it as $$ \nabla \omega  = 0 $$ ---> $$ \frac{\delta \omega}{\delta y} = 0 $$
$$  \frac{\delta \omega}{\delta \lambda} = 0 $$ Which results in $$ 1  - \lambda \frac{y''}{(1 +  (y')^2)^{\frac{3}{2}}} = 0 $$ $$ \int_0^1{\sqrt{1 + (y')^2} } dx = l $$ Now i'm not sure what to do at this stage... Help would be appreciated!! (My problem is I was trying to eliminate $\lambda$ and solve for y as a single differential equation which didn't end up happening As per Alex's Answer The first equation yields that $$ 1  - \lambda \frac{y''}{(1 +  (y')^2)^{\frac{3}{2}}} = 0 $$ We can set $y' = u$ $$ 1  - \lambda \frac{u'}{(1 +  (u)^2)^{\frac{3}{2}}} = 0 $$ Which yields $$ \frac{1}{\lambda} = \frac{1}{(1 +  (u)^2)^{\frac{3}{2}}} u'$$ We can hit this with the Leibniz Chain Rule. To find $$ \int \frac{1}{\lambda} dx = \frac{u}{(1+u^2)^{\frac{1}{2}}} $$ Furthermore that yields $$ \left(\int \frac{1}{\lambda} dx \right)^2 (1 + u^2) = u^2 $$ Which allows us to solve for $u$ as $$ \frac{\int \frac{1}{\lambda} dx}{\left( 1 - \left(\int \frac{1}{\lambda} dx \right)^2 \right)^{\frac{1}{2}} }  = u$$ Then it follows that $$ y = \int  \frac{\int \frac{1}{\lambda} dx}{\left( 1 - \left(\int \frac{1}{\lambda} dx \right)^2 \right)^{\frac{1}{2}} } dx $$ If we add in constants $$ y = \int  \frac{\int \frac{1}{\lambda} dx+C_1}{\left( 1 - \left(\int \frac{1}{\lambda} dx + C_1 \right)^2 \right)^{\frac{1}{2}} } dx + C_2 $$ Now we have the constraints that $$ y(0) = 1, y(1) = 0, \int_0^1{\sqrt{1 + (y')^2} } dx = l $$ Given that $\lambda$ is a function i'm not sure how to proceed.","['ordinary-differential-equations', 'calculus-of-variations', 'nonlinear-optimization', 'lagrange-multiplier', 'functional-analysis']"
805386,Decimal form of irrational numbers,"In the decimal form of an irrational number like:
$$\pi=3.141592653589\ldots$$
Do we have all the numbers from $0$ to $9$. I verified $\pi$ and all the numbers are there. Is this true in general for irrational numbers ? In other words, for an irrational number
$$x=\sum_{n\in \mathbb{Z}} a_n 10^n$$ Does $a_n$ takes all the numbers between $0$ and $9$ ?","['prime-numbers', 'sequences-and-series', 'number-theory']"
805416,Prove that $\prod\limits_i(1+2\alpha_{i})\prod\limits_j(1-2\beta_{j})<\prod\limits_i(1+2x_{i})\prod\limits_j(1-2y_{j})$,"Let $m,n\in N^{+}$ and $i=1,2,\ldots,n,\;j=1,2,\ldots,m\,$ and $\,x_{i},\alpha_{i},y_{j},\beta_{j}$ be real numbers such that $$0\le x_{i}<\alpha_{i}<\dfrac{1}{2},\qquad0\le y_{j}<\beta_{j}<\dfrac{1}{2}$$ Assume that $$\prod_{i=1}^{n}(1+x_{i})\prod_{j=1}^{m}(1-y_{j})=\prod_{i=1}^{n}(1+\alpha_{i})\prod_{j=1}^{m}(1-\beta_{j})$$ Show that $$\prod_{i=1}^{n}(1+2\alpha_{i})\prod_{j=1}^{m}(1-2\beta_{j})<\prod_{i=1}^{n}(1+2x_{i})\prod_{j=1}^{m}(1-2y_{j})$$ this problem seems it's nice.
my idea:
the condition can $$\sum_{i=1}^{n}\ln{(1+x_{i})}+\sum_{j=1}^{m}\ln{(1-y_{j})}=\sum_{i=1}^{n}\ln{(1+\alpha_{i})}+\sum_{j=1}^{m}\ln{(1-\beta_{j})}$$ and prove $$\sum_{i=1}^{n}\ln{(1+2\alpha_{i})}+\sum_{j=1}^{m}\ln{(1-2\beta_{j})}<\sum_{i=1}^{n}\ln{(1+2x_{i})}+\sum_{j=1}^{m}\ln{(1-2y_{j})}$$ then I can't.Thank you","['inequality', 'analysis']"
805436,Solve $\int\frac{\sqrt{(x-5)(x+3)}}{(x-1)(x^2-25)}\ dx$,"I have some problems with the task. How to evaluate
$$\int\frac{\sqrt{(x-5)(x+3)}}{(x-1)(x^2-25)}\ \mathrm{d}x$$
I have absolutely no idea. Help me please. Thank you.","['integration', 'indefinite-integrals']"
805439,prove that a function whose derivative is bounded also bounded,"I got this problem: Let $f$ be a differentiable function on an open interval $(a,b)$ such that $f'$ (the derivative of $f$) is bounded on $(a,b)$ (meaning there exist $0<M$ such that $\forall x\in(a,b), |f'(x)|\leq M$), Prove that $f$ is also bounded on $(a,b)$. I tried to prove it but wasn't able to proceed.
Thanks.","['calculus', 'derivatives']"
805451,Proof of archimedean property,"I am trying to self-study Baby Rudin (and it's proving quite challenging to me) Could someone clarify where the underlined part comes from? Text: (a) If $x \in R, y \in R,$ and $x > 0$ , then there is a positive integer $n$ such that $nx > y$ . Proof (a) Let $A$ be the set of all $nx$ , where $n$ runs through the positive integers.  If (a) were false, then $y$ would be an upper bound of $A$ .  But then $A$ has a least upper bound in $\mathbb{R}$ .  Put $\alpha = \sup A$ .  Since $x > 0$ , $\alpha - x < \alpha$ , and $\alpha - x$ is not an upper bound of $A$ . $\underline{\text{Hence $\alpha - x < mx$ for some positive integer $m$}}$ .  But then $\alpha < (m+1)x \in A$ , which is impossible, since $\alpha$ is an upper bound of $A$ . Thanks in advance",['real-analysis']
805455,Are acyclic coverings cofinal in the set of coverings?,"I am interested by the following question in algebraic geometry. Recall that a covering $\mathfrak{U}$ of a topological space $X$ is acyclic for a sheaf $\mathscr{F}$ if we have $H^q(U_{i_0,\cdots, i_p},\mathscr{F})=0,$ for all $q>0$, where $H^*$ is in my case $\check{C}$ech cohomology (but it could be also more generally sheaf cohomology). My question is : are acyclic coverings cofinal in the set of all coverings of $X$? More precisely, given any covering $\mathfrak{U}$, can we find a finer covering $\mathfrak{V}$ that is acyclic? If the question is not true in general, under which conditions is it true (if it is true)? The question is motivated by a proof of Leray's Theorem ( http://en.wikipedia.org/wiki/Leray%27s_theorem ). Thanks in advance.","['homology-cohomology', 'sheaf-theory', 'algebraic-geometry']"
805470,"Using the substitution $u=x^3$, find the general solution of $xy''+y'+9x^5=0$.","Using the substitution $u=x^3$, find the general solution of $xy''+y'+9x^5=0$. I have no idea about above question? Could somebody suggest me a solution or resource for such problems?",['ordinary-differential-equations']
805479,Summation with Ceilinged Logarithmic Function,"According to Johann Blieberger's paper - ""Discrete Loops and Worst Case Performance"" (1994):
$$
\sum_{i = 1}^{n}\left \lceil \log_2{(i)} \right \rceil = n\left \lceil \log_2{(n)} \right \rceil - 2^{\left \lceil \log_2{(n)} \right \rceil} + 1
$$ Now, I was wondering if someone knows what the following may equal? $$
\sum_{i = 1}^{n}i\left \lceil \log_2{(i)} \right \rceil = ?
$$","['logarithms', 'summation', 'discrete-mathematics', 'ceiling-and-floor-functions']"
805512,"For fixed $z_i$s inside the unit disc, can we always choose $a_i$s such that $\left|\sum_{i=1}^n a_iz_i\right|<\sqrt3$?","Let $z_1,z_2,\ldots,z_n$ be complex number such that $|z_i|<1$ for all $i=1,2,\ldots,n$. Show that we can choose $a_i \in\{-1,1\}$, $i=1,2,\ldots,n$ such that
$$\left|\sum_{i=1}^n a_iz_i\right|<\sqrt3.$$",['complex-analysis']
805518,"Probability that $5 \mid x^4 - y^4$ for random $x, y$","Two numbers $x$ and $y$ are chosen at random without replacement from the set $\{1,2,3,\cdots,100\}$. Find the probability that $x^4 - y^4$ is divisible by $5$. I don't know how to proceed with this problem. So any help would be appreciated.","['probability', 'contest-math']"
805520,why do equations work and how do they relate to each other? [duplicate],"This question already has answers here : Algebra: What allows us to do the same thing to both sides of an equation? (12 answers) Closed 8 months ago . Ok, so I understand that an equation is something like
15 = 15 , and that the only criteria as far as I can tell for it being an equation is that both sides are equal to each other. I have a few questions, the first is a question about why two equations are related to each other? For instance, if I had an equation like 15 = 15 and I subtracted another equation 7 = 7 from it, then I would have 8 = 8, which is still an equation yes, and I understand that it is possible to get back to the original equation by adding 7 to both sides again, but is it directly equal to the original equation without algebraic manipulation? The reason that I ask this first question is that I'm curious about how after algebraic manipulation a result from a newly gotten equation directly applies to the original. If I had x + 5 = 8, and I subtracted the equation 5 = 5 from it, I would get that x = 3. I would then find that I could plug that value into the original and find that 3 + 5 = 8, which is a true equation. But why does subtracting another equation allow me to find the unknown in the original? And finally, what makes equations special and unique from fractions in that you can add, subtract, multiply, divide, etc, all you wish from both sides of an equation but you can't do that with fractions. I understand that when you do that with a fraction, the value changes, however, when you do that with an equation doesn't the equation change? why are equations special? why can you do freely whatever you want to an equation but not a fraction?","['fractions', 'algebra-precalculus']"
805538,How to evaluate this integral with $\sin$ and $\cos$?,$$ \int \sin^6 x\cos^4x\ dx$$ I have absolutely no idea how to solve it. I tried to use formula of degree reduction but failed. Help me please. Thank you.,['integration']
805550,Variance stabilization for Poisson data,"Intro Let $Z > 0$ be a random variable with the mean and variance defined as $\mathbb{E}\{ Z \}$ and $\operatorname{Var}\{ Z \}$, respectively. The variance stabilization transform (VST) $f(z)$ turns heteroskedastic data $z$ to homoskedastic data $f(z)$ with constant variance, e.g., variance equals 1. Poisson distribution For Poisson distributed data with $\mathbb{E}\{ Z \} = \operatorname{Var}\{ Z \}=\lambda$ this VST, so-called Anscombe transformation, is given by [1,2]: $$f(z) = 2\sqrt{z + 3/8}$$ Based on the first order Taylor expansion we can write (this is called Delta method in the literature) [3]: $$\operatorname{Var}\{f(z)\} \approx  \left( \left.\frac{df}{dz}\right|_{z=\mathbb{E}\{ Z \}} \right)^2 \operatorname{Var}\{Z\} = \frac{\operatorname{Var}\{Z\}}{\mathbb{E}\{ Z \} + 3/8}$$ Problem I performed a Monte Carlo simulations to compare sample variance of the stabilized data $f(z)$ and the variance obtained by the above equation, i.e., $\operatorname{Var}\{f(z)\}$ both numerically as a sample variance and theoretically as follows: $$\operatorname{Var}\{f(z)\} \approx \frac{\lambda}{\lambda + 3/8}$$ Moreover, I went further and derived second order approximation for $Var\{f(z)\}$. There is a mismatch between variance of stabilized data $f(z)$ (green curve) and those obtained theoretically and numerically by means of the $\operatorname{Var}\{f(z)\}$. Can anyone explain me this inconsistency? Anscombe, F. J. (1948), ""The transformation of Poisson, binomial and negative-binomial data"", Biometrika 35 (3–4): 246–254, doi:10.1093/biomet/35.3-4.246, JSTOR 2332343 http://en.wikipedia.org/wiki/Anscombe_transform Kendall's Advanced Theory of Statistics: Volume 1: Distribution Theory by Alan Stuart and Keith Ord (Apr 20, 2009), page. 351, eq. 10.14","['statistics', 'transformation', 'random-variables']"
805565,What is the inverse of the $\mbox{vec}$ operator?,"There is a well known vectorization operator $\mbox{vec}$ in matrix analysis. I've vectorized my matrix equations, did some transformation of vectorized  equations and now I want to get back to the matrix form. Is there special operator for it?","['matrices', 'linear-algebra', 'matrix-equations', 'terminology', 'vectorization']"
805580,What is the probability that the selected function maps prime numbers to prime numbers?,"Let $X = \{1, 2, 3, . . . , 25\}$ . If a student selects a function randomly from the set of all functions from $X$ onto $X$ , then what is the probability that the selected function maps prime numbers to prime numbers ? No idea how to proceed, please guide.","['probability', 'functions', 'combinatorics']"
805590,How can I prove that $Aut(C_p\times C_p)\simeq GL_2(\mathbb Z/p\mathbb Z)$?,"How can I prove that $Aut(C_p\times C_p)\simeq GL_2(\mathbb Z/p\mathbb Z)$? No theorical argument came to my mind, so I'm trying to build explicitly an isomorphism $\phi:Aut(C_p\times C_p)\longrightarrow GL_2(\mathbb Z/p\mathbb Z)$, but I'm stuck. Can someone help me please? Thank you all","['finite-groups', 'group-theory', 'abstract-algebra']"
805594,Is there a definition of a dual Lie algebra?,"Let $L$ be a Lie algebra. For vector spaces, modules, Banach spaces, etc. we have the notion of a dual. Question: Is it possible to define naturally a Lie algebra $L^*$ that is in some sense dual to $L$? If $L$ is semisimple over an algebraically closed field of characteristic zero, then $L$ is uniquely determined by its root system, and there is a good definition of a dual root system. So if $L$ has root system $\Phi$, we could define $L^*$ to be the semisimple Lie algebra with dual root system $\Phi^\vee$. Does this make sense? Is this a good definition? Is there a definition of a dual that would be consistent with this? Looking up ""dual of a Lie algebra"" on the internet brings up pages about Lie coalgebras , which seems to be the dual of the category of Lie algebras. I also found that we can define a Poisson manifold structure of the dual vector space $L^*$. The definition of a Poisson  manifold looks similar to that of a Lie algebra, but I do not really know anything about this, and the material on that wikipedia page goes way over my head.","['root-systems', 'lie-algebras', 'abstract-algebra']"
805617,Evaluate $\int_0^1\frac{x\ln x}{(1+x^2)^2}\ dx$,"$$\int_0^1\frac{x\ln x}{(1+x^2)^2}\ dx
$$
Help me please. I don't know any ways of solution. Thank you.","['definite-integrals', 'improper-integrals', 'calculus', 'integration']"
805648,Charactristic polynomial of a F-linear transformation with respect to Galois group,"Let $K$ be a Galois extension of $F$, and let $a \in K$. Let $L_a : K \to K$ be the $F$-linear transformation defined by $L_a(b)=ab$. Show that the characteristic polynomial of $L_a$ is $\prod_{\sigma \in \operatorname{Gal}(L/K)}(x- \sigma (a))$ and the minimal polynomial of $L_a$ is $\min(F,a).$","['galois-theory', 'linear-algebra']"
805656,Clarifying definition of outward unit normal,"I would like to figure out how to properly define the outward unit normal vector $\nu$ for a bounded domain $\Omega \subset \mathbb{R}^n$ with smooth boundary $\partial \Omega$ ($n \ge 2$). I am following Gilbarg and Trudinger's Elliptic Partial Differential Equations of Second Order . This function $\nu$ doesn't seem to be defined anywhere in Gilbarg and Trudinger, but it is used often, and even at the beginning of the text, when the divergence theorem is stated. First, I will start with a definition from section 6.2 in Gilbarg and Trudinger: Let $\Omega \subset \mathbb{R}^n$ be a bounded domain. We say $\partial \Omega$ is of class $C^k$ if and only if, for each $x_0 \in \partial \Omega$, there is a open ball $B(x_0) = B$ and an bijective function $\psi \colon B \to D \subseteq \mathbb{R}^n$ so that: $\psi(B \cap \Omega) \subseteq \mathbb{R}^n_+ = \{x \in \mathbb{R}^n | x_n > 0\}$, $\psi(B \cap \partial \Omega) \subseteq \partial \mathbb{R}^n_+ = \{x \in \mathbb{R}^n | x_n = 0\}$, $\psi \in C^k(B), \psi^{-1} \in C^k(D)$. Note: D is open in $\mathbb{R}^n$ by invariance of domain. Now, starting with this definition, I would like to come to a suitable definition for the outward unit normal (i.e., a definition that makes the divergence theorem hold). Here's what I have so far. For $x_0 \in \partial \Omega$, we can let $\psi = (\psi_1, \dots \psi_n) : B \to D$ be as in the definition above, and then notice that $B \cap \partial \Omega$ is a level set of the function $\psi_n$ ($\psi_n \equiv 0$ on $B \cap \partial \Omega$). Now, from multivariable calculus, I remember learning that $\nabla \psi_n(x_0)$ ""points perpendicular"" to the level set $B \cap \partial \Omega$. Intuitively, this seems to be to the property that we want $\nu$ to possess, so it seems like a good attempt to define  $\nu(x_0) = \frac{\nabla \psi_n(x_0)}{||\nabla \psi_n(x_0)||}$. However, I see two issues with trying to make this our definition for $\nu$. How do we know that $\nabla \psi_n (x_0) \neq 0$, so that we can make it into a unit vector? Since the map $\psi$ corresponding to a particular ball is not necessarily unique, how do we know that $\nu$ is well defined? Any comments are greatly appreciated!","['multivariable-calculus', 'partial-differential-equations']"
805658,Chromatic recurrence,"1) How do you prove the Chromatic recurrence theorem: $$χ(G;k)=χ(G−e;k)−χ(G·e;k)$$ I'm thinking by induction, but then you would have to assume something about the type of graph G...surely it can't be done any other way? 2) (See below - please ignore my numbering)! Let this graph be G. Find an explicit formula for $χ(G;t)$. My answer: $χ(G;k) = k(k-1)(k-2)^2(k-3)^2$ Is this correct? Or is this not an 'explicit' formula?","['graph-theory', 'discrete-mathematics']"
805677,What to do to calculate $\int_{-\pi/4}^{+\pi/4}e^{-\tan\theta}\mathrm{d}\theta$,"I have to calculate the following integral:
$$A=\int_{-\pi/4}^{+\pi/4}e^{-\tan\theta}\mathrm{d}\theta.$$
What I did:
Let $t=\tan\theta$. Thus, $\dfrac{\mathrm{d}t}{\mathrm{d}\theta}=1+\tan^2\theta=1+t^2.$
Therefore, 
$$A=\int_{-1}^{+1}\dfrac{e^{-t}}{1+t^2}\mathrm{d}t.$$
Now, I write $\dfrac{1}{1+t^2}=\sum\limits_{k=0}^{\infty}(-t^2)^k.$
And therefore, $$A=\int_{-1}^{+1}\sum\limits_{k=0}^{\infty}(-1)^k t^{2k}e^{-t}\mathrm{d}t.$$
What to do now? Also, what to do to calculate $$B=\int_{\pi/4}^{\pi/2}e^{-\tan\theta}\mathrm{d}\theta.$$
Should I do the same as the previous case? Thanks.","['sequences-and-series', 'integration']"
805684,Proving variance of U-statistics is decreasing,"I read Wassily Hoeffding's paper ""a class of statistics with asymptotically normal distribution"". In proving ""$n\sigma^{2}(U_{n})$ is decreasing in n"" in Theorem 5.2, it simply says ""using (5.33) and (5.31)"". Yet this is not obvious to me. Is there any other proof I can find to read? Thank you.",['statistics']
805693,Find $\lim _{ n\to\infty}\sum _{k=1}^{n}\frac{\sqrt{k}}{{n}^{\frac{3}{2}}}$,Need help computing: $\displaystyle\lim _{n\to\infty}\sum _{k=1}^{n}\frac{\sqrt{k}}{{n}^{\frac{3}{2}}}$ Now my intuition is that using Stolz-Cesaro $\displaystyle\lim _{n\to\infty}\sum _{k=1}^n\frac{\sqrt{k}}{n^{\frac{3}{2}}}=\lim _{ n\to\infty}\frac{1}{n}\sum _{k=1}^n\sqrt{\frac{k}{n}}=1$ Is it correct or not?,"['sequences-and-series', 'calculus', 'limits']"
805703,find all values of k for which A is invertible,"$\begin{bmatrix}
k &k  &0 \\ 
k^2 &2  &k \\ 
 0& k & k
\end{bmatrix}$ what I did is find the det first: 
$$\det= k(2k-k^2)-k(k^3-0)-0(k^3 -0)=2k^2-k^3-k^4$$ when $det = 0$  the matrix isn't invertible $$2k^2-k^3-k^4=0$$
$$k^2(k^2 +k-2)=0$$
$$k^2+k-2=0$$
$$(k+2)(k-1)=0$$
$k = -2$ or $k = 1$. I am lost here how to find the value for k when the matrix is invertible.","['matrices', 'linear-algebra']"
805704,$ \tan 1^\circ \cdot \tan 2^\circ \cdot \tan 3^\circ \cdots \tan 89^\circ$,"How can I find the following product using elementary trigonometry? $$ \tan 1^\circ \cdot \tan 2^\circ \cdot \tan 3^\circ \cdots \tan 89^\circ.$$ I have tried using a substitution, but nothing has worked.","['trigonometry', 'algebra-precalculus', 'products']"
805718,How to prove that the inverse of a matrix is unique?,The ring of matrix is not an integral domain. How to prove that the inverse is unique?,"['matrices', 'ring-theory', 'linear-algebra', 'abstract-algebra']"
805756,Second derivative of $\frac{\ln t}{\sqrt t}$ and derivative of $\arccos(1-2x^2)$,"$f(t)=\dfrac{\ln t}{\sqrt t}$ I'm stuck on the algebra of finding the second derivative. For the first derivative, I got: $f'(t)=\dfrac{t^{\frac{-1}{2}}(1-\frac{1}{2}\ln t)}{t^2}$ For the second derivative, I'm stuck on the algebra... If someone could differentiate this and show me the steps, I'd really appreciate it. Also: Differentiate $y=\arccos(1-2x^2)$ with respect to x, and simplify your answer. So far I have: $\dfrac{-4x}{\sqrt{4x^2-4x^4}}$ Am I on the right lines?",['derivatives']
805796,How do I transform an r.v. using the floor function? (exponential distribution),"Just had a bash at this question for my Intro to Maths Stats module...I got to the end with a probability density function rather than a probability mass function, namely $f_Y(y) = \lambda a e^{-\lambda a y}.$ Obviously I'm missing some subtleties with the floor function that makes the new r.v. into a probability mass function instead. Anyways, here it is... Suppose $X$ is an $\text{exponential}(\lambda)$ r.v. given by 0 for $x$ < 0 and $\lambda e^{-\lambda x}$ for $x \geq 0$ . Recall the function $\lfloor x\rfloor$ is defined as the largest integer $n \leq x.$ Let $Y$ be defined by $ Y = \lfloor \frac{X}{a} \rfloor$ , where $a$ > 0. Find the probability mass function of $Y$ and hence deduce that $Y$ is a geometric r.v., stating its parameter. Thanks in advance (should be a quick one!)
Sam","['probability-distributions', 'probability', 'exponential-distribution']"
805820,conditional expectation of brownian motion,"Let $(B_t)_{t\geq 0}$ be a standard Brownian motion in $\mathbb{R}^d$. It is intuitive that, for fixed $s<t<u$ $$\mathbb{E}[B_t\mid \sigma(B_s,B_u)]=B_s+\frac{t-s}{u-s}(B_u-B_s).$$ However, I cannot think of a way to show this rigorously. If first attempted to take $A\in\sigma(B_s,B_u)$ and show that $\mathbb{E}[1_A B_t]=\mathbb{E}[1_A(B_s+\frac{t-s}{u-s}(B_u-B_s))]$. But I cannot manage to show this equality. I'd be very thankful for any ideas and suggestions on how to tackle this problem.","['probability-theory', 'brownian-motion', 'conditional-probability']"
805821,How can I find the following product? $ \tan 20^\circ \cdot \tan 40^\circ \cdot \tan 80^\circ.$,"How can I find the following product using elementary trigonometry? $$ \tan 20^\circ \cdot \tan 40^\circ \cdot \tan 80^\circ.$$ I have tried using a substitution, but nothing has worked.","['trigonometry', 'algebra-precalculus']"
805835,A Polish space which is not locally compact,"I want to find an example of Polish space which is not locally compact. I am thinking about the space of all continuous function from $[0,1]$ to $R$, endowed with the metric $d(f,g) = \sup_{x\in [0,1]}|f(x)-g(x)|$. I know this space is complete. And by Weierstrass Approximation Theorem, all the polynomials with rationals coefficients are a countable dense subset of it, so it is Polish. Then suppose the function $f=0$ has a compact neighbourhood, then there exists $r >0$ such that all the continuous functions bounded by $r$ are in the neighbourhood. But then we can define a sequence of functions such as $g_n(x) = \begin{cases} 0, x<a_n\\ r,x>a_{n+1}\\r \frac{x-a_n}{a_{n+1} - a_n}, a_n \leq x\leq a_{n+1}\end{cases}$, where $(a_n)_n$ increases to(but never reaches) 1. Then for $m,n$ different, we have $d(g_n, g_m) = r$, so the function $f=0$ has no compact neighbourhood. Therefore this space is not locally compact. Did I miss something?",['general-topology']
805857,Countable sum of measures is a measure,"Prove that if $\mu_1, \mu_2, \dots$ are measures on a measurable space and $a_1, a_2, \dots \in [0,\infty)$, then $\sum_{n=1}^\infty a_n\mu_n$ is also a measure. I need some help justifying the third equality in the final line of my proof. My idea was to break this into finite and infinite cases and use facts about absolute convergence, but I'm not sure of the details. My solution: First, we let $(X, \mu_n, \mathcal A)$ be a measure space for all $n\in \mathbb N$ and define $\nu_n = a_n\mu_n$.  Since $\nu_n(\emptyset) = a_n\mu_n(\emptyset) = a_n\cdot0=0$ and $$\nu_n(\cup_{i=1}^\infty A_i) = a_n\mu_n(\cup_{i=1}^\infty A_i) = a_n\sum_{i=1}^\infty \mu_n(A_i) = \sum_{i=1}^\infty a_n\mu_n(A_i) = \sum_{i=1}^\infty \nu_n(A_i),$$
we know that $\nu_n$ is a measure for all $n\in \mathbb N$. So we are reduced to the case that a countable sum of measures is again a measure. Let $\mu = \sum_{n=1}^\infty \nu_n$. Since $\nu_n(\emptyset) = 0$ for all $n \in \mathbb N$, then $\mu(\emptyset) = \sum_{n=1}^\infty \nu_n(\emptyset) = 0$. So, we show that $\mu$ is countably additive. That is, if $A_i\in \mathcal A$ for all $i \in \mathbb N$ are pairwise disjoint, we show $\mu(\cup_{i=1}^\infty A_i) = \sum_{i=1}^\infty \mu(A_i)$. Then,
\begin{align*}
\mu(\cup_{i=1}^\infty A_i) &= \sum_{n=1}^\infty \nu_n(\cup_{i=1}^\infty A_i) =\sum_{n=1}^\infty\sum_{i=1}^\infty \nu_n(A_i) = \sum_{i=1}^\infty\sum_{n=1}^\infty \nu_n(A_i) = \sum_{i=1}^\infty \mu(A_i). \\
\end{align*}",['real-analysis']
805884,Undergraduate Introduction to Modular Forms,What are the best introductory texts (or lecture notes) on modular forms aimed at an advanced undergraduate audience (for a student with a course in complex analysis and two courses in algebra and analysis each)?,"['modular-forms', 'reference-request', 'number-theory']"
805893,"A logarithmic integral $\int^1_0 \frac{\log\left(\frac{1+x}{1-x}\right)}{x\sqrt{1-x^2}}\,dx$","How to prove the following $$\int^1_0 \frac{\log\left(\frac{1+x}{1-x}\right)}{x\sqrt{1-x^2}}\,dx=\frac{\pi^2}{2}$$ I thought of separating the two integrals and use the beta or hypergeometric functions but I thought these are not best ideas to approach the problem. Any other ideas ?","['definite-integrals', 'improper-integrals', 'calculus', 'integration']"
805899,Linear and monotone mapping,"Let $f:\mathbb{R}^n \rightarrow \mathbb{R}^n$ be continuous and monotone , i.e.,
$$ \left( f(x) - f(y) \right)^\top \left( x-y\right) \geq 0$$
for all $x,y \in \mathbb{R}^n$. Say for which matrices $A \in \mathbb{R}^{n \times n}$, the function $x \mapsto A f(x)$ is monotone as well.","['operator-theory', 'real-analysis', 'analysis', 'hilbert-spaces', 'functional-analysis']"
805902,Lines tangent to parabola at point.,"I'm struggling to figure out what I'm exactly required to do. The problem states ""Compute which lines through the point $(1, 0)$ that are tangent to the parabola defined by $y = x^2$."" I believe it's a simple question however I've been going around this for quite a bit. I'll appreciate any kind of help! Thank you!",['derivatives']
805912,When is it useful to reduce mathematical objects to foundational levels and when it is not?,"When is it useful to reduce mathematical objects to foundational levels and when it is not? Let's say you work in the field of computer vision, or else.
How can you claim your method is optimal if you don't prove it down
to the lowest levels of mathematics? Here are two cases when it helps to get things down to low levels and when it is
not so useful: 1) A relation R is defined as set of ordered pairs (x,y), such that the relation
x R y holds. You can think of a relation in two ways: the intuitive, where you think
ok I have two objects x and y and there is relation between them, or you can think
of it the set theory way where a relation is a set of pairs. In this case reducing
the relation down to set theory, does add new knowledge or view on what a relation
is and can be helpful. The idea of an empty relations is very useful, meaning
that that relation does not hold for no two objects. In summary, it is useful
to think about a relation both the intuitive and the set theory way. 2) On the other hand for some things it is not useful to get them down to the
fundamental levels. For example, an ordered pair. Intuitively you know what it is.
Then the question is, can I learn more about it from its set theory definition?
My opinion is no, because a pair (x,y) is expressed as {{x}, {x,y}} and that
definition in terms of sets does not really add any new understanding to the idea
of an ordered pair. It is just a set theory code, cryptic code, that just puts
that mathematical object in se","['philosophy', 'foundations', 'elementary-set-theory']"
805916,Uniform convergence,I got a task: research $$\sum_{n=1}^\infty~e^{-nx^2}\sin nx$$    for a uniform convergence. I see that  $ \sup_{x\in X} |f_n(x)-f(x)|\to 0 $ when $x\ne0$. But what I must do when $x=0$?,"['convergence-divergence', 'sequences-and-series', 'real-analysis', 'uniform-convergence']"
805918,"Prove that when dividing a square field among three people, one person must own two points more than 1 km apart","We have a square field with a $1$ km side we need to divide among three people (it doesn't have to be fair, one of them could even get none of it!).
How would I prove that at least one of the persons owns two points distant by strictly more than $1$ km ? The way the square is divided doesn't have any special restriction (for instance, it would even be : all the points with rational distance from the upper left corner goes to the 1st person etc etc) If someone doesn't have anything, then it's obvious (it would mean that the two others would both have two corners on a side, and by drawing two circles for each we would see that some of the area would not be given to anyone.) If one of the persons has 3+ corners, it's obvious.
Let's suppose one of the persons has at exactly two corners.
We can also show easily that if the two other corners belong to the same person, the problem becomes obvious. ($\rightarrow$ we'd just need to draw the circles from the case where one of the persons has no area at all, and then give the area not in the circles to that person. It then becomes obvious that person would own segments on opposite sides, which would imply there are two points verifying the requirement.) How would I solve it when one person has two corners, and the two others each have one corner ?",['geometry']
805932,$\iiint \frac{1}{x^2+y^2+(z-2)^2}dA$ where $A=\{x^2+y^2+z^2 \leq 1\}$ check my answer!,"I would like someone to review my solution please, the original question is to calculate $\iiint \frac{1}{x^2+y^2+(z-2)^2}dA$ where $A=\{x^2+y^2+z^2 \leq 1\}$ What I did: First I changed variables to polar coordinates in order to simplify the boundaries: $x=r\sin\theta cos\phi$, $y=r\sin\theta \sin\phi$, $z=r\cos\theta$, $0\leq r \leq 1$, $0\leq \theta \leq \pi$, $0 \leq \phi \leq 2\pi$ and the jacobian is $r^2\sin\theta$. to get the following result: $$\int_{0}^{2\pi}\int_{0}^{\pi}\int_{0}^{1} \frac{r^2sin\theta}{r^2-2rcos\theta+4}drd\theta d\phi$$ We can see that $\phi$ doesn't appear in any integral, so we can just multiply by $2\pi-0=2\pi$ and forget about it: $$\int_{0}^{2\pi}\int_{0}^{\pi}\int_{0}^{1} \frac{r^2sin\theta}{r^2-2rcos\theta+4}drd\theta d\phi =2\pi \int_{0}^{\pi}\int_{0}^{1} \frac{r^2sin\theta}{r^2-2rcos\theta+4}drd\theta$$ now I used substitution, $\alpha=-cos\theta$, $d\alpha =sin\theta d\theta$, $-1 \leq \alpha \leq 1$ $$2\pi \int_{0}^{\pi}\int_{0}^{1} \frac{r^2sin\theta}{r^2-2rcos\theta+4}drd\theta=2\pi \int_{-1}^{1}\int_{0}^{1}\frac{r^2sin\theta}{r^2+2r\alpha+4}dr\frac{d\alpha}{sin\theta}$$ cancel the sine to get: $$2\pi \int_{-1}^{1}\int_{0}^{1}\frac{r^2}{r^2+2r\alpha+4}drd\alpha$$ this integral is very difficult (at least wasn't apparent to me) if we integrate by $r$. luckily, Fubini's theorem states that we can integrate by $\alpha$ first and the result won't change: $$2\pi \int_{-1}^{1}\int_{0}^{1}\frac{r^2}{r^2+2r\alpha+4}drd\alpha=2\pi\int_{0}^{1}\int_{-1}^{1}\frac{r^2}{r^2+2r\alpha+4}d\alpha dr $$ The antiderivative of $$\frac{1}{r^2+2r\alpha+4}$$ with respect to alpha is $$\frac{\ln(r^2+2r\alpha+4)}{2r}$$ since $\alpha$ goes from $-1$ to $1$: $$\frac{\ln(r^2+2r+4)}{2r}-\frac{\ln(r^2-2r+4)}{2r} = \frac{\ln(r+2)^2-\ln(r-2)^2}{2r}=\frac{\ln(\frac{r+2}{r-2})}{r}$$
so: $$2\pi\int_{0}^{1}\int_{-1}^{1}\frac{r^2}{r^2+2r\alpha+4}d\alpha dr=2\pi \int_{0}^{1}r\ln(\frac{r+2}{r-2})dr$$ Now I integrated by parts $\int uv'=uv-\int u'v$ where $u=\ln(\frac{r+2}{r-2})$, $u'=\frac{-4}{r^2-4}$, $v'=r$, $v=\frac{r^2}{2}$: $$\int r\ln(\frac{r+2}{r-2})dr=\frac{r^2ln(\frac{r+2}{r-2})}{2}-\int\frac{-2r^2}{r^2-4}dr =\frac{r^2ln(\frac{r+2}{r-2})}{2}+2(r+\ln(\frac{r-2}{r+2})+2)$$ when $r=1$: $$\frac{1^2ln(-3)}{2}+2(1+\ln(\frac{-1}{3})+2)=\frac{1}{2}\ln(-3)-2\ln(-3)+6=-\frac{3}{2}\ln(3)-\frac{3\pi i}{2}+6$$ when $r=0$: $$0+2(0+\ln(-1)+2)=2\ln(-1)+4=2\ln(1)+2\pi i+4=4+2\pi i$$ Subtract the 2 results to get: $$-\frac{3}{2}\ln(3)-\frac{3\pi i}{2}+6-4-2\pi i=2-\frac{3}{2}\ln(3)-\frac{7\pi i}{2}$$ Multiply this result by $2\pi$ to reach the final answer which is $$4\pi-3\pi \ln(3)-7\pi^2i$$ Is this indeed the correct answer? Is there a better way of solving this? this seems like a very difficult way to do the exercise.","['multivariable-calculus', 'logarithms', 'calculus', 'integration']"
805937,Algebra: What allows us to do the same thing to both sides of an equation?,"I understand that the expressions on both sides of an equal sign are the same entity, and I know that when you modify one side, the other must be changed because it is referring to the same thing. What I do not understand is why making a new equation (adding or taking away from an expression) allows one to know what an unknown represents. What about equations lets us do this?",['algebra-precalculus']
805954,What does the dot product of two vectors represent?,"I know how to calculate the dot product of two vectors alright. However, it is not clear to me what, exactly, does the dot product represent . The product of two numbers, $2$ and $3$, we say that it is $2$ added to itself $3$ times or something like that. But when it comes to vectors $\vec{a} \cdot \vec{b}$, I'm not sure what to say. ""It is $\vec{a}$ added to itself $\vec{b}$ times"" which doesn't make much sense to me.","['geometry', 'vectors']"
805975,equivalence classes of ∼ are left cosets of H in G - my attempt,"Let $H$ be a subgroup of G, and define a relation $∼$ on G by the
  rules that $x∼y$ mean $x^{-1}y\in H $. Show that $∼$ is an equivalence
  relation and its equivalence classes are the left cosets of $H$. My attempt We know that a relation $R$ on a set $X$ is a set of ordered pairs of members of $X$ which satisfies the condition of the given relation. To prove that the relation is an equivalence relation, we need to check if the relation $∼$ have all the properties $∼$ is reflexive if $x∼x$ for all $x\in G$ $∼$ is symmetric if $x∼y \Rightarrow y∼x$ for all $x,y\in G$ $∼$ is transitive if $x∼y$ & $y∼z$ then $x∼z$ for all $x,y,z\in G$ So, we can see that the relation is reflexive since
$$x^{-1}x=1 \forall x\in H$$
It's also symmetric
$$x^{-1}y {,} \forall x,y\in H$$
and since the identity element exist we know that an element $j$ exist such that
$$x^{-1}yj=1 <=> j=y^{-1}x \in H$$
Therefore its symmetric. The relation is also transitive:
$$x∼y .AND. y∼z. THEN.x∼z \forall x,y,z \in H$$
$$(x^{-1}y)(y^{-1}z)=x^{-1}z \in H$$
Since the relation have all the properties listed above, the relation is an equialance relation. Now we are going to show that the equivalence classes of this relation is the left cosets. Since the distinct left cosests form a partition of $G$, its equal to the equivalence classes because the equivalence classes are the parts of the partition of $G$, which means the equivalence classes are also forming the partition. The equivalence classes are the set $$[x]=\{y \in G | y∼x\}$$
and by the reflexivitive we get
$$[x]=\{y \in G | x∼y\}=\{y\in G|x^{-1}y\in H\}$$
$x^{-1}y\in H$ gives us that 
$$y=x(x^{-1}y)=y\in xH$$
This means that 
$$y=xh$$
for some $h \in H$ and this gives us
$$h=x^{-1}y$$
which is the relation $x∼y$. Therefore
$$[x]=xH$$","['discrete-mathematics', 'equivalence-relations', 'normal-subgroups', 'group-theory', 'proof-writing']"
805976,Show that $2^n(\cos^n(\frac{2\pi}{9})+\cos^n(\frac{4\pi}{9})+\cos^n(\frac{8\pi}{9}))\in\mathbb{Z}$,"Let $$a_n=2^n\left[\cos^n\left(\dfrac{2\pi}{9}\right)+\cos^n\left(\dfrac{4\pi}{9}\right)+\cos^n\left(\dfrac{8\pi}{9}\right)\right].$$ Show that $a_n\in\mathbb{Z}$ for all $n\in\mathbb{Z}$ . Find the last digit of $a_{10^6}$ . My progress: I believe it can be solved by expressing $a_n$ as a linear recurrence by using the cubic equation $x^3-3x+1=0$ which has the roots $x_1=2\cos\left(\dfrac{2\pi}{9}\right)$ , $x_2=2\cos\left(\dfrac{4\pi}{9}\right)$ , $x_3=2\cos\left(\dfrac{8\pi}{9}\right)$ . I'm just not really sure how to connect $a_n$ to this cubic equation. I guess that if you could find a linear recurrence to $a_n$ , the last digit would be cyclic and could be found that way. I was hoping to solve it without using computer work, but maybe that's tough.","['recurrence-relations', 'discrete-mathematics']"
805982,Does scaling lead to weak convergence to the null function?,"Let $f\in L^p(\mathbb{R}^d)$, with $1<p<\infty$. Is it true that 
  $$\lambda^{\frac{d}{p}}f(\lambda x ) \rightharpoonup 0\quad \text{ weakly in }L^p\text{ as }\lambda\to+\infty?$$ One has the easy case for $f\in L^{p-\epsilon}\cap L^p$. This condition allows the use of Hölder's inequality as follows (here $\frac{1}{p}+\frac{1}{p'}=1$ and $\phi$ is a continuous function with compact support): 
$$\begin{split}\left\lvert \int_{\mathbb{R}^d} \lambda^{\frac{d}{p}} f(\lambda x)\phi(x)\, dx\right\rvert& \le \lambda^{\frac{d}{p}}\lVert f(\lambda x)\rVert_{L^{p-\epsilon}}\lVert \phi\rVert_{L^{(p-\epsilon)'}} \\ 
&= \lambda ^{\frac{d}{p}- \frac{d}{p-\epsilon} } \lVert f\rVert_{L^{p-\epsilon}}\lVert\phi\rVert_{L^{(p-\epsilon)'}}\to 0.
\end{split} $$
But what happens if that condition is removed? I carried out an explicit check on the standard example of a function $f$ that belongs to $L^2(\mathbb{R})$ and does not belong to $L^{2-\epsilon}(\mathbb{R})$ for any $\epsilon > 0$, namely 
$$f(x)=\begin{cases} 0 , & x<2 \\ \frac{1}{\sqrt{x}\log x}, & x \ge 2\end{cases}.$$
Taking $\phi=\chi_{[a, b]}$ with $2<a<b$ one has 
$$\left \lvert \int_{\mathbb{R}} \lambda^{\frac{1}{2}}f(\lambda x)\phi(x)\, dx \right\rvert 
= \dfrac{ 
\int_{\lambda a }^{\lambda b} \frac{dy}{\sqrt{y}\log(y)}
}
{\lambda^{\frac{1}{2}}}, $$
and an application of l'Hôpital's rule shows that the right hand side tends to $0$ as $\lambda \to \infty$. This implies weak convergence to $0$ by a standard density argument. This seems to point towards an affirmative answer to the question in the gray box.","['functional-analysis', 'real-analysis']"
806012,Computing the volume element of an oriented Riemannian manifold,"I'm reading Gallot-Hulin-Lafontaine, and in section 2.7 they say they following: I wanted to check that the second $v_g,$ given in a local oriented chart, satisfied the first property. So I took an oriented basis $(e_1,\ldots,e_n)$ satisfying $g(e_i,e_j) = \delta^i_j,$ compared it to the frame $(\partial_1,\ldots,\partial_n)$ (the coordinate vector fields in the $x^i$ coordinates) by writing $e_j = a^i_j \partial_i$ (using summation notation) for some invertible matrix $(a^i_j)$, and computed $$ v_g(e_1,\ldots,e_n) = v_g(a^i_1 \partial_i, \ldots, a^i_n \partial_i) = \sqrt{\det(g_{i,j})} a^1_1 \cdots a^n_n. $$ This is supposed to equal 1, but I don't see how it follows from the relations $$\delta^i_j = g(e_i,e_j) = a^k_i a^l_j g_{k,l}.$$ I think I made an error somewhere, but I don't know where. Thanks!","['riemannian-geometry', 'differential-geometry']"
806014,Infinite sum of Bessel Functions,"I came across the following sum in my work involving the infinite sum of a product of Bessel functions. Does anyone have any idea of how to express this in a simpler form? 'a' and 'b' are positive numbers, and I am also interested in the case where a=b. Thanks! $$\sum_{n=1}^{\infty}(-1)^{n}J_{2n}(a)J_{2n}(b)$$","['special-functions', 'sequences-and-series']"
806016,Is injective function $f:A \to A$ always surjective?,"Ok so while browsing a book(namely Herbert Endertons book ""Elements of set theory"") I have stumbled upon a curiosity which provoked me to try to prove this.Here is how I went about it,but I do not think my solution is correct. All answers as well as corrections are more then welcome. Proof: Since $f: A\to A$ and f is injective we have $$(x,y)\in f \implies x \in A  \;\;\land \;\; y\in A \implies (y,z)\in f \;\; \land \;\; z\neq x $$ by using this step repeatedly,we will eventually exhaust set A of members,and thus range is equal to domain. However I am not sure that I have covered a case where there is element which is in relation with x.Also I am not sure what would happen if the domain and range are set of real numbers(as I have only managed to study up to natural numbers so far). All input is highly appreciated","['elementary-set-theory', 'functions']"
806018,Line Integrals and Surface Integrals,"Can someone please explain what surface integrals and line integrals are measuring? Is a line integral the arc length along a surface, and a surface integral is the surface area? Also, why is a line integral equal to $0$ on a conservative closed path? Thank you!","['multivariable-calculus', 'intuition']"
806024,"Weak topology on $L^p,~p> 1$","How looks like the weak topology in the particular case  $X=L^p$, I mean, is possible to detail this topology beyond standar form: Arbitrary union of finite intersections  open pre-images of opens in the real line?","['reference-request', 'functional-analysis', 'real-analysis', 'analysis']"
806064,Is there a highest order of infinity?,"Does there exist an infinite set of cardinality such that it can never be reached by taking power sets of a set with cardinality aleph-null. Please prove your answer, or include a link to a proof. I apologize for any excessively loose terminology, I am new to this subject of different infinities.","['infinity', 'elementary-set-theory']"
806095,Double harmonic summation,"Let us consider a lattice formed by all points with integer and positive coordinates on a Cartesian plane, and where $K$ is the maximal value for the $x$-axis. Let us assign to each lattice point the value $1/(xy)$, where $x$ and $y$ are its coordinates. Drawing the two lines $y = x$ and $y = Jx$ (with $J$ real number $>1$), a triangular region between the two lines is identified. I would like to determine an asymptotic expansion for the summation of the values of all points included in this triangular region when $K$ tends to infinity. I calculated that this asymptotic expansion is given by $\log(K) \log(J) + O(1)$.  However, I am particularly interested in the limit of this constant term when $K$ tends to infinity, since it shows an irregular behaviour with several discontinuities when plotted against $J$ (see the Figure below, showing the value of this constant term on the $y$-axis vs $J$ on the $x$-axis). As shown in the Figure, for $J = 1$ (where the two lines coincide and the triangle reduces to a line crossing all points with $x = y$), the limit of the constant term, and in this case of the whole summmation, corresponds to the infinite sum of inverse squares, yielding $\pi^{2}/6 \approx 1.64$. Starting from this value, the function then shows discontinuities over its whole range. Just to describe two of them that are evident in magnitude and that have been highlighted in the Figure: for $J = 1.49999$ the limit of the constant term is about $1.025$, but for $J = 1.5$ it abruptly increases to about $1.30$. Similarly, for $J = 1.99999$ the limit of the constant term decreases to about $0.88$, whereas for $J = 2$ it abruptly increases to about $1.70$. The reason for all these discontinuities is that, as the $y = Jx$ line rotates counterclockwise (i.e., as $J$ increases), new sets of aligned points are progressively and discontinuously included in the triangular region. Accordingly, the largest discontinuities occur for integer values of $J$, as for these values new and relatively large sets of points are included in the region. Generalizing, the magnitude of each jump is equal to the sum of all points corresponding to the slope $J=\frac{y}{x}$ (where $\frac{y}{x}$ is an irreducible fraction), which in turn is given by the sum of inverse squares multiplied by $\displaystyle \frac{1}{xy}$. In this view, this question is equivalent to that of determining an asymptotic expansion for the double harmonic sum $\displaystyle \frac{1}{xy}$, calculated over all possibile coprime values of $x$ and $y$  such that $\frac{y}{x}$ is a rational number included in the interval between $1$ and $J$. I would like to determine a general expression for the constant term of this summation. I tried a number of approaches, including application of Euler-MacLaurin formula or Fourier transformations, but each attempt failed. I am not necessarily searching a closed form in the strict sense, which probably could not exist. Rather, I would be very interested in finding a more compact or elegant general expression for this term, in comparison with the trivial way of reporting it as the difference between the double harmonic summation and the logarithmic term $\log(K) \log(J)$.","['sequences-and-series', 'number-theory', 'asymptotics', 'summation', 'limits']"
806099,Analysis on using Unconventional underlying fields,"I'm curious if people study analysis while using fields that are not $\mathbb{R}$. I remember seeing a post about doing analysis on $\mathbb{Q}$, but $\mathbb{Q}$ is not complete! Mostly I'm interested in applying functional analysis with differing underlying fields. The fields I have in mind are like field extensions of a given polynomial, or a given set of polynomials. I'm unsure if one can construct a complete field in this way (without constructing the reals). This seems to dip into algebra, analysis and topology so for me, it's probably a bit to advanced to actually make any progress with alone. Has anyone done analysis in this sort of way? Are there any applications whatsoever (am I being incredibly silly considering this)?","['reference-request', 'functional-analysis', 'soft-question', 'analysis']"
806140,Find roots of a function,"$f$ is a function defined on the whole real line which has the property that $f(1+x)=f(2-x)$ for all $x$. Assume that the equation $f(x)=0$ has $8$ distinct real roots. Find the sum of these roots. I don't get this problem at all, just that if $x=\frac{1}{2}$, the property works. Can someone explain this to me?","['contest-math', 'roots', 'functions']"
806195,"Integral $\int_0^{\pi/4}\frac{dx}{{\sin 2x}\,(\tan^ax+\cot^ax)}=\frac{\pi}{8a}$","I am trying to prove this interesting integral$$
\mathcal{I}:=\int_0^{\pi/4}\frac{dx}{{\sin 2x}\,(\tan^ax+\cot^ax)}=\frac{\pi}{8a},\qquad \mathcal{Re}(a)\neq 0.
$$
This result is breath taking but I am more stumped than usual.  It truly is magnificent.  I am not sure how to approach this,
note $\sin 2x=2\sin x \cos x$.  I am not sure how to approach this because of the term
$$
(\tan^ax+\cot^ax)
$$
in the denominator.  I was trying to use the identity 
$$
\tan \left(\frac{\pi}{2}-x\right)=\cot x
$$
since this method solves a similar kind of integral but didn't get anywhere.    A bad idea I tried was to try and differentiate with respect to a
$$
\frac{dI(a)}{da}=\int_0^{\pi/4}\partial_a \left(\frac{dx}{{\sin 2x}\,(\tan^ax+\cot^ax)}\right)=\int_0^{\pi/4}  \frac{(\cot^a x \log(\cot x )+\log(\tan x ) \tan^a x)}{\sin 2x \, (\cot^a x+\tan^a x)^2}dx
$$
which seems more complicated when I break it up into two integrals.  How can we solve the integral?  Thanks.","['calculus', 'integration', 'definite-integrals', 'real-analysis', 'complex-analysis']"
806216,Finding All Integers Satisfying the Condition,"Find all the solutions of the inequality- $$\sqrt{x(\ln x +\ln \ln x)}-1 > y > \sqrt{x(\ln x+ \ln \ln x-1)}$$ Where $x,y$ $\in$ $\mathbb N$. Determine the set of integral values of $(x,y)$. I think for all $y$ greater than some $n$ there will always be some $x \in \mathbb R^+$ so that the inequality holds but even the proof of that seems elusive to me. I have not made any progress regarding this problem. Any hint will be appreciated.","['inequality', 'number-theory']"
806224,Prove that $\frac{1}{a}+\frac{1}{b}+\frac{1}{c}\le\frac{3}{\sqrt{7}}$,"Let $a,b,c>0$ such that $$\dfrac{1}{a^2+2}+\dfrac{1}{b^2+2}+\dfrac{1}{c^2+2}=\dfrac{1}{3}.$$ Show that $$\dfrac{1}{a}+\dfrac{1}{b}+\dfrac{1}{c}\le\dfrac{3}{\sqrt{7}}.$$ My try: since $$\dfrac{1}{2+a^2}=\dfrac{1}{2}\left(1-\dfrac{a^2}{a^2+2}\right)$$ so $$\dfrac{a^2}{a^2+2}+\dfrac{b^2}{b^2+2}+\dfrac{c^2}{c^2+2}=\dfrac{7}{3}$$ we only prove $\dfrac{1}{a}+\dfrac{1}{b}+\dfrac{1}{c}\le\dfrac{3}{\sqrt{7}}$ and I want use Cauchy-Schwarz inequality to prove it,But I can't works,such $$\left(\dfrac{a^2}{a^2+2}+\dfrac{b^2}{b^2+2}+\dfrac{c^2}{c^2+2}\right)(a^2+2+b^2+2+c^2+2)\ge (a+b+c)^2$$ $$(a^2+b^2+c^2+6)\ge \dfrac{3}{7}(a^2+b^2+c^2+2ab+2bc+2ac)$$ $$\Longrightarrow 4(a^2+b^2+c^2)+42\ge 6(ab+bc+ac)$$ and let $$p=a+b+c,q=ab+bc+ac,r=abc$$ so $$2p^2+21\ge 7q$$ and we only prove $$\dfrac{1}{a}+\dfrac{1}{b}+\dfrac{1}{c}=\dfrac{ab+bc+ac}{abc}=\dfrac{q}{r}\le\dfrac{3}{\sqrt{7}}$$ maybe this is not true. But this not usefull to solve this problem . Thank you","['multivariable-calculus', 'inequality', 'contest-math', 'real-analysis', 'uvw']"
806232,Summing a series,"This problem was inspired by a typo on a homework assignment for Calculus 2, which covers integration and series. Find the sum of $$\sum_{n=0}^{\infty} \frac{1}{2^{n^2}}$$ Does anyone have any idea regarding where they'd begin with this problem? Maybe some fancy residue calculus trick?","['summation', 'sequences-and-series']"
806242,A group with certain three distinct cyclic subgroups,"Is there some group with elements $a,b$ such that $\langle ab\rangle=\langle ba\rangle$, yet the cyclic subgroups generated by $a,b$ and $ab$ are distinct? If $\langle ab\rangle=\langle ba\rangle$ then $ab$ and $ba$ do commute, that is $ab^2a=ba^2b$, but I cannot find a useful consequence of this equality.",['group-theory']
806254,Using Integration By Parts results in 0 = 1,"I've run into a strange situation while trying to apply Integration By Parts, and I can't seem to come up with an explanation.  I start with the following equation: $$\int \frac{1}{f} \frac{df}{dx} dx$$ I let: $$u = \frac{1}{f} \text{ and } dv = \frac{df}{dx} dx$$ Then I find: $$du = -\frac{1}{f^2} \frac{df}{dx} dx \text{ and } v = f$$ I can then substitute into the usual IBP formula: $$\int udv = uv - \int v du$$ $$\int \frac{1}{f} \frac{df}{dx} dx = \frac{1}{f} f - \int f \left(-\frac{1}{f^2} \frac{df}{dx}\right) dx$$ $$\int \frac{1}{f} \frac{df}{dx} dx = 1 + \int \frac{1}{f} \frac{df}{dx} dx$$ Then subtracting the integral from both sides, I've now shown that: $$0 = 1$$ Obviously there must be a problem in my derivation here...  What wrong assumption have I made, or what error have I made?  I'm baffled.","['calculus', 'integration', 'fake-proofs']"
806284,Prove equality of two vectors if they have equal divergence and equal curls,"I have following question: Fields with equal divergence and equal curls $F_1$ and $F_2$ are two vectors fields, you may write them as $F_1 = M_1i+N_1j+P_1k$, $F_2 = M_2i+N_2j+P_2k$. Suppose that $\nabla \cdot F_1 = \nabla \cdot F_2$ and $\nabla \times F_1 = \nabla \times F_2$ over a region D enclosed by the oriented surface S with outward unit normal n and that $F_1 \cdot n = F_2 \cdot n$ on S. Prove that $F_1=F_2$ throughout D. I came across this question when studying ""Stokes's Theorem and Divergence Theorem"" in Thomas Calculus, so I suppose we should use either of them to solve this, except I don't know how. All I could figure out is 
$$F_1 \cdot n = F_2 \cdot n\Rightarrow\iint\limits_s F_1 \cdot n \, d\sigma = \iint\limits_s F_2 \cdot n \, d\sigma\Rightarrow\iiint\limits_D \nabla \times F_1\, dv = \iiint\limits_D \nabla \times F_2 \, dv,$$ the last step using divergence theorem. Or
$$\nabla \times F_1 = \nabla \times F_2 \Rightarrow\iint\limits_s \nabla \times F_1\cdot n \, d\sigma= \iint\limits_s \nabla \times F_2 \cdot n \, d\sigma \Rightarrow \oint\limits_c F_1 \cdot dr =\oint\limits_c F_2 \cdot dr,$$ the last step using Stokes's theorem.
This is all I get, then what? Am I on a wrong path? Can anyone solve this problem? Thanks.","['multivariable-calculus', 'vector-analysis']"
806315,Improper integral of exponential function times the integer part of $x$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question I would like to solve $\int_{0}^{\infty} \lfloor x\rfloor e^{-x} dx$ for its exact solution. This was on a previous GRE Mathematics exam.","['improper-integrals', 'calculus', 'integration', 'gre-exam']"
806330,Differentiable Path of Operators and their Inverses,"Let $\mathcal{H}$ be a separable Hilbert space. Consider a differentiable map $\mathbb{R} \rightarrow \mathcal{B}(\mathcal{H}), t \mapsto A(t)$, where $\mathcal{B}(\mathcal{H})$ is the space of bounded linear operators from $\mathcal{H}$ into itself with respect to the operator norm (by differentiable I mean differentiable in the Frechet-sense). Furthermore, assume, for each $t$, that $A(t)$ has the following properties: (1) for each $t$ there is a orthogonal decomposition of $\mathcal{H} = \mathcal{H}_{t}^{1} \oplus \mathcal{H}_{t}^{2}$, where $\mathcal{H}_{t}^{1}$ is a finite dimensional subspace of $\mathcal{H}$; (2) $A(t)|_{\mathcal{H}_{t}^{1}} \equiv 0$, $A(t)$ are selfadjoint and $\dim{(\mathcal{H}_{t}^{1})} = n > 1$ (here $n$ is independent of $t$, hence for all $t$, $\mathcal{H}_{t}^{1}$ have the same dimension greater than $1$); (3) $A(t)|_{\mathcal{H}_{t}^{2}}:\mathcal{H}_{t}^{2} \rightarrow \mathcal{H}_{t}^{2}$ is an isomorphism; (4) The $(A(t)|_{\mathcal{H}_{t}^{2}})^{-1} : \mathcal{H}_{t}^{2} \rightarrow \mathcal{H}_{t}^{2}$ are bounded operators; (5) $(A(t)|_{\mathcal{H}_{t}^{2}})^{-1}A(t) : \mathcal{H} \rightarrow \mathcal{H}_{t}^{2}$ is an orthogonal projection. Extend now the oprators $(A(t)|_{\mathcal{H}_{t}^{2}})^{-1}$ to the whole $\mathcal{H}$ by: $A(t)^{-1}x = 0$ if $x \in \mathcal{H}_{t}^{1}$ and $A(t)^{-1}|_{\mathcal{H}_{t}^{2}} = (A(t)|_{\mathcal{H}_{t}^{2}})^{-1}$. Is it true that then the map $\mathbb{R} \rightarrow \mathcal{B}(\mathcal{H}), t \mapsto A(t)^{-1}$ is Frechet-differentiable? I'm sure I've mentioned too many assumptions. I know that if the operators $A(t)$ are invertible (on the whole space) then the map $t \mapsto A(t)^{-1}$ is Frechet-differentiable. But what about in this case? Clark","['operator-theory', 'functional-analysis', 'derivatives', 'analysis']"
806332,When inverse functions are helpful?,I pass some colloquiums to find inverse functions. But still can't understand the real help of them. Only one real world example come to my mind: converting units of measurement (but those convertions should be injective). Are there any other staff behind it when inverse functions helps a lot?,"['inverse', 'functions']"
806394,Prove that $A^k = 0 $ iff $A^2 = 0$,Let $A$ be a $  2 \times  2 $ matrix and  a positive integer $k \geq 2$. Prove that $A^k = 0 $ iff $A^2 = 0$. I can make it to do this exercise if I have $ \det (A^k) = (\det A)^k $. But this question comes before this. Thank you very much for your help!,"['matrices', 'linear-algebra']"
806439,Find a chance that intersection of power set entries is an empty set,"We are given set $A = \{1,2, ...n\}$. $k$ entries picked from the power set of $A$. Task is to find probability that  $A_1 \cap A_2 \space \cap \space... \cap \space A_k = \emptyset$. I came up with solution, but result looks overcomplicated and probably with better knowledge of combinatorics one could do better and find actual answer. Solution We are given: $card(A)=n$ and $X_i \in 2^A$. We will denote $card(X_i) = m_i$ Also, I derived following formulas: Chance of appearing of specific element $a$ in the subset $X_i$: $\frac{C_{n-1}^{m_i-1}}{C_{n}^{m_i}} = \frac {m_i} n$. Analogously, chance of appearing two specific elements in the subset $X_i$: $\frac{C_{n-2}^{m_i-2}}{C_{n}^{m_i}} = \frac {(m_i-1)m_i} {(n-1)n}$. Final idea is: probability of intersection $X_1,X_2...X_k$ being an empty set is: 1 - P(intesection has card 1) - P(intesection has card 2) ... - P(intesection has card n). I was able to write it as: $$1 - \sum_{i=1}^n\prod_{j=1}^k\prod_{l=1}^i \frac{m_j - l +1}{n - l +1}$$ Could it be considered as valid solution? Also I would appreciate hints about mistakes in it. Thank you.","['solution-verification', 'probability', 'proof-verification', 'combinatorics']"
806472,Analytical solutions of Thomas Fermi equation,"The Thomas Fermi model of atoms and nuclei is used in many applications of atomic and nuclear physics. The ODE related to this model is:
$$\frac{d^2}{dx^2}\phi(x)=x^{-\frac{1}{2}}\phi(x)^{3/2}$$
with boundary conditions:
$$\phi(0)=1$$
and:
$$\phi(\infty)=0$$
The best attempt to solve it is given by Majorana: http://arxiv.org/pdf/physics/0111167v1.pdf but unfortunatly also Majorana wasn't able to solve it analytically. Is there today some advanced method to find an analytical solution of this equation or the only possible way to solve it is a numerical method? Thanks.","['boundary-value-problem', 'ordinary-differential-equations']"
806498,The diffential of commutator map in a Lie group,"Leb $G$ be a Lie group and $f:G\times G\rightarrow G$ be the commutator map $:(x,y)\mapsto xyx^{-1}y^{-1}$. How to obtain the Lie bracket in the associated Lie algebra of $G$ from the derivatives of $f$? (We know that the Lie bracket is defined via the adjoint representation.) (I saw $df_{(e,e)}(X,Y)=[X,Y]$ somewhere. Thanks to @John for remarking this is false. But I think there is indeed a relation between the Lie bracket and derivatives of $f$.  )","['lie-groups', 'lie-algebras', 'derivatives', 'differential-geometry']"
806532,Why must an interior point of $E$ be an element of $E$?,"This question takes place in a general metric space $X$. Let $x$ be an interior* point of $E \subset X$ iff there exists a deleted neighborhood of $x$ that is contained in $E$. This is like the normal definition of ""interior point"", except it uses ""deleted neighborhood"" instead of ""neighborhood"", thus allowing a point not in $E$ to be an interior* point of $E$. My question is: why is this not the standard definition of ""interior point""?  I see a couple reasons that it would make a more elegant system. ""Limit point"" and ""interior* point"" are both defined in terms of deleted neighborhoods ($x$ is a limit point of $E$ iff all deleted neighborhoods of $x$ include some point of $E$).  This is more symmetrical. (Note: I do not yet have a general/categorical notion of duality) ""Limit point"" and ""interior* point"" are more adequately dual, for $x$ is a limit point of $E$ iff $x$ is not an interior* point of the complement of $E$, whereas this does not hold for ""limit point"" and ""interior point"". The dual notions of closure and interior are more symmetrically defined using ""interior* point"".  The closure is defined as the union of $E$ and the set of limit points of $E$, and the interior is defined as the intersection of $E$ and the set of interior* points of $E$.  The duality between closure and interior is harder to see with the standard definition of interior as the set of interior points of $E$.  Also the proof that the complement of the closure of $E$ is the interior of the complement of $E$ reduces to a few applications of DeMorgan's law. So why do people use ""interior point"" and not ""interior* point""?","['general-topology', 'metric-spaces', 'real-analysis', 'definition']"
806573,Integral formula for polar coordinates,"The polar coordinates of point $x \in \mathbb{R} \setminus \{0\}$ are pairs $(r,\gamma)$, where $0 < r < \infty$ and $\gamma \in S^{d-1} = \{x \in \mathbb{R}^{d}\mid |x| = 1\}$. These are determined by
$$r = |x|, \quad\gamma = x/|x|,$$ and reciprocally by $x = r\gamma$. Then we have:
$$\int_{\mathbb{R}^{d}}f(x)dx = \int_{S^{d-1}} \left( \int_{0}^{\infty}f(r\gamma)r^{d-1}dr \right) d\sigma(\gamma).$$ The proof of this formula using the Fubini's theorem. However, I can't understand that the relationship between those measure spaces. And I was so confused by this equation:
$$\mu_{1}(E) = \int_{E}r^{d-1}dr.$$ Besides, I also want to know about the integral formula for the general case. Is there a universal steps to construct the integral formula with respect to the Jacobi in the Reimann integral.","['polar-coordinates', 'real-analysis']"
806620,When can I say that $f(x) \gt g(x) \implies f'(x) \gt g'(x)$?,"Are there cases when this relation holds?
$$f(x) \gt g(x) \implies f'(x) \gt g'(x)$$ I.e. what are the conditions on $f(x)$ and $g(x)$ for that to be true? Is it even possible to determine them? In case it is always valid, how can it be proved?",['derivatives']
806624,The open sets in Banach space,"Let $X$ and $Y$ be two Banach spaces. And we set $X\times Y=\{(x, y): x\in X$ and $ y\in Y\}$. If we take a open set $U$ in $X\times Y$, then does $U$ has the form $U_{X}\times U_{Y}$? Here $U_{X}$ and $U_{Y}$ are the open sets in $X$ and $Y$ respectively.","['general-topology', 'functional-analysis']"
806636,Question on primitive roots of unity,"Let $p$ be an odd prime and $\omega$ be a primitive $p$ th root of unity. The question is to prove that: $$(1-\omega)(1-\omega^2) \cdots (1-\omega^{p-1})=p$$ What I have done so far is: I can see that this is true for $p=3$ $$(1-\omega)(1-\omega^2)=1-(\omega+\omega^2)+w^3=1-(-1)+1=3=p$$ I am not able to prove this in general.... $$(1-\omega)(1-\omega^2) \cdots (1-\omega^{p-1})=1-(\omega+\omega^2+\cdots+\omega^{p-1})+????+\omega^{\frac{p(p-1)}{2}}$$ I do not have any idea what that $????$ could be but all I can say is: $(\omega+\omega^2+\cdots +\omega^{p-1})=-1$ $\omega^{\frac{p(p-1)}{2}}=1$ So, $(1-\omega)(1-\omega^2)\cdots (1-\omega^{p-1})=3+????$ I am not able to do more than this. There could be some (hard) way of doing it by hand multiplying all those things but I am looking for a more theoretical idea. Please help me to clear this up.","['roots-of-unity', 'abstract-algebra']"
806645,Explain the minus sign in the following formula.,"I just read that: If $z=f(x,y)=c$, be the equation of a curve, then the slope of the tangent to the curve at any point (x,y), is given by
$$m=\frac {dy}{dx}=-\frac{\frac{\partial z}{\partial x}}{\frac {\partial z}{\partial y}}$$ I don't see how the minus sign creeps in here.(Of course I don't have a proof, but the - sign is against intuition). A proof(or a link to a simple proof) would be nice, and an intuitive explanation would be nicer. Thanks for help.","['multivariable-calculus', 'implicit-differentiation', 'implicit-function-theorem', 'derivatives']"
806692,Lebesgue integral with repect to counting measure,"Let $\Omega$ be a set, $\mathcal{A} = \mathcal{P}(\Omega)$ the power set, $\mu$ counting measure, $f$ a nonnegative function on $\Omega$, I want to show that $$ \int_\Omega f d\mu = \sum_{x \in \Omega} f(x) $$ where $\sum_{x \in \Omega} f(x) = \sup \{\sum_{x \in F} f(x): F \mbox{ finite },\, F \subset \Omega \}$. $\forall F \subset \Omega$, we have $$ \int_{\Omega} f d\mu \ge \int_F f d\mu = \sum_{x \in F} \int_{\{x\}} f d\mu = \sum_{x \in F} f(x) \mu(\{x\}) = \sum_{x \in F} f(x)$$ so $ \int_{\Omega} f d\mu \ge \sup_{F \subset \Omega} \{ \sum_{x \in F} f(x) \}$. How do I show the reverse inequality ?",['measure-theory']
806711,Sum of these quotient can not be integer,"Suppose $a$ and $b$ are positive integers such that are relatively prime (i.e., $\gcd(a,b)=1$). Prove  that, for all $n\in \mathbb{N}$, the sum $$                    
\frac{1}{a}+\frac{1}{a+b}+\frac{1}{a+2b}+\cdots+\frac{1}{a+nb}
$$ is not an integer. I think I have tried many ways I could, but none led me to the complete answer. Do you have any idea?","['elementary-number-theory', 'number-theory']"
806725,derivative after changing variable,"I have just studied a lesson about derivative of a function but I still confuse in the following case. Suppose that I have a function:
$$ f(x) = 2x^2 + 3x + 1$$ 
and I want to calculate $\frac{d}{dx}f(x)$ and it is
$$ \frac{d}{dx}f(x) = 4x + 3$$ I try to change the variable $x$ such that $x=e^u$, and then
$$f(e^u) = 2e^{2u} + 3e^u + 1\quad\quad\quad (1)$$ and I have 
$$\frac{d}{du}f(e^u) = 4e^{2u}+3e^u = e^u(4e^u + 3)=\frac{dx}{du}\frac{df}{dx}\quad\quad\quad (2)$$ But I just want to take the derivative by $x$, not by $u$, that means
$$\frac{d}{dx}f(e^u) = 4e^u + 3 \quad\quad\quad (3)$$ So, I confuse between $(2)$ and $(3)$. Which is correct? Because the transformation is needed for a calculation in next step (using variable $u$) of my exercise. Maybe my question is stupid but I appreciate if anyone can explain clearly the difference in two ways of taking derivative by $x$ and $u$.","['ordinary-differential-equations', 'calculus', 'derivatives']"
806759,"How to prove: $f(x)$ is differentiable on $(0,+\infty)$","The function $f(x)$ is defined on    $(0,+\infty)$. We know $f'(1)$ exists and we have that $$\forall x,y \in(0,+\infty), \quad  f(xy)=yf(x)+xf(y)$$ How to prove:$f(x)$ is differentiable on $(0,+\infty)$ and$$f'(x)=\frac{f(x)}{x}+f'(1)?$$ I've got $f(1)=0$, but have no idea to prove other things.","['ordinary-differential-equations', 'calculus', 'functions']"
806779,Linear Algebra determinant reduction,"Prove, without expanding, that
\begin{vmatrix}
1 &a  &a^2-bc \\ 
1 &b  &b^2-ca \\ 
1 &c  &c^2-ab 
\end{vmatrix} vanishes. Any hints ?",['linear-algebra']
806831,Proving ${n \choose p} \equiv \Bigl[\frac{n}{p}\Bigr] \ (\text{mod} \ p)$,"This is an exercise from Apostol, which i have been struggling for a while. Given a prime $p$, how does one show that $${n \choose p} \equiv \biggl[\frac{n}{p}\biggr] \ (\text{mod} \ p)$$ Note that $\Bigl[\frac{n}{p}\Bigr]$ denotes the integral part of $\frac{n}{p}$. I would also like to know as to how does one try to solve this problem. Well, what we need is to show is whenever one divides ${n \choose p}$ by a prime $p$ the remainder is the integral part of $\frac{n}{p}$. Now, $${ n \choose p} = \frac{n!}{p! \cdot (n-p)!}$$ Now $n!$ can be written as $$n!= n \cdot (n-1) \cdot (n-2) \cdots (n-p) \cdots 2 \cdot 1$$ But i am really struggling in getting the integral part.",['number-theory']
806889,On the numbers of maximal subgroups of a $p$-group,"Let $G$ be a $p$-group, i.e. $|G|=p^n$. Call $\Phi(G)$ the Frattini group of $G$. Then we have that $G/\Phi(G)\simeq(C_p)^d$ ($d$ copies of the cyclic group of order $p$, i.e. $\overbrace{C_p\times\cdots\times C_p}^{d-times}$), for some $d\in\mathbb N$. And till here it's all right. Then my teacher said that the numbers of maximal subgroup of $G$ is
$$
\frac{p^d-1}{p-1}.
$$
What I can't understand is: Why the numbers of maximal subgroups of a $p$-groups are of the form $$
\frac{p^m-1}{p-1}=1+p+p^2+\cdots+p^{m-1}
$$ for some $n\in\mathbb N$. Why $m=d$, hence in which way $d$ is related to the numbers of maximal subgroup of $G$. Any help would be appreciated so much. Thank you all.","['finite-groups', 'group-theory', 'abstract-algebra']"
806919,"Second derivative test inconclusive, all derivatives are 0, moving critical point to origin, no result?","Here is a function $f(x,y)=x^4 + 6x^2y^2 + y^4 -4x^3 - 12xy^2 + 6x^2 + 6y^2 - 4x + 1$. I've happily proved that $(1,0)$ is a critical point for that function. Now I'd like to decide whether is it a saddle point, a minimum or a maximum. I've seen that some technique that might work is to ""move"" the origin to this point $(1,0)$. But I don't see how it works. What I've tried: I've rewritten the function in term of my new coordinates when moving the point but of course I face the same problem of zero-derivatives. Do I not get the technique? Can you tell me about it? Thank you!","['optimization', 'partial-derivative', 'functional-analysis', 'functions']"
806994,Difference between Borel Sigma algebra and Cylindrical sigma algebra?,"I see that there are two differen concepts for Sigma Algebras on cartesian products over the real numbers. The first one is the Borel Sigma Algebra created by the product topology. The other one is the cylindrical sigma algebra. 
Actually, when I read the definition of cylinder sets via projections see Wikipedia , I first thought that these concepts would be the same. Somehow, this seems to be wrong. So how are they related to each other. Is one of them coarser than the other or are they in general incomparable and why is the cylindrical one used in probability theory?","['measure-theory', 'probability-theory', 'stochastic-calculus', 'real-analysis', 'probability']"
807006,Connection vs Curvature,"Why is twice a connection usually referred to the curvature: $\overline{\nabla}\circ\nabla=F^\nabla$ Is there an axiomatic definition of curvature, e.g. it is module-linear operator etc?","['manifolds', 'vector-bundles', 'differential-geometry']"
807022,subgroups of the group of pentagon symmetries,"The pentagon has 5 line symmetries and therefore we will have 10 symmetries. So, we let the group G with order 10 denote the symmetry group of a pentagon. A subset $H$ of $G$ is a subgroup $(H, *)$ to the group $(G, *)$ if and only if $(H,*)$ is a group. To determine how many subgroups there are, I can use the Lagrange's theorem which tells us that the subgroups of a group with order n have a order m such that $m | n$. By this theorem we get know that the group $G$ has 5 subgroups since the divisors m of 10 is $m=1,2,5,10$. The question is, how shall I sketch the lattice of subgroups? Shall I check every possible subset and then check if they are subgroups or is there a faster way? I know that the 10 symmetries are the identity element, 4 rotation and 5 reflections. We can see these operation of the transformation as permutation. The first transformation that rotates 72 degrees are the permutation (ABCDE), 144 degrees are the permutation (ABCDE)^2 etc. This permutation have the order 5 since if we rotate 5 times we will get the identity (""the original pentagon"") . The reflection transformations are permutations with 2 cycles with length 2. But how do I know that the subgroups with order 5 are the ones with identity and 4 rotations? EDIT The order 2 is easy to determine. The subsets $\{i,g\}$ there $g \in G -\{reflections\}$ are not groups because the inverse of g is not in the subset. BUT if g is one of the reflections then we have a group, since the reflections have the order 2 which means that the element $g$ is the inverse of it self. This means that the subset is a subgroup because (i) it is closed and (ii) the inverse is in the subset. EDIT 2 Can I think like this?
We let a subset be 
$$H = \{\text{id},r,r^2,r^3,z\}$$
there r are the rotation and z is the reflection. By checking the properties for a group, we can see that the properties about that every element in H has an inverse does not hold. the element $r$ has the inverse $r^4$ which is not in $H$ and therefore the subset $H$ cannot be a subgroup. So, by removing one of the rotations and putting one of the reflections, we see that we are removing some inverses. So, the only subgroup of order 5 are 
$$K=\{\text{id},r,r^2,r^3,r^4\}$$ Am I thinking correctly? Or is it better to write down the group table to find the subsets which are subgroups?","['dihedral-groups', 'discrete-mathematics', 'group-theory', 'normal-subgroups']"
807053,Application of weak $L^p$ estimate besides for proving boundedness of some linear operator,"For all $1\leq p< \infty$, weak-$L^p(\mathbb{R}^d)$ space is defined as a set  of all functions $f$ such that 
$$\gamma^p|\{x\in \mathbb{R}^d: |f(x)|>\gamma\}|<\infty$$
for every $\gamma>0$. By Chebyshev inequality, if $f\in L^p(\mathbb{R}^d)$, then $f\in$ weak-$L^p(\mathbb{R}^d)$.
Let $T$ be a linear operator on  weak-$L^p(\mathbb{R}^d)$ and $1\leq p <\infty$. If there exist a constant $C_1>0$ such that
$$\gamma^p|\{x\in \mathbb{R}^d: |Tf(x)|>\gamma\}|\leq C_1 \|f\|_p^p.$$
for every $\gamma>0$, 
then by using Marcinkiewicz Interpolation Theorem, we have the boundedness of $T$ on $L^p(\mathbb{R}^d)$ for $1<p<\infty$, that is $\|Tf\|_p\leq C_2\|f\|_p$.
One of the examples of the operator $T$ is Hardy-Littlewood maximal operator $M$. My question is that what is the application of weak type estimates of linear operator besides proving the boundedness of the operator?","['functional-analysis', 'measure-theory', 'harmonic-analysis', 'real-analysis', 'lp-spaces']"
