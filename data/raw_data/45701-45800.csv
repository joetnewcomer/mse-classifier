question_id,title,body,tags
457390,"Independence of $(X,Y)$ with joint PDF $f_{X,Y}(x,y)=8xy$ on $ 0<y<x<1$","I know that as a general property, if $f_{X,Y}(x,y)=g(x)h(y)$ , then we say X and Y are independent random variables. However, I am having trouble to accept this statement. Take the case: $f_{X,Y}(x,y)=8xy, 0<y<x<1$ Then, $f_{X}(x)=4x$ and $f_{Y}(y)=4y$ , where $f_{X}(x).f_{Y}(y)\ne f_{X,Y}(x,y)$ Maybe I am getting something wrong over the limits of integration, I often trip on simple things... Or maybe, in this case, since the variables are dependent in the limits of integration, then they cannot be independent. But I havent seen any book point that as a requirement... So I suppose I got something wrong in my calculations. If someone could please clarify this for me, I would be grateful.","['probability-theory', 'probability-distributions', 'independence']"
457391,Is this parabola the same as this circle?,"Let $K$ be a field of characteristic not 2. Is there an invertible rational function between $\mathbb{P}^1(K) = \{ [s:t] : s,t \in K, (s,t) \neq (0,0) \}$ and $V= \{ [x:y:z] : 2xy+z^2 = 0 \}$? Here $[s:t]=[u:v]$ iff $sv=tu$ and $(s,t)\neq (0,0) \neq (u,v)$. A rational function must be homogenous to be well defined.","['rational-functions', 'algebraic-geometry', 'projective-geometry']"
457392,Is a square-integrable continuous local martingale a true martingale? [duplicate],"This question already has an answer here : Is continuous L2 bounded local martingale a true martingale? (1 answer) Closed 10 years ago . I am wondering, if the following is true without any other assumptions and if so, how to prove it: Let $(M_t)_{t \geq 0}$ be a continuous local martingale on a filtered probability space $(\Omega, \mathcal{F}, (\mathcal{F}_t)_{t\geq 0}, P)$ that satisfies the usual conditions. If $(M_t)_{t\geq 0}$is square integrable (that is, for all $t\geq 0$ we have $E[M_t^2] < \infty$) then $(M_t)_{t\geq 0}$ is a true martingale. Thanks for any advice.","['probability-theory', 'stochastic-processes', 'martingales']"
457400,Function and its exterior derivative,"Is there an example of a function $f:M\to \mathbb R$, where $M$ is a differentiable manifold, such that $f$ is constant on the hypersurface $\Sigma$  and its exterior derivative $df\neq 0$ on $\Sigma$? My intuition of the exterior derivative is simply how $f$ changes in any arbitrary direction. Is this not right? I ask this due to a proof in these notes on page 125 for the Lemma $K_{ab}=K_{ba}$. The first line of the proof suggests that such an example exists? Or perhaps I have misunderstood something?","['differential-geometry', 'exterior-derivative', 'manifolds', 'functions']"
457412,Why is the Jacobian matrix the transpose of what I would think it'd be/usefully be (total derivative is a synonym) (EDIT: I was a total wally),"I'm sorry this isn't a yes/no/am-I-right question but I seriously cannot see why the Jacobian/total derivative matrix is what it is?
I am also using it as LaTeX practice (for maths) hence the barely relevant blocks of math. (note the terms in the title and this message is what I hope to get clarified, just incase they are wrong) $f:\mathbb{R}^n\rightarrow\mathbb{R}^m$
and $f(x)=y$ I will use the notation of $x^i$ being the ith member of a vector x, that is: $x=(x^1,x^2,x^3, ... ,x^k)$ for a vector of order/length k. Consider also the linear map: (or should I say transform?) $A:\mathbb{R}^n\rightarrow\mathbb{R}^m$ Consider now $x,u \in \mathbb{R}^n$ (I would use delta x for u, but then my notation could backfire) The best linear approximation we can have for the ith coordinate of the image is: $$f(x+u)^i = f(x)^i + \sum^n_{j=1}(\frac{\partial f(x)^i}{\partial x^j}u^j)$$ Which is basically the definition of a partial derivative. Nothing new here. Clearly now:
$$f(x) + \begin{bmatrix}
\frac{\partial f(x)^1}{\partial x^1} &
\frac{\partial f(x)^1}{\partial x^2} &
...&
\frac{\partial f(x)^1}{\partial x^n} \\
\frac{\partial f(x)^2}{\partial x^1} &
\frac{\partial f(x)^2}{\partial x^2} &
...&
\frac{\partial f(x)^2}{\partial x^n} \\
...&...&...&...\\
\frac{\partial f(x)^m}{\partial x^1} &
\frac{\partial f(x)^m}{\partial x^2} &
...&
\frac{\partial f(x)^m}{\partial x^n}
\end{bmatrix}*\begin{bmatrix}u^1\\u^2\\...\\u^n\end{bmatrix}
\approx f(x+u)$$ Let: $$\begin{bmatrix}
\frac{\partial f(x)^1}{\partial x^1} &
\frac{\partial f(x)^1}{\partial x^2} &
...&
\frac{\partial f(x)^1}{\partial x^n} \\
\frac{\partial f(x)^2}{\partial x^1} &
\frac{\partial f(x)^2}{\partial x^2} &
...&
\frac{\partial f(x)^2}{\partial x^n} \\
...&...&...&...\\
\frac{\partial f(x)^m}{\partial x^1} &
\frac{\partial f(x)^m}{\partial x^2} &
...&
\frac{\partial f(x)^m}{\partial x^n}
\end{bmatrix}*\begin{bmatrix}u^1\\u^2\\...\\u^n\end{bmatrix}
=\begin{bmatrix}v^1\\v^2\\...\\v^m\end{bmatrix}$$ Then: $f(x+u)\approx y+v$ That is a pretty compelling case for not transposing it! If you transpose it you can then use row-vectors and pre-multiply, rather than post, but column-vectors and linear algebra are something that is so well established, I wont restate. Now the total derivative matrix is listed in my notes (quite correctly IMO) as what I've just put above. Writing it like I have above looks nice, because now let that matrix be A: $f(x+u) \approx f(x)+Au$ isn't that lovely! The ""Jacobian of a transformation"" however is written as ""the determinant of the transpose of this matrix"" and I must ask WHY?
Transposing a matrix does not affect it's determinant! I cannot find any reason to transpose it UNLESS there is some notation I don't know about where: $$\frac{\partial (x,y)}{\partial(u,v)}$$ = some 2x2 matrix that is the transpose of what I claim it ought to be. But my book says the above denotes a determinant <---NOT a matrix So why might I want to transpose it? Unless there are several things with ""Jacobian"" in the name maybe, could someone correct me! Edit: The books consider $A^T$ as the Jacobian Matrix (?) and ""The Jacobian of the transformation"" is defined using the determinant of that matrix, which is written as just: $$\frac{\partial (y^1,y^2,...,y^n)}{\partial(x^1,x^2,..,x^n)}$$ Obviously in this case n=m I WAS A HUGE DIPSTICK I'm so sorry guys, this has wasted everyone's time, 'cept maybe John's..... In the 2x2 case: $$r_1=x_1-x_0 = (\frac{\partial x}{\partial u},\frac{\partial y}{\partial u})\Delta u$$ $$r_2=x_2-x_0 = (\frac{\partial x}{\partial v},\frac{\partial y}{\partial v})\Delta v$$ You can then find the area as $\lVert r_1 \times r_2\rVert$ And
$$r_1\times r_2 = det\begin{bmatrix}
\frac{\partial x}{\partial u} &
\frac{\partial y}{\partial u}
\\
\frac{\partial x}{\partial v} &
\frac{\partial y}{\partial v}\end{bmatrix} . \Delta u\Delta v\boldsymbol{k}$$ It is talking about the transpose of that! I am so sorry everyone!","['notation', 'calculus', 'differential-geometry']"
457428,For how many $n \in \mathbb{N}$ is $\sqrt{n^2+2379}$ natural?,"Here's my attempt at a solution: the expression $\sqrt{n^2+2379}$ is natural iff  $$n^2 + 2379 = x^2, \quad \mbox{ for some } x \in \mathbb{N}.$$ Therefore $$(x+n)(x-n)=2379=3 \cdot 13 \cdot 61.$$ I try to represent $2379$ as a product of two natural numbers, this can be done in four ways: $$2379=(3 \cdot 13 )\cdot 61$$
$$2379=3 \cdot (13 \cdot 61)$$
$$2379=(3 \cdot 61)\cdot 13$$
$$2379=1 \cdot 2379 $$ Comparing these options to $(x-n)(x+n)=2379$ produces four pairs, since $$(x-n)(x+n) = ab \implies x=(a+b)/2, \ n= (a-b)/2, \quad \mbox{ assuming } a>b.$$ The four $n$'s are then $11,85,395,1189$. Is my solution correct? Is there a way of doing this more theoretically, without knowing explicitly the prime factorization of $2379$?","['elementary-number-theory', 'discrete-mathematics']"
457434,A trigonometry problem,Solve θ in $\sin^2θ$ - $\cos^2θ$ = 1 $$-1 = \cos^2θ - \sin^2θ \\ -1 = \cos(2θ)$$ What would be the next step to solve this enigma?,['trigonometry']
457447,"If $R$ is an integral domain, then $R[[x]]$ is an integral domain","While solving another problem (specifically Exercise 7.2 in Atiyah & Macdonald's Introduction to  Commutative Algebra ), I got stuck in the following step: If $R$ is an integral domain, how I can prove that $R[[x]]$ is an
  integral domain? Here $R[[x]]$ is the set of all formal series in $x$ with coefficients in $R$. So typical element of $R[[x]]$ would have the form $a_0+a_1x+a_2x^2+\cdots$ where $a_i\in R$. So I need to prove that if
$$
(a_0+a_1x+a_2x^2+\cdots)(b_0+b_1x+b_2x^2+\cdots)=0
$$
then $a_i=0$ and $b_i=0$ for all $i\ge 0$. Now, I am not particularly fond of opening up those brackets :( Is there any slick way of proving this?","['commutative-algebra', 'abstract-algebra']"
457462,$\|A-B\|^2 = ?$,"We know that if $x,y \in \mathbb{R}$
\begin{equation}
(x-y)^2 = x^2 -2xy + y^2
\end{equation}
If $x,y$ are vectors in $\mathbb{R}^n$ we have
\begin{equation}
|x-y|^2=|x|^2 - 2 \ x \cdot y +|y|^2.
\end{equation}
where $x\cdot y$ is the usual scalar product. We know that there are several ways to define $\|A\|$ when $A$ is a matrix, for example
\begin{equation}
\|A\| = \sup  \{ |Ax|: |x|=1\}
\end{equation}
Is there a similar formula as above? This is a formula to $\|A-B\|^2?$",['matrices']
457472,Understanding $A^A$ in set theory,"If $A=\left\{1,2,3\right\}$ so what will be $A^A$? What is the geometric interpretation for $A^A$? Thanks",['elementary-set-theory']
457477,"Evaluate the triple integral, tetrahedron","$$\iiint_E x^2dV, \text{where E is the solid tetrahedron with vertices }(0,0,0), (1,0,0), (0,1,0), \text{and (0,0,1)}$$ I need some assistance on setting up the limits. If someone could help me learn how to set up my limits of integration, that would be great. I should be able to integrate it just fine.","['multivariable-calculus', 'integration']"
457495,"If $A, B, C$ are finitely generated $\mathbb{Z}/{p^n}\mathbb{Z}$-modules such that $A \oplus B \simeq A \oplus C$, then $B \simeq C$","A friend that is preparing for an algebra qualifying exam asked me the following question yesterday, but I really have no idea of how to approach the problem. Let $A, B$ and $C$ be finitely generated  $\mathbb{Z}/{p^n}\mathbb{Z}$-modules (p is a prime number) such that $A \oplus B \simeq A \oplus C$. Prove that $B \simeq C$. I would really appreciate if someone can provide me some help with this question. Thank you very much.","['modules', 'ring-theory', 'abstract-algebra']"
457500,Maximum and minimum of an integral under integral constraints.,"Find the maximum and minimum of the following integral in terms of $f(x),a,C$: \begin{align}I=\int_{0}^{a} \frac{x}{f(x)}p(x)dx  \end{align}
s.t.: 1) $\int_{0}^{a} p(x)dx=1$ 2) $\int_{0}^{a} f(x)p(x)dx=C$ Notes: 1) $p(x)$ is an unknown probability density function. 2) $x,f(x),p(x)\geq 0 \;,\; C>0$ 3) $f(0)=0$ 4) $\lim_{x \to 0}\frac{x}{f(x)}=0$","['optimization', 'calculus', 'calculus-of-variations', 'probability-distributions', 'linear-programming']"
457523,Self-intersection of a divisor $D$ with complete linear system $|D|$ without fixed component,"Let $D$ be a divisor on an algebraic complex smooth projective surface $S$. Assume that the complete linear system $|D|$ is not empty and has no fixed component. Is it true that $D^2 \geq 0$, where $D^2$ is the self-intersection of $D$?",['algebraic-geometry']
457542,Error in proof: $\mathbb{C} \cong \mathbb{C} \times \mathbb{C}$??,"I've unintentionally ""proved"" the following: $$\mathbb{C} \cong \mathbb{C} \times \mathbb{C}$$ Can you help me tracing the error I made resulting to this non-proof? Here it is. First of all, I recall an algebraic theorem about the complex plane: $\mathbb{C} \cong  \mathbb{R}[X]/(X^2+1)$ . The rest of the non-proof is about the apparent isomorphism $\mathbb{C} \times \mathbb{C} \cong  \mathbb{R}[X]/(X^2+1)$ . The ring $R[X]$ is a commutative ring containing a unit, so we can write the ideal $(X^2+1)$ as a product of ideals $(X-i)(X+i)$ . These ideals are indivisable: $(X+i)(X-i) \ni \frac{1}{2}(X+i)-\frac{1}{2}(X-i)=i$ , so every polynomial $q = i^3q \cdot i$ is contained in the sum of ideals. Now we can use the generalisation of the Chinese remainder theorem: 
For a commutative ring R with unity, and indivisible ideals $I,J$ applies $R/IJ \cong R/I \times R/J$ . Now we have $\mathbb{R}[X]/(X^2+1) \cong \mathbb{R}[X]/(X+i) \times \mathbb{R}[X]/(X-i)$ . I recall that for every homomorphism of rings $f: R \rightarrow S$ the isomorphism $R/\ker(f) \cong f(R)$ holds. Consider the mapping $s_r \ : \ R[X] \rightarrow S \ : \ \sum a_i X^i \mapsto \sum a_i r^i$ . This substitution map is an homomorphism. A special case is the homomorphism $s_i \ : \ \mathbb{R}[X] \rightarrow \mathbb{C} \ : \ \sum a_i X^i \mapsto \sum a_i r^i$ that substitutes $i$ in $X$ . Its kernel is exactly the ideal $(X-i)$ . The image clairy contains $\{ a + bi: a,b \in \mathbb{R} \} = \mathbb{C}$ , and the image is contained in $\mathbb{C}$ as well. So we obtain $\mathbb{C} \cong \mathbb{R}[X]/(X+i)$ . The same trick with the substitution $s_{-i}$ shows that $\mathbb{C} \cong \mathbb{R}[X]/(X-i)$ .
This results into $\mathbb{C} \cong \mathbb{C} \times \mathbb{C}$ . Here ends the ""proof."" I feel a little bad about using $s_i$ , because $i \notin \mathbb{R}$ , but I remember that a similar mapping had to be used to proof that $\mathbb{C} \cong  \mathbb{R}[X]/(X^2+1)$ . I'd be thankful if you help me to sift this through and find the error(s).","['ring-theory', 'abstract-algebra', 'fake-proofs']"
457557,Finding volume using triple integrals.,"Use a triple integral to find the volume of the solid: The solid enclosed by the cylinder $$x^2+y^2=9$$ and the planes $$y+z=5$$ and $$z=1$$ This is how I started solving the problem, but the way I was solving it lead me to 0, which is incorrect. $$\int_{-3}^3\int_{-\sqrt{9-y^2}}^{\sqrt{9-y^2}}\int_{1}^{5-y}dzdxdy=\int_{-3}^3\int_{-\sqrt{9-y^2}}^{\sqrt{9-y^2}}\left(4-y\right)dxdy=\int_{-3}^3\left[4x-xy\right]_{-\sqrt{9-y^2}}^\sqrt{9-y^2}dy= {8\int_{-3}^3{\sqrt{9-y^2}}dy}-2\int_{-3}^3y{\sqrt{9-y^2}}dy$$ If this is wrong, then that would explain why I'm stuck. If this is correct so far, that's good news, but the bad news is that I'm still stuck. If someone could help me out, that would be wonderful, thanks!","['multivariable-calculus', 'integration']"
457562,Local coefficient systems for schemes,"Let $B$ be a path connected topological space with universal cover $p:X \rightarrow B$.
Let $G = \pi_1B$, then for a $G$-module $M$ we can form $X \times_G M = X \times M / (g x,m) \sim (x, g m)$ where $M$ is given the discrete topology. The sections of the bundle $X \times_G M \rightarrow B$ form a locally constant sheaf associated to $M$. Is there an analogous construction of a sheaf over a scheme $B$ using some sort of action of the etale fundamental group to form a scheme over $B$?",['algebraic-geometry']
457569,Is taking inverse automatically well-defined?,"By the usual definition, Lie group is a manifold $G$ with a group structure on it such that the multiplication $m\colon G\times G\to G$ and taking inverse $i\colon G\to G$ are both smooth maps. But it is not difficult to proove that actually we need only the smoothness of the multiplication map $m$. The proof uses the fact that the preimage $m^{-1}(1)$ of $1\in G$ is a smooth submanifold of $G\times G$, and the inverse function theorem. Now I am wondering, is that true for algebraic groups? It might be obvious, but it's not obvious to me, since in this case we can't use methods from the smooth case. More precisely, suppose $G$ is a variety with a group structure such that $m\colon G\times G\to G$ is a regular map. Is it true that it automatically guarantees regularity of the inversion map $i\colon G\to G$ ? Thank you very much for your help!","['algebraic-geometry', 'algebraic-groups', 'lie-groups', 'definition']"
457572,"Local-global properties (localization): free, projective, injective, flat, torsion-free, etc?","Let $R$ be a commutative unital ring. We say that a property $(\ast)$ of modules is local-global when the following conditions are equivalent for any $R$-module $M$: $M$ is a $(\ast)$ $R$-module; $S^{-1}M$ is a $(\ast)$ $S^{-1}R$-module for any multiplicatively closed subset $S\!\subseteq\!R$; $M_\mathfrak{p}$ is a $(\ast)$ $R_\mathfrak{p}$-module for any prime ideal $\mathfrak{p}\!\unlhd\!R$; $M_\mathfrak{m}$ is a $(\ast)$ $R_\mathfrak{m}$-module for any maximal ideal $\mathfrak{m}\!\unlhd\!R$. I'm asking for examples of local-global properties. I've heard that flat is such a property and that injective isn't. What about free , projective , torsion-free $(\{m\in M: \exists \text{ non-zero-divisor }r\in R\text{ with }rm=0\}=0)$, divisible $(\forall$ non-zero-divisors $r\in R\, \forall m\in M\, \exists x\in M: rx=m)$, ...?","['homological-algebra', 'commutative-algebra', 'abstract-algebra']"
457577,How many different shapes can I make with this toy?,"I have the following toy, perhaps some of you have seen it before. It consists of a bunch of cubes with an elastic string in the middle. You can bend it into different shapes like this: Or this: Or even this: Here is the product page for it on Amazon if you want more of a description. From one block to the next, you can orient the next either on the top, or on one of the four sides. With this, I think you have no more than $5^{11}$ possible choices you can make while playing with it. But some of these will give the same shape up to translation and rotation. There's also the problem of cubes colliding, excluding some choices. For instance, in the very first picture, there is only one way to make that shape. In the second, I think there are about 8. For instance, you can ""rotate"" the loop by placing the start and end points at a different place. In the third, I think there is an argument that there are no other ways to make that shape, since you don't have four subunits forming a square. All this is to ask, how many different shapes can I make with this toy? If I have a toy with $n$ subunits instead, what is the answer then? [If this question is related to any serious areas of math or well known problems, let me know! I suspect there might be some connection with protein folding, but I know nothing about such things. Or perhaps there is some algebraic way to think about this, where my question translates into counting the number of orbits under some group action.]","['discrete-mathematics', 'combinatorial-geometry', 'recreational-mathematics', 'combinatorics']"
457579,Is my proof correct? (a generalization of the Laurent expansion in an annulus),"I want to see if my solution to the following problem in Ahlfors' Complex Analysis text is correct. The problem reads: Let $\Omega$ be a doubly connected region whose complement consists of the components $E_1, E_2$.   Prove that every analytic function $f(z)$ in $\Omega$ can be written in the form $f_1(z)+f_2(z)$ where $f_1(z)$ is analytic outside of $E_1$ and $f_2(z)$ is analytic outside of $E_2$. (Note that this is a generalization of the familiar Laurent expansion in an annulus.) Here is my attempt at the proof: Firstly, we will prove the statement for a bounded region $\Omega$: It is given that $\Omega^c=E_1 \cup E_2$, where the complement is taken in the Riemann sphere. Exactly one of these components contains $\infty$, and the other one is hence bounded. Suppose WLOG that $E_1$ is bounded and $\infty \in E_2$. The boundary of $\Omega$ is $$\partial \Omega=\partial (\Omega^c)=\partial \left(E_1 \cup E_2 \right)=\overline{E_1 \cup E_2} \setminus \text{int}(E_1 \cup E_2)=E_1 \cup E_2 \setminus (\text{int}E_1 \cup \text{int} E_2)=(E_1 \cup E_2) \cap [(\text{int} E_1)^c \cap (\text{int} E_2)^c]\\=(E_1 \cap (\text{int} E_1)^c \cap (\text{int} E_2)^c) \cup (E_1 \cap (\text{int} E_1)^c \cap (\text{int} E_2)^c) \\ =\partial E_1 \cap (\text{int} E_2)^c \bigcup \partial E_2 \cap (\text{int} E_1)^c=\partial E_1 \cup \partial E_2.$$ where I have used information from this question. Next, given $\delta>0$ we cover the plane by the net of squares of side $\delta$, induced by the lines $x=m \delta,y=n \delta$, and we denote by $Q_j, j \in J$ the closed squares in the next which are contained entirely in $\Omega$; because $\Omega$ is bounded $J$ is finite, and if $\delta$ is sufficiently small $J$ is not empty. Denote the distance between $\partial E_1,\partial E_2$ by $\rho$. It is clear that $\rho>0$, and therefore for $\delta<\frac{\rho}{\sqrt{2}}$ the closed squares of the net are partitioned into three groups: The squares contained entirely in $\Omega$, $Q=\{Q_j: j \in J \}$. The squares which meet $E_1$ (exclusively), $R=\{R_k: k \in K \}$. The squares which meet $E_2$ (exclusively), $S=\{S_l: l \in L \}$. Furthermore, if $\delta<\frac{\rho}{2\sqrt{2}}$ two squares from $R$ and $S$ can't be adjacent to each other. It is proven in the text that $$ f(z)=\frac{1}{2 \pi i} \oint_{\partial Q} \frac{f(\zeta)}{\zeta-z} \mathrm{d} \zeta,$$ for all $z \in \text{int} Q$. We can prove once more that $\partial Q=\partial R \cup \partial S$, so that
$$f(z)=\frac{1}{2\pi i}\oint_{\partial S} \frac{f(\zeta)}{\zeta-z} \mathrm{d} \zeta+\frac{1}{2 \pi i}\oint_{\partial R} \frac{f(\zeta)}{\zeta-z} \mathrm{d} \zeta=:f_1(z)+f_2(z)$$ with the suitable orientation. This will work for any $z \in \Omega$ provided that we take $\delta$ sufficiently small, such that $z \in \text{int} Q$. Finally, if $\Omega$ is not bounded, and $z \in \Omega$, repeat this proof in the restricted domain $\Omega'=\Omega \cap \{\zeta: |\zeta|<|z|+1 \}$. Is this correct?","['complex-analysis', 'solution-verification']"
457581,Find all complex solutions to an exponential equation,Find all complex numbers z such that $e^{-2iz}/4 + e^{-iz}/2 + 1 + 2e^{iz} + 4e^{2iz} = 0 $ Rewriting the left-hand side using Eulers formula doesn't seem to get me anywhere. Need some help with this one! Thanks in advance!,"['complex-numbers', 'complex-analysis']"
457586,"Proving that a ""prime graph"" is connected","Let the prime graph be defined as the graph of all natural numbers, with two vertices being connected if the sum of the numbers on the two vertices add up to a prime number. Prove that the prime graph is connected. This has no solution on the textbook. How should I approach this problem? I'm thinking of proving everything is connected via some path to $1$ but I don't know how to do that.","['prime-numbers', 'graph-theory', 'combinatorics']"
457612,On sections of the tangent bundle of a Grassmannian,"Being more familiar with linear operators than with geometry, I like to see $G_K(r,n)$ , the Grassmannian of all $r$ dimensional subspaces in $K^{r+n}$ ( $K=\mathbb{R}, \mathbb{C}$ ), as the set of all rank $k$ projections (self-adjoint idempotents) in $M_n(K)$ . And I am also interested in the infinite-dimensional Grassmannians sitting in $B(H)$ , the algebra of bounded linear operators on a separable infinite-dimensional $K$ Hilbert space. In the latter, the projections split into connected components according to their rank and their nullity. These are smooth manifolds, but modelled on an infinite-dimensional (for $r\neq 0$ and $n\neq 0$ ) Banach space. They are the infinite-dimensional analogues of the above. I cheated with the usual notations to include the latter: for instance, $G_\mathbb{C}(3,\infty)$ corresponds to the rank $3$ projections in $B(H)$ . Thinking about some linear questions, I ended up being interested in the following: does there exist a nowhere vanishing section of the tangent bundle of $G_K(r,n)$ ? The two cases I am really comfortable with are $G_\mathbb{R}(1,1)$ (yes, that's $S^1$ and the tangent bundle is trivial), and $G_\mathbb{C}(1,1)$ (no, by the hairy ball theorem since it is $S^2$ ). I vaguely know that under some conditions, the tangent bundle of a manifold admits a nowhere vanishing section if and only if its Euler class (or should  say number?) is zero. And that under some conditions, this coincides with the Euler characteristic of the manifold. Questions: 1 - What is a precise statement and set of conditions for the latter, hopefully applying to the (possibly infinite-dimensional) Grassmannians? 2 - If it applies, what are the relevant Euler invariants (characteristic/class/number) for $G_K(r,n)$ ? After a lot of googling, I think I found $\binom{r+n}{r}$ in the complex case (without being sure because I am having a hard time understanding the geometric language). Is this true? What does the number mean exactly? What about the real case? What about the infinite-dimensional case? 3 - Ultimately, I am mostly interested in knowing when I can say that any section of the tangent bundle of $G_K(r,n)$ must vanish, and how to justify it properly. Could you clarify this for me? 4 - I think it is about time for me to understand these things. Do you know a friendly reference for someone who has a lot of difficulty with geometry? Thank you. Edit: forget the infinite-dimensional analogue. In $B(H)$ , the unitary group is much less twisted than in $M_n$ . A famous theorem of Kuiper shows that it is contractible. If I am not mistaken, this entails that the Grassmannians of $B(H)$ have a trivial tangent bundle.","['vector-bundles', 'differential-geometry']"
457617,How to solve differential equations using fft?,Can anyone point me to the principles and books/websites about it? Which properties must the differential equation have that a solution with fft is possible? Why can it be solved that way?,"['ordinary-differential-equations', 'fourier-analysis', 'reference-request']"
457629,The analogue of euler's theorem in $\mathbb{F}_p[x]$,"Let $p$ be a prime number, and $m(x)$ be in $\mathbb{F}_p[x]$. the analogue of euler's theorem is that for certain polynomials $a(x)$ in $\mathbb{F}_p$, and some number $\phi_p(m)$, $$a(x)^{\phi_p(m)} = 1\mod m(x)$$ for which polynomials $a(x)$ does this theorem apply?
what is the number $\phi_p(x)?$ my solution but not sure if this is right? $\phi_p(m)$ is the totient function. it gives back the integers less than or equal to $m$ which are relatively prime to $m$, this theorem applies for $a(x)$ polynomials which are coprimes with $m(x).$",['abstract-algebra']
457641,How to generate algebraic span of a set of matrices (how many multiplications?),"I've got a question about matrices and matrix algebras that offhand seems difficult, I'm wondering there is any sharp solution? Or perhaps it's known to not have any solution at all? Suppose you have some set of n complex DxD matrices {M1,...,Mn}, and consider the algebra which they generate (under finite multiplications and additions with coefficients over the complex numbers), in particular, consider the case where that algebra is NOT the full matrix algebra M_D(C). EDIT: First question, I suppose, is to ask, given the generators (and supposing that they're linearly independent), what's the best way to figure out the sub-algebra (or even just its dimension) of the full matrix algebra that you can generate? Second, It seems clear that you should be able to generate any ""basis"" element (in the vector space sense, a matrix with a one in exactly one entry and zero everywhere else) which exists in your algebra after some finite number of multiplications. My question is, is there a good way to figure out exactly what the ""maximum"" number of multiplications you'd need to generate any of the basis elements is? Certainly it should be bounded, but has anyone figured out bounds on this, perhaps different bounds given different conditions on your set of generators? If anyone recognizes this as something other people have thought about/figured out and could point me in the right direction I would be very grateful!","['operator-algebras', 'matrices']"
457678,Are there any strategy to solve this system of multivariate quadratic equation?,"Solve:
$$
(\sum_{j=1}^{n}a_{ij}x_{j})(\sum_{j=1}^{n}a_{ij}y_{j})=0, \quad i=1,\cdots, 2n-1\\
\sum_{j=1}^{n}x_{j}y_{j}=0
$$
,where $a_{ij}$ are known real constants and $x_{j}$ and $y_{j}$ are nonzero unknowns to be solved in $\mathbb{Q}$. The motivation of this question is trying to decompose a set of vectors $a_{i}$ into two hyperplanes with orthogonal normal vectors. P.S. Thanks to S.B.'s comment. In my specific application, $a_{ij}$ are generated so that a nonzero solution is guaranteed to exist and the number of $a_{i}$ always exceeds the dimension of the space in question. I know that they belong to two such subspaces, but I want to know which. Thanks very much!","['multivariable-calculus', 'algebraic-geometry']"
457698,Modular Functions with Rational Fourier Expansions,"I have been reading the paper of Cox, McKay and Stevenhagen ""Principal Moduli and Class Fields"", http://arxiv.org/pdf/math/0311202v1.pdf , and I have a question regarding the nature of the function field for $X_0(N)$: if I have a modular function for $\Gamma_0(N)$ that has a rational $q$-expansion at $\infty$, does it follow that $f\in\mathbf{Q}(j,j_N)$? Allow to me to elaborate on some discoveries I've made reading the above paper, and playing with sage: I understand that the function field over $\mathbf{C}$ for $X_0(N)$ is $\mathbf{C}(j,j_N)$, and that the $\mathbf{Q}$-function field given by $\mathbf{Q}(j,j_N)$ defines the curve $X_0(N)$ over the rationals. Thus, any modular function for $\Gamma_0(N)$ can be written as 
rational function in $j$ and $j_N$. Now, for the case of level $N=1$ modular functions, it is stated in the paper that if $f$ is a modular function that has a fourier expansion at $\infty$ with rational coefficients, then $f$ in fact lies in $\mathbf{Q}(j)$, which seems intuitive. However, I have recently discovered that the analogous fact does not hold for modular functions for $\Gamma_0(N)$ that have a rational fourier expansion at $\infty$. Using a paper of Maier, I have been able to play with the hauptmoduln for $\Gamma_0(N)$ when the group has genus zero. These functions have rational $q$-expansions, but don't necessarily lie in $\mathbf{Q}(j,j_N)$. Indeed, using the function $t_2$ in his paper (a hauptmodul for $\Gamma_0(2)$ that has rational $q$-expansion), I computed that $$t_2(1/4\sqrt{-7} - 1/4)$$ is an algebraic integer of degree $2$. In particular, it is definitely not a rational number. On the other hand, the theory of complex multiplication ensures that both $j(1/4\sqrt{-7} - 1/4)$ and $j_2(1/4\sqrt{-7} - 1/4)$ are integers. Therefore, $t_2$ cannot lie in $\mathbf{Q}(j,j_2)$, since otherwise $t_2(1/4\sqrt{-7} - 1/4)$ would have to be rational as well. What is troubling about this fact is that, in the paper of Cox et al., it is stated that if $f$ is a modular function for $\Gamma_0(N)$ and if $\tau$ is an elliptic point of order $2$ for $\Gamma_0(N)^\dagger$, but not one for $\Gamma_0(N)$, then $f(\tau)$ must lie in the maximal abelian extension of $K=\mathbf{Q}(\tau)$ and that this follows from basic complex multiplication theory. Now, if it were the case that $f\in\mathbf{Q}(j,j_N)$, then I'd be happy to believe this, but I've just seen that this is not the case. Therefore, I don't see how basic complex multiplication theory says anything about the nature of $f(\tau)$ in this case. Lastly, as mentioned above, it is stated explicitly that for level $N=1$, we do know that such a modular function with rational $q$-expansion must lie in $\mathbf{Q}(j)$. Does this result remain true for $X_0(N)$ when it has genus zero? That is, after fixing a hauptmodul $h$ with rational fourier expansion, so that any modular function for $\Gamma_0(N)$ can be written as a rational function in $h$, is it true that those functions with rational $q$-expansions can be written as a rational function of $h$ with coefficients in $\mathbf{Q}$? If anyone can shed some led on any part of this problem, I would very much appreciate it!","['modular-forms', 'algebraic-geometry', 'algebraic-number-theory', 'number-theory']"
457708,"Classifying ""nice"" topological spaces on (occasionally pathological) sets","Background : By a unique convergence (UC) topology, I mean a topology under which sequences converge to at most one point. Suppose we are given a set $X$ and a topology $\mathcal T$ on $X$. It can be readily shown that each of the following implies the next: (1) $\mathcal T$ is the discrete topology on $X$. (2) $\mathcal T$ is a Hausdorff topology on $X$. (3) $\mathcal T$ is a UC topology on $X$. (4) $\mathcal T$ is a T$_1$ topology on $X$. Moreover, (4) $\implies$ (3) if and only if $X$ is Dedekind-finite; (3) $\implies$ (1) if and only if $X$ is finite. I've also shown the following: Suppose that $X$ is an amorphous set, $\mathcal T$ a Hausdorff topology on $X$, $C:=\bigl\{x\in X:\{x\}\in\mathcal T\bigr\}$ the set of $\mathcal T$-clopen points of $X$. Then $C$ is cofinite in $X$, and putting $n=|X\setminus C|,$ the following are equivalent: (a) $n\ne 0.$ (b) $\langle X,\mathcal T\rangle$ is compact; in particular, an $n$-point compactification of the discrete space on $C$. (c) $\mathcal T$ is not the discrete topology on $X$. From this, we see that for amorphous $X$, (2) need not imply (1)--so, unless there aren't any amorphous sets, it follows that D-finiteness need not be sufficient for (2) $\implies$ (1). Finally, if $X$ is uncountable, then the cocountable topology on $X$ shows that (3) need not imply (2). The Question : I intend to play more in the realm between (1) and (2) later ( e.g. : regular Hausdorff, normal Hausdorff). At the moment, though, I'd like to refine what I have already as far as possible. Specifically, I'm curious about the following: Is it known to be true that (3) $\implies$ (2) if and only if $X$ is finite? If so, does anyone know of a non-Hausdorff UC topology on a countably infinite set? Is there known to be an equivalent condition on the cardinality of $X$ so that (2) $\implies$ (1)?","['general-topology', 'set-theory', 'separation-axioms']"
457710,"Upper triangular matrices in $\mathrm{SL}(2,\mathbb{R})$","If $G$ is a compact Hausdorff topological group then every neighborhood of the identity contains a neighborhood $U$ which is invariant under conjugation. That is, $gUg^{-1}=U$ for all $g\in G$ . Proof: The map $f:G \times G \rightarrow G$ defined by $f(g, k) = gkg^{-1}$ is continuous. If $V$ is an open neighborhood of the identity, then $G-V$ is compact and $U=G-f(G \times (G-V))$ is open, contained in $V$, invariant under conjugation, and contains the identity. Now, consider the (non-compact) subgroup $T$ of $\mathrm{SL}(2,\mathbb{R})$ consisting of upper triangular matrices, i.e. $2\times 2$ matrices of the form 
$$\begin{pmatrix}a& b\\0& 1/a\end{pmatrix},\;\;\text{$a\in\mathbb{R}-\{0\}$ and $b\in\mathbb{R}$.}$$ Is the conclusion of the first paragraph false for $\mathbf{T}$?","['general-topology', 'topological-groups', 'group-theory']"
457717,What is the absolute minimum that must be accepted/defined in order to prove 1+1=2?,"As I know the ""1 + 1 = 2"" question has been asked before, my question (for now anyway) is more specific: Assuming as little as possible and accepting as few definitions as possible, what are the very basic axioms and definitions that you absolutely must accept in order to prove 1 + 1 = 2? Whenever this question gets asked, the immediate responses are things like, ""well you have to prove what '1', '2', '+', and '=' are.""  And that's fine, but in order to prove all four of those things, and then ultimately what they mean together, what is the absolute bare minimum that you simply must accept for any approach to this problem with a completely blank slate?  e.g. Peano's axioms?","['axioms', 'discrete-mathematics', 'peano-axioms']"
457719,approximating diagonal of inverse sum of low rank and diagonal matrices,"I was wondering if there is any theorem or algorithm to approximate the diagonal elements of the inverse of sum of low rank symmetric positive semi-definite and non-negative diagonal matrix. Let me be more specific. Let say I have: $\mathbf{M} = \Lambda + diag(\mathbf{q})$, where $\Lambda$ is a low rank symmetric positive semi-definite and $diag(\mathbf{q})$ is a diagonal matrix whose diagonal elements are specified by the non-negative vector $\mathbf{q}$. I would like to approximate $(\mathbf{M}^{-1})_{ii}$, diagonal elements of the inverse of $\mathbf{M}$. Q: Is there any way to approximate it efficiently? I can come up with a linear that is very large and if I solve it, I can find the diagonal elements of $\mathbf{M}^{-1}$, but is a trivial one! Isn't it a common problem for people who find to find pre-conditioning for solving large linear system. I could not find anything. My problem is not pre-conditioning. I am actually interested to find diagonal elements of $\mathbf{M}^{-1}$. Thanks,","['matrices', 'approximation', 'linear-algebra', 'numerical-methods', 'numerical-linear-algebra']"
457739,How do I define the limits of a double integral in polar coordinates over an annulus?,"Evaluate the double integral by re-writing them in polar coordinates: $\displaystyle\iint\limits_{R}\frac{y^2}{x^2}\ dA$, where $R$ is part of the annulus (ring) $9\leq x^2+y^2\leq 25$ lying in the first quadrant and below the line $y=x$. So from this, I gather (assuming I understood correctly) that $R=\{(x,y)\mid9\leq x^2+y^2\leq 25,\ 0\leq y\leq x\}$. There are two circles, one where $r=5$ and one where $r=3$. I would guess that what I'm looking for is the larger circle minus the smaller circle, but doing that the only way I can think of yields the following: \begin{gather}
(x^2+y^2)-(x^2+y^2)=25-9\\
0=16
\end{gather} I'm clearly way off track here; how do I look at this so I can define the bounds of the double integral in polar coordinates?","['multivariable-calculus', 'polar-coordinates']"
457742,H is a set of elements $a$ such that $(ax)^2 = (xa)^2$ for all $x$ in G. Prove H is a subgroup of G.,"It is given that H is the set of all elements $a$ in a group G such that $(ax)^2 = (xa)^2$ for every $x$ in G . Prove that H is a subgroup of G. I came across this question while solving the book on Abstract algebra by Pinter. My approach to this problem was :- consider two elements $p$ and $q$ in the set H.
Then $(px)^2 = (xp)^2$ for every $x$ in G . And 
$(qx)^2 = (xq)^2$ for all $x$ in G . from this I was trying to show that $(pqx)^2 = (xpq)^2$ for all $x$ in G . By which we can show that pq is also part of H. And thus H is closed with respect to products. (That H is closed with respect to inverses also needs to be proven but I am stuck in the first stage itself) This approach worked in a previous problem where one had to show that center of a group is a subgroup. There the property of elements in the set C (the center) was 
$ax = xa$ for all $x$ in G . The lack of square term made it easy to prove. So I thought maybe I shouldn't use the same approach. And hence I tried using $x^{-1}$ instead of $x$ in the equation for the element $q$  along with the equation for p. But that is also not working out. If G was Abelian proving this would have been very easy. But it is not given so. Hence I am stuck. Thanks.",['group-theory']
457769,Expected value with indicator random variables,"I don't understand the solution for problem 7a at http://www.ma.utexas.edu/users/geir/teaching/m362k/weeklyhw9solns.pdf . Reproduced below for reference: Suppose that A and B each randomly, and independently,
  choose 3 of 10 objects. Find the expected number of objects chosen by both A and B. solution: Let $X$ be the number of objects chosen by both A and B. For $1 \le i \le
10$, let $$
\begin{align}
X_i = \begin{cases} 1 &\mbox{if } \text{object i is chosen by A and B} \\
0 &\mbox{otherwise } \end{cases} 
\end{align}
$$
  Then $X = X_1 + ... + X_{10}$. We find $$
E[X_i] = 0\cdot P(X_i = 0) + 1\cdot P(X_i = 1) = P(X_i = 1) = 9/100.
$$
  By the linearity of expectation, $$E[X] = 10\cdot E[X_i] = 0.9$$ I don't understand how they reduced $E[X_i]$ (don't they need $P(X_i = 2, 3, ..., 10)$ terms?) and how $9/100$ was computed.","['probability', 'random-variables']"
457777,Limit of a function with factorial [duplicate],"This question already has answers here : Prove that $\lim \limits_{n \to \infty} \frac{x^n}{n!} = 0$, $x \in \Bbb R$. (15 answers) Closed 10 years ago . $\lim_{n \rightarrow \infty} (x^n/n!)=0$. prove.
x is finite whereas n is infinite. But increasing n means also increasing $x^n$. It is understandable that if n is too large n! will exceed $x^n$. How it can be proved in a mathematically precise way?","['factorial', 'limits']"
457787,"""Efficient version"" of Cayley's Theorem in Group Theory","I'm considering finite groups only.
Cayley's theorem says the a group $G$ is isomorphic to a subgroup of $S_{|G|}$.
I think it's interesting to ask for smaller values of $n$ for which $G$ is a subgroup of $S_n$. Obviously, it's not always possible to do better than Cayley's theorem. But sometimes it is possible (for example, $\mathbb{Z}_6$ as a subgroup of $S_5$). So I'm asking: Given a finite group $G$, is there an algorithmic way to find or approximate the minimal $n$ for which $G$ is isomorphic to a subgroup of $S_n$? If the answer to $(1)$ is not known, is it known for specific classes of groups? In particular, for finite abelian groups, is it true that for a prime $p$, the minimal $n$ for $\mathbb{Z}_{p^{t_1}} \times \mathbb{Z}_{p^{t_2}}$ is $p^{t_1}+p^{t_2}$ (I can prove that is is true for different primes $p_1$ and $p_2$, but have problems when it's the same prime in both factors). Thanks!","['permutations', 'group-theory']"
457797,An inequality involving arctan of complex argument,"I have the following conjecture:
\begin{equation}
\text{Re}\left[(1+\text{i}y)\arctan\left(\frac{t}{1+\text{i}y}\right)\right] \ge \arctan(t), \qquad \forall y,t\ge0.
\end{equation} Which seems to be true numerically. 
Can anyone offer some advice on how to approach proving (or disproving) this? It originates from a question involving the (complex) Hilbert transform of a symmetric non-increasing probability distribution:
\begin{equation}
h(y) = (1+\text{i}y)\int_{-\infty}^\infty \frac{1}{1 + \text{i}(y-t)}\text{d}G(t)
\end{equation}
and attempting to show $\text{Re}[h(y)]$ takes its minimum at $y=0$.","['trigonometry', 'inequality', 'complex-analysis', 'integral-transforms']"
457798,"How to find $P_1$ in $(x,y)$ form","From following diagram, $A_1$ is center of circle of radius $r$. All distances are in coordinate system $(x,y)$. Distance from $A_1P_2$ is known. Distance $A_1,A_2,A_3$ is also known from origin. I want to find point $P_1$. I appreciate any help in this regard. Thanks.","['analytic-geometry', 'geometry', 'trigonometry']"
457807,Positive semidefinite matrix problem,"This is a simple question, at least, looks like. Let $x\in\mathbb{R}^n$ and consider the matrix $C$ such that $C_{ij}=|x_i|+|x_j|-|x_i-x_j|$, show that $C$ is positive semidefinitive. I could prove it for some special cases, but the general case is not coming, any help is welcome. Thanks in advance.","['matrices', 'linear-algebra']"
457821,Is a flat morphism of complex algebraic varieties open in the analytic topology?,"Let $X,Y$ be algebraic varieties over $\mathbb{C}$ . A morphism $f:X\to Y$ induces a morphism $f^{an}:X^{an}\to Y^{an}$ between the associated complex analytic spaces (actually, I am interested only in the topological aspects). There are a lot of results relating the properties of $X,Y,f$ and those of $X^{an},Y^{an},f^{an}$ , known collectively as GAGA. I am interested in the following: If $f$ is flat, does it follow that $f^{an}$ is open? It is known that if $f$ if flat then it is open in the Zariski topology. A similar looking ""dual"" statement that I am aware of is that if $f$ is proper, then $f^{an}$ is proper in the topological sense and in particular closed. In general, I would like to know sufficient conditions on $f$ , for $f^{an}$ to be open. Edit: This is not stated or proved in Serre's GAGA (at least not explicitly). I did read somewhere that it is true, but without a proof or reference to one.","['analytic-geometry', 'algebraic-geometry']"
457825,Problem checking that a fuction verifies the Laplace equation.,"I'm having trouble solving an excersive from a past final that goes like this: Prove that if $u(x,y) \in \mathbb{C}^2$ satisfies $u_{xx} + u_{yy} = 0$ in $\mathbb{R}² - \{(0,0)\} $ then $v(x,y) = u( \frac{x}{x² + y²} ; \frac{y}{x²+y²})$ also satisfies it. Here's what I did: Let $ \alpha (x,y) = ( \frac{x}{x² + y²} , \frac{y}{x²+y²}) $, so $ \frac{\partial v}{\partial x} = \frac{\partial u}{\partial x} ({\alpha(x,y)}) \frac{\partial \alpha_1}{\partial x} + \frac{\partial u}{\partial y} ({\alpha(x,y)}) \frac{\partial \alpha_2}{\partial x}$ $ \frac{\partial² v}{\partial x²} = \frac{\partial^2 u}{\partial x²} ({\alpha(x,y)}) \frac{\partial \alpha_1}{\partial x} + \frac{\partial u}{\partial x} ({\alpha(x,y)}) \frac{\partial² \alpha_1}{\partial x²} + \frac{\partial^2 u}{\partial xy} ({\alpha(x,y)}) \frac{\partial \alpha_2}{\partial x} + \frac{\partial u}{\partial y} ({\alpha(x,y)}) \frac{\partial² \alpha_2}{\partial x²}$ Likewise for $y$. I did all the operations and went for $ \frac{\partial² v}{\partial x²} + \frac{\partial² v}{\partial y²} $ but couldn't actually make it equal to $0$, so I'm wondering if this is actually the right way to go. Thanks in advance for any help.","['multivariable-calculus', 'ordinary-differential-equations', 'calculus']"
457835,Non-rigorous (maybe a good pop-math) book about real analysis?,"I am reading a real analysis book at the moment, but I feel the lack of something I believe that could be a good feature: Historical remarks about the concepts and also some chat about how those concepts are interconnected. I'm self-studying and most of the time I don't have someone to talk about those concepts - I would like to read some insights about the introduced concepts. The only book I know that is similar to what I'm look is Analysis by Its history . Are there more books such as this one? I'm reading Derbyshire's Unknown Quantity - for example. It would be nice to have a resource that talks about the concepts in analysis such as this book. I'm not looking specifically for a textbook on real analysis, it could be a non-serious book to be read together with a textbook. It's nice to have an idea of how the things are interconnected without spending hours trying to grasp the precise meaning of the concept.","['book-recommendation', 'reference-request', 'real-analysis']"
457845,Propagation of Error,"If I have a function $$f(x,y)=\sqrt{x^2+y^2}$$ with error in $x$ be $\Delta x$ and error in $y$ be $\Delta y$, then how do we calculate ${\Delta f}$? I know if we have $$f(x)=x^n$$, then I at least that $\frac{\Delta f}{f}=|n|\frac{\Delta x}{x}$. I have no idea how to proceed.","['statistics', 'error-propagation']"
457858,"Polynomials dense in $C^\infty(U, V)$?","Let $V$ be a Banach space and $U$ an open subset of $\mathbb{R}^n$. Let $C^\infty(U, V)$ denote the Fréchet space of $V$-valued smooth functions on $U$ with seminorms
$$ \| u\|_{\alpha,K} = \sup_{y \in K} | D^\alpha u(y)|$$
for each compact subset $K$ of $U$. My question is: Are polynomials (or analytic functions) with values in $V$ dense in this space? I could not find a definite answer so far...","['functional-analysis', 'polynomials']"
457864,Textbooks with exposition done mostly in proof outlines or exercises?,"As the title indicates, I'm trying to find books where the exposition of the main course of thought is done entirely or mostly in outlines of proofs, or as exercises with or without hints. I'm trying to force my reading to be more ""active"", and I think that such a book would be good training-wheels. No particular topics, but preferably something on the introductory level. I'm particularly interested in basic Differential Geometry and/or Algebraic Topology related topics right now. (I have ""undergraduate level"" background in Real Analysis, Abstract Algebra, Linear Algebra and General Topology, and I'm trying to get started with Algebraic Topology and Differential Geometry for my own personal and educational enrichment.) Texts on other topics would be welcome for later reference. Much thanks.","['geometry', 'differential-geometry', 'algebraic-topology', 'reference-request', 'differential-topology']"
457877,Rounding number nearest 0.05,"I have question about rounding and please help me, suppose that question is round given number nearest 0.01 or 0.1 or 0.05 or maybe nearest 0.5, then what could i do? For example we are given some rational value 0.16 or 0.167, how could I round it to nearest 0.05? What is required I could not understand well. My attempt is following if we have data like 2.65, because after point first number is greater then 5(also it could be equal to 5), then nearest to 0.1, this number is equal to 3, but what about number 0.16 rounded to nearest 0.05 or 0.01?  Please help me.",['algebra-precalculus']
457878,To prove the equivalence definition of Riemann integral.,"I have some trouble with the Riemann integral, specifically, the definition of it in an article on wikipedia. We say that the Riemann integral of $f$ equals s if the following condition holds: For a given $\varepsilon>0$, there exists $\delta$ such that for any tagged partition $x_0,\cdots,x_n$ and $t_0,\cdots,t_{n-1}$ whose mesh is less than $\delta$, we have
$$\left|\sum_{i=0}^{n-1}f(t_i)(x_{i+1}-x_i)-s\right|<\varepsilon.$$ Unfortunately, this definition is very difficult to use. It would help to develop an equivalent definition of the Riemann integral which is easier to work with. We develop this definition now, with a proof of equivalence following .(?) Our new definition says that the Riemann integral of f equals s if the following condition holds: For all $\varepsilon>0$, there exists a tagged partition $x_0,\cdots,x_n$ and $t_0,\cdots,t_{n-1}$ such that for any refinement $y_0,\cdots,y_m$ and $s_0,\cdots,s_{m-1}$ of $x_0,\cdots,x_n$ and $t_0,\cdots,t_{n-1}$, we have
$$\left|\sum_{i=0}^{m-1}f(s_i)(y_{i+1}-y_i)-s\right|<\varepsilon.$$ It is easy to show that the first definition implies the second. To show that the second definition implies the first, it is easiest to use the Darboux integral. First one shows that the second definition is equivalent to the definition of the Darboux integral; for this I want you to give me some hints . However, I know that it is also easy to show that a Darboux integrable function satisfies the first definition. The original article says that the second definition is equivalent to the definition of the Darboux integral; for this see the article on Darboux integration . Well, I couldn't find anything useful information.","['riemann-sum', 'real-analysis']"
457903,Newton's method in higher dimensions explained,"I'm studying about Newton's method and I get the single dimension case perfectly, but the multidimensional version makes me ask question... In Wikipedia Newton's method in higher dimensions is defined as: $$\textbf{x}_{n+1} = \textbf{x}_n - [Hf(\textbf{x}_n)]^{-1}\nabla f(\textbf{x}_n), \;\;\; n \geq 0.$$ Where $\textbf{x}_n$ is the $p$-dimensional vector at $n$th iteration, $[Hf(\textbf{x}_n)]^{-1}$ is the inverse of the Hessian matrix of the function $f(\textbf{x})$ at $\textbf{x}_n$ and $\nabla f(\textbf{x}_n)$ is the gradient of the function $f(\textbf{x})$ at $\textbf{x}_n$. That is: $$\left( \begin{array}{c}
x_1^{(n+1)}  \\
x_2^{(n+1)}  \\
\vdots \\
x_p^{(n+1)}  \end{array} \right) = \left( \begin{array}{c}
x_1^{(n)}  \\
x_2^{(n)}  \\
\vdots \\
x_p^{(n)}  \end{array} \right) - \left( \begin{array}{cccc}
\frac{\partial^2f}{\partial x_1^2}(\textbf{x}_n) & \dots & \dots &\frac{\partial^2f}{\partial x_p\partial x_1}(\textbf{x}_n)\\
\frac{\partial^2f}{\partial x_1\partial x_2}(\textbf{x}_n)  & \ddots & \vdots & \vdots\\
\vdots & \vdots & \vdots & \vdots\\
\frac{\partial^2f}{\partial x_1\partial x_p}(\textbf{x}_n) & \dots & \dots & \frac{\partial^2f}{\partial x_p^2}(\textbf{x}_n)  \end{array} \right)^{-1}\left( \begin{array}{c}
\frac{\partial f}{\partial x_1}(\textbf{x}_n)  \\
\frac{\partial f}{\partial x_2}(\textbf{x}_n)   \\
\vdots \\
\frac{\partial f}{\partial x_p}(\textbf{x}_n)   \end{array} \right)$$ Now my question is: ""What is the intuition behind this formula?"" This resembles somehow the gradient descent algorithm, but the inverse of the Hessian is like it came from the magician's hat :S Can somebody give me a similar kind of proof as is given here on the one-dimensional case: Why does Newton's method work? Why the Hessian? Why its inverse?! :) Intuition of the formula? Thank you for any help :) P.S. I here is the page I got the formula above: http://en.wikipedia.org/wiki/Newton%27s_method_in_optimization#Higher_dimensions Note also that in my notation the topscript in the $x_i$s doesn't mean exponent, it's just an iteration label...","['optimization', 'multivariable-calculus', 'calculus', 'linear-algebra', 'partial-derivative']"
457911,"Whether $(0,1)$ and $(0,1]$ are homeomorphic [duplicate]","This question already has answers here : Is there exist a homeomorphism between either pair of $(0,1),(0,1],[0,1]$ (3 answers) Closed 10 years ago . In connection with the question continuous onto map from $(0,1)\to (0,1]$ I would like to know whether $(0,1)$ and $(0,1]$ are homeomorphic. The map mentioned in the above question is onto but not a bijection. So does such a continuous bijection exist?",['general-topology']
457916,Prove approximation given by the physicist Max Born,"In an old book about optics, I have found a nice approximation, that for large l one has: $$P_l(\cos(\theta))  \sim \sqrt{\frac{2}{l \pi \sin(\theta)}} \sin \left((l+\frac{1}{2}) \theta + \frac{\pi}{4} \right)$$, where $P_l$ is the l-th Legendre polynomial. Unfortunately, I do not have any clue how to prove this, but maybe somebody here has an idea and an error approximation for this approximation? A reference would be sufficient too, of course.","['special-functions', 'calculus', 'approximation', 'real-analysis', 'analysis']"
457947,Definition of limit,"I learnt at school that this limit $\lim_{x\to 0}\frac{1}{x}$ doesn't exist, and intiuitively it seems that such is the case, but I just don't get it. To begin with, I understand the definition of limit in this way, please tell me where I'm wrong or if I'm missing something: Let $A, B\subseteq \mathbb{R}$ and $f:A\longrightarrow B$ a function such that $a\in A$ is an acummulation point. Then we say that $l\in B$ is the limit of the function $f$ when $x$ approches $a$ and is denoted by $\lim_{x\to a}f=l$ if and only if $\forall \epsilon\in \mathbb{R}(\epsilon>0)\exists\delta\in \mathbb{R}(\delta >0)\forall x\in A(0<|x-a|<\delta\longrightarrow |f(x)-l|<\epsilon)$. So, accordingly, I have the function $f:\mathbb{R}\setminus\{0\}\longrightarrow\mathbb{R}$ such that $f(x)=\frac{1}{x}$. Since $0\notin Dom (f)$ then it doesn't even make sense to talk about the definition of $\lim_{x\to 0}\frac{1}{x}$. Also I think that I probably need to change in my definition the part of $(\forall x\in A)$ for $(\forall x\in \mathbb{R})$. This is consistent because if my metric spaces were not subsets of $\mathbb{R}$, for example if I had $E_{1}, E_{2}$ metric spaces and $A\subseteq E_{1}, B\subseteq E_{2}$ such that $f:A\longrightarrow B$. For the part $|x-a|<\delta$ to make sense it's necessary that $x\in A$ or $x\in E_{1}$. The problem here is that taking $(\forall x\in E_{1})$ might turn undefined many points of the part $|f(x)-l|$ because it might be that $A\subseteq E_{1}$ but $A\neq E_{1}$. Edit: With all the suggestions - thank you so much guys - my new definition is this way: Let $A, B\subseteq \mathbb{R}$ and $f:A\longrightarrow B$ a function such that $a\in \mathbb{R}$ is an acummulation point of $A$. Then we say that $l\in \mathbb{R}$ is the limit of the function $f$ when $x$ approches $a$ and is denoted by $\lim_{x\to a}f=l$ if and only if $\forall \epsilon\in \mathbb{R}(\epsilon>0)\exists\delta\in \mathbb{R}(\delta >0)\forall x\in A(0<|x-a|<\delta\longrightarrow |f(x)-l|<\epsilon)$. Now, I have this problem. With this definition I can prove that given the function $f:\mathbb{R^{+}}\longrightarrow \mathbb{R}$ such that $f(x)=\sqrt{x}$, then $\lim_{x\to 0}\sqrt{x}=0$. But officially this limit doesn't exist, though $\lim_{x\to 0^{+}}\sqrt{x}=0$. If I substitute $\forall x\in A$ for $\forall x\in \mathbb{R}$ then the problem seems to be fixed. But now this doesn't allow to talk about rational functions, like for example if I take the function $f:\mathbb{Q}\longrightarrow \mathbb{R}$ such that $f(x)=x$ then $\lim_{x\to 0}f(x)$ doesn't exist. What am I missing?","['calculus', 'real-analysis']"
457968,What is the probability that the sum of two random numbers is less than a given number?,"Let us assume a pure random number generator generates a random number between the given range $[0,m]$ with equal probability. Given $m_1$, let it generate a random number($r_1$) in the range $[0,m_1]$.
Given $m_2$, let it generate a random number($r_2$) in the range $[0,m_2]$. Now what is the probability that $r_1 + r_2 < K$ ( another number)? How can I calculate this probability?",['probability']
457977,"Integrating $\int_0^\infty \frac{\log x}{(1+x)^3}\,\operatorname d\!x$ using residues","I am trying to use residues to compute $$\int_0^\infty\frac{\log x}{(1+x)^3}\,\operatorname d\!x.$$My first attempt involved trying to take a circular contour with the branch cut being the positive real axis, but this ended up cancelling off the term I wanted. I wasn't sure if there was another contour I should use. I also had someone suggest using the substitution $x=e^z$, so the integral becomes $$\int_{-\infty}^\infty\frac{ze^z}{(1+e^z)^3}\,\operatorname d\!z$$so that the poles are the at the odd multiples of $i\pi$. I haven't actually worked this out, but it does not seem like the solution the author was looking for (this question comes from an old preliminary exam). Any suggestions on how to integrate?","['residue-calculus', 'calculus', 'integration', 'complex-analysis', 'contour-integration']"
457990,Whats wrong with this proof?,"Theorem: $x$ is a real number with $x \neq 1.$ If $\frac {x^2+1}{x-1} =x$, then $x=-1$. If we suppose that $x=-1$. Then $\frac {x^2+1}{x-1} = \frac {(-1)^2+1}{-1-1} = \frac {2}{-2} = -1 = x$ I would say that the prove is not correct in the second step when we have $(-1)^2$, but I am not completely sure. I appreciate your answer!!!",['algebra-precalculus']
458002,Simplify $(xy^{-1})/(y^2/x^3)^{-1}$,Need to simplify this equation: $$(xy^{-1})/(y^2/x^3)^{-1}$$ So far I have $= \frac{x/y}{1/(y^2/x^3)}$ But don't know what to do next. Any help much appreciated,['algebra-precalculus']
458005,"Prove that $f$ is Injective and Surjective: $f:N\times N \rightarrow N :f(m,n)= 2^{m-1}(2n-1)$","I`m trying to prove that $f$ is Injective and Surjective
$$f:N\times N \rightarrow N :f(m,n)= 2^{m-1}(2n-1)$$
what I did so far is to set $m_{1},m_{2},n_{1},n_{2}$ so by definition of injective function if $f(x1)=f(x2) \rightarrow x1=x2$ $$2^{m_1-1}(2n_1-1)=2^{m_2-1}(2n_2-1)$$
$$2^{m_1}(2n_1-1)=2^{m_2}(2n_2-1)$$
from here, if $n_1=n_2$ so $m_1=m_2$ and its enough right? I would like to get some advice how to do that, I dont know if I did right. Thanks!",['discrete-mathematics']
458017,When is Jacobian invertible?,"Let $(f,U)$ be a chart on $M$ a smooth $n$-manifold. I know the inverse function theorem by which $f$ is invertible on $U$ iff its Jacobian is. What about the other direction? Is there any theorem about conditions under which the Jabobian of a map $f$ is going to be invertible?","['multivariable-calculus', 'differential-geometry']"
458046,p-adic expansion of a rational number,"Studying $p$-adic numbers I encountered the following theorem: Given a eventually periodic sequence $(a_n)_{n=k}^{\infty}$ such that $0 \le a_n <p$, the sum
\begin{equation*}
\sum_{n=k}^{\infty}a_np^n
\end{equation*}
converges p-adically to a rational number. The proof of this fact consists mainly in rearranging the sum. Here is my problem... In all the books I have seen this is not justified. Only some authors prove a theorem about rearrangement, but in other parts of their books and seems we don't need it here. Why I can rearrange the terms of this sum? Why I don't need any theorem? Thank you all!","['sequences-and-series', 'p-adic-number-theory', 'number-theory']"
458047,The free group II$_{\infty}$ factor isomorphism problem,"Let $\Gamma$ be an infinite discrete group, and $H = l^{2}(\Gamma)$ the separable infinite dimensional Hilbert space. Let $\rho$ be the left regular representation of $\Gamma$ on $H$. Definition : Let $L(\Gamma) := \rho (\Gamma)''$ the von Neumann algebra generated by $\Gamma$. Proposition :  $L(\Gamma)$ is a $II_{1}$ factor iff $\Gamma$ is ICC (infinite conjugacy class). Let $\Gamma = \mathbb{F}_{n} = \langle a_{1}, a_{2},..., a_{n} \vert   \rangle$  the free group with $n$ generator. It's ICC iff $n \geq 2$. Free group factor isomorphism problem : $L(\mathbb{F}_{n}) ≃ L(\mathbb{F}_{m})$, $∀n,m≥2$ ? Voiculescu's formula (see here p 3) :  $L(\mathbb{F}_{n}) \simeq L(\mathbb{F}_{(n-1)k^{2}+1}) \otimes M_{k}(\mathbb{C})$ Example :  $L(\mathbb{F}_{2}) \simeq L(\mathbb{F}_{5}) \otimes M_{2}(\mathbb{C})$ Corollary : $\bigotimes_{i} L(\mathbb{F}_{n_{i}})   \simeq \bigotimes_{i} L(\mathbb{F}_{m_{i}})$ if $\prod_{i}(n_{i}-1) = \prod_{i}(m_{i}-1)$ Observation : $L(\mathbb{F}_{n}) \otimes B(H) \simeq L(\mathbb{F}_{(n-1)k^{2}+1}) \otimes M_{k}(\mathbb{C}) \otimes B(H) \simeq L(\mathbb{F}_{(n-1)k^{2}+1})  \otimes B(H)$ However, ""$\exists k_{1}, k_{2} $ : $(n-1)k_{1}^{2}+1 = (m-1)k_{2}^{2}+1$"" $\Leftrightarrow$  ""$(n-1)(m-1)$ is a square"". Corollary : $L(\mathbb{F}_{n}) \otimes B(H) \simeq  L(\mathbb{F}_{m}) \otimes B(H)$   if $(n-1)(m-1)$ is a square . Question :  Is it known to be true in general : $L(\mathbb{F}_{n}) \otimes B(H) \simeq  L(\mathbb{F}_{m}) \otimes
 B(H)$ $\forall n, m \ge 2$ ? (if ""no"", is it equivalent to the free group factor isomorphism problem ?) In general :  $L(\mathbb{F}_{n}) \simeq L(\mathbb{F}_{m})^{\alpha} $ with  $\alpha = (\frac{m-1}{n-1})^{1/2}$. Definition : Let $\mathcal{M}$ be a $II_{1}$ factor, then $\mathcal{M}^{t} \simeq p(M_{k}(\mathbb{C}) \otimes  \mathcal{M})p \simeq q(B(H) \otimes  \mathcal{M})q$, with $q \in B(H) \otimes  \mathcal{M}$ and $p \in M_{k}(\mathbb{C}) \otimes  \mathcal{M}$ projections, $Tr(q) = t$,  $k=\lceil t \rceil$ and $\tau(p) = \frac{t}{k}$. Remark : Let $n, m \ge 2$ such that $(n-1)(m-1)$ is a square. Let the $II_{\infty}$ factor $\mathcal{N} \simeq  L(\mathbb{F}_{n}) \otimes B(H) \simeq  L(\mathbb{F}_{m}) \otimes B(H)$. Let $Tr$ (resp. $Tr'$) be the trace on $\mathcal{N}_{+}$ coming from the unique trace of $L(\mathbb{F}_{n})$ (resp. $L(\mathbb{F}_{m})$). Let the projection $p, q \in \mathcal{N}$ such that $Tr(p) = Tr'(q) = 1$. Then  $p \mathcal{N} p \simeq L(\mathbb{F}_{n})$ and $q \mathcal{N} q \simeq L(\mathbb{F}_{m})$. So, $Tr' = \alpha Tr$ with  $\alpha = (\frac{n-1}{m-1})^{1/2}$.","['operator-algebras', 'reference-request', 'von-neumann-algebras', 'functional-analysis']"
458056,"5 cars, 4 parking places. Derangements and permutations with fixed points","I found an exercise in combinatorics: In the parking of a building, there a re five parking spots, with their owner cars assigned
  to them. One day only four cars arrived. In how many ways can they park so that not one cars 
  parks on their corresponding spot? So I think the following way: consider the missing car. It may arrive and park on its own parking spot, there are $5\cdot D_4$ ways of doing that, where $D_n$ is the number of derangements of $n$-element set, or it may arrive and find that his place is already taken. Then it takes someone other's place, thus making a complete derangement of 5 element set. So the total number is $5\cdot D_4+D_5$. Am I thinking correctly? The real problem I have with this is that I found it in some early pop-quiz some teacher gave during the introduction to probability class. Isn't there an easier way?","['derangements', 'permutations', 'probability', 'combinatorics']"
458071,"If $f$ is an entire function with $|f(z)|\le 100\log|z|$ and $f(i)=2i$, what is $f(1)$?","Let $f$ be an entire function with $|f(z)|\le 100\log|z|,\forall |z|\ge 2,f(i)=2i, \text{ Then} f(1)=?$ I have no idea how to solve this one! $g(z)={f(z)\over \log|z|}$ Then Can I say $g$ is constant by Liouville Theorem?",['complex-analysis']
458090,Calculating limits using the $\epsilon$-$\delta$ definition.,Suppose you have a function $f(x)=\frac{x^2-4}{x-2}$ . How then do we find the limit as $x\to2$ in accordance with the $\epsilon-\delta$ definition? I mean suppose we don't know how to calculate the limit and we have to derive a method to calculate the limit using $\epsilon-\delta$ definition of limit. Then what intuition will be used to derive it and what will be the value?,"['real-analysis', 'limits']"
458102,Diffeomorphism of $\mathbb{C}P^1$ and $S^2$.,"In an exercise I am asked to find a (smooth) submersion of $S^3$ onto the sphere $S^2$. So far I have a submersion of $S^3$ onto $\mathbb{C}P^1$. Are $\mathbb{C}P^1$ and $S^2$ diffeomorphic? If so, how does one construct a diffeomorphism between the two and what is the geometric intuition behind the construction? Thank you.","['manifolds', 'differential-geometry']"
458103,"Nested roots sequence, how to prove it's monotone and bounded?","Let $a\ge1$ and define the sequence $(x_n)$ recursively by: $$x_1 = \sqrt{a}$$ $$x_{n+1}= \sqrt{a+x_n}$$ Here's what I did: Plugging in some values makes it seem as if the sequence is increasing. I first solve the equation $t=\sqrt{a+t}$ , equivalently $t^2 -t -a =0$ , to get an idea what's going on. The roots are $$t_{1,2}= \frac{1 \pm \sqrt{1+4a} }{2}.$$ Therefore, between the roots, that is for $$t\in \left( \frac{1 - \sqrt{1+4a} }{2}, \frac{1 + \sqrt{1+4a} }{2}\right)$$ we have $t^2-t-a \le 0 \iff t \le \sqrt{a+t}$ . Here's my attempt at showing inductively that $$\forall n\in \mathbb{N}, \ x_n \le \frac{1 + \sqrt{1+4a} }{2}$$ For $n=1$ , the statement is true (simple arithmetic). Suppose it's true for $n$ . Consider $$x_{n+1}= \sqrt{a+x_n}\le \sqrt{a+\frac{1 + \sqrt{1+4a} }{2}}=\frac{1 + \sqrt{1+4a} }{2},$$ because $\frac{1 + \sqrt{1+4a} }{2}$ satisfies $x=\sqrt{x+a}$ . So this establishes the sequence $(x_n)$ is bounded. Now, by induction again, I try to show it's monotonically increasing. The base case $x_1\le x_2$ is obvious. Assume (strong induction) $x_{n-1}\le x_n$ for all $n>1$ . But since we have $$x_1\le x_n \le \frac{1 + \sqrt{1+4a} }{2}, $$ then $x_n$ lies in the appropriate interval, so $x_n \le \sqrt{a+x_n}=x_{n+1}.$ Is this proof correct? Can the condition on $a$ be relaxed to $a>0$ ? Maybe even small negative $a$ ? And could someone provide me with another proof of convergence of $x_n$ ? I absolutely hate this one!","['recurrence-relations', 'sequences-and-series', 'proof-verification', 'real-analysis']"
458105,Constructing a non-linear system with prerequisites about the nature of its critical points.,"An exercise from the book I am reading is: ""Construct a non-linear system that has four critical points:two saddle points, one stable focus, and one unstable focus."" I have tried many systems. I found one quickly but I was lucky even if I had a few clues thanks my previous trials. I wonder if there is any way to find such systems using a not completely ""gropingly way"". Edit: with only two equations in the system. The system I have is: $\dot{x}=y^2-x^2$ $\dot{y}=x^2+y^2-2$","['dynamical-systems', 'linear-algebra', 'self-learning', 'ordinary-differential-equations']"
458108,On the ineptitude of the Lie derivative to define directional derivatives,"I'm stuck at question 4-3. from John Lee's Riemannian Manifolds : There exists a vector field on $\Bbb R^2$ that vanishes along the $x_1$-axis, but
  whose Lie derivative with respect to $∂_1$ does not vanish on the $x_1$-axis. Defining: $v=a \partial_1+b \partial_2$ with $a,b \in C^\infty(\Bbb R^2)$ such that $a(x,0)=b(x,0)=0$, the Lie derivative should be: $$\mathcal L_{\partial_1}(v)=[\partial_1,v]=\partial_1 v - v \partial_1= \partial_1 a \partial_1+\partial_1 b \partial_2 - a \partial_1^2-b \partial_2 \partial_1=\frac{\partial a}{\partial x_1}\partial_1+\frac{\partial b}{\partial x_1}\partial_2$$ But now, at the point $p=(x,0)$
$$\mathcal L_{\partial_1}(v)(p)=\frac{\partial a}{\partial x_1}|_p\partial_1+\frac{\partial b}{\partial x_1}|_p\partial_2$$ would have to be $0$, because the vanishing of $a$ and $b$ on the $x_1$-axis implies the vanishing of $\partial_1 a$ and $\partial_1 b$ along the $x_1$-axis. Where's the error in my above reasoning?","['riemannian-geometry', 'vector-fields', 'differential-geometry']"
458145,Solve for $\theta$ in $2\sec^2θ-4 =0$,Solve for $\theta$ in $2\sec^2θ-4 =0$ I have gotten toward $\sec^2θ=2$ Then $\dfrac{1}{\cos^2θ} = 2$ What is the next step to this problem?,['trigonometry']
458154,What maths is being used to calculate this interest?,"I'm curious about how my bank is calculating the interest on my credit card. No matter what I do, I cannot make the numbers add up! Below is a photo of my latest statement. It's for 13th June - 12th July. There were no purchases, but an opening balance of £907.19, and a payment of £9.07  on 8th July. The statement says that interest for my entire balance (all purchases) is ""0.026% per day (9.95% APR)"". The statement clearly says on the back that interest is calculated daily. So, I took the opening balance and added 0.026% per day, then subtracted £9.07 on 8th July, then continued adding 0.026% per day, until 12th July. I ended up with a closing balance of £904.98 (theirs is £906.73). I've subsequently tried all sorts of different calculations, and cannot come to their figure without increasing the rate quite a bit. Even if I round up every days value to the nearest penny, I only get £905.32. So; how are they calculating this? Or is their maths wrong and I'm being charged higher than the rate being claimed? -- Update: 03/08/2013 -- Spoke to someone at my banks credit card department today. She didn't really seem to understand the maths. When I told her I'd multiplied by 1.00026^30 she asked where there was a 1! She did, however, say: Yearly rate: 9.95% Monthly rate: 0.793% (this wasn't on the bill) Daily rate: 0.026% Interest is calculated daily The interest period was 29 days (though this makes the numbers slightly further out, not closer!) However, this good information (well, confirmation of what I had) was somewhat undermined when she said ""Some interest will be calculated from the opening balance (£907.19) and some from the closing balance (£906.73). This doesn't really make sense (how can you calculate interest using a figure that is derived from the interest?!). So said she'd have to pass the info on to their ""back office"" who can send me a full breakdown. I look forward to receiving it! :-/",['algebra-precalculus']
458179,Prove with Induction for $n\in \mathbb{N}$ and $n$ is even for $1^2-3^2+5^2-7^2+\dots+(2n-3)^2-(2n-1)^2=-2n^2 $,"I want to prove by indection, for $n\in\mathbb N$ even: $$1^2-3^2+5^2-7^2+\dots+(2n-3)^2-(2n-1)^2=-2n^2 $$ what I did first is to check the numbers, so if $n$ is even lets take $n=2$ so $(2\cdot 2-3)^2-(2\cdot 2-1)^2=-2\cdot 4$ lets take $n=4$ so $(2\cdot 4-3)^2-(2\cdot 4-1)^2\neq-2\cdot 16$ I did something wrong? Thanks!","['induction', 'discrete-mathematics']"
458189,why geometric multiplicity is bounded by algebraic multiplicity?,"Define The algebraic multiplicity of $\lambda_{i}$ to be the degree of the root $\lambda_i$ in the polynomial $\det(A-\lambda I)$ . The geometric multiplicity the be the dimension of the eigenspace associated with the eigenvalue $\lambda_i$ . For example: $\begin{bmatrix}1&1\\0&1\end{bmatrix}$ has root $1$ with algebraic multiplicity $2$ , but the geometric multiplicity $1$ . My Question : Why is the geometric multiplicity always bounded by algebraic multiplicity? Thanks.","['matrices', 'linear-algebra']"
458191,Use triple integrals to find the volume of...,"The solid enclosed by the parabaloid $$x=y^2+z^2$$ and the plane $$x=6$$ I wanted to make sure that I'm setting up the correct integral before I start to integrate it. $$\int_{-\sqrt{6}}^{\sqrt{6}}\int_{-\sqrt{6-y^2}}^{\sqrt{6-y^2}}\int_{y^2+z^2}^6dxdydz$$ If this is incorrect, would someone be able to help guide me in the right direction?","['multivariable-calculus', 'integration']"
458211,Salvaging a damaged cable,"Let's say we have a cable of unit length, which is damaged at one unknown point, the location of which is uniformly distributed. You are allowed to cut the cable at any point, and after a cut, you'd know which piece is damaged and which is not. You can do this as many times as you want, and you want to maximize the expected length of the biggest undamaged piece after all the cutting. What is the best you can do? The strategy need not be deterministic. I currently have a lower bound of $\frac12$ and upper bound of $\frac34$. The lower bound comes from just cutting the cable in half once. For the upper bound, notice that if the fault is at $\frac12 \pm x$, then you cannot do better than $\frac12 +x$. So taking the expected value,
$$ \int_0^{\frac12} \left(\frac12+x\right)2 dx = \frac34$$ I initially thought that an optimal strategy would have to be applied recursively to the damaged piece, but now I'm no longer convinced of this. If you've already obtained an undamaged piece of length $l$, then there is no point in cutting a damaged piece into two pieces of length $\leq l$. Any reference to an existing treatment is also welcome.","['game-theory', 'probability']"
458212,A weak version of Brouwer's Theorem,Let $A : \Bbb{R}^n\longrightarrow \Bbb{R}^n$ be an affine map and let $X\subseteq \Bbb{R}^n$ be a compact convex set which is invariant under $A$. I want to show that $A$ has a fixed point in $X$. REMARK Of course this can be done using Brouwer's Theorem. But I am looking for elementary proofs.,"['general-topology', 'geometry']"
458221,A little fun with tournaments (graphs).,"Assume $G$ is a tournament , i.e. a (finite) directed graph such that between any two vertices, $a$ and $b$, there is at least one edge in one of the two directions, $a\rightarrow b$ or $b\rightarrow a$. Show that there is at least one Hamiltonian path , i.e. a path, following the direction of the edges and visiting all vertices exactly once. (This part is a classical exercise and it is here to prepare for the second part of the problem). Consider all possible losers, i.e. the set of all vertices that can be end-points of Hamiltonian paths of the tournament, see Part (1). Show that the subgraph of all losers has a Hamiltonian cycle , i.e. a cycle that follows the direction of the edges and passes through every vertex exactly once and returns to the initial vertex. For example these are all tournaments and the $\color{red}{\text{red}}$ dots are the losers. Notice how there is always a cycle joining them.","['graph-theory', 'discrete-mathematics']"
458230,Continuity of $L^1$ functions with respect to translation,"Let $f\in L^1$, consider the map $t\mapsto f_t=f(x-t)$, then how can one show that $t\mapsto f_t$ is continuous? More explicitly one wants to show that $\lim_{h\to 0}|f_{t+h}-f_t|_{L^1}=0$. I tried to use approximation by $C_0(\mathbb{R})$ functions $g^n$ to approximate $f$ in $L^1$ norm. Then one has $\lim_{h\to 0}|g^n_{t+h}-g^n_t|_{L^1}=0$, but then I came across the problem: how can one show that the two limits can exchange so that one has $$\lim_{h\to 0}|f_{t+h}-f_t|_{L^1}=\lim_{h\to 0}\lim_{n\to\infty}|g^n_{t+h}-g^n_t|_{L^1}=\lim_{n\to\infty}\lim_{h\to 0}|g^n_{t+h}-g^n_t|_{L^1}=0.$$ Can someone help me with some conditions on which two limits can be exchanged, or do you have a better way of proving the continuity? Thank you!","['measure-theory', 'continuity', 'real-analysis', 'lebesgue-integral', 'limits']"
458238,Fractions in Ancient Egypt,"In ancient Egypt, fractions were written as sums of fractions with numerator 1. For instance,$ \frac{3}{5}=\frac{1}{2}+\frac{1}{10}$. Consider the following algorithm for writing a fraction $\frac{m}{n}$ in this form$(1\leq m < n)$: write the fraction $\frac{1}{\lceil n/m\rceil}$ , calculate the fraction $\frac{m}{n}-\frac{1}{\lceil n/m \rceil}$ , and if it is nonzero repeat the same step. Prove that this algorithm always finishes in a finite number of steps. Note:if $ n\in \mathbf{Z} $ and $n-1<x\leq n ,  \lceil x\rceil=n$","['egyptian-fractions', 'discrete-mathematics', 'problem-solving']"
458239,"Let $G$ be a finite p-primary abelian group. If a is an element of largest order in G, then $A= \langle a \rangle$ is a direct summand of G.","I was trying to read the proof from Advanced Modern Algebra (Rotman), but there was something that seemed confusing to me. It's only the last part that's confusing, but I put the whole proof anyway. I'm not sure if I understood ""$A \cap B \subseteq A \cap ((A + C') \cap B) \subseteq A \cap C' = \{0\}$"". Normally, I would think that for any two sets $A$ and $B$, $A \cap B \subseteq A$ and $A \cap B \subseteq B$, because intersection can only make a set smaller (or equal to) but not bigger, right? But here it seems (at least to me) to go backwards. We need to assume that $B \subseteq (A+C') \cap B$. I don't understand $A \cap ((A + C') \cap B) \subseteq A \cap C' = \{0\}$ either. Here, we have to assume that $(A+C') \cap B \subseteq C'$. However, we know that the intersection $(A+C') \cap B$ for sure contains $C'$ since $C' \subseteq A+C'$ and $C' \subseteq B$. So it can only be greater than or equal to $C'$, right? Thank you in advance","['abelian-groups', 'abstract-algebra', 'finite-groups', 'proof-explanation', 'group-theory']"
458253,associated haar measure of dual group of a product,"Let $G_1$ and $G_2$ be locally compact abelian groups equipped with Haar measure $\mu_{G_1}$, $\mu_{G_2}$ and $G=G_1 \times G_2$ equipped with $\mu_{G_1} \otimes \mu_{G_2}$. I would like to show that the associated Haar measure on $\hat{G}=\hat{G_1} \times \hat{G_2}$ is the product $\mu_{\hat{G_1}} \otimes \mu_{\hat{G_2}}$of the associated Haar measures. Let $f_1\colon G_1\to\mathbb{C}$ and $f_2\colon G_2 \to \mathbb{C}$ be continuous functions with compact support and $f\colon G \to \mathbb{C}$ defined by $(x_1,x_2)\mapsto f_1(x_1)f_2(x_2)$. I proved that
$$
\int_{\widehat{G}}|\mathcal{F}f(\chi_1,\chi_2)|^2d\mu_{\widehat{G}}(\chi_1,\chi_2)=\int_{\widehat{G_1} \times \widehat{G_2}} |\mathcal{F}f(\chi_1,\chi_2)|^2 \ d(\mu_{\widehat{G_1}}\otimes \mu_{\widehat{G_2}})(\chi_1,\chi_2).
$$ How to complete the proof?","['fourier-analysis', 'group-theory']"
458257,Visualization of the diffeomorphism!,"Basic to all mathematics is the notion-here used quite informally-of a
  set with structure. For every type of structure there is a notion of equivalence
  (or isomorphism)-a one-to-one onto function that, in an appropriate sense,
  preserves the structure. A particular type of structure defines a branch of
  mathematics: the study of those concepts preserved by equivalence. For
  example, a group is a set furnished with the structure group operation. The
  notion of equivalence is the usual notion of isomorphism of groups. (Semi-Riemannian geometry with applications to Relativity, by Barrett O’neill) Consider following table: I know if $f:X\to Y$ be a one-to-one onto function, then two sets $X$ and $Y$ have the same cardinality and it is sufficient for me to visualize the equivalence in this case. If $f:X\to Y$ be a homeomorphism, then one can deform the topological space $X$ to the topological space $Y$ without cutting and gluing, it is sufficient for me to visualize the equivalence in this case. If a coffee cup and a donut are given to me, I can realize from their shapes that they are homeomorphic. If $f:X\to Y$ be an isometry, then one can coincide the semi-riemannian manifold $X$ to the semi-riemannian manifold $Y$, it is sufficient for me to visualize the equivalence in this case. Question 1: Is the above statement true? Question 2: I have no idea to visualize the equivalence in the Manifold theory case, diffeomorphism. Can someone help me? Can I judge about the equivalence of the two manifolds from their shapes in this case? Thanks.","['differential-geometry', 'general-topology', 'manifolds', 'riemannian-geometry', 'visualization']"
458264,Dimension of $\mathbb{Q}\otimes_{\mathbb{Z}} \mathbb{Q}$ as a vector space over $\mathbb{Q}$,"The following problem was subject of examination that was taken place in June. The document is here . Problem 1 states: The tensor product $\mathbb{Q}\otimes_{\mathbb Z}\mathbb{Q}$ is a vector space
  over $\mathbb{Q}$ by multiplication in the left factor, i.e.
  $\lambda(x\otimes y)=(\lambda x)\otimes y$ for $\lambda, x,
 y\in\mathbb{Q}$. What is the dimension of
  $\mathbb{Q}\otimes_{\mathbb{Z}}\mathbb{Q}$ as a vector space over
  $\mathbb{Q}$? I only know the definition of tensor product for modules (via universal property). How does one go about calculating dimension of such a vector space? Thanks!","['vector-spaces', 'tensor-products', 'abstract-algebra']"
458275,A question concerning the indefinite integral of a function and the a.e. property,"$\textbf{Problem}$  Let $L=L(X,\textbf{X},\mu)$ denote the set of all integrable functions. Suppose that $f$ belongs to $L$ and that its indefinite integral is $$\lambda(E)=\int_{E} f d\mu,    E\in \textbf{X}.$$ Show that $\lambda(E)\geq 0$ for all $E\in\textbf{X}$ if and only if $f(x)\geq 0$ for almost all $x \in X$. $\textbf{Solution}$ Assume $f(x)\geq 0$ for almost all $x\in X$. Pick any set $E\in\textbf{X}$. There are two cases to consider. If $f(x)\geq 0$ for all $x\in E$, then $f^{+}\chi_{E} \geq f^{-}\chi_{E}$. Hence, $\int_{E} f^{+} d\mu \geq \int_{E} f^{-} d\mu$; therefore, $$\lambda(E)=\int_{E} f d\mu =\int_{E} f^{+} d\mu - \int_{E} f^{-} d\mu \geq 0.$$ If there exists an $x\in E$ such that $f(x)<0$ then because  $f(x)\geq 0$ for almost all $x\in X$, $E$ must have measure zero. Since, in this case,  both functions $f^{+}\chi_{E}$ and $f^{-}\chi_{E}$ would be $0$ almost everywhere, their integrals are zero. Thus, $\lambda(E)=\int_{E} f d\mu = 0$. I am having trouble proving the other direction. I want to pick any set $E$ in our $\sigma$-algebra X and show that 
(1) if $E$ does not have measure zero, then we must have $f(x)\geq 0$, and 
(2) if $E$ does have measure zero, then we cannot determine anything about $f(x)$. I think I got (2). I am just unsure about (1). A hint would be great! Thank you!","['lebesgue-integral', 'measure-theory']"
458286,Bridge HCP held by the best hand at the table?,"In the game of Bridge, what is the expected number of high card points held by the player holding the most high card points at the table? $A=4$, $K=3$, $Q=2$, $J=1$.","['probability', 'combinatorics']"
458289,"The ""depth"" of a set","I came to think about a subject which I'm almost sure has already be studied, but I would not know how to search for it. What I mean is the ""depth"" of a set. For finite depths (what that means will be clear in a moment), it is easy to define: The empty set has depth zero. A non-empty set has a depth of one more than the largest depth of its member sets. So for example, the set $\{\emptyset\}$ has depth $1$, the sets $\{\emptyset,\{\emptyset\}\}$ and $\{\{\emptyset\}\}$ have both depth $2$, and $\{\{\{\emptyset\}\},\{\emptyset\}\}$ has depth 3. Now it is obvious that this concept extends to infinite depths. For example, $\omega$ has infinite depth because it contains sets of any finite depth. Now it seems obvious that $\{\omega\}$ should have a larger depth because its element already has an infinite depth. So it may make sense that the possible depths are given by ordinal numbers (a nice side effect would be that each ordinal number would be its own depth). On the other hand, maybe it doesn't really make sense to make that distinction (just like $\omega$ and $\omega+1$ have the same cardinality). So maybe the depth should be measured by cardinal numbers instead. Or maybe the depths form their own class of numbers, distinct both from the class of cardinals and the class of ordinals? Clearly to make this decision, there needs to be a formal way to decide whether two sets have the same depth. I have no idea how to define it (except for finite depth by the explicit recursion), or if there can be a meaningful definition at all (besides the obvious choice to give all sets of infinite depth the same depth $\infty$). However if the depth can have a meaningful definition for infinite-depth sets, I'm sure this has already be done by someone (although quite possibly under another name; a web search for ""depth of sets"" didn't seem to find anything relevant). (PS: I have no idea which of the two ""set-theory"" tags is appropriate; I just assumed that if I can discover the concept without ever having had a course in set theory, it's probably elementary and thus chose that tag)",['elementary-set-theory']
458294,Fourier-Bessel series coefficients,"When finding the coefficients of a Fourier-Bessel series, the Bessel functions satisfies, for $k_1$and $k_2$ both zeroes of $J_n(t)$,  the orthogonality relation given by:
$$\int_0^1 J_n(k_1r)J_n(k_2r)rdr = 0, (k_1≠k_2)$$
and for $k_1 = k_2 = k$: $$\int_0^1 J_n^2(kr)rdr = \frac12J_n^{'2}(k)$$ I understand how to get the first result since the Bessel's equation can be interpreted as a Sturm-Liouville problem, but how can I show the second one?","['fourier-series', 'special-functions', 'integration']"
458307,Is this always true?,"Suppose $\left|x_{1}\right|\ge\left|x_{2}\right|\ge\left|x_{3}\right|$, $\left|y_{1}\right|\ge\left|y_{2}\right|\ge\left|y_{3}\right|$, and $$\left(x_{1}-y_{1}\right)\left(x_{2}-y_{2}\right)\left(x_{1}-y_{2}\right)\left(x_{2}-y_{1}\right)<0,$$
is it true that $$\sqrt{\left|t\right|}+\sqrt{\left|x_{1}+x_{2}+x_{3}-y_{1}-y_{2}-y_{3}-t\right|}\ge\left|\sqrt{\left|x_{1}\right|}-\sqrt{\left|y_{1}\right|}\right|+\left|\sqrt{\left|x_{2}\right|}-\sqrt{\left|y_{2}\right|}\right|+\left|\sqrt{\left|x_{3}\right|}-\sqrt{\left|y_{3}\right|}\right|$$
for any $t$?","['inequality', 'multivariable-calculus', 'calculus', 'real-analysis']"
458329,Determining similarity between paths (sets of ordered coordinates).,"With limited knowledge of mathematics, I am not sure what tags to use for this question. I have a path on a 2D surface called $(p1)$. A path consists of a set of ordered $(x,y)$ coordinates. By ordered I mean the first line segment in a path would be $(x1,y1) to (x2,y2)$, the second line segment would be $(x2,y2) to (x3,y3)$ and so on. So these ordered points create a shape and direction of travel similar to what you would see on top-down Google Maps view. I need to match this path $(p1)$ against some other arbitrary paths to determine which one is the closest to the original path $(p1)$ in terms of shape and direction of travel. The number of line segments making up each path could be arbitrary by the way so there needs to be a way of handling tolerance. Not sure what this is called but I have explored some LQE techniques such as the Kalman Filter in vain. What I am looking for is analysing a static set of ordered points against another rather than progressive prediction. I am not sure what constructs can represent similarity between paths. Any guidance would be highly appreciated.","['geometry', 'linear-algebra', 'trigonometry']"
458347,Hint on solving $ \frac{dx}{dt} = t - tx $,"Can you please give me a hint how to continue solving this differential equation? $$ \frac{dx}{dt} = t - tx $$ Rewriting yields $$ \frac{dx}{dt} + tx = t $$ Now I can use integrating factor $$ \mu = e^{\int t dt} = e^{t^2 / 2} $$ So I can multiply whole equation with $ \mu $ and integrate both sides $$ e^{t^2 / 2} x = \int te^{t^2 / 2}dt$$ To solve integral on r.h.s. I put $u = t$ and $\dfrac{dv}{dt} = e^{t^2 / 2}$, so
$\frac{du}{dt} = 1;\;\;v = \int e^{t^2 / 2} dt$. Now this second integral leads to substitution, let's put $z=t^2 / 2$, so $ \;\dfrac{dz}{dt} = t $. That is, $\; dt = \dfrac{dz}{t}.\;$ Putting back to integral yields $$ \int \frac{e^z}{t}dz $$ But i don't know how to solve this. I only went through examples, where substitution eliminated occurrence of original variable.",['ordinary-differential-equations']
458353,Derivative of Standard Normal Inverse,"How can I calculate the derivative of the standard normal inverse. I think the derivative of $\Phi^{-1}(x)$ is $$\frac{1}{\phi(\Phi^{-1}(x))}.$$ I would like to know how to find the derivative of $$\Phi^{-1} \left(\frac{x}{c}\right),$$ where $c$ is a known constant. Any help would be much appreciated.","['inverse', 'probability', 'derivatives']"
458364,Why is the sequential closure not sequentially closed?,"In my understanding, a sequentially closed subset $A\subset X$ of a topological space $X$ is one that contains every sequential limit point of itself, whereas the sequential closure of $A$ is defined as $[A]_{seq}=\{x\in X: \exists (x_n)\in A^{\mathbb{N}}: x_n\to x\}$. I think that the sequential closure need not be sequentially closed, because assuming to the contrary that every sequential closure was sequentially closed, I can construct the contradiction that every sequential space is a Frechet-Urysohn space as follows: Let $X$ be a sequential space. We must show $\overline{A}=[A]_{seq}$. ""$\overline{A}\subset[A]_{seq}$"": $[A]_{seq}$ is sequentially closed, thus closed since $X$ is sequential. Also $A\subset[A]_{seq}$ trivially. Hence $\overline{A}=\bigcap_{A\subset F\subset X closed}F \subset [A]_{seq}$. ""$\overline{A}\supset[A]_{seq}$"": This is true for every topological space (every limit of a sequence is part of the closure) Am I right? If yes, isn't the notation exceptionally inconvenient?",['general-topology']
458365,how does this translate to a circle with radius 5: $\sqrt{24-2x-x^2}$,"I tried squaring both sides to get this $y^2 = 24-2x-x^2$, then putting the $x$'s with the $y$'s to get $y^2 + x^2 + 2x = 24$. Then I tried dividing everything by 24, but I don't see it. Tried factoring too.",['algebra-precalculus']
458375,How to show that a limit cannot be another number?,"Let:
$$
G(x) = \left\{ \begin{array} {cc} x \sin \frac{1}{x} , & x\neq 0 \\
0, & x=0 \end{array} \right.
$$ I can understand that the function is continuous at $x=0$ because: For $\epsilon>0$ and $\delta>0$, this implies, for all $x$ $$
 |x-0|<\delta \implies |f(x)-0| < \epsilon \\
 |x|<\delta \implies |f(x)| < \epsilon \\
 |x|<\delta \implies |x\sin \frac{1}{x}| < \epsilon \\
|x|<\delta \implies |x||\sin \frac{1}{x}| < \epsilon \\
\therefore \delta = \frac{\epsilon}{\sin \frac{1}{x}}
$$ So, for any $\epsilon>0$, we can find a $\delta=\frac{\epsilon}{\sin \frac{1}{x}}$ so that $ |x-0|<\delta \implies |f(x)-0| < \epsilon$ is true. Hence, $\lim \limits_{x\to 0}G(x)=G(0)=0$ My text also mentions that $G$ will only be continuos at $0$ if $G(0)=0$. So now I am wondering why can't it be any number, $l$? So far here is what I have come up with using the same manipulations as above: $$|x-0|<\delta \implies |f(x)-l| < \epsilon \\
|x|< \frac{\epsilon + l}{\sin \frac{1}{x}}
$$ I had expected this to lead to a contradiction when $l \neq 0$ but so far I can't see it. How do I show that $\lim \limits_{x \to 0}G(x)$ must be $0$ and where did I go wrong in my workings? Thank you in advance for any help provided.","['inequality', 'algebra-precalculus', 'continuity', 'proof-writing', 'limits']"
458376,"Prove $g_n f_n \rightarrow gf$ in $L_p([0,1])$. Where $f_n$ converges and $(g_n)_{n=1}^\infty $ is a sequence of bounded measurable functions","Suppose that $ f_n \rightarrow f $ in $ L_p([0,1])$ with respect to the $|| . ||_p$ norm. $\{g_n\}_{n=1}^{\infty} $is a sequence of measurable functions such that $|g_n| \leq M$ for each $n$ and $g_n \rightarrow g$. Work done so far: $g_n \rightarrow g$ a.e. implies that $g_n^p \rightarrow g^p$ a.e. Next since $|g_n|^p \leq M^p \in \mathbb{R} $ by Lebesgue Dominated Convergence Theorem we get
$\int_{[0,1]} g_n^p \rightarrow \int_{[0,1]} g^p. $ Then, 
$\int_{[0,1]} |g_n f_n - gf|^p \leq \int_{[0,1]} |g_nf_n - g_nf|^p + \int_{[0,1]} |g_n f - gf|^p $ (by Minkowski's) $=  \int_{[0,1] }|g_n|^p|f_n-f|^p + \int_{[0,1]} |f|^p |g_n - g|^p$ So at this point I will put $ (\int_{[0,1]} |g_n f_n - gf|^p)^{1/p} = || g_n f_n - gf||$ And I can almost show that the last two terms go to 0, but am having trouble dealing with $|g_n|^p$ in the first term and $|f|^p$ in the second term.","['lebesgue-integral', 'real-analysis']"
458381,Elementary divisors of an abelian group,"From Advanced Modern Algebra (Rotman): Proposition 4.10 If $G$ is an abelian group and $p$ is prime, then $G/pG$ is a vector space over $\Bbb{F}_p.$ Definition If $p$ is prime and $G$ is a finite $p$ -primary abelian group, then $$d(G)=\dim(G/pG).$$ Definition Let $G$ be a finite $p$ -primary abelian group, where $p$ is prime. For $n \geq 0$ ,  define $$U_p(n,G) = d(p^n,G) - d(p^{n+1}, G).$$ The textbook says that when we decompose a finite $p$ -primary abelian group into factors, $U_p(n,G)$ will be ""the number of cyclic summands having order $p^{n+1}$ "". Definition If $G$ is a $p$ -primary abelian group, then its elementary divisors are the numbers in the sequence $ U_p(0,G)$ $p'$ s, $U_p(1, G)$ $p^2$ 's, ... , $U_p(t-1,G)$ $p^t$ 's Then the textbook gives an example: decomposing an abelian group of order $72=2^33^2$ . Basically, you just say $8 = (2)(4) = (2)(2)(2)$ and $(9)=(3)(3)$ , and you have the elementary divisors, right? But I don't know how to relate this to the method that Rotman uses. In other words (for example), we have $U_2(0,G)$ $2$ 's, and $U_2(0,G) = \dim(G/2G) - \dim(2G/4G)$ . $\{0+2G, 1+2G\}$ is a basis for $G/2G$ , so $\dim(G/2G)=2$ and $\{0+2G, 2+2G\}$ is a basis for $2G/4G$ , so $\dim(2G/4G)=2$ , right? But then $U_2(0,G)=0$ ???","['finite-groups', 'group-theory', 'abstract-algebra', 'abelian-groups']"
458395,"functional analysis in probability theory, Feller processes, contraction semigroups","In an entire year of probability theory coursework at the graduate level, there was only one time when functional analysis seriously appeared.  That was ergodic theory.  Now that my self-studies have carried me away to Feller processes, it has shown up again, and some serious analysis as opposed to combinatorics and elementary measure theory has begun to show up.  Are there any other points where functional analysis or operator theory plays a big role? More specifically, I have noticed that the notion of a contraction semigroup, which is important in Feller processes, can be generalized for contractions on a banach space. (In the Feller theory, the correspondence of generator, semigroup, and Feller process occurs where the semigroup is defined on the vanishing-at-infinity continuous functions on some locally compact separable metric space.)  Is this merely for curiosity's sake, or is there some use of this in probability theory or elsewhere? (Don't contraction semigroups have something to do with the Feynman path integral characterization of quantum mechanics?)","['probability-theory', 'functional-analysis', 'operator-theory']"
458404,How can we compute Pseudoinverse for any Matrix,"If we have a system of linear equations $Ax=b$, then in case $A$ is invertible it easy to say that the solution is $x=A^{-1}b$. In all other cases, even if $A$ is invertible, the solution if it exist will be in the form $x=A^{+}b+(I-A^{+}A)w$, where $A^{+}$is called pseudoinvers of  $A$, and $w$ is a vector of free parameters. My question here is how to compute $A^{+}$ for any matrix $A$? what is the way for doing that? It is easy to compute $A^{+}$ if the column are linearly independent (so that $m>=n$), $A^{+}=(A^{T}A)^{-1}A$,  and also if the rows are linearly independent (so that $m<=n)$, $A^{+}=A^{T}(AA^{T})^{-1}$, but I dont know how to compute $A^{+}$ if $A$ is sequare non invertible matrix or if the columns or rows are not linearly independents. The above does not works. If anyone have any idea about computing pseudoinverse or if there is easier method for finding the solution $x$ for system of linear equations $Ax=b$, please help me in all cases, and please keep in mind that I want to find the general form for the solution if it exist not just for a particular $b$.","['pseudoinverse', 'linear-algebra']"
458411,"If $T$ is an operator on a complex inner-product space, each eigenvalue $|\lambda|=1$ and $\|Tv\|\le\|v\|$, show that $T$ is unitary.","If $T$ is an operator on a finite-dimensional complex inner product space, each eigenvalue $|\lambda|=1$ and $\|Tv\|\le\|v\|$, show that $T$ is unitary. Here's what I had in mind and where I was stuck: $$\|Tv\|\le\|v\| \to \langle v,(I-T^*T)v\rangle \ge0$$ Therefore $I-T^*T$ is self-adjoint hence there exists an orthonormal basis of eigenvectors of $I-T^*T$. I'm able to deduce that each one of its eigenvalues is real and satisfies $\lambda\ge 0$. A possible approach I thought I might take is calculate $\operatorname{trace}(I-T^*T)$ and maybe show that it's $0$. That would complete the proof since then we would get $\lambda=0$ for all of its eigenvalues which would imply $I-T^*T=0 \to T^*T=I$ and hence $T$ is unitary. However:
$$\operatorname{trace}(I-T^*T)=\operatorname{trace}(I)-\operatorname{trace}(T^*T)=n -\operatorname{trace}(T^*T)$$ I don't know how to evaluate the second term. I realize that $T^*T$ is positive and all of its eigenvalues are nonnegative, but I don't know how to go on from here. Any help would be greatly appreciated (or otherwise, I'd love to see other ways to go about the problem).","['linear-algebra', 'inner-products', 'operator-theory']"
458418,Variable substitution in probability,"In modeling the number of claims filed by an individual under an automobile policy during a three-year period, an actuary makes the simplifying assumption that for all integers $n \ge 0$, $p_{n+1}=\frac{1}{5} p_n$, where $p_n$ represents the probability that the policyholder files $n$ claims during the period.  Under this assumption, what is the probability that a policyholder files more than one claim during the period? My first step was the convert the probability function from future values by variable substitution.  So I assign $k=n+1 \implies n=k-1$: $\therefore p_k=\frac{1}{5} p_{k-1} \text{ for } k \ge 1\tag{1}$ Now we can calculate the probabilites for some k values: $k=0:  p_0$ $k=1:  p_1=\frac{1}{5}p_0$ $k=2:  p_2=\frac{1}{5}p_1=(\frac{1}{5})^2 p_0$ $\vdots$ $k=k:  p_k=(\frac{1}{5})^k p_0$ Since the probabilities sum to 1: We can solve for $p_0:  1 = p_0 ( 1 + (\frac{1}{5}) + (\frac{1}{5})^2 + \cdots )=\cfrac{p_0}{1-1/5}$
$\implies p_0=0.8$ Now this is where I get confused.  The question asks us to calculate $\Pr[n>1]$, so: $\Pr[n>1]=1-\Pr[n \le 1]\tag{2}$ Now when calculating equation(2), I thought  I would have to transform $n$ to $k$, so Equation (2) becomes: $\Pr[n>1]=1-\Pr[k \le 2]=1-\Pr[k=0]-\Pr[k=1]-\Pr[k=2]\tag{3}$ But this is not correct.  The solution is just replacing exactly n with k with no substitution.  In other words, the solution is: $\Pr[k>1]=1-\Pr[k \le 1]\tag{4}=1-0.8-0.16$ Can someone please explain why this the case?  Why don't I have to transform n to k when solving this question?  If $n$ is the number of claims during the period, then k is the number of claims per period PLUS ONE.  Thanks in advance!  Have a great weekend!","['statistics', 'probability', 'actuarial-science']"
458420,Subadditivity inequality and power functions [duplicate],"This question already has answers here : Prove that $(p+q)^m \leq p^m+q^m$ (2 answers) Closed 9 years ago . Is it true that if $a,b\in\mathbb{R}$ with $a,b\geq 0$ and $0<r<1$, then $(a+b)^r\leq a^r+b^r$?","['inequality', 'exponentiation', 'calculus', 'algebra-precalculus']"
