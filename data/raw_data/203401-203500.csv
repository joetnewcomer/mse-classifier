question_id,title,body,tags
4016984,Why do we care about the Hilbert Cube?,"The Hilbert Cube is defined to be the countable infinite Cartesian products of the interval $[0,1]$ or anything homeomorphic to $[0,1]$ . Why do we care about this object?",['general-topology']
4017010,Differentiable but not absolutely continuous cumulative distribution function,"There are many examples of functions that are differentiable but not absolutely continuous. But these examples are unbounded oscillating functions (see for example some of the answers to this question Differentiable but not Absolutely continuous ). Of course we also know that absolute continuity implies differentiability almost anywhere, but not necessarily differentiability. On the other hand, every cumulative probability distribution function is bounded in the interval $[0,1]$ , it is increasing and continuous on the right. The question is whether there is any cumulative probability distribution function that is differentiable at every point $x$ but is not absolutely continuous. If it exists, this would also be an example of a continuous distribution function without a density function.","['probability-distributions', 'examples-counterexamples', 'absolute-continuity', 'derivatives', 'probability-theory']"
4017011,Prove that $\sqrt{13}$ is irrational in 3 ways.,"I am asked how to prove that the $\sqrt{13}$ is irrational in 3 ways. I only know of one, where we assume $\sqrt{13} = \frac{a}{b}$ where $a, b$ are coprime, and we prove with contradiction that $13 \mid a$ and $13 \mid b$ . However, I am not sure where to begin with the other two proofs. I thought that this was the only way to prove irrationality of a number. I would really appreciate some help on where to start/look for to start the two other proofs.","['proof-writing', 'discrete-mathematics']"
4017037,Numbers of the kind $0.aaa\ldots =\frac{1}{aaa\ldots a}$,"What are the integers $a$ such that $$
0.\underbrace{aaa\ldots}_{\infty\text{ times}} =\frac{1}{\underbrace{aaa\ldots}_{k\text{ times}}}
$$ eg. $$
0.333\ldots=1/3\\
$$ while $$
0.1616\ldots\ne1/16\ne1/1616\ne1/\underbrace{161616\ldots}_{\text{any }k}
$$ I was able to reduce $a$ to $$
a=\frac{10^d-1}{\sqrt{10^{k\,d}-1}}
$$ where $d$ is the number of digits in $a$ in base $10$ . If this is correct, is $k=1,d=1$ the only solution for integral $a$ ?","['algebra-precalculus', 'decimal-expansion', 'arithmetic', 'rational-numbers']"
4017092,Proving $\tan 3^{\circ}$ is irrational,I want to show $\tan 3^{\circ}$ is irrational I have looked at other similar questions but they all have different patterns to  approach trignometric values like $\tan3$ so what I am thinking of is assuming $tan 3$ is rational that is to say $\tan 3 = a/b$ so this means $\sin 3^{\circ} / \cos 3^{\circ} = a/b$ so we have $\sin 3^{\circ}b= \cos 3^{\circ} a$ so from here I want to find a contradiction but I need help.,"['trigonometry', 'real-analysis']"
4017093,Notation for Range for a Function,"I was given a question where I was asked to determine if a function is one-to-one and/or onto. It was given like this: $\mathbb{Z}^+\to\mathbb{Z}^+,f\left(x\right)=\left(\frac{x}{5}\right)-4$ In this case, what would the $\mathbb{Z}^+\to\mathbb{Z}^+$ mean? Does the first $\mathbb{Z}^+$ signal the range for $x$ and the second $\mathbb{Z}^+$ signal the range for $f\left(x\right)$ ?",['functions']
4017109,Finding Joint PDF of Two Non-Independent Continuous Random Variables,"I'm in the process of reviewing some stats using A First Course in Probability by Sheldon Ross. For the chapter on Joint Distributions, it shows how to obtain the Joint PDF given two independent continuous random variables. However, if the variables weren't independent, how would I go about obtaining the joint PDF of the two variables? Is there a systematic way of going about it similar to when the variables are independent? So for example, if $f(x)$ and $f(y)$ is the PDF of two continuous independent random variables, I can find their joint PDF $f_{x,y}(x,y)$ by simply multiplying $f(x)$ and $f(y)$ . However, how will I find $f_{x,y}(x,y)$ if $X$ and $Y$ were not independent? Thanks!","['statistics', 'probability-distributions', 'probability-theory']"
4017117,Convergence of a Generalized Taylor Expansion,"I have been playing around with the fundamental theorem of calculus: Starting with $$f(x)=f(x_0)+\int_{x_0}^x f'(t_1) \mathrm{d}t_1, \tag{1}$$ one can apply the FTC again, this time to the derivative, to get $$f'(t_1)=f'(x_0)+\int_{x_0}^{t_1} f''(t_2) \mathrm{d}t_2. \tag{2}$$ Substituting $(2)$ in $(1)$ gives $$f(x)=f(x_0) + f'(x_0) (x-x_0)+\int_{x_0}^x \int_{x_0}^{t_1} f''(t_2) \mathrm{d}t_2\, \mathrm{d}t_1.$$ This is one way to get the classical Taylor expansion, with the remainder term here in iterated integral form. I wondered what would happen if different ""centers"" are used at every step. For example, replacing Equation $(2)$ with $$f'(t_1) = f'(x_1)+ \int_{x_1}^{t_1} f''(t_2) \mathrm{d}t_2,  $$ gives $$f(x)=f(x_0)+f'(x_1)(x-x_0)+\int_{x_0}^x \int_{x_1}^{t_1} f''(t_2) \mathrm{d}t_2 \, \mathrm{d} t_1. $$ What I got after $n$ steps was $$f(x)=P_n(x;x_0,x_1,\dots,x_n)+R_n(x;x_0,x_1,\dots,x_n),$$ where $$P_n(x;x_0,x_1,\dots,x_{n})=\sum_{k=0}^n f^{(k)}(x_k) \int_{x_0}^x \int_{x_1}^{t_1} \cdots \int_{x_{k-1}}^{t_{k-1}} \mathrm{d}t_k \, \cdots \mathrm{d}t_2 \, \mathrm{d} t_1, $$ and $$R_n(x;x_0,x_1,\dots,x_{n}) = \int_{x_0}^x \int_{x_1}^{t_1} \cdots \int_{x_{n-1}}^{t_{n-1}} \int_{x_n}^{t_n} f^{(n+1)}(t_{n+1}) \mathrm{d}t_{n+1}\,\mathrm{d}t_n \, \cdots \mathrm{d}t_2 \, \mathrm{d} t_1.$$ Some of the low-order polynomials are: $$\begin{align}
P_0 &= f(x_0), \\
P_1 &= f(x_0)+f'(x_1)(x-x_0), \\
P_2 &= f(x_0)+f'(x_1)(x-x_0)+ \frac{f''(x_2)}{2}(x - x_0) (x + x_0 - 2 x_1),\\
P_3 &= P_2+ \frac{f'''(x_3)}{6} (x-x_0) \left(x^2-3 x_1^2+x_0 \left(x+x_0\right)-3 \left(x+x_0-2 x_1\right) x_2 \right).
\end{align} $$ My questions are: Do the multivariate polynomials $\int_{x_0}^x \int_{x_1}^{t_1} \cdots \int_{x_{k-1}}^{t_{k-1}} \mathrm{d}t_k \, \cdots \mathrm{d}t_2 \, \mathrm{d} t_1$ have a closed form? Is this expansion well-known? Aside from polynomials, and analytic functions where $x_0=x_1=\dots$ , are there criteria for which an infinite series expansion exists? (that is $\lim_{n\to \infty} R_n =0 $ .) Thanks.","['closed-form', 'sequences-and-series', 'taylor-expansion', 'real-analysis']"
4017158,"Spivak Prologue, Chapter 2, problem 7: prove $\sum_{i=1}^n k^p$ can always be written as sum of powers of n","This is problem 7 of Spivak's Calculus, 4th Edition, Prologue Chapter 2: Show that $$\sum_{i=1}^n k^p$$ can always be written in the form $$\frac{n^{p+1}}{p+1} + An^{p} + Bn^{p-1} + Cn^{p-2} + ...$$ There is also a hint to use the method from problem 6. I have a few questions on some specific details about the solution in the solution book, which I reproduce in what follows: Let A be the set of all natural numbers for which $$\sum_{i=1}^n k^p$$ can be written in the form $$\frac{n^{p+1}}{p+1} + An^{p} + Bn^{p-1} + Cn^{p-2} + ...$$ . Using induction on $p$ , for $p=1$ we have $$\sum_{k=1}^n k = \frac{n(n+1)}{2} = \frac{n^2}{2} + n$$ so $p=1$ is in $A$ . Suppose the statement is true for all natural numbers smaller than $p$ (actually the solution book has smaller than or equals; so here is the first question: is it $<$ or $\leq$ here? ). The Binomial Theorem yields: $$(k+1)^{p+1}-k^{p+1} = (p+1)k^p + terms\ involving \sum_{k=1}^n k^r for\ r < p\tag{1}$$ By our induction assumption, we can write each $\sum_{k=1}^n k^r$ as an expression involving powers $n^s$ with $s\leq p$ . Writing out $(1)$ for $k=1,...,n$ we obtain: $$2^{p+1}-1^{p+1}=(p+1)1^p +\ ...$$ $$3^{p+1}-2^{p+1}=(p+1)2^p +\ ...$$ $$(...)$$ $$(n+1)^{p+1}-n^{p+1}=(p+1)n^p +\ ...$$ Adding the equations, we obtain: $$(n+1)^{p+1} - 1 = (p+1)\sum_{k=1}^n k^p +\ terms\ involving\ \sum_{k=1}^n k^r,\ for\ r<p\tag{2}$$ Now at this point, the solution actually says we obtain something else: $$\frac{(n+1)^{p+1}}{p+1}=\sum_{k=1}^n k^p+\ terms\ involving\ \sum_{k=1}^n k^r,\ for\ r<p\tag{3}$$ So the second question is: what assumptions are involved in obtaining $(3)$ ? Ie, in (2) does the term 1 on the lefthand side cancel with one of the terms on the righthand side? It is also true that each term on the righthand side has a (p+1) term, so is that term the one dividing the lefthand side? Finally, as we noted above, because of the induction assumption for all natural numbers less than $p$ , we can write each $\sum_{k=1}^n k^r$ as an expression involving powers of $n^s$ with $s\leq p$ . Therefore, isolating $\sum_{k=1}^n k^p$ we get: $$\sum_{k=1}^n k^p = \frac{(n+1)^{p+1}}{p+1}+\ terms\ involving\ powers\ of\ n\ less\ than\ p+1$$ . Therefore, if $s$ is in $A$ for $s<p$ then $p$ is in $A$ ; therefore by induction $A=N$ . Final question: is this considered a rigorous proof?",['algebra-precalculus']
4017216,$n$ balls into $n$ urns until there is no empty urn.,"We have $n$ balls and $n$ urns. Step 1 . Throw $n$ balls into $n$ urns randomly. Check each urn and if there is more than one ball in an urn, choose only one and keep in the urn and remove all the other balls. Step 2. Suppose there are $k$ balls ''not placed'' in an urn in Step 1. Throw these $k$ balls into the urns randomly. And move on in this fashion until there is no empty urn. What is the expected number of urns that are empty in each step? Answer. Step 1 is easy. For any urn $u_{j}$ , define $X_{j}$ as $X_{j}=1$ if no ball hits and $X_{j}=0$ , otherwise. Then, expected number of empty urns is just $E(X)$ where $X=X_{1}+X_{2}+...+X_{n}$ . Note that $E(X_{j})=Pr(X_{j}=1)=(\frac{n-1}{n})^n$ . Hence, $E(X)=n(\frac{n-1}{n})^n$ . After Step 1, things get complicated. A heuristic approach for Step 2: The expected number of empty urns (and hence unplaced balls) is just $n(\frac{n-1}{n})^n$ . Thus, for large $n$ , the expected number of empty urns in Step 2 is $n\left( \frac{n-1}{n}\right) ^{n}\left( \frac{n-1}{n}\right) ^{n\left(\frac{n-1}{n}\right) ^{n}}$ (within some bound?) Is this approach correct? Can this be made rigorous?","['expected-value', 'balls-in-bins', 'combinatorics', 'conditional-expectation']"
4017218,Concrete Bezout's Theorem Calculation,"For context: I'm taking an algebraic geometry class and TAing for a calculus class. My students had the classic problem of finding the area between $x^3$ and $x^2$ , but primed by algebraic geometry, I had a thought while I was grading: Shouldn't $x^2$ and $x^3$ intersect in $2 \cdot 3 = 6$ points by Bezout's Theorem? Obviously for the purpose of the calculus class the answer is ""no"", the only intersections are $0$ and $1$ , but there are 3 reasons why this might be the case: We're working over $\mathbb{R}$ not $\mathbb{C}$ We're not working in a projective setting $x^2$ and $x^3$ actually intersect twice at $0$ , so our curves aren't suitably ""generic"" (whatever that means). So I tried to solve these problems by considering (in $\mathbb{C}$ ) the intersection of $yz = x^2 + \alpha z^2$ $yz = x^3 + \beta z^3$ Here we've projectivized, and the $\alpha$ and $\beta$ were added to try and solve the genericness issue while keeping the equation somewhat simple. So surely these equations will have 6 solutions, right? Well... If we look in the $x=1$ plane, then we see $1 + \alpha z^2 = yz = 1 + \beta z^2$ , so either $z=0$ or $z = \frac{\alpha}{\beta}$ . I think the solution $z=0$ doesn't actually exist, though, since $y0 = 1 + \alpha 0^2$ has no solutions for $y$ . So we pick up 1 solution. If we look in the $y=1$ plane, nothing interesting happens since we can always just eliminate $y$ , so any solutions will already by in the $x=1$ or $z=1$ planes. Let's move on. If we look in the $z=1$ plane, then we get $x^2 + \alpha = y = x^3 + \beta$ , so we pick up 3 complex solutions. So then we end up with 4 solutions instead of the expected 6. Where did I go wrong? I suspect the issue is either adding $\alpha$ and $\beta$ alone don't make these curves ""generic enough"", whatever that means (so the double root $z=0$ that we killed off in step 1 should really be counted, bringing our total to 6) I've misunderstood something about solving equations where we can eliminate some variables, and there are some extra roots in the $y=1$ plane that I shouldn't have ignored. Any clarification is appreciated! Thanks in advance!","['algebraic-curves', 'algebraic-geometry', 'abstract-algebra']"
4017220,Why do my Stack Exchange reps follow a power law?,"I noticed a pattern while looking at my network profile the other day, and I'm wondering if it's a fluke, or if there is something deep to it. My reps for my top five Stack Exchange communities follow a inverse-square power law pretty neatly.  (Red dots are data; blue curve is a perfect inverse-square law.) The ratio of my top SE rep to subsequent ones is 1, 4.02, 8.86, 16.58, 21.15.  All but the last are within a few percent of the expected 1, 4, 9, 16, 25 for an inverse-square law.  I'm not a statistician, so I have the following questions: How can I go about testing whether this is a fluke or not? Is there a universality argument for why this power law might arise? Some remarks: If you go further down my list of SE reps, the power law disappears, because it mostly consists of sites I've only visited or maybe posted once on.  All power laws have a cutoff, though, so this is unsurprising. I've looked at some other user profiles, and there seem to be different classes of users.  Many are only active on one site, and there is no power law there.  Others are active on multiple sites and do seem to have superficially similar statistics to mine, but I don't know enough to test whether any of this is statistically significant.","['applications', 'statistics', 'probability-limit-theorems', 'probability']"
4017227,How is the inclusion map both an Immersion and Submersion between Manifolds,"Hi i am trying to figure out why an inclusion map is both and immersion and submersion. This is what i have tried so far.Let $S$ be an open subset of a manifold $M$ . Now the inclusion mapping  is $\iota:S\to M$ . Now to prove immersion/submersion we have to show that each of its differentials $\iota_{*,p}$ , for $p \in S$ , is, resp, injective/surjective. By definition of differential of a smooth map $F$ ,we have $(F_{*,p}(X_p))f=X_p(f\circ F)$ where $F_{*,p}:T_pM\to T_{F(p)}N$ where $M$ and $N$ are manifolds.Now, taking $F$ as the inclusion map $\iota$ , we get $(\iota_{*,p}(X_p))f=X_p(f\circ \iota)=X_p(f)$ where $\iota_{*,p}:T_pS\to T_{\iota(p)=p}M$ . My questions are as follows: How do we know from this that each $\iota_{*,p}$ is injective and surjective so that $\iota$ is both an immersion and a submersion?","['tangent-spaces', 'smooth-manifolds', 'inclusion-exclusion', 'manifolds', 'differential-geometry']"
4017241,How to Calculate a Weighted GPA,How would I be able to calculate my overall average grade (or grade point average) for these courses? Course Course Credit (weight) Course Grade Biology 101 45 86 Psychology 210 30 74 Chemistry 250 45 88 English 200 60 77 My understanding is by simply adding the course grades column together and dividing by the total cumulative possible marks. (86+74+88+77)/400 = 0.8125 But this number seems very strange in the 0 to 4 GPA.,['statistics']
4017257,"""Zero set of finitely many polynomials."" but what polynomials are we talking about?","This is a follow-up question of Zero set of finitely many polynomials. When it says ""As the zero set of finitely many polynomials, 𝑅 is a closed subset of 𝑆×𝑆""
I understand we are saying that determinant of submatrix is all zero. But I'm not sure how it is associated with polynomials. It just looks like a bunch of computations. What polynomials are we talking about? Could you give me any concrete example or formula for this? I would really appreciate the answers.","['general-topology', 'linear-algebra', 'differential-geometry']"
4017267,Does any probability distribution have an entropy defined?,"There are lot of probability distribution having infinite moments, for example Cauchy distribution has even the first moment infinite. Therefore, often we cannot calculate second moments used in measures of dispersion or uncertainty (variation and standard deviation). In some application, for example finance, we could replace such measures with entropy. However, firstly I would like to know whether any probability distribution has defined entropy (in particular Shannon entropy). In case of discrete distributions with finite number of possible outcome the entropy is $$
H = -\sum_{i=1}^{n} p_i \log p_i,
$$ where $p_i$ is probability of i th outcome. Since $p_i > 0$ and number of terms in the sum is finite, the sum is defined and it is finite. But I am getting stuck with case $n \rightarrow +\infty$ . In this case I need to prove that the sum  under condition that $\sum_{i=1}^{+\infty}p_i = 1$ converges. Similarly in case of continuous distribution, I would need to prove that integral $$
H = -\int_{\mathbb{R}} f(x) \log f(x) \mathrm{d}x
$$ for any real function satisfying $f(x) > 0\,\, \forall \in \mathbb{R}$ and $\int_\mathbb{R}f(x)\mathrm{d}x=1$ exists and it is finite. Is it possible to prove these statements?","['statistics', 'convergence-divergence', 'entropy']"
4017278,Collinearity in bicentric pentagon,"Can you provide a proof for the following claim: Claim . The circumcenter, the incenter, and the excenter of the pentagon formed by diagonals in a bicentric pentagon are collinear. GeoGebra applet that demonstrates this claim can be found here . My idea is to show that $|OJ|=|OI|+|IJ|$ . By Fuss formula we know that $$r(R-|OI|)=(R+|OI|)\sqrt{(R-r+|OI|)(R-r-|OI|)}+(R+|OI|)\sqrt{2R(R-r-|OI|)}$$ where $R$ and $r$ are circumradius and inradius of bicentric pentagon, respectively. But how to express lengths $|OJ|$ and $|IJ|$ in terms of $R$ and $r$ ?","['euclidean-geometry', 'geometry', 'polygons']"
4017315,How to solve for $\theta$ in the equation $\sin(2\theta) = \sin(\theta)$ using complex numbers?,"I know how to solve for $\theta$ using the general solution method, by transposing $\sin(\theta)$ to the other side and applying the identity $\sin(2\theta) = 2\sin(\theta)\cos(\theta)$ to get the equation $\sin(\theta)(2\cos(\theta) - 1) = 0$ and then taking the general solution for $\sin(\theta) = 0$ and $2\cos(\theta) - 1 = 0$ . But I want to know how to use complex numbers to solve this question and get the same answers. I tried using Euler's formula and writing both $\sin(\theta)$ and $\sin(2\theta)$ as $(e^{i\theta}-e^{-i\theta})/2i$ and $(e^{2i\theta}-e^{-2i\theta})/2i$ respectively and I even got an equation of the form $y^4 - y^3 + y - 1 = 0$ , where $y = e^{i\theta}$ . However, solving that only yielded one of the principle solutions i.e $\theta = \pi$ , I should also get $\theta = \pi/3$ , but I haven't been able to get it. Any help on this is greatly appreciated!","['trigonometry', 'roots', 'complex-numbers']"
4017329,How is the Algebra $C_{p}^{\infty}(U)$ of germs of $C^\infty$ functions in $U$ at $p$ is the Same as $C_{p}^{\infty}(M)$,"Hi i am reading An introduction to manifolds by Loring and have some doubts in remark 8.2. It is written that If $U$ is an open set containing $p$ in $M$ then the algebra $C_{p}^{\infty}(U)$ of germs of $C^\infty$ functions in $U$ at $p$ is the same as $C_{p}^{\infty}(M)$ .Hence, $T_pU=T_pM$ . My first question is: How do we know that the algebra $C_{p}^{\infty}(U)=C_{p}^{\infty}(M)$ . I know that, the equivalence class of $(f,U)$ is called the germ of $f$ at $p$ . I have a second question which is related to the differential of a map. It is written that: The equation $(F_{*}(X_p))f=X_p(f\circ F)$ is independent of the representative of the germ. My second question is that here in the above equation $f$ is the representative of a germ and it is appearing inside the equation then how this equation is independent of the representative $f$ ? For reference i am attaching the screenshots where i have highlighted the part where these two statements are mentioned.","['tangent-spaces', 'smooth-manifolds', 'germs', 'manifolds', 'differential-geometry']"
4017382,Does the path component functor admit a right adjoint?,"Does $\pi_0:Top\to Set$ , sending a topological space to its path-connected components, admit a right adjoint? If not, does it admit a right adjoint if we restrict it to certain topological spaces, say CW complexes?","['general-topology', 'category-theory', 'algebraic-topology']"
4017417,Computing the integral $I=\int_{0}^{1}\sqrt{1-x^{\pi}}dx$,Let $I=\int_{0}^{1}\sqrt{1-x^{\pi}}dx$ If we use $u=x^{\pi}$ then we get $dx=\frac{du}{\pi^{\frac{\pi-1}{\pi}}}$ are there any better identites or substitution that can make integral easier to compute?,"['integration', 'calculus', 'special-functions']"
4017441,A quite difficult limit: $\lim _{x\to 0}\frac{\exp(x^2)-\cos x-x\sin x}{\sinh^2x}$,"I tried this limit with Taylor series. However, proceeding in this manner I obtained a series over another series. Furthermore, I do not know how to continue as long as we have $x$ tends to $0$ . Were it to be $x$ tends to infinite, this limit would be simpler. This is what I got $$\begin{align}&
\lim _{x\to 0}\frac{\exp(x^2)-\cos x-x\sin x}{\sinh^2x} \\[6pt]
=\;&\frac{\frac12x^2+\frac{5}{8}x^4+\frac{23}{144}x^6+\frac{241}{5760}x^8+\frac{3359}{403200}x^{10}+\cdots}{{x^2+\frac{1}{3}x^4+\frac{2}{45}x^6+\frac{1}{315}x^8+\frac{2}{14175}x^{10}+\cdots}}
\end{align}$$ I can't continue.","['limits', 'taylor-expansion']"
4017454,Integration of a radial function over a bounded domain,"Let $\Omega$ be a bounded domain in $\mathbb{R}^N$ . Let $f(x)=|x|^\alpha$ . Then $f\in L^1(\Omega)$ if $\alpha>-N$ . The above fact seems to hold for the following reason. Since $\Omega$ is bounded, there exists $R>0$ such that $\Omega\subset B(0,R)$ . Then, we have \begin{align*}
I&=\int_{\Omega}f(x)dx\\
&\leq\int_{B(0,R)}|x|^\alpha dx\\
&=\frac{r^{\alpha+N}}{\alpha+N}\Bigg|_{0}^{R}\\
&=\frac{R^{\alpha+N}}{\alpha+N},
\end{align*} where $\alpha+N>0$ . Then we get $f\in L^1(\Omega)$ . Kindly inform me, if the above argument seems fine with you. Thanks.","['integration', 'measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'riemann-integration']"
4017526,"Maximum value of $(x−1)^2+ (y−1)^2+ (z−1)^2$ with constraint $x^2+y^2+z^2 ≤2 , z≤1$","So the problem is that I have $D(f)=\{(x,y,z), x^2+y^2+z^2 ≤2 , z≤1\}$ and I have to determine the maximum value for the function $(x−1)^2+ (y−1)^2+ (z−1)^2$ in $D$ . I'm just confused as I don't actually know if $z\le1$ counts as a constraint as well, or is it just for me to sketch the area, which is actually a part of the question.
Furthermore, I know that I have to use Lagrange multiplier method, but I honestly don't know how because $\le$ is making the question hard for me. Do I just calculate as usual and count $\le$ the same as $=$ ? appreciate all the feedback Edit: I have calculated the grad f =0 which is = $D(f)=(2(x-1), 2(y-1), 2(z-1))$ where I've got that $x=y=z= 1$ and $f(1, 1, 1)=0$ . (I don't know what to do with this though). Then I calculated $L(x, y, x, λ) = (x−1)^2+(y−1)^2+(z−1)^2 +λ(x^2+y^2+z^2-2)$ , then the four cases where I got the same value which is $-2λ= 2(x-1)/x = 2(y-1)/y = 2(z-1)/z$ . Which means that $x=y=z$ , put it in the $D$ function $x^2+ x^2+ x^2$ and ended up with $x=y=z= −+√2/√3$ . I took the minus sign for the maximum distance from $(1,1,1)$ . which means that the answer is $x=y=z= −√2/√3$ . Is it correct?","['multivariable-calculus', 'lagrange-multiplier']"
4017602,Spanning tree created with cycles breaking different form the Maximal Spanning Tree.,"Let $G$ be a connected graph with $N$ nodes, $B$ the set of the nodes and $V$ the set of the edges of $G$ . For all edges $e \in V$ , there is an associate positive weight $\nu_e > 0$ on this edge ( $\nu_e=0$ if there is no connection). We suppose that there are no self-connecting edges (an edge that connects a node to himself) and that all the edges have different weigth. It is very easy, using Kruskal or Prim's algorithm, to find a maximal spanning tree $T_{max} \subseteq V$ that is the spanning tree that maximizes the graph sum $$\sum_{e \in T_{max}} \nu_e.$$ Now, I want to operate on $G$ following this instruction : For every cycle $c$ , I remove the edge of the cycle that have the most minimal weight (and I do nothing if this edge has already been removed before). At the end of this simple algorithm, we get a spanning tree $T$ that covers every edges, and by definition of the maximal spanning tree we have : $$\sum_{e \in T} \nu_e \leq \sum_{e \in T_{max}} \nu_e.$$ However, on all the examples I've tried, I always end up with both sums being equal... (I end up with $T=T_{max}$ ) Is their a counter-example that would verify the following $$\sum_{e \in T} \nu_e <\sum_{e \in T_{max}} \nu_e.$$ Or maybe the tree $T$ constructed using this method has to be a maximal spanning tree ? Any help or ideas are welcomed.","['graph-theory', 'trees', 'discrete-mathematics', 'discrete-optimization']"
4017606,"""Introduction to Smooth Manifolds"" - differential of a function query","I'm trying to understand the differential $df$ as an approximation to $\Delta f$ , in Lee's Introduction to Smooth Manifolds (p282-283 - see image below). He says “let $p$ be a point on $M$ ” but then, in the diagram, labels $p$ in $U$ but not on $M$ . Why does he do that?","['differential-forms', 'smooth-manifolds', 'differential-geometry']"
4017611,"Find the value of parameter a, so the polynomial has root with multiplicity","everyone! Please help me understand what do I have to do here. I have a function: $$f(x) = x^3 + ax^2 +3x - 1$$ I need to find possible values of parameter a , such that the root of the function has multiplicity. I have approached this problem like that: $$f'''(x) = 6 + 2a$$ So I have found that $$ a = -3$$ Are there any more values of parameters a, that correspond with the requirement above?","['algebra-precalculus', 'polynomials', 'ordinary-differential-equations']"
4017616,"Cube question without coordinates, cross sections and planes","We have a cube with corners $ABCDA_1B_1C_1D_1$ . The points $A_1B_1C_1D_1$ lie above the square $ABCD$ . We also have a plane that goes through the middle of line $BC$ , through the middle of square $ABA_1B_1$ , through the middle of $A_1B_1C_1D_1$ . At what ratio does the plane cut line $AB$ . What I did, I've put the cube into the coordinate system $B(0,0,1), A_1 (0,1,0) \text{ and } A(0,0,0)$ , $D(1,0,0)$ and then it was pretty easy to solve. I just got the equation of the plane and then solved for intersection of the line that goes through AB, to get the point. Then I knew the ratio. My question is, how to solve this problem without putting the cube into the coordinate system? SOLUTION: solution should be that the plane cuts AB in ratio 3:1",['geometry']
4017659,Why is the kernel of a group homomorphism so called?,"I took a course in Linear Algebra last fall. I have come to associate the word kernel with the nullspace of matrices/linear transformations - and now that I am studying Group Theory, similar intuition doesn't seem to carry forward. Why would anyone name it kernel (in group theory) if it really isn't the same thing as that in linear algebra? Perhaps there is a relation or connect between the two definitions that I am missing. Could someone help me better understand why the kernel of a homomorphism is so defined? To document the definitions: (Linear Algebra): Consider a linear transformation $T:V\to W$ . $$\ker T = \{x\in V: T(x) = 0\}$$ (Group Theory): Let $\phi:G\to H$ be a group homomorphism. $$\ker\phi = \{x\in G: \phi(x) = 1_H\}$$ where $1_H$ is the identity in $H$ . Thanks!","['definition', 'abstract-algebra', 'linear-algebra', 'group-theory', 'terminology']"
4017670,"How to calculate $ \int_0^{\pi/2}\log(1+\sin(x))\log(\cos(x)) \,dx $?","How to calculate $$ \int_0^{\pi/2}\log(1+\sin(x))\log(\cos(x)) \,dx \,\,?$$ I tried to use the Fourier series of log sine and log cos and I got that the integral is equal to : $$ \frac{\pi^2}{24}-\sum_{k=1}^{\infty}\sum_{n=1}^{\infty}\frac{(-1)^{n+k}}{k(4k^2-(2n-1)^2)}$$ has anyone a idea to how to find the closed-form of the last series or how to start out differently with the integral?","['integration', 'definite-integrals', 'sequences-and-series']"
4017736,The expectation of $e^X \left(1-(1-e^{-X}\right)^n)$ when $X$ has Exponential Distribution,"To my surprise, I was able to evaluate the following expression in Mathematica: $$E\left[e^X \left(1-(1-e^{-X}\right)^n) \right] = \frac{y}{y-1} \left(1-\frac{1}{\binom{n+y-1}{y-1}}\right)\quad X\sim\text{Exp}(y)$$ with the right hand side being equal to $\text{HarmonicNumber}(n)$ in the particular case $y=1$ , and equal to $n$ when $y=0$ . If we define $\binom{n}{k} = \frac{\Gamma(n+1)}{\Gamma(n-k+1)\Gamma(k+1)}$ the results seems to hold for all $x,y\in\mathbb R$ , though I mostly care about $n$ and $y$ as positive integers. I have no idea how to prove this by hand.
I tried a series expansion of the exponentials without realizing much.
I also tried rewriting in terms of the uniform distribution, since $e^{-X}$ has the same distribution as $U^{1/y}$ for $U\sim\text{Uniform}(0,1)$ . Are there any tricks or properties I'm missing?","['uniform-distribution', 'expected-value', 'harmonic-numbers', 'exponential-distribution', 'probability']"
4017763,Expectation of sample variance,"Let $s^2$ be sample variance, $\sigma^2$ be population variance $E[\frac{(n-1)s^2}{\sigma^2}] = E[\chi^2_{n-1}] = (n-1) \implies \frac{(n-1)E[s^2]}{\sigma^2} = n-1 \implies E[s^2]=\sigma^2$ But if i do in followng way, i am getting wrong answer $E[s^2]=E[\frac{1}{n-1} \sum_{i=1}^n (x_i-\bar x)^2] \\ = \frac{1}{n-1} \sum_i (E[x_i^2] + E(\bar x^2) - 2E[\bar x]E[x_i])$ I know that $E[\bar x] = \mu$ , population mean $E[x_i^2] = var(x_i)+E[x_i]^2 = \sigma^2+\mu^2 \\ E[\bar x^2] = var(\bar x)+E[\bar x]^2 = \frac{\sigma^2}{n}+\mu^2$ Plugging these in above boldface equation $E[s^2] = \frac{1}{n-1} (n(\sigma^2+\mu^2)+n(\frac{\sigma^2}{n}+\mu^2)-2\mu^2) \\ \frac{n+1}{n-1} \sigma^2$ I know this is wrong. But i donot know where i made the mistake.","['self-learning', 'statistics', 'variance', 'expected-value', 'probability']"
4017806,An infinite product for $\frac{\pi}{2}$,"Please help prove $$
\begin{align}
\frac{\pi}{2}&=\left(\frac{1}{2}\right)^{2/1}\left(\frac{2^{2}}{1^{1}}\right)^{4/(1\cdot 3)}\left(\frac{1}{4}\right)^{2/3}\left(\frac{2^{2}\cdot4^{4}}{1^{1}\cdot3^{3}}\right)^{4/(3\cdot 5)}\left(\frac{1}{6}\right)^{2/5}\left(\frac{2^{2}\cdot4^{4}\cdot6^{6}}{1^{1}\cdot3^{3}\cdot5^{5}}\right)^{4/(5\cdot 7)}\cdots\\[5pt]
&=\prod_{n=1}^{\infty}\left(\frac{1}{2n}\right)^{\frac{2}{2n-1}}\left(\prod_{k=1}^{n}\frac{\left(2k\right)^{2k}}{\left(2k-1\right)^{2k-1}}\right)^{\frac{4}{\left(2n-1\right)\left(2n+1\right)}}
\end{align}
$$ Here's my progress $$
\begin{align}
\frac{\pi}{2}&=\prod_{n=1}^{\infty}\left(\frac{1}{2n}\right)^{\frac{2}{2n-1}}\left(\prod_{k=1}^{n}\frac{\left(2k\right)^{2k}}{\left(2k-1\right)^{2k-1}}\right)^{\frac{4}{\left(2n-1\right)\left(2n+1\right)}}\\[5pt]
&=\prod_{n=1}^{\infty}\left(\frac{1}{2n}\right)^{\frac{2}{2n-1}}\left(\prod_{k=1}^{n}\frac{\left(2k\right)^{2k}}{\left(2k-1\right)^{2k-1}}\right)^{\frac{2}{2n-1}-\frac{2}{2n+1}}\\[5pt]
&=\lim\limits_{m\to\infty}\frac{\prod_{n=1}^{m}\left(\frac{1}{2n}\right)^{\frac{2}{2n-1}}\left(\prod_{k=1}^{n}\frac{\left(2k\right)^{2k}}{\left(2k-1\right)^{2k-1}}\right)^{\frac{2}{2n-1}}}{\left(\prod_{k=1}^{m}\frac{\left(2k\right)^{2k}}{\left(2k-1\right)^{2k-1}}\right)^{\frac{2}{2m+1}}\prod_{n=2}^{m}\left(\prod_{k=1}^{n-1}\frac{\left(2k\right)^{2k}}{\left(2k-1\right)^{2k-1}}\right)^{\frac{2}{2n-1}}}\\[5pt]
&=\lim\limits_{m\to\infty}\frac{\prod_{n=1}^{m}\left(\frac{1}{2n}\right)^{\frac{2}{2n-1}}\left(\frac{\left(2n\right)^{2n}}{\left(2n-1\right)^{2n-1}}\right)^{\frac{2}{2n-1}}}{\left(\prod_{k=1}^{m}\frac{\left(2k\right)^{2k}}{\left(2k-1\right)^{2k-1}}\right)^{\frac{2}{2m+1}}}\\[5pt]
&=\lim\limits_{m\to\infty}\frac{\left(\prod_{n=1}^{m}\frac{2n}{2n-1}\right)^{2}}{\left(\prod_{k=1}^{m}\frac{\left(2k\right)^{2k}}{\left(2k-1\right)^{2k-1}}\right)^{\frac{2}{2m+1}}}\\[5pt]
&=\lim\limits_{m\to\infty}\frac{\pi\left(\frac{\Gamma(m+1)}{\Gamma(m+\frac12)}\right)^{2}}{\left(\prod_{k=1}^{m}\frac{\left(2k\right)^{2k}}{\left(2k-1\right)^{2k-1}}\right)^{\frac{1}{m}}}\\[5pt]
\iff \frac12&=\lim\limits_{m\to\infty}\frac{\left(\frac{\Gamma(m+1)}{\Gamma(m+\frac12)}\right)^{2}}{\left(\prod_{k=1}^{m}\frac{\left(2k\right)^{2k}}{\left(2k-1\right)^{2k-1}}\right)^{\frac{1}{m}}}
\end{align}
$$ I'm stuck here for now. Edit:
Drawing from this post we apparently just need to show that $$\left(\prod_{k=1}^{m}\frac{\left(2k\right)^{2k}}{\left(2k-1\right)^{2k-1}}\right)^{\frac{1}{m}}\sim 2m$$","['pi', 'closed-form', 'products', 'infinite-product', 'limits']"
4017812,$y''+p(t)y'+q(t)y=0$ has finite number of zeros,"Given $y''+p(t)y'+q(t)y=0$ and $p,q$ are continuous on $\mathbb{R}$ and let $y$ be a non-trivial solution of the system. Prove that in any finite interval $[a,b]$ exists at most a finite number of zeros $\{t_k\}_{k=1}^{n}\subset[a,b]$ such that $y(t_k)=0$ for every $k$ I've thought transforming into S-L form by multiply the equation with $e^{\int p(s)}$ and then I get : $(y'e^{\int p(s)})'+e^{\int p(s)}q(t)y=0$ but I don't know how can I say something about the number of zeros from this equation. any hint?","['sturm-liouville', 'ordinary-differential-equations']"
4017845,Why is the equivalence relation in $L^p$ space of equal almost everywhere valid?,"I know that on $L^p(\mathbb{R}^n)$ , two functions $f$ , $g$ are regarded as the same, denoted $f\sim g$ , if $f=g$ almost everywhere.
Transitivity of equivalence relation is satisfied, i.e. if $f\sim g$ and $g\sim h$ , then $f\sim h$ . And ""countable transitivity"" also holds, i.e., if $f \sim r_1$ , $r_1 \sim r_2 \sim r_3 \sim \cdots \sim g$ , then $f\sim g$ . This is because a countable union of measure zero sets is still of measure zero. Now my question is why ""uncountable transitivity"" doesn't hold? Functions $\chi_{[0,s]}$ where $s$ ranges over $[0,1]$ , cannot be all in the same equivalence class. But it seems plausible to connect any two such functions $\chi_{[0,s]}, \chi_{[0,t]}$ by uncountably many equivalence relations. I think it might be because the equivalence relation cannot be used infinitely many times. But I'm still confused and I guess it is a little related to set theory. Could anyone say more about this?","['measure-theory', 'real-analysis']"
4017850,What is the meaning of $\cap_{n=1}^\infty \cup_{i=n}^\infty A_i=\{A_n \text{ infinitely often}\}$ mean?,"The second Borel-Cantelli lemma refers to a sequence of independent events $A_n$ such that $\sum_{n=1}^\infty \Pr(A_n)=\infty,$ and says that in this case infinitely many $A_n$ events occur almost surely. $$\bigcap_{n=1}^\infty \bigcup_{i=n}^\infty A_i=\{A_n \text{ i.o.}\}$$ The indexing in the union considers the union of only events beyond a certain event $n$ in the sequence. So it would comprise the occurrence of any events after $n.$ But what is the intersection? Does it simply mean that all these composite events after every single $n$ do occur?",['probability-theory']
4017918,Positive integer solutions of equations of the form $ x^4+bx^2y^2+dy^4=z^2$,"A method used to answer the post Does the equation $y^2=3x^4-3x^2+1$ have an elementary solution? showed that the only positive integer solutions of the equations $$ x^4-3x^2y^2+3y^4=z^2$$ $$X^4+6X^2Y^2-3Y^4=Z^2,$$ are $(1,1,1)$ and $(1,1,2)$ , respectively. Furthermore these solutions are related in that each can be deduced from the other. In general, let $b,d,D$ be integers such that $b^2=4d+D$ and consider the pair of equations $$ x^4+bx^2y^2+dy^4=z^2\tag 1$$ $$X^4-2bX^2Y^2+DY^4=Z^2\tag 2$$ where we can assume that $(x,y)=(X,Y)=1$ . Then for the method of the aforementioned post to produce an infinite sequence of solutions, we require a solution $(x,y,z)$ of $(1)$ to generate the solution $(\frac{z}{x},y,|\frac{x^4-dy^4}{x^2}|)$ of $(2)$ and we require a solution $(X,Y,Z)$ of $(2)$ to generate the solution $(\frac{Z}{2X},Y,|\frac{X^4-DY^4}{4X^2}|)$ of $(1)$ . I can prove that for this to occur $y=Y$ is odd. Also, since $x$ must be a factor of $z$ , $x^2$ is a factor of $d$ . Therefore there are only a finite number of possibilities for $x$ and so we are dealing with a finite loop of solutions. Beyond that, I only know that when solving specific equations these loops are rare and, when they occur, seem to have period $2$ . Questions What periods are possible for such loops of solutions? What else can be determined about them?","['number-theory', 'elementary-number-theory', 'diophantine-equations']"
4018025,Prove that $\angle AEF =90^\circ$ given a square $ABCD$,"Let $ABCD$ be a square and $E\in CD$ such that $DE=EC$ . Let $F\in BC$ such that $BC=4FC$ . Prove that $\angle AEF =90^\circ$ . My attempt: Proving that $\angle AEF =90^\circ$ is the same as proving that $\triangle AEF$ is a right triangle. In other words, we wish to prove that $AE^2 +EF^2 = AF^2$ . I’ve tried a lot of methods to reach this point but none of them worked.","['contest-math', 'geometry']"
4018031,Alternative characterization of total variation of $L^1$ functions,"This is about exercise 3.3 from Ambrosio, Fusco and Pallara Functions of bounded variation and free discontinuity problems . I struggled with this for some time. Let $\Omega$ be an open set and $u \in L^1_{loc}(\Omega)$ . Show that the totalvariation $V(u, \cdot)$ is the least Borel measure $\mu$ s.t. $$
\int_K \frac{|u(x+y) - u(x)|}{|y|}\mathrm{d}x \leq \mu\big(\{x \in \Omega: \text{dist}(x,K) < |y|\}\big).
$$ for any compact set $K \subset \Omega$ and any $y \in \mathbb{R}^N\setminus \{0\}$ such that $|y| < \text{dist}(K, \partial \Omega)$ . Here the total variation is defined on open sets $A$ like usual by $$ V(u,A) := \sup\left\{ \int_A u(x)\text{div}\phi(x) \mathrm{d}x: \phi \in C^1_c(A), \left\lVert\phi\right\rVert_\infty \leq 1\right\}.$$ Does anyone have an idea? Particular the part about that the total variation is the least Borel measure that has this property has me kind of stumbled.","['measure-theory', 'total-variation', 'geometric-measure-theory', 'bounded-variation']"
4018040,Any good upper bounds for $\sum_{i = 0}^{m} 2^i {k+i \choose i}$?,"I am trying to solve a recursion (I faced it when I wanted to analyze the running time of an algorithm precisely). I reduced it to compute a ""good"" upper bound for $\sum_{i = 0}^{m}2^i {k + i \choose i}$ . We have these assumptions that $1 < m \leq Ck$ , for some $C\in \mathbb{N}$ .
I have tried many approximations but the bounds are not what I want. They are very loose. On the other hand, it doesn't look like a very sophisticated summation but I have so much difficulty solving it!
Does anyone have any ideas?","['summation', 'binomial-coefficients', 'combinatorics']"
4018088,P-values and statistical significance,"The mean for the result of a regional test is $525$ points with a deviation of $80$ . A $90$ students class did the test and got a mean score of $535$ . Is the mean score of the class different from the regional mean score for a statistical significance of $0.05$ ? I'm trying to understand the role of statistical significance and just can't wrap my head around how could these means not be different, would love to get some help understanding this problem.",['statistics']
4018090,"Probability of Power Rangers, please correct me if I am wrong","There are five Power Rangers.  Of the five,  two are male(Red, Black) and three are female (Pink, Yellow,blue.)I randomly select two of the Power Rangers, without replacement. (a)  What is the probability that the black Ranger is one of the two selected Power Rangers? pretending that you only randomly select one power ranger, the 
probability of picking the black would just be 1/5, so if you were 
to pick another it would be 1/4 so it would be 1/5 * 1/4 = .05 so 5% chance? 
it just seems low (b)  What is the probability at least one of the two selected Power Rangers is female? probability that one is female is 3/5, so if you were to pick 
another power ranger at random would it be 3/5*3/4 (c)  Given that at least one of the two selected Power Rangers is male, what is the conditional probability the Pink Ranger is selected? conditional probability, wouldnt it just be 33.3% that the pink is selected given theres only three females? (d)  Are the events “the Pink Ranger is one of the two selected” and “at least one of the two selected Power Rangers is female” independent?  Explain why or why not. Yes, event A effects event B.","['statistics', 'probability']"
4018110,Calculate the area of a $N \times N$ grid using a $2D$ random walk.,"Is there a formula to determine the approx. steps needed to calculate the area of a $N \times N$ grid? Suppose we have a discrete random walk on $\mathbb{Z}^2$ starting at $(0,0)$ and each ""step"" is determined by adding one of the vectors $(1,0), (−1,0), (0,1), (0,−1)$ . The walk continues in the same manner for many steps and cannot step outside its boundary edges or corners. Anytime the walk completes a unit square perimeter, it's added to the total area so far. This walk continues until every unit square has been completed. As the comment section noted, this is equivalent to walking every segment. Example A random walk on a $150\times150$ grid in progress... EDIT Finally wrote a C program to traverse $N \times N$ grids. For example, the $10 \times 10$ grid is iterated $100$ times and the average steps taken. 10x10 Grid, Total Steps: 2455
10x10 Grid, Total Steps: 2206
10x10 Grid, Total Steps: 1872
10x10 Grid, Total Steps: 2390
10x10 Grid, Total Steps: 2044
10x10 Grid, Total Steps: 2411
10x10 Grid, Total Steps: 2976
10x10 Grid, Total Steps: 2718
10x10 Grid, Total Steps: 2669
10x10 Grid, Total Steps: 3641
10x10 Grid, Total Steps: 1879
10x10 Grid, Total Steps: 2288
10x10 Grid, Total Steps: 1906
10x10 Grid, Total Steps: 1688
10x10 Grid, Total Steps: 1857
10x10 Grid, Total Steps: 2571
10x10 Grid, Total Steps: 3085
10x10 Grid, Total Steps: 2274
10x10 Grid, Total Steps: 3288
10x10 Grid, Total Steps: 2096
10x10 Grid, Total Steps: 2415
10x10 Grid, Total Steps: 1850
10x10 Grid, Total Steps: 2113
10x10 Grid, Total Steps: 1926
10x10 Grid, Total Steps: 3149
10x10 Grid, Total Steps: 2189
10x10 Grid, Total Steps: 1873
10x10 Grid, Total Steps: 1662
10x10 Grid, Total Steps: 3776
10x10 Grid, Total Steps: 3109
10x10 Grid, Total Steps: 1723
10x10 Grid, Total Steps: 2088
10x10 Grid, Total Steps: 2726
10x10 Grid, Total Steps: 1897
10x10 Grid, Total Steps: 1935
10x10 Grid, Total Steps: 1719
10x10 Grid, Total Steps: 2358
10x10 Grid, Total Steps: 2501
10x10 Grid, Total Steps: 3118
10x10 Grid, Total Steps: 2870
10x10 Grid, Total Steps: 2459
10x10 Grid, Total Steps: 3090
10x10 Grid, Total Steps: 1862
10x10 Grid, Total Steps: 2370
10x10 Grid, Total Steps: 1905
10x10 Grid, Total Steps: 2063
10x10 Grid, Total Steps: 2255
10x10 Grid, Total Steps: 2484
10x10 Grid, Total Steps: 2861
10x10 Grid, Total Steps: 1535
10x10 Grid, Total Steps: 2026
10x10 Grid, Total Steps: 3210
10x10 Grid, Total Steps: 3116
10x10 Grid, Total Steps: 2013
10x10 Grid, Total Steps: 2204
10x10 Grid, Total Steps: 1668
10x10 Grid, Total Steps: 1614
10x10 Grid, Total Steps: 2347
10x10 Grid, Total Steps: 2694
10x10 Grid, Total Steps: 4518
10x10 Grid, Total Steps: 2213
10x10 Grid, Total Steps: 3105
10x10 Grid, Total Steps: 2483
10x10 Grid, Total Steps: 1900
10x10 Grid, Total Steps: 2732
10x10 Grid, Total Steps: 3267
10x10 Grid, Total Steps: 2392
10x10 Grid, Total Steps: 2540
10x10 Grid, Total Steps: 2805
10x10 Grid, Total Steps: 2872
10x10 Grid, Total Steps: 5039
10x10 Grid, Total Steps: 3851
10x10 Grid, Total Steps: 2909
10x10 Grid, Total Steps: 2081
10x10 Grid, Total Steps: 2621
10x10 Grid, Total Steps: 2561
10x10 Grid, Total Steps: 2296
10x10 Grid, Total Steps: 1655
10x10 Grid, Total Steps: 3922
10x10 Grid, Total Steps: 3123
10x10 Grid, Total Steps: 4437
10x10 Grid, Total Steps: 2631
10x10 Grid, Total Steps: 2175
10x10 Grid, Total Steps: 2606
10x10 Grid, Total Steps: 2214
10x10 Grid, Total Steps: 2831
10x10 Grid, Total Steps: 2565
10x10 Grid, Total Steps: 3157
10x10 Grid, Total Steps: 2268
10x10 Grid, Total Steps: 1704
10x10 Grid, Total Steps: 2817
10x10 Grid, Total Steps: 2695
10x10 Grid, Total Steps: 2102
10x10 Grid, Total Steps: 4982
10x10 Grid, Total Steps: 2618
10x10 Grid, Total Steps: 2219
10x10 Grid, Total Steps: 4198
10x10 Grid, Total Steps: 3987
10x10 Grid, Total Steps: 1868
10x10 Grid, Total Steps: 2375
10x10 Grid, Average Steps: 2564 Similar grid and graph results follow: 10x10   Grid, Average Steps: 2564
20x20   Grid, Average Steps: 13829
30x30   Grid, Average Steps: 34849
40x40   Grid, Average Steps: 69704
50x50   Grid, Average Steps: 112535
60x60   Grid, Average Steps: 178182
70x70   Grid, Average Steps: 249028
80x80   Grid, Average Steps: 354800
90x90   Grid, Average Steps: 456223
100x100 Grid, Average Steps: 575570 QUESTION Given an $N \times N$ grid, is there a way to devise a formula to find the approx. number of random steps needed to compute its area based upon these program results? Maybe a Lagrange Interpolating Polynomial like this: $f(x) = \\ \begin{array}{c}  \frac{31381 x^9}{8640000000000}-\frac{1427173 x^8}{806400000000}+\frac{1549913 x^7}{4200000000}-\frac{123941687 x^6}{2880000000}+\frac{886369883 x^5}{288000000}-\frac{1602458819 x^4}{11520000}+\frac{17031670657 x^3}{4320000}-\frac{67368570503 x^2}{1008000}+\frac{1020468443 x}{1680}-2208005 \end{array}$ Thanks. // Calculate the area of a N×N grid using a 2D random walk.

#include <stdio.h>
#include <stdbool.h>
#include <stdlib.h>
#include <time.h>
#include <random>

unsigned int GRID_SIZE;
std::minstd_rand simple_rand;

typedef struct
{
    int xF;
    int yF;
    int xT;
    int yT;
} FromTo;


typedef struct
{
    FromTo FT;
    bool walked;
} segment;

int xFrom, yFrom, xTo, yTo;

segment* xPaths[1000];
segment* yPaths[1000];


void PathsCheck(segment** Paths)
{
    int i=0, j=0;
    segment* Segments;

    for (i = 0; i < GRID_SIZE; i++)
    {
        Segments = Paths[i];

        for (j = 0; j < GRID_SIZE; j++)
        {
            // Check for reversible walks {(0,0),(1,0)} or {(1,0),(0,0)}
            if ((((Segments[j].FT.xF == xFrom) && (Segments[j].FT.yF == yFrom)) &&
                ((Segments[j].FT.xT == xTo) && (Segments[j].FT.yT == yTo))) ||
                (((Segments[j].FT.xT == xFrom) && (Segments[j].FT.yT == yFrom)) &&
                ((Segments[j].FT.xF == xTo) && (Segments[j].FT.yF == yTo))))
            {                
                Segments[j].walked = true;
                return;
            }
        }
    }
}


int PathsStats(segment** Paths)
{
    int i = 0, j = 0, segmentsTraversed = 0;
    segment* Segments;

    for (i = 0; i < GRID_SIZE; i++)
    {
        Segments = Paths[i];

        for (j = 0; j < (GRID_SIZE - 1); j++)
        {
            if (Segments[j].walked)
            {
                segmentsTraversed++;
            }
        }
    }

    return segmentsTraversed;
}


void GenerateRandomWalk(void)
{
    // (0,3) (1,3) (2,3) (3,3) 
    // (0,2) (1,2) (2,2) (3,2) 
    // (0,1) (1,1) (2,1) (3,1) 
    // (0,0) (1,0) (2,0) (3,0)

    xFrom = xTo;
    yFrom = yTo;

    do
    {
        switch (simple_rand() % 4)
        {
        case 0: if (yTo != (GRID_SIZE - 1)) yTo++; break; // up            
        case 1: if (yTo != 0) yTo--; break;               // down            
        case 2: if (xTo != 0) xTo--; break;               // left            
        case 3: if (xTo != (GRID_SIZE - 1)) xTo++; break; // right
        }
    } while ((xFrom == xTo) && (yFrom == yTo));
}


void CreateXsegments(void)
{
    int x, y, i=0, j;
    segment* xSegments;

    // xSegments[0] = {(0,3),(1,3)} {(1,3),(2,3)} {(2,3),(3,3)}
    // xSegments[1] = {(0,2),(1,2)} {(1,2),(2,2)} {(2,2),(3,2)}
    // xSegments[2] = {(0,1),(1,1)} {(1,1),(2,1)} {(2,1),(3,1)}
    // xSegments[3] = {(0,0),(1,0)} {(1,0),(2,0)} {(2,0),(3,0)}

    for (y = (GRID_SIZE - 1); y >= 0; y--)
    {
        xSegments = (segment*)malloc((GRID_SIZE - 1) * sizeof(segment));
        if (!xSegments)
        {
            exit(-1);
        }
            
        xPaths[i++] = xSegments;

        j = 0;

        for (x = 0; x < (GRID_SIZE - 1); x++)
        {
            xSegments[j++] = { {x,y,x + 1,y},false };
        }
    }
}


void CreateYsegments(void)
{
    int x, y, i = 0, j;
    segment* ySegments;

    // ySegments[0] = {(0,3),(0,2)} {(0,2),(0,1)} {(0,1),(0,0)}
    // ySegments[1] = {(1,3),(1,2)} {(1,2),(1,1)} {(1,1),(1,0)}
    // ySegments[2] = {(2,3),(2,2)} {(2,2),(2,1)} {(2,1),(2,0)}
    // ySegments[3] = {(3,3),(3,2)} {(3,2),(3,1)} {(3,1),(3,0)}

    for (x = 0; x < GRID_SIZE; x++)
    {
        ySegments = (segment*)malloc((GRID_SIZE - 1) * sizeof(segment));

        if (!ySegments)
        {
            exit(-1);
        }

        yPaths[i++] = ySegments;

        j = 0;

        for (y = (GRID_SIZE - 1); y > 0; y--)
        {
            ySegments[j++] = {{x,y,x,y - 1},false};
        }
    }
}


int main(int argc, char *argv[])
{
    int WalksDone;
    int xWalks, yWalks;
    int TotalSteps, AvgSteps;
    int ctr,ctrmax=102,avg,avgmax=100;

    simple_rand.seed((unsigned int)time(0));

    // Compute Grids 10x10, 20x20, ... ,100x100

    for (ctr = 11; ctr < ctrmax; ctr += 10)
    {
        AvgSteps = 0;

        for (avg = 0; avg < avgmax; avg++)
        {
            GRID_SIZE = ctr;
            WalksDone = (GRID_SIZE * (GRID_SIZE - 1));

            TotalSteps = 0;

            xWalks = yWalks = 0;
            xFrom = yFrom = xTo = yTo = 0;

            CreateXsegments();
            CreateYsegments();

            do
            {
                TotalSteps++;

                GenerateRandomWalk();

                if (xWalks != WalksDone)
                {
                    PathsCheck(xPaths);
                    xWalks = PathsStats(xPaths);
                }
                if (yWalks != WalksDone)
                {
                    PathsCheck(yPaths);
                    yWalks = PathsStats(yPaths);
                }

            } while ((xWalks != WalksDone) || (yWalks != WalksDone));

            printf(""%ux%u Grid, Total Steps: %d\n"", GRID_SIZE - 1, GRID_SIZE - 1, TotalSteps);

            AvgSteps += TotalSteps;

            // Release memory....
            for (int i = 0; i < GRID_SIZE; i++)
            {
                free(xPaths[i]); xPaths[i] = NULL;
                free(yPaths[i]); yPaths[i] = NULL;
            }
        }

        printf(""%ux%u Grid, Average Steps: %d\n"", GRID_SIZE - 1, GRID_SIZE - 1, AvgSteps/avgmax);
    }

    return 0;
}","['stochastic-processes', 'random-walk', 'probability', 'euclidean-geometry']"
4018119,Proof of De la Vallée-Poussin's Test,"Here's what I'm trying to prove. Suppose that $A \subseteq \mathbb{R}^n$ and $J = [c,+\infty)$ . Let $f: A \times J \to \mathbb{R}^p$ be continuous and suppose that there exists a function $g: J \to [0,+\infty)$ such that: $$\forall (x,t) \in A \times J: \|f(x,t)\| \leq g(t)$$ Suppose that $\int_{c}^{\infty} g(t) \ dt$ is convergent. Then, $\int_{c}^{\infty} f(x,t) \, dt$ is uniformly convergent for $x \in A$ . Here's the definition of uniform convergence (I'm pretty sure that this is really just an extension of the definition of improper integrals on the real line). Again, let $f$ be as given above. Then, define $F(x) = \int_{c}^{\infty} f(x,t) \, dt$ . We say that $f$ is uniformly convergent for $x \in A$ iff: $$\forall \epsilon > 0: \exists D > c: x \in A \land d \geq D \implies \left\| F(x)-\int_{c}^{d} f(x,t) \right\| < \epsilon$$ Proof Attempt: Observe that for any fixed $x \in A$ , we have: $$\forall i \in \{1,2,\ldots,p\}: |f_i(x,t)| \leq \left\|f(x,t)\right\| \leq g(t)$$ $$\implies \forall d > c: \int_{c}^{d} |f_i(x,t)| \ dt \leq \int_{c}^{d} g(t) \ dt$$ Then, since $\int_{c}^{d} g(t) \ dt$ converges as $d \to \infty$ , it follows that $\int_{c}^{d} |f_i(x,t)| \ dt$ converges as $d \to \infty$ by comparison. Then, this implies that $\int_{c}^{\infty} f_i(x,t) \ dt$ converges and since the integral of each component function of $f$ converges, it follows that $\int_{c}^{\infty} f(x,t) \ dt$ converges. $\Box$ The thing that I'm somewhat worried about is if I'm missing something crucial over here. Like, I'm just wondering if I've overlooked something or if I would actually have to do a more formal argument using the definition directly. I'd appreciate it if someone could have a look at my working.","['real-analysis', 'multivariable-calculus', 'solution-verification', 'uniform-convergence', 'convergence-divergence']"
4018141,Cohomology ring of complex grassmanian as a quotient,"This is about the complex version of this question , I am interested in understanding the integral cohomology ring of $\mathrm{Gr}_k(\mathbb{C}^n)$ as the following quotient of the integral cohomology ring of $\mathrm{Gr}_k(\mathbb{C}^{\infty})$ : $$
H^*(\mathrm{Gr}_k(\mathbb{C}^n))\cong H^*(\mathrm{Gr}_k(\mathbb{C}^{\infty}))/\langle \bar{c}_{n-k+1},\dots,\bar{c}_n\rangle.
$$ Here the $\bar{c}_i$ are polynomials in the Chern classes $c_i$ of the tautological $k$ -plane bundle over $\mathrm{Gr}_k(\mathbb{C}^{\infty})$ , and are defined by the relation $$
c\bar{c}=1.
$$ (Recall that $H^*(\mathrm{Gr}_k(\mathbb{C}^{\infty}))\cong \mathbb{Z}[c_1,\dots,c_k].$ ) The approach suggested for the real case (with $\mathbb{Z}/2$ coefficients) in the linked question is to show that the inclusion $\mathrm{Gr}_k(\mathbb{C}^{n})\subset \mathrm{Gr}_k(\mathbb{C}^{\infty})$ induces a surjection $H^*(\mathrm{Gr}_k(\mathbb{C}^{\infty}))\to H^*(\mathrm{Gr}_k(\mathbb{C}^n))$ ; the polynomials $\bar{c}_{n-k+1},\dots,\bar{c}_n$ are zero in $H^*(\mathrm{Gr}_k(\mathbb{C}^n))$ , hence the above map induces a surjection from the quotient $H^*(\mathrm{Gr}_k(\mathbb{C}^{\infty}))/\langle \bar{c}_{n-k+1},\dots,\bar{c}_n\rangle \to H^*(\mathrm{Gr}_k(\mathbb{C}^n))$ ; use a dimension count to deduce that the latter map is also injective, hence an isomorphism. Question: Since we are working with integral cohomology, which is merely a ring (not a $\mathbb{Z}/2$ -vector space), my question is how one could carry out or alter step (3) to obtain injectivity. Thanks for the help. Any references are appreciated.","['algebraic-topology', 'grassmannian', 'algebraic-geometry', 'homology-cohomology', 'characteristic-classes']"
4018208,Matrix exponential for non-commutative operator entries of matrix,"I would like to find the matrix exponential $e^{iHt}$ of the Hermitian matrix $H$ where $$
H=\begin{pmatrix}
\delta& \sqrt{2}a & 0\\
\sqrt{2}a^\dagger &0& \sqrt{2}a\\
0 &\sqrt{2}a^\dagger&-\delta
\end{pmatrix}
$$ $$[a,a^\dagger]=a a^\dagger-a^\dagger a=1$$ $$[a,\delta]=[a^\dagger,\delta]=0.$$ The dagger $\dagger$ denotes complex conjugate. My thought is to make use of the definition of matrix exponential $e^{X}=\sum_{k=0}^{\infty} \frac{1}{k !} X^{k}$ and calculate $H^2$ and $H^3$ to find some pattern to exploit. For example, in the special case where $\delta=0$ , we can find a diagonal matrix $D$ $$
D=\begin{pmatrix}
4a^\dagger a+6 &0&0\\
0&4a^\dagger a+2&0\\
0&0&4a^\dagger a-2
\end{pmatrix}
$$ such that $H^{2n+1}=D^{n}H$ and $H^{2n+2}=D^{n}H^2$ , with which we can obtain a neat result of $e^{i H t}$ . However, it seems that no such diagonal matrix exists for $\delta \neq 0$ case. Are there any other ways to calculating matrix exponential like this with non-commuting entries? Any input is much appreciated!","['quantum-mechanics', 'noncommutative-algebra', 'linear-algebra', 'tensor-products']"
4018279,Suppose $f$ and $g$ are strictly convex functions and $f$ is increasing. Can $(f\circ g)^{\prime \prime}$ ever equal $0$?,"Edit: Ah, this seems to answer my concerns. Take that Spivak, you big cheater! Original post: This concerns a problem in Calculus by Michael Spivak. Specifically 3rd edition, Chapter 11 Appendix, Problem 5. I'll give the full problem for context. My question concerns the last part (c). Please note: this concerns strictly convex functions. Spivak's convention is for ""convex"" to mean ""strictly convex"" unless otherwise specified. Problem 4 (referenced in part (a)) shows that $f$ is convex on an interval if and only if for all $x$ and $y$ in the interval we have $$f(tx + (1-t)y)<tf(x) + (1-t)f(y)\text{, for }0<t<1.$$ This is not used for part (c) but it's included here for completeness. Chapter 11 Appendix, 5. (a) Prove that if $f$ and $g$ are convex and $f$ is increasing, then $f\circ g$ is convex. (It will be easiest to use Problem 4.) (b) Give an example where $g\circ f$ is not convex (c) Suppose that $f$ and $g$ are twice differentiable. Give another proof of the result of part (a) by considering second derivatives. For part (c) I have: $$(f\circ g)^{\prime}(x) = f^{\prime}(g(x))\cdot g^{\prime}(x)$$ $$(f\circ g)^{\prime\prime}(x) = f^{\prime\prime}(g(x))\cdot [g^{\prime}(x)]^2 + f^{\prime}(g(x))\cdot g^{\prime\prime}(x)$$ If $f$ and $g$ are convex, twice differentiable, and $f$ is increasing, we know that $f^{\prime} > 0$ , except possibly at the leftmost edge of the interval, if such a point exists. This is because $f^{\prime} \geq 0$ and $f^{\prime}$ is increasing. $[g^{\prime}]^2 > 0$ except possibly at a single point. $f^{\prime\prime}$ and $g^{\prime\prime}\geq 0$ . Furthermore, they cannot be $0$ over an interval. They can maybe be zero at distinct points? Taking this all together I see that $(f\circ g)^{\prime\prime} \geq 0$ . However, I don't think I've quite shown that it's greater than $0$ . Can $(f\circ g)^{\prime\prime} = 0$ at discrete points? I think it cannot vanish over any interval, as this would require $g^{\prime\prime}$ to be zero over the interval, which in turn means $g^{\prime}$ is constant. But the discrete points thing, I'm not sure about. The Answer Book solution says: (c) We have $$ (f\circ g)^{\prime} = (f^{\prime} \circ g)g^{\prime}$$ $$ (f\circ g)^{\prime\prime} = (f^{\prime\prime}\circ g) g^{\prime 2} + (f^{\prime}\circ g)g^{\prime\prime}$$ Since $f^{\prime\prime}, g^{\prime\prime}, g^{\prime} \geq 0$ it follows that $(f\circ g)^{\prime\prime} > 0$ if $f^{\prime} > 0$ . That last sentence seems false...","['calculus', 'convex-analysis', 'derivatives']"
4018317,"Gaussian with prior $p(\mu, \Sigma) \propto |\Sigma|^{-(d+1)/2}$. Why is the posterior $\Sigma \mid y \sim \text{Inv-Wishart}(S^{-1})$?","According to Gelman et al book , page 73, if $p(\mu, \Sigma) \propto |\Sigma|^{-(d+1)/2}$ then $\Sigma \mid y \sim \text{Inv-Wishart}(S^{-1})$ with $n-1$ degrees of freedom for $$S = \sum_i (y_i - \bar{y})(y_i - \bar{y})^T$$ I cannot get the inverse, $S^{-1}$ , am I missing something please? Here is how I do it: By construction any matrix $\sum_i X_i X_i^T$ will have the Wishart distribution if $X$ is drawn from the multivariate normal distribution (with known covariance matrix). Hence $S$ will follow the Wishart with $n-1$ degrees of freedom (conditional on $\Sigma$ ): $$S \sim W_{n-1}(\Sigma)$$ with density: $$
\operatorname{p}(S \mid \Sigma) =  \frac{  |S|^{  \frac{1}{2}(n-d-2)  } \exp\Big[ -\frac{1}{2} \operatorname{Tr}(\Sigma^{-1} S) \Big]  }{  2^{\frac{1}{2}(n-1)d }  |\Sigma|^{(n-1)/2} \Gamma_d(\frac{n-1}{2})    }
$$ From Bayes theorem: $p(\Sigma \mid S) \,\, p(S) = p(S \mid \Sigma) \,\, p(\Sigma)$ and since $S\sim W_{n-1}(\Sigma)$ we get: \begin{align}
 \operatorname{p}(\Sigma \mid S, \text{data})  	& \propto\operatorname{p}(S \mid \Sigma) \cdot |\Sigma|^{-(d+1)/2}  \nonumber \\
			& \propto |\Sigma|^{-(n+d)/2} \exp\big[ -\frac{1}{2} \operatorname{Tr}(\Sigma^{-1} \, S)\big] \nonumber
\end{align} Isnt the last one the density (up to a scalar) of the Inv-Wishart( $S$ )? According to the book, it should have been the Inv-Wishart( $S^{-1}$ ) instead. What am i doing wrong please?","['statistics', 'bayesian', 'gaussian', 'normal-distribution']"
4018332,Is this Perfect Binary Tree Countably Infinite or Uncountably Infinite?,"Given a perfect binary tree which at a certain fixed level has infinitely many leaves, hence each leaf at that fixed level has infinitely many ancestors. From that fixed level the tree also extends to infinite height. Are the nodes of this tree countably infinite or uncountably infinite? I know that a rooted binary tree, even if extended to a height of infinity is countably infinite; just start at the root and enumerate level by level. However, I cannot imagine a way to count the nodes of this tree or to apply the idea that the union of countably infinite subtrees is countable. Thus, I’m leaning towards it being uncountably infinite but have serious doubts. How can a tree look like that? Imagine that instead of the tree simply growing in height it is also expanding sideways as shown below, so it is infinitely high, infinitely wide and infinitely deep. Getting infinitely wide is illustrated below.","['graph-theory', 'trees', 'set-theory', 'discrete-mathematics']"
4018337,Find the area of a regular polygon,I found a quiz on advanced trigonometry and geometry online and I was doing it for fun and it asks Prove that for any regular polygon with side length $S$ and number of sides $N$ that $A =  S N \cot(\pi/N)/4$ I have been stumped for 30 minutes now. Can somebody help?,"['trigonometry', 'area', 'geometry', 'polygons']"
4018357,Question about integral on the complex plane,"That is the infernal integral: $\int_{|z|=2}{\frac{e^{z+\frac{1}{z}}}{1-z^2}}dz$ I tried to solve it with residuals, but I can't find the expression of the function in its Laurent form.
Sorry if the question is already posted, i don't speak the language well yet.","['complex-analysis', 'complex-integration', 'residue-calculus']"
4018377,$\int_{\Omega} f \psi = 0$ for every $\psi$ which is zero at $\partial \Omega$ imples $f=0$,"This is a generalization of my previous question . Let $I=[t_{0},t_{1}]\subset \mathbb{R}$ be fixed and $\Omega \subset \mathbb{R}^{n}$ . Let $\psi$ and $f$ be sufficiently differentiable (we can assume it to be smooth) and let us assume that $\psi(t_{0},x)= \psi(t_{1},x) = 0$ for every $x \in \mathbb{R}^{n}$ and $\psi(t,x)|_{\partial \Omega} = 0$ for every $t \in I$ . If: $$\int_{I}\int_{\Omega}f(t,x)\psi(t,x)dxdt = 0$$ for every $\psi$ satisfying the above conditions, is it true that $f(t,x) \equiv 0$ ?","['integration', 'multivariable-calculus', 'analysis']"
4018407,How to evaluate $\int _0^{\frac{1}{2}}\frac{\ln \left(x\right)\ln \left(1-x\right)\ln \left(1+x\right)}{1+x}\:dx$,"I want to evaluate: $$\int _0^{\frac{1}{2}}\frac{\ln \left(x\right)\ln \left(1-x\right)\ln \left(1+x\right)}{1+x}\:dx,$$ but I don't see how can I achieve so. My attempts so far have been rewriting the integral using algebraic identities such as: $$ab=\frac{1}{2}a^2+\frac{1}{2}b^2-\frac{1}{2}\left(a-b\right)^2=\frac{1}{4}\left(a+b\right)^2-\frac{1}{4}\left(a-b\right)^2,$$ that yield other integrals like: $$\int _0^{\frac{1}{2}}\frac{\ln \left(x\right)\ln ^2\left(1-x\right)}{1+x}\:dx,\:\int _0^{\frac{1}{2}}\frac{\ln \left(x\right)\ln ^2\left(\frac{1-x}{1+x}\right)}{1+x}\:dx.$$ Normally the beta function and expanding terms into series is used to deal with these kind of integrals yet neither can be used because of the upper bound. What else can be done in order to compute the main integral? Thanks.","['integration', 'definite-integrals']"
4018431,Prove that sin A/2 * sin B/2 * sin C/2 = r/4R,"The other day I came across an identity in the book ""Problems from the Book"" and it was presented as well known: $$\sin \frac{A}{2} \cdot \sin \frac{B}{2} \cdot \sin \frac{C}{2} = \frac{r}{4R}$$ However I wasn't familiar with thee identity so I tried proving it. Here is part of my attempt in solving this problem: I first rewrote $\sin \frac{A}{2} \cdot \sin \frac{B}{2} \cdot \sin \frac{C}{2}$ as $\frac{r^3}{AI\cdot BI \cdot CI}$ (where I is the incenter of $\bigtriangleup ABC$ ). Then I tried using the fact that [ABC] =abc/4R (where [ABC] represents the area of $\bigtriangleup ABC$ )which allowed me to rewrite the equation as $\frac{r^2}{AI\cdot BI \cdot CI} = \frac{[ABC]}{abc}$ . I tried various things at this point but none of my attempts were successful... Does anyone have a proof of this identity?",['trigonometry']
4018463,"what does the professor mean by ""the convergence to the limit point is fast?""","I am considering the following facility location problem: Let $S$ be a subset of interval $[0,1]$ , which denotes the set of positions of agents . With a little abuse of notation, $S$ also denotes the set of all agents. For instance, $S=\{1, \frac{1}{2}, \frac{1}{3}, \cdots\}$ indicates that there is an agent in $1, \frac{1}{2}, \frac{1}{3}, \cdots$ , respectively. Now we need to locate a facility on the real line(to serve all the agents). Suppose the $y\in \mathbb{R}$ is the location of the facility, then the cost of agent $x\in S$ is definte as $cost(x, y):=|x-y|$ . The total cost is the sum of all agents' cost, i.e., $\sum_{x\in S} |x-y|$ . In a discussion with a professor by email, he made the following three observations and asked me to check their correctness: If $y$ is not a limit point of $S$ then the total cost is infinite. The total cost is finite iff $y$ is the only limit point of $S$ and the convergent to the limit point is fast . Suppose there are $m$ facilities, define the cost of an agent to be the distance to the closest facility. Then the total cost is bounded iff each facility is in a limit point of $S$ and the convergence to each facility is fast . I understood his observations except the ""convergence to the limit point is fast"". And I proposed $S=\{1, \frac{1}{2}, \frac{1}{3},\cdots\}$ as an counter example to observation $2$ since the only limit point here is $0$ but the total cost $\lim_{n=1}^{\infty}\frac{1}{n}$ is unbounded. He argued that it is not a counter example because the convergence is slow . I've learnt the concepts of the rate of convergence and the order of convergence , but what does he mean by the convergence is fast or slow? I think there must be some missing prerequisite knowledge I should know first.","['limits', 'real-analysis']"
4018471,How to get collection of points inside polygon without holes?,I have 2D polygon (integer vertices) without holes. I would like to have a collection of all the points (integer coordinates) inside polygon. Can I do it faster that checking all points within polygon's boundary and applying https://math.stackexchange.com/a/3441442/725387 for each of them? Can I apply any precomputation on polygon?,"['computational-geometry', 'geometry', 'polygons', 'algorithms']"
4018491,Ideal of height $>1$ containing no non-zero prime ideals.,"Edit: Badam Baplan gives a remarkable example below, which answers the question completely. I would still appreciate any other examples that others may come up with; in particular, is an example still possible if we ask for $R$ to be Noetherian? Let $R$ be a (commutative, unital) ring and $I<R$ an ideal. Recall that we define $$\operatorname{ht}I=\min\{\operatorname{ht}P:P\in\operatorname{Spec}R,P\geqslant I\},$$ where $\operatorname{ht}P$ is defined in the usual way for a prime ideal $P$ . Is there a nice example of an integral domain $R$ and an ideal $I$ such that (i) $I$ contains no non-zero prime ideals, and (ii) $\operatorname{ht}I>1$ ? Note: by Krull's height theorem , if $R$ is Noetherian then $I$ cannot be principal. If we drop the condition that $R$ is an integral domain, then we can get examples where $\operatorname{ht}I$ is arbitrarily large. For instance, let $F$ be your favorite field, and define $A$ to be the polynomial ring $F[x_1,\dots,x_n]$ . Choose any non-zero ideal $M\leqslant A$ , with some $o\in M\setminus\{0\}$ of minimal degree. (For later, note that $o\notin x_1M+\dots+x_nM$ ; call this fact $(\star)$ .) Now, consider the ring structure on the product $R:=A\times M$ defined by $(a,m)+(b,n)=(a+b,m+n)$ $(a,m)\cdot(b,n)=(ab,an+bm)$ for all $a,b\in A$ and $m,n\in M$ . Note that every element $(0,m)$ is nilpotent, so any prime ideal of $R$ must contain $0\times M$ . Conversely, if $P$ is a prime ideal of $A$ , then $P\times M$ is a prime ideal of $R$ . With this in mind, consider the ideal $I<R$ generated by the elements $(x_i,0)$ for $1\leqslant i\leqslant n$ . First note that $I$ contains no prime ideals; indeed, one can explicitly compute $I$ to be the product $$(x_1A+\dots+x_nA)\times(x_1M+\dots +x_nM),$$ where both direct factors are considered as ideals of $A$ . In particular, by fact $(\star)$ , we have $(0,o)\notin I$ , and so (by the remark above, since $(0,o)$ is nilpotent), $I$ cannot contain any prime ideal. On the other hand, consider the prime ideal $P:=\langle x_1,\dots,x_n\rangle\times M>I$ . This is the unique minimal prime lying above $I$ , since $P=I+(0\times M)$ and every prime must contain $0\times M$ . However, we have $\operatorname{ht}P=n$ , since $$0\times M<\langle x_1\rangle\times M<\langle x_1,x_2\rangle\times M<\dots<P$$ is a strictly ascending chain of primes below $P$ . Thus, since $P$ is the unique minimal prime above $I$ , we have $\operatorname{ht}I=n$ . One can extend this example in the natural way to find an example where $\operatorname{ht}I=\infty$ . So this resolves the question completely if we do not require $R$ to be an integral domain. However, I'm struggling to find an example where $R$ is an integral domain. Can anyone think of a nice example? I tried attempting to consider the example above as a quotient of an appropriate polynomial ring, but didn't make any progress. My thinking was that we could perhaps find a desirable prime lying below the kernel of the projection map, and then quotient by that to find a domain with some similar behavior. However, this doesn't seem to work out very nicely. As a smaller follow-up question, what is the geometric significance (if any) of such a ring?","['ring-theory', 'abstract-algebra', 'commutative-algebra']"
4018502,Probability: Conditioning equations,"I saw in many different context that any probability result that is true for unconditional probability remains true if everything is conditioned on some event. For instance, consider the following equation: $$P(B\cap C)=P(B)P(C|B).$$ Then by conditioning both sides on $A$ , we get $$P(B\cap C|A)=P(B|A)P(C|B\cap A).$$ However, it is possible to find counterexamples as given here . So I was wondering when this conditioning the both sides of equality operation is valid. I am, in particular, interested   in the following equality: $$P(X_4, X_3, X_2, X_1)=P(X_4 \mid X_3, X_2, X_1)\cdot \mathrm P(X_3 \mid X_2, X_1)\cdot \mathrm P(X_2 \mid X_1)\cdot \mathrm P(X_1).$$ Is it possible to condition both sides on $A$ and get $$P(X_4, X_3, X_2, X_1|A)=P(X_4 \mid X_3, X_2, X_1,A)\cdot \mathrm P(X_3 \mid X_2, X_1,A)\cdot \mathrm P(X_2 \mid X_1,A)\cdot \mathrm P(X_1|A)$$ here? Many thanks in advance.","['conditional-probability', 'measure-theory', 'probability']"
4018532,Rectangle in polar coordinates,"Suppose that we have $D=[-a,a]\times [-b,b]\subseteq \mathbb{R}^{2}$ . How can I transform that region into a new region described by polar coordinates? If we start by making a graph, we can see that the graph will be a rectangular region that can be partitioned by the diagonals of the rectangle into 4 isosceles triangles. So the region in polar can be written as 4 regions in polar coordinates and one of them is of the form $$D_{1}=\{(r,\theta): \theta\in [-\arctan(b/a),+\arctan(b/a)]; r\in [0,a/\cos(\theta)] =D_{3}$$ $$D_{2}=\{(r,\theta): \theta\in [-\arctan(a/b),+\arctan(a/b)]; r\in [0,b/\cos(\theta)]=D_{4}$$ Is it correct? Would the other regions have a similar scheme or should I change the approach?",['multivariable-calculus']
4018534,Example of Non-Measurable Bijection from $\mathbb R \to \mathbb R$,"The title is fairly self explanatory. I am looking for an example of a function from $\mathbb R\to\mathbb R$ that is bijective, but not measurable with respect to Lebesgue measure, if such an example exists.","['measure-theory', 'lebesgue-measure', 'measurable-functions', 'real-analysis']"
4018535,Taylor expansion of $\frac{ \cos( \ln (n+1))}{(n+1)^{1/2}}$,Taylor Series Expansion of $$\frac{ \cos( \ln (n+1))}{(n+1)^{1/2}}$$ My try- $$\cos(\ln (n+1))= \cos\left (\ln \ n+ \ln\left(1+\frac{1}{n}\right)\right)$$ $$=\cos (\ln\  n) \cos\left(\ln\left(1+\frac{1}{n}\right)\right)-\sin(\ln \ n)\sin\left(\ln \left(1+\frac{1}{n}\right)\right) $$ How to proceed?,"['real-analysis', 'calculus', 'taylor-expansion', 'sequences-and-series', 'trigonometry']"
4018537,Conditional Probability vs Dependent Events,"I'm conceptually/intuitively confused about when we would use the joint probability (multiplication rule) versus a conditional probability, specifically when the dependent event has no chance of occurring without the other event. Here's an example that illustrates my confusion: Suppose we have a weird city, where there's a 20 percent chance of rain (so a 80% chance of any other weather). Now suppose that it can only rain frogs when it rains, and there's a 10% chance of frogs. Why can we not use bayes rule to model: $$Pr(frogs | rain) = \frac{Pr(rain | frogs)\cdot Pr(frogs)}{Pr(rain)} = \frac{1 \cdot 0.1}{0.2}$$ I know the correct way of doing it would be the multiplication rule, but why can we not use a conditional probability? We know that the probability of raining frogs is 0.1 because it cannot occur in any other scenario other than when it rains, and if there are raining frogs, we must have rain so $Pr(rain | frogs)=1$ . And we also have $Pr(rain)=0.2$ , so it seems like we have everything we need for conditional probability. The correct answer would of course be $0.2\cdot0.1=0.02$ . What am I missing aside from the nonsensical results? Edited for sensical numbers, but assume that the probability of raining frogs is just the proportion of days on which it rains.","['conditional-probability', 'probability-theory', 'independence', 'bayes-theorem', 'probability']"
4018562,Prove $\lim\limits_{n\to\infty}(\frac{a}{n})=0$,"I'm very new to the epsilon definition of a limit and I was hoping I could get some feedback to see if I have the right idea. For any $a\in\mathbb{R}$ , $$\lim\limits_{n\to\infty}\left(\frac{a}{n}\right)=0$$ Proof: Let $\epsilon >0$ . Choose $N>\frac{|a|}{\epsilon}$ . Then for all $n\geq N$ , since $n\geq N>\frac{|a|}{\epsilon}$ , we have $$n>\frac{|a|}{\epsilon}\;\;\;\Rightarrow\;\;\;\epsilon >\frac{|a|}{n}$$ Therefore, $$\left|\frac{a}{n}-0\right|=\frac{|a|}{n}<\epsilon$$ $\blacksquare$","['solution-verification', 'sequences-and-series', 'real-analysis']"
4018603,"Showing the sequence $\sqrt{2}, \sqrt{2\sqrt{2}}, \sqrt{2\sqrt{2\sqrt{2}}}, \dots$ tends to $2$ using the Epsilon-Neighbourhood definition","I am given the sequence $$a_{n+1} = \sqrt{2 a_n}, \quad a_1 = \sqrt{2}.$$ That is, the sequence $$ \sqrt{2}, \sqrt{2\sqrt{2}}, \sqrt{2\sqrt{2\sqrt{2}}}, \dots$$ I am aware of using the recursive method to find the limit: setting $x = \sqrt{2x}$ and getting $x = 2$ , rejecting $x = 0$ due to the sequence being monotone and positive. I now want to show that the limit of this sequence is $2$ using the epsilon-neighbourhood definition for a convergent series: Let $(a_n)$ be a sequence that converges to a real number $a$ . Then, for every number $\epsilon > 0$ , there exists a number $N \in \mathbb{N}$ such that for all $n \geq N$ , $|a_n - a| < \epsilon$ . I take the logarithm on both sides and arrive at $$ \left| \left( \frac{1}{2} + \frac{1}{4} + \cdots + \frac{1}{2^n} \right) \ln 2 - \ln 2 \right|  < \epsilon. $$ Using triangle inequality, $|x - y| \geq |x| - |y|$ , I arrive at $$ \left| \left( \frac{1}{2} + \frac{1}{4} + \cdots + \frac{1}{2^n} \right) \right| - |\ln 2| < \epsilon. $$ Add $\ln 2$ to both sides $$ \left| \left( \frac{1}{2} + \frac{1}{4} + \cdots + \frac{1}{2^n} \right) \right| < \epsilon + \ln 2. $$ The left hand side can be rewritten as a sum of $n$ terms in a geometric series with first term $\frac{1}{2}$ and common ratio $\frac{1}{2}$ , $$ \frac{\frac{1}{2} \left( 1 - \left( \frac{1}{2} \right)^n \right)}{1 - \frac{1}{2}} = 1 - \frac{1}{2^n} < \epsilon + \ln 2. $$ I am unsure of how to proceed beyond this point.","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
4018612,Proof for sum and difference of angles in terms of tan inverse,"We have the following formulas for sum of angles when angles are in terms of tan inverse: $\tan^{-1}(x)+\tan^{-1}(y)$ = $\tan^{-1}((x+y)/(1-xy))$ ,  if $xy<1$ $\pi+\tan^{-1}((x+y)/(1-xy))$ ,  if $x>0,y>0$ and $xy>1$ $-\pi +\tan^{-1}((x+y)/(1-xy))$ ,  if $x<0,y<0$ and $xy>1$ I tried it like this :
Let $\tan^{-1} (x)=A$ and $\tan^{-1}(y)=B$ where $A,B \in(-(\pi/2),(\pi/2))$ So , $\tan(A+B)=(\tan A+\tan B)/1-\tan A \tan B=(x+y)/1-xy$ $\tan^{-1}((x+y)/(1-xy))=\tan^{-1}(\tan(A+B))$ let $A+B=\alpha$ = $\alpha+\pi$ , $-\pi<\alpha<-\pi/2$ $\alpha,  -\pi<\alpha <\pi/2$ $\alpha-\pi,  \pi/2<\alpha <\pi$ Further how to proceed to get the condition xy><1...?","['trigonometry', 'inverse-function', 'inverse']"
4018671,Multivariate residues in simple cases,"I have been looking at residues of multivariate functions and found there are quite a few difficulties (see e.g. Multivariate Residue Theorem? or Multivariate/multidimensional residues ). In the literature, this is discussed in the context of manifolds, 1-forms and currents. Unfortunately, I am not an expert on manifolds. Question: Are there ""simple rules"" deriving from the general treatment that can be applied in more basic cases. I am thinking of multivariate functions $f(x,y,z, ...)$ with simple poles at equal points $x=y,~ x=z, ...$ , where I would like to evaluate the residue at multiple, coinciding points $x=y=z$ as consecutive residues $\text{Res}_{x=y} \text{Res}_{y=z} \cdots$ in a consistent way. Example: Consider the function $f(x,y,z) = \frac{1}{(x-y)(x-z)}$ defined on $\mathbb{C}^3$ . It has singularities on and the 1-dimensional subspaces $\{(x,y,z) | x=y \}$ and $\{ (x,y,z) | x=z\}$ which intersect at $x=y=z$ . Computing the residue on the intersection can be done through consecutive application of residues: $$
\text{Res}_{y=z} \text{Res}_{x=y} \frac{1}{(x-y)(x-z)} = \text{Res}_{y=z} \frac{1}{(y-z)} = 1. 
$$ However, exchanging the residues leads to a wrong result: $$
\text{Res}_{x=y} \text{Res}_{y=z} \frac{1}{(x-y)(x-z)} = 0.
$$ Is there a procedure that tells me how to correctly take certain residues or at least relate different combinations of residues which give the same result? (For example $\text{Res}_{y=z} \text{Res}_{x=y}$ and $\text{Res}_{z=x} \text{Res}_{y=x}$ in the previous example) Background: In quantum field theory, amplitudes (vacuum expectation values of time-ordered products of fields) are meromorphic functions in $\mathbb{C}^k$ . Poles correspond to the temporary fusion of particles and higher-order poles at the intersection of more than two points (which I would like to evaluate as consecutive residues) appear when there are more complicated composite particles. I appreciate any help or literature recommendation!","['complex-analysis', 'multivariable-calculus', 'residue-calculus']"
4018693,How to find derivative of $\int_0^{\sin x} (1+t)^{\frac{1}{t}} dt$,"I am asked to solve this question:
' Which one is the higher order infinitesimals when $\mathbf{x \rightarrow 0 \, \int_0^{\sin x} (1+t)^{\frac{1}{t}} dt}$ ' or $\mathbf{x^2}$ . I know that:I have to solve $\lim_{x \rightarrow 0}\frac{\int_0^{\sin x} (1+t)^{\frac{1}{t}} dt}{x}$ by using L 'Hospital's rule and compare the result with $x^2$ But I cant find the derivative. I have recited that the derivative of $\int_{φ(x)}^{ψ(x)}f(t)dt$ (if x is not in f(t)) is $f[φ(x)]φ'(x)-f[(ψ)]ψ'(x)$ , without actually knowing how it comes. But for now, this equation seems impossible since I cannot get $(1+0)^{\frac{1}{0}}$ , I don't think $\lim (1+0)^{\frac{1}{0}}$ should be right, since the hint said the $\int_0^{\sin x} (1+t)^{\frac{1}{t}} dt$ ~ $ex$ So what should I do? Is the equation I have recited succeed all the time?","['limits', 'derivatives']"
4018796,Compute the limit of the sequence $x_n=(2-\sqrt{2})(2-\sqrt[3]{2})...(2-\sqrt[n]{2})$,"At the end of the book where I got the problem it says that the limit is $0$ ; therefore, I have tried to majorize with a sequence having also limit $0$ . Then I have looked at the series obtained by taking $\log(x_n)$ and trying to prove that it goes to $-\infty$ .","['limits', 'sequences-and-series']"
4018834,Uniform distribution on the unit sphere rotated by a random orthogonal matrix,"Question 1 . Let $u\in \mathbb{R}^n $ be a random vector uniformly distributed on $\mathbb{S}^{n-1}$ , and $T\in \mathbb{R}^{n\times n}$ be a random orthogonal matrix. If $u$ and $T$ are independent , is $Tu$ uniformly distributed on $S^{n-1}$ and statistically independent of $T$ ? I get this question when thinking about the following one. Question 2 . Let $u, v\in\mathbb{R}^n$ be two independent random vectors, and $u$ be uniformly distributed on $\mathbb{S}^{n-1}$ . Consider the inner product $u^\top v$ . Take a constant vector $v_0\in \mathbb{S}^{n-1}$ . It seems that $u^\top v$ has the same distribution as $u^\top v_0$ ; $u^\top v$ and $v$ are statistically  independent. Is this true? Towards a positive answer to Question 2, we let $T$ be the Housholder matrix such that $Tv = v_0$ . Note that $T$ is independent of $u$ . Then $$
u^\top v = u^\top (T^\top v_0) = (Tu)^\top v_0.
$$ If the answer to Question 1 is yes, then $Tu$ and $u$ are identically distributed, and $Tu$ is independent of $v$ , and hence the answer to Question 2 is yes. (BTW, are Question 1 and Question 2 equivalent?) Any comments or criticism will be appreciated. Thank you. (A different but related question: $X$ is independent of $\mathcal{G}$, $f(X ,Y)$ is independent of $Y$, $Y$ is $\mathcal{G}$-measurable, then $f(X,Y)$ is independent of $\mathcal{G}$? )","['independence', 'haar-measure', 'random-matrices', 'probability-theory', 'random-variables']"
4018900,Finding the value of $ax^4+by^4$,"If $\quad a+b=23 , \quad ax+by=79,\quad ax^2+by^2=217,\quad
 ax^3+by^3=691\quad$ find the value of $ax^4+by^4$ . Here is my attempt: $$(a+b)(x+y)=ax+by+ay+bx\rightarrow 23(x+y)=79+(ay+bx)$$ $$(ax+by)(x+y)=ax^2+by^2+axy+bxy\rightarrow79(x+y)=217+23 xy$$ In each equation I have two unknowns it seems that doesn't work.","['contest-math', 'algebra-precalculus', 'polynomials', 'recurrence-relations']"
4018905,"$X$ is independent of $\mathcal{G}$, $f(X ,Y)$ is independent of $Y$, $Y$ is $\mathcal{G}$-measurable, then $f(X,Y)$ is independent of $\mathcal{G}$?","Let $(\Omega, \mathcal{F}, P)$ be a probability space, $\mathcal{G}\subset \mathcal{F}$ be a sigma algebra, $X, Y : \Omega \to \mathbb{R}^n$ be random vectors, and $f$ be a measurable function on $\mathbb{R}^{2n}$ .
Suppose that $X$ is independent of $\mathcal{G}$ , $f(X ,Y)$ is independent of $Y$ , and $Y$ is $\mathcal{G}$ -measurable. Is it true that $f(X,Y)$ is independent of $\mathcal{G}$ ? Motivation: This question arises from a randomized algorithm. In this algorithm, each iteration receives some randomness that is independent of the previous iterations. In my question, $\mathcal{G}$ indeed represents the randomness of the algorithm up to iteration $k$ , $Y$ is a vector generated by iteration $k$ , $X$ is some new randomness injected into the algorithm at iteration $k+1$ , and $f(X,Y)$ is a quantity computed from $X$ and $Y$ . It turns out that $f(X,Y)$ is statistically independent of $Y$ . I would like to prove that $f(X,Y)$ is independent of the first $k$ iterations, which will be interesting and convenient. Any comments or criticism will be appreciated. Thank you. A related question: Uniform distribution on the unit sphere rotated by a random orthogonal matrix .","['stochastic-analysis', 'independence', 'stochastic-processes', 'probability-theory', 'probability']"
4018936,"How to take the directional derivative of an integral over $u$ from $(x,y)$ to $(1,1)$","Please consider the following function $$
v(x,y) = \int_{(x,y)}^{(1, 1)}u\,dS
$$ $v(x,y)$ is the integral along the straight line from $(x,y)$ to $(1, 1)$ . I'm wondering how I can take the directional derivative in the direction of the vector from $(x,y)$ to $(1, 1)$ . Let's say that the vector going from the origin through $(x,y)$ and through $(1, 1)$ is called $\beta$ . How do I take the directional derivative in the direction of $\beta$ at the point $(x,y)$ ? Intuitively I would say that $$
\beta\cdot\nabla v(x,y) = - u(x,y)
$$ but I'm not sure how I can show this rigorously.","['integration', 'multivariable-calculus', 'derivatives']"
4019097,"If a subset of the square grid can be tiled by $1\times n$ rectangles for every $n$, can it be tiled by infinite rays?","Suppose that we have some set $S$ of grid-aligned squares in the plane; equivalently, we can think of our set as $S\subset \mathbb{Z}^2$ . Suppose that for every positive integer $n$ , $S$ can be tiled by disjoint copies of a $1\times n$ rectangle (possibly rotated). Is it necessarily the case that $S$ can be tiled by congruent copies of an infinite ""ray"" of squares, i.e., a region congruent to the set $\{(k,0)\ |\ k\ge0\}$ ? For example, the region given by removing from $\mathbb{Z}^2$ the points $(0,0), (1,1)$ , and $(-1,2)$ can be tiled by every $1\times n$ rectangle, and also by infinite rays, as shown: I'd like to say that this follows from some kind of compactness argument, but my attempts to apply such reasoning ran into trouble (I can't rule out that the $1\times n$ tilings have their endpoints move away from the origin without a well-defined limiting behavior). Any thoughts on how to prove this (or a counterexample, if my intuition is badly wrong)? I believe the same statement should hold in $\mathbb{Z}^n$ with $1\times1\times\ldots\times1\times n$ tiles and the same kind of rays; if the original statement proves easy to show, I would be interested in this generalization. As a remark, the converse is obviously true, since the infinite ray can be tiled by any $1\times n$ rectangle.","['polyomino', 'logic', 'geometry', 'tiling']"
4019139,Strong law of large numbers - Continuous martingales - Reference request,"Let $(\Omega, \mathcal F P)$ be a probability space with a filtration $\mathcal F_t$ and $M = (M_t,t\geq 0)$ be a real-valued continuous $\mathcal F_t$ -martingale such that its quadratic variation satisfies $\langle M\rangle_\infty = \infty$ a.s. Then, the strong law of large numbers for martingales yields $$
\lim_{t\to\infty} \frac{M_t}{\langle M\rangle_t}=0,
$$ a.s. (see e.g. Lipster & Shirayev Theory of Martingales , Corollary 1.1, p. 144). I'm looking for a reference for this result, but in the case of vector-valued continuous martingales. In particular, let $M$ be a vector-valued $\mathcal F_t$ -martingale (with values in $\mathbb R^d$ ). In this case, the quadratic variation $\langle M \rangle$ is defined as the unique $Q = (Q_t, t \geq 0)$ with values in $\mathbb R^{d\times d}$ such that $$
M_t \otimes M_t - Q_t
$$ is an $\mathcal F_t$ -martingale (see e.g. Pavliotis & Stuart, Multiscale Methods: Averaging and Homogenization , Definition 3.18, p. 46). What can we say in this case? For example, if $\langle M \rangle_t$ is a non-singular (thus in this case symmetric positive definite) matrix a.s. for all $t \geq 0$ and such that $\|\langle M\rangle_\infty\| = \infty$ a.s., can we say that $$
\lim_{t\to\infty} \langle M \rangle_t^{-1} M_t = 0, \qquad \qquad (1)
$$ a.s. in $\mathbb R^d$ ? Example I give a simple example of a martingale I am interested in. Let $W$ be a one-dimensional Wiener process with natural filtration $\mathcal F_t$ and let $\beta = (\beta_t, t\geq 0)$ be a $\mathcal F_t$ -adapted stochastic process with values in $\mathbb R^d$ and components $\beta_t = (\beta_t^{1}, \ldots, \beta_t^{d})^\top$ . Then consider the $\mathcal F_t$ -martingale $$
M_t = \int_0^t \beta_s \, \mathrm{d} W_s = \begin{pmatrix}\int_0^t \beta_s^1 \, \mathrm{d} W_s, \ldots, \int_0^t \beta_s^d \, \mathrm{d} W_s \end{pmatrix}^\top.
$$ The quadratic variation of $M$ satisfies (by Itô isometry) $$
\langle M \rangle_t=\int_0^t \beta_s \beta_s^\top \, \mathrm{d} s.
$$ Can we conclude something in the line of $(1)$ ?","['martingales', 'law-of-large-numbers', 'quadratic-variation', 'probability-theory', 'stochastic-calculus']"
4019148,show that $\lim_{n\to+\infty}\frac{1}{n}\sum_{k=0}^{n}f(x_{k})$ is exists,"let $f:[0,1]\to R^{+}$ real-valued continuous functions,and such $$\int_{0}^{1}f(x)dx=2019,~~\int_{0}^{1}f^2(x)dx=20181027$$ (1):show that:there exists unique sequence $x_{0},x_{1},\cdots,x_{n}\in [0,1]$ ,such $x_{0}<x_{1}<\cdots<x_{n}$ and for any postive integer $k=1,2,\cdots,n$ .such $$\int_{x_{k-1}}^{x_{k}}f(t)dt=\dfrac{1}{n}\int_{0}^{1}f(t)dt$$ (2):and show that $$\lim_{n\to+\infty}\dfrac{1}{n}\sum_{k=0}^{n}f(x_{k})$$ is exists.and find this value. I can do it $(1)$ exists.I think it is First mean value theorem for integration。but How to this sequence is unique. How to solve this (2),if this limt has exists.it seem use Stolz-Cesaro's Lemma: $$\lim_{n\to+\infty}\dfrac{1}{n}\sum_{k=0}^{n}f(x_{k})=\lim_{n\to\infty}f(x_{n})$$ this problem is my teacher gave me the exercise, these two problems I can not solve all , so I want to ask the teacher here,Thanks","['integration', 'limits']"
4019186,Integer solution to $x^4 + x^3 = y^4 +7$,"Find an integer solution or show there are none of $$x^4+x^3=y^4+7$$ I have found using python that there are no solutions for x, y less than 100 but also that the equation has at least one solution modulo n for every n less than 100 so I can't attack in the usual way by showing it has no solutions mod n for some n. Could someone suggest an alternate method/ approach I could use? (not looking for a straight solution just some hints or tips)","['number-theory', 'discrete-mathematics', 'polynomials', 'elementary-number-theory']"
4019190,Riemann and Ricci tensor,"Let $(M,g)$ be a smooth manifold and $f:M \rightarrow \mathbb{R}$ a smooth function. Can we get some expression of: $$ \partial_k f g^{jh} R^k_{hij}$$ in terms of the Ricci tensor?
(I use the notations $R^a_{cdb} \partial_a = R(\partial_c, \partial_d) \partial_b$ and $R_{bd}= R^c_{bcd}$ ) In a paper, I have seen that $$\partial_k f g^{jh} R^k_{jih}= \partial_j fR^j_i$$ I have the following ansatz: $$\partial_k f g^{jh} R^k_{hij} =  \partial_k f  g^{jh} g^{lk} R_{hijl}
=- \partial_k f  g^{jh} g^{lk} R_{ihjl}=-\partial_k f  g^{jh} g^{lk}  g_{hl}R^h_{ihj} \\
=-\partial_k f  g^{jh} \underbrace{g^{lk}  g_{hl}}_{= \delta_{kh}}R_{ij} = \partial_h f  g^{jh} R_{ij} = \partial_h f   R^j_i
$$ I pretty sure that the first $=$ is correct but the third $=$ just looks wrong to me, because there are three $h$ s. Can someone help me here? Thanks in advance!","['tensors', 'semi-riemannian-geometry', 'differential-geometry']"
4019288,"Is it silly to write $\phi : [a,b] \rightarrow \phi([a,b])$?","If it is rather silly, how would you express such a function? For example (to be specific), if $\phi : [a,b] \rightarrow \mathbb{R}$ is injective, how would you express the fact that the same function with the co-domain restricted to the range of $\phi$ is bijective? EDIT: I am assuming I haven't previously defined what the function $\phi$ is in any way. ANSWER FROM COMMENTS: It is not silly to write $\phi : [a,b] \rightarrow \phi([a,b])$ .",['functions']
4019294,Identical balls for non-identical people,"I have 40 identical black balls, 23 identical red balls, and 31 identical yellow balls. I want to distribute this to 12 distinct people such that each person gets at least one of each color ball. How many ways can I make this distribution? I started with the stars and bars method. For the 40 black balls: $\binom{39}{11}$ For the 23 red balls: $\binom{22}{11}$ For the 31 yellow balls: $\binom{30}{11}$ After this I'm unsure. Do I just apply multiplication rule and multiply all three of these combinations?","['binomial-coefficients', 'combinatorics']"
4019326,About Getzler's rescaling operator,"I am trying to read the heat kernel proof of the Atiyah-Singer index theorem by the method of Getzler's rescaling method. Here, we define an operator $$(\delta_{\lambda}\phi)(t,x)=\sum_{j=0}^n \lambda^{-j}\phi(\lambda^2t,\lambda x)$$ $\phi$ is defined on $\mathbb R^{+}\times U$ with values in $Cl(T_qM)\otimes End(W)$ where $W$ is the twisted bundle for Clifford module bundle $E=S\otimes W$ . We can imagine $\phi(t,x)$ as terms like asymptotic expansion of heat kernels $k(t,x)$ and identify it with CLifford algebra basis. And we define the Getzler's operator as $\delta_{\lambda} A \delta_{\lambda}^{-1}$ for some operators (For the square of the Dirac operator $D^2$ , this is actually the rescaled Dirac laplacian $D_{\lambda}^2$ , which has the rescaled heat kernel, this transforms the asymptotic expansion with $t\to0^{+}$ to rescaled $\lambda\to 0^{+}$ ) My question is how does the inverse $\delta_{\lambda}^{-1} $ work ? How to calculate it on operators like $A=\partial_t$ , the example shows that this is equal to $\delta_{\lambda} \partial_{t} \delta_{\lambda}^{-1}=\lambda^{-2}\partial_{t}$","['mathematical-physics', 'riemannian-geometry', 'differential-geometry']"
4019384,Differentiable function and the limit as x goes to infinity,"Let $$f: \mathbb{R} \to \mathbb{R}, \lim_{x \to \infty} f'(x) = 0.$$ Prove: $$\lim_{x \to \infty} (f(x + 2) - f(x)) = 0$$ I know I need use the MVT somewhere in here. I know $f$ is differentiable on $(x, x+2)$ so $$f(x+2) - f(x) = 2f'(c)$$ for some $c \in (x,x+2).$ So if we keep looking at the interval as $x \to \infty$ then it seems that's all we need, but I'm not sure how to make it more rigorous. Edit:
Am I on the right track here: $$f(x+2) - f(x) = 2f'(c)$$ implies $$\lim_{x \to \infty} f(x+2) - f(x) = \lim_{c \to \infty} 2f'(c) = 0$$","['derivatives', 'analysis']"
4019414,"Group $G =\langle a, b\rangle$ with $a^{p^m}=b^{p^r}=1$ and $b^{-1}ab=a^n$ has commuting subgroups.","Here $n^{p^r}\equiv 1\pmod{p^m}$ and $p$ is prime. We say $A, B\leq G$ commute if $AB =BA$ . I've shown that commuting subgroups is equivalent to $xy = y^tx^s$ for any $x, y\in G$ and some $t, s\in \mathbb{Z}$ . This is because one can restrict to cyclic groups when showing that any two subgroups commute. Next I've noted that $G$ is a quotient of group of pairs $(t, s)\in \mathbb{Z}_{p^r}\times \mathbb{Z}_{p^m}$ with product $(t, s)*(t', s') := (t+t', n^{t'}s+s')$ . This is where number theory pops in. My question can be then phrased in terms of a system of equations: \begin{cases} xt+yt'\equiv t+t'\pmod{p^r}\\ n^{yt'}\sum\limits_{i=0}^{x-1}n^{ti}s+\sum\limits_{i=0}^{y-1}n^{t'i}s' \equiv s+n^ts'\pmod{p^m}\end{cases} in positive integers $x, y$ . This is where I'm stuck.","['combinatorial-group-theory', 'elementary-number-theory', 'group-theory']"
4019444,Does this type of equation have a name $b^x+b^y=x^b+y^b$?,"I was ""randomly"" suggested the video ""Grapesでいろんな二次グラフを描いてみた"" , on the Hi Shibacchi YouTube channel, of various graphs. Japanese text and frantic synth music were in the background. Eventually, it came to a set of equations of the form $$b^x+b^y=x^b+y^b$$ for some constant b. I would like to know if this type of equation has a name. I put it in Desmos and played around with the sliders and it has some neat properties. If b is even then the equation forms two curves, one of which is closed. But if it's odd, the equation forms only one curve -which is closed. There is also symmetry along the line y=x. Edit:
After looking at it some more I found that for some reason b=2 is unique, in that it seems to be the only even number for which the closed curve doesn't contain the origin. Also, 1 and 3 are interesting. 1 doesn't contain a closed curve; additionally, for all the other odd numbers the closed curve crosses both the x and y axes at b, except for 3, which has no real roots. Edit2: Implicit differentiation with respect to b yields: $$xb^{x-1}+yb^{y-1}=ln(x)x^b+ln(y)y^b$$ Which when graphed is similar for all N > 3, it consists of two curves, starting and ending on the y and x axis, respectively. It's really cool when b = 3, or less! I'm not sure what the mathematical terminology is, but the two curves ""pinch"" together. At b = 2 the equation seems to be inconsistent for all x and y. And at b = 1 there is only one curve!","['algebra-precalculus', 'terminology']"
4019484,how many base $10$ decimal expansions can a real number have?,"A somewhat unintuitive result of real analysis is that decimal expansions are not unique. For example, $$0.99999...=1.$$ So it can be gathered that every real number has at least one base- $10$ decimal expansion, sometimes even two. But is two the maximum ? Are there any real numbers with three different base- $10$ decimal expansions? Intuitively, I would think not, but I have close to no idea how to prove it other than knowing that the easiest method would be a proof by contraction. It may help to restrict the problem by considering the expansions of numbers only in $[0,1]$ . That is because if $a\in[0,1]$ has more than two base- $10$ decimal expansions, then so does $a+x$ for all $x\in\Bbb R$ . And likewise, if $x\in\Bbb R\setminus [0,1]$ has more than two base- $10$ expansions, it can be written as $x=\mathrm{sgn}(x)(\lfloor x\rfloor+a)$ , where $a\in[0,1)$ , and by necessity $a$ has more than two base- $10$ expansions. To be clear, I should define what I mean by base- $10$ expansion. Let $N\in[0,1]$ . Then a decimal expansion of $N$ is a sequence $\delta=(\delta_0,\delta_1,\delta_2,...)$ of integers $0\le \delta_i\le 9$ such that $$\sigma(\delta):=\sum_{i\ge0}\frac{\delta_i}{10^i}=N.$$ Furthermore, let $\mathcal U=\{(a_0,a_1,a_2,...):0\le a_i\le 9,\, a_i\in\Bbb Z\}$ and let $$D_N=\{\delta\in\mathcal U :\sigma(\delta)=N\}.$$ Lastly, let $$\mathcal C_k=\{N\in[0,1]:\#(D_N)\ge k\},\qquad k\in\Bbb N$$ where $\#(S)$ is the number of elements in the set $S$ . So, is $\mathcal C_k$ empty for $k>2$ ?","['real-numbers', 'decimal-expansion', 'sequences-and-series', 'real-analysis']"
4019497,$\lim_{x\to 0} \frac{\cos \left(\pi \cdot \frac{1-\cos (ax)}{x^2}\right)}{x^2} $,"I have to find for which values of $a \in \Bbb N, a \ne 0$ the following limit exists and it is finite: $$\lim_{x\to 0} \frac{\cos \left(\pi \cdot \frac{1-\cos (ax)}{x^2}\right)}{x^2}  $$ Applying L'Hôpital's rule: $$\frac{1-\cos (ax)}{x^2}\sim \frac{\sin (ax) \cdot a}{2x}\sim \frac{a^2}{2}$$ Then $$ \frac{\cos (\pi \cdot \frac{1-\cos (ax)}{x^2})}{x^2}  \sim   \frac{\cos (\pi \cdot \frac{a^2}{2})}{x^2}.$$ $$\cos (\pi \cdot \frac{a^2}{2})=0 \implies a^2=1+2k, \quad k \in \Bbb N$$ and in this case the limit is $0$ . In the book the suggested solution is $a^2=1+2k$ for which the limit is $$ \frac{(-1)^k \cdot (2k+1)^2\cdot\pi}{24}$$ but I don't understand this solution. Trying to solve the limit with $a^2=1+2k$ : $$ \frac{\cos \left(\pi \cdot \frac{1-\cos (ax)}{x^2}\right)}{x^2} \sim \frac{-\sin (\pi \cdot \frac{1-\cos ax}{x^2}) \cdot \pi \cdot  \frac{\sin (ax)  a  x^2 - (1-\cos (ax))  2x}{x^4}}{2x} $$ $$ =  \sin \left( \frac{\pi}{2}+k \pi\right) \cdot \pi \cdot \frac{(1-\cos(ax))2- \sin(ax) ax}{2 \cdot x^4}$$ $$= (-1)^k \cdot \pi \cdot \frac{(1-\cos(ax))2- \sin(ax) ax}{2 \cdot x^4} $$","['limits', 'real-analysis']"
4019502,"Show that $\exists \delta > 0, \forall x \in ]0,\pi[, \exists n \in \Bbb N, |\sin(xk^n)|\ge \delta$.","Let $k \ge 2$ , $k \in \Bbb N$ . Show that $\exists \delta > 0, \forall x \in ]0,\pi[, \exists n \in \Bbb N, |\sin(xk^n)|\ge \delta$ . My intuition tells me that we can pick $\delta=1/2$ . I tried to study $u_n = \sin(xk^n)=U_{k^n}(\sin(x))=U_k(u_{n-1})$ . I thought of introducing a variant of Chebyshev polynomials $U_n(\sin(x))=\sin(nx)$ . But it didn't help much. Does someone have a hint? Thanks. (here $\Bbb N = \{0,1,2,\ldots\}$ .) I needed this result for solving this exercice (which is a oral exam that was posed during the competitive exams of Polytechnique, #1 engineering school in France). Show that for $f(z)=z^k$ with $k \ge 2$ $$
\exists \delta >0, \forall x,y \in \Bbb U, x \neq y \implies \exists n \in \Bbb N, |f^{(n)}(x)-f^{(n)}(y)| \ge \delta.
$$ Suppose $x \neq 0$ and $y/x=e^{i \theta}$ , \begin{align}
| f^{(n)}(x) - f^{(n)}(y) | &= |x^{k^n} - y^{k^n}|
=
 | 1- e^{i \theta k^n}|\\
&= | e^{-i \theta k^n/2} - e^{i \theta k^n/2}|
= |2i \sin(\theta k^n/2)| = 2|\sin (\theta k^n/2)|
\end{align} So $$
|f^{(n)}(x)-f^{(n)}(y)| \ge \delta \iff |\sin (\theta k^n/2)| \ge \delta/2
$$","['calculus', 'sequences-and-series', 'real-analysis']"
4019509,Is there an analogue of the moduli space of the torus in semi-Riemannian signature?,"I'm starting to study Riemann surfaces and already met the fact that Riemann surfaces have both a complex structure and a conformal structure that are, in fact, very closely related. If we consider a Riemann surface one can classify the different conformal structures and if I correctly understand the space whose points label these different conformal structures is the so-called Riemann moduli space. For the torus the moduli space is $${\cal M}={\cal H}/{\rm PSL(2,\mathbb{Z}})$$ where ${\cal H}$ is the upper half plane in $\mathbb{C}$ and ${\rm PSL}(2,\mathbb{Z})={\rm SL}(2,\mathbb{Z})/\mathbb{Z}_2$ . So the distinct conformal structures of the torus are identified by a complex number $\tau$ with ${\rm Re}(\tau)\leq 1/2$ , ${\rm Im}(\tau)>0$ and $|\tau|>1$ . Now, all of this is in the context of Riemann surfaces which are equipped with a conformal structure and hence with an equivalence class of Riemannian metrics. But I would say nothing stops us from picking the manifold $\mathbb{T}^2=S^1\times S^1$ and endowing it with a Lorentzian metric, like $$g=-d\phi\otimes d\phi+d\psi\otimes d\psi,$$ where $\phi$ and $\psi$ are angle coordinate functions on $S^1$ and $(\phi,\psi)$ is the product chart. Question : Is there an analogue of the moduli space and of the modular parameter for such a Lorentzian torus? My intuition says that there should be because we can still consider two Lorentzian metrics conformally equivalent if they are a Weyl rescaling of one another, and we can still talk about a conformal structure as an equivalence class of such metrics.","['riemann-surfaces', 'conformal-geometry', 'semi-riemannian-geometry', 'differential-geometry']"
4019548,Is it true that the edge weight of a bridge equals to its least-squares potential difference within a graph?,"Consider a (not necessarily connected) directed multigraph $G=(V,E,t,h,w,u)$ , where V is the vertex set , E is the edge set , $t: E \rightarrow V$ is the function of edge tails , $h: E \rightarrow V$ is the function of edge heads , while $w: E \rightarrow \mathbb{R}^+$ and $u: E \rightarrow \mathbb{R}$ are two (fixed) weight functions . Suppose that $\pi: V \rightarrow \mathbb{R}$ is a potential function minimizing the following (least-squares) objective function: $\mathit{\Omega}( \mathit{\Pi})=\sum\limits_{e \in E}{w_e{[u_e-\mathit{\Pi}(h_e)+\mathit{\Pi}(t_e)]}^2}$ . Is it true that if $e^* \in E$ is a bridge ( i.e. , an edge whose deletion increases the number of components within G - multiple edges are not bridges here), then $\pi(h_{e^*})-\pi(t_{e^*})=u_{e^*}$ ? If so, how to prove this conjecture?","['graph-theory', 'least-squares', 'directed-graphs', 'discrete-mathematics']"
4019549,Existence of a complete norm on $\ell^2$ which extends $\|۰\|_1$ (on $\ell^1$),"We know that norm-1 is a complete norm on $\ell^1.$ Also $\ell^1$ is a subspace of $\ell^2.$ Now, is there a complete norm
on $\ell^2$ which extends norm-1 (on $\ell^1$ )?","['banach-spaces', 'normed-spaces', 'functional-analysis']"
4019553,"Book recommendation for Introductory Differential Geometry, with lots of examples (calculations)",Could you give a recommendation for differential geometry or curves and surfaces with lots of examples and calculations? I need lots of examples to understand a topic therefore it would great if there are some book with good calculations.,"['surfaces', 'curves', 'geometry', 'reference-request', 'differential-geometry']"
4019555,"""Moral"" difference between Poincare and Sobolev inequalities","I wonder what are the ""moral"" differences between Poincare and Sobolev inequalities.
Let me state them (hopefully without errors) using Wikipedia as source: Poincare inequalities Let $\Omega$ be a domain in $\mathbb R^n$ bounded in at least one direction, then there exists some $C = C(p, \Omega)$ such that for all $u \in W^{1,p}_0(\Omega)$ ( $1\leq p < \infty$ ) $$
\Vert u \Vert_{L^p(\Omega)} \leq C \Vert \nabla u \Vert_{L^p(\Omega)}
$$ We can also change the condition of $u$ belonging in $W^{1,p}_0(\Omega)$ by $u \in W^{1,p}(\Omega)$ and $\int_\Omega u dx = 0$ (only for bounded $\Omega$ ). This is called Poincare-Wirtinger. Gagliardo-Nirenberg-Sobolev inequality Assume $u \in W^{1,p}(\mathbb R^n)$ (in Wikipedia they say $u\in C^1(\mathbb R^n)$ with compact support but by density I think it doesn't matter, correct me if I'm wrong please).
Then for $p \in [1,n)$ , there exists some $C=C(p)>0$ such that $$
\Vert u \Vert_{p^*} \leq C \Vert \nabla u \Vert_{p}
$$ where $p^*$ is some real number larger than $p$ and depending on $n$ and $p$ . I can see that Poincare inequalities are intimately related to domains, whereas GNS isn't. But at first glance, GNS is stronger because if we assume $\Omega$ bounded then $u \in W^{1,p}_0(\Omega) \subset W^{1,p}(\mathbb R^n)$ (by extending $u$ by $0$ outside of $\Omega$ ) and moreover $\Vert \nabla u \Vert_p \lesssim \Vert \nabla u \Vert_{p^*}$ by Holder ineq. Summing up, it seems to me that in GNS we don't ask any condition on $u$ besides being in $W^{1,p}$ and we get an (intuitively) better bound on its $p$ -norm because it ""uses"" lower integrability on $\nabla u$ . A related very vague question, whenever I am working in a domain, when should I be thinking about Poincare inequality and when about GNS inequality?","['sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
4019588,Limit of two uncorrelated random variables,"Let $\{X_n\}$ and $\{Y_n\}$ be two sequences of uncorrelated random variables with finite fourth moments. Also, let $$
X_n \xrightarrow{d} X \text{    and    } Y_n\xrightarrow{d} Y,
$$ where $X$ and $Y$ are standard normal random variables. Can we conclude $(X_n,Y_n)\xrightarrow{d} (X',Y')$ such that $X'$ and $Y'$ are independent standard normal random variables? If not, can you please provide some sufficient conditions? Thanks for the help.","['weak-convergence', 'probability-distributions', 'probability-theory', 'probability']"
4019628,Random time vs stopping time & expectation,"Let $B_t$ be a standard Brownian motion. Let us introduce a stopping time $\tau$ as $$\tau \ = \ \ \inf\Big\{t:\ |B_t|=1\Big\}.$$ Now, what I am interested in are random variables $\tau_x$ defined as $$\tau_x(\omega) \ = \ x\cdot\tau(\omega),$$ for $x> 0$ . Obviously, $\tau_x$ is not a stopping time anymore. Nevertheless, we can still
consider a random variable $$B_{\tau_x}(\omega) \ = \ B_{\tau_x(\omega)}(\omega),$$ and it is (if I understand correctly) still well defined, i.e. measurable - as claimed in The strong Markov property with an uncountable index set . My question is, are basic quantities such as $$\mathbb{E}\Big(B_{\tau_\frac{1}{2}}\Big|B_{\tau}=1\Big)$$ computable? How can we calculate it? My crude intuition is, that $$\mathbb{E}\Big(B_{\tau_x}\Big|B_{\tau}=1\Big) \ = \ x,$$ as $\Delta:=B_{\tau}-B_{0}=1$ and on average we should make $x$ of it in the first $x$ part of random $\tau$ time. I would be glad for any help and insight.","['conditional-expectation', 'stopping-times', 'brownian-motion', 'probability-theory', 'probability']"
4019674,prove that $\arcsin (3/5) /\pi $ is irrational,"I was asked to prove that on the unit circle, the rational points are dense. My idea is to first show that the point (3/5,4/5) corresponds to an irrational angle (more precisely, its ratio with respect to $\pi$ ), then by rotation, its image will be dense on the circle. This is Kronecker's theorem? So I have to show that the angle is irrational.","['number-theory', 'trigonometry']"
4019680,Showing $\cos A\cos B\cos C=\frac{s^2-(2R+r)^2}{4R^2}$ and $\cos A+\cos B+\cos C=1+\frac rR$ in $\triangle ABC$,"In a triangle with vertices $A$ , $B$ , $C$ , semiperimeter $s$ , inradius $r$ and circumradius $R$ , prove that $$\cos A\cos B\cos C=\frac{s^2-(2R+r)^2}{4R^2}$$ and $$\cos A+\cos B+\cos C=1+\frac rR$$ (note: we can also discover the value of $\cos A\cos B+\cos B\cos C+\cos C\cos A$ using the identity $\cos^2A+\cos^2B+\cos^2C+2\cos A\cos B\cos C=1$ ) Since the last time I've posted this question (the original thread is now deleted), I've reflected a bit on the suggestions of several users. First, I included relevant informations and defintion and second I did try to use the cosine law, but It did not give me help. I was referred by a friend to the identities $$\begin{align}
a+b+c &= 2s \tag{1} \\[4pt]
ab+ac+bc &= s^2+r^2+4rR \tag{2} \\[4pt]
abc &= 4Rrs \tag{3}
\end{align}$$ The first and third facts are obvious, while the second I do not know for sure to be true (although it probably is) and appears to model the numerator of the first identity in $\cos A\cos B\cos C$ . Any other idea?","['trigonometry', 'algebra-precalculus', 'triangles', 'geometry']"
4019709,"Localizing C[x,y]/(xy) to get a direct product of Laurent polynomials.","I am trying to show $$\left(\mathbb C[x,y]/(xy)\right)_{x+y}\cong \mathbb C[x^{\pm 1}] \times \mathbb C[y^{\pm 1}].$$ In class, my professor did the example $$\left(\mathbb C[x,y]/(xy)\right)_{x} \cong \mathbb C[x^{\pm 1}]$$ by using the fact that $A_f \cong A[t]/(tf - 1)$ for a commutative ring $A$ . I am trying to mimic this approach. I get that $$\left(\mathbb C[x,y]/(xy)\right)_{x+y} \cong \left(\mathbb C[x,y]/(xy)\right)[t]/(t(x+y)-1)$$ $$=\mathbb C[x,y,t]/(xy, t(x+y) - 1).$$ I am not really sure how to simplify this quotient to get what I need. I would really appreciate any help! Thanks.","['ring-theory', 'abstract-algebra', 'commutative-algebra']"
4019716,Can I simply replace the first and second derivatives with the gradient and laplacian in the curvature of the graph of a function?,"Can I simply replace the first and second derivatives with the gradient and laplacian in the curvature of the graph of a function to generalize to a multivariable curvature functional of the graph of a function? The curvature of the graph of a function is given by the following. $$\mathscr{k}_f(x) = \frac{f^{\prime\prime}(x)}{(1 + [f^{\prime}(x)]^2)^{\frac{3}{2}}}$$ Assuming a second-differentiable scalar function, is the following a valid generalization of this type of curvature to the multivariable case? $$\mathscr{k}_f(\vec{x}) = \frac{\nabla_{\vec{x}}^2 f(\vec{x})}{(1 + [\nabla_{\vec{x}} f(\vec{x})]^2)^{\frac{3}{2}}}$$ Edit Matthew Pilling convinced me that taking the square of a gradient is not directly possible. I was implicitly assuming I could collapse the vectors by summing the components, however it would be technically correct to make this explicit using either dot products or the trace of the diagonal of the resulting vectors. $$\mathscr{k}_f(\vec{x}) = \frac{\nabla_{\vec{x}}^2 f(\vec{x}) \cdot \vec{1}}{(1 + [\nabla_{\vec{x}} f(\vec{x})\cdot \vec{1}]^2)^{\frac{3}{2}}} =  \frac{\text{tr}[\text{diag}[\nabla_{\vec{x}}^2 f(\vec{x})]]}{(1 + [\text{tr}[\text{diag}[\nabla_{\vec{x}} f(\vec{x})]]]^2)^{\frac{3}{2}}}$$ This is with the diagonal of a vector $\text{Diag}(\vec{x})$ being the construction of a diagonal matrix whose diagonal entries are the corresponding components of the vector $\vec{x}$ . Beyond this correction on vector operations, I'm still interested in whether the corrected equation captures the same idea of curvature as the original equation.","['laplacian', 'multivariable-calculus', 'derivatives', 'curvature']"
4019738,Antichains and weighted sums,"Given an antichain $S_1,S_2,\dots,S_m$ of subsets of $\{1,2,\dots,n\},$ does there always exist positive integers $x, y_1,\dots,y_n$ so that for $i=1,\dots,m$ we have: $$\sum_{k\in S_i} y_k =x\tag 1$$ (Antichain means that for for $i\neq j,$ we have $S_i\not\subseteq S_j.$ ) Just a question that occurred to me while working on another problem. Certainly, given $x,y_1,\dots,y_n,$ the set $$\mathcal A =\left\{S\subseteq\{1,\dots,n\}\mid \sum_{k\in S} y_k =x\right\}$$ is an antichain, so this question asks if all antichains are a subset of an antichain of the form $\mathcal A.$",['combinatorics']
4019759,Probability that a character kills the boss in a 3 versus 1 fight,"In a RPG game, your three characters A, B and C fight a boss.
The boss has $1000$ hp.
The attacks are sequential: A attacks then B attacks then C attacks then A attacks again, etc.
Character A can do any integral amount of damage between $25$ and $50$ with equal probability.
Character B can do any integral amount of damage between $30$ and $70$ with equal probability.
Character C can do any integral amount of damage between $10$ and $80$ with equal probability.
Assuming that the boss is not strong enough to kill any of the characters before it dies, what is the probability that player A will be the one to deliver the final blow and kill the boss?
Same question for players B and C. Unfortunately I don't even know how to get started on this problem, any hint would be helpful.",['probability']
4019776,How to show that $D$ is a Borel measurable set and $D_{f}$ is a Borel function.,"How to show that $D_{f}$ is a Borel measurable function. Well I have one Lipschitz function $f:\Bbb{R}^{n}\to \Bbb{R}$ and I want to proof that $D_{f}:D\to L(\Bbb{R}^{n},\Bbb{R})$ is Borel function, where $D=\{ x\in \Bbb{R}^{n}: f'(x)\quad \text{exist }\}$ I try with the definition to show that $\forall U$ Borel set in $ L(\Bbb{R}^{n},\Bbb{R})$ imply $D_{f}^{-1}(U)$ is Borel set. Then let $U$ Borel set in $L(\Bbb{R}^{n},\Bbb{R})$ hence $D_{f}^{-1}(U)=\{x\in \Bbb{R}^{n}: D_{f}(x)\in U\}$ but $D_{f}(x)$ is one linear transformation  hence $D_{f}^{-1}(U)=\{x\in \Bbb{R}^{n}: T(x)\in U \}$ can to say : Like $T$ is continuous because is linear transformation then $D_{f}^{-1}(U)$ is measurable imply is Borel set?, can somebody help me please or give me one hint...thank you","['measure-theory', 'geometric-measure-theory', 'multivariable-calculus', 'linear-algebra', 'measurable-functions']"
