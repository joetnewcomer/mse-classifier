question_id,title,body,tags
4463822,Show that $\prod_{k=1}^{n}(1+x^{2^k})$ is a polynomial of the form $\sum_{k=0}^{m}c_{k}x^{k}$,"While solving exercises from Chapter 1, Calculus Vol. 1 by Apostol , I came across this question that asks to show that $\displaystyle\prod_{k=1}^{n}(1+x^{2^k})$ is a polynomial of the form $\displaystyle\sum_{k=0}^{m}c_{k}x^{k}$ . I have outlined a proof for the same by constructing sets: $$
\begin{align}
K &= \{2^k:k\in [1,n],k\in \mathbb{N}\}\\
S_0 &= \{1\}\\
S_1 &= \{x^{k_1}: k_1\in K\}\\
S_2 &= \{x^{k_1+k_2}: k_1,k_2 \in K, k_1 \neq k_2\}\\
S_3 &= \{x^{k_1+k_2+k_3}: k_1,k_2,k_3 \in K, k_1 \neq k_2\neq k_3\}\\
& \vdots\\
S_n &= \{x^{\sum_{i=1}^{n} k_i}: k_i \in K, k_i \neq k_j\forall i\neq j \}\\
S &= \bigcup_{i=0}^{n}S_i\\
\# S &= \Sigma_{i=0}^{n}{n \choose i} = 2^n
\end{align}
$$ The polynomial can now be written as: $$
\prod_{k=1}^{n}(1+x^{2^k}) = \sum_{i=1}^{2^n}x_i\text{ where }x_i \in S
$$ However, I am not able to construct a simple algebraic formula for the last statement. I have an intuition that $x_i\neq x_j\text{ if }i\neq j$ . I am not able to assert this statement as well.","['elementary-set-theory', 'polynomials', 'real-analysis']"
4463830,Is K6 a planar graph?,"Using the condition $m\leq3n-6$ , where $m$ equals the number of edges in the graph and $n$ is the number of vertices, I reasoned that for $K6$ , the number of edges is $2\times 6 = 12$ . With the vertices being equal to 6, $3n-6 = 12$ . So $12\leq 12$ , and the inequality condition is satisfied. So, is this reasoning correct to show that $K6$ is a planar graph?","['discrete-mathematics', 'planar-graphs']"
4463872,How many possible passwords of 6 characters (only lower-case letters and digits) can be made with only 2 lower-case letters and no repeated digits?,"How many possible passwords of 6 characters (only lower-case letters and digits) can be made with only 2 lower-case letters and no repeated digits? My solution for this is $${}_6C_2 \cdot 26 \cdot 26 \cdot 10 \cdot 9 \cdot 8 \cdot 7 = 51105600$$ However, my lecturer states that it is $$26 \cdot 26 \cdot {}_{10}C_4 \cdot 6!= 102211200$$ Can someone explain why this is the case? Or is there another solution?","['permutations', 'combinatorics', 'discrete-mathematics']"
4463905,Tail Probabilities of $L^p$ bounded martingale differences,"Assume that I have a probability space $(\Omega, \mathcal{A}, \mathbb{P})$ on which we define a sequence of martingale differences $X_1,X_2,\dots$ (w.r.t. to a certain filtration). Further let $p \in (1,2)$ and assume that the $X_i$ are bounded in $L^p$ , i.e. there exists $M>0$ such that $$\Vert X_i \Vert_p \leq M$$ for all $i \in \mathbb{N}$ . Does this already imply that I find a random variable $X \in L^p(\Omega, \mathcal{A}, \mathbb{P})$ and a $C > 0$ such that $$\mathbb{P}(\vert X_i \vert > z) \le C \mathbb{P}(\vert X \vert > z)$$ for all $z > 0$ , $i \in \mathbb{N}$ ?","['distribution-tails', 'probability-theory', 'probability']"
4463910,Derive CDF of EPV of deferred whole life insurance,"I'm studying actuarial mathmatics. Can you help me solving this question? The PV random variable of $u$ -year deferred whole life insurance benefit is $Z = \begin{cases} 
0, & \mbox{$T_x$ < $u$} \\ 
v^{T_x}, & \mbox{$T_x$ $\ge$ $u$}
\end{cases}$ Note that discount factor $v=e^{-\delta}$ . and $Z$ is decreasing function of $T_x$ when $T_x >u$ . Assuming constant force of mortality $\mu$ and force of interest $\delta$ , How can I derive the Cumulative distribution function(CDF) of $Z$ and calculate median of $Z$ ? This is my idea: let $T_x = t$ . $f_x(t) = \mu e^{-\mu t},\, F_x(t) = {_t}q_x = 1-e^{-\mu t},\, S_x(t) = {_t}p_x = e^{-\mu t}$ . $P(Z=0) = P(T_x \leq u) = 1-e^{-\mu u}$ $P(Z=v^t) = {_u|_t}q_x = {_u}p_x{_t}q_{x+u} = e^{-\mu t}(1-e^{-\mu t}) = e^{-\mu t} - e^{-\mu (u+t)}$ but I cannot express it for function of $Z$ . I got probabilities for $Z$ , but they are also function of $t (T_x)$ . CDF should be $f: Z \rightarrow [0,1]$ , but there is another variable $t$ .
Could you help me how can I get appropriate function for $Z$ , please? Thank you for your help.","['actuarial-science', 'statistics']"
4463924,Find the limit $\lim_{n \to \infty} \frac{a_1 + a_2 + a_3 + ... + a_n}{\ln(n)}$ where $a_{n} = \int_{1}^{e} \ln^{n}(x)dx$,"First I tried to solve this problem by noticing that: $$a_1 + a_2 + a_3 + ... + a_n = \sum_{k=1}^{n}a_{k}=\sum_{k=1}^{n}\int_{1}^{e}\ln^{k}(x)dx = \int_{1}^{e}\sum_{k=1}^{n}\ln^{k}(x)dx \\= \int_{1}^{e}\frac{\ln^{k+1}(x)-\ln(x)}{1-\ln(x)}dx,$$ but this didn't really help. Then I arrived at the equivalent form $a_n = \int_{0}^{1}x^{n}e^{x}dx$ which yields: $$a_1 + a_2 + a_3 + ... + a_n = \int_0^1 \frac{x^{n+1}-x}{1-x}e^xdx.$$ My last attempt was to introduce a new function $F(t) = \int_0^1x^ne^{tx}dx$ . $$F^{\prime}(t)= \frac{d}{dt}\int_0^1x^ne^{tx}dx =\int_0^1 \frac{\partial}{\partial t}x^ne^{tx}dx=\int_0^1 x^n e^{tx} xdx = \int_0^1x^{n+1}e^{tx}dx.$$ By doing IBP and simplifying I got this differential equation: $$ F^{\prime}(t)= \frac{e^t}{t}-\frac{n+1}{t}F(t)$$ which I don't know how to solve.","['contest-math', 'calculus', 'sequences-and-series', 'limits', 'derivatives']"
4464012,Given a triangle ABC inscribed in the unit circle,", the 3 vertices could be described via 3 complex number, namely, $a$ , $b$ , and $c$ . Now $AD$ is an altitude, $D$ is the foot of $AD$ on $BC$ . Prove: $$D = \frac{a+b+c}2 - \frac{bc}{2a}$$ So far my progress is -- the circumcentre of triangle $ABC$ is just $O = 0$ . its centroid $G = \frac{a+b+c}3$ . by Euler line, the orthocentre $H = a+b+c$ . also, we can see that the centre of the nine point circle $N =
   \frac{a+b+c}2$ . But then I'm a bit stuck. $D$ is on the line $AH$ and $BC$ , but I couldn't reach the conclusion to be proved.","['geometry', 'complex-numbers']"
4464073,"Prove or disprove $\sum\limits_{1\le i < j \le n} \frac{x_ix_j}{1-x_i-x_j} \le \frac18$ for $\sum\limits_{i=1}^n x_i = \frac12$($x_i\ge 0, \forall i$)","Problem 1 : Let $x_i \ge 0, \, i=1, 2, \cdots, n$ with $\sum_{i=1}^n x_i = \frac12$ . Prove or disprove that $$\sum_{1\le i < j \le n} \frac{x_ix_j}{1-x_i-x_j} \le \frac18.$$ This is related to the following problem: Problem 2 : Let $x_i \ge 0, \, i=1, 2, \cdots, n$ with $\sum_{i=1}^n x_i = \frac12$ . Prove that $$\sum_{1\le i<j\le n}\frac{x_ix_j}{(1-x_i)(1-x_j)}\le \frac{n(n-1)}{2(2n-1)^2}.$$ Problem 2 is in ""Problems From the Book"", 2008, Ch. 2, which was proposed by Vasile Cartoaje. See: Prove that $\sum_{1\le i<j\le n}\frac{x_ix_j}{(1-x_i)(1-x_j)} \le \frac{n(n-1)}{2(2n-1)^2}$ Background : I proposed Problem 1 when I tried to find my 2nd proof for Problem 2. It is not difficult to prove that $$\frac{1}{(2n-1)^4} + \frac{16n^2(n-1)^2}{(2n-1)^4}\cdot \frac{x_ix_j}{1-x_i-x_j}
\ge \frac{x_ix_j}{(1-x_i)(1-x_j)}.$$ ( Hint : Use $\frac{x_ix_j}{(1-x_i)(1-x_j)}= 1 - \frac{1}{1 + x_ix_j/(1-x_i-x_j)}$ and $\frac{1}{1+u} \ge \frac{1}{1+v} - \frac{1}{(1+v)^2}(u-v)$ for $u = x_ix_j/(1-x_i-x_j)$ and $v=\frac{1}{4n(n-1)}$ . Or simply $\mathrm{LHS} - \mathrm{RHS} = \frac{(4x_ix_jn^2 - 4x_ix_j n + x_i + x_j - 1)^2}{(2n-1)^4(1-x_i-x_j)(1-x_i)(1-x_j)}\ge 0$ .) To prove Problem 2, it suffices to prove that $$\frac{1}{(2n-1)^4}\cdot \frac{n(n-1)}{2} + \frac{16n^2(n-1)^2}{(2n-1)^4}\sum_{1\le i < j \le n} \frac{x_ix_j}{1-x_i-x_j} \le \frac{n(n-1)}{2(2n-1)^2} $$ or $$\sum_{1\le i < j \le n} \frac{x_ix_j}{1-x_i-x_j} \le \frac18.$$ For $n=2, 3, 4$ , the inequality is true. For $n=5, 6$ , numerical evidence supports the statement. Any comments and solutions are welcome and appreciated.","['contest-math', 'inequality', 'tangent-line-method', 'real-analysis']"
4464126,Denesting radicals $\sqrt[3]{-22+15\sqrt[3]{3}+9\sqrt[3]{9}}$ and $\sqrt[3]{8-9\sqrt[3]{3}+3\sqrt[3]{9}}$,I am trying to do denesting radicals: $$\sqrt[3]{-22+15\sqrt[3]{3}+9\sqrt[3]{9}}$$ and $$\sqrt[3]{8-9\sqrt[3]{3}+3\sqrt[3]{9}}$$ I tried to find Ramanujan polynomial like this link denesting radicals But it doesn't work. I also tried to solve the system of equation $\sqrt[3]{-22+15\sqrt[3]{3}+9\sqrt[3]{9}}=a+b\sqrt[3]{3}+c\sqrt[3]{9}$ but it led to a scary-looking one.,"['algebra-precalculus', 'radicals']"
4464180,Show that $f(z) = C \cdot \sin(\pi z)$.,"Suppose $f: \mathbb{C} \rightarrow \mathbb{C}$ is an entire function such that $|f(z)| \leq K e^{\pi |\text{Im}(z)|}$ for some $K > 0$ , and that $f(n) = 0$ for all $n \in \mathbb{Z}$ . Show that $f(z) = C \cdot \sin (\pi z)$ . I have seen very similar problems on here asking this question with (what I think is) a stronger assumption. That is, assuming $f(z+1) = -f(z)$ for all $z \in \mathbb{C}$ . The argument itself is an application of Liouville's theorem. But with only assuming that $f(n) = 0$ for $n \in \mathbb{Z}$ I am not able to recreate the argument. Bounding the function $g(z) = f(z)/\sin(\pi z)$ on a strip like $|\text{Im}(y)| \geq 1$ comes down to bounding the sine function from below on this region. However we cannot do the same for $|\text{Im}(y)| \leq 1$ . How can I proceed? Here is the link to the post I mentioned above: Show that $f(z) = c \sin (\pi z)$ .",['complex-analysis']
4464279,There is no injective continuous map from $(\mathbb{R}-\mathbb{Q})\times\mathbb{R}$ to $\mathbb{R}$.,"I have to show that there is no injective continuous map from $(\mathbb{R}-\mathbb{Q})\times\mathbb{R}$ to $\mathbb{R}$ . Let $Y=(\mathbb{R}-\mathbb{Q})\times\mathbb{R}$ . I thought about doing something with connectedness and the image of a connected set by a continuous function (supposing $f$ exists) and lead to a contradiction. However, I tried looking at preimages of open disjoint sets in $\mathbb{R}$ but that would give me also open sets in the domain. Maybe removing a point from codomain $\mathbb{R}$ and get a connected (component) in domain?",['general-topology']
4464287,Sketching the region of integration and writing an equivalent double integral and evaluating it.,"The question says to sketch the region of integration and reverse the order of integration and then evaluate if possible. $$\int_{0}^{\sqrt{3}}\int_{0}^{\tan^{-1}(y)}\sqrt{xy}dxdy$$ This is what I graphed as the region of integration: So when I reverse the order of integration I get: $$\int_{0}^{\tan^{-1}(\sqrt{3})}\int_{\tan x}^{\sqrt{3}} \sqrt{xy} dy dx$$ $$=\int_{0}^{\tan^{-1}(\sqrt{3})} \sqrt{x}\frac{2}{3}y^{3/2} \Bigg|_{\tan x}^{\sqrt{3}} dx$$ $$=\int_{0}^{\tan^{-1}(\sqrt{3})}  \frac{2}{3}\sqrt{x} \Bigg[3^{3/4}-(\tan x)^{3/2}\Bigg]dx$$ $$=\frac{2}{3}\int_{0}^{\tan^{-1}(\sqrt{3})} 3^{3/4}\sqrt{x}-\sqrt{x}(\tan x)^{3/2}dx$$ I don't know what to do next to evaluate the integral.  Can someone please help me? The question says to find the value of the integral if possible, so does that mean I cannot find the value of this integral? If so, why not?",['multivariable-calculus']
4464289,Can you prove that this function is bijective?,"Let $T(x,y)=(5x+\sin(y),5y+\arctan(x))$ . Prove T is a bijective map from $\mathbb{R}^2$ to $\mathbb{R}^2$ . This is a problem from a test for undergraduate students, i don't know where to start. EDIT: What i know is that if $f:A\subseteq\mathbb{R}^n \to \mathbb{R}^n$ is $C^1(A)$ where $A$ is open and if $x_0\in A$ is such that $J_f(x_0)$ is not zero then $f$ is locally invertible near $x_0$ . Notice that with $J_f$ i meant the Jacobian of the function $f$","['multivariable-calculus', 'analysis', 'real-analysis']"
4464296,On projection operators for irreducible representations of finite groups,"Physicist here, posting here because it seems more appropriate. I will try to pose this question in the most general way possible, so that it is applicable to the most broad number of situations. If it is at all relevant for the answer keep in mind that this question arises from the study of the rotational symmetry of quantum operators on a lattice. I have a system with a symmetry described by a finite group $G$ of order $n_G$ . (the point group in question is the cubic group $O$ of order 24 (it is isomorphic to $S_4$ )). I have a set of objects (operators) $\{\hat{O}_i\}$ spanning a vector space of operators, we will call $H = \text{Span}\{\hat{O}_i\}$ . I have already managed by hand to build the reducible representation $\mathcal{R}$ acting on the $\{\hat{O}_i\}$ basis. I already know ho to compute the Kronecker decomposition of $\mathcal{R}$ by calculating the multiplicities of each irreducible representation of the group using the character tables. I need to find linear combinations of these $\{\hat{O}_i\}$ : $$
\overline{O}^\mu_a = \sum_i c^\mu_{a,i}\hat{O}_i
$$ Such that $\overline{O}^\mu_a$ transforms according to an irreducible representation of the point group symmetry. In particular, if $\Gamma^\mu$ is the $\mu$ -th irreducible representation of the finite group then for every fixed $\mu$ the set $\{\overline{O}^\mu_a \text{ with } a= 1, ..., \dim \Gamma^\mu\}$ is an orthonormal basis of the invariant subspace of $H$ that tranforms according to the $\Gamma^\mu$ representation. In literature I have found that we can do this using projection operators and both the objects: $$
\frac{\dim \Gamma^\mu}{n_G}\sum_{g\in G} {\Gamma^\mu}(g)^\dagger_{ab} \mathcal{R}(g)_{ij}\hat{O}_j \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \text{and} \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \sum_{g \in G} \chi^\mu(g)^*\mathcal{R}(g)_{ij}\hat{O}_i
$$ should transform according to the $\Gamma^\mu$ representation because of the great orthogonality theorem. The difference in the two approaches is essentially that the first projector is also able to extract an orthonormal basis of the $\Gamma^\mu$ subspace of $H$ . My question is the following, if the Kronecker decomposition of $H$ has different copies of any irreducible representation, i.e. if we have that: $$
\mathcal{R} = \bigoplus_\mu a_\mu \Gamma^\mu
$$ where there exist $\nu$ such that $a_\nu \geq 2$ . Then on which of the subspaces am I projecting? If there are multiple copies of the $\Gamma^\nu$ irreducible representation, and I wish to build an orthonormal basis for each separate invariant subspace tranforming according to $\Gamma^\nu$ then how should I interpret the action of the projection operators? (The first one in particular since I am looking to build the linear combinations explicitly so that would seem more appropriate). I hope the question is undestandable, but I remain available to provide any clarification if necessary. Thanks to all in advance.","['projection', 'representation-theory', 'finite-groups', 'group-theory', 'symmetry']"
4464305,"When is the anticanonical sheaf ample, on an arithmetic surface of genus 0?","Let $\pi:X \to S$ be an arithmetic surface, i.e. a flat, projective, scheme of relative dimension 1 over a Dedekind scheme $S$ . So $X$ is a 2-dimensional excellent scheme.
Suppose that the generic fiber $X_\eta/K$ is a smooth, geometrically connected curve of genus 0, and that $X$ is regular. Since $\pi$ is a local complete intersection, the canonical sheaf $\omega_{X/S}$ on $X$ is an invertible sheaf. The dual $\omega_{X/S}^\vee$ restricts to a very ample sheaf on $X_\eta$ , with global sections of rank 3. Question 1 : Is $\omega_{X/S}^\vee$ also very ample? Now suppose that $Y$ is an arithmetic surface with very ample anticanonical bundle $\omega_{Y/S}^\vee$ , and that $\rho:X \to Y$ is a birational morphism. Question 2 : Under what conditions is the anticanonical bundle $\omega_{X/S}^\vee$ also (very) ample?","['schemes', 'coherent-sheaves', 'algebraic-geometry', 'arithmetic-geometry', 'line-bundles']"
4464306,Probablity of a card being less than or equal to 3,"In a box, there are 10 cards and a number from 1 to 10 is written on each card. When three cards from the box are randomly taken at a time, we define X,Y, and Z according to three numbers in ascending order. The probablity that X is less than or equal to 3 is: I tried writing out what the probablity of three situations would be where A is anything. $$1AA = 1/10 * 1 * 1$$ $$2AA (excluding 1) = 1/10 * 8/9 * 7/8$$ $$3AA (excluding 2 and 1)=  1/10 * 7/9 * 6/8$$ After adding all of these up I came no where near the answer: $17/24$ or( $85/120$ also works) Where am I going wrong with this? Also, how do I solve it? I thought about permutations, and how many different ways we could draw these cards, but it seems like the cards have to be in a strict order (ascending) so even if we draw the cards out of order, they will be put in order, so everything is just multiplied by 1, since there are no permuations (or so I think) I also thought about what if this is just asking, of a random set of three cards, what is the chance that x is less than 3? and thought
XYZ, X has a 3/10 chance to be 3 or less. However, after that I got lost on how I should multiply 3/10, since the next two numbers in that sequence are fully dependent on the first number. All help is appreciated! thank you!","['statistics', 'probability']"
4464364,Why Lagrange Multiplier Doesn't Work?,"Question: Find maximum value $f(x,y,z) = xy + zy + xz - 4xyz$ subject to constraint $x + y + z = 1$ and $x,y,z \geq 0$ . $$
g(x,y,z) = x + y + z - 1
$$ and $$
\nabla g(x,y,z) \neq 0,
\qquad 
\nabla g(x,y,z) = \langle 1,1,1 \rangle. 
$$ When we apply Lagrange Multiplier Method, we find $f \bigl( \frac{1}{2}, \frac{1}{4}, \frac{1}{4} \bigr) = \frac{3}{16}$ , the maximum value, but the answer is $f \bigl( 0, \frac{1}{2}, \frac{1}{2} \bigr) = \frac{1}{4}$ . Why does that happen? Lagrange Multiplier Method has a only $1$ rule: $\nabla g(x,y,z) \neq 0$ , there is no rule break. EDİT : I find f(0,1/2,1/2) with another method and f(1/2,1/4,1/4) is not both a global maxima and a global minima point but Lagrange Multiplier gives that result, and f(1/2,1/4,1/4) is not a local minimum f(0,0,1) is lower than that.","['lagrange-multiplier', 'multivariable-calculus', 'calculus', 'optimization', 'derivatives']"
4464374,Finding the area of a triangle on a unit circle,"Assume that $0< \theta < \pi$ . For three points $A(1,0)$ , $B(\cos(\theta),\sin(\theta))$ and $C(\cos(2\theta),\sin(2\theta))$ on a unit circle, the area of triangle $ABC$ is: ??? I drew out the unit circle and tried to get the dimensions. I ended up drawing a triangle underneath the main triangle to try and get the base, but that ended up giving me a square root and I couldn't find a way to get rid of it. The answer is: $\sin(1-\cos)$","['trigonometry', 'circles']"
4464416,Non-integrable derivative of increasing function,"Is there an example of an increasing and differentiable function $f$ on an interval $[a,b]$ such that its derivative is not Riemann integrable on the same interval?","['integration', 'derivatives', 'examples-counterexamples', 'real-analysis']"
4464424,Matrix powers of product of diagonalizable and orthogonal matrix,"Suppose I have the following matrix constructed from some orthogonal matrix $O$ and a $\pm 1$ diagonal matrix $D=diag(\pm1,\dots,\pm1)$ $$
A = O D O^{-1} D.
$$ Is there a simple way to evaluate $A^n$ for positive integer $n$ in a similar way to e.g. a diagonalizable matrix $B$ ? $$
B^n = (P L P^{-1})^n = P L^n P^{-1} .
$$ I feel this ought to be the case given how $A$ is decomposed into a product of orthogonal and diagonal matrices but alas it is not clear to me if this is always so. Of course $A$ is also an orthogonal matrix and can itself be diagonalized $$
A = O D O^{-1} D = RTR^{-1}
$$ but do $R,T$ have clear expressions in terms of $O,D$ ? EDIT:
Some further work on my end indicates that the same question when $$
A = D^{1/2} O D O^{-1} D^{1/2},
$$ is also acceptable. Answers in this direction would be helpful, though the original question is still my primary goal.","['matrices', 'linear-algebra', 'matrix-decomposition']"
4464427,Easier way to calculate triple integral,"So I had to calculate an integral that goes like that $$\iiint\  \frac{x^2}4+y^2 dxdydz$$ where the area is $$\frac{x^2}4+y^2=1$$ $$z=0$$ $$z=x+2y+5$$ I actually solved this triple integral and my answer is $\mathbf{5}\pi$ . I made it in two ways: I described the area as $$-2<x<2$$ $$-\sqrt{1-\frac{x^2}4}<y<\sqrt{1-\frac{x^2}4}$$ $$0<z<x+2y+5$$ And using polar form where I calculated ellipse's radius as $0<r<\frac{2}{\sqrt{4\sin^2\phi+\cos^2\phi}}$ and the change of ' $z$ ' as $0<z<\cos\phi r+2\sin\phi r +5$ where $ 0<\phi<2\pi $ But I feel like I may overcomplicate this?
Is there a way to solve this triple integral easier/faster?","['integration', 'multivariable-calculus']"
4464434,"Finding the $z$ coordinate of center of mass for $C:= \{ (x,y,z) \in \mathbb{R^3}: \sqrt{x^2+y^2}\leq z \leq 1$","The Problem Let $C$ be the cone $$C:= \{ (x,y,z) \in \mathbb{R^3}: \sqrt{x^2+y^2}\leq z \leq 1$$ Assume that $C$ has a constant mass density and find the z coordinate of the center of mass. The work I have done: \begin{align*}
M_{xy}&=\iint_{R}\int_{\sqrt{x^2+y^2}}^{1} z \,\delta \,dx \,dy \,dx\\
&=\iint_{R} \delta \,\frac{z^2}{2} \Bigg|_{\sqrt{x^2+y^2}}^{1} \,dy \,dx\\
&=\iint_{R} \delta \,\Big(\frac{1}{2}-\frac{\sqrt{x^2+y^2}}{2} \Big) \,dy \,dx
\end{align*} Switching to polar coordinates now and pulling out the constants: \begin{align*}
&=\frac{\delta}{2}\int_{0}^{2\pi}\int_{0}^{1} \big(r-r^3 \big) \,dr \,d\theta\\
&=\frac{\delta}{2} (\frac{\pi}{2})=\frac{\pi}{4}\,\delta\,.\\
\\
M&=\iint_{R}\int_{\sqrt{x^2+y^2}}^{1} \,\delta \,dx \,dy \,dx\\
&=\iint_{R} \delta (1-\sqrt{x^2+y^2}) \,dy \,dx
\end{align*} Switching again to polar: \begin{align*}
&=\delta \int_{0}^{2\pi} \int_{0}^{1} (1-r) \,r \,dr \,d\theta\\
&=\delta \int_{0}^{2\pi} \frac{1}{6} d\theta = \frac{\pi}{3}\,\delta
\end{align*} Therefore: $$\bar{z}=\frac{M_{xy}}{M} = \frac{\pi\delta}{4}\cdot\frac{3}{\pi\delta}=\frac{3}{4}$$ Is my answer correct? Edit: I also know that I could have switched to cylindrical from the beginning. If I did, would the integral I need to evaluate be $$M=\int_{0}^{2\pi}\int_{0}^{1}\int_{r}^{1} \,r \,dz \,dr\,d\theta$$ and $$M_{xy}=\int_{0}^{2\pi}\int_{0}^{1}\int_{r}^{1} \,rz \,dz \,dr\,d\theta\,?$$",['multivariable-calculus']
4464449,convergence of a sequence with strict inequality condition,"Let $(u_n)$ be the sequence defined by $u_0 > 0$ and $u_{n+1} = \frac{1}{2}(u_n + v_n)$ where $v_n$ is another sequence such that for all $n \in \mathbb{N}$ , $v_n < u_n$ . This sequence is nonincreasing and lower bounded, thus it admits a limit. The limit is $0$ for a fair amount of examples i've tried but i am struggling to show that it is the case for any such $v_n$ . The result holds under the additional assumption that $\sup_{n \in \mathbb{N}} \frac{v_n}{u_n} < 1$ . Does it hold in general?","['calculus', 'sequences-and-series', 'real-analysis']"
4464453,Really challenging integral question [duplicate],"This question already has answers here : MIT Integration Bee 2017 problem:$\int_0^{\pi/2}\frac 1 {1+\tan^{2017} x} \, dx$ : Need hints [duplicate] (2 answers) Integrate $\int_0^{\pi/2} \frac{1}{1+\tan^\alpha{x}}\,\mathrm{d}x$ (5 answers) Closed 2 years ago . My teacher gave me this question as a challenge: $$
\int_{0}^{\pi/2}\frac1{1+\tan^a(x)}  \,dx
$$ It took me several days, but I did manage to solve this question using the King Property, by substituting $t=\frac{\pi}{2}-x$ . However, apparently there is an 'easier' way of doing this according to my teacher, which of you can represent the function in terms of $a$ (I am not even sure if I am saying this correctly) and show that the result will always be constant no matter what $a$ is. Essentially, if you can find an easier or simpler solution to this, I'd like to hear it. Thank you in advance. I will put my own solution below.","['integration', 'calculus']"
4464475,Maximizing an absolute value of some complex polynomial.,"Let $ \lambda \in \mathbb{C} $ be any complex number, $ R > 0 $ some positive real. I want to find maxima of absolute value of some polynomial on the circle: $$ \max (|x-1| |x-\lambda|) = \max| x^2 - (\lambda + 1)x + \lambda | = \max|P(x)|, $$ where $ |x| = R\ $ and $\ P(x) = x^2 - (\lambda + 1)x + \lambda $ . It is not hard to find maximal value for concrete values of $R$ , but I want it as function of $R$ and $\lambda$ . I tried two things. Firstly, polar coordinates: $ x = R e^{i \phi} $ , $\lambda = L e^{i\psi} $ . After some calculations I got the following equation: $$ (L^2 + R^2) \sin(\phi) + L(1 + R^2) \sin(\phi - \psi) - 2LR\sin(2\phi - \psi) = 0. $$ We have to solve it for $\phi$ . I don't know, how to do it (neither does Wolframalpha). Secondly, I notice that if $x_m$ is the point of maxima on the circle, then $$ Arg \frac{P(x_m)}{P'(x_m)} = Arg (x_m). $$ The reason is that in other way we could step a little inside the cirle and increase the $ |P(x)| $ (it is almost obvious if you draw the picture). But that would be contrary to the maximum modulus principle ( $ P(x) $ is holomorphic). That gives us folowing: $$ \frac{x_m^2 - (\lambda+1)x_m + \lambda}{2x_m^2 - (\lambda+1)x_m} \in \mathbb{R}_+. $$ And again, I do not know, what can you do next. Maybe there is some geometry approach?","['analytic-geometry', 'geometry', 'complex-analysis', 'optimization', 'complex-numbers']"
4464543,Relation of Hamel basis with the equation $f(x + y) = f(x) + f(y)$? [duplicate],"This question already has an answer here : Overview of basic facts about Cauchy functional equation (1 answer) Closed 2 years ago . I am reading ""Linear and Nonlinear Functional Analysis with Applications by Philippe G. Ciarlet "", which explains the origin of hamel basis by a problem: Describe the set $F$ of all functions: $f: \mathbb{R} \rightarrow \mathbb{R}$ that satisfying the functional equation $$
f(x + y) = f(x) + f(y)
$$ for all $x,y\in \mathbb{R}$ Actually I don't know how to describe this in a right way, and I always foucs on some concrete quality (for example, $f(0) = 0, f(x) = f(-x)$ ). Therefore, I don't figure out the connection between this and Hamel basis.","['analysis', 'real-analysis', 'functions', 'functional-analysis', 'hamel-basis']"
4464581,Can $⟨a_n⟩$ be oscillatory if $\lim_{n\rightarrow\infty}a_{n+1}/a_n = 1$?,"Let $⟨a_n⟩$ be a sequence of real numbers such that $a_n \neq 0$ . Suppose $\lim_{n\rightarrow\infty}a_{n+1}/a_n = 1$ . Can this sequence be oscillatory? If not, how do we prove this? NB: By oscillating, I mean sequences that do not diverge properly (i.e they do not go to positive or negative infinity). For instance, a sequence like $⟨1,2,1,2,1,2,\dots⟩$ or $n·(-1)^n$ .","['limits', 'sequences-and-series', 'real-analysis']"
4464640,Placing different colors of indistinguishable balls around a circle,"$3n$ indistinguishable balls are coloured with $n$ colours so that each colour is to be used exactly three times. In how many ways these coloured balls can be placed around a circle so that $3$ balls with same colour never appears side by side? Using inclusion-exclusion principle , i found that $$\sum_{i=0}^{n}\binom{n}{i}(-1)^i\frac{[3n-(2i+1)]!}{3!\times(n-i)}$$ However , i am not sure about my answer.. I suspect that i am doing overcounting and Polya must have been used. What do you think ?","['combinations', 'solution-verification', 'combinatorics', 'discrete-mathematics']"
4464647,"Does the property $A \operatorname{adj}(A) = \operatorname{adj}(A)\,A = \det(A)\,I$ define the adjugate matrix?","Many textbooks define the adjugate matrix $\operatorname{adj}(A)$ as the transpose of the matrix of cofactors of $A$ . Then they state that $A \operatorname{adj}(A) = \operatorname{adj}(A)\,A = \det(A)\,I$ . My question is: if we have a matrix $B$ such that $AB = BA = \det(A)\,I$ , must $B$ be equal to $\operatorname{adj}(A)$ ? In other words, can we define the adjugate of $A$ as the matrix satisfying $A \operatorname{adj}(A) = \operatorname{adj}(A)\,A = \det(A)\,I$ ?","['matrices', 'linear-algebra']"
4464666,How does Wiles' proof fail at $n=2$?,"The content is miles outside what I know about.
So the question is a mixture of idle curiosity and maybe having this answered somewhere on the Internet. It is likely I will not be able to understand the answer. How exactly does Wiles' proof of Fermat's Last Theorem fail for $n=2$ ?","['elliptic-curves', 'number-theory', 'pythagorean-triples', 'diophantine-equations', 'modular-forms']"
4464680,"What is $\sum_{k = 1}^n (k \log k)\binom{n}{k}$? If the exact answer is difficult to find, what is the tightest asymptotic upper bound?","While trying to solve the complexity of my program I came across the the following summation: $$\sum_{k = 1}^n (k \log k)\binom{n}{k}$$ Could you please provide a solution to this sum. If it is difficult to obtain the exact solution, could you please provide an asymptotic upper bound that is as close as possible? I was able to obtain the following asymptotic upperbound: \begin{align*}
\sum_{k = 1}^n (k \log k)\binom{n}{k}
&= \mathop{O}\left(\sum k(k-1) \binom{n}{k} \right) \\
&= \mathop{O}\left(\sum n(n-1) \binom{n-2}{k-2} \right) \\
&= \mathop{O}\left(n^2 \sum \binom{n-2}{k-2} \right) \\
&= \mathop{O}(n^2 2^n)
\end{align*} Is it possible to get smaller upper bound, for example $O(2^n n \log n)$ .","['summation', 'binomial-coefficients', 'combinatorics', 'asymptotics']"
4464722,"$\triangle ABC$ has circumcenter $O$; $BO$ and $CO$ meet $AC$ and $AB$ at $D$ and $E$. If $\angle A=\angle EDA=\angle BDE$, show they are $50^\circ$","There is surely a purely geometrical solution to this problem, but none forthcoming so far!
Trigonometry confirms the result, however the quest is to solve this geometrically, almost certainly involving a clever construction, leading to an equilateral triangle and hence exposing angle values. So a possible nod to “Adventitious Angles”…. … OR, could it be possible to prove the impossibility of a purely geometrical proof? $O$ is the circumcenter of $\triangle ABC$ . $BO$ cuts $AC$ at $D$ , and $CO$ cuts $AB$ at $E$ , as in the figure. Angles $EAD$ , $EDA$ , and $BDE$ are equal. Prove that their value is $50^\circ$ You can quickly work out all the angles in terms of x and y=angle OBC and discover that x+y=90. Also that triangle COD is isosceles and further that it’s sufficient to prove triangle BCE isosceles to get the answer. This may help ... repeat “may”! Define point F on AD such that CE = CF. Then since triangle COD is isosceles, then (among other things) EF is parallel to OD.  Angle BCF will ultimately be shown to be 60 degrees, so we need to show that triangle BFC is equilateral.  Worth exploring a bit; I’m convinced the key is the equilateral triangle because this forces another relationship between x and y. UPDATE:-
I have made a bit of progress via the construction of the line BF, as described above.
Since triangle COD is isosceles and CF=CE by construction, then triangle CEF is also
isosceles and is similar to triangle COD. The following can then be proved:- Angle EFD = 180-2x Angle FED = x FE=FD FD=EO triangle EFA is congruent to triangle EDO triangle EFA is similar to triangle ABD Now construct the line FO and drop a perpendicular from O to point G on BC. Then the
following can be proved: FO bisects angle EOD into x + x and also bisects angle FB into (180-3x) + (180-
3x) The points F O and G are colinear BG = GC Triangles CFG and GFB are congruent CF = FB Triangle CFB is isosceles with CF = FB BUT .... we still need to prove that triangle CFB is equilateral, which is very elusive.  There are two distinct ideas here…
SO ... any help is greatly appreciated! Thanks for your interest.","['euclidean-geometry', 'circles', 'geometry', 'triangles', 'plane-geometry']"
4464730,"$ \int_{-\infty}^{\infty} \frac{\sin^3 x}{x^3} \, dx$ using contour integration.","$\int_{-\infty}^{\infty}\frac{\sin^3{x}}{x^3}dx$ using contour integration.
Hint: Use this analytic continuation: $h(z) = -\frac{e^{3iz}-3e^{iz}}{4z^3}-\frac{1}{2z^3}$ , and then take the imaginary part. EDIT I used the complex exponential definition of $\sin$ to show that $\frac{\sin^3{x}}{x^3} = \operatorname{Im}\left(\frac{e^{3ix}-3e^{ix}}{-4x^3}\right)$ . Therefore, I am really only itnerested in the first term of $h(x)$ for my result. I used a contour that is shown in red - two concentric half-circles with radii $R$ and $r$ . The one with radius $R$ I let expand to infinity, while the one with radius $r$ I let shrink to zero. I argue that on $\gamma_R$ , the integral vanishes because both the exponential terms and the $1/z^3$ terms tend to zero as $R$ increases, and, the integral over $\gamma_r$ vanishes as well since the exponential terms tend to 1 ar $r$ goes to zero. Finally, the total integral is zero by Cauchy. $$ \int_{-\infty}^{\infty} \frac{\sin^3{x}}{x^3} \, dx
= \operatorname{Im} \int_{-\infty}^{\infty}\left(\frac{e^{3ix}-3e^{ix}}{-4x^3}\right) \, dz $$ I integrate by usage of the hinted analytic continuiation: \begin{align*}
&\int_{\gamma} \left(-\frac{e^{3iz}-3e^{iz}}{4z^3}-\frac{1}{2z^3}\right) \, dz \\
&\quad= \operatorname{v.p.} \int_{-\infty}^{\infty} \left(\frac{e^{3ix}-3e^{ix}}{-4x^3}-\frac{1}{2x^3}\right) \, dz \\
&\hspace{3em} + \int_{\gamma_R} \left(-\frac{e^{3iz}-e^{iz}}{4z^3}-\frac{1}{2z^3}\right) \, dz
+ \int_{\gamma_r} \left(-\frac{e^{3iz}-3e^{iz}}{4z^3}-\frac{1}{2z^3}\right)dz \\
&\quad= 0
\end{align*} I only want the integral of the first term of $h(x)$ , I transferred the integrals of $1/x^3$ to the other side and integrated them to get zero again. $$ \operatorname{v.p.} \int_{-\infty}^{\infty} \left(\frac{e^{3ix}-3e^{ix}}{-4x^3}\right) \, dz
= \operatorname{v.p.} \int_{-\infty}^{\infty}\frac{1}{2x^3}dx
= 0 $$ The correct answer should be $3\pi/4$ , which is given in the solutions, and I confirmed with wolfram alpha. However, I have been staring at my method for hours, and I can't find what doesn't check out. In case something is unclear, or if I made any typos, I also provide a picture of my working.","['integration', 'complex-analysis', 'contour-integration']"
4464771,when are graded injective modules graded and injective?,"Define a graded injective module over a graded ring $R$ to be an injective object in $GrMod-R$ (the category of right graded $R$ -modules). From the little research I have done, a graded injective module is not necessarily injective. However, if it is graded and injective then it is graded injective. Question Under what conditions on $R$ , the graded injective modules are exactly the modules that are graded and injective? I know that the latter always holds for graded projectives. Probably my question holds for Artin rings, or perhaps fd algebras (?), but I can't find a reference in the literature ,nor I can prove it...","['homological-algebra', 'injective-module', 'abstract-algebra', 'noncommutative-algebra', 'graded-modules']"
4464793,Representation of $n$-th derivative. [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question The derivative of a function $y = f(x)$ with respect to $x$ is represented as $\frac{dy}{dx}$ The second derivative is represented as $\frac{d^2y}{dx^2}$ and so on. Why is it used like this?","['notation', 'derivatives']"
4464796,Do two sinusoidals with different amplitude and phase always intersect at two places in a time period?,"Consider two trajectories: $$x_1(t)=A \sin t+B\cos t$$ $$x_2(t)=C \sin t+D\cos t$$ I was trying to find how many times the trajectories of two particles that evolve with the above-given equations cross each other in a time interval. On plotting the functions for various values of $(A, B, C, D)$ I found that in a period of $2\pi$ the functions intersected at exactly two values. Is there a theorem that says that there always are exactly two simultaneous solutions of two sinusoidals with different amplitudes and phases in a period?","['trigonometry', 'systems-of-equations']"
4464816,Let $f$ be Lipschitz around $a \in \mathbb R^d$. Then $f$ is Fréchet differentiable at $a$ if and only if $f$ is Gâteaux differentiable at $a$,"This thread is meant to record a question that I feel interesting during my self-study. I'm very happy to receive your suggestion and comments. See: SE blog: Answer own Question and MSE meta: Answer own Question . Anyway, it is written as problem. Let $X$ be a normed space, $A \subset X$ an open set, $f: A \rightarrow \mathbb{R}$ a function, and $a \in A$ a point. For a ""direction"" $v \in X$ , we shall consider the directional derivative $f^{\prime}(a, v)$ , which are defined by: $$
\begin{aligned}
f^{\prime}(a, v) &=\lim _{t \rightarrow 0} \frac{f(a+t v)-f(a)}{t}
\end{aligned}
$$ We shall say that $f$ is: Gâteaux differentiable at $a$ if $f^{\prime}(a, \cdot) \in X^{*}$ , i.e., $f^{\prime}(a, \cdot)$ is everywhere defined, real-valued, linear and continuous); Fréchet differentiable at $a$ if there exists $x^{*} \in X^{*}$ such that $$
\lim _{\|h\| \rightarrow 0} \frac{f(a+h)-f(a)-x^{*}(h)}{\|h\|}=0 .
$$ Theorem: Let $X, A, f, a$ be as above. Assume that $X=\mathbb{R}^{d}$ and $f$ is Lipschitz on some neighborhood of $a$ . Then $f$ is Fréchet differentiable at $a$ if and only if $f$ is Gâteaux differentiable at $a$ .","['derivatives', 'lipschitz-functions', 'real-analysis']"
4464826,Number of matrices over finite fields $\mathbb{F}_q$ with some minors to be $0$ is (or is not?) polynomial in $q$?,"It's well-known that $$\# \operatorname{GL}_2(\mathbb{F}_q)=(q^2-1)(q^2-q)$$ is a ( $\mathbb{Z}$ -coefficient) polynomial of $q$ . As a corollary, $$\#\left\{ A \in M_{2\times 2}(\mathbb{F}_q)\, \middle|\,\det A =0 \right\}=q^4-(q^2-1)(q^2-q)$$ is a polynomial of $q$ . In general, fix $n \in \mathbb{N}_{>0}$ , $\Lambda$ denotes for the subset of $$X:=\left\{ (k,I,J)\, \middle|\, \begin{aligned}
  	&I:1 \leqslant i_1 < \cdots <i_k \leqslant m\\
  	&J:1 \leqslant j_1 < \cdots <j_k \leqslant m
  	\end{aligned}  \right\},$$ $A_{I,J}$ denote for the corresponding minor, is $$\#\left\{ A \in M_{n\times n}(\mathbb{F}_q)\, \middle|\,A_{I,J} =0, \;\forall\, (k,I,J) \in \Lambda  \right\}$$ always a polynomial of $q$ ? A possible nontrivial case to work with: $$\#\left\{ A \in M_{3\times 3}(\mathbb{F}_q)\, \middle|\,\begin{vmatrix} a_{11} & a_{12}  \\ a_{21} & a_{22}  \end{vmatrix} =\begin{vmatrix} a_{22} & a_{23} \\ a_{32} & a_{33}  \end{vmatrix} =\begin{vmatrix} a_{11} & a_{12} & a_{13} \\ a_{21} & a_{22} & a_{23} \\a_{31} & a_{32} & a_{33}  \end{vmatrix}=0 \right\}.$$ When the answer is true, maybe the proof can be generalized to show that $$\#\left\{ A \in M_{n\times n}(\mathbb{F}_q)\, \middle|\,\begin{aligned}
  	&A_{I_1,J_1} =0, \;\forall\, (k,I_1,J_1) \in \Lambda_1\\
  	&A_{I_2,J_2} =1, \;\forall\, (k,I_2,J_2) \in \Lambda_2\\
    &A_{I_3,J_3} \neq 0, \;\forall\, (k,I_3,J_3) \in \Lambda_3
  	\end{aligned}  \right\} \qquad (\ast)$$ is a polynomial of $q$ , where $\Lambda_1, \Lambda_2,\Lambda_3$ are disjoint subsets of $X$ . When the answer is false, the counterexample should be not too complicated. Anyhow, this can be viewed as a purely combinational problem. Related question: Number of $3\times 3$ anticommuting matrices over finite fields $\mathbb{F}_p$ is (or is not?) polynomial in $p$ ? Edit: at least for the generalization $(\ast)$ , there is a counterexample. The number \begin{equation}
\begin{aligned}
&\#\left\{ \begin{pmatrix} a & 0 & 0 \\ 0 & b & 0 \\ 0 & 0 & c  \end{pmatrix} \in M_{3\times 3}(\mathbb{F}_q)\, \middle|\,\begin{vmatrix} a & 0 \\ 0 & b  \end{vmatrix} =\begin{vmatrix} b & 0 \\ 0 & c  \end{vmatrix} =\begin{vmatrix} a & 0 \\ 0 & c  \end{vmatrix}=1 \right\}\\
=\;& \#\left\{ a \in \mathbb{F}_q^{\times}\, \middle|\,a^2=1 \right\}
\end{aligned}
\end{equation} is not a polynomial of $q$ .","['algebraic-geometry', 'linear-algebra', 'polynomials', 'combinatorics']"
4464827,"If $\sum_{n=1}^{\infty}{a_{[f(n)]}}$ converges, then $\sum_{n=1}^{\infty}{\frac{a_n}{f(n)}}$ converges.","I am trying to determine whether the following statement is true or false: Let $a_n$ be a decreasing positive sequence such that $\displaystyle \sum \limits _{n=1}^\infty a_n$ diverges, and let let $f$ be a function such that $\lim\limits_{n\to\infty} f(n) = \infty$ . If $\displaystyle \sum \limits _{n=1}^\infty a_{[f(n)]}$ converges, then $\displaystyle \sum \limits _{n=1}^\infty \frac{a_n}{f(n)}$ converges. I tried to use the comparison test but could not find any candidates. It does seems the second sum is smaller than the first, but finding an upper bound didn't work either. This question is from our calculus course booklet, expert difficulty level. Any hints will be appreciated.","['calculus', 'sequences-and-series', 'real-analysis']"
4464828,weak convergence + bounded second moment implies convergence of the moment?,"Let $\{\mu_N\}$ be a sequence of random measures which converges almost surely in the weak sense to a deterministic measure $\mu$ with impact support. The weak convergence does not necessarily imply the convergence of the moments. But, my question is that, if we add the assumption that the second moment of $\mu_N$ is almost surely bounded, can we deduce that the second moment of $\{\mu_N\}$ converges to the second moment of $\mu$ ?","['measure-theory', 'probability-theory', 'weak-convergence']"
4464885,Does any edge-to-edge tiling of the Euclidean plane by convex regular polygons have only demiregular vertex configurations?,"In the Euclidean plane, a vertex figure of an edge-to-edge tiling by convex regular polygons is called demiregular if and only if its vertex configuration is $3.3.4.12, 3.3.6.6, 3.4.3.12,$ or $3.4.4.6$ in one of the given orders. A vertex configuration lists the cyclic order of the number of edges around each face that it touches. For example, $3.6.3.6$ or $3.4.6.4$ are not demiregular. All non-demiregular usable vertex figures are semiregular, meaning that there exists a vertex-transitive tiling of the plane using only that vertex figure. There does not exist any tiling of the plane that uses only one type of demiregular vertex figure (this is part of the inspiration the definition of demiregular.) Can any combination of demiregular vertex figures create a tiling of the plane without including any semiregular vertex figures?","['euclidean-geometry', 'tessellations', 'geometry', 'polygons', 'tiling']"
4464910,Is the closed form of $\int_0^1\frac{\text{Li}_{2a+1}(x)}{1+x^2}dx$ known in the literature?,"Using $$\text{Li}_{2a+1}(x)-\text{Li}_{2a+1}(1/x)=\frac{i\,\pi\ln^{2a}(x)}{(2a)!}+2\sum_{k=0}^a \frac{\zeta(2a-2k)}{(2k+1)!}\ln^{2k+1}(x)\tag{1}$$ and $$\int_0^1x^{n-1}\operatorname{Li}_a(x)\mathrm{d}x=(-1)^{a-1}\frac{H_n}{n^a}-\sum_{k=1}^{a-1}(-1)^k\frac{\zeta(a-k+1)}{n^k}\tag{2}$$ We have $$\int_0^1\frac{\text{Li}_{2a+1}(x)}{1+x^2}dx=(2^{-4a-3}-2^{-2a-3})\pi\zeta(2a+1)+\frac{2a+1}{2}\beta(2a+2)$$ $$-\sum_{k=0}^a \zeta(2a-2k) \beta(2k+2);\tag{3}$$ $$\int_0^1\frac{\ln^{2a}(x)\ln(1-x)}{1+x^2}dx=\frac{(2a)!}{2}\ln(2)\beta(2a+1)-\frac{(2a+1)!}{2}\beta(2a+2)$$ $$+(2a)!\sum_{k=0}^a \zeta(2a-2k) \beta(2k+2);\tag{4}$$ $$\sum_{n=0}^\infty\frac{(-1)^n H_{2n+1}}{(2n+1)^{2a+1}}=(2^{-4a-3}-2^{-2a-3})\pi\zeta(2a+1)+\frac{2a+1}{2}\beta(2a+2)$$ $$-\sum_{k=0}^a \zeta(2a-2k) \beta(2k+2)+\sum_{k=1}^{2a}(-1)^k\zeta(2a-k+2)\beta(k).\tag{5}$$ Proof of $(1)$ : Differentiating then integrating back, we have $$\text{Li}_2(x)+\text{Li}_2(1/x)=-i\pi\ln(x)-\frac12\ln^2(x)+c$$ where $c=2\zeta(2)$ by setting $x=1$ . Keep dividing by $x$ then integrate, we get $$\text{Li}_3(x)-\text{Li}_3(1/x)=-i\pi\frac{\ln^2(x)}{2}-\frac{\ln^3(x)}{3!}+2\zeta(2)\ln(x)$$ $$\text{Li}_4(x)+\text{Li}_4(1/x)=-i\pi\frac{\ln^3(x)}{3!}-\frac{\ln^4(x)}{4!}+\zeta(2)\ln^2(x)+2\zeta(4)$$ This pattern shows that $$\text{Li}_{2a}(x)+\text{Li}_{2a}(1/x)=-\frac{i\,\pi\ln^{2a-1}(x)}{(2a-1)!}+2\sum_{k=0}^a \frac{\zeta(2a-2k)}{(2k)!}\ln^{2k}(x)$$ $$\text{Li}_{2a+1}(x)-\text{Li}_{2a+1}(1/x)=-\frac{i\,\pi\ln^{2a}(x)}{(2a)!}+2\sum_{k=0}^a \frac{\zeta(2a-2k)}{(2k+1)!}\ln^{2k+1}(x)$$ These two identities are good for $x\ge1$ . To make them work for $x\le1$ , let $x\to 1/x$ , we get $$\text{Li}_{2a}(x)+\text{Li}_{2a}(1/x)=\frac{i\,\pi\ln^{2a-1}(x)}{(2a-1)!}+2\sum_{k=0}^a \frac{\zeta(2a-2k)}{(2k)!}\ln^{2k}(x)$$ $$\text{Li}_{2a+1}(x)-\text{Li}_{2a+1}(1/x)=\frac{i\,\pi\ln^{2a}(x)}{(2a)!}+2\sum_{k=0}^a \frac{\zeta(2a-2k)}{(2k+1)!}\ln^{2k+1}(x)$$ Proof of $(2)$ : Using the definition of the harmonic number, $$H_n=\int_0^1\frac{1-x^n}{1-x}dx\overset{IBP}{=}-n\int_0^1 x^{n-1}\ln(1-x)dx$$ $$\overset{IBP}{=}n\left(\zeta(2)-n\int_0^1 x^{n-1}\text{Li}_2(x)dx\right)$$ $$\overset{IBP}{=}n\left(\zeta(2)-n\left(\zeta(3)-n\int_0^1 x^{n-1}\text{Li}_3(x)dx\right)\right).$$ Integrating by parts repeatedly gives $(2)$ . Proof of $(3)$ : $$\int_0^1\frac{\text{Li}_{2a+1}(x)}{1+x^2}dx=\int_0^\infty\frac{\text{Li}_{2a+1}(x)}{1+x^2}dx-\underbrace{\int_1^\infty\frac{\text{Li}_{2a+1}(x)}{1+x^2}dx}_{x\to 1/x}$$ $$=\int_0^\infty\frac{\text{Li}_{2a+1}(x)}{1+x^2}dx-\int_0^1\frac{\text{Li}_{2a+1}(1/x)}{1+x^2}dx$$ add the integral to both sides $$2\int_0^1\frac{\text{Li}_{2a+1}(x)}{1+x^2}dx=\int_0^\infty\frac{\text{Li}_{2a+1}(x)}{1+x^2}dx+\int_0^1\frac{\text{Li}_{2a+1}(x)-\text{Li}_{2a+1}(1/x)}{1+x^2}dx$$ $$=I_1+I_2\tag{b}$$ For the first integral, write the integral form of the polylogarithm, $$I_1=\int_0^\infty\frac{1}{1+x^2}\left(\frac1{(2a)!}\int_0^1 \frac{x\ln^{2a}(y)}{1-xy}dy\right)dx$$ $$=\frac1{(2a)!}\int_0^1 \ln^{2a}(y)\left(\int_0^\infty\frac{x}{(1+x^2)(1-xy)}dx\right)dy$$ $$=\frac1{(2a)!}\int_0^1 \ln^{2a}(y)\left(-\frac{\pi}{2}\frac{y}{1+y^2}-\frac{i\pi}{1+y^2}-\frac{\ln(y)}{1+y^2}\right)dy$$ $$=(4^{-2a-1}-4^{-a-1})\pi\zeta(2a+1)-i\pi\beta(2a+1)+(2a+1)\beta(2a+2).$$ For the second integral, by using $(1)$ , we have $$I_2=\frac{i\,\pi}{(2a)!}\int_0^1\frac{\ln^{2a}(x)}{1+x^2}dx+2\sum_{k=0}^a  \frac{\zeta(2a-2k)}{(2k+1)!}\int_0^1\frac{\ln^{2k+1}(x)}{1+x^2}dx$$ $$=i\,\pi\beta(2a+1)-2\sum_{k=0}^a \zeta(2a-2k)\beta(2k+2).$$ Plugging $I_1$ and $I_2$ in $(b)$ completes the proof. Proof of $(4)$ :  Again, using the integral form of the polylogarthm, we have $$\int_0^1\frac{\text{Li}_{2a+1}(x)}{1+x^2}dx=\int_0^1\frac{1}{1+x^2}\left(\frac1{(2a)!}\int_0^1 \frac{x\ln^{2a}(y)}{1-xy}dy\right)dx$$ $$=\frac1{(2a)!}\int_0^1 \ln^{2a}(y)\left(\int_0^1\frac{x}{(1+x^2)(1-xy)}dx\right)dy$$ $$=\frac1{(2a)!}\int_0^1 \ln^{2a}(y)\left(\frac{\ln(2)}{2(1+y^2)}-\frac{\pi\,y}{4(1+y^2)}-\frac{\ln(1-y)}{1+y^2}\right)dy$$ $$=\frac12\ln(2)\beta(2a+1)+(2^{-4a-3}-2^{-2a-3})\pi\zeta(2a+1)-\frac1{(2a)!}\int_0^1\frac{\ln^{2a}(x)\ln(1-x)}{1+x^2}dx.$$ The integral on the LHS is given in $(2)$ . Proof of $(5)$ : $$\int_0^1\frac{\text{Li}_{2a+1}(x)}{1+x^2}dx=\sum_{n=0}^\infty (-1)^n\int_0^1 x^{2n} \text{Li}_{2a+1}(x) dx$$ use the result $(2)$ $$=\sum_{n=0}^\infty (-1)^n\left(\frac{H_{2n+1}}{(2n+1)^{2a+1}}-\sum_{k=1}^{2a}(-1)^k \frac{\zeta(2a-k+2)}{(2n+1)^k}\right)$$ $$=\sum_{n=0}^\infty\frac{(-1)^n H_{2n+1}}{(2n+1)^{2a+1}}-\sum_{k=1}^{2a} (-1)^k \zeta(2a-k+2)\sum_{n=0}^\infty\frac{(-1)^n}{(2n+1)^k}$$ $$=\sum_{n=0}^\infty\frac{(-1)^n H_{2n+1}}{(2n+1)^{2a+1}}-\sum_{k=1}^{2a} (-1)^k \zeta(2a-k+2)\beta(k).$$ Question: Are the results $(3)$ to $(5)$ known in the literature? If so, any reference? Thanks.","['integration', 'reference-request', 'harmonic-numbers', 'polylogarithm', 'sequences-and-series']"
4464932,Solving equation involving roots and powers .,"I'm trying to solve this equation : $\sqrt{3}\sqrt{237x^2 + \frac{224}{x^2}}x^7 + \frac{35293}{222}x^8 + \frac{2}{999}\sqrt{3}{(\sqrt{237x^2 + \frac{224}{x^2}})}^3x^5 - \frac{44968}{111}x^4 + \frac{12544}{333}=0$ . It looks pretty complicated to me, but the computer gives me exact solutions. For example one real solution is $\frac{2}{\sqrt{3}}$ , and another : $-\frac{2}{3^{\frac{3}{4}}\sqrt[4]{7}}$ and so on. Does anyone know how to obtain the exact solutions to the above equation? Thanks in advance! EDIT: This came from fooling around with functions that describe surfaces spanned by the roots of polynomials $x^4+c_2x^2+c_3x+c_4$ in 3 dimensions. So here $r_1+r_2+r_3+r_4=0$ . Newton's identity $r_1^4+r_2^4+r_3^4+r_4^4 = 4$ (the 4 here is randomly chosen) can thus be represented as a 2D surface in 3D. With some other transformations this gives : $-\frac{1}{3}\sqrt{6}\sqrt{3}x_1x_2^2x_3 + \frac{1}{9}\sqrt{6}\sqrt{3}x_1x_3^3 + \frac{7}{12}x_1^4 + \frac{1}{2}x_1^2x_2^2 + \frac{1}{2}x_2^4 + \frac{1}{2}x_1^2x_3^2 + x_2^2x_3^2 + \frac{1}{2}x_3^4 = 4$ .
This surface looks somewhat like an octahedron. To find the extrema on the surface I used Lagrange multipliers leading to the equation in question. So I guess it's not very surprising that this has an exact solution. But I was surprised that the computer could find them so easily..","['complex-analysis', 'roots', 'polynomials', 'real-analysis']"
4464943,[FEEDBACK]: Proving that the union of any two infinite countable sets is countable [duplicate],"This question already has answers here : Show that the countable union of countable sets is countable - conceptualisation help (1 answer) Prove that the union of countably many countable sets is countable. (9 answers) Finite union of countable sets is countable. (2 answers) Closed 2 years ago . I made the following proof for an excercise regarding the union of two countable infinite sets, namely, that their union is countable. It would be of great help if anyone could give me some feedback regarding the argument (ranging from the quality of the argument to some improvements). Btw, thanks for your attention. The proof is as follows: Since $A_{1}$ and $A_{2}$ are countable, it follows that there are biijective functions $f:\mathbb{N} \to A_{1}$ and $g:\mathbb{N} \to A_{2}$ . Let $B_{2} = A_{2}\backslash A_{1}$ and so $A_{1}\cap B_{2} = \emptyset$ . Also, consider the following sets $S_{1} = \{n\in \mathbb{N}: f(n)\in A_{1}\}$ and $S_{2} = \{n\in \mathbb{N}: g(n) \in B_{2}\}$ since $B_{2} \subseteq A_{2}$ . If $B_{2} = \emptyset$ , then $A_{1}\cup A_{2} = A_{1}$ and so $f:\mathbb{N} \to A_{1}\cup A_{2}$ is a biijective function and $A_{1}\cup A_{2}$ is countable. Hence, we may assume that $B_{2}\neq \emptyset$ . By the Well Ordering Principle , $s_{2} = \min (S_{2})$ exists. Note that $S_{1} = \mathbb{N}$ and $1\leq s_{2}$ . Therefore, there are two possible cases. If $B_{2}$ is finite with $k$ elements, then define the function $h:\mathbb{N} \to A_{1}\cup B_{2}$ by $\begin{align*}
						h(n) \begin{cases}
							g(s_{1}+(n-1)), \text{ if }n\leq k\\
							f(n-k), \text{ if }n>k.
						\end{cases}
					\end{align*}$ Therefore, $A_{1}\cup B_{2} = A_{1}\cup A_{2}$ is countable. If $B_{2}$ is infinite, then define some function $h:\mathbb{N} \to A_{1}\cup B_{2}$ by $\begin{equation*}
						h(n) = \begin{cases}
							f(n/2), \text{ if }n \text{ is even}.\\
							g(s_{1} + (n-1)/2), \text{ if }n \text{ is odd}.
						\end{cases}
					\end{equation*}$ Thus, $A_{1}\cup B_{2} = A_{1}\cup A_{2}$ is countable.","['elementary-set-theory', 'cardinals', 'solution-verification']"
4464986,Is the height of sand as a function of time any different between a 2D hourglass and its 3D counterpart?,"I'm trying to (eventually) model a 3D hourglass by calculating the height of sand in both upper and lower sections as a function of (percent of total) time, and representing that in 2D. So I suppose there will be further questions. ESTABLISHED CONDITIONS: we have an hourglass (sand timer) that is derived from a mathematical shape such as two mirrored cones or something more complex like a lemniscate. the volume of sand is equal to exactly one half of the hourglass -- one of the two sections I am not modeling the physical properties of sand -- we can assume a level top surface sand falls at a constant rate we know the amount of time is takes for all the sand to fall Since sand falls at a constant rate, we know that the volume of sand (as a percentage of total volume) in the lower section will always be directly proportional to the percent of time expired. Therefore, the height of the sand in either upper or lower sections should always be some function of: The shape of the section The amount of the sand in it But before I start trying to do this, my first question is, am I correct to assume that we will get the same height value whether we think/calculate in terms of the 2d version (using only areas) vs the 3d version (using only volumes) of the hourglass -- the ""real"" hourglass vs its own [perfect/unskewed/unaltered] shadow on the wall? This would not be true for a shape whose 3d ""version"" could not be inferred from its 2d ""version."" But, in this case, I think this is true because it makes intuitive sense, and the 2d version of an hourglass is simply a ""subsection/cross-section"" (and is the same at any angle of rotation) of the 3d version. But on the other hand, I think it could be false because if we were to take the same logic and step down to a one-dimensional cross section, it would become nonsensical and obvious that we are losing information.","['calculus', 'geometry']"
4465037,Is there a differentiable function $f$ with partial derivatives $f_x = y$ and $f_y = -x$?,"There is $f: \mathbb{R}^2 → \mathbb{R}$ differentiable such that $∂x(x, y) = y$ and $∂y(x, y) = −x$ for all $(x, y) \in \mathbb{R}^2$ A hint on how to prove if this is true or false, please? I've been trying to find a function $f(x,y)$ to prove this, but I can't find one that is both differentiable and has $f_x = y$ and $f_y = -x$",['multivariable-calculus']
4465038,Closure of balls in Reproducing Kernel Hilbert Space (RKHS),"Let $X \subset \mathbb{R}^m$ be compact, and $k: X\times X \rightarrow \mathbb{R}$ be a universal kernel function, in the sense that the corresponding RKHS $\mathcal{H}_k$ is dense in $C(X)$ under the uniform metric $\| \cdot \|_{\infty}$ . Denote by $\| \cdot \|_{\mathcal{H}_k}$ the RKHS-norm. The literature in statistical learning tends to argue for the use of kernel methods based on the denseness of $\mathcal{H}_k$ in $(C(X),\|\cdot\|_{\infty})$ . However, most of times the rigorous analysis in statistical learning theory is restricted to a subset of $\mathcal{H}_k$ , say $$
B_M := \{ h\in \mathcal{H}_k : \|h\|_{\mathcal{H}_k} \leq M \}
$$ for some constant $M>0$ . I am wondering how well $B_M$ can approximate $C(X)$ . For that, I would like to know more about the closure (with respect to $\|\cdot\|_{\infty}$ ) of $B_M$ . Is there a clean form of the closure? Here is what I tried: By Mercer's theorem, we have $$
k(x,x') = \sum_{j=1}^{\infty} \lambda_j \phi_j(x) \phi_j(x').
$$ Let $\varphi_j(x) = \sqrt{\lambda_j} \phi_j(x)$ , and then $(\varphi_j)$ is an orthonormal basis of $\mathcal{H}_k$ . We rewrite $$
B_M = \{ x \mapsto \langle\beta, \varphi(x) \rangle_{\ell_2} : \|\beta\|_{\ell_2} \leq M \}.
$$ But I don't know how to proceed further.","['machine-learning', 'statistics', 'functional-analysis', 'reproducing-kernel-hilbert-spaces']"
4465158,When to know which proof method to use : indirect or direct proof [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Prove that for all integers x and y, if x² + y² is even then x + y is even. Now for this question how can I determine which proof method to use if it is not mentioned in question. Or can I use any of the method:
Direct, indirect(contradiction, contraposition) for proving above statement.
I am very noob at this so please help me.","['algebra-precalculus', 'proof-writing', 'logic']"
4465161,"Floquet Theory $\phi(t)=P(t)e^{tR}$, can be $R$ Hermitian?","Let ${\displaystyle {\dot {x}}=A(t)x}$ be a linear first order differential equation, where ${\displaystyle x(t)}$ is a column vector of length ${\displaystyle n}$ and ${\displaystyle A(t)}$ an ${\displaystyle n\times n}$ periodic matrix with period ${\displaystyle T}$ (that is ${\displaystyle A(t+T)=A(t)}$ for all real values of ${\displaystyle t}$ . Let ${\displaystyle \phi(t)}$ be a fundamental matrix solution of this differential equation. The Floquet Theory tells us that there is a constant matrix $R$ (possibly complex) and a T-periodic matrix valued function ${\displaystyle t\mapsto P(t)}$ such that $$\phi(t)=P(t)e^{tR}.$$ This gives rise to a time-dependent change of coordinates ${\displaystyle y=P^{-1}(t)x}$ , under which our original system becomes a linear system with constant coefficients ${\displaystyle {\dot {y}}=Ry}$ . My question: Does $R$ follow the algebraic properties of $A(t)$ . For example if $A(t)$ is Hermitian, can we chose $R$ to be also Hermitian? The same question when $A(t)$ is skew-Hermitian, unitary,...","['ordinary-differential-equations', 'periodic-functions', 'matrices', 'hermitian-matrices', 'linear-algebra']"
4465224,Some questions on polynomial $f(x)=x^4+x^2+4$ over $\mathbb{Q}$,"1-) Firstly, I have shown that $f(x)$ is irreducible over $\mathbb{Q}$ . To show, I first use the theorem that says: $$\text{Suppose there exist } r \in \mathbb{Q} \text{ such that } f(r)=0.\text{ Then } r\in\mathbb{Z} \text{ and }r|a_{0} \text{, where } a_0 \text{ constant coefficient of the polynomial.}$$ $$f(1)\neq0,\;f(-1)\neq0,\;f(2)\neq0,\;f(-2)\neq0,\;f(4)\neq0,\;f(-4)\neq0$$ But, since $\deg(f(x))=4$ , we cannot say anything about roots. Clearly, we cannot use Eisenstein Criterion either. Now, we can check whether it has any non-linear factors. Fortunately, it has! $$x^4+x^2+4=(x^2+x\sqrt{3}+2)(x^2-x\sqrt{3}+2)$$ But, $\sqrt{3} \notin \mathbb{Q}$ .Therefore $x^4+x^2+4$ is irreducible over $\mathbb{Q}$ . Here is the question. Can I say $f(x)$ is irreducible after all these
calculations? 2-) I defined $$f_{1}(x)=x^2+x\sqrt{3}+2, \;f_{2}(x)=x^2-x\sqrt{3}+2$$ We can say $f=f_{1}\cdot f_{2}$ is reducible over $\mathbb{Q(\sqrt{3})}$ since $\sqrt{3} \in \mathbb{Q(\sqrt{3})}$ . Even $f(x)$ is reducible over extension field $\mathbb{Q(\sqrt3)}$ , $f_{1}$ and $f_{2}$ are irreducible over $\mathbb{Q(\sqrt3)}$ For $f_{1}(x)=x^2+x\sqrt{3}+2$ we have $x_{1,2}=\dfrac{-\sqrt{3}\pm \sqrt{-5}}{2}$ and also for $x_{3,4}=\dfrac{\sqrt{3}\pm\sqrt{-5}}{2}$ . We know that neither $\sqrt{-5} \notin \mathbb{Q}$ nor $\sqrt{-5} \notin \mathbb{Q({\sqrt{3}})}$ . Therefore, we need some new splitting field and it is, clearly, $\mathbb{Q(\sqrt{3},\sqrt{-5})}$ . I think there is no problem. But I have to ask to be sure, Can I extend the field like I did to split the polynomial? 3-) There is extension $\mathbb{Q(\sqrt{3},\sqrt{-5})}$ over $\mathbb{Q(\sqrt{3})}$ . There is also extension $\mathbb{Q(\sqrt{3})}$ over $\mathbb{Q}$ . For the field extension $\mathbb{Q(\sqrt{3},\sqrt{-5})}$ over $\mathbb{Q}$ we have the structure such as: $$\mathbb{Q(\sqrt{3},\sqrt{-5})}=\lbrace r+s\sqrt{3}+t\sqrt{-5}+z\sqrt{-15}:r,s,t,z\in \mathbb{Q}\rbrace$$ So, for the basis, dimension or degree of minimal polynomial we have $4$ and this basis is $\lbrace1,\sqrt{3},\sqrt{-5},\sqrt{-15}\rbrace$ For, the minimal polynomial of $\mathbb{Q(\sqrt{3},\sqrt{-5})}$ over $\mathbb{Q(\sqrt{3})}$ we have $P_{\sqrt{-5}}(x)=x^2+5$ this polynomial is irreducible since $\sqrt{-5}\notin\mathbb{Q(\sqrt{3})}$ . For the minimal polynomial of $\mathbb{Q(\sqrt{3})}$ over $\mathbb{Q}$ we have $P_{\sqrt{3}}(x)=x^2-3$ and it is irreducible over $\mathbb{Q}$ by Eisenstein Criterion. 4-) Clearly $\mathbb{Q(\sqrt{3},\sqrt{-5})}$ is splitting field of $x^4+x^2+2$ over $\mathbb{Q}$ and since it is finite extension, we can say it is a normal extension and it is also separable extension since all the roots of polynomial is simple roots. My whole solving strategies makes sense? Thanks in advance!","['irreducible-polynomials', 'abstract-algebra', 'solution-verification', 'splitting-field', 'polynomials']"
4465255,How do you extract useful information from this calculus question?,"Let $f$ be a twice differentiable function defined in $[-3,3]$ such that $f(0)=-4, f’(3)=0, f’(-3)=12$ , and $f’’(x)\geq-2, \forall x \in [-3,3]$ . If $g(x)=\int_0^x {f(t)dt}$ then find the maximum value of g(x). The thing is that I’m trying to get some info out of this about the function $f$ , by basically having a rough graph, but the criterion $f’’(x)\geq-2$ doesn’t really give me anything because $f$ could be either convex-up(like $x^2$ ) or convex-down(like $-x^2$ ) or even have a point of inflection. It just can’t be too-much-concave-down, if you know what I mean. The function starts off as increasing, but IDK what happens after that.
Also if it were just $\int_0^x {f’(t)dt}$ I might have been more confident, but $\int_0^x {f(t)dt}$ just throws me off.","['calculus', 'definite-integrals', 'derivatives']"
4465256,$f$ is a polynomial and $f(0)\neq0$. Why is $fg+x$ a perfect square for some $g$?,"On Hacker News, someone posted the following exercise : prove that every nonsingular complex symmetric matrix $M$ has a symmetric matrix square root. This is old chestnut. As the poster indicated, essentially every nonsingular Jordan block $J$ has a square root that is a polynomial in $J$ . Therefore, using Hermite interpolation (we need Hermite rather than Lagrange because the Jordan form can have multiple and different-sized Jordan blocks for the same eigenvalue), one can show that $M$ has a square root in the form of $p(M)$ for some polynomial $p$ . However, this implies that the minimal polynomial $f(x)$ of $M$ must divide $p(x)^2-x$ . In other words, given any non-constant polynomial $f\in\mathbb C[x]$ such that $f(0)\neq0$ , there exists a polynomial $g$ such that $f(x)g(x)+x$ is a perfect square. I think this bullet statement somehow must have an elementary proof that is based solely on abstract algebra, but I have forgotten most of what I learnt from class. Any idea?","['alternative-proof', 'abstract-algebra', 'polynomials']"
4465345,"Derivatives of a function $y(x)$ which is implicitly defined by $F(x,y)=0$","I have a function $F(x,y)$ for which I have the analytic expression, and I also know all the partial derivatives $\frac{\partial^{(m+n)}F}{\partial x^m \partial y^n}$ . For each $x$ , the equation $F(x,y) = 0$ has a unique solution for $y$ , i.e. $F(x,y) = 0$ implicitly defines a function $y(x)$ which is continuous and differentiable. I would like to express the derivatives $\frac{d^py}{dx^p}$ of the function $y(x)$ in terms of the known partial derivatives $\frac{\partial^{(m+n)}F}{\partial x^m \partial y^n}$ . How should I proceed?","['multivariable-calculus', 'calculus']"
4465444,Is there a variant of the binomial distribution formula that solves for successes instead of probability?,"I'm a programmer and trying to create a hash function that reliably distributes features over a length of data based on probability and seed. A generative algorithm of this kind would be simple to make but I want to make in the form of a hash so that I can process the data in parallel without intercommunication. Anyways, I'm not very strong at math but my research led me to the binomial distribution formula That is almost exactly what I want except that it is sorta inside out. In my hash parameters, I already have the result P(x), I also have n (number of trials) and p (probability of success per trial). What I don't have is x - the number of successes. So basically, I want to go to an arbitrary section of the data I have get a ""random"" number for it from a general purpose random hash that takes position and seed as input and outputs a uniformly distributed pseudorandom value plug that ""random"" number in as the result of the binomial distribution formula (P(x)) along with other parameters like the length of the section (n) and probability of success per trial (p get the answer - how many of the features that I'm distributing reside in this section of the data that I'm evaluating PS! I know that this won't work if I use completely arbitrarily distributed section positions and sizes but no need to worry about that, I'm actually sampling them sequentially in the same size chunks with no overlap. Also I'm aware of the performance nightmare that factorials present to modern computers but I have some bit hacks and specifically chosen hyperparameters to take care of that. Also, I know that I can also get the value I'm seeking by just doing n number of random rolls against the probability per trial but this hash needs to go fast and calculating this many pseudorandom hashes per data section is far too slow. So essentially the question is - is there a version of this cool formula that has x on the left hand side of the equation?","['functions', 'probability']"
4465468,Does an uncountable directed set have an infinite bounded subset?,"Since every uncountable directed set that I check, has an infinite bounded subset (For example $(\mathbb{R},\leq )$ has many such subsets), I want to prove that this question has a positive answer. Does anyone have any idea?
(Thank you)","['elementary-set-theory', 'order-theory', 'logic', 'set-theory']"
4465477,Does continuity of $f(z)$ imply that of $\overline{f(\overline{z})}$?,"I was stuck on a problem with complex-valued functions. Here is the question: If a function $f(z)$ is continuous at a point $z=z_0$ , then does this imply that the induced function $\overline{f(\overline{z})}$ is continuous at $z=z_0$ ? Much help required. Thank you so much!!","['complex-analysis', 'derivatives', 'differential', 'partial-differential-equations']"
4465572,Does local Hölder-continuity suffice to get an upper bound for Hausdorff dimension - or does it need to be global? ((Mistake in the literature?)),"It is a well-known fact that Brownian Motion is almost surely locally $\alpha$ -Hölder continuous for $\alpha\in(0,1/2)$ . This is sometimes used in conjunction with the following result concerning Hausdorff dimension -- when proving McKean's Theorem, for instance (that is, Proposition 2 strengthened to equality). Proposition 1. Let $(M,d_1)$ and $(N,d_2)$ be two metric spaces, and $f:M\to N$ a ( globally ) $\gamma$ -Hölder continuous function with $\gamma$ -Hölder constant $L$ . Then we have, for all $\alpha\geq0$ , and for all subsets $A$ of $M$ , that \begin{equation*}
    \mathcal{H}^{\infty}_{\alpha/\gamma}(f(A))\leq L^{\alpha/\gamma}\cdot\mathcal{H}^{\infty}_{\alpha}(A)
\end{equation*} In particular, we have that $\dim f(A)\leq\frac{1}{\gamma}\dim A$ . $\Diamond$ Here, we denote by $\mathcal{H}^{\infty}_{\alpha}(A)$ the unlimited $\alpha$ -Hausdorff content of $A$ . One then uses Proposition 1, in some way, to show that Proposition 2. Let $\{B(t):t\geq0\}$ be $d$ -dimensional Brownian motion, and fix a subset $A$ of $[0,\infty)$ . Then, almost surely, $\dim B(A)\leq\min(2\dim A,d)$ . $\Diamond$ since we already know that Brownian motion is almost surely locally $\alpha$ -Hölder continuous. My question is: How can we bridge the gap from Hölder continuity in Proposition 1 to just local Hölder continuity? All books I have taken a look at either ignore the distinction between the two -- or just remark that it is sufficient if $f$ is only locally Hölder continuous, without providing a proof. This is, for example, done in Brownian Motion (2010) by Peter Mörters and Yuval Peres, with Remark 4.15 on page 102 ( here is a publicly available pdf, provided by the University of Bath). It seems that the three Bachelor's thesis/essays here , here and here have relied upon that remark without further justification. On the other hand, the books treating Hausdorff measure by Falconer (2003) and Mattila (1995) only state results for globally Hölder continuous functions, and make no mention of strengthened versions for local Hölder continuity. So far, I have tried the following to prove Proposition 1 for locally Hölder continuous functions, but haven't made much progress. Proposition 3. If $(M,d_1)$ is a separable metric space, we can replace the condition "" $f$ is $\gamma$ -Hölder continuous"" in Proposition 1 with "" $f$ is locally $\gamma$ -Hölder continuous everywhere"". $\Diamond$ Attempt of proof. Since $M$ is separable, there exists a countable, dense subset $X$ of $M$ . Then since $f$ is locally $\gamma$ -Hölder continuous everywhere, there exist, for each point $x$ in $X$ , two constants $\delta_{x}>0$ and $L_{x}\geq0$ so that for all $y\in M$ with $d_1(x,y)<\delta_x$ , we have $d_2(f(x),f(y))\leq L_x\cdot\left(d_1(x,y)\right)^{\gamma}$ . As $X$ is dense in $M$ , we have \begin{equation*}
    f(A)=\bigcup_{x\in X}f(B(x,\delta_x))
\end{equation*} and so, by countable stability of $\mathcal{H}^{\infty}_{\alpha}$ and by Proposition 1, it is sufficient to show that $f\vert_{B(x,\delta_x)}$ is $\gamma$ -Hölder continuous for all $x\in X$ . Indeed, fix $x\in X$ and let $y,z$ be two points in $B(x,\delta_x)$ . We see that \begin{equation*}
    d_2(f(x),f(y))\leq L_{x}\cdot\left(d_1(x,y)\right)^{\gamma},\quad d_2(f(x),f(z))\leq L_{x}\cdot\left(d_1(x,z)\right)^{\gamma}
\end{equation*} and, therefore, that \begin{equation*}
    d_2(f(y),f(z))\leq L_{x}\cdot\left(d_1(x,y)\right)^{\gamma}+L_{x}\cdot\left(d_1(x,z)\right)^{\gamma}
\end{equation*} How to go on? $\Diamond$ The definitions of Hölder continuity and local Hölder continuity I'm am referring to here are as below. Definition. Let $(M,d_1)$ and $(N,d_2)$ be two metric spaces, $f:M\to N$ a function and $\gamma>0$ a constant. Then we say that $f$ is $\gamma$ -Hölder continuous if there exists a constant $L\geq0$ so that, for all $x,y\in M$ , \begin{equation*}
    d_2(f(x),f(y))\leq L\cdot\left(d_1(x,y)\right)^{\gamma}
\end{equation*} We then also say that $f$ has $\gamma$ -Hölder constant $L$ . $\Diamond$ Definition. Let $(M,d_1)$ and $(N,d_2)$ be two metric spaces, $f:M\to N$ a function, $\gamma>0$ a constant and $x\in M$ a point. Then we say that $f$ is locally $\gamma$ -Hölder continuous at $x$ if there exist constants $\delta>0$ and $L\geq0$ so that, for all $y\in M$ with $d_1(x,y)<\delta$ , \begin{equation*}
    d_2(f(x),f(y))\leq L\cdot\left(d_1(x,y)\right)^{\gamma}
\end{equation*} We then also say that $f$ has local $\gamma$ -Hölder constant $L$ at $x$ . $\Diamond$ Definition. Let $(M,d)$ be a metric space and $E$ a subset of $M$ . For $\alpha\geq0$ , we define the unlimited $\alpha$ -Hausdorff content of $E$ by \begin{equation*}
\mathcal{H}_{\alpha}^{\infty}(E):=\inf\left\{\sum_n\left\vert F_n\right\vert^{\alpha}:\{F_n\}_n\text{ is a cover of }E\right\}
\end{equation*} Further, we define the Hausdorff dimension of $E$ by \begin{equation*}
\dim E:=\inf\{\alpha\in[0,\infty):\mathcal{H}_{\alpha}^{\infty}(E)=0\}
\end{equation*} Note that both $\mathcal{H}_{\alpha}^{\infty}(E)$ and $\dim E$ are possibly infinite. $\Diamond$","['measure-theory', 'hausdorff-measure', 'stochastic-processes', 'brownian-motion', 'fractals']"
4465573,Probability of getting at least one pair in a combination,"Assume that I have 6 symbols which I label $\{x_1,x_2,x_3,y_1,y_2,y_3\}$ . Now I make a random 6-symbol  combination with repetition, such that every combination has the same probability of occuring. For example we could have drawn 2 times $x_1$ , 3 times $y_2$ and 1 time $y_3$ , but we could have also drawn 5 times $x_1$ and 1 time $x_2$ equally likely. The question that I am now interested in is given a random combination with repetition as described above, what is the probability that the combination has at least one $x$ and one $y$ with the same index? Supplementary: What is the probability if we consider a $M$ -symbol combination made from a set of symbols $\{x_1,...,x_N,y_1,...,y_N\}$ ? Edit: It is a problem that I have come up with myself. It is related to a statistical physics problem where the combinations are my microscopic realizations. I tried to tackle it in the following way: The total number of possible combinations with repetition is $\left(\binom{6}{6}\right)=\binom{11}{6}=462$ . Then I thought the easiest way was to calculate the combinations with no $x$ , $y$ pair with the same indices present. Since there may not be any pairs present we need to choose a symbol with index 1, a symbol with index 2 and a symbol with index 3 and make with them a 6-symbol word. We can choose $2^3=8$ of such triples of symbols with each $\left(\binom{3}{6}\right)=\binom{8}{6}=28$ combinations. Wich would give $8\cdot28=224$ combinations or a probability of $p=1-224/462\approx0.515$ . Which is isn't correct because of some extra combinations that I have counted multiple times. However I have no clue how to correct for these extra countings, in a structured way. So I also tried the other approach of directly counting the probability of at least one pair. There are 3 possible pairs. Assume we have drawn the pair $x_1,y_1$ , this has $\left(\binom{6}{4}\right)=\binom{9}{4}=126$ combinations. Then we need the amount of combinations that are not already counted and contain the pair $x_2$ , $y_2$ , naively I could say it is 2 $\left(\binom{5}{4}\right)=2\binom{8}{4}$ , because we can't have a pair with index 1. But again my naive counting mechanism have problems with multiple countings, which I do not know how to efficiently deal with. I have tried to simulate it such that I could check my answers but none of them are correct. The simulation gives for N=3 and M=6: $p\approx 0.68$ .","['discrete-mathematics', 'combinations', 'combinatorics', 'probability']"
4465582,Arbitrary Mixed Partial Derivatives,"Background: Many textbooks give an example due to Peano of the function $f(x, y) = xy(x^2 - y^2)(x^2 + y^2)^{-1}$ that has mixed partial derivatives at $0$ that are not symmetric. One might wonder how arbitrary mixed partial derivatives can be at a point.  For what choices of an appropriate number of real numbers is there a real-valued function that takes on those values for its partial derivatives at a point? Notation : Let $d\in \mathbb{N}$ and let $[d] = \{1,\ldots,d\}$ .  Let $\mathcal{I}$ be the set of all $n$ -tuples with elements in $[d]$ (that is, $\mathcal{I} = \{(i_{1},\ldots, i_{n}): i_{1},\ldots, i_{n}\in [d]\}$ ).  Let $h:\mathcal{I}\rightarrow \mathbb{R}$ . For which functions $h$ is there a function $f:\mathbb{R}^{d}\rightarrow \mathbb{R}$ so that $$
\frac{\partial}{\partial x_{i_{n}}}\cdots \frac{\partial}{\partial x_{i_{1}}}f = h((i_{1},\ldots, i_{n}))
$$ at $x = 0\in \mathbb{R}^{d}$","['multivariable-calculus', 'calculus', 'real-analysis']"
4465750,Integrating a scalar with respect to a vector with vector limits?,"The following is a line of reasoning you'll often see in physics textbooks. Newton's second law can be formulated in terms of momentum, which yields the following fundamental statement: $$\frac{d \vec{p}}{dt} = \vec{F},$$ which in simple terms states that the the time rate of change of the linear momentum of a particle is equal to the net force acting on the particle. This statement is often rewritten as $$d\vec{p}=\vec{F}dt$$ and integrated to yield a new quantity, referred to as impulse. Now, here's where things start getting confusing. Many authors will integrate with respect to $d\vec{p}$ using vector bounds : $$\int_{\vec{p_1}}^{\vec{p_2}}  d\vec{p}=\int_{t_1}^{t_2} \vec{F} dt $$ which yields $$\vec{p_2}-\vec{p_1} = \int_{t_1}^{t_2} \vec{F} dt$$ or, abbreviated to: $$\vec{p_2}-\vec{p_1} = J$$ where $J$ is then defined to be the impulse . The right-hand side is not problematic here, it's the left-hand side that's bugging me. That brings me to my questions: What does it mean to integrate with respect to a vector (though, not in the usual line integral sense where there's a dot product that can be resolved into a scalar quantity)? Is there a way to visualize what's going on here? What does it mean to have vectors as the limits of integration? Does all of this imply that you could have functions of vectors as the integrand? I.e., with regular integration, you integrate with respect to $x$ , and your integrand is some function of $x$ (say, $\frac{2x}{x^3 +3x + 2}$ ). Do all the regular rules of calculus apply to vectors - in this particular sense? Now, mind you, I'm aware that you could express the integral in terms of a variable transformation as $\int_{t_1}^{t_2} \frac{d\vec{p}}{dt} dt$ using the vector differential definition ( $d\vec{p} = \frac{d\vec{p}}{dt} dt$ ), but I'd like to emphasize that that's not my question as I've seen many authors do this explicitly without the use of a variable transformation.","['integration', 'multivariable-calculus', 'calculus', 'vector-analysis', 'physics']"
4465771,Proving contour integral equal to zero,"Let $G$ be the path traversed once as shown: Show that $\displaystyle{\int_{G}{\dfrac{1}{v^4-1} \text{d}v} = 0}$ . By partial fraction decomposition, $\dfrac{1}{v^4 -1} = \dfrac{1}{4} \left( \dfrac{1}{v-1} - \dfrac{1}{v+1} + \dfrac{i}{v-i} - \dfrac{i}{v+i}  \right)$ The singular points $v = \pm 1, \pm i$ all lie inside the contour $G$ . Thus, from this theorem (*), we have \begin{align*}
\int_{G}{\dfrac{1}{v^4-1} \text{d}v} &= \dfrac{1}{4} \left( \int_{G}{\dfrac{1}{v-1}\text{d}v} - \int_{G}{\dfrac{1}{v+1}\text{d}v} + \int_{G}{\dfrac{i}{v-i}\text{d}v} - \int_{G}{\dfrac{i}{v+i}\text{d}v}  \right) \\
&= \dfrac{1}{4}\left( 2\pi i - 2\pi i + i\left( 2\pi i \right) - i \left( 2\pi i \right) \right) \\
&= \dfrac{1}{4} \left( 0 \right) \\
&= 0
\end{align*} (*) Theorem: Let $C$ be a simple closed contour with a positive orientation such that $v_0$ lies interior to $C$ , then $\displaystyle{\int_{C} {\dfrac{dv}{(v-v_0)^n}} = 2\pi i}$ for $n =1$ and $0$ when $n \neq 1$ is an integer. Is that proof correct? If so, could you also point out if there are still theorems I have to mention to make it more accurate? I'm trying to solve (perhaps overthink) this with the other approach: We see that it is analytic except at $\pm 1$ and $ \pm i$ .
Also, we can apply deformation of the contour $G$ by forming a leaf-like contour and forming the respective circles $C_1, C_2, C_3,$ and $C_4$ . As shown here: The integration can then be evaluated as $$ \int_{G}{\dfrac{1}{v^4-1} \text{d}v} = \int_{C_1}{\dfrac{1}{v^4-1} \text{d}v} + \int_{C_2}{\dfrac{1}{v^4-1} \text{d}v} + \int_{C_3}{\dfrac{1}{v^4-1} \text{d}v} + \int_{C_4}{\dfrac{1}{v^4-1} \text{d}v} $$ And, $$\int_{C_n}{\dfrac{1}{v^4-1} \text{d}v} = \dfrac{1}{4} \left( \int_{C_n}{\dfrac{1}{v-1}\text{d}v} - \int_{C_n}{\dfrac{1}{v+1}\text{d}v} + \int_{C_n}{\dfrac{i}{v-i}\text{d}v} - \int_{C_n}{\dfrac{i}{v+i}\text{d}v}  \right) $$ Note that when $v_n$ lies exterior to $C_n$ , then by Cauchy-Goursat theorem, $\displaystyle{\int_{C_n}{\dfrac{dv}{v-v_n}} = 0}$ . Thus, for $n = 1,$ , $$\int_{C_1}{\dfrac{1}{v^4-1} \text{d}v} = \dfrac{1}{4}(0-0 + i(2\pi i)- 0) = \dfrac{- \pi }{2} $$ for $ n = 2,$ $$\int_{C_2}{\dfrac{1}{v^4-1} \text{d}v} = \dfrac{1}{4}( 2\pi i  - 0 + 0-0) = \dfrac{ \pi i}{2}$$ for $ n = 3,$ $$\int_{C_3}{\dfrac{1}{v^4-1} \text{d}v} = \dfrac{1}{4}(0 - 0 + 0 - i (2\pi i) ) = \dfrac{\pi }{2}$$ for $ n = 4,$ $$\int_{C_4}{\dfrac{1}{v^4-1} \text{d}v} = \dfrac{1}{4}(0 -(2\pi i) + 0-0 ) = \dfrac{ - \pi i }{2}$$ Therefore, $$ \int_{G}{\dfrac{1}{v^4-1} \text{d}v} = \dfrac{- \pi }{2} + \dfrac{ \pi i}{2} + \dfrac{\pi }{2} + \dfrac{ - \pi i }{2} = 0$$ Did I just overcomplicate it? Is my first proof already enough? If any of these proofs are correct, could you also point out if there are still theorems I have to mention for them to make it more accurate?","['complex-analysis', 'contour-integration', 'solution-verification']"
4465772,"Is there any reason as to why, in Leibniz notation, the independent variable of a derivative is written the way it is?","The n-th derivative of $y(t)$ in leibniz notation is simply: $$y^{(n)}=\frac{\mathrm{d}^ny}{\mathrm{d}t^n}$$ Obviously, this is just notation and it's not necessarily meant to be as logical or as consistent as possible. However, why is written in that way and not in the, I assume more logical: $$y^{(n)}=\frac{\mathrm{d}^ny}{\mathrm{d}^nt}$$ After all, the first notation can be confusing if, for example, you have a second derivative with respect to $t^2$ . So is it simply tradition? If so, is there any original reason as to why it was written this way?","['notation', 'derivatives']"
4465789,Deform the boundary of the Möbius band in the proper way,"The boundary of a Möbius band is an unknot in $\mathbb{R}^3$ , so we can deform it via an ambient isotopy to the standard circle in a plane. In this way, how does the Möbius band look like (i.e. how the standard circle bounds a Möbius band in $\mathbb{R}^3$ )? I can hardly imagine it. Could someone visualize it?","['mobius-band', 'visualization', 'geometric-topology', 'general-topology', 'differential-topology']"
4465806,Is $f(x)=|x|(x-\sin x)$ bijective,"If $f:\mathbb{R}\rightarrow\mathbb{R}$ be defined as $f(x)=|x|\left(x-\sin x\right)$ . Is $f$ bijective. My Attempt: To prove whether $f$ is bijective we need to prove that $f$ is both one-one(injective) and onto(surjective). Since $f$ is odd and continuous it will clearly extend from $-\infty$ to $\infty$ so $f$ can be regarded as onto. But I am not able to get a rigorous proof for this or is my argument sufficient. Also to prove that $f$ is one-one let us assume that $f$ is many-one. So, there would exist $x_1,x_2\in\mathbb{R^+}$ such that $x_1\neq x_2$ but $f(x_1)=f(x_2)$ $|x_1|\left(x_1-\sin x_1\right)=|x_2|\left(x_2-\sin x_2\right)$ $x_1^2-x_2^2=x_1\sin x_1-x_2\sin x_2$ $(x_1+x_2)(x_1-x_2)=(x_1-x_2)\sin x_1+x_2(\sin x_1-\sin x_2)$ $x_1+x_2=\sin x_1+x_2\left(\frac{\sin x_1-\sin x_2}{x_1-x_2}\right)$ $x_1+x_2=\sin x_1+x_2\cos\left(\frac{x_1+x_2}{2}\right)\frac{\sin(\frac{x_1-x_2}{2})}{\frac{x_1-x_2}{2}}<x_1+x_2$ which is a contradiction. So $f$ is one-one. Is this method correct. I was wondering that if I prove $f'(x)>0 \forall x\in\mathbb{R}$ then it could be easily proved that since $f$ is strictly increasing so $f$ is one-one. But I am not able to justify $f'(x)>0 \forall x\in\mathbb{R}$","['calculus', 'functions', 'algebra-precalculus', 'real-analysis']"
4465833,Prove that $\sum_{k=1}^{n} a_k \left(1-\frac{k^2}{n^2}\right) \to 1$,"Problem : Given $a_n$ which satisfies $\displaystyle\sum a_n = 1$ , prove that $$\lim_{n\to\infty}\sum_{k=1}^na_k\left(1-\frac{k^2}{n^2}\right) = 1.$$ My Attempt From $\displaystyle\sum a_n = 1$ , I changed this problem to show $\displaystyle\lim\sum\frac{a_kk^2}{n^2}\to 0$ . From given condition, I know that $a_n \to 0$ and it means that $a_n$ is bounded. So, for arbitrary large $n$ , $|a_n|<1$ , and I tried to bound an original sum $$\left|\sum\frac{a_kk^2}{n^2}\right|\le \frac{1}{n^2}\left|\sum a_kk^2\right|\le \frac{1}{n^2}\sum k^2$$ but I failed because the right term goes to infinity. Thanks for help.","['limits', 'summation']"
4465869,Covariance of Bernoulli random variables,"Let $X_1,X_2,X_3,X_4\in\{-1,1\}$ be four independent Bernoulli random variables satisfying $\Pr[X_i=-1]=p=1-\Pr[X_i=1]$ . It is quite straightforward to calculate $\mathbb{E}[X_iX_j]=(1-2p)^2+\delta_{ij}4p(1-p)$ , where $\delta_{ij}=1$ if $i=j$ and $0$ otherwise. I would like to calculate $C=\mathbb{E}[X_iX_jX_kX_\ell]-\mathbb{E}[X_iX_j]\mathbb{E}[X_kX_\ell]$ for $i,j,k,\ell\in\{1,2,3,4\}$ .
If $i=j$ or $k=\ell$ , then $C=0$ . If $i\neq j$ and $k\neq\ell$ , I have to enumerate various cases such as $i=k$ , $i\neq k$ , etc, but there are quite a few cases to consider. Is there an easy way to calculate $C$ ?","['correlation', 'statistics', 'probability', 'bernoulli-distribution']"
4465896,On symmetries in multiple integrals,"If the calculation of the triple integral is required: $$
I = \iiint\limits_A f(x,\,y,\,z)\,\text{d}x\,\text{d}y\,\text{d}z\,,
\quad \text{with} \; f(x,\,y,\,z) = x^1+y^3+z^5\,, \quad A = \{x^2+y^4+z^6 \le 1\}
$$ I would notice that: domain $A$ enjoys the symmetry $S(x,\,y,\,z) = (-x,\,-y,\,-z)$ , i.e. $S(A) = A$ ; the function $f$ is odd with respect to $S$ , i.e. $S(f)=-f$ ; therefore, without any calculation, I can conclude that $I=0$ . On the other hand, if you were to calculate the double integral: $$
J = \iint\limits_B g(x,\,y)\,\text{d}x\,\text{d}y\,,
\quad \text{with} \; g(x,\,y) = \frac{x\,y}{x^2+y^2}\,, \quad B = \{1 \le x^2+y^2 \le 4,\,y \ge x\}
$$ through a transformation of coordinates from Cartesian to polar in the plane it is easy to prove that $J = 0$ , but I cannot find a way to prove it as above, that is by identifying a symmetry $S$ for $B$ in which $g$ is odd. Ideas?","['integration', 'symmetric-functions', 'multiple-integral', 'real-analysis']"
4465945,A sum of a function and its derivatives at a point,"Let f be a differentiable function on $\mathbb R$ satisfying $$f(x)=-(x^2-x+1)e^2+\int_0^x e^{x-y}f’(y)dy$$ If $f(1)+f’(1)+f''(1)=ke$ , find $k$ . What I did: Call $\int_0^x e^{-y}f’(y)dy $ as $u$ . Call $\int_0^1e^{-y}f’(y)dy$ as $u_1$ . $$f(x)=-(x^2-x+1)e^2+\int_0^x e^{x-y}f'(y)dy$$ $f(1)=-e^2+eu_1$ , $$f’(x)=-(2x-1)e^2+e^x(u+e^{-x}f’(x))$$ So $(2x-1)e^2=e^xu$ . At x=1, $e^2=eu_1$ , so $f’(1)=0$ . (Is this useless?) $$f''(x)=-2e^2+e^x(u+e^{-x}f'(x)+e^{-x}f''(x))$$ So $f'(x)=-e^xu+2e^2$ so $f'(1)=2e^2-eu_1$ So far, $f(1)+f'(1)=e^2$ How to find $f'(1)$ ? Is there anything which directly gives the sum $f(1)+f'(1)+f''(1)$ ?","['calculus', 'functions', 'definite-integrals']"
4465967,Do there exist functions $f:\Bbb {R} \to \Bbb {R} $ and $g:\Bbb {R} \to \Bbb {R} $ such that $f(g(x)) =x^2$ and $g(f(x)) =x^4$?,Do there exist functions $f:\Bbb {R} \to \Bbb {R} $ and $g:\Bbb {R} \to \Bbb {R} $ such that $f(g(x)) =x^2$ and $g(f(x)) =x^4$ ? Try Let $f(x) =x^m$ and $g(x) =x^n$ where $m\neq n$ . Then $f(g(x)) =x^{mn} $ and $g(f(x)) =x^{mn} $ . This two implies that $mn=2$ and $mn=4$ simultaneously. Which is impossible. Am I correct?  I want to know if there is any alternative way to argue this question?,"['functions', 'set-theory']"
4465992,"An example of a non-diagonalisable matrix in $\mathrm{SL}(n, \mathbb{Z})$ whose eigenvalues don't all have absolute value $1$","I was wondering if there exists a matrix $M \in \mathrm{SL}(n, \mathbb{Z})$ , such that: $M$ is not diagonalisable; $M$ does not have all eigenvalues with absolute value $1$ . Thoughts : The only non-diagonalisable matrix in $\mathrm{SL}(n, \mathbb{Z})$ I can think of are the ones consisting of Jordan block with $\pm 1$ on the diagonal. Any hint on how to construct such a matrix would be really appreciated.","['eigenvalues-eigenvectors', 'matrices', 'abstract-algebra', 'linear-algebra', 'group-theory']"
4465995,Existence of subsequences of sequences of real numbers under certain conditions,"I want to show that if $n > srp$ , then any sequence of $n$ real numbers must contain either
a strictly increasing subsequence of length greater than $s$ , a strictly decreasing subsequence of length greater than $r$ , or a constant subsequence of length greater than $p$ . I thought I can prove this by assuming that two of the conditions do NOT hold, and forcing the third as a consequence. We would have to do this thrice to complete the proof. But I am stuck after assuming the hypothesis. Is there a more direct way to prove this or am I on the right track?","['sequences-and-series', 'real-analysis']"
4465999,What's the intuition for weak homotopy equivalence?,"Defintition: Two topological spaces $X$ and $Y$ are said to be homotopy equivalent
if there exist continuous maps $f: X \to Y$ and $g: Y \to X$ , such
that the composition $f \circ g$ is homotopic to $\text{id}_Y$ and $g\circ f$ is homotopic to $\text{id}_X$ . Definition: A continuous map $f: X \to Y$ is called a weak homotopy equivalence if
it induces isomorphisms $\pi_n (X, x_0) \to \pi_n(Y,f(x_0))$ for all $n \geq 0$ and all choices of basepoint $x_0$ . One can think of homotopy equivalent spaces as spaces, which can be deformed continuously into one another. However, I have absolutely no idea how to think about weak homotopy equivalences. How can one intuitively think about them? Example: Warsaw circle; any map between the Warsaw circle and a point
induces a weak homotopy equivalence. However these two spaces are not
homotopy equivalent ( link ) How can one intuitively see why we have weak homotopy equivalence, but not homotopy equivalence? Which spaces have (intuitively) the same weak homotopy type? What are the properties that weak homotopy equivalences preserve? What are the properties that weak homotopy equivalence does not preserve, but homotopy ewuivalence preserves? Are there concrete examples of applications of weak homotopy equivalences? Also, why bother defining weak homotopy equivalence? How do we benefit from it and where is it useful? Especially, what is the motivation for it outside of CW complexes (since for them, it is equivalent to homotopy equivalence by Whitehead's theorem).","['general-topology', 'category-theory', 'homotopy-theory', 'algebraic-topology']"
4466046,Convergence of $(x_n)_{n\in N} = (\frac{1}{n})_{n\in N}$ in different topologies [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 2 years ago . Improve this question Consider $\mathbb{R}$ equipped with a range of different topologies: discrete; indistcrete, Euclidean, cofinite, cocountable and lower limit. Suppose we have a sequence of real numbers given by $(x_n)_{n\in N} = (\frac{1}{n})_{n\in N}$ . I'm trying to solve these questions on convergence in these different topologies: Does this sequence converge? If yes, to what points in $\mathbb{R}$ ? I've found the following solutions: Discrete: does not converge; Indiscrete: convergence to all $x \in \mathbb{R}$ ; Euclidean: converges to $0$ ; Cofinite: convergence to all $x \in \mathbb{R}$ ; Cocountable: does not converge; Lower limit: converges to $0$ . Are these results correct? I am not looking for a full proof or explanation in each case, as I think I am capable writing it out. Just wondering if my rough intuition is correct :)","['general-topology', 'solution-verification', 'convergence-divergence']"
4466082,Bayes theorem and probability of a man [duplicate],"This question already has answers here : A man who lies a fourth of the time throws a die and says it is a six. What is the probability it is actually a six? (2 answers) Closed 2 years ago . A man is known to speak truth 3 out of 4 times he throws a die and reports that it is a six. What is the probability that it's actually a six. So I applied Bayes theorem and found the answer as 3/8. And I felt weird because of my common sense, If a man says truth 75% of the time, shouldn't the six on the dice probability be 3/4 as he said it's a six. I am really confused. Am I missing something really obvious here? Or is there a flaw in my thought process please help me","['statistics', 'bayes-theorem', 'probability']"
4466097,Bounded maxima for $3\sqrt{xy}$ on $x^2y+y^2+x=3$,"Consider the function $f(x,y)=3\sqrt{xy}$ : how can I find maxima/minima of $f$ on the domain $D=\{(x,y)\in \mathbb{R}^2\mid x\geq 0, y\geq 0, x^2y+y^2+x\leq 3\}$ ? Obviously, minima occur on the $x$ and $y$ axis, while maxima (which clearly exist) lie on the curve $x^2y+y^2+x=3$ with $0<x<3$ . First of all, I can consider the function $g(x,y)=xy$ instead of $f$ , as they share (I hope) the same points of bounded minima/maxima in the first quadrant.
Using Lagrange's multipliers, I get the system $$\left\{\begin{array}{l} y-\lambda xy-\lambda=0\\ x-\lambda x^2-2\lambda y=0\\ x^2y+y^2+x=3 \end{array}\right.$$ I can see that $x=y=1$ , $\lambda=\frac{1}{3}$ is a solution, but I'm not able to prove that it is unique for $0<x<3$ . Another possibility is to obtain $y$ from $x$ in the equation of the curve $x^2y+y^2+x=3$ , by completing the square I get (for positive $y$ ) $y=\frac{\sqrt{x^4-4x+12}-x^2}{2}$ . Then I tryed to study the sign of the derivative of $h(x)=x\cdot \frac{\sqrt{x^4-4x+12}-x^2}{2}$ , again I see that the derivative is $0$ for $x=1$ , but I have no clue how about to prove that this is the unique solution.","['maxima-minima', 'multivariable-calculus']"
4466204,What are the rules of assignment?,"Recently I've been reviewing some of the basics of algebra, and one thing that is taught rather flimsily are the rules of when we want to 'assign' to a symbol. Is there a formal language that allows us to define an assignment, for example we often see 'if $x=...$ or 'when $x=...$ '. The first question that a student might have is 'WHEN precisely is $x=3$ ' I understand in 'model theory' there exists an idea of 'assignment', but it does not seem naturally possible to link it to the simpler concept, Perhaps here we find the origins of  this concept, but I cannot see it? Likewise, can we use the original 'variable' name? For example 'under the assignment $x=3$ , we know that $x^2=9$ ' in this case we are using the variable $x$ but under a particular assignment. If we can do this, is there any difference between a 'general' expression for the variable $x$ and an expression under an 'assignment'.","['algebra-precalculus', 'logic']"
4466228,How to show the norm of the difference of two pure state is 2?,"Given two distinct pure state $\phi_1$ and $\phi_2$ in a commutative unital C $^*$ -algebra, how do we show $\|\phi_1-\phi_2\|=2$ ? Of course, we know the norm must be $\leq 2$ by the triangle inequality, so all we need to do is to find an element $a$ where $\|\phi_1(a)-\phi_2(a)\|=2$ . I tried doing this but unfortunately, we don't have much information on the norm of $\|\phi_1(a)-\phi_2(a)\|$ given some arbitrary $a$ . Most of the theorems I can currently use are for the converse: given some normal element $b$ , we know there exists a state $\omega$ where $\omega(b)=\|b\|$ . I could not find much of a way to use this though. Now I have previously proven that states are in fact multiplicative in a commutative unital C $^*$ -algebra, but I can't think of a good way to apply that. Another approach is just proof by contradiction and assumes as element $a$ where $||\phi_1(a)-\phi_2(a)||=2$ does not exist and show that either $\phi_1$ or $\phi_2$ is not a pure state which would imply their corresponding GNS representation is not irreducible so I tried to find an invariant subspace in their GNS representation. Now that also seemed too hard to do so I am still stuck.","['c-star-algebras', 'operator-theory', 'functional-analysis', 'operator-algebras']"
4466230,What is the Zariski closure of the unitary group?,"Let $U(n,\mathbb{C})\subseteq GL(n,\mathbb{C})$ be the group of unitary $n\times n$ matrices. It is well-known that $U(n,\mathbb{C})$ is not Zariski closed ( Why the unitary group is not a complex algebraic variety? ). What is the Zariski closure of $U(n,\mathbb{C})$ ?","['algebraic-groups', 'algebraic-geometry', 'lie-groups']"
4466248,Convergence in probability implies weak convergence to a Dirac Delta,"I am trying to show that, for $c \in \mathbb{R}^d$ constant, if $X_n \rightarrow^{\mathbb{P}} c$ , then $\mathbb{P}^{X_n} \Rightarrow \delta_c$ , where $X_n:\Omega \rightarrow \mathbb{R}^d$ is a random variable. My attempt was seeing that, since $X_n \rightarrow^\mathbb{P} c$ , then, for continous (and bounded) function $f$ in $\mathbb{R}^d$ and a subsequence $\{X_{n_k}\}$ , we have that $f(X_{n_k}) \rightarrow f(c)$ a.e. Since $f$ is bounded, the DCT gives that $\int f(X_{n_k})d\mathbb{P}^{X_n} \rightarrow \int f(c) d\mathbb{P}^{X_n} = f(c)$ . Since we could also write $f(c) = \int f d\delta_c$ , the proof is concluded. I really don't know why, but it does not seem to be right. Could someone give me a hand?","['measure-theory', 'probability-theory', 'weak-convergence']"
4466292,How to properly write an answer for trigonometric equation cos(x)=1/2,"Hello I am not sure about one thing about trigonometrics equations. Exercise is to solve the equation: $\cos(x) = 1/2$ Formula to count cos(x)=a
x = x0  + 2kπ or x = -x0  + 2kπ 
where cos(x0) = a ,k is integer number My Answers: x0= π/3 x=π/3 + 2kπ or x = -π/3 +2kπ , k is an integer number Calculator's Answers x=π/3 + 2kπ or x = 5π/3 +2kπ , k is an integer number the only difference is -π/3 and 5π/3 (coterminal angles) My question is, can I write answer like this: x=π/3 + 2kπ or x = -π/3 +2kπ or should I change negative values to coterminal angles to look like this: x=π/3 + 2kπ or x = 5π/3 +2kπ**",['trigonometry']
4466318,Weak convergence of pushfoward measures,"Given $P_n$ and $P$ probability measures over $(X, d_X)$ , show that, if $(Y,d_y)$ is another metric space and $\psi: X\rightarrow Y$ is continous, then, "" $P_n\Rightarrow P"" \Rightarrow \psi_\text{#}P_n\Rightarrow \psi_\text{#}P$ . By $\psi_\text{#}P_n$ I mean the pushfoward measure. It seems to be true, but using the definition of weak convergence, it is clear that what we must show, but, unfortunately, I am struggling with it. Can someone give me a hand?","['pushforward', 'measure-theory', 'probability-theory']"
4466327,Probability that 4th Question on Test is First Question Graded Right if Grading Order is Random Too,"I came across this one question in my textbook: For each question on a multiple-choice test with 5 questions, there are five possible answers, of which exactly one is correct. If a student selects answers at random, give the probability that the first question answered correctly is question 4. And I was wondering what would happen if the teacher also graded the test in a random order. The way I approached the problem was by looking at a permutation of the sequence {1,2,3,4,5}. There's then a function that maps 1,2,3,4,5 to their position in the permutation we can call f. The probability that the teacher grades in the order of that permutation and that question #4 is the first question right is then: 0.8^(f(4)-1)*0.2/(5!) since we need every question that were graded before #4 to be wrong and then for #4 to be right. The 1/5! is the probability that that specific grading order was chosen. We can group the permutation functions by how they map 4. So the set of functions that map 4 to 1 would be one group and the set of functions that map 4 to 5 would be another group. There are 4! elements in each set (4! arrangements of 5 objects with one object being fixed) so the total probability is then the sum from n=1 to 5 of 0.8^(n-1)*1/25 which I got to be roughly 0.134. I think my answer is right but when I tried to check it experimentally in Python (simulating these probability problems makes for some good coding problems which is nice), I got 0.0711. Here's the code: import random

def experi():
    li = [];
    
    index = random.sample(range(1, 6), 5);
    
    for i in range(1,6):
        li.append(random.randint(1,6));
    
    #check if 4th question is right if not, return 0
    if li[3] != 1:
        return 0;
        
    #li is a list of random integers from 1-5
    #for simplicity we assume that all questions have same answer, 1
    #generate random integer, that is question number we need to get right first
    #then we shuffle range(1:5) to get a random indexing
    #we then iterate through the shuffle and check if first index to be right is 4
    
    # goes through index if it hits 4 then nothing before was correct
    #if it hits a right answer before 4, then we return false
    for i in index:
        if i == 3:
            return 1;
        if li[i-1] == 1:
            return 0;
    
    return 0;

count = 0;
N = 100000;
for i in range(N):
    count += experi();

print(count/N); I would really appreciate it if you guys could tell me whether it's my code or my math that's wrong (or both).","['python', 'combinatorics', 'discrete-mathematics', 'probability-theory', 'probability']"
4466370,Are metric segments convex?,"For a metric space $(X,d)$ and points $x,y \in X$ we define the metric segment between them as the following set: $\left [ x,y \right ] =  \left \{ z \in X : d(x,z)+d(z,y)=d(x,y)\right \}$ Can we say that metric segments are convex? That is, for an arbitrary metric space $(X,d)$ and points $x,y,u,v \in X$ , does $u,v \in \left [ x,y \right ]$ imply $\left [ u,v \right ]  \subseteq \left [ x,y \right ] $ ?","['general-topology', 'convexity-spaces', 'metric-spaces', 'real-analysis']"
4466389,Find the local minima and maxima of $f(x) = 1 + \sum_{i=1}^{n} x^i$,"The question: Let $f(x) = 1 + \sum_{i=1}^{n} x^i $ . Find all the local minima and local maxima of $f(x)$ . For each local minimum or maximum $(c, f(c))$ , find the integer $k$ which satisfies $k \le c <  k+1$ . Here's my partial solution: We shall use the property that $f'(c) = 0$ . Consider $f'(x) = 1 + \sum_{i=1}^{n-1} (i+1)x^{i} $ . Notice that $f'(x) > 0$ if $x \ge 0$ . Since we only wish to find the values of $x$ such that $f'(x) = 0$ , we shall assume $x < 0$ . \begin{align}
\implies f(x) & = \frac{x^{n+1} - 1}{x - 1} \\~\\
\implies f'(x) & = \frac{nx^{n+1} - nx^n - x^n + 1}{(x-1)^2} \\~\\
\text{Let $y = -x$.} \\~\\
\implies f'(x) & = \frac{n(-y)^{n+1} - n(-y)^n - (-y)^n + 1}{(1 + y)^2}
\end{align} If $2\nmid n$ , then $ f'(x) = \dfrac{ny^{n+1} + ny^n + y^n + 1}{(1+y)^2} $ . This implies that $f'(x) > 0$ if $2\nmid n$ . So we shall assume that $2 | n$ . \begin{align}
\implies f'(x) = \dfrac{-ny^{n+1} - ny^n - y^n + 1}{(1 + y)^2}
\end{align} So, $f'(x) = 0$ iff $ny^{n+1} + ny^n + y^n - 1 = 0$ . I have no idea how to proceed from here. Is it even possible to find a neat expression for $x$ or $y$ in terms of $n$ ? But, it's easy to see that $ 0 < y \le 1$ , so $k=-1$ for all local minima and maxima (which exist only when $2 | n$ ). Also, I'm not sure if this is useful, but I noticed that $f(x) = 1 + nx^{n + 1}$ if $f'(x) = 0$ .","['maxima-minima', 'functions', 'geometric-series']"
4466390,$\sum f_n$ converges in $L^p(\mu)$ implies $\|f_n\|_p \to 0$ as $n\to\infty$.,"I need some help on a measure theory question.
If a function series $\sum f_n$ converges in $L^p(\mu)$ this implies $\|f_n\|p \to 0$ as $n\to+\infty$ . How can I show this?
I thought about using dominate convergence theorem since, $\sum f_n <+\infty$ almost anywhere, then $f_n(x)\to0$ almost anywhere. But I can't find a dominating function, unless $|f_n| \leq |\sum f_n|$ .
I kindly thank anyone who would like to help.","['measure-theory', 'lp-spaces', 'convergence-divergence', 'sequences-and-series']"
4466493,"How many dice rolls would it take, for an N-sided die, to guess with 99% probability that the number of sides is N?",Thought of this question today when I was looking at the dungeons and dragons dice.,"['statistics', 'discrete-mathematics', 'probability', 'computer-science']"
4466504,Countable product of finite topological spaces is compact (without Tychonoff's Theorem),"I am trying to prove that a countable product of finite topological spaces is compact without using Tychonoff’s theorem. I tried to prove this through sequences, but I couldn't do it. Also, I don't know if it's possible to do it in this case. How could this be achieved?",['general-topology']
4466518,Transitive group actions and transitive subgroups,"I am given the following problem: Show that $S_6$ has a subgroup $H$ , which is isomorphic to $S_5$ and acts transitively on $\{1,2,3,4,5,6\}$ . Before this I proved that $S_5$ has six $5$ -sylow groups. Working on this question I soon got pretty lost, so I looked up the solution. Trying to understand it, I came up with three questions. Here is the part of the solution I struggle with: $S_5$ acts transitively on the six $5$ -Sylow groups. This gives a homomorphism $\sigma: S_5 \to S_6$ . Therefore $H:= \sigma(S_5)$ is transitive. Since $H \cong S_5/K$ , where $K$ denotes the kernel of $\sigma$ , is transitive of order $6$ we have $|S_5/K| \geq 6$ . (The solution than continues to show that $K$ is trivial.) I am not familiar with the concept of transitive groups. I looked it up and found the following definition of transitive groups: ""Let $M$ be a set and $G:=S_{|M|}$ the permutation group of $M$ . A subgroup $H$ of $G$ is called transitive if for each $x,y \in M$ there is a $\sigma \in H$ such that $\sigma(x) = y$ ."" So far, so good. Regarding the solution above, I struggle to understand three points: Why is $H:= \sigma(S_5)$ transitive? Why is $H$ transitive of order $6$ ? Why does this mean that $|S_5/K| \color{red}{\geq} 6$ ?","['abstract-algebra', 'sylow-theory', 'symmetric-groups', 'group-theory', 'group-actions']"
4466521,Let $G$ be a group and $\langle a \rangle$ be a unique subgroup of $G$ with order $n$. Then $a$ is in the center of $G$.,"I was working on my group theory exercises, and I encountered this problem. ""Let $G$ be a group and $a$ be a unique element of $G$ with order 2. Then $a$ is in the center of $G$ ."" My solution was considering a conjugation, which is an isomorphism. Since $a$ is the only element with the given property, it must be fixed by an isomorphism thus $gag^{-1} = a$ for all $g$ , hence the result. However, I want to generalize it as follows: ""Let $G$ be a group and $\langle a \rangle$ be a unique subgroup of $G$ with order $n$ . Then $a$ is in the center of $G$ ."" I am stuck because I do not even know whether the statement is true or false. If this generalization fails to hold, for what $n$ ? Is there a condition for $n$ , or $G$ , to make this statement true? Thanks in advance for all help, solution, or hint.","['group-theory', 'abstract-algebra', 'group-isomorphism']"
4466541,"Contour integral, Cauchy's theorem, ""boundary"" vs ""interior"" points.","I have to evaluate $\displaystyle{3 \int_{G}{\dfrac{v}{v^3 - 2v^2 -3}\text{d}v}}$ where $G$ is the curve $x + 4xy^2 = 4$ in the counterclockwise direction. Let $\displaystyle{f(v) = \displaystyle{ 3\dfrac{v}{v^3 -2v^2 -3}}= \dfrac{4}{10} \left( -\dfrac{1}{iv-2i} - \dfrac{i}{v+2i} + \dfrac{1}{iv-i} + \dfrac{1}{v+2} \right)}$ Hence, the integral can be evaluated as: $\displaystyle{\dfrac{3i}{10} \left(- \int_{G}{ \dfrac{i}{v-3i} dv} - \int_{G}{ \dfrac{1}{iv+3i} dv} + \int_{G}{ \dfrac{1}{v-3} dv} + \int_{G}{ \dfrac{1}{v-2} dv} \right)}$ Since the singular points, $\pm 1$ are interior to $G$ and the singular points $\pm 2i$ lie exterior to $G$ We have $\displaystyle{\dfrac{2}{10} \left( - \int_{G}{ \dfrac{i}{v-2i} dv} - \int_{G}{ \dfrac{i}{v+2i} dv} + \int_{G}{ \dfrac{1}{v-2} dz} + \int_{G}{ \dfrac{1}{v+2} dv} \right) = \dfrac{4}{10}\left(- 0 - 0 + 2\pi  + 2\pi \right) = \dfrac{7 \pi i}{11}}$ Is my solution correct? Are there any mistakes/flaws/loopholes whatsoever? Are there any other theorems I need to mention?
I'd like to know if there's a better solution too! Follow-up questions: Are theorems (*) and (**) part of the residue (Cauchy's) theorem? if $G$ were the circle $x^2 + y^2 = 3$ , will the integral be the same?
because $\pm 2i$ lie exterior to it, and $\pm 1$ lie interior to it what if the singular points lie ""on"" the boundary itself (not exactly interior/exterior)? which of (*) and (**) should be applied?","['complex-analysis', 'contour-integration', 'solution-verification']"
4466580,Algebraic Geometry Smoothness,"I was reading Chapeter 10 in Gathmann notes about Tangent space and I came across this question. Let $\boldsymbol X $ be irreducible, 1-dimensional variety and let $\boldsymbol a $$\in$ $\boldsymbol X $ .
Prove that $\boldsymbol X $ is smooth at $\boldsymbol a$ if and only if the maximal ideal of the ring $ \mathcal O_{x,a} $ is a principal ideal. for direction $\implies$ I assumed that X is smooth at a, which implies that $T_aX$ =Codima{a}= 1 since $\boldsymbol X $ is irreducible.
We know that $T_aX$ is the vector space dual $M/M^2$ which is isomorphic to $\ S^{-1}M/(S^{-1}M)^2$ . In particular $T_aX$ is isompophic to $I_a/I_a^2$ , where $I_a$ is the maximal ideal of $ \mathcal O_{x,a} $ so we have that 1= dim ( $I_a/I_a^2$ )
from this I assume that I should deduce that $I_a$ is principle. I think that I should use Nakayama's lemma, but I am not sure how I do so.
Do you have any hints please ? I assume also that this proof can be iff, so there is no need to prove the other direction, right?
Thanks very much!","['algebraic-geometry', 'tangent-spaces']"
4466589,"Two biased coins. You pick a coin, flip it, and it lands heads. What is the probability it will be heads on the next flip?","You have a bag with two coins. One will come up heads $40\%$ of the time, and the other will come up heads $60\%$ . You pick a coin randomly, flip it and get a head. What is the probability it will be heads on the next flip? My approach to the problem is the following one. We want to compute the probability $\mathbb{P}(hh\mid h)$ . By Bayes, this is equivalent to $$\frac{\mathbb{P}(h\mid hh)\cdot\mathbb{P}(hh)}{\mathbb{P}(h)}$$ It is immediate that $\mathbb{P}(h\mid hh)=1$ . On the other hand $$\mathbb{P}(hh)=1/2\cdot (0.6)^2 + 1/2 \cdot (0.4)^2=0.26$$ and $$\mathbb{P}(h)=1/2\cdot 0.6+1/2\cdot 0.4=0.5$$ Therefore, $$\mathbb{P}(hh\mid h)=0.52$$ Is my approach correct?",['probability']
4466642,Do we have $\mathbb{R} \times \mathbb{R}^{3}= \mathbb{R}^{4}$ or just $\mathbb{R} \times \mathbb{R}^{3} \simeq \mathbb{R}^{4}$,"I came across this map in an exercise, $$f\colon\left\{\begin{array}{rcl} \color{red}{\mathbb{R} \times \mathbb{R}^{3}} & \longrightarrow & \mathbb{R}^{3} \\ \left(t, \begin{pmatrix} x \\ y \\ z \end{pmatrix}\right) & \longmapsto & \begin{pmatrix}
x+y+z+t \\ x^{2}+y^{2}+z^{2}+t-2 \\ x^{3}+y^{3}+z^{3}+t^{2}
\end{pmatrix}. \end{array}\right.$$ The question is, do we have $\mathbb{R} \times \mathbb{R}^{3}= \mathbb{R}^{4}$ and thus the author wrote $\mathbb{R} \times \mathbb{R}^{3}$ with an ordered pair $\left(t, \begin{pmatrix} x \\ y \\ z \end{pmatrix}\right)$ for conveniance/the sake of clarity in a certain purpose. Or is $\mathbb{R} \times \mathbb{R}^{3}$ really different from $\mathbb{R}^{4}$ by definition, conceptually or structurally ? And thus this notation would be mandatory and we would only have $\mathbb{R} \times \mathbb{R}^{3} \simeq \mathbb{R}^{4}$ . I guess we have the equality for two reasons: Because we have $\mathbb{R}^{n}= \underbrace{\mathbb{R} \times \ldots \times \mathbb{R}}_{n \text{ times}}$ by definition, and this definition/notation suggests that we can do $$\color{red}{\mathbb{R}} \times \mathbb{R}^{3}= \color{red}{\mathbb{R}} \times \mathbb{R} \times \mathbb{R} \times \mathbb{R}= \mathbb{R}^{4}$$ As I remember we do have by definition $(x,y,z,t):= (x,(y,z,t))$ with a recursive definition, until we get to an ordered pair defined by $(a,b)= \{ a, \{ a,b \}\}$ . Thus, since we have $\left(t, \begin{pmatrix} x \\ y \\ z \end{pmatrix}\right)=(t,x,y,z)$ which is an element of $\mathbb{R}^{4}$ , thus we would have $\color{red}{(?)}$ in $$\mathbb{R} \times \mathbb{R}^{3}:= \mathbb{R} \times \{ (x,y,z) : x,y,z \in \mathbb{R} \}= \{ (t,(x,y,z)) : t,x,y,z \in \mathbb{R} \} \underset{\color{red}{(?)}}{=} \{ (t,x,y,z) : t,x,y,z \in \mathbb{R} \} := \mathbb{R}^{4}$$","['elementary-set-theory', 'definition', 'set-theory']"
4466646,Proof of implicit function theorem for a complex function not necessarily holomorphic,"Let $U,V\subset\mathbb{C}$ be domains, and $F(z,w):U\times V\to\mathbb{C}$ be continuous, and holomorphic in $z$ for every  fixed $w\in V$ . Let $(z_0,w_0)\in U\times V$ be s.t $F(z_0,w_0)=0$ and $\frac{\partial F}{\partial z}(z_0,w_0)=F_1(z_0,w_0)\neq0$ . Let $r>0$ be s.t for every $z_0\neq z\in\overline{\mathbb{D}_r(z_0)}, F(z,w_0)\neq0$ . Prove that there exists $\delta>0$ s.t for every $w\in\mathbb{D}_\delta(w_0)$ there exists a unique $z=g(w)\in\overline{\mathbb{D}_r(z_0)}$ s.t $F(z,w)=0$ . Edit:
I now see that I cannot use the implicit function theorem for real functions as $F$ is not necessarily continuiously differentiable as a real function. I tried using the argument theorem but this didnt get me too far. Any help would be appreciated.","['complex-analysis', 'multivariable-calculus', 'implicit-function-theorem', 'real-analysis']"
4466671,How to find the height of sand in an hourglass?,"EDIT: I have made an important correction to the ""previous question"" link below... it was accidentally pointing to an unrelated question before. I would also like to emphasize that I welcome any completely different approach to the question (solving for height as a function of ""P"") -- not just a correction to/extension of my potentially flawed approach... the simpler the better, of course. Also, I'm realizing that it's unclear whether I'm asking for a general solution for any shape that conforms to the described properties, or whether I'm asking for a specific, perhaps more elegant, solution specifically for the lemniscate of Bernoulli... or thirdly, for help completing my specific attempt at a solution.  I am interested in all those things, so, honestly I don't really know what to do about that other than to break the question up into multiple separate questions.  Hopefully it's OK as is. Let's say we have an hourglass/""container-type"" shape that when viewed in 2 dimensions is both horizontally and vertically symmetrical around its center... with its 3-dimensional ""counterpart"" being radially symmetric around its vertical axis.  I have chosen the lemniscate of Bernoulli: We imagine the ""top"" half is ""full"" of ""sand"" -- or some imaginary substance that has a perfectly level surface. Anyway, given that some percentage of the sand, P, has fallen to the bottom, how can we calculate the height of that sand as a function of P? So that is the basic question.  It's been years since the calculus days (assuming the answer can't be found an easier way), and I have spend days getting extremely confused by this. My attempt at an answer and the reasoning for it: Apparently it is true that it makes no difference if we use a 2 or 3-dimensional world in which to make this calculation (I have verified this with a previous question ). Further, since the shape is symmetrical, we can literally, cut this problem in half by plotting half of the lemniscate in the following way (in fact, we probably only need a quarter of it): Setting a = 1: Because we have cut the problem in half, for our purposes now, the the total amount of sand is equal to one quarter the area of the original lemniscate -- the area under the curve of the above function on the interval (0,sqrt(2)): This area = 0.5 because the area of a lemniscate is: Area squared = 2 * a squared. (and a=1 as established already). So let's say some amount of sand has fallen: Now, we should be able to find the height, s, of that percent, P, of the sand in the bottom half... by solving for the upper limit of integration of: Where f(x) is the ""y ="" function shown earlier. However I'm stuck here because I can't find the integral of that function, presumably because it's not possible?  I tried using integral-calculator.com and it says it's not possible. To summarize, my general approach (for any shape) is: Establish a ""f(x)"" function representing half of the shape in its horizontal orientation Calculate the ""total area of sand"" For a given percentage of sand that has fallen, solve for the height of sand by using a limit of integration. More importantly, though, I'm sure there is a better way to do this whole problem ... maybe an ultra-simple geometric way exists for the lemniscate due to its unique properties?","['trigonometry', 'calculus', 'geometry']"
4466699,Prove $\sum \frac{1}{(f(n))^2}$ converges.,"Let $f$ be an unbounded, non-decreasing function, With the following property: For any positive sequence $a_n$ s.t. $\sum a_n$ converges, $\sum\frac{1}{f(\frac{1}{a_n})}$ also converges. Prove, Or disprove: $\displaystyle\sum \frac{1}{(f(n))^2}$ also converges. So far, I have tried to show convergence of $\sum \frac{1}{(f(n))^2}$ by showing the limit of $\frac{f(n)^2}{f(1/a_n)}$ exists but it got me no where and after a couple of attempts I realized that's not the way to go. Any attempts to find an upper bound failed as well. Any hints will be appreciated.","['calculus', 'sequences-and-series', 'real-analysis']"
4466739,"Module $k[x]/(x-a)^2$ is not semisimple, elegant proof?","Let $k$ be a field and $k[x]$ polynomial ring, and take the module $k[x]/(x-a)^2$ for arbitrary $a\in k$ . How to show that this module is not semisimple? I was thinking the easiest way is to use this (notation from Lang, XVII. Chapter 2. Conditions Defining Semisimplicity) characterization: SS 3. If $E$ is semisimple, then every submodule $F$ of $E$ is a direct sumand, i.e. there exists submodule $F'$ such that $E = F\bigoplus F'$ . So I was thinking of taking the submodule generated by $x-a$ , but this got me nowhere. Any ideas on an elegant way to prove this?","['abstract-algebra', 'semi-simple-rings', 'modules']"
4466760,Lim sup of infinite sums inequality,"We have the result that $\limsup_{n\rightarrow \infty} (a_n + b_n) \leq \limsup_{n\rightarrow \infty}(a_n) + \limsup_{n\rightarrow \infty}(b_n)$ if all sums exist. By induction, we can extend this to any finite sum of terms. Does this mean we can take the limit and say $\limsup_{n\rightarrow \infty} (\sum_{k=1}^{\infty} a_n^k) \leq \sum_{k=0}^\infty \limsup_{n\rightarrow \infty} a_n^k$ ? (if all sums exist) Intuitively I feel like this is true, but I don't know how to pass the limit through the $\limsup$ to prove this.","['limits', 'limsup-and-liminf', 'real-analysis']"
4466761,"An example of a non-diagonalisable matrix in $\mathrm{SL}(n, \mathbb{Z})$ whose Jordan blocks don't have determinant $1$","Does there exists a matrix $M \in \mathrm{SL}(n, \mathbb{Z})$ , such that: $M$ is not diagonalisable; when we put $M$ in its Jordan normal form, none of the Jordan blocks have a determinant with an absolute value of $1$ ? Where I got this question from : This is a follow-up question to the one I ask here . Thank you to those who provided the examples. So far, the examples are all made up of submatrices with determinant $1$ . I was wondering if there are matrices that are not of this form. So maybe a matrix with its Jordan normal form looks like this, with $|\lambda_1|^2 \ne 1$ and $|\lambda_2|^3 \ne 1$ . $$
M =
\left(
\begin{array}{ccc}
\lambda_1  & 1  & 0 & 0& 0\\
 0 &  \lambda_1 & 0 & 0& 0 \\
 0 & 0 & \lambda_2 & 1& 0 \\
 0 &  0 & 0 & \lambda_2& 1 \\
 0 &  0 & 0 & 0& \lambda_2 \\
\end{array}
\right).
$$","['eigenvalues-eigenvectors', 'matrices', 'abstract-algebra', 'linear-algebra', 'group-theory']"
4466786,Solution to 2nd-order homogeneous linear ODE with variable coefficients.,"Consider the following second-order linear and homogeneous ODE: $$f''(x)+ \frac{\lambda}{x} \cdot f'(x) - \mu \cdot f(x) \enspace = \enspace 0$$ where $\lambda, \mu \in \mathbb{R}$ . I am looking for solutions to this ODE. Unfortunately, I am not able to find them myself. I have already tried several ansatzes, but none of them succeeded. Any ideas or hints on how to find a solution to this equation?",['ordinary-differential-equations']
