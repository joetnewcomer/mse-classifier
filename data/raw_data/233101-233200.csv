question_id,title,body,tags
4857894,Find limit: $\lim\limits_{n \rightarrow \infty} \left( \cos\frac an \right)^n$,"EDIT: since the proposed below ""property"" is incorrect in general, one can solve the limit by exponentiating the function. When investigating this limit $$\lim\limits_{n \rightarrow \infty} \left( \cos\frac an \right)^n$$ I have found a property that allows to find the limit pretty easy: $$\lim\limits_{x \rightarrow 0} f(x)^{g(x)} = e^{\lim\limits_{x \rightarrow 0} (f(x)-1) \cdot g(x)}$$ Then a rule of derivative for $\left(\frac 00\right)$ limits is applied to get $1$ as an answer. However, I have not been able to find any name or reference to the property above. Does anyone have a link to this property? or its name? If it is non-valid one, what's the approach to use for such a limit?","['limits', 'calculus', 'approximation']"
4857907,What is the Lebesgue measure of zero-dimensional space?,"I learnt about the concept of the Lebesgue measure some time ago, and one question was always confusing to me (and was never answered). What is the Lebesgue measure of zero-dimensional space? What I know is that the Lebesgue measure is defined as the standard way of measuring a subset of some Euclidean space $R^n$ , where $n$ is the dimension of the space. This means that: The standard way to measure the subset (a “part” that is well-defined in the space) of a line ( $R^1$ ) is length; makes sense The standard way to measure the subset of a plane ( $R^2$ ) is area; makes sense The standard way to measure the subset of a solid space ( $R^3$ ) is volume; makes sense And this continues for dimensions $d > 3$ in some $R^d$ . But when It comes to $R^0$ , there are two questions that often come unanswered and can really confuse you: Q1 If Lebesgue measure is defined on $n$ -dimensional space as a standard way to assign measure to a proper subset of $R^n$ , how would we define the Lebesgue measure of $0$ -dimensional space? This amounts to measuring the subset of a point, which kind of doesn’t make sense in my mind. Q2 I think we define the dimension of some $S^n$ , where $S$ can be some space, as the number of coordinates (also: coordinate axis) needed to specify the location of some point in/on $S_n$ . This makes sense for $1$ -dimensional space, as you just need one number on the number line to find a location of a point on the number line, and for $2$ -dimensional space, you need two: the $x$ and $y$ -axis to specify a point on a plane. Their logic continues for higher dimensions. But how does it make sense that we need “no coordinates” to specify a point on a point? Or is all of this above stuff nonsense and a point is just zero length? If that’s a case, why would we assign a new dimension to something that can be measured in a Lebesgue measure defined in another dimension? I couldn’t find any useful information anywhere else for these questions, hence Any help or clarification is appreciated!","['euclidean-geometry', 'lebesgue-measure', 'geometry']"
4857913,Subspaces with common images,"Let $X$ and $Y$ be finite dimensional vector spaces over $\mathbb{C}$ , and let $S,T:X\to Y$ be linear transformations. Is there a method for determining all subspaces $V\subseteq X$ such that $S(V)=T(V)$ (as subspaces not necessarily pointwise). I am especially interested in the case where $\text{dim} X \geq \text{dim} Y$ .","['abstract-algebra', 'linear-algebra', 'linear-transformations', 'algorithms']"
4857936,Characterization of groups with only low-dimensional irreducible (real or complex) representations,"For a finite group $G$ define $d_K(G)$ as the largest dimension of an irreducible representation of $G$ on a $K$ -vector space. I find the case $K=\mathbb R$ more geometrically appealing but I suspect $K=\mathbb C$ has better properties. It's an exercise to prove that $d_\mathbb C(G)=1$ if and only if $G$ is abelian, so I ask: is there a characterization of groups such that $d_\mathbb C(G)=2,3,\dots$ in terms of group-theoretical properties of $G$ ? And the same for $d_\mathbb R$ . Let $V_1, \dots, V_r$ be the irreducible complex representations of $G$ . We know that $r$ is the number of conjugacy classes and $$\sum_i \dim(V_i)^2=|G|.$$ So if $d_\mathbb C(G)$ is small, we know that $r$ is large compared to $|G|$ i.e. $G$ has many conjugacy classes. I include examples of groups with $d_\mathbb C(G)=2$ : the dihedral groups, the quaternion group, $S_3$ . And the same for three dimensions: $A_4$ , $S_4$ , $\text{SL}(2,3)$ .","['representation-theory', 'group-theory', 'finite-groups']"
4857983,"When studying a book (like Rudin ) where the problems are not intended to be fully solvable by a student, what criteria show you're ready to advance?","When self studying a text where it is not expected to be able to solve all (or most) of the problems, what are the appropriate criteria to use for advancement? A word about the problems. There are a great number of them. It would be an extraordinary student indeed who could solve them all.... Many are introduced not so much to be solved as to be tackled. The value of a problem is not so much in coming up with the answer as in the ideas and attempted ideas it forces on the would-be solver. --Herstein Advanced books, like Rudin and Herstein, are intentionally written with problems ""not so much to be solved as to be tackled.""  The value in this is self-evident.  But it raises a question: How does a self-learner know when they should continue tackling more problems in a section (or book), and when they should say ""well, I can't solve every problem here, and I haven't even attempted many of them; but I've learned quite a bit, and my time is now best spent learning the next thing."" The inherent challenge here is that learning math is not linear .  Often the only true way to master Section N is to roughly learn Section N+1, and the only way to master Topic A is to roughly learn Topic B. A full solution to every problem in Rudin would probably take years, but, more importantly, can't really be done without learning more advanced topics.  The insight gained from those gives clarity and depth and tools to solve Rudin's problems.  Yet jumping ahead prematurely is a road to nowhere. In a course, this is not an issue: You do the problem sets, take the test, and if you pass, that indicates sufficient mastery to move on.  But a self-learner doesn't have this external cadence.  What criteria, then, should they use? I emphasize: The question is not ""What criteria suggest to go on when stuck on a specific problem ?"".  Rather, it is: When self-studying a book in which you're not expected to be able to solve all the problems of a section, due to their difficulty, what criteria indicate that someone can or should nonetheless advance to the next section?. For an elementary book, the answer is clear ""When you can do the vast majority of problems at the end of a section without error.""  But for an advanced, proof based book, you may never be able to solve all the proofs for a given section; even an honest attempt to do so could take years.  So there must be other criteria a self-learner can use to advance.  What are they? Of course, there is no rigorous objective test for this.  This question is looking for general patterns and soft criteria of the form ""Stay in a section until... but once... it's generally good to move further."" This question is not about a course, academic program, or career path , but about self-study , which is explicitly on topic at Math.SE. Neither is this question about anyone's ""specific circumstances.""  The question is applicable to anyone engaged in advanced self-study: When self studying a text where it is not expected to be able to solve all (or most) of the problems, what are the appropriate criteria to use for advancement? Thus, the question meets Math.SE criteria for self-learning and soft-question , both of which are explicitly on topic of Math.SE: The process of studying mathematics without formal instruction . Don't use this tag just because you were self-studying when you came across the mathematical question you're asking; it is only for when the fact that you're self-studying is what your question is about .","['self-learning', 'real-analysis', 'abstract-algebra', 'education', 'soft-question']"
4858026,Equal sign meaning in equations vs functions,"My kids are learning about functions for the first time, and I was hoping for a little clarity concerning what the equal sign means in a variety of contexts. I have checked out, and understood parts of, the available discussion on the differences between equations and functions. (As a philosopher it was much easier to follow the ""word explanations"" than the explanations in ""math notation."" My intro to logic class was at least 100+ years ago, and didn't help much.) I would like to offer my understanding of the different ways the equal sign seems to be used (with examples), and would love constructive feedback. In equations, the equal sign seems to be used to denote the following things; (these descriptions are my own words, I'm sure there are ""real"" names for what I am trying to describe, also I don't really understand the difference between ""equals"" and ""is equivalent to""): tautologies: $5 = 5$ ; equivalent ""values"": $4 = 8/2$ (the value four is equivalent to the value of eight halves); equivalent expressions: $2x/4 = x/2$ ; value/ expression of a given variable: ""if $x = 2$ ...""; value of an unknown variable, after you know what the ""answer"" is; the value that makes the equation true ""Solve for $x$ ; [math stuff]; $x = 14$ ."" In functions, the equals sign seems to have a different use. It seems to me that in ""function notation"" the equal sign is used more to mean ""therefore"" or the ""then"" part of an ""if then"" conditional. But even here there seems to be several uses. $f(x) = 7x + 3$ , seems to say ""for function $f$ , if the input is $x$ , then the output will be $7x + 3$ ."" So the equal sign relates input to output. But $f(x) = 7x + 3$ also seems to relate input to the rule (""relation""?) that governs the output values. So in this case it means: ""given this input, do this, to calculate the output."" (given function $f$ in #1) "" $f(2) = 17$ "" relates a specific input value (2) to a specific output value (17). Also, if given a function $f$ (from #1), $f(x) = 24$ , seems to represent the question ""what input (into function f) leads to an output of 24?"" Or in other words: output + rule, leads to input. The one overlap I have managed to find between equations and functions, is that the equal sign seems to be able to represent a ""conditional"" for both equations and functions. $f(x) = 7x + 3$ seems to say: ""for $f$ , if $x$ , then $7x + 3$ ."" $f(2) = 17$ seems to say: ""for $f$ , if 2, then 17."" $f(x) = 17$ seems to say: ""for $f$ , if (something unknown), then 17"". Or: ""for $f$ , what input leads to output of 17?"" $8/4 = 2$ means: ""if you have eight fourths, then you (also) have two wholes."" $x = 3$ , as a ""given"" means: ""given equation 'something', if you use 3 as the value of x, then..."". $x = 5$ , as a solution, means: ""given equation 'something', if you use 5 for the value of $x$ , then the equation will be true."" So what do you think? I do really think the equal sign and its variety of uses, is the source of my confusion. Does any of what I have said make sense? Please help! (And thanks!)","['functions', 'terminology']"
4858089,Am I Using Rellich Compactness Theorem Correctly to extract a convergent subsequence,"I'm trying to work through how Rellich compactness theorem is used at the start of this proof to extract the subsequence Given an sequence $\{y_n\}^{\infty} _{n=1} \in H_A(D^*)/ \mathbb{R}$ that is bounded in the energy norm over $D^*$ , you can extract a subsequence that converges in $H^1(D)$ to an element of $H_A(D)/ \mathbb{R}$ . The start of the proof was given as:
Use Poincare Inequality along with Rellich compactness theorem to extract a convergent subsequence in $L^2(D^*)$ . Some notes on terminology: $D \subset D^* \subset \mathbb{R}^n$ (for $n=2,3$ ), the energy norm is $||x||^2 _{E(D)} = \int_{D} A \nabla x \cdot
   \nabla x \mbox{ } d \vec{x}$ , $A$ is a $n \times n$ symmetric positive definite matrix, $H_A(D)$ is the space of functions in $H^1(D)$ that are A harmonic on $D$ My attempt so far is: Consider a sequence $\{y_n\}^{\infty} _{n=1} \in H_A(D^*)/ \mathbb{R}$ that is bounded in the energy norm over $D^*$ . This means there exists some positive M such that $||y_n||_{E(D^*)} =\int_{D^*} A \nabla y_n \cdot \nabla y_n \leq M$ . I was thinking that if I can show that the sequence is bounded in $H_0 ^1( D^*)$ then I can use Rellich compactness Theorem to extract a convergent subsequence in $L^2(D^*)$ (?). I tried to follow what I saw here first but I'm not sure this is correct because I think I need to use the quotient space. Next I tried to follow what I found here in the second answer. I took $y_0 \in H_A(D^*)/ \mathbb{R} \subset H^1(D^*)$ to be the average value of $y$ in $D^*$ . This, I think, means that $y_n - y_0 \in H^1 _0(D^*)$ (?). Then $||y_n - y_0||^2_{H^1 _0(D^*)}$ $ = \int_{D^*} (y_n - y_0)^2 d \vec{x} + \int_{D^*} \nabla(y_n - y_0)^2 d \vec{x}$ $\leq C \int_{D^*} \nabla(y_n)^2 \mbox{ } d \vec{x} +\int_{D^*} \nabla(y_n - y_0)^2 \mbox{ } d \vec{x} $ (last inequality is by alternate version of Poincare Inequality from this source) $= (C+1) \int_{D^*} \nabla y_n \cdot \nabla y_n \mbox{ } d \vec{x} -\int_{D^*} 2 \nabla y_0 \cdot \nabla y_n + \nabla y_0 \cdot \nabla y_0 \mbox{ } d \vec{x}$ But here is where I get confused. I was hoping to be able to use the boundedness of the energy norm in this line of reasoning but without the $A$ matrix involved in the integrals I'm not sure how I can. Once the above bounded argument is fixed, next we can say that by Rellich compactness theorem there exists a subsequence $\{u_{n_k}\} = \{Ty_{n_k}\}$ that converges in $L^2(D^*)$ (I think?). Then since the subsequence converges it is Cauchy in $L^2(D^*)$ . Is this the correct way to use Rellich compactness theorem in the start of this proof? Any input is greatly appreciated. Thank you greatly in advance! If you're interested, I'm referencing this paper.","['normed-spaces', 'real-analysis', 'solution-verification', 'functional-analysis', 'compactness']"
4858090,Best strategy for choosing valued items. (variant of secretary problem) [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 5 months ago . Improve this question Suppose we have to fill our bag with items and each item has a value $V_i \sim \text{Uniform}[a,b]$ where each random variable is iid. There are $N$ items in total but only a fraction $x$ of all items can be put inside the bag. When an item is put inside the bag or discarded the next item appears and you cannot go back. The goal here is to maximize the total value of the bag, i.e., $\max_B \sum_{i\in B}V_i$ . A naive strategy is to put all items in the bag until the bag is full, with corresponding expectation: $E(B)=xN\frac{b-a}{2}$ . My idea is to put all items with values between $[b - y(b-a), b]$ in the bag, where $y$ is updated, i.e., $y=$ number of remaining items in bag divided by $ N$ .  However I don't know what the expectation of this strategy is. What is the best strategy for this problem?  The problem is somewhat similar to the secretary problem but now we are looking for the best $x$ fraction of secretaries, instead of the best single secretary.","['expected-value', 'binomial-distribution', 'probability-theory', 'probability']"
4858092,Question about Stein's Real Analysis Lemma 3.5 in Chapter 2,"Lemma $3.5$ If $E_1 \subset \mathbb{R}^{d_1}$ and $E_2 \subset \mathbb{R}^{d_2}$ , then $$m_* \left( E_1 \times E_2 \right) \leq m_* \left( E_1 \right) m_* \left( E_2 \right),$$ with the understanding that if one of the sets $E_j$ has exterior measure zero, then $m_* \left( E_1 \times E_2 \right) = 0$ . The above is the statement of Lemma $3.5$ in chapter $2$ of Stein's real analysis. The author proves that $m_* \left( E_1 \times E_2 \right) \leq \left( m_* \left( E_1 \right) + \epsilon \right) \left( m_* \left( E_2 \right) + \epsilon \right)$ for any $\epsilon > 0$ . I think this completes the proof of the Lemma $3.5$ by the arbitrariness of $\epsilon > 0$ . However, in the textbook, it is divided into two cases as follows: If neither $E_1$ nor $E_2$ has exterior measure $0$ , then from the above we find $$m_* \left( E_1 \times E_2 \right) \leq m_* \left( E_1 \right) m_* \left( E_2 \right) + O \left( \epsilon \right),$$ and since $\epsilon$ is arbitrary, we must have $m_* \left( E_1 \times E_2 \right) \leq m_* \left( E_1 \right) m_* \left( E_2 \right)$ . If for instance $m_* \left( E_1 \right) = 0$ , consider for each positive integer $j$ the set $E_2^j = E_2 \cap \left\{ y \in \mathbb{R}^{d_2} : \left\lvert y \right\rvert \leq j \right\}$ .
Then, by the above argument, we find that $m_* ( E_1 \times E_2^j ) = 0$ .
since $( E_1 \times E_2^j ) \nearrow \left( E_1 \times E_2 \right)$ as $j \to \infty$ , we conclude that $m_* \left( E_1 \times E_2 \right) = 0$ . But, why do we have to divide the cases? It seems to me that it suffices to describe it as the case that $E_1$ and $E_2$ has nonzero exterior measure, in both cases. Am I missing something? Edit) The $m_*$ is the one which is usually called Lebesgue outer measure, and called exterior measure in the textbook.","['measure-theory', 'lebesgue-measure', 'real-analysis']"
4858101,Compute the Lie derivative for $X=y \frac{\partial}{\partial x}$ and $Y=x \frac{\partial}{\partial y}$,"Question : On $\mathbf{R}^2$ , let $X=y \frac{\partial}{\partial x}$ and let $Y=x \frac{\partial}{\partial y}$ , with corresponding flows given by $\phi_t(x, y)=(x+t y, y)$ and $\psi_t(x, y)=(x, y+t x)$ . Then show that the Lie derivative, $\mathcal L_XY=-x\frac{\partial}{\partial x}+y\frac{\partial}{\partial y}$ The definition given in the book, Definition 4.7.1. Let $T$ be a tensor field of type $(r, s)$ on $\mathbf{R}^n$ and let $X$ be a vector field with flow $\phi_t: \mathbf{R}^n \rightarrow \mathbf{R}^n$ . The Lie derivative of $T$ with respect to $X$ , denoted by $\mathcal{L}_X T$ , is the $(r, s)$ -tensor defined as $$
\mathcal{L}_X T=\left.\frac{d}{d t}\right|_{t=0}\left(\phi_t^* T\right) .
$$ But when we have a ambient space like for this example then do we need the flow to define the Lie derivative? Inspired from this M.SE answer , I give a try below: $$
\begin{align}
\mathcal L_XY&=\mathcal L_X\left(x\frac{\partial}{\partial y}\right)\\
&=[\mathcal L_X(x)]\frac{\partial}{\partial y}+x[\mathcal L_X\left(\frac{\partial}{\partial y}\right)]\\
&=[y\frac{\partial}{\partial x}(x)]\frac{\partial}{\partial y}+x[y\frac{\partial}{\partial x}\left(\frac{\partial}{\partial y}\right)]\\
&=y\frac{\partial}{\partial y}+?
\end{align}
$$ but here I guess $\mathcal L_X(\frac{\partial}{\partial y})$ doesn't make sense! Or I am not expert enough to guess the meaning.","['lie-derivative', 'differential-geometry']"
4858131,How to minimize an expression to show the norm,"I'm quite surprised I can't solve this problem. Given the following function : $\forall\left(x,y\right)\in\mathbb{R}^{2},\quad f(x,y)=x^{4}+y^{4}-2(x-y)^{2}$ show that $\forall\left(x,y\right)\in\mathbb{R}^{2} \quad f(x,y)\geq{\frac{1}{2}}(x^{2}+y^{2})^{2}-4(x^{2}+y^{2})$ I show that $2(x-y)^{2} \leq 4(x^{2}+y^{2})$ Then I want to show that $x^{4}+y^{4} \geq  \frac{1}{2}(x^{2}+y^{2})^{2}$ But it's here that I'm struggling, I can only show that $x^{4}+y^{4} \geq 2x^{2}y^{2}$ And I can't go further. I know that you can solve the exercice the other way around, by maximizing $\frac{1}{2}(x^{2}+y^{2})^{2}$ , but I want to understand, how you can do it without knowing the result, in the case I have to show in the future that a function is infinite. Thanks everyone","['multivariable-calculus', 'calculus', 'inequality']"
4858184,Regular curve and the implicit function theorem?,"Given $\gamma(t)=(x(t),y(t)):\mathbb{R}\to\mathbb{R^2}$ be a smooth regular curve. i.e. $\gamma'(t)\neq0$ . Is there any relationship between such a curve and the implicit function theorem? In particular, is it true that at any point in which the curve is regular, it can be represented as a graph of a function $x=x(y)$ or $y=y(x)$ , at least locally? I am asking because if e.g. $x'(t_0)\neq0$ then the tangent at this point is not parallel to the y-axis, and at least graphically, it seems like it would imply that there is a neighborhood of $(x(t_0),y(t_0)) $ in which the curve is a function $y=y(x)$ . Thank you","['multivariable-calculus', 'differential-geometry']"
4858185,"Entire function bounded in every horizontal line, and has limit along the positive real line","Let $f(z)$ be an entire function (holomorphic function on $\mathbb{C}$ ) satifying the following condition: $$|f(z)|\leq \max (e^{\text{im}(z)},1 ),\ \forall z\in\mathbb{C}$$ $$\lim_{\mathbb{R}\ni t\rightarrow+\infty} f(t)=0$$ My question is: can we prove that the following limit exists? $$\lim_{\mathbb{R}\ni t\rightarrow-\infty} f(t)$$ Maybe we can even prove $f(z)=0$ . But I do not know how to prove it. My trying: if $f(z)$ has finitely many zeros, then by Hadamard factorization theorem, $f(x)=e^{az+b}P(z)$ where $P(z)$ is a polynomial. such a function can not be bounded by $\max(e^{\text{im}(z)},1)$ , unless $P(z)\in\mathbb{C}$ and $ia\in\mathbb{R}$ . Then we know $f(z)$ has to be $0$ . But if $f(z)=0$ has infinitely many solution, then I do not know how to proceed.","['complex-analysis', 'entire-functions', 'harmonic-functions']"
4858213,"Possibility of bounding $\sum_{n=0}^N |a_n|$ from above by $\sup_{z\in (0,1)} |\sum_{1\leq n\leq N} (1+z+\ldots+z^{n-1}) a_n|$","Assume that $a = (a_0,a_1,\ldots,a_N)$ where $N \in \mathbb{N}_+$ is fixed belongs to the space $$V = \left\{a \in (-1,1)^{N+1} : a\neq {\bf 0},~~ \sum_{n=0}^N a_n = 0,~~a_N = 0\right\}$$ I am wondering if it is possible to bound $\sum_{n=0}^N |a_n|$ (or $\max_{0\leq n\leq N} |a_n|$ since $N$ is finite and fixed) by some constant multiple of $\sup_{z\in (0,1)} |\sum_{1\leq n\leq N} (1+z+\ldots+z^{n-1}) a_n|$ (or of some polynomial functions of $\sup_{z\in (0,1)} |\sum_{1\leq n\leq N} (1+z+\ldots+z^{n-1}) a_n|$ ? Any help or suggestions are greatly welcomed!","['inequality', 'discrete-mathematics', 'sequences-and-series']"
4858224,Why are Gaussian measures seen as the standard measure for infinite dimensional spaces?,"I'm learning about infinite dimensional probability, and most resources I've consulted so far motivate things by saying there is no infinite dimensional Lebesgue/translation invariant measure that gives nontrivial measures for unit balls in a Banach space. The proposed alternative is almost always to look Gaussian measures instead. Why are they seen as the standard alternative to Lebesgue measure when doing probability in infinite dimensions?","['gaussian-measure', 'probability-theory', 'normal-distribution']"
4858232,"Determining the circumdiameter of a triangle, given the distance from a vertex to the orthocenter and the length of the opposite side","Problem I'm trying to solve: Given triangle $ABC$ inscribed in a circle a shown. The altitudes of the triangle meet at point $P$ . $AP=21\text{cm}$ and $BC=20\text{cm}$ . What is the diameter of the circle? My Attempt Let the point where the altitude of $AB$ meets $AB$ be $Q$ ,the point where the altitude of $AC$ meets $AC$ be $R$ and the point where the altitude of $BC$ meets $BC$ be $S$ . Then let $PQ$ be $21x$ . From the similarity of $\triangle APQ$ and $\triangle BCQ$ , $BQ=20x$ and by the pythagorean theorem $BP=29x$ . It's relatively easy to see that $\triangle AQP \sim \triangle ABS \sim \triangle PCS \sim \triangle BCQ$ and pretty much the same for most other triangles that can be found in the circle however I'm lost as to where to go from there since everything else just seems to give lengths of triangle sides in terms of $x$ . I've also tried drawing radii and diameters through the vertices of the triangle in order to determine some possible relation between the angles, sides and the circle's radius but this doesn't seem to get anywhere either. My original idea was to determine the area of triangle and the sides of the triangle from which the radius readily follows but I just seem to have too little information to move forward with anything? I don't think there's a way to apply Ptolemy's theorem or any other theorem here so I just simply don't know how to move forward.","['contest-math', 'circles', 'geometry', 'triangles', 'recreational-mathematics']"
4858257,For every subgroup $H$ of a finite abelian group $ G$ there exist an endomorphism $\phi$ with $\text{Im}(\phi)=H$,"This is exercise 7 from ""The Theory of Finite Groups"" by Hans Kurzweil, page 49. For every subgroup $H$ of a finite abelian group $ G$ there exist an endomorphism $\phi$ with $\text{Im}(\phi)=H$ I believe it can be tackled using the classification theorem of abelian groups, which states that every abelian group is a direct product of cyclic groups. However, I am unable to proceed further with the given information. I know that $G$ is a product of cyclic groups and $H$ and $G$ is a product of some of these factors.","['group-homomorphism', 'abelian-groups', 'group-theory', 'finite-groups']"
4858296,How to reasonably estimate the probability of your father being exactly 12222 days older than you?,"On 2024/05/03, my brother is 10,000 days of age, while my father will be 22,222 days old.
To tell them as a fun-fact, I would like to grab a feel of how special this is. I have no access to datasets that could provide me a distribution of the likelihood of becoming a parent at n days of age. It doesn't matter whether this child is the father's first child. (Off-topic: I asked chat gpt for inspiration on how to celebrate this event, and to my surprise it was quite creative as long as it didn't have to organize it itself.) Kind regards from Belgium",['probability']
4858402,Proving a parametrized function cannot generically cover a curve,"Let $D$ be a set of infinitely smooth (in $C^\infty$ ) functions from $\mathbb{R}^2$ to $\mathbb{R}$ that are strictly increasing in both arguments. Let $C$ be a compact subset of $\mathbb{R}^N$ and $g:\mathbb{R}^2 \times C \to \mathbb{R}$ be some twice-continuously differentiable function strictly increasing in the first two arguments. $C$ is its parameter space. I want to show that the following property holds for a generic $f\in D$ : For every $k\in \mathbb{R}$ , $x \in C$ , the set $
\{(a,b) \in \mathbb{R}^2: \ \ g(a,b; x)= f(a,b)=k \}
$ is countable. By `generically' I mean that it holds on an open and dense set of functions $f$ in $D$ . Intuition: The parameter space of $g$ is finite-dimensional. Thus, there are not enough degrees of freedom to align the level curves of $f$ and $g$ along any region of positive length. Infinite dimentional Thom's transversality theorem seems relevant, but I do not know how to apply it.","['general-topology', 'differential-topology', 'transversality']"
4858411,Continuous bijection to Hausdorff is homeomorphism $\Rightarrow$ compact,"There is a famous theorem that for a compact topological space $X$ , continuous bijection $f:X\to Y $ where $Y$ is Hausdorff is homeomorphic. I want to know if the converse is true, i.e. Let topological sapce $X$ satisfy the following property: For any continuous bijection $f:X\to Y $ where $Y$ is Hausdorff is homeomorphic. Then,  can we say $X$ is compact? For example, if $X=(0,1]$ then let $Y$ be a circle and continuous bojection $f:X\to Y$ be connecting $1\in X$ to $0\notin X$ , so we fail to construct counterexample.
If $X=(0,1)$ then connect $0\notin X$ to $\frac{1}{2}\in X$ .","['general-topology', 'compactness']"
4858415,"Integration of $ \int_{0}^{\frac{\pi}{2}} x \log(1-\cos x) \,dx $ [closed]","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 months ago . This post was edited and submitted for review last month and failed to reopen the post: Original close reason(s) were not resolved Improve this question Question: What is the closed form of this following integral? $
\int_{0}^{\frac{\pi}{2}} x \log(1-\cos x) \,dx.$ Here is my solution we know that $$\displaystyle{\sum\limits_{n = 1}^\infty  {\frac{{\cos nx}}{n}}  = \frac{1}{2}\left( {\sum\limits_{n = 1}^\infty  {\frac{{{e^{inx}}}}{n}}  + \sum\limits_{n = 1}^\infty  {\frac{{{e^{ - inx}}}}{n}} } \right) =  - \frac{1}{2}\log \left( {1 - {e^{ix}}} \right)\left( {1 - {e^{ - ix}}} \right) =  - \frac{1}{2}\log 2\left( {1 - \cos x} \right) = }$$ $$\displaystyle{ =  - \frac{{\log 2}}{2} - \frac{1}{2}\log \left( {1 - \cos x} \right) \Rightarrow \boxed{\log \left( {1 - \cos x} \right) =  - \log 2 - 2\sum\limits_{n = 1}^\infty  {\frac{{\cos nx}}{n}} }}$$ , so $$\displaystyle{\int\limits_0^{\pi /2} {x\log \left( {1 - \cos x} \right)dx}  =  - \log 2\int\limits_0^{\pi /2} {x\,dx}  - 2\sum\limits_{n = 1}^\infty  {\frac{1}{n}\int\limits_0^{\pi /2} {x\cos nx\,dx} }  =  - \frac{{{\pi ^2}\log 2}}{8} -   2\sum\limits_{n = 1}^\infty  {\frac{1}{n}\left( { - \frac{1}{{{n^2}}} + \frac{{\cos \dfrac{{n\pi }}{2}}}{{{n^2}}} + \pi \frac{{\sin \dfrac{{n\pi }}{2}}}{{2n}}} \right)}  = }$$ $$\displaystyle{ =  - \frac{{{\pi ^2}\log 2}}{8} + 2\zeta \left( 3 \right) - 2\sum\limits_{n = 1}^\infty  {\frac{{\cos \dfrac{{n\pi }}{2}}}{{{n^3}}}}  - \pi \sum\limits_{n = 1}^\infty  {\frac{{\sin \dfrac{{n\pi }}{2}}}{{{n^2}}}}  =  - \frac{{{\pi ^2}\log 2}}{8} + 2\zeta \left( 3 \right) - \sum\limits_{n = 1}^\infty  {\frac{{\left( {{i^n} + {{\left( { - i} \right)}^n}} \right)}}{{{n^3}}}}  - \frac{\pi }{{2i}}\sum\limits_{n = 1}^\infty  {\frac{{\left( {{i^n} - {{\left( { - i} \right)}^n}} \right)}}{{{n^2}}}}  \Rightarrow }$$ $$\displaystyle{ \Rightarrow \boxed{\int\limits_0^{\pi /2} {x\log \left( {1 - \cos x} \right)dx}  =  - \frac{{{\pi ^2}\log 2}}{8} + 2\zeta \left( 3 \right) - \left( {L{i_3}\left( i \right) + L{i_3}\left( { - i} \right)} \right) - \frac{\pi }{{2i}}\left( {L{i_2}\left( i \right) - L{i_2}\left( { - i} \right)} \right)}}$$ However, it holds that $$\displaystyle{L{i_3}\left( z \right) + L{i_3}\left( { - z} \right) = \frac{1}{4}L{i_3}\left( {{z^2}} \right)}$$ , so $$\displaystyle{L{i_3}\left( i \right) + L{i_3}\left( { - i} \right) = \frac{1}{4}L{i_3}\left( { - 1} \right) = \frac{1}{4}\sum\limits_{n = 1}^\infty  {\frac{{{{\left( { - 1} \right)}^n}}}{{{n^3}}}}  =  - \frac{3}{{16}}\zeta \left( 3 \right)}$$ and $$\displaystyle{L{i_2}\left( i \right) - L{i_2}\left( { - i} \right) = \sum\limits_{n = 1}^\infty  {\frac{{{i^n}}}{{{n^2}}}}  - \sum\limits_{n = 1}^\infty  {\frac{{{{\left( { - i} \right)}^n}}}{{{n^2}}}}  = \sum\limits_{n = 1}^\infty  {\frac{{{i^{2n - 1}}}}{{{{\left( {2n - 1} \right)}^2}}}}  + \sum\limits_{n = 1}^\infty  {\frac{{{i^{2n}}}}{{{{\left( {2n} \right)}^2}}}}  - \sum\limits_{n = 1}^\infty  {\frac{{{{\left( { - i} \right)}^{2n - 1}}}}{{{{\left( {2n - 1} \right)}^2}}}}  - \sum\limits_{n = 1}^\infty  {\frac{{{{\left( { - i} \right)}^{2n}}}}{{{{\left( {2n} \right)}^2}}}}  = }$$ $$\displaystyle{ = 2\sum\limits_{n = 1}^\infty  {\frac{{{i^{2n - 1}}}}{{{{\left( {2n - 1} \right)}^2}}}}  = \frac{2}{i}\sum\limits_{n = 1}^\infty  {\frac{{{{\left( { - 1} \right)}^n}}}{{{{\left( {2n - 1} \right)}^2}}}}  =  - 2i\sum\limits_{n = 1}^\infty  {\frac{{{{\left( { - 1} \right)}^n}}}{{{{\left( {2n - 1} \right)}^2}}}}  = 2i\sum\limits_{n = 0}^\infty  {\frac{{{{\left( { - 1} \right)}^n}}}{{{{\left( {2n + 1} \right)}^2}}}}  = 2i \cdot G}$$ Therefore, $$\displaystyle{\int\limits_0^{\pi /2} {x\log \left( {1 - \cos x} \right)dx}  =  - \frac{{{\pi ^2}\log 2}}{8} + 2\zeta \left( 3 \right) - \left( {L{i_3}\left( i \right) + L{i_3}\left( { - i} \right)} \right) - \frac{\pi }{{2i}}\left( {L{i_2}\left( i \right) - L{i_2}\left( { - i} \right)} \right) = }$$ $$\displaystyle{ =  - \frac{{{\pi ^2}\log 2}}{8} + 2\zeta \left( 3 \right) + \frac{3}{{16}}\zeta \left( 3 \right) - \frac{\pi }{{2i}}\left( {2i \cdot G} \right) =  - \frac{{{\pi ^2}\log 2}}{8} + \frac{{35}}{{16}}\zeta \left( 3 \right) - \pi  \cdot G}.$$ Sorry to the community for the misunderstanding. When DecarbonatedOdessa asked, ""Is there a question in there somewhere?"" I misunderstood what they were asking and answered, ""Yes, on AOPS, but I’m trying a new way to find the answer."" It was my mistake; they asked me something else, and I answered something else.","['integration', 'calculus', 'definite-integrals', 'closed-form']"
4858423,"Can Stolz-Cesaro theorem be applied to this problem? If $\lim\limits_{x\to\infty}(f(x+1)-f(x))=l$, Prove that $\lim\limits_{x\to\infty}\frac{f(x)}x=l$","If $f :(a , \infty ) \to \mathbb{R}$ and $f $ is bounded on every $(a,b)$ such that $a<b <\infty$ ,  prove that $\lim\limits_{x \to \infty }(f(x+1) - f(x))=l$ implies $\lim\limits_{x \to \infty  }\frac{f(x)}{x}=l$ . The first thing that came to my mind was Stolz-Cesàro theorem case $\frac{*}{\infty}$ :- If $b_n $ is a monotone increasing sequence and $\lim \limits_{n \to \infty} b_n = \infty $ ,
and if $\lim \limits_{n \to \infty} \frac{a_{n+1}-a_n}{b_{n+1}- b_n}= l \in \overline{\mathbb{R}} $ , then $\lim \limits_{n \to \infty} \frac{a_n }{b_n}=l$ . Does this really solve this problem? There are uncountably many sub-sequences with the limit $l$ , i.e., there is a subsequence for all $x\in (a, a+1]$ with limit $l$ , but this doesn't imply that the sequence has the limit $l$ . One famous example where there are infinitely many sub-sequences with the same limit but the limit of the sequence doesn't exist is: $$a_n =
\begin{cases}
\frac{1}{r},  & \text{if $n$ is a power of prime $n = p^r \ : r\ge1$} \\[2ex]
0, & \text{if $n$ is not a power of prime  }
\end{cases}$$ One can make infinitely many sub-sequences that converge to $0$ although $a_n $ doesn't converge to $0$ . After a lot of time thinking, I couldn't prove this problem, so I searched on MSE for a solution and found this , which gives a general proof for this problem. But my question is: Can we use the Stolz-Cesàro theorem to solve this problem? If we can use the Stolz-Cesàro theorem, how do we complete the proof?","['analysis', 'real-analysis', 'alternative-proof', 'sequences-and-series', 'limits']"
4858434,Finding the limit of $n(\ln2-\sum_{k=1}^n\frac{1}{n+k})$.,"Let $$A_n:=\frac{1}{n+1}+\cdots+\frac{1}{2n}.$$ It is well known that $A_n$ is an increasing sequence, and $\lim_{n\rightarrow \infty}A_n=\ln(2)$ .
Motivated by how fast $A_n$ converges to $ln(2)$ , I would like to know the limit below $$\lim_{n\rightarrow\infty}n\left(\ln(2)-A_n\right).$$ First, since $1/(1+x)$ is a strictly decreasing function, we have $$\ln 2=\int_0^1 \frac{1}{1+x}\, dx<\frac{1}{n}\sum_{k=0}^{n-1}\frac{1}{1+k/n}=\frac{1}{n}+\cdots+\frac{1}{2n-1}.$$ Therefore, we have $$\ln(2)-A_n<\left(\frac{1}{n}+\cdots+\frac{1}{2n-1}\right)-\left(\frac{1}{n+1}+\cdots+\frac{1}{2n}\right)=\frac{1}{n}-\frac{1}{2n}=\frac{1}{2n}.$$ Hence $B_n:=n(\ln2-A_n)$ is bounded from above, and $$\limsup_{n\rightarrow\infty}B_n\le \frac{1}{2}.$$ Furthermore, since $b_n:=1/(\ln 2-A_n)$ is strictly increasing, by the Stolz theorem, we have $$\lim_{n\rightarrow \infty}B_n=\lim_{n\rightarrow \infty}\frac{1}{b_{n+1}-b_n}=\lim_{n\rightarrow \infty}4(1+\frac{1}{2n})B_nB_{n+1}.$$ Therefore, if $B_n$ has a limit, then the limit has to be $0$ or $1/4$ . However, first, I have some trouble in showing the monotonicity of $B_n$ , and more importantly, I don't know how to exclude the possibility that the limit of $B_n$ cannot be $0$ . Any ideas or comments are fully appreciated.","['calculus', 'sequences-and-series']"
4858437,Interpretation of change in direction cosines of a variable line: Pythagorean theorem for small angles?,"Consider a variable rotating line passing through a fixed point. The angle between two successive/adjacent positions of the line is a small angle $\delta \theta$ . If the change in the direction cosines of the line in these two positions is $\delta l$ , $\delta m$ , $\delta n$ respectively, prove that: $$(\delta \theta)^2=(\delta l)^2+(\delta m)^2+(\delta n)^2$$ This sort of resembles the formula for the length of a vector expressed in terms of the projections on 3 orthogonal axes. Does this above expression somehow result from the fact that we can treat angular vector variables in the same manner as all other kinds of vectors (by all other kinds of vectors, I mean displacement, velocity, acceleration, etc, and by angular vector variables, I mean angular displacement, angular velocity ( $\omega$ ), etc)? How can I interpret this expression? I am curious because I found this to be a surprisingly concise and elegant formula for describing small angles of a variable line in 3D. EDIT: I found an answer for this but I still have some doubts; let the initial direction cosines be $(l,m,n)$ and final direction cosines be $(l+\delta l, m+\delta m, n+ \delta n)$ . So, $l^2+m^2+n^2=1$ and $(l+\delta l)^2+ (m+\delta m)^2+ (n+ \delta n)^2=1$ $\implies 2(l\delta l + m \delta m + n \delta n) = - ((\delta l)^2+(\delta m)^2+(\delta n)^2)...(i)$ Taking the dot product, we get $\cos(\delta \theta)=l(l+\delta l)+m(m+\delta m)+n(n+\delta n)$ $\implies \cos(\delta \theta)=1+l\delta l + m \delta m + n \delta n$ Since $\delta \theta$ is small, we may approximate $cos(\delta \theta)$ as $\left(1-\dfrac{(\delta \theta)^2}{2}\right)$ . Now, using (i), it is easy to see that, hence $(\delta \theta)^2=(\delta l)^2+(\delta m)^2+(\delta n)^2$ ...(ii). I decided to take things a step further and write $\delta l = \cos(\alpha+\delta \alpha)-\cos(\alpha)$ , where $\delta \alpha$ is the small angle change of the line with the x-axis. Similar relations may be written for $\delta m$ and $\delta n$ . In the end, I was hoping to find a relation of the Pythagorean form containing $(\delta \alpha)^2+(\delta \beta)^2+(\delta \gamma)^2$ which I could perhaps interpret better, but I got a complicated mess of terms which eventually boils down to the following expression upon neglecting all terms above the second order; $$(\delta \theta)^2=(\delta \alpha)^2 \sin^2 \alpha + (\delta \beta)^2 \sin^2 \beta + (\delta \gamma)^2 \sin^2 \gamma ...(iii)$$ which is a simple expression but it doesn't give any insight as to why $\delta \theta$ obeys such a simple law. Does anyone have any insight into this problem or perhaps a more clever alternative way of arriving at equation (iii)?","['analytic-geometry', 'vectors', '3d', 'taylor-expansion', 'trigonometry']"
4858465,Candies Withdrawal Game,"You are taking out candies one by one from a jar that has 10 red candies, 20 blue candies, and 30 green candies in it. What is the probability that there are at least 1 blue candy and 1 green candy left in the jar when you have taken out all the red candies? Why is my approach wrong: $$\frac{2 \cdot 58!}{10! \cdot 29! \cdot 19!} \,\Big / \frac{60!}{10! \cdot 30! \cdot 20!}$$ Reasoning:
There are 2 cases: last candy is green, 2nd last candy is blue last candy is blue, 2nd last candy is green For each of the cases, where the last and 2nd last candy withdrawn is fixed, there are $\frac{58!}{10!29!19!}$ ways to arrange the rest of the candies. Hence, the numerator. For the denominator, it is the total number of ways to arrange all the candies, $\frac{60!}{10!30!20!}$ . However, as compared to the answer, $7/12$ , my approach seems to be undercounting. Why?","['combinatorics', 'probability']"
4858505,Estimating the expected supremum of the absolute value of a Gaussian process,"I'm currently reading a famous paper of Talagrand and fail to ""easily see"" that for a Gaussian process $(X_t)_{t\in T}$ and any $t_0 \in T$ one has $$ E \sup_T | X_t | \leq E |X_{t_0}| + 2E \sup_T \, X_t $$ Could anybody please provide some details? For reference: The statement appears in (1) on page 2 of Regularity of gaussian processes","['probability-theory', 'probability', 'normal-distribution']"
4858545,Asymptotic convergence of sampling distribution of the sample variance,"Let's consider a set $\{X_i\}_{i=1}^N$ of $N$ i.i.d. random variables drawn from the distribution $P_X(x) = \mathcal{N}(\mu, \sigma^2)$ . Define the variable $$\hat{\sigma}^2 = \frac{1}{N} \sum_i (X_i - \hat{\mu})^2$$ where $\hat{\mu} \equiv \frac{1}{N}\sum_i X_i$ ; it follows that (see for example here ) : $$\hat{\sigma}^2 \sim \frac{1}{2^{\frac{N-1}{2}}\Gamma\left( \frac{N-1}{2}\right)}x^{\frac{N-3}{2}} \left( \frac{N}{\sigma^2} \right)^{\frac{N-1}{2}} e^{-\frac{x}{2} \frac{N}{\sigma^2}} \;\;\;\;\;\;\;\; \;\;\;\;\;\;\;\; \;\;\;\;\;\;\;\; (1)$$ Now, given that $\hat{\sigma}^2$ is the sample variance, from the law of large numbers, in the $\lim_{N \to \infty}$ , $\hat\sigma^2$ converges in probability to the expected value $\sigma^2$ . Question: Is it possible to show that in the $\lim_{N \to \infty}$ the measure of $\hat\sigma^2$ distribution (Eq. (1)) concentrates around the value $\sigma^2$ , i.e. $$\lim_{N \to \infty} P(|\hat \sigma^2 - \sigma^2|>\epsilon )=0 \;,  \;\;\; \forall \epsilon>0 \; \;?$$","['statistics', 'normal-distribution', 'chi-squared', 'probability-theory', 'probability']"
4858593,Continuity at a single point implies continuity at the whole domain for a given function.,"Let $f:(0, \infty)\to\mathbb{R}$ be a function such that $$f(x)=f\bigg(\frac{x}2+1\bigg).$$ Show that there exists a $p\in (0, \infty)$ such that if $f$ is continuous at $p$ , then $f$ is continuous everywhere. My idea: I started by noticing that $$x=\frac{x}{2}+1\implies x=2.$$ I want to show that if $f$ is continuous at $2$ , then $f$ is continuous everywhere. Am I right? How to proceed if $p=2$ ?","['continuity', 'functions', 'real-analysis']"
4858603,Understand the definition of covariant derivative for parameterized set,"A geometric set $S \subset R^n$ is a set having the property that for each point $p \in S$ , there is a vector subspace $T_pS \subset T_p\mathbb R^n$ . Moreover, these subspaces should vary smoothly with $p$ and should all have the same dimension. Let $U\subset\mathbb R^k$ be a domain and let $\phi:U\rightarrow\mathbb R^n(k\leq n)$ be a smooth, one-to-one function that is regular for all $p\in U$ . A parameterized set $S=\phi(U)$ is defined to be the image of $U$ in $\mathbb R^n$ by $\phi$ . The geometric features of the parameterized set $S$ come from “encoding” features of the parameter space $U$ through the function $\phi$ . Then the author ( First Steps in Differential Geometry Riemannian, Contact, Symplectic by Andrew McInerney ) built intuition like Riemannian metrics, Riemannian Connection and curvature on the geometric set or more specifically the parameterized set. Proposition 5.1.9. Let $(U, g)$ be a Riemannian space, $\mathcal{X}(U)$ the set of smooth vector fields on $U$ , and $\Lambda_1(U)$ the set of smooth one-forms on $U$ . Then the map $\gamma: \mathcal{X}(U) \rightarrow \Lambda_1(U)$ given by $\gamma(X)=i(X)$ g for $X \in \mathcal{X}(U)$ , i.e., $\gamma(X)$ is the differential one-form such that for any vector field $Y$ on $U$ , $$
(\gamma(X))(Y)=g(X, Y),
$$ induces a vector space isomorphism $\gamma_p: T_p U \rightarrow T_p^* U$ for all $p \in U$ . Definition 5.3.2. Suppose $X$ and $Y$ are smooth vector fields on a Riemannian space $(U, g)$ . Let $\theta_Y=\gamma(Y)$ be the one-form corresponding to the vector field $Y$ under the isomorphism $\gamma$ induced by $g$ defined in Proposition 5.1.9. Construct a new oneform $\theta_{Y, X}$ as follows: $$
\theta_{Y, X}=\frac{1}{2} i(X)\left[\mathcal{L}_Y g+d \theta_Y\right] .
$$ The covariant derivative of $Y$ with respect to $X$ (relative to the metric tensor $g$ ), denoted by $\nabla_X Y$ , is the vector field $$
\nabla_X Y=\gamma^{-1}\left(\theta_{Y, X}\right) .
$$ The assignment $\nabla:(X, Y) \mapsto \nabla_X Y$ is also known as the Riemannian connection corresponding to $g$ . I didn't understand the motivation behind this definition of the covariant derivative, $\nabla_X Y$ , as others have explained it as the horizontal (or tangential) component of the directional derivative, $D_X Y$ , or as the change of $Y$ in the direction of $X$ using any curve $\gamma$ which goes in the direction of $X$ and uses parallel transport to transport $Y(\gamma(t))$ back to $T_pM$ in order to compare it with $Y(p)$ . However, I couldn't connect Definition 5.3.2. with any of those. It would be greatly appreciated if anyone could shed some light on it. Another question I have is: I didn't come across any examples for computing connections of vector bundles or covariant derivatives on abstract manifolds. Is there a resource where I can find examples or problems to work on? Without seeing these examples, I find it difficult to grasp the complete picture, and I'm starting to forget whatever I've read so far. Thank you in advance.","['connections', 'differential-geometry']"
4858605,Lower Bound of a Function for proving an Inequality,"Actually, I am trying to solve a mathematical problem, which involves proving an inequality. For that I already know the bounds of LHS of the inequality and now I need the lower bound of the RHS of the inequality (which I mentioned below in the list). I want a function $F(x)$ such that $F(x) \leq G(x)$ , where $G(x)$ is: $\sqrt{x}  \ln(x)  \ln(x)$ $\frac{1}{8}\pi  \sqrt{x}  \ln(x)  \ln(x)$ $2  \sqrt{x}  \ln(x)  \ln(x)$ Here all the above three values are equivalent (in the context of the question) so all or any value that is suitable can be considered for the calculation of lower bound. But the additional constraint or condition is that $F(x) > H(x)$ , where $H(x) = 0.006409\frac{x}{\ln(x)}$ Note - Kindly note that this is NOT a homework question. I have been trying very hard to find it, so any help will be greatly appreciated. Thanks in advance!","['inequality', 'functions', 'upper-lower-bounds']"
4858632,"On $\int_0^\pi\arctan(1+\cos x)\,\mathrm{d}x\overset{?}{=}\pi\operatorname{arccot}\sqrt{\phi}$","$\newcommand{\d}{\,\mathrm{d}}\newcommand{\arccot}{\operatorname{arccot}}$ I recently took part in a UK university integration bee (which is over, so, there is no issue posting about it). My team did pretty well but of course there were a few we didn't get; I find this one interesting in particular. $$J:=\int_0^\pi\arctan(1+\cos x)\d x=\pi\arccot(\sqrt{\phi})$$ Where appears the golden ratio. (well, we don't actually know what the real answer is but according to numerical reverse engineering software it checks out to $\pi\arccot(\sqrt{\phi})$ and this is just plausible enough) Using elementary symmetries you can realise $J=\int_0^{\pi/2}\arctan(2\csc^2(x))\d x=\int_0^{\pi/2}\arctan(2\sec^2(x))\d x$ or that $J=\int_0^{\pi}\arctan(2\cos^2(x/2))\d x$ . No apparent reduction in complexity. We tried differentiation under the integral sign with: $\int_0^\pi\arctan(\alpha(1+\cos x))\d x$ $\int_0^\pi\arctan(\alpha+\cos x)\d x$ $\int_0^\pi\arctan(1+\alpha\cos x)\d x$ $\int_0^\pi\arctan(1+\cos(\alpha x))\d x$ None seemed to give anything we could work with. The only real trick up my sleeve - contour integration - is almost certainly inapplicable here. Does anyone have any ideas? There's probably an easy way that we missed.","['integration', 'definite-integrals']"
4858634,What are the prerequisites to study Calculus on Manifolds.,"I'm a bachelor degree math student who is interested in differential geometry and topology and doing my way through it. Recently I discovered the world of Calculus on Manifolds and I wish to know what are the prerequisists to studying it. I know that, besides a lot of Topology, Analysis and Linear Algebra, I need also some of Tensor Algebra (I don't know if it's the correct therm for it) and learning about the Wedge Product, Exterior Derivative and etc. However, I don't really know to where to get started. I want to know if there is a recomendation to what subjects to studied first and some good references. I apologize if the english isn't proper or it was already been asked before.","['manifolds', 'multivariable-calculus', 'differential-topology', 'reference-request']"
4858642,Seeking Efficient Solution Strategies for a Triple Integral,"I'm attempting to evaluate the following triple integral: $$
\int_{-1}^1 \int_{-1}^1 \int_0^{\frac{4}{\sqrt{2}}\big(1+yz-|y+z|\big)} \sqrt{2x^2+(y-z)^2} \, dx \, dy \, dz
$$ I initially attempted a direct solution, and while the inner integral has an antiderivative, the upper limit poses challenges due to its complexity. Integrating the resulting expression with this limit inflates the integral. Subsequently, I explored a suitable transformation but haven't identified an effective one. I'm seeking guidance on potential strategies or clever approaches to solve this integral more efficiently. Your insights and assistance would be greatly appreciated.","['integration', 'multivariable-calculus', 'definite-integrals']"
4858646,Is this map a smooth embedding?,"Take the map $\gamma: (1,\infty) \to \mathbb{R}^2$ be defined by $t \mapsto (\frac{1}{t}\cos(2\pi t),\frac{1}{t}\sin(2\pi t))$ . I'm able to show that it is an injective smooth immersion. Now, I'd like to show that it is a smooth embedding. To this regard, I have to show that $\gamma: (1,\infty) \to \gamma((1,\infty))$ is a homeomorphism. Well, I suppose that it is sufficient to show that the above map is open or closed. I have no clue. In fact, taking an open set $U$ of $(1,\infty)$ , how to describe its image? Or at least, how to see that its image contains an open set? However, in Guillemin & Pollack's book I found that it is sufficient to show that the map is proper, i.e. the preimage of compact sets is again a compact set. Hence I take a compact $K \subseteq \gamma((1,\infty))$ . Then $K$ is compact in $\mathbb{R}^2$ , so that it is closed and bounded. What about its preimages? It is quite difficult to work with the function $\gamma$ !","['differential-topology', 'differential-geometry']"
4858659,Expected waiting time for $n$ successive successful tasks,"Let's assume we have $n$ assignments $a_1$ , $a_2$ , $\cdots$ , $a_n$ . Each assignment $a_i$ can be done with probability $0<p_i<1$ in a time $t_i>0$ . But if you fail in the $i$ -th task ( $i < n$ ), then you have to begin from the start.
Thus, for the complete process to be consider a success, the last $n$ final tasks must be successful for the first time. For example, for $n=1$ , succeeding in the complete task in $k$ steps corresponds to failing $k-1$ times and then managing to do the task $t_1$ . Because the expected number of steps is $\frac{1}{p}$ and each of the failed tasks takes $\frac{t_1}{2}$ (using a uniform law), I think the expected time is: $$\left(\frac{1}{p_1}-1 \right) \cdot \frac{t_1}{2} +t_1 = \frac{t_1(1+p_1)}{2p_1}$$ My first attempt was to find the law of the waiting time and then calculate the expected value : $$\sum_{k=1}^{+\infty} \left(\frac{(k-1)t}{2}+t \right)(1-p)^{k-1}p = \frac{t(1+p)}{2p} $$ I wasn't able to find a formula for $n\geq 2$ .","['expected-value', 'statistics', 'probability']"
4858691,Primes satisfying $3^{d \cdot ord_p(2)+1} \equiv 2 \pmod{p}$ -- only 331?,"I'm looking for primes $p$ that satisfy the integer equation $3^{d \cdot ord_p(2)+1} \equiv 2 \pmod{p}$ am amazed that of the first 30k primes, only $p=331$ works (eg, with $d=4$ ): $3^{4 \cdot 30 + 1} \equiv 2 \pmod{331}$ Are there methods or tools for trying to show that $p=331$ is in fact the only solution (or not)? Or does the chaotic nature of $ord_p(2)$ make this hopeless? The equation is motivated by enforcing the coprimality of two periods, namely the period of $3^x-2^x \pmod{p}$ and the period of $2^k-1 \pmod{p}$ .","['number-theory', 'elementary-number-theory', 'prime-numbers']"
4858761,Explicit example of an algebraic surface of Kodaira dimension 1 that is not a product of two curves.,I already know that the product of an elliptic curve and any curve of genus greater that 2 will give rise to a surface of Kodaira dimension 1. Here is one strategy I have been suggested. Take a rational surface over the projective line that is a genus 1 fibration. For example the blow up of the base locus of a pencil of cubics. Then base change this to a curve of degree greater that 2 through a finite morphism. I am however unable to show that the resulting construction has Kodaira dimension 1 or that it is not the product of 2 curves.,"['algebraic-geometry', 'surfaces']"
4858776,Discrete math at the graduate level,"As a graduate student, I haven't delved deeply into several discrete math subjects such as combinatorics and graph theory. I have always felt that these areas often present a mishmash of techniques and problems, and I have not been able to construct a cohesive mental framework for appreciate these subjects. I'm keen to address this deficiency. I am seeking recommendations for resources that encompass various aspects of Combinatorics (including extremal and additive types), Graph theory (including algebraic approaches), Discrete probability, geometry, and related subjects in modern discrete mathematics. Ideally, I'm searching for the most effective method to grasp these subjects as a graduate student. I want to avoid books that merely skim the surface, spending excessive time on introductory material without delving into relevant techniques. Instead, I'm seeking resources that promptly introduce key techniques and concepts while providing comprehensive coverage of the subject matter. The hope of following this approach is that I can use these topics in my research as well. By following this approach, I hope I can increase my repertoire and perhaps even integrate these topics into my research endeavors as well. I would greatly appreciate any suggestions you may have.","['soft-question', 'book-recommendation', 'discrete-mathematics', 'reference-request']"
4858779,Normal block upper triangular matrix proof,"Prove that if a block upper triangular matrix is normal then its off-diagonal blocks is zero and each of its diagonal blocks is normal.
This question was asked before, but it got just one answer which contains a mistake(it does not take into consideration the order of multiplication of blocks). A complex square matrix $A$ is normal if it commutes with its conjugate transpose $A^*$ ( $A$ is normal $<=>$ $A^*A=AA^*$ ). So let’s say the matrix M is normal and it is block upper triangular, so it looks like this: $$M = \begin{pmatrix} A & B \\ 0 & C \end{pmatrix} $$ $$M^* = \begin{pmatrix} A^* & 0 \\ B^* & C^* \end{pmatrix} $$ We know that $A$ and $C$ are square, and we want to prove that $A$ and $C$ are normal, $B=0$ .
If $M$ is normal, doing the block-computations gives us four following equations 1) $AA^* + BB^* = A^*A$ ,
2) $A^*B=BA^*$ ,
3) $B^*A=CB^*$ ,
4) $C^*C+B^*B=CC^*$ . This is as far as I was able to get, have no idea how we can prove that $B=0$ from this.
For context, I have completed a year long course of linear algebra, so I would say I know all the basic characteristics of normal matrices, such as spectral theorem and also some facts about Gram matrix of columns of matrix M(that it is a Hermitian matrix for example) and so on.","['matrices', 'linear-algebra', 'block-matrices']"
4858795,How to compute $\displaystyle\lim_{n\to\infty} \frac1{n+1}\sum_{k=1}^n \left|X+\frac kn\right|-\left|X-\frac kn\right|$?,"I was just playing around with the real absolute value, trying to build something smooth (for no particular reason). After some experimentation I got to the sequence $(f_n)_n$ given by $$f_n(X) := \frac1{n+1}\sum_{k=1}^n \left|X+\frac kn\right|-\left|X-\frac kn\right|$$ This sequence got my attention for its graphs (in fact, I build it so its graphs would behave like this): I wonder how to compute $f(X) = \displaystyle\lim_{n\to\infty} f_n(X)$ . I haven't been able to solve this not even with the help of Wolfram Mathematica. Is $f$ really smooth? Of course, I'm only interested in values in $(-1, 1)$ for $X$ .","['limits', 'smooth-functions', 'absolute-value', 'real-analysis']"
4858815,Using Model-Theoretic Proof of Ax-Grothendieck for the Riemann Hypothesis,"A proof of Ax-Grothendieck utilizes model theory and the fact that the theorem is true for finite fields, and also algebraic closures of finite fields. See here . I have a (perhaps naive) question: considering that the Riemann hypothesis has been proved over finite fields, is it possible to utilize the approach to prove the Riemann hypothesis over $\mathbb{C}$ ? I'm guessing the answer is a sound ""no,"" otherwise it would've been done already.  Where does the argument fail? Is it in writing the Riemann hypothesis in first order logic, or something with the ideas?","['riemann-zeta', 'model-theory', 'algebraic-geometry', 'riemann-hypothesis']"
4858828,Why isn't the integral of the perimeter the area,"For a circle the perimeter is replaced with the circumference. And the area is the integral of the circumference, which makes sense $ C = 2\pi r $ $ A = \int dr C = \int dr 2\pi r = \frac{1}{2} 2 \pi r^2 = \pi r^2 $ However, if we try to do this for a square we get $ P = 4L $ $A = \int P dL  = \int dL (4L) = 4 \left( \frac{1}{2} L^2 \right) = 2L^2 $ Which is not the area of the square $A = L^2$ In fact it differs by a factor of 2. Why? It makes complete sense for the area to be the integral of the perimetre as it is the boundary and the integral of the boundary is the area but apparently it's not the case. What is the mathematical reason for this?","['integration', 'analytic-geometry', 'area', 'geometry', 'calculus']"
4858947,upper semicontinuous definitions,"I'm learning about upper (lower) semicontinuous and saw $3$ defintions for this: Definition 1: The function $f: A\subset\mathbb{R}^n\to\mathbb{R}$ is called upper semicontinuous(resp.: lower semicontinuous) at $x_0$ if $\forall\epsilon>0,\exists\delta>0$ s.t: $f(x)-f(x_0)<\epsilon$ ( resp.: $f(x)-f(x_0)>\epsilon)$ $\forall x\in B(x_0,\delta)$ ; $f$ is upper semicontinuous (resp.: lower semicontinuous) on $A$ if $f$ is upper semicontinuous (resp.:  lower semicontinuous) at every point in $A$ . Definition 2 a) $\forall a\in\mathbb{R}$ , the set $\{x\in A: f(x)<a\}$ is open in $A$ (resp.: $\{x\in A: f(x)>a\}$ is open in $A$ ). Definition 3 b) $\forall b\in\mathbb{R}$ , the set $\{x\in A: f(x)\geq b\}$ is closed in $A$ (resp.: $\{x\in A: f(x)\leq b\}$ is closed in $A$ ). I can see that def2 is equivalent to def3. But why def1 is equipvalent to def2 (or def3)? Could someone explain to help me understand better? Thanks in advance","['semicontinuous-functions', 'real-analysis', 'multivariable-calculus', 'calculus', 'general-topology']"
4858953,Distribution theory for random projections,"Suppose $v$ is a fixed vector in $\mathbb R^n$ , and let $u\in S^{n-1}$ (unit sphere in $n$ dimensions; $S^{n-1}=\{x\in\mathbb R^n:\|x\|=1\}$ ) be uniformly generated. What is the distribution of $\langle v, u\rangle u$ ? My hunch is that this is uniformly distributed on $D^{n}(\|v\|)$ , the disk on $n$ dimensions with radius $\|v\|$ . Here, $D^n(r)=\{x\in\mathbb R^n: \|x\|\leq r\}$ . I am not entirely sure how to address this though. How does this generalize for $\langle u_1, v\rangle u_1 + \langle u_2, v\rangle u_2$ ? Here $u_1,u_2$ are randomly picked orthonormal vectors. So, $\langle u_1, u_2\rangle =0$ . It would be great if there is a resource or reference for these kinds of distribution theories. EDIT: I think my conjecture was wrong. Suppose for simplicity $\|v\|=1$ . For $n=2$ , write $v=(\cos(\alpha),\sin(\alpha))$ and $u=(\cos(\theta),\sin(\theta))$ where $\theta\sim Unif(-\pi, \pi)$ and $\alpha$ is fixed. Then, $\langle u, v\rangle u=(\cos(\theta-\alpha)\cos(\theta), \cos(\theta-\alpha)\sin(\theta)$ . This doesn't seem to be uniformly distributed on $D^n$ (take $\alpha = 0$ ) but I am not sure.","['orthogonal-matrices', 'projection-matrices', 'linear-algebra', 'probability-theory']"
4858963,Integrating $\int_{-2}^{-1} \frac{\arctan(1-x)}{x}\mathrm dx$ [duplicate],"This question already has answers here : Evaluating $\int_1^2\frac{\arctan(x+1)}{x}\,dx$ (3 answers) Closed 5 months ago . As the title says, how do I evaluate $$\int_{-2}^{-1} \frac{\arctan(1-x)}{x}\mathrm dx$$ I tried u-sub, integration by parts and Feynman's trick, but they just not get me anywhere.
This is a 12th grade olympiad practice problem and because of the fact that the integral  is not elementary. I assume there should be some ""smart trick"" that I can't think of. Also, after integration by parts - by integrating $\frac{1}{x}$ and differentiating $\arctan(1-x)$ - it looks pretty similar to Serret’s integral. The value of the integral looks similar to the value of Serret’s integral too, so I wonder if there something to do with Serret’s integral.","['integration', 'definite-integrals', 'contest-math']"
4859000,Prove that $\lim_{x\to-\infty}\left(\psi(x)-\psi\left(\frac x2\right)-\frac1x-\ln 2\right)\sin(\pi x)=\pi$,"I was messing around on Desmos when I saw this interesting limit: $$\lim_{x\to-\infty}\left(\psi(x)-\psi\left(\frac x2\right)-\frac1x-\ln 2\right)\sin(\pi x)=\pi$$ This is of course what I think is the limit, but it seems to be true. Here $\psi$ denotes the digamma function. I do know that $$\lim_{x\rightarrow0}\left(\psi(x)-\psi\left(\frac x2\right)-\frac1x\right)=0$$ But I don't know how this can help. Also, removing the $\ln2$ term and replacing it with some constant $a\ne\ln2$ makes it [seem] non-convergent.","['limits', 'calculus', 'digamma-function']"
4859007,Feasibility of Meeting Patterns in Combinatorial Lunch Gatherings,"I encountered a problem in Applied Combinatorics as detailed here which presents an intriguing scenario: Over a 15-week semester, a graduate student has lunch in the campus food court every Tuesday, joined by various combinations of six friends. Throughout the semester, each friend joined him 11 times, each pair of friends joined him 9 times, each trio of friends 6 times, each quartet of friends 4 times, and each group of five friends 4 times. All seven individuals had lunch together once. Using the principle of inclusion-exclusion, we deduce that there are no weeks where the graduate student dines alone. However, I am curious about the practical possibility of this arrangement. Specifically, is it feasible to have 15 subsets $S_1, \dots, S_{15}$ of $[6]=\{1, 2, \dots, 6\}$ such that: Each singleton subset of $[6]$ is contained in 11 of the $S_i$ , Each pair subset of $[6]$ is contained in 9 of the $S_i$ , And so forth... Essentially, is the scenario as described possible, and are there sufficient or necessary conditions to validate its feasibility? Update: The correct answer to the problem should be the student ate alone once. But that's not what I am asking.","['inclusion-exclusion', 'combinatorics']"
4859159,How to find all $2 \times 2$ matrices whose $4^{\text{th}}$ power is the identity matrix but its lower powers are not?,"Question. To put the question in another way, let $G$ be the set of all invertible linear maps of $\mathbb{R}^2\to\mathbb{R}^2$ , and it is not hard to show that $G$ is a group under composition, and the question asks for those elements of $G$ which have order $4$ . My Attempt. First of all, I can show that every element of $G$ is equivalent to left-multiply by a $2 \times 2$ invertible matrix. Then, I was able to find elements of $G$ of order $2$ by brutal-force algebra. However, the brutal-force method becomes tedious to be used to tackle the given question. I know two elements of $G$ which have order $4$ , left-multiplying by a matrix which represents either a clockwise rotation of $90$ degrees or an anticlockwise rotation of $90$ degrees, but are they the only elements of order $4$ ? I have no clue how to proceed. Note. I am merely asking for a hint rather than a solution. Thank you!",['matrices']
4859168,Supremum of average of i.i.d. stochastic processes,"Suppose that $(X_t)_{t\in [0, T]}$ is a stationary stochastic process with continuous sample paths such that $\mathbb E[X_t] = 0$ and $\mathbb E[|X_t|^2] < \infty$ , and assume that $$
S := \mathbb E \left[ \sup_{t \in [0, T]} |X_t|\right] < \infty.
$$ Take $J$ independent copies $(X^1_t), \dotsc, (X^J_t)$ of the process $(X_t)$ . Does it hold that $$
\mathbb E \left[\sup_{t \in [0, T]} \left| \frac{1}{J} \sum_{j=1}^JX^j_t \right| \right] \leq \frac{S}{\sqrt{J}} \, ?
$$ possibly up to a constant on the right-hand side. In other words, does the left-hand side decrease at the usual Monte Carlo rate? Particular case. If $X_t$ is a Gaussian process, then the answer is yes, and both sides are in fact equal. Indeed, it holds in this case that $$
\frac{1}{\sqrt{J}} \sum_{j=1}^J X^j = X \qquad \text{in law as stochastic processes,}
$$ because both sides are Gaussian processes with the same mean and covariance functions. Can we say something on the case of a general mean-zero stationary stochastic process $X$ ? Possible idea: The result could perhaps be proved by using a central limit theorem for function-valued random variables. Indeed it seems possible that $$
\frac{1}{\sqrt{J}} \sum_{j=1}^{J} X^j \to Z \qquad \text{in some appropriate weak sense},
$$ where $Z$ is a stationary Gaussian process with mean 0 and covariance variance $$
k(s) = \mathbb E[Z_0 Z_s] = \mathbb E [X_0 X_s].
$$ This seems to be the content of this paper . However, even assuming that a central limit theorem holds, I do not see how a conclusion could be reached, as the supremum is not a bounded function, and uniform integrability seems hard to prove.","['stochastic-processes', 'probability-theory']"
4859231,"Let $n\equiv 1\pmod 8$. Do there exist $x,y,z\in\mathbb{Z}$ with $x\equiv \pm3\pmod 8$ and $x^2+4y^2+4z^2=n$?","Let me preface this by saying I know very little about quadratic forms and most of what I know is about quadratic forms in two variables, whilst this question is about a quadratic form in three variables. Let $n\ge 1$ ( Actually, $n> 1$ , to make it interesting, see the edit ) be a positive integer, $n\equiv 1\pmod 8$ . Then there exist $x,y,z\in\mathbb{Z}$ $$
n = x^2 + 4y^2+4z^2.
$$ Question: Can we always find such $(x,y,z)$ with $x\equiv \pm 3\pmod 8$ ? My attempt: Suppose $n\equiv 9\pmod{16}$ and $n$ is represented over the integers by $u^2+16v^2+16w^2$ . Then we can take $(x,y,z)=(u,2v,2w)$ . Now, according to this , the form $u^2+16v^2+16w^2$ is regular, which I believe means such a representation of $n$ does indeed exist. For $n\equiv 1\pmod{16}$ , the existence of a representation with $x\equiv \pm 3\pmod{8}$ is equivalent to $n$ being represented over the integers by $$
u^2 + (4v+2u)^2 + (4w+2u)^2 = 9u^2+16v^2+16w^2+16uv+16uw.
$$ However, I know basically nothing about this quadratic form. Its discriminant is $256$ and does not show up in the aforementioned list of regular forms. Any pointers in the right direction are appreciated. Edit (added after ThibautOphelia's answer): There is no such solution when $n=1$ , but I'm mainly interested in the case $n>1$ .","['number-theory', 'quadratic-forms']"
4859265,Random Walk Problem in Feller Probability Theory vol 2 Chapter XII page 425,"Let $X_{i}$ be iid discrete random variable with distribution $P(X_{1}=-1)=q$ and $P(X_{1}=i)=f_{i}$ for all $i\geq 0$ . Then consider the random walk $S_{n}=\sum_{i=1}^{n}X_{i}$ and $S_{0}=0$ . Let $\lambda_{r}$ be the probability that the probability that the first positive term of the sequence $S_{1},S_2,...$ assumes the value $r$ . In otherwords, $\lambda_{r}$ is the probability that the first ladder height takes the value $r$ . Now, problem $3$ asks us to show the following reccurence, $$\lambda_{r}=f_{r}+q(\lambda_{r+1}+\lambda_{1}\lambda_{r})$$ And problem $4$ asks us in the above setting, if $\gamma_{r}$ denotes the probability that the first non-negative term of $S_1, S_2,. . .$ assumes the value $r$ , then we have the following recurrence, $$\gamma_{r}=f_{r}+\frac{q}{1-\gamma_{0}}\cdot\gamma_{r+1}$$ My attempt: For the problem $3$ ,  let $A_{r}$ be the event that the first positive term of the sequence $S_{1},S_{2},...$ assumes the value $r$ and I write in the following way: $\lambda_{r}=P(X_{1}=r)+P(X_{1}=-1,A_{r})$ . Now after hitting $-1$ , for $A_{r}$ to occur the random walk restarted at $-1$ can be such that the first value strictly above $-1$ it hits is either $r+1$ OR we have that the first value strictly above $-1$ is $1$ , in which case, we return to $0$ and then we restart the walk and hit level $r$ . The above is written in words so that I don't get lost in notations. Hence by the Strong Markov Property, I can write the above in the form as $$P(X_{1}=-1,A_{r})= q\lambda_{r+1}+q\lambda_{1}\lambda_{r}$$ which proves the relation for $\lambda_{r}$ . Now for the problem $4$ , I can argue that after $X_{1}=-1$ , the restarted random walk can either hit the level $r+1$ above $-1$ or it can hit the level $0$ above $-1$ and again we restart at $-1$ . So I think we'll get a geometric progression that we after reaching the level $0$ above $-1$ , $k$ times, we hit level $r+1$ and this $k$ can be any non negative integer. So I think we should get the following relation, $$\gamma_{r}=f_{r}+q(\gamma_{r+1}+\gamma_{0}\gamma_{r+1}+\gamma_{0}^{2}\gamma_{r+1}+...)=f_{r}+\frac{q\gamma_{r+1}}{1-\gamma_{0}}$$ Question: Is my thinking above correct or am I missing some details? If yes, then can someone tell me how to write this up with full rigour as I am struggling a lot to actually come up with the justifications or writing out the reasoning using the law of total probability. To sum up, I think what I did above is correct and I would appreciate it if someone can write out the wordy justification I gave in terms of ""measurable"" events and give me an expression using the law of total probability.","['random-walk', 'markov-chains', 'solution-verification', 'probability-theory', 'probability']"
4859287,What does this series converge to? $\sum_{n=0}^\infty \beta(4n+1)-\beta(4n+3)$,"I was investigating patterns in sums of Dirichlet beta function and I found out that if $$a_n=\beta(4n+1)-\beta(4n+3) $$ then the associated series seems to approach a number: $$\sum_{n=0}^\infty a_n=\beta(1)-\beta(3)+\beta(5)-\beta(7)+\beta(9)-\beta(11)+\dots=-0.18698991\dots $$ So my question is: what is the value of this series? I tried to use the integral representation of $\beta$ : $$\beta(s)=\frac{1}{\Gamma(s)}\int_0^\infty\frac{x^{s-1}e^{-x}}{1+e^{-2x}}dx $$ but then I couldn't interchange the sum and integral, since this would change the result. EDIT As @KStarGamer and @ClaudeLeibovici pointed out, result seems to be $$\sum_{n=0}^\infty a_n\stackrel{(?)}=\frac{\pi}{4}\text{sech}\left(\frac{\pi}{2}\right)-\frac12 $$ Now the question is: how to prove it?","['integration', 'real-analysis', 'calculus', 'sequences-and-series', 'limits']"
4859314,What category is this? (Objects are sets and distinguished subsets of power set),"Let $\mathcal{C}$ be the category whose objects are sets $X$ equipped with distinguished subsets of the associated power set $\mathcal{U}_X \subset \mathcal{P}(X)$ , so that their union is all of $X$ (i.e. $\bigcup\limits_{U \in \mathcal{U}_X} U = X$ ). morphisms $(X, \mathcal{U}_X) \xrightarrow{f} (Y, \mathcal{U}_Y)$ are set functions $f: X \to Y$ so that for each element $V \in \mathcal{U}_Y$ the inverse image under $f$ is in $\mathcal{U}_X$ (i.e. $f^*: \mathcal{U}_Y \to \mathcal{U}_X$ is a function) We know that the categories $Top$ of topological spaces and continuous functions as well as $Meas$ of sets with sigma algebras and measurable functions between them are full sub categories of this category. Is there a common name for $\mathcal{C}$ ?","['general-topology', 'category-theory', 'measure-theory', 'terminology']"
4859317,Differentiating a function with respect to another,"Motivation: in a computer science book, there are two $\mathbb{R}^d\to\mathbb{R}$ functions $f$ and $g$ related by $$f(\textbf{x}) = x_kA\left(g(\textbf{x})\right)+ B(\textbf{x})$$ for functions $A:\mathbb{R}\to\mathbb{R}$ and $B:\mathbb{R}^d\to\mathbb{R}$ . The author casually writes $$\frac{\partial f}{\partial g}(\textbf{x}) = x_kA'\left(g(\textbf{x})\right)$$ and, while I understand the intuition, I'm struggling to formally and generally define $\partial f/\partial g$ . The question: given two $\mathbb{R}^d\to\mathbb{R}$ functions $f$ and $g$ , when and how are we to define $$\frac{\partial f}{\partial g}?$$ My attempts: here are two definitions that have failed so far: Definition $1$ : we say $f$ is differentiable with respect to $g$ if there is a function $\phi$ such that $$f = \phi\circ g$$ in which case we define $$\frac{\partial f}{\partial g}(\textbf{x}) = \phi'(g(\textbf{x})).$$ The issue here is that such $\phi$ (almost) never exists. Furthermore, the original relation in the book does not follow this form. We need something more general. Definition $2$ : we say $f$ is differentiable with respect to $g$ iff there is a function $\phi$ such that $$f(\textbf{x}) = \phi\left(g(\textbf{x}),\textbf{x}\right)$$ for any $\textbf{x}\in\mathbb{R}^d$ , in which case we define $$\frac{\partial f}{\partial g}(\textbf{x}) = \frac{\partial \phi}{x^0}(g(\textbf{x}),\textbf{x})$$ in coordinates $\phi(x^0,x^1\ldots,x^d) = \phi(x^0,\textbf{x})$ . Letting $\phi : (x^0,\textbf{x})\mapsto x_kA(x^0)+B(\textbf{x})$ we find that the example at the beginning is covered by this definition. The issue now has to do with the domain of $\phi$ ; I did not specify it in the definition because I do not know what its domain should be. If we set the domain of $\phi$ as $$\bigg\{(g(\textbf{x}),\textbf{x}) : \textbf{x}\in\mathbb{R}^d\bigg\}$$ then it is often so small that it does not allow us to differentiate: if $g$ is given by $(x,y)\mapsto x$ , we'd ideally wish for $$\frac{\partial f}{\partial g} = \frac{\partial f}{\partial x},$$ but in such case $\text{dom}(\phi)$ is $$\bigg\{ (t,x,y) : t = x\bigg\},$$ which does not allow us to differentiate. On the other hand, if we require the domain of $\phi$ to be $\mathbb{R}^{d+1}$ , then the derivative is no longer unique: simply let $f,g:\mathbb{R}\to\mathbb{R}$ be the identity. Then both $$\phi:(t,x) \mapsto x
\ \ \ \ \text{ and }
\psi:(t,x) \mapsto t$$ comply with the property $$x = \phi(x,x) = \psi(x,x),$$ yet $$0 = \frac{\partial\phi}{\partial x^0} \neq 
\frac{\partial\psi}{\partial x^0} = 1.$$","['real-analysis', 'multivariable-calculus', 'calculus', 'definition', 'partial-derivative']"
4859353,find ${dy}/{dx}$ of $x\sqrt{1+y} + y\sqrt{1+x} = 0$,"Question My approach I tried by applying basic product rule, but could not proceed further; don't know how to eliminate the y factors in the solution. How to prove it?","['calculus', 'derivatives']"
4859366,"In the plane, if every boundary of a unit circle center at a blue point contain exactly 10 red points can there be more blue points than red points?","There are finitely many points in the plane which is colored red and blue  , for every blue point $x$ we always have |{ $y: |x-y| = 1, y$ is red}| = 10. Can there be more blue points than red points? I have struggled this problem for quite a while but only figure out: 1: Let $A_c$ be the red points lie on the circle $(c, 1)$ then $|A_i \cap A_j| \le 2$ and $|A_i \cap A_j \cap A_k| \le 1$ for every blue points $i, j, k$ but it does not solve the problem because there are configuration such that $|A_i| = 10, |A_i\cap A_j| \le 1$ and there are more sets than elements. We need more geometric properties from circles to solve in this way 2: if we change from ""exactly 10"" to ""at least 10"" then the answer is YES. the configuration is blue points are { $(x/M, y/M): 1\le x,y \le N, x+y$ is odd} and red points are { $(x/M, y/M): 1\le x,y \le N, x+y$ is even} for some large odd integer $N$ and an appropriated integer $M$","['combinatorics', 'geometry']"
4859454,Example of smooth compactly supported function,"Is there an easy example of a smooth compactly supported function (ie. a test function) that equals $e^x$ on the interval $[-1,1]$ ? This is in reference to the following stack exchange question here , where they describe a nice procedure but don't give an explicit example of such a function. I've been trying to construct one and it does not seem obvious at all.
Is there something more explicit to know it's existence?","['smooth-functions', 'analysis']"
4859493,Probability of flips n to 2n-1 being all tails?,"Let us perform infinitely many fair coin flips and write them down. I want to find the probability of the event in which there exists $n \ge 2$ where the $n$ th, $(n+1)$ th, …, $(2n-1)$ th flips are all tails. I am not sure if there exists some closed form of this. I wrote code to approximate this probability (with a lower bound) with the first $2i-1$ flips, up to $i=20$ : use rayon::prelude::*;

fn flip_n(n: usize) -> (usize, usize) {
    let total_count = 1 << (2 * n - 1);
    let success_count = (0..total_count)
        .into_par_iter()
        .filter(|&sequence| {
            (2..=n).any(|n| {
                let end_index = 2 * n - 1;
                let mask = (1 << end_index) - (1 << (n - 1));
                sequence & mask == mask
            })
        })
        .count();

    (success_count, total_count)
}

fn main() {
    for i in 2..=20 {
        let (success_count, total_count) = flip_n(i);
        println!(
            ""{} / {} ≈ {:.7}"",
            success_count,
            total_count,
            success_count as f64 / total_count as f64
        );
    }
} And I got this output: 2 / 8 ≈ 0.2500000
10 / 32 ≈ 0.3125000
44 / 128 ≈ 0.3437500
182 / 512 ≈ 0.3554688
740 / 2048 ≈ 0.3613281
2982 / 8192 ≈ 0.3640137
11972 / 32768 ≈ 0.3653564
47972 / 131072 ≈ 0.3659973
192056 / 524288 ≈ 0.3663177
768554 / 2097152 ≈ 0.3664751
3074876 / 8388608 ≈ 0.3665538
12300812 / 33554432 ≈ 0.3665928
49205864 / 134217728 ≈ 0.3666123
196828666 / 536870912 ≈ 0.3666220
787325084 / 2147483648 ≈ 0.3666268
3149321132 / 8589934592 ≈ 0.3666292
12597326120 / 34359738368 ≈ 0.3666304
50389387580 / 137438953472 ≈ 0.3666310
201557716520 / 549755813888 ≈ 0.3666314 The difference between consecutive lower bounds here has a rather interesting pattern which makes me think that there might be some exact solution for infinite flips, but I have not succeeded in finding such a solution. Any help would be appreciated!","['combinatorics', 'probability']"
4859534,When is isometry space of compact metric space a manifold?,"Supposse we have a compact metric space $(X, d)$ . Let $(\text{Iso}(X, d), D)$ be a metric space of all isometries $f : X \rightarrow X$ with a metric $D$ defined with: $$D(f, g) = \text{sup}\{d(f(x), g(x)) \mid x \in X\}.$$ Im interested in the following question. When is this space $(\text{Iso}(X, d), D)$ a manifold ( https://en.wikipedia.org/wiki/Manifold )?
In particular, what are some conditions metric space $X$ can satisfy so we can conclude $\text{Iso}(X, d)$ is a manifold? I was able to find this post Isometries of Riemannian manifold . Here it says that if $X$ is a Riemannian manifold than group of isometries is a Lie group which implies it is a manifold. Altough Im not sure that this implies space of isometries with metric $D$ defined above is a manifold.","['manifolds', 'general-topology', 'isometry', 'metric-spaces']"
4859542,Poisson's distribution for probability,"This question is more for learning purposes than anything however I came across this while trying to solving the following problem: The odds of winning the lottery are 1 to 50000 million. This week, 50 million
tickets are sold for the latest drawing. What is the probability that at least one
winning ticket was sold? A friend of mine told me this had something to with Poisson's distribution. What is it exactly about Poisson's distribution that allows you to solve this problem? From my own research the formula for Poisson's distribution is $$P(X=x)=\frac{\lambda^xe^{-\lambda}}{x!}$$ where $x$ is a discrete variable representing the number of occurences of an event and $\lambda$ is the mean number of occurences of the event. Based on this, I'm assuming the 1 in 50000 million is just supposed to represent any arbitrarily small number and is $\lambda$ equal to this probability however I don't really understand the concept well enough to apply it. Can someone explain Poisson's distribution in general and in the context of this problem?","['contest-math', 'poisson-distribution', 'recreational-mathematics', 'probability-theory', 'probability']"
4859567,Need Some Hints on How to Simplify Further for Set Question,"I am given $(A ∪ (B − C)) ∪ (C − (A ∩ B))$ I used De Morgans Law and the Distributive Law, but I ran into a roadblock where I could not simplify any further. I got to: $((A ∪ B) ∩ (A ∪ C')) ∪ ((C ∩ A') ∪ (C ∩ B'))$ Any tips on how to proceed? I did draw a Venn diagram and got a rough idea of what I should be headed towards, but I don't see a way how to get there.","['elementary-set-theory', 'discrete-mathematics']"
4859597,Can real integrals that are computed using complex contour integration depend on the choice of contour?,"I am studying the following integral: $$\int_{-\infty}^\infty \frac{1}{2\pi i} \frac{-e^{-ix(a-b)}}{x^2 - c^2} dx$$ where $a, b, c > 0$ are real constants. The integrand has poles along the real axis when viewed as a complex function. My approach to solving this integral was to create a contour with two semicircles of radius $\epsilon$ and close the contour by creating a big semicircle. In other words, we would have a contour like the one in the figure below: but instead of having a semicircle cutout near the origin there would be two at $\pm c$ . One can then use the residue theorem. I made a post about this integral on physics SE: https://physics.stackexchange.com/q/800770/288281 . In that post I was surprised to find out that the choice of contour does matter and will give different answers, in contrast to something like $$\int_{-\infty}^\infty \frac{\sin(x)}{x}dx$$ which does not depend on the choice of contour. This is briefly discussed in this question: When does the value of a complex contour integral depend on the choice of the contour of integration? . I have two questions: When does the value of an integral over the real line, when computed using complex contour integration, depend on the choice of contour and why? The approach used to solve this integral in physics textbooks is also to use the residue theorem, but they first push the poles slightly above or below the real axis and then take a limit. So the integral becomes $$\lim_{\epsilon \rightarrow 0} \int_{-\infty}^\infty \frac{1}{2\pi i} \frac{-e^{-ix(a-b)}}{x^2 - c^2 + i\epsilon} dx.$$ Why is it necessary to push the poles above/below the real axis? What is wrong with the contour approach I described above which keeps the poles on the real axis? Is this because the integral is not well defined?","['integration', 'complex-analysis', 'contour-integration', 'residue-calculus']"
4859601,Calculate the speed of the slowest flying machine in Minecraft with probabilities,"In Minecraft (sandbox video game made of blocks,written in Java), I have recently created a flying machine (assemble of blocks which moves on its own) and I have trouble calculating its speed, I hope someone can help me. Topic : probabilities Context [vocab and general context]: Minecraft runs on a clock, steping 20 times per second. There are 20 'game ticks' (gt for short) in a second , 72 000 gt per hour.
Thunderstorm is a weather in the game and only during this weather, lightning bolts can appear. A chunk is a 16 wide *16 long *256 high piece of the world. The duration of thunderstorms is between 3 600 and 15 600 gt (3 mins to 13 mins) with a pseudorandom uniform distribution [for details it is drawn with java.util.Random.nextInt(int bound = 12000)+3600 ] The duration of 'clear' weather ( time between thunderstorms ) is similarly drawn but with bound of 168000 and added 12000 making it from 12 000 to 180 000 gt .
It is assumed that the player don't sleep(=drawn time is the actual time between thunders). During (only) thunder weather, there is a 1/(100 000) chance per gt of a lightning bolt occuring in a chunk.
A lighting bolt position in a chunk is randomly selected using a LCG (linear congruential generator) [with parameters $a=3,c=1013904223$ and $m=2^{32}$ for formula $X_{n+1} = (a*X_n + c) \mod m$ ] and can (I think) be associated with a uniform distribution for the coordinates of the position along the two horizontal axis [given basically by ((LCG >> 2) & 15) for one axis and ((LCG >> 2) >> 8 ) & 15 ] and the vertical coordinate is given by the block at the highest position (top-most block vertically). There is then a $\dfrac{1}{100\, 000} * \dfrac{1}{16*16} = \dfrac{1}{25\, 600\, 000} $ chance per gt of a lighting bolt hitting a block (my block is placed to be the highest in its column of blocks) when it is thundering. [these probabilities are independant, therefore multiply them to get the proba of both happening, the target block can only be in 1 chunk at a time] My flying machine need, to progress 1 block forward, 1 lighting bolt hit on 1 block [a piston that reacts to the lightning bolt] and to move 2 blocks forward, it requires 2 lightning bolts, spaced in time by 9 gt and the second lightning bolt (bolt for short) needs to happen at a different coordinate than the previous one (1 block offset in a horizontal direction). The targeted block may have moved to a different chunk (I don't think it changes the results). If the second bolt did not happen at the right place/time, then the flying machine flies back in the other direction with a speed of 10gt per block (as opposed to the 9gt per block of the +X movement).
We have these two 'forces' opposing : the random lightning bolts pushing the flying machine forward (let's say in the +X direction) while another circuit pushes the flying machine backwards (-X direction) if bolts are not received at the right time and place. Problem Based on the context, you probably think that the flying machine mostly goes in the -X direction seeing how rare thunderstorms and lightning bolts are (its true !), the problem formulates as follows : What is the probability that this machine travels 30 M(million) blocks in the +X direction ? Resolution attemp : We'll start by seeing a few usefull observations then formulate more clearly then I will describe my attempt. Observations The flying machine is faster in the +X direction (9gt per block) than in the -X direction (10gt per block). There is a lot more time on average where it is not thundering as the average off thunder (no thunderstorms) is 96 000 gt (consecutive)(80 mins) while the average thunderstorm duration is only 9 600 gt(consecutive)(8 mins). The maximum distance traveled during a thunderstorm (+X direction) (15 600gt) is $\frac{15600 }{9} = \frac{5200}{3} \approx 1\, 733.\overline{3}$ blocks while the minimum distance traveled during clear weather (-X direction(dir for short)) is $\frac{12000 }{10} = 1200$ blocks which is less than the maximum +X dir distance, with a maximum overall forward distance of $\frac{5200}{3}-1200=\frac{1600}{3} \approx 533.\overline{3}$ blocks ==> it is possible to overall go forward. For the maximum thunderstorm duration, the given clear weather duration that moves the same distance (but opposite direction) is $\frac{15600 }{9}*10 = \frac{52000}{3} \approx 17333.\overline{3}$ gt (which is an integer in reality).
This means that any clear weather duration over this number will result in a total (during a cycle thunder, no thunder) distance in the -X direction no matter the thunderstorm duration. Oppositely, for the maximum clear weather duration, the maximum number of blocks progressed in the -X direction is $\frac{180 000}{10} = 18 \,000$ blocks as, even during a thunderstorm, it is not garanted to go forward at all (no lightning bolts) Mathematical formulation A parameter $F$ (forward) is given initialy by a random uniform distribution (integers) $U(3\, 600,15 \, 600)$ A parameter $B$ (backward) is given initialy  by a random uniform distribution (integers) $U(12\, 000,180 \, 000)$ A parameter $L$ (lightning bolt) is given by a descrete probability $p_L = \dfrac{1}{25\, 600 \, 000}$ A parameter $T$ (thundering) that is true or false (1 or 0) that says when it is thundering A parameter $x_n$ (position from the origin ( $x_0=0$ )) of the flying machine with conditions that $x_n>0,\forall n \in \mathbb{N}$ The pseudo algorithm of the process is described here When T switches from 0 to 1 : draw F
When T switches from 1 to 0 : draw B

If T is 1: (thunderstorm)
    cycle F number of times:
        if cooldown is 0: 
             draw L (lightning bolt occur ?)
        otherwise :
             subtract 1 from cooldown
        if L is 1 (success):
            cooldown is set to 9 gt
            x_n is increased by 1
            L is to 0
        if cooldown is -1 :
            x_n is decreased by 1
            cooldown is set to 10
    set T to 0 once cycle is finished
if T is 0 : (clear weather)
    x_n is decreased by min(x_n,B/10)
    (min to not become negative
    set T to 1 The goal is to calculate the time taken on average for x_n to reach 30 000 000. My resolution attempt I tried to bound the minimum time : from the previous observations, we can travel forward (+X dir) as maximum of 533 blocks every thunder and clear weather cycle, so every 27 600 gt.
This gives us the shortest time possible with perfect luck of $ \frac{27600}{533}\times 30\, 000 \, 000 = 1 553 470 920$ gt (59.1 years (fast!)) Then I tried to estimate it using gambler's ruin but am not sure at all if I used it corectly.
There are 6 480 000 couples (thunder, clear) with a positive amount of ticks (thunder gt-clear gt) out of the 2 016 000 000 couples possible, giving a probability of 0.32142857 % to have a couple with more thunder gt than clear gt. Doing the sum of the values of all the couples (thunder gt-clear gt) gives a value of 7 782 481 200, which I after multiplied it by probability of it beeing positive to give the overal expected value of positive couples : $p =25\, 015\, 118$ . then using this formula I found online, we can calculate the expected nb of gt to have to wait to have 9*30M gt : $ p+ \dfrac{\left(p\right)^{9*30*10^6-1}-1}{p-1}$ Which gives a result of around $10^{(10^{9.3})}$ That is the expected time to wait before the thunder/clear weather cycle give the right conditions to reach the goal with perfect lighting bolts luck. To take into account I use the same formula but swapping the $p$ for the $1/p_L$ (average time between good lighting bolts and with the time calculated above, giving the formula $ \dfrac{1}{p_L}+ \dfrac{\left(\dfrac{1}{p_L}\right)^{10^{(10^{9.3})}-1}-1}{\dfrac{1}{p_L}-1}$ Which gives a result of (around) $10^{(10^{(10^{(9.3)})})}$ gt Which is very slow ! Conclusion I am really not sure about these calculations and would like if anyone could guide me to find the speed of this machine. It is expected to take a lot longer than $7*10^{9*10^7}$ but the upper bound has no estimate.
I would gladly answer any questions about details or general questions to help resolve this problem. Thank you for reading !",['probability']
4859625,Is $357911$ the only perfect power that is obtained by concatenating $5$ or more consecutive odd numbers(in decimal)?,"Is $357911$ the only perfect power that is obtained by concatenating $5$ or more consecutive odd numbers(in decimal)? I noticed that while memorizing all perfect cubes from $1$ to $10^{6}$ , $357911=71^{3}$ is a perfect cube that is obtained by concatenating $5$ consecutive odd numbers(namely $3, 5, 7, 9,$ and $11$ ). But is $357911$ the only perfect power is  obtained by concatenating $5$ or more consecutive odd numbers? I know these things: If a odd number is a perfect square, then the number must be $1\pmod{8}$ , so if we want to make a perfect square that is obtained by concatenating $n$ odd numbers, then the number must be (either) form of $40k+1$ or $40k+9$ . If we want our number that we concatenated to be a perfect 5th power, then the last two digits must either one of these: $01, 07, 25, 43, 49, 51, 57, 75, 93, 99$ . I have no idea for other perfect odd prime powers.","['number-theory', 'square-numbers', 'sequences-and-series', 'recreational-mathematics', 'perfect-powers']"
4859647,Question about proof of general formula for $\sin^n \theta$,I was reading the wikipedia page about list of trigonometric identites and came across the following identities for $$\cos^n \theta $$ when n is odd:- $$\cos^n \theta = \frac{2}{2^n}\sum_{k=0}^{\frac{n-1}{2}} {n\choose k}\cos ((n-2k)\theta)$$ for $$\cos^n \theta $$ when n is even:- $$\cos^n \theta = \frac{1}{2^n}{n\choose \frac{n}{2}} + \frac{2}{2^n}\sum_{k=0}^{\frac{n}{2} - 1}{n\choose k}\cos((n-2k)\theta)$$ I tried to prove it using the binomial theorem expansion of $(\cos \theta + i \cdot \sin \theta)^n$ and isolating the $\cos^n \theta$ term however i do not understand how to proceed any help would be appreciated,['trigonometry']
4859670,Why am I getting a finite integral for infinite area?,"The following is the graph of the $\tan(x)$ function: We can clearly see there how it’s undefined at $\frac \pi 2$ . Now, what if we wanted to find the area between the tangent function and the x-axis  in the interval $[0, 2]$ ? The following happens: $$\int \tan(x) dx = -\ln|\sec(x)| + c, \quad c\in\mathbb{R}$$ $$\implies \int_{0}^{2} \tan(x) = (-\ln|\sec(2)|) - (-\ln|\sec(0)|)$$ $$\implies (-\ln|\sec(2)|) - (-\ln(1)) = (-\ln|\sec(2)|) + \ln(1)$$ $$ |\sec(2)| = 2.40299796…$$ So what we end up getting is something in the form $$\int_{0}^{2} \tan(x) dx = -\ln(2.40299..) + \ln(1)$$ Which ends up giving us $$-0.87671710853 + 0$$ Which is definitely a finite value! However, when you look at the above graph, you clearly see that there should be infinite area there, as the tangent is asymptotic one unit before there. What’s going on here?","['integration', 'calculus', 'trigonometric-integrals']"
4859686,Abelian Groups and Z(G),"We know that if we have a group G such that G/Z(G) is cyclic this implies that G is abelian Let’s take an example: If we have |G/Z(G)|=7 which is prime then it is cyclic which would imply that G is abelian However, G is abelian if and only if G=Z(G) In the above example we don’t have G=Z(G) since otherwise |G/Z(G)|=1 So does that mean that G/Z(G) can’t be cyclic unless it is the trivial group?","['group-theory', 'abelian-groups']"
4859693,Intersection of two ellipses at exactly 2 points,"Thanks for your time. Let us consider the ellipses as $x^TAx=k$ and $x^TBx=l$ . We can assume that we know $A$ and $B$ . Suppose if we give one value to $k$ , then we can adjust $l$ such that one ellipse will lie entirely inside the other ellipse and touch exactly at two points. I was wondering if there is any analytical way to obtain the solutions $(x,k,l)$ for this system. If not, how to numerically solve this? Any help much appreciated!","['numerical-linear-algebra', 'numerical-methods', 'geometry', 'ellipsoids']"
4859712,Specifying a line equation with respect to 2 another perpendicular line equations.,"Suppose that we have 2 line equations, call $L$ , $D$ , where $$L: \frac{x-a}{u}= \frac{y-b}{v}= \frac{z-c}{w}$$ $$D: \frac{x-a}{m}= \frac{y-b}{n}= \frac{z-c}{p}$$ and let $L\perp D$ . Moreover, suppose that $\alpha,\beta$ are given, where $\alpha + \beta \geq \frac{\pi}{2}$ .
I need to find a line equation, call $K$ , in the 3D space in such a way that the angle between $K$ and $L$ becomes $\alpha$ and the angle between $K$ and $D$ becomes $\beta$ .
I know that to achieve such a line or lines we must find the intersection between 2 cones, where the central axis of the first cone is line $L$ , with half-angle $\alpha$ and the central axis of the second is the line $D$ , with half-angle $\beta$ . However, I don't know how to get through this process.","['analytic-geometry', 'geometry', 'calculus', 'linear-algebra', 'trigonometry']"
4859715,Is this a correct definition for generating set of a group?,"The Wikipedia article doesn't define the criteria for a generating set for a group in terms of logical propositions, so here's my attempt at it. It seems from ( Why do generating sets need not contain the inverses of their elements? ) and the Wikipedia article that the generating set doesn't need its inverses, so I tried to take that into account for the definition. One other thing: It's a bit slippery to define the construction method, so we'll make a custom function $(\ggg )$ that makes this definition easier to write formally. Have a group $\mathfrak G = \big( G , * \big)$ . Where $\left(G \times G \xrightarrow{\quad  * \quad} G \right)$ . For convenience, define a function $\ggg$ such that $$\ggg(A) = *(A \times A) $$ where $A$ is any set we want. A generating set of $\mathfrak G$ is a set $F = \{f_i \} $ such that $$g \in G \iff g \in (\ggg)^N \big(\{ f_i\} \cup \{ f_i^{-1}\} \big) $$ For some $N \in \mathbb N$ Would this be correct?","['elementary-set-theory', 'group-theory', 'abstract-algebra', 'combinatorial-group-theory']"
4859726,Evaluate: $\int_{-2}^{2} \frac{x^2}{1+5^{x}} dx$,"Evaluate: $$\int_{-2}^{2} \frac{x^2}{1+5^{x}} dx$$ After checking f(-x) for odd/even function and not getting suitable results. Let $$1+5^x=t$$ $$dx=\frac{dt}{log(5)(t-1)}$$ $$x^2=\frac{(t-1)^2}{(log(5))^2}$$ Limits changed from $[-2,2]$ to $[\frac{26}{25},26]$ $$\int_{\frac{26}{25}}^{26} \frac{(t-1)^2}{[(log(5))^2(t)(log(5)(t-1)]} dt$$ $$\frac{1}{(log(5))^3}\int_{\frac{26}{25}}^{26} \frac{t-1}{t} dt$$ This gave me some abomination that wasn't the answer I required which is 8/3. I now also know the intended solution as mentioned below: Let $$I=\int_{-2}^{2} \frac{x^2}{1+5^{x}} dx$$ Using Identity of f(a+b-x) from definite integrals: $$I=\int_{-2}^{2} \frac{(2-2-x)^2}{1+5^{(2-2-x)}} dx$$ $$I=\int_{-2}^{2} \frac{x^2}{1+5^{(-x)}} dx$$ $$I=\int_{-2}^{2} \frac{(5^x)x^2}{1+5^{x}} dx$$ $$2I=\int_{-2}^{2} \frac{x^2}{1+5^{x}}+\frac{(5^x)x^2}{1+5^{x}} dx$$ $$2I=\int_{-2}^{2} x^2 dx$$ $$I=\frac{1}{6}.[2^3-(-2^3)]=\frac{8}{3}$$ So why didn't my first approach work?","['integration', 'definite-integrals', 'logarithms', 'calculus', 'derivatives']"
4859727,Some doubtful implication for mathematical analysis.,"Let, $f(x),g(x),f_1(x),g_1(x)$ are positive real valued bounded and continuous functions on domain of non-negative reals and also having range between $0$ and $1$ . And, also, $f_1(x),g_1(x)$ are decreasing function. Now, if $\sup(f(x))\ge\sup(g(x))$ with $f_1(x)\ge g_1(x)$ then is it true that $\sup(f(x)f_1(x))\ge\sup(g(x)g_1(x))$ ? If, $f_1(x),g_1(x)$ are constant functions, then above implication is true. Is this true for non constant functions $f_1(x),g_1(x),f(x),g(x)$ ?","['monotone-functions', 'real-analysis', 'functions', 'inequality', 'supremum-and-infimum']"
4859774,Forgetful functor $Z(C)\rightarrow C$ has Left Adjoint,"The monoidal center $Z(C)$ of a monoidal category $C$ comes with a forgetful functor $F:Z(C)\rightarrow C$ defined $Z(X,\phi)=X.$ Does $F$ always admit a left adjoint? This is known (Section 3.2.) if $C$ is a tensor category. What about the general case? Tried the General Adjoint Functor Theorem but I'm not even sure if $F$ preserves limits in general.","['monoidal-categories', 'category-theory', 'adjoint-functors', 'tensor-products', 'limits']"
4859778,Prove Verification: show by definition that $\lim_{x \to 9} \sqrt{x-8}=1$,"Question: Prove by definition that $\lim_{x \to 9} \sqrt{x-8}=1$ Answer: $\forall \epsilon > 0, \exists \delta = (1+ \epsilon)^2-1 > 0 \; s.t. \; | \sqrt{x-8} -1 | < \epsilon$ indeed: 1- We can note that $\forall \epsilon>0 , (1+ \epsilon)^2-1>(1- \epsilon)^2-1$ and that $(1- \epsilon)^2-1>-(1+ \epsilon)^2+1$ (trivial to prove). 2- Hence from ""1-"" we have that if $ |x-9| < (1+\epsilon)^2-1 \Leftrightarrow -(1+\epsilon)^2+1< x-9 < (1+\epsilon)^2-1 $ we can restrict to the case of $x$ verifying $ (1- \epsilon)^2-1 < x-9 < (1+\epsilon)^2-1$ 3- So we continue and we get: $(1- \epsilon)^2 < x-8 < (1+\epsilon)^2 \Leftrightarrow 1-\epsilon < \sqrt{x-8} < 1+\epsilon \Leftrightarrow -\epsilon < \sqrt{x-8} -1 < \epsilon$ and the last expression is equivalent to write $|\sqrt{x-8} -1|<\epsilon$ . Q.E.D. Is it correct? Thank you.","['limits', 'calculus', 'solution-verification', 'continuity']"
4859784,How to perform this sum,"I encountered this sum $$S(N,j)= \frac{2 \sqrt{2}h(-1)^j}{N+1}\cdot\sum _{n=1}^{\frac{N}{2}}
\frac{\sin ^2\left(\frac{\pi  j n}{N+1}\right)}{\sqrt{2 h^2+\cos \left(\frac{2 \pi  n}{N+1}\right)+1}},$$ where $h\in \mathbb{R}^+, \{n,j\}\in \mathbb{Z}^+$ and $N\to \infty.$ It has the curious property that for a fixed $h$ (say $5/4$ ) as $N$ increases, the value of the sum seems to be the same for all values of $j$ other than the first few ( $j=1,2,3,\ldots$ ) and the last few $j=N,N-1,N-2,\ldots$ , otherwise there is a single value $a$ , which alternates in sign i.e. $$S(N,j)=(\ldots, a,-a,a,-a,\ldots).$$ Is it possible to obtain an expression for $S(N,j)$ by summing over $n$ , either for finite $N$ or if that's not possible is it possible to obtain $$\lim_{N\to \infty} S(N,j)$$ or at least the value of $|a|$ ?","['riemann-sum', 'summation', 'real-analysis']"
4859786,Adapting a proof of the non-separability of Morrey Spaces for a different definition.,"In the article ""Morrey spaces, their duals and preduals"", by Marcel Rosenthal and Hans Triebel , for every $1 \leqslant p < \infty$ and $-\frac{n}{p} < r < 0$ the Morrey Spaces are defined as $$ L^r_p(\mathbb R^n) := \left\{f \in L^p_{\text{loc}} \, \colon \, \| f \|_{L^r_p(\mathbb R^n)} < \infty \right\},  $$ where $$ \| f \|_{L_p^r(\mathbb R^n)} := \sup_{J \in \mathbb N_0, \, M \in \mathbb Z^n} 2^{J(\frac{n}{p}+r)} \| f \|_{L^p(Q_{J,M})}, $$ where $Q_{J,M}$ represents the usual dyadic cubes in $\mathbb R^n$ with sides of length $2^{-J}$ parallel to the axes of coordinates and $2^{-J}M$ as the lower left corner. At some point (Proposition $3.7$ ) we have the result Propostion. Let $1 \leqslant  p < \infty$ and $-n/p < r < 0$ . Then the space $L^r_p(\mathbb R^n)$ is non-separable. Proof. Let $$ Q_{J_l,M^l} = 2^{-J_l}M^l + 2^{-J_l}(0,1)^n, \quad l \in \mathbb N $$ be disjoint cubes with $Q_{J_l,M^l} \subset Q = (0,1)^n,$ where $J_l \in \mathbb N, J_1 < J_2 < \dots $ and $M^l \in \mathbb Z^n.$ Let $$ f^\lambda = \sum_{l=1}^\infty \lambda_{J_l,M^l}2^{-J_lr}\chi_{J_l,M^l}, $$ where $\chi_{J_l,M^l}$ is the charateristic function of $Q_{J_l,M^l}$ and $\lambda = \{\lambda_{J_l,M^l} \}_{l=1}^\infty$ with either $\lambda_{J_l,M^l} = 1$ or $\lambda_{J_l,M^l} = -1$ . Let $J \in \mathbb Z$ and $M \in \mathbb Z^n$ . Then $$ 2^{J(\frac{n}{p}+r)} \int_{Q_{J,M}} |f^\lambda(x)|^p \, dx \leqslant \sum_{l \colon J_l \geqslant J} 2^{-(J_l-J)(\frac{n}{p}+r)p} + \sum_{l \colon J_l < J} 2^{(J-J_l)rp} < \infty $$ where we used $\frac{n}{p}+r > 0$ and $r > 0$ . Hence $f^\lambda \in L^r_p(\mathbb R^n)$ . If $\lambda^1$ and $\lambda^2$ are two different admitted sequences then one has $\lambda^1_{J_l,M^l} = 1$ and $\lambda_{J_l,M^l} = -1$ for some $l \in \mathbb N$ and $$ \| f^{\lambda^1} - f^{\lambda^2} \|_{L^r_p(\mathbb R^n)} \geqslant 2^{J_l(\frac{n}{p}+r)} \left( \int_{Q_{J_l,M^l}} |(f^{\lambda^1} - f^{\lambda^2})(x)|^p \, dx \right)^{1/p} = 2. $$ But the set of all these admitted functions $f^\lambda$ is non-countable, having the cardinality of $\mathbb R$ . Thus it follows that $L^r_p(\mathbb R^n)$ is non-separable. $  \blacksquare$ I find the proof quite hard to understand, perhaps because I don't have much experience in dealing with the problem of separability of function spaces. Either way, the main purpose of my question is not the proof itself. Most of the time, when reading texts from different authors, Morrey spaces won't be defined in the same way. I am most used to the following definition: Consider $1 \leqslant p < \infty$ and $0 < \lambda < n$ arbitrarily. Then the Morrey Space $L^{p,\lambda}(\mathbb R^n)$ is defined as $$ L^{p,\lambda} := \left\{ f \in L^p_{\text{loc}}(\mathbb R^n) \, \colon \sup_{x \in \mathbb R^n, \, r > 0} r^{-\lambda} \| f \|_{L^p(B(x,r)}^p < \infty \right\}. $$ Now, my main goal is to prove that the Morrey Spaces (defined as I just showed) are non-separable for every $1 \leqslant p < \infty$ and $0 < \lambda < n$ . For this, I think that it might be possible to adapt the proof provided by Triebel and Rosenthal that I've quoted above, but I am having a hard time doing so. I appreciate any help, hints or answers in advance.","['lebesgue-measure', 'separable-spaces', 'lebesgue-integral', 'real-analysis', 'functional-analysis']"
4859811,Volume enclosed by convex surface and tangent plane over a region $\mathcal R$,"Consider a convex surface $\mathcal S$ defined by $z = f(x,y)$ . The volume between the surface and its tangent plane at point $P$ , enclosed within exterior $\mathcal S$ is minimal when $P$ is  the centroid of region $\mathcal R$ . Note :There is a region $\mathcal R$ whose outline is any general curve lying along the $xy$ -plane, and it extends along the $z$ -axis.
For example, if $\mathcal R$ is a circle in the $xy$ -plane, extending it along the $z$ -axis results in a cylinder, denoted as exterior $\mathcal S$ . I have proven this for $P(x,y) = (0,0)$ when region $\mathcal R$ is a circle of radius $r$ , as $P$ is its centroid for any convex surface. However, I am struggling to prove why this result holds for any convex surface $z = f(x,y)$ and any region $\mathcal R$ . Some of the tools I used to tackle the problem include Lagrange multipliers, the Euler-Lagrange equation, and since the volume under the surface is constant, the problem is equivalent to showing that the volume under the tangent plane at point $P$ is minimum for $P$ , where $P$ is the centroid of any region $\mathcal R$ and for any surface $z= f(x,y)$ .","['optimization', 'multivariable-calculus', 'calculus-of-variations']"
4859888,A $2D$ random walk with step size $1$ starts on the edge of a disk of radius $r$. What is probability that the walk will return to the disk?,"Consider a two dimensional random walk with step size $1$ and each step in a random direction, with the angle $\theta$ uniformly distrbuted in $[0,2\pi)$ . The walk starts on the perimeter of a disk of radius $r$ . What is probability that the walk will ever return to the disk, in terms of $r$ ? By ""the walk will ever return to the disk"", I mean the walk will have a vertex on or within the perimeter of the disk, besides the initial one. I came up with this question when thinking about the fact that a two dimensional lattice walk will return to the origin with probability $1$ , as proved by Polya in 1921. I have not been able to find any reference that answers my question. Context:","['random-walk', 'probability', 'reference-request']"
4859912,How to show that two integrals are equal?,"In my advanced calculus course, I am struggling with the following problem where we need to show that the two integrals are equal. Consider a function $g:[0,1] \times [0,1] \to \mathbb{R}$ defined by $$
g(x,y) 
= 
\min \{x, y \} - xy,
\quad 
\mbox{for} 
\quad 
0 \le x, y \le 1.
$$ Now, for a continuous function $f:[0,1] \to \mathbb{R}$ ,
then how do we prove that \begin{align}
& {} 
\int_{0}^{1} 
\left( 
\dfrac{1}{1-x}
\right)^{2}
\left[ 
\int_{x}^{1}
\int_{x}^{1}
f(y) (1-y) f(z) (1-z) \, dy \, dz
\right] \, dx \\[15pt]
& =
\int_{0}^{1}
\int_{0}^{1}
f(x) f(y) g(x,y) \, dy \, dx?
\end{align} I am not even sure where to start and the most critical part for me is how do we convert the triple integration on the left to just double integration on the right. So, I would appreciate for any guidance. Thank you! Update: Numerically I am able to verify. For example, considering $f(x) = 3x^{2}$ , we get the following: $$
LHS 
=
\frac{9}{112} 
=
RHS.
$$ But still do not know how we prove the general case!","['integration', 'measure-theory', 'definite-integrals', 'real-analysis', 'multivariable-calculus']"
4859925,Simplify $n$th derivative of $\frac{\log^3 x}{1-x}$,"I need to simplify $n$ th derivative of $$f(x)=\frac{\log^3 x}{1-x}$$ where $0<x<1$ I tried writing $f(x)=u_1u_2u_3u_4$ where $u_1=u_2=u_3=\log x$ and $u_4=\frac{1}{1-x}$ . Using Leibniz rule for $n$ th derivative we get $$f^{(n)}(x)=\sum_{k_1+k_2+k_3+k_4=n} \binom{n}{k_{1},k_{2},k_{3},k_{4}}u_1^{(k_{1})}u_2^{(k_{2})}u_3^{(k_{3})}u_4^{(k_{4})}$$ Now we have using $u_1^{(k_1)}=\frac{(-1)^{k_1+1} (k_1-1)!}{x^{k_1}}$ and $u_4^{(k_4)}=\frac{k_4!}{(1-x)^{1+k_4}}$ $$f^{(n)}(x)=\sum_{k_1+k_2+k_3+k_4=n} \left(\frac{n!}{k_1!k_2!k_3!k_4!}\right)\frac{(-1)^{k_1+1} (k_1-1)!(-1)^{k_2+1} (k_2-1)!(-1)^{k_3+1} (k_3-1)!k_4!}{x^{k_1+k_2+k_3} (1-x)^{1+k_4}} $$ $$f^{(n)}(x)=n!\sum_{k_1+k_2+k_3+k_4=n} \frac{(-1)^{k_1+k_2+k_3+1}}{k_1k_2k_3 x^{k_!+k_2+k_3}(1-x)^{1+k_4}} $$ $$f^{(n)}(x)=\frac{n!(-1)^{n+1}}{x^n}\sum_{k_1+k_2+k_3+k_4=n} \frac{(-1)^{k_4}}{k_1k_2k_3}\frac{x^{k_4}}{(1-x)^{1+k_4}} $$ Any help would be highly appreciated. Thank you.","['logarithms', 'analysis', 'real-analysis', 'calculus', 'derivatives']"
4859950,"If $\{\|T^n\|:n\in\mathbb{Z}\}$ is bounded for an invertible operator $T$ over a Hilbert space, must $T$ be conjugate to an orthogonal operator?","Suppose that $A$ is a invertible matrix with complex entries such that $\{\|A^n\|:n\in\mathbb{Z}\}$ is bounded. We consider the Jordan normal form of $A$ . It is well known that \begin{align*}
&\begin{pmatrix}
x & 1 & 0 &\cdots & 0 & 0\\
0 & x & 1 &\cdots & 0 & 0\\
\vdots & \vdots & \vdots &\ddots & \vdots & \vdots\\
0 & 0 & 0 &\cdots & x & 1\\
0 & 0 & 0 &\cdots & 0 & x\\
\end{pmatrix}^n_{d\times d} = \begin{pmatrix}
x^n & (x^n)' & (x^n)'' &\cdots & (x^n)^{(d-2)} & (x^n)^{(d-1)}\\
0 & x^n & (x^n)' &\cdots & (x^n)^{(d-3)} & (x^n)^{(d-2)}\\
\vdots & \vdots & \vdots &\ddots & \vdots & \vdots\\
0 & 0 & 0 &\cdots & x^n & (x^n)'\\
0 & 0 & 0 &\cdots & 0 & x^n\\
\end{pmatrix}\\
=&\begin{pmatrix}
x^n & nx^{n-1} & n(n-1)x^{n-2} &\cdots & n\cdots(n-(d-2)+1)x^{n-(d-2)} & n\cdots(n-(d-1)+1)x^{n-(d-1)}\\
0 & x^n & nx^{n-1} &\cdots & n\cdots(n-(d-3)+1)x^{n-(d-3)} & n\cdots(n-(d-2)+1)x^{n-(d-2)}\\
\vdots & \vdots & \vdots &\ddots & \vdots & \vdots\\
0 & 0 & 0 &\cdots & x^n & nx^{n-1}\\
0 & 0 & 0 &\cdots & 0 & x^n\\
\end{pmatrix},\quad n\in\mathbb{Z},
\end{align*} so the $n$ -th power of a size- $d$ Jordan block with digonal element $x$ has $\ell^1$ or $\ell^\infty$ norm $$
|x|^n+n|x|^{n-1}+\cdots+n\cdots(n-(d-1)+1)|x|^{n-(d-1)},
$$ and this number is bounded with respect to $n$ if and only if $|x|=1$ and $d=1$ , so the Jordan form of $A$ is a unitary matrix. What happens in infinite dimension? Let $V$ be a Hilbert space and $T\in\operatorname{GL}(V)$ (in the sense that $T$ is invertible and $T$ , $T^{-1}$ are continuous). If $\{\|T^n\|:n\in\mathbb{Z}\}$ is bounded, must $T$ be conjugated to an orthogonal operator? Also, if $V$ is merely a Banach space, could there be anything interesting to be said?","['banach-spaces', 'operator-theory', 'orthogonality', 'hilbert-spaces', 'functional-analysis']"
4859951,Degree-$p$ étale covers of affine line,"Let $k$ be an algebraically closed field of positive characteristic $p$ . Suppose that $F$ is a monic irreducible polynomial over $k[x]$ of degree $p$ whose discriminant is an element of $k$ . Is then $F$ necessarily of the form $$F=T^p+aT+f(x),$$ for some $a\in k$ and $f(x)\in k[x]$ ? I'm interested in this because I'm looking at degree- $p$ étale covers of the affine line $\mathbb{A}^1_k$ . Of course Artin-Schreier covers like the above provide examples, and I know that there are non-Galois degree- $p$ étale covers of $\mathbb{A}_k^1$ as well. But are there any non-Artin-Schreier covers given by a polynomial $F$ as above with constant discriminant? If I am not mistaken, this means that the covering curve is a smooth plane curve.","['algebraic-curves', 'positive-characteristic', 'irreducible-polynomials', 'algebraic-geometry', 'abstract-algebra']"
4859956,Why did I never learn about magmas?,"While I’ve never taken an actual abstract algebra course , there are some things I know about the typical curriculum structure: First, define an algebraic structure. Explain groups. Everything else. But we seem to skip the most fundamental algebraic structure: The magma A magma is perhaps the simplest thing you could explain, way simpler than groups: “A magma is a set equipped with one binary operation which is closed by definition. That’s all there is to the definition of a magma! Some well-known magmas are: Integers over addition, subtraction, multiplication Real numbers over addition, subtraction multiplication, division Complex numbers over every arithmetic operation Why did I never hear about a magma ever before while still being well into groups? This diagram (source: Wikipedia: Magma (algebra) ) can show how they are relevant in the structure of the algebraic structures, magmas to groups: Isn’t this a nice visual to explain how all the algebraic structures between magmas and groups are related? PS: I find the name “magma” kind of interesting; why does it have the same name as molten natural material from which igneous rocks are formed? That makes them even more mysterious.","['magma', 'abstract-algebra']"
4859977,Recurrence differential equations arising from the Normal PDF,"Let $a,b,c:\mathbb{R}\rightarrow\mathbb{R}$ be differentiable functions, with $a(t)\rightarrow -\infty$ and $c(t)\rightarrow -\infty$ as $t\rightarrow -\infty$ , and with $a(t)\rightarrow\infty$ and $c(t)\rightarrow\infty$ as $t\rightarrow\infty$ . Let $\phi:\mathbb{R}\rightarrow\mathbb{R}^+$ be the density of a standard normal random variable, meaning that for all $z\in\mathbb{R}$ : $$\phi(z)=\frac{1}{\sqrt{2\pi}} \exp{\left(-\frac{z^2}{2}\right)}.$$ For $j\in\mathbb{N}$ , let $z_j:\mathbb{R}\rightarrow\mathbb{R}$ with: $$z_j(t)=\int_{-\infty}^t{\exp{\left(a(\tau)-a(t)\right)}\,\left(b(\tau)+c(t)-c(\tau)\right)^j\,\phi\left(b(\tau)+c(t)-c(\tau)\right)\,d\tau},$$ for all $t\in\mathbb{R}$ , where you may assume the integral exists and is finite for all $j\in\mathbb{N}$ and $t\in\mathbb{R}$ . Finally, let $z_{-1}:\mathbb{R}\rightarrow\mathbb{R}$ . Then from differentiating $z_j(t)$ (in $t$ ), we have that for $j\in\mathbb{N}$ and $t\in\mathbb{R}$ : $$z_j'(t)=\left(b(t)\right)^j\,\phi\left(b(t)\right)-a'(t)z_j(t)+c'(t)\left(jz_{j-1}(t)-z_{j+1}(t)\right),$$ where, as usual, dashes denote first derivatives. I want to derive a differential equation for $z_0(t)$ that does not depend on $z_1(t),z_2(t),\dots$ . Is there a way to solve the recurrence equation (holding $t$ fixed) here to leave a differential equation? Or is there some other direct way to get a differential equation for $z_0(t)$ ? The solution should be somehow related to the recurrence relation for $z_j$ ( $j\in\mathbb{N}$ ): $$0=\beta^j\varphi-\alpha z_j+\gamma\left(jz_{j-1}-z_{j+1}\right).$$ When $\phi=0$ or $\beta=0$ , and $\alpha=-\gamma$ , this gives: $$z_{j+1}=z_j+jz_{j-1},$$ which is the sequence here and here (the number of involutions on a finite set) for appropriate initial conditions.","['involutions', 'recurrence-relations', 'normal-distribution', 'ordinary-differential-equations']"
4860139,Constructing Smooth and Analytic Maps for a Given Trace $y=|x|$,"As we know, a curve in $2$ -dim Euclidean space is defined as a map $\alpha: I \rightarrow \mathbb{R}^2$ , where $I$ is an open interval. The set $\alpha(I) \subset \mathbb{R}^2$ represents the trace or image of the curve. The property of being smooth or analytic for a curve depends on whether the map $\alpha$ is smooth or analytic, respectively. Interestingly, the smoothness of a curve does not necessarily correlate with the smoothness of its image. For instance, the function $y = \sqrt[3]{x^2}$ is not differentiable at $x=0$ . However, we can identify an analytic map $x = t^3$ , $y = t^2$ with same trace. My question focuses on how to construct a smooth, or even an analytic, map that corresponds to the trace $y=|x|$ . For a smooth map, I have managed to construct $x = t e^{-1/t^2}$ , $y = |t| e^{-1/t^2}$ . It is verifiable that the $n$ -th derivative at $t=0$ is $0$ . How would one go about constructing an analytic map for this trace? Alternatively, is it possible to prove that no such analytic map exists for this trace?","['analytic-geometry', 'calculus', 'differential-geometry']"
4860192,Special Type of Locally Metrizable Space,"We say a topological space is locally metrizable if for every $x\in X,$ there is an open set $U$ containing $x$ which is metrizable. That is, the subspace topology on $U$ is the topology induced by some metric $d_U.$ In my research, I've come across a space which is locally metrizable such that for some $d:X^2\rightarrow[0,\infty],$ all such metrizable neighborhoods $U$ , we have $d_U$ is a metric equivalent to $d$ restricted to $U^2.$ Intuitively, the space only fails to be a metric space insofar as there exist $x,y\in X$ such that $d(x,y)=\infty.$ This notion seems much stronger as it states that each pair of local metrics coincide (up to equivalence) everywhere they are defined. Is there a name for such a space, or a related condition? Are there any obvious corollaries? (ideally that $X$ is metrizable haha)","['metrizability', 'general-topology', 'metric-spaces']"
4860208,Is this a valid proof that $A \cup (B \cap C) \not= (A \cup B) \cap C$?,"I'm currently taking an introductory proof-writing course, and was wondering whether the following proof is incorrect: Prove or disprove the following statement: if $A$ , $B$ and $C$ are sets then $A \cup (B \cap C) = (A \cup B) \cap C$ . Proof. The statement is false. Suppose we have some $x \in A$ such that $x \not\in B$ and $x \not\in C$ . Then $x$ is an element of $A \cup (B \cap C)$ , but is not an element of $(A \cup B) \cap C$ . Is there some issue with ""supposing"" such an $x$ exists in this way? This question was marked wrong because it is ""not reasonable"", I asked for further clarification and this is the response I got: The question asked you to prove but not just to provide explanation. You can use digits or numbers to prove this.  For example, A=(1,2,3), B=(3, 4), C=(2) to prove this question which is more detailed rather than just to explain. I'm open to being wrong here, I'm just having a hard time understanding the TA's explanations and would appreciate some outside feedback. Thanks!","['elementary-set-theory', 'proof-writing', 'solution-verification']"
4860211,Curve cover direction,"I have interesting problem: Let's imagine a wire bent into a curve. We have a set of non-stretchable plastic covers of various diameters. The larger the diameter of the cover, the deeper it can be placed on the wire. The cover has some direction. With the casing diameter approaching zero, the direction is that of the derivative at the ends of the curve. If the cover is wide enough so that the entire curve fits in it, there is only one cover instead of two (starting and ending) and its direction can be calculated using the ""rotating calipers"" algorithm (in practice, a poly-line can be used instead of a smooth curve). How to calculate the direction depending on the curve (implemented as a polyline) and the width of the cover? Problem goal: image reconstruction where we have many polylines and gaps between parts of polylines, we need to find the most appropriate line B for line A and connect them by filling the gap - if tail cover of A intersect with head cover of B, optionally, we also limit the cover lengths. Hint: maybe easier parameter will be not width but rather depth; if depth small - direction will equals to direction first/last segment; up to the length of this segment; next, when will covered two segments, direction will between direction first and second segment, weighted with (first segment length, length of part of second segment); next will weighted direction between (first segment, second segment, part of third segment) etc. Using rotating calipers on k first/last of n vertex ?","['geometry', 'differential-geometry']"
4860221,Limit of the ratio of two matrix expansions,"With $M$ , $N$ and $W_r$ non-zero (invertible) square matrices, how can one calculate the following limit \begin{equation}
\lim_{\epsilon \to 0}\left[ I -  \frac{M \left(\sum_{r=0}^{\infty} \epsilon^{-r} W_{r} \right) M}{I - M \left( \sum_{r=0}^{\infty} \epsilon^{-r} W_{r} \right)  N} \right],
\end{equation} where $0 < \epsilon \ll 1$ and $I$ is the identity matrix.","['matrices', 'limits']"
4860293,"How to calculate this integral $\int_{0}^{\infty} \left(\frac{x - 1}{\ln(x)}\right)^2 \cdot \frac{1}{1 + x^n} \,dx$","How to calculate this integral $$ \int_{0}^{\infty} \left(\frac{x - 1}{\ln(x)}\right)^2 \cdot \frac{1}{1 + x^n} \,dx$$ This is how I start $$f(a)=\int_{0}^{\infty} \frac{(x^a-1)^2}{\ln^2(x)}\frac{1}{1+x^n}dx$$ Feynman trick $$f’’(a)=\int_{0}^{\infty} \frac{4x^{2a}}{1+x^n} - \frac{2x^a}{1+x^n} dx$$ used well known value of $$\int_{0}^{\infty} \frac{x^c}{1+x^b}dx $$ $$ \int_{0}^{\infty} \left(\frac{x - 1}{\ln(x)}\right)^2 \cdot \frac{1}{1 + x^n} \,dx=2 \int_0^1 \left( \ln \tan \frac{\pi(2t+1)}{2n}-\ln \tan \frac{\pi(t+1)}{2n} \right) dt$$ or $$ \int_{0}^{\infty} \left(\frac{x - 1}{\ln(x)}\right)^2 \cdot \frac{1}{1 + x^n} \,dx=\frac{2n}{\pi} \left( \int_\frac{\pi}{n}^\frac{3\pi}{2n} \ln \tan x dx - \int_\frac{\pi}{2n}^\frac{\pi}{n} \ln \tan x dx\right) dt$$ which seems numerically correct. How would you suggest to proceed?","['integration', 'calculus', 'definite-integrals', 'closed-form']"
4860294,"$M$ in triangle $ABC$ ; images $A',B',C'$ by inversions wrt circles $(MBC),(AMC),(ABM)$ are such that $A'B'C'$ equilateral : is $M$ a known center?","Yesterday, a question occurred to me, and I tried to find the center of the triangle that satisfies the condition I am thinking of, but I have not been able to do so yet Suppose a triangle $∆ABC$ , what is required is to determine the appropriate position of the point M that makes the triangle $∆A'B'C'$ To be an equilateral triangle where the points $A',B',C'$ are the inversion of the vertices of the triangle with respect to the three circles that each pass through two vertices of the triangle.  And the point $M$ I tried searching some centers from the Clark Kimberling Encyclopedia online and verified that they do not achieve this property. I tried about $15 centers of the triangle. I don't want to try all the points in the encyclopedia to find this point. Is there a faster way?  For example, how do we create this point with a ruler and compass?","['euclidean-geometry', 'inversive-geometry', 'geometry']"
4860309,How to prove that $[(p→q)∧(q→r)]→(p→r)$ is a tautology without using a truth table?,"How to prove that [(p→q)∧(q→r)]→(p→r) is a tautology without using the truth table?
I did these steps but i did not know how to continue ≡ [ (¬p ∨ q )  ∧  ( q → r ) ] → ( p → r )  By conditional law ≡ [ (¬p ∨ q )  ∧  ( ¬q ∨  r ) ] → ( p → r )  By conditional law ≡ [ (¬p ∨ q )  ∧  ( ¬q ∨  r ) ] → ( ¬p ∨ r )  By conditional law ≡ ¬ [ (¬p ∨ q )  ∧  ( ¬q ∨  r ) ] ∨ ( ¬p ∨ r )  By conditional law ≡ ¬ (¬p ∨ q )  ∨ ¬( ¬q ∨  r ) ∨ ( ¬p ∨ r )  By DeMorgan’s ≡ p ∧ ¬ q  ∨ ¬( ¬q ∨  r ) ∨ ( ¬p ∨ r )  By DeMorgan’s ≡ p ∧ ¬ q  ∨ q ∧  ¬ r  ∨  ¬p ∨ r  By DeMorgan’s","['logic', 'discrete-mathematics']"
4860320,"Without using L'Hopitals rule, how do you get $\lim_{x \to 0} \frac{1 - \cos 5x}{\sin 3x}$?","Without using L'Hopitals rule, how do you get the limit $$\lim_{x \to 0} \frac{1 - \cos 5x}{\sin 3x}$$ Using L'Hopital's, I can just take the derivative of the numerator $5 \sin 5x$ and denominator $3 \cos 3x$ which goes to $0/1$ or zero. But how do you show this without using derivatives? Is there a trigonometric trick so that the denominator $\sin 3x$ is transformed so the term does not become $0/0$ ? Any lead would be appreciated. Thanks","['limits-without-lhopital', 'limits', 'derivatives']"
4860345,"Proof of expected length in random division of $[0,1]$ interval","I have trouble fully understanding the proof in a formal manner for the expected length of the $k^{th}$ smallest interval when we randomly divide the $[0,1]$ interval using $n$ points. The $k^{th}$ smallest interval's expected length is equal to $$\frac{\frac{1}{k} + \frac{1}{k+1} + \dots + \frac{1}{n+1}}{n+1}$$ Proof : Without loss of generality, assume the $[0,1]$ segment is broken into segments of length $s_1 \geq s_2 \geq \dots \geq s_n \geq s_{n+1}$ , in that order. We are given that $ s_1 + \dots + s_{n+1} = 1$ , and want to find the expected value of each $s_k$ . Set $ s_i = x_i + \dots + x_{n+1} $ for each $ i = 1, \dots, n+1 $ . Then, we have $ x_1 + 2x_2 + \dots + (n+1)x_{n+1} = 1 $ , and want to find the expected value of $ s_k = x_k + \dots + x_{n+1} $ . If we set $y_i = ix_i $ , then we have $ y_1 + \dots + y_{n+1} = 1 $ , so by symmetry $ E[y_i] = \frac{1}{n+1} $ for all $ i $ . Thus, $ E[x_i] = \frac{1}{i(n+1)} $ for each $ i $ , and now by linearity of expectation $
E[s_k] = E[x_k] + \dots + E[x_{n+1}] = \frac{1}{n+1} \left( \frac{1}{k} + \dots + \frac{1}{n+1} \right)
$ QED I don't quite get how we use symmetry to claim that $E[y_i] = \frac{1}{n+1}$ ? I would really appreciate help in filling out the gaps in my understanding.","['expected-value', 'proof-explanation', 'combinatorics', 'probability']"
4860349,Discern how many triangles are possible given two sides and a non-included angle,"For the longest time, I always thought you could only determine a triangle, having only two sides, if you also had the included angle. Recently I solved a trigonometry problem where I was given $2$ sides and a non included angle and I was able to determine the third side, which was eye opening to me. So I did some doodles to try and see why is it possible to sometimes determine a triangle given only $2$ sides and a non included angle. What I concluded was that if you have sides $a$ and $b$ as well as the angle adjacent to $a$ , you can draw side $a$ and on one end draw a circle of radius side $b$ , on the other end draw a line at the given angle. What you will notice is that sometimes the circle is too small and the angle is too big so the line never touches the circle. Other times the line can touch it exactly once and other times exactly twice. Since a line cannot touch a circle more than twice, there are no more possibilities. So I want to know, is that idea correct? Also if it is correct how do I know whether the given two sides and angle determine $0$ triangles, $1$ triangle or $2$ triangles? I can tell that when it is $1$ triangle and side $a$ is greater than side $b$ , the line drawn at an angle is tangent to the circle, hence a $90°$ degrees angle is formed, there is a right triangle where $sin(B) = \frac{b}{a}$ .  Where $B$ is the given angle, adjacent to side $a$ and opposite of side $b$ . Of course what I am interested in is knowing whether or not the converse of that fact is true, ie if $2$ sides and a non included angle opposite of side $b$ are given and $a > b$ , and $sin(B) = \frac{b}{a}$ then there exists exactly one triangle with those requirements and it's a right triangle with hypotenuse side $a$ . Of course if side $a$ is equal to side $b$ there can only be at most one triangle, thinking of it as the circle engulfing side $a$ . There will always be one triangle as long as the angle is lesser than $90°$ . If side $a$ is less than side $b$ , then side $a$ is not fully engulfed and there will always be a triangle not matter what angle (lesser than 180° of course). So, I would like to know for all possibilities ( $a > b$ , $a = b$ , $a < b$ , etc...): How many triangles are there given sides $a$ and $b$ and angle opposite to $b$ , $B$ .","['triangles', 'trigonometry', 'geometry']"
4860373,"""Correct"" way of seeing that $\frac{\partial}{\partial A} f(AB) = \frac{\partial f(X)}{\partial X} B^T$, where $X = AB$","Lemma: Let $A \in \mathbb{R}^{m\times n}$ and $B \in \mathbb{R}^{n\times k}$ be matrices, and let $f:\mathbb{R}^{m\times k} \to\mathbb{R}$ be a differentiable function. Let $X = AB$ . Then $$
\frac{\partial f(X)}{\partial A} = \Big(\frac{\partial f(X)}{\partial X}\Big)B^T,
$$ where the right-hand side is the matrix product, and we are writing $\frac{\partial f(X)}{\partial X}$ for the matrix with $(i,j)$ -entry $\frac{\partial f(X)}{\partial X_{ij}}$ . Proof: One way to see this is by using the multivariable chain rule to get $$
\frac{\partial f(AB)}{\partial A_{ij}} = \sum_{k,l}\frac{\partial f(X)}{\partial X_{kl}}\cdot\frac{\partial X_{kl}}{\partial A_{ij}},
$$ and then observing that $$
\frac{\partial X_{kl}}{\partial A_{ij}} = \mathbb{1}_{i=k}B_{jl},
$$ which implies that $$
\sum_{k,l}\frac{\partial f(X)}{\partial X_{kl}}\cdot\frac{\partial X_{kl}}{\partial A_{ij}} = \sum_{l}\frac{\partial f(X)}{\partial X_{il}}B_{jl} = \Big(\Big(\frac{\partial f(X)}{X}\Big)B^T\Big)_{ij}.
$$ $$\tag*{$\blacksquare$}$$ My question: The thing we are trying to show looks pretty much exactly like the single variable chain rule, namely that for real numbers $x = ab$ , we have $$
\frac{\partial f(x)}{\partial a} = \Big(\frac{d f(x)}{dx} \Big)\cdot b,
$$ so I'm wondering if there is some appropriate ""matrix chain rule"" that lets us see the lemma immediately, without having to expand it in terms of all these scalar derivatives. I've searched around things like ""matrix/tensor chain rule"", ""matrix/tensor calculus"", but I haven't found exactly what I'm looking for. I suspect that the answer lies in tensor calculus, but the references I've found contain a lot of abstraction, and it seems they are intended for a much more general setting (i.e. general relativity or the like).","['multivariable-calculus', 'matrix-calculus', 'chain-rule']"
4860383,Proving that the set of $a$ for which the roots of $P(X)-a$ are all real is an interval,"I found this problem on a problem sheet about polynomials: Let $P \in \mathbb{R}[X]$ , $S_a = \{t \in \mathbb{C} \mid P(t) = a\}$ , and $I = \{a \in \mathbb{R} \mid S_a \subset \mathbb{R}\}$ . Show that $I$ is an interval. I can see intuitively why this must be true: if we take a polyomial $P$ such that all the roots of $P'$ are real and simple, then the graph of $P$ shows that this interval is exactly the interval between the smallest maximum of $P$ and the largest minimum of $P$ . I tried to show that this holds, but I couldn't.","['algebra-precalculus', 'roots', 'polynomials']"
4860396,Recover direct summands in derived category?,"Let $E,F\in D^b(X)$ , where $D^b(X)$ denotes the derived category of coherent sheaves on some smooth variety $X$ . I am thinking about the following question: If $E \oplus E[1] \simeq F \oplus F[1]$ , is it true that $E \simeq F$ ? One can also ask the similar question where 'shifted by $1$ ' replaced by 'shifted by $n$ ' for any fixed $n\in \mathbb Z$ .","['homological-algebra', 'derived-categories', 'direct-sum', 'algebraic-geometry', 'commutative-algebra']"
4860431,Number of words with $3n$ letters where no $3$ consecutive letters are the same,"This is similar to this question , and I wanted to apply the technique of inclusion-exclusion to see if I understand it. I try to explain as many details as possible in my reasoning, and I would like to know if my solution is correct? In an alphabet of $n$ distinct letters, how many words of length $3n$ , where each letter appears $3$ times, can be formed such that no $3$ consecutive letters are the same? Attempt. Suppose first that the identical letters are distinguishable. Choose $k$ letters to form consecutive triples in our word, where $k=0,1,...,n$ . There are ${n \choose k}$ choices for these letters. Then, we may order the remaining letters arbitrarily, of which there are $(3n-k)!$ ways to do so, since these are just permutations. Implicitly, we are regarding each triple as one letter. Next, since we assumed the identical letters are distinguishable, each triple has $3!=6$ different orderings, giving a total of $6^k$ different orderings for our $k$ triples, by the product rule. These three steps are independent, so by the product rule, we get there are ${n \choose k}(3n-k)!6^k$ words with $k$ consecutive triples. However, we now must account for the fact that there are identical letters. Each triple has $3!=6$ different orderings, so we have to divide by $6^n$ to remove the duplicate words. Thus, by principle of inclusion-exclusion, the total number of words is $$\sum_{k=0}^n \frac{1}{6^n} (-1)^k{n\choose k} (3n-k)!6^k = \frac{1}{6^n} \sum_{k=0}^n (-1)^k {n \choose k}(3n-k)!6^k.$$","['inclusion-exclusion', 'solution-verification', 'combinatorics', 'discrete-mathematics']"
4860521,A maximal invariant generates the invariant $\sigma$-algebra,"Let $G$ be a group action on the set $X$ , and let $f:(X,\Sigma_X)\to (Y,\Sigma_Y)$ be a measurable maximal invariant ( $f$ is constant on each orbit and take different values on different orbits). Am asked to show that if $(X,\Sigma_X)$ and $(Y,\Sigma_Y)$ are standard Borel then $$\sigma(f)=\{B\in \Sigma_X:g^{-1}(B)=B \text{ for all } g \in G\}$$ The inclusion $\subset$ is easy. How can I show the other inclusion? It suffices to show that for any measurable invariant (constant on each orbit) $g:(X,\Sigma_X)\to [0,1]$ there exists measurable $h:(Y,\Sigma_Y)\to [0,1]$ such that $g=h\circ f$ . This is because we can then take $g=1_B$ so that $B=g^{-1}(1)=f^{-1}(h^{-1}(1))\in \sigma (f)$ . Any invariant function $g$ is function of $f$ . But how to choose $h$ in a measurable way? Can I use a measurable selection theorem ?","['borel-sets', 'measure-theory', 'group-actions', 'ergodic-theory']"
