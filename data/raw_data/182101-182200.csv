question_id,title,body,tags
3323992,Minimum of two submodular functions,"Let $V$ be a finite set, and denote with $2^V$ the corresponding power set. 
Consider two (non-monotone) submodular function $f:2^V\rightarrow \mathbb{R}_{\geq 0}$ and $g:2^V\rightarrow \mathbb{R}_{\geq 0}$ . Consider the function $$
H: 2^V \rightarrow \mathbb{R}_{\geq 0} : U \mapsto \min (f(U), g(U)).
$$ Is the function $H$ also a submodular function?","['matroids', 'combinatorics', 'discrete-mathematics']"
3324018,"Choosing two numbers from set $\{10,11...,99\}$ that satisfy the given conditions","Given the set of numbers $\{10,11,...,99\}$ , with no repetitions and no order significance. Let $A$ be the set of options of choosing pairs with the same tens number. Let $B$ be the set of options of choosing only two even numbers. Let $C$ be the set of options which the difference between $2$ numbers satisfies $-2 \leq x \leq 2$ . How do I calculate the sizes of $A$ , $B$ , $C$ ? For $A$ : Ss we know we can choose $2$ numbers from $\{10, \ldots, 99\}$ ,  we have two positions that we need to fill. Therefore, for the first position, we have $90$ possibilities. And after choosing the first number, the second one will only have $9$ options from a group with the same tens number. So that gives us $$\frac{90 \cdot 9}{2}$$ For $B$ : In total, we have $45$ even numbers out of $\{10, \ldots, 99\}$ . 
For the first position, we have $45$ possibilities. And for the second position, we remain with only $44$ even numbers to choose from.
So that gives us $$\frac{45 \cdot 44}{2}$$ For $C$ : For each given number chosen from $\{12, \ldots,97\}$ , we can pair it with $4$ different numbers that will fulfill the condition (ex. <12, 10\11\13\14> the subtraction of 12 and all those numbers will give as a difference that is $-2 \leq x \leq 2$ .) And for the numbers $11$ and $98$ , there are only $3$ numbers to choose from. And for the numbers $10$ and $99$ , there are only $2$ numbers to choose from. In total: $85 \cdot 4 + 2 \cdot 3 + 2 \cdot 2$ . Is this calculation is right?","['combinatorics', 'discrete-mathematics']"
3324022,"Why does $x_0 + \sin(x_0) \approx \pi$, when computing it multiple times? [duplicate]","This question already has answers here : Consecutively Adding Sines (3 answers) Closed 4 years ago . Why does $x_0 + \sin(x_0) \approx \pi$ when computing this multiple times on the calculator? So for any value of up to $\approx 6.25$ , doing the following operation ( $x_0 + \sin(x_0)$ , then the newly obtained value (let's call it $x_1$ ) is replaced instead of $x_0$ : $x_1 + \sin(x_1)$ ) many times leads to a value, which is very close to $\pi$ . However, when going above that value, this will result in roughly $3\pi$ , $5\pi$ , etc. Could anyone please try to explain why the simple first calculation works? EDIT: Thank you so much for your answers guys - through a combination of the many, I believe to now understand why!",['trigonometry']
3324023,What is longer? Length of $2^n$ or number of $0$ in $n!$?,"What is longer? Length of $2^n$ or number of $0$ at the end of $n!$ ?
Assume that $n$ is really big, big number... Solution Look at terms of $2^k$ : $$2,4,8,16,32,64,128,256,512,1024,2048,4096... $$ It can be seen that $$ \lfloor\frac{n}{3} \rfloor \ge length(2^n)\ge \lfloor\frac{n}{4} \rfloor		 $$ Now, lets look at $n!$ . We know that $0$ is created at the end iif we use $2$ and $5$ or $10$ . Number of $2$ is greater than number of $5$ so  we can count number of $5$ . $$\mbox{number of 0 in } n! = \sum_{k \ge 0} \lfloor\frac{n}{10^k} \rfloor +   \sum_{k \ge 0} \lfloor \frac{n}{5^k} \rfloor  $$ $$ (n-1)\left(  \sum_{k \ge 0} \frac{1}{10^k}  +   \sum_{k \ge 0}  \frac{1}{5^k}   \right)\ge \mbox{number of 0 in } n! \ge n \left(  \sum_{k \ge 0} \frac{1}{10^k}  +   \sum_{k \ge 0}  \frac{1}{5^k}   \right) $$ $$ \mbox{number of 0 in } n! \approx \frac{13}{36} \cdot n \approx 0.361 \cdot n \ge \frac{1}{3} \cdot n $$ So the longer is  number of $0$ in $n!$ . Have I done this exercise correctly? update $$ (n-1)\left(    \sum_{k \ge 0}  \frac{1}{5^k}   \right)\ge \mbox{number of 0 in } n! \ge n \left(  \sum_{k \ge 0}  \frac{1}{5^k}   \right) $$ $$ \mbox{number of 0 in } n! \le 1/4 $$ so length of 2^n is greater that trailing $0$ in $n!$","['number-theory', 'factorial', 'divisibility']"
3324026,Is there a mathematical function for a sinusoidal function that each wave is omega shaped?,"I am interested to know if there is any possibility to define the function or equation for a sinusoidal function , similar to |sine(x)| but with each wave as an Omega shape , as you can see in the image, there is a continuous variation from S shaped Omega to C shaped, so it seems to me that there can be a function that could also consider this. clearly it would be something like a system of equations : x=x(t)
y=y(t) later I would need to draw these functions  in 2D space, so knowing that the shape of S shaped omega is in contrast with the definition of a function ( no more than one point should be cut along each vertical line cutting the function)
but I hope I would be able to do this through the definition of some cloud of points in a programming software","['trigonometry', 'functions']"
3324033,How to proceed further in this Arithmetico-Geometric Progression problem,"Question: The sum to $n$ terms of the series, $S=1+5(\frac{4n+1}{4n-3})+9(\frac{4n+1}{4n-3})^2+13(\frac{4n+1}{4n-3})^3+....$ The following image is my approach towards the problem. Could you please tell how to proceed? I proceeded in this way as I did not want to mug-up the complicated formula given for AGP summation. The final answer is $n(4n-3)$",['sequences-and-series']
3324043,Loss functions for Regression task,"I am trying to understand the idea of Loss functions For Regression Task perfectly. I have read many textbooks and articles, and I came up with questions related to this subject. Several different uses of loss functions can be distinguished. (a) In prediction problems: a loss function depending on predicted and observed value defines the quality of a prediction. (b) In estimation problems: a loss function depending on the true parameter and the estimated value defines the quality of estimation. (c) Many estimators (such as least squares or M-estimators) are defined as optimizers of certain loss functions which then depend on the data and the estimated value. Now, since my focus is on Loss Functions For Regression Task ( $y_i=\theta_0 +\theta_1x_{i1}+\dots + \theta_px_{ip} +\epsilon_i$ ,y is the dependent variable and x is the independent one) My questions are as follows. Should I write the loss function formula as a function of the parameter or of the variables ( $\mathrm{L}\big(\theta,\hat\theta\big)$ or $\mathrm{L}\big(y,\hat y\big)$ )? Should I consider the Loss function formula for one point or Not (with sums or not)? Note My thought is to introduce Loss function first and then to use the standard notation for all Loss functions (least square, absolute value and Huber Loss, Quntile Loss and so on). UPDATED I did the following but I am not sure L2 Loss $$ \mathrm{L}\big(\{y_{(i)}, \hat{y}_{(i)}\}_{i=1}^n\big) = \mathrm{\sum}_{i=1}^n\big(y_i-\hat y_i\big)^2;$$ L1 Loss $$ \mathrm{L}\big(\{y_{(i)}, \hat{y}_{(i)}\}_{i=1}^n\big) = \mathrm{\sum}_{i=1}^n|y_i-\hat y_i|;$$ Huber Loss $$
\mathrm{L}\big(\{y_{(i)}, \hat{y}_{(i)}\}_{i=1}^n\big) = \begin{cases}
\frac{1}{2}\mathrm{\sum}_{i=1}^n(y_i-\hat y_i)^2 & |y_i-\hat y_i| \leq \delta \\ \delta\mathrm{\sum}_{i=1}^n|y_i-\hat y_i|-\frac{1}{2}\delta^2 & \text{otherwise}
\end{cases}
$$ Log-Cosh Loss $$\mathrm{L}\big(\{y_{(i)}, \hat{y}_{(i)}\}_{i=1}^n\big)= \log[\cosh\mathrm{\sum}_{i=1}^n(y_i-\hat y_i)];$$ Quantile Loss $$\mathrm{L}\big(\{y_{(i)}, \hat{y}_{(i)}\}_{i=1}^n\big) = \big[\tau \mathrm{\sum}_{i=1}^n|y_i-\hat y_i| + (1 + \tau)\mathrm{\sum}_{i=1}^n(y_i-\hat y_i)\big].$$","['statistics', 'regression', 'machine-learning', 'functions', 'optimization']"
3324074,Totally Cool Proof of Sierpinski's Theorem?,"Talking about Theorem. If $\mu$ is a non-atomic measure on $X$ and $0<t<\mu(X)$ then there exists $E$ with $\mu(E)=t$ . The proofs I see all use Zorn's lemma or transfinite recursion. Don't get me wrong, I think the proof by transfinite recursion is simple, natural and elegant: We try to construct $E$ as a union of sets with small measure. After we have $\omega$ of them it may be that the measure of the union is still less than $t$ , so we just go ahead and ""define"" $E_\alpha$ for countable ordinals $\alpha$ , and for some countable $\alpha$ we must have $\mu\left(\bigcup_{\beta<\alpha}E_\beta\right)=t$ . (One could easily convert that to a proof by Zorn's lemma that seems simpler and more natural than the Zorn proofs I've seen: Consider a maximal collection $(E_\alpha)$ of disjoint sets of positive measure with $\sum\mu(E_\alpha)\le t$ ...) So that's nice and ""intuitive"", but it seems like there ""should"" be a more elementary argument. There is a proof using nothing but epsilons and deltas, although it's a little bit complicated. (I kinda like the proof of the Main Lemma there; it's clear  that the ML is something tending in the direction of the theorem, and indeed the proof of the theorem from ML is straightforward.) Anyway, my question is whether anyone sees how to make the following proof work: Totally Cool Proof. Let $A$ be the ""measure algebra"", that is, the space of equivalence classes of measurable sets modulo null sets. Define a metric on $A$ by $d(E,F)=\mu(E\Delta F)=||\chi_E-\chi_F||_1$ (say we're in the case $\mu(X)<\infty$ .) Then $(A,d)$ is connected (because why? ), hence $\mu(A)$ is connected. Note I tend to believe that $(A,d)$ is in fact path-connected, because it seems to me that a limit of successive refinements of the chain obtained in proof of the $\frac12$ theorem at that link should give a path. But no points for working that out; what I'm wondering about is a totally trivial proof that there are no non--trivial clopen sets...",['measure-theory']
3324076,Evaluating the product containing the reciprocals of all primes $\prod_{k=1}^\infty\left(1+\frac{(-1)^k}{p_k}\right)$,"How to compute the following product: $$\prod_{k=1}^\infty\left(1+\frac{(-1)^k}{p_k}\right)=\left(1-\frac{1}{2}\right)\left(1+\frac{1}{3}\right)\left(1-\frac{1}{5}\right)\left(1+\frac{1}{7}\right)\dots$$ where $p_k$ is the $k^\text{th}$ prime number? My Observation, but NOT SURE: Using $k=1$ to $k=18$ , the product is almost $0.578282825\dots$ and that value is $$\frac{\frac{\pi}{5}+\frac{\pi}{6}}{2}=\frac{11\pi}{60}\approx0.575958653\dots$$ So, is the product really tends to $\frac{11\pi}{60}$ ? Any help/hint will be appreciated. THANKS!","['infinite-product', 'number-theory', 'pi']"
3324078,Calculation of probability. Why is my solution wrong?,"The problem (taken from Harvard Stat 110) is as follows: For a group of 7 people, find the probability that all 4 seasons
  (winter, spring, summer, fall) occur at least once each among their
  birthdays, assuming that all seasons are equally likely. The authors propose a solution using Inclusion-Exlusion method, which is clear for me, so I decided to try a different method, using naive definition of probability. Here's my solution: 1. Denominator, as there are $4^7$ ways to assign seasons to these people, will look as follows: $|\Omega|=4^7$ 2. To compute the numerator, we have to pick 4 people, and assign seasons to them ( $\binom{7}{4}\times4!$ ways). Then we assign seasons to the rest ( $4^3$ ways).
So, numerator: $\binom{7}{4}\times4!\times4^3$ . This solution looks reasonable for me, however it's incorrect.
Please, explain, why I'm wrong?","['probability-theory', 'probability']"
3324089,Intuition on Dominating Measures and Absolute Continuity,"From Wikipedia, A measure $\mu$ on Borel subsets of the real line is absolutely
  continuous with respect to Lebesgue measure $ \lambda$ (in other
  words, dominated by $\lambda$ ) if for every measurable set $ A$ , $\lambda (A)=0$ implies $\mu(A)=0$ . This is written as $\mu \ll\lambda$ . I understand mathematically what is written, and perhaps what is meant by it on some level. However, I cannot fully understand all the intuition behind this. Namely, Why does "" $\lambda (A)=0$ implies $\mu(A)=0$ "" mean absolute continuity . As in, is this the same continuity in the traditional $\epsilon$ - $\delta$ sense? Are they equivalent? If so .... why? The definition of "" $\lambda (A)=0$ implies $\mu(A)=0$ "" seems so minimal to me to imply an $\epsilon$ - $\delta$ continuity What is then the significance of absolute continuity of measures? Why is it important to have dominating measures, as far as probability/statistics is concerned? Is there some intuition as to why they should be defined/exist? The original question which spurred this investigation is along the lines of: Suppose $X$ is a random variable, and $\exists F: T = F(X)$ , then the joint distribution of ( $X,T$ ) is not dominated by a product measure. I'm not sure what the above should mean, or why it is overall important to ensure dominance by a measure, so care is needed when defining the joint and conditional densities.","['statistics', 'lebesgue-measure', 'measure-theory']"
3324098,Dual of a Hopf algebra,"Given is a Hopf algebra $(H,m,\eta, \Delta, \epsilon, S)$ . We know that there is a dual notion of it, called the dual Hopf algebra on $H^{*}$ as a vector space. It has the natural structure of a Hopf algebra. We know that the finite-dimensional algebra $(H,m, \eta)$ has the structure of a coalgebra, given by the maps: $m^{*}: H^{*} \rightarrow (H \otimes H)^{*}\cong H^{*} \otimes H^{*}, m^{*}(f)(a \otimes b)=f(ab),$ $u^{*}: H^{*} \rightarrow \mathbb{K}$ , $u^{*}(f)=f(1_{H})$ , for any $f \in H^{*}$ and $a,b \in H$ . On the other side the coalgebra $(H, \Delta, \epsilon)$ has the structure of an algebra, this is true even if $H$ is of infinite dimension. Its structural maps should be the following: $\Delta^{*}: H^{*} \otimes H^{*} \rightarrow H^{*}$ , $\Delta^{*}(f \otimes g)(\Delta(h))=f(h_{(1)})g(h_{(2)}),$ $\epsilon^{*}=\epsilon(h)$ , for any $f,g \in H^{*}$ and $h \in H$ . My question is how to define the dual notion of the antipode? How would the precise assignment look like? Thank you in advance for your help!","['quantum-groups', 'abstract-algebra', 'representation-theory', 'hopf-algebras']"
3324152,"Finding the smallest positive x,y such that $x^2 - 17y^2 = 1$","Part (b) of this question: a) Express $\sqrt{17}$ as a continued fraction. b) Hence, or otherwise, find the smallest positive integers $x$ , $y$ such that $x^2 - 17y^2 = 1$ . I'm fine with part (a) and I know that the answer to (b) is probably $x =33$ and $y = 8$ and that it has something to do with the convergents of the continued fraction I found in (a). But I don't really know the relation between $x$ , $y$ and these convergents and as a result can't really provide an adequate answer to the question. Any help would be greatly appreciated. Thank you!","['continued-fractions', 'pell-type-equations', 'discrete-mathematics']"
3324226,Does there exist an algorithm which detects the starting and stop points of valleys in a time-series?,"I was able to loosely code something which does this in Python, but I was just wondering if there was a known mathematical formula or proper algorithm which estimates these points. I've marked ""starting points"" in green and ""ending points"" in red. My intuition led me to estimating the second-derivative and doing peak detection on it, but I'm sure that my hunch isn't some novel invention, so I'd just like to make sure.","['maxima-minima', 'derivatives', 'data-analysis']"
3324320,$n$-th derivative of $x^\alpha$ where $\alpha = m + 1/2$,"It is well-known that, for any real $\alpha$ and nonnegative integer $n$ $$ \frac{d^n x^\alpha}{dx^n} = \alpha(\alpha-1)\cdots(\alpha - n + 1) x^{\alpha - n}  $$ I just found out that the coefficient is known as a falling factorial $$ \alpha(\alpha-1)\cdots(\alpha - n + 1) =: (\alpha)_n $$ where $(\alpha)_n$ is Pochhammer's symbol. It seems that in the case $\alpha = 1/2$ and more generally $\alpha = m + 1/2$ where $m$ is a nonnegative integer, it is possible to express $(\alpha)_n$ with powers of 2 and standard (integer) factorials.  For example: $$ (1/2)_4 = \frac12\bigg(-\frac12\bigg)\bigg(-\frac32\bigg)\bigg(-\frac52\bigg) =- \frac{1\times3\times5}{2^4} = -\frac{5!}{2^4\times(2\times4)} =- \frac{5!}{2^4\times2^2\times 2!} $$ Would anyone know a good reference to such formulas?  I am guessing the cases $n>m$ and $n<m$ must be distinguished. Thanks!
p.","['pochhammer-symbol', 'radicals', 'derivatives', 'factorial']"
3324366,Showing a Functor is not Representable,"I have this old qual problem that I don't know how to do: So let $ F: Rings \to Sets$ given by $R \mapsto \{(a,b) \in R^2, aR + bR =  R\}$ . The action on the morphism is the obvious one. Now the problem asks to show that the functor is not representable. So here is what I found on the internet: According to the method on the second page of this pdf http://pi.math.cornell.edu/~zbnorwood/ucla/files/repfunctors.pdf ,
suppose $F  = Hom(A, \_)$ , then there is $(a, b) \in A^2, aA + bA =A$ such that for $B$ a ring and $(x, y) \in B^2, xB+ yB = B$ then there exists unique ring map $f: A \to B$ such that $f(a) = x, f(b) = y$ . I don't know how to reach a contradiction from there. Or does anyone have any great method for proving a not representable functor is not representable in general? I find this type of problems really hard.","['ring-theory', 'abstract-algebra', 'category-theory']"
3324410,Irreducible components of $x_1x_4 -x_2x_3 = x_1x_3 - x_2^2=0$,"I am going through introductory course on commutative algebra.
Let us have an algebraic set $X$ in $\mathbb{C}^4$ that is described as $x_1x_4 -x_2x_3 (f) = x_1x_3 - x_2^2 (g) =0$ . I am asked to find irreducible subsets of X, and to compare $I = (f,g)$ , the ideal $I(X)$ which is all the polys that $h|_X$ =0 and the intersection of ideals of the irreducible components. So far $f$ is a cone with the origin at $(0,0,0,0)$ . 
One of the components seem to be $x_1=x_2=0$ Here is a similar task that gives a way to make a problem easier in case there are elements that are reducible. The task is taken from here and I have solved the same question for $(x_1x_2-x_3^2=x_3-\lambda(x_1+x_2)=0)$ for $\lambda \in \mathbb{C}$ which is an intersection of a plane and a cone. But I can't imagine 4-dimensional space. I used the fact that homogeneous polynomial of second power is always reducible. May be that could help here. Update. I have found three related questions: Checking one of prime ideals of X , Krull dimension of I(X) , Groebner base for the system . thanks in advance","['algebraic-geometry', 'commutative-algebra']"
3324412,"Are the units of a ring	$\Bbb {Z}_n, +, •$ also the generators of the cyclic group $\Bbb{Z}_n, + $","I noticed while studying for an introductory Algebra course, that the units $ x $ of $\Bbb {Z}_n, +, •$ had to be integers so that $\gcd(x, n) = 1$ . But aren't those elements generators of $\Bbb {Z}_n, +$ too? As far as I can tell, yes. But is there an underlying reason, theory or something to back this? Or is this just it?","['cyclic-groups', 'finite-groups', 'ring-theory', 'abstract-algebra', 'group-theory']"
3324429,connectedness can be checked on special fibre,"Let $X$ be a scheme over $\mathrm{Spec}(R)$ , $R$ a DVR with residue field $k = R/\mathfrak{m}$ . I read an argument that said that if the special fibre $X_k$ is connected then $X$ is connected. Is this true without any assumptions on $X$ ? In the case I care about $X \to \mathrm{Spec}(R)$ is affine (in fact finite) flat. Is the argument correct when we include one or both of these assumptions, and why? Edit: As Mohan has pointed out in the comments, this cannot be true in the general case where $X$ is affine and flat. I'm curious whether it's true when $X$ is also finite. For example, I'm told $X = \mathrm{Spec}(\mathbb{Z}_p[x]/(x^p-1))$ is connected but I don't see why. It's special fibre is clearly connected.","['connectedness', 'algebraic-geometry', 'schemes']"
3324435,Is the presheaf defined by $U\mapsto (\mathcal I(U))^2$ a sheaf of ideals of $\mathcal O_X$?,"Let $(X,\mathcal O_X)$ be a ringed space and $\mathcal I$ a sheaf of ideals of $\mathcal O_X$ , is the presheaf defined by $U\mapsto (\mathcal I(U))^2$ a sheaf of ideals of $\mathcal O_X$ ?","['algebraic-geometry', 'sheaf-theory']"
3324438,"Find the increasing function $f:\mathbb{R} \to \mathbb{R}$ such that $\int_{0}^{x}f(t)\,dt=x^2$ for all $x\in \mathbb{R}$","Find the increasing function $f:\mathbb{R} \to \mathbb{R}$ such that $$\int_{0}^{x}f(t)\,dt=x^2\text{ for all }x\in \mathbb{R}$$ My solution: Let $F:\mathbb{R} \to \mathbb{R}$ , $F(x)=\int_{0}^{x}f(t)\,dt$ . Then it follows that $F$ is differentiable and that $F'(x)=2x$ for all $x\in \mathbb{R}$ . For $a\in \mathbb{R}$ we have that $$2a=F'(a)=\lim_{x\searrow a}\frac{F(x)-F(a)}{x-a}=\lim_{x\searrow a}\frac{\int_{a}^{x}f(t)\,dt}{x-a}\ge \lim_{x\searrow a} \frac{\int_{a}^{x}f(a)\,dt}{x-a}=\lim_{x\searrow a}\frac{(x-a)f(a)}{x-a}=f(a)$$ and $$2a=F'(a)=\lim_{x\nearrow a}\frac{F(x)-F(a)}{x-a}=\lim_{x\nearrow a}\frac{\int_{a}^{x}f(t)\,dt}{x-a}\le \lim_{x\nearrow a} \frac{\int_{a}^{x}f(a)\,dt}{x-a}=\lim_{x\nearrow a}\frac{(x-a)f(a)}{x-a}=f(a).$$ From these two relations it follows that $f(x)=2x$ for all $x\in \mathbb{R}$ . I think that my solution works, but what I would like to know is why we can't take $f$ to be decreasing. Assuming that it were decreasing, by reversing the inequalities from above we get that $f(x)=2x,\forall x \in \mathbb{R}$ , which is a contradiction. What I want to find out is if there is any other way to reach a contradiction in this case. More precisely, I would like to know what may have motivated the authors of this problem to consider $f$ to be increasing instead of decreasing(I doubt that they just tried both cases and chose the one that actually worked).","['integration', 'functions', 'real-analysis']"
3324489,How is the derivative of a function $f$ related to the derivative of a function whose graph is the image of the graph of $f$ under a rotation?,"The aim of this self-answered question is to record an answer worked out to a question posted earlier today that was deleted before the answer could be submitted. Suppose $f : U \to \Bbb R$ , $U \subseteq \Bbb R$ , is a function differentiable at a point $x$ . If the image of the graph of $f$ under a rotation $R$ is the graph of some function $\tilde f$ , is $\tilde f$ differentiable at $\tilde x := p(R(x, f(x)))$ , where $p$ is the projection onto the first coordinate?","['calculus', 'derivatives', 'geometry', 'rotations']"
3324509,Show that angles are equal in a circumscribed circle,"We have a $\triangle ABC$ and a circumscribed circle $k$ . Line $c$ is
  parallel to the tangent of the circle in $C$ . Show that $\angle CAB = \angle CA_1B_1$ . So, $\angle CAB = \dfrac{\newcommand{arc}[1]{\stackrel{\Large\frown}{#1}}\arc{BQ} + \newcommand{arc}[1]{\stackrel{\Large\frown}{#1}}\arc{QC}}{2}$ and $\angle CA_1B_1=\dfrac{\newcommand{arc}[1]{\stackrel{\Large\frown}{#1}}\arc{BQ} +\newcommand{arc}[1]{\stackrel{\Large\frown}{#1}}\arc{PC}}{2}$ . From here, we see that we should prove that $\newcommand{arc}[1]{\stackrel{\Large\frown}{#1}}\arc{QC}$ is equal to $\newcommand{arc}[1]{\stackrel{\Large\frown}{#1}}\arc{PC}$ . The only way that I see is with congruent triangles ( $OC\cap PQ=K; \triangle KPC \cong \triangle KQC$ ). Can we do it faster?","['euclidean-geometry', 'tangent-line', 'circles', 'geometry']"
3324529,Proving associativity of addition with weird carry operation,"There is a somewhat famous example of group cohomology witnessing $\mathbb{Z}/100$ as an extension of $\mathbb{Z}/10$ by $\mathbb{Z}/10$ , with the standard carry function $c$ as a 2-cocycle (cf. this paper ) Of course, this is not the only extension of $\mathbb{Z}/10$ by $\mathbb{Z}/10$ , and indeed if we use $2c$ as our carry function (i.e. we carry 2 instead of 1 on each stage) we get another extension, this time isomorphic to $\mathbb{Z}/2 \oplus \mathbb{Z}/50$ . 
With the ""standard"" carry function $c$ , we can iterate this process: $\mathbb{Z}/1000$ is an extension of $\mathbb{Z}/100$ by $\mathbb{Z}/10$ $\mathbb{Z}/10,000$ is an extension of $\mathbb{Z}/1000$ by $\mathbb{Z}/10$ and so on. It is clear that $\mathbb{Z}$ should be some sort of limit of these groups
(I suspect it is the finitely supported subgroup of the inverse limit, but I haven't formally checked this), and I am curious how to extend this procedure to other groups and other carry functions. Which brings us to my question: If we take as our carrier set $(\mathbb{Z}/10)^*$ and define addition letter by letter, with the regular carry function $c$ , we get $\mathbb{N}$ . However, proving that this operation is associative requires knowledge of how the carries interact, which I'm having trouble adding to my induction. As an example of where things become strange, consider 10 + 81 + 99, using $2c$ as our carry function: associating left gives (10 + 81) + 99 = 91 + 99 = 400 
(since 9+1=0, we carry a 2, 9+9=8, we carry a 2 for the 9+9 and a 2 for the new 8+2 from our old carry) This issue of ""carrying twice"" doesn't come up in the standard carry case, because at any stage we have at most 9+9=18, with a carry is 19, and so we only ever carry 1 or 0. I'm not sure how to handle this in my induction. Answers which generalize to cocycles over other groups are appreciated, as that is where I plan to take this. I'm putting this in the automata theory tag as well, because they might 
be more familiar with methods of proving these sorts of operations associative.","['group-extensions', 'group-theory', 'automata']"
3324542,Is it possible to find the local maximum of $\sqrt[x]{x}$ without using derivative?,"Let $f(x)=\sqrt[x]{x}$ , where $x\in\mathbb{R^{+}}$ Using derivative, $$\frac{d}{dx}(x^{\frac 1x}) = -x^{\frac 1x - 2} (\log(x) - 1)$$ $$f'(x)=0 \longrightarrow x=e$$ $$\text{max}\left\{\sqrt[x]{x}\right\}=\sqrt[e]{e}$$ But,I'm looking for a way, which is doesn't include derivative.","['real-numbers', 'maxima-minima', 'calculus', 'functions', 'derivatives']"
3324562,Real roots of $ 1+\frac{x}{1!}+\frac{x^2}{2!}+\frac{x^3}{3!}+\cdots +\frac{x^n}{n!} $ [duplicate],"This question already has answers here : Find the number of real roots of $1+x/1!+x^2/2!+x^3/3! + \ldots + x^6/6! =0$. (10 answers) Closed 4 years ago . Let $Q_n(x)$ be the degree $n$ polynomial $$ 1+\frac{x}{1!}+\frac{x^2}{2!}+\frac{x^3}{3!}+\cdots +\frac{x^n}{n!} $$ How many real roots does the equation $Q_n(x)=0$ have? My attempt: It is obvious that $Q_n(x)$ will have all its real roots in the negative part of the real line if there is any. Also, we notice that if $n$ is odd, then there is at least one real root by the complex conjugate root theorem . So I conjecture that there is exactly one root for $n$ odd and there is no root for $n$ even. However, I don't know how to analyze $Q_n(x)$ . All I can do is to take derivative and this does not provide more useful information. Any hint is appreciated! Thanks.","['algebra-precalculus', 'roots', 'polynomials', 'real-analysis']"
3324579,Sorting collinear Points on a 3D Line,"I have a list of points in 3 space that are all collinear.  I need to sort the list of points so I may process them in order.  I don't care or we don't have a choice which end of the line we start from since the line directions vary and there is no sense of beginning or end--they are lines!  However, I will have many lists of collinear points that will be parallel to each other and I would like the sort method to yield sorting them in the same direction. An early attempt, which is flawed, was to pick one of the points in the list and compute distance (magnitude) to all other points and then use this distance to sort. However, that might only work if the chosen point was on one end or the other.  Thanks",['geometry']
3324617,Understanding Addition inference Rule,"Studying Discrete Structures, Logic, And Computability by James L. Hein , came across this proof. On line 3, the author uses that rule to get $A v B$ . Two questions arose: Is it possible to introduce a variable that was not mentioned in the Premises ? What would be the reasoning behind that ? Is it possible to introduce a variable that was mentioned in the Premises with the opposite truth value (negated if it wasn't or vice versa) ?","['natural-deduction', 'logic', 'discrete-mathematics']"
3324662,"Derivative of $\int_0^tf(x,t)dx$?","Derivative of $\int_0^tf(x,t)dx$ ? Fundamental theorem of calculus works for $\int_0^tf(x)dx$ $$\frac{d}{dt}\int_0^tf(x)dx=f(t)$$ but how about this case?","['integration', 'multivariable-calculus', 'calculus', 'derivatives']"
3324731,probability picking parts no replacement,"In a bin containing 30 parts, 27 parts are good and 3 parts are defective. a) What is the probability that if you select 3 parts randomly, without replacing the parts in the bin, from the bin that you will have 1 defective part? I thought of $\dfrac{\dbinom{27}{1}\dbinom{26}{1}\dbinom{3}{1}}{\dbinom{30}{1}\dbinom{29}{1}\dbinom{28}{1}}$",['probability']
3324787,An algebraic solution for $\log_3(x+1)+\log_2(x)=5$,"The logarithmic equation $$\log_3(x+1)+\log_2(x)=5$$ has an obvious solution, namely $x=8$ . However, I can't seen to find an algebraic demonstration/deduction of this fact. This has been an ""unsolvable"" problem for me since my early days in elementary/middle school. Any solution not relying on inspection would be appreciated. EDIT: Driven by @TobyMak's comments: The main issue here is that this problem was supposed to be solved by a middle school student. Using analysis and knowing beforehand that $x=8$ solves the equation does the job. I would like to know if there are finite algebraic steps which lead to the result.","['algebra-precalculus', 'logarithms']"
3324793,$\operatorname{Spec}k[\epsilon]/(\epsilon^2)$ and $\operatorname{Spec}k[x]_{(x)}$ are both one point,"I'm working through professor Vakil's book on algebraic geometry, which I recommend (it can be found at https://math.stanford.edu/~vakil/216blog/FOAGjun1113public.pdf ). I'd like to check my answers to Exercises 3.2.A(a) and 3.2.A(b). 3.2.A(a) Describe $\operatorname{Spec}k[\epsilon]/(\epsilon^2)$ . Answer: since the prime ideals of the quotient ring $R/\mathfrak{a}$ are uniquely determined by the prime ideals of $R$ that contain $\mathfrak{a}$ , a prime ideal of $k[\epsilon]/(\epsilon^2)$ is given by some $\mathfrak{b} \in \operatorname{Spec}k[\epsilon]$ such that $\mathfrak{b} \supset (\epsilon^2)$ . However, since $\mathfrak{b}$ is prime, $\epsilon \in \mathfrak{b}$ . Therefore, $\mathfrak{b} \supset (\epsilon)$ , and as a consequence, $\operatorname{Spec}k[\epsilon]/(\epsilon^2) \simeq \operatorname{Spec}k[\epsilon]/(\epsilon) \simeq \operatorname{Spec}k = \{pt\}$ . 3.2.A(b) Describe $\operatorname{Spec}k[x]_{(x)}$ . Answer: Using corollary 11.20(2) of https://web.mit.edu/18.705/www/13Ed.pdf , the prime ideals of $\operatorname{Spec}k[x]_{(x)}$ are uniquely determined by the prime ideals of $k[x]$ contained in $(x)$ . Assume $\mathfrak{p} \in \operatorname{Spec}k[x]$ is such that $(0) \subsetneq \mathfrak{p} \subsetneq (x)$ . Since $k[x]$ is a PID, $\mathfrak{p} = (xa)$ for some $a \in k[x]$ . However, since $\mathfrak{p}$ is prime and $x \notin \mathfrak{p}$ , $a \in \mathfrak{p}$ . Then $xa\mid a$ so $x$ is a unit, contradiction. We conclude $\operatorname{Spec}k[x]_{(x)} \simeq \{(x)\}$ . I will appreciate any comments! :)","['algebraic-geometry', 'ring-theory', 'proof-verification', 'commutative-algebra']"
3324796,How to differentiate a parametrised curve lying on a surface,"I would like to ask how to differentiate a curve lying on a regular parametrised surface. I came across several questions that involve a curve lying on a surface. Differentiating the parametrised curve was necessary to prove the statements. My teacher gave us the following theorem (or definition?) as a 'clue' but I am struggling to understand why this is true. $\vec r$ ' = $\vec x $$_u$$\cdot$ u'+ $\vec x$$_v$$\cdot$ v' i.e., Let $\vec x$ (u, v) = (f $_1$ (u,v), f $_2$ (u,v), f $_3$ (u,v)) be a regular parametrised surface and $\vec r$ (t) = $\vec x$ (u(t), (v(t)) be a curve lying on the surface Then, $\frac{d\vec r}{ds}$ = ( $\frac{df_1(u, v)}{du}$$\cdot$$\frac{du}{dt}$ + $\frac{df_1(u, v)}{dv}$$\cdot$$\frac{dv}{dt}$ , ..., ...) = $\vec x $$_u$$\cdot$ u'+ $\vec x$$_v$$\cdot$ v' I understand the chain rule, but I don't quite understand why the two derivatives of vector are added together.
Is it possible that this is because the following is (might be?) true: $\vec r$ (u, v) = $\alpha$$\vec r$$_u$ + $\beta$$\vec r$$_v$ where they are linearly independent? I am new to this and am still struggling with vector differentiation. I know this question may sound stupid but try not to laugh... Your help will be greatly appreciated. :)","['multivariable-calculus', 'differential-geometry']"
3324810,Field contained in a division ring lies in the center of the ring,"Given a division ring $R$ . A field $F$ is contained in $R$ . Show that $F \subseteq Z(R)$ . I think this statement is correct, but I find it difficult for me to prove it. I am aware of the fact that for a division ring $R$ , the center of $R$ , $Z(R)$ is a field.",['abstract-algebra']
3324825,How to change the limits of given integral,"I need to evaluate the following integral : $$\int_{ -1}^1\int_{1+x}^1\cos\left(x+y\right)e^{(y-x)}dydx$$ I know that I need to change the variables by using substitution $u = x+y$ and $v =y-x$ but I am confused about changing the limits of the new integral , I am trying to get the limits by drawing the graph of given limits in (x,y) and then , draw the corresponding graph in u-v plane using given equation, But I am still not getting it . Can please someone explain on how to change limits of this integral, and how should I proceed while tackling such problems of the same kind ? Thank you","['integration', 'multivariable-calculus']"
3324826,why with least squares I get a minimum?,"I was reading about least squares method and every book I read just said that we can get the minimum value solving a equations system. For example. If I have $$
Q=\sum(Y_i-\beta_0-\beta_1X_i)^2
$$ then solving this $$
\frac{\partial Q}{\partial \beta_0}=0
$$ $$
\frac{\partial Q}{\partial \beta_1}=0
$$ We get a minimum value. But my question is how I know that the solution is a minimum and not a maximum nor a saddle point?","['linear-regression', 'optimization', 'statistics', 'least-squares']"
3324854,How to draw $4$ touching circles,I am trying to figure out a way for drawing $4$ touching circles like this: Would appreciate help of any kind.,"['euclidean-geometry', 'circles', 'geometry']"
3324949,Limiting expectation of a uniformly integrable local martingale.,"Assume that $M = (M_t)_{t\geq 0}$ is a uniformly integrable continuous local martingale with $M_0 \in L^1$ and $\lim_{t\to\infty} M_t = M_\infty$ almost surely. By Fatou's Lemma we know that $E[M_\infty] \leq E[M_0]$ . Question: What are equivalent conditions for the equality $E[M_\infty] = E[M_0]$ to hold? More information: A necessary condition for the above condition to hold is that $M$ is a (uniformly integrable) martingale. Moreover, Novikov's and Kazamaki's criterion provide sufficient conditions. Also, I am mostly interested in the case where $M$ is non-negative (and therefore automatically a supermartingale; then the equality actually holds iff $M$ is a martingale).","['stochastic-processes', 'local-martingales', 'martingales', 'probability-theory', 'stochastic-calculus']"
3324954,"Find the number of permutations of the set $\left\{ 1,2,3,4,5,6,7\right\}$ not containing four consecutive elements of ascending order","Find the number of permutations of the set $\left\{ 1,2,3,4,5,6,7\right\} $ not containing four consecutive elements of ascending order. My try: All permutations in cycles are $6!$ . Let's deal with cases that do not meet the requirements of the task: When four growing elements are not at the beginning: - choice of beginning: ${3 \choose 1}$ - choice of four numbers ${6 \choose 4}$ So: $${3 \choose 1}\cdot {6 \choose 4}\cdot 2!=90$$ When four growing elements are at the beginning: $${6 \choose 3}\cdot 3!=120$$ Then we must count cases common to the previous two considerations: $${6 \choose 4}\cdot2!=30$$ That is why my answer is: $$6!-90-120+30=540$$ However I wrote a Python program to check the number of solutions and he says it's $342$ so I have a mistake. Can you help me and tell me what I'm doing wrong?",['combinatorics']
3324991,Is this relation a transitive one?,"$$A = \{1, 2, 3, 4\}$$ Is the relation x > y on $A$ transitive? If yes please explain why it is so. There will be the pair (2,1) as 2 > 1. However y being 1 will have no other pair (y,z) as 1 is the smallest number in the set $A$ . So the condition
for the relation to be transitive: $\forall x,y,z \in A : x R y \land y R z \implies x R z$ . will return false as there will be no $y R z$ pair to satisfy the whole condition. Is my thinking right?","['elementary-set-theory', 'relations']"
3325001,Doubt in finding the general term and sum of $n$ terms of the series $1+5+19+49+101+181+295+\dots+T_n$?,"The following image has both the problem and its solution. I have a doubt in the solution, the details of which I have included below the image. Here, the author has assumed $T_n$ as an arbitrary cubic equation (Step indicated by the RED box). My doubt is, why has he assumed it as a cubic equation and not a quadratic or biquadratic equation or any other degree equation? Kindly clarify my doubt.",['sequences-and-series']
3325034,Quadrilaterals that has congruent opposite sides is parallelograms,"Quadrilaterals that has congruent opposite sides is parallelograms. The following is a proof. for quadrilateral ABCD, AB = CD, BC = AD, AC = AC hence ABC = CDA (SSS) mBAC = mDCA (alternate interior angle theorem) hence AB // DC mACB = mCAD (alternate interior angle theorem) AD // BC (Q.E.D) but, I don't know why D, B is opposite by line AC for the alternate interior angle theorem. How to prove it? How to prove that ABCD is convex?","['quadrilateral', 'euclidean-geometry', 'proof-writing', 'geometry']"
3325042,The subset of the positive reals has no smallest element,"There is statement in the book : ""The subset $ A =\{\frac{1}{n} : n \in \mathbb{N} \} $ of the positive reals has no smallest $ n $ element because for any $ x_0 = \frac{1}{n} \in A $ that we might pick, there is always a smaller element $ \frac{1}{n+1} \in A $ ."" And the book said it is false. But I found similar questions ( first , second , third ) that prove the statement. Is the book wrong and the statement is truth?","['elementary-set-theory', 'proof-explanation', 'order-theory', 'proof-verification']"
3325051,"Understanding a corollary based on dominating product measures for the joint density: $(X,Y)$, if $Y=g(X)$","I recently came across this statement in page 627 of ""Theory of Statistics"", by Schervish. If $Y = g(X)$ , then the joint distribution of (X,Y) is not dominated by a product measure, even if the distribution of $X$ is dominated. I have tried to pour some time into understanding this but: I currently have no intuition as to why this should be so? How come conventional product measures would not work on this joint space? How come a joint density written with these constraints ( $Y = g(X)$ ), is not dominated even if $X$ is dominated? In addition to this, he states to consider a measurable space: $(\mathcal{Y},\mathcal{B}_2)$ a measurable space such that $\mathcal{B}_2$ contains all singletons What is implied by this? If a measurable space is Borel does it not already contain the singleton elements? Or does he mean a space with exclusively singleton elements? What does he mean to capture by saying this so explicitly. For context, the following is the extract of the text, with the two parts which I would like to better understand: EDIT: Problem 7 on page 662:","['measure-theory', 'probability-theory', 'intuition', 'products']"
3325081,To prove topologically not same,"The sets $A=\{ (x,y) \in \mathbb{R}  \;|\; xy=0 \text{ and } x+y \geq 0 \}$ $B=\{ (x,y) \in \mathbb{R}  \;|\; xy=0 \} $ are not homeomorphic. In $A$ if we remove the origin  it becomes $2$ pieces, in $ B$ it comes $4$ . Is there any other way to prove this?",['general-topology']
3325123,Proving Map with Order Condition is Group Morphism,"Let $(G, \circ)$ and $(H,\ast)$ be groups. Suppose $G$ is cyclic with a order $n \in \Bbb N $ and $g$ is a generator.  Let $ h \in H$ be an element with $\text{order}(h)\ |\ n$ . Show that the map $\phi: G \rightarrow H $ determined by $\phi(g)= h $ is a group homomorphism. I tried this way: Take $x,y \in G$ then there are $r,s \in \mathbb{Z}$ such that $x = g^r $ and $ y =g^s$ . Next $\phi( g^r\circ g^s)= \phi(g^{r+s})= \phi(g)^{r+s}= h^{r+s}=h^r\ast h^s = \phi(g)^r \ast \phi(g)^s= \phi(g^r) \ast \phi(g^s)$ . So I did not use the fact that $\text{order}(h) \ |\ n$ . So I must be wrong somewhere. Someone who can point it out for me? Thanks in advance!","['group-homomorphism', 'group-theory', 'abstract-algebra', 'cyclic-groups']"
3325185,Find all the integral solutions to the equation $323x+391y+437z=10473$,Find all the integral solutions to the equation $323x+391y+437z=10473$ . I know how to find integer solutions in two variables using Diophantine Equations. But I am stuck here because it involves 3 variables. Can I get a hint?,"['number-theory', 'elementary-number-theory']"
3325231,Can a countable set contain uncountably many infinite subsets such that the symmetric difference of any two such distinct subsets is finite?,"There is a similar topic about finite intersections and the constructs for that case are pretty clear (for example, limits of real numbers approached by monotonically increasing sequences of rational numbers). But, is that the case for finite symmetric differences? It not obvious at all for me... What the construct can be if it is possible (is it possible to find the bijection between almost disjoint family and a family of sets with finite symmetric differences)? What's the counter-example if it's not?",['elementary-set-theory']
3325240,How to divide a number from both sides of from congruence equation from $79^{80}\equiv 1 \pmod{100}$ to $79^{79}\equiv x \pmod{100}$?,"This problem is to solve $79^{79} \equiv x \pmod{100}$ . I'm aware this may be solved by binomial expansion or other methods. But when we apply Euler's theorem we obtain $79^{80} \equiv 1 \pmod{100}$ , which seems to be very close to our goal. I just need to divide 79 from both sides. Now I can do this using a stupid method: by subtracting 100 from LHS to obtain -99, -199, -299,... until ""X99"" is divisible by 79. I then find that $79 \times(-81)=-6399$ . So we obtain $79^{80} \equiv -6399 \pmod{100}$ and divides 79 on both sides as 79 is coprime of 100. This gives me $79^{79}\equiv-81\equiv19 \pmod{100}$ . My question is if there is a more systematic/standard way of carrying out a division on both sides, perhaps something related to ""inverse"" etc. A group theory/ring theory approach is welcome as well.","['number-theory', 'abstract-algebra', 'modular-arithmetic']"
3325250,Another proof of reflexive Hilbert spaces,"Here is the proof that every Hilbert space is refexive: Let $\varphi\in\mathcal{H^{**}}$ be arbitrary. By Riesz, there is a unique $f_\varphi\in\mathcal{H^*}$ with $\varphi(f)=\langle\,f,f_\varphi\rangle$ for all $f \in\mathcal{H^*} $ . Using the same notation and theorem, we have $\hat{y}_{f_\varphi}(f)= f(y_{f_\varphi})=\langle\,y_{f_\varphi},y_f\rangle=\langle\,f,f_\varphi\rangle=\varphi(f)$ This implies $\hat{y}_{f_\varphi}=\varphi$ , thus $\mathcal{H}$ reflexive. I understood all the steps except for the last implication. Basically, we just showed that $2$ functionals from bi-dual space $\mathcal{H^{**}}$ are the same, why would it imply that $\mathcal{H}$ is reflexive? Any explanation would be highly appreciated!","['hilbert-spaces', 'functional-analysis']"
3325284,Is this true for all polynomials,"I took $3$ random polynomials with non zero roots one having even degree and two having odd degrees $f(x)=\color{red}{4}x^2-(4\sqrt3+12)x+12\sqrt3$ having roots $\color{blue}{3,\sqrt3}$ and leading coefficient $\color{red}{4}$ and calculated values of $xf'(x)$$(f'(x)$ is the derivative of $f(x))$ at both roots which are $3f'(3)$ and $\sqrt3f'(\sqrt3)$ and then sum of their reciprocals $\frac1{3f'(3)}+\frac1{\sqrt3f'(\sqrt3)}=\frac{-1}{12\sqrt3}=\frac{-1}{\color{red}{4}}\left(\frac{1}{\color{blue}{3\cdot\sqrt3}}\right)$ then repeated same thing for $g(x)=\color{red}{1}x^3-\frac{20}{3}x^2-12x+\frac{32}{3}$ having roots $\color{blue}{8,-2,\frac{2}{3}}$ $\frac1{8g'(8)}+\frac1{-2g'(-2)}+\frac1{\frac{2}{3}g'(\frac2 3)}=\frac{1}{\color{red}{1}}\left(\frac{1}{\color{blue}{8\cdot-2\cdot\frac2 3}}\right)$ $h(x)=\color{red}{1}x^5+41x^4+137x^3-1601x^2-1818x+3240 $ having roots $\color{blue}{1,-2,5,-9,-36}$ $\frac1{1h'(1)}+\frac1{-2h'(-2)}+\frac1{5h'(5)}+\frac1{-9h'(-9)}+\frac1{-36h'(-36)}=\frac{1}{\color{red}{1}}\left(\frac{1}{\color{blue}{1\cdot-2 \cdot5\cdot-9\cdot-36}}\right)$ Is this true for all polynomials? Is there any known result?",['calculus']
3325302,How big can the Hausdorff dimension of the closure of a smooth curve be?,"Consider curves in $\mathbb{R}^n$ . Smooth curves have Hausdorff dimension $1$ . The closure of a smooth curve can have Hausdorff dimension $> 1$ .
(For example, a curve dense in a torus.) How big can the Hausdorff dimension of the closure of a smooth curve be? (Can it be $> 2$ ? For instance, can there be a smooth curve dense in a solid torus?)","['curves', 'general-topology', 'dimension-theory-analysis', 'differential-geometry']"
3325311,number of binary solutions under linear restrictions,"I am interested in the following counting problem: Consider $x_1,\dots,x_n\in\{0,1\}$ . How many solutions exist under the restriction that $Ax=b$ , where $A$ is a $m\times n$ matrix with binary entries and $b_i\in \{0,\dots,n\}$ . Note that this counting problem might be related to the case where there is only one restriction (see for example How many solutions to $x_1 + x_2 + x_3 + x_4 + x_5 = 21$ given the following restrictions ... .). However, I am unable to generalize the ideas used here for the problem described above. If anyone has an idea how to approach this problem or is able to point me in the direction of a paper which solves something similar, I would appreciate it greatly. Thanks in advance.","['combinatorics', 'binary-programming', 'reference-request']"
3325340,"Verify the following limit using epsilon-delta definition: $ \lim_{(x,y)\to(0,0)}\frac{x^2y^2}{x^2+y^2}=0$","Show that $$ \lim\limits_{(x,y)\to(0,0)}\dfrac{x^2y^2}{x^2+y^2}=0$$ My try:
We know that, $$ x^2\leq x^2+y^2 \implies x^2y^2\leq (x^2+y^2)y^2 \implies x^2y^2\leq (x^2+y^2)^2$$ Then, $$\dfrac{x^2y^2}{x^2+y^2}\leq x^2+y^2 $$ So we chose $\delta=\sqrt{\epsilon}$","['limits', 'calculus', 'epsilon-delta']"
3325375,Let $f(z)=\frac{\bar z^2}{z}$ when $z\neq 0$ and $f(0)=0$. Show that $f'(0)$ does not exist.,"Let $f(z)=\frac{\bar z^2}{z}$ when $z\neq 0$ and $f(0)=0$ . Show that $f'(0)$ does not exist. $$f'(0)=\lim_{z \to 0} \frac{f(z)-f(0)}{z-0}=\lim_{z \to 0} \left( \frac{x-iy}{x+iy}\right)^2$$ Reaching the origin along the line $y=mx$ , we get $$f'(0)=\lim_{x \to 0} \left( \frac{x-imx}{x+imx}\right)^2=\left( \frac{1-im}{1+im}\right)^2$$ Since this value depends on $m$ , the derivative takes different values along different paths and hence does not exist. Is this right and what are other ways to do this?","['proof-verification', 'complex-analysis', 'limits', 'derivatives', 'complex-numbers']"
3325376,Group where for each $d \ \big|\ |G|$ there is unique subgroup of order $d$,"Let $(G,\cdot)$ be a finite group with $\Bbb N \ni n\ge 2$ elements. Prove that if for every divisor $d$ of $n$ there is a unique subgroup of $G$ which has $d$ elements, then $(G,\cdot)$ is a cyclic group. Solution : Consider the sets $M_d=\{a\in G| \operatorname{ord} a=d\}$ . Any two of these sets are disjoint and they form a partition of $G$ . We have $M_d \neq \emptyset \iff \exists$ a cyclic subgroup of $G$ of order $d$ . Let's denote this subgroup by $H_d$ . According to the hypothesis, $H_d$ is the unique subgroup of order $d$ of $G$ . $\implies M_d=\{a \in G \mid \langle a\rangle=H_d\}$ , so $|M_d|=\phi(d)$ . We have that $n=\sum\limits_{d|n}|M_d|=\sum\limits_{d|n}\phi(d)$ , which is true, so there will exist a cyclic subgroup of $G$ of order $n$ . Hence, $(G,\cdot)$ is cyclic. I came up with this solution after I read the solution of a similar problem and I tried to use the same reasoning to solve this problem. I think that the reasoning itself is sound, but I feel that there may be a few issues with my solution. I am basically assuming that none of the sets $M_d$ is empty and I don't think that is correct. Intuitively, it is , because the sets $M_d$ form a partition of $G$ and if one of them is empty, then they no longer form a partition. But I don't think that it is necessary for them to form a partition, so one of them may as well be empty and, as a result, my reasoning is flawed. A friend suggested that I should just change $|M_d|=\phi(d)$ to $|M_d|\le \phi(d)$ (which is obviously true) and then I would have that $n=\sum\limits_{d|n}|M_d| \le \sum\limits_{d|n}\phi(d)=n$ , which would imply that every set $M_d$ is not empty, so $H_d$ exists and the desired conclusion is reached. To me, this seems true, but I would like to know if it really is and if there are any other better ways to repair the flaw in my solution. Edit: Is it possible that I may not actually be assuming that $M_d$ is non-empty? What I mean is : it is true that $M_d=\{a \in G \mid \langle a\rangle=H_d\}$ (it is true because if there are to be elements of order $d$ , then they will be a generator of that cyclic subgroup of order $d$ ).From here I get that $|M_d|=\phi(d)$ , so since the sets $M_d$ form a partition I reach the equality $n=\sum\limits_{d|n}|M_d|=\sum\limits_{d|n}\phi(d)$ , which is true, so from here I would get that every $M_d$ is non-empty and the conclusion would follow. Does this work?","['finite-groups', 'group-theory', 'abstract-algebra', 'proof-verification']"
3325382,How to check if a function is convex,"According to a calculus book I have been reading, we call a function $g(x)$ a convex function if $$g(\lambda x +(1-\lambda)y) \leq \lambda g(x) +(1-\lambda)g(y)$$ , for all $x,y$ and $0<\lambda<1$ . But if I have to check if a given function is convex or not,this definition seems hard and impractical to use. So,my question is, is there any easier way of checking convexity of a function and if there is,then why it is equivalent to this defiinition. Thanks in advance!","['self-learning', 'calculus', 'functions', 'real-analysis']"
3325440,Loss of a randomized decision rule,"I am looking into the Wikipedia article with the topic Randomised decision rule . In the ""Definition and interpretation"" section, I see the formula of randomized loss: $$L(\theta,d^*)=\int_{A\in\mathcal{A}}d^*(x,A)L(\theta,A)dA$$ where $\mathcal{A}$ is the action space. What bothers me is that the action space can be anything, not necessarily a subset of real numbers, so it does not make senseto integrate with respect to an action. Can anybody help me to make sense out of this? EDIT: After looking into several books, including Lehmann, I'm ashamed to admit that I still not understand the domain, codomain and the (joint?) measurability details of the above.","['decision-theory', 'statistics', 'probability']"
3325457,Understanding Convolution in K-Theory via an example,"I've spent lots of time in Chriss and Ginzburg's ""Complex Geometry and Representation Theory"" and despite convolution (in Borel-Moore homology or K-theory) being very central, I feel like I'm still lacking a little understanding. I'd like some help with the following example. On the representation theory side, I'd like to consider the following simple example. Let $G=SL_2(\mathbb{C})$ , and let $T \subset B$ be the toral subgroup of diagonal matrices and the Borel subgroup consisting of upper triangular matrices respectively. Let $V_{\Lambda_1}$ denote the irreducible representation of highest weight $\Lambda_1$ . Taking the tensor square of this representation yields the following decomposition into irreducibles: $V_{\Lambda_1} \otimes V_{\Lambda_1} \simeq V_{2 \Lambda_1} \oplus V_0$ . I'd like to geometrize this a la Ginzburg. Via Borel-Weil, we know that $H^{0}(G/B, L_{\Lambda_1}) \simeq V_{\Lambda_1}$ , where $L_{\Lambda_1}$ is the associated bundle $G \times_{B} \mathbb{C}^{-\Lambda_1}$ . What I would like is an operation on $G$ -equivariant sheaves which corresponds to the tensor product of representations, so that $H^0(G/B, L_{\Lambda_1} * L_{\Lambda_1}) \simeq V_{2 \Lambda_1} \oplus V_0$ . Note that the operation cannot be the tensor product. To see this, remember that $G/B = \mathbb{P}^1$ , and $L_{\Lambda_1}$ is isomorphic to $\mathscr{O}_{\mathbb{P}^1}(1)$ ; if I tensor this sheaf with itself and take global sections I will get the irreducible 3-dimensional representation $Sym^2(V_{\Lambda_1})=V_{2\Lambda_1}$ . Here is where I know that $*$ is supposed to be convolution, as defined by Ginzburg. (If anyone would like the definition, I can provide it, but that would lengthen this post even more). Question 1: Is it correct to expect that $\mathscr{O}_{\mathbb{P}^1}(1) *\mathscr{O}_{\mathbb{P}^1}(1) \simeq \mathscr{O}_{\mathbb{P}^1}(2) \oplus \mathscr{O}_{\mathbb{P}^1}$ ? This is the only way I can see the global sections giving me the correct representation. Question 2: If this is indeed the case, is there an explicit description in terms of global sections $T_1, T_2$ of $\mathscr{O}_{\mathbb{P}^1}(1)$ , if the coordinates on $G/B=\mathbb{P}^1$ are $[T_1:T_2]$ ? It is easy to get the global sections $T_1^2, T_1T_2, T_2^2$ as a basis for $V_{2 \Lambda_1}$ , but I cannot see how to get the basis for $\mathscr{O}_{\mathbb{P}^1}$ . I've got more thoughts, but I think this is already quite long for a post. Please let me know if I can provide any additional information.","['algebraic-geometry', 'representation-theory']"
3325467,solve the functional equation $f(x+t)-f(x-t)=4xt$,"I think this question might be related with arbitrary functions, but I’m not sure. I also tried to set $t$ to different values but couldn’t get it to work.
I tried to set $t=x$ and end up with $f(2x)=f(0)+4x^2$ , $f(x)=f(0)+x^2$ .","['functional-equations', 'functions', 'proof-verification']"
3325481,"initial value problem $y'=-y^2, y(1)= \sqrt{2}$","hey I cant seem to solve this at all, not sure how you do it with no x values $$y'=-y^2, y(1)= \sqrt{2}$$","['initial-value-problems', 'ordinary-differential-equations']"
3325492,"Test for zeros in [0,1] of polynomial in $\mathbb{Z}[x]$","I'm looking for a general non-constructive way (I assume there isn't a constructive way in general) to test if a polynomial with integer coefficients has a zero in [0,1]. I am aware of the rational root theorem, but I don't believe this is useful in all cases. Could anyone point me toward literature on this subject? Or directly tell me if such a test is possible and/or what it is? This question can be approached in many ways - sorry if I have tagged incorrectly!","['algebraic-geometry', 'polynomials', 'analysis']"
3325526,How can we construct radical axis of 2 circles where one is inside the other one?,How can we construct radical axis of 2 circles where one is inside the other one? For example in this case. On this web site http://mathafou.free.fr/pbg/sol139.html they construct one but it's not explained.,"['power-of-the-point', 'euclidean-geometry', 'geometry', 'geometric-construction']"
3325533,A challenging geometry proof?,"Given: $C$ on $\overline{AB}$ such that $BC=3AC$ and $m\angle B=2m\angle XCB$ . To show: $AX=2AC+BX$ I have verified this result with trigonometry and analytic geometry and double-checked my work with GeoGebra.  But it seems like such an elegant result that there should be a purely geometric proof.  Any ideas? I was inspired to investigate this diagram trying to solve a different problem here on MSE.  As far as trying to come up with a proof on my own I tried constructing $M,N$ on $\overline{AX}$ such that $AM=AC$ and $NX=BX$ and drawing some isosceles triangles. That might be fruitful (since you'd only have to show $AM=MN$ ), but nothing leapt out at me quickly.","['euclidean-geometry', 'proof-writing', 'conic-sections', 'geometry']"
3325535,Number of solutions to the equation $x_1+x_2+x_3+x_4=19$ with $0\leq x_i\leq 8$ [duplicate],"This question already has answers here : Counting bounded integer solutions to $\sum_ia_ix_i\leqq n$ (5 answers) Closed 1 year ago . Find the number of solutions to the equation $x_1+x_2+x_3+x_4=19$ with $0\leq x_i\leq 8$ . I know that I should use inclusion-exclusion, but I don't quite see why. If I had this problem: Find the number of solutions to the equation $x_1+x_2+...+x_5=10$ with
  no restrictions to $x_i$ : The solution to this would be $14 \choose 10$ (like a stars-bars problem). Back to the first problem, I see why can't use that... Let's say I want to solve something equivalent such as: $(x_1+8)+(x_2+8)+(x_3+8)+(x_4+8)=19$ with no restrictions to $x_i$ . That would be $x_1+x_2+x_3+x_4=-13$ which doesn't make sense as I'm working with natural numbers. Can someone explain me why inclusion-exclusion applies to this? I understand the theorem but I don't get why I should use it on this.","['proof-explanation', 'inclusion-exclusion', 'combinatorics', 'discrete-mathematics']"
3325585,When does $e^{hD}$ give a well defined operator on analytic functions?,"Let $D$ denote the differentiation operator. It is a classic result that $e^{cD}f(a)=f(a+c)$ if $f(x)$ is an analytic function and the radius of convergence of the Taylor series of $f(x)$ at $x=a$ is bigger than $c$ .  More generally, if $T$ is a linear operator on an algebra satisfying $T(ab)=T(a)b+aT(b)$ and $S=e^T$ is well defined (e.g., if $T$ is locally nilpotent or the algebra has a norm and $T$ is bounded), then $S(ab)=S(a)S(b)$ .  This implies that if $f$ is an analytic function, and if everything actually makes sense, then $S(f(a))=f(S(a))$ . In particular, if $T=h(x)D$ and $S=e^{h(x)D}$ , then defining $g(x)=S(x)$ (the left hand side is a function of $x$ , the right hand side is an operator applied to the identity function) satisfies $S(f(x))=f(g(x))$ , at least when things work out and everything is well defined. Question: What conditions on $h$ or $f$ make things work out, i.e., turn this formal argument into a rigorous argument? Some observations.  If $T(f)=\lambda f$ , then $e^T(f)=e^{\lambda}f$ , and if $h(x)f'(x)=\lambda f(x)$ , then $f(x)=e^{\lambda \int 1/h(x) dx}$ .  If we set $H(x)=\int 1/h(x) dx$ , then this implies that $H(g(x))=1+H(x)$ .  If this functional equation has no solution, or if the solution was not analytic, that would show that $e^{hD}$ was not a well defined operator, but short of that, I don't see a good approach to the problem.  Trying to get an explicit formula just seems too messy.","['complex-analysis', 'operator-theory', 'functional-analysis', 'real-analysis']"
3325599,(X×Y)∖(A×B)= ((X\A)×Y)∪(X×(Y\B))?,"I am solving the following equation out of a book: (X×Y)∖(A×B)= ((X\A)×Y)∪(X×(Y\B)) However i have strong doubts that this is a typo since i am getting a different result everytime. Can someone check my logical connections and see if im right or if i am wrong? Let (x,y)∈ ((X×Y)∖(A×B)) Definition of \ applied ⇔(x,y) ∈ (X×Y) ^ (x,y)∉ (A×B) defintion of × applied ⇔ (x∈X ^ yεY) ^(x∉A ^ y∉B) (Now i will demand  (x∈X ^ yεY)  twice) ⇔  (x∈X ^ yεY) ^  (x∈X ^ yεY)  ^ (x∉A ^ y∉B) (Commutation and assosication applied) ⇔ x∈X ^ x∉A ^ y∈Y ^ x∈X ^ y∈Y ^ y∉B Definition of \ and defintion of × applied ⇔ (x,y)∈ ((X\A)×Y) ^ (x,y)∈ (X×(Y\B)) defintion of × applied ⇔(x,y)∈ (X\A)×Y) ∩ (X×(Y\B)) Thus follows  ((X×Y)∖(A×B))=(X\A)×Y) ∩ (X×(Y\B)) I tried to get the other direction to equal the first in order to check if they wrongly typed  ∪ instead of ∩ however i gave up since it got really compliated.",['elementary-set-theory']
3325606,How to evaluate $\int_0^1\frac{\ln x\ln^2(1-x)}{1+x}dx$ in an elegant way?,"How to prove, in an elegant way that $$I=\int_0^1\frac{\ln x\ln^2(1-x)}{1+x}dx=\frac{11}{4}\zeta(4)-\frac14\ln^42-6\operatorname{Li}_4\left(\frac12\right)\ ?$$ First, let me show you how I did it \begin{align}
I&=\int_0^1\frac{\ln x\ln^2(1-x)}{1+x}\ dx\overset{1-x\ \mapsto x}{=}\int_0^1\frac{\ln(1-x)\ln^2x}{2-x}\ dx\\
&=\sum_{n=1}^\infty\frac1{2^n}\int_0^1x^{n-1}\ln^2x\ln(1-x)\ dx\\
&=\sum_{n=1}^\infty\frac1{2^n}\frac{\partial^2}{\partial n^2}\int_0^1x^{n-1}\ln(1-x)\ dx\\
&=\sum_{n=1}^\infty\frac1{2^n}\frac{\partial^2}{\partial n^2}\left(-\frac{H_n}{n}\right)\\
&=\sum_{n=1}^\infty\frac1{2^n}\left(\frac{2\zeta(2)}{n^2}+\frac{2\zeta(3)}{n}-\frac{2H_n}{n^32^n}-\frac{2H_n^{(2)}}{n^22^n}-\frac{2H_n^{(3)}}{n2^n}\right)\\
&=2\zeta(2)\operatorname{Li}_2\left(\frac12\right)+2\ln2\zeta(3)-2\sum_{n=1}^\infty\frac{H_n}{n^32^n}-2\sum_{n=1}^\infty\frac{H_n^{(2)}}{n^22^n}-2\sum_{n=1}^\infty\frac{H_n^{(3)}}{n2^n}
\end{align} By substituting $$S_1=\sum_{n=1}^\infty \frac{H_n}{n^32^n}=\operatorname{Li}_4\left(\frac12\right)+\frac18\zeta(4)-\frac18\ln2\zeta(3)+\frac1{24}\ln^42$$ $$
S_2=\sum_{n=1}^{\infty}\frac{H_n^{(2)}}{{n^22^n}}=\operatorname{Li_4}\left(\frac12\right)+\frac1{16}\zeta(4)+\frac14\ln2\zeta(3)-\frac14\ln^22\zeta(2)+\frac1{24}\ln^42$$ $$S_3=\sum_{n=1}^\infty\frac{H_n^{(3)}}{n2^n}=\operatorname{Li_4}\left(\frac12\right)-\frac{5}{16}\zeta(4)+\frac78\ln2\zeta(3)-\frac14\ln^22\zeta(2)+\frac{1}{24}\ln^42$$ along with $\operatorname{Li}_2(1/2)=\frac12\zeta(2)-\frac12\ln^22$ we get the closed form on $I$ . Note that $S_1$ , $S_2$ and $S_3$ can be found here , here and here respectively. Now we can see how boring and tedious our calculations are as we used results of three harmonic series with powers of 2 in the denominator. A friend ( who proposed this problem ) suggested that the integral can be done without using harmonic series, so any idea how to do it that way? Thanks","['integration', 'definite-integrals', 'polylogarithm', 'sequences-and-series', 'riemann-zeta']"
3325619,An equation involving multisets,"For multisets $A, B, C, A', B', C'$ , if $A \uplus B \uplus \{B \uplus C\} \uplus \{A \uplus \{C\}\}$ = $A' \uplus B' \uplus \{B' \uplus C'\} \uplus \{A' \uplus \{C'\}\}$ , must $A=A',B=B',C=C'$ , where $\uplus$ denotes mutliset sum as defined here https://oeis.org/wiki/Multisets#Multiset_sum EDIT: Here's why I'm interested in this question. In simply relationally typed higher-order languages following Orey ""Model Theory for the Higher Order Predicate Calculus"" (1959), predicates have different syntactic types, which are identified with sequences of types. The idea is that, if a predicate is of type $\langle t_1,\dots,t_n\rangle$ , then it combines with $n$ arguments respectively of types $t_1,\dots,t_n$ in that order to form a formula. I'm interested in how to think about higher-order languages like this except where, intuitively, the argument-places of predicates are unordered; to form a formula by combining a predicate with some arguments you can't just list the arguments -- instead (simplifying somewhat) you biject arguments with argument-places of the predicate. In this framework, types of predicates aren't identified with sequences of types, but with multisets of types, since multisets are basically unordered sequences. The reason I'm interested in the particular equation above is that, in thinking about how to do combinatory logic in such a higher-order language, it turns out that the analogue of what are usually called B combinators end up having types of the above form, and I'm interested in whether these combinators, in this setting, are uniquely determined by their types, or whether there could be distinct B-like combinators of the same type. (Intuitively, such a combinator of type $A \uplus B \uplus \{B \uplus C\} \uplus \{A \uplus \{C\}\}$ can combine with arguments $a_1,...,a_n$ the multiplicity of the types of which is $A$ , $b_1,...,b_m$ the multiplicity of the types of which is $B$ , a predicate of type $\{B \uplus C\}$ , and a predicate of type $\{A \uplus \{C\}\}$ to form a formula. For example, if $A=B=C=\{e\}$ (where $e$ is the base type of individuals), the relevant B-like combinator will be analogous to the simply relationally-typed lambda-term $\beta := (\lambda x^ey^eX^{\langle e,e\rangle}Y^{\langle e,\langle e\rangle\rangle}.Yx(\lambda z^e.Xyz))$ , which combines with terms $a$ and $b$ of type $e$ , a predicate $R$ of type $\langle e,e\rangle$ , and a predicate $S$ of type $\langle e, \langle e\rangle\rangle$ , to form a formula $\beta abRS$ which we can think of as saying that individual $a$ stands in relation $S$ to the property of being $R$ -related to individual $b$ .)","['combinatory-logic', 'multisets', 'higher-order-logic', 'type-theory', 'elementary-set-theory']"
3325621,Solution verification on homework problem. Separable first order ODE IVP.,The answer is supposedly $y^2 = 1 + \sqrt{x^2 - 16}$ I don't know where I went wrong cause I know for a fact that my substitution of $x = 4 \sec(\theta)$ is correct. I know for a fact that after substitution the integral becomes $\int \sec^2(\theta)= \tan(\theta)+C$ . I am pretty sure that my substitution of $\tan(\theta)$ is correct. Am I missing something? $2y \frac{dy}{dx} = \frac{x}{\sqrt{x^2 - 16}}  \space \space \space y(5)=2$ $\int 2y \space dy = \int \frac{4\sec(\theta)}{\sqrt{(4\sec(\theta))^2-16}}\space d(\theta)$ $y^2 = \int \frac{4\sec(\theta)}{\sqrt{(\sec^2(\theta)-1)16}}\sec(\theta) \ tan(\theta)$ $y^2 = \frac{4\sec(\theta)}{4\tan(\theta)}\sec(\theta)\tan(\theta)$ $y^2 = \int sec^2(\theta)$ $y^2 = \tan(\theta) + c$ Using the reference triangle: Tangent is equal to $\frac{\sqrt{x^2-16}}{4}$ $y^2= \frac{\sqrt{x^2-16}}{4} + C$ $4 = \frac{3}{4}+ C$ $C = \frac{15}{4}$ $y^2= \frac{\sqrt{x^2-16}}{4} + \frac{15}{4}$,"['calculus', 'proof-verification', 'ordinary-differential-equations', 'fundamental-solution']"
3325634,Finding the True Mean: How to solve this?,"This is the last question I have to ask for a project at my university, I have until the 20th of August to answer this, but I have been staring at it all week and have found no clues that I can understand in the book provided to me by the university. I'm bordering on desperate now. Can packaging of a healthy food product influence child´s desire to consume the product? This was the question of interest in an article published in the Journal of Consumer Behaviour (Vol. 10, 2011). A fictitious brand of a healthy food product – sliced apples- was packaged to appeal to children (a smiling cartoon apple was on the front of the package). The researchers showed the packaging to a sample of 408 school children and asked each whether he or she was willing to eat the product. Willingness to eat was measured on a 5-point scale, with 1 = “not willing at all” and 5 = “very willing”. The data are summarized as follows: x-bar = 3.69, s = 2.44. Suppose the researchers knew that the mean willingness to eat an actual brand of sliced apples (which is not packaged for children) is µ = 3. a) Conduct a test to determine whether the true mean willingness to eat the brand of sliced apples packaged for children exceeded 3. Use α = 0.05 to make your conclusion. (2.5 points) b) The data (willingness to eat values) are not normally distributed. How does this impact (if at all) the validity of your conclusion in part a)? (0.5 points) So basically I need the answer to this. I have tried everything I can remember and I find nothing. I'm certain it has something to do with a hypothesis test for the true mean, but I lack the knowledge on how to properly solve it, or if it is the Z-value or the T-value or something else they are asking me to provide. I tried using this formula:     Z=(3.69-3)/(2.44/√408)=5.71. And then I realised that I didn't even use the α =0.05 that part A demands I use.","['statistics', 'normal-distribution', 'hypothesis-testing']"
3325649,"Find $\frac{d \rho}{d x}$ for $\rho = \rho(t,x(t),p(t))$","I got a question relating to this thread difference between implicit, explicit, and total time dependence Considering the reply in the top by Kostya, I konw what is the difference between $\frac{\partial \rho}{\partial t}$ and $\frac{d \rho}{d t}$ . What I want to know is what is $\frac{d \rho}{d x}$ for a function $\rho = \rho(t,x(t),p(t))$ ? In my opinion, we have $$\frac{{d\rho }}{{dx}} = \frac{{\partial \rho }}{{\partial t}}\frac{{dt}}{{dx}} + \frac{{\partial \rho }}{{\partial x}}$$ , if $x$ and $p$ are independent variables. But if that is the case, I get another confusion about integration by parts in calculating an integration in calculate time evolution of ensemble average so i guess I got some misunderstanding","['calculus', 'derivatives']"
3325673,Question about confidence intervals for the ratio $\frac{\sigma^2_x}{\sigma^2_y}$,"Hello I have already one problem that stipulates: Consider two independent random samples $\mathsf{X_1,X_2,\ldots,X_n}$ and $\mathsf{Y_1,Y_2,\ldots,Y_m}$ from the respective normal distribution $N(\mu_x,\sigma^2_x)$ and $N(\mu_y,\sigma^2_y)$ where the four parameters are unknown. Given $0<\alpha<1$ , the problem asks to find some expressions for the random variables $L$ and $U$ such that $$P\left(L<\frac{\sigma^2_x}{\sigma^2_y}<U\right) = 1-\alpha$$ If someone might check on this my work please: I have that $$ \displaystyle\frac{\frac{\frac{(m-1)S_y^2}{\sigma^2_y}}{(m-1)}}{\frac{\frac{(n-1)S_x^2}{\sigma^2_x}}{(n-1)}}= \frac{\sigma^2_x\,S^2_y}{\sigma^2_y\,S^2_x} \sim F(m-1,n-1)$$ has Fisher distribution with $m-1 \,\text{and}\,n-1$ degrees of freedom where $S^2_x\, \text{and}\,S^2_y$ are the respective sample variances. So, $$P\left(L<\frac{\sigma^2_x}{\sigma^2_y}<U\right) = 1-\alpha$$ $$ P\left(L\frac{S^2_y}{S^2_x}<\frac{\sigma^2_x\,S^2_y}{\sigma^2_y\,S^2_x}<U\frac{S^2_y}{S^2_x}\right) = 1-\alpha$$ $$f_{1-\frac{\alpha}{2}}(m-1,n-1) = L\frac{S^2_y}{S^2_x}\quad \Longrightarrow L = \frac{S^2_x}{S^2_y}\frac{1}{f_{\frac{\alpha}{2}}(n-1,m-1)}$$ and $$f_{\frac{\alpha}{2}}(m-1,n-1) = U\frac{S^2_y}{S^2_x}\quad \Longrightarrow U = \frac{S^2_x}{S^2_y}\,{f_{\frac{\alpha}{2}}(m-1,n-1)}$$ Is this alright? or have I mistakes? please if somebody may help me thank you in advance.","['confidence-interval', 'statistics', 'probability-distributions', 'parameter-estimation']"
3325676,Question about Set within Set,"I got the following sets: A= { { 1 , 3 , 5 , 7 , 9 } , { 1 , 2 , 3 } , 1 , 2 , 3 , 4 , 5 } B= { 1 , 3 , 5 , 7 , 9 } I'm a bit confused. What would A ∩ B be?",['elementary-set-theory']
3325678,"Integral involving hypergeometric function $\int_0^1[{}_2F_1(\frac13,\frac23;1;x^3)]^2dx$","Question: How to prove $$I=\int_0^1\bigg[{}_2F_1\left(\frac13,\frac23;1;x^3\right)\bigg]^2dx=\frac{\sqrt3}{32\pi^5}\Gamma\left(\frac13\right)^9?$$ Source : An integral competition post of my country. Attempt Recall the series definition of hypergeometric function $$_2F_1(a,b,c,x)=\sum_{n=0}^\infty\frac{(a)_n(b)_n}{(c)_nn!}x^n,$$ we can transform $I$ into the series form $$I=\sum_{n,m=0}^\infty\frac{(a)_n(a)_m(b)_n(b)_m}{(c)_n(c)_mn!m!(3n+3m+1)}$$ But I can not handle this series. I also thought of using complex method. $$I=\int_0^1\bigg[{}_2F_1\left(\frac13,\frac23;1;x\right)\bigg]^2\frac{x^{-2/3}}3dx$$ then let $f(z)=\bigg[{}_2F_1\left(\frac13,\frac23;1;z\right)\bigg]^2(-z)^{-2/3}$ and use keyhole contour, where $(\cdot)^{-2/3}$ is the principal branch of the multi-valued function. But the nature of the branch of the integrand in the inteval $[1,\infty)$ is too complex for me to handle. It involves another definite integral which is similar to $I$ .","['integration', 'definite-integrals', 'special-functions', 'modular-forms', 'hypergeometric-function']"
3325679,Computer the flux of $\nabla \ln \sqrt{x^2 + y^2 + z^2}$ across an icosahedron centered at the origin,"Let $S$ be the surface of an icosahedron centered at origin) and let $$f(x,y,z)=\ln \sqrt{x^2+y^2+z^2} .$$ Calculate the flux $$\iint_S (\nabla f \cdot n) d\sigma,$$ where $n$ is the outward unit normal vector on $S$ . [My attempt] I tried to use divergence theorem. $$\iint (\nabla f \cdot n) d\sigma = \iiint (\nabla \cdot \nabla f ) dV ,$$ where $(\nabla \cdot \nabla f ) = \frac{1}{x^2 + y^2+z^2}$ . However, I can't find a parametrization of the icosahedron to find the triple integral. How to find this value?","['multivariable-calculus', 'calculus', 'surface-integrals']"
3325684,Combinatorial Argument for Exponential and Logarithmic Function Being Inverse,"Consider the following two generating functions: $$e^x=\sum_{n=0}^{\infty}\frac{x^n}{n!}$$ $$\log\left(\frac{1}{1-x}\right)=\sum_{n=1}^{\infty}\frac{x^n}{n}.$$ If we live in function-land, it's clear enough that there is an inverse relationship between these two things. In particular, $$e^{\log\left(\frac{1}{1-x}\right)}=1+x+x^2+x^3+\ldots$$ If we live in generating-function-land, this identity is really not so obvious. We can figure out that the coefficient of $x^n$ in $e^{\log\left(\frac{1}{1-x}\right)}$ is given as $$\sum_{a_1+\ldots+a_k=n}\frac{1}{a_1\cdot \cdots \cdot a_k}\cdot \frac{1}{k!}$$ where the sum runs over all ways to write $n$ as an ordered sum of positive integers. Supposedly, for each choice of $n$ , this thing sums to $1$ . I really don't see why. Is there a combinatorial argument that establishes this?","['combinatorics', 'generating-functions']"
3325757,Finding the geometric progression based on the given details,"The sum of infinite number of terms of a GP is 4, and the sum of their cubes is 192. Find the series. The following image is solution from my book. My doubt is why is $r=-2$ rejected? Is there any reason. If so please tell me.",['sequences-and-series']
3325763,How many ways are there to arrange 4 letters from “combinatorics”?,How many ways are there to arrange 4 letters from “combinatorics”? So I’m studying about combinatorics and permutations. And I stuck with this question. So I just doing my own step but I want to make sure that it’s correct or not. thank you very much and sorry about my bad grammar :),"['permutations', 'combinatorics']"
3325771,"If $\mathbf{R}$ is an upper triangular matrix, then does $\|\mathbf{R}\| \le \|\mathbf{R} + \mathbf{R}^T\|$ hold?","Let $\mathbf{R}\in\mathbb{R}^{n\times n}$ be upper triangular and $\|\cdot\|$ be the induced 2-norm of matrices.
Then, does $\|\mathbf{R}\| \le \|\mathbf{R} + \mathbf{R}^T\|$ hold?",['linear-algebra']
3325818,Are decompositions of a random variable into a sum of two IID random variables unique?,"Let $Z$ be a real-valued random variable, and suppose that $Z = X_1 + X_2$ where $X_1$ and $X_2$ are i.i.d. random variables. Suppose further that $Z = Y_1 + Y_2$ where $Y_1$ and $Y_2$ i.i.d. random variables. Does it follow that $Y_1$ and $X_1$ are identically distributed? I've looked into indecomposable distributions and infinitely divisible distributions, but could not find a result/example immediately answering the above question.","['characteristic-functions', 'independence', 'probability-distributions', 'probability-theory', 'probability']"
3325820,Largest consecutive integer using basic operations and optimal digits?,"If you are first time reading this , you may want to read the summary section last. Solution summary and questions Sequence values If the allowed operations are $(+,-,\times,\div)$ and parentheses $(\space)$ , then the $f(n)$ is the number of consecutive integers we can make starting at $1$ , given $n$ ""digits"" that each needs to be used exactly once. Equivalently, it is the largest integer we can make such that all smaller integers $\in\mathbb N$ can be made as well. The $d$ is (optimal?) digit set used, where $d=\{d_1,\dots,d_n\}=(d_1,\dots,d_n)\in\mathbb N^n$ . So far I have the following data given $n=1,\dots,5$ digits to use (best so far): \begin{array}{ccccccc}
n & 1&2&3&4&5&6\\
f(n)& 1 & 3 & 10 & 52 & 351 & ? \\
d & \{1\} & \{1, 2\} & \{1, 2, 4\} & \{2, 3, 4, 22\} & \{3, 6, 8, 12, 37\} & ? 
\end{array} The $1,3,10$ are optimal. The $52$ entry is probably optimal, but I'm not sure if this can be proven. The $f(5)\ge 351$ can be obtained using $\{3, 6, 8, 12, 37\}$ . I don't think it can be better. Notice the weird similarity to the $A052446$ sequence. Pure coincidence? $Q_1$ : Is there any reason to suspect $f(4)=52,f(5)=351$ aren't the optimal solutions? I haven't computed $f(n)$ for $n\ge6$ significatnly, I do not know how to do it efficiently. There is a similar sequence such that $A142153(n-1)$ $\approx f(n)$ . The main difference being that linked sequence does not require all digits to be used when building a single number, giving it more freedom and expected larger terms than my sequence. The offset $(n-1)$ is due to it starting at $n=0$ . $Q_2$ : Can we find (compute) significant (lower bounds) $f_d(n)$ for $n\ge 6$ ? I've found so far $f_d(6)\ge 2200$ using $d=\{2, 10, 13, 30, 49, 56\}$ . This was done with a simple c++ search checking random digit sets: run it on repl.it . I want to thank user TheSimpliFire for helping me run the code for $f(6)$ . - The goal was to reach $f(6)\gt 3000$ if possible, but it looks hard unless the search can be optimized. Lower bound ""Weak"" lower exponential bound is known: $f(n)\gt 2^{n/3}$ . This is based on a related problem that allows only $1$ 's and $(+,\times)$ . - ""Complexity of $n$ "". This can be imporoved: We can using $d=\{1,2,4,\dots,2^{n-1}\}$ , show that the following lower bounds hold: $f(n)\ge 2^n-1,n\ge 1$ , which confirms optimal $f(1),f(2)=1,3$ . $f(n)\ge 2^n+2,n\ge 3$ , which confirms optimal $f(3)=10$ . $f(n)\ge 2^n+10,n\ge 4$ , which gives sub-optimal $f(4)\ge26$ . Twice less than $f(4)=52$ . These bounds not hard to construct since this $d$ set has nice inductive properties. But I haven't noticed a pattern that can be generalized to all $n$ . It looks hard. The best we can do with this set $d=\{d_i=2^{i-1},i=1,\dots,n\}$ of digits is: $$f(n)\ge f_{d}(n)= 2^n-1+g(k)$$ where $g(k)=0,0,3,11,45,533\dots$ for $n\ge k$ where $k=1,2,3,4,5,6,\dots$ $Q_3:$ The $2^n$ grows slower than $g(k)$ , for large $n$ . Can we demystify $g(k)$ in terms of $n$ ? Equivalently, What is the smallest number that can't be made using powers of two? Seems $f_d(n)=2^n+g(k)\ll f(n)$ for large $n$ for this $d=\{d_i=2^{i-1},i=1,\dots,n\}$ . Notice this $d$ is optimal for $n\le 3$ . Can we find better digit sets for $n\ge 4$ ? $Q_4:$ What's a better set $d$ for which we can show higher lower bounds, in terms of on $n\ge 4$ ? Problem Up to how many consecutive integers $\in\mathbb N$ , can be made using only the four basic
  operations: $+$ addition, $-$ subtraction, $\times$ multiplication, $\div$ division Given $n$ numbers (""digits"") as building blocks, if parentheses are allowed? The goal is to build all integers from $1$ to $N$ , while maximizing $N$ , for given $n$ amount of digits. We are given $d\in\mathbb N^n$ natural numbers (""digits"") to work with. We define $f_d(n)$ as maximal $N$ reachable using digits $d$ , and $f(n)$ as maximal $f_d(n)$ , given $n$ . Example Lets take $n=4,f_d(4)$ for example. We can try using $d=\{4,4,4,4\}$ four fours, \begin{array}{}
1 &= (4 + 4 - 4) \div 4 \\
2 &= 4 - ((4 + 4) \div 4)  \\
3 &= (4 + 4 + 4) \div 4 \\
4 &= ((4 - 4) \times 4) + 4 \\
5 &= ((4\times4)+4)\div4 \\
6 &= ((4 + 4) \div 4) + 4 \\
7 &= 4 - (4\div4 - 4) \\
8 &= (4 + 4 + 4) - 4\\
9 &= (4\div4 + 4) + 4
\end{array} And see that $f_{\{4,4,4,4\}}(4)=9$ , because if you try hard enough, $10$ can't be made! This means that $f(4)\ge f_d(4)= 9$ is at least nine. We probably need a better set of digits $d$ to use, to make $10$ and beyond. Definitions The digit set $d$ allows duplicate digits, and exactly $n$ digits ( elements ), and all digits ( elements ) must be used exactly once . Given a fixed set of $n$ digits $d=\{d_1,\dots,d_n\}$ , we can construct consecutive integers from $1$ to $N\in\mathbb N$ using the basic operations and parentheses, but we can't construct $N+1$ . Then we define the value $f_d(n)=N$ . Then we can define $f(n)=\max f_d(n)=N_{\text{max}}$ , for $d\in\mathbb N^n$ . That is, maximized $N$ obtained by using the optimal set of digits $d=\{d_1,\dots,d_n\}$ for a given case of using $n$ digits. How to efficiently calculate, practically prove, $f(n)$ for given $n$ ? The sets of digits are not ordered, so naturally: WLOG we can assume $d_1\le d_2\le \dots \le d_n\implies d_n=\max\{d_1,\dots,d_n\}$ . Keep this in mind. Clarifications All integers $1,2,3,\dots,N$ must be constructed ; Using all digits from digit set $d$ exactly once. ""Concatenation"" is not allowed . That is, combining digits like $\{1,1\}$ to make $11$ is forbidden. We are after optimal $d=\{d_1,\dots,d_n\}$ that will allow us to construct the longest such sequence by applying the basic operations $+,-,\times,\div$ to the given digit set, when talking about maximal $N$ . Solving small cases Cases $n=1,2$ Trivially, $f(1)=1$ for $d=\{1\}$ , since we can't apply binary operations to a single digit. It can be easily seen that $f(2)=3$ is best, using optimal digits set $d=\{1,2\}$ , here: $$\begin{array}{}
1 &= 2 - 1 \\
2 &= 2 \times 1 \\
3 &= 2 + 1 \\
\end{array}$$ This is optimal: Since if we are given $d=\{d_1,d_2\}$ , if not $d_2-d_1=1$ or not $d_1=d_2$ , we can't make $1$ , thus $f_d(2)=0$ in these $d$ cases. And we can't make $2$ unless they either add up to two, differ by two, or one is two times other. The only case that also extends to $3$ , is the $d=\{1,2\}$ making this $f(2)=3$ proof easy. Case $n=3$ It can be shown $f(3)=10$ if you observe enough cases. It can be seen that $f_d(3)= 3$ at best, if $d_3$ is too large. I have checked the rest (small enough) cases computationally. The optimal set is $d=\{1,2,4\}$ and the solutions can be seen below: $$\begin{array}{}
1 = 4 - (1 + 2) \\
2 = 4 - (1 \times 2) \\
3 = (1 - 2) + 4 \\
4 = (2 - 1) \times 4 \\
5 = 4 - (1 - 2) \\
6 = (1 \times 2) + 4 \\
7 = (1 + 2) + 4 \\
8 = (1 \times 2) \times 4 \\
9 = 1 + (2 \times 4) \\
10 = (1 + 4) \times 2 \\
\end{array}$$ Case $n=4$ The $f(4)=52$ is a conjectured solution, using $d=\{2,3,4,22\}$ . The previous records are $f_{\{1, 2, 5, 6\}}(4)=43, f_{\{1, 2, 5, 8\}}(4)=51$ . I have checked all $d_4\lt 64$ , and tabulated maximal $N=y$ for subsets of digits such that $d_4=x$ : Is it possible to prove $f(4)=52$ ? Update: I extended the calculations to $d_4\le 100$ and the $52$ indeed seems to be optimal. A similar problem to $f(4)$ , but roots and exponentiation are allowed, was asked . Computing larger cases Cases $n\ge 5$ Is it possible to set up bounds or make progress in calculating these cases? If not, can we optimize the computation? I'm running a brute force search. For this result, all sets of digits with $d_5\le 15$ have been checked with record being $f_{\{2, 8, 9, 12, 13\}}=271$ . But this is going on too slow in my python code to extend further. (Code based on this four fours solver .) So I've decided to not brute force all sets, but try ones with $d_1,d_2=1,2$ or $d_1,d_2=2,3$ and $d_3\le d_4/2$ , for $d_5\ge 20$ . I've reached $d_5=45$ so far, with these restrictions on $d_1,d_2,d_3$ . This is where $f_{\{2, 3, 7, 8, 38\}}=324$ was found: seen solutions . Update: I've implemented the search in c++ which is faster now. I've checked all digits up to $d_5 \le 35$ so far, where the best was $f(5)=333$ . I've also checked a restricted search where $d_5\le 120$ but $d_4\le 12$ so far, which is where the newest $f(5)=351$ was found. I've also checked a restricted search where $d_5\le 60$ but $d_4\le 24$ so far,  with no better results. Growth of $f(n)$ ? Can we analyse and give bounds on growth of $f(n)$ ? The best I have so far is: using $d_i=2^{i-1}$ to show $f(n)\gt 2^n,n\gt 2$ . Here is ""weak"" linear bound (explicit construction) example to get inspired: Weak linear lower bound (explicitly constructive) For $d$ , we pick $\{1,\dots,1\}$ all $1$ 's. We can then make $1,\dots,2n-4$ easily: $$\begin{array}{}
1 &= (1+1)-(1\times1\times\dots\times 1) &= 2 - 1\\
2 &= (1+1)\times(1\times1\times\dots\times 1) &= 2 \times 1\\
3 &= (1+1)+(1\times1\times\dots\times 1) &= 2 + 1\\
4 &= (1+1)+1+(1\times1\times\dots\times 1) &= 2 + 1 + 1\\
\dots & & \\
n &= (1+1)+(1+1+1+\dots+ 1) &= 2 + (n-2) \\
n &= (1+1)\times(1+1)+(1+1+\dots+ 1) &= 2\cdot2 + (n-4) \\
n+1 &= (1+1)\times(1+1+1)+(1+\dots+ 1) &= 2\cdot3 + (n-5) \\
n+2 &= (1+1)\times(1+1+1+1)+(1+\dots+ 1) &= 2\cdot4 + (n-6) \\
\dots & & \\
2n-4 &= (1+1)\times(1+1+1+\dots+ 1) &= 2(n-2) + (n-n)
\end{array}$$ We have now shown $f(n)\ge 2n-4$ with this trivial digit set. Note that this works if we replace $(1+1)$ with $(d_n\div d_{n-1})$ if $d_{n-1}=d_n/2$ , so we also have an infinite family of digit sets that can achieve at least $2n-4$ , since $d_n\in\mathbb N$ can be any digit. Perhaps instead of $(1+1)$ , we can use this and pick $d_n/2=2n-3$ to continue the construction? Note that we could also replace other $1$ 's with similar substitutions and keep the initial construction still valid. Can we do better with this idea, and show it is better than exponential bound given below? This idea was discussed by user @Countingstuff in the comments (second-by-date comment). Exponential lower bound (based on a related problem) The bound is ""weak"" due to ignoring $(-,\div)$ operations, and due to using only $1$ 's as digits. Lets restrict the problem to only $(+,\times)$ operations, and define this restricted $\overline{f}(n)$ . We have: $$
f(n)\ge \overline{f}(n)
$$ By definition. For $\overline{f_d}$ , optimal $d$ consists of pure $1$ 's, since otherwise, $N=1$ can't be made. Now this becomes related to the "" Complexity of natural number $n$ "" problem. That is, $a(N)$ - minimal number of $1$ 's for expressing $N$ using $1$ 's and $+,\times$ . Now, this has known bounds: $3\log_2N \ge a(N) \ge 3\log_3N$ , $\space$ [R. K. Guy, Unsolved Problems in Number Theory, Sect. F26.]. The upper bound is obtained by expanding $N$ in binary with Horner's algorithm. Improving the upper bound is still an open problem. We will use the upper bound for $a(N)$ to get the ""weak"" lower bound for $f(n)$ . If $N_0$ some number, notice that $a(N_0)$ defines the price of building $N_0$ , in terms of the amount of digits. And since the price $a(N)$ is bounded above by a monotone increasing function, if we can build $N_0$ with at least the bound given amount of digits, we can also build numbers $1,\dots, N_0$ with that many or less digits, thus $N\ge N_0$ . Also, an important fact is that if we can build $N_0$ with $n$ digits, we can build it with $\ge n$ digits as well. This is due to optimal $d$ being a set of $1$ 's for restricted $\overline{f_d}$ , so we can multiply two digits $1$ 's to reduce the case of digits, down to $n$ , for every case $\gt n$ . So, by the definition of $a(N)$ and $\overline{f}(n)$ we have: $$\begin{array}{}
k(N)\ge a(N_0) \implies \overline{f}(k(N_0))\ge N_0 \\
\end{array}$$ So we can use the result on bounds of $a(N)$ to establish: $$
3\log_2N_0 \ge a(N_0) \implies \overline{f}(3\log_2 N_0)\ge N_0 \implies \overline{f}(n)\ge 2^{n/3}
$$ By substitution $n=3\log_2 N_0\implies N_0=2^{n/3}$ . We have obtained: An exponential lower bound for the original problem, $f(n)\ge 2^{n/3}$ follows from $f(n)\ge\overline{f}(n)$ . But note that $f(n)\gt 2^{n/3}$ it actually certainly strict. For example, last two digits can be $d_0,d_0$ where $d_0=\frac12 2^{(n-1)/3}$ . The $(d_0/d_0)=1$ leaves us with $n-1$ case of $1$ 's, so we can reach $2^{(n-1)/3}$ at least. Now use $(d_0+d_0)=2^{(n-1)/3}$ . Now we are left with $n-2$ case of $1$ 's free to use again. Which means we can reach at least $2^{(n-1)/3}+2^{(n-2)/3}\gt 2^{n/3},n\gt 3$ . I believe $f(n)\gg \overline{f}(x)\ge 2^{n/3}$ is actually much greater than this ""weak"" bound. Questions regarding bounds Can we improve this by getting a ""non-weak"", and better bound? - Perhaps use the fact that $(-,\div)$ allows extending the explicit weak linear construction I mentioned earlier? Can we obtain non-trivial upper bounds? A trivial upper bound can be the upper bound on number of (not necessarily consecutive) distinct positive integers that can be built with the given operations and $n$ digits. I'm not sure how I would establish a non-trivial upper bound. - Bound that uses the fact that integers are consecutive. Idea is to find upper bound on the ""hole"" that breaks the consecutive sequence? Update on lower bound The $f(n)\gt 2^n,n\gt 2$ was included in the summary section at the beginning, more details are there. Partial answers answering any point of this question are appreciated.","['number-theory', 'recreational-mathematics', 'combinatorics', 'asymptotics']"
3325837,Again boxes with marbles and strategy,"Let’s consider 3 identical jewelry boxes, one with 2 green marbles, one with 2 blue marbles and last one with one green and one blue.
  Before opening any box we set a target, either to pick two marbles of the same color or different. We then randomly choose a box and then a marble (without seeing its color before choosing it). We then see the color of the marble and put it back to its box. We repeat the process by picking a box (same with the previous or different) and a marble from it (again randomly). Find the probability that we succeed (i.e. if we had chosen to go for “two of the same color”, we indeed got two marbles of the same color, or, if we chose to go for two marbles of different colors, we got two different. We assume that our moves are of absolute logic. Let's assume that we choose to find two marbles of the same color. 
We pick one box (probability $\frac{1}{3}$ ), say we get a green marble (is the (conditional) probability $\frac{1}{2}$ ??), then we must select either the same box again (hoping we will get a marble of the same color - blue probability $\frac{1}{2}$ ) or another box, probability $\frac{1}{2}$ for the box and probability 0 if we pick the box with the two blue marbles, 1/2 if we pick the box with 1+1 and 1 if we pick the box with the 2 green (assuming the one we chose the first time was the 1+1). By intuition only, I think that I must set the target to pick 2 marbles of the same color, as the chances for this are 2/3 overall. I don't know how to continue :(","['combinatorics', 'probability']"
3325838,Can a sequence converges modulo every r>0 but diverge?,"Is it possible to have a sequence $\{x_n\}$ of real numbers which diverge to $\infty$ (and has no other finite limit points), but satisfy the condition that $x_n\pmod{r}$ converges for every real $r>0$ ? I'm aware of related results such as ""the fractional parts of $\{n\alpha\}_n$ are dense in $[0,1]$ (and thus do not converge)"" and more general versions of these statements, giving counterexamples for select values of $r$ . However, I'm wondering if the ""for every $r>0$ "" part of the statement makes the existence of such an $\{x_n\}$ impossible. I feel this is the case, but have been unable to come up with a rigorous proof.","['convergence-divergence', 'ergodic-theory', 'real-analysis']"
3325867,Prove there exists $2011$ consecutive amazing integers,"Recently, I have found this problem: We call a positive integer $n$ amazing if there exists positive integers $a, b, c$ such that the equality $$n = (b, c)(a, bc) + (c, a)(b, ca) + (a, b)(c, ab)$$ holds. Prove that there exists $2011$ consecutive positive integers which are amazing. Here some amazing numbers: In the picture from left to right you find the numbers: $n$ , $a$ , $b$ and $c$ . I have tried to solve this problem in a lot of different ways, for example using the definition of $GCD$ , or divisibility but I can't go on. Any idea? Note:by $(m, n)$ we denote the greatest common divisor of positive integers $m$ and $n$ .","['number-theory', 'gcd-and-lcm', 'divisibility', 'elementary-number-theory']"
3325882,"Given an isometry $F$ between Lie groups, does $dF$ commute with (differentials of) left translations?","Let $G$ and $H$ be Lie groups equipped with left invariant metrics, and let $F \colon G \to H$ be an identity-preserving isometry. Does the differential $dF$ commute with left translations? More precisely, if $v \in T_{e}G$ ( $e$ being the identity element of $G$ ), is it true that $$
\left(L_{F(p)}\right)_{\ast} \left(dF_{e}(v) \right) = dF_{p}\left( \left(L_{p}\right)_{\ast}(v) \right) \,?
$$ EDIT: An equivalent question would be: Is the image of a left invariant vector field under $dF$ also left invariant? I believe this is not true in general, but maybe under some extra assumptions on $G$ or $H$ ?","['group-theory', 'riemannian-geometry', 'lie-groups', 'differential-geometry']"
3325886,Linear subspaces of maximal dimension in a projective quadric.,"Let $k$ be an algebraically closed field of characteristic $\neq 2$ and $Q_r\subset \mathbb P^n_k$ the quadric hypersurface  given by the equation $x_0^2+\cdots+x_r^2=0 \;(0\leq r\leq n)$ in the projective $n$ -space over $k$ with coordinates $x_0, \cdots,x_n$ . Needless to say $Q_r$ is singular if $r\lt n$ . Question: what is the maximum dimension $M=M(n,r)$ of the linear subspaces $L\subset Q_r$ , as a function of $n$ and $r$ ? For example $M(3,3)=1$ , $M(2,1)=1$ and $M(n,0)=n-1$ .","['algebraic-geometry', 'quadrics']"
3325887,Finding $\phi$ so that we have $3$ equal sets,"Find all angles $\phi$ , if any, for which the set $S=\left \{ \sin(\phi),\sin(2\phi),\sin(4\phi) \right \}$ , the set $C=\left \{ \cos(\phi),\cos(3\phi),\cos(9\phi) \right \}$ , and the set $T=\left \{ \tan(\phi),\tan(4\phi),\tan(16\phi) \right \}$ to be three equal sets. What I have noticed; in $S$ , the angles can be arranged to be in geometric progression. Similarly in $C$ and $T$ , but I do not know how is that useful. I could not even start solving this problem. Any help will be appreciated.","['trigonometry', 'geometric-progressions']"
3325912,How visualize a Volume,"I need to calculate some volumes, but I can't because I'm not able to visualize them.I 'm not able to set the integrals. I'm going to show my problem: I have that volume $V:=\{\ \underline{x} \in \mathbb{R^3} : x,y,z \ge 0 ,\ z \le 2-x^2-y,\ z \le x+2y \} \\ \underline{x}:=(x,y,z)$ How can I see it? Should I only use algebra and abandon any visual approach? If yes how? Thanks in advance P.S.
Obviously the tools like Geogebra 3D I don't take them into consideration, I would like to succeed in this without using these tools. I would also like to add that generally if I can see the volume I have no problems with the integral calculation. The problem is all there, sometimes I can see the volume at other times absolutely not!","['integration', 'multivariable-calculus', 'visualization', 'volume']"
3325939,Homotopy Lifting Problem,"$X, \tilde{X}$ are hausdorff, path connected spaces $p:\tilde{X} \rightarrow X$ is a local homeomorphism Under these assumptions we have the following lemma: If $f:Y \rightarrow X$ is continuous, and $Y$ is connected, f has at most one lift with respect to $p$ , that is if $f_1$ , $f_2$ are both lifts with respect to $p$ , then $f_1 = f_2$ or there is no point in $Y$ where $f_1 = f_2$ I want to prove the following: Let $a$ , $b$ be homotopic paths in $X$ (so that in particular $a$ , $b$ have the same starting and endpoints), via the homotopy $F:I \times I \rightarrow X$ , and suppose that $f_t = F(.,t)$ each have lifts $\tilde{f_t}$ with respect to $p$ starting at some $\tilde{x_0} \in p^{-1}(a(0))$ . ( $I$ is $[0,1]$ ) Then the paths $\tilde{f_t}$ are homotopic in $\tilde{X}$ and in particular have a common starting and endpoint. Attempt: So far I have been able to construct a lifted homotopy, $\tilde{F}:[0,\epsilon] \times I \rightarrow \tilde{X}$ via considering a neighbourhood of $\tilde{x_0}$ , $U$ where $p$ is a homeomorphism, then reasoning that $F^{-1}(p(U))$ is open in $I \times I$ and contains ${0} \times I$ , so that $[0,\epsilon] \times I \subset F^{-1}(p(U))$ and $F([0,\epsilon] \times I) \subset p(U)$ for some $\epsilon > 0$ . Then I defined $\tilde{F} = p \restriction_{U}^{-1} \circ F \restriction_{[0,\epsilon]\times I}$ a lift of $F$ on the desired domain. We also have that $\tilde{F} \restriction_{{0}\times I} = \tilde{x_0}$ So I know that the set of all $\epsilon \in I$ such that a lift as constructed above exists is nonempty, and that each lift corresponding to such an $\epsilon$ is unique, so that any other lift is either a continuation or a restriction of this lift (that is any other lift on some domain $[0,\epsilon_1] \times I$ must agree with lifts on domains that are contained within this domain i.e. $\epsilon_2 < \epsilon_1$ ) , which follows by our lemma. I have also been able to show that given such a lift, if $\epsilon < 1$ , we can always construct a continuation of the lift, that is we can find a lift $\tilde{F'}:[0,\epsilon + h] \times I \rightarrow \tilde{X}$ , where $h$ depends on $\epsilon$ ,  but don't have control over how much bigger the continuation of the lift is ( $h$ is dependent on $\epsilon$ ). Which implies that if we can show $\sup A \in A$ , then $1 \in A$ and we are done. I am stuck at this point, as I cannot show that $\sup A \in A$ necessarily.. I would be extremely grateful for any help EDIT:
I should add I am talking about homotopy of paths all throughout this question, no ""free"" homotopies where endpoints of each path in the homotopy are different - In this case any lifted homotopy will have to be a homotopy of paths by virtue of the fact that $p$ is a local homeomorphism, and so the preimage of an endpoint is a discrete set.. so this isn't a major concern, what is the primary trouble is how to construct a valid lifted homotopy on all of $I \times I$","['complex-analysis', 'general-topology', 'algebraic-topology', 'analysis']"
3325956,When a maximal ideal is not contained the union of the others,"Let $R$ be a commutative ring with 1 and $a\in R$ such that $a\not=a^2$ and assume that there is an ideal $I$ of $R$ such that $a\not\in I$ and if $J$ is an ideal of $R$ , then $(a\not\in J)\Rightarrow (J\subseteq I)$ . Set $m:=\{r\in R\mid ra\in I\}$ and assume that $m $ is a maximal ideal. Can we show that $m\not\subseteq \bigcup_{n\in\operatorname{Max}(R)\setminus \{m\}}n$ , where $\operatorname{Max}(R)$ is the set of all maximal ideals of $R$ ? If that is not true under what conditions on $a$ it is true? I am studying zero-dimensional rings in which every prime ideal has the form $m$ as above for some element $a$ .  In the case that $a=a^2$ , then the result is true since then $a$ is a local idempotent and $m$ is the only maximal ideal that contains $1-a$ .  I'm hoping it is still true in general that there is a local idempotent $e$ such that $1-e\in m$ , which would imply the result.","['algebraic-geometry', 'ring-theory', 'abstract-algebra', 'commutative-algebra']"
3325962,Different approaches to calculating angle between two vectors,"I can calculate angle θ between two dimensional vectors a and b as the inverse cosine of their dot product divided by their magnitude: θ = arccos (a · b / (|a| * |b|)), where |a|≠0 and |b|≠0   (1) I have also seen it calculated like this: θ = arctan(a.y / a.x) - arctan(b.y / b.x), where a.x≠0 and b.x≠0  (2) What is the difference between these two approaches and can I derive the first formula from the second or vice versa?","['trigonometry', 'linear-algebra']"
3325992,Number of $1$'s in a binary number,"I'm working on a function $\zeta(\xi)$ that takes as input an integer $\xi$ (in base $10$ ) and calculates how many $1$ 's  there are in its binary representation. How can I write such function? Here is a graph of $\zeta(\xi)$ , for $0\leq\xi\leq250$ , created in Excel: By now, I have tried only brute-forcing: calculate a lot of values of $\zeta(\xi)$ to try to find a common pattern, but this doesn't seem helpful in finding an explicit formula. Any idea?","['binary-operations', 'number-theory', 'binary', 'elementary-number-theory']"
3325995,Is there a integer that makes $e^{\pi\sqrt{n}}$ closer to an integer than 163?,"$e^{π\sqrt{163}}$ is almost an integer about $262537412640768744$ . Let $\delta = -\log_{10}{\left|[x] -x\right|}$ , where $[x]$ means round $x$ . $\delta(e^{π\sqrt{163}}) \approx 12.125$ , I searched for integers less than one million and did not find a larger one. \begin{array}{l|l}
 n & \delta \\
 \hline
 163 & 12.12498077672643 \\
 652 & 9.785848809982161 \\
 1467 & 8.005405448223059 \\
 58 & 6.750100588198867 \\
 2608 & 6.510795060473921 \\
 478233 & 6.336824235216279 \\
 881967 & 6.179002616555315 \\
 880111 & 6.049818696834100 \\
 67 & 5.873691345976712 \\
 160874 & 5.779904075261147 \\
 895056 & 5.744074506024677 \\
 22905 & 5.609682778906657 \\
 674707 & 5.608982629715706 \\
 95041 & 5.548433878234871 \\
 486396 & 5.540950430696813 \\
 343732 & 5.507752498953491 \\
 357711 & 5.478776357709137 \\
 54295 & 5.365357632965891 \\
 613399 & 5.357752793344790 \\
 470884 & 5.281604204081554 \\
\end{array} $163$ is the biggest in class number 1. $652 = 4 \times 163$ , so worse than $163$ . $1467 = 9 \times 163$ , so worse than $163$ . $58 = 232/4$ , where $232$ is class number 2. Then I searched in primes, but seems worse. \begin{array}{l|l}
 n & \delta \\
 \hline
 163 & 12.12498077672643 \\
 67 & 5.873691345976712 \\
 2259143 & 5.594638040601917 \\
 1003957 & 5.559376877231691 \\
 2785649 & 5.506950408472213 \\
 3227963 & 5.506387694695041 \\
 2471017 & 5.031440103309939 \\
 33563 & 4.912614873386113 \\
 719 & 4.894475032853204 \\
 28201 & 4.841231735669607 \\
\end{array} So, is there a integer that makes $e^{\pi\sqrt{n}}$ closer to an integer than 163?","['number-theory', 'pi', 'approximation']"
3326006,Completeness of the weighted $L^2$ space,"Consider the weighted $L^2-$ space defined by $M:=\{z:\mathbb{R}^+\to H^2(\Omega)\cap H^1_0(\Omega);\int_{0}^{\infty}g(s)\|\nabla z(s)\|^2_2ds<\infty\},$ equipped with the inner product $\langle z_1,z_2\rangle=\int_{\Omega}\int_{o}^{\infty}g(s)\nabla z_1(s).\nabla z_2(s)dsdx.$ where $g$ is a positive, non-increasing and $L^1(0,\infty)$ function. I want to show that $M$ is complete. This is my attempt,
Let $(u_n)$ be a Cauchy sequence in $M$ , this implies that $(u_n)$ is Cauchy in $H^2(\Omega)\cap H^1_0(\Omega)$ . But $H^2(\Omega)\cap H^1_0(\Omega)$ is complete, therefore, $u_n\to u\in H^2(\Omega)\cap H^1_0(\Omega).$ But I could not satisfy the condition $\int_{0}^{\infty}g(s)\|\nabla u(s)\|_2^2ds<\infty$ .","['sobolev-spaces', 'functional-analysis']"
3326009,Definiton of expectation of product of random variables,"Let $X,Y:(\Omega,\mathcal F)\rightarrow(\mathbb R,\mathcal B)$ be measurable, i.e. random variables, and $P$ a probability measure on $(\Omega,\mathcal F)$ . What is the precise definition of $E[Z]$ , where $E$ denotes expectation and $Z = X\cdot Y$ . In my undergraduate course we calculated $E[Z]$ by $$E[Z] = E[XY] = \int\int xyf(x,y)\ \mathrm dxd\mathrm y$$ (assuming for a second that exists the density $f$ ). I don't see how we get the double integral. I guess $Z$ is defined on $(\Omega\times\Omega,\mathcal F\otimes\mathcal F)$ ? But what is the corresponding probability measure? How do we know that a measure even exists? Clearly, if $X$ and $Y$ are independent, then the product measure $P\otimes P$ is the corresponding measure and we get $$E[Z] = \int Z\ \mathrm dP\otimes P = \int\int X\cdot Y\ \mathrm dP\mathrm dP$$ by Fubini's theorem.","['expected-value', 'measure-theory', 'probability-theory']"
3326027,How to prove that number of unlabelled binary trees $n$ nodes is given by Catalan number,Suppose i have 1 nodes hence total number of binary trees is 1.Suppose i have 2 nodes then total number of binary trees is 2.Then suppose i have 3 nodes then total number of binary trees is 5. How to prove that for n nodes it is equal to Catalan number i.e total number of unlabelled binary tree with node n is $(2n)! / (n+1)!n!$ .Please provide some easy explanation of derivation since derivations on web seems either little vague or incomplete . For more information of what i am talking about see the article https://www.geeksforgeeks.org/enumeration-of-binary-trees/,"['trees', 'graph-theory', 'combinatorics', 'discrete-mathematics', 'algorithms']"
3326101,Is it possible to utilize the convergence of the sequence $z_{n+1}=a/(1+z_n)$ to prove that the sequence $x_{n+2} = \sqrt{x_{n+1} x_n}$ is convergent?,"I'm doing Problem II.4.6 in textbook Analysis I by Amann/Escher. For $x_0,x_1 \in \mathbb R^+$ , the sequence $(x_n)_{n \in \mathbb N}$ defined recursively by $x_{n+2} = \sqrt{x_{n+1} x_n}$ is convergent. My questions: I'm not sure if my attempt (the parts from Lemma 4 to the end) is fine or contains logical gaps/errors. Could you please verify these parts? Any suggestion is greatly appreciated. Particularly, I'm not sure if my induction in case $m > n$ in the part ""... $\color{blue}{\text{vacuously true}}$ ...""  and the proof that there exists $0 < \beta < 1$ such that $y_{n+1} \le \beta y_n$ are correct or not. There is Problem II.4.5 as follows: For $z_0,a \in \mathbb R^+$ , the sequence $(z_n)_{n \in \mathbb N}$ defined recursively by $z_{n+1}=a/(1+z_n)$ is convergent. Using Mathematica, I found that both of the sequences $(x_n)_{n \in \mathbb N}$ and $(z_n)_{n \in \mathbb N}$ share the same plot as follows. I would like to ask whether it is possible to utilize the convergence of $(z_n)_{n \in \mathbb N}$ to prove the convergence of $(x_n)_{n \in \mathbb N}$ . Thank you so much for your help! My attempt: First we consider the case $x_0 < x_1$ . Lemma 1: $x_{2n} < x_{2n+1}$ for all $n$ . Proof: The statement trivially holds for $n=0$ . Let it hold for some $n$ . We have $$\begin{aligned} x_{2(n+1)} < x_{2(n+1)+1} & \iff x_{2n+2} < x_{2n+3} \\ &\iff \sqrt{x_{2n+1} x_{2n}} < \sqrt{x_{2n+2} x_{2n+1}} \\ &\iff  x_{2n} < x_{2n+2}  \\ &\iff x_{2n} < \sqrt{x_{2n+1} x_{2n}} \\&\iff x_{2n} < x_{2n+1}\quad (\star) \end{aligned}$$ in which $(\star)$ follows from inductive hypothesis. As such, the statement holds for $n+1$ . Lemma 2: $x_{2n} < x_{2n+2}$ for all $n$ . Proof: We have $x_{2n} < x_{2n+2} \iff x_{2n} < \sqrt{x_{2n+1} x_{2n}} \iff x_{2n} < x_{2n+1}$ , which is true by Lemma 1 . As a consequence, $(x_{2n})_{n \in \mathbb N}$ is increasing. Lemma 3: $x_{2n+3} < x_{2n+1}$ for all $n$ . Proof: We have $x_{2n+3} < x_{2n+1} \iff \sqrt{x_{2n+2} x_{2n+1}} < x_{2n+1} \iff x_{2n+2} < x_{2n+1} \iff$ $\sqrt{x_{2n+1} x_{2n}} < x_{2n+1} \iff x_{2n} < x_{2n+1}$ , which is true by Lemma 1 . As a consequence, $(x_{2n+1})_{n \in \mathbb N}$ is decreasing. Lemma 4: $x_{2m} < x_{2n+1}$ for all $m,n$ . Proof: In case $m \le n$ , we have $x_{2m} \overset{(\star)}{\le} x_{2n} \overset{(\star\star)}{<} x_{2n+1}$ in which $(\star)$ follows from the fact that $(x_{2n})_{n \in \mathbb N}$ is increasing, and $(\star\star)$ follows from Lemma 1 . We prove the statement in case $m > n$ by induction on $m$ . It's $\color{blue}{\text{vacuously true}}$ for $m=0$ . Let it hold for some $m$ . We have $$\begin{aligned} x_{2(m+1)} < x_{2n+1} & \iff x_{2m+2} < x_{2n+1} \\ &\iff \sqrt{x_{2m+1} x_{2m}} < x_{2n+1} \\ &\iff  x_{2m+1} x_{2m} < x^2_{2n+1} \quad (\star) \end{aligned}$$ in which $(\star)$ follows from $x_{2m} < x_{2n+1}$ (by inductive hypothesis) and from $x_{2m+1} < x_{2n+1}$ (by $m > n$ and $(x_{2n+1})_{n \in \mathbb N}$ is decreasing). As such, the statement holds for $n+1$ . We define the sequence $(y_n)$ by $y_n := x_{2n+1} - x_{2n}$ . We next prove that there exists $0 < \beta < 1$ such that $y_{n+1} \le \beta y_n$ for all $n$ . $$\begin{aligned} y_{n+1} < \beta y_n &\iff x_{2(n+1)+1} - x_{2(n+1)} < \beta (x_{2n+1} - x_{2n}) \\ &\iff x_{2n+3} - x_{2n+2} < \beta (x_{2n+1} - x_{2n}) \\&\iff \sqrt{x_{2n+2} x_{2n+1}} - x_{2n+2} < \beta (x_{2n+1} - x_{2n}) \\ &\iff \sqrt{x_{2n+2}} (\sqrt{x_{2n+1}} - \sqrt{x_{2n+2}}) < \beta (x_{2n+1} - x_{2n})\end{aligned}$$ Since $x_{2n+2} > x_{2n}$ , $\sqrt{x_{2n+1}} - \sqrt{x_{2n+2}} < \sqrt{x_{2n+1}} - \sqrt{x_{2n}}$ . As such, it suffices to prove that there exists $0 < \beta < 1$ such that $\sqrt{x_{2n+2}} (\sqrt{x_{2n+1}} - \sqrt{x_{2n}}) < \beta (x_{2n+1} - x_{2n})$ . We have $$\begin{aligned} &\sqrt{x_{2n+2}} (\sqrt{x_{2n+1}} - \sqrt{x_{2n}}) < \beta (x_{2n+1} - x_{2n}) \\ &\iff \sqrt{x_{2n+2}} < \beta (\sqrt{x_{2n+1}} + \sqrt{x_{2n}}) \\ &\iff \dfrac{\sqrt{x_{2n+2}}}{\sqrt{x_{2n+1}} + \sqrt{x_{2n}}} < \beta \\&\iff \left( \dfrac{\sqrt{x_{2n+2}}}{\sqrt{x_{2n+1}} + \sqrt{x_{2n}}}\right)^2 < \beta^2  \\ &\iff \dfrac{x_{2n+2}}{x_{2n+1} + 2\sqrt{x_{2n+1} x_{2n}} + x_{2n}} < \beta^2 \\ &\iff \dfrac{x_{2n+2}}{x_{2n+1} + 2x_{2n+2} + x_{2n}} < \beta^2\\ &\iff \dfrac{1}{2+ x_{2n+1}/x_{2n+2} + x_{2n}/x_{2n+2}} < \beta^2  \end{aligned}$$ As a result, we are done if we choose $1/\sqrt{2} <\beta < 1$ . Then $y_{n+1} \le \beta y_n$ and thus $y_{n} \le \beta^n y_0$ for all $n$ . We have $0 \le \lim_{n \to \infty} y_n \le \lim_{n \to \infty} \beta^n y_0 = 0$ . As such, $\lim_{n \to \infty} y_n = 0$ and so $\lim_{n \to \infty}x_{2n} = \lim_{n \to \infty}x_{2n+1} = \alpha$ . From Lemmas 2 , 3 , and 4 , our sequence $(x_n)_{n \in \mathbb N}$ looks like $$x_0 < x_2 < x_4 < \cdots < x_{2n}< \cdots <x_{2n+1} < \cdots <x_5<x_3<x_1$$ By Nested Intervals Theorem, we have $$\lim_{n \to \infty}x_{2n} = \lim_{n \to \infty}x_{2n+1}$$ Next we prove that $$\lim_{n \to \infty}x_{n} = \alpha$$ Approach 1: For $\varepsilon > 0$ , there exists $N \in \mathbb N$ such that $|x_{2n} - \alpha| < \varepsilon$ and $|x_{2n+1} - \alpha| < \varepsilon$ for all $n > N$ . Thus $|x_{n} - \alpha| < \varepsilon$ for all $n > 2N$ . As a result, $\lim_{n \to \infty}x_{n} = \alpha$ . Approach 2: Given $n \in \mathbb N$ , we have $A := \{2k+1 \in \mathbb N \mid k \ge n\} \subseteq B := \{k \in \mathbb N \mid k \ge n\}$ and, for each $k \in B$ , there exists $k' \in A$ such that $x_k \le x_{k'}$ . As such, $\sup_{k \ge n} x_{k} = \sup_{k \ge n} x_{2k+1}$ and thus $\inf_{n \ge 0} \sup_{k \ge n} x_{k} = \inf_{n \ge 0} \sup_{k \ge n} x_{2k+1}$ . Similarly, we have $\sup_{n \ge 0} \inf_{k \ge n} x_{2k} =$ $\sup_{n \ge 0} \inf_{k \ge n} x_{k}$ . It follows that $$\alpha = \sup_{n \ge 0} \inf_{k \ge n} x_{2k} = \sup_{n \ge 0} \inf_{k \ge n} x_{k} \le \inf_{n \ge 0} \sup_{k \ge n} x_{k} = \inf_{n \ge 0} \sup_{k \ge n} x_{2k+1} = \alpha$$ and thus $\lim_{n \to \infty} x_{n} = \alpha$ . The case $x_0 > x_1$ is similar, while the case $x_0 = x_1$ is trivial.","['alternative-proof', 'convergence-divergence', 'sequences-and-series', 'real-analysis']"
3326108,Existence of only finitely many geodesics,"The following question arose from Theorem 16.3 (p.90) in the book Morse theory from John Milnor. We are dealing with a complete Riemannian manifold $M$ , an $a \in \mathbb{R_{>0}}$ and two points $p,q \in M$ which are not conjugate along any geodesic from $p$ to $q$ of length $\le \sqrt{a}$ . Then the question is:
Why are there only finitely many geodesics from $p$ to $q$ of length $\le \sqrt{a}$ . I have already tried arguing this way:
Assume that there are infinitely many geodesics $(\gamma_n)_{n \in \mathbb{N}}$ of the kind spoken of. Since the closed ball $B:=\{ v \in T_pM : \Vert v \Vert \le \sqrt{a}\}$ is compact (by Heine-Borel), there exists a subsequence of the vectors $(\gamma_n(0))_{n \in \mathbb{N}} \in B$ which converges against an $v_\infty \in B$ . The fact that solutions of DGLs depend continuously on the initial value provides that the curve $\gamma_{v_\infty} = exp(t \cdot v_\infty)$ also ends in $q$ . Now the idea is, that this sequence yields a proper, geodesic variation $\alpha:(-\varepsilon, \varepsilon) \times [0,1] \to M$ of $\gamma_{v_\infty}=\alpha(0,-)$ . This would yield a Jacobifield $J=\frac{D}{ds}\alpha(0,t)$ along $\gamma_{v_\infty}$ , which vanishes at $p$ and $q$ , so we get a contradiction to the premise that $p$ and $q$ are not conjugate along any geodesic. Solution : I don't think there is a way to extract uncountably many geodesics of length $\le \sqrt{a}$ , all of which connect $p$ and $q$ . So first of all, to get a variation $\alpha:(-1,1) \times [0,1] \to M$ we may do the following: Let $(v_n)_{n \in \mathbb{N}}$ be the (sub)sequence converging to $v_\infty$ . Set $v:(-1,1) \to B; v\left(\frac{1}{n}\right) := v_n$ for $n \ge 2$ . Then extend $v$ differentiably (i.e. by connecting the $v_n$ through lines and then smoothing the edges out). Finally, set $\alpha(s,t) := exp(t \cdot v(s))$ . As $M$ is complete, this makes sense and is well defined. This certainly is a geodesic variation of $\gamma_{v_\infty}$ . What remains to show is that the vector field $\frac{D}{ds}\alpha(0,t)$ vanishes at $q$ (to get the contradiction from above). Notice, that the $\alpha(s,-)$ mustn't connect $p$ and $q$ for all $s$ , but for $s=\frac{1}{n}$ . Since $\alpha$ is differentiable, we can compute $\frac{D}{ds}\alpha(0,1)$ by choosing the sequence $(s_n=\frac{1}{n})_{n \in \mathbb{N}}$ which yields $\frac{D}{ds}\alpha(0,1) = 0$ since the difference quotient is 0 for all $s_n$ because the $\alpha(s_n,-)$ connect $p$ and $q$ by our assumption.","['morse-theory', 'geodesic', 'differential-geometry']"
3326158,Proof of sub-additivity for Shannon Entropy,"in A Mathematical Theory of Communication (CE Shannon, 1948) , the entropy of a categorical random variable is defined as: $$H(X)=-\sum_{i}P(X=i)\log P(X=i)$$ while the joint entropy of two such variables is defined as: $$H(X,Y)=-\sum_{i,j}P(X=i,Y=j)\log P(X=i,Y=j)$$ Then it is stated (p.12) that ""It is easily shown that"": $$H(X,Y)\leq H(X)+H(Y)$$ with equality for independence. I believe this property is referred to as sub-additivity, and I'm wondering what this ""easy"" way to prove it might be. What I have tried so far: I believe, using the Law of Total Probability, we can get $H(X)+H(Y)=-\sum_{i,j}P(X=i,Y=j)\log (P(X=)P(Y=j))$ which would establish the equality for independence, but I don't know how to get the inequality. That would seem to require $P(X=i,Y=j)\leq P(X=i)P(Y=i)$ which is not always true. I've found a source that proves the inequality using two other properties ( Chain Rule and Dropping the Conditional ). But these are introduced later in Shannon's paper so can't be the ""easy"" proof he had in mind?","['entropy', 'probability']"
