question_id,title,body,tags
968167,Prove that $\text{int(intA)=int(A)}$?,"I want to prove that $\text{int(intA)=int(A)}$ (and we are in metric space). I have two questions regarding this. (1). I came up with this proof but don't know if it's correct or not. First I use one of the results in the book, which claims that ""set $\text{A}$ is open if and only if $\text{A=intA}$. A set is an open set if every points in that set is an interior points, so $\text{int(A)}$ is an open set. So $\text{int(intA)=int(A)}$. (2). Now, I'm thinking about using open balls to do this. It seems fairly easy to prove that $\text{int(intA)}\subset \text{int(A)}$. But I don't know how to go the other way around.","['general-topology', 'elementary-set-theory', 'real-analysis']"
968171,Can the distance between two points equals zero,Can the distance between two point on a plane be zero? I just assumed yes but I have heard the argument no because if the points are in the same location then they are the same point and thus you are not measuring the distance between two points any more.  Others say you cannot have two points occupy the same location.  (Or can two points occupy the same location because they are dimensionless.)  Or can we say the distance is zero by some limiting argument such as point A and point B get closer and closer together the distance between goes to zero. So maybe it is never actually be zero but the limit is zero.,['geometry']
968199,"Why does $E(XY)^2 \le E(X^2)E(Y^2)$ fail to hold for complex $X, Y$?",Does the Cauchy-Schwarz inequality hold only for real vectors? Why is that so?,"['inequality', 'probability', 'expectation']"
968203,A smooth cubic is not rational,"We consider projective curves over the closed field $\mathbb{k}$. It can be proven that the curve is rational iff its genus $g=0$. Also the curve is birationally equivalent to a nonsigular cubic iff its genus $g=1$. This means, in particular, that smooth cubics are not rational. But this proof is not so elementary, I think: it uses the notion of genus, that is rather difficult to introduce (divisors, spaces $L(D)$...). How the statement can be proven without divisors and genus?",['algebraic-geometry']
968209,Is the following subset of a plane connected? (picture),"It's the union of a sequence of interlocked ""chains"" formed from closed semicircles. The chains can be seen having different shades of gray in the picture. There's no line in the middle, just the endpoints of arcs which form the semicircles, else it would be trivial. Connected means it can't be decomposed into 2 nonempty open sets. I think it's not connected, so I thought about taking one semicircle and including all semicircles which intersect small neighborhoods of the original semicircle's endpoints, iterating this process I can get an open subset which is not the entire thing (if the neighborhoods are chosen sufficiently smaller and smaller). But I would need it also to be closed in order to separate it, but I don't see that it has to be.","['general-topology', 'connectedness']"
968244,Identifying the k points in 2D geographic space which are 'most distant' from each other,"I have a set of DNA samples from Y plants in a given geographic area.  I'm going to be doing DNA sequencing on individuals in this population (and a number of other, separate populations), however due to financial constraints I'm unable to perform sequencing on all Y individuals.  I've decided that I can afford to sequence k (out of Y) in each separate area. I'd like to select the k samples which are farthest apart/most geographically distributed within the Y samples I collected.  Samples that are taken from plants in close proximity to each other are more likely to be closely related, and I'd like to sequence what are ultimately the most genetically diverse samples for my later analysis. So, the question is: given a set of Y points/samples in 2d geographic space (lat/long coordinates), how do I select the k points that are most geographically distributed/distant from each other? As I've explored this a bit, I think the problem I'm really having is how to define 'distance' or 'most distributed'.  Some of the metrics I've though of (e.g. maximum average distance between the k points) result in really unintuitive point selection in certain cases (for example, if two points are right next to each other but far away from another cluster of all the other points, the two points will be included even if they're almost on top of each other). I have a feeling that this is not an uncommon problem, and there must be good answers out there.  I'll add that I have access to a large cluster and I can brute force the problem to some extent. I'd appreciate any and all advice or discussion; this is an interesting theoretical topic to me.","['statistics', 'graph-theory', 'clustering']"
969257,Non-Metrizable Topological Spaces,"What are some motivations/examples of useful non-metrizable topological spaces? I am trying to get a feel for what parts of math have topologies appear naturally, but not induced by a metric space. Also, it would be cool and informative if you could list some basic topological properties that each of these spaces have. Thanks.","['general-topology', 'metric-spaces', 'examples-counterexamples']"
969262,Doubt about Probability of arranging identical balls,"There are four boxes and 12 balls. The boxes are numbered and hence distinguishable but the balls are identical. What is the probability that a random arrangement would result in 10 balls in box 1 2 ball in box 2 and the rest boxes are empty ? My attempt was solving $x_1+x_2+x_3+x_4 = 12$ and only one case is favourable. My friend's attempt - assume the balls are numbered, total number of arrangements is $4^{12}$ out of which $\frac{12!}{10!2!}$ are favourable. Whose method is correct? EDIT Okay if we choose to throw the balls then the probability comes out as $$\frac{\frac{12!}{10!2!}}{4^{12}}$$. Now if the balls are unidentical then also the answer is $\frac{\frac{12!}{10!2!}}{4^{12}}$. How is it happening ?","['probability-theory', 'probability']"
969272,Recommendation on setting the reference axis for mathematical objects,"(I don't know what the title should be for this post, please change it if you have a better title. Also tags) In many situations, there arises cases that one mathematical structure embeds into another mathematical structure. Moreover, some structures are defined as these relations, namely universal mapping property. For example, the standard construction of a completion $M$ of a metic space $X$ (i.e. via Equivalence classes of cauchy sequences) is a set NOT containing $X$. That is, $X\not\subset M$. However, there is a trick to transform this to a set $S$ which has identical mathematical meaning of $M$ and containing $X$. To be clear, here is a trick to transform a group $G$ to which an algebraic structure $M$ embeds, to indeed a group $H$ literally containing $M$. Yes, this trick is extremely messy. However, I found this trick necessary if one wants to define ""the reference"" object. For example, via this trick, one can define "" the completion $M$ of a metric space $X$ such that $X\subset M$"" and "" the field of quotients $F$ of an integral domain $R$ such that $R\subset F$ and "" the free group $F(S)$ on a set $S$ such that $S\subset F(S)$ and etc. When I first learned this trick, I felt happy and satisfied with the fact that I can make an output object to be a set containing a input object. However, the more I define mathematical objects in this way, I feel like I'm not doing mathematics but working in a factory, since this trick is extremely artificial. However, if one does not define the reference axis, there should always be one more line in proofs, that is, ""Let $f$ be the canonical map"". I really want to know what people think on my opinion. I think this process is foolish but it deserves. What do you think?","['soft-question', 'category-theory', 'elementary-set-theory', 'abstract-algebra']"
969276,Help proving that an integer sequence is periodic,"I have been trying to solve this problem and i have no idea how to proceed: Let $p,q,n,a$ integers where
$n>0$,
$p$ and $q$ are relative primes and
$a \neq 0$.
Prove that: 
$$(aq^k \text{mod } p^n \ : \ k\geq 0),$$
is periodic of period $T_n$.
Also prove that for $n$ sufficiently large holds that $T_n=C p^n$, where $C$ is a constant and that the elements in $(aq^k \text{mod } p^n \ : \ 0\leq k < T_n)$ are all diferent. Any help will be appreciated.",['number-theory']
969282,Evaluate $\int_{0}^1 x^{p}(\log x)^q dx$,"Evaluate $$\int_{0}^1 x^{p}(\log x)^q dx$$
for $p \in \mathbb{N}$ and $q \in \mathbb{N}$.","['definite-integrals', 'closed-form', 'calculus', 'integration']"
969307,Can a $\mathbf{Q}$-basis of $\mathbf{R}$ be explicitly defined?,"Could someone give me an explicit basis of $\mathbf{R}$ as a vector space over $\mathbf{Q}$? I know some linearly independent subset, namely $1,e,e^2,\dots$ but this seems to be a deep result already (this is just the transcendence of $e$, right?), but no maximal linearly independent subset. Let me clarify: I know how to prove that every vector space (over a division ring) has a basis, it is by Zorn's lemma and equivalent to AC. I don't think that this directly implies that one cannot describe some basis explicitly; can one prove that the existence of a basis of $\mathbf{R}$ over $\mathbf{Q}$ is equivalent to AC ? This would convince me.","['rational-numbers', 'elementary-set-theory', 'linear-algebra', 'real-numbers', 'axiom-of-choice']"
969328,"Can $f :(\Bbb R, +) \to (\Bbb R, +)$ be a homomorphism?","QUESTION : Is there a homomorphism $$f :(\Bbb R, +) \to (\Bbb R, +)$$ that does not have the form $x \mapsto ax$, where $a\in\mathbb{R}$?","['group-theory', 'abstract-algebra']"
969337,The column space of a matrix A is the set of solutions of Ax = b?,"Is it true to state , The column space of a matrix A is the set of solutions of Ax = b? Why?","['matrices', 'linear-algebra']"
969339,Rational map of a curve to an elliptic curve,"If I have a curve given by
$$ y^2 = (x^3-1)(x^3-a), $$
how do I find out if there is a rational variable transformation $y=y(s,t)$, $x=x(s,t)$ that maps this curve onto an elliptic curve of the form
$$ s^2+a_1st+a_3 s=t^3+a_2t^2+a_4t+a_6. $$
I think it's relevant that $x\mapsto a^{1/3}/x$ leaves the roots of the r.h.s. unchanged, but I don't know how I can use that. I learned that there should exist a quotient of the original curve by the involution $x\mapsto a^{1/3}/x$, but I am not clear how I would actually compute it. Is there a way to explicitly determine the rational functions $y(s,t)$, $x(s,t)$?","['algebraic-geometry', 'elliptic-curves']"
969344,Statistics question Conditional Probability,"Question:
Of three cards, one is painted red on both sides; one is painted black on
both sides; and one is painted red on one side and black on the other.
A card is randomly chosen and placed on a table. If the side facing up
is red, what is the probability that the other side is also red? My Attempt:
number designates side and letter the colour
Card 1: R1 R2
Card 2: B1 B2
Card 3: R1 B2
P(R2|R1) = P(R1R2)/P(R1)
P(R2|R1) = (1/3)/(1/2)
P(R2|R1) = 2/3
I did this in a conditional probability manner but my instinct says the answer should just be 1/2...","['statistics', 'conditional-probability']"
969345,How to solve a differential equation that is equal to a constant?,"How to solve a differential equation:
$${{d ^2 u} \over {d x^2}} + u = k,$$
where $k$ is some constant number? I know that if this was  ${{d ^2 u} \over {d x^2}} + u = 0$, then an auxiliary equation:   $m^2 + 1 = 0$ can be used where $m = \pm i$ to which I think the solutions are: ${{u} }$ = $A\sin(t) + B\cos(t)$? But what about if the zero is a constant?",['ordinary-differential-equations']
969350,Conformal classes and almost-complex structures,"It is well-known that on closed oriented surfaces $S$, conformal classes of metrics on $S$ correspond bijectively to complex structures on $S$. My understanding is that this correspondance goes as follows: Given a metric $g$ on $S$, there is a unique almost-complex structure $J$ (which is automatically integrable in dimension 2) such that $g(u,Ju) = 0$ and that $u \wedge Ju$ is positively oriented for all tangent vectors $u$. i.e. the metric $g$ gives a way to ""rotate 90 degrees counter-clockwise"". Clearly, given a conformally equivalent metric $e^ug$, this construction gives the same $J$. Conversely, given an almost-complex structure $J$, we can take any metric $g$ and form the metric $h(u,v) = g(u,v) + g(Ju,Jv)$. Then since it is symmetric, we have $h(u,Ju) = h(Ju,JJu) = -h(u,Ju)$ so $h(u,Ju) = 0$, confirming that we have a bijection. Now let $S_1$ and $S_2$ be two Riemann surfaces and let $[g_1]$ and $[g_2]$ be the conformal classes of metrics corresponding to their complex structures. If $f : S_1 \to S_2$ is holomorphic, how are the two classes $[g_1]$ and $f^*[g_2]$ on $S_1$ related? In particular, if $f$ is a biholomorphism, does it follow that $[g_1] = f^*[g_2]$? If $f : (S_1,J_1) \to (S_2,J_2)$ is a holomorphic map, then $df \circ J_1 = J_2 \circ df$ where $df$ is the differential of $f$. So if $f$ is actually a biholomorphism and the underlying spaces $S_1 = S_2 = S$ are the same, then the two complex structures $J_1$ and $J_2$ would be conjugate; $(df) \circ J_1 \circ (df)^{-1} = J_2$. This suggests that my last statement in the second paragraph should not be true as is since these two almost-complex structures don't seem to give the same orthogonal vectors in the construction of the first paragraph. Still, something almost as strong should be true but I can't exactly figure out what.","['complex-geometry', 'differential-geometry', 'riemann-surfaces', 'riemannian-geometry', 'conformal-geometry']"
969358,Is a coherent locally free sheaf isomorphic it's dual?,"Hartshorne chapter II problem 5.1 a) is to prove that the double dual of a coherent locally free sheaf $\mathscr{E}$ over a ringed space $(X,O_X)$ is isomorphic to $\mathscr{E}$.  This can be done by defining an analog of the evaluation map and showing it is an isomorphism on a cover of open sets on which $\mathscr{E}$ is free. Now we can apply the non-canonical isomorphism of free modules of finite rank with their dual locally to see that there is a cover by open sets under which the restriction of $\mathscr{E}$ and the dual of $\mathscr{E}$ are isomorphic.  However, I believe the general philosophy is that maps which are canonical patch together to form morphisms of sheaves while maps that are not canonical don't necessarily patch together.  So in the case of coherent locally free sheaf and it's dual, do the local isomorphisms not patch together in general?","['sheaf-theory', 'algebraic-geometry']"
969377,Prove that the distance between 2 Cauchy sequences is convergent.,"Here is the exact question: Let $(S,d)$ be a metric space. Let $(p_n)$ and $(q_n)$ be two Cauchy sequences in $(S,d)$(note that these two sequences are not necessarily convergent since $(S,d)$ is not necessarily complete). Define a sequence $a_n = d(p_n, q_n)\in\mathbb{R}$. Prove that $(a_n)$ is a convergent sequence. My attempt: Since $p_n$ is Cauchy, there exists $N_1$ such that $m,n> N_1 \implies d(p_m, p_n)< \epsilon$. In particular, $d(p_m, p_n)< (m-n)\epsilon$ for $m,n> N_1$ Since $q_n$ is Cauchy, $d(q_m, q_n) < (m-n)\epsilon$ for $m,n> N_2$ Thus for $N= \max(N_1, N_2)$, and $m,n> N, d(p_n, q_n) = d[(d(p_N, q_N) +...+ d(p_m, q_m)),0]$,
which is less than $(m-n)\epsilon- (m-n)\epsilon= 0$, and thus $<\epsilon$ I don't think the final line of my argument is correct.","['cauchy-sequences', 'convergence-divergence', 'real-analysis', 'metric-spaces']"
969412,Is the Projective Real Plane Compact?,"I feel like $\Bbb P (\Bbb R^2)$ is compact, but I know that $\Bbb R^2$ is locally compact, therefore it has a one-point compactification. $\Bbb P (\Bbb R^2)$ adds more than one point to the real plane, so I am a little confused. Not sure how to think about this problem.","['general-topology', 'projective-space', 'algebraic-geometry', 'projective-geometry']"
969430,Question on the correlation between two dependant variables,"I'm working on this question and it's stumping me. Let Sn = X1 + ... + Xn (with n>=1) be a random walk with X1,...,Xn be iid RV's. E(Xk)=mu Var(Xk)=sigma^2. Find the covariance of Sn and Sm Can anyone help out? I am trying to use the equation Cov[Sn, Sm] = E[SnSm] - E[Sn]E[Sm]","['statistics', 'correlation']"
969493,$M$ is a simple module if and only if $M \cong R/I$ for some $I$ maximal ideal in $R$.,"I am trying to show the following statement (taken from Rotman's Advanced Modern Algebra ): Let $M$ be an $R$-module. Then $M$ is a simple module if and only if $M \cong  R/I$ for some $I$ maximal ideal in $R$. If $M$ is simple, then $0 \neq M$, so I can pick $x \in M, x \neq 0$. Since $M$ is simple, we have $Rx=M$. If I define $f: R \to M$ as $f(r)=rx$ then by the first isomorphism theorem, $R/Ker(f) \cong Im(f)=M$. How can I show that $Ker(f)$ is a maximal ideal? I would also appreciate some help to prove the other implication.","['modules', 'ring-theory', 'abstract-algebra']"
969545,Can someone explain the meaning of $\setminus$ in operations with sets? [duplicate],"This question already has answers here : What means a ""$\setminus$"" logic symbol? (2 answers) Closed 9 years ago . I have never faced with such operator... what does ' $\setminus$ ' mean?
Does this expression make any sense? $(A \cup B) \setminus C = A \cup (B \setminus C)$","['notation', 'elementary-set-theory']"
969553,I get two different answers on simple equation. What am I doing wrong?,"For the equation: $-x^2 = -2x(3x+1)$ I can either multiply it out on the right side and get a $-6x^2-2x$ or just divide both sides by $-2x$. However, when divide out both sides, I just get one answer: $-2/5$. When I multiply it out, I get two answers: $-2/5$ and $0$. What is wrong with dividing both sides by $-2x$??",['algebra-precalculus']
969591,Evaluating a trigonometric product $\prod_{n=1}^{\infty}\cos^2\left(\frac{1}{n^2}\right)$,"I'm interested in finding a closed form for 
$$\prod_{n=1}^{\infty}\cos^2\left(\frac{1}{n^2}\right)$$ Wolfram Alpha confirms that it converges, but I can't find any plausible closed forms. I've made some efforts to rewrite it in terms of stuff of the form $re^{i\theta}$ and make it a geometric series, but I think a more high powered solution may be needed. Any ideas?","['trigonometry', 'convergence-divergence', 'infinite-product']"
969613,Find the pdf of $X+Y$ (discrete case),"Given the marginal pdfs: $$p_X(k)= e^{-\lambda}\frac{\lambda^k}{k!}\text{ and }p_Y(k)= e^{-\mu}\frac{\mu^k}{k!},\quad k=0,1,2,\ldots$$ find the pdf of $X+Y$. I know for $W=X+Y$, $p_W(w)= \sum_x p_X(x)p_Y(w-x)$ So far I have: $$p_W(w)= e^{-\lambda-\mu}\sum_x\frac{\lambda^x\mu^{w-x}}{x!(w-x)!}
,\ldots$$ but I am not seeing where this is coming from. If you're summing all $x$'s, wouldn't you get an infinite sum?","['statistics', 'probability', 'random-variables']"
969616,"Show that $f:\mathbb{R}^2\to\mathbb{R}$ defined by $f(x,y)=x+y$ is continuous using open sets.","The problem statement is, Show that $f:\mathbb{R}^2\to\mathbb{R}$ defined by $f(x,y)=x+y$ is continuous using open sets. I know that to show $f$ to be continuous I take an arbitrary open set $O\subset\mathbb{R}$ and show that $f^{-1}(O)$ is open in $\mathbb{R}^2$. We can simplify this by first showing that for any $(a,b)\in\mathbb{R},$  $f^{-1}(a,b)$ is open in $\mathbb{R}^2.$ Now, we have
$$f^{-1}(a,b)=\{(x,y):f(x,y)\in(a,b)\}=\{(x,y):a<x+y<b\}$$
To show that $f^{-1}(a,b)$ is open, we need to show that for every $u\in f^{-1}(a,b)$, there exists a $\delta>0$ such that $B_\delta(u)\subset f^{-1}(a,b).$ One way I thought about showing this was to first fix $y$ in $(x,y)\in f^{-1}(a,b)$ and range over all $x$. Do the same for $y$ and then try to find an appropriate $\delta$. I did find this question (which is exactly mine) Using the open set definition of continuity to directly prove a function is continuous Yet, the I didn't completely understand the hints or answers given. Thanks for any help or feedback.",['general-topology']
969619,Continuous function on $\mathbb{R}^{n}$ preserving compactness - some clarification,"My professor went over a proof of the following in class: Suppose $A \in \mathbb{R}^{n}$ is compact and $f:A \rightarrow \mathbb{R}^{n}$ is continuous. Then $f(A)$ is compact. The proof (presented by my professor in class) is as follows: Since $f$ is continuous, the set $ \{f^{-1}(U_{i})|i \in I \}$ is an open cover for $A$. Since $A$ is compact, each open cover has a finite sub cover, hence $ \{ f^{-1}(U_{j}) | j \in I \}$ is a finite sub cover. Therefore, $ \{ U_{j} | j \in I \}$ is a finite sub cover for $f(A)$ and $f(A)$ is compact. There are a few areas of this proof which are not quite clear to me, addressed in the four questions below (the last two are purely notational questions): Does this hold for any metric space or is this just a special property of $\mathbb{R}^{n}$? A part of me is skeptical that this proof is sufficient. It seems that we've only shown that one open cover (i.e. $ \{U_{i} | i \in I \} $ )  of $f(A)$ has a finite sub cover. Does it matter that we've given no explicit bound for the finite sub cover? That is, shouldn't the finite sub cover be written: $ \{ f^{-1}(U_{i})| i \in I$ and $i \leq j \}$ Why does each $i$ have to be in an index set $I$? Can't I just set $i \in \mathbb{N}$?","['continuity', 'compactness', 'analysis']"
969624,Proof that a group representation matrix is diagonalizable?,"Suppose we have a finite group $G$ and and an $n$-dimensional vector space $V\cong \Bbb C^n$ over the field $\Bbb C$ of complex number. My professor said the other day that for every group element $g$ in $G$ and for every representation $\rho:G\to\text{GL}_n(\Bbb C)$ of $G$ on $V$, the matrix $\rho(g)\in\text{GL}_n(\Bbb C)$ is diagonalizable. I'm having trouble convincing myself that this is true. The text below is from a website that agrees with what my professor said: $~~~~~$ I believe that all the eigenvalues of $M$ must be $n$-th roots of unity, and that each eigenvalue appears only once as root of $M$'s minimal polynomial. I am having trouble convincing myself, however, that this means $M$ is diagonalizable. How do we know that the eigenvectors of $M$ span the vector space $V$? Couldn't $M$ have a minimal polynomial of degree less than $n$? Any help would be much appreciated.","['linear-algebra', 'representation-theory']"
969684,"Evaluate $\int_{0}^{1} \frac{\left[\rm{Li}_2\left(\frac{1}{2} \right)-\rm{Li}_2\left(\frac{1 + x}{2}\right)\right]\ln( 1 - x)}{1 + x}\,dx$","$\def\Li{{\rm{Li}}}$How to evaluate the following integral$${\large\int_0^1} {\frac{{\left[ {\Li_2\left( {\frac{1}{2}} \right) - \Li_2\left( \frac{1 + x}{2} \right)} \right]\ln \left( {1 - x} \right)}}{{1 + x}}}\, dx$$","['closed-form', 'calculus', 'integration', 'special-functions', 'definite-integrals']"
969714,The rank and eigenvalues of the operator $T(M) = AM - MA$ on the space of matrices,"This problem is from Artin Algebra Second edition, 5.2.3. Let $A$ be an $n\times n$ complex matrix. $(a)$ Consider the linear operator $T$ defined on the space $\mathbb{C}^{n\times n}$ of all complex $n\times n$ matrices by the rule $T(M) = AM - MA$ . Prove that the rank of this operator is at most $n^2-n$ $(b)$ Determine the eigenvalues of $T$ in terms of the eigenvalues $\lambda_1,\cdots,\lambda_n$ of $A$ . For part $(a)$ , I tried to use Dimension Formula. But, I don't know how to show that $\dim(\ker(T))$ is greater than equal to $n$ . For part $(b)$ , I really don't know... Can someone help me?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
969720,What is the main difference between a vector space and a field?,"In my opinion both are almost same. However there should be some differenes like any two elements can be multiplied in a field but it is not allowed in vector space as only scalar multiplication is allowed where scalars are from the field. Could anyone give me atleast one counter- example where field and vector space are both same.
Every field is a vector space but not every vectorspace is a field.
I need an example for which a vector space is also a field. Thanks in advance. (I'm not from mathematical background.)","['vector-spaces', 'linear-algebra', 'abstract-algebra', 'field-theory']"
969749,Problem about right triangles.,"Given N>1 right triangles. Sum one legs of each of them, then sum all the left legs, then sum all hypotenuses. These 3 sums form the sides of a right triangle. Prove all given N triangles are similar I'm really stuck on this one. Got that sum of all hypotenuses is the end hypotenuse. but can't proceed from it. Any help would be appreciated.","['geometry', 'algebra-precalculus']"
969765,From algebraic master degree to algebraic geomery Phd,"I am a foreign master student in algebra at the final year. I'm familar with categorical algebra and have interesting in algebraic geomery and number theory. I have learned some knowledge about scheme theory and algebraic number theory from online notes, but have not read Hartshorne yet. I want to apply for a Phd program in algebraic geometry or arithmetic geometry in US universities. But I wonder if my background can be accepted, especailly considering my poor english skill. My questions are: 1, Can my background be accepted for some good Phd programs in algebraic/arithmetic geometry? 2, Except Harvard, Princeton, Berkeley, Chicago, MIT, Stanford, Columbia etc., which have been listed in USNews, where are good Phd programs in algebraic/arithmetic geometry? 3, Is there some useful suggestions about further learning on algebraic/arithmetic geometry?","['education', 'algebraic-geometry', 'soft-question']"
969769,Property of uniformly tight random variables?,"I'm stumped on the following question, which is problem 1.3.9 in the book Weak Convergence and Empirical Proceses by van der Vaart and Wellner. It is based on the following notion of asymptotic tightness: Definition : A sequence of random variables $X_1, X_2, \ldots$ taking values in a metric space with metric $d$ is asymptotically tight if for every $\epsilon > 0$ there exists a compact $K_0$ such that for every $\delta > 0$ we have $\varliminf_{n \to \infty} P(X_n \in K_0^\delta) \ge 1 - \epsilon$ where $K_0^\delta = \{x: d(x, K_0) < \delta\}$ is the $\delta$-enlargement of $K_0$. For convenience, the definition of uniform tightness is Definition : A sequence of random variables $X_1, X_2, \ldots$ is uniformly tight if for every $\epsilon > 0$ there exists a compact $K$ such that $P(X_n \in K) \ge 1 - \epsilon$ for every $K$. The problem is: Claim :  A sequence $X_n$ is uniformly tight if and only if it is asymptotically tight and each $X_n$ is tight. I cannot seem to prove the non-trivial direction of this claim. The following hint is given: Hint : Fix $\epsilon > 0$. Take a compact $K_0$ with $\varliminf P(X_n \in K_0^\delta) \ge 1 - \epsilon$ for every $\delta$. Choose $n_1 < n_2 < \cdots $ such that $P(X_n \in K_0^{1/m}) \ge 1 - 2 \epsilon$ for $n \ge n_m$. For $n_m < n  \le n_{m+1}$ choose a compact $K_n$ with $P(X_n \in K_0^{1/m} - K_n) < \epsilon$. Now $K = \bigcup_{n = 0} ^ \infty K_n$ is compact and $P(X_n \in K) \ge 1 - 3 \epsilon$. Now, I understand everything in the hint except for the claim that $K = \bigcup_{n = 0} ^ \infty K_n$ is compact. I assume I'm missing something in how $K_n$ is constructed that makes the countable union compact, since obviously a countable union of compact sets isn't necessarily compact. I also can't seem to find a proof of this claim anywhere other than this book, except a proof in the book Introduction to Empirical Processes and Semiparametric Inference which apparently just copies this hint and leaves the claim that $K$ is compact as ""an exercise left to the reader."" EDIT : I think I have a sketch now for compactness, so if anyone could verify it I would be appreciative. The $K_n$ can be chosen so that $K_0 \subseteq K_n \subseteq K_0^{1/m}$ for $n_m < n \le n_{m+1}$. Given an open cover $\{U_\alpha\}$ of $K$, find a finite subcover of $K_0$, $U_1, \ldots, U_K$. Next, find $m$ such that $K_0^{1/m} \subseteq \bigcup_{k = 1} ^K U_k$ (exists because $K_0$ is compact and $\bigcup_{k = 1} ^ K U_k$ is open). Hence $U_1, \ldots, U_K$ is an open cover for $K_n$ for all $n > n_m$. Now, just use compactness of $K_1, \ldots, K_{n_m}$ extend the open cover $K_{n_m + 1}, K_{n_m + 2}, \ldots$ to one which covers all $K_n$.","['probability-theory', 'measure-theory', 'probability']"
969781,A beautiful game of gold and silver coins,"A stack of silver coins is on the table. For each step we can either remove a silver coin and write the number of gold coins on a piece of paper, or we can add a gold coin and write the number of silver coins on another piece of paper. We stop when only gold coins are left. Prove that the sums of numbers on these two papers are equal. Tried playing the game and the problem seems right each time,  but I can't proceed from there. Is it done by induction?","['game-theory', 'algebra-precalculus', 'puzzle', 'combinatorics']"
969786,$5$ digit no. in which at least $3$ digits are identical.,"The number of $5$-digit numbers that can be made with digits $\left\{1,2,3,4,5,6\right\}$ in which at least $3$ digits are identical is. $\bf{My\; Try::}$ No.,s in which at least $3$ digits are Identical is $ = $ Total -no digit are identical - exactly $2$ digit are identical. So Total no. of ways is $ = 6\times 6 \times 6 \times 6 \times 6=6^5$ and no digit are identical is $ = 6\times 5 \times 4 \times 3 \times 2 = 6!$ and I did not understand how can i find the cases in which exactly $2$ digits are identical. Help me Thanks",['combinatorics']
969816,"Why does $M\otimes k(\mathfrak{m})=M_\mathfrak{m}/\mathfrak{m}M_\mathfrak{m}$? (From Matsumura, proof of Theorem 4.8.)","Matsumura's Commutative Ring Theory , proof of Theorem 4.8, page 27, says: Let $A$ be a ring, $M$ a finite $A$-module, and $\mathfrak{m}$ a maximal ideal. If $k(\mathfrak{m})=A_\mathfrak{m}/\mathfrak{m}A_\mathfrak{m}$ is the residue field of $A_\mathfrak{m}$, then $$
M\otimes k(\mathfrak{m})=M_\mathfrak{m}/\mathfrak{m}M_\mathfrak{m}.
$$ I know $A_m/mA_m\cong (A/m)_\bar{m}$, but even then
$$
M\otimes k(m)\cong M\otimes (A/m)_\bar{m}=\cdots?
$$ Even if $(A/m)_\bar{m}\cong A/m$, then doesn't
$$
M\otimes k(m)\cong M\otimes A/m\cong M/mM
$$
but that's not the same as $M_m/mM_m$, is it?","['modules', 'commutative-algebra', 'abstract-algebra']"
969827,$G$ finite group with $H \leq G$ with $G = \bigcup_{g \in G} gHg^{-1} \implies H=G$,"Let $G$ be a finite group and let $H$ be a subgroup of $G$. If $G = \bigcup_{g \in G} gHg^{-1}$, then I have to show $H=G$. Let $N(H) =\left\{ g \in G \ \bigl| \ gHg^{-1}=H\right\}$. What I have done is the following : If $g \in H$ then I know that $gHg^{-1} =H$. And if $g_{1}Hg_{1}^{-1} = g_{2}Hg_{2}^{-1}$ then I have $g_{2}^{-1}g_{1}Hg_{1}^{-1}g_{2}=H$ which says $g_{1}^{-1}g_{2} \in N(H)$ or in other words $g_{2} \in g_{1}N(H)$. From the above $2$ things I am able to infer that if $g_{k} \in G$ is in some coset of $N(H)$ the union is same. Means say if $g_{k} \in g_{1}N(H)$ then $g_{1}Hg_{1}^{-1} = g_{k}Hg_{k}^{-1}$ while looking at the union we don't have to count $g_{k}$ and $g_{1}$ seprately as they are both the same. I am not able to proceed further. The point is I don't really know what I have to contradict in order to conclude $H=G$.","['group-theory', 'abstract-algebra']"
969862,Let $f(x)= (\sin x)^x$ Find $f'(\frac{\pi}{2})$,"I'm not sure if I derived it right. So, Let $f(x)$ = $(\sin x)^x$ . $f' = x(\cos x)$ right? then just substitute so $f' = \frac{\pi}{2}(\cos\frac{\pi}{2})$ ? Since $\cos(180°)$ is equal to $-1$ . Then its - $\frac{\pi}{2}$ ? they said it's wrong. after reading all the comments I arrived with $f'$ = $(\sin x)^x$ $\frac{\sin x\ln(\sin x) + x\cos x}{\sin x}$ then substitute $\frac{\pi}{2}$ to x so that's $90 \deg$ $\cos90$ is $0$ and $\sin90\deg$ is $1$ so $1$ raised to $90\deg$ then $\frac {(1)(1)+0}{1}$ my final answer is now $\frac{\pi}{2}$ which is in the multiple choice. But is it correct?","['trigonometry', 'calculus']"
969865,Application of Davenport theorem,"The Davenport theorem (or Cauchy-Davenport theorem for some authors ) states that for any two nonempty
subsets $A$ and $B$ of the prime field $\mathbb Z/p\mathbb Z$ we have $$|A+B| ≥ \min(p, |A|+|B|−1),$$ where
$A+B := \{a+b \;\; \mod p \;:\; a ∈ A, b ∈ B\}$. In the following paper by P. Erdos and H. Heilbronn https://www.renyi.hu/~p_erdos/1964-18.pdf the authors apply Davenport theorem in the proof of$\;$ LEMMA I.1. I can not understand how Davenport theorem is applied here. Can someone can help me?","['number-theory', 'combinatorics']"
969895,How find this integral $I=\int_{0}^{+\infty}\frac{x}{1+e^x}dx$,"Question: $$I=\int_{0}^{+\infty}\dfrac{x}{1+e^x}dx$$ I know use
$$I=\int_{0}^{\infty}\dfrac{xe^{-x}}{1+e^{-x}}dx=\sum_{k=0}^{\infty}\int_{0}^{\infty}xe^{-(k+1)x}dx=\sum_{k=1}^{\infty}(-1)^{k-1}\cdot\dfrac{1}{k^2}=\dfrac{\pi^2}{12}$$ someone have other methods? Thank you,Because I want collect more methods,Thank you",['integration']
969898,Is the following a semiring?,I have the following problem: Let $f: X' \rightarrow X$ be any map and $\mathcal{H} \subseteq \mathcal{P}(X)$ a semring. Is $f^{-1}(\mathcal{H})$ a semiring? Thanks for your help!,"['measure-theory', 'elementary-set-theory', 'real-analysis']"
969936,Isotropy subgroup is closed,"I am studying a book and I am asked to prove the following: Show that the isotropy subgroup (for a certain right action of a topological group $G$) of $y\in Y$ is closed for $Y$ some topological space. I have a proof for the case that $Y$ is Hausdorrf: $ \sigma^{-1}(y)\cap (\{y\}\times G) = \{y\}\times \text{Iso}(y)$ and since $\sigma$ is continuous and $\{y\}$ and $\{y\}\times G$ are closed, so is Iso($y$). But this relies crucially on the fact that the point is closed, which is only true for Hausdorff spaces. So my question is: Do we need Hausdorff to prove the result? Thanks.","['general-topology', 'group-theory']"
969956,Differentiability - general function?,"I know that a function is differentiable if the limit exists as $\Delta x \to 0$ of a certain limit. But how can one know this beforehand? I mean, we usually just differentiate using rules that we have derived using the limit definition, but then how we do know that the function we apply them to actually did pass the ""limit test"" and is differentiable? Is there some way to just look at a function and know whether it's differentiable or not? And not just for single variable, but for multivariables as well?",['derivatives']
969972,Does a compact operator always have a kernel?,"I am sorry if this question is stupid..... I raise it when I read Lax's book Functional Analysis. We know that some integral operators are compact, for example an integral operator from $L^2[Y]$ to $L^2[X]$ defined by
   $$ (Kf)(x) = \int{K(x,y)f(y)dy}$$ 
is compact if $X$ and $Y$ are compact space and the kernel is square integrable. But how about the converse question? Does any compact operator from $L^2[Y]$ to $L^2[X]$ always has a kernel $K(x,y)\in{L^2}$? If not, under what conditions this compact operator have such kernel? Moreover, how about other spaces, such as $C(X)$, $L^p$ space? (For genreal $L^p$ space, I am not sure this question is meaningful, since the above integral may diverge....) Can anyone give me a hint or any references? Thank you!","['integral-operators', 'compact-operators', 'functional-analysis']"
970062,How to show that two quadratic forms are equivalent?,"To show to quadratic forms are not equivalent, we can find rank, or discriminant or some element which is represented by either one only etc. But Is there a general criterion to show that two binary(right now I am only concerned for binary) quadratic forms are equivalent.
Like here is an example which uses variable transformation, but every time find what transformation will apply is tough. $\textbf{Example-}$ $X^2-Y^2 $ and $4XY$. replacing $X,Y$ by $X+Y,X-Y$ do the job here. Nnow there are criterion which gives an equivalent condition to check whether two binary forms are equivalent or not , like $\textbf{Criterion 1-}$ On algebraically closed fields, same dimension and same rank suffice. $\textbf{Criterion 2-}$ On Reals, same rank and same signature suffices. $\textbf{Criterion 3-}$ On finite fields,same discriminant is enough. But in general if we are given field as some arbitrary $K$, then what to do? I am very new at quadratic forms. Any help will be appreciated. I know that we can check similarity of their corresponding matrices, but is there any other way, beside checking matrices are similar or not. Like how would you proceed on these couple of question below. If there is no other method, can somebody please explain me the method to check whether two matrices are similar or not, I am really weak with matrices. $\textbf{Question 1-}$ Prove $X^2-4XY+3Y^2, X^2-Y^2,aX^2-aY^2$ are equivalent over $K$. $\textbf{Question 2-}$ Show i) $X^2-Y^2 \sim XY$ over $K$,   ii) $3X^2-2Y^2 \sim X^2-6Y^2$ (over $Q$)","['quadratic-forms', 'linear-algebra']"
970106,"Prove that $\int_0^1 \frac{{\rm{Li}}_2(x)\ln(1-x)\ln^2(x)}{x} \,dx=-\frac{\zeta(6)}{3}$","I have spent my holiday on Sunday to crack several integral & series problems and I am having trouble to prove the following integral \begin{equation}
\int_0^1 \frac{{\rm{Li}}_2(x)\ln(1-x)\ln^2(x)}{x} \,dx=-\frac{\zeta(6)}{3}
\end{equation} Using integration by parts, $u=\ln^2(x)$ and $dv=\displaystyle\frac{{\rm{Li}}_2(x)\ln(1-x)}{x} \,dx$, I manage to obtain that the integral is equivalent to
\begin{equation}
\int_0^1 \frac{{\rm{Li}}_2^2(x)\ln(x)}{x} \,dx
\end{equation}
where ${\rm{Li}}_2^2(x)={\rm{Li}}_2(x)^2$, square of dilogarithm of $x$. Could anyone here please help me to prove the above integral preferably with elementary ways ( high school methods/ not residue method )? Any help would be greatly appreciated. Thank you.","['integration', 'definite-integrals', 'harmonic-numbers', 'real-analysis', 'polylogarithm']"
970125,"Evaluate $\int_0^1\frac{\ln(1-x)}{x}\text{Li}_3\left(\frac{1+x}{2}\right)dx$ , $\int_0^1\frac{\ln^2(1-x)}{x}\text{Li}_2\left(\frac{1+x}{2} \right)dx$","How can we evaluate the following integrals: $$\int_0^1\frac{\ln(1-x)}{x}\text{Li}_3\left(\frac{1 + x}{2} \right)\,dx\\
.\\
\int_0^1\frac{\ln^2(1-x)}{x}\text{Li}_2\left(\frac{1 + x}{2} \right)\,dx$$","['improper-integrals', 'closed-form', 'calculus', 'integration', 'definite-integrals']"
970126,Integration of $\sqrt{x+\sqrt{x^2+3x}}$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I faced the following indefinite integration problem:
$$\int \sqrt{x+\sqrt{x^2+3x}}dx$$ This result by WolframAlpha suggests that there is an elementary way to compute this integration. But I don't know how to start. Any hints would be appreciated.","['calculus', 'integration']"
970130,Multiple Integral Substitution Error,"I just started learning about the substitution rule for multiple integrals and I decided to give myself an example problem: Calculate $\iint_R{(x^2 + y^2)dA}$ with $R = \{(x, y) \in \Bbb{R} \ |\ 0
\le x + 2y \le 2 \land 0 \le x - y \le 1\}$ To calculate this, I decided to substitute $x = \frac{1}{3}(u+2v)$ and $y = \frac{1}{3}(u-v)$, (which is the same as $u = x + 2y$ and $v = x - y$). Under this substitution, the region of integral becomes $S = \{(u, v) \in \Bbb{R} \ |\ 0 \le u \le 2 \land 0 \le v \le 1\}$, which we can integrate directly. Now our integral is
$$
\begin{align}
\iint_R{(x^2+y^2)dA} & = \int_0^1\int_0^2{\left[\frac{1}{9}(u+2v)^2 + \frac{1}{9}(u-v)^2\right]\left|\frac{\partial{(x, y)}}{\partial{(u, v)}}\right|dudv} \\
& = -\frac{1}{27}\int_0^1\int_0^2{\left[(u+2v)^2 + (u-v)^2\right]dudv}.
\end{align}
$$
Because $\left|\frac{\partial{(x, y)}}{\partial{(u, v)}}\right| = -\frac{1}{3}$. Here is when I run into a problem. The original integrand is positive everywhere, so the volume is positive as well. But the transformed integrand is positive everywhere as well, so when multiplied by a negative constant it must mean that the volume is negative. How can the volume be both positive and negative at the same time? Where was my error?","['multivariable-calculus', 'integration']"
970133,Prove that $\sum\limits_{n=1}^\infty \frac{n^2(n-1)}{2^n} = 20$,"This sum  $\displaystyle \sum_{n=1}^\infty \frac{n^2(n-1)}{2^n} $showed up as I was computing the expected value of a random variable.
My calculator tells me that  $\,\,\displaystyle \sum_{n=1}^\infty \frac{n^2(n-1)}{2^n} = 20$.
How can I show that? I know how to find the value of the sum $\,\displaystyle \sum_{n=1}^\infty \frac{n^2}{2^n},\,$ but I can't deal with $\displaystyle \sum_{n=1}^\infty \frac{n^3}{2^n}$","['sequences-and-series', 'power-series', 'summation', 'calculus']"
970171,How can one derive Stokes lines of the Stokes phenomenon of asymptotics from a differential equation?,"Is there a standard technique to calculate Stokes lines and anti-Stokes lines of the Stokes phenomenon of asymptotics for a function defined as the general solution to a differential equation without directly solving the differential equation? For example, consider the differential equation
\begin{gather}
\frac{dz}{d\phi} = \lambda e^{i \phi} z - 1
\end{gather}
where $\lambda$ and $\phi$ are real, but $z$ is complex.  This has solution
\begin{gather}
z_A(\phi) = A e^{- i \lambda \exp(i \phi)} + i e^{- i \lambda \exp(i \phi)} \operatorname{Ei} \left( i \lambda e^{i \phi} \right)
\end{gather}
where $A$ is a constant and $\operatorname{Ei}$ is the exponential integral.  I therefore conclude that the general solution for $z$ in the above differential equation has Stokes lines that correspond to the Stokes lines for $\operatorname{Ei}(i \lambda e^{i \phi})$, viz., $\phi = \pi / 2$ and $\phi = - \pi / 2$. This is all very well, but consider that I now generalise the above differential equation in some way, e.g., write $\lambda = \lambda(z)$, add a term proportional to $z^2$, or do something even more exotic, such that I can no longer find a solution.  Can one nevertheless determine the Stokes lines and anti-Stokes lines that a general solution has?","['asymptotics', 'ordinary-differential-equations', 'special-functions', 'complex-analysis']"
970174,Characterization of the Haar measure in terms of the integrals of characters,"I was reading a paper and I think that they used the following theorem: Let $G$ compact group and $\mu$ a probability measure on $G$. If 
$$\hat{\mu}(\xi)= \int_G \overline{\xi(x)} d\mu(x) = \begin{cases} 0 & \text{ if }\xi = 0 \\ 1 & \text{ if } \xi\neq 0\end{cases} \quad \xi \in \hat{G}$$
then $\mu$ is the Haar measure. Is this theorem true? I looked on the book An Introduction to Harmonic Analysis of Katznelson that my teacher recommended and I only found the converse of the theorem on a exercise. Any help will be appreciated.","['measure-theory', 'harmonic-analysis', 'reference-request']"
970177,How to prove $\sum_{n=0}^{\infty} \frac {(2n+1)!} {2^{3n} \; (n!)^2} = 2\sqrt{2} \;$?,"I found out that the sum
   $$\sum_{n=0}^{\infty} \frac {(2n+1)!} {2^{3n} \; (n!)^2}$$
converges to $2\sqrt{2}$. But right now I don't have enough time to figure out how to solve this.
I would really appreciate any help. Just one tiny hint might help too.","['sequences-and-series', 'closed-form', 'summation', 'calculus']"
970183,Demonstrating that a function is monotonically increasing/decreasing,"my question is more of a conceptual one, but i'll use the problem i'm stuck on to keep things clear. I am confused about how to demonstrate whether a function is strictly monotonically increasing or decreasing etc. (i'm using the wrong brackets because the curly ones keep disappearing) I have the function $$(f : x \in \mathbb{R} : x < 0) \rightarrow \mathbb{R}, f(x) = \frac{1}{x^{2}}$$ and I need to decide whether it is (strictly) monotonically increasing (or decreasing) and then show algebraically why this is the case. I can see that it is strictly monotonically increasing and that it fits the inequality $$f(x_{1}) < f(x_{2})$$ for all $$x_{1}, x_{2} \in (-\infty, 0)$$ with $$x_{1} < x_{2}$$ but I am confused about how I show this algebraically. I'd really appreciate a general response to this that I can apply to similar problems. Thank you very much.",['functions']
970186,Mathematical expression to form a vector from diagonal elements,"I would like to know is there any way to express mathematically (using matrices multiplication, addition, etc.) a vector which is formed from the diagonal elements of a matrix. For example, I have a matrix called $\mathbf{M}$ and I want to create a vector  $\mathbf{v}$ such that
$\mathbf{v}= \text{diagonal elements of } \mathbf{M} $ Any matrix algebra or operation do that ? Thank you.","['matrices', 'linear-algebra']"
970190,"Finding square roots of a matrix of the form $A^\prime A$, where $A=\begin{bmatrix}I \\ a^{T}\end{bmatrix}$ for some column vector $a$","I have a matrix of quite special form:
$$S=A'A$$
$$A=\begin{bmatrix}
 1 &0  &\dots &0 \\ 
 0 &1  &\dots &0 \\ 
 0 &0  &\dots &1 \\ 
 a_{1} &a_{2} &\dots &a_{n} 
\end{bmatrix}$$
Thus $A$ is a $(n+1)\times n$ and $S$ is $n\times n$ symmetric matrix. 
I am wondering if there is some name for the matrices like $A$. 
I am implementing some numerical algorithm and I need to find inverses and square roots of very large matrices $S$. Since the matrix I am dealing with is of quite simple form, maybe there are some properties that would allow fast square root computations. Maybe some members of this community has some insight on how to make square root calculations faster. Does the matrix have a name I can research?","['matrices', 'terminology']"
970194,Existence of non-trivial linear functional on any vector space,"For every vector space $V$ does there exist a linear functional $f$ ( a linear map from $V$ to $F$ the underlying field ) such that for some $ \vec v \in V$ , $f(\vec v) \ne 0$ ? If it does exist , can we prove the existence without the ""axiom of choice "" ? Is the existence equivalent to axiom of choice ?","['vector-spaces', 'linear-transformations', 'linear-algebra', 'axiom-of-choice']"
970213,Is it possible to define a map from $\aleph_0$?,"In an assignment question I am asked to show that the cardinality of the set of all functions from $\mathbb{N}$ to $\mathbb{N}$ is equal to $2^{\aleph_0}$. To proceed with my proof I am trying to understand what exactly $2^{\aleph_0}$ is. In my professor's lecture notes, he defines $2^A$ to be the set of all functions from $A$ to $\{0, 1\}$. Based on this, I am thinking that $2^{\aleph_0}$ is simply the set of functions from $\aleph_0$ to $\{0, 1\}$. However, I am confused because I am not sure how to think of $\aleph_0$--is it a set, a number, or something else entirely? From what I understand, $\aleph_0$ is defined to be equal to the cardinality of $\mathbb{N}$ so I would think that $\aleph_0$ is just a number, but this seems naive to me--if $\aleph_0$ were a number, how could I define a map from it? After doing some research on what $2^{\aleph_0}$ is I learned the astonishing fact that $|\mathbb{R}|=2^{\aleph_0}$ which has left me even more confused: If $|\mathbb{R}|=2^{\aleph_0}$ then isn't a $2^{\aleph_0}$ just a number? But if $2^{\aleph_0}$ is a number, how can it be a set containing functions (as per my professor's definition of $2^A$ where $A$ is a set). I suspect that the significance of $\aleph_0$ transcends the meaning of $2^A$ in the context of “regular” sets because it is very special in set theory, in which case, what is $\aleph_0$ and is it possible to define a map from it?","['cardinals', 'elementary-set-theory']"
970231,Proving a Binomial Identity,"Problem $\boldsymbol{25}$ [$\boldsymbol{5}$ Points]: Show that
$$
\sum_{k=0}^n\binom{n+k}{k}\frac1{2^k}=2^n
$$ Hint: Denote  the left hand side by $f(n)$ and prove that $f(n+1)=2f(n)$. Original Image Can you please help me with problem 25. I need to prove that $f(n+1)=2 f(n)$, where $f(n)$ is the LHS of the expression, from there on I can do it my self. I have tried using the binominal theorem and using different summation identities but i just cant get there. Please help me.","['binomial-theorem', 'binomial-coefficients', 'combinatorics']"
970267,"If $f $ is differentiable at $(x,y)$ then $ f_{xy}$ exists at $(x,y)$?",Suppose $f:{\bf R}^2 \rightarrow {\bf R}$ is once differentiable at a point $p$. Does it follow that $f_{xy}$ (the derivative of $f $ w.r.t to $x$ and then w.r.t to $y$) exist at $p$?,['derivatives']
970270,Complex Measures: Integrability,"Problem On the one hand, a complex measure decomposes into:
$$\mu=\Re_+\mu-\Re_-\mu+i\Im_+\mu-i\Im_-\mu=:\sum_{\alpha=0\ldots3}i^\alpha\mu_\alpha$$ This gives rise to the integrability condition:
$$f\in L(\mu)\iff f\in L(\mu_\alpha)\quad(\alpha=1,\ldots,3)$$ On the other hand, a complex measure admits a derivative:
$$\mu(E)=\int_Eu\mathrm{d}|\mu|\quad(|u|=1)$$ This gives rise to the integrability condition:
$$f\in L(\mu):\iff fu\in L(|\mu|)\iff f\in L(|\mu|)$$ So the question arises wether these approaches coincide:
  $$f\in L(|\mu|)\iff f\in L(\mu_\alpha)\quad(\alpha=1,\ldots,3)$$ Attempt So far by construction it is:
$$\mu_\alpha(E)=\int_Eu_\alpha\mathrm{d}|\mu|\quad(0\leq u_\alpha\leq1)$$
which gives for positive functions:
$$\int|f|\mathrm{d}\mu_\alpha=\int|f|u_\alpha\mathrm{d}|\mu|\leq\int |f|\mathrm{d}|\mu|$$
That proves the inclusion:
$$f\in L(|\mu|)\implies f\in L(\mu_\alpha)\quad(\alpha=1,\ldots,3)$$
But what about the converse? Related For a formal treatment see: Complex Measures: Integration For a related recapitulation see: Complex Measures: Variation For a similar problem see: Complex Functions: Integrability For a general problem see: Radon-Nikodym: Integrability?","['functional-analysis', 'measure-theory', 'integration', 'definition']"
970318,Cohomology and Base Change - Degree 0 Sanity Check,"Both Vakil and Hartshorne describe Cohomology and Base Change in the following way: Suppose $f:X \rightarrow Y$ is a projective (in Vakil, proper)
  morphism of Noetherian schemes, $F$ a coherent sheaf on $X$ flat over
  $Y.$ If the natural map $\phi^i(y): R^if_*(F) \rightarrow H^i(X_y,F_y)$ is surjective, then $\phi^{i-1}(y)$ is also surjective
  if and only if $R^if_*(F)$ is locally free near $y$. An important special case would be when $i=0$. I'm nervous about the fact that neither author singles out this special case, and my silly question is: does the hypothesis ""$\phi^{-1}(y)$ is surjective"" hold vacuously when $i=0$? In other words, is surjectivity of $\phi^0(y)$ enough to conclude local freeness of $f_*F$ near $y$? Thanks.","['algebraic-geometry', 'reference-request']"
970350,Alpha mixing property of a $\mathbb{R}^d$ valued Stochastic Process,"In statistics and probability literature, a strictly stationary stochastic process $\{X_t\}\in\mathbb{R}$ is called  $\alpha$-mixing if $\alpha(n)=\sup_{A\in\mathcal{F}_{-\infty}^{0}, B\in\mathcal{F}_{n}^{\infty}}|P(A)P(B)-P(AB)|\longrightarrow 0$ as $n\rightarrow 0$ where $\mathcal{F}_{a}^{b}$ denotes the $\sigma$-algebra generated by $\{X_t; i\leq t\leq j\}$. Let us now consider an $\mathbb{R}^d$-valued (stationary) stochastic process $\{Z_t\}$ defined as $\{Z_t\}:=\{Z_{1t},Z_{2t},...,Z_{dt}\}^{T}$. I was wondering if the process $\{Z_t\}$ being mixing would imply that its marginal processes $\{Z_{it}\}$ $\forall i$ being mixing or vice versa.. I understand this should be rather straightforward, but could not rigorously provide a proof with this.. This is not a homework, just personal curiosity.","['probability-theory', 'stochastic-processes', 'time-series', 'mixing']"
970368,What is an $R$-algebra?,"In the following, assume that rings are rings with unity. Here is the definition of $R$ -algebra from Wikipedia: Let $R$ be a commutative ring and $(M,+,\cdot)$ an $R$ -module. Assume $\ast$ is a binary operation on $M$ , such that: $x\ast (y+z)= x\ast y + x\ast z$ $\forall x,y,z \in M.(x+y)\ast z = x\ast z + y\ast z$ $\forall r,s \in R,x,y \in M.(rx)\ast (sy)=(rs)(x\ast y) (r,s\in R, x,y\in M)$ then $(M,+,\cdot,\ast)$ is called an $R$ -algebra. This definition has the same form as my definition for ""algebra over a field"". Note that this definition does not require $\ast$ to be associative. Here is an equivalent definition given in Dummit&Foote (original form is given using a ring homomorphism): Let $(M,+,\cdot)$ be a ring and $R$ a commutive ring. If $M$ is an $R$ -module and the multiplication on $M$ is bilinear, then $M$ is called ""an $R$ -algebra"". Note that this definition requires $\ast$ to be associative. What is the usual definition for $R$ -algebra? References Abstract Algebra, Dummit and Foote, 3rd edition, page 355.","['definition', 'ring-theory', 'abstract-algebra', 'algebras', 'modules']"
970403,Mean Value Theorem: finding two numbers in the same interval,"Let $f,g:[0,1] \to \mathbb{R}$ such that $f'(x)>0,\ g'(x) >0,\ \forall x\in [0,1]$. Moreover, $f(0)= g(0)$ and $f(1)=g(1)$. Prove that exists $x_1, x_2 \in [0,1]$ such that $$f(x_1) = g(x_2), \ \text{and}\ \ f'(x_1) = g'(x_2)$$ I've tried to use Mean Value Theorem with: a) $h(x)= f(x)-g(x)$ b) $h(x) = f(x) - xg(x)$ c) $h(x) = f(x)g(x)$ d) Using $g(1-x)$ instead of $g(x)$ But nothing seems to help in order to find at least one of $x_1$ or $x_2$. I think that, finding one of them, the other could be easy to get. Thanks for the help!","['calculus', 'derivatives']"
970407,What is the metric on a cone?,"I'm trying to learn differential geometry.  I thought a cone would be an easy place to start with calculating a metric, shape operator, what have you. First of all, by the way, when I say ""cone"" I mean the map $f: (x,y) \rightarrow (x,y,\sqrt{x^2+y^2})$  Nothing fancy. So I run through a prescription for getting a metric: $g_{ij} = \partial_i f_k \partial_j f_k$ where repeated indices indicate sum. I get $G=((2x^2+y^2)\,dx^2+2xy\,dx\,dy+(x^2+2y^2)\,dy^2)/(x^2+y^2)$ Can someone just tell me whether this is right or not, and show me how to correct myself if I have gone wrong?  I can't find this formula or, surprising to me, any other formula anywhere.  I thought this would be a widely discussed example.  Maybe I ought to just stop being cheap and buy a book?","['metric-spaces', 'differential-geometry']"
970409,Possible eigenvalues of a matrix $AB$,"Let matrices $A$, $B\in{M_2}(\mathbb{R})$, such that $A^2=B^2=I$, where $I$ is identity matrix. Why can be numbers $3+2\sqrt2$ and $3-2\sqrt2$  eigenvalues for the Matrix $AB$? Can  be numbers $2,1/2$  the eigenvalues of matrix $AB$?","['matrices', 'matrix-calculus', 'linear-algebra', 'eigenvalues-eigenvectors']"
970431,Example for non-Riemann integrable functions,"According to Rudin (Principles of Mathematical Analysis) Riemann integrable functions are defined for bounded functions.For every bounded function defined on a closed interval $[a,b]$ Lower Riemann Sum and Upper Riemann sum are bounded .More mathematically $m(b-a) \leq L(P,f) \leq U(P,f) \leq M(b-a)$ where $m,M$ are lower and upper bounds of the function $f$ respectively. Rudin says that Upper Riemann Sum and Lower Riemann sum always exists,but their equality is the question. But while searching for non-examples we need to find a bounded function whose upper sum not equal to lower sum.One of the book is given example as $\frac{1}{x}$ in the interval $[0,b]$. But this function is not bounded.
Can we use $\sin(\frac{1}{x})$ in the interval $[0,1]$. Explain how?","['examples-counterexamples', 'riemannian-geometry', 'integration', 'real-analysis']"
970468,change the basis of a matrix,"Is the methodology to change the basis of a matrix the same as changing the basis of a vector?  For example, if I had $A : \mathbb{R}^2 \to \mathbb{R}^2$ $$A=\begin{pmatrix} 3 & -5 \\ 2 & 7 \end{pmatrix}$$ in the standard basis and wanted it in the basis $v_1 = (1,3), v_2=(2,5)$. To do this, I simply multiply $A * \begin{pmatrix} 1 & 2 \\ 3 & 5 \end{pmatrix}$ to get $\begin{pmatrix} -12 & -19 \\ 23 & 39 \end{pmatrix}$?  Is this correct?","['matrices', 'linear-algebra']"
970480,"The sequence $x_{n+1}=\frac{x_n}{2}-\frac{2}{x_n}, x_0>0$ is bounded?","Consider the sequence $$x_{n+1}=\frac{x_n}{2}-\frac{2}{x_n}, x_0>0.$$
How can you prove that this sequence is bounded or unbounded for those values ​​of $x_0$ for which it is defined.
With a number generator I noticed that all terms of the positive out of range $[-2,2]$
 form finite sets in strictly decreasing order. We found that it can be periodically. For $x_0=\frac{2}{\sqrt{3}}$ its terms  repeat of 2 by 2. I tried to prove boundedness to the method of reduction to absurdity but we did. Thanks so much for any suggestion","['recurrence-relations', 'sequences-and-series']"
970496,Dense open subsets of schemes,"Let $X$ be a scheme. Let $U$ be an open subset of $X$. It is clear that if $U$ contains all the generic points of $X$ (by which I mean the generic points of irreducible components of $X$) then $U$ is dense in $X$. Is the converse of this statement true in general? That is, if $U$ is dense in $X$ does it contain all the generic points of $X$? I know the converse is true for an affine scheme with finitely many minimal primes, hence for a scheme $X$ whose set of irreducible components is locally finite. So the statement holds for any locally Noetherian scheme. $\textbf{Proof for the affine case when the ring has finitely many minimal primes:}$ Let $X = Spec(A)$. Let $p_1, \dots, p_n$ be the minimal primes of $A$. Let $U$ be a dense open of $Spec(A)$. Suppose $U = \{p_a : a \in A\}$. Then $$\overline{U} = \mathbb{V}(\cap_{a \in A} p_a) = Spec(A)$$ So, $\cap_{a \in A} p_a = nil(A)$. Let $p_{b_1}, \dots, p_{b_k}$ be the minimal primes of $A$ in $U$. Then $\cap_{a \in A} p_a = \cap p_{b_j}$. So for any minimal prime $p_i$, $nil(A) = \cap p_{b_j} \subset p_i$. By minimality and the fact that $p_i$ is prime, $p_i = p_{b_j}$ for some $j$ ($\textbf{here I need finiteness of the set of minimal primes}$), and so $p_i \in U$.","['commutative-algebra', 'algebraic-geometry']"
970505,"When simplifying $\sin(\arctan(x))$, why is negative $x$ not considered?","Let $u = \arctan(x)$, hence $x = \tan(u)$ for $u$ belongs in $(-\frac\pi2, \frac\pi2)$. Since $u$ belongs in $(-\frac\pi2, \frac\pi2)$, we consider $\sin(u)$ where $u$ belongs in $(-\frac\pi2, \frac\pi2)$. I used the unit circle to determine that the hypotenuse is $\sqrt{x^2 + 1}$ and got an answer $\sin(u) = \frac{x}{\sqrt{x^2 + 1}}$ when I consider than the angle $u$ lies between $(0, \frac\pi2)$. That's what my textbook says too. However, why don't we also consider when $x$ is negative, and the angle $u$ lies between $(-\frac\pi2, 0)$ ?",['trigonometry']
970512,Equation of a line tangent to circumference,"Discover the general equation of the tangent line to the circumference $x^2 + y^2 - 2x + 4y + 1 = 0$ by the point $(3,4)$. NO CALCULUS . by the circumference equation i discovered that $C(1, -2)$ and $r=2$ with the point $P(3,4)$ I put in the line equation: $$(y - yo) = m (x - xo)$$
    $$y - 4 = mx - 3m$$ 
    $$mx - y + 4 - 3m = 0$$ with the equation and the point of the circumference, I put them in the distance between point and line equation: $$\frac{|a x + by + c|} { \sqrt{a² + b²}} = 2$$ $$\frac{|m + (-2)(-1) + 4 - 3m|}{ \sqrt{(m)² + (-1)²}} = 2$$ $$\frac{|-2m + 6| }{ \sqrt{m² + 1} }= 2$$ $$\left(\frac{|-2m + 6| }{\sqrt{m² + 1
}}\right)^2 = 2^2$$ $$4m² - 24m + 36 = 4m² + 4$$ $$m = \frac{3}{4}$$ With this i found the equation: $\frac{3}{4}x - y = 0$ Wolfram graphic: http://www.wolframalpha.com/share/clip?f=d41d8cd98f00b204e9800998ecf8427eohl0i7ciu3 Thanks everybody!","['analytic-geometry', 'geometry', 'circles']"
970523,How many ways can the sum of $n$ dice be $s$?,"For example, if $n = 2$ , and $s=7$ one could have $(1,6), (2,5), (3,3), (4,3), (5, 2), (6,1)$ , for six ways. If $n = 10$ and $s = 30$ , one possible combination could be $(1, 2, 3, 4, 3, 2, 1, 5, 6, 3)$ .","['permutations', 'combinatorics']"
970540,Deriving $\frac{d}{dz} = \frac{1}{2}(\frac{d}{dx}-i\frac{d}{dy})$ Intuitively,"Without the usual math (i.e. the usual algebra you use to define these things), why should we want to define $$\frac{d}{dz} = \frac{1}{2}(\frac{d}{dx}-i\frac{d}{dy})$$
$$\frac{d}{d\bar{z}} = \frac{1}{2}(\frac{d}{dx}+i\frac{d}{dy})$$ I keep forgetting the $\tfrac{1}{2}$ and keep forgetting the minus signs. If we re-write $-i$ as $-i=\tfrac{1}{i}$ we can rewrite the above as $$\frac{d}{dz} = \frac{1}{2}(\frac{d}{dx}+\frac{1}{i}\frac{d}{dy})$$
$$\frac{d}{d\bar{z}} = \frac{1}{2}(\frac{d}{dx}-\frac{1}{i}\frac{d}{dy})$$ which is a bit more intuitive since $\bar{z}$ is on the L.H.S. & there's a corresponding minus R.H.S. etc... but this still isn't intuitive enough - we can incorrectly derive them using something stupid like $$\frac{d}{dz} = \frac{d}{d(x+iy)} = \frac{d}{dx} + \frac{d}{d(iy)} = \frac{d}{dx} + \frac{1}{i} \frac{d}{dy}$$ Is there a way to make this a bit nicer/logical and to include to $2$? $$\frac{d}{dz} = \frac{d}{d[2(x+iy)]} = ...$$ Maybe with pictures ?",['complex-analysis']
970541,Computing volume element in spherical coordinates,"Suppose $y = (r, \theta^1, \theta^2)$ are spherical coordinates in $(\mathbb{R}^3,g)$. What is the $d\text{vol}$ in these coordinates? I solved it but I don't know if it's right. My solution: We want $d\text{vol} = \sqrt {\det (g^y)} dr \, d\theta^1 \, d\theta^2$ Let $x = (x^1,x^2,x^3)$ be cartesian coordinates in $\mathbb{R}^3$. Then $$x^1 = r\cos\theta^1\sin\theta^2; \quad x^2 = r\sin\theta^1\sin\theta^2; \quad x^3 = r\cos\theta^2$$ I know that $\det (g^y) = \det (g^x) (\det J)^2$, where $\displaystyle J_{ij} = \frac{\partial x^j}{\partial y^i}$. It follows that $$g^x_{ij} = \left\langle \frac{\partial}{\partial x^i},\frac{\partial}{\partial x^j} \right\rangle_{\mathbb{R}^3} = \delta_{ij} \\ \implies g^x = \text{Id} \\ \implies \det (g^y) = (\det J)^2 \\ \implies \sqrt{\det (g^y)} = |\det J| $$ Then $d\text{vol} = |\det J| \, dr \, d\theta^1 \, d\theta^2$ where $\det J = -r^2 \sin(\theta^2) (\sin(\theta^1) \sin(\theta^2)+\cos^2(\theta^2))$ Is it correct?","['coordinate-systems', 'tensors', 'differential-geometry', 'spherical-coordinates']"
970578,Trigonometry equation with arctan,"Solve the following equation: $\arctan x + \arctan (x^2-1) = \frac{3\pi}{4}$. What I did Let  $\arctan x = \alpha, \arctan(x^2-1) = \beta$, $\qquad\alpha+\beta = \frac{3\pi}{4}$ $\tan(\alpha+\beta) = \tan(\frac{3\pi}{4}) = -1$ $$\frac{\tan\alpha + tan\beta}{1-\tan\alpha\tan\beta} = \frac{x+x^2-1}{1-x(x^2-1)} = -1$$ $\begin{align}
x^2+x-1 &= -(1-(x^3-x)) = -1+x^3-x \\
\iff x^2 + x &= x^3-x \\
\iff x(x+1) &= x(x^2-1) \qquad\implies \boxed{x_1 = 0}\\
\implies x+1 &= x^2-1 \\
\iff x^2-x-2 &= 0 \\
\end{align}$ $\therefore x_1 = 0,\quad x_2 = 2,\quad x_3 = -1$ However, the equation only works for $x=2$. I wonder Did I do this in an efficient manner? Is there any easy way to find $x$ where there's no fake solutions?",['trigonometry']
970596,$\sum_{n=1}^\infty \frac{n+1}{\sqrt{n^3+1}}$convergent/divergent?,Please could someone help prove $$\sum_{n=1}^\infty \frac{n+1}{\sqrt{n^3+1}}$$ converges/diverges? Thank you.,"['convergence-divergence', 'sequences-and-series', 'analysis']"
970601,Gradient vs Conservative vector field: What's the difference?,"From the definitions I'm reading between the two: The gradient vector field is defined by its construction: gradient of a scalar (or real) function generally over two or more variables. The conservative vector field is defined by the common characteristic of every curve in this field: only the endpoints matter, not the path. Interpretation wise in traditional multi-variable calculus view, these two type of fields sound exactly the same. I've had some difficulty trying to pinpoint which one is more abstract or specialized, much less their difference. According to Wikipedia (I may have committed blasphemy): Conservative vector fields and the gradient theorem The gradient of a function is called a gradient field. A (continuous)
  gradient field is always a conservative vector field: its line
  integral along any path depends only on the endpoints of the path, and
  can be evaluated by the gradient theorem (the fundamental theorem of
  calculus for line integrals). Conversely, a (continuous) conservative
  vector field is always the gradient of a function. Obviously this doesn't help trying to understand the difference, if any.",['multivariable-calculus']
970615,Showing that a sequence $a_n=(-4)^n$ is a solution of the recurrence relation $a_n = -3a_{n-1} + 4a_{n-2}$,"I'm having some trouble with showing that a sequence $a_n$ is a solution to the recurrence relation $a_n = -3a_{n-1} + 4a_{n-2}$ . (See image below). The sequence is given by $a_n = (-4)^n$ . I'm given the answer in the solutions manual, but I have absolutely no clue what is going on between step II and III. How did they get rid of the $n-1$ exponent? What did they multiply/divide/subtract/add to the equation? \begin{align*}
-3a_{n-1}+4a_{n-2}
& =-3(-4)^{n-1}+4(-4)^{n-1} \\
& =(-4)^{n-2}\bigl((-3)(-4)+4\bigr) \\
& =(-4)^{n-2}\cdot16 \\
& =(-4)^{n-2}(-4)^2 \\
& =(-4)^n \\
& =a_n
\end{align*}","['recurrence-relations', 'sequences-and-series', 'discrete-mathematics']"
970646,Bijection Between $\mathbb{Z}_+$ and a Subset of $\mathbb{Z}_+ \times \mathbb{Z}_+$,"Let $T=\{(a,b)\mid a,b\in\mathbb Z_+, b\leq a\}.$ Find a bijective function $f: T \to \mathbb{Z}_+$ I have tried to find a function but I can't, how does such function look like?",['analysis']
970650,"Verifying that $(G, \circ )$ is a group, where the notion of $G$ and $\circ$ become very complex.","First of it all, sorry about that horrible title, if you know how to refine it please be my guest and do so. This question is of the same caliber as $\hom(V,W)$ is canonic isomorph to $\hom(W^*, V^*)$ that I used to ask a long while ago. Unfortunately this comes with two things. 1st being that I do understand as good as nothing about this problem, 2nd that I need to write a lot of things down in order to even make this post look like a question, although the most honest kind of question I could ask would be ""Whaaaaaa?"" Problem : Let $I \neq \emptyset$ be a set and $(G_i, \circ_i)_{i \in I}$ be a family of groups. Let $G:= \times_{i \in I} G_i$ and consider the mapping $\circ : G \times G \to G$ be defined by  $$ (x_i)_{i \in I} \circ (y_i)_{ i \in I} := (x_i \circ_i y_i)_{i \in I} $$
  Show that $(G, \circ)$ is a group. Wow, okay. I'd love to understand this problem, but I don't. Let me show to you however that I've done my homeworks and at least know what is expected of me. My approach : First I want to introduce all the symbols, starting by the most simple ones $(x_i)_{i \in I}$ is a family of elements in $M$. This makes more sense to me when I consider $M^I := \text{map}(I,M)$ the mappings from $I \to M$ where $I$ is the set of indices. For $I= \mathbb{N}$ I would get the regular sequences with values in $M(=\mathbb{R}/\mathbb{C}$) $\times_{i \in I} G_i:= \lbrace x:I \to \bigcup_{i \in I} G_i \mid x_i \in G_i , \forall i \in I\rbrace $ is the direct product of family of sets $(G_i)_{i \in I}$ for $I= \lbrace 1,2 \rbrace$ I get the cartesian product, I don't quite see it to be honest but I can take it as granted. next for $(G, \circ)$ to be a group I need to verify several things: First the operation $\circ$ must be associative , that is for three elements $x,y,z \in G$ I must show that $x \circ (y \circ z) = (x \circ y) \circ z$. So the elements in $G$ are families $(x_i)_{i \in I}$ with elements in $M$, so I believe I have to show that $$((x_i)_{i \in I} \circ (y_i)_{i \in I}) \circ (z_i)_{i \in I} :\overset{?}= (((x_i)_{i \in I}  \circ (y_i)_{i \in I}) \circ_i z_i)_{i \in I}\overset{?}=(x_i \circ_i y_i \circ_i z_i)_{i \in I} \\ = ???? = (x_i)_{i \in I} \circ ((y_i)_{i \in I} \circ (z_i)_{i \in I}))$$
although I have no idea if I am associating my parenthesis correctly here, the expression is just too complicated for me to handle. then I need to show that there is an neutral element in $G$, that means that for all $(x_i)_{i \in I}$ there is an element such that $$(x_i)_{I \in I} \circ e = e \circ (x_i)_{i \in I} = (x_i)_{i \in I} $$
since we're talking about family of functions maybe the right guess would be the identity mapping, but I am guessing here. finally, I need to show that there exists an inverse element for every element of $G$  so that when I compose it with $\circ$ I get the identity again. Here my journey ends, or begins, there is nothing I can add. I would appreciate some initial kicks that show me how to get going, how to even start formulate a 'proof' or how one can think about all this stuff above. Sorry for the mess.","['self-learning', 'group-theory']"
970660,Character table of the non-abelian group of order 21,"I'm working my way through the first Chapter of Fulton and Harris' Representation Theory and I'm trying exercise 3.26: There is a unique nonabelian group $G$ of order 21, which can be realized as the group of affine transformations $ T_{\alpha,\beta}(x) = \alpha x + \beta$ of the line over the field with seven elements, with $a$ a cube root of unity in that field. Find the irreducible representations and character table. To start, I was trying to find the conjugacy classes of $G$, $\alpha = 1,2,4$. Of course $\{T_{1,0}\}$ is the easiest conjugacy class. Furthermore, I found that $T_{\alpha^{-1},-\alpha^{-1}\beta}$ is the inverse of $T_{\alpha,\beta}$ so using that to find conjugates:
$$T_{\alpha,\beta}\cdot T_{\gamma,\delta} \cdot T_{\alpha^{-1},-\alpha^{-1}\beta} = T_{\gamma, -\gamma \beta + \alpha \delta + \beta}$$ We see that conjugacy classes will be of the form $\{T_{\alpha, x}\}$ so we have at least 3 conjugacy classes. How do I proceed from here? Is this even the right way to tackle this exercise?","['representation-theory', 'group-theory', 'abstract-algebra']"
970696,Why are there so many universal properties in math?,"I don't really understand why there are so many universal properties in math or why they all need to be highlighted. For example, I'm studying some Algebra right now.  I have found three universal properties that are all basically saying the same thing, although the details are different: Universal property 1 : If $R, S$ are rings and $\theta: R \to S$ is a ring map, then for each $s \in S$ , there is a unique map $\hat{\theta_{s}} : R[x] \to S$ such that if $i: R \to R[x]$ is the inclusion map, we get $\theta = \hat{\theta_{s}} \circ i$ . Universal property 2 : If $D$ is an integral domain and $F$ is a field with $\phi : D \to F$ a one-to-one ring map, then there is a unique map $\hat{\phi} : Q(D) \to F$ such that $\hat{\phi} \circ \pi = \phi$ , where $\pi : D \to Q(D)$ sends $a$ to $\frac{a}{1}$ ( $Q(D)$ the fractional field of $D$ ). Universal property two was used to prove that in a field of characteristic $0$ , the rationals are a subfield, and in a field of characteristic $p$ ( $p$ prime), $\mathbb{Z}_{p}$ is a subfield. Universal property 3 : If $R, S$ are rings, $\phi: R \to S$ is a ring map, and $I$ is an ideal such that $I \subseteq \text{ker}(\phi)$ , then there is a unique map $\overline{\phi} : R/I \to S$ such that $\phi = \overline{\phi} \circ i$ where $i: R \to R/I$ maps $a$ to $\overline{a}$ . It is really hard for me to keep track of all of these universal properties, especially when they are all usually referenced by the single name ""universal property"".  Is there a point to all of these universal properties? Honestly, I don't even know if my question is clear, or how to ask a better question in this regard.","['ring-theory', 'category-theory', 'abstract-algebra', 'field-theory']"
970719,Question about complete metric on manifolds,I've recently been wondering about whether non-complete metrics on manifolds can be transformed into complete metrics on manifolds and whether all manifolds have complete metrics. After some googling I came across this link and the first comment says that any metric is actually conformal to a complete metric. I was wondering if anybody can show me a proof of this because I have had difficulty finding one. Thank you!,"['riemannian-geometry', 'differential-geometry']"
970745,Topological Group Structure on a Subset of $\mathbb R$,"I have been pondering over this question for quite a long time. Please help.
Is it possible to define some group operation on $[a,b]$ (with the usual topology inherited from $\mathbb R$) so that it becomes a topological group?
Thanks for any help.",['general-topology']
970754,Proof of Casorati-Weierstrass?,"In Stein's Complex Analysis, he presents the following statement and proof of Casorati-Weierstrass: Suppose $f$ is holomorphic in the punctured disc $D_r(z_0) - \{z_0\}$ and has an essential singularity at $z_0$. Then, the image of $d_r(z_0) - \{z_0\}$ under $f$ is dense in the complex plane. Proof: We argue by contradiction. Assume that the range of $f$ is not dense, so that there exists $w \in \mathbb{C}$ and $\delta > 0$ such that $$|f(z) - w| > \delta$$ for all $z \in D_r(z_0) - \{z_0\}$. We may therefore define a new function on $D_r(z_0) - \{z_0\}$ by $$g(z) = \frac{1}{f(z) - w}$$ which is holomorphic on the punctured disc and bounded by $1/\delta$. Hence, $g$ has a removable singularity at $z_0$. Statement 1: If $g(z_0) \neq 0$, then $f(z) - w$ is holomorphic at $z_0$, which contradicts the assumption that $z_0$ is an essential singularity. Statement 2: In the case that $g(z_0) = 0$, then $f(z) - w$ has a pole at $z_0$ also contradicting the nature of the singularity at $z_0$. The proof is complete. My Question: In regards to statement 1, why precisely is this true? I can rewrite $g(z) = \frac{1}{f(z) - w}$ as $f(z) - w = \frac{1}{g(z)}$, and if $g(z_0) \neq 0$, then $f(z_0) - w$ is defined -- does it immediately follow that $f(z_0)$ is holomorphic at $z_0$?",['complex-analysis']
970778,Möbius Tranformation: Map two non intersecting circles to concentric circles,"Show that two non intersecting circles can always be mapped by a suitable Möbius transformation to two concentric circles. I wanted to map the center of the first circle to the center of the second circle then using scaling the radius would give me the concentric circles. But having problem to execute. Suggestions please,","['mobius-transformation', 'complex-analysis']"
970796,How to solve $1.1^x +1.5^x = 3.46$,"I'm drawing a total blank as to how to solve this for x ... $$
1.1^x + 1.5^x = 3.46
$$ I thought I could differentiate and substitute the first derivative back into the equation, but I must be rustier than I thought because I'm it's not working out correctly. Incidentally, the answer is $x=2$. Any thoughts on how to solve this type of equations would be very much appreciated. Kindest regards, Jack",['calculus']
970806,What is a clever proof of Hilbert's basis theorem?,"So I am studying commutative algebra at the moment and I have come across the proof of the Hilbert Basis Theorem (the proof I have is the same as the one in Reid's Undergraduate Commutative Algebra ). I can't see how I would ever have thought of such a proof and I can't find anywhere which gives a good motivation for it. I wondered if anyone here could help me out? EDIT : Following Martin Brandenburg's advice I will outline the proof and explain where I get the feeling: ""why would you do that?"" Theorem. If $A$ is a Noetherian ring (commutative with 1), then $A[X]$ is also Noetherian. Proof/Discussion. First, we pick any ideal $I$ in $A[X]$. We aim to find a finite set of generators for it. We only have data about ideals in $A$, so we need to pass from the ideal $I$ in $A[X]$ to ideals in $A$. Given any polynomial $f \in I$, a natural way to obtain elements of $A$ is to look at its coefficients. The most ""obvious"" coefficients to look at are the constant term and the leading coefficient. Just looking at the constant terms discards a lot of information about $I$ and so we don't go this way. Let $\lambda(f)$ denote the leading coefficient of $f \in A[X]$. We can define $J=\{a \in A : \exists f \in I \text{ such that } a=\lambda(f)\}$ but this is not necessarily an ideal of $A$. For example, if $a,b \in J$, then $\exists f,g \in I$ with $a=\lambda(f)$ and $b=\lambda(g)$. It is then natural to say, ""well $f+g \in I$ (since $I$ is an ideal) and $\lambda(f+g)=a+b$ so we have $a+b \in J$"" but this only works if $\deg f = \deg g$. So we are led to defining, for each $m\in\mathbb{N},$ $$J_m=\{a \in A : \exists f \in I \text{ with } \deg f = m \text{ such that } a = \lambda(f)\}\cup \{0\}.$$ Then, indeed, each $J_m$ is indeed an ideal of $A$. Now we can use that $A$ is Noetherian to obtain that each $J_m$ is finitely generated: $$J_m=(a_{m1},\ldots,a_{mr_m})$$ for some $a_{ij} \in A$. In particular, given $m \in \mathbb{N}$, we have, for each $1\leq j \leq r_m$, some $f_{mj}\in I$ with $\deg f_{mj}=m$; $\lambda(f_{mj})=a_{mj}$. Define, for each $m\in \mathbb{N}$, $$S_m = \{f_{mj} : 1\leq j \leq r_m\}.$$ We claim that the (infinite) set $S=\bigcup_{m\in\mathbb{N}}S_m$ generates $I$. Suppose $f \in I$ with $\deg f = n$ and $\lambda(f)=a$. Then $a \in J_n$ and so there exists $s_1,\ldots,s_{r_n} \in A$ such that $$a=s_1a_{n1}+\ldots+s_{r_n}a_{nr_n}.$$ Consequently, if we define $g=\sum_{k=1}^{r_n}s_kf_{nk} \in (S_n)$, we have that $\lambda(g)=a$. In particular, $f-g \in I$ with $\deg(f-g)<n$. Proceeding inductively, we obtain $h \in (S_0,S_1,\ldots,S_n)$ such that $f=h$. This shows that $S$ is an infinite set of generators for $I$. However, we now observe that $J_m\subseteq J_{m+1}$ for each $m \in \mathbb{N}$. Indeed, if $a \in J_m$, then we take $f \in I$ with $\deg f=m$ such that $\lambda(f)=a$ and see that $Xf \in I$ (since $I$ is an ideal), $\deg Xf = m+1$, $\lambda(Xf)=a$, whence it follows that $a \in J_{m+1}$. As $A$ is Noetherian it satisfies the ACC on ideals and so there exists $N \in \mathbb{N}$ such that $$J_{N}=J_{N+k} \text{ for all } k \in \mathbb{N}$$ and so the set $S$, which generates $I$, is in fact finite! This concludes the proof. // Having typed it out in this way and really had a good think about it, it doesn't seem too unnatural I suppose (although, of course, I'm still not at all convinced I could have come up with it). I suppose the bit where we notice that the $J_m$'s form an ascending chain seems like a ""bit of good luck"" rather than having any reason to expect that to be the case... What are your thoughts about my interpretation? Many thanks!","['commutative-algebra', 'ring-theory', 'abstract-algebra', 'noetherian']"
970820,N circles in the plane,You are given a family of n pairwise intersecting circles in the plane. No three intersect(share a common point). Find a simple formula for counting the number of regions determined by these circles. Given n=4 we will have 14 regions How can I find this pattern while expanding upwards.,['combinatorics']
970825,"Prove that the closure of complement, is the complement of the interior","Let $(X,d)$ a metric space and $A\subset X$ . Prove that $$\overline{(A^c)}=\overset{\circ}{(A)}^c$$ i.e. the closure of complement, is  the complement of the interior. Proof. If $x\in \overline{(A^c)}$ then $x\in A^c$ or $x\in (A^c)'$ . Since $\overset{\circ}{A} \subset A \Rightarrow A^c \subset \overset{\circ}{(A)}^c$ so, if $x\in A^c$ then $x\in \overset{\circ}{(A)}^c$ . Now if $x \not\in A^c$ but $x\in (A^c)'$ then $\forall r>0, B(x;r)-\{x\}\cap A^c \not= \emptyset.$ And now I've to deduce that $x\not\in \overset{\circ}{A}$ so $x\in \overset{\circ}{(A)}^c$ , but I can't figure out how.","['general-topology', 'real-analysis']"
970849,Limit $\lim_{x \to 1} \ (1-x^2)\tan(\frac{\pi x}{2})$?,"Somebody, help me please with this limit $$\lim_{x \to 1} \ (1-x^2)\tan\left(\frac{\pi x}{2}\right)$$ I've tried to dissasemble this equation into $$\lim_{x \to 1} \ (1-x^2)\frac{\sin\frac{\pi x}{2}}{\cos\frac{\pi x}{2}}$$ Sinus will be equal to 1, so: $$\lim_{x \to 1} \ \frac{(1-x^2)}{\cos\frac{\pi x}{2}}$$ And then I don't know what should i do next. I feel very sorry that i didn't mention it before, but i need to solve it without l'hospital rule.","['limits-without-lhopital', 'limits']"
970853,Four consecutive heads from ten coin flips [duplicate],"This question already has answers here : Probability of tossing a fair coin with at least $k$ consecutive heads (5 answers) Closed 9 years ago . If we flip a fair coin $10$ times, what is the probability we get $\ge 4$ consecutive heads? An approach would be to consider the probability of all consecutive heads, cut off by tails, e.g., HHHHTxxxxx THHHHTxxxx ... HHHHHTxxxx THHHHHTxxxx ... but this is complicated, and also has a problem that some patterns overlap (e.g., HHHHTHHHHT). Is there a simpler way to do this?",['probability']
970868,Why isn't the quotient space $V/V = \{ V \}$?,"If $W \subset V$, then one defines the quotient space, $$V/W = \{ v + W : v \in V \}$$ So why isn't this right? $$V/V = \{v + V : v \in V \} = \{V \}$$? I read that $V/V = \{ 0 \}$? Why can't the whole set $V/V$ be partition, by $V$ itself?",['linear-algebra']
970891,How can I find a closed form for the summation (i^2)(-1^i+1) systematically?,"In one of my homeworks I was given the following sequence $1^2-2^2+3^2-4^2+\dots (-1)^{n+1}n^2$, and I'm supposed to find a closed form formula and prove that it works. Rewriting this as a sum gives the following $$\sum_{i=1}^{n}(-1)^{n+1}i^2$$ I have found the closed form, which is $-\frac{1}{2} (-1)^n n (n+1)$, and I also have the proof, which was trivial to get. The problem is that I do not know how to get to this formula in a systematic way, without a wild guess or a tool like Mathematica, which would somehow just spit out the answer. I started reading Knuth's Concrete Mathematics, which seems to describe how to approach these problems in general, but I'm having a hard time understanding the text (I'm in first semester studying Computer Science.) I tried comparing the data this sum generates ($1, -4, 9, -16, 25, -36, 49, -64$), and tried looking at the prefix sums ($1, -3, 6, -10, 15, -21, 28, -36, 45, -55$), but I just don't know how this is supposed to help me in finding this formula. TL;DR: How can I systematically find a closed form formula for this particular summation, or any arbitrary one in general? I tried looking through the other questions, but they tend to address more complicated formulars which I'm having hard trouble understanding.","['closed-form', 'summation', 'sequences-and-series']"
970892,Show Laplace operator is rotationally invariant,"I'm trying to show the Laplace operator is rotationally invariant. Essentially this boils down to showing
$$\frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2} = \frac{\partial^2 f}{\partial u^2} + \frac{\partial^2 f}{\partial v^2}$$ where
$$u = x \cos \theta + y \sin \theta$$
$$v = -x \sin \theta + y \cos \theta$$ I think I'm on the right track by noting that 
$$\frac{\partial^2 f}{\partial x^2} = \frac{\partial}{\partial x}\left(\frac{\partial f}{\partial x}\right) = \frac{\partial}{\partial u}\left(\frac{\partial f}{\partial x}\right)\frac{\partial u}{\partial x} + \frac{\partial}{\partial v}\left(\frac{\partial f}{\partial x}\right)\frac{\partial v}{\partial x}$$
but I'm having difficulty reaching an end game where I show
$$\frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2} = \frac{\partial^2 f}{\partial u^2}({\sin}^2 \theta + {\cos}^2 \theta) + \frac{\partial^2 f}{\partial v^2}({\sin}^2 \theta + {\cos}^2 \theta)$$","['multivariable-calculus', 'ordinary-differential-equations', 'laplacian', 'partial-derivative', 'derivatives']"
