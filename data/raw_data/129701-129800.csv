question_id,title,body,tags
2007570,Absolute values of complex irreducible characters of finite groups,"I had few questions on complex irreducible characters of finite groups which are mostly on their arithmetic nature. I will also mention here that I am considering only $\mathbb{C}$-irreducible characters of finite groups . If $\chi$ is an irreducible $\mathbb{C}$-character of a finite group $G$, then one can see that $|\chi(g)|\leq |G|$ for any $g\in G$. My question is about opposite side of this fact. To avoid triviality, we do not consider zero  character values. Question 1. Is there lower bound on $\{|\chi(g)|:g\in G\}\setminus \{0\}$? For second question, it is well known that character values are algebraic integers, and so are their absolute values (am I right?). But, absolute values are also real numbers. This forced me to consider the question: Question 2. Consider those real numbers which are absolute values of irreducible $\mathbb{C}$-characters of finite groups. Is this set dense in $\mathbb{R}$? The third question came because of the very basic property of characters. Question 3. Given any algebraic integer, does there exists a finite group which takes this value for some irreducible character? (In other words, does any algebraic integer sits in character table of some finite group?)","['finite-groups', 'representation-theory', 'group-theory', 'characters']"
2007626,Normalisation using Softmax- What advantage does exponential provide,"I am trying to apply some bench marking across different organizations. I have 3 organizations with 3 scores using which I would like to relatively rank them. For e.g. Org 1 = 115, Org 2 = 105, Org 3= 50, then $\mathbf{x} = (115, 105, 50)$ I was told to try Softmax function \begin{equation}
\mathrm{softmax}(\mathbf{x})=\frac{e^{x_{i}}}{\sum_{j=1}^{3}e^{x_{j}}}
\end{equation} as it normalizes the values. I could also normalize using \begin{equation}
\mathrm{standard~normalisation}(\mathbf{x})=\frac{x_{i}}{\sum_{j=1}^{3}x_{j}}
\end{equation} Can anyone tell me what advantage does the Softmax function provide above the standard normalization discussed above? Does the exponential in softmax help in any specific way to increase/reduce the margin between the compared entities?","['statistics', 'functions']"
2007643,Let $A$ be an $n \times n$ matrix with real entries such that $A^2 + I = 0$ then $n$ is even.,"Let $A$ be an $n \times n$ matrix with real entries such that $A^2 + I = 0$ then $n$ is even. And if $n = 2k$, then $A$ is similar over the field of real numbers to a matrix of the block form $$\begin{bmatrix}
    0      & -I \\
    I & 0 \\
\end{bmatrix}$$ 
where $I$ is the $k \times k$ identity matrix. I have done the first part. Since $\det(A^2) = \det (-I)$ we must have $\det (-I)$ non negative and hence $n$ must be even. Need Help in the second part. Thank You.","['jordan-normal-form', 'cyclic-decomposition', 'linear-algebra', 'cyclic-groups']"
2007652,Abstract Algebra Group Theory maximal subgroups,"Let $G$ be a group. Let  $\ g \in G, g \neq e $ where e is the identity element. How do you prove that there is a maximal subgroup of G, say H, with $g \notin H $ ?  Zorn's lemma maybe? Thanks.","['abstract-algebra', 'group-theory', 'elementary-set-theory']"
2007678,Proving that a vector field is conservative using only Green Theorem,"Consider a vector field $F: \mathbb{R}^2/\{\vec{0}\} \to \mathbb{R}^2$ $$F=(F_1(x,y),F_2(x,y))$$ $\mathbb{R}^2/\{\vec{0}\}$  is not a simply connected domain . Suppose also that $F$ is irrotational . Can the following procedure be valid to prove that $F$ is conservative? I find one closed curve $\gamma_1$ that goes around the origin and such that $$\oint_{\gamma_1} F \cdot ds=0$$
(assuming that such curve exists). If I consider any other closed curve $\gamma_2$ that goes around the origin, then I can use Green Theorem and see the union of $\gamma_2 \cup \gamma_1$ as the border of a regular domain in $\mathbb{R}^2$. 
Let's say this domain is $D$: then its border is $\partial D=\gamma_1 \cup \gamma_2$. I have to choose the positive orientation for $\partial D$ but suppose that $\gamma_1$ and $\gamma_2$ already have the right orientations in order to have $+\partial D$ (I think that this is not restrictive). Therefore I can finally say that: $$\oint_{+\partial D} F \cdot ds=\oint_{\gamma_1 \cup \gamma_2 } F \cdot ds=\oint_{\gamma_1  } F \cdot ds+\oint_{\gamma_2  } F \cdot ds= \int \int_{D} \partial_{x} F_2- \partial_{y} F_1=0$$ $$\implies \oint_{\gamma_1  } F \cdot ds=-\oint_{\gamma_2  } F \cdot ds$$
Since $F$ is irrotational. But $\oint_{\gamma_1} F \cdot ds=0$, therefore $$\oint_{\gamma_2  } F \cdot ds=0$$ This is valid for any curve $\gamma_2$ that goes around the origin. (indipendently from the fact that $\gamma_1$ and $\gamma_2$ are indeed oriented in the proper way to have $+\partial D$). For any curve $\gamma_3$ that does not go around the origin it is possible to find a subset $A \subset \mathbb{R}^2/\{\vec{0}\}$ simply connected such that $\gamma_3 \subset A$, and $F$ is irrotational, $F$ is conservative in $A$ and $$\oint_{\gamma_3} F \cdot ds=0$$ So in conclusion we have 
$$\oint_{\gamma} F \cdot ds=0 \,\,\, \forall \gamma \subset \mathbb{R}^2$$ and $F$ is conservative. Is the previous proof valid or are there any mistakes? I think it should be valid, but it looks strange because if it is, I would conclude that $F$ is conservative looking at one only curve $\gamma_1$, which seems a bit reductive I think?","['vector-fields', 'calculus', 'multivariable-calculus', 'integration', 'vector-analysis']"
2007728,Finding matrix BA given AB,"Given a matrix $$AB = \begin{bmatrix}-2&-14&14\\5&15&-10\\4&8&-3\end{bmatrix},$$ where $A$ is a $3\times 2$ matrix, and $B$ a $2\times 3$ matrix, how do I find the matrix $BA$ ? I was told to find the basis for the rowspace of $AB$ , and that $(AB)^2 = 5AB$ . However, I do not see how these 2 informations can help me find $BA$ at all. Any help would be appreciated.","['matrices', 'linear-algebra']"
2007729,"How to obtain the continuity of a binary function w.r.t. one of it's variables, in Applebaum's book for Levy processes?","My question came from page 392 of of D. Applebaum's book ""Levy processes and Stochastic calculus"" . I will put it in a nutshell. Let $\nu$ be a measure on $B_c(0)\setminus\{0\}$ satisfying $\int_{0<|x|<c}|x|^2\,\nu(dx)<\infty$. Function $F:\mathbb R^d\times(B_c(0)-\{0\})\to\mathbb R$ satisfies
  \begin{equation}\tag 1
\int_{0<|x|<c}|F(y_1,x)-F(y_2,x)|^2\,\nu(dx)<K|y_1-y_2|^2,\quad \forall y_1,y_2\in\mathbb R^d,
\end{equation}
  and 
  \begin{equation}\tag 2
|F(y,x)|\le|\rho(x)||\delta(y)|,\quad \forall y\in\mathbb R^d，x\in B_c(0)\setminus\{0\},
\end{equation}
  where $\rho:B_c(0)\setminus\{0\}\to\mathbb R$ satisfies $\int_{0<|x|<c}|\rho(x)|^2\,\nu(dx)<\infty$ and $\delta:\mathbb R^d\to\mathbb R^d$ is Lipschitz continuous. Question: Prove that for each $x\in B_c(0)\setminus\{0\}$, the mapping $y\to F(y,x)$ is continuous. What I can conclude is from $(1)$ that
$$
F(y_n,x)\to F(y,x) \text{ in } L^2(B_c(0)\setminus\{0\},\nu), \quad \text{as } y_n\to y,
$$
as a consequence, there is a subsequence $\{y_{n_k}\}$ such that $
F(y_{n_k},x)\to F(y,x)$ for $\nu$-a.s. $x$. But how to get the continuity of $F(\cdot,x)$ for each $x$? Any comments will be appreciated. Thanks in advance.","['real-analysis', 'probability-theory', 'measure-theory', 'levy-processes', 'stochastic-analysis']"
2007791,Characterise Abelian groups categorially,"I wonder if there is any way to characterise Abelian groups (in Grp ) in the language of category theory. This is so basic that I can't imagine that this is not possible, but I cannot think of a way how. One idea was to say a group is Abelian iff it is equal to its Abelianisation, but this does not work, because in order to define the Abelianisation we already need to know what Abelian groups are. Then I thought maybe requiring that all subgroups are normal would be enough, but this is not strong enough since there are non-Abelian groups with only normal subgroups. There's probably something I'm not thinking about. Would appreciate some input.","['category-theory', 'group-theory']"
2007803,Does $\emptyset \setminus A$ make sense?,Let be $A$ set. Does $\emptyset \setminus A$ make sense?,['elementary-set-theory']
2007851,"What are the inverse operations of the ""Partial derivative"" and the ""Total derivative""?","If a univariate function like $f(x)$ is differentiable, we denote its derivative by $\frac{\mathrm{d} }{\mathrm{d} x}f(x)$ and its integral by $\int f(x)\mathrm{d} x$. If the function happens to be multivariate we denote its ""Partial derivative"" by $\frac{\partial }{\partial x_i}f(x_1,\cdots ,x_i,\cdots ,x_n)$ and its total derivative by $\frac{\mathrm{d} }{\mathrm{d} x_i}f(x_1,\cdots ,x_i,\cdots ,x_n)$. Now this is my question: What are the inverse operations of ""Partial derivative"" and ""Total derivative"" of a multivariate function? Do we have such things as ""Partial Integral"" or ""Total integral"" of a multivariate function? And if this is true, what do we call such ""Partial Integral"" and ""Total integral"" of a multivariate function, and what are the agreed-upon notations for them?","['notation', 'calculus', 'multivariable-calculus', 'inverse', 'definition']"
2007908,Hilbert-C*-Modules and interior tensor products,"Let $A$ and $B$ be $C^*$-Algebras, $E$ a Hilbert-$A$-module, $F$ a Hilber-$B$-Module and 
$$\pi: A \rightarrow \mathcal{L}_B(F)$$ a $*$-homorphisms of C*-Algebras, where $\mathcal{L}_B(F)$ denotes the C*-Algebra of adjointable operators on $F$. Now, let $x \in E$ and $y \in F$ such that
$$\langle y, \pi(\langle x,x \rangle)(y) \rangle=0.$$ I want to show that for any $T \in \mathcal{L}_A(E)$ we have 
$$\langle y, \pi(\langle T(x),T(x) \rangle)(y) \rangle=0.$$
This would prove that the homomorphism $$F \otimes 1: E\otimes_\pi F \rightarrow E\otimes_\pi F $$ is well defined. Thank you","['functional-analysis', 'operator-algebras']"
2008011,Find a mistake in the following bogus proof,"Theorem: The function $f:\mathbb{R} \rightarrow [-10,10]$ defined by $f(x) = \cos(x)+\sin(x)$ for all $x \in \mathbb{R}$ has no maximum or minimum on ($-\infty,+\infty$) Proof: The function is differentiable on $\mathbb{R}$ so one should be able to find its extrema by setting the derivative to 0. In particular, $$(\sin(x)+\cos(x))' = 0$$
$$\cos(x)-\sin(x) = 0$$
$$\sin(x) = \cos(x)$$
$$\sin(x+\pi/2) = \sin(x)$$
$$x+\pi/2 = x.$$ And the final equation is never true.
Yet WolframAlpha disagrees with my conclusions...","['fake-proofs', 'trigonometry']"
2008090,Analytical continuation of complete elliptic integral of the first kind,"I am dealing with a problem involving the complete elliptical function of the first kind, which is defined as: $K(k)=\int_0^{\pi/2} d\theta \frac{1}{\sqrt{1-k^2\sin^2(\theta)}}=\int_0^1 dt \frac{1}{\sqrt{1-t^2}\sqrt{1-k^2 t^2}} $ for $k^2<1$. I am trying to find however how to analytically continue the function for cases where $k^2>1$, and especially when $k^2$ is complex and classify it depending on $\mathrm{Im}(k^2)$ is complex or not. This looks like a very trivial question that must be written somewhere, but i couldn't find it explicitely not in several references or here in the forum. The closest solution i found has been in these notes: http://www.damtp.cam.ac.uk/user/md327/fcm_2.pdf Where they say in a last remark that the analytically continuation should be written in terms of $K(k^2) n +iK'(k')m$, where $k'$ is just the complimentary modulus  and $n,m$ integers, however, right now i don't know how to prove it, and what are the $n,m$ depending on $\mathrm{Re,Im}(k^2)$ Someone can help?","['complex-analysis', 'analytic-continuation', 'elliptic-integrals']"
2008111,Use mathematical induction to prove an assertion [duplicate],"This question already has answers here : Prove that $ n^3 + 5n$ is divisible by 6 for all $n\in \textbf{N}$ [duplicate] (4 answers) Closed 7 years ago . The assertion: $n^3 + 5n$ is divisible by $6$ I have completed the basis step $(n=1)$ and the first part of the induction step $(n=k)$, but I am stuck on the second part $(n=k+1)$. This is what I have so far: For $n=k$: $k^3 + 5k = 6t$ For $n= k+1$: $(k+1)^3 + 5(k+1)$ $= k^3 + 3k^2 + 8k + 6$ $= (k^3 + 5k) + 3k + 3k^2 + 6$ $= 3k^2 + 3k + 6t + 6$
$= ???$ I cannot pull out a $6$ because that would leave halves that cannot be counted as integers. How should I proceed?",['discrete-mathematics']
2008128,Understanding the combinatorial argument for $\binom{\binom{n}{2}}{2} = 3 \binom{n+1}{4}$.,"I was playing around the expression for $\binom{\binom{n}{2}}{2}$, and I discovered that it equals $3\binom{n+1}{4}$. I couldn't come up with any combinatorial argument, but found various ones on this site. I'm trying to understand a particular one. In this comment , the user r9m gives the following combinatorial argument: A direct combinatorial interpretation of the factor $3$ can be obtained by counting number of parallelograms in a equilateral triangle with side length $(n−1)$ and tiled with $(n−1)^2$ equilateral triangles with side length $1$(like this ). Of course one way of counting is $\binom{\binom{n}{2}}{2}$. The other way is divide the parallelograms into $3$ cases (each parallelogram must have its diagonal parallel to one of the $3$ sides of the equilateral triangle) which is $3 \times \binom{n+1}{4}$. I'm having trouble understanding both parts of this argument. In particular, I cannot think of the things to choose from for both binomial coefficients. For the first half, what are the $\binom{n}{2}$ things, from which we need to choose $2$? I suspect that since a parallelogram is uniquely defined in this grid by its longer diagonal, they are the endpoints of the diagonal of a parallelogram. But there are some restrictions for choosing the endpoints of a diagonal: e.g. the line joining them cannot be parallel to any of the sides of the equilateral triangle. For the second half, I understand the factor of $3$, and counting parallelograms with their shorter diagonal parallel of a particular side. However, I cannot see a ""thing"" that exists $n+1$ times in this figure. I suspect $4$ is the number of vertices of a parallelogram, but what is $n+1$?","['combinatorics', 'binomial-coefficients', 'combinatorial-proofs']"
2008138,Exponential of the zero matrix,"It is well-known that the exponential of the zero matrix is the identity matrix, but I tried to prove the opposite implication, and I failed. Can you help me to show that $e^A =I$ implies $A =0$ ? Many thanks!!","['ordinary-differential-equations', 'linear-algebra']"
2008141,Quotient of Polynomial Ring by Irreducible Polynomial is Simple Extension,"Let $F$ be a field, and $f$ an irreducible polynomial in $F[x]$. Is $F[x]/(f)$ necessarily of the form $F(\alpha)$, where $\alpha$ is a root of $f$? The only examples I know, e.g.
$\mathbb{R}[x]/(x^2+1)\cong\mathbb{R}(i)\cong\mathbb{C}$ seems to support the argument. What I know is $K=F[x]/(f)$ is a field when $f$ is irreducible, and $[K:F]=\deg f$. Thanks for any help in proving or disproving.","['abstract-algebra', 'galois-theory', 'extension-field', 'field-theory']"
2008142,Characterising subgroups of Prüfer $p$-groups.,"In my recent study of Artinian modules I have been looking at Prüfer $p$-groups (which I will denote by $\mathbb Z_{p^\infty}$ from now on). I am attempting to prove that $\mathbb Z_{p^\infty}$ is an Artinian $\mathbb{Z}$-module which is not finitely generated. To do this I am trying to show that every proper non-trivial submodule of $\mathbb Z_{p^\infty}$ is equal to $\left(\frac{1}{p^n}\mathbb{Z_{}}\right)/\mathbb{Z}$ for some $n$. I am using the following definition of $\mathbb Z_{p^\infty}$:
$$\mathbb Z_{p^\infty}=\left\{x\in \mathbb{Q}/\mathbb{Z}\mid \exists n:p^nx=0 \right\}$$
I have read in several places, Atiyah & MacDonald Example 6.3 and Wikipedia to name a few, that the subgroups of $\mathbb Z_{p^\infty}$ are of this form. This would demonstrate that $\mathbb Z_{p^\infty}$ is Artinian. However, I can't seem to find anywhere a proof or example showing why all the subgroups are of this form. I would like to understand this further, as it is not immediate to me that this would be the case, but my attempts to figure out why have so far been futile. I may be thinking too much and missing a simple explanation. I have looked at starting with an arbitrary subgroup $H$ such that $H\neq 0$ and $H\neq\mathbb Z_{p^\infty}$ and seeing if I can deduce anything from that. I got this far, but it doesn't seem to be going anywhere. I have also looked at Sylow's theorems, but I'm not sure if they will be any use to me as $|\mathbb Z_{p^\infty}|=\infty$ (unless I'm wrong about this!). I would be extremely grateful if anybody could offer a few hints here as I am slowly losing my sanity trying to figure it out! Thanks, Andy.","['abstract-algebra', 'modules', 'artinian', 'group-theory']"
2008209,"What does it mean to ""provide"" a set with a $\sigma$-algebra?","In the past weeks, I've often read that something is ""provided"" with a $\sigma$-algebra, but I don't understand what this is supposed to mean. For example, when we say that we provide $\Bbb R$ with the Borel algebra, what do we receive? A new set? And why is this even necessary? Edit: I would like to give some additional information on what confuses me here. As another example, take a look at one of the tasks we were given. Let $\Omega \neq \emptyset$ be a set, $(\Xi, \Sigma)$ be a measure space and $f: \Omega \rightarrow \Sigma$ be a map. Define $\sigma(f) := \{f^{-1}(F) : F \in \Sigma \}$. Now, determine $\sigma(f)$ for $f: \Bbb R \rightarrow \Bbb R$, $x \rightarrow x$. In this case, let $\Bbb R$ be provided with the $\sigma$-algebra of the borel sets. How do I have to undertand this in this specific context?",['measure-theory']
2008267,Is it possible to quantify the quality of a probability estimator?,"Given a number of sources of probability estimates, what is the best way to quantify the ""best"" source. For example, let's say I have two sources of estimates, A and B. If A says the probabilities are [.3, .5, .4, .9, .8] and B says the probabilities are [.7, .9, .5, .5, .6] and the event results are [false, false, true, true, false], how does one generally establish whether A or B was ""better?"" I've been asked to clarify the specifics of the question, but my question is less about a specific solution and more that I'm interested in all the angles from which this problem is attacked. If I were pressed into providing specifics, I'd point to a pair of thoughts I've had about this. First, when I hear people say, ""I'm 30% sure that...."" or, ""There's only a 10% chance of that ever happening,"" I have wondered how you could gauge that person's skill at guessing probabilities. Clearly, I could collect a few hundred samples from that individual and see if the stuff he labels at 10% happens roughly 10% of the time, his 20s 20% of the time, 30s 30%, etc. But if the sample set is, say, a dozen different estimates covering the range from 0.0 to 1.0, how do you assess the quality of those estimates? This is a question that's been tickling the back of my mind for years. Second, I might be writing a genetic algorithm that will look at current, highly local, weather patterns and guess the probability of the wind switching to 15-20MPH between SW and NW. I have decades of historical data, taken every few minutes, to train with, but analyzing the fitness of an individual in the gene pool hinges on that individual's accuracy in guessing probabilities.","['machine-learning', 'statistics', 'estimation', 'probability']"
2008314,Square root of normal positive operators over real Hilbert spaces,"A bounded linear operator $A$ on a Hilbert space $H$ is called a positive operator if $\langle Ax, x\rangle \geq 0$ for all  $x$ in $H$. It is known that, if $A$ is a positive operator on a Hilbert space  $H$ over the complex field $\mathbb{C}$, then $A$ has unique positive square root. My question is the following: 
Does a normal positive operator on an infinite dimensional Hilbert space over the real field $\mathbb{R}$ has a normal positive square root? If  exist, is it unique?","['functional-analysis', 'operator-algebras', 'operator-theory']"
2008323,Binomial Coefficient of a Binomial Coefficient,"The question here and here refers a neat identity equating the binomial coefficient of a binomial coefficient to another binomial coefficient. $$\binom {\binom n2}2=3\binom {n+1}4$$ Are there any other similar identities, and is there a systematic way of converting one form to the other?","['combinatorics', 'binomial-coefficients']"
2008338,If $f$ vanishes sufficiently fast at $x_0$ does this imply that all derivatives vanish as well?,"Let $f: U \rightarrow \mathbb{R} $, with $U \subset \mathbb{R}^n$ open, be infinitely differentiable. Suppose there is a $x_0 \in U$ such that $$
\lim_{x \rightarrow x_0} \frac{f(x)}{|x-x_0|^k}=0
$$ for all $k \in \mathbb{N}$. How can we prove that every derivative $D^{\alpha} u(x_0)$, $\alpha \in \mathbb{N}^n$, is zero? For $|\alpha|=1$ we can just use the definition of the partial derivative. But in the case $n=2$ this already gets messy.","['derivatives', 'real-analysis']"
2008373,Cauchy's integral formula with high tech methods,"Using Stokes theorem there is particularly nice way to prove Cauchys theorem. If $U$ is a domain in $\mathbb{C}$ with (piecewise) smooth boundary $\Gamma$, then for all differentiable functions $g: \bar U \rightarrow \mathbb{C}$ we have
$$
 \int_\Gamma g dz = \int_Ud(gdz)=\int_U \frac{\partial g}{\partial \bar z} d\bar z \wedge dz = 2i \int_U \frac{\partial g}{\partial \bar z} d\mathcal{L}^2
$$
(where $\mathcal{L}^2$ is the two dimensional Lebesgue measure on $\mathbb{C}$). Consequently, if $g$ is holomorphic, then the line integral over $\Gamma$ vanishes. I want to know if this reasoning also gives rise to Cauchy's integral formula. How do I want to do this? For simplicity we assume that $0 \in U$ and want to prove that
$$
 f(0) = \frac{1}{2\pi i} \int_\Gamma \frac{f(z)}{z} dz.
$$
The function $z \mapsto \frac{1}{z}$ is locally integrable over $\mathbb{C}$ and  homogeneous of degree $-1$, hence it can be considered as a tempered distribution which is also homogeneous of degree $-1$. Since this distribution is holomorphic away from $0$, we conclude that $\frac{\partial}{\partial \bar z}\frac{1}{z}$ has its support in $\{0\}$ and is homogeneous of degree $-2$. Consequently it is a multiple of the Dirac distribution at $0$, which we denote by $\delta$. Either by a computation or in anticipation of Cauchy's formula we may assume that
$$
\frac{\partial}{\partial \bar z}\frac{1}{z} = \pi \delta
$$
To prove Cauchy's integral formula I want to perform the following computation: Let $f$ be holomorphic in a neighbourhood of $\bar U$, then (trusting our inner physicist) we see
$$
\frac{1}{2\pi i} \int_\Gamma \frac{f(z)}{z} dz = \frac{1}{\pi} \int_U\frac{\partial }{\partial \bar z}\left(\frac{f(z)}{z}\right)  d\mathcal{L}^2 = \frac{1}{\pi} \int_U f(z) \frac{\partial}{\partial \bar z}\frac{1}{z} d\mathcal{L}^2 = \int_U f(z)  \delta d\mathcal{L}^2 = f(0)
$$
Of course this is not rigorous, the main problem being that we are dealing with a tempered distribution, which we can only apply to Schwartz functions and not to holomorphic functions. My question is: Can we do this in a rigorous way, somehow using holomorphic functions as test functions? (In light of this question I read about hyperfunctions, which somehow seem to be related, but at a first glance the theory seemed to be quite extensive - too much to answer the question myself right now. So maybe if anyone is familiar with these concepts my question might be very easy to answer. Any ideas are welcome!)","['functional-analysis', 'complex-analysis', 'real-analysis']"
2008388,Prove ${{n+1} \choose {m+1}} = \sum_{k=m}^{n}{k \choose m}$ using a purely combinatorial argument. [duplicate],"This question already has answers here : Proof of the hockey stick/Zhu Shijie identity $\sum\limits_{t=0}^n \binom tk = \binom{n+1}{k+1}$ (20 answers) Closed 7 years ago . Prove ${{n+1} \choose {m+1}} = \sum_{k=m}^{n}{k \choose m}$ using a
  purely combinatorial argument. I don't think I understand how to do a combinatorial proof. I know the left side expands to: $${{n+1} \choose {m+1}} = \frac{(n+1)!}{(m+1)!(n+1-m-1)!} = \frac{(n+1)!}{(m+1)!(n-m)!}$$ For the right side: $$\sum_{k=m}^{n}{k \choose m} = {{k+1} \choose {m+1}} = \frac{(k+1)!}{(m+1)!(k+1-m-1)!} = \frac{(k+1)!}{(m+1)!(k-m)!}$$ Which is similar to what I got on the top. Where do I go from here?","['combinatorics', 'elementary-set-theory']"
2008417,Calculating ...5(5+4(4+3(3+2(2+1(1))))),"I've been puzzling over this question for a while now, and I've finally decided to turn to the StackExchange community in order to get an answer. How would one determine the value of the expression ...5(5+4(4+3(3+2(2+1(1)))))) to n , assuming that in this case n = 5? Cheers!",['sequences-and-series']
2008440,Sum of the inverse of all positive integers which do not contain the digit 8 [duplicate],"This question already has answers here : Does the harmonic series converge if you throw out the terms containing a $9$? [duplicate] (2 answers) Closed 7 years ago . Let $No8$ be the set of positive integers that do not contain the digit $8$. For example, $123456790 ∈ No8$ but $1234567890 \notin No8$. Show that $$\sum_{n\in No8} \frac 1n<80$$ The bound in the above inequality is not the best possible; what is the best upper bound for $\sum_{n\in No8} \frac 1n$?","['real-analysis', 'calculus', 'functions', 'number-theory', 'summation']"
2008442,$\sum_\limits{n=0}^{\infty} a_n$ converges $\implies \sum_\limits{n=0}^{\infty} a_n^2$ converges [duplicate],"This question already has answers here : Prove that if $\sum{a_n}$ converges absolutely, then $\sum{a_n^2}$ converges absolutely (3 answers) Closed 7 years ago . Let $(a_n)$ be a sequence of positive terms and suppose that $\sum_\limits{n=0}^{\infty} a_n$ converges. Show that $\sum_\limits{n=0}^{\infty} a_n^2$ converges. This is in the section on the Comparison Test so that must be what I'm supposed to use.  But I don't see how.  $(a_n)^2$ might be smaller or larger than $a_n$ depending on $a_n$.  And I can't use the Comparison Test with some other series because there's no info here about how fast $\sum a_n$ converges.  Hmm.  Any hints?","['real-analysis', 'sequences-and-series', 'calculus']"
2008446,"Elementary Cardinal Arithmetic question from Jech's ""Set Theory""","Exercise 5.19 in Jech's ""Set Theory"" If $\alpha \lt \omega_1 $ then prove $\aleph_\alpha^{\aleph_1} = \aleph_\alpha^{\aleph_0}\cdot2^{\aleph_1}$ I have no idea how to even start with this type of question (but I am sure it will help me with a later question which I am struggling with which I cannot ask here, as it is graded). The latter half of Chapter 5 is littered with theorems but scanning each to find something usable has not been the most logical approach.",['elementary-set-theory']
2008474,Prove that 11 divides a if and only if 11 divides the alternating sum of the digits of a,Been stuck in this problem for quite a  while. Apparently uses modular congruence to solve.,"['congruence-relations', 'number-theory', 'elementary-number-theory', 'modular-arithmetic', 'discrete-mathematics']"
2008494,Solution to $\frac{x}{\tan\left(\frac{\pi}{2}-\frac{\pi}{x}\right)}=\pi$,"In the following equation, is it possible to solve for numerical value of $x$. $$\frac{x}{\tan\left(\frac{\pi}{2}-\frac{\pi}{x}\right)}=\pi$$","['algebra-precalculus', 'trigonometry']"
2008508,Proving Caratheodory measurability if and only if the measure of a set summed with the measure of its complement is the measure of the whole space.,"Suppose we have a premeasure $\mu$ on a space $X$ such that $\mu(X) < \infty$. Prove that $E \subset X$ is Caratheodory measurable iff $ \mu^*(E)+ \mu^*(E^C) = \mu(X)$. Going in the forward direction is fairly easy. Assuming that E is Caratheodory measurable, we can just substitute X into $\mu^*(A) = \mu^*(A \cap E) + \mu^*(A \cap E^C) $, and then we note that the outer measure and the premeasure of X themselves would have the same value. The other direction is more difficult however. My primary idea of how to solve this part is to show that $\mu^*(A)$ and $\mu^*(A \cap E) + \mu^*(A \cap E^C) $ are both greater than and less than each other to show equality. However, I am not completely sure how to proceed with this. Can anybody provide any pointers as to how to prove the equality between these two expressions?","['measurable-sets', 'measure-theory']"
2008658,Measure of a Borel set.,"Let $f: [0,1)\rightarrow [0,1)$ be defined by
$$f(x)=
\begin{cases} 
\hfill 2x   \hfill & x < \frac12 \\
\hfill 2x-1 \hfill & \frac12\le x<1 \\
\end{cases}$$
Suppose $E$ is a Borel subset of $[0,1)$ such that $f^{-1}(E)=E$. Use a density point argument to show that $m(E)=0$ or $m(E)=1$. I have tried to use the symmetry of the preimages of $E$ to imply the measure of $E$ is arbitrarily close to 1 and therefore equal to 1. However, I still stuck on this. Could you help me with this? Thank you very much.","['multivariable-calculus', 'real-analysis']"
2008662,"Why is $(z^2-x^2y, y^2-xz, x^3-yz)$ a prime ideal?","How can I prove that the ideal $I = (z^2-x^2y, y^2-xz, x^3-yz)$ is a prime ideal of $ K[x,y,z]$. I want to construct a morphism $\phi:K[x,y,z] \rightarrow K[t,s]$ whose kernel is equal to $I$ but from the picture I just don't see a parametrization or how to do it.","['algebraic-geometry', 'commutative-algebra']"
2008709,Shape of spectrum of bounded linear operator on complex Banach space,"I was reading Kreyszig’s Introductory Functional Analysis with Applications some time ago in which the author discusses bounded linear operators $T$ on complex Banach spaces $X$, proving results such as that the spectrum $\sigma(T)$ ($\lambda\in\mathbb{C}$ such that $(T-\lambda I)^{-1}$ is not a bounded operator defined on a set dense in $X$) is closed and (using complex analysis ) that it is nonempty and has spectral radius $\sup{|\lambda\in\sigma|}=\lim_\limits{n\rightarrow\infty}{||T^n||^{\frac{1}{n}}}$ (where the norm of an operator is defined in the usual way as $||T||=\sup_\limits{||x||=1}{||Tx||}$). The use of complex analysis and bounding within a disk made me think for some reason of the Mandelbrot set and wonder whether there could exist a bounded linear operator whose spectrum ‘happened’ to be the Mandelbrot set, and if so how it would be found. Specifically are there higher-order constraints on the shape of the spectrum of these operators? I could not think of any immediate way of doing the problem in reverse to try to define an operator whose resolvent would not exist at specified locations, or perhaps this is actually trivial (the book did not touch on this topic too deeply)? I could find nothing relevant when I searched for this sort of thing. Thus my question is the following: can bounded linear operators on complex Banach spaces have relatively arbitrary shapes in the complex plane and if not what are the constraints? Finally, within those constraints is it possible to find possible operators and Banach spaces (since we constrain neither) for given spectral shapes?","['functional-analysis', 'complex-analysis', 'spectral-theory', 'operator-theory']"
2008724,"$O$ is the center of the circle, $AC$..","In the given figure,  $O$ is the center of the circle,  $AC$ is the chord and $BT=TC$. Prove that $\angle OAT=\angle OBT$. My Attempt 
If we join $BC$ then we have, 
$\angle TBC=\angle TCB$  {Given that $BT=TC$}.
And,
$\angle AOB=2\angle TCB=2\angle TBC$    {By the relation that central angle is double of inscribed angle standing on same arc and from above}. I got struck at here. Please help me to complete this.",['geometry']
2008746,Prove that$f(n) = 16n^3+12n^2+3n+1$ is a perfect square if and only if $n = 0$,"Prove that the polynomial $f(n) = 16n^3+12n^2+3n+1$ from $\mathbb{Z} \to \mathbb{Z}$ is a perfect square if and only if $n = 0$. I thought about factoring this polynomial but didn't see an easy way of doing that. I also thought about using a modular arithmetic argument, but wasn't sure which modulus to chose. What else can we do?",['number-theory']
2008747,Is there a mistake in the problem? Continuity of a two-variable function.,"Let $\phi : \mathbb{R} \rightarrow \mathbb{R}$ be a $C^2$ function, such that $\phi (0) = 0$ and $\phi''(0) \neq 0$. If
$$
f(x,y) = 
\begin{cases}
 \frac{x\phi(y) - y\phi(x)}{x^2+y^2}, &\text{if } (x,y) \neq (0,0) \\
 0, &\text{if } (x,y) = (0,0)
\end{cases},
$$
then show that $f$ is continuous, but not $C^1$. I have tried solving it. The problem is, that if $\phi(x)=\sqrt{x}$, then $f$ would not be continuous (taking the path $y=2x$, and letting $x \rightarrow 0$ makes the limit $-\infty \neq 0$). Did I not understand the question properly? Is taking $\phi(x) = \sqrt{x}$ as a counter example a mistake? Is there some mistake with the problem? And if not, could I get some sort of hint on solving it, as I have tried a few methods, but I can't seem to solve it. Edit: I may have solved it, but I am not sure if it is correct. Let $\epsilon > 0$. We have
\begin{align}
|f(x,y) - f(0,0)| &= \frac{|x\phi(y)-y\phi(x)|}{x^2+y^2} \\
&\leq \frac{|x||\phi(y)|+|y||\phi(x)|}{x^2+y^2} \\
&\leq \frac{\sqrt{x^2+y^2}(|\phi(y)| + |\phi(x)|)}{x^2+y^2}, \quad \text{since }|x|,|y|\leq\sqrt{x^2+y^2} \\
&= \frac{|\phi(x)| + |\phi(y)|}{\sqrt{x^2+y^2}}.
\end{align} For any of those $x,y \in \mathbb{R}^*$, because $\phi$ is continuous at $0$ with $\phi(0) = 0$, by having $\epsilon_1 = y^2 > 0$ and $\epsilon_2 = x^2 > 0$, there must be some $\delta_1, \delta_2 > 0$, such that if $|x|\leq\delta_1$ and $|y|\leq\delta_2$, then $|\phi(x)|\leq\epsilon_1=y^2$ and $|\phi(y)|\leq\epsilon_2=x^2$. From this, we pick $\delta_m = \min\{\delta_1, \delta_2\}$ and have $|x|,|y|\leq\delta_m$. Continuing
\begin{align}
\frac{|\phi(x)| + |\phi(y)|}{\sqrt{x^2+y^2}} &\leq \frac{x^2+y^2}{\sqrt{x^2+y^2}} \\
&= \sqrt{x^2+y^2} \\
&\leq |x| + |y| \\
&\leq 2\delta_m
\end{align} We pick $\delta = \min\{\epsilon, 2\delta_m\}$, making $f$ continuous at $(0,0)$. Could someone tell me if taking $\epsilon_1 = y^2$ and $\epsilon_2 = x^2$ was a mistake?","['multivariable-calculus', 'continuity']"
2008784,What is the reasoning behind why the ratio test works?,"The ratio test says that, if we have the positive series $$\sum_{n=1}^{\infty} a_n,$$ such that $\lim_{n \to \infty} \dfrac{a_{n+1}}{a_n} = L$ , then (1) if $L < 1$ , then $\sum_{n=1}^{\infty}a_n$ is absolutely convergent; (2) if $L > 1$ , then $\sum_{n=1}^{\infty}a_n$ is divergent; (3) if $L = 1$ , then the ratio test gives no information. I want to understand the reasons behind why and how this works, rather than just memorising formulae. I have attempted to reason about this theorem myself. It can be seen that we're taking the ratio between the second term in the series, $a_{n+1}$ , and the first term in the series, $a_n$ . This is exactly how one finds the common ratio in a geometric sequence ( $r = \dfrac{a_{n+1}}{a_n} )$ . We then take the limit of this ratio, which I assume is to find the relative rate of change between $a_{n+1}$ and $a_n$ . In which case, it is more effective to take the absolute value of the limit, $\lim_{n \to \infty} \begin{vmatrix}{ \dfrac{a_{n+1}}{a_n} }\end{vmatrix} = L$ . This seems analagous to how the limit comparison test theorem works. Therefore, I presume that, if $L < 1$ , then this implies that $a_n$ has a greater rate of change than $a_{n+1}$ , which implies that each successive term in the series is getting smaller, and so as we go to infinity, each successive term is converging towards $0$ . As such, the series should converge to some value. Analogously, I presume that, if $L > 1$ , then this implies that $a_{n+1}$ has a greater rate of change than $a_n$ , which implies that each successive term in the series is getting larger, and so as we go to infinity, the terms diverge towards infinity. Is this reasoning correct? If anything is incorrect, then please clarify why it is incorrect, and what the correct reasoning is.","['intuition', 'real-analysis', 'sequences-and-series']"
2008811,Independence of 2 events involving inner products of random vector,"We have $4$ fixed $n$-dimensional binary vectors $U,V,A,B$. We have another random $n$-dimensional binary vector $Z$ where each element is Ber$(p)$. So $P$ is a event where $\left<U,Z\right>\equiv\left<V,Z\right>\pmod 2$ (inner product) and $Q$ is an event where $\left<A,Z\right>\equiv\left<B,Z\right>\pmod 2$. So are $P$ and $Q$ independent or not? Note that all calculations are done modulo $2$.","['independence', 'probability-theory', 'probability']"
2008842,What is this group isomorphic to?,"Let $G=S_n$ act on $\{1,2,...,n\}$ and let $A\subset \{1,2,...,n\}$ so that $|A|=k$. If $G_A$ is the subset of $G$ that fixes all the points in $A$, what is $G_A$ isomorphic to? It makes sense that $G_A$ would be isomorphic to $S_{n-k}$ since, the $k$ points are fixed and that would result in $k$ one-cycles. What would be the best way of going about proving this?","['permutations', 'abstract-algebra', 'combinatorics', 'group-theory']"
2008873,Finding the range of the $n$-dimensional polar coordinate transform,"Let $x=(x_1, \cdots, x_n)\in \mathbb{R}^n$ be Cartesian coordinates and $(r,\theta)=(r,\theta_1, \cdots , \theta_{n-1})$, where $r\in (0,\infty), \theta_1,\dots, \theta_{n-2}\in (0,\pi)$ and $\theta_{n-1}\in (-\pi,\pi)$ be polar coordinates. The coordinate transform is given by 
$$\Psi:(r,\theta_1, \cdots, θ_{n - 1})\mapsto x=\begin{cases} x_1=r\cos{\theta_1}, \\
x_2=r\sin{\theta_1}\cos{\theta_2}, \\
x_3=r\sin{\theta_1}\sin{\theta_2}\cos{\theta_3}, \\
\vdots \\
x_{n-1}=r\sin{\theta_1}\sin{\theta_2}\dots \sin{\theta_{n-2}}\cos{\theta_{n-1}}, \\
x_n=r\sin{\theta_1}\sin{\theta_2}\dots \sin{\theta_{n-2}}\sin{\theta_{n-1}}.
\end{cases}$$ I am trying to find the range of this function $\Psi$. I think it is $\mathbb{R}^n \backslash \{x:x_n=0,x_{n-1}\le 0\}$, but I cannot think of a way to show this explicitly from the definition of $\Psi$. I would greatly appreciate any help.","['multivariable-calculus', 'polar-coordinates']"
2008875,How Many 5 Card Hands Have At Least 2 7s,I am trying to find out how many 5 card hands have at least two 7s. I came up with the following solution: $${4 \choose 2}{48 \choose 3} + {4 \choose 3}{48 \choose 2} + {4 \choose 4}{48 \choose 1} = 108336$$ Is this correct or am I on the right track?,"['probability', 'discrete-mathematics']"
2008885,"Projective space, explicit descriptions of isomorphism between homology.","NOTE: This is a followup question to my question here . Consider $\mathbb{P}_\mathbb{R}^2$ , i.e. the $\mathbb{R}$ -projective plane. Here is a CW complex structure on $\mathbb{P}_\mathbb{R}^2$ . A $0$ -cell $e^0$ , a $1$ -cell $e^1$ , and a $2$ -cell $e^2$ which is attached to $e^1$ by a degree $2$ map. Here is a $\Delta$ -complex structure on $\mathbb{P}_\mathbb{R}^2$ . Question. What's an explicit description of the isomorphism between $H_*^{\text{cellular}}(\mathbb{P}_\mathbb{R}^2)$ and $H_*^{\text{simplicial}}(\mathbb{P}_\mathbb{R}^2)$ given the specific cellular structure and specific simplicial structure I have chosen to endow $\mathbb{P}_\mathbb{R}^2$ with here? Daniel McLaury gave the following answer here . In general, if you want the map from cellular homology to singular homology, just notice that if you have a homology class represented by a cell then that cell's closure can be regarded as a singular simplex, so send the cell to itself. If you want to talk about simplicial homology here, probably the easiest way of thinking about things is to show that both cellular and simplicial homology are isomorphic to singular homology.  That way you don't have to worry about comparing the simplicial structure you've chosen with a cellular structure you've chosen.  And the situation above works for both cases. However, that does not answer my question. I'm interested in an explicit description of the isomorphism between $H_*^{\text{cellular}}(\mathbb{P}_\mathbb{R}^2)$ and $H_*^{\text{simplicial}}(\mathbb{P}_\mathbb{R}^2)$ given the specific cellular structure and specific simplicial structure I have chosen to endow $\mathbb{P}_\mathbb{R}^2$ with here.","['algebraic-topology', 'general-topology', 'fundamental-groups', 'homology-cohomology']"
2008917,Matrix multiplication using Galois field,"$$\begin{bmatrix}1 &1 &6\\4& 3& 2\\5 &2& 2\\5& 3& 4\\4& 2& 4\end{bmatrix}\begin{bmatrix}4\\5\\6\end{bmatrix} = \begin{bmatrix}3\\5\\4\\3\\2\end{bmatrix}. $$
I am not getting that how come this result is possible ? [Editor's comment #1: The question makes sense, but the asker forgot to explain their notation - possibly because they have not been exposed to any alternatives (happens regrettably often when programmers and/or telecommunication majors are introduced to finite fields). Below please find an elaboration of my educated guess, JL.] Here the notation is using a common way of writing polynomials with binary coefficients as integers. We are working over the field $GF(2^3)$ aka $\Bbb{F}_8$ defined as $\Bbb{F}_2[\alpha]$, where $\alpha$ is a zero of an irreducible cubic. We then compactly represent an arbitrary element 
$$
z=a_0+a_1\alpha+a_2\alpha^2\in GF(8), \ a_0,a_1,a_2\in GF(2),
$$
as the sequence of bits
$$
z=a_2a_1a_0
$$
that is then (internally to the computer program) stored as the integer
$$
i(z)=(a_2a_1a_0)_2
$$
in base two. For example, the element $\alpha^2+\alpha$ is converted to $6$, because
$$
\alpha^2+\alpha=1\cdot\alpha^2+1\cdot\alpha^1+0\cdot\alpha^0=110_2=6.
$$ [Editor's comment #2: A popular choice is that $\alpha$ is a zero 
of the polynomial $x^3+x+1$. In other words, we have the equation
$$
\alpha^3+\alpha+1=0.
$$
Unless I made a mistake, the first component of the matrix product above matches with this minimal polynomial in the sense that the calculation
$$
1\cdot4+1\cdot5+6\cdot6=1\cdot\alpha^2+1\cdot(1+\alpha^2)+(\alpha+\alpha^2)^2=\alpha+1=3,$$
is true when $\alpha^3+\alpha+1=0$, JL.]","['matrices', 'finite-fields', 'matlab', 'linear-algebra']"
2008969,Proportion of cube closer to centre than outside,"The question ‘what proportion $p_2$ of a square is closer to the centre than the outside?’ has been asked here before and the answer shown to be $\frac{4\sqrt{2}-5}{3}$. In another question asking the same for an equilateral triangle an answer is given generalizing this to a regular $n$-gon . I once extended the solution method of this answer to computing the proportion $p_3$ of a cube closer to the centre than the outside, by considering a $2\times2\times2$ cube centred at the origin and considering by symmetry only the square pyramid whose base is the side $y=1$ and apex is the origin $(0,0,0)$ and then further restricting this by requiring by symmetry $z>0$ and $x>z$ (the volume under consideration will then be $\frac{1}{48}$th of the cube). The integrand of our problem is then $\frac{1-x^2-z^2}{2}-x$ but the limits of the integration become more complex than the two-dimensional case, and the solution to the problem is now given (unless I’ve made an error) by: $$p_3=6\int_{0}^{\frac{\sqrt{3}-1}{2}}\int_{z}^{\sqrt{2-z^2}-1}\frac{1-x^2-z^2}{2}-x\;dx\;dz$$ where the upper limits of the integrations are found by solving $\frac{1-x^2-z^2}{2}=x$ and then $\sqrt{2-z^2}-1=z$ and the lower limits follow by the definition of the region we are integrating on; the factor of $6$ comes from dividing $48$ by $2^3$ (the volume of the whole cube). I once managed to integrate this by hand to: $$p_3=\frac{5}{4}-\frac{9\sqrt{3}}{8}+\frac{\pi}{4}$$ and Wolfram Alpha agrees giving $p_3\approx0.086841$. However, if we step this up to a 4-cube then the integral becomes correspondingly more complicated and I have no idea how to explicitly compute the resulting integral. I do not know how this method could possibly be extended easily either. My question is this: the problem of what proportion $p_n$ of an $n$-cube is closer to the centre than the periphery seems to be one that might have a simpler or deeper way of solving it (perhaps just because it can be stated so easily); is there an alternative solution method to just doing a brute force integration over the bounding region? If not, is there any way the integration can be transformed to be more tractable so that for instance it can be calculated explicitly for a 4-cube?","['volume', 'integration', 'definite-integrals', 'geometry']"
2008999,Shortest number of steps to reach a position,"I'm on an infinite number line. I start at 0 and at each step can move to the left or to the right. At the $n$'th step my step length is n. So my motion can be $1$ move to the right, $2$ moves to the left and then $3$ moves to the right. What is the minimum number of steps required to reach $n$-th position? I'm looking for closed form solutions - I've realised that it is always possible to reach the $n$-th position in atmost $2n-1$ moves where $n>0$ and $-2n$ moves where $n<0$. How do I get a closed form? I tried to formulate the problem as a recurrence relation, where $f(n):\mathbb{Z}\to\mathbb{N}$ is the minimum number of steps needed to reach the $n$-th position and ended up with this $$f(n\pm f(n))=f(n)-1$$ where  the $\pm$ means that it's sometimes plus and sometimes minus. This may seem to be rubbish to you, but this is all I could do. Please help, thanks.","['combinatorics', 'graph-theory', 'recurrence-relations', 'discrete-mathematics']"
2009027,Lie algebra of the two dimensional torus,"In ""An Introduction To Manifold (2nd Edition)"" Remark 16.15, it says "" For the torus $\mathbb{R}^2 / \mathbb{Z}^2$, the Lie algebra $\mathfrak{g}$ has $\mathbb{R}^2$ as the underlying vector space and the one-dimensional Lie subalgebras are all the lines through the origin"". My questions are: What's the bracket of $\mathfrak{g}$ which has $\mathbb{R}^2$ as underlying vector space? To make $\mathbb{R}^2$ as a Lie algebra, we can define $[x,y] = 0, x,y\in \mathbb{R}^2$, or $[a,a]=[b,b]=0$ and $[a,b]=a$ where $a$ and $b$ are two basis of $\mathbb{R}^2$. Are both bracket definition valid for 2-torus? Are there possible other lines than those passing through the origin that are one-dimensional Lie subalgebras with bracket definitions other than above two? Thanks","['manifolds', 'differential-geometry', 'lie-algebras']"
2009036,Induction proof using inequalities,"I'm having trouble proving the following by induction: $\forall n \in \mathbb{N}, (n\ge2) \implies ((\sqrt{2})^n \le n!)$ So far I solved the base case for n = 2. $((\sqrt{2})^2 \le 2!)$ is true. However I'm having trouble determining the induction hypothesis and conclusion, and am just generally lost on how to proceed. Any suggestions?","['induction', 'proof-writing', 'discrete-mathematics']"
2009042,Estimating entropy from a set of measurements,"Given a set of measurements, such as $528, 412, 281, 66, 338, 249$, is it possible to compute an estimate on how much entropy each measurement provides? Just to clarify: I seek an estimate for the amount of unpredictability to expect from a measurement, measured in bits (shannons). I am experimenting with ways to harvest entropy (for seeding a cryptographically secure pseudorandom number generator), and one of my entropy sources provides imprecise measurements of the time a process takes to complete. The process is the same each time, the measurement should be approximately the same each time, so variation should (by design) mainly be due to measurement error. The smallest theoretically possible measurement is $0$, the largest is unknown. My math background is limited, so I would appreciate clear and comprehendible explanations.","['information-theory', 'statistics', 'entropy', 'probability']"
2009070,Positive square root on a real Hilbert space?,"I've found several references stating that when $T: H \to H$ is a positive, bounded linear operator on a complex Hilbert space, it has a unique positive square root, i.e. a positive, bounded linear operator $S$ such that $S^2=T$. What can we say when $H$ is a real Hilbert space? Does there always exist a positive square root, but which is non-unique? What kind of statements about the existence and uniqueness of a positive square root hold in this case?","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
2009098,"(Geometry) Circle, angles and tangents problem","Let P be an external point of a circle with center in O and also the intersection of two lines r and s that are tangent to the circle. If PAB is a triangle such that AB is also also tangent to the circle, find AÔB knowing that P = 40°. I draw the problem: Then I tried to solve it, found some relations, but don't know how to proceed. I highly suspect that PAB is isosceles, but couldn't prove it.",['geometry']
2009129,"Let $G$ be a finite abelian group with elements $a_1,a_2,\dots,a_n$. If $G$ has more than one element of order $2$ then $a_1a_2\dots a_n=1$.","Let $G$ be a finite abelian group with elements $a_1,a_2,\dots,a_n$. If $G$ has more than one element of order $2$ then $a_1a_2\dots a_n=1$. Attempt Clearly, if $a_i$ is not of order 2, the inverse of $a_i$ must be in the product. So the elements left are all of order $2$ or identity, say $b_1,b_2,\dots,b_m$ Since $b_i^2=1$ for $i=1,\dots,m$. Let $H=\{1,b_1,\dots,b_m\}$ Then $H \cong C_2\times C_2 \times\dots \times C_2$. For $C_2\times C_2$, it is indeed $V$-group $\{1,a,b,ab\}$. Clearly, $1abab=1$. Assume the result holds for direct product of less than $k$ cyclic groups of order $2$.
Let $H$ be a direct product of $k$ cyclic groups of order $2$. Write $H=\langle b_1\rangle \times \dots \times \langle b_k\rangle$. Consider $K=\langle b_1\rangle \times \dots\times \langle b_{k-1} \rangle$. Then the result holds for $K$. Now I need to relate this result to $H$.","['finite-groups', 'abstract-algebra', 'group-theory']"
2009134,Why is this trigonometric identity true?,"Suppose $$\frac{{{{\sin }^4}(\alpha )}}{a} + \frac{{{{\cos }^4}(\alpha )}}{b} = \frac{1}{{a + b}}$$ for some $a,b\ne 0$. Why does $$\frac{{{{\sin }^8}(\alpha )}}{{{a^3}}} + \frac{{{{\cos }^8}(\alpha )}}{{{b^3}}} = \frac{1}{{{{(a + b)}^3}}}$$",['trigonometry']
2009178,Partial derivatives of implicit functions,"So, I have an implicit expression for a change of variables from Cartesian to a different system using $u$ and $v$. This is given by: $G(x,y,z,u,v)=0$, $F(x,y,z,u,v)=0$, where $F$, $G$, $u=f(x,y,z)$ and $v=g(x,y,z)$ are all differentiable. Differentiating F, say, we get: $\frac{dF}{dx} = \frac{\partial{F}}{\partial{x}} + \frac{\partial{F}}{\partial{u}} \frac{\partial{u}}{\partial{x}} + \frac{\partial{F}}{\partial{v}}\frac{\partial{v}}{\partial{x}}$ My questions: Is this because you have $\frac{\partial{x}}{\partial{x}} = 1$, and  $\frac{\partial{y}}{\partial{x}} = \frac{\partial{z}}{\partial{x}} = 0$? This seems like an obvious question but I don't really understand where the $ \frac{\partial{F}}{\partial{x}}$ term is coming from, or why is just appears here. For example if we had $f(x,y,z)=f(x(t), y(t), z(t))$, if we wanted to differentiate that with respect to t we wouldn't have an $ \frac{\partial{f}}{\partial{t}}$ term.","['multivariable-calculus', 'partial-derivative']"
2009179,Why is $c^3\ge abc$?,"Why is $c^3\ge abc$ ? there is a step in proving some inequality which I don't understand. It is clear that $a^3+b^3\ge ab^2+ba^2=ab(a+b)\tag1$ from rearrangement inequality, but then how does he conclude that the whole $a^3+b^3+c^3\ge ab(a+b)+abc$. He should have proved (assumed) that somehow directly, because otherwise he wouldn't show $(1)$","['inequality', 'proof-verification', 'algebra-precalculus', 'contest-math', 'fractions']"
2009189,Finding sum of infinite series $1+\frac{x^3}{3!}+\frac{x^6}{6!}+\frac{x^9}{9!}+\ldots $,"So the question is 'express the power series $$1+\frac{x^3}{3!}+\frac{x^6}{6!}+\frac{x^9}{9!}+\ldots $$
 in closed form'.
Now we are allowed to assume the power series of $e^x$ and also we derived the power series for $\cosh x$ using exponentials. Now my question is the best way to approach the problem above. There is a hint that says 'use the fact that $\zeta^2+\zeta +1=0 $ where $\zeta $ is a cube root of unity'. The way I solved this was to recognise that the third derivative of the series was equal to the series itself. So I just solved a linear ODE of order 3 and then found the constants (and so the hint made sense - in a way). But I don't think the question was designed for me to do this and so I feel as though I'm missing something obvious that makes this problem very easy. Can anyone see any alternatives that make use of the hint in a more natural way?","['exponential-function', 'real-analysis', 'taylor-expansion', 'ordinary-differential-equations']"
2009199,Proving properties of binary relations with existential quantifier,"I'm taking a discrete mathematics course in my computer science studies and came across the following: Given the relation:
$$R = \{(a, b)\in\Bbb Z\ \times\Bbb Z\ | \exists z\in\ \Bbb Z\ : a - b = z\cdot p \}$$ with $p\in \Bbb N_0\;$, prove whether or not the relation is reflexive, symmetrical, antisymmetrical or transitive. As I understand the question I only have to provide one z that satisfies this condition for each property. Assuming that is the case I found the following answers: The relation is: reflexive , since $z = 0$ satisfies $a - a = z \cdot p$ $^1$ symmetrical , since $a-b = z \cdot p \implies b - a = z \cdot p$  is true for $z = 0$ anti-symmetrical , since $ a- b = z \cdot p \land b-a = z \cdot p \implies a = b$ is true for $z = 0$ transitive , since $a-b = z\cdot p \land b -c = z\cdot p\implies a = c$ is true for $z = 0$ However, I think I commit some very basic fallacies, because I completely ignore p. Additionally, if we assume that R is not transitive, would I have to prove it for every z? Edit: Forgot to ask a question: Are these answers correct and if not why?","['relations', 'discrete-mathematics']"
2009276,"Find all polynomials $p: \mathbb{Z} \to \mathbb{Z}$ with $p(a)p(b) \in p(\mathbb{Z})$ for $a,b\in\mathbb Z$.","Find all polynomials $p: \mathbb{Z} \to \mathbb{Z}$ such that for any $a, b \in \mathbb{Z}$, there is $c \in \mathbb{Z}$ with $p(c) = p(a)p(b)$. I suspect $p(x) = (x - k)^n$ but I'm having trouble proving it...","['number-theory', 'polynomials']"
2009284,Set of ordinals less than the first uncountable ordinal and countability,"I am trying to solve the following question from Royden's Real Analysis (3rd edition, Chap. 1, Problem 32). Let $Y$ be the set of ordinals less than the first uncountable ordinal, i.e., $Y= \{ x\in X: x<\Omega \}$. Show that every countable subset $E$ of $Y$ has an upper-bound in $Y$ and hence a least upper-bound. I have the following question: If $Y$ is assumed to be the set of ordinals less than the first uncountable ordinal, then shouldn't $Y$ be countable by definition? and so, every subset of a countable set is countable? and then, $\Omega$ is an upper-bound to each $E \subset Y$?","['real-analysis', 'elementary-set-theory']"
2009292,Why is intersection of all sets with indices from T an empty set?,"I am reading now ""Topics in Algebra"" of Herstein. Here is said that: If S is the set of real numbers and T is the set of rational numbers, let for $\alpha \in T$, $A_\alpha=\{ x \in S | x \ge \alpha \}$. Here $\bigcap_{\alpha \in T} A_\alpha$ is the null(empty) set.But the sets $A_\alpha$ are not mutually disjoint. Could you please explain two last sentences? Why the intersection is empty and at the same time they are not mutually disjoint? Or is it typo in the book?",['elementary-set-theory']
2009321,Sphere packing question AGAIN.,"This question has probably been asked before but when I searched the site I could not find the answer. Suppose we have and $n$-dimensional ball with radius $R$. How many, smaller  $n$-dimensional ball with radius $r$ can we fit in this ball.  Let this number be denoted by $N$. I am aware that this is still an open question in math. But can we give some lower and upper bounds on $N$? For example, \begin{align}
N \le \frac{{\rm Vol}(R)}{{\rm Vol}(r)}= \left(\frac{R}{r} \right)^n,
\end{align} My questions is: Are there any non-asymptotic lower bounds on $N$ in terms of $R,r,n$? If this question has been answered in this site before. Please direct me to it. 
There was and answer in the comments that we can have an asymptotic bound by Minkowski–Hlawka theorem. However, I would like to see more explanations on how it relates. For the bounty, I would really like a precise argument possible with some references.","['spheres', 'packing-problem', 'euclidean-geometry', 'geometry']"
2009336,Closed form for $\prod_{i=2}^{\infty} (1 - \frac{1}{i!})$,"Question. I wonder whether there exists a closed form for the following infinite product
  $$
\prod_{i=2}^{\infty} (1 - \frac{1}{i!})
$$ I can prove that the product is convergent, but failed to attain a closed form without luck. Any hint is really appreciated.","['infinite-product', 'sequences-and-series', 'closed-form']"
2009343,On the closed form for $\sum_{m=0}^\infty \prod_{n=1}^m\frac{n}{4n-1}$,"We have
$$\sum_{m=0}^\infty \prod_{n=1}^m\frac{n}{3n-1}=\frac{3}{2}+\frac{\ln(\sqrt[3]{2}-1)}{2^{7/3}}+\frac{\sqrt{3}}{2^{4/3}}\arctan\frac{\sqrt{3}}{2\sqrt[3]{2}-1}\tag1$$
$$\sum_{m=0}^\infty \prod_{n=1}^m\frac{n}{3n-2}=\frac{3}{2}-\frac{\ln(\sqrt[3]{2}-1)}{2^{5/3}}+\frac{\sqrt{3}}{2^{2/3}}\arctan\frac{\sqrt{3}}{2\sqrt[3]{2}-1}\tag2$$
with the first discussed in this post . ( Update ) Courtesy of the answers below, we also have,
$$\sum_{m=0}^\infty \prod_{n=1}^m\frac{n}{4n-1}=\frac{4}{3}+\frac{\ln\big((4^{1/4}-3^{1/4})\sqrt{2+\sqrt{3}}\big)}{3^{5/4}\sqrt{2}}+\frac{\sqrt{2}}{3^{5/4}}\arctan\big(3^{1/4}\sqrt{2+\sqrt{3}}\big)\tag3$$
$$\sum_{m=0}^\infty \prod_{n=1}^m\frac{n}{4n-3}=\frac{4}{3}-\frac{\ln\big((4^{1/4}-3^{1/4})\sqrt{2+\sqrt{3}}\big)}{3^{3/4}\sqrt{2}}+\frac{\sqrt{2}}{3^{3/4}}\arctan\big(3^{1/4}\sqrt{2+\sqrt{3}}\big)\tag4$$Walpha gives a closed-form for $(3)$, but uses two log functions and two arctans. The two answers below show it can  be simplified further similar to $(1),(2)$.","['hypergeometric-function', 'sequences-and-series']"
2009427,Hain's commutator formula for iterated integrals,"Exercise 7 in Hain's notes on the de Rham fundamental group of $\mathbb{P}^1\setminus \left\{0,1,\infty\right\}$ says the following (for a real or complex smooth manifold $M$): Let $\alpha, \beta$ be two loops based at a point $x\in M$ and $\omega_1, \omega_2\in \Omega^1  (M)$ two smooth (real or complex) 1-forms on $M$. Then the commutator in $\pi_1 (M,x)$ is related to a period matrix via $$\int_{[\alpha,\beta]} \omega_1 \omega_2 = \det\left( \matrix{{\int_\alpha \omega_1,\int_\alpha \omega_2}\\{\int_\beta \omega_1 ,\int_\beta \omega_2}}\right).$$ I am struggling to prove this using the shuffle product/coproduct/path reversal formulas. Assuming I haven't made a calculation mistake, however, I believe it reduces to showing that $$\int_\alpha \omega_1\omega_2 + \int_\beta \omega_1\omega_2 + \int_\alpha \omega_2\omega_1 + \int_\beta\omega_2\omega_1 = 2\int_\alpha\omega_1\omega_1+2\int_\beta\omega_2\omega_2$$
i.e.
$$ \left(\int_\alpha\omega_1\right)\left(\int_\alpha\omega_2\right)+ \left(\int_\beta\omega_1\right)\left(\int_\beta\omega_2\right)= \left(\int_\alpha\omega_1\right)^2+\left(\int_\beta\omega_2\right)^2,$$ which I am not totally confident is correct. I have three questions relating to this: 1) Can anybody provide a proof for this formula? I can't find one referenced anywhere, but I believe it is just a clever applyication the basic shuffle product (etc...) formulas for iterated integrals. 2) More conceptually, is there a reason we expect such a relation to hold (i.e. without having to explicitly calculate it)? For example, suppose $M$  has a $2\times 2$ period matrix $A$; as far as I understand this matrix provides the coefficients for an isomorphism between the de Rham cohomology and singular cohomology of $M$. Why should its determinant relate to the iterated integral over the commutator of the two generators of $H_1(M)$ given by the images of $\alpha, \beta$ in the abelianistion map $\pi_1 (M,x)\to H_1 (M)$? 3) When the period matrix is larger, are there further relations between its determinant and more complicated iterated integrals involving elements of $\pi_1 (M,x)$ and the basis elements for $H^1_{ dR} (M)$?","['algebraic-topology', 'manifolds', 'iterated-integrals', 'algebraic-geometry']"
2009447,"Ring of integers of $\mathbb{Q}(\sqrt{-3},\sqrt{5})|\mathbb{Q}$ and group of units","I'm having some problems finding the ring of integers of $\mathbb{Q}(\sqrt{-3},\sqrt{5})|\mathbb{Q}$. How can I find it? Also, I'd like to prove that $\alpha:=\frac{1+\sqrt{-3}+\sqrt{5}+\sqrt{-15}}{4}$ generates a subgroup of finite index of the group of units of $\mathbb{Q}(\sqrt{-3},\sqrt{5})|\mathbb{Q}$, but I don't know how to apply the Dirichlet theorem to prove it (that's the only point I've got to so far). I already know how to compute its discriminant and therefore I know which primes ramify, the problem is that I really don't know how to find its ring of integers, even though I've felt the temptation of writting $\mathcal{O}_{\mathbb{Q}(\sqrt{-3},\sqrt{5})}=\mathbb{Z}\left[\frac{1+\sqrt{-3}}{2},\frac{1+\sqrt{5}}{2}\right]$ Thanks in advance.","['number-theory', 'algebraic-number-theory']"
2009465,Finding Density From Expected Value,"Problem:
Given that $X \sim N(0,1)$, let $Y = e^{X}$. Find a formula for the density, $f_{Y}(y)$. Progress:
Using the Law of the Unconscious Statistician, I computed $$E[Y] = E[e^{X}] = \sqrt{e}.$$ I figured that a potential solution had to satisfy both: $$\int_{\mathrm{R}} f_{Y}(y) \, dy = 1$$
$$\int_{\mathrm{R}} yf_{Y}(y) \, dy = \sqrt{e}$$ I tried playing around with integration by parts on the second one but realized that wasn't going to get me anywhere because I can't find $f'$ or $\int f \, dy$. Now that I'm typing it out, maybe I can make integration by parts work using $$F(y) = \int_{-\infty}^{t} f_{Y}(t) \, dt$$ If anyone has some insight that would be really helpful. I'm probably on the wrong track but I'm gonna go play around with this some more.","['statistics', 'integration', 'probability', 'calculus']"
2009485,Taylor approximation and monotonicity of the function,"Consider a real $f(x)$. If the Taylor approximation of the function is, say, decreasing, can I conclude that the function (near the point were the approximation is made) is decreasing too? As an example $$f(x)=\mathrm{lg}(1+\frac{1}{x}) \sim_{x \to \infty} \frac{1}{x}$$
Can I therefore say that,since $\frac{1}{x}$ is decreasing
, then also $f(x)$ is decreasing when $x \to \infty$? Is there any theorem that links the Taylor approximation with the monotonicity of the function ?","['real-analysis', 'taylor-expansion', 'calculus', 'functions', 'approximation']"
2009493,Finding number of distinct walks between two vertices in a graph using Matrix Multiplication,"Say, we have a graph G represented by an adjacency matrix A. Adjacency Matrix A

A = 0 1 1 0
    1 0 1 1
    1 1 0 1
    0 1 1 0 It is said that A^n[i][j] equals the
number of distinct walks of length [![n][2]][2] which start at vertex i and end at vertex j A^n = A*A*A...n times Testing for n = 2 A^2 = 2 1 1 2
      1 3 2 1
      1 2 3 1
      2 1 1 2 This says that, the number of paths of length 2, between vertex 0 and 0 is 2, which is indeed correct. The paths are 0-1-0 and 0-2-0 Testing for n = 3 A^3 =  2 5 5 2
        5 4 5 2
        5 5 4 5
        2 5 5 2 This says that, the number of paths of length 3, between vertex 0 and 1 is 5. Are these paths 0-0-2-1 , 0-1-2-1 , 0-1-3-1 , 0-2-0-1 , 0-2-1-1 and `0-2-3-1' I would like to know the idea behind this method, and how it's working.","['eigenvalues-eigenvectors', 'graph-theory', 'adjacency-matrix', 'triangles', 'discrete-mathematics']"
2009538,Colimit of a direct system of monomorphisms,"Let $\mathcal A$ be an abelian category, $\{X_i,f_{ij}\}_{i\leqslant j\in I}$ a direct system of $\mathcal A$ such that for any $i\leqslant j\in I$, $f_{ij}:X_i\to X_j$ is an monomorphism. Suppose the colimit of $\{X_i,f_{ij}\}$ exists, can we deduce that the structural morphisms $u_i:X_i\to \varinjlim X_i$ are monomorphisms? What I know is that it holds when $\mathcal A$ has enough injective objects and $I=\mathbb N$.","['category-theory', 'abstract-algebra', 'limits-colimits', 'abelian-categories']"
2009540,Roots of unity of a quadratic field,"Let $K$ be a quadratic number field, and $\mu(K)$ the group of roots of unity of $K$. I'm trying to prove that (with the two exceptions of $\mathbb{Q}(\sqrt{-1})$ and $\mathbb{Q}(\sqrt{-3})$) $$\mu(K) = \{1, -1\}$$ The case where $K$ is imaginary is easier, since by Dirichlet's unit theorem, we have $$\mathcal{O}_K^* = \mu(K) \times \mathbb{Z}^{1 + 0 - 1} = \mu(K)$$ And it is easy to prove that $\alpha \in \mathcal{O}_K^* \iff N(\alpha) = 1$. Dealing with the $d \equiv 2, 3 \mod 4$ and $d \equiv 1 \mod 4$ separately we get a complete characterization of $\mathcal{O}_K^*$, and therefore of $\mu(K)$, for $K$ imaginary. But for $K$ real this doesn't work anymore, because we have $$\mathcal{O}_K^* = \mu(K) \times \mathbb{Z}^{0 + 2 - 1} = \mu(K) \times\mathbb{Z}$$ Instead, and the approach above gives infinite units (solution to Pell's equation), and says nothing about the roots of unity. I'm guessing that one could use the fact that a real quadratic field has only one embedding, and that embedding is real, together with the fact that the only roots of unity in $\mathbb{R}$ are $\pm 1$. Is there an elementary way to prove the result without separating the
  real and imaginary case, and/or without using Dirichlet's unit theorem?","['number-theory', 'roots-of-unity', 'algebraic-number-theory']"
2009551,"Why is this famous proof of the chain rule called ""technically incorrect"" in this pdf? [duplicate]","This question already has an answer here : Why does this proof of the chain rule not work? (1 answer) Closed 7 years ago . So I was looking through various proofs of the chain rule...and I came across this paper. The first proof given is complete and quite well-explained. But another simplistic proof is given in the end...which is mentioned as ""technically incorrect"". Can anyone tell me why? Here is the incorrect proof in question: $$\begin{aligned}
(f \circ g)'(x) &= \lim_{h \to 0}\frac{f(g(x+h)) - f(g(x))}{h} \\
\implies (f \circ g)'(x) \cdot \left(\frac{1}{g'(x)}\right) &= \lim_{h \to 0}\left(\frac{f(g(x+h)) - f(g(x))}{h}\right)\cdot\left(\frac{h}{g(x+h)-g(x)}\right)\\
&= \lim_{h \to 0}\left(\frac{f(g(x+h)) - f(g(x))}{g(x+h)-g(x)}\right) \\
&= f'(g(x)) \\
\end{aligned}$$","['derivatives', 'chain-rule', 'calculus', 'functions']"
2009571,How to derive this curious approximation to the cube root of $a + bi$?,"In this Wikipedia article in Portuguese is given the following approximation for the cube root of a complex number $ c = a + bi$: $$ \sqrt[3]{c} \approx k\left ( \frac{29z^3 + 261z^2 + 255z + 22}{7z^3 + 165z^2 +324z+71} \right ) $$ where $ \sqrt[3]{c} = \sqrt[3]{k^3z},\quad $ $ \forall k, z\in \mathbb{C}, z \neq  0 $ This gives an approximation, say $p_1$, and then you can use this approximation as a new value of $k$ to get another better approximation $p_2$, and so on. The question is: how this approximation can be derived? I think that it's an application of Newton's method or some truncated series, but I don't know the details. Also, what precise is the approximation? Does converges to the cube root for any initial values?","['abstract-algebra', 'approximation-theory', 'complex-analysis', 'numerical-methods', 'convergence-divergence']"
2009574,Homomorphisms on unitary complex Banach algebras are continuous,"Let $A$ be a complex Banach algebra and $h:A\to\mathbb{C}$ a homomorphism. Let $h=0$ then the problem is trivial, so suppose that $h\ne 0$. Then there exists $x\in A$ with $h(x)\ne 0$ such that $h(x)=h(ex)=h(e)h(x)\implies h(e)=1$. Now, we set $y=x-h(x)e$. Why does this belong to $\mathscr{N}(h)$? In a proof I have read it is claimed that $1=h(y y^{-1})=h(y)h(y^{-1})$, which is supposedly ""impossible""; but I don't see how? And then it's claimed that this implies that $h(x)\in\sigma_{A}(x)$ and the conclusion is that $|h(x)|\le\|x\|$. Would someone be able to explain why these final steps hold?","['functional-analysis', 'operator-algebras']"
2009591,Cancellation in quotient of fractional ideals,"When reading about fractional ideals of rings of integers, I came upon the following footnote: For fractional ideals $\mathfrak{a}$, $\mathfrak{b}$ and $\mathfrak{c}$ with $\mathfrak{a} \supset \mathfrak{b}$, $$\displaystyle ^{\mathfrak{a}\mathfrak{c}}/_{\mathfrak{b}\mathfrak{c}} \simeq \ ^{\mathfrak{a}}/_{\mathfrak{b}}$$ as $\mathcal{O}_K$-modules. This was not obvious to me, so I tried to prove it, however did not succeed. I think it must be connected to the unique product decomposition in Dedekind domains. I also found this question , where someone was also not sure how to prove this isomorphism, but did not succeed either. Any help is greatly appreciated! Thanks in advance!","['number-theory', 'dedekind-domain']"
2009675,Why does a 1/x^2 graph decrease at a decreasing rate and not at an increasing rate.,"For $y=1/x^2$ As $x$ increases, the denominator ($x^2$) increases at an increasing rate. E.g. $1^2$ to $2^2$ is a difference of $3$, but $2^2$ to $3^2$ is a difference of $5$ So wouldn't it follow that $y$ decreases at an increasing rate, because: $y$ is inversely proportional to $x^2$ (i.e. $y$ decreases as $x^2$ increases) $x^2$ increases at an increasing rate Hence, $y$ decreases at an increasing rate (as $x^2$ increases at an increasing rate) Now I obviously know this isn't the case because the graph shows that $y$ decreases at a decreasing rate, so could you please spot the error in my thinking? An actual graph of $y$ vs $1/x^2$ is shown below in blue (flatter over time), whereas I thought the shape (ignore the values) would as more like the red version (where it gets steeper over time):","['exponential-function', 'functions', 'graphing-functions']"
2009708,"Are $f(x,y,z)=x$ and $f(x)=x$ equivalent?","Suppose I have a function $f(x,y,z)=x$, is it equivalent to $f(x)=x$? Is it a correct abbreviation? Or can I maybe write $g(x)=f(x,y,z)$ so $g(x)=x$? What is mathematically correct? Thanks!","['real-analysis', 'notation', 'calculus', 'functions']"
2009726,What textbook/reference should I read in order to answer these questions?,"Might be a strange question, but what textbook/reference should I read in order to be able to solve problems like the followings? I only took one class in classical differential geometry, and we covered chapter one through chapter five from this notes . But still I do not have sufficient knowledge to solve these problems. I have taken standard (?) undergraduate level classes in analysis (Apostol, but no measure theory), topology (Greene) and algebra (Hungerford, the introduction one). Example 1 : Let $S^2$ be the unit sphere in $\mathbb{R}^3$. Define map $f: S^2 \to \mathbb{R}^3$ by
  $$f (x,y,z)\longrightarrow (yz-x,zx-y,xy-z)$$
  Determine all the singular points of $f$. A point $p$ is singular if if the rank of the differential at $p$ is less than 2. Example 2 : Let $n \ge 1$ be an integer and $M \subset \mathbb{R}^{n+2}$ a smooth $n$-dimensional submanifold, which is a closed subset of $\mathbb{R}^{n+2}$. Prove that for any $x_0 \in M$, there exists a line $L$ in $\mathbb{R}^{n+2}$ satisfying the condition:
  $$L\cap M = \{x_0\}$$ Example 3 : Let $V$ be an $n$-dimensional real vector space with $n \ge 2$. Prove that every element $v \in \wedge^{n−1}V$ can be written as
  $$v = v_1 \wedge ... \wedge v_{n−1}$$
  with some elements $v_1, ..., v_{n−1} \in V$ . Here $\wedge^{n−1}V$ denotes the $(n − 1)$-st exterior product of $V$ .","['reference-request', 'differential-geometry', 'exterior-algebra']"
2009742,"Volume of a ""Swiss Cube""","Inspired by this video , I wanted to see if I could calculate the volume that remains if a cube is bored through with cylinders on all sides. Here is the final product from the video: I decided to focus on just one unit cube, with cylinders bored through on all sides, and assumed that the ratio of the volume removed for just one unit cube would be the same as the ratio for the ""Swiss Cube"" with 25 cylinders bored through on each side. The trouble I'm running in to is the overlap of the cylinders as you bore through from all directions. I do not know how to calculate the area of overlap between cylinders bored through in even two dimensions, let alone the total three. After one cylinder is bored through, the volume remaining would be: $V_{\text{remaining}} = s^3 - \pi\left( \frac{1}{2}s \right)^2 s = s^3 \left(\frac{4 - \pi}{4} \right)$, where s is the unite cube side length. I am not sure where to go from here though... How would one figure out how much overlap there is between the cylinder bored through in one dimension and the cylinder bored through in a perpendicular direction? And then, how would one do the same for the third cylinder bored through?","['recreational-mathematics', 'calculus', 'geometry']"
2009888,Sum of all possible combinations,"Guys I just discovered something amazing. Can someone please confirm this? The sum of all possible ways to form a number with $n$ digits, using its digits, without repetition, is equal to $11\ldots1\cdot m(n-1)!$, where $m$ is the sum of the digits of the number, and the amount of $1$'s is equal to $n$. For example, $123$ can be arranged $132, 231, 213, 312, 321$. The sum of these numbers is equal to $1332$. $(111)(6)(2)$. I'll be waiting for my Fields Medal.","['number-theory', 'combinatorics', 'summation']"
2009952,Another way to show convergence of $ \sum_{n=1}^{\infty} \frac{ (-1)^n }{n} $,"We know the series $$ \sum_{n=1}^{\infty} \frac{ (-1)^n }{n} $$ converges. The usual argument is to notice $b_n = \frac{1}{n}$ is decreasing, positive and converges to $0$ , thus the series converges by the alternating test. Q: Is there another way to show this series converges?","['alternative-proof', 'convergence-divergence', 'sequences-and-series', 'calculus']"
2009953,image of circle after inversion,"Given a circle $C$ of radius $r$ and center $(x_0,y_0)$, what is the center and radius of $C$ after inversion in the unit circle? A simpler question has been asked: Image of a circle under conformal map $1/z$","['quadratics', 'euclidean-geometry', 'geometry']"
2010035,Definition of smooth manifold using sheaves.,"While defining differential manifolds using the concept of sheaves wikipedia gives the following definition. A differentiable manifold (of class $C_k$) consists of a pair $(M, \mathcal{O}_M)$ where $M$ is a topological space, and $\mathcal{O}_M$ is a sheaf of local $\mathbb{R}$-algebras defined on $M$, such that the locally ringed space $(M,\mathcal{O}_M)$ is locally isomorphic to $(\mathbb{R}^n, \mathcal{O})$. [$\mathcal{O}(U)=C^k(U,\mathbb{R})$ is the structure sheaf on $\mathbb{R}^n$.] In one of my courses I have been asked to verify whether the above definition is equivalent to the standard definition using atlases, but in that the condition of ""locally"" ringed spaces is missing, that is I am supposed to prove that $M$ is a smooth manifold if and only if there is a sheaf $\mathcal{O}_M$ of local $\mathbb{R}$-algebras defined on $M$, such that the ringed space $(M,\mathcal{O}_M)$ is locally isomorphic to $(\mathbb{R}^n, \mathcal{O})$ where $\mathcal{O}(U)=C^{\infty}(U,\mathbb{R})$ is the structure sheaf on $\mathbb{R}^n$. So I was wondering if the condition of every stalk being a local ring (locally ringed space) is necessary in the case of smooth manifolds.","['sheaf-theory', 'smooth-manifolds', 'manifolds', 'differential-geometry', 'ringed-spaces']"
2010045,what is the advantage of LU factorization,"In this question Necessity/Advantage of LU Decomposition over Gaussian Elimination it is asked why LU factorization is useful. I understand how this reduces time complexity of solving a number equations of the form Ax=b for matrix A and column matrix b but why don't you just find A -1 instead? Inversion has a lower time complexity than LU factorization (comparing the value used in the previous link and ones found here https://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations ) and matrix multiplication has the same time complexity in this case as is needed to solve for different values of b. Overall, I see the value of LU factorization as opposed to resolving multiple matrix equations but I don't know why it would be better than the method I described that uses matrix inversion. Clearly LU factorization has some value, I would like to know what that it. Thanks I believe the answer to this question is that all square matrices have a P T LU factorization while not all square matrices are invertible. Therefore P T LU factorization is more versatile. Any other insights are still appreciated however so please comment or answer the question. Thanks",['matrices']
2010067,What is an intuitive way to understand the dot product in the context of matrix multiplication?,"I was trying to understand where it came from that each row in a matrix multiplication is a dot product, as in: $$
Ax = \left( 
\begin{array}{ccc}
a_{1}^T \\
\vdots \\
a_m^T  \end{array} 
\right)x = \left( 
\begin{array}{ccc}
a_{1}^Tx \\
\vdots \\
a_m^T x  \end{array} 
\right)
$$ what is an intuitive explanation or interpretation that each row is a dot product of the vector x? What I do understand is that $Ax$ encodes a linear transformation $T$. Consider a super simple example in 2 dimensions to explain what I do understand. I understand that $Ax = A [x_1 x_2] = T(v) = T(x_1 \hat i + x_2 \hat j) = x_1 T(\hat i) + x_2 T( \hat j)$. This makes me interpret intuitively that a multiplication by a matrix gives me a new vector that is composed of the same linear combination of the transformed basis vectors (or whatever vectors v is composed of) [source] . Furthermore one can easily see from this view where the multiplication of a matrix comes from: $$Ax = \left[ 
\begin{array}{ccc}
a_{11} & a_{12} \\
a_{21} & a_{22} \\  
\end{array} 
\right] 
x = \left[ 
\begin{array}{ccc}
T(\hat i)_1 & T(\hat j)_1\\
T(\hat i)_2 & T(\hat j)_2\\
\end{array}
\right]
\left[
\begin{array}{ccc}
x_{1} \\
x_{2} \\  
\end{array} 
\right]
= 
x_1\left[ 
\begin{array}{ccc}
T(\hat i)_1 \\
T(\hat i)_2 \\
\end{array}
\right]
+ 
x_2
\left[
\begin{array}{ccc}
T(\hat j)_1\\
T(\hat j)_2\\
\end{array}
\right]
=
\left[ 
\begin{array}{ccc}
T(\hat i)_1 x_1 + T(\hat j)_1 x_2\\
T(\hat i)_2x_2 + T(\hat j)_2 x_2\\
\end{array}
\right]
$$ where now its obvious why matrix multiplication is defined the way it is (because of linear transformations). Notice that the nice thing about this view is that one can interpret that each column of the matrix tells us how each basis vector changes . i.e. each column specifies how $\hat i$, $\hat j$ are transformed. Furthermore, the amount it used to be in the old vector is retained but now its in the new direction $T(\hat i)$ for the first coordinate. This for me is really intuitive and explains a lot of where matrix multiplication comes from. However, if you notice this view reveals that each row $(Ax)_i = a_1^T x$ is a dot product of the initial array representation of the vector. This seems to me to not be a coincidence and that something deeper has to be going on. Usually dot products are related with projections so I was trying to understand if each coordinate of $(Ax)_i$ might actually be encoding how much the original $x$ is being projected into each row vector of $A$ (or possible something to do with the row space of $A$ i.e. $C(A^T)$ ). In an attempt to understand this I considered what each row means: $$ \left[ a_{i,1} \dots a_{i,m} \right] \left[ \begin{array}{ccc}
x_1\\
\vdots\\
x_n \\
\end{array} \right] = \sum^n_{j=1} a_{ij} x_j$$ in the old interpretation I had of what a column of a matrix is (this time the matrix is 1 by m), it seems that the columns $a_{i,j}$ specifies how much some basis vector $e_i$ is transformed. However, I've had difficulties understanding beyond that what the significance of the dot product of $x$ with the rows of $A$ means. Does someone know how to interpret this or how to understand it at a conceptual level, similar to the way the interpretation I gave of what the columns of a matrix mean? Are we doing some transformation to the row space of $A$ or something like that?","['intuition', 'linear-algebra', 'linear-transformations']"
2010172,Represent a complex-valued matrix into real-valued matrix,If I have a complex matrix ${\bf W} \in {\Bbb C}^{M\times N}$ . Why can this matrix be written as follow? $$ {\bf W} = \begin{bmatrix} {\bf W}_r & -{\bf W}_i \\ {\bf W}_i & {\bf W}_r \end{bmatrix} \in {\Bbb R}^{2M\times 2N} $$ I appreciate your answers!,"['matrices', 'block-matrices', 'complex-numbers']"
2010189,Are there any special rules when making a substitution in an integral?,"Please consider the integral: $$\int_{-a}^{a}x^2dx=\frac{2a^3}{3}$$ I would like to know why I can't make the substitution: $$u=x^2$$ When I make the substitution, the limits of the integral will be the same, and the integral itself will be zero, which is the wrong answer. So why does this simple change of variables not work as I have expected? Please note that I do not want help solving the integral, I know how to solve it several ways. My question is why does this specific attempt at a solution not work?","['indefinite-integrals', 'integration', 'calculus']"
2010255,Why is substitution allowed in Taylor Series?,"While finding the Taylor Series of a function, when are you allowed to substitute? And why ? For example: Around $x=0$ for $e^{2x}$ I apparently am allowed to substitute $u=2x$ and then use the known series for $e^u$. But for $e^{x+1}$ I am not allowed to substitute $u=x+1$. I know the technique for finding the Taylor Series of $e^{x+1}$ around $x=0$ by taking $e^{x+1}=e\times e^x$. However, I am looking for understanding and intuition for when and why it is allowed to apply substitution. Note: there are several question that are similar to this one, but I have found none that actually answers the question ""why""; or that shows a complete proof. EDIT: Thanks to the answer of Markus Scheuer I should refine the question to cases where the series is finite, for example $n\to3$","['taylor-expansion', 'calculus']"
2010293,How do I find if two matrices are unitarily equivalent and the corresponding unitary matrix?,"I'm trying to solve some exercises on linear operators and I came acroos the notion of unitary equivalence recently. I'm having problems solving the following exercise. I have two matrices- $
A=\begin{bmatrix}
    0&0&1\\0&0&0\\1&0&0
\end{bmatrix}$ and $
B=\begin{bmatrix}
    0.5&0.5&0\\0.5&0.5&0\\0&0&-1
\end{bmatrix}$. The question is to check if the matrices are unitarily similar and if so, to find the unitary matrix $C$ such that $B=C^{-1}AC$. I have calculated the eigenvalues and both have the same set of eigenvalues-$0,1,-1$. Since the eigenvalues are distinct and the same, the matrices are similar. But how do I check if they are unitarily similar? And if so, what will be my matrix $C$? I have a feeling that I need to do something with an orthonormal basis of eigenvectors of one of the matrices, but here I'm not sure. I would appreciate some help. Thanks.","['linear-algebra', 'linear-transformations']"
2010361,Estimating and checking the maximum of sin(t)+cos(t),"This is a problem from Calculus by Gilbert Strang. But please note that at this point, the author has not yet introduced the formal definition of a derivative nor the concept of limits. Draw a graph of $f(t) = sin(t) + cos(t)$. Estimate its greatest height
  (maximum $f$) and the time it reaches that height. By computing $f^2$ check
  your estimate. Since $sin(0) = 0$, $cos(0) = 1$ and $sin(\frac \pi 2) = 1$ and $cos(\frac \pi 2) = 0$, the maximum of $f$ should be in the middle. Based on that assumption, our estimate is $sin(\frac \pi 4) + cos(\frac \pi 4) = \sqrt 2$ at $t = \frac \pi 4$. Now, $f^2(t) = (sin(t) + cos(t))^2 = 1 + 2sin(t)cos(t)$ so $f^2(\frac \pi 4) = 1 + 2 \cdot \frac{\sqrt 2}2 \cdot \frac{\sqrt 2}2 = 2 = (\sqrt 2)^2$. I do not think I have really checked my estimate. Maybe I do not fully understand the problem. Where am I missing?","['trigonometry', 'calculus']"
2010394,Proving the existence and uniqueness of an operator over a Hilbert space,"Let $H$ be a Hilbert space and let $f \colon H \times H \to \mathbb C$ be a
  sesquilinear map such that
  $$    M = \sup \{ |f(x, y)| \mid x, y \in H, \|x\| = \|y\| = 1 \} < \infty$$ Prove that there exists a unique operator $S \in B(H)$, such that
  $$    f(x, y) = \langle Sx, y \rangle,\qquad\forall x, y \in H.$$
  Finally, prove that $\|S\| = M$. My incomplete attempt Fix $x \in H$ and consider the functional
\begin{align*}
    \Phi_x \colon H &\to \mathbb C\\
                  y &\mapsto \overline{f(x, y)}
\end{align*} $\Phi_x \in H^\star$ is well-defined by construction, since by
hypothesis $f(x, y) \in \mathbb C$. $\Phi_x$ is linear.
Let $y, z \in H$ and $\alpha, \beta \in \mathbb C$. Then
$$\Phi_x(\alpha y + \beta z) = \overline{f(x, \alpha y + \beta z)} =
    \alpha \overline{f(x, y)} + \beta \overline{f(x, z)} = \alpha
    \Phi_x(y) + \beta \Phi_x(z).$$ $\Phi_x$ is bounded. Let $y \in H$. We have to prove that there
exists a constant $c \in \mathbb R$ such that $|\Phi_x(y)| \leq
c\|y\|$. If $y = 0$, the inequality is trivially true. Therefore,
suppose $y \neq 0$. Using the bilinearity of $f$ we have that
$$|\Phi_x(y)| = |\overline{f(x, y)}| = |f(x, y)| =
    \|x\|\cdot\|y\|\left|f\left(\frac{x}{\|x\|},
    \frac{y}{\|y\|}\right)\right| \leq M\|x\| \cdot \|y\|$$
Therefore we can take $c = M\|x\| \in \mathbb R$, since $x$ is fixed.
We also observe that $\|\Phi_x\| \leq M\|x\|$. By Riesz's representation theorem, there exists a unique element in $H$, which we call $Sx \in H$, such that $\Phi_x(y) = \overline{f(x, y)} = \langle y, Sx \rangle$. We will now prove that $S \in B(H)$. $S$ is linear. Let $x, z \in H$ and $\alpha, \beta \in \mathbb C$.
For all $y \in H$, we have that
$$\langle y, S(\alpha x + \beta z) \rangle = \overline{f(\alpha x +
    \beta z, y)} = \overline{\alpha f(x, y) + \beta f(z, y)} =
    \bar\alpha \langle y, Sx \rangle + \bar\beta \langle y, Sz \rangle
    = \langle y, \alpha Sx + \beta Sz \rangle$$
From the arbitrariness of $y$, it follows that $S(\alpha x + \beta z) =
\alpha Sx + \beta Sz$. $S$ is bounded. From Riesz's theorem, we have that $\|Sx\| =
\|\Phi_x\|$, and at point $3.$ above we proved that $\|\Phi_x\| \leq
M\|x\|$. So $\|S\| \leq M \in \mathbb R$ and $S$ is bounded. Finally, we use the definition of operator's norm:
$$\|S\| = \sup \{ \|Sx\| \mid x \in H, \|x\| = 1 \} = {\large\textbf{?}}$$ Questions 1. Is the proof correct up to the last point? I'm particularly interested in the second part, where I applied Riesz's theorem. 2. How should I conclude it? I know it must be related to the definition of $M$, probably I'm just missing something simple.","['functional-analysis', 'operator-theory', 'proof-verification']"
2010406,Peter Walker's $C^{\infty}$ conjectured nowhere analytic slog,"Consider the function $h(x)$ which is conjectured to be $c^\infty$ nowhere analytic, and can be used to generate what we call the base change slog, which is the inverse of the basechange sexp.  This is Peter Walker's helper function from his 1991 paper.  In http://eretrandre.org/rb/files/Walker1991_111.pdf Peter Walker proves $h(x)$ is $C^{\infty}\;$ infinitely differentiable.  How can we prove that $h(x)$ nowhere analytic?  $h(x)$ has a surprisingly simple definition, and converges nicely at the real axis. $$l(x) = \ln(x+1)$$
$$h_n (x) =  l^{[n]}\exp^{[n]}(x) $$
$$h(x) = \lim_{n\to \infty} h_n (x) $$ There is an analytic Abel function $\alpha(z)$ for iterating $f(z)=\exp(z)-1,\;\;\alpha(f(z))=\alpha(z)+1$, which has an aymptotic series studied by Ecalle; see https://mathoverflow.net/questions/45608/does-the-formal-power-series-solution-to-ffx-sin-x-converge .
Then Peter Walker's slog function, which has also been referred to the basechange slog, is: 
$$\text{slog}(x) = \alpha(h(x))\;\;\;\text{slog}(\exp(x))=\text{slog}(x)+1 $$ Peter Walker was aware of the difficulties of defining $h(z)$ in the complex plane, and wrote, ""...we cannot identify our function ... with Kneser's function defined by conformal mappings, without an extension of the domain of the function h to include nonreal values. Until both these difficulties have been overcome, the possibility remains that ... two ... distinct generalized logarithms have been constructed."" In fact, we now have more tools to generate Kneser's analytic sexp(z)/slog(z) solution, and there is a 1-cyclic mapping connecting it to Walker's solution.  For Walker's solution, the issue is that when $\exp^{[n-1]}(z)=(2m-1)\pi i\;$ then $\exp^{[n]}(z)=-1\;$ so $l(\exp^{[1]}(z))\;$ has a singularity in the definition of $h_n(z)$ and these singularities get arbitrarily close to the real axis as n increases. So even though the iteration of $h_n(x)$ converges superbly at the real axis, it fails to converge in any radius in the complex plane, no matter who small that radius is.  As far as I know, it has yet to be proven that Walker's solution doesn't converge to its Taylor series anywhere, so that Walker's solution is nowhere analytic. Here are some steps I took to understand the $h(x)$ function by understanding the $h_n(x)$ sequence. I continue to use the shorthand $l(x)=\ln(x+1)\;$ along with $l^{[n]}(x)$ for the iterated $l(x)$.  I also make use of the shorthand $\chi(x)=\exp(x)\;\;\;\chi^{[n]}(x)=\exp^{[n]}(x);$ and the shorthand $\Delta_n(x)=h_n(x)-h_{n-1}(x)$. $$ h_0(x)=x;\;\;\; h_1(x) = h_0(x) + l\left(\frac{1}{\exp(x)}\right) $$ $$ \Delta_1(x) = l \left(\frac{1}{ \chi^{[1]}(x) }\right)$$ $$ \Delta_2(x) = l \left( l \left(\frac{1}{ \chi^{[2]}(x) }\right)\frac{1}{ (\chi^{[1]}(x))+1 } \right)$$ $$ \Delta_3(x) = l \left(l \left(l \left(\frac{1}{\chi^{[3]}(x)}\right)\frac{1}{ \chi^{[2]}(x)+1 } \right)\frac{1}{ l^{[1]}(\chi^{[2]}(x))+1 }\right)$$ $$ \Delta_4(x) = l \left(l \left(l \left(l \left(\frac{1}{\chi^{[4]}(x)}\right)\frac{1}{ \chi^{[3]}(x)+1 } \right)\frac{1}{ l^{[1]}(\chi^{[3]}(x))+1 }\right)\frac{1}{ l^{[2]}(\chi^{[3]}(x))+1 }\right)$$
$$ \Delta_4(x) \approx \frac{1}{\chi^{[4]}(x)}\cdot\frac{1}{ \chi^{[3]}(x)+1 } \cdot \frac{1}{ l^{[1]}(\chi^{[3]}(x))+1 }\cdot\frac{1}{ l^{[2]}(\chi^{[3]}(x))+1 }\cdot\left(1-\frac{O}{2\chi^{[4]}(x)}\right)$$ The above equation can be extended arbitrarily.  One can also expland these equations using the Tayor series $l(x)=x+\frac{-x^2}{2}+\frac{x^3}{3}+\frac{-x^4}{4}+...$, which is what I think the next step is which leads to an expansion whose first term is the approximation above.  But then ultimately, we need to show that sum of these $\Delta_n(x)$ is nowhere analytic by studying the Taylor series expansion of $\Delta_n(x)$.  Then one hopes to show that as n increases, for low enough terms, the Taylor series for $\Delta_n(x)$ is very small compared with $\Delta_{n-1}(x)$ but for large enough terms, the Taylor terms grow faster than any $r^n$, so that the series radius of convergence gets arbitrarily small.","['real-analysis', 'complex-analysis', 'analyticity', 'tetration', 'power-towers']"
2010468,Solving a second-order nonlinear ODE with a singularity on x=0,"I'm doing some reasearch on electromagnetic nanostructures and I have to solve this differential equation (the exact values of the constants don't matter, I just want all the possible solutions of y(x) given some values to these constants). $$
\frac{d^2 y}{dx^2}=-\frac{1}{x}\frac{dy}{dx}+\frac{\sin(2y)}{2} (\frac{1}{x^2}+\frac{K}{A})-\frac{D}{A}\frac{\sin(y)}{x}+\frac{\mu HM}{2A}\sin(y)
$$ from x=0 till x=R, with the boundary conditions $$
y(0)=0,\ \frac{dy}{dx}(R)=\frac{-D}{2A}
$$ I believe you can not find an analitic solution to this equation, so I've been trying to use numerical methods like the shooting method (given the boundary conditions, I found it appropiate). The thing is that the singularity on x=0 doesn't let me find the solutions. I obtain different results depending on how many steps I take in the method. I also posted this on Computational Science and Physics StackExchange, but for now I couldn't fix it.","['numerical-methods', 'ordinary-differential-equations']"
2010505,How to show these sets are equal: $\overline{X \setminus A} = X \setminus A^\circ$,"Given a metric space $(X,d)$ with $A\subseteq X $, show that $\overline{X \setminus A} = X \setminus A^\circ$ I know that I have to show that $\overline{X \setminus A} \subseteq X \setminus A^\circ$ and that $X \setminus A^\circ \subseteq  \overline{X \setminus A}$. Already I have: since $A^\circ \subseteq A$, $X \setminus A \subseteq X \setminus A^\circ$
and that since $A^\circ$ is open, $X \setminus A^\circ$ is closed. Using the fact that $\overline{X\setminus A}$ is the smallest closed subset to contain $X \setminus A$, 
$$\overline{X \setminus A} \subseteq X \setminus A^\circ$$
How do I go about proving the other way?","['general-topology', 'metric-spaces', 'alternative-proof', 'elementary-set-theory']"
2010556,"Polya's theorem on polynomials, ""Proofs from THE BOOK""""","I have a small question about the proof of the following statement by Pólya from ""Proofs from THE BOOK, Springer 2014"" Let $$f(z) = z^n + b_{n-1}z^{n-1} + \cdots + b_0$$ be a complex polynomial, degree $n\geq 1$, leading coefficient $1$. Associate with $f(z)$ the set
$$\mathcal{C} := \{ z\in \mathbb{C}: |f(z)| \leq 2 \}$$ Take any line $L$ in the complex plane and consider the orthogonal projection $\mathcal{C}_L$ of the set $\mathcal{C}$ onto $L$. Then the total length of any such projection never exceeds $4$. The proof says that we can take $L$ as the real axis of the complex plane, by rotation and translation of the plane. My professor wants that I show that the resulting (after the rotation / translation) $\mathcal{C}'$ is again of the form $\{z \in \mathbb{C} : |g(z)| \leq 2\}$ for some complex polynomial $g$ with degree $n\geq 1$ and leading coefficient $1$, in this way we can wlog assume that $L=$ real axis, $\mathcal{C}_L = \mathcal{R} = \{ x \in \mathbb{R} : x + iy \in \mathcal{C'}\text{ for some }y\in\mathbb{R} \}$, and continue the proof using another theorem: Theorem : Let $f(z)$ be a complex polynomial of degree $n\geq 1$, and leading coefficient $1$. Set $\mathcal{C}$ as above and let $\mathcal{R}$ be the orthogonal projection of $\mathcal{C}$ onto the real axis. Then there are intervals $I_1,\cdots,I_t$ on the real line which together cover $\mathcal{R}$ and satisfy $l(I_1) + \cdots + l(I_t)\leq 4$ How can I show this? Which form has it?","['complex-analysis', 'polynomials']"
2010558,Do constant functions have asymptotes?,"As far as I have learned a function has a horizontal asymptote $y = k$ if and only if 
$$\lim_{x \to \infty} f(x) = k$$ or $$\lim_{x \to -\infty} f(x) = k$$ Now, for a constant function $$f(x) = c$$ we have $$\lim_{x \to \infty} f(x) = \lim_{x \to -\infty} f(x) = c$$ Does this mean that all constant functions have horizontal asymptotes, or is this definition not the one commonly used?","['asymptotics', 'functions', 'limits']"
2010562,Can series converge even if the general term does not have limit?,"Consider the following series
$$\sum_{n \geq 1} \sin \left(\frac{n^2+n+1}{n+1} \pi\right)$$ The general term of the series does not go to zero, in fact $$\nexists\lim_{n \to \infty} \sin \left(\frac{n^2+n+1}{n+1} \pi\right) $$ Nevertheless on textbook I find that 
$$\sum_{n \geq 1} \sin \left(\frac{n^2+n+1}{n+1} \pi\right) = \sum_{n \geq 1} (-1)^n \sin \left(\frac{\pi}{n+1} \right)$$
Which converges conditionally. I understand how to get the last series and why it converges conditionally, but I always thought that a necessary condition for any convergence of a series is that the limit of the general term is zero. Am I missing something?","['real-analysis', 'calculus', 'divergent-series', 'sequences-and-series', 'analysis']"
2010583,Is integrating $f(x)= x\exp(-x^2/2)$ with substitution $u = x^2$ well defined?,"I have the following question, which is: I know how to integrate $f(x) = x\exp(-x^2)$ using the standard method of subsitution, however I was wondering if this method is well defined, and if so why exactly. The reason I ask this, is because a coordinate transformation must be a bijective and continuously partially differentiable mapping, from say an set U to another open set V. Now formally $u\colon \mathbb{R} \to \mathbb{R}$, $u(x) = x^2$ is not a coordinate transfer, so I ask: why would the substitution $u(x) = x^2$ be a well defined one? Is it because we do not use definite integrals?",['integration']
2010594,Tangent of an injective regular curve independent of its parametrization,"I am trying to show that the tangent of a regular curve is independent of its parametrization. Let $c, \tilde c: \mathbb R \to \mathbb R^2$ be injective $C^1$-curves and $c'(t) \not=0, \tilde c'(s) \not= 0$. Now assume that $c$ and $c'$ define the same curve as point set, i.e. $c(\mathbb R)=\tilde c (\mathbb R)$. I want to show that $c'(t_0)$ and $\tilde c'(s_0)$ differ just by a $\mathbb R$-multiple, whenever $c(t_0)=c(s_0)$. We may assume $t_0=s_0=0,c(s_0)=t(s_0)=0$. I tried to parametrize by arc length, but how can I know that then the parametrizations must be the same up to orientation? I tried to look at the parameter change between $c$ and $\tilde c$, but how can I know that $\tilde c ^{-1} \circ c$ is differentiable?","['curves', 'differential-geometry', 'analysis']"
2010656,Intuition behind the Geometric Mean,"Our (awesome) statistics professor told us about the best intuition behind the definition of the Arithmetic Mean (he had heard of during his career). Here's what he said: Imagine a 10-yard-long wooden plank. Think of each data value in the data set as a stone that weighs 1 pound with its position on the plank determined by the data value the stone represents. Now, place a fulcrum under the plank. The AM is the number corresponding to the fulcrum's position when the plank with the stones on it is completely still and parallel to the ground. The Weighted AM is the same situation with some of the stones having the weight distinct from 1 pound. Of course, he then told us that this real-life physical example can easily be turned into a precise problem from physics and investigated formally using mathematics, arriving at the familiar nice properties the AM has. He said he'd never seen a rationele for the definition of the Geometric Mean (or other means, for that matter) even remotely close to the one described above for the AM. I thought I'd turn to the massive knowledgeable community of MSE for an answer. Side question: besides the physical intuition described above, what other rationales are there for why the AM is defined the way it is?","['intuition', 'means', 'statistics']"
