question_id,title,body,tags
3009733,"Proof: There is no function $f \in C^2(\mathbb{R^3})$ with gradient $\nabla f(x,y,z) = (yz, xz, xy^2)$","How can one show that there is no function, which is a continuously partially derivable function $f \in C^2(\mathbb{R^3})$ with this gradient $$\nabla f(x,y,z) = (yz, xz, xy^2)$$ I thought about using the Hessian matrix since one has to calculate all second partial derivatives of $f$ there. Since only the gradient is given, can I calculate the antiderivatives first: $yz = xyz$ $xz = xyz$ $xy^2 = xy^2z$ Now I want to calculate the antiderivatives of the antiderivatives: $xyz = \frac{yzx^2}{2}$ $xyz = \frac{yzx^2}{2}$ $xy^2z = \dfrac{y^2zx^2}{2}$ I didn't calculate the antiderivatives of the partial derivatives and I don't even know if that way is correct...","['analysis', 'continuity', 'functions', 'partial-derivative', 'derivatives']"
3009749,Over Silverman’s differential forms on curves,"I’m reading Silverman’s Arithmetic of Ellipctic curves. In II.4 he gives an definition of differential form as the set of $dx$ for $x$ in $\overline{K}(C)$ . Taking the complex circle $x^2+y^2=1$ in $\mathbb{P}^2$ . By 4.2(a), $xdy$ is a differential form. By definition there exists $t\in\overline{K}(C)$ such that $dt=xdy$ . If we integrate $\sqrt{1-y^2}dy$ , it yields an $arcsin$ , which suggests that such a function $t$ wouldn’t be algebraic... What I’m I missing here? What is the function $t$ such that $dt=xdy$ ?","['algebraic-geometry', 'elliptic-curves']"
3009808,Finding the Green Function,"I'm having some trouble finding the Green function of the following differential equation: $$
\frac{d[x y'(x)]}{dx} = f(x)\\
0 \leq x \leq 1\\ 
y(1) = 0
$$ $y(0)$ is finite.","['boundary-value-problem', 'greens-function', 'ordinary-differential-equations']"
3009852,Table tennis win probability,"This problem is from my teacher and I think their answer is wrong. The problem is in the context of table tennis. The players in the tournament final are Ani and Bertha. The score in the game is drawn at 20-20. The final game will continue until one player has scored two more points than the other. It is known from previous games between Ani and Bertha that the probability of Ani winning each point is 0.6. Find the probability that Ani will win the game after exactly 8 more points. I think that this means that, over the next 6 games on the 2nd, 4th and 6th game Ani and Bertha need to have a draw. For each draw there are two possible paths. Ani wins then Bertha or Bertha then Ani. After the 6th game Ani just needs to win twice to win after exactly 8 points. However my teacher says that: If Bertha wins the first game, it is not possible for Ani to win after exactly 8 points. and also asserts that there is only one path to the desired outcome. Using this they find the probability of Ani winning after exactly 8 points to be 0.005. ( Here is the linked image: I found an alternate answer using multiple paths. $P(\text{Ani winning a game})=0.6$ $P(\text{Bertha winning a game})=0.4$ $P(\text{Ani win after 8 points})=2\dot(0.4 \cdot 0.6)\cdot2\dot(0.4 \cdot 0.6)\cdot2\dot(0.4 \cdot 0.6)\cdot(0.6\cdot0.6)=0.040\ (2sf)$ After I found this answer I asked my teacher if the proposed answer was correct. My teacher replied saying that there was nothing wrong with it. Am I missing something painfully obvious and if so what? or is the teacher's answer incorrect?","['decision-trees', 'probability']"
3009864,Babylonian Method Limit Question,"The Babylonian Method for finding square roots is a method that takes a guess, say $x$ , and averages $x$ and $\frac{a}{x}$ , where $a$ is the number you want to find the square root of. It then uses the average as a guess, and does the algorithm again. The value outputted will converge towards $\sqrt{a}$ . Translating this into algebraic terms, we get that $$\lim_{n\to\infty}f^n(2)=\sqrt{2},$$ where $f(x)=\frac{x+\frac{2}{x}}{2}$ . I wondered what would happen if we changed the initial input value. So, this is my question. Let $f(x)=\frac{x+\frac{2}{x}}{2}$ . What is $$\lim_{n\to\infty} f^n(2^n)?$$ Plugging this into my calculator, I got an answer that was about $1.591891656$ . I have no idea what is special about this number. If anyone could figure this out, I would appreciate it.","['limits', 'radicals']"
3009865,Maclaurin series for $\arctan^{2}(x)$,"I have a question here that requires me to find the Maclaurin series expansion of $\arctan^{2}(x)$ . Now I know how to find it for $\arctan(x)$ , by taking the derivative, expanding it into a series, and integrating back (given x is in the interval of uniform convergence), But applying that here leaves me with $$\frac{df}{dx}=2\arctan(x)\frac{1}{(x^2+1)}$$ I am not sure If I can pick out parts of the product (like $\arctan(x)$ ) and differentiate, expand , then integrate them. Even if I did, how would I go about multiplying two series? Is there an easier way to do this? Thanks.","['power-series', 'taylor-expansion', 'sequences-and-series']"
3009900,Folland Exercise 3.17,"Let $(X, \mathcal M, \mu)$ be a finite measure space, $\mathcal N$ a sub- $\sigma$ -algebra of $\mathcal M$ , and $\nu = \mu|\mathcal N$ .  If $f \in L^1(\mu)$ , there exists $g \in L^1(\nu)$ (thus $g$ is $\mathcal N$ -measurable) such that $\int_E f d\mu = \int_E g d\nu$ for all $E \in \mathcal N$ ; if $g'$ is another such function then $g = g'$ $\nu$ -a.e.  (In probability theory, $g$ is called the conditional expectation of $f$ on $\scr{N}$ .) I have managed to prove this statement to be true by defining a measure $\lambda$ such that $d\lambda = gd\nu$ and then using Lebesgue-Radon-Nikodym theorem. Now as an extension of the problem, I want to characterize $g$ in terms of $f$ when $\mathcal N = \{\emptyset, X\}$ , and when $\mathcal N=\{\emptyset, X, E, E^c\}$ for some $E\in\mathcal M$ . Now I'm not sure how to do the last bit, and completely stuck here. I would like to get some help on how to tackle the last part.","['measure-theory', 'real-analysis']"
3009914,$f$ is an entire function s.t $|f(z)|=1$ $\forall z \in \Bbb R$. prove that $f$ has no zeros in $\Bbb C$,My attempt: I was trying to apply identity theorem that if the zeros of the function do have any limit point and it will be a zero function but setting $g(z)=f(z)-1$ will not help me. Can anyone help me in that!!,"['analysis', 'complex-analysis', 'holomorphic-functions', 'entire-functions', 'analytic-functions']"
3009920,Find the sum: $\sum_{n=2}^\infty \frac{1}{n^2-1}$,"Evaluate : $$\sum_{n=2}^\infty \frac{1}{n^2-1}$$ I've tried to rewrite the questions as $$\sum _{n=2}^{\infty \:\:}\left(-\frac{1}{2\left(n+1\right)}+\frac{1}{2\left(n-1\right)}\right)$$ but still couldnt't get any answer as when I substitute numbers $(n)$ into the $Sn \left(-\frac{1}{6}+\frac{1}{2}-\frac{1}{8}+\frac{1}{4}-\frac{1}{10}\right)$ , $Sn$ just keeps going on and on.  So how do I solve this problem and what does this series converge to?","['limits', 'convergence-divergence', 'sequences-and-series']"
3009931,"Given an n by n matrix of 0s and 1s, find the maximum number of 1s you can remove if you can only remove 1s with another 1 in the same row or column","This is a computer science interview question I heard from a friend and we can't seem to figure it out. Basically, given a square matrix of 0s and 1s, you can remove any 1 one at a time, but only if at the current time there is another 1 in the same row or column as the 1 to be removed. What is an algorithm to calculate the maximum number of 1s that can be removed for any such matrix? I suspect this has something to do with graph theory (treating the matrix as an adjacency matrix) or possibly linear algebra, but I'm not certain. Any advice is appreciated. We did figure out the following: treating the matrix as a directed graph, where a 1 at (i,j) indicates an edge from i to j, then we can remove an edge from the graph iff after removing the edge there would still be an edge from i to another vertex OR there would still be a vertex from j to another vertex. So we want to remove the greatest number of edges (where we count a bidirectional edge as two different edges, one in each direction).","['graph-theory', 'matrices', 'linear-algebra', 'algorithms', 'computer-science']"
3009998,Show that the Mobius bundle is a smooth real line bundle and it is non-trivial.,"I'm reading John Lee's Introduction to Smooth manifolds 2nd edition. Consider the problem 10-1: Define an equivalence relation on $\mathbb{R}^2$ by $(x,y) \sim (x',y')$ if and only if $(x',y')=(x+n,(-1)^n y)$ for some $n \in \mathbb{Z}$ . Let $E=\mathbb{R}^2 / \sim$ and $q:\mathbb{R}^2 \rightarrow E$ be the quotient map. Let $\pi_1:\mathbb{R}^2 \rightarrow \mathbb{R}$ be the projection onto the first factor and $\epsilon:\mathbb{R} \rightarrow S^1,x \mapsto e^{2\pi i x}$ be the smooth covering map. Then there exists a map $\pi:E \rightarrow S^1$ such that $\pi \circ q=\epsilon \circ \pi_1$ since $\epsilon \circ \pi_1$ is constant on each equivalence class. (a) Show that $E$ has a unique smooth structure such that the quotient map $q:\mathbb{R}^2 \rightarrow E$ is a smooth covering map. (b) Show that $\pi:E \rightarrow S^1$ is a smooth rank-1 vector bundle. (c) Show that it is not trivial. My attempted solution: proposition 4.40 in the book says Suppose $M$ is a connected smooth $n$ -manifold and $f:E \rightarrow M$ is a topological covering map. Then $E$ is a topological $n$ -manifold and has a unique smooth structure such that $f$ is a smooth covering map. This proposition is similar to part(a), however, the map $q$ is from $\mathbb{R^2}$ to $E$ not the other way around. How should I manipulate $q$ to satisfy this proposition? For part(b), the only thing I know is that part (a) gives $E$ is smooth but I have no clue about the rest. For part(c), Lee defines a trivial bundle to be a bundle with a global trivialization. Suppose $E$ has a global trivialization $\Phi:\pi^{-1}(S^1) \rightarrow S^1 \times \mathbb{R}$ . If I can show $\pi^{-1}(S^1)=E$ , then since $\Phi$ is a homeomorphism we have $E \cong S^1 \times \mathbb{R}$ . Then if I can show they can't be homeomorphic to each other, the result follows. But is it true that $\pi^{-1}(S^1)=E$ and mobius strip can't be homeomorphic to the unit cylinder?","['vector-bundles', 'differential-topology', 'smooth-manifolds', 'differential-geometry']"
3010046,Analytic function must be free from $\bar{z}.$,"How can i say that analytic function must be free from $\bar{z}?$ I verified it for many examples like $\bar{z}, z^2+\bar{z} $ etc and found that the results seems to be true according to me . I am thinking  like as if any complex function contains $\bar{z}$ term in any form(obviously in nontrivial form  unlike $\bar{z}-\bar{z}$ ) then that terms is never analytic and hence whole function is also never analytic. Please suggest . Thanks .",['complex-analysis']
3010081,Why doesn't integrating over a sphere with $\phi$ between $0$ and $2\pi$ and $\theta$ between $0$ and $\pi$ work?,"One way of integrating over a sphere with $p = 1$ is by integrating over $p$ from $0$ to $1$ , $\phi$ from $0$ to $\pi$ , and $\theta$ from $0$ to $2 \pi$ Here is a link that can graph parametric surfaces in spherical coordinates: http://www.math.uri.edu/~bkaskosz/flashmo/sphplot/ If you enter in what is above, then you will find that the graph is indeed, a sphere. Furthermore, if you integrate $p^2\sin (\phi)$ over these ranges, you will get $\frac {4\pi}{3}$ which is the expected value. I noticed that $p$ from $0$ to $1$ , $\phi$ from $0$ to $2\pi$ , and $\theta$ from $0$ to $\pi$ also seems to create a sphere. Note the subtle change: $\phi$ is from $0$ to $2\pi$ and $\theta$ is from $0$ to $1\pi$ . If you plug this in to the grapher, you find that what you get resembles a sphere. However, when you integrate $p^2\sin (\phi)$ over $p$ from $0$ to $1$ , $\phi$ from $0$ to $2\pi$ , and $\theta$ from $0$ to $\pi$ , you get $0$ .   Why is that?","['integration', 'multivariable-calculus', 'spherical-coordinates', 'multiple-integral']"
3010121,Existence of a vector $v$ in $V$ such that the $T$-annihilator of $v$ is the minimal polynomial for $T$.,"Definition: $T$ -annihilator of a vector $\alpha$ (denoted as $p_\alpha$ ) is the unique monic polynomial which generates the ideal
such that $g(T)\alpha = 0$ for all $g$ in this ideal. I'm trying to prove the below statement without invoking the Cyclic Decomposition Theorem. Let $T$ be a linear operator on a finite-dimensional vector space $V$ .
Then there exists a vector $v$ in $V$ such that the $T$ -annihilator of $v$ is the minimal polynomial for $T$ . Attempt: Assume that there is no such $v$ . Then every vector has a $T$ -annihilator of degree less than that of the minimal polynomial. Define a monic polynomial $h$ which is the sum of $T$ -annihilators of given basis elements. Then $h(T)v=0$ for all $v\in V$ . But this contradicts the definition of minimal polynomial since the degree of $h\lt$ the degree of the minimal polynomial. Can someone verify my argument?","['minimal-polynomials', 'solution-verification', 'linear-algebra', 'linear-transformations']"
3010218,Deriving the Chi-squared distribution using characteristic functions,"I would like to directly derive the probability density function (PDF) for a Chi-squared distribution with $k$ degrees of freedom using characteristic functions. If $X_{1}, X_{2}, \dots, X_{k}$ are independent, standard normal random variables, then $$ Y = \sum_{i=1}^{k} X_{i}^{2} $$ and $Y$ is chi-squared distributed with $k$ degrees of freedom. The PDF for $Y$ when $k = 1$ is given by $$ f(x, 1) = \frac{1}{\sqrt{2 \pi x}} e^{-\frac{1}{2} x} $$ and its respective characteristic function is $$ \varphi_{Y_{1}} (\omega) = \int_{-\infty}^{\infty}  f(x, 1) e^{iwx} dx = (1 - i2 \omega)^{-\frac{1}{2}} \text{,}$$ where $i$ is the imaginary number. For a general $k$ degrees of freedom, $Y$ 's characteristic function is given by $$\varphi_{Y} (\omega) = (1 - i2 \omega)^{-\frac{k}{2}} \text{.}$$ Is it possible to explicitly derive $f(x, k)$ using the inverse Fourier transform, where $$ f(x, k) = \frac{1}{2 \pi} \int_{-\infty}^{\infty} (1 - i2 \omega)^{-\frac{k}{2}} e^{-iwx} d\omega ?$$ I have had no success with this approach, but I'm probably missing something very obvious. Failing that, is it possible to derive a formula for $k=2$ , where $$f(x, 2) = \frac{1}{2 \pi} \int_{-\infty}^{\infty} (1 - i2 \omega)^{-1} e^{-iwx} d\omega ?$$ This would at least allow me derive the PDF inductively. In addition, I am aware that $f(x, 1)$ can be represented as the Gamma distribution $\text{Gamma}(x, \frac{1}{2}, \frac{1}{2})$ and the sum of independent Gamma random variables is known to be Gamma distributed, therefore, for this example, $$ Y \sim \text{Gamma} ( \cdot, \frac{k}{2}, \frac{1}{2}) \text{.} $$","['integration', 'probability-distributions', 'fourier-transform', 'chi-squared', 'probability-theory']"
3010276,Mathematics solution for Gerrymandering problem? [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed last month . Improve this question Gerrymandering is a practice intended to establish a political advantage for a particular party or group by manipulating district boundaries, and can create large disproportions in voting results as we recently often hear in media. I have recently heard very nice podcast about mathematican (Jonathan Mattingly) finally providing hard evidence for Gerrymandering: which is finally able to start convincing regulators, "" recognizing what is too far "". Specifically , they define score of given division of state into districts, then (Monte Carlo) sample 24000 divisions, getting some distribution of elected democrats (e.g. 3 to 7 out of 13) - and it has turned out that elected 3 was below 1% of the sample - what can be seen as a strong evidence of Gerrymandering. It is great that mathematics can now point hard evidence there, but from one side it is after the fact, from the other it can only point extreme Gerrymandering - like 3 seats for 3-7 distribution. In contrast, we would rather expect that the number of seats just agrees with vote proportions on the state level . So the question is if mathematics could also offer a solution to prevent such problems in the first place. Mathematicians might be a better than politicians group for finding such solution, so I would like to ask for such possibilities, for example: Proportionality on state level - we calculate the number of democrats that should represent given state from vote proportion on state level, then choose them from districts with the largest proportions. However, some districts would have minority representative. Open competition for choosing the division : regulators define restrictions for ""proper"" map and concrete evaluation function (e.g. compactness + uniform population + some geographical score) using shared common data, and deadline for the competition - then e.g. everybody can send own proposal and the one having the highest score in the deadline moment wins - this map will be used. While finding the best one is a hard problem, this way many would be motivated to use computational power for this search, and finally there would be one objective winner. The main question here is existence of objective criteria for map which is ""proper""? They might differ between states, but evaluation score could be chosen on federal level. Requirement of proportion agreement of chosen map - a map to be accepted requires that the number of its elected seats, according to the last election data, has to agree with state-level proportions. The 3. option seems safe, but still might leave a place for some bad behavior, so the best would be just having a clear definition of a ""proper"" map and some evaluation score - which should be maximized, hence just choosing the best one accordingly to this score would leave no place for political fight. This evaluation score should contain some compactness - e.g. if preferred shape is circle, we can find the smallest circle district fits in, largest circle which fits in district - and put their proportion into the score: 1 corresponds to perfect circle district (analogously for square as perfect shape). We can also put proportion of district circumference and circle there. Its another term should be uniform population distribution, what can be also easily evaluated. This kind of evaluation is party-neutral and could be chosen on federal level - ending the problem of Gerrymandering once for all: there is just chosen proposed ""proper"" map having the highest evaluation score. What are other possible solutions? Could one of them be implemented? Can the Gerrymandering problem be ended once for all? Ps. Parallel Reddit discussion .","['game-theory', 'optimization', 'voting-theory', 'geometry']"
3010283,Find all prime number $p$ such that $2^p+p^2$ is prime number,"Find all prime number $p$ such that $2^p+p^2$ is prime number First I try with $p=2$ , that is not true because I get $8$ and that is not prime number. Then I try with $p=3$ that is true, I get $17$ . Now I need to see all prime number that is bigger then $3$ . Every prime number $p>3$ can write as $p=6k+1$ or $p=6k-1$ , $k\in \mathbb N$ . I try to put $p=6k+1$ then I get $p^{6k+1}+(6k+1)^2=2(2^{3k})^2+36k^2+12k+1$ then I try to factorization this like that $a=2^{3k}$ and $b=6k$ then I get $2a^2+b^2+2b+1$ I change because I think it is easy to see how to factorization, but there I stop I do not how to continue, I do not have idea how to factorization to get something like this $x\cdot y=n$ , where $n$ is prime number, and then since every prime number is $n=1\cdot n$ so one of them x or y must be 1 that is my idea for the task. Can you help me?","['elementary-number-theory', 'divisibility', 'discrete-mathematics', 'prime-numbers']"
3010305,Multivariate function to univariate function,"I'm currently trying to understand the proof of the directional derivative of a multivariate function $f(x,y)$ at the point $(x_0,y_0)$ along the vector $\vec u \langle a,b \rangle $ . $$D_\vec u f(x_0,y_0) = \lim_{h\to0} \dfrac{f(x_0 + ah, y_0 + bh) - f(x_0, y_0)}{h}$$ Then, it says let's put: $$ g(h) = f(x_0 + ah, y_0 + bh) $$ How can we change a function of 2 variables to a function of only one variable, which is a totally different one. Is it really valid? How is this process called, I couldn't find the exact name to search for more details. Thank you.","['multivariable-calculus', 'calculus']"
3010307,"Explanation for that for a particle, $v^2 = (dl / dt)^2 = (dl)^2 / (dt)^2,$ $l$ is the arch that the particle traces out","In the book of Mechanics by Landau, at page 8, it is claimed that $$v^2 = (dl / dt)^2 = (dl)^2 / (dt)^2,$$ where $v$ is a the velocity of the particle in the cartesian
  coordinates, $l$ is the arch that the particle traces out. I know that this is completely a abus d’ notation ; however, is there any intuitive way of seeing this ?","['classical-mechanics', 'analysis', 'euler-lagrange-equation', 'physics', 'mathematical-physics']"
3010327,Find residues of $f(z)=\frac{1}{(e^{z}-1)^{2}}$,"How to find the residues of $f(z)=\dfrac{1}{(e^{z}-1)^{2}}$ I have found that the poles $z=2\pi i n$ . But when I apply the formula $\dfrac{1}{(m-1)!}\lim\limits_{z\rightarrow z_{0}}\dfrac{d^{m-1}}{dz^{m-1}}\left((z-z_{0})^{m}f(z)\right)$ , I got $\lim\limits_{z\rightarrow z_{0}}\dfrac{d}{dz}(z-z_{0})^{2}\dfrac{1}{(e^{z}-1)^{2}}$ , which is so complicated that I cannot get the limit value.","['complex-analysis', 'residue-calculus']"
3010409,Mutually commuting matrix with $A_i^2=0$,"Let $A_1,\dots,A_n$ be mutually commuting $m\times m$ matrices such that $A_i^2=0$ for all $1\le i \le n$ . If $m<2^n$ , prove that $A_1 A_2\cdots A_n=0$ Since $A_i^2=0$ So $\operatorname{Im}(A)\subset \ker(A) \implies \dim(\ker(A))\ge \frac m 2$ I think we have to use it to prove ..but don't know how go through ...","['matrices', 'nilpotence', 'linear-algebra']"
3010441,Rosenfeld's $7 \times 7$ square puzzle,"A $7 \times 7$ square puzzle may be described as following. Start with a $7 \times 7$ square divided into $7 \cdot 7$ unit squares. First select a unit square and mark it. And then, in each subsequent step duplicate the current marked squares by translating them onto a set of unmarked squares; mark the new squares so that the number of squares marked is doubled at each step. Determine the maximum number of squares marked repeating this process. The answer is, amazingly, $32$ . I do not include the solution for users pleasure. This puzzle is due to M. Rosenfeld. He wrote in his paper titled 'A ""simple"" rectangular puzzle'(2007), that Many mathematicians tried to solve the $7 \times 7$ square puzzle. Some succeeded others did not. Stan Wagon showed Raphael Robinson the puzzle. Raphael contacted me and told me that he solved it while taking a bath. He was wondering why some people had difficulties solving the puzzle. He discovered that if you make a wrong selection in the initial step
  then it will be impossible to mark 32 squares on the 7×7 square. He sent me
  a sketch of a very nice proof showing that the final shape of the 32 marked
  squares is unique (modulo rotations by 90, 180, 270 degrees). The pattern is ( $\cdots$ ommited $\cdots$ ). I hope to publish the proof in the near future. And as far as I know, he never published the proof. I have tried to prove the uniqueness of the final configuration for several hours in vain. So my question is the following. The Question Prove that the final configuration of the $7\times 7$ square puzzle with maximum number of marked squares is unique up to rotations and reflections. Edit: As pointed by @hardmath, the problem has introduced Rosenfeld's article titled 'a dynamic puzzle.'(1991) For the links to the paper quoted and mentioned, see the comment below by hardmath.","['puzzle', 'discrete-geometry', 'combinatorics', 'discrete-mathematics', 'tiling']"
3010470,Showing that $\lim\limits_{x→0}\frac{x\sin(1/x)-\cos(1/x)}x$ does not exist without sequence,"Show that $$\lim_{x→0}\frac{x\sin(1/x)-\cos(1/x)}x$$ does not exist. I understand that at $0$ , the $\dfrac{\cos(1/x)}x$ term varies between $(-\infty , + \infty)$ . But I want a complete formal proof that use the definition of limit ( $ε, δ$ ) and not using sequences like ( $2k\pi n$ ) or other techniques like l'Hopital, etc… How to write a formal proof for that? Also I want to show that $\lim\limits_{x\to0} (x\sin(1/x) - \cos(1/x))$ does not exist without using any sequences and only using the definition of limit.","['limits', 'calculus', 'trigonometry']"
3010521,"$\mathcal{E}(C(K, \mathbb{C})) = \{\omega_a : a \in K\}$","We know that $C(K, \mathbb{C})$ is a $C^*$ -algebra of complex valued functions on a compact $K$ . Now, for all $a \in K$ , define the linear functional $\omega_a \colon C(K, \mathbb{C}) \rightarrow \mathbb{C}$ by $\omega_a(f) = f(a)$ . Then, $\omega_a$ is a state (it's not difficult to check that). Denote by $\Sigma(C(K, \mathbb{C}))$ the set of states of $C(K, \mathbb{C})$ and by $\mathcal{E}(C(K, \mathbb{C}))$ the set of pure states (ie, extremal states) of $C(K, \mathbb{C})$ . Now, define the following set subset of $C(K, \mathbb{C})$ : $C_a(K,\mathbb{C}) = \{ f \colon K \rightarrow \mathbb{C} : f(a) = 0 \}$ . Using the fact that $C(K, \mathbb{C}) = C_a(K, \mathbb{C}) \bigoplus \mathbb{C}\textbf{1}$ , I need to show that: $$\mathcal{E}(C(K, \mathbb{C})) = \{\omega_a : a \in K\}.$$ Part 1. $\{\omega_a : a \in K\} \subset \mathcal{E}(C(K, \mathbb{C})).$ Suppose that $w_a$ is not a pure state. That means that we can write $w_a = \lambda \omega_1 + (1 - \lambda)\omega_2$ , with $\omega_1, \omega_2 \in \Sigma(C(K, \mathbb{C}))$ and $\lambda \in (0, 1)$ . Let $f \in C(K, \mathbb{C})$ . So, $f = f_a + c,$ where $f_a \in C_a(K, \mathbb{C})$ and $c \in \mathbb{C}$ . Then, $$\omega_a(f) = \omega_a(f_a) + c = 0 + c = c.$$ On the other hand, \begin{align*} \omega_a(f) &= \lambda \omega_1(f) + (1 - \lambda)\omega_2(f)\\
&= \lambda(\omega_1(f_a) + c) + (1 - \lambda)(\omega_2(f_a) + c)\\
&= \lambda\omega_1(f_a) + (1 - \lambda)\omega_2(f_a) + c.
\end{align*} Putting the above expressions together, we get that $\lambda\omega_1(f_a) = -(1-\lambda)\omega_2(f_a)$ , which leads us to an absurd, because $\lambda > 0, (1 - \lambda) > 0, \omega_1(f_a) \geq 0$ and $\omega_2(f_a) \geq 0$ . Part 2. $\mathcal{E}(C(K, \mathbb{C})) \subset \{\omega_a : a \in K\}$ . This is where I'm struggling. Could someone help me?","['c-star-algebras', 'banach-algebras', 'functions', 'functional-analysis']"
3010577,Regular Measures,"Let $\Sigma$ be the Borel $\sigma$ -algebra of $\mathbb{R}$ . We define a measure $\mu$ on $\Sigma$ . For every Borel set $A$ we define $\mu(A)$ to be the number of elements from the set $\{\frac{1}{n}: n\in\mathbb{N}\}$ which are in $A$ . The question asks to prove this measure is not regular. From what I know $\mu$ is called regular if for any measurable set $A$ the following holds: $\mu(A)$ =sup{ $\mu(K)$ : $K\subseteq A$ , $K$ is compact and measurable} The problem is that I got the impression that the statement I need to prove is simply wrong. Let $A\in\Sigma$ . If $\mu(A)<\infty$ then we can take $K=A\cap\{\frac{1}{n}:n\in\mathbb{N}\}$ . This is a compact subset of $A$ which has exactly the same measure as $A$ . If $\mu(A)=\infty$ then we can write $A\cap\{\frac{1}{n}:n\in\mathbb{N}\}=\{x_m\}_{m=1}^\infty$ using the fact that this is a countable set. And then for every $m\in\mathbb{N}$ we define $K_m=\{x_1,x_2,...,x_m\}$ . We get that $K_m$ is a measurable compact subset of $A$ which has measure $m$ . Because we define that for all $m\in\mathbb{N}$ we get that for any $M>0$ there is a measurable compact subset $K\subseteq A$ with $\mu(K)>M$ . Hence the supremum of the measures of the compact subsets of $A$ is $\infty$ , just like $\mu(A)$ . So $\mu$ is actually regular. Am I missing something here, or is the statement really wrong?","['measure-theory', 'lebesgue-measure', 'borel-measures']"
3010693,Solving a dual integral equation involving a zeroth-order Bessel function,"Consider the following dual integral equations \begin{align}
	 \int_0^\infty  q^3 f_0(q) J_0 (qr) \, \mathrm{d} q &= g(r) \qquad\qquad\quad (0<r<1) , \\ 
	 \int_0^\infty f_0(q) J_0 (qr) \, \mathrm{d} q &= 0 \,\quad\qquad\qquad\quad (r>1) \, ,
\end{align} where $$
g(r) = \frac{9}{4\pi} \frac{16h^6-72h^4 r^2 + 18h^2 r^4 +r^6}{(h^2+r^2)^{11/2}} \, . 
$$ We search a solution of the integral form \begin{equation}
 f_0 (q) = \int_0^1 \lambda(t) \sin (qt) \, \mathrm{d} t \, , 
\label{integralWithHeaviside_sin}
\end{equation} which clearly satisfies the integral equation for $r>1$ by making use of the relation \begin{equation}
 \int_0^\infty J_0 (qr) \sin(qt) \, \mathrm{d} q = \frac{H(t-r)}{(t^2-r^2)^{1/2}} \, ,  
\end{equation} where $H(\cdot)$ denotes Heaviside function. For $0<r<1$ , it follows from three successive integration by parts that \begin{equation}\label{longEqBending}
	  \begin{split}
	   \int_0^\infty & J_0(qr) \, \mathrm{d} q \int_0^1 q^3 \lambda(t)\sin(qt) \, \mathrm{d} t
	   \\
	   &= \int_0^\infty J_0(qr) \, \mathrm{d} q \bigg( \left(\lambda''(1)-q^2 \lambda(1)\right) \cos(q) + q \lambda'(1) \sin(q) 
	   -\lambda''(0) + q^2 \lambda(0) \\
&\qquad- \int_0^1 \lambda'''(t) \cos(qt) \, \mathrm{d} t \bigg) \, .
	  \end{split}
	\end{equation} For the integral on the right-hand side of the latter equation to be convergent, we require that $\lambda(0)=\lambda(1) =\lambda'(1)=0$ .
Thus, the latter equation becomes \begin{equation}\label{secondTermBending}
	\int_0^\infty J_0(qr) \, \mathrm{d} q \int_0^1 q^3 \lambda(t)\sin(qt)
	= -  \frac{\lambda''(0)}{r} - \int_0^r \frac{\lambda'''(t) \, \mathrm{d} t}{(r^2-t^2)^{1/2}}   \, ,
\end{equation} after using identity \begin{equation}
 \int_0^\infty J_0 (qr) \cos(qt) \, \mathrm{d} q = \frac{H(r-t)}{(r^2-t^2)^{1/2}} \, . \label{integralWithHeaviside_cos}
\end{equation} Thus, the integral equation can be simplified as \begin{equation}
		  \frac{\lambda''(0)}{r} +  \int_0^r \frac{\lambda'''(t) \, \mathrm{d} t}{(r^2-t^2)^{1/2}} = -g(r) \, ,
\end{equation} By multiplying both members of the latter equation by $r/(s^2-r^2)^{1/2}$ and integrating with respect to $r$ from 0 to $s$ , the resulting equation reads \begin{equation}
 \lambda''(s) = - \frac{24 h^3}{\pi^2 } \frac{s(3h^2 - 5s^2)}{(s^2+h^2)^5} \, .
\end{equation} The latter equation can now be easily solved. 
    But the problem is that we have required that $\lambda(0)=\lambda(1)=0$ but also $\lambda'(1)=0$ .
    As the final equation is a second order ODE, only 2 boundary conditions are in principal required. 
    I would be grateful if someone here could be of help and clarify how this could be explained. Thank you!","['integration', 'improper-integrals', 'ordinary-differential-equations', 'real-analysis', 'complex-analysis']"
3010705,Computing the value of a function based on the geometric series of 1/2^n,"So in John B. Conway's First Course in Analysis Book we're told to consider the interval $[a,b],$ and let $\{r_n\}$ denote a sequence of all rationals in said interval. Next, we define a map $\alpha:[a,b]\to\mathbb{R}$ by $$\alpha(t)=\sum_{\substack{n\in\mathbb{N}\\r_n<t}}\dfrac{1}{2^n}.$$ Totally fine with that definition. Where I'm confused is when he says that $\alpha(b)=1.$ If $b$ is irrational surely that would be the case as $\alpha(b)$ would just be a geometric sum which converges to $1$ . If $b$ is rational, however, it seems like $\alpha(b)$ would never be $1$ . Consider $r_n=b$ for some $n\in\mathbb{N}$ , hence $\alpha(b)=1-1/2^n<1.$ So I'm confused as to why Conway says it's $1$ . Could anyone explain? Thank you.","['geometric-series', 'analysis', 'real-analysis']"
3010720,"For $0 < x < 1$, express $\sin[\sin^{-1}(x) + \cos^{-1}(x)]$, in terms of $x$","I need to express $\sin[\sin^{-1}(x) + \cos^{-1}(x)]$ , in terms of $x$ , if $0 < x < 1$ . I'm not sure how to solve this. If I knew the value of $x$ , I would try and apply the identity, $\sin(A-B)=\sin(A)\cos(B)+ \cos(A)\sin(A)$ , but since the answer is the real number $1$ , I don't see how that would work. For example: $$\sin[\sin^{-1}(x) + \cos^{-1}(x)]$$ $$\sin[\sin^{-1}(x)] \cdot \cos[\cos^{-1}(x)] + \cos[\sin^{-1}(x)] \cdot \sin[\cos^{-1}(x)]$$ $$x \cdot x + \cos[\sin^{-1}(x)] \cdot \sin[\cos^{-1}(x)]$$ $$x^2 + \cos[\sin^{-1}(x)] \cdot \sin[\cos^{-1}(x)]$$ That's where I'm stuck.","['algebra-precalculus', 'trigonometry']"
3010723,Showing that image of a certain linear map is either trivial or a straight line,"From S.L Linear Algebra: Let $A$ be a non-zero vector in $R^2$ . Let $F: \mathbb{R}^2
 \rightarrow W$ be a linear map such that $F(A)=O$ . Show that the image
  of $F$ is either a straight line or $\{0\}$ . I've taken following theorems from the book to try and construct the answer (proofs of theorems are omitted): Theorem 3.2. Let $V$ be a vector space. Let $L: V \rightarrow W$ be a linear map of $V$ into another space $W$ . Let $n$ be the
  dimension of $V$ , $q$ the dimension of the kernel of $L$ , and $s$ the
  dimension of the image of $L$ . Then $n = q + s$ . In other words, $$\dim  V= \dim \operatorname{Ker} L + \dim\operatorname{Im } L$$ Answer that I have constructed assumes all possibilities of dimension that kernel might have (due to cardinality, and Theorem 3.2 , $\dim\operatorname{Ker}F \in \{0, 1, 2\}$ of a linear map $F$ ). Possibility 1) $\dim\operatorname{Ker} F = 2$ If the dimension of kernel is $2$ , that is, image is zero dimensional according to Theorem 3.2 ( $\dim \operatorname{Im} F = \dim\mathbb{R}^{2} - \dim\operatorname{Ker}F = 2 - 2 = 0$ ), then considering that kernel is a subspace, $\mathbb{R}^2 = \operatorname{Ker}F$ , and therefore $F$ is a zero map having the image of $\{0\}$ . Possibility 2) $\dim\operatorname{Ker}F = 1$ If kernel is $1$ -dimensional, then so is the image according to Theorem 3.2 and thus we have a straight line as the image of $F$ , considering that we have one-dimensional image under linear map $F$ . Possibility 3) $\dim\operatorname{Ker}F =\{0\} $ (Presumably impossible) Kernel can't be zero-dimensional, since it is spanned by two dimensional vectors that are not zero vectors. Conclusion: Hence the image of $F$ is either a straight line or $\{0\}$ . Is this answer sufficient and true? My explanation of Possibility  2) concerns me the most, it might not be specific enough. Thank you!","['functions', 'linear-algebra', 'linear-transformations']"
3010728,"In the square $ABCD$, prove that $BF+DE=AE$.","Consider the Square $ABCD$ . The point $E$ is on the side $CD$ . If $F$ is on the side $BC$ such that $AF$ is the bisector of the angle $BAE$ . Prove that $$BF+DE=AE.$$ By Pythagorean theorem we have $(AD)^2+(DE)^2=(AE)^2$ then $DE=\sqrt{(AE)^2-(AD)^2}$ also, $DE=AE\sin(EAD)$ and $BF=AF\sin(BAF)$ on the other hand we have $BAE+EAD=90^0$","['calculus', 'area', 'geometry']"
3010750,Sufficient condition for $L^\infty$-convergence in martingale convergence theorem.,"Let $I$ denote the unit interval and $f:I\to I$ be a Borel measurable function.
For each $n$ let $P_n$ denote the partition of $I$ defined as $$P_n= \left\{\left[0, \frac{1}{2^n}\right), \left[\frac{1}{2^n}, \frac{2}{2^n}\right), \left[\frac{2}{2^n}, \frac{3}{2^n}\right), \ldots, \left[\frac{2^n-2}{2^n}, \frac{2^n-1}{2^n}\right],\left[\frac{2^n-1}{2^n}, 1\right]\right\}$$ and let $\mathcal A_n$ be the $\sigma$ -algebra on $I$ generated by $P_n$ .
Define $f_n=E[f|\mathcal A_n]$ , where the conditional expectation is with respect to the Lebesgue measure. It is known by the martingale convergence theorem that $f_n\to f$ pointwise a.e. and also in $L^1$ . Question. Are there some (nice) sufficient conditions on the nature of $f$ which ensure that the convergence above is in $L^\infty$ also?","['measure-theory', 'lp-spaces', 'martingales', 'convergence-divergence', 'probability-theory']"
3010753,How to determine local extrema for $f(x) = x\cdot \sin(x) ^ {\sin(x)}$,I need to find the local extrema points of the following function: $f(x)  = x\cdot\sin(x) ^ {\sin(x)}$ I was already able to derive to this function: $f'(x)  = x (\ln(\sin(x))+1)\cos(x)\sin(x)^{\sin(x)}+\sin(x)^ {\sin(x)}$,"['maxima-minima', 'calculus', 'derivatives', 'trigonometry']"
3010796,How do I simplify $\frac{\sin(2x)}{1-\cos (2x)}$?,$$\dfrac{\sin(2x)}{1-\cos (2x)}$$ How do I simplify given expression? My attempt: We know the double-angle identity for $\sin(2x)$ and $\cos(2x)$ as shown below $$\sin(2x) = 2\sin (x)\cos(x)$$ $$\cos(2x) = 2\cos(x)-1$$ So we have that $$\dfrac{2\sin (x)\cos(x)}{1-2\cos(x)-1} = \dfrac{2\sin(x)\cos(x)}{-2\cos^2(x)} = \dfrac{2\sin(x)}{-2\cos(x)} = -\tan (x)$$ I believe I've gone wrong somewhere.,['trigonometry']
3010835,How to solve $\int\frac{\ln x}{x^2(\ln (x)-1)^2}dx$ by substitution,"$$\int\frac{\ln x}{x^2(\ln (x)-1)^2}dx$$ Hello, I haven't be able to solve this integral, I've tried to do $u = \ln (x)-1$ but couldn't make it work, any insight?","['integration', 'indefinite-integrals', 'calculus']"
3010837,What is $\frac{1}{|{x}|}-\frac{x^2}{|x|^3}$?,"What's the result of: $$\frac{1}{|{x}|}-\frac{x^2}{|x|^3}$$ Is it $$\frac{1}{|{x}|}-\frac{x^2}{|x|x^2}=\frac{1}{|{x}|}-\frac{1}{|x|}=0$$ or $$\frac{1}{|{x}|}-\frac{x^2}{|x|^2x}=\frac{1}{|{x}|}-\frac{1}{x}\frac{x^2}{|x|^2}=\frac{1}{|{x}|}-\frac{1}{x}=\left\{\begin{matrix}\frac{2}{x},x<0\\ 0,x>0 \end{matrix}\right.$$","['algebra-precalculus', 'absolute-value']"
3010869,(Why) can we treat a function of a variable as another independent variable?,"I'm currently reading my numerical analysis textbook and something's bugging me. To get into it, let's take a look at the following differential equation; $$u'(x) = f(x, u(x))$$ In order to determine the stability of the equation, one may calculate the Jacobian, $$J(x, u(x)) = \frac{\partial f}{\partial u}|_{(x, u(x))}$$ Here is a specific differential equation: $$u'(x) = -\alpha(u(x) - sin(x)) + cos(x)$$ For which the Jacobian is $$J(x, u(x)) = -\alpha$$ Basically, we treated both $sin(x)$ and $cos(x)$ as constants with respect to $u$ , but I don't really understand why. Most of the time, when we take a derivative the variables are independant, which is not the case here as they both depend on the same variable $x$ . This means that the ""rate of change of $sin(x)$ with respect to $u(x)$ "" is zero, but the value of $u(x)$ only changes if the value of x itself changes, so shouldn't the value of $sin(x)$ change aswell? Thank you!","['jacobian', 'multivariable-calculus', 'numerical-calculus', 'numerical-methods', 'derivatives']"
3010906,Representing a Multiple of the Fundamental Class of a Surface,"Let us denote a connected, oriented surface of genus $g$ by $\Sigma_g$ . It is easy to see that if we have a map of degree $1$ from $\Sigma_g$ to $\Sigma_h$ then $g\geq h$ . 
Suppose now that $g\geq 2$ and fix a $k\in \mathbb{Z}$ . Consider the following question: What is the minimal Euler characteristic of a surface $\Sigma_h$ such that there exists a map $f\colon\Sigma_h\to\Sigma_g$ such that $f_*([\Sigma_h])=k[\Sigma_g]$ . My intuition tells me that the minimal Euler characteristic case is represented by a $k$ -fold covering i.e. the minimal Euler characteristic should be $k(2-2g)$ , but I have a hard time proving this. Edit: Mikes answer is great, but the both us are interested in a more elementary proof.","['surfaces', 'geometric-topology', 'general-topology', 'differential-topology', 'algebraic-topology']"
3010908,Showing that $F = \{A \subseteq \mathbb{R} : 0 \in A^{\circ} \text{or } 0 \in (A^c)^\circ\}$ is an algebra.,"I am trying to show that $F = \{A \subseteq \mathbb{R} : 0 \in A^{\circ} \text{or } 0 \in (A^c)^\circ\}$ is an algebra. Here, $A^{\circ}$ denotes the interior of A. I am having trouble showing, in particular, that: $A, B \in F$ with $0 \in (A^c)^\circ, 0 \in (B^c)^\circ$ implies that $A \cup B \in F$ . I can't figure out how to put things together to show that $0$ is in either $(A \cup B)^{\circ}$ or $((A \cup B)^c)^{\circ}$ . A few (potentially) useful facts I know: $((A \cup B)^c)^{\circ} \subseteq (((A \cup B)^{\circ})^c)^{\circ}$ $A^{\circ} \cup B^{\circ} \subseteq (A \cup B)^{\circ}$",['elementary-set-theory']
3010921,"Closed form for $K(n)=[0;\overline{1,2,3,...,n}]$","I just started playing around with fairly simple periodic continued fractions, and I have a question. The fractions can be represented ""linearly"": for $n\in\Bbb N$ , $$K(n)=[0;\overline{1,2,3,...,n}]$$ I am seeking for a closed form for $K(n)$ . I found the first few. $n=1$ : $$K(1)=\frac1{1+K(1)}$$ $$\Rightarrow K(1)=\frac{-1\pm\sqrt{5}}2$$ $n=2$ : $$K(2)=\frac1{1+\frac1{2+K(2)}}$$ $$\Rightarrow K(2)=-1\pm\sqrt{3}$$ $n=3$ : $$K(3)=\frac1{1+\frac1{2+\frac1{3+K(3)}}}$$ $$\Rightarrow K(3)=\frac{-4\pm\sqrt{37}}3$$ $n=4$ : $$K(4)=\frac1{1+\frac1{2+\frac1{3+\frac1{4+K(4)}}}}$$ $$\Rightarrow K(4)=\frac{-9\pm2\sqrt{39}}5$$ As you may be able to tell, these results are all found by simplifying the fraction until one has a quadratic in $K(n)$ , at which point the quadratic formula may be applied. I would be surprised if there wasn't a closed form expression for $K(n)$ , as they can all be found the same way. I've failed to recognize any numerical patterns in the results, however. So, I have two questions: $1)$ : How does one express $K(n)$ in the $\operatorname{K}_{i=i_1}^\infty \frac{a_i}{b_i}$ notation? I was thinking something like $$K(n)=\operatorname{K}_{i\geq0}\frac1{1+\operatorname{mod}(i,n)}$$ $2)$ : What is a closed form for $K(n)$ ? Thanks. Update: I'm pretty sure that all the $\pm$ signs in the beginning of the question should be changed to a $+$ sign.","['number-theory', 'continued-fractions', 'closed-form']"
3010934,Finding function given limit,"$$\lim_{x\to2} \frac{x^2-cx+d}{x^2-4} = 3$$ Find $c$ and $d$ . I tried replacing all the x's with 2, but ended up with 0 on the bottom. In order for the limit to exist, something from the top has to cancel out with $(x+2)$ or $(x-2)$ . How do I find $c$ and $d$ ?",['limits']
3010967,Find the determinant of $N \times N$ matrix,"I have the following $N \times N$ matrix. \begin{vmatrix}
0 & 1 & 1 & \ldots & 1 \\ 
1 & a_1 & 0 & \ldots & 0 \\ 
1 & 0 & a_2 & \ldots & 0 \\ 
\vdots & \vdots& &\ddots& \vdots\\
1 & 0 & 0 & \ldots & a_n \\ 
\end{vmatrix} There seems to be a pattern going on for the determinant of the $5 \times 5$ version of this matrix, but I'm not sure how I would find the determinant for the $N \times N$ one.","['matrices', 'determinant', 'linear-algebra']"
3010979,How to solve this integral/better way to approach?,"$$\int_{0}^{c} dy \sqrt{\frac{c-1/2y^2+1/3y^3}{1+2y}}$$ where c is a constant. This is coming from trying to find the area $$\int_{U \le c} dq_1dq_2$$ where $$U=\frac{1}{2}(q_1^2+q_2^2)-\frac{1}{3}q_2^3+q_1^2q_2$$ bounded by energy $c=U(q_1,q_2)$ .",['integration']
3010996,Is there an exact solution for tan(36) using origami from a unit square?,"This question is more for chagrins and curiosity than anything else: Is there a way to use origami to construct the tangent of 36 degrees (~0.7265425)? 
I've come up with the image below, which is accurate to about 5 decimal places (the exact decimal eludes me at the moment), but I'd like something closer if it exists. The vertical red line on the right is at x = ~0.7265403. As I said, the question is mostly for chagrins (as the method above is close enough in practice), but I'd appreciate any more creative solutions.","['trigonometry', 'origami']"
3010998,Why do similar matrices represent the same linear transformation? [duplicate],"This question already has answers here : Similar Matrices and Linear Transformations (2 answers) Closed 5 years ago . I don’t understand the theorem: $A$ and $B$ are similar if and only if they represent the same linear transformation. I know one direction ""If $A$ and $B$ represent the same linear transformation then they are similar"", but why is the other direction also true? 
(I did only basic linear algebra so could you please give an easy proof if possible! Or any intuitions for this theorem! Thank you!)",['linear-algebra']
3011043,"How to show that $\langle a,b \mid aba^{-1}ba = bab^{-1}ab\rangle$ is not Abelian?","I'd like to show that $$
G = \langle a,b \mid aba^{-1}ba = bab^{-1}ab\rangle
$$ is non-Abelian. I have tried finding a surjective homomorphism from $G$ to a non-Abelian group, but I haven't found one. The context is that I would like to show that the figure- $8$ knot complement is non-trivial using knot groups. Thanks a lot!","['knot-invariants', 'group-theory', 'combinatorial-group-theory', 'knot-theory', 'abelian-groups']"
3011047,Expected value of a card game with 6 cards,"A deck contains 3 cards with +1 value and 3 cards with -1 value. The dealer shuffles the cards and deals them face up one by one. After each card is dealt, you have the option of stopping the game. Once the game is stopped, you get paid according to the total value of the cards that were dealt. E.g. if you stop the game after +1, +1, +1, you get +3. What is the expected value of the optimal strategy for this game. My stab at it: Since the net sum of the cards is zero, you will never lose any points on each round. If your trailing score is negative, you can keep drawing to get to at least flat. Strategy: Draw until you get a cumulative score of +1 and stop. Since there are a total of 20 permutations 6!/(3!*3!) of this game, only 5 sequences will give you a trailing score of 0 or below. So the expected value of this strategy: .75*1 + .25*0 = .75 Strategy 2: Draw two cards, if you have a cumulative score that is greater than 1, stop. Otherwise draw until you get a score of 1 and stop. I was unable to figure out how to do the math for this strategy, but I did simulate it and apparently it has an expected value of .85. Can someone walk me through the math of the second strategy? If the second strategy is not the optimal one, what is a better strategy?","['game-theory', 'optimization', 'card-games', 'probability']"
3011065,partial derivative of a polynomial belongs to a maximal ideal,"If we consider an affine space $\mathbb{A}_K^n=\mathrm{Spec}\,K[T_1,\cdots,T_m]$ over a field $K$ . It's easy to show that $T_x\mathbb{A}_K^n\simeq K^n$ where $x$ is a $K$ -point corresponding to the maximal ideal of the form $(T_1-x_1,\cdots,T_n-x_n)$ . But I wonder how to show that $\dim T_x\mathbb{A}_K^n=n$ (or maybe fail to equal) for a general closed point correspond to a general maximal ideal $\mathfrak m$ . I tried to consider the map $\mathfrak m\to \kappa(x)^n,\,g\mapsto(\frac{\partial g}{\partial T_1}(x),\cdots,\frac{\partial g}{\partial T_n}(x))$ . If $x$ is $K$ -point, it's easy to show that the kernel is $\mathfrak m^2$ , and induced a bijection: $\mathfrak m/\mathfrak m^2\to \kappa(x)^n=K^n$ . But in the general case, is that right? I think it's just a injection. This is equivalent to prove the following: Conjecture : If $g\in\mathfrak m$ and we have $\dfrac{\partial g}{\partial T_i}\in\mathfrak m$ for all $i$ , then $g\in\mathfrak m^2$ . If $\mathfrak m=(T_1-x_1,\cdots,T_n-x_n)$ , it is verified by Taylor expansion. But for general maximal ideal, I don't know how to do it.","['algebraic-geometry', 'commutative-algebra']"
3011094,$U\subseteq\mathbb{R}^n$ is open and connected $f:U\to \mathbb{R}^m$ differentiable.$Df(x)=0$ $\forall x \in U$. then $f$ is constant.,"Attempt: Since U is open and connected, U is path connected. then there exists a path $\gamma(t):[0,1]\to U$ between any points $a,b\in U$ such that $\gamma(1)=b$ and $\gamma(0)=a$ Define $h(t)=(f\circ\gamma)(t):\mathbb{R}\to \mathbb{R}^m$ What I want to do: $h(1)-h(0)=\int_0^1 \frac{d}{dx}f(\gamma(t))dt=\int_0^1Df(\gamma(t))\gamma^\prime(t)dt=0$ then $f(b)=f(a)$ $\forall a,b\in U$ so $f$ is constant. But I don't know that this path is differentiable, so this approach doesn't work.","['multivariable-calculus', 'connectedness']"
3011105,Localization and p-adic completion of Integers coincide?,"I want to know if $\mathbb{Z}_{(p)}$ (localization by a prime ideal) and $\mathbb{Z}_p$ (the completion of p-adic integers) are isomorphic. It seems true, but i don't know how to prove it. Does it holds for every PID? Thanks.","['number-theory', 'commutative-algebra']"
3011113,Several rectangles cover the unit square. Can I find a disjoint set of them whose area is at least $1/4$?,"I am interested in the following question: Let a finite sequence of rectangles in $\mathbb{R}^2$ be given such that The edges of the rectangles are parallel to the coordinate axes, and The rectangles cover the unit square, $[0,1]^2$ . Is it possible to find, among these rectangles, a collection of mutually disjoint rectangles whose combined area is at least $1/4$ ? As of yet, I'm not sure if a solution exists. My friend and I have spent a while thinking about this and have gotten nowhere. Any help is greatly appreciated.","['combinatorial-geometry', 'combinatorics', 'geometry']"
3011161,Is it true that $F$ is a field if and only if $F[X]$ is an Euclidean domain?,"Question: Let $F$ be a commutative ring with identity. 
  Is it true that $F$ is a field if and only if $F[X]$ is an Euclidean domain? If $F$ is a field, clearly one can do division algorithm to prove that $F[X]$ is an Euclidean domain.
What puzzles me is the converse, that is, if $F[X]$ is an Euclidean domain, can we conclude that $F$ is a field? My attempt:
Let $u\in F$ be a nonzero element. 
Consider $1,u\in F[X].$ Since $F[X]$ is an ED, there exist $f(X),r(X)\in F[X]$ such that $$1 = uf(X) + r(X)$$ where $\deg(r(X))<\deg(f(X)).$ Since the constant polynomial $1$ has degree $0,$ it follows that $\deg(f(X)) = 0.$ Denote $f(X) = v\in F.$ Since $\deg(r(X))<\deg(f(X)) = 0,$ it implies that $r(X) = 0.$ Therefore, we have $$1 = uv.$$ Hence, $u$ is a unit and thus $F$ is a field. Is my attempt above correct?","['field-theory', 'abstract-algebra', 'proof-verification', 'polynomials']"
3011164,Two type of balls in a bag,"In a bag there are $15$ red and $5$ white balls. Two balls are chosen at random and one is found to be red. The probability that the second one is also red is? I have attempted this question by counting all the favorable cases: Both red $(15×14)$ One red one white $(15×5)$ Our case is both red. The probability is, by Baye's theorem, $\dfrac{15×14}{15×14+15×5}$ . However, the answer is not $\dfrac{14}{19}$ but $\dfrac{7}{12}$ .",['probability']
3011200,"Power series which diverges precisely at the roots of unity, converges elsewhere","Is there a complex power series $\sum a_nz^n$ with radius of convergence $1$ which diverges at the roots of unity (e.g., $z=e^{2\pi i\theta}$ , $\theta \in \mathbb{Q}$ ) and converges elsewhere on the unit circle ( $z=e^{2\pi i\theta}$ , $\theta \in \mathbb{R} \setminus \mathbb{Q}$ )? I know $\sum \frac{z^n}{n}$ is a series with radius of convergence $1$ which converges everywhere on the unit circle except $1$ . Perhaps we can play around with this to get the desired result. I also know that $\sum \frac{z^{n!}}{n}$ diverges at the roots of unity, but I am not aware of a result that it converges at all other points on the unit circle. Note similar questions have been asked here before, but they do not directly answer the question posed above.","['complex-analysis', 'conditional-convergence', 'convergence-divergence', 'power-series']"
3011205,"Prove that if $(a,b)=1$ then there exist some $m,n$ such that $a^m+b^n\equiv 1 ($mod $ab)$","Prove that if $(a,b)=1$ then there exist some $m,n$ such that $a^m+b^n\equiv 1\pmod {ab}$ . Number $a$ , $b$ are nature and positive number. Since $(a,b)=1$ then there some number $x$ , $y\in \mathbb Z$ such that $ax+by=1$ . Since $(a,b)=1$ then I can use Fermath's theorem $a^{b-1}\equiv 1 \pmod b$ , and $b^{a-1}\equiv 1 \pmod a$ so then $a^b\equiv a \pmod {ab}$ and $b^a \equiv b \pmod {ab}$ . So $a^b+b^a\equiv a+b \pmod {ab}$ . But I am not so sure that I going in right direction. Can you help me?",['discrete-mathematics']
3011230,How to prove that $(-18+\sqrt{325})^{\frac{1}{3}}+(-18-\sqrt{325})^{\frac{1}{3}} = 3$,"How to prove that $\left(-18+\sqrt{325}\right)^{\frac{1}{3}}+\left(-18-\sqrt{325}\right)^{\frac{1}{3}} = 3$ in a direct way ? I have found one indirect way to do so: Define $t=\left(-18+\sqrt{325}\right)^{\frac{1}{3}}+\left(-18-\sqrt{325}\right)^{\frac{1}{3}}$ , and then observe $t$ is a root of $f(x) = x^3 + 3x - 36 = 0$ . Also observe that $f(3) = 0$ . Now $f(x)$ has only one real root, since $f'(x) = x^2+3$ has no real solution. So $t =3$ , as desired. But I couldn't find any direct/algebraic way of fiddling it for a while. I guess morever this is true: $\left(-\frac{t(t^2+3)}{2}+\sqrt{\left[\frac{t(t^2+3)}{2}\right]^2 + 1}\right)^{\frac{1}{3}}+\left(-\frac{t(t^2+3)}{2}-\sqrt{\left[\frac{t(t^2+3)}{2}\right]^2 + 1}\right)^{\frac{1}{3}} = t$ , which can possibly be proved in the same indirect way but I don't know how to prove this by direct manipulation. One way maybe is to write $z_+ = \left(-\frac{t(t^2+3)}{2}+\sqrt{\left[\frac{t(t^2+3)}{2}\right]^2 + 1}\right)^{\frac{1}{3}}$ , $z_- = \left(-\frac{t(t^2+3)}{2}-\sqrt{\left[\frac{t(t^2+3)}{2}\right]^2 + 1}\right)^{\frac{1}{3}}$ , and writing $t = z_+ + z_-$ , observe $z_+z_- = -1$ , so $(x-z_+)(x-z_-) = x^2 - tx -1$ , and then with Fundamental Theorem of Symmetric Polynomials, maybe calculating $(z_+^3 - z_-^3)^2$ and $(z_+^3 + z_-^3)$ in terms of $t$ would help ?","['galois-theory', 'abstract-algebra', 'polynomials']"
3011249,Finding the Maximum and Minimum Values of a Function in a Domain,"Find the maximum and minimum values of the function $f(x, y) = 2x^2+3y^2-4x-5$ on the domain $x^2+y^2\le 225$ . After finding the first partial derivatives, I found that $(1, 0)$ was a critical point and I found that it was a local minimum from the second derivative test. So the minimum value of $f(x, y)$ would be $-7$ at the point $(1, 0)$ . However, what I am confused about is how to find the maximum value and point. Since this function does not have a local maximum point, I thought that the answer would simply be on the boundaries of the inequality. However, it seems that neither the point $(15, 0)$ or $(0, 15)$ give the correct answer. If anyone knows how I should approach this problem and can provide feedback, I would be very grateful!","['partial-derivative', 'multivariable-calculus', 'calculus', 'optimization']"
3011280,"For $p\in(1,\infty)$, why does $||f||_p=||g||_p=\left|\left|\frac{f+g}{2}\right|\right|_p$ imply that $f=g$?","Problem Statement. I am working on the following exercise: Prove that if $\mu$ is a measure, $p\in(1,\infty)$ and $f,g\in
 L^p(\mu)$ are such that $$||f||_p=||g||_p=\left|\left|\frac{f+g}{2}\right|\right|_p,$$ then $f=g$ . Notation. For a measure space $(X,\mathcal{S},\mu)$ and $p\in(0,\infty]$ (where $\mathbf{F}$ is taken to be either $\mathbf{R}$ or $\mathbf{C}$ ): $L^p(\mu)=\{\tilde{f}: f\in\mathcal{L}^p(\mu)\}$ $\mathcal{L}^p(\mu)=\{f:X\rightarrow\mathbf{F}: f \text{ is } \mathcal{S}\text{-measurable and } \int f\,d\mu<\infty\}$ $\tilde{f}=\{f+z: z\in\mathcal{Z}(\mu)\}$ where $\mathcal{Z}(\mu)$ is the set of $\mathcal{S}$ -measurable functions from $X$ to $\mathbf{F}$ that equal $0$ almost everywhere. My Thoughts. I am a bit confused as to how this is even an exercise, and here is why.  We define $$||\tilde{f}||_p=||f||_p$$ for $p\in (0,\infty].$ Thus even though the $f$ and $g$ given are actually $\tilde{f}$ and $\tilde{g}$ , it doesn't matter since $||\tilde{f}||_p=||f||_p$ and $||\tilde{g}||_p=||g||_p$ , thus implying that $||f||_p=||g||_p$ .  But if this is the case then $$\left(\int |f|^p\,d\mu \right)^{1/p}=\left(\int |g|^p\,d\mu \right)^{1/p}.$$ How could that possibly be the case if $f\neq g$ ?  I would say I'm done at this point, but clearly I am missing something.  I didn't even use the last equality, i.e. $$\left|\left|\frac{f+g}{2}\right|\right|_p.$$ So what am I missing here?  There must be something I am misunderstanding! Thanks in advance for your help!","['measure-theory', 'normed-spaces', 'lp-spaces', 'real-analysis']"
3011349,Calculus of variations confusion,"Let's say I have the lagrangian $$L(x,u,u')=u'$$ If apply the Euler-Lagrange equation for $L$ , I have: $$\frac{\partial L}{\partial u}-\frac{d}{dx}\frac{\partial L}{\partial u'}=0-\frac{d}{dx}(1)=0$$ If I choose to apply to $L^2$ , I have: \begin{equation}
\frac{\partial L^2}{\partial u}-\frac{d}{dx}\frac{\partial L^2}{\partial u'}=0-\frac{d}{dx}(2u')=-2u'' \tag{1}
\end{equation} If I expand the Euler-Langrange equation for $L^2$ , I get: \begin{equation}
\frac{\partial L^2}{\partial u}-\frac{d}{dx}\frac{\partial L^2}{\partial u'}=2L\frac{\partial L}{\partial u}-\frac{d}{dx}(2L\frac{\partial L}{\partial u'})=2L(\frac{\partial L}{\partial u}-\frac{d}{dx}\frac{\partial L}{\partial u'})-2\frac{dL}{dx}\frac{\partial L}{\partial u'}
\end{equation} $L$ does not explicitly depend on x, so: \begin{equation}
\frac{\partial L^2}{\partial u}-\frac{d}{dx}\frac{\partial L^2}{\partial u'}=2L(\frac{\partial L}{\partial u}-\frac{d}{dx}\frac{\partial L}{\partial u'})=2L(0)=0?? \tag{2}
\end{equation} Why does $(1)$ differ from $(2)$ ? What am I doing wrong?","['multivariable-calculus', 'calculus', 'calculus-of-variations']"
3011362,"In a 7x7 grid, what is the number in the bottom right corner?","My math teacher have presented me with a problem, that in my opinion is quite hard. It goes. ""You have a 7x7 grid. Some of the spaces in the grid are already filled with numbers. You have to insert numbers in the remaining spaces, so that the sum in every 3x3 grid inside the 7x7, is 2019. What number should be in the bottom right corner?"" Here is the grid. I know the answer is 7, but I have no idea of how you arrive at that answer.","['pattern-recognition', 'analysis']"
3011387,"Measure on Lie Algebra ""induced"" by Haar measure on U(n)","On the unitary group $U(n)$ , the Haar measure provides a suitable notion of uniformity for many applications. The Lie Group $U(n)$ is generated by the Hermitian matrices, i.e., I can write any $A \in U(n)$ as $$A = \exp(\sum_{j,k=1}^n i a_{jk}\Omega_{jk})$$ where $a_{jk}$ are real coefficients dependent on A and $\Omega_{jk}$ are the standard basis elements of the Lie Algebra $\mathfrak{u}(n) = \{X \in \mathbb{C}^{n \times n } | X^\dagger = X\}$ . My question is this: What is the measure ""induced"" on the Lie Algebra by the Haar measure on $U(n)$ ? Put another way: What measure on $\mathbb{R}^{n \times n}$ do I have to use to sample the $a_{jk}$ if I want the corresponding unitary matrices to be distributed according to the Haar measure?","['measure-theory', 'haar-measure', 'lie-algebras', 'lie-groups']"
3011393,"Lower bound of $e(P)$, the amount of linear extensions of a poset $P$ of cardinality $n$","I am trying to solve the problem, stated as follows Let $P$ be an $n$ -element poset. If $t \in P$ then $\lambda_t= \{ s \in P: s \leq t \}$ Show that $e(P) \geq \frac{n!}{\prod_{t \in P} \lambda_t}$ Where $e(P)$ is the number of linear extensions of P. I think I may be close to a proof, but I am unable to prove the last part and I am starting to doubt its validity. A theorem in my textbook states that $e(P)$ is equal to the number of chains $0 = I_0 < ... < I_n = 1$ of length $n$ in $J(P)$ . $J(P)$ is graded of rank $n$ . If $I_2$ covers $I_1$ in $J(P)$ then $I_2 = I_1 \cup t$ for some minimal element $t \in P - I_1$ . My idea was to create a procedure for making orderings of the elements in $P$ from the chains $0 = I_0 < ... < I_n = 1$ by: Suppose your ordering so far is $(s_1, s_2,..., s_{k-1})$ . Since $I_k = I_{k-1}\cup t$ , place $t$ into the order either at the end or to the left of an $s_i$ such that $s_i \leq t$ . This can be done in $\lambda_t$ ways. These orderings do not necessarily end up being unique but there are $\prod_{t \in P} \lambda_t e(P)$ of them. If it can be proven that we can create any arbitrary order $\{ s_1, ... ,s_n\}$ this way, the sought inequality follows (as there are $n!$ arbitrary orderings and possibly more procedure orderings). This is where I am stuck, however. I am not able to find a proof.","['order-theory', 'combinatorics', 'discrete-mathematics']"
3011395,Number of Hamiltonian cycles in complete graph Kn with constraints,"I am currently working on a exercice which aims to count the number of hamiltonian cycles in a complete graph. Since it is a completely new topic to me, I struggle to think about how to solve the problem.
I understand how to count the number of Hamiltonian cycles in a complete graph Kn but my main problem is: what if we have constraints on some particular edges that the Hamiltonian must contain?
Here is the exercice with which I'm struggling with Suppose Kn is a complete graph whose vertices are indexed by
[n] = {1,2,3,...,n} where n >= 4. In this question, a cycle is identied solely by the collection of edges it contains; there is no particular orientation or starting point
associated with a cycle. (Give your answers in terms of n for the following questions. (a) How many Hamiltonian cycles are there in Kn? -> My answer : (n-1)!/2. In fact, there is no particular orientation or stationg point, so we can avoid counting the starting point (thus we have n-1) (b) How many Hamiltonian cycles in Kn contain the edge {1,2}? -> My answer : since I consider the edge {1,2} as a vertex, the number of  HC should be (n-2)!/2 (c) How many Hamiltonian cycles in Kn contain both the edges{1,2} and {2,3}? -> My Answer : Same reflexion as above, there are (n-3)!/2 hamiltonian cycles (d) How many Hamiltonian cycles in Kn contain both the edges {1,2} and {3,4}? -> My question : should I consider {1,2} and {3,4} as proper vertices also? (e) Suppose that M is a set of k <= n
2 edges in Kn with the property that no two
edges in M share a vertex. How many Hamiltonian cycles in Kn contain all the
edges in M? Give your answer in terms of n and k. -> Note : Do you have any hint? (f) How many Hamiltonian cycles in Kn do not contain any edge from {1,2}, {2,3} and {3,4}? -> Note : Do you have any hint? Thanks by advance for your help","['graph-theory', 'discrete-mathematics', 'hamiltonian-path']"
3011468,Dense subset of two Banach spaces also dense in the intersection,"My question is: Let $ V $ be a vector space (over $ \mathbb K\in\{\mathbb{R}, \mathbb{C}\} $ ), $ X,Y\subseteq V $ two subspaces equipped with norms $ \|\cdot\|_X, \|\cdot\|_Y $ such that $ (X,\|\cdot\|_X) $ and $(Y,\|\cdot\|_Y)$ are Banach spaces and $ D\subseteq X\cap Y$ . If $ D $ is dense in $ (X,\|\cdot\|_X) $ and $(Y,\|\cdot\|_Y)$ , is $ D $ also dense in $ X\cap Y $ equipped with $ \|\cdot\|:=\|\cdot\|_X + \|\cdot\|_Y $ ? At first sight, it seemed very clear to me that this should be true. But I even fail to answer the following (possibly) easier question: Let $ X $ be a vector space over $ \mathbb K $ equipped with two norms $ \|\cdot\|_1, \|\cdot\|_2 $ such that $ (X,\|\cdot\|_1) $ and $(X,\|\cdot\|_1)$ are Banach spaces and $ D\subseteq X$ . If $ D $ is dense in $ (X,\|\cdot\|_1) $ and $(X,\|\cdot\|_2)$ , is $ D $ also dense in $ X $ equipped with $ \|\cdot\|:=\|\cdot\|_1 + \|\cdot\|_2 $ ? The answer is yes, if $ \|\cdot\|_1, \|\cdot\|_2 $ are equivalent, so I tried to think about a counterexample using nonequivalent norms on a specific space and I also found a nice paper about nonisomorphic complete norms ( https://www.researchgate.net/publication/226200984_Equivalent_complete_norms_and_positivity ) but it didn't helped me so far to construct anything useful for my question. Thanks for your help!","['banach-spaces', 'functional-analysis']"
3011485,Trying to understand why the zeta function is a rational function under certain conditions. Questions about some equations.,"Information: I linked the pages below, which relate to my questions. I am currently reading "" A Classic Introduction to Modern Number Theory "" by Kenneth Ireland and Michael Rosen. In the 11th chapter they consider the zeta function. In the third section of this chapter they want to show that the Zeta Function is associated to $a_0x_0^m+a_1x_1^m+...+a_nx_n^m$ .
They start with: $$N_s = q^{s(n-1)}+q^{s(n-2)}+ ... + q + 1 + \frac{1}{q^s} \sum_{\chi_0^{(s)},...,\chi_n^{(s)}} \chi_0^{(s)}(a_o^{-1}) \cdots \chi_n^{(s)}(a_n^{-1})g(\chi_0^{(s)}) \cdots g(\chi_n^{(s)}) $$ That's ok, but I don't see why $$ q^{s(n-1)}+q^{s(n-2)}+ ... + q + 1 + \frac{1}{q^s} \sum_{\chi_0^{(s)},...,\chi_n^{(s)}} \chi_0^{(s)}(a_o^{-1}) \cdots \chi_n^{(s)}(a_n^{-1})g(\chi_0^{(s)}) \cdots g(\chi_n^{(s)}) = $$ $$q^{s(n-1)}+q^{s(n-2)}+ ... + q + 1 + \frac{1}{q^s}  \sum_{\chi_0,...,\chi_n} \chi_0(a_o^{-1})^s \cdots \chi_n(a_n^{-1})^sg(\chi_0) \cdots g(\chi_n) $$ That was my first question . And here comes my second question : At the end they use Proposition 11.1.1 to get: $$Z_f(u) = \frac{P(u)^{(-1)^n}}{(1-u)(1-qu)(1-q^{n-1}u)} $$ Here I don't see where the $(-1)^n$ came from. I'm aware that you need context to answer my questions. So here are the pages: And here is Proposition 11.1.1: If you need something more, let me know. 
Thank you for your help.","['number-theory', 'finite-fields', 'zeta-functions', 'characters']"
3011491,$\tan^2 10^\circ+\tan^2 50^\circ+\tan^2 70^\circ=9$ [duplicate],"This question already has an answer here : Proving $\tan^210^\circ+\tan^250^\circ+\tan^270^\circ=9$ (1 answer) Closed 5 years ago . Strangest thing... *: $$\tan^2 10^\circ+\tan^2 50^\circ+\tan^2 70^\circ=9\tag{1}$$ The trick, as always, is how to prove it. My idea was to add a ""missing"" tangent and analyze a similar expression: $$\tan^2 10^\circ+\tan^2 30^\circ+\tan^2 50^\circ+\tan^2 70^\circ$$ ...and then to attack this sum pairwise (first and the last term, second and third). Despite the fact that I got the same angle ( $80^\circ$ ) here and there, I got pretty much nowhere with this approach. The other interesting fact is that (1) can be rewritten as: $$\cot^2 20^\circ+\cot^2 40^\circ+\cot^2 80^\circ\tag{1}$$ ...and now the angles are in nice geometric progression. That's the vector of attack that I'm trying to exploit now, but maybe you can entertain youself a little bit too. * Borrowed from ""Usual suspects""",['trigonometry']
3011497,Picture of the Universal Cover of the Hyperbolic Pair of Pants,Does anyone have a good picture of the universal cover of the hyperbolic pair of pants with geodesic boundary in either upper half space or the disk? I'm also wondering how the picture changes as you change the geodesic boundary lengths of the pair of pants. Thanks.,"['general-topology', 'differential-topology', 'hyperbolic-geometry', 'differential-geometry']"
3011499,Is the set $\{ (X_n)_{n \in \mathbb{N}} \text{ has a nondecreasing subsequence} \}$ measurable?,"Given a measurable space $(\Omega, \mathcal{A})$ and $\mathcal{A}/\mathcal{B}(\mathbb{R})$ -measurable maps $X_n : \Omega \to \mathbb{R}$ , $n \in \mathbb{N}$ , is the set $$
A:= \{\omega \in \Omega | (X_n(\omega))_{n \in \mathbb{N}} \text{ has a nondecreasing subsequence} \}
$$ in $\mathcal{A}$ ? My intuitive answer was yes. But I have been struggling to show this. Basically, the problem is that there are uncountably many subsequences. To clarify: A sequence of real numbers $(a_n)_{n \in \mathbb{N}}$ is nondecreasing if $a_n \leq a_{n+1}$ for all $n \in \mathbb{N}$ . Here are some ways of trying to show the measurability that don't work. Trying to write $A$ as $$
B:= \bigcap_{n \in \mathbb{N}}\bigcup_{k \geq n}\bigcup_{l > k}\{X_k \leq X_l\}
$$ doesn't work, because $B$ doesn't have to be in $A$ , see the sequence $-1,-1,-2,-2,-3,-3,\dots$ Defining, for all $k \in \mathbb{N}$ , the random variables $T_0^k := k$ , and then recursively $$
T_{j+1}^k := \inf\{n \geq T_j^k|X_n \geq X_{T_j^k}\}
$$ and then considering the set $$
C:= \bigcup_{k \in \mathbb{N}}\bigcap_{j \in \mathbb{N}}\{T_j^k < \infty\}
$$ doesn't work, because $A$ doesn't have to be in $C$ , see the sequence $0,\frac12,0,\frac13,0,\frac14,0,\dots$ Considering the sets $$
S_k =  \{(X_n)_{n \in \mathbb{N}} \text{ has a nondecreasing subsequence of length } k \}
$$ and arguing that $A = \bigcap S_k$ . In fact the reverse inclusion does not hold as can be seen by the sequence: $$1,1+1/2,$$ $$0,0+\frac{1}{2}, \; 0+\frac{3}{4},$$ $$-1,-1+\frac{1}{2},-1+\frac{3}{4},-1+\frac{7}{8},$$ $$-2,-2+\frac{1}{2},-2+\frac{3}{4},-2+\frac{7}{8}, -2+\frac{15}{16}, \ldots$$ Update : I still don't know the answer to this question. However, I feel like if $A$ was always measurable, it shouldn't be so difficult to find a proof. For showing non-measurability, I have tried the following. Let $X_n$ be iid $U([0,1])$ distributed. Now if we assume that $A$ is measurable, then $A$ is also in the terminal $\sigma$ -algebra $\mathcal{T}_\infty$ of the $X_n$ . Now if we define $$
B := \{\omega \in \Omega | (X_n(\omega))_{n \in \mathbb{N}} \text{ has a nonincreasing subsequence} \},
$$ then we have $P(A \cup B) = 1$ because every sequence of real numbers has a monotone subsequence, and $P(A) = P(B)$ because the $X_n$ are $U([0,1])$ -distributed. This gives us $P(A) > 0$ , and thus $P(A) = 1$ because $A \in \mathcal{T}_\infty$ . So all you would have to do to find a contradiction is to find a set of strictly positive measure where $(X_n)$ doesn't have a nondecreasing subsequence. Update : George Lowther has given an extensive answer. To sum up: We can use the lemma in his answer to show that our set $A$ need not be in $\mathcal{A}$ , but is always analytic which means in particular that, given any probability measure $P$ on $(\Omega, \mathcal{A})$ , we can always assign a meaningful measure to $A$ because $A$ is in the completion of $\mathcal{A}$ w.r.t. $P$ . Here is how we use the lemma: Given any measurable space $(\Omega,\mathcal{A})$ and $A$ as above, the first implication of the lemma directly implies that $A$ is analytic. To show that $A$ need not be in $\mathcal{A}$ , we construct a counterexample. Let $(\Omega,\mathcal{A}) = (\mathbb{R},\mathcal{B}(\mathbb{R}))$ . Then there exists a set $A \subseteq \Omega$ that is analytic but is not in $\mathcal{A}$ . Now the second implication of the lemma tells us that we can construct a sequence $(X_n)_{n \in \mathbb{N}}$ of random variables such that $$
A = \{\omega \in \Omega | (X_n(\omega))_{n \in \mathbb{N}} \text{ has a nondecreasing subsequence} \}.
$$","['stochastic-processes', 'measure-theory', 'probability-theory', 'probability']"
3011524,How is $C_0^k(\mathbb R)$ defined?,"I'm sorry for asking such a short question, but I see the space $C_0^k(\mathbb R)$ everywhere being used without a rigorous definition. $C_0(\mathbb R)$ is the space of continuous functions on $\mathbb R$ vanishing at infinity. The question is, is $C_0^k(\mathbb R):=C_0(\mathbb R)\cap C^k(\mathbb R)$ or is $C_0^k(\mathbb R):=\left\{f\in C^k(\mathbb R):f^{(i)}\in C_0(\mathbb R)\text{ for all }i\in\left\{0,\ldots,k\right\}\right\}$ ? Those spaces shouldn't coincide.","['derivatives', 'analysis']"
3011543,Limit of $\lim_{x \to 0} (\cot (2x)\cot (\frac{\pi }{2}-x))$ (No L'Hôpital),"$\lim_{x \to 0} (\cot (2x)\cot (\frac{\pi }{2}-x))$ I can't get to the end of this limit. Here is what I worked out: \begin{align*}
& \lim_{x \to 0} \frac{\cos 2x}{\sin 2x}\cdot\frac{\cos(\frac{\pi }{2}-x )}{\sin(\frac{\pi }{2}-x )}
\lim_{x \to 0}\frac{\frac{\cos2x }{2x}}{\frac{\sin 2x}{2x}}\cdot \frac{\cos(\frac{\pi }{2}-x )}{\sin(\frac{\pi }{2}-x )}
= \lim_{x \to 0} \frac{\cos 2x}{2x} \cdot \frac{\cos(\frac{\pi }{2}-x )}{\sin(\frac{\pi }{2}-x )} \\
= & \lim_{x \to 0} \frac{{\cos^2 (x)}-{sin^2 (x)}}{2x}\cdot\frac{\cos(\frac{\pi }{2}-x )}{\sin(\frac{\pi }{2}-x )}
= \lim_{x \to 0} \left(\frac{\cos^2(x)}{2x}-\frac{sin^2 x}{2x}\right)\cdot \frac{\cos(\frac{\pi }{2}-x )}{\sin(\frac{\pi }{2}-x )} \\
= & \lim_{x \to 0} \left(\frac{1-\sin^2 x}{2x}-\frac{sin x}{2}\right)\cdot \frac{\cos(\frac{\pi }{2}-x )}{\sin(\frac{\pi }{2}-x )}
= \lim_{x \to 0} \left(\frac{1}{2x}-\frac{\sin^2 x}{2x}-\frac{sin x}{2}\right) \cdot \frac{\cos(\frac{\pi }{2}-x )}{\sin(\frac{\pi }{2}-x )} \\
= & \lim_{x \to 0} \left(\frac{1}{2x}-\frac{\sin x}{2}-\frac{sin x}{2}\right)\cdot \frac{\cos(\frac{\pi }{2}-x )}{\sin(\frac{\pi }{2}-x )}
= \lim_{x \to 0} \left(\frac{1}{2x}-2\frac{\sin x}{2}\right)\cdot \frac{\cos(\frac{\pi }{2}-x )}{\sin(\frac{\pi }{2}-x )} \\
= & \lim_{x \to 0} \left(\frac{1}{2x}-\sin x\right)\cdot \frac{\cos(\frac{\pi }{2}-x )}{\sin(\frac{\pi }{2}-x )}
\end{align*} Here is where I can't seem to complete the limit, the 2x in the denominator is giving me a hard time and I don't know how to get rid of it. Any help would be appreciated. (In previous questions I got a really hard time because of my lack of context, I hope this one follows the rules of the site. I tried.)","['limits', 'calculus', 'limits-without-lhopital', 'trigonometry']"
3011555,"Find the general solution in terms of Bessel functions: $t^2x'' + x' + x = 0, \quad t < 0, \text{ Hint: } s = 2\sqrt{t}$","I was asked the following question: Find the general solution in terms of Bessel functions: $$t^2x'' + x' + x = 0, \quad t < 0, \text{ Hint: } s = 2\sqrt{t}$$ My approuch I think that what I have to do is transform the given equation in one that has a form of a Bessel equation, and for that it must be used the hint . $\frac{ds}{dt} = t^{-1/2}$ $\frac{dx}{dt} = \frac{dx}{ds}\frac{ds}{dt} = t^{-1/2} \frac{dx}{ds}$ $\frac{d^2x}{dt^2} = \frac{d}{dt} \Big( \frac{dx}{dt} \Big) = \frac{d}{dt} \Big( t^{-1/2} \frac{dx}{ds} \Big) = \frac{d}{dt}t^{-1/2} \frac{dx}{ds} +  t^{-1/2}\frac{d}{dt} \Big( \frac{dx}{ds} \Big) = \frac{-1}{2} t^{-3/2} \frac{dx}{ds} + t^{-1/2} \frac{d}{ds} \Big( \frac{dx}{ds} \Big) \frac{ds}{dt} = \frac{-1}{2} t^{-3/2} \frac{dx}{ds} + t^{-1} \frac{d^2x}{ds^2}$ So, in the given equation, now we have: $$
\begin{align}
t^2\Big( \frac{-1}{2} t^{-3/2} \frac{dx}{ds} + t^{-1} \frac{d^2x}{ds^2} \Big) + t^{-1/2}\frac{dx}{ds} + x  &= 0 \\
\frac{-1}{2}t^{1/2}\frac{dx}{ds} + t\frac{d^2x}{ds^2} + t^{-1/2}\frac{dx}{ds} + x &= 0 \\
\frac{-1}{2} \frac{s}{2} \frac{dx}{ds} + \frac{s^2}{4} \frac{d^2x}{ds^2} + \frac{2}{s} \frac{dx}{ds} + x &= 0 \\
s^2 \frac{d^2x}{ds^2} + \Big( \frac{8}{s} - s \Big)\frac{dx}{ds} + 4x &= 0
\end{align}
$$ Which doesn't have a Bessel-equation form. So please, can anybody enlighten me? Thanks in advanced!","['ordinary-differential-equations', 'bessel-functions']"
3011590,"What is an intuitive explanation for how the t-distribution, normal distribution, F-distribution and Chi-square distribution relate to each other?","What is an intuitive explanation for how the t-distribution, normal distribution, F-distribution, and Chi-square distribution relate to each other? Could anyone explain this clearly with a sensible example? I am a biologist and 've been trying to understand this nearly 10 years now. Every time use the statistical tests without a proper understanding of the base. Textbooks do not refer to this question either, moreover, we are not math or stat specialized in the university.","['chi-squared', 'normal-distribution', 'probability']"
3011614,The product of locally compact spaces is locally compact,"My definition of local compactness is as follows: A topological space $(X, \mathcal{T})$ is locally compact if, for every $x \in X$ , there is a $U \in \mathcal{T}$ with $x \in U$ such that $\overline{U}$ is compact. I am then asked to prove that, if $X$ and $Y$ are locally compact and Hausdorff , then $X \times Y$ equipped with the product topology is also locally compact. Trouble is, I don't believe I use Hausdorff in my proof! And I don't see where it breaks down. Here it is: Let $(X, \mathcal{T}_X)$ and $(Y, \mathcal{T}_Y)$ be locally compact. Consider a point $(x, y) \in X \times Y$ . Then there exist $U \in \mathcal{T}_X$ with $x \in U$ and $V \in \mathcal{T}_Y$ with $y \in V$ such that $\overline{U}$ is compact in $X$ and $\overline{V}$ is compact in $Y$ . Firstly, $U \times V$ is open in $X \times Y$ , and $(x,y) \in U \times V$ . Furthermore, $\overline{U}$ is compact as a subset of $X$ , so considered as a topological space with the subspace topology, it is also compact. Similarly for $\overline{V}$ . Then the space $\overline{U} \times \overline{V}$ equipped with the product topology is also compact. Now I believe that the product topology induced by the topologies on $\overline{U}$ and $\overline{V}$ is the same as the subspace topology induced by considering $\overline{U} \times \overline{V}$ as a subspace of $X \times Y$ . So $\overline{U} \times \overline{V}$ is also compact with respect to the subspace topology, and so it is a compact subset of $X \times Y$ . But $\overline{U} \times \overline{V} = \overline{U \times V}$ , so we're done.",['general-topology']
3011622,"Why are we using ""Euler's Number"" constantly? [duplicate]",This question already has answers here : Why is the number $e$ so important in mathematics? (8 answers) Closed 5 years ago . I am a student at technical university.We are currently studying Calculus and I am really curious about why we are using Euler's Number.,"['exponentiation', 'logarithms', 'functions', 'trigonometry', 'exponential-function']"
3011637,"Does $\lim_{(a, b) \to (0, 0)} \sqrt{\frac{a^2b^2}{a^2 + b^2}} = 0$?","Does $$\lim_{(a, b) \to (0, 0)} \ \sqrt{\frac{a^2b^2}{a^2 + b^2}} = 0 \ ?$$ I'm trying to show that $$\lim_{(a, b) \to (0, 0)} \ \sqrt{\frac{a^2b^2}{a^2 + b^2}} = 0 $$ but I am getting stuck. I was thinking that as a starting point I could show that $$\lim_{(a, b) \to (0, 0)} \ \frac{a^2b^2}{a^2 + b^2} = 0 $$ and then conclude that since $$\lim_{x \to 0} \sqrt{x} = 0$$ and $\frac{a^2b^2}{a^2 + b^2} \to 0$ as $(a, b) \to (0, 0)$ we arrive at $$\lim_{(a, b) \to (0, 0)} \ \sqrt{\frac{a^2b^2}{a^2 + b^2}} = 0.$$ Firstly is my approach above a correct one. Secondly how can show that $$\lim_{(a, b) \to (0, 0)} \ \frac{a^2b^2}{a^2 + b^2} = 0. $$ Because I don't see any way to show the above (apart from perhaps proving it from the definition directly, which I would like to avoid if there is an easier way to do it). Also it could be the case that the initial limit doesn't even exist.","['limits', 'multivariable-calculus']"
3011673,Different way of solving $\frac{d^2u}{dx^2}=1$?,"I'm a third year physics student, not a math student.
The conventional way to solve this would be: $$\frac{d^2u}{dx^2}=\frac{d}{dx}(\frac{du}{dx})=1 \Rightarrow d(\frac{du}{dx})= dx\Rightarrow \int d(\frac{du}{dx})=\int dx\Rightarrow \frac{du}{dx}=x+A \Rightarrow 
du=(x+A)dx \Rightarrow u=\frac{x^2}{2}+Ax+B$$ So I'm wondering if what follows is correct: $$\frac{d^2u}{dx^2}=1 \Rightarrow d^2u=(dx)^2 \Rightarrow d(du)=dxdx \Rightarrow \int d(du)=\int dxdx \Rightarrow du=\int dxdx$$ At this point, I don't know if there are other ways to proceed, but I use integration by parts $$\int vdw=vw-\int wdv$$ by considering $v=dx$ and $dw=dx$ , so that $w=x$ and $dv=d(dx)$ : $$du=\int dxdx=xdx-\int x·d(dx)$$ If I assume that $-\int x·d(dx)=C$ is a constant, we get $$du=xdx+C \Rightarrow u=\frac{x^2}{2}+Cx+D$$ which is what we had originally.
However, how would I go about proving that $\int x·d(dx)=constant$ ? Is it because $d(dx)=0$ ? And how do I prove that? Are there any other interesting ways to solve this differential equation?","['integration', 'indefinite-integrals', 'calculus', 'ordinary-differential-equations']"
3011692,How to show that $p(1)\ \text{is real} \iff \ p(-1)\ \text{is real}$,I have been working on this problem and I cannot figure it out! I spent hours of time on it with no use. Can anybody help? The question is: Suppose $p(x)$ is a polynomial with complex coefficients and even degree( $n=2k$ ). All zeros of $p$ are non-real and with length equal to $1$ . prove $$p(1)\in\mathbb{R} \;\;\Longleftrightarrow\;\; p(-1)\in\mathbb{R} $$,"['functions', 'linear-algebra', 'polynomials']"
3011739,If $\operatorname{Sym}_X \simeq \operatorname{Sym}_Y$ then there is bijection from $X \to Y$,"If $\operatorname{Sym}_X \simeq \operatorname{Sym}_Y$ then there is bijection from $X \to Y$ ? , I proved the other way around, i think i need to build $f$ from $\psi : \operatorname{Sym}_X \to\operatorname{Sym}_Y$ .","['symmetric-groups', 'group-theory', 'abstract-algebra']"
3011775,Geometric understanding of subtracting lambda from diagonals,"Given the definition of eigenvalues/eigenvectors: $Av = \lambda v $ you could rearrange the terms to be: $(A - \lambda I)v = 0$ Geometrically, the first equation says that multiplying by $A$ is the same as scaling the vector $v$ by $\lambda$ . However, in the second equation, how do you visualize the effect of subtracting the matrix $\lambda I$ from matrix $A$ and how does that induce a linearly dependent set of basis vectors? TL;DR: I understand that the new matrix $(A-\lambda I)$ collapses the span of $v$ into a lower dimension but I don't understand how $A$ relates to $(A-\lambda I)$ geometrically.","['visualization', 'linear-algebra', 'geometry', 'eigenvalues-eigenvectors']"
3011846,Limits for sine and cosine functions,"Recently I took a test where I was given these two limits to evaluate: $\lim_\limits{h \to 0}\frac{\sin(x+h)-\sin{(x)}}{h}$ and $\lim_\limits{h \to 0}\frac{\cos(x+h)-\cos{(x)}}{h}.$ I used sine and cosine addition formulas and found the value of each limit individually, eventually canceling out $\sin x\cdot \frac1h$ and $\cos x\cdot \frac1h$ because I learned that we can evaluate limits piece by piece. As a result, I got $\cos x $ and $-\sin x$ as my two answers. However, my teacher marked it wrong saying that we cannot cancel $\sin{x}\cdot\frac1h$ or $\cos{x}\cdot\frac1h$ because those limits do not exist. Can someone please explain why this doesn't work? I thought that we can cancel those limits out since we never look at $0,$ just around $0,$ when evaluating these two limits. Sine: $$\frac{\sin(x+h)-\sin(x)}h=\frac{\sin(x)\cos(h)+\sin(h)\cos(x)}h-\frac{\sin(x)}h$$ $$=\sin(x)\frac1h+\cos(x)-\sin(x)\frac1h=\cos(x)$$ Cosine: $$\frac{\cos(x+h)-\cos(x)}h=\frac{\cos(x)\cos(h)-\sin(x)\sin(h)}h-\cos(x)\frac1h$$ $$=\cos(x)\frac1h-\sin(x)\cdot1-\cos(x)\frac1h=-\sin(x)$$ Note: I am allowed to assume $\lim_\limits{x\to 0} \frac{\sin(h)}h=1,\lim_\limits{x\to 0} \frac{\cos(h)-1}h=0.$","['limits', 'calculus', 'trigonometry']"
3011870,mean vs median geometric interpretation?,"I'm looking at this picture on wikipedia, comparing the median and mean of an arbitrary distribution. But what does it mean exactly? From the figure, it looks like the mean is the center of mass of the distribution (in the sense that you could balance the distribution on that point). However, since the median has $50\%$ to its left and right, it seems a more reasonable candidate for the center of mass. Which one is it? And what is the geometric interpretation of the other metric?","['statistics', 'median', 'means']"
3011888,$\lim_{x\to -\infty} x+\sqrt{x^2-3x}$,"Hey so I'm having a bit of a hard time understanding this one. $\lim_{x\to -\infty} x+\sqrt{x^2-3x}$ 1) $x+\sqrt{x^2-3x}$ * $(\frac{x-\sqrt{x^2-3x}}{x-\sqrt{x^2-3x}})$ 2) $\frac{x^2-(x^2-3x)}{x-\sqrt{x^2-3x}}$ 3) $\frac{3x}{x-\sqrt{x^2(1-\frac{3}{x}})}$ 4) $\frac{3x}{x-\sqrt{x^2}*\sqrt{1-\frac{3}{x}}}$ 5) $\frac{3x}{x-x(\sqrt{1-\frac{3}{x}})}$ 6) $\frac{3}{1-(\sqrt{1-\frac{3}{x}})}$ Now I would just take the limit, it would result in $\frac{3}{1-1}$ which would be undefined. For some reason, the $x$ in the denominator of step 5 should turn into $-(-x)$ which in turn would be positive and therefore be $\frac{3}{1+\sqrt{1=\frac{3}{x}}}$ which would equal $\frac{3}{2}$ . I really don't get it. Apparently the $-\infty$ would mean that $\sqrt{x^2}$ = $-x$ . We didn't even evaluate the limit yet.. how does that turn into $-x$ , just because we know the limit is negative does not mean we evaluated it yet..., why not simplify until there is no more simplification to be done, which is what I did in my steps, which would evaluate to undefined? Would love some help, thanks!","['limits', 'calculus']"
3011980,Example for Etale Morphism,"I'm want to understand the concept of etale morphism of schemes using following definition: A morphism $f: X \to Y$ is etale iff it is * flat * (1), locally of finite type (2) and has the separable field condition (3): Here (1), (2) and (3) mean: (1) For every $x \in X$ the induced morphism $f_x ^{\#}:\mathcal{O}_{Y, f(x)} \to \mathcal{O}_X$ is flat (2) There exist an open affine neighbourhood $U_x =Spec(R)$ of $x$ and an o. a. n. $V_{f(x)}= Spec(S)$ of $f(x)$ with $f(U_x) \subset V_{f(x)}$ such that the induced ring map $S \to R$ is of finite presentation (3) Let $m_x \subset \mathcal{O}_{X,x}$ the unique maximal ideal of local ring $\mathcal{O}_{X,x}$ and respectively $m_{f(x)} \subset \mathcal{O}_{X,x}$ the unique maximal ideal of $\mathcal{O}_{Y,f(x)}$ : Then the induced finite field extension $\mathcal{O}_{Y,f(x)}/m_{f(x)} \to \mathcal{O}_{X,x}/m_x$ is separable I'm trying to acquire the intuition for etaleness by considering following four examples (a) $Spec(\mathbb{C}[T, T^{-1}]) \to Spec(\mathbb{C}[T])$ (b) $Spec(\mathbb{C}[T] /(T^d - 2))\to Spec(\mathbb{C}[T])$ (c) $Spec(\mathbb{C}[T, Y]/(Y^d - T)) \to Spec(\mathbb{C}[T])$ (d) $Spec(\mathbb{C}[T, T^{-1},Y]/(Y^d - T)) \to \mathbb{C}[T]$ My attempts: (a) Is is flat since it just a localization of $\mathbb{C}[T] $ on $T$ . Or a secound argument: Open embeddings are etale. But what about (b), (c) and (d)? All induced ring maps $\mathbb{C}[T] \to ...$ in (b),(c), (d)$ are quotient maps, therefore of finite presentaions. Since beeing from finite presentations behaves well under base changes / localisations, condition (2) holds. What about conditions (1) and (3)? Why it suffice to consider in all cases only the localisation on $p= (T)$ ? The main problem here for me is to analyze what hapens on stalks, therefore what happens with the localisations of the ring map $\mathbb{C}[T] \to ...$ with respect an arbitrary point /prime ideal $p =(T - \lambda)$ for $\lambda \in \mathbb{C}$ . I guess that one can distinguish two relevant cases 1. $\lambda=0$ and 2. $\lambda \neq 0$ arbitrary. Could anybody explain how to argue exactly for (1) and (3)?","['algebraic-geometry', 'schemes']"
3011998,Why am i getting two real roots of the cubic $x^3+x+5=0$,I was going through the solution of depressed cubic equation $$x^3+x+5=0$$ By Cardano's Method we assume $$x=u+v$$ Then we have $$(u+v)^3-3uv(u+v)-(u^3+v^3)=0$$ Comparing with given cubic we get $$u^3+v^3=-5 \tag{1}$$ $$uv=\frac{-1}{3}\tag{2}$$ Solving $(1)$ and $(2)$ we get $$u^3-\frac{1}{27u^3}=-5$$ Letting $u^3=p$ we get $$27p^2+135p-1=0$$ which gives two real distinct roots of $p$ which $\implies$ two real distinct roots of $u$ and hence two real distinct roots of $v$ Hence two distinct real roots of $x$ what went wrong here?,"['cubics', 'algebra-precalculus', 'polynomials']"
3012008,Evaluating double sums with related indices,"I am having trouble finding any techniques that allow people to solve double sums where the indices rely on each other. For example, suppose I have the following sum: $$\sum_{i=1}^{n-1}\sum_{j=i+1}^n i + j$$ What techniques can I use to eliminate the sums, and arrive at a simple algebraic expression in terms of only n?","['summation', 'discrete-mathematics']"
3012014,Permutation of array.,"Let $E$ be the set of the first $x$ even numbers and $O$ the set of the first $y$ odd numbers. (1) How many permutations are there of the set $E \cup O$ ? I think that's just $(x+y)!$ . (2) How many permutations are there such that the last element of $E$ appears at an odd position? Examples. $[1,2,3,4,5]$ doesn't count since $4$ occurs at position $4$ . $[4,1,2]$ counts since $2$ is at position $3$ . $[2,1,5,3]$ counts since $2$ is at position $1$ . Original post: Suppose we have an array of length z. Which consists of x different even numbers and y different odd numbers. So $x \in [2_1,4_2,6_3 \dots (2n)_x]$ and $y \in [1_1,3_2,5_3 \dots (2n+1)_y]$ So z = x+y. We also know that x => 1 always applies. 1st question: How many different arrays of length z there are. That should be exactly $z!$ many or? 2nd question: How many different arrays are there so that the last even number in the array is on an odd index. (The array in this example starts with index 1) Examples: 1) [1,2,3,4,5] This array has length 5. The last even number in the array is 4 and has index 4 in the array, so we don't count such an array. 2) [52,3,14]. The last even number in this array is 14 and has index 3. So such an array counts towards it. 3) [52,3,5,7]. The last even number in this array is 52 and has index 1. So such an array counts towards it.","['combinations', 'combinatorics']"
3012050,"Given second and first derivatives at 2 points, prove that some point in between them has third derivative greater than or equal to 24.","Let $f$ be a function that is $C^3$ on an open interval containing $[0,1]$ - that is,  the third derivative $f'''$ exists and is continuous on an open interval containing $[0,1]$ . Assume that $f(0) = f'(0) = f''(0) = 0$ and that $f'(1) = f''(1) = 0$ . If $f(1) = 1$ , prove that there is some $c\in\left(0,1\right)$ such that $f'''(c) \geq 24$ . Not sure how to approach this problem, been stuck on it for a while. Any help would be nice. I tried using the Mean Value Theorem, and got that at some point $c_1\in\left[0,1\right], f'(c_1) = \frac{f(1)-f(0)}{1-0}=1$ and there is some point $c_2 \in [c_1,1]$ such that $f''(c_2) = \frac{f'(1)-f'(c_1)}{1-c_1}=\frac{-1}{1-c_1}<-1$ and there is some point $c_3\in[c_2,1]$ such that $f'''(c_3) = \frac{f''(1)-f''(c_2)}{1-c_2}>1$ . I'm not sure how to extend this to $24$ though, or even if this method will work. Is there a way to use Taylor Polynomials perhaps?",['derivatives']
3012070,Tensor product of finitely generated algebras,I am trying to compute tensor product of finitely generated algebras over a field. I was able to compute few special tensor products. Is there a general technique which allows one to compute the tensor product for any two finitely generated algebras over a field. I'm looking for this because im interested in computing fibre product of schemes.,"['algebraic-geometry', 'tensor-products', 'commutative-algebra']"
3012078,An attractor for blow-up solutions to a cubic oscillator,"(Related to this MathOverflow question ). Consider the nonlinear ODE $$\tag{1}
\frac{d^2u}{dt^2}+u=u^3, \qquad t\in\mathbb R,$$ which has the conserved quantity $$\tag{2}
E=\frac12 u'^2+\frac12 u^2 -\frac14u^4.$$ Consider only these solutions that satisfy $u>0$ and $u'>0$ . I am interested in solutions that blow-up at time $T$ , in the sense that $$
\lim_{t \nearrow T} u(t)=+\infty.$$ The following family describes all solutions with $E=0$ , parametrized by the blow-up time; $$
u_{0, T}(t):=\frac{\sqrt{2}}{\sin(T-t)}.$$ The phase portrait suggests that the trajectories of these solutions are an attractor for (1); and this is reasonable, because (2) yields $$
u'=\sqrt{2E -u^2 + \frac12u^4} = \frac{u^2}{\sqrt2} + O(1), $$ so when $u$ is very big I expect $u$ to be indistinguishable from the unique solution to $v'=\frac{v^2}{\sqrt 2} $ that blows up at $T$ , that is, $$v_T(t)=\frac{\sqrt2}{T-t}, $$ and $v_T$ is asymptotically equivalent to $u_{0, T}$ as $t\nearrow T$ . I would like to obtain a more precise, quantitative version of this attraction. Question . Let $u$ be a solution to (1) such that $u(t)\to +\infty$ as $t\nearrow T$ . Is it true that $$|u(t)-u_{0, T}(t)|\to 0,\qquad \text{as }t\nearrow T?$$ Is it true that $$\frac{u(t)}{u_{0,T}(t)}\to 1,\qquad \text{as }t\nearrow T?$$ Remark . The equation (1) is a special case of Duffing equation .","['analysis', 'ordinary-differential-equations']"
3012090,How to evaluate this nonelementary integral?,"Let $x>0$ . I have to prove that $$
\int_{0}^{\infty}\frac{\cos x}{x^p}dx=\frac{\pi}{2\Gamma(p)\cos(p\frac{\pi}{2})}\tag{1}
$$ by converting the integral on the left side to a double integral using the expression below: $$
\frac{1}{x^p}=\frac{1}{\Gamma(p)}\int_{0}^{\infty}e^{-xt}t^{p-1}dt\tag{2}
$$ By plugging $(2)$ into $(1)$ I get the following double integral: $$
\frac{1}{\Gamma(p)}\int_{0}^{\infty}\int_{0}^{\infty}e^{-xt}t^{p-1}\cos xdtdx\tag{3}
$$ However, I unable to proceed any further as I am unclear as to what method should I use in order to compute this integral. I thought that an appropriate change of variables could transform it into a product of two gamma functions but I cannot see how that would work. Any help would be greatly appreciated.","['gamma-function', 'multivariable-calculus']"
3012183,"$n$ lines in a plane, proper coloring of intersection points with just 3 colors","Draw $n$ lines in a plane so that there are no parallel lines and there are no three lines passing through the same point. Each intersection point is colored red, green or blue. Prove that it is possible to color all intersection points in a “proper” way, so that any two adjacent points (like $A_i, A_j$ ) have different colors. This also means that if you ""travel"" along an arbitrary line, you will cross $n-1$ intersection points, constantly changing colors from one intersection point to another. My first (and last) try was to use induction. Obviously for two or three lines, we have one or three intersection points and with three colors available we have the base of induction proved. However, the induction step is more difficult. I was able to prove the induction step if in every possible arrangement of lines it was possible to find a line that divides the plane into two halves with one half having no intersection points. However, I was able to construct counter-examples where such line does not exist. The last time I tried to solve a similar red-green-blue problem I discovered Ramsey theory. I wonder what I will discover this time :)","['graph-theory', 'combinatorics', 'coloring', 'plane-geometry']"
3012200,Getting Canonical Coordinates in differential equations from Lie Group,"I've been trying to understand how Lie Groups can help solve differential equations ( this 12-page pdf is the most straightforward explanation I've seen). My understanding is that when a first-order differential equation $\frac{dy}{dx}=h(x,y)$ has a continuous ""translation symmetry"" $(x,y)\mapsto(x,y+\lambda)$ , it becomes very easy to solve the equation using basic integration of one variable. The problem is that most differential equations in standard $(x,y)$ coordinates don't have this nice translation symmetry, and so we need to change to a set of ""canonical coordinates"" $(X,Y)$ which do have the desired translation symmetry $(X,Y)\mapsto(X,Y+\lambda)$ . The main condition that these new canonical coordinates need to satisfy, is that the $Y$ coordinate should be aligned with the $\lambda$ variable ( $\frac{dY}{d\lambda}=1,\frac{dX}{d\lambda}=0$ ), so that we get the nice translation symmetry we want: $$\frac{dY}{d\lambda}=\frac{dY}{dx}\frac{dx}{d\lambda}+\frac{dY}{dy}\frac{dy}{d\lambda}=Y_x\xi+Y_y\eta=1$$ $$\frac{dX}{d\lambda}=\frac{dX}{dx}\frac{dx}{d\lambda}+\frac{dX}{dy}\frac{dy}{d\lambda}=X_x\xi+X_y\eta=0$$ We also require that the symmetry condition be satisfied: $$\frac{dY}{dX}=\frac{D_xY}{D_xX}=\frac{Y_x+Y_y y'}{X_x+X_y y'}=h(X,Y)$$ Here's where I'm stuck. Basically all the terms in the above equations are unknowns, and it seems incredibly difficult to solve for the new coordinates $(X,Y)$ . I've also seen the ""linearized symmetry condition"" below, but it still results in a difficult-to-solve equation: $$\eta_x-\xi_y h^2 +(\eta_y -\xi_x)h - (\xi h_x + \eta h_y) = 0$$ Is there a nice, algorithmic approach for deducing a set of canonical coordinates? Or does it ultimately come down to ""guess and check"" with the above equation?","['lie-groups', 'ordinary-differential-equations']"
3012229,Show that $\lim_{x\to0}f(x) = \lim_{x\to0}f(x^3)$ (Real Analysis),"I'm trying to prove  that $$\lim_{x\to0}f(x) = \lim_{x\to0}f(x^3)$$ (The domain is not specified and neither the continuity, so it really is only about the limit of an arbitrary function).. I'm guessing I need to simply use the definition. However I'm not sure where to start. Here is what I had in mind, however I feel like it's not at all how it should be proved. Proof Let $\lim_{x\to0}f(x) = L$ . Then, we have that $$ \forall \epsilon > 0, \exists \delta>0
 \text{ such that whenever } 0<|x|< \delta \Rightarrow |f(x) - L| < \epsilon$$ Let $y = x^3$ , then we want to show that $$|f(y) - L| < \epsilon \text{ whenever } 0<|x| = |y^{\frac{1}{3}}| < \delta$$ And here is where I get stuck. Is there any more efficient way to prove this? Thank you!","['limits', 'proof-verification', 'real-analysis']"
3012259,"Necessary, but not sufficient for showing $f$ is measurable.","I am trying show that if $\{ x\in [a, b] | f(x) =c\} $ is measurable for all $ c\in \mathbb{R} $ is not sufficient to show that $f$ is measurable on $[a, b] $ . \
Possible approach : I thought If I defined a non measurable set and define $ f$ to evaluate whether or not $ x $ is in the set.","['general-topology', 'measure-theory', 'real-analysis']"
3012277,Counting question on bit strings - problem with using cases,"How many bit strings of length 10 either begin with three 0s or end with two 0s? I solved this question using cases but I do not seem to be getting the answer of $352$ . My attempt:
Consider two cases: Case 1: The string begins with three $0$ s and does not end with two $0$ s. There is only $1$ way to choose the first three bits, $2^5$ ways for the middle bits, and $3$ ways for the last two bits ( $4$ ways to construct a string of two bits, minus $1$ way to make three $0$ s). There are $2^5 \cdot 3$ ways to construct strings of this type. Case 2: The string does not begin with three $0$ s but ends with two $0$ s. There are $2^3 - 1 = 7$ ways to choose the first three bits without three $0$ s, $2^5$ ways for the middle bits, and $1$ way for the last two bits. There are $7 \cdot 2^5$ ways to construct strings of this type. By the rule of sum, there are $2^5 \cdot 3 + 2^5 \cdot 7 = 320$ ways to construct bit strings of length 10 either begin with three $0$ s or end with two $0$ s.","['combinatorics', 'discrete-mathematics']"
3012298,F test vs T test. What is the real diference?,"As I've learnt, a T - test is used to compare 2 populations’ means, whereas an F-test (ANOVA) is used to compare 2/> populations’ variances. At the end is this doing the same thing? My background is from biology and no strong math/stat background. I wonder because whenever I used ANOVA (comparing >2 groups) followed by postHOC Tukey and not observing sig. differences, supervisor asking to use multiple t-test every time. Is this acceptable way of doing statistics. I see there are many publications in biology where they do not follow statistics taught in the Textbooks.","['statistical-inference', 'statistics', 'variance', 'normal-distribution']"
3012312,"Why are the fundamental and anti-fundamental representation in $\text{SL}(2,\mathbb{C})$ not equivalent?","I am currently learning group theory and I learnt that the fundamental representation and the anti-fundamental representation of $\text{SL}(2,\mathbb{C})$ , $2 \times 2$ matrix with determinant of $1$ , are not equivalent.  This means that no similarity transformation can map one of them to the other. My professor gave an explanation (on the 2nd last paragraph on page 75 of the following document http://www-pnp.physics.ox.ac.uk/~tseng/teaching/b2/b2-lectures-2018.pdf ) but I don't see how the difference in the signs in the exponent imply that the representations are inequivalent. Can anyone please explain the explanation of my professor, or perhaps give another explanation?","['group-theory', 'representation-theory', 'lie-groups']"
3012316,Positive semidefiniteness of symmetric matrix with diagonal = 1 and non-diagonal elements less than 1,Does anyone know any useful results with respect to symmetric matrices with constant diagonals (specifically with respect to whether all eigenvalues are greater than $0$ )? I am working on a set of general $n \times n$ matrices with diagonal entries all equal to $1$ and non-diagonal entries between $0$ and $1$ and I am attempting to figure out whether or not this is a subset of positive semidefinite matrices,"['matrices', 'linear-algebra', 'positive-semidefinite', 'symmetric-matrices']"
3012322,Find the probability that the roots of the quadratic $U_1x^2+U_2x+U_3$ are real,"The question, from the textbook: Mathematical Statistics and Data Analysis Let $U_1, U_2, U_3$ be independent random variables uniform on $[0,1]$ . Find the probability that the roots of the quadratic $U_1x^2+U_2x+U_3$ are real. I know this question has already been asked on StackExchange but I'd like to present my incorrect attempt at it in the hopes that someone could tell me where I went wrong. So this question boils down to finding $P(U_2^2-4U_1U_3\ge 0)$ which is the discriminant. Which is equivalent to $1-P(-\sqrt{4U_1U_3} \lt U_2\lt \sqrt{4U_1U_3})$ Since all three random variables are uniform on $[0,1]$ , their density function would be just be $1$ . Putting it all together, I get the triple integral of $\int_{0}^{1}\int_{0}^{1}\int_{-\sqrt{4u_1u_3}}^{\sqrt{4u_1u_3}}du_2du_1du_3$ Which is what I think should equal to $P(-\sqrt{4U_1U_3} \lt U_2\lt \sqrt{4U_1U_3})$ The triple integral turns out to be a number greater than 1 which is obviously wrong. Where did I go wrong? Can anything be salvaged here, perhaps a triple integral with different bounds? I saw the solution to this question done by someone else: Probability that a quadratic polynomial with random coefficients has real roots but I don't think I would be able to think of something like that in a test setting. Any pointers would be much appreciated!","['integration', 'uniform-distribution', 'proof-verification', 'probability-distributions', 'probability']"
3012343,Sufficient statistic for a function of the parameter,"We know that if $T$ is a sufficient statistic for $\theta$ then $f(T)$ is a sufficient statistic for $f(\theta)$ if $f(.)$ is a one -one function.
But,what if $f$ is not one one?
For example, in case of Bernoulli $(p)$ ,how to find the sufficient statistic for $p(1-p)$ ?","['statistical-inference', 'statistics', 'probability-distributions']"
3012356,"there are at least $\frac{p+1}{2}$ integers $d$, with $0 \leq d < p$, so that the equation $x^3+x=d \pmod p$ has a root$\pmod p$","Prove that for infinitely many prime numbers p, there are at least $\frac{p+1}{2}$ integers $d$ with $0 \leq d<p$ such that the equation $x^3+x \equiv d \pmod p$ has a root $\pmod p$ My first attempt was to prove by contradiction that the equation $x^3+x=d \pmod p$ does not have three different roots for some $p$ , but I realized that I was wrong. How can I prove or disprove the question ? (Sorry for my English)","['number-theory', 'discrete-mathematics', 'polynomials', 'elementary-number-theory']"
