question_id,title,body,tags
630438,Calculating square roots of operators using power series for $\sqrt{1 - z}$,"The following is a theorem from Reed & Simon's Methods of Modern Mathematical Physics, Volume I . Here, we are working in a complex Hilbert space $(\mathcal{H}, (\cdot, \cdot))$, and $\mathscr{L}(\mathcal{H})$ is the space of bounded linear operators $\mathcal{H} \to \mathcal{H}$. Statement of theorem: Let $A \in \mathscr{L}(\mathcal{H})$ be positive (i.e., $(x, Ax) \ge 0$, all $x \in \mathcal{H}$). Then there is a unique positive $B \in \mathscr{L}(\mathcal{H})$ such that $B^2 = A.$ The proof in the text begins as follows: ""It is sufficient to consider the case where $||A|| \le 1$. First observe that $$||I- A|| = \operatorname{sup}_{||\phi|| = 1}|((I-A)\phi, \phi)| \le 1.$$ Next we use that fact that $\sqrt{1-z} = 1 + \sum_{k=1}^\infty c_kz^k$ converges absolutely for complex $z$ satisfying $|z| \le 1$, where the constants $c_k$ are known explicitly. This fact implies that the series $1 + \sum_{k=1}^\infty c_k(I- A)^k$ converges in norm to an operator $B$. Since the convergence is absolute, we can square the series and rearrange terms, which proves that $B^2 = A \dots$ I am able to verify most of the statements in this passage. However: My question is, how does one successfully work out the calculation for squaring the series? I have been trying for awhile to do the formal multiplication
 $$(1 + c_1(I - A) + c_2(I-A)^2 + \cdots )(1 + c_1(I - A) + c_2(I-A)^2 + \cdots ),$$ using the fact that $0 = 1 + \sum_{k=1}^\infty c_k$. But I am just getting a bunch of messy terms. Is there a good trick to use, or an easier way to realize that $B^2 = A$? Hints or solutions are greatly appreciated.",['functional-analysis']
630463,Left/Right inverses of functions.,"I am currently studying functions in general, and I've come across left and right inverses, however I can't wrap my head around the following: $f(x) = 3x^4$ I know this function doesn't have an inverse because we get the quad root of $x/3$, however does it have a left/right inverse?","['algebra-precalculus', 'functions']"
630465,Morphisms of $k$-schemes who agree on $\overline{k}$-points.,"Let $k$ be a field and $X,Y$ be two finite-type $k$ schemes such that $X$ is geometrically reduced. Let $f,g : X \to Y$ be two morphisms of $k$-schemes such that the induced morphisms : $X(\overline{k}) \to Y(\overline{k})$ are equal. How does one show that $f = g$. There is a hint saying that one can reduce this to the case where $X$ is affine and $Y = \mathbb{A}^1_k$ and $k = \overline{k}$. I have't been able to prove the hint nor the result assuming the hint so I would be very grateful for help or a reference. (this isn't homework) Also I would like to know what goes wrong with this when $X$ isn't geometrically reduced.",['algebraic-geometry']
630472,Find $\int_0^{\frac{\pi}{4}}e^{\sec^2 x}dx$,How can we find $$\int_0^{\frac{\pi}{4}}e^{\sec^2 x}dx$$ I tried $t=\frac{\pi}{4}-x$ but this seems not work. Any hints?,"['definite-integrals', 'calculus', 'integration']"
630490,How does the sum of the series “$1 + 2 + 3 + 4 + 5 + 6\ldots$” to infinity = “$-1/12$”? [duplicate],"This question already has answers here : To sum $1+2+3+\cdots$ to $-\frac1{12}$ (18 answers) Closed 10 years ago . ( I was requested to edit the question to explain why it is different that a proposed duplicate question. This seems counterproductive to do here, inside the question it self, but that is what I have been asked by the site and moderators. There is no way for me to vote against their votes. So, here I go: Please stop voting this as a duplicate so quickly, which will eventually lead to this question being closed off. Yes, the other question linked to asks the same math, but any newcomer to the problem who was exposed to it via physics, as I was, will prefer this question instead of the one that is purely mathematically. I beg the moderators to not be pedantic on this one. This question spills into physics, which is why I did the cross post to the physics forum as well. ) How does the sum of the series “1 + 2 + 3 + 4 + 5 + 6…” to infinity = “-1/12”, in the context of physics? I heard Lawrence Krauss say this once during a debate with Hamza Tzortzis ( http://youtu.be/uSwJuOPG4FI ). I found a transcript of another debate between Krauss and William Lane Craig which has the same sum. Here is the paragraph in full: Let’s go to some of the things Dr. Craig talked about. In fact, the
  existence of infinity, which he talked about which is
  self-contradictory, is not self-contradictory at all. Mathematicians
  know precisely how to deal with infinity; so do physicists. We rely on
  infinities. In fact, there’s a field of mathematics called “Complex
  Variables” which is the basis of much of modern physics, from
  electro-magnetism to quantum mechanics and beyond, where in fact we
  learn to deal with infinity; without the infinities we couldn’t do the
  physics. We know how to sum infinite series because we can do complex
  analysis. Mathematicians have taught us how. It’s strange and very
  unappetizing, and in fact you can sum things that look ridiculous. For
  example, if you sum the series, “1 + 2 + 3 + 4 + 5 + 6…” to infinity,
  what’s the answer? “-1/12.” You don’t like it? Too bad! The
  mathematics is consistent if we assign that. The world is the way it
  is whether we like it or not. -- Lawrence Krauss, debating William Lane Craig, March 30, 2011 Source: http://www.reasonablefaith.org/the-craig-krauss-debate-at-north-carolina-state-university CROSS POST: I'm not sure if I should post this in mathematics or physics, so I posted it in both. Cross post: https://physics.stackexchange.com/questions/92739/how-does-the-sum-of-the-series-1-2-3-4-5-6-to-infinity-1-12 EDIT: I did not mean to begin a debate on why Krauss said this. I only wished to understand this interesting math. He was likely trying to showcase Craig's lack of understanding of mathematics or logic or physics or something. Whatever his purpose can be determined from the context of the full script that I linked to above. Anyone who is interested, please do. Please do not judge him out of context. Since I have watched one of these debates, I understand the context and do not hold the lack of a full breakdown as being ignorant. Keep in mind the debate I heard this in was different from the debate above.","['summation', 'sequences-and-series', 'infinity']"
630537,Algorithm for comparing the size of extremely large numbers,"Is there a simple algorithm to decide which of the numbers $$a \uparrow ^b c \text{ and } d \uparrow ^e f$$ is the bigger one ? Using the hyperoperation, the numbers can be denoted with $$H_{b+2}(a,c)\text{ and } H_{e+2}(d,f)$$ I tried using the recursive definition of $H$ $$H_n(a,b) = H_{n-1}(a,H_n(a,b-1))$$ and induction to get useful properties, but without substantial success. If the given numbers are very large, the following heuristic should give the
correct result in many cases : If $b>e$, then the first number is bigger.
If $b=e$ and $c>f$, then the first number is bigger.
If $b=e$ and $c=f$, it is trivial to compare the numbers. Of course, this heuristic cannot hold in all cases. Any ideas?","['hyperoperation', 'number-theory']"
630619,What does $\alpha+\gamma$ mean when $\alpha$ and $\gamma$ are well-ordered sets?,"I was asked to prove the following: let $\gamma$ be a well ordered set with the following property: for any $\alpha$ and $\beta$  well ordered sets, if $\alpha+\gamma=\beta+\gamma$ then $\alpha=\beta$. Show that $\gamma$ is a finite set. This might be a very doable question to solve, but I don't understand it. What does $\alpha+\gamma$ mean? they are not numbers, they are sets. What does this notation mean?","['notation', 'ordinals', 'elementary-set-theory']"
630641,Center of Direct Product is the Direct Product of Centers,"The exercise for which I am seeking feedback wants me to prove that the center of a direct product is the direct product of the centers. That is, $$Z(G_1 \times \cdots \times G_n)=Z(G_1) \times \cdots \times Z(G_n).$$ Attempt at Solution: We proceed by induction on $n$ . First, we prove our desired for $n=2$ ; this will establish our basis step. Let $(g_{1},g_{2}) \in Z(G_{1} \times G_{2})$ . Then $(g_{1},g_{2})(x_{1},x_{2})=(x_{1},x_{2})(g_{1},g_{2})$ for all $(x_{1},x_{2}) \in G_{1} \times G_{2}.$ This implies $g_{1}x_{1}=x_{1}g_{1}$ and $g_{2}x_{2}=x_{2}g_{2}$ for all $x_{1} \in G_{1}$ and for all $x_{2} \in G_{2}$ . Hence, $g_{1} \in Z(G_{1})$ and $g_{2} \in Z(G_{2})$ . To prove the reverse inclusion, this time let $(g_{1},g_{2}) \in Z(G_{1}) \times Z(G_{2})$ Then, $g_{1}x_{1}=x_{1}g_{1}$ and $g_{2}x_{2}=x_{2}g_{2}$ for all $x_{1} \in G_{1}$ and for all $x_{2} \in G_{2}$ ; it, of course, follows that $(g_{1},g_{2})(x_{1},x_{2})=(x_{1},x_{2})(g_{1},g_{2})$ for all $(x_{1},x_{2}) \in G_{1} \times G_{2}.$ Indeed, $(g_{1},g_{2}) \in Z(G_{1} \times G_{2})$ For our induction step, assume that desired result holds for some $n$ ; that is, assume $$Z(G_1 \times \cdots \times G_n)=Z(G_1) \times \cdots \times Z(G_n).$$ We show $$Z(G_1 \times \cdots \times G_n \times G_{n+1})=Z(G_1) \times \cdots \times Z(G_n) \times Z(G_{n+1}).$$ By our basis step, $$Z(G_1 \times \cdots \times G_n \times G_{n+1})=Z(G_1 \times \cdots \times G_n) \times Z(G_{n+1}).$$ Then, using our induction hypothesis, we obtain $$Z(G_1 \times \cdots \times G_n) \times Z(G_{n+1})=Z(G_1) \times \cdots \times Z(G_n) \times Z(G_{n+1}).$$ Hence, our induction step has been established. Finally, by the principle of mathematical induction, we conclude $$Z(G_1 \times \cdots \times G_n)=Z(G_1) \times \cdots \times Z(G_n),$$ for any finite collection of groups $G_{1}, \ldots , G_{n}.$ $\blacksquare$ Question: This may be a stupid question; but, I'll ask anyway! Would it be wrong if I completed the proof by letting $(g_{1},\ldots , g_{n}) \in Z(G_1 \times \cdots \times G_n)$ and showing $(g_{1},\ldots , g_{n}) \in Z(G_1) \times \cdots \times Z(G_n)$ ? (Then, of course, proceed by proving the reverse inclusion.) Thank you!","['direct-product', 'group-theory', 'abstract-algebra', 'solution-verification']"
630644,Is there an infinite group that contains every finite group (and no infinite group) as a subgroup?,"Question is in the title. For bonus points, construct the group $G$ such that it also has no infinite proper subgroups. (This second question relates to the Prüfer group , but that group is abelian, and clearly $G$ is nonabelian since it has nonabelian subgroups.) Ignoring the second constraint for now, it is clear that the direct product of every finite group contains every finite group as a subgroup, but it is not a very ""natural"" group. Are there any examples of more common infinite groups that also happen to have every finite group as a subgroup?","['infinite-product', 'finite-groups', 'group-theory']"
630650,Energy norm: what is the intuition behind?,"Last week I've read the following definition of Energy Norm (along with the definitions of a distance, Euclidean norm, p-norm, etc..: we were talking about metric spaces). Specifically, for $A\in \mathbb{R}^{n\times n}$ positive definite, the energy norm of $x\in \mathbb{R}^{n}$ is defined as follows:
$$
||x||_{A} := \sqrt{x^T A x} 
$$ I felt completely lost. Is there any intuition / geometrical representation behind this concept that may help me to understand it? Thank you in advance!","['metric-spaces', 'analysis']"
630670,"Prove that an algebra is finitely generated iff it is isomorphic to the quotient ring $R[x_1,\dots,x_n]/I$","This is a basic question, but I haven't done abstract algebra in a while and not certain of the answer. We say that an $R$-algebra $A$ is finitely generated if there exist $a_1, \dots, a_n$ such that $A=R[a_1,\dots, a_n]$. I want to prove that an $R$-algebra $A$ is finitely generated iff it is isomorphic to the quotient ring $R[x_1,\dots,x_n]/I$. Assume $A$ is finitely generated by $a_1,\dots,a_n$. We can define a unique algebra homomorphism $f\colon R[x_1,\dots,x_n] \to A$ in the usual way (apply the homomorphism $h$ from $R$ to $A$ to the coefficients, and change $x_i$ to $a_i$). The image of $f$ is $R[a_1,\dots,a_n]$. By one of the isomorphism theorems, we conclude that $A$ is isomorphic to $R[x_1,\dots,x_n]/I$ where $I$ is the kernel of $f$. I now struggle with the other direction. I found a proof online that says given $A$ is isomorphic to $R[x_1,\dots,x_n]/I$ by a map $g$, we can conclude that there exists a surjective ring homomorphism $f\colon R[x_1,\dots,x_n]\to A$. Am I right to understand that this homomorphism is given by applying $g$ to elements of $R[x_1,\dots,x_n]$ which are not in $I$ and mapping elements in $I$ to zero? Now since $R[x_1,\dots,x_n]$ is generated by $x_1,\dots,x_n$, $A$ will be generated by $f(x_1),\dots,f(x_n)$. I don't have an intuitive understanding of why this is true either.",['abstract-algebra']
630676,What's a matrix?,"What is a matrix exactly? What are matrices used for? I have read some of the Wikipedia article, but since my math knowledge is pretty basic, I didn't understand much. Could you explain to me in simple language what matrices are, and what they are used for? For example, I know what a rotation matrix is and what it's used for, but don't know why it's called a 'matrix'. For me it's just a formula ($x' = x\cos\theta - y\sin\theta$, $y' = x\sin\theta + y\cos\theta$), that I can use to get the new position of a point after a rotation. Don't know why it's called a matrix and what matrices are and do in general. Thanks",['matrices']
630682,How to calculate this triple summation?,"I need to calculate the following summation:
$$\sum_{j=1}^m\sum_{i=j}^m\sum_{k=j}^m\frac{{m\choose i}{{m-j}\choose{k-j}}}{k\choose j}r^{k-j+i}$$
I do not know if it is a well-known summation or not. (The special case when $r=1$ is also helpful.) Even a little simplification is good, unfortunately I cannot simplify it more than this! Edit: another way to write this summation is:
$$\sum_{j=1}^m\sum_{i=j}^m\sum_{k=j}^m\frac{{m\choose i}{{m}\choose{k}}}{j{k\choose j}}r^{k-j+i}$$
Anybody can help with this one?","['summation', 'algebra-precalculus', 'binomial-coefficients', 'combinatorics']"
630684,"How to find the integral: $ \int \frac{2x}{\sqrt {4x-1}}\, \mathrm{d}x\;?$","My problem, is how to find the integral of $$ \int \frac{2x}{\sqrt {4x-1}}\, \mathrm{d}x$$ Can I do this?
$$ \int \frac{\frac{1}{2}\cdot4x-1+1}{\sqrt {4x-1}}\, \mathrm{d}x$$
$$ \frac{1}{2}\int \frac{4x-1+1}{\sqrt {4x-1}}\, \mathrm{d}x$$
$$ \frac{1}{2}\int \frac{4x-1}{\sqrt {4x-1}}+\frac{1}{\sqrt {4x-1}}\, \mathrm{d}x$$
$$ \frac{1}{2}\int \sqrt {4x-1}+\frac{1}{\sqrt {4x-1}}\, \mathrm{d}x$$
then
$$ 4x-1= u/'$$
$$ 4dx= du$$
$$ dx= \frac{1}{4}du$$
insert that in the integral
$$ \frac{1}{2}\int \sqrt {u}+\frac{1}{\sqrt {u}}\cdot\frac{1}{4}\, \mathrm{d}u$$
$$ \frac{1}{8}\int \sqrt {u}+\frac{1}{\sqrt {u}}\, \mathrm{d}u$$ and I get
$$\frac{1}{12}\cdot u\cdot \sqrt{u}+ \frac{1}{4}\cdot \sqrt{u}+C$$
$$\frac{1}{12}\cdot(4x-1)\cdot \sqrt{4x-1}+ \frac{1}{4}\cdot \sqrt{4x-1}+C$$ and that's the correct solution. But can I just rewrite $2x$ as $\frac{1}{2}\cdot4x-1+1$ and then put $\frac{1}{2}$ before the integral? Thank you in advance!","['calculus', 'integration']"
630725,how to prove $\tan A+\sec A=\frac{1}{(\sec A-\tan A)}$?,"how to prove $\tan A+\sec A=\frac{1}{(\sec A-\tan A)}$ ? I already tried:
$$\begin{align}
\sin A/\cos A+1/\cos A&=1/(\sec A-\tan A)\\
\sin A+1/\cos A&=1/(\sec A-\tan A)\\
\end{align}$$",['trigonometry']
630742,What's the explanation for why n^2+1 is never divisible by 3?,"What's the explanation for why $n^2+1$ is never divisible by $3$? There are proofs on this site, but they are either wrong or overcomplicated. It can be proved very easily by imagining 3 consecutive numbers, $n-1$, $n$, and $n+1$. We know that exactly one of these numbers must be divisible by 3. 
$$(n-1)(n)(n+1)=(n)(n-1)(n+1)=(n)(n^2-1)$$ Since one of those first numbers had to have been divisible by $3$, this new product $(n)(n^2-1)$ must also be divisible by $3$. That means that either $n$ (and by extension $n^2$) or $n^2-1$ is divisible by $3$. If one of those has to be divisible by $3$, then $n^2+1$ cannot be. So it is definitely true. My question is why is this true, what is inherent about $1$ more than a square number that makes it not divisible by $3$? Another way of saying this might be to explain it to me as if I don't know algebra.",['number-theory']
630760,Smallest topology containing a family of other topologies on a set $X$,"Let $T_a$ be a family of topologies on a set $X$. What is the smallest topology containing all the $T_a$? Obviously, the smallest it could be is the union of all the $T_a$, but that's not always a topology. So is it just the topology generated by the subbasis $\bigcup T_a$? I feel like this is too simple of an answer, since the question is phrased asking to prove that there is a unique smallest topology containing all the $T_a$. (I'm working through Munkres' Topology on my own.)",['general-topology']
630791,How to rewrite $7-\sqrt 5$ in root form without a minus sign?,"How to rewrite $7-\sqrt 5$ in root form without a minus sign ? 
For clarity ""root form "" means an expression that only contains a finite amount of positive integers , additions , substractions , multiplications and root extractions (sqrt, cuberoot etc). For example some quintic equations cannot be solved in root form. A "" root form without a minus sign "" means an expression that only contains a finite amount of positive integers , additions , multiplications and root extractions (sqrt , cuberoot etc). So the solution could look something like this : $$ 7-\sqrt5 = \sqrt{...+1+(...)^{\frac{2}{3}}}+\sqrt{...+2(...)^{\frac{1}{3}}}$$ How to solve such problems ? EDIT Warning : $\dfrac{44}{7+\sqrt 5}$ is not a solution , since no divisions are allowed! I got that answer 3 times now so I put it in the OP as a warning , not just the comments.","['radicals', 'abstract-algebra', 'polynomials']"
630796,Evaluate $ \sum_{n=1}^{\infty} \frac{\sin \ n}{ n } $ using the fourier series,"I am a beginner with Fourier series and I have to evaluate the sum $$\sum_{n  =1}^{\infty}{\sin\left(n\right) \over n}$$ I don't know which function I have to take to evaluate the fourier series ...
Someone can give me a hint ? Thanks in advance!","['fourier-series', 'sequences-and-series']"
630809,What we're never taught explicitly,"I would like to make a complaint really. School math(s) can be the most boring way to learn: sitting down and rote learning binomial expansion or the volume of a cylinder is just not interesting. It seems that schools don't teach the interesting way, with plenty of variety and proof. I have some very basic facts that students are never taught explicitly, perhaps because of the rigidity of education. Instead, teachers seem to count on a mistake being made. My specific example is the fact that ab is not equal to a*b , but (a*b). We are all taught of the order of operations, however the rule stating that ab can be expressed as (or is shorthand for) a*b , is wrong. I was pulled up when I tried to solve a linear-style expression like 20/2a=4 like a smart-alec by first assuming that this is equal to 20/2*a=4 . This is wrong, right? Apparently, terms are always in their own little group, and this effects the order of operations. 20/2a=4 is the same as 10/(2*a)=4 . The mistake would not have been made by using TeX style, maths notation. My questions are: Am I correct in saying ab = (a*b) ? Why are these things generally overlooked? Are there any other typical errors involving the order of operations, especially when using linear notation? Are these things simplified by teachers as to avoid bombarding the students with 'special cases'?","['notation', 'binary-operations', 'education', 'algebra-precalculus']"
630836,How is called the class of functions whose inverse function is a polynomial?,How is called the class of functions whose inverse function is a polynomial? Is there any study of such functions?,"['functions', 'polynomials']"
630838,Complex and Kähler-manifolds,"I was woundering if anyone knows any good references about Kähler and complex manifolds? I'm studying supergravity theories and for the simpelest N=1 supergravity we'll get these. Now in the course-notes the're quite short about these complex manifolds. I was hoping someone of you guys might know a good (quite complete book) about the subject ? edit I've also posted this on the physics stackexchange -site, hoping that maybe a string-theorist of supergravity-specialist might be able to provide some information. But from what I'm seeing in the posts here the answers are already very nice! A big thanks in advance, I'll be going trough the sources somwhere in the end of this week or the beginning of next week somewhere!","['complex-manifolds', 'differential-geometry', 'kahler-manifolds', 'string-theory', 'reference-request']"
630872,Christoffel Symbols and the change of transformation law.,"I have seen it written that the change of co-ordinate form is given by the following: $$ \tilde \Gamma^{i}_{jk} = {\partial \tilde x^i \over \partial x^\alpha} \left [ \Gamma^\alpha_{\beta \gamma}{\partial x^\beta \over \partial \tilde x^i}{\partial x^\gamma \over \partial \tilde x^k} + {\partial ^2 x^\alpha \over \partial \tilde x^j \partial \tilde x^k} \right ]$$ I am at a loose end as to how to prove this though. I have seen a proof(which I have included below) but in particular I do not understand the second step. 
If someone could explain this second step, I would be very grateful! Note : I would only like to see a proof involving co-ordinates. If you prove another way, please be sure to include some detail, as I will most likely be unfamiliar with it! Thanks!","['tensors', 'differential-geometry']"
630890,Does $\sum _{n=1}^{\infty } \frac{\sin(\text{ln}(n))}{n}$ converge?,"Does $\sum _{n=1}^{\infty } \dfrac{\sin(\text{ln}(n))}{n}$ converge? My hypothesis is that it doesn't , but I don't know how to prove it. $ζ(1+i)$ does not converge but it doesn't solve problem here.","['sequences-and-series', 'riemann-zeta']"
630896,Are cosets groups?,"I ran into this question when reading Artin's Algebra book and tried to google the answer but seems it's too easy that I didn't get any. My answer is: Not necessarily. Proof: From the definition of a left coset: $aH=\{ah\ |\ h\in H\}$, where $H$ is a subgroup of $G$, and $a\in G$. If we want $aH$ to be a group, it has to be a closure: $ah_{1}ah_{2}\in aH$, thus $h_{1}ah_{2}\in H$. And since $a\in G$ according to the assumption, $h_{1}ah_{2}\notin H$. So cosets are not necessarily groups. Am I correct? Thanks.","['group-theory', 'abstract-algebra']"
630909,Calculate adjusted / reciprocal values from a sequence of numbers,"tl;dr (summary) I'm a beginner in mathematics. My question is: is there a formula to calculate the right column in the following table based on the values of the left column? $$
\begin{array}{|c|c|}
\hline {\rm AwardedCount} & {\rm CalculatedScore} & {\rm ExpectedScore} \\
\hline 1303591 & 10 & 10 \\
\hline 108023 & 186 & 125 \\
\hline other data & … & … \\
\hline 12114 & 339 & 250 \\
\hline 20 & 790 & 500 \\
\hline 1 & 1000 & 1000 \\
\hline \end{array}
$$ Note that they are only examples of expected values, I just want to show the distribution I want at the end. The ExpectedScore value should be: $ExpectedScore = [10, 1000]$ The middle column show the score I was able to calculate. The formula I currently use is (thanks to MPW and Brian Rushton ): $$
CalculatedScore = \Big(\big(1 - \log(AwardedCount; MaxAwardedCount)\big) \times 990 \Big) + 10
$$ The $log()$ function use two arguments, the first is the input value and the second is the base, hereby MaxAwardedCount . This formula is what I was looking for, but I keep this question opened just in case someone have a simpler idea. Original question with details (Adjust scores based on rarity) I'm working on a personal project which involves calculating scores based on badges earned on StackExchange badges. I want to calculate a score from 1 to 1000 based on the rarity of a badge. A badge awarded to a few users (eg. only one user) should have a score of 1000. A badge awarded to a numerous users should have a lower score (always greater or equal to 1). Let's take some examples: The most awarded badge is Popular question , earned 1303591 times, let's call it MaxAwardedCount One of the least awarded badge is castle-activerecord , earned only once Another badge Famous Question was awarded 108023 times, let's call it AwardedCount The Favorite Question badge was awarded 12114 times Current method My formula is : $$
Score = \frac{\frac{MaxAwardedCount}{AwardedCount}}{MaxAwardedCount} \times 1000 = \frac{1000}{AwardedCount}
$$ The value is then rounded to the superior integer value. Results The Famous Question badge, most earned (108023 times): $\frac{1000}{108023} = 0.009257 \approx 1$ A rare badge, awarded only 20 times: $\frac{1000}{20} = 50$ A rare badge, awarded only twice: $\frac{1000}{2} = 500$ A rarest badge, awarded only once: $\frac{1000}{1} = 1000$ Expectation The problem is that it gives significant scores only to rare badges. Is it possible to find a formula which will give bigger scores even to more common badges? Plus, a badge earned 10 times on sites A and B is more valuable on site A if A have more users than B (it is less frequent on A than on B). So the score has to been adjusted depending on the MaxAwardedCount value for each site. To go further, would it be interesting to calculate the mean of the award count of each badge in order to give a score of about 500 to the badge which are never rare nor frequent? Since I got all the data from StackOverflow badges, I have calculated that the average of AwardedCount is 2451.6115. Is it possible to give an arbitrary score of 500 to this badge, then calculate the score of all the other badges? I don't know much about mathematics so please use only simple words.",['algebra-precalculus']
630918,Digits of $\pi$ forming primes?,"Let $f(n)$ be the first $n$ digits of $\pi$ . How many times is $f(n)$ prime on the interval $[1, k]$ ? Are there infinitely many prime $f(n)$'s on $[1, \infty)$? I know this is probably be a very hard question and most likely an open problem, but I am just curious.","['prime-numbers', 'number-theory']"
630931,"For which $n$ is it ""feasible"" to classify groups of order $n$?","Classifying groups of small order is a standard exercise in group theory classes, and especially after learning the Sylow Theorems and Direct/Semidirect products, it is possible to classify groups of a relatively large order (i.e., $>100$). For example, in the section on semidirect products, Dummit and Foote have a handful of multipart exercises where you are asked to classify groups of orders which have ~$15$ isomorphism types each. On the other hand, they never (as far as I can tell in what I have read) completely classify groups of order $16=2^4$ (although I think they mention almost all of them at various points). Of course, groups of order $2^n$ are notoriously hard to classify (the most comprehensible article doing so for $n=16$ that I have read was $12$ pages long). If we only look at odd order groups, does classifying all odd groups, say, with order below $100$, become feasible? And how many powers of $2$ are needed to make a classification too tedious? $2^4$ by itself is already rather tedious, so I guess $4$ would have to be the smallest power dividing the order? Edit: Does anyone know of some nice group orders, where classifying all groups of that order is nontrivial, but isn't too difficult and gives some interesting groups?",['group-theory']
630942,Necessary condition for have same rank,"Let $P,Q$ real $n\times n$ matrices  such that $P^2=P$ , $Q^2=Q$ and $I-P-Q$ is an invertible matrix. Prove that $P$ and $Q$ have the same rank. Some help with this please , happy year and thanks.","['vector-spaces', 'matrices', 'linear-algebra', 'algebra-precalculus']"
630950,Gorenstein ring VS. Gorenstein singularity,"A normal variety is said to have Gorenstein singularity iff its canonical divisor is a Cartier divisor (one can always define the canonical divisor on a normal variety and it can be proved to be a Weil divisor). What is the relation between Gorenstein singularity and Gorenstein ring? More precisely, is it true that a normal variety has Gorenstein singularity iff the local ring of its structure sheaf at any point is Gorenstein? One can assume the normal variety is moreover Cohen-Macaulay if that helps.","['gorenstein', 'commutative-algebra', 'algebraic-geometry', 'cohen-macaulay']"
630966,Why study metric spaces?,"Most universities have a 3rd year undergraduate analysis course in which metric spaces are studied in depth (compactness, completeness, connectedness, etc...). However, in practice it seems that most of these metric spaces are normed vector spaces. Why not just cover normed vector spaces instead of metric spaces? Even if we lose some generality, normed vector spaces feel more natural and interesting, in my opinion, at least.","['education', 'metric-spaces', 'real-analysis']"
631025,Viewing Laurent polynomials as a localization of $R[X]$?,"I believe that the Laurent polynomials over a ring $R$ are simply the localization of $R[X]$ at $S=\{X^n:n\geq 0\}$. However, I've always thought as Laurent polynomials as like ""polynomials"" in that they form a ring with specified addition and multiplication operations, not as equivalence classes in $S^{-1}R$. If you're coming at this from these two different viewpoints, what would it mean that the Laurent polynomials are the localization of $R[X]$ at $S$? Would that essentially mean that there is a ring isomorphism between then identifying an equivalence class with a Laurent polynomial as follows?
$$
(\sum_{i=0}^m r_iX^i)/X^n\leftrightarrow \sum_{i=0}^m r_iX^{i-n}
$$ Is that what is formally meant?","['commutative-algebra', 'abstract-algebra']"
631029,Confusion over Directly Proving Surjectivity,"I have a question related to the surjectivity of a function. I understand what surjectivity is, in the sense that, if $f:X\longrightarrow Y$, then $f$ is surjective if $\forall_{y\in Y}\exists_{x\in X}f(x)=y$, or simpler (using the image) $f(X)=Y$. My troubles seem to lie in actually proving that either of these hold. For most proofs that I've seen on surjectivity, if the function has an inverse, then they use that and plug it back into the formula for the function to establish that the function is indeed a surjection. This usually goes as follows: Ex) For $f:\mathbb R\longrightarrow\mathbb R$, $f(x)=\frac{1}{2}x$, you find $x=2y$ for some $x\in\mathbb R$, and say $f(2y)=y$ completes the proof. I know that, algebraically, plugging in $2y$ into $f$ gives $y$, but I don't understand how showing $f(2y)=y$ completes the proof. Is it related to the fact that all real numbers can be described as 2 times another real number? Second, the above hinges on the fact that $f$ has an inverse. What if $f$ doesn't have an inverse? Ex) $f:\mathbb R \longrightarrow \mathbb R$, $f(x)=x^3-x$ does not have an inverse, but if you graph it, it clearly is onto. In both cases, the second definition provided above, $f(X)=Y$, is extremely easy to understand, but it feels useless - almost as if you know that the image of the domain is equal to the codomain, then you wouldn't need to prove it's onto in the first place. Any suggestions or help in understanding this would be much appreciated. If it helps, I'll mention that I don't seem to have any problem proving whether a function is injective, or not.","['discrete-mathematics', 'functions']"
631042,Direct proof of empty set being subset of every set,"Recently I finished my first pure mathematics course but with some intrigue about some proofs of definitions by contradiction and contrapositive but not direct proofs (the existence of infinite primes for example), I think most of them because the direct proof extends away from a first mathematics course or the proofs by contradiction/contrapositive are more didactic. The one that most bothers me in particular is the demonstration that the empty set is a subset of every set, and it is unique. I understand the uniqueness and understand the proof by contradiction: ""Suppose $\emptyset \subsetneq A$ where $A$ is a set. So it exists an element $x \in \emptyset$ such that $x \notin A$ wich is absurd because $\emptyset$ does not have any elements by definition."" but I would like to know if there exists a direct proof of this and if indeed extends from a first course. Thanks beforehand.",['elementary-set-theory']
631053,Probability question - how many cycles before all items are chosen,"I have a container of 100 yellow items. I choose 2 at random and paint each of them blue. I return the items to the container. If I repeat this process, on average how many cycles will I make before all 100 items are painted? It is obviously 50 (100/2) if there is no replacement. But in this case, the items are returned to the container, so the same item could be chosen often. What if we choose 3?","['probability', 'combinatorics']"
631075,How to derive thresholds from a pooled sample of values,"Question: The context of this question is actually finance, however the question itself is a statistical issue. Suppose I have the following expression: $$\rho = \frac{2\bar{x}}{(s^*_x)^2}+1  \ \ \ \ \ ... (1)$$ where $\bar{x} = \frac{1}{T} \sum_{t=1}^{T} x_t$ $(s^*_x)^2 = \frac{1}{T} \sum_{t=1}^T (x_t - \bar{x})^2$ Assume $T$ is some fixed constant. Note: $T$ is just the total number of observations of $x_t$. I have data on $x_t$ for each 'entity' (here an entity just simply refers to a firm/company). In total, I have 2228 entities and for each entity I have $T$ observations of $x_t$. Note there are no distributional assumptions on $x_t$, so one can make any reasonable assumptions in order to solve the problem that I mention further below. For each entity, I substitute the $T$ observations of $x_t$ into Eqn. $(1)$ and obtain a value for $\rho$. Thus in total, I have 2228 values of $\rho$. Now, a large value of $\rho$ means the entity is ""bad"" and a small value of $\rho$ means the entity is ""good"". However, the problem is how large does a value of $\rho$ have to be in order to classify an entity as ""bad""? That is, what is the threshold such that if $\rho$ exceeds the threshold value, then we can classify the entity as ""bad""? For example, let's say the threshold is $400$, if entity A had a $\rho = 300$ while entity B had a $\rho = 1000$, then entity A is ""good"" while entity B is ""bad"". My attempts so far: My first attempt was to try get data on an entity that is known to be ""bad"" and then calculate its $\rho$ and use this value as the threshold. The problem is that I cannot obtain data on ""bad"" entities. For my next attempt, I obtained the empirical distribution by applying a kernel density estimator on the 2228 values of $\rho$. Then I calculate the 99th percentile (for robustness, I also calculated the 97.5th and 95th percentile) of this pooled distribution and use this value as the threshold. However, the main critique is that this is too arbitrary and there is not enough rationale for using this method. Queries: So I am wondering if anyone has any ideas on how what statistical/mathematical techniques/methods I can apply to derive appropriate thresholds for $\rho$. Currently, I really have no idea on what tools are available for this problem. EDIT 1 This edit is in response to some of the comments below. I am ready (and quite confidently) to assume $\rho$ measures the ""goodness"" of a company. Actually I am dealing within the hedge funds industry and it is a very opaque industry. It can be shown through an arbitrage argument that $\rho$ outperforms many other standard measures of performance such as the Sharpe ratio, Sortino ratio, Jensen's alpha etc. In this sense, $\rho$ doesn't necessarily play a causal role, i.e., it is not actually concerned with deciding which hedge funds are ""bad"" or ""good"", it is in fact a measure of performance that is shown to be highly resistant to hedge fund's manipulation of their returns. It can be shown that if $\rho$ is high, then it most likely means the fund is manipulating their returns, hence the label ""bad"", whereas if $\rho$ is low, then it most likely means the fund is not manipulating their returns, hence the label ""good"". As a consequence, I do not actually know which hedge funds are actually ""good"" or ""bad"" in my sample. I simply know the $\rho$ values of each fund, hence the need for some cut-off point that determines whether the $\rho$ values are too big 'relative' to the rest of the sample. I am not sure if the following information will help, but it can be shown (through the use of Central Limit Theorem/Slutsky's Theorem) that if we assume $x_t$ to be a weakly stationary process with mean $\mu_x$ and variance $\sigma_x^2$, then the asymptotic distribution of $\rho$ for a single fund is given by:
\begin{align*}
\rho \stackrel{asymp}{\sim} N\left(1+ \frac {2\mu_x}{\sigma^2_x}, \frac 4{\sigma^2_xT}\right)
\end{align*} However, this is only the $\rho$ value for one particular fund, I am not sure how it is of any use to determining some sort of threshold for the entire sample. Is there some sort of statistical framework/technique which we can apply here to deduce some sort of threshold? Additional assumptions are not a problem, I am just curious if we can get some sort of threshold first. Thank you all for the inputs so far, I highly appreciate them. EDIT 2: In response to Eupraxis1981 I ran MLE on the original log-likelihood (before the edit) which was $$\max\limits_{\mu,\sigma^2}\mathcal{L}(\hat{\dot\rho},s^{*2};\mu,\sigma^2) = -\frac{N\ln(2\pi)}{2}-\sum\limits_{i=1}^N \{\frac{1}{2}\ln(\sigma^2+\frac{4}{s^{*2}_iT})+\frac{1}{2(\sigma^2+\frac{4}{s^{*2}_iT})} (\hat{\dot\rho}_i-\mu)^2\}$$ and got some very sensible results for the estimates of $\mu$ and $\sigma^2$. However, I am not quite sure how you arrived at the modified log likelihood currently shown, could you outline how you derived it? More specifically, how did $\dot\rho_i$ get introduced into the log-likehood? Also, what values do I use for $\dot\rho_i$? For $\hat{\dot\rho} = \{\hat{\dot\rho}_1,\hat{\dot\rho}_2....\hat{\dot\rho}_N\}$, I use the values derived from equation (1), that is, for each investment, I calculate $\displaystyle \frac{2\bar{x}}{(s^*_x)^2}+1$ using the returns of that particular investment. But what would I use for $\dot\rho_i$?","['statistics', 'mathematical-modeling']"
631099,How find this sequence $\{x_{n}\}$ such $\lim_{n\to \infty}x_{n}\left(1-\frac{n(1-na_{n})}{\ln{n}}\right)=1$,"Consider the sequence $\{a_{n}\}$ satisfying $a_{1}\in(0,1)$,such
$$a_{n+1}=a_{n}(1-a_{n})$$
question: Find a sequence $\{x_{n}\}$ such that
$$\lim_{n\to \infty}x_{n}\left(1-\dfrac{n(1-na_{n})}{\ln{n}}\right)=1$$ I have prove this
$$\lim_{n\to \infty}\dfrac{n}{\ln{n}}(1-na_{n})=1$$
But I can't find this $x_{n}$  Thank you such as: How prove this $\displaystyle\lim_{n\to \infty}\frac{n}{\ln{(\ln{n}})}\left(1-a_{n}-\frac{n}{\ln{n}}\right)=-1$","['sequences-and-series', 'limits']"
631106,"Visual Group Theory's Intuitive Proof - Cayley's Theorem - Nathan Carter pp. 85, Theorem 5.1","Theorem 5.1. Cayley's Theorem: Every group is isomorphic to a collection of permutations. Figure 5.31. A multiplication table for the group $V_4$, with nodes numbered 1 through 4 to facilitate analyzing how the arrows permute the elements. The permutation for each arrow color is shown on the right. Figure 5.32. A multiplication table made up of the permutations created in Figure 5.31. Each cell highlights the destination to which the permutation sends 1, using the corresponding color from Figure 5.31, emphasizing what the colors of the arrows already showed: The two tables contain the same pattern. This proof can be summarized as two steps: Create a permutation for each column in
a group’s multiplication table, and then inspect how those permutations treat the group’s
identity element. Figure 5.32 illustrates these two steps. It shows a multiplication table
comprised of the permutations from Figure 5.31, and each cell of the table highlights the
result of applying the permutation to the identity element 1. The correspondence between
Figures 5.31 and 5.32 is clear: If I remove all but the highlighted elements from Figure
5.32, all that remains is the multiplication table from Figure 5.31. This proof is more casual but I want to understand this before Fraleigh. The aim is to prove a multiplication table made out of the permutations of any group behaves the same as the mutliplication table of any group. viz. $p_i \cdot p_j = p_k \iff i \cdot j = k.$ For some reason, I understand figures 5.31 and 5.32 but I'm still unconvinced. (1.) I think I understand the first three paragraphs. I'm confounded by the last two. Why does the proof only ""consider how the permutations treat the identity element from the original group""? What about the other elements mapped by the permutations? (2.) The proof says applying to $p_k$ to $1$ means multiplying $1$ by $k$. Is this because the permutation for column $k$ maps $1$ to $k$? I can see this is true for $V_4$ in Figure 5.32. $V_4$ was defined to have this property. However, how's it true in general? We don't know what the permutation $p_k$ is? (3.) Same question as (2.) for $p_i \cdot p_j$. (4.) I don't fully know why I'm unsettled hence what other things am I missing?","['visualization', 'intuition', 'group-theory', 'proof-verification']"
631110,Lim inf with norm and weak convergence,The following is an real analysis qualifying exam problem that I cannot solve: Suppose $X$ is a Banach space and that $(x_n)$ converges weakly to $x$. Show that $\liminf ||x_n|| \geq ||x||$. Using the Uniform Boundedness Principle I can show that $\sup_{n \in \mathbb{N}} ||x_n -x||$ is finite. Using Alaoglu's Theorem I can show that some subset of $(x_n)$ converges in norm to $x$. I feel like I am close with this but cannot seem to finish the problem.,"['functional-analysis', 'real-analysis']"
631117,Evaluate the limit $\lim_{x\to 0} \frac{(\tan(x+\pi/4))^{1/3}-1}{\sin(2x)}$,"Evaluate the limit
$$\lim_{x\to 0} \frac{(\tan(x+\pi/4))^{1/3}-1}{\sin(2x)}$$
I know the limit is $1\over3$ by looking at the graph of the function, but how can I algebraically show that that is the limit. using this limit: $$\lim_{x \rightarrow 0} \frac{(1+x)^c -1}{x} =c$$? (without L'Hopital Rule)","['calculus', 'limits']"
631138,How to compute the integral $\int_0^\infty\frac{x}{e^x+1}dx$ using the Residue theorem.,"How to compute the integral $\int_0^\infty\frac{x}{e^x+1}dx$ using the Residue theorem, just as the title says. I have used rectangles, circles to do, but without any progress. By changing variable $y=e^x$, we get $\int_1^\infty \frac{\ln y}{y(y+1)}dy$. I still have no idea.","['residue-calculus', 'integration', 'complex-analysis', 'contour-integration']"
631159,Locally constant sheaves over an irreducible space is constant.,"In Hartshorne's  Algebraic Geometry Chapter II Proposition 6.15: If $X$ is an integral scheme, the homomorphism $CaCl X \rightarrow Pic X$ is an isomorphism. In the proof he wants to prove that $\mathcal L \otimes \mathcal K= \mathcal K$. It is clear that on an open cover $\{U_i\}$ $(\mathcal L \otimes \mathcal K)|_{U_i}\cong \mathcal K$. From this he concludes that $\mathcal L \otimes \mathcal K \cong \mathcal K$, which follows from a general fact that if ""$X$ is irreducible, a sheaf whose restriction to each open set of a covering of $X$ is constant, (*) to  is in fact a constant sheaf"". Can someone please give a  proof of the above fact that locally constant sheaves over an irreducible space is actually constant . I guess Harthsorne wants to say that it is isomorphic to a constant sheaf.","['sheaf-theory', 'algebraic-geometry']"
631163,How to combat memorization [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 5 years ago . Improve this question As a student in high school, I never bothered to memorize equations or methods of solving, rather I would try to identify the logic behind the operations and apply them. However, now that I've begun to teach Algebra in high school, I find it rather frustrating when students either a) memorize methods of solving the textbook problems or b) look for a general formula/method to ""just plug in to"" I've tried to throw them curveballs as my old Algebra teacher did, but usually they just dismiss it as ""a weird problem"" and continue using whatever method they have been. My objection to A is that it often impedes actual learning. Upon seeing a chunk of 6 similar problems in the textbook, many students just apply the same steps to every problem in the section (and usually get quite a couple wrong). My objection to B is that from my experience, students who flat out memorize equations (like $x=\frac{-b \pm \sqrt{b^2-4ac}}{2a}$ for quadratic equations) often fail to extend the same logic (completing the square/simplification) when faced with different but similar problems. They also frequently misapply the ""magic formulas"" they were taught before (i.e. solving simple quartics $ax^4+bx^2+c$ with the quadratic formula) and needing plenty of prompting after the suggestion of substituting $x^2$. This is the problem identified in this question and in particular the issue raised in this comment .","['education', 'algebra-precalculus', 'soft-question']"
631182,How to prove that $n\sum\limits_{d\mid n}\frac{|\mu(d)|}{d}=\sum\limits_{d^2\mid n}\mu(d)\sigma\left(\frac{n}{d^2}\right)$?,"This is problem 11 part b in chapter 3 of Tom M. Apostol's ""Introduction to Analytic Number Theory"". A variation on Euler's totient function is defined as
$$\varphi_1(n) = n \sum_{d \mid n} \frac{|\mu(d)|}{d}$$
The question asks to show that
$$\varphi_1(n) = \sum_{d^2 \mid n} \mu(d) \sigma\left( \frac{n}{d^2} \right)$$
My attempt so far: I have proved in part (a) of the same question that
$$\varphi_1(n) = n \prod_{p \mid n}\left(1 + \frac{1}{p} \right)$$
And so in an attempt to equate these two expressions I write
\begin{eqnarray}
\varphi_1(n) &=& n \prod_{p \mid n}\frac{p + 1}{p} \\
&=& n \left(\prod_{\substack{p \mid n \\ p^2 \mid n}}\frac{p + 1}{p}\right)\left(\prod_{\substack{p \mid n \\ p^2 \nmid n}}\frac{p + 1}{p}\right)
\end{eqnarray}
Let $s = \prod_{\substack{p \mid n \\ p^2 \mid n}} p$ and $r = \prod_{\substack{p \mid n \\ p^2 \nmid n}} p$. Then
\begin{eqnarray}
\varphi_1(n) &=& n \frac{\sigma(s)}{s} \frac{\sigma(r)}{r} \\
&=& \sigma(s) \sigma(r) \frac{n}{sr}
\end{eqnarray}
Using $N = \mu * \sigma$ where $*$ is the Dirichlet convolution and $N(n) = n$ we obtain
\begin{eqnarray}
\varphi_1(n) &=& \sigma(s) \sigma(r) \sum_{d \mid \frac{n}{sr}}\mu(d) \sigma\left( \frac{n}{srd} \right)
\end{eqnarray}
Because $(r, \frac{n}{srd}) = 1$ we can simplify the expression:
\begin{eqnarray}
\varphi_1(n) &=& \sigma(s) \sum_{d \mid \frac{n}{sr}}\mu(d) \sigma\left( \frac{n}{sd} \right)
\end{eqnarray}
We know that $\frac{n}{r}$ is square, and that all $d$ that contribute (a non zero value) to the above sum are squarefree, because otherwise $\mu(d) = 0$, and so the sum over $d$ such that $d \mid \frac{n}{sr}$ is the same as the sum over $d$ such that $d^2 \mid n$. This brings us to where I am stuck:
\begin{eqnarray}
\varphi_1(n) &=& \sigma(s) \sum_{d^2 \mid n}\mu(d) \sigma\left( \frac{n}{sd} \right)
\end{eqnarray}
I cannot see how to proceed from here. Hints or answers for how to proceed from where I currently am, or how to show what is required using a different approach would be appreciated.","['number-theory', 'analytic-number-theory', 'mobius-function', 'summation', 'arithmetic-functions']"
631205,Is it possible to prove that $\lim_{x\to 0} {ln(x)x} = 0$ without L'Hospital's rule? [duplicate],"This question already has answers here : $\lim_{x\to0^{+}} x \ln x$ without l'Hopital's rule (2 answers) Closed 10 years ago . Could somebody give me the answer:
Is it possible to prove that $\lim_{x\to 0} {\ln(x)x} = 0$ without L'Hospital's rule?","['calculus', 'limits']"
631221,Inequalities for the tail of the normal distribution (Halfin-Whitt paper),"I am reading the famous paper by Halfin and Whitt, [1]. I'd like to prove remark (1) on page 575. The authors state \begin{align}
\frac{\beta \alpha}{(1-\alpha)} = \frac{\phi(\beta)}{\Phi(\beta)} \Rightarrow \alpha = \frac{\phi(\beta)}{\beta \Phi(\beta) + \phi(\beta)},
\end{align} where $\phi(x)$ is the standard normal pdf and $\Phi(x)$ the standard normal cdf. The authors want to have bounds on $\alpha$, stating \begin{align}
1 - \Phi(\beta) \le  \alpha \le \frac{1-\Phi(\beta)}{1-\beta^{-2}\Phi(\beta)}, \quad \beta \ge 1. \qquad \qquad (1)
\end{align} The authors state that they use (1.8) on page 175 of Feller [2]. This equation reads \begin{align}
(x^{-1} - x^{-3})\phi(x) < 1 - \Phi(x) < x^{-1} \phi(x), \quad x > 0.
\end{align} By manipulating this equation I obtain \begin{align}
\frac{\phi(\beta)}{\beta^{-2}\phi(\beta) + \beta} < \alpha < \beta^{-1} \phi(\beta), \quad \beta > 0. \qquad \quad \quad (2)
\end{align} Both bounds $(1)$ and $(2)$ are indeed valid for their respective domains. Clearly, the difference for these bounds has to do with the fact that $\beta \ge 1$ in the first, and $\beta > 0$ in the second. I do not know how to obtain $(1)$, does anyone else have an idea? [1] S. Halfin, and W. Whitt, Heavy-traffic limits for queues with many exponential servers. PDF [2] W. Feller, An introduction to probability theory and its applications, Vol. I, Ed. 3.","['distribution-tails', 'statistics', 'queueing-theory', 'probability-theory', 'normal-distribution']"
631230,Confusion with the definition of mean value,"For some reason the formula for mean started to trouble me: $$\mu  = \frac{1}{b-a}\int_a^b f(x)\:dx$$ The reason this confuses me a bit is because when I read this formula I read it as: $\text{Mean} = \frac{\text{Area}}{\text{Length}}$. I've used to the idea that mean is the average value of a set of numbers e.g. $\frac{1+2+3+4+5}{5} = 3$. Should I interpret this value as the average area under a curve or as the average value of a set function values? Picture will point out my question: Hope I made my question clear :) Does mean value always equal $\text{Mean} = \frac{\text{Area (or volume)}}{\text{Length}}$. The definition confuses me because the integral doesn't equal the sum of function values $f(x)$, it is the area under the curve . This might be a very simple question but nonetheless confused me x)","['average', 'calculus']"
631280,"Embedding 2nd countable, zero-dimensional Hausdorff space in the Cantor space","The Cantor Space $2^{\mathbb N}$ is the space of all infinite $0$-$1$-sequences with the metric $d(x,y) = 0$ for $x=y$ or $d(x,y) = 1/k$ where $k$ is the least integer such that $x_k \ne y_k$. Now I read the following proof: Every second-countable Hausdorff zero-dimensional space $X$ with clopen $\{ B_i \}_{i \in \mathbb N}$ could be embedded into Cantor space via the map $f : X \to 2^{\mathbb N}$ where each $f(x)$ is the characteristic function of the set $\{ i \in \mathbb N : x \in B_i \}$, i.e. $f(x)(i) = 1$ iff $x \in B_i$. Then $d(f(x), f(y))$ gives a metric for $X$. But where do I need that $X$ is zero-dimensional. As I see it the condition secound-countable and Hausdorff are enough, the first ensures that we can asscociate to each $x \in X$ a subset of $\mathbb N$, the Hausdorff condition ensures that the map is an injection (actually I think $T_1$ would also be enough to assume here). That it is a metric is also clear. But I do not see where zero-dimensionality is used?","['general-topology', 'descriptive-set-theory', 'analysis']"
631282,Cox rings of toric varieties,"Let $X$ be a projective toric variety over a field $k$.  Is it true that the Cox ring of $X$ is the polynomial ring over the Picard group of $X$?  If not, what is the significance of the Picard group of a toric variety in terms of its Cox ring?","['commutative-algebra', 'algebraic-geometry']"
631300,Trying to understanding the proof of the fact that Kazhdan property (T) implies expanders.,"I am trying to trying to understanding the proof of the fact that Kazhdan property (T) implies expanders. This is a result of Grigory Margulis. It is stated in Proposition 3.3.1 on Page 30 of the book discrete groups, expander graphs, and invariant measures of Alexander Lubotzky. Let $H=L^2(\Gamma/ N)$. Here $\Gamma$ is a finitely generated Kazhdan group $N$ is a finite index normal subgroup of $\Gamma$. Let $V = \Gamma/ N$. $L^2(\Gamma/ N)$ is the set of functions $f$ such that $||f||^2 = \sum_{x \in V} |f(x)|^2 < \infty$. $\Gamma$ acts on $H$ by $(\gamma f)(x) = f(x\gamma), x \in V, \gamma \in \Gamma$. Let $H_0 = \{f \in H: \sum_{x\in V} f(x) = 0\}$. How to show that $H=H_0 \oplus \mathbb{C} \chi_V$ as a $\Gamma$-module? Why the action of $\Gamma$ on $V$ is transitive implies that the only $\Gamma$-invariant functions on $V$ are the constants $\mathbb{C} \chi_{V}$? Why then it follows that $H_0$ does not contain the trivial representation? Why $\Gamma$ is Kazhdan implies that $H_0$ does not have almost invariant functions? Thank you very much.","['discrete-mathematics', 'representation-theory', 'graph-theory', 'group-theory', 'combinatorics']"
631317,Baire Category Theorem proof in Gamelin Greene - how do they shrink the closure of open ball,"I am confused by a step in the Gamelin and Greene proof of the Baire Category Theorem. Here is the start of the proof. Theorem: Let $\{U_n\}_{n=1}^{\infty}$ be a sequence of dense open subsets of a complete metric space $X$.   Then $\cap_{n=1}^{\infty}U_n$ is also dense in $X$. Proof: Let $x \in X$ and let $\epsilon > 0$. It suffices to find $y \in B(x;\epsilon)$ that belongs to $\cap_{n=1}^{\infty} U_n$. Indeed, then every open ball in $X$ meets $\cap U_n$, so that $\cap U_n$ is dense in $X$. Since $U_1$ is dense in X, there exists $y_1 \in U_1$ such that $d(x,y_1) < \epsilon$. Since $U_1$ is open, there exists $r_1 > 0$ such that $B(y_1;r_1) \subset U_1$. ... so far so good, I get it this far. They continue... By shrinking $r_1$, we can arrange $r_1 < 1$, and $\overline{B(y_1;r_1)} \subset U_1 \cap B(x,\epsilon)$. This is where I am confused. I don't like this fuzzy use of ""shrink"" here but get what they mean I think.  I see that we could shrink $B(y_1;r_1)$ as they indicate but I don't see how  the closure $\overline{B(y_1;r_1)}$ can be shrunk. Could there be an unusual metric space where the open ball is dense in $X$ or something similar that we just cant think of offhand which would make this impossible? How can we be sure this is true in general in a rigorous way? Thanks for your help.","['general-topology', 'baire-category']"
631323,If every subspace of a vector space V is invariant under a linear transformation T then T is a scalar transformation,"I got the following problem Let $V$ be a vector space over field $\mathbb{F}$ and let $T:V \to V$ be a linear transformation such that every subspace of $V$ is invariant under $T$, Show that there exist a scalar $\alpha \in \mathbb{F}$ such that $T = \alpha I$ (meaning $T$ is a scalar transformation) I tried to show it but I got that the matrix for $T$ in some basis $B$ is a diagonal matrix where each entry on the main diagonal is some eigenvalue $\lambda _i$, How do I show that all the eigenvalues are equal to each other?","['vector-spaces', 'linear-algebra']"
631324,Find where line intersects sine function,"Here we have sin((x+1)*(pi/2)): Now let's say we have a point at (x=2, y=1)... And we draw a line to the origin (x=0, y=0)... If we create a point where the line intersects the sine function, we get a new point.
Is there a way to find out the (x,y) of this new point?",['trigonometry']
631337,"Non Existence of matrices $A,B\in M_n(\mathbb{R})$ such that $(I-(AB-BA))^n=0$","Question is to Prove: Non Existence of matrices $A,B\in M_n(\mathbb{R})$ such that $(I-(AB-BA))^n=0$. This question has already been asked already but then i am asking for clarification of another solution i have tried on my own. First of all $I-(AB-BA)=0$ does not have solution because of trace property. Now, I Would let $C=AB-BA$ and consider $(C-I)^n=0$ Now, Minimal polynomial of $C$ would be $(x-1)^m$ for some $m\leq n$ and $m\neq 1$ so I would consider jordan form for this... I would end up with the case that jordan form of $C$ (some of would be jordan blocks with entries in the diagonal $1$ and rest of the rows would just be )would be $$\begin{bmatrix}1&1&0&0&\cdots& 0\\ 0&1&1&0&\cdots& 0\\ 0&0&1&1&\cdots& 0\\ 0&0&0&1&\cdots& 0\\ -&-&-&-&-&-\\0&0&0&0&\cdots &
1\end{bmatrix}\\$$ So, Trace of Jordan form of $C$ would be $n$. thus for the same reason as why $AB-BA=I$ have no solution we now conlcude that : $(I-(AB-BA))^n=0$ is not satisfied by any matrices. I have used that Trace of $A$ would be same as Trace of $CAC^{-1}$ for any $C$. Not very sure if i can use this.. I would be thankful if some one can confirm if what i have done is sufficient/correct. Thank you.","['matrices', 'linear-algebra']"
631348,Proof of Raabe's test,"Let $\sum a_n$ be a series of non-negative terms and let $$L = \lim_{n\to\infty}n\left(1-\frac{a_{n+1}}{a_n}\right)$$
Prove that the series converges (resp. diverges) if $L > 1$ (resp. $L<1$). I've tried, for example, that when $L<1$, $$n\left(1-\frac{a_{n+1}}{a_n}-L\right)= \frac{n(a_n-a_{n+1}-La_n)}{a_n}\ge\frac{n(a_n-a_{n+1}-a_n)}{a_n}=\frac{-na_{n+1}}{a_n}$$ and then using epsilons and the sort, but I can't get anywhere. Any tips? P.S. using Kummer's test doesn't count","['sequences-and-series', 'calculus', 'limits']"
631355,Relationship between different topologies of bounded operators on a Hilbert space,"I am self-studying functional analysis. Given that $B(H)$ are the bounded operators on a Hilbert space, $H$. I would like to ask how to formally prove that the weak topology is weaker than the strong topology, the strong topology is weaker than the strong-* topology, the strong-$*$ topology is weaker than the norm-topology. We would also like to prove that ""weaker"" can be replaced by ""strictly weaker"" by providing sequences that converge in the weaker topology but not in a stronger topology. Finally, if the weak and norm topologies coincide does it imply $B(H)$ is finite dimensional ? My idea for a proof is as follows : We define a set of semi-norms for the different topologies and show that convergence in a stronger topology implies convergence in the weaker topologies. But I am unsure about how to prove strictly weaker. Also, I am being unable to form an intuitive picture of what it means for two topologies to coincide. Any help would appreciated and I would like to thank you for helping me.","['general-topology', 'hilbert-spaces', 'functional-analysis', 'operator-theory']"
631388,How to show that $\lim_{n\rightarrow \infty }{a_n}^{b_n}=\alpha ^\beta $?,"If $\lim_{n\rightarrow \infty }{a_n}=\alpha (\neq 0) $ and $\lim_{n\rightarrow \infty }{b_n}=\beta$, then $\lim_{n\rightarrow \infty }{a_n}^{b_n}=\alpha ^\beta $? I unconsciously used this but I realized I'd never seen this theorem before. Is it true?",['limits']
631409,Any ultrafilter over a finite set is principal,"Let $I$ be a finite set. Let $\mathcal{U}$ be an ultrafilter over $\mathcal{P}(I)$. I want to prove that $\mathcal{U}$ is principal. My work: let $\mathcal{U}=\{S_1,\ldots,S_k\}$. Since $\varnothing\notin\mathcal{U}$ and $S_i\cap S_j\in\mathcal{U}$ for every $i,j$, we have that $S_1\cap\ldots\cap S_k\neq\varnothing$. Let $a\in\displaystyle\bigcap_{1}^{k}S_j$. I claim that $\mathcal{U}=\mathcal{U}_a$, the principal ultrafilter generated by $a$, i.e. that $\mathcal{U}=\{S\mid a\in S\}$. Now, $\mathcal{U}\supseteq\{S\mid a\in S\}$ is obvious. By maximality of ultrafilters, i get $\mathcal{U}=\{S\mid a\in S\}$. Where is the error?","['filters', 'elementary-set-theory', 'proof-verification']"
631422,Is Euler's Introductio in analysin infinitorum suitable for studying analysis today?,"I've read the following quote on Wanner's Analysis by Its History : ... our students of mathematics would profit much more from a study of Euler's Introductio in analysin infinitorum , rather than of the available modern textbooks. (André Weil, 1979; quoted by J.D. Blanton, 1988, p. xii) I got the mentioned book (there is a translated version published by Springer ) and it seems a nice read. The translator mentions in the preface that the standard analysis courses puts low emphasis in the ordinary treatise of the elements of algebra and also that he fixes  this defect. My concern at the moment is that the book may be dated but André Weil said it's a worthy read, I'd like to know if someone already read Euler's book and some modern introduction to analysis to make a fair comparison. It's important to notice that although the book is a translation, the translator made some edits in several parts of the book, I guess that with the intention of making it a readable piece for today's needs.","['math-history', 'infinitesimals', 'reference-request', 'soft-question', 'analysis']"
631437,Measure minimization for a combination of overlapping sets,"This problem may have been worked out before but I don't know where to start looking so I hope one of you can help me.  The problem is as follows: There are $N$ variable-sized finite sets $\boldsymbol{X}_i$, $i=1..N$ containing integers. The sets may overlap i.e. an item $x_i \in \boldsymbol{X}_1$ may also occur in another set, i.e. $x_i \in \boldsymbol{X}_2$. There is a measure $m_i = \mathrm{cost}(\boldsymbol{X}_i)$ that can be calculated for each set $\boldsymbol{X}_i$ and for any union of sets, e.g. $\mathrm{cost}(\bigcup\limits_{i=1,2}\boldsymbol{X}_i)$. How to find the combination of (unions of) sets containing at least once all the items from the original sets $\boldsymbol{X}_i$, such that the sum of the resulting measures $m$ is minimized? The ""brute force"" approach would be to generate all possible combinations of unions of sets (do not unite any sets, unite all sets, or unite some sets), calculate the sum of the measures of these combinations and then select the combination yielding the lowest sum of measures. However, I'm sure this can be done more elegantly. Can someone point me in the right direction?","['optimization', 'combinatorics']"
631442,"Integrate $\sin x/(1+\sin x)$, how to?",How can I integrate $\displaystyle\int{\dfrac{\sin x}{1+\sin x}}dx$? I have already tried by applying different trigonometric results.,"['trigonometry', 'integration']"
631449,$uv$ is harmonic if and only if $u+icv$ is analytic for some real c,"Let $u$ and $v$ be non constant harmonic functions on a complex domain. Prove that $uv$ is harmonic if and only if $u+icv$ is analytic for some real $c$. I can prove the ""if"" part. I am having some trouble with the ""only if"" part. My argument is : $uv$ is harmonic implies $u_xv_x+u_yv_y=0$. This means that $<u_x,u_y>$ is perpendicular to $<v_x,v_y>$. This implies that $<v_x,v_y> = c<-u_y,u_x>$. This proves the result. My question is - does this sound rigorous enough?","['harmonic-functions', 'complex-analysis']"
631462,Prove that $\lim\limits_{n \rightarrow \infty} \left(\frac{23n+2}{4n+1}\right) = \frac{23}{4} $.,"My attempt: We prove that $$\displaystyle \lim\limits_{n \rightarrow \infty} \left(\frac{23n+2}{4n+1}\right) = \frac{23}{4} $$ It is sufficient to show that for an arbitrary  real number  $\epsilon\gt0$, there is a $K$
 such that for all $n\gt K$, $$\left| \frac{23n+2}{4n+1} - \frac{23}{4}
 \right| < \epsilon.  $$ Note that $$ \displaystyle\left| \frac{23n+2}{4n+1} - \frac{23}{4} \right| = \left| \frac{-15}{16n+4} \right|  $$ and for $ n > 1 $ $$ \displaystyle \left| \frac{-15}{16n+4} \right| = \frac{15}{16n+4} < \frac{1}{n}. $$ Suppose $ \epsilon \in \textbf{R} $ and $ \epsilon > 0  $.  Consider $ K = \displaystyle \frac{1}{\epsilon} $.  Allow that $ n > K $.  Then $ n > \displaystyle \frac{1}{\epsilon} $.  So $ \epsilon >\displaystyle \frac{1}{n} $.
Thus $$ \displaystyle\left| \frac{23n+2}{4n+1} - \frac{23}{4} \right| = \left| \frac{-15}{16n+4} \right| = \frac{15}{16n+4} < \frac{1}{n} < \epsilon. $$  Thus $$ \displaystyle \lim\limits_{n \rightarrow \infty} \left(\frac{23n+2}{4n+1}\right) = \frac{23}{4}. $$ Is this proof correct? What are some other ways of proving this? Thanks!","['alternative-proof', 'proof-verification', 'real-analysis', 'limits']"
631465,Hilbert's syzygy theorem in the analytic setting,"If $X$ is a projective variety then Hilbert's syzygy theorem says that any coherent sheaf of $\mathcal O_X$ modules has a finite resolution by locally free modules. By GAGA, I believe this should imply that over any smooth complex submanifold $X$ of $\mathbb CP^n$, a coherent sheaf of modules over the sheaf of holomorphic functions has a finite resolution by holomorphic vector bundles. Assuming what I said is correct, is there a direct proof of this in the analytic setting?  Also, is the analytic statement true for more general complex manifolds (e.g. Kahler)? Note: this is a crosspost from MO .","['algebraic-geometry', 'complex-geometry']"
631487,Asymptotics of the classical occupancy problem,"Classical Occupancy Problem . There are $n$ distinct labeled balls in an urn. $k$ of them of uniformly selected with replacement. What is the probability that the sample contains at least one ball of each kind. Let $(M_1,\ldots, M_n)$ be the vector of counts of each kind in the sample. The vector $(M_1,\ldots, M_n)$ follows multinomial distribution $\operatorname{Mult}\left(k, \{\frac{1}{n},\ldots, \frac{1}{n}\}\right)$, and the probability is
$$
   p_{k,n} = \Pr(M_1 > 0, \ldots, M_n >0)  \tag{1}
$$
It can be explicitly computed either using inclusion-exclusion principle, or by building a recurrence relation for $p_{k,n}$:
$$
   p_{k,n} = \sum_{m=0}^n (-1)^m \binom{n}{m} \left(1-\frac{m}{n}\right)^k = \frac{n!}{n^k} \mathcal{S}_2\left(k, n\right) \tag{2}
$$
where $\mathcal{S}_2\left(k, n\right)$ denotes Stirling number of the second kind . See Brian Gladman's notebook from mersseneforum.org or section 5.6 of Problems and snapshots from the world of probability for more details. For $k \ggg n$, the probability $p_{k,n}$ is very close to 1 (see DMLF for asymptotic behavior of the Stirling number). I am interested in obtaining more precise asymptotic expansion, perhaps by using CLT to evaluate $(1)$. References or explicit solutions are appreciated.","['asymptotics', 'probability']"
631496,Recursion definition,"Give a recursive defintion of the following set: $\{ 5^m  7^n \mid m, n \in N \}$ I don't have the slightest idea how to approach this question, id be really grateful if someone could provide me with guidance","['discrete-mathematics', 'recursion']"
631518,Harmonic series,Is there a sequence that converges to zero such that the series over the product of every summand of the harmonic series with the appropriate element of the sequence is not convergent?,"['functions', 'calculus', 'real-analysis', 'analysis']"
631556,Find this limit $\lim_{n\to\infty}\frac{1}{n^{1+\alpha}}(a_{1}+a_{2}+\cdots+a_{n})$,"let sequence $\{a_{n}\}$ such
$$\lim_{n\to\infty}\dfrac{a_{n}}{n^{\alpha}}=1(\alpha>0)$$ Useing Riemann integral of suitably chosen  functions,Find  the following limit
$$I=\lim_{n\to\infty}\dfrac{1}{n^{1+\alpha}}(a_{1}+a_{2}+\cdots+a_{n})$$ If  this problem can use Stloz lemma: we have
$$I=\lim_{n\to\infty}\dfrac{a_{1}+a_{2}+\cdots+a_{n}}{n^{1+\alpha}}=\lim_{n\to\infty}\dfrac{a_{n}}{n^{1+\alpha}-(n-1)^{1+\alpha}}=\dfrac{1}{\alpha+1}$$
becasuse
$$\lim_{n\to\infty}\dfrac{a_{n}}{n^{\alpha}}=1(\alpha>0)$$ But use Riemann integral of suitably chosen  functions: I have
$$I=\lim_{n\to\infty}\dfrac{1}{n}\sum_{i=1}^{n}\dfrac{a_{i}}{n^a}$$ I guess we will prove
$$I=\int_{0}^{1}x^{\alpha}dx=\dfrac{1}{1+\alpha}$$
But I can't prove this equation. Thank you","['integration', 'limits']"
631572,More accurate estimation of mathematical constant $e$,"Very often in books and also on Wikipedia we can find that:
$$e \approx \left(1+\frac{1}{n}\right)^n$$
but I want more accurate estimation, it means instead using $\approx$ I wonder if I can use $\leq$, $\geq$ or $>,<$ and if it is possible how can I show that?","['algebra-precalculus', 'parameter-estimation', 'discrete-mathematics']"
631613,Non-principal ultrafilters and Ultrafilter Lemma,"$\textbf{Definition}$ A family $\mathscr{F}$ of subsets of $I$ has the finite intersection property if for each $S_1, \ldots,S_n\in\mathscr{F}$ it holds that $S_1\cap\ldots\cap S_n\neq\varnothing$. $\textbf{Ultrafilter Lemma}$ If a family $\mathscr{F}$ has the finite intersection property, then there is an ultrafilter $\mathcal{U}\supset\mathscr{F}$. Thus there exist non principal ultrafilters...... I can't understand how one can deduce the existence of non-principal ultrafilters from the ultrafilter lemma.","['filters', 'elementary-set-theory']"
631627,Finding relatives of the series $\varphi =\frac{3}{2}+\sum_{k=0}^{\infty}(-1)^{k}\frac{(2k)!}{(k+1)!k!2^{4k+3}}$.,"Consider $\varphi=\frac{1+\sqrt{5}}{2}$, the golden ratio . Bellow are series $(3)$ and $(6)$ that represent $\varphi$
$$
\begin{align*}
\varphi &=\frac{1}{1}+\sum_{k=0}^{\infty}\cdots&(1)\\
\varphi &=\frac{2}{1}+\sum_{k=0}^{\infty}\cdots&(2)\\
\varphi &=\frac{3}{2}+\sum_{k=0}^{\infty}(-1)^{k}\frac{(2k)!}{(k+1)!k!2^{4k+3}}&(3)\\
\varphi &=\frac{5}{3}+\sum_{k=0}^{\infty}\cdots&(4)\\
\varphi &=\frac{8}{5}+\sum_{k=0}^{\infty}\cdots&(5)\\
\varphi &=\frac{13}{8}+\sum_{k=0}^{\infty}(-1)^{k+1}\frac{(2(k+1))!}{((k+1)+1)!(k+1)!2^{4(k+1)+3}}&(6)\\
\vdots&\\
\end{align*}
$$ When looking at the leading terms of $(3)$ and $(6)$  $\;\frac{3}{2}$ and $\frac{13}{8}$ respectively, one is tempted to conjecture that there are similar formulas to fill the holes in the above table. I'd like to know if such family of formulas exist. Thanks. EDIT: Note that both formulas connect the Golden Ratio $\varphi$ to Catalan Numbers $$
C_{k}=\frac{(2k)!}{(k+1)!k!}
$$
so for $(3)$ we have
$$
\varphi =\frac{3}{2}+\sum_{k=0}^{\infty}(-1)^{k}\frac{C_{k}}{2^{4k+3}}
$$
and for $(6)$ we have
$$
\varphi =\frac{13}{8}+\sum_{k=0}^{\infty}(-1)^{k+1}\frac{C_{k+1}}{2^{4(k+1)+3}}
$$
So, maybe this could be used, somehow, to find the other formulas.","['golden-ratio', 'catalan-numbers', 'sequences-and-series', 'constants']"
631641,Convergence of $\sum a_n$ where $a_n$ is defined recursively,"Let $a_1 = 1$ and 
$$\frac{a_{n+1}}{a_n} = \frac{3}{4}+\frac{\left(-1\right)^n}{2}$$ Question : 
How to show that $\sum a_n$ converges, i.e.
$$\sum_{n=1}^{\infty} a_n< \infty$$ I am able to show, that at least $a_n\rightarrow 0$ which is a necessasy condition for the convergence: First the subsequence $\left(a_{2k}\right)$ tends to zero because it holds $$\frac{a_{2k+2}}{a_{2k}}=\frac{a_{2k+2}}{a_{2k+1}}\cdot \frac{a_{2k+1}}{a_{2k}} = \frac{5}{4}\cdot\frac{1}{4}=\frac{5}{16}<1$$ Now note that
$$a_{2k+3} = a_{2k+2}\cdot \left(\frac{3}{4}+\frac{1}{4}\right)=a_{2k}\cdot\frac{5}{16}\cdot\frac{5}{4}=a_{2k}\frac{25}{64}$$
Hence $a_{2k+3}$ and therefore $a_{2k+1}$ and consequently $a_k$ tends to zero as well. However, I was not able to show the convergence of the series mentioned before. I tried to apply ration test, root test but I did not found an answer. I thought about comparing $\sum a_n$ with some kind of geometric sum, but I did not found an appropriate expression to compare with","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
631649,Nets and Convergence: Why directed indices?,"Please do read carefully (I know Nets-Topology-Filters and their interrelations!!!) 1.) Why do we require nets to be indexed by directed sets (apart from it simply works compared to filters and topology). Is there a reason w.r.t. to the notion of convergence ? So far there are those hints: Notion of a good Direction Uniqueness of Limit 2.) Moreover, why does it make sense to say that the following net converges even though it grows arbitrarily large on one side:
$$\Lambda:=\{1,2\}\times\mathbb{N}:(i,n)\leq(i',n') :\Leftrightarrow i\leq i',n\leq n'\\ x_{(1,n)} :=n, x_{(2,n)} :=0$$ Thanks in advance. Cheers, Alex","['general-topology', 'nets']"
631670,What is the motivation defining Matrix Similarity?,"I'm taking the course Linear Algebra 1, and recently we've learned about matrix similarity. What is the motivation defining it? or, What are the uses/applications for this definition? Thanks","['matrices', 'linear-algebra']"
631682,determinant of the linear transformation $T(X) =\frac{1}{2} (AX+XA)$,"Let $V$ vector space of all matrices $3\times3$, and let $A$ be the diagonal matrix : $$
\begin{pmatrix}
1 &  0 & 0\\
0  &  2& 0 \\
0  &  0& 1\end{pmatrix}
$$ Compute thee determinant of the linear transformation $T(X) =\frac{1}{2} (AX+XA)$. Any hints would be appreciated.","['vector-spaces', 'linear-transformations', 'matrices', 'linear-algebra', 'determinant']"
631693,Absolutely convergent series,"I am looking for an easy proof of the following theorem ( I know how to prove this by using Banach-Steinhaus), but I guess there must be something much easier: If for every $(t_n)_n$ such that $t_n \rightarrow  0$ the series $\sum_n s_nt_n$ converges, then $\sum_n s_n$ converges absolutely. Probably one needs to look at particular sequences $(t_n)$, but I do not know which one.","['sequences-and-series', 'calculus', 'real-analysis', 'analysis']"
631704,Square of Bernoulli Random Variable,"I was wondering about the distribution of the square of a Bernoulli RV. My background in statistics is not too good, so maybe this doesn't even make sense, or it is a trivial problem. Let, $Z\sim X^2$, where $X\sim \text{Ber}(p)$. $F_Z(z)=\Pr(X^2\leq z)$ $=\Pr(-z^{1/2}\leq X\leq z^{1/2})$ $=F_X(z^{1/2})-F_X(-z^{1/2})$ At this point I'm pretty confused I mean the CDF is right-continuous while I know $Z$ is a discrete RV. $\implies P_Z(z)=\frac{ d}{dz}\{F_X(z^{1/2})-F_X(-z^{1/2})\}$ I guess you can define the derivative to be: $\frac{d}{dx}f(x)=\frac{f(x+1)-f(x)}{1}$ or something... and we have $F_X(x)=\begin{cases}
0, & \text{if }x<0 \\
1-p, & \text{if }0\leq x\lt 1 \\ 1, & \text{if } x\geq1
\end{cases}$ Any help is appreciated (is my approach correct?)","['statistics', 'probability']"
631712,"Prove that for every $x\in[0,1]$, this is true $\sqrt{1+2x}\geq x+1-(1/(2x^2))$","Prove that for every $x\in[0,1]$, this is true $\sqrt{1+2x}\geq x+1-(\frac{1}{2x^2})$ i proved that $x+1-\sqrt{1+2x}>0$ by: $(x+1)^2 -1-2x=x^2$ so $x+1>\sqrt{1+2x}$ but then don't know how to proceed for this question Thank you in advance",['algebra-precalculus']
631754,Limit of sequence $\frac{1}{2^n} \sum\limits_\epsilon f(\epsilon_1\lambda+\dots+\epsilon_n\lambda^n)$,"Let $0<\lambda<1$ and $f\in C(\mathbb{R},\mathbb{R})$. Consider
  $I_{n,\lambda}=\frac{1}{2^n}  \sum\limits_{(\epsilon_1,\dots,\epsilon_n) \in \{-1,1\}^n} f(\epsilon_1\lambda+\dots+\epsilon_n\lambda^n)$.
  Show that the sequence $(I_{n,\lambda}(f))_{n\in\mathbb{N}}$ has a limit. I found this exercise in a book (it is an exercise from ENS Paris), if someone has an idea please share it.","['sequences-and-series', 'real-analysis', 'limits']"
631769,Double orthogonal complement of any closed subspace is it self [duplicate],"This question already has answers here : If $M=M^{\perp\perp}$ for every closed subspace $M$ of a pre-Hilbert space then $H$ is complete (2 answers) Closed 2 years ago . Let $H$ be a pre-Hilbert space such that any closed sub space $M \subset H$ has the property $M^{\bot \bot}=M$. Prove that $H$ is a Hilbert space (ie, prove that $H$ is complete) My attempt: As $H^*$ ($L(H,\mathbb{K})$) is complete then I want to prove that $H \cong H^*$. But I don't know how to construct an isometry between them. I will appreciate highly who can give me some ideas Thank in advance!","['inner-products', 'hilbert-spaces', 'functional-analysis']"
631776,Prove that the series is convergent and calculate the sum.,"Let's say  that $$x_{1} \gt 0$$  We define the sequence by the formula
  $$x_{n+1} = - \ln(x_{1} +x_{2}+x_{3}+\dots+x_{n}) $$
  Prove that the series $$\sum_{n=2}^{ \infty } x_{n}$$ is convergent and find the sum of it. My attempt was to use the identity $$\ln(1+x)\lt x$$ somehow, but without any results.  I've also determined that the elements of the sequence are positive and that $$x_{n+1} = - \ln(x_{1} +x_{2}+x_{3}+\dots+x_{n}) = \ln\left(\frac{1}{x_{1} +x_{2}+x_{3}+\dots+x_{n}}\right)$$","['sequences-and-series', 'calculus']"
631784,Uniform convergence in integrated survival function implies uniform convergence of distribution functions?,"For a probability distribution function $F$ supported on a bounded interval $[a,b]$, the integrated survival function (ISF) is defined as $$\Psi_F(t)=\mathbb E_F\max\{X-t,0\}=\int_t^b(1-F(x))d x.$$
Clearly, if two distributions have the same ISF then they are equal. The question is whether uniform convergence in ISF implies uniform convergence in distribution function, or at least just point-wise. Consider distribution functions $F,F_1,F_2,\dots$ all supported on a bounded interval $[a,b]$. Suppose $\sup_t\left|\Psi_{F_n}(t)-\Psi_F(t)\right|\to0$. Is it true that $\sup_t\left|{F_n}(t)-F(t)\right|\to0$, or at least that $\forall t\ \left|{F_n}(t)-F(t)\right|\to0$? Does it help to assume that $\forall n,t\ \Psi_{F_n}(t)\geq\Psi_F(t)$?","['convergence-divergence', 'probability-theory', 'uniform-convergence', 'probability-distributions', 'probability']"
631790,Sum of floor of rational product,"Given natural numbers $a,b,n$, where $a<b$, $n<b-1$, and $a$ and $b$ coprime, Find a closed form for the sum: ${\displaystyle \sum_{k=1}^n \left\lfloor k \frac{a}{b} \right\rfloor}$ We know when $n=b-1$ the sum is $\frac{1}{2}(a-1)(b-1)$, but is there a closed form for the sum when $n<b-1$? (Or, is it provable that no closed form exists?)","['discrete-mathematics', 'elementary-number-theory', 'combinatorics']"
631792,Prove discrete inequality,"Prove the following inequality for each natural $n$:
$$(n+1)^{n-1} \leq n^n$$
In fact I am not sure if it is true, but at least for $n\leq 4$ it holds true. I tried induction, but with no success.
Thanks in advance for help.","['induction', 'discrete-mathematics']"
631800,Does this orbifold embed into $\mathbb{R}^3$?,"Let $X$ be the space obtained by gluing together two congruent equilateral triangles along corresponding edges. Note that $X$ has the structure of a Riemannian manifold except at the three cone points.  In particular, $X$ is a Riemannian orbifold. Is there an isometric embedding of $X$ into $\mathbb{R}^3$?","['orbifolds', 'riemannian-geometry', 'differential-geometry']"
631808,What does the Cayley graph of the Grigorchuk group 'look like'?,"I've recently renewed my interest in tilings, and as a result have taken some splashes into Word Processing in Groups (in search of good information on the automatic groups related to hyperbolic tilings) and the amazing The Symmetries of Things .  This got me thinking about the question in the title: the isogonal embedding of Cayley graphs of certain groups (the simplest example certainly being $\mathbb{Z}^2$ with the presentation $\{a,b\ |\ ab=ba\}$) as plane tilings implies the polynomial growth of those groups.  Contrariwise, while a group like the free group on two generators can't have a 'nice' embedding in the plane because of its exponential growth rate, it can be embedded fairly nicely into the hyperbolic plane (indeed, versions of this sort of embedding form the basis of the various hyperbolic visualization tools; see e.g. http://en.wikipedia.org/wiki/Hyperbolic_tree ).  So what about the Grigorchuk Group $G$? To be a bit more concrete: I'm particularly interested in the Cayley graph of $G$ with respect to its 'full' (non-minimal) set of generators $a,b,c,d$.  Here are the things I've been able to figure out about it from first principles: Obviously this graph can't be isogonally embedded in any Euclidean space, for the reasons given above: since its growth rate is superpolynomial, there's not enough room for all the different group elements of length $n$ to be $n$ unit 'steps' away from the origin in any isogonal manner. The graph has arbitrarily large 'faces' (that is, minimal cycles) in it, corresponding to the lack of a finite presentation of $G$. I'm fairly certain the graph isn't planar: since the generators $b,c,d$ generate a subgroup of $G$ isomorphic to the Klein 4-group, each vertex of the Cayley graph is part of some embedded $K_4$ (corresponding to some element of the form $wa$ and the associated elements $wab, wac, wad$).  In particular, the four elements $e, b, c, d$ form a $K_4$ subgraph, and any independent connection of each of these four elements to some other common element (which I'm reasonably certain must exist) would induce a $K_5$ in the Cayley graph and thus imply non-planarity. OTOH, it seems like it should be possible to 'mod out' the Cayley graph of $G$ by these $K_4$s, creating a reduced graph where vertices of the graph correspond to equivalence classes $\langle wa, wab, wac, wad\rangle$ of elements and the four edges from any vertex correspond to (right) multiplication of the element $wa$ by $a$, $ba$, $ca$, and $da$; this seems like it shouldn't fundamentally change the structure of the graph, just collapse the 'trivial' local structure. It's this last reduced graph that I'm particularly curious about: is it planar?  Better yet, does it have any sort of nice (ideally isogonal) embedding into the hyperbolic plane?  And if not, is there at least any interesting (again, ideally isogonal) embedding of the full Cayley graph of $G$ into some (finite-dimensional) hyperbolic space?","['cayley-graphs', 'group-theory']"
631815,Two conics have exactly one intersection point,"We have two conics $Q_1,Q_2$ on $\mathbb{P}_2$ over some algebraically closed field. Also $Q_1$ and $Q_2$ are supposed to be smooth. I've just discovered Bezout's theorem, which states that two algebraic curves with degrees $m$ and $k$ have exactly $km$ intersection points (of course some of them can be the same). So, I'd like to build some examples when two conics have exactly $1,2,3$ and $4$ distinct intersection points. All cases but not the $1$st are quite easy. For example, $q_1(x,y,z)=x^2+y^2-z^2$ and $q_2(x,y,x)=x^2+2y^2-z^2$ are two polynomials which define smooth conics on $\mathbb{P}_2$ and they have exactly $2$ intersection points $(1:0:1)$ and $(1:0:-1)$. When we need three or four points, there are similar examples. But what about $1$ point? I cannot build an example. Is it possible? I'd like to note that conics are smooth.","['algebraic-geometry', 'algebraic-curves']"
631816,"Prove that for every $ \quad n\in\mathbb{N},\quad \mathbb{R}^{n} = \mathfrak{c}$?",I was thinking about induction like: Base: $$\#\mathbb{R}^{1} = \#\mathbb{R} = \mathfrak{c}$$ And for $n+1$ $$\#\mathbb{R}^{n+1} = \#\mathbb{R}^{n}\mathbb{R} = \mathfrak{c}$$ But it seems too easy. Do you have some other ideas?,"['cardinals', 'elementary-set-theory']"
631865,Radius of Convergence and its application to a Power Series including $x^{2n}$ rather than $x^n$,"(Radius of Convergence) Consider the Power Series $f(x)=\sum_{n=0}^{+ \infty}a_n x^n$, the radius of convergence $\rho$ can be found using $$\rho = \displaystyle \lim_{n \to + \infty} \left| \frac{a_n}{a_{n+1}} \right|$$ I did quite a few exercises already using the above definition and successfully computed the radius of convergence with it. But I stumbled across this example which I find interesting:
$$\sum_{n=0}^{+ \infty} \frac{(2n)!!}{n^n}x^{2n}\tag{taken from Michaels Analysis I}$$
For the sake of the argument let $0^0:=1$, otherwise just start from $n=1$. First I note that this, from a narrow point of view, is a power series to me. However, I can see that it  is not quite in the form of $\sum a_n x^n$ but in the form $\sum a_n x^{2n}$. My leading impulse was to ignore that fact and just compute it anyway using the above definition. Here is what came out:
$$\displaystyle \lim_{n \to + \infty} \frac{(2n)!!}{n^n}\cdot \frac{(n+1)^{n+1}}{(2n+2)!!}= \lim_{n \to + \infty} \frac{(2n)!!(n+1)}{(2n+2)(2n)!!} \cdot \left(\frac{n+1}{n}\right)^n= \frac{e}{2}=\rho$$
so I would have concluded that $|x|< \frac{e}{2}$ is the Radius of convergence (without having checked the behavior on the endpoints) . This is not the right answer, the correct answer would be $\rho = \sqrt{ e / 2}$. Now as I looked for similar exercises on this website I often saw that a lot of people don't use the above definition and just use the Quotient Criteria (d'Alembert Criteria) to find the Radius of convergence. Indeed, using this criteria here things work out much nicer: $$ \lim_{n \to + \infty} \left|\frac{a_{n+1}}{a_n} \right|=\lim_{n \to + \infty} \frac{(2n+2)!!x^{2n+2}}{(n+1)^{n+1}}\cdot \frac{n^n}{(2n)!!x^{2n}}=\lim_{n \to + \infty} x^2\frac{(2n+2)(2n)!!}{(n+1)(2n)!!}\left( \frac{n}{n+1}\right)^n \\ = \frac{2x^2}{e}\overset{!}<1 \implies x^2 < \frac{e}{2}\implies \rho = \sqrt{\frac{e}{2}}$$ Question : Is there a specific way of route I can go into to decide how to find the radius of convergence? It might be a bit far fetched to say such a thing, but what I have seen on this site, most people use the Quotient Criteria rather then the definition above. Also, is there a way I could alter the above example to use the Radius of Convergence definition I have given above in the header? Or would this be too much trouble in the first place to even consider doing such? Additional : In the same book, C.T. Michaels Analysis 1, he shows that the Radius of Convergence for the $J_0$ Besselfunction is $\infty$ by using the exact definition as in the header above: $$J_0(x)= \sum_{n=0}^{+ \infty} \frac{(-1)^nx^{2n}}{2^{2n}(n!)^2}$$
which might help you to understand or rather highlight my confusion.","['definition', 'limits', 'calculus', 'analysis']"
631887,Good source for a point set topological introduction to CW complexes?,Most algebraic topology books I found don't dwell too much on point set topology of CW complexes. I'd like too become more familiar with them. Anyone knows a good source (with exercises) too learn the basic point set topological results on cw complexes?,"['general-topology', 'algebraic-topology', 'reference-request', 'cw-complexes']"
631897,Relation between sets on a semi-rings,"How can one given rectangles a union of disjoint rectangles in $\Bbb R^{n+1}$(more specifically in $\mathcal J^n $ ): $\bigsqcup_{j \in \Bbb{N}}I^{n+1}_j=\bigsqcup_{j \in \Bbb{N}}(I_j^1 \times I_j^n)$  decompose them like this: $$I=\bigsqcup_{j \in \Bbb{N}}(I_j^1 \times I_j^n)=\text{why?}\bigsqcup_{k \in \Bbb{N}}\bigsqcup_{l \in \Bbb{N}}(\widetilde{I}_k^1 \times \widetilde{I}_l^1)=\bigsqcup_{k \in \Bbb{N}}\widetilde{I}_k^1 \times \bigsqcup_{l \in \Bbb{N}}\widetilde {I}_l^n \in \mathcal J^1 \times \mathcal J^n$$ Using the fact that $\mathcal J^n$ is a semi-ring. The $\widetilde{I}$ are different from the $I$'s? The last equality is easy but the first one I can't get. For more details on where these $\widetilde{I}$ should come from see here . I can't relate however the previous steps(in the question) to this. Notation: $\sqcup$ is disjoint union, $I$ and $\widetilde{I}$ are rectangles (sets of the form $[a,b)$), $\mathcal J^n$ is the collection of all rectangles it is also a semi-ring .",['elementary-set-theory']
631909,Ordinal inequality - simple question,"We are given 2 ordinals: $\alpha$ and $\beta$ where $\beta$ does not have a maximal number (So it's transfinite, right?) We are asked to find $\alpha,\beta$ such that: $\alpha+\beta > \beta+\alpha$ My problem is, that I don't think such a solution exists when alpha is a finite ordinal (lets say that $\beta=\omega$). if it is, then $\alpha+\beta = \{0,1,2,...,\alpha-1,0^*,1^*,2^*,...\} = \omega$ and $\beta+\alpha = \{0,1,2,...,0^*,1^*,2^*,...(\alpha-1)^*\} > \omega$ So I think $\alpha$ also has to be a transfinite ordinals. But I can't for the life of me think of such an ordinal that this will be true.","['ordinals', 'elementary-set-theory']"
631918,Prove that $\frac{\tan{x}}{\tan{y}}>\frac{x}{y} : \forall (0<y<x<\frac{\pi}{2})$,"Prove that $\frac{\tan{x}}{\tan{y}}>\frac{x}{y} : \forall (0<y<x<\frac{\pi}{2})$. My try, considering $f(t)=\frac{\tan{x}}{\tan{y}}-\frac{x}{y}$ and derivating it to see whether the function is increasing in the given interval. I should be sure that $\lim_{x,y\rightarrow0}\frac{\tan{x}}{\tan{y}}-\frac{x}{y}\geq0$ for the previous derivative check to be useful, which I'm not yet, but I'm assuming it's $0$ since I'd say that since both $x,y$ approach $0$ equally then the quotient of both their tangents and themselves is $1$, hence the substraction being $0$. However, the trouble arrives at the time of derivating it because of the 2 variables, I'm not sure if I have to fix one and derivate in terms of the other one, or what to do. I have to say I'm currently coursing a module on real single-variable analysis, so it can't have anything to do with multivariable analysis.","['trigonometry', 'inequality', 'derivatives', 'real-analysis']"
631939,Quadratic formula - math error,"I'm attempting a past paper and I have been asked to compute the derivative for $(x^2-2x+2)$ and from this I calculated $2x-2$ . Once I completed this, I was then asked to find and classify the stationary point. I usually use quadratic formulas to start this off, but for some reason I'm receiving a maths error. If someone can help me out, much appreciated. $$\frac{2 + \sqrt{-4-4\cdot 1\cdot2}}{2}$$",['algebra-precalculus']
631958,Continuous linear map,"I am trying to understand how to start with this exercise. Let $\Omega \subset \mathbb{R}^n$, $n\ge 3$, open and bounded and 
$$
C^{1,b}(\Omega)= \{\,f\in C^1(\Omega): \text{$f$ and all its partial  derivatives $D_if$ are bounded} \}
$$
with the norm $\,\|f\|=\|f\|_{\infty} + \sum_i \|D_if\|_\infty$. Now let $g:\Omega \times \Omega \rightarrow \mathbb{R}$, such that,
$$
x \neq y \,\,\Longrightarrow\,\, |g(x,y)| \le C\,|x-y|^2
$$ 
for some constant $C>0$, 
and 
$$
\int _{\Omega} g(.,y)\,f(y)\, dy \in C^{1,b}(\Omega)\quad \text{for all $\,f\in C^b(\Omega)$.}
$$ 
Then show that there is a constant $A$ such that 
$$
\Big|\,D_i \int_{\Omega} g(x,y) \,f(y)\, dy\,\Big|\le A\|f\|_{\infty}, 
\quad\text{for all $\,\,f \in C^b(\Omega),\, x \in \Omega$ and $i=1,...,n$.}
$$
Okay let's summarize this. What I probably need to show is that the map $V: C^b(\Omega) \rightarrow C^{1,b}(\Omega)$, $f \mapsto \int_{\Omega} g(.,y)f(y) dy$ is a continuous map(it is linear). If I have this, then this solves the excercise. What's the problem here?- The thing is, we do not know anything about the nature of $g$. Furthermore, I notice that all spaces that appear here are Banach spaces! By the way, in this excercise is a hint given that we shall use the following theorem: $X,Y,Z$ Banach spaces and $T:X\rightarrow Y$ linear and $J:Y \rightarrow Z$ linear, injective and continuous as well as $J \circ T$ be continuous, then $T$ is also continuous. I do not see how this is helpful cause I do not see any injective operator that appears here. If anything is unclear, please let me know.","['calculus', 'measure-theory', 'real-analysis', 'analysis', 'functional-analysis']"
631982,How to treat differentials?,"In my Calculus class, my math teacher said that differentials such as $dx$ are not numbers, and should not be treated as such. In my physics class, it seems like we treat differentials exactly like numbers, and my physics teacher even said that they are in essence very small numbers. Can someone give me an explanation which satisfies both classes, or do I just have to accept that the differentials are treated differently in different courses? For example, if the linear density of a solid rod is $d$, in Physics class we would say that the mass of a very small part of the rod $dx$, is $d*dx$, so my physics teacher would say $dm=d*dx$. P.S. I took Calculus 2 so please try to keep the answers around that level. P.S.S. Feel free to edit the tags if you think it is appropriate.","['calculus', 'real-analysis']"
631994,Cauchy Schwarz inequality for random vectors,"If $X$ and $Y$ are random scalars, then Cauchy-Schwarz says that
$$| \mathrm{Cov}(X,Y) | \le \mathrm{Var}(X)^{1/2}\mathrm{Var}(Y)^{1/2}.$$
If $X$ , $Y \in \mathrm{R}^n$ are random vectors, is there a way to bound the covariance matrix $\mathrm{Cov}(X,Y)$ in terms of the matrices $\mathrm{Var}(X)$ and $\mathrm{Var}(Y)$? (Note that, $\mathrm{Cov}(X,Y), \, \mathrm{Var}(X), \,\mathrm{Var}(Y) \in \mathrm{R}^{n\times n}$ and $\mathrm{Var}(X)_{ij} = \mathrm{Cov}(X_i,X_j)$ ) In particular, is it true that
$$\mathrm{Cov}(X,Y) \preceq \mathrm{Var}(X)^{1/2}\left(\mathrm{Var}(Y)^{1/2}\right)'$$
where the square roots are Cholesky decompositions, and the inequality is read as meaning that the right hand side minus the left hand side is positive semidefinite? EDIT: I will put what i am trying to do, maybe it helps for an answer. I have $X$, $Y, \, Z \in \mathrm{R}^2$  such that $Z = X + Y$. I know $\mathrm{Var}(X)$ and $\mathrm{Var}(Y)$ and I need $\mathrm{Var}(Z)$. As i don't know $\mathrm{Cov}(X,Y)$ I intend to over-estimate  $\mathrm{Var}(Z)$ with a matrix $V$ such that $V-\mathrm{Var}(Z) \succeq 0$. That's why i want to know if Cauchy-Schwarz holds for random vectors. If it does, then:
\begin{align*}
\mathrm{Var}(Z) & = \mathrm{Var}(X)+\mathrm{Var}(Y)+\mathrm{Cov}(X,Y)+\mathrm{Cov}(Y,X) \\
                & \preceq \mathrm{Var}(X)+\mathrm{Var}(Y) + \mathrm{Var}(X)^{1/2}\left(\mathrm{Var}(Y)^{1/2}\right)' +\mathrm{Var}(Y)^{1/2}\left(\mathrm{Var}(X)^{1/2}\right)' \\
    & =  \left( \mathrm{Var}(X)^{1/2} +\mathrm{Var}(Y)^{1/2}\right)\left(\mathrm{Var}(X)^{1/2} +\mathrm{Var}(Y)^{1/2}  \right)'
\end{align*} For sure i know i could take $V = 2\left(\mathrm{Var}(X)+\mathrm{Var}(Y)\right)$  and it will work. But it seems to extreme and i am looking for a better bound.","['inequality', 'statistics', 'bilinear-form', 'matrices', 'probability']"
632013,Function derivatives,"Earlier I asked a question about derivatives and for some reason i'm just not able to answer the question. However, I've attempted a near identical question but on another past paper, and think I may have it. If someone could check over and see if it's correct. If it is correct, could someone explain to me why I can do this one but not the other -.- Given the function $f(x)=2x^3-3x^2-36x+5$ Compute the derivative $f'(x)$ Find and classify the stationary points of $f(x)$ $$\frac{d}{dx} f(x) = 6x^2 - 6x - 36$$ I then used the quadratic equation in order to find the values of $x$, being $-2$ when minus and $3$ when addition. So, I then went onto to calculate $y$ for each by substituting the values of $x$ in. From this I learned when $x = -2, y = 49$ and when $x = 3, y = -76$. Giving me $( -2, 49 )$ and $( 3, -76 )$. From here I introduced derivative 2 in order to find rate of change. From this I found 
$$\frac{d^2y}{dx^2} = 12x - 6$$ Once again I substituted the values of $x$ in and found when $x = -2 dx^2 = -30$ meaning it is in fact a maximum since it's below the value 0. I then went onto to prove $x = 3$ eventually giving me that $dx^2$ is $30$ therefore $(3, -76)$ is a minimum. I'm pretty bad at maths to be honest. However, I found this pretty straight forward. However, for my other question Quadratic formula - math error I still feel literally clueless. If I understand this then should I understand my other question? The questions are basically identical, I just don't understand the logic..","['calculus', 'derivatives']"
632026,Overall Probability for Multiple Independent Events on Single Trial,"Am working on a probability problem where a game is described using the hypergeometric distribution. The sample successes are $3...7$, the number of samples is $7$, population successes are $10$, and the number in population is $55$. Summing the probabilities gives $\sim0.1040683327$ or ""overall odds"" of about $1$ in $9.61$. Here's the tricky part. For each play, there are $3$ sets of $7$ numbers, and only one set may be chosen by the player (the other $2$ are chosen randomly). Basically, $3$ independent trials on a single slip. So how do you calculate the overall odds of winning per play for each level ($3...7$)? According to the operator it is $1$ in $3.6$. Using the Binomial distribution, taking the probability of at least one success and averaging it with the probability of exactly one success gives overall odds of exactly $1$ in $3.6$. However, this is not the closest approximation compared to using the Rule of Complements on the sum of probability from the hypergeometric distribution mentioned earlier. That result comes out to be $\sim 0.2808414272$ or about $1$ in $3.56$. The closest approximation seems to come from using a formula derived from the Poisson distribution...this gives overall odds of $1$ in $3.58$. Keep in mind I am trying to calculate the closest probability of each success level so that the overall odds come out to be nearest $1$ in $3.6$. Now, rounded to a couple decimal places both methods I tried come to the same results, but I just want to make sure I am doing this correctly. If this isn't clear, basically I want to calculate the actual probability of winning for each tier based on the fact that 3 trials occur in the same play. Obviously it isn't as simple as dividing each odds by 3 since there is the chance of winning more than once. Thanks","['statistics', 'probability']"
632040,Are $p \to (q \to r)$ and $p \to (q \wedge r)$ logically equivalent?,"Is $p \to (q \to r)$ logically equivalent to  $p \to (q \wedge r)$? I simplified each one, I got $\neg\, p \vee(q \vee r)$ and $\neg\, p ∨(\neg\, q \wedge r)$ respectively. Not sure if my simplification is correct, if not how to simplify it? How to find out if I can simplify any further? Your advice is greatly appreciated.","['logic', 'propositional-calculus', 'discrete-mathematics']"
