question_id,title,body,tags
384604,"When in topology is $A = f^{-1} \circ f[A]$ or $B = f \circ f^{-1}[B]$ true, for an $f$ which is not one-to-one?","I'm having a bit of trouble with an example problem in the topology book I'm reading.  It's problem #11 (pp 104) of the ""Solved Problems"" section of Chapter 7, of the Schaum's Outline for ""General Topology"" (Seymour Lipschutz, ISBN 0070379882). In the proof outlined in the example, the following statement is made at an intermediate step of the proof: $$\overline{f[A]} = f[f^{-1}[\overline{f[A]}]]$$  And again later as part of the same proof (in the other direction of the iff), a similar statement is made: $$\overline{f[f^{-1}[F]]}=\bar{F}$$ I can see how these statements would follow if the $f$ were one-to-one.  But I can't see how that would be true in-general.  Is there something about the closure of a set, or a closed set in-general, which makes these statements true? Theorem 2.8 (pp 21) in the same book states that $A \subset f^{-1} \circ f[A]$ and $B \supset f \circ f^{-1}[B]$, but I can't see when those become equalities (other than when $f$ is one-to-one). Without making the assumptions in the above statements, I am able to come to the same conclusion as the proof does, by a different route.  But I'm still curious whether there is something elementary which I am not quite understanding. If more context is necessary, I can update this post with the entire example, and my alternate solution to it.  But I just wanted to get the initial question out there, in case there is a simple answer that doesn't depend on the proof as a whole.","['general-topology', 'self-learning', 'elementary-set-theory', 'functions']"
384619,"Can we write every uncountable set $U$ as $V∪W$, where $V$ and $W$ are disjoint uncountable subsets of $U$? [duplicate]","This question already has answers here : Uncountable subset with uncountable complement, without the Axiom of Choice (2 answers) Infinite Set is Disjoint Union of Two Infinite Sets (1 answer) Closed 11 years ago . Is it true that for every uncountable set $U$, we can write $U=V∪W$, where $V$ and $W$ are disjoint uncountable subsets of $U$ ?","['elementary-set-theory', 'axiom-of-choice']"
384623,Function Notation,"due to our national cirriculum (the way in which it was taught in high school). We just said that f(x) means a function. Though I understand this isn't necessarily correct? In high school we used that. However having entering university, we have something else. Say, $f:[0,1]\rightarrow \mathbb{R}$ where $f(x)=x^2$ Now I am not too familiar with the notation. All know is, [0,1] represents the domain and $\mathbb{R}$ represents codomain. Could anyone elaborate further?","['notation', 'functions']"
384629,How far to look before line-of-sight will intersect a star,"I was told this sort-of riddle by someone, having to do with the proof for the finite age of the universe, and I'm not sure how to approach the answer. Assuming that the entire universe is uniformly filled with sun-like stars (let the sun-radius be $R$) with a density of $N$ stars per cubic Mpc, how far out into space one would have to look, on average, before the line of sight intersects a star It seems like a simple calculation, but I can't seem to wrap my head around it.",['probability']
384643,Integral of $\frac{{x^{1/2}}+3}{2+{x^{1/3}}}$,"I want to solve this integral and think about doing the following steps: $1)\quad t=x^{1/3}$ $2)\quad x=t^3$ $3)\quad dx=2t^3\,dt$ How I can show $\sqrt{x}$ as $t$? $$\frac{x^{1/2}+3}{2+x^{1/3}}$$
Thanks!","['calculus', 'integration', 'indefinite-integrals']"
384648,Basis for $\mathbb{[Q(\pi):Q]}$,I'm trying to figure out whether the basis of $\mathbb{Q}(x)$ over $\mathbb{Q}$ is countable when $x$ is transcendental. I know that the elements in $\mathbb{Q}(x)$ will be rational functions in $x$ and so they are countable like algebraic numbers. Let the rank be the sum of coefficients and degrees of polynomials in denominator and numerator. So it passes the necessary condition for countable basis outlined by Asaf Karagila in Countable/uncountable basis of vector space . I have no more ideas to go with. Edit: Obviously a basis will have to be countable if the space is countable. So how do I go about finding a basis?,"['vector-spaces', 'rational-functions', 'linear-algebra']"
384663,"Non-Borel subsets of [0,1] and a definition in an article","I have the following problem to answer: let $B\subseteq \mathbb{R}^{n}$ be a compact set, let $b\in B^{[0,1]}$ and let $\{\pi_{i};i\in [0,1]\}$ denote the canonical projections. Is the following a well-defined probability measure on the Borel $\sigma$-algebra on $B$:
$$ \beta(b)(E):=\int_{[0,1]}f_{E}(i) d\lambda(i) $$
where $f_{E}(i)=1$ if $\pi_{i}(b)\in E$ and $0$ otherwise? I have  attacked the problem as follows: all there is to show is that for each Borel-measurable set $E\subseteq B$ the function $f_{E}$ is measurable. Assume that $|B|\geq 2$ and $x\neq y$ elements of $B$, then $\{x\}$ is a Borel-measurable subset of $B$. Assume that there exists $Z\subseteq [0,1]$ not Borel measurable and define $b$ by:
$$\pi_{i}(b)=\begin{cases}x & \text{if }i\in Z\\ y & \text{otherwise}\end{cases}$$
then $f_{\{x\}}^{-1}(\{1\})=Z$ and hence not Borel-measurable. So the questions are the following: Is there any non-Borel measurable subset $Z\subseteq [0,1]$? It seems that yes, as of the standard example (e.g. here ). Is there another way this could work out? Am I doing something wrong? The reason why I am reluctant to say NO is that this is a basic assumption in a published paper ( thou clicketh here, footnote 6 ). This leads to another question; does my expression differ from the one used in the paper:
$$\beta(b)(E) = \int_{\{i\in[0,1]:b_{i} \in E\}} di$$ Thank you very much Manuel",['measure-theory']
384673,On the construction of hyperelliptic Riemann surfaces.,"I have seen two ways to construct hyperelliptic curves, and it seems to me that the intuition behind the change of coordinate is not the same. I like better the second construction (which is pretty topological), but understand better the intuition of the first one (which is more analytical). First construction. In my lecture notes, one constructs an hyperelliptic curve as follow : consider the Riemann surface $X \subset \mathbb C^2$ defined by $y^2 = p(x)$ for some polynomial $p(x) = (x-a_1) \dots (x-a_k)$ such that $a_i \neq a_j$ whenever $i \neq j$. Then, the holomorphic function $\pi \colon (x,y) \mapsto x$ is a ramified covering of degree 2 (the branching points being $a_1, \ldots, a_k$). The idea is now to extend this ramified covering to a application $\tilde X \to \mathbb P^1$ of degree 2. In order to do that, observe that when $x \to \infty$, also $y \to \infty$, and let be two new local coordinates $z = 1/x$, $w = 1/y$. Then pulling back a small punctured disk centered in $0$ by $z$ and rewritting $y^2 = p(x)$ as $w^2 = 1/p(1/z)$, it appears that we can extend $\pi$ above $z = 0$ by one or two points depending of the parity of $k$. We then have the wanted $\tilde X$, compact Riemann surface. Second construction. (Ref. Rick Miranda's Algebraic Curves and Riemann Surfaces ) As before we have $X \subset \mathbb C^2$ and we also construct $Y \subset \mathbb C^2$ defined by $w^2 = z^{2m} p(1/z)$ where $k=2m$ or $2m-1$. Then let the biholomorphism
$$\varphi \colon \{(x,y) \in X \mid x \neq 0\} \to \{(z,w) \in Y \mid z \neq 0\}, (x,y) \mapsto (z,w) = (1/x, y/x^m),$$
and we obtain $\tilde X$ by glueing $X$ and $Y$ over $\varphi$. Question. What is the intuition behind the change of coordinates $z=1/x$, $w=y/x^m$ in the second construction ? It does not seems natural to me, whereas the change $z=1/x$, $w=1/y$ does. In other words, where does it come that we set $Y$ as the locus of $w^2 = z^{2m}p(1/z)$ ?","['riemann-surfaces', 'complex-analysis']"
384700,Show that the zero set of $f$ is an orientable submanifold of $\Bbb R^{n+1}$.,"Suppose $f(x_1,...,x_{n+1})$ is a$ C^∞$ function on $\Bbb R^{n+1}$ with $0$ as a regular value. Show that the zero set of $f$ is an orientable submanifold of $\Bbb R_{n+1}$. In particular, the unit n-sphere $S_n$ in $\Bbb R^{n+1}$ is orientable. I think that By the regular level set theorem, if $0$ is a regular value of a $C^∞$ function $f(x_1,...x_{n+1})$ on $\Bbb R^{n+1}$, then the zero set $f^{−1}(0)$ is a $C^∞$ manifold. And I guess that I need to apply a theorem. The theorem is following.. THM: A manifold M of dimension n is orientable if and only if there exists a $C^∞$ nowhere-vanishing n-form on M. But I dont know how to apply this theorem. Please help me show how to apply this theorem to my question explicitly and instructively if my solution way is correct. Thank you for help.","['manifolds', 'linear-algebra', 'differential-geometry']"
384708,"What does $ d\tan(x) = \sec^2(x)\,dx $ mean?","What does $ d\tan(x) = \sec^2(x)\,dx$ mean? I've seen it used in integration problems to make it more simpler. However, I'm not really sure what it means. Can someone explain this to me?","['calculus', 'integration']"
384713,Looking for a (nonlinear) map from $n$-dimensional cube to an $n$-dimensional simplex,"I am looking for a (nonlinear) map from $n$-dimensional cube to an $n$-dimensional simplex; to make it simple, assume the following figure which is showing a sample transformation for the case when $n=2$. (sorry for my bad drawing). The two circles in the rectangle, are set of points, which are mapped to the rectangle. Note that, points by this transformation maintain their relative position to each other, as shown in the figure. http://tinypic.com?ref=30bcxzp Any suggestion how to find such transformation?","['geometry', 'general-topology', 'algebraic-geometry', 'algebraic-topology', 'conformal-geometry']"
384723,"How to calculate the ""difference between $X$ and $Y$""","I feel like this is the silliest question ever, so I apologize in advance! a statement reads: $Z$ is the difference between $X$ and $Y$ . Which of these is true? $Z = X - Y$ $Z = Y - X$ $Z = |X - Y|$ I want to say it's the third, or whichever is larger minus whichever is smaller, but I can't be certain. This came up in a textbook I'm studying.  Attrition is the difference between the actual number of guest rooms picked up and the number of guest rooms guaranteed by the meeting sponsor in the contract. Thanks!",['algebra-precalculus']
384731,$\frac{1}{4^n}\binom{1/2}{n} \stackrel{?}{=} \frac{1}{1+2n}\binom{n+1/2}{2n}$ - An identity for fractional binomial coefficients,"In trying to write an answer to this question: calculate the roots of $z = 1 + z^{1/2}$ using Lagrange expansion I have come across the identity $$
\frac{1}{4^n}\binom{1/2}{n} = \frac{1}{1+2n}\binom{n+1/2}{2n}.
\tag{1}
$$ Could anyone help me prove this?  The few identities I know for binomial coefficients aren't enough to get anywhere useful and I don't see a way to account for the large difference in the number of factors in their respective numerators and denominators.","['binomial-coefficients', 'combinatorics']"
384732,"Find the value of $\int_{-\infty}^\infty \int_{-\infty}^\infty e^{-(x^2+xy+y^2)} \, dx\,dy$","Given that $\int_{-\infty}^\infty e^{-x^2} \, dx=\sqrt{\pi}$ . Find the value of $$\int_{-\infty}^\infty\int_{-\infty}^\infty e^{-(x^2+xy+y^2)} \, dx\,dy$$ I don't understand how I find this double integral by using the given data. Please help.","['multivariable-calculus', 'multiple-integral', 'integration']"
384735,finding Laurent expansion of a periodic function,"How are Laurent series and Fourier series related to each other? There is a problem that states that for a periodic function $F(z + 2 \pi ) = F(z)$ that is analytic in finite plane. $$F(z) = \sum_{n=-\infty}^\infty \alpha_n e^{inz}, \alpha_n=\frac{1}{2\pi}\int_0^{2\pi}F(z)e^{-inz}dz$$ How do I relate $z^n$ to $e^{inz}$ and $\displaystyle \frac{1}{2\pi i}\oint_\gamma\frac{F(z)}{z^{n+1}}dz$ to $\displaystyle \frac{1}{2\pi }\int_0^{2\pi}F(z)e^{-inz}dz$. Added:: It looks that if $z = e^{i\theta}$ the Laurent series looks like Fourier series. But I not get why $n$ goes from $-\infty$ to $\infty$ since the $F(z)$ is analytic in finite plane shouldn't $n$ start from $0\to \infty$?","['laurent-series', 'complex-analysis']"
384739,Probability of two people in a group of n people sharing the *exact* birthday?,"I understand the solution to the birthday paradox. But I was wondering how I would calculate the probability of two people having the same age, or the exact birthday, down to matching years. I am thoroughly confused. Please help.",['probability']
384740,Irreducible polynomials and affine variety,"Let $k$ be any field, and let $f,g\in k[x,y]$ be two irreducible polynomials such
that $g$ is not divisible by $f$. Prove that $V(f,g)\subseteq A_k^2$ is finite.","['commutative-algebra', 'algebraic-geometry']"
384751,self-adjoint operator proof,"Let $T$ be a densely defined closed unbounded operator on a Hilbert space $H$. A number $\lambda \in C$ is called an approximate eigenvalue of T if there is a sequence ${X_n} \subset D(T)$, with $\|X_n\|=1, n=1,2,... $ s.t. $(T-\lambda I)X_n \rightarrow 0$ as $n \rightarrow \infty$. Then how to prove that if $T$ is self adjoint then any $\lambda \in \sigma(T)$ is an approximate eigenvalue? Was thinking about using spectral theorem, first assume there doesn't exist the sequence $X_n$ and try to induce the contradiction.","['hilbert-spaces', 'functional-analysis']"
384765,Prove that $\lim_{N\rightarrow\infty}(1/N)\sum_{n=1}^N f(nx)=\int_{0}^1f(t)dt$,"Suppose $f$ is continuous and periodic on the reals with period 1. Prove that if $x\in[0,1]$ is an irrational number, then $$\lim_{N\rightarrow\infty}\frac{1}{N}\sum_{n=1}^N f(nx)=\int_{0}^1f(t)dt$$ Suggestion: First consider $f(t) = e^{2\pi(ikt)}$ where k is an integer. I can see that this is a limit of a weighted average, but the suggestion throws me off. I've seen the suggestion in fourier transforms but it's not clicking at the moment. Any help would be welcome.","['equidistribution', 'real-analysis', 'analysis']"
384766,How to construct a matrix $A$,Construct a matrix $A$ such that $A^2\ne 0$ but $A^3=0$. I need your help to find $A$. Please help. Thanks in advance.,"['matrices', 'linear-algebra']"
384778,A series converges absolutely if and only if every subseries converges,"Question: A subseries of the series $\sum _{n=1}^\infty a_n$ is defined to be a series of the form $\sum _{n=1}^\infty a_{n_k}$, for $n_k \subseteq \Bbb N$. Prove that $\sum _{n=1}^\infty a_n$ converges absolutely if and only if each subseries $\sum _{n=1}^\infty a_{n_k}$ converges. Suggested solution: $\Rightarrow$ We assume $\sum _{n=1}^\infty a_n$ converges absolutely $\Rightarrow \lim_{n \to \infty} |a_n|$=0. We know from the definition of series that it's actually the sequence of partial sums so $\sum _{n=1}^\infty a_n = S_n$. Therefore we can treat it like a sequence and say that it converges to L. Since $S_n$ converges to L, each of it's sub sequences also converge to L. Therefore $\sum _{n=1}^\infty a_{n_k} =S_{n_k} \to L$ as well. $\Leftarrow$ We assume each subseries converges. Specifically the sub series $\sum _{\Bbb N even} a_n = A$  $\sum _{\Bbb N odd} a_n = B$ . Since these two series comprise all of the naturals, then  $\sum _{n=1}^\infty a_n =\sum _{\Bbb N even} a_n+\sum _{\Bbb N odd} a_n = A+B$ . Therefore it converges to A+B. I would like to verify this proof, because I've given it a lot of thought, and still not 100 percent sure about it. Please hint me, and notify me about any mistakes.
Thanks.","['sequences-and-series', 'calculus', 'absolute-convergence']"
384780,Closed form for $\sum_{n=-\infty}^{\infty} \frac{1}{n^4+a^4}$,"I've been working with series this week and came across a couple that have been bugging me. I'm looking for the closed form of: $$
J(a)=\sum_{-\infty}^{\infty} \frac {1} {n^4+a^4}
$$ As with the other one I posted, solving for the closed form seems like a futile effort as nothing involving differentiation, integration, or DE form leads to a known series solution, such as $e^{x}$, $ln(x)$, etc.  I'm running out of hair here.  I'll thank anyone who's willing to help.","['sequences-and-series', 'calculus']"
384790,Unique continuos linear function given a continuous function from a dense space in X to Y (Y is a Banach Space).,"Let $X$ be a normed space, let $Y$ be a Banach Space, let $D\subseteq X$ be a dense linear subspace of $X$ and let $L:D\rightarrow Y$ be a continuous linear function. Then there is a unique continuous linear function $M:X\rightarrow Y$ such that $M|_D=L$. The task is to prove this theorem. I have no idea where to even start, any direction you can give me would be greatly appreciated. edit: "" Banach Space, let $D\in X$ "" [;\rightarrow ;] """" Banach Space, let $D\subseteq X$ """"","['normed-spaces', 'continuity', 'derivatives']"
384791,Showing that the arithmetic mean is greater than or equal to the geometric mean (Spivak Calculus 3rd Chapter 2 Problem 22),"If $a_1, \ldots, a_n \ge 0$, the arithmetic mean $$A_n={a_1 + \cdots + a_n \over n}$$ and the geometric mean $$G_n = \sqrt[n]{a_1 \cdots a_n}$$ satisfy $G_n \le A_n$. As a first step to prove this inequality, the author suggests to suppose $a_1 \lt A_n$; then some $a_i$ satisfies $a_i \gt A_n$, so we suppose $a_2 \gt A_n$. Let $\overline a_1 = A_n$ and $\overline a_2 = a_1 + a_2 - \overline a_1$.
The first question of the exercise is to prove that $\overline a_1 \overline a_2 \ge a_1 a_2$. This is easy enough because it's the same as proving that $A_n^2 -(a_1+a_2)A_n + a_1a_2 \le 0$, that is $(A_n - a_1)(A_n - a_2) \le 0$, which is true because $(A_n - a_1) \gt 0$ and $(A_n - a_2) \lt 0$. The next question is to explain why repeating this process eventually proves that $G_n \lt A_n$. Let $\overline G_n$ and $\overline A_n$ be the geometric and arithmetic means obtained by replacing $a_1$ and $a_2$ with $\overline a_1$ and $\overline a_2$.
From the inequality just proved, it's $\overline G_n \ge G_n$; moreover, $\overline A_n = A_n$, so being able to prove $\overline G_n \le A_n$ would also prove $G_n \le A_n$. I can easily see that replacing every $a_i$ with $A_n$, the geometrical mean would equal $A_n$, but I've not been able to prove formally by induction that continuing to replace $a_i$ with $A_n$ keep the resulting geometric mean $\le G_n$. I thought it would be necessary to ensure that the arithmetic mean is unchanged; so I would expect it to be $\overline a_i = A_n$ for $i=1,\ldots,k \lt n$ and $\overline a_{k+1} = [(a_1 + \ldots + a_{k+1}) - (\overline a_1 + \ldots + \overline a_k)]$. The first inequality that was proved is the case $k=1$, but I'm having difficulties in understanding how to: Prove that the inequality holds for $k=l+1$ if it holds for $k=l$ Justify the case $k=n$, because $a_{n+1}$ would appear in the expression Here's a sketch of the proof for 1. that I failed to complete; if the inequality holds for $k=l$, then $$A_n^l(\sum_{i=1}^l a_i - \sum_{i=1}^{l-1} \overline a_i) - \prod_{i=1}^l a_i \ge 0.$$ Then for $k=l+1$ the inequality is written $$A_n^{l+1}(\sum_{i=1}^{l+1} a_i - \sum_{i=1}^{l} \overline a_i) - \prod_{i=1}^{l+1} a_i \ge 0$$ that is, noting that $\overline a_l = A_n$, $$A_nA_n^l(\sum_{i=1}^l a_i - \sum_{i=1}^{l-1} \overline a_i) + A_n^{l+1}a_{l+1} - A_n^{l+2} - a_{l+1}\prod_{i=1}^{l} a_i \ge 0.$$ Now, if $a_{l+1} = A_n$, we get the expression for $k=l$; if $a_{l+1} \gt A_n$, then the inequality holds if the following holds $\overline a_l = A_n$, $$A_nA_n^l(\sum_{i=1}^l a_i - \sum_{i=1}^{l-1} \overline a_i) + A_n^{l+2} - A_n^{l+2} - a_{l+1}\prod_{i=1}^{l} a_i \ge 0,$$ that is $$A_nA_n^l(\sum_{i=1}^l a_i - \sum_{i=1}^{l-1} \overline a_i) - a_{l+1}\prod_{i=1}^{l} a_i \ge 0,$$ but I've not been able to complete the proof. Also, I can't find a way to write the case $k=n$. Thanks for your attention and assistance.","['inequality', 'induction', 'means', 'algebra-precalculus']"
384804,Combine transformation matrices,"Question: Find the transformation matrix that combines the following transformation matrices, in order: $$\begin{bmatrix}
 &3  &0  &0  &0 \\ 
 &0  &-1  &0  &0 \\ 
 &0  &0  &2  &0 \\ 
 &0  &0  &0  &1 \\  
\end{bmatrix}$$ $$\begin{bmatrix}
 &\frac{\sqrt3}{2}  &0  &\frac{-1}{2}  &0 \\ 
 &0  &1  &0  &0 \\ 
 &\frac{1}{2}  &0  &\frac{\sqrt3}{2}  &0 \\ 
 &0  &0  &0  &1 \\  
\end{bmatrix}$$ $$\begin{bmatrix}
 &1  &0  &0  &3 \\ 
 &0  &1  &0  &-1 \\ 
 &0  &0  &1  &2 \\ 
 &0  &0  &0  &1 \\  
\end{bmatrix}$$ I know you are meant to multiply them together, and I get the same result online calculators get, but the answer in my textbook is: $$\begin{bmatrix}
 &\frac{3\sqrt3}{2}  &0  &-1  &3 \\ 
 &0  &-1  &0  &-1 \\ 
 &\frac{3}{2}  &0  &\sqrt3  &2 \\ 
 &0  &0  &0  &1 \\  
\end{bmatrix}$$ Am I missing something, how is this result achieved?","['matrices', 'linear-algebra']"
384810,A Fourier series exercise,"Can anyone give me a hand with this exercise about Fourier series? Let $f(x)=-\log|2\sin(\frac{x}{2})|\,\,\,$ $0\lt|x|\leq\pi$ 1) Prove that f is integrable in $[-\pi,\pi]$. 2) Calculate the Fourier coefficients of $f$. 3)The Fourier series converge to $f$? $------------------$ What I know: About part 2, as f is even, then it would be enough to calculate the ""$a_n$"" coefficients of the series. That is, the $\int_{-\pi}^{\pi}f(x)cos(nx)$. This integrals can be done integrating by parts, I think. (am I right?) My problems are part 1 and 3, I don't see how to prove them. Thanks for any help. EDIT : Also, i met a problem at part 2. Calculating $a_n$, i arrive at a point where i need to find the value of $\int_{0}^{\pi}cotag(\frac{x}{2})sin(nx)$. I know (checked it numerically) that the value of this integral is $\pi$ for any natural $n$. But I can't find a way to prove this ""by hand"", as integration by parts doesn't seem to work here... Any ideas?","['fourier-series', 'fourier-analysis', 'analysis']"
384830,$f(x)=\tanh(1+\tanh^{-1}(x))$ or $f:\tanh(x) \to \tanh(x+1)$ is a rational function?,"This is (again) more a recreational/incidental question. Playing with iteration of functions I considered the function $$ f(x) = \tanh(1+\tanh^{-1}(x)) \tag1$$ such that $$ f : \tanh(x) \to \tanh(x+1) \tag 2$$
Pari/GP is kind enough to provide the first few coefficients of the Taylor-series of $f(x)$ numerically.
$$ f(x) \sim  0.7615941559557649 + 0.4199743416140261 x - 0.3198500042246123 x^2 \\ + 0.2435958939998914 x^3 - 0.1855212092851373 x^4 + 0.1412918687974069 x^5  \\ - 0.1076070615601738 x^6 + 0.08195290922380060 x^7 - 0.06241485672841984 x^8  \\ + O(x^9) $$ Looking at the coefficients it seemed to me that they give just an alternating geometric series with quotient $q=-\tanh(1)$ and a scaling factor $a = \frac 1q - q$ such that -by that numerical heuristic-  the power-series of $f(x)$ is  $$f(x) \underset{\text{guessed}}{=} -q + a \sum_{k=1}^\infty q^k x^k \tag 3$$ which reduces then to the rational function $$ f(x) \underset{\text{guessed}}{=} { a \over 1-x\cdot q }- \frac 1q \tag 4$$ I'm surprised that this results in such a simple function - how would a proof for the algebraic identity (4) look like?","['sequences-and-series', 'functions']"
384834,Inverse of negative entropy function on positive orthant,"What is the inverse of the function $f: \mathbb{R}^{+}\to \mathbb{R}$, $f(x) = x \ln x$? This is an invertible function on the domain mentioned above.","['calculus', 'algebra-precalculus']"
384835,Does $f'$ analytic imply $f$ analytic?,"If $f'$ is known to be analytic, does it mean that $f$ is analytic as well? I've tried to expand $f$ and then to replace the tail of it by the expansion of $f'$, yet the factorials don't add up. I also tried to start with the known-to-converge expansion of $f'$ yet it was unclear how to move to $f$ (I didn't have integration yet). If the statement isn't true then how does one prove, for example, that $f(x)=-\log\cos(x)$ is analytic in zero by using the fact that its derivative $\tan(x) = \sum_{n=1}^\infty (-1)^{n-1} 2^{2n}(2^{2n}-1) B_{2n}x^{2n-1}/(2n)!$ is analytic in zero?","['calculus', 'analyticity', 'real-analysis']"
384855,"""Square root"" of a normal RV?","Say $X_1,X_2$ are independently drawn from the same distribution (call it $X$) and that their product, $X_1X_2$ falls on a standard normal distribution. Is it possible to get a pdf or cdf for $X$? My progress: The $n$th moment of a standard normal is $0$ for odd $n$ and $n!!$ for even $n$. Then for even $n$: $\mathbb{E}[(X_1 X_2)^n] = \mathbb{E}[X_1^n] \mathbb{E}[X_2^n] = \mathbb{E}[X^n]^2 = n!! $ Thus the $n$th moment of $X$ is $\mathbb{E}[X^n] = \sqrt{n!!}$ for even $n$ and zero otherwise. Therefore...","['statistics', 'probability', 'random-variables', 'probability-theory']"
384856,The set of numbers whose decimal expansions contain only 4 and 7,"Let $S$ be the set of numbers in $X=[0,1]$ that when expanded as a decimal form, the numbers are 4 or 7 only. The following are the problems. a), Is S countable ? b), Is it dense in $X$ ? c), Is it compact ? d), Is it perfect ? For a), I want to say that it is intuitively, but I have no idea how to prove this. I tried to come up with a bijection between $S$ and $\Bbb Z$ but I couldn't find one. For b), my understanding of a set being ""dense"" means that all points in $X$ is either a limit point or a point in $S$. Am I right? Even if I were, I am not sure how to show this. For c), my intuition tells me that it is because it is bounded. So if I could show that it is closed I will be done, I think.  But I am still iffy with the idea of limit points, and I am not sure what kind of limit points there are in $S$. For d), Because I can't show that it's closed I am completely stuck. I am teaching myself analysis, and I only know up to abstract algebra. Since I never took topology, please give me an explanation that helps without knowledge of advanced math.",['analysis']
384860,"For which integers x, y is $2^x + 3^y$ a square of a rational number?","For which integers x, y is $2^x + 3^y$ a square of a rational number? (Of course $(x,y)=(0,1),(3,0)$ work)","['elementary-number-theory', 'diophantine-equations', 'contest-math', 'number-theory']"
384865,Good textbooks on Non-Euclidean Geometry? [duplicate],"This question already has answers here : I'm researching about geometry non-Euclidean [closed] (3 answers) Closed 5 years ago . I'm currently taking a class called Foundations of Geometry. We started with the stereographic projection and carried onward through fractional linear transformations, and now we are working with the Poincaré Disk Model. We've been finding things like non-Euclidean lines, circles with their non-Euclidean centers and non-Euclidean distances, delving into hyperbolic trigonometry. We don't use a textbook though, the professor just wrote up his own notes, and while good, they're restricted to just our 10 quarter class, and we're just studying one of the non-Euclidean geometries. So I was wondering if anyone had suggestions on some books that may cover more of the hyperbolic geometry or perhaps some elliptic, or any others in general. Thanks! =D",['geometry']
384878,Show that $dX_t=1_{X_t\not=0} dW_t$ does not have a pathwise unique solution.,"Given the SDE :  $$dX_t=1_{X_t\not=0} dW_t \qquad \text{with} \quad X_{0}=\xi $$ how can I  construct two obvious strong solutions to prove that SDE has non pathwise uniquenss Indeed Consider the stopping time $$ \sigma = inf  \left\{ t ≥ 0: \xi +Wt \preceq 0 \right\} $$ and set 
$$X_t= \xi +W_{t \wedge \sigma} $$ This process X is a strong solution of SDE $dX_t=1_{X_t\not=0} dW_t$ , $X_{0}=\xi $ 
Indeed, it is $ \mathcal f_t^{(\xi , \mathcal W)} $ adapted, $ X_{0}=\xi $ we have $$X_t-X_0=\int_0^t 1_{({s  \prec   \sigma })}dW_s=\int_0^t1_{({\xi +W_{s\wedge \sigma}>0})} dX_t=\int_0^t 1_{{X_t\not=0}}dW_s $$
which means that $$dX_t=1_{X_t\not=0}dW_s,\qquad X_0=\xi $$ so $X_t $ is solution of our SDE my question how can i construct just two obvious strong solutions to prove that SDE has non pathwise uniquenss i'll be grateful for any help best regards, Educ","['stochastic-processes', 'stochastic-integrals', 'probability-theory', 'stochastic-calculus', 'stochastic-differential-equations']"
384893,How was the normal distribution derived?,"Abraham de Moivre, when he came up with this formula, had to assure that the points of inflection were exactly one standard deviation away from the center, and so that it was bell-shaped, as well as make sure that the area under the curve was exactly equal to one. And somehow they came up with the standard normal distribution, which is as follows: $$\displaystyle\phi(x) = \frac{1}{\sqrt{2\pi}}e^{-\dfrac{1}{2}x^2}$$ And even cooler, he found the distribution for when the mean was not $0$ and the standard deviation was not $1$, and came up with: $$\displaystyle f(x) = \frac{1}{\sigma\sqrt{2\pi}}e^{-\dfrac{(x - \mu)^2}{2\sigma^2}}$$ And so what I ask is, how? How was an equation come up with that fit all the aforementioned criteria? Moreover, how do the numbers $\pi$ and $e$ come into this?","['statistics', 'normal-distribution', 'probability-distributions', 'math-history']"
384902,Classification of local Artin (commutative) rings which are finite over an algebraically closed field,"A result in deformation theory states that if every morphism $Y=\operatorname{Spec}(\mathcal{A})\rightarrow X$ where $\mathcal A$ is a local Artin ring finite over $k$ can be extended to every $Y'\supset Y$ where $Y'$ is an infinitesimal thickening of $Y$ , then $X$ is non-singular. My question is: If $k$ is algebraically closed, can we say explicitly what every local Artin ring finite over $k$ is? $\mathcal A$ can be of the form $k[t]/(t^n)$ or for instance if its maximal ideal isn't principally generated $k[t^2,t^3]/(t^4)$ . Are there $\mathcal A$ which we cannot write in this ""adjoin various powers of $t$ and mod out by some power of $t$ "" form? If there are more exotic $\mathcal A$ can we say anything non-tautological about the structure of such an $\mathcal A$ ? Thanks.","['ring-theory', 'algebraic-geometry', 'deformation-theory', 'artinian', 'commutative-algebra']"
384923,What exactly is a probability measure in simple words?,"Can someone explain probability measure in simple words?  This term has been hunting me for my life. Today I came across Kullback-Leibler divergence .  The KL divergence between probability measure P and Q is defined by, $$KL(P,Q)= \begin{cases}
              \int \log\left(\frac{dP} {dQ}\right)dP & \text{if}\ P\ll Q, \\
              \infty & \text{otherwise}.
              \end{cases}$$ I have no idea what I just read.  I looked up probability measure , it refers to probability space .  I looked that up, it refers to $\sigma$-algebra.  I told myself I have to stop. So, is a probability measure just a probability density but a broader and fancier saying? Am I overlooking a simple concept, or is this topic just that hard?","['information-theory', 'measure-theory', 'probability']"
384934,"How does this ""combinatorial proof"" work?","For any non-integer $n$, $$(1+x)^n=\sum_{k=0}^{n}\binom{n}{k}x^k$$ Let $y_1,\dots,y_n$ be variables and, for any subset $S$ of $\{1,\dots,n\}$, let $y^S$ denote the product of the $y_i$'s for each $i\in S$ (thus $y^{\{1,3,4\}}=y_1y_3y_4$). Therefore from the one-to-one correspondence above $$(1+y_1)(1+y_2)\cdots(1+y_n)=\sum_{S\in\{1,\dots,n\}}y^S$$
Now, substituting $y_i= x$ for each $i$, the term $y^S$ becomes $x^{|S|}$. Hence the result follows. This is the first ""combinatorial proof"" in my introductory combinatorics textbook. I don't really get the one-to-one correspondence part. How does that work?",['combinatorics']
384937,Equation of Cone vs Elliptic Paraboloid,"I can't understand why $$\frac{z}{c} = \frac{x^2}{a^2} + \frac{y^2}{b^2} \tag{*}$$ corresponds to an elliptic paraboloid and $$\frac{z^2}{c^2} = \frac{x^2}{a^2} + \frac{y^2}{b^2} \tag{**}$$ to a cone, and not the other way around. I tried to understand by looking at the traces of $z(x,y)$. For example, I did so for (**): $\boxed{\text{When } x = k:}$ Then (**) becomes: $\displaystyle \frac{z^2}{c^2} - \frac{y^2}{b^2} =\underbrace{\frac{k^2}{a^2}}_{\text{a constant}} \color{green}{\text{: hyperbolas in the $yz$-plane.}}$ ${\boxed{\text{When } y = k:}}$ Then (**) becomes: $\displaystyle \frac{z^2}{c^2} - \frac{x^2}{a^2} = {\underbrace{\frac{k^2}{b^2}}_{\text{a constant}}\color{red}{\text{: hyperbolas in the $xz$-plane.}}}$ $\boxed{\text{When } z = k:}$ Then (**) becomes: $\displaystyle \underbrace{\frac{k^2}{c^2}}_{\text{a constant}} = \frac{x^2}{a^2} + \frac{y^2}{b^2} \color{blue}{\text{:  ellipses in the $xy$-plane.}}$ I sketched the following shape based on this information, but it doesn't seem to tell me whether it's an elliptic paraboloid or a cone? $\Large{\text{Supplementary Question:}}$ Thank you very much to all your answers, all of which helped! Based on them, the key step seems to be to look at the traces of $z(x,y)$ for $k = 0.$ I now understand that this answers my question, but why did my original work with $k \neq 0 $  fail to do so? My textbook doesn't mention the latter straightforward ""trick."" $\Large{\text{Question S.1:}}$ @bubba: Thank you very much for your answer to the Supplementary Question. To clarify your answer, did you mean: ""but, in either case, these are hyperbolas curves} unless $k=1.$"" As I wrote above, for $\text{(*)}$, the traces $x=k \text{ & }y = k$ do yield hyperbolas. But for $\text{(*)}$, $ \boxed{\text{When } x = k:}$  Then (*) becomes $\displaystyle \frac{z}{c} - \frac{y^2}{b^2} =\underbrace{\frac{k^2}{a^2}}_{\text{a constant}} \text{: PARAbolas in the $yz$-plane.}$ ${\boxed{\text{When } y = k:}}$ Then (*) becomes: $\displaystyle \frac{z}{c} - \frac{x^2}{a^2} = {\underbrace{\frac{k^2}{b^2}}_{\text{a constant}}{\text{: PARAbolas in the $xz$-plane.}}}$. Of course, the fact the traces of (*) are parabolas and NOT hyperbolas still doesn't answer my original question. As you kindly explained and I now understand, it's necessary to consider $k = 0.$","['geometry', 'multivariable-calculus']"
384948,Extreme Value Theorem Proof (Spivak),"Them: If $f$ is continuous on $[a,b]$ , then there is a $y$ in $[a,b]$ such that $f(y) \geq f(x)$ for each $x \in [a,b]$ Proof . We already know that $f$ is bounded on $[a,b]$ , which means that the set $$\{ f(x):x\text{ in }[a,b]\}$$ is bounded. This set is obviously not $\varnothing$ , so it has a least upper bound $\alpha$ . Since $\alpha\geqslant f(x)$ for $x$ in $[a,b]$ it suffices to show that $\alpha=f(y)$ for some $y$ in $[a,b]$ . Suppose instead that $\alpha\neq f(y)$ for all $y$ in $[a,b]$ . Then the function $g$ defined by $$g(x)=\dfrac1{\alpha-f(x)},\quad x\text{ in }[a,b]$$ is continuous on $[a,b]$ , since the denominator of the right side is never $0$ . On the other hand, $\alpha$ is the least upper bound of $\{f(x):x\text{ in }[a,b]\}$ ; this means that $$\text{for every $\epsilon\gt0$ there is $x$ in $[a,b]$ with $\alpha-f(x)\lt\epsilon$}.$$ This, in turn, means that $$\text{for every $\epsilon\gt0$ there is $x$ in $[a,b]$ with $g(x)\gt1/\epsilon$}.$$ But this means that $g$ is not bounded on $[a,b]$ , contradicting the previous theorem. $\Rule{0.3em}{0.87em}{0.1em}$ OKay first of all how on earth does one come up with $g(x)$ ? It just feels like it comes out of nowhere. On the other hand what does This means that: for every $\epsilon > 0$ , there is x in $[a,b]$ with $\alpha - f(x) < \epsilon$ even mean? This statement is true, I agree, but I have absolutely no feeling for it. I also do not understand the last line with $g$ . He could have chosen $\epsilon  = \alpha - f(x)$ and be done it no?",['calculus']
384957,Every nonidentity element in a free group $F$ has infinite order,"I'm trying to prove that every nonidentity element in a free group $F$ has infinite order. I'm really new on free groups and I found this subject really strange I couldn't understand it very well yet, I need a help or a hint to solve this question. I attached the definition of free groups: Thanks in advance","['free-groups', 'group-theory', 'abstract-algebra']"
384964,On the existence of a non-negative function on a Banach space whose limit at every point is infinity.,"Does there exist a Banach space $ X $ (possibly non-separable) and a mapping $ F: X \to X $ such that
$$
\forall a \in X: \quad
\lim_{\substack{x \in X \setminus \{ a \} \\ x \to a}} \| F(x) \|_{X} = \infty?
$$ Note: If the Banach space $ X $ is trivial, then the answer is a vacuous affirmative as the zero element, $ 0_{X} $, is the sole element of $ X $ and hence not a limit point. We may thus restrict our attention to only non-trivial Banach spaces.","['general-topology', 'functional-analysis', 'banach-spaces', 'limits']"
384967,Ask a question about an example in a course note on optimization problem with equality constraint,"I have two difficulties on understanding the solution to an example in a course I took this semester on optimization. This example is given to illustrate the usage of Lagrange multiplier method (please see Example 1 in the image below: $${\Large ?}\;\left\{\begin{align*}(x_1-x_2)(x_2-x_3)(x_3-x_1)&=0\\x_1^2+x_2^2+x_3^2&=4\\x_1+x_2+x_3&=1\end{align*}\right.$$
  One solution is $$x_1=x_2,\;x_3=1-2x_1,\;2x_1^2+(1-2x_1)^2=4 \\ \left(\dfrac13+\dfrac{\sqrt{22}}6,\;\dfrac13+\dfrac{\sqrt{22}}6,\;\dfrac13-\dfrac{\sqrt{22}}3\right) \\ \left(\dfrac13-\dfrac{\sqrt{22}}6,\;\dfrac13-\dfrac{\sqrt{22}}6,\;\dfrac13+\dfrac{\sqrt{22}}3\right)$$ and permutations of these. $\underline{\text{Example 2}:}$ $$\begin{array}{ll}\text{minimize}&ax\\\text{subject to}&x_1x_2+x_1x_3+x_2x_3=0\\&x_1^2+x_2^2+x_3^2=1\end{array}$$
  Necessary conditions for optimality: $$\eqalign{&{\Large\Rightarrow}\;\;\;\left\{\begin{array}{l}a_1+\lambda_1(x_2+x_3)+2\lambda_2x_1=0\\a_2+\lambda_1(x_3+x_1)+2\lambda_2x_2=0\\a_3+\lambda_1(x_1+x_2)+2\lambda_2x_3=0\\x_1x_2+x_1x_3+x_2x_3=0\\x_1^2+x_2^2+_3^2=1\end{array}\right.\\
&{\Large\Rightarrow}\;\;\;\left|\begin{matrix}a_1 & x_2+x_3 & x_1 \\ a_2 & x_3+x_1 & x_2 \\ a_3 & x_1+x_2 & x_3\end{matrix}\right|=0\\
&{\Large\Rightarrow}\;\;\;\underbrace{(x_1+x_2+x_3)}_{\neq0}\left|\begin{matrix}a_1 & 1 & x_1 \\ a_2 & 1 & x_2 \\ a_3 & 1 & x_3\end{matrix}\right|=0.}$$ I marked my question with a red ""?"" in the image. I can not understand how these two steps comes out. Could you please help me? I also have the same difficulty for the second example, I hope, after I solve the first example with your help, I can understand the second one myself. But if I still fail to understand it, I'll post it and ask for help here. Sorry for my dullness in math and thank you for any help.","['optimization', 'matrices', 'linear-algebra', 'multivariable-calculus']"
384974,"If $\lim\limits_{x \to \infty} f'(x) = L$ and $\lim\limits_{n \to \infty} f(n) = A$ exists, prove that $L = 0$.","Here is the homework problem I am stuck on: Let $f$ be differentiable on $(0,\infty)$.  If $\lim\limits_{x \to \infty} f'(x) = L$ exists in $\mathbb{R}$ and $\lim\limits_{n \to \infty} f(n) = A$ exists in $\mathbb{R}$, prove that $L = 0$. From the given information, I know that we get to assume: $f$ is continuous at every point $s \in (0,\infty)$. We can now apply the MVT. So far this is what I'm thinking:
First, I think this describes a function which increases towards a horizontal asymptote.
I have created a strictly increasing sequence $\{x_n\} = \{x_1, x_2, \dots, x_n \}$ to serve as the $x$ values in $(0, \infty)$.  This gives me a sequence of intervals basically. I can apply the MVT on each of these intervals, getting a sequence of $c_n \in (x_{n-1}, x_n)$. But I don't see where to go from here.  I am guessing I will need the squeeze theorem later, but there's a gap in between. Perhaps I'm doing something wrong? Thanks for your help.",['real-analysis']
384992,Square integrable function that doesn't go to zero?,"I'm reading through some elementary quantum mechanics textbooks and a few authors mention that ""there exist pathological functions that are square-integrable but do not go to zero at infinity."" ( Griffiths ) I am having trouble coming up with one, does anybody have an example? The only one I can think of is the dirac distribution (which isn't even a function...):","['integration', 'functions']"
385002,"Finding maximum score in a ""bubble pop"" game","Consider the following game: there is a n×n field, where each cell is randomly coloured in one of m colours. Let a group of cells be a set of same-coloured cells s.t. every cell in a group has at least one common edge with another same-coloured cell. A group of s$\geq$k cells can be ""popped"" i.e. removed from the field and a player is assigned a score for it. When a group is removed, the remaining cells are displaced s.t. no cell has an empty cell underneath it (basically, remaining cells ""fall down""). If a column vanishes as a result of popping, every non-empty column to the left of it is displaced one cell to the right. The game ends when there are no groups left on the field. The score is a function of s , and in the end a cumulative score is calculated. The aim of the game is to get maximum cumulative score. The question is if there is an algorithm that allows to calculate maximum possible end score for a given starting arrangement of cells? I suspect it has something to do with graph searching, but I have little experience with such things. Can anyone please suggest how can one approach such kind of a problem? I have also thought about doing something with cellular automata, but I really doubt this approach (however fun it might be).","['graph-theory', 'game-theory', 'discrete-mathematics']"
385006,"if the curvature is constant and positive, then it is on the circunference","I'm trying to prove that if $\alpha(t)=(x(t),y(t))$ is a $C^2$ regular curve $(\alpha'\neq0)$ with constant and positive curvature, then $\alpha$ is on the circumference and if $\alpha$ is on the circumference, then it's curvature is constant. I solved the second part since $\alpha$ is the circunference, then $\alpha(t)=(r\cos\theta,r\sin\theta)$ , so $|\alpha'(t)|=r$ , I need help in the first part. Thanks a lot.","['multivariable-calculus', 'differential-geometry']"
385008,Homogenous measure on the positive real halfline,"Define a measure $\mu\not=0$ on positive real number $\Bbb R_{>0}$ such that for any measurable set $E\subset\Bbb R_{>0}$ and $a\in \Bbb R_{>0} $, we have $\mu(aE)= \mu(E)$, where $aE=[ax;x\in E]$. I am totally blank about this problem. I ponder on it several times but didn't get any idea. This exercise illustrates lebesgue measure's abstract and weird nature. Because if we assume E as a subset of real numbers or any interval, it totally disagrees to fulfill this translation.","['lebesgue-integral', 'measure-theory', 'geometric-measure-theory']"
385013,What is the quotient $\mathbb Z[\sqrt{3}]/(1+2\sqrt{3})$?,"I am currently doing a past paper and it asks the following: Prove that for $I=(1+2\sqrt{3})$ we have $\mathbb Z[\sqrt{3}]/I$ a field with $11$ elements. If I assume standard algebraic number theory then it would only be a few lines: We know $N(I)=|\mathcal O/I|$ where $\mathcal O=\mathbb Z[\sqrt{3}]$. And the norm of a principal ideal is equal to the absolute value of the norm of its generator, i.e. $N(I)=|N(1+2\sqrt{3})|=|1-3\cdot 4|=11$. So $|\mathcal O/I|=11$ and hence $\mathcal O/I$ must be the finite field with $11$ elements. But this paper is for a normal Commutative Algebra module and I cannot assume any of this. Is there any other way to approach this?","['ideals', 'algebraic-number-theory', 'abstract-algebra']"
385015,I know this DE is solvable...,"I need help with a seemingly simple looking diff equ $$
x\frac {d^{2}y} {dx^{2}}+2y=0
$$ $$
\rightarrow \frac {d^{2}y} {dx^{2}}+2\frac {y} {x}=0
$$ $v= (\frac {y} {x})$ substitution isn't working as it eventually shows:
$$
xv''+v'+2v=0
$$ which isn't any easier.  That variable is making my blood pressure go up. I know I'm looking past something stupid.","['ordinary-differential-equations', 'calculus']"
385021,"Maximum likelihood estimators, hypergeometric and binomial","I'm trying to solve a two part problem. The set up is as follows: consider a bag with $\theta$ red marbles and $7-\theta$ blue marbles, with $\theta$ being unknown. Let $x$ denote the number of red marbles found in a sample of 3. If we sample without replacement , what is a maximum likelihood estimator for $\theta$ (the number of red marbles), based on our sample?
If we sample with replacement , what is the maximum likelihood estimator for $\theta$. I'd also like to check if these estimators are unbiased, and which has the smaller variance (I'd expected sampling without replacement to be superior). 1.) Sampling without replacement yields a hypergeometric distribution, with the likelihood function $\large L(\theta)=\frac{\binom{\theta}{x}\binom{7-\theta}{3-x}}{\binom{7}{3}}$. I think what I want to do is look at the ratio $\large \hat{L(\theta)}=\frac{L(\theta)}{L(\theta+1)}$, since this should be increasing up to the point $ \hat{L(\theta)}>1$ and decreasing afterwards, and we can take the MLE to be this point of inflection. A bit of algebra shows this point to be $\frac{8x-3}{3}$. When this fraction is an integer, we can see that $ \hat{L(\theta)}=1$, so $\frac{8x-3}{3}+1$ is also an MLE (it is not unique). If it is not an integer, we take the floor and see that the MLE is $[\frac{8x}{3}]$, where the brackets represent the floor function (since $[\frac{8x-3}{3}]<[\frac{8x}{3}]$, we only have one MLE in this case). 2.) The binomial case is more confusing to me, though perhaps I'm just thinking about it incorrectly. I can easily take the maximum likelihood estimate of P (which is, in this case, $\frac{\theta}{7}$), and show that this MLE is simply $\frac{x}{3}$ (this follows from taking the derivative of the log likelihood and setting it to zero). Then solving the equation $\frac{\theta}{7}=\frac{x}{3}$ yields $\theta=\frac{7x}{3}$ (this result is similar to the hypergeometric result, which is reassuring). It is not, however, a whole number and I can't tell if I should take the floor or the ceiling in this case (or perhaps both provide MLEs)? Finally, assuming that my logic is sound up to this point, I'm not sure how to check whether either of these are unbiased, or how to compare the variances (I think this should be relatively easy - I'm just drawing a blank!) Thanks so much for reading - any help is greatly appreciated!","['statistics', 'parameter-estimation', 'probability-distributions', 'optimization']"
385029,How do I prove the arithmetic-geometric mean inequality?,"I am following along with this bare-bones proof of the arithmetic-geometric mean inequality with two real numbers. I'm having difficulty understanding the logic behind this step:
$$
\frac{a}{2}+\frac{a}{2}< \frac{b}{2}+\frac{a}{2}\Rightarrow a< \frac{b+a}{2}
$$ How is the step of adding $\frac{a}{2}$ to both sides valid? Also, if you have a better/easier way of proving this, please let me know. Thanks!","['inequality', 'discrete-mathematics']"
385039,Abstract algebra T/F questions.,"This is from our review and my study group is wondering if we can get some feedback on our progress: $1$. The symmetric group $S_3$ only has two proper normal subgroups. True, because $e \subset A_3 \subset S_3$. $2$. Every abelian group is cyclic. False, every cyclic group is abelian but the converse is not true OR a counter example is a Klein-4 group. $3$. The ideal generated by $x^2+1$ in $\mathbb{R}[x]$ is maximal. True. Every ideal generated by irreducible element in principal domain is maximal. $4$. The order of the cycle $(a_1, \cdots, a_k) \in S_n$ is $k$. False. The order should be $k-1$. $5$. Let $f: R \to S$ be a ring homomorphism, and $I \subset S$ a maximal ideal. Then $f^{-1}(I)$ is maximal. True. Because isomorphism preserves ring properties (honestly no idea how to do this one).","['ring-theory', 'group-theory', 'abstract-algebra']"
385044,Construction of a join function of infinitely many derivatives.,"I am curious if anyone can construct a function made up of more than one e.g. $|x| = x, x\geq 0$ and $-x, x\leq 0$. However I would require that it must be infinitely differentiable and in the above case of $|x|$ it must be infinitely differentiable at 0. I suspect that we can't find one but if anyone has an example or a rigorous explanation as to why it doesn't work it would be grateful.",['analysis']
385046,What needs to be true of $f$ for $f_{xy}=f_{yx}$?,"What conditions does a function $f$ have to fulfill in order that:
$\frac{\partial}{\partial x}(\frac{\partial f}{\partial y})=\frac{\partial}{\partial y}(\frac{\partial f}{\partial x}) $? I am trying to prove something else, and I have just got it down to this bit, which is usually true, but I'm not sure what was to be true of $f$ for this to be true. Continuity? Differentiable?",['calculus']
385058,"Looking for a differentiable function which behaves somewhat like $\min(x,1)$","Is there a differentiable function $f : [0,2] \rightarrow [0,1]$ such that $f(x) = 0$ iff $x=0$ and $f(x) = 1$ iff $x \in [1,2]$? What about $n$ times differentiable for any $n$, or infinitely differentiable? Thank you!","['functions', 'calculus', 'real-analysis']"
385064,Nilpotent matrices with same minimal polynomial and nullity,"From Hoffman and Kunze. Let $N_1$ and $N_2$ be 6 X 6 nilpotent matrices over the field F. Suppose that
  $N_1$ and $N_2$ have the same minimal polynomial and the same nullity. Prove that
  $N_1$ and $N_2$ are similar. Show that this is not true for 7 X 7 nilpotent matrices. Right so nilpotent matrices have $N^k= 0$ for some k. Since these have the same nullity and minimal polynomial $N_1^k = N_2^k = 0$ from some k right? The same minimal polynomial implies the same characteristic values but thats not enough to say they have the same jordan form and are thus similar right? and how would I get started in proving this breaks for 7x7 nilpotent matrices? Thanks in advance for any assistance.","['matrices', 'linear-algebra']"
385067,Closed form for $\sum_{n=1}^\infty\frac{(-1)^n n^4 H_n}{2^n}$,"Please help me to find a closed form for the sum $$\sum_{n=1}^\infty\frac{(-1)^n n^4 H_n}{2^n},$$ where $H_n$ are harmonic numbers : $$H_n=\sum_{k=1}^n\frac{1}{k}=\frac{\Gamma'(n+1)}{n!}+\gamma.$$","['closed-form', 'gamma-function', 'summation', 'sequences-and-series']"
385069,Perron's formula (Passing a limit under the integral),"I want to understand why assuming that $\sum_{n \ge 1} \frac{a_n}{n^s}$ converges uniformly for $\mathrm{Re}(s) > \sigma > 0$ with $c > \sigma$ implies that
$$
\sum_{n \le x} \, \!\!^* a_n = \frac 1{2\pi i}\int_{c-i\infty}^{c+i\infty} \sum_{n \ge 1}  \frac{a_n}{n^s} \frac{x^s}{s} \, ds. 
$$
I've managed to show that for $c > 0$,
$$
\frac 1{2\pi i}\int_{c-i \infty}^{c + i \infty} \frac{y^s}s \, ds = \begin{cases}
0 & \text{ if } 0 < y < 1 \\
1/2 & \text{ if } y = 1 \\
1 & \text{ if } y > 1 \\
\end{cases}
$$
so we can write
$$
\sum_{n \le x} \, \!\!^* a_n = \frac 1{2\pi i} \sum_{n \ge 1} \int_{c-i\infty}^{c+i\infty} a_n \left( \frac xn \right)^s \frac{ds}s \overset{!}{=} \frac 1{2\pi i}\int_{c-i\infty}^{c+i\infty} \sum_{n\ge 1} \frac{a_n}{n^s} \frac{x^s}s \, ds.
$$
But that $!$ that I put there means I don't understand why the sum can go under the integral sign. Any ideas about that part? Thanks.","['analytic-number-theory', 'complex-analysis']"
385083,A problem on linear algebra,"If $M$ is a $3 \times 3$ matrix such that
$$[ 0 ~~1 ~~2 ]M = [ 1 ~~0~~ 0 ] \text{  and  } [ 3~~ 4 ~~5 ]M = [ 0 ~~1 ~~0 ]$$
then what is the value of $[ 6 ~~7 ~~8 ]M$ ? I guess some matrix property needs to be used.",['linear-algebra']
385093,Spanning a Vector space of matrices by symmetric and skew symmetric matrices.,"How do I span a vector space of $4\times 4$ matrices with real values by symmetric and skew symmetric matrices? The basis of vector space of $4\times 4$ matrices has 16 elements, each containing one 1 and fifteen 0's. All I have to figure out is finding a combination of symmetric and skew symmetric matrices to get each of these elements. Please just provide a hint. Thank you in advance.",['linear-algebra']
385094,Closed form for $\sum_{n=1}^\infty\frac{(-1)^n n^a H_n}{2^n}$,"Is there a closed form for the sum $$\sum_{n=1}^\infty\frac{(-1)^n n^a H_n}{2^n},$$ where $H_n$ are harmonic numbers : $$H_n=\sum_{k=1}^n\frac{1}{k}=\frac{\Gamma'(n+1)}{n!}+\gamma.$$ This is a generalization of my previous question that was just a special case for $a=4$.","['closed-form', 'gamma-function', 'summation', 'sequences-and-series']"
385109,Question about Conditional Expectation,"I have a seemingly trivial question regarding conditional expectation. Consider $x$ and $y$ be two integrable random variables on Probability space (X, $\Sigma$, $P$) such that $$E(X|Y) =_{a.s} Y$$ and $$E(Y|X) =_{a.s} X$$
Show that $$X=_{a.s} Y$$ The thing looks like a simple proof result, but I don't know how to move on after showing that$$\int_{B} Y = \int_{B} X$$ for all $B \in \sigma(x)$ and $B \in \sigma(y)$ Now any hint on how to proceed? Thank you so much in advance","['probability-theory', 'conditional-probability']"
385127,"In a metric $(X,d)$, prove that for each subset $A$, $x\in\bar{A}$ if and only if $d(x,A)=0.$","In a metric space $(X,d)$, prove that for each subset $A$, $x\in\bar A$ if and only if $d(x,A)=0$ I feel like this isn't necessarily true. For example, let $X$ equal the reals and $A$ be some open subset of $X$, let's say $(0,1)$. Then $0.5$ is an element of $\bar{A}$, but $d(x,A) = d(0.5,0) \neq 0$ This question seems simple enough; I don't know why it's giving me such trouble.","['general-topology', 'metric-spaces']"
385129,Proof of complement of intersection defined using an arbitrary set.,"I hate asking questions like these (ones where I have no idea what it is talking about). Let $ \xi$ be a  collection of sets and define 
  $$I= \bigcap \{ F|F \in \xi \}\quad\text{and}\quad U= \bigcup \{ F|F \in \xi \}.$$
  Prove that $I^{c}= \bigcup \{ F^{c}|F \in \xi \}$ and $U= \bigcap \{ F^{c}|F \in \xi \}$ are true. This looks a lot like just proving it for the basic case (intersections of sets and their complement, and union of 2 sets and their complement) but the language has made me a bit lost. Homework problem so please just give help not a complete answer thx.",['elementary-set-theory']
385187,Monotonicity of functions,"Let $f(x) = xe^{x^2} + e^{-x^2}$ I'd like to prove that this function increases monotonically in the interval $(0,1)$. I was able to do it by taking the derivative and proving it was greater than zero.
(though it took me quite some time to do that) I wanted to know if there was any other more elegant method to do the same.",['calculus']
385194,What can we say about the size of $HK\cap KH$ when $HK\neq KH$?,"If $G$ is a finite group, and $H$, $K$ are proper subgroups of $G$, then it is not necessary that $HK=KH$. But, these two subsets have same size. The question I would like to ask, then,  is If $HK\neq KH$, then what can we say about the size of $HK\cap KH$? (Note that $H\cup K\subseteq HK\cap KH$.)","['finite-groups', 'group-theory', 'abstract-algebra', 'combinatorics']"
385197,How many elements of order $7$ are there in a group of order $28$ without Sylow's theorem?,How many elements of order $7$ are there in a group of order $28~?$ I need to prove this result without using the Sylow's Theorem.By Sylow's Theorem it has only one subgroup and the answer becomes $~6$ . But in the book the problem is in the Cauchy's Theorem chapter and I want to prove it by this only.Can someone help me please.,"['abstract-algebra', 'sylow-theory', 'finite-groups', 'alternative-proof', 'group-theory']"
385199,Are there any properties of the diag operator?,"Let $u$ and $v$ be a column vector of same dimension. 1.) Can anyone give some properties about the operations of function, such as $\text{diag}(u)+\text{diag}(v)=\text{diag}(u+v)$? 2.) Is there any mathematical representation  to express the function diag? Thanks a lot.",['matrices']
385212,Primary decomposition of power of a prime.,"Let $R$ be a commutative Noetherian ring with unit. Suppose $P$ is a prime ideal that is not maximal. How can we go about finding a normal (reduced) primary decomposition of the power of $P$, say a normal decomposition for $P^2$ or $P^3$?","['commutative-algebra', 'algebraic-geometry']"
385228,Does Real Eigenvalues mean it is an hermitian Matrix,"Let us say I know that a given $N\times N$ matrix has all its eigenvalues as real, does it mean, it is hermitian. How do I prove (or disprove) that?",['linear-algebra']
385237,Find a parametric formula to $n=(a^2+1)(b^2+1)$ in three distinct ways,"I mentioned that the number $4420$ is expressible in the form $(a^2+1)(b^2+1)$ (where $a,b$ are positive integers) in three distinct ways,here is a list of these numbers:
$$4420=(1^2+1)(47^2+1)=(3^2+1)(21^2+1)=(5^2+1)(13^2+1)$$
$$26650=(2^2+1)(73^2+1)=(5^2+1)(32^2+1)=(9^2+1)(18^2+1)$$
$$……$$
$$16567585450=(13^2+1)(9872^2+1)=(47^2+1)(2738^2+1)=(278^2+1)(463^2+1)$$ I think about this problem from here: A question on elementary number theory Here is a relative problem ： http://www.mathpages.com/home/kmath275.htm So I wonder are there some parametric formulas for sets of these numbers(or at least for part of them)?Thanks in advance!","['parametric', 'elementary-number-theory', 'number-theory']"
385256,Question on Showing points of discontinuities of a function are removable (or not),"The question is as follows: Given function: $F(x,y)=\frac{x + 2y}{sin(x+y) - cos(x-y)}$ Tasks: a/ Find points of discontinuities b/ Decide if the points (of
  discontinuities) from part a are removable Here is my work so far: (1) For part a, I think the points of discontinuities should have form $(0, \frac{\pi}{4} + n\pi)$ or $(\frac{\pi}{4} + n\pi, 0)$ , since they make the denominator undefined.  For convenience of part b, I choose to specifically deal with the point $(0, \frac{\pi}{4})$ (2) Recall definition: A point of discontinuity $x_0$ is removable if the limits of the function under certain path are equal to each other, as they are ""close"" to $x_0$.  In particular, if the function is 1 dimensional, we get the notion of ""left"" and ""right"" limits.  But here we talk about paths of any possible direction.  However, these limits are not equal to $f(x_0)$, which can be defined or undefined. (3) I'm having trouble of ""finding"" such paths @_@ I come across with these two, by fix x-coordinate and vary y-coordinate:
$F(x, x^2 - \frac{\pi}{4})$
and $F(x, x^2 - x - \frac{\pi}{4})$
They both have limit to be $\frac{\pi}{2\sqrt(2)}$ as x approaches 0 (by my calculation) But what I can say about these results?  I feel that discontinuities of $F(x,y)$ should be not removable, but I don't know if my thought is correct. Would someone please help me on this question? Thank you in advance ^^",['analysis']
385262,To calculate $ \lim_{n\to \infty} \Big(\sum_{m=1}^r (a_m)^n\Big)^{1/n}$,"Let $a_1 , a_2 , ..., a_r$ be positive real numbers such that $a_1 > a_2 > ... > a_r$. Without any more information given , can we exactly calculate $$ \lim_{n\to \infty} \Bigg(\sum_{m=1}^r (a_m)^n\Bigg)^{1/n}\ ?$$","['sequences-and-series', 'real-analysis', 'limits']"
385300,Property of partial traces,"Consider the Kronecker product of $A \in M_m, B \in M_n$:
$A \otimes B = \left( \begin{matrix} a_{11}B&...&a_{1m}B\\ \vdots&\ddots\\a_{m1}B&...&a_{mm}B \end{matrix} \right)$ $A \otimes B$ can also be thought of as an $n \times n$ block matrix. This representation can be seen as $\left( \begin{matrix} T_{11}&...&T_{1n}\\ \vdots&\ddots\\T_{n1}&...&T_{nn} \end{matrix} \right)$, where each $T$ entry in the block is an $m \times m$ matrix. If we define the two partial traces of a Kronecker product between two matrices as follows: $Tr_1(A \otimes B) = \sum_{i=1}^n T_{ii}$. We have $Tr_1 \in M_m$. $Tr_2(A \otimes B) = \left( \begin{matrix} Tr(T_{11})&...&Tr(T_{1n})\\ \vdots&\ddots\\Tr(T_{n1})&...&Tr(T_{nn}) \end{matrix} \right)$. We have $Tr_2 \in M_n$. How does one show that for any $X \geq 0$, $Im(Tr_2(X) \otimes Tr_1(X)) \supset Im(X)$ (where $X$ is Hermitian and has the form $A \otimes B$ for some $A,B$)?","['operator-algebras', 'tensor-products', 'linear-algebra', 'trace']"
385301,Contour integral with branch cut,"This is a question based on the method here: http://en.wikipedia.org/wiki/Methods_of_contour_integration#Example_.28V.29_.E2.80.93_the_square_of_the_logarithm The author chose a contour which requires a bit of a ""magical"" replacement of the original function $\displaystyle f(x)=\frac{\log(x)}{(1+x^2)^2}$ with analysis of $\displaystyle f(z)=\left(\frac{\log(z)}{(1+z^2)}\right)^2$, the need for which becomes apparent later I chose to instead pick a contour that only involves the upper half of the figure drawn, discarding the lower line N and cutting the curve through with the section of the real line $\mathbb R^+$ Numerically I obtain the same result:
\begin{align}
\int_\gamma f(z)dz &= \int_{\small M}+\int_{\small R^+} \\
&=\int_0^\infty\frac{\log(-x+i\epsilon)}{(1+(-x+i\epsilon)^2)^2}dx+\int_0^\infty f(x)dx \\
2\pi i\cdot\operatorname{Res}[f(z),i]&=\int_0^\infty\frac{\log(x)+i\pi}{\left(1+x^2\right)^2}dx+\int_0^\infty f(x)dx&\epsilon\to0 \\
2\pi i\cdot (\frac18(\pi+2i))&=\int_0^\infty\frac{i\pi}{\left(1+x^2\right)^2}dx+2\int_0^\infty f(x) dx\\
-\frac\pi2+\frac{i\pi^2}4&=\frac{i\pi^2}4+2\int_0^\infty f(x) dx\\
\int_0^\infty f(x)dx&=-\frac\pi4
\end{align} Is it just coincidence that I have the same result? Was there any flaw in my method? If not, why did the author pick a contour that requires a nonintuitive analysis which ""as it turns out ... is a multiple of the initial integral that we wish to calculate?""","['complex-analysis', 'contour-integration']"
385313,Lemma of Whitehead,"this is the lemma of Whitehead And i really don't understand the proof How to see that $k$ is well defined (i.e how to write an element from $X\cup_{\varphi_i}e^{\lambda} , i=0,1$ ) and how to write $l$ ? Please Thank you","['definition', 'homotopy-theory', 'algebraic-topology', 'analysis']"
385318,A question on Tight probability measures (regular measure),"This is somewhat a basic question, but I'm having difficulty proceeding with a certain part of the proof. I was reading Billingsley ""Convergence of Probability Measures"", and I encountered the following question: Question: Given a metric space $X$ and $\mathscr{B}$ the Borel sigma algebra, prove that a probability measure $P$ on $X$ is tight iff 
$$\forall A \in \mathscr{B},\quad \sup \{P(K): K\subset A, K \mbox{ compact}\} = P(A)$$ My Proof: ($\Rightarrow$)
Put $A=X$. Then we have
$$1 = P(X) = \sup \{P(K): K\subset X, K \mbox{ compact}\}$$
By definition of sup, we get $\forall \epsilon > 0$, $\exists K$ compact such that
$$P(K) \geq 1-\epsilon$$ Thus P is tight. ($\Leftarrow$) Billingsley suggests using the following theorem: Probability measures on metric spaces are regular. That is 
$$\forall A \in \mathscr{B}, \forall \epsilon > 0, \exists F \mbox{  closed}, G \mbox{  open such that}$$
$$F \subset A \subset G, \quad P(G \setminus F) < \epsilon$$ I do not know how to use compactness here. I reasoned that if I could prove that $\forall \epsilon > 0$, $\exists K \subset A$ compact such that $P(A\setminus K) < \epsilon$, I would be done. Since the compact sets in ""tightness"", needn't be subsets of A, I don't know how to use it. I was able to show the easy inequality which is: $$\sup \{P(K): K\subset A, K \mbox{ compact}\} \leq P(A)$$
(since $K\subset A$) I would appreciate any ideas, hints and tips (if not answers) to this. References are also welcome. I searched for ""Tight Regular Measures"" and ""Tight Probability"" but to no useful results.","['general-topology', 'measure-theory', 'metric-spaces', 'probability-theory']"
385322,deg functions and maps,"For any map $f$ between curves $C_1$ and $C_2$, one defines $\mathrm{deg}(f) = [K(C_1) : f^*K(C_2)]$ as given in ""The Arithmetic of Elliptic Curves"" by Silverman. 
For algebraic functions on elliptic curves it is possible to define the degree as the number of poles (with multiplicities). Why is this the same? Can you give a reference?","['algebraic-geometry', 'reference-request', 'algebraic-curves', 'elliptic-curves']"
385339,Prove that a sum converges to a trigonometric expression,$$2^n \cos \left (\frac{n \pi}{2} \right )=\sum_{k=0}^{n} (-1)^k \binom{2n}{2k}$$ I expanded the LHS and got $$\binom{2n}{0}-\binom{2n}{2}+\binom{2n}{4}-\binom{2n}{6}+\cdots+(-1)^{n}\binom{2n}{2n}$$ Is this a telescoping series? Where can I go from here?,"['trigonometry', 'sequences-and-series', 'binomial-coefficients']"
385343,How to show this tridiagonal matrix has eigenvalues $\lambda_{j}=4\sin^2{\frac{j\pi}{2(n+1)}}$?,"Show that the $n\times n$ tridiagonal matrix 
$$A=\begin{bmatrix}
2&-1&0&0&0\\
-1&2&-1&0&0\\
\vdots&\ddots&\ddots&\ddots&\vdots\\
0&0&-1&2&-1\\
0&0&0&-1&2
\end{bmatrix}
$$ has the eigenvalues
$$\lambda_{j}=4\sin^2{\dfrac{j\pi}{2(n+1)}},j=1,2,\cdots,n$$","['tridiagonal-matrices', 'eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'toeplitz-matrices']"
385362,"Do ""cut set"" and ""edge cut"" mean the same thing?","The definitions I have are: A cut set of a graph $G$ induced by a partition of $G$'s vertices
  into sets $X$ and $Y$ is the set of all edges with one endpoint in $X$
  and another endpoint in $Y$. An edge cut of a connected graph $G$ is a set $S$ of $G$'s edges
  such that $G$-$S$ is disconected and $G$-$S$' is connected for any
  proper subset $S$' of $S$. They do not appear to mean the same thing, yet my course materials refer to both as ""cuts"" of G. So please help me understand: do the ""edge cut"" and ""cut set"" of a graph refer to the same set?","['graph-theory', 'network-flow', 'discrete-mathematics', 'discrete-optimization']"
385380,Why is the differential of a map between manifolds a map between the tangent spaces?,"In the books that I have seen, given a smooth map $\phi: M \rightarrow N$ where $N$ and $M$ are manifolds, the differential at a point $x$ is defined as $d \phi_x: T_x M \rightarrow T_x N$ . Why is it the case that the differential is defined as a map of the tangent spaces? Is it possible to show that this is true taking, for example, the definition of the tangent space of $M$ at $x$ to be $(dF_x)^{-1}(0)$ if $M=F^{-1}(0)$ ? For example, the problem I am working on treats $SO(n, \mathbb{R})$ as a manifold of $M(n, \mathbb{R})$ . Given $w_1, \ldots w_n \in SO(n, \mathbb{R})$ I define the function \begin{align}
\varphi: SO(n, \mathbb{R}) &\rightarrow SO(n, \mathbb{R})\\
g & \mapsto gw_1g^{-1}w_1^{-1} \ldots g w_n g^{-1}w_n^{-1}
\end{align} I need to show that $d \varphi_I$ (where $I$ is the identity matrix) is a map from $SO(n, \mathbb{R})$ to itself where $SO(n, \mathbb{R})$ is the set of anti-symmetric matrices and is the tangent space of $SO(n, \mathbb{R})$ at $I$ . Thanks in advance.","['manifolds', 'differential-geometry']"
385394,"Are edge cuts, vertex cuts, and cut sets all variously called ""cuts""?","I've seen ""cut"" being used to refer to all three, in different places, and sometimes in the same book. Which does ""cut"" most commonly refer to? p.s. I am aware that ""cut"" itself can be defined to refer to a certain partitioning, but here I am only interested in a cut as a set.","['network-flow', 'discrete-mathematics', 'definition', 'graph-theory', 'discrete-optimization']"
385414,Prove that if $A$ is symmetric and has a LU-decomposition then $A=LDU' \Rightarrow U'=L^T$,"Suppose the matriz $A$ has a LU-decomposition, in other words, suppose there exists matrices $L$ and $U$ such that $A=LU$ where $L$ is lower triangular and $U$ is upper triangular. We can to prove that $A$ has a LDU'-decomposition, where $D$ is a diagonal (to do so, put $d_{ii}=u_{ii}$ and $u'_{kj}=u_{kj}/u_{kk}$). Prove that if $A$ is symmetric then $A=LDU' \Rightarrow  U'=L^T$, where $L^T$ is the transpose of matrix $L$. Yes, $A$ is invertible. Therfore, $LDU'=U'^TDL^T\Rightarrow U'=L^T$. Here is the solution (question 9) .","['matrices', 'numerical-methods']"
385417,How do I sum two Poisson processes?,"If we have a Poisson Process $Y$ with intensity $\lambda$ and a Poisson Process $X$ with intensity $\mu$, where $X$ and $Y$ are two independent Poisson processes. How can I find the process $Z=Y+X$? I know it should involve convolutions in some way but I dont know how to construct it!","['statistics', 'probability-distributions']"
385431,Uniqueness of distribution with moments $M_n$ if $\limsup_{n\to\infty} \frac{1}{n}\sqrt[n]{M_n}$ finite,"There's a theorem which states that the moments, i.e. $M_n  = \mathbb{E}\left(X^n\right)$, of a distribution uniquely identify the distribution if $$
  R := \left(\limsup_{n\to\infty} \frac{1}{n}\sqrt[n]{M_n}\right)^{-1} > 0 \text{.}
$$ The proof for this that I'm looking at argues this by observing that this condition implies the convergence of the following series expansion of the moment-generating function $$
  M(t) = \sum_{n=0}^\infty M_n \frac{t^n}{n!}
$$
on $(-R,R)$ (note that $\sqrt[n]{n!} \leq n$). It then asserts that since $\phi(t) = M(it)$, where $\phi$ is the characteristic function and $M$ the moment-generating function of some random variable $X$, this defines the characteristik function, which is known to define the distribution uniquely. My problems with that reasoning is that as far as I can see $M$ only defines $\phi$ on $M$'s radius of convergence, i.e. $(-R,R)$. Who's to say that there couldn't be two different extensions $\phi_1$,$\phi_2$ which both agree with $M(it)$ on $(-R,R)$? If I knew $\phi$ to be analytically extendable to the simply connected region $$
   \{t + i\delta\,:\, |\delta| < \epsilon, t \in \mathbb{R}\}
$$ (i.e., a stripe around the real axis), then such an extension would be unique, and that would preclude the possibility of $\phi_1 \neq \phi_2$. But I don't see why such an extension would need to exist. Since I'm starting from (except for the growth condition) arbitrary moments, a priori I don't even know that there's any distribution with those moments. And even if I did, I'd only know that there's some $\phi'$ which agrees with $\phi$ on $[0,R)$, not necessarily on $[0,R)\times(-\epsilon,\epsilon)$. Can anyone shed some light on this? I have the feeling that I'm overlooking some crucial property of $\phi$, but I can't seem to find it.","['power-series', 'fourier-analysis', 'probability-theory', 'complex-analysis', 'characteristic-functions']"
385435,Is $z\cdot\sin(z)$ (function from $\mathbb{C} \to \mathbb{C}$) surjective?,"We know by Picard's theorem that any entire function is either constant, or surjective or misses only 1 point. It is easy to observe that $\sin{z}$, $\cos{z}$ are surjective. Is $f \cdot g$ surjective if $f$ and $g$ are entire and surjective?
It is indeed true when $f$ and $g$ are polynomials. Does there a characterization of entire functions missing a point and surjective entire functions? Or any relation between them?",['complex-analysis']
385448,Can somebody provide an explanation to the formula of a one elementary integral?,"Here is the formula: $$
\int{\frac{dx}{x}} = \ln{|x|} + C
$$ In my textbook it is given without proof, so I have a little confusion here. From the definition of integral this equality must be true: $$
(\ln|x| + C)` = \frac{1}{x}
$$ But I failed to derive it. Cause according to the rule of differentiation of a complex funtion $(f_1(f_2(x)))` = f_1`(f_2(x))*f_2`(x) $ (if I understand it right) the derivative of $\ln|x| + C$ is: $$
(\ln|x| + C)` = (\ln|x|)` + C` = \frac{1}{|x|} * |x|` + 0
$$ And this is confirmed by the Wolfram Mathematica: So this is obviously not $\frac{1}{x}$. Can somebody provide an explanation for this problem? My appreciation.","['self-learning', 'integration', 'derivatives']"
385457,Showing equality in Cauchy-Schwarz inequality,"With $\mathbf{u,v}$ being vectors in $\mathbb{R}^n$ euclidean space, the Cauchy–Schwarz inequality is $$
{\left(\sum_{i=1}^{n} u_i v_i\right)}^2 \leq \left(\sum_{i=1}^{n} u_i^2\right)\left(\sum_{i=1}^{n} v_i^2\right)
$$ further given that $\mathbf{u}=\lambda\mathbf{v}$, the csi looks like the following: $$
{\left(\sum_{i=1}^{n} \lambda v_i v_i\right)}^2 \leq \left(\sum_{i=1}^{n} (\lambda v_i)^2\right)\left(\sum_{i=1}^{n} v_i^2\right)
$$ With equality applying in the Cauchy-Schwarz inequality only if $\mathbf{u,v}$ are linear dependent, how do I show that equality is given in this case? A start would be enough, I'm quite new to linear algebra Edit: Thanks so far! Rewriting the last line - following your advice - I get the following $$
{\lambda^2\left(\sum_{i=1}^{n} v_i^2\right)}^2 \leq \lambda^2\sum_{i=1}^{n} v_i^2\sum_{i=1}^{n} v_i^2
$$ Okay I'm not sure about the following, so make sure you have foul fruit nearby to throw at me: Canceling $\lambda^2$ this results in $$
{\left(\sum_{i=1}^{n} v_i^2\right)}^2 \leq \sum_{i=1}^{n} v_i^2\sum_{i=1}^{n} v_i^2
$$ with the inquality being wrong, equality applies... is that evidence enough?","['linear-algebra', 'inequality']"
385462,Chernoff bound proof using Markov,"Does anyone familiar with the following format of Chernoff bound: $$
Pr\left(\frac{1}{n}\sum\limits_{i=1}^n X_i \gt T\right ) \le \inf_{\gamma \gt 0}{\left (  \frac{E[e^{\gamma X_i}]}{e^{\gamma T}} \right )}^n,
$$ where $X_i$ are i.i.d.
How can this format be evaluated from Markov bound? Thanks","['statistics', 'inequality', 'probability']"
385469,Why can I write the curve shortening flow system as..,"Consider the family of curves $$\gamma:S^1\times [0, T)\rightarrow \mathbb R^2, \gamma(u, t)=(x(u, t), y(u, t)),$$ where $u$ parametrizes the trace of the curve and $t$ parametrizes which curve is being considered. Can anyone explain me why I can write the system $$\frac{\partial\gamma}{\partial t}(u, t)=k(u, t)N(u, t),$$ as $$\frac{\partial}{\partial t}\left[\begin{array}{c} x\\ y\end{array}\right]=\frac{1}{\sqrt{x_u^2+y_u^2}}\left[\begin{array}{cc}y_u^2&-x_uy_u\\ -x_uy_u&x_u^2 \end{array}\right]\left[\begin{array}{c} x_{uu}\\ y_{uu}\end{array}\right].$$ Here $k(u, t)$ is the curvature and $N(u, t)$ is the unit inner normal vector. A curve $\gamma$ satisfying the considered equation with an additional initial value is said to be evoluting by the curve shortening flow. I need to write that equation in the matrix form for discussing the parabolic nature of the flow so that I could apply the parabolic theory of PDE for assuring short time existence for it..","['plane-curves', 'partial-differential-equations', 'differential-geometry', 'mean-curvature-flows']"
385476,Inequalities between Probability and expectation,"I would like to prove the following When $a>0$ and X is a non-negative and measurable function $\frac{E[X]}{a}\ge \sum _{ n\in N  }^{  }{ P(X>an) } \ge \frac { 1 }{ a } \left( E[X]-a \right) $ I know that $\sum _{ n\in N }^{  }{ P(X>an) } $ $=\sum _{ k\in N }^{  }{ kP\left( ka<X\le (k+1)a \right)}$ $=\sum _{ k\in N }^{  }{ kE\left( { 1 }_{ (ka,(k+1)a] }\left( X \right)  \right)  } $ $=\sum _{ k\in N }^{  }{ E\left( k{ 1 }_{ (ka,(k+1)a] }\left( X \right)  \right)  } $ If it is without the summation, I know that $E\left( k{ 1 }_{ (k,\infty ) }\left( X \right)  \right) \le E\left[ X \right] $
because $k{ 1 }_{ (k,\infty ) }\left( x \right) \le x$ I'm quite stuck here. It seems that I'm kind of there but I'm missing something important. Thanks a lot!!",['probability-theory']
385477,Question on closed sets,"If $A,B\subset\mathbb{R}^n$ are closed. Let 
$$M=\{p\in\mathbb{R}^n\,:\,\exists\,t\in[0,1],a\in A,b\in B\;\mathrm{s.t.}\;p=t\cdot a+(1-t)\cdot b\}$$
Is $M$ closed? Why?",['general-topology']
385478,"Spectral Theorem for bounded compact, self-adjoint operators as corollary of Hilbert-Schmidt theorem","I'm following Debnath and Mikusinksi's ""Introduction to Hilbert Spaces with Applications"" and am trying to understand how the spectral theorem for compact self-adjoint operators is a corollary of the Hilbert-Schmidt theorem. Here is the Hilbert-Schmidt theorem: Theorem (Hilbert-Schmidt) Let $T:H\to H$ be a bounded,
compact, self-adjoint linear operator on a complex Hilbert space $H$.
Then there exists an orthonormal set of eigenvectors $\left(w_{n}\right)$
corresponding to non-zero eigenvalues $\left(\lambda_{n}\right)$
s.t. for each $x\in H$ we can write unique 
$$
x=\sum_{n=1}^{\infty}a_{n}w_{n}+v
$$
 for some $a_{n}\in\mathbb{C}$ and $v\in\mathscr{N}\left(T\right)$. ...and here is the spectral theorem that I wish to prove: Spectral Theorem Let $T$ be a bounded, compact, self-adjoint
linear operator on a complex Hilbert space $H$. Then $H$ has an
orthonormal basis $\left\{ v_{n}\right\} _{n\in\mathbb{N}}$ consisting
of eigenvectors of $T$. Furthermore, 
$$
Tx=\sum_{k=1}^{\infty}\lambda_{k}\left\langle x,v_{k}\right\rangle v_{k}
$$
 where $\lambda_{k}$ is the eigenvalue associated with eigenvector
$v_{k}$. Could anyone help me to understand how this comes about from the Hilbert-Schmidt theorem? The explanation in the textbook is not helpful to me. The explanation is as follows: ""Debnath & Mikusinski's proof of the spectral theorem goes as follows: ""To obtain a complete orthonormal system $\left\{v_1 , v_2 , \ldots \right\}$, we need to complement the system $\left\{u_1, u_2, \ldots \right\}$, defined in the proof of the Hilbert-Schmidt theorem, with an arbitrary orthonormal basis of $\mathscr N (T)$. The eigenvalues corresponding to the vectors that form $\mathscr N (T)$ are all equal zero. The desired equality follows from the continuity of $A$."" I can post up the proof of the Hilbert-Schmidt theorem if it is helpful?","['spectral-theory', 'hilbert-spaces', 'functional-analysis']"
385518,Locally finite + quasi-compact versus finite,"Let $f: X \rightarrow Y$ be a morphism of, say, locally noetherian schemes.
Suppose that $f$ is locally finite (that is for every open affine subset $U= spec A$ of $Y$,
$f^{-1}(U)$ can be covered by open affine subsets $V_i=spec B_i$ such that
each $B_i$ is a finitely generated $A$-module), and quasi-compact (so in the above one can assume that there are finitely many $V_i$ as abovecovering $f^{-1}(U)$). Then does it imply that $f$ is finite? I don't think that's true, but I'd like a counter-example (or if it is true, a proof or reference). Thanks.",['algebraic-geometry']
385520,Solve $\;\;y+(x^2y^3-x)y'=0;\;\;y(4)=1$,"I wish to solve $$\;y(x)+(x^2y(x)^3-x)y(x)'=0;\quad y(4)=1$$ It is supposed to be by multiplying by an integrand factor to turn it into an exact equation, but wolfram alpha gives these solutions which don't look so good. Is this problem OK or is there probably something wrong with it? If it is ok, how can I solve it?",['ordinary-differential-equations']
385544,Evaluate $\int \frac {\operatorname d\!x} {2x \sqrt{1-x}\sqrt{2-x + \sqrt{1-x}}}$,"$$\int \dfrac {\operatorname d\!x} {2x \sqrt{1-x}\sqrt{2-x + \sqrt{1-x}}}$$ Hey there, I've got this complicated integral to evaluate, but I don't know how to go about. I have tried making two substitutions: $ t^2 = 1 - x $ $ x = \sin^2\theta $ But both gave another complicated integral to evaluate: $$ \int \dfrac {\operatorname d\!t} {(t^2-1)\sqrt{ t^2 + t + 1 }} $$ I tried to get the answer for this one using wolfram alpha, but it gave a HUGE , simply HUGE solution. I also tried to get the solution for the original question via wolfram alpha, but it timed out. Any ideas?","['calculus', 'integration', 'indefinite-integrals']"
385574,Summation of logs,Are there any useful identities for quickly calculating the sum of consecutive logs? For example $\sum_{k=1}^{N} log(k)$ or something to this effect. I should add that I am writing code to do this (as opposed to doing this on a calculator) so N can be very large.,"['logarithms', 'summation', 'number-theory']"
385582,Another trigonometric proof...?,"... sigh..another problem how shall I prove the following?
$$ {\cot A\over1- \tan A} + {\tan A \over 1- \cot A} = 1 + \tan A + \cot A$$ so what now? the following's what I've done:
$$\cot A - \cot^2 A + \tan A- \tan^2 A \over 2 - \tan A - \cot A$$",['trigonometry']
