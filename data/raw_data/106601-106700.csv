question_id,title,body,tags
1517237,Is there a name for a monoid with a distinguished absorbing element?,"Let $M = (M,·,1,0)$ be a monoid $(M,·,1)$ together with an distinguished absorbing element $0 ∈ M$, that is such that $∀x ∈ M\colon 0·x = 0 = x·0$. Does such a structure $M$ have a nice name? Furthermore, is there a name for such structures $M$, where the units of $M$ are exactly the nonzero elements of $M$, i.e. $M^× = M\setminus \{0\}$? Example . Every ring is such a structure when only considering multiplication. Fields are then examples where the units are exactly the nonzero elements.","['abstract-algebra', 'monoid', 'terminology']"
1517274,Evaluation of $\int \sqrt{1+\cot x}dx$?,"What is $$\int \sqrt{1+\cot x}dx$$ My friends and I tried using all possible trigonometric formula. We couldn't find a way to solve it 
Please help me solve it.","['calculus', 'integration']"
1517281,How well path-connected can a (special) partition of $\Bbb R^2$ be?,"It turned out that How well connected can a (special) partition of $\Bbb R^2$ be? had a a few nice answers using continum-many pairwise disjoint dense connected sets. Connectedness is just weirder than one first thinks ... So let's up the ante to path-connectedness: Let $\{A_i\}_{i\in I}$ be a family of subsets of $\Bbb R^2$ (where $I=\Bbb N$ or $\Bbb Z$; I don't know if it makes a difference - in the linked question the distinction was irrelevant as  solutions with all indices ""completely linked"" were found even for $I\approx \Bbb R$) such that $\bigcup_{i\in I} A_i=\Bbb R^2$ $i\ne j\implies A_i\cap A_j=\emptyset$ $A_i\ne\emptyset$ $A_i$ is path-connected $A_i\cup A_{i+1}$ is path-connected How often can it happen that $A_i\cup A_j$ is path-connected for $j\notin\{i-1,i,i+1\}$? Definition. Let's say that an index  $n\in I$ is infinitely linked / almost completely linked / completely linked if $A_n\cup A_i$ is path-connected for infinitely many/almost all/all $i\in I$. One possibility configuration is to let the $A_i$ be vertical stripes, in which case no $n\in I$ is infinitely linked.
With another configuration one can achieve that  there exists exactly one $n\in I$ that is completely linked (let $A_n=\{(0,0)\}$ and all other $A_i$ suitable sectors of $\Bbb R^2\setminus\{(0,0)\}$).
Can more than that be achieved? I.e., are there configurations with more (two, three, arbitrarily many, infinitely many, almost all, all) completely linked indices? Or maybe at least more almost completely linked indices? For $I=\Bbb Z$, I can find configurations two infinitely linked indices. Are three or more infinitely linked indices possible? Are two infinitely linked indices possible with $I=\Bbb N$? Note that  with $\Bbb R^3$ instead of $\Bbb R^2$ one can easily achieve that all indices are completely linked. EDIT: Only after seeing Crostul 's solution (and how it can be adapted for $I=\Bbb Z$, I noticed that it is not possible to have three or more completely linked indices: Pick a point in each of the three sets and a point in each of three other sets. Then we can pick a path witnessing the path-connectedness of the respective unions (wlog.(!) these paths do not intersect) and obtain a solution to the famous gas-water-electricity problem (i.e., a planar embedding of $K_{3,3}$), which is impossible.","['connectedness', 'general-topology']"
1517299,"A vector $x$ is orthogonal to a set $E$ closed under scalar multiplication if and only if $\operatorname{dist}(x,E)=\|x\|$","Let $X$ be an inner product space. Let $E\subset X$ be closed under scalar multiplication and $x \in X$. Then $x \perp E$ if and only if $\operatorname{dist}(x,E)=||x||$. I am able to show the forward part but not able to prove the backward part i.e. $\operatorname{dist}(x,E)=||x|| \implies x \perp E$ Please provide some hints!","['inner-products', 'functional-analysis']"
1517323,Not every holomorphic function $f$ can be written as $f(z)=e^{g(z)}$,"Problem: Show that not every holomorphic function $f:\Bbb C-\{0\}\to\Bbb C-\{0\}$ can be written as
  $$f(z)=e^{g(z)}$$
  for some holomorphic function $g:\Bbb C-\{0\}\to\Bbb C$. I tried to arrive at a contradiction by supposing
$$e^{g(z)}=\frac{1}{z}$$
for some $g$. We would have $\int_\gamma e^{g(z)}dz=2\pi i$ over the unit circle, so it would be sufficient to show that $e^{g(z)}$ extends to a holomorphic function on $\Bbb C$, but I am not sure if we can do this.",['complex-analysis']
1517344,Exponential distribution is self-decomposable,"I need to prove that if $X$ has an exponential distribution then it is self-decomposable and I need to prove it in two ways. I've already proved it by using Paul-Lévy theorem which says that: $X$ is self-decomposable $\iff $$(\forall c\in[0,1])$ $(\exists Y_{c} \perp X)$ $X=cX+Y_{c}$ I guess that the second way would be by finding such sequence of independent random variables $Z_{j}$ and sequences $a_{n}$,$b_{n}$ that: $a_{n}(Z_{1}+...+Z_{n})+b_{n} \Rightarrow X$ But I don't know how to find those sequences. Thanks for any help!","['probability-theory', 'probability-distributions']"
1517371,Solving a First Order Non-Linear Differential Equation of the form $\frac{dy}{dx}=ab-\frac{b}{a}y^2$,I was wondering how to solve the following DE $$ \frac{dy}{dx}=ab-\frac{b}{a}y^2 $$ as i cannot seem to find any site or PDF which adresses this specific DE or a similar equation. Any help is much appriciated. Thank you for your time! :-),"['calculus', 'ordinary-differential-equations']"
1517381,Trace of Product of Powers of $A$ and $A^\ast$,"Let $n$ be odd, $\displaystyle v=1,...,\frac{n-1}{2}$ and $\displaystyle \zeta=e^{2\pi i/n}$. Define the following matrices: $$A(0,v)=\left(\begin{array}{cc}1+\zeta^{-v} & \zeta^v+\zeta^{2v}\\ \zeta^{-v}+\zeta^{-2v}&1+\zeta^{v}\end{array}\right),$$
$$A(1,v)=\left(\begin{array}{cc}\zeta^{-1}+\zeta^{-v} & \zeta^{v}\\ \zeta^{-v}&\zeta^{-1}+\zeta^{v}\end{array}\right).$$
$$A(n-1,v)=\left(\begin{array}{cc}\zeta+\zeta^{-v} & \zeta^{2v}\\ \zeta^{-2v}&\zeta+\zeta^v\end{array}\right).$$ I am hoping to calculate for each of these $A$
$$\text{Tr}\left[\left(A^k\right)^*A^k\right]=\text{Tr}\left[\left(A^*\right)^kA^k\right].$$ All I have is that $A$ and $A^*$ in general do not commute so I can't simultaneously diagonalise them necessarily. I do know that if we write $A=D+(A-D)$ (with $D$ diagonal), that
$$A^*=\overline{D}+(A-D).$$ I suppose anybody who knows anything about calculating $$\text{Tr}(A^kB^k)$$ can help. Context: I need to calculate or rather bound these traces to calculate a distance to random for the convolution powers of a $\nu\in M_p(\mathbb{G}_n)$ for $\mathbb{G}_n$ a series of quantum groups of dimension $2n^2$ ($n$ odd). For $u=2,...,k-2$, $A(u,v)$ is diagonal so no problems there.","['quantum-groups', 'linear-algebra', 'roots-of-unity', 'matrices']"
1517382,"In a Topological vector space, a subspace of codimension 1 is either dense or closed.","Let $X$ be a topological vector space and $V$ be a linear subspace of $X$ such
  that $\text{dim}(X/V)=1$, then either V is closed or $\overline{V}=X$.
  In other words if it is not closed then it is dense. I believe that this is true and TrialAndError's answer to "" $\ker f$ is either dense or closed when $f$ is a linear functional on a normed linear space "", seems to confirm this. 
But I would like to make sure that I have understood correctly why this is the case. My reasoning is simply that if V is a subspace of X, so is $\overline{V}$. If V is not closed then they are distinct subspaces,and my intuition is that there isn't enough room for anything ""bigger"" than $\overline{V}$. This is because: $\exists x_0 \in \overline{V} \setminus V$ and so $\text{span}\{x_0\} \subset \overline{V}$ and therefore so does $V+\text{span}\{x_0\}$ but $X=V\oplus\text{span}\{x_0\}$ (I guess I'm using the theorem of incomplete basis to say this) so $X=\overline{V}$. Perhaps there is a better way of seeing this without implicitly invoking the axiom of choice?","['banach-spaces', 'general-topology']"
1517399,Variance and covariance,"I'm practicing for an exam and a mock question has me completely stumped. If someone could show me the steps I would be very grateful! There are two random variables, $A$ and $B$. $Var(A) = 9$, and $Var(B) = 4$, and $Cov(A, B) = 2$. a) What is $Var(2A - 3B + 10)$? b) $U = A + B$, and $V = A + aB$, where $a$ is decided so $Cov(U, V) = 0$. What are the possible values of $a$? c) $A$ and $B$ are simultaneously distributed with the Normal distribution, where $U$ and $V$ are the same as in the previous problem. What is $Cov(e^{sU}, e^{rV})$?","['covariance', 'statistics']"
1517411,"$f(x)$ has a limit, prove that $\sqrt{f(x)}$ has a limit","The question is : Let $f$ be a positive function defined on an interval $[a,\infty)$, such that $\lim\limits_{x\to\infty} f(x)=0$. Prove that $\lim\limits_{x\to\infty} \sqrt{f(x)}=0$. If $f(x)$ has a limit it means there is an $\varepsilon > 0$ and an $M>0$ s.t. for every $x>M$, $|f(x) - l| < \varepsilon.$ It seems kind of obvious that it is true yet I can't find a way to prove it. Thanks in advance !","['infinity', 'radicals', 'limits']"
1517427,Find eigenspace for eigenvalues of a linear transformation $T(M)=-2M^t+M$,"Let $V$ be the matrix space $4 \times 4$ over $\Bbb R$. $T: V \to V$ is a linear transformation defined by: $$T(M)=-2M^t+M$$ for all $M \in V$. Find the minimal polynomial of T. For every eigenvalue $\lambda$ of $T$, find the eigenspace $V_\lambda$ and calculate its dimension. Find $T$'s characteristic polynomial. I have solved section 1 this way: Let $S(M)=M^t$. Therefore $S^2(M)=M \Rightarrow S^2=I$. $$T=-2S(M)+S^2$$ Since $$ S^2=M$$ $$\Rightarrow T=-2S+I$$ $$\Rightarrow 2S=I-T$$ $$\Rightarrow 4S^2=(I-T)^2=I^2-2T+T^2=I-2T+T^2$$
Since $$4S^2=4I$$
$$\Rightarrow T^2-2T-3I=0$$
$$\Rightarrow(T+1)(T-3)=0$$ When further explanations we get the the eigenvalues are $$\lambda=-1$$ $$\lambda =3$$ However, to find eigenspace I need the original matrix, to calculate $$(A-\lambda I)$$ How do I find such a matrix for calculation? Thanks, Alan","['eigenvalues-eigenvectors', 'linear-algebra', 'minimal-polynomials']"
1517446,Find complete integral of $(y-x)(qy-px) = (p-q)^{2}$,"Find complete integral for partial differential equation $(y-x)(qy-px) = (p-q)^{2}$ where  $p={ \partial  z \over \partial x},q={ \partial  z \over \partial y}$. My attempt: The given equation is  f(x,y,z,p,q) = $(y-x)(qy-px) - (p-q)^{2}$
The Charpit's auxilary equation will be given by $${dp \over 2px-(p+q)y}={dq \over 2qy-(p+q)x}={dx \over {2(p-q)-x2+xy}}={dy \over {-2(p-q)+xy-y2}}$$ 
From here I tried to proceed but no solvable fraction turned out.","['characteristics', 'ordinary-differential-equations', 'partial-differential-equations']"
1517460,Sign table in $2^k$ factorial experiment,"I have a factorial experiment with four factors $\{A,B,C,D\}$ ($k=4$) , just to ilustrate the case with $k=3$, the signal table is \begin{matrix}
& I & A & B & C & AB & AC & BC & ABC\\
(1) & +1 & -1 & -1 & -1 & +1 & +1 & +1 & -1\\
a & +1 & +1 & -1 & -1 & -1 & -1 & +1 & +1\\
b & +1 & -1 & +1 & -1 & -1 & +1 & -1 & +1\\
ab & +1 & +1 & +1 & -1 & +1 & -1 & -1 & -1\\
c & +1 & -1 & -1 & +1 & +1 & -1 & -1 & +1\\
ac & +1 & +1 & -1 & +1 & -1 & +1 & -1 & -1\\
bc & +1 & -1 & +1 & +1 & -1 & -1 & +1 & -1\\
abc & +1 & +1 & +1 & +1 & +1 & +1 & +1 & +1\\
\end{matrix} I know this is just a signal table with produtcts of $+ $and $-$, but is there any quick way to assemble it without having to look at the signs? I would like to know it, because with the table is easier and faster to calculate the contrasts, otherwise I would have to do $$A=(a-1)(b+1)(c+1)(d+1)$$
$$B=(a+1)(b-1)(c+1)(d+1)$$
$$.....$$
$$ABCD=(a-1)(b-1)(c-1)(d-1)$$ Is there any easier way to assemble this table? As I need to make the table a hand to study for the exam, I was looking at it and I saw a few things about the contrasts $(A,B,C,D)$: $+1$ in which the letter appears $(AB,AC,BC,AD,BD,CD)$: $+1$ in $(1)$, in the rows where the pair appears and in the rows where one or two of the letters does not belong to the pair appears $(ABC,ABD,ACD,BCD)$:$+1$ in rows which appears each letter of triple alone, row in which the triple appears and rows where the letter does not belong to triple appears (only in pairs) $ABCD$: $+1$ in all pairs and $ABCD$","['statistics', 'combinatorics']"
1517464,Why is the tensored up inverse image left adjoint to the direct image?,"For sheaves of sets, given a map $f:X\rightarrow Y$, there's the usual $f^{-1}\dashv f_\ast$ adjunction. In the context of sheaves of modules, there's supposedly an adjunction $f^\ast \dashv f_\ast$ where $f^\ast(-)=f^{-1}(-)\otimes \mathcal O_X$. Here, $f^\ast$ is a functor $\mathcal O_Y$-$\mathsf{Mod}\rightarrow \mathcal O_X$-$\mathsf{Mod}$. I don't really understand how $f^\ast$ is a left adjoint of $f_\ast$. What has changed in this context to make for a different left adjoint to what seems to be the same functor $f_\ast$. Where do morphisms of ringed spaces come into play? I thought the proof should be one line using the $f^{-1}\dashv f_\ast$ and $-\otimes B\dashv \mathsf{hom}(B,-)$ adjunctions. Here's my attempt:
$$\begin{aligned}\mathsf{Hom}\left(f^{-1}(G)\otimes\mathcal O_{X},F\right) & \cong\mathsf{Hom}\left(\mathcal O_{X},\mathsf{hom}(f^{-1}G,F)\right)\\
 & \cong\mathsf{Hom}\left(\mathcal O_{X},\mathsf{hom}(G,f_{\ast}F)\right)\\
 & \cong\mathsf{Hom}\left(\mathcal O_{X}\otimes G,f_{\ast}F\right)\\
 & \cong\mathsf{Hom}\left(G,f_{\ast}F\right)
\end{aligned}
$$ Here are my doubts: Is there really an iso $\mathsf{hom}(f^{-1}G,F)) \cong \mathsf{hom}(G,f_{\ast}F))$ of internal hom sheaves? I mean, the adjunction only yields isos of hom-sets, so why should it lift to an iso of sheaves? I remember reading that this adjunction depends on the notion of a morphism of ringed spaces, and yet, that notion does not seem to play any role in the proof...","['algebraic-geometry', 'sheaf-theory', 'category-theory']"
1517475,Parity preservation in set cardinality,"Let $A,B,Q$ be three sets such that $|A\cap Q|,|B\cap Q|$ are both even.
How can I prove that $|((A\cup B) - (A\cap B))\cap Q|$ is also even. All sets are finite.",['elementary-set-theory']
1517478,Differentiate $[x^{5\coth(6x)}]'$,"can you help me to differentiate this function?
$$[x^{5\coth(6x)}]'$$ My steps: $$[x^{5\coth(6x)}*\ln(x)]*[5(1-\coth^2(6x))]*[6]$$ I dont know what formula i should use $$[x^n]'$$ or $$[a^x]'$$
thanks for advice.","['hyperbolic-functions', 'derivatives']"
1517488,Prove That $M^2+xM+yI$ and $M^2-xM+yI$ are non-singular,"Let $M$ be an Invertible Hermitian matrix and let $x,y\in\Bbb R$ such that $x^2\lt 4y$,Then Prove That $M^2+xM+yI$ and $M^2-xM+yI$ are non-singular. My Attempt: $$(M^2+xM+yI)(M^2-xM+yI)=(M^2+yI)^2-(xM)^2$$ Now I Don't Know How to proceed further, I know that all the eigen values of Hermitian matrix are real. Help is needed. Thank you.","['linear-algebra', 'matrices']"
1517489,Permutation of integers,"Let $n$ be a positive integer and let $(a_1,...,a_n)$ be a permutation of $\{1,2,...,n\}$. Define $$A_k = \{ a_i | a_i < a_k, i >k\} \\  B_k = \{a_i | a_i > a_k, i < k\}$$
  for $1 \leq k \leq n$. Prove that $\sum^{n}_{k=1} |A_k| = \sum^{n}_{k=1} |B_k|$. The problem confuses me a bit. It asks to prove that both sets will have the same cardinality, but for example, if I choose $n = 10$ and $k = 4$, for the $A_k$ part I will have $i > k$, which means $5...10$, so I have $6$ elements, while in the set $B_k$, I have $i < k$, so I will have $1...3$, meaning $4$ elements. Am I interpreting the problem correctly, if not, can someone improve and help?","['discrete-mathematics', 'summation', 'combinatorics', 'permutations']"
1517498,Sum and convergence of series $\sum\limits_{n=2}^{\infty}\ln \left(1-\frac{1}{n^2}\right)$ [duplicate],"This question already has answers here : Computig the series $\sum\limits_{n=2}^\infty \ln\left(1-\frac{1}{n^2}\right)$ (4 answers) Closed 8 years ago . How do I calculate the sum of $$\sum _{n=2}^{\infty \:}\ln \left(1-\frac{1}{n^2}\right)$$ and prove that it is a convergent series? I tried using comparison by choosing $a_n = -\frac{1}{n^2}$ and saying that if this is a convergent series, then my series is also a convergent one, since the $\lim _{n\to \infty }\left(\frac{\left(\ln\left(1-\frac{1}{n^2}\right)\right)}{-\frac{1}{n^2}}\right)$ would be $1$. I'm not sure if this is the correct way of doing this though, since I'm working with positive term series.","['sequences-and-series', 'convergence-divergence']"
1517515,How to find the area of a square inside a semicircle using only the radius?,"Provided with only the radius of the semicircle (10 cm) and the knowledge that the corners of the square touch the semicircle, how can one find the area of this square?","['geometry', 'circles']"
1517525,Integration of $\frac{1}{dx}$ in physical applications,"$$\frac{1}{dc} = \frac{dx}{εx}$$ That's what I was left with when I was finding the capacitance of a parallel plate capacitor with non-uniform dielectric in it. I just needed to find $c$ (capacitance) for this problem where the total distance ($D$) was also given. But I don't think this integration which is $$∫\frac{1}{dc} = ∫\frac{dx}{εx}$$ [$ε$ is constant]
can be solved. Can it be? Or am I doing something wrong?","['physics', 'ordinary-differential-equations']"
1517537,Determine the smallest disc in which all the eigen values of a given matrix lie,"Let , $$A=\left[\begin{matrix}1&-2&3&-2\\1&1&0&3\\-1&1&1&-1\\0&-3&1&1\end{matrix}\right]$$Which of the following is the smallest disc in $\mathbb C$  which contains all eigen values of $A$. $|z-1|\le 7$ $|z-1|\le 6$ $|z-1|\le 4$. Characteristic polynomial of $A$ is $x^4-4x^3+21x^2-48x+46$. From this computing eigen values is very difficult in hand. Without computing eigen values how we can detect the required interval ? Does there any other process??","['linear-algebra', 'matrices']"
1517539,"If a real symmetric matrix has repeated eigenvalues, why does it still have n linearly independent eigenvectors?","I know that if $A=A^T$ is real, then the eigenvalues are real, and that eigenvectors corresponding to different eigenvalues are orthogonal. Is there an easy way to see what happens in the case of a repeated eigenvalue, or does this require some sophisticated arguments (that I guess will come later in my book)?","['eigenvalues-eigenvectors', 'linear-algebra']"
1517581,Function $f$ such that $f$ is non-periodic but $f(f(x))$ is?,"Is there a ""nice"" example of a function $f$ such that $f(x)$ is non-periodic but the composition $f(f(x))$ is? By nice I mean that preferably it will be defined entirely on the domain $R$ and be continuous/differentiable with the composition having non-zero period. For example the function $f(x>0)=-x, f(x \leq 0) = 0$ is not nice.","['periodic-functions', 'fourier-analysis', 'functions']"
1517619,"Prove that if one function is greater or equal than another, then so it is its limit.","Let $g(x)$ and $f(x)$ be real functions such that $f(x) \le g(x);  \forall x$ such that both $f$ and $g$ are defined. Using the $\epsilon$-$\delta$ definition of limit show that $\lim_{x \to a} f(x) \le \lim_{x \to a} g(x)$, given that both are defined. Here's my solution: Let's assume the contrary, so let $\lim_{x \to a} f(x) = M$ and $\lim_{x \to a} g(x) = N$, such that $M>N$. Now using the condition we have: $$f(x) + N < g(x) + M: \quad \quad \forall x \in D_f \text{ and } x \in D_g$$
$$f(x) - M < g(x) - N; \quad \quad \forall x \in D_f \text{ and } x \in D_g$$ Hence there always exists $\epsilon$ such that $\mid f(x) - M \mid < \epsilon  <\mid  g(x) - N \mid$ or $\mid f(x) - M \mid > \epsilon  > \mid  g(x) - N \mid$, since the set of reals is dense and we don't have equality. Hence for this $\epsilon$ we're not able to find $\delta$ such that: $$0<\mid x-a \mid < \delta \implies \mid f(x) - M \mid < \epsilon \quad \text{or} \quad 0<\mid x-a \mid < \delta \implies \mid g(x) - N \mid < \epsilon$$ which means that one of the limits is wrong which isn't possible. Hence $M\le N$. Q.E.D. I think this proof is alright, but is it possible to prove the statement without the initial assumption, or at least without using the fact that the set of reals is dense?","['calculus', 'limits', 'epsilon-delta']"
1517625,"Orthocentre, circumcentre, midpoint of a side and foot of altitude form a rectangle","A rectangle $HOME$ has sides $HO=11$ and $OM=5$. A triangle $ABC$ has $H$ as intersection of altitudes, $O$ as the circumcentre, $M$ as the midpoint of $BC$ and $E$ as the foot of altitude from $A$. Find the length of $BC$. I need some hints to start off with the problem. Also, a diagram would help. Thanks.",['geometry']
1517642,"Compact manifold, regular value","I am still trying to convince myself about a fact which I've seen in Milnor's book ''Topology from the differentiable viewpoint'':
Let M and N be manifolds of the same dimension. If M is a compact manifold and $y \in N$ is a regular value and $F: M \rightarrow N$ is a smooth map, then $F^{-1} (y)$ is a finite set (possibly empty).
I tried thinking on this direction but still I don't see how to conclude that $F^{-1} (y)$ has to be a finite set:
M is a manifold so it is an Hausdorff space $\Rightarrow$ every point is a close set, furthermore because $F$ is smooth then is also continuos (since differentiability implies continuity) $ \Rightarrow F^{-1} (y)$  is closed in $M$. But $M$ is compact so every close subset of a compact subset is also compact then also $F^{-1}(y)$ is compact. For Hypothesis $y$ is a regular value which implies that $F^{-1}(y)$ contains only regular points, by the implicit function theorem if $x \in F^{-1}(y)$ then there exist an open neighborhood $U$ of $x$ where F restricted to U is a local diffeomorphism. How can I conclude that $F^{-1}(y)$ is a finite set? I told by using compactness but I think I miss something","['differential-topology', 'differential-geometry', 'manifolds']"
1517684,Laymans explanation of the relation between QFT and knot theory,Could someone give an laymans explanation of the relation between QFT and knot theory? What are the central ideas in Wittens work on the Jones polynomial?,"['knot-theory', 'quantum-field-theory', 'differential-geometry', 'algebraic-topology', 'knot-invariants']"
1517704,Limit $\lim_{x\to0^-}{(1+\tan(9x))^{\frac{1}{\arcsin(5x)}}}$,"I have a limit:
$$\lim_{x\to0^-}{(1+\tan(9x))^{\frac{1}{\arcsin(5x)}}}$$ Are these steps correct? Substitution: $x = n$, $n\to\infty$: $$\lim_{n\to\infty}=(1+\frac{\sin(9n)}{\cos(9n)})^{\frac{1}{\arcsin(5n)}}$$
$$\lim_{n\to\infty}=e^{\frac{\sin(9n)}{\cos(9n)\arcsin(5n)}}$$ Back from substitution: $n = x$, $x\to0^-$: $$\lim_{x\to0^-}=e^{\frac{\sin(9x)}{\cos(9x)\arcsin(5x)}}$$
$$\lim_{x\to0^-}=e^{\frac{\sin(9x)}{\cos(9n)\arcsin(5x)}\cdot\frac{9x5x}{9x5x}}$$
$$\lim_{x\to0^-}=e^{\frac{9x}{5x\cos(9x)}}$$
$$\lim_{x\to0^-}=e^{\frac{9}{5\cos(9\cdot0^-)}}$$
$$\lim_{x\to0^-}=e^{\frac{9}{5}}$$",['limits']
1517707,Gateaux derivative of integral operator,"Let $\Omega\subset \mathbb{R}$ and consider an integral operator $E\colon L^{2}(\Omega) \rightarrow \mathbb{R}$ given by $E(u) = \int_{\Omega} F(u(x))\,dx$ for $u\in L^{2}(\Omega)$. Suppose $F\colon \mathbb{R}\rightarrow \mathbb{R}$ has a derivative $f$. What other conditions do I need for $E$ to be Gateaux differentiable or have directional derivatives in a given direction $\psi \in L^{2}(\Omega)$? In particular, without any further assumptions, the [wiki][1] article on Gateaux differentiability gives the derivative as $E^{\prime}(u)(\psi) = \lim\limits_{\tau\rightarrow 0} \int_{\Omega}\int^{1}_{0}f(u+ \tau s \psi)\psi \,ds\,dx = \int_{\Omega} f(u)\psi\,dx = \langle f(u),\psi \rangle$ Where the fundamental theorem of calculus was used to write the difference quotient as the inside integral. But it seems that to move the limit inside the integrals we need $f$ to be bounded or some growth condition to use dominated convergence theorem. Is this ${necessarily}$ true? Or can we get Gateaux differentiability without boundedness or any other conditions on $f$? In particular, I am worried that $f(u)\not\in L^{2}(\Omega)$. I note a previous post talks about a growth condition. Thanks!","['functional-analysis', 'derivatives']"
1517710,"Is it known whether a constant $A$ exists, such that there is always a Carmichael-number between $x$ and $Ax$ for $x\ge 561$?","For prime numbers, such a constant is well known. For $n\ge 2$, there is always
a prime between $n$ and $2n$, so $A=2$ does the job. Carmichael-numbers are much rarer, so I wonder, whether a constant $A$ has been found and be proven to do the job for $n\ge 561$ ? The count upto $10^{21}$ shows that there are Carmichael-numbers with $3,4,5,...,21$ digits, so is $A=10$ sufficient ?","['prime-numbers', 'number-theory', 'recreational-mathematics', 'pseudoprimes']"
1517715,Finding matrices with polynomials of an exact form,"Might be a bad title here, but I am looking through some old prelim questions and am curious if someone may assist with this one: Find a list of real matrices, as long as possible, such that: 1) The characteristic polynomial of each matrix $p(x) = (x-1)^{5}(x+1)$. 2) The minimal polynomial of each matrix is $m(x) = (x-1)^{2}(x+1)$. 3) No two matrices in the list are similar to each other. Any tips? Is this leading to Jordan normal form?","['linear-algebra', 'matrices']"
1517718,Does every infinite field contain a countably infinite subfield?,"Does every infinite field contain a countably infinite subfield? It's easy to see that every field $K$ contains either the rational numbers $\Bbb Q$ (when $K$ has characteristic $0$) or a finite field $\Bbb F_p$ (when $K$ has characteristic $p$). Thus, in the characteristic $0$ case, the answer is an easy ""yes."" But if $K$ is infinite and has characteristic $p>0$, does the fact that $K \supset \Bbb F_p$ allow us to conclude that $K$ has a countably infinite subfield?","['extension-field', 'abstract-algebra', 'field-theory']"
1517818,Find $dy/dx$ if $xe^{9y}+y^4\sin(4x)=e^{8x}$,"If $xe^{9y}+y^4\sin(4x)=e^{8x}$ implicitly defines $y$ as a function of $x$ then what is $\displaystyle \frac{dy}{dx}$? So far, I have made the following steps: 1) Get all parts of the equation onto one side 2) Find the derivative of the whole equation 3) This equals $9e^{9y}+y^4(4cos(4x))+4y^3(sin(4x))-8e^{8x}$ 4) Now, I think I am to get 'y' by itself. However, I am not sure how to do this, since there are $y$ variables as exponents, as well as non-exponent $y$ variables. Does anyone know how I may find the derivative of this function? All help is appreciated.","['derivatives', 'calculus', 'trigonometry']"
1517835,"Without the Axiom of Choice, does every infinite field contain a countably infinite subfield?","Earlier today I asked whether every infinite field contains a countably infinite subfield. That question quickly received several positive answers, but the question of whether those answers use the Axiom of Choice has spawned off an interesting discussion in its own right. Thus I'd like to pose that question separately: Without using the Axiom of Choice, can it be shown that every infinite field contains a countably infinite subfield? Note that the corresponding question for sets has a negative answer, but since fields have so much more structure than sets, it is not a priori unreasonable to me that there might exist an AC-less resolution for fields. EDIT: For the purposes of this question, an infinite set is one that is not bijective with $\{1, \dots, n\}$ for any $n \in \Bbb N$. Thanks to @MartinSleziak for bringing this issue up in chat.","['extension-field', 'field-theory', 'axiom-of-choice', 'abstract-algebra', 'set-theory']"
1517843,"Prove by induction that $S(n,3) > 3^{n-2}$ for all $n≥6$","Prove by induction that $S(n,3) > 3^{n-2}$ for all $n≥6$ I have done the base case for this problem, using $n=6$ as my base case:
$$S(6,3) > 3^{6-2}$$ $$S(6,3) > 81$$ -I am brand new to Stirling numbers and am unsure as to how to confirm this base case, and how to move forward with the rest of the problem. Any help is appreciated.","['stirling-numbers', 'induction', 'discrete-mathematics', 'inequality']"
1517855,Applications of Hodge theory to topology and analysis,"I am going to give a talk for the PhD students' seminar at my university. The audience is composed mainly by algebraic topologists, algebraic geometers and analysts. I have decided that I'm going to talk about Hodge theory as it has links with all of these fields, starting from the basics and going up to use it to show that deRham cohomology on compact manifolds is finite dimensional. If possible, I would like to give other interesting (and, if possible, not too hard) examples of applications. Does any of you know some?","['soft-question', 'big-list', 'algebraic-geometry', 'algebraic-topology', 'partial-differential-equations']"
1517862,"Prove that ∀a, b, u, v ∈ Z − {0} ua + vb = 1 → gcd(a, b) = 1","How can I prove this statement: $\forall a,b,u,v \in \mathbb{Z} - \big\{{0\big\}}\hspace{0.7em}ua+vb=1 \rightarrow \gcd(a,b)=1$ I don't even really know how to start off. Probably with Euclid's Extended GCD Algorithm? Thanks in advance.","['discrete-mathematics', 'gcd-and-lcm', 'divisibility', 'elementary-number-theory']"
1517888,Find all the real solutions to the equation: $(x+i)^n-(x-i)^n=0$,"Find all the real solutions to the equation: $$(x+i)^n-(x-i)^n=0$$ The answer is given, I will type it out until the line which is unclear to me (meaning I understand all the steps leading up to the last line). $$\left(\frac{x+i}{x-i}\right)^n=1 \implies \frac{x+i}{x-i}=\sqrt[n]{1}=\cos \frac{2k \pi}{n}+i\sin\frac{2k\pi}{n},\qquad k=0,1,\ldots,(n-1)$$ Now we find $x$:
$$x=\frac{\sin\frac{2k\pi}{n}-i(1+\cos\frac{2k\pi}{n})}{1-\cos\frac{2k\pi}{n}-i\sin\frac{2k\pi}{n}}$$ The rest is clear, just this last line.","['analysis', 'calculus', 'complex-analysis', 'complex-numbers']"
1517981,Taking derivative with respect to a vector x,"$\textbf{x}$ is a n-by-1 vector, $F(\textbf{x})$ is function from $R^{n} \rightarrow R^{n\times n}$. What is the derivative of $F(\textbf{x})\textbf{x}$ with respect to $\textbf{x}$? $\dfrac{dF(\textbf{x})\textbf{x}}{d\textbf{x}}$ = ?","['calculus', 'matrices']"
1518029,"Are uncountable ""Schauder-like"" bases studied/used?","We could define the following notion of basis in a way analogous to unconditional Schauder basis : If $X$ is a topological vector space over $\mathbb R$ and $B=\{b_i; i\in I\}$ be a subset of $X$. We say that $B$ is a basis if, for every $x\in X$ there exists a unique ""coefficient function"" $c\colon I\to\mathbb R$ such that
  $$\sum_{i\in I} c(i) b_i =x.$$ Probably more natural notation -- resembling the usual notation for linear combinations -- would be $\sum\limits_{i\in I} c_i b_i =x$. The sum $\sum\limits_{i\in I} v_i$ of elements of a topological vector space is defined as a limit of the net
$$x_F=\sum_{i\in F} x_i$$
on the directed set consisting of all finite subsets of $I$ (ordered by inclusion). This seems to be the usual approach for defining sums over an index set which is not necessarily countable. It is defined in this way, for example, in this answer . Does this type of basis have a name? Are such basis studied? Are they useful in some areas of mathematics? For example, orthonormal basis (maximal orthonormal set) in a Hilbert space is such basis. Motivation for this questions is that it seems to be a very natural next step after defining Hamel basis and Schauder basis. In a typical curriculum, most people usually encounter the word basis for the first time in connection with vector space. If we only have structure of a vector space, we only can do finite sums and finite linear combinations. So trying to define basis using something like $\sum\limits_{i=1}^\infty c_i b_i$ is not possible. But later we learn about normed spaces and topological vector space, where we have the notion of convergence and thus the expression $\sum\limits_{i=1}^\infty c_i b_i$ makes sense. So we now can define the Schauder basis and the definition seems very similar to the definition of Hamel basis - we just replaced finite sum by an infinite series. Now we could try to define the analogous notion for arbitrary index set, not just $\mathbb N$. One possible way to do this would be to use the notion of sum over arbitrary index set which I described above. (On $\mathbb N$ we have a natural ordering, while on arbitrary set $I$ we do not have an order which we could call ""natural"". Therefore this notion is closer to unconditional Schauder basis than to Schauder basis.) When trying to find some references for this type of basis I found the following remark in Heil's Basis Theory Primer ( doi:10.1007/978-0-8176-4687-5 ; some version of the manuscript seems to be available on the author's website : Remark 4.4: (d) The definition of basis requires that $\{x_n\}$ be a countable sequence. Sometimes, as in Exercises 3.6 and 3.7, it is possible to deal with uncountable systems that have basis-like properties, but to avoid confusion we will not call such systems bases. The above remark suggest that the type of basis I described above is probably not very useful. (By the way the Exercise 3.6 and 3.7 mentioned in this remark contain, among other things, the fact that orthonormal basis of a Hilbert space has such properties.) On the other hand, special case of such basis is an orthonormal basis in a Hilbert space. I'd say that the fact that an inner-product space has an orthonormal basis gives some useful information about this space. But I guess that it might be difficult to use similar basis in a sensible way in a Banach space, which is not a Hilbert space. Despite this skepticism, I posted the question here. It is still possible that I will learn from answers about some unexpected applications. EDIT: Almost immediately after posting this question I have noticed this older question: What do we call a Schauder-like basis that is uncountable? I would argue that the questions are a bit different. The other posts only asks about the name for such basis, not for applications. And the OP does not describe how exactly they want to go from the countable case to the arbitrary case. (Although to me the above seems the most natural way, the phrasing of the other question leaves also other possibilities open. (And in fact, a comment posted there describes some kind of basis which seems different from my definition above.) I will leave it to other users to judge whether the two questions are different enough to remain open, or whether one of them should be closed as a duplicate. EDIT 2: After a bit of searching I found a post on MO which asks (if I understand it correctly) whether the cardinality of this type of basis (assuming it exists) is determined uniquely by the space $X$: Uniqueness of dimension in Banach spaces","['schauder-basis', 'topological-vector-spaces', 'functional-analysis', 'normed-spaces']"
1518039,a set is invariant under translation for a certain measure,"Assume $A\in\mathbb{R}^n$ is a Lebesgue null set and $\mu$ is a positive $\sigma$-finite measure living on $A$ (i.e. $\mu(A^c)=0$) such that 
$$
\mu(A+r)=\mu(A),\forall r\in\mathbb{R}^n
$$
does this imply that $\mu=0$? I think of this when I am learning the Lebesgue-Radon-Nikodym theorem and the invariant property under translation of Lebesgue measure. I think the answer is yes but still need more justification. 
Any hint would be appreciated!","['lebesgue-measure', 'real-analysis', 'measure-theory']"
1518043,Covariant derivative of a vector field along a curve,"In the following proposition of Do Carmo's Riemannian Geometry, I don't understand part (c) because $\frac{DV}{dt}$ is a vector field along the curve $c$, so it has domain $I$, while $\nabla_{\frac{dc}{dt}}Y$ is a vector field on $M$ with domain $M$, so how can they be equal? Also, the affine connection $\nabla$ is defined for two vector fields on $M$, $X$ and $Y$, and gives another vector field on $M$ $\nabla_X Y$. So how can we speak of  $\nabla_{\frac{dc}{dt}}Y$ if $\frac{dc}{dt}$ is a vector field along $c$ and not a vector field on $M$?","['differential-geometry', 'connections']"
1518061,Proving the principle of inclusion-exclusion using Möbius inversion,"In Enumerative Combinatorics v. I, Stanley applies Möbius inversion to $B_n$, the poset of subsets of $[n]$, to show that $\forall f,g : B_n \to \mathbb{C}$, $$
g(S) = \sum_{T \subset S} f(T) \, \,  \forall S \subset [n]
\\
\iff
\\
f(S)= \sum_{T \subset S} (-1)^{|S-T|} g(T) \, \, \forall S \subset [n].
$$ How can I get the usual statement of the principal of inclusion-exclusion from this?","['order-theory', 'discrete-mathematics', 'inclusion-exclusion', 'combinatorics', 'mobius-inversion']"
1518077,A characterisation of functions of $\mathbb{N} \rightarrow \mathbb{R}$ of the form $f(n) = \sum_k a_k k^n$,"I'm looking for a characterisation of functions $f : \mathbb{N} \rightarrow \mathbb{R}$ for which there exists $(a_k) \in \mathbb{R}^\mathbb{N}$ such as $f(n) = \sum_k a_k k^n $ for all $n \in \mathbb{N}$. I don't think that every functions of $\mathbb{N} \rightarrow \mathbb{R}$ can be written like this. An easy calculus (using Vandermonde matrix) show that for $N \in \mathbb{N}$, one can find a function $f_N$ such as $f_N(N) = 1$ and $f_N(n) = 0$ if $n < N$. So for a given function $f$, we can find a function $g$ of the form we want such as $f(n) = g(n)$ for $n < N$, with of course no information after $N$ on $g$. I'm looking for a condition on $\lim f(n)$ as $n$ go to infinite for $f$ to be of the given form (by the result before, it's the only kind of condition we can put on $f$).","['power-series', 'sequences-and-series', 'real-analysis']"
1518092,Two mutually singular and absolutely continuous measures means one measure is identically zero,"The claim is that if $\nu$ is a signed measure on (X,M) and $\mu$ is a positive measure on M, $\nu\perp\mu$, and $\nu<<\mu$, then $\nu=0$. I can see that $\nu=0$ if $\mu(E)=0$ by absolute continuity. I am having trouble seeing why $\nu(E)=0$ when $\mu(E)>0$. For example, I have drawn two disjoint circles representing A and B, and another circle representing E intersecting both A and B. In this case, $\mu(B\cap E)>0$ and $\nu(A\cap E)>0$. Could someone explain to me why this drawing/idea is not a counterexample to the claim? It (Definitions: $\nu\perp\mu$ means the two measures are mutually singular, i.e. there exist disjoint sets A and B in M such that $\nu(E)=\nu(A\cap E)$ and $\mu(E)=\mu(B\cap E)$ for all $E\in M$; $\nu<<\mu$ means $\nu$ is absolutely continuous with respect to $\mu$, i.e. $\nu(E)=0$ whenever $E\in M$ and $\mu(E)=0$.)",['measure-theory']
1518113,Find an angle in a triangle with cevians,"Given triangle ABC such that angles B and C both measure 70 degrees, points E and F lie on sides AB and AC, respectively, such that angle ABF measures 30 degrees and angle ACE measures 50 degrees. Segments CE and BF intersect at point P. Find the measure of angle BAP. Also, how do I generalize this problem with other angle measures? (i. e., when the angles of B and C and when the cevians necessarily split the angles are changed)","['euclidean-geometry', 'geometry', 'triangles']"
1518170,Show series representation of orthogonal polynomials,"wikipedia has the following series expansion for hermite polynomials, namely: $$\exp \left\{xt-\frac{t^2}{2}\right\} = \sum_{n=0}^\infty {\mathit{He}}_n(x) \frac {t^n}{n!}.$$ Does anybody see how this can be shown. I tried rearranging a few terms, but did not get far.","['calculus', 'orthogonal-polynomials', 'real-analysis', 'mathematical-physics', 'analysis']"
1518175,Moore Penrose Inverse for symmetric matrix [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Is there any proof that a MPI of symetric matrix is symmetric matrix?
Basically I need that Moore-Penroses invers of positive semidefinite matrix is positive semidefinite.
I can show that x^T(A+)x >=0. But A+ also need to be symmetric for positive semidefinite. Thank you for your help.",['matrices']
1518180,"Combinatorics 8 men, 8 women, each choosing red or blue balls from bin","My sister posed this question to me and I'm a little surprised to be struggling so much with it. 8 men and 8 women choose balls from a bin that contains 8 blue balls and 8 red balls. After the selection is done, what is the probability of that 4 men have a red ball and 4 men have a blue ball? I was able to brute force the problem for 2 men, 2 women, 2 red and 2 blue balls (answer is 2/3) and I wrote a little script to brute force the answer for 4 men, 4 women, 4 red and 4 blue balls (answer is 20736 / 40320). I can't figure out how to generalize the count though. Any help would be much appreciated.","['probability', 'combinatorics']"
1518214,No closed form for $\sum_{n\in P} \frac{1}{n^2}$,"I think that I can say with a fair amount of assurance that $$\sum_{n\in \mathcal P} \frac{1}{n^2}$$ has no closed form (assuming that $\mathcal P$ represents the full set of primes) I currently know the following: a) The sum converges at $ 0.45224742\dots$ b) The definition of a closed from expression is that you can express the constant with the following: addition, multiplication, subtraction, and division raising a number to a power that exists (Includes reciprocals, roots, powers, and powers to fractional exponents) known constants such as $\pi,e, \gamma, \phi \cdots$ and no others trigonometric functions and their inverses ($\sin,\text{arccsc}, \cot, \text{arcsec}\cdots\text{\etc.}$) hyperbolic trig functions and their inverses ($\text{arccosh},\text{tanh},\text{arccoth}$) You may not use anything that involves limits. A few off limits :) might be limits, derivatives, integrals, infinite sums, infinite products, and so on. c) I know, at least, that the number is irrational. The irrationality of this concept [in part] inspired this question. The reason I think that there is no closed form is due to the randomness of primes and that often times even random sums have no closed form. But really, I am not looking for whether or not this has a closed form, but a proof that there exists no closed form. Go as complicated as necessary to solve. Thanks for any help. I realize that the a proof of the closed form is often extremely difficult, and even unknown for even the simplest of constants ($\gamma$ and $\zeta(3)$). I did know of the difficulty of a proof like this before asking this question. The reason I thought it might be easier was due to how random the distribution of primes were. (Remember we are trying to prove that there is no closed form not the opposite.) PS: As a high school student, could you please namedrop the names of theorems please in your proof so I could learn more?","['closed-form', 'prime-numbers', 'sequences-and-series', 'number-theory']"
1518227,Volume Forms Induced by Embedding,"Let $(M, g)$ be a Riemannian Manifold of dimension $d$, $g$ naturally gives rise to an invariant volume form $V_M \in \Omega^d(M)$. Let $\Sigma$ be a smooth embedded submanifold of dimension $d-1$ in $M$. One can pull back the metric $g$ by the embedding map and construct am invariant volume form $V_\Sigma \in \Omega^{d-1}(\Sigma)$. Question :
Is it true that \begin{equation}
    V_\Sigma = i_nV_M
\end{equation} where $n|_p$ is the unit normal with respect to $g$ at $p \in \Sigma$. Comments : I think it is well known (and easy to check) that the above equation is true for surfaces in $\mathbb R^3$, but I am not sure if it holds in general. If not true, is there a general equation of this type where one can express the ""induced volume element"" in terms of the global volume element, without explicit reference to the metric?","['differential-geometry', 'riemannian-geometry', 'differential-forms']"
1518230,How to build the solution to a first-order PDE with the method of characteristics?,"I'm having a hard time to understand the idea of the initial curve in the method of characteristics. Suppose we have a quasi-linear first order PDE in two variables: $$a(x,y,u)u_x+b(x,y,u)u_y=c(x,y,u).$$ I already know that if we consider $S$ the graph of $u$, that is $$S = \{(x,y,u(x,y))\in \mathbb{R}^3 : (x,y)\in \mathbb{R}^2\},$$ then the characteristic curves $c: I\subset \mathbb{R}\to \mathbb{R}^3$ are curves which lie on the surface $S$ and satisfies $$\dfrac{dc_1(t)}{dt}=a(c_1(t)), \quad \dfrac{dc_2(t)}{dt}=b(c_2(t)), \quad \dfrac{dc_3(t)}{dt}=c(c_3(t)),$$ which is the characteristic system. All of that is nice, with this we can get a curve in $S$ passing through each point of the surface. Now, usually to actually solve a problem we also need to give one initial curve which intercepts the characteristic curves. The problem is that I don't get the idea of this initial curve. In fact, I'm so confused with this that I didn't even know how to properly explain what those initial curves are above. In that case what are those initial curves and what is the idea behind them? And mainly, after solving the characteristic system and knowing the parametrization of the characteristic curves, how does one use the initial curve to find the solution to the problem? How to build the solution to the PDE from the characteristic curves and the initial curve together?","['calculus', 'differential-geometry', 'multivariable-calculus', 'ordinary-differential-equations', 'partial-differential-equations']"
1518250,Solving Burgers' equation $u_y+uu_x=0$ with arbitrary initial values,"Consider the PDE $$u_y+uu_x=0$$ with the condition $u(x,0)=f(x)$. I want to solve this using the method of characteristics. The first thing I've done was to solve the characteristic system. In that case the system is $$\dfrac{dx}{dt}=u, \quad \dfrac{dy}{dt}=1, \quad \dfrac{du}{dt}=0.$$ In that case we get, with $c_1,c_2,c_3$ constants, $u=c_3$, $x=c_1+c_3t$ and $y=t+c_2$. Now as I understand, the initial condition can be thought of as a curve $\sigma(s)=(s, 0, f(s))$ which cuts the characteristics. The idea then is to write $u$ as a function os $s$ and $t$ that is $s$ picks a characteristic and $t$ the value of $u$ at some point of it. In that case if we imagine that give $s$ the characteristic is intercepted at $t=0$ we find $c_2=0$, $c_1=s$ and $c_3=f(s)$. Now for any $t$ on this characteristic $u$ is the same so $u(s,t)=f(s)$. Now we have to express $s$ and $t$ in terms of $x,y$. The point is that we easily get $t=y$, but $s=x-yf(s)$. In that case we would have $$u(x,y) = f(x-yf(s))$$ which is obviously wrong. What is wrong here? How is the right way to do this?","['characteristics', 'ordinary-differential-equations', 'partial-differential-equations']"
1518259,Curvature of given metric space,"As my question 1 and 2 , I still have many problems. First, the hyperbolic manifold is the manifold $(\mathbb R^n , g)$ given by one chart $\mathbb R^n$, where in spherical coordinates $(\theta^0= s, \theta^1, \cdots, \theta^{n-1})$, the metric is given by 
$$\tag{1} g = ds^2 + \frac1M \sinh^2(\sqrt M s) d\Omega^2.$$
I want to compute the curvature of $(\mathbb R^n,g)$.I try to compute $\Gamma_{ij}^k$, but in different dimension,$d\Omega^2$ has different form , I can't get $g_{ij} $ for $i,j\ne0$.Then ,I don't know how to do it .","['differential-geometry', 'riemannian-geometry', 'ricci-flow']"
1518277,Pushforward of algebraic cycles,"Let $f: X \to Y$ be a proper morphism of smooth integral projective varieties over an algebraically closed field $k$ of characteristic 0, where $dim X = dim Y = n$.
Denote by $CH_i(W):= Z_i(W)/\sim$ be the Chow group of $i$-cycles on $W$, where $Z^i(W)$ is the group of $i$-cycles on $W$ and $\sim$ means rational equivalence. The push-forward $f_\ast: Z_i(X) \to Z_i(Y)$ is a group homomorphism that is compatible with rational equivalence, meaning that it descends to a group homomorphism
$$ f_\ast : CH_i(X) \to CH_i(Y).$$
When $i = n-1$, under the above assumptions on $X$ and $Y$ we have that $CH_{n-1}(X) =CaCl(X) = Pic(X)$ and $CH_{n-1}(Y) =CaCl(Y)=Pic(Y)$, since rational equivalence is the same as linear equivalence.
Hence, $f_\ast$ is a group homomorphism
$$ f_\ast : Pic(X) \to Pic(Y).$$ Assuming that $Pic(Y)$ and $Pic(X)$ are representable by algebraic group schemes (which they are, under our assumptions), is $ f_\ast : Pic(X) \to Pic(Y)$ a morphism also as algebraic group schemes ? Moreover, I'm slightly confused about one thing: usually the pushforward of a line bundle is not a line bundle, meaning that the above morphism $ f_\ast : Pic(X) \to Pic(Y)$ ""looks"" wrong! Hence, is the word ""pushforward"" an abuse of terminology in the context of cycles? i.e. do pushforwards of invertible line bundles actually correspond to pushforwards of cycles? If not, is there any relation between the two?","['algebraic-geometry', 'picard-scheme', 'divisors-algebraic-geometry']"
1518335,Prove the estimator $\hat{B}$ of ridge regression = mean of the posterior distribution under a Gaussian prior,"I want to prove that the estimator of ridge regression is the mean of the posterior distribution under Gaussian prior. $$y \sim N(X\beta,\sigma^2I),\quad \text{prior }\beta \sim N(0,\gamma^2 I).$$ $$\hat{\beta} = \left(X^TX + \frac{\sigma^2}{\gamma^2}I\right)^{-1}X^Ty.$$ What I'm trying to show is want to show that $\mu$ = $\hat{B}$, for $\mu$ in $$-\frac{1}{2}(\beta - \mu)^T\Sigma^{-1}(\beta - \mu)$$ $\Sigma^{-1}$ is the covariance matrix for the posterior distribution $p(\beta\mid X,y)$. There is a solution to this question the last couple of lines on page 3 from http://ssli.ee.washington.edu/courses/ee511/HW/hw3_solns.pdf . I'm baffled as to how it does this. (The problem is exercise 3.6.) Edit: $\mu$ is the mean of the posterior. Edit2: Last couple of lines of problem 3.6 say ""which is the single $\beta$ term in the $p(\beta|y, X)$ equation."" What is the single $\beta$ term? This sentence makes no sense to me. I'm not sure what the relevance of saying something is the the singe $\beta$ term to this proof. Edit2 continued: For convenience, ""$m_b = \frac{1}{\sigma^2I}\Sigma_bX^Ty$, and $B^T\Sigma_b^{-1}m_b = \frac{1}{\sigma^2}B^tX^ty$, which is the single $\beta$ term in $p(\beta |X,y)$ equation."" (me: okay, how is this helpful to the proof?)","['regularization', 'bayesian', 'linear-algebra', 'regression']"
1518344,Find the maximum and minimum values absolute value,"So I am asked to find the maximum and minimum  of the function: $$f(x)=(2+|x|)\sqrt{2+(2-x)^2}$$ on the interval $[-1,2]$ So I took the derivative and got: $$\frac{ 2((x-2)|x|+x(x^2-3x+3)) }{|x|\sqrt{(2+(2-x)^2}}$$ which is in fact correct. So I set it equal to zero and try to find the critical points. The problem is though, how do I solve for $2((x-2)|x|+x(x^2-3x+3))=0$??? I certainly can't see a way...","['calculus', 'derivatives']"
1518351,Group of symmetries of circle contains elements of all orders,"Let $G$ be the symmetry group of a circle. I tried to answer the following question: Show that $G$ contains elements of every finite order as well as elements of infinite order. My answer: Let $n \in \mathbb N_{>0}$ . Then the rotation by $360/n$ has order $n$ hence we can find an element of order $n$ for any $n >0$ . Now we need to show that there exist elements of infinite order. To this end, let $R$ be rotation by $360/\sqrt{2}$ . Then $R$ has infinite order because $n \sqrt{2} \neq 360 k$ for all $n,k \in \mathbb Z \setminus \{0\}$ . To see this, note that if $n \sqrt{2} =360 k$ for some $n,k \in \mathbb Z \setminus \{0\}$ then $$ 2n^2 = 360^2 k^2$$ which is equivalent to $$ \left({n \over k}\right)^2 = {360^2 \over 2}$$ ${360^2 \over 2}$ is an integer which implies $k=1$ . So we have $$ n^2 = {360^2 \over 2} = 64800$$ Now note that $254^2=64516$ < 64800 < 255^2=65025$$ This concludes the proof. Is my answer correct? - And if it is, is there a better way than trial and error to find
  numbers such that $64800$ is between their squares to finish the proof?","['solution-verification', 'group-theory']"
1518422,"Prove that if $\mathbb{C}-K$ is connected, then $K$ is polynomially convex.","Prove that if $\mathbb{C}-K$ is connected, then $K$ is polynomially convex. $K $ polynomially convex means $K=\hat{K}$ where $$\hat{K}=\{z\in\mathbb{C}:|p(z)|\le \max_{ζ\in K}|p(ζ)|\text{ for all polynomials}\; p\}$$ My Try Let $z_0\in \mathbb{C}-K$. Then $K\cup\{z_0\}$ also has connected complement. Take a sequence $\{z_n\}$ such that $ z_n\rightarrow z_0$. Consider $f_n(z)=\frac{1}{z-z_n}$. Now $f_n(z)$ is analytic  on a neighborhood of $K\cup\{z_0\}$. Fix $n$. Then by Runge's theorem there is a sequence $\{p_m\}$ of polynomials such that $p_m$ converges uniformly to $f_n$ on $K\cup\{z_0\}$. Now I wanted to pick one $p_m$ so that $|p_m(z_0)|>\max_{ζ\in K}|p(ζ)|$, but how could I do it? Can somebody please help me to complete my almost completed proof?","['approximation', 'polynomials', 'complex-analysis']"
1518423,Bounded sequence with repelling terms,"I was wondering: Is it possible to construct a bounded sequence $\{a_n\}$ of real numbers satisfying $|a_n-a_{n+k}| > 1/k \, \forall k \geq 1$? I've tried to come up with such a sequence, to no avail.  But I have no idea how to disprove this, either.","['analysis', 'sequences-and-series', 'real-analysis']"
1518436,"Is Every Sequentially Compact, First Countable Space Also Compact?","I want to know if sequential compactness in first countable space implies compactness. I know the implication is correct in metric space (a proof that uses Lebesgue number), but I cannot mimic a proof in a general first countable space.
Or perhaps we cannot get compactness when we only have sequential compactness, but only countable compactness or Lindelof?","['real-analysis', 'general-topology']"
1518463,"Show a map from infinite product of ${0,1}$ to the Cartesian product of itself is a bijection","Prove that the map $f: \{0,1\}^{\Bbb N}\to \{0,1\}^{\Bbb N}\times \{0,1\}^{\Bbb N}$ given by ($a_1,a_2,a_3,a_4...$) $\mapsto$ ($a_1,a_3,a_5...$) $\times$ ($a_2,a_4,a_6...$)is bijective, where $\{0,1\}^{\Bbb N}$ denotes the infinite product of $\{0,1\}$ I guess the map could be interpreted as the sequence $a_1,a_2,a_3,a_4...$ mapping to the pair of sequences ($a_1,a_3,a_5...$;$a_2,a_4,a_6...$  ) but how do I show this is bijective, especially the case of surjection?","['elementary-set-theory', 'real-analysis', 'functional-analysis', 'functions', 'general-topology']"
1518492,Showing $\sin(nx)$ is a complete orthonormal system,"I want to prove that the system $\sin(nx)$ for $n=1,2,\cdots$ is complete in $L_2[0,\pi]$, so what I do is assume that: $$\int_0^\pi f(x)\sin(kx)dx=0,\quad k=1,2,\cdots$$ An define an odd function: $$\overline{f}(x) =\left\{ \begin{matrix}f(x),&0\leq x\lt \pi\\ -f(-x),& -\pi \leq x \lt 0\end{matrix} \right.$$ And we have that $\int_{-\pi}^\pi \overline{f}(x) dx = 0, \int_{-\pi}^\pi \overline{f}(x)\cos(nx) dx=0 $ Since $\overline{f}$ is an odd function we have: $$\int_{-\pi}^\pi \overline{f}(x)\sin(nx) dx =2 \int_{-\pi}^\pi \overline{f}(x)\sin(nx)dx=2\int_0^\pi f(x)\sin(nx)d=0$$ Where the last bit equals zero by assumption. Now this is the bit I don't understand, I am meant to conclude: "" Thus, since the system $\{1,\sin(nx),\cos(nx)\}_n$ is complete in $L^2[-\pi,\pi]$, we obtain $\overline{f}(x)=0$ in $[-\pi,\pi]$ and hence $f(x) = 0$ in $[0,\pi]$""","['orthonormal', 'functional-analysis']"
1518523,Non-uniqueness of solutions of an ordinary differential equation,"For instance, consider the following initial value problem $$x'=3x^{2/3}, \ \ \ \ x(0)=0$$ This initial value problem has infinitely many solutions given by $$ x(t) = \begin{cases}
0 & t<c \\
(t- c)^3 & t \geq c
\end{cases} \ \ \ \ \ (*) $$ for any non-negative $c$. Picard's existence theorem says that the initial value problem $x'=f(x,t), x(t_0)=x_0$ has a unique solution if $f(x,t)$ is continuous at $(x_0,t_0)$ and Lipschitz continuous in $x$. So the non-uniqueness comes from the fact that $3x^{2/3}$ is not Lipschitz at $x=0$. But I was wondering why a student taking a basic undergrad course in differential equations is not able to get the totality of solutions (*) ? i.e. one proceeds like this  $$ \frac{1}{3}x^{-2/3}dx=dt \ \ \ \Rightarrow \ \ \ \ x^{1/3}=t+C  $$ applying the initial condition we get $C=0$. So $$x(t)=t^3$$ Thanks","['initial-value-problems', 'ordinary-differential-equations']"
1518564,Are there any non-trivial automorphisms on the Natural Numbers under addition?,"I'm curious about whether or not there is an automorphism on $(\mathbb{N};+)$ that isn't the identity. I suspect there isn't, but I'm not quite sure how to prove it.","['abstract-algebra', 'monoid']"
1518674,Maximizing the pairwise Frobenuis distance between M othrogonal matrices,"I want to maximize the pairwise Frobenius distance between $M$ orthogonal matrices. That is, I'm looking for $Q_{i}, i = 1, 2, ... M$ such that
\begin{equation*}
\begin{aligned}
& \underset{ 1 \leq i, j \leq M}{\text{min}}
& & || Q_{i} - Q_{j} ||^2_F
\end{aligned}
\end{equation*}
is maximized. I know there are numerical algorithms that can provide the answer to that. I'm just wondering if the solution has a simple structure. For example, if the solution can be parameterized by a single variable $t$ (and possibly some orthogonal matrix $A$). Edit: It would also be nice if I someone could lead me to directions on how to bound that.","['numerical-linear-algebra', 'lie-groups', 'manifolds', 'differential-geometry', 'linear-algebra']"
1518679,"Geometry book for the university with solved exercises (affine space, euclidean space, etc...)","I'm looking for a book with solved exercises of affine space, affine transformations, etc... I found a lot of books and pdf's with theory, but none of them contained solved exercises, and I'm having difficulties solving the problems of my exercises' list. Could anybody recommend me one? Thanks!","['geometry', 'affine-geometry', 'soft-question']"
1518727,Joint density of exponential and sum of exponentials / general RV,"I need to find the density $f_{x,z}$ where $x \sim exp(\lambda_1)$ and $z = x + y$, where $y \sim exp(\lambda_2)$. $x$ and $y$ are independent. Finding the density of $z$ is not too hard (and has also been answered on here several times). I am stumped by trying to find the joint density of $x$ and $z$ - they are clearly not independent. Add in complications such as that surely $f_{x, z} = 0$ if $z < x$, and I am thoroughly confused.","['probability', 'statistics']"
1518738,When can I move the limit operand into a function?,When can I move $\lim$ inside an expression? what are the requirements from the function? For example: $\displaystyle \lim_{x \to \infty}\frac{\sqrt{x^2+2}}{3x-6}$,"['calculus', 'limits']"
1518751,"What groups can I safely refer to, to demonstrate various theorems in a first course in abstract algebra?","When studying abstract algebra, I do prefer having a nice simple and concrete example to demonstrate the theorem/lemma. However, the 'first course' book that I am currently learning from often uses (in my opinion) quite complicated examples to demonstrate the theorem/lemma. Sometimes this is fine, but other times I may as well be reading Chinese. For example, my 'go-to' group for an infinite abelian group is $\left ( \mathbb{Z}, + \right )$. My 'go-to' group for a finite abelian group is $\left ( \mathbb{Z_n}, + \right )$ What are some nice and easy-to-understand Non-abelian finite groups Non-abelian infinite groups that I could use to demonstrate/test the theorems I learn? I understand that 'easy' is a subjective term. But I am trusting your expertise as to what would be considered 'easy' for someone first learning abstract algebra.",['abstract-algebra']
1518758,Infinite Lebesgue integral over all infinite measure subsets?,"This question is in particular for $\mathbb{R}^+$. What properties must a finite function $f$ have such that $\int_A f d\mu = \infty$ for all A with $\mu(A) = \infty$? As pointed out previously (when the question was not framed correctly), obviously any constant $f$ will have infinite integral.","['real-analysis', 'measure-theory']"
1518774,Which natural numbers satisfy $2^n > n^2$?,"Which natural numbers satisfy $2^n > n^2$ ? My work. Step 1: $n = 1 $, $2^1 > 1^2$. True. For $n = k$, $2^k > k^2$. For $n = k+1$,
$$ 2^{(k+1)} > (k+1)^2 \\
2\cdot 2^k>k^2+2k+1 \\ 
2^k+2^k > k^2+2k+1$$ $2^k > k^2 \text{ - from step 1}$ $2^k > k^2+2k+1$ How I can find the numbers now?","['discrete-mathematics', 'induction', 'elementary-number-theory']"
1518793,Use integration by parts to find the integral $\int\frac{\sqrt {4x^2-9}}{x^2}dx$,"$$\int\frac{\sqrt {4x^2-9}}{x^2}dx$$ I tried to solve this using integration by parts, but I come up with something that is much more difficult to solve. How can this be solved?","['calculus', 'indefinite-integrals', 'integration-by-parts', 'integration']"
1518795,Minimizing $\int_{0}^{1} (1+x^2)f^2(x)dx$,"What is $$\min_{f\in D} \int_{0}^{1} (1+x^2)f^2(x)\mathrm dx,$$
where $D$ is the collection of all continuous real functions from $[0,1]$ such that $\int_{0}^{1} f(x)$ = 1. My attempt Note that $\int_{0}^{1} (1+x^2)f^2(x)dx$ = $\int_{0}^{1} f^2(x)dx$ + $\int_{0}^{1} x^2f^2(x)dx$. Now, by Schwarz inequality, $\int_{0}^{1} f^2(x)dx$ $\geq (\int_{0}^{1} f(x)dx)^2$ and $\int_{0}^{1} (xf(x))^2dx$ $\geq (\int_{0}^{1} xf(x)dx)^2$. $\int_{0}^{1} xf(x)dx$ = ?. What I tried what follows: Let F(x) = $\int_{0}^{x}f(t)dt$. Then, $\int_{0}^{1} xf(x)dx$ = $xF(x)\vert_0^1 - \int_{0}^{1} F(x)dx$ \. I am stuck at this point. However, even if I somehow compute this integral, still I don't believe that ($\int_{0}^{1} xf(x)dx$)^2 + ($\int_{0}^{1} f(x)dx$)^2 is the required minimum. Please suggest. P.S: Obvious, however for clarification, f^2 is not composition, but pointwise multiplication.","['optimization', 'calculus', 'integration']"
1518811,"Integrate $\int r^n \sin r \,dr$","How to compute $\int r^n \sin r\, dr, n\in \Bbb Z$? In fact, I really need 10 reputation points to ask a complex question.","['analysis', 'integration']"
1518851,Logic behind normal line in expressing plane,"why do we consider normal line in expressing a plane,say in $R^3$, of the form $ ax + by + cz = d $? What is the logic behind this normal line selection? Plz provide intuitive explanations.Thanks",['multivariable-calculus']
1518909,Finding the probability mass function given the cumulative distribution function,"Suppose that the cumulative distribution function of a random variable X is given by $
F(a) = 
\begin{cases} 
    0,& a < 0 \\
    1/5, & 0 \leq a < 2 \\
    2/5, & 2 \leq a < 4 \\
    1, & a \geq 4 
\end{cases}
$ Find the probability mass function of X? My reasoning is as follows:
The cdf is discontinuous at the points 0, 2, and 4. Between these $F'(a)$ is defined and $=0$, hence the pmf needs definition only at these points. But how do we get the probabilities at a = 0, 2, 4?","['probability', 'probability-distributions']"
1518911,Rules for exponential and logarithm with complex arguments,"Stackexchange community, i have a question concerning the rules for exponentials and logarithms with complex arguments. For real arguments we have: $$e^{a+b}=e^a\cdot e^b$$
$$e^{a-b}=e^{a}/e^{b}$$
$$e^{\ln a}=a$$
$$\ln(a\cdot b)=\ln a + \ln b$$
$$\ln(\frac{a}{b})=\ln a - \ln b$$
$$\ln(e^{a})=a$$
$$\log_a(b)=\frac{\log_c(b)}{\log_c(a)}$$ Can i use these laws also for complex numbers? I know I have to take care of periodicity and singularities.",['complex-analysis']
1518912,"Why is it that for $n<60$, the simple groups are precisely the cyclic groups $\mathbb{Z}_N$ for prime $n$?","I was reading this Wikipedia article and came across this For groups of order $n<60$, the simple groups are precisely the cyclic groups $\mathbb{Z}_n$ for prime $n$. I was wondering, why is this true for $n<60$? What is so special about this value?",['abstract-algebra']
1518932,Symmetric relation definition - why is this false?,"Can someone explain to me why the following statement is false, according to my study materials for discrete mathematics? If a relation $R$ on a set $X$ is symmetric, then $x\,R\,y$ and $y\,R\,x$ for all $x,y\in X$. How can this be false? I thought that if a relation is symmetric, then you need to have $xy$ and $yx$ in both directions, for all elements of a set. This is the answer provided in the book: False. The definition states that in order for $R$ to be symmetric on $X$, we have that if $x\,R\,y$ for $x, y \in X$ then $y\,R\,x$ also. This not imply that all $x$ and $y$ in $X$ are related under $R$. What am I missing here?","['elementary-set-theory', 'relations']"
1518962,Defining measure on homeomorphic spaces,"Say you have two homeomorphic spaces $X\cong Y$, and a measure $\mu$ defined on the measurable space $(X,\scr{B}$$(X))$, where $\scr B$$(X)$ is the Borel sigma-algebra of $X$. Since $\scr B$$(X)$ is generate by the open sets of $X$, and $U\subseteq X$ is open in $X$ $\Leftrightarrow$ $f(U)\subseteq Y$ is open, isn't it true that $\mu$ is also a measure on $(Y,\scr B$$(X))$, with $\mu(U)=\mu(f(U))$?",['measure-theory']
1519028,Torus cannot be embedded in $\mathbb R^2$,"I've shown that $T^2$ can be embedded in $\mathbb R^3$.
I just can't see why it can not be embedded in $\mathbb R^2$. Ideas: suppose $F: \mathbb S^1\times \mathbb S^1 \to \mathbb R^2$ is continuous injective then we can construct (somehow) $G:\mathbb S^1\to \mathbb R$ continuous injective so we get a contradiction. we know that $\mathbb R^2$ is homeomorphic to the punctured $2$-sphere, so we get embedding $F$ from $T^2$ to $\mathbb S^2\setminus\{0\}$, thus $F$ is not onto $\mathbb S^2$ and then I can show that it is homotopic to the constant map, but I can't see any contradiction in this situation. Thank you in advance.","['homotopy-theory', 'algebraic-topology', 'general-topology']"
1519140,Normed Linear Space - maximum norm vs. $||f||_1$,"For $f$ in $C[a,b]$ define $$|| f ||_1 =\int_a^b |f|.$$ 
a. Show that this is a norm on $C[a,b]$. b. Show that there is no number $c \geq0$ for which $$||f||_{max} \leq c ||f||_1 \ for \ all  \ f \ in  \ C[a,b]$$ c. Show there is a $c\geq 0$ for which $$||f||_1 \leq c||f||_{max}  \ for \ all  \ f  \ in  \ C[a,b]$$ (where $||f||_{max}=\max\limits_{x \in [a,b]} |f(x)|)$ I proved a. by showing all norm properties (the triangle inequality, positive homogeneity and nonnegativity). I also proved part b. by false assumption that leaded me to contradiction Any help on part c.
Thanks","['measure-theory', 'real-analysis', 'functional-analysis', 'normed-spaces', 'inequality']"
1519149,Does continuous injective functions preserve disconnectedness?,"It is well known result that continuous functions send connected spaces to connected spaces. It is also known that if $f:\mathbb{R}^n\rightarrow\mathbb{R}^n$ is continuous and injective, then if $A\subset\mathbb{R}^n$ is open, so it is $f(A)$. And it is also known that a continuous bijective function between topological spaces doesn't necessarily have to be an open function. So, what if we give a little twist to all these results? Let $f:\mathbb{R}^n\rightarrow\mathbb{R}^m$ be a continuous injective function and let $A\subset\mathbb{R}^n$ be an open and disconnected set. Does $f(A)$ need to be open or disconnected? I already know that $f(A)$ isn't necessarily open, since you can consider inclusion $i: \mathbb{R} \rightarrow\mathbb{R}^2$ with $i(x) = (x,0)$. Clearly $i$ is continuous and injective and any open set in $\mathbb{R}$ will be sent to a line segment in $\mathbb{R}^2$ which isn't an open set under its standard metric topology. But now I'm having troubles with either proving or finding a counterexample for disconnectedness. If there is a counterexample out there, then due to the Invariance of Domain Theorem, $m\neq n$ necessarily. But I couldn't think of any. Then I've also tried to give a proof, but I got stuck. Here's what I've tried: Take $f$ and $A$ as stated. Since $A$ is disconnected, there are two open sets $B,C$ such that $A=B\cup C$ and $B\cap C=\emptyset$, hence $\overline{B}\cap C=B\cap\overline{C}=\emptyset$ (where $\overline B$ means the closure of $B$). This means that $f(A)=f(B)\cup f(C)$ and due to injectivity we can easily check that $f(B)\cap f(C)=\emptyset$. But $f(B),f(C)$ aren't necessarily open in $\mathbb{R}^m$ as shown by the previous example, so we can't conclude that $f(A)$ is disconnected. I would need to show that $\overline{f(B)}\cap f(C)=f(B)\cap \overline{f(C)}=\emptyset$ Let $z\in\overline{f(B)}\cap f(C)$. Then there is $c\in C$ such that $f(c)=z$. Due to continuity, we also know that $f(\overline B)\subset \overline{f(B)}$. If $z\in f(\overline B)$ there is $b\in\overline B$ such that $f(b)=z$. Due to injectivity, $b=c$, hence $\overline{f(B)}\cap C \neq \emptyset$ which is a contradiction. Therefore, $z\in\overline{f(B)}\setminus f(\overline B)$... and here's where I'm stuck. Any help will be dearly appreciated.","['real-analysis', 'general-topology']"
1519182,St. Petersburg's Paradox elaboration [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Find N (the entrance fee in dollars) such that you would expect to break even if you played the St. Petersburg's lottery every minute of every day of your life. For more information on the St. Petersburg lottery, see the Wikipedia entry: https://en.wikipedia.org/wiki/St._Petersburg_paradox Edit I'm going to assume the topic-closers closed this topic because they weren't sure which question I was asking.  That is, break even and stop, or break even and keep playing anyway. Both.  Or neither.  Or pick your own version!!!","['probability', 'statistics']"
1519187,Ring homomorphisms from $\mathbb{Z}_n$ to $\mathbb{Z}_m$,"I'm trying to find the ring homomorphisms from $\mathbb{Z}_n$ to $\mathbb{Z}_m$. What I think is the answer is two cases: 1) If $m \gt n $ there is no ring homomorphism. 2) Otherwise, the homomorphism sends each element $x$  in $\mathbb{Z}_n$ to $(x \bmod m)$ in $\mathbb{Z}_m$. Is this correct? EDIT:
Part of the ring homomorphism definition is that 1 is sent to 1","['abstract-algebra', 'ring-theory']"
1519193,Characterization of group homomorphisms from $\mathbb R$ to $\mathbb R$,"I am trying to characterize all the group homomorphisms from $\DeclareMathOperator{R}{\mathbb R}\R$ to $\R$ . I have characterized all the ""continuous"" group homomorphisms from $\R$ to $\R$ . They are of the form $f(x) = f(1) x$ . Now I claim that all the group homomorphisms from $\R$ to $\R$ are necessarily continuous. Is this claim correct? I provide my justifications below. Let $f$ be any group homomorphism from $\R$ to $\R$ . Since $f(x+y) = f(x) + f(y)$ would hold for all $x,y$ in $\mathbb Q$ , f(restricted to $\mathbb Q$ ) is a group homomorphism from $\mathbb Q$ to $\R$ . However, all the group homomorphisms from $\mathbb Q$ to $\R$ are continuous as they are of the form $f(x) = f(1)x$ . Not only that, they are uniformly continuous as $|f(x)-f(y)| = |f(1)(x-y)|< \epsilon$ if I choose $\delta$ as $\epsilon/|f(1)|$ . Since $f$ is uniformly continuous on a dense subspace of $\R$ , it can be extended to a unique continuous function in its closure. (Rud Exercise in Ch4. Continuity). Thus, every group homomorphism from $\R$ to $\R$ is continuous and hence are of the from $f(x) = f(1)x$ .","['group-theory', 'real-analysis', 'general-topology']"
1519204,Is there a way to solve $\sqrt a + \sqrt b = \sqrt n$ analytically?,"Often in (high school) math competitions, there are equations that look very simple, yet are non-trivial to solve. One such problem is $$ \sqrt a + \sqrt b = \sqrt n $$ where $a, b \in \mathbb{Z}$ and $n$ is usually an arbitrary value, like a year (e.g. $n = 2016$). The problem then asks to find all possible values of $a$ and $b$. Is there a way to solve this problem analytically, or is there a method that can be done by hand (or with a scientific, non-programmable calculator) that isn't just trial-and-error?",['algebra-precalculus']
1519242,Finding the double integral over a specified region.,"Let $D$ be the region in the xy-plane that is bounded by the coordinate axes and the line $x+y =1$ , we need to find : $\displaystyle\iint (x-y)e^{ x^{2} + y^{2}}dydx$ over $D$. I am trying the change of variables technique here : Let $ u = x-y$ and $v = x + y$ and by considering the region given the integral came out to be : $ \displaystyle\int_0^1 \int_0^v ue^{ \frac{ u^{2} + v^{2}}{2}}dudv$ , First integrating w.r.t $u$ gives : $\displaystyle\int_0^1 e^{v^{2}} - e^{\frac{v^{2}}{2}}dv$ , That is the point where I am stuck .. Could anyone help me with this ? Keeping $u$ constant , i.e changing the order of integration isn't helping..","['calculus', 'multivariable-calculus', 'integration']"
1519281,"If $\int_{0}^{\infty} f(x) \, dx $ converges, will $\int_{0}^{\infty}e^{-sx} f(x) \, dx$ always converge uniformly on $[0, \infty)$?","I previously asked about sufficient conditions to conclude that $$\lim_{s \to 0^{+}}\int_{0}^{\infty} e^{-sx} f(x) \, dx = \int_{0}^{\infty} f(x) \, dx$$ when $\int_{0}^{\infty} f(x) \, dx$ does not converge absolutely. Daniel Fischer showed that a sufficient condition is if $\int_{0}^{\infty} e^{-sx} f(x) \, dx$ converges uniformly on $[0, \delta]$ for some $\delta >0$. Recently I came across the following exercise: Show that if $F(s) = \int_{0}^{\infty} e^{-sx} f(x) \, dx$ converges
  for $s=s_{0}$, then it converges uniformly on $[s_{0}, \infty)$. The above excercise is exercise 27 in the first supplement to the textbook Introduction to Real Analysis by William F. Trench. It's basically a stronger version of a theorem that states that if $f(x)$ is continuous on $[0, \infty)$ and $\int^{{\color{red}{x}}}_{0} e^{-s_{0}u} f(u) \, du$ is bounded for all $x \ge 0$, then $\int_{0}^{\infty} e^{-sx} f(x) \, dx$ will converge uniformly on $[s_{1}, \infty)$ for $s_{1} >s_{0}$. A proof of this theorem can be found on page 20 of the supplement. But with the only condition being that $\int_{0}^{\infty} e^{-s_{0}x} f(x) \, dx$ must converge, it's hard to believe that there is not a counterexample. Perhaps it has something to do with $e^{-sx}$ being monotonic in the parameter $s$.","['calculus', 'limits', 'real-analysis', 'improper-integrals', 'laplace-transform']"
1519283,Prove that there is no simple group of order $48$.,"I wrote a proof of the aforementioned statement. I am aware that there is another post similar to this one , but my proof differs significantly from all of the answers in that post, and I'd like to know if my proof is valid. By the third Sylow theorem, the number of Sylow 2-subgroups $n_2$ divides $3$, and $n_2 \equiv 1 \mod 2$, so $n_2 \in \{ 1, 3 \}$. Similarly, $n_3$ divides $16$, and $n_3 \equiv 1 \mod 3$. So, $n_3 \in \{ 1,4,16 \}$. If $n_2 = 1$, we are done, as the Sylow 2-subgroup is the desired normal subgroup. If $n_2 = 3$, take any two Sylow 2-subgroups $P$ and $Q$. Their intersection $P \cap Q$ has order either equal to $1, 2, 4$ or $ 8$. Using the formula $|PQ| = \frac{|P||Q|}{|P \cap Q|}$, we can eliminate $1$, $2$ and $4$ (since in these cases, $|PQ|$ is greater than the order of the group itself). So, it must be the case that $|P \cap Q| = 8$. Then, since $P \cap Q$ has index 2 in both $P$ and $Q$, it must be the case that $P \cap Q$ is normal in $P$ and $Q$. So, the normalizer of $P \cap Q$, which I denote $N(P \cap Q)$, has order at least $|P \cup Q| = 24$, and the order divides $48$. So, $N(P \cap Q)$ is either $24$ or $48$. If it is $24$, then $N(P \cap Q)$ is normal in $G$ (since it has index $2$). If it is $48$, then $P \cap Q \triangleleft G$. This completes the proof.","['abstract-algebra', 'group-theory']"
1519285,Determinant of Adjacency Matrix is null,"Let be $D=(V,E)$ . Prove the determinant of its adjacency matrix , $det(A) = 0$ $\iff$ $\exists S \subseteq V $ (nonempty) such that $|v_{ext} \cap S|$ is an even number , $\forall $ v $\in V$ . $v_{ext}$ denotes the nodes $u$ such that $vu \in E$.
Also , D may have loops (i.e $\exists$ $A_{uu} =1$). All operations are made in $GF(2)$. I have tried the direct implication in this way : if $det(A) = 0$ , it means that the vectors of $A$ are not linearly independents. But what`s the next step ? Thanks!","['graph-theory', 'linear-algebra', 'matrices']"
1519325,Partial derivatives of the hypergeometric ${_2F_1}$,"Do formulas for the partial derivatives of the hypergeometric function ${_2F_1}$ exist? I mean I am interested in $$\frac{\partial}{\partial a}\  {_2F_1}(a,b,c,z)$$$$\frac{\partial}{\partial b}\  {_2F_1}(a,b,c,z)$$
$$\frac{\partial}{\partial c} \ {_2F_1}(a,b,c,z)$$","['partial-derivative', 'real-analysis', 'definite-integrals', 'hypergeometric-function', 'derivatives']"
1519347,"Arithmetic rules for big O notation, little o notation and so on...","There are many asymptotic notations like the big O notation: big Omega notation, little o notation, ... Thus there are many arithmetic rules for them. For example Donald Knuth states in Concrete Mathemtics (p. 436) the following rules (without a proof): $f(n)=O(f(n))$ $c O(f(n)) = O(f(n))$, if $c$ is constant $O(O(f(n))) = O(f(n))$ ... My Question: Can you recommend a reference where all arithmetic rules of the asymptotic notations are stated and proved? It would be great if also the connections between the asymptotic notations are formulated and shown, e.g. $O(o(f(n))=o(f(n))$. My research results so far: The question What are the rules for equals signs with big-O and little-o? investigates the interpretation rules for the asymptotic notations. The Wikipedia article ""Big O notation"" states some rules but without a proof. (As already mentioned) there are some rules in Concrete Mathematics page 436 without proof. The article ""Some Rules for Big-Oh Notation"" lists some rules (without a proof). Reason for my question: I write my thesis which heavily bases on asymptotic notations. I want to prove all the arithmetic rules I used which are a lot... (I also use other notations like the big Delta notation ). A list of already proved arithmetic rules - which I can cite - would be great here ;-) Update: I had an idea to minimize the number of needed arithmetic rules via generalizing the concept of asymptotic notations. I describe this idea in the MO thread Generalization of asymptotic notations like big O or little o notation .","['notation', 'calculus', 'real-analysis', 'asymptotics', 'reference-request']"
1519353,Interpretation of eigenvectors of Hessian in context of local min/max/saddle?,"Say $f \in C^2$ so we can possibly use its Hessian $H$ to determine whether $f$ has a local max, min, or saddle at a critical point $x_0$. Since $H(x_0)$ is real and symmetric, it is diagonalizable, say with eigenvector-eigenvalue pairs $(v_1,\lambda_1),\ldots,(v_n,\lambda_n)$. The second derivative test asserts that if all the $\lambda_i$ are strictly positive, then $f$ has a local min, if they are all strictly negative, then $f$ has a local max, and if there are at least one strictly positive and one strictly negative, then $f$ has a saddle point. Is there some geometric interpretation to what the $v_i$ are? Are the $v_i$ somehow directions in which the function restricted to that direction has concavity $\lambda_i$?","['optimization', 'stationary-point', 'calculus', 'multivariable-calculus']"
1519367,Difference between gradient and Jacobian,"Could anyone explain in simple words (and maybe with an example) what the difference between the gradient and the Jacobian is? The gradient is a vector with the partial derivatives, right?","['jacobian', 'vector-fields', 'scalar-fields', 'multivariable-calculus', 'derivatives']"
1519383,Can someone explain the integration of $\sqrt{v²+\tfrac14}$ to me?,"I am currently trying to integrate this root: $$\sqrt{v^2+\frac{1}{4}}$$ According to several integration calculators on the web it is: $$\frac{\operatorname{arsinh}(2v)}{8} +\frac{v\sqrt{v^2+\tfrac{1}{4}}}{2}$$ However, I just can't get my head around it. I have absolutely no idea where that $\operatorname{arsinh}$ is coming from. My take on this would have been: $$f = \left(v^2+\frac{1}{4}\right)^{\frac{1}{2}}\implies F = \frac{2}{3}\cdot\frac{1}{2v}\left(v^2+\frac{1}{4}\right)^{\frac{3}{2}}$$","['derivatives', 'integration']"
1519400,Why do we care whether a functor is representable?,"In the algebraic geometry textbook by Görtz and Wedhorn, the authors prove that several common functors are representable. For example, the Grassmannian functors are representable . Beyond being cute category-theoretical facts, why does this matter? What practical benefits come form knowing that certain functors are representable? Does this observation simplify or make possible the proofs of certain theorems, for example? This is perhaps too broad a question, so I should mention I'm mostly interested in the context of algebraic geometry.","['algebraic-geometry', 'soft-question', 'category-theory']"
