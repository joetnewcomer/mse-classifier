question_id,title,body,tags
2186411,Distance between ellipse and line,What is the distance between the ellipse $$\frac{x^2}{9}+\frac{y^2}{16}=1$$ and the line $y=6-x$. I think I need to be using Lagrange Multipliers but don't know how.,"['calculus', 'analytic-geometry', 'multivariable-calculus', 'maxima-minima', 'lagrange-multiplier']"
2186415,Computing homology/cohomology of unit tangent bundle,"This is a continuation of my previous question here: Homeomorphism for computing homology/cohomology of unit tangent bundle I am trying to calculate the homology and cohomology of the space
$$T=\{(v,w)\in S^n \times S^n \mid v \cdot w = 0 \}$$
which is the unit tangent bundle, or sometimes called the Stiefel 2-manifold $V_2(\mathbb{R}^{n+1})$. Instead of using a Gysin sequence ( The circle bundle of $S^2$ and real projective space ) or determining the cell structure of $T$ based on the cell structure of $SO(n)$ (see previous question), the goal is to define
$$T_+=\{(v,w) \in T \mid v_0 \ge 0,  \ \  T_-=\{(v,w) \in T \mid v_0 \le 0 \}$$
where $v_0$ is the first coordinate of $v$ in $(v,w)$. Then I am supposed to prove that
$$T_+ \cong S_+ \times S^{n−1}, \ \ T_- \cong S_- \times S^{n-1}$$
where $S_+=\{v\in S^n \mid v_0 \ge 0\}$ and $S_-=\{v\in S^n \mid v_0 \le 0\}$. This proof is done in the previous question. This might be obvious, but from here I don't see how having these homeomorphisms gives us an alternate technique for homology/cohomology calculations. Update (3/17/17): My first thought was obviously to use Mayer-Vietoris. 
\begin{eqnarray*}
H_{n+1}(T) &\rightarrow& H_n(T_+ \cap T_-) \rightarrow H_n(T_+) \oplus H_n(T_-) \rightarrow H_n(T) \rightarrow H_{n-1}(T_+ \cap T_-) \rightarrow H_{n-1}(T_+) \oplus H_{n-1}(T_-) \\
\cdots &\rightarrow& H_1(T_+) \oplus H_1(T_-) \rightarrow H_1(T) \rightarrow H_0(T_+ \cap T_-) \rightarrow H_0(T_+) \oplus H_0(T_-) \rightarrow H_0(T) \rightarrow 0.
\end{eqnarray*}
Since $T_+ \cap T_- \simeq S^{n-1}$ and $T_{\pm} \simeq S_{\pm} \times S^{n-1}$, we have
\begin{eqnarray*}
H_{n+1}(T) &\overset{\partial_*}\rightarrow& H_n(S^{n-1}) \overset{\iota_*}\rightarrow H_n(S_+ \times S^{n-1}) \oplus H_n(S_- \times S^{n-1}) \overset{1-f_*}\rightarrow H_n(T) \overset{\partial_*}\rightarrow H_{n-1}(S^{n-1}) \\ 
&\overset{\iota_*}\rightarrow& H_{n-1}(S_+ \times S^{n-1}) \oplus H_{n-1}(S_- \times S^{n-1}) \cdots \overset{\iota_*}\rightarrow H_1(S_+ \times S^{n-1}) \oplus H_1(S_- \times S^{n-1}) \\
&\overset{1-f_*}\rightarrow& H_1(T) \overset{\partial_*}\rightarrow H_0(S^{n-1}) \overset{\iota_*}\rightarrow H_0(S_+ \times S^{n-1}) \oplus H_0(S_- \times S^{n-1}) \overset{1-f_*}\rightarrow H_0(T) \rightarrow 0.
\end{eqnarray*}
So take for example $n = 4$. Then $H_i(S^{n-1}) = H_i(S^3)$ which is only nontrivial for $i = 0, 3$. Also $H_i(S_+ \times S^{n-1}) \simeq H_i(S_+) \times H_i(S^{n-1}) = H_i(S^{n-1}) = H_i(S^3)$ since $S_+$ is contractible. So 
\begin{eqnarray*}
0 &\rightarrow & H_{4}(T) \overset{\partial_*}\hookrightarrow \mathbb{Z} \overset{\iota_*}\hookrightarrow \mathbb{Z} \oplus \mathbb{Z} \overset{1-f_*}\rightarrow H_3(T) \rightarrow 0 \rightarrow 0 \oplus 0 \rightarrow H_2(T) \rightarrow 0 \rightarrow 0 \rightarrow H_1(T) \overset{\partial_*}\hookrightarrow \mathbb{Z} \\
&\overset{\iota_*}\hookrightarrow& \mathbb{Z} \oplus \mathbb{Z}
\overset{1-f_*}\rightarrow H_0(T) \rightarrow 0.
\end{eqnarray*}
From here, $H_2(T) = 0$. Since $\iota_*$ is injective, by exactness we get $\partial_*: H_1(T) \rightarrow \mathbb{Z}$ is the zero map. Thus, $H_1(T) = 0$, but that is not correct . (I think $H_1(T)$ is supposed to be $\mathbb{Z}_2$.) Also, how do we determine $f_*$? Should $f_*$ sometimes be multiplication by 2 and sometimes be 0 depending on whether $n$ is even or odd? Is the following passage from Hatcher's VB text relevant to the explanation? (And if so, could someone further explain it? I don't really understand what it's saying).","['algebraic-topology', 'group-cohomology', 'general-topology', 'homology-cohomology']"
2186442,Writing columns of a matrix as linear combinations of other columns,Let A be the matrix: $$\begin{pmatrix} 1&2&3&2&1&0\\2&4&5&3&3&1\\1&2&2&1&2&1 \end{pmatrix}$$ What is the best way to write the fifth and sixth columns of the matrix as linear combinations of the first and third columns?,"['matrices', 'linear-algebra', 'vector-spaces']"
2186445,What is the bandwidth of a matrix?,"I was solving a problem which involved finding the bandwidth of a matrix. I interpreted the bandwidth as a non-negative number which is closest to the diagonal. And this interpretation of mine does work on some examples. However, the condition is: Bandwidth of a matrix A is defined as the smallest non-negative integer K such that A(i, j) = 0 for |i - j| > K. Now, I am confused as the condition says that a[i,j] should be 0 and |i-j| of the same should be > K. I am not able to figure out why a[i,j] should be 0. Please help me clearing what K is and what does this condition evaluate to.",['matrices']
2186459,Find $1^2+3^2+...99^2$ given $1^1+2^2+...+100^2$ and $1^1+2^2+...+50^2$,"We know that $1^1+2^2+...+100^2=338350$ and $1^1+2^2+...+50^2=42925$. Find $1^2+3^2+...99^2$. I don't know really where to start. I tried to find a pattern in the sequences, but there was none. Can I substitute values for the equations?","['summation', 'sequences-and-series']"
2186504,"Find Center of Circle given Radius, Circumference Point, and that Point's Rotation","I need to find the center point of a circle $(x,y)$ given: • The radius $\mathbf r$ of the circle • A point on the circumference of the circle $\mathbf (a,b)$ • The clockwise degrees of rotation $\mathbf t$ of the point $(a,b)$ about the center point $(x,y)$ Here's an illustration : I've tried $\begin{cases}
x=a+r\;\cos(t) \\
y=b+r\;\sin(t)
\end{cases}$ and it seemed to get me close but it's possible I'm missing an additional piece of the puzzle.","['circles', 'trigonometry', 'geometry']"
2186553,Weightest Rankings Table for Office Pool League,"My office recently got a pool table and many of us here are quite competitive, others are not but everyone is interested in a office pool ranking system. I have created a spreadsheet system for logging results but I cannot figure out a way of ranking fairly. I ideally we would like to have a system of weighted rankings, so if a low ranked player (say using data from the last month) beats the office pool champ it has a higher effect than than if the office champ beats Mr low-rank. I thought about a system of using only the scores against OTHER opponents to use for the adjusting of the players rankings but I can't figure out a system where this works. it seems like high ranking players might lose ranking by beating lower level opposition. All the matches are just W/L checks, no other variables. Does anyone know if a sensible matrix/formula/not sure that would be good for us to use here. This one has be a little stumped.","['matrices', 'statistics']"
2186570,"If two group actions on a set are both transitive, must they be the same?","Suppose we have a group $G$ and a set $S$ and two different group actions
$$
 \phi:G \to \mathrm{Sym}(S) \qquad \psi:G \to \mathrm{Sym}(S)
$$
so that both $\phi$ and $\psi$ are transitive. Can we conclude from this that $\phi = \psi$? If not, what is a counterexample? If not, are there situations in which this does hold, for example, if $S$ is finite?","['group-actions', 'abstract-algebra', 'group-theory']"
2186695,Proof that $a_n < b_n \implies \lim(a_n) \le \lim(b_n)$,"First of all, I'm aware that there are many questions like this on the site, but they all seem to be related to either $\limsup$ or $\liminf$ and I couldn't find anything that would help me with my problem. I've done some Googling and found some great resources, but I'm still not quite sure how to get to some steps and would like your assistance. The problem is as follows: Given $a_n < b_n$ prove that $\lim_{n\to \infty}(a_n) \le \lim_{n\to\infty}(b_n)$ . The proof is then done by contradiction, assuming that $a = \lim_{n\to \infty}(a_n) > b =\lim_{n\to\infty}(b_n)$ . We take an $\epsilon = \frac{a-b} 2$ , so that the $\epsilon$ -neighborhoods of $a$ and $b$ are disjoint. From the definition of limits, we now know that there is such a $N$ , so that $\forall n > N : |a_n-a|<\frac\epsilon2$ and $|b_n-b|<\frac\epsilon2$ . The next step is absolutely always confusing. Two variants I've found are either: $a_n>a-\epsilon=a-\left(\frac{a-b} 2\right)=b+\left(\frac{a-b} 2\right)=b+\epsilon>b_n$ In which I do not understand why any two terms of that (in)equality are like that, or it is said that if $a > b$ , there must be such an $\epsilon$ so that $a - \epsilon > b + \epsilon$ . Then, $a - \epsilon > b + \epsilon > b_n, a_n > a - \epsilon > b + \epsilon > b_n$ , which contradicts $a_n \le b_n$ . Here I simply cannot comprehend how we came to the conclusion that $a_n > a - \epsilon$ and $b + \epsilon > b_n$ . The definition of the limit uses absolute values everywhere, so surely the values depends on the signs of $a_n$ and $a$ , and $b_n$ and $b$ . Please help me understand what is it that I'm missing here. Thanks in advance!","['real-analysis', 'inequality', 'analysis', 'limits']"
2186738,"Is it possible to exist a ""three-dimensional matrix""?","We all have seen matrices that are ""bi-dimensional"" (i'm using the quotes here because i'm not talking about the number of lines, but about the way you represent a matrix, as a rectangle). I was wondering if we can define a space where we have similar objects, but instead of being a rectangle it would be a box, cubic or non-cubic.  Imagine for a example a space $M$ of ""3D"" Matrices, and a 3D matrix $A$ would have numbers represented by $a_{ijk}$, where $i$ is equivalent to a column, $j$ to a line, and $k$ to another line, but this time in a 3-dimensional way. We can imagine a simple $2\times2\times2$ ""3D-Matrix"" we would have eight entries: $a_{111}, a_{112}, a_{121}, a_{122}, a_{211}, a_{212}, a_{222}$ instead of 4 in a normal matrix. Does this concept exist? I have tried looking in this forum for ""3D matrices"" but didn't found anything. Also looked on google but couldn't find anything. Thanks.",['matrices']
2186769,If $z\mapsto f(z)^n$ is analytic then $f$ is analytic,"Let $U$ be an open connected set in $\Bbb C$ and $f:U\to \Bbb C$ be a continuous map such that $z\mapsto f(z)^n$ is analytic for some positive integer $n$. Prove that $f$ is analytic. I think the statement is FALSE. Consider the function $f(z)=\sqrt z$ in any open connected set $U\subset \mathbb C$ containing $0$. Then $f$ is continuous and $f(z)^2$ is analytic , but $f$ is not analytic. Is my argument correct or there are some misunderstanding ? If the statement is TRUE then how I can proceed to prove it ?","['analyticity', 'complex-analysis', 'analytic-functions', 'complex-numbers']"
2186770,"For finitely generated abelian groups $A$ and $B$, prove that $A \oplus A \simeq B \oplus B$ implies $A \simeq B$","Suppose that $A$ and $B$ are finitely generated abelian groups (NOT necessarily finite, just finitely generated). And suppose that $A \oplus A \simeq B \oplus B$. I need to prove that $A \simeq B$. Now, since $A$ and $B$ are finitely generated abelian groups, we have that both $A$ and $B$ have the unique primary decompositions $A \simeq \mathbb{Z}_{p_{1}^{r_{1}}} \oplus\mathbb{Z}_{p_{2}^{r_{2}}} \oplus \cdots \oplus   \mathbb{Z}_{p_{k}^{r_{k}}} \oplus \mathbb{Z}^{m} $ and $B \simeq \mathbb{Z}_{q_{1}^{s_{1}}} \oplus\mathbb{Z}_{q_{2}^{s_{2}}} \oplus \cdots \oplus   \mathbb{Z}_{q_{l}^{s_{l}}} \oplus \mathbb{Z}^{n}$. Then, $A \oplus A \simeq B \oplus B$ implies that $(\mathbb{Z}_{p_{1}^{r_{1}}} \oplus\mathbb{Z}_{p_{2}^{r_{2}}} \oplus \cdots \oplus   \mathbb{Z}_{p_{k}^{r_{k}}} \oplus \mathbb{Z}^{m}) \oplus (\mathbb{Z}_{p_{1}^{r_{1}}} \oplus\mathbb{Z}_{p_{2}^{r_{2}}} \oplus \cdots \oplus   \mathbb{Z}_{p_{k}^{r_{k}}} \oplus \mathbb{Z}^{m}) 
\simeq (\mathbb{Z}_{q_{1}^{s_{1}}} \oplus\mathbb{Z}_{q_{2}^{s_{2}}} \oplus \cdots \oplus   \mathbb{Z}_{q_{l}^{s_{l}}} \oplus \mathbb{Z}^{n})\oplus (\mathbb{Z}_{q_{1}^{s_{1}}} \oplus\mathbb{Z}_{q_{2}^{s_{2}}} \oplus \cdots \oplus   \mathbb{Z}_{q_{l}^{s_{l}}} \oplus \mathbb{Z}^{n})$ where $p_{i}$, $q_{i}$ are primes. Then, where do I go from here? Note : This question is similar to this one but it is NOT a duplicate because there they are asking specifically for finite abelian groups and I am asking about finitely generated abelian groups. Of course, all finite abelian groups are finitely generated, but there might be nuances involved with finitely generated abelian groups that are not touched upon in the case where the groups are finite, and thus might not be addressed in that answer. Also, in the answer to that question, I do not understand the notation 
$\mathbb{Z}/p^{n_1}\mathbb{Z} \times \mathbb{Z}/p^{n_2}\mathbb{Z} \times \ldots \mathbb{Z}/p^{n_m}\mathbb{Z}$ where $p$ is prime. If you are going to use that notation in your answer to this question, could you please explain to me what that means? Also, please be willing to answer LOTS of follow-up questions! I am going to need to be asking them most likely. Thank you.","['abstract-algebra', 'group-isomorphism', 'abelian-groups', 'finitely-generated', 'group-theory']"
2186784,Does $\int _0^{\infty }\:\frac{1}{1+x^2\left(\sin x\right)^2}\ \operatorname dx$ converge?,I have been trying to prove the following integral: $$\int _0^{\infty }\:\frac{1}{1+x^2\left(\sin x\right)^2}\ dx$$ diverges (please correct me if I am mistaken). I have tried to use different comparison tests (as this is an integral of a positive function) with no success. Any ideas?,"['improper-integrals', 'integration', 'convergence-divergence', 'calculus']"
2186810,Are there infinitely many primes $p$ such that $p^2+1$ is divisible by a prime greater than $p$?,"I've been trying to come up with an elementary construction, but to no avail. Are more advanced tools needed? If we consider an analog to this question where we do not require p to be prime (i.e. if there are infinitely many integers $n$ such that $n^2+1$ is divisible by a prime greater than $n$), then the question becomes much easier: Pick a prime $p$ that is $1$ mod $4$, and let $g$ be a generator of mod $p$. Then choosing $n\equiv g^{\frac{p-1}{4}}$ mod $p$, with $n<p$, works.","['number-theory', 'elementary-number-theory']"
2186858,Second Partials test to classify a critical point,"Look at the function. $h(u, v)  =  u^3 + 12uv − 6v^2$ (i) Find the critical points of h. (ii)    For each critical point in (a), find the value of D(a, b) from the Second Partials test that is used to classify the critical point. For i) I got the answer (0, 0), (-2, 2) by using the equations $h_u=-6u^2+12v=0$
and 
$h_v=12u-6v=0$ How do I find the value of D(a,b) for ii)?","['multivariable-calculus', 'calculus']"
2186867,Cartan's proof of the determination of the metric by means of curvature,"This is our setup: Let $(M,g)$ and $(\tilde{M},\tilde{g})$ be $n$-dimensional Riemannian manifolds. Pick two points $p\in M$ and $\tilde{p}\in\tilde{M}$, fix some linear isometry $$i:\mathrm{T}_p M\to\mathrm{T}_\tilde{p}\tilde{M},$$
  let $V\subseteq M$ be a normal neighborhood of $p$ such that $\exp_\tilde{p}$ is defined on $i\circ\exp_p^{-1}(V)$, and define $$f:V\to\tilde{M},\ \ \ \ q\mapsto\exp_\tilde{p}\circ i\circ\exp_p^{-1}(q).$$ For all $q\in V$, there exists a unique normalized geodesic $\gamma:[0,t]\to M$ in $V$, with $\gamma(0)=p$ and $\gamma(t) = q$. Denote by $P_t$ the parallel transport along $\gamma$ from $\gamma(0)$ to $\gamma(t)$. Define $$\phi_t:\mathrm{T}_q M\to\mathrm{T}_{f(q)}\tilde{M},\ \ \ \ v\mapsto \tilde{P_t}\circ i\circ P_t^{-1}(v)$$ where $\tilde{P_t}$ is the parallel transport along the normalize geodesic $\tilde{\gamma}:[0,t]\to\tilde{M}$ given by $\tilde{\gamma}(0)=\tilde{p}$, $\tilde{\gamma}\,'(0)=i(\gamma'(0))$. Now, suppose we are given a Jacobi field $J$ on $\gamma$ such that $J(0)=0$, and assume (the conditions of the theorem in fact give us this) that $\tilde{J} = \phi_t\circ J$ is a Jacobi field along $\tilde{\gamma} = f\circ\gamma$. Now, in the proof of this theorem (which is found in Do Carmo ), we are told that $\tilde{J}\,'(0) = i(J'(0))$. But why is this so? It seems a bit bizarre for me to even see a derivative inside of another function – the opposite of what happens in the usual chain rule.","['riemannian-geometry', 'differential-geometry', 'curvature']"
2186870,Sums of fifth powers of rational integers,"We have the polynomial identity $360\ (2X + 1) = (X+1)^{5} + (X+4)^{5} + (-X -3)^{5} + (-X -3)^{5} - (X-2)^{5} - (X-2)^{5} + (X-3)^{5} + X^{5}.$ Thus, every rational integer that is the product of $360$ by an odd rational integer is the sum of $8$ fifth powers of rational integers. If $x$ is a rational integer prime to $6$, then $x$ is of the form $y^{5} + 360\ (2t + 1)$, with $y$ and $t$ rational integers. Thus, every rational integer prime to $6$ is a sum of $9$ fifth powers of rational integers. Thus every odd rational integer $n$ is a sum of $10$ fifth powers of rational integers. (If $n$ is prime to $3$, it results a fortiori from the preceding fact. If $n$ is divisible by $3$, $n - 2^{5}$ is a sum of $9$ fifth powers by the preceding fact.) Also, every even rational integer $n$ is the sum of $10$ fifth powers of rational integers. (Indeed, $n - 1^{5}$ or $n - 3^{5}$ is prime to $6$ and is thus a sum of $9$ fifth powers of rational integers by a preceding fact.) Thus every rational integer is a sum of $10$ fifth powers of rational integers. My question is : can this result be improved, in other words : is it proven that every rational integer is the sum of $9$ fifth powers of rational integers ? Thanks in advance for the answers.",['number-theory']
2186883,Visualizing Orbits and Transitivity,"I'm having trouble ""visualizing"" orbits and transitivity. So starting with an example, if I have the group $G=S_4$ acting on a non empty set $A=\{1,2,3,4\}$ I know that for example, the stabilizer of the element $2$, represented $G_2$ is isomorphic to $S_3$, because intuitively, if $2$ 'stays put', the other three element $1,3$ and $4$ can be permuted and thus there are 6 permutations of $\{1,3,4\}$.  Thus I know $$G_2=\{1_{S_4},(1 3),(14),(34),(134),(143)\}$$ Now I'm trying to understand orbits.  Orbits are equivalence classes.  Basically, I think that I'm looking at all 24 permutations acting on an element in $A$.  So, if $\sigma\cdot i=\sigma(i)$, I'm looking for all permutations that send any element to a particular place in the permutation.  So, the orbit of $S_4$ containing 2 would then be $$\{(24),(234),(1342),(1423),(13)(24),(142)\}$$ I'm pretty sure this is wrong.  These are elements of $S_4$ while my action is suppose to be into the set $A$ How do I visualize the appropriate orbits?  How can I view the action that is occurring in my mind so that these misunderstandings don't occur?  The question regarding transitivity also holds, since I need to understand orbits before understanding transitivity.","['permutations', 'abstract-algebra', 'group-theory']"
2186903,Confused about proof of Leibniz Integral Rule,"If we set $G(x) = \int_{0}^{x} f(x,y) dy$, then \begin{align}
\frac{G(x+d)-G(x)}d =& \frac{\int_{0}^{x+d} f(x+d,y)dy - \int_{0}^{x} f(x,y)dy}d \\
=& \frac{\int_{0}^{x}f(x+d,y)dy+\int_{x}^{x+d} - \int_{0}^{x}f(x,y)dy}d
\end{align} By grouping, $$\int_{0}^{x}\frac{f(x+d,y)-f(x,y)}ddy + \int_{x}^{x+d}f(x+d,y)dy,$$ which leads to: $$\int_{0}^{x}f'(x,y)dy + \frac{\int_{0}^{x+d}f(x+d,y)dy-\int_{0}^{x}f(x+d,y)dy}d.$$ Why is the second term not equal to $f(x+d,x)$? I know it isn't, I'm just trying to see where I'm going wrong in the proof.","['multivariable-calculus', 'integration', 'calculus', 'proof-verification']"
2186930,Approximating a Lebesgue measurable set by a finite union of intervals,"I am reading Real Analysis by Yeh and have a question about the following result (Thm 3.25 in the book) Theorem If $E \in \mathfrak{M}_L$ and $\mu_L(E)< \infty$, then $\forall \epsilon>0$ $\exists$ finitely many open intervals $I_1, \ldots, I_N$ s.t. $\mu_L(E \triangle \cup_{n=1}^NI_n)< \epsilon$. Notations: $\mathfrak{M}_L$ is the $\sigma$-algebra of Lebesgue measurable subsets of $\mathbb{R}$, $\mu_L$ denotes Lebesgue measure.  If we're not sure $E \in \mathfrak{M}_L$, then $\mu_L^*(E)$ denotes the Lebesgue outer measure of E.  For intervals $I$, Yeh sometimes uses $\ell(I)$ to denote their length.  The symmetric difference of 2 sets is $A \triangle B:=(A \setminus B) \cup (B \setminus A)$. I didn't know how to prove this, so I read Yeh's proof.  After a while I tried to prove it again but came up with something simpler that seems to work, so wanted to ask if I might have missed something.  My attempt is below, followed by Yeh's proof (it's long, so I of course want something simpler in my notes if possible).  Thanks in advance for any help. My attempt: Fix $\epsilon>0$.  Use the definition of outer measure as an infimum to pick a sequence $(I_n)$ of open intervals s.t. 
$E \subseteq \cup_{n=1}^ \infty I_n$ and $\sum_{n=1}^\infty \mu_L(I_n) \leq \mu_L(E) + \epsilon$.
Since $\mu_L(E)< \infty$, $\sum_{n=1}^\infty \mu_L(I_n)$ converges, so pick $N \in \mathbb{N}$ s.t. $\sum_{n=N+1}^\infty \mu_L(I_n)< \epsilon$.
Then
\begin{split}
\mu_L(E \triangle \cup_{n=1}^NI_n) &= \mu_L \big( (E \setminus \cup_{n=1}^N I_n) \cup ( \cup_{n=1}^N I_n \setminus E) \big) \\
& \leq \mu_L(E \setminus \cup_{n=1}^N I_n)+\mu_L( \cup_{n=1}^N I_n \setminus E) \\
& \leq \mu_L(\cup_{n=1}^\infty I_n \setminus \cup_{n=1}^N I_n)+\mu_L( \cup_{n=1}^\infty I_n \setminus E) \\
& \leq \mu_L(\cup_{n=N+1}^\infty I_n)+\mu_L( \cup_{n=1}^\infty I_n)- \mu_L(E) \\
& \leq \sum_{n=N+1}^\infty \mu_L(I_n)+ \sum_{n=1}^\infty \mu_L(I_n)- \mu_L(E) <2 \epsilon
 \end{split}
where we have repeatedly used that a measure is monotone and subadditive.   In the 4th line, we have also used an earlier fact that $A,B \in \mathfrak{M}_L$, $A \subseteq B$, $\mu_L(A)< \infty$ implies $\mu_L(B \setminus A)= \mu_L(B)- \mu_L(A)$.  Since $\epsilon$ is arbitrary, this is the desired result. (I'm cutting the proof here, but Yeh pretty much bounds each of the 3 pieces on the RHS separately after this).","['real-analysis', 'lebesgue-measure', 'measure-theory']"
2186995,What are the additive (and multiplicative) continuous characters of $\mathbb{F}_p((x))$?,"Let $\mathbb{F}_p((x))$ be the local field of formal laurent series over the finite field $\mathbb{F}_p$ considered as a locally compact field. What are the additive continuous characters $\mathbb{F}_p((x)) \to
 \mathbb{C}^{\times}$? What are the multiplicative characters $\mathbb{F}_p((x))^{\times} \to
 \mathbb{C}^{\times}$? I know how characters of $\mathbb{Q}_p$ are all built out of taking the sum of the fractional part of the $p$-adic expansion which is well defined upto an integer and I understand why it's continuous. For $\mathbb{F}_p((t))$ however I have no idea where to start. The presence of the finite field confuses me when I try to define a homomorphism. I also know that $\mathbb{F}_p((x))^{\times}=\mathbb{F}_p[[x]]^{\times}\times x^\mathbb{Z}$. So it will presumably be enough to understand additive characters of $\mathbb{F}_p[[x]]$. Unfortunately here i'm stuck with the same problem as before...","['number-theory', 'algebraic-number-theory', 'class-field-theory', 'representation-theory']"
2187024,How to find a differential equation given its solution?,"I was given the solution of a differential equation and I need to find its differential equation, specifically a second order differential equation with constant coefficients. $e^x + e^{-x} + e^{2x}$ Someone please help me with this. I am very confused since the solution has three terms. Doesn't the solution should contain only two terms since it is the solution of a second order differential equation?","['derivatives', 'ordinary-differential-equations']"
2187051,Numerical Integration for integrable singularity,"Till this time i have learned three numerical technique  to find the  definite integration. They are Simpson, Trapezoidal and Gauss-legendre formula. The sad thing is that I can't apply these theorem directly of my integration has any integrable singularity within the interval. Can you give me any special technique  so i can use these  theorem for  that type of integrations?","['simpsons-rule', 'numerical-methods', 'integration', 'complex-integration']"
2187063,Why Rolle's theorem gives me wrong answer?,"Find number of zeroes of $f(x) = 1 - x^{-2}$. I assume that this function has two or more zeroes in the domain $ \mathbb{R} - \{0\}$. Since $f^\prime (x) = \large{2\over x^3}$, therefore we can say      $f^\prime(x) \ne 0$ for all $x \in   \mathbb{R} - \{0\}$. Therefore by Rolle's theorem we can say that our assumption is wrong (because if it was correct then for any two zeroes $a,b\in\mathbb{R} - \{0\}$, $f^\prime(c) = 0$ where $c \in [a, b]$)  and  $f(x)$ has one zero at most in $\mathbb{R} - \{0\}$. What we deduced is incorrect given the fact that $f(\pm 1) = 0$ and $\{\pm 1\} \in \mathbb{R} - \{0\}$. Here I followed a similar proof . What is the error in my proof ?","['derivatives', 'real-analysis', 'rolles-theorem', 'calculus', 'continuity']"
2187104,proving that there are infinitely many zero polynomials over a finite field,"Given a finite field F with c elements, how would one prove that there are infinitely many polynomials that represent the zero function over the field F? I know we have infinitely many polynomials over this field, isn't it straightforward that by choosing all the coefficients to be zero all those infinitely many polynomials are zero functions?","['polynomials', 'linear-algebra', 'functions', 'vector-spaces']"
2187175,Find the limit of a function as $ x$ approaches $0$,"How can I find the limit of $\dfrac{\cos(3x) - 1 }{x^2}$ as $x\to 0$? If someone could please break down the steps, for clear understanding. I'm studying for the GRE. Thanks in advance !!","['limits-without-lhopital', 'calculus', 'limits']"
2187228,"How do I find the maximum and minimum points of f(x,y) on a unit circle?","I'm supposed to find the maximum and minimum values of $f(x,y) = xy^2$ on the circle $x^2 + y^2 = 1$. My work so far: $\bigtriangledown f = (y^2 ,xy)$ Let $g(x,y) = x^2 + y^2 $ $\bigtriangledown g = (2x,2y)$ $\bigtriangledown f = \lambda \bigtriangledown g$ and I'm not really sure where to go from here.","['multivariable-calculus', 'optimization', 'lagrange-multiplier']"
2187231,Proving the limit of $\frac{1}{n^2+n}$ = 0 using the $\epsilon$ - N definition,"So, I'm stuck on this question, and have been working on it for a few hours, probably because I'm not 100% in understanding the definition. But here's the question: Using the $\epsilon$ - N definition of the limit prove that, $\lim_{x \to ∞}{1\over(n^2+n)}$ = $0$ (sorry I don't know how to write fractions in limits). In other words, given $\epsilon$ > $0$, find explicitly a natural number N which satisfies the statement in the definition of the limit. So the definition I received in lectures is: Let $(a_n)_1^∞$ ($1$ should be $n=1$, I couldn't get it to work, sorry) be a sequence of real numbers $(a_n)_1^∞$ = {$a_1, a_2, a_3,...$} . Definition: We write $\lim_{n \to ∞} a_n = a$, and say the limit of $(a_n)_1^∞$ equals $a$, if for every $\epsilon$ > 0 there exists N ∈ $\mathbb{N}$ such that if $n ≥ N$, then $|a_n - a| < \epsilon$. So far this is what I've done: |$\frac{1}{n^2+n}$ + 1| < $\epsilon$ $\therefore$ |$\frac{1-n^2+n}{n^2+n}$ + 1| < $\epsilon$ I did try other ways like disregarding the 'n' in the denominator since $n^2$ is more significant then it, but I don't think I'm supposed to do that. I'm really just stuck on what to do next as I don't really understand the process. Any help would be GREATLY appreciated, thanks! :)","['limits', 'propositional-calculus', 'epsilon-delta', 'proof-explanation', 'sequences-and-series']"
2187290,The probability that $a$ and $b$ satisfy the inequality $a-2b+10>0$?,"Nine identical balls are numbered $1,2,3,.........,9$ are put in a bag.$A$ draws a ball and gets the number $a$ and puts back in the bag. Next $B$ draws a ball and gets the number $b$. The probability that $a$ and $b$ satisfy the inequality $a-2b+10>0$ ? My Try :- Total pairs of $(a,b)$ possible are $81$ . If $a=1$, then $b = 1,2,3,4,5$. Similarly for $a=2$. If $a=3$, then $b = 1,2,3,4,5,6$. Similarly for $a=4$. If $a=5$, then $b = 1,2,3,4,5,6,7$. Similarly for $a=6$. If $a=7$, then $b = 1,2,3,4,5,6,7,8$. Similarly for $a=8$. If $a=9$, then $b = 1,2,3,4,5,6,7,8,9$. Total favourable pairs are $61$. Hence, Total Probability = $\frac{61}{81}$ However, I don't have an answer for  this. Am I right or missing something ?","['probability-theory', 'inequality', 'probability', 'discrete-mathematics']"
2187304,Show that $\lim_{x \to c} x^{3}=c^{3}$,Please check my proof I will use the fact that $\lim_{x \to c}x^{3}=c^{3}$ equivalent $\lim_{x \to c}x\lim_{x \to c}x\lim_{x \to c}=(c)(c)(c)$ for $\lim_{x \to c} x=c$ we let $\epsilon >0$ and $\delta >0$ we have $0<|x-c|<\delta \leftrightarrow |x-c|<\sqrt[3]{\epsilon }$ but in this case we want to proove $\lim_{x \to c}x^{3}=c^{3}$ We will have $0<|x-c|<\delta \leftrightarrow |x-c|<\sqrt[3]{\epsilon }$ $0<|x-c|<\delta \leftrightarrow |x-c|<\sqrt[3]{\epsilon }$ now $\lim_{x \to c}x^{3}=c^{3}\rightarrow \lim_{x \to c}x\lim_{x \to c}x\lim_{x \to c}x=(c)(c)(c)$ $0<|x-c|<\delta \leftrightarrow |x-c||x-c||x-c|<\sqrt[3]{\epsilon }\sqrt[3]{\epsilon }\sqrt[3]{\epsilon }=\epsilon $,"['real-analysis', 'proof-verification', 'limits']"
2187317,Contacting Hyperplanes in a CAT(0) cube complex,"I've been reading about CAT(0) cube complexes and have come across an assertion about contacting hyperplanes that I can not figure out. First, we say that two hyperplanes $V, W$ cross if there is a $2$-cube whose distinct midcubes are contained in $V, W$ respectively. Two hyperplanes, $V, W$ osculate if they do not cross and there exist distinct $1$-cubes dual to $V,W$ which share a vertex. We say two hyperplanes contact if they cross or osculate, which is if $N(V) \cap N(W) \neq \emptyset$. (Where $N(V)$ is the carrier of the hyperplane $V$.) (These definitions are from Mark Hagen's paper, Weak Hyperbolicity of Cube Complexes and Quasi-Arboreal Groups https://arxiv.org/pdf/1101.5191.pdf ) This paper states two hyperplanes $V,W$ contact if and only if no other hyperplane $U$ separates $V$ and $W$. The same statement is in other papers and in Hagen's thesis he actually defines contact as the separating condition and states that it is equivalent to the definition above. So it seems that there should be a straightforward proof, but in discussions with other graduate students we have not uncovered it. This question has risen in the context of understanding the proof that the contact graph of a CAT(0) cube complex is quasi-isometric to a tree. The scenario we are worried about is roughly sketched in this picture . The orange hyperplanes are not separated by the blue (or any other hyperplane) but do not contact. Any thoughts would be appreciated, thanks!","['geometric-topology', 'geometric-group-theory', 'geometry']"
2187326,Find the quickest distance from one angle to the next,"BTW, I don't really know how to use LaTeX, so please correct this for me... thanks. So I've been wrestling this for about an hour, but it kept failing all the time.  Basically, I'm trying to find the shortest direction to change from one angle to the next.  Here are some examples: From 90 degrees to 225, it would be faster to increase angle, since it would only have to go 135 degrees instead of 225 degrees rotating the other way. From 90 degrees to 315, it would be faster to decrease angle.  Reason is opposite of previous. Sorry that I don't have an image, but if this is unclear please ask.
Is there a formula that I can use that doesn't relate conditional statements?  Thanks for your help guys :D",['trigonometry']
2187381,"Prove that if a commutative ring $R$ is integral domain, then the polynomial ring $R[x]$ is also an integral domain.","I know that it is true that if a commutative ring $R$ is integral domain, then the polynomial ring $R[x]$ is also an integral domain. But I am having troubles with proving this statement. Can I ask for someone's help, please?","['abstract-algebra', 'ring-theory', 'polynomials', 'integral-domain']"
2187388,How do I use the convolution theorem to solve an initial value problem?,"I'm not quite sure how to use the convolution theorem for this problem. My attempt is that I took the laplace transform of both sides, however I'm confused as to what to do after. Thanks!","['initial-value-problems', 'ordinary-differential-equations', 'convolution', 'laplace-transform']"
2187405,prove that $\lim_{x \to 1}\frac{x^{2}-x+1}{x+1}=\frac{1}{2}$,"Please check my proof Let $\epsilon >0$ and $\delta >0$ $$0<x<\delta \rightarrow \frac{x^{2}-x+1}{x+1}-\frac{1}{2}<\epsilon $$ $$\frac{2x^{2}-2x+2-x+1}{2x+2}<\epsilon $$
$$\frac{2x^{2}-3x+1}{2x+2}<\epsilon $$
since   $\frac{2x^2-3x+1}{2x+2} <\frac{2x^{2}-3x+2}{2}$ then $\frac{2x^{2}-3x+1}{2}< \epsilon $ $2x^{2}-3x+1<2\epsilon $
choose $2\epsilon =\delta $ then $\frac{2x^{2}-3x+1}{2}<\frac{2\epsilon }{2}=\epsilon $ by transitivity of inequality $\frac{2x^{2}-3x+1}{2x+2}<\epsilon $","['real-analysis', 'proof-verification', 'limits']"
2187422,How can we show that $\int_{0}^{\pi/4}{\tan^{2e}x-2\sin^2 x\over \sin(2x)\ln{\tan x}}\mathrm dx={1\over 2}+{1\over 2}\ln{\pi\over 2}?$,"We have the integral $$\int_{0}^{\pi/4}{\tan^{2e}x-2\sin^2 x\over \sin(2x)\ln{\tan x}}\mathrm dx={1\over 2}+{1\over 2}\ln{\pi\over 2}\tag1$$ What other methods can employ to prove $(1)$? An attempt: Rewrite $(1)$ as $$\int_{0}^{\pi/4}{\tan^{2e} x\over \sin(2x)\ln{\tan x}}\mathrm dx-2\int_{0}^{\pi/4}{\sin^2x\over \sin(2x)\ln{\tan x}}\mathrm dx=I_1+I_2\tag2$$ $u=\tan x$ $\implies du=(1+u^2)dx$, then $I_1$ becomes $${1\over 2}\int_{0}^{1}{u^{-e-1}\over \ln u}\mathrm du\tag3$$ Again, $u=e^v \implies du=e^vdv$, then $(3)$ becomes $${1\over 2}\int_{0}^{\infty}e^{-2ev}\mathrm dv={1\over 4e}\tag4$$ $$I_2=\int_{0}^{\pi/4}{\tan x\over \ln \tan x}\mathrm dx$$ $u=\tan x \implies (1+u^2)dx$, then $I_2$ becomes $$\int_{0}^{1}{\mathrm du\over \ln u }{\cdot {1\over u^{-1}+u}}\tag5$$ Again, $u=e^v \implies du=e^vdv$, then $(5)$ becomes $${1\over 2}\int_{0}^{\infty}{e^{-v}\over v}\cdot{\mathrm dv\over \cosh v}=\int_{0}^{\infty}{\mathrm dv\over v(1+e^{2v})}\tag6$$ Not sure how to deal with $(6)$...(diverge?)","['improper-integrals', 'integration', 'definite-integrals', 'calculus']"
2187451,Are there any paths that will always show if there is a limit?,I'm trying to do limits in 3D and I'm wondering whether or not there are paths along which the limit of any function at any point can always be found. In my book it isn't clear whether this exists or not; neither is it clear how to choose a path if this does exist. In the book they replace $y$ with $kx$ a lot but sometimes they replace $x$ and $y$ with $0$ separately  and sometimes they use $x^2$. I've seen some people have already asked similar questions but about specific formulas and I can't link that to my exact question. Thanks for any help!,"['3d', 'limits']"
2187546,Interesting limit with log function,Compute the following limit:$$ \lim _{n \to \infty} \frac{1}{n}\sum_{k=0}^{n-1}\left[\frac{k+1}{n}-\frac{1}{2}\right]\log(2n-2k-1) .$$ I do not know how to start as I am new in this subject. Can you help me?,"['sequences-and-series', 'limits']"
2187559,Finite almost everywhere and essential supremum,"I have difficulty in understanding the difference of the concepts ""finite almost everywhere"" and having finite essential supremum (as in $\Vert f \rVert_\infty= inf\{a \geq 0: \mu(\{x : |f(x)| >a \}) =0\} < \infty$. I know that if a function f is integrable then it is finite almost everywhere.
Is $\lVert f \rVert_\infty < \infty $ the same as being bounded almost everywhere? A function such as $\frac{1}{\sqrt{x}}$ is finite almost everywhere on $[0,1]$ (since it is integrable) but not bounded almost everywhere? I would be very greatful if some one could help me and explain the difference and maybe come with some examples. Kind regards,","['functional-analysis', 'real-analysis', 'lp-spaces', 'measure-theory']"
2187586,"Prove that for every countable ordinal $\alpha$, $\alpha\times[0,1)$ is order isomoprhic to $[0,1)$","I need to prove that for every countable ordinal $\alpha$, $X_{\alpha} = \alpha\times[0,1)$ is order isomorphic to $[0,1)$, where the order on $X_{\alpha}$ is the lexicographical order. I wanted to go by induction on the countable ordinals. I was able to manually construct a function $f:X_{\omega}\to[0,1)$ that is an order isomorphism, so the base case I have. So, suppose by induction that for some countable ordinal $\alpha$, for all $\beta < \alpha$, $X_{\alpha}\cong [0,1)$. I need to show that $X_{\alpha+1}\cong[0,1)$. So my attempt was to use the fact that $X_{\alpha + 1} = \left(\alpha\cup\{\alpha\}\right)\times[0,1)$ and to use the induction hypothesis to get an order isomorphism $f'$ between $\alpha\times[0,1)$ and $[0,1)$, and to use the trivial isomorphism $f''$ between $\{\alpha\}\times[0,1)$ and $[0,1)$, and then take the union of these functions $f = f'\cup f''$. But then a problem arises when trying to compare $f(\alpha,r)$ and $f(\gamma,q)$ where $\gamma < \alpha$, since nothing promises me that $f'(\gamma,q) < f''(\alpha,r)$. I assume after I figure out for successor ordinal, the generalization to a limit ordinal will not be difficult?","['order-theory', 'elementary-set-theory', 'ordinals']"
2187649,Extrema under constraints,"Find the critical points of the function $f(x_1, x_2)=x_1x_2$ under the constraint $2x_1+x_2=b$. Using the method of Lagrange multipliers I got the following: \begin{equation*}L(x_1,x_2,\lambda )=x_1x_2-\lambda \cdot \left (2x_1+x_2-b\right )\end{equation*} \begin{align*}&L_{x_1}(x_1,x_2,\lambda)=0 \Rightarrow x_2-2\lambda=0  \\ & L_{x_2}(x_1,x_2,\lambda)=0 \Rightarrow x_1-\lambda=0  \\ &  L_{\lambda}(x_1,x_2,\lambda)=0 \Rightarrow -\left (2x_1+x_2-b\right )=0\end{align*} Solving this system we get the critical point $\left (\frac{b}{4}, \frac{b}{2}\right )$. To check what extrema (if there exists) it is, we do the following: 
$$f_{x_1} =x_2 , \ f_{x_2}=x_1 , \ f_{x_1x_1}=0 . \ f_{x_1x_2}=1 , \ f_{x_2x_2}=0$$ Then:  \begin{equation*}f_{x_1x_2}\left (\frac{b}{4}, \frac{b}{2}\right )=1>0 \ \text{ and } \ f_{x_1x_1}\left (\frac{b}{4}, \frac{b}{2}\right )f_{x_2x_2}\left (\frac{b}{4}, \frac{b}{2}\right )-\left (f_{x_1x_2}\left (\frac{b}{4}, \frac{b}{2}\right )\right )^2=0\cdot 0-1=-1<0\end{equation*} Therefore, $\left (\frac{b}{4}, \frac{b}{2}\right )$ is a saddle point. Is this correct? Because at Wolfram there are some maxima. $$$$ Then I want to check if there are extrema if we have an other constraint, $\{(x_1, x_2)\in \mathbb{R}^2 \mid x_1\geq 0, x_2\geq 0\}$. A critical point is \begin{equation*}\nabla f=\begin{pmatrix}0 \\ 0\end{pmatrix}\Rightarrow \begin{pmatrix}x_2 \\ x_1\end{pmatrix}=\begin{pmatrix}0 \\ 0\end{pmatrix} \Rightarrow x_1=0 \ \text{ und } \ x_2=0\end{equation*} But this point is again a saddle point, right? Then I wan to check if there are extrema if we have an other constraint, $\{(x_1, x_2)\in \mathbb{R}^2 \mid x_1\geq 0, x_2\geq 0\}$. A critival point is \begin{equation*}\nabla f=\begin{pmatrix}0 \\ 0\end{pmatrix}\Rightarrow \begin{pmatrix}x_2 \\ x_1\end{pmatrix}=\begin{pmatrix}0 \\ 0\end{pmatrix} \Rightarrow x_1=0 \ \text{ and } \ x_2=0\end{equation*} But this point is again a saddle point, right?","['optimization', 'constraints', 'calculus', 'multivariable-calculus', 'lagrange-multiplier']"
2187653,Silly question on trigonometry,"So, the question was about finding the range of $\cos(2\sin x)$. He said that the range of $2\sin(x)$ is from $-2 \to 2$ which is quite easy to understand. Then he went on to draw the circle saying that the value of $\cos2$ is in the second quadrant and the value of $\cos(-2)$ is in the fourth quadrant. Then, he marked the range of $\cos[-2,2]$ in the figure with red. But, why did he mark the right side only? Why didn't he mark the left side of the circle? Any sort of help is much appreciated! Thanks a ton in advance!",['trigonometry']
2187667,Definition of Sheaf of Rational Functions on Integral Scheme?,"Given an integral (i.e. irreducible and reduced) scheme $X$ of finite type over an algebraically closed field $k$.
We can consider $X$ as a variety.
On a cover $\{U_i\}$ of affine varieties, $U_i \simeq V(I_i)$ for $I_i \subset k[x_1,\dots ,x_n]$, the field of rational functions $K(U_i)$ is given as the quotient field of the coordinate ring $k[x_1,\dots,x_n]/I_i$.
We may consider the sheaf of rational functions on $U_i$, which just gives the field of rational functions on every open.
This should define a sheaf on all of $X$. Given an arbitrary scheme $X$.
In the section on Cartier Divisors in Hartshorne, there is a very complicated definition for the sheaf of rational functions on $X$ given.
The text states: ""On an arbitrary scheme, the sheaf $\mathcal{K}$ replaces the concept of function field of an integral scheme."" What is a good definition for the sheaf of rational functions on an arbitrary integral scheme?
  That is, a definition not as specific as the first one, but not as general as the second one. The question arose when studying the chapter on line bundles on curves in Gathmann's lecture notes.
There the sheaf of rational functions on a curve $X$ is used without prior introduction.
Does the word curve imply that the scheme is a variety?
I always thought of a curve as any one-dimensional scheme.","['schemes', 'sheaf-theory', 'algebraic-geometry']"
2187676,Discrete math(Divisors and primes),"Is the following statement true or false?Explain.
There are integers $x,y,$ and $z$ such that $14$ divides $2^x  × 3^y ×  5^z$. My guess is false but I don't know how to explain it?Does it have anything to do with the fundamental theorem of arithmetic?",['discrete-mathematics']
2187679,What's the right way of finding the median of the lower and upper quartiles of a box and whisker plot?,"Let's say I have a set of test scores from 20 applicants $5, 15, 16, 20, 21, 25, 26, 27, 30, 30, 31, 32, 32, 34, 35, 38, 38, 41, 43, 66$ Obviously, the median of this set would be $30$ and $31$, so I would just get the average, though that's not what I'm looking for. What I'm really looking for is the median of the lower and upper quartiles. I have found 2 ways, both yielding different answers. 1st way : Finding the lower quartile, the range would be $5$ to $30$, and the median of the set would be $21$. This is based on a video that I watched. 2nd way : Same problem, but instead of just finding the median, I use a formula. $x_{kth}=(\frac{k}{4})n=\frac{1}{4}(20)=5$ This means the median for the lower quartile is the 5th spot, which is $21$. Sounds good, except that I have to do an extra step. Get the average of the values $x_k$ and $x_{k+1}$ positions. This means I have to average the 5th and 6th positions. $Q_1=\frac{5_{th}+6_{th}}{2}=\frac{21+25}{2}=23$ This is entirely different from $21$. This method came from a textbook. Which way is correct?","['statistics', 'order-statistics']"
2187701,"Prove that if an inverse function exists, then it is unique.","I have been trying to solve this proof for some time in preparation for a test, though I'm not sure if I am going about this the correct way. Prove that if an inverse function exists, then it is unique. I am attempting proof by contradiction. Let $f$ be a function, with an inverse. Let $a$ be an inverse of $f$. Let $b$ also be an inverse of $f$. $$f\circ a = x$$
$$f\circ b = x$$
$$(f\circ b)(f\circ a)  = x(f\circ a)$$
$$(f\circ b)x  = x(f\circ a)$$
$$(f\circ b)  = (f\circ a)$$
because $(f\circ b) = x$ and $(f\circ a) = x$, $a = b$, thus proving that if an inverse of $f$ exists, it is then unique. I'm not sure why, but something feels a bit off with my reasoning, or at least the way I have explained it. If anyone could shed some light on a better way for me to explain this, I would greatly appreciate it.","['proof-explanation', 'inverse', 'functions', 'proof-verification']"
2187703,Can we judge closedness of vitali set?,"I am not able to judge whether the vitali set is closed or not( in its parent set or u can say reals).....
Since it is 'mainly ' a subset of irrationals(except one rational representative) and irrationals are not closed subset of reals....I believe(am not sure) vitali set is not closed.....
But if I construct a set by taking irrational representatives in such a way that these form a sequence with 0(or any rational) as the limit point and the rational representative to be the same limit point.......then can I say that this set is closed???
M very confused.....kindly help me understand this concept.....
Any help will be heartily appreciated.....","['lebesgue-measure', 'measure-theory']"
2187765,"If $H$ is a normal subgroup of $G$ with $G/H$ abelian, then the commutator subgroup of $G$ is in $H$.","This is part of Exercise 2.7.9 of F. M. Goodman's ""Algebra: Abstract and Concrete"" . Let $C$ be the commutator subgroup of a group $G$. Show that if $H$ is a normal subgroup of $G$ with $G/H$ abelian, then $C\subseteq H$. The following seems to be wrong. My Attempt: The commutator subgroup $C$ of $G$ is the subgroup generated by all elements of the form $xyx^{-1}y^{-1}$ for $x, y\in G$. Since $G/H$ is abelian, we have for $x, y\in G$,
$$\begin{align}
xyx^{-1}y^{-1}H&=xyy^{-1}x^{-1}H \\
&=H,
\end{align}$$ so that all elements of the form $xyx^{-1}y^{-1}$ are in $H$. Thus $C\subseteq H$. But I don't use the fact that $H$ is normal. What have I done wrong and what is the right proof?","['abstract-algebra', 'group-theory', 'proof-verification']"
2187774,Opposite of Levi-Civita,I know that every Riemannian metric induces a unique connection. Question: My question is if the opposite direction is indeed true.  That is given a connection $\nabla$ on $M$ does there exist a Riemannian metric $g_{\nabla}$ on $M$ such that $\nabla$ is the Levi-Civita connection for $g_{\nabla}$?,"['fiber-bundles', 'riemannian-geometry', 'differential-geometry', 'metric-geometry', 'connections']"
2187784,Find the image of the Möbius transformation,"My question is: Find the image of the area $C=\{z\in \mathbb{C}:|z+3|\geq 3\}$ of the Möbius transformation $w=f(z)=\frac{z}{z+6}$. I have drawn the image in the z-plane and then taken three points $z_{1},z_{2},z_{3}$ and then used the function for $w$ to get values for $w_{1},w_{2},w_{3}$. Then I have drawn the image for the w-plane. See figure. Is this correct?","['complex-analysis', 'mobius-transformation']"
2187807,Question about an inference involving an uncountable union of null events,"Let $P$ and $Q$ be random probability measures on $(\Omega, \mathcal{F}, \mu)$ a probability space. That is, $P: \mathcal{F} \times \Omega\to [0,1]$ is a probability measure on $(\Omega, \mathcal{F})$ for each fixed $\omega \in \Omega$ and measurable for each fixed $A \in \mathcal{F}$. Same for $Q$. Let $d$ be the total variation distance, i.e. $d(\mu_1, \mu_2) = \sup_{A \in \mathcal{F}}|\mu_1(A) - \mu_2(A)|$ for any probability measures $\mu_1, \mu_2$ on $(\Omega, \mathcal{F})$. In this paper , I believe that something like the following inference is made (the relevant part is on page 644 in the proof of Theorem 9.2; I'm abstracting away from details in the paper that I believe to be irrelevant to my question). Suppose that for all $A \in \mathcal{F}$ and for $\mu$ almost every $\omega$ we have
$$|P(A)(\omega) - Q(A)(\omega)| \leq g(\omega),$$
where $g$ is a random variable on $(\Omega, \mathcal{F})$. Then, taking a supremum over $A \in \mathcal{F}$ yields
$$d(P(\omega), Q(\omega)) \leq g(\omega)$$
for $\mu$ almost every $\omega$. But this seems problematic to me since there are potentially uncountably many $A$. That is, we know that for each $A \in \mathcal{F}$, there is a $\mu$-null set $F_A$ of points at which the first inequality fails. The set of points at which the second inequality fails is $\cup_A F_A$, which may have positive $\mu$ probability because the union is uncountable. Am I correct to be doubtful about this or is the inference valid? Added. Actually, the inference in the paper is slightly different from the way I represented it above. But my worry remains and I'd appreciate feedback on both inferences. Suppose now that for all $A \in \mathcal{F}$ and for $\mu$ almost every $\omega$ we have
$$|P(A)(\omega) - Q(A)(\omega)| \leq f(A,\omega),$$
where $f$ is a real-valued function on $\mathcal{F} \times \Omega$ satisfying any requisite measurability properties. Then, taking a supremum over $A \in \mathcal{F}$ yields
$$d(P(\omega), Q(\omega)) \leq \sup_{A \in \mathcal{F}}f(A,\omega)$$
for $\mu$ almost every $\omega$. Now the worry is this. Let $F$ be the set of points at which the last inequality fails and let $\omega_0 \in F$. Then for some $A_0 \in \mathcal{F}$ we have
$$|P(A_0)(\omega_0) - Q(A_0)(\omega_0)| > \sup_A f(A, \omega_0) \geq f(A_0, \omega_0).$$
So $\omega_0$ is a point at which $|P(A)(\omega) - Q(A)(\omega)| \leq f(A,\omega)$ fails for some $A$. Hence, repurposing the notation introduced above, we have $F \subseteq \cup_A F_A$. And $F$ need not have probability $0$ as the union is uncountable, contradicting our inference.","['real-analysis', 'probability', 'measure-theory', 'probability-theory']"
2187811,Jacobson Radical of External Direct Sum of Rings,"The fact I want to prove is given $A$ and $B$ are rings, then 
  $$J(A\oplus B) = J(A)\oplus J(B).$$ I am not happy with my current proof, which I feel like I just patched things from different sources together and I think it barely works. I want to check if it's correct and I am looking for a (simpler) proof that perhaps using a similar kind of argument both ways. My current proof: $J(A)\oplus J(B)$ is a (right) quasi-regular ideal since both $J(A)$ and $J(B)$ are, there exists $x$ and $y$ such that $(1-a)x=1$ and $(1-b)y=1$ for all $a\in J(A)$, $b\in J(B)$, $(1,1)-(a,b)=(1-a,1-b)\times (x,y)=(1,1)$. I know that the Jacobson radical contains all right quasi-regular ideals, so $J(A)\oplus J(B)\subset J(A\oplus B)$. False Reasoning, correction in answers. Conversely, every maximal right ideal of $A\oplus B$ is of the form $M_A\oplus M_B$ where $M_A$ is a maximal ideal of A etc. If $(a,b)\in J(A\oplus B)$, then $(a,b)\in M_A\oplus M_B$ for all maximal right ideals $M_A$, $M_B$ in $A$ and $B$ respectively. Therefore $(a,b)\in J(A)\oplus J(B)$, so $J(A\oplus B) \subset J(A)\oplus J(B)$.","['abstract-algebra', 'ring-theory', 'maximal-and-prime-ideals', 'ideals']"
2187827,How do you prove that a commutative C* algebra has no nontrivial nilpotents?,"In one of the responses to this question Commutative unital Banach algebra with nilpotent elements someone comments ""But of course, you can't find a commutative C∗-algebra with nontrivial nilpotents."" How do you prove this?","['functional-analysis', 'c-star-algebras']"
2187837,Sturm–Liouville problem: approximating potential.,"Let one-dimentional Sturm–Liouville problem:
$$
\frac{d^2f(x)}{dx^2}+U(x)f(x)=\lambda f(x)
$$
with some appropriate boundary conditions, have a set of solutions $\{\lambda_i,\phi_i\}$. Let further the sequence of functions $u^{(n)}(x)$ uniformly converge to $U(x)$ as $n$ tends to infinity. Is it true, that assuming the same boundary conditions the set of solutions of the approximate problem
$$
\frac{d^2f(x)}{dx^2}+u^{(n)}(x)f(x)=\lambda f(x),
$$
$\{\lambda^{(n)}_i,\phi^{(n)}_i\}$ converges to $\{\lambda_i,\phi_i\}$?","['eigenvalues-eigenvectors', 'sturm-liouville', 'partial-differential-equations', 'eigenfunctions', 'ordinary-differential-equations']"
2187850,"Spivak's Manifold, Theorem 2.7, proof without chain rule.","For the following theorem: Spivak stated, Although the chain rule was used ... it could easily have been eliminated. I believe there is a proof without invoking the auxiliary function $h$ - but I don't see how we can show $D_jf(a)$ exists, moreover, even if it exists, I couldn't show the derivative of $f$ is of the desired form without using MVT...","['multivariable-calculus', 'jacobian', 'partial-derivative', 'derivatives']"
2187861,maximum number of number of roots of $p(x) = 0$ is,"Let $p(x)=x^6+ax^5+bx^4+x^3+bx^2+ax+1.$ Given that $x=1$ is a root of $p$ but $x=-1$ is not, find the maximum number of number of roots of $p$. My attempt: $x=0$ in not a root of $p(x)=0.$ So
$$\left(x^3+\frac{1}{x^3}\right)+a\left(x^2+\frac{1}{x^2}\right)+b\left(x+\frac{1}{x}\right)+1=0$$ So
$$\displaystyle \left(x+\frac{1}{x}\right)^3-3\left(x+\frac{1}{x}\right)+a\left(x+\frac{1}{x}\right)^2-2+b\left(x+\frac{1}{x}\right)+1=0$$ So
$$ t^3+at^2+(b-3)t+1=0,$$
where
$$\left(x+\frac{1}{x}\right) = t \quad\text{ and }\quad |t|\geq 2.$$ Given $x=1$ is a root of $p$, $1+a+b+1+a+b+1=0$, so
$$\displaystyle a+b = -\frac{3}{2}$$ so
$$t^3+at^2+\left(-\frac{9}{2}-a\right)t+(1-2a) = 0.$$ $t=2$ is a root, so
$$(t-2)\bigg[t^2+(a+2)t+\left(\frac{2a-1}{2}\right)\bigg]=0,$$ So discriminant of above quadratic equation is $\displaystyle D = a^2+6>0$. So above equation has $2$ distinct real roots. But I did not know how I use $x=-1$ is not a root. Could some help me to solve it? Thanks.",['algebra-precalculus']
2187862,Proof of an Elliptic Integral Relation,"In celebration of Pi Day, I messed around with the following Ramanujan formula : $$\sum_{n=0}^{\infty} \binom{2 n}{n}^3 \frac{42 n+5}{2^{12 n+4}} = \frac1{\pi} $$ It turns out that, through some identities such as the following : $$\sum_{n=0}^{\infty} \binom{2 n}{n}^3 x^n = \frac{4 K\left(\frac{1}{2} \left(1-\sqrt{1-64 x}\right)\right)^2}{\pi ^2} $$ we can derive an analytical expression for the original sum.  This analytical expression leads me to the following question: How does one prove the following relation? $$ 2 \sqrt{7} E(m) K(m) - (2+\sqrt{7}) K(m)^2 = \frac{\pi}{2} $$ where $$K(m) = \int_0^{\pi/2} \frac{d \phi}{\sqrt{1-m \sin^2{\phi}}} $$
  $$E(m) = \int_0^{\pi/2} d\phi \, \sqrt{1-m \sin^2{\phi}} $$ and $$m = \frac{8-\sqrt{63}}{16} $$ It seems to me that there is some combination of the integrals that lends itself to a massive simplification, but I have yet to have found it.  Thus, I pose this to see if any of my fellow integral killers can drudge up any insights I may have missed.","['integration', 'definite-integrals', 'elliptic-integrals', 'pi', 'special-functions']"
2187893,Let $f(x)=x^{2}$ show that f is differentiable at $0$,"The book that I use has no example for proving the function is diffentiable. It's just give defination of differentiable . 
I don't how exacty prove differentiable at some point.this problem I work by check it has limit and conclude if limit is true and exist it is differentiable Ok,Let check my proof we found derivative by using elementary calculus that is 
$f'(x)=2x$ and plug in $0$ in $f'$ [$f'(0)=0$] if it's differentiable $f'(0)=0$ must be true let $\epsilon >0$ the defination of differentiable is $$|\frac{f(x)-f(c))}{x-c}-L|<\epsilon $$ in this case $$|\frac{x^{2}-0}{x-0}-0|<\epsilon $$ $$\frac{(x)(x)}{x}<\epsilon $$ $x< \epsilon$ Choose $\epsilon =\delta $ then $x<\epsilon$ since of f' exist and it's true by definition of limit. therefore it's differentiable at $0 $","['derivatives', 'real-analysis', 'proof-verification']"
2187923,Why aren't there complex solutions to $\sin(x) = 0$?,Suppose that the addition formula works for $\sin(a+bi) = 0$ where $a$ and $b$ are real. Then $\tan(a) = \tanh(b)$ for any real $b$ and $a$ are valid solutions to the given equation. There are many solutions to $a$ and $b$. But why do none of them yield $\sin(a+bi) = 0$?,"['complex-analysis', 'trigonometry', 'complex-numbers', 'proof-verification']"
2187946,Where does the $t$ come from in the solution to a critically damped differential equation?,"When solving homogeneous second order constant coefficient linear ODEs ($ay''+by'+cy=0$), there are three 'cases' that solutions fall into, based on the roots $r_1$, $r_2$ of the characteristic equation $ar^2+br+c=0$: $r_1, r_2 \in \Bbb R,\; r_1 \ne r_2$, aka ""overdamped"", for which the general solution is of the form $y(t) = c_1 e^{r_1 t} + c_2 e^{r_2 t}$. $r_1, r_2 \in \Bbb C,\; r_1=\overline{r_2}$, aka ""underdamped"", for which the general solution is $y(t) = c_1 e^{\Re(r)\,t}
   \cos\Im(r)\,t + c_2 e^{\Re(r)\,t} \sin\Im(r)\,t$. $r_1, r_2 \in \Bbb R,\; r_1 = r_2$, aka ""critically damped"", for which the general solution is $y(t) = c_1 e^{rt} + c_2 t e^{rt}$. I understand the underdamped solution as essentially the same thing as the overdamped solution, equivalent to picking complex $c_1, c_2$ such that $y(t)$ is always real. But the critically damped case doesn't seem to fit neatly as a generalization of the other cases - that extra 't' makes it at least appear like it's something else entirely. Where does the ""$t$"" actually come from in the critically damped case?
Why don't the other cases require or allow this?",['ordinary-differential-equations']
2187949,Limits with L'Hopital - guessing and confirm: $\lim _{x \to 0^+} (1+x)^{\large\frac1{\sin x}}$,"With L'Hopital I have$$\lim _{x \to 0^+} (1+x)^{\large\frac1{\sin x}}=\lim _{x \to 0_+} e^{\ln{(1+x)^\frac{1}{\sin x}}}=\lim _{x \to 0_+} e^{\ln(1+x)}\cdot\frac{1}{\sin x}$$
$$=\lim _{x \to 0_+} \frac{\ln(1+x)}{\sin x}=\lim _{x \to 0_+}\frac{\frac{1}{1+x}}{\cos x}=1$$ I just want someone to confirm it is the limit and I want to ask too if there is any method that I can guess the limit without actually calculating it? Thanks in advance!","['calculus', 'limits']"
2187963,How did Mohan Srivastava crack Ontario scratchcards?,"Wired ran a 2011 article about how a statistician, Mohan Srivastava, cracked Ontario scratchcards such as this one . First, he thought about the program that produced the numbers on the cards. 'Of course, it would be really nice if the computer could just spit out
  random digits. But that’s not possible, since the lottery corporation
  needs to control the number of winning tickets. The game can’t be truly
  random. Instead, it has to generate the illusion of randomness while
  actually being carefully determined.' He realised that if a card had a certain feature, it was likely profitable. Srivastava was looking for singletons, numbers that appear only a single
  time on the visible tic-tac-toe boards. He realized that the singletons
  were almost always repeated under the latex coating. If three singletons
  appeared in a row on one of the eight boards, that ticket was probably a
  winner. How might a program that produced the numbers work? And how did Srivastava infer that consecutive singletons would be predictive of winning cards?","['lotteries', 'probability', 'gambling']"
2188009,Estimating the volume of a tumor from x-ray scans,"Consider the problem of estimating the volume of a tumor, given X-ray scans along orthogonal axes. It may be known that the tumor has a somewhat spherical shape. To formalise this idea, let $T \subset \mathbb{R}^3$ be the tumor, $s$ the area of its surface, $m$ its volume and $C = s^3/m^2$. From the isoperimetric inequality, we have $C \geq 6^2 \pi$, with equality iff $T$ is a ball. Correspondingly, we say that $T$ is a quasi-ball if $C \approx 6^2 \pi$. We are now given the areas $m_1$, $m_2$ and $m_3$ of the projections of $T$ along orthogonal axes. From the Loomis-Whitney inequality (or Cauchy-Schwarz in this case), we have the following estimate of the volume $m$ of $T$: $$
\max_i \sqrt{\frac{2^3 m_i^3}{C}} \le m \le \sqrt{m_1 m_2 m_3}.
$$ Problem. Can we find such an estimate of $m$ that is close to sharp when $T$ is a quasi-ball and exact when $T$ is a ball? The problem could be easier to solve in 2 dimensions for planar shapes.","['inequality', 'analysis', 'geometry']"
2188024,"If I have a jar with $n$ jelly beans in it, what is the probability that I am missing at least one of the 49 flavors?","Assuming each flavor is equally likely to appear. I initially thought it would be just: $1 - 49 \left( \frac{48}{49} \right)^n$ But then I realized that couldn't be right because some configurations would be overcounted (resulting in a negative probability with a small enough $n$, like 100). I wrote a program to calculate it, so I have approximations of several of the probabilities, but I would like to know how do it with a general formula (ideally with a variable number of flavors as well).","['combinatorics', 'statistics', 'probability']"
2188103,$ \int_{0}^{ \infty} \int_{0}^{ \infty} \frac { e^{-(x+y)}}{x+y} dx dy $,Question : The integral $$ \int_{0}^{ \infty} \int_{0}^{ \infty} \frac { e^{-(x+y)}}{x+y} \mathop{dx}\mathop{dy} $$ is (a) infinite (b) finite but can not be evaluated in closed form (c) 1 (d) 2 . I tried substituting $u=x+y$ and $v=y$ that led me no where . I'm not even sure about convergence of integral .Any help would be greatly appreciated .,"['multivariable-calculus', 'real-analysis', 'calculus']"
2188150,Proving your solution when using constructive counting,"How many distinct ways can the faces of a cube be painted with $6$
  different colors? Two paintings are considered identical if the cube can be oriented so that the cubes look the same. This problem can be solved in at least two ways that I know of. One of them is to fix the bottom of cube and count the number of possible distinct paintings. There are $5$ possibilities for the top of the cube and since the other $4$ sides make up a ""circle"" there are $3!$ unique arrangements there. In all, there are $5 \times 3!$ unique paintings. To use this method we must be sure of three things: 1) Our method can be used to construct any element of the set we are counting. 2) The same number of options were available during any particular construction. 3) We will never construct the same object in two different ways, i.e. by making different choices during our construction. I want to see if I understand these bullet points. A unique painting of a cube is an element in the set we are counting. Each one can be constructed by fixing the bottom of a cube. I think they are saying there are as many outcomes if we start by constructing the painting by fixing the red side on the bottom of the cube as there would be if we started our construction by fixing the black side of the cube first. [Black and red are just arbitrary colors here.] I am not sure what this is saying. My questions. Does my interpretation of the first two bullets make sense? Can someone please elaborate on the third one.","['combinatorics', 'discrete-mathematics']"
2188152,The difference between $\frac{\bar X-\mu}{S´/\sqrt{n}}$ and $\frac{\bar X-\mu}{s´/\sqrt{n}}$,"Imagine we're dealing with a normal population, with known mean $\mu$, but unknown variance $\sigma^2$. We know that $\frac{\bar X-\mu}{S'/\sqrt{n}}\sim t(n-1)$. (T-Student distribution) Now, suppose someone asks us to calculate $P(\bar X >c)$ and give us $s'=3$. I've seen people write the following: $P(\bar X >c)=P(\frac{\bar X-\mu}{s'/\sqrt{n}}<\frac{c-\mu}{s'/\sqrt{n}})=P(T>\frac{c-\mu}{s'/\sqrt{n}})$, where $T\sim t(n-1)$. This sequence of equalities doesn't seem to be correct, since a draw of $S'$, i.e. $s'$, is not the same as the r.v.  $S'$. If it's correct, why is that? Any help would be appreciated.","['statistics', 'probability', 'statistical-inference']"
2188213,Understanding Intermediate value theorem.,"I will first state the theorem in my words and then my problem. If function $f$ is continuous on $[a,b]$ and $f(a) > 0 > f(b)$ or $f(a) < 0 < f(b)$ then the function has at least a zero in $[a,b]$. I have two problems with this theorem. My book does not say that "" at least "" part, it just says ""a zero"", is not the book wrong ? example : $f(x) = x^3 - 5x^2 +  6x$ on $[-100,100]$. Let $f$ be such that $f(x) = x^2$. Now $f$ is certainly continuous on $[-1,1]$ but $f(-1) = f(1) = 1$. Thus it does not satisfy any of the last two conditions still it has a zero at $x = 0$. What have I missed ?","['derivatives', 'real-analysis', 'continuity', 'calculus']"
2188235,"What is required to show $S = \{e^{i n \theta}: n \in \mathbb{Z}\}$ is a basis for $L^2([0, 2\pi])$?","I have read some papers that make use of a 'Fourier basis' when decomposing some functions, but I am wondering whether there is more depth behind that phrase and what can we rigorously say about this basis. Suppose we want to be rigorous. In that case is it ok to simply say that the set of functions $S = \{e^{i n \theta}: n \in \mathbb{Z}\},$ forms a basis for $L^2([0, 2\pi])$ because any function $f \in L^2([0, 2\pi])$ can be represented as a linear combination of cosines and sines? Or is it necessary to show that the set of functions $S$ is a Hamel or Schauder basis for the space $L^2([0, 2\pi])$? If it's the latter, which type of basis is this set of functions $S$, Hamel or Schauder? And how do we show it is a basis?","['functional-analysis', 'schauder-basis', 'fourier-analysis']"
2188286,Intuition for the Dual Space in Finite Dimensional Vector space,"Let me give you an example of how I think of linear operators first. Consider a linear operator $A: \mathcal{V} \to \mathcal{V}$. We have $A(\mu {\bf v} + \lambda {\bf w}) = \mu A({\bf v}) + \lambda A({\bf w})$ holding identically for $\mu, \lambda \in \mathbb{K}$ and ${\bf v}, {\bf w} \in \mathcal{V}$. Therefore, the set of all linear operators on $\mathcal{V}$ forms a vector space in its own right. Suppose $\mathcal{V} = \mathbb{R}^3$. To visualize this, I typically imagine $A$ as being represented by a 9D vector. This helps me quickly see various orthogonal decompositions into its symmetric and skew pieces or its spherical and deviatoric pieces. I have tended to do the same thing for the dual space, $\mathcal{V}^*$; that is, I have been imagining $\mathcal{V}$ and $\mathcal{V}^*$ as ${\it totally \ separate \ spaces}$. They are objects of different type after all. I have been thinking of elements of $\mathcal{V}$ as geometric vectors and elements of $\mathcal{V}^*$ as ""things that operate"" on those vectors. But I've just reached a hurdle. Say we are working in $\mathbb{R}^2$ with a set of geometric vectors. It is common to represent a vector ${\bf x} \in \mathbb{R}^2$ on either a covariant or contravariant basis: ${\bf x} = x_i {\bf a}^i = x^i {\bf a}_i$ with the property that ${\bf a}_i \cdot {\bf a}^j = \delta_i^j$. But wait a second. I've been doing some reading and is it true that ${\bf a}_i \in \mathbb{R}^2$ but ${\bf a}^j \in (\mathbb{R}^2)^*$? If so, then we are layering the two spaces on one. And the dual set is not to be thought of as a set of linear functionals but as a set of geometric vectors that are available which have a nice duality property. So is it true that in this interpretation, if we write ${\bf x} = x_j {\bf a}^j$ it is to be thought of as a linear functional, but if we write ${\bf x} = x^j {\bf a}_j$ then it is to be thought as a geometric vector? But ${\bf x}$ is supposed to represent the ${\it same}$ object, and elements of $\mathbb{R}^2$ and $(\mathbb{R}^2)^*$ are fundamentally different! How is this possible?","['differential-geometry', 'linear-algebra']"
2188299,Solving a second-order linear ODE: $\frac{d^2 y}{dx^2}+(x+1)\cdot \frac{dy}{dx}+5x^2\cdot y=0$,"Recently, a friend challenged me to find the general solution of the following differential equation: $$\frac{d^2 y}{dx^2}+(x+1)\cdot \frac{dy}{dx}+5x^2\cdot y=0 \tag{1}$$ This is a second-order linear ordinary differential equation. I have tried putting this ODE into the form of a Sturm-Liouville Equation by multiplying both sides by $e^{\int (x+1)~dx}$ to obtain:
$$e^{\frac{x^2}{2}+x}\cdot\frac{d^2 y}{dx^2}+(x+1)\cdot e^{\frac{x^2}{2}+x}\cdot \frac{dy}{dx}+5x^2\cdot e^{\frac{x^2}{2}+x}\cdot y=0$$
By the reverse product rule:
$$\frac{d}{dx}\left(e^{\frac{x^2}{2}+x}\cdot y'(x)\right)+5x^2\cdot e^{\frac{x^2}{2}+x}\cdot y=0 \tag{2}$$
Now, it is in Sturm-Liouville form, however I am unsure how to proceed from here. Therefore, I have instead tried to do some substitution on the differential equation to eliminate the first order term to obtain this form:
$$\frac{d^2 y}{dx^2}+q(x)\cdot y=0$$
Therefore, I have tried using the substitution:
$$y=e^{-\frac{(1+x)^2}{4}}\cdot z$$
$$\ln y=\ln{z}-\frac{(1+x)^2}{4}$$
Differentiating implicitly both sides w.r.t $x$:
$$\frac{y'}{y}=\frac{z'}{z}-\frac{1}{2}(x+1) \tag{3}$$
Differentiating again:
$$\frac{y\cdot y''-(y')^2}{y^2}=\frac{z\cdot z''-(z')^2}{z^2}-\frac{1}{2}$$
Thus:
$$\frac{y''}{y}-\left(\frac{y'}{y}\right)^2=\frac{z''}{z}-\left(\frac{z'}{z}\right)^2-\frac{1}{2}$$
Substituting $(3)$:
$$\frac{y''}{y}=\left(\frac{z'}{z}-\frac{1}{2}(x+1)\right)^2+\frac{z''}{z}-\left(\frac{z'}{z}\right)^2-\frac{1}{2}$$
Expanding gives:
$$\frac{y''}{y}=\left(\frac{z'}{z}\right)^2-\left(\frac{z'}{z}\right)(x+1)+\frac{1}{4}(x+1)^2+\left(\frac{z''}{z}\right)-\left(\frac{z'}{z}\right)^2-\frac{1}{2}$$
$$\frac{y''}{y}=-\left(\frac{z'}{z}\right)(x+1)+\frac{1}{4}(x+1)^2+\left(\frac{z''}{z}\right)-\frac{1}{2} \tag{4}$$
Going back to our original ODE $(1)$:
$$y''+(x+1)y'+5x^2\cdot y=0$$
$$\frac{y''}{y}+(x+1)\frac{y'}{y}+5x^2=0$$
Substituting $(3)$ and $(4)$ gives:
$$-\left(\frac{z'}{z}\right)(x+1)+\frac{1}{4}(x+1)^2+\left(\frac{z''}{z}\right)-\frac{1}{2}+(x+1)\left[\frac{z'}{z}-\frac{1}{2}(x+1)\right]+5x^2=0$$
Cancelling terms gives:
$$\left(\frac{z''}{z}\right)-\frac{1}{4}(x+1)^2-\frac{1}{2}+5x^2=0$$
Which gives the ODE:
$$z''+\left[5x^2-\frac{1}{2}-\frac{1}{4}(x+1)^2\right]z=0$$
When the $z$ term is expanded, it gives:
$$z''+\frac{1}{4}(19x^2-2x-3)z=0 \tag{5}$$
I tried identifying this ODE as a known type, however I could not. Therefore, I am stuck at this point. Note that I am trying to avoid a series solution for this differential equation. I am aware that the result will be in terms of non-elementary functions. Wolfram|Alpha suggests that the solution will be in terms of the Hermite polynomial $H_n(z)$ defined as:
$$H_n(z)=\frac{n!}{2\pi i} \oint e^{-t^2+2tz}\cdot t^{-n-1}~dt$$
And the Kummer confluent hypergeometric function $_1F_1(a;b;x)$ defined as:
$$_1F_1(a;b;x)=1+\frac{a}{b}x+\frac{a(a+1)}{b(b+1)}\frac{x^2}{2!}+\cdots=\sum_{k=0}^{\infty} \frac{(a)_k}{(b)_k}\frac{x^k}{k!}$$
Where $(a)_k$ and $(b)_k$ are Pochhammer Symbols . In conclusion, I would appreciate some guidance on how to continue solving this ODE analytically. I was thinking that equation $(5)$ seems simpler to solve from what we have, however if $(1)$ seems easier, please feel free to continue from the original ODE. Thanks in advance. Edit: I figured that I could simplify $(5)$ further by completing the square:
$$\frac{d^2 z}{dx^2}+\left[\frac{19}{4}\left(x-\frac{1}{19}\right)^2-\frac{29}{38}\right]z=0$$
And then applying the substitution $u=x-\frac{1}{19}$ and $du=dx$. Evaluating $\frac{d^2 z}{dx^2}$:
$$\frac{dz}{dx}=\frac{dz}{du}\cdot \frac{du}{dx}=\frac{dz}{du}$$
Thus, differentiating w.r.t $x$ gives:
$$\frac{d^2 z}{dx^2}=\frac{d}{dx}\left(\frac{dz}{du}\right)=\frac{d}{du}\left(\frac{dz}{du}\right)\frac{du}{dx}=\frac{d^2 z}{du^2}$$
Therefore, we reduce it to the form:
$$\frac{d^2 z}{du^2}+\left[\frac{19}{4}u^2-\frac{29}{38}\right]z=0 \tag{6}$$","['sturm-liouville', 'ordinary-differential-equations', 'calculus']"
2188307,Decide whether the function $g(\overline{z}) = z$ has a primitive in any open subset of $\mathbb{C}$.,Decide whether the function $g(\overline{z}) = z$ has a primitive in any open subset of $\mathbb{C}$. Im really not sure how to answer this question so any help will be appreciated.,"['complex-analysis', 'complex-numbers', 'functions']"
2188316,Steepest descent of integrand with a movable saddle?,"I want to apply the steepest descent method to the following integration:
$$
\int_0^\infty e^{-x^2 + i \sqrt{x^2 + 1} \cdot \lambda } dx
$$ It has movable saddle so I need to transform it into the standard form, something like $$
\int_C g(z) e^{\lambda f(z) } dz
$$ I know for Gamma function:
$$ \Gamma(x+1)= \int_0^\infty e^{-t} t^{x} dt =\int_0^\infty e^{-t + x \ln t} dt $$
letting $t = x s$ transforms it into standard form. And for Airy function: $$Ai(x) = \frac{1}{2 \pi} \int_{-\infty}^{\infty} e^{i (t^3/3 + x t)} dt $$ letting $t = \sqrt{x} z$ does the trick. However, no change of variable seems to transform my integration into the standard form. For this reason I can not proceed at all. Any hint or suggestion ? Thanks!","['complex-analysis', 'integration', 'asymptotics']"
2188351,"If $f(x) \in \mathbb{Q}[x]$ is irreducible, then is $f(x^2)$irreducible?","I found a set of practice questions, one of which asks whether or not $f(x) \in \mathbb{Q}[x]$ irreducible implies $f(x^2)$ irreducible. Is this true? I'm having trouble thinking of a counterexample. Is there an irreducibility criterion that we could use?",['abstract-algebra']
2188388,Seemingly Identical Random Variables with Different Variances,"In my probability class, we did the following problem regarding expected values/variance: Consider an experiment where you roll a fair, 6-sided dice until you see a 6. Let $T$ be a random variable denoting the total sum, including the final 6. Also, consider an experiment where you roll a fair, 6-sided dice until you see a 1. Let $S$ be a random variable denoting the total sum, including the final 1. a) Which is larger, $E[T]$ or $E[S]$? We showed that $E[T] = E[S] = 21$, by conditioning $T$ and $S$ on a random variable $N$ denoting the total number of rolls. b) Which is larger, $Var[T]$ or $Var[S]$? Here, we showed that $Var[T] > Var[S]$, by again conditioning on $N$. However, I took a different approach to (b). I noted that when we consider the variance of a random variable, we are really concerned with the deviation between a value the random variable can take and it's expectation, not that actual numbers themselves. Also, note each roll is independent of the others. Therefore, let $T = T_1 + T_2 + ... + T_N$, where $T_i$ is the value rolled on the i-th roll, and define $S_i$ similarly. I believe $Var[T_i] = Var[S_i]$ on any given roll before the final one, as in both experiments, the deviations can take the values $-2, 1, 0, 1, 2$ with probability $\frac{1}{5}$. Furthermore, on the last roll of each experiment, the deviations between the values rolled and the expectation are identical, taking the value $3$. If all of the deviations are identical then, how are the variances different? Note: I do understand how to compute the variances by conditioning on $N$, and accept that my answer was wrong. However, I'm specifically looking for where the logic breaks down in my argument, as it seems that the deviations and probabilities are the same for each experiment, which to me implies that the variances should be equal as well.","['expectation', 'conditional-expectation', 'probability', 'variance']"
2188392,Fourier transform of $e^{-i|x|^2}$,"I am trying to calculate the Fourier transform of $f(x)=e^{-i|x|^2}$ for $x\in\mathbb{R}^n$.
Roughly speaking, the Fresnel integral implies that
$$\hat{f}(\xi)=(2i)^{-n/2}e^{i|\xi|^2/4}$$
where the Fourier transform of a function $g$ is defined as
$$\hat{g}(\xi)=(2\pi)^{-n/2}\int_{\mathbb{R}^n}g(x)e^{-ix\cdot\xi}dx,\ \ \xi\in\mathbb{R}^n.$$
However, as this post says, $f$ is not in $L^1$ and the Fresnel integral holds in the sense of improper Riemann integral not in the sense of Lebesgue integral. I think this equality $\hat{f}(\xi)=(2i)^{-n/2}e^{i|\xi|^2/4}$  is true in the sense of distributions and the proof of this calculation is based on distribution theory, but I cannot go further. How can we prove this?
I appreciate any advice.","['functional-analysis', 'distribution-theory', 'fourier-transform']"
2188410,Proving $\int_0^\infty\frac{\sin(x)}x\ dx=\frac{\pi}2$. Why is this step correct?,"I came across a different approach on the proof: $$\int_0^\infty \frac{\sin(x)}x\ dx=\frac{\pi}2$$
First, recall the identity: $$\sin(A)-\sin(B)=2\sin\left(\frac{A}2-\frac{B}2\right)\cos\left(\frac{A}2+\frac{B}2\right)$$ 
Applying the identity for: $$A=kx+\frac{x}2\ \land\  B=kx-\frac{x}2$$ 
We obtain:$$\sin\left(kx+\frac{x}2\right)-\sin\left(kx-\frac{x}2\right)=2\sin\left(\frac{x}2\right)\cos\left(kx\right)\Rightarrow \\\cos\left(kx\right)=\frac{\sin\left(kx+\frac{x}2\right)-\sin\left(kx-\frac{x}2\right)}{2\sin\left(\frac{x}2\right)}$$
Using the previous result, we can easily show that:
$$\frac12+\cos(x)+\cos(2x)+\cdots+\cos(\lambda x)=\frac{\sin\left(\lambda x+\frac{x}2\right)}{2\sin\left(\frac{x}2\right)}  \quad \text{where $\lambda \in \mathbb{N}$}$$
Integrating the last expression: $$\int_0^\pi\frac{\sin\left(\lambda x+\frac{x}2\right)}{\sin\left(\frac{x}2\right)}\ dx=\int_0^\pi\left(1+2\cos(x)+2\cos(2x)+\cdots+2\cos(\lambda x)\right)\ dx=\pi$$
We can also prove (since $f(x)$ is continuous on $[0,\pi]$), using Riemann-Lebesgue Lemma, that: $$\lim_{\lambda\to\infty}\int_0^\pi\underbrace{\left(\frac2t-\frac1{\sin\left(\frac{t}2\right)}\right)}_{f(x)}\sin\left(\lambda t+\frac{t}2\right)dt=\lim_{\lambda\to\infty}\int_0^\pi\left(\frac{2\sin\left(\lambda t+\frac{t}2\right)}t-\frac{\sin\left(\lambda t+\frac{t}2\right)}{\sin\left(\frac{t}2\right)}\right)=0$$
Therefore: $$\left(1\right)\  \lim_{\lambda\to\infty}\int_0^\pi\frac{2\sin\left(\lambda t+\frac{t}2\right)}t=\lim_{\lambda\to\infty}\int_0^\pi\frac{\sin\left(\lambda t+\frac{t}2\right)}{\sin\left(\frac{t}2\right)}=\pi$$
$$$$Returning to the initial problem:
$$\\$$
Let: $$x=\lambda t+\frac{t}2$$
Thus:
$$\int_0^\infty \frac{\sin(x)}x\ dx \stackrel{\eqref{*}}=\frac12\lim_{\lambda\to\infty}\int_0^{\color{teal}{\pi}}\frac{2\sin\left(\lambda t+\frac{t}2\right)}{t}\ dt$$
Using the result obtained from $(1)$:$$\int_0^\infty \frac{\sin(x)}x\ dx=\boxed{\frac{\pi}2}$$
$$$$ My question comes from $\color{teal}{(???)}$, Why is it correct to have $\pi$ instead of $\infty$ when changing the limits of integration?","['real-analysis', 'integration']"
2188427,What well-known objects have this as their symmetry group?,"I'm currently working with a geometric object that has a symmetry group isomorphic to the direct sums of three cyclic groups of order two, i.e.,
$$\mathbb{Z}_2\oplus\mathbb{Z}_2\oplus\mathbb{Z}_2,$$
so it is generated by three reflections. I'm wondering if any other, well-known and well-studied objects have this as their symmetry group as well? Thank you.","['reference-request', 'symmetry', 'group-theory']"
2188438,Proving convergence of the Dirichlet Eta function,"I've been struggling to prove this for a project as I'm not an expert in the field, so i decided to go back to basics. The Dirichlet Eta Function is defined by: $$ \eta (s) = \sum_{n=1}^{\infty} \frac{(-1)^{n-1}}{n^{s}},  \text{  where }  s= \sigma +it $$ The idea i have had is to use the fact that $n^{s} = n^{\sigma}n^{it} = n^{\sigma}(\cos(\ln(n)t)+i\sin(\ln(n)t))$ So we can re-write the sum as: $$\sum_{n=1}^{\infty} \frac{(-1)^{n-1}}{n^{s}}  = \sum_{n=1}^{\infty} \frac{(-1)^{n-1}}{n^{\sigma}(\cos(\ln(n)t)+i\sin(\ln(n)t))} = \sum_{n=1}^{\infty}\frac{(-1)^{n-1}}{n^{\sigma}} (\cos(\ln(n)t)-i\sin(\ln(n)t)) $$ So what we end up turning our original problem into two different real series: $$ \eta (s) = \sum_{n=1}^{\infty} \frac{(-1)^{n-1}}{n^{s}} = \sum_{n=1}^{\infty}\frac{(-1)^{n-1}}{n^{\sigma}}\cos(\ln(n)t) - i\sum_{n=1}^{\infty}\frac{(-1)^{n-1}}{n^{\sigma}}\sin(\ln(n)t)) $$ So now my idea is to prove convergence for these two individual real series, which in turn will give me convergence for the complex series. Is there anything wrong with this approach?","['dirichlet-series', 'number-theory', 'riemann-zeta', 'convergence-divergence', 'analysis']"
2188494,"Fractional integrals problem: $g(x)_{|_{[0,t]}}=\frac{(-1)^{\alpha-1}}{\Gamma(1-\alpha)}\int_x^t(y-x)^{-\alpha}h(y)\,dy$","Let's consider $0<\alpha<1/2$ and denote by $W_T^{1-\alpha,\infty}(0,T)$ the space of measurable functions $g:[0,T]\to\Bbb R$ such that
$$
||g||_{1-\alpha,\infty,T}:=\sup_{0<s<t<T}\left[\frac{|g(t)-g(s)|}{(t-s)^{1-\alpha}}+\int_s^t\frac{|g(y)-g(s)|}{(y-s)^{2-\alpha}}\,dy\right]<+\infty\;\;\;.
$$ Moreover, we define the right sided Riemann-Liouville integral of order $1-\alpha$ of a function $f\in L^p(0,t)$, with $1\le p\le\infty$, as
$$
I_{t-}^{1-\alpha}f(x):=\frac{(-1)^{\alpha-1}}{\Gamma(1-\alpha)}\int_x^t(y-x)^{-\alpha}f(y)\,dy\;\;\;
$$
for a.a. $x\in[0,t]$. My problem is the following: in a paper by Nulart and Rascanu it is stated that, if $g\in W_T^{1-\alpha,\infty}(0,T)$ then its restriction to $[0,t]$ stays in $I_{t-}^{1-\alpha}(L^{\infty}(0,t))$ for all $0<t<T$; so in other words, given such $g$, there exists $h\in L^{\infty}(0,t)$ such that
$$
g(x)|_{[0,t]}=I_{t-}^{1-\alpha}h(x)=\frac{(-1)^{\alpha-1}}{\Gamma(1-\alpha)}\int_x^t(y-x)^{-\alpha}h(y)\,dy\;\;\;.$$ It seems to me, that I DON'T HAVE to search explicitly the $h$ depending on the $g$ but rather I should use a theoretical argument, which proves the existence of such $h$; but I don't know how to do it. I'm quite lost, can someone shade a light please? EDIT: Obviously $\Gamma$ is the Euler Gamma function and $(-1)^{\alpha-1}=e^{i\pi(\alpha-1)}$, but these terms are constant, thus this doesn't play any relevant role here. SECOND EDIT: We can state the ""symmetric"" claim; the underlying duality could help. We denote by $W_0^{\alpha,1}(0,T)$ the space of measurable functions $f:[0,T]\to\Bbb R$ such that
$$
||f||_{\alpha,1}:=\int_0^T\frac{|f(s)|}{s^{\alpha}}\,ds+\int_0^T\int_0^s\frac{|f(s)-f(y)|}{(s-y)^{\alpha+1}}\,dyds<+\infty
$$ As before we define the left sided Riemann-Liouville integral of order $\alpha$ of a function $f\in L^p(0,t)$, with $1\le p\le\infty$, as
$$
I_{0+}^{\alpha}f(x):=\frac{1}{\Gamma(\alpha)}\int_0^x(x-y)^{\alpha-1}f(y)\,dy\;\;\;
$$
for a.a. $x\in[0,t]$. Then if $g\in W_0^{\alpha,1}(0,T)$ then its restriction to $[0,t]$ stays in $I_{0+}^{\alpha}(L^1(0,t))$ for all $0<t<T$.","['fractional-calculus', 'real-analysis']"
2188497,The reverse of finding the arc length,"As we know, finding the arc length of a function $f(x)$ from $x=a$ to $x=b$ is straightforward and can be implemented numerically. For a particular function $f(x)$ that I have, suppose that I have numerically computed its arclength to be approximately $L$ using Simpson's rule. Now, for a set of values $\ell_k$ such that $0 \le \ell_k \le L$, I want to find $x_k\in [a,b]$ for which the arc length of $f(x)$ from $x=a$ to $x = x_k$ is $\ell_k$. I am not sure what's the best way to do this numerically but I followed the suggestion here . That is, if $L(x)$ is the arclength function, $L(x) = \int_a^x \sqrt{1+f'(x)^2} dx$ which yields a differential equation $\frac{dx}{dL} = \frac{1}{\sqrt{1+f'(x)^2}}$. Solving this differential equation numerically is then not much of a problem. I used the initial condition that the $x-$value corresponding to arclength 0 is $x=a$. Now, inevitably, numerical errors arise. That is, after solving the differential equation numerically, the $x-value$ corresponding to length $L$ is not exactly $b$. Oftentimes, it goes slightly beyond $b$. I used Matlab's ode45 to solve the differential equation. I am wondering if I can impose two conditions on this equation, i.e. $x(0) = a$ and $x(L) = b$. If so, how can I solve the ODE numerically? It seems like bvp methods don't apply. Any suggestions?","['arc-length', 'calculus', 'matlab', 'numerical-methods', 'ordinary-differential-equations']"
2188532,Induced subgraph is a trail of length $2r-1$,"Let $G$ be a simple connected graph of radius $r$. Prove that we can find $2r-1$ vertices such that their induced subgraph is a trail. I've tried induction on $V(G)$, but haven't really made progress. The equality case occurs when $G$ is a complete graph, but I'm not sure what to make of this.","['combinatorics', 'graph-theory']"
2188588,Confused about derivation of center of mass formulae,"So, not sure if I'm really dumb and not getting something obvious or if there is more complexity here...Let's do 2 objects first. Say C.O.M. is x°. Then $x° = \dfrac{x_1M_1 +x_2M_2}{M_1+M_2} $ I get the ""idea"" of this formula–you are in a sense averaging the value of the masses. But is there some blatantly obvious reason for why this is true? It can easily be derived from: $(x°-x_1)M_1 = (x_2-x°)M_2$ but I don't see why the initial statement ($x° = \dfrac{x_1M_1 +x_2M_2}{M_1+M_2} $) is a priori true. Is there a geometric intuition? If we are doing a continuous non-constant function: $\int_{a}^{x°}f(x)(x°-x)dx= \int_{x°}^{b}f(x)(x-x°)dx $ It can be derived that this is equal (if I did it right) to $\dfrac{\int_{a}^{b}xf(x)dx}{\int_{a}^{b}f(x)dx} $ But again, is there a more obvious geometric intuition? Thanks","['calculus', 'proof-verification', 'multivariable-calculus', 'integration', 'proof-explanation']"
2188602,The size of the set of matrices with spectral radius less than 1,"Consider the set of all matrices with spectral radius $<1$, denoted $\mathcal C=\{A\in \mathbb{C}^{n\times n}:\rho(A)<1\}$. This is an interesting set, partly because $A\in \mathcal C\iff \lim\limits_{k\to\infty} A^k= 0$. It seems difficult to describe the geometry of $\mathcal C$, but let's ask about its size in terms of the Lebesgue measure $\mu$ on   $\mathbb{C}^{n\times n}$. Question : What is the asymptotic behavior of $\mu(\mathcal C\cap \{A:\|A\|\le r\})$ as $r\to\infty$? (That is, is it some power of $r$, or $\log r$, etc?) Remarks It does not matter what matrix norm is used here, since they are all equivalent. Let's exclude the trivial case $n=1$. $\mu(\mathcal C)=\infty$, which can be shown as follows. Let $\epsilon>0$ be such that any $n\times n$ matrix with all entries satisfying $|a_{ij}|<\epsilon$ has spectral radius less than $1$. Denote by $\mathcal E$ the set of matrices with all entries between $\epsilon/2$ and $\epsilon$ in absolute value. 
Let $D$ be the diagonal matrix with diagonal entries $(2,1,\dots,1)$. Then the sets $D^k\mathcal E D^{-k}$, $k\in\mathbb Z$, are disjoint, have the same (positive) Lebesgue measure, and are contained in $\mathcal C$. The claim follows. The argument in item 3 shows that $\mu(\mathcal C\cap \{A:\|A\|\le r\}) \gtrsim \log r$.","['matrices', 'eigenvalues-eigenvectors', 'asymptotics', 'linear-algebra']"
2188608,Integrating a hedgehog,"As motivation of the title, consider the shape of the function $e^{-x}\left(x+\lfloor x\rfloor^2\right)$ as plotted by WolframAlpha : This exercise I believe that is very easy, let $\lfloor x\rfloor$ the floor function (... obviously we combine with this function when we want to define an integral of the kind hedgehog), then $$\int_0^6 e^{-x}\left(x+\lfloor x\rfloor^2\right)dx=\sum_{k=1}^6\left(\int_{k-1}^k xe^{-x}dx+(k-1)^2\int_{k-1}^ke^{-x}dx\right),$$ by integrating by part the first summand we get $$\sum_{k=1}^6\left(e^{-k+1}-ke^{-k+1}+ke^{-k}-2e^{-k}-k^2e^{-k}+k^2e^{-k+1}\right)\approx 2.13235.$$
Truly Wolfram Alpha online calculator get the closed-form and agree with my calculations. I know that it is using geometric series (and variation of those), if you want to see the closed-form and get the comparison type these codes, first the integral integrate e^(-x)(x+(floor(x))^2)dx, from x=0 to x=6 and secondly the finite sum that we've obtained sum e^(-k+1)-k e^(-k+1)+k e^(-k)-2 e^(-k)-k^2 e^(-k)+k^2 e^(-k+1), from k=1 to k=6 Now this question, maybe isn't important but I believe that it is a nice exercise with the purpose to be in a good mood Question. Can you calculate as a closed-form with all details the infinite case of an integral for a hedgehog, this
  $$\int_0^\infty e^{-x}\left(x+\lfloor x\rfloor^2\right)dx?$$
  If you believe that isn't feasible get a closed-form, you can provide us your approximation. Thanks a lot.","['closed-form', 'integration', 'definite-integrals', 'recreational-mathematics', 'ceiling-and-floor-functions']"
2188636,there is at most one point at distance exactly $1$ from three distinct points in the plane,"Consider $n\geq 1$ points in the plane. I want to show that there is at most one point at distance exactly $1$ from any three distinct points in the plane. I want to prove this as part of a larger proof I am writing for a particular problem. This fact seems obvious, yet it is not that easy for me to prove. I will assume that I am working with the Euclidean distance. Is there any way to prove this fact using the triangle or reverse triangle inequalities? Thank you!","['combinatorics', 'plane-geometry', 'euclidean-geometry', 'geometry']"
2188656,Expected value of $X^n$,"Given: $F_X(x)$ is a CDF and: $E[X] = \int\limits_0^\infty (1-F_X (x))\, dx\ $ How do I prove: $E[X^n] = \int\limits_0^\infty nx^{n-1}(1-F_X(x))dx   $",['probability']
2188659,Is it possible to use the multiple scales technique to a set of coupled ODEs?,"I need to solve a set of coupled ODEs. The ODEs are well indicated for using the multiple scales method (generalised oscillator equations), I have just never done such a thing on a ODEs set. Is it possible? How should I adapt the steps? Please note: Since there is a good chance I haven't been lucky enough finding in literature and google, I'll be really glad for an online reference as well. EDIT: Please, provide minimal working example or a reference containing it.","['reference-request', 'ordinary-differential-equations', 'dynamical-systems', 'perturbation-theory']"
2188703,"Find orbits of the group action of $GL(n, F)$ on set of $n \times n$ matrices","Let $M_{n}(F)$, $n\times n$ matrices over $F$, and $G=GL(n,F)$, $n\times n$ invertible matrices. $G$ acts on $M_{n}(F)$ via left multiplication. Find the orbits of this group action. Firstly, all the $G$ in $M$ is an orbit from the linear algebra fact. It's also clear that left multiplication can be seen as row operation. But when $G$ acts on the non-invertible matrices, things will become very complicated since there are so many possibilities of reduced row echelon forms. My question is how can we find a neater way to organize all those orbits and express them clearly ?","['matrices', 'abstract-algebra', 'linear-groups']"
2188715,Relations similar to $\sin(\pi/18) + \sin(5\pi/18) = \sin(7\pi/18)$,"This I checked numerically (and can be proven analytically easily). I guess there are many similar relations between the numbers $$\{ \sin\frac{m\pi}{q}, 1\leq m \leq q \} , $$ where $q$ is some integer. Can anyone give some reference?",['trigonometry']
2188746,Prove that $(A+B)^n = 0$,Let $A$ and $B$ be $n \times n$ real matrices such that $A^n = B^n = 0$ and $AB = BA$. Prove that $(A+B)^n = 0$. We have $$(A+B)^n = A^n+A^{n-1}B\binom{n}{1}+\cdots+AB^{n-1}\binom{n}{n-1}+B^n.$$ I tried proving this for just the case $n = 2$. We have $(A+B)^2 = A^2+2AB+B^2 = 2AB$ since $A^2 = B^2 = 0$. Then I didn't see how to show that $AB = 0$.,['linear-algebra']
2188762,prove by case |x-y| - 3|y| ≤ |x+2y| - possible solution?,"So there is an easier way to solve this problem by using the proven triangle inequality theorem, but if I were to solve this with proof by cases, can I add $$3|y|$$ to both sides of the equation and prove for that or would this be considered a different proof? So instead of proving: $$|x-y| - 3|y| ≤ |x+2y|$$ I instead prove for $$|x-y| ≤ |x+2y| + 3|y|$$
Then for case1: $$x≥y,y≥0$$, then $$x-y≥0.$$
Leftside = $$|x-y| = x-y$$ by definition as $$x-y≥0$$
Rightside = $$|x+2y| + 3|y| = x+2y+3y$$ since $$x≥y,y≥0$$
Therefore $$|x-y| ≤ |x+2y| + 3|y|$$ Is this a valid to do?","['inequality', 'proof-verification', 'discrete-mathematics']"
2188771,statistics range rule of thumb confidence interval,"Suppose that the minimum and maximum ages for typical textbooks currently used in college courses are 0 and 8 years. Use the range rule of thumb to estimate the standard deviation. Standard deviation = I have gotten max - min / 4 = 8 - 0 / 4 

               = 2 Find the size of the sample required to estimage the mean age of textbooks currently used in college courses. Assume that you want 98% confidence that the sample mean is within 0.4 year of the population mean. Required sample size = I have no clue how to get the required sample size What are the correct answers?","['means', 'statistics', 'confidence-interval']"
2188772,"Why does a curve in projective space ""look like"" a sphere?","Whenever I read about curves in $\Bbb{P}^2(\Bbb{C})$, I am asked to imagine them to be spheres. However, I do not have a good idea of why they should be spheres. I know, that $\Bbb{P}^1(\Bbb{C})$ looks like a sphere. Does the fact that a curve too looks like a sphere follow from the fact that most curves are isomorphic to $\Bbb{P}^1(\Bbb{C})$?",['algebraic-geometry']
2188786,statistics finding the confidence level of the interval estimate medical expenses,"A confidence interval for the true mean of the annual medical expenses of a middle-class American family is given as ($ 738, $ 777). If this interval is based on interviews with 110 families and a standard deviation of $ 120 is assumed. Suppose all annual medical expenses of middle-class American families follow an approximately normal distribution. (a) What is the sample mean of annual medical expenses? sample mean = 777 + 738 / 2
            = 757.5 (b) What is the confidence level of the interval estimate (as a decimal) CI = sample mean + z alpha/2 * (standard deviation / square root n) Isolate for z alpha/2 777 = 757.5 + z alpha/2 * (120/square root 110) Rearrange (777 * square root 110) / (757.5 * 120) = z alpha/2 0.089650657 = z alpha/2 What are the correct solutions and answers?","['statistics', 'probability', 'confidence-interval']"
2188834,How do I show that partial derivatives exist everywhere?,"I'm having trouble with a certain multi-variable calculus question.
$$  f(x,y) =
\begin{cases}
\large\frac{2xy^2}{x^2 + y^4},  & \text{$(x,y)\neq 0$} \\[2ex]
0, & \text{$(x,y) = 0$}
\end{cases}$$ I need to show that both $\large\frac{∂f}{∂x}$ and $\large\frac{∂f}{∂y}$ exist everywhere. I can easily manage to find both partial derivatives, but I'm not really sure what the question means when it asks to show that they ""exist everywhere"". Any help would be appreciated, thanks.","['derivatives', 'partial-derivative', 'multivariable-calculus', 'continuity', 'vector-analysis']"
2188858,Sum of subgradients belongs to subgradient of sums?,"I was going through this page : https://www.stats.ox.ac.uk/~lienart/blog_opti_basics.html , and at the end of part 1 ""Subgradient and First-order Optimality Condition"", the author says: Before moving on, it is useful to note (and not too hard to convince oneself) that the following inclusion holds for the subdifferential of a sum:
  $\sum_i ∂f_i⊆∂∑_if_i$. Can anyone explain what this means? If $f_i$ is not differentiable, then it can have multiple values of subgradient, right? Then what does the sum of subgradients of the functions $f_i$ amount to? And how do we show the above result?","['continuity', 'subgradient', 'convex-optimization', 'calculus']"
2188895,How to evaluate the following limits?,"I was reading a proof on the evaluation of $\int_0^\infty e^{-x^2}\ dx$ without advanced techniques and stumbled upon two limits that I can't seem to crack:
$$\lim_{m\to\infty}\left(\sqrt{m}\cdot\prod_{n=1}^m\frac{2n}{2n+1}\right)=\frac{\sqrt{\pi}}2$$
$$\lim_{m\to\infty}\left(\sqrt{m}\cdot\prod_{n=2}^m\frac{2n-3}{2n-2}\right)=\frac1{\sqrt{\pi}}$$
The proof does not go into detail on how these limits were obtained, and since I wanted to understand it completely, I thought this would be the best place to ask. I have not been exposed to infinite products (only summations) and therefore I do not know which rules to apply (I feel as if they are quite similar?). In both cases, I see that an indeterminate form $0\cdot\infty$ presents its self, therefore I am guessing Hospital would be a nice approach? Any help  is appreciated! Also, my calculus book does not tackle infinite products, any suggestions on books that might give me a general outlook on the subject?","['infinite-product', 'limits']"
2188952,Find the maximum of the value $F=x_{1}x_{2}x_{3}+x_{2}x_{3}x_{4}+\cdots+x_{n-2}x_{n-1}x_{n}+x_{n-1}x_{n}x_{1}$,"Let $x_{i}\ge 0$ and such $$x_{1}+x_{2}+\cdots+x_{n}=1$$
  Find the maximum of the value
  $$F=x_{1}x_{2}x_{3}+x_{2}x_{3}x_{4}+\cdots+x_{n-2}x_{n-1}x_{n}+x_{n-1}x_{n}x_{1}$$ case $1$. when $n=3$,then
$$F=2x_{1}x_{2}x_{3}\le2\dfrac{(x_{1}+x_{2}+x_{3})^3}{27}=\dfrac{2}{27}$$
but for $n\ge 4$,I can't solve it","['inequality', 'a.m.-g.m.-inequality', 'polynomials', 'optimization', 'multivariable-calculus']"
2188962,Determine if this series converges or diverges,"$$\sum_{n=1}^\infty \sin^{[n]}(1)$$ Where by $\sin^{[n]}(1)$ we mean $ \sin\left(\sin\left(\dots\sin(1)\right)\right)$ composed $n$ times. Have tried the divergence test, which fails. 
Have tried Ratio test, also fails, as the limit is 1.  Integral test, or root test do not seem promising. Help is appreciated","['power-series', 'sequences-and-series', 'calculus']"
