question_id,title,body,tags
3087833,$\sum_{n=1}^\infty a_n \cos nx$ unbounded near $0$ if $\sum a_n$ diverges?,"If $a_n$ is a decreasing positive sequence and tends to $0$ , and given $$\sum_{n=1}^\infty a_n=+\infty$$ can we prove that $$\lim_{x\rightarrow 0}\sum_{n=1}^{\infty} a_n \cos nx =+\infty$$ or at least prove the series above is unbounded for $x$ in a neighborhood of $0$ ? For the power series $$\sum_{n=1}^\infty a_n \left(1-x\right)^n $$ the conclusion holds, because $\left(1-x\right)^n$ is positive. I wonder if trigonometric series can have the similar conclusion, so I tested several $a_n$ , plotted the graph, and discovered that it is probably true. However, since $\cos nx$ is not identically positive, it is hard to give a rigorous proof, and I cannot give a counter-example either. Anyone has some ideas?","['trigonometric-series', 'analysis', 'real-analysis', 'complex-analysis', 'sequences-and-series']"
3087860,Does the function $f\circ g(x) = (f\circ g)(x)$ have same properties?,"Is $f\circ g(x) = (f\circ g)(x)$ ? Do they have similar properties on how they work as a functions. The function $(f\circ g)(x)$ is equal to $f(g(x))$ . But I am unaware on how $f\circ g(x)$ works. My guess is that $f\circ g(x)$ is the same as $(f\circ g)(x)$ since you compose the $x$ in $(f\circ g)(x)$ together to achieve $f \circ g(x)$ . But a problem that i noticed that if we compose $(f\circ g)(x)$ it together as I stated to get $f\circ g(x)$ , it would also imply that you can achieve $f(x)\circ g$ Due to that problem, I am unaware what is the appropriate answer. Furthermore, I am unable to find anything online.","['functions', 'proof-verification']"
3087865,Finding a $f(x)=\sum_{k\geq 0}a_k x^{4k+2}$ such that $f(x) \to 0$ as $x \to \infty$,"To provide a little context for this question, I recently proved that for a suitable function $f(x)$ the following identity holds $$\sum_{k=0}^{\infty}f'(k)=-2\sum_{n=1}^{\infty}\frac{f'(n)}{e^{2\pi n}-1}$$ The criteria for suitability of the function $f(x)$ essentially comes down to two major factors.  Firstly, $f(x)$ must possess a power series expansion of the form $$f(x)=\sum_{k=0}^{\infty}a_k x^{4k+2}$$ such the series $$\sum_{k=0}^{\infty}\frac{\vert{a_k}\vert}{(2\pi)^{4k}}(4k+2)! < \infty$$ Secondly, we must have $f(x) \to 0$ as $x \to \infty$ . After proving this, I wanted to find a specific example so that I could compute both of the series to ensure the identity actually holds and I didn't just make some error in my proof.  I didn't think this would be too difficult of a task, but frustratingly I have not been able to come up with a single example! My first thought was to try something Bessel-like as $J_v(x) \to 0$ as $x \to \infty$ .  Along these lines I figured the most sensible function to start with was the Wright function $z^2\phi(4,3,-z^4)$ where $$\phi(\alpha,\beta,z) = \sum_{n=0}^{\infty}\frac{z^n}{n!\Gamma(\alpha n + \beta)}$$ so that $$z^2\phi(4,3,-z^4) = \sum_{n=0}^{\infty}\frac{(-1)^n}{n!(4n+2)!}z^{4n+2}$$ Unfortunately, I quickly became aware of the fact that the asymptotics of more general hypergeometric functions can become quite complicated.  More specifically to my needs, $z^2\phi(4,3,-z^4)$ does not go to $0$ as $z \to \infty$ . This paper gives the asymptotics for the Wright function. I am wondering, does anyone have any suggestions on constructing a function with my desired properties?  Or showing that such a function does indeed exist?","['sequences-and-series', 'special-functions', 'real-analysis']"
3087952,"If $f(x)=\int_{0}^{x}\sqrt{f(t)}\,dt$ then $f(6)$ is?","let $f:[0,\infty) \rightarrow[0,\infty]$ be continuous on $[0,\infty]$ and differentiable on $(0,\infty)$ . if $f(x)=\int_{0}^{x}\sqrt{f(t)}dt$ then $f(6)$ is ? $f(0)=0$ $f'(x)=\sqrt{f(x)}\implies f'(6)=\sqrt{f(6)}\implies f'(6)^2=f(6)$ Now I am trying to find out $f'(6) $ somehow $f'(6)=\lim_{x \rightarrow 6}\dfrac{f(x)-f(6)}{x-6}=\lim_{x \rightarrow 6}\dfrac{f(x)-f'(6)^2}{x-6}$ $f'(0)=\lim_{x \rightarrow 0}\dfrac{f(x)-f(0)}{x-0}$ I am missing something and I am not able to solve this problem by above steps.
 Any hint?","['calculus', 'real-analysis']"
3087981,"On $A$ algebra homomorphisms $A[[X_1,...,X_n]]\to Q(A)$, where $A$ is a complete DVR","Let $(A,\mathfrak m)$ be a complete Discrete Valuation Ring (complete w.r.t. the $\mathfrak m $ -adic topology) with fraction field $K$ . Let $\phi : A[[X_1,...,X_n]]\to K$ be an $A$ -algebra homomorphism. Then is it true that $\phi(X_i) \in \mathfrak m, \forall i=1,...,n$ ?","['formal-power-series', 'algebraic-geometry', 'commutative-algebra', 'valuation-theory']"
3088018,Finding limit as $x \rightarrow 0$,"The question asks to find $$\lim _{x \rightarrow 0} \dfrac{\sin x^n}{\left(\sin x\right)^m} \;\;\;\forall\; m<n$$ I solved it by applying the L'Hopital rule since it is of the form $\frac{0}{0}$ and then once I differentiated we get $$\lim_{x \rightarrow0}       \left(\frac{\frac{d \sin x^n}{dx}}{\frac{ \left(d \sin x \right)^m}{dx}}\right),
$$ which gives us $$
\lim_{x \rightarrow0} \frac{n\cos x \cdot x^{n-1}}{\left(m \sin x\right)^{m-1} \cos x}.
$$ Now this gives us a function of the form $$\frac{n x^{n-1}}{\left(m \sin x\right)^{m-1}},
$$ which means that since $n>m$ now, we can keep differentiating the denominator and we will eventually get something of the form $\frac{0}{k}$ which means the limit must be $0$ . 
This is how I have gone about it. I have $2$ questions: $1.$ Is there a better method than this to solve it? $2.$ Can we find out the limit of this function if $m>n$ ?","['limits', 'calculus']"
3088089,On the evalution of an infinite sum,"I wish to show that $$\sum_{n = 0}^\infty (-1)^n \left [\frac{2n + 1/2}{(2n + 1/2)^2 + 1} + \frac{2n + 3/2}{(2n + 3/2)^2 + 1} \right] = \frac{\pi}{\sqrt{2}} \frac{\cosh \left (\frac{\pi}{2} \right )}{\cosh (\pi)}.$$ The reason I wish to find such a sum is as follows.
The question here called for the evaluation (I have added its value) of $$\int_0^\infty \frac{\sqrt{x} \cos (\ln x)}{x^2 + 1} \, dx = \frac{\pi}{\sqrt{2}} \frac{\cosh \left (\frac{\pi}{2} \right )}{\cosh (\pi)}.$$ As one of the comments, the OP remarked that they would like to see different approaches to the evaluation of the integral so I thought I would try my hand at one that does not rely on contour integration and the residue theorem. My approach was as follows: \begin{align}
\int_0^\infty \frac{\sqrt{x} \cos (\ln x)}{x^2 + 1} \, dx &= \int_0^1 \frac{\sqrt{x} \cos (\ln x)}{x^2 + 1} \, dx + \int_1^\infty \frac{\sqrt{x} \cos (\ln x)}{x^2 + 1} \, dx\\
&= \int_0^1 \frac{\cos (\ln x) (x + 1)}{\sqrt{x} (1 + x^2)} \, dx,
\end{align} after a substitution of $x \mapsto 1/x$ has been enforced in the second of the integrals. Now if we enforce a substitution of $x \mapsto e^{-x}$ one arrives at $$\int_0^\infty \frac{\sqrt{x} \cos (\ln x)}{x^2 + 1} \, dx = \int_0^\infty \frac{\cos x \cosh (x/2)}{\cosh x} \, dx.$$ Writing the hyperbolic functions in terms of exponentials we have \begin{align}
\int_0^\infty \frac{\sqrt{x} \cos (\ln x)}{x^2 + 1} \, dx &= \int_0^\infty \frac{\cos x (e^{-x/2} + e^{-3x/2})}{1 + e^{-2x}} \, dx\\
&= \text{Re} \sum_{n = 0}^\infty (-1)^n \int_0^\infty \left [e^{-(2n + 1/2 - i) x} + e^{-(2n + 3/2 - i)x} \right ] \, dx\\
&= \text{Re} \sum_{n = 0}^\infty (-1)^n \left [\frac{1}{2n + 1/2 - i} + \frac{1}{2n + 3/2 - i} \right ] \tag1\\
&= \sum_{n = 0}^\infty (-1)^n \left [\frac{2n + 1/2}{(2n + 1/2)^2 + 1} + \frac{2n + 3/2}{(2n + 3/2)^2 + 1} \right],
\end{align} which brings me to my sum. Some thoughts on finding this sum Rewriting the sum $S$ in (1) as follows: \begin{align}
S &= \text{Re} \cdot \frac{1}{4} \sum_{n = 0}^\infty \left [\frac{1}{n + 1/8 - i/4} + \frac{1}{n + 3/8 - i/4} - \frac{1}{n + 5/8 - i/4} - \frac{1}{n + 7/8 - i/4} \right ]\\
&= \text{Re} \cdot \frac{1}{4} \sum_{n = 0}^\infty \left (\frac{1}{n + 1} - \frac{1}{n + 7/8 - i/4} \right ) + \frac{1}{4} \sum_{n = 0}^\infty \left (\frac{1}{n + 1} - \frac{1}{n + 5/8 - i/4} \right )\\
& \qquad - \frac{1}{4} \sum_{n = 0}^\infty \left (\frac{1}{n + 1} - \frac{1}{n + 3/8 - i/4} \right ) - \frac{1}{4} \sum_{n = 0}^\infty \left (\frac{1}{n + 1} - \frac{1}{n + 1/8 - i/4} \right )\\
&= \frac{1}{4} \text{Re} \left [\psi \left (\frac{7}{8} - \frac{i}{4} \right ) + \psi \left (\frac{5}{8} - \frac{i}{4} \right ) - \psi \left (\frac{3}{8} - \frac{i}{4} \right ) - \psi \left (\frac{1}{8} - \frac{i}{4} \right ) \right ]. 
\end{align} Here $\psi (z)$ is the digamma function. I was rather hoping to use the reflexion formula for the digamma function, but alas it does not seem to take me any closer to a final real solution. Final thought While it would be nice to see how to evaluate this sum, perhaps my approach was not the best so alternative methods to evaluate the integral that avoid this sum and does not rely on contour integration would also be welcome.","['integration', 'improper-integrals', 'definite-integrals', 'closed-form', 'sequences-and-series']"
3088114,von Neumann sub algebras of $L^{\infty}$,"I know that $L^{\infty}([0,1],\mu)$ acting on $L^{2}([0,1],\mu)$ is a von Neumann algebra. How will be the von Neumann sub algebras $L^{\infty}([0,1],\mu)$ look like?","['von-neumann-algebras', 'measure-theory']"
3088120,Definition of prime numbers and equivalence,"A prime number $p$ is a positive integer that has exactly two different dividers ( $1$ and itself). This is a very clear and universal definition. My notes say that this definition is equivalent to the previous one: $p$ is a prime number if from $p \mid ab$ follows that $p \mid a$ or $p \mid b$ for $a,b \in \mathbb{Z}$ . I was wondering why this is an equivalent definition for a prime number. Thanks in advance!","['elementary-number-theory', 'divisibility', 'discrete-mathematics', 'prime-numbers']"
3088257,Intuition for the Stone-Čech compactification via ultrafilters,"Definitions used: Given some set $X$ , denote by $\beta X$ the set of ultrafilters on $X$ . We can view $X$ as a subset of $\beta X$ by identifying each point $x \in X$ with the principal ultrafilter associated to $x$ . Further, the collection of all sets of the form $\widehat{A} = \{ \mathcal{U} \in \beta X\ |\ A \in \mathcal{U} \}$ supplies us with a basis for a topology on $\beta X$ . If we view $X$ as a discrete space and equip $\beta X$ with the topology generated by the aforementioned basis, then $\beta X$ is termed the Stone-Čech compactification of $X$ . The space $\beta X$ is both compact and Hausdorff; the proofs of both of these facts are routine. My question: Purely formally, I feel that I understand all of the above, in the sense that I can solve a problem of the kind ""given the set $X$ , define the set $\beta X$ as above; verify that what we claim to be a basis is indeed a basis, and show that under the topology generated by this basis $\beta X$ is both compact and Hausdorff"" painlessly. My issue is that I have no sense of why we might expect $\beta X$ to be compact Hausdorff in the first place. Is this something that could be anticipated, or is it just a happy accident that we find when asking ourselves (quite reasonably) whether or not $\beta X$ has these properties? My intuition: In general, I think of compactifications as ""adding points at infinity"" so that anything that wants to ""escape to infinity"" gets ""captured"". This is pretty vague, but works reasonably well for (e.g.) the Alexandroff compactification. The Alexandroff compactification of $\mathbb{R}$ is just $S^1$ , so that anything that can run away to infinity in $\mathbb{R}$ ends up ""looping back around"" in $S^1$ . I have less intuition for (ultra)filters, and tend to think of filters as being prescriptions for saying when certain subsets of a set $X$ are ""large enough"", and of an ultrafilter extending a given filter as being a (not, in general, unique) way of consistently extending that prescription to apply to all subsets of $X$ . This basically came from the answers of Henning Makholm and Asaf Karagila to this math.SE question . Unfortunately, I'm struggling to use this understanding of ultrafilters and compactifications to see why we would suspect that $\beta X$ is compact Hausdorff before outright proving it. (I apologise for such a vague question being so long: given how what I ask is in some senses nebulous and non-concrete, I wanted to be completely explicit about both the definitions I use and the intuition that I already have).","['filters', 'general-topology', 'compactification', 'intuition']"
3088265,Cardinality of sets of functions $\mathbb{R}\to \mathbb{N}$ and $\mathbb{N}\to \mathbb{R}$. [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Let $B^A$ denote the set of all functions $A \to B$ . Prove that $\left|\mathbb{R}^\mathbb{N}\right|<\left|\mathbb{N}^\mathbb{R}\right|$ .","['elementary-set-theory', 'cardinals']"
3088304,Finding sum of none arithmetic series,"I have a question to find the sum of the following sum: $$
S = \small{1*1+2*3+3*5+4*7+...+100*199}
$$ I figured out that for each element in this series the following holds: $$
a_n = a_{n-1} + 4n - 3
$$ But I don't know where to go from here, I tried subtracting some other series but that did not work very well","['summation', 'telescopic-series', 'sequences-and-series']"
3088362,On the definition of Schwartz functions,"$$
\mathcal{S}(\mathbb{R}^{n})=\Big\{f\in C^{\infty}(\mathbb{R}^{n})\,\Big|\; \sup_{\mathbb{R}^{n}}|x^{\alpha}D^{\beta}f(x)|<\infty\, \forall \alpha,\beta\, \text{multi indexes}\Big\}.
$$ I can't find why is necessary the derivate condition; can you give me an example of a function such that $\sup_{\mathbb{R}^{n}}|x^{\alpha}f(x)| < \infty \,\forall \alpha \,\text{multi index}$ but exists $\beta$ such that $\sup_{\mathbb{R}^{n}}|x^{\alpha}D^{\beta}f(x)|=\infty$ ?","['definition', 'schwartz-space', 'functional-analysis']"
3088383,Is there a possible geometric method to find length of this equilateral triangle?,"Problem Given that $AD \parallel BC$ , $|AB| = |AD|$ , $\angle A=120^{\circ}$ , $E$ is the midpoint of $AD$ , point $F$ lies on $BD$ , $\triangle EFC$ is a equilateral triangle and $|AB|=4$ , find the length $|EF|$ . Attempt At first glance, I thought it could be solved using a geometric method. I considered the law of sines/cosines , similar triangles , Pythagorean theorem , even Menelaus' theorem , however, got properties which contributed nothing to calculate $|EF|$ . What I've got after draw a line perpendicular to $BC$ through $E$ $\triangle ABH$ and $\triangle AHD$ are both equilateral triangles of length 4. $\triangle EFD \sim \triangle GEH$ $|EH|=2\sqrt{3}$ Algebraic method Eventually, I've changed my mind to embrace algebra. I found it is easy to coordinate $E,A,B,D$ and $C$ is related to $F$ (rotation) and $B$ (same horizontal line). Make $E$ as the origin, $AD$ points to $x$ -axis, $HE$ points to $y$ -axis, we got $E = (0,0)$ $A = (-2,0)$ $B = (-4,-2\sqrt{3})$ $D = (2,0)$ Point $(x, y)$ in line $BD$ has $y=\frac{1}{\sqrt{3}}(x-2)$ . Assume $F=(x_0,y_0)$ , $C=(x_1,y_1)$ , we can obtain $C$ by rotating $F$ around pivot $E$ $60^{\circ}$ counter-clockwise $$
\begin{bmatrix}
x_1 \\ y_1
\end{bmatrix} 
= 
\begin{bmatrix}
\cos{\theta} & -\sin{\theta} \\
\sin{\theta} & \cos{\theta} 
\end{bmatrix}
\begin{bmatrix}
x_0 \\ y_0
\end{bmatrix} 
$$ , also we know that $BC$ is parallel to $x$ -axis, then $$
\begin{align*}
y_1 
 & = \sin{60^{\circ}} x_0 + \cos{60^{\circ}} y_0 \\
 & = \sin{60^{\circ}} x_0 + \cos{60^{\circ}} \frac{1}{\sqrt{3}}(x_0-2) \\
 & = -2\sqrt{3}
\end{align*}
$$ , thus $F=(-\frac{5}{2}, -\frac{3\sqrt{3}}{2})$ , and finally $|EF|=\sqrt{13}$ Thoughts afterwords I noticed that $F$ (through its coordinate) is actually the midpoint of $BK$ . It may be a key point in geometric method, but I cannot prove it either. Graph I made it in GeoGebra and it is shared. Please go and edit it to save your time if you have any idea. 
Link: https://www.geogebra.org/graphing/yqhbzdem","['euclidean-geometry', 'analytic-geometry', 'vectors', 'geometry', 'geometric-transformation']"
3088396,Finding incomplete solutions of second order ODE system,"For a smooth, 1-periodic, positive function $c:\mathbb{R}\rightarrow (0,\infty)$ consider the following second order ODE system for the curve $\gamma(t)= (x(t),y(t),z(t)):\mathbb{R}\rightarrow \mathbb{R}^3$ (note that I will denote the derivative of $c$ by a prime and the derivatives of the curve components $x,y,z$ by dots). \begin{align}
(i) \hspace{15mm} \ddot{x}(t)+ \frac{c'(z(t))}{c(z(t))}~ \dot{x}(t)\dot{z}(t)=0 \\
(ii) \hspace{14mm} \ddot{y}(t) +\frac{c'(z(t))}{c(z(t)))}~\dot{y}(t)\dot{z}(t)=0 \\
(iii) \hspace{16mm} \ddot{z}(t)-c'(z(t)) ~ \dot{x}(t)\dot{y}(t)=0
\end{align} My question: I'm interested in finding a function $c$ as described above such that the system has ""incomplete"" solutions, i.e. solutions $\gamma:\mathbb{R}\rightarrow \mathbb{R}^3$ which are not defined for all times $t\in\mathbb{R}$ . Or alternatively I want to show that for all $c$ as above there are no incomplete solutions. Background: the background to this problem is a geometric one: I have a family of metrics $\{g_c\}$ given on $\mathbb{R}^3$ (where $c$ is as described above) and I'm asking myself if all those metrics are geodasically complete. Solving the geodesic equation for those metrics gives the above system of ODEs.","['nonlinear-system', 'riemannian-geometry', 'ordinary-differential-equations']"
3088415,Apply the Implicit Function Theorem to find a root of polynomial,"Caculate the value of the real solution of the equation $x^7+0.99x-2.03$ , and give a estimate for the error. The hint is: use the Implicit Function Theorem. I dont know how to use the IFT in this case, I'm not familiarized with this. I think in construct a function $F:\mathbb{R}^n \times \mathbb{R} \to \mathbb{R}$ with some parameters of which one is the root. Maybe $$F(c_1,c_2,c_3,x) = c_{1}x^7 + c_{2}x - c_{3}.$$ But I'm note sure about this. Can someone help me?","['derivatives', 'implicit-function-theorem', 'real-analysis']"
3088460,Restriction of scalars $G \mapsto \operatorname{Res}_{\mathbb C/\mathbb R} G$ is injective?,"Let $G$ be a linear algebraic group over $\mathbb C$ , and let $G_0 = \operatorname{Res}(\mathbb C/\mathbb R, G)$ be the linear algebraic group over $\mathbb R$ obtained by Weil restriction of scalars.  One way to construct $G_0$ is by taking the defining polynomials for $G$ with complex coefficients, and rearranging these into a system of polynomials with real coefficients. Is the functor $G \mapsto G_0$ faithful?  It seems like this should be the case.  If we base change $G_0$ back to $\mathbb C$ , we get the product $G \times G$ , although not $G$ itself. In more algebraic terms, the question comes down to undoing this process of rearranging the system of polynomials.  If we have polynomials $$f(T) = a_0 + a_1T + \cdots + a_nT^n \in \mathbb C[T]$$ then we write $T = X+iY$ , $a_j = b_j + ic_j$ , and rearrange the condition $f(t) = 0$ into the condition that two polynomials in the variables $X$ and $Y$ vanish.  The question is whether any two reversals of this process give the same complex algebraic variety over $\mathbb C$ .","['algebraic-geometry', 'algebraic-groups']"
3088494,Prove that $\lim n\int_1^a\frac{1}{1+x^n}dx=\ln 2$,"My problem is that for a given $a>1$ , we have that $$\lim_{n\to\infty}n\int_{1}^{a}\frac{1}{1+x^n}dx=\ln 2$$ The natural idea seems to be to add and substract $x^n$ from the numerator and we obtain easily that $$n\int_{1}^{a}\frac{1}{1+x^n}dx=n(a-1)-a\ln(1+a^n)+\ln2+\int_1^a\ln(1+x^n)dx$$ which would sort of explain the $\ln 2$ result but I can't continue from here.","['limits', 'definite-integrals', 'real-analysis']"
3088503,"Why $ \int_0^{2\pi}\frac{\cos t - r}{1 - 2r\cos t + r^2}\,dt=0$ for $r\in[0,1)$","Define $$
I(r) = \int_0^{2\pi}\frac{\cos t- r}{1 - 2r\cos t + r^2}\,dt
$$ over $r\in [0,1)$ . Numerical experiments suggest $I(r) = 0$ for all $r\in [0,1)$ . But I can't show this analytically. This integral appears when computing the Cauchy transform of $\overline z$ over a unit circle. The latter, therefore, seems to be constantly zero.","['integration', 'trigonometric-integrals', 'definite-integrals', 'real-analysis']"
3088519,Prove that $P(A ∩ B) ≤ P(A ∪ B) ≤ P(A) + P(B)$,"I don´t know if my proof is right. I separated it into 2: $1) P(A ∩ B) ≤ P(A ∪ B)$ Pf: $P(A ∪ B) = P(A\setminus B) + P(B\setminus A) + P(A ∩ B)$ and we know that $0 ≤ P(A\setminus B) ≤ 1$ and $0 ≤ P(B\setminus A) ≤ 1$ so $P(A ∩ B) ≤ P(A ∪ B)$ $2)  P(A ∪ B) ≤ P(A) + P(B)$ Pf: $P(A ∪ B) = P(A) + P(B) - P(A ∩ B)$ and we know that $0 ≤ P(A ∩ B) ≤ 1$ so $P(A ∪ B) ≤ P(A) + P(B)$ Therefore, $P(A ∩ B) ≤ P(A ∪ B) ≤ P(A) + P(B)$","['elementary-set-theory', 'probability']"
3088540,Functions with finite right-hand limits are Borel measurable,"I'm studying for my exam in measure and integration theory and we got some exercises that we can do for preparation and I'm stuck on this one. Every function $f:\Bbb R \rightarrow \Bbb R $ (from reals to reals) with the property that $\displaystyle\lim _{ h\to 0^{+}}{ f(x+h) } $ exists for all $x\in \Bbb R $ is Borel measurable. I just proved that the pointwise limit of measurable functions is again measurable. So I thought about ways we could represent our $f$ as a limit of (Borel) measurable functions but I dont think it is in general possible to find such a sequence for an arbitrary $f$ . Further I feel like i don't understand the condition that $$\lim _{ h\to 0^+ }{ f(x+h) } $$ exists correctly. Is it possible to derive some form of continuity with this property? Could someone shed some light on this problem for me, thanks for any help.","['measure-theory', 'real-analysis']"
3088543,Number of ways to arrange word 'KBCKBCKBC',"The word 'KBCKBCKBC' is to be arranged in a row such that no word contains the pattern of KBC . $Attempt$ Event $A$ =1st KBC is in the pattern, $B$ =2nd KBC is in the pattern and similar is the event C. Now required is $n((notA) (notB) (notC)) =Total ways - [\sum n(A) - \sum n(AB)+ \sum n(ABC)] $ Total ways = $\frac{9!}{3!3!3!}$ $\sum n(AB) = \frac{5!}{2!}$ $\sum n(ABC) = 1$ But, my main doubt is that I am not able calculate $\sum n(A)$ . Any suggestion? Also please suggest about different method you know. Thanks for the help.","['permutations', 'inclusion-exclusion', 'combinatorics']"
3088620,Why is the $C^\infty(M)$-module of smooth sections of a vector bundle $E$ not free?,"Let $M$ be a second countable smooth manifold. When I learned about differential geometry, a side note was made about how if $E$ is a vector bundle, $\Gamma(E)$ is a $C^\infty(M)$ -Module that is not free, but projective. I now realized that I have no idea how to prove that! My first attempt was to look for torsion elements, but $F_R(X)$ (the free $\operatorname{\underline{R-Mod}}$ over the set $X$ ) having no torsion elements is only satisfied if $R$ is a domain – which is clearly not the case for $C^\infty(M)$ (take bump functions with different support). So: How do you show that $\Gamma(E)$ is not free as a $C^\infty(M)$ -Module? What are good tactics to show that a (non-finitely generated) module is not free if the ring $R$ is not even a domain?","['free-modules', 'modules', 'vector-bundles', 'abstract-algebra', 'differential-geometry']"
3088623,Small question on Pythagoras theorem,The projections-of-the-legs over the hypotenuse should add up to the hypotenuse $c$ . Is there any alternative way to prove below? $$a\cos \alpha + b\sin \alpha = \sqrt{a^2+b^2}$$,['algebra-precalculus']
3088666,What is approximately the distribution of your total earning?,"You play a game in a casino: you roll two dice and if the sum of the spots equals seven, you win $5$ €. In every other case, you lose $1$ €. You decide to play this game $120$ times. What is approximately the distribution of your total earning? So the probability that the sum  of two dice $X$ and $Y$ is $7$ can be calculate with: $P(X+Y=7)=\frac{6}{36}=\frac{1}{6}$ considering all the cases: ((1,6), (2,5), (3,4), (4,3), (5,2), (6,1)). Then the probability that the sum of the two dice is not $7$ is $1-\frac{1}{6}=\frac{5}{6}$ . So I think that the distribution should be $Bin(120,\frac{1}{6})$ but from the teacher answer it is $N(0,600)$ , where I'm wrong? Why is not Binomial but Normal?","['statistics', 'dice', 'probability']"
3088677,How to prove that $\int_{0}^{\infty}\ln^2(x)\sin(x^2)dx=\frac{1}{32}\sqrt{\frac{\pi}{2}}(2\gamma-\pi+\ln16)^2$,"Wolfram Alpha provides $$\int_{0}^{\infty}\ln^2(x)\sin(x^2)dx=\frac{1}{32}\sqrt{\frac{\pi}{2}}(2\gamma-\pi+\ln16)^2\tag{1}$$ But I haven't figured out the way to verify this result. I know Frullani's Integral $$\ln(x)= \int_{0}^{\infty}\frac{e^{-t}-e^{-xt}}{t}dt$$ I also know $$\int_{0}^{\infty}\sin(x^2)~dx=\frac{1}{2}\int_{0}^{\infty}x^{-1/2}\sin(x)~dx$$ Then, $$\begin{align}
\int_{0}^{\infty}\ln^2(x)\sin(x^2)dx&=\int_{0}^{\infty}\left(\int_{0}^{\infty}\frac{e^{-t}-e^{-xt}}{t}dt\right)\left(\int_{0}^{\infty}\frac{e^{-n}-e^{-xn}}{n}dn\right)\sin(x^2)~dx\\
&=\frac{1}{2}\int_{0}^{\infty}\left(\int_{0}^{\infty}\frac{e^{-t}-e^{-xt}}{t}dt\right)\left(\int_{0}^{\infty}\frac{e^{-n}-e^{-xn}}{n}dn\right)\frac{\sin(x)}{\sqrt{x}}dx\\
&=\frac{1}{2}\int_{0}^{\infty}\int_{0}^{\infty}\int_{0}^{\infty}\frac{e^{-t}-e^{-xt}}{t}\frac{e^{-n}-e^{-xn}}{n}\frac{\sin(x)}{\sqrt{x}}~dx~dn~dt\\
&=\frac{1}{2}\int_{0}^{\infty}\frac{1}{t}\int_{0}^{\infty}\frac{1}{n}\int_{0}^{\infty}(e^{-t}-e^{-xt})(e^{-n}-e^{-xn})\frac{\sin(x)}{\sqrt{x}}~dx~dn~dt\\
&=\frac{1}{2}\int_{0}^{\infty}\frac{1}{t}\int_{0}^{\infty}\frac{1}{n}\int_{0}^{\infty}(e^{-t-n}-e^{-xn-t}-e^{-xt-n}+e^{-xt-xn})\frac{\sin(x)}{\sqrt{x}}~dx~dn~dt
\end{align}$$ What should I do next?
There is also a general case $$\int_{0}^{\infty}\ln^2(x^a)\sin(x^2)dx=\frac{a^2}{32}\sqrt{\frac{\pi}{2}}(2\gamma-\pi+\ln16)^2\tag{2}$$ But I think $(2)$ becomes easy to prove if we can prove $(1)$ .","['integration', 'calculus']"
3088698,Invariance for translations of the Lebesgue measure,"Let $T\colon\mathbb{R}\to\mathbb{R}$ a linear trasformation of $\mathbb{R}$ defined as $Tx:=ax+b$ , where $a,b\in\mathbb{R}$ , $a\ne 0.$ We want to show the invariance for translations of the Lebesgue measure using the following result. Theorem. For all $E\subseteq\mathbb{R}$ we have $\lambda^*(T(E))=|a|\lambda^*(E);$ Notation. $\lambda^*$ is the Lebesgue outer measure, that is $$\lambda^*(E):=\inf\bigg\{\sum_{n=1}^{+\infty}\lambda_0(I_k)\;\bigg|\;\{I_n\}\subseteq\mathcal{I},E\subseteq\bigcup_{n=1}^{+\infty}I_n\bigg\},$$ where $\mathcal{I}$ is the algebra of plurintervals and $\lambda_0\colon\mathcal{I}\to [0,+\infty]$ is a measure definited as following: let $$\mathcal{I}_0=\{(a,b]\;|\;-\infty\le a\le b<+\infty)\}\cup\{(a,+\infty)\;|a\in\mathbb{R}\},$$ the family $\mathcal{I}$ consists of the finite disjoint unions of elements of $\mathcal{I}_0,$ then \begin{cases}
\lambda_0(\emptyset):=0 \\
\lambda_0((a,b]):=b-a & \text{if $-\infty<a\le b<+\infty$}\\
\lambda_0((a,+\infty)):=+\infty &\text{if $a\in\mathbb{R}.$}
\end{cases} Moreover, if $E\in\mathcal{I}\setminus\mathcal{I}_0$ $$\lambda_0(E):=\sum_{k=1}^{n}\lambda_0(E_k)$$ where $\{E_k\}_{k=1}^{n}\subseteq\mathcal{I}_0$ and $E=\bigcup_{k=1}^{n}E_k.$ $\mathcal{L}$ is the Lebesgue's $\sigma-$ algebra. Proof. We consider the linear transformations on $\mathbb{R}$ : $$T_1x:=\frac{a}{|a|}x,\quad T_2x:=|a|x,\quad T_3x:=x+b.$$ We observe that $T$ is the composition of $T_1,T_2$ and $T_3$ . In fact let $x\in\mathbb{R}$ , $$T_3T_2T_1x=T_3T_2\bigg(\frac{a}{|a|}x\bigg)=T_3(ax)=ax+b.$$ We start to prove that $\lambda^*(T_3(E))=\lambda^*(E).$ $(a)$ Let $\lambda^*(E)<+\infty.$ Then for $\varepsilon>0$ exists $\{I_k\}_{k\in\mathbb{N}}$ such that $$E\subseteq\bigcup_{k=1}^{+\infty} I_k\quad\lambda^*(E)+\varepsilon > \sum_{k=1}^{+\infty}\lambda_0(I_k).$$ Then $$T_3(E)\subseteq T_3\big(\bigcup_{k=1}^{+\infty} I_k\big)=\bigcup_{k=1}^{+\infty} T_3(I_k).$$ Therefore, $$\lambda^*(T_3(E))\le\sum_{k=1}^{+\infty}\lambda_0(T_3(I_k))\color{RED}{=}\sum_{k=1}^{+\infty}\lambda_0(I_k)<\lambda^*(E)+\varepsilon.$$ In the red equality we used the fact that for definition $\lambda_0$ is invariant for trasformation of type $T_3$ . Then for the arbitrariness of $\varepsilon$ we have that $\lambda^*(T_3(E))\le\lambda^*(E).$ Question 1. How can I show that $\lambda^*(T_3(E))\ge\lambda^*(E)$ ? $(b)$ Let $\lambda^*(E)=+\infty$ . We suppose for absurd that $\lambda^*(T_3(E))<+\infty$ , then exists $\{I'_k\}_{k\in\mathbb{N}}\subseteq\mathcal{I}$ such that $$T_3(E)\subseteq\bigcup_{k=1}^{+\infty}I'_k,\quad\sum_{k=1}^{+\infty}\lambda_0(I'_k)<\lambda^*(T_3(E))+\varepsilon<+\infty.$$ Since $E\subseteq\bigcup_{k=1}^{+\infty}\big[T_3^{-1}(I'_k)\big]$ we have $$\lambda^*(E)\le\sum_{k=1}^{+\infty}\lambda_0(T_3^{-1}(I'_k))\color{GREEN}{=}\sum_{k=1}^{+\infty}\lambda_0(I'_k)<+\infty,$$ absurd. Question 2. Why is the equality in green is valid? $$$$ Question 3. How can I formally show that $\lambda_0$ is invariant for transformations of the type $T_1, T_2, T_3$ ? In the same way it is shown that $\lambda^*(T_2(E))=|a|\lambda^*(E)$ and $\lambda^*(T_1(E))=\lambda^*(E).$ Therefore \begin{equation}
\begin{split}
\lambda^*(T(E))=&\lambda^*(T_3(T_2(T_1(E))\\
=&\lambda^*(T_2(T_1(E))\\
=&\lambda^*(T_1(E))\\
=&|a|\lambda^*(E)
\end{split}
\end{equation} Question 4. Is it true or false that $\lambda^*(T^{-1}(E))=|a|\lambda^*(E)$ ? How can I show it? My answer is false, but $$\lambda^*(E)=\lambda^*\big(T\big[T^{-1}(E)\big]\big)=|a|\lambda^*\big(T^{-1}\big(E\big)\big).$$ Therefore $\lambda^*\big(T^{-1}\big(E\big)\big)=\frac{1}{|a|}\lambda^*(E).$ Correct? Clarifications on the answer Thanks for the ansewer @астон вілла олоф мэллбэрг
, but some doubts remain to me.  My book says to proceed this way $\lambda^*(T_1(E))=\lambda^*(E)$ , $\lambda^*(T_2(E))=|a|\lambda^*(E)$ , $\lambda^*(T_3(E))=\lambda^*(E).$ You explained to me that if $I\in\mathcal{I}$ , then $T_3(I)\in\mathcal{I}$ , moreover $\lambda_0$ is invariant under $T_3$ , then it is proved that $\lambda^*(T_3(E))\le\lambda^*(E),$ how can I show that $$\lambda^*(T_3(E))\ge\lambda^*(E)?$$ The same procedure can lead to show that $\lambda^*(T_2(E))=|a|\lambda^*(E)$ , with the necessary changes about $\lambda_0.$ Since $T_1(I)\notin\mathcal{I}$ , how can I show that $\lambda^*(T_1(E))=\lambda^*(E)?$ And finally how do I paste everything to show that $\lambda^*(T(E))=\lambda^*(E)$ ? Thanks!
Thanks!","['proof-explanation', 'measure-theory', 'lebesgue-measure']"
3088703,Wasserstein distance between hyperplane and cube,"Let $\mu$ be the uniform measure on the cube $Q = [-1,1]^n$ , and $\nu$ be the uniform measure on the surface $$
V = \{(x_1,\dots,x_n)\in Q \mid \sum x_i = 0\}.
$$ I am curious about Wasserstein distance between $\mu$ and $\nu$ , using the $l^\infty$ distance on $\mathbb{R}^n$ . That is, I would like a bound on $$
\sup_{\|f\|_{Lip}=1} |\mathbb{E}_\mu f - \mathbb{E}_\nu f|.
$$ I expect that the distance is on the order of $n^{-1/2}$ based on the following two calculations.  First, one guess is that the function $S(x)=\frac{1}{n}|\sum x_i|$ would be close to optimizing the above supremum, and $$
|\mathbb{E}_\mu S - \mathbb{E}_\nu S| \leq Cn^{-1/2}.
$$ The second heuristic follows from the fact that if $x\in Q$ is sampled according to $\mu$ , then with high probability $|\sum x_i| \leq Cn^{1/2}$ , so by nudging each of the coefficients by an amount $n^{-1/2}$ it should be possible to land on the plane.  This gives a transport map from $\mu$ to a measure supported on $V$ that has cost roughly $n^{-1/2}$ .  The problem is that the transported measure is not the same as $\nu$ , so this does not constitute a proof.","['measure-theory', 'concentration-of-measure', 'optimal-transport', 'probability-theory']"
3088727,Discrete mathematics - logical equivalence?,"I'm asked to find a logical expression that is equivalent to the one listed in the question below, but I'm stumped as to what steps I would take next. If someone could show me step by step how to solve them and what rules would be used, I would really appreciate it. Using only the NOT and the AND operators, find an expression that is equivalent to ┬¼(a Ōł¦ ┬¼b)Ōåö­ØæÉ The furthest I got is (┬¼aŌł©b)Ōåöc by using De Morgan's law, but I don't know how I can simplify it further than that. Someone told me the final answer is b Ōåö c but I have no idea how they got there or if it's even correct?","['propositional-calculus', 'logic', 'discrete-mathematics']"
3088807,Irresistible: $T(p)=\int_0^{\pi/2}x\tan(x)^p\mathrm dx$ for $-2<p<1$,"I am working on a challenge posed to me by the book Irresistible Integrals , finding a closed form for the integral $$T(p)=\int_0^{\pi/2}x\tan(x)^p\mathrm dx,\qquad -2<p<1$$ I am confident that a closed form exists, because the book tells me to find it. My efforts: $$T(p)=\int_0^{\pi/2}x\tan(x)^p\mathrm dx$$ $x=\arctan u$ : $$I(p)=\int_0^\infty \frac{u^p}{1+u^2}\arctan u\,\mathrm du$$ $u=\frac1t$ : $$T(p)=\int_0^{\infty}\frac{t^{-p}}{1+\frac{1}{t^2}}\arctan(1/t)\frac{\mathrm dt}{t^2}$$ $$T(p)=\frac\pi2\int_0^{\infty}\frac{t^{2-p}}{1+t^2}\mathrm dt-\int_0^\infty \frac{t^{2-p}}{1+t^2}\arctan t\,\mathrm dt$$ $$T(p)=\frac\pi2J(p)-T(2-p)$$ Then focusing on $$J(p)=\int_0^{\infty}\frac{t^{2-p}}{1+t^2}\mathrm dt$$ As I have shown before, this integral relates to the Beta function: $$\int_0^{\infty}\frac{t^{2b-1}\mathrm dt}{(1+t^2)^{a+b}}=\frac12\mathrm{B}(a,b)=\frac{\Gamma(a)\Gamma(b)}{2\Gamma(a+b)}$$ So $$J(p)=\frac12\Gamma\left(\frac{p-1}2\right)\Gamma\left(\frac{3-p}2\right)$$ But this only works for $p\in(1,3)$ , so I'm thinking that my functional equation is entirely false. Does anyone know how to evaluate this integral? Thanks. Edit: As was noted in the comments, we have $$T(p)=\frac\pi2\int_0^\infty \frac{t^{-p}}{1+t^2}\mathrm dt-\int_0^\infty \frac{t^{-p}}{1+t^2}\arctan t\,\mathrm dt$$ So redefining $J(p)=\int_0^\infty \frac{t^{-p}}{1+t^2}\mathrm dt$ We have that $$J(p)=\frac12\Gamma\left(\frac{1-p}2\right)\Gamma\left(\frac{1+p}2\right)$$ Then if we recall that $$\Gamma(s)\Gamma(1-s)=\frac\pi{\sin\pi s}$$ $$\Gamma(s/2)\Gamma(1-s/2)=\frac\pi{\sin\frac{\pi s}2}$$ $$\Gamma\left(\frac{1+s}2\right)\Gamma\left(\frac{1-s}2\right)=\frac\pi{\sin\frac{\pi(s+1)}2}=\frac\pi{\cos\frac{\pi s}2}$$ So $$T(p)+T(-p)=\frac{\pi^2}{4\cos\frac{\pi p}2}$$","['integration', 'calculus', 'closed-form']"
3088814,Are isomorphic plane curves projectively equivalent?,"Let $C$ and $D$ be two projective plane curves (over $\mathbb{C}$ ) of degree $d>1$ . Suppose that $C$ and $D$ are isomorphic. Are $C$ and $D$ projectively equivalent? For smooth curves this is a theorem by M. Noether. So we may restrict to the singular curves. Any reference, idea or counterexample will be welcome.","['algebraic-curves', 'algebraic-geometry']"
3088817,Compactness of an integral operator from $L^2$ to $L^2$,"I want to prove that The operator (linear and bounded) $T: L^2(0,1) \rightarrow L^2(0,1)$ , defined by: $Tu(x)=\int_0^1\sin(x^2+y^2)u(y)dy$ , is compact. Just by using theory, it's an Hilbert Schmidt operator, so it's compact. Indeed, the kernel $k(x,y) = \sin(x^2+y^2) \in L^2([0,1] \times [0,1])$ . I want to use a more direct approach, by using Ascoli-Arzelà. First of all, I see that $|Tu(s)-Tu(t)|=| \int_0^1 [\sin(s^2+y^2)-\sin(t^2+y^2)]u(y)dy| < \varepsilon ||u||_{L^2}^2$ , since $s \mapsto \sin(s^2+y^2)$ is continuous on a compact set, then it's unformly continuous . Then $Tu(x)$ is continuous, and then $T: L^2([0,1]) \rightarrow C^{0}[0,1] \subset L^2([0,1])$ To prove compactness, I take $B \subset L^2(0,1)$ , with $||u|| \leq M_b$ , for $u \in B$ . I want to prove that $T(B)$ is relatively compact in $C^0([0,1])$ by using Ascoli-Arzelà. $T(B)$ is equibounded $|Tu(x)|=|\int_0^1 \sin(x^2+y^2) u(y) dy| \leq 1\cdot ||u||_{L^2}^2 \leq M_b$ Now I show equicontinuity Again, I compute $|Tu(s)-Tu(t)| = \int_0^1 [\sin(s^2+y^2)-\sin(t^2+y^2)]u(y)dy| \leq |s-t| ||u||_{L^2}^2$ by MVT applied to $s \mapsto \sin(s^2+y^2)$ for $s \in [0,1]$ . So $T(B)$ is equilipschitz, thus equicontinuos. Then, by Ascoli-Arzelà, $T(B)$ is relatively compact in $C^0([0,1])$ . Now, since the immersion $C^0 \hookrightarrow L^2[0,1]$ is continuos, then $T(B)$ is relatively compact in $L^2[0,1]$ . Is my second approach okay? Or do I need to fix something?","['arzela-ascoli', 'operator-theory', 'compact-operators', 'functional-analysis']"
3088920,Solve recursion,"$a_n=n^2\times a_{(n-1)}$ , for $ n>0, a_0=1$ Whats the correct formula to use in this case? I solved problem with recursion before, but they had ' $+$ ' instead of $'\times'$ so there is following formula to simply solve them: $ar^n+bnr^n$ . Is there something similar, but for multiplication instead?",['discrete-mathematics']
3088994,Examples of connected door spaces.,"A topological space $X$ is a door space if any subset of $X$ is either open or closed (or both). Naturally, a connected door space is that in which any proper subset is either open or closed, but not both. According to this paper , there are only three types of topologies yielded by connected door spaces: particular point topologies, excluded point topologies, and $T_1$ topologies in which any two non-disjoint open sets have infinite intersection. Is there any explicit example of a connected door space of the third type? The cofinite topology on any infinite set satisfies the third type but is never a door space, and I can't really think of spaces in which open intersections are infinite...","['general-topology', 'examples-counterexamples', 'connectedness']"
3089031,$| \sin x| > \frac{\sqrt{2-\sqrt{2}}}{2}$ iff $1/8< \{ \frac{x}{\pi}\} < 7/8$ where $\{x\}$ is the fractional part of $x$,"This is a problem that arose while reading the book ""Putnam and Beyond"": Why is $| \sin x| > \frac{\sqrt{2-\sqrt{2}}}{2}$ iff $\frac18 < \{ \frac{x}{\pi}\} < \frac78$ where $\{x\}$ is the fractional part of $x?$ This was used in proving the divergence of $\sum \frac{ |\sin n|}{n}$ , although the divergence is not in question here.","['fractional-part', 'trigonometry', 'problem-solving', 'inequality']"
3089033,Four equal circles intersect: What is the area of the small shaded portion and its height,"In terms of $R$ which is the radius of all four circles, what is the area of the intersection region of these four equal circles and the height of the marked arrow in the figure? The marked arrow is along the line CD, also the midpoint of all the circles are points A, B, C and D. Looking for a very short intuitive solution. I have checked similar questions on this site for example this and this .","['circles', 'geometry']"
3089092,Finding all continuous functions such that $\int_0^xf(t)dt=(f(x))^2+C $,"$C$ is a constant. FTC shows that $f(x)^2+C$ must be differentiable, which means that $f(x)^2$ is differentiable. But we don't know that $f(x)$ is differentiable then, right? I had the idea that the only two solutions are $f(x)=0$ or $f(x)=\frac{x}{2}$ , but this is assuming that $f(x)$ is differentiable. I'm not sure how to show that they are the only solutions (if they even are the only solutions).","['integration', 'real-analysis']"
3089101,Minimum number of rectangles to cover diagonal-free grid,"I'm trying to figure out the minimum number of rectangles required to cover an $n \times n$ grid, minus the diagonal. What this is means is the following: Suppose we have an $n \times n$ grid, with the diagonal missing. What is the minimum umber of rectangles I need that are contained within the grid such that the union of the rectangles covers the entire grid? I think the answer should be $\log_2 n$ . Attainment is easy, there are two $n^2/4$ squares (by which I mean two squares with area $n^2/4$ ), four $n^2/16$ squares, 8 $n^2/64$ squares, and so on. Summing this (and assuming $n = 2^m$ ) you get $$
\sum_{k=1}^{m = \log_2 n} 2^k \cdot n^2/4^k = \sum_{k=1}^m n^2 2^{-k} = n^2(1 - 1/n) = n^2 - n.
$$ But I don't see a clean way to argue that this is the best you can do.","['discrete-optimization', 'rectangles', 'combinatorics']"
3089174,Geometry with parallelogram,"My question is... I want to know your another solution. or I want to know if my solution is appropriate. and I’d appreciate some feedback on my work. Mentioned the word) Parallelogram ABCD, $\angle BAE = \angle CAE$ , $\overline{BE}+\overline{BC}=\overline{BD}$ , Find the $\overline{BC} : \overline{BD}$",['geometry']
3089177,Is it possible to define a function $f$ from positive real to positive real such that $f(f(x)) = {1 \over x}$,"Is it possible to define a function $f$ , from positive real to positive real such that $f(f(x)) = {1 \over x}$ ? The motivation comes from $1990$ IMO problem $4$ , which one step involves defining such a function over the positive rationals. In the countable rational space one can use the trick that divides numbers into two countable lists and map one to another using different functions. A comment in the video of that problem suggests a new problem: whether the function can be extended to positive real numbers? Basically we need to find a way to partition the reals into two sets and have two functions mapping one set to another set in a bijective way and the composition of the two functions in either order will give ${1 \over x}$ . My thought is this looks impossible but I cannot prove it.","['algebra-precalculus', 'functions']"
3089186,"If $H$ is a subgroup, and $xHx^{-1} \subsetneq H$, for all $x$ in $G$, then is H a normal subgroup?","Here $xHx^{-1} \subsetneq H$ means $xHx^{-1}$ as to be a proper subset of $H$ . From Gallian, Contemporary Abstract Algebra: Normal Subgroup: A subgroup $H$ of a group $G$ is called a normal subgroup of $G$ if $aH =
Ha$ for all $a$ in $G$ . We denote this by $H$ $\triangleleft$ $G$ ..... Normal Subgroup Test: A subgroup $H$ of $G$ is normal in $G$ if and only if $xHx^{-1} \subseteq H$ for all $x$ in $G$ . Proof If $H$ is normal in $G$ , then for any $x$ $\epsilon$ $G$ and $h
$ $\epsilon$ $H$ there is an $h^{'}$ in
  H such that $xh = h^{'}x$ . Thus, $xhx^{-1} = h^{'}$ , and therefore $xHx^{-1} \subseteq H$ . Conversely, if $xHx^{-1} \subseteq H$ for all $x$ , then, letting $x = a$ , we have $aHa^{-1} \subseteq H$ or $aH \subseteq Ha$ . On the other hand, letting $x = a^{-1}$ , we have $a^{-1}H(a^{-1})^{-1} = a^{-1}Ha \subseteq H$ or $Ha \subseteq aH$ . From above theorem of Normal subgroup test, if $1.$ $xHx^{-1} \subsetneq H$ or $2.$ $xHx^{-1}=H$ , $H$ will be a normal subgroup. But from the first definition of normal subgroups given above in the extract, $H$ seems to be normal only if $xH=Hx \implies xHx^{-1}=H$ . Then, if $H$ is a subgroup, and $xHx^{-1} \subsetneq H$ , for all $x$ in $G$ , is H a normal subgroup? If yes, is it not against the definition of normal subgroup?","['normal-subgroups', 'group-theory', 'abstract-algebra']"
3089259,"Determining the limit of $\sqrt{x^2+y^2} \ln(x^2+y^2)$ as $(x,y)$ approaches $(0,0)$","I want to evaluate the limit of $\sqrt{x^2+y^2}\ln(x^2+y^2)$ as $(x,y)$ approaches $(0,0)$ . Using polar coordinates, $x=r \cos \theta$ , $y= r \sin \theta$ , I obtain $\sqrt{x^2+y^2}\ln(x^2+y^2)=2r\ln(r)$ but I can not understand why this would be more simple than the original expression, or how I can proceed with this problem.","['limits', 'multivariable-calculus']"
3089279,Investigate the significance level $α = 0.01$.,"If you throw a coin in a vending machine, the coin is being weighed by the machine to determine its value. For statistical purposes, you decide to throw $4$ fifty-cent coins in this machine and let $\overline{X}_4$ be the estimator for the mean weight $μ$ of a fifty-cent coin. Assume that a single measurement has a normal distribution with expectation $μ$ and variance $σ^2 = 0.04$ . You find out that $\overline{x}_4 = 7.54$ . Investigate by using a statistical test whether $μ$ equals $7.5$ at significance level $α = 0.01$ . Solve: I assume $H_0:\mu=7.5$ and $H_1:\mu\neq7.5$ So it is a two-tailed problem and I have an $\alpha=0.005$ on the right and the same on the left. So from the table the critical values for these $\alpha$ are 2.57 and -2.57.
So I can compute $Z=\frac{7.48-7.5}{\frac{\sqrt{0.004}}{\sqrt{4}}}=-0.63$ that is inside the region where we don't reject $H_0$ so we don't reject it. Is it correct? Can someone please help me? Or I should use the p-value?","['statistics', 'probability']"
3089290,Calculate $\lim\limits_{n\rightarrow \infty }\sum_{k=1}^{n}\frac{6}{k(k+1)(k+3)}$,"$$\lim_{n\rightarrow \infty }\sum_{k=1}^{n}\frac{6}{k(k+1)(k+3)}$$ I tried to simplify the sum and I got $\frac{2}{k}-\frac{3}{k+1}+\frac{1}{k+3}$ but  I can't use this to simplify the terms.Also,I tried to amplify with $k+2$ and I got $$\frac{(k+3)-1}{k(k+1)(k+2)(k+3)}=\frac{(k+3)}{k(k+1)(k+2)(k+3)}-\frac{1}{k(k+1)(k+2)(k+3)}$$ but the terms also don't simplify.","['limits', 'calculus']"
3089328,Evaluate $\int_{0}^{\pi/2}\cos^{2n+1}(x)dx$,How can I compute this Integral for integer $n$ from $0$ to $\pi/2$ $$\int_{0}^{\pi/2}\cos^{2n+1}(x)dx?$$,"['trigonometry', 'contour-integration', 'definite-integrals', 'reduction-formula']"
3089363,When does this system of congruences hold?,"Let $\alpha,\beta,\gamma$ be quadratic irrationalities of the form $(n\pm\sqrt{n^2-4})/2$ for some integer $n$ (the $n$ is different for each of the three numbers). What are the solutions to the system of congruences $$\begin{cases}\alpha+\alpha^{-1}+\beta+\beta^{-1}\equiv\gamma+\gamma^{-1}\\\alpha^p+\alpha^{-p}+\beta^p+\beta^{-p}\equiv\gamma^p+\gamma^{-p}\end{cases}\pmod{p}?$$ First, note that the question is well-defined, and $\alpha+\alpha^{-1}$ and $\alpha^p+\alpha^{-p}$ are both integers. This is because $$\alpha=\frac{n+\sqrt{n^2-4}}{2}\implies\alpha^{-1}=2\cdot\frac{n-\sqrt{n^2-4}}{n^2-(n^2-4)}=\frac{n-\sqrt{n^2-4}}2,$$ so $\alpha,\alpha^{-1}$ are conjugate. Further, $\alpha^n+\alpha^{-n}=(\alpha+\alpha^{-1})(\alpha^{n-1}+\alpha^{-(n-1)})-(\alpha^{n-2}+\alpha^{-(n-2)})$ , and it is easily verified that $\alpha^2+\alpha^{-2}\in\mathbb Z$ . These two facts together imply the sequence $(\alpha^n+\alpha^{-n})_{n\in\mathbb N}\in\mathbb Z$ , and in particular, $\alpha^p+\alpha^{-p}\in\mathbb Z$ . The identical argument of course shows the same thing for $\beta$ and $\gamma$ , so even though we seem to have weird irrationalities in the congruences, all of the quantities involved are actually integers. So the congruences are just the normal relations defined on $\mathbb Z$ . Naturally, I tried to set $\alpha+\alpha^{-1}=n_1$ , $\beta+\beta^{-1}=n_2$ , $\gamma+\gamma^{-1}=n_3$ . Then the first congruence becomes a nice $n_1+n_2\equiv n_3$ mod $p$ , but unfortunately the second congruence has no nice representation in $n_1,n_2,n_3$ . So unless I'm missing something, this approach cannot work. Any thoughts or partial solutions would be greatly appreciated!","['number-theory', 'abstract-algebra', 'modular-arithmetic']"
3089365,Interchanging $\limsup$ and $\sup$,"Let $f_n: \mathcal{X} \to [0,1]$ be a sequence of functions and $\alpha \in (0,1)$ . I want to show that $$
\limsup_{n \to \infty} \sup_{x \in \mathcal{X}} f_n(x) \leq \alpha
$$ implies $$
\sup_{x \in \mathcal{X}} \limsup_{n \to \infty} f_n(x) \leq \alpha
$$ but my $\limsup$ 's are a little rusty. Any tips?",['limits']
3089391,Proving the injectivity of an entire function,"This is an exercise from a book I was reading: Suppose that an entire function $f:\mathbb{C} \to \mathbb {C}$ satisfies $$f(z)\in \mathbb{R} \iff z\in \mathbb{R} .$$ Prove that $f'$ does not vanish on $\mathbb{R}$ . The author gave a hint; he told us to use the following theorem: Theorem: Suppose that a function $f$ is holomorphic in an open set $U$ , that $z_0$ is a point of $U$ , and that $f$ takes the value $w_0$ with multiplicity $m$ at $z_0$ . Then there exist $s>0$ and a domain $D$ that is contained in $U$ with the properties that $D$ is contained in a closed disk centered at $z_0$ that is contained in $U$ , $f(D)=\Delta(w_0,s),$ $f(z)\neq w_0,\ f'(z)\neq 0$ for all $z\in D-\{z_0\}$ , for each $w$ in $\Delta ^{\ast}(w_0,s)$ , there are exactly $m$ points in $D$ that are mapped to $w$ by $f$ . (Here the symbol $\Delta(w_0,s)$ denotes the open disk of radius $s$ centered at $w_0$ , and $\Delta^{\ast}(w_0,s)=\Delta(w_0,s)-\{w_0\}$ .
  ) $\blacksquare$ Here's what I have tried. My attempt: Following the author's direction, I try to use the apply
  the following theorem to prove the problem by contradiction. Suppose that $f'(z_0)=0$ for some $z_0$ in $\mathbb{R}$ . Choose $D$ and $s$ as in the above theorem. Fix a point $w_1$ in $\Delta(w_0,s)\cap \mathbb{R}$ . According to the theorem, there are at
  least $2$ points in $D$ that are mapped to $w_1$ by $f$ . Now since $f$ is real on $\mathbb{R}$ , so is $f'$ . By choice of $D$ , $f'(z)\neq 0$ for $z\in D^{\ast}:=D-\{z_0\}$ . So $f'$ is either
  always positive or always negative on the set $A:=\{x\in\mathbb{R}\cap
> D|\ x< z_0\}$ . The same thing can be said about $f'$ on the set $B:=\{x\in\mathbb{R}\cap D|\ x> z_0\}$ . If $f'$ happened to be
  positive on both of these sets, then $f$ would be strictly increasing
  on $A\cup \{z_0\}\cup B$ , contrary to the result in the previous
  paragraph and our hypothesis that $f(z)$ is real iff $z$ is real.
  Hence $f'>0$ on $A$ and $f'<0$ on $B$ , or $f'<0$ on $A$ and $f'>0$ on $B$ . I feel like I am going in the wrong direction. But I cannot find any other direction. Can anyone help me? Thanks in advance!","['complex-analysis', 'entire-functions']"
3089395,How can $2\cos(x-\frac{\pi}2) = -2\sin(x-\frac{\pi}2)$,How can $2\cos(x-\dfrac{\pi}2) = -2\sin(x-\dfrac{\pi}2)$ I know that $\cos(-x) = \cos(x)$ and that $\cos(\dfrac{\pi}2-x) = \sin(x)$ From these two formulas I can get $1.$ $2\cos(x-\dfrac{\pi}2) = 2\cos(\dfrac{\pi}2-x)$ $2.$ $2\cos(\dfrac{\pi}2-x) = 2 \sin(x)$ $3.$ $ 2\sin(x) = -2\sin(-x)$ $4.$ How can I get $-2\sin(-x) = -2\sin(x-\dfrac{\pi}2)$ It was part of calculation of limit: $lim_{x->(\dfrac{\pi}{2})} \dfrac{1-e^{2cosx}}{2cosx} \dfrac{2cos(x-\dfrac{\pi}{2})}{sin(4(x-\dfrac{\pi}{x}))}$ and from there in the next step we assumed the identity I mentioned above,"['algebra-precalculus', 'trigonometry']"
3089411,Equilateral triangle that has its vertices on the centers of $3$ different chords of a circle,"$A$ is the center of the circle. The rest of the data are on the diagram. Using geogebra, it is easy to see that $\triangle EZH$ is equilateral, but I can't prove it. Any idea?","['euclidean-geometry', 'triangles', 'circles', 'geometry']"
3089423,Intermediate Value Theorem in $ \mathbb{R}^2$ and $ \mathbb{R}^3$,"Let $f:\mathbb{R}^n \rightarrow \mathbb{R} $ be a continuous function and let $a,b \in \mathbb{R}^n$ . Let $g:\mathbb{R} \rightarrow \mathbb{R} $ be defined as: $ g(t) = f(ta + (1-t)b)  $ . i) Prove that $g$ is continuous. My answer: I have done this using the fact that g is a composition of continuous functions and the fact that f is continuous ii) Prove that the following Intermediate Value Theorem is true for $f$ : If $d$ is a number between $f(a)$ and $f(b)$ then there exists a point $c \in \mathbb{R}^n $ such that $f(c)=d$ . My attempt at a proof: First we make the observation that $g(0)=f(b)$ and that $g(1)=f(a)$ . Since $g$ is a real and continuous function $\implies$ there exists a $c' \in[0,1]$ such that $g(c')=d$ since d is a number between $f(a)$ and $f(b)$ . Thus $f(c'a+(1-c')b)=d$ and were are done. iii) State and prove a similar Intermediate Value Theorem for continuous functions $h:R \rightarrow \mathbb{R}$ and $h':B \rightarrow \mathbb{R}$ where $R$ is an open or closes rectangle in $\mathbb{R}^2$ and B is an open or closed ball in $\mathbb{R}^3$ My thoughts: Since we have proven it for $\mathbb{R}^n$ is the arguement not just to say that both sets are subsets of $\mathbb{R}^n$ ? I would like to know if the answer to iii) is that simple and also if my proof  in ii) is correct? Thanks in advance!","['continuity', 'functions', 'real-analysis']"
3089426,"If $G \subset GL_n(\mathbb{C})$ has finitely many conjugacy classes for all element, is it finite?","Let be $G \subset GL_n(\mathbb{C})$ such that there is some $r \in \mathbb{N}^{*}$ and $g_1, \ldots, g_r \in G$ so that for all $g \in G$ , $g$ is conjugated to some $g_i, i \in [[1, r]]$ in $G$ . Is $G$ finite? I feel like that yes, I tried to poke the stabilizer, but I have no reason to think that it'd be finite.","['group-theory', 'representation-theory']"
3089456,Calculating only the needed part of Q of thin QR decomposition,"A rectangular, $A \in \mathbb{R}^{m \times n}$ matrix, where $m \ge n$ , can be decomposed (QR factorization): $$A = \begin{bmatrix}Q_1 | Q_2 \end{bmatrix}\begin{bmatrix}R\\0\end{bmatrix}$$ where $Q_1$ and $Q_2$ has orthonormal columns, and $R$ is upper triangular. I'm implementing a routine (based on Householder reflections) which calculates $Q_1$ and $R$ (so called thin/reduced QR decomposition). My question is: is it possible to calculate $Q_1$ without calculating $Q_2$ ? The problem is that a Householder matrix is $\mathbb{R}^{m \times m}$ , and $Q_1 \in \mathbb{R}^{m \times n}$ , so I cannot multiply them. My routine currently calculates $Q=[Q_1|Q_2]$ , and then throws away the $Q_2$ part.","['matrices', 'linear-algebra', 'matrix-decomposition']"
3089462,"In a Banach space, absolute convergence of series implies convergence","Proof/Hint Request : I came upon a shortly stated Lemma while revising for my Functional Analysis semester exam. It follows as : Lemma : The absolute convergence of $\sum_{n=1}^{+ \infty}x_n$ implies the converge of $\sum_{n=1}^{+\infty} x_n$ , where $x_n$ is a sequence in a Banach Space. Now, I know that the absolute convergence of the noted sequence means that $\sum_{n=1}^{+ \infty} \|x_n\|$ is convergent, but I cannot see how to find a way to prove the lemma. Any hints or elaborations will be appreciated.","['real-analysis', 'hilbert-spaces', 'functional-analysis', 'sequences-and-series', 'convergence-divergence']"
3089508,Characterising minors of diagonal matrices,"Let $k,d$ be positive integers, $1<k<d$ . Let $\lambda_I=\lambda_{i_1,\ldots,i_k}$ be real numbers, indexed by multi-indices $I=(i_1,\ldots,i_k)$ , where $1\le i_1<\ldots<i_k \le d$ . Are there necessary and sufficient conditions on $\lambda_{i_1,\ldots,i_k}$ which are equivalent to the existence of $\sigma_1,\ldots,\sigma_d \in \mathbb{R}$ such that $\lambda_{i_1,\ldots,i_k}=\sigma_{i_1}\cdot \ldots\cdot\sigma_{i_k}$ holds for every multi-index $I$ ? In other words, I am asking whether we can characterise which sequences of real numbers can arise as the $k$ -minors of diagonal $d \times d$ matrices? I am interested mainly in the case where all the $\lambda_{i_1,\ldots,i_k}$ are non-zero. I have heard that the general problem of recognizing $k$ -minors of arbitrary square matrices is open, but I am hoping that for diagonal matrices, the situation maybe better understood. I guess this should be easier by starting over $\mathbb{C}$ . What is known about that case? Commnet: If I understand correctly, the Plucker relations only describe the minors of top-degree of a non-square matrix. Here I am talking about the minors of degree $k$ , when $1<k<d$ , i.e. non-top minors of a square matrix .","['determinant', 'algebraic-geometry', 'polynomials', 'real-algebraic-geometry', 'exterior-algebra']"
3089529,Centroid within non-convex 2d polygon,"The centroid of an object is defined as the arithmetic mean of all points of the object. For non-convex objects, the centroid is often not a part of the object itself: Is there a definition of a centroid-like point which always lies within the object? A definition that tackles 2 dimensional polygon objects is sufficient. I could think of something like the following, however, I would prefer a well-known definition if there is one: Let $s_p(a, b)$ be the shortest path from $a \in p$ to $b \in p$ such that all points of the path are within $p$ . Let $S_p := \{s_p(a, b) | a, b \in p\}$ . Let $d$ be the longest path in $S_p$ . The mid point of $d$ is a centroid-like point and it always lies within $p$ .","['centroid', 'geometry', 'polygons']"
3089539,"Solve recursion $a_n=a_{n-1}-6\cdot3^{n-1}$ for $n>0, a_0=0$","$a_n=a_{n-1}-6\cdot3^{n-1}$ for $n>0,  a_0=0$ So I calculate first terms $a_0=0$ $a_1=-6$ $a_2=-24$ $a_3=-78$ I don't see any relation so $a_n=a_{n-1}-6\cdot3^{n-1}$ $a_{n-1}=a_{n-2}-6\cdot 3^{n-2}$ . . . $a_2=a_1-6\cdot3^{1}$ $a_1=a_0-6\cdot 3^{0}$ Not sure what to do next, Wolfram solves it in this way: $a_n=-3\cdot(3^{n}-1)$ How do I get to this point?",['discrete-mathematics']
3089593,Advanced combinatorics question: rows with open en closed brackets,"Consider a row with open and closed brackets. A row is correct if for each open bracket there is a unique closed bracket further in the row. In other words: if this row of brackets can be seen as a correct mathematical expression from which all numbers and operation symbols are omitted. Or again in other words: for each point in the row, the amount of open brackets for this point has to be at least the amount of closed brackets for this point. Show that the number of correct rows with $n$ pairs of brackets is given by $\frac1{n+1} \binom{2n}{n}$ . Remark: Following statements can (you don't have to use them) give some inspiration (you'll need more arguments and the given statements are not written in the correct order!): If a row of brackets does not satisfy the conditions (bad row), then there is a point $\dots$ on which the number of closed brackets exceeds the number of the open brackets for the first time. An alternative row is a row with $n-1$ open brackets and $n+1$ closed brackets. It's clear that $g \circ f$ is the identity map on the bad rows and that $f \circ g$ is the identity map on the alternative rows. This implies that $f$ and $g$ are bijections. $$\binom{2n}{n} - \binom{2n}{n-1} = \dots = \frac1{n+1} \binom{2n}{n}$$ ""... change all open brackets on positions $2k+2, \dots, 2n$ in this alternative row $r$ into closed brackets ..."" I have no idea how to start with this proof. Any clues? Thanks a lot!",['combinatorics']
3089607,Probability that sum of integer reciprocals is larger than a fixed number.,"Suppose $n$ numbers are drawn independently from the list of $m$ integers $\{1,2,3,\ldots ,m\}$ uniformly at random. Denote these $n$ picks as $x_1,x_2,\ldots x_n$ . Note that $n\geq m$ is possible. Fix a positive integer $C$ . I am trying to determine the probability that $$\sum_{i = 1}^{n} \frac{1}{x_n}\geq C.$$ However I am not really sure where to start as I have not done much work with probability before. Is there some way to get such a probability?","['discrete-mathematics', 'probability']"
3089619,"Let $A$ be a chain. $B,C$ subsets of $A$ s.t $A= B\cup C$. If $B$ and $C$ are well-ordered then A is well-ordered.","My attempt: Assume that $B$ and $C$ are well-ordered and A is not.
Since A is not well-ordered it contains an infinite descending sequence $\{a_i\}_{i=0}^\infty$ . If the sequence has a limit $l$ $\in$ $A$ then $l$ is in B or C. With no loss of generality assume $l \in B$ , then we can find $N \in \mathbb{N}$ such that $\{a_i\}_{i=N}^\infty$ $\subseteq B$ . Then $B$ contains an infinite descending sequence hence it is not well ordered and we have a contradiction. Question: How can I treat the case $\{a_i\}_{i=0}^\infty$ is divergent?","['elementary-set-theory', 'well-orders']"
3089625,are geodesic shortest path or quickest path?,"I'm a bit confused with geodesics : are they the shortest path (in distance) or the quickest path (in time). For example, Let take a triangle ABC. I'm using a car. I'm in $A$ and I have to go in $B$ . The path $AB$ is 2km long, but I can go at 10 km/h only, where as the path that path through C has 4 km length, but it's a free way and I can go at 100 km/h. Clearly, the path through C is quicker, but the path AB is shorter. What is going to be the Geodesic ? The path through $C$ or the path $AB$ ?",['differential-geometry']
3089627,"Analogous ""Dark Sector"" Trigonometric (and Hyperbolic) Functions","Existing Definitions: $$\zeta(n)=\sum_{k=1}^\infty \frac{ 1 }{k^n}$$ $$\lambda(n)=\sum_{k=1}^\infty \frac{ 1 }{(2k-1)^n}=\frac{\left(2^n-1\right)}{2^n}\zeta (n)$$ $$\eta(n)=\sum_{k=1}^\infty \frac{(-1)^{k-1}}{k^n}=\left(1 -2^{1-n} \right) \zeta (n)$$ $$\beta(n)=\sum_{k=1}^\infty \frac{(-1)^{k-1}}{(2k-1)^n}$$ The existing well known trigonometric functions $\csc(x)$ , $\sec(x)$ , $\tan(x)$ and $\cot(x)$ in infinite series form are: $$\csc(x)=\frac{1}{x}+2 \sum _{k=1}^{\infty } \frac{\eta(2 k)  }{\pi ^{2 k}}\;x^{2 k-1}$$ $$\sec(x)=2\sum _{k=1}^{\infty } \frac{\ 2^{2 k-1} \beta(2 k-1)  }{\pi ^{2 k-1}}\,x^{2 k-2}$$ $$\tan(x)=2 \sum _{k=1}^{\infty } \frac{2^{2 k} \lambda(2 k)  }{\pi ^{2 k}}\,x^{2 k-1}$$ $$\cot(x)=\frac{1}{x}-2 \sum _{k=1}^{\infty } \frac{  \zeta (2 k)}{\pi ^{2 k}}\,x^{2 k-1}$$ I am now going to define some analogous new definitions, using the odd Zeta constants and the even Beta constants, and postfix them with an ""i"": $$\text{csci}(x) =2 \sum _{k=1}^{\infty } \frac{\eta(2 k+1)  }{\pi ^{2 k+1}}\,x^{2 k}-\frac{1}{x}+\frac{2 \log (2)}{\pi }$$ $$\text{seci}(x)=2\sum _{k=1}^{\infty } \frac{\ 2^{2 k}\; \beta(2 k)  }{\pi ^{2 k}}\,x^{2 k-1}$$ $$\text{tani}(x)=2 \sum _{k=1}^{\infty } \frac{2^{2 k+1} \;\lambda(2 k+1) }{\pi ^{2 k+1}}\,x^{2 k}+\frac{2 \log (2)}{\pi }$$ $$\text{coti}(x)=-2 \sum _{k=1}^{\infty } \frac{ \zeta (2 k+1)}{\pi ^{2 k+1}}\,x^{2 k}-\frac{1}{x}+\frac{2 \log (2)}{\pi }$$ You could try the same analogy with ""dark sector"" hyperbolic functions. e.g. $$\text{sechi}(x)=2\sum _{k=1}^{\infty } \frac{(-1)^{k-1} 2^{2 k}\; \beta(2 k)  }{\pi ^{2 k}}\,x^{2 k-1}$$ It is immediately apparent that there are certain similarities between normal trigonometry and ""dark sector"" trigonometry For example $\text{seci}(x)=\text{csci}(x+\frac{\pi}{2})$ , and $\text{csci}(x)=\text{coti}(x/2)-\text{coti}(x)$ . But also differences for example $\text{tani}(x)$ is not equal to the inverse of $\text{coti}(x)$ . However both the inverses appear to lead to the same new function, that differs only by an inversion and a phase shift of $\pi/2$ . Graph for $1/\text{tani}(x)$ Graph for $1/\text{coti}(x)$ Similar thing happens with the inverse of $1/\text{csci}(x)$ and $1/\text{seci}(x)$ to give $\text{sini}(x)$ and $\text{cosi}(x)$ Graph for $\text{sini}(x)$ Graph for $\text{cosi}(x)$ Examples of combining ""dark sector"" functions with normal trigonometric functions look quite interesting: Graph for $\text{cosi}(x)+\cos(x)$ Graph for $\text{cosi}(x)-\cos(x)$ I've just sketched this structure using Mathematica before I waste too much time on it. There may be a better way of defining the four starting analogous functions: $\text{csci}(x)$ , $\text{seci}(x)$ , $\text{tani}(x)$ and $\text{coti}(x)$ . Does anyone know of attempts to develop what I call here ""dark sector"" trig or hyperbolic functions? Does anyone recognise any of these functions and where they might have an application?","['trigonometry', 'sequences-and-series']"
3089647,Does a change of variable affect the function,"If I have a function $f: \mathbb{R}^2 \to \mathbb{R}$ then I can get $f$ in polar coordinates by doing : $f \circ g(r, \theta)$ where $g(r, \theta) = (r \cos \theta, r \sin \theta)$ . Now my question is the following : Does the shape of the graph of $f$ in the cartesian plane will look exactly the same as the shape of $f \circ g(r, \theta)$ drawn in the polar coordinates plane ? I am saking this question because for example if I take a function $h : \mathbb{R} \to \mathbb{R}$ then the shape of $h(x)$ doesn't look like the sape of $h(2x)$ . So for me it's not clear that if I transform $f$ to get the function in polar coordinates then in the cartesian plane we calculate : $f \circ g(\sqrt{x^2+y^2}, Arctan(y/x))$ or we calculate $f \circ g (x, y)$ . Because in the second interpretation the functions aren't the same. For example $h(x)$ and $h(2x)$ aren't the same functions. Thank you !","['multivariable-calculus', 'calculus', 'polar-coordinates', 'real-analysis']"
3089696,Flip $n$ coins on a circle. Assume a coin has been chosen from among those whose neighbors are both heads. What's the probability it is heads?,"This is a generalization of the problem below (first appeared here ) I am particularly curious to know if there is a closed-form formula to calculate the probability for any $n$ and any probability of heads $p$ . note: One doesn't need to calculate the probability to show that it is not 50-50.  If $n=3$ , the exact probability can be calculated with few computational steps. For larger $n$ , relatively simple algorithms can be used to calculate the probability; some are more efficient than others.","['puzzle', 'conditional-probability', 'paradoxes', 'combinatorics', 'probability']"
3089721,Prove f has a fixed point if it is increasing but not necessarily continuous,"Suppose $f : [0, 1] \rightarrow [0, 1]$ is increasing (but not necessarily continuous).
Show that there is a number $x \in [0, 1]$ with $f(x) = x$ .
(Hint: You can’t apply the IVT directly because the function need not be
continuous. Draw a picture and try to copy the proof of the Intermediate
Value Theorem.) I don't understand how copying the IVT and connecting it to my graph would help me prove this since the IVT has nothing to do with increasing functions(or am I wrong about this?)","['functional-analysis', 'analysis', 'real-analysis']"
3089782,I'm stuck integrating $\int \sqrt{x^2-a^2} dx$ using trigonometric substitution,"When I'm trying to integrate $\int \sqrt{x^2-a^2} dx$ using trigonometric substitution, I get stuck. Here's the complete solution so far: $$
x(\theta)=a\sec{\theta}\\
x'(\theta)=a\tan{\theta}\sec{\theta}\\
\theta=\sec^{-1}\left(\frac{x}{a}\right)\implies \theta\in\left[0,\frac{\pi}{2}\right)\cup\left(\frac{\pi}{2},\pi\right]\\
$$ $$
\begin{align}
\int \sqrt{x^2-a^2} dx
&=\int \sqrt{[x(\theta)]^2-a^2}x'(\theta)d\theta\\
&=\int \sqrt{a^2\sec^2{\theta}-a^2}a\tan{\theta}\sec{\theta}d\theta\\
&=a^2\int \sqrt{\tan^2{\theta}}\tan{\theta}\sec{\theta}d\theta\\
&=a^2\int |\tan{\theta}|\tan{\theta}\sec{\theta}d\theta
\end{align}
$$ I take it that at this point I end up with two integrals one for when $\tan{\theta}>0$ (on $\left[0,\frac{\pi}{2}\right)$ ) and another one for when $\tan{\theta}<0$ (on $\left(\frac{\pi}{2},\pi\right]$ ): $$
\theta\in\left[0,\frac{\pi}{2}\right): \int \sqrt{x^2-a^2} dx = a^2\int \tan^2{\theta}\sec{\theta}d\theta\\
\theta\in\left(\frac{\pi}{2},\pi\right]: \int \sqrt{x^2-a^2} dx = a^2\int (-\tan{\theta}\tan{\theta}\sec{\theta})d\theta = -a^2\int \tan^2{\theta}\sec{\theta}d\theta
$$ But that doesn't seem to be right because the integral of a function has one unique answer, as far as I know. What am I doing wrong?","['integration', 'trigonometric-integrals']"
3089804,Find the number(s) $k$ such that $k\mathbb{Z} = \mathbb{Z}$,"I am just starting out with Discrete Math and there is a question in my book that is Find the number(s) $k$ such that $k \mathbb{Z} = \mathbb{Z}$ . The answer is -1 and 1. I understand why it is 1 because any number multiplied by 1 is itself, what I don't understand is why the other answer is -1. For example, if $k = -1$ then $(-1)\mathbb{Z}$ would be all the values of $\mathbb{Z}$ , but if that is the case, then why can't $k$ could also equal 2 or any other integer?","['integers', 'discrete-mathematics']"
3089867,Comparison of five books on Measure Theoretic Probability.,"I am reading measure theoretic probability for the first time. I wish to know how the following books compare with each other. My final goal is to understand many research papers in electrical engineering which use rigorous probability (like spectral shaping of quantization noise etc) to be able to understand Floquet theory which is used by circuit simulators to model phase noise of circuits. Specifically, I need to understand stochastic differential equations to be able to understand the nuts and bolts of various machine learning models ie the data science part of machine learning The five books I have in mind are the following: Athanasios Papoulis  and S. Unnikrishna Pillai, ""Probability, Random Variables and Stochastic Processes"" Grimmett & Stirzaker, ""Probability and Random Processes"" Sidney I. Resnick, ""A Probability Path"" Patrick Billingsley, ""Probability and Measure"" David Williams, ""Probability with Martingales"" I have a hunch that the above lists it in increasing order of detail and difficulty. Nevertheless, given that my goal is as listed above, please let me know as to what each book has to offer.","['measure-theory', 'ordinary-differential-equations', 'reference-request', 'probability-theory', 'stochastic-calculus']"
3089875,Calculate the Laurent Series for : $(8z+6+8i)/(2z^2-3z-4iz)$,"I have to find the Laurent-Series with $0<|z|<5/2$ and $z_0=0$ for: $$\frac{8z+6+8i}{2z^2-3z-4iz}$$ I already did this: $$
\frac{8z+6+8i}{2z^2-3z-4iz} = \frac{A}{2\cdot(z-0)}+ \frac{B}{2\cdot(z-1.5-2i)}\\
A=-2 \text{ and } B=6 \\
\frac{8z+6+8i}{2z^2-3z-4iz} = -1\cdot\frac{1}{z} + 3\cdot\frac{1}{z-1.5-2i}
$$ I hope this is correct so far. 
My book says the formula for a Laurent Series is : $$\sum_{k=1}^{\infty} a_k\cdot\frac{1}{[z-z_0]^k} + \sum_{k=0}^{\infty}b_k\cdot[z-z_0]^k=\sum_{k=-\infty}^{\infty} c_{k}\cdot[z-z_{0}]^{k}$$ But I have no Idea what i have to do now. I hope someone can help me. Thank you!","['complex-analysis', 'taylor-expansion', 'laurent-series']"
3089880,Minimal generating set,"I am having a difficult time wrapping my head around this idea of minimal generating set. The book gives a definition for it and i've tried looking it up but the definitions are obviously similar. Can someone break it down to simpler terms and provide a basic example? Here is my books def. Generating Set : If $G$ is a group and $S$ is a subset of $G$ such that $G=\langle S\rangle$ , then $S$ is called a generating set of $G$ . Minimal Generating Set : A generating set $S$ for $G$ is a minimal generating set if $S\setminus\{x\}$ is no longer a generating set for $G$ for all $x\in S$ .","['group-theory', 'abstract-algebra']"
3089886,My simulation of the Central Limit Theorem does not converge to correct value,"The Lindeberg–Lévy CLT states: Assume $\\{ X_1, X_2, \dots \\}$ is a sequence of i.i.d. random variables with $\mathbb{E}[X_i] = \mu$ and $\text{Var}[X_i] = \sigma^2 < \infty$ . And let $S_n = \frac{X_1 + X_2 + \dots + X_n}{n}$ . Then as $n$ approaches infinity, the random variables $\sqrt{n}(S_n − \mu)$ converge in distribution to a normal $\mathcal{N}(0, \sigma^2)$ . I have written a small numerical simulation to check my understanding, and it does not do what I hypothesized. Each red dot is the estimated $\sigma^2$ for 2000 samples of $\sqrt{n}(S_n - \mu)$ from the uniform distribution. The blue line is the true $\sigma^2$ for the uniform distribution. I would expect that as $n$ increases, the red dots converge to towards the blue line. But that is not what happens. What's wrong with my understanding of the CLT? Here is the code that generated the figure. import numpy as np
import matplotlib.pyplot as plt
from   scipy.stats import norm

a = 0
b = 1
mu_lim  = 1/2.  * (a + b)
var_lim = 1/12. * (b - a)**2
reps = 2000
fig, axes  = plt.subplots(1)
variances = []
x = range(1, 1000, 10)

for n in x:
    rvs = []
    for _ in range(reps):
        Sn = np.random.uniform(a, b, n).mean()
        rvs.append(np.sqrt(n) * (Sn - mu_lim))
    _, std = norm.fit(rvs)
    variances.append(std**2)

plt.plot(x, [var_lim for _ in x])
plt.scatter(x, variances)
plt.show()","['central-limit-theorem', 'probability']"
3089905,A discrete normal subgroup is contained in the center,Let $G$ be a connected Lie group and $N$ a discrete normal subgroup of $G$ . Then $N$ is contained in the center $Z(G)$ . I've fooled around with this for a little bit and I can't figure out how to use the hypothesis that $N$ is discrete. I think maybe it uses some fact that I do not know.,"['group-theory', 'abstract-algebra', 'lie-groups']"
3089943,Proving the No Retraction Theorem,"I try to understand a proof of the No Retraction Theorem which states that for any compact smooth manifold $M$ with boundary $\partial M \neq \emptyset$ , there is no smooth map $$
f : M \to \partial M , \ \ \ f|_{\partial M } = id.
$$ For the proof we suppose that such a map exists. Then by Sard's theorem we find a regular value $r \in \partial M$ and the preimage of $r$ under $f$ is a 1-dimensional manifold. The author now continues to say that the boundary of this preimage has to be a subset of $\partial M$ . My questions is: Why do we know that?","['general-topology', 'functions', 'differential-topology']"
3089957,Periodic solutions of a planar ODE,"Linearizing the equation of the two body problem at a circular solution I came accross the following planar second order system of differential equations $$
\begin{cases}
2\frac{1}{\omega^2} \ddot{u}=3u\cos2\omega t+3v\sin2\omega t+u\\
2\frac{1}{\omega^2}\ddot{v}=3u\sin2\omega t-3v\cos2\omega t+v
\end{cases}
$$ It is easy to see that $(u,v)=(-\sin\omega t,\cos\omega t)$ is a $\frac{2\pi}{\omega}$ -periodic solution. I'm wondering if there are other independent ones.
 Do you have any suggestion to find them?",['ordinary-differential-equations']
3089958,A question about Frattini subgroup of specific form,"Suppose $p$ is a prime number and $G$ is a finite group, such that $\Phi(G) = C_p \times C_p$ , where $\Phi$ denotes the Frattini subgroup. Is it always true, that $p^4$ divides $|G|$ ? This statement can be easily proved for $p$ -groups by seeing that no group of order $p$ , $p^2$ or $p^3$ (there is a full classification of such groups) possesses a Frattini subgroup of the aforementioned form. Knowing that any finite nilpotent group is a direct product of $p$ -groups and that the Frattini subgroup of a finite direct product of finite groups is the direct product of their Frattini subgroups, we can reach the same conclusion about finite nilpotent groups. However, I do not know, how to prove this statement in general. Any help will be appreciated.","['finite-groups', 'nilpotent-groups', 'abstract-algebra', 'group-theory', 'frattini-subgroup']"
3089978,$f(x)$ from $f(g(x))$,"Is it always possible to find $f(x)$ if the composite function $h(x) = f(g(x))$ and $g(x)$ are given? In other words, can there be any cases where, for given $h(x)$ , we can not express it in an explicit function of $g(x)$ ?","['functions', 'special-functions', 'function-and-relation-composition']"
3090008,Is it possible get an algebraic expression for $\sin 1°$ that does not contain roots of negative values?,"Is it possible get an algebraic expression for $\sin 1°$ that does not contain roots of negative values, so that it can be evaluated entirely using only real numbers? For example, this paper gives some algebraic expressions for it, but they all involve complex numbers.","['real-numbers', 'algebraic-number-theory', 'trigonometry']"
3090048,Evaluate $\sum_ \limits{n=1}^{\infty} \frac{n}{1 \cdot 3 \cdot 5 \cdots (2n+1) } $,$$\sum_ \limits{n=1}^{\infty} \frac{n}{1 \cdot 3 \cdot 5 \cdots (2n+1) } $$ $$1 \cdot 3 \cdot 5 \cdots (2n+1) = \frac{1 \cdot 2 \cdot 3 \cdots (2n+2)}{2 \cdot 4 \cdot 6 \cdots (2n+2)} = \frac{(2n+2)!}{2^{n+1} \cdot (n+1)!} $$ But the follow up gives me $\infty$ . How to approach this type of exercises? The result should be $1/2$,"['limits', 'calculus', 'sequences-and-series']"
3090118,From infinite dimensional function space to n-dimensional real space,"I am an engineering student who works in the field of optimal control. Problems in this field are typically framed in infinite dimensional Sobolev space, $W^{k,p}(\Omega)$ , as: \begin{equation} \label{optimalControl}
\begin{aligned}
&J[u(t)] = \underset{u(t)}{\mathrm{minimize}} \int_{t_{0}}^{t_{f}} L(t,x(t),u(t))\hspace{0.1cm} dt \\
&s.t. \hspace{0.8cm} \dot{x}(t) = f(t,x(t),u(t)) \\
& \hspace{1.5cm}x(0) = x_{start} \\
& \hspace{1.5cm}x(t_f) = free
\end{aligned}
\end{equation} where, $\hspace{4.6cm} x(t)\in C^1[t_o,t_f]$ is state vector, $\hspace{4.6cm}u(t)\in C^1[t_o,t_f]$ is control vector, $\hspace{4.6cm}f[t,x(t),u(t)]$ is system dynamics, $\hspace{4.6cm}L[t,x(t),u(t)]$ is Lagrangian, and $\hspace{4.6cm}J[u(t)]$ is a scalar cost function One of the methods to solve such a problem is to discretize it directly and recast it as a nonlinear program (NLP) in finite dimensional real space, $\mathbb{R}^{n}$ . Here is my question: What mathematical justification do we have to solve an infinite dimensional problem by converting it to a finite dimensional problem and expect to get a correct solution? In addition to looking for some relevant theorems that allow us to do that, it will be very helpful if somebody can also help me understand this intuitively. Note : After digging a bit myself, I found a theorem which may be relevant here and is called Lax Equivalence Theorem. Is this it?","['optimal-control', 'numerical-methods', 'nonlinear-optimization', 'functional-analysis']"
3090166,Why can't I sub $a=0$ into this expression?,"I was doing a maths problem from the Internet which involved the function $$J(a)=\int_{0}^{\infty}\frac{\cos(ax)}{1+x^2}\mathrm{d}x.$$ The aim of the problem was to use the relation $J''(a)-J(a)=0$ (differentiation with respect to $a$ ) to evaluate the following integral: $$I=\int_{-\infty}^{\infty}\frac{\cos(x)}{1+x^2}\mathrm{d}x.$$ However, part of the problem involved finding the value of $J'(0)$ to solve the above second order differential equation to find $J(a)$ . The argument is as follows: $$\begin{align}J'(a) &=\int_{0}^{\infty}\frac{-x\sin(ax)}{1+x^2}\mathrm{d}x \\ &= \int_{0}^{\infty}\frac{-(x^2+1-1)\sin(ax)}{x(1+x^2)} \mathrm{d}x \\ &= -\int_{0}^{\infty}\frac{\sin (ax)}{x} \mathrm{d}x+\int_{0}^{\infty}\frac{\sin(ax)}{x(1+x^2)}\mathrm{d}x \end{align}.$$ By letting $a \rightarrow 0$ from the positive side, $J'(0)=-\pi/2$ using the standard result for $$\int_{0}^{\infty}\left(\frac{\sin(ax)}{x}\right)\mathrm{d}x = \pi/2, \text{ 
 for } a>0 $$ Then we can solve that differential equation, find that $$J(a)=(\pi/2)e^{-a}$$ for $a>0$ and hence find $I$ . My question is, why is it necessary to find $J'(0)$ in this way? It isn't clear to me why we can't just substitute $a=0$ into the first expression for $J'(a)$ and conclude $J'(0)=0$ . I only have an informal understanding of limits, please keep that in mind.","['integration', 'limits', 'calculus']"
3090183,Abuse of notation in the chain rule,"I have a function: $f: \mathbb{R}^p \to \mathbb{R}^n$ . Now let's define the functions $x_i : \mathbb{R}^p \to \mathbb{R}$ , and hence we can define the function $\phi : (u_1,..., u_p) \to (x_1(u_1,...,u_p), ..., x_p(u_1,...,u_p))$ Then my book is defining the partial derivative of $f \circ \phi$ at $u_j$ as $$\frac{\partial f\circ \phi}{\partial u_j} = \sum_{i = 1}^p \frac{\partial x_i}{\partial u_j} \frac{\partial f}{\partial x_i}$$ But it doesn't mean anything to take the partial derivative at a function!?  So $\frac{\partial f}{\partial x_i}$ doesn't make sense, since $x_i$ is a function; I mean we can't calculate the partial derivative at a function.
For example it doesn't mean anything to say $\frac{\partial (x^2+y^2)}{\partial xy}$ , right? So I guess this is an abuse of notation and that the right formula is $$\frac{\partial f\circ \phi}{\partial u_j} = \sum_{i = 1}^p \frac{\partial x_i}{\partial u_j} \frac{\partial f}{\partial a_i}$$ where the $a_i$ are independent variables and not functions! Am I correct? Thank you!","['real-analysis', 'notation', 'multivariable-calculus', 'calculus', 'chain-rule']"
3090188,Explanation of differing solutions for an exact ODE,"I was solving the following ODE $$ y \cos(xy) + x \cos(xy) y' = 0$$ My initial intuition to solving it is to observe that it can be factored as: $$ \cos(xy) (y + xy') = 0$$ So over $x,y$ that don't satisfy $\cos(xy) = 0$ we have $$ y  + xy' = 0$$ And this is an exact eqation which has solutions of the form $$ xy = C$$ Now the video series that the ODE originated from takes a different approach. It notices that $$\frac{\partial}{\partial y} [y \cos(xy)] = \cos(xy)- xy \sin(xy) , \frac{\partial}{\partial x} [x\cos(xy)] = \cos(xy) - xy \sin(xy)  $$ So therefore the solutions are of the form $ \sin(xy) = C$ clearly my approach doesn't agree with the classical approach, but my only difference was dividing out  a term which is 0 in a set non-dense in $\mathbb{R}^2$ so I don't understand why my answer differs so much. And my intuition that $xy$ should be constant for all points where $\cos(xy) \ne 0$ can't possibly be true so I feel i'm deeply missing some intuition here.","['ordinary-differential-equations', 'partial-differential-equations']"
3090206,A unique solution for $y'=\cos\left(y\right)$,"I've considered the non-linear problem $$ \displaystyle \left(\star\right) \ \ \ \ \begin{cases}
\displaystyle y'(x)=\cos\left(y(x)\right)\\
y(0)=\alpha, \ \alpha \in \mathbb{R}
\end{cases}$$ I want to prove that it admits a unique solution on $\mathbb{R}$ . I've used the following lemma : Grönwall Lemma : If $y$ satisfies for all $t \in \left[0,+\infty\right[$ the inequality $$
y'\left(t\right) \leq \beta\left(t\right)y\left(t\right)
$$ then for all $t \in \left[0,+\infty\right[$ $$
y\left(t\right) \leq y\left(0\right) \text{exp}\left(\int_{0}^{t}\beta\left(s\right)\text{d}s\right)
$$ Then let $y_1$ and $y_2$ be two solutions of $(\star)$ then we have $$
(y_1-y_2)'=\cos\left(y_1\left(t\right)\right)-\cos\left(y_2\left(t\right)\right)=-2\sin\left(\frac{y_1+y_2}{2}\right)\sin\left(\frac{y_1-y_2}{2}\right)
$$ So letting $Y=(y_1-y_2)/2$ we have $$
Y' \leq \sin\left(\frac{y_1\left(t\right)+y_2\left(t\right)}{2}\right)\sin\left(-Y\right)
$$ Using that $Y\left(0\right)=0$ , we have $$
y_1(t)-y_2(t) \leq 0
$$ I can then use the same argument with $Z=y_2-y_1$ to obtain $y_2(t)-y_1(t) \leq 0$ to have $$
y_1=y_2
$$ Can somebody tell me if it's true ( or correct me to fill the proof )? My problem is the majoration of $Y'$ because I dont know the sign of the sin ( can't be maxed by $1$ then ), and it depends on $y_1$ and $y_2$ .",['ordinary-differential-equations']
3090244,Norm and Weak Topologies agree?,"so my professor mentioned that when a normed space is finite dimensional the norm and weak topologies agree. To show the topologies agree it should be enough to show that they have the same convergent nets. I can see how if a net $x_\alpha\rightarrow x$ in the norm topology then it converges in the weak topology. Namely, for arbitrary $f\in X^*$ we know by continuity that $f(x_\alpha)\rightarrow f(x)$ , which means $x_\alpha\rightharpoonup x$ . However, I can't see the other way. Would anyone have some intuition as to why convergence in the weak topology implies convergence in the norm topology? I'm assuming that this direction is where the finite dimension of our space comes in to play. Thanks in advanced.","['general-topology', 'functional-analysis', 'weak-convergence']"
3090257,Variance of the sum of uncorrelated variables,"In using the Bienaymé formula to find the variance of means, I do not understand why $$\operatorname{Var}\!\left(\frac{1}{n}\sum_{i=1}^{n}{X_i}\right)=\frac{1}{n^2}\sum_{i=1}^n{\operatorname{Var}(X_i)}$$ I assume it is a matter of simple algebraic manipulation, but I do not understand it. Could someone please explain this property?","['statistics', 'variance', 'probability-theory']"
3090260,"Determining $B^{\mathrm{o}},\partial B,B'$ for $B=b_n=\{-1-\frac{6n}{n^2-10},n\in \mathbb{N}\cup \{0\} \}$","As title suggests, I have $B=b_n=\{-1-\frac{6n}{n^2-10},n\in \mathbb{N}\cup \{0\} \}$ and have to determine $B^{\mathrm{o}},\partial B,B'$ (i.e. sets of interior,boundary and accumulation points,respectively). To start with, if we take function assosicated to set it is obvious that we have a pair of vertical asymptotes at $x=\sqrt 10$ . $b(x)\to -\infty$ for $x\to {\sqrt 10}^+$ and $b(x)\to +\infty$ for $x\to{\sqrt 10}^-$ .Taking derivative $$b'(x)=\frac{6(x^2+10)}{(x^2-10)^2}\gt0$$ We find out that function is monotone increasing. $3\lt\sqrt 10\lt4$ so on the left of $\sqrt 10$ , we are considering $n\in[0,3]$ ,which gives us $\max b_n=17$ and on the right we are approaching $-1$ ,with $\min b_n=-5$ . As for the sets, I think $B'$ might equal to $\{-1\}$ because our set gets denser as we approach -1.I am clueless about the other two.","['elementary-set-theory', 'calculus', 'real-analysis']"
3090268,Is the algebraic structure of the full matrix ring preserved by every Lie algebra endomorphism?,"Let $A = \mathcal M_n(k)$ be the full matrix algebra over a field $k$ . If $\phi:A\to A$ is a nonzero endomorphism of $A$ as a Lie algebra, must it automatically be an endomorphism of $A$ as a unital $k$ -algebra? If not, what would be necessary conditions? EDIT As TorstenSchoeneberg pointed out in the comments, a necessary condition is that $\phi$ is the identity on $k$ . Could this also be a sufficient condition?","['matrices', 'ring-homomorphism', 'lie-algebras']"
3090405,Structure Constants for $ 2 $ by $ 2 $ Matrices,"The space of $2 \times 2$ matrices is $4$ -dimensional. For a generic choice of $3$ matrices $X$ , $Y$ , and $Z$ , we can take a basis to be $\{\mathrm{Id}_2, X, Y, Z\}$ . The following fact seems, experimentally, to be true: Expand the three products $YX$ , $ZY$ , and $XZ$ in this basis: $$ \begin {align*}
YX &= a_{yx} \mathrm{Id} + b_{yx}X + c_{yx}Y + d_{yx}Z \\[1.2ex]
ZY &= a_{zy} \mathrm{Id} + b_{zy}X + c_{zy}Y + d_{zy}Z \\[1.2ex]
XZ &= a_{xz} \mathrm{Id} + b_{xz}X + c_{xz}Y + d_{xz}Z
\end {align*}
$$ Then it seems that we always have the following relations among these structure constants: $$ b_{yx} = d_{zy}, ~~ c_{yx} = d_{xz}, ~~ c_{zy} = b_{xz} $$ I do not see why this is true. Does anyone know a proof or explanation?","['matrices', 'abstract-algebra', 'linear-algebra']"
3090408,"Find all finite sets $A$ so that $A\times\mathcal P(A) =\mathcal P(A)\times A$, where $\mathcal P(A)$ is the power set of $A$.","Find all finite sets $A$ so that $A\times\mathcal P(A) =\mathcal P(A)\times A$ , where $\mathcal P(A)$ is the power set of $A$ . Now I'm a beginner at Discrete Math so I'm not sure how to tackle this problem. I was expecting that a set with elements would provided to prove this. My best hunch is that all sets should work since its the same on both sides of the equal sign. If you could help me find out how work through the question, instead of just an answer that would be great!",['discrete-mathematics']
3090460,Prove that $(A \triangle C) \cap (B \triangle C) \subseteq (A \cap B) \triangle C$,"This is a exercise from How To Prove It by Velleman.  Exercise 3.5.24 to be exact.  The solutions I can find online involve using 4 cases.  My proof involves 2 so I was wondering if I was skipping some steps. Proof: Let x be an arbitrary element of $(A \triangle C) \cap (B \triangle C)$ .  It follows that $x \in A \triangle C$ and $x \in B \triangle C$ . We will consider 2 cases. Case 1: $x \in C$ .  Since $x \in A \triangle C$ , it follows that $x \notin A$ .  Also since $x \in B \triangle C$ , it follows that $x \notin B$ .  This means $x \in C \setminus (A \cap B)$ thus $x \in (A \cap B) \triangle C$ . Case 2: $x \notin C$ .  Since $x \in A \triangle C$ , it follows that $x \in A$ .  Also since $x \in B \triangle C$ , it follows that $x \in B$ .  This means $x \in (A \cap B) \setminus C$ thus $x \in (A \cap B) \triangle C$ . Both cases gave us $x \in (A \cap B) \triangle C$ and since x was arbitrary $(A \triangle C) \cap (B \triangle C)  \subseteq (A \cap B) \triangle C$ Is this proof a valid one?  Any feedback would be greatly appreciated. Thanks in advance.","['elementary-set-theory', 'solution-verification']"
3090501,Change of Coordinate and Chain Rule,"I think I am confused about something very fundamental about change of coordinates and how it affects computing the derivatives, and I would really appreciate some clarification. Let me set up my question appropriately: Suppose we have a function $f:\mathbb{R}^n \to \mathbb{R}$ , and I want to compute its gradient $\nabla_{x}f(x_0)$ at some point $x_0 \in \mathbb{R}^n$ . However, the expression of $f$ is very complicated in this coordinate system, and I know that in another coordinate system described by $x \mapsto y$ , where we have a nice invertible linear function $Ax=y$ , the gradient $\nabla_{y}f(y_0)$ in that coordinate system has a very simple form. I want to make use of this simple $\nabla_y f(y_0)$ to compute $\nabla_{x}f(x_0)$ . However, it seems like a simple application of the chain rule does not really give me what I want, because $$\nabla_x f(x_0) = \nabla_x f(AA^{-1}x_0) = A^T\nabla_yf(AA^{-1}x_0) = A^T\nabla_yf(x_0)$$ Now I am stuck. Is there no hope of making use of the gradient in one coordinate system to compute the gradient in another coordinate system like I am trying to do? Am I making some basic mistakes? Are there alternatives? Any clarification/help is appreciated! BTW, I am also curious about a related problem on Hessian calculation. In Hessian Matrix Identity , the following is claimed to hold: $$ H(g,x') = A^tH(f, x)A, \text{ where } g(x')=f(Ax)$$ This is not correct is it? I mean take a simple $f(x)=x^2$ and $g(x')=f(ax)=(ax)^2$ , we have $$\frac{d^2g}{dx'}(x')=2, \text{ while } a\times\frac{d^2f}{dx^2}(x)\times a=2a^2$$","['analysis', 'real-analysis', 'multivariable-calculus', 'calculus', 'linear-algebra']"
3090510,Prove that $11^{16} + 16^{11} \equiv 0 \mod {17}$,"I was checking the following Fermat's theorem exercise: Prove that $11^{16} + 16^{11} \equiv 0 \mod {17}$ Because both $11$ and $16$ are primes with $17$ I applied the theorem individually, so the first one $$11^{16}\equiv 1 \mod {17}$$ gives me a result directly. But the after applying the theorem to the second one $$16^{16} \equiv 1 \mod {17}$$ I don't know the way to go back in the power from $16$ to $11$ which is the number requested. Is that as easy as $16 \equiv -1 \mod {17}$ ? Any help will be really appreciated.","['number-theory', 'modular-arithmetic', 'discrete-mathematics']"
3090537,Why do we take only intervals for solution of differential equation [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Suppose the solution to my equation blows up at 0 and is well defined everywhere else. Then why can't we just take R-{0} as the domain of the function? Also can someone give an example of a nonzero function whose first order derivative is zero? Edit: sorry, nonzero function which is not constant.
 Suppose the solution to a differential equation is  1/x then why do we have to take an interval and not R-{0}","['integration', 'interval-arithmetic', 'ordinary-differential-equations']"
3090558,The Lie bracket of $\mathfrak{gl}_n(\mathbb{R})$ is the matrix commutator,"Notation/preliminaries. Let $\mathfrak{g}$ denote the Lie algebra (of left-invariant vector fields) on the Lie group $G$ . Its Lie bracket $[.,.]\colon \mathfrak{g}\times\mathfrak{g}\to\mathfrak{g}$ is defined by $$[X,Y]_p(f)=X_p(Y_{\square}(f))-Y_p(X_\square(f))$$ for any vector fields $X,Y\in C^{\infty}(TG)$ , any point $p\in G$ and any smooth function $f\in C^{\infty}(G)$ . Here, $X_\square(f)\colon G\to\mathbb{R}$ is the smooth map defined by $q\mapsto X_q(f)$ . Let $T_eG$ denote the tangent space at the identify element $e$ , consisting of all linear maps $C^{\infty}(G)\to \mathbb{R}$ which satisfy the product rule. The tangent space is equipped with the Lie bracket $[\![.,.]\!]\colon T_eG\times T_eG\to T_eG$ given by $[\![X_e,Y_e]\!]=[X,Y]_e$ . This gives us a Lie algebra isomorphism $\mathfrak{g}\cong T_eG$ . More precisely, one can show that every tangent vector $X_e\in T_eG$ can be extended in a unique way to a left-invariant vector field $X\in \mathfrak{g}$ . For the Lie group $G=\mathrm{GL}_n(\mathbb{R})$ , we can use $x\colon \mathrm{GL}_n(\mathbb{R})\to \mathbb{R}^{n\times n}$ defined by $p\mapsto p$ as global coordinates. We will use $\Big\{\Big(\frac{\partial}{\partial x^{ij}}\Big)_e\Big\}_{i,j=1}^n$ as a basis for $T_e\mathrm{GL}_n(\mathbb{R})$ . Here, $\Big(\frac{\partial}{\partial x^{ij}}\Big)_e(f)=\partial_{ij}(f\circ x^{-1})\vert_{x(e)}$ for everh smooth function $f\colon \mathrm{GL}_n(\mathbb{R})\to\mathbb{R}$ . This gives rise to a vector space isomorphism $T_e\mathrm{GL}_n(\mathbb{R})\cong \mathbb{R}^{n\times n}$ via $\sum_{i,j} a_{ij}\Big(\frac{\partial}{\partial x^{ij}}\Big)_e\mapsto (a_{ij})$ . For any vector field $X$ on $\mathrm{GL}_n(\mathbb{R})$ , we let $M_X$ denote the matrix associated to $X$ via the identifications $\mathfrak{gl}_n(\mathbb{R})\cong T_e\mathrm{GL}_n(\mathbb{R})\cong \mathbb{R}^{n\times n}$ . Problem. I want to show that under the identifications $\mathfrak{gl}_n(\mathbb{R})\cong T_e\mathrm{GL}_n(\mathbb{R})\cong \mathbb{R}^{n\times n}$ , $[.,.]$ corresponds to the matrix commutator on $\mathbb{R}^{n\times n}$ . Or more precisely: For any vector fields $X$ and $Y$ on $\mathrm{GL}_n(\mathbb{R})$ , it holds that $M_{[X,Y]}=M_XM_Y-M_YM_X$ . Own attempt. I have realized that it suffices to show that for two tangent vectors $X_e=\sum_{i,j} a_{ij} \Big(\frac{\partial}{\partial x^{ij}}\Big)_e$ and $Y_e=\sum_{i,j} b_{ij} \Big(\frac{\partial}{\partial x^{ij}}\Big)_e$ , it holds that $$[X,Y]_e=\sum_{i,j,k} \big(a_{ik}b_{kj}-b_{ik}a_{kj}\big)\Big(\frac{\partial}{\partial x^{ij}}\Big)_e.$$ The first step, I guess, is to find the extensions $X$ and $Y$ of $X_e$ and $Y_e$ , respectively. I'm more or less convinced that for any $p=(p_{ij})\in \mathrm{GL}_n(\mathbb{R})$ , it holds that $$X_p=\sum_{i,j,k} p_{ik}a_{kj}\Big(\frac{\partial}{\partial x^{ij}}\Big)_p.$$ Can we conclude from this that $X=\sum_{i,j,k} x_{ik}(\square)a_{kj}\Big(\frac{\partial}{\partial x^{ij}}\Big)_\square$ holds? I've then tried to compute $[X,Y]_e(f)$ for an arbtirary $f\in C^\infty(\mathrm{GL}_n(\mathbb{R}))$ , using the formula in (1) above, and end up with the scary expression $$[X,Y]_e(f)=\Bigg(\sum_{i,j} a_{ij} \Big(\frac{\partial}{\partial x^{ij}}\Big)_e\Bigg)\Bigg(\Big(\sum_{i,j,k} x_{ik}(\square)b_{kj}\Big(\frac{\partial}{\partial x^{ij}}\Big)_\square\Big)(f)\Bigg)-\Bigg(\sum_{i,j} b_{ij} \Big(\frac{\partial}{\partial x^{ij}}\Big)_e\Bigg)\Bigg(\Big(\sum_{i,j,k} x_{ik}(\square)a_{kj}\Big(\frac{\partial}{\partial x^{ij}}\Big)_\square\Big)(f)\Bigg)\,,$$ from which I have no idea where to go. Am I at all on the right track here? It feels like my main problem is that I get a little bit lost in all the notation and all identifications we make back and forth. Indeed, proofs of this fact can be found in many text books (e.g. Lee's Introduction to Smooth Manifolds p. 194), but the notation there tends to be too coarse for me to follow what is going on.","['smooth-manifolds', 'lie-algebras', 'lie-groups', 'differential-geometry']"
3090560,Infinite series with $2$ positive and $2$ negative terms,Finding value  of $$1+\frac{1}{5}-\frac{1}{7}-\frac{1}{11}+\frac{1}{13}+\frac{1}{17}-\frac{1}{19}-\frac{1}{23}+\cdots$$ Try: I have solved in using Integration But i am trying to solver it without using integration Witting above series as $$\sum^{\infty}_{n=0}(-1)^n\bigg[\frac{1}{6n+1}+\frac{1}{6n+5}\bigg]$$ Now i am trying to solve it using euler reflection formula Could not find any clue could some help me to solve it,['sequences-and-series']
3090626,Proving irrationality of $\sqrt[3]{3}+\sqrt[3]{9}$ [duplicate],"This question already has answers here : If $\sqrt[3]{a} + \sqrt[3]{b}$ is rational then prove $\sqrt[3]{a}$ and $\sqrt[3]{b}$ are rational (2 answers) Closed 5 years ago . I need to prove $$\sqrt[3]{3}+\sqrt[3]{9}$$ is irrational, I assumed $$\sqrt[3]{3}+\sqrt[3]{9} = \frac{m}{n}$$ I cubed both sides and got $$\sqrt[3]{3}+\sqrt[3]{9} = \frac{m^3-12n^2}{9n^3}$$ I tried setting $$\frac{m^3-12n^2}{9n^3} = \frac{m}{n}$$ but that led me nowhere. so what can I do?","['number-theory', 'radicals', 'irrational-numbers']"
3090636,$\sum\limits_{n=1}^{\infty}\arctan{\frac{2}{n^2+n+4}}$,$$\sum\limits_{n=1}^{\infty}\arctan{\frac{2}{n^2+n+4}}$$ We know that : $\arctan{x} - \arctan{y} = \arctan{\frac{x-y}{1+xy}}$ for every $ xy > 1 $ I need to find two numbers which satisfy: $ab = n^2+2n+3 $ and $ a-b =2$ in order to telescope. Edit: I am very sorry on the denominator it should have been $n^2+n+4$ not $n^2+2n+4$ Similarly here : $$\sum\limits_{n=1}^{\infty}\arctan{\frac{8n}{n^4-2n^2+5}}$$ The result should be $ \arctan 2 $ on the first one and $ \pi/2 + \arctan2  $ on the second one.,"['calculus', 'trigonometry', 'telescopic-series', 'sequences-and-series']"
3090700,Asymptotic formula for $\sum_{k=1}^n \frac{1}{\varphi(k)}$?,"Is an asymptotic formula of $$\sum_{k=1}^n \frac{1}{\varphi(k)}$$ known ? The infinite sum $$\sum_{k=1}^\infty \frac{1}{\varphi(k)}$$ diverges which can be shown by comparing it to the harmonic series $$\sum_{k=1}^\infty \frac{1}{k}$$ Numerical values : ? sum(j=1,10^7,1.0/eulerphi(j))
%44 = 31.26649923752769616067244698051873057166
? sum(j=1,10^8,1.0/eulerphi(j))
%45 = 35.74179524657529982203363898007376015266
? So, the value seems to be roughly $1.94\cdot \ln(n)$ . Is this actually true, and if yes, what is known about the constant near $1.94$ ?","['number-theory', 'totient-function', 'asymptotics', 'elementary-number-theory']"
3090712,How does a section of a bundle with fibre $\mathbb{P}^N$ give us a spin structure?,"In ""Spin Structures on Manifolds"" Milnor says that for a principal $SO(n)$ bundle $\pi:E\to X$ a spin structure can be defined as follows: Let $Spin(n)$ act on a sphere $S^N$ in such a way that the kernel $\mathbb{Z}_2$ of the cover $Spin(n) \to SO(n)$ acts freely, thus giving an action of the quotient $SO(n) $ on the quotient $\mathbb{P}^N$ . He considers the bundle with fibre $\mathbb{P}^N$ associated to the principal bundle $\pi:E\to X$ and says that a spin structure can be seen as a section of this bundle but he doesn't give any detail. How can we get a spin structure on $E$ from such a section?","['differential-topology', 'algebraic-topology', 'differential-geometry']"
3090832,Solve $\frac{dx}{dy}+\frac{x}{\sqrt{x^2+y^2}}=y$,Solve the differential equation Solve $$\frac{dx}{dy}+\frac{x}{\sqrt{x^2+y^2}}=y$$ My try: I used $x=y \tan z$ $$\frac{dx}{dy}=\tan z+\sec^2 z\frac{dz}{dy}$$ So we get: $$\tan z+\sec^2 z\frac{dz}{dy}+\sin z=y$$ Any clue from here?,"['trigonometry', 'derivatives', 'ordinary-differential-equations']"
