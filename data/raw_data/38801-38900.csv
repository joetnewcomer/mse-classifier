question_id,title,body,tags
379773,Cancelling differentials,"I'll start with an example. In physics, $x(t)$ represents the $x$-position of a particle, and $v(t)$ its ($x$-)velocity. To determine the total displacement of a particle on the interval $[a, b]$, we can use the formula $$\Delta x = \int_a^b{v(t)~dt}$$ To me, this makes sense, because $v = \frac {dx}{dt}\\$, so the above equation is equivalent to: $$\Delta x = \int_a^b{v(t)~dt} = \int_a^b{\frac {dx}{dt}~dt} = \int_a^b{dx} = x(b) - x(a) = \Delta x$$ However, I've been told that you can't just ""cancel"" the $dt$ differential because it's not ""proper."" Another example uses parametric arc length: $$\ell = \int_a^b{\sqrt{\left ( \frac {dx}{dt} \right )^2 + \left ( \frac {dy}{dt} \right )^2} dt}$$ Now take a standard function, $y = f(x)$. We can define $x = t$, and then we have $y(t) = f(t)$, $x(t) = t$, and $\frac{dx}{dt} = 1$. Then, $\frac {dy}{dt} = \frac {{dy}~/~{dx}}{{dx}~/~{dt}} = \frac {{dy}~/~{dx}} 1 = \frac {dy}{dx}$, and our formula simplifies to $$\ell = \int_a^b{\sqrt{1 + \left ( \frac {dy}{dx} \right )^2} dt}$$ This is indeed the correct formula for arc length of a function (also derivable with Pythagorean theorem), but it relies on being able to cancel the $dx$s in $\frac {{dy}~/~{dx}}{{dx}~/~{dt}}$. So, my question is, when, if ever, can you cancel differentials?","['ordinary-differential-equations', 'calculus']"
379775,Natural Numbers and Well ordering,"I have to show that in any non empty subset of $N$ there is least element.
Note: This is not a homework question. So this is how my incomplete proof looks like. And I tried this by induction: let $S$ be nonempty subset of $N$. I defined $M = \{m \in N \mid m\le s \text{ for all } s \in S\}.$ Then I showed $1$ is in $M$. I did this using proof by contradiction. Now if $s$ is in $S$ then $s < s^+$. So $s^+$ is not in $M$. Thus $M$ is not equal to $N$. Thus there exists $z$ in $M$ such that such that $z^+$ is not in $M$. Now I have to show $z$ is the least element of $S$. Since $z$ is in $M$ by the way $M$ is defined $z$ must be least element of $S$. But what if $z$ is not in $S$? What should I do? Help please.",['elementary-set-theory']
379781,"Intersection of connected open sets with union $[0,1]^2$ is connected","I'm trying to show that if the union of two open connected sets equals $[0,1]^2$, then their intersection is also connected. My attempt: Let $U,V \subset [0,1]^2$ be open and connected, and suppose $U \cap V$ is disconnected. Then there exist disjoint open sets $A,B$ such that $U \cap V = A \cup B$. But then $U = U \backslash V \cup (A \cup B)$ and $U \backslash V \cap (A \cup B) = \emptyset$. So this means $U$ is disconnected if $U \backslash V$ is open since $A \cup B$ is open. But I don't think $U \backslash V$ is open since $U \backslash V = U \cap V^c$ so it's the intersection of an open set with a closed set. Should I be going about this in a different way?",['general-topology']
379788,Simple u-subsitution - Paradoxical Result,"If I were to try and take $$\int{\mathrm{sin}(t)\mathrm{cos}(t)dt} $$ I would either take $u=\mathrm{sin}(t) $, yeilding a result of $\frac{1}{2} \mathrm{sin}^2(t) + C$, or I would take $u=\mathrm{cos}(t) $, yeilding a result of $-\frac{1}{2} \mathrm{cos}^2(t)+ C$. These two results are not equivalent.  What just happened?",['integration']
379806,How to prove that $ E:=ABC D $ is also positive definite?,"Now I think this is true: Let $A$, $B$, $C$ and $D$ be symmetric, positive definite matrices and suppose that $E:=ABCD $ is symmetric. 
  How might I prove that $E$ is also positive definite? the similar question  can see: How to prove that $D := ABC$ is also positive definite? @Landscape  this not true, 
Really? Thank you everyone","['matrices', 'quadratic-forms', 'linear-algebra']"
379809,is there a name for this function (parity of a finite sequence)?,"Variants of this question have been crossposted to Stack Overflow and Computational Science Stack Exchange . Additional answers may be found at these other sites. Math people: In an attempt to solve a larger problem, I defined a function $\sigma$ as follows: if $(x_1, x_2, \ldots, x_n)$ is a finite sequence of distinct real numbers, then 
$\sigma(x_1, x_2, \ldots, x_n) = 1$ if $(x_1, x_2, \ldots, x_n)$ is an even permutation of an increasing sequence, and $\sigma(x_1, x_2, \ldots, x_n) = -1$ if $(x_1, x_2, \ldots, x_n)$ is an odd permutation of an increasing sequence.  Does this function have a name?  I Googled ""parity of a finite sequence"" and found nothing.  I found plenty on the parity of a permutation, but $(x_1, x_2, \ldots, x_n)$ is not a permutation.  Note that $n$ can be any positive integer.  The function is defined, and I need to define it, only for finite sequences of distinct real numbers. An example of an increasing sequence is $(1, 2, 4, 7, 10)$.  The numbers $x_1, \ldots, x_n$ are distinct, so there is exactly one increasing sequence you can form using all of them exactly once. Here is an example: $(2.3, 4.7, 9.9, 10, 13)$ is an increasing sequence of real numbers.  $(4.7, 2.3, 10, 9.9, 13)$ is an even permutation of that sequence.  So $\sigma(4.7, 2.3, 10, 9.9, 13) = 1$.  Got it? Regardless of whether this function has a standard name, does anyone know if there is a function built-in to Matlab or Maple to compute it? UPDATE: I got some help at Stack Overflow.  If I enter A = [2 7 4 10] then [i a] =sort(A) then a at the Matlab command prompt, the value of $a$ is $[1\ 3\ 2\ 4]$. The sign of the permutation vector $a$ can be computed in Matlab in two lines using only two additional commands: J=eye(length(a)); sign =det(J(:,a))) Stefan (STack Exchange FAN)","['maple', 'matlab', 'combinatorics']"
379818,Solving Riemann-Stieltjes integral:$\int_{- \pi/4}^{\pi/4} f(x)dg(x)$,"I'm having trouble solving this Riemann-Stieltjes integral: $$\int_{- \pi/4}^{\pi/4} f(x)dg(x),$$ where $$f(x):= \begin{cases} \frac{\sin^4x}{\cos^2x}{} &\text{if }x\ge0,  \\{}\\ \frac1{\cos^3x} &\text{if }x<0,\end{cases}$$ and $$g(x)=\begin{cases} \phantom{-} 1+\sin(x) &\text{if }-\pi/4 <x<\pi/4,  \\ -1 &\text{otherwise}.\end{cases}$$ I believe the only jump discontinuities are at $-\pi/4$ and $\pi/4$ . Which $g=-1$ at both of those points. I'm struggling with the rest. What formula should I be using to compute the integral and what should my answer look like? Thanks for any help!","['calculus', 'integration', 'trigonometry', 'real-analysis', 'stieltjes-integral']"
379824,Largest and smallest eigenvalues of a hermitian matrix,How to show that the largest and smallest eigenvalues of a hermitian matrix $A \in \mathbb{C}^{n \times n} $ can be found as: $\displaystyle \lambda_{max} = \underset{x\neq0}{\max{\frac{x^*Ax}{x^*x}}}$ and $\displaystyle \lambda_{min} = \underset{x\neq0}{\min{\frac{x^*Ax}{x^*x}}}$,"['numerical-linear-algebra', 'matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
379829,Solve $\sin(x)+2\sin(x)\cos(x)=\pi/4$,"Is it possible to solve (not approximate) the following trigonometric equation by hand? 
$$\sin(x)+2\sin(x)\cos(x)=\pi/4.$$",['trigonometry']
379833,$f(x) = e^{-x^2}$ series representation,"Let $f(x) = e^{-x^2}$, defined for $x \in \mathbb{R}$. Find a series representation of a function $F:\mathbb{R} \to \mathbb{R}$ such that $F(0)=0$ and $F'(x)=f(x)$ for each $x$. I know that the answer to this is in some form of a Taylor series, but I don't even know where to start beyond that...","['calculus', 'analysis']"
379836,Why this is not a sigma algebra,"Let be $\Omega$ the interval $(0,1]$ and let $\mathcal{F}$ be the set of all sets of the form $(a_0,a_1]\cup(a_2,a_3]\cup\cdots\cup(a_{n-1},a_n]$, where $0\le a_0\le a_1\le\cdots\le a_n\le 1$. Show that $\mathcal{F}$ is not a $\sigma$-algebra. I have attempted a similar question: Let be $\Omega = [0,1]$ and $G = \{[0,\frac{1}{3}],[\frac{1}{2},1]\}$. What is $\sigma(G)$? My answer is the following, not sure whether this is correct: $$\sigma(G) = \left\{\emptyset, \left[0,1\right], \left[0,\frac{1}{3}\right], \left[\frac{1}{2},1\right], \left[\frac{1}{3},\frac{1}{2}\right], \left[0,\frac{1}{3}\right]\cup\left[\frac{1}{2},1\right], \left[\frac{1}{3},1\right], \left[0,\frac{1}{2}\right]\right\}.$$ But using a similar reasoning, I wasn't able to to prove the first question is not a $\sigma$-algebra. I think if we apply all properties of $\sigma$-algebra, the resulting sets are all of the form $(a_0,a_1]\cup(a_2,a_3]\cup\cdots\cup(a_{n-1},a_n]$. My intuition is to try to come up with a set of the form $[a_{i-1},a_i)$, but I found no clue. Side questions: We know that the usual subsets of $\mathbb{R}$ are in $\mathcal{B}$($\mathbb{R}$). And any one point set, $\mathbb{N}$ and $\mathbb{Q}$ are in $\mathcal{B}$($\mathbb{R}$). But does $\mathcal{B}$($\mathbb{R}$) contains the set of all irrational numbers? Why? Any helps will be greatly appreciated. Thanks!",['measure-theory']
379841,How to enumerate subgroups of each order of $S_4$ by hand,"I would like to count subgroups of each order
(2, 3, 4, 6, 8, 12) of $S_4$,
and, hopefully, convince others that I counted them correctly.  In
order to do this by hand in the term exam, I need a clever way to do
this because there can be as many subgroups of a group of order 24 as
$2^{23}$. Do you know how to do this? (I would be most grateful if you could tell me what part of the answer to the old question answers my question before voting to close.)","['finite-groups', 'group-theory', 'symmetric-groups']"
379843,"Prove for continuous $f$ and $g$,$f(x)<g(x)$ there exists $k$ such that $f(x)+k<g(x)$","Suppose that $f$ and $g$ are continuous on $[a,b]$ and for each $x$, it holds that $f(x)<g(x)$. Prove that there exists $\alpha>0$ such that for each $x$, it holds that $f(x) + \alpha <g(x)$ (Notice that $\alpha$ may not depend on $x$). We have done a similar problem with $f(x)>0$ and proving $\alpha>0$ exists such that $f(x)>\alpha$, but I'm not exactly sure how to use supremum and infimum to solve the above version.","['calculus', 'analysis']"
379854,differential equation12,"After 30 days of radioactive decay,100 mg of a radioactive substance was observed to remain. After 120 days, only 30 mg of this substance was left. 
A. How much substance was originally present?
B. What is the half-life of this radioactive substance?
C. How long will it take before only 1% of the original amount remains? I have no clue what so ever",['ordinary-differential-equations']
379878,Stokes' Theorem,"Let $C$ be the following, let $C$ be the curve of intersection of the cylinder $x^2 + y^2 = 1$ and the given surface $z = f(x,y)$, oriented counterclockwise around the cylinder. Use Stokes' theorem to compute the line integral by first converting it to a surface integral. (a) $\int_C (y \, \mathrm{d}x + z \, \mathrm{d}y + x \, \mathrm{d}z),\quad z=x \cdot y$. I'm having a problem setting up the problem. I appreciate any assistance.",['multivariable-calculus']
379882,In how many different ways can we place $8$ identical rooks on a chess board so that no two of them attack each other?,In how many different ways can we place $8$ identical rooks on a chess board so that no two of them attack each other? I tried to draw diagrams onto a $8\times8$ square but I'm only getting $16$ ways.  Does that sound right? Thanks for the help!,"['problem-solving', 'combinatorics']"
379891,What does it mean to take an integral of a probability?,"My understanding is that you have some function $y=f(x)$ to represent a probability density function, correct? For instance for a uniform random variable it looks like a giant rectangular block. I don't really know what a density function tells you but for a uniform variable it's $1\over(b-a)$. I assumed this meant ""the probability that you 'land' in this area is $1\over(b-a)$"" but then I read that taking the integral of the density function gives you the probability? And then somehow I see that sometimes you can take the integral of the probability function, for example if you want to know the probability that the sum of n random variables exceeds x, it requires taking the integral of a probability function and so on and so forth. For example see http://mathworld.wolfram.com/UniformSumDistribution.html after the line ""while the sum of $n-1$ variates being less than 1 is."" I am getting lost in my understanding of what the integral of this and that represents. Is there a simple way to understand what is what, here?","['statistics', 'probability']"
379902,"If $cf(\kappa)=\lambda$, then is every sequence of length $\lambda$ cofinal in $\kappa$?",Take $\omega_1$ for instance.  Let's say I have a sequence of (distinct) ordinals of length $\omega_1$.  Will this sequence be cofinal in $\omega_1$?,"['cardinals', 'elementary-set-theory', 'ordinals']"
379903,Incomplete vector field,"Is there a way I can tell if a vector field on a manifold or just $\mathbb{R}^n$ is incomplete simply by just looking at its formula.  For instance on $\mathbb{R}$, $\displaystyle X= (x^2+1) \frac{\partial}{\partial x}$, is incomplete as it shoots off to infinity in finite time as evidenced by its flow $F=\tan(t-C)$.  Should I be able to see that X was going to be incomplete without computing $F$?","['multivariable-calculus', 'manifolds', 'differential-geometry']"
379904,How to prove this identity for ${}_3F_2$ (Generalized Hypergeometric Function)?,"This may look like homework, but it is not. I've found this identity (using Mathematica): $$
{}_3F_2 \left( \matrix{1,1,1 \\ 2, e} ; 1 \right) = (e-1) \psi^{\prime}(e-1),
$$ valid for $e$ with $\mathcal{R}(e)>0$, where ${}_3F_2$ is the Generalized Hypergeometric Function (as in here ) and $\psi^{\prime}$ is the trigamma function (definition here ). It's also in Wolfram's site: http://functions.wolfram.com/07.27.03.0083.01 The problem is... I've no idea how to prove it. I've tried using the definition of the Pochhammer symbol and some simplifications to get this: $$
{}_3F_2 \left( \matrix{1,1,1 \\ 2, e} ; 1 \right) = \sum_{k=0}^{\infty} \frac{\Gamma(k+1)\Gamma(e)}{(k+1)\Gamma(e+k)},
$$ but it's not even close to the series for trigamma function: $$
(e-1) \psi^{\prime}(e-1) = (e-1) \sum_{n=0}^{\infty} \frac{1}{(e-1+n)^2}.
$$ Any help/tips/references are appreciated.","['special-functions', 'hypergeometric-function', 'complex-analysis']"
379906,Manifold Boundary versus Topological Boundary.,"Let $M$ a $n$-manifold whit boundary, i.e., for each $x\in M$, there exist $U_x\subseteq M$ open in the topology of $M$ such that $U_x$ is homeomorphic to $\mathbb{R}^n$ or homeomorphic to $\mathbb{H}^n$, where $$
\mathbb{H}^n = \{ (x_1,\ldots,x_n) \in \mathbb{R}^n \;:\; x_n \geq 0\}.
$$ Denote by $\partial M $ the boundary of $M$, i.e., $\partial M = \{x \in M\;:\;U_x \cong \mathbb{H}^n \}$. Suppose that $M$ is embedding in a topological space $X$ and denote by $\partial_T M$ the topological boundary of $M$, i.e., $\partial_T M = X \setminus (Ext(M) \cup Int(M))$. I conjecture that $\partial M \subseteq \partial_T M$. Is it true? This make sense? If yeah, you can give me a good argument?  If not, you can show me a counter-example?","['general-topology', 'manifolds-with-boundary', 'manifolds']"
379909,"The relationship between inner automorphisms, commutativity, normality, and conjugacy.","An inner automorphism of a group $G$ is defined to be a function $f: G \to G$ such that for $x\in G$ $f(x) = a^{-1}xa.$ I have three somewhat broad questions about this: Why is it related to the notion of an automorphism.  That is, what about this says 'structure preserving'? I have heard inner automorphisms say something about the degree to which commutativity is upheld in a group.  How is this specifically? How does this relate to the notions of normality conjugacy of a group? Sorry if these questions are too broad.","['definition', 'abstract-algebra', 'group-theory', 'finite-groups', 'intuition']"
379928,Why are the real numbers with the K-Topology not metrizable?,"I will denote the real numbers with the $K$-Topology as $R_{K}$ (If someone doesn't know or remember this topology, read here ). I understand that $R_{K}$ is not regular, since the set $K$ cannot be separated from the point $0$, and it is second-countable, since you can take as basis the intervals with rational endpoints. It seems to me that this is not enough to prove that $R_{K}$ is not metrizable, but I don't know how to proceed. Someone suggested me to use Urysohn metrization theorem, but I think it is not possible in this case since it is not a characterization of metric spaces.",['general-topology']
379934,Computing RSA Algorithm,"Modulus $N=247$; encryption exponent $r=7$ Encrypt $100$; Decrypt $120$. $Solution:$ Encryption of $100$ is $35$. Decryption exponent of is $31$. Decryption of $120$ is $42$. For a discrete math textbook I'm reading, I am faced with the above question. It gives the solution but does not really explain how they got it. So at the moment I am completely confused with RSA. Any step by step explanation would be great.","['cryptography', 'elementary-number-theory', 'algorithms', 'discrete-mathematics']"
379994,What does the stalk of a sheaf of discontinuous sections look like?,"I'm having some kind of cognitive dissonance here, but I'm having trouble figuring out which of my beliefs is false.  Let $\mathscr{F}$ be a sheaf of abelian groups on a topological space $X$ and $x \in X$.  Write $\mathscr{G} := \prod_{x \in X} i_\ast(\mathscr{F}_x)$, where $i_\ast(\mathscr{F}_x)$ is the $\mathscr{F}_x$-valued skyscraper sheaf at $x$. We have $\mathscr{G}(U) := \prod_{x \in X} \Gamma(U, i_\ast(\mathscr{F}_x)) = \prod_{x \in U} \mathscr{F}_x$, which we can regard as the set of functions $s : U \to \bigsqcup_{x \in U} \mathscr{F}_x$ by writing $s(x)$ for the $x$-entry of the direct product.  So $\mathscr{G}$ is the sheaf of discontinuous sections of $\mathscr{F}$. Since taking stalks commutes with taking direct sums products, we have $\mathscr{G}_x = \mathscr{F}_x$ for each $x \in X$. On the other hand, looking at elements of $\mathscr{G}_x$ directly, they represent functions $s : U \to \bigsqcup_{x \in U} \mathscr{F}_x$ up to equivalence on some open set.  But it's easy to construct all sorts of such functions which don't agree on any open neighborhood of $x$ but which have the same value for $s(x)$ -- just send all the neighboring points absolutely anywhere.  So $\mathscr{G}_x$ is much, much larger than $\mathscr{F}_x$. Where is the mistake? Update: Thanks to both of you for helpful answers; it was tough choosing just one.","['sheaf-theory', 'algebraic-geometry']"
379996,Computing $\bmod$s with large exponents by paper and pencil using Fermat's Little Theorem.,"I'm having a bit of trouble computing $\bmod{mod}$s of large numbers using Fermat's Little Theorem. For example, how would you compute $7^{435627650}\mod 13$? The solution given is $435627650\mod 12=2,$ so $7^2\mod{13} = 10.$ In general, how does one solve this type of question with large exponents and mods by paper and pencil? I'm also a bit confused about where the $12$ came from and how this problem was solved.","['discrete-mathematics', 'number-theory', 'modular-arithmetic', 'elementary-number-theory', 'finite-groups']"
380004,I roll 6-sided dice until the sum exceeds 50. What is the expected value of the final roll?,"I roll 6-sided dice until the sum exceeds 50. What is the expected value of the final roll? I am not sure how to set this one up. This one is not homework, by the way, but a question I am making up that is inspired by one. I'm hoping this will help me understand what's going on better.","['statistics', 'probability']"
380011,Zeta Regularized Determinant of Laplacian,"Can anyone point me to a resource where the zeta regularized determinant of the Laplacian is explicitly computed for simple two dimensional surfaces, say a rectangle or torus or cylinder?","['reference-request', 'riemannian-geometry', 'functional-analysis']"
380033,How can I find the shortes path on square prism?,"My boss ask us a geometry question a few hours ago, but we can't find a solution at all.. We have a square prism that long edge is 12 cm and short (base) edges are 4 cm. We have 2 points ( A and B ). And these are 0,5 cm away from the nearest egde (blue lines) and these points extensions divide two equal pieces (2 cm - 2 cm) their nearest edges. The question is; Find a way to A to B smaller than 16cm .. The rule is ; the way can't use inside of the prism, only can use surface of the prism. First of all, for finding the shortest path, I tried to open the prism like; Even with that way, |AB| will be more than 16 cm.. Is there any solution for <16 cm? Note: I tagged the question with only geometry tag. So, please feel free to update it..",['geometry']
380036,Probability mass function [duplicate],"This question already has answers here : Probability density function vs. probability mass function (4 answers) Closed 2 years ago . Why is the probability function of a discrete random variable called a probability ""mass"" function? What does the word ""mass"" mean here?","['statistics', 'probability-distributions']"
380047,Is there any prime $p$ such that $(p-1)!+1=p^m$,"According to Wilson Theorem, we know that 
$$p\mid(p-1)!+1$$
for $p\in\mathbb{P}$. Also, we have $(2-1)!+1=2^1\\
(3-1)!+1=3^1\\
(5-1)!+1=5^2$ I guess there is no such prime $p$ satisfying $(p-1)!+1=p^m$ besides $2,3,5$. But I have no idea to prove it. Could anyone give me a hand?",['number-theory']
380057,Visualize soliton solutions of a PDE,"In trying to visualize soliton solutions of a PDE I faced this sentence: We now think of solitons as self-similar solutions, i.e., solutions which evolve along
symmetries of the flow. Question 1: Which solutions are called ""self-similar solutions""? Question 2: What is the meaning of ""symmetries of the flow""? and How can one find them in PDEs? Thanks in advance.","['partial-differential-equations', 'differential-geometry']"
380062,"Quick, basic exponent problem",Quick question regarding some exponential rules: Why is it that $(1-(1-x))^n = x^n$?,['algebra-precalculus']
380078,Trisecting a paper using hand and without using a ruler or compass [duplicate],"This question already has answers here : How can a piece of A4 paper be folded in exactly three equal parts? (13 answers) Closed 9 years ago . This is a practical problem born while folding a paper. We can bisect a paper by using only hand. $\star$ Easy, fold it so that the two ends (of the length) coincide and press
  the paper to get the bisector of the length. Repeating the $\star$ again and again we can divide the paper into $2^n$ (where $n\in\mathbb{N}$) parts using only hand. But how can we divide the paper into some other(I mean other than $2^n$) number of parts .And particularly, How can we divide the paper into three parts? Using only hand and instruments like ruler, compass, protractor etc and cutting away any piece of paper is banned. I would recommend the reader to take a paper and try it!, it's really interesting!.","['geometry', 'recreational-mathematics']"
380094,sufficiency and necessity of convergence of $\sum a_n$ wrt convergence of $\prod (1 + a_n)$,"Does there exist a sequence $a_n$  of complex numbers such that $\sum _{i = 0}^\infty a_n$ converges and the product $\prod _{i = 0}^\infty (1+a_n)$ does not converge to any complex number(not even 0). And conversely a sequence  $a_n$ s.t. $\prod _{i = 0}^\infty (1+a_n)$ converges to a non zero complex number. But $\sum _{i = 0}^\infty a_n$ does not converge. We all know that if $\sum _{i = 0}^\infty a_n $ converges absolutely iff the corresp product converges absolutely. So i tried alternating serieses like $ a_n = (-1)^n /n $ and $(-1)^n / \sqrt n $  but that did not work. i tried like $ \sum _{i} \sum _ {k} \frac{ e^{2(pi)i/k}}{k} $but i couldn't go furthur.
Can anybody help?","['sequences-and-series', 'infinite-product', 'complex-analysis']"
380116,Number of coefficients of a multivariable polynomial,"Let $g \in \mathbb{F}[x_1, \dots, x_n]$ be a polynomial of degree $d$ with $n$ variables. Number of its coefficients is ${n+d \choose d}$ Is there an easy proof? It clearly holds for univariate polynomial $n=1$ . It holds even for some polynomials I tried, for example $g(x,y) = x^3 + y^3 + x^2y + y^2x + y^2 + xy + x^2 + x + y + 1$ , where $10 = {2+3 \choose 3}$ .","['polynomials', 'multivariate-polynomial', 'combinatorics']"
380126,"""Inverse"" of tensor product","I am trying to figure out something. I have a 4-tensor $\phi_{i \, j \, k \, \ell}$ and I know that $\phi = A \otimes B$, being $A$ and $B$ two matrices. With indices, I know this: $\phi_{i \, j \, k \, \ell} = A_{k \, i} \, B_{j \, \ell}$ Now, if I know $A$ and $B$ I can create $\phi$. How can I do the inverse? If I know $\phi$, how can I find $A$ and $B$? I know this is not an ""inverse"" tensor product, but I hope I was sufficiently clear :)","['matrices', 'tensors']"
380135,Residual spectrum is empty,"I'm following Kreyszig's ""Introductory Functional Analysis with Applications"" and am trying to follow the proof of the following Theorem (9.2-4 on p. 468) For a bounded self-adjoint linear operator $T:H\to H$  on a complex Hilbert space $H$, $$\sigma_{r}\left(T\right)=\emptyset,$$
i.e. its residual spectrum is empty. The proof refers to the following Lemma: Lemma (projection theorem) Suppose that $Y$
is a closed subspace of a Hilbert space $H$. Then 
$$
H=Y\oplus Y^{\perp}.
$$ Kreysig's begins his argument as follows. "" Suppose, for contradiction, that $\sigma_{r}\left(T\right)$ is non-empty;
indeed, pick $\lambda\in\sigma_{r}\left(T\right)$. Then by definition of the residual spectrum, $R_{\lambda}:=T_{\lambda}^{-1}=(T-\lambda I)^{-1}$
exists but its domain is not dense in $H$. "" I understand everything so far. He then goes to argue: ""Hence by the Projection Theorem, there is a $y \neq 0$ in $H$ which is orthogonal to the domain of $R_{\lambda}$."" I don't see why this is. I wonder if someone could very kindly explain?","['operator-theory', 'spectral-theory', 'functional-analysis']"
380177,What is the difference between a Ring and an Algebra?,"In mathematics, I want to know what is indeed the difference between a ring and an algebra ?","['ring-theory', 'algebras', 'abstract-algebra', 'definition']"
380184,Proof that there is no Banach-Tarski paradox in $\Bbb R^2$ using finitely additive invariant set functions?,"I am wondering if anyone is familiar with the above topic? I have found a proof that it is possible to define a finitely additive invariant set function in $\mathbb{R}^2$ on the circle in Lax's book ""Functional Analysis"". He follows the proof up by saying that this proves that there is no banach-tarski paradox in the plane but I don't see why. Is it obvious? If it isn't can anyone tell me where I can find a proof of this using the existence of such functions? Cheers","['general-topology', 'functional-analysis', 'paradoxes']"
380191,When is a matrix congruent to a diagonal matrix and how to find the congruent transformation?,"What matrix can be congruent to a diagonal matrix and how can we find the congruent transform and the diagonal matrix? One special case is when the congruence is also similarity. For example, for a normal matrix, we can use a transform which is both similar and congruent to convert it into a diagonal matrix. But is it the only case where congruence to a diagonal matrix is of interest? Thanks and regards!","['matrices', 'linear-algebra']"
380199,Are algebraic numbers analogous to group elements with finite order?,"Would you say that the ""elements with finite order"" in group theory are analogous to ""algebraic numbers"" in field theory? I thought this is the case since requiring an algebraic number $\alpha$ to be the root of a polynomial (i.e. requiring a finite combination of terms in $\alpha$ using $+$ and $\times$ to give the identity zero) is like the two-operation equivalent of an element $g$ in group theory having finite order (where there is only one operation $\times$ and we require a term in $g$ which is required to give the identity 1). However I don't think the analogy is quite complete because in the case of the polynomial we are allowed to also multiply powers of $\alpha$ by other elements of the field to achieve the identity.","['soft-question', 'group-theory', 'abstract-algebra', 'algebraic-number-theory']"
380232,Different interpretations of point mass (degenerate distribution),"In a Probability book by Karr, the point mass (degenerate distribution) is defined as: The point mass (degenerate distribution) at (a fixed point) $\omega\in\Omega$: $\epsilon_{\omega}(A)$ = $1_A(\omega)$ (where $1$ is the indicator function). Since the LHS is a function of A (for a fixed outcome $\omega$), and the RHS is a function of $\omega$ (for a fixed event A), how can the two functions be equal? What does the equality here represents? Is it ok if I interpret it as $\mathbb{P}(A) = \epsilon_{\omega}(A)$? If yes, why, if no why not? I might care too much about unnecessary details, but any clarification is appreciated.","['probability-theory', 'probability']"
380234,Advice: Modern vs. Classics,"First of all, my apologies if (well, I know I am but I don't know where to put it) I am posting this in the wrong place. So please feel free to move it to someplace else or to tag it differently if that is possible. Anyways, I've been reading Lang's Linear Algebra and Lang's Undergraduate Algebra and I feel that they might not be the books I was looking for. They don't seem to be thorough enough and even though I have really been enjoying Lang's style I've started to look for other texts to use instead. I've narrowed it down to Hoffman & Kunze vs. Friedberg, Insel & Spence for Linear Algebra and for Abstract Algebra to Artin vs. Dummit & Foote , but I'm having troubles deciding which ones to go with. I've looked at reviews for all of them and they all seem to be great books and exactly what I'm looking for, but I don't know which ones to take as the main ones for reading. Can anyone who is familiar with these help me decide? What are the differences between each book in each set? These are both for self-study and abstraction isn't a real issue. Thank-you.","['advice', 'soft-question', 'linear-algebra', 'abstract-algebra']"
380248,"order of $\langle (123) , (234) \rangle$","As homework the teacher asks us to determine how many elements are there in  $\langle (123) , (234) \rangle \subset S_4$ . I've started doing all the multiplications between the elements, and I've counted so far $9$ different elements. But I think there is a easier way to determine the order of this subgroup of $S_4$. My argument is: $(123)$, $(234)$ are even permutations, so they can generate only even permutations. So our subgroup has at most $12$ elements. I've counted so far $9$ distinct elements, so using the Lagrange Theorem it must have 12 elements. Is it correct this argument?","['permutations', 'finite-groups', 'group-theory']"
380253,Singular Value Decomposition of a block diagonal matrix,"For a block diagonal matrix , we have an identity for its cholesky decomposition i.e. $chol(Z) = chol(blockdiag(A,B,...)) = blockdiag(chol(A),chol(B),...)$ (Here, $Z = blockdiag(A,B,...)$) I want to know whether there any such similar identities for SVD of a block diagonal matrix. Thanks.","['matrices', 'linear-algebra', 'svd', 'block-matrices']"
380271,Rouché's Theorem on $z^{10} + 10z + 9$,"Please note: this question was asked before, but the solution provided does not work as far as I know; see How to find the number of roots using Rouche theorem? We have $f(z) = z^{10} + 10z + 9$ and have to use Rouché's theorem to estimate the number of zeroes in $D(0,1)$. The theorem requires that we find a $g(z)$ for which $|f(z)-g(z)|<|f(z)|+|g(z)|$ for all $z \in \partial D(0,1)$. Just like in the aforementioned question, I wanted to divide by a factor $(z+1)$, and use Rouché's theorem on $h(z) = f(z)/(z+1)$ and $g(z) = 9$. 
However, if $z = -1$, then $|h(z)-g(z)| = 9$ and $|h(z)|+|g(z)| = 9$, so we do not have a strict inequality. The reason for this is that $-1$ is a zero of multiplicity $2$ in $f(z)$. I then thought that dividing by $(z+1)$ again would help me, but now I am left with having to prove that $|z^8 - 2z^7+3z^6-4z^5+5z^4-6z^3+7z^2-8z| < |z^8 - 2z^7+3z^6-4z^5+5z^4-6z^3+7z^2-8z+9| + |9|$ for all $z \in \partial D(0,1)$. Maple and Wolfram both agree this is valid for all $z \in \partial D(0,1)$, but how do I prove this? Or is there a better function $g(z)$ that I can use? Thanks","['roots', 'complex-analysis', 'polynomials']"
380272,Notation for number of distinct elements in a set,"Let $L = \{a_{1}, a_{2}, a_{3}, a_{4}, a_{5}, ... ,a_{n}\}$ be a logtrace containing a finite set of antenna samples submitted within a time window. What what would be a good way to express the number of distinct cellIDs $a^{cid}$ in $L$? where $a_{t}^{cid}$ is the cellID of the current registered antenna at time $t$. Assuming $A=\{1,4,3,5,4,3\}$, the result of the calculatin i'm searching for should be 4. Btw: What would be $ \#(A \cap A)$ ? 4 or 6? (if the result is 4, i would still like to avoid this weird notation.) Here's how i chose to write it, with the help of Brian M. Scott's answer. Let $a$ be an antenna sample, where $a^{cid}$ indicates the cellID and $a^{lac}$ the location area code (lac) of the antenna sample. Let $T = \{a_{1}, a_{2}, a_{3}, a_{4}, a_{5}, ... ,a_{n}\}$ be a logtrace containing a finite sequence of antenna samples $a$ submitted within a time window, and $T^{cid}$ the finite sequence of cellIDs $a^{cid} \in T$. Then, Number of distinct cellIDs $=|C|$. Where $C$ is a set of cellIDs $c \in T^{cid}$.",['elementary-set-theory']
380284,Cauchy integral formula for $\int_\gamma \frac{\sin z }{z^4-16}dz$,I have working through past exam questions and I think I have the hang of the Cauchy integral formula and the extended formula... but am a little stuck with how to work these examples out... and the denominators aren't of the form $(z-z_0)^n$ Any help in how to solve these types of questions would be greatly appreciated... $(i) \displaystyle\int_\gamma \dfrac{\sin z}{z^4-16}$ (with $\gamma$ in the unit circle in $\mathbb{C}$ traversed in the anti-clockwise direction) $(ii)\displaystyle\int_\gamma \dfrac{\cos z}{z(z^2-8)}$ (with $\gamma$ being the circular contour given by $\gamma(t)=e^{it}$ for $1 \leq t \leq 2\pi$,"['complex-analysis', 'contour-integration']"
380308,"Which group is isomorphic to $\left\langle\begin{bmatrix}0&1\\1&0\end{bmatrix},\begin{bmatrix}1&-1\\0 & -1 \end{bmatrix} \right\rangle$?","Both matrices have determinant equal to -1, so their products are matrices with determinant $\in \{1,-1\}$. Can I conclude that this is isomorphic to $ O_2(\mathbb{R}) $ ?","['linear-algebra', 'group-theory']"
380318,Cutting a cube by plane cuts,"This is an extension of a 3rd grade problem . How many pieces can one get at most if one cut a unit cube with n plane cuts? 1,2,4,8, ??? And assuming cutting through an area 1 takes time t, what is the least time needed to achieve the maximal pieces for n cuts, asymptotically?","['geometry', 'recreational-mathematics']"
380326,The range of the derivative of a differentiable function,"I read somewhere that, given a function $f$ differentiable on $[a,b]$, the range of $f'$ can be (1) a closed interval or (2) an open interval or (3) a half-open interval or (4) an unbounded interval Can someone give an example for each one ?","['examples-counterexamples', 'derivatives', 'real-analysis']"
380355,Functional equation $f\Big(\frac{x+y}{2}\Big)+f\Big(\frac{2xy}{x+y}\Big)= f(x)+f(y)$,"Can someone help me please with this problem? If the function
$f:\mathbb{R}^+\rightarrow\mathbb{R}$ satisfies the equation 
$f\Big(\frac{x+y}{2}\Big)+f\Big(\frac{2xy}{x+y}\Big)=
f(x)+f(y)$,
then it satisfies also $2f(\sqrt{xy})=f(x)+f(y)$. I tried to collect more formulas
from substitutions like $\sqrt{xy}\rightarrow x$, $x\rightarrow\frac{x+y}{2}$
but didn't succeed.","['algebra-precalculus', 'functions', 'functional-equations']"
380359,Why is $\sqrt{4} = 2$ and Not $\pm 2$? [duplicate],"This question already has answers here : Square roots -- positive and negative (5 answers) Why is the even root of a number always positive? (3 answers) Closed 11 years ago . I've always been told that if $\ x^2 = 4,$ $ =>x = \pm2$ But recently, Prof. mentioned that if $x = \sqrt{4}$, Then $x = +2(only)$ I am very skeptical about this because they both mean the same thing and still yield different results! So how is the above statement justified?",['algebra-precalculus']
380364,Is there any way to find minimum without the use of derivatve?,"The function is: $$\sqrt{(x+1)^2+\left(2x^2-\frac{1}{4}\right)^2}$$
It simplifies to: $$\sqrt{4x^4+2x+\frac{17}{16}}$$","['optimization', 'functions']"
380386,weak/vague convergence,"I am trying to understand 'vague/weak convergence' and need to decide whether or not a measure converges vaguely or weakly. Weak convergence implies vague convergences. However, I don't really understand whole thing. The measure $\delta_n$ converges vaguely but not weakly, but I cannot see how that works if I take the definition of weak/vague convergence weak convergence : $\int f(x)\, \mu_n(dx) \stackrel{n\rightarrow\infty}{\to} \int f(x)\, \mu(dx)\, f \in C_b$ vague convergence : $\int f(x)\, \mu_n(dx) \stackrel{n\rightarrow\infty}{\to} \int f(x)\, \mu(dx)\, f \in C_0$ If I take the $\delta_n$ from above I have $\int f(x)\, \delta_n\,(dx) \stackrel{n\rightarrow\infty}{\to} \int f(x)\, \delta_{\infty}(dx)$ How do I take the limit ? Do I calculate the integral at every n while $n\rightarrow \infty$, say if $f(x) \in C_b$ (e.g. $f \equiv 1)$ I get always $1$ but at some $n$ I get $0$ since $f(x)$ is bounded and, hence, it does not converge weakly ? How does the vague case look like ? jed","['weak-convergence', 'probability-distributions', 'probability']"
380403,Is it true that every finite subset of a Hausdorff space has no limit point?,"Let $X$ be a Hausdorff space. Assume a finite $A\subset X$ has a limit point $b$, say. Every pair $a\in A, b\in X$ has disjoint neighborhoods. Denote those neighborhoods of $b$ by $U_a$ for each $a\in A$. Now, $\cap U_a$ is clearly a neighborhood of $b$ and disjoint from $A$, contradicting the fact that $b$ is a limit point of $A$. So I think the answer is yes, if I didn't make any mistakes.","['general-topology', 'separation-axioms']"
380417,a totally ordered set with small well ordered set has to be small?,"doing something quite different the following question came to me:
1)If you have a totally ordered set A such that all the well ordered subset are at most countable, is it true that A has at most the cardinality of continuos? 2)More in general is it true that if a set A totally ordered has well ordered subset of lenght at most $|B|$ then A has at most cardinality $2^{|B|}$?","['elementary-set-theory', 'order-theory']"
380427,transitivity of commutator,"I remember a quantum mechanics lecture where my professor said ""Two matrices $A, B$ which commute with a third matrix $C$, $[A,C]=[B,C]=0$, commute with each other: $[A,B]=0$."" I pointed out the identity $C=\mathbb{I}$ as an obvious counterexample, to which he restated the proposition to exclude my counterexample: ""Two matrices $A, B$ which commute with a third matrix $C\neq\mathbb{I}$, $[A,C]=[B,C]=0$, commute with each other: $[A,B]=0$."" He said further that he didn't know if this was a theorem, but he had never come across a counterexample. Thinking about it now, a straightforward exception is a block diagonal $C$ which is the identity in a given block, but not the other blocks so $C\neq\mathbb{I}$, and $A,B$ which are only nonzero in the given block. My question is whether, apart from these trivial cases, transitivity of the commutator is generally true or not? If not what is a counterexample? If it is generally true for matrices how far can it be extended to other systems?","['relations', 'matrices', 'noncommutative-algebra']"
380429,"How can I tell if a matrix can be LU decomposed without actually finding the L, U?","I've seen quite a few problems like that. For example, suppose we have the following A matrix: \begin{pmatrix}
 5 & 1 & 1 & 1 & 0 &1\\ 
 2 & 6 & -1 & 0 & -1 &1\\ 
 {1} & {3} & {-9} & {2} & {-1} &1\\
 {2} & {3} & {4} & {12} & {-1} &0\\ 
 {1} & {1} & {1} & {2} & {9} &8\\ 
 {0} & {0} & {0} & {0} & {-3} &0
 \end{pmatrix} and the problem given is to find out without actually doing the calculations to find the L & U, that the matrix can be decomposed to a LU product (A=LU) without doing any row exchanges (which means there's no P matrix used (or P=I if you will)). The only hint given is that one should use the last row of the matrix to find out that the determinant of the matrix isn't 0. Now, as far as I understand: a) If the determinant of a A matrix is not 0, then the A matrix is invertible. b) If a A matrix is invertible and the determinants of the A[1...k, 1...k] matrices are not 0 (which makes those invertible as well), then the A matrix can be decomposed to LU. So, if per the suggestion, I use the last row to find the determinant of the matrix, due to the zeroes, I get detA=-3*detA$_{65}$ (where detA$_{65}$ is the determinant of the matrix A if we remove row 6 and column 5) right? Now that determinant still requires a bit of work (which troubles me I am not solving this right..), but anyway, if I continue the calculations, its value is non 0. But still that only proved that A is invertible. Now I have to find the determinants of 6 matrices: 1) \begin{pmatrix}5
\end{pmatrix} 2) \begin{pmatrix}
 5 & 1 \\ 
 2 & 6
 \end{pmatrix} 3) \begin{pmatrix}
 5 & 1 & 1\\ 
 2 & 6 & -1\\
 2 & 6 & -9\\
 \end{pmatrix} ....... and if none of those are 0, then and only then I can answer that the A matrix can be decomposed to LU, right? Now, that's quite a lot of work, which makes me think I am not solving correctly the problem. Any ideas? PS Excuse me for the crappy typesetting at times, this is my first time here and I did my best to learn and use LaTeX but I still have a lot to learn.","['matrices', 'linear-algebra']"
380435,Intuition behind Direct limits,"Let $R$ be a commutative ring and $x\in R$ be a nonzero divisor. Then i know that the direct limit of  $R\mapsto R\mapsto R\mapsto\cdots $, where each map is multiplication by $x$ is $R_x$, the localization of $R$ at ${1,x, x^2,...}$. Similarly the direct limit of $R/x^n\mapsto R/x^{n+1}\mapsto\cdots $, where maps are multiplication by $x$ is $R_x/R$. My Question: How does one guess what the direct limit of a given direct system is, once the guess is made, then one can go about proving it using the universal property. Can someone provide an intuition for direct limits, at least in the above 2 cases? Thanks","['homological-algebra', 'commutative-algebra', 'abstract-algebra']"
380445,Inverse image of Veronese like map,"The following is a very elementary question but I can't find the error: Denote $D$ the diagonal $\{[x_0:x_1],[x_0:x_1]\} \subset \mathbb P^1$x $\mathbb P^1$. Let $\phi: \mathbb P^1 \longrightarrow \mathbb P^2$ defined by  $\phi([t_0:t_1])=(t_0^2:2t_0 t_1:t_1^2)$ and let P be its image. Similar to the Veronese map, this is an isomorphism and we have $P = \{[u_0: u_1: u_2] | u_0 u_2 = \frac {u_1^2} 4\}.$ Let $i$ be the natural isomorphism $\mathbb P^1 \longrightarrow D \subset\mathbb P^2$. Let $\psi:\mathbb P^1$ x $\mathbb P^1 \longrightarrow \mathbb P^2$ be defined by $\psi([x_0:x_1],[y_0:y_1])= [x_0 y_0: x_0 y_1 + x_1 y_0 : x_1 y_1]$. One sees that $\psi(D) = P$. We have $\psi \big |_{D}=\psi \big |_{im(i)}$ is an isomorphism to $P$, because $\phi$ is and $\psi \circ i = \phi$ (and it's easy to write down the inverse morphism explicitely). But if I calculate it manually I get $\psi^{-1}(P) = V((x_0 y_1 - x_1 y_0)^2) \subset \mathbb P^1$x $\mathbb P^1$, which is 2 times the Diagonal $D$ (which must be true because we have a correspondence between biquadratic curves in $\mathbb P^1$x $\mathbb P^1$ and quadrics in $\mathbb P^2$). But this contradicts $\psi \big |_{D}$ being an isomorphism (and the latter in turn is used by an author to prove s.th., so I somehow hope it is not too far away from the truth / there is a way to fix his argument, but that's a different story).",['algebraic-geometry']
380455,A combinatorial identity related to Chebyshev differential equation,"Let $m,k$ be an positive integers with $k\le m$. Does anyone have a proof that $$\sum_{j=k}^m {2m+1\choose 2j+1}{j\choose k}=\frac{2^{2(m-k)}(2m-k)!}{(2m-2k)!k!}?$$
This is related to Chebyshev differential equation.","['analysis', 'discrete-mathematics', 'combinatorics']"
380475,Finding a generalization for $\int_{0}^{\infty}e^{- 3\pi x^{2} }\frac{\sinh(\pi x)}{\sinh(3\pi x)}dx$,"$\;\;\;\;$I was reading the introduction of Paul J. Nain's book ""Dr. Euler's fabulous formula"" where he talks about the sense of beauty in mathematics and quotes the G.N.Watson as saying that a particular formula gave him ""... a thrill which is indistinguishable from the thrill which I feel when I enter the Sagrestia Nuova of the Capelle Medicee and see before me the austere beauty of the four statues representing Day, Night, Evening, and Dawn which Michelangelo has set over the tombs of Guiliano de'Medici and Lorenzo de'Medici"" . The formula is
\begin{align*}
\int_{0}^{\infty}e^{-3\pi x^{2} }\frac{\sinh(\pi x)}{\sinh(3\pi x)}dx=\frac{1}{e^{2\pi/3}\sqrt{3}}\sum_{n=0}^{\infty}\frac{e^{-2n(2n+1)\pi}}{(1+e^{-\pi})^{2}\cdots(1+e^{-(2n+1)\pi})^{2}}
\end{align*}
I have a question relating this formula: Is it possible to get a generalization of the following form
\begin{align*}
\int_{0}^{\infty}e^{- m\pi x^{2} }\frac{\sinh(\pi x)}{\sinh(m\pi x)}dx
\end{align*}
where $3$ is replaced by $m$?","['residue-calculus', 'improper-integrals', 'sequences-and-series', 'integration', 'contour-integration']"
380497,"Integral, limit, sequence of functions","I'm not sure how to formulate the title, but here is a problem I've come across recently and I'm not sure how to go about solving it. Let $$P_n(x) = \frac{x^n(bx-a)^n}{n!}, \quad a,b,n \in \mathbb{N}.$$ Prove that $$\lim _{n \rightarrow \infty} \int_{0}^{\pi} P_n(x) \sin x d x = 0.$$ Could you help me with that?","['sequences-and-series', 'integration', 'real-analysis', 'limits']"
380500,"Prove that the number of pairs $(A,B)$ equals ${{n}\choose{i}}{{n-i}\choose{r-i}}{{n-r}\choose{s-i}}$","Prove that the number of pairs $(A,B)$ with $A\subseteq N_n, B\subseteq N_n, |A|=r, |B|=s, and |A\cap B|=i$ equals $$ {{n}\choose{i}}{{n-i}\choose{r-i}}{{n-r}\choose{s-i}}.$$ My teacher told me that I am supposed to give a proof using combinatorics (so not a purely algebraic one). What I did was draw a Venn-diagram with the sets A and B, and then I think you can interpret ${{n}\choose{i}}$ as the number of combinations from the intersection of A and B, ${{n-i}\choose{r-i}}$ as the combinations from $A - A\cap B$ and ${{n-r}\choose{s-i}}$ as the number of combinations from $B-A\cap B$ . However, I am not sure whether this is a complete proof. Could anyone please comment on my approach and/or suggest a different approach and then give the proof? Thank you in advance.","['elementary-set-theory', 'combinatorics']"
380507,Trig and algebra problem: Finding sides of a triangle,"Let $ABC$ be a triangle such that $\angle ACB = \pi/6$ and let $a,b,c$ denote the lengths of the sides opposite to $A,B,C$, respectively. What are the value(s) of x for which $a = x^2 + x + 1, b = x^2-1$ and $c = 2x+1$? I used law of cosines, then saw that I should apply the identity $a^2 + b^2 = (1/2)[(a+b)^2 + (a-b)^2]$, but I didn't know how to handle the remaining terms. (In other words, I got stuck early in the problem).","['trigonometry', 'algebra-precalculus']"
380514,General proof that a product of nonzero homogeneous polynomials is nonzero (under certain conditions).,"Background, Notation, Definitions : Given a set $X$, I define the set $M(X)$ of monomials with $X$-indeterminates to be the set of elements of $\omega^X$ having finite support. Given $m_0,m_1\in M(X)$, I define the operation $*$ on $M(X)$ by $$(m_0*m_1)(x):=m_0(x)+_\omega m_1(x).$$ $\langle M(X),*\rangle$ is then a commutative, cancellative monoid, with the zero element of $\omega^X$ as the identity. Given a ring $R$, it is then natural to define the set $R[X]$ of polynomials with $R$-coefficients and $X$-indeterminates to be the set of elements of $R^{M(X)}$ having finite support. We define the addition and multiplication operations $\oplus$ and $\odot$ on $R[X]$ in terms of the addition and multiplication operations $+$ and $\cdot$ on $R$ as follows: $$(p_0\oplus p_1)(m):=p_0(m)+p_1(m)$$ $$(p_0\odot p_1)(m):=\underset{m_0*m_1=m}{\sum_{m_0,m_1\in M(X)}}p_0(m_0)\cdot p_1(m_1).$$ Then $\langle R[X],\oplus,\odot\rangle$ is a ring. It will be commutative when $R$ is, with unity when $R$ has one. I define the function $\deg:M(X)\to\omega$ by $$\deg(m):=\sum_{x\in X}m(x),$$  and the function $\sigma:\bigl(R[X]\smallsetminus\{0_{R[X]}\}\bigr)\to\omega$ by $$\sigma(p):=\max\{\deg(m):m\in M(X),p(m)\ne0_R\}.$$ It is readily seen that $\deg(m_0*m_1)=\deg(m_0)+_\omega\deg(m_1)$ and that $\sigma(p_0\odot p_1)\le\sigma(p_0)+_\omega\sigma(p_1)$ whenever $p_0,p_1,p_0\odot p_1\ne 0_{R[X]}$. I define the set $H(R,X)$ of homogeneous polynomials with $R$-coefficients and $X$-indeterminates to be the set of all $p\in R[X]\smallsetminus\{0_{R[X]}\}$ such that $$\sigma(p)=\min\{\deg(m):m\in M(X),p(m)\ne0_R\}.$$ It is readily seen that $H(R,X)\cup\{0_{R[X]}\}$ is a sub-semigroup of $\langle R[X],\odot\rangle$ (a sub-monoid if $R$ is unital). The Actual Question : It seems clear to me that $R$ has the zero product property ($a\cdot b=0_R$ implies $a=0_R$ or $b=0_R$) if and only if $\langle H(R,X),\odot\rangle$ is a semigroup. In that case, the restriction of $\sigma$ to $H(R,X)$ should be a semigroup homomorphism--that is, $\sigma(h_0\odot h_1)=\sigma(h_0)+_\omega\sigma(h_1)$. Unfortunately, I have been banging my head against the wall trying to prove these for some time now. In particular, I'm having trouble showing that whenever $R$ has the zero product property, then $h_0\odot h_1\ne0_{R[X]}$ whenever $h_0,h_1\in H(R,X)$. I've tried to proceed by induction on the cardinalities of the supports of $h_0,h_1$, but I can't figure out how to make the induction step click. Any suggestions, hints, or nice proofs of this?","['ring-theory', 'group-theory', 'abstract-algebra', 'polynomials']"
380527,"If $\frac{\partial \varphi}{\partial x}=f(x,y),\frac{\partial\varphi}{\partial y}=g(x,y)$, what is $\varphi$?","Suppose we have a real-valued function $\varphi(x,y)$ such that
$$
\frac{\partial \varphi}{\partial x}=f(x,y)\quad\text{and}\quad\frac{\partial\varphi}{\partial y}=g(x,y)
$$
for some functions $f$ and $g$. How can we recover the function $\varphi$? Using the chain rule, we have
$$
d\varphi=\frac{\partial\varphi}{\partial x}dx+\frac{\partial\varphi}{\partial y}dy=f(x,y)dx+g(x,y)dy
$$
So maybe $\varphi$ can be found by
$$\varphi(x,y)=\int f(x,y)dx+g(x,y)dy$$
but I am not sure what this integral means. It seems like a line integral, but over what curve? What is an indefinite line integral?","['multivariable-calculus', 'partial-derivative', 'indefinite-integrals', 'partial-differential-equations']"
380531,"Minimizing the expectation over a set, wrt to the Gaussian measure","I have recently read a proof [1] where, at the last step, the authors use an inequality which basically amounts to a lower bound on
$\int_\mathbb{R} \mathbf{1}_A(x)|x| \phi(x)dx$, where $\phi$ is the Gaussian pdf ($\phi(x)=\frac{e^{-x^2/2}}{\sqrt{2\pi}}$) and $A$ is a Borel set subject to $\int_\mathbb{R} \mathbf{1}_A(x)\phi(x)dx = p$. The bound they use is $p^2/2$; I was wondering if this was tight (up to a constant factor), or if one could improve this to get better than a square dependence on $p$:
$$
\min_{A\in\mathcal{B}_\mathbb{R}} \int_\mathbb{R} \mathbf{1}_A(x)|x| \phi(x)dx\qquad\\
\text{s.t.} \int_\mathbb{R} \mathbf{1}_A(x)\phi(x)dx = p
$$ Does anyone know if a result of this type is known? Any help or suggestion is welcome. Clement. [1] Theorem 4 of Testing halfspaces In In Proc. 20th Annual Symposium on Discrete Algorithms (SODA (2009) by Kevin Matulef, Rocco A. Servedio, Ronitt Rubinfeld","['normal-distribution', 'measure-theory']"
380567,Bayesian learning,"Imagine we assume there are two different types of coins: Coin A: a fair coin, p(heads) = 0.5. Coin B: biased to heads at p(heads)=0.7. We then want to learn from samples which coin we are flipping. Assume a naive prior over the two coins, so we have a Beta distribution, $\beta_0(1,1)$. You flip the coin and see heads. Since you know the probability that coin A would generate heads is 0.5 and you know the probability that coin B would generate heads is 0.7, we update our distribution as: $$
\beta_1 = (1+\frac{0.5}{1.2},1+\frac{0.7}{1.2}) \approx (1.4167, 1.5833)
$$ Is this the correct way to update the distribution or will it improperly bias the distribution in some way?","['statistics', 'bayesian', 'statistical-inference']"
380582,"Finding poles, indicating their order and then computing their residues","I really don't understand the concept behind finding poles in Complex Analysis and I can't find anything on the internet or in books that helps me grasp the concept... The following are past exam questions that I'm looking at but don't know where to go with with them in order to find their poles, indicate their order to then compute their residues.. Any help would be greatly appreciated... $(i) f(z)=\dfrac{\sin z }{(z-1)\sinh z}$ $(ii)g(z)= \dfrac{\sin z}{z(z^2+4)}$","['singularity', 'complex-analysis']"
380588,Do these two sets of matrices form groups?,"Stimulated by some Physics backgrounds , consider the following two sets of matrices. Notations and definitions:Let $A,B$ be two complex $n\times n$ matrices, then $\left [ A,B \right ]\overset{\underset{\mathrm{def}}{}}{=}AB-BA$ and $ e^A\overset{\underset{\mathrm{def}}{}}{=} \sum_{m=0}^{\infty }\frac{A^m}{m!}. $ Let $M_1,M_2,M_3$ be three $n\times n$ Hermitian matrices, and they satisfy $[M_1,M_2]=iM_3,[M_2,M_3]=iM_1,[M_3,M_1]=iM_2$ identities, where $i=\sqrt{-1}$. Now define a set $X$ of unitary matrices:$X=\left \{ e^{i\alpha M_3}e^{i\beta  M_2}e^{i\gamma M_3} :\alpha,\beta,\gamma \in \mathbb{R}\right \},$ and another set $Y$ of unitary matrices:$Y=\left \{ e^{i(\alpha M_1+\beta  M_2+\gamma M_3)} :\alpha,\beta,\gamma \in \mathbb{R}\right \},$ where $i=\sqrt{-1}$ ( Note that the number indices of the Hermitian matrices $M$ are different in $X$ and $Y$ ). And my questions are as follows: (1) Is $X=Y$ ? (2) If (1) is true, is the set $X$ a group ? (3) If both (1) and (2) are true, is $X\cong SU(2)$ true ? Supplements: For concreteness, let's take a look at the following simple example. Consider the Physically called spin-$\frac{1}{2}$ ""Pauli"" matrices $M_1=\frac{1}{2}\bigl(\begin{smallmatrix}
 0& 1\\ 
 1&0 
\end{smallmatrix}\bigr),M_2=\frac{1}{2}\bigl(\begin{smallmatrix}
 0& -i\\ 
 i&0 
\end{smallmatrix}\bigr)$ and $M_3=\frac{1}{2}\bigl(\begin{smallmatrix}
 1& 0\\ 
 0&-1 
\end{smallmatrix}\bigr),$ and it's easy to find that $M_1^2+M_2^2+M_3^2=\frac{1}{2}(\frac{1}{2}+1)\mathbb{I}$, where $\mathbb{I}$ is a $2\times2$ identity matrix. In the above example, direct calculation of matrices $e^{i\alpha M_3}e^{i\beta  M_2}e^{i\gamma M_3}$ in $X$ shows that $X=SU(2)$ (then $X$ is a group), and it's also easy to verify that $Y\subseteq SU(2)$. So now the question is, is $SU(2)\subseteq Y$ too ? Thanks in advance.","['representation-theory', 'mathematical-physics', 'linear-algebra', 'quantum-mechanics', 'group-theory']"
380649,Partial Derivatives vs Implicit Differentiation,"The question is: Let $G(x,y)=x^2y^4-3x^4y$. (i) Find the first partial derivatives $G_x$ and $G_y$. (ii) Using (i) above, find $\frac{dy}{dx}$. (iii) If $G(x,y)=0$, confirm your answer in part (ii) above, finding $\frac{dy}{dx}$ using implicit differentiation.",['multivariable-calculus']
380672,Analogue of the Schwartz–Zippel lemma for subspaces,"Let $f : \mathbb{R}^n \to \mathbb{R}$ be a nonzero multivariate polynomial of total degree $d$ over the reals, and $S \subset \mathbb{R}$ be finite.  Pick a positive integer $k$, choose $y_1, \ldots, y_k$ randomly and uniformly from $S^n$, and consider the $k$-variable polynomial $$g(t_1, \ldots, t_k) = f(t_1 y_1 + \cdots + t_k y_k)$$ Question : Is there a nice upper bound on the probability that $g(t)$ is the zero polynomial? This is similar to the Schwartz-Zippel lemma , but instead of picking a single point we pick a random linear subspace.  Indeed, if $k = 1$, $f$ is homogeneous, and $0 \notin S$, it is exactly the Schwartz-Zippel lemma, and we have $$Pr(g=0) \le \frac{d}{|S|}$$ For general $k$, allowing only one $t_i$ to be nonzero at a time gives $$Pr(g=0) \le \frac{d^k}{|S|^k}$$ However, this bound seems very weak, since it ignores all the cross terms in $g$, so hopefully a much stronger bound exists.","['probability', 'polynomials']"
380684,Proving an invertible matrix which is its own inverse has determinant $1$ or $-1$ [duplicate],This question already has answers here : Prove that an involutory matrix has eigenvalues $\pm 1$ (6 answers) Closed 5 years ago . Let A be an invertible $n \times n$ matrix whose inverse is itself. Prove that $\det(A)$ is either $1$ or $-1$. I'm really lost in class. I don't even know where to start. Please help.,"['matrices', 'linear-algebra', 'involutions', 'determinant']"
380689,Fourier Transform calculation,"I am trying to calculate the Fourier Transform of
$$f(x)=\exp(-\frac{|x|^2}{2}).
$$
Thus, I am looking at the integral
$$
\hat{f}(u)=\int_{\mathbb{R}^n} \exp(-\frac{|x|^2}{2}) \cdot \exp(ix\cdot u) dx.
$$
I can't figure out how to evaluate this integral.  Am I trying the wrong approach to calculate the transform or should I be able the integral.  Note the integral is a Lebesgue integral. Thanks.","['fourier-analysis', 'functional-analysis', 'integration']"
380693,"The thought process of derivatives explained (intermediate calculus) ""derivatives with respect to what""","My intention here is to contribute, if there is a problem with my solution or explanation--if it is wrong--please add a comment and don't just down vote. My answer represents my understanding and I spent a lot of time writing it; it would be very helpful to know if there is a flaw so I may fix it or take down my answer so nobody learns a mistaken concept. I had asked a question on here previously about trying to find a deeper understanding of derivatives. There was just a missing link in the whole picture. My question can be found here . Recently I had an epiphany and developed a better understanding of derivatives and I'd like to share that here with an example problem. Since this is a question and answer format forum, I pose the question: ""When we take derivative, how do we know what we have to take them with respect to?"" Note that this information assumes that one already understands the general concept of a derivative... i.e. $f'(x) = \lim_{h\rightarrow 0 }    \frac{f(x+h) - f(x)}{(x+h)-x}$ and how a derivative finds the instantaneous change of a function","['calculus', 'intuition', 'derivatives']"
380755,Give an example of a continuous linear operator $\displaystyle\|T\|=\sup_{\|x\|\le1} \|T(x)\|$ such that the supremum not reached,"Let $T:X\longrightarrow Y$ be a continuous linear operator , $X \;,\;Y$ normed spaces with $$\|T\|=\sup_{\|x\|\le1} \|T(x)\|$$ Give an example of a continuous linear operator such that the supremum not reached $$\|T(x)\|<\|T\|\;\; ,\;\; \|x\|\le 1$$ If the space $X$ is finite dimensional the unit ball is compact then the supremum is reached Any hints would be appreciated.",['functional-analysis']
380767,Enumerating all antichains in a finite poset,"I have some reasonably small finite posets (on less than 20 points) and would like to iterate over all ""downsets"" in the poset, where a downset is a set closed under ≤ (so if x in X, and y ≤ x, then y in X). A downset can be specified (and for my purposes, is specified) by an antichain (a set of incomparable elements, the maximum elements of the downset). I would therefore like to iterate over all antichains in the poset. The poset is small enough to iterate over all subsets, but I think one can do much better than this. What are some efficient algorithms to iterate over the antichains of a finite poset? The poset can be given (at your choice) by its transitive reduction (“Hasse diagram” or “covering relation”) or by the list of principle downsets.","['order-theory', 'algorithms', 'combinatorics']"
380768,Functional equation $f(xy)=f(x)+f(y)$ and differentiability,"I want to prove the following claim: If $f:(0,\infty)\to\mathbb{R}$ satisfying  $f(xy)=f(x)+f(y)$, and if $f$ differentiable on $x_0=1$, then $f$ differentiable  for all $x_0>0$. Thank you.","['calculus', 'derivatives', 'functional-equations']"
380785,What does it mean to integrate with respect to the distribution function?,"If $f(x)$ is a density function and $F(x)$ is a distribution function of a random variable $X$ then I understand that the expectation of x is often written as: $$E(X) = \int x f(x) dx$$ where the bounds of integration are implicitly $-\infty$ and $\infty$. The idea of multiplying x by the probability of x and summing makes sense in the discrete case, and it's easy to see how it generalises to the continuous case.  However, in Larry Wasserman's book All of Statistics he writes the expectation as follows: $$E(X) = \int x dF(x)$$ I guess my calculus is a bit rusty, in that I'm not that familiar with the idea of integrating over functions of $x$ rather than just $x$. What does it mean to integrate over the distribution function? Is there an analogous process to repeated summing in the discrete case? Is there a visual analogy? UPDATE: I just found the following extract from Wasserman's book (p.47): The notation $\int x d F(x)$ deserves some comment. We use it merely
  as a convenient unifying notation so that we don't have to write
  $\sum_x x f(x)$ for discrete random variables and $\int x f(x) dx$ for
  continuous random variables, but you should be aware that $\int x d F(x)$  has a precise meaning that is discussed in a real analysis
  course. Thus, I would be interested in any insights that could be shared about what is the precise meaning that would be discussed in a real analysis course?","['statistics', 'probability', 'random-variables', 'integration']"
380798,Is any closed-form representation known for the sum $\sum\limits_{n=1}^{\infty}\frac{\mu(n)\log n}{n^2}$?,"Is any closed-form representation known for the sum $\sum\limits_{n=1}^{\infty}\frac{\mu(n)\log n}{n^2}$, where $\mu(n)$ is the Möbius $\mu$-function ?","['prime-numbers', 'closed-form', 'sequences-and-series', 'number-theory']"
380802,Minimum eigenvalue and singular value of a square matrix,How to show that the relationship $\left | \lambda_{min} \right | \geq \sigma_{min}$ holds between the minimum eigenvalue and singular value of a square matrix $A \in \mathbb{C}^{n \times n}$?,"['numerical-linear-algebra', 'matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
380819,A combinatorial identity with Pochhammer's symbol,"Let $m,k$ be an positive integers with $k\le m$. I am trying to prove $$\sum_{j=0}^k{\frac{1}{2}\choose k-j}\frac{2^{2j}(m+j)!}{(m-j)!(2j)!}=\frac{P(n,k)}{(2k)!}$$
where $n=2m+1$ and $P(n,k)=\prod_{i=0}^{k-1} (n^2-(2i)^2)$. We can use Pochhammer's symbol and write the left side as
$$(-1)^k\sum_{j=0}^k\frac{(-1/2)_{k-j}(m+1)_j(-m)_j}{(1/2)_j(k-j)!j!}$$
We can also write the right hand side as $$(-1)^k\frac{(-m-\frac{1}{2})_k(m+\frac{1}{2})_k}{(\frac{1}{2})_kk!}.$$ So I think the identity must follow from some identities in hypergeometric functions.  Does anyone see a way to do it?","['analysis', 'discrete-mathematics', 'hypergeometric-function', 'combinatorics']"
380823,"Calculus, dx on top of fraction?","I'm studying for a final, and I haven't seen any mention of any problem of this form in class or in my homework. I can't figure out how to go about solving this problem: $$\int^{e^6}_{1}{\frac{dx}{x(1+\ln(x))}}$$ What I was thinking is: $$\int{\frac{dx}{x(1+\ln(x))}}+C = \int{\frac{1}{x(1+\ln(x))}dx}+C =ln(ln(x)+1)+C $$ then solve for $$F(e^6) - F(1)$$ But I'm not so sure this is the correct approach. Can someone highlight why the dx is in such an unusual position?","['calculus', 'integration']"
380825,How do you orthogonally diagonalize the matrix?,"How do you orthogonally diagonalize the matrix A? Matrix A = $$
\begin{bmatrix}
1 & 1 & 1 \\
1 & 1 & 1 \\
1 & 1 & 1 
\end{bmatrix}
$$",['linear-algebra']
380843,Describe all ring homomorphisms,Describe all ring homomorphisms of: a) $\mathbb{Z}$ into $\mathbb{Z}$ b) $\mathbb{Z}$ into $\mathbb{Z} \times \mathbb{Z}$ c) $\mathbb{Z} \times \mathbb{Z}$ into $\mathbb{Z}$ d) How many homomorphisms are there of $\mathbb{Z} \times \mathbb{Z} \times \mathbb{Z}$ into $\mathbb{Z}$ Note: These were past homework questions and my professor already gave out answers. I just need someone to help me understand and approach this type of problem. Thank you.,"['ring-theory', 'abstract-algebra']"
380849,Spectrum of the unbounded operator $i\partial_x$,"I've been puzzling over this for some time now, and can't quite make my intuitions precise.  I need to find the resolvent set and spectrum of the operator $$
Lu=i\frac{du}{dx}
$$ taken to be (densely) defined over $L^2([0,\infty))$, and eventually its adjoint, which is the same operator but on the set (assuming I've computed it correctly): $$
\text{Dom}(L^*)=\{v\in L^2[0,\infty):v(0)=0\}
$$ The pointwise spectrum of $L$ is easy to compute: $(\lambda I-L)u=0$ is a simple ODE, whose solution along with the $L^2$ condition implies $$
\sigma_p(L)=\{\lambda=a+bi\in\Bbb{C}:b<0\}, 
$$the lower half-plane.  Now intuitively, since $\sigma(L)$ is a closed set, I expect $\rho(L)$ to be the upper half-plane, the residual spectrum to to be the real axis, and the continuous spectrum to be empty.  However I'm struggling to show this rigorously since $L$ is an unbounded operator, and all the theory I find pertains to bounded linear operators. So here are my questions: Is there a (somewhat) direct way to characterize the residual spectrum of an operator without explicitly computing $(\lambda I-L)^{-1}$? Or am I just being a whimp and should find $(\lambda I-L)^{-1}$? The adjoint clearly has no pointwise spectrum because of the domain restriction.  Does this mean its resolvent set will be all of $\Bbb{C}$ or am I missing something? Feel free to direct me to your favorite book on spectral/operator theory if necessary - I can't seem to find answers to my questions after looking in 4 or 5.  Thanks!","['operator-theory', 'spectral-theory', 'functional-analysis']"
380862,At least two people have the same birthday,"If there are 85 students in a statistics class and we assume that there are 365 days in a year, what is the probability that at least two students in the class have the same birthday? I tried solving it by taking into account the fact that it will be extremely difficult to solve for the probability of at least having the same birthday and started off by solving it in the complement fashion, where P(at least two people having the same birthday) = 1 - P(every person's birthday is unique), but have been trying to the possible numerator/denominator for this problem.","['permutations', 'birthday', 'probability']"
380866,conditional expectations for independent random variables,"I have a question regarding the conditional expectation. Any hint or help is appreciated! Consider $a,b,$c are random variables on probability space (X, $\Sigma$, $P$),all of them are integrable and furthermore, $a$ is independent of $c$ and $b$ is also independent of $c$. Then does the following claim hold? $$E(a|b,c) =_{a.s} E(a|b)$$ I plan to use the fact that $E(E(a|b,c)|b) = E(a|b)$, since $\sigma(b) \subset\sigma(b,c) $, but then I get stuck at showing $E(E(a|b,c)|b) = E(a|b,c)$. Any help or hint is appreciated!","['probability-theory', 'probability', 'conditional-probability']"
380870,Dieudonné complete and topologically complete are equivalent for every space $X$.,"How can we show that: For every topological space $X$ the following conditions are equivalent: A space $X$ is topologically complete if $X$ is homeomorphic to a closed subspace of a product of metrizable spaces. A topological space $X$ is Dieudonne complete if there exists a complete uniformity
on the space $X$ . Tychonoffness is a necessary condition to proof? Thanks.","['general-topology', 'uniform-spaces']"
380906,"Find the equation of the tangent line to the polar curve at given $(x,y)$.","Find the equation(s) of the tangent line(s) to the curve given $(x,y)$ point. $$r=1-2\sin(\theta )$$ at $(0,0)$.  I am not sure how to go about find the the tangent line. Do I need to convert from polar to rectangular? Thanks!",['calculus']
380918,Prove that the complement of $\mathbb{Q} \times \mathbb{Q}$. in the plane $\mathbb{R}^2$ is connected. [duplicate],This question already has answers here : Formal proof that $\mathbb{R}^{2}\setminus (\mathbb{Q}\times \mathbb{Q}) \subset \mathbb{R}^{2}$ is connected. (3 answers) Closed 11 years ago . Prove that the complement of $\mathbb{Q} \times \mathbb{Q}$. in the plane $\mathbb{R}^2$ is connected. I have no idea how can I do that. If $\mathbb{R} \setminus\mathbb{Q}$ is connected then the proof is easy which is not true. somebody help me please.thanks for your time.,"['general-topology', 'connectedness']"
380924,"Lipschitz functions in $\mathbb{R}^n, \ \ \mathbb{R}^m$, extension","I've found the following lemma : Let $\{x_1, . . . , x_k\}$ be a ﬁnite collection of points in $\mathbb{R}^n$
,
and let $\{y_1, . . . , y_k\}$ be a collection of points in $\mathbb{R}^m$, such that $$|x_i - x_j|\le |y_i - y_j| \ \ \ \ \ \  \forall i,j \in \{1,...,k\}$$. If $r_1, . . . , r_k$ are positive numbers such that $$\bigcap _{i=1} ^{k} \overline{B}(x_i, r_i) \neq \emptyset,$$ then $$\bigcap _{i=1} ^{k} \overline{B}(y_i, r_i) \neq \emptyset$$. My question is: how does this lemma imply that if we let
$F = \{x_1, . . . , x_k\} \subset \mathbb{R}^n$
, $ f : F \rightarrow \mathbb{R}^m$ be a $1$-Lipschitz map, let
$x \in \mathbb{R}^n$, set $r_i:= |x − x_i|$ and $y_i:= f(x_i)$, then by this lemma there exists a point $y \in \mathbb{R}^m$ such that $|y − f(x_i)| \le |x − x_i|$ for each $i$. It may be that it's a stupid question and this result is really obvious, but I would appreciate an answer anyway. Thank you.","['general-topology', 'convex-analysis', 'combinatorial-geometry', 'real-analysis']"
380942,A minor question about the Cantor Set,"I'm self teaching analysis and the second chapter is about some basic topology. According to the book ""Principles of Mathematical Analysis (3rd)"" from Walter Rudin,
the Cantor Set is constructed as follows, from what I know. Let $E_0$ be the interval $[0,1] \subset \mathbb {R}$.
Dividing this set in three equal parts and removing the inner segment $({1\over{3}},{2\over3})$, let $E_1$ be the union of intervals $[0,{1\over3}]\text{ and }[{2\over3},1]$.
Next we will take the inner segment of each intervals in $E_1$ and so on... The infinite set $P = \cap_{i=1}^{\infty} E_i $ is called the Cantor Set. I understand that $E_1 \supset E_2 \supset E_3 ...$ and $E_i$ is the union of $2^i$ intervals each with length $3^{-i}$. And I also understood why it will be a perfect set. However, this is the part that I couldn't quite understand from the book.
intuitively thinking I can see that P doesn't contain any segment $(a,b)$. The book says, ""No segment of the form"" $$({3k+1\over 3^m},{3k+2\over 3^m})$$ ""where k and m are positive integers, has a point in common with P. Since every segment $(a,b)$ contains a segment of this form, if $$3^{-m} < {b-a \over 6}$$ P contains no segment."" How did it come up with the number 6 ? Is it not enough to find a ""large enough value of m"" such that $3^{-m} < b-a$ ?  It would be most helpful if someone could explain it with some diagram.  Or if you are confident enough that you can help me out with just words, I am open to that, too.","['general-topology', 'analysis']"
380946,Generalizing Jitsuro Nagura's result: my resulting upper bound for the second chebyshev function is too low. What am I doing wrong?,"I've been reading through Jitsuro Nagura's classic proof that there is a prime between $x$ and $\frac{6x}{5}$ and it seems to me that it should be possible to improve on his upper bound for the second Chebyshev function. In Nagura's paper, he establishes the following inequality: $$\psi\left(x\right) - \psi\left(\frac{x}{1806}\right) \le T\left(x\right) - T\left(\frac{x}{2}\right) - T\left(\frac{x}{3}\right) - T\left(\frac{x}{7}\right) - T\left(\frac{x}{43}\right) - T\left(\frac{x}{1806}\right) < 1.0851x $$ where $T\left(x\right) = \log\Gamma\left(\lfloor{x}\rfloor+1\right)$ Then, he establishes an upper bound using: $$\psi\left(x\right) < 1.0851\left(x + \frac{x}{1806} + \frac{x}{1806^2} + \frac{x}{1806^3} + \ldots\right) < 1.086x$$ Using my analysis in this question and this question , and this effort to apply Stirling's formula in the same way as Nagura, then, for $x \ge 986$ , I am finding: $$T\left(\frac{x}{2}\right) - T\left(\frac{x}{3}\right) - T\left(\frac{x}{6}\right) < 0.321x$$ Applying the same approach as Nagura, I am finding: $$T\left(\frac{x}{2}\right) - T\left(\frac{x}{3}\right) - T\left(\frac{x}{6}\right) \ge \psi\left(\frac{x}{2}\right) - \sum_{m=1}^{\infty}\left[\psi\left(\frac{x}{6m-3}\right) - \psi\left(\frac{x}{6m-2}\right) + \psi\left(\frac{x}{6m}\right) - \psi\left(\frac{x}{6m+2}\right) \right] \ge \psi\left(\frac{x}{2}\right) - \psi\left(\frac{x}{3}\right)$$ Putting it all together, I come up with: $$\psi\left(\frac{x}{2}\right) < 0.321\left(x + \frac{x}{3} + \frac{x}{3^2} + \frac{x}{3^3} + \ldots\right) < \frac{3}{2}*0.321 = 0.4815x$$ Which, after seting $x = 2y$ , results in: $$\psi\left(y\right) < 0.4815\left(2y\right) = 0.963y$$ Considering the best known upper bound is $1.03883$ , I am certainly doing something wrong. Can anyone help me to figure out what's wrong with my analysis? Thanks, -Larry Update: I wrote a simple java app to check $\psi(x)$ .  I am calculating $\psi(1627) > 1.01363*(1627)$ .  Hopefully, this will lead me to the mistake that I made.  When I figure it out, I'll post it as part of this update. So far, my suspicion is that the $0.321x$ is wrong.  Based on $\psi(1627)$ , it should be greater than $0.67575x$ . I found the mistake.  :-) This is wrong: $$\psi\left(\frac{x}{2}\right) < 0.321\left(x + \frac{x}{3} + \frac{x}{3^2} + \frac{x}{3^3} + \ldots\right) < \frac{3}{2}*0.321 = 0.4815x$$ It should be: $$\psi\left(\frac{x}{2}\right) < 0.321\left(x + \frac{2x}{3} + \frac{2^2{x}}{3^2} + \frac{2^3{x}}{3^3} + \ldots\right) < \frac{3}{1}*0.321 = 0.963x$$","['number-theory', 'logarithms', 'chebyshev-function', 'factorial', 'gamma-function']"
380949,"Prove that the Complex plane is closed, open and perfect.","Prove that the Complex plane is closed, open and perfect. My intuition is destroyed by the fact that a set can be open and closed at the same time. 
The following is my understanding. open: If all points in set $E$ is interior to $E$, then $E$ is open. I think this means that all points $p$ in $E$ has a neighborhood that is a proper subset of $E$. closed: If every limit point of $E$ is a point of $E$, then $E$ is closed. I think this means that all neighborhoods of every limit point $p$ in $E$ contains a distinct point in $E$. Perfect: If $E$ is closed and if every point of $E$ is a limit point of $E$. I'm not quite sure I understand the difference between a point and a limit point... This reminds me, since the complement of an open set is closed, does that mean that the complement of the complex plane, the empty set, is neither open nor closed ?","['general-topology', 'analysis']"
380955,Confusion about cofinality,"I'm confused about the notion of the cofinality of a cardinal . Since I think the source of the confusion is the Von Neumann cardinal assignment , my first question is: Question 0 . Is there an article or book that purposely distinguishes between a cardinal and its associated initial ordinal? Anyway, for the duration of this question, lets adopt this distinction. Thus we have two order-isomorphic proper classes, $\mathrm{Ord}$ and $\mathrm{Card}$. And although we have retained the identification $[0,\alpha)=\alpha$ for $\alpha \in \mathrm{Ord}$, we have abandoned it for cardinals. Additionally, given cardinal numbers $\mu$ and $\nu$, lets write $[\mu,\nu)$ for the set of all cardinals $\kappa$ with $\mu \leq \kappa < \nu$. Furthermore, let $x \mapsto \underline{x}$ denote the unique order isomorphism $\mathrm{Ord}\rightarrow \mathrm{Card}$, so for example: if $\omega$ is the least infinite ordinal, then $\underline{\omega}$ is the least infinite cardinal. Also, let $\eta : \mathrm{Card} \rightarrow \mathrm{Ord}$ denote the proper class function that maps every cardinal number to its initial ordinal. And finally, for every subset $A$ of a well-ordered set, lets write $\mathrm{ord}(A)$ for the unique ordinal that is order-isomorphic to $A$. So in general, we have that $\mathrm{ord}(A) \in \mathrm{Ord}$. Now my understanding is that the cofinality $\mathrm{cf}(\alpha)$ of an ordinal $\alpha$ is defined as the least ordinal $\beta$ such that there exists a cofinal subset of $\alpha$, call it $B$, such that $\mathrm{ord}(B)=\beta$. Question 1 . Under these definitions, how does one define the cofinality of a cardinal number $\kappa$? Is it: The ordinal $\mathrm{cf}\,\mathrm{ord}[0,\kappa)$ The cardinal $|\mathrm{cf}\,\mathrm{ord}[0,\kappa)|$ The ordinal $\mathrm{cf}\,\eta({\kappa})$ The cardinal $|\mathrm{cf}\,\eta({\kappa})|$ Something else??? I honestly can't work it out.","['elementary-set-theory', 'cardinals', 'reference-request', 'ordinals']"
380983,Solutions to $e^x + x = 2$,"I am extremely new to mathematics, and I don't have much training except for the basics so please excuse my rather basic question. The question itself: If I have the relationship $e^x + x - 2 = 0$; and $k$ is the number of solutions in $[0,1]$
and $n$ is the number of solutions not in $[0,1]$ what is $k$? what is $n$? My Questions (sorry if they are many) (1) What is the proper name for this type of equation. It doesn't seem to be a function, just a relationship of one variable to some constants. (2) How do you tell how many solutions an equation like this has just from looking at it? It seems like if you have an equation like $x^2 + 2x + 5 = 0$; you have at least two solutions. But what about the $e^x$? How do you predict how many solutions there will be then? (3) Once I re-arrange the equation to $e^x + x = 2$; what algebraic steps could I follow if I wanted to find the exact solution?","['exponential-function', 'algebra-precalculus', 'roots']"
