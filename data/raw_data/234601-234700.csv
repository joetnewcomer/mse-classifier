question_id,title,body,tags
4903002,Functoriality for presheaves,"Let $\mathcal{C}$ be a small category. Functoriality for presheaves says that for any functor $u\colon\mathcal{C}\to\mathcal{D}$ the precomposition functor $u^*\colon PSh(\mathcal{D})\to PSh(\mathcal {C})$ has two adjoints $u_!, u_*$ on the left and on the right correspondingly, see SGA 4, Exposé I, Proposition 5.1 or ncatlab or stacks 1 , stacks 2 . It is a particular case of the Kan extension. (Here we consider only presheaves of sets.) These functors can be defined as follows: $$u_!F(Y)=\varinjlim_{Y\to u(X)} F(X)$$ $$u_*F(Y)=\varprojlim_{u(X)\to Y} F(X)$$ for any $Y\in \mathcal{D},\; F\in PSh(\mathcal{C})$ , see Theorem 2.3.3 on Kan extensions in Kashiwara-Schapira ""Categories and Sheaves"" (here the limits are reversed since we work with contravariant functors = presheaves). I try to understand this construction in the case of topological spaces. Let $f\colon Y\to X$ be a continuous map of topological spaces. Let $Op(X)$ , $Op(Y)$ be the categories of open subsets where morphisms are inclusions. Then there is a functor $u\colon Op(X)\to Op(Y)$ which sends $U\subset X$ to $f^{-1}U\subset Y$ . Then we get a functor $u^*\colon PSh(Y)\to PSh(X)$ which is the usual pushforward $f_*$ . The functor $$u_!F(V)=\varinjlim_{V\subset f^{-1}(U)} F(U)=\varinjlim_{f(V)\subset U} F(U)=f^{-1}F(V)$$ is the usual pullback for presheaves. However, I cannot unfold the definition of the second adjoint $u_*$ . By the general definition above, one should have $$u_*F(V)=\varprojlim_{f^{-1}(U)\subset V} F(U).$$ But then it is not clear how the restriction maps look like: for an inclusion $V\subset V^\prime$ of open subsets in $Y$ we should have a map $$u_*F(V^\prime)=\varprojlim_{f^{-1}(U)\subset V^\prime} F(U) \to \varprojlim_{f^{-1}(U)\subset V} F(U)=u_*F(V).$$ However, each $f^{-1}(U)$ contained in $V$ is contained in $V^\prime$ and not vice versa. So the map seems to be in the opposite direction $$\varprojlim_{f^{-1}(U)\subset V} F(U) \to \varprojlim_{f^{-1}(U)\subset V^\prime} F(U).$$ Thus, what we have constructed is not a presheaf of sets but rather a covarinat functor ${Op(Y)}\to Sets$ . I would be grateful if you could tell me where is my mistake.","['algebraic-geometry', 'kan-extensions', 'category-theory', 'sheaf-theory']"
4903029,Looking for alternative proofs of this statement about angles,"This is the theorem to prove. Below is my proof that I consider rather long and complex. The given data is on this drawing: Construct $\angle DCE = \angle DCB$ . The point $E$ on ray $CE$ is chosen in such way that $CE = CB$ , and that is always possible by segment construction axiom. Connect points $B$ , $E$ , and $D$ . $_\Delta CDB \cong _\Delta CDE$ by SAS, because $CD$ is their common side, $CB = CE$ by construction, $\angle DCB = \angle DCE$ by construction. Therefore $\angle DBC = \angle DEC$ , as they are opposite to side $CD$ of these triangles. Let $O$ be the intersection point of $AD$ and $CE$ . Also connect points $A$ and $C$ to construct a line $AC$ . $_\Delta ABC$ is isosceles because $AB = BC$ as given by the statement of the theorem. Then $\angle BCA = \angle BCA$ . Since $\angle BAD = \angle BCE$ , then $\angle ECA = \angle DAC$ as well. We have $AO = CO$ because $\angle OAC = \angle OCA$ implies $_\Delta AOC$ is isosceles. As $AD = CE$ , we get $AO + OD = CO + OE$ . As $AO = CO$ , we get $AO + OD = AO + OE$ , which implies $OD = OE$ , therefore $_\Delta OED$ is also isosceles. Even more, $\angle OED = \angle ODE = \angle OAC = \angle OCA$ . $_\Delta AED \cong _\Delta CDE$ by SAS because $AD = CE$ , $ED$ is their common side, and $\angle ADE = \angle CED$ . This implies $\angle EAD = \angle ECD$ , therefore $\angle EAB = 2\alpha - \alpha = \alpha$ , which implies $AE$ is on the angle bisector of $\angle DAB$ . $_\Delta DAB$ is isosceles since $AB = AD$ by theorem's statement. Therefore, angle bisector is also median and altitude. Then median and altitude of $_\Delta BED$ to side $BD$ also coincide, therefore $_\Delta BED$ is isosceles with $BE = ED$ . Since also $BD = DE$ , $_\Delta DEB$ is equilateral, therefore all internal angles of this triangle are equal to one another, $60^\circ each$ . $_\Delta AEB \cong _\Delta AED$ by SAS because $AE$ is their common side, $AB = AD$ , $\angle EAD = \angle EAB$ . Therefore, $\angle ABE = \angle ADE$ . As points $B$ and $O$ are both equidistant from points $A$ and $C$ , they lie on perpendicular bisector of $AC$ . Therefore, $BO$ is also median and angle bisector of $\angle ABC$ . But same goes for $_\Delta BED$ and its angle $\angle EBD$ . Then $\angle EBO = \angle DBO = 0.5\cdot 60^\circ = 30^\circ$ . By using the notation on the last image, $\angle ABC = \beta + 30^\circ + 30^\circ + \beta = 60^\circ + 2\beta$ . Consider the right triangle $_\Delta BCG$ . Its acute angles sum up to $90^\circ$ , therefore: \begin{align*}
30^\circ + \beta + \alpha + \alpha + \beta &= 90^\circ \\
2\alpha + 2\beta &= 60^\circ \\
\alpha + \beta &= 30^\circ \\
\beta &= 30^\circ - \alpha
\end{align*} Now we are ready to express $\angle ABC$ : $$
60^\circ + 2\beta 
= 60^\circ + 2(30^\circ - \alpha) 
= 60^\circ + 60^\circ - 2\alpha 
= 120^\circ - 2\alpha
$$ Which was to be proven. What are shorter alternatives to that proof? I'm considering trigonometry, too, but I would prefer good old elementary geometry.","['alternative-proof', 'euclidean-geometry', 'angle', 'geometry']"
4903061,Representation determined by traces,"Let $A$ be a unital algebra over the complex numbers and let $\pi,\pi':A\to M_n(\mathbb C)$ be two unital algebra homomorphisms. Assume both are surjective and their traces agree, i.e., $tr\ \pi(a)=tr\ \pi'(a)$ holds for every $a\in A$ . Does it follow that they are conjugate, i.e., there exists an invertible matrix $S$ with $\pi'(a)=S\pi(a)S^{-1}$ for every $a\in A$ ? If so, is it a classical result?","['representation-theory', 'linear-algebra']"
4903091,Expected value of 1/X^2 when X follows an inversed gamma distribution,"I am working on calculating the expected value of the reciprocal of the square of a variable $X$ that follows an Inverse Gaussian distribution with parameters $\mu$ (mean) and $\lambda$ (shape). The probability density function (PDF) of the Inverse Gaussian distribution is given by: $f(x; \mu, \lambda) = \left(\frac{\lambda}{2\pi x^3}\right)^{\frac{1}{2}} \exp\left(-\frac{\lambda (x-\mu)^2}{2\mu^2 x}\right)
$ for $x > 0$ . I am trying to find: $
E\left[\frac{1}{X^2}\right] = \int_{0}^{\infty} \frac{1}{x^2} f(x; \mu, \lambda) \, dx
$ which simplifies to: $
E\left[\frac{1}{X^2}\right] = \left(\frac{\lambda}{2\pi}\right)^{\frac{1}{2}} \int_{0}^{\infty} x^{-\frac{7}{2}} \exp\left(-\frac{\lambda (x-\mu)^2}{2\mu^2 x}\right) \, dx
$ I am unsure how to approach solving this integral and am wondering if there is a known closed-form solution or if it generally requires numerical methods for evaluation. Insights or references to relevant techniques or literature would be greatly appreciated.","['statistics', 'probability-distributions']"
4903097,Motivation for Hartshorne's formula for the $j$-invariant,"On p. 317 of [1], Hartshorne (and he is not the only one) conjures the $j$ -invariant of an elliptic curve out of the blue \begin{equation*}
    j=2^8\frac{(\lambda^2-\lambda+1)^3}{\lambda^2(\lambda-1)^2}
\end{equation*} where $\lambda$ is the parameter in the Legendre-form of the equation of the given elliptic curve. I know that $\lambda$ is the cross ratio of the four branch points when representing the given elliptic curve as a twofold branched cover of the projective line and that the above expression is cooked up in just the way given above as to make the different possible values of the cross ratio obtained by permuting the branch point by an automorphism unique, but is there a nice way to motivate the given form of it? [1] Hartshorne, R. ― Algebraic Geometry , Graduate Texts in Mathematics 52, Springer 1977.","['algebraic-geometry', 'elliptic-curves']"
4903111,Induced map on stalks is bijective for all $x\in X$ if and only if the morphism of presheaf is bijective for any open subset,"Claim:Let $X$ be a topological space and $\mathscr{F},\mathscr{G}$ be two presheaves on $X$ . Let $\varphi:\mathscr{F}\rightarrow \mathscr{G}$ be a morphism of presheaves. If $\mathscr{F},\mathscr{G}$ are both sheaves, then the induced maps on stalks $\varphi_x:\mathscr{F}_x\rightarrow \mathscr{G}_x$ is bijective for all $x\in X$ $\Leftrightarrow$ $\varphi(U):\mathscr{F}(U)\rightarrow \mathscr{G}(U)$ is bijective for all $U\subset X$ open. Question: I am mainly confused about the surjectivity of the only if direction. That is, assume $U\subset X$ open then for each $t\in \mathscr{G}(U)$ we need to find some $s\in \mathscr{F}(U)$ such that $\varphi(s)=t$ . The author claims for each $x\in U$ we can find an open neighbourhood $U^x$ of $x$ in $U$ and $s^x\in \mathscr{F}(U^x)$ such that $(\varphi_{U^x}(s^x))_x=t_x$ , where $(\varphi_{U^x}(s^x))_x,t_x$ denote the image of $\varphi_{U^x}(s^x)$ and $t$ under the map $\mathscr{F}(U)\rightarrow \mathscr{F}_x$ respectively. I don not know why this is true? Why it is not necessarily surjective for a larger open nbhd then after some suitable shrinking we can assume on a small open nbhd of $x$ the corresponding morphism between two sheaves is surjective. It is the second proposition in page 52 of Ulrich Görtz and Torsten Wedhorn's Algebraic Geometry I:Schemes.","['algebraic-geometry', 'sheaf-cohomology', 'category-theory', 'sheaf-theory']"
4903149,Conjecture: Generalization of the triangle inequality to exponents of the sides,"Let $(x,y,z)$ be the sides of a triangle whose vertices are uniformly random on the circumference of a circle. Experimental data using a simulation with $10^9$ trails for each tested value of $a \ge 1$ suggests that: When $a \ge 1$ then the probability that $x^a + y^a \ge z^a$ is $P\left(x^a + y^a \ge z^a\right) = \frac{2}{3} + \frac{1}{3a^2}$ ,  or equivalently if $x \le y \le z$ . Then $P\left(x^a + y^a \ge z^a\right) = \frac{1}{a^2}$ . Can this Conjecture be proved or disproved? Related question . Julia source code using Random
step = 10^9
while true
    a = 1
    while true
        f = 0
        for _ in 1:step
            angles = rand(3) .* 6.283185307179586
            vertices_x = cos.(angles)
            vertices_y = sin.(angles)
            push!(vertices_x, vertices_x[1])
            push!(vertices_y, vertices_y[1])
            
            x_diff = diff(vertices_x)
            y_diff = diff(vertices_y)
            side_lengths = sqrt.(x_diff.^2 .+ y_diff.^2)
            x, y, z = side_lengths
            
            if x^a +y^a >= z^a
                f += 1
            end
        end
        prob = f/step
        println((a, prob, prob / (2/3*(1 + 1/2/a^2))))
        
        a = round(a + 0.1, digits=10)
    end
end","['geometry', 'triangles', 'numerical-methods', 'inequality', 'probability']"
4903156,"Ricci tensor of an arbitary Riemannian bundle $(E,g')$","Consider a Riemannian manifold $(M,g)$ . One can then equip $TM$ with the Levi-Civita connection and talk about the curvature tensor $R \in \Gamma(\Lambda^2 T^*M \otimes \text{End}(TM))$ . The Ricci tensor will be the $(0,2)$ -tensor obtained by contracting $R$ with $g$ . What about if we have some arbitary bundle with a another Riemannian metric $(E,g')$ over $M$ equipped with a connection $\nabla$ . This gives us a way to talk about curvature $R_\nabla$ and hence we could in theory obtain something similar to the Ricci tensor, by contracting $R_\nabla$ with $g'$ right? Is this still called the Ricci tensor even when we don't consider the tangent bundle or what is this?","['riemannian-geometry', 'differential-geometry']"
4903171,Irreducible but not absolutely irreducible representations,"Let $\mathbb F_q$ be a field of $q$ elements where $q$ is an odd prime power. Let $G$ be a finitely generated group and $\rho:G \to \operatorname{GL}_2(\mathbb F_q)$ be an irreducible representation over $F_q$ which is not absolutely irreducible. Let $\operatorname{Frob}_q$ be the Frobenius map sending $x\in \overline{F}_q$ to $x^q\in \overline{F}_q$ . Why is $\rho$ of the form $V\oplus \operatorname{Frob}_q(V)$ , where $V$ is a 1-dimensional representation of $G$ over $\overline{\mathbb{F}}_q$ ? Here I think that $V$ corresponds to a group homomorphism $G\to \mathbb{F}_{q^2}^{*}$ because the characteristic polynomials of matrices in $ \operatorname{GL}_2(\mathbb{F}_q) $ is of degree 2. By assumption, $\rho$ is reducible over $\overline{F}_{q^2}$ , so it is expected to yield a splitting as a direct sum $V\oplus W$ . But what I don't understand is why the complement of $V$ is $W=\operatorname{Frob}_q(V)$ . Thanks for your help.","['galois-theory', 'number-theory', 'representation-theory', 'direct-sum']"
4903179,Relationship between a differential form and the tangent plane,"Consider a point $(1, 2, 3) \in \Bbb R^3$ , if we consider an exterior form of degree $1$ , given by $$w=\sum_{i=1}^3 a_{i} dx_{i}$$ So, for our case $$
w(1, 2, 3) = \sum_{i=1}^3 a_{i}(1, 2, 3) \, dx_{i(1, 2, 3)} := a_{1}(1, 2, 3) \, dx_{(1, 2, 3)} + 2 \, a_{2}(1, 2, 3) \, dy_{(1, 2, 3)} + 3 \, a_{3}(1, 2, 3) \, dz_{(1, 2, 3)}
$$ If we try to take the kernel of that application for that point, we could make a particular case and find the points $x_1,$ , $x_2$ and $x_3$ for which \begin{align*}
   dx_{(1, 2, 3)} (x_1, x_2, x_3)=0 &\implies dx_{(1, 2, 3)} (x_{1}(1, 0, 0)+x_{2}(0, 1, 0)+x_{3}(0, 0, 1))=0\\
    &\implies x_{1}dx_{(1, 2, 3)}(1, 0, 0)+x_{2}dx_{(1, 2, 3)}(0, 1, 0)+x_{3}dx_{(1, 2, 3)}(0, 0, 1)=0
\end{align*} Here, starting from kronecker's delta function, i.e. knowing that $dx_{i}(e_{j})=0$ if $i \neq j$ and $dx_{i}(e_{j})=1$ if $i = j$ Perhaps I could state that $0+x_2+x_3=0$ And it would get a value that belongs to the kernel of that application, say $v \in \mathbb{R}_{(1, 2, 3)}^3$ , we could state that $$w(p) \cdot v=0?$$ My main idea of all this is to consider the tangent plane of a surface associated to the point $(1, 2)$ and determine what relation has the kernel of the application, with that tangent plane searched. Any idea or suggestion that helps me to get this idea on track, it was an idea subtly mentioned by my professor, but I can't find the right formalization to express it. Thanks!","['multivariable-calculus', 'differential-geometry']"
4903204,closed form of $\int_{[0 ; 1]} \frac{\operatorname{Li}_3\left(-x^2\right)}{1+x} d x$,"Question: closed form of $$\int_{[0 ; 1]} \frac{\operatorname{Li}_3\left(-x^2\right)}{1+x} d x$$ My try to solve the integral $$
\begin{aligned}
& I=\int_{[0 ; 1]} \frac{\operatorname{Li}_3\left(-x^2\right)}{1+x} d x \\
& \text { - } \operatorname{Li}_{s+1}(z)=\frac{(-1)^s}{s !} \int_{[0 ; 1]} \frac{z \cdot \log ^s(t)}{1-t z} d t \\
& \rightarrow \operatorname{Li}_3\left(-x^2\right)=-\frac{1}{2} \int_{[0 ; 1]} \frac{x^2 \cdot \log ^2(t)}{1+t x^2} d t \\
& I=-\frac{1}{2} \iint_{[0 ; 1]^2} \frac{x^2 \cdot \log ^2(t)}{(1+x)\left(1+t x^2\right)} d t d x \\
& \log t=-u \rightarrow d t=-e^{-u} \\
& {[0 ; 1] \rightarrow \mathrm{R}^{+}} \\
& I=-\frac{1}{2} \iint_{[0 ; 1] \times \mathrm{R}^{+}} \frac{x^2 \cdot t^2 e^{-u}}{(1+x)\left(1+x^2 e^{-u}\right)} d u d x \\
& I=-\frac{1}{2} \sum_{n \geqslant 0} \iint_{[0 ; 1] \times \mathrm{R}^{+}} \frac{(-1)^n x^{2+2 n} \cdot t^2 e^{-u(n+1)}}{(1+x)} d u d x \\
& u(n+1)=\varphi \rightarrow d u=d \varphi /(n+1) \\
& I=-\frac{1}{2} \sum_{n \geqslant 0} \iint_{[0 ; 1] \times \mathrm{R}^{+}} \frac{(-1)^n x^{2+2 n} \varphi^2 \cdot e^{-\varphi}}{(n+1)^3(1+x)} d \varphi d x \\
& I=-\sum_{n \geqslant 0} \int_{[0 ; 1]} \frac{(-1)^n}{(1+n)^3} \cdot \frac{x^{2 n+2}}{1+x} d x \\
& \text { - } \int_{[0 ; 1]} \frac{\Psi^{2 \lambda+2}}{1+\Psi} \mathrm{d} \Psi=\frac{1}{2}\left[H_{n+1}-H_{n+1 / 2}\right] ; n>-3 / 2 \\
& I=\frac{1}{2} \sum_{n \geqslant 0} \frac{(-1)^{n+1}}{(1+n)^3} \cdot\left[H_{n+1}-H_{n+1 / 2}\right] \\
& \therefore \int_{[0 ; 1]} \frac{\operatorname{Li}_3\left(-x^2\right)}{1+x} d x=\frac{1}{2} \sum_{n \geqslant 0} \frac{(-1)^{n+1}}{(1+n)^3} \cdot\left[H_{n+1}-H_{n+1 / 2}\right] \\
& \rightarrow \int_{[0 ; 1]} \frac{\mathrm{Li}_3\left(-x^2\right)}{1+x} d x=-0,181596 \ldots \\
&
\end{aligned}
$$ is there any way to evaluate last Euler sum","['integration', 'calculus', 'euler-sums', 'definite-integrals']"
4903218,Proving the chromatic number of this graph is $4$,"I was required to prove that the following graph $G = (V, E)$ satisfies $\chi(G) = 4$ : Since $C_5 \subseteq G$ we have $\chi(G) \geq 3$ . Since $G$ is connected and $\Delta(G) = 5$ , Brook's theorem implies $\chi(G) \leq 5$ . However, I have not been able to advance any further. My approach was to construct sub-graphs of $G$ and derive contradictions from assuming proper colorings of $3$ and $5$ colors. I have not succeeded at this attempt. Any hint or solution is appreciated.","['graph-theory', 'coloring', 'discrete-mathematics']"
4903227,How to find the inverse Laplace transform of function $s\csc(2s)$?,"When dealing with one ODE, it happened to find the inverse Laplace transform of function $$
F(s)=\frac{s}{\sin(2s)}.
$$ I suppose it exists the inverse Laplace transform, but I could not find any standard formula from Laplace tables, either. I try to expand in Laurent series and found $$
\frac{1}{\sin(s)}={\frac {-2i{{\rm e}^{-is
}}}{{{\rm e}^{-2is}}-1}} 
$$ from here . But it seems incredibly difficult to proceed. Would someone has a simple way, please advise?","['laurent-series', 'functional-analysis', 'ordinary-differential-equations', 'laplace-transform']"
4903249,Stuck on Differential Geometry proof,"My concrete questions are (for context see below): Is is true that $i$ as below embeds $M$ in $T^*\mathbb{R}^n$ ? Is it true that $M$ is Lagrangian in $\mathbb{C}^n$ if and only if $i(M)$ is Lagrangian in $T^*\mathbb{R}^n$ ? Is it true that Theorem 4.3 implies that $$dh=\text{proj}_{d\psi}y\iff dh=(\sum_ky_k\dot\psi_k)d\psi$$ as I derived below? How can I obtain the identity stated by Harvey (quoted below)? Here is the context: In his book ""Spinors and Calibrations"", F.R. Harvey provides a definition of Lawlor necks (which I restate below as Definition 1 ) as $n$ -dimensional submanifolds of $\mathbb{C}^n\cong\mathbb{R}^{2n}$ , and then introduces an equivalent characterization by looking at intersections of Lawlor necks with $n$ -planes $P_{\theta}$ , which I define below. Definition. Let $\theta=(\theta_1,\dots,\theta_n)\in\mathbb{R}^n$ . Then we denote by $$P_\theta=\{(t_1e^{i\theta_1},\dots,t_1e^{i\theta_1})\in\mathbb{C}:t_k\in\mathbb{R}\}$$ the $n$ -plane in $\mathbb{C}^n$ obtained by rotating $\mathbb{R}^n$ by $e^{i\theta}$ . $\diamond$ Harvey remarks that the intersection of a Lawlor neck $M$ with $P_\theta$ , for any $\theta$ , is either empty or a compact hypersurface of $P_\theta$ (indeed, it can be easily shown that, if not empty, $M\cap P_\theta$ is an ellipsoid). In Theorem 7.78, Harvey proves that Lawlor necks are the only possible special Lagrangian submanifolds of $\mathbb{C}^n$ that admit this property. In his proof, Harvey claims the following (which I cannot quite follow): ~verbatim quote~ ""If $M$ is to consist of the union of hypersurfaces in a family of the $n$ -planes $P_\theta$ , and $M$ is to be Lagrangian, then $M$ must be of the form (set $w_j=R_je^{i\theta_j}$ ) $$M(\Gamma,h)=\left\{ w\in\mathbb{C}^n:\sum_{j=1}^nR^2_j\frac{\text{d}\theta_j}{\text{d}s}=\frac{\text{d}h}{\text{d}s}\right\}$$ for some curve $\Gamma$ in the $\theta$ -space and some function $h(s)$ defined on $\Gamma$ (here, $\theta(s)$ parametrizes $\Gamma$ ). This can be reforumlated as a general fact about Lagrangian submanifolds with degenerate (one-dimensional) projection onto one of the Lagrangian axis planes, using the alternate symplectic coordinates $p_j=\frac{1}{2}R^2_j$ and $q_j=\theta_j$ , $j=1,\dots,n$ . (Note that $\text{d}p_j\wedge\text{d}q_j=\text{d}x_j\wedge\text{d}y_j$ . See the article 'Calibrated Geometries' by Harvey-Lawson for a proof of $M_a=M(\Gamma,h)$ .)"" ~end of quote~ I am struggling with rigorously understanding how the identity $$\sum_{j=1}^nR^2_j\frac{\text{d}\theta_j}{\text{d}s}=\frac{\text{d}h}{\text{d}s}$$ is derived (what result from'Calibrated Geometries' by Harvey-Lawson is being used?). Here is what I understand so far: The alternate symplectic coordinates let us embed a Lawlor neck $M$ into $T^*\mathbb{R}^n\cong\mathbb{R}^n\times\mathbb{R}^n$ , via $$i:(r_ke^{i\theta_k})_{k=1}^n\mapsto((\theta_1,\dots,\theta_n),(r_1^2/2,\dots,r_n^2/2))$$ Since $\text{d}p_j\wedge\text{d}q_j=\text{d}x_j\wedge\text{d}y_j$ , $M$ is Lagrangian in $\mathbb{C}^n$ if and only if $i(M)$ is Lagrnagian in $T^*\mathbb{R}^n$ . Now $T^*\mathbb{R}^n$ is equipped with the natural projection $\pi:T^*\mathbb{R}^n\to\mathbb{R}^n$ . Clearly, we have $\pi(P_\theta)=\{\theta\}$ (where we view $P_\theta$ as a subset of $T^*\mathbb{R}^n$ via $i$ ). Since the intersection of a Lawlor neck $M$ with each plane $P_\theta$ is either empty or a ( $n-1$ dimensional) hypersurface, the projection $\pi:M\to\mathbb{R}^n$ is degenerate with constant rank $1$ . This, I beleive, lets us apply the following result from 'Calibrated Geometries' by Harvey-Lawson (Theorem 4.3): Theorem. Suppose $i(M)=X$ is an $n$ -dimensional Lagrangian submanifold of $T^{\\*}\mathbb{R}^n$ whose projection $\pi:X\to\mathbb{R}^n$ is degenerate with constant rank $p$ . Then there exists a unique pair of an $p$ -dimensional submanifold $M$ of $\mathbb{R}^n$ and a real-valued function $h$ on $M$ so that $X$ is the affine subbundle $A$ of $T^{\\*}\mathbb{R}^n$ obtained by translating the normal bundle $N(M)$ of $M$ in the cotagent bundle $T^{\\*}M$ by the exterior derivative $\text{d}h$ , i.e., $$A_x=N_x(M)+(dH)_x$$ for all $x\in M$ , where $H$ is some smooth extension of $h$ to the ambient space $\mathbb{R}^n$ . $\diamond$ In our case, the projection $\pi:i(M)\to\mathbb{R}^n$ has constant rank $1$ , so if $M$ is Lagrangian, there exists a $1$ -dimensional submanifold $\Gamma$ of $\mathbb{R}^n$ (say $\Gamma$ is parametrized by $\psi=(\psi_1,\dots,\psi_n):\mathbb{R}\to\mathbb{R}^n$ with $\vert{\psi}\vert\equiv1$ ) and a function $h:\Gamma\to\mathbb{R}$ (with $d_ph\in T^*\mathbb{R}^n$ ) so that, for $$(\psi_1(t),\dots,\psi_n(t),R_1,\dots,R_n)\in i(M)$$ we have that $(R_1,\dots,R_n)-d_{\psi(t)}h$ is an element of $N_{\psi(t)}(M)$ . Denoting by $d\psi$ the covector associated with $\dot\psi(t)$ , this is equivalent to $(R_1,\dots,R_n)-d_{\psi(t)}h\perp d\psi$ . Since $d\psi$ is paralell to $dh:=d_{\psi(t)}h$ , and $\vert{d\psi}\vert=1$ , this is equivalent to $$dh=\text{proj}_{d\psi}y\iff dh=(\sum_ky_k\dot\psi_k)d\psi$$ where $y=\sum_ky_kd\theta_k$ , $d\psi=\sum_k\dot\psi_k\cdot d\theta_k$ . I feel like this gets me somewhere near the identity $$\sum_{j=1}^nR^2_j\frac{\text{d}\theta_j}{\text{d}s}=\frac{\text{d}h}{\text{d}s}$$ But I am uncertain about whether my steps so far are correct, and what the full derivation looks like. I am especially concerned that $X=i(M)$ does not appear to be an affine subbundle of $T^*\mathbb{R}$ (its fibres $X_p$ are not linear subspaces of $T_p^*\mathbb{R}$ ), which seemingly contradicts Theorem 4.3. Since Harvey references the article by Harvey-Lawson as a whole, instead of pointing to a specific section, I am also not sure if Theorem 4.3 is the only relevant result. The article by Harvey-Lawson can be downloaded for free here . Definition 1. (Lawlor Necks) Let $n\geq2$ and $a=(a_1,\dots,a_n)$ be a vector in $\mathbb{R}^n$ with $a_k\geq0$ . We define $n$ functions $z^a_k\mathbb{R}\to\mathbb{C}$ as follows. First, set $$P^a:\mathbb{R}\longrightarrow\mathbb{R},\qquad y\mapsto\frac{1}{y^2}\left(\left(1+a_1y^2\right)\cdots\left(1+a_py^2\right)-1\right),$$ and, for $k\in\{1,\dots,n\}$ , $$r^a_k:\mathbb{R}\longrightarrow\mathbb{R},\qquad y\longmapsto\sqrt{a_k^{-1}+y^2},$$ as well as $$\theta^a_k:\mathbb{R}\longrightarrow\mathbb{R},\qquad y\longmapsto a_k\int_0^y\frac{\text{d}y}{(1+a_ky^2)\sqrt{P^a(y)}}$$ Then we define $z^a_k:\mathbb{R}\to\mathbb{C}$ as follows, interpreting $(r^a_k,\theta^a_k)$ as polar coordinates; $$z^a_k:\mathbb{R}\longrightarrow\mathbb{C},\qquad y\longmapsto r_k(y)\cdot e^{i\cdot\theta^a_k(y)}.$$ We now use the functions $z^a_k$ to define the following submanifold of $\mathbb{C}^n$ ; $$M_a=\left\{(t_k\cdot z^a_k(y))\in\mathbb{C}^n:y,t_k\in\mathbb{R},\sum_kt_k^2=1\right\}.$$ We call $M_a$ a Lawlor neck . $\diamond$","['symplectic-geometry', 'calibrated-geometry', 'riemannian-geometry', 'differential-geometry']"
4903253,Are there programs which compute integrals in $\mathbb{R}^n$?,"I look for a software which computes integrals like, for example, this one: $$\int_{B_R}\frac{|x|^3 dx}{(\varepsilon^2+|x|^2)^{n-1}},$$ where $\varepsilon>0$ and $R>0$ are not specific numbers like $1$ or $\pi,$ $B_R$ is the ball centered in the origin of radius $R$ of $\mathbb{R}^n$ and $n$ is a non-specific natural number. PS. I ask this because we have lots of programs which compute integrals with specific numbers in $\mathbb{R}$ , $\mathbb{R}^2$ and $\mathbb{R}^3,$ but not in an arbitrary $\mathbb{R}^n.$ I really appreciate any answers in advance.","['integration', 'indefinite-integrals', 'multivariable-calculus']"
4903269,Is every extension of by an Abelian Group isomorphic to a central extension?,"Suppose $A$ is an abelian group and $$0\to A\to H\to G\to 0$$ is exact. Does it follow that that this SES is isomorphic to one of the form $$ 0\to A\to H'\to G\to 0$$ such that $A$ is contained in the center $Z(H')$ of $H'$ ? I ask for the following reason: According to this article ,
there's a bijection between the second cohomology group $H^2(G, A)$ and the set of
equivalence classes of extensions of $G$ by $A$ . On the other hand, according to this Wikipedia article , there's a bijection between $H^2(G,A)$ and the set of equivalence classes of central extensions of $G$ by $A$ . Therefore, the above two facts seem to be contradictory if not every extension of $G$ by $A$ is equivalent to some central extension of $G$ by $A$ . However, this fact doesn't seem true to me. If this isn't true, then how can one reconcile the above two facts?
For example, $$H^2(\mathbb{Z};\mathbb{Z}) = H^2(K(\mathbb{Z},1);\mathbb{Z}) = H^2(S^1;\mathbb{Z}) = 0$$ so the second fact then tell us the only central extension of $\mathbb{Z}$ by $\mathbb{Z}$ is the trivial one $$0\to\mathbb{Z}\to\mathbb{Z}^{\oplus 2}\to\mathbb{Z}\to 0.$$ However the first fact then seems to be wrong, as for example $$0\to\mathbb{Z}\to\mathbb{Z}\rtimes\mathbb{Z}\to \mathbb{Z}\to 0$$ seems like an extension which I suspect isn't isomorphic to the trivial one, so the first fact would imply that $H^2(\mathbb{Z};\mathbb{Z})$ has at least two elements (the equivalence classes corresponding to both the extensions I just gave), a contradiction to the fact that $H^2(\mathbb{Z};\mathbb{Z}) = 0$ .","['general-topology', 'group-cohomology', 'algebraic-topology']"
4903273,Finding the area of a quadrilateral in this picture,"This was from a past exam we were given. I am stuck, but here is what I have so far. To find the area of EFGH, we can find the individual coordinates of E,F,G,H so we can find the distance between each vertex and finally compute the area. According to hint, I will centre $B(0,0)$ . Since $|AB| =2$ , then I label $A(0,2)$ . We were also given that $E$ has a height of $1$ . So I label $E(x,1)$ , where x is some unknown x coordinate. I was able to obtain x by using that the triangle ABE is equilateral, so all three sides are equal. Hence $|AB| = |BE| = 2$ . Also $|EG| = 1$ . Then the triangle BEG is a right angled triangle, so by pythagorean $x = \sqrt{3}$ . Hence $E(\sqrt{3}, 1)$ . Following this, we also have $G(\sqrt{3},0)$ . But now, I am stuck on finding $H$ and $F$ , as it seems they are not really given anything in the question to work with. Edit: I can try to find the equation of the line connecting B and E. That would give $y = \frac{1}{\sqrt{3}}x$ . However, it doesn't seem like we know either x or y coordinates.",['geometry']
4903285,Reversed Fubini's,"Assume we have a real valued function $F:\mathbb{R}^{n} \times (0, \infty) \to \mathbb{R}$ .
And assume that we have the function $ g: \mathbb{R}^{n} \to \mathbb{R} $ given by $$
g(x) = \int_{0}^{\infty} F(x,r) dr 
$$ Is Lebesgue measurable. can we conclude that $ F $ is also (n+1)-Lebesgue measurable as a function of $\mathbb{R}_{+}^{n+1}$ ?
If it helps, we have that $g \in L^{r}(\mathbb{R}^{n})$ for some $ r \in (0,\infty)$ .","['measure-theory', 'analysis', 'real-analysis', 'functional-analysis', 'fubini-tonelli-theorems']"
4903330,Density of which function space for a negative Sobolev space?,"Let $\Omega$ be a bounded domain in $\mathbb{R}^N$ (let us assume it has smooth boundary). We know that the Sobolev space $H_{-s}(\Omega)$ for a negative index $-s < 0$ can be defined in terms of duality i.e. $$
f \in H_{-s}(\Omega) \iff \|f\|_{-s,\Omega} := \sup_{g \in C^{\infty}_c(\Omega), \|g\|_{s,\Omega}=1} |\langle f,g\rangle| < \infty.
$$ Suppose now I want to define a different negative Sobolev space in the following way: $$
f \in H_{-s}^*(\Omega) \iff \|f\|^*_{-s,\Omega} := \sup_{g \in C^{\infty}(\bar{\Omega}), \|g\|_{s,\Omega}=1} |\langle f,g\rangle| < \infty.
$$ Then can we say that $C^{\infty}(\bar{\Omega})$ functions on $\Omega$ are dense in both $(H_{-s}(\Omega), \|.\|_{-s,\Omega})$ and $(H_{-s}^*(\Omega), \|.\|^*_{-s,\Omega})$ ? Any reference or proof will be highly appreciated. I think I know that for non-negative Sobolev indices $s \geq 0$ , $C^{\infty}(\bar{\Omega})$ functions are dense (in fact this may be a definition of Sobolev spaces of positive indices right ?) in both $H_{s}(\Omega) \equiv H_{s}^*(\Omega)$ (the norms are same then).
 
A related link can be found here .","['measure-theory', 'sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
4903335,Does complete and separable Wasserstein space imply the completeness of the base space?,"Also asked on MathOverflow. Let $(Z,d)$ be a metric space, and for $p\geq 1$ , consider a metric space $(W_p,d_{W^p})$ defined by The Wasserstein Space $\begin{align}W_p = \{\mu|\mu\textrm{ is a Borel probability measure on Z such that} \int_{Z}d(z_0,z)^p\mu(dz)<\infty \textrm{ for some }z_0 \} \end{align}$ and The Wasserstein distance $\begin{align} d_{W^p}(\mu,\nu) = \inf_{\pi}\left(\int_{Z\times Z}d(z,z')^p\pi (dz\times dz')\right)^{1/p}\end{align}$ where $\pi$ is a coupling between $\mu$ and $\nu$ i.e. a probability measure on $Z\times Z$ such that $\pi(A\times Z)=\mu(A), \pi(Z\times B)=\nu(B)$ for any measurable $A,B\subset Z$ . Let us assume that $Z$ is separable (since otherwise, something like Nedoma's pathology can show up and make things complicated). It is well known that if $Z$ is complete, then the Wasserstein space is also complete. Is the converse true? That is, I want to prove the following: Conjecture. Complete and separable Wasserstein distance implies $Z$ is complete (assuming $Z$ is separable). My Attempt. Google took me to Counter-example to the completeness of the Wasserstein metric , but this is about $Z$ complete $\Rightarrow$ W space is complete, so it is not really what I want. I considered a simple case $Z=(0,1)$ , and if the conjecture is true, the W space should be incomplete. To prove this, I took the sequence of Dirac measures $\{\delta_{1/n}\}$ , which is a Cauchy sequence in the W distance, but I couldn't prove that it does not converge. Maybe it converges to some exotic probability measure? I don't know. Edit 1 : According to this thesis , it seems that Theorem A.1, p238 says a topological space is complete if and only if the weak convergence of probability measures is complete. However, this is not directly applicable since the fact that the W distance metrizes the weak convergence is only proven for complete & separable spaces.","['complete-spaces', 'optimal-transport', 'probability-theory', 'metric-spaces']"
4903348,Can a connected planar graph have 10 vertices and edges? is this possible?,"Can a connected planar graph have 10 vertices and edges? is this possible? Using Euler’s formula, $V − E + F = 2$ . $10 − 10 + F = 2$ , Therefore $F = 2$ . Do I also need to use this formula: $2E$ $\geq$ $3F$ ? or Do I use $E \leq 3v-6$ ? I'm a little lost if this type of graph is possible or not and how to go from here.
Thanks!","['connectedness', 'graph-theory', 'education', 'planar-graphs', 'discrete-mathematics']"
4903349,"Why is $ \lim_{(x,y) \to (0,0)} \frac{\sin(xy)}{xy}$ defined while $\lim_{(x,y,z) \to (0,0,0)} \frac{\sin(xyz)}{xyz}$ is not?","I've found an exercise that compares the following limits: $$ \lim_{(x,y) \to (0,0)} \frac{\sin(xy)}{xy} \qquad\text{and}\qquad \lim_{(x,y,z) \to (0,0,0)} \frac{\sin(xyz)}{xyz}$$ The solutions suggests the first limit exists and is equal to 1, whereas the latter limit does not exist. My working is as follows: From a one-variable approach, it is known that $ \lim_{x \to 0} \frac{\sin(x)}{x} = 1$ . Thus, it is reasonable to suppose $ \lim_{\textbf{v} \to (0,0)} \frac{\sin||\textbf{v}||^2}{||\textbf{v}||^2}=1.$ It could be said by epsilon-delta further, that because $ \lim_{x \to 0} \frac{\sin(x)}{x} = 1$ , given $\epsilon > 0$ , we can find a $\delta > 0$ with $0 < \delta < 1$ , such that $0 < |x| < \delta $ implies $|\frac{\sin(x)}{x} - 1| < \epsilon$ . If $0 < ||\textbf{v}|| < \delta$ , then $0 < ||\textbf{v}|| < \delta^2 < \delta$ , and finally, $|f(\textbf{v}) - 1| = |\frac{\sin||\textbf{v}||^2}{||\textbf{v}||^2}-1| < \epsilon$ . I feel comfortable with this logic for two variables, however I am interested in why the logic fails when introducing a third variable. I predict it is largely due to how the variables behave but if someone could provide me with some intuition as to how to spot this behavioural shenanigans I would greatly appreciate it; Thank you in advance!","['multivariable-calculus', 'limits', 'calculus', 'epsilon-delta']"
4903362,Prove or Disprove: Is there a connected planar graph with an odd number of faces where every vertex has a degree of 6?,"Prove or Disprove: Is there a connected planar graph with an odd number of faces where every vertex has a degree of 6? I know, Theorem: In a connected planar graph where each vertex has the same degree of 6, the number of faces cannot be odd. Proof :
Let G be a connected planar graph with every vertex is degree 6. By Handshake lemma: $ ∑Deg(Vi) = 2E$ Since $Deg(V) = 6$ for all V, then $6V = 2E$ $E = 3V$ (Confused here) Using Euler's for a connected planar: $ V - E + F = 2$ (Confused on this part) Since V is an integar, 2V is even. Thus F is also even. Therefore by contradiction a connected planar graph with every vertex of Deg=6 CANNOT have an odd # of faces. QED. Is there a better way at proving this? Am I leaving out anything? I feel like i'm over thinking this.","['graph-theory', 'proof-writing', 'solution-verification', 'discrete-mathematics', 'planar-graphs']"
4903410,Distribution of $\frac{X_1 X_2}{\sum_{i=1}^n X_i^2}$,"I currently have a problem in deriving the distribution (or moments) of the random variable \begin{align*}
T = \frac{X_1X_2}{\sum_{i=1}^n X_i^2},\\
\text{where } X_i \sim N(0, 1).
\end{align*} I attempted to utilize the fact that $\sum_{i=1}^n X_i^2 \sim \chi_{(n)}.$ However, because the numerator and the denominator is not independent, I have encountered difficulty in proceeding. As far as I am aware, I have not found any known distribution (or moments) for the above random variable $T$ .","['statistics', 'probability-distributions']"
4903448,Area of a Quater-Circle with hyperbolic elements,"The actual question states the following; ""Find the mass of a Quater-Disc (in terms of R), in the first quadrant, of radius 'R' if density varies as D = xy"" My first thought was somehow turning this problem into another one in hyperbolic coordinates and integrating for the transformation of a circle there with density varying radially, but then I realised I can't do that because I don't know how to. I also thought about taking hyperbolic elements and the density function as xy=k where k goes from 0 to R/2 but I just couldn't figure out how to take elements that don't have an anchor for me to keep constant. I can visually grasp the problem statement and its intention but I fail to materialize it into equations I can evaluate.. Any help is appreciated.","['integration', 'multivariable-calculus', 'calculus']"
4903450,Combinatorics- What is wrong in this approach,"The question is- In an examination, a question paper consists of 12 questions divided into two parts i.e., Part 1 and Part 2, containing 5 and 7 questions, respectively. A student is required to attempt 8 questions in all, selecting at least 3 from each part. In how many ways can a student select the questions? I know that this can be done in this way- Selecting 5 questions from 1st part and 3 questions from 2nd part.
That will be in, ⁵C₅ × ⁷C₃ = 35 ways. Selecting 4 questions from 1st part and 4 questions from 2nd part. That will be in ⁵C₄ × ⁷C₄ = 175 ways. And at last Selecting 3 questions from 1st part and 5 questions from 2nd part. ⁵C₃ × ⁷C₅ = 210 ways. Total ways = 35 + 175 +210 = 420. But if the student selects 3 questions from 5 questions of 1st part, 3 from 7 question of 2nd part and 2 from the remaining 6 questions of union of 1st and 2nd part then there is a problem. If this happens then, ⁵C₃ × ⁷C₃ × ⁶C₂ = 5250. .
So, what is wrong with this approach? Why is the answer incorrect?","['combinations', 'combinatorics']"
4903539,how to evaluate $\int_0^{\infty} \frac{x \ln ^2\left(1-e^{-2 \pi x}\right)}{e^{\frac{\pi x}{2}}+1} d x$,"Question: how to evaluate $$\int_0^{\infty} \frac{x \ln ^2\left(1-e^{-2 \pi x}\right)}{e^{\frac{\pi x}{2}}+1} d x$$ MY try to evaluate the integral $$
\begin{aligned}
& I=\int_0^{\infty} \frac{x \ln ^2\left(1-e^{-2 \pi x}\right)}{e^{\frac{\pi x}{2}}+1} d x \\
& e^{-\frac{\pi x}{2}} \stackrel{\rightharpoonup x}{=}-\frac{4}{\pi^2} \int_0^1 \frac{\ln (x) \ln ^2\left(1-x^4\right)}{1+x} d x \\
& =-\frac{4}{\pi^2} \int_0^1 \frac{(1-x)\left(1+x^2\right) \ln (x) \ln ^2\left(1-x^4\right)}{1-x^4} d x \\
& =-\frac{4}{\pi^2} \int_0^1 \frac{\left(1-x+x^2-x^3\right) \ln (x) \ln ^2\left(1-x^4\right)}{1-x^4} d x \\
& =-\frac{4}{\pi^2}\left(\int_0^1 \frac{\ln (x) \ln ^2\left(1-x^4\right)}{1-x^4} d x-\int_0^1 \frac{x \ln (x) \ln ^2\left(1-x^4\right)}{1-x^4} d x\right. \\
& \left.+\int_0^1 \frac{x^2 \ln (x) \ln ^2\left(1-x^4\right)}{1-x^4} d x-\int_0^1 \frac{x^3 \ln (x) \ln ^2\left(1-x^4\right)}{1-x^4} d x\right) \\
&  \stackrel{x^4\rightharpoonup  x}{=}\frac{1}{4 \pi^2}(\underbrace{\int_0^1 \frac{x^{-\frac{3}{4}} \ln (x) \ln ^2(1-x)}{1-x} d x}_{I_1}-\underbrace{\int_0^1 \frac{x^{-\frac{1}{2}} \ln (x) \ln ^2(1-x)}{1-x} d x}_{I_2} \\
& +\underbrace{\int_0^1 \frac{x^{-\frac{1}{4}} \ln (x) \ln ^2(1-x)}{1-x} d x}_{I_3}-\underbrace{\int_0^1 \frac{\ln (x) \ln ^2(1-x)}{1-x} d x}_{I_4}) \\
&
\end{aligned}
$$ I don't know how to evaluate last $4$ integrals","['integration', 'calculus', 'definite-integrals', 'closed-form']"
4903544,Does a finite intersection (or union) generalise to an arbitrary one?,"Say we have a collection $\Omega$ of sets, and a statement $P(s)$ which can be either true or false depending on the input set $s$ . Say we take two arbitrary sets $a$ and $b$ in $\Omega$ and that for all $a,b\in\Omega$ , $P(a) \land P(b) \implies P(a \cap b)$ . Does this then imply that $\displaystyle \forall a\in\Omega\; P(a) \implies P\left(\bigcap_{s\in\Omega}s\right)$ ? Intuitively I can see how it would be true for collections with a finite or even countably infinite sizes, as you could just keep appending intersections with another element until you ""got them all"", like say if $\Omega = \{s_0,s_1,s_2,\cdots\}$ then you can do $$\displaystyle P(s_0) \Rightarrow P(s_0 \cap s_1) \Rightarrow P(s_0 \cap s_1 \cap s_2) \Rightarrow \cdots \Rightarrow P\left(\bigcap_{i\in\mathbb{N}}s_i\right)$$ but I don't necessarily know if this generalises to collections with uncountably infinite sizes since there really isn't that sort of inductive reasoning you can do to recursively append intersections when you're in the uncountably infinite. Does this intuitive implication hold true for collections of any size?","['elementary-set-theory', 'set-theory']"
4903579,Analyzing Cumulative Distribution Functions in Sampling Without Replacement vs. With Replacement,"I am studying a population of $N$ bits, comprising $K$ ones and $N-K$ zeros. For sampling $n$ bits without replacement, the situation conforms to a hypergeometric distribution. The sum of these $n$ bits, $S_n$ , yields a mean of $n\frac{K}{N}$ and a variance of $n \frac{K}{N} \frac{N-K}{N} \frac{N-n}{N-1}$ . Conversely, sampling $n'$ bits with replacement aligns with a binomial distribution, with the sum $S_{n'}$ having a mean of $n'\frac{K}{N}$ and a variance of $n' \frac{K}{N} \frac{N-K}{N}$ . For my analysis, I plotted the cumulative distribution functions (CDFs) for the normalized sums $\frac{S_n}{n}$ and $\frac{S_{n'}}{n'}$ , considering values of $n'$ within the range $\left[n,\lfloor n\frac{N-1}{N-n}\rfloor\right]$ . I observed that for normalized sums exceeding $\frac{K}{N}$ , the binomial CDF consistently lies below the hypergeometric CDF. The trend is longer followed for $n'>n\frac{N-1}{N-n}$ . It is noted that the variance of the normalised hypergeometric distribution is lower than that of the binomial distribution if $n'<n\frac{N-1}{N-n}$ . If $X$ is a hypergeometric distribution with n draws without replacement from a population of size $N$ with $K$ successes and $Y$ is a binomial distribution $B(n',K/N)$ , then what is the maximum $n'$ for which $F_Y(f n')\leq F_X(f  n)$ for $f\geq K/N$ ? . I suppose that the maximum $n'= \lfloor n\frac{N-1}{N-n}\rfloor$ . Heres an animation for $\frac{K}{N}=0.5$ , with $N=50$ where the number of binomial trials is fixed at $n'=n\frac{N-1}{N-n}=21$ and number of hypergeometric trials is fixed at $n=15$ . The portion marked green is the region where the normalized sums are greater than $p=\frac{K}{N}$ . In this region the binomial CDF is below the hypergeometric CDF. I'm curious if this relationship between the distributions' CDFs is a recognized phenomenon. Does anyone know of relevant research articles on this topic? Additionally, here’s the Mathematica code used for generating these plots, adjustable for different $p=K/N$ values: Manipulate[Nx = 10^2;
 n = 30;
 x = p Nx;
 ListPlot[{Table[{k/Floor[binomialtrials], 
     CDF[BinomialDistribution[Floor[binomialtrials], p], k]}, {k, 1, 
     Floor[binomialtrials]}], 
   Table[{k/n, 
     CDF[HypergeometricDistribution[n, Floor[x], Nx], k]}, {k, 1, 
     n}]}, Joined -> True, PlotRange -> All, 
  PlotLegends -> {""bin"", ""hype""}, 
  Epilog -> {RGBColor[0, 1, 0, 0.25], Rectangle[{p, 0}, {1, 1}], Red, 
    Line[{{p, 0}, {p, 1}}]}], {binomialtrials, n, n (Nx - 1)/(Nx - n),
   1}, {p, 10^-2, 1}] Does anyone have insights or references which might explain this pattern? EDIT Let $h(x;n,N,K)$ denote the probability mass function of the hypergeometric distribution and $b(x;n,p)$ that of binomial distribution, where $p=K/N$ .I need to compare the hypergeometric distribution and the modified binomial distribution, where the number of samples $n'=a n$ , where $a= \frac {N-1}{N-n}$ .Denoting $x'=a x $ , let us first figure out the ration $\frac{h(x;n,N,K)}{b(x';n',p)}$ . Note that in general $x'$ and $n'$ need not be integers. For simplicity lets start by assuming they are. Now we can compare the probabilities. $$
\begin{aligned}
\frac{h(x;n,N,K)}{b(ax;an,p)}&=&\frac{b(x;n,p)}{b(ax;an,p)}\frac{h(x;n,N,K)}{b(x;n,p)}\\
&=&\frac{{n\choose x}p^x(1-p)^{n-x}}{{an\choose ax}p^{ax}(1-p)^{a(n-x)}}\frac{h(x;n,N,K)}{b(x;n,p)}\\
&=& \frac{n!}{x!(n-x)!}\frac{(ax)! (a(n-x))!}{(an)!}p^{x-ax}(1-p)^{(n-x)-(a(n-x))}\frac{h(x;n,N,K)}{b(x;n,p)}\\
\end{aligned}
$$ Applying stirlings approximation $n!\sim \sqrt{2 \pi n}\left(\frac{n}{e}\right)^n$ , we get, $$
\begin{aligned}
\frac{h(x;n,N,K)}{b(ax;an,p)}&\sim&\sqrt{a}\left(\frac{(1-x/n)^{n-x}(x/n)^{x}}{(1-K/N)^{n-x}(K/N)^{x}}\right)^{a-1} \frac{h(x;n,N,K)}{b(x;n,p)}\\
&\sim& \sqrt{a}\left(\left(\frac{N}{n}\right)^n\left(\frac{x}{K}\right)^x\left(\frac{n-x}{N-K}\right)^{n-x}\right)^{a-1}\frac{h(x;n,N,K)}{b(x;n,p)}\\
\end{aligned}
$$ I'm stuck here. My goal here is to proceed similar to this answer by LPZ .","['cumulative-distribution-functions', 'probability-distributions', 'probability', 'upper-lower-bounds']"
4903607,'Integrating' a matrix times a gradient,"Suppose $f:\mathbb{R}^n\to \mathbb{R}$ is a differentiable function such that $\nabla f = g$ , where $g:\mathbb{R}^n\to \mathbb{R}^n$ . Further let $A\in \mathbb{R}^{n\times n}$ . Does there always exist a function $h:\mathbb{R}^n\to \mathbb{R}$ such that $\nabla h = Ag$ ? If so, can it be recovered from $f$ ? Feel free to make any assumptions on $A$ .",['multivariable-calculus']
4903610,$f(x)=\sqrt{\frac{x-1}{x-3}}$ and $g(1)=e$ which of the following options is/are correct?,"Multiple Choice Question : In a question, a student was given to find the derivative of the product of two functions $'f'$ and $'g'$ . The student by mistake thought $(fg)'=f'\cdot g'$ for this question and co-incidentally got the correct answer. Given that $f(x)=\sqrt{\frac{x-1}{x-3}}$ & $g(1)=e$ which of the following options is/are correct? (a) $g(x)$ is discontinuous at one point. (b) $\lim_{x\to \infty} g(x)=1$ (c) $\lim_{x\to \alpha} \frac{x^3-8}{x-2}=12$ where $\alpha$ is number of point of discontinuity of $g(x)$ (d) $g(x)$ is discontinuous at two points. My Solution : With $f(x)=\sqrt{\frac{x-1}{x-3}}$ , we can see $f(x)$ is discontinuous at $x=3$ and $f'(x)=\frac{-1}{(x-3)\left(\sqrt{(x-1)(x-3)}\right)}$ so $f'(x)$ is discontinuous at $x=1,3$ Now according to question $f'(x)g'(x)=f(x)g'(x)+g(x)f'(x)$ $\implies g'(x)\left(f'(x)-f(x)\right)=g(x)f'(x)$ $\implies g'(x)\left(\frac{-1}{(x-3)\left(\sqrt{(x-1)(x-3)}\right)}-\sqrt{\frac{x-1}{x-3}}\right)=g(x)\left(\frac{-1}{(x-3)\left(\sqrt{(x-1)(x-3)}\right)}\right)$ $\implies g'(x)\left(x^2-4x+4\right)=g(x)$ After solving above differential equation and setting $g(1)=e$ , I am getting $g(x)=e^{\frac{1}{2-x}}$ which is discontinuous at $x=2$ My Doubt : (i) Since $f'(x)$ is discontinuous at $x=1,x=3$ so I think $g(x)$ should be discontinuous at $x=3$ too. because We are getting $g(x)$ after solving $f'(x)$ (ii) Is $f'(x)$ is discontinuous at $x=1,3$ correct or should I say it is discontinuous at $x=1$ because $x=3$ is not in domain of $f(x)$","['ordinary-differential-equations', 'continuity', 'calculus', 'solution-verification', 'derivatives']"
4903628,Extension of C1 functions,"I studying the extension problem for classes of function $C^0,C^1,D^1$ ( $D^1=$ class of derivable function).
For $C^0$ function there is Tietze theorem and for $D^1$ function there is Jarnik theorem (rediscovered by G. Petruska and M.Laczkovich-https://math.wvu.edu/~kciesiel/prepF/129.DifferentiableExtensionThm/129.DifferentiableExtensionThm.pdf). I pose attention on $C^1$ functions. I know that: exists a function $f\in C^1(X)$ on a perfect set $X ⊂ \mathbb{R}$ with no has extension $F \in C^1(\mathbb{R})$ . I'm looking for a necessary and sufficient condition for existence of a extension of $f\in C^1(X)$ where $X\subseteq\mathbb{R}$ is perfect. I have found a very general Whitney's theorem that i want adapte to monodimensional case.
I ask: it's true that $f\in C^1(X)$ is extendible to $F\in C^1(\mathbb{R})$ iff $\forall \varepsilon>0$ $\exists\delta>0$ t.c. $\lvert  f(x)-f(y)-f'(y)(x-y)\rvert<\varepsilon\lvert  x-y\rvert$ $\forall x,y\in P$ , $\lvert x-y\rvert<\delta$ ? Is this correct? Can someone kindly show me a reference or an idea of ​​the proof (aslike Jarnik?) of this property?","['continuity', 'question-verification', 'derivatives', 'real-analysis']"
4903633,Blowing Up along Reduced vs Non-Reduced Subschemes,"In Eisenbud's book, 'The Geometry of Schemes' (see Proposition IV-40), he demonstrates a connection between blowing up schemes along reduced and non-reduced subschemes. Specifically, he illustrates that when blowing up $\mathbb{A}^2$ along the origin (reduced) and along the double point (non-reduced), the resulting schemes intersect after blowing up the nonsingular point in the former case and at the singular point in the latter. How does the choice between blowing up along a non-reduced versus a reduced subscheme impact the resulting scheme's geometry and practical applications, and what insights does it provide into the intersection behavior of the blown-up schemes? Eisenbud's explains, before the proof of the proposition, that the non-reduced case ""preserves"" more information: ""the lines through the origin in the plane are not made disjoint"" after the blow up. So  useful properties like the curvature are not effected (from what I understand at least). Do you know any other similar examples or any useful facts/information about this that would help me understand it better ?","['complex-geometry', 'algebraic-geometry', 'blowup', 'schemes']"
4903664,Particular solution of this second order differential equation,"I am a bit stuck on the following second order differential equation, using the method of undertermined coefficients. $$y'' + 3y' + 2y = xe^{-x}$$ The homogenous solution is easy to find, but I run into some issues with the particular solution. $y = Axe^{-x}$ doesn't seem to be a good enough guess, but I am not sure why? Since it doesn't appear in the homogenous solution I thought it would be independent from it. What is a better particular solution to get started with this?","['calculus', 'ordinary-differential-equations']"
4903680,How do we show that $\lim_{x\to0}(1+x)^{\frac{1}{x}}$ is a finite number,"I'm in high school I always wonder why does the below limit $$ \lim_{x\to0}(1+x)^{\frac{1}{x}} \tag{1}$$ necessarily converges to a finite number the places where I searched in the internet I found that it's a definition but why does it really needs to converge to a specific number I searched for it in many places some of the explanations which I found on quora ,YouTube and etc some said that we can just verify it by plugging in some small number some were kind of circular proof only like they took $\ln$ in expression (1) then they used L hospitals rule but as we know while finding the derivative of the log function we ourself assume that the limit(1) is a Constant and then we proceed. Also another way I thought was to consider $(1+\frac{1}{x})^{x}$ as a function I differentiated it and we clearly see as $x \to \infty$ it's slope tends to 0 thus it must be a constant but again in between I had to differentiate the log function so I want to ask that is there any way to really show the (1) approaches a finite number. Or do I need some more mathematical knowledge to do it?",['limits']
4903689,Defining a custom function,"The Problem Define a function $f:\mathbb{R\times R\rightarrow R}$ which satisfies the following properties: $$\frac{\partial f(x,k)}{\partial x}=0\text{ at }x=0$$ $$\forall k\in\mathbb{R}:f(1,k)=1$$ $$\forall x\in[0,1]:\lim_{k\rightarrow+\infty}f(x,k)=x$$ The function also has to possess $\mathbb{C}^{\infty}$ smoothness , i.e, it should be infinitely differentiable, with respect to the first variable. The Context I figured that anyone with a graphing calculator can go about plotting graphs, if the equation for it is given (at least for most well-behaved equations). However, creating a custom function, given only a sketch of how its plot should look seemed interesting. My target was a function $f(x,k)$ with $k$ being a tunable parameter. Its plot had to look like this: Basically, the function is anchored at the point $(1,1)$ , has a slope of $0$ at $x=0$ , and increasing the value of $k$ makes it look closer to $y=x$ . An Example $$f\left(x,k\right)=\frac{2}{\pi}\cos^{-1}\left(\frac{1}{1+e^{-k}}\cos\left(\frac{\pi x}{2}\right)\right)$$ This was a function that I came up with. Here's the Desmos graph. Finally I am looking for more functions that satisfy the given criteria, hoping that they will lead to more insight into this graph-to-function type of problems. While functions related to the example case are OK of course, I am looking for more ways to approach the question at hand.","['graphing-functions', 'smooth-functions', 'functions', 'limits', 'recreational-mathematics']"
4903708,"Given a quotient map $p:X \to Y$, when is $p \times id_Z: X \times Z \to Y \times Z$ a quotient map?","Given a quotient map $p:X \to Y$ , when is $p \times id_Z: X \times Z \to Y \times Z$ a quotient map?  As shown in another question , it is sufficient for $Z$ to be locally compact. I'm now wondering about conditions on $X$ and $Y$ . I know of two As mentioned in the same question, the condition that $Y \cong X/A$ for $A$ a compact subspace of $X$ is also sufficient (and that the map $p$ is the induced one). If $X$ and $Y$ are compact Hausdorff, then it also holds. What are some other conditions? Ideally, I'd like for the two above conditions to be implied by only one condition. Maybe the first one implies the second one, though I'm not seeing this.",['general-topology']
4903751,"Unambiguous derivative notation in Spivak's ""Calculus on Manifolds""","I don't understand Spivak's comment at the end that $f$ means something different on the two sides of the equation. Don't they both refer to the same function? Also, the expression $D_1(f \circ (g, h))$ isn't clear about which variable should be first. The first var of $f$ is $u$ , but the first variable of $g, h$ is $x$ . So I'm wondering what that statement means since this notation purports to remove ambiguities. I'm self-studying to prepare for grad school after a long gap, so I don't have a professor to consult. Thank you for any advice.","['notation', 'multivariable-calculus', 'calculus', 'manifolds']"
4903789,evaluation of $\sum_{n=1}^{\infty} (-1)^{n-1} \frac{H_{n} H_{n+1}^{(2)}}{(n+1)^{2}}$ and other Euler sums,"I was trying to evaluate this famous integral $$\int_{0}^{1} \frac{\ln (x) \ln^{2}(1+x) \ln(1-x)}{x} \ dx $$ Here is my attempt so solve the integral \begin{align}
&\int_{0}^{1} \frac{\ln (x) \ln^{2}(1+x) \ln(1-x)}{x} \ dx = 2 \int_{0}^{1} \frac{\ln (x) \ln(1-x)}{x} \sum_{n=1}^{\infty} (-1)^{n-1} \frac{H_{n}}{n+1} x^{n+1} \ dx \\
&= 2 \sum_{n=1}^{\infty} (-1)^{n-1} \frac{H_{n}}{n+1} \int_{0}^{1} x^{n} \ln(x) \ln(1-x) \ dx \\
&= 2 \sum_{n=1}^{\infty} (-1)^{n-1} \frac{H_{n}}{n+1} \frac{\partial }{\partial a \partial b} B(a,b) \Big|_{(a=n+1,b=1)} \\
&= 2 \sum_{n=1}^{\infty} (-1)^{n-1} \frac{H_{n}}{n+1} B(n+1,1) \Big [ \Big( \psi(n+1)-\psi(n+2) \Big) \Big(\psi(1)-\psi(n+2) \Big)-\psi'(n+2)\Big] \\
&= 2 \sum_{n=1}^{\infty} (-1)^{n-1} \frac{H_{n}}{(n+1)^{2}} \Big[ (H_{n} -H_{n+1} ) (-H_{n+1}) - \frac{\pi^{2}}{6} + H_{n+1}^{(2)} \Big] \\
&= 2 \sum_{n=1}^{\infty} (-1)^{n-1} \frac{H_{n}}{(n+1)^{2}} \Big[\Big(-\frac{1}{n+1} \Big) (-H_{n+1}) - \frac{\pi^{2}}{6} + H_{n+1}^{(2)} \Big] \\
&= 2 \sum_{n=1}^{\infty} (-1)^{n-1} \frac{H_{n} H_{n+1}}{(n+1)^{3}} - \frac{\pi^{2}}{3} \sum_{n=1}^{\infty} (-1)^{n-1} \frac{H_{n}}{(n+1)^{2}} + 2 \sum_{n=1}^{\infty} (-1)^{n-1} \frac{H_{n} H_{n+1}^{(2)}}{(n+1)^{2}} \\
&= 2 \sum_{n=1}^{\infty} (-1)^{n-1} \frac{(H_{n})^{2}}{(n+1)^{3}} + 2 \sum_{n=1}^{\infty} (-1)^{k-1} \frac{H_{n}}{(n+1)^{4}} - \frac{\pi^{2}}{3} \sum_{n=1}^{\infty} (-1)^{n-1} \frac{H_{n}}{(n+1)^{2}} + 2 \sum_{n=1}^{\infty} (-1)^{n-1} \frac{H_{n} H_{n+1}^{(2)}}{(n+1)^{2}}
\end{align} Evaluating the first Euler sum is probably quite difficult, and the fourth sum seems crazy. Maybe I made a mistake. Note that: this is not a duplicate of the question because I want to know the evaluation of the last 4 Euler sums, not the main integral.
Thank for reading. edit; wrong link","['integration', 'definite-integrals', 'euler-sums', 'calculus', 'closed-form']"
4903807,Defining the Ricci tensor on a hermitian manifold,"The following is an excerpt from a set of notes I'm following. Let $M$ be a complex manifold of dimension $n$ and let $g$ be an Hermitian structure in $T M$ . It is called an Hermitian metric on $M$ . A complex manifold $M$ with an Hermitian metric $g$ is called an Hermitian manifold. Then we can write $$ \begin{equation*}
g=\sum g_{i \bar{j}} d z^{i} d \bar{z}^{j}, \quad \text { where } \quad g_{i \bar{j}}=g\left(\partial / \partial z^{i}, \partial / \partial \bar{z}^{j}\right) \tag{1.7.7}
\end{equation*}
$$ (Following the tradition, we write $d z^{i} d \bar{z}^{j}$ instead of $d z^{i} \otimes d \bar{z}^{j}$ ). Let $D$ be the Hermitian connection of $g$ . Let $R$ be the curvature of $D$ ; it is in $A^{1,1}(\operatorname{End}(T M))$ . In terms of the frame field $\left(\partial / \partial z^{1}, \cdots, \partial / \partial z^{n}\right)$ and its dual $\left(d z^{1}, \cdots, d z^{n}\right)$ , the curvature can be expressed as $$
\begin{equation*}
R=\sum \Omega_{j}^{i} d z^{j} \otimes \frac{\partial}{\partial z^{i}}, \quad \text { where } \quad \Omega_{j}^{i}=\sum R_{j k \bar{h}}^{i} d z^{k} \wedge d \bar{z}^{h} \tag{1.7.8}
\end{equation*}
$$ Expressing (1.4.13) in terms of local coordinates, we have $$
\begin{equation*}
R_{j a \bar{b}}^{i}=-\sum g^{i \bar{k}} \frac{\partial^{2} g_{j \bar{k}}}{\partial z^{a} \partial \bar{z}^{b}}+\sum g^{i \bar{k}} g^{p \bar{q}} \frac{\partial g_{p \bar{k}}}{\partial z^{a}} \frac{\partial g_{j \bar{q}}}{\partial \bar{z}^{\theta}} \tag{1.7.9}
\end{equation*}
$$ If we set $$
\begin{equation*}
R_{j \bar{k} a \bar{b}}=\sum g_{i \bar{k}} R_{j a \bar{b}}^{i} \tag{1.7.10}
\end{equation*}
$$ then (1.7.9) reads as follows: $$
\begin{equation*}
R_{j \bar{k} a \bar{b}}=-\frac{\partial^{2} g_{j \bar{k}}}{\partial z^{a} \partial \bar{z}^{b}}+\sum g^{p \bar{q}} \frac{\partial g_{p \bar{k}}}{\partial z^{a}} \frac{\partial g_{j \bar{q}}}{\partial \bar{z}^{b}} \tag{1.7.11}
\end{equation*}
$$ We define two Hermitian tensor fields contracting the curvature tensor $R$ in two different ways. We set $$
\begin{gather*}
R_{k \bar{h}}=\sum R_{i k \bar{h}}^{i}=\sum g^{i \bar{j}} R_{i \bar{j} k \bar{h}}, \quad R i c=\sum R_{k \bar{h}} d z^{k} \otimes d \bar{z}^{h}  \tag{1.7.12}\\
K_{i \bar{j}}=\sum g^{k \bar{h}} R_{i \bar{j} k \bar{h}}, \quad \hat{K}=\sum K_{i \bar{j}} d z^{i} \otimes d \bar{z}^{j} \tag{1.7.13}
\end{gather*}
$$ I have two questions. Does the author here have an unconventional way of defining the Ricci tensor? From the looks of it, they seem to define it as the contraction of the last two indices $j$ and $i$ in $$R^i_{jkl} dz^k \wedge d\bar{z}^l\otimes dz^j \otimes \frac{\partial}{\partial z^i}$$ which would differ from the standard using the first and last index. Why isn't $\hat{K}$ identically zero given the symmetries of $R$ ?","['complex-geometry', 'differential-geometry']"
4903821,"Prove that $E\left[\,{\left\vert\,{g(X)+g(Y)}\,\right\vert}\,\rule{0pt}{4mm}\right] \geq E[|g(Y)|]$","Let $X, Y$ be two independent random variables, both uniformly distributed on $[0, 1]$ and let $g:\mathbb{R}\rightarrow \mathbb{R} $ be continuous function. Does following inequality always hold? $E\left[\,{\left\vert\,{g(X)+g(Y)}\,\right\vert}\,\rule{0pt}{4mm}\right] \geq E[|g(Y)|]$ I think this is more calculus problem, as this inequality can be rewritten in the following way: $\int_0^1\int_0^1|g(x)+g(y)|dxdy \geq \int_0^1|g(y)|dy$ It is easy to show that $\int_0^1\int_0^1(g(x)+g(y))^2dxdy\geq \int_0^1g(y)^2dy$ but I don't know how to derive initial inequality.","['real-analysis', 'expected-value', 'calculus', 'inequality', 'probability-theory']"
4903880,Chi-squared divergence inequalities proof using Cauchy-Schwarz,"I am trying to prove the two following inequalities for distributions $P$ and $Q$ with densities $p$ and $q$ respectively, using the Chi-squared divergence defined as: $$\mathcal{X}^2(p||q) = \int\frac{(p-q)^2}{q} d\mu$$ $\left|\mathbb{E}_p[x] - \mathbb{E}_q[x]\right| \leq \sqrt{\mathcal{X}^2(p||q)} . \sqrt{\mathbf{\text{Var}}_q(x)}$ $|\mathbb{E}_p\left[x^2\right] - \mathbb{E}_q\left[x^2\right]| \leq \sqrt{\mathcal{X}^2(p||q)} . \sqrt{\mathbb{E}_q\left[x^4\right]}$ I managed to prove the second inequality using Cauchy-Schwarz( $\left(\mathbb{E}[XY]\right)^2 \leq \mathbb{E}[X^2]. \mathbb{E}[Y^2])$ : $$\left(\int (p - q)x^2 \hspace{0.2cm}dx\right)^2 = \left(\int \frac{p - q}{q} x^2 q \hspace{0.1cm}dx \right)^2 = \left(\mathbb{E}_q\left[\frac{(p-q)}{q}x^2\right]\right)^2$$ $$ \leq \mathbb{E}_q\left[\frac{(p-q)^2}{q^2}\right] .\mathbb{E}_q\left[x^4\right] = \mathcal{X}^2(p||q) .\mathbb{E}_q\left[x^4\right]$$ But using the same method for the first inequality yields $\mathcal{X}^2(p||q) .\mathbb{E}_q\left[x^2\right]$ for the right-hand side. I cannot seem to find a way to use Cauchy to derive $\mathbf{\text{Var}}_q(x)$ . I would really appreciate any hints.","['inequality', 'probability-distributions', 'cauchy-schwarz-inequality', 'probability-theory']"
4903924,Functions with restrictive behavior on $\mathbb{S}^2$,"Let $ f $ be a smooth function defined on the sphere such that the set of points where $ f(x) - f(\tilde{x}_y) $ vanishes divides $\mathbb{S}^2$ into exactly four regions for all $y\in \mathbb{S}^2$ , where $\tilde{x}_y $ is the reflection of $ x $ with respect to the plane $ P_y $ passing through the origin with normal vector $ y $ . I believe such a function does not exist. My idea is to use Borsuk-Ulam type theorems to prove it. However, I have not been successful in doing so. Any hints would be appreciated.","['analytic-geometry', 'geometry', 'general-topology', 'differential-topology', 'algebraic-topology']"
4903932,Proof of Beppo Levi's Theorem [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 2 months ago . Improve this question I am self-studying measure theory using Measure Theory by Donald Cohn. The text presented the following result but lack of detailed proof. I tried to write up the proof, and I would really appreciate it if someone could help me check if it is correct and rigorous. Here is the result: Beppo Levi's Theorem $\quad$ Let $(X,\mathscr{A},\mu)$ be a measure space, and let $\sum_{k=1}^{\infty}$ be an infinite series whose terms are $[0,+\infty]$ -valued $\mathscr{A}$ -measurable functions on $X$ . Then \begin{align*}
    \int\sum_{k=1}^{\infty}f_kd\mu = \sum_{k=1}^{\infty}\int f_kd\mu.
\end{align*} Here is my attempt: Proof $\quad$ Let $g_n=\sum_{k=1}^nf_k(x)$ and $g=\sum_{k=1}^{\infty}f_k(x)$ . By Proposition 2.1.5 and 2.1.6 below, $g_n$ 's and $g$ are $\mathscr{A}$ -measurable. Since each $f_k$ is $[0,+\infty]$ -valued $\mathscr{A}$ -measurable, it follows that the sequence $\{g_n\}$ is an increasing sequence, so that $\sum_{k=1}^nf_k(x)\to\alpha\in[0,+\infty]$ for all $x$ in $X$ . Denote $\alpha = \sum_{k=1}^{\infty}f_k(x)$ , so that $\lim_{n\to\infty}\sum_{k=1}^nf_k(x) = \alpha = \sum_{k=1}^{\infty}f_k(x)$ for all $x$ in $X$ . Hence, \begin{align*}
g_1(x) \leq g_2(x) \leq \dots
\end{align*} and \begin{align*}
g(x) = \sum_{k=1}^{\infty}f_k(x) = \lim_{n\to\infty}\sum_{k=1}^{n}f_k(x) = \lim_{n\to\infty}g_n(x)
\end{align*} hold at every $x$ in $X$ . Therefore, by the Monotone Convergence Theorem (see below), we have \begin{align*}
\int\sum_{k=1}^{\infty}f_kd\mu = \int gd\mu = \lim_{n\to\infty}\int g_nd\mu = \lim_{n\to\infty}\int\sum_{k=1}^{n}f_kd\mu = \lim_{n\to\infty}\sum_{k=1}^n\int f_kd\mu,\tag1
\end{align*} where the last equality holds because of the linearity of the integral. Since $f_k$ is $[0,+\infty]$ -valued, then $\int f_kd\mu = \sup\left\{\int gd\mu:g\in\mathscr{S}_+\ \text{and}\ g\leq f_k\right\}$ must be $[0,+\infty]$ -valued, and so $\sum_{k=1}^n\int f_kd\mu$ is $[0,+\infty]$ -valued as well. Thus, $\sum_{k=1}^n\int f_kd\mu \to \lambda \in [0,+\infty]$ . Denote $\lambda=\sum_{k=1}^{\infty}\int f_kd\mu$ , so that $\lim_{n\to\infty}\sum_{k=1}^n\int f_kd\mu = \lambda = \sum_{k=1}^{\infty}\int f_kd\mu$ . Therefore, equality (1) implies \begin{align*}
\int\sum_{k=1}^{\infty}f_kd\mu = \sum_{k=1}^{\infty}\int f_kd\mu.
\end{align*} Thanks a lot in advance! Results used in my proof: Proposition 2.1.5 $\quad$ Let $(X,\mathscr{A})$ be a measurable space, let $A$ be a subset of $X$ that belongs to $\mathcal{A}$ , and let $\{f_n\}$ be a sequence of $[-\infty,+\infty]$ -valued measurable functions on $A$ . Then the function $\lim_{n\to\infty}f_n$ (whose domain is $\{x\in A:\limsup_{n\to\infty}f_n(x)=\liminf_{n\to\infty}f_n(x)\}$ ) is measurable. Proposition 2.1.6 $\quad$ Let $(X,\mathscr{A})$ be a measurable space, let $A$ be a subset of $X$ that belongs to $\mathcal{A}$ , let $f$ and $g$ be $[0,+\infty]$ -valued measurable functions on $A$ , and let $\alpha$ be a nonnegative real number. Then $\alpha f$ and $f+g$ are measurable. Theorem 2.4.1 $\quad$ The Monotone Convergence Theorem $\quad$ Let $(X,\mathscr{A},\mu)$ be a measure space, and let $f$ and $f_1,f_2,\dots,$ be $[0,\infty]$ -valued $\mathscr{A}$ -measurable functions on $X$ . Suppose that \begin{align}
    f_1(x) \leq f_2(x) \leq \dots
\end{align} and \begin{align}
    f(x) = \lim_{n\to\infty}f_n(x)
\end{align} hold at $\mu$ -almost every $x$ in $X$ . Then $\int fd\mu = \lim_{n\to\infty}\int f_nd\mu$ .","['integration', 'measure-theory', 'analysis', 'real-analysis', 'limits']"
4903943,Renyi parking problem for finite intervals,"The so called Renyi parking constant gives the covering density of an infinite interval $[0,L]_{L\to\infty}$ that was randomly covered by unit intervals. Covering is only allowed if the place is not occupied by a previously covered interval. The process finishes if the largest uncovered segment is shorter than $1$ . The covering density $C_\infty$ can be exactly expressed by a double integral $$C_\infty=\int_0^\infty \exp\left(-2\int_0^x\dfrac{1-e^{-y}}{y}{d}y\right)dx\approx 0.74759792\ldots \;\text{for} \; L \to \infty,\tag{1}$$ i.e. almost $75\%$ are occupied by disjunct unit intervals. If the interval to be covered is finite then no exact density is known except for the trivial cases $$\begin{matrix}C=&0 \;&\text{for} \; &L \lt 1\\C=&1/L\; &\text{for} \; &1\le L \le 2\\C=&2/3\; &\text{for} \; &L = 3.\end{matrix}\tag{2}$$ The best density approximation for all other cases I could find is already 60 years old (Dvoretzky1964). It evaluates the expected density to $$C=L^{-1}\left(C_\infty (L+1)-1\right) +\mathcal{O}\left[L^{-1}\left(\dfrac{2e}{L}\right)^{L-3/2}\right]\;\text{for} \; L \gt 2,L\ne3.\tag{3}$$ Especially for small $L$ this approximation is very inaccurate.
For $L=2.01$ we expect from eq. $(2)$ a density close to $0.5$ but get from eq. $(3)$ $C=0.622+\mathcal{O}\left[0.826\right]$ . For $L=3.01$ we expect from eq. $(2)$ a value close to $0.\overline{6}$ and also get from eq. $(3)$ $C=0.664+\mathcal{O}\left[0.811\right]$ . But for both examples the error term is larger than the expected value. Does a better approximation or exact expression for the expected density exist? What is known about the density distribution for $L\gt2,L\ne3$ ? Dvoretzky, A.; Robbins, H.; On the Parking Problem, Publ. Math. Inst. Hung. Acad. Sci. 9, 209–224 (1964) (there eq.1.3, free download )","['probability', 'reference-request']"
4903960,How to construct a nonzero real number between two given nonzero real numbers?,"Statement: Let $$X=$$ $$\{(a,b) \in \mathbb{R} \setminus \{0\} \times \mathbb{R}\setminus \{0\}:a<b\}$$ There exists a function $f:X \rightarrow \mathbb{R} \setminus \{0\}$ such that for all $(a,b) \in X$ , $|f(a,b)-b| \le \frac{3}{4}|a-b|$ and $|f(a,b)-a| \le \frac{3}{4}|a-b|$ . I proved this statement constructively without using the axiom of countable choice, but for doing that, I assumed real numbers are regular sequences of rational numbers (according to Bishop). The idea of the proof is that you construct a rational number $q$ such that $|q-b| < \frac{3}{4}|a-b|$ and $|q-a| < \frac{3}{4}|a-b|$ . If $q=0$ then put $f(a,b)=\frac{\frac{a+b}{2}+b}{2}$ and if $\neg(q=0)$ then put $f(a,b)=q$ . Now I wonder how can we prove this statement by considering real numbers as Dedekind cuts of rational numbers? i.e if we consider real numbers as Dedekind cuts, can we prove this statement constructively without using the axiom of countable choice? The proof that I mentioned doesn't go well if reals are Dedekind reals, because we cannot easily construct the desired rational number, if we restrict ourselves to not use the axiom of countable choice. Can anyone help me with this? Thank you.","['real-numbers', 'real-analysis', 'constructive-mathematics', 'axiom-of-choice', 'rational-numbers']"
4903979,Is $\operatorname{FinGrp}^{\operatorname{op}}$ a concrete category?,"I'm an undergraduate math student currently studying group theory, which I've been loving a lot. Recently I've been reading up on some (very) basic category theory, and in the process I've developed some questions. My understanding is that a concrete category is a category with a faithful functor into the category of sets, which means that in a certain sense a concrete category can be realized as a category of structured sets with morphisms that are functions of sets preserving said structure. Thus in the case of the category FinGrp , the forgetful functor into Set is a faithful functor, so FinGrp is a concrete category. I'm also pretty sure I at least intuitively understand the idea of the opposite category. Which leads me to the question posed in the title. Can we understand the opposite category of the category of finite groups as being some kind of sets with a preserved structure, in the same way we can view the category of finite groups as sets with a preserved structure? If not, how would one show that no such faithful functor exists? Even if the answer to this question might be currently be beyond my understanding, I'd appreciate any direction in getting closer to understanding this. Thank you!","['group-theory', 'category-theory']"
4904000,A question on proving an inequality involving a sequence of real numbers,"Let $a_n$ be a sequence of real numbers such that $1=a_1 \le a_2 \le a_3 \le \cdots \le a_n.$ Additionally, we have that $a_{i+1}-a_i \le \sqrt{a_i},$ for all $1 \le i <n.$ Then prove that $$\sum_{i=1}^{n-1}\frac{a_{i+1}-a_i}{a_i} \le 2 \log_2 n.$$ My attempt: Consider the LHS of the given inequality to be proved. $$\sum_{i=1}^{n-1}\frac{a_{i+1}-a_i}{a_i} \le \sum_{i=1}^{n-1}\frac{\sqrt{a_i}}{a_i} = \sum_{i=1}^{n-1}\frac{1}{\sqrt{a_i}}.$$ Since we have that $1=a_1 \le a_2 \le a_3 \le \cdots \le a_n,$ we get that $\frac{1}{\sqrt{a_i}} \le 1$ for all $1 \le i <n.$ Hence, $$\sum_{i=1}^{n-1}\frac{a_{i+1}-a_i}{a_i} \le  \sum_{i=1}^{n-1}\frac{1}{\sqrt{a_i}} \le n-1.$$ I know that this is very loose bound on the given sum. How can I possibly improve this? Please give any hints or suggestions. Thanks for all your inputs in advance.","['inequality', 'sequences-and-series', 'real-analysis']"
4904038,Multiple Integral Problem with Dirac Delta Constraint: Seeking Guidance,"I am working on a challenging multiple integral problem and would appreciate any assistance. The integral is as follows: $$
\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} \ldots \int_{-\infty}^{+\infty} \log(\sqrt{x_1^2+y_1^2}) \cdot \log(\sqrt{x_2^2+y_2^2}) \cdot \ldots \cdot \log(\sqrt{x_m^2+y_m^2}) \cdot \delta\left(\sum_{i=1}^{N} (x_i^2+y_i^2)-1\right) \, dx_1 \, dy_1 \, dx_2 \, dy_2 \ldots dx_N \, dy_N
$$ where $ m $ is less than $ N $ , and $ N $ is a large natural number. The Dirac delta function ( $ \delta $ ) imposes a constraint on the problem. I have seen some of your insightful answers on related topics, @achille hui, and I was wondering if you could offer any guidance or suggestions on this problem. Your expertise would be greatly appreciated. Thank you,","['integration', 'multivariable-calculus', 'calculus', 'real-analysis']"
4904073,"How to show that $\left[D_\mu, F^{\mu\nu}\right]=\left(\partial_\mu \delta_{ae}-gf^{bae}A_\mu^b\right)F^{\mu\nu a}t^e$?","I'm trying to show that $$\left[D_\mu, F^{\mu\nu}\right]=\left(\partial_\mu \delta_{ae}-gf^{bae}A_\mu^b\right)F^{\mu\nu a}t^e\tag{1}$$ where the covariant derivative, $D_\mu=\partial_\mu+ig A_\mu$ , the gauge field $A_\mu=A_\mu^b t^b$ with $t^b$ being the matrix generators of the fundamental representation. $g$ is a constant and $F^{\mu\nu}=F^{\mu\nu a}t^a$ is the Maxwell field strength tensor. Using the commutator relation $[A+B, C]=[A,C]+[B,C]$ , and the Lie algebra $[t^a, t^b]=if^{abc}t^c$ , where $f^{abc}$ is a structure constant. I find that, $$\left[D_\mu, F^{\mu\nu}\right]=\left[\partial_\mu+ig A_\mu, F^{\mu\nu}\right]=[\partial_\mu, F^{\mu\nu a}t^a]+ig[A_\mu^b t^b,F^{\mu\nu a}t^a]$$ $$=\partial_\mu F^{\mu\nu e}t^e-F^{\mu\nu e}t^e\partial_\mu+igA_\mu^bF^{\mu\nu a}[t^b,t^a]$$ $$=\partial_\mu F^{\mu\nu e}t^e-{F^{\mu\nu e}t^e\partial_\mu}-gA_\mu^bF^{\mu\nu a}f^{bae}t^e$$ $$=\partial_\mu \delta_{ae}F^{\mu\nu a}t^e-{F^{\mu\nu e}t^e\partial_\mu}-gA_\mu^bF^{\mu\nu a}f^{bae}t^e$$ $$=\left(\partial_\mu \delta_{ae}-gf^{bae}A_\mu^b\right)F^{\mu\nu a}t^e-\color{red}{F^{\mu\nu e}t^e\partial_\mu}\tag{2}$$ The final equality of $(2)$ is identical to $(1)$ except for the presence of the term in red which I cannot seem to get rid of. Why should the term marked red vanish?","['representation-theory', 'calculus', 'partial-derivative', 'derivatives', 'mathematical-physics']"
4904074,Dividing a polyhedron into two similar copies of itself,"The paper Dividing a polygon into two similar polygons provides that there are only three families of polygons that are irrep-2-tiles (can be subdivided into similar copies of the original). Right angled triangles $1:\sqrt{2}$ parallelograms The Golden Bee I wish to find examples of polyhedra that are irrep-2-tiles. The only example I have been able to find is: The $1:2^\frac{1}{3}:2^\frac{2}{3}$ parallelopipeds. Are there further examples? I would like to find as many as possible. I have now posted this question on MathOverflow also. Edit: A diagram of the Golden Bee from the linked paper. It seems plausible that there could be a $3d$ analogue. Addressing Jaap Scherphuis' comment, such a polyhedron would be able to tile $\mathbb{R}^3$ , provided you used copies of different sizes. An analogue of the Pinwheel tiling would work. However, I can't think of a way to guarantee that we only use a finite amount of different sizes of the tile. The ""natural"" tiling, adjoining copies of the polyhedron again and again to cover the entire plane will need arbitrarily large polyhedra. We can subdivide these to reduce their size, but unless we have some lucky scaling factors we'll end up with infinitely many different sizes of tile.","['polyhedra', 'geometry', 'combinatorics', 'iterated-function-system', 'tiling']"
4904108,The length of a curve determined by a curve in the tangent space starting from the origin.,"Let $M$ be a Riemannian manifold, $p$ is a point of $M$ . Suppose $exp_p$ is defined on an open neighborhood $U$ of the origin, and let $v$ be a vector in $U$ . By definition, the length of the curve $exp_p(tv), t\in[0,1]$ is just $|v|$ . However, if I choose an arbitrary curve $\alpha(t)$ in $U$ joining the origin and $v$ , what can I say about the length of $exp_p(\alpha(t))$ . Is it necessary that the length of $exp_p(\alpha(t))$ is always larger than $|v|$ ?","['geometry', 'riemannian-geometry', 'differential-geometry']"
4904147,Existence of measurable cardinals in ZFC,Here by measureable cardinal I mean a cardinal $\kappa$ that admits a measure $\mu$ on $2^\kappa$ such that $\mu(\kappa)=1$ and $\forall x\in \kappa$ $\mu\{x\}=0$ . My question is can such a cardinal be proved to exist in ZFC? When we additionally require that $\mu$ must be $\kappa$ additive then such a cardinal cannot be proved to exist as it must be weakly inacessible. From theorem 1.4 on page 176 of Drake's book it is shown that the first measurable cardinal must have a measure that is $\kappa$ additive. It is then weakly inacessible and so cannot be shown to exist in ZFC. This is very close to showing the lack of existence of measurable cardinal but isn't quite there.,"['measure-theory', 'set-theory']"
4904183,How to apply Ito's Formula to show that this is a martingale?,"In the book Brownian Motion, Martingales and Stochastic Calculus by J.F. Le Gall, in order to give an alternatice derivation of the distribution of $L_{U_{a}}^{0}(B)$ where $L^{0}_{t}(B)$ is the Local-Time at $0$ of a Standard Brownian Motion and $U_{a}=\inf\{t:|B_{t}|\geq a\}$ , he states as a remark that ""use ItĂ´â€™s formula to verify that, for every $\lambda>0$ , $$(1+\lambda |B_{t}|)e^{-\lambda L_{0}^{t}(B)}$$ is a continuous Martingale (local)"". My question: What is the function that we are supposed to apply Ito's Formula to? I can write $L_{0}^{t}(B)=|B_{t}|-\int_{0}^{t}\text{sgn}(B_{s})\,dB_s$ by using Tanaka's Formula. In that case, I will get $$(1+\lambda|B_{t}|)\exp\bigg(-\lambda |B_{t}|+\lambda\int_{0}^{t}\text{sgn}(B_{s})\,dB_{s}\bigg)$$ But the problem is I cannot express it in the form of $f(X_{t})$ where $f$ is some function and $dX_{t}=\mu_{t}\,dt+\sigma_{t}\,dB_{t}$ inorder to apply Ito's Formula. Can someone help me out with this?","['local-time', 'probability', 'martingales', 'brownian-motion', 'stochastic-calculus']"
4904193,What problems will arise if we define matrix multiplication this way?,"$a\in \mathbb{R}^n$ $a=(a_1,a_2,\dots,a_n)$ lets define this to be equivalent to $(a_1,a_2,\dots,a_n,0,0,0 \dots,0)$ (finite many zeros) by this I think we can make an $n \times m$ matrix $A$ equivalent to any $ p \times p$ $B$ matrix with $p\ge \max\{n,m\}$ by $B_{ij}= A_{ij}$ if $1\le i\le n$ and $1\le j \le m$ otherwise all the other entries of the matrix $B$ will be $0$ now we can multiply any two matrices $A, B$ by making them in the form of $P_1$ , $P_2$ such that $P_1, P_2$ are $p \times p$ matrices where $p is \max\{ n,m,r,s\} $ where $A$ is an $n \times m$ matrix and $B$ is a $r \times s$ matrix  . my question is What problems will arise if we define matrix multiplication this way ? There should be a lot of problems because mathematicians because if there aren't any problems someone would probably generalise matrix multiplication this way Another question is: is this definition agrees with the usual one in the cases where both methods of multiplying are defined? l examples that I tried result to the ""same"" matrix but I couldn't prove that.","['matrices', 'soft-question', 'linear-algebra', 'vectors']"
4904234,Notation for the pairwise union of the elements of two sets of sets,"Is there some special notation or name for this operation of taking the pairwise union of the elements of two sets of sets $S$ and $P$ ? $$S\ \dot{\cup}\ P := \big\{s \cup p \mid (s,p) \in S \times P\big\}$$ E.g., $\big\{\{1,2\}, \{3,4\} \big\}\ \dot{\cup} \ \big\{\{4,5\}, \{6,7\} \big\} = \big\{\{1,2,4,5\}, \{1,2,6,7\}, \{3,4,5\}, \{3,4,6,7\} \big\}$ . The term ""unordered Cartesian product"" seems to be related but different in that the set $\{s,p\}$ rather than the pair $(s,p)$ is considered, though not the union $s \cup p$ .","['elementary-set-theory', 'notation']"
4904268,Uniform convergence and Lebesgue integral (Bogachev 10.4),"I was reading chapter 10.4 of Bogachev's Measure Theory book, when this definition is given: And, after this definition, he does the following observation: My issues are: what does he mean when he says ""by mean of uniform approximations""? And, more precisely, what is he effectively doing? It seems to me that he's somehow bringing the limit inside of the integral (in the sense that, since $f$ is bounded, there exists a sequence of simple functions $(f_n)_n$ that converges uniformly to $f$ , and he's bringing the limit for $n\rightarrow +\infty$ inside the integral), but why can he do it? Why can we put the limit inside the integral for all the integrals involved (with respect to $\mu, |\mu|$ and $\mu^{\mathcal{B}}(\cdot,x)$ )? I thought about some sort of application of the dominated convergence theorem, which explains also the $|\mu|$ -integrability of the function $x \mapsto \|\mu^{\mathcal{B}}(\cdot, x)\|$ , since this hypothesis gives the finiteness of the measure $\mu^{\mathcal{B}}(\cdot,x)$ for $|\mu|$ -almost every $x$ , but is not clear to me how to precisely use this fact. Just to make it clear: if $\mu$ is a measure on a space $X$ , then $\|\mu\|:=|\mu|(X)$ , where $|\mu|$ is the total variation of $\mu$ .","['measure-theory', 'lebesgue-integral', 'uniform-convergence']"
4904344,Algebra Math Olympiad Question,"The following question is a Math Olympiad Problem: Find $x>0$ that solves $x\sqrt{x\sqrt x}=2$ The answer is $\sqrt[7]{16}$ but I got $2\sqrt[3]{2}$ by: $$\begin{align}x\sqrt{x\sqrt x}=2&\to \sqrt{x\sqrt{x}}=\frac2x\\&\to
x\sqrt{x}=\frac{4}{x^{2}}\\&\to \sqrt{x}=\frac{4}{x}\to
 x=\frac{16}{x^{2}}\\&\to x^{3}=16\\&\to x=\sqrt[3]{16}\\&\to
 x=2\sqrt[3]2\end{align}$$ What have I done wrong?","['contest-math', 'exponentiation', 'algebra-precalculus']"
4904372,Finding the area of an ellipse which is the intersection of $z=x^2+y^2$ and $z=1+2x$.,"I'm not sure of the names of different parts of an ellipse but here goes. I'm trying to Find the area of an ellipse which is the intersection of $z=x^2+y^2$ and $z=1+2x$ . The area is given by $\pi ab$ where $b$ and $a$ are half the length of the major and minor axis respectively. From both equations we have $1+2x=x^2+y^2\iff (x-1)^2+y^2=2$ . The largest value of $z$ with this constraint is $z(1+\sqrt{2})$ and least $z(1-\sqrt{2})$ . Thus follows that the vertices of the major axis are $(1+\sqrt{2},0,3+2\sqrt{2})$ and $(1-\sqrt{2},0,3-2\sqrt{2})$ . Thus the length of the major axis is $||(2\sqrt{2},0,4\sqrt{2})||=\sqrt{40}$ which follows $b=\sqrt{10}$ . I don't know how to obtain the vertices of the minor axis. I guessed that the z components of the vertices of the minor axis is half the length of $z(1+\sqrt{2})$ and $z(1-\sqrt{2})$ but it is wrong.","['multivariable-calculus', 'geometry']"
4904450,Shooter and 8 targets,"A shooter shoots at eight identical targets in a shooting gallery. The probability of hitting each target with each shot is the same. It takes the shooter 11 shots to hit all 8 targets. What is the probability that the shooter hit fewer than 4 targets with the first five shots? I did the following: $p = \frac{8}{11}$ , $q = \frac{3}{11}$ - for Bernoulli formula. Then I calculated $P(x<4) = 1 - P(x=4) - P(x=5) = 0.72$ . But my friend told me that answer is $\frac{1}{2}$ . Where is a mistake in my solution?",['probability']
4904483,Determining values of a parameter for which an initial value problem has a polynomial solution,"Given the following IVP: \begin{cases}
\ddot{y}-3t\dot{y}-ky=0\\
y(0)=1; \; \dot{y}(0)=0
\end{cases} I want to determine the possible values of $k$ in order to obtain a polynomial solution; if $p(t)=a_0+a_1t+ \dots + t^n$ would be a solution; then $a_0=1; a_1=0$ ; so I'd get $p(t)=1+ a_2t^2+ \dots + t^n$ and I also have that: $$(-3n-k)t^n=0 \iff k=-3n$$ But now I just could find solutions for $k=-6n$ , i.e., for $\ddot{y}-3t\dot{y}+6ny=0$ with a polynomial of degree $2n$ as solution but I can't find a way to reason why shouldn't exist a polynomial solution for $k=-3-6n$ .  Any suggestions?","['polynomials', 'ordinary-differential-equations']"
4904485,"As a derivation, a tangent vector is independent of the chart.","Lee's Smooth Manifolds primarily defines tangent vectors as derivations. That is, functions $v: C^\infty(M) \to \mathbb{R}$ that satisfy the Leibniz rule. By appealing to a chart $(U, \phi)$ , we can write down a derivation $v$ concretely as a linear combination of basis vectors given by $d\phi^{-1}_{\phi(p)} \frac{\partial}{\partial x_i}$ . When we use a different chart, we of course have a different representation. In order to compute how the derivation acts on a function $f \in C^\infty(M)$ , I believe we have the following procedure: Write down $f \circ \phi^{-1}$ , the coordinate representation of $f$ . Compute $v(f) = v(f \circ \phi^{-1} \circ \phi) = d\phi_p (v)(f \circ \phi^{-1})$ . The RHS is simply applying partial derivatives in the ordinary sense, and we are done. Ah! I seem to have resolved my question in the course of writing it. I wanted to ask why it was obvious that, if you write down $v$ with respect to different bases, that computing $v(f)$ gets you the same result (i.e. is well defined), but that is just bullet point 2. (right?) Apologies for frivolous questions! Everything is largely still an indistinct mess of words and symbols for me, so I just want to make sure I understand things in plodding detail. I find a lot of the time that while I can both mechanically compute and regurgitate definitions accurately, I have little understanding of what I am doing all the same.",['differential-geometry']
4904498,Proving that $0 = \pi - \frac{\pi^5}{5!} - \frac{\pi^7}{7!} + \frac{\pi^{11}}{11!} + \frac{\pi^{13}}{13!} - \frac{\pi^{17}}{17!}-\cdots$,"I'm looking for a proof that: $0 = \pi - \frac{\pi^5}{5!} - \frac{\pi^7}{7!} + \frac{\pi^{11}}{11!} + \frac{\pi^{13}}{13!} - \frac{\pi^{17}}{17!}- \frac{\pi^{19}}{19!} + \frac{\pi^{23}}{23!}+\cdots$ . The sequence is not, as might be thought, $1$ and the primes greater than $3$ , but rather the numbers congruent to $1$ or $5$ mod $6$ . So far the only path I can see to prove the identity is to prove that: $(2n-1)\pi + \frac{[(2n-1)\pi]^3}{3!} - \frac{[(2n-1)\pi]^7}{7!}-\frac{[(2n-1)\pi]^9}{9!} + \cdots =\frac{[(2n-1)\pi]^3}{3!}+\frac{[(2n-1)\pi]^5}{5!} - \frac{[(2n-1)\pi]^9}{9!} - \frac{[(2n-1)\pi]^{11}}{11!} + \cdots = (-1)^{n-1} \cosh\Big(\frac{\sqrt{3}}{2}(2n-1)\pi\Big).$ Then subtract the second series from the first and set $n = 1$ . But I'm having a hard time to find a way to prove that as well (I found those identities empirically). I know that Euler found the somewhat similar identities: $1-\frac{1}{5}+\frac{1}{7} - \frac{1}{11}+\cdots = \frac{\pi}{3} \cdot \frac{\sqrt{3}}{2}$ . $1-\frac{1}{5^3}+\frac{1}{7^3} - \frac{1}{11^3}+\cdots = \Big(\frac{\pi}{3}\Big)^3 \cdot \frac{\sqrt{3}}{2}$ . Is there some way to morph either of them into the ones I want to prove?Besides that, I also know the sum of the related series: $\pi + \frac{\pi^5}{5!} - \frac{\pi^7}{7!} - \frac{\pi^{11}}{11!} + \frac{\pi^{13}}{13!} + \cdots= \dfrac{e^{\frac{\sqrt{3}}{2}\pi}+e^{-\frac{\sqrt{3}}{2}\pi}}{3}$ . But I don't see how that helps.","['hyperbolic-functions', 'sequences-and-series']"
4904555,Is the curve $y^7=x^2(x-1)^2$ hyperelliptic?,"When playing around with genus $3$ curve $X$ which has an automorphism $\sigma$ of order $7$ . Using the Riemann-Hurwitz formula, one find the map $X\to Y:=X/\langle\sigma\rangle$ is a degree $7$ map with $3$ ramification points on $Y$ of index $7$ . Also $Y$ should be of genus $0$ , so we get $X\to\mathbb P^1$ . So by some process, the equation of $X$ is equivalent to $y^7=x^a(x-1)^b$ . Here the ramification point is $0,1,\infty\in\mathbb P^1$ . Assuming $X$ is projective and smooth, which means that $X$ is a normalization of the compactification of the above plane curve. By a classification, there are only four non equivalent cases: $(a,b)=(3,1),(2,2),(2,1),(1,1)$ . In cases $(3,1),(1,1)$ , one can show the curve is birationally equivalent to $y^7-1=x^2$ easily. And in the case $(2,1)$ , we get the famous Klein curve with $168$ automorphisms. But what happened in the case $(2,2)$ ? Is there a way to determine whether the curve in that case is hyperelliptic or not?","['algebraic-curves', 'riemann-surfaces', 'algebraic-geometry', 'birational-geometry']"
4904568,Set of Five 5-Digit Numbers Such That Their Fifth Powers Sum Up to the Concatenation of the Numbers,"I initially wondered about this while experimenting with my calculator. I found that $12^2+33^2=1233$ . Using a quick Python program, I then found $88^2+33^2=8833$ . Curious about cubes, I wrote a C program and found these four examples: $$\begin{align*}
166^3+500^3+333^3 &=166,500,333\\
296^3+584^3+415^3 &=296,584,415\\
710^3+656^3+413^3 &=710,656,413\\
828^3+538^3+472^3 &=828,538,472.
\end{align*}$$ I then searched for fourth powers, which required significant computation time, yielding this result: $$1485^4+5308^4+5107^4+1603^4=1485,5308,5107,1603$$ (Note: Technically, the commas are misplaced, but they make the sequence easier to read.) Without optimization, approximately 1000 times faster, it would not be feasible for me to find all solutions for fifth powers. Does a set of five 5-digit numbers exist such that their fifth powers sum up to the concatenation of the numbers?","['number-theory', 'recreational-mathematics']"
4904571,"Entire function $f$ such that $f(z)=f(P(z))$, where $P$ is a polynomial of degree at least $2$.","Let $f$ be a entire function and $P$ be a polynomial of degree at least $2$ . If $$f(z)=f(P(z)),\quad \forall z\in\mathbb C,$$ Is the entire function $f$ constant function? My thought: If $f$ is not constant, then $f$ must be transcendental entire function.
If the sequence $\{z_n=P^n(z)\}$ iterated by $P$ has a limit point $w_0$ in $\mathbb C$ ,
then $$f(z)=f(z_1)=\cdots=f(z_n)=\cdots,\quad \lim_{n\to\infty}f(z_n)=f(w_0),$$ then $f(z)\equiv w_0$ by Identity theorem.
But this is not always ture. For enample, if $P(z)=z^2+1$ , take $z=1$ , then $z_n\to\infty$ . Also if $$f(z)=f(e^z),\quad \forall z\in\mathbb C,$$ can we have $f$ is constant function? Any hints and help will welcome.","['complex-analysis', 'limits', 'dynamical-systems']"
4904578,How can I simplify this combinatorics expression?,"I got a expression that is related to the combinatorics, and it looks like this: $$\sum_{k=1}^n \frac{2^{2k-1}}{k}\binom{2n-2k}{n-k}\cdot \frac{1}{\binom{2n}{n}}$$ it is from a question I've been studying, and with another approach, I got the answer: $$\sum_{k=1}^n\frac{1}{2k-1}$$ so I think the two should be the same, which means that $$\sum_{k=1}^n \frac{2^{2k-1}}{k}\binom{2n-2k}{n-k}\cdot \frac{1}{\binom{2n}{n}}=\sum_{k=1}^n\frac{1}{2k-1}$$ and to verify this, I wrote a python program to justify. And the outcome is that the two are very likely to be the same. (I tried when $n=1$ to $n=50$ , and the difference is tiny) So can anyone help me to prove it? I've tried many ways but all failed, I even asked chat-gpt but it didn't help. Thanks a lot if you can think of a way to prove it","['summation', 'binomial-coefficients', 'combinatorics']"
4904598,Cutting Up a Rectangle and Piecing Together a Square of the Same Area,"Original Question Given a rectangle $ABCD$ where $AD=a$ and $AB=b$ , cut up the rectangle into some pieces such that piecing the pieces back together will form a square with the same area as the original rectangle. (This is a third part of a question. The second part gives us a way to construct a point $M$ on $AD$ such that $CM=\sqrt{ab}$ , and the points $P$ and $E$ below are remains of the construction, where $PC=MC$ and $CE=AB$ .) My Question Given a rectangle $ABCD$ where $AD=a$ and $AB=b$ ( $a>b$ ), if there is a point $M$ on $AD$ such that $CM = \sqrt{ab}$ , if there is a square $CMNQ$ as shown in the diagram below, does $B$ always fall on the edge $NQ$ ? I am asking this question simply because the teacher just drew the diagram without proving that $N$ , $B$ and $Q$ are collinear, because if they are not collinear, the original question would require a different method of cutting. Note that here, $FA=MD$ and $F$ falls on the extension of $NQ$ . IFF $N, B, Q$ are collinear, then we will have that the area of triangles $FAB$ and $MDC$ are equal because of a simple congruence and also $FMN$ and $BCQ$ are also congruent. If we have $O$ as the intersection of $AB$ and $MN$ , we have that the sum of the areas of triangles $FAB$ and $OAM$ is equivalent to the sum of the areas of the triangles $FMN$ and $ONB$ , which is equivalent to the areas of $ONB$ and $BCQ$ . The irregular quadrilateral $OMCB$ in the middle remains the same, and if $N, B, Q$ are collinear, then the areas of the rectangle $ABCD$ , parallelogram $FMCB$ and the square will all be equal. So may I ask if $N, B, Q$ are collinear?","['rectangles', 'triangles', 'geometry']"
4904637,Evaluate the integral $\int_{-\infty}^{\infty}\binom{n}{x}dx$.,Evaluate the integral $\int_{-\infty}^{\infty}\binom{n}{x}dx$ . This question came in Cambridge Integration Bee and I have no clue what to do in this. I rewrote $\binom{n}{x}$ as $\frac{n!}{{x!}{(n-x)!}}$ but I don't know how to integrate those factorials. Also what to do if $n$ isn't an integer as no information regarding it is given?,"['integration', 'calculus', 'real-analysis']"
4904641,"Can a non-trivial continuous function ""undo"" the discontinuities of another function?","Apologies for the unclear title, I have no idea if the property I'm looking for has a better name. I'm wondering if there exists a pair of functions $f, g : \mathbb{R} \rightarrow \mathbb{R}$ such that : $g$ is a bijection and is nowhere continuous (for an example, see this answer ). $f$ is continuous and not constant. $f \circ g$ is continuous.","['real-numbers', 'continuity', 'real-analysis']"
4904726,Three topologies on the space of sections of a vector bundle,"Let $E\to M$ be a Riemannian vector bundle over an oriented Riemannian manifold $(M,g)$ with a connection $\nabla$ . Let $\Gamma(E)$ denote the vector space of sections of $E\to M$ . For $\sigma \in \Gamma(E)$ , its Sobolev $k$ -norm $(k=1,2,\dots)$ is defined by $$ |\sigma|_k^2:=\int_M ||\sigma||^2+||\nabla \sigma||^2+\cdots+||\nabla^k \sigma||^2 v_g$$ where $v_g$ is the volume form of $M$ . The completion of the space $V^k(E):=\{\sigma \in \Gamma(E):|\sigma|_k<\infty\}$ is denoted by $W^k(E)$ . I want to compare three different topologies on $V^k(E)$ . By definition of $W^k(E)$ we have $V^k(E)\subset W^k(E)$ , and the norm $|\cdot |_k$ on $W^k(E)$ defines a topology on $W^k(E)$ , and hence on $V^k(E)$ . Second, since $\Gamma(E)$ is a vector space it has a topology: the  weak topology determined by all finite-dimensional subspaces (cf. Infinite Dimensional Topological Vector Space ). Since $V^k(E)\subset \Gamma(E)$ , we have another topology on $V^k(E)$ . Finally, there is a topology $V^k(E)$ induced by the $C^\infty$ -topology ( https://en.wikipedia.org/wiki/Whitney_topologies#Whitney_C%E2%88%9E-topology ) of $C^\infty(M,E)$ . Are these three topologies the same? Is there a ""natural"" choice of a topology of $\Gamma(E)$ that are used commonly?","['complete-spaces', 'vector-bundles', 'sobolev-spaces', 'functional-analysis', 'differential-geometry']"
4904740,Binomial distribution in reliability theory,"Do binomial distributions $Bin(n,p)$ always have increasing hazard rate?","['statistics', 'probability-distributions', 'binomial-distribution', 'reliability', 'probability-theory']"
4904754,A functor $\mathsf{Grp} \to \mathsf{Grp}$ with $\mathbb{Z} \mapsto G$,"Given a group $G$ , does there exist a functor $\square \tilde{\otimes} G: \mathsf{Grp} \to \mathsf{Grp}$ with the following properties? $\mathbb{Z} \tilde{\otimes} G \cong G$ $\square \tilde{\otimes} G$ preserves all direct sums, direct products and free products The idea is that $\square \tilde{\otimes} G$ is a ""base change from $\mathbb{Z}$ to $G$ "". I'm particularly interested in the cases $G = \mathbb{Q}$ and $G = \mathbb{R}$ .","['group-theory', 'category-theory']"
4904763,About $\int_0^1\bigg(\frac{x^a-x^b}{\log(x)}\bigg)^2 \text{d}x=\log\bigg(\frac{(2a+1)^{2a+1}(2b+1)^{2b+1}}{(a+b+1)^{2(a+b+1)}}\bigg)$,"For $a>-\frac{1}{2}, b>-\frac{1}{2}$ , we have $$\int_0^1\bigg(\frac{x^a-x^b}{\log(x)}\bigg)^2 \text{d}x=\log\bigg(\frac{(2a+1)^{2a+1}(2b+1)^{2b+1}}{(a+b+1)^{2(a+b+1)}}\bigg)$$ For example, choosing $a=9$ and $b=6$ , we have $$\int_0^1\bigg(\frac{x^9-x^6}{\log(x)}\bigg)^2 \text{d}x=\log\bigg(\frac{(19)^{19}(13)^{13}}{(16)^{32}}\bigg)$$ I could not prove the result by any method actually. I am interested in the proof of this result, using both real method and complex method, not only one. Is there a known resource for proofs of such amazing results? Your help would be appreciated. THANKS!","['integration', 'definite-integrals', 'real-analysis', 'complex-analysis', 'calculus']"
4904804,"Rees Algebra Isomorphism $A[xt, yt] \cong A[X, Y] / (yX - xY)$","David Eisenbud's book ""The Geometry of Schemes"" states the following: Proposition IV-25 : Let $A$ be a Noetherian ring and $x, y \in A$ ; let $B$ be the Rees algebra $$ B = A[xt, yt] \subset A[t].$$ If $x, y \in A$ is a regular sequence, then $$ B \cong A[X, Y] / (yX - xY)$$ via the map $X \mapsto xt$ , $Y \mapsto yt$ . Proof . First we invert $x$ and set $X' = x^{-1}X \in A[x^{-1}][X, Y]$ . The element $yX' - Y \in A[x^{-1}][X, Y] = A[x^{-1}][X', Y]$ generates the kernel of the map $$A[x^{-1}][X', Y] \longrightarrow A[x^{-1}][t],$$ $$X' \mapsto t,$$ $$Y \mapsto yt.$$ Since $(yX' - xY) = (yX - Y)$ in the ring $A[x^{-1}][X, Y]$ , it suffices to show that $x$ is a nonzero divisor modulo $yX - xY$ in $A[X, Y]$ . In the second part of the proof he proves that $x$ is a nonzero divisor using Koszuls homology. Could someone provide the skeleton of the proof ? Why we invert $x$ in the beginning and why it suffices to show that $x$ is a nonzero divisor modulo $yX - xY$ in $A[X, Y]$ ? $\bullet$ It seems we invert $x$ is to work with localizations. So we get an isomorphism on the level of the local rings which then somehow gives us the desired isomorphism.","['blowup', 'ring-isomorphism', 'algebraic-geometry', 'ring-theory', 'abstract-algebra']"
4904831,"How to determine number of isomorphic trees, and how to draw them?","The question is ""How many nonisomorphic spanning trees does each of these simple graphs have? Draw them. a) K3
b) K4
c) K5"" I found that there is only one nonisomorphic tree for K3, but I can't seem to figure out many there are for the other two. How would I find these, and how would I draw them? For further context, here is what I've found so far:","['trees', 'discrete-mathematics']"
4904865,Prove that $M$ is the centroid of the triangle $BCD$.,"the question Consider the tetrahedron $ABCD$ and $M$ a point inside the triangle $BCD$ . Parallels taken from $M$ to the edges $AB$ , $AC$ , $AD$ intersect the faces $(ACD)$ , $(ABD)$ , respectively, $(ABC)$ at the points $A', B',$ respectively, $ C'$ . If $(BCD) || (A' B 'C')$ , prove that $M$ is the centroid of the triangle $BCD$ . my idea the drawing So we have $B'M|| AC, A'M||AB, C'M||AD$ As you can see, I intersected the plane $(A'B'C')$ with $AD,AC,AB$ in $X,Y,Z$ We can simply demonstrate that $Y,A',X$ are collinear Analogus, $X,B',Z$ and $Z,C',Y$ are collinear We can demonstrate that because $(ZYX)||(BCD)$ and both planes are intersected by 2 parallel lines such as BZ and A'M , we get that BZ=A'M which makes BMA'Z a parallelogram Analogus, XC'MD and YB'MC parallelograms. I don't know what to do going forward! Hope one of you can help me! Thank you!","['centroid', 'geometry']"
4904867,"Signal processing, vector spaces and probability","Given a function $f \in L^2[0, T]$ $$
f(t) = \sum_{n=0}^{N} a_n e_n(t) = \sqrt{\frac{2}{T}}\sum_{n=0}^{N} a_n \sin{\left (\frac{\pi nt}{T} \right)}
$$ with the following dot product: $$
\left \langle f, g \right \rangle = \int_0^Tf(t)g(t)\;dt
$$ To find $a_n$ is easy to see that: $$
a_n = \left \langle f(t), e_n(t) \right \rangle = \left \langle f(t),\sqrt{\frac{2}{T}} \sin{\left (\frac{\pi nt}{T} \right)}  \right \rangle 
$$ Now imagine that the signal is ""contaminated"" with noise. $$
x(t) = f(t) + \varepsilon(t)
$$ $$
\varepsilon(t) \sim \mathcal N(0, \sigma)
$$ If you want to find the dot product we have: $$
\left \langle x(t), e_n(t) \right \rangle = \left \langle f(t) + \varepsilon(t), e_n(t) \right \rangle = \left \langle f(t), e_n(t) \right \rangle + \left \langle \varepsilon(t), e_n(t) \right \rangle = a_n + \left \langle \varepsilon(t), e_n(t) \right \rangle
$$ So finally we have: $$
\left \langle x(t), e_n(t) \right \rangle = a_n + \left \langle \varepsilon(t), e_n(t) \right \rangle
$$ $$
\left \langle \varepsilon(t), e_n(t) \right \rangle = \sqrt{\frac{2}{T}}\int_0^T \varepsilon(t) \sin{\left (\frac{\pi nt}{T} \right)} dt
$$ Now imagine we are trying to send a signal with the coefficients $a_n$ , which can only take the random values of $1$ and $-1$ . Both values are equiprobable $\left(P(a_n = 1) = P(a_n = -1) = \frac{1}{2} \right)$ . At the arrival of the contaminated signal we will decide we recieved a $1$ if: $$
\left \langle x(t), e_n(t) \right \rangle > 0
$$ and $-1$ if: $$
\left \langle x(t), e_n(t) \right \rangle < 0
$$ Then: $$
P(\text{Error Reciving 1}) = P(\text{Decide -1} | \text{Sent 1}) = P(\left \langle x(t), e_n(t) \right \rangle < 0 | a_n = 1) =\\ \; \\
P(a_n + \left \langle \varepsilon(t), e_n(t) \right \rangle < 0 | a_n = 1) = P(1 + \left \langle \varepsilon(t), e_n(t) \right \rangle < 0) = P(\left \langle \varepsilon(t), e_n(t) \right \rangle < -1)\\ 
$$ Applying the same reasoning for the error of $-1$ , we finally get: $$
P(\text{Error Reciving 1}) = P(\left \langle \varepsilon(t), e_n(t) \right \rangle < -1)
$$ $$
P(\text{Error Reciving -1}) = P(\left \langle \varepsilon(t), e_n(t) \right \rangle > 1)
$$ The thing is, how would you find: $$
P(\left \langle \varepsilon(t), e_n(t) \right \rangle < -1) \\ \; \\
P(\left \langle \varepsilon(t), e_n(t) \right \rangle > 1)
$$ I've tried transforming the probability density function of $\varepsilon(t)$ , but the transofrmation function is very complex to deal with: $$
\delta(t) = g(\varepsilon(t)) = \left \langle \varepsilon(t), e_n(t) \right \rangle = \sqrt{\frac{2}{T}}\int_0^T \varepsilon(t) \sin{\left (\frac{\pi nt}{T} \right)} dt
$$ $$
f_\delta (\delta) = \frac{f_\varepsilon(\delta)}{|g'(\delta)|}, \; \; \; \text{where $f$ denotes the probability density function}
$$ How should I approach this? Any hint? It is possible to find an analytical form of this transformation?","['probability-distributions', 'functional-analysis', 'probability']"
4904873,The extreme points of a convex hull of any set is the same with the extreme points of this set?,"I consider any set $A$ in $\mathbb{R}^n$ . Note that $A$ is not necessary to be a convex set. I define the extreme point as follows: Given any set $C$ , a point $a\in C$ is an extreme point of the set $C$ if we cannot find any two different points $a_0\in C,a_1\in C$ and $a_0\neq a_1$ such that $a=\lambda a_0 + (1-\lambda) a_1$ , for any $\lambda\in(0,1)$ My question is: whether or not, the set of the extreme points of $A$ is the same as the set of the extreme points of $conv(A)$ , where $conv(A)$ means the convex hull of set $A$ . I guess the two sets of extreme points above would be the same set since the operator $conv()$ should not generate or remove any extreme points of $A$ . If the two sets are different, that means there exists a point in $conv(A)$ such that the point is the extreme point of $conv(A)$ but not the extreme point of $A$ . I think this leads to a contradiction but I cannot vigorously argue it.","['general-topology', 'convex-analysis']"
4904923,How to evaluate $\lim\limits_{x\to 0} \frac{d}{dx} \frac{e^{-ax}-e^{-bx}}{x} $ using integral?,I tried to find this limit $$ \Omega = \lim_{x\to 0} \frac{d}{dx} \frac{e^{-ax}-e^{-bx}}{x} $$ without using series or finding derivative of that function So I tried to use the integral $$ \int_0^\infty e^{-tx} dt = \frac{1}{x} $$ then $$ \Omega = \lim_{x\to 0} \frac{d}{dx} (e^{-ax}-e^{-bx}) \int_0^\infty e^{-tx} dt $$ now the way that I think its wrong $$ \Omega = \int_0^\infty \lim_{x\to 0} \frac{d}{dx} \left(e^{-(a+t)x}-e^{-(b+t)x}\right) dt $$ So $$ \Omega = \int_0^\infty \left(-(a+t)+(b+t) \right) dt $$ which is diverge . So how can I use the integral correctly ? and why its wrong ? also can we get the limit for the second derivative by integral ?,"['integration', 'limits', 'derivatives', 'infinity']"
4904938,Open Set based on Function Image in Order Topology,"I was reading through this stackexchange post, and the user Pete L. Clark stated that, given a continuous function $f:X\to X$ , for $X$ being completely linearly ordered with the order topology, the sets $\{x\in X\mid f(x) < x\}$ and $\{x \in X \mid f(x) > x\}$ are open. I am completely at a loss for how to prove this. For a bit of context on my background, I am a novice self-studying topology from Munkres' Second Edition. Thank you in advance for your assistance!","['continuity', 'general-topology', 'functions', 'order-topology']"
4904940,Papa Rudin Theorem $7.15$.,"There is the definition of $(D\mu)(x)$ : There is the theorem: If $\mu$ is a Borel measure on $R^k$ and $\mu \ \bot \ m$ , then $$(D\mu)(x) = \infty \ a.e. [\mu]. $$ (Denote this equality by $(1)$ .) There is the proof: There is a Borel set $S \subset R^k$ with $m(S) = 0 $ and $\mu(R^k - s) = 0 $ , and there are open sets $V_j \supset S$ with $m(V_j) \lt 1/j$ , for $j = 1,2,3$ ,...
For $N = 1,2,3,...,$ let $E_N$ be the set of all $x \in S$ to which correspond radii $r_i = r_i(x)$ , with $\lim r_i = 0$ , such that $$\mu(B(x,r_i)) \lt Nm(B(x,r_i)).$$ ( Denote this inequality by $(2)$ .) Then $(1)$ holds for every $x \in S - \bigcup_{N} E_N$ . Fix $N$ and $j$ , for the moment. Every $x \in E_N$ is then the center of a ball $B_x \subset V_j$ that satisfies $(2)$ . I don't understand how do we conclude that Every $x \in E_N$ is then the center of a ball $B_x \subset V_j$ that satisfies $(2)$ . Any help would be appreciated.","['measure-theory', 'lebesgue-measure', 'analysis', 'real-analysis', 'functional-analysis']"
4904942,"Given $n > 1$, let $p$ be a prime number such that $n < p < 2n$ (by the way, there is always a prime between $n$ and $2n$).","Given $n > 1$ , let $p$ be a prime number such that $n < p < 2n$ (by the way, there is always a prime between $n$ and $2n$ ). Does $p$ divide $\binom{2n}{n}$ ? Explain. What I did I found out that this is an example of Lucas' Theorem, which states that: Let $m,n$ be two natural numbers, $p$ be a prime. Suppose that $m, n$ admit the following base $p$ representation $$m=m_0+m_1p+\cdots+m_sp^s,\qquad n=n_0+n_1p+\cdots+n_sp^s$$ with $0\le m_i, n_i \le p-1$ , then $$\binom{n}{m}\equiv\prod_{i=0}^{s}\binom{n_i}{m_i}\ (\bmod p)$$ I am wondering on how to apply Lucas' Thereom to this problem, if it is even the correct application.",['discrete-mathematics']
4904995,"Imagine you have points on a circle labeled $0,1,2,...,126$, so point $126$ is followed by point $0$.","Imagine you have points on a circle labeled $0,1,2,...,126$ , so point $126$ is followed by point $0$ . You start at point $0$ , and you repeatedly jump by $5$ , so you first land on point $5$ , then $10$ , then $15$ , etc... How many jumps do you need to land on point $1$ ? Try to think about the mathematical concept needed to figure this out without guessing. What I did Based on the fact that this is a Discrete Mathematics question, I am assuming the concept that they are trying to convey is divisibility/mod. I am thinking of finding the solution through this equation: $$5n\equiv 1\pmod{127}$$ I think that in some way, this will lead to the number of jumps to land on point $1$ . Is it $51$ ?",['discrete-mathematics']
4905013,"What is the limit probability an element of $x \in S$ belongs to $f^n(S)$, for $n \to \infty$?","Let $S$ be a finite set of $|S|=n$ elements and $F$ be the set of all functions $f:S\rightarrow S$ . It's easy to demonstrate that the integer sequence $\{c_i\} = |{\rm Im}(f^i)|$ : is non increasing; consists of a strictly decreasing sequence up to a certain $n'$ , after which becomes constant; $n' \leq n$ where $n'$ , as defined above, is the maximum number for which $i \leq n' \implies \{c_i\} = |{\rm Im}(f^{i})|$ is strictly decreasing; Quick demonstration: $\forall i \geq 1, {\rm Im}(f^i) = {\rm Im}(f|_{{\rm Im}(f^{i-1})})$ while $f^0$ is identity and $f|_A$ means "" $f$ restricted to $A$ "". Obviously, either $\left|\textrm{Im}(f|_{\textrm{Im}(f^{i-1})})\right| < |\textrm{Im}(f^{i-1})|$ or $\left|\textrm{Im}(f|_{\textrm{Im}(f^{i-1})})\right| = |\textrm{Im}(f^{i-1})|$ which demonstrates 1. 2 derives from the fact $|\textrm{Im}(f|_{\textrm{Im}(f^{i-1})})| = |\textrm{Im}(f^{i-1})|$ means that $f|_{\textrm{Im}(f^{i-1})}$ is a permutation, and permutations are closed with respect of composition. 3 follows from observing the simple example in which $S = \{1, 2, \cdots, n', \cdots, n\}$ and $f(x) = x+1$ , for $x \in \{1, \cdots, n-1\}$ and $f(n) = n'$ . In this case, we have $\{c_i\} = n-i$ for $1 \leq i < n$ and $\{c_i\} = 1$ for $n \leq i$ , and that shows that $n'$ can have any value between $0$ and $n$ . So, in summary, and roughly speaking, 'if you iterate a function over a finite set enough times, you end up with fixed-sized set'. My question is: when size $|S| = n$ of the initial set tends to infinity, and $f$ is randomly chosen from $F$ , what is the expectation of the ratio of the sizes of the set resulting of such iterations and the initial set? Namely what is $\lim_{n \to \infty}E[|\textrm{Im}(f^n(S))|/n]$ There is an immediate application to this question which are the considerations about loss of entropy due to birthday paradox in hashes.","['random-functions', 'probability-limit-theorems', 'birthday', 'discrete-mathematics']"
4905026,Convergence of the difference of the convolution of sequence of functions and a function,"Let $(g_j)_{j \in \mathbb{N}} \subseteq \mathscr{L}_1(\mathbb{R}^n)$ with $\|g_j\| = 1$ and $g_j \geq 0$ for all $j \in \mathbb{N}$ . Suppose that $\lim_{j \to \infty} d_j = 0$ where $d_j := \sup\{\|x\| \mid x \in \operatorname{supp}(g_j)\}$ . I want to prove that for all $f \in \mathscr{L}_1(\mathbb{R}^n)$ it is true that $$
\lim_{j \to \infty} \|f * g_j - f\|_1 = 0.
$$ So far I've proved that for all $f \in \mathscr{L}_1(\mathbb{R}^n)$ and all $\epsilon > 0$ there exist some $\delta > 0$ such that $\|f - \tau_a f\|_1 < \epsilon$ for all $a \in \mathbb{R}^n$ with $\|a\| < \delta$ where $\tau_a f(x) = f(x - a)$ . It is not clear to me the path to follow. I think I can use the distributivity of the convolution to product to obtain \begin{align*}
\|f * g_j - f\|_1 &= \|f * g_j - h * g_j\|_1 + \|h * g_j  - f\|_1\\
&\leq \|(f - h)* g_j\|_1 + \|h * g_j  - f\|_1\\
&\leq \|(f - h)\|_1 \|g_j\|_1 + \|h * g_j  - f\|_1
\end{align*} for some suitable function $h \in \mathscr{L}_1(\mathbb{R}^n)$ .","['measure-theory', 'lebesgue-integral', 'convolution']"
4905032,How can we show that this integral is nonnegative?,"Let $c_0>0$ and $\ell\in[0,1]$ ; $(E,\mathcal E,\lambda)$ be a measure space; $\mu$ be a probability measure on $(E,\mathcal E)$ ; $p:E\to[0,\infty)$ be $\mathcal E$ -measurable with $$p_\lambda:=\int p\:{\rm d}\lambda>0;$$ $f\in L^2(\pi)$ and $$\mu f:=\int f\:{\rm d}\mu.$$ Are we able to show that $$\Gamma(f):=c_0\langle f,f-\mu f\rangle_{L^2(\mu)}-\frac\ell{2p_\lambda}\int\lambda({\rm d}x)\int\mu({\rm d}y)\min(p(x),p(y))|f(x)-f(y)|^2$$ is nonnegative? If this is too hard or not possible to show in general, I'm especially interested in the case where $E=[0,1)^d$ for some $d\in\mathbb N$ , $\mathcal E$ is the Borel $\sigma$ -algebra on $E$ , $\lambda$ is the restriction of the $d$ -dimensional Lebesgue measure on $E$ and $\mu$ is the uniform distribution on $E$ . In particular, $\lambda=\mu$ . I would also be willing to assume that $c_0\ge1$ or even $c_0=1$ . We clearly got $$\Gamma(f)\ge c_0\langle f,f-\mu f\rangle_{L^2(\mu)}-\frac\ell2\int\pi({\rm d}x)\int\mu({\rm d}y)|f(x)-f(y)|^2\tag1,$$ where $\pi$ is the measure with density $\frac p{p_\lambda}$ with respect to $\lambda$ . However, I also wasn't able to show that $(1)$ is nonnegative so far. EDIT : It would be enough for me if there would be a choice for $c_0$ for which $\Gamma(f)>0$ for all $f\in L^2(\pi)$ . However, $c_0$ should be kept as small as possible. Continuing from $(1)$ , we clearly got $$\langle f,f-\mu f\rangle_{L^2(\mu)}=\int\mu({\rm d}x)\int\mu({\rm d}y)|f(x)-f(y)|^2+\int\mu({\rm d}x)\int\mu({\rm d}y)f(y)(f(x)-f(y))\tag2$$ and hence (combining with $(1)$ ) $$\Gamma(f)\ge\left(c_0-\frac\ell{2p_\lambda}\right)\int\mu({\rm d}x)\int\mu({\rm d}y)|f(x)-f(y)|^2+\int\mu({\rm d}x)\int\mu({\rm d}y)f(y)(f(x)-f(y))\tag3.$$ The second term on the right-hand side is equal to $|\mu f|^2-\mu|f|^2$ - i.e. the variance of $f$ with respect to the probability measure $\mu$ - and hence nonnegative. Consequentially, $\Gamma(f)$ is nonnegative as long as $$c_0\ge\frac\ell{2p_\lambda}\tag4.$$ Anything wrong?","['measure-theory', 'lebesgue-integral', 'probability-theory', 'real-analysis']"
4905042,Solving the Differential Equation $ xy(x)y'(x) = y(x) - 1 $,"I am given the differential equation: $$ xyy' = y - 1 $$ I have tried to solve it by separating the variables, but I have only come this far: $$ \int 1 + \frac{1}{y-1} dy = \int \frac{1}{x} dx = y + \log|y-1| = \log{|x|} + C $$ I am struggeling on how to isolate $ y(x) $ . Can somebody please give me a hint on how to continue?","['integration', 'calculus', 'ordinary-differential-equations']"
4905070,Convert an equation to its elliptic form,"I am failing to convert $L = \frac{\sqrt{2}}{2}\int_{0}^{\phi_0} \frac{\sin(\phi)}{\sqrt{\sin \phi_0 - \sin \phi}} d\phi$ into $L=\int_{\theta_1}^{\pi/2}\frac{2k^2\sin^2(\theta)-1 }{\sqrt{1-k^2\sin^2 \theta}}d\theta$ . The original manuscript makes the following substitution $1+\sin(\phi)=2k^2\sin^2(\theta)=(1+\sin\phi_0)\sin^2\theta$ Yet, something is amiss. If you would be so kind as to lend a hand? (Incidentally this is the solution to the problem of large deformation in a cantilevered beam)","['mathematical-physics', 'elliptic-integrals', 'ordinary-differential-equations']"
4905080,Example of a PID in which $SL_n \neq E_n$,"In lectures on algebra, the fact was proved using simple methods that if $R$ is a Euclidean ring, then $\mathrm{SL}_{n}(R) = \mathrm{E}_n(R)$ , where $\mathrm{SL}_{n}(R) = \{m \in \mathrm{M}_{n \times n}(R) \space | \space \Delta m = 1\}$ , $\mathrm{E}_n (R) = \langle t_{i j}(\lambda) \space | \space i \neq j, i, j \in \{1, ..., n\}, \lambda \in R \rangle$ . At the same lecture, it was said that this is generally incorrect for PID. Unfortunately, I don't have enough experience to answer this question, but I want to make sure of the fact expressed by the teacher. Can you give a counterexample?","['abstract-algebra', 'examples-counterexamples']"
4905118,How many seven-digit numbers have seven distinct nonzero digits that appear in increasing order from left to right?,"How many seven-digit numbers have seven distinct nonzero digits that appear in increasing order from left to right? If we were not restricted by the increasing order of digits, the solution would be $\binom{9}{7}\cdot7!=36\cdot7!=181\, 440$ However, the requirement of increasing order of digits truly throws a wrench into my plans. I have noticed that the first digit must be less than or equal to $3$ , so there are $3$ possible numbers for the first digit. Then, we can perform casework to determine the number of possible numbers for the second digit. If the first digit is $3$ , then the second digit must be $4$ (1 option). If the first digit is $2$ , then the second digit can either be $3$ or $4$ (2 options). If the first digit is $1$ , then the second can either be $2$ , $3$ , or $4$ (3 options). So, there are $6$ possible second digits. However, continuing down this path is highly tedious and prone to error. Is there a better way of solving this problem?",['combinatorics']
4905134,"What is $\int_{0}^{\pi/2}\frac{\operatorname{lcm}(a\cos x,a\sin x)}{a^2}dx$?","I came up with this while messing around with the $\gcd$ and $\operatorname{lcm}$ functions in Desmos. $$I(a)=\int_{0}^{\pi/2}\frac{\operatorname{lcm}(a\cos x,a\sin x)}{a^2}dx$$ The function inside the integral always has a slope of $0$ but is very discontinuous. At higher values of $a$ it seems to approximate $\frac{\sin 2x}{2}$ with fewer lines approximating $\frac{\sin 2x}{4},\frac{\sin 2x}{6},$ and so on as pictured below for $a=100$ . Some more things I noticed (mostly through experimentation): $I$ is undefined when $-\frac{\sqrt{2}}{2}<a<\frac{\sqrt{2}}{2}$ . I can not find any other values of $a$ that make $I$ undefined. $I(\pm \frac{\sqrt{2}}{2})=0$ $I(a)=2\int_{0}^{\pi/4}\frac{\operatorname{lcm}(a\cos x,a\sin x)}{a^2}dx$ The integrand turns into $3$ parts at $a=\sqrt{\frac{5}{2}}$ , $2$ parts again back at $a=\sqrt{\frac{9}{2}}$ . In fact, every time it changes how many parts it is made up of seems to be at $a=\sqrt{\frac{b}{2}}$ where $b$ is an odd number. I suspect the pattern is $b_n=1,5,9,...,4n-3$ . As for actually evaluating the integral, I really don't know how to proceed. EDIT: It seems that Desmos defines $\operatorname{lcm}(a,b)$ as $\operatorname{lcm}(\lfloor a+\frac{1}{2}\rfloor,\lfloor b+\frac{1}{2}\rfloor)$ . This seems like it should help significantly but I still am unsure of how to proceed. EDIT 2: I simplified(?) it into this integral: $$\int_{0}^{\pi/2}\frac{1}{a^{2}}\frac{cs}{c-cs+s+2\sum_{k=1}^{c-1}\lfloor\frac{ks}{c}\rfloor}dx$$ where $s=\lfloor\frac{1}{2}+a\sin x\rfloor$ and $c=\lfloor\frac{1}{2}+a\cos x\rfloor$","['integration', 'ceiling-and-floor-functions', 'definite-integrals', 'gcd-and-lcm', 'trigonometric-integrals']"
4905138,How is $\zeta(0)$ actually $-1/2?$,"I was searching around the forum, and I came across: $$\zeta(0) = \lim_{s\to 0}\, 2^{s-1} \pi^s \cdot \frac{\sin(\pi s/2)}{\pi s/2} \cdot \Gamma(1-s) \cdot s\zeta(1-s) = 2^{-1} \pi^0 \cdot 1 \cdot \Gamma(1) \cdot (-1) = -\frac{1}{2}.$$ But how does the last term, $$s\zeta(1-s)=$$ Equal -1? Which definition is being used here? How does 0 times the zeta function give -1? The original answer was given at https://math.stackexchange.com/a/1751998/1277963","['complex-analysis', 'riemann-zeta']"
4905141,"Finding a closed form for $\sum_{S \subseteq \{1,...,n\}} \prod_{k \in S} k$ and prove it.","Let $n\in \mathbb{N}$ . Consider the product $\prod_{k \in S} k$ where $S \subseteq \{1,...,n\}$ . I want to find a closed formula for $\sum_{S \subseteq \{1,...,n\}} \prod_{k \in S} k$ (and show it is correct). Attempt:
If $S =\emptyset$ , then $\prod_{k \in S} k:=1$ . I will denote $s(n):=\sum_{S \subseteq \{1,...,n\}} \prod_{k \in S} k$ .
Since I don't have an idea what the closed form could be, I tried to do some explicit examples. For $n=1$ , we get $s(1)= 1+1$ For $n=2$ , we get $s(2)=1+1+2+1*2$ (i.e. $s(2)=s(1)+1*2$ ) For $n=3$ , we get $s(3)=1+1+2+1*2+3+2*3+1*3+1*2*3$ (i.e $s(3)=s(2)+3+2*3+1*3+1*2*3$ ). I do see some kind of pattern. I.e. that $s(n)=s(n-1)$ +""something"",but I do not know how to explicitly write it down and prove it really holds. I think the best idea would be to get an explicit formula and try induction. Any help would be appreciated.","['combinatorics', 'discrete-mathematics', 'products']"
4905145,$2$-for-$2$ asymmetric Hex,"If the game of Hex is played on an asymmetric board (where the hexes are arranged in a $k\times k+1$ parallelogram), the player who wants to connect the closer pair of sides can force a win, regardless of who goes first. The reflection strategy is detailed here . I was wondering if this advantage conferred to the player connecting the closer pair of sides remains if each player plays $2$ stones per turn, rather than $1$ . In this scenario the reflection-style proof seems to break down as a player can place in both a hex and its paired hex on the same turn. We assume the first player is the one who needs to connect the farther pair of sides (as it is easy to see first player wins if they need to connect the closer pair). From playing around with a pencil and paper, I can tell that player $1$ wins for $k=1,3$ , and player $2$ wins for $k=2$ . It seems like player $2$ may also win for $k=4$ though I haven't worked through every possibility and fully convinced myself of that. Who is the winner for large $k$ ? Will it always depend only on the parity of $k$ ? Or for sufficiently large $k$ , will one of the two advantages (first move vs. shorter side) always win?","['game-theory', 'recreational-mathematics', 'combinatorics', 'combinatorial-game-theory']"
4905148,Products of algebraic groups and sums of Lie algebras,"Let $G$ be a connected solvable algebraic group. Then we know $G = T \ltimes G_u$ is a semi-direct product, where $T$ is a maximal tori, $G_u$ is the unipotent part of $G$ . Main Question. Why does this imply the following equality of Lie algebras? $$
L(G) = L(T) \oplus L(G_u)
$$ This appears, for example in Borel's Linear Algebraic Groups, Proof of Proposition 13.14. Maybe I'm missing some algebraic geometry observations? Thoughts and Discussion. To what extent is the same statement true when $H_1, H_1 \leq G$ are closed subgroups such that $m\colon H_1 \times H_2 \to G, m(h_1,h_2) = h_1 h_2$ is bijective? Does $m$ being surjective or dominant alone imply already $L(H_1) + L(H_2) = L(G)$ ? Is separability relevant here? If I only know $m$ injective, i.e. $H_1 \cap H_2 = \{e\}$ , does this imply $L(H_1) \oplus L(H_2) \hookrightarrow L(G)$ ?","['algebraic-geometry', 'lie-algebras', 'algebraic-groups']"
4905178,an interesting coincidence with group orders: is there some theorem explaining it?,"The sequence  OEIS A333646: $1,6,15,28,30,33,40,42,51,66,69,84,91,95,102,105,117,120,135,138,140,141,145,159,165,182,186,190,210,213,\cdots$ Contains numbers that are divisible by the largest prime factor of the sum of their own divisors. For instance the sum of divisors of $15$ is $24$ , the biggest prime divisor of $24$ is $3$ , and $3$ divides $15$ . If $G$ is a group and $|G|>6$ is featured in the sequence above, it seems guaranteed there will be at least one element of $G$ that has an order which is not a power of a prime. I've verified this up to and including $213$ , and the pattern feels pretty compelling. I wonder, is there some theorem explaining this? The converse does not hold, with the smallest example being $|G|=45$ . But in general, at least for small numbers, a group with elements of exclusively power-of-prime orders can be constructed more often than not. For instance if $|G|=20$ we have $G=F_5$ . EDIT: @diracdeltafunk was kind enough to verify this up to order 1065, and @testacount has a promising lead for a full explanation. Hopefully I'll have more time to pursue it later this week. EDIT: When thinking of groups $G$ such that the order of every element must be a power of a prime, two families are immediate examples: $p$ -groups (ie. groups whose orders are powers of primes) non-abelian groups of order $pq$ , where $p,q$ are distinct primes and $p$ divides $q+1$ . And, apart from $1$ and $6$ , groups from neither family may have orders in A333646. But there are also (comparatively sparse) additional cases, such as $12,18,20,24,36,44,\cdots$ this explanation doesn't account for.","['number-theory', 'group-theory', 'finite-groups']"
4905179,Expand $(1-z)^{-m}$ for $m \in \mathbb{N}$ in powers of $z$,"Expand $(1-z)^{-m}$ for $m \in \mathbb{N}$ in powers of $z$ I've already read the links on this post and this post . The former concerns itself with the user's specific interest in a way to do it while the latter uses an approach that might lend itself to the approach I want to use. I'm mostly interested in solution verification. I may reference the second post. To expand in powers of $z$ , we observe that $f(z)=(1-z)^{-m}$ is analytic in neighborhoods about $z=0$ and hence has a Taylor expansion exists. We write $f(z)=\sum_{n=0}^\infty \frac{f^{(n)}(z)}{n!}z^n$ . Now, we experiment with derivatives. We see that $$f'(z)= -m(1-z)^{-m-1} \cdot (-1)  \hspace{0.2cm} ; \hspace{0.2cm} f''(z) = m(m+1)(1-z)^{-m-2}$$ $$\dots \hspace{0.2cm} f^{(n)}(z) = m(m+1)\dots(m+n-1)(1-z)^{-m-n}$$ $$ \implies f^{(n)}(z) =  \frac{(m+n-1)!}{(m-1)!}(1-z)^{-m-n} $$ Evaluating at $z=0$ gives $$f^{(n)}(0) = \frac{(m+n-1)!}{(m-1)!}$$ Hence, the expansion reads $$f(z) = \sum_{n=0}^\infty \frac{(m+n-1)!}{(m-1)!n!}z^n$$ $$\color{blue}{= \sum_{n=0}^\infty {m+n-1 \choose n}x^n}$$ In the posts I linked at the beginning, the answer was either derived via some binomial formula or via explicit manipulation of geometric series (in the style of the classic $\frac{1}{1-z}$ formula); the second post, which took advantage of the $\frac{1}{1-z}$ formula, did manage to interpret the coefficients using an "" $n$ choose $k$ "" style but this style is different from my result. I just want to be sure that what I wrote is equivalent to the work of the two linked posts. It seemed most intuitive to me to simply do this directly a la $n^{th}$ derivatives - in this way, no fancy outside tricks are needed.","['complex-analysis', 'binomial-theorem', 'taylor-expansion']"
4905198,Every non-empty subset of $\Bbb{N}$ (whether it’s finite or infinite) has a minimum. One can’t say the same about $\Bbb{Z}$.,"Every non-empty subset of $\Bbb{N}$ (whether it’s finite or infinite) has a minimum. One can’t say the same about $\Bbb{Z}$ . Find a total order relation $≺$ on $\Bbb{Z}$ such that every non-empty subset of $\Bbb{Z}$ has a minimum under the $≺$ relation. What I did I am thinking that the divisibility relation will work to define a total order relation on the integers such that every non-empty subset of $\Bbb{Z}$ has a minimum. I would first define $a ≺ b$ if $∣a∣$ divides $∣b∣$ , where $∣x∣$ denotes the absolute value of $x$ . $a≺b$ if and only if $∣a∣$ is a divisor of $∣b∣$ . If $∣a∣=∣b∣$ , then $a≺b$ if $a<b$ . This relation satisfies the following properties: Totality, Reflexivity, Transitivity. With this relation, every non-empty subset of $\Bbb{Z}$ will have a minimum element under $≺$ . Because, for any $a$ in the subset, there will always be an integer with the smallest absolute value that divides $∣a∣$ , and that integer will be the minimum element. Am I correct?",['discrete-mathematics']
4905199,"Proof explanation of result 5.11 in Linear Algebra Done Right, Sheldon Axler","The below result is from Linear Algebra Done Right, 4th edition, Sheldon Axler: 5.11 linearly independent eigenvectors Suppose $T \in \mathcal{L}(V)$ . Then every list of eigenvectors of $T$ corresponding to distinct eigenvalues of $T$ is linearly independent. Firstly, cool result. Secondly, I'm having trouble understanding one part of Axler's proof. He does a proof by contradiction. Since he assumes the result is false, he states: ... there exists a smallest positive integer $m$ such that there
exists a linearly dependent list $v_1, \ldots, v_m$ of eigenvectors
of $T$ corresponding to distinct eigenvalues $\lambda_1, \ldots,
\lambda_m$ of T (note that $m \geq 2$ because an eigenvector is, by
definition, nonzero). My question is why must there specifically exist a smallest positive integer $m$ ? Is that referring to the note in the parenthesis, i.e., $m$ cannot be smaller than $2$ ? This part is integral to the proof, so I must know.","['proof-explanation', 'linear-algebra', 'linear-transformations', 'eigenvalues-eigenvectors']"
