question_id,title,body,tags
2543194,Find the range of eccentricity of an ellipse such that the distance between its foci doesn't subtend any right angle on its circumference.,"What is the range of eccentricity of ellipse such that its foci don't subtend any right angle on its circumference? I thought that the eccentricity would definitely be more than $0$ and less than $\frac{1}{\sqrt2}$ The latter value is for an ellipse with $ae=b$, in which a right angle is subtended on an endpoint of the minor axis.","['conic-sections', 'geometry']"
2543209,Prove directly from the definition that $\lim\limits_{x\to 0^+}\ln(x) = - \infty$,"Prove directly from the definition that $\lim\limits_{x\to 0^+}\ln(x) = - \infty$ I tried to use the sequence definition of the limit, namely: Given $f: D \to R$  If $a$ is a limit point of $D\subseteq R$ and for all sequences $x_n \in D \to a$ $f(x_n) \to g,$ then 
$g = \lim\limits_{x \to a}f(x)$ So, first of all, let's take any sequence $x_n$ such that $x_n \to 0$. Now, consider the sequence $f(x_n) = \ln(x_n)$. As $x_n$ approaches zero, $\ln(x_n)$ will approach negative infinity (how can I prove this formally). What's more, we can infer that $x_n > \lim _{n\to \infty}\ln(x_n)$, and so 
$$\lim_{x \to 0^+} \ln(x) = - \infty$$
How can I improve my reasoning to make this proof clear and acceptable?","['real-analysis', 'calculus', 'limits']"
2543217,"Error in $\int\limits_0^{\infty}dx\,\frac {\log^2 x}{a^2+x^2}$","This is my work for solving the improper integral$$I=\int\limits_0^{\infty}dx\,\frac {\log^2x}{x^2+a^2}$$I feel like I did everything write, but when I substitute values into $a$, it doesn’t match up with Wolfram Alpha. First substitute $x=\frac {a^2}u$ so$$\begin{align*}I & =-\int\limits_{\infty}^0du\,\frac {2\log^2a-\log^2 u}{x^2+a^2}\\ & =\int\limits_0^{\infty}du\,\frac {2\log^2a}{a^2+x^2}-\int\limits_0^{\infty}du\,\frac {\log^2 u}{a^2+x^2}\end{align*}$$Hence$$\begin{align*}I & =\int\limits_0^{\infty}du\,\frac {\log^2a}{a^2+x^2}\\ & =\frac {\log^2a}{a^2}\int\limits_0^{\pi/2}dt\,\frac {a\sec^2t}{1+\tan^2t}\\ & =\frac {\pi\log^2a}{2a}\end{align*}$$However, when $a=e$ Wolfram Alpha evaluates the integral numerically as$$I\approx 2.00369$$however the input that I arrived at evaluates numerically$$\frac {\pi}{2e}\approx0.5778$$Where did I go wrong? And how would you go about solving this integral?","['integration', 'definite-integrals']"
2543229,Prove that there is a number with $n$ digits that satisfy some conditions,"Prove that for every positive integer $n$ there is a positive integer with the following characteristics: I) It has exactly n digits. II) None of the digits are zero. III) It is divisible by the sum of its digits. Obs.: The base considered is base 10. What I've been able to do so far is this: The number $5^m$ has $d=\lfloor m\cdot log_{10}(5)\rfloor+1$ digits. Let $a$ be a positive number with $n$ digits such that 1) $n\geq m+1$ 2) The last digits of $n$ are the representation of $5^m$ in the decimal base. For example, 2341625 has as its last digits the representation of $5^4=625$ in the decimal base. 3) The sum of its digits is $5^{d'}$ with $d'\leq d$. If the number $5^m$ in the decimal base doesn't have $0$ as one of its digits, then $a$ will satisfy the conditions of the problem. For example: Let $m=3$ and $s(a)$ the sum of the digits of $a$. We have $5^3=125$. $s(a)\in\{5^3,5^2,5,5^0\}$(see 3) ). $a=b_1\cdots b_k125$ where $b_1,\cdots,b_k$ are the first digits of $a$. None of them are zero and $1\leq b_i\leq 9$, with $1\leq i\leq k$, therefore $k\leq b_1+\cdots+b_k\leq 9k$. $s(a)=b_1+\cdots+b_k+1+2+5\in\{5^3,5^2,5,5^0\}\Rightarrow b_1+\cdots+b_k\in\{117,17,-3,-7\}\Rightarrow $ $b_1+\cdots+b_k\in\{117,17\}$ If $b_1+\cdots+b_k=117$, then $k\leq 117\leq 9k\Rightarrow 13\leq k\leq 117$. If $b_1+\cdots+b_k=17$, then $k\leq 17\leq 9k\Rightarrow 2\leq k\leq 17$. Looking at the two inequalities above and knowing that $a=b_1\cdots b_k125$, we prove the problem for $5\leq n\leq 120$. To be clearer: Choose $k=7$, then $2\leq k=7\leq 17$. So is possible find $b_1,\cdots,b_7$ such that $b_1+\cdots+b_7=17$. Choose $b_1=\cdots=b_6=2$ and $b_7=5$, for example. Then $a=2222225125$ satisfies the conditions of the problem. One problem I can't work around is when $5^m$ has $0$ as one of its digits. That's why I can't solve the problem. This problem is found in a Brazilian journal geared toward mathematics olympiads. In the issue in which this problem appears there is the introduction of Klarner's theorem. So maybe there is a solution using this theorem, but I can not figure out how to use it in solving this problem. Klarner's theorem : Let $a,m,p$ be given positive integers. If we can cover a $m \times n$ board using $1 \times p$ pieces, with no leftovers or overlapping pieces, then $p$ divides $m$ or $p$ divides $n$","['number-theory', 'elementary-number-theory']"
2543275,"Construct a truth table for the following sentence to determine whether the argument is valid or invalid P ∨ Q, P → R, ¬R ∴ Q","Proving Validity of a Symbolic Argument Using Truth Tables I am looking to determine the validity of this argument using the truth table method: P ∨ Q, P → R, ¬R ⊨ Q I cannot yet embed the image of my truth table on here because I haven't earned emough points of my profile yet, so I will try to explain it the best I can. I have used the column headers | P | Q | R |¬R | P ∨ Q | P → R | Q | After filling out this truth table I have found that in row 3, the premises 'P ∨ Q' and 'P → R' are true and yet the conclusion is false, which would indicate that the argument is invalid. However I am wondering whether I should also take into account the truth value of the premise '¬R'. If I do this, then I find only one critical row (row 6), and here I find the conclusion to be true. As there are no rows where the premises are true and the conclusion is false, I read from this that the argument is valid. However, I am apprehensive to draw this conclusion; for one because I am not sure whether I have used the correct column headers, and for another because I am not sure whether I should be be looking at '¬R' as a separate premise and considering it's truth value to determine the validity of the conclusion. As you can probably tell,  I am a beginner in logic, so I would appreciate any help to clarify this. Thank you.","['propositional-calculus', 'logic', 'discrete-mathematics']"
2543316,Square elements of an abelian group,"Does every element of an abelian group $G$ have to be a square (ie for $g \in G$, $x = g^2$) if every element of a subgroup $H$ of $G$ and every element of the factor group $G/H$ is square? Since the elements modded out by $H$ are regained in the union of the factor group with $H$, I expect that it must be true, but that is not very rigorous and I am struggling to make it so.","['abstract-algebra', 'group-theory']"
2543317,Confusion about Taylor approximation away from center point,"I'm trying to learn Taylor expansions and was watching a tutorial here. In the tutorial, Taylor approximation is introduced by first showing Maclaurin series, which is basically taylor series at $x=0$. The introduction seems intuitive to me: First suppose we want to approximate a function $f(x)$ with polynomials at $x=0$ given derivative of $f(x)$ exists for any order at $x=0$, then we can start with very simple approximation at $x=0$:
\begin{equation}
f(x) \approx f(0)
\end{equation}
then add more and more higher order terms,
\begin{equation}
f(x) \approx f(0) + f'(0)x + f''(0)\frac{x^2}{2} + ...
\end{equation}
this makes sense, since the RHS exactly matches the LHS for any order derivatives at $x=0$, here is a picture of taylor approximation of $sin(x)$ at $x=0$ up to order 3: image or use wolfram . My question is, we are making approximation of $f(x)=sin(x)$ locally at/around $x=0$, but (as you can see from the plot) why as the more higher order terms being added, the approximation also become more and more like $f(x)$ even far away from $x=0$, intuitively why this is the case? Because what I understand is, the approximation is only derived locally around $x=0$. Does this also imply that with enough higher order terms Taylor expansion at $x=0$ and $x=a$ where $a\ne0$ are just the same? Furthermore, with enough terms does taylor series approximate $f(x)$ everywhere and not just $x=0$ anymore?","['taylor-expansion', 'polynomials', 'sequences-and-series', 'calculus']"
2543345,"If $p$ is prime, $p\ne3$ then $p^2+2$ is composite [duplicate]","This question already has answers here : For which primes p is $p^2 + 2$ also prime? (5 answers) Closed 2 years ago . I'm trying to prove that if $p$ is prime,$p\ne3$ then $p^2+2$ is composite. Here's my attempt: Every number $p$ can be put in the form $3k+r, 0\le r \lt 3$, with $k$ an integer. When $r=0$, the number is a multiple of 3, so that leaves us with the forms $3k+1$ and $3k+2$. The first one will be even when $k$ is odd, and the second one will be even when $k$ is even. So we will see what happens for each form in the case that $k$ is even (for the first form) and $k$ is odd (for the second form): $p=3k+1$, $k$ is even Since $k$ is even, we can write it as $k=2q$ for some $q$. Then $p^2+2=(3(2q)+1)^2+2=(6q+1)^2+2=6^2q^2+12q+1+2=3(12q^2+4q+1)$ So $p^2+2$ is composite. $p=3k+2$, $k$ is odd Then, $k$ can be written as $k=2q+1$, for some $q$. Then $p^2+2=(3(2q+1)+2)^2+2=(6q+5)^2+2=6^2q^2+60q+25+2=3(12q^2+10q+9)$ And again, $p^2+2$ is composite. QED Is that a correct proof? Is not the same that comes in the answer books.","['divisibility', 'number-theory', 'prime-numbers', 'modular-arithmetic', 'elementary-number-theory']"
2543473,$H_{dR}^k(M/G)\to H_{dR}^k(M)$ is injective,"Let $M$ be a smooth manifold and $G$ a finite group of automorphisms acting properly on it. If $\pi:M\to M/G$ is the projection map, prove that $\pi^*:H_{dR}^k(M/G)\to H_{dR}^k(M)$ is injective. I know how to prove that $\pi^*:\Omega^k (M/G)\to\Omega^k (M) $ is injective using the fact that $\pi$ is a surjective submersion. But how do I prove injectiveness in cohomology?","['homology-cohomology', 'smooth-manifolds', 'differential-geometry', 'pullback']"
2543508,Connection on fiber bundle of generic fiber,"I am looking for references about connections on a generic fiber bundle. 
A lot of books deal with connections on vector bundles, some books as the Kobayashi-Nomizu generalize the concept of connection to principal bundles. I know that exists also a more general notion of connection on fiber bundles (for example in Kolar-Michor-Slovak's book ""Natural Operators in Differential Geometry"" it is shown using horizontal and vertical bundles), but I have had some difficulties in finding other good references. Can someone suggest me a good book? This question is different from Reference Request for Fibre Bundle Theory from the Smooth Manifold Point of View as mine it is more specific on connections, among the books suggested there only the abovementioned K-M-S deals with  connections on general fiber bundles.","['reference-request', 'connections', 'fiber-bundles', 'differential-geometry']"
2543535,Relation between de Rham Cohomology group of Lie group as a manifold and group cohomology of Lie group,"Is there some relation between De Rham Cohomology group of Lie group as a manifold and group cohomology of Lie group? At first glance, they are two different things. De Rham Cohomology group is defined by differential form on manifold. While group cohomology is used to classify the group extension. My question: 1.For group cohomology $H^n_\sigma(G,A)$, we need group $G$, abelian group $A$ and $\sigma : G\rightarrow Aut(A)$. If I fixed $G$ is some Lie group,  $A=\mathbb{R}$ and $\sigma$ as trivial homomorphism. Is there some relation between group cohomology $H^n_0(G,\mathbb{R})$ and De Rham cohomology $H^{n}_{dR}(G)$?","['algebraic-topology', 'group-cohomology', 'differential-geometry']"
2543546,Constructing truth tables to determine the validity of a symbolic argument,"Proving Validity of a Symbolic Argument Using Truth Tables I am looking to determine the validity of this argument using the truth table method: (P ∨ ¬Q) → P I cannot yet embed the image of my truth table on here because I haven't earned enough points of my profile yet, so I will try to explain it the best I can. I have used these column headers: | P | Q | ¬Q | P ∨ ¬Q | P | After filling out this truth table I have found that the first row reads: | T | T | F | T | T | | T | F | T | T | T | | F | T | F | F | T | | F | F | T | T | F | Row 2 shows all true premises and a true conclusion, however row three shows all true premises and a false conclusion (which would indicate invalidity). I want to conclude that the presence of a row where a false conclusion is derived from true premises determines that the argument is invalid. However, I was just concerned that Row 2 (showing all true premises and a true conclusion) somehow somehow affect this. As you can probably tell, I am a beginner in logic, so I would appreciate any help to clarify this. Thank you.","['propositional-calculus', 'logic', 'discrete-mathematics']"
2543551,Proving a set of functions is uncountable,"I am trying to prove that $D(\mathbb{N}$)={ $f\in \mathbb{N}^\mathbb{N}$ | f is a bijection such that $f(n)\neq n$ for all $n\in\mathbb{N}$} is uncountable. So, I was thinking of showing $D(\mathbb{N})$ ~ $P(\mathbb{N})$ using Cantor Bernstein Theorem. For the one direction, is it found to say since $D(\mathbb{N})\subset \mathbb{N}^\mathbb{N}$ ~$P(\mathbb{N})$ then there is an injection from $D(\mathbb{N})$ to $P(\mathbb{N})$? I am not too sure how to go about the other direction. Should I show equinumerous to functions from $\mathbb{N}^\mathbb{N}$ instead of using the power set?","['proof-writing', 'elementary-set-theory']"
2543572,Solving $\frac{d^2 \theta}{d x^2} - m^2\theta = 0$ using the Ritz method,"I'm trying to solve the following ODE using the Ritz method: $$\frac{d^2 \theta}{d x^2} - m^2\theta = 0$$ With the boundary conditions $$\frac{d\theta}{dx}\Bigg{|}_{x=0} = 0$$ $$\theta(1) = \theta_0$$ I'm trying to follow the book ""Conduction Heat Transfer"" by Vedat S. Arpaci (chap. 8). So this is what I did so far: 1) Transform the problem into a variational problem: $$
\int_o^1 \Bigg{(}\frac{d^2 \theta}{d x^2} - m^2\theta\Bigg{)} \delta\theta\ dx = 0
$$ 2) (Ritz Method) Select a convergent sequence of functions such that $$
y(x) = \sum_{n=0}^Na_n\phi_n(x)
$$ I choose the following $y(x)$: $$y(x) = \sum_{n=0}^N\theta_0(1 - (1 - x^2)(a_0 + a_1x^2 + a_2x^4 + ...))$$ Which yields the approximation $$
y(x) = \phi_0(x) = \theta_0(1 - (1 - x^2)a_0)
$$ 3) Apply (2) in (1) in order to obtain $a_0$ $$
\int_o^1 \Bigg{(}\frac{d^2 \theta}{d x^2} - m^2\theta\Bigg{)} \delta\theta\ dx =
$$
$$
\theta_0\int_o^1 \Bigg{(}2a_0 - m^2(1 - (1-x^2)a_0) \Bigg{)} \delta\theta\ dx = 0
$$ Where $\delta F$ is the variation of the functional $F(x, y, y^\prime)$, that is, $$
\delta F = \frac{\partial F}{\partial y}\delta y + \frac{\partial F}{\partial y^\prime}\delta y^\prime
$$ And this is where I got stuck. The book suggest the following: $$
\theta_0\int_o^1 \Bigg{[}2a_0 - m^2(1 - (1-x^2)a_0) \Bigg{]} \delta\theta\ dx =
$$
$$
\theta_0\int_o^1 \Bigg{[}2a_0 - m^2(1 - (1-x^2)a_0) \Bigg{]} \Bigg{[} -(1-x^2)\delta a_0 \Bigg{]} dx = 0
$$ But I don't understand the application of $\delta \theta$ in this case, because I though $a_0$ was meant to be a constant (Should it really?), then $\theta$ is not a functional in relation to it. Assuming $a_0$ is a function, and the step above is correct (Which I don't understand why), I would also be stuck in the next step: $$
\theta_0\int_o^1 \Bigg{[}2a_0 - m^2(1 - (1-x^2)a_0) \Bigg{]} \Bigg{[} -(1-x^2)\delta a_0 \Bigg{]} dx = 0
$$ For this step, the book suggests to use the following identity, which I was unable to apply here: $$
\int_0^l(l^2-x^2)^mdx = \frac{(2m)!!}{(2m+1)!!}l^{2m+1}
$$ I would be grateful for any suggestion at this point.","['variational-analysis', 'ordinary-differential-equations', 'mathematical-physics', 'finite-element-method']"
2543653,Group of push-out,"I'm looking at a question regarding the push-out of $\mathbb{Z}$ to itself via the $\times2$ and $\times3$ homomorphisms. As I see it, the group will be $\{x,y\mid x^3=y^2\}$. But the questions asks to prove that it is $\{x,y\mid xyx=yxy\}$, with a hint to consider $xy$ and $yxy$. I guess that I can switch to generators that are combinations of $x$ and $y$, such as the suggested ones, but I still can't get the presentation that I'm after. Any suggestions on how I can prove this result?","['group-homomorphism', 'group-theory', 'free-groups']"
2543677,Can Cauchy's theorem for abelian groups be proved directly from Lagrange's theorem?,"I am trying to verify the following proposition: Let $G$ be a finite Abelian group and let $p$ be a prime that divides the
  order of $G$. Then $G$ has an element of order $p$. My proof:
By Lagrange's theorem: $x^{|G|}=e$. By assumption we have $kp=|G|$ for some prime $p$. So $e=x^{|G|}=x^{kp}$. Thus $|x^k|=p$. $\blacksquare$ The book's proof uses induction and cosets -- is this necessary? For reference, here's the book proof: Clearly, this statement is true for the case in which $G$ has ­order 2.
  We prove the theorem by using the Second Principle of Mathematical Induction on $|G|$. That is, we assume that the statement is true for all Abelian groups with fewer elements than G and use this assumption to show that the statement is true for G as well. Certainly, G has elements of prime order, for if $|x| = m$ and $m = qn$, where $q$ is prime, then $|x^n| = q$. So let $x$ be an element of $G$ of some prime order $q$, say. If $q=p$, we are finished; so assume that $q \neq p$. Since every subgroup of an Abelian group is normal, we may construct the factor group $\bar{G} = G/\langle x\rangle$. Then $\bar{G}$ is Abelian and $p$ divides $|G|$, since $|\bar{G}| = |G|/q$. By induction, then, $G$ has an element — call it $y\langle x\rangle$ — of order $p$. Then, $(y\langle x\rangle)^p = y^p\langle x\rangle = \langle x\rangle$ and therefore $y^p \in \langle x\rangle$. If $y^p = e$, we are done. If not, then $y^p$ has order $q$ and $y^q$ has order $p$. $\blacksquare$","['finite-groups', 'abelian-groups', 'group-theory', 'solution-verification']"
2543688,When is $\frac{a^2+b}{b^2+a}$ an integer?,"Obviously with $a,b$ integers and $b$ can't be greater than $a$. I found some solutions, like $(12,8)$ and $(135,95)$ which give the integer $2$, and $(10,5)$ which gives $3$, but I can't find a relationship between the solutions.",['number-theory']
2543740,The Inverse of $y=x^5-x^3+x$ in terms $y=$,"I tried finding the inverse of $y=x^5-x^3+x$ in terms of getting there to be only one y value. Such that y equals some function of x. I know that the original function is a one to one function because it passed the horizontal line test. Thus it must have a inverse function. The first thing I did was switch the y's and x's 
$$x=y^5-y^3+y$$
The next thing I did was take the derivative of the function because I thought I could maybe try to take the integral after which might help me.
$$\frac{dy}{dx}(x=y^5-y^3+y)$$
$$\frac{dy}{dx}=\frac{1}{5y^4-3y^2+1}$$
I'm confused on how to take the integral of the function and that is as far as I got. If taking the integral of the function is not the right way can some please show me what is?","['algebra-precalculus', 'calculus']"
2543784,Mean value thorem - Showing $\sqrt{1+x} < 1+\frac{x}{2}$ for $x>0$,"So as the title states I have to show $\sqrt{1+x} < 1+\frac{x}{2}$ for $x>0$. This is a example from the book which has to be explained for me, i'm having a hardtime understanding the proof. I do however understand the concept of MVT. So the rest of the solution looks like the following: If $x>0$, apply the Mean-Value Theorem to $f(x)= \sqrt{1+x}$ on the interval $[0,x]$. There exist $c\in [0,x]$ such that
  $$\frac{\sqrt{1+x}-1}{x}=\frac{f(x)-f(0)}{x-0}=f'(c)=\frac{1}{2\sqrt{1+c}}<\frac{1}{2}
$$
  The last inequality hold because $c>0$. Mulitiplying by the positive number $x$ and transposing the $-1$ gives $\sqrt{1+x} <1+\frac{x}{2}$, So I am not sure why he(the author) choose $\frac{1}{2}$, it seems a little arbitrary to me. My guess is that you're allowed to pick a number for the derivative of $c$ which suits the cause/solution best, as long as it's $0<c<x$. I'm not sure though. All help would be greatly appriciated!","['inequality', 'calculus']"
2543787,Indicator variable with boxes and balls,"We have 10 blue balls labeled from 1 to 10 and 10 red balls with same labels and we randomly put them into 10 boxes so that in each box is one blue and one red ball. Find the expected number of boxes, that have blue and red ball with same labels. In solution it says let indicator value have properties I(0) = 9/10 and I(1)=1/10. E(X)=10*1/10 = 1 Now I don't understand why, because I would say I(1) = 10*(2C2) / (20C2) since we have to pick 2 balls out of 20 and we have 10 pair of them ({1,1},{2,2},..). And E(X) 10*I(1). But is it 1/10 because we have to choose one pair out of 10? If that is true, why can we say that, since the number of all combinations is 20C2.","['combinations', 'balls-in-bins', 'probability', 'combinatorics', 'random-variables']"
2543802,"If $A$ and $B$ are $n×n$ matrices, $AB = -BA$ , and $n$ is odd, show that either $A$ or $B$ has no inverse. [duplicate]","This question already has answers here : Proof if $AB+BA=0$ Then atleast one of the matrices are singular. (4 answers) Closed 6 years ago . If $A$ and $B$ are $n×n$ matrices, $AB = -BA$ , and $n$ is odd, show that either $A$ or $B$ has no inverse. I have no clue how to do this and any help/guidance would be appreciated! Thanks in advance! $$det(AB) = det(-BA)$$ 
$$det(AB)= det(-B)det(A)$$ 
$$det(AB) = (-1)^ndet(BA)$$ since n is odd 
$$det(AB) = -det(BA)$$
$$det(A)det(B) = -det(B)det(A)$$
$$2det(A)det(B) = 0$$ Therefore $det(A)=0$ or $det(B)=0$","['matrices', 'linear-algebra', 'inverse']"
2543810,Are there partial orders (posets) of dimension $n$ with arbitrarily many linear extensions?,"By dimension, I use the definition that was formulated by Dushnik and Miller: If $P$ is a partial order, then the dimension of $P$ is the minimum number of linear extensions of $P$ whose intersection is exactly $P$. A, not nessecarily minimum, set of linear extensions whose intersection is exactly $P$ is called a realizer . Intuitively, as the number of linear extensions increases, the number of possible realizers increases, possibly decreasing the dimension. EDIT: $n=1$: The answer is no. The only partial orders with dimension $1$ are already linear orders, so every dimension $1$ poset has only one linear extension. $n=2$: As mentioned by @CarlMummert, antichains of size $m$ have dimension $2$ and have $m!$ linear extensions, so there exist posets of dimension $2$ with arbitrarily many linear extensions.","['combinatorics', 'order-theory']"
2543834,Eigenvectors and their relationship to (first order) linear differential equations,"Ok, so in my differential equations class we've been doing problems which more or less amount to solving equations of the form: $$\frac{dY}{dt} = AY$$ Where $A$ is just some $2\times2$ linear transformation and $Y$ is a parametric vector function defined more specifically as $$Y(t) = \begin{bmatrix}
x(t) \\
y(t)
\end{bmatrix}$$ The end result, assuming that there exists $\lambda_1, \lambda_2 \ne 0; \lambda_1 \ne \lambda_2$ which define the eigen values for A, is a definition for $Y(t)$ of the form, $$Y(t) = k_1e^{\lambda_1t}\vec{V_1} + k_2e^{\lambda_2t}\vec{V_2}$$ Where $\vec{V_1}, \vec{V_2}$ are the corresponding eigen vectors to their respective eigen values and $k_1, k_2$ are just some constants. For solutions which involve either $k_1 = 0$ or $k_2 = 0$ , the end result is a straight-line solution. The rest are exponential curves within the vector space defined by the eigen vectors. My understanding of eigen vectors, from a linear algebra class I took a year ago, so far is as follows (roughly): geometrically speaking, an eigenvector is any vector whose direction after transformation by some matrix $A$ remains the same. It's only scaled and/or negated. Every eigenvector for some matrix $A$ composes a subspace which in turn defines the eigen space for $A$ 's vector basis. therefore, the eigenvectors which $span(A)$ are linearly independent and define a coordinate space which also exists within $A$ . Regardless of whether or not the above is correct (if there's a mistake, any clarification/correction would be appreciated), what is it about eigenvectors specifically which allows for them to be used to solve these forms of differential equations?","['eigenvalues-eigenvectors', 'ordinary-differential-equations', 'linear-algebra']"
2543845,Submanifolds of $\mathbb{R}^{n}$,$X$ is a submanifold of $\mathbb{R}^{n}$ if and only if for all $p\in X$ exist an open set $U\subset\mathbb{R}^{n}$ and a $C^{\infty}$ map $r:U\rightarrow U$ such that $r\circ r=r$ and $X\cap U=r(U)$. In the first way $\Rightarrow$ i think it is easy but in the second way $\Leftarrow$ i am not shure how to carry that to the definition of a submanifold.,"['differential-geometry', 'differential-topology']"
2543860,The angles of the triangle ABC satisfy A = 3B. What is the least possible perimeter of ABC assuming its sides are integers.,"The angles of the triangle $\bigtriangleup ABC$ satisfy $\measuredangle A = 3* \measuredangle B$. What is the least possible perimeter of $ \bigtriangleup ABC$ assuming its lengths are integers. This is a problem that was in a packet we received in our problem-solving club at school. Here is what I have so far The smallest possible triangle whose sides are all integers would be $(1,1,1)$ with perimeter, $P = 3$. The smallest right triangle would be $(3,4,5)$ with $P = 12$. Since the right triangle has angles $(30,60,90)$, it meets the conditions to be the triangle we need. From this, I've deduced that,
$$3 < P_{ABC} \leq 12$$
From here I have gone case by case, $P = 4$, $P= 5$, and so on to see if there is a sum of three integers that would make a triangle. I used the triangle inequality to get rid of any sums that don't make a triangle and if it was possible to make I triangle I calculated the angles.
Going through these cases I have not found a triangle that meets the condition, so I believe the smallest possible perimeter is 12. I was curious if anyone has another way to do this problem, thanks EDIT: As Oscar pointed out I am wrong with my assumptions so I am back to the drawing board","['contest-math', 'geometry']"
2543862,"Evaluating the integral $\int_0^{\infty} \frac{\sin(x)}{\sinh(x)}\,dx$","I was trying to evaluate the following integral,
 $$I=\int_\limits {-\infty}^{\infty} \dfrac{\sin(x)}{\sinh(x)}\,dx$$  but had no success. I first expanded the the hyperbolic sine:
$$I=2\int_\limits {-\infty}^{\infty} \dfrac{\sin(x)}{e^{x}-e^{-x}}\,dx=2\Im \int_\limits {-\infty}^{\infty} \dfrac{e^{ix}}{e^{x}-e^{-x}}\,dx$$
I then substituted $u=e^x$,
$$I=2\Im\int_\limits {0}^{\infty} \dfrac{u^i}{u^2-1}\,du$$
Now, I'm not really sure what to do. Also, after exchanging the $\Im$ with the integral seemed to create a non-integrable singularity at $u=1$. When can you not do that?","['improper-integrals', 'integration', 'calculus']"
2543866,Regular closure of $\mathbb{Q}(t)$,"Let $K$ be the algebraic closure of $\mathbb{Q}(t)$, so $\overline{\mathbb{Q}(t)} = K$. How to describe the subfield L of K which is the regular closure of $\mathbb{Q}(t)$, so $L\cap{\overline{\mathbb{Q}}}=\mathbb{Q}$ and $L$ is maximal with respect to this property and being algebraic over $\mathbb{Q}(t)$?","['abstract-algebra', 'field-theory']"
2543883,Standard or non-standard notation for a function not being dependent on a specific variable.,"Is there a standard or non-standard notation for a function not being dependent on a specific variable. For example, if a function depends on $t$ (time), we denote it $f(t)$. On the other hand, is there a way to express in symbols that $f$ does not vary with $t$? Something like $\forall t_1:\forall t_2: f(t_1)=f(t_2),$ but that logical statement written more compactly.","['notation', 'logic', 'functions']"
2543887,Orthogonal Projection of a function onto $M$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Let $I_1, · · · , I_N$ be pairwise disjoint intervals whose union is $[0,1]$. Let
  $$M = \lbrace g ∈ L^2([0,1]) :\text{ g is constant on $I_n$ } \forall n \rbrace.$$
   Suppose $f \in L^2([0,1])$. Determine $P_M f$. Please help.","['functional-analysis', 'approximation-theory', 'hilbert-spaces']"
2543943,Bounds for change of variable,"U and V are independent and uniformly distributed on (0,1). Find the joint density of $X=\frac{\sqrt{U}}{\sqrt{U}+\sqrt{V}}$ and $Y={\sqrt{U}+\sqrt{V}}$. I've been able to find without a hitch that $f_{XY}(x, y)=4(1-x)xy^3$ for some values of X and Y. My textbook confirmed that this is correct. My problem comes from evaluation the values of X and Y over which the joint pdf takes a positive value. I reasoned that, since $0<u<1$ and $0<v<1$, that $0<x<1$ and $0<y<2$. Integrating the pdf over these values of x and y, however, does not yield one. The textbooks says that the bounds are $0<x<1$ and $0<y<\min\left(\frac{1}{x}, \frac{1}{1-x}\right)$, which indeeds integrate to 1. How were these bounds for y obtained? I have a feeling that the answer might be connected to the fact that $X=\frac{\sqrt{U}}{Y}$, but I am unable to explain why.","['change-of-variable', 'probability']"
2543985,"Show the series
$\sum_{n=1}^\infty\frac{n^2a_n}{(a_1+a_2+\cdots+a_n)^2}$ is convergent.","Assume $a_i>0$ and $\sum\limits_{n=1}^\infty\dfrac{1}{a_i}$ is convergent. Show the series
$$\sum_{n=1}^\infty\frac{n^2a_n}{(a_1+a_2+\cdots+a_n)^2}$$ is convergent. Since we can get the convergence of
$$\sum_{n=1}^\infty\frac{n}{a_1+a_2+\cdots+a_n},$$
is it feasible to apply Abel's test? Or I should use other methods?","['convergence-divergence', 'sequences-and-series', 'calculus']"
2544020,Relations Proof: Intersection of Two Sets of Path Length n,"I am trying to answer the following question: Prove that $(R \cap S)^{n} \subseteq (R^{n} \cap S^{n})$ for all $n\geq1$ Attempt using Induction Base Step $(R \cap S)^{1} \subseteq (R^{1} \cap S^{1})$ $R \cap S \subseteq R \cap S$ (obviously true) Induction Assumption Assume that $(R \cap S)^{k} \subseteq (R^{k} \cap S^{k})$ for some arbitrary $k \geq 1$ Prove for k+1 $(R \cap S)^{k+1} \subseteq (R^{k+1} \cap S^{k+1})$ Here, I'm not sure where to use the our assumption that it is true for $n = k$ Attempt Using Mathematical Logic The relation $R^{n}$ on set A contains all $(a,b)$ such that $a R^{n} b$ for some $a \in A,b \in A$ . Similarly, the relation $S^{n}$ on set A contains all $(c,d)$ such that $c S^{n} d$ for some $c \in A,d \in A$ . $R\cap S$ on set A contains all $(e,f)$ such that $e R f$ and $e S f$ for some $e \in A,f \in A$ . How do I show what $(R\cap S)^{n}$ is, and prove it is a subset of $R^{n} \cap S^{n}$ ?","['proof-writing', 'relations', 'discrete-mathematics']"
2544044,Is there a set whose power set is countably infinite? [duplicate],"This question already has answers here : Existence in ZF of a set with countable power set (2 answers) Closed 6 years ago . Does there exist a set whose power set is countably infinite? I know for sure that if a set has a finite number of elements, then its power set must have a finite number of elements, and if a set has an infinite number of elements, then its power set must have an infinite number of elements (possibly uncountably many elements). Then, there must not exist something like that (which I stated at first). Am I right? Please someone clarify it.","['cardinals', 'elementary-set-theory']"
2544045,Optimal stopping in red vs black card game deck of 52 cards,"I have a optimal stopping problem that is solved by recursion. I was stumped by this question in an interview once. I am hoping someone can walk me through the reasoning so I can reproduce it on similar problems. Imagine you are playing a card game you start with a well shuffled deck of $52$ cards, containing $26$ red cards and $26$ black cards, stacked face down. You have a sequence of turns, $52$ possible turns in total, each turn you either pull the top card and turn it over, or you quit. If you pull a red card you win $1$ , and if you pull a black card you lose $1$ .  If you played all $52$ turns without stopping you are guaranteed to break even. What is the optimal stopping strategy? The solution at the time involved recursion, or a recursion equation. The base cases are that if you know the deck has only red cards remaining (i.e. all $26$ black cards have been pulled) you keep playing until finished. If you know the deck has only black cards remaining, you definitely stop. Working back from this, you get the policy. But I don't recall the notation for writing this policy/decision rule. I suspect it looks something like a difference or recursion equation, but I'm not sure.","['recurrence-relations', 'decision-theory', 'recursion', 'card-games', 'ordinary-differential-equations']"
2544074,How to recover a divisor from its valuation (Hartshorne II.6 and ex. II.4.5),"Throughout this post we assume $X$ is a scheme satisfying the condition (*) stated at the beginning of Hartshorne II.6 ($X$ is a noetherian, integral, separated scheme which is regular in codimension 1). Denote the fraction field of $X$ by $k(X)$. Consider a prime divisor $Y\subset X$ with generic point $\eta$. Then, the local ring $\mathcal{O}_{\eta,X}\subset k(X)$ is a DVR with valuation $v_Y$. Hartshorne then claims that, conversely, given the discrete valuation $v_Y: k(X)^\times\to\mathbb{Z}$ it's possible to recover $Y$ via exercise II.4.5, which states de following: let $X$ be an integral of finite type over a field $k$, having function field $k(X)$. We say that a valuation $k(X)/k$ has center $x$ on $X$ if it's valuation ring dominates $\mathcal{O}_{X,x}$ (a) If $X$ is separated over $k$, then the center of any valuation of $k(X)/k$ on $X$ (if it exists) is unique. [...] I have two main questions, one regarding the proof of this exercise and the other on how to apply it to the divisor situation: (1) Exercise 4.5 seems like a simple application of the valuative criterion of separatedness, so my first question is: do we really need the finite type hypothesis in here? To show this I want to construct the following diagram:
$$
\require{AMScd}
\begin{CD}
\operatorname{Spec}K(X) @>{}>> \operatorname{Spec}\mathcal{O}_{X,x}\\
@VVV @VVV \\
\operatorname{Spec}R_v @>{}>> X,
\end{CD}
$$
where the generic points $(0)$ get mapped to $x\in X$. However, I don't know where to map the closed point of $\operatorname{Spec}R_v$ . Is there a canonical choice? After this the result follows immediately, even without the finite type assumption. (2) Given a prime divisor $Y$ with valuation $v_Y$, I want to show that the center of the valuation is exactly $\eta$, in which case it becomes clear how we recover $Y$. One direction is clear: $\eta$ is easily seen to be in the center of $v_Y$ ($\mathcal{O}_{\eta,X}$ dominates itself trivially). For the converse I consider two cases: $x$ is in the center of $v_Y$ and either $x\in Y$ or not. If $x\in Y$ then by passing to an affine neighborhood, $U=\operatorname{Spec}A$, $x$ corresponds to some prime ideal $p$ and $Y$ another one $P$ where $P\subseteq p$. Since $A_P$ dominates $A_p$ we have in particular that $A_p\subseteq A_P$ and $P\cap A_p=p$ (inside $k(X)$). However, $P\subset A_p$ and we get that $P=p$, i.e., $x$ must be the generic point of $Y$. When trying to apply the same approach to the case where $x\not\in Y$ I get stuck, we want to get a contradiction, but since I don't know how the local rings $\mathcal{O}_{X,x}$ and $\mathcal{O}_{X,\eta}$ (corresponding to $v_Y$) interact within $k(X)$ I can't proceed. Any suggestions for this part? I guess part of my problem is that I don't know how would we recover a prime divisor from an arbitrary valuation.","['schemes', 'valuation-theory', 'algebraic-geometry']"
2544154,Evaluating $\int_0^{\infty} \frac{\tan^{-1} x}{x(1+x^2)} dx$,"The question is to evaluate $$\int_0^{\infty} \frac{\tan^{-1} x}{x(1+x^2)} dx$$ I used the substitution $x=\tan a$ then the given integral becomes $\int_0^{\pi/2} \frac{\tan^{-1}(\tan a)}{\tan a} da$
Now $\tan^{-1} (\tan a)=a \forall a \in [0,\pi /2]$ so that the integrand becomes $a/ \tan a$.i am facing trouble evaluating this.i tried using $a \to \pi/2 -a$ but couldn't simplify.Any ideas?","['integration', 'calculus']"
2544183,The graph of the derivative of a function $f(x)$ is shown and $f(-3)=-1$. How many local minima of the function $g(x) = \left | 2f(x)+x^2 \right |$?,"The graph of the derivative $f'(x)$ of a function $f(x)$ is shown in the figure below. If $g$ is a function defined for all $x$ by $g(x) = \left | 2f(x)+x^2 \right |$ and $f(-3)=-1$ , how many local minima does the function $g$ have? This is what I have done.
From the figure, I can draw this table We have $g(x)=\sqrt{( 2f(x)+x^2 )^2}$ so its derivative is $g'(x)=\frac{2(2f(x)+x^2)(2f'(x)+2x)}{2\sqrt{(2f(x)+x^2)^2}}$ .
I see that $2f'(-3)+2(-3)=0$ and $2f'(-1)+2(-1)=0$ so $g'(-3)=0$ and $g'(-1)=0$ . I believe that there exists an $-3<x_0<-1$ such that $2f'(x_0)+2(x_0)=0$ which implies $g'(x_0)=0$ . I'm stuck here, I don't know the sign of $g'(x)$ in any interval. This is my prediction.
We have $g(x)=\left | 2\left [ f\left ( x \right )-\left ( \frac{-x^2}{2} \right ) \right ] \right |$ , consider the graph of the function $y=f(x)$ and the function $y=\frac{-x^2}{2}$ . From the table above, I think that the graph of the function $y=f(x)$ is always ""higher"" (I don't know the exact word) than the graph of the function $y=\frac{-x^2}{2}$ for all $x$ , which implies $\left [ f\left ( x \right )-\left ( \frac{-x^2}{2} \right ) \right ] >0$ for all $x$ , so $g(x) = 2f(x)+x^2$ and its derivative is $g'(x)=2f'(x)+2x=2[f'(x)-(-x)]$ . Now from the figure above, draw the graph of the function $y=-x$ . We will see that the two graphs have 3 intersection points, which are $(-3,3)$ , $(-1,1)$ and $(x_0,-x_0)$ where $-3<x_0<-1$ , we notice that $f'(x)-(-x)>0$ for $-3<x<x_0$ (the graph of $y=f'(x)$ is higher) and $f'(x)-(-x)<0$ for $x_0<x<-1$ (the graph of $y=-x$ is higher). I draw this table I conclude that $g$ has 2 local minima. If my prediction is right please show me how to prove this, or show me another way to finish this exercise. Thank you.","['derivatives', 'maxima-minima', 'calculus', 'graphing-functions']"
2544219,Proving Validity of a Symbolic Argument Using Truth Tables,"Proving Validity of a Symbolic Argument Using Truth Tables I am looking to determine whether the following argument is valid/invalid using the truth table method: $$(P \to (Q \land\lnot Q)) \models \lnot P$$ I cannot yet embed the image of my truth table on here because I haven't earned enough points of my profile yet, so I will try to explain it the best I can. I have used these column headers: $$\begin{array}{|c:c|c:c:c|c|}\hline
P & Q & ¬Q & Q ∧ ¬Q & P → (Q ∧ ¬Q) & ¬P 
\\ \hline
 T & T & F & F & F & F 
\\
 T & F & T & F & F & F 
\\
 F & T & F & F & T & T 
\\
 F & F & T & F & T & T 
\\ \hline
\end{array}$$ When it comes to reading validity from the truth table, I am not 100% certain what columns I should be taking into account. At the moment I am only taking account of the 4th column i.e. $(P \to (Q \land \lnot Q)$ as the only premise whose truth value I should look at, from which I can read that there are no situations where a false conclusion is derived from true premises and hence the argument is valid. I just would like to clarify whether this is the right way of approaching reading validity (as you can probably tell I am a beginner in logic). Thank you.","['propositional-calculus', 'logic', 'discrete-mathematics']"
2544229,Is infinite upper triangular matrix with nonzero entries on the diagonal invertible?,"Let's say we have an infinite square matrix where rows and columns are indexed by $\mathbb{N}$. We also know that every entry on the diagonal is nonzero and the matrix is upper triangular. Is it enough to conclude that our matrix is invertible? It is true for finite matrices, but does it also hold for infinite matrices? If not, what if we consider the case where only finite number of entries in each row and column are nonzero? What I want to do is: Let's say we have 
$$A(i, j) = \sum_{k \in \mathbb{N}} B(i, k) \cdot C(k, j)$$ 
for $i, j \in \mathbb{N}$ and we want to prove that there exists $D$ such that
$$C(i, j) = \sum_{k \in \mathbb{N}} D(i, k) \cdot A(k, j).$$ 
Then we can rewrite it as a matrix product:
$$A = B \cdot C.$$
Can we use the fact that $B$ is upper triangular and has nonzero diagonal to show that
$$C = B^{-1} \cdot A$$
and
$$C(i, j) = \sum_{k \in \mathbb{N}} B^{-1}(i, k) \cdot A(k, j)?$$","['matrices', 'infinite-matrices', 'inverse']"
2544261,Find $x$ such that $2^x+3^x-4^x+6^x-9^x=1$,"The question: Find values of $x$ such that $2^x+3^x-4^x+6^x-9^x=1$, $\forall x \in \mathbb R$. Notice the numbers $4$, $6$ and $9$ can be expressed as powers of $2$ and/or $3$. Hence let $a = 2^x$ and $b=3^x$. \begin{align}
1 & = 2^x+3^x-4^x+6^x-9^x \\
& = 2^x + 3^x - (2^2)^x + (2\cdot3)^x-(3^2)^x\\
& = 2^x + 3^x - (2^x)^2 + 2^x\cdot3^x-(3^x)^2 \\
& = a+b-a^2+ab-b^2 \\
0 & = a^2-ab+b^2-a-b+1
\end{align} \begin{align}
0 & = a^2-ab+b^2-a-b+1 \\
& = 2a^2-2ab+2b^2-2a-2b+2 \\
& = (a^2-2ab+b^2)+(a^2-2a+1)+(b^2-2b+1) \\
& = (a-b)^2 + (a-1)^2 + (b-1)^2
\end{align} This is where I am stuck. I am convinced that this factorisation could help solve the question, but I don't know how. Also, once we find values for $x$, we must prove that there are no further values of $x$. Could someone complete the question?","['algebra-precalculus', 'problem-solving']"
2544283,Convergence of subsequences in a compact set of $\mathbb{R}^n$,"For any sequence in a compact set $K$ of $\mathbb{R}^n$, it is well known that there is a subsequence that is convergent to a point in $K$. Is this true that for any sequence in a compact set $K$ of $\mathbb{R}^n$, there is a partition of this sequence into several subsequences that every subsequence is convergent to a point in $K$. Intuitively, it is correct to me. Any constructive proof?","['general-topology', 'real-analysis', 'limits']"
2544285,Work out the value of $\int_{0}^{\infty}{\cos{x}\over x}[1-\cos(nx)]\mathrm dx$,How to show that $(1)=\ln(n^2-1)?$ $$2\int_{0}^{\infty}{\cos{x}\over x}[1-\cos(nx)]\mathrm dx=\ln(n^2-1)\tag1$$ $n>1$ $\cos(nx)=2\cos{x}\cos[(n-1)x]-\cos[(n-2)x]$ $$2\int_{0}^{\infty}\left({\cos{x}\over x}-{{2\cos^2{x}\cos[(n-1)x]\over x}}+{\cos{x}\cos[(n-2)x]\over x}\right)\mathrm dx\tag2$$,"['integration', 'definite-integrals', 'laplace-transform']"
2544286,Birthday problem without electronic aids in a nuclear winter,"The Birthday Problem is well known, with many related questions and answers on this site. Most solutions somewhere make use of a statement equivalent to:
$\frac{365!}{342!365^{23}} < \frac 1 2$. The correctness of this statement is usually demonstrated by asserting (by use of a calculator, other electronic means, or log tables) that the left hand side is approximately 0.492703. My question asks: ""What would be the most efficient way of demonstrating the truth of the above statement using only pen and paper?""  Assume that all computers and tables of logarithms have been destroyed in a nuclear holocaust. Clearly it would be possible (but painful) to do this following long-division in long-hand:
$$\frac{365\cdot 364 \cdot 363 \cdot \dots \cdot 343 } {365\cdot 365 \cdot 365 \cdot \dots \cdot 365}$$ but there must be better ways. My first thought was to prove something simpler from which the result still follows.  For example, one can show easily with pen and paper that
$$\frac{365!}{342!365^{23}} = \prod_{k=0}^{22}\left(1-\frac k {365}\right)<\prod_{k=0}^{22}  e^{-\frac k {365}}= \exp\left({-\frac {253}{365}}\right).$$  It would therefore be sufficient to demonstrate that $\exp\left({-\frac {253}{365}}\right) < \frac 1 2$ (which is a true statement since $\exp\left({-\frac {253}{365}}\right) \approx 0.4999982478$). Equivalently it would be sufficient to show that $\frac{253}{365}>\ln 2$.  But these may not be the best ways of proceeding, and I have not managed to bring them to a satisfactory pen-and-paper conclusion.","['inequality', 'taylor-expansion', 'asymptotics', 'probability', 'numerical-methods']"
2544394,The inverse of a $\Psi$DO is a $\Psi$DO,"The following question looks quite simple, but unfortunately I was not able to find an answer in the literature so far. Let $A \in OPS^m(X)$, $m \in \mathbb R$, be a pseudodifferential operator on a compact manifold $X$. If $A$ is invertible, is it true that the inverse $A^{-1}$ is actually a pseudo-differential operator $A^{-1} \in OPS^{-m}(X)$? By invertble I mean that $A^{-1}$ is defined on $C^\infty(X)$ and in this space $AA^{-1} = A^{-1}A = \mathrm{Id}$. For example, a similar statement is used in the beginning of p.293 of [M.Taylor, Pseudodifferential Operators, 1981]: If $\in OPS^m$ is elliptic, positive self-adjoint operator on a
  compact manifold $X$, or order $m>0$, then $(I+P)^{-1} \in OPS^{-m}$ is compact. Since it is not explained, I think it must be quite obvious.","['functional-analysis', 'microlocal-analysis', 'pseudo-differential-operators']"
2544418,Is a power series uniformly convergent in its interval of convergence?,"Let $R>0$ be the radius of convergence of a power series $Σa_nx^n$. Is it not uniformly convergent in $(-R,R)$? My book goes out of its way to say that if $[a,b]⊂(-R,R)$, then the power series converges uniformly in $[a,b]$. Can't we just say that it is uniformly convergent in $(-R,R)$?","['uniform-convergence', 'real-analysis', 'power-series', 'calculus']"
2544420,Is $\lim_{n\to\infty}2^{-n/2}\sum_{k=1}^{n-1}\frac{k^2\cdot2^{k/2}}{k+\frac{1}{2}}\left(\frac{\Gamma(k)}{\Gamma(k+\frac{1}{2})}\right)^2=1+\sqrt{2}$?,"After I've read a question posted on MathOverflow I tried to combine it with the statement of a problem published in the American Mathematical Monthly (that I've omitted, in fact in my sum are dropped two terms since the Gamma function is undefined at such points). That is, the MONTLHY published a theorem that now I've specialized for some sequeces and numbers, and after I've calculated with Wolfram Alpha online calculator my conjecture, the following in next question. Question. Prove or refute $$\lim_{n\to\infty}2^{\frac{-n}{2}}\sum_{k=1}^{n-1}\frac{k^2\cdot2^{\frac{k}{2}}}{k+\frac{1}{2}}\left(\frac{\Gamma(k)}{\Gamma(k+\frac{1}{2})}\right)^2=1+\sqrt{2},\tag{1}$$
  where $\Gamma(s)$ denotes the gamma function. Many thanks. I don't know if from the detailed and interesting solution of MONTHLY's problem can be deduced my closed-form $(1)$ easily (I do not think so). Thus my conjecture is based on experiments with the mentioned online tool and my code sum 2^(-100000000/2) k^2 2^(k/2)/(k+1/2) (Gamma(k)/Gamma(k+1/2))^2, from k=1 to 100000000-1 or clik over More digits after you run this code sum 2^(-1000000000/2) k^2 2^(k/2)/(k+1/2) (Gamma(k)/Gamma(k+1/2))^2, from k=1 to 1000000000-1 I know that should be useful Stirling's approximation or some inequality related to the gamma function, combined with some numeric method of summation. References: [1] The sum of an hydrogen atom related infinite series , posted on MathOverflow with quote to the article by Tamar Friedmann and C. R. Hagen, Quantum Mechanical Derivation of the Wallis Formula for $\pi$, Journal of Mathematical Physics 56 , 112101 (2015). [2] Problem E 1760 [1965,183] A Convergent Sequence Arising from a Difference Equation , proposed by I. I. Kolodner, American Mathematical Monthly Vol. 73, No. 4, (1966), pages 414-415.","['real-analysis', 'limits', 'summation', 'sequences-and-series', 'gamma-function']"
2544429,"""Shrinking"" open sets technique.","So I was reading a lot of proofs in geometry and analysis and sometimes the follow phrase gets used ""if necessary, shrink open sets $U$ and $V$ so that property $X$ is satisfied"" or something along the lines of that. What exactly does this mean? Here is an example. I was reading something in differential geometry and this is one of those ""is this chart dependant"" questions. I think this is differential geometry's way of asking ""is this thing well-defined"". Anyways, when defining the Tangent Space, one will be asked ""what if we use another chart?"". So let $X$ be a manifold in $\mathbb{R}^n$ with chart $\phi: U \subset \mathbb{R}^k \to X$ and $\phi(0) = x \in X$.  Now suppose we have another chart $\psi: V \to  X$ with $\psi(0) = x$, then by shrinking $U$ and $V$, we may assume $\phi(U) = \psi(V)$ . I believe this is so that we can define the map $h = \psi^{-1}\circ \phi$, because if the image sets are not equal, then $\psi^{-1}$ may not be defined on $\phi(U)$. Or is ""shrink"" here imply that the image sets are ""equal up to diffeomorphism""?","['real-analysis', 'proof-writing', 'differential-geometry', 'proof-explanation']"
2544518,Find the sum of the series $S = \sum_{k=1}^{n} \frac{k}{k^{4} + k^{2} + 1} $,"$$ S = \sum_{k=1}^{n} \frac{k}{k^{4} + k^{2} + 1} $$ I started by factorizing the denominator as $k^2+k+1$ and $k^2-k+1$
The numerator leaves a quadratic with $k$ and $k-1$ or a constant with $k+1$ and $k-1.$
I tried writing the individual terms, ofcourse, it was useless.
How do I do this?",['sequences-and-series']
2544522,Transform one Bessel function integral representation into another,"I want to transform one integral representations of the Besselfunction of first kind of zeroth order into another
$$
J_0(x) = \frac 2 \pi \int_1^\infty \frac{\sin(xt)}{\sqrt{t^2-1}}\,\mathrm dt = \frac 1\pi \int_0^\pi \cos\big(x\sin(\varphi)\big)\,\mathrm d\varphi
$$
I want to do it with integration techniques (substitution, partial integration, ...) and not just show the equivalence via series representation of the Bessel function or the Bessel's differential equation. I tried a substitution of
$$
t = \tan\big(\frac \varphi 2\big) + 1\\
\mathrm dt = \frac{1}{2\cos\big(\frac \varphi 2\big)^2} \mathrm d\varphi\\
\varphi = 2\arctan(t-1)\\
$$
to transform the limits from $1 ... \infty$ to $0 ... \pi$. It follows
$$
J_0(x) = \frac 2 \pi \int_0^\pi \frac{\sin\big[x\big(\tan\big(\frac \varphi 2\big)+1\big)\big]}{2\cos\big(\frac \varphi 2\big)^2\sqrt{\big(\tan\big(\frac \varphi 2\big) + 1\big)^2 -1}}\,\mathrm d\varphi\\
= \frac 1 \pi \int_0^\pi \frac{\sin\big[x\big(\tan\big(\frac \varphi 2\big)+1\big)\big]}{\cos\big(\frac \varphi 2\big)^2\sqrt{\tan\big(\frac \varphi 2\big)^2 + 2\tan\big(\frac \varphi 2\big)}}\,\mathrm d\varphi
$$
With this, the integrals run over the same range, however the integrands are still completely different (plotting the integrands shows completely different curves but integration gives valid results according to mathematica). How can I transform this complicated integrand into the simpler one? Or is there a better possibility for a substitution, ...?","['bessel-functions', 'integration', 'definite-integrals']"
2544568,Advantages of Lebesgue measurable sets over Borel ones in $L^p$ theory?,"Borel $\sigma$-algebra $\mathcal B$ is simply easier to work with (in my opinion) as it behaves well with respect to the topology of our space. Nevertheless, the $\sigma$-algebra $\mathcal M$ of all Lebesgue measurable sets is simply richer. I can conceive that there're probably some interesting stuff going on. Suppose $\Omega\subset\Bbb R^n$ be open domain. What are some major differences between $L^p(\Omega,\mathcal B,\mu)$ and $L^p(\Omega,\mathcal M,\mu)$? Does completeness of $\mathcal M$ allow us to prove some interesting theorems that the structure of $\mathcal B$ is not big enough to support? More generally, what do we gain by replacing $\mathcal B$ with its completion in a more general topological space $X$?","['real-analysis', 'lebesgue-measure', 'functional-analysis', 'lebesgue-integral', 'measure-theory']"
2544570,How to choose correct strategy for irreducibility testing in $\mathbb{Z}[X]$?,"In the standard abstract algebra curriculum, one learns a battery of irreducibility tests for factoring polynomials over $\mathbb{Z}$ (equivalently, by Gauss' lemma, over $\mathbb{Q}$).  For instance (not all names standard): Linear Factor Test: A polynomial has a linear factor over $\mathbb{Z}$ if and only if it has a root in $\mathbb{Q}$. Quadratic/Cubic Test: A polynomial of degree 2 or 3 is reducible if and only if it has a linear factor. Brute Force Method: Write out the forms of all possible factorizations.  For instance, after checking a quartic for linear factors, look at $(X^2+aX+b)(X^2+cX+d)$.  Obtain a system of equations for the coefficients.  Determine whether solutions exist.  Ugh.  (Though, more feasible over $\mathbb{Z}_p$.) Mod-$p$ Irreducibility Test: If there exists a prime $p$ such that a polynomial is irreducible over $\mathbb{Z}_p$, then it is irreducible over $\mathbb{Z}$. Eisenstein's Criterion: If there exists a prime $p$ which divides all but the lead coefficient, and whose square does not divide the constant term, then the polynomial is irreducible. Substitution tricks: The reducibility of a given polynomial $f(X)$ is related to the reducibility of other polynomials like $f(aX+b)$ or the reversal $X^n f(1/X)$. Complexify: Factor the polynomial into linear factors over $\mathbb{C}$.  Every higher-degree divisor of the polynomial is a product of several of these linear factors.  Try out all the products of the linear factors and verify that all of them have non-integer coefficients.  (See for instance Jyrki Lahtonen's solution in this post ). Special cases: E.g. cyclotomic polynomials are something you should just know. These are often used in combination.  One can prove that $X^4+X+1$ is irreducible over $\mathbb{Z}$ by showing it's irreducible over $\mathbb{Z}_2$, which in turn can be easily done by the ""brute-force"" approach since there are very few quadratics over $\mathbb{Z}_2$.  Jyrki Lahtonen's solution in this post shows that $f(X):=X^4-10X^2+1$ is irreducible by applying Eisenstein with $p=2$ to the reversal of $\frac{1}{8} f(2X+1)$.  (Gorgeous!) How does one get a sense for which tricks to try when?  There are infinitely many primes $p$ to try with Eisenstein and mod-$p$ tests, though in practice $p$ tends to be small.  Allowing substitution tricks opens up a dizzying array of possibilities.  I'm thinking by analogy with the convergence tests one learns in calculus.  One can just try different approaches until one of them works, but one can also see patterns: a series with powers or factorials is likely amenable to the Ratio Test, terms of ""smaller order"" can be eliminated by the Limit Comparison Test, terms that you know how to bound can be handled by the Comparison Test, and functions you know how to integrate are promising candidates for the Integral Test. Are there analogous clues to look for here?  How might you ""smell"" which test is likely to work with which polynomial?","['irreducible-polynomials', 'abstract-algebra', 'soft-question']"
2544593,$\lim_{n\to\infty} \sum_{k=1}^n \frac{k!}{n!}$,I'm presented with the limit $\lim_{n\to\infty}\sum_{k=1}^{n} \frac{k!}{n!}$ I've got a hunch that it diverges to infinity but I wasn't able the prove that the sum is superior to a series diverging to infinity. I would like a hint about how I should start. Thanks a lot.,"['limits', 'sumset', 'calculus', 'factorial', 'sequences-and-series']"
2544627,"Infinite group has infinitely many subgroups, namely cyclic subgroups.","If $G$ is an infinite group then $G$ has infinitely many subgroups. Proof: Let's consider the following set: $C=\{\left \langle g \right \rangle: g\in G \}$ - collection of all cyclic subgroups in $G$ generated by elements of $G$. Two cases are possible: Exists infinitely many distinct cyclic subgroups $\Rightarrow$ We are done. Exists finitely many distinct cyclic subgroups for example $C=\{H_1, H_2,\dots, H_n\}$. Then $G=\bigcup \limits_{i=1}^{n}H_i$. Since $G$ is infinite then WLOG suppose that $H_1$ is also infinite, where $H_1=\left \langle g_1 \right \rangle$. Let's consider the following set $\{\left \langle g_1^n \right \rangle: n\in \mathbb{N}\}$ - the collection of all cyclic sugroups of $H_1\subset G.$  Let $K_1=\left \langle g_1 \right \rangle$, $K_2=\left \langle g_1^2 \right \rangle$, $K_3=\left \langle g_1^3 \right \rangle$, $\dots$. It's easy to show that $K_n$ and $K_m$ are distinct for $n\neq m$. Indeed, WLOG take $n<m$ and taking $g_1^n\in K_n$ but $g_1^n\notin K_m$ otherwise $g_1^n=g_1^{ml}$ where $l\in \mathbb{Z}$ $\Rightarrow$ $g_1^{n-ml}=e$ and since $H_1$ is infinite $\Rightarrow$ $n=ml$ which is contradiciton since $m>n$. Thus, the subgroups $K_n$ for any $n\in \mathbb{N}$ are cyclic subgroups of $H_1$ $\Rightarrow$ cyclic subgroups of $G$. Is this reasoning correct?","['abstract-algebra', 'infinite-groups', 'group-theory', 'solution-verification']"
2544637,Probability that everyone shows up for flight?,"The probability of a flight reservation being a no-show is unknown but
  after observing $10000$ flight reservations we found that $95\%$ of
  those people showed up. If we consider a new sample of $100$ flight reservations, what is the
  chance that each of the people shows up? Can we find a useful upper bound to it? I assume that all show-ups are i.i.d. If we write $p$ for the probability of a passenger showing up for her flight, then the probability that everyone shows up is simply $p^{100}$, but of course $p$ is not known. My idea was to use the information that we had $95\%$ show-ups in the sample with $10000$ reservations to bound likely values of $p$. How can we proceed?","['probability-theory', 'probability', 'statistics']"
2544639,"In a ring, result of multiple (of ""addition"" operation) is not the same as result of multiplication, correct?","In a ring, a multiple for addition is written as $na$ to stand for $(a + a + ... + a)$. This is not necessarily the same as $n * a$ (the ""multiplication"" operation).  Is that correct? Multiple is only the same as multiplication for specific rings such as Integers.  Is that right? I suspect the answer to be the case but I have never seen a proof one way or the other. Thanks",['abstract-algebra']
2544676,What is the meaning of the area bound by two curves?,"As the title states, I don't fully understand what the meaning of the area between two curves is, in an application sense. For example, if I was provided with the equations of two velocity curves, what does the area between some region from a to b mean? Is it the distance between the two objects in motion? Edit: Thanks to everyone that responded to the post, it was all very useful :D","['integration', 'calculus']"
2544721,"If $G$ has no nontrivial subgroups, show that $G$ must be finite of prime order [duplicate]","This question already has answers here : Group with more than one element and with no proper, nontrivial sub groups must have prime order. (2 answers) Closed 6 years ago . We know the following fact from gorup theory: If $G$ is a group of prime order then it has no nontrivial subgroups. Lets try to prove the converse statement: If $G$ has no nontrivial subgroups, show that $G$ must be finite of prime order. Proof: Suppose by contradiction: If $G$ has no nontrivial subgroups $\Rightarrow$  $G$ is infiinite or $|G|\neq p$. The case when $G$ is infinite we can rule out using that topic . Suppose that $|G|=n$ where $n$ is composite $\Rightarrow$ $n=pm$ where $p$ - prime and $m\geqslant 2$. Let $a\in G$ such $a\neq e$ then $a^{pm}=e$. If $a^p\neq e$ then considering the cyclic group of G, namely $H=\left \langle a^p\right \rangle$ $\Rightarrow$ $1<|H|\leqslant m<pm$ this is a contradiciton. If $a^p=e$ then we know that $a\neq e$ and considering the cyclic subgroup of $G$, namely $H=\left \langle a\right \rangle$ $\Rightarrow$ $1<|H|\leqslant p<pm$ So we get two contradiction and it follows that $G$ is finite and its order is prime. P.S. I think that my post is not duplicate because my solution somewhat is different from given duplicates. And this solution was created by me and it was important for me to understand is it correct or not.","['abstract-algebra', 'group-theory', 'proof-verification']"
2544726,Finding a $F$-related field in $\mathbb{RP}^2$,"I am trying to prove the following exercise from the book Introduction to Smooth Manifolds - J.M. Lee . Let $F: \mathbb R^2 \rightarrow  \mathbb{RP}^2$ be the smooth map
  $F(x,y)= [x,y,1]$, and let $X\in \mathfrak X(\mathbb R^2)$ defined by
  $X= x\frac{\partial}{\partial y} -y\frac{\partial}{\partial x}$. Prove
  that there is a vector field $Y\in\mathfrak X (\mathbb{RP}^2)$ that is
  $F$-related to $X$, and compute its coordinate representation in
  terms of each of the standard charts of $\mathbb{RP}^2$. I noticed that $F$ is the inverse of a chart and calculated $dF(X)$ and I don't know what to do next.","['vector-fields', 'smooth-manifolds', 'differential-geometry']"
2544782,"Does there exist a sequence $(a_n)$ such that, for all $n$, $a_0 +a_1 X +\cdots+a_nX^n$ has exactly $n$ distinct real roots?","Does there exist a sequence $(a_n)_{n≥0}$ such that, for all $n$, $a_0 +a_1 X +\cdots+a_nX^n$ has exactly $n$ distinct real roots ? I wonder if such a sequence exists. Maybe something with algebraically independent real numbers ? Is it possible to give an example of such a sequence ?","['real-analysis', 'polynomials', 'roots', 'calculus', 'sequences-and-series']"
2544808,Cotangent space of a variety,"I encountered this definition of the contangent space of a variety $V$ at $x$, $$T^*_x = \mathfrak m_x/\mathfrak m_x^2 $$ with $\mathfrak m_x = \{f\in k[V]: f(x)=0 \}$. Could you help me with it? From a differential point of view, we can define the (co-)/tangent space in a point by taking equivalence classes of curves going through that point. The definition above seems kind of similar, but I am not used to the algebraic setting. First of all, I don't really understand the definition of $k[V]$. I know, that we can get it by restricting polynomials to $V$, but why is that $k[V]= k[x_1,\dots,x_n]/I$? I want to get a better understanding of this language by going through some examples. First I look at a sphere $S^2$ given by $x^2+y^2+z^2-1=0$. Then $p_x=2x$, $p_y=2y$ and $p_z=2z$. Thus $p_x=p_y=p_z=0$ only at $(0,0,0)$ but this is not on $S^2$. So for every $(a,b,c)\in S^2$ the tangent space is given by 
$$2a(x-a)+2b(y-b)+2c(z-c)=0,$$
which is $2$-dimensional. Why does its dual correspond to $\mathfrak m_x/\mathfrak m_x^2$. Another example is $V$ given by $$x^3+y^3-3xy=0,$$ then $p_x=3(x^2-y)$ and $p_y=3(y^2-x)$. So $p_x=p_y=0$ at $(0,0)\in V$. Hence $V$ has a singular point. How does this reflect in the abstract formalism?",['algebraic-geometry']
2544842,Do integer primes split completely in intermediate fields?,"Is it true that if the ideal, generated by the integer prime $p,$ splits in $KL,$ then it splits completely in both $K$ and $L$? I only know that if $p$ has a first degree prime divisor in $KL,$ then it has a first degree prime divisor in $K$ and $L,$ but I don't know how to approach complete splitting.","['abstract-algebra', 'ring-theory', 'algebraic-number-theory', 'ideals']"
2544944,"$G$ group of order $2p^m$, $N$ is a minimal normal subgroup, then $N\leq Z(S)$, where $S \in Syl_p(G)$","Suppose $G$ is a group of order $2p^m$, where $p\geq 3$ is prime, $m >0$. Let $N$ be minimal normal $p$-subgroup of $G$. Then $N$ is contained in the center of $S$, where $S \in \text{Syl}_p(G)$. I have shown that $G$ is solvable, meaning that $G$ has an abelian series, but I don't know how this helps. We know that since $|\text{Syl}_p(G)|\equiv 1 \mod p$ and $|\text{Syl}_p(G)|$ must divide $2$, then $|\text{Syl}_p(G)|=1$, meaning that $S$ is the unique $p$-Sylow subgroup of $G$. Now $S$ is of order $p^m$, so $S$ must be nilpotent (another fact that I'm not sure if it is useful or not). Since $N$ is a $p$-subgroup, it must be contained in some $p$-Sylow subgroup of $G$, so it has to be in $S$. Thus, $N\leq S$. I want to show that $N \leq Z(S)$. I can't see how to do this directly, so perhaps I can use the minimality of $N$ to show that $N=N\cap Z(S)$. My issue is that I know that $N$ is minimal in $G$, but I don't necessarily know that $N$ is minimal in $S$. Could someone point me in the right direction? Thank you very much.","['finite-groups', 'abstract-algebra', 'normal-subgroups', 'sylow-theory', 'group-theory']"
2544992,Pole placement in uncontrollable systems with state-feedback.,"I am somewhat confused on how the standard form for an uncontrollable system can be used to implement state-feedback on the controllable subspace. I understand how to use feedback to achieve pole-placement in completely controllable systems. I don't understand how this can then be applied to controllable subspaces of uncontrollable systems. For example, suppose I have an LTI system with eigenvalues {-1, ,1, 2} where eigenvalues {1, 2} are part of the controllable submatrix while -1 is uncontrollable. How do change the pole-locations for the controllable eigenvalues? Thank you.","['control-theory', 'ordinary-differential-equations']"
2545008,The number of parking tickets issued in a certain city...,"The number of parking tickets issued in a certain city on any given day has Poisson distribution with parameter $\mu = 50.$ Calculate the approximate probability that between $35$ and $80$ tickets are given on a day. I'm not sure how to approach this, but the wording in the problem gives me a hint that this is a normal distribution problem, that's all I know. Any help will be appreciated.","['statistics', 'normal-distribution']"
2545022,Bijection between left and right cosets,"For a subgroup $H$ of $G$ define the left coset $aH \ (a\in G)$ of $H$ in $G$ as the set of all elements of the form $ah, \ h\in H$. Show that there is a one-to-one correspondence between the of left cpsets of $H$ in $G$ and the set of right cosets of $H$ in $G$. Proof: Let $\phi:GH\to HG$ defined by $\phi(gH)=Hg^{-1}$. Mapping $\phi$ is well-defined. In other words, if $g_1H=g_2H$ then we need to show that $Hg_1^{-1}=Hg_2^{-1}$. Indeed, if $x\in Hg_1^{-1}$ $\Rightarrow$ $x=h_1g_1^{-1}$ for some $h_1\in H$ $\Rightarrow$ $x^{-1}=(g_1^{-1})^{-1}h_1^{-1}=g_1h_1^{-1}\in g_1H=g_2H$ $\Rightarrow$ $x^{-1}=g_1h_1^{-1}=g_2h_2$ for some $h_2\in H$ 
$\Rightarrow$ $x=h_2^{-1}g_2^{-1}\in Hg_2^{-1}$ $\Rightarrow$ $Hg_1^{-1}\subset Hg_2^{-1}$. The same reasoning shows that converse inclusion holds. Thus $Hg_1^{-1}=Hg_2^{-1}$ $\Rightarrow$ the mapping $\phi$ is well-defined. For $Hg\in HG$ one can find $g^{-1}H\in GH$ such that $\phi(g^{-1}H)=Hg$ We'll show that if $Hg_1^{-1}=Hg_2^{-1}$ $\Rightarrow$ $g_1H=g_2H$.
If $x\in g_1H$ $\Rightarrow$ $x=g_1h_1$ for some $h_1\in H$ $\Rightarrow$ $x^{-1}=h_1^{-1}g_1^{-1}\in Hg_1^{-1}=Hg_2^{-1}$ $\Rightarrow$ $x^{-1}=h_2g_2^{-1}$ $\Rightarrow$ $x=g_2h_2^{-2}\in g_2H$. Thus $g_1H\subset g_2H$. The same reasoning shows the converse inclusion, hence $g_1H=g_2H$. Is this reasoning correct? P.S. Firstly I was considering the mapping defined by $\phi(gH)=Hg$ but i was not able to derive above properties. Can anyone explain why this mapping is ""bad""?","['abstract-algebra', 'group-theory', 'proof-verification']"
2545037,Prove the bounds for the matrix exponential,"Prove that $ e^{-t\|A\|} \le \|e^{tA}\| \le e^{t\|A\|} $ for any matrix $A \in \mathbb{R}^{n \times n}, t > 0$, where $e^{tA} = I + tA + t^2 \dfrac{A^2}{2!} + t^3 \dfrac{A^3}{3!} + \cdots$ It is easy to prove the right part of the inequality $ \|e^{tA}\| \le e^{t\|A\|} $ for $t > 0$: $\|e^{tA}\| = \| I + tA + t^2 \dfrac{A^2}{2!} + t^3 \dfrac{A^3}{3!} + \cdots \| \le 1 + \|tA\| + \dfrac{\|tA\|^2}{2!} + \cdots = e^{\|tA\|}$ But I got stuck with the left part. Great thanks for any help or ideas!","['matrices', 'inequality', 'linear-algebra']"
2545146,Bounded linear transformation definition clarification,"My professor defines bounded linear transformations (operators) between two norm linear spaces as ""linear map that maps bounded sets to bounded sets"". But in many books has defined it as a linear map $T:X\to Y$ such that: for all $x\neq 0$ there is $M\ge 0$ with $$\dfrac{\|Tx\|_Y}{\|x\|_X}\le M.$$ However, I can not see any immediate equivalence between these two definitions. Are these two equivalent? If it is yes, How can you see it? Also, I would like to know the definition and the intuition behind the unbounded linear operators.","['functional-analysis', 'normed-spaces', 'real-analysis', 'unbounded-operators']"
2545172,"Evaluate $\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}\frac{1}{\cosh(x)+\cosh(y)} \, dy \, dx$","My friend gave me this problem, and I'm not too sure where to start. I know single integrals relatively well, but I'm pretty new to double integrals. If someone could show a step-by-step solution, that would be great. $$\int_{-\infty}^{\infty}\int_{-\infty}^\infty \frac 1 {\cosh(x)+\cosh(y)} \, dy \, dx$$ I've tried hyperbolic tangent half-angle substitution and normal substitution, but I have no idea if that applies to double integrals as well.","['multivariable-calculus', 'hyperbolic-functions']"
2545181,Pairwise uncorrelated random variables in Strong Law of Large Numbers (SLLN),"On Wikipedia Strong Law of Large Numbers is given as follows. Let $\{X_n\}$ be a sequence of independent identically distributed $\mathbb{R}$-valued random variables with finite expectation $\mathrm{E}[X_k] = \mu, ~ \forall k \in \mathbb{N}$. Let $S_n$ denote the corresponding sequence of partial sums. Then as $n\rightarrow\infty$ we have $\frac{S_n}{n}\rightarrow \mu$ almost surely. My question: Is it possible to weaken the condition of $\{X_n\}$ beeing independent identically distributed (i.i.d) random variables and instead merely consider pairwise uncorrelated identically distributed $\{X_n\}$? In 1980 Etemadi proved that i.i.d random variables can be replaced by pairwise independent random variables in the aforecited SLLN. I know that pairwise independence concept is close to pairwise uncorrelatedness. On the other hand $\mathrm{Cov}(X_i,X_j)$ by definition requires random variables $X_i$ and $X_j$ to have finite variances. Does it mean that answer to my question is ""NO"" because $X_i$ and $X_j$ have only finite expectations?","['law-of-large-numbers', 'probability-theory']"
2545189,Continuity of a function $\varphi : \ell_1 \to \mathbb{R}$ defined by $\varphi \left (\left ( x_n \right )_{n=1}^{\infty} \right )=\sum x_n^2$,"Show that the function $\varphi: \ell_1 \to \mathbb{R}$ defined by $$\varphi \left (\left ( x_n \right )_{n=1}^{\infty} \right )=\sum_{n=1}^\infty x_n^2$$
  is continuous I've tried proving using the $\varepsilon-\delta$ definition, but I seem to fail finding a proper $\delta$. I have tried bounding $d\left(\varphi\left(x_{n}\right),\varphi\left(a_{n}\right)\right)$ with $\sum\limits _{n=0}^{\infty}\left|x_{n}-a_{n}\right|\left|x_{n}+a_{n}\right|$ for some $\delta$ (where $a_n$ is the series in the $\delta$-ball around $x_n$) but it seems to be a dead end. Is this the right approach, or should I try a different bound?","['general-topology', 'real-analysis', 'metric-spaces', 'continuity']"
2545217,"Show that $(C_b (0,1],||\cdot||_{\infty})$ is not separable","I'm not sure what I'm suppose to do for this question. Any help would be greatly appreciated. I know that there is a similar question like this for $[0,1)$ instead. But is there anyway for me to show this without having to prove the isomorphism between $[0,1)$ and $(0,1]$?","['functional-analysis', 'real-analysis', 'compactness', 'separable-spaces']"
2545250,"I found a way to calculate Quadratic min mod $N$, but why does it work?","I am trying to factor $N$ using Dixon's factorization method , so I am looking at the equation: $$a^2\equiv b(\mod{N})$$ If I am able to find $b$ that is a perfect square, I will be able to factor $N$. While looking at the values of the following $f(x)$, I noticed something very interesting: $$f(x)\equiv(\lceil\sqrt{N}\rceil+x)^2(\mod{N})$$ The values of $f(x)$ grow as $x$ grows, but then they fall again and start over, like waves. Since there is a bigger chance of finding B-smooth values when $f(x)$ is small, it is beneficial to only look at the start of the waves. I noticed that most of the time $f(x)<\sqrt{N}$ in those locations, and by experiment I found a formula to get those values. $$f_{min}(x)=\lceil\frac{\lceil\sqrt{(a-b+1)^2+4(xN-a)}\rceil+(a-b+1)}{2}\rceil+\lceil\sqrt{N}\rceil$$ $a = f(0)$ $b = f(1)$ Edit: tnx to Tob Ernack that notice that $f_{min}(x)$ can be reduced to $$f_{min}(x)=\lceil\sqrt{Nx}\rceil$$ Note that $\mod{N}$ been removed and it still works $f(f_{min}(x))$ will be either the start or the end location of the wave (if it is the end, then the next value is the start) So my question is Why does the formula work? Edit: Here is another interesting observation: $f(a) < f(b)$ iff $\lceil\sqrt{Na}\rceil^2-Na<\lceil\sqrt{Nb}\rceil^2-Nb$ Here are example values: $N=296629285609=570043\cdot 520363$ $\lceil\sqrt{N}\rceil=544637$ $f(f_{min}(0)) = 176160$ $f(f_{min}(1)+1) = 303071$ $f(f_{min}(2)+1) = 612094$ $f(f_{min}(3)+1) = 704640$ $f(f_{min}(4)+1) = 15980$ Here is the java code I use to evaluate this: private BigInteger nextJump(BigInteger a, BigInteger b, BigInteger index, BigInteger root) {
        BigInteger abDif = a.subtract(b).add(ONE);
        BigInteger difPower = abDif.pow(2);
        return sqrCeil(
                difPower
                        .add(V_4.multiply(N.multiply(index).subtract(a)))
        )
                .add(abDif)
                .divide(TWO).add(root);
    }

    BigInteger lastY = TWO;

    private BigInteger sqrCeil(BigInteger value) {
        BigInteger y = lastY;
        BigInteger result = value.divide(y);
        while (true) {
            BigInteger subtract = y.subtract(result);
            if (subtract.abs().equals(BigInteger.ONE) || subtract.equals(ZERO)) {
                break;
            }
            y = result.add(y).divide(TWO);
            result = value.divide(y);
        }
        lastY = y;
        return y;
    }","['prime-factorization', 'factoring', 'number-theory', 'modular-arithmetic', 'elementary-number-theory']"
2545317,Is this pigeonhole principle problem preventing progress by pretermitting pertinent particulars?,"I'm tutoring someone in discrete math and one of the questions that came up is this: Suppose an equilateral triangle made of paper is torn into tiny bits.  If the original triangle was 2 meters on a side, show that if you choose 5 of the tiny bits of paper there are 2 bits which were originally no more than 1 meter apart in the triangle. I don't think this is true as stated.  Don't we need to know how many bits the triangle was torn into?  If it was torn into, say, 1000 bits, then could we not take 5 bits such that any 2 of them were more than 1 meter apart in the triangle? I suspect that the question meant to say the triangle was torn into 5 pieces, although I haven't thoroughly pursued this assumption.","['pigeonhole-principle', 'discrete-mathematics']"
2545322,Multiplying a Curve by a Plane,"Is there a field of mathematics that considers multiplying functions in a manner analogous to matrix multiplication? For instance, Let $\mathbf{x}$ is an $n$-dimensional vector such that $x_i=\sin(2\pi \frac {i} {n}))$, for $i=1,\ldots, n$. Let $\mathbf{A}$ be an $n\times n$ matrix where $A_{i,j}=\cos(4\pi \frac {i} {n} - 2\pi \frac {j} {n})$ for each $i,j$. Let $\mathbf{y}=\mathbf{A}\mathbf{x}$ so that $y_i=\frac 1 2 \sin(4\pi \frac {i} {n})$. If we imagine $n$ going to infinity, then we can define an operator, $\text{prod_fcn}$, such that $\text{prod_fcn}(x(t), A(t, s)) = y(t)$. This example is illustrated graphically below: Obviously this is just one simple example of a curve being ""warped"" by a plane. I'm curious to know if this sort of functional operation is a commonly studied thing. If so, any information about this would be appreciated.","['functional-analysis', 'matrix-calculus']"
2545338,homogeneous spaces are real analytic,Let $G$ be a Lie group and $H$ be a closed subgroup. How to prove that the homogeneous space $G/H$ is a real analytic manifold?,"['smooth-manifolds', 'differential-geometry', 'lie-groups']"
2545344,Finding volume of hyperboloid bounded by two planes,"I want to find the volume bounded by hyperboloid $\cfrac{x^2}{a^2}+\cfrac{y^2}{b^2}-\cfrac{z^2}{c^2} = 1$ and the planes $z=-c, z=c$. I do not know whether should I use the cylindirical coordinates or spherical coordinates. At first, I am thinking to set $x =au, y=bv,z=cw$ and now we have $u^2+v^2 -w^2 = 1$. Jacobian of this transformation is $abc$. I guess that after this change of variables If I take a cross section then it will give me a circle on $uv-$plane but I do not know the reason. If we consider the part of the volume that is inside the first octant, my intuition says that the desired volume is $\displaystyle \int_{0}^{1}\int_{0}^{1-v^2}\int_{0}^{u^2+v^2-1}g(u,v,w)abc\times dwdudv$
 and I am not sure about $g$... To sum up, I appreciate if you could explain me what is going on exactly in a basic way.","['multivariable-calculus', 'integration', 'calculus']"
2545347,Solving second order differential equation 1,"I want to solve the initial value problem \begin{align*}
\frac{d^2c}{dx^2} = -\pi^2 x^2c -\pi\frac{s}{\sqrt{c^2+s^2}} \\
\frac{d^2s}{dx^2} = -\pi^2 x^2s +\pi\frac{c}{\sqrt{c^2+s^2}}
\end{align*}
with inital value $ c(0)=1, \frac{dc}{dx}(0)=0, s(0)=0, \frac{ds}{dx}(0)=0.$ I know that the exact solution is
\begin{align*}
c(x)=\cos(\frac{\pi}{2}x^2), s(x)=\sin(\frac{\pi}{2}x^2).
\end{align*} But, I couldn't derive the solution... Any help is appreciated!! Thank you!",['ordinary-differential-equations']
2545348,Series involving error function,"In a problem of probability I obtained the following summation $$
\sum_{n=0}^\infty [ \mathrm{erf} \ (1+n)k - \mathrm{erf} \ nk ]^2
$$ but I have no idea of how to sum it. I observed (through numerical calculation) that the sum is directly proportional to $k$, at last for $k\sim 10^{-3}$. For large $n$ the value of both error functions is very close to $1$. Then, the 'most important' terms of the sum are the ones of small $n$. Then, I thought, the term corresponding to $n=0$ would give a reasonable approximation to the sum. If $k$ is small, the term for $n=0$ is approximately $k^2$, which is a completely different behavior than the observed. I checked the terms of the summation and many of then are important, therefore we can not obtain the behavior of the summation only from the largest term. How can I obtain at least the behavior of the sum with $k$, or how to obtain an approximate value for the sum?","['probability', 'sequences-and-series']"
2545356,Commuting Operator,"If we consider the operator $T(f) = \int_0^x f(t)dt$ on the Banach space $C[0,1]$, is it possible to classify all linear operators $A$ such that $AT=TA$? Intutively, I feel like $AT=TA$, then it must be the case that either $A=T$ or $A$ is given by covolution.  Does anyone have any ideas if my hunch might be true?","['functional-analysis', 'compact-operators', 'operator-theory', 'analysis']"
2545379,Error in Edwards's arclength proof?,"This question applies to Edwards's Advanced Calculus of Several Variables,
the proof of theorem V-1.1, page 288, etc. If $\vec{\gamma}:\left[t_0,t_{L}\right]\to\mathbb{R}^n$ is
  a $\mathscr{C}^1$ path, then $\mathscr{s}\left[\vec{\gamma}\right]$
  exists, and $\mathscr{s}\left[\vec{\gamma}\right]=\int_{t_0}^{t_L}\left|\vec{\gamma}' [t]\right| \, dt$. I did this for $\mathbb{R}^{3}$. But replacing $3$ with $n$ will
generalize my demonstration. It was not my intent to ask if Edwards
was correct when I started writing this up, so I did it very much
my way. It was only when I happened upon his claim that $\left|\mathscr{P}\right|<\delta_1$ was a sufficient restriction to satisfy $$\left|\mathfrak{t}_a-\mathfrak{t}_b\right|<\delta_1\implies\left|{\overset{*}{\gamma}}' \left[\mathfrak{t}_a\right]-{\overset{*}{\gamma}}' \left[\mathfrak{t}_b\right]\right|<\frac{\varepsilon}{2(t_L-t_0)},$$ that I came to believe Edwards was wrong about that. If someone has
a copy of Edwards's text, please have a look to see if I am reading
it correctly; and he was indeed mistaken. I contended he needs $\left|\mathscr{P}\right|<\frac{\delta_1}{\sqrt{n}}$, instead. In either case, could someone please verify my proof? I acknowledge
it is a bit terse, and done using my own inventions. Let $\vec{\gamma}:[t_0,t_L]\to\mathbb{R}^3$ be a
smooth path in $\mathbb{R}^3$. To find the arclength: Introduce the partition $\mathscr{P}=\left\{ t_0,\dots,<t_i,\dots,<t_k =t_L \right\} $ of the interval $\left[t_{0},t_{L}\right]$. Write $\Delta t_i=t_i-t_{i-1}$. Define the mesh of $\mathscr{P}$ as $\left|\mathscr{P}\right| \equiv \max[\Delta t_i]$. Write $\Delta\vec{\gamma}_{i}=\vec{\gamma}\left[t_{i}\right]-\vec{\gamma}\left[t_{i-1}\right]$. Define $ \overset{*}{\mathfrak{t}}_i\in\left[t_{i-1},t_i\right]^{3}$
as $\overset{*}{\mathfrak{t}}_i=\left\{ \overset{*}{t_i^1},\overset{*}{t_i^2}, \overset{*}{t_i^3}\right\}$ such that $\Delta\vec{\gamma}_i=\left\{ {\gamma^1}' \left[\overset{*}{t_i^1}\right],{\gamma^2}'\left[\overset{*}{t_i^2}\right],{\gamma^3}' \left[\overset{*}{t_i^3}\right]\right\} \Delta t_i$. Define $\overset{*}{\gamma}':\left[t_0,t_L\right]^3\to\mathbb{R}^3$
as $\overset{*}{\gamma}'\left[\mathfrak{t}\right]=\left\{ {\gamma^1}' [t^1], {\gamma^2}' [t^2], {\gamma^3}' [t^3] \right\} $. Define $$\mathscr{s}\left[\vec{\gamma},\mathscr{P}\right]=\sum_{i=1}^k\left|\overset{*}{\gamma}'\left[\overset{*}{\mathfrak{t}_i}\right]\right|\Delta t_i=\sum_{i=1}^k\left|\Delta\vec{\gamma}_i\right|$$
which is not a proper Riemann sum. Define $$\mathscr{R}\left[\vec{\gamma},\mathscr{P}\right]=\sum_{i=1}^k\left|\vec{\gamma}'\left[t_i\right]\right|\Delta t_i \approx \sum_{i=1}^k \left|\Delta\vec{\gamma}_i\right|,$$
which is a proper Riemann sum. Define $\mathfrak{t}_i\in\left[t_{i-1},t_i\right]^3$ as $\mathfrak{t}_i=\left\{ t_i,t_i,t_i\right\} $.
So ${\overset{*}{\gamma}}' \left[\mathfrak{t}_i\right] = \vec{\gamma}'[t_i]$. Because $\vec{\gamma}$ is $\mathscr{C}^1$, the first derivatives
of the component functions ${\gamma^1}',{\gamma^2}',{\gamma^3}'$
are uniformly continuous on the closed and bounded interval $[t_0,t_L]^3$.
This means that given an arbitrarily small $\varepsilon>0$ there
is a $\delta_1>0$ such that for $\mathfrak{t}_a, \mathfrak{t}_b \in [t_0,t_L]^3$ $$\left|\mathfrak{t}_a-\mathfrak{t}_b\right|<\delta_1 \implies \left|\overset{*}{\gamma}' \left[\mathfrak{t}_a \right]-\overset{*}{\gamma}'\left[\mathfrak{t}_b\right]\right|<\frac{\varepsilon}{2(t_L-t_0)}.$$ Applying the triangle inequality: $$\left|\left|\overset{*}{\gamma}'\left[\mathfrak{t}_{a}\right]\right|-\left|\overset{*}{\gamma}' \left[\mathfrak{t}_b\right]\right|\right| \le \left|\overset{*}{\gamma}' \left[\mathfrak{t}_a\right]-\overset{*}{\gamma}' \left[\mathfrak{t}_b\right] \right|.$$ So $$\left|\mathfrak{t}_a-\mathfrak{t}_b\right|<\delta_1 \implies \left|\left|\overset{*}{\gamma}' \left[\mathfrak{t}_a\right]\right|-\left|\overset{*}{\gamma}' \left[\mathfrak{t}_b\right]\right|\right| < \frac{\varepsilon}{2(t_L-t_0)}.$$ Taking the difference of the polygonal approximation and the Riemann
sum gives $$\left|\mathscr{s}\left[\vec{\gamma},\mathscr{P}\right]-\mathscr{R}\left[\vec{\gamma},\mathscr{P}\right]\right|=\left|\sum_{i=1}^k \left(\left|\overset{*}{\gamma}'\left[\overset{*}{\mathfrak{t}_i} \right]\right| -\left|\vec{\gamma}' [t_i]\right|\right) \Delta t_i\right|$$ $$\le\sum_{i=1}^k\left|\left|\overset{*}{\gamma}'\left[\overset{*}{\mathfrak{t}_i}\right]\right|-\left|\overset{*}{\gamma}'\left[\mathfrak{t}_i\right]\right|\right|\Delta t_i.$$ If the mesh of the partition is restricted by $\left|\mathscr{P}\right|<\delta$,
since $\mathfrak{t}_i,\overset{*}{\mathfrak{t}_i}\in\left[t_{i-1},t_i\right]^3$ it follows that $$\left|\mathfrak{t}_i-\overset{*}{\mathfrak{t}_i} \right| \le \delta \left|\left\{ 1,1,1\right\} \right|=\delta\sqrt{3}.$$ So, for $\left|\mathfrak{t}_{i}-\overset{*}{\mathfrak{t}_{i}}\right|<\delta_1$
to hold, the mesh shall be restricted to $\left|\mathscr{P}\right|<\frac{\delta_1}{\sqrt{3}}$.
This means that for each term $$\left|\left|\overset{*}{\gamma}'\left[\overset{*}{\mathfrak{t}_i} \right]\right| -\left|\overset{*}{\gamma}' \left[\mathfrak{t}_i\right] \right| \right| < \frac{\varepsilon}{2(t_L-t_0)}.$$ So $$\left|\mathscr{s}\left[\vec{\gamma},\mathscr{P}\right]-\mathscr{R}\left[\vec{\gamma},\mathscr{P}\right]\right|< \sum_{i=1}^k \frac \varepsilon {2(t_L-t_0)}\Delta t_i = \frac \varepsilon 2.$$ The function $\left|\vec{\gamma}' \left[t\right]\right|$ is
continuous on $\left[t_{0},t_{L}\right]$ and is, therefore, bounded.
Since it can be extended beyond $\left[t_{0},t_{L}\right]$ by specifying $t\notin\left[t_{0},t_{L}\right]\implies\left|\vec{\gamma}'\left[t\right]\right|=0$,
it has bounded support. It is, therefore, integrable so that, given
$\frac{\varepsilon}{2}$ there exists $\delta_2>0$ such that $$\delta_2>\left|\mathscr{P}\right|\implies\left|\mathscr{R}\left[\vec{\gamma},\mathscr{P}\right]-\int_{t_{0}}^{t_{1}}\left|\vec{\gamma}' [t] \right| \,dt\right| <\frac \varepsilon 2.$$ Taking $\delta=\min\left[\delta_1,\delta_2\right]$ implies $$\left|\mathscr{s}\left[\vec{\gamma},\mathscr{P}\right]-\mathscr{R} \left[\vec{\gamma},\mathscr{P}\right]\right| + \left|\mathscr{R} \left[\vec{\gamma},\mathscr{P}\right]-\int_{t_0}^{t_L} \left|\vec{\gamma}' [t] \, \right| \, dt\right|<\varepsilon.$$ A sanity check $\left|a-b\right|=\left|\left(a-c\right)+\left(c-b\right)\right|\le\left|\left(a-c\right)\right|+\left|\left(c-b\right)\right|$
leads to $$\delta>\left|\mathscr{P}\right|\implies\left|\mathscr{s}\left[\vec{\gamma},\mathscr{P}\right]-\int_{t_0}^{t_L}\left| \vec{\gamma}' [t]\right|\,dt\right|<\varepsilon.$$ That is $$\lim_{\left|\mathscr{P}\right|\to0}\mathscr{s}\left[\vec{\gamma},\mathscr{P} \right]=\lim_{\left|\mathscr{P}\right|\to0}\mathscr{R}\left[\vec{\gamma},\mathscr{P}\right]\equiv\int_{t_0}^{t_L}\left|\vec{\gamma}' [t]\right| \, dt$$ Also written $$\int_{t_0}^{t_L}\left|\frac{d\vec{\gamma}}{dt}[t] \right| \,dt = \int_{t_0}^{t_L}\left|\vec{\gamma}'[t]\right| \, dt.$$ Verification of the triangle inequality application: $$\left|a-b\right| = \left|a+c\right| \le \left|a\right| + \left|c\right| = \left|a\right| + \left|b\right|$$ $A=a+b$; $B=a-b$ $\left|A+B\right|\le\left|A\right|+\left|B\right|$ So $$2\left|a\right|\le\left|a+b\right|+\left|a-b\right|\le\left|a-b\right|+\left|a\right|+\left|b\right|$$ $$\left|a\right|\le\left|a-b\right|+\left|b\right|$$ $$\left|a\right|-\left|b\right|\le\left|a-b\right|$$ Let $C=-B$. $$\left|A-B\right|=\left|A+C\right|\le\left|A\right|+\left|C\right|$$ $$\left|A-B\right|\le\left|A\right|+\left|B\right|$$ $$2\left|b\right|\le\left|a-b\right|+\left|a\right|+\left|b\right|$$ $$\left|b\right|-\left|a\right|\le\left|a-b\right|$$ $$\left|\left|a\right|-\left|b\right|\right|\le\left|a-b\right|$$","['multivariable-calculus', 'proof-verification']"
2545385,Automorphisms of curves of genus one,"Suppose $C$ is a curve with genus one. What can be said about its automorphism group in relation with its Jacobian $E$? As it is a torsor over its Jacobian, we have an injective morphism from the automorphism group of $E$ to that of $C$. When is this an isomorphism? Does the image of Aut$(E)$ have finite index in general? (Here I consider translations on $E$ as automorphisms.)","['elliptic-curves', 'algebraic-geometry']"
2545396,What is the inverse laplace transform of an inverted function?,I have $\mathcal{L}\{y'\}+4\mathcal{L}\{y\circledast e^{-4t}\}=\mathcal{L}\{1\}$ with $y(0)=0$ So we get: $sY+4Y\frac{1}{1+4}=\frac{1}{s}$ $\iff Y = \frac{1}{s^2+\frac{4s}{s+4}}$ Now I could rewrite this as $Y=\frac{1}{F(S)}$ but I am not aware of any identity for $\mathcal{L}^{-1}\{\frac{1}{F(s)}\}$. How can I find the Laplace inverse of this expression?,"['ordinary-differential-equations', 'convolution', 'laplace-transform']"
2545413,Finding all the groups of an order up to isomorphism,"In general, how does one best approach a question of the form, ""Find all the groups of order n up to isomorphism?"" Abelian groups seem to be easier to find. The first step is factoring out n, but beyond that? Could someone outline a good set of criteria to look at for n or direct me to a good reading?","['abstract-algebra', 'group-theory', 'order-theory']"
2545417,Probability that a random matrix will have full column rank?,"It is known that for a random matrix $A\in \mathbb{C}^{M\times K}$ with $M>K$, if each element is i.i.d. Gaussian generated, then $A$ has full column rank with probability one. Now, assume that each element of $A$ is in the form of $e^{j\theta}$, where $\theta$'s are i.i.d. uniformly distributed in $(0,2\pi)$. Can I prove that $A$ has full column rank, with probability one? Thanks.","['random-matrices', 'linear-algebra']"
2545422,Conditional joint probabiltiy of a given pair,"The bivariate PDF of a random pair $(X, Y)$ is given by:
$f_{X,Y}(x,y) = 2e^{-x}e^{-2y}$ , $x\ge0, y\ge0$ What is the probability $Y < 4$ given  $X > 1$? I calculated the conditional probability as $f_{Y\mid X}(y) = \frac{f_{X,Y}(x,y)}{f_X(x)}$ From using the above formula I got $f_{Y\mid X}(y) = 2e^{-2y}$, with $f_X(x) = e^{-x}$ I am confused on how to calculate the probability now that I have the equation $f_{Y, X}$","['probability', 'bivariate-distributions']"
2545501,Solve $x^4 -7x^3 + 4x^2 +39x -45=0$,Solve  $x^4 -7x^3 + 4x^2 +39x -45=0$ I tried this question by using the products of roots $= -45 $. But factorization didn't go well. Trial and error method is not working. Please help me,['algebra-precalculus']
2545507,Help in applying the pigeonhole principle to this graph question,"Question: Prove in a finite graph with $\geq 2$ vertices that two vertices have the same degree. I am essentially 90% done with the proof. Given $n = |V|$ for a finite graph $G = (V,E)$, I showed a vertex in the graph must have degree $< n$, and denoted a set $S = \{0,1,2,...,n-1\}$ which contains the possible degrees for each vertex. Both of $0,n-1$ cannot be in $S$, as a vertex connected to all vertices implies no vertex has a degree of $0$; likewise, the converse is true. So, the actual set $D$ of possible values is $\{1,2,...,n-1\}$ or $\{0,1,2,...,n-2\}$. In either case, $|D| = n - 1 < |V|$, so there is no injection from $|V|$ to $|D|$. I am not sure how to use this to show at least two vertices in $D$ share a value in $D$. Does this immediately follow?","['graph-theory', 'proof-verification', 'number-theory', 'proof-writing', 'discrete-mathematics']"
2545564,How do I solve $\int e^{\frac{1}{x}}dx$?,"I'm trying to solve this as part of some problem, but I'm not able to. Can anyone integrate the above problem? Please let me know. Thank you.","['integration', 'calculus']"
2545601,Is $Hom(-.A)$ exact?,"Let $A=k[[x_1,\cdots,x_n]]$ be the ring of power series in $n$ variables over a field of characteristic zero $k$. Let 
$$\mathcal{C}=\cdots\rightarrow P_{v+1}\rightarrow P_v\rightarrow P_{v-1}\cdots$$
be a complex of projective modules such that the $v-$th homology is also projective for all $v$ and the connecting morphisms in the homology complex are all zero . Let $-^*=Hom(-,A)$ stand for the dual functor and consider the dual complex $$\mathcal{C}^*=\cdots\rightarrow P_{v-1}^*\rightarrow P_v^*\rightarrow P_{v+1}^*\cdots$$ Is it true that the $v-$th homology in $\mathcal{C}^*$ is equal to $H_v^*$ where $H_v$ is the $v-$th homology in $\mathcal{C}$?","['modules', 'algebraic-geometry', 'abstract-algebra', 'commutative-algebra', 'algebraic-topology']"
2545639,Integration - fraction part of square root of x,"Question $\int_{0}^{100}\left\{ \sqrt{x}\right\} \,dx$ Where $\{.\}$ denotes the fractional part of x. My Approach We know that $\left[x\right]$+$\left\{ x\right\} $=x
$\Longrightarrow$$\left\{ x\right\} =x-\left[x\right]$ $\int_{0}^{100}\left\{ \sqrt{x}\right\} \,dx$ =$\int_{0}^{100}$$\sqrt{x}\,dx$
-$\int_{0}^{100}$$\left[\sqrt{x}\right]\,dx$=$\left[\frac{\sqrt{x^{3}}}{\frac{3}{2}}\right]_{0}^{100}-$$\int_{0}^{100}\left[\sqrt{x}\right]\,dx$. I cannot solve $\int_{0}^{100}\left[\sqrt{x}\right]\,dx$. But I have
an idea if somehow I can prove that $\left[\sqrt{x}\right]$ is a periodic
function with period $p$ such that $p|100$ then $p\int_{0}^{\frac{100}{p}}\left[\sqrt{x}\right]\,dx$. That
would be easy to solve.","['definite-integrals', 'calculus']"
2545649,Is there a Hausdorff-Young inequality which applies between a length n sequence and its n Discrete Fourier Transform?,"I have been looking around for generalization of the Hausdorff-Young inequality that can be applied between a length $n$ sequence and its $n$-Discrete Fourier Transform (DFT) but no luck. The n-DFT $X$ of a sequence $x$ of length $n$ is defined as:
$$ 
X_k = \sum\limits_{l=0}^{n-1} x_l \exp\left(\frac{-2\pi j k l}{ n}\right)
$$
Any help is appreciated. Regard.","['fast-fourier-transform', 'fourier-analysis', 'analysis', 'fourier-transform']"
2545653,"Given $\sum a_n$ converges and $a_n \ge 0$. Want to find $\{b_n\}$, such that $b_n\to \infty$ and $\sum a_nb_n$ converges","The question is as in the title. I think $\{b_n\}$ should be some function of $a_n$. I was thinking about 
$$b_n = \frac{1}{n\sqrt{a_n}},$$ 
but I don't know if $b_n$ approaches infinity. Can someone give some hint about what $b_n$ should be?","['real-analysis', 'sequences-and-series']"
2545666,How can I find the radius of curvature of a pipe when given the angle?,"I am given a pipe with a 3mm diameter with walls of nearly infinite thinness (so the impact is not affected the the thickness of the pipe) that has something travelling down the center of it in a line. How can I find the minimum radius of curvature of the center line of this pipe such that when the line intersects the wall it will not have an angle greater than 69 degrees? I have tried making a triangle that connects the point where the curve starts, the impact point, and the center of the curve, but that only tells me the angles of that triangle, leaving the sides all unknown. I have found that the length of the outer arc within the triangle has a length of 1.2 times the radius, but again, that isn't helpful. I have no other ideas about how I would even proceed with this and searching online for something I can extrapolate the answer from has been fruitless. The goal is to then find the radius of the circle that is created by curving at that rate. Added explanation from comments:
The problem can essentially be boiled down to: Two lines are travelling parallel to each other 1.5 mm apart along the x-plane. At some arbitrary point, the line below curves up and intersects the line above it, creating an angle of 69 degrees from the tangent of the curving line. If the line continues curving at the same speed to create a circle, what is the radius of that circle (i.e. the radius of curvature).","['angle', 'curvature', 'geometry']"
2545873,All irreducible polynoms of degree 4 in $\mathbb{Z}_2$,"I need to find all irreducible polynoms of degree at most 4 in $\mathbb{Z}_2$ This is my result: $$ x^4 + x^1 + 1 \\
x^4 + x^2 + 1\\
x^4 + x^3 + 1  \\
x^4 + x^3 + x^2 + x^1 + 1 \\
$$ Is this correct?","['polynomials', 'modular-arithmetic', 'discrete-mathematics']"
2545878,Two urns drawing out a single ball,"I have two urns, one with $2$ red, $3$ green, and $2$ blue balls and the other with $3$ red, $4$ green, and $3$ blue balls. If I pick an random urn and draw one ball, and that ball is blue, what is the probability it came from the first urn? So far, I have: $P(U1|B)=(P(B|U1)*P(U1))/P(B)$ Plugging in values, I use $(2/7*1/2)/5/17$ For that, I get $17/70$. If consider the numerator $P(U1,B)$ instead, I seem to come up with $2/5$ instead. What am I doing wrong?","['bayes-theorem', 'probability']"
2545906,Fourier analysis step in an example regarding concentration of measure.,"I am following Terrence Tao's notes on concentration of measures here , Tao defines
${S_n := X_1+\ldots+X_n}$ Then at a certain point he says: ""suppose that ${n = 2^m-1}$, and that ${X_j := (-1)^{a_j \cdot Y}}$, where ${Y}$ is drawn uniformly at random from the cube ${\{0,1\}^m}$, and ${a_1,\ldots,a_n}$ are an enumeration of the non-zero elements of ${\{0,1\}^m}$. Then a little Fourier analysis shows that each ${X_j}$ for ${1 \leq j \leq n}$ has mean zero, variance ${1}$, and are pairwise independent in ${j}$; but ${S_n}$ is equal to ${(n+1) {\bf I}( Y = 0 ) - 1}$, which is equal to ${n}$ with probability ${1/(n+1)}$; this is despite the standard deviation of ${S}$ being just ${\sqrt{n}}$."" What is this little Fourier analysis that makes the facts stated obvious?","['probability-theory', 'fourier-analysis', 'probability', 'measure-theory']"
2545957,Show that the sequence is increasing and unbounded,"I am unable to proceed after a certain point in a small proof, which I present below. I can understand why the sequence under question is increasing and would like to further understand why it is unbounded. I additionally include necessary definitions and results used in the proof at the end of the post. Let $g: [a, \infty) \rightarrow $ be right-continous with finite left limits and of finite variation on $[a, \infty)$. Define $T_0 := a$ and let $T_1$ be the minimum of $a+1$ and the first time when $V_{[a,t]}(g)$ exceeds $\frac{1}{2}$, i.e. $$
T_1 : = \min \left\{ a+1, \inf \left\{ t \in (a, \infty):V_{[a,t]}(g) > \frac{1}{2} \right\} \right\},
$$ with the covention that $\inf \emptyset = \infty$. Since $t \mapsto V_{[a,t]}(f)$ is right-continous, we have $T_1 >a.$  Further, define $T_2, T_3, \ldots $ inducively by $$
T_{k+1} : = \min \left\{ a+k+1, \inf \left\{ t \in (T_k, \infty): V_{[T_k,t]}(g) > \frac{1}{2} \right\} \right\}.
$$ Then $T_{k+1} > T_{k}$, and since each $g$ is of finite variation we have $\lim_{k \rightarrow \infty} T_k = +\infty.$ I understand how it is concluded that $T_{k+1} > T_k$. To elaborate, first observe $V_{[a,t]}(g)$ is right-continuous and is equal to $0$ for $t = a$. Thus, by right-continuity, there exists $\delta >0$ such that for all $t \in [a, a+\delta)$ $$
V_{[a,t]}(g) < \frac{1}{2}.
$$ Therefore, $\inf \left\{ t \in (a, \infty): V_{[a,t]}(g) > \frac{1}{2} \right\} > a$, and $$
T_1 : = \min \left\{ a+1, \inf \left\{ t \in (a, \infty): V_{[a,t]}(g) > \frac{1}{2} \right\} \right\} > a = T_0.
$$ Thus, $a = T_0 < T_1 \leq a+1$. With similar reasoning, we have $$
T_2 : = \min \left\{ \underbrace{a+2}_{> T_1}, \underbrace{ \inf \left\{ t \in (T_1, \infty): V_{[T_1,t]}(g) > \frac{1}{2} \right\} }_{> T_1} \right\} > T_1.
$$ Thus, $a = T_0 < T_1 < T_2 \leq a+2$. Eventually, we can conclude that $$
T_k < T_{k+1} \leq a + k + 1.
$$ However, I don't understand why the last statement is true: since each $g$ is of finite variation we have $\lim_{k \rightarrow
> \infty} T_k = +\infty.$ Maybe someone could make this clear. Relevant definitions follow below. Let $I$ be a real interval and $f : I \rightarrow \mathbb{R}$. The total variation of $f$ over $[a,b] \subset I$ is defined as \begin{equation}
V_{[a,b]}(f) := \sup_{ \substack{ a = t_0 < t_1 < \ldots < t_n = b \\ n \in \mathbb{N}} } \sum_{i=1}^{n} |f(t_i) - f(t_{i-1})|
\end{equation} (i.e. the supremum is taken taken over all possible partitions $a = t_0 < t_1 < \ldots < t_n = b$, $n \in \mathbb{N}$ ). The function $f$ is said to be of finite variation on $I$ if $V_{[a,b]}(f) < \infty$ for all compact subintervals [a,b] of $I$. If $f$ is a right-continuous function on $I$, then for $c \in I$, $t \geq c$, the function $t \mapsto V_{[c,t]}(f)$ is also right-continuous.","['real-analysis', 'probability-theory', 'measure-theory', 'ordinary-differential-equations', 'stochastic-calculus']"
2545959,How can I show that this operator is bounded on $L^2$?,Consider the integral operator $$Tf(x) = {\int}_{-\infty}^{\infty} \frac{\sin(x - y)}{x - y}f(y)dy$$ How can I show that $T$ is bounded on $L^2$? I know that bounded means there is a constant $c$ independent of $f$ such that ${\| Tf \| }_{L^2} \leq c \|f\|_{L^2}$ but I do not seem to succeed on solving this. Any help would be very much appreciated.,"['functional-analysis', 'integral-operators', 'operator-theory']"
2545971,Integration not area,"In which (general) interval is the integration of
     $$\sin x\, dx$$
Greater than the integration of
  $$\sin (2x)\,dx$$
Note :it's integration not area","['inequality', 'trigonometry', 'calculus', 'functions', 'integration']"
2545972,Evaluating $\int_0^{\pi /2} \frac{ \log (1+\cos a \cos x)}{\cos x} dx$,The question is to evaluate $$\int_0^{\pi /2} \frac{ \log (1+\cos a \cos x)}{\cos x} dx$$ I tried using leibnitz rule $$F'(a)=\int_0^{\pi /2} \frac{ -\sin a}{(1+\cos a \cos x)}dx$$ Now I used the substitution $\tan(x/2)=t$ to get $$-2 \sin a \int_0^1 \frac{ dt}{1+t^2 +\cos a (1-t^2)} $$ which can be rewritten as $$-2\frac{\sin a} {1- \cos a}\int_0^{1} \frac{ dt}{t^2 +\frac{1+ \cos a}{1-\cos a}} $$ which evaluates to $-a$.i am not sure where I went wrong.Any ideas?,"['real-analysis', 'integration', 'calculus']"
