question_id,title,body,tags
1549504,The corner of the squre,"A square is a topological manifold with boundary but not a smooth manifold with boundary because of its corners. But I am confused about it. I think since for a specific corner $p$, there is only one chart to cover $P$ (in order to be compatible), say $(U,f)$ , thus in the NBHD of $P$ the transition maps can only be $ff^{-1},f^{-1}f$, so the charts are compatible, so a square has a smooth structure. I feel confused about it. Could you tell me where I went wrong? Thank you!","['smooth-manifolds', 'differential-geometry', 'manifolds-with-boundary']"
1549506,To prove the limit of $\frac{x^2+2\cos x-2}{x\sin^3 x}$ at zero is $1/12$,"To Prove $$\lim_{x \to 0}\frac{x^2+2\cos x-2}{x\sin^3 x}=\frac{1}{12}$$
I tried with L'Hospital rule but in vain.",['limits']
1549509,Given Square Matrices,Given square matrices $A$ and $B$. The matrix $B$ is the square root of matrix $A$ if $A=B^2$. Question: Under what condition is $√B$ real and unique? I'm not sure where to start with this? What does is mean under what condition is the square root real and unique?,"['ordinary-differential-equations', 'linear-algebra', 'discrete-mathematics']"
1549543,Evaluate $\lim_{x\to \infty} \frac{\tan^{2}(\frac{1}{x})}{(\ln(1+\frac{4}{x}))^2}$,"$$\lim_{x\to \infty} \frac{\tan^{2}(\frac{1}{x})}{(\ln(1+\frac{4}{x}))^2}$$ I came across this problem and I am having trouble evaluating it. I know that the whole limit will probably be $0$ and that both the numerator and denominator approach $0$. How do I evaluate it? Using L'Hospital's rule leads to complex expressions, so I don't think that's a good method. Thank you for the help.","['calculus', 'limits']"
1549545,Using multiple integrals for tough single integrals,"I'm just getting started on double integrals, and I recently saw the super cool way to use double integrals to arrive at $$\int_{-\infty}^{\infty} e^{-x^2} dx = \sqrt{\pi}$$ So, I am wondering if there are any other integrals involving functions with no elementary antiderivative (for example $\sin(x^2)$ or $\tan(x^3)$) which are readily solved using multiple integrals.","['multivariable-calculus', 'big-list', 'integration']"
1549546,A solid strategy to prove: $A \subset B\Leftrightarrow A=A\cap B \Leftrightarrow B= A\cup B $,"To begin i tried to prove that the first statement implies second, but took a while to type that (now let's prove the other 5 implications, which would fullfill the circle....), I think there must be a short way to do this. Any ideas?",['elementary-set-theory']
1549581,How do I find $\liminf$ and $\limsup$ if $a_{2n}=\frac {a_{2n-1}}2$ and $a_{2n+1}=\frac12+\frac {a_{2n}}2$?,"Its given that $a_1=a>0$ and that for any $n>1$ two things happen:
$$a_{2n}=\frac {a_{2n-1}}2$$
$$a_{2n+1}=\frac12+\frac {a_{2n}}2$$ How do I find $\lim\inf$ and $\lim\sup$
I am trying to look at $a_{2n+1}$ and $a_{2n-1}$ $a_{2n}$ and $a_{2n-2}$ But I am unable to prove that they are bounded. NOTE: Look at joeys answer for correct solution.","['recurrence-relations', 'limits', 'limsup-and-liminf', 'calculus', 'sequences-and-series']"
1549621,"$\int_0^\infty t|f'(t)|^2\,dt < \infty$ and $\lim_{T \to \infty} T^{-1} \int_0^T f(t)\,dt = L$, do we have that $f(t) \to L$ as $t \to \infty$?","Let $f \in C^1([0, \infty))$ and suppose that $\int_0^\infty t|f'(t)|^2\,dt < \infty$ and $\lim_{T \to \infty} T^{-1} \int_0^T f(t)\,dt = L$. Do we have that $f(t) \to L$ as $t \to \infty$?","['real-analysis', 'calculus', 'functional-analysis', 'integration', 'sequences-and-series']"
1549623,"Probability that two independent samples, each one without repetition, share K elements","Consider the following experiment: Population of size $N$. Two independent samples, each one without replacements . Samples have different number of trials, let's say $n_1$ and $n_2$. What's the probability that these samples share exactly $K$ elements? Please note that I say ""share"" in any order, not ""match"".","['combinatorics', 'statistics', 'probability']"
1549636,"Prove or disprove: For every integer $k\in \mathbb{Z}$, if $f(x)$ is additive, then $f(kz)=kf(z)$.","Given the definition of additive : A function $f:\mathbb{R} \to \mathbb{R}$ is called additive if $f(x+y)=f(x)+f(y)$ for all $x,y\in \mathbb{R}$. We want to prove or disprove the following claim: For every integer $k\in \mathbb{Z}$, if $f(x)$ is additive, then $f(kz)=kf(z)$. I think this statement is true, and I have a good idea on how to prove it, if it is. Here is an outline of my proof so far: Claim: For every integer $k\in \mathbb{Z}$, if $f(x)$ is additive, then $f(kz)=kf(z)$. Case 1: $k=0$ We have $f(0z)=f(z-z)=f(z)-f(z)=0=0f(z)$ Case 2: $k>0$ We have $f(kz)=f(z_1+z_2+...+z_k)=f(z_1)+f(z_2)+...+f(z_k)=kf(z)$ Case 3: $k<0$ We have $f(kz)=f(z_{-1}+z_{-2}+...+z_k)=f(z_{-1})+f(z_{-2})+...+f(z_k)=kf(z)$ Is this claim true? If so, have I proven it? Have I used proper notation? Is there a more efficient way to prove this? Any help would be appreciated.","['functions', 'proof-verification']"
1549654,"For non-zero real $x$, $y$, $z$ and complex $a$, $b$, $c$ with $|a|=|b|=|c|$, if $x+y+z=0=ax+by+cz$, then $a=b=c$","Let $x,y,z \in \Bbb R-\{0\}$ and $\alpha,\beta,\gamma \in \Bbb C$ such that $|\alpha|=|\beta|=|\gamma|=1$ . If $x+y+z=0=\alpha x+\beta y+\gamma z$ , then prove that $\alpha=\beta=\gamma$ . My approach: From the given data, $\alpha=\cos\theta_1+i\sin\theta_1$ where $\theta_1 \in [0,2\pi)$ . Similarly, $\beta=\cos\theta_2+i\sin\theta_2$ and $\gamma=\cos\theta_3+i\sin\theta_3$ . where $\theta_2,\theta_3 \in [0,2\pi)$ . Then we get homogeneous system of equations as below, $$
\left\{
\begin{array}{c}
x+y+z=0 \\
x\cos\theta_1+y\cos\theta_2+z\cos\theta_3=0 \\
x\sin\theta_1+y\sin\theta_2+z\sin\theta_3=0
\end{array}
\right.
$$ Then, $$
\begin{vmatrix}
1 & 1 & 1 \\
\cos\theta_1 & \cos\theta_2 & \cos\theta_3 \\
\sin\theta_1 & \sin\theta_2 & \sin\theta_3 \\
\end{vmatrix}=0$$ because $x,y,z$ are non-zero. On solving the determinant we get, $\sin(\theta_2-\theta_3)+\sin(\theta_3-\theta_1)+\sin(\theta_1-\theta_2)=0$ $\Rightarrow 2\sin(\frac {\theta_2-\theta_3+\theta_3-\theta_1}2)\cos(\frac {\theta_2-\theta_3-\theta_3+\theta_1}2)-\sin(\theta_2-\theta_1)=0$ $\Rightarrow 2\sin(\frac {\theta_2-\theta_1}2)\cos(\frac {\theta_1+\theta_2}2 -\theta_3) - 2\sin(\frac {\theta_2-\theta_1}2)\cos(\frac {\theta_2-\theta_1}2)=0$ $\Rightarrow \sin(\frac {\theta_2-\theta_1}2)(\cos(\frac {\theta_1+\theta_2}2 - \theta_3) - \cos(\frac {\theta_2-\theta_1}2))=0$ $\Rightarrow  \sin(\frac {\theta_2-\theta_1}2)=0$ or $\cos(\frac {\theta_1+\theta_2}2 - \theta_3) - \cos(\frac {\theta_2-\theta_1}2)=0$ $\Rightarrow \theta_1=\theta_2$ or $\theta_1=\theta_3$ (because $\theta_1,\theta_2,\theta_3 \in [0,2\pi)).$ Hence $\alpha=\beta$ or $\alpha=\gamma$ . :(","['systems-of-equations', 'trigonometry', 'complex-numbers', 'determinant']"
1549655,does uncorrelated imply independence for 2 valued random variables?,"Let $(X_n)_{n \geq 1}$ be identically distributed random variables such that $\mathbb{P}[X_1 = 1] =  \mathbb{P}[X_1 = -1] = \frac{1}{2}$ and for any $i_1< \cdots < i_p, \mathbb{E}[X_{i_1} \cdots X_{i_p}] = 0$ for any $p \in \mathbb{N}.$ Can I conclude that $(X_n)_{n \geq 1}$ are i.i.d.? In other words, does uncorrelated imply independence in this case? I know that in this case they are pairwise independent.","['independence', 'probability-theory', 'probability']"
1549679,Is this proof of $(xy)^{-1}=y^{-1}x^{-1}$ valid?,"Proof. Let $G$ be a group, and $x,y\in G$. Then, we have $xy(xy)^{-1}=e$, where $e$ is the identity element of $G$. Multiplying on the left by $x^{-1}$, we get $y(xy)^{-1}=x^{-1}$. Multiplying once again on the left by $y^{-1}$ gives $(xy)^{-1}=y^{-1}x^{-1}$, which was what was to be shown. Obviously this comes to the correct conclusion, but is it valid by the laws of algebra? The assumption that $xy(xy)^{-1}=e$ is directly from the fact that $G$ is a group (closed under inversion and the operation), but perhaps it's just my tendency to view $xy$ as two completely separate elements rather than an actual member of $G$ that's distracting me? Is there a better way to show this? Because if it is valid, it seems (to me, at least, and beauty of the proof is in the eye of the writer..) more ""intuitive"" than the proof my book gave.","['abstract-algebra', 'group-theory', 'proof-verification']"
1549700,Why the fact that the $\lim_{n\rightarrow\infty}(E_{m})=0$ implies this $ m(E_n)< \epsilon $?,"I have a really basic question that I believe may seem trivial to most of you, but I graduated in physics and am currently trying to get my head around some measure theory. Since the question involve just a part of the whole problem, I will paraphrase just this part. ...Let $E_m$ be a decreasing sequence of sets in a sigma algebra R, such that
$ \lim_{n\rightarrow\infty}(E_m)=0 $ Thus, given an $\epsilon > 0 $ , there exists a number $n$ such that       $ m(E_n)< \epsilon $. Can someone tell me why the former implies the latter?","['real-analysis', 'lebesgue-measure', 'measure-theory', 'elementary-set-theory']"
1549701,Countable intersection of open sets results in a closed set,"In $\Bbb R$, if we take the intersection of open intervals $\left(a-\frac1n,b+\frac1n\right)$ for $n\in\Bbb N$, what we get is a closed interval $[a,b]$. It makes sense intuitively, but what is the rigorous proof of this statement?",['elementary-set-theory']
1549720,Camera position and 3D perspective projection,"I have 3D points $P_1, P_2, P_3,..., P_N$ and the result of a 3D perspective projection: $p_1, p_2, p_3,..., p_N$. Is there a way to obtain camera position having only that data? Is it possible having camera fov?",['geometry']
1549725,Evaluating $\lim_{x\to 0}\frac{\sin(x)\arcsin(x)-x^2}{x^6}$ Step by Step Using L' Hopital Rule,The limit to be found is $$ \lim_{x\to 0}\frac{\sin(x)\arcsin(x)-x^2}{x^6}$$ I've tried l'hopital rule but it gets really messy. I've also tried splitting it into 2 limits but that doesn't work. I can't think of any meaningful substitution either. PS: I know the answer $1/18$ but I'm interested in the method. Thank you.,"['calculus', 'limits']"
1549751,Probability distributions parameterized by the median / mode / mean absolute deviation?,"Some probability density functions' parameters include the mean and the variance (like the normal distribution). Are there examples of probability distributions that are parameterized by other measures of central tendency (median, mode) and dispersion (mean absolute deviation)?","['probability', 'probability-distributions']"
1549761,The eternally sleeping beauty. (Thought experiment regarding uniform distribution on the natural numbers),"A cousin of mine recently confronted me with a thought experiment that in essence contained an analogical situation to the following problem: Assume you are a beauty with the following properties: -You know there was a first day on which you woke up. -You know each time you fall asleep, you lose your memories of the previous times you woke. -You are immortal and live in an temporally infinite universe. You are confronted with the question: What probability do you ascribe to the even ""Today is the n-th time I woke up.""? It seems to me that there is no answer within Kolmogorov's probability theory, since any day seems equally likely and you cannot have an uniform distribution over the natural numbers. Is the question not well defined? I would love to read your thoughts.",['probability']
1549767,lim sup and lim infs of Brownian Motion: $B_t/\sqrt{t}$ as $t \to \infty$ or as $t \to 0$.,"Below is my question. Q7.9 is what I'm stuck on. I've done Q7.8; I included it in the picture because I'll use it in Q7.9, and it gives a definition that I'll use. Update: This question is now solved, and I've added the details below. What I've done so far is this: By using time-inversion, $(tB_{1/t})_{t\ge0}$, and $(-B_t)_{t\ge0}$, sign-inversion of Brownian motion, we have that the four random variables in question are all equal to each other. Further, we see that the first is $\mathcal{F}_{0^+}$ measurable, since $$ \limsup_{t \to 0} \frac{B_t}{\sqrt{t}} = \lim_{s \to 0} \sup_{t \le s} \frac{B_s}{\sqrt{s}}, \ \text{and} \ \sup_{t \le s} \frac{B_s}{\sqrt{s}}$$ is $\mathcal{F}_s$ measurable for all $s > 0$, and thus the limit is $\mathcal{F}_{0^+}$ measurable. Hence by Blumenthal's $0$-$1$ law, it is almost surely constant. Hence we now have that the four random variables in question are equal to each other and almost surely constant. Since $\mathbb{P}(B_{t'} > 0) = 1/2$ for all $t' > 0$, by the Markov property, we have that the almost sure constant must be at least $0$. I'm stuck on showing that this constant is in fact $+\infty$. I wanted to use the scaling property, $(cB_{t/c^2})_{t\ge0}$, of Brownian motion, but the issue is that this gives $$\frac{cB_{t/c^2}}{\sqrt{t}} = \frac{B_{t/c^2}}{\sqrt{t/c^2}} = \frac{B_s}{\sqrt{s}}$$ where $s = t/c^2$. When considering just $B_t$ or $B_t/t$, we get a factor $c$ or $1/c$ out the front, and so, since this must hold for all $c$, we know that it must be $0$ or $\infty$. (We can then show which it is.) However, we don't get this nice property when using $B_t/\sqrt{t}$. Solution: Define $A^x_t$ and $A^x$ as follows:
$$A^x_t = \left\{ \sup_{s \le t} \frac{B_s}{\sqrt{s}} \le x \right\}, ~
A^x = \left\{ \lim_{t \downarrow 0}\sup_{s \le t} \frac{B_s}{\sqrt{s}} \le x \right\}
= \left\{ \limsup_{t \downarrow 0} \frac{B_s}{\sqrt{s}} \le x \right\}.$$
Observe that $B_t/\sqrt{t} \sim N(0,1)$. Thus, since $\sup_{s \le t} {B_s}/{\sqrt{s}} \ge {B_t}/{\sqrt{t}}$,
$$P \left( \sup_{s \le t} \frac{B_s}{\sqrt{s}} \le x \right) \le P \left( \frac{B_t}{\sqrt{t}} \le x \right) = \Phi(x),$$
where $\Phi$ is the cdf for the standard normal. We want to show that $P(A^x) = 0$ for every $x \in \mathbb{R}$ ($\therefore x \neq \infty$); by Blumenthal's $0$-$1$ law, it is enough to show that $P(A^x) < 1$. Now, $A^x_{1/n} \downarrow A^x$ as $n \to \infty$, so by monotone convergence,
$$P(A^x) = \lim_{n \to \infty}P(A^x_{1/n}) \le \Phi(x) < 1, \ x \in \Bbb R.$$
Thus $P(A^x) < 1$, ie $P(A^x) = 0$, for all $x \in \mathbb{R}$. Thus the almost sure constant must be $+\infty$. Thank you to Jay.H for helping me with this!","['stochastic-processes', 'probability-theory', 'brownian-motion', 'random']"
1549774,$n$-th derivative of $f(\ln x)$,"Find general formula for $n$-th derivative of $y = f(\ln x)$. To start with I found couple of derrivatives: \begin{align}
y' &={1 \over x}f'(\ln x) \\
y''  &={1 \over x^2}(f''(\ln x)-f'(\ln x)) \\
y'''  &={1 \over x^3}(f'''(\ln x)-3f''(\ln x)+2f'(\ln x)) \\
y''''  &={1 \over x^4}(f''''(\ln x)-6f'''(\ln x)+11f''(\ln x)-6f'(\ln x)) \end{align}
Thought it would be easy to notice a certain pattern and prove it by induction. But I can not observe anything useful. Maybe there is something like $n \choose k$ in general formula, if it exsists. I need a wise hint.","['derivatives', 'induction', 'calculus']"
1549779,Give me hints for evaluating this limit,"Evaluate this limit:
$$\lim_{n\to\infty}{\left\{\left(1+\frac{1}{n}\right)^n-\left(1+\frac{1}{n}\right)\right\}}^{-n}$$
Please give me some hints. If you provide a complete answer instead, please include a spoiler tag.","['real-analysis', 'analysis', 'limits']"
1549807,"Showing that there do not exist uncountably many independent, non-constant random variables on $ ([0,1],\mathcal{B},\lambda) $.","I have this problem in my assignment: Show that there do not exist uncountably many independent, non-constant random variables on $ ([0,1],\mathcal{B},\lambda) $, where $ \lambda $ is the Lebesgue measure on the Borel $ \sigma $-algebra $ \mathcal{B} $ of $ [0,1] $. Can someone please help me to solve this?","['independence', 'probability-theory', 'lebesgue-measure', 'measure-theory', 'random-variables']"
1549808,Why this function is continuous and not differentiable at point $x=1$,"I have a function $$f(x) = \begin{cases}x^2+2,& x\leq 1\\x+2 ,& x > 1\end{cases}$$
I have to show that this function is continuous and not differentiable at point $x=1$, but when I look for left and right derivative of my function I get that they are equal. Can anybody have some  other idea?","['derivatives', 'functions']"
1549838,"If $J$ is tangent point of $GH$ with incircle of $FGH$ and $D$ is intersection of $F$-mixtilinear inclrcle with $(FGH)$, then $\angle FGH=\angle GDJ$.","Let $FGH$ be a triangle with circumcircle $A$ and incircle $B$ , the latter with touchpoint $J$ in side $GH$ . Let $C$ be a circle tangent to sides $FG$ and $FH$ and to $A$ , and let $D$ be the point where $C$ and $A$ touch, as shown here. Prove that $\angle FGH = \angle GDJ$ .","['circles', 'plane-geometry', 'euclidean-geometry', 'triangles', 'geometry']"
1549843,Prove the following limits without using l'Hospital and Sandwich theorem,"Prove the following limits: $$\lim_{x \rightarrow 0^+} x^x = 1$$
$$\lim_{x \rightarrow 0^+} x^{\frac{1}{x}}=0$$
$$\lim_{x \rightarrow \infty} x^{\frac{1}{x}}=1$$ They are not that hard using l'Hospital or the Sandwich theorem. But I curious if they can be solved with the basic knowledge of limits. I have been trying to make some famous limits like the definition of $e$ but without luck.
Thank you for your help.","['limits-without-lhopital', 'limits']"
1549862,Are there matrices $A$ and $B$ such that $AB = BA \neq I$,"I've been learning about matrices and the identity matrix $I$.
It says when $AB = BA = I$, then $A$ and $B$ are inverses of one another.
Is it possible for $AB$ to equal $BA$ but not equal $I$?",['matrices']
1549873,"If the Exponential map is a diffeomorphism at a point, can we say something about other points?","Let $M$ be a complete (connected) Riemannian manifold, $p \in M$ some point in $M$. 
Assume $exp_p$ is a diffeomorphism from $T_pM$ onto $M$. Is it true that $exp_q$ is a diffeomorphism for all points $q \in M$? Of course if $M$ has a transitive isometry group, than the answer is positive, but what about other cases? Note that according to this answer this is equivalent to asking whether all geodesics of $M$ are globally length minimizing or all points in $M$ are joined by unique geodesics.","['riemannian-geometry', 'differential-geometry', 'geodesic']"
1549932,Tensor product of modules: $\Bbb Z[x]/\langle f(x) \rangle \otimes_{\Bbb Z} \Bbb Z/p\Bbb Z \cong (\Bbb Z/p\Bbb Z)[x]/\langle f(x) \rangle$,"This is a question about tensor product of modules. How to show that
  $$\Bbb Z[x]/\langle f(x) \rangle \otimes_{\Bbb Z} \Bbb Z/p\Bbb Z \cong (\Bbb Z/p\Bbb Z)[x]/\langle f(x) \rangle$$
  for any prime $p$ and irreducible polynomial $f(x)\in\Bbb Z[x]$? Attempt: I start with the map
$$\phi:\Bbb Z/p\Bbb Z[x] \to \Bbb Z[x]/\langle f(x) \rangle \otimes_{\Bbb Z} \Bbb Z/p\Bbb Z$$
defined by
$$\phi(a_0+a_1x+\cdots+a_nx^n)=1\otimes a_0+x\otimes a_1+\cdots+x^n\otimes a_n.$$
It is easy to show that $\phi$ is a well-defined surjective module homomorphism, so it suffices to show that
$$\ker\phi=\langle f(x) \rangle \subset\Bbb{Z}/p\Bbb{Z}[x].$$ But this is where I am stuck. Suppose
$$\phi(a_0+\cdots+a_nx^n)=1\otimes a_0+\cdots+x^n\otimes a_n=(a_0+\cdots+a_nx^n)\otimes 1=0.$$
I am tempted to say that this implies that $a_0+\cdots+a_nx^n=0\in\Bbb{Z}[x]/\langle f(x)\rangle$, but I am not sure how to justify this.","['abstract-algebra', 'modules', 'tensor-products']"
1549971,When there exists function $f$ such that for given $g$ we have $f'=g$?,"I am looking for a theorem that states when function $g: \mathbb R \mapsto \mathbb R$ is a derrivative, i.e. there exists $f$ such that $f'=g$. What about if we just need this condition almost everywhere? I have looked at Lebesgue differentiation theorem but I either it is not the way to go or i can't extract it from there. I think I have seen such a theorem few years ago, but I can't recall it. Maybe I'll provide some background. I am considering the following integral:
$$\int_{\mathbb R} \frac{ - g ( \bar x - y)}{|y|^{\alpha +1}} \phi (y/R) d y$$
Where $g$ is bounded function that is twice-differentiable everywhere except zero. At zero there may be some strange behaviour, not sure how strange. I assume  $\alpha \in (0,2)$ (it has to do with fractional laplacian) and that $\varphi$ is smooth cut-off function thtat is zero at a ball around orgin. I want to write the following:
$$\int_{\mathbb R} \frac{ - g ( \bar x - y)}{|y|^{\alpha +1}} \phi (y/R) d y =  \int_{\mathbb R} \partial_k f(\bar x -y) \frac{\phi (y/R)}{|y|^{\alpha+1}} d y = \int_{\mathbb R}  f(\bar x -y) \partial_k \left[ \frac{\phi (y/R) }{|y|^{\alpha+1}} \right] d y$$
If I explicitly assume that $g$ is a derrivative of $f$ it works. I think I can also works when $g$ is Schwartz function. Am I right? But I want to obtain the most general result, hence my question.","['derivatives', 'real-analysis', 'integration']"
1549981,Proof by Induction with Two Basis,"I did an assignment where I used the proof by induction three times in the same manner, and now I have doubts creeping up whether this method was valid or not. I would be quite relieved if you could tell me if that's correct or not: The sequence $(a_n)_{n\in\mathbb{N}}$ is given through $$a_1 = 1,\quad a_2 = \frac{1}{2},\quad a_{n+2}=a_na_{n+1} \text{ for } n\geq 1.$$ I want to show $A(n): a_n \geq a_{n+1} \forall\, n\geq 1$. So I did the base case as follows $$n=1:\quad a_1 = 1,\quad a_2=\frac{1}{2},\quad \therefore a_1=1 \geq \frac{1}{2} = a_2 \quad\checkmark$$
$$n=2:\quad a_2 = \frac{1}{2},\quad a_3=\frac{1}{2},\quad \therefore a_2=\frac{1}{2} \geq \frac{1}{2} = a_3 \quad\checkmark$$
Now comes the part where I'm insecure. For the induction step I assume that $A(n): a_{n} \geq a_{n+1}$ and $A(n+1): a_{n+1} \geq a_{n+2}$ are true and I want to deduce $A(n+2): a_{n+2} \geq a_{n+3}$. Because of the ordering axiom of $(\mathbb{R},+,\cdot\,)$ I think I can multiply $A(n)$ and $A(n+1)$ to get $$a_n \cdot a_{n+1} \geq a_{n+1} \cdot a_{n+2}$$
and with the definition of the recursive defined sequence $a_n$ I would get
$$a_{n+2} = a_n \cdot a_{n+1} \quad\geq\quad a_{n+1} \cdot a_{n+2} = a_{(n+1)+2} =  a_{n+3} \quad\checkmark$$
the induction step. Do I get away with this?","['induction', 'sequences-and-series', 'analysis']"
1549982,How to solve the differential equation: $y'=\sqrt{|y|}$,"While trying to solve the differential equation: $y'=\sqrt{|y|}$. I got confused how to deal with the absolute value. I want to draw a sketch for the direction field for that equation, and see for what initial values does this equation fulfill the conditions of the existence and uniqueness Theorem. I tried to do the integral according to the sign, depends if $(y>0)$ or $(y<0)$. but I'm still not sure if my result is right. result that I got: while $y>0$ : $y=({\frac{x}{2}+c})^{2}$ while $y<0$ : $y=({-\frac{x}{2}+c})^{2}$ if that's the case, Its hard for me to imagine the Direction field by these two equations, because they are always above axis: $x$. How does it look? any hints?","['integration', 'ordinary-differential-equations', 'calculus']"
1550007,Exact solution of Second order ODE,"We have the second order differential equation $\epsilon \dfrac{d^{2}y}{dx^{2}} + \dfrac{dy}{dx} +y = 0$ with boundary values $y(0)=0,\, \, \,  y(1)=1$. I would like to get the exact solution in the form $$y(x) = C \exp(\alpha x)\sinh(\beta x)$$
with $\alpha, \beta$ and $C$ as constants. I'm too sure how to go about this, I have tried to substitute the solution form into the differential equation but I don't think I am going in the right direction.","['asymptotics', 'ordinary-differential-equations', 'perturbation-theory']"
1550010,Why is the matrix multiplication defined as it is? [duplicate],"This question already has answers here : Intuition behind Matrix Multiplication (14 answers) Closed 8 years ago . Matrix multiplication is defined as: Let $A$ be a $n \times m$ matrix and $B$ a $m\times p$ matrix, the product $AB$ is defined as a matrix of size $n\times p$ such that $(AB)_i,_j = \sum\limits_{k=1}^mA_i,_kB_k,_j$. For what good reason did mathematicians define it like this?","['matrices', 'definition']"
1550011,"Real Analysis Folland Problem 48, product measures","Let $X = Y = \mathbb{N}$, $\mathcal{M} = \mathcal{N} = 2^{\mathbb{N}}$, $\mu = v = $ counting measure. Define $f(m,n) = 1$ if $m = n$, $f(m,n) = -1$ if $m = n + 1$, and $f(m,n) = 0$ otherwise. Then $\int |f| d(\mu\times v) = \infty$, and $\int\int f d\mu d v$ and $\int\int f d v d\mu$ exist and are unequal. proof:
$\int |f|d(\mu\times v) = (\mu\times v)\left(\bigcup_{n=1}^{\infty}\{(n,n),(n+1,n)\}\right)$. Let $\{A_n\times B_n\}_{n\in\mathbb{N}}$ be a sequence of rectangles covering $\bigcup_{n=1}^{\infty}\{(n,n),(n+1,n)\}$, then $\{A_n\times B_n\}_{n\in\mathbb{N}}$ covers $\mathbb{N}$ and hence $\sum_{n=1}^{\infty}\mu(A_n\times B_n) = \infty$. This implies that $$\sum_{n=1}^{\infty}\mu(A_n)v(B_n) = \sum_{n=1}^{\infty}\mu(A_n)\mu(B_n) \geq \sum_{n=1}^{\infty}\mu(A_n\cap B_n) = \infty$$ Since $\mu(A_n\cap B_n)\in \{0\}\cup [1,\infty] \forall n\in\mathbb{N}$. Therefore, $$\int|f|d(\mu\times v) = \inf\{\infty\} = \infty$$ I am confused on the last part where $\int|f|d(\mu\times v) = \inf\{\infty\}$, can anyone provide some reasoning here, note the proof is not complete. Now to complete the proof (sort of): $\int\int f(m,n) d\mu(m)dv(n)$; for the inner integral for fixed $n$, we want to know the counting measure $m$ such that $f(m,n) = 1_{\{n\}}(m) - 1_{\{n+1\}}(m)$, and hence $$\int f(m,n) d\mu(m) = \mu(\{n\}) - \mu(\{n+1\}) = 0$$ This implies that $$\int\int f(m,n)d\mu(m)dv(n) = 0$$ $\int\int f(m,n) dv(n)d\mu(m)$; for the innter integral for fixed $m$, we want to know the counting measure of $n$ such that $f(m,n) = 1_{\{m\}}(n) - 1_{\{m-1\}}(n)$, and hence $$\int f(m,n) dv(n) = v(\{m\}) - v(\{m-1\}) = 0$$ In the problem it states that these two integrals are not equal but seems to me they will both be 0? Any suggestions or comments here are greatly appreciated.","['real-analysis', 'measure-theory']"
1550032,Almost Surely convergence with Bernoulli,"How can I demonstrate that a  sequence of Bernoulli Random Variables Xn with parameter $\frac1{2n^2}$ converges almost surely to some random variable X?
I know that $X_n$ takes the value $1$ with Probability $\frac1{2n^2}$ and $0$ with probability $1-\frac1{2n^2}$. 
Thank you in advance!","['borel-cantelli-lemmas', 'probability-theory', 'limsup-and-liminf', 'convergence-divergence']"
1550049,Why are the fibers of principal G-bundles homeomorphic to G?,"I'm trying to get a grip on the modern geometric formulation of gauge theory, in particular connections on principal G-bundles. However, I am stuck right after the definition already: Virtually all introductory texts I found mention (without proof) the fact that the fiber of such a bundle is homeomorphic to the structural group. To avoid ambiguity, let's use the Wikipedia definition: Definition: Let $G$ be a topological group. A principal $G$-bundle is a fiber bundle $F \hookrightarrow P \xrightarrow{\pi} X$ together with a continuous right action
  $$P \times G \to P$$
  $$(p,g) \mapsto p.g$$
   of $G$ on $P$ which preserves fibers, i.e.
  $$\pi(p.g) = \pi(p) $$
  $\forall p \in P$, $g \in G$
  and is free and transitive on all  $F_x = \pi^{-1}(\{x\})$. It appears to be a standard fact that $F \cong G$; I haven't a clue how to prove this, though. My best guess is to fix an element $p\in P$ and consider the restricted group action
$$G\cong\{p\}\times G \to F_{\pi(p)} \cong F$$
By transitivity, freeness and continuity of the group action, this map is a continuous bijection which is not necessarily a homeomorphism unless e.g. $G$ is compact and $F$ is Hausdorff. I can buy that $F$ is Hausdorff if we restrict ourselves to manifolds, but even then $G$ certainly does not have to be compact. What am I missing? Any help is greatly appreciated.","['principal-bundles', 'fiber-bundles', 'topological-groups', 'differential-geometry']"
1550054,"5 geometric shapes, all touching each other","I was playing aroud with shapes, which all connected. I managed to get 3 and 4 shapes all connected to each other, but I can't get 5 to work in 2D. Does anyone have an idea what these shapes are called and also how to get 5 shapes connected? It would be the best, if all shapes were congruent.","['planar-graphs', 'recreational-mathematics', 'geometry']"
1550065,A ''strange'' integral from WolframAlpha,"I want integrate:
$$
\int \frac{1}{\sqrt{|x|}} \, dx
$$
so I divide for two cases
$$
x>0 \Rightarrow \int \frac{1}{\sqrt{x}} \, dx= 2\sqrt{x}+c
$$ $$
x<0 \Rightarrow \int \frac{1}{\sqrt{-x}} \, dx= -2\sqrt{-x}+c
$$
But WolframAlpha gives:
$$
\int \frac{1}{\sqrt{|x|}} \, dx=\left(\sqrt{-x}+\sqrt{x} \right)\operatorname{sgn}(x)-\sqrt{-x}+\sqrt{x}  +c
$$
How I can interpret this result? Maybe I'm wrong?","['wolfram-alpha', 'radicals', 'integration', 'absolute-value']"
1550089,"Integrate: $\int\ln(2x+1) \, dx$","$$\int\ln(2x+1) \, dx$$ I setting up this problem and I am finding it hard to understand why $dv= 1$. When using this formula 
$$\int u\ dv=uv-\int v\ du$$ And using these Guidelines for Selecting $u$ and $dv$: “L-I-A-T-E” Choose $u$ to be the function that comes first in this list: L: Logrithmic Function I: Inverse Trig Function A: Algebraic Function T: Trig Function E: Exponential Function","['integration', 'calculus']"
1550099,Closed form solution for $\rho$: $\frac{d}{d\tau}\sqrt{\left(\rho^{3}\frac{d^{2}\rho}{d\tau^{2}}+\rho\right)}=\nu\rho$ with initial conditions,"Consider the following differential equation for $\rho$:
$$\frac{d}{d\tau}\sqrt{\left(\rho^{3}\frac{d^{2}\rho}{d\tau^{2}}+\rho\right)}=\nu\rho$$
This equation can be rewritten as a system of 3 first-order differential equations:
$$\frac{d\rho}{d\tau}=A,$$
$$\frac{dA}{d\tau}=\frac{B^{2}-\rho}{\rho^{3}},$$
$$\frac{dB}{d\tau}=\nu\rho.$$
Therefore, it is possible to numerically solve this equation eg using a Runge-Kutta method.
However, I would like to know if it is possible to find a closed form solution to this equation with initial conditions: $\rho=1$, $A=0$ and $B=1$.
Any help is welcome.","['ordinary-differential-equations', 'closed-form']"
1550112,"Hat check problem. Ten friends total, five with sombreros, five with fedoras.","A group of ten people give their hats to the coatroom attendant. Five of the ten are wearing sombreros, and five and wearing fedoras. How many ways can the clerk return the hats so that no one gets their hat back if, a: No one gets the right kind of hat b: Everyone gets the right kind of hat c: The attendant loses the sombreros and only returns the 5 fedoras. However the five people in the group that do get a hat back, may or may not have gotten the correct hat back.","['probability', 'inclusion-exclusion', 'combinatorics', 'factorial', 'discrete-mathematics']"
1550113,"Prove that if all the $78$ vertices of a graph have at least degree $5$, then the graph must have a cycle 6.",In a $78$ member company everyone knows at least $5$ others. We sit them around 6-person tables. Prove that in every case there is a seating when at least at one table everybody knows his neighbors. I think it's a proof by contradiction. Assume that the graph where the vertices are the people and the edges are the relation has no $6$ long cycle. How does it limit the sum of the degree?,"['graph-theory', 'discrete-mathematics']"
1550155,"Prove that a bounded, monotone increasing, and continuous function is uniformly continuous","I'm trying to prove that a function $f:[0,\infty) \to \mathbb R$ that is continuous, monotone increasing and bounded is uniformly continuous. Here's a skech of what I've got so far:
$f(x) \to L$ for some $L \in \mathbb R$. Fix $\gamma>0$ then $[f^{-1}(0),L-\gamma]:=[a,b]$ is a compact interval and so $f$ is uniformly continuous on $[a,b]$. This is where I'm stuck, If I let $x,y \in [a,b]$ then $\forall \epsilon>0, \exists \delta>0$ such that $0<|x-y|<\delta \implies |f(x)-f(y)|<\epsilon$. If $x,y \notin[a,b]$ then $x,y>b$ and so I know $|f(x)-f(y)| \leq |f(x)-L|+|f(y)-L|$ which are each less than $L-\gamma$. What $\delta$ can I use to bound this expression? And what about the case where $x \in [a,b]$ and $y>b$?","['uniform-continuity', 'epsilon-delta', 'real-analysis']"
1550164,Determining if a semigroup or monoid can extend to a group,"I was thinking a few days ago, and it crossed my mind to wonder if one could extend, say, an arbitrary monoid to a group. My first thought was that it ought to be simple: Take a monoid $M$ with identity $e$, and for each $x \in M$, if there did not exist $y \in M$ such that $xy = yx = e$, define $x^{-1}$ to meet the condition; after carrying out this process, call the new object $G$. We should have an inverse element for each element of the monoid. But then I thought about it, and recalled that a group $G$ has certain properties that should be able to carry back to any sub-semigroup, e.g. properties of inverses. For example, if I have a group $G$, and there's some element $g$ such that $xg = x$ for some $x$, then $g$ is the unique identity. To see this, let $y$ be any other group element. Then we have
\begin{align*}
xg & = x \\
\Rightarrow (y x^{-1}) xg & = (y x^{-1}) x \\
= y g & = y ,
\end{align*}
so $g$ is an identity element for all elements of the group. But this would mean that if there were some element $x \in G$ for which there exists $e_{x} \in G$ for which $x e_{x} = x$, but there also existed $x' \in G$ for which $x' e_{x} \neq x'$, then $G$ would not be a group. Let $X$ be some set, and define the semi-group $M = X^{2} \cup \{ \natural \}$, where $\natural \not \in X^{2}$ and $X$ contains more than one element. Define the semi-group by
\begin{align*}
\mathbf{a} \mathbf{b} & = \begin{cases}
(a_{1}, b_{2}) , & \mathbf{a}, \mathbf{b} \in X^{2}, a_{2} = b_{1}, \\
\natural , & \textrm{otherwise} .
\end{cases}
\end{align*}
Now let $M = S \cup \{ e \}$, where $e$ is just an affixed identity. Then $M$ is a monoid. Now assume for contradiction that $G$ is a group containing the sub-monoid $M$, and consider the element $\mathbf{a} = (a_{1}, a_{2}) \in M$. Then the element $e_{\mathbf{a}} = (a_{2}, a_{2}) \in M$ would satisfy $\mathbf{a} e_{\mathbf{a}} = \mathbf{a}$, so $e_{\mathbf{a}}$ is a right-identity for $\mathbf{a}$. If $G$ is a group, then for any element $\mathbf{b} \in G$, we'd have $\mathbf{b} e_{\mathbf{a}} = \mathbf{b}$. But if $\mathbf{b} \in X^{2} \subset M$, and $b_{2} \neq a_{2}$, then $\mathbf{b} e_{\mathbf{a}} = \natural \neq \mathbf{b}$. So $G$ is not a group, a contradiction. This led me to wonder, when can you extend a monoid or semi-group to a group? Is there a known characterization? Are there some handy sufficient conditions? Thanks.","['abstract-algebra', 'group-theory']"
1550194,how do I prove standardizing a normally distributed random variable,"Let X be a random variable of mean $\mu$ and variance $\sigma^2$. Use the properties of expectation to show that $$Z=\frac{X-\mu}{\sigma}$$
has mean 0 and variance 1. Let Z be a random variable of mean 0 and variance 1. Show that 
$$X=\sigma Z+\mu$$
has mean $\mu$ and variance $\sigma^2$. I think I have to use $f_Z(z)=\frac{1}{\sqrt{2\pi}}e^{\frac{-z^2}{2}}$ to help me prove this but I have no idea where to start? I know what expectation is and how to calculate it but which properties specifically is the question talking about?","['probability', 'random-variables']"
1550203,What does the symbol $\Subset$ mean? [duplicate],"This question already has an answer here : What does the symbol $\subset\subset$ mean? [duplicate] (1 answer) Closed 8 years ago . It always possible to shrink a domain $U_\alpha$ to $V_\alpha$ in the sense that $$V_\alpha\Subset U_\alpha\quad\text{and} \quad\bigcup_{\alpha}U_\alpha=\bigcup_{\alpha}V_\alpha\,?$$ What does $\Subset$ mean ? Is it an error ?","['general-topology', 'notation', 'analysis']"
1550249,Understanding Bell's inequality vs. quantum mechanics,"I have difficulty to understand how Bell's inequality rules out local hidden variable theory . It seems to me that there is some hidden variable in the Kolmogorov's axiomatization of probability theory, where quantum mechanic is based, so what's the point? To be precise, first let's state Bell's (or called CHSH) inequality in mathematical terms: Suppose $X,Y,X',Y'$ are random variables which are almost surely bounded by $1$. Then we have $\mathbb E\lvert XY+XY'+X'Y-X'Y'\rvert\le2$. It easily follows from the fact that $\lvert XY+XY'+X'Y-X'Y'\rvert\le2$ a.s. Now let's focus on spin measurement , which contradicts Bell's inequality, and where Hilbert spaces are finite dimensional therefore we needn't care about infinitude issues. Let $H=\mathbb Ce_1\oplus\mathbb Ce_2$ be the state space of spin 1/2, and $H\otimes H$ to be the state space of the spin measurement. We prepare for the initial state $\psi=(e_1\otimes e_2-e_2\otimes e_1)/\sqrt2$. As computed in wiki page , there is a specific choice of $a,b,a',b'\in S^2$ (for example, $a=(1,0,0),a'=(0,1,0),b=(1/\sqrt2,-1/\sqrt2,0),b'=(1/\sqrt2,1/\sqrt2,0)$) such that $S(a,b,a',b'):=\sigma(a,b)+\sigma(a,b')+\sigma(a',b)-\sigma(a',b')=-2\sqrt2$, hence the measurement results of spins cannot be described as random variables of a probability space. On the other hand, the measurement results should be random variables by the formulation of quantum mechanics. I don't understand what's really involved here. I call for a mathematical explanation for this. Any help is welcome. Thanks! EXPLANATIONS: It seems to me that I need to elaborate the description for spin measurements. First, $H=\mathbb Ce_1\oplus\mathbb Ce_2$ is a Hilbert space with Hermitian product $\langle x_1e_1+x_2e_2,y_1e_1+y_2e_2\rangle=\overline{x_1}y_1+\overline{x_2}y_2$. Pauli matrices $S_x=\begin{bmatrix}0&1\\1&0\end{bmatrix},S_y=\begin{bmatrix}0&-i\\i&0\end{bmatrix},S_z=\begin{bmatrix}1&0\\0&-1\end{bmatrix}$ (which correspond to spins around $x,y,z$-axes) acts on this space, and set $S_u=xS_x+yS_y+zS_z$ for $u=(x,y,z)\in S^2$. It seems to me that the measurement results are associated with random variables. For example, the measurement result of the spin around $u$ is measured by the observable $S_u\otimes1$, and the correlation $\sigma(u,v)$ with expectation of the random variable correspondent to $S_u\otimes S_v$. The state vector is $\psi=(e_1\otimes e_2-e_2\otimes e_1)/\sqrt2$ (normalized), therefore $\sigma(u,v)=\langle\psi,(S_u\otimes S_v)\psi\rangle$. (I didn't take advantage of Dirac's notation)","['quantum-mechanics', 'probability-theory', 'mathematical-physics', 'quantum-information']"
1550259,Cardioid in coffee mug?,"I've been learning about polar curves in my Calc class and the other day I saw this suspiciously $r=1-\cos \theta$  looking thing in my coffee cup (well actually $r=1-\sin \theta$ if we're being pedantic.) Some research revealed that it's called a caustic. I started working out why it would be like this, but hit a snag. Here's what I did so far: Consider the polar curves $r=1-\cos \theta$ and $r=1$. Since for a light ray being reflected off a surface (or the inside of my cup) the $\angle$ of incidence =$\angle$ of reflection, a point on the circle $(1,\theta)\to(1,2\theta)$. It looks like this has something to do with the tangent lines, so I pretend there's an $xy$ plane centered at the pole to find the slope of the line connecting the points. Since it's the unit circle the corresponding rectangular coordinates are $(\cos \theta, \sin \theta)$ and $(\cos 2\theta, \sin 2\theta).$ So 
$$m={\sin 2\theta-\sin \theta \over \cos 2\theta-\cos \theta}$$
now we see if it matches up with the slope of the lines tangent to the cardioid
$$\frac{dy}{dx}={r'\sin \theta+r \cos \theta \over r' \cos \theta - r \sin \theta}={\sin^2\theta - \cos^2 \theta +\cos \theta \over 2\sin \theta \cos \theta -\sin\theta}={\cos \theta - \cos 2\theta\over \sin 2\theta-\sin \theta}$$ They're similar, but not identical. In particular $\frac{dy}{dx}=-\frac1m$. What error have I made, or what have I overlooked conceptually? Thanks in advance.","['polar-coordinates', 'calculus']"
1550268,How to use Cauchy-Reimann equations to show that complex conjugate of a variable be treated as a constant,Why can the complex conjugate of a variable be treated as a constant when differentiating with respect to that variable?,['complex-analysis']
1550325,derivative on both sides,"I am reading about feedback topologies and having some problems about math. I am not a math student so I need your help. Could you explain if the operation of taking derivative of both sides correct rigorously. 
I read that we can't treat dA as a number (standard analysis) and there is something about differential form that could make it correct.
Am I understanding it correctly?","['derivatives', 'calculus']"
1550331,Why does the natural extension of a lower prevision dominate it?,"On p. 48 in Troffaes and de Cooman's Lower Previsions there's a claim that ""It is clear that"" the natural extension $\underline{E}_\underline{P}$ of lower prevision $\underline{P}$ dominates (42) it, i.e. that $\underline{E}_\underline{P}(f) \geq \underline{P}(f)$ for all bounded functions (""gambles"") in the domain of $\underline{P}$. For the last week or two, I've been trying to understand why, without success. Since I think that familiarity with lower previsions is uncommon, but familiarity with ideas needed to answer my question are, I'll give (too many? too few?) details (with page numbers in parentheses). A lower prevision $\underline{P}$ (38) is a function $\sup\{\mu \in \mathbb{R}: f-\mu \in {\cal D}\}$ from a set $\cal D$ that includes all bounded functions that are nowhere negative, includes no functions that are negative somewhere, and is closed under finite addition and multiplication by non-negative reals (30f)). A lower prevision that avoids sure loss is (among other, equivalent, things, 42) one where the set ${\cal A}_{\underline{P}} = \{f-\mu : f \in \mbox{domain of } \underline{P} \mbox{ and } \mu<\underline{P}\}$ (42) is such that $\sum_{k=1}^n \lambda_k f_k$ is nowhere negative, for any $f_k \in {\cal A}_{\underline{P}}$ and any nonnegative reals $\lambda_k$. The natural extension $\underline{E}_{\underline{P}}$ (47) of a lower prevision $\underline{P}$ that avoids sure loss, is a function from any bounded function to a real number: $$\underline{E}_{\underline{P}} = \sup\{ \alpha \in \mathbb{R} : f - \alpha \geq \sum_{k=1}^n \lambda_k [f_k - \underline{P}(f_k)], n \in \mathbb{N}, f_k \in \mbox{domain of } \underline{P}, \lambda_k \in \mathbb{R}, \lambda_k \geq 0 \}$$ I see that $f-\alpha$ dominates $f-\underline{P}(f)$ for any $f$ in the domain of $\underline{P}$ (letting $n=1$ and $\lambda_1 = 1$).  But why should the $\sup\alpha$ be greater than or equal to $\underline{P}(f)$?  Off the top of my head (and also after much pondering and exploration), if anything, I'd think the inequality should go the other way (since both $\alpha$ and $\underline{P}(f)$ are subtracted in the definition of $\underline{E}_{\underline{P}}$.  Sorry for all of the detail--I'm not sure that all of it is relevant.  I think I'm missing something obvious, or that there's some basic fact about suprema that I don't understand. [Note: Most of the tags I've attached to this question are not quite appropriate, but they're the closest tags we have at the moment.  I don't have sufficient privilege on this site to create a new tag, but I've posted an ""answer"" in Tag management 2015 in meta.math.SE proposing a new tag ""imprecise-probability"", which I believe would be the correct tag.]","['imprecise-probability', 'probability-theory', 'supremum-and-infimum', 'expected-value']"
1550388,A closed form of $\int_0^1{\dfrac{1-x}{\log x}(x+x^2+x^{2^2}+x^{2^3}+\cdots)}\:dx$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I need some hint to calculate this integral $$\int_{0}^{1}{\dfrac{1-x}{\log x}\left(x+x^{2}+x^{2^2}+x^{2^3}+\cdots\right)}{\rm d} x$$ Regards!","['integration', 'definite-integrals', 'calculus', 'closed-form']"
1550414,Why are we justified in using the real numbers to do geometry?,"Context: I'm taking a course in geometry (we see affine, projective, inversive, etc, geometries) in which our basic structure is a vector space, usually $\mathbb{R}^2$. It is very convenient, and also very useful, since I can then use geometry whenever I have a vector space at hand. However, some of that structure is superfluous, and I'm afraid that we can prove things that are not true in the more modest axiomatic geometry (say in axiomatic euclidian geometry versus the similar geometry in $\mathbb{R}^3$). My questions are thus, in the context of plane geometry in particular: Can we deduce, from some axiomatic geometries, an algebraic structure? Are some axiomatic geometries equivalent, in some way, to their more algebraic counterparts? (Note that by « more algebraic » geometry, I mean geometry in a vector space. The « more algebraic » counterpart of axiomatic euclidian geometry would be geometry in $R^2$ with the usual lines and points, and where we might restrict in some way the figures that we can build.) I think it is useful to know when the two approaches intersect, first to be able to use the more powerful tools of algebra while doing axiomatic geometry, and second to aim for greater generality. Another use for this type of considerations could be in the modelisation of geometry in a computer (for example in an application like Geogebra). Even though exact symbolic calculations are possible, an axiomatic formulation could be of use and maybe more economical, or otherwise we might prefer to do calculations rather than keep track of the axiomatic formulation. One of the two approaches is probably better for the computer, thus the need to be able to switch between them.","['analytic-geometry', 'foundations', 'geometry']"
1550440,What comes after geometric mean?,"The formula for computing the geometric mean seems to be the arithmetic mean formula except with all operations ""shifted up"" by one in the hyperoperator chain. While arithmetic mean is: $$\frac{a+b+c+\cdots}{n}$$ In the geometric mean, the addition has been replaced with multiplication and division replaced with a root: $$(a b c\cdots)^{1/n}$$ One might thus wonder whether this could be extended further, replacing the multiplication with an exponentiation and the root with a ""super-root,"" the inverse of a tetration. Something like: $$\left(a^{b^{c^{\cdots}}}\right)_n$$ Where the subscript $n$ stands for $n$th super-root. Of course, this is problematic for the reason that exponentiation is not commutative; nonetheless, is there any such generalization of means and what significance could it hold?","['algebra-precalculus', 'means', 'power-towers']"
1550463,Sufficient condition in proving open mapping theorem for Banach spaces,"Statement of the open mapping theorem: Let $X, Y$ be Banach spaces, $T:X\to Y$ be a continuous linear transformation. If T is onto, then T is an open map (i.e. for any open set $O\subset X$, $T(O)\subset Y$ is open. [EDITED] Claim: It suffices [in proving that T is an open map] to show that $T(B_X(1))$ contains an open ball centered at the origin, where $B_X(1)$ is the open ball of radius 1 centered at the origin in $X$. I'm not seeing how this condition implies that all open sets map to open sets. Linearity of T seems to be important here, but nothing is coming to mind except the definition $T(af+bg)=aT(f)+bT(g)$ for $a,b\in\mathbb{R}$, $f,g\in X$. Would greatly appreciate some insight. Thanks!","['functional-analysis', 'banach-spaces']"
1550504,Prove the following using Chebyshev and Markov inequality.,"Suppose $X$ is a random variable with mean $\mu$ and variance $\sigma^2$ . Show that $$P(|X-\mu| \geq k\sigma) \leq \frac{1}{k^2}$$ Question: I know the exercise wants me to use Markov inequality and  Chebyshev inequality, but I can't reach the same answer. If someone can help me, it will be appreciated. Thanks!","['probability-theory', 'probability', 'statistics']"
1550511,"$\mathcal{Ext}^i(\mathcal{O}_{L_1}, \mathcal{O}_{L_2})$ and $\text{Ext}^i(\mathcal{O}_{L_1}, \mathcal{O}_{L_2})$ for two lines in $\mathbb{P}^3$","Let $L_1$ and $L_2$ be two lines in $\mathbb{P}^3$. I want to compute $\mathcal{Ext}^i(\mathcal{O}_{L_1}, \mathcal{O}_{L_2})$ and $\text{Ext}^i(\mathcal{O}_{L_1}, \mathcal{O}_{L_2})$. Basically, there are three cases: $L_1$ and $L_2$ coincide, $L_1$ and $L_2$ intersect and $L_1$ and $L_2$ do not intersect. For convenience suppose that $L_1=\{z_2=z_3=0\}$, where $z_0,z_1,z_2,z_3$ are the homogeneous coordinates. The we have the following locally-free resolution for $\mathcal{O}_{L_1}$: $$0\to\mathcal{O}_{\mathbb{P}^3}(-2)\stackrel{\left(
\begin{array}{c}
z_2\\
-z_3\\
\end{array}
\right)}\longrightarrow\mathcal{O}_{\mathbb{P}^3}(-1)\oplus\mathcal{O}_{\mathbb{P}^3}(-1)\stackrel{(z_3\,z_2)}\longrightarrow\mathcal{O}_{\mathbb{P}^3}\to\mathcal{O}_{L_1}\to0. \,\,\,(1)$$ In order to compute $\mathcal{Ext}^i(\mathcal{O}_{L_1}, \mathcal{O}_{L_2})$ I need to apply $\mathcal{Hom}(\_, \mathcal{O}_{L_2})$ to (1) and to compute cohomologies of the complex
$$0\to\mathcal{O}_{L_2}\stackrel{\left(
\begin{array}{c}
z_3\\
z_2\\
\end{array}
\right)}\longrightarrow\mathcal{O}_{L_2}(1)\oplus\mathcal{O}_{L_2}(1)\stackrel{(z_2\,-z_3)}\longrightarrow\mathcal{O}_{L_2}(2)\to0.\,\,\,(2)$$
Now if $L_2=L_1$ for example, then it seems that all maps in (2) are equal to 0 and then we have $\mathcal{Ext}^0(\mathcal{O}_{L_1}, \mathcal{O}_{L_1})=\mathcal{O}_{L_1}$, $\mathcal{Ext}^1(\mathcal{O}_{L_1}, \mathcal{O}_{L_1})=\mathcal{O}_{L_1}(1)\oplus\mathcal{O}_{L_1}(1)$, $\mathcal{Ext}^2(\mathcal{O}_{L_1}, \mathcal{O}_{L_1})=\mathcal{O}_{L_1}(2).$ Is it correct? Suppose now that $L_1$ and $L_2$ do not intersect. Then we can assume that $L_2=\{z_0=z_1=0\}$. I have some difficulties computing cohomologies of (2). Also, how could I compute $\text{Ext}^i(\mathcal{O}_{L_1}, \mathcal{O}_{L_2})$? $\textbf{Update}$ It seems that I need to use local-to-global $\text{Ext}$ spectral sequence
$$H^p(X, \mathcal{Ext}^q(F,G))\Rightarrow\text{Ext}^{p+q}(F,G).$$ Can anyone help me with this?",['algebraic-geometry']
1550512,(CLT) Number of rolls of two fair dice to be 90% certain that the percentage of times they show the same face is between 5/36 and 7/36,"How often do you have to roll two fair six-sided dice to be 90% certain that the percentage of times they show the same face is between 5/36 and 7/36? I was thinking, to apply the central limit theorem, between the two bounds, but I have no idea how to setup it. First of all thanks to Henry for your answer. My professor said, First : From the statement of the problem one must know, how to apply the
  correction factor to correctly have the limit in which one evaluate
  the normal, and find the correct n. Second: The distribution is binomial and it will be impossible have a
  greater value (%) for 486 than 487. I have three question:

1) How Henry obtain (5/36n)^(1/2) for the standard deviation.
2) Where is my mistake evaluating the probability of 486 and 487.
3) How to solve it using the CLT. Thanks.","['probability-theory', 'probability', 'dice']"
1550520,"If functions compose both ways to make automorphisms, are they isomorphisms?","Let's say that we have morphisms $f:A \to B$ and $g : B \to A$ such that $f \circ g$ and $g \circ f$ are both automorphisms (an automorphism is a morphism that is both iso and endo). Are $f$ and $g$ isomorphisms? The converse is true. Also they won't necessarily be inverses. If it is not true in general, which categories is it true for? (It is vacuously true if the category is a groupoid.)","['category-theory', 'groupoids', 'morphism', 'functions']"
1550547,Does the existence of the derivative at a point imply the existence of the left and right derivative?,"I'm asking this because I've seen ""results"" in the internet that state: A function $f$ is differentiable at $x = a$ if and only if both the right-hand derivative and left-hand derivative at $x = a$ exist and both of these derivatives are equal. And the counter implication appears in passing in my notes: If a function $f$ is differentiable at $x = a$ then both the right-hand derivative and left-hand derivative at $x = a$ exist and both of these derivatives are equal. However, the function $x^2 \sin \frac{1}{x}$ is differentiable in $\mathbb{R}$ even thought the lateral derivatives don't exist at $0$. This example appears in my notes, which is distressing because (unless I'm committing a logical fallacy) then it's not true that the existence of the derivative at a point imply the existence of the left and right derivative at that point (which would not be consistent with the previous statement).","['derivatives', 'real-analysis', 'calculus']"
1550600,Square of a differential [duplicate],"This question already has answers here : Square of a second derivative is the fourth derivative (4 answers) Closed 8 years ago . Just wondering, is this valid: $$
\left(\frac{df}{dx}\right)^2=\frac{d^{2}f}{dx^{2}}
$$","['ordinary-differential-equations', 'calculus']"
1550643,Finding $f(n)=f(f(n-1))+f(f(n+1))$,"Determine whether a function exists from the positive integers to the positive integers which satisfies the equation: 
$$f(n)=f(f(n-1))+f(f(n+1))$$. My guess is that this function does not exist, as through trial and error I found that $f(n)=\frac{n}{2}$ is a solution to the functional equation. Obviously this is not enough, but I don't know how to tackle this problem. I found that $f(n+2)-f(n)=f(f(n+3))-f(f(n-1))$, but this doesn't seem very useful to me. Can anyone help me with this problem?","['functional-equations', 'functions', 'elementary-number-theory']"
1550652,Relationship between discriminants and smoothness of curves,"My understanding of the use of the discriminant in elliptic curve theory is to test whether an elliptic curve in Weierstrass normal form over a field not of characteristic either 2 or 3, $y^{2} = x^{3}+Ax+B$, is smooth, i.e., non-singular. What I am confused about is the relationship between the discriminant and smooth curves. For instance, $y=x^{2}$ over $\mathbb{R}$ has a zero discriminant, yet is a smooth curve. Why does a zero discriminant of an elliptic curve tell us that the curve is not smooth, and why does this  not seem to apply likewise to other types of curves, such as, quadratics? Is it perhaps because smoothness implies non-singularity for elliptic curves, but in general this is not the case?","['plane-curves', 'algebraic-geometry', 'curves', 'elliptic-curves', 'algebraic-curves']"
1550737,"Exist unique $f \in C([0, 1])$ such that $f(x) = \int_0^x K(x, y)\,f(y)\,dy + g(x)?$","Let $K \in C([0, 1] \times [0, 1])$ and $g \in C([0, 1])$. Does there exist a unique $f \in C([0, 1])$ such that, for all $x \in [0, 1]$, we have$$f(x) = \int_0^x K(x, y)\,f(y)\,dy + g(x)?$$","['real-analysis', 'calculus', 'functional-analysis', 'integration', 'analysis']"
1550739,Has anyone seen this pattern that evaluates to $-\frac{1}{3}$ always?,"I was recently doodling and came upon an interesting pattern. Beginning with $0$, add $1$, subtract $2$, divide by $3$, and multiply by $4$. Then add $5$, subtract $6$, divide by $7$, and multiply by $8$. Hopefully it's clear what I'm doing. $$ \frac {\frac {0+1-2}{3} * 4 +5-6} {7} *8\dots$$ After each division step (after diving by $3$, or $7$, or $11$, and so on ...), the function evaluates to $-\frac{1}{3}$. Has anyone seen this, and if so, where? Can anyone brainstorm a practical use, or is it simply an interesting quirk? Thanks, all.","['pattern-recognition', 'sequences-and-series']"
1550784,"$f_n \in C([0, 1])$, does there exist $(a, b)$, $p \in \mathbb{N}$ where $\sup_\limits{x \in (a, b)} |f(x) - f_n(x)| < \epsilon$ for $n > p$?","Assume that $f_n \in C([0, 1])$ and $f_n(x) \to f(x)$ as $n \to \infty$ for each $x \in [0, 1]$. For any $\epsilon > 0$, does there exist a nonempty interval $(a, b)$ and $p \in \mathbb{N}$ such that$$\sup_{x \in (a, b)} |f(x) - f_n(x)| < \epsilon$$for any $n > p$? Here, $C([0, 1])$ is the space of continuously differentiable functions defined on $[0, 1]$.","['real-analysis', 'calculus', 'functional-analysis', 'sequences-and-series', 'analysis']"
1550796,"Exists continuous $f_n: [0,1] \to \mathbb{R}$ that converges pointwise, as $n \to \infty$, to $\chi_\mathbb{Q}$? [duplicate]","This question already has answers here : Existence of a sequence of continuous functions convergent pointwise to the indicator function of irrational numbers (2 answers) Closed 8 years ago . Does there exist a sequence of continuous $f_n: [0, 1] \to \mathbb{R}$ that converges pointwise, as $n \to \infty$, to $\chi_\mathbb{Q}$, the characteristic function of the rationals in $[0, 1]$?","['real-analysis', 'calculus', 'continuity', 'sequences-and-series', 'analysis']"
1550806,"Closed form solution to $\int_0^1\arctan^2(x)\,\sqrt{x}\,dx$","I need to compute this integral:
$$\int_0^1\arctan^2(x)\,\sqrt{x}\,dx$$
I tried integration by parts, and also introducing a parameter $\arctan(a\,x)$ and differentiation wrt it, but these approaches did not lead to anything useful. Please help.","['trigonometry', 'calculus', 'closed-form', 'integration', 'definite-integrals']"
1550807,"Why a left-invariant Haar measure is $\mu(A)=\int_A \frac{1}{a^2}da\,db$ and a right-invariant Haar measure is $\mu'(A)=\int_A\frac{1}{a}da\,db$?","Let $G$ be the group of affine transformations of $\mathbb R$, $x\mapsto ax+b$, $a>0$. $G$ is the half-plane $(a,b);a>0$. A left-invariant Haar measure is $\mu(A)=\int_A \frac{1}{a^2}da\,db$, whereas a right-invariant Haar measure is $\mu'(A)=\int_A\frac{1}{a}da\,db$. Why a left-invariant Haar measure on $G$ is $\mu(A)=\int_A \frac{1}{a^2}da\,db$ and a right-invariant Haar measure on $G$ is $\mu'(A)=\int_A\frac{1}{a}da\,db$? What are the explicit formulas for the left action and right action? Any help will be greatly appreciated!","['harmonic-analysis', 'measure-theory', 'lie-groups']"
1550808,Proving a function is not Riemann integrable,"Prove that the bounded function $f$ defined by $f(x)=0$ if $x$ is irrational and $f(x)=1$ if $x$ is rational is not Riemann integrable on $[0,1]$. I was given the hint to use the inverse definition of Riemann integrable and consider the cases of the partition being all rationals, and all irrationals between $[0,1]$, but I'm not too sure how to go about it.",['real-analysis']
1550818,"3 Drawers and 2 kind of socks, what is the probability that you get a pair (red or black)?","There are 3 drawers in a dresser`, and you are equally likely to pick
  any of the three. In drawer 1, there are 2 black socks and 3 red
  socks. In drawer 2, there are 3 black socks and 2 red socks. In drawer
  3, there are 3 black socks and 3 red socks. Once you have randomly
  selected a drawer, you randomly pull out a sock of that drawer. If you were to randomly choose a drawer and the draw two socks
  from that drawer, what is the probability that you get a pair (red
  or black)? Where is my mistake: P(R OR B|D1)= 2/5 * 3/4 = 3/10 
P(R OR B|D2)= 3/5 * 2/4 = 3/10
P(R OR B|D3)= 1/2 * 1/2 = 1/4

P(R OR B)=P(R OR B|D1) P(D1) + P(R OR B|D2) P(D2) +P(R OR B|D3) P(D3) The correct answer is 0.4, but if I use my work I can not reach that value. Can you help me to know where is my mistake?
Thanks, comunity.","['probability-theory', 'probability', 'statistics']"
1550822,What does pdf tell me that an induced probability measure doesn't? I.E what is the point of a pdf?,"If we use the following definition: Let $(\Omega, \mathscr{F},P)$ be a probability space, and let $X:\Omega \to \mathbb{R}^k$ be a random vector. Let $P_X$ be the probability measure on $\mathscr{B}(\mathbb{R}^k)$induced by $X$. If $P_X$ is absolutely continuous w.r.t $k$-dimensional lebesgue measure $\mu$, with density $f_X:\mathbb{R}^k \to \mathbb{R}$, then $f_X$ is called the probability density function} of $X$, and $X$ is referred to as a continuous random variable}. For any set $B\in \mathscr{B}(\mathbb{R}^k)$, we have
$$
P_X(B) = \int_Bf_X \, d\mu = \int\dots\int1_B(x_1,\dots,x_k)f_X(x_1,\dots,x_k) \, dx_1 \dots \, dx_k
$$ Focusing on the first part, $P_X(B) = \int_Bf_X \, d\mu$, why do we WANT to know this? Does $f_X$, the pdf, tell us something that $P_X$ doesn't? I guess $P_X$ is defined on the borel sets, whereas $f_X$ is defined on $\mathbb{R}^k$... Or is the answer just something along the lines that we want to work with Lebesgue measure instead of $P_X$, and $f_X$ allows us to do so?",['probability-theory']
1550873,"If an event $\{X_n = 1\}$ happens infinitely often with probability 1, why can't $X_n \overset{a.s.}\to 1$?","I saw an example in a book where $X_n \sim^{iid} Bern(\frac{1}{n})$. The book claims that since $\sum_{n=1}^{\infty}P(\{X_n = 1\}) = \infty$, the event $\{X_n = 1\}$ happens infinitely often with probability 1 (by Borel-Cantelli). Why can't $X_n \overset{a.s.}\to 1$? It seems very obvious to me but I cannot get it to work by the book's definition of almost sure convergence, that $X_n \overset{a.s.}\to X$ means: $$
P(\{\omega \in \Omega: \lim_{n \to \infty}X_n(\omega) = X(\omega)\})=1.
$$ Is there a way to show this using this very definition of almost sure convergence? Thanks!","['independence', 'probability-theory', 'borel-cantelli-lemmas', 'measure-theory', 'convergence-divergence']"
1550900,Necessary and sufficient conditions for an abelian group to be a vector space over $\mathbb{Q}$,"I know if $A$ is an abelian group under addition, then the properties of addition of vector spaces are satisfied. But how do I determine necessary and sufficient conditions for $A$ to be an abelian group? In particular, I would appreciate an explanation of how to check a condition is necessary and then sufficient.","['abstract-algebra', 'vector-spaces']"
1550932,Evaluating $\int_{0}^{\infty}\frac{\sin(ax)}{\sinh(x)}dx$ with a rectangular contour,"I need to try to evaluate $\int_{0}^{\infty}\frac{\sin(ax)}{\sinh(x)}dx$ and it seems like this is supposed to be done using some sort of rectangular contour based on looking at other questions. My main issue is that I am unsure how this kind of contour works in general. For example: How high or low should I have the rectangle contour? Should the contour be centered on the real axis or should it actually be shifted up or down or does it depend? When you make bumps on the contour about the singularities, do you make the bumps as to include the singularities inside of the domain or should they be outside of the domain? I ask the last question based on this question "" tough integral involving $\sin(x^2)$ and $\sinh^2 (x)$ "" here in which robjohn had his contour surround the singularity at $i$ yet did not surround the singularity at $-i$, so I was wondering if this choice matters and why not include or exclude both singularities using the contour. For this, though, I believe I need to use the singularities at $0$ and $i\pi$, but I suppose I could have the rectangle between any two consecutive singularities on the imaginary axis, correct? Either way, any insight on this would be appreciated. Edit: There is no information given on a. I assume it is an arbitrary complex parameter.","['residue-calculus', 'complex-analysis', 'improper-integrals', 'integration', 'contour-integration']"
1550934,How to get nth derivative of $\arcsin x$,"I want to calculate the nth derivative of $\arcsin x$ . I know $$
\frac{d}{dx}\arcsin x=\frac1{\sqrt{1-x^2}}
$$ And $$ 
\frac{d^n}{dx^n} \frac1{\sqrt{1-x^2}} = \frac{d}{dx} \left(P_{n-1}(x) \frac1{\sqrt{1-x^2}}\right) = \left(-\frac{x}{(1-x^2)^{}} P_{n-1}(x) + \frac{dP_{n-1}}{dx}\right)\frac1{\sqrt{1-x^2}} = P_n(x) \frac1{\sqrt{1-x^2}}
$$ Hence we have the recursive relation of $P_n$ : $$ 
P_{n}(x)=-\frac{x}{(1-x^2)^{}} P_{n-1}(x) + \frac{dP_{n-1}}{dx}, \:P_0(x) = 1
$$ My question is how to solve the recursive relation involving function and derivative. I think it should use the generating function, but not sure what it is.","['derivatives', 'polynomials', 'calculus', 'generating-functions', 'recursion']"
1550962,Polar decomposition of Bounded Normal Operator on Hilbert Space,"It is well known that if $T$ is a bounded linear operator on a infinite dimensional Hilbert space $H$ then there exists unique partial isometry $U$ such that $T=U \vert T \vert$,where $\vert T \vert =(T^*T)^{1/2}$.Such a decomposition is called a polar decomposition of $T$.I am trying to solve the following problem: Suppose $T$ is Bounded Normal operator on $H$ ,then there exists unique unitary operator $U$ such that $T=U \vert T \vert$ I don't have any clean way to show the existence of such a unitary operator.Can someone please give me some idea to prove this?","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
1550977,"prove that, for some $p$ & $q, a_p, a_p+a_{p+1} + \cdots$ all are positive","Let $ a_1,a_2,\ldots ,a_{100}$ be real numbers, each less than one, satisfy
 $ a_1+a_2+\cdots+a_{100} > 1$ Show that there exist two integers $p$ and $q$ , $p<q$, such that the numbers $$a_q, a_q+a_{q-1}, \ldots, a_q+\cdots+a_p,$$ $$a_p, a_p+a_{p+1},\ldots,a_p+\cdots+a_q$$ are all positive. I proved that if $n$ is the smallest integer such that 
$ a_1+a_2+\cdots+a_n>1$ 
then all the sums $a_n,a_n+a_{n-1},\ldots,a_n+\cdots+a_1$ are positive.
Will this help to prove? source : Test of Math at 10+2 level( A collection of old ISI B.stat & B.math entrance exam question papers)","['combinatorics', 'contest-math']"
1551015,"How to show that deleting at most $(m-s)(n-t)/s$ edges from a $K_{m,n}$ will never destroy all its $K_{s,t}$ subgraphs.","This problem is from Graph Theory by Diestel Chapter 7 (Extremal Graph Theory) section 5 (regularity lemma) problem 9. I was thinking about applying the Erdos & Stone theorem, but I am honestly lost and I am not sure how to go about this problem. Any help will be greatly appreciated.","['combinatorics', 'graph-theory', 'discrete-mathematics']"
1551065,T compact if and only if $T^*T$ is compact.,"I have an operator $T \in B(\mathcal{H})$ .
I need to prove that T is comapct if and only if $T^*T$ is compact. One way is ok, because if $A$ or $B$ is compact then $AB$ is compact, so I get at once that if $T$ is compact then $T^*T$ is compact. But how do I go the other way? If I assume that $T^*T$ is compact I am not quite sure how to see that $T$ is compact. If I assume for contradiction that $T$ is not compact I must also have that $T^*$ is not compact. If I knew that either $T$ or $T^*$ was invertible it would be ok, because then I could find a bounded subsequence that did not converge. But when I do not have invertibility I am not quite sure how to proceed.","['functional-analysis', 'compact-operators', 'adjoint-operators']"
1551095,Are there more convenient charts than Riemannian normal coordinate chart?,"Let $(M,g)$ be an arbitrary smooth Riemannian manifold of $n$ dimensional and $p_0\in M$. $\nabla$ denotes the Levi Civita connection. It is well known that there is a coordinate chart around $p_0$ s.t. 
\begin{eqnarray}
& g_{ij}(p_0)=\delta_{ij}\\
& \nabla_{\frac{\partial}{\partial x^i}}\dfrac{\partial}{\partial x^j}(p_0)=0\ \ \ (i,j=1,\cdots, n). 
\end{eqnarray}
""Riemannian normal coordinate chart centered at $p_0$"" is one of them. Can we take a coordinate chart $(U;x^1,\cdots,x^n)$ around $p_0$ s.t. 
\begin{eqnarray}
& g_{ij}(p_0)=\delta_{ij}\\
& \nabla_{\frac{\partial}{\partial x^i}}\dfrac{\partial}{\partial x^j}(p_0)=0\\
& \sum_{k=1}^n\nabla_{\frac{\partial}{\partial x^k}}\nabla_{\frac{\partial}{\partial x^k}}\dfrac{\partial}{\partial x^j}(p_0)=0\\
-(i,j=1,\cdots, n)?
\end{eqnarray}","['manifolds', 'riemannian-geometry', 'differential-geometry']"
1551124,Notation for higher degree derivatives,"Lebniz's notation for ordinary derivatives as quotients of differentials is a convenient abuse of notation, since it lets you express things like the chain rule and the derivative of the inverse function in a suggestive form: $$\frac{dz}{dx} = \frac{dy}{dx} \cdot \frac{dz}{dy}$$ $$\frac{dx}{dy} = \frac{1}{\frac{dy}{dx}}$$ where $x,y,z$ are interdependent variables. This approach completely breaks down with second and higher order derivatives, since for example the second derivative of the inverse is $$\frac{d^2x}{dy^2} =-\frac{d^2y}{dx^2} \left(\frac{dy}{dx} \right)^{-3} \neq \frac{1}{\frac{dy^2}{d^2x}}$$ where the left hand side isn't even defined. I know that the concept of differential can be formalized, for example as infinitesimal variables in nonstandard analysis, and that this, in a sense, explains why these formal manipulations work. I know the concept of second degree differential exists, that's why I suspect that the reason they don't work in the case of higher degree derivatives is because the notation must be ""wrong"".  My question is: Is it possible to modify Leibniz's notation for second and higher order derivatives, so that the corresponding ""differentiation rules"" can be obtained by formal algebraic manipulation of the differentials $dx$, $d^2x$, etc. involved?","['derivatives', 'notation', 'calculus']"
1551165,Proof step in Rademacher's Theorem,"In the proof of Rademacher's theorem, we assume that $f: \Bbb R^n \to \Bbb R$ is a Lipschitz function and $v \in \Bbb R^n$ is a vector with $\Vert v \Vert = 1$. Our aim is to show, that 
$$ \mathrm D_v f(x) = v \cdot \text{grad} f(x) \; ,$$
where $\mathrm D_v f(x)$ is the directional derivative of $f$ at the point $x$ in the direction $v$, and on the right sight of the equation we have the euclidean scalar product of $v$ and the gradient of $f$ at the point $x$. In the proof we have shown, that 
$$
\int_{\Bbb R^n} \mathrm D_v f(x) \zeta(x) \; \mathrm dx = \int_{\Bbb R^n} [v \cdot \text{grad}f(x)] \zeta(x) \; \mathrm dx
$$
for any $\zeta \in C_c^\infty(\Bbb R^n)$. 
Why is this enough to know, that 
$$ \mathrm D_v f(x) = v \cdot \text{grad} f(x) $$
holds?","['geometric-measure-theory', 'real-analysis', 'measure-theory']"
1551187,If $A$ is positive definite then any principal submatrix of $A$ is positive definite,If $A$ is positive definite then any principal submatrix of $A$ is  positive definite. Proof; In the proof i dont understand about $j_i$'s.. Can some one interpret the proof in a simpler way(may be the original one is simpler) if someboy is rewriting the proof it would give me a better understanding.(if possible),"['positive-definite', 'linear-algebra']"
1551193,Limit of $\frac{\sqrt{1-\cos x}}x$ using l'Hôpital,"I'm trying to find
$$\lim_{x\downarrow 0}\frac{\sqrt{1-\cos x}}{x}$$
using l'Hôpital's rule but I seem to be stuck in a loop. I have tried applying l'Hôpital several times but the derivatives always contain the radical and the whole thing ends up being $0\over0$ Is there some way to rewrite $1-\cos x$ or is there something else I'm missing?","['radicals', 'trigonometry', 'calculus', 'limits']"
1551196,Exponential generating function and number of balls,"Use exponential generating functions to determine the number $a_n$ of ordered choices of $n$ balls such that there are $2$ or $4$ red balls, an even number of green balls, and an arbitrary number of blue balls. If we denote red with $r$, green with $g$, and blue with $b$. I guess we will have $r^2 + r^4$ for red balls, $1 + b + b^2 + \ldots = \frac{b}{1-b}$ for blue balls. But how can I express the green balls, and how can I then solve the problem using exponential generating functions?","['generating-functions', 'combinatorics', 'discrete-mathematics']"
1551198,"Does there exist $f \in L^1(\mathbb{R})$ where $\lim_{r \to 0} {1\over{r}} \int_{x-r}^{x+r} f(y)\,dy = \infty$?","If $E \subset \mathbb{R}$ has measure $0$, does there exist $f \in L^1(\mathbb{R})$ such that, for every $x \in E$,
$$\lim_{r \to 0} {1\over{r}} \int_{x-r}^{x+r} f(y)\,dy = \infty?$$
What if $E$ has positive measure?","['real-analysis', 'functional-analysis', 'integration', 'lp-spaces', 'measure-theory']"
1551206,"Certain set is dense in $l^p$ if and only if $\{x_n : n \in \mathbb{N}\} \notin l^q$, where $1/p + 1/q = 1$","Assume that $\{x_n : n \in \mathbb{N}\} \subset \mathbb{R}$ is such that $x_n \neq 0$ for some $n$. Let $p \in (1, \infty)$ and$$G := \left\{\{y_n : n \in \mathbb{N}\} \in l^p : \lim_{N \to \infty} \sum_{n=1}^N y_n x_n = 0\right\}.$$Do we have that $G$ is dense in $l^p$ if and only if $\{x_n : n \in \mathbb{N}\} \notin l^q$ where $1/p + 1/q = 1$?","['real-analysis', 'calculus', 'functional-analysis', 'lp-spaces', 'analysis']"
1551225,"Hints to compute if exists $\lim_{n\to\infty}\sum_{k=1}^n\sigma(k^2)/\sum_{k=1}^n\sigma(k)$, which $\sigma(n)=\sum_{d\mid n}d$, and other question","I would like receive hints at least for one of the following problems, these are going from experiments. Can you provide to me hints for at least one of the following problems? I will try put the answer this week. If you want provide hints for one of the problems and solve the another, too is welcome. My goal is learn and made useful post for this site: A) Prove or refute that $\exists$ a real $\delta$ such that $$\lim_{n\to\infty}\sum_{k=1}^{n}\sigma(k)-\left(\frac{n}{rad(n)}\right)^{2+\delta}\sum_{k=1}^{n}\mu(k)k=0,$$
  where $\mu(m)$ is Mobius function , $\sigma(m)$ is the sum of divisors function and $rad(m)$ is defined by $rad(1)=1$ and if $m>1$ by the product of distinct primes dividing $m$, $\prod_{p\mid m}p$ (for example $rad(12)=6$). I believe that previous exercise is more difficult than this B) Compute, if exists, 
  $$\lim_{n\to\infty}\frac{\sum_{k=1}^n\sigma(k^2)}{\sum_{k=1}^n\sigma(k)}.$$ I believe that B) is more easy and useful currently to me. I know Bachmann's theorem about the average order of the sum of divisor function (page 60 in Apostol, Introduction to Analytic Number Theory), an how it was proved. If you want say an hint about the numerator in the limit of B), then I will try it. Thanks in advance. I excuse that this post is tagged as experimental mathematics, since I've used my computer to claim this questions, I don't know if these are in the literature.","['analytic-number-theory', 'limits', 'multiplicative-function', 'arithmetic-functions', 'experimental-mathematics']"
1551254,Integer solutions of $x^3+y^3=z^3$ using methods of Algebraic Number Theory,"I'm asked to prove that the famous equation $$x^3+y^3=z^3$$ has no integer (non-trivial) solutions, i.e. FLT for $n=3$ I'm aware that on this website there are solutions using methods of Number Theory (the infinite descendant proof for example, or well, Wiles' Theorem) But my lecturer told us it can be done by methods of Algebraic Number Theory, i.e. using certain number fields and properties of them. As an hint, he told us to consider the extension $$\mathbb{Q}(\sqrt{3})$$ and using the result that characterises ramified or non-ramified primes in quadratic fields. Now I'd be lying saying that I have some idea on how to attack this problem. I thought that something helpful would come using some analogue of the reasoning of finding roots of $x^2+y^2=z^2$, i.e. reasoning with the norm of a specific quadratic extension, but the norm gives a quadratic relation in this case, and not a cubic one. On the other hand I thought, ok let's consider cubic extension, but for $$\mathbb{Q}(\sqrt[3]{d})$$ the norm of $a+b\sqrt[3]{d}+c\sqrt[3]{d^2} $  is $$a^3+b^3d+c^3d^2-3abc$$ and so I have a kind of cubic relation, BUT I don't know how to get rid of the $abc$ term. I'm aware that this is not a big effort, but this is what I'm able to think as a strategy to attack this problem. Instead of full solutions I'd prefer suggestion and reasonings, otherwise I'll never learn how to proceed with these kind of problems :) Thanks in advance","['number-theory', 'diophantine-equations', 'algebraic-number-theory']"
1551286,How many chains are there in a finite power set?,"Let $A$ be a finite set with $n$ elements. How many chains are there in $\mathcal P(A)$ -- that is, how many different subsets of $\mathcal P(A)$ are totally ordered by inclusion? It's easy enough to count maximal chains; there are $n!$ of them. But counting all chains gets me into horrible inclusion-exclusion situations even if I try to do it by hand for small $n$. Of course this is also the number of chains in a Boolean algebra with $2^n$ elements, or the number of chains in a finite lattice with $2^n$ elements. By hand computation, the number of chains for $n$ running from $0$ to $6$ is $2, 4, 12, 52, 300, 2164, 18732$. This sequence appears to be unknown in OEIS.","['combinatorics', 'lattice-orders', 'order-theory']"
1551300,"Proof of ""Singular values of a normal matrix are the absolute values of its eigenvalues""","I want a simple proof of this fact using only definitions and basic facts. I've searched for it for some time and I couldn't find a satisfying proof. So I attempted to do it myself. Let $A \in \mathbb{C}^{n \times n}$ and $A^H$ be conjugate transpose of $A$. Let $A$ be normal, i.e. $A A^H = A^H A$. The singular values of $A$ are defined as $\sigma \in \mathbb{R}^{\geq 0}$ such that $$ \begin{align*}
A v &= \sigma u \\
A^H u &= \sigma v
\end{align*} $$ where $u^H u = v^H v = 1$. $u$ and $v$ are called left and right singular vectors respectively. Now multiplying the first equation with $A^H$ and the second equation with $A$ from the left we obtain
$$ \begin{align*}
A^H A v &= \sigma A^H u = \sigma^2 v \\
A A^H u &= \sigma A v = \sigma^2 u
\end{align*} $$ Since $A$ is normal we obtain
$$ \begin{align*}
A A^H v &= \sigma^2 v \\
A A^H u &= \sigma^2 u
\end{align*} $$ I believe we can conclude that either $u=v$ or $u=-v$ if singular values are distinct. So by the definition we can see that either $\lambda=\sigma$ or $\lambda=-\sigma$ is also an eigenvalue of $A$. So $\sigma = | \lambda |$. Edit: As @levap pointed out we can only conclude that $u = e^{i \theta} v, \theta \in [0, 2 \pi)$. Then we see that $$ \begin{align*}
Av &= \sigma e^{i \theta} v \\
A^H v &= \sigma e^{-i \theta} v
\end{align*} $$ So, we can say that $\lambda = \sigma e^{i \theta}$ is an eigenvalue of $A$. Also, by the lemma given below $\sigma^2 \geq 0$, so $\sigma \in \mathbb{R}$ and we can always select $\sigma \geq 0$ (using $-u$ in the definition if $\sigma \leq 0$). Therefore, we can conclude that $\sigma = |\lambda|$. Also, $v$ is an eigenvector of $A^H$ with $\bar{\lambda}$. Lemma. Eigenvalues of $AA^H$ are real and non-negative. Proof. $0 \leq \lVert A^H v \rVert_2 = v^H A A^H v = \sigma^2 v^H v = \sigma^2$. What happens if singular values are not distinct?","['eigenvalues-eigenvectors', 'svd', 'linear-algebra', 'proof-verification']"
1551309,Proof that the number $\sqrt[3]{2}$ is irrational using Fermat's Last Theorem,"Suppose that $\sqrt[3]{2}=\frac{p}{q}$. Then $2q^3 = p^3$ i.e $q^3 + q^3 = p^3$, which is contradiction with Fermat's Last Theorem. My question is whether this argument is a correct mathematical proof, since Fermat's Last Theorem is proven, or does it loop on itself somewhere along the proof of the Theorem? In other words, does the proof of Fermat's Theorem somehow rely on the fact that $\sqrt[3]{2}$ is irrational? UPD: As pointed out in comments, this actually is a valid argument, no matter what was used in the proof of the Fermat's Last Theorem (which from now on will be referred to as the Proof). What really interests me, is whether the Proof uses on some step the fact that $\sqrt[3]{2}$ is irrational?","['number-theory', 'proof-verification']"
1551316,Spotting substitution in $\int \frac{1}{(t+\cos \alpha)^2 + \sin^2 \alpha}$,"I have been solving a STEP II question 6 (2000 paper), part 1 and after tons of thought you end up at: $\displaystyle{\int_0^1 \frac{1}{(t+\cos \alpha)^2 + \sin^2 \alpha} dt}$ and then yet again you have to make a substitution. I was not able to proceed after I ended up here, so I looked into the answers and apparently I had to come up with the following substitution: $t+\cos \alpha = \sin \alpha \tan u$ which works extremely well. Using $\frac{1+\cos \alpha}{\sin \alpha}=\tan(\frac{\pi}{2}-\frac{\theta}{2})$ for the upper integral bound and then the integral nicely simplifies to just $1$. My question is the following: what hints could I use just looking at that integral that that is the substitution I had to use?","['integration', 'trigonometry']"
1551332,Prove that $\lim_{h \to 0}\frac{1}{h}\int_0^h{\cos{\frac{1}{t}}dt} = 0$,I'm trying to prove that $$\lim_{h \to 0}\frac{1}{h}\int_0^h{f(t)dt} = 0$$ where $$f(t) = \begin{cases}\cos{\frac{1}{t}} &\text{ if } t \neq 0\\ 0&\text{otherwise}\end{cases}.$$ Can someone give me a hint where to start? Darboux sums somehow seem to lead me nowhere. NOTE: I cannot assume that $f$ has an antiderivative $F$.,"['real-analysis', 'integration', 'calculus', 'limits']"
1551348,What happens when the normal to surface is zero?,"In Differential Geom we're always given that surfaces should be regular, meaning the partial derivatives at every point are linearly independent, or the normal is non-zero. I get that the tangent space isn't well defined when the partial derivatives are linearly dependent. But I can't find any explanations as to what is happening to the surface itself. If someone could give a more geometrical/ intuitive reason why surfaces should be regular that would be great!",['differential-geometry']
1551355,Zeros on the boundary of analytic functions,"If $f$ is analytic in $\{z\in \mathbb{C}, \Im z>0\}$, and continuous in  $\{z\in \mathbb{C}, \Im z\ge 0\}$. I'm curious about the structure of the set 
$$
E=\{z\in \mathbb{R},~~ f(z)=0\}
$$
When restrict $f$ on the real line, it's not analytic, so $E$ may not be discrete. My question: Is there an example such that the set $E$ contains uncountable points (such as a cantor set)? Is it true that $E\subset \mathbb{R}$ is of measure $0$?",['complex-analysis']
1551377,When is the space $L^\infty(\mu)$ finite-dimensional?,"There is a theorem that for a given $p\in [1,\infty)$ a space $L^p(\mu)$ is finite dimensional iff the set of values of $\mu$ is finite. Is a similar theorem for the space $L^\infty(\mu)$  for general positive measure $\mu$ ( finite or infinite)? Edit. Idea of the proof for $L^p(\mu)$ with $p\in [1,\infty)$. We show that if the set of values of $\mu$ is infinite then $dim L^p(\mu)=\infty$. There exists a sequence of pairwise disjoint measurable subsets of $X$ such that $0<\mu(P_n)<\infty$ with the property that the  following set is infinite
$$
\{\mu(D): D \textrm{ is measurable, } D\subset X\setminus \bigcup_{k=1}^n P_k \}
$$
For, we take measurable
$D_1 $  be such that  $0< \mu (D_1)<\mu(X)$ and $D_2=X\setminus D_1$.
Let
$$
W_1=\{\mu(D): D \textrm{ is measurable}, D \subset D_1 \},
$$
$$
W_2=\{\mu(D): D \textrm{ is measurable} , D \subset D_2 \}.
$$
At least one among the sets $W_1, W_2$ is infinite, since for arbitrary measurable $D$ we have $D=(D\cap D_1) \cup (D\cap D_2)$. Let $P_1=D_1$ if $W_1$ is finite and $P_2=D_2$ if $W_2$ is finite.
Let pairwise disjoint measurable $P_1,...,P_n $  with the property $0<\mu(P_i)<\infty$ and such that the set $\{\mu(D): D \textrm{ is measurable}, D\subset X\setminus \bigcup_{k=1}^n P_k \}$ is infinite  be defined. Let $X_n=X\setminus \bigcup_{k=1}^n P_k$. Then there is a measurable  $E_1\subset X_n$ such that $0<\mu(E_1)<\mu(X_n)$. Let $E_2:=X_n\setminus E_1$.
We put
$$
V_1=\{\mu(D): D \textrm{ is measurable}, D \subset E_1 \},
$$
$$
V_2=\{\mu(D): D \textrm{ is measurable }, D \subset E_2 \}.
$$
We define $P_{n+1}=E_1$ or $E_2$ depending on $V_1$ or $V_2$ is finite.
The characteristic functions of sets $P_1, P_2,...$ are linearly independent. We show that if a set of values of $\mu$ is finite then $dim L^p(\mu)<\infty$.
Let $x_1$ be a smallest positive finite value of measure  and let $\mu(D_1)=x_1$. Then $D_1$ is an atom. Next we take the smallest positive finite value $x_2$ of the measure on $X\setminus D_1$ and a set $D_2 \subset X\setminus D_1$ with $\mu(D_2)=x_2$-it is an atom, and so on. The procedure have to finish after finite many steps, say $n$ steps. On the set $X \setminus (D_1\cup...\cup D_n)$ the measure takes at most two values: zero and infinity, hence each function from $L^p(\mu)$ is zero a.a on this set. On arbitrary atom measurable function is constant a.a. (because it is true for measurable simple functions). Hence arbitrary function from $L^p(\mu)$ is equal a.a to linear combination of characteristic function of atoms $D_1,...,D_n$.","['functional-analysis', 'lp-spaces', 'measure-theory', 'analysis']"
1551388,How to solve this integral: $\int_{-\infty}^\infty\frac{x^2 e^x}{(e^x+1)^2}\:dx$,"I am trying to solve an integral like this:
$$
I=\int \frac{x^2 e^x}{(e^x+1)^2} dx
$$
And I get this answer:
$$
\int \frac{x^2 e^x}{(e^x+1)^2}dx=x^2-\frac{x^2}{e^x+1}-2x\text{ln}(e^x+1)+2\int\text{ln}(e^x+1)dx
$$
Where ln denotes natural logarithm .
The last integral can be rewritten as Li$_2(-e^x)$:
\begin{gather}
\int\text{ln}(e^x+1)dx=\begin{cases} u=e^x\\
du=e^xdx\Rightarrow dx={du\over u}\end{cases}\Rightarrow\\
\Rightarrow \int\text{ln}(e^x+1)dx=\int\frac{\text{ln}(u+1)}{u} du
\end{gather}
As Li$_1(z)=-\text{ln}(1-z)\Rightarrow \text{ln}(u+1)=\text{ln}(1-(-u))=-\text{Li}_1(-u)$, it yields:
\begin{gather}
\int\frac{\text{ln}(u+1)}{u} du=-\int\frac{\text{Li}_1(-u)}{u}du=-\text{Li}_2(-u)=-\text{Li}_2(-e^x)
\end{gather}
Finally:
\begin{gather}
\int \frac{x^2 e^x}{(e^x+1)^2} dx=\int \frac{x^2 e^x}{(e^x+1)^2}dx=x^2-\frac{x^2}{e^x+1}-2x\text{ln}(e^x+1)-2\text{Li}_2(-e^x)
\end{gather}
Now, I need to evaluate $I$ from $-\infty$ to $\infty$. I have solved it in Wolfram Alpha, but although it often shows the step by step option, in this case, it doesn't. The result is $\pi^2/3$, which is barely $\zeta(2)$, where $\zeta(\cdot)$ is the Riemann's zeta function, closely related to polylogarithms. So the question is how to evaluate this integral from $-\infty$ to $\infty$. Thank you in advance.","['riemann-zeta', 'integration', 'definite-integrals', 'polylogarithm']"
