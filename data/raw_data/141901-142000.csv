question_id,title,body,tags
2298013,Example of a continuous and Gâteaux differentiable function that is not Fréchet differentiable.,"Is there an example of a function $f:\mathbb{R}^2 \to \mathbb{R}$, with $f(0,0) = 0$, that is Gâteaux differentiable (all directional derivatives exist) and continuous at $(0,0)$, but is not Fréchet differentiable at $(0,0)$? Edit: By Gâteaux differentiable, I use the definition that the Gâteaux derivative is not required to be a linear map, but just all the directional derivatives to exist in all directions.","['real-analysis', 'calculus', 'functional-analysis', 'multivariable-calculus', 'frechet-derivative']"
2298024,Five Points on a plane..,"There are 5 points on a plane. From each point, perpendiculars are drawn to the line joining the other points. What is the maximum number of points of intersection of these perpendiculars ? 
I cant think of the logic please help me out...","['combinatorics', 'plane-geometry']"
2298049,"If a set is open, its ""slices"" are also open. Converse?","Suppose $X$ and $Y$ are topological spaces and $U \subseteq X \times Y$. Now, I managed to prove that whenever $U$ is open all ""slices"" along $Y$ are also open: \begin{equation}
U \; \text{is open} \implies \forall \, x \in X : \left \{ y \in Y : \left( x, y \right) \in U \right \} \; \text{is open}
\end{equation} Obviously the same applies to slices along $X$. Does the converse hold? That is, suppose that for a given set $U \subseteq X \times Y$ all slices along $X$ and $Y$ are open, can we conclude that $U$ is open? My gut feeling tells me, that we need something like Hausdorffness to ensure that we have sufficiently ""small"" open sets, but I fail to prove it (or disprove it for that matter). My idea so far is quite simple. If $U$ is empty then all is well, so suppose there is an element $\left( x, y \right) \in U$. We can then look at the neighbourhood filters $\mathcal{F}_x$ and $\mathcal{F}_y$ of $x$ and $y$ respectively. Then the statement is equivalent to the existence of some $A \in \mathcal{F}_x$, $B \in \mathcal{F}_y$ such that \begin{equation}
A \times B \subseteq U
\end{equation} This seems to me impossible to prove without further assumptions... What assumptions are necessary and sufficient? Uniform topology comes to mind as it assures some symmetry between openness in $X$ and $Y$ directions.",['general-topology']
2298079,What does $\Bbb R^{\Bbb R}$ mean?,What does $\mathbb{R}^\mathbb{R}$ mean? I mean I cannot picture it in any way. I found it in an algebra problem and it's bugging me.,"['notation', 'elementary-set-theory']"
2298103,Isomorphism of rings induces isomorphism of affine schemes,"I am new to schemes and I would be very grateful if someone would check my argument below. Important Note. I am following Ravi Vakil's notes: https://math.stanford.edu/~vakil/216blog/FOAGfeb0717public.pdf I am currently on page 136 (exercise 4.3.A). So far we have only defined an isomorphism of schemes as an isomorphism of ringed spaces. We have yet to cover morphisms between schemes and so the in the following solution, I cannot merely say ""Spec is a functor from commutative rings to affine schemes and, since functors preserve isomorphisms, we are done!"" Many thanks! Let $A$ and $B$ be commutative unital rings. Suppose that $\rho:B \to A$ is a ring isomorphism. I want to show that there is an induced isomorphism of the affine schemes
$$\mathrm{Spec }(A)\to \mathrm{Spec}(B).$$
Since Spec is a contravariant functor from CRing to Top, we see that $\rho$ induces a homeomorphism
$$\pi:\mathrm{Spec}(A)\to \mathrm{Spec}(B).$$
I must now construct an isomorphism of sheaves
$$\Phi:\mathcal{O}_B\to\pi_*\mathcal{O}_A$$
where I have abbreviated $\mathcal{O}_{\mathrm{Spec}(B)}$ (resp. $\mathcal{O}_{\mathrm{Spec}(A)}$) to $\mathcal{O}_B$ (resp. $\mathcal{O}_A$). For each $f \in B,$ we define
$$D_B(f)=\{P \in \mathrm{Spec}(B) \, : \, f \notin P\}.$$
The collection $\mathcal{B}=\{D_B(f) \, : \, f \in B\}$ is a basis for the Zariski topology on Spec$(B)$. For each $f \in B$ define
$$S_{f,B}=\{g \in B \, : \, D_B(f)\subseteq D_B(g)\}.$$ Observe that $\pi^{-1}(D_B(f))=D_A(\rho(f))$ $\rho(S_{f,B})=S_{\rho(f),A}$ and so we have $$\pi_*\mathcal{O}_A(D_B(f))=\mathcal{O}_A(\pi^{-1}(D_B(f)))=S_{\rho(f),A}^{-1}A=(\rho(S_{f,B}))^{-1}A.$$ Hence, for each $f \in B,$ we have an induced isomorphism of rings
$$\Phi_{D_B(f)}:S_{f,B}^{-1}B\to (\rho(S_{f,B}))^{-1}A.$$
Moreover, it is clear that, if $D_B(f)\subseteq D_B(g),$ then the following diagram commutes
$$\require{AMScd}
\begin{CD}
S_{g,B}^{-1} B @>{\Phi_{D_B(g)}}>> (\rho(S_{g,B}))^{-1}A\\
@VVV @VVV \\
S_{f,B}^{-1} B @>>{\Phi_{D_B(f)}}> (\rho(S_{f,B}))^{-1}A
\end{CD}$$ 
where the vertical arrows are the ring morphisms arising from the inclusion $S_{g,B} \subseteq S_{f,B}.$ In other words, for each $f\in B,$ we have a ring isomorphism
$$\Phi_{D_B(f)}:\mathcal{O}_B(D_B(f))\to\pi_*\mathcal{O}_A(D_B(f))$$
and this collection of ring isomorphisms is compatible with the restriction maps for the base $\mathcal{B}.$ We thus have a morphism of ""sheaves on the base $\mathcal{B}$"" which thus induces a morphism of sheaves
$$\Phi:\mathcal{O}_B\to\pi_*\mathcal{O}_A.$$
Since the induced ring morphisms on stalks
$$\Phi_p:\mathcal{O}_{B,p} \to (\pi_*\mathcal{O}_{A})_{p}$$
are all isomorphisms (as each $\Phi_{D_B(f)}$ is an isom), it follows that $\Phi$ is an isomorphism of sheaves.","['schemes', 'affine-schemes', 'algebraic-geometry', 'proof-verification']"
2298108,Primes where $(p-1) ^ 2 + 1$ and $(p+1) ^ 2 + 1$ are also prime,"I'm following a math course about basic number theory. The course contains an Open Problems section with Landau’s conjecture , that states: "" There are infinitely many primes of the form $n^2 + 1$. "". Examples include: $2 = 1^2 + 1$ $5 = 2^2 + 1$ $17 = 4^2 + 1$ $37 = 6^2 + 1$ I noticed that n in these examples are primes minus one. So I made a program that checks for the first x primes if $(p-1) ^ 2 + 1$ is also prime. This yields the primes: $2, 3, 5, 7, 11, 17, 37, 41, 67, 127, 131, 151, 157, ..$ I also checked out $(p+1) ^ 2 + 1$, which yields: $3, 5, 13, 19, 23, 53, 73, 83, 89, 109, 149, 179, 223, ..$ Both formula's seem to yield numbers at about the same rate.
However, what I find strange is the intersection of the sets. If I look for primes where both $(p-1) ^ 2 + 1$ and $(p+1) ^ 2 + 1$ are also prime, only 3 and 5 seem to suffice. From there the sets seem to go their seperate ways. Now I would like some insight into why this is, but I can't find the above formula's or the sets using searches. With my computer I tried the first 50 million primes but only 3 and 5 seem to have this these properties. What am I looking at here? Are there other primes known that satisfy these properties?","['number-theory', 'prime-numbers']"
2298122,A sum over all permutations,"I want to consider the sum 
$$\sum_{\sigma\in\mathfrak{S}_n}\frac{x^{s(\sigma)}}{|\sigma|}$$
where $x$ is a real number, $s(\sigma)$ is the number of cycles of $\sigma$ and $|\sigma|$ is the product of lengths for cycles of $\sigma$. Will it possible to have an exact formula or a generating series for this number when $n$ ranges?","['combinatorics', 'symmetric-groups']"
2298132,complex matrices of rank not greater than k is irreducible algebraic variety,"So, help guys. How to prove that the set of all complex n×n matrices of rank not greater than $k$ is an irreducible algebraic variety of dimension $k(2n − k)$. Some definitions here: $A$ algebraic variety, if set of its points are common zeros of polynomials $\in K[x_1, x_2, ..., x_n]$ $A$ irreducible algebraic variety, if its cannot be represented as $A = B\cup C$. Where $B,C$ - are algebraic varieties.",['algebraic-geometry']
2298143,First encounter of Sturm-Liouville problem,"I have been assigned to find a solution to a specific Sturm-Liouville problem as preparation for an upcoming interview. This is in fact the first time I've ever met this class of problems (being a second year mathematics student at university). Anyway I've done some research and had a good crack at the problem but I find myself not knowing whether anything I've done is right. Here is the phrasing of the question: Any linear second order ordinary differential equation can be written in the classical Sturm-Liouville form, $$L(y(x))=\lambda w(x)y(x),\;x\in[a,b],\;(1)$$ in which the operator, $L$, is self-adjoint. Typically, $(1)$ will be subject to boundary conditions of the form, $$A_1y(a) + B_1y′(a)=0,\;A_2y(b) + B_2y′(b)=0.\;(2)$$ The solution of $(1)$, subject to $(2)$, gives rise to an infinite set of eigenfunctions, $y_n(x)$, which are orthogonal with respect to one another and the weight function, $w(x)$. Each eigenfunction has an associated, real eigenvalue, $λ_n$. The conditions we are given to work with are: $$L = \frac{d^2}{dx^2} + 1,\;x ∈ [0, 1],$$
  $$w(x) = 1,$$
  $and,$
  $$y(0) = 0,\,y'(1) = 0.$$ I am asked to find the analytic solution to this particular Sturm-Liouville problem which I worked out to be:
$$y_n(x) = B_n\sin\left(\left(2n+1\right)\frac{\pi}{2}x\right),\;n\in\mathbb Z$$ where $B_n$ is undetermined. I am asked to determine $B_n$ by imposing: $$\int_0^1y_n^2(x)\,dx=1.$$ Using this I found that $B_n=\pm\sqrt{2},$ which troubles me because in all the examples I've looked at regarding Sturm-Liouville problems a situation like this (where the constants are ambiguous) has not arisen. So I am worried I have made an error somewhere leading up to this. Anyway the next task is to represent $g(x)=x$ as an infinite series using the previously found eigenfunctions over the domain $x\in[0,1].$ Now I searched online for a method to do this and found this document: Non-homogeneous Sturm-Liouville problems . Looking at the top of the second page they give a formula for finding the coefficients/weightings to express any function over $[0,1]$ as a series of eigenfunctions. Using this and my eigenfunctions I found that $$x=\frac{8}{\pi ^2}\sum_{n=1}^\infty\frac{(-1)^n}{(2n+1)^2}\sin\left(\left(2n+1\right)\frac{\pi}{2}x\right).$$ But I know this is completely wrong as I plotted this sum on MatLab to a sufficient number terms and it looked nothing like the function $g(x)=x$. Now if you've read this far that is much appreciated and any help you could provide would be fantastic as I really would like to do well in solving this problem. Of course I will continue to research into this topic (I've even bought a textbook on Sturm-Liouville theory!) and will keep this post updated as necessary.","['functional-analysis', 'sturm-liouville', 'ordinary-differential-equations']"
2298162,algebraic variety of dimension 0 [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question How to prove that if algebraic variety has zero dimension it must be finite set of points.
In other words: how to prove that it can't be infinite set ??? Definitions algebraic variety V - if V is the common zero set of a polynomial system over Field K (polynomes from $K[x_1,...,x_n]$) dimension of V is $ trdeg(K(V) : K)$, $K$ - is assumed to be algebraically closed",['algebraic-geometry']
2298202,Bounding real valued integral with complex variable,"This is an exercise from Gamelin's Complex Analysis , IV.3.3. Let $f(z)=\sum_{k=0}^n c_k z^k$ be a polynomial. My question is in part (b). Before getting into the details, (a) states that If the $c_k$'s are real, then $$
\int_{-1}^1 f(x)^2 dx \leq\pi\int_0^{2\pi}|f(e^{i\theta})|^2\frac{d\theta}{2\pi}.
$$ (b) If the $c_k$'s are complex, show that $$
\int_{-1}^1 |f(x)|^2 dx \leq\pi\int_0^{2\pi}|f(e^{i\theta})|^2\frac{d\theta}{2\pi}.
$$ To solve it, we write $c_k=a_k+ib_k$ ($a_k$ and $b_k$ real). $$
|\sum_kc_kx^k|^2 = |\sum_ka_kx^k + i\sum_kb_kx^k|^2 = (\sum_ka_kx^k)^2 + (\sum_kb_kx^k)^2,
$$ then $$
\int_{-1}^1 |f(x)|^2dx = \int_{-1}^1dx((\sum_ka_kx^k)^2 + (\sum_kb_kx^k)^2)\leq \frac{\pi}{2\pi}\int_0^{2\pi}d\theta(|\sum_ka_ke^{i\theta k}|^2 + |\sum_kb_ke^{i\theta k}|^2),
$$ where I have used twice part (a). Here is where I am stuck, I cannot find a valid relation between $|\sum_ka_ke^{i\theta k}|^2 + |\sum_kb_ke^{i\theta k}|^2$, and $|f(e^{i\theta})|^2$.","['complex-analysis', 'integration']"
2298204,Prove that $\operatorname{cond}_2(A) \le n \cdot \operatorname{cond}_2(DAD)$,"Let the matrix $A \in \mathbb{C}^{n\times n}$ be positive definite with the unit diagonal. Let the matrix $D \in \mathbb{C}^{n\times n}$ be diagonal positive definite. Prove that $$\operatorname{cond}_2(A) \le n\cdot \operatorname{cond}_2(DAD),$$ where $\operatorname{cond}_2(A) = \|A\|_2\|A^{-1}\|_2$. Really I have no idea how to prove it. I can only propose several suitable inequalities such that $\|B\|_2^2 \le \|B\|_1\|B\|_\infty$, $\|DAD\|_2 \le d_{\max}^2\|A\|_2$, where $d_{\max} = \|D\|_2$ is the maximal diagonal element of $D$. And $\|D^{-1}A^{-1}D^{-1}\|_2 \le \dfrac{1}{d_{\min}}\|A^{-1}\|_2$, so $\operatorname{cond}_2(D^{-1}AD^{-1}) \le \dfrac{d_{\min}}{d_{\max}} \operatorname{cond}_2(A)$. Great thanks for any help or ideas!","['matrices', 'normed-spaces', 'inequality', 'linear-algebra']"
2298220,Sobolev Embeddings (reference request),"The following two results are often used in research papers: $$W^{2,1}_p(J\times \Omega)\hookrightarrow L^\infty(J\times\Omega)\qquad\text{and}\qquad \|u^2\|_{L^p(J\times\Omega)}\le \|u\|^2_{W^{2,1}_p(J\times \Omega)},$$
  where $$W^{2,1}_p(J\times \Omega):=L^p(J,W^2_p(\Omega))\cap W^1_p(J,L^p(\Omega)),\qquad J\subset\mathbb{R},\quad \Omega\subset\mathbb{R}^n\quad\text{bounded, smooth}$$ However, I could not find a book/article/proof I could use as a reference for these embeddings. It is not clear to me why these results hold and for which $p$ it holds. I suppose that there is a lower bound for $p$?","['real-analysis', 'reference-request', 'functional-analysis', 'book-recommendation', 'sobolev-spaces']"
2298256,Function that converts values to 0 or 1,"I'm looking for a function that takes a number between 0 and 1 and converts it into 0 if number is between 0 and 0.5, and into 1 if number is between 0.5 and 1. So far I've got the first part, f(x) = max(x - 0.5, 0.0), but can't figure out how to continue the formula for the second part. EDIT: The idea is to write it as one expression to avoid if branching.","['algebra-precalculus', 'functions']"
2298259,Function that fails to be differentiable on a set of measure zero.,"I've been trying to do the following question, but I've been unable to make any conclusions at all. If anyone could offer a suggestion, please do! It's appreciated. Let $E \subset \mathbb{R}$ be a set of Lebesgue measure zero. Show that there exists a function defined on $\mathbb{R}$ which is continuous and increasing everywhere and that fails to be differentiable at each point in $E$.","['measurable-functions', 'real-analysis', 'lebesgue-measure', 'measure-theory']"
2298298,Let G be a multiplicative group of $n\times n$ matrices. If $Int(G)\not = \emptyset$ then $G$ is open on $\mathbb{R}^{n^2}$,"Let G be a multiplicative group of $n \times n$ matrices. If $\text{int}(G)\not = \emptyset$ then $G$ is open on $\mathbb{R}^{n^2}$ Clarifying notation: $\text{int}$ denotes the set of interior points of $G$ . If $G$ is an open set then $G = \text{int}(G)$ . I think the best way is to try a contradiction. Suppose that exists $a \in G$ s.t. $a \not \in \text{int}(G) \implies \forall \; \delta>0, B(a,\delta)\cap(\mathbb{R}^{n^2}-G)\not =\emptyset$ which means any ball centered in $a$ must contain points of the complement of G. Now, if $\text{int}(G) \not =\emptyset\implies \exists b \in G$ s.t. $B{(b,r)}\subset G$ for some $r \in \mathbb{R}_+$ . Since $G$ is a multiplicative group, there is an inverse of every $y\in B(b,r)\subset G$ . then $\forall y \in B(b,r)$ , $y\times a \in G$ (by the closure axiom on the group axioms). Now, that's where I'm stuck, my intention was to somehow use the inverse of every $y$ to show that the ball around a must be a subset of $G$ hence getting that $a \in \text{int}(G)$ , but I don't know how. Any tips?","['general-topology', 'group-theory', 'proof-verification']"
2298336,Help understand the facrtorization theorem,I am reading the following proof about factorization theorem but I have trouble understanding the highlighted part. Related lemma:,"['probability-theory', 'probability', 'statistics']"
2298344,Is there any intuitive relationship between $A A^{T}$ and $A^{T} A$?,"I’m struggling to understand the intuition behind the following arguments. If anyone please can point me in the right direction (in particular, a book that discuss this sort of construction). Let $S_1 = A A^{T}$ , $S_2 = A^{T} A$ , $\Pi_1$ the projection onto the range of $S_1$ , $\Pi_2$ the projection onto the range of $S_2$ . Define $\tilde{A} = \lim_{\epsilon \downarrow 0} (\epsilon I + S_1)^{-1} \Pi_1$ , $T = A^{T} \tilde{A}$ then $TA = \Pi_2$ , $AT = \Pi_1$ . Let $M = \begin{pmatrix} S_1 & 0 \\ 0 & I_d \end{pmatrix}$ a $2d \times 2d$ matrix, $\Sigma = (T, I - \Pi_2)$ a $d \times 2d$ matrix, then $\Sigma M \Sigma^T = I_d$ , $A\Sigma M = S_1$ . I can prove every claim, it’s just that I don’t understand the intuition behind it at all. It seems to me that there is something to it that I can’t quite put my finger on. I think the crux lies in the relationship between $S_1$ and $S_2$ , but I might be wrong. This construction comes out of nowhere in a book that only uses it as an auxiliary result, and I can’t find any reference to this sort of thing anywhere. It feels like it should be something general and applicable elsewhere.","['positive-definite', 'linear-algebra']"
2298345,How to show that $\int_{0}^{\pi/4}{\ln(\cos x)\ln(\sin x)\over \sin(2x)\tan(2x)}\mathrm dx={\ln(2^2)-\ln^2(2)\over 8}?$,Given that: $$\int_{0}^{\pi/4}{\ln(\cos x)\ln(\sin x)\over \sin(2x)\tan(2x)}\mathrm dx={\ln(2^2)-\ln^2(2)\over 8}\tag1$$ I am not sure how to go about to begin tackling this problem of proving $(1)$.,"['integration', 'calculus']"
2298392,Showing that the minimal polynomial of an $n \times n$ matrix has degree at most $n$ without using the Cayley-Hamilton Theorem,"Let $A$ be an $n \times n$ matrix over a field $k$. Or, more generally, an endomorphism of an $n$-dimensional $k$-vector space. Then the minimal polynomial $p_A(t)$, of $A$, has degree at most $n$. The usual way to show this is as a corollary of Cayley-Hamilton: If $\Phi_A(t) = \det(tI - A)$ then $\Phi_A(A) = 0$ and $\deg \Phi_A = n$. Since $p_A \mid \Phi_A$, it follows that $\deg p_A \le n$. One can also prove this using the structure theorem: The $k[t]$-module $V = k^n$, with action given by $t \cdot v = Av$, decomposes as a direct sum $$V \cong \bigoplus_{i = 1}^r k[t]/(q_i), $$ where $0 \ne q_1 \mid q_2 \mid \dots \mid q_r = p_A$. Taking dimensions we have $$ n = \sum_{i = 1}^r \deg q_i. $$ Therefore $\deg p_A = \deg q_r \le n$. It is clear that we do not need the full strength of the structure theorem; all we need to do is show that there is a module-embedding $$ k[t]/(p_A) \hookrightarrow V. $$ This is shown in the course of proving the structure theorem. Question: Can we show that $\deg p_A \le \dim V$ without using Cayley-Hamilton or the the structure theorem? In particular, are there any easier proofs of this fact than as a corollary of Cayley-Hamilton?","['alternative-proof', 'modules', 'linear-algebra', 'minimal-polynomials']"
2298399,Analytic function and the Lagrange interpolating polynomial,"Let $f(z)$ be analytic in a closed set $A$ and bounded by contour $C$ . Let $z_1,z_2,...,z_n$ be different arbitrary point in the interior of $C$ and let $w_n(z)=(z-z_1)(z-z_2)...(z-z_n) $ . Prove the integral $$P(z)=\frac{1}{2\pi i} \int_C \frac{f(x)}{w_n(x)} \frac{w_n(x)-w_n(z)}{x-z} dx$$ is a polynomial of degree $(n-1)$ that is the same as $f(z)$ at $z_1,z_2,...,z_n$ points. Note: $P(z)$ is the Lagrange interpolating polynomial. I think I have an idea for the proof, but I don't know how to write it formally. Idea I think this formula $$f^n(z_0)=\frac{n!}{2\pi i} \int_J \frac{f(x)}{(x-z_0)^{n+1}} dx $$ will be useful because practically is telling us that P $(z)$ must be 'equal to' $\frac{f^n(z_0)}{n!} \left(\frac{w_n(x)-w_n(z)}{x-z} \right)$ . Now the rest is trying to proof that $\frac{f^n(z_0)}{n!} \left(\frac{w_n(x)-w_n(z)}{x-z} \right)$ must be something very similar to the Lagrange polynomial. Is this a good idea? Could be demonstrated in another way?
Thanks for any suggestions/hint/tip/help.","['complex-analysis', 'analytic-functions', 'complex-integration']"
2298402,Finding solutions to $2^x+17=y^2$,"Find all positive integer solutions $(x,y)$ of the following equation: 
  $$2^x+17=y^2.$$ If $x = 2k$, then we can rewrite the equation as $(y - 2^k)(y + 2^k) = 17$, so the factors must be $1$ and $17$, and we must have $x = 6, y = 9$. However, this approach doesn't work when $x$ is odd.","['number-theory', 'diophantine-equations', 'elementary-number-theory']"
2298435,Difficult Inverse trigo problem,"Given
$$\arccos(y_1) + \arccos(y_2) + \dots + \arccos(y_k) =kπ$$
for any value of $k>1$ and 
$$
A= y_1^1 + y_2^2 + \dots + y_{2k}^{2k},
$$
the task is to find the value of $A$. I have no idea from where should I start with the problem. I tried taking cosine on both sides in first equation but it's not helping.","['trigonometry', 'trigonometric-series', 'inverse-function', 'inverse']"
2298464,Matrix Representation of an Operator (Volterra),"Generally, how can I find the matrix of a given operator $K$ with respect to a given basis ${e_n}$? I thought I should use $\langle K(e_n),e_m\rangle$, is it the right way? In particular, how can I find the matrix representation of Volterra operator, i.e $K(\varphi)=\int_{a}^{b}k(t-s)\varphi(s)ds$? Is there easier way than the way I proposed?",['functional-analysis']
2298476,How to Prove a 3 dimensional curve isn't contained in a Quadratic Surface?,"So I'm given a curve parametrically as $$ C = \begin{pmatrix} x = t \\ y  = t^2 \\ z = t^3 \end{pmatrix} $$ And  I wish to show that there doesn't exist a surface $S$ of the form $$ A + Bx + Cy + Dz + Exy + Fxz + Gyz + Hx^2 + Iy^2 + Kz^2 = 0 $$ That contains said curve. But I'm not really sure how to do this? One Idea: So in a simpler case of just showing that no surface $S$ of the form $A + Bx + Cy + Dz = 0$ contains the curve $C$, one can observe that $C$ has non-zero torsion, whereas every curve bounded in a plane $S$ will have to have $0$ torsion, so clearly $C$ is not contained in $S$. This motivates me to then ask: how do I generalize ""Torsion"" to a more general measure that is bounded for all quadratic surfaces?","['differential-geometry', 'algebraic-geometry']"
2298498,Solving $z^5=-16+16\sqrt3i$ using the fifth roots of unity,"1 Write down the fifth roots of unity. Hence, or otherwise, find all the roots of the equation
  $$z^5=-16+16\sqrt3i,$$
  giving each root in the form $re^{i\theta}$. [4] In this question, I can work out the answer using de Moivre's theorem, but the question implies that I have to use the 5 roots of unity somehow. Does it just mean that I have to solve the equation in the same way as I solved it for the 5 roots of unity, or whether I have to actually use the 5 roots of unity?","['algebra-precalculus', 'roots-of-unity', 'complex-numbers']"
2298507,Maze with a randomly moving obstacle,"There is a 8*8 maze, and a player starting at (0, 0) wants to arrive at (7, 7) in minimal moves. For each round (a round may contain several moves), the obstacle will be randomly set at a grid it has not been set before, also, it won't be set at either (0, 0) or (7, 7). After the obstacle is set (although the player has no idea where it is in this round), the player has to give a probability distribution of his move in this round, e.g. up: 0.5, down: 0.2, left: 0.2, right: 0.1, then his move will be generated depending on the distribution. If he bumps into the obstacle or gets out of the maze (e.g. move right when he is at (7, 0)), he has to stay at the current grid, and another move will be generated. The process goes on until he moves to a feasible grid. When a round ends, the player will know where the obstacle was in the last round. To be clear, supposed the player is in the nth round, then he will know the history of the obstacle from the first round to the (n-1)th round. My question is, given the history of the obstacle and the current position of the player, is there a strategy to minimized expected moves from a probabilistic perspective ? EDIT I've wrote a simulation program , and tried several strategies with it. Define a strategy consisting of four real values, representing the probability of moving up, down, left, and right, respectively.The naive one [0.25, 0.25, 0.25, 0.25] got an average of 73 moves. Another strategy is defined below: if up and right are both safe, return [0.5, 0, 0, 0.5] if up is safe, return [1, 0, 0, 0]; if right is safe, return [0, 0, 0, 1] if at the right most line, return [0.5, 0, 0.5, 0]; if at the up most line, return [0, 0.5, 0, 0.5] else, return [0.5, 0, 0.5, 0] In the end, the second strategy need 18.4573 moves on average. (10000 trials) It is a huge success when comparing with the naive one, but I am struggling with getting closer to the theoretically minimum of 14 moves. I appreciate any advice or suggestions. Confirmation There is a $(X,Y)=(0:N-1,0:N-1) \in \mathbb{R}^2, N=8$ maze Yes There is no inner walls or paths at the maze (Then it is not a maze??), Yes, I called it a maze only because there is a single randomly appearing obstacle. The positions cannot get outside the domain, hence evidently the movement have to be properly constrained, Yes, if the intended move generated by the probability distribution will make the player get out of the maze, the count of moves will increment by one, and the player has to stay at the current position until an feasible move is generated. There is an changing obstacle at an unknown position $(x^o,y^o)$, for every time $t$, Yes The obstacle position  at $t=n-1$ is known at $t=n$, Yes For every time $n$, the obstacle change their coordinates according an uniform distribution on $(X,Y)$. Hence, the obstacle can ""jump"" to their new position, Yes The obstacle don't take a previous coordinate. Hence the uniform distribution is over $(X,Y)-(X^o,Y^o)$, $(X^o,Y^o)={(x^o(t),y^o(t),t=1...n-1)}$. Hence the obstacle takes its last move at $t=N^2$ and then it disappears (??), The obstacle won't be set on the stating point and the ending point, so the player will lose the game if he can not reach the exit in $N^2 - 2$ rounds The player position $(x(t),y(t))$ one square (up, down, left or right) per time, Yes The player cannot pass, hence make no move at all (??), I am not sure what you are referring. If the obstacle hits the player by a player move or an obstacle change, the player loses, If the obstacle hits the player by a player move, as I stated in my problem, If he bumps into the obstacle or gets out of the maze (e.g. move right when he is at (7, 0)), he has to stay at the current grid, and another move will be generated. The process goes on until he moves to a feasible grid. In short, the player loses the game iff he can not reach the exit in $N^2 - 2$ rounds. If the obstacle hits the player by an obstacle change, we assume that the player is strong enough to lift the obstacle, so he can safely stay with the obstacle in the same grid. If the player reach the exit, the player wins. Yes","['probability', 'algorithmic-game-theory']"
2298544,Find equation for solution of differential equation.,"Please help me to solve this problem: Differential equation $y''+p(x)y=0$ has nonzero solution $f(x)$. Find the equation for function $z(x)=\frac{f'(x)}{f(x)}$. My ideas: I only see that $z(x) = \ln(y(x))'$. I tried to express this function in terms of $p(x)$, but failed. Can you please help me with the problem?
Thanks a lot! Update:
After the hint given by A.Γ. it was trivial to show that required equation is $z'+z^2+p=0$.
Thanks a lot for your help, A.Γ.!","['cauchy-problem', 'ordinary-differential-equations']"
2298568,"Given distance covered as a function of time, find acceleration.","Since this question covers more aspects of differentiation and mathematical manipulation than kinematics, I am posting it here. My attempt : On differentiating position(x) once, we get velocity(v) and on differentiating position twice, we get acceleration(A). Therefore, $xv=at+b$ and $A x^1/3= (vx) (x-vx) $ are the two equations I got. But, I can't seem to express acceleration completely in terms of position, as given in the options below. Are the options wrong or am I missing something?",['derivatives']
2298630,Is it possible to obtain a non-skewed coin from a skewed coin? [duplicate],"This question already has answers here : How to choose between two options with a biased coin (1 answer) Puzzle about technique of fair using of unfair coin (7 answers) Closed 7 years ago . I was thinking about a puzzle, unfortunately I do not remember where I saw it, which asked about Given a skewed coin where the $p_H \neq p_T$ where $p_H$ and $p_T$
  are probability of observing head in one coin flip and probability of
  observing tail in a single coin flip, respectively. Is it possible to
  obtain a non-skewed coin by flipping the given skewed coin? Even keywords for more search are greatly welcomed.","['probability-theory', 'random-variables']"
2298639,Find short and simple methods to solve $24x^4+1=y^2$,"Find all  this diophantine equation  $$24x^4+1=y^2\tag{1} $$  postive integers solution it is clear $(x,y)=(1,5)$ I know $y^{2}=Dx^{4}+1$, where $D>0$ and is not a perfect square, has at most two solutions in positive integers (cf. L. J. Mordell, Diophantine equations, p. 270. Does this equation have another proof such Lucas's assertion, with short and simple methods? Like this paper: Anglin, W. S. ""The Square Pyramid Puzzle."" Amer. Math. Monthly 97, 120-124, 1990. The square pyramid puzzle In the paper,Following two question have simple methods to solve it. There are no positive integers $x$ such $2x^4+1$ is a square. and There is exactly one positive integer $x$,namely $1$, such that $8x^4+1$ is a square? But How can I find simple methods to solve $(1)$?","['number-theory', 'diophantine-equations']"
2298645,A Hard Geometry Problem on circle,"$$\angle(ABC) = 30°\\
\angle(BCO) = 20°\\
\angle(OCD) = 20°$$ How do i find $\angle(ODC)$ ? so i wanted to show my teacher this but he is not available yet. Can someone help me to solve? geometry problems on circle seems hard to me. Thanks!","['circles', 'geometry']"
2298704,Variance of $X_{i}+X_{j}$ if $X_{1} + \ldots + X_{N}=1$,"I have random variables $X_{1}, X_{2}, \ldots, X_{N}$, where $X_{i} \in \{0,1\}$ and
$$X_{1} + \ldots + X_{N}=1$$
I.e. exactly one of the $X_{i}$'s are $1$, and the rest are $0$. In addition, denote $P(X_{i} = 1) = p_{i}$, where $\sum_{i} p_{i}=1$. I do not want to assume that the $X_{i}$'s are identically distributed, meaning we may have $p_{i} \neq p_{j}$ for some $i\neq j$. I now want to calculate the variance of $X_{i}+X_{j}$ for any $i \neq j$, but am having some difficulty. Can anyone provide a formula and an explanation of how to do so for this example? Much appreciated!","['statistics', 'probability', 'variance', 'random-variables']"
2298714,Projectivization of a vector space: projective geometry definition vs algebraic geometry definition,"Let $V$ be a vector space. In a course of projective geometry I was told that
$$
\mathbb{P}V=\{l\subseteq V:l \text{ is a line in }V\}.
$$
Studying algebraic geometry I have seen that the projectivization of the vector space $V$ is defined as 
$$
\mathbb{P}V=\mathrm{Proj}\left(\bigoplus_{k=0}^{\infty}\mathrm{Sym}^{k}(V^{\vee})\right).
$$
The problem is that I don't really understand how this spaces are related to each other. To be more precise, given a line $l\subseteq V$, which is the homogeneous prime ideal of $\bigoplus_{k=0}^{\infty}\mathrm{Sym}^{k}(V^{\vee})$ corresponding to $l$, and given a point $p\in \mathrm{Proj}\left(\bigoplus_{k=0}^{\infty}\mathrm{Sym}^{k}(V^{\vee})\right)$ (do we need it to be closed?), which is the line of $V$ corresponding to $p$?","['projective-geometry', 'algebraic-geometry']"
2298779,How to compute 2-adic square roots?,"I know that, for a $2$-adic unit to be a perfect square, it must be of the form $\cdots001.$, for example the number $17$ ($10001.$) is a $2$-adic square. How would I go about finding the $2$ adic expansion of its square roots? There ought to be two, either of which is $-1$ times the other, but I don't know how to find either one. I've tried setting up long multiplication and guessing digits that work, but there seem to be too many degrees of freedom. Any insights are appreciated.","['number-theory', 'perfect-powers', 'square-numbers', 'p-adic-number-theory']"
2298810,Moment-generating function,Let X~Exponential(1). I know that the moment-generating function of an exponential distribution is defined as $(1-t\lambda)^{-1}$. And hence $E[e^{tx}]=(1-t)^{-1}$. But what is $E[Xe^{tx}]$? Would that be the first moment of the moment-generating function?,"['statistics', 'moment-generating-functions']"
2298811,Derivatives of trigonometric functions: $y= \frac{x \sin(x)}{1+\cos(x)}$,I'm trying to find the derivative of: $$y= \frac{x \sin(x)}{1+\cos(x)}$$ I've tried but I can't achieve the simplified form - Here's my try- $$y' =  \left(\frac{x \sin(x)}{1+\cos(x)}\right)'$$ $$y' = \frac{x\sin^2(x) + (\cos(x)+1 )(\sin(x)+x\cos(x))}{(\cos(x)+1)^2}$$ I'm pretty sure the above is correct that is why I didn't show the steps in between ... but I can't simplify it until - $$\frac{x+\sin(x)}{1+\cos(x)}$$ Which concept or formula am I missing out from in order to simplify it further? Or what should I do next? Thanks!,"['derivatives', 'trigonometry', 'calculus']"
2298823,Squares in $(\operatorname{rad}(1)^2+1)\cdot(\operatorname{rad}(2)^2+1)\ldots(\operatorname{rad}(n)^2+1)$,"For integers $n\geq 1$ , $\operatorname{rad}(n)$ denotes the radical of an integer, see in Wikipedia this definition $$\operatorname{rad}(n)=\prod_{p\mid n}p,$$ if $n>1$ with factorization $n=\prod_{p\mid n}p^{e_p}$ , and defining $\operatorname{rad}(1)=1$ . I'm inspired in a similar conjecture due to Amdeberhan, and Medina and Moll. Question. I believe that the following conjecture holds. Can you prove or refute it? There exists an integer $N$ such that $\forall n>N$ $$\prod_{k=1}^n(1+(\operatorname{rad}(k))^2)$$ is not a square. Many thanks. References: Amdeberhan, and Medina and Moll, Arithmetical properties of a sequence arising from an arctangent sum, J. Number Theory (2007).","['conjectures', 'analytic-number-theory', 'number-theory', 'prime-numbers', 'elementary-number-theory']"
2298831,Proving that a group of order $77$ is cyclic.,"Prove that a group of order $77$ is cyclic. I reached a step then got stuck. My attempt: Let $G$ be a group with $|G|= 77$. $G$ may have elements of orders $7$, $11$ and $77$ (divisors of $77$). If $G$ has an element of order $77$, then we are done. If $G$ has only elements of order $7$, then the number of elements of order $7$ is divisible by $\phi(7)= 6$, then we will have, due to the presence of the identity element of order $1$, $|G|= 77= 6k+1$, for some $k$. This yields that $76=6k$, but $6\nmid 76$. Similarly if we suppose that $G$ has only elements of order $11$. We will work the same way until reaching $10\nmid 76$. Hence we conclude that $G$ has elements of order $7$ and $11$. Here I don't know how to continue. I know that if $a,b \in G$, where $|a|= 7$ and $|b|= 11$ then $|ab|$ divides $lcm(7,11)= 77$, but how to show that there is an element of order $77$?? I should let you know that I didn't take the theorem saying: $|HK|= \frac{|H||K|}{|H\cap K|}$, as I see it in similar proofs.","['finite-groups', 'group-theory', 'cyclic-groups']"
2298834,Does this Cartan-Eilenberg exercise contain a mistake?,"In Cartan and Eilenberg, Homological Algebra , Exercise 10, page 123, the last statement is the following: if $A\to B$ is a ring homomorphism such that $B$ is projective as an $A$-module, then for any $A$-module $M$ we have
$$
\text{inj.dim}_B(B\otimes_AM)\leq \text{inj.dim}_A(M).
$$
This immediately implies that if $B$ projective as an $A$-module and $M$ is an injective $A$-module, then $B\otimes_AM$ is an injective $B$-module. However, in this stack exchange question , @EricWofsey gave a counter-example: let $A=k[x]$ the polynomial ring over a field $k$ and $B=l[x]$ where $l/k$ is a non-algebraic field extension. Since $A$ and $B$ are PID's, a module is injective if and only if that module is divisible. Let $M=k(x)$ then $M$ is an injective $A$-module. But $B\otimes_A M=l\otimes_k k(x)$ is the subring of $l(x)$ consisting of rational functions which can be written with a denominator in $k[x]$. In particular if $t\in l$ is not algebraic over $k$, then $\frac{1}{x-t}\notin l\otimes_k k(x)$ but $x-t\in l\otimes_k k(x)$. Therefore $l\otimes_k k(x)$ is not divisible hence not injective as an $l[x]$-module. It seems that this gives a counter-example of Exercise 10. I'm not sure if that exercise is wrong or I misunderstand something.","['injective-module', 'abstract-algebra', 'modules', 'homological-algebra']"
2298857,Why does the negative sign leave when this expression is simplified?,I was working on some math problems on Khan Academy and wondered why does the negative '-' sign go away when the following radical expression is simplified? In particular how does one obtain the equality $$\frac{-4}{-6} \pm \color{red}{-}\frac{2\sqrt{7}}{6} = \frac{2}{3} \mp \frac{7}{\sqrt{3}}$$,"['algebra-precalculus', 'radicals']"
2298876,Find all points where the function is differentiable and calculate its derivative,"I need help with this:
I need to find all points where this function is differentiable:
$f:\mathbb{R}^{3}\rightarrow \mathbb{R}, \begin{pmatrix}x\\ y\\ z\end{pmatrix} \mapsto e^x \sin (z) + z \cos\bigl( \sqrt{x^2 + y^2 +1}\,\bigr).$ After that I must calculate the derivatives at that points. This is a part of an exercise in my analysis class. It is the first part of a larger exercise but i need to understand this first to do the rest. I know so far that to calculate the derivatives i need to show that the function is continous partial differentiable. But I don't know how to find all these point and do it for them. Can you give me a hint?",['multivariable-calculus']
2298880,measurability of supremum of a class of functions,"Let $f:X\times Y \mapsto R$ be a measurable function on product space $X\times Y$, where $X$ and $Y$ both are some metric spaces. Define $g(x) := \sup_{y\in Y} f(x,y)$. [Q.] Is $g$ a measurable function on $X$? If not, what is the sufficient condition to be measurable?",['real-analysis']
2298943,What will the equation of a sine wave having the axis as a parabola $y= ax^2$ be?,approximate representation of my curve(in red),"['plane-curves', 'functions', 'analytic-geometry']"
2298992,Proving that a group acting freely on a tree is a free group,"I want to prove that a group that acts freely on a tree is a free group.
The proof I saw used weird things (in particular it considered edges as line segments, and used ""half-edges"") and I didn't like it so i tried to come up with my own proof, and the one I found seems much simpler, and therefore it seems suspicious (why go with a weird complicated proof when there is a simple, natural one ?). 
Here goes : 
I first prove the result assuming the action is transitive : let $G$ be a group acting freely and transitively on the (nonempty) tree $T= (V,E)$. Let $v$ be any vertex in $V$ and for $x$ a vertex, we let $N(x)$ be the set of neighbours of $x$. I also let $N := N(v)$ for simplicity. For all $n\in N$, there is $g\in G$ with $g\cdot v = n$, because the action is transitive and since the action is free, this $g$ is unique : we denote it by $g_n$. Then we put $S= \{g_n\mid n\in N\}$ and $S'\subset S$ such that for all $n\in N$, either $g_n$ or $g_n^{-1}$ belongs to $S'$, these options being mutually exclusive. I want to show that $S'$ is a free generating set for $G$.
First of all, it is a generating set : let $g\in G$ and let $x_0 = v, x_1,..., x_m, x_{m+1} = g\cdot v$ be a path from $v$ to $g\cdot v$ in $T$. Since the action is transitive, we can find $g_i$ with $g_i \cdot v = x_i$. Since $\{x_i, x_{i+1}\}\in E$, it follows that $g_{i+1}^{-1}g_i\in S$ and thus, since $g_1\in S$, we get that $g\in \langle S\rangle = \langle S'\rangle$, which is what I wanted to prove. I now have to prove that $S'$ is a free generating set. But to any reduced word on $S'\cup S'^{-1}$ one can associate a path, and if, when computing the word in $G$ one gets $e$ (the unit of $G$), then we have a cycle in $T$, which is a contradiction with the fact that $T$ is a tree.
Therefore $G$ has a free generating set : $G$ is a free group. Now if the action of $G$ isn't transitive, we make it transitive : let $G$ act freely on the tree $T=(V,E)$. Let $v$ be any vertex in $V$ and $V' := G\cdot v$ (the orbit of $v$). $g\cdot v$ and $h\cdot v$ are connected in an edge in $T' = (V', E')$ if and only if either they are connected in an edge in $T$, of if all paths from one to the other in $T$ don't intersect $G\cdot v$. Then $T'$ has no cycle because $T$ is a subdivision of $T'$, and $T$ has no cycles. Moreover, by construction, $T'$ is connected : $T'$ is a tree.
The obvious action of $G$ on $T'$ is then free and transitive so we can use the previois result : $G$ acts freely and transitively on a tree, so it is a free group. In conclusion, if $G$ acts freely on a tree, it is free. My doubts about this proof are about the point where I prove that $S'$ is a free generating set. They come from this fact : it seems that $\Bbb{Z}/2\Bbb{Z}$ acts freely on the tree with two vertices. The action is obvious, and $1$ has no fixed point, so the action is indeed free. But $\Bbb{Z}/2\Bbb{Z}$ is not a free group. And when looking at how my ""proof"" goes wheb $G=\Bbb{Z}/2\Bbb{Z}$ and $T$ is the tree with two vertices, the point where it stops working is precisely the point where I claim that $S'$ is a free generating set. 
While writing this, I see that my mistake is when I claim that I can define $S'$ : for $\Bbb{Z}/2\Bbb{Z}$, since $1= -1$, I cannot define $S'$ as I say. 
But I know that the theorem is true : what am I not seeing ? EDIT: I'm adding this because according to another post on math.SE, it seems that the theorem that I'm mentioning (or at least one of its consequences: the Nielsen-Schreier theorem, which states that a subgroup of a free group is itself free) implies the axiom of choice for finite sets. However, in my ""proof"" I seem to only be using $AC(2)$, i.e. the axiom of choice for sets with $2$ elements (when picking $S'$), but if I remember correctly, the axiom of choice for finite sets isn't a consequence of $AC(2)$, and so I can't have proven the NS-theorem with only $AC(2)$. Can anyone help me spot either the mistake in the proof or the point where I use more than $AC(2)$ ?","['group-actions', 'trees', 'group-theory', 'proof-verification']"
2299015,Proving Trigonometric Equality,"I have this trigonometric equality to prove: $$\frac{\cos x}{1-\tan x}-\frac{\sin x}{1+\tan x}=\frac{\cos x}{2\cos^2x-1}$$
I started with the left hand side, reducing the fractions to common denominator and got this:
$$\frac{\cos x+\cos x\tan x-\sin x+\sin x\tan x}{1-\tan^2x}\\=\frac{\cos x+\cos x(\frac{\sin x}{\cos x})-\sin x+\sin x(\frac{\sin x}{\cos x})}{1-\left(\frac{\sin^2x}{\cos^2x}\right)}\\=\frac{\cos x+\left(\frac{\sin^2x}{\cos x}\right)}{1-\frac{\sin^2}{\cos^2x}}$$and by finding common denominator top and bottom and then multiplying the fractions i got: $$\frac{\cos^2x}{\cos^3x-\cos x\sin^2x}$$ which is far from the right hand side and I don't know what am I doing wrong. What is the correct way to prove this equality?","['algebra-precalculus', 'trigonometry']"
2299034,differ between $M$ and $G/G_{x_0}$,"I have a Lie group $G$ acting transitively on $M$. Why is $M$ diffeomorphic to $G/G_{x_0}$? Here is the function. It remains to see that it is differential both ways.
$$ \phi:G/G_{x_0}\rightarrow M : g G_{x_0}\rightarrow g\cdot x_0$$ Will inverse function theorem do the trick?","['abstract-algebra', 'differential-geometry', 'lie-algebras', 'lie-groups']"
2299042,Matrices of Full Rank is a Smooth Manifold Proof Clarification,"In Lee's Introduction to Smooth Manifolds, he proves that matrices of full rank are a manifold as such: Suppose $m < n$, and let $M_m(m \times n, \mathbb{R})$ denote the subset of $M(m \times n, \mathbb{R})$ consisting of matrices of rank $m$. If $A$ is an arbitrary such matrix, the fact that rank $A = m$ means that $A$ has some nonsingular $m \times m$ minor. By continuity of the determinant function, this same minor has nonzero determinant on some neighborhood of $A$ in $M(m \times n, \mathbb{R})$, which implies that
A has a neighborhood contained in $M_m(m \times n, \mathbb{R})$. Bolding my own, as that's the part I'm having a little trouble with. My understanding is that, because the matrix is invertible it is contained in $\text{det}^{-1}((-\infty, 0) \cup (0, \infty)) \subseteq GL(m, \mathbb{R})$, which is open, since $\text{det}$ is continuous. Then, as $GL(m, \mathbb{R})$ has the subspace topology inherited by $M(m, \mathbb{R})$, this must be contained in an open set of $M(m, \mathbb{R})$, which is in turn contained in an open subset of $M(m \times n, \mathbb{R})$. Then, the intersection of this set with $M_m(m \times n, \mathbb{R})$ will be a neighbourhood $A$. I have two questions: Do I have the right understanding of this argument? How do we know that the vector space topology that on $M(m, \mathbb{R})$ agrees with the subspace topology it will inherit from $M(m \times n, \mathbb{R})$?","['general-topology', 'smooth-manifolds', 'differential-geometry', 'differential-topology']"
2299050,Integrating Square Root of Rational Trigonometric Equation,"Problem Show that $$\int_k^\pi \sqrt{\frac{1-\cos x}{\cos k-\cos x}} \, dx = \pi$$ for all $0\leq k<\pi$. Remark I was trying to prove the isochronous property of the cycloid curve and I ended up with this integral. I don't know how to start. I'm pretty confident that the answer is $\pi$ because I tried plugging in some values of $k$ in Maple and it always returned approximately $\pi$. Need help, please.","['cycloid', 'definite-integrals', 'trigonometry', 'calculus']"
2299065,Truth of $x^2-2=0$,"From Algrebra by Gelfand , it says that ""When we claim that we have solved the equation $x^2-2=0$ and the answer is $x=\sqrt{2}$ or $x=-\sqrt{2}$, we are in fact cheating. To tell the truth, we have not solved this equation but confessed our inability to solve it; $\sqrt{2}$ means nothing except ""the positive solution of the equation $x^2-2=0$ Can someone please explain what he really means? Does he mean every irrational number is meaningless? Thanks in advance.","['algebra-precalculus', 'irrational-numbers']"
2299090,Proof of $(a+b)^x=a^x+b^x$ implies $x=1$,"I'd like to prove that for $a,b>0$, 
  $$(a+b)^x=a^x+b^x \implies x=1.$$ I tried to study the variation of the map $f:x\mapsto (a+b)^x-a^x-b^x$ but unfortunatly it's not monotone since 
$$f'(x)= (\ln (a+b)-\ln (a))a^x + (\ln (a+b)-\ln (b))b^x .$$
Taking $\ln$ in the equation doesn't seems to help either. I feel like I'm missing something obvious. Any help will be greatly appreciate.",['functions']
2299126,Show that half-closed rational intervals dont form a basis for the Lower Limit Topology,"The Lower Limit Topology is the topology generated by the basis $\mathcal{B}$. $\mathcal{B} := \{[a,b) \subseteq \mathbb{R} : a,b \in \mathbb{R}, a < b\}$ I need to show that: $\mathcal{B}_{\mathbb{Q}} := \{[a,b) \subseteq \mathbb{R} : a,b \in \mathbb{Q}, a < b\}$ is not a basis for the Lower Limit Topology. I had shown earlier that the Lower Limit Topology contains the interval $(a,b), \forall a, b \in \mathbb{R}$ by the following proof: We take the collection $\mathcal{C} = \{[a+\frac{1}{n},b): n \in$
  $\mathbb{N}, n > \frac{1}{b-a}\}$. Clearly $\mathcal{C} \in \mathcal{B}$ and
  $\bigcup \mathcal{C} = (a,b)$. In $\mathcal{B}_{\mathbb{Q}}$, for any $a,b$ that are irrational, this proof does not work (since $a+\frac{1}{n}$ and $b$ would not be rational). Initially, I thought I could show that these irrational intervals could not exist in the topology generated by $\mathcal{B}_{\mathbb{Q}}$. But, I'm no longer convinced that's true and am stuck on how to proceed.","['real-analysis', 'limits', 'irrational-numbers', 'rational-numbers', 'general-topology']"
2299162,Can I say that $\left\vert\int_0^\infty \cos x \; dx \right\vert\leq 1$?,"We know that $\int_0^\infty \cos x \; dx$ is undefined. This seems like a very simple question, but I just want to confirm it is okay to do so: Can I say that $$\bigg|\int_0^\infty \cos x \; dx \;\bigg  |\leq 1 \,\textrm{?}$$ Since it is equal to 
$$\bigg[\sin x\bigg]^\infty_0 = \lim_{x \rightarrow \infty} \sin x$$ I have genuinely not seen this done before, it seems like we can say it for sure. Since the limit does not exist but it is not ""unbounded""?","['improper-integrals', 'integration', 'trigonometry', 'calculus']"
2299177,If $x \geq 2$ prove that $\sum_{ n \leq x} \frac{1}{\phi(n)} = \mathcal{O}(\log(x))$,"If $x \geq 2$ prove that $\sum_{ n \leq x} \frac{1}{\phi(n)} = \mathcal{O}(\log(x))$ . This problem is from Apostol's analytic number theory book in the chapter 3 exercises. I am stuck on this problem as I am simply not sure how to do it. I know from the previous chapters that the following relation exists $$\phi(n) = \sum_{d \mid n}\mu(d) \frac{n}{d}$$ So I have $\sum_{n \leq x} \phi(n) = \sum_{n \leq x} \sum_{d \mid n}\mu(d) \frac{n}{d}$ , where $\mu(d)$ is the Möbius function. Can anyone offer some information on how to proceed or use this relation?","['analytic-number-theory', 'totient-function', 'asymptotics', 'number-theory', 'summation']"
2299189,Finding MLE for $P[X > x]$ with $x>0$ given for exponential distribution?,"Problem: Let $X_1, \ldots, X_n$ be a random sample from an exponential distribution with parameter $\theta$. Find a MLE for $P[X > x]$ with $x>0$ given (fixed). My attempt: I first calculated: $$ P[X > x] = \int_x^{\infty} \theta e^{-\theta y} dy = e^{-\theta x}. $$ I also know that $$ L(\theta; \vec{x}) = \prod_{i=1}^n f(x_i; \theta) = \theta^n \exp \left(- \theta \sum_{i=1}^n x_i \right).$$ Then $$ \ln L(\theta; \vec{x}) = n \ln(\theta) - \theta \sum_{i=1}^n x_i. $$ How to proceed now? Normally when we are looking for the MLE for a parameter $\theta$, we differentiate with respect to that parameter. But now I'm asked to find the MLE for a probability. Do I just differentiate with respect to $e^{-\theta x}$? Help is appreciated.","['statistics', 'probability', 'statistical-inference']"
2299195,Why doesn't the limit of $(1 + x - y) / (x^2+ y^2) $ exist?,"How to compute the following limit:
$$\lim_{(x,y)\to (0,0)}\frac{1+x-y}{x^2+y^2}$$
? The teacher's answers is ""the limit doesn't exist"". But when replace the variables, the value is 
$$\frac{1 + 0 - 0}{0^2+0^2}=\frac{1}{0}=\infty.$$
Which one is correct?","['multivariable-calculus', 'real-analysis', 'calculus', 'limits']"
2299234,series solution laplace equation,"I need help finding th series solution to the laplace equation 
$u_{xx} +u_{yy}=0\\$
in the infinite rectangle 
$\Pi =(-\infty,0]$x$[0,\pi]$ in $R^2(x,y)$
provided that sup$_{(x,y)\in\Pi}|u(x,y)|<\infty$ and the function u=u(x,y) satisfy the boundary values 
$u_y(x,0)=u_y(x,\pi)=0, u(0,y)=h(y).$ I have seperated the variables to be $\frac{X''(x)}{-X(x)}=\frac{Y''(y)}{Y(y)}=\lambda$ and split them up to two ODE, but i cant figure out what to do next to meet the boundry conditions when the conditions are with respect to derivative of y. I also dont quite understand the meaning of the notation with sup. All help is apperciated!","['harmonic-functions', 'ordinary-differential-equations']"
2299274,Equivalent definitions of genus of a connected orientable surface,"There are two definitons of genus of a connected, orientable surface.
The first one defines genus as an integer representing the maximum number of cuttings along non-intersecting closed simple curves without rendering the resultant manifold disconnected. The second one — as the number of handles on it. Question . How to prove that they are equivalent? So far, I have tried to prove that from the second definition follows the first one. I understood, that cutting of closed curve leaves manifold connected if this curve is homeomorphic to $a$ cycle (defined in the  attached picture ) of one of the torus (I consider handles as torus with holes sticked to the sphere). For the case of curve lying on sphere, by the Jordan Curve Theorem (any simple closed curve separates $S^2$ into two connected components) we obtain that such curves divide surface into two connected components . I don't understand how to deal with the arbitrary closed curve on $M_g$, e.g., if it goes along several handles in different ways. I have thought about splitting the manifold into sphere and handles, thus, splitting the curve into smaller parts, and dealing with each part separately, but this doesn't seem to lead me anywhere.","['general-topology', 'differential-geometry', 'surfaces']"
2299275,Zeroes of derivative of Weierstrass's elliptic function,"I'm asked to show that the Weierstrass's elliptic function $\wp: \mathbb{C}/\Gamma \rightarrow \mathbb{C}P^1$ has exactly 4 branch points. My problem is that I don't see why there are 4 branch points and not just 3. I looked at the zeroes of the derivative $\wp '$. Since $\wp '$ is doubly periodic and odd this implies that $\frac{w_1}{2}$, $\frac{w_2}{2}$ and $\frac{w_1+w_2}{2}$ are zeros of $\wp '$, where $w_1,w_2$ span $\Gamma$. But I know that an elliptic function has the same number of poles as it has zeros (where the order of the poles / zeroes matters). Since $\wp '$ has only one pole (of order 3) I know that the three zeros are all of order 1 and in particular there can't be a fourth zero. Where is my mistake?","['riemann-surfaces', 'complex-analysis']"
2299306,Probability that the number of different-colored cards in two decks is equal,"After googling a bit and filling up a couple pieces of scratch paper, I haven't found a way to prove my intuition of the solution to this problem. Take two normal identical decks of cards (52 each), combine them, and shuffle them randomly. Then cut the combined deck of 104 cards in half, giving you new decks A & B. 1) What is the probability that the number of red cards in deck A is equal the number of black cards in deck B? 2) How many cards would one have to check to ensure that those two numbers are equal? Say we call X: the number of red cards in deck A, X': the number of black cards in deck A, Y: the number of red cards in deck B, and Y': the number of black cards in deck B. For part 1, my intuition says that P(X == Y') = 1, since X is always equal to Y': X = 0    X' = 52   Y = 52   Y' = 0,
X = 1    X' = 51   Y = 51   Y' = 1,
...,
X = 51   X' = 1    Y = 1    Y' = 51,
X = 52   X' = 0    Y = 0    Y' = 52. And for part 2, my intuition says 52, because you couldn't know if you've seen all the cards of whichever color you're looking for in whichever deck you're looking through until you look at all the cards in that deck. So my ultimate question is twofold: is my intuition correct, and how would I prove those answers?
Does proving that P(X == Y') = 1 have something with a cdf and/or stats-related calculations, or could you just use an induction-ish (sort of like the above table) proof?","['statistics', 'proof-writing', 'probability']"
2299318,How to Prove that $(A ∪ B) \setminus (A ∩ B) = (A \setminus B) ∪ (B \setminus A)$,"Here is what I want to prove $$(\mathsf A \cup \mathsf B)\setminus(\mathsf A \cap \mathsf B)=(\mathsf A\setminus\mathsf B)\cup(\mathsf B\setminus\mathsf A)$$ And here is what I've got so far $$
\begin{align*}
(\mathsf A \cup \mathsf B)\setminus(\mathsf A \cap \mathsf B) &= (\mathsf A \cup \mathsf B)\cap(\mathsf A \cap \mathsf B)^\mathsf C \\
&=(\mathsf A \cup \mathsf B)\cap(\mathsf A^\mathsf C\cup\mathsf B^\mathsf C) \\
&=((\mathsf A \cup \mathsf B)\cap\mathsf A^\mathsf C)\cup((\mathsf A \cup \mathsf B)\cap\mathsf B^\mathsf C)
\end{align*}
$$ From this point on, I cannot figure out how to prove that the Left Hand Side (LHS) is equal to $(\mathsf A\setminus\mathsf B)\cup(\mathsf B\setminus\mathsf A)$","['elementary-set-theory', 'discrete-mathematics']"
2299345,Coordinate system vs ordered basis,"I have an issue with the definition of coordinate system in differential geometry vs the definition of coordinate system in linear algebra. The post is a bit long, but it's necessary so that I get my point across. Let $V$ be an $n$-dimensional normed space over the reals and equip $V$ with the topology that its norm induces. $V$ can be given a natural smooth structure, making it into a smooth $n$-manifold. Now, let $\{v_1, \dots, v_n\}$ be an ordered basis for $V$. Any $p \in V$ can be written as $p = c^i v_i$, where we are using Einstein notation. This means that $p$ has the coordinate representation $(c^1, \dots, c^n)$, relative to the given basis. This seems to define a coordinate system - not in the usual differential geometric sense, but if $V = \mathbb{R}^n$ then a basis gives us coordinate axes. However, we also have the usual definition of a coordinate system about $p$: The ordered pair $(U, \varphi)$ is a coordinate system about $p$ if $U \ni p$ and $U$ is open and $\varphi$ is a diffeomorphism onto some open subset of $\mathbb{R}^n$. This allows us to naturally identify $p$ with $(x^1(p), \dots, x^n(p))$ where the $x^i$ are the local coordinates of $\varphi$. So it seems that the two definitions of coordinate systems above give us the same thing: a way to uniquely identify $p$ with a point of $\mathbb{R}^n$, which is precisely what we want. However, the two definitions are not equivalent. Let me demonstrate: Given that $V$ is a finite-dimensional vector space, I will make the usual identification of $V$ with $T_p V$ and just write $V$ instead. Similarly, even though $p \in V$, it will also be used interchangeably as both an element of $V$ as well as $T_p V$. Given a coordinate system $(U, \varphi)$, it induces a coordinate basis at $p$, and this is like a coordinate system in the first linear algebraic sense that I described. That's fine. In a differential geometric sense, $p$ is identified with $(x^1(p), \dots, x^n(p))$. In a linear algebraic sense, we can write $p = p^i \frac{\partial}{\partial x^i}$ where $p^i = p(x^i)$. The coordinate representation of $p$, in the linear algebraic sense is then $(p^1, \dots, p^n)$ which is naturally identified with $(x^1(p), \dots, x^n(p))$. So whether we are using the differential geometric or linear algebraic definition of coordinate system, we get the same identification $p \leftrightarrow (x^1(p), \dots, x^n(p))$. However, the two definitions gave the same identification only because we used a coordinate basis. From what I have previously read (I don't remember the source, but I am sure that you more knowledgeable posters will be aware of this), not every basis for $V$ is a coordinate basis. That is, there could be an ordered basis $\{w_1, \dots, w_n\}$ such that no coordinate chart induces it. This bothers me, because by giving an ordered basis $\{w_1, \dots, w_n\}$, we indeed do have a coordinate system - every element of $V$ has a coordinate representation relative to the basis, BUT, this basis may not necessarily give rise to a coordinate chart. So now we have a coordinate system in one sense (the linear algebraic) but we do not have an equivalent coordinate system in the differential geometric sense. This bothers me a lot! The differential geometric definition of coordinate system was conceived of for when there is no natural  or useful linear algebraic definition of coordinate system: That is, for when we cannot identify a manifold with its tangent space. But in the case when the manifold is a finite dimensional normed space, we can identify the manifold with its tangent space (for example, $\mathbb{R}^n \leftrightarrow T_p \mathbb{R}^n$), and so in this case, both definitions should be equivalent, i.e. give the same coordinate system, but they do not, as I just demonstrated. How do I reconcile this?","['differential-geometry', 'differential-topology']"
2299355,How to measure the information content of a function?,"I would say that the function $f(x)=x^2$ has more ""information"" than the function $f(x)=1$. Is this true, and if so, is there a way to measure the information content of a function?","['information-theory', 'functions']"
2299357,Dirac measures are extreme points of unit ball of $C(K)^*$.,"I've seen proofs that Dirac measures are the extreme points of probability measures, but how do we prove it for general complex Borel measures with total variation norm 1? I only want to know why they're in the set of all extreme points.","['functional-analysis', 'real-analysis', 'measure-theory']"
2299382,"Is the function $f(x, y)= \frac{x^3}{x³+y^2}$ continuous?","I want to know if the function is continuous. $$f(x,y)=\begin{cases}\frac{x^3}{x^3+y^2},&(x,y)\neq(0,0)\\0,&(x,y)=(0,0)\end{cases}$$ First of all, I evaluate the limit by putting the point $(0,0)$ into the function: $$\lim_{(x,y)\to (0,0)}\frac{x^3}{x^3+y^2}$$
? The result is 0/0. Then, I used the path rule. The first path: $y=x$ The result is $0$. The second path is $y=x^2$. The result is $1$. The third path is $y=0$. The result is $1$. Are my result correct? The book says that this limit exists.","['multivariable-calculus', 'continuity', 'calculus']"
2299394,"$\{\{\{∅\}\}\} ⊂ \{∅, \{∅\}\}$ true or false?","I know $\{\{∅\}\} ⊂ \{∅, \{∅\}\}$ is true because the right hand side contains the left hand side and another element, at least according to the text I'm going by so wouldn't that make $\{\{\{∅\}\}\} ⊂ \{∅, \{∅\}\}$ true?","['elementary-set-theory', 'discrete-mathematics']"
2299400,"Finding MLE for uniform distribution $U[\theta_1 - \theta_2, \theta_1 + \theta_2]$","Problem statement: Let $X_1, \ldots, X_n$ be a random sample from a uniform distribution $U[\theta_1 - \theta_2, \theta_1 + \theta_2]$, with $\theta_1 \in \mathbb{R}$ and $\theta_2 > 0$. Determine the MLE for $(\theta_1, \theta_2)$. My attempt: The density function for $X$ is $$f_X(x) = \frac{1}{2 \theta_2} 1_{[\theta_1 - \theta_2, \theta_1 + \theta_2]} (x). $$ Then the likelihood function is $$ L(\theta_1, \theta_2; \vec{x}) = \frac{1}{(2 \theta_2)^n} \prod_{i=1}^n 1_{[\theta_1 - \theta_2, \theta_1 + \theta_2]} (x_i). $$ So I need to minimize $$ (2 \theta_2)^n$$ subject to the contraint $$ \theta_1 - \theta_2 \leq x_{(1)} \leq x_{(n)} \leq \theta_1 + \theta_2.$$ From the left most inequality I have $\theta_1 - x_{(1)} \leq \theta_2$. From the right most inequality I have $x_{(n)} - \theta_1 \leq \theta_2$. Adding these I get $x_{(n)} - x_{(1)} \leq 2 \theta_2$. So I think an estimator for $\theta_2$ is $$ \hat{\theta}_2 = \frac{1}{2} ( x_{(n)} - x_{(1)}). $$ Is this reasoning correct? And also, how to find an estimator for $\theta_1$ from this? Thank you for any help!","['statistics', 'probability', 'statistical-inference']"
2299444,If the set of odd numbers is a subset of $\mathbb N$ then surely it is smaller than $\mathbb N$,"I have been studying Cantor's theorem, and I follow entirely that the set of natural numbers $\mathbb{N}$ is countable, as is the set of odd numbers (let's call it $\mathbb{O}$). I understand his proof that there is a correspondence between the two sets and feel like I could accept that they therefore have the same cardinality based on that ... but ... hold on ... We know that $\mathbb{O}$ is a subset of $\mathbb{N}$ right? $\mathbb{N}$ certainly contains all of the odd numbers. We also know that $\mathbb{N}$ contains numbers that are not odd. So if $\mathbb{N}$ contains all of $\mathbb{O}$ and some other stuff as well then surely it would be totally justified to argue that $\mathbb{N}$ is larger than $\mathbb{O}$?","['infinity', 'elementary-set-theory']"
2299482,Is $c+Y$ lognormal?,"Let $Y$ be a lognormal random variable and let $c>0$ be a constant. Is $c+Y$ lognormal? My attempt: We need to check if $X=\log(c+Y)$ is a normal random variable. Let $F_X$ denote the cumulative distribution function of $X$. Since $Y$ is lognormal, $\log (Y)$ is a normal random variable. In particular this means that $Y>0$. $\begin{aligned}[t]
F_X(x)&=P\{X\le x\} \\
&=P\{\log(c+Y)\le x\} \\
&=P\{c+Y\le e^x\} \\
&=P\{Y\le e^x-c\}
\end{aligned}$ We have already noted that $Y>0$. So, if $e^x-c$ is negative, $P\{Y\le e^x-c\}=0$. That is, $F_X(x)=0$ if $x<\log c$. But the cumulative distribution function of a normal random variable is always positive. So, $X$ is not a normal random variable. So, $c+Y$ is not lognormal. Is this correct? (I'm very new to probability.)",['probability']
2299484,Triangular distribution of a+b sums for rationals a/b of bounded height,"Let $a/b$ be a rational in $(0,1)$ expressed in lowest terms.
The height of $a/b$ is $\max \{a,b\}$.
For each rational in $(0,1)$ of height $\le h$, form the sum $a+b$.
So, for example, here are the rationals of height $\le 6$
and their sums:
\begin{array}{ccccccccccc}
 \frac{1}{6} & \frac{1}{5} &
   \frac{1}{4} & \frac{1}{3} &
   \frac{2}{5} & \frac{1}{2} &
   \frac{3}{5} & \frac{2}{3} &
   \frac{3}{4} & \frac{4}{5} &
   \frac{5}{6} \\
 7 & 6 & 5 & 4 & 7 & 3 & 8 & 5
   & 7 & 9 & 11 \\
\end{array}
Now form a histogram of these sums. So above, the bin for $3$ gets $1$ count
because only $\frac{1}{2}$ leads to $3$, but the bin for $7$ gets a count
of $3$ because each of $\{ \frac{1}{6}, \frac{2}{5}, \frac{3}{4} \}$ sum to $7$. Here is the histogram for $h \le 24$: You can see the bin for $3$ still has a count of $1$, the
bin for $47$ has a count of $1$ for $\frac{23}{24}$, and the bin
for $46$ is empty. The tallest bin is for $23$, whose sum is
achieved by $11$ fractions: $\{ \frac{1}{22}, \frac{2}{21}, \ldots, \frac{11}{12} \}$. Here is the histogram for $h \le 256$: My question is: What explains the features of this plot. I would appreciate explanations of some of the structure that seems to be
emerging in this plot,
from the left-right symmetry to more subtle features.
Perhaps I am hallucinating structure where there
is none, but it seems one can discern a series of nested triangles that roughly
demarcate regions of differing density, something like this:","['number-theory', 'prime-numbers', 'rational-numbers']"
2299588,"How many natural numbers less than 1000 are divisible by 2, 3, or 5?","For the purposes of this problem, 0 is an natural number, and 0 is divisible by all natural numbers. I think that this is the answer but I'm not sure. Natural numbers divisible by $2 = 1000/2 =500$ natural numbers divisible by $3 = 1000/3=333$ natural numbers divisible by $5 = 1000/5=200$ natural numbers divisble by 2 and $3 =1000/(2*3)=166$ natural numbers divisible by 2 and $5 = 1000/(2*5)=100$ natural numbers divisble by 3 and $5 = 1000/(3*5)=66$ natural numbers divisble by 2 , 3 or $5 = 1000/(2*3*5)=33 + 1$(if we include 0) Natural number less than 1000 divisible by 2, 3 or $5 500+333+200 - (166 +100 + 66) + 34= 735$ I'm a little confused, since the question says how many natural numbers less than 1000 are divisible by 2,3, or 5. But I counted 1000 as a number divisible by 2, even though the question states that the number being divided must be less 1000, similarly $1000/10$ and $1000/5$ should I include these numbers as dividends?
Also should I include 0 since it is a number that is divisible by 2,3, or 5.","['inclusion-exclusion', 'discrete-mathematics']"
2299604,Why are elliptic curves important for elementary number theory?,"Elliptic curves (or even Abelian varieties) are useful tools for many high-falutin' reasons They can be used to construct $\ell$-adic Galois representations One can find automorphic forms from an elliptic curve fairly easily There is a nice way to find formal group laws using elliptic curves Families of elliptic curves provide nice geometric examples for various cohomological phenomena But, I have yet to learn why they they are important from an elementary number-theoretic perspective. Why did early mathematicians ""run into"" elliptic curves and abelian varieties to begin with and how are they useful for elementary number theory?","['number-theory', 'elliptic-curves', 'abelian-varieties', 'elementary-number-theory']"
2299655,Ways to count lattice paths with backtracking,"I have been studying lattice paths, and I stumbled across this problem. Given a rectangular grid with (0,0) and (m,n) as its corners, find the number paths possible from (0,0) to (m,n). There are several rules, of course. The object must stay within the boundaries of the grid, inclusive. The object must go either up one unit, or to the right one unit for each step. However ... The object may choose to go down one unit once in the entire path, or not at all. I started this problem with the formula: C(n,k) = Choose k from n combinations Number of paths = [number of paths without going down] + [number of path with going down] Number of paths = C(m + n, n) + n * C(m + n + 2, m) Is this the correct formula? Part 2: What would the formula be if object would not be allowed to land on an arbitrary point, (i, j), if given that 0 < i < m and 0 < j < n?","['combinatorics', 'discrete-mathematics']"
2299658,Local rings are not 'really local' in Zariski topology,"My professor made a comment the ""Local rings are not really local in the Zariski topology (on say $\mathbb{C}^{n}$). Thus we take completions of local rings at all points of a smooth variety which turn out to be the same. However in the classical topology local rings are local because Zariski topology has very large open sets."" He does not expect us to understand what completions are, but I donot even intuitively understand the first part of the statement. Can someone make the statement precise and tell exactly what he means by 'local rings not 'really local' in Zariski topology, however they are in normal topology' ?",['algebraic-geometry']
2299682,Baby Rudin Exercise 2.9: Do $E$ and $\bar{E}$ always have same interiors?,"The question asks: Do $E$ and $\bar E$ always have same interiors? Here, $\bar E$ denotes the closure of $E$. That is, $\bar E = E \cup E'$, where $E'$ denotes the set of limit points of $E$. Also, let $E^\circ$ denote the interior of $E$. My attempt at proof: Answer. Yes Clearly, $E^\circ \subseteq (\bar E)^\circ$. Therefore, we need to prove only that $(\bar E)^\circ \subseteq E^\circ$. If $(\bar E)^\circ$ is empty, then $E^\circ$ is also empty. Therefore, assume that $(\bar E)^\circ$ is non-empty. Consider a point $p \in (\overline E)^\circ$. For some $r > 0$, we have that for any $0 < r' \le r$, $N_{r'}(p) \subseteq \bar E$. Here, $N_a(p)$ denotes the (open) neighborhood of $p$. We need to show that $p \in E^\circ$. That is, there exists some $\rho > 0$ such that $N_\rho(p) \subseteq E$. Therefore, assume for contradiction that for all $\rho > 0$, there exists a point $p' \in N_\rho(p)$ such that $p' \not \in E$. In particular, for any $0 < \rho \le r$, there exists a $p' \in N_\rho(p)$, but $p' \not \in E$. Therefore, $N_\rho(p) \subseteq E'$. In particular, $p \in E'$, i.e. $p$ is a limit point of $E'$. However, this is a contradiction because for every neighborhood of a  limit point of $E$ must contain a point of $E$. But the result is not true as shown by the following example. $E = \mathbb Q \subset \mathbb R$. Here, $\mathbb Q^\circ = \emptyset$, but $\bar{\mathbb{Q}} = \mathbb R$. So what is wrong with my proof? I thought for a while (even considering the same example!), and I can't find my mistake.","['fake-proofs', 'self-learning', 'real-analysis', 'real-numbers']"
2299683,Direct proof that$ Var(cX) = c^2Var(X)$,"I'm trying to prove that $Var(cX) = c^2Var(X)$ and this is what I have so far: $Var(cX) = E((cX - \mu)^2)$ $ = E(c^2X^2 - 2cX\mu + \mu^2)$ $ = c^2E(X)-2c\mu E(X)+\mu^2$ by linearity of expectation $ = c^2E(X)-2c\mu^2+\mu^2$ by $E(X) =\mu$ Here, I am stuck, I know that I have a $c^2$ now but I'm having trouble making the right side of $c^2$ equal to $Var(X)$. EDIT: With the help of below commenters, this is the correct proof. $Var(cX) = E((cX - c\mu)^2)$ $ = E(c^2(X^2-2x\mu+\mu^2))$ $ = c^2E(X^2-2x\mu+\mu^2)$ by linearity $=c^2E((X -\mu)^2)$ $= c^2Var(X)$","['statistics', 'proof-writing', 'variance']"
2299716,A Coin is Tossed Until Heads is Encountered n number of Times,"Let $C$ be a coin whose probability for showing heads is $p$. Suppose we have an experiment in which we toss the coin till we see heads for the first time. Let's describe this experiment formally. The sample space $\Omega$ here is the following set $\Omega=\{H, TH, TTH, \ldots \}=\{T^nH: n\geq 0\}$. We assign a probabilty $P:\Omega\to \mathbf R$ as $P(T^nH)=(1-p)^n p$. Here's my problem . In order for this to genuinely be a probability measure on $\Omega$, we must have $\sum_{n=0}^\infty P(T^nH)=1$. And an elementary calculation shows that this is indeed the case. But is there a more conceptual reason as to why is this happening. Defining $P(T^nH)=(1-p)^n p$ is natural because when we toss a coin in succession $n+1$ times, the probability that tails shows up for the first $n$ times and then heads shows up at the end ""must be"" $(1-p)^np$, for the tosses are ""independent"". But where, in which probability space, is this independence being talked about? More generally, if we had a more complicated experiment, where the coin $C$ was tossed till heads shows for a total of $n$ times, then checking that $P$, defined in the similar spirit as for $n=1$, is indeed a probability measure would be quite cumbersome. One can of course think of more involved scenarios. So basically we want to build a new probability space out of the simple space $\{H, T\}$ with probability measure $P(H)=p$ and $P(T)=1-p$. But is there some conceptual framework which lets us build the spaces above, and more, without the bare hands cumbersome approach? Thank you.",['probability-theory']
2299760,Definitions of E(X^2) - expected value of r.v. X squared,"My book has two examples of computing $E(X^2)$ Let X be the score on a fair die $E(X^2) = \frac{1}{6}(1^2 + 2^2+3^2+4^2+5^2+6^2)$ Let X be the number of fixed points in a permutation $E(X^2)=\sum_i^nE(X_i)^2 + \sum_{i\neq j}E(X_iX_j)$ I understand that the second one comes from the fact that $X = X_1+X_2+...X_n$ so $X^2 = (X = X_1+X_2+...X_n)(X = X_1+X_2+...X_n)$ which is where the two summations come from. The part I don't understand is how the two methods relate. Can we express the score on a fair die in the form of the second definition, or is the second definition reserved only for indicator r.v.'s ?","['probability-theory', 'expectation', 'statistics']"
2299777,How to evaluate the closed form of $I=\int_{0}^{1}\ln[\sin(\pi x)]\ln^2[2\sin(\pi x)]\mathrm dx?$,Evaluate the closed from of: $$I=\int_{0}^{1}\ln[\sin(\pi x)]\ln^2[2\sin(\pi x)]\mathrm dx$$ We have the following: $$\int_{0}^{1}\ln^2[2\sin(\pi x)]\mathrm dx={\zeta(2)\over 2}\tag2$$ $$\int_{0}^{1}\ln[\sin(\pi x)]\mathrm dx=-\ln(2)\tag3$$ Approximately $$I\approx-{\zeta(2)\over \ln (2)}$$ Indefinite integral: $u=\sin(\pi x)\implies du=\pi\cos(\pi x) dx$ $${1\over \pi}\int{\ln(u)\ln^2(2u)\over \sqrt{1-u^2}}\mathrm du\tag4$$ $$(1-x)^{-1/2}=\sum_{k=0}^{\infty}{(2k-1)!!\over (2k)!!}x^k$$ $${1\over \pi}\sum_{k=0}^{\infty}{(2k-1)!!\over (2k)!!}\int{ u^{2k} \ln(u)\ln^2(2u)}\mathrm du\tag5$$,"['integration', 'definite-integrals', 'calculus', 'closed-form']"
2299812,Big Omega with a plus/minus subscript,"I am reading an article that says $q(x)=\frac{M(x)}{\sqrt{x}}=\Omega_{\pm}\{{1}\}$, where M(x) is the Mertens function.  What is the difference between $\Omega_{\pm}$ and $\Omega$?","['number-theory', 'asymptotics', 'notation', 'discrete-mathematics']"
2299814,Number of possibilities for n persons at m tables with at least 5 persons per table,"given are n persons and m tables, with $ n \geq 5m $. How many possibilities are there, to put the persons to the m tables, so that at each table are at least 5 persons?
The arrangement of the persons at a table does not matter. Also the tables are not distinguishable. I thought about the second Stirling number.
As it describes the number of possibilities for k not empty sets from n elements, so that every element is in exactly one set.
But with this I do not take into account, that I need at least 5 elements in each set. How can I fix this or is there an approach which fits better to this problem? Kind regards,
Niklas","['permutations', 'combinatorics', 'stirling-numbers']"
2299830,Is the commutator subgroup of a commutator subgroup itself?,"Let $G$ be a multiplicative group. The commutator of $a,b\in G$ is the element $aba^{-1}b^{-1}$. (Now $a,b\in G$ commute iff their commutator is the identity.) The commutator subgroup of $G$, denoted $[G,G]$, is the subgroup generated by all commutators of all elements. Example. If $G$ is abelian, then every commutator is the identity, so the commutator subgroup $[G,G]$ is the trivial group. (The commutator subgroup is used to construct the abelianization of $G$ as the quotient $G/[G,G]$, which I've encountered in learning homology.) Now, an arbitrary element of $[G,G]$ need not be itself a commutator. So, is the commutator subgroup of $[G,G]$ again all of $[G,G]$? If not, is there an easy characterizations of groups $G$ for which the commutator subgroup of $[G,G]$ is again $[G,G]$?",['group-theory']
2299863,Average of ratios - I don't get it,"I'm calculating ratios from paired samples and there is a point I don't understand.
Supposed that I measured the values of 2 paired samples: A and B, and then I calculate the ratios from those values. Ratio 1: $\frac{A}{B} = 0.5$ Ratio 2: $\frac{A}{B} = 2.0$ Normally one would calculate the average $ratio = \frac{(Ratio 1 + Ratio 2)}{2} = 1.25$. Then the conclusion would be: the value of A is 1.25 times higher than that of B. But, the ratios can be understood as: Ratio 1 = 0.5 --> the value of B is double the value of A Ratio 2 = 2 --> the value of A is double the value of B Then, the average ratio of A and B should be equal 1. Does that make sense to you? Where is the flaw? Thanks all,","['algebra-precalculus', 'statistics', 'average']"
2299869,Question about two idempotent symmetric matrices,"Let $A$ and $B$ be two idempotent symmetric matrices such that
the difference matrix $A-B$ is a positive semidefinite matrix. The question is to show that $$AB=BA=B.$$ I first thought that the problem is about simultaneous diagonalization, but I don't know how to proceed.","['matrices', 'positive-definite', 'statistics', 'idempotents', 'linear-algebra']"
2299881,"Neglect $1/2 \ln(2\pi n)$ in Stirlings approximation formula, but this term is not bounded or gets smaller, but larger","One form of Stirlings approximation reads
$$
 \ln(n!) \approx n\ln(n) - n + \frac{1}{2} \ln(2\pi n)
$$
another
$$
 \ln(n!) \approx n\ln n - n.
$$
But thats makes me wonder, for the difference of both is $\frac{1}{2}\ln(2\pi n)$, which gets arbitrary large (surely very slow, but it is not bounded...), so the error between both approximations gets larger and larger for $n \to \infty$, but it is not the point of an approximation formula to give a lower error for $n \to \infty$? So, in what sense is the second approximation valid, when the difference between both terms nonetheless becomes larger and larger for $n\to \infty$? Could anybody please explain this to me?","['real-analysis', 'analytic-number-theory', 'factorial', 'analysis', 'approximation']"
2299904,Leverage points in linear regression,"From the wikipedia , leverage of a point is defined as the measure of how far away the independent variable values of an observation are from those of the other observations. Mathematically for point(observation) $x_i$, it is given by $h_{ii}=x_i^T(X^TX)^{-1}x_i$, where rows of matrix $X \in R^{n*d}$ contains points. Now my question is how does the formula leads to the interpretation given in first line. This is how I see it, If we calculate the covariance matrix from the observation to find mahalanobis type distance metric we have covariance as $(X^TX-\frac{1}{n^2}X^T \mathbf{1} X)$, ( note rows of X are our points) where $\mu^T=\frac{1}{n}[1,1...,1]X$ and $\mathbf{1} \in R^{n*n}$ is matrix of all $1$'s. And now if we use this as distance metric shouldn't the leverage be defined as $\hat{h_{ii}}=(x_i-\mu)^T(X^TX-\frac{1}{n^2}X^T \mathbf{1} X)^{-1}(x_i-\mu)$ ? How does one come up with the interpretation? Also I am curious what properties of colspace of $X$ does leverage score(leverage of each point) help us understand? Any help, comments, hints are greatly appreciated. Thanks.","['linear-regression', 'statistics', 'numerical-linear-algebra']"
2299931,Simulate a 12-sided fair die with a 10-sided fair die,"If I have a single 10-sided fair die and I want to simulate a 12-sided fair die, what would be the most efficient way to do so? Thus, we have to ensure that the likelihood of each result is equally likely.","['probability-theory', 'dice']"
2299994,A infinite series expansion for $e^e$.,"How can $e^e$ be expressed in an infinite series with as much simplification as possible. I wrote the series of $e^x$ by keeping $x$ as $e$ and from there I also expanded every $e$ in this expansion now I was thing about expanding it further by binomial theorem but I am not able to understand how can i use binomial theorem here and how much can this be simplified in another words I am trying to write this series as simple as expansion of $e$ , is it possible and how it can be done. Any help will be highly appreciated , thanks in advance.","['algebra-precalculus', 'sequences-and-series']"
2300001,"Find limit $a_{n + 1} = \int_{0}^{a_n}(1 + \frac{1}{4} \cos^{2n + 1} t)dt,$","Find the limit of the sequence: $$a_{n + 1} = \int_{0}^{a_n}(1 + \frac{1}{4} \cos^{2n + 1} t)dt,$$ such that $a_0 \in (0, 2 \pi)$ That was one of the tasks in the Olympiad . Here is my approach. First, I wanted to simplify the integral: $\int_{0}^{a_n}(1 + \frac{1}{4} \cos^{2n + 1} t)dt = \int_{0}^{a_n}(dt) +  \frac{1}{4} \int_{0}^{a_n} \cos^{2n + 1} (t) dt$ That leads to the following relation: $$a_{n + 1} = a_n + \frac{1}{4} \int_{0}^{a_n} \cos^{2n + 1} (t) dt$$ Now, there is a $\cos t$ with some power which reminded me of the standart integral $\int \cos^n(x) dx$. We can find a recursive formula for it in the following way: $I_n = \int \cos^n(x) dx = \int \cos(x) \cos^{n - 1}(x) dx = \sin x \cos^{n - 1}x - (n - 1)\int \sin(x) \cos^{n - 2}(x) (- \sin (x)) dx.$ This leads to $I_n = \sin x \cos^{n - 1}x + (n - 1) I_{n - 2} - (n - 1) I_n$ And final recurrence relation is
$$I_n = \frac{1}{n} \sin x \cos^{n - 1}x + \frac{n - 1}{n} I_{n - 2}$$ For a long time I am trying to make a connection between the original integral $\int_{0}^{a_n} \cos^{2n + 1} (t) dt$ and this recurrence relation, but I have failed to come up with anything meaningful at the moment. Well, I guess we can just plug in $2n + 1$ instead of $n$ and we get $$I_{2n + 1} = \frac{1}{2n + 1} \sin x \cos^{2n}x + \frac{2n}{2n + 1} I_{2n - 1}$$ Ok, now if we try to evaluate this as definite integral we should get $I_{2n + 1}(a_n) - I_{2n + 1}(0) = (\frac{1}{2n + 1} \sin a_n \cos^{2n}a_n + \frac{2n}{2n + 1} I_{2n - 1}(a_n)) - (0 + \frac{2n}{2n + 1} I_{2n - 1}(0))$ $I_{2n + 1}(a_n) - I_{2n + 1}(0) = \frac{1}{2n + 1} \sin a_n \cos^{2n}a_n + \frac{2n}{2n + 1} I_{2n - 1}(a_n) - \frac{2n}{2n + 1} I_{2n - 1}(0).$ So, 
$$\frac{1}{4} \int_{0}^{a_n} \cos^{2n + 1} (t) dt = \frac{1}{4(2n + 1)} \sin a_n \cos^{2n}a_n + \frac{2n}{4(2n + 1)} \big[ I_{2n - 1}(a_n) - I_{2n - 1}(0) \big] $$ $$\frac{1}{4} \int_{0}^{a_n} \cos^{2n + 1} (t) dt = \frac{1}{4(2n + 1)} \sin a_n \cos^{2n}a_n + \frac{2n}{4(2n + 1)} \big[ I_{2n - 1}(a_n) - \cos a_0 \big] $$ I would appreciate any help if you provide me with some insights or clues on how to proceed.","['recurrence-relations', 'limits', 'calculus', 'integration', 'sequences-and-series']"
2300061,Fibonacci sequence starting with any pair of numbers,"Is there a formula for a Fibonacci sequence starting with any pair? I know there is a formula for a Fibonacci sequence starting with $1, b$ but what if I want to start with $a, b$ as $3,4$ for example? Thank you","['number-theory', 'recurrence-relations', 'sequences-and-series']"
2300065,Is it possible to calculate trigonometric functions with the imaginary exponential,By Eulers identity $e^{i \theta}=\cos(\theta)+i \sin(\theta)$ sine and cosine can be written in exponential form as $\sin(\theta)=\frac {e^{i \theta}-e^{-i \theta}}{2i}$ and $\cos(\theta)=\frac {e^{i \theta}+e^{-i \theta}}{2}$. Could you calculate specific values of the trigonometric function with these formulae? My guess is that the complex exponential can only be calculated using Euler's identity so you have to know the values of sine / cosine to begin with. Is there any method to calculate the value of sine / cosine using the identity above? Is there any reason why it isn't (is?) possible?,"['complex-analysis', 'trigonometry', 'complex-numbers']"
2300083,Fully-ordered set and transfinite mathematical induction,"Let $A$ be a fully-ordered class and let $P(x)$ be a statement which is either true or false for each element $x\in A$. Suppose that following condition holds: Ind. If $P(y)$ is true for every $y<x$, then $P(x)$ is true. Then, $P(x)$ is true for every element $x \in A$. Statement: If $A$ satisfies the above things, then $A$ is well-ordered . I want to prove the statement, but I'm lost.
Suppose A is a fully-ordered set but not well-ordered, and A also satisfies the above things. Since A is not well-ordered, $\exists B\subseteq A$ such that $B$ does not have a least element. I want to show this leads to a contradiction.",['elementary-set-theory']
2300085,What's a visual proof for the expansion of $\tan(A+B)$ and $\tan(A-B)$?,I am looking for a visual proof of the following trig identity: $$\tan(A+B) = \frac{\tan A + \tan B}{1 - \tan A\tan B}.$$ Similarly for $\tan(A-B)$.,"['algebra-precalculus', 'trigonometry']"
2300143,"Is the relation $R = \{ ( 1,2 ) \}$ on $A = \{ 1,2,3,4 \}$ not reflexive, not symmetric, antisymmetric and transitive?","Given $R = \{ ( 1,2 ) \}$ over $A = \{ 1,2,3,4 \}$: $R$ is not reflexive because there's no $(1,1)$ and $(2,2)$. $R$ is not symmetric because there isn't $( 2,1 )$. $R$ is anti-symmetric because there isn't $( 2,1 )$. And $R$ is transitive because there isn't a $(2,x)$ element in $R$. If  $(1,2) \in R \land (2,x) \in R$ is false, then $(1,2) \in R \land (2,x) \in R \to (1,x) \in R$ is true, and therefore $R$ is transitive. Is this correct?","['relations', 'solution-verification', 'discrete-mathematics']"
2300149,"Show that $\operatorname{Hom}_{R} (R,M) \cong M$","Let $R$ be a commutative ring with unit and $M$ a right $R$ -module. Consider the assignment $\varphi: \operatorname{Hom}_{R} (R,M) \rightarrow M$ , $f \mapsto \varphi(f) = f(1)$ . Show that $\varphi$ is an isomorphism. My approach: We have to prove $\varphi$ is a morphism, then $\varphi$ is a injection, surjection, hence $\varphi$ is an isomorphism. $\forall f,g \in \operatorname{Hom}_{R} (R,M)$ $\varphi(fg) = (fg)(1) = f(1)g(1) = \varphi(f) \varphi(g)$ $\Rightarrow \varphi$ is a morphism $\forall f,g \in \operatorname{Hom}_{R} (R,M)$ $\varphi(f) = \varphi(g) \Rightarrow f(1) = g(1) \Rightarrow f = g$ $\Rightarrow \varphi$ is injective $\Rightarrow \varphi$ is a homomorphism How can I prove $\varphi$ is surjective to conclude $\varphi$ is an isomorphism? Sorry for my poor English.","['abstract-algebra', 'modules']"
2300157,Diameter cutting x Center mass,"I'm trying to set the ratio between the variation of the diameter cutting in the region lower a sphere with respect to distance from the center of mass with the center of the radius of the sphere. For example, if the diameter is zero the center of mass is zero. If the diameter lower is equal to the diameter of the sphere, the Center of mass is $1.875$. I have this equation, but this is relative to $H$. Using trigonometry could find this reason. But was thinking to have a answer in terms of integration or derivation. I wanted to understand how was obtained the above equation. I believe that has been by integration. Something like this: Equation","['derivatives', 'integration']"
2300165,Defining the square root of $z$ squared and determining the location of branch cuts,"I am asked the following: For $\epsilon > 0$, we define
    $$ \sqrt{z^2} = \lim_{\epsilon \to 0} \sqrt{z^2 + \epsilon^2}\,, $$
    where the principle value square root is used on the right-hand side.
    Determine the location of the branch cuts and show that $\sqrt{z^2} = \text{sign}(\text{Re } z) z$ I have tried the following. Let $\epsilon > 0$ be given and l et $z-i\epsilon = r_1 e^{i\theta_1}$ and $z+i\epsilon = r_2 e^{i\theta_2}$.
I know we can write 
$$f_\epsilon(z) := \sqrt{z^2 + \epsilon^2} = \sqrt{(z-i\epsilon)(z+i\epsilon)} = \sqrt{r_1r_2} e^{i(\theta_1 + \theta_2)/2}\,.$$
I see that the branch points are $i\epsilon$ and $-i\epsilon$.
Now, following the reasoning done in this StackExchange question and this handout, we can argue that $[-i\epsilon, i\epsilon]$ would be a sufficient branch cut to make $f_\epsilon(z)$ single-valued. The book defines the principle value square root by a branch cut along the negative real axis, corresponding to $\sqrt 1 = 1$. This means $\sqrt z = \sqrt r e^{\theta i / 2}$ where $\theta \in (-\pi, \pi]$, the principle value of the argument, i.e. $\text{Arg } z$. In the given defition, the principle value square root is used, therefore; $\theta_1, \theta_2 \in (-\pi, \pi]$. Does this mean that, for example, reasoning about encircling $z = i\epsilon$ (and not $z = -i\epsilon$), as done in mentioned StackExchange question;
$$\sqrt{r_1}e^{i(\theta_1+2\pi)/2} = \sqrt{r_1}e^{i\theta_1/2}e^{\pi i} = -\sqrt{r_1}e^{i\theta_1/2}\,,$$
is not permitted by the bounds of $\theta_1$?
I'm not quite sure whether this means I am force to make the branch cuts $[i\epsilon, \infty)$ and $[-i\epsilon, -\infty)$. As for the follow-up question; $\sqrt{z^2} = \text{sign}(\text{Re } z) z$, I have tried writing it as follows:
$$
\begin{align*}
\sqrt{z^2} &= e^{\log(z^2)/2} \\
&= e^{\frac{1}{2}\left( \ln |z|^2 + i \text{Arg} (z^2) \right)} \\
&= |z|e^{i \text{Arg} (z^2)}\,.
\end{align*}
$$
This means I have to show $e^{i \text{Arg} (z^2)} = \text{sign}(\text{Re } z)e^{i \text{Arg} z}$, which I've been unable to do thus far.","['radicals', 'complex-analysis', 'branch-points', 'branch-cuts']"
2300172,Geometric series convergence in the p-adic numbers,"I am not satisfied with my understanding of this type of question: let $a \in \mathbb Q$ , for which primes p does the series $\sum_{k = 0}^{\infty} a^k $ converge in the p-adic numbers $\mathbb Z_p$ ? Find the sum of the series in each case. Let's just say $a = 15/7$ , then I understand that the sum converges for $p = 3$ and $p = 5$ since $|a|_3 = 1/3 < 1$ and $|a|_5 = 1/5 < 1$ But when the sum converges isn't it always just $\sum_{k=0}^{\infty} \frac{15}{7} = \frac{1}{1-\frac{15}{7}} = -\frac{7}{8}$ ? I would like someone to confirm or deny this assertion.","['number-theory', 'p-adic-number-theory']"
2300206,"How many numbers less than $m$ and relatively prime to $n$, where $m>n$?","Let $m$ and $n$ be two integers such that $m>n$. Then find the number of integers less than $m$ and relatively prime to $n$. I had come across a problem of this type with specific values for $m$ and $n$, unfortunately, the values I don't remember anymore. So I asked this general question. How to solve this type of question? My thoughts are that we need to count the numbers. So we can count the number of integers less than $m$ and relatively prime to $m$ using Euler's totient function . Now among those numbers, also belongs the numbers which are relatively prime to $n$. We can also find the numbers less than $n$ and relatively prime to $n$. That will give a rough estimation. But how do we know about the actual number of such integers? Can anybody help me with this? Thanks.","['number-theory', 'coprime', 'totient-function']"
2300220,Funny(?) Probability Problem [duplicate],"This question already has answers here : Famous puzzle: Girl/Boy proportion problem (Sum of infinite series) (7 answers) Closed 7 years ago . So I ran accross the following problem today on a forum: ""In an attempt to reduce male birth rates, feminists have passed a law
  which forces families to stop having children after their first male
  child. After this law is passed, what is the expected ratio of male
  children to female children?"" It's unclear whether families are supposed to continue having children until their first male child or if they may stop at any earlier point, but let's assume the former. Let's also assume that everybody obeys the law, and that either sex has an equal chance of being born. I thought I had a simple solution, because the problem is logically equivalent to the following process: Generate N infinite random sequences of boys and girls Cut each sequence after the first occurrence of a boy Concatenate the results and measure the ratio of boys to girls This is equivalent to generating a random sequence of boys and girls by stopping at each boy but then continuing again (up to N times), so the only difference from a normal random sequence is that this sequence always ends with a boy. However, if N grows to infinity, it seems like this last element (which can never be reached) becomes irrelevant, so the ratio of boys and girls should be 1:1 like in a normal infinite random sequence. This seems perfectly logical to me, but a few people kept insisting that it is wrong, ranting about ""biased estimators"" and claiming that the real ratio will be biased in favor of females. Is my reasoning flawed? If so, why? [EDIT] Contrary to some suggestions, I don't think this question is a duplicate. It asks about the validity of a particular approach to solving the problem, not just for a solution.",['probability']
