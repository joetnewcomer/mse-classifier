question_id,title,body,tags
3363018,Equality of subsheaves of a sheaf,"Given two subsheaves $\mathcal{F}$ and $\mathcal{G}$ of a sheaf $\mathcal{O}$ on a topological space X, prove that $\mathcal{F}_p = \mathcal{G}_p$ for every p $\in$ X $\Rightarrow$ $\mathcal{F}(U) = \mathcal{G}(U)$ for every open $U \subseteq$ X I've been trying to prove this in context of showing that if $\mathcal{F}_p \xrightarrow{\phi_p} \mathcal{F'}_p \xrightarrow{\psi_p} \mathcal{F''_p}$ is exact (as a sequence of stalks) at $\mathcal{F'_p}$ then $\mathcal{F} \xrightarrow{\phi} \mathcal{F'} \xrightarrow{\psi} \mathcal{F''}$ is exact (as a sequence of sheaves) at $\mathcal{F'}$ . I got till the point where we have that $(Im(\phi))_p = (Ker(\psi))_p$ for every p in X and I want to use the above proposition to get that $Im(\phi) = Ker(\psi)$ as subsheaves of $\mathcal{F'}$ but I have no idea how to prove the proposition rigorously. Any help would be appreciated!","['algebraic-geometry', 'sheaf-theory']"
3363106,"Is ""ln"" (natural log) and ""log"" the same thing if used in this answer?","Find $x$ for $4^{x-4} = 7$ . Answer I got, using log, was ${\log(7)\over 2\log(2)} + 4$ but the actual answer was ${\ln(7)\over2\ln(2)} + 4$ I plugged both in my calculator and turns out both are the equivalent value. Anyways, is using either one of ln or log appropriate for this question? Obviously ln is when log has the base e, and log is when it has the base 10. Final question: How do I know when to use which? that is which of ln or log is used when solving a question?? For example, if a question asks to find $x$ for $e^x = 100$ , I will use $\ln$ since $\ln(e)$ cancels out. If a question asks to find $2^x = 64$ , i will use log since "" $e$ "" isn't present in the question. So is using either $\log$ or $\ln$ the same?","['algebra-precalculus', 'exponential-function', 'logarithms']"
3363107,Finding $f\in\mathbb{Q}[x]$ such that $f(\sqrt{2}+\sqrt{3})=\sqrt{2}$ and $\deg(f)\leq 3$. What's wrong with my approach?,"I'd like to find a polynomial $f(x) \in \mathbb{Q}[x]$ satisfying $$f(\sqrt{2}+\sqrt{3})=\sqrt{2}$$ and $\deg(f) \leq 3$ . What I've been trying is the following: Since $f(\sqrt{2}+\sqrt{3})=\sqrt{2}$ , then $f(\sqrt{2}+\sqrt{3})-\sqrt{2}=0$ . so think of $g(x)=f(x+\sqrt{3})-x$ as a polynomial over $\mathbb{Q}(\sqrt{3})$ . And I've already known that $x^2 -2$ is irreducible over $\mathbb{Q}(\sqrt{3})$ $g(x)$ has a $\sqrt{2}$ as a root of itself, $x^2 -2$ divides $g(x)$ in $\mathbb{Q}(\sqrt{3})[x]$ . $g(x)$ must be of the form $(x^2 -2)(ex+f)$ where $e, f \in  \mathbb{Q}(\sqrt{3})$ and also of the form $a(x+\sqrt{3})^3 +b(x+\sqrt{3})^2 +c(x+\sqrt{3}) +d -x$ , where $f(x)=ax^3 +bx^2 +cx+d \in \mathbb{Q}[x]$ . after comparing the coefficients of two polynomials, I found that $f(x)=\frac{1}{4}x^3-\frac{9}{4}x$ . But the actual polynomial is $\frac{1}{2}x^3-\frac{9}{2}x$ . There must be a flaw in the above reasoning. Where did I do a mistake? Could you point it out? Thank you.","['field-theory', 'abstract-algebra', 'irreducible-polynomials', 'polynomials']"
3363109,Finding $a$ and $b$ such that $\lim_{x\to25}\frac{\sqrt{x}-5}{ax+b} = \frac{1}{40}$,"So I am given the following question: Suppose $$\lim _{x\to 25}\frac{\sqrt{x}-5}{ax+b} = \frac{1}{40}$$ Find $a$ and $b$ . I'm not exactly what to do from here, but what I did was multiplying $$\frac{\sqrt{x}-5}{ax+b}$$ by its conjugate 
( $\frac{ax-b}{ax-b}$ ), resulting in $$\frac{100a}{625a^2-b^2} = \frac{1}{40}$$ Now I'm stuck and not sure what to do from here. Am I on a correct track?",['limits']
3363120,From $f(t)=o(\|t\|^2)$ to $\frac{\partial f}{\partial y}(t) = o (\|t\|)$,"Suppose that $f:\mathbb{R}^2\to\mathbb{R}$ satisfies $f(0,0)=0$ and $f(t)=o(\|t\|^2)$ , $t\to (0,0)$ . If the first and second partial derivatives all exist, is it true that $$\frac{\partial f}{\partial y}(t) = o (\|t\|)\, , \, t\to (0,0)$$ $$\frac{\partial f}{\partial x}(t) = o (\|t\|)\, , \, t\to (0,0)$$ ? My attempt Put $\phi(s)=f(su)$ where $u=(1,0)$ . Then we have $$\phi(s)=\phi(0)+\phi'(0) s + \frac12 \phi''(0)s^2 +o(s^2)\, , \, s\to 0$$ Via $f(t)=o(\|t\|^2)$ , $t\to (0,0)$ we have $\phi(s)=o(s^2)$ and hence $\phi(0)=\phi'(0)=\phi''(0)=0$ . Thus $$\frac{\partial f}{\partial x}(su)=o(s)\, , \, s\to 0$$ But I get confused whether we can say $$\frac{\partial f}{\partial x}(t) = o (\|t\|)\, , \, t\to (0,0)$$ Any hints? Thanks in advance! Added The reason why I asked this question is to try to find a possible method to solve the following problem . Suppose that $f:\mathbb{R}^n\to\mathbb{R}$ with $f(0)=0$ satisfying $$f(x)=o(\|x\|^m)\,,\,x\to0$$ If all the $m$ -order  partial derivatives exist, prove that the partial derivatives equal $0$ at the origin (or give a counterexample). Actually based on the answer that was put forward, it is certain that this method does not work. I also want to ask for some hints for the new posted question. Thanks in advance!","['partial-derivative', 'multivariable-calculus']"
3363126,specifying the restriction of a homeomorphism,"I have topological spaces $A$ and $B$ and subspaces $C \subset A$ and $D \subset B$ . Say I have homeomorphisms $h: C \to D$ and $f: A \to B$ . I also know that $f|C : C \to D$ is a homeomorphism. Using these facts, can I make a homeomorphism $g: A \to B$ such that $g|C = h$ ?","['general-topology', 'functions']"
3363141,Probability that a number passing the Fermat test is prime,"I'm studying a computer science textbook that has a section on the Fermat test as an example of a probabilistic method. Given a number $n$ , the Fermat test is stated as pick a random number $a < n$ . If $a^n \equiv a\pmod n$ , chances are good that $n$ is prime. Else, $n$ is certainly not prime. Excepting the Carmichael numbers, the book goes on to say: one can prove that, for any $n$ , the condition does not hold for most of the integers $a < n$ unless $n$ is prime. Thus, if $n$ passes the test for some random choice of $a$ , the chances are better than even that $n$ is prime. If $n$ passes the test for two random choices of a, the chances are better than 3 out of 4 that $n$ is prime. By running the test with more and more randomly chosen values of $a$ we can make the probability of error as small as we like. While I understand that repeating the test increases the probability of $n$ being prime, I do not understand how they arrived at those numbers : better than even - testing once, better than 3 out of 4 - testing twice. I can see that, for a random choice of $a$ , the first statement means $P(\text{passing the test}) \lt 0.5$ when $n$ is composite and equal to $1.0$ otherwise. How do I calculate the probability that $n$ is prime, given that the test passes $x$ times?","['conditional-probability', 'elementary-number-theory', 'primality-test', 'probability']"
3363187,When is rank(A+B)=rank(A)+rank(B) for matrices?,I know that for matrices $$\operatorname{rank}(A+B)\leq \operatorname{rank}(A) + \operatorname{rank}(B)$$ but when does the equality hold?,"['matrices', 'matrix-rank', 'linear-algebra']"
3363338,"Baby Rudin Chapter 6, Problem 15 : Strict inequality","Problem 15 in Chapter 6 of Principles of Mathematical Analysis by Walter Rudin: Suppose $f$ is real, continuously differentiable on $[a,b]$ , $f(a)=f(b)=0$ , and $\int_a^b f^2(x)dx = 1$ . Prove that $\int_a^b xf(x)f'(x)dx = -1/2$ $\int_a^b [f'(x)]^2dx \cdot \int_a^b x^2f^2(x)dx > 1/4$ I am able to prove the first part using integration by parts and the second using Cauchy-Schwarz. To get a strict inequality, I assumed that there was equality, in which case $xf(x) = \lambda f'(x)$ for all $x \in [a,b]$ for some constant $\lambda$ . I am unable to get a contradiction with this (note that Rudin has not introduced the exponential and logarithmic functions and so I don't want to integrate both sides directly).","['integration', 'stieltjes-integral', 'analysis', 'real-analysis']"
3363369,Which is the importance of Young’s tableaux in mathematics?,"I don’t know much about combinatorics, I’m just getting started on this. I want to know, why Young’s tableaux are important? and why it is important to relate them to matrices? 
Thank you very much.","['matrices', 'young-tableaux', 'combinatorics']"
3363391,"What is the size of a set of sets of the empty set {{}, {{}}, {{{}}}}?","What is the size of a set of sets of the empty set {{}, {{}}, {{{}}}}? I am not sure if the empty set, in this case, can be considered as a set and make the size 3 or if it is 2 or 0. thanks",['elementary-set-theory']
3363419,Does the resonance theorem in functional analysis have anything to do with resonance in mechanics?,"I am now learning the following version of the resonance theorem. Let $X, Y$ be Banach spaces. Let $\{T_\lambda:
\lambda\in\Lambda\}$ be a family of bounded linear operators from $X$ to $Y$ . If $\{T_\lambda:
\lambda\in\Lambda\}$ is pointwise bounded on $X$ , then $\{T_\lambda:
\lambda\in\Lambda\}$ is uniformly bounded, i.e., $\sup\|T_\lambda\|<\infty$ . Or equivalently, if $\sup\|T_\lambda\|=\infty$ , then there exist $x\in B$ such that $\sup\|T_\lambda x\|=\infty$ . For those who don't think it can be called ""resonance"", see theorem 1.16 here : My statement is equivalent to this. Also, in physics, we know that resonance occurs when the imposed frequency onto an oscillating system equals its natural frequency. Question: How is the resonance theorem related to resonance in physics?","['fourier-analysis', 'functional-analysis']"
3363465,"Two matrices $A,B$ such that $e^{(A+B)}=e^{A}e^{B}$ but $AB\neq BA$?","So I saw at ODE class the properties of the exponential matrix so we can use it as the  canonical basic solution to linear ODE systems, and the teacher show us that if two matrices $A,B$ hold that $AB=BA$ then $e^{(A+B)t}=e^{At}e^{Bt}$ but said the reciprocal does not necesarily holds. I tried to find two matrices to show a counter example for the reciprocal, but couldn't find them in the matrices with real coefficients.
My question is, such matrices exist? Do i need to consider them with complex coefficients? Update: I re-checked my notes to see if i made a mistake, and the propertie is without the $t$ involved, or maybe could be seen as $t=1$ (original question: ""Two matrices $A,B$ such that $e^{(A+B)t}=e^{At}e^{Bt}$ but $AB\neq BA$ ?"")",['ordinary-differential-equations']
3363514,Is any smooth fibre bundle a smooth Hurewicz fibration?,"From https://pdfs.semanticscholar.org/e737/a4f8b93242910c050c2faf761236dcf60f64.pdf ( Theorem 2.1 ) it follows: (*) If $\pi:P\rightarrow M$ is a topological  fibre bundle over a paracompat hausdorff topological space $M$ then it is a Hurewicz fibration and hence a Serre fibration. (In the category of topological spaces) I found the analogous notion of homotopy lifting property and Serre/Hurewiz fibration in the category of smooth manifolds here When is a fibration a fiber bundle? . My question is the following : Does (*) holds in the category of smooth manifolds also? I got an affirmative answer at least for Serre fibration in https://mathoverflow.net/questions/116231/given-a-serre-fibration-between-manifolds-how-ugly-can-it-be (where in the question it is mentioned ""Clearly smooth fibre bundles are Serre fibrations"" by @David Roberts.) But (no proof or any reference where such proof is discussed) is mentioned in the question. So can anyone please give a proof of (*) or suggest any reference where such proof is discussed (at least for Serre fibration)? Also it would be very helpful if someone can suggest some references or literature resources where the notion of Serre/Hurewicz  fibration in the category of smooth manifolds is discussed. Thanks in Advance.","['fiber-bundles', 'fibration', 'smooth-manifolds', 'algebraic-topology', 'differential-geometry']"
3363519,Intuition for multiplying by x for independent solutions,"I'm taking a differential equations course, and I was wondering what the intuition behind multiplying by x to get a linearly independent solution to a 2nd order homogeneous linear ODE is. Consider the DE: $$
y^{\prime\prime} + 4y^{\prime} + 4y = 0
$$ Evaluating the characteristic polynomial: $$
\lambda^2 + 4\lambda + 4 = 0\\
(\lambda+2)^2=0, \lambda=-2\ \text{(double root)}\\
y=c_1e^{-2x}+c_2xe^{-2x}
$$ I'm trying to get a hold of why multiplying by $x$ makes sense. I understand the  derivation via variation of coefficients, but I don't get why it makes sense. Why does multiplying a solution to a differential equation by $x$ to get another solution that is linearly independent make sense? Is it a guess, or is there some deeper intuition for why this makes sense in the case of a double root? Does multiplying a function of $x$ by $x$ always produce a new linearly independent function? My teacher mentioned something about it being the first term of some taylor series expansion for $f(\epsilon)$ when nudging $x$ by $\epsilon$ in the first solution to the DE, but I didn't really understand that explanation. Is there more to that explanation?","['linear-algebra', 'taylor-expansion', 'ordinary-differential-equations']"
3363535,Is torsion even useful?,"I have run across the existence of torsion as I study Reimannian geometry. I also know that in the case of Reimannian geometry, we can always find a unique metric-preserving connection with zero torsion: the Levi-Cevita connection. This begs the question, why is torsion a fruitful concept? I have found certain answers on math.se which provide examples of connections with torsion that look highly unnatural, like this one about torsion in two dimensions . What do we as mathematicians gain by studying torsion? Is there a single ""natural"" example of torsion? This Math overflow question: what is torsion intuitively seems to have fantastic answers that I cannot access - I simply do not know enough math, in particular, Lie groups and solder forms. Is there some way to ""elaborate"" the answers there with an example in 2D or 3D such that the essence is retained? I have often seen this picture: While this picture shows us what torsion is after defining it , it doesn't tell us why we would care to pick such a connection in the first place! So this is not a satisfactory answer for me right now. I want to understand why we even want torsion.","['connections', 'riemannian-geometry', 'differential-geometry']"
3363602,"$ab+ac+bc \equiv 1 \bmod abc$ or ""easy chinese remainder theorem problems""","When teaching students about the Chinese remainder theorem, it is traditional to ask them questions like: ""An integer $n$ is equivalent to $r_1 \bmod m_1$ , to $r_2 \bmod m_2$ and to $r_3 \bmod m_3$ . Compute $n \bmod m_1 m_2 m_3$ ."" For example, There are certain things whose number is unknown. If we count them by threes, we have two left over; by fives, we have three left over; and by sevens, two are left over. How many things are there? -- Sunzi Suanjing, 3rd century CE. If it happens that $m_1 m_2 \equiv 1 \bmod m_3$ , $m_1 m_3 \bmod m_2$ and $m_2 m_2 \bmod m_1$ , then the question is particular easy to answer: One has $n = r_1 m_2 m_3 + r_2 m_1 m_3 + r_3 m_1 m_2$ . I noticed this when preparing for my class today and planning to ask such a question with $(m_1, m_2, m_3) = (2,3,5)$ , which has this property. Note that we can rewrite this property as $m_1 m_2 + m_1 m_3 + m_2 m_3 \equiv 1 \bmod m_1 m_2 m_3$ . So, for the fun of it, here is my question: Can we describe all $k$ -tuples of integers $(m_1, m_2, \ldots, m_k)$ such that $$m_1 m_2 \cdots m_{j-1} m_{j+1} \cdots m_k \equiv 1 \bmod m_j$$ for $1 \leq j \leq k$ ?","['number-theory', 'chinese-remainder-theorem', 'elementary-number-theory', 'diophantine-equations']"
3363621,The necessity of absolute convergence in the convergence of the Cauchy product of series?,"The Mertens' theorem claims that Suppose $\sum_{n=0}^\infty a_n,\sum_{n=0}^\infty b_n$ are two convergent series of complex numbers, convergent to $A,\beta$ respectively. If $\sum_na_n$ converges absolutely, then the Cauchy product $\sum_{n=0}^\infty c_n$ converges to $A\beta$ , where $c_n=\sum_{k=0}^na_kb_{n-k}$ . I wonder whether the absolute convergence of $\sum_na_n$ is generally necessary. I know that there are counterexamples where $\sum_na_n, \sum_nb_n$ converge conditionally but the Cauchy product $\sum_nc_n$ diverges. However, they are too special. I also know that the Cesàro sum of $(c_n)$ is $A\beta$ . The precise question of which I wonder the answer is that: Given a series $\sum_{n=0}^\infty a_n$ of complex numbers. Suppose that for all convergent series $\sum_{n=0}^\infty b_n$ of complex numbers, the Cauchy product $\sum_{n=0}^\infty c_n$ converges. Does this imply that the series $\sum_na_n$ converges absolutely? Denote by $\beta_n$ the partial sum $\sum_{k=0}^nb_n$ . The previous question is equivalent to the following: Given a series $\sum_{n=0}^\infty a_n$ of complex numbers. Suppose that for all convergent sequences $(\beta_n)$ of complex numbers, the convolution sequence $(\sum_{k=0}^na_k\beta_{n-k})_{n\in\mathbb N}$ converges as $n\to\infty$ . Does this imply that the series $\sum_na_n$ converges absolutely? We have some immediate consequences: First we take $\beta_n=1$ for all $n\in\mathbb N$ to deduce that $\sum_na_n$ converges. In this case, we can only test with those $(\beta_n)$ such that $\lim_{n\to\infty}\beta_n=0$ . And the Silverman-Töplitz theorem tells us that the Cesàro mean of $(\sum_ka_k\beta_{n-k})_n$ tends to zero, hence what we know is that $\lim_{n\to\infty}\sum_ka_k\beta_{n-k}=0$ under the assumption that $\lim_{n\to\infty}\beta_n=0$ . My idea to attack is that, given a conditionally convergent series $\sum_na_n$ , we try to find a sequence $\beta_n$ and some $\epsilon>0$ such that there are infinitely many $n$ such that $\lvert\sum_ka_k\beta_{n-k}\rvert>\epsilon$ . I don't know how to proceed next. Note There is a more highbrow aspect. Denote by $c_0\subseteq \ell^\infty$ the closed subspace of sequences which converge to zero. Mertens' theorem claim that the convolution map $a*-\colon \ell^\infty\to \ell^\infty$ restricts to a map $c_0\to c_0$ for any absolutely convergent series $\sum_{n=0}^\infty a_n$ . This hints that the preceeding question might be solved by tools in functional analysis, such as Baire's category theorem. Update I suddenly come up with a possible solution: As indicated above, our assumption is that $a*-\colon c_0\to c_0$ is a well-defined linear operator. To invoke closed graph theorem, assume that $\beta^{(n)}\to \beta$ and $a*\beta^{(n)}\to\gamma$ in $c_0$ . The convergence in $c_0$ implies the pointwise convergence, therefore $a*\beta=\gamma$ . By closed graph theorem, the operator $a*-$ is continuous, that is to say, there is a constant $M$ such that $\lVert a*\beta\rVert_{\ell^\infty}\le M\lVert \beta\rVert_{\ell^\infty}$ for all $\beta\in c_0$ . Then for all $m\in\mathbb N$ , we take $(\beta_n)_n\in c_0$ such that $\beta_na_{m-n}=\lvert a_{m-n}\rvert$ and $\lvert\beta_n\rvert=1$ for $n\le m$ , and $\beta_n=0$ for $n>m$ . Then we have $\sum_{n=0}^m\lvert a_n\rvert\le\lVert a*\beta\rVert_{\ell^\infty}\le M$ . Q.E.D. Is it correct?","['cauchy-product', 'real-analysis', 'functional-analysis', 'sequences-and-series', 'convergence-divergence']"
3363638,"Is it meaningful to say ""take a random measurable subset of [0, 1] with measure 0.5""?","Is it meaningful to say take a random measurable subset of [0, 1] with measure 0.5? If it is, is it then true that for any $r\in[0, 1]$ , the probability that $r$ is in a random measurable subset of $[0, 1]$ with measure 0.5 is $0.5$ ? Context: I was studying entropy encoding and thought that one way to think about why entropy encoding efficient is this: for each finite code word $s$ of length $d$ , assign a subset $A = f(s)$ of $[0, 1)$ such that $\{f(s) : s \text{ is a code word of length } d\}$ partitions $[0, 1)$ , and $$Pr(s' = s | s' \text{ is of length }d) = |A|$$ For example, in arithmetic encoding, we have $f(0) = [0, 1/2), f(1) = [1/2, 1), f(00) = [0, 1/4), ...$ . Then, knowing the length $d$ , $f(s)$ can be represented by any real number $\bar s\in f(s)$ . Now, the crucial part of entropy encoding is that in general, for each code $s$ , there exists a real number $\bar s\in f(s)$ that is representable in under $$-\log_2 (Pr(s' = s | s' \text{ is of length }d)) = -\log_2 |f(s)|$$ bits. For example, the binary string $b_1...b_n$ represents the fraction $(b_1...b_n)_2/2^n$ , where $(b_1...b_n)_2$ denotes the string decoded as the binary code of an integer. If we assume that it is nonzero, then $b_n$ can always be chosen as $1$ , that is, $(b_1...b_n)_2$ is an odd number. There are $2^{n-1}$ such numbers, and indeed, since $b_n$ is always $1$ , it can be dropped. So the new encoding would have $b_1...b_{n-1} \mapsto (b_1...b_{n-1}1 )_2/2^n$ . However, I thought that it is not necessary to use binary fractions. The crucial thing is that we have an injective ""coding"" function $\{0, 1\}^n \to [0, 1)$ , and on average , each $f(s)$ contains one image of the coding function. Suppose it can be proven that for any $r\in [0, 1)$ , the probability that a random measurable subset $S\in[0, 1)$ contains $r$ is $|S|$ , then it is immediate that arithmetic coding would work, because on average each $f(s)$ would contain one number with codelength $-\log_2|f(s)|$ .","['analysis', 'entropy', 'probability']"
3363671,Errors and approximations,I needed help with this question: The diameter and altitude of a can in the shape of a right circular cylinder are measured 4cm and 6cm respectively. The possible error in each measurement is 0.1cm.Find approximately the maximum possible error in values computer for the  volume. My try: $V=24π$ $$ V= \pi r^2 h $$ $$ dV= \frac {dV}{dr} dr + \frac {dV}{dh} dh$$ $$ = (2\pi rh) dr + (\pi r^2)dh$$ $$ \frac {dV}{V} = 2(dr/r)+ (dh/h) = 2(0.1)+ (0.1) = 0.3 $$ $dV=0.3X 24π=7.2π cc$ But the answer is $1.6πcc$ . What I did wrong?,['derivatives']
3363709,How can I find an approximation of a smooth function $R^2 \to R^4$ such that when restricted to $S^1$ it is an immersion?,"I am having trouble with the following exercise: Given a smooth function $f: R^2 \to R^4$ and $S^{1}$ embedded in $R^2$ , then $\forall \epsilon >0$ there exists a smooth function $f_{1}$ such that $sup|f(x)-f_{1}(x)|< \epsilon$ , which is an immersion when restricted to $S^1$ .","['manifolds', 'differential-geometry']"
3363788,Analysis of longest run of heads when flipping a fair coin.,"Consider a sequence of $n$ unbiased coin flips. Consider the length of the
longest contiguous sequence of heads. (a) Show that you are unlikely to see a sequence of length $c + \log_2(n)$ for $c > 1$ (give a decreasing bound as a function of c). (b) Show that with high probability you will see a sequence of length $\log_2 n − O(\log_2 \log_2 n)$ . For (a) I want to use Markov's inequality to get a bound. For that, I need to find $\mathbb{E}[X]$ where $X$ is the longest run of heads after $n$ flips. I'm not sure how to get $\mathbb{E}[X]$ .","['probability-limit-theorems', 'asymptotics', 'probability-theory', 'probability']"
3363800,"Euler sequence, exact sequence and Blow Up","In $ X = \mathbb{P}^{n}$ we have the Euler sequence: $$0 \longrightarrow \mathcal{O}_{X} \longrightarrow \mathcal{O}_{X}(1)^{\oplus (n+1)} \longrightarrow T_{X} \longrightarrow 0 $$ Let $Y \subset X$ be a smooth subvariety and $\pi: \widetilde{X} \longrightarrow X$ the morphism of blow up along of $Y$ . Is there an exact sequence in $\widetilde{X}$ analogous to the Euler sequence in $X$ ? 1) Is $\widetilde{X}$ an algebraic variety? Is it projective? 2) Is Bott's formula valid for $\widetilde{X}$ ? Sorry if my questions are trivial to you, but I am a beginner in Algebraic Geometry. About exact sequence : 3) What are the references where I can find exact sequences after a blow up along a smooth subvariety? 4) More precisely, I would like to learn more about exact sequences in $\widetilde{X}$ and later learn to calculate cohomologies. Thanks in advance.","['algebraic-geometry', 'sheaf-cohomology', 'sheaf-theory']"
3363852,Find the $f(x)$ if $f(f(x)+xf(y))=f(x)+xy$,"Find all $f:\Bbb R\to \Bbb R$ ,and such for any real number $x,y$ have $$f(f(x)+xf(y))=f(x)+xy$$ Let $x=y=0$ we have $$f(f(0))=f(0)$$ and I found a similar problem If the function $f$ satisfies the equation $f(xf(y)+x)=xy+f(x)$, find $f$","['functional-equations', 'functions']"
3363869,Sketching the region of $\int_0^2 \int^{y^2}_0dxdy$,"My textbook shows the answer as being: Note that I've interpreted the $y^2x$ to be extraneous information for the problem of simply sketching the region the double integral is specifying; maybe I'm wrong about this? My question is: isn't the region negated in the answer? It seems to me that the region should be the region above the line $y=0$ and below the curve $x=y^2$ However, the question shows the region as being the region above the curve $x=y^2$ and below the line $y=2$ Why is the latter and not the former correct? How can we know which is being specified by the integral?","['integration', 'multivariable-calculus', 'calculus', 'multiple-integral']"
3363944,A question on giving prizes when there is no restriction on the number of prizes per person,"A group consisting of $3$ men and $6$ women attends a prizegiving ceremony. If $ 5$ prizes are awarded at random to members of the group, find the probability that exactly $3 $ of the prizes are awarded to women if a) There is a restriction of at most one prize per person b) There is no restriction on the number of prizes per person I did part a) and got the same result as the solution but I failed at getting the same answer for part b). When I looked at the working outs of both parts, I noticed a significant difference in the ways two parts are solved. This is the working out for part a) (which is also similar to my working out)
a) $\frac{6C3\times 3C2}{9C5} = \frac{10}{21}\ $ And this is the working out of part b) 
b) $\ 5C3 \times (\frac{3}{9})^{2} \times (\frac{6}{9})^{3}\  = \frac{80}{243}\ $ I'm so confused why part b) is done in such a different way than part a) and as a student, how can I know when to consider the numerator and denominator separately like part a) and when to find the probability of each component and times all of them together like part b)? Also, can we solve part b) in a similar way like part a)? Does anyone have any tips on how to distinguish these sorts of methods? Thank you very much for helping.","['combinations', 'combinatorics', 'probability']"
3363946,Find the limit of $\lim_{x\to 1}\frac{\sqrt{1-\cos{2(x-1)}}}{x-1}$.,"Find the limit: $\lim_{x\to 1}\frac{\sqrt{1-\cos{2(x-1)}}}{x-1}$ . My solution: Let $t=x-1$ then as $x\to 1$ , $t\to 0$ . Therefore $\lim_{x\to 1}\frac{\sqrt{1-\cos{2(x-1)}}}{x-1}= \lim_{t\to 0}\frac{\sqrt{1-\cos2t}}{t}=\lim_{t\to 0}\frac{\sqrt{2\sin^2t}}{t}=\sqrt{2}\lim_{t\to 0}\frac{\sin t}{t}=\sqrt{2}$ . But my teacher said that the limit does not exist. So my problem is what's wrong with my solution? Where did I go wrong? Is there any limit? Any help will be nice. Thank you.","['indeterminate-forms', 'limits', 'functions']"
3363951,Composition of multivariate functions.,"How can I understand a theorem about the composition of two functions: $g = \gamma: I \subset \mathbb{R} \rightarrow \mathbb{R}^m$ $f: \mathbb{R}^m \rightarrow \mathbb{R}$ if it looks like this: $d(f \circ \gamma)(t_0) = df(\gamma(t_0))d\gamma(t_0)=\langle\nabla f(\gamma(t_0)), \gamma^{\prime}(t_0)\rangle$ Isn't $d(f \circ \gamma)(t_0)$ just another way to write $df(\gamma(t_0))$ ? How can I understand this notation?","['multivariable-calculus', 'calculus', 'parametric', 'real-analysis']"
3363986,example of an inﬁnite group [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question I am studying group theory, I want to an example of an inﬁnite group, say, $G$ , such that $G$ contains a normal subgroup $H$ and $Ord(aH) = n$ in $G/H$ but $G$ does not contain an element of order $n$",['group-theory']
3364039,"""usual limit"" from filter","I'm reading this in which the author says that $\lim_{x\to a}f(x)=y$ if for every neiborhood $U$ of $y$ , $f^{-1}(U)$ belongs to the filter of neigbohoods of $a$ . What about the following function ? $f(x)=1$ if $x=0$ and $f(x)=0$ otherwise. With the usual notion of limit, we have $\lim_{x\to 0}f(x)=0$ regardless to the fact that $f(0)$ itself has a ""strange"" value. With the limit defined from the filter of neigborhoods, the function $f$ has no limit at $x=0$ . EDIT(add justification): if $U=(-1/2, 1/2)$ we have $f^{-1}(U)=R\setminus\{0\}$ , which is not a neigborhood of $0$ . Am I missing something or the ""filter"" limit does not brings back the usual notion of limit ?","['filters', 'limits']"
3364082,What is wrong with this solution to the limits question?,"Evaluate $\lim\limits_{x\to\infty}x-x^2\ln\bigg(1+\dfrac1{x}\bigg)$ . My solution: \begin{align}
\lim\limits_{x\to\infty}x-x^2\ln\bigg(1+\frac1{x}\bigg)&=\lim\limits_{x\to\infty}x-\frac{x\ln(1+\frac1{x})}{\frac{1}x}\\
&=\lim\limits_{x\to\infty}x-(x\cdot 1)\\
&=\lim\limits_{x\to\infty}x-x\\
&=0
\end{align} I got $0$ as answer, but the correct answer is $\frac12$ . I solved it using another method, but I just need to know why this won't work. Any ideas?",['limits']
3364098,"Proof of ""$\| I-A\|<1$ implies $A$ is invertible"" using contraction mapping","For a linear operator $A:\mathbb{R}^n\rightarrow \mathbb{R}^n$ consider its norm defined by $$\| A\| = \sup\{ |Ax| \,\,|\,\, x\in\mathbb{R}^n, \,\, \|x\|\le 1\}.$$ From the definition it is clear that $\| Ax\| \le \|A\| \|x\|$ for all $x\in\mathbb{R}^n$ . With this notation, we come to the problem. Theorem: If $A$ is a linear operator with $\| I-A\|<1$ then $A$ is invertible. Proof: Let $\| I-A\| = c<1$ . We can assume that $A\neq I$ (o.w. we are done), hence $c>0$ . Let us denote the operator $I-A$ by $T$ . Notice that if $\|x\| \le 1$ then $\| Tx\| \le \| T\| \|x\| <1$ . Hence, $T$ takes closed unit ball of $\mathbb{R}^n$ into itself. Moreover, $\|Tx-Ty\|  \le \|T\| \| x-y\| \le c\| x-y\|$ where $0<c<1$ . This means that $T$ is a contraction mapping on closed unit ball; it must have unique fixed point. But $0$ is already a fixed point of $T$ ; thus for $x\neq 0$ we have $T(x)\neq x$ i.e. $(I-A)(x)\neq x$ i.e. $A(x)\neq 0$ , i.e. $A$ is injective on closed unit ball (and hence on $\mathbb{R}^n$ ). This forces that $A$ must be invertible. Q. Is this proof correct? (I tried to use property of contraction of mapping, which we got from hypothesis).","['multivariable-calculus', 'linear-algebra']"
3364118,Which groups can be proven to be simple using Iwasawa criterion?,"Recall first the following result of Iwasawa and its corollaries.
In what follows, $G$ is a group acting primitively on a set $E$ , and $x_0\in E$ .
We also assume that there exists a normal subgroup $A$ of $Stab_G(x_0)$ such that the various conjugates of $A$ generate $G$ . Thm.(Iwasawa) Under the previous assumptions, for any normal subgroup $N$ of $G$ , either $N$ acts trivially on $E$ , or $G/N$ is isomorphic to a quotient of $A$ . Corollary 1. If $G=[G,G]$ and $A$ is solvable, then all proper normal subgroups act trivially on $E$ , or $G$ is simple. Corollary 2. If $G=[G,G]$ and $A$ is solvable, and if $H$ denotes the kernel of the action of $G$ on $E$ , then $G/H$ is simple. Corollary $2$ is a powerful criterion to show that a group $G$ is simple, but the only application to simplicity I know is the case of $PSL(V)$ , where $V$ is a finite dimensional $K$ -vector space of dimension $n$ ( $K$ is any field) is simple (except for $n=2$ and $\vert K\vert\leq 3$ ) using Corollary 2. After giving it a bit of thinking, I convinced myself that the simplicity of the alternating group $A_n$ for $n\geq 6$ may be proven using  Corollary 2  by letting $A_n$ acts on the set of transpositions, even if I didn't find any reference using this approach. And that's it...Of course, I'm not a group theorist, so it's more likely that I don't know other classical applications of Iwasawa criterion, and I really would like to learn them. Hence the following: Question. Which other group may be proven to be simple using the results above ? I'm not assuming $G$ to be finite. For example, can we prove that $SO_{2n+1}(\mathbb{R})$ and $PSO_{2n}(\mathbb{R})$ are simple using Corollary 2 (or 1, or the general thm) ? The only proof I know for $SO$ reduces to the case $n=3$ (like simplicity of $A_n$ can be reduced to the simplicity of $A_5$ ) Same question for $PSp_{2n}(K)$ , where $K$ is an arbitrary field (except for the few exceptional cases). I suspect we could use symplectic transvections, and we can make this group to act on lines, but i didn't check. Once again, the only proof i know reduces to the case of $PSp_2(K)$ . I'm also interested by any other example which is not cited above (references are welcome !)","['group-theory', 'simple-groups']"
3364125,Evaluate $\sum _{n=1}^{\infty } \frac{\sin \left(x \sqrt{a^2+n^2}\right)}{\left(a^2+n^2\right)^{3/2}}$ and generalize it,"In this post the following is proved $$\small \sum _{n=1}^{\infty } \frac{\sin \left(x \sqrt{a^2+n^2}\right)}{\sqrt{a^2+n^2}}=\frac{1}{2} \pi  J_0(a x)-\frac{\sin (a x)}{2 a},\ \ \sum _{n=1}^{\infty } \frac{\cos \left(x \sqrt{a^2+n^2}\right)}{\sqrt{a^2+n^2}}=-\frac{1}{2} \pi  Y_0(a x)-\frac{\cos (a x)}{2 a}$$ But how to established the harder one $$\small\sum _{n=1}^{\infty } \frac{\sin \left(x \sqrt{a^2+n^2}\right)}{\left(a^2+n^2\right)^{3/2}}=-\frac{\sin (a x)}{2 a^3}+\frac{\pi  x \coth (\pi  a)}{2 a}+\frac{1}{4} \pi ^2 x^2 (\pmb{H}_1(a x) J_0(a x)-\pmb{H}_0(a x) J_1(a x))-\frac{1}{2} \pi  x^2 J_0(a x)+\frac{\pi  x J_1(a x)}{2 a}$$ Here $J, \pmb{H}$ denotes Bessel and Struve functions. Update: By M-L theorem and repeated integration one have $$\small \sum _{n=1}^{\infty } \frac{\cos \left(x \sqrt{a^2+n^2}\right)}{\left(a^2+n^2\right)^2}=-\frac{\cos (a x)}{2 a^4}+\frac{\pi  \coth (\pi  a)}{4 a^3}+\frac{1}{8} \pi ^2 x^3 \left(1-\frac{1}{a^2 x^2}\right) F(a x)+\frac{\pi ^2 \text{csch}^2(\pi  a)}{4 a^2}+\frac{1}{4} \pi  x^3 J_0(a x)-\frac{\pi  x^2 \coth (\pi  a)}{4 a}-\frac{\pi  x^2 J_1(a x)}{4 a}$$ Where $F(t)=\pmb{H}_0(t) J_1(t)-\pmb{H}_1(t) J_0(t)$ . Analytic continuation allows us to extend the range to $|a|<1$ , $x\in (0,2\pi)$ , for instance $$\small\sum _{n=1}^{\infty } \frac{\cos \left(\sqrt{4 n^2-1}\right)}{\left(n^2-\frac{1}{4}\right)^2}=2 \pi ^2 \pmb{L}_1(1) I_0(1)-2 \pi ^2 \pmb{L}_0(1) I_1(1)+\pi ^2-8 \cosh (1)+2 \pi  I_0(1)-2 \pi  I_1(1)$$ Moreover, differentiating closed-form of $\sum _{n=1}^{\infty } \left(\frac{\sin \left(x \sqrt{a^2+n^2}\right)}{\sqrt{a^2+n^2}}-\frac{\sin (n x)}{n}\right)$ w.r.t $x$ yields: $$\small\sum _{n=1}^{\infty } \left(\cos \left(\pi  \sqrt{n^2+1}\right)-(-1)^n\right)=1-\frac{\pi  J_1(\pi )}{2}$$","['closed-form', 'bessel-functions', 'special-functions', 'sequences-and-series']"
3364173,Are there infinite triples of consecutive integers whose numbers of factors are increasing?,"We know that there exists infinite numbers of integers $n$ such that $d(n)<d(n+1)$ , where $d(n)$ is the number of positive divisors of $n$ .
Question: are there infinite numbers of integers $n$ such that $d(n)<d(n+1)<d(n+2)$ ?",['number-theory']
3364177,Symmetric matrix as a sum of symmetric matrices,Let matrix $M \in \mathbb{N}^{5 \times 5}$ be symmetric with non-negative integer entries and zeros on the main diagonal and having the property that the row sums are equal to $2r$ for some $r \geq 2$ . I want to prove that $M$ can be written as a non-negative integral linear combination of $5 \times 5$ symmetric matrices having non-negative integer entries with zero entries on the main diagonal and having the property that the row sums are equal to $2$ . Is there way to prove this? I tried with some simple examples and it seems to be correct.,"['matrices', 'algebraic-graph-theory', 'combinatorial-geometry', 'linear-algebra', 'combinatorics']"
3364202,How is the mean represented in boxplots,"How is the mean represented in boxplots?
In the image below weather situation 3 shows outliers pulling the mean down and so I reasoned that situation 4 would have a higher mean than the rest because the median has a higher Humidity than situation 1 and 2. But, I got the wrong answer. Thank you.",['statistics']
3364241,Mapping an Ellipse to a Circle with the Circle's center offset inside the Ellipse,"I am creating a program which maps an Ellipse to a Circle. However, there is a twist, the center of the Circle is offset inside the Ellipse. See this picture: Ellipse and Circle In this picture the red dot inside the ellipse is the location of the Circle's center in the Ellipse. So, I know the dimensions and centers of both the Circle and the Ellipse and the center point of the Circle inside the Ellipse. Now, how would I go about mapping points inside this Ellipse to a Circle? Edit: Sorry for not clarifying my question. Yes, I meant that the red dot in the Ellipse is the Circle's center mapped into the Ellipse. I took a while to reply but I haven't been slacking off, I already implemented the solution given by you people. As Aretino mentioned, I used Homography to solve this problem. See: http://www.corrmap.com/features/homography_transformation.php If only I had checked this page more often, I would have known that Linear Transformation would have been far more simpler. So for everyone with this problem, use Linear Transformation as described by Aretino. I will be using it to make my program simpler. Thank you all so much for helping me out. Here is the end result of your effort: :) https://youtu.be/EvBG166Ly6Y","['conic-sections', 'circles', 'geometry', 'transformation']"
3364262,What is the relationship between the definition of a well defined operation and a binary operation?,"Def.1. A binary operation on a nonempty set $A$ is a map $f:A\times A\to A$ such that $f$ is defined for every pair of elements in $A$ , and $f$ uniquely associates each pair of elements in $A$ to some element of $A$ . It seems that the definition of a binary operation includes the definition of a well defined operation (condition 2). But I see other books using the term: Well defined binary operation ! Is there a not well defined binary operation ? So that just confuses me. What is meant by that ?","['binary-operations', 'abstract-algebra']"
3364281,"Do we need to check all 10 axioms to verify that some set, call it $V$, is a vector space?","The definition of the vector space from the book: Let $\bf u, v$ and $\bf w$ be vectors in the set $V$ . The set $V$ is
  called a vector space if it satisfies the following 10 axioms. The vector addition $\bf u + v$ is also in the vector space $V$ . Commutative law: $\bf u + v = v + u$ Associative law: $\bf (u+v) + w = u + (v + w)$ Neutral element. There is a vector called the zero vector in $V$ denoted by $\bf O$ which satisfies $$\bf u + O = u$$ for every vector $\bf u $ in $V$ Additive inverse: $\bf u + (-u) = O$ Let $k$ be a real scalar. Then $k\bf u$ is also in $V$ . Let $k$ and $c$ be scalars, then $k(c\mathbf{u}) = (kc)\mathbf{v}$ Let $k$ be a real scalar. Then $k(\mathbf{u + v}) = k\mathbf u + k\mathbf v $ Let $k$ and $c$ be real scalars, then $(k+c)\mathbf u = k\mathbf{u} + c\mathbf{u}$ For every vector $\bf u$ : $1\mathbf{u} = \mathbf{u}$ We say that if the elements of the set $V$ satisfy the above 10 axioms
  then $V$ is called a vector space and the elements are known as vectors. Suppose we have some set, call it $S$ , and we verified that axiom $1$ and $6$ hold. Does it make sense to check other axioms? Isn't it self-evident that they will be satisfied? If it is not, could you provide me an example when axiom $1$ and $6$ hold but at least one other fail?",['linear-algebra']
3364289,Prove that function $\mathbf{R}^3\to\mathbf{R}^3$ is injective,"Prove that $f:\mathbf{R}^3\longrightarrow \mathbf{R}^3:(x,y,z)\longmapsto (e^{2y}+e^{2z},e^{2x}-e^{2z},x-y)$ is injective. Assume $f(x,y,z)=f(x',y',z')$ , then this gives the system $\begin{cases}e^{2y}+e^{2z}=e^{2y'}+e^{2z'} \\ e^{2x}-e^{2z}=e^{2x'}-e^{2z'} \\ x-y=x'-y' \end{cases}$ . If I can conclude that $x=x'$ , then it follows from (3) that $y=y'$ and from (2) that $z=z'$ . I tried adding (1) and (2) to obtain $e^{2x}+e^{2y}=e^{2x'}+e^{2y'}$ , but I have no idea how to proceed. Could someone provide some help? I think there is just a method I don't see.","['algebra-precalculus', 'functions']"
3364294,Total derivative only defined on open subset,"Let's say that $f: M \to\mathbb{R}^n$ , where $M \subset \mathbb{R}^m$ , is totally differentiable at point $a$ so that we have an open subeset $U$ with $a \in U \subset M$ . Why does $U$ have to be an open set? What's wrong with it if you assume that $U$ is closed and $a$ lies on the edge of subset $U$ ? edit Why is it not sufficient to assume that $a$ is a limit point if you want to show the uniqueness of the total derivative?","['multivariable-calculus', 'derivatives']"
3364400,"Prove that Hopf maps on $S^3, S^2$ and $\mathbb{C} \mathbb{P}^1$ are smooth submersions","Endow $S^3$ with its standard smooth structures from the stereographic projections, i.e. $$\chi_1:S^3 \setminus \{(0,0,0,1) \} \to \mathbb{R}^3, \chi(x,y,z,t) = \frac{1}{1-t}(x,y,z) $$ and $$\chi_2: S^3 \setminus \{(0,0,0,-1) \} 
 \to \mathbb{R}^3, \chi_2(x,y,z,t) = \frac{1}{1+t}(x,y,z).$$ Do the same for $S^2$ , call the charts $\eta_1, \eta_2$ (in the same order as the ones for $S^3$ ). Now, consider the complex projective space $\mathbb{C} \mathbb{P}^1$ endowed with the smooth structure given by the charts $\{(U_0, \varphi_0), (U_1, \varphi_1)\},$ $$U_0 = \{[z_0:z_1] \ \mid \ z_0 \neq 0 \} \text{ and } U_1 = \{[z_0: z_1] \ \mid \ z_1 \neq 0 \},$$ where $[x:y]$ represents the complex line through the point $(x,y)$ and $0$ in $\mathbb{C}^2$ , and $$\varphi_0([z_0: z_1]) = \frac{z_1}{z_0} \text{ and } \varphi_1([z_0: z_1]) = \frac{z_0}{z_1}. $$ Now define the Hopf maps: $$h: S^3 \to S^2, h(x,y,z,t) = (x^2+y^2-z^2-t^2, 2(yz-xt), 2(xz+yt)) $$ and $$H:S^3 \to \mathbb{C} \mathbb{P}^1, H(x,y,z,t) = [(x+iy):(z+it)]. $$ Is there an easier way to prove that $h$ is a well-defined smooth submersion and that $H$ is a smooth submersion (with respect to the respective smooth structures)? By this I mean we can of course compute $\eta_i \circ h \circ \chi_j^{-1}, \forall i,j \in \{1,2 \}$ and $\varphi_k \circ H \circ \chi_l^{-1}, \forall k,l \in \{1,2 \}$ and prove that they are smooth (in the classical real-analysis sense) and that they are submersions, but this is a very tedious process. So, are there easier ways to do this? Will this maybe be easier if we switch the smooth structure of the unit spheres from stereographic projections to, say, normal projections (though we increase the number of combinations of charts to verify from 4 to 48), since they induce the same smooth structure?","['manifolds', 'projective-space', 'smooth-manifolds', 'differential-geometry']"
3364404,"Given $X\sim\text{Bin}(n,p)$ and $Y\sim\text{Ber}\left(\frac Xn\right)$, find $E[X\mid Y]$","If $X\sim \operatorname{Binom}(n,p)$ and $Y\sim \operatorname{Ber}\left(\frac Xn\right)$ , then find $E[X\mid Y]$ . Is there a name for such a random variable $Y$ , where its distribution depends on another r.v. ? I got after some lengthy calculation $$P(Y=0)=1-p$$ $$P(Y=1)=p$$ I don't know over which variable to sum ? I must get a function in terms of $Y$ Then $$E[X\mid Y=1]=\sum_\limits{???}\frac{P(X=k)P(Y=1\mid X=k)}{P(Y=1)}$$ what I know, (assuming there are $n$ trials with $n\ge k$ ) $$P(X=k)=\binom{n}{k}p^k(1-p)^{n-k}$$ $$P(Y=1\mid X=k)=\frac{k}{n}$$ It is also inappropriate to set $Y=1$ instead of $Y=m$ for some $m$ , otherwise I cannot recognize $Y$ in the formula. How to remedy this ? EDIT: When the variable goes from $k=0$ to $n$ I obtain the following, $$E[X\mid Y=1]=np-p+1,\quad E[X\mid Y=0]=p(n-1)$$ so it seems legitimate to combine these 2 in the following way, $$E[X\mid Y]=(np-p+1)Y+\left(p(n-1)\right)(1-Y)$$ Is this true ?","['conditional-expectation', 'probability-distributions', 'probability-theory']"
3364413,Limit of this expression when n tends to infinity,The limit is equal to: $$\lim_{n\to\infty} n^2 \int_0^1 \frac{1}{(1+x^2)^n} dx$$ P.S. What should be the better approach for such kinds of problems?,"['limits', 'calculus', 'definite-integrals']"
3364437,Aesthetic proofs that involve Field Theory / Galois Theory,"I am preparing for an oral exam on Abstract Algebra, especially Field Theory and Galois Theory. Now, I'm looking for some aesthetic proofs that involve Galois Theory/Field Theory for two reasons. I may be asked to point out the basic concepts of Galois Theory and their fields of applications and consequences. Therefore it might be useful to know an non-standard example. I am just interested in the field of Abstract Algebra and I'm looking forward to find some topics and fields, in which I can intensify my knowledge. I know already two very basic examples: The application of Field Theory to clarify the classical antique problems on Straightedge and Compass Construction (Squaring the Circle, Doubling the Cube, Angle Trisection, Construction of a regular Polygon). The application of Galois Theory to determine whether a polynomial is solvable in radicals. Which further aesthetic proofs are there, that involve the basic concepts and theorems of Field Theory / Galois Theory? Of course, the number of such proofs is huge, so I'm looking for good examples in the sense pointed out above. Many thanks in advance.","['big-list', 'field-theory', 'galois-theory', 'abstract-algebra', 'soft-question']"
3364447,The center of the group of $n\times n$ upper triangular matrices with a diagonal of ones,"Let $\mathbb{F}_{p}$ be a finite field of order $p$ and $H_{n}(\mathbb{F}_{p})$ be the subgroup of $GL_n(\mathbb{F}_{p})$ of upper triangular matrices with a diagonal
of ones. Note that the center $Z(H_{3}(\mathbb{F}_{p}))$ is well
known and isomorphic to $\mathbb{F}_{p}$ (see center or dummit ). Here, I'm looking for $Z(H_{n}(\mathbb{F}_{p}))$ . Any help would be appreciated so much. Thank you all.","['heisenberg-group', 'general-linear-group', 'linear-groups', 'abstract-algebra', 'group-theory']"
3364463,Is differentiation as a map discontinuous?,"I came across the statement below: Let $C([0,1])$ be the space of all continuous functions over the interval $[0,1]$ equipped with the Supremum norm. Assume $A$ is a map on the space of all differentiable functions whose derivative is continuous into $C([0,1])$ . Also, $A$ is differentiation in the sense that it maps a functions to its derivative. The map $A$ (differentiation) is discontinuous. It's written that the last sentence is well-known but I can't make any sense of it. How can I arrive at such a conclusion? Actually, I am looking for an explicit counterexample. Any help would be highly appreciated.","['calculus', 'general-topology', 'functional-analysis', 'real-analysis']"
3364483,Why solving a differentiated integral equation might eventually lead to erroneous solutions of the original problem?,"Consider the following integral equation araising in a mathematical-physical problem: $$
\int_0^r f(t) \arcsin \left( \frac{t}{r} \right) \, \mathrm{d}t 
+ \frac{\pi}{2} \int_r^R f(t) \, \mathrm{d} t = r \, \qquad
(0<r<R) \, , 
$$ where $f(t)$ is the unknown function, and $R$ is a positive real number.
By differentiating both sides of this equation with respect to the variable $r$ , one obtains $$
-\frac{1}{r} \int_0^r \frac{f(t)t \, \mathrm{d}t}{\sqrt{r^2-t^2}} = 1 \, , 
$$ the solution of which can readily be obtained as $$
f(t) = -1 \, .
$$ Nevertheless, upon substitution of the latter solution into the original integral equation given above, one rather gets an additional $-\pi R/2$ term on the left hand side. i was wondering whether some math details or assumptions are overlooked here during this resolution. Any help would be highly appreciated. An alternative resolution approach that leads to the desired solution is also most welcome. Thank you","['integration', 'definite-integrals', 'integral-equations', 'analysis', 'real-analysis']"
3364550,multiple choice question on group of matrices,"Consider the set of matrices $$G=\left\{ \left( \begin{array}{ll}s&b\\0&1 \end{array}\right) b \in \mathbb{Z}, s \in \{1,-1\} \right\}.$$ Then which of the following are true G forms a group under addition G forms an abelian group under multiplication Every element of G is diagonolizable over $\mathbb{C}$ G is finitely generated group under multiplication I am getting
1) is false since not closed under addition
2)Forms a group under multiplication (  abelian or not i don't know)
3)Not true if $a=1$ 4) dont know
please help me to complete","['group-theory', 'abstract-algebra']"
3364607,Does $\frac{dx}{dy}$ at $0$ exist and $\frac{dy}{dx}\frac{dx}{dy}$ at $0$ is $1$ for the following function?,$$y =f(x)=\begin{cases}x+x^2\sin\frac1{x^2}&\text{if }x\ne 0\\ 0&\text{if }x=0\end{cases}$$ We can see $\dfrac{dy}{dx}$ at $0$ is $1$ . My question: Does $\dfrac{dx}{dy}$ at $0$ exist and $\dfrac{dy}{dx}$ . $\dfrac{dx}{dy}$ at $0$ is $1$ ? If not then  is it because $f$ can not be invertible in any nbd around the point $0$ ? Actually  I was trying to understand when $\dfrac{dx}{dy}$ at a point exists and $\dfrac{dy}{dx}$ . $\dfrac{dx}{dy}$ at that point is $1$ if $\dfrac{dy}{dx}$ at that point exists. Can anyone please help me to clear  my doubt?,"['calculus', 'derivatives', 'real-analysis']"
3364690,$f:\mathbb{R}^n\to\mathbb{R}^n$ is diffeomorphism iff $f$ is local diffeomorphism and proper map,I have to prove that a proper local diffeomorphism in $\mathbb{R}^n$ is a diffeomorphism. I'm trying to show that it is injective but I just have that the preimage of every $y\in\mathbb{R}^n$ is a finite set. Could anybody help me? Thanks.,"['differential-topology', 'differential-geometry', 'diffeomorphism', 'real-analysis']"
3364710,Can one always interchange the order of a surface and volume integral?,"Consider a continuous charge distribution in volume $V'$ . Draw a closed surface $S$ inside the volume $V'$ . Consider the following multiple integral: $$A=\iiint_{V'}   \left[      \iint_S   \dfrac{\cos(\hat{R},\hat{n})}{R^2} dS    \right] \rho'\ dV' =4 \pi\ m_s$$ where $R=|\mathbf{r}-\mathbf{r'}|$ $\mathbf{r'}=(x',y',z')$ is coordinates of source points $\mathbf{r}=(x,y,z)$ is coordinates of field points $\cos(\hat{R},\hat{n})$ is the angle between $R$ and normal to surface element $\rho'$ is the charge density and is continuous throughout the volume $V'$ $m_s$ is the total charge inside surface $S$ Also consider the following multiple integral: $$B= \iint_S        \left[    \iiint_{V'}     \dfrac{\cos(\hat{R},\hat{n})}{R^2}   \rho'\ dV'  \right] dS$$ where the symbols have the meanings stated above. \begin{align}
B &= \iint_S        \left[    \iiint_{V'}  \rho'   \dfrac{\hat{R} \cdot \hat{n}}{R^2}   \ dV'  \right] dS\\
&=\iint_S        \left[    \iiint_{V'}  \rho'   \dfrac{\hat{R} }{R^2}   \ dV'  \right] \cdot \hat{n}\ dS\\
&=\iint_S        \mathbf{E} \cdot \hat{n}\ dS
\end{align} Is $A=B\ ?$ i.e. Is interchanging the order of surface and volume integration valid? I know it is usually valid but my doubt is due to the following reasons: In the surface integral of equation $A$ , when $\mathbf{r'} \in S$ , we can only use spherical coordinate system with origin at point $\mathbf{r'}$ (in order to avoid improper integral with limits). So while computing $A$ , we cannot use only one coordinate system. Instead, we have to use infinitely many coordinate systems. In the volume integral of equation $B$ , for all $\mathbf{r}$ , i.e. for all $\mathbf{r} \in S$ , we can only use spherical coordinate system with origin at point $\mathbf{r}$ (in order to avoid improper integral with limits). So while computing $B$ , we cannot use only one coordinate system. Instead, we have to use infinitely many coordinate systems. Edit: I know $\int \left[\int f(x,y)\,dx \right]dy = \int \left[\int f(x,y)\,dy \right]dx$ is true usually. Also, if in the diagram, if the volume $V'$ is contained within the surface $S$ , then it is valid to change the order of integration. But here the issue is a little different. The surface $S$ is inside the volume $V'$ (please have a look at my diagram) and thus improper integral comes into play. While computing $A$ , if we need to avoid improper integrals, we have no choice except to work with infinitely many spherical coordinate systems each having their origin at points $\in V'$ . Similarly while computing $B$ , if we need to avoid improper integrals, we have no choice except to work with infinitely many spherical coordinate systems each having their origin at points $\in S$ . Then how is it valid to change the order of integration in this situation? That is, how can $A=B?$","['integration', 'multivariable-calculus', 'calculus', 'solid-angle']"
3364713,Definition of measure on an algebra violating algebra definition,"My textbook's definition of measure goes like this A set function $\mu$ defined on an algebra $\mathscr A$ is called measure if: a) $\mu ( \emptyset ) = 0 $ b) $\mu$ is countably additive: i.e., if $\{A_n\}^\infty_{n=1} $ is a countable collection of sets in $\mathscr A$ such that (i) $A_n \bigcap A_m = \emptyset$ for $ n \neq m$ , and (ii) $ A = \bigcup^\infty_{n=1} A_n \in \mathscr A $ , then $\mu(A) = \sum^\infty_{n=1} \mu(A_n$ ). However, in the definition of algebra, the book defined it to be closed under finite unions. To cross-check, this maths stack exchange post confirms that an algebra and sigma algebra's difference is the fact that algebra may not be closed over infinite unions. Therefore, $A$ in the definition of measure may not belong to the algebra which doesn't make sense as I think the set function $\mu$ is $\mathscr A \rightarrow [0, \infty] $ (closed braces on infinity as given in my book). Can someone please solve my confusion? I think it may be that the set function is defined from smallest sigma field containing $\mathscr A$ then it would make sense but it is not apparent.","['measure-theory', 'abstract-algebra']"
3364729,Is there a recurrence relation which has no closed formula?,"From what I know, it is unknown whether $x_n=x_{n-1}^2 + 1$ has a closed form. Is there a recurrence relation which is known to have no closed form with a proof of inexistence? Assuming a closed form is a non recursive description using the elementary operations of addition multiplication and power, or, assuming any other good definition of ""closed form"". Edit There are similar questions out there, but the answers are a little bit going around the question. So is there one with proof or is it unknown? And if it depends on the definition of a closed form, then what are the (or some) options? How strong can a closed form definition be to still have a recursive relation that can be proved to not being able to have its form? Update Because it is a big question, and I don't want to open a new small one, I think a good representative small question about this subject is: 
Is there a recurrence relation with a domain of the natural numbers, described by elementary functions, which has no closed form defined as: A closed form of a recurrence relation with a domain of natural numbers is a function $f$ that can be described as a composition of a constant number of elementary functions without reccursion. i.e, $f(n) = f_1(f_2( \dots (f_k(n))) \dots) $ where $f_i$ is elementary for all $1 \leq i \leq k$ I think this definition is the most intuitive and basic. For example, the relation $x_n = x_{n-1}+1$ has a closed form in this sense: $$f(n) = f_1(f_2(f_3(f_4(n))))$$ Where $f_1$ is division, $f_2(n)=(n,2)$ , $f_3$ is multiplication and $f_4(n) = (n,n+1)$ Is there a recurrence relation which has no closed form in this sense?","['number-theory', 'elementary-number-theory']"
3364741,Integral of directional derivative.,"I have just learned about a proof for why the gradient ""shows the direction of steepest ascent"" involving: $\partial_{v_0} f(x_0) = (f \circ \gamma)^{\prime}(t_0) = \langle\nabla f(x_0), v_0\rangle$ with: $\gamma (t_0) = x_o, \gamma^{\prime}(t_0)=v_0$ which I now understand. A little later in the script, it is presented that: $f(x_1) - f(x_0) = \int^b_a \langle \nabla f (\gamma(t)), \gamma^{\prime}(t)\rangle dt$ . for every $C^1$ -curve $\gamma:[a,b] \rightarrow U \subset \mathbb{R}^n$ with $\gamma(a) = x_0, \gamma(b) = x_1$ , which is without proof or definition. Does anybody have an intuition or explanation as to why this holds true or maybe just a link to where I can read more?","['multivariable-calculus', 'derivatives', 'parametric', 'real-analysis']"
3364766,Well-definedness of conormal sheaf,"In the definition of the conormal sheaf, we are given a locally closed immersion $X \to Y$ , which factors through some closed subscheme $Z$ so that we have $X \to Z \to Y$ , where the first map is a closed immersion and the second an open immersion. We then take the ideal sheaf $\mathcal{I}$ corresponding to the closed immersion $f:X\to Z$ , and define the conormal to be $\mathcal{I}/\mathcal{I^2}$ , viewed as an $\mathcal{O}_X$ -module (is it correct to say that the conormal is $f^*(\mathcal{I}/\mathcal{I^2})$ ?). I've tried to show that is independent of the choice of $Z$ , but haven't really managed to work it out successfully (perhaps factoring through the scheme-theoretic closure might work?). How does one show that the conormal is well-defined?","['quasicoherent-sheaves', 'algebraic-geometry', 'sheaf-theory']"
3364802,Proof Verification: any open set can be written as countable union of open intervals,"I came up with the following proof that open sets can be written as a countable union of (not necessarily disjoint) open intervals, but I’m uncertain about one step I took. I’ve looked at Any open subset of $\Bbb R$ is a at most countable union of disjoint open intervals. [Collecting Proofs] , but I not sure if my proof is among them. Recall that the definition of open subset is that for every point $x$ in an open subset $U$ , there exists some $\delta_x$ such that the neighborhood around the point, $(x-\delta_x, x+\delta_x)$ lies fully within $U$ . That means $U$ can be written as $$U=\bigcup_{x\in U}(x-\delta_x, x+\delta_x)$$ which you can verify yourself by proving both $\subseteq$ and $\supseteq$ . This does not guarantee a countable union, so we are not done. Let's make the following tweak: find a number, $\delta_x'\leq \delta_x$ such that $x-\delta_x'$ is rational. If $x-\delta_x' = x_1-\delta_{x_1}'$ for some $x_1\neq x$ , then replace both intervals with the interval $(x-\delta_x', \max\{x+\delta_x', x_1+\delta_{x_1}'\})$ . If we union over all these intervals, we get countably many open intervals (because the rationals are countable) that union to $U$ : $$U= \bigcup_{x\in U}(x-\delta_x',\max\{\ldots\})$$ and we are done. My concern is about the step where I combine potentially uncountably many intervals into one using $\max$ . Is this allowed? Is the overall proof valid? If not, is there an easy fix, or should I scrap the proof?","['elementary-set-theory', 'general-topology', 'proof-verification', 'real-analysis']"
3364847,Number of group homomorphisms from $S_4$ to $S_4$.,"I need to find the number of group homomorphisms from $S_4$ to $S_4$ . Let, $f$ be a group homomorphism.
So, the $\ker(f)$ is a normal subgroup of $S_4$ . The normal subgroups of $S_4$ are $\{(1)\}, V_4=\{(1), (12)(34), (14)(23), (13)(24)\}, A_4$ and $S_4$ . If $\ker(f)=\{(1)\}$ then we know that $\operatorname{Aut}(S_4)\cong S_4$ . So, there are $24$ homomorphisms (isomorphisms). If $\ker(f)=S_4$ there is only $1$ homomorphism. If $\ker(f)=A_4$ then $|f(S_4)|=2$ by first isomorphism theorem. All elements outside $A_4$ must be sent to a single non-identity element of order $2$ because of transpositions that are present in $S_4$ which are of order $2$ . So, $f(S_4\backslash A_4)$ has $6+3=9$ options corresponding to transpositions and product of two transpositions respectively. Hence, there are $9$ homomorphisms. Now, adding all of these I get a total of $34$ homomorphisms. But, the answer to the problem given in the book is $34$ . So, I am suspecting that there are no homomorphisms whose kernel is $V_4$ but I am not able to prove this. So, can anyone please help me? Thanks!","['group-theory', 'abstract-algebra', 'permutation-cycles']"
3364851,"Number of words with two ""$A$"" using two letters from ""$RATA$"" and three letters from ""$TIERRA$""","Find the number of words with two "" $A$ "" using two letters from "" $RATA$ ""
  and three letters from "" $TIERRA$ "". What I did: There are two cases, one where I choose both $A$ from $RATA$ and the rest of the letters from $TIERRA$ , and the other one where I choose an $A$ from $RATA$ and the other $A$ from $TIERRA$ : 1. Choosing both $A$ from $RATA$ : There are ${5}\choose{2}$ ways to put the $A$ s on the word, and then I choose the other three letters from $TIERRA$ : $\frac{5\cdot4\cdot3}{2!}$ So there are $5\choose2$$\frac{5\cdot4\cdot3}{2!}=300$ words using both $A$ from $RATA$ . 2. Choosing an $A$ from $RATA$ and the other one from $TIERRA$ : Again, there are ${5}\choose{2}$ ways to put the $A$ s on the word, there are only two options to choose a letter from $RATA$ (either $R$ or $A$ ), and then there are $\frac{5\cdot4}{2!}$ ways to choose the remaining two letters from $TIERRA$ . So there are ${5}\choose{2}$$\frac{5\cdot4}{2!}=100$ words in this case. By the rule of sum, there are $300+100=400$ words for this problem. But the solution to this problem is $430$ . What am I doing wrong?","['combinatorics', 'discrete-mathematics']"
3364852,The closed-form of $\sum_{n=0}^{\infty}\frac{(-1)^n H^{(2)}_{n}}{(2n+1)^2} $,"How to Prove that $$  \sum_{n=0}^{\infty}\frac{(-1)^nH^{(2)}_{n}}{(2n+1)^2} \;\;=\;\;\frac{7 \pi \;  \zeta(3)}{4}-\frac{\zeta(2)G}{2}+\frac{45\zeta(4)}{8}-\frac{\Psi^{(3)}\big(\frac{1}{4}\big)}{128}$$ where $H_n^{(m)}=\sum_{k=1}^n\frac1{k^m}$ is the $n$ th generalized harmonic number of order $m$ , $\zeta$ is the Riemann zeta function and $G$ is Catalan constant? This problem proposed by Ahmad Albow","['integration', 'polygamma', 'complex-analysis', 'harmonic-numbers', 'sequences-and-series']"
3365025,Please explain this statement from Sentential Logic.,"On a textbook I am using, there's this question: Let $P$ stand for the statement “I will buy the pants” and $S$ for the statement “I will buy the shirt.” What English sentences are represented by $\lnot (P \land \lnot S)$ ? And the answer is I will not buy the shirt without the pants . I don't get why with the use of ""without""? Why it is not I will not buy the pants or I will buy the shirt with the use of DeMorgan's Law. I know I am missing something, thank you in advance.","['propositional-calculus', 'logic', 'discrete-mathematics', 'logic-translation']"
3365137,Finding bijection between ordered n-tuple of integers and integers,"I've got a question for an assignment, but I don't really understand the question. I have however thought of a strategy to solve it. I'm looking for an explanation of the question and feedback on my strategy for finding a bijection. Question: Let $S = \{(a_1, a_2, . . . , a_n)| n \geq 1, a_i \in Z^{\geq 0} \text{ for }  i = 1, 2, . . . , n, a_n \neq 0\}$ . Find bijection from set $S$ to set $Z^+$ . What I understand from the question is that $S$ is the set $(a_1,a_2,...,a_n)|n \geq 1$ and each element of that set, $a_i$ , is an element of $Z^{\geq 0}$ , which to me looks like $S=Z$ . What I don't understand is what $\text{ for }  i = 1, 2, . . . , n, a_n \neq 0\}$ means and how it relates to the problem. My strategy for solving this problem is to create a function from $f:S\rightarrow Z^+$ and then to find the inverse function, then use the inverse function to find a bijection for an element of $Z^+$ . Is that the best way to solve this? Also thought about proving the cardinality, $|S|=|Z^+|$ , and saying that implies that the sets are bijective, but I don't know if the tutor would accept that.","['elementary-set-theory', 'functions']"
3365153,"How many numbers $n$ are there such that $\gcd(n,\phi(n)) = 1$?","Let $f(x)$ be the number of such natural numbers $n \le x$ such that $\gcd(n,\phi(n)) = 1$ . Since $\phi(n)$ is even for $n \ge 3$ , hence apart from $1$ and the trivial set of primes, all numbers with the above property must be square free odd composites. But not all square free composites have this property e.g. the number $21$ is an exception. The sequence of odd composite numbers with this property are $15, 33, 35,51,65,69,77, 85,87, 91, 95, \ldots$ My calculations for $x = 6.5 \times 10^9$ suggests that $$
0.23223 < \frac{f(x)}{x} < 0.27863
$$ Question : What is known about the asymptotics of $f(x)$ ? Related question : A conjecture on numbers coprime to its Euler's totient function","['number-theory', 'divisibility', 'asymptotics', 'prime-numbers']"
3365198,question from real analysis?,suppose we are given a function $f$ such that for $x \in \mathbb{R}$ we have the relationship that $ |\sup(f'(x))| < 1 $ . We must to prove that for any $\{s_n\} \in \mathbb{R}$ such that $s_n=f(s_{n-1})$ the sequence is ${s_{n}}$ is convergent. I first used the fact that $ |f'(x)| < 1 $ which would imply that $ -x<f(x)<x $ . Substituting $ x=s_n$ in the relation I get that $s_{n}$ is a decreasing sequence but how to show that it is bounded below so that I can conclude that it is convergent !,"['functions', 'sequences-and-series', 'functional-analysis', 'real-analysis']"
3365266,Guessing the number of other $1$'s in a binary sequence,"Consider the set of all binary sequence of length $n+1$ , $B=\big\{(b_i)_{i=0}^n\,\big| b_i\in\{0,1\}, \forall i\big\}$ . Construct a function $f: \{0,\cdots,n\}\times \{0,1\}\to \{0,\cdots, n\}$ , such that $\forall (b_i)_{i=0}^n\in B,\,\exists i\ni f(i,b_i)=\sum_{j\ne i}b_j$ . What is a systematic way to construct this function? Putting it more colloquially, we assign $n+1$ persons one-to-one to all the digits of an arbitrary binary sequence of length $n+1$ . Each person can see but the digit assigned to him. Devise a strategy so that at least one person guesses correctly the sum of the remaining digits other than his own. Epilogue: It was answered brilliantly on Mathoverflow.net after I posted the question there.","['puzzle', 'information-theory', 'discrete-mathematics', 'recreational-mathematics', 'coding-theory']"
3365279,Interpretation of parametric differentiation,"""How does parametric differentiation make sense both mathematically and graphically?"" I mean the method is simple to understand since one only has to differentiate both equations and divide (generally), but what does it actually mean to differentiate 2 questions and then divide them to find the differential of one with respect to another? I've worked out the idea for the mathematical aspect and realized that $da/db$ is just a ratio so it's just the idea that $a:b = 2:3$ and $b:c = 6:11$ and if one is required to find $a:c$ , he'd divide both. I think same thing holds for differentiation. But then what's the purpose of the notion familiarly stated with derivatives ""derivative of one with respect to another?"" But I was struggling with the graphical interpretation, I got ideas that the graph would become a curved surface in 3D and the tangent will become a plane or that it might be related to partial derivatives and such but I think this is beyond me (class 12 student in India). A detailed explanation is welcome though. Here's one from a snippet of a book,
“ x and y are given as functions of a single variable e.g. x =f(t) and y=g(t) are 2
functions of a single variable. In such a case x and y are called parametric functions or parametric equations and t is called the parameter. To find dy/dx in case of parametric functions, we first obtain
relationship between x and y by eliminating the parameter t and then we differentiate it with respect to x. But, it is not always convenient to eliminate the parameter. Therefore dy/dx can also be by the following formula, $$
\frac{d y}{d x}=\frac{d y / d t}{d x / d t}
$$ I have also found this alongside with it,
“To prove it, let Δx and Δy be the changes in x and y respectively corresponding to small change is Δt in t. Then, $$
\frac{\Delta y}{\Delta x}=\frac{\Delta y / \Delta t}{\Delta x / \Delta t} \Rightarrow \frac{d y}{d x}=\lim _{\Delta x \rightarrow 0} \frac{\Delta y}{\Delta x}=\frac{\lim _{\Delta t \rightarrow 0} \frac{\Delta y}{\Delta t}}{\lim _{\Delta t \rightarrow 0} \frac{\Delta x}{\Delta t}}=\frac{\frac{d y}{d t}}{\frac{d x}{d t}}
$$ So I guess, this takes care of the mathematical aspect (though I'm still not convinced with it) but what about the graphical interpretation?","['ordinary-differential-equations', 'differential', 'calculus', 'implicit-differentiation', 'algebra-precalculus']"
3365309,"If $G \oplus H$ is isomorphic to a proper subgroup of itself, then must the same be true of one of $G$ and $H$?","Let $G$ and $H$ are groups. If $G \oplus H$ is isomorphic to a proper subgroup of itself, then must the same be true of one of $G$ and $H$ ? I found some examples of $G$ such that $G$ has no proper subgroup isomorphic to $G$ . For example, $\mathbb{Q}$ and $\mathbb{Q}\oplus \mathbb{Q}$ has no proper  subgroup isomorphic to each mother group. (The reason: If $f:\mathbb{Q}\oplus \mathbb{Q}\rightarrow\mathbb{Q}\oplus \mathbb{Q}$ is injective group homomorphism, then $f$ is also $\mathbb{Q}$ -module homomorphism, so $f$ is $\mathbb{Q}$ -linear map. So, injectivity of $f$ implies surjectivity of $f$ . This means $\mathbb{Q}\oplus \mathbb{Q}$ has no isomorphic subgroup.) I think there is counter-example of this claim but I can't choose one.. How to prove or take counter-example?","['direct-product', 'group-theory', 'abstract-algebra', 'group-isomorphism']"
3365315,Characterization of the measures in a cocountable $\sigma$-algebra,"I found an interesting exercise in the preprint of Measure, integration and real analysis of Sheldon Axler . Exercise 12 of section 2C says: Suppose $X$ is a set and $\mathcal{S}$ is the $\sigma $ -algebra of all subsets $E$ of $X$ such that $E$ or $X\setminus E$ is countable. Give a complete description of the set of all measures in $(X,\mathcal{S})$ . My try: in first place every singleton is measurable so for every measure $\mu$ on $(X,\mathcal{S})$ there is a function $f_\mu :X\to [0,\infty ]$ such that $$
\mu (\{x\})=f_\mu (x),\quad \text{ for each }x\in X\tag1
$$ and note that if $A$ is a countable set then $$
\mu (A)=\sum_{x\in A}f_\mu (x)\tag2
$$ so it seems, at first glance, that the sets of all measures in $(X,\mathcal{S})$ can be represented by the set of functions $[0,\infty ]^X$ , and indeed this would be the case if $X$ is countable. Now I will try to go further describing more precisely any measure on $(X,\mathcal{S})$ , so let $P:=\{x\in X: f_\mu (x)>0\}$ and assume that $X$ is uncountable. Case 1: $P$ is countable and $\mu (P)<\infty $ , hence $\mu (P^\complement )=\mu (X)-\mu (P)$ so the measure of $P^\complement $ is determined by choosing a value for $\mu (X)\in[\mu (P),\infty ]$ . Case 2: $P$ is countable and $\mu (P)=\infty $ , hence $\mu (X )=\infty $ and the measure of $P^\complement $ can be chosen arbitrarily in $[0,\infty]$ . Case 3: $P$ is uncountable what implies that if $P$ is measurable then $\mu (P)=\mu (X)=\infty $ , because it can be shown that exists some $\epsilon >0$ such that $f_\mu(P)\cap (\epsilon ,\infty )$ is uncountable. In any case, being $P$ measurable or not, this means that every uncountable measurable set have infinite measure because it have an uncountable subset such that every singleton have positive measure. My questions: Is this characterization correct? For the case 2 I dont have a proof about the consistency of giving to $\mu(P^\complement)$ an arbitrary value on $[0,\infty]$ . If this would be correct, how I can prove it rigorously?","['measure-theory', 'proof-verification', 'analysis']"
3365397,Why do we need charts to define a submersion/immersion?,"I am learning the theory of smooth manifolds and have a question on the definitions of a submersion/immersion and its dependency on given charts. Given a smooth map $f:M\mapsto N$ between two smooth manifolds of finite dimension. If I am correct this means that given any chart $\chi$ of $M$ and chart $\chi^\prime$ on $N$ , $$f_{\chi^\prime}^{\chi}=\chi^\prime\circ f\circ\chi^{-1}$$ is smooth in the usual sense of analysis. Now to prove if $f$ is a submersion (or similar an immersion) at $p\in M$ one checks that, $$(df_{\chi^\prime}^{\chi})_{\chi(p)}$$ is surjective\injective. By the chainrule, $$\big(d(\chi^\prime\circ f\circ\chi^{-1})\big)_{\chi(p)}=(d\chi^\prime)_{\chi(p)}\circ(df)_p\circ(d\chi^{-1})_{\chi^{-1}(p)}.$$ But since all charts a homeomorphisms their differentials are isomorfisms. Now my question is, why bother looking at $f_{\chi^\prime}^{\chi}$ if you can just look at whether or not the differential of $f$ is surjective/injecitive? The differentials of the charts are after all isomorfisms. Am i looking at it the right way? Beside that, in the practical situation of having to check wheter or not a map is a submersion/immersion one has to do this for all combination of charts contained in the two atlases which induce the smooth structures, thats a bit cumbersome... Is there a trick/theorem one can use?",['differential-geometry']
3365398,Is there a Math Term for P(A&B)/P(A)P(B)?,"If the ratio is greater than 1, then the posterior probability of either A or B will be higher than the prior probability of either A or B. I suppose it's as if A correlates with B. However, if A correlates with B, then A and B are random variables instead of ""events"". So I wonder if we have something like this in probability. Basically, 2 variables, indicate one another. I wonder if P(A&B)/P(A)P(B) = P(A|B)/P(B) = P(B|A)/P(A) has a name? That name, let's call it L, (I think it should be called evidence strength or something) has an interesting property. It shows how much increase of probability an evidence give and it is always symmetrical. Imagine a drug test with 99% sensitivity and 99% specificity. Imagine .5% drug users. So out of 100000 people tested we have 500 users. 495 of which is tested positive. We also have 99500 non users. 995 of which is tested positive. Here, the probability of user is .5%
Probability of those tested positive is around 1.5% The ratio I am talking about is around 66. If we know a guy is a user, we know how likely he is tested positive. Just multiply the probability of being tested positive by 66 and we get around 33%. If we know a guy is tested positive, we know the probability that he is a user. Just multiply the probability that he is a user, which is .5% by 66 and we get 33% Wow. That means the strength of evidence of one path of reasoning is exactly the same both way. A->B doesn't always mean B->A. However, they increase the probability of the conclusion by the same amount.","['probability-theory', 'probability']"
3365419,"Limit of $f(x, y)$ at $(0, 0)$","I need to show $$\lim_{(x, y) \rightarrow (0,0)} \frac{xy(x^2-y^2)}{(x^2+y^2)^{3/2}} = 0
$$ Not really sure how to go about this without using the epsilon delta definition, which I would prefer not to. Any sort of help is appreciated. Edit: I do have the inequality: $$\frac{xy(x^2-y^2)}{(x^2+y^2)^{3/2}} \le \frac{xy(x^2+y^2)}{(x^2+y^2)^{3/2}} = \frac{xy}{(x^2+y^2)} $$","['limits', 'multivariable-calculus']"
3365467,Range of any non-constant rational function,"$\textbf{Question}$ . We know that the range of any nonconstant complex polynomial is $\mathbb{C}$ by the Fundamental Theorem of Algebra. What can you say about the range of any nonconstant rational function $f$ ? $\textbf{Attempt / thoughts}$ . Write $f=p/q$ and we try to solve $p(z)/q(z)=\lambda$ because this is possible if and only if $\lambda$ is in the range of $f$ . Now define $g(z)=p(z)-\lambda q(z)$ . Solving the previous equation is equivalent to solving $g(z)=0$ except that we need to take care of the case where $q(z)=0$ (I think, I'm not sure). If $g(z)$ is a nonconstant complex polynomial then it will have a root and then we are done. So we consider the values of $\lambda$ such that $g(z)$ is a nonconstant complex polynomial... which I think is hard to determine. Would really appreciate some help on how to proceed or advice on whether I'm on the right track at all.","['complex-analysis', 'functions', 'polynomials']"
3365491,Two Matrices $A$ and $B$ are similar if and only if their characteristic Matrices $xI_n-A$ and $xI_n-B$ are equivalent.,"As a part of an advanced junior undergraduate Linear Algebra course we're trying to prove the following statement: ""Two Matrices $A$ and $B$ are similar if and only if their characteristic Matrices $xI_n-A$ and $xI_n-B$ are equivalent."" where as $A,B \in K^{n \times n}$ , $xI_n-A \in K[x]$ , $K $ is a Field and $K[x]$ is the polynomial ring over $K$ . Equivalence of $xI_n-A$ and $xI_n-B$ in $K[x]$ is defined as: $xI_n-A$ and $xI_n-B$ are equivalent if there exists invertible matrices $S$ and $T$ in $K[x]$ such that $S(xI_n-B)T=xI_n-A$ The first direction of the proof is quite easy, the second one however is much more difficult, in the textbook the lecturer uses an algebraic proof, without explaining the motivation behind it. Here's an overview of the Proof "" $\Rightarrow$ "" There is an invertible Matrix $S$ such that $S^{-1}AS=B$ , multiplication of $S^{-1}(xI_n-A)S$ yields $xI_n-B$ "" $\Leftarrow$ ""  Let $S,T$ be invertible Matrices in $K[x]^{n\times n}$ such that $S(xI_n-B)T=xIn-A$ For every Matrix $C \in K[x]^{n \times n}$ there are Matrices $C_i \in K^{n \times n}$ such that $C= \sum_{x=0}^{m}x^iC_i$ Using this definition we get: $C(A)= \sum_{x=0}^{m}A^iC_i \in K^{n\times n}$ for $A \in K^{n \times n}$ Which implies that for Matrices $C,D \in K[x]^{n\times n}$ and $A \in K^{n \times n}$ : $$
\begin{align*}(C+D)(A) = C(A) + D(A)\end{align*}
$$ $$
\begin{align*}(C \cdot D)(A) = (C(A)\cdot D)(A)\end{align*}
$$ One can verify that $A \cdot S(A) = S(A) \cdot B \quad$ (1) and using induction we get $A^i \cdot S(A) = S(A) \cdot B^i \quad , \forall i \in \mathbb{N}$ We now prove that $S(A)$ is invertible. Because $S \in K[x]^{n\times n}$ is invertible there is $C \in K[x]^{n\times n}$ such that $S \cdot C= I_n$ using the previous results one can verify that $S(A) \cdot C(B)= I_n$ which implies that $S(A)$ is invertible which implies using (1) that $S(A)^{-1} \cdot A \cdot S(A) =B$ and thus the result. So here is my question: how could an undergraduate student come up with the idea for such proof, what are the main ideas/observations that could lead to it? If there is actually no intuition behind the proof, do you know of any alternative solutions to prove it? I've tried to work on it myself but I didn't come far, the reason is that we used this proof to use the Smith Normal form to build the theory of the rational/Frobenius normal form and then the Jordan normal form that's why I would appreciate a proof that doesn't assume the rational form","['abstract-algebra', 'linear-algebra']"
3365534,find all entire functions $f$ such that $f(\frac{1}{n})=f(\frac{1}{n²})$,"I've got determine all entire functions $f$ such that $f(\frac{1}{n})=f(\frac{1}{n²})$ is fullfilled for all $ n\in \mathbb{N}$ . Knowing, that they are entire we can write down both terms as a taylor series around $0$ : $f(1/n)=\sum_{k=0}^\infty a_k(\frac{1}{n})^k=a_0+a_1\frac{1}{n}+a_2\frac{1}{n}^2+a_3\frac{1}{n}^3+a_4\frac{1}{n}^4...$ $f(1/n^2)=\sum_{k=0}^\infty a_k(\frac{1}{n^2})^k=a_0+a_1\frac{1}{n^2}+a_2\frac{1}{n^2}^2+a_3\frac{1}{n^2}^3+a_4\frac{1}{n^2}^4...$ When they are equal, then the coefficients are $0$ for all odd numbers, that is $a_k=0$ for $k=2n+1$ , That means $a_1=a_3=a_5=...=0$ . Then because of the equality of both series we get $a_2=a_1=0$ which then implies $a_4=a_2=0$ and so on. 
 So there is no entire function other then a constant function, right? Is there maybe a more simple proof for this? Edit: My argumentation for $f(0)=0$ is wrong. So $a_0$ is the only coefficent I have.","['complex-analysis', 'entire-functions', 'alternative-proof']"
3365571,Determine whether (¬p ∧ (p → q)) → ¬q is a tautology.,"The answer is not a tautology.
I know the answer based on the true table, however I wanna try another method. Here is my method:
(¬p ∧ (p → q)) → ¬q
≡ ¬(¬p∧(¬p∨q))∨¬q
≡p∨(p∧¬q)∨¬q
≡((p∨p)∧(p∨¬q))∨¬q Which part am I wrong?Thanks for your explanation!",['discrete-mathematics']
3365582,Tensor product of injective linear maps,"Let $X,Y,U,V$ be vector spaces. Let $S:X\to U$ and $T:Y\to V$ be linear maps. Then by linearisation there exists a linear map $$S\otimes T : X\otimes Y \to U\otimes V,\quad x\otimes y \mapsto (Sx) \otimes (Ty). $$ If $S$ and $T$ are injective, then their tensor product is, too. I think I managed to justify this as follows. Note that $U = S(X) \oplus U'$ . Define $S' : U\to X$ such that $S'(S(x_u) +u' ) = x_u$ . One readily verifies linearity and that is a left inverse for $S$ . Analogously, define $T':V\to Y$ . Then by linearisation, there exists linear $$S'\otimes T' : U\otimes V \to X\otimes Y,\quad (S(x_u)+u') \otimes (T(y_v) + v') \mapsto x_u\otimes y_v. $$ This would give a left inverse for $S\otimes T$ hence making it injective. I seem to recall that tensoring injective morphisms between modules does not always preserve injectivity. In fact, a certain module $F$ for which $\mbox{id}_F \otimes \phi$ is injective for all injective morphisms $\phi$ is called flat. What am I invoking here that allows this to work for vector spaces? Is it the decomposition $U=S(X) \oplus U'$ ?","['modules', 'linear-algebra', 'tensor-products', 'functional-analysis', 'linear-transformations']"
3365587,Solve for $x$ from this quadrilateral without using law of cosines.,Solve for $x$ . I would be able to solve this with law of cosines (with a LOT of work!) but the students that this problem was presented are not familiar with law of cosines. Is there something I am missing? My approach would be to calculate the hypotenuse of the right triangle by using Pythagorean theorem. Therefore I would know everything needed to use law of cosines. If needed $y = (3x-4)\tan36°$ . I think there might a simpler solution for this but what is it?,"['quadrilateral', 'geometry']"
3365603,Open mapping $\iff$ bounded inverse $\iff$ closed graph,"I've studied closed graph theorem. In particular I first saw the open mapping theorem, then the bounded inverse theorem and finally the closed graph. I saw the proof that if a linear operator is closed then is bounded. Then my notes state ( $X,Y$ Banach spaces): $$ T:X\to Y  \text{ linear,  then } \\ T \text{ closed} \iff \textit{G}(T)\text{ closed }$$ Now I've some doubts. This statement looks very trivial to me but when I try to prove this I have necessarily to define a norm in $X \times Y$ , e.g. $ ||\cdot||_{X\times Y}=||\cdot||_X+||\cdot||_Y$ and prove it, but this is not a general proof. I give definitions: \begin{align}
& T \text{ is closed if } x_n\to x \text{ and } Tx_n \to y \implies y=Tx \\&
G(T)=\{ (x,y)\in X \times Y: Tx=y \}
\end{align} So the point is this, my notes proved: $$ T  \text{ closed} \iff T \text{ bounded}$$ Then they say $$ T \text{ closed} \iff G(T) \text{ closed}$$ Hence the first theorem can be restated as $$ T \text{ bounded} \iff G(T) \text{ closed}$$ I want to clarify the second $\iff$ .
Moreover it concludes by saying that: $$ \text{Open mapping } \iff \text{Bounded inverse }\iff \text{Closed graph} $$ Im not sure about this. I tryed to prove that $$ \text{Closed graph} \implies \text{Open mapping }$$ But I only managed to prove that if $C$ is closed then $T(C)$ is closed. But $$ T(C^c) \ne T(C)^c$$ unless T is injective, so that I cannot conclude my proof.",['functional-analysis']
3365654,Finding longest sequence such that $4k + 1$ is neither prime nor a perfect square,"What is the largest value of $k$ such that $4k + 1$ produces  maximum consecutive terms which are neither primes nor perfect squares and $k$ is a natural number. For example, at $k = 16$ , we get a sequence of two consecutive terms, 65 and 69 which are neither prime nor square. One of my friend asked me this question and I am unable to solve it. Can anybody please solve it?","['elementary-number-theory', 'prime-numbers', 'sequences-and-series']"
3365745,Two side-by-side squares are inscribed in a semicircle. The diameter of the semicircle is 16. What is the sum of the two squares' areas?,"Two side-by-side squares are inscribed in a semicircle. The diameter of the semicircle is $16$ . What is the sum of the two squares' areas? This is a bonus question from my online math class that I've been trying to solve but haven't gotten very far. I named $CD$ $x$ and $HD$ $y$ , then drew $OB$ and $OF$ , then did the Pythagorean theorem to try to get $x^2+y^2$ but I didn't have much luck with that.","['circles', 'geometry']"
3365754,Distance from a point in a set to a subset of that set is Lipschitz,"The question I'm stuck on is the following: Let $(X,d)$ be a metric space and let $Y$ be a subset of $X$ . If $x\in X$ , define the distance $d(x,Y)$ as $\inf\{(d(x,y):y\in Y\}$ . Show that the mapping from $X$ to $\mathbb{R}:x\rightarrow d(x,Y)$ is Lipschitz , i.e. that there exists a constant $C>0$ such that $|d(x,Y)-d(x',Y)|\le Cd(x,x'), x,x'\in X$ . I'm quite lost as to how to approach it because there is no upper bound for $d(x,x')$ and thus the left side can easily go off to infinity. How can I relate distance between two points and the difference in their distances to $Y$ in a way that one constant works for the entire set?","['metric-spaces', 'lipschitz-functions', 'real-analysis']"
3365776,Definable homeomorphisms in o-minimal geometry,"I am currently working through the proof of the so called ""triangulation theorem"" on page 130 in Lou van den Dries book ""Tame Topology and o-minimal Structures."". Triangulation Theorem: Let $S\subset R^m$ be a definable set, with definable subsets $S_1,...,S_k$ . Then $S$ has a triangulation in $R^m$ that is compatible with these subsets. I got ruminative at the following passage: ""Therefore we modify $F$ as follows to $\tilde{F}$ . Each $f\in F$ extends, first continuously to the
  closure of its domain, and then, by the last remark of (2.3), further to a continuous definable function $\tilde{f}:A\rightarrow R$ ."" I went on and looked up the remark (2.3), which, in my opinion, demands the $\Phi$ function in the definition of a triangulation to be continuous in both directions (i.e. a topological homeomorphism), in order to fullfill. The full ""remark"" (2.3) in vdD book is: (2.3) Definition. Let $A\subset R^m$ be a definable set. A triangulation in $R^n$ of $A$ is a pair $(\Phi,K)$ consisting of a complex $K$ in $R^n$ and a definable homeomorphism $\Phi:A\rightarrow \mid K \mid$ . Note that then $\Phi^{-1}(K):=\left\{ \Phi^{-1}(\sigma): \sigma\in K\right\}$ is a finite partition of A. We call $(A,\Phi^{-1}(K))$ a triangulated set. The triangulation is said to be compatible with the subset $A'\subset A$ if $A'$ is a union of elements of $\Phi^{-1}(K)$ . Note that by Chapter 6.(1.10), we have: A is closed and bounded $\iff$ the complex K is closed (where $A\subset R^m$ is a definable set). In that case each continuous definable R-valued function on $cl(C)$ , where $C\in\Phi^{-1}(K)$ , has a continuous definable R-valued extension to A, by lemma (2.2). Where chapter 6, (1.10) says: (1.10) Proposition. If $f:X\rightarrow R^n$ is a continuous definable map on a closed bounded set $X\subset R^m$ , then $f(X)$ is closed and bounded in $R^n$ . and lemma (2.2) says (2.2) Lemma. Let $K$ be a closed complex in $R^m$ and $L$ a closed subcomplex. Then each continuous definable function $f:\mid L \mid \rightarrow R$ has a continuous definable extension $\tilde{f}:\mid K \mid \rightarrow R$ . So, in order to apply lemma (2.2) we need a closed simplicial complex $K$ , which follows from the continuity of $\Phi$ (here we need the continuity) and proposition (1.10). Since in the proof of the triangulation theorem, the functions $f$ which ought to be extended to $A$ have sets of $\Phi^{-1}(K)$ as a domain, we need to consider $f\circ \Phi$ in the situation of lemma (2.2), which also needs $\Phi$ to be continuous. I am confused a bit now because this paper calls the ""definable homeomorphisms"" in the triangulation theorem ""definable bijections"", hence not necessarily continuous (referring to the attribute of a homeomorphism as structure preserving in case of the ""definable"" structure). Page 4 says: A definable homeomorphism is a tame bijection between tame sets.  To repeat: definable homeomorphisms are not necessarily continuous. When you want to define the so called definable Euler characteristic like on page 4 here Definition 2.2. If $X\in\mathcal{O}$ is tame and $h:X\rightarrow \cup \sigma_i$ is a definable bijection with a collection of open simplices, then the definable Euler characteristic of X is: $\chi(X):=\sum_{i}(-1)^{dim\;\sigma_i}$ , where $dim\;\sigma_i$ is the dimension of the open simplex $\sigma_i$ . We understand that $\chi(\emptyset)=0$ since this corresponds to the empty sum. where, in my opinion, the definable bijection term arises from the understanding of a definable homeomorphism as a definable bijection, because in the same paper the triangulation theorem from van der Dries book is cited as: Theorem 2.1 (Triangulation Theorem [16]). Any tame set admits a definable bijection with a subcollection of open simplices in the  geometric realization of a finite Euclidean simplicial complex. Moreover, this bijection can be made to respect a partition of a tame set into tame subsets. Although page 70 of van den Dries book basically says a definable injection suffices for the well-definedness of the Euler characteristic (2.4) Proposition: If $f:S\rightarrow R^n$ is an injective definable map, then $E(S)=E(f(S))$ . a definable homeomorphism in sense of a definable, bijective, continuous function with continuous inverse, will make life in case of the well-definedness of the definable Euler characteristic much easier, because there wont be any need to refer to (2.4) of van den Dries book. I browsed van den Dries' book a bit, but i didn't find the definition of a ""definable homeomorphisms"". So do they need to be definable, bijective and continous with a continuous inverse or do they only need to be definable and bijective (which leads to a problem with the remark (2.3) above). Thank you in advance, 
Soucerer","['model-theory', 'logic', 'algebraic-geometry', 'abstract-algebra', 'general-topology']"
3365820,"$x =r\cos \theta$ and $y = r\sin\theta$, determine $\frac{\partial r}{\partial x}$ and $\frac{\partial \theta}{\partial x}$","Given that $x =r\cos \theta$ and $y = r\sin\theta$ , determine $\frac{\partial r}{\partial x}$ and $\frac{\partial \theta}{\partial x}$ Attempt: I thought I'd calculate $\frac{\partial x}{\partial r}$ , treat it as a fraction and say $\frac{\partial r}{\partial x} = 1/\frac{\partial x}{\partial r}$ , however that doesn't work. Then I thought I'd set $r = \frac{x}{\cos \theta}$ and differentiate about $x$ , but this path leads to the same result above. I'm not sure how $y = r\sin \theta$ comes into play here. Official Answer: $$ \frac{\partial r}{\partial x} = \cos \theta, \quad \frac{\partial \theta}{\partial x} = \frac{- \sin\theta }{r}$$","['partial-derivative', 'multivariable-calculus']"
3365927,Homomorphism from $S_4$ to $S_3$,"I was reading Artin's Algebra and stumbled upon this example of a homomorphism $\phi:S_4 \to S_3$ . See here and here for the example. My question is what motivates the partition of the set into pairs of subsets of order 2. The text never bothers to explain the reason behind the move. In addition, the writer claims that ""An element of the symmetric group $S_4$ permutes the four indices, and by doing so it also permutes these three partitions."" What does it even mean to permute the partitions? How does permuting the partitions correspond to permuting the indices? Then I got completely lost when he says $(1\ 2\ 3\ 4)$ acts on the set $\{\Pi_1,\Pi_2,\Pi_3\}$ as $(\Pi_1\ \Pi_3)$ . Exactly how are they the same?","['group-homomorphism', 'group-theory']"
3365942,Show $\mathrm{det}(M)$ is well defined.,"One intuitive way to approach studying the determinant of a given matrix $M$ is to inspire its formal definition in the signed volume of applying the corresponding transformation to the unit $n$ -cube. By noticing that $M = E_1...E_nM^R$ where $E_i$ is an elementary matrix and $M^R$ is the row reduced echelon form of $M$ one could define $\mathrm{det}(M)$ as $\frac{\prod^{}_{} \mathrm{diag}(M^R)}{p}$ , where $p = \prod^{}_{}\mathrm{det}(E_i)$ . The issue is that one could arrive at $M^R$ in more than one way, so that the elementary matrices may differ, so might $p$ . How could one then prove that regardless of how one computes $M^R$ the product of the resulting elementary matrices will always be the same, that is, how could one prove that the above definition of the determinant is well defined? Would appreciate any help.","['determinant', 'proof-writing', 'matrices', 'linear-algebra', 'linear-transformations']"
3365967,Determine values for which the general solution converges,"Textbook problem. Given the following general solution to a recurrence relation $$z_n = \alpha(1+\sqrt{3})^n + \beta(1-\sqrt{3})^n$$ For which values $\alpha, \beta$ does the solution converge? And determine the order of the rate of convergence for these values. By attempting to plot the sequence in some interval with varying values of $\alpha, \beta$ it seems like it will converge whenever $\alpha=0$ and $\beta = (-\infty, \infty)$ , but how can i go about determining this in a more rigorous way?","['convergence-divergence', 'numerical-methods', 'analysis', 'real-analysis']"
3366017,12 donuts split to 5 children,"Suppose you buy 12 identical donuts and wish to give them to the 5 children you are babysitting. How many different ways
can you distribute the donuts if:
(a) there are no restrictions My answer for this question is, A) Combination with Repetition: (n+r-1,r) = (12+5-1,5) = (16,5) B) But some people are getting different answers: (n+r-1,r) = (12+5-1,4)  = (16,4)
using the logic:
00|00|0000|000|0
there need to be 4 dividers to divide into 5 groups. Please tell me which one is the right answer.","['combinatorics', 'discrete-mathematics']"
3366026,"Did I solve this right? Simplify $\frac{\sqrt[3]{x^2}}{\sqrt[6]{x}}$, I got $\sqrt x$","$$\frac{\sqrt[3]{x^2}}{\sqrt[6]{x}}$$ I got $\sqrt x$ . The question says ""Simplify the following expressions (defined in their respective domains)"". The domain of the one I got isn't exactly the same as the domain of the one given because of the zero... is this correct? If not where did it go wrong and how do I fix it?","['calculus', 'algebra-precalculus']"
3366039,A group of important generating functions involving harmonic number.,"How to prove the following identities: $$\small{\sum_{n=1}^\infty\frac{H_{n}}{n^2}x^{n}=\operatorname{Li}_3(x)-\operatorname{Li}_3(1-x)+\ln(1-x)\operatorname{Li}_2(1-x)+\frac12\ln x\ln^2(1-x)+\zeta(3)}\tag1$$ $$\small{\sum_{n=1}^\infty\frac{H_{n}^{(2)}}{n}x^{n}=\operatorname{Li}_3(x)+2\operatorname{Li}_3(1-x)-\ln(1-x)\operatorname{Li}_2(1-x)-\zeta(2)\ln(1-x)-2\zeta(3)}\tag2$$ $$\sum_{n=1}^\infty (H_n^2-H_n^{(2)})x^{n}=\frac{\ln^2(1-x)}{1-x}\tag3$$ $$\sum_{n=1}^\infty\frac{H_{n}^2}{n}x^{n}=\operatorname{Li}_3(x)-\ln(1-x)\operatorname{Li}_2(x)-\frac13\ln^3(1-x)\tag4$$ $$\small{\sum_{n=1}^\infty H_n^3x^n=
\frac{\operatorname{Li}_3(x)+3\operatorname{Li}_3(1-x)+\frac32\ln x\ln^2(1-x)-3\zeta(2)\ln(1-x)-\ln^3(1-x)-3\zeta(3)}{1-x}}\tag5$$ $$\small{\sum_{n=1}^\infty H_nH_n^{(2)}x^n=
\frac{\operatorname{Li}_3(x)+\operatorname{Li}_3(1-x)+\frac12\ln x\ln^2(1-x)-\zeta(2)\ln(1-x)-\zeta(3)}{1-x}}\tag6$$ $$\sum_{n=1}^\infty\left(H_n^3-3H_nH_n^{(2)}+2H_n^{(3)}\right)x^n=-\frac{\ln^3(1-x)}{1-x}\tag7$$ Edit: Here is some extra identities and proofs in the answer sections $$\sum_{n=1}^\infty \frac{H_n^{(3)}}{n}x^n=\operatorname{Li}_4(x)-\ln(1-x)\operatorname{Li}_3(x)-\frac12\operatorname{Li}_2^2(x)\tag8$$ $$\sum_{n=1}^\infty\frac{ H_n^{(2)}}{n+1}x^{n}=\frac{2\operatorname{Li}_3(1-x)-\operatorname{Li}_2(1-x)\ln(1-x)-\zeta(2)\ln(1-x)-2\zeta(3)}{x}\tag{9}$$ $$\small{\sum_{n=1}^\infty\frac{ H_n^{2}}{n+1}x^{n}=\frac{6\operatorname{Li}_3(1-x)-3\operatorname{Li}_2(1-x)\ln(1-x)-\ln^3(1-x)-3\zeta(2)\ln(1-x)-6\zeta(3)}{3x}}\tag{10}$$ Note: Proofs for (3) and (7) should be done without using the formula of the sterling number of the first kind : $\frac{\ln^k(1+x)}{k!}=\sum_{n=k}^\infty(-1)^{n-k} \begin{bmatrix} n \\  k \end{bmatrix}\frac{x^n}{n!}$ .","['integration', 'harmonic-numbers', 'polylogarithm', 'generating-functions', 'sequences-and-series']"
3366044,Is $\infty + (\infty/\infty)$ indeterminate?,"I know $ (\infty/\infty)$ is indeterminate, but it can't be less than $0$ . So can you assume $\infty + (\infty/\infty)$ is determinate because $\infty + n$ where $n\ge 0$ is still $\infty$ ? The equation this question is based off of is $$\lim_{n \to \infty} \frac{n \log n + n}{\log n}.$$ This is in the context of big O notation. Would this be form be valid to use to determine the numerator's function is big Omega of the denominator? Or should l'hopitals rule be used to find a determinate and defined limit?","['indeterminate-forms', 'limits', 'infinity']"
3366064,How deep is the liquid in a half-full hemisphere?,"I have a baking recipe that calls for $1/2$ tsp of vanilla extract, but I only have a $1$ tsp measuring spoon available, since the dishwasher is running. The measuring spoon is very nearly a perfect hemisphere. My question is, to what depth (as a percentage of hemisphere radius) must I fill my teaspoon with vanilla such that it contains precisely $1/2$ tsp of vanilla? Due to the shape, I obviously have to fill it more than halfway, but how much more? (I nearly posted this in the Cooking forum, but I have a feeling the answer will involve more math knowledge than baking knowledge.)","['calculus', 'trigonometry', 'volume']"
3366073,Finding the gradient and Hessian of $\frac{1}{2}|Ax-By|^2$,"I'm trying to compute the gradient and Hessian of the following function $$f(x,y) = \frac{1}{2}|Ax-By|^2$$ where $A$ and $B$ are $m \times n$ matrices, $x, y \in \mathbb{R}^n$ , and $f: \mathbb{R}^{2n} \to \mathbb{R}$ . I honestly don't have a clue on the best way to proceed. Usually, to find the gradient, I would rewrite the function in sums and derive from there - but the square and multiple vector arguments have me stumped. I am not looking for a solution but rather a hint on where to start. Furthermore, am I right in thinking that $\nabla f(x,y)$ is a vector in $\mathbb{R}^{2n}$ consisting of the partial derivatives along $x$ and $y$ , and $\nabla^2 f(x,y)$ to be a $2n \times 2n$ matrix? Thank you in advance.","['multivariable-calculus', 'matrix-calculus', 'derivatives', 'hessian-matrix', 'quadratics']"
3366097,CLT for maximum of random walk,"Consider a symmetric random walk. Let $M_n = \max\{0,S_1,\cdots,S_n\}$ . I want to find $$\lim_{n\to\infty} Pr( M_n / \sqrt{n} \leq x) $$ I know how to calculate $Pr(M_n = m)$ and how it is connected to the $Pr(S_n = k)$ and I want to use it in my proof, but do not really now how.
My best bet is using Central Limit theorem. Would appreciate if someone can help me with tying these two things together.","['statistics', 'probability-theory', 'random-walk']"
3366101,What is Banach's Homogeneous Space Problem of 1932?,"I have seen some references to Banach's homogeneous space problem from 1932 which was solved by Gowers. Could I ask what this problem actually states, I have tried searching and cannot find anything (or nothing which was free access anyway).","['banach-spaces', 'functional-analysis']"
3366139,Proving a formula for the area of a parallelogram from coordinates,"I have this simple (high school level) exercise: The $ABCD$ quadrilateral is a parallelogram of vertices $A(0;0)$ , $B(20;10)$ and $D(10,y)$ . If your area is $600$ , what is the measure of $y$ ? I have thought that the area of the parallelogram is: $$\mathcal{A}_{\text{area}}=|ad-bc| \tag{1}$$ Hence I will have as solutions: EDIT by comment: $$600=|ad-bc|=|100-20(y+10)|\iff y=-35\quad \mathrm{or}\quad \:y=25.$$ but the solution is $y=35$ and this way not give me the solution of the problem, why? Question: Why with the $(1)$ have I not to find the solution? Is there a simpler proof of $(1)$ like to that have I put? Proof: If I have two vectors $\bar a$ and $\bar b$ then area of a parallelogram is: $$|\bar a\times \bar b|=ab|\sin(\theta)|=ab\sqrt{1-\cos^2(\theta)}\tag{2}$$ Now $$\cos(\theta)=\frac{\bar a\cdot\bar b}{ab} \tag{3}.$$ Replacing the $(3)$ in the $(2)$ we get: $$|\bar a\times \bar b|=ab\sqrt{1-\cos^2(\theta)}=ab\sqrt{1-\left(\frac{\bar a\cdot\bar b}{ab}\right)^2}$$ $$=\sqrt{a^2b^2\left(1-\left(\frac{\bar a\cdot\bar b}{ab}\right)^2\right)}=\sqrt{(\bar a \cdot \bar a)(\bar b \cdot \bar b)-(\bar a\cdot\bar b)^2}. \tag{4}$$ If $\bar a=(a_1,a_2)$ and $\bar b=(b_1,b_2)$ we have from $(4)$ that: $$=\sqrt{(a_1^2+a_2^2)(b_1^2+b_2^2)-(a_1b_1+a_2b_2)^2}$$ or $$=\sqrt{(a_1b_2-a_2b_1)^2}=|a_1b_2-a_2b_1|$$ This gives $(1)$ . $\square$","['euclidean-geometry', 'analytic-geometry', 'area', 'vectors', 'geometry']"
3366161,Is $\sin \infty$ an indeterminate form?,"I had a long discussion in chat over what seems like a simple question: Is $\sin \infty$ an indeterminate form ? What do you think? :) I'm labelling this as (soft-question) to be safe, but it should have a clear answer depending on the definition of indeterminate form used.
The term ""indeterminate form"" is seldom used in post-calculus mathematics, but I believe it has one or more accepted definitions, which are either informal or formal. So any answer which takes a standard definition and argues the case would be interesting to me. How to make a good answer: State the definition of indeterminate form, either from an online or textbook source, or a definition you came up with on your own. Determine, using your stated definition, whether $\sin \infty$ is indeterminate or not. EDIT: What do I mean by $\sin (\infty)$ ? It's not a well-defined expression, but neither are any of the other indeterminate forms: $\frac{0}{0}$ doesn't exist, $1^\infty$ , doesn't exist, and so on. So the question is whether this expression -- which is not well-defined, just like any other indeterminate form -- is an indeterminate form.","['indeterminate-forms', 'limits', 'calculus', 'soft-question']"
3366180,More examples of maximal non-normal subgroups?,"I'm looking for examples of maximal non-normal subgroups. From another post I found the example of {(1), (12)} in $S_3$ but would like some more to help get my mind around the concept. Anyone have more examples?","['group-theory', 'abstract-algebra']"
3366182,Series$\sum_{n=1}^\infty\big((1+1/n)^n-e\big)$,"I can't figure out whether this series is convergent. I'm trying to use d'Alembert or Cauchy ratio tests, but however far I go with Taylor series it always ends up being one.
The series is : $$\sum_{n=1}^\infty \big((1+1/n)^n-e\big)$$",['sequences-and-series']
3366187,A proof in module theory: a set theoretic consideration $|\bigcup_{i \in I} B_i| \leq |Y|$,"The set-theoretic result used in the proof I want to know about is the following: Let $(B_i)_{i \in I}$ be a family of sets such that, for all $i,j \in I$ , either $B_i \subseteq B_j$ or $B_j \subseteq B_i$ holds and, for all $i \in I$ , $|B_i| \leq |Y|$ . Then $|\bigcup_{i \in I} B_i| \leq |Y|$ . Which conditions must be true (if any) for this to hold, and why? I tried to put a well-order on both $I$ and $Y$ , but didn't succeed even with that. This seem to be implicitly assumed in the following proof (the book is Abstract Algebra by Grillet). If this inequality is not true in the general case, I wonder if there is a condition in the proof that make it true.","['well-orders', 'free-modules', 'modules', 'abstract-algebra', 'elementary-set-theory']"
