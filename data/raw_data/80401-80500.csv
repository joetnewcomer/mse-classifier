question_id,title,body,tags
1039597,How to analyse a random walk with random transition probabilities,"Consider a $1$-dimensional random walk with discrete time steps. We start at the origin and at each integer position there is possibly different probability of moving right one step, or left one step. For each position $i$ a single coin toss is made to fix the transition probabilities at that position. With probability $1/2$ there  is a probability of moving right of $2/3$ and probability of moving left of $1/3$. With probability $1/2$ there is a probability of moving left of $2/3$ and probability of moving right of $1/3$. For a given position $i$ this coin toss is only ever done once so the transition probabilities for that position are then fixed forever. If you start at the origin, how far away do you expect to be after $n$ steps?  I would be happy with a large $n$ approximation if that is easier.","['random-walk', 'probability']"
1039599,Commutators in a group,"Let $G$ be a group and for $x,y\in G$, define $[x,y]=x^{-1}y^{-1}xy$ to be the commutator of $x$ and $y$. If $y_1,\cdots,y_n\in G$, is it true that $[x,y_1\cdots y_n]$ can be written of a product of conjugates of $[x,y_i]$ with $i=1,\cdots,n$? Namely, is it true that there exist elements $g_1,\cdots,g_n\in G$ such that $$[x,y_1\cdots y_n]=[x,y_{j_1}]^{g_1}\cdots[x,y_{j_n}]^{g_n},$$ where $\{j_1,\cdots,j_n\}=\{1,\cdots,n\}$ and $[x,y_{j_i}]^{g_i}=g_i^{-1}[x,y_{j_i}]g_i$?","['group-theory', 'abstract-algebra']"
1039605,Hard sum with harmonics numbers [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Prove or disprove that $S=\displaystyle\sum_{n=1}^{\infty}\frac{{H_n^{2}}~{H_n^{(2)}}+3{H_n^{(4)}}}{n~2^n}=\frac{25}{16}\zeta(5)+\frac{7}{8}\zeta(2)\zeta(3)$.","['calculus', 'integration', 'definite-integrals', 'harmonic-numbers', 'polylogarithm']"
1039606,Finding the limit without L'Hopital's rule,"$$\lim_{h\to 0}\frac{\cos(x_0+h)-\cos(x_0)}h \quad\text{as } x_0\in(0,\pi)$$ I did actually do it without L'Hopital rule as I just multiplied the top and bottom of the conjugate of the top of the fraction and just went from there, using the addition formula for the cosine. But this was extremely tedious. I was wondering if there is an easier way. The answer to this gives $-\sin(x_0)$.",['limits']
1039622,Continuous functions satisfying $f(x)+f(2x)=0$?,"I have to find all the continuous functions from $\mathbb{R}$ to $\mathbb{R}$ such that for all real $x$,
$$f(x)+f(2x)=0$$ I have shown that $f(2x)=-f(x)=f(x/2)=-f(x/4)=\cdots$ etc. and I have also deduced from the definition of continuity that for any $e>0$, there exists a $d>0$ so if we have that: $|2x-x|=|x|< d$, this implies that $|f(2x)-f(x)|=|-2f(x)| < e$. Is this the correct way to begin? And if so, how should I continue? Thank you!","['continuity', 'functions']"
1039641,"Given a probability distribution, how many times do I have to repeat an experiment so see a certain outcome","My question concerns random number generation under certain constraints. I assume that the random number generator is good enough to generate uniformly distributed numbers. This means that each number has the probability 1/N to occur. How many times should I repeat the experiment (generating a random number) such that it's is very likely that a see a certain number. I think there was a theorem that could give me a value, given a certain bound on how certain I want to be that the event happened (i.e. if I want to be 50% certain that it appears I run it x times, if I want to be 99% certain I run it y times, with x < y ).","['probability-distributions', 'probability']"
1039651,"Does (Z, +) have two generators but infinitely many generating sets?","We say the group of integers under addition Z has only two generators, namely 1 and -1. However, Z can also be generated by any set of 'relatively prime' integers. (Integers having gcd 1). I have two questions here. Couldn't find a satisfactory answer anywhere. If a group is generated by a set consisting of a single element, only then is it cyclic? Does 'generator' mean a single generating element? Is it correct to say '(Z, +) has two generators but infinitely many generating sets'? Thank you for your help!","['cyclic-groups', 'group-theory', 'abstract-algebra']"
1039664,"Simple proof that there is no isomorphism between any two of $ Aut(\hat{C}) $(Riemann Sphere),$ Aut(H^+) $(upper half plane) and $ Aut(C) $","Referring the groups of automorphisms (holomorphic bijections) of the respective domains. This is a homework problem. Is a basic course, so sophisticated answers may not be of help (it has a simple solution according to my teacher).  Also, it looks like an Algebra problem, but I’ve been assured that there is a solution within complex analysis, so if anyone can give a non algebraic proof, it will be appreciated. I tried constructing a conformal mapping (between two of the domains) using a supposed isomorphism, also calculate the unit roots (of second degree, and some of higher degree) in each of the groups, and a couple ideas more, but with no luck. 
Thanks in advance for your help (and sorry about my poor English). Edit:The question was edited to avoid sophisticated algebraic answers.  Please, just use the very basic of algebra in your solution. Is a complex analysis exercise! (of course, if you just want to share a sohpisticated answer that can help other users, welcome.)",['complex-analysis']
1039685,Probability of an integer being a prime,"$\Omega=\mathbb{N}^*,P(\omega=n)=\dfrac{1}{2^n}$, let $A_k$ be the event $k\mid\omega$. 1) Find $P(A_k)$ 2) Let B be the event ""$\omega$ is prime"", show that $\frac{13}{32}<P(B)<\frac{209}{504}$ One can see easily that $P(A_k)=\dfrac{1}{2^k-1}$ To find $P(B)$, I did the following : $$\begin{align} P(B)&=\displaystyle\sum_{n\in\mathbb{N}^*}P(\omega=n)P\left(\bigcap_{k=2}^{\lfloor\sqrt{n}\rfloor}\overline{A_k}\right)
\\&=\sum_{n\in\mathbb{N}^*}\dfrac{1}{2^n}\left(1-P\left(\bigcup_{k=2}^{‌​\lfloor\sqrt{n}\rfloor}{A_k}\right)\right)
\\&\le\sum_{n\in\mathbb{N}^*}\dfrac{1}{2^n}\left(1-\sum_{k=2}^{\lfloor\sqrt{n}\rfloor}P\left(A_k\right)‌​\right)
\\&=\sum_{n\in\mathbb{N}^*}\dfrac{1}{2^n}\left(1-\sum_{k=2}^{\lfloor\sqrt{n}\rfloor}\dfrac{1}{2^k-1}\right)\end{align}$$ However, I cannot find a good simplification of that bound.","['prime-numbers', 'probability']"
1039695,Theorem 3.54 (about certain rearrangements of a conditionally convergent series) in Baby Rudin: A couple of questions about the proof,"Here's the statement of Theorem 3.54 in Principles of Mathematical Analysis by Walter Rudin, 3rd edition: Let $\sum a_n$ be a series of real numbers which converges, but not absolutely. Suppose 
  $$-\infty \leq \alpha \leq \beta \leq +\infty.$$
  Then there exists a rearrangement $\sum a_n^\prime$ with partial sums $s_n^\prime$ such that 
  $$\lim_{n\to\infty}\inf s_n^\prime = \alpha, \ \ \ \mbox{ and } \ \ \ \lim_{n\to\infty}\sup s_n^\prime = \beta.$$
  [ Rudin has numbered this set of inequalities as (24). ] Now I've got a couple of questions regarding Rudin's proof: First, when he has taken real-valued sequences $\{\alpha_n\}$, $\{\beta_n\}$ such that $\alpha_n \to \alpha$, $\beta_n \to \beta$. But then he has also required that $\alpha_n < \beta_n$ and $\beta_1 > 0$. Now is either of  these two inequalities necessary for the proof to proceed, especially $\beta_1 > 0$? Second, in the very last sentence Rudin states: ""Finally, it is clear that no number less than $\alpha$ or greater than $\beta$ can be a subsequential limit of the partial sums of (25)."" How is this statement true? I mean how to explicitly verify this? For those who haven't got a copy of Rudin on hand, I'll edit this question to reproduce Rudin's proof in its entirety. Let $$p_n = \frac{|a_n| + a_n}{2}, \ q_n = \frac{|a_n| - a_n}{2} \ (n = 1, 2, 3, \ldots). $$ 
  Then $p_n - q_n = a_n$, $p_n + q_n = |a_n|$, $p_n \geq 0$, $q_n \geq 0$. The series $\sum p_n$, $\sum q_n$ must both diverge. For if both were convergent, then $$\sum \left( p_n + q_n \right) = \sum |a_n|$$ would converge, contrary to hypothesis. Since $$ \sum_{n=1}^N a_n = \sum_{n=1}^N \left( p_n - q_n \right) = \sum_{n=1}^N p_n - \sum_{n=1}^N q_n,$$ divergence of $\sum p_n$ or convergence of $\sum q_n$ (or vice versa) implies divergence of $\sum a_n$, again contrary to hypothesis. Now let $P_1, P_2, P_3, \ldots$ denote the non-negative terms of $\sum a_n$, in the order in which they occur, and let $Q_1, Q_2, Q_3, \ldots$ be the absolute values of the negative terms of $\sum a_n$, also in their original order. The series $\sum P_n$, $\sum Q_n$ differ from $\sum p_n$, $\sum q_n$ only by zero terms, and are therefore divergent. [ In fact both these series diverge to $+\infty$. Am I right? ] We shall construct sequences $\{m_n \}$, $\{k_n\}$, such that the series $$ P_1 + \cdots + P_{m_1} - Q_1 - \cdots - Q_{k_1} + P_{m_1 + 1} + \cdots + P_{m_2} - Q_{k_1 + 1} - \cdots - Q_{k_2} + \cdots, $$ which clearly is a rearrangement of $\sum a_n$, satisfies (24). [ Rudin has numbered the last expression as (25). ] Choose real-valued sequences $\{ \alpha_n \}$, $\{ \beta_n \}$ such that $\alpha_n \rightarrow \alpha$, $\beta_n \rightarrow \beta$, $\alpha_n < \beta_n$, $\beta_1 > 0$. [ What if $\beta_1 \leq 0$? What if $\alpha_n \geq \beta_n$ for some $n$? What will go wrong? ] Let $m_1$, $k_1$ be the smallest integers such that $$P_1 + \cdots + P_{m_1} > \beta_1,$$ $$P_1 + \cdots + P_{m_1} - Q_1 - \cdots - Q_{k_1} < \alpha_1;$$  let $m_2$, $k_2$ be the smallest integers such that $$P_1 + \cdots + P_{m_1} - Q_1 - \cdots - Q_{k_1} + P_{m_1 + 1} + \cdots + P_{m_2} > \beta_2,$$ $$P_1 + \cdots + P_{m_1} - Q_1 - \cdots - Q_{k_1} + P_{m_1 + 1} + \cdots + P_{m_2} - Q_{k_1 + 1} - \cdots - Q_{k_2} < \alpha_2;$$ and continue in this way. This is possible since $\sum P_n$, $\sum Q_n$ diverge. If $x_n$, $y_n$ denote the partial sums of (25) whose last terms are $P_{m_n}$, $-Q_{k_n}$, then $$ | x_n - \beta_n | \leq P_{m_n}, \ \ \ |y_n - \alpha_n | \leq Q_{k_n}. $$ Since $P_n \rightarrow 0$, $Q_n \rightarrow 0$ as $n \rightarrow \infty$, we see that $x_n \rightarrow \beta$, $y_n \rightarrow \alpha$. Finally, it is clear that no number less than $\alpha$ or greater than $\beta$ can be a subsequential limit of the partial sums of (25). [ How do we show this? ]","['conditional-convergence', 'sequences-and-series', 'real-analysis', 'analysis']"
1039768,Similar to Cauchy inegral formula,"Let $f=u+iv$ be an analytic function in disk $\mathbb{D}$ and $0<r<1$.
Can you help me to prove that $$\pi{r}f'(0)=\int_{0}^{2\pi}\frac{u(re^{i\theta})}{e^{i\theta}}d\theta\;\;\;?$$ I tried with the Cauchy integral formula, but unsuccessfully.",['complex-analysis']
1039777,Locus of a point $P$ inside $\triangle ABC$,"$P$ is a point inside $\triangle ABC$. $X$, $Y$ and $Z$ are feet of perpendiculars from $P$ on $BC$, $CA$ and $AB$ respectively. Find the locus of $P$ if $XY=XZ$ and $A \equiv (4,3)$, $B \equiv (4,7)$, $C \equiv (6,6).$ One way I can think of is by writing the equation of the lines $PX$, $PY$ and $PZ$ and find $X$, $Y$ and $Z$ in terms of the co-ordinates of $P$ by finding the intersection of these lines with the sides of the triangle. Then, using the distance formula, imposing the given condition. But doing this is lengthy and  not feasible in a test. Is there a way to find the locus elegantly using geometry?","['geometry', 'triangles', 'coordinate-systems']"
1039785,"example of a sequence $f_n$, $n=1,2...$ of integrable functions converging to $f$ s.t limit of integral of $f_n$ does not exist","Is there an example of a sequence of of functions $f_n$ converging to a function $f$ such that $f_n$, $n=1,2...$ are integrable and nonegative and their integral over a measurable set $A$ is less than a finite $K$ for all $n$
, however the limit of integral of $f_n$ on $A$ does not exist? I am just trying to understand why Fatou theorem has $\liminf$ of integral of $f_n$. Thank you","['lebesgue-integral', 'measure-theory']"
1039797,How to find the number of right-angled triangles with integer sides and inradius $2009$?,"Problem: How to find the number of right-angled triangles with integer sides and inradius $2009$ . Please help, as I have no clue how to proceed with this problem. I do know that the inradius of a right-angle triangle with sides $a$ , $b$ , and $c$ is given by $$r = \frac{ab}{a+b+c}.$$","['geometry', 'triangles']"
1039819,Connected sum of projective plane $\cong$ Klein bottle,"How can I see that the connected sum $\mathbb{P}^2 \# \mathbb{P}^2$ of the projective plane is homeomorphic to the Klein bottle? I'm not necessarily looking for an explicit homeomorphism, just an intuitive argument of why this is the case. Can we see it using fundamental polygons?",['general-topology']
1039829,Asymptotics of $\prod_{x=1}^{\lceil\frac{n}{\log_2{n} }\rceil} \left(\frac{1}{\sqrt{n}} + x\left(\frac{1}{n}-\frac{2}{n^\frac{3}{2}} \right)\right) $,"I am trying to work out the large $n$ asymptotics of $$S_n = \prod_{x=1}^{\lceil\frac{n}{\log_2{n} }\rceil} \left(\frac{1}{\sqrt{n}} + x\left(\frac{1}{n}-\frac{2}{n^\frac{3}{2}} \right)\right) .$$ Here is my attempt so far $$\prod_{x=1}^{k} (A + Bx) = \frac{B^k \Gamma(k+1+A/B)}{\Gamma(1+A/B)}.$$ In our case $A/B \approx \sqrt{n}$ and $\left(\frac{1}{n}-\frac{2}{n^\frac{3}{2}} \right) \approx \frac{1}{n}$.  Therefore $$S_n \approx \frac{\frac{1}{n}^{\frac{n}{\log_2{n}}} \left(\frac{n}{\log_2{n}} + \sqrt{n}\right)!}{\sqrt{n}!}$$ I am not really sure where to go from here, if I haven't already taken an approximation too far. I tried taking logs and defining in maple f:=(x,n)-> log(1/sqrt(n)+x*(1/n-2/n^(3/2))) Now if you do plot(-(sum(f(x, n), x = 1 .. n/log(n))), n = 10 .. 100) you get what looks like a linear function of $n$. However if you do limit(-(sum(f(x, n), x = 1 .. n/log(n)))/n, n = infinity) you get $0$.","['asymptotics', 'calculus', 'real-analysis']"
1039831,What are the connections between the three Mertens' theorem?,"In number theory the three Mertens' theorems are the following. Mertens' $1$st theorem. For all $n\geq2$ $$\left\lvert\sum_{p\leqslant n} \frac{\ln p}{p} - \ln n\right\rvert \leq 2.$$ Mertens' $2$nd theroem. $$\lim_{n\to\infty}\left(\sum_{p\le n}\frac1p -\ln\ln n-M\right) =0,$$ where $M$ is the Meissel–Mertens constant . Mertens' $3$rd theroem. $$\lim_{n\to\infty}\ln n\prod_{p\le n}\left(1-\frac1p\right)=e^{-\gamma},$$ where $\gamma$ is the Euler–Mascheroni constant . What connections are there between in this three theorems, beside that all of them about prime series and products? What relationships are behind the scenes? I know that the $2$nd theorem is connected to prime number theorem , and the other two theorems? The motivation of the question is this really nice answer .","['prime-numbers', 'sequences-and-series', 'calculus', 'number-theory']"
1039834,finding the period of $\sin(2x+3)$,"I tried to find the period of $\sin(2x+3)$; looking for $p>0$ such that $ \sin(2(x+p)+3)=\sin(2x+3),$ for all $ x \in R$ which means:  $ \sin(2(x+p)+3)  - \sin(2x+3)= 0 ,$ for all $ x \in R$ that is $\sin(p)\cdot \cos(2x+3+p)=0$, for all $ x \in R$ I'm not sure how to continue....","['calculus', 'functions', 'periodic-functions']"
1039863,Modulo: Calculating without calculator??,"Calculate the modulo operations given below (without the usage of a calculator): $101 \times 98 \mod 17 =$ $7^5 \mod 15 =$ $12^8 \mod 7 =$ $3524 \mod 63 =$ $−3524 \mod 63 =$ Ok with calculator I have no problem with it. However, I need to learn how can I compute them without calculator.","['modular-arithmetic', 'discrete-mathematics']"
1039864,Show that $\lim_{x \to +\infty}\left(f(x)+f'(x)\right)=0 \Rightarrow \lim_{x \to +\infty} f(x)=0$,How to show that $\lim_{x \to +\infty}(f(x)+f'(x))=0 $ implies $\lim_{x \to +\infty} f(x)=0$?,"['calculus', 'derivatives', 'limits']"
1039887,The inverse of $(I-A)$ and the spectral radius of a nonnegative $A$ matrix,"Suppost that $A$ is a nonnegative matrix , and let denote the identitiy matrix with $I$ and the spectral radius of $A$ with $\rho(A)$. Note that because $A$ is nonnegative according to the Perron–Frobenius theorem $\rho(A) = \lambda_\max(A)$. Statement. The following two are equivalent $I-A$ matrix is invertible and $(I-A)^{-1}$ is a nonnegative matrix $\lambda_\max(A) < 1$. Note that because of the statement we also know that the Neumann series of $A$ convergent. Question. How could we prove this statement?","['matrices', 'linear-algebra', 'inverse', 'eigenvalues-eigenvectors']"
1039896,Sigma-algebra generated by a set of random variables,"I know from standard textbooks that ""Given the measurable functions $X_i:(\Omega,\mathcal{F})\rightarrow(\Omega_i,\mathcal{A}_i)$, the $\sigma$-algebra generated by a set of random variables $(X_i; i\in I)$ is given by
\begin{equation}
\sigma\big(X_i;~i\in I\big)=\sigma\left(\bigcup_{i\in I}\sigma(X_i)\right)=\sigma\left(\bigcup_{i\in I} X_i^{-1}(\mathcal{A}_i)\right)"".
\end{equation}
I could understand this idea conceptually, but when this becomes to the real examples I am a bit confused. For example, suppose that $I$ is a discrete time set $I=\mathbb{N}$ and $X_i:\Omega\rightarrow\mathbb{R}$ denotes the number of heads in $i$th draw of a coin. Now it is clear that e.g.
\begin{align}
\sigma(X_1)=\big\{\emptyset,\{T\},\{H\},\Omega\big\} ~~etc..
\end{align}
My questions are as follows: What would then be the exact elements of $\sigma(X_1,X_2,...,X_k)=:\mathcal{F}_1^k$ for some $k\in\mathbb{N}$? (say when $k=2$?) Should I distinguish the events H and T in $i$th draw from those in $j$th draw? ($i\ne j$) Does this idea hold also for the random vector? That is, $\sigma(X_1,X_2)=\sigma(Y)$ where $Y$ is a random vector defined as $Y=(X_1,X_2)^{T}$ (with $T$ being transpose), and $I$ is now obviously $\{1,2\}$. Many thanks in advance, John.","['probability-theory', 'stochastic-processes', 'measure-theory', 'mixing']"
1039900,"Properties of the greatest common divisor: $\gcd(a, b) = \gcd(a, b-a)$ and $\gcd(a, b) = \gcd(a, b \text{ mod } a)$","Prove that (a) gcd(a, b) = gcd (a, b – a) (b) Let r be the remainder if we divide b by a. Then gcd(a, b) = gcd(a, r). I solved part a like: Assume a=pcommon pa b=pcommon pb gcd (a,b) = pcommon b-a = pcommon*(pb-pa)  So: gcd(a, b-a) = common again But I need help for part b guys I can solve it but I need a mathematical expression.","['elementary-number-theory', 'discrete-mathematics']"
1039936,Inevitable Zero-Sum numbers in a set,"Prove that for any set of $2n+3$ integers from the interval $[-2n-1,2n+1]$ there is a triple $(x,y,z)$ such that $x+y+z=0$. Example  : Choose $5$ number from $\{-3,-2,-1,0,1,2,3\}$ there are $x,y,z$ with $x+y+z=0$.","['induction', 'number-theory']"
1039937,Conditional expectation of second moment given sum of iid variables.,"We have $\xi_i \geq 0$, $\forall i = \overline{1,n}$ (i.i.d. variables). 
Assume that $S_n = \xi_1 +...+ \xi_n$. It is easy to show that $\mathrm{E} (\xi_1\vert S_n = 1) = \frac{1}{n}$. Now we want to look at the second moment: $\mathrm{E}(\xi_1^2\vert S_n = 1)$. 1) Since $0\leq\xi_i\leq 1$ then $\xi_i\geq \xi_i^2,\: \forall i=\overline{1,n},$ finally, $\mathrm{E}(\xi_1^2\vert S_n = 1) \leq \mathrm{E}(\xi_1\vert S_n = 1) = \frac{1}{n}$. 2) On the other hand,
by Jensen's  inequality we have: $(\mathrm{E}(\xi_1\vert S_n = 1))^2\leq \mathrm{E}(\xi_1^2\vert S_n = 1),$ where$(\mathrm{E}(\xi_1\vert S_n = 1))^2 = \frac{1}{n^2}$. The question is: how can we prove that the second moment has order of $\frac{1}{n^2}$; namely how we can get upper bound as $\frac{c}{n^2}$, where $c$ is a constant?","['statistics', 'stochastic-processes', 'conditional-expectation', 'probability']"
1039945,Solving $x\frac{\partial u}{\partial x} + y\frac{\partial u}{\partial y }=1$,"I want to solve the differential equation $$x\frac{\partial u}{\partial x} + y\frac{\partial u}{\partial y }=1$$ with the initial condition $u(1,y)=y.$ I'm very unfamiliar with possible methods to solve pde's. A method I found ( link ) would go as follows: $$\dot{x}=x,\;\;\;\;x(0)=1\\\dot{y}=y,\;\;\;\; y(0)=y\\\dot{u}=1,\;\;\;\;u(0)=1$$
but the second equation doesn't seem possible. Can this method be applied to solve the equation or I need a new one? Another question: In the link (page 2) they wrote $x(t)=0$, and after $x(t)=e^t$ as a solution, but how can that be when $e^t$ is nonzero for every $t$?","['ordinary-differential-equations', 'partial-differential-equations']"
1039955,"$\forall\ x,y,z\in \mathbb{R}$ Show that: $|x+y|+|y+z|+|x+z|\leq |x+y+z|+|x|+|y|+|z|$","$\forall\ x,y,z\in \mathbb{R}$ Show that: $$|x+y|+|y+z|+|x+z|\leq |x+y+z|+|x|+|y|+|z|$$ i tired, i notice that $x,y,z$ plays a symmetrical role in the inequality notice also that \begin{align*}
|x+y|+|y+z|+|x+z|\leq |x+y+z|+|x|+|y|+|z| & \Longleftrightarrow \\
 (|x+y|-|x|)+(|y+z|-|y|)+(|x+z|-|z|) \leq |x+y+z| 
\end{align*}
note that $\forall a,b\in \mathbb{R}\quad |a|-|b|\leq |a+b| $
then  $$(|x+y|-|x|)+(|y+z|-|y|)+(|x+z|-|z|) \leq |x|+|y|+|z|$$
i'm stuck here any help would be appreciated!","['absolute-value', 'inequality', 'calculus', 'real-analysis', 'analysis']"
1039956,Caratheodory: Inner Measure,"Reference This problem grew out from: Inner Measure vs. Outer Measure Setting Given a plain space $\Omega$ and a possibly empty semiring $\mathcal{S}$. Consider a premeasure $\mu:\mathcal{S}\to\overline{\mathbb{R}}_+$. Safe a trivial extension:
$$\mu_0(S):=\mu(S):\quad\quad\mu_0(\varnothing):=0\quad(\mathcal{S}_0:=\mathcal{S}\cup\{\varnothing\})$$ (This accounts the case of an empty semiring.) Preextend this to countably disjoint unions:
$$D=\bigsqcup_kS_k:\quad\mu_\infty(D):=\sum_k\mu_0(S_k)\quad(\mathcal{S}_\infty:=\{\ldots,D,\ldots\})$$ (This overgoes Hahn-Kolmogorov and integrates the induced ring.) Introduce the inner measure and outer measure:
$$\mu_+(A):=\inf_{A\subseteq D}\mu_\infty(D)$$
$$\mu_-(A):=\sup_{D\subseteq A}\mu_\infty(D)$$ (The outer measure only serves for comparison!) Problematics Now, the problem is that extension is not unique to $\sigma$-algebras:
$$\Omega:=\{1,2\}:\quad\mu_+(\Omega)=\infty\neq1=\mu_-(\Omega)\quad(\mathcal{R}:=\{\varnothing,(1)\})$$
But preferably are finite or leastways countably finite measures. However, Caratheodory doesn't do that, here!!
$$\mu_+(E_n)<\infty:\quad E_n\nrightarrow\Omega$$ Also this shows that measurability can't be in terms of comparison:
$$E\in\mathcal{M}_\pm:\quad\mu_+(E)=\mu_-(E)$$ (Therefore, a definition in terms of inner measure itself seems to be the only way out...) Imitating measurability for outer measures fails, too:
$$E\in\mathcal{M}_-:\quad\mu_-(A)=\mu_-(A\cap E)+\mu_-(A\cap E^\complement)\quad(A\subseteq\Omega)$$ (Subadditivity was crucial at alot of steps of Caratheodory.) Question So what could be a candidate for measurability in terms of inner measure?? Attempt Set an intermediate extension:
$$A\cap S_\Omega=\varnothing,D\in\mathcal{S}_\infty:\quad\mu_\Omega(A\sqcup D):=\mu_\infty(D)+0\quad\left(S_\Omega:=\bigcup_{D\in\mathcal{S}_\infty}D=\bigcup_{S\in\mathcal{S}_0}S\right)$$
Then the extended family contains the space itself:
$$\mathcal{S}_\Omega:=\{\ldots,A\sqcup D,\ldots\}:\quad\Omega\in\mathcal{S}_\Omega$$ (Caution: This is not a ring anyway.)","['measure-theory', 'elementary-set-theory']"
1039967,Show that $\lim_{n\to ∞} |a_n| = |a|$ if $a_n\to a$,"Let $(a_n)$ be a convergent sequence with $\lim\limits_{n\to \infty} a_n = a$. 
  Show that  $$\lim_{n\to \infty} |a_n| = |a|$$
  Then state and disprove the converse statement. In order to prove that I would use the following inequality $||a|-|b|| \le |a-b|$. Let $\epsilon>0$ be arbitrary. $(a_n) \rightarrow a$ and thus by definition there exists a $N$ such that
$$|a_n-a|< \epsilon \text{ for all } n \geq N$$ Since I want to show that $|a_n| \to |a|$,  I apply the inequality from above and get 
$||a_n|-|a|| \le |a_n-a| < \epsilon$ for all $n≥N$ following $||a_n|-|a||< \epsilon$ for all $n\ge N$. As this hold for any $\epsilon$ by definition $|a|$ is a limit of $|a_n|$. My first question would be if this proof is right. My second question is concerning the converse statement. I don't quite get what the converse statement here is. Normally if $P\Rightarrow Q$ the converse is $Q\Rightarrow P$ so is the converse
$$\lim_{n\to \infty} |a_n| = |a| \Rightarrow \lim_{n\to ∞} a_n = a\quad?$$","['convergence-divergence', 'sequences-and-series', 'limits']"
1039983,"Subsets of $\{1,2,3,4,5,6,7,8\}$ with at least 1 odd and 1 even number","How can I formally write the number of subsets of $S=\{1,2,3,4,5,6,7,8\}$ with at least 1 odd and 1 even number? I know if I take the subset with even numbers, $E =\{2,4,6,8\}$, there are $2^4-1$ subsets with even numbers (excluding $Ø$), and the same number for an the odd subset, $O$, and multiplying these together will give me an exact answer. But I'm not really satisfied because this isn't very formal, and I don't know how to show this with the proper mathematical symbols. Thanks in advance !","['notation', 'elementary-set-theory']"
1039988,Showing that the product group of $G$ and $H$ satisfies the universal property for coproducts in the category of abelian groups $\mathbf{Ab}$,"I'm working on another problem of Aluffi's Algebra. Given the category $\mathbf{Ab}$ of abelian groups, the problem is to show that for any two groups $G$ and $H$ the product group $G\times H$ satisfies the universal property for coproducts in $\mathbf{Ab}$. This amounts to showing that $G\times H$ is initial in the category $\mathbf{Ab}^{G,H}$. In other words we need to find a homomorphism $\sigma\in\text{Hom}(G\times H,K)$ and two suitable homomorphisms $\psi_G\in\text{Hom}(G,G\times H)$ and $\psi_H\in\text{Hom}(H,G\times H)$ such that for given $\varphi_G\in\text{Hom}(G,K)$ and $\varphi_H\in\text{Hom}(H,K)$ we have
\begin{equation}
\sigma\circ\psi_G=\varphi_G\\
\sigma\circ\psi_H=\varphi_H
\end{equation}
I think that defining 
\begin{equation}
\psi_G(g):=(g,e_H)\\
\psi_H(h):=(e_G,h)\\
\sigma(g,h):=\varphi_G(g)\varphi_H(h)
\end{equation}
(where $e_G,e_H$ are the identities of $G$ and $H$ and the last product is in $K$) gives the homomorphism we want (checking that $\sigma$ is actually a group homomorphism requires commutativity, so this won't work in $\mathbf{Grp}$), but my problem is proving uniqueness of $\sigma$. Any hints?","['category-theory', 'abstract-algebra', 'abelian-groups']"
1040000,Find a sequence converging to zero but not the element of $\ell^p$ space for any $1<p<\infty$,"I am studying functional analysis and I have a problem about finding a sequence converging to zero such that this sequence is not in $\ell^p$ for any $p$ . By $\ell^p$ , I mean $$\ell^p := \left\{ (x_k)=(x_1,x_2,...):\sum_{k=1}^\infty|x_k|^p<\infty \right\}$$ where $1<p<\infty$ . First, I thought of the simple sequence $(1/k)_{k \in \mathbb{N}}$ which converges to zero, but, then, I realized it is an element of $\ell^p$ when $p>2$ . I thought of a couple more examples, but they did not work either. Can somebody help me out here?","['functional-analysis', 'lp-spaces']"
1040015,% of % - Please Help Me Prove My Friend Wrong,"Here is the situation:  My friend and I are at an impasse.  I believe I'm correct, but he's so damn stubborn he won't believe me.  Also, I'm not the most articulate at explaining things.  Hopefully some of you guys can help me explain this to him in a way he'll understand.  Here is the problem: A DVD is either at his parent's house or his own.  The probability that it's at his house is 30%.
If the DVD is at his own house, there is a 90% chance it's on the porch, and a 10% chance it's in the living room.
What is the % chance the DVD is on the porch? My friend says you take 90% of 30% which is 27 and that is the % chance it's on the porch.  Is this correct?  I don't believe so. I believe that regardless of where the DVD is, the chance of it being anywhere in his house is still 30% overall.  Location inside his house won't change those odd because the porch and the living room are both part of the house.  If there is a 90% chance it's on the porch, it doesn't change the overall odds of it being in that location. Now, if you rephrase the question and ask, ""The DVD Is either at my parents, my porch, or my living room.  What is the % chance it's on my porch?"", the answer is 33%.  If there are three places it could be, then there is 33.333% chance it's on the porch.  Even if it's a 90% chance it's at his house, if there are only three places it can be, it remains the same. I think the correct way of answering the question is:  There is a 30% chance the DVD is at my house.  If it is at my house, there is a 90% chance it's on my porch.  They are two separate odds and you can't take a percentage of the overall odds since the locations are inside the house. Is this correct or am I wrong?  And regardless, please give me your explanation.",['probability']
1040039,Why is trigonometry important in calculus? [closed],Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 9 years ago . Improve this question I need to write short note why trigonometry is important is calculus and engineering mostly for presentation. I am not focusing on on what topic it specifically it appears (because I am guessing the list would be mile long) but by due to which of it's property. My guess is that it's solely due to it's connection with very simple geometric structures triangles and circles and complex numbers. I hope I am not being redundant and besides what other property can be attributed to trigonometric functions that it makes essential in calculus?,"['trigonometry', 'calculus', 'soft-question']"
1040088,Misplaced complex analysis intuition on Riemann Surfaces,"Next week I will be giving a lecture, based on Chapter 2.6 from Jost's book Compact Riemann Surfaces . He states the following theorem: Theorem 1 ( Jost Theorem 2.6.2 ) Let $S$ and $\Sigma$ be Riemann Surfaces, assume that $\Sigma$ is hyperbolic and complete with respect to the hyperbolic metric. Then any bounded holomorphic map $f: S\backslash\{p\}\to \Sigma$ extends to a holomorphic map $\overline{f}: S \to \Sigma$. Now, the definition of hyperbolic that Jost is using is not the standard definition, he defines the hyperbolic metric $d_H$ on $\Sigma$ to be $d_H(p,q) := \inf \{ \sum\limits_{i=1}^n d(z_i,w_i): n \in \mathbb{N},\ p_0,\ p_1,\dots,\ p_n \in \Sigma,\ p_0 = p,\ p_n = q,$
$\phantom{spacespacespace} f_i: D \to \Sigma \ \text{holomorphic}, \ f_i(z_i) = p_{i-1},\ f_i(w_i) = p_i   \}$. For reference purposes this is apparently a special case of the ""Kobayashi metric"". Let $D$ be the unit disk in the complex plane. From complex analysis, we have the following theorem (I paraphrase from Rudin's Real and Complex Analysis ): Theorem 2 Suppose $f: D\backslash \{0\} \to \mathbb{C}$ is holomorphic and bounded. Then $f$ has a removable singularity at $0$. Now, if we consider a coordinate chart $\psi_1$ on $S$ in a neighborhood of $\{p\}$, with $\psi_1(p) = 0$, and an atlas $\{(\phi_n,U_n)\}$ on $\Sigma$, we can write $\phi_i \circ f \circ \psi_1^{-1}: D\backslash \{0\} \to D$. On immediately seeing the statement of the theorem, I want to claim that this map is bounded. Is this true? And, if so, can we not simply apply Theorem 2 to obtain Theorem 1? My complex analysis intuition says this should be trivial, but Jost produces a much more complicated proof, which lacks intuition.","['riemann-surfaces', 'complex-analysis']"
1040096,Solution of inhomogenous ODE (4th order),"Hello stackexchangers, I have an inhomogenous ODE in 4th order. This ODE is the constitutive law to describe a material by using the ""Wiechert model"" (p. 15) which is given by $p_0\sigma + p_1\frac{\text{d}\sigma}{\text{d}t} + p_2\frac{\text{d}^2\sigma}{\text{d}t^2} + p_3\frac{\text{d}^3\sigma}{\text{d}t^3} + p_4\frac{\text{d}^4\sigma}{\text{d}t^4} = q_0\epsilon + q_1\frac{\text{d}\epsilon}{\text{d}t} + q_2\frac{\text{d}^2\epsilon}{\text{d}t^2} + q_3\frac{\text{d}^3\epsilon}{\text{d}t^3} + q_4\frac{\text{d}^4\epsilon}{\text{d}t^4}$, where $p_i$ and $q_i$ a time-dependant coefficients that are known from experiments but are available in analytical form; and $\sigma$ is a time-dependant tension that is known from a previous calculation for each instant of time $t_k$ in something like a kind of table of values, like: $t_0$ : 0 $t_1$ : 0 $t_2$ : 0 $t_3$ : 0 $t_4$ : 0.017 $t_5$ : 0.030 $t_6$ : 0.039 $t_7$ : 0.046 $t_8$ : 0.052 $t_9$ : 0.055 $t_{10}$ : 0.058 $t_{11}$ : 0.060 $t_{12}$ : 0.062 $t_{13}$ : 0.063 $t_{14}$ : 0.064 $t_{15}$ : 0.065 $t_{16}$ : 0.066 $t_{k-1}$ : 0.067 $t_{k}$ : 0.068 It could also be said that there's no previous impact before $t = t_0 = 0$ and $\epsilon = 0$, $\sigma = 0$ as well as $\frac{\text{d}^n\sigma}{\text{d}t} = \frac{\text{d}^n\epsilon}{\text{d}t} = 0$ at $t = t_0 = 0$. Now I want to calculate the resulting strain $\epsilon(t_k)$ which is caused by $\sigma(t_k)$. For further calculations I need something like $\epsilon(\sigma) = \dots$ The problem is that I don't know a function to describe $\sigma(t)$ continously. And I guess that there exist no analytical solution to the equation above. That's why I am looking for an approximate solution. I know that the coefficients $q_i$ and $p_i$ are time-dependend, what makes it more difficult to find a solution. My idea now is to consider the problem in time-steps, where one time-step $t_{k-1} - t_k$ is so small that those parameters could be considered as constant. In the mentionnend script (p. 16; ""Example 8"") it is said "" It may be that the input strain function is not known as a mathematical expression, or its mathematical expression may be so complicated as to make the transform process intractable. In those cases, one may return to the differential constitutive equation and recast it in finite-difference form so as to obtain a numerical solution. [...] "" Is it somehow possible to rewrite the given 4th-order-ODE in finite-difference form? So that I can calculate an approximation of $\epsilon$? Or is there no way around numerical methods like Runge-Kutta? I hope that someone can help me ... Many thanks in advance!","['ordinary-differential-equations', 'discrete-mathematics', 'numerical-methods']"
1040103,How to find a solution to the elliptic curve,"We know that one solution of the given elliptic curve is (2, 1) and we have to find another rational solution such that $x$ is not equal to 2 by drawing a tangent to the curve at (2, 1). $$y^2=x^3- 7$$ However, by drawing a tangent at (2, 1), the line does not intersect the curve at any other point. How do I get another solution?","['elliptic-curves', 'number-theory']"
1040105,Proving of $\frac{\pi }{24}(\sqrt{6}-\sqrt{2})=\sum_{n=1}^{\infty }\frac{14}{576n^2-576n+95}-\frac{1}{144n^2-144n+35}$,"This is a homework for my son, he needs the proving.I tried to solve it by residue theory but I couldn't. $$\frac{\pi }{24}(\sqrt{6}-\sqrt{2})=\sum_{n=1}^{\infty }\frac{14}{576n^2-576n+95}-\frac{1}{144n^2-144n+35}$$","['sequences-and-series', 'calculus']"
1040108,Use induction to prove $\sum_{k=1}^n\frac{k}{2^k}=2-\frac{n+2}{2^n}$,Use induction on $n\in\Bbb N$ to prove that $$\sum_{k=1}^n\frac{k}{2^k}=2-\frac{n+2}{2^n}\;.$$ I have got as far as to the induction step where I have: $$S(n+1)= 2-\frac{n+3}{2^{n+1}}$$ and this should be equal to $$S(n) +\frac{n+1}{2^{n+1}} = 2-\frac{n+2}{2^n}+\frac{n+1}{2^{n+1}}$$ Now I am kinda stuck.. all I end up with is ; $$ ... = 2-\frac{3n+5}{2^{n+1}}\;.$$ Would someone help me out?,"['induction', 'discrete-mathematics']"
1040127,$\int_{-1}^{1}|f(t)|dt \geq C\left(\int_{0}^{2}|f(t)|^2\right)^{1/2}$ for polynomials,"Prove that there exists constant $C>0$ that for all $f \in P_n$ we have:
  $$\int_{-1}^{1}|f(t)|dt \geq C\left(\int_{0}^{2}|f(t)|^2\right)^{1/2}$$
  Where $P_n$ is space of polynomials with degree less than or equal to $n$. There is one solution using functional analysis: first we note that functions $\|\|_1$ and $\|\|_2$ are norms on $P_n$: $$\|f\|_1=\int_{-1}^{1}|f(t)|dt$$ $$\|f\|_2=\left(\int_{0}^{2}|f(t)|^2\right)^{1/2}$$ Now $P_n$ is finite vector space and all norms on finite vector spaces are equivalent, so the inequality holds. In my opinions it's a suprising result, so I'm looking for elementary proof of this inequality.","['alternative-proof', 'functional-analysis', 'polynomials']"
1040128,How to integrate $\int_1^\infty \frac{dx}{x^2\sqrt{x^2-1}}$?,How to integrate $$\int_1^\infty \frac{dx}{x^2\sqrt{x^2-1}}$$ I tried both $t=\sqrt{x^2-1}$ and $t=\sin x$ but didn't reach the right result.,"['calculus', 'integration']"
1040136,Uncountably infinite set between 1-2 and 1-10?,"Just a quick question: Is the size of the set of real numbers from 1 to 2 greater, or equal in size to the number of real numbers between 1 and 10? I'm a Physicist so I'm not totally clued up on Mathematical jargon pertaining to set theory...",['elementary-set-theory']
1040140,Graph of weakly continuous linear operator,"I have a few questions regarding the graph of an operator. Consider the operator $T:X \rightarrow Y$ between Banach spaces $X,Y$. Assume that $T$ is a linear operator which is (weak, weak)-continuous, so $T$ is continuous when $X$ and $Y$ are endowed with the weak topology. Consider the graph $G(T) := \{(x,y) \in X \times Y: ~~Tx = y \}$. The two questions I have are: Can we conclude that $G(T)$ is weakly closed subspace of $X \times Y$? Also, since $G(T)$ is convex can we then use Mazur's Theorem to conclude that $G(T)$ is strongly closed in $X \times Y$? Thanks.","['operator-theory', 'closed-graph', 'functional-analysis', 'real-analysis']"
1040154,Is every metric space a subspace of some connected metric space?,"Is every metric space a subspace of some connected metric space? If the space itself is connected then we're done, but if not then I think we can extend our metric space to make it connected.  I'm not sure whether this will work or not, but intuitively I think the answer is yes.","['general-topology', 'connectedness', 'metric-spaces']"
1040214,Probability that a cow is black given that I've observed at least one side is black,"I'm on a farm with six cows; three are white, two are black and one is completely black on one side and completely white on the other. I see one cow from the side, who appears to be black (that is, the side that I see is black). What's the probability that the cow is black? I tried to figure out a solution, but it's wrong as it conflicts with the solution I'm given. I don't understand completely what I'm missing and where I'm going wrong, so I would appreciate some advice which would lead me in the right direction. Let $P$ be the event that the cow I observe is completely black, and $S$ be the event that at least one side is black. $S$ is given, so I need to find $P(B|S)$. $P(B|S) = \frac{P(S|B)P(B)}{P(S)}$ $P(S|B) = 1$, since if the entire cow is black then at least one side is black. $P(B) = \frac{1}{3}$ since there are two black cows among a group of six. And $P(S) = \frac{1}{2}$ since there are three out of six cows with at least one black side. so $P(B|S) = \frac{P(B)}{P(S)} = \frac{2}{3}$ However the answer I'm given is $\frac{4}{5}$","['bayes-theorem', 'probability']"
1040230,Reference requests for an opt-cited result in Jennrich (1969),"Lemma 2 on page 637 of Jennrich (1967) states that: Let $Q$ be a real-valued function on $\Theta\times Y$ where $\Theta$
  is a compact subset of a Euclidean space and $Y$ is a measurable
  space. For each $\theta$ in $\Theta$ let $Q(\theta,y)$ be a measurable
  function of $y$ and for each $y$ in $Y$ a continuous function of
  $\theta$. Then there exists a measurable function $\hat{\theta}$ from
  $Y$ into $\Theta$ such that for all $y$ in $Y$: $$
 Q(\hat{\theta}(y),y)=\inf_\theta Q(\theta,y). $$ I have a few questions about this please: Where can I find an alternative source (preferably a text book) of proof for this result? Jennrich's writing is too dense for me at the moment. If you know a relatively accessible proof, please share it here with me and others. Jennrich's proof begins with: Let $\{\Theta_n\}$ be an increasing sequence of finite subsets of
  $\Theta$ whose limit is dense in $\Theta$. This seems to be a consequence of $\Theta$ being compact. What is the name of this property? Thank you!","['probability-theory', 'reference-request', 'measure-theory', 'probability']"
1040246,"Suppose that the ODE $x'=f(x)$ on $\mathbb{R}$ is bounded, $|f(x)| \leq M$ for all x","Prove that no solution of the ODE escapes to infinity in finite time. What I've gotten so far is: $x' = \frac{dx}{dt} = f(x)$. And, $-M \leq \frac{dx}{dt} \leq M$. Thus, by integrating, $|x(t)| \leq Mt$. $x(t)$ will go to infinity as $t$ goes to infinity, but is a correct proof? Any help would be greatly appreciated!","['ordinary-differential-equations', 'real-analysis']"
1040257,How to evaluate the composed euler sum $\sum_{n=1}^\infty \frac{H_{kn}}{n^2}$,"Is there a closed form for the following ? $$\sum_{n=1}^\infty \frac{H_{kn}}{n^2}$$ I suspect it is easy for $k={1,2}$ ; but the complexity might increase for greater values Can we generalize $$\sum_{n=1}^\infty \frac{H_{kn}}{n^q}$$ where the harmonic numbers are defined as $$H_{kn} = \sum_{j=1}^{kn} \frac{1}{j}$$","['polylogarithm', 'sequences-and-series', 'harmonic-numbers']"
1040266,"Inner product, differential forms and surfaces (Stokes' theorem)","I'm trying to understand how do you get the Kelvin-Stokes theorem
\begin{equation} \int_{S} (\nabla\times \omega) \cdot \mathrm{d}S = \int_{\partial S} \omega \cdot \mathrm{d}r \end{equation}
from the generalized Stokes' theorem
\begin{equation} \int_{M} \mathrm{d} \omega = \int_{\partial M} \omega \end{equation}
I am aware that this question is answered here . However, I am looking at a more specific part of the question. If I start looking at a vector $\omega = a \mathrm{d}x +  b \mathrm{d}y +  c \mathrm{d}z$, and take it's exterior derivative $\mathrm{d}\omega = \left(\partial_x b - \partial_y a \right) \mathrm{d}x \wedge \mathrm{d}y + \left(\partial_z c - \partial_y b \right) \mathrm{d}x \wedge \mathrm{d}y +\left(\partial_x c - \partial_z a \right) \mathrm{d}x \wedge \mathrm{d}z$ and notice that in the basis $\{ \mathrm{d}x^i \wedge \mathrm{d} x^j \}$ this is the cross product. But how to go from here - how to identify this with the inner product with $\mathrm{d}S$. How to even write what are the surface and line elements in general?","['multivariable-calculus', 'differential-forms', 'differential-geometry']"
1040273,Nice proof that $\mathbb{Z}[\sqrt{6}]$ is a Euclidean domain wrt absolute norm map,"I know that $\mathbb{Z}\left[\sqrt{6}\,\right]$ is a Euclidean domain with respect to the absolute valued norm map $x+y\sqrt{6} \mapsto |x^2-6y^2|$. I think I proved this result with some common techniques, but the proof is a bit sloppy and it requires a lot of cases. (Basically, I checked that for every $z \in \mathbb{Q}(\sqrt{6})$ there is $\gamma \in \mathbb{Z}[\sqrt{6}]$ such that $|N(z-\gamma)|<1$.) Does there exist a short proof for this result, with less cases or a more, say, enlightening method? Many thanks.","['algebraic-number-theory', 'abstract-algebra']"
1040283,Find the probability density function of $Y=X^2$,"Consider the random variable X with probability density function $$f(x) = \begin{cases} 
 3x^2; & \text{ if, } 0 < x < 1 \\
 0; & \text{ otherwise }
\end{cases}$$ Find the probability density function of $Y=X^2$. This is the first question of this type I have encountered, I have started by noting that since $0<x<1$, we have that $0< x^2<1$. So $X^2$ is distributed over $(0,1)$. I'm not really sure how to progress or what method to take to actually find the pdf.","['probability-theory', 'probability-distributions', 'probability', 'functions']"
1040287,Taylor Series of $2xe^x$,"I have to find the Taylor Series for $2xe^x$ centred at $x=1$. I came up with the following. $$e^x = e^{x-1} \times e = e \bigg( \sum_{n=0}^\infty \frac{(x-1)^n}{n!}\bigg)$$ Then consider $2xe^x$. $$2xe^x = 2xe \bigg( \sum_{n=0}^\infty \frac{(x-1)^n}{n!}\bigg) = \bigg( \sum_{n=0}^\infty \frac{2xe(x-1)^n}{n!}\bigg) $$ I am wondering whether this is a right Taylor Series centred at $x=1$. I do understand that the $(x -1)^n$ implies that it is centred at $1$. But, I am very not sure with my answer since there are two terms of $x$, that is $x$ and $(x-1)^n$. Any clarification and explanation would be highly appreciated.","['sequences-and-series', 'calculus', 'taylor-expansion']"
1040298,Covariance of uniform distribution and it's square,"I have $X$ ~ $U(-1,1)$ and $Y = X^2$ random variables, I need to calculate their covariance.
My calculations are:
$$
Cov(X,Y) = Cov(X,X^2) = E((X-E(X))(X^2-E(X^2))) = E(X X^2) = E(X^3) = 0
$$
because
$$
E(X) = E(X^2) = 0
$$
I'm not sure about the $X^3$ part, are my calculations correct?","['probability-theory', 'covariance', 'probability', 'random-variables']"
1040302,Showing that $p^n(1-p) \leq \frac{1}{en}$,"I am reading a paper and found the following Lemma without a proof. Let $X_1, \ldots, X_{n+1}$ be independent Bernoulli random variables, where $\Pr[X_i = 1] = p$. Let $E$ be the event that the first $n$ variables are all $1$, but the $X_{n+1}$ is $0$.
Then $\Pr[E] \leq \frac{1}{en}$. I understand that $\Pr[E] = p^n(1-p)$. How is it that $p^n(1-p) \leq \frac{1}{en}$?",['probability']
1040308,$L^\infty(S^1)$ is not separable,"Let $S^1$ be the unit circle and $L^\infty(S^1)$ the space of measurable functions $f:S^1\to\mathbb{C}$ such that $\|f\|_\infty<\infty$. (In fact $L^\infty(S^1)$ consists of equivalence classes of functions, where $f\sim g$ is they are equal almost everywhere.) How to show that $L^\infty(S^1)$ is not separable? $L^\infty(S^1)$ can be thought as the space of $2\pi$ periodic functions.
I have been able to show that the space of periodic functions (of arbitrary period) is not separable by showing that the collection of functions of the form
$$f_s(x):=e^{isx}$$
for $s\in\mathbb{R}$ is uncountable and satisfies
$$\|f_s-f_t\|_\infty=2\delta_{st},$$
but I fail to adapt this to the case of $2\pi$ periodic functions. Is there another approach?","['lp-spaces', 'analysis']"
1040314,Find probability that random triangle covers centre of circumscribed circle,"We are given the equilateral triangle A. On each edge of the triangle we pick a point: randomly (probability distribution is uniform) independently of others We construct new triangle B from randomized points. Task is to find the chance of B containing the centre of circle circumscribed around triangle A. I would appreciate hints and pointers. Thanks! Edit Suppose $P_0$ is chosen on the bottom line of triangle A. $P_O = (x_0,0), x_0 \in [0,1]$ Let's find geometrical place of points $P_1, P_2$. If $P_1$ is on the upper left edge, that $P_1 = (x_1,\sqrt 3 x_1), x_1 \in [0, \frac 1 2]$. Then $P_2$ is upper right edge, and $P_2 = (x_2, \sqrt 3 (1 - x_2)), x_2 \in [\frac 1 2, 1]$. Centre point is $C = (\frac 1 2, \frac 1 {2 \sqrt 3 })$. Now, we shall find the constraints for points. For fixed $x_0$, $P_1$ and $P_2$ must lay below the line between $P_0$ and $C$. But I wonder, if there is a way to describe constraint better? Since this most trivial way suffers from situation when line $CP_0$ and one of the edges intersects outside of range $x_m$. Edit 2 I have listened to the useful hints about advantages of angle-based view on the problem, and believe that now I have the geometry part figured: As earlier, We fixed $P_0$ on the bottom edge and on the step 1 we pick $P_1$ on the left edge. Consider $\angle \alpha$ line between bottom edge and line $CP_0$. Then $\alpha \in [\frac \pi 6, \frac \pi 2]$. Then prohibited sector for left edge has angle $\frac \pi 2 - \alpha$. Using same logic on the step 2 we obtain prohibited sector for point $P_2$. And now it looks like I have to get down to all that integration, so your suggestions are welcome!","['geometry', 'probability', 'geometric-probability']"
1040319,Combined Distribution of Random variable,"How to compute $P[T1 \le T2 \le t]$ for T1, T2 is independent random variable with exponential distribution in terms of cmf, pdf of T1 and T2? Similarly for $P[T1 \le T2 \le T3.. \le t]$  ? I tried this: $P[T1 \le T2 \le t] = P [T2 \le t] P[T1 \le T2]$ $= P [T2 \le t] \int_{x=0}^\infty P[T1 \le x ]P[x = T2] dx$ $= F_{T2}(t) \int_{x=0}^\infty F_{T1}(x) f_{T2}(x)dx $ which does not seem to give me the right result.. I think I made mistake at the first expansion, but could not think of any other way. Thanks","['statistics', 'exponential-function', 'probability-theory', 'probability-distributions', 'probability']"
1040323,Homogeneous polynomials and line bundles,"In Huybrechts' Complex Geometry text, he makes the following claim: (Claim) ""Any homogeneous polynomial $s \in \mathbb{C}[z_o,\dots, z_n]_k$ of degree $k$ defines a linear map $(\mathbb{C}^{n+1})^{\otimes k} \to \mathbb{C}.$ "" He then writes, using the claim: ""This gives rise to a holomorphic map $\mathbb{P}^n \times (\mathbb{C}^{n+1})^{\otimes k} \to \mathbb{C}$ which is linear on any fibre of the projection to $\mathbb{P}^n$ . The restriction to $\mathcal{O}(-k)$ thus provides a holomorphic section of $\mathcal{O}(k)$. This way we associate to any homogeneous polynomial $s$ of degree $k$ a global holomorphic section of $\mathcal{O}(k),$ which will also be called $s.$"" Is the following map the one he is referring to in his claim? There is a basis $B_1$ for the space of homogeneous polynomials of degree $k$ which consists in all distinct products of $k-$ tuples of variables. There is a basis $B_2$ for the space $(\mathbb{C}^{n+1})^{\otimes k}$ which consists in all $(n+1)^k$ sequences of basis elements of $C^{n+1}.$  Now $B_2$ is larger than $B_1$, but the two are in 1:1 correspondence modulo reordering of sequence elements in $B_1$. This allows us to define an injective map.","['fiber-bundles', 'algebraic-geometry', 'vector-bundles', 'complex-geometry']"
1040326,"Hartshorne 3.5.3, how to use surjectivity on global sections and Nakayama to conclude globally generated","There is a step in 3.5.3 of Hartshorne that I am stuck at. The setup is this: Let $\mathcal{F}$ be a coherent sheaf on a scheme $X$ which is proper over $\text{Spec}(A)$ for a noetherian ring $A$.  Let $\mathcal{L}$ be an invertible sheaf on $X$.  Let $P$ be a closed point of $X$ and let $\mathcal{I}_P$ be the ideal sheaf of the closed subset $\{P\}$. Let $\mathcal{F'}= \mathcal{F} \otimes \mathcal{L}^n$, $k(P)= \mathcal{O}_X/\mathcal{I}_P$. Suppose that $H^0(\mathcal{F'})\to H^0(\mathcal{F'}\otimes k(P))$ is surjective.  The claim is that there exists $s_i\in H^0(\mathcal{F'})$ such that the images of the $s_i$ in $\mathcal{F'_P}$ generate $\mathcal{F'_P}$ as an $\mathcal{O}_{X,P}$-module. Hartshorne says this is by Nakayama's lemma over the local ring $\mathcal{O}_{X,P}$. What I have tried: I know that $k(P)$ has the property that it's stalk at $P$ is $\mathcal{O}_{X,P}/\mathfrak{m}$, where $\mathfrak{m}$ is the max ideal of $\mathcal{O}_{X,P}$.  So the stalk of $\mathcal{F'}\otimes k(P)$ at $P$ is of the form $M/\mathfrak{m}M$ with $M$ being the stalk of $\mathcal{F'}$ at $P$.  Now it looks like Nakayama would be useful, but I do not see how to use it here.  Furthermore, I cannot see where surjectivity of global sections comes into play. I have also tried to prove it in the case where $X=\text{Spec}(R)$ is affine, since then I can write $\mathcal{F'}$ as $\widetilde{M}$ for some finitely generated $R$-module $M$.  Also, this affine case originally appealed to me because I have explicitly calculated what $\mathcal{I}_P$ is in this case. I know that the surjectivity of global sections gives a surjection between germs of global sections. Finally, I wanted to add that for my question I do not think $X$ proper over $A$ matters, nor do I think the presence of $\mathcal{L}$ matters.  This is why I have used the notation $\mathcal{F'}$.",['algebraic-geometry']
1040359,Product measures and absolute continuity,"For $j=1,2$, let $\mu_j,\nu_j$ be $\sigma-$finite measures on $(X_j, M_j)$ such that $\nu_j<<\mu_j$. Prove that $\nu_1 \times \nu_2 << \mu_1 \times \mu_2$. Here, does it suffices to prove that $\nu_1 \times \nu_2(A\times B)=0$ whenever $\mu_1 \times \mu_2(A\times B)=0$ for any box $A\times B$? Or should I prove that $\nu_1 \times \nu_2(E)=0$ whenever $\mu_1 \times \mu_2(E)=0$ for any $E\in M_1\otimes M_2$?",['measure-theory']
1040372,Taylor series of a definite integral,"Consider the function of a parameter $\alpha > 0$, given by
$$f(\alpha) = \frac{2}{\sqrt 2\pi} \int_0^\infty e^{\dfrac{-x^2}{2\alpha^2}}\cosh(x)\log\cosh(x) dx.$$
From Wolfram-alpha, it seems that for small values of $\alpha$, 
$$f(\alpha) = \frac{\alpha^3}{2}+\frac{\alpha^5}{2} + o(\alpha^5).$$
How can one establish this rigorously? Edit: Per the comment below, I used dfrac to make it more visible.","['calculus', 'integration', 'definite-integrals', 'real-analysis', 'limits']"
1040375,Find coordinates of point that intersects circle,"I got a circle of 900 radius, knowing its center coordinates A(x1, y1) and got another point with also known coordinates B(x2, y2). I draw a line between point A and B. It intersects the circle in a point C(x,y). How can I find the coordinates of that point?","['geometry', 'circles']"
1040400,A sequence of $n^2$ real numbers which contains no monotonic subsequence of more than $n$ terms,"I'm following a Combinatorics course at the moment, and have recent proved the Erdős–Szekeres Theorem (or, at least, some variation of): A sequence of length $n^2 + 1$ either contains an increasing subsequence of length $n+1$, or a decreasing one of length $n+1$. I have been set an exercise to prove the following: For each natural number $n$, find a sequence of $n^2$ real numbers which contains no monotonic subsequence of more than $n$ terms. I can naively / informally how to do this, but no method which would seem to involve any sort of Graph / Ramsey Theory.  I'm assuming that I'll have to use Erdős–Szekeres, since I'm in a Combinatorics course, or notice something about its proof, to come up with a formal construction of the sequence, but can't see how I'd go about it. Would using Erdős–Szekeres be the right way to go about this, or is there a different / simpler combinatorial way to explore? Thanks!","['ramsey-theory', 'graph-theory', 'combinatorics']"
1040424,"What is a good, hi-tech textbook on complex analysis?","I am looking for an introductory textbook for Complex Analysis that is hi-tech . All the books I have looked at suffer from the same problem; they're only assuming that the reader is familiar with is basic real analysis, and thus, are by design, low-tech. I'm looking for a textbook that: Doesn't shy away from treating the Riemann sphere as a manifold, and
clearly distinguishes it from $\mathbb{C}$, so it's easy to keep
track of where my functions live. Gives the statement of Cauchy's theorem in a modern, algebraic topological language of (co)homology Actually compares the theorems, where applicable, to the $2$-dimensional real case with more than passing remarks Doesn't give whacky definitions of topological properties (eg. simple connectedness) This isn't a complete list, but this should give you a good idea about what I mean by hi-tech. Additional extras: Has a sane statement of Liouville's theorem. Why say that ""bounded entire functions are constant"" when you could be saying ""the image of a function $\mathbb{C} \to \mathbb{C}$ is dense or a single point""? Covers basic multivariable complex analysis Treats the logarithm, etc. as functions from a Riemann surface, rather than the clumsy ""multifunction"" treatment Treats power series formally and then passes to convergent ones I basically want someone like John M. Lee to write a complex analysis book. (His book on Smooth Manifolds is about as good as textbooks get, in my opinion.) The closest I have found was Cartan's text, but I'm hoping that someone on this site might know something even better. Many thanks!","['algebraic-topology', 'book-recommendation', 'reference-request', 'complex-analysis']"
1040434,Fubini's theorem application proof check,"I have proven a problem but I am unsure whether it is correct because the proof seems so simple that I think I might be mistaken. Please be kind to comment on my proof and tell me whats wrong with it. The problem: Let $A$ be a rectangle in $\Bbb R^k$ and B a rectangle in $\Bbb R^n$. Let $Q=A\times B$. Let $f:Q\to R$ be bounded and Riemann integrable. Show that if $\int_Qf$ exists, then $\int_yf(x,y)$ exists for $x\in A-D$  where D is a set of measure zero in $\Bbb R^k$. My idea: It just seems like a direct application of Fubini theorem. I wrote that if $\int_Qf $ exists, then by fubini theorem, $\int_Qf=\int_x\int_y f$ and it implies that $\int_yf(x,y)$ exists. Fubini's theorem version that I use:
Let $A$ be a rectangle in $\Bbb R^k$ and B a rectangle in $\Bbb R^n$. Let $Q=A\times B$. Let $f:Q\to R$ be bounded. $f$ is in the form $f(x,y)$ for $x\in A, y\in B$. If f is integrable over Q, then $$\int_Q f=\int_x \int_yf=\int_y\int_xf$$ Is this right? Thank you very much for your help","['integration', 'functions', 'proof-verification', 'real-analysis', 'analysis']"
1040442,How do I solve simultaneous congruence modulo equations,"How do I find one value of $x$ in these equations?
$$
\begin{cases}
x \equiv 3 \pmod{5}\\
x \equiv 4 \pmod{7}
\end{cases}
$$","['modular-arithmetic', 'discrete-mathematics', 'congruences']"
1040443,How to take the derivative of a matrix with respect to itself?,Could someone please explain how to take the derivative of matrix with respect to itself? $$\frac{\partial \textbf{X}}{\partial \textbf{X}}$$ where $\textbf{X}$ is an M x N matrix,"['matrix-calculus', 'linear-algebra', 'derivatives']"
1040450,Extensions of $\mathbb{Z}$ by $\mathbb{Z}_2$,"Well. My question is very concrete. Does anybody know all the groups $G$ such that it fits in a short exact sequence $1\to \mathbb{Z}\to G\to \mathbb{Z}_2 \to 1$, where $\mathbb{Z}_2$ are the integers modulo $2$. It is well known that such extensions are classified by $H^2(\mathbb{Z}_2,\mathbb{Z})$, and this cohomology group is isomorphic to $\mathbb{Z}_2$. Now the trivial element is represented by any semidirect product, and there are just two of them, explicitely: $\mathbb{Z}\times\mathbb{Z}_2$ and $\mathbb{Z}\rtimes \mathbb{Z}_2 \cong D_\infty$ the inifnite dihedral group. And the nontrivial element can be represented by $\mathbb{Z}$ clearly. Is there any extension missing?","['group-extensions', 'abstract-algebra']"
1040454,"Reproducing kernel Hilbert space, why?","Let $K: X \times X \rightarrow \mathbb{C}$ be a positive definite kernel on a set $X$, i.e. for any $x_1, \cdots, x_n \in X$, the matrix $$
[K(x_i, x_j)]_{ij} \in \mathbb{C}^{n \times n}
$$ is positive definite. The reproducing kernel Hilbert space $\mathcal{H}_K$ with kernel $K$ is the Hilbert space closure of the set $\{ K_x(y) = K(x,y)\}$ with the inner product $$
\langle K_x(y), K_{x'}(y) \rangle_{\mathcal{H}_K} = K(x, x'). 
$$ Question Consider the vector space of functions on $X$ (no additional structure is assumed on $X$). Define an inner product by $$
\langle \delta_x, \delta_{x'} \rangle = K(x, x'). 
$$ Then the resulting Hilbert space $\mathcal{H}$ is isomorphic to $\mathcal{H}_{K}$ via the isomorphism $$
\delta_x(y) \mapsto K_x(y).
$$ $\mathcal{H}$ seems a much more natural and straight forward object than $\mathcal{H}_K$, so what is gained by the ""reproducing kernel"" construction? The reproducing kernel construction makes pointwise evaluation an element of the dual...why is this useful? In particular, what are some examples of specific contexts where $\mathcal{H}_K$ is more handy than $\mathcal{H}$ (I am guessing they must exist)?","['hilbert-spaces', 'functional-analysis', 'machine-learning']"
1040464,Domain of definition of $(1-y)/x$ on $x^2+y^2=1$?,"I'm self-teaching myself some basic algebraic geometry, and I wanted to double check something that seems too easy. An exercise sheet I found asks to compute the domain of definition of the rational function $f(x,y)=\frac{1-y}{x}$ on the circle $x^2+y^2=1$ in $\mathbb{A}^2$, the affine $2$-space over an algebraically closed field $k$. I think the domain of definition is everywhere on the curve except when $x=0$, so the domain of definition would be 
$$
\{(x,y)\in\mathbb{A}^2:x^2+y^2=1\}\setminus\{(0,1),(0,-1)\}.
$$ Does something more nuanced happen in $\mathbb{A}^2$, or is that all there is to it here? Thanks.","['affine-geometry', 'rational-functions', 'algebraic-geometry']"
1040477,Showing that $\lim_{x\to\infty}\left(\sqrt{x^2+c}-x\right)=0$,A limit I had to compute recently boiled down to the following limit: $$\lim_{x\to\infty}\left(\sqrt{x^2+c}-x\right)=0\quad\mbox{for $c\ge0$}$$ How can I show that this limit is correct?,"['real-analysis', 'limits']"
1040479,Shooting bullets [duplicate],"This question already has answers here : Colliding Bullets (5 answers) Closed 8 years ago . This is from http://domino.research.ibm.com/Comm/wwwr_ponder.nsf/challenges/May2014.html Every second, a gun shoots a bullet in the same direction at a random constant speed between 0 and 1. The speeds of the bullets are independent uniform random variables. Each bullet keeps the exact same speed and when two bullets collide, they are both annihilated. After shooting $n$ bullets, prove that the probability that eventually all the bullets will be annihilated is zero if $n$ is odd and $\prod_{i=1}^{n/2} \frac{2i-1}{2i}$ when $n$ is even. I tried to write recursion without success and Markov chain's but I don't see how them helps here. The case of $n\equiv 1 \pmod 2$ seems to be trivial.",['probability']
1040495,Question about some properties of combinatorial structures,"Consider $\mathcal A$ as the set of perfect matchings in the complete bipartite graph $K_{n,n}$ and let  $i$ be an edge of $K_{n,n}$. 
Let 
$$
B_i=\{a\in \mathcal A: \hbox{matching }a\hbox{ has edge }i\}.
$$
Clearly $\frac{|\mathcal A|}{|B_i|}=\frac{n!}{(n-1)!}=n$, which is $poly(n)$ and which is independent of $i$. I have the following question: For which combinatorial structures (other than perfect matchings) it holds that $\frac{|\mathcal A|}{|B_i|}$ is independent of $i$? Is there any name for this property?","['combinatorial-proofs', 'discrete-mathematics', 'combinatorics']"
1040497,"Brownian motion, reproducing kernel Hilbert space, and the Laplace operator","Consider the standard Brownian motion on $[0,1]$: $$
dB_t, \; B_0 = 0,
$$ defined on the probability space $(\Omega, P)$. It covariance function is $K(s,t) = \min \{s ,  t\}$ on $[0,1] \times [0,1]$. The RKHS with reproducing kernel $K$ is the Sobolev space $$
\mathcal{H}_K = \{f \; {\tt absolutely \; continuous}, \; f(0) = 0, f'\in L^2[0,1] \}
$$ with inner product $$
\langle f, g \rangle_{\mathcal{H}_K} = \int f'g'.
$$ This can be seen by noting that $t \mapsto \min \{ s,t\}$ has weak derivative $1_{[0, s]}$. Questions $\mathcal{H}_K$ is isomorphic to the Hilbert space generated by $\{ B_t\}_{t \in [0,1]}$, with isomorphism $K_t(s) = K(t,s) \mapsto B_t \in L^2(\Omega, P)$. So it looks like one can define a stochastic integral against $dB_t$ with deterministic integrands. Is there a name for this integral? It looks a bit strange when compared to the Ito integral. For example, the increment $B_{s_2} - B_{s_1}$ is identified with $$
\min(s_2, t) - \min(s_1, t).
$$ I've encountered the claim that ""(the differential operator) $-\frac{d^2}{dx^2}$ is the reproducing kernel of $B_t$"". How is $-\frac{d^2}{dx^2}$ related to $K$? Subject to boundary conditions, integrating by parts can recover the inner product on $\mathcal{H}_K$ but I don't see an identification with the Sobolev space $\mathcal{H}_K$: $$
- \int f''g = \int f'g'.
$$ Related to 2.: the infinitesmal generator of $B_t$ as a Markov process happens to be the Laplacian $\frac{d^2}{dx^2}$. Is this a related to the above? The Cameron-Martin space of $B_t$ also just happens to be $\mathcal{H}_K$. Same objects, all related to the Brownian motion $B_t$, keep coming up via (apparently) different constructions...what's happening here? Is there a way they fit together?","['stochastic-processes', 'stochastic-integrals', 'probability-theory', 'brownian-motion', 'hilbert-spaces']"
1040498,Questions about the Moduli Space of Vector Bundles of rank 2 with trivial determinant,"Let $M_0$ be the moduli space of rank 2 semi-stable vector bundles over X with trivial determinant which is a singular projective variety of dimension $3g-3$. $M_0$ is constructed as the $GIT$ quotient of the $R(2,p)$ by $SL(p)$. Let $M_0^{s}$ be the points of moduli space corresponding to the semi-stable points of $R(2,p)$. Then the singular locus of $M_0$ is the Kummer Variety $\mathbb{K}$ or the complement of $M_0^{s}$. The elements of $\mathbb{K}$ are of the form $L\oplus L^{-1}$, where L is a line bundle of degree 0. $\mathbb{K}_0$ be bundles of the form $L\oplus L^{-1}$ such that $L=L^{-1}$, i.e., $L^2$ is trivial. Question 1 - What is meant by a Kummer Variety? Why $\mathbb{K}_0$ is the Kummer Variety of dimension g? $\mathbb{Z_2}$ acts on $Jac_0$ by involution i.e., $(0,L)\longmapsto L$ and $(1,L)\longmapsto L^{-1}$ $\mathbb{K}$ $\cong$ $Jac_0//\mathbb{Z_2}$. There are $2^{2g}$ number of fixed points $\mathbb{Z_2^{2g}}=\{[L\oplus L^{-1}:L\cong L^{-1}]\}$of the action. Question2 .- Is this isomorphism is isomorphism as varieties? Question3- Why are there are $2^{2g}$ number of fixed points of the action. Thus $M_0$ has a stratification $M_0=M_0^{s}\coprod(\mathbb{K}-\mathbb{Z_2^{2g}})\coprod Z_2^{2g}$. Over each point in the deepest strata $\mathbb{Z_2^{2g}}$ there is unique closed orbit in $R(2,p)^{ss}$. By deformation theory, the normal space of the orbit at a point h, which represents $L\oplus L^{-1}$ where $L\cong L^{-1}$ is, $H^{1}(End_0(L\oplus L))\cong H^{1}(\mathcal(O))\oplus \mathcal{sl}(2)$ Question4 - Why is the last statement true?","['algebraic-geometry', 'vector-bundles']"
1040505,Why is $(1-\cot 37^\circ)(1-\cot 8^\circ)=2.00000000\cdots$?,"Apparently, 
$$(1-\cot 37^\circ)(1-\cot 8^\circ)=2.00000000000000000\cdots$$ Since it is a $2.0000000000\cdots$ instead of $2$, it isn't exactly $2$. Why is that?",['trigonometry']
1040513,Using an Integral to Solve for a Variable a,"I am struggling to use the following equation: $$
\int_0^a \sqrt{a^2-x^2}\,\,\text{sgn}(|x|-1)\, dx = 0
$$ where $a > 1$, to deduce that $a = \text{cosec}(\frac{\pi}{4} - \frac{\alpha}{2})$, where $\alpha$ satisfies $\alpha = \cos(\alpha)$. I integrate the integrand, via $$
\int_0^a \sqrt{a^2-x^2}\,\,\text{sgn}(|x|-1)\, dx = -\int_0^1 \sqrt{a^2-x^2}\, dx + \int_1^a \sqrt{a^2-x^2}\, dx 
$$ But once I calculate those integrals I cannot seem to get any closer to the answer. Any help would be great.","['trigonometry', 'integration']"
1040547,Finding range for $\frac{1}{\exp(x^2)+3}$,"What is the range of $$\large\frac{1}{e^{x^2}+3}$$ I know that the answer is $\dfrac{1}{4}\ge h(x)\gt0$, but how do I show it",['functions']
1040553,Adapted but not progressively measurable?,"Let $X(t,\omega)$ be a stochastic process: $$
X: \mathbb{R}^+ \times \Omega \rightarrow \mathbb{R},
$$ where $(\Omega, \mathcal{F}_t, \mathcal{F}, \mu)$ is a stochastic basis. Some definitions: $X$ is said to be measurable if it is Borel measurable with respect to the product $\sigma$-algebra $\mathcal{B}(\mathbb{R}^+) \otimes \mathcal{F}$, where $\mathcal{B}(\mathbb{R}^+)$ is the Borel $\sigma$-algebra on $\mathbb{R}^+$. $X$ is said to be adapted if, for all $t>0$, $X(t, \omega)$ is $\mathcal{F}_t$-measurable. $X$ is said to be progressively measurable if, for all $T > 0$, the restriction of 
$X$ to $[0, T] \times \Omega$ is Borel measurable with respect to the product $\sigma$-algebra $\mathcal{B}([0, T]) \otimes \mathcal{F}_T$-measurable. Question Apparently an adapted and measurable process need not be progressively measurable. This necessarily means that $\mathcal{B}([0, T]) \otimes \mathcal{F}_t$ 
  is not the $\sigma$-algebra $[0, T] \times \Omega$ inherits as a subset of $\mathbb{R}^+ \times \Omega$. Could somebody give a simple example of such a process, adapted and measurable but not progressively measurable? Or a reference for such?","['probability-theory', 'reference-request']"
1040555,Visualizing Balls in Ultrametric Spaces,"I've been reading about ultrametric spaces, and I find that a lot of the results about balls in ultrametric spaces are very counter-intuitive. For example: if two balls share a common point, then one of the balls is contained in the other. The reason I find these results so counter-intuitive is that I can easily picture ""counter-examples,"" the problem being that these ""counter-examples"" are balls in Euclidean space. My issue is not that I cannot prove these results. My issue is that I don't know how to think about/picture balls in ultrametric spaces, which makes it more difficult for me to actually come up with the proofs. Hence, does anyone have any hints as to how to think about/picture balls in ultrametric spaces?","['p-adic-number-theory', 'analysis']"
1040573,"If the probability density on a random vector is symmetric, then each variable is identically distributed?","Let $X$ be a random vector with joint distribution $F$ and density $f$. If $f$ is symmetric, is this equivalent to each random variable being identically distributed? We say $f$ is symmetric if it is invariant to a permutation in its arguments. For $X$ a vector of length $n$ of discrete random variables (say integer valued just for the sake of it) this gives $\Pr(X_i=x)=\sum_{Y\in\mathbb{Z}^{n-1}} f(X_i=x,X_{-i}=Y)$. But with $f$ symmetric, whichever $i$ we choose should be arbitrary, so $\Pr(X_i=x)=\Pr(X_j=x)$ for any choice of $x,i,j$. Is this correct? Does this change at all for continuous random variables? I would just replace the sum with an integral?",['probability']
1040597,Assume that $f$ is $2\pi$ continuous and $C^1$ such that $\int_{-\pi}^{\pi} f(x) dx=0$.,"Show that $\int_{-\pi}^{\pi} (f(x))^2 dx \leq \int_{-\pi}^{\pi} (f'(x))^2 dx$. So here's my approach to this question: Assume that $f$ was $2\pi$ continuous and $C^1$. Therefore, we have that $s_n(f)$ converges uniformly to $f$. So let  $f(x) = \frac{a_0}{2} + \sum_{n = 1}^{\infty} (a_n \cos (nx) + b_n \sin (nx))$. Since we are given $\int_{-\pi}^{\pi} f(x) dx = 0$, we have that $a_0 = 0$. Now we find $f'$ in terms of coefficients of $f$: $$f'(x) = \sum_{n = 1}^{\infty} (n b_n \cos(nx) - n a_n \sin (nx))$$ We have that all the eigenfunctions are orthogonal on $[-\pi, \pi]$ and  $\int_{-\pi}^{\pi} \sin^2(nx) dx = \pi = \int_{-\pi}^{\pi} \cos^2(nx) dx$ So by Parseval's identity, we have that: $$\int_{-\pi}^{\pi} (f(x))^2 dx = \pi \sum_{n=1}^{\infty} (a^2_n +b^2_n)$$ $$\int_{-\pi}^{\pi} (f'(x))^2 dx = \pi \sum_{n=1}^{\infty} n^2 (a^2_n +b^2_n)$$ It is clear that $n^2 \geq 1$ for all $n \in \mathbb{N}$, so we have that: $$\int_{-\pi}^{\pi} (f(x))^2 dx = \pi \sum_{n=1}^{\infty} (a^2_n +b^2_n)\leq  \pi \sum_{n=1}^{\infty} n^2 (a^2_n +b^2_n) = \int_{-\pi}^{\pi} (f'(x))^2 dx $$ Some reason I feel like there's something wrong with this. But I can't put my finger on it. Is there a better approach to this?","['fourier-series', 'real-analysis']"
1040609,Range of Influence of the Wave Equation?,"Suppose $u$ is a solution of the two-dimensional wave equation
$$u_{tt}-c^2 \Delta u=f(x)$$ 
with initial values $u(0),u_t(0)$ that have support on the disc $x_1^2+x_2^2 \le 1$. Up to what time can you be sure that $u=0$ at the point $(x_1,x_2)=(2,3)$? My attempt: I think it depends on the point farthest from $(2,3)$ in the disc, which is $(-\frac{-2 \sqrt {13}}{13},-\frac{-3 \sqrt {13}}{13})$. Then by the range of influence of wave equation, the time should be $t=\frac{14+2\sqrt {13}}{c}$, where $c$ is constant of two dimensional wave equation $u_{tt}-c^2 \Delta u=f(x)$, $14+2\sqrt {13}$ is the distance of $(2,3)$ and $(-\frac{-2 \sqrt {13}}{13},-\frac{-3 \sqrt {13}}{13})$. Is that right? Can anyone help? Thanks so much!:)","['wave-equation', 'partial-differential-equations', 'analysis']"
1040617,algebra with topology homework problem,"Hello Everyone, I have this homework problem, I'm going to share what i have so far, not sure if Im in the right path. First, I have: $$f \sim g \,  \Leftrightarrow \,x_0 \in \mathbb{R^n}, \exists \,U \ni x_0\,\mid f|_U = g|_U$$ (A) Reflexivity: $f \sim f \Rightarrow$ for $x_0 \in \mathbb{R^n}, \exists \,U \ni x_0\,\mid f|_U = f|_U$ (B)Symmetry:  If $f \sim g$ then $g \sim f$ $\Rightarrow$ for $x_0 \in \mathbb{R^n}, \exists \,U \ni x_0\,\mid f|_U = g|_U$ and $g|_U = f|_U$ (C)Transitivity:
If $f \sim g$ and $g \sim h$, then $f \sim h \Rightarrow $ for $ x_0 \in \mathbb{R^n}, \exists \,U,V \ni x_0\,\mid f|_U = g|_U$ and $\,\,\,\,\,\,\,\,g|_V = h|_V,$ therefore $f|_{U \cap V} = h|_{U \cap V}$, so $f \sim h$ Now, the equivalence class are defined as follows:
 $$[f]= \{\varphi \in C_{x_0}\ | \varphi \sim f\} \Rightarrow \varphi|_U = f|_U $$ $$[g]= \{\pi \in C_{x_0}\ | \pi \sim g\}  \Rightarrow \pi|_V = g|_V$$ They are welldefined, lets suppose that $[f]=[\phi]$ and $[g]=[\psi]$, then we say that:$[f]+[g] = [\phi]+[\psi] $ and $[f][g]=[\phi][\psi] $. Now by definition,for $x_0 \in \mathbb{R^n}, \exists \,U \ni x_0\, ,f|_U = \phi|_U$ and $\exists \, V \ni x_0\ ,g|_V = \psi|_V $, this implies that:$$(f+g)|_{U \cap V} = (\phi+\psi)|_{U \cap V} \Rightarrow [f + g] = [\phi + \psi],$$ $$(f g)|_{U \cap V} = (\phi \psi)|_{U \cap V} \Rightarrow [f  g] = [\phi  \psi]$$ So they are well defined.On the other hand, I have: $$\phi:C_{x_0} \longrightarrow \mathbb{R}, \phi[f]=f(x_0) $$ So the kernel of $\phi$ is $M_{x_0}$, so by the first isomorphism theorem, we have that:
$$ C_{x_0}/M_{x_0} \cong \mathbb{R} $$Now, $\mathbb{R}$ is a field, therefore $C_{x_0}/M_{x_0} $ is a field $\Rightarrow$ $M_{x_0}$ is maximal. To prove that $M_{x_0}$ is the unique maximal, first we notice that $M_{x_0}$ contains no units, so if $f \notin M_{x_0}.$ Then $f(x_0) \neq 0 \Rightarrow \exists \, U \ni x_0$ such that $f(y) \neq 0, \forall y \in U \Rightarrow 1/f$ exists in a neighborhood of $x_0, \, \Rightarrow 1/f$ is a unit in $C_{x_0} \Rightarrow C_{x_0}$ is a $\mathbf{local \,ring}$, so $M_{x_0}$ is the unique maximal by the characterization of $\mathbf{local\, rings}$ Now to prove that $M_{x_0}$ is finitely generated, We have:
$$ h(1) - h(0) = \int^1_0 h'(s)\,ds$$ where $f(x_0)=0 $ in $M_{x_0}$ and $h(s) = f(s(x-x_0) +x_0)$. On the other hand, $$h'(s) = \sum\limits_{i=1}^n \frac{\partial}{\partial x_i} \frac{\partial x_i}{\partial s}, $$ 
but $\frac{\partial x_i}{\partial s} = (x_i - x_0^{i}),$ this is true because for $s \in \mathbb{R}$ and notice that $h:\mathbb{R} \rightarrow \mathbb{R}$, therefore $(s(x-x_0) +x_0) \in \mathbb{R} \Rightarrow (s(x_i-x_0^{i}) +x_0) \in \mathbb{R^n} $. Now, $h(1) = f(x)$ and $ h(0) = f(x_0)=0$. Hence: $$f(x) = \sum\limits_{i=1}^n (x_i-x_0^{i})\cdot(\int^1_0 \frac{\partial f}{\partial x_i}\,ds),$$ Now, since the integral $\int^1_0 \frac{\partial f}{\partial x_i}\,ds$ depends on the variable $s$, we thus have that the generators of $M_{x_0}$ are $(x_i-x_0^{i})$. In other words,
$$M_{x_0} = \langle x_1-x_0^{1},x_2-x_0^{2}, \cdots, x_n-x_0^{n}\rangle$$ Now im not sure about a few thing: 1) this is the right proof for the equivalence relation ${\bf Done}$ 2) I don't understand how to proof that they are well defined ${\bf Done}$ 3) $C_{x_0}/M_{x_0} $ is a field, then $M_{x_0} $ is maximal, this prove that is the unique one. ${\bf Done}$ 4) Is the procedure in $M_{x_0}$ is finitely generated clear or I need some other stuff, my professor told me that the functions in the exercise are smooth too","['general-topology', 'ring-theory', 'ideals', 'abstract-algebra']"
1040633,Integration by parts (Differential Geometry),"I am studying the proof of a theorem and I am stuck. It says that by integration by parts we get that: For $g(t)$ a variation of Riemannian metrics wih $g'(0)=h,$ $$\int_{M} (-\Delta (tr h) + \delta^2 h)\;dV_g=0$$ where $\Delta$ is the rough Laplacian, and $\delta^2 h=\nabla^i \nabla^j h_{ij}$ is the double-divergence operator. I don't understand how integration by parts imply that this integral is equal to zero. Any help is appreciated!","['geometry', 'riemannian-geometry', 'differential-geometry']"
1040653,Homotopy of double chain complexes,"Consider complexes $(A,d_1), (A',d_1)$, $(C,d_2), (C',d_2)$ and morphisms $f_1,f_2: (A,d_1)\to (A',d_1)$ and $g_1,g_2: (C,d_2)\to (C',d_2)$ of degrees $0$. Consider the functor $(-\otimes-)$, then 
$$A\otimes C = \bigoplus_{m,n} A^m\otimes C^n, \text{along with differentials}$$
$$
\partial_1 = d_1\otimes C: A^n\otimes C^m\to A^{n+1}\otimes C^m,
$$
$$
\partial_2 = (-1)^n A\otimes d_2: A^n\otimes C^m\to A^n\otimes C^{m+1}
$$
 forms a double complex. Given homotopies $s:f_1\cong f_2$ and $t:g_1\cong g_2$, Cartan Eilenberg claims that $(s\otimes C, (-1)^nA\otimes t)$ yields a homotopy between $f_1\otimes g_1$ and $f_2\otimes g_2$ which I failed to see. As a first step, we need to check that 
$$
(s\otimes C)\partial_1+\partial_1(s\otimes C)+ (-1)^n(A\otimes t)\partial_2+ (-1)^n\partial_2(A\otimes t) = f_1\otimes g_1-f_2\otimes g_2
$$
but this is not true, as the left hand side simplifies to
\begin{align*}
& (s\otimes C)\partial_1+\partial_1(s\otimes C)+ (-1)^n(A\otimes t)\partial_2+ (-1)^n\partial_2(A\otimes t)\\
= & (sd_1+d_1s)\otimes C+ (-1)^{2n} A\otimes (td_2+d_2t)\\
= &(f_1-f_2)\otimes C+ A\otimes (g_1-g_2)
\end{align*}
which is not equal to the right hand side. Could you please help me point out what went wrong? Thank you. The relevant material is page 63 last but one paragraph of Cartan Eilenberg, see attached.","['abstract-algebra', 'homological-algebra', 'tensor-products', 'spectral-sequences', 'abelian-categories']"
1040665,Is there always an equilibrium point in a field?,"For instance, considering a set of planets represented as point masses that create a gravitational field, will there always, no matter what set of points, be a place where I can stand with no net force acting upon me? For a simple two or three body case, there seems to always be a point or a region, but I'm not sure if it generalizes to all cases.","['physics', 'functions']"
1040700,Is the limit function $f$ continuous if $f_n(x_n)\to f(x)$? [duplicate],"This question already has answers here : If $f_n(x_n) \to f(x)$ whenever $x_n \to x$, show that $f$ is continuous (4 answers) Closed 9 years ago . Let $I\subset\mathbb{R}$ be an interval and let $(f_n)$ be a sequence of continuous real-valued functions on $I$. Consider the following statements: $f_n\to f$ uniformly; For every sequence $(x_n)$ in $I$ converging to $x\in I$, we have $f_n(x_n)\to f(x)$; $f:\ I\longrightarrow\mathbb{R}$ is continuous. Certainly (1) implies (2) and (3). If $I$ is compact, (2) and (3) together imply (1), otherwise counterexamples can be found. My interest is on the relationship between (2) and (3), specifically does (2) imply (3)? My intuition says no, since (2) would appear to be a strictly weaker statement than (1). However, (2) is certainly stronger than pointwise convergence of $(f_n)$, and so far I have been unable to think of a counterexample. Can anyone think of a counterexample (or proof)","['real-analysis', 'analysis']"
1040702,"Function notation meaning: $f: \{a,b\} \to a$ - Zorich - MA I - p18","I have some notation I haven't seen before: $$f: \{a,b\} \to a\text{ and } g:\{a,b\}\to b$$ What does this mean? We are mapping from some $X=\{a,b\}$ to some $Y=a$? So pretty much we are always mapping to the first element? I don't get why this implies $g \circ f : \{a,b\} \to b$ We first map $\{a,b\}\to a$ and then map $a \to b$? That doesn't make sense to me. I feel like I have an element after $f$ and then $g$ doesn't make sense. What am I thinking about incorrectly? Also, why are we mapping from a set, to an element?","['algebra-precalculus', 'functions']"
1040717,How to prove this integral is divergent: $\int_{0}^{1}\frac{dx}{\ln{x}\ln{(1-x)}}$,"Show that this following integral is divergent (or diverges, if you prefer) $$\int_{0}^{1}\dfrac{dx}{\ln{x}\ln{(1-x)}}$$ I know that $x=0,1$ are singularities of the function and I want use the following well-known inequality: $$\ln{(1+x)}<x, \,\text{whenever $x>-1$}.
$$ so $$\dfrac{1}{\ln{x}\ln{(1-x)}}>\dfrac{1}{-x\ln{x}}>0$$ since $$\int_{0}^{1}\dfrac{1}{x\ln{x}}=\ln{\ln{x}}|_{0}^{1}=+\infty$$ Are there any other methods I could use?","['convergence-divergence', 'calculus', 'integration', 'definite-integrals', 'analysis']"
1040729,Prove domain of Dependence Inequality for the Wave Equation?,"Let $(x_0,t_0)\in R^{n+1}$ with $t_0>0$, and let $\Omega$ be the conical domain in $R^{n+1}$ bounded by the backward characteristic cone with apex at $(x_0,t_0)$ and by the plane $t=0$. Suppose $u\in C^2(\overline \Omega)$ and statisfies $$\Delta u -u_{tt}-q(x)u=0$$ in $\Omega$, where $q(x)>0$. Derive the domain of dependence inequality
$$\int_{B(x_0,t_0-T)}u_{x_1}^2+...+u_{x_n}^2+u_{t}^2+qu^2|_{t=T}dx\le \int_{B(x_0,t_0)}u_{x_1}^2+...+u_{x_n}^2+u_{t}^2+qu^2|_{t=0}dx$$
where $0\le T\le t_0$ and $B(x_0,r)$ denotes the ball ${x:|x-x_0|<r}$. My attempt: I have no clue about this problem. Maybe using energy's method? Can anyone give me some hints or references like lecture notes? Thanks so much!","['functional-analysis', 'partial-differential-equations', 'wave-equation']"
1040753,If $f(x) $ and g(x) are functions such that $f(x+y) =f(x)g(y) +g(x) f(y) $ then ...,"Question : 
If $f(x) $ and g(x) are functions such that $f(x+y) =f(x)g(y) +g(x) f(y) $ then $\begin{vmatrix}
f(\alpha) & g(\alpha) & f(\alpha + \theta) \\ f(\beta) & g(\beta) & f(\beta +\theta) \\ f(\gamma) & g(\gamma) & f(\gamma + \theta) \\
\end{vmatrix}$ is independent of (a) $\alpha$ (b) $\beta$ (c) $\gamma$ (d) $\theta$ My approach  : Let x =0, y =0 the given equation becomes : $f(0+0) = f(0) g(0) +g(0)f(0) $ $\Rightarrow f(0) =2f(0)g(0) $ $\Rightarrow f(0) \{ 1-2g(0)\} =0$ $\Rightarrow f(0) =0; g(0) =\frac{1}{2}$ Now assuming x=1, y=0 we get $f(1) =\frac{1}{2}$ But I dont know how to proceed further to get f(x) and g(x) please guide thanks.","['algebra-precalculus', 'functions']"
1040764,"For a given group $G$ , what are the sets on which a non-trivial group action of $G$ can be defined ?","Say we are given a group $G$ , we want to find those sets on which we can define an action of $G$ ; now in this sense any set $X$ works as we can always define the trivial action $o:G \times X \to X$ by $gox:=x$ ; but what if we want to allow only non-trivial actions ? that is for a given group $G$ can we always define a non-trivial group action on any set $X$ ? If not then can we classify those sets , depending on $G$ , on which a non-trivial group action of $G$ can be defined ?","['group-theory', 'group-actions']"
1040772,Proving $x^2 - y^2 + z^2 \gt (x - y + z)^2$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Prove that $$x^2 - y^2 + z^2 > (x - y + z)^2$$ where: $x < y <z$  for all natural numbers. Thank for help.","['inequality', 'algebra-precalculus']"
1040780,$G/Z(G) \cong \mathbb Z_p \times \mathbb Z_p$ then $p||Z(G)|$,"Problem Let $G$ be a finite group with $G/Z(G) \cong \mathbb Z_{p} \times \mathbb Z_{p}$. Then $p| |Z(G)|$. My attempt at a solution Consider the action of $G$ on itself by conjugation. By the class equation, we have $$|G|=|Z(G)|+\sum_{i=1}^r [G:C_G(x_i)], \space [G:C_G(x_i)]>1$$
It is easy to see that $Z(G) \leq C_G(x)$ for all $x$ so, by Lagrange theorem, $|Z(G)| | |C_G(x)|$. As $|C_G(X)|||G|=|Z(G)|p^2$, it follows $\dfrac{|C_G(x)|}{|Z(G)|}|p^2$. We can write $[G:C_G(x_i)]=\dfrac{[G:Z(G)]}{[C_G(x_i):Z(G)]}=\dfrac{p^2}{[C_G(x_i):Z(G)]}$ Since $[G:C_G(x_i)]>1$ for $i=1,...,r$, and by the last equality, we have $p| [G:C_G(x_i)]$ for $i=1,...,r$. But then we also have $p||G|$. As $p$ divides $|G|$ and $\sum_{i=1}^r [G:C_G(x_i)]$, it follows $p$ divides $Z(G)$. I am not sure if my solution is correct, I would appreciate corrections, improvement, or an alternative answer if anyone feels like sharing a different solution. Edition: I've realized I am not so sure how to properly justify the sentence ""...$|Z(G)| | |C_G(x)|$. As $|C_G(X)|||G|=|Z(G)|p^2$, it follows $\dfrac{|C_G(x)|}{|Z(G)|}|p^2$..."", any help with that part would also be appreciated.","['group-theory', 'abstract-algebra']"
1040792,NIMO 16.8 Expected Value + Probability,Let $p=2^{16}+1$ be a prime. A sequence of $2^{16}$ positive integers $\{a_n\}$ is monotonically bounded if $1\leq a_i\leq i$ for all $1\leq i\leq 2^{16}$. We say that a term $a_k$ in the sequence with $2\leq k\leq 2^{16}-1$ is a mountain if $a_k$ is greater than both $a_{k-1}$ and $a_{k+1}$. Evan writes out all possible monotonically bounded sequences. Let $N$ be the total number of mountain terms over all such sequences he writes. Find the remainder when $N$ is divided by $p$.,"['discrete-mathematics', 'probability', 'contest-math']"
1040793,How to show that $\lim_{x\to \infty}f'(x)=0$,"Let $f$ be a real-valued, bounded, twice differentiable function defined on $(0,\infty)$ with $f'(x)\ge 0$ and $f''(x)\le 0$. Show that $$\lim_{x\to \infty}f'(x)=0$$ I understand $f: (0,\infty) \rightarrow \mathbb{R}, |f(x)|<M$ and $f''$ exists. But I coun't find the way to use the facts and show the limit is zero.","['self-learning', 'derivatives', 'real-analysis', 'limits']"
1040831,Are there non-equivalent cardinal arithmetics?,"‎Generalizing a concept in mathematics is always a problematic situation. In most cases there are several ways to generalize a notion and it is not easy to decide if a particular generalization is more natural , useful or better than the other alternatives. The same situation happens in set theory when we are trying to generalize the arithmetic operators to infinities. The case of ordinal arithmetic is less controversial because it has a straightforward recursive definition applicable for all usual and hyperoperators. But in the case of cardinal arithmetic we have defined all addition, multiplication and exponentiation cases separately as follows: $\kappa+\lambda$ is the size of disjoint union of two sets with $\kappa$ and $\lambda$ elements . $\kappa.\lambda$ is the size of Cartesian product of two sets with $\kappa$ and $\lambda$ elements . $\kappa^\lambda$ is the size of set of all functions from a set with $\lambda$ elements to a set with $\kappa$ elements. In each case we isolated a combinatorial property and defined our arithmetic operator as the size of a set definable from parameters $\kappa$ and $\lambda$ . As it is clear this method of generalizing operators could be done in many different ways and some of them could be non-equivalent . For example in finite combinatorics $m+n$ could be size of many different definable sets rather than disjoint union and these definable notions could be different on infinite cardinals. Note that according to the usual definition of our cardinal arithmetic which remained unchanged since the beginning of set theory, the first two operators (addition and multiplication) became counter-intuitively equal and as trivial as maximum operator. Also they are completely determined within ZFC. On the other hand the third operator (exponentiation) became highly non-trivial and completely undetermined even in the simplest case. i.e. ZFC cannot decide about the value of $\aleph_0^{\aleph_0}$ . Why such a large gap exists between cardinal exponentiation and cardinal addition and multiplication? Why addition and multiplication are counter-intuitively equal? Are there better arithmetics on cardinal numbers which have a more natural behavior , a rich theory and a deep connection with each other? Let us explore the above questions more precisely by considering all possible definitions for arithmetic operators over cardinals. Definition 1: Let $*:\omega\times\omega\rightarrow\omega$ be an arithmetic operator (i.e. ordinary addition, multiplication, exponentiation, tetration, ... over natural numbers), the first order formula $\phi (x,y,z)$ in the language of set theory is called a $*$ - notion over cardinals (e.g. addition notion over cardinals, multiplication notion over cardinals, etc.) if and only if $(a)~~ZFC\vdash \forall \kappa,\lambda\in Card~~~~~\{x~|~\phi (x,\kappa,\lambda)\}$ is a set. $(b)~~ZFC\vdash \forall m,n\in\omega~~~~~| \{x~|~\phi (x,m,n)\} |=m*n$ Associated with any $*$ - notion $\phi (x,y,z)$ over cardinals one can define an operator $*_{\phi}:Card\times Card\rightarrow Card$ as follows: $\forall\kappa,\lambda\in Card~~~~~\kappa *_{\phi}\lambda :=|\{x~|~\phi (x,\kappa,\lambda)\}|$ Note that by property $(a)$ , the operator $*_{\phi}$ is well-defined. Also by property $(b)$ it is a generalization of arithmetic operator $*$ to infinite cardinals. Example: If $+:\omega\times\omega\rightarrow\omega$ is the ordinary addition of natural numbers then the first order formula $\phi (x,y,z):\exists s\in y~\exists t\in z~~~x=\langle s,0 \rangle \vee x=\langle t,1\rangle$ asserting that "" $x$ is a member of disjoint union $y$ and $z$ "" is a $+$ - notion over cardinals and the corresponding operator $+_{\phi}:Card\times Card\rightarrow Card$ is the usual addition of cardinals. Definition 2: If $*:\omega\times\omega\rightarrow\omega$ is an arithmetic operator and $\phi (x,y,z), \psi (x,y,z)$ are two $*$ - notions over cardinals, we call $\phi, \psi$ equivalent , $\phi \sim \psi$ , if and only if their corresponding cardinal arithmetics are same. i.e. $$ZFC\vdash \forall\kappa,\lambda\in Card~~~~~\kappa *_{\phi}\lambda = \kappa *_{\psi}\lambda$$ Question 1: Is there any addition notion for cardinals non-equivalent to the usual addition notion of cardinals? If yes, how many of such addition notions are there up to $\sim$ equivalence relation? In the other words, is there any formula $\phi (x,y,z)$ such that: $ZFC\vdash \forall \kappa,\lambda\in Card~~~~~\{x~|~\phi (x,\kappa,\lambda)\}$ is a set $ZFC\vdash \forall m,n\in\omega~~~~~| \{x~|~\phi (x,m,n)\} |=m+n$ $ZFC\nvdash \forall\kappa,\lambda\in Card~~~~~\kappa *_{\phi}\lambda = \kappa +\lambda$ What about multiplication and exponentiation? In particular, is there an exponentiation notion over cardinals that its value in the simplest case, $\aleph_0$ , remains undetermined even if we have a full knowledge of values of the usual cardinal exponentiation by assuming GCH? Precisely, is there any formula $\phi (x,y,z)$ in the language of set theory such that: $ZFC\vdash \forall \kappa,\lambda\in Card~~~~~\{x~|~\phi (x,\kappa,\lambda)\}$ is a set $ZFC\vdash \forall m,n\in\omega~~~~~| \{x~|~\phi (x,m,n)\} |=m^n$ $ZFC+GCH\nvdash \aleph_0 *_{\phi} \aleph_0=\aleph_0^{\aleph_0}$ (equivalently $ZFC+GCH\nvdash | \{x~|~\phi (x,\aleph_0,\aleph_0)\} |=\aleph_1$ ) Besides nice behavior of each particular arithmetic operator over cardinals, it is important to consider the relative situation of these operators with respect to each other. In fact we should search for a sequence of generalizations for addition, multiplication, exponentiation, ... on cardinals that satisfies some nice properties. Definition 3: Let $\{*^i\}_{i\in \omega}$ be the natural enumeration of all arithmetic operators on natural numbers (i.e. $*^0$ , $*^1$ , $*^2$ , $*^3$ are addition, multiplication, exponentiation and tetration respectively.) and $\{\phi_{i}(x,y,z)\}_{i\in\omega}$ is a sequence of formulas such that $\forall i\in\omega~~~\phi_{i}(x,y,z)$ is a $*^i$ - notion. Now consider the sequence $\{*^{i}_{\phi_{i}}\}_{i\in\omega}$ of arithmetic notions over cardinals. We call the sequence $\{*^{i}_{\phi_{i}}\}_{i\in\omega}$ natural iff $$\forall i\in\omega~\forall\kappa,\lambda\in Card\setminus\{0,1\}~~~~~\kappa *^{i}_{\phi_{i}}\lambda >\kappa, \lambda$$ e.g. Each sequence of cardinal arithmetics which contains the usual addition (or multiplication) of infinite cardinals is not natural because for all infinite cardinals $\kappa, \lambda$ we have $\kappa +\lambda = \kappa$ or $\kappa +\lambda = \kappa$ . Two sequences $\{*^{i}_{\phi_{i}}\}_{i\in\omega}$ and $\{*^{i}_{\psi_{i}}\}_{i\in\omega}$ are equivalent, $\{*^{i}_{\phi_{i}}\}_{i\in\omega}\sim\{*^{i}_{\psi_{i}}\}_{i\in\omega}$ , iff $$\forall i\in\omega~~~~~\phi_i\sim\psi_i$$ Question 2: How many natural sequences of cardinal arithmetics are there up to equivalence relation defined in definition 3? Question 3: Which other properties can we add to "" being natural "" to get a unique sequence of cardinal arithmetics up to equivalence? Could such a unique sequence with nice properties, be our standard cardinal arithmetic?","['set-theory', 'logic', 'cardinals', 'arithmetic', 'combinatorics']"
1040856,tangent space of manifold and Kernel,"I want to understand the proof of this Theorem : Theorem : 
Let $ S $ be a submanifold of $ E $ and let $ a \in S $. Assume that there exists a submersion $f : E \supset U  \rightarrow F$  of class $ \textit{C}\ ^{1} $ and $ b\in f(U) $ such that $ S=f^{-1}(b) $ then $ T_{a}S=Ker f'(a) $. Proof : 
Since $ f(S)\subset \{b\}$, $f'(a).T_{a}S\subset \{0\}$. Hence $T_{a}S\subset Ker f'(a)$. Since both spaces have the same dimension, the result follows. My problem is that I am not able to understand all the steps in the proof. Can some one help me?","['linear-algebra', 'differential-geometry', 'analysis']"
1040873,"An example of a function in $L^1[0,1]$ which is not in $L^p[0,1]$ for any $p>1$","Title says most of it. Could you help me find an example? It is easy obviously to show a function that would not be in $L^p[0,1]$ for a specific $p$ (say $(1/x)^{1/p}$, but I can't see how it would be done for all $p$. The reason I'm asking is because we proved in class that $L^p[0,1]$ is nowhere dense as a subset of $L^1[0,1]$, so there must be some $L^1[0,1]$ like this.. Thanks :) Added: thanks for all the comments. there was some missing parts about how to use convergence theorems that i couldn't complete my own so i'd love assistance :)","['lp-spaces', 'functional-analysis', 'real-analysis', 'analysis']"
