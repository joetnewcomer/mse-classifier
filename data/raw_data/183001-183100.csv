question_id,title,body,tags
3344941,How do I find the range of the following function?,"The question says to find the range and domain of $$P(x) = \frac{\sin(x)-1}{\sqrt{3-2\sin(x)-2\cos(x)}}$$ How do I approach this problem? For domain, I know I should set the denominator $>0$ so that it doesn't become undefined...but not really how to proceed further. Any help would be appreciated.",['functions']
3344950,Local idempotents in power series rings,"Let $R$ be a commutative ring with identity. Recall that an idempotent element $e$ of $R$ is an element a such that $e^2=e$ , and a local idempotent is an idempotent a such that $Re$ is a local ring. We know the following facts: 1) $f\in R[[x]]$ is idempotent if and only if $f^2=f\in R$ , where $R[[x]]$ is the ring of power series over R. 2) The maximal ideals of the ring $R[[x]]$ have the form $M’=(M,x)$ where $M$ is a maximal ideal of $R$ . Question: Let $e^2=e$ be an idempotent element in $R$ (also in $R[[x]]$ ) if the following is true?: $e^2=e$ is a local idempotent element in $R$ if and only if $e^2=e$ is a local idempotent element in $R[[x]]$ .","['algebraic-geometry', 'ring-theory', 'abstract-algebra', 'commutative-algebra']"
3344975,What if there are infinite stationary points?,"I want to calculate extremes of certain multivariable function $f(x,y)=(6−x−y)x^2y^3$ . After solving system of derivatives $f_x=0$ and $f_y=0$ I got something like this: $P_1=(x,0),x\in \mathbb R$ $P_2=(0,y),y\in \mathbb R$ $P_3=(2,3)$ First two conditions are satisfied with infinite number of $x$ and $y$ . How am I supposed to act in such situation? Do I have to check the first two points in some way? If so, how should I do this?","['analysis', 'extreme-value-analysis']"
3345025,"Proving that $C=\{A \cup N : A \in \mathcal{A}, N \in \mathcal{N}\}$ is a $\sigma$-algebra","I am having trouble proving this part (for a bigger homework problem). I have to prove that the set $$C=\{A \cup N : A \in \mathcal{A}, N \in \mathcal{N}\}$$ is a $\sigma$ -algebra where $(X,\mathcal{A},\mu)$ is a measure space and $\mathcal{N}$ is the collection of all null sets with respect to $\mathcal{A}$ and $\mu$ . I am stuck in the part of proving closure under complements. I already completed closure under unions. Let $A \in \mathcal{A}$ and $N \in \mathcal{N}$ . Then $(A \cup N)^C = A^C \cap N^C$ . But I don't know how to proceed. I thought the complement of a null set would have measure equal to that of the set $X$ (Assuming it is part of the sigma algebra $\mathcal{A}$ ). Is it better to prove also closure under intersections and then use that and closure under unions to prove closure under complements?","['measure-theory', 'real-analysis']"
3345037,Prove that a function is bijective and show that G is a group,"Let $a\in\mathbb{R}^∗$ and $b\in \mathbb{R}$ . Consider the function $f_{a,b} \in \operatorname{Fun}(\mathbb{R},\mathbb{R})$ given by $f_{a,b}(x)= ax + b$ . a) Show that $f_{a,b}$ is a bijection, and find its inverse function. b) Let $G$ be the set of functions $\{f_{a,b}|a \in \mathbb{R}^∗
, b \in \mathbb{R}\}$ . Show that $G$ is a group, where the group operation is composition of functions. (Thus $G$ is a subgroup of $\operatorname{Bij}(\mathbb{R}, \mathbb{R})$ .) My attempt to solve part a: Let $x_1, x_2 \in \mathbb{R}$ and assume $x_1 \ne x_2$ . Then $f_{a,b}(x_1) = ax_1+b$ and $f_{a,b}(x_2) = ax_2+b$ . Thus $f_{a,b}(x_1) \ne f_{a,b}(x_2)$ and hence, $f_{a,b}$ is injective. Since $a\in \mathbb{R}^∗$ and $b\in \mathbb{R}$ , then $ax+b\in \mathbb{R}$ and thus $f_{a,b}(x)=ax + b\in \mathbb{R}$ and since it is a mapping from $\mathbb{R}$ to $\mathbb{R}$ then $f_{a,b}(\mathbb{R})=\mathbb{R}$ which means that $f_{a,b}$ is surjective. Therefore, $f_{a,b}$ is at a time injective and surjective which means it is bijective. It's inverse function: $$f_{a,b}^{-1}(x)=\frac{x-b}{a}$$ Could you please check if I made any mistake in the proof and please give some insights on how to solve part b? thank you!","['group-theory', 'abstract-algebra', 'function-and-relation-composition', 'inverse-function']"
3345050,Stochastic domination and sum of random variables,"I'm dealing with a statement that seems trivial but I couldn't prove it rigorously. Suppose that I have two i.i.d. random variables $X_1$ and $X_2$ and another couple of i.i.d. variables $Y_1$ and $Y_2$ ( $X$ and $Y$ are independent on each other and do not need to have the same law). Suppose that $X$ dominates $Y$ in the sense that $$\mathbb{P}(X \ge t) \ge \mathbb{P}(Y \ge t), \quad \forall \: t \in \mathbb{R}  $$ How can I show that $$\mathbb{P}(X_1+X_2 \ge t) \ge \mathbb{P}(Y_1+Y_2 \ge t), \quad \forall \: t \in \mathbb{R}  $$ This seems pretty intuitive to me but I didn't get far.","['measure-theory', 'summation', 'probability', 'random-variables']"
3345073,Two very advanced harmonic series of weight $5$,"Very recently Cornel discovered two ( update: in fact there are more as seen from the new entires )  fascinating results involving harmonic series using ideas from his book, (Almost) Impossible Integrals, Sums, and Series , and which are the core of a new paper he's preparing: \begin{equation*}
\sum _{n=1}^{\infty } \frac{H_n H_{2 n}}{(2 n)^3}
\end{equation*} \begin{equation*}
=\frac{307}{128}\zeta(5)-\frac{1}{16}\zeta (2) \zeta (3)+\frac{1}{3}\log ^3(2)\zeta (2) -\frac{7}{8}  \log ^2(2)\zeta (3)-\frac{1}{15} \log ^5(2)
\end{equation*} \begin{equation*}
-2 \log (2) \operatorname{Li}_4\left(\frac{1}{2}\right) -2 \operatorname{Li}_5\left(\frac{1}{2}\right);
\end{equation*} and \begin{equation*}
\sum _{n=1}^{\infty } \frac{H_n H_{2 n}}{(2 n-1)^3}
\end{equation*} \begin{equation*}
=6 \log (2)-2 \log ^2(2)-\frac{1}{12}\log ^4(2)+\frac{1}{12} \log ^5(2)-\frac{3}{2} \zeta (2)-\frac{21}{8} \zeta (3)+\frac{173}{32} \zeta (4)
\end{equation*} \begin{equation*}
+\frac{527}{128} \zeta (5)-\frac{21 }{16}\zeta (2) \zeta (3)+\frac{3}{2} \log (2) \zeta (2)-\frac{7}{2}\log (2)\zeta (3)-4\log (2)\zeta (4)+\frac{1}{2} \log ^2(2) \zeta (2)
\end{equation*} \begin{equation*}
-\frac{1}{2}  \log ^3(2)\zeta (2)+\frac{7}{4}\log ^2(2)\zeta (3)-2 \operatorname{Li}_4\left(\frac{1}{2}\right)+2 \log (2)\operatorname{Li}_4\left(\frac{1}{2}\right),
\end{equation*} or, after adjustments, the form $$\sum _{n=1}^{\infty}\frac{H_n H_{2 n}}{(2 n+1)^3}$$ $$=\frac{1}{12}\log ^5(2)+\frac{31}{128} \zeta (5)-\frac{1}{2} \log ^3(2)\zeta (2)+\frac{7}{4} \log ^2(2)  \zeta (3)-\frac{17}{8} \log (2)\zeta (4) \\+2\log (2) \operatorname{Li}_4\left(\frac{1}{2}\right).$$ Update I : A new series entry obtained based on the aforementioned series \begin{equation*}
\sum _{n=1}^{\infty } \frac{H_n H_{2 n}^{(2)}}{(2 n)^2}
\end{equation*} \begin{equation*}
=\frac{23 }{32}\zeta (2) \zeta (3)-\frac{581}{128} \zeta (5)-\frac{2}{3}\log ^3(2) \zeta (2)+\frac{7}{4} \log^2(2)\zeta (3) +\frac{2}{15} \log ^5(2)
\end{equation*} \begin{equation*}
+4\log (2) \operatorname{Li}_4\left(\frac{1}{2}\right) +4 \operatorname{Li}_5\left(\frac{1}{2}\right);
\end{equation*} Update II : Another new series entry obtained based on the aforementioned series \begin{equation*}
\sum _{n=1}^{\infty } \frac{H_n H_{2 n}^2}{(2 n)^2}
\end{equation*} \begin{equation*}
=\frac{23 }{32}\zeta (2) \zeta (3)+\frac{917 }{128}\zeta (5)+\frac{2}{3}  \log ^3(2)\zeta (2)-\frac{7}{4}  \log ^2(2)\zeta (3)-\frac{2}{15} \log ^5(2)
\end{equation*} \begin{equation*}
-4 \log (2)\operatorname{Li}_4\left(\frac{1}{2}\right)-4 \operatorname{Li}_5\left(\frac{1}{2}\right);
\end{equation*} Update III : And a new series entry from the same class of series with an unexpected (and outstanding) closed-form \begin{equation*}
\sum _{n=1}^{\infty } \frac{H_{2n} H_{n}^{(2)}}{(2 n)^2}=\frac{101 }{64}\zeta (5)-\frac{5 }{16}\zeta (2) \zeta (3);
\end{equation*} It's interesting to note that $\displaystyle \sum _{n=1}^{\infty } \frac{H_{n} H_{n}^{(2)}}{n^2}=\zeta(2)\zeta(3)+\zeta(5)$ , which may be found calculated in the book, (Almost) Impossible Integrals, Sums, and Series , by series manipulations. A note : The series from UPDATE III seems to be known in literature, and it already appeared here https://math.stackexchange.com/q/1868355 (see $(3)$ ). Update IV : Again a new series entry from the same class of series \begin{equation*}
\sum _{n=1}^{\infty } \frac{H_n^2 H_{2 n}}{(2 n)^2}
\end{equation*} \begin{equation*}
=\frac{9 }{16}\zeta (2) \zeta (3)+\frac{421 }{64}\zeta (5)+\frac{2}{3} \log ^3(2)\zeta (2) -\frac{7}{4} \log ^2(2)\zeta (3) -\frac{2}{15} \log^5(2)
\end{equation*} \begin{equation*}
-4 \log(2)\operatorname{Li}_4\left(\frac{1}{2}\right) -4 \operatorname{Li}_5\left(\frac{1}{2}\right);
\end{equation*} Update V : A strong series - September 26, 2019 $$\sum _{n=1}^{\infty } \frac{H_{2n} H_n^{(2)}}{(2 n+1)^2}$$ $$=\frac{4}{3}\log ^3(2)\zeta (2) -\frac{7}{2}\log^2(2)\zeta (3)-\frac{21}{16}\zeta(2)\zeta(3)+\frac{713}{64} \zeta (5)-\frac{4}{15} \log ^5(2)$$ $$-8 \log (2)\operatorname{Li}_4\left(\frac{1}{2}\right) -8\operatorname{Li}_5\left(\frac{1}{2}\right);$$ Update VI : Three very challenging series - September 28, 2019 $$i) \ \sum _{n=1}^{\infty } \frac{H_n H_{2 n}^{(2)}}{(2 n+1)^2}$$ $$=\frac{35}{32} \zeta (2) \zeta (3)-\frac{651}{128} \zeta (5)+\frac{1}{3}\log^3(2)\zeta(2)-\frac{7}{4}\log^2(2)\zeta (3)+\frac{53}{16} \log (2)\zeta (4) -\frac{1}{30} \log ^5(2)$$ $$+4 \operatorname{Li}_5\left(\frac{1}{2}\right);$$ $$ii) \ \sum _{n=1}^{\infty } \frac{H_n H_{2 n}^2}{(2 n+1)^2}$$ $$=\frac{35}{32} \zeta (2) \zeta (3)+\frac{465}{128} \zeta (5)+\frac{1}{2}\log^3(2)\zeta(2)-\frac{7}{4}\log^2(2)\zeta (3)-\frac{11}{16} \log (2)\zeta (4) -\frac{1}{12} \log ^5(2)$$ $$-2\log(2) \operatorname{Li}_4\left(\frac{1}{2}\right);$$ $$iii) \ \sum _{n=1}^{\infty } \frac{H_n^2 H_{2 n}}{(2 n+1)^2}$$ $$=\frac{21}{16} \zeta (2) \zeta (3)-\frac{217}{64} \zeta (5)+\frac{2}{3}\log^3(2)\zeta(2)-\frac{7}{4}\log^2(2)\zeta (3)+ \log (2)\zeta (4) -\frac{1}{15} \log ^5(2)$$ $$+8\operatorname{Li}_5\left(\frac{1}{2}\right);$$ Update VII : Critical series relation used in the Update VI - September 28, 2019 $$i) \sum _{n=1}^{\infty } \frac{H_n H_{2 n}^2}{(2 n+1)^2}-\sum _{n=1}^{\infty } \frac{H_n H_{2 n}^{(2)}}{(2 n+1)^2}$$ $$=\frac{1}{6}\log ^3(2)\zeta (2) -4\log (2)\zeta (4)+\frac{279}{32} \zeta (5)-\frac{1}{20} \log ^5(2)-2 \log (2)\operatorname{Li}_4\left(\frac{1}{2}\right) -4 \operatorname{Li}_5\left(\frac{1}{2}\right);$$ $$ii) \ 4 \sum _{n=1}^{\infty } \frac{H_n H_{2 n}^2}{(2 n+1)^2}-\sum _{n=1}^{\infty } \frac{H_n^2 H_{2 n}}{(2 n+1)^2}$$ $$=\frac{49}{16} \zeta (2) \zeta (3)+\frac{1147}{64}\zeta (5)+\frac{4}{3}\log^3(2)\zeta (2) -\frac{21}{4} \log ^2(2)\zeta (3) -\frac{15}{4}\log (2)\zeta (4)-\frac{4}{15} \log ^5(2)$$ $$-8 \log (2)\operatorname{Li}_4\left(\frac{1}{2}\right) -8\operatorname{Li}_5\left(\frac{1}{2}\right),$$ where $H_n^{(m)}=1+\frac{1}{2^m}+\cdots+\frac{1}{n^m}, \ m\ge1,$ designates the $n$ th generalized harmonic number of order $m$ , $\zeta$ represents the Riemann zeta function, and $\operatorname{Li}_n$ denotes the Polylogarithm function. A note : for example, for those interested, one of the possible ways of calculating both series from UPDATE III and UPDATE IV is based on building a system of relations with the two series by exploiting $\displaystyle \int_0^1 x^{n-1} \log^2(1-x)\textrm{d}x=\frac{H_n^2+H_n^{(2)}}{n}$ and $\displaystyle \sum_{n=1}^{\infty} x^n(H_n^2-H_n^{(2)})=\frac{\log^2(1-x)}{1-x}$ .
Apart from this, the series from UPDATE III allows at least a (very) elegant approach by using different means. Using the first series we may obtain (based on the series representation of $\log(1-x)\log(1+x)$ and the integral $\int_0^1 x^{n-1}\operatorname{Li}_2(x)\textrm{d}x$ ) a way for proving that $$\int_0^1 \frac{\operatorname{Li}_2(x) \log (1+x) \log (1-x)}{x} \textrm{d}x=\frac{29 }{64}\zeta (5)-\frac{5 }{8}\zeta (2) \zeta (3).$$ Then, based on the solution below and using the alternating harmonic series in the book, (Almost) Impossible Integrals, Sums, and Series , we have $$\int_0^1 \frac{\operatorname{Li}_2(-x) \log (1+x) \log (1-x)}{x} \textrm{d}x$$ $$=\frac{5 }{16}\zeta (2) \zeta (3)+\frac{123 }{32}\zeta (5)+\frac{2}{3}  \log ^3(2)\zeta (2)-\frac{7}{4}  \log ^2(2)\zeta (3)-\frac{2}{15}\log ^5(2)\\-4 \log (2)\operatorname{Li}_4\left(\frac{1}{2}\right)-4 \operatorname{Li}_5\left(\frac{1}{2}\right).$$ And if we add up the two previous integrals, we get $$\int_0^1 \frac{\operatorname{Li}_2(x^2) \log (1+x) \log (1-x)}{x} \textrm{d}x$$ $$=\frac{275}{32}\zeta (5)-\frac{5 }{8}\zeta (2) \zeta (3)+\frac{4}{3}  \log ^3(2)\zeta (2)-\frac{7}{2}  \log ^2(2)\zeta (3)-\frac{4}{15}\log ^5(2)\\-8 \log (2)\operatorname{Li}_4\left(\frac{1}{2}\right)-8 \operatorname{Li}_5\left(\frac{1}{2}\right).$$ Update (integrals): Another curious integral arising during the calculations $$\int_0^1 \frac{x \log (x) \log(1-x^2) \operatorname{Li}_2(x)}{1-x^2} \textrm{d}x=\frac{41 }{32}\zeta (2) \zeta (3)-\frac{269 }{128}\zeta (5).$$ QUESTION : Have these series ever been known in literature? I'm not interested in solutions but only if the series appear anywhere in the literature.","['integration', 'reference-request', 'harmonic-numbers', 'calculus', 'sequences-and-series']"
3345078,"Extrinsics vs Intrinsics geometry, intuitive explanation","I was wondering if anyone can give me an insight of what is meant with ""Intrinsics Geometry"" and ""Extrinsics Geometry"". At the beginning I thought this was like a distinction between differentiation and integration (in order to distiguish local analysis from global analysis), however I have the feeling I might have got this completely wrong. So I looked this up on wikipedia and I quote what I've found: From the beginning and through the middle of the 18th century,
  differential geometry was studied from the extrinsic point of view:
  curves and surfaces were considered as lying in a Euclidean space of
  higher dimension (for example a surface in an ambient space of three
  dimensions). The simplest results are those in the differential
  geometry of curves and differential geometry of surfaces. Starting
  with the work of Riemann, the intrinsic point of view was developed,
  in which one cannot speak of moving ""outside"" the geometric object
  because it is considered to be given in a free-standing way. The
  fundamental result here is Gauss's theorema egregium, to the effect
  that Gaussian curvature is an intrinsic invariant. The intrinsic point of view is more flexible. For example, it is
  useful in relativity where space-time cannot naturally be taken as
  extrinsic (what would be ""outside"" of it?). However, there is a price
  to pay in technical complexity: the intrinsic definitions of curvature
  and connections become much less visually intuitive. These two points of view can be reconciled, i.e. the extrinsic
  geometry can be considered as a structure additional to the intrinsic
  one. (See the Nash embedding theorem.) In the formalism of geometric
  calculus both extrinsic and intrinsic geometry of a manifold can be
  characterized by a single bivector-valued one-form called the shape
  operator. I still don't think like I get it, can anyone clarify? From the quote above what I'm getting is that intrinsics geometry assumes that the geometry analyzed is embedded in a bigger space (for example in differential geometry of curve and surface when we define the first fundamental form we rely on the euclidean metric of $\mathbb{R}^3$ to provide a definition, while we don't do this in Riemannian geometry where we define the Riemann tensor). I'm not sure again though I fully understand the difference.","['soft-question', 'riemannian-geometry', 'differential-geometry']"
3345121,Sheafification of coker-presheaf of exp-map,"This question seems so obvious to me, that I think there could be a answer to it already. If so, I would appreciate a link! Let $X$ be a complex manifold. Let $\exp:\mathcal{O}_X \to \mathcal{O}_X ^\ast$ be the exponential map-morphism between the sheaf of holomorphic functions on $X$ and the sheaf of nowhere vanishing holomorphic functions on $X$ . Then $\exp$ is not surjective on arbitrary open subsets of $X$ : For example there is a holomorphic log-function on $\mathbb{C}\backslash(-\infty,0]$ AND on $\mathbb{C}\backslash[0,+\infty)$ but not on their union. Right? Q1.: Is my understanding correct, that the coker-presheaf $\text{coker}(\exp)$ is NOT trivial, then? Q2.: How do I see explicitly that the sheafification of this coker-presheaf is trivial? Is there a good explicit description of this sheafified coker-presheaf? If $\text{coker}^\sharp(\exp)$ and $\text{im}^\sharp(\exp)$ are the sheafified coker, resp. image presheaves. Is there an ""easy"" connection between them? Rem.: The sheafification $F^\sharp$ of a sheaf $F:Open(X)\to Rings$ as I know it, is as defined in Iversen: \begin{align}
 F^\sharp(U):=\{ \varphi_U \in \prod_{x \in U} F_x | \forall y \in U \exists y \in V \subset U:\exists g\in F(V):\varphi_U(y)=(V,g) \in F_y \}.
\end{align} The restriction is the restriction to smaller products of stalks, which then still satisfy the property required. I inserted a bit of my own notation since I can think of it beter this way. Is this construction correct? I could replace $\prod$ with $\coprod$ , right? Thanks in advance!","['complex-geometry', 'algebraic-geometry', 'sheaf-cohomology', 'sheaf-theory']"
3345158,Prove that the reduced row echelon form (rref) of an $n$ by $n$ matrix either is the identity matrix 𝐈 or contains at least one row of zeroes.,"I'm trying to prove the following proposition Prove that the reduced row echelon form (rref) of an $n$ by $n$ matrix either is the identity matrix $\bf I$ or contains at least one row of zeroes. Firstly, I will quote the definition of the rref from the same book where the proposition was given: A matrix is in reduced row echelon form, normally abbreviated to rref,
  if it satisfies all the following conditions: If there are any rows containing only zero entries then they are located in the bottom part of the matrix. If a row contains non-zero entries then the first non-zero entry is a 1. This 1 is called a leading 1. The leading 1’s of two consecutive non-zero rows go strictly from top left to bottom right of the matrix. The only non-zero entry in a column containing a leading 1 is the leading 1. Now, my attempt: Assume $\bf A$ is $n$ x $n$ matrix, where $\bf R$ is rref of $\bf A$ . Suppose $\bf R ≠ I$ . Then $\bf R$ must have a leading $1$ (call it $x_{i,j}$ ) which is located in ith row and jth column and $j > i$ . Since $\bf R$ is in rref, then all leading $1$ must go strictly to the bottom right of the matrix. We are left with the $n - j$ columns and $n - i$ rows. because $j > i$ , then $n - i > n - j$ and thus there must be at least $j-i$ zero rows. Now suppose $\bf R$ doesn't have row of zeros. In this case, if $x_{i,j}$ = 1, then $i = j$ , because we've shown that if $j > i$ then $\bf R$ will have row of zeros. And by definition of the identity matrix, we can conclude that $\bf R = I$ $\Box$ . Although I have a lot of doubts, but I will ask: is it correct? The proposition is kind of intuitive, however, it was a struggle for me to formalize my thoughts. If you have any remarks/suggestions about the proof above, I'd be glad to hear them!","['proof-writing', 'proof-verification', 'linear-algebra']"
3345165,Taylor expansion of a function on the unit sphere,"I would like to understand how Taylor expansion works on the unit sphere.
Similar questions have already been asked here and here , but I did not quite understand the answers.
What stopped me from understanding the answers was mostly my lack of knowledge about differential geometry and manifolds (I guess). Maybe someone could guide me through an example. Assume we are given a function $f: \mathbb{S}^2 \rightarrow \mathbb{R}$ . To make it more precise I just assume a polynomial $f(x,y,z) = x^1y^2 z^3$ . Let $p$ be the north pole, e.g. $p=(0,0,1)^T$ . Let $q$ be close to $p$ and given by $q=\epsilon \cdot (a,b,c)^T \in \mathbb{S}^2$ for $\epsilon$ small. The previous answers were mentioning the tangent space, which, to my understanding, is the plane $\{(x,y,1) \text{ for } x,y \in\mathbb{R}\}$ . Now the part where I am unsure. Do I simply compute $\partial_x f(x,y,z) = y^2z^3$ and $\partial_y f(x,y,z) = 2xyz^3$ And obtain $f(q) \approx f(p) + q_1\partial_x f(p) + q_2 \partial_y f(p)$ where $q_i$ represents the $i$ -th entry of $q$ . What about the difference in $z$ ? I somehow need to incorporate the curvature of my space, or (and maybe equivalently) the mapping from the sphere to the tangent space. How would this work? What would this mapping look like for the unit sphere? Instead of $f(q) \approx f(p) + q_1\partial_x f(p) + q_2 \partial_y f(p)$ , do I maybe have to use $f(q) \approx f(p) + \tilde{q}_1\partial_x f(p) + \tilde{q}_2 \partial_y f(p)$ where $\tilde{q}$ is the projection of $q$ onto the tangent space?","['taylor-expansion', 'differential-geometry']"
3345211,Euler vs. Heun Numerical Methods,"I have a question about Heun's numerical method. I have the understanding that Heun's method is basically an improved Euler method which uses Euler as a predictor step and find the values of $y$ at the next steps and take average of the two. However, I was thinking, what if I create two predictor steps? For instance: a) One called $y_n^*$ that predicts $y$ at $\frac{h}{10}$ $y_n^*=y_n+\frac{h}{10}f(y_n)$ b) Another called $y_{n+1}^{**}$ that predicts the value at $\frac{2h}{10}$ $y_{n+1}^{**}=y_n+\frac{2h}{10}f(y_n)$ Finally: the actual would be calculated by $y_{n+1}=y_{n}+h[\omega(y_n^*)+(1-\omega)f(y_{n+1}^{**})]$ , $\omega\in\mathbb{R}$ For instance, we can make $\omega = \text{""anything to make truncation error at least one and particular omega""}$ ( $\omega=\frac{1}{2}$ ) will give us truncation error two. But I am not exactly sure I understand this completely. How is it (if it is) better than having one predictor step? In case anything isn't clear: $h$ is the step size and the interval is [ $x_n$ , $x_{n+1}$ ] Thank you.","['education', 'numerical-methods', 'discrete-mathematics', 'math-software']"
3345219,"""Squeezing lemma"" for tubolar neighborhoods","During the proof of the fact that every smooth submanifold $N \subset R^n$ has a tubolar neighborhood, I need to prove that there is a smooth function $f: N \mapsto \mathbb{R}^+$ that ""squeezes"" the tubolar nbhd into an open set $U$ such that the map $g:(p,v) \mapsto p+v$ is an embedding from $U$ to $\mathbb{R}^n$ . Now, I get why this works locally ( $dg_{(p,0)}$ is the identity, if I am not mistaken), but I would like to see a relatively rigorous proof that this ""squeezing function"" is smooth and more important that $g$ restricted to $U$ is an embedding. Again, this sounds obvious given how $g$ is defined, but I would like to see a sufficiently rigorous proof. EDIT: As pointed out, it should be explained why I bother searching for such $f$ . The fact is that $g$ is an embedding if you restrict yourself on a sufficiently small neighborhood $U$ of $N$ seen into its normal bundle. The squeezing function is required to embed $\nu N$ into $U$ leaving $N$ fixed. This way I’d have that $g \circ f$ is an embedding of $\nu N$ in $\mathbb{R}^m$ that is also an open nbhd of $N$ and leaves $N$ fixed, so it is a tubolar nbhd.","['smooth-manifolds', 'differential-geometry']"
3345229,Equivalent forms of Hahn Banach Theorem,"I am studying the Hahn Banach Theorem in the case of Topological Vector Spaces, and would like to prove the equivalence between the following three statements: [(HB1): Geometric Hahn Banach Theorem ] Let E be a TVS, M a linear manifold in E and A a nonempty convex open subset of E such that $M\cap A=\emptyset$ . Then there exists an hyperplane containing M and not intersecting A. [(HB2): Analytical Hahn Banach Theorem] Let E be a vector space, p  a seminorm on E and M a subspace of E. If f is a linear form on M such that $|f(x)|\leq p(x)\ \forall x\in M$ then there exist a linear extension to E such that $|f_1(x)|\leq p(x)\ \forall x\in E$ [(HB3): Separation of Points] If E is a Hausdorff LCS, then E' separates points of X. That is, if x and y are distinct points of E, then there exists some $\lambda\in E' $ such that $\lambda(x)\neq\lambda(y)$ . Above E' is the continuous dual of the space E. I have understood the proof of (HB1) based on the Zorn's Lemma. Moreover in many references (Treves, Schefer) one can find a proof of $HB1\rightarrow HB2$ . Schecter which claims the three result equivalents, does not provide explicit proofs of this implications, since he actually goes through various other equivalent results. Does anyone know a reference or may suggest how to see the remaining implications?","['topological-vector-spaces', 'reference-request', 'functional-analysis', 'hahn-banach-theorem', 'convex-analysis']"
3345240,Closed form of $\sum_{n = 1}^{\infty} \frac{n^{n - k}}{e^{n} \cdot n!}$,"When seeing this question I noticed that $$
\sum_{n = 1}^{\infty} \frac{n^{n - 2}}{e^{n} \cdot n!}
= \frac{1}{2}.
$$ I don't know how to show this, I tried finding a power series that matches that but no avail. Hints are very much appreciated. But this can be generalised:
Define $$
S_{k}(x)
:= \sum_{n = 1}^{\infty} \frac{n^{n - k}}{x^{n} \cdot n!}.
$$ WolframAlpha shows e.g. that $S_1(e) = 1$ and $$
S_0(x) = - \frac{W(-x^{-1})}{1 + W(-x^{-1})},
$$ where $W$ denotes the Lambert W-function.
Is there any closed form for this sum or a special $k$ or $x$ beyond those results? Somebody attempted to answer this using the Lagrange inversion theorem. I didn't work out completely but looked quite promising.","['power-series', 'summation', 'lambert-w', 'sequences-and-series']"
3345290,About the measurability of unbounded function on interval,"I was asked if a real function $f$ on $[a,b]\subseteq \mathbb{R}$ with countably many points of discontinuity is $\mathcal{B}_{\mathbb{R}}$ - measurable. If $f$ were bounded, I know it's Riemann/Lebesgue integrable, meaning that it is measurable. What if $f$ were unbounded? Thanks!","['integration', 'self-learning', 'measure-theory']"
3345304,Derived tensor product and cohomology,"Apologies for the naive question. Let $X$ be a projective variety over a field, and let $F^\bullet$ be an object in $D^b(X):= D^b_{coh}(\operatorname{Qcoh}X)$ . Suppose now that $E$ is an object complex in $D^b(X)$ ; I would like to know when $H^i(F^\bullet \otimes^L E) \cong H^i(F^\bullet) \otimes E$ . Certainly if $i$ is the maximal integer such that $H^i(F^\bullet) \neq 0$ the formula holds by right exactness of the tensor product, but say if $F^\bullet$ belongs to $\operatorname{Perf} X$ , is this true for all $i$ ?","['homological-algebra', 'algebraic-geometry', 'derived-categories']"
3345305,What is a Gradient?,"I am having trouble understanding visually what a gradient is. My understanding is it is a generalisation of tangential slopes to higher dimensions and gives the direction of steepest ascent. There are 4 different pictures I have: 1) From Khan Academy. How does it make sense to have a 2d gradient when your function is 3d? And shouldn't it be tangential to the function? The only way this makes sense to me is if you consider it as the projection of the tangential gradient vector onto the x-y plane. Is this right? 2) From a Medium article explaining Lagrange Multipliers. I understand the gradient for f but I'm not able to understand the gradient of g visually. It is a plane right? 3) I have plotted some samples from MacOS Grapher. I'm assuming Vector Field Cartesian form is the Gradient Vector. Why are the arrows going inward? Shouldn't they be tangential to the curve? 4) Finally, I have drawn some 3d curve. Could you tell me which gradient is correct? A, B or C? Any help appreciated. Sorry for the lengthy post but I have been breaking my head on this for a while. Thanks in advance. Edit: Changed Legrande to Lagrange.","['calculus', 'linear-algebra']"
3345320,Supremum and Infimum Proof: $\inf(x) + \sup(y) \leq \sup(x+y)$,"Im stuck on how to prove this: $$\inf(x) + \sup(y) \leq \sup(x+y)$$ I know that $$\inf(x) \leq \sup(x)\\
x \leq y\implies \sup(x) \leq \inf(y)\\
\sup(x) + \sup(y) \geq \sup(x+y)\\
\inf(x) + \inf(y) \leq \inf(x+y)\\
x \leq y\implies \sup(x)\leq \sup(y)$$ How can I utilize these to prove this? I've come to the conclusion that $$\inf(x)+\inf(y) \leq \inf(x+y) \leq \sup(x+y) \leq \sup(x) + \sup(y)$$ I've also tried utilizing the $\sup(x) = -\inf(-x)$ proof, but that doesn't seem to work either.","['inequality', 'supremum-and-infimum', 'analysis']"
3345393,"If $f$ is a $0$-form and $dx$ a $1$-form, then does $f\ dx=f\wedge dx$?","If $f$ is a $0$ -form and $dx$ a $1$ -form, then does $f\ dx=f\wedge dx$ ? Background: I am trying to prove that $d(f\ dx)=df\wedge dx$ using only the four properties of $d$ : (1) $d(w+v)=dw+dv$ (2) $d(w\wedge v)=dw\wedge v+(-1)^{\deg w}w\wedge dv$ (3) $f$ is a $0$ -form $\implies df$ is the differential of $f$ (4) $f$ is a $0$ -form $\implies d^2f=0$ My proof: $d(f\ dx)=d(f\wedge dx)=df\wedge dx+f\wedge d^2x=df\wedge dx$ . The second and third equal signs come from property 2 and 4 respectively. But the first one must come from $f\ dx=f\wedge dx$ . My question is why this is true. Although it seems very trivial, I believe a rigorous explanation is as follows: Let $A$ be the alternating map from the tensor product of $0$ -forms and $1$ -forms to its subspace of alternating tensors. Then by definition $f\wedge dx=A(f\otimes dx)$ . But there is a multiplication defined between $0$ -forms and $1$ -forms, so that tensoring means multiplying, and $f\otimes dx= f\ dx$ . And $A$ , as the alternating map over $1$ -forms, is actually the identity. Hence $f\wedge dx=A(f\otimes dx)=f\ dx$ Is this a correct explanation?","['exterior-derivative', 'exterior-algebra', 'differential-forms', 'differential-geometry']"
3345404,Surface integrals in spherical coordinates,"If I am given a surface in spherical coordinates $(r,\theta,\varphi)$ , such that it is parametrised as: $$
\begin{align}
r&=r(\theta,\varphi)\\
\theta&=\theta\\
\varphi&=\varphi
\end{align}
$$ What is the area $S$ of such surface? Or more specifically, can you show how to get the result: $$
S=\int_{0}^{2\pi}\int_{0}^{\pi}\sqrt{r^2+\left(\frac{\partial r}{\partial \theta}\right)^2 + \frac{1}{\sin^2\theta}\left(\frac{\partial r}{\partial \varphi}\right)^2}\;r\sin\theta\;{\rm d}\theta\,{\rm d}\varphi
$$ Some definitions that I am using: $k$ -surface :
Let $k,N\in\mathbb{N}$ , $k<N$ , $M\subset \mathbb{R}^N$ is called a $k$ -surface , if there exists a non-empty open set $E\subset \mathbb{R}^k$ and a map $\varphi:\mathbb{R}^k\to \mathbb{R}^N$ , such that: (i) $\varphi(E)=M$ , (ii) $\varphi\in C^1(E;\mathbb{R}^N)$ , and (iii) the rank of Jacobi matrix of $\varphi$ is equal $k$ everywhere on $E$ .
The surface is called simple if $\varphi$ is also injective on $E$ and $\varphi^{-1}$ is continuous of $\varphi(E)$ . Surface integral of the first kind :
Let $k,N\in\mathbb{N}$ , $k<N$ , $M\subset \mathbb{R}^N$ is a simple $k$ -surface parametrized by the map $\varphi:\mathbb{R}^k\to \mathbb{R}^N$ , from the open set $E\subset \mathbb{R}^k$ and $f:\mathbb{R}^N\to\mathbb{R}$ is defined on $M$ . The surface integral of the first kind is defined by: $$
\int_M f\,\mathrm{d}S:=\int_E f(\varphi(t))\sqrt{\det{G(D_\varphi(t))}}\,\mathrm{d}t\,,
$$ if the integral on the right exists in the Lebesgue sense and is finite. Here, $G(A)$ denotes the Gramm matrix made from columns of $A$ and $D_\varphi$ is the Jacobi matrix of the map $\varphi$ . The numeric value of: $$
S_k(M):=\int_M f\,\mathrm{d}S\,,
$$ is called the $k$ -dimensional surface area of the $k$ -surface $M$ . Motivation for the question Now these definitions can be used to calculate e.g. the surface of a unit sphere. When one describes the sphere by the map (omitting one longitudinal line): $\varphi: (\eta,\psi)\mapsto(\cos\psi\cos\eta,\cos\psi\sin\eta,\sin\psi)$ , where $(\eta,\psi)\in E=(0,2\pi)\times(-\frac{\pi}{2},\frac{\pi}{2})$ . The Gramm matrix looks like: $$
\begin{pmatrix}
\cos^2\psi & 0 \\
0 & 1
\end{pmatrix}
$$ one ends up with the (here $\lambda_2$ denotes the Lebesgue measure): $$
S_2(M) = \int_E 1\sqrt{\det{G(D_\varphi(\eta,\psi))}}\,\mathrm{d}\lambda_2(\eta,\psi)=\int_0^{2\pi}\int_{-\frac{\pi}{2}}^{\frac{\pi}{2}}\cos\psi\,\mathrm{d}\psi\,\mathrm{d}{\eta}=4\pi
$$ I did not do anything else but blindly followed the definitions. The wrong result: If I do the same approach to the above problem at hand. My map is $\varphi:\,(\theta,\phi)\mapsto (r(\theta,\phi),\theta,\phi)$ , the Jacobian is then: $$
\begin{pmatrix}
\frac{\partial r(\theta,\phi)}{\partial \theta} & \frac{\partial r(\theta,\phi)}{\partial \phi} \\
1 & 0 \\
0 & 1
\end{pmatrix}
$$ The rank of this matrix is 2 as needed for a 2-surface. The Gramm matrix is then: $$G(D_\varphi)=
\begin{pmatrix}
1+ \left(\frac{\partial r(\theta,\phi)}{\partial \theta}\right)^2 & \frac{\partial r(\theta,\phi)}{\partial \theta}\frac{\partial r(\theta,\phi)}{\partial \phi} \\
\frac{\partial r(\theta,\phi)}{\partial \theta}\frac{\partial r(\theta,\phi)}{\partial \phi} & 1+ \left(\frac{\partial r(\theta,\phi)}{\partial \phi}\right)^2 
\end{pmatrix}
$$ with determinant evaluated to: $$
\det(G(D_\varphi)) = 1 + \left(\frac{\partial r(\theta,\phi)}{\partial \theta}\right)^2 + \left(\frac{\partial r(\theta,\phi)}{\partial \phi}\right)^2
$$ which leads to the surface area: $$S=\int_{S\subset\mathcal{R}^3}{\rm d}S=\int_{0}^{2\pi}\int_{0}^{\pi}\sqrt{1+\left(\frac{\partial r}{\partial \theta}\right)^2 + \left(\frac{\partial r}{\partial \varphi}\right)^2}\;{\rm d}\theta\,{\rm d}\varphi$$ Which is incorrect. The question is why, and please show the correct way with explanation because as suggested by the example with unit sphere, I did not have to do any transformations and it did work with curvilinear coordinates right away. So the answer provided by Quanto does not address this at all. Note to the edit: I have added quite a lot of details since the answer by Quanto, but the root problem is the same - to see by calculation explicitly how one arrives to the correct result and to understand why the my calculation for a sphere works (where i am not using Cartesian coordinates) but fails here.","['integration', 'calculus', 'surface-integrals', 'surfaces']"
3345424,Tangent and transcendental numbers,"Apart from the cases where $\theta$ is a rational multiple of $\pi$ , if $\theta$ is a transcendental number, is $\tan(\theta)$ necessarily transcendental? If yes, would it be possible, in some cases, to express both numbers via algebraic expressions, in the sense of using a finite number of basic algebraic operations plus exponentiation ( $+,-,\times,\div,\wedge$ ) to express the number? For example, $2^{\sqrt{2}}$ is transcendental. If no, is there an easy counterexample? The main motivation behind my question is to understand the nature of the relation between an angle and its tangent. Edit: Slight correction regarding the cases involving $\pi$ that I'm not interested in.","['number-theory', 'trigonometry', 'algebraic-number-theory', 'transcendental-numbers']"
3345436,"$\{x_n\}$ is a sequence in E such that $\forall T\in B(E,F),T(x_n) $ converges then $x_n$ also converges","$E,F$ are 2 Banach Spaces such that $\{x_n\}$ is a sequence in $E$ such that $\forall T\in B(E,F)$ such that $T(x_n) $ converges then $x_n$ also converges. I thought to apply the Uniform Boundedness principle. But I could not succeed. Please Can any  One just give me Some Hint SO that I could solve this problem? Any Help will  be appreciated","['functional-analysis', 'real-analysis']"
3345442,Market Making Card Game Strategy,"Recently i played a market making card game during a job round of a company. Following is the description of the same - In a game there are 5 players and 13 cards, used in total. Each card has a value. At the start of the game, each player is given a card from the set of 13 cards. There will be 4 cards face down on the table. The rest of the card will be discarded and will never come back in the game. Trading - The sum S of all the values of the cards will be traded in the game,i.e, the sum of the values of 9 cards. This will be done in several steps. Round 1 - Each player will know nothing but his own card, but in the subsequent rounds, cards faced down will be revealed one at a time. One of the player, say Player 1, starts by market making S. The initial market cannot be more than 20 points wide, i.e, the sell price cannot be more than higher than the buy price. All the players are free to trade. Once a trade happens, the market maker(i.e, player 1 will make a new market. This continues untill there are no trades. Round 2 - Before the start of the round, one card on the table will be turned up. Player 2 then makes the market at most 15 points wide. As before, others can trade or improve. Round 3-5 - In the further rounds, one card at a time will be revealed. Remaining players will start making markets. The market can be at most 10 points wide in round 3, and 5 wide in subsequent rounds. Settlement - At the end of the game, we shall calculate the sum of all the values of the cards on the table. The sum will be settlement value. What strategy i should apply for making most profit?","['finance', 'probability']"
3345446,Finding when $x^3-x-1$ splits $\bmod p$ using the Dedekind eta function,"I'm reading this paper (Higher Reciprocity Laws and Modular Forms of Weight One by T. Hiramatsu), and I'm trying to prove the examples given at the end. Specifically: the number of solutions of $x^3 - x - 1 \equiv 0 \pmod p$ is given by $$a(p)^2 - \left( \frac{-23}{p} \right),$$ where $(\frac{-23}{p})$ is the Legendre symbol and $a(p)$ is the $p$ th coefficient of the expansion $$\eta(\tau)\eta(23\tau) = \sum_{n=1}^{\infty} a(n)q^n, \ \ \ \ \ \ \  \ q=e^{2\pi i\tau},$$ and $\eta(\tau)$ is the Dedekind eta function. So here is what I've done. I've shown that by Euler's pentagonal number theorem $$F(\tau) = \eta(\tau)\eta(23\tau) = \sum_{u,v \in \mathbb{Z}} (-1)^{u+v}q^{((6u+1)^2 + 23(6v+1)^2)/24}.$$ From the paper, we have that F is a modular form of type $(1,\epsilon)$ of $\Gamma_0(92)$ , where $$\epsilon(d) = \left( \frac{-23}{d} \right).$$ The Hecke operator acts on F by $$T_pF = F(p\tau) + \frac{1}{p}\sum_{b=0}^{p-1}F\left(\frac{\tau +b}{p}\right)$$ I don't think it should be too hard to show this is an eigenform, I probably just need to show that $a(n)$ is multiplicative and maybe some relationship between consecutive prime powers. Though, I'm unsure as to whether the multiplicativity should follow from it being a Hecke eigenform, and that I should be proving it a different way. Once it is shown to be a Hecke eigenform, there is a theorem by Serre and Deligne, which says that there is a corresponding linear representation $$\rho: \mathrm{Gal}(\overline{\mathbb{Q}}/\mathbb{Q}) \to GL_2(\mathbb{C})$$ and if $p$ is a prime for which $\rho$ is unramified, then $$\mathrm{tr}(\rho(\text{Frob}_p)) = a(p) \quad\text{ and }\quad \det(\rho(\text{Frob}_p)) = \epsilon(p).$$ Furthermore, $\ker\rho = \mathrm{Gal}(\overline{\mathbb{Q}}/K)$ , where $K$ is some finite Galois extension. My main question is this: How do I find a polynomial $f$ such that $K$ is the splitting field of $f$ ? For this particular case, I know that $f(x) = x^3-x-1$ works, but I have no clue how to show this is true. My professor, sent me a link to this site, and I should be able to determine which extension it is by just looking at traces, but I'm curious as to whether there are any general methods for computing this . I'm able to show that $a(p) = 0 \iff \rho(\text{Frob}_p)$ is a matrix of order 2 , and by looking at conjugacy classes of $S_3$ I can determine that this corresponds to the fact that $f(x)$ factors as a linear polynomial and an irreducible quadratic over $\mathbb{Z}/p\mathbb{Z}$ . Similarly, $f(x)$ is irreducible if $a(p) = -1$ , and $f$ splits completely if $a(p) = 2$ . Showing that these are the only values $a(p)$ can take shouldn't be too hard. I imagine it just involves some modular arithmetic and that fact that the theorem by Serre and Deligne gives that $|a(p)| \leq 2$ . If I can solve all of this, the last thing I would hope to find, are conditions on $p$ for which $a(p)$ takes on the values above. I can show that $a(p) = 0$ if $\left(\frac{-23}{p}\right)=-1$ . In the paper I'm reading, in a previous example, he uses the fact that if $\left(\frac{-11}{p}\right) = 1$ then there exists $a,b \in \mathbb{Z}$ such that $p = a^2 + ab + 3b^2$ to show that the coefficients of the modular form in that example are determined by whether $p = x^2 + 11y^2$ or $3p = x^2 + 11y^2$ . However, that claim that $p = a^2+ab+3b^2$ relies on the fact that $\mathbb{Z}\left[\frac{1+\sqrt{-11}}{2}\right]$ is a UFD. In the example I'm trying to prove, the analogous case would be to use $p = a^2+ab+6b^2$ to split it into the cases of whether $p = x^2+23y^2$ or $6p = x^2 + 23y^2$ , and I can do this with no problems. The main problem with this however, is that $\mathbb{Z}\left[\frac{1+\sqrt{-23}}{2}\right]$ has class number 3, so we don't always have that $p = a^2 + ab + 6b^2$ . My final question is how can I get around this failure of unique factorization? One idea I have, is to instead use the class number and to show that $p^3 = a^2 + ab + 6b^2$ IS possible to possibly determine $a(p^3)$ and then use the recurrence relation for $a(p^n)$ to determine the value of $a(p)$ . However, I'm completely stuck here and have no clue if this will actually work or will involve some kind of circular argument. Any help would be greatly appreciated!","['number-theory', 'modular-forms', 'algebraic-number-theory']"
3345466,Presentation of Alternating group of order n,"The presentation $$\langle s_3,\dots, s_n|s_i^3=1, (s_is_j)^2=1, 3\le i\neq j\le n\rangle$$ is valid for alternating groups of order $n$ . I have to prove this. (This is Exercise 7.2 of Oleg Bogopolski's book Introduction to group theory , on its page 64.) One approach suggested in the text is $ s_i\to (1 2 i)$ . I am unable to establish that it is a presentation by this method. Can there be a way to establish equivalence with a standard presentation?","['symmetric-groups', 'group-presentation', 'group-theory', 'combinatorial-group-theory']"
3345486,Correctly applying rules of differentiation,"Let $f: \mathbb{R} \to \mathbb{R}$ be: $$
     f(x)=\left\{\begin{array}{lll} \frac{x^3-\sqrt{2e^x}}{3x^3}, & x>0 \\
         -x^2+2x^4-7, & x=0 \\
x^3-4e^2x, & x < 0.
\end{array}\right .
$$ If I want to analyze rigorously where $f$ is differentiable I would do it as follows: As $\mathbb{R_{>0}}$ is an open set we can apply the rules of differentiation (quotient rule, chain rule etc...) to $f_{\vert \mathbb{R_{>0}}}$ and hence $f$ is differentiable on the restriction $\mathbb{R_{>0}}$ . Then I apply the same reasoning to $f_{\vert \mathbb{R_{<0}}}$ . Although $f(x)=x^2+2x^4-7$ looks nice and smoothly, I mustn't apply the rules of differentiation to $f(x)=x^2+2x^4-7$ as it is only defined like this on an isolated point and not an open set. So I have to check the limit of the differential quotient to correctly prove if $f$ is differentiable or not on this restriction. I don't want to calculate the limit but can you give me a quick feedback on whether I have understood it correctly or not? I am not 100% sure if it is right to say that I mustn't apply the rules of differentiation to $f$ where it is only restricted on a sigle point. Any comments are appreciated","['limits', 'calculus', 'derivatives', 'real-analysis']"
3345488,Explanation of White Noise,"I have been trying to understand what a White Noise is and also a White noise Process and I have been trying to piece together different definitions that I have found online. I was wondering if my understanding of White Noise is correct These notes say that the the mathematical definition of White Noise is and $0$ mean Generalized Gaussian Processes on $S$ (I believe that $S$ needs to be a smooth function of rapid decrease?), namely $Y(\phi)$ , such that the variance of $Y(\phi)$ is $\int_{\mathbb R} \phi(t)^2 dt$ . So from my understanding, let $ \phi(t) \in S $ be a test function then we can consider the generalized stochastic process $$ X(\phi)=\int_{\mathbb R}\phi(t)dB_t $$ where $B_t$ is a brownian motion on $\mathbb R$ . So $X$ here is the Wiener Integral. It is a standard result that $X(\phi)$ is a $0$ -mean Gaussian random variable with variance $\int_{\mathbb R}\phi(t)^2dt $ . So according to the above definition, $X$ is a white noise. But, in the same notes linked above, it says that White Noise can be thought of as the derivative of a Brownian Motion, which i'll refer to as $\dot{B}_t$ . Now using the stochastic integration by parts formula we see that $$ -\int_{\mathbb R}\phi '(t)B_tdt = \int_{\mathbb R}\phi(t)dB_t \tag{1} $$ and now we will informally denote this last integral as $$ \int_{\mathbb R}\phi(t)\dot{B}_tdt \tag{2} $$ So putting (1) and (2) together we see that $$ -\int_{\mathbb R}\phi '(t)B_tdt = \int_{\mathbb R}\phi(t)\dot{B}_tdt \tag{3} $$ And we now see that $\dot{B}_t$ is the weak or distributional dervitive of the Brownian motion $B_t$ . So now in the same notes listed above, the author says that the process $X(\phi)$ , which was already said to be a White Noise, defines a White Noise $\dot{B}$ . My question now is that does White Noise refer to both $X$ and $\dot{B}$ ? If we regard White Noise as the derivative (in the sense of distributions) of a Brownian Motion then $\dot{B}$ is a White Noise. But just using the mathematical definition of a White Noise we also see that $X$ is a White Noise. Any input is appreciated!","['stochastic-processes', 'brownian-motion', 'probability-theory', 'probability']"
3345508,Sharpness of Kolmogorov-Chentsov,"The Kolmogorov-Chentsov continuity theorem is a general way to estimate the Hölder continuity of a process $X$ (up to taking a different version $\tilde{X}$ of $X$ ). However, I would like to know if this criterium is optimal. That is, given a process $X:[0,K] \longrightarrow \mathbb{R}$ define: $$
\alpha :=
\sup\Big\{ \frac{\log \mathbb{E}[|X_t-X_s|^p]}{p\log |t-s|}-\frac{1}{p}  \; \Big| \; t,s \in [0,K], p> 1, \mathbb{E}[|X_t-X_s|^p]<\infty   \Big\}
$$ Then, is it true that there exists no version $\tilde{X}$ of $X$ s.t $\tilde{X}$ is $\alpha$ -Hölder? Or maybe, just for $\beta >\alpha$ ? For instance, this statement is true for the Brownian Motion, however, at least in the proof I know for such fact uses the exact scaling $B_{at} \sim \sqrt{a}B_t$ , however, the moment condition is more general. Is there an additional assumption you need to make the statement true? I appreciate any references or ideas. EDIT: I suppose the constant I am ignoring is actually going to make a difference. So let me rephrase it. For $p > 1$ , define $\alpha(p)$ via $$
  \log \mathbb{E}|X_t - X_s|^p =   \alpha(p)\log|t-s| + O(1).
$$ if such expansion is possible.
Now, define $\alpha_c = \sup\{ \frac{\alpha(p)-1}{p}: p \text{ s.t }\mathbb{E}[|X_t-X_s|^p] <\infty \}$ . And then, the question is wether $X$ has a $C^\beta$ version for $\beta>\alpha_c$ .","['holder-spaces', 'probability-distributions', 'stochastic-processes', 'brownian-motion', 'probability']"
3345540,"Exact solution to a non-linear differential equation needed, if possible [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question I'd like to know how to solve the ODE $$\ddot{x} = \frac{x}{1 + ax^2}.$$ This equation represents the basic mechanism involved during the mass acceleration of an object by a Flywheel. Because the mass accelerates on the radial track, that crosses the Flywheel, the transfer of momentum from the Flywheel to the accelerating mass, produces a decrease in the angular velocity of the Flywheel. The solution to this equation would allow the tracking of the angular velocity change of the Flywheel over time. To simplify the presentation, the radial reference $r$ has been replaced by "" $x$ "" and "" $a$ "" represents a constant. The derivative of $x$ is in terms of time "" $t$ "".",['ordinary-differential-equations']
3345569,"What does ""$\times$"" mean when specifying the domain of a function?","Just a quick question on function notation. If specifying the function like this: $$f : X \times X \to Y,$$ what does the ' $\times$ ' symbol mean exactly? Does it mean that 2 elements of domain $X$ are combined via some relation ' $\times$ ' to give an element of codomain $Y$ or does it somehow represent a Cartesian product of the two sets, namely $X^2$ . In the latter case I don't know what the above specification means.","['notation', 'functions']"
3345588,Complete subset of $X$ such that elements are of a fixed norm value implies $X$ Banach,"I am doing the exercise 5 in section 5.2 of Naylor's Linear Operator Theory in Engineering and Science. Let $(X, ||·||)$ be a normed linear space and let $S_r = \{x ∈ X : ||x|| = r\}$ where $r > 0$ . Assume that $X \neq \{0\}.$ Show that $(X, || · ||)$ is a Banach space if and only if $(S_r, || · ||)$ is
  complete for some $r > 0$ . The left to right proof is easy enough. However, I'm having trouble proving right to left. In fact, I think it's incorrect. As a counterexample, let $X$ be the rationals over the field of rationals with the usual absolute value norm. This should be indeed a normed linear space. Fix $r$ >0. So $S_r$ should just be $\{-r,r\}$ . Here, the Cauchy sequences are the ones that are eventually constant. These clearly converge to either $-r$ or $r$ . Hence $S_r$ is complete, but $X$ , the rationals, is not Banach. Am I missing something? Any help is appreciated. Edit: As pointed out, my counterexample fails since my space must be over the reals or the complex numbers. This still leaves me at a roadblock. Any hint is appreciated.","['banach-spaces', 'complete-spaces', 'normed-spaces', 'hilbert-spaces', 'functional-analysis']"
3345642,Finding an integrating factor for $(3t + \frac{6}{y})dt + (\frac{t^2}{y} + \frac{3y}{t})dy = 0$,"I want to solve the differential equation $$
\begin{equation}
(3t + \frac{6}{y})dt + (\frac{t^2}{y} + \frac{3y}{t})dy = 0\
\end{equation}
$$ using an integrating factor of the form $t^a y^b$ in order to make it exact, where $$
M(t, y) = 3t + \frac{6}{y},\\
N(t, y) = \frac{t^2}{y} + \frac{3y}{t}.
$$ So we want $$
\begin{align}
\frac{\partial}{\partial y} (t^ay^bM) &= \frac{\partial}{\partial t} (t^ay^bN)\\
b t^a y^{b-1} M+ t^ay^b \frac{\partial}{\partial y}M  &= at^{a-1}y^bN + t^a y^b \frac{\partial}{\partial t}N.
\end{align}
$$ By susbtituting $$
\begin{align}
\frac{\partial}{\partial y}M &= -\frac{6}{y^2} \\
\frac{\partial}{\partial t}N &= \frac{2t}{y} - \frac{3y}{t^2},
\end{align}
$$ I arrived at $$
3b + 6(b-1)t^{-1}y^{-1} = (a+2) + 3(a-1)t^{-3}y^{2}.
$$ But how do I find the values of $a$ and $b$ from here? (Also, if my calculations could be verified, I'd really appreciate it!) Edit #1: Apparently, on the last line, I had arrived at $(a+1)$ , when in fact it should have been $(a+2)$ .","['integrating-factor', 'ordinary-differential-equations']"
3345698,How to prove function $f(X) := \text{tr} \left( X^{-1} A \right)$ is convex?,"Let $S^{n}_{+}$ and $S^{n}_{++}$ denote the set of positive semidefinite and positive definite (symmetric) $n \times n$ matrices, respectively. Let function $f : S^{n}_{++} \to \mathbb R$ be defined by $$f(X) := \text{tr} \left( X^{-1} A \right)$$ where $A \in S^{n}_{+}$ . When $f$ is differentiable, given that $$\nabla_X f = - X^{-1}AX^{-1}$$ can we show that $f$ is convex via the use of the equivalent proposition of convexity $$\langle\nabla f(X)-\nabla f(Y),\ X-Y\rangle \ge 0$$ where $\langle \cdot, \cdot\rangle$ denotes the inner product of $S^{n}_{++}$ ? Or can it be proven that the function is convex in a simpler way?","['multivariable-calculus', 'matrix-calculus', 'convex-analysis']"
3345713,Proof check for condition on being measurable,"I was wondering if the following proof works to prove the following statement: Prove the following are equivalent for $E \subseteq \mathbb{R}$ , where $m$ denotes the Lebesgue outer measure. (i) $E$ is measurable (definition taken to be satisfying the Caratheodory criterion). (ii) $m(B) = m(B \cap E) + m(B \cap E^c)$ for all Borel sets $B$ . (iii) $m(U) = m(U \cap E) + m(U \cap E^c)$ for all open sets $U$ . Proof:
(i) $\Rightarrow$ (ii), (i) $\Rightarrow$ (iii), (ii) $\Rightarrow$ (iii) are all trivial. (iii) $\Rightarrow$ (ii) follows from the fact that the $\sigma$ -algebra generated by the open sets is equal to the Borel algebra. To see (iii) $\Rightarrow$ (i), cover $A$ by open intervals $I_k$ such that $m(A) + \epsilon \geq \sum_k I_k $ , then we have: $$
m(A) + \epsilon \geq m(\cup_k I_k) = m(\cup_k I_k \cap E) + m(\cup_k I_k \cap E^c)
$$ by our hypothesis, but then since $A \subseteq \cup_k I_k$ we have that $m(\cup_k I_k \cap E) \geq m(A \cap E)$ and likewise for $E^c$ by monotonicity, thus giving: $$
m(A) + \epsilon \geq m(A \cap E) + m(A \cap E^c)
$$ Letting $\epsilon \rightarrow 0$ thus gives the inequality and hence the result (reverse inequality trivially follows from countable sub-additivity). This completes the proof. I'm fairly new to measure theory so any feedback, corrections or help would be greatly appreciated!","['measure-theory', 'proof-verification', 'lebesgue-measure', 'real-analysis']"
3345716,Proof of Hahn Banach Theorem corollary: the dual of a LCS sperates points,"I am having troubles in understanding the proof of some corollaries to the Hahnn Banach Theorem, from Treves' ""Topological Vector Space, Distribution and Kernels"" Now summing up my doubts: In corollary 1, where is the hypothesis of local convexity exploited? Why $E/M_0$ Hausdorff automatically implies $f'$ continuous? In corollary 2 where is the hypothesys of Hausdorfness used ? The
only reason I can come up with, adapting the proof of Corollary 1, as
the author suggests, is that if $E$ is Hausdorff, then $$E/Cl\{0\}=E/\{0\}=E$$ , and hence the proof is simplified, we do not
have to mess with the projection $\phi$ . But why is it essential? Finally, Schechter in his Handbook of Analysis and its foundations,
claims the Corollary 2 is actually equivalent , and hence not
properly a corollary,  to the Hahn Banach theorem.  Any direct way to
see this ? For reference, I am using the following two versions of Hahn Banach (those of Treves). [(HB1): Geometric Hahn Banach Theorem ] Let E be a TVS, M a linear manifold in E and A a nonempty convex open subset of E such that $M\cap A=\emptyset$ . Then there exists an hyperplane containing M and not intersecting A. [(HB2): Analytical Hahn Banach Theorem] Let E be a vector space, p  a seminorm on E and M a subspace of E. If f is a linear form on M such that $|f(x)|\leq p(x)\ \forall x\in M$ then there exist a linear extension to E such that $|f_1(x)|\leq p(x)\ \forall x\in E$","['proof-explanation', 'topological-vector-spaces', 'functional-analysis', 'hahn-banach-theorem', 'duality-theorems']"
3345720,Understanding Hartshorne's definition of subvariety,"In Hartshorne's Algebraic Geometry, he defines subvarieties in exercise 3.10 of chapter I as follows: A subset of a topological space is locally closed if it is the intersection of an open set with a closed set. If $X$ is a quasi-affine variety and $Y$ is an irreducible locally closed subset, then $Y$ is also a quasi-affine variety. We call $Y$ a subvariety of $X$ . My questions are: How is $Y$ a quasi-affine variety? Given that $Y$ is an irreducible locally closed subset of a quasi-affine variety $X$ , I know that $X$ is an open subset of an affine variety $V \subseteq \textbf{A}^{n}$ , and $Y=A \cap B$ for some open $A \subseteq V$ and closed $B \subseteq V$ . But how does this imply that $Y$ is an open subset of an affine variety? Why does he define subvarieties in this way? It seems like an unnatural and needlessly complicated definition for a subobject. I think that a subvariety ought to be simply defined as a subset of a variety that is also a variety. Why doesn't Hartshorne do this?","['affine-varieties', 'algebraic-geometry']"
3345761,"Question on conjectured formulas for $B_n$, $\eta(s)$, and $\zeta(s)$","The $B(s)$ function defined below is the extension of the Bernoulli number function $B_n$ in the spirit of Analytic Continuation of Bernoulli Numbers ... except the definition here follows the convention $B_1=-1/2$ instead of $B_1=1/2$ which is advocated by the referenced paper. Note $B(n)=B_n$ when n is a positive integer. (1) $\quad B(s)=(-1)^{s-1}\,s\,\zeta(1-s)$ The following two figures illustrate the real and imaginary parts of the $B(s)$ function defined in formula (1) above. The red discrete portion of Figure (1) illustrates the evaluation of the real part of $B(s)$ defined in formula (1) where $s=n$ and n is a positive integer, and the red discrete portion of Figure (2) illustrates the evaluation of the imaginary part of $B(s)$ defined in formula (1) at integer values of $s$ . Note the imaginary part of $B(s)$ always seem to evaluate to zero at negative as well as positive integers. Also note $B(0)$ as defined in formula (1) above is indeterminate but seems to converge to $B_0=1$ in a limit sense. Figure (1): Illustration of real part of $B(s)$ Figure (2): Illustration of imaginary part of $B(s)$ The following conjectured formulas are refinements of formulas defined in my three previous questions on the Dirichlet eta function , Riemann zeta function , and Bernoulli number function . (2) $\quad \eta(s)=\underset{m\to\infty}{\text{lim}}\left(\frac{1}{2^m}\sum\limits_{n=1}^m\frac{(-1)^{n-1}}{n^s}\sum\limits_{i=0}^{m-n}\binom{m}{m-n-i}\right)$ (3) $\quad \zeta(s)=\underset{m\to\infty}{\text{lim}}\left(\frac{1}{2^m\left(1-2^{1-s}\right)}\sum\limits_{n=1}^m\frac{(-1)^{n-1}}{n^s}\sum\limits_{i=0}^{m-n}\binom{m}{m-n-i}\right)\,,\quad s\ne 1+\frac{2\,π\,i\,k}{\log(2)}$ (4) $\quad B(s)=\underset{m\to\infty}{\text{lim}}\left(\frac{(-1)^{s-1}\,s}{2^m\,\left(1-2^s\right)}\sum\limits_{n=1}^m (-1)^{n-1} n^{s-1}\sum\limits_{i=0}^{m-n}\binom{m}{m-n-i}\right)\,,\quad s\ne \frac{2\,π\,i\,k}{\log(2)}$ Formulas (2), (3), and (4) above are related and a proof of any one of these would imply the correctness of all three formulas. Formulas (2), (3), and (4) above for $\eta(s)$ , $\zeta(s)$ and $B(s)$ are illustrated following the questions below. With respect to formula (2) above, if one defines $a(m,n)=\frac{(-1)^{n-1}}{2^m}\sum\limits_{i=0}^{m-n} \binom{m}{m-n-i}$ then I believe $\underset{m\to\infty}{\text{lim}}\left(a(m,n)\right)=(-1)^{n-1}$ where smaller values of $n$ converge much faster than larger values of $n$ . This explains why $\eta(s)=\underset{m\to\infty}{\text{lim}}\left(\sum\limits_{n=1}^m\frac{a(m,n)}{n^s}\right)$ which is equivalent to formula (2) above evaluates much differently than $\eta(s)=\underset{m\to\infty}{\text{lim}}\left(\sum\limits_{n=1}^m\frac{(-1)^{n-1}}{n^s}\right)$ which only converges for $\Re(s)>0$ . I've reviewed formulas for $\eta(s)$ and $\zeta(s)$ on Wikipedia and Wolfram MathWorld and haven't found any formulas similar to formulas (2) and (3) above. I believe formulas (2) and (3) evaluate exactly correct when $s$ is a non-positive integer and $|s|\le m-1$ . Exact convergence at non-positive integer values at finite evaluation limits seems to be a characteristic of global (or nearly global) formulas for $\eta(s)$ and $\zeta(s)$ such as the following which seem to evaluate exactly correct when $s$ is a non-positive integer and $|s|\le K$ . (5) $\quad\eta(s)=\underset{K\to\infty}{\text{lim}}\left(\sum\limits_{n=0}^K\frac{1}{2^{n+1}}\sum\limits_{k=0}^n\frac{(-1)^k\,\binom{n}{k}}{(k+1)^s}\right)$ (6) $\quad\zeta(s)=\underset{K\to\infty}{\text{lim}}\left(\frac{1}{1-2^{1-s}}\sum\limits_{n=0}^K\frac{1}{2^{n+1}}\sum\limits_{k=0}^n\frac{(-1)^k \binom{n}{k}}{(k+1)^s}\right)\,,\quad s\ne 1+\frac{2\,π\,i\,k}{\log(2)}$ (7) $\quad\zeta(s)=\underset{K\to\infty}{\text{lim}}\left(\frac{1}{s-1}\sum\limits_{n=0}^K\frac{1}{n+2}\sum\limits_{k=0}^n\frac{(-1)^k \binom{n}{k}}{(k+1)^s}\right)$ I believe formula (4) above for $B(s)$ evaluates exactly correct when $s$ is a positive integer and $s\le m$ which leads to formula (8) below for $B_n$ . I've reviewed formulas for $B_n$ on Wikipedia and Wolfram MathWorld and the most similar formula I found is illustrated in formula (9) below where $\mathcal{S}_{n-1}^{(k)}$ is the Stirling number of the second kind . (8) $\quad B_n=\frac{(-1)^n\,n}{2^n\,\left(2^n-1\right)}\sum\limits_{k=1}^n (-1)^{k+1}\,k^{n-1}\sum\limits_{i=0}^{n-k}\binom{n}{n-k-i}\,,\quad n>0$ (9) $\quad B_n=\frac{n}{2^n\,\left(2^n-1\right)}\sum\limits_{k=0}^{n-1} (-1)^{k+1}\,k!\,2^{n-k-1}\,\mathcal{S}_{n-1}^{(k)}\,,\quad n>0$ My interest in the $B(s)$ function is motivated in part by the observation that formulas (8) and (9) above are somewhat similar, and it seems to me a proof of formula (8) above for $B_n$ (via a proof of the equivalence of these two formulas or some other means) might perhaps lead to a proof of formula (4) above for $B(s)$ which would also imply the correctness of formulas (2) and (3) above for $\eta(s)$ and $\zeta(s)$ . Formulas (8) and (9) above both evaluate correctly for $n=1$ , and I believe proving the simplified relationship illustrated in formula (10) below is equivalent to proving the correctness of formula (8) above but this is the extent of my progress to date. (10) $\quad\sum\limits_{k=1}^n (-1)^{k+1}\,k^{n-1}\sum\limits_{i=0}^{n-k} \binom{n}{n-k-i}=2^n\sum\limits_{k=0}^{n-1}\frac{(-1)^{k+1}}{2^{k+1}}\sum\limits_{i=0}^k (-1)^i\,\binom{k}{i}\,(k-i)^{n-1},\quad n\gt 1$ Question : Is formula (8) above for $B_n$ true, false, or an unprovable statement (an example of Gödel's incompleteness theorems)? Formula (2) for $\eta(s)$ above can be rewritten as illustrated in formula (11) below. I verified formula (11) below evaluates exactly the same as formula (5) for $\eta(s)$ above (which is known to be a globally convergent formula) for the first $100$ positive integer values of $K$ , so this is an encouraging result with respect to the conjectured global convergence of formulas (2) and (11). (11) $\quad \eta(s)=\underset{K\to\infty}{\text{lim}}\left(\frac{1}{2^{K+1}}\sum\limits_{n=0}^K\frac{(-1)^n}{(n+1)^s}\sum\limits_{k=0}^{K-n}\binom{K+1}{K-n-k}\right)$ The following two figures illustrate formulas (2) and (3) above for $\eta(s)$ and $\zeta(s)$ in orange overlaid on the corresponding reference functions in blue where formulas (2) and (3) are both evaluated at $m=100$ . Note both formulas seem to converge for $s\in\mathbb R$ . Figure (3): Illustration of formula (2) for $\eta(s)$ Figure (4): Illustration of formula (3) for $\zeta(s)$ The following two figures illustrate the real and imaginary parts of formula (4) above for $B(s)$ in orange overlaid on the corresponding reference function defined in formula (1) above in blue where formula (4) is evaluated at $m=100$ for both figures. The red discrete portion of the first figure below illustrates evaluation of the real part of formula (4) for $B(s)$ at positive integer values of $s$ , and the red discrete portion of the second figure below illustrates evaluation of the imaginary part of formula (4) for $B(s)$ at positive and negative integer values of $s$ . Note the real and imaginary parts of formula (4) both seem to converge for $s\in\mathbb R$ . Figure (5): Illustration of real part of formula (4) for $B(s)$ Figure (6): Illustration of imaginary part of formula (4) for $B(s)$ The following three figures illustrate the absolute value, real part, and imaginary part of formula (3) above for $\zeta(s)$ evaluated along the critical line $s=1/2+i\,t$ in orange overlaid on the reference function in blue. Formula (3) is evaluated at $m=100$ for all three figures. The red discrete portion of each of the three figures below illustrates the evaluation of formula (3) for $\zeta(s)$ at the first $10$ non-trivial zeta zeros in the upper-half plane. I won't illustrate it here, but I'll note that formulas (2) and (4) for $\eta(s)$ and $B(s)$ also seem to converge along the critical line $s=1/2+i\,t$ in a similar manner. Figure (7): Illustration of formula (3) for $|\zeta(1/2+i\,t)|$ Figure (8): Illustration of formula (3) for $\Re(\zeta(1/2+i\,t))$ Figure (9): Illustration of formula (3) for $\Im(\zeta(1/2+i\,t))$","['number-theory', 'incompleteness', 'binomial-coefficients', 'bernoulli-numbers', 'riemann-zeta']"
3345764,Modeling with differential equations,"I am struggling a bit to convert a word/modeling problem into a differential equation to then solve. The question is:
Assume a town has a population of 100,000 citizens, within a week 10,000 people are  mysteriously ill. Assume that the rate of increase
of the number who are ill is proportional to the number of people who have not yet fallen ill. How long will it be until half the town have fallen ill? I think it should end up being something like ds/dt=r(s-100000) where s is the number of people that have fallen sick and r is some rate for it to be proportional to.",['ordinary-differential-equations']
3345765,On the ring structure of $K_0$ of the punctured spectrum of a regular local ring,"Let $(R, \mathcal m, k)$ be a regular local ring of dimension at least $3$ . Let $K_0(X)$ be the Grothendieck group of algebraic vector bundles over the punctured spectrum $X =Spec R \setminus \{\mathfrak m \}$ . Now $K_0(X)$ also has a commutative ring structure induced from the tensor product of vector bundles. My question is : Is $K_0(X)$ an integral domain as a ring ?","['algebraic-k-theory', 'algebraic-vector-bundles', 'homological-algebra', 'algebraic-geometry', 'commutative-algebra']"
3345766,Is $M_0(\mathbb F)$ a valid construct?,"Or, is there a $\text{dim}\ 0$ matrix ring? I assume you can define $M_0(\mathbb F) := \{[]\}$ and $\mathbf I_0 := []$ , but I couldn't find any confirmation on this.","['matrices', 'linear-algebra']"
3345769,$\prod_{k=1}^{n} \Big( k^2 + k \Big)$,Consider this product: $$\beta_{n} = \prod_{k=1}^{n} \Big( k^2 + k \Big)$$ I have tried applying associativity rule: $$\beta_{n} = \prod_{k=1}^{n} \Big(k^2 + k\Big) = \prod_{k=1}^{n}k^2 + \prod_{k=1}^{n}k = (n!)^2 + n! = n! (n! + 1)$$ For $n = 4$ this produces output $600$ . But it should be $2880$ . WolframAlpha gives this as a result: $\beta_{n} = (n!)^2(n+1)$ Hence I assume that associativity rule does not work like it would work with sums. So how do I go about computing this quite simple product?,"['summation', 'discrete-mathematics', 'products']"
3345771,Find $k^{th}$ power of a square matrix,"I am trying to find the $A^{k}$ , for all $k \geq 2$ of a matrix, \begin{pmatrix}  a & b \\ 0 & 1  \end{pmatrix} My approach: $A^{2}=\begin{pmatrix}  a^2 & ab+b \\ 0 & 1 \end{pmatrix}$ $A^{3}=\begin{pmatrix}  a^3 & a^{2}b+ab+b \\ 0 & 1 \end{pmatrix}$ $A^{4}=\begin{pmatrix}  a^4 & a^{3}b+a^{2}b+ab+b \\ 0 & 1 \end{pmatrix}$ $A^{5}=\begin{pmatrix}  a^5 & a^{4}b+a^{3}b+a^{2}b+ab+b  \\ 0 & 1 \end{pmatrix}$ Continuing this way, we obtain $A^{k}=\begin{pmatrix}  a^k & (a^{k-2}+a^{k-3}+a^{k-4}+.....+1)b  \\ 0 & 1 \end{pmatrix}$ I am stuck here! I was wondering if you could give me some hints to move further. I appreciate your time.","['matrices', 'diagonalization', 'linear-algebra']"
3345790,Generalizing the Runge approximation theorem for Riemann Surfaces: approximating by nonvanishing functions,"The Runge approximation theorem for open Riemann Surfaces says the following. If $X$ is an open Riemann surface and $Y \subset X$ is a Runge subset, i.e., $X \setminus Y$ has no relatively compact connected components, then any holomorphic function on $f:Y \to \mathbb{C}$ can be approximated, uniformly on compact subsets of $Y$ , by holomorphic functions on $X$ . My question is the following. Say $f$ on $Y$ is nonvanishing, i.e., $f:Y \to \mathbb{C}\setminus \{0\}$ . Can $f$ be approximated, uniformly on compact subsets of $Y$ , by nonvanishing holomorphic functions $X \to \mathbb{C}\setminus \{0\}$ ? Obviously this problem is easy if I could lift the function $f$ with respect to the exponential map, but in general we can't do that. We can obviously locally lift, i.e. lift $f$ on neighbourhoods of every point of $Y$ , but I'm not sure how that could be useful. Does anyone have any ideas? Edit: to avoid topological obstructions, we may assume that $f$ can be extended to a continuous nonvanishing function on $X$ .","['riemann-surfaces', 'approximation-theory', 'complex-geometry', 'complex-analysis', 'algebraic-topology']"
3345821,How many 10 digit numbers begin with (652)- and contain no zeroes?,"I'm slightly confused, but I answered it as $9^7$ . My reasoning is that the area code isn't relevant to how many numbers are possible, which leaves it as $7$ digits with $9$ possibilities each (since $0$ can't be used) So the answer should be $9\times9\times9\times9\times9\times9\times9$ (one $9$ for each digit that needs a number between $1$ - $9$ ) or $9^7$ , right?","['combinatorics', 'discrete-mathematics']"
3345826,Necessary/Sufficiency Conditions for Measurable Mapping,"I'm interested in seeing if it is possible to have a numerical (implementable on a finite precision computer) method to determine if a given function is measurable or not. It would be great if some one could direct me towards some references to this end if it's a very well studied thing; I'm just finding it a little hard to search. An example application : Say I have a complicated procedure that can be expressed as a mapping $f$ , between two measurable spaces $(\Omega, F)$ and $(\Lambda,G)$ , given that the measure in the first space is a probability measure ( $\mu(\Omega)=1$ ). I am interested in assigning a probability for each subset $\lambda\in G$ based on it's pre-image in $f^{-1}(\lambda)\in F$ . If $f$ is measurable, I can do this simply as \begin{equation}
p(\lambda) = \mu(f^{-1}(\lambda)).
\end{equation} Key here is that it may not be possible to express the procedure as an analytic function and the best I can do is write a numerical code for it that generates $f(x), \frac{d}{dx}f(x), \dots $ for any given $x\in \Omega$ . Also, $\Omega$ could be high-dimensional, potentially, so graphical approaches might not be feasible in the general sense. Having quick conditions to check for the measurability of $f$ could greatly aid in understanding the appropriateness of the above formula. Edit: I'm editing this in response to the holds. I have removed the word ""numerical"" from the title, indicating that I'm looking for some practically useful result that I can use to determine if a given mapping is measurable or not. I understand that numerical implementation could be a separate question by itself. So all the question now seeks is some useful result that could be in the form of necessary or sufficient conditions for measurability of a function . I'm leaving the bode of the question intact to retain the context of this edit.","['statistics', 'probability-theory', 'measure-theory']"
3345845,Finite etale and choice of topology,"Let $X =$ Spec $(R)$ be an affine scheme and $f:Y \rightarrow X$ be an affine scheme over $X$ . Let us denote the category of affine schemes over $X$ as Aff $_X$ . In Lenstra's notes Galois Theory for Schemes (p.71 Lemma 5.10, see below) he shows that in order for $Y$ to be finite etale over $X$ it is necessary and sufficient that there exists an affine scheme $g:W\rightarrow X$ in Aff $_X$ which is surjective, flat, and finite and the pull-back $Y\times_{X}W \cong \coprod_{N}W$ for some finite set $N$ . Put another way, this theorem states (with a little more work) that $Y$ is finite etale over $X$ if and only if it is locally totally split in the fppf topology. That is, there exists an fppf coverage of $X$ such that $Y$ is totally split when pulled-back over this cover. So we could define finite etale by saying: $Y\rightarrow X$ is finite etale if there exists an fppf cover of $X$ over which $Y$ is totally split. This is nice because it feels similar to the definition of a covering space from topology. But there are (at least) two other natural choices of topology that we could put on Aff $_X$ . Namely, the flat topology and the fpqc topology. Question: Do each of these topologies give equivalent definitions of finite etale? i.e. is it true that: $Y$ is flat locally totally split iff $Y$ is fpqc locally totally split iff $Y$ is fppf locally totally split? Due to the relative ""fineness"" of these topologies we know that fppf locally totally split implies fpqc locally totally split implies flat locally totally split. I can prove that all three coincide if $R$ is a field. I can almost show fppf locally totally split is the same as fpqc locally totally split for an arbitrary ring; I get stuck at one step. Any references or comments would be great! Thanks http://websites.math.leidenuniv.nl/algebra/","['algebraic-geometry', 'grothendieck-topologies']"
3345862,Beginner abstract question. Why does a group operation of an element on itself return 1 or e?,"I have some gaps in my understanding. This is my first abstract algebra course as an undergrad and the professor is truly all over the place. We are using Fraleigh's book and in the first week have covered pieces of the first 150 pages. Week 2 topics are Lagrange, cyclic, roots of unity, normal subgroups. A total mishmash as far as I’m concerned. Ok, so my super basic question. Why does $x\ast x$ or $x^2=1?$ I understand $xx^{-1}$ would equal $e=1$ . The application. Prove that a group in which every element different from the identity element has order 2 is Abelian. The proof makes sense. The notion that $x\ast x=1$ does not.","['group-theory', 'abstract-algebra']"
3345893,Confidence Intervals - Doubts on Interpretations,"Suppose we use a sample mean $\bar{X}$ to construct a $95\%$ confidence interval $[a, b]$ . I was told that it is incorrect to say that there is a $95\%$ probability that the population mean lies between $a$ and $b$ . Because the population mean is a constant and not a random variable. The probability that a constant falls within any given range is either $0$ or $1$ . However, from the textbook it is said that we expect $95\%$ of the confidence intervals to include the population mean . If $95\%$ of the confidence intervals are expected to include the population mean, then each confidence interval has $95\%$ probability to include the population mean. Therefore I think it is correct to say there is a $95\%$ probability that the population mean lies between $a$ and $b$ . Where did I make mistakes?","['statistics', 'confidence-interval', 'probability']"
3345896,Proof that a subset of a finite set is finite,"Can someone please tell me if this proof is rigorous? I have a hunch it's circular, and I am suspicious at how short it is. However, I'm also having trouble convincing myself that it's incorrect. Suppose $B$ is a finite set and let $A \subseteq B$ .
There exists $k \in \mathbb{N}$ such that $\{1, 2, \dotsc, k\} \sim B$ .
Set $k' = |B \setminus A|.$ Then $A$ is isomorphic to $\{1, 2, \dotsc, k - k'\}$ , so it is finite.
Finite sets are countable, so $A$ is countable. Thank you!","['elementary-set-theory', 'proof-verification']"
3345918,No. of finite group (nonidentity)elements $x$ satisfying $x^5=e$ is a multiple of $4$,"In a finite group $G$ with $e:=\text{id}_G$ , show that the number of nonidentity elements that satisfy the equation $x^5=e$ is a multiple of 4. This is number $50$ , Ch. $2$ from Gallian's text. I have seen two repeats of this question on MSE ( Show that number of solutions satisfying $x^5=e$ is a multiple of 4? , In a finite group, show that the number of nonidentity elements that satisfy the equation $x^5=e$ is a multiple of 4. ) but I still have questions about the question and my proof. My first question: Do we have to assume that $x^5=e$ for some $x\in G$ in the first place? My thinking is that this is a yes since in general a finite group may not have such an $x$ . Proof of claim : Suppose some $x\in G$ , $\space$$x\neq e$ satisfies the condition $x^5=e$ . Then note that $x^2\in G$ and $$(x^2)^5=(x^5)^2=e^2=e$$ so $x^2$ satisfies the condition. Similarly $x^3\in G$ and $x^4\in G$ . Observe that $$(x^3)^5=(x^5)^3=e^3=e$$ $$(x^4)^5=(x^5)^4=e^4=e$$ so that $x^3$ and $x^4$ also satisfy the condition. Once we verify that $x,x^2,x^3,x^4$ are distinct and that $x^i\neq e$ for $1\leq i \leq 4$ we will have proved the claim since for every $x$ that is a solution, so is $x^2$ , $x^3$ , and $x^4$ . Thus solutions come in multiples of $4$ . Note that we don't consider elements like $x^6$ or $x^7$ as solutions because $x^6=x$ and $x^7=x^2$ i.e. for $n>5$ , $x^n=x^i$ where $i\in\{1,2,3,4,5\}$ . So, considering powers of elements modulo $5$ is enough. To show each $x^i$ is distinct, we assume the contrary. That is, assume $$x^i=x^j$$ for some distinct $i,j\in\{1,2,3,4\}$ . Thus if we take $i$ to always be the greater of the two, $$x^i=x^j\iff x^{i-j}=e$$ so $$i-j=1,2\text{ or } 3$$ Note it is impossible $i-j=1$ by the assumption that $x\neq e$ . If $i-j=2$ or $i-j=3$ , then $$x^2=e\text{ and } x^3=e\implies x^3=x^2\cdot x=e\cdot x=x = e$$ but the latter shows $x=e$ if $x^3=e$ and $x^2=e$ ; this is a contradiciton. Thus it must be false that $x^i=x^j$ for some distinct $i,j\in\{1,2,3,4,5\}$ . In proving the above, we saw that the $x^2=e=x^3$ leads to a contradiction, so to show the last claim, namely that $x^i\neq e$ , we show that $x^4\neq e$ . Again assume that indeed $x^4=e$ . Then $$x^4=e=x^5\iff e=x\therefore\text{ contradiction }$$ $\blacksquare$ My second question: Is the above proof correct? By removing the condition that the group be finite, how could this change the conclusion about the number of solutions? I never really utilized that $G$ was finite above (maybe tacitly? I don't know) so I'm pretty stumped on this one.","['abstract-algebra', 'proof-verification']"
3345922,How to solve given differential equation $(x^3y^3+x^2y^2+xy+1)ydx+(x^3y^3-x^2y^2-xy+1)xdy=0$?,The equation to solve is: $$(x^3y^3+x^2y^2+xy+1)ydx+(x^3y^3-x^2y^2-xy+1)xdy=0$$ I tried putting $xy=t$ but that just gave me this: $$\frac{t^3-t^2-t+1}{t^3+t^2+t+1}dt=\frac{dx}{x}$$ I suppose there must be some clever factoring involved somewhere but I can't see it so can someone guide me on how to advance or perhaps suggest an alternate method?,['ordinary-differential-equations']
3345955,Boolean algebras and measures without complements,"A (concrete) Boolean algebra $\mathcal{B}$ on a set $X$ is any nonempty set of subsets of $X$ that is closed under union, intersection, and complements  relative to $X$ . With some redundancy, this implies that it is characterized by the following axioms: $\varnothing, X \in \mathcal{B}$ . (Union) If $E, F \in \mathcal{B}$ , then $E \cup F \in \mathcal{B}$ . (Intersection) If $E, F \in \mathcal{B}$ , then $E \cap F \in \mathcal{B}$ . (Complement) If $E \in \mathcal{B}$ , then $X \setminus E \in \mathcal{B}$ . Is there a standard name for the more general structure in which axiom 4 is dropped? For example, let $X = \mathbb{N}$ , and let $\mathcal{B}$ contain precisely $X$ and its finite subsets. This satisfies 1-3 but not 4. In addition, a vector measure $\mu$ on a Boolean algebra $\mathcal{B}$ is a map $\mu \colon \mathcal{B} \to V$ , where $V$ is a vector space, such (i) $\mu(\varnothing)=0$ ; and (ii) whenever $E$ and $F$ are disjoint, $\mu(E \cup F) = \mu(E)+\mu(F)$ . This definition makes sense if $\mathcal{B}$ is only required to satisfy axioms 1-3, but it seems to be misleading to call such a mapping on the more general structure a `measure'. So is there a standard name for ""measures"" that are not required to be defined on Boolean algebras? If there aren't standard names, are there any names that would sound natural and reasonable to mathematicians? EDIT: The first question has been answered, but the second (about measures) remains open.","['boolean-algebra', 'measure-theory', 'terminology']"
3345979,How many numbers are between $1$ and $9999$ in this case?,"How many natural numbers between $1$ and $9999$ have the sum of the digits: $a)$ equal to $9$ . $b)$ equal to $16$ My atempt:
 So for $a)$ , I did $\dbinom {9+4-1} {4-1} = 220$ For $b)$ , I calculated the total solution just like in the first case and I got $969$ .
Now, since the digits are between $0$ and $9$ , I have to take away the number of solutions between $10-16$ . Let's say that $x_1, x_2, x_3, x_4$ are the digits.
So if one of them is $10$ then the sum of the remaining three is 6 and the number of solutions is: $\dbinom {4} {1} \cdot \dbinom {6+3-1} {3}$ . 
I did the exact same thing for the cases where one of them is $11, 12, 13, 14, 15$ or $16$ . I add them and got $336$ .
The final solution for me is: $969-336=633$ . Is it correct?","['combinations', 'combinatorics', 'discrete-mathematics']"
3345984,"For the function $f(x,y,z)= xyz$ how close to the point $(0,0,0)$ should one take the point $(x,y,z)$ in order to make $|f(x,y,z)-f(0,0,0)|<0.008$?","For the function $$f(x,y,z)= xyz$$ how close to the point $(0,0,0)$ should one take the point $(x,y,z)$ in order to make $|f(x,y,z)-f(0,0,0)|<0.008$ ? here is my solution: after substitution in the absolute value inequality we get $|xyz|<0.008$ $\Rightarrow$ $\sqrt {x^{2}y^{2}z^{2}}<0.008$ but for $x,y,z <1$ $\sqrt {x^{2}y^{2}z^{2}} < \sqrt{x^{2}+y^{2}+z^{2}}$ And If we choosed the distance to be less than $\delta = 0.008$ the condition will hold. the solution of the book is $\delta = 0.2\sqrt{3}$ my questions are : Is my solution correct? how to obtain the solution of the book?","['limits', 'multivariable-calculus']"
3346074,Proof of Zariski's Lemma to Nullstellensatz (Fulton),"This proof of Zariski's Lemma is from Fulton's Algebraic Curves. Proposition. If a field L is ring-finite over a subfield K, then L is module-finite (and hence algebraic) over $K$ . Proof. Suppose $L = K[v_1,...,v_n]$ . The case n = 1 is taken care of by the above discussion, so we assume the result for all extensions generated by n − 1 elements. Let $K_1 = K(v_1)$ . By induction, $L = K_1[v_2,...,v_n]$ is module-finite over $K_1$ . We may assume $v_1$ is not algebraic over K (otherwise Problem 1.45(a) finishes the proof).
Each $v_i$ satisfies an equation $v_i^{n_i} +a_{i1}v_i^{n_i−1}+···=0,a_{ij} ∈K_1$ . If we take $a∈K[v_1]$ that is a multiple of all the denominators of the $a_{ij}$ , we get equations $(av_i)^{n_i} +aa_{i1}(av_i)^{n_i−1}+···=0$ . It follows from the Corollary in §1.9 that for any $z ∈ L = K[v_1,...,v_n]$ , there is an $N$ such that $a^Nz$ is integral over $K[v_1]$ . In particular this must hold for $z ∈ K (v_1)$ . But since $K (v_1)$ is isomorphic to the field of rational functions in one variable over $K$ , this is impossible (Problem 1.49(b)). The corollary refers to this statement: Let S be a domain. The set of elements of $S$ that are integral over $R$ is a subring of $S$ containing $R$ . I have two questions: How does ""for any $z ∈ L = K[v_1,...,v_n]$ , there is an $N$ such that $a^Nz$ is integral over $K[v_1]$ ."" follow from the Corollary? Why is $z ∈ K (v_1)$ a particular case for this statement? It does not appear to me that $K (v_1)$ is a subset of $K[v_1,...,v_n]$","['algebraic-geometry', 'abstract-algebra', 'commutative-algebra']"
3346153,Covariance matrix of a stationary random process,"Cxx is the covariance matrix of a stationary random process X[k]. Assume we create X0 by subtracting the nonzero mean mx from X, consisting of samples of X[k]. Then, the covariance matrix for X0 is different from Cxx? What if X[k] is wide-sense-stationary or not stationary?","['statistics', 'stationary-processes', 'covariance']"
3346224,If $f$ is a bijection of ${\mathbb N}$ then there exist infinitely many triples $a<b<c$ with $f(b)={f(a)+f(c)\over2}$.,"Let $f$ be a bijection from the set of nonnegative integers to itself. Show that there exist infinitely many triples of nonnegative integers $(a,b,c)$ with $f(a) + f(c) = 2f(b)$ and $a < b < c$ . Hello everybody. I hope you are all doing well. The question you see above is a question I could not solve. :( Any help would be appreciated. Here's what I though of: A.P. stands for Arithmetic Progression We just want to show that there exist infinitely many integers such that $f(a), f(b), f(c)$ are in A.P. $a < b< c$ . Since $f$ is a bijection, it makes our work easier. Suppose otherwise. There exist no $a, b, c$ with the conditions required. That is, there exists no $f(a), f(b), f(c), a < b < c$ such that they are in A.P. Hence, $f(0), f(1), f(k)$ where is $k$ is a non-negative integer, can never be in A.P. Let $f(0) = l$ and $f(1) = m$ . Also let $d = m - l$ . Note that since $f$ is a bijection, $f(k) \neq l, m$ and $l \neq m$ . Also assume $f(k) = p \neq m \neq l$ $$f(0) = l$$ $$f(1) = m$$ We consider $f(1) > f(0)$ .
OK now since $f(0), f(1), f(k)$ can not be in AP, we have $p - m \neq m-l$ . That is there exists no $k$ in non negative integers when $m, l, p$ are in AP, which is absurd iterating $k$ from $2$ . Let me give you an example to make it clearer. Let $f(0) = 5$ and $f(1) = 20$ . The difference is $15$ . Clearly, $35$ would satisfy our conditions. Since $f$ is bijection, there should be some number $k$ such that $f(k) = 35$ . That is $f(0), f(1), f(k)$ are in AP. Of course $k$ is greater that $0, 1$ because it is not $0,1$ and an integer. It only works for $f(1) > f(0)$ but I thought that the whole set of nonnegative integers must have a pairing, not just $0$ and $1$ . In addition, while something like $f(0) = 10$ and $f(1) = 5$ might not work, there are is an infinite number of other pairs that will work. Please help. I would be glad to have my ""solution"" being corrected. Please also inform if this question is a duplicate as it seems as a very common question but I could not find this anywhere on the internet. Thank You. EDIT: As pointed out by Martin R (thank you), this has an answer for one such triplet. It is here: Solve this problem on functions","['algebra-precalculus', 'functions', 'arithmetic-progressions']"
3346226,How to prove that $\sqrt[3]{BC^2}=\sqrt[3]{BD^2}+\sqrt[3]{CE^2}$.,"So we have ABC is a right triangle at A, AH be the altitude,  HD, HE are respectively the height of the triangle AHB and AHC.  Prove that $\sqrt[3]{BC^2}=\sqrt[3]{BD^2}+\sqrt[3]{CE^2}$ . I try using Pythagorean theorem but I only end up at $BC^2=3(AH^2)+BD^2+CE^2$ and I don't know where to go next or maybe I choose wrong path
I also try to use what we're proving and simplify it too but no luck. 
It looks kinda easy but I've just started studying Geometry ( it's still difficult for me )so I hope everyone here could help me, Thanks",['geometry']
3346259,Is Sophomore's Dream Transcendental?,"Sophomore's dream is the pair of identities $$
\int_0^1 x^{-x}\,dx=\sum_{n=1}^\infty n^{-n}\\[20pt]
\int_0^1x^x\,dx=\sum_{n=1}^\infty (-1)^{n+1}n^{-n}
$$ Are these numbers transcendental?","['integration', 'definite-integrals', 'transcendental-numbers']"
3346286,Why is Chi square test with 1 dof infinite in 0,"In order to better understand the link between hypothesis testing and likelihood, I was recently trying to compare value of binomial probability and Chi square pearson test in the coin toss (or equivalently random bit generator). If we run 100 coin toss experiments, the probability of finding 50 tails and 50 head is around 8%, given binomial model.
Indeed, the likelihood of the binomial model with p=0.5 (my null hypothesis) given the 50/50 outcome is 0.08, which in itself does not means much, but comparing with other models (p=0.1, p=0.2) one can see that this is actually a pretty good likelihood. The problem I have is when I try to analyse the result with chi square pearson test. My null hypothesis is the binomial model with p=0.5. First I don't understand why I can use the Chi square model, what makes it valid in this case, as it is supposed to be used for normally distributed data (what is supposed to be normally distributed here ?) Also, and this is a much bigger issue to me, when computing chi square value with one dof in this case (sist.chi2.pdf(Q,1)), I obtain inf value in the case where the result is 50/50, ie a Q of 0. Why am I seeing this result ? am I right saying that Chi2 test is completely meaningless in the case of 1 dof ? thank you in advance for your help.","['binomial-distribution', 'statistics', 'normal-distribution', 'hypothesis-testing']"
3346300,Limit of function $f(x) = \sqrt{(xa + d)^2 + x^2 b^2} - \sqrt{(xa - d)^2 + x^2 b^2}$,"I tried to calculate limit when $x$ goes to infinity for the following function $$f(x) = \sqrt{(xa + d)^2 + x^2 b^2} - \sqrt{(xa - d)^2 + x^2 b^2}$$ where $a$ , $b$ , $d$ are some positive constants. It's easy to see that terms before and after minus sign goes to infinity so that gives me indeterminate symbol. Is there some way to solve this problem?","['limits', 'calculus', 'real-analysis']"
3346302,Find an example about splitting field,"Let $f(x)$ be an irreducible polynomial in $\mathbb{Q}[x]$ , and let $K$ be the splitting field of $f(x)$ over $\mathbb{Q}$ . Now, suppose that $E$ is a splitting field of some polynomial in $\mathbb{Q}[x]$ with $\mathbb{Q}\subseteq E\subseteq K$ , and that $\alpha_{1},\alpha_{2},\ldots,\alpha_{n}$ are roots of $f(x)$ in $K$ . In this situation, prove or disprove : $$\deg(\alpha_{1},E)=\cdots=\deg(\alpha_{n},E)$$ I think that the splitting field $K=\mathbb{Q}(\sqrt[8]{2},i)$ of $f(x)=x^{8}-2\in\mathbb{Q}[x]$ over $\mathbb{Q}$ is a counterexample for this question when $E=\mathbb{Q}(\sqrt{2})$ . Am i correct? or is there an example rather than this? If it is, under what conditions, the relation $\deg(\alpha_{1},E)=\cdots=\deg(\alpha_{n},E)$ could be true. Give some comment or advice. Thank you!","['field-theory', 'galois-theory', 'abstract-algebra', 'splitting-field', 'extension-field']"
3346313,Prove that $C_0(X)$ is separable given that X is locally compact metric space,"I'm struggling to prove the following fact: Suppose that $X$ is locally compact metric space. Let us denote with $C_0(X)$ the space of functions vanishing at infinity (i.e., $\forall f \in C_0(X)$ $\forall \varepsilon > 0$ $\exists  \, E\subset X$ s.t. $E$ is compact and $|f(x)|<\varepsilon$ for $x \in X\setminus E$ ). Then $C_0(X)$ is separable. I've proven that $C_0(X)$ equipped with a supremum norm is a Banach space, and that $C_c(X)$ (functions with compact support) are dense in $C_0(X)$ , so my guess would be to somehow use those facts to prove that $C_0(X)$ is separable. However, I can't exactly see how. I've seen the cases for compact spaces or using the assumption of $\sigma$ -compactness. Any help is highly appreciated.","['function-spaces', 'banach-spaces', 'functional-analysis', 'separable-spaces']"
3346326,Show convergence in probability of the reciprocal,"I have the following problem- If $Y_n$ converges in probability to $Y$ then show that $\frac{1}{Y_n}$ converges in probability to $\frac{1}{Y}$ . Also $P(Y_n=0) = 0$ for all $n$ and $P(Y = 0) = 0$ My attempt - Since $Y_n$ converges in probability to $Y$ then we know that $Y_n$ is bounded in probability
and $Y$ is also bounded in probability , so I can get $M$ s.t. $$P(|Y_nY| > M) < \eta$$ then $P(|\frac{1}{Y_n} - \frac{1}{Y}| > \epsilon) = P(\frac{|Y_n-Y|}{|Y_nY|} > \epsilon) \leq  P(\frac{|Y_n-Y|}{|Y_nY|}>\epsilon,|Y_nY| > M) +P(\frac{|Y_n-Y|}{|Y_nY|}>\epsilon,|Y_nY| \leq M) \leq P(|Y_nY| > M) + P(\frac{|Y_n-Y|}{|Y_nY|}>\epsilon,|Y_nY| \leq M)  $ I don't know how to go ahead from here,  basically the problem is the second term in the last expression,  if I can somehow manipulate that to use the convergence of $Y_n$ I'd be done.
So can someone please provide me with the solution to this problem Edit: I have made the correction and now it says bounded in probability not just bounded.","['statistics', 'convergence-divergence', 'probability-theory']"
3346342,"How to prove geometrically that $\langle a-b,b-c\rangle=\frac{1}{2} (|a-c|^2-|a-b|^2-|c-b|^2)$","It is straighforward to prove algebraically that if $a,b,c$ are points in the Euclidean plane, then $$\langle a-b,b-c\rangle=\frac{1}{2} (|a-c|^2-|a-b|^2-|c-b|^2).$$ However, actually this formula seems to have a very geometric flavour, i.e. a formula involving the area of the rectangle whose sides are $bc$ and the projection of the segment $ab$ onto $bc$ and the areas of the squares constructed on the sides $ab$ , $bc$ and $ac$ respectively. Does anyone see an elementary geometric proof of that formula?","['euclidean-geometry', 'geometry']"
3346349,Modular Elliptic Curves and Eta Products,"The elliptic curve $E:y^2+y=x^3-x^2$ of conductor $11$ is interesting as the associated modular form (this is over $\bf Q$ ) is $$
F=q\prod_{n>0}(1-q^n)^2(1-q^{11n})^2
$$ Clearly this exhibits a very nice $\eta$ -product. Is anyone aware of other elliptic curves over $\bf Q$ which have a simple minimal equation and whose associated modular form is a nice $\eta$ -product or even a nice $\eta$ -quotient?","['number-theory', 'modular-forms']"
3346371,Example of a function which is not differentiable on parts of its domain,"Can you provide me with an example of a function $f:\mathbb{R} \to \mathbb{R}$ which is not piece-wise defined and differentiable on some parts of its domain and some parts not? I am curious to know whether it is possible to say soemthing like this: ""function f is differentiable until point x=5 but for values x>5  it is no longer differentiable"". (I know that you can achieve this with functions like $f(x)= x^{q \over p}, p,q \in \mathbb{N}$ at point $0$ but that is not what I am looking for.) Any ideas are welcome!","['calculus', 'functions', 'derivatives', 'real-analysis']"
3346379,If $p(x)$ is a polynomial then $\lim_{k \to \infty}\frac{p(k+1)}{p(k)}=1$,"Let $p(x)$ be a polynomial of degree $n$ , i.e $p(x)=a_nx^n+a_{n-1}x^{n-1}+...a_0, a_n\neq0$ For every $\varepsilon >0$ , we have to find a stage such that after that stage it should be like $${\left|\frac{p(k+1)}{p(k)}-1\right|<\varepsilon},$$ i.e. $${\left|\frac{p(k+1)-p(k)}{p(k)}\right|=\frac{|a_n((k+1)^n-k^n))+...a_2((k+1)^2-k^2)+a_1|}{|a_nk^n+a_{n-1}k^{n-1}+...a_0|}}$$ I dont know how to proceed further","['sequences-and-series', 'real-analysis']"
3346395,Examples of simple non-parallelizable smooth manifolds,"I'm looking for examples of simple non-parallelizable smooth manifolds and honestly just general insight into the concept of a manifold being parallelizable. $S^2$ would be parallelizable, right? At each point on $S^2$ , you can have two vectors meet orthogonally that are tangent to $S^2$ , and would thus span the tangent space at that point. It seems to me that if you have an $n$ dimensional smooth manifold, that if you can find $n$ linearly independent vector fields, (so that at each point on the manifold, $V_1(x),....,V_n(x)$ are linearly independent)$, Then your manifold would be parallelizable. General insight and comments greatly appreciated!","['smooth-manifolds', 'manifolds', 'differential-topology', 'soft-question', 'differential-geometry']"
3346437,"Let A,B,C be sets. If A△B=A△C, does this imply that B=C?","I believe that a counterexample exists, but I have struggled to find one since I need to satisfy (A\B) U (B\A) = (A\C) U (C\A), which is a very complex statement. Also I used △ to represent symmetric difference.","['elementary-set-theory', 'discrete-mathematics']"
3346439,Question about the proof of the Picard–Lindelöf theorem,"I am currently trying to understand the proof of the following theorem, concerning the existence and uniqueness of local solutions to an initial value problem (IVP): Let $\Omega$ be an open subset of $\mathbb{R}\times\mathbb{R}^{n}$ , $(t_{0},x_{0})\in\Omega$ a point and $f\colon\Omega\to\mathbb{R}^{n}$ a continuous function that is Locally Lipschitz-continuous in its second variable. Then there exists a $\delta>0$ and a unique $C^{1}$ -function $\hat{u}\colon[t_{0}-\delta,t_{0}+\delta]\to\mathbb{R}^{n}$ that satisfies $$(t,\hat{u}(t))\in\Omega,\quad\hat{u}'(t)=f(t,\hat{u}(t)),\quad \hat{u}(t_{0})=x_{0}$$ for all $t\in[t_{0}-\delta,t_{0}+\delta]$ . Below is a sketch of the proof, where we use the Banach fixed-point theorem : Since $f$ is locally Lipschitz-continuous in the second variable, we are able to find an open neighbourhood $V$ around $(t_{0},x_{0})$ in $\Omega$ and a constant $L\geq0$ such that $$\|f(t,x)-f(t,y)\|\leq L\cdot\|x-y\|$$ for all $x,y\in V$ . Now choose a bounded open neighbourhood $U$ of $(t_{0},x_{0})$ in $V$ such that $\overline{U}\subset V$ . The boundedness of $U$ ensures that $\overline{U}$ is compact. Hence, since $f$ is continuous, the map $$\overline{U}\to\mathbb{R},\quad(t,x)\mapsto\|f(t,x)\|$$ attains a maximum $m\geq0$ . Now choose $\delta>0$ and $\varepsilon>0$ such that $$[t_{0}-\delta,t_{0}+\delta]\times\overline{B_{\varepsilon}(x_{0})}\subset\overline{U},\quad m\cdot\delta\leq\varepsilon,\quad L\cdot\delta<1.$$ The space $C^{0}([t_{0}-\delta,t_{0}+\delta],\mathbb{R}^{n})$ with the metric $$d_{\max}(u,v):=\max_{|t-t_{0}|\leq\delta}\|u(t)-v(t)\|$$ is a complete metric space. Now define $$X:=\{u\in C^{0}([t_{0}-\delta,t_{0}+\delta],\mathbb{R}^{n}) \ | \ d_{\max}(u,x_{0})\leq\varepsilon\},$$ where $x_{0}$ denotes the constant function $x\mapsto x_{0}$ . Then $X$ is a closed ball in the metric space $(C^{0}([t_{0}-\delta,t_{0}+\delta],\mathbb{R}^{n}),d_{\max})$ . Since $X$ is closed, it is also a complete metric space (with the resticted metric). Now define a map $$\Phi\colon X\to X,\quad\Phi(u)(t):=x_{0}+\int_{t_{0}}^{t}f(\tau,u(\tau)) \ d\tau.$$ One can verify that the condition $m\cdot\delta\leq\varepsilon$ ensures that $\Phi(X)\subset X$ . One can also show that $$d_{\max}(\Phi(u),\Phi(v))\leq L\cdot\delta\cdot d_{\max}(u,v)$$ So the condition $L\cdot\delta<1$ shows that $\Phi$ is a contraction. Hence, by the Banach fixed-point theorem, there exists a unique $\hat{u}\in X$ such that $\Phi(\hat{u})=\hat{u}$ . Differentiating both sides with respect to $t$ yields the desired result. MY QUESTION: The (sketch of the) proof above shows that there exists a unique local solution $\hat{u}$ for the IVP in $X$ . But the theorem states that there exists a unique solution in the space $C^{1}([t_{0}-\delta,t_{0}+\delta],\mathbb{R}^{n})$ . So why is it sufficient to prove existence and uniqueness in $X$ ? More precisely: how do we know that the IVP has no other local solution $\hat{v}$ in $C^{1}([t_{0}-\delta,t_{0}+\delta],\mathbb{R}^{n})\setminus X$ , i.e. a solution with $d_{\max}(\hat{v},x_{0})>\varepsilon$ . MY ATTEMPT: I think that it suffices to show any $u\in C^{1}([t_{0}-\delta,t_{0}+\delta],\mathbb{R}^{n})$ that solves the IVP must lie in $X$ . Because such a $u$ is continuous in $t_{0}$ and satisfies $u(t_{0})=x_{0}$ , there exists a $r>0$ (possibly smaller than $\delta$ ) such that $\|u(t)-x_{0}\|\leq\varepsilon$ whenever $|t-t_{0}|\leq r$ . However, this does not prove that $\|u(t)-x_{0}\|\leq\varepsilon$ on all of $[t_{0}-\delta,t_{0}+\delta]$ , i.e. that $u\in X$ .","['ordinary-differential-equations', 'initial-value-problems', 'fixed-point-theorems', 'lipschitz-functions', 'contraction-operator']"
3346459,Pluennecke inequality for Lebesgue measure?,"Suppose $G$ is a group. $A \subset G$ . Let’s define $\{A_n\}_{n = 1}^\infty$ by the following recurrence: $$A_n =  \begin{cases} A && \quad n = 1 \\ A_{n - 1}A && \quad n > 1 \end{cases}$$ Here $AB$ means $\{ab| a \in A, b \in B\}$ . In group theory there is a following theorem: Pluennecke inequality Suppose $G$ is an abelian group and $A \subset G$ is a finite non-empty subset. Then $\forall n > 2$ $$|A_n| \leq \frac{|A_2|^n}{|A|^{n-1}}$$ I wonder if there is an analogical statement in real analysis. To be exact, my question is: Is the following conjecture true? My conjecture: Suppose $A$ is a measurable subset of $\mathbb{R}$ ( $\mathbb{R}$ is considered to be a group under addition), such that $\mu(A) > 0$ and $\mu(A_2) < \infty$ . Then $\forall n > 2$ $$\mu(A_n) \leq \left(\frac{\mu(A_2)}{\mu(A)}\right)^n \mu(A)$$ Here $\mu$ stands for Lebesgue measure. The additional supposition about the measure of $A_2$ is caused by this . If that conjecture is false I would like to know an explicit counterexample.","['measure-theory', 'lebesgue-measure', 'real-analysis', 'group-theory', 'abelian-groups']"
3346466,Infinite group with finitely many conjugacy classes of cardinality $n$.,"Does there exist an infinite group $G$ such that: There are no conjugacy classes containing infinitely many elements. For every $n \in \mathbb{N}$ , there are only finitely many conjugacy classes containing exactly $n$ elements. Some basic observations: $G$ cannot be Abelian, otherwise it would have infinitely many conjugacy classes containing $1$ element. $G$ must have infinitely many conjugacy classes. A basic idea I had was to construct a group $$G := \bigoplus_{n \in \mathbb{N}} G_n,$$ where $G_n$ is a finite group with $2$ conjugacy classes: one containing the neutral element, of size $1$ , and the other containing all other elements, of size $p_n$ . If all $p_n$ are prime and $p_1 < p_2 < \cdots < p_n < \cdots$ , I believe the conditions would be satisfied. However, I have no idea if there are infinitely many primes $p_n$ for which such groups $G_n$ exist...","['group-theory', 'infinite-groups']"
3346469,Topological classification of a finite union of open balls in $\mathbb{R}^n$,"What are the possible topological shapes (i.e. up to homeomorphism) of a finite union of open balls in $\mathbb{R}^n?$ For example, for $n = 1$ , open balls are just open intervals and a finite union of open intervals is just a disjoint union of open intervals (the union of two intervals that overlap is again an interval) For $n = 2$ , we can have a disjoint union of open balls, but also an annulus, or an ""annulus with many holes"", a disjoint union of ""annuli with many holes"" and maybe something else. Is there a classification of these possible shapes? EDIT",['general-topology']
3346493,Representing softmax mathematically,"I have softmax as follows: $$\sigma(\mathbf{z})_i = \frac{e^{z_i}}{\sum_{j=1}^K e^{z_j}} \text{ for } i = 1, \dotsc , K \text{ and } \mathbf z=(z_1,\dotsc,z_K) \in\mathbb{R}^K$$ As borrowed from Wikipedia. I have a tensor of dimension $100 \times 100 \times 256$ , let's call this $\mathcal{X}$ . I have a variable that I have to denote just as $\mathbf{x}_{i,j} \in \mathcal{X}$ - I can't use triple indices. I am doing a channel-wise softmax using python. However, I'd also like to write this mathematically but unsure how to represent this along the depth dimension. Here's my attempt at it: $$\sigma(\mathbf{x}_{i,j}) = \frac{e^{\mathbf{x}_{i,j,k'}}}{\sum_{k=1}^{256}{e^{\mathbf{x}_{i,j,k}}}}$$ where $1 \leq k' \leq 256$ . Is this proper notation or does it not have the intended understanding?","['notation', 'discrete-mathematics']"
3346499,Finding the UMVUE of $\lambda^2$ for $X \sim Pois(\lambda)$,"Hello, I am trying to work on this problem and the following is what I know so far. Usually the steps that I take to solve these problms are 1), Find the MLE 2), Find its Bias.  If biased, adjust it. 3), Show completeness of the distribution. Once these steps are taken then the Lehman-Scheffe theorem will let us know that the unbiased estimator is the UMVUE. However, this is what I got so far. a), $\hat{\lambda}_{MLE} = \bar{X}$ so $\hat{\lambda^2}_{MLE}=\bar{X}^2$ The problem with this is that $$E[\bar{X}^2]=\frac{\lambda}{n}+\lambda^2$$ so I do not know a simple way to adjust this to make it into an unbiased estimator. For $(\lambda-1)^2$ I get the same problem with $(\bar{X}-1)^2$ where $$E[(\bar{X}-1)^2]=\frac{\lambda}{n}+(\lambda-1)^2$$ . Poisson is a regular exponential class so it is simple to show completeness.
I am just having problem with the algebraic manipulation . . . I would appreciate your help.","['statistics', 'parameter-estimation', 'maximum-likelihood']"
3346508,Theorem 5.10 in Rudin's Real & Complex Analysis,"I am stuck on theorem 5.10 on Big Rudin. The theorem is here: If $X$ and $Y$ are Banach spaces and if $\Lambda$ is a bounded linear transformation of $X$ onto $Y$ which is also one-to-one, then there is a $\delta >0$ such that $$||\Lambda x||\geq \delta ||x||$$ for all $x\in X$ . The proof is here: If $\delta$ is chosen as in theorem 5.9 (the open mapping theorem) in big Rudin, that is such that to every $y\in Y$ with $||y||<\delta$ there corresponds an $x\in X$ with $||x||<1$ so that $\Lambda x=y$ , the conclusion of that theorem, combined with the fact that $\Lambda$ is now one-to-one, shows that $||\Lambda x||<\delta$ implies $||x||<1$ . Hence $||x||\geq 1$ implies $||\Lambda x||\geq \delta$ , and $$||\Lambda x||\geq \delta ||x||$$ holds for all $x\in X$ . I understand that $||x||\geq 1$ implies $||\Lambda x||\geq \delta$ , but I couldn't fill gap between it and $||\Lambda x||\geq \delta ||x||$ holding for all $x\in X$ . If $||x||=1$ , it is clear. How fill this gap?","['proof-explanation', 'functional-analysis']"
3346550,"Which of the following best represents a portion of the graph $y = \frac{1}{e^x} + x - \frac{1}{e}$ near (1, 1)","By taking derivatives, I know that the slope of this function is positive near (1, 1) and the magnitude of the slope will keep increasing. However, how can we tell the difference between (A) and (D)? Thanks!",['functions']
3346596,Autocorrelation function of a wide-sense cyclostationary process,"I came across a question in which the following figure was given and the question was: ""The autocorrelation function RXX[k1,k2] of a zero-mean random process X[k] is depicted below. Which of the following properties are fulﬁlled?"". The answer is: it's a wide-sense cyclostationary with period 2. How can we conclude this based on the autocorrelation function? In general, if the autocorrelation matrix is diagonal, what can we conclude about the underlying process?","['statistics', 'stationary-processes', 'correlation']"
3346609,Prove $\int_0^\infty \frac{\ln^2x\ln(1+x)}{x(1+x)} dx=7\zeta(4)$,"How to prove, without using beta function that $$\int_0^\infty\frac{\ln^2x\ln(1+x)}{x(1+x)}\ dx=7\zeta(4)$$ where $\zeta$ is the Riemann zeta function. Also, can we take advantage of this result to solve some harmonic series?","['integration', 'definite-integrals', 'real-analysis', 'calculus', 'riemann-zeta']"
3346611,Question about a convex combination of characteristic functions,"To show that $\sum_k p_k\phi_k$ is a characteristic function where each $\phi_k$ is, it shown here that $\sum_kp_k =1$ is sufficient. I don't understand how $X_N = \sum_k X_k1_{N=k}$ has the characteristic function $\sum_kp_k\phi_k$ , where $N$ is independent of $X_k$ and are defined on the same underlying space? $$\phi_{X_N}(t)=E[\text{exp}(it\sum_k X_k1_{N=k})] = E[\Pi_k \text{exp}(it X_k1_{N=k})]=?$$","['characteristic-functions', 'probability-theory']"
3346618,"""Non-trivial"" solutions to equal products of consecutive integers","$\bullet\ \textbf{Question}$ One can find equivalent products of consecutive integers such as $$8\cdot9\cdot10\cdot11\cdot12\cdot13\cdot14=63\cdot64\cdot65\cdot66.$$ Other solutions of this have been posted already ( Equal products of consecutive integers ). But the implied meaning of 'trivial' solutions in other posts seems unsatisfactory -- I think I can convince you. There appear to be exactly $4$ non-trivial solutions after adjusting our vocabulary. One of which is the previous equation. I'm curious; are their any other non-trivial solutions? $\bullet\ \textbf{Triviality}$ Firstly, let's use the notation $a^{(b)}=\prod_{k=0}^{b-1}(a+k)$ to denote rising factorial. The previous equation then becomes $8^{(7)}=63^{(4)}$ . All solutions come in pairs -- one overlapping and one disjoint. For example, if we take the solution $$2^{(5)}=2\cdot3\cdot4\cdot5\cdot6=8\cdot9\cdot10=8^{(3)},$$ which we will call disjoint because no integer appears on both sides, we can create an overlapping solution multiplying both sides by $7$ : $$2^{(6)}=2\cdot3\cdot4\cdot5\cdot6\cdot\textbf{7}=\textbf{7}\cdot8\cdot9\cdot10=7^{(4)}.$$ This duality means that boring solutions like $2^{(2)}=2\cdot3=6^{(1)}$ can be disguised as interesting by transforming them from disjoint to overlapping: $$2^{(2)}=6^{(1)}\quad\rightarrow\quad 2^{(4)}=4^{(3)}.$$ For example, two answers on a previous post gave $3^{(9)}=5^{(8)}$ as an ""interesting"" solution. But this is simply the overlapping dual of $3\cdot 4 = 12$ . In general, if $a^{(b)}=c^{(d)}$ is a solution, then so is its dual: $$a^{(c-a)}=(a+b)^{(c+d-a-b)}.$$ So here we define a trivial solution either 1) having overlap or 2) having only one term on one side (previous inquiries seemed to only have considered #2). $\bullet\ \textbf{Non-trivial Solutions}$ There are $4$ known non-trivial solutions under this definition: $$2^{(5)}=8^{(3)},\quad 5^{(3)}=14^{(2)},\quad 19^{(4)}=55^{(3)},\quad\text{and}\quad 8^{(7)}=63^{(4)}.$$ I ran a computer search on equivalent $a^{(b)}$ for $a<100,000$ and $b<50$ and found nothing new ( https://repl.it/@onnomc/EqualProductsOfConsecutiveIntegers ). $\bullet\ \textbf{Proof Attempts}$ One attempt is to note $a^{(b)}=\frac{(a+b-1)!}{(a-1)!}$ and that therefore solutions to $a^{(b)}=c^{(d)}$ are also solutions to $A!B!=C!D!$ . But apparently even $A!B!=C!$ has not yet been solved ( On the factorial equations $A! B! =C!$ and $A!B!C! = D!$ ). I thought also to use Stirling's approximation since $$(a+1)^{(b)}=\frac{(a+b)!}{a!}\approx \Big(\frac{a+b}{a}\Big)^{a+1/2}\Big(\frac{a+b}{e}\Big)^b$$ and ... well, hope for the best. I made no progress here. I tried also bounding the number of distinct primes dividing $a^{(b)}$ . We can bound $c$ from below since $$a^b<a^{(b)}=c^{(d)}<(c+d-1)^d\quad\Rightarrow\quad c>a^{b/d}-d+1.$$ And of course, the non-overlapping criteria gives $c\ge a+b$ . Thus if the prime bound rises fast enough, we can show that we are trying to fit too many prime divisors into $c(c+1)...(c+d-1)$ . The furthest I got down this trail was finding $r$ consecutive integers with a product divisible by at most $r$ primes. For example, the largest solution for $r=5$ is $c=24$ since $$24\cdot25\cdot26\cdot27\cdot28=2^6\cdot3^4\cdot5^2\cdot7\cdot13.$$ The largest solution for $r=42$ seems to be $c=2175$ . But I cannot prove these are the largest such integers -- only that they appear so empirically ( https://repl.it/@onnomc/ConsecutiveIntegersOfFewPrimes ). Interestingly, the case $r=2$ yields $c=+\infty$ if there are infinitely many Mersenne primes.","['number-theory', 'combinatorics', 'prime-numbers', 'factorial']"
3346630,Problem III.2.7 in textbook Analysis I by Amann: A function induces a topological space,"I'm doing Problem III.2.7 from textbook Analysis I by Amann. Here is my attempt: Assume $A\subseteq B$ , then $B = A \cup (B-A)$ . So $h(B)= h(A \cup (B-A)) = h(A) \cup h(B-A)$ by (iii). Hence $h(A) \subseteq h(B)$ and thus $h$ is increasing. We have $h(\emptyset) = \emptyset$ , so $\emptyset^c = X \in \mathcal T_h$ . We have $X \subseteq h(X) \subseteq X$ , so $h(X)=X$ and thus $X^c = \emptyset \in \mathcal T_h$ . Assume that $(A_i)_{i\in I}$ is a family of sets such that $A_i \in \mathcal T_h$ for all $i \in I$ , so $f(A_i^c) = A_i^c$ for all $i \in I$ . Let $A = \cup_{i\in I} A_i$ . Then $A^c = (\cup_{i\in I} A_i^c)^c = \cap_{i\in I} A_i^c$ . We will prove $A \in \mathcal T_h$ by showing $f(A^c) = A^c$ . Because $A^c \subseteq f(A^c)$ , it suffices to show that $f(A^c)\subseteq A^c$ . We have $f(A^c) = f(\cap_{i\in I} A_i^c) \subseteq f(A_i^c) = A_i^c$ because $\cap_{i\in I} A_i^c \subseteq A_i^c$ for all $i \in I$ . As such, $f(A^c) \subseteq \cap_{i\in I} A_i^c = A^c$ . Assume that $(A_i)_{i\in I}$ is a finite family of sets such that $A_i \in \mathcal T_h$ for all $i \in I$ , so $f(A_i^c) = A_i^c$ for all $i \in I$ . Let $A = \cap_{i\in I} A_i$ . Then $A^c = (\cap_{i\in I} A_i)^c = \cup_{i\in I} A_i^c$ . We have $f(A^c) = f(\cup_{i\in I} A_i^c) = \cup_{i\in I}f( A_i^c) = \cup_{i\in I} A_i^c = A^c$ . Hence $A \in \mathcal T_h$ . My questions: Could you please verify if my proof look fine or contains logical gaps/errors? Any suggestion is greatly appreciated. From (iii), I get $h(A \cup B)=h(A) \cup h(B)$ for all $A, B \in \mathcal{P}(X)$ . As such, $f(\cup_{i\in I} A_i^c) = \cup_{i\in I}f( A_i^c)$ in case $I$ is finite. I feel that it still holds in case $I$ is infinite or uncountable by transfinite induction. I would like to ask of this understanding of me is correct. Thank you so much!","['general-topology', 'proof-verification', 'real-analysis']"
3346643,How would you go about integrating $\frac{1}{(-16+4x^2)}$ with respect to $x$?,"How would you go about integrating $\frac{1}{(-16+4x^2)}$ with respect to $x$ ? I've tried U-substition and integration by parts, but I can't see to get an answer and I'm assuming I'm missing some sort of trick: When I used U substition, i've tried letting $u=4x^2-16$ , but the $du$ term always has an ""x"" in it. When I used integration by parts, i pulled out a $1/4$ and my two parts were $\frac{1}{x-2}$ and $\frac{1}{x+2}$ , but I couldn't see a way of simplifying from there. I guess I can try partial fractions, but again, I dont see an way of making it simpler, and i'm not so comfortable with that method. Any help is appreciated.","['integration', 'indefinite-integrals', 'calculus']"
3346702,"If $\lim A_n$ exists, then $P(\lim A_n) = \lim P(A_n)$","Given a sequence $\{A_n\}$ of events with $\lim A_n = A$ , I would like to show that $P(\lim A_n) = \lim P(A_n)$ . $\lim A_n = A$ implies that $\limsup A_n = A$ . Thus $\bigcap \bigcup_{k=n}^{\infty}A_k=A$ Let $B_n=\bigcup_{k=n}^{\infty}A_k$ for every $n$ . Then $B_n$ is non increasing.
We have: $P(\lim A_n) = P(A) = P(\bigcap \bigcup_{k=n}^{\infty}A_k)=P(\bigcap B_n) = \lim P(B_n)$ since $B_n$ non-increasing.
Thus $P(\lim A_n) = \lim P(\bigcup_{k=n}^{\infty}A_k))$ . How do I go from here to $\lim P(A_n)$ ? Any hep would be greatly appreciated.","['limsup-and-liminf', 'limits', 'probability-theory', 'probability']"
3346708,Integral solutions of $a^{2} + a = b^{3} + b$,"Find all pairs of coprime positive integers $(a,b)$ such that $b<a$ and $a^2+a=b^3+b$ My approach: $a(a+1)=b(b^2+1)$ so $a|(b^2+1)$ and $b|(a+1)$ Now after this I am not able to do anything.pls help.","['cubics', 'number-theory', 'elementary-number-theory', 'diophantine-equations']"
3346712,Extremely hard function problem,"This problem was a question on a math test I took, and I didn't know how to solve it. How would you solve this? Let $$f(x)=e^{-xe^{-\sqrt{x}}+e^{\sqrt{x}}}+2e^{xe^{-\sqrt{x}}+e^{\sqrt{x}}}.$$ Find $$f(f(f(f(f(f(f(f(f(f(x)))))))))).$$ EDIT For more convenience, the expression of $f(x)$ is given by \begin{align*}
f(x) = \exp\bigl(-x\exp(-\sqrt{x}) + \exp(\sqrt{x})\bigr)+{} \\{}+ 2\exp(x\exp(-\sqrt{x}) + +\exp\bigl(\sqrt{x})\bigr).
\end{align*}",['functions']
3346721,Turning a continuous everywhere differentiable nowhere function into a smooth function by infinitely many times definite integration?,"Let $W(x)$ be a real-vlued function defined on a (possibly infinite) interval $\text{T}\subseteq\mathbb{R}$ containing $0$ that is continuous everywhere differentiable nowhere on $\text{T}$ . Define the sequence of function $f_n:\text{T}\to\mathbb{R}$ as follows: $$f_0(x)\triangleq{W(x)}$$ and $$f_n(x)\triangleq\int_{0}^{x}f_{n-1}(u)du$$ for $n=1,2,3,4,5,...$ . Then it follows the fact that $f_n$ is differentiable exactly $n$ -times everywhere on $\text{T}$ . Question: Does there exist such $W(x)$ and $\text{T}$ so that the sequence of function $f_n$ on $\text{T}$ ""converges"" to a limit function $f_{\infty}$ on $\text{T}$ with $f_{\infty}$ being infinitely many times differentiable (i.e., smooth) on $\text{T}$ ?","['sequence-of-function', 'convergence-divergence', 'analysis', 'real-analysis']"
3346748,About (relatively) recent progress in manifold topology and de Rham cohomology,"Background : I'm at the end of my BsC and in the next semester I'll start my MsC. I'm already familiar with analysis on manifolds (at the level of Tu's ""An Introduction to Manifolds"" and Spivak's ""A Comprehensive Introduction to Differential Geometry, Volume 1"") and classic differential geometry (at the level of Do Carmo's ""Differential geometry of curves and surfaces""). My main goal is to deeply understand how smooth manifolds work in terms of their topology and geometry. unfortunately I can't spend the whole 2 years of the MsC in this endeavor, so I need a more pinpoint focus in the future, so I'd like some help in deciding a sort of pre-project given the following (I'll try to be as specific as possible): Understanding the algebraic and differential topology of manifolds is a big deal for me. Right now I'm studying Milnor's ""Topology from the differentiable viewpoint"" and I'd really like to know what's out there beyond the topics he already covers (like, where does one go after Hopf's theorem?) The interplay of geometry and topology. Like the Bonnet-Myers theorem, (I think) Morse's theory, the sphere theorem and Hamilton's theorem, that kind of stuff. I'm also particularly interested in deeply understanding some of the topics Wellington de Melo covers in his ""Topology of manifolds"", like bundle geometry and the morphism of Chern-Weil. I know most of you will say ""ask your advisor, he's the best one to guide you in this"" but to be honest he's more or less as lost as I am. If it were possible I'd just spend the next 2 years of the MsC just trying to understand the topics I mentioned, but this is not doable and eventually I'm gonna have to focus on something a lot more specific. So I'm looking for advice: is this too much to expect for 2 years? Should I focus on something in particular on the list above? What have people been up to with diffential topology of manifolds now?","['advice', 'manifolds', 'differential-topology', 'algebraic-topology', 'differential-geometry']"
3346804,Challenging sum: Compute $\sum_{n=1}^\infty\frac{H_{2n}H_n^{(2)}}{(2n)^2}$,"Prove that $$S=\sum_{n=1}^\infty\frac{H_{2n}H_n^{(2)}}{(2n)^2}=\frac{101}{64}\zeta(5)-\frac5{16}\zeta(2)\zeta(3)$$ where $H_n^{(m)}=\sum_{k=1}^n\frac1{k^m}$ is the n $th$ generalized harmonic number of order $m$ and $\zeta$ is the Riemann zeta function. This problem is proposed by Cornel Valean and can be found here . Here is how I managed to find the integral representation: We have $\int_0^1 x^{2n-1}\ln(1-x)\ dx=-\frac{H_{2n}}{2n}$ , then we can write $$\sum_{n=1}^\infty\frac{H_{2n}H_n^{(2)}}{(2n)^2}=-\frac12\int_0^1\frac{\ln(1-x)}{x}\sum_{n=1}^\infty\frac{H_n^{(2)}}{n}(x^2)^n\ dx\\=\small{-\frac12\int_0^1\frac{\ln(1-x)}{x}\left(\operatorname{Li}_3(x^2)+2\operatorname{Li}_3(1-x^2)-\ln(1-x^2)\operatorname{Li}_2(1-x^2)-\zeta(2)\ln(1-x^2)-2\zeta(3)\right)\ dx}$$ So any idea how to crack this integral or different approach? Thanks. UPDATE: This result was mentioned by @nospoon here in equation $(3)$ . He didn't post the solution but he provided the idea.","['integration', 'definite-integrals', 'harmonic-numbers', 'polylogarithm', 'sequences-and-series']"
3346815,How to know whether a polyhedron fits within another?,"I need to know whether a sofa fits within an elevator. I know their dimensions, and I found this topic . However, does it check the fitting regardless of the orientation of the contained solid ? Or does it only try translating the moving object inside the container without changing its orientation ? I know a bit about linear algebra but pretty much nothing about convex optimization.","['convex-hulls', 'convex-optimization', 'convex-geometry', 'geometry', 'elementary-set-theory']"
3346824,When two triangles have the same heights?,"Let $\Delta ABC$ and $\Delta EFD$ be triangles with sides $a$ , $b$ , $c$ and $d$ , $e$ , $f$ . All sides have different lengths. I am looking for a functional condition for sides when triangles can have the same heights $h_E=h_B$ . My attempt. I have found the three cases when two triangles can have the same hights. Case 1. Acute triangles Case 2. Acute triangle and obtuse triangle Case 3. Obtuse triangles","['triangles', 'geometry']"
3346828,"How would you prove if $ab|(a+b)(a+b+1)$, then $(a,b) \leq \sqrt{a+b}$ for positive integers $a$ and $b$?","How would you prove if $ab|(a+b)(a+b+1)$ , then $(a,b) \leq \sqrt{a+b}$ for positive integers $a$ and $b$ ? My thoughts: I tried squaring both sides of $(a,b) \leq \sqrt{a+b}$ but don't know what to do with $(a,b)^2$ afterwards. I thought maybe using $\sqrt{ab} \leq \sqrt{(a+b)(a+b+1)} = \sqrt{(a+b)^2 + (a+b)}$ would help but I don't see how I could use it. Thanks in advance!","['number-theory', 'inequality', 'gcd-and-lcm', 'elementary-number-theory']"
3346864,Finite groups without nontrivial core-free subgroups,"Let $G$ be a group. A subgroup $H$ of $G$ is called core-free if \begin{equation*}
\bigcap_{g\in G}gHg^{-1} = 1.
\end{equation*} Equivalently, $H$ is core-free if and only if for any subgroup $N$ of $H$ , if $N\lhd G$ then $N = 1$ . Now assume groups below are finite . A Dedekind group $G$ (a group such that all its subgroups are normal) has no nontrivial core-free subgroup as \begin{equation*}
\bigcap_{g\in G}gHg^{-1} = H\ne 1
\end{equation*} for any nontrivial subgroup $H$ of the Dedekind group $G$ . This list includes all abelian groups and Hamilton groups ( $Q_8\times A\times B$ with $A$ abelian of odd order and $B = \mathbb{Z}_2^n$ for some $n$ ). My question: I aim to characterize all finite groups which has no nontrivial core-free subgroups. An example of such group which is not Dedekind is the dicyclic group of order $12$ (see comments here ). Is there any sort of classification of such groups? Added: The motivation of this question is to find some conditions of subgroups such that quasi-primitivity implies primitivity: Proposition: If $G$ has a regular subgroup $H$ , then $G$ is quasi-primitive if and only if $G$ is primitive. Note that if $H$ is transitive and has no non-trivial core-free subgroup, then $H$ is regular. The question comes to characterize what $H$ is up to isomorphism. Added (Sep 10, 2019): This is true: $G$ has no nontrivial core-free subgroup then if all of the Sylow subgroups of $G$ are not core-free, and inparticular all of the cyclic subgroups of prime order of $G$ are normal. For example, $C_3:C_4$ (dicyclic, $3$ -Sylow is normal and $2$ -Sylows contain the center) and $C_7:C_9$ ( $7$ -Sylow is normal and $3$ -Sylows contains the center) both have no nontrivial core-free subgroups. Also I think the following might be true: $C_{p^d}:C_{q^e}$ has no nontrivial core-free subgroups if $(p-1)\nmid q^e$ , where $p,q$ are distinct primes. In this case $p$ -Sylow is normal and $q$ -Sylow contains the center.","['group-theory', 'abstract-algebra', 'finite-groups']"
3346874,What's stopping us from defining isomorphism in general?,"I'm told that an isomorphism is a kind of underdetermined term, unlike say, group isomorphism or ring isomorphism.  Why couldn't we just say $\phi$ is an isomorphism on object $A$ if for all operations (or primitive relations) $R$ on $A$ , and all $a, b \in A$ , $\phi(a) R \phi(b) = \phi(a R b)$ and it is a bijection.  I realize it requires some second-order quantification of relations, but that's not exactly unheard of. If I've been careful, then this definition of isomorphism when applied to groups gives us group isomorphisms, and when applied to rings gives us ring isomorphisms.  If we wanted to discuss things that preserved some but not all relations on an object, say for example we wanted to talk about preserving the abelian group operation on a ring, we could just refer to that as a group isomorphism on the ring or something like that.",['abstract-algebra']
3346879,Show these 2 expressions are logically equivalent,"Show that $ (p\land r)\oplus(\lnot p\land q) $ and $ (p\lor q)\land (\lnot p \lor r) $ are logically equivalent. I have some trouble with this type of question, especially when it comes to $\oplus$ . After I tried to rewrite the expression with $\land$ and $\lor$ , I got lost.","['logic', 'discrete-mathematics']"
3346882,Number of sub graphs of a complete graph,"Let $G$ be a complete graph with $m$ edges and $n$ vertices, and $P(G)$ be the set of all possible sub graphs of $G$ . Then the number of elements in $P(G)$ , i.e., $|P(G)|=2^n+\binom m1+\binom m2+...+\binom mm.$ I believe that this formula is true. Your valuable comments are most welcome, please.","['elementary-set-theory', 'graph-theory']"
3346883,Bijection and Isomorphim in Set Theory,"Let A and B be two well-ordered sets. Is it ture that A and B are isomorphic if A and B are bijective? Motivation:
I am studying Bourbaki's Elements of Methematics and have just reached Sec 3.2, Chap 3 where the concept of $\mathbb{N}$ have not appeared yet but Bourbaki seems to have assumed Cantor–Bernstein theorem. I want to proof the theorem with the knowledge I have obtained from Bourbaki's work and if the above statement is ture the theorem is also ture.",['elementary-set-theory']
3346916,Coin flips and Dice rolls,"A die is rolled 100 times, and the sum of the numbers that are rolled is recorded as X (for example, if a 6 is rolled every time, X = 600).
A coin is tossed 600 times, and the number of heads is recorded as Y. 
Find P(X > Y). I know E[X] = 350 and E[Y] = 300, but I am not able to find the probability of X > Y. Any help is appreciated.",['probability']
