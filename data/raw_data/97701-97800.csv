question_id,title,body,tags
1348949,What is the actual definition of a function?,"I am learning precalculus and my book defines the following: A function $f$ from a set $A$ to a set $B$ is a rule that assigns to every element $a$ in $A$ one and only one value in $B$. Well, I am thinking, a rule isn't something that I've seen defined mathematically. So what is a function, really? Is it a subset of $A\times B$ or something?","['elementary-set-theory', 'definition', 'functions']"
1348981,Borel set of $\mathbb R^n$ with $n > 1$,"According to various sources, the Borel set over $\mathbb{R}^n$ can be defined in several equivalent ways: For instance, it can be defined as the smallest sigma-algebra containing every open set of $\mathbb{R}^n$ or the smallest sigma-algebra containing the sets  $(a_1, b_1) \times ... \times (a_n, b_n)$ for $a_1, ..., a_n, b_1, ..., b_n \in \mathbb{R}$. I did not manage to find any demonstration for this equivalence, and to me it seems to be false so I would like to know where is the flaw in my reasoning. I assumed $n = 2$ and thanks to the  properties of a sigma algebra, I restated the problem with closed sets. If the above definitions are equivalent then
the smallest sigma-algebra containing every closed set of $\mathbb{R}^2$ must be the same as as the one generated by the rectangles $[a_1, b_1] \times [a_2, b_2]$.
While it is obvious that the second sigma algebra is  included in the first, I think there are closed sets that can't be expressed as a countable union of rectangles. For example if you take a closed triangle $A(0,0)$ $B(1, 0)$ $C(1, 1)$ and consider the side $[AC]$, it is neither horizontal nor vertical therefore every point of $[AC]$ must be a corner of a rectangle, which means at least as much rectangles are needed to fill the triangle as there are points in $[AC]$ which is not a countable set AFAIK. I think my idea can be easily generalized for any $n \geq 2$. I believe I either made a mistake somewhere in my proof or I did not understand the definition for the borel set over $\mathbb{R}^n$. In any case I'd be happy to know where the flaw is. Thank you.","['probability-theory', 'general-topology', 'measure-theory']"
1349009,Open set in a general metric space.,Let d define a metric on an infinite set $M$. Show that there exists an open set $U$ such that $U$ and its complement are infinite. (Infinite referring to cardinality in both instances) I know this is trivial with the discrete metric and also trivial on the reals with the usual metric but I'm not sure how to proceed for a general metric.,"['metric-spaces', 'real-analysis']"
1349011,Density of measurable sets in $\mathbb{R} $,"Let $A$ be a Lebesgue measurable set in $\mathbb {R} $. We can classify the points in $\mathbb{R}$ as 3 disjoint subsets: density 0 points $A_1$, density 1 points $A_2$, otherwise $A_3$. By the Lebesgue density theorem, $A_3$ is measure zero. Question: Can I prove $m(A)=m(A_2)=m(cl(A_2))$? Or does some equality fail? Here $m$ is the usual Lebesgue measure and the closure is taken in the usual topology.","['real-analysis', 'measure-theory']"
1349042,"Two types of errors, type-$1$ error and type-$2$ error, can not be minimized simultaneously when the sample size $n$ is already fixed. How?","I read in some of the books that the two types of errors, type-$1$ error and type-$2$ error, can not be minimized simultaneously in Neyman Pearson Theory of testing of hypothesis when the sample size $n$ is already fixed.I am clear up to this that if one tries to reduce the type-$2$ error then the reduction in the number of time committing the type-$2$ error leads to the number of times rejection of the null hypothesis when it is actually false. that is one can say that it leads to the increment of correct rejection. but then how it can be connected to the increment in type-$1$ error, is my problem.","['hypothesis-testing', 'statistics', 'statistical-inference']"
1349059,the probability density function (PDF) of concatenation of two Gaussian variables,"Gaussian variable $x$ follows from $N(u_x,\sigma_x^2)$ and $y$ follows from $N(u_y,\sigma_y^2)$. Assume we have the vector $\bf{z}=[x,y]^T\in R^2$, then it seems that no matter whether $x$ and $y$ are independent or not, we always have that $\bf{z}$ also follows from the Gaussian distribution $N([u_x,u_y]^T, Cov([x,y]^T))$, where $Cov$ means the covariance. The above claim is reformulated from the last eight lines on the left column in page 4 of http://www.cs.bham.ac.uk/~axk/ICML_Flip_2013.pdf . Could anyone show why the distribution of $\bf{z}$ is Gaussian? and how to get the related parameters?","['calculus', 'probability-distributions', 'random-variables', 'statistics', 'probability']"
1349064,why $\lim_{x \to \frac{\pi}{4}} \frac{\cos 2x}{\sin x-\cos x}=-\sqrt{2}$?,"I have this very simple limit to find
$$\lim_{x \to \frac{\pi}{4}} \frac{\cos (2x)}{\sin x-\cos x}$$
which is equal to $-\sqrt{2}$. However I can get the outcome as mentioned, or $\sqrt{2}$ in the following way:
$$\lim_{x \to \frac{\pi}{4}} \frac{\cos (2x)}{\sin x-\cos x}=\lim_{x \to \frac{\pi}{4}} \frac{\cos ^2x-\sin^2x}{\sin x-\cos x}=\lim_{x \to \frac{\pi}{4}} \frac{(\cos x-\sin x)(\cos x+\sin x)}{\sin x-\cos x}$$
$$=\lim_{x \to \frac{\pi}{4}} (\sin x+\cos x)=\sin\frac{\pi}{4}+\cos\frac{\pi}{4}=\frac{\sqrt{2}}{2}+\frac{\sqrt{2}}{2}=\sqrt{2}$$
Why the mentioned solution method is wrong?
Is limit outcome dependent on the expression rearrangement?","['limits-without-lhopital', 'calculus', 'limits', 'trigonometry']"
1349093,Sum of two kronecker products as a kronecker product,"I seek for the following relationship (if there is one so): $$C \otimes D = (A_1 \otimes B_1) + (A_2 \otimes B_2)$$ I would like to obtain $C = f(A_1,A_2)$ (in terms of $A$'s) and $D = g(B_1,B_2)$ (in terms of $B$'s). For simplicity, we can assume $A_i$ and $B_i$ are covariance matrices, so positive-definite, square, and symmetric. Any help is greatly appreciated! PS: For more simplification (if so), we can assume $\dim(A_1) = \dim(A_2)$ and same for $B_i$'s.","['linear-algebra', 'kronecker-product']"
1349098,"Finding the kernel, eigenvalues, and eigenvectors of the operator $L(x) := x'' + 3 x' + 4 x$","I want to find the kernel, eigenvalues and eigenvectors of the differential operator: $$L(x)=x''+3x'-4x$$ on the $\Bbb C \space \space \text{vectorspace} \space \space  C^{\infty}(\Bbb R)$ as well as the solution the the homogenous differential equation: $$x''+3x'-4x=0$$ First question: I have only seen differential operators in the from of $\frac{d}{dx}$. Is there something special about $L(x)$? Does it have a special meaning in linear algebra? Second question: As far as I know, eigenvalues and eigenvectors are only defined for square matrices. However the coefficient matrix of this differential equation is not square. Do I have to turn this second order diff. equation into a system of first order equations in order to find the eigenvalues and eigenvectors? Third question: If the answer to the second question is yes. How do I turn $L(x)=x''+3x'-4x$ into a system of first order differential equations? I looked up how to convert an $n^{th}$ order diff. equation into a system of lower order differential equation ( LINK ) but the author always has equations that are equal to zero. Here my equation is equal to $L(x)$. How do I deal with that?","['eigenvalues-eigenvectors', 'linear-algebra', 'ordinary-differential-equations']"
1349101,Area of overlapping squares,"I'm working on a programming project and got to the point where I need to find how much is the blue square overlapping each of the other 9 squares. The squares' sides(including the blue one's) are 1-length. The blue square is tilted by the alpha angle.
I've thought of  some trivial approaches to the problem, but they are severely inefficient, and due to the fact that I have to run this test around 784 X 42000 times, an analytic solution would be best. Also, I also thought of checking each of the 2 triangles in the blue square to the triangles in the other squares, but that means 36 checks, which is quite slow. I would like to get something like a 3x3 matrix with the areas of the overlapping regions (some of the values in the matrix may be 0). Assuming we know the coordinates of A, B, C, D and the angle alpha (we would only need to know two of them actually), is there a more efficient approach to finding the area of the overlapping parts (and filling the matrix)?","['rectangles', 'geometry', 'area', 'rotations']"
1349119,matrix representations and polynomials,"I just investigated the following matrix and some of its lower powers: 
$${\bf M} = \left[\begin{array}{cccc}
1&0&0&0\\
1&1&0&0\\
1&1&1&0\\
1&1&1&1
\end{array}\right] , {\bf M}^2 = \left[\begin{array}{cccc}
1&0&0&0\\
2&1&0&0\\
3&2&1&0\\
4&3&2&1
\end{array}\right], \\{\bf M}^3 =  \left[\begin{array}{cccc}
1&0&0&0\\
3&1&0&0\\
6&3&1&0\\
10&6&3&1
\end{array}\right]
, {\bf M}^4 = \left[\begin{array}{cccc}
1&0&0&0\\
4&1&0&0\\
10&4&1&0\\
20&10&4&1
\end{array}\right]
$$ As a function of the exponents, indices (1,1) seem to be constant 1, (2,1) seem to be linear function, (3,1) seem to be arithmetic sum and the fourth one seems to be sums of arithmetic sums. I have some faint memory that these should be polynomials of increasing order (well I know it for sure up to the arithmetic sum), but I can't seem to remember what they were called or how to calculate them. Does it make sense to do polynomial regression or is that uneccessary? This is following the train of thought from matrix representation of generating element for parabola , maybe you can see what I'm jabbing away at. So the question is: is there an easy way to linearly combine the first columns of these matrices to generate the first 4 monomials? I can always do a linear regression with monomial basis functions, but that would be a little silly if this is already a well known way to do it.","['polynomials', 'representation-theory', 'binomial-coefficients', 'matrices']"
1349122,Homeomorphism between $S^2$ and $CP^1$ via uniqueness of quotient,"I am trying to show that $S^2$ and $\mathbb{C}P^1$ are homeomorphic making use of the following result - see e.g. Jack Lee Introduction to topological manifolds. Let $Y \xrightarrow{\pi_1} X_1 $, $Y \xrightarrow{\pi_2} X_2$ be quotient maps which are constant on each other fibres. Then there exist a unique homeomorphism $f:X_1\rightarrow X_2$ such that $f\circ\pi_1=\pi_2$. In fact  $f=\bar \pi_2$, the map induced by $\pi_2$ on the quotient, $\bar \pi_2(x)=\pi_2(y)$ where $y$ is any point of $Y$ such that $\pi_1(y)=x$. Now let \begin{equation}Y=S^3=\{(z^1,z^2)\subset\mathbb{C}^2 : |(z^1)|^2+|(z^2)|^2=1\},\end{equation}
\begin{equation} X^1=S^2=\{(z,t)\in \mathbb{C}\times\mathbb{R}:|z|^2+t^2=1\},\end{equation}
\begin{equation}
X^2=\mathbb{C}P^1=S^3/ \sim,
\end{equation}
with the equivalence relation being $[z^1,z^2]=[u^1,u^2]$ if $(u^1,u^2)=\exp(i\ a)(z^1,z^2)$ for some real number $a$. Let $\pi_2$ be the quotient projection onto $\mathbb{C}P^1$ which we equip with the quotient topology. Let $\pi_1$ be the Hopf projection
\begin{equation}
\pi_1(z^1,z^2)=(2z^1 \bar{z}^2, |z^1|^2-|z^2|^2).
\end{equation}
The Hopf projection is onto, continuous and, since it is a fibre bundle projection, open. Hence it is a quotient map. 
So both $\pi_1$ and $\pi_2$ are quotient maps and one can check that they have the same fibres. It should follow that 
\begin{equation}
\begin{split}
\bar\pi_2&:S^2\rightarrow \mathbb{C}P^1, \quad \bar\pi_2(z,t)=[z,t],\\
\bar\pi_1&:\mathbb{C}P^1\rightarrow S^2, \quad \bar\pi_1([z^1,z^2])=(2 z^1\bar z^2,|z^1|^2-|z^2|^2)
\end{split}
\end{equation}
are one the inverse of the other.  But they are not. One can check that the inverse of $\bar\pi_1$ is given by $\bar\pi_1^{-1}(z,t)=1/\sqrt{2(1-t)}(z,1-t)$. However what I am really interested in is understanding where the argument goes wrong and $\bar\pi_1^{-1}$ is not given by $\bar\pi_2$. UPDATE As pointed out by John Hughes, my computation of $\bar \pi_2$, the inverse of $\bar \pi_1$ was wrong. In case anyone is interested if $(z,t)\in S^2$, $z=|z|\exp(i \phi)=\sqrt{1-t^2}\exp(i\phi)$, then
\begin{equation}
\bar\pi_2(z,t)= \left[ \sqrt{ \frac{1 + t}{2}} \mathrm{e} ^{ i \, \frac{\phi }{2}}, \sqrt{ \frac{1 - t}{2}} \mathrm{e} ^{ -i \, \frac{\phi }{2}} \right].
\end{equation}","['quotient-spaces', 'differential-geometry', 'fiber-bundles', 'general-topology']"
1349148,Line integral of vector field/Why doesn't my solution work?,"The question in its entirety: Determine for which constants A & B the vector field $$\mathbb{F} = (Axln(z))\mathbb{i} + (By^2z)\mathbb{j} + ((\frac{x^2}{z})+y^3)\mathbb{j}$$ is conservative . If $\Bbb{C}$ is the straight line from $(1,1,1)$ to $(2,1,2)$ find $$\int_c2xln(z)\,dx+2y^2z\,dy + y^3\,dz$$ Now the trick here is supposed to be to observe that for A = 2 and B = 3 the field is conservative, and very similiar to the integral that we have to evaluate, so we can split it up into two parts (one conservative and a non-conservetive). However, as an exercise I wanted to see if I could do it without the ""trick"". I expressed the line parametrically as $$\Bbb{C(t)} = [t,1,t]$$ for $1\leq t\leq 2$. Inserting this into the integral we get $$\int_1^22tln(t)+2t + 1\,dt$$ which evaluates to $$4\,ln(2)+\frac{5}{2}$$
and the answer is supposed to be $$4\,ln(2)-\frac{1}{2}$$ What is it that I'm doing wrong? Is there something wrong with my understanding of work integrals, or have I just missed something minor? UPDATE: I have experienced a similar problem on the next couple of questions that have similar structure, so I am assuming that there is some catch to the integral that it might not be as easily parametriziable as I thought. Where exactly did I go wrong in my line of thinking?","['vector-fields', 'calculus', 'multivariable-calculus', 'definite-integrals']"
1349171,Is the Sinc function continuous?,"Is  $\frac{\sin x}{x}$ a continuous function or is it not? I am confused with the fact that at zero it cannot be defined yet the limit surely exists. So, the question of its continuity arises.","['continuity', 'limits', 'real-analysis']"
1349177,Functions $f$ such that $f(z+1)-f(z)$ is holomorphic,"Find all functions $f:\mathbb C\to\mathbb C$ such that $f(z+1)-f(z)$ is entire. I am curious about this, because an algebraic analog states that if $f:\mathbb Z\to\mathbb N$ is such that $f(m+1)-f(m)$ agrees with a polynomial in $m$ for $m\gg0$ then $f(m)$ agrees with a polynomial in $m$ for $m\gg0$.",['complex-analysis']
1349190,Definition of submanifolds by regular values,"Let $f: M \rightarrow N$ and $q \in N$ be a regular value, then $f^{-1}(q)$ is a submanifold of $M$. Now assume that $q \in N$ is not a regular value, but you pick $K:=f^{-1}(q) \cap \{p \in M; Df|_p \text{ is surjective.}\}.$ Does this mean that $K$ is a manifold? Or more generally, is there a way out to define a manifold if our $q$ is not a regular value?","['differential-geometry', 'manifolds', 'real-analysis']"
1349199,"How do I prove that for any two points in $\mathbb{C}$, there exists a $C^1$-curve adjoining them?","Let $G$ be an open-connected subset of $\mathbb{C}$. Let $a,b$ be two distinct points in $G$. How do I prove that there exists a $C^1$-curve $\alpha:[0,1]\rightarrow G$ such that $\alpha(0)=a$ and $\alpha(1)=b$? Here's how I tried: I have proven that there exists a polygonal path joining $a,b$ just like below. Then, this curve is $C^1$-curve except for the ""edges"" of the curve. Now let's focus on an edge. Since the image is lying in an open set $G$, we can have an open neighborhood $N$ of an edge. And if we transform the curve in $N$ to a dotted line, then it would be a $C^1$ cirve around an edge. However, I have a trouble with formalizing this idea. How do I formally show that a curve-image around an edge can be transformed into a dotted line?",['complex-analysis']
1349207,Arrangement of any number of objects from $n$ objects,"Prove that the total number of arrangements of objects by taking any number of objects from $n$ different objects is $\lfloor e \times n! - 1 \rfloor$, where $e$ is the natural base. I tried it by making cases that either we choose $1$ object in $\dbinom {n}{1} $ way and arrange it in $1$ way or two objects and so on, obtaining $$ \sum_{r=0}^n \dbinom {n}{r} \times r! $$ However, the quantity that we have to prove it equal to is entirely different. Any help will be appreciated. Thanks.","['permutations', 'algebra-precalculus', 'combinations', 'ceiling-and-floor-functions', 'combinatorics']"
1349216,Differentiating the exponent power series,"We know that
$$
e^x = \sum\limits_{n=0}^{\infty}\frac{x^n}{n!}
$$
We know that the series is uniformly convergent everywhere, and therefore we can differentiate term by term, i.e
$$
\left(\sum\limits_{n=0}^{\infty}\frac{x^n}{n!}\right)' = \sum\limits_{n=0}^{\infty}\frac{nx^{n-1}}{n!}
$$ But the above is equal to $e^x$. What will happen if I do this $n$ times? $$
(e^x)^{(n)} = \sum\limits_{n=0}^{\infty}1
$$ What is wrong here?","['power-series', 'calculus', 'derivatives']"
1349249,How do I evaluate $\lim_{n\rightarrow \infty}\frac{1}{\sqrt{n}}\sum_{k=1}^{n}\frac{1}{\sqrt{k}}$? [duplicate],This question already has answers here : Evaluate the limit $\lim_{n\rightarrow \infty}\frac{1}{\sqrt{n}}\left(1+\frac{1}{\sqrt{2}}+\frac{1}{\sqrt{3}}+\ldots+\frac{1}{\sqrt{n}}\right)$ (3 answers) Closed 6 years ago . How do i evaluate this limit : $$\displaystyle \lim_{n\rightarrow \infty}\frac{1}{\sqrt{n}}\left(1+\frac{1}{\sqrt{2}}+\frac{1}{\sqrt{3}}+............+\frac{1}{\sqrt{n}}\right)$$ ? Thank you for any help .,"['sequences-and-series', 'calculus', 'limits']"
1349266,Solving for x using two derivatives and algebra.,"There are two things I don't understand about the following: "" Set these derivatives equal to each other and solve the resulting equation. $2\sqrt3\cos(x) = 2\sin(x)$ $= \sqrt3 = \tan(x)$ (since $\cos(x)$ can't be 0) On the specified domain $[0, 2\pi]$ that means that: $x = \frac13\pi$ and $x = \frac43\pi$ "" Why can't $\cos(x)$ be zero - surely it is 0 at $\frac12\pi$ and $\frac34\pi$, which are both in the domain. Why $x = \frac{\pi}3$ and $x = \frac{4\pi}3$ - this is a non-calculator problem$\ldots$","['algebra-precalculus', 'derivatives']"
1349276,Does the equation $2\cos^2 (x/2) \sin^2 (x/2) = x^2+\frac{1}{x^2}$ have real solution?,"Do the equation
  $$2\cos^2 (x/2) \sin^2 (x/2) = x^2+\frac{1}{x^2}$$
  have any real solutions? Please help. This is an IITJEE question. Here $x$ is an acute angle.
I cannot even start to attempt this question. I cannot understand.",['trigonometry']
1349305,Prove that $f(X\cap f^{-1}(Y))=f(X)\cap Y$,"Let $\ f\colon A\to B$ and let $X\subset A$, $Y\subset B$, prove that
  $$f(X\cap f^{-1}(Y))=f(X)\cap Y$$ The ""$\subset$""$-$inclusion is easy: if $y\in f(X\cap f^{-1}(Y))$, exists a $x\in X\cap f^{-1}(Y)$ such that $f(x)=y$. Thus, $x\in X$ and $x\in f^{-1}(Y)$, and hence $f(x)\in f(X)$ and $f(x)\in Y$. This leads to $f(x)=y\in f(X)\cap Y$. I'm having problems with the other inclusion. If I proceed the same way I get: if $y\in f(X)\cap Y$, then $y\in f(X)$ and $y\in Y$. Thus, exists a $x\in X$ such that $f(x)=y$, and exists a $x'\in f^{-1}(Y)$ such that $f(x')=y$. If $x=x'$, it's clear the result, but don't know whether $x=x'$. I don't know what to do. I'll thank any help.","['elementary-set-theory', 'functions']"
1349325,"Operator on $L^2 (0,1)$ defined by convolution with $|x-y|^{-\alpha}$","Define $A: L^2 (0,1) \to L^2(0,1)$
$$Af(x) = \int_0^1 f(y) \frac{1}{|x-y|^\alpha} dy \quad , \quad \alpha \in (0,1)$$ For what values of $\alpha$ is it well defined? Bounded? Compact? I tried doing the appropriate integrals but I really don't understand what am I supposed to do in this specific case.","['lp-spaces', 'integral-operators', 'hilbert-spaces', 'functional-analysis']"
1349369,Limit of a sum.,"While fixing my answer to this question I noticed that (actually the question is equivalent to this modulo some algebra) $$\frac{1}{2}=\lim_{x\to\infty}\sum_{i=0}^\infty \frac{x^{i-1}}{i!\sum_{j=0}^i\frac{x^j}{j!}}$$ The series converges pretty much like an exponential series, so is easy to numerically evaluate, but I cannot seem to beat it into submission. Further experimentation leads me to conjecture that $$\sum_{i=0}^\infty \frac{x^{i}}{i!\sum_{j=0}^i\frac{x^j}{j!}} = \frac{x+\ln x}{2}+O(1)$$","['sequences-and-series', 'calculus', 'limits']"
1349393,Does $\tan (x)$ equal $\frac{-1}{x-\frac{\pi}{2}}+\frac{-1}{x+\frac{\pi}{2}}+\frac{-1}{x-\frac{3\pi}{2}}+\frac{-1}{x+\frac{3\pi}{2}}+...$?,"I set my Year 12 students a question involving the sums of rational functions $\frac{1}{x-n}$. The graph of a sum of these functions looks an awful lot like a tan graph. This led me to ask: Does $\tan (x)$ equal $\frac{-1}{x-\frac{\pi}{2}}+\frac{-1}{x+\frac{\pi}{2}}+\frac{-1}{x-\frac{3\pi}{2}}+\frac{-1}{x+\frac{3\pi}{2}}+...$? I've played with it a little. I can show that the derivative of the right hand side is $1$ at $x=0$, which is promising. I haven't got any further. (I am assuming convergence of the RHS...) i. Might somebody have a delicious proof or disproof of this identity? ii. Varying the +s and -s in the sum seems to produce graphs that look like $\sec(x)$. Is there a general method to write a function that has vertical asymptotes as a sum of such reciprocal functions? Thanks!","['taylor-expansion', 'infinity', 'sequences-and-series', 'trigonometric-series', 'trigonometry']"
1349398,Measure of curve smoothness,"Could someone please give me the intuition behind using integral of squared second derivative as a measure of curve smoothness? I was thinking that since curvature measures how fast a curve changes, should we not be integrating the square of curvature? Basically why are we ignoring the denominator from the definition of curvature before even checking if first derivative is small enough. This is also used in Smoothing Splines so I guess there is something to it then just being a mere approximation.","['plane-curves', 'spline', 'derivatives']"
1349401,"If $G$ is a group of order $2^nm$, where $m$ is odd and $(m-1)!<2^n$, show that $G$ is not simple.","If $G$ is a group of order $2^nm$, where $m$ is odd and $(m-1)!<2^n$, show that $G$ is not simple. I started out by trying to prove this using the Sylow theorem, but it led nowhere. I was able to prove this for the case $n=1$. Perhaps someone can generalize the following proof for any $n$: Let $\pi:G\to S_G$ be the left-regular representation and let $x\in G$ be an element of order $2$. Since $\pi$ is injective, the restriction map
$$
\pi \mid_{H}:H=\langle x \rangle \to S_G
$$
is also injective. Let $g\in G$. Then the $H$-orbit of $g$ is $\{ g,xg \}$, so that $\pi(x)$ is the product of $m$ disjoint $2$-cycles. But $m$ is odd, which implies $\pi(x)$ is an odd permutation. It follows that $\pi(G)$ is not a subgroup of $A_G$. Now consider $\pi(G)A_G$, which is a subgroup of $S_G$ since $A_G$ is normal. I claim that $S_G=\pi(G)A_G$. To see this, observe that $S_G/A_G$ is cyclic of order $2$, generated by the class of $\pi(x)$. Then $\sigma\in S_G$ implies that 
$$
\sigma A_G = \pi(x)^s A_G
$$ 
for some $s$. Conclude that $\sigma\in \pi(G)A_G$ and $S_G=\pi(G)A_G$, as required. Therefore,
$$
|S_G|=|\pi(G)S_G|=\frac{|\pi(G)||A_G|}{|\pi(G)\cap A_G|}
$$
and we see that $[\pi(G):\pi(G)\cap A_G]=2$, so that $G$ has a normal subgroup ($G$ is isomorphic to its image in $S_G$). Can this proof be generalized?","['abstract-algebra', 'group-theory', 'finite-groups', 'permutations']"
1349414,A basic question about closed set in Zariski topology,"Suppose I have homogeneous polynomials $f_1, .., f_r \in \mathbb{C}[x_1, ..., x_n]$, and let $I = (f_1, ..., f_r)$. Let $V:=V(I) \subseteq \mathbb{C}^n$ be the points where $f_i$'s vanish. Suppose $V$ can be expressed as
$$
V = V_1 \cup V_2,
$$ 
where $V_1$ and $V_2$ are non-empty Zariski closed sets. 
Let $V_i = V(I_i)$. Does it then follow that $I_i$ is an ideal generated by homogeneous polynomials $(i=1,2)$ as well? I am asking this because I was wondering if every irreducible component of $V$ must contain the $\mathbf{0} = (0, ..., 0)$ point or not. Thank you very much! PS I would like to add why I asked this question here.
I was learning about codimension of intersection of varieties. In Basic question related to dimension of intersection of two varities ,
I was pointed out that when $V$ and $W$ are not 
irreducible algebraic sets then the formula 
$$
codim \ V + codim \ W \geq codim (V \cap W)
$$
does not necessarily hold (But it holds true when $V$ and $W$ are affine irreducible varieties that have non-trivial intersection). What I was wondering was that perhaps this inequality holds true even when $V$ and $W$ are not necessarily irreducible in the projective setting. I wanted to prove it, so I wanted to think about the zero sets of homogeneous polynomials in the setting $\mathbb{C}^n$ so that I could apply the inequality where I know it holds true.","['algebraic-geometry', 'zariski-topology']"
1349424,Symbol $\Gamma$ when talking about vector fields.,"I noticed several times online that people tend to use the symbol $\Gamma(M,TM)$ when talking about the space of smooth vector fields on smooth manifolds. I find this totally confusing, as in differential geometry this should be the same as $C^{\infty}(M,TM).$ Thus, I don't see why one would introduce this strange notation. Can anbody motivate it or is there even a difference between the two spaces?","['differential-topology', 'differential-geometry']"
1349441,Is My Proof that $\pi^e < e^{\pi}$ Valid? [duplicate],"This question already has answers here : Comparing $\pi^e$ and $e^\pi$ without calculating them (15 answers) Closed 8 years ago . The other day, a math teacher at my college gave me a challenge problem: Prove that $$\pi^e < e^{\pi}$$ without using a calculator. The next day, I found a valid proof, but I used a log table instead of a calculator, so my proof is hardly satisfying. I went looking for another proof and I came up with something that might not be legitimate. Here's my proof: Suppose that is an $x$ such that $x^e < e^x$ Then taking the natural log of both sides, $$\ln(x^e) < \ln(e^x)$$ $$e\ln(x) < x$$ $$\ln(x) < \frac{x}{e}$$ Differentiate both sides, $$\frac{1}{x} < \frac{1}{e}$$ $$x>e$$ Thus, $x^e < x^e$, for $x > e$ Since $\pi > e$, therefore $\pi^e < e^{\pi}$ I think my proof is good except perhaps where I differentiated both sides of the inequality. I know that there are many cases where this is invalid, but I'm not sure about this case.","['derivatives', 'proof-verification', 'inequality']"
1349466,Calculating $\sum_{k=0}^{n}\sin(k\theta)$ [duplicate],"This question already has answers here : How can we sum up $\sin$ and $\cos$ series when the angles are in arithmetic progression? (8 answers) Closed 8 years ago . I'm given the task of calculating the sum $\sum_{i=0}^{n}\sin(i\theta)$. So far, I've tried converting each $\sin(i\theta)$ in the sum into its taylor series form to get: $\sin(\theta)=\theta-\frac{\theta^3}{3!}+\frac{\theta^5}{5!}-\frac{\theta^7}{7!}...$ $\sin(2\theta)=2\theta-\frac{(2\theta)^3}{3!}+\frac{(2\theta)^5}{5!}-\frac{(2\theta)^7}{7!}...$ $\sin(3\theta)=3\theta-\frac{(3\theta)^3}{3!}+\frac{(3\theta)^5}{5!}-\frac{(3\theta)^7}{7!}...$ ... $\sin(n\theta)=n\theta-\frac{(n\theta)^3}{3!}+\frac{(n\theta)^5}{5!}-\frac{(n\theta)^7}{7!}...$ Therefore the sum becomes, $\theta(1+...+n)-\frac{\theta^3}{3!}(1^3+...+n^3)+\frac{\theta^5}{5!}(1^5+...+n^5)-\frac{\theta^7}{7!}(1^7+...+n^7)...$ But it's not immediately obvious what the next step should be. I also considered expanding each $\sin(i\theta)$ using the trigonemetry identity $\sin(A+B)$, however I don't see a general form for $\sin(i\theta)$ to work with.","['taylor-expansion', 'calculus', 'summation', 'sequences-and-series', 'trigonometry']"
1349471,"$y^2 = x^3 - 26$, exist ideal satisfying conditions?","For the solution $(x, y) = (3, 1)$ of $y^2 = x^3 - 26$, does there necessarily exist an ideal $I$ of the integer ring $\mathbb{Z}[\sqrt{-26}]$ of $\mathbb{Q}(\sqrt{-26})$ such that $(y + \sqrt{-26}) = (1 + \sqrt{-26})$ is equal to $I^3$ but this $I$ is not principal?","['ring-theory', 'number-theory', 'abstract-algebra', 'elementary-number-theory', 'algebraic-number-theory']"
1349487,Is there a function that can be subtracted from the sum of reciprocals of primes to make the series convergent,The gamma constant is defined by an equation where the harmonic series is subtracted by the natural logarithm: $$\gamma = \lim_{n \rightarrow \infty }\left(\sum_{k=1}^n \frac{1}{k} - \ln(n)\right)$$ It is well known that both the harmonic series by itself and the sum of reciprocals of primes are divergent. Is there a well known function that when subtracted from the sum of reciprocals of primes makes the resultant series convergent? Is there a function $f(x)$ that makes the following series convergent: $$\lim_{n \rightarrow \infty }\left(\sum_{p\text{ is a prime }}^n \frac{1}{p} - f(n)\right)$$,"['prime-numbers', 'sequences-and-series', 'convergence-divergence']"
1349495,Subring of $\mathcal O(\mathbb C)$,"Let $\mathfrak A \subset \mathcal O(\mathbb C)$ be the subring generated by the nowhere zero analytic functions $f: \mathbb C \to \mathbb C$. Do we have a precise description of $\mathfrak A$? Is $\mathfrak A = \mathcal O (\mathbb C)$, or equivalently is there a holomorphic function $f$ such that $f \neq g_1 + \dots + g_r $ for all $g_1, \dots, g_r \in \mathcal O^*(\mathbb C)$ ? For the moment, I only know that $\mathfrak A$ contains constants functions, and the functions on the form $z \mapsto e^f$ where $f$ is some holomorphic map. But I have really no idea how to solve this problem. Any hints?","['abstract-algebra', 'commutative-algebra', 'complex-analysis', 'ring-theory']"
1349529,Analytic continuation of a certain Dirichlet series,"Is there an elementary way to analytically continue $$f(s)=\sum_{n=1}^\infty \frac{(-1)^n}{(2n+1)^s}$$ to the entire complex plane? It is not hard to see (by grouping terms in pairs and using the mean value theorem) that it converges for $\Re(z)>0$. I realize there is a vast literature on Dirichlet series that almost certainly answers this with some general theorem. However, this sum appears as a qualifying exam question (1.43), so presumably there is a more direct method. For example, if the terms did not alternate, we could just take $(1-2^{-s})\zeta(s)$ and use the fact $\zeta(s)$ has a continuation to the entire plane.","['sequences-and-series', 'analyticity', 'dirichlet-series', 'complex-analysis']"
1349578,Is a meromorphic function satisfying $f(2z)=\frac{f(z)}{1+f(z)^2}$ constant?,"Let $f(z)$ be a holomorphic function on the unit disk satisfying $f(0)=0$ and $$f(2z)=\frac{f(z)}{1+f(z)^2}.$$ Extend it to a meromorphic function on the entire complex plane using this recursion. Must $f(z)$ be constant? I think so, but I can't prove it. Substituting $g(z)=1/f(z)$ and rearranging yields $$g(2z)=g(z)+\frac{1}{g(z)},$$ which seems useful, but I'm not sure how to proceed after that.",['complex-analysis']
1349580,Definition of covering (deck) transformation for smooth manifolds: Are they diffeomorphisms?,"In John Lee's book Riemannian Manifolds , a covering transformation (or deck transformation) of a smooth covering map $\pi:\tilde{M}\to M$ (of connected smooth manifolds) is defined to be a smooth map $\varphi:\tilde{M}\to\tilde{M}$ such that $\pi\circ\varphi=\pi$. I was expecting that the definition includes the additional assumption that $\varphi$ is a diffeomorphism , but apparently John Lee doesn't include it in his definition. Question: Does this definition imply that $\varphi$ is a diffeomorphism? It is clearly at least an immersion ($d\varphi$ is everywhere injective) because $d\pi\circ d\varphi=d\pi$ and $\pi$ is a local diffeomorphism. Moreover, $\varphi$ maps $\tilde{M}$ to itself, so $d\varphi$ is bijective everywhere. Hence it would suffices to show that $\varphi$ is bijective . Is that the case?","['differential-geometry', 'algebraic-topology', 'riemannian-geometry', 'covering-spaces']"
1349608,inscribed circle in $n$-gon,"If I'm given a circle with radius $r$ and I want to create a polygon with side $n$ (say $n=5$) which can cover the circle fully,  then how to prove that a regular polygon is the solution with minimum area?","['plane-geometry', 'geometry', 'circles', 'polygons']"
1349619,Find this Determinant,"I have to find this determinant, call it $D$  \begin{vmatrix}
    \frac12 & \frac1{3}& \frac1{4} & \dots  & \frac1{n+1} \\
    \frac1{3} & \frac14 & \frac15 & \dots  & \frac1{n+2} \\
    \vdots & \vdots & \vdots & \ddots & \vdots \\
    \frac1{n+1} & \frac1{n+2} & \frac1{n+3} & \dots  & \frac1{2n}
\end{vmatrix} As there are no zeros in there, despite being a symmetric matrix, finding this determinant is tough for me. Is there any tricks etc. I do not know any softwares to find this determinant. I tried to make a pattern by calculating for $n=1,2,3,\dots$ $n=1 \hspace{5cm}D_1=\frac12\\ n=2 \hspace{5cm} D_2=\frac12\frac14-\frac13\frac13\\ \\n=3 \hspace{5cm} D_3=\frac12\frac14\frac16-\frac13\frac13\frac16-\frac12\frac15\frac15-\frac14\frac14\frac14+\frac13\frac14\frac15+\frac13\frac14\frac15$ What I spot from here is, to get $D_2$, (even case) We get $\frac12\frac14$ by multiplying diagonal entries and then subtracting $\frac1x\frac1x$ where $x=\frac{2+4}2$ Next, to get $D_3$ (odd case),  we  get our first term i.e. $\frac12\frac14\frac16$ by multiplying diagonal entries and to obtain the rest we follow this pattern that subtract $\frac1x\frac1y\frac1z$, where first we fix $x=2$ and make $y=z=\frac{4+6}2=5$, similarly next we subtract by fixing $x=6$ and $y=z=\frac{2+4}2=3$ and then by fixing $x=4$ and $y=z=\frac{4+4}2=4$, and to get terms that get added we add terms of the form $\frac1x\frac1y\frac1z$ by putting $x=\frac{2+4}2 , y=\frac{4+4}2=4,z= \frac{4+6}2=5$, but we do it $2$ times. Now out of curiosity I had to calculate $n=4,5$. Here are them- For $n=4 \text{(even case)} \hspace{3cm} D_4=\frac1{2.4.6.8}-\frac1{2.5.5.8}-\frac1{2.4.7.7}-\frac1{2.6.6.6}\frac1{3.3.6.8}-\frac1{3.4.6.7}-\frac1{5.5.3.7}-\frac1{3.4.6.7}-\frac1{4.4.4.8}-\frac1{4.5.5.6}-\frac1{3.5.5.7}-\frac1{4.5.5.6}-\frac1{4.5.5.6}+\frac1{2.5.6.7}+\frac1{2.5.6.7}+\frac1{4.5.5.6}+\frac1{3.3.7.7}+\frac1{3.4.5.8}+\frac1{3.6.6.5}+\frac1{3.4.5.8}+\frac1{4.4.5.7}+\frac1{4.4.6.6}+\frac1{3.6.6.5}+\frac1{5.5.5.5}+\frac1{4.4.5.7}$. This helps somewhat in recognizing a pattern in even case, but to be sure one has to find $n=6$ case too. I guess $n=5$ case will be enough to recognize a pattern, if the one above mentioned in $n=3$ works, as by that, $D_5$ should come out to be $D_5=\frac1{2.4.6.8.10}- {^5C_2} \text{terms of the form} \frac1{x_1x_2x_3x_4x_5}, \text{where any three terms say} x_1,x_2,x_3$  are fixed out of $2,4,6,8,10$ and $x_4,x_5$ takes values of mean of the other two remaining and similarly for positive terms, but they seem very less number of terms as there were already $12$ negative terms in expansion of $D_4$, so here some more negative terms will appear and their pattern can be known by only finding them, after a few steps, may be upto $n=11$ or $12$, we can see a general pattern appearing. I am sure after calculating all this that there is a pattern, but may be too complex to find by hand, as calculations gets huge, and it is also probably a hammer to kill an ant, as I am not aware of any other trick, I worked all this out, may be someone can find a quicker solution?","['determinant', 'linear-algebra', 'matrices']"
1349622,Improper integral $\int_0^\infty \frac{\sin(x)}{x}dx$ - Showing convergence.,"1)Show that for all $n\in\mathbb{N}$ the following is true: $$\int_{\pi}^{n\pi}|\frac{\sin(x)}{x}|dx\geq C\cdot \sum_{k=1}^{n-1}\frac{1}{k+1}$$ for a constant $C>0$ and conclude that the improper integral $\int_0^\infty \frac{\sin(x)}{x}dx$ isn't absolutely convergent. 2)Show that the improper integral $\int_0^\infty \frac{1-\cos(x)}{x^2}dx$ is absolutely convergent. (The integrand is to be expanded continuous at $x=0$.). 3)Using 2), show that the improper integral $\int_0^\infty \frac{\sin(x)}{x}dx$ is convergent. We started discussing improper integrals in class and our prof showed us how some can be solved and some can't. Anyways, Here were my ideas so far: 1) I thought about to do the integral and seeing if what I get out of it gives me any idea to show the inequality. But I couldn't even solve the integral (not by hand nor with the help of an integral calculator). So I don't know what to do next. 2)To be hoenst I'm totally lost here. No idea how to approach it. 3)Well, since I didn't solve 2). Sorry for my lack of work here, but this topic just doesn't want to stick with me.","['real-analysis', 'improper-integrals', 'absolute-convergence', 'integration', 'convergence-divergence']"
1349644,What is the maximum amount of solutions to $f(x+1)f(x)= ax^2+bx+c$.,"$f(x)$ is going to be in the form $mx+h$ thus, $(mx+m+h)(mx+h) = ax^2+bx+c$. With basic algebra $m= \pm \sqrt{a}$. Also $(m+h)(h)=c$. I would guess that because $(m+h)h=c$ has two solutions max if $m$ is one number, there will be 4 solutions max if $m$ is two numbers am I right? I'm trying to find the max amount of solutions to $f(x)f(x+1)= ax^2+bx+c$","['algebra-precalculus', 'recursion']"
1349654,How do i evaluate this integral $ \int_{\pi /4}^{\pi /3}\frac{\sqrt{\tan x}}{\sin x}dx $?,"Is there some one show me how do i evaluate this integral :$$ \int_{\pi /4}^{\pi /3}\frac{\sqrt{\tan x}}{\sin x}dx $$ Note :By mathematica,the result is :
$\frac{Gamma\left(\frac1 4\right)Gamma\left(\frac5 4\right)}{\sqrt{\pi}}-\sqrt{2} Hypergeometric2F1\left(\frac1 4,\frac3 4,\frac5 4,\frac1 4\right).$
and i think it elliptic integral . Thank you for any kind of help","['gamma-function', 'trigonometry', 'definite-integrals', 'integration']"
1349666,Difference between stochastic process and chaotic system [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Can anyone please point out some difference and similarity between stochastic system  and chaotic system?","['statistics', 'soft-question']"
1349668,What does $f^{-1}(B)= \{ x \in X \mid f(x) \in B\}$ mean?,"I have encountered the expression
$$f^{-1}(B) = \{ x \in X \mid f(x) \in B\}$$
My questions are: 1) What does the $-1$ exponent mean in this context? 2) Is it right to say ""if the set $X$ contains the element $x$ then the image of $x$ is contained in the set $B$""? 3) What does it mean to assign a function with this notation $\{ x \in X \mid f(x) \in B\}$? How could function be equal to this notation?","['elementary-set-theory', 'functions']"
1349689,Explaining the definition of vector bundles,"Recall the definition of a vector bundle: Let $M$ be a topological space. A $k$ -dimensional vector bundle over $M$ is a topological  space $E$ with a surjective continuous  map $\pi\colon E \to B$ , satisfying the following: For each $p\in M$ : a) The fiber $E_p=\pi^{-1}(p)$ is a (real) vector space of dimention $k$ . b) for each $p \in M$ , there's a neighborhood $U\ni p$ and a homeomorphism $\phi\colon \pi^{-1}(U) \to U \times \mathbb{R}^k$ such that: c) $P_1\circ \phi = \pi$ , where $P_1$ is projection onto the first factor. d)  for each $q\in U$ , the restriction $\phi\colon E_q \to {q}\times \mathbb{R}^k$ (where $\phi$ is the homeomorphism from c)) is a linear isomorphism. My questions:
If I'm right the condition (b) guarantees that the attached vector spaces are locally of the same dimention. But why we need condition (c)? And what extra information  condition (d) gives us besides what we already have from condition (a)?","['manifolds', 'vector-bundles', 'general-topology']"
1349704,"Function that decays faster than any polynomial, but not in the Schwartz space?","Motivated by the very restrictive condition imposed in the definition of the Schwartz space, I was wondering about the following question. Is there a $C^\infty$ function that decays faster than any polynomial, but
  whose derivatives do not? That is, we would like $|x^n f(x)|$ to be bounded for all $n$ and $x$, but for $|x^n f^{(k)}(x)|$ to be unbounded for all $n$ and $k>0$ as $x$ ranges over the reals. Unfortunately, I only really know one rapidly decaying function (the exponential), and it doesn't work here. Maybe if we tack on some oscillation, like $\sin(x^2)$, that would help?","['real-analysis', 'schwartz-space']"
1349706,How can I raise a Taylor Series to a power?,"I have recently been undertaking the challenge of finding the antiderivative of $x^x$. In doing so, I have come across the idea of raising a Taylor series to a variable exponent. I came to the following conclusion: $$(\sum_{n=0}^\infty c_nx^n)^p = \sum_{{n_1}=0}^\infty \sum_{{n_2}=0}^\infty \cdots \sum_{{n_p}=0}^\infty c_{n_1}x^{n_1} c_{n_2}x^{n_2} \cdots c_{n_p}x^{n_p}.$$ Now, for multiplying two different Taylor series, this was as far as I could get, but assuming that it is a single Taylor series (as is the case for raising one to an exponent), I believe that one has: $$c_{n_1}x^{n_1} = c_{n_2}x^{n_2} = \cdots = c_{n_p}x^{n_p}.$$ Following from this, one would have the result: $$\left(\sum_{n=0}^\infty c_nx^n\right)^p = \sum_{n=0}^\infty \left(c_nx^n\right)^p.$$ Is my logic mathematically sound, and is this a proper result? I have tried Googling this, but no results have come up. Thank you for your help.","['taylor-expansion', 'sequences-and-series', 'exponentiation']"
1349773,Taking limits on each term in inequality invalid?,"So this inequality came up in a proof I was going through. $$c - 1/n < f(x_n) \leq c$$ Where $c$ is a real number, $f(x_n)$ is the image sequence of some arbitrary sequence being passed through a function and $n$ is a natural number. At this point the author simply concludes that this implies the function sequence converges to $c$. It's pretty clear that this is happening, but I'm not exactly sure what the proper justification is. Are we taking limits as $n \to \infty$ on all sides of the inequality? So that we get $$c < \lim_{n \to \infty} f(x_n) \leq c$$ Can we just take limits on all sides of an inequality like that? It seems like that could lead to problems as you could take a situation like $$1 - 1/n < 1$$ but then doing what I suggested would just lead to $1<1$ which is not true. So what is the argument that I seem to be overlooking? Thanks.","['limits', 'real-analysis', 'proof-verification', 'inequality']"
1349802,how to define that a nonlinear operator is bounded and continuous,"We always see the definition of bounded and continuous linear operator.
I am wondering how to define that a nonlinear operator is bounded and continuous.
Is there any book providing this definition?","['operator-theory', 'real-analysis', 'functional-analysis']"
1349809,Must a basis for an $n$-dimensional vector space have $n$ vectors?,"Does a basis for an $n$-dimensional vector space have to have $n$ vectors? For example, if I form a basis for $\mathbb{R}^n$, do I need at least $n$ vectors in my basis set? In other words, can I form a basis for $\mathbb{R}^n$ by using only $n-1$, or less, vectors? Note that, in this question, we only consider the whole vector space not creating a basis for a subspace.","['vector-spaces', 'linear-algebra']"
1349810,The inequality $\frac{MA}{BC}+\frac{MB}{CA}+\frac{MC}{AB}\geq \sqrt{3}$,"Given a triangle $ABC$, and $M$ is an interior point. Prove that:
$\dfrac{MA}{BC}+\dfrac{MB}{CA}+\dfrac{MC}{AB}\geq \sqrt{3}$. When does equality hold?","['geometry', 'triangles', 'geometric-inequalities', 'inequality']"
1349811,A limit problem: $\lim\limits_{n\to\infty}\frac{1+\frac{1}{2}+\frac{1}{4}+\cdots+\frac{1}{2^n} }{1+\frac{1}{3}+\frac{1}{9}+\cdots+\frac{1}{3^n} }$,I need help in solving the limit below: $$\lim_{n\to\infty}\frac{1+\frac{1}{2}+\frac{1}{4}+\cdots+\frac{1}{2^n} }{1+\frac{1}{3}+\frac{1}{9}+\cdots+\frac{1}{3^n} }$$ What I've done is to simplify the upper part to: $$\frac{2^{n+1}-1}{2^n}$$ Any hints or solutions will be greatly appreciated.,"['sequences-and-series', 'calculus', 'limits']"
1349829,Find: $\lim_{x\to0}\left(\lim_{n\to\infty}2^{2n}\left(1-\left(f ^{\circ n}(x)\right)\right)\right)$,"Let $$f:[0,1]\to\Bbb R\;\;\mbox{defined by}\;\;\; f(x)=\sqrt{\frac{1+x}{2}}$$ Find: $$\lim_{x\to0}\left(\lim_{n\to\infty}2^{2n}\left(1-\left(\overbrace {f \circ f \circ f \cdot\cdot\cdot \circ f}^{n}(x)\right)\right)\right)$$ I mainly need help with simplifying the composite function. I'll try to take it on from there. Any (substantial) hints or solutions will be greatly and sincerely appreciated.","['function-and-relation-composition', 'limits']"
1349861,Why is the commutator group a subgroup?,"I am in Intro to Algebra, and have a question regarding the commutator subgroup. I am a bit confused with the premise, though, with how the set is a subgroup in the first place. Let $C$ be the set of commutators of $G$. Then two arbitrary elements of $C$ would be $aba^{-1}b^{-1}$ and $cdc^{-1}d^{-1}$. I don't see how $C$ is closed under multiplication. That is, I don't see how
$$aba^{-1}b^{-1}cdc^{-1}d^{-1}\in C.$$
Am I making a wrong assumption in assuming that the binary relation is multiplication? Any help would be appreciated. Again, this is my first semester of algebra, so try to keep it basic.","['abstract-algebra', 'normal-subgroups']"
1349888,Question about required rigour with intro real analysis text,"I have just begun trying to self study introductory analysis and I am just having some questions about being specific on rigour. In the book I am using, titled Introduction to Real Analysis, 4th edition by Robert G. Bartle and Donald R. Sherbert. The second chapter begins with listing the properties of $\mathbb{R}$ and then does a bunch of the basic proofs of the properties of reals using just the given axioms. My question is, it mentions that It is worth noting that no smallest positive real number can exist, in fact if $$a \gt 0$$ then we have $$0 \lt \frac{1}{2}a \lt a$$ 
  (why?) Now, of course I understand that is true but I am just wanting to only use justifications. And I am wondering how we can say that $\frac{1}{2}a \lt a$, I mean, I am not sure that it defines any sort of rule that ordered the numbers like that or some sort of division or order of rationals. How can that result come from Trichototmy? I know that since $a \gt 0$ and since it can be shown that if $a \gt 0$ then $a^{2} \gt 0$ (because if $a \in P$ then $a(a) \in P$) so that settles that, and also that $\frac{1}{2} \gt 0$ since $\pm \frac{\sqrt2}{2} \in \mathbb{R}$ hence $\frac{1}{2} \gt 0$ and so $(1/2)a$ is greater then zero, but how to conclude that $(1/2)a$ is ordered less than $a$? Is there any source where I can see how the rationals are ordered anyways (but I would still be interested in how from these principals it can be concluded). I hope it makes sense, maybe I am missing something or being very naive, but hopefully someone gets what I am trying to say. Thanks a lot","['real-numbers', 'real-analysis']"
1349906,Are there closed curves for which acceleration is orthogonal to position?,Can we find $\vec{f} : \mathbb{R}\rightarrow \mathbb{R}^3 $ such that $\vec{f}(t) \cdot \frac{d^2 \vec{f}(t)}{dt^2} =0$ and $\vec{f}(0) = \vec{f}(T)$ for some $T >0$ ? Exclude the trivial cases. I want $\frac{d \vec{f}}{dt} \neq 0$ for some part of the trajectory.,"['vectors', 'ordinary-differential-equations']"
1349907,"What is the relation between rank of a matrix, its eigenvalues and eigenvectors",I am quite confused about this. I know that zero eigenvalue means that null space has non zero dimension. And that the rank of matrix is not the whole space. But is the number of distinct eigenvalues ( thus independent eigenvectos ) is the rank of matrix?,"['eigenvalues-eigenvectors', 'matrix-rank', 'linear-algebra']"
1349927,Differentiation with dependent variable,"Let $$
F(x, y) = x^3 + 7 y^2 x^4 - (2 x - y)^3
$$ and let $y=f(x)=x^2+1$. Is it correct to write $$
\frac{\partial F}{\partial y}=\frac{\partial F}{\partial x}\frac{\partial x}{\partial y}?
$$ If yes then why $$
\left.\frac{\partial F}{\partial y}\right|_{y=f(x)}\neq\left.\frac{\partial F}{\partial x}\frac{\partial x}{\partial y}\right|_{y=f(x)}
$$ This is what I tried F[x_, y_] := x^3 + 7 y^2 x^4 - (2 x - y)^3

TT := x^2 + 1
X1 := F[x, y] // D[#, y] & // ReplaceAll[#, {y -> TT}] & // ExpandAll
X2 := F[x, y] // D[#, x] & // Times[#, 1/D[TT, x]] & // 
   ReplaceAll[#, {y -> TT}] & // ExpandAll Why $X1\neq X2$?",['ordinary-differential-equations']
1349945,Sequence uniform convergence but the derivatives are not.,"Give a sequence $(f_n)_{n\in \mathbb{N}}$ of differentiable functions which uniformly converge to $0$, but for which the seqeunce $(f_n')_{n\in \mathbb{N}}$ of the derivatives isn't even pointwise convergent. I found this one in my textbook marked as ""Fun things to solve"" and although it may be fun, it's kind of hard to do. To be honest I already failed at the first hurdle. I couldn't even find a sequence of functions which uniformly converges to $0$. Is there a certain way of dealing with this kind of problem? Because it seems kind of hard for me to come up with sequences without a mathematical of way of doing so (or maybe there is a mathematical way I just don't know yet).","['sequences-and-series', 'uniform-convergence']"
1349955,Calculate the derivative,"I'm asked to find the derivative of the following: $$
\sqrt[4]{x} + \sqrt[3]{3x}
$$ I attempted to solve the problem and got the following result, but my book says I am wrong. $$
\frac 14x^{-\frac 34} + x^{-\frac 23}
$$ When I checked I got the following as the correct answer. Why is it 3x and not x? What am I doing wrong here?
$$
\frac 14x^{-\frac 34} + 3x^{-\frac 23}
$$","['calculus', 'derivatives']"
1349957,"Roots of $p(x)=\prod_{i=1}^{2n}(x-d_i)+k^2, \ \ \ \ n\in\mathbb N,\ k\in\mathbb R$","Let
$$p(x)=\prod_{i=1}^{2n}(x-d_i)+k^2, \ \  \ \ n\in\mathbb N,\ k\in\mathbb R$$
where $d_i>0$ for all $i=1,\dots,2n$. Can I infer that
$$p(x)=0$$
has only roots with positive real part?","['polynomials', 'algebra-precalculus']"
1349978,Why can we treat infinitesimals as real numbers in integration by substitution?,"During integration by substitution we normally treat infinitesimals as real numbers, though I have been made aware that they are not real numbers but merely symbolic, and yet we still can, apparently, treat them as real numbers. For instance, consider we want to integrate the expression $3x(x^4+1)^3$. A common way to do this is to let $u=x^4+1$, where $\frac{du}{dx}=4x^3$, and thus $du=4x^3dx$ which is appropriately used in our substitution to obtain $\int3x(u)^4 du$, and then we simply directly integrate this new integrand. However, while I understand the process and why we do it in such a manner, I am perplexed as to why we can still rigorously treat the infinitesimals as real numbers. So, my question is if anyone can elaborate on exactly why it is logically rigorous to treat infinitesimals as real numbers during substitution for integration. (Note: My question does not concern as to what ""dx"" means in integration simply because my question is defined in the prospect of treating infinitesimal derivatives as ratios specifically in integration by substitution, where other questions do not specifically address. )","['calculus', 'integration']"
1349999,"Is it true that $\sin x > \frac x{\sqrt {x^2+1}} , \forall x \in (0, \frac {\pi}2)$?","Is it true that $$\sin x > \dfrac x{\sqrt {x^2+1}} , \forall x \in \left(0, \dfrac {\pi}2\right)$$  (I tried differentiating , but it's not coming , please help)","['inequality', 'real-analysis', 'trigonometry']"
1350001,Help with Definite integral question,"Anyone please help with this question: (a) Show that: 
\begin{align}
 \int_{0}^{a} f(x) dx = \int_{0}^{a} f(a-x) dx 
\end{align} (b) Hence show that: \begin{align} 
\int_{0}^{\frac{\pi}{4}} \frac{1-\sin(2x)}{1+\sin(2x)} dx = \int_{0}^{\frac{\pi}{4}} \tan^2{x} dx 
\end{align} And evaluate the integral. I'd done part (a) and for part (b) I tried: \begin{align}
\int_{0}^{\frac{\pi}{4}} \frac{1-\sin(2(\frac{\pi}{4} - x))}{1+\sin(2(\frac{\pi}{4} - x))}
\end{align}
\begin{align}
\int_{0}^{\frac{\pi}{4}} \frac{1-\sin\left(\frac{\pi}{2} - 2x\right)}{1+\sin \left(\frac{\pi}{2} - 2x\right)}
\end{align} Which give: \begin{align}
\int_{0}^{\frac{\pi}{4}} \frac{1-\cos(2x)}{1+\cos(2x)}
\end{align} But I was lost after that. I'm not sure if I'm on the right track... Thanks for your time. This is a H/W question from P. 173 of Arnold and Arnold. 4 Unit Mathematics. Melbourne 1993 .","['trigonometry', 'definite-integrals', 'integration']"
1350018,Two questions on the Grothendieck ring of varieties,"1) In the definition of the Grothendieck ring of varieties over a field $k$, which definition of the various notions of ""variety"" is chosen? Finite type and separated, or maybe more? 2) If $\mathbb{L}$ is the class of the affine line in the Grothendieck ring, does the class of $\mathrm{GL}_n$ equal $(\mathbb{L}^n - 1) \cdot \dotsc \cdot (\mathbb{L}^n - \mathbb{L}^{n-1})$? Somehow this should be true, but for this I would need a ""fibration relation"", which does not seem to follow from the scissor relation.","['algebraic-geometry', 'reference-request']"
1350045,Approximate a large number with perfect powers,"I'm dealing with number theory now and I have an interesting question. 
Every number can be approximated with two perfect powers, where perfect power is a number in form $$a^b$$$$a,b \geq 2, a,b \in \mathbb N $$ My question is, how close can I approximate a given number? The number is huge.... So what can be smallest interval which contains the given number and its bounds are perfect powers? Thank you!","['perfect-powers', 'number-theory']"
1350062,Why do people prefer cosine to sine when speaking of harmonic oscillation?,"In almost all of the physics textbooks I have ever read, the author will write the oscillating function as $$x(t)=\cos\left(\omega t+\phi\right)$$ My question is that,  is there any practical or historical  reason why we should prefer $\cos$ to $\sin$ here? One possible explanation I can think of is that, to trigger a harmonic oscillation movement, we usually push the mass (to the maximum displacement) from the balance point at the initial moment, for which the cosine function will be neater to use than sine ($\phi=0$). But is it really the case?","['math-history', 'physics', 'soft-question', 'trigonometry']"
1350084,Determine the number of subsets,"How many distinct subsets of a set $\text{A}$ are there, containing at least $9$ elements, where the total number of elements in set $\text{A}$ is $18$ ? I've solved it by making cases of either choosing $9$, $10$, $11$ and so on elements from the set and then adding them up, i.e, $$\sum_{r=9}^{18} \dbinom{18}{r} $$ However, the answer given in my book is $$\dfrac{1}{2} \times \dfrac{18!}{9! \cdot 9!} + 2^{17}$$ Although the numerical value of my answer and book's answer is equal, I'm interested in knowing the intended solution of the author. The term $\dfrac{1}{2} \times \dfrac{18!}{9! \cdot 9!}$ is dividing $18$ elements into two equal parts. The term $2^{17}$ is the total number of subsets of a set containing $17$ elements. But I can't connect these two things with the question. Any help will be appreciated. Thanks. P.S. If anyone is interested in knowing how I found $\displaystyle \sum_{r=9}^{18} \dbinom{18}{r} $ here is my method, Let $\text{S} = \displaystyle \sum_{r=9}^{18} \dbinom{18}{r} $ By Binomial Theorem, $2^{18} = (1+1)^{18} = \displaystyle \sum_{r=0}^{18} \dbinom{18}{r} $ $\implies 2\text{S} - \dbinom{18}{9} =2^{18} \left( \because \dbinom{18}{r} = \dbinom{18}{18-r}\right)$ and the rest follows.","['elementary-set-theory', 'alternative-proof', 'combinations', 'combinatorics', 'binomial-coefficients']"
1350094,Can we obtain $f(y+x)=y+f(x)$ from $f(x^2+f(x)^2+x)=f(x)^2+x^2+f(x)$?,"$\mathbb Z^+$ is the set of positive integers. Find all functions $f:\mathbb{Z}^+\rightarrow \mathbb{Z}^+$ such that
  $$f(m^2+f(n))=f(m)^2+n\quad(\clubsuit)$$ Let $P(x,y)$ be the assertion: $f(x^2+f(y))=f(x)^2+y \; \forall x,y \in \mathbb{Z}^+.$
$P(x,x)$ gives us $f(x^2+f(x))=f(x)^2+x$.
$P(x,x^2+f(x))$ gives us $f(x^2+f(x)^2+x)=f(x)^2+x^2+f(x)$. Can we obtain $f(y+x)=y+f(x)$ from $f(x^2+f(x)^2+x)=f(x)^2+x^2+f(x)$ ?","['functional-equations', 'functions']"
1350132,"If $B$ is a BM and $\mathcal F_t=\sigma(B_s,s\le t)$, then $(B_{s+t}-B_t)_{s\ge 0}$ is independent of $\mathcal F_t^+:=\bigcap_{s>t}\mathcal F_s$","Let $B=(B_t)_{t\ge 0}$ be a Brownian motion on a probability space $(\Omega,\mathcal A,\operatorname{P})$, i.e. $B$ is a real-valued stochastic process with $B_0=0$ almost surely $B$ has independent and stationary increments $B_t\sim\mathcal{N}_{0,\;t}$ $B$ is almost surely continuous Let $\mathbb F=(\mathcal F_t)_{t\ge 0}$ be the filtration generated by $B$ and $$\mathcal F_t^+:=\bigcap_{s>t}\mathcal F_s\;\;\;\text{for all }t\ge 0\;.$$ **Claim:**$\;$ Let $t>0$ and $$B':=(B_{s+t}-B_t)_{s\ge 0}\;.$$ Then $B'$ is independent of $\mathcal F^+_t$. Proof: $\;$ Since $B$ is almost surely right-continuous $$B_{s+t_n}-B_{t_n}\stackrel{n\to\infty}{\to}B'_s\;\;\;\text{almost surely}\tag{1}$$ for all $t_n\downarrow t$ and $s\ge 0$. And further, observing that $B'$ is a Brownian motion independent of $\mathcal F_t$, we see that $$\left(B_{s_1}',\ldots,B_{s_m}'\right)\stackrel{(1)}{=}\lim_{n\to\infty}\underbrace{\left(B_{s_1+t_n}-B_{t_n},\ldots,B_{s_m+t_n}-B_{t_n}\right)}_{=:X_n}\;\;\;\text{almost surely}\tag{2}$$  for all $s_1,\ldots,s_m\ge 0$. Again, it's easy to verify, that $$X_n\text{ is independent of }\mathcal F_{t_n}\supseteq\mathcal F_t\;\;\;\text{for all }n\in\mathbb{N}\;.$$ So, we're really close, but I don't find the right argument to conclude the independence of $\left(B_{s_1}',\ldots,B_{s_m}'\right)$ and $$\mathcal F_t^+=\bigcap_{n\in\mathbb{N}}\mathcal F_{t_n}\;.$$ So, how do I need to argue?","['probability-theory', 'measure-theory', 'stochastic-calculus', 'stochastic-processes', 'brownian-motion']"
1350143,Normal Operators: Meet,"Given a Hilbert space $\mathcal{H}$ . Normal Operators: $$\mathcal{N}(\mathcal{H}):=\{N:N^*N=NN^*\}$$ Borel Calculus: $$\mathcal{B}(N):=\{\eta({N}):\eta\in\mathcal{B}(\mathbb{C},\mathbb{C})\}$$ Commutativity: $$N_\pm\in\mathcal{N}(\mathcal{H}):\quad N_+N_-=N_-N_+$$ Borel Calculus: $$\mathcal{B}(N_+)\subseteq\mathcal{B}(N_-)\lor\mathcal{B}(N_-)\subseteq\mathcal{B}(N_+)$$ Meet Operator: $$N_+\wedge N_-\in\mathcal{N}(\mathcal{H}):\quad\mathcal{B}(N_\pm)\subseteq\mathcal{B}(N_+\wedge N_-)$$ (Symbolic Meet!)","['hilbert-spaces', 'operator-theory', 'functional-analysis']"
1350147,Is there a unique preferred connection on a general manifold?,"I was wondering whether, for a given finite-dimensional manifold, the connection $\nabla$ exists and is uniquely defined? Afais for Riemannian manifolds, there exists always exactly one Levi-Civita connection, but the calculation is rather cumbersome. Now, if we consider manifolds without a metric, is there still always one connection (now we do not require torsion-freeness and compatibility with the metric, of course)?","['differential-topology', 'differential-geometry', 'manifolds', 'connections']"
1350150,Example where partial derivatives commute but are not continuous.,"I am looking for an example of a function $f:\mathbb R^2\to\mathbb R$ such that there is a point $x\in\mathbb R^2$ with the following properties: 1) All partial derivatives of second order exist in a neighborhood of $x$. 2) At least one of those partial derivatives is not continuous in $x$. 3) The Hessian matrix of $f$ in $x$ is symmetric. I think it should be possible to find such a function but I wasn't very successful in finding one. If we drop the first property it is easy, with it however, I didn't find any example yet. Any help appreciated.","['partial-derivative', 'multivariable-calculus', 'real-analysis', 'derivatives']"
1350189,Why are the two limits equal?,"I want to show that if $g$ is continuous at $a$ and $f$ at $g(a)$, then
$$\lim_{x \to a}{\frac{f(g(x))-f(g(a))}{g(x)-g(a)}} = \lim_{x \to g(a)}{\frac{f(x)-f(g(a))}{x-g(a)}}$$
Now I know that continuity implies that 
$$\lim_{x \to a}{f(g(x))} = \lim_{x \to g(a)}{f(x)} = f(g(a))$$
and
$$\lim_{x \to a}{g(x)} = \lim_{x \to g(a)}{x} = g(a)$$
so it is quite easy to see that the two original limits are equal. How do I prove this? I cannot repeatedly use the limit laws since I get a limit that is zero ($\lim_{x \to a}{(g(x)-g(a))}$) and so cannot apply the quotient rule.","['calculus', 'limits']"
1350205,A confusion in a calculation with complex numbers,"Consider the followings:
$$
1+e^{ix}+e^{2ix}+e^{3ix}= \dfrac{1-e^{4ix}}{1-e^{ix}}
$$
Then, we take absolute square to the both sides
$$
|1+e^{ix}+e^{2ix}+e^{3ix}|^{2}= \dfrac{1-\cos4x}{1-\cos x}
$$
When we put $x=0$, the left side is $|1+1+1+1|^2=16$, but the right side is ill-defined ($0/0$)
It's really confused to me. What's happened? Thanks in advanced. Thanks for everyone's quick response.
I think the absolute square of right side is correct. $|\dfrac{A}{B}|^{2}=\dfrac{A^*A}{B^*B}$ Consider the right side:
$$
\dfrac{1-e^{4ix}}{1-e^{ix}}=\dfrac{(1-e^{4ix})(1-e^{-4ix})}{(1-e^{ix})(1-e^{-ix})}=\dfrac{1+1-(e^{4ix}+e^{-4ix})}{1+1-(e^{ix}+e^{-ix})}= \dfrac{2-2\cos4x}{2-2\cos x}
$$ I found that my problem is due to the carelessness on the limitation of formula $1+x+...+x^{N-1}=\dfrac{1-x^{N}}{1-x}$, which is valid for x$\neq$1 Thanks","['complex-numbers', 'real-analysis', 'algebra-precalculus', 'trigonometry']"
1350212,Scaling a svg image while keeping the offset position.,"I have an svg image of a map that i have to scale up to make it zoom in. Javascript has a function to scale up SVG images. However the svg scale function uses the upper left corner as center when zooming. So to counter this the usual trick is to shift the svg 50% to the left and 50% up so that the center moves to the upper left corner. Then scale the image and again move the image back. Edit: I think this article might say what i need to do but i do not know enought about matrices: http://www.cs.rit.edu/~icss571/clipTrans/2DTransBack.html#BACK3.0 Edit3: Here is some more information about the problem: http://commons.oreilly.com/wiki/index.php/SVG_Essentials/Transforming_the_Coordinate_System#svgess-CHP-5-FIG-9 The logic behind it looks like this. var bbox = mapGroup.getBBox(); // the element of the svg image i want to scale up/down.
// finding center of element
var cx = bbox.x + (bbox.width/2); // x is the offset of the element horizontally
var cy = bbox.y + (bbox.height/2);  // y is the offset of the element vertically

// Shift the image so that the middle is in the upper left corner taking into account the amout of scaling;
mapGroup.attr('transform', 'translate(-' +(cx-(scale*cx)) + ', -' + (cy-(scale*cy)) + ')');
// scale the image
mapScaleGroup.attr('transform', 'scale('+ scale +')');
// Shift the image back again
mapGroup.attr('transform', 'translate(' + (cx-(scale*cx)) + ', ' + (cy-(scale*cy)) + ')'); This Works perfectly when i only want to hit the center of the image, however i have added a drag functionality that causes the offset to change. This causes problems as you can see here: http://nho-municipality-map.divshot.io/ Zoom to see how it should be or drag the map and then zoom to see the mistake. So I think the key to the problem lies ether in this part: cx = bbox.x + (bbox.width/2) or this part (cx-(scale*cx)) How do i take the custom offset into account? Edit2: Here is all the information i get from the bbox.",['matrices']
1350218,Differentiate expression involving reciprocal of square roots.,I need to differentiate $$5\over 2+\sqrt{1+3x}$$ I can get the answer from Wolfram Alpha but I'm trying to understand the working. Do I use the chain rule? My calculus is at the basic level.,"['calculus', 'derivatives']"
1350264,What does holomorphic at the cusp infinity means,"In the usual theory of classical modular forms, the modular forms defined to be ""holomorphic at the cusp infinity"". I do not know what this should mean? can anyone explain it for me? Thanks","['modular-forms', 'complex-analysis']"
1350265,"Calulating the Ramsey number $R(T, K_{1,n})$ of a tree $T$ and bipartite graph $K_{1,n}$","Let $m,n \ge 2$ be such that $m-1$ is a divisor of $n-1$. Let $T$ be a tree with $m$ vertices. Calculate the Ramsey number $R(T,K_{1,n})$. Thoughts :
I'm having trouble approaching this question. I think the detail about the divisibility is somehow related to the fact that $n-1$ is the number of nodes on one side of the bipartite graph. $m-1$ is the number of nodes in a tree excluding some defined ""root"". I'd love some ideas on what to consider and how to approach such a question. My main problem is that I don't know what to do with the info about divisibility and forms of the two possible subgraphs. I'm wondering if there is some way to connect this to Chvátal's Theorem on $R(T,K_n)$.","['graph-theory', 'ramsey-theory', 'discrete-mathematics']"
1350270,What did I do wrong?,"So, I have found the following problem. This problem is a multiple-choice one, and I have to pick the correct answer. The problem, gives a function $f:D \to R$, $$f(x)=\frac{xe^x}{e^x-a}$$ with $a$ being a real number. I have managed to proof that if $a \in (0,1)$, the function is strictly increasing. I will describe how. If $a \in (0,1)$, the function is well defiend for all real numbers, except $\ln{a}$. The derivate is:
$$f'(x)=e^x\frac{e^x-a-ax}{(e^x-a)^2}$$ To study its sign we only need to study the sign of $g(x) = e^x-a-ax$. Since $$g'(x)=e^x-a$$ I have found that $g(x)>0$, and $x_0=-a\ln{a}$ it's a minimum point. It follows that $f'(x)>0$, and hence f is strictly increasing. So, what's the mistake in my reasoning..?","['calculus', 'derivatives']"
1350296,How can $f(x)=x^4$ have a global minimum at $x=0$ but $f''(0)=0$?,"$f(x)=x^4$ has a global minimum in $\Bbb R$ at the point $x=0$, but $f''(0)=0$. This case confuses me. For every $0\neq x\in I$, $f(x)>f(0)$. So how can it be that $f''(0)=0$, following $f'(x)$ doesn't change its sign at $x=0$?
I could accept it if there was a little segment $I$ around $x=0$ fulfilling $f(x)=0$ for every $x\in I$. But I don't see why that can be the case, since, again, $x=0$ is the only $x$ fulfilling $f(x)=0$. This contradicts my logic. Can someone help me understand how this is possible?",['algebra-precalculus']
1350393,Distance between point and plane - why use the dot product?,"So according to this , the signed distance between a point and a plane will be the dot product of the plane's normal vector (does it have to be a unit vector?) and the point-in-plane minus the point vector. I searched everywhere and I can't find a good explanation on why does the dot product give the correct answer. I even studied a little bit more about the dot product itself and I came to know that the dot product of a * b is like multiplying the magnitudes of the vectors that go on the same direction . This still doesn't help me understand my problem. If it matters, I encountered this problem as a programmer.","['vector-spaces', 'linear-algebra', 'vectors']"
1350411,"Prove that $X,Y$ are independent iff the characteristic function of $(X,Y)$ equals the product of the characteristic functions of $X$ and $Y$","Let $(\Omega,\mathcal A,\operatorname P)$ be a probability space $X$ and $Y$ be random variables on $(\Omega,\mathcal A,\operatorname P)$ with values in $\mathbb{R}^m$ and $\mathbb{R}^n$, respectively $\varphi_Z$ denote the characteristic function of a random variable $Z$ Claim : $\;$ $X$ and $Y$ are independent iff $$\varphi_{(X,Y)}(s,t)=\varphi_X(s)\varphi_Y(t)\;\;\;\text{for all }s\in\mathbb{R}^m\;\text{and}\;t\in\mathbb{R}^n\tag{1}$$ Proof : $\;$ ""$\Rightarrow$"": Let $Z:=(X,Y)$ and $u:=(s,t)\in\mathbb{R}^m\times\mathbb{R}^n$ $X$ and $Y$ are independent $\Rightarrow$ $e^{i\langle s,\;\cdot\;\rangle}\circ X$ and $e^{i\langle t,\;\cdot\;\rangle}\circ Y$ are independent $\Rightarrow $ \begin{equation}
\begin{split}
\varphi_Z(u)&\stackrel{\text{def}}{=}\operatorname E\left[e^{i\langle u,Z\rangle}\right]\\
&=\operatorname E\left[e^{i\langle s,X\rangle+i\langle t,Y\rangle}\right]\\
&=\operatorname E\left[e^{i\langle s,X\rangle}e^{i\langle t,Y\rangle}\right]\\
&=\operatorname E\left[e^{i\langle s,X\rangle}\right]\operatorname E\left[e^{i\langle t,Y\rangle}\right]\\
&\stackrel{\text{def}}{=}\varphi_X(s)\varphi_Y(t)
\end{split}
\end{equation} ""$\Leftarrow$"": Let $\tilde X\sim X$ and $\tilde Y\sim Y$ be independent Since a finite measure on $\mathbb{R}^d$ is uniquely determined by its characteristic function, $$\varphi_X=\varphi_{\tilde X}\;\;\;\text{and}\;\;\;\varphi_Y=\varphi_{\tilde Y}\tag{2}$$ Thus, \begin{equation}
\begin{split}
\varphi_{(X,Y)}(s,t)&\stackrel{(1)}{=}\varphi_X(s)\varphi_Y(t)\\
&\stackrel{(2)}{=}\varphi_{\tilde X}(s)\varphi_{\tilde Y}(t)\\
&=\varphi_{(\tilde X,\tilde Y)}(s,t)
\end{split}
\end{equation} by ""$\Rightarrow$"" Again, since the distribution of $(X,Y)$  is uniquely determined by $\varphi_{(X,Y)}$, we've got $$(X,Y)\sim (\tilde X,\tilde Y)$$ Especially, $Z:=(X,Y)$ and $\tilde Z:=(\tilde X,\tilde Y)$ have the same distribution function $F$ Now, I got stuck. From the definition of $F$ and the definition of independence, it seems to be obvious, that we can conclude the independence of $X$ and $Y$. However, how do we need to argue in detail?","['probability-theory', 'characteristic-functions', 'measure-theory']"
1350412,"Show that in any triangle, we have $\frac{a\sin A+b\sin B+c\sin C}{a\cos A+b\cos B+c\cos C}=R\left(\frac{a^2+b^2+c^2}{abc}\right),$","Show that in any triangle, we have $$\frac{a\sin A+b\sin B+c\sin C}{a\cos A+b\cos B+c\cos C}=R\left(\frac{a^2+b^2+c^2}{abc}\right),$$
where $R$ is the circumradius of the triangle. Here is my work: We know that $A+B+C=180^\circ$, so $C=180^\circ -(A+B)$. Plugging this in, we get that $\sin C=\sin (A+B)$ and $\cos C = -\cos (A+B)$. When we plug this into the equation we get, $$\frac{a\sin A+b\sin B+c\sin (A+B)}{a\cos A+b\cos B-c\cos (A+B)}.$$ If we expand out $c\sin (A+B)$ and $c\cos (A+B)$, we get $$\frac{\sin A+b \sin B+c \cos A\cos B - c\sin A\sin B}{a\cos A+b\cos B-c\cos A\cos B+c\sin A\sin B}.$$ Using the Extended Law of Sines, we can use $\sin A=\frac{a}{2R}$, $\sin B=\frac{b}{2R}$, and $\sin C=\frac{c}{2R}$. How can I continue on?","['plane-geometry', 'algebra-precalculus', 'geometry', 'triangles', 'trigonometry']"
1350424,Arithmetic and Geometric Progression Question 1,"Problem: The second, third and sixth terms of an arithmetic progression are consecutive terms of a geometric progression. Find the common ratio of the geometric progression. My attempt: I thought of rewriting the terms as $a+d,a+2d,a+5d$ where $a$ is the first term and $d$ is the common difference. Now, since these are consecutive terms of a GP, $$\Longrightarrow \dfrac{a+2d}{a+d}=\dfrac{a+5d}{a+2d}=r$$ where $r$ is the common ratio. However, when I cross-multiplied the terms $\dfrac{a+2d}{a+d}=\dfrac{a+5d}{a+2d},$ I got $$a^2+4ad+4d^2=a^2+6ad+5d^2$$ I'm unable to proceed any further. Any help would be really appreciated. Many thanks!","['arithmetic-progressions', 'algebra-precalculus']"
1350426,Assumptions on functions so that integral is zero,"Let $f:\mathbb{R}\to\mathbb{R}$ and $g:\mathbb{R}\to\mathbb{R}$ be two arbitrary functions. Assume $g\in L^2(\mathbb{R})$. I'm looking to find out the minimal set of assumptions on $f$ and $g$ such that the following integral is zero, for every $x\in\mathbb{R}$: $$ \int_\mathbb{R}\frac{f(x)-f(y)}{x-y}g(y)dy = 0 $$ Here is what I came up with so far: Let $x\in\mathbb{R}$ be given. Write $$ \int_\mathbb{R}\frac{f(x)-f(y)}{x-y}g(y)dy = \lim_{\varepsilon\to0} \int_{\mathbb{R}\backslash B_\varepsilon(x)}\frac{f(x)-f(y)}{x-y}g(y)dy +\lim_{\varepsilon\to0} \int_{B_\varepsilon(x)}\frac{f(x)-f(y)}{x-y}g(y)dy$$ The first summand is equal to Cauchy's principal value, and is proportional to the delta distribution, in case $z\mapsto\left[f(x)-f(z)\right]g(z)$ is holomorphic and goes to zero as $|z|$ goes to infinity. Thus, the delta distribution evaluates this function to zero. For the second summand, assume $f$ is analytic and write $f(y)\approx f(x)+f'(x)(y-x)+\mathcal{O}((y-x)^2)$. We find then \begin{eqnarray} 
\int_\mathbb{R}\frac{f(x)-f(y)}{x-y}g(y)dy &=& \lim_{\varepsilon\to0} \int_{B_\varepsilon(x)}\frac{f(x)-f(y)}{x-y}g(y)dy       \\
  &=& \lim_{\varepsilon\to0} \int_{B_\varepsilon(x)}\left[f'(x)+\mathcal{O}((y-x)^2)\right]g(y)dy \nonumber \\
  &=&f'(x)\lim_{\varepsilon\to0} \int_{B_\varepsilon(x)}g(y)dy+\lim_{\varepsilon\to0} \int_{B_\varepsilon(x)}\mathcal{O}((y-x)^2)g(y)dy    \nonumber \\
&=& 0
\end{eqnarray} Thus, my question is: 1) Is it true that the minimal requirements are that $f$ and $g$ be holomorphic and $z\mapsto\left[f(x)-f(z)\right]g(z)$ goes to zero as $|z|$ goes to infinity? 2) If this is the case, is the proof so far correct?","['proof-verification', 'contour-integration', 'integration', 'analysis', 'complex-analysis']"
1350437,"Guessing the length of a playlist on ""shuffle random?""","The other night I was hanging out with some friends and someone put on a playlist on shuffle random, where the songs are drawn uniformly at random from a fixed playlist. The person who put the playlist together forgot how many songs were in it, so the topic came up of how to estimate the size of the playlist purely based on what we hearing. We came up with a few high-level ideas for how to do this. For example, using ideas from the Birthday Paradox, we thought we could listen until we heard a song repeated for the first time, then use that to make an educated guess about how many songs were on the playlist in total. We also thought that we could listen for a long time and build up a frequency histogram of the number of times each song was played, then use the fact that it should look somewhat normally distributed to get the mean and variance and from there estimate the total number of songs on the list. None of us are statisticians or have a lot of training in machine learning, but I suspect that this is probably a well-studied problem and that there are some really nice techniques we can use to estimate the playlist size. Are there a good family of techniques for estimating the playlist size? From a practical perspective, would any of these techniques be something that would be relatively easy to work out without a computer or calculator? Thanks!","['birthday', 'statistics', 'recreational-mathematics']"
1350441,"What primes were ""pending"" at the time of Wiles's proof of FLT?",I would like to know what instances of Fermat's Last Theorem were pending at the time of Wiles's proof. More specifically: what families of irregular primes had been discarded as possible counterexamples at the time of Wiles's proof? Was any parallel progress made between the announcement and the publication of the proof?,"['math-history', 'number-theory']"
1350456,Probability a blackjack dealer will bust if you know their score and know the exact deck?,"If you know the exact cards left in a deck, and the score of the dealer, how can you calculate the exact probability that they will bust? The dealer behaves as follows: If the dealer's score is less than 16, the dealer will ""hit"" and take another card. If the dealer has over 17 (even a ""soft"" score of 17 or greater with an ace and another 6 points from the other cards) the dealer will stay. And just for clarification, in the game of blackjack an Ace can count either as 11 points or 1 point, so if the score with 11 points is still under 21, it is called a ""soft"" hand, meaning if the next card would put you over 21, the ace can be counted as 1 point instead. I am able to calculate the probability of busting on the first hit as follows: $$
P(\text{busts on hit } | \text{ current score, deck}) = {(\text{# cards in deck where card + score} \gt 21) \over \text{total cards in deck}}
$$ The issue I am running into is the recursive part, where the dealer must continue to hit if their score is less than 16. For instance, if the dealer has a score of 13 to start, they could hit and receive an ace, a 2 or a 3 and they would have to hit again. So the total probability of busting on the first or second hit would be something like: $$
P(\text{busts on first or second hit } | \text { current score, deck}) \\= P(\text{busting on first hit}) + P(\text{less than 16 on first hit and busting on second}) \\
= {(\text{# cards in deck where card + score} \gt 21) \over \text{total cards in deck}} \\ + \sum\limits_x P(\text{getting score of x on hit}) \times P(\text{busting on next hit with score of x})
$$ The problem seems to get even hairier when you consider that the dealer might receive several cards and still have less than 16, albeit with a low probability for most deck compositions. Is there an elegant (or at least less awful) way to express/calculate this recursive term in this problem?","['probability', 'card-games', 'combinatorics']"
1350488,Jacobi field strange condition.,"I am currently reading a textbook (Kuehnel) saying that if $V,W \in T_pM$ are such that $\langle V,W \rangle =0$ and $\|V\|=\|W\|=1,$ then 
$Y(t):=D \exp(tV)(tW)$ is a Jacobi field. The thing is, I don't understand why this textbook has all these conditions on $V,W$? Isn't it true that this also holds if we have any $V,W \in T_pM,$ cause all we should need is a variation of geodesics.","['riemannian-geometry', 'real-analysis', 'manifolds', 'analysis', 'differential-geometry']"
1350594,Non linear second order ODE,"I really need help solving this : $$y_{xx}-\left(y^{3}-y\right)-\varepsilon\frac{1}{2}\left(1-y^{2}\right)=0
  $$
With boundary conditions :
$$ y(\pm \infty  )=-1 $$ I need to find a solution that is accurate up to $O(\epsilon)$
i all so know that
$$ y^{(k)}(\pm \infty) = 0\;\;\;\;\; for\; \; k>0 $$
Thanks alot! Please note that holding boundary condition is not easy and very important, 
the answer given below is a great effort but unfortunatly it is not a good answer.
any help would be great!","['asymptotics', 'nonlinear-system', 'ordinary-differential-equations', 'perturbation-theory']"
1350599,Essential supremum via cumulant,"Let $p(t)=\log \mathbb{E}[\exp (tX)]$ for $X$ real valued random variable. Now it holds (assuming that $p$ is smooth and finite on $\mathbb{R}$) that $p'(\infty)=\text{ess}\sup X$.
How can I prove that? For step functions it is easy, but how can I (by simple methods) show that it holds for all random variables?","['probability-theory', 'probability-limit-theorems', 'probability-distributions', 'functional-analysis']"
1350635,When do I use a z-score vs a t-score for confidence intervals?,"I have a set of 1000 data points.  I would like to estimate their mean using a confidence interval.  I read somewhere that if the sample size, $n$, is bigger than 30 you should use a t-score, and else use a z-score. Is that true?",['statistics']
1350640,How to use Cross Product Properites to do proof,"How do I proceed with a proof for this question? Prove that:
\begin{equation}
       (a \times  b) \cdot (c \times d)  =  \begin{vmatrix}
    a \cdot c & b \cdot c \\
    a \cdot d & b \cdot d \\
    \end{vmatrix} 
\end{equation}
I have to use the cross product properties to do the proof: So far I have taken the det of the right side: \begin{equation}
(a \times b) \cdot (c \times d) = (a \cdot c) \cdot (b\cdot d) - (b \cdot c)(a \cdot d) 
\end{equation} I don't understand how to use the properities after this step.","['vectors', 'multivariable-calculus', 'proof-writing']"
1350657,"Does the concept of ""cograph of a function"" have natural generalisations / extensions?","First, definitions: The graph of a function $f : A \to B$ is a subset of $A \times B$, namely the set $\{(x,y) : x \in A, y \in B, f(x) = y\}$. The cograph of a function $f : A \to B$ is the quotient of $A \sqcup B$ by the equivalence relation that identifies $x$ with $f(x)$ for all $x$ (and so basically identifies each element of the codomain with its entire preimage under $f$). These are categorical duals, in the sense that the graph is the pullback of $f$ along the identity, and the cograph is the pushout of $f$ along the identity. From either the graph or cograph of a function, the original function can be recovered. We can even precisely specify the condition on a subset of $A \times B$ to be a graph of a function, or on a quotient of $A \sqcup B$ to be a cograph. If we relax that condition on graphs, we get something else interesting, with a rich theory behind it: general relations between $A$ and $B$, including partial functions or multi-valued functions and many other things besides, with various possible properties, of which being ""functional"" is only one. If we relax the condition on cographs, I can't as easily see what we get out of it. General quotients of $A \sqcup B$ can represent some relations between $A$ and $B$, but e.g. can't do multivalued functions in full generality, and the treatment of partial functions is less natural (e.g. suppose a partial $f$ is not defined at either $x$ or $y$, should we identify $x$ and $y$ in the quotient?). So, I can't see that the cograph has as many ""places to go"" as the graph does, it doesn't seem to expose as many characterisations, variations, or generalisations of the concept of a function. Is there some useful perspective I'm missing here, or is the cograph just not as important mathematically as the graph is?","['category-theory', 'functions']"
1350670,Differential topology versus differential geometry,"I have just finished my undergraduate studies. During last two semesters I've taken two subjects dealing with manifolds: Analysis on manifolds, containing: definition of manifold, tangent space (as derivations and classes of curves), vector fields, vector bundles, flows, Lie derivatives, integration on manifolds (Stokes theorem), forms, Hodge decomposition theorem Introduction to differential geometry (for me it should be called introduction to Riemannian manifolds) containing: tensor calculus introduction, Riemannian manifold definition, connections, curvatures, geodesic, normal coordinates, geodesic completeness theorem, classification through curvature, Jacobi fields, harmonic maps. Now, for me differential geometry was/is a theory about manifolds, so anything dealing with manifolds is a branch of differential geometry. On the other hand, I am preparing for taking part in local conference called ""algebraic and differential topology"".  I have read: I- books references , II-  books references , III- wikipedia , yet I still don't really know if differential topology is subtheory of differential geometry or is it separate theory and how is it located between differential geometry and algebraic topology. For example I expect that studies on Riemannian manifolds are part of differential geometry but would problem of classification manifolds up to diffeomorphism be a part of differential topology or geometry? Request : I would be grateful for your characterisation of differential topology and differential geometry possibly with examples of problems, theorems present at them.","['differential-topology', 'differential-geometry', 'soft-question']"
1350672,Why is this set of polynomials linearly dependent?,"$$1 + 2t+ t^2, 3-9t^2,1 + 4t + 5t^2$$ (A) Linearly dependent       or        (B) Linearly independent The answer is A from the answer key. This is a test review. I don't see that either polynomial is a scalar multiple of any of the other polynomials.  How can I test for linear dep|indep with polynomials?  If these were vectors I would just put them in a matrix and row reduce (or if a square matrix, check the determinant), but I'm not sure what to do here.",['linear-algebra']
1350673,Example of Non-separable stochastic process.,This question is related to the link: https://www.encyclopediaofmath.org/index.php/Separable_process The link provided a basic definition of separable Stochastic process. I felt all the process under study seems to be separable. Is it true? Is there any example of  Non-separable stochastic process which is of some importance?,"['probability-theory', 'real-analysis', 'functional-analysis', 'soft-question']"
1350703,Find the value of $x$ such that $\sqrt{4+\sqrt{4-\sqrt{4+\sqrt{4-x}}}}=x$,"Find the value of $x$, $$\sqrt{4+\sqrt{4-\sqrt{4+\sqrt{4-x}}}}=x$$ Help guys please, I have tried and I got, $x=-2, x=1$, and I think it's wrong","['nested-radicals', 'systems-of-equations', 'number-theory', 'complex-numbers']"
