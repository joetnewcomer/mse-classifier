question_id,title,body,tags
4562783,How many ways we can distribute 10 distinct objects among 4 persons such that each person gets at most 9 objects?,"Given the question: ""How many ways we can distribute $10$ distinct objects among $4$ persons such that each person gets at most $9$ objects?"" The correct answer given is $4^{10} -4$ . We have subtracted the 4 cases in which each person gets all 10 objects. Can't the answer be $10 \cdot 4^9$ ? We have ${10 \choose 1}$ ways of selecting an object. We remove that object and now each object has $9$ choices. So each object can now get at most $9$ objects only.","['combinations', 'combinatorics', 'discrete-mathematics']"
4562847,Curiosities of the function $Q(x)=\sum_{n=1}^\infty \frac{P_n(x)}{n(2n+1)}$ where $P_n(x)$ is a sequence of all polynomials with unit coefficients,"Backround: I have been studying the peculiar function $$Q(x)=\sum_{n=1}^\infty \frac{P_n(x)}{n(2n+1)}$$ where $P_n(x)$ is the set of all polynomials with unit coefficients, defined by the binary expansion of $n$ . For example $$n=57=\color{red}{111001}_2\iff P_n(x)=\color{red}{1}x^5+\color{red}{1}x^4+\color{red}{1}x^3+\color{red}{0}x^2+\color{red}{0}x^1+\color{red}{1}x^0.$$ Some properties: This function seems intimately tied with the Euler-Mascheroni constant $\gamma$ , $\pi$ , and the natural logarithm. For instance, with some algebraic manipulation of some of the ""easier"" values of $n$ , we can find that $$Q(0)=\sum_{n=0}^\infty \frac{1}{(2n+1)(2(2n+1)+1)}=\frac{1}{4}(\pi-\ln(4)),$$ as calculated by WolframAlpha , and $$Q(1)=\sum_{n=1}^\infty\frac{H(n)}{n(2n+1)}=\ln\left(\frac{4}{\pi}\right)+\gamma,$$ where $H(n)$ is the Hamming weight of the binary expansion of $n$ , proven by combining some of the series expansions of $\gamma$ . Questions: Some questions arose while playing around with this function. Can we find other ""interesting values"" of $Q$ , for $Q(-1)$ , $Q(2)$ , $Q\left(\frac{1}{2}\right)$ , for example? Can we find a closed form of $Q$ , in terms of other elementary / transcendental functions? Or at the very least, the coefficients of its power series? My work on its power series: When it comes to its power series $$Q(x)=\sum_{n=0}^\infty c_n x^n,$$ using properties of binary, we can deduce that. $$c_n = \sum_{k=0}^\infty \sum_{m = 2^n} ^ {2^{n + 1} - 1} \frac{1}{(2^{n + 1} k + m)(2(2^{n + 1} k + m) + 1)}.$$ Plugging in values of $n=0,1,2$ into WolframAlpha, we find that $$c_0 = \frac{1}{4}(\pi-2\ln(2))\approx 0\approx 0.43883,$$ $$c_1 = \frac{1}{8}(\pi (2\sqrt{2}-1) - 6\ln 2)\approx 0.19816,$$ $$c_2 = \frac{1}{16}\left(\frac{\pi\left(-6-5\sqrt{2}+8\sqrt{2+\sqrt{2}}+4\sqrt{2(2+\sqrt{2})}\right)}{2+\sqrt{2}}-14\ln(2)\right)\approx 0.09301.$$ However I'm not sure what methods it used to calculate such, and if they can be used to generalize a closed form for any $c_n$ . At the very least, my pattern recognition sees that $c_n$ is of the form $2^{-(n+2)}(A_n\pi - B_n \ln 2)$ , with $A_n$ an algebraic number and $B_n$ a natural number. Any and all insight would be greatly appreciated.","['euler-mascheroni-constant', 'closed-form', 'polynomials', 'sequences-and-series', 'power-series']"
4562911,Difference integral of continuous function,"Let $f:\mathbb R\rightarrow \mathbb R$ be a continuous function such that $$\lim_{t\rightarrow -\infty}f(t)=l_1,\hspace{0.4cm} \lim_{t\rightarrow +\infty}f(t)=l_2$$ Evaluate $$\int_{-\infty}^{+\infty}\left[f(t+1)-f(t)\right]dt$$ I thought of variable change : We have $$\int_{-\infty}^{+\infty}f(t+1)dt-\int_{-\infty}^{+\infty}f(t)dt$$ By substituting $u=t+1$ in the first integral, we obtain $$\int_{-\infty}^{+\infty}f(u)du-\int_{-\infty}^{+\infty}f(t)dt$$ My mind says it's the same integral so it must be equal to $0$ . But we still have no idea about the convergence of the integrals. I tried also to parametrize the integral : Let $$I(\alpha)=\int_{-\infty}^{+\infty}t^\alpha f(t)dt$$ Which in the end will lead to $I(0)-I(0)=0$ But here I still hesitate whether I defined $I$ as a diverging function","['integration', 'limits', 'convergence-divergence']"
4562925,For what $k$ does $\sin(x)$ hit $kx$ 9 times,"I saw this problem online and I am pretty stuck with it, here is the problem For what $k$ does $kx$ intersect $\sin(x)$ exactly 9 times? My first thought when looking at this problem was to divide out the $x$ . I would then be left with $\sin(x)/x=k$ I then tried to find some clever limit or derivative to get the answer, but I am stuck. I assume there is some clever calculus I can do to get this answer, but I can't find it. Thanks!","['calculus', 'trigonometry']"
4562945,Is any Euclidean ball contained in D some pseudo-hyperbolic ball?,"We have that the pseudo-hyperbolic distance in the open unit disk $\mathbb D$ is defined by $$ \rho(z,w) = |\phi_w(z)|,  \qquad \phi_w(z) = \frac{w - z}{1 - \overline w z}$$ where $z,w \in \mathbb D.$ And the pseudo-hyperbolic ball is defined by $$ \Delta(p,r) = \{z \in \mathbb{D} | \rho(p,z)<r\}, \quad 0<r<1.$$ There is a proposition which says that for any $p\in\mathbb{D}$ and $0<r<1$ , the pseudo-hyperbolic ball is a Euclidean ball with center and radius given by $$P = \frac{1-r^2}{1-r^2|p|^2}p, \quad R = \frac{1-|p|^2}{1-r^2|p|^2}r,$$ i.e. $\Delta(p,r) = B(P,R).$ Composition Operators and Classical Function Theory says that The pseudo-hyperbolic distance induces the usual Euclidean topology. and I'd like to prove it. By the proposition mentioned above, it's clear that the topology induced by pseudo-hyperbolic distance is contained in the Euclidean topology. However, when I want to prove the inverse relation, I have no idea but to prove that ""any Euclidean ball contained in $\mathbb{D}$ is also some pseudo-hyperbolic ball"", which means that for any given $P \in \mathbb{D}, 0<R<1, B(P,R) \subset \mathbb{D}, \exists p \in \mathbb{D}$ and $0<r<1$ , s.t $$P = \frac{1-r^2}{1-r^2|p|^2}p, \quad R = \frac{1-|p|^2}{1-r^2|p|^2}r$$ holds. But I don't know how to prove it. My questions are: Is my assumption above right? If not, how can I prove ""The pseudo-hyperbolic distance induces the usual Euclidean topology""?","['complex-analysis', 'metric-spaces']"
4562952,"Given $d$, how many values of $n$ should I test to get a square of form ${2n^2+d}$","Given $d$ , how many values of $n$ should I test to get a square of the form ${2n^2+d}$ Both $d$ and $n$ are a positive integers. There must also be some periodicity in $n$ to jump from the first square to the second square and so on. Basically I am looking to find that series of $n$ for which ${2n^2+d}$ is a square. My testing so far has shown that for some values of $d$ there is no $n$ at all which can generate a square.","['number-theory', 'pell-type-equations', 'elementary-number-theory']"
4562967,Binomial transform of fibonacci sequence is negated fibonacci sequence proof,"I'm trying to prove that the following relation holds $$
\sum_{j=0}^n \binom{n}{j}(-1)^j F_j = -F_n
$$ Where $F_i$ denotes the $i$ -th finonacci number. I'm currently trying an induction argument but I get stuck at $$
\sum_{j=0}^n \binom{n}{j}(-1)^j F_j = (-1)^n F_n + \sum_{j=0}^{n-1} \binom{n}{j}(-1)^j F_j = (-1)^n F_n + \sum_{j=0}^{n-1} \binom{n}{j}(-1)^j F_{j-1} + \sum_{j=0}^{n-1} \binom{n}{j}(-1)^j F_{j-2} = 
$$ $$
= (-1)^n F_n + \sum_{j=0}^{n-1} \binom{n-1}{j}\frac{n}{n-j}(-1)^j F_{j-1} + \sum_{j=0}^{n-1} \binom{n}{j}\frac{n}{n-j}(-1)^j F_{j-2}
$$ I would like to find a way to apply the induction hypothesis on the expresion above but the term $n/(n-j)$ makes it difficult because it depends on $j$ so I can't get it out of the sum. I already know how to prove this relation using generating functions, but currently I need to solve the problem using induction. Thanks in advance for the help.","['fibonacci-numbers', 'binomial-coefficients', 'combinatorics', 'discrete-mathematics']"
4562981,Complex differential forms and their integrals,"Recently, I was reading the book of J.M. Lee Introduction to smooth manifolds , more precisely, chapters 12, 14, 16 where (covariant) tensor fields on smooth manifolds, differential forms and finally integrals of differential forms were defined. While reading I thought about line integrals from classical analysis, in other words, integrals $\int_{\gamma} f(z)\,\mathrm{d}z$ , where $\gamma$ is a smooth curve in complex plane.
Here, $f(z)\,\mathrm{d}z$ can be viewed as ""holomorphic 1-form"". S o, I was wondering whether one can generalize notion of integral for ""holomorphic $n$ -forms"", e.g., forms on complex $n$ -manifold having a local formula $f(z)\,\mathrm{d}z_1 \wedge\mathrm{d}z_2\wedge\dots\wedge\mathrm{d}z_n$ for $f$ complex-valued holomorphic map? This is not obvious for me, at least approach in the book I mentioned can not be generalized directly, for instance, because it uses smooth partitions of unity, while we can't expect analytic ones exist (however, this is not the only case that in my opinion can not be generalized directly).","['complex-geometry', 'complex-integration', 'differential-forms', 'differential-geometry']"
4563057,What are the quaternion algebras over $\mathbb{F}$ for a field $\mathbb{F}$?,I know that the only quaternion algebras over $\mathbb{R}$ are the quaternions and the split-quaternions. What is the characterization of the quaternion algebras over a particular field? Which of these be extended to octonion algebras?,"['matrices', 'abstract-algebra', 'field-theory', 'quaternions']"
4563077,Collection of all unitary operators in a Hilbert space is a closed set,"Let $\mathcal{H}$ be a Hilbert space. $\mathcal{U(H)}$ be the set of all unitary operators on H. Then I want to show that $\mathcal{U(H)}$ is a (norm-) closed subset of the Banach space $\mathcal{L(H)}$ , the space of all bounded Linear operators on H. I have tried taking a sequence of unitary operators on $\mathcal{U(H)}$ , but I couldn't conclude. Can somebody please guide me?","['banach-spaces', 'inner-products', 'operator-theory', 'hilbert-spaces', 'functional-analysis']"
4563081,Radon-Nikodym derivative of SDE law,"Let $(\Omega, (\mathcal F, \mathbb P)$ be a probability space, $T$ some index set, and $(S, \Sigma)$ a measurable space. Let $X^f$ and $X^g : T × \Omega \to S$ be stochastic processes defined by the stochastic differential equations
Let $$dX^{f}_t = f(X_t) dt + \sigma(X_t)dW_t, \\ dX^{g}_t = g(X_t) dt + \sigma(X_t)dW_t.$$ Denote by $\mathbb Q_f$ , resp. $\mathbb Q_g$ , the corresponding laws, i.e., $$\mathbb Q_f[A] = \mathbb P[\{\omega: t\mapsto X_t^f(\omega) \in A \}] $$ I want to compute the Radon-Nikodym derivative $\frac {d\mathbb Q_f}{ d \mathbb Q_g}$ . I know that the answer is connected to Girsanov's theorem, which needs to be applied twice. Girsanov's Theorem Let $\theta_t$ be an adapted process satiysfying the Novikov condition. Define a probability measure $\mathbb Q$ by $\frac{d\mathbb Q}{d\mathbb P}\Big|_{\mathcal F_t} = \mathcal E(\theta_t)$ . Then the stochastic process $t \mapsto W_t - \int_0^t \theta_s ds$ is a standard Wiener process under the measure $\mathbb Q$ . My (updated) attempt. As pointed out by @zhoraster, I should consider the process $Y_t = \Sigma^{-1}(X^f_t) X^f_t$ , which satisfies $$dY^f_t = \sigma^{-1}(X_t) f(X_t) dt + dW_t\enspace,$$ i.e. $Y:t\mapsto \int_0^t \sigma^{-1}(X_s) f(X_s) ds + W_t$ . According to Girsanov's theorem, this is a standard Wiener process under $\mathbb Q$ , defined by $\frac{d\mathbb Q}{d\mathbb P} = \mathcal E\left(-\sigma^{-1}(X_t) f(X_t)\right)$ , i.e., with $\theta_t = -\sigma^{-1}(X_t) f(X_t)$ . Further, $Y_t^0$ is a standard Wiener process wrt to $\mathbb Q$ . Define $$\Phi: \Omega \to C([0,T],S)\\
\omega \mapsto \left(t\mapsto W_t(\omega)\right) \enspace.$$ We know ( ? ) that the laws $\mathbb Q_{Y_t^f}$ and $\mathbb Q_{Y_t^0}$ satisfies for all measurable $A \subset C(T,S)$ that $$
\mathbb Q_{Y_t^0}[A] 
= \mathbb P[\{\omega: t\mapsto W_t(\omega) \in A \}]
= \mathbb P[\Phi^{-1}(A)]
= (\Phi_* \mathbb P) [A]
\\
\mathbb Q_{Y_t^f}[A] 
= \mathbb Q[\{\omega: t\mapsto W_t(\omega) \in A \}]
= \mathbb Q[\Phi^{-1}(A)]
= (\Phi_* \mathbb Q) [A]
$$ By the definition of $\mathbb Q$ , this means that $$\mathbb Q_{Y_t^f}\big[A\big] 
= \mathbb Q\left[\Phi^{-1}(A)\right]
= \mathbb E_{\mathbb P}\left[\mathcal E(\theta_t) \mathbb 1_{\Phi^{-1}(A)}\right]
 $$ In other words, $\mathbb Q_{Y_t^0} = \Phi_* \mathbb P$ and $\mathbb Q_{Y_t^f} = \Phi_* \mathbb Q$ . If the former is true, then my question reduces to whether the Radon-Nikodym derivative of push forward measures is the same as the Radon-Nikodym derivative of the original measures. Presumably, this only holds if $\Phi$ satisfies certain properties. Update: Bounty added","['measure-theory', 'stochastic-analysis', 'stochastic-processes', 'probability-theory', 'stochastic-calculus']"
4563164,Attempting to prove $(A\setminus B) × (C\setminus D) = (A × C) \setminus [(A × D) ∪ (B × C)]$.,"I am trying to prove the following equality where A, B, C and D are sets. (A \ B) × (C \ D) = (A × C) \ [(A × D) ∪ (B × C)] x stands for the cartesian product. As I am trying to prove via inclusion equality this is my attempt so far, I am trying to construct the forward implication but I am not sure how. I understand that to prove set equality you must prove one set is a subset of the other and vice versa but this question has me stumped. Find below my thought process so far and thanks in advance for your help! Foward Implication: (A \ B) × (C \ D) ⊆ (A × C) \ [(A × D) ∪ (B × C)] (A \ B) × (C \ D) = (A\C) Reverse Implication: (A × C) \ [(A × D) ∪ (B × C)] ⊆ (A \ B) × (C \ D) I am unsure how to progress from here any help would be highly appreciated!",['elementary-set-theory']
4563243,"Count ordered pairs $i$,$j$ for the following $\sum_{i=1}^M\sum_{j=1}^N \text{isPrime}(\gcd(i,j))$","Given $M$ , $N$ we are to find $\sum_{i=1}^M\sum_{j=1}^N \text{isPrime}(\gcd(i,j))$ where $\text{isPrime}(X)=1$ if $X$ is prime, $0$ otherwise. My thoughts are in the direction to somehow extend/generalize the solution to count of number of pairs of coprime as I stumbled upon that problem earlier How many coprime ordered pairs are there up to $N$? Number of ordered pairs of coprime integers from $1$ to $N$ Efficient way to compute $\sum_{i=1}^n \varphi(i) $","['number-theory', 'prime-numbers']"
4563267,"For an integral curve on a smooth manifold, can the interval on which it is defined be non-open?","I'm studying Professor Lee's Introduction to Smooth Manifolds (Second Edition) and Introduction to Riemannian Manifolds (Second Edition), (ISM and IRM, respectively).
In ISM Chapter 3 section Velocity Vectors of Curves on page 68, he defines the domain
of a curve to be an interval $J$ , most of the time open, but sometimes with one or two
endpoints. The rest of the section (defining velocity vectors of smooth curves) makes
perfect sense with any kind of interval $J$ . Then we get to ISM Chapter 9, the section on Integral Curves on page 206, in which we deal
with ""differentiable"" (I assume that is to be taken
to be the same as smooth) curves, but no mention is made of what kind of interval
they are defined on. But that's fine; I can deal with them being defined on intervals
with zero, one or two endpoints, up until page 212 when a maximal integral curve is
defined as ""one that cannot be extended to an integral curve on any larger open interval (emphasis added)"". This is followed by the Fundamental Theorem on Flows , in which property (a) states that $$\theta^{(p)}\colon\mathscr{D}^{(p)}\to M$$ is the ""unique smooth maximal integral curve of $V$ starting at $p$ ."" [In this context, $\mathscr{D}^{(p)}$ is an open interval.] So now I have a question. The definition of maximal integral curve and the theorem work
fine if integral curves are defined only on open intervals. But if they can be defined
on intervals with one or two endpoints, then I imagine there could be a problem where
there were two different integral curves, one defined on an open interval and one defined
on that interval plus an endpoint, say, having the same values on the open interval, but
not being extendable any further. Then both curves would have to be considered to be
maximal, thus breaking uniqueness. So here's the question finally. This theorem is for smooth manifolds without
boundary. Is that sufficient to show that what I just described can't happen? I know
of two ways that an integral curve might not be extendable: if it blows up at the
endpoint or if it runs into the boundary. If there is no boundary and if it can be
extended to an endpoint, then it is not blowing up at the endpoint, and it can be
extended further (waving hands furiously here). So is there any other way that an
integral curve can be prevented from extending? If not, can I safely assume that
maximal integral curves (into smooth manifolds without boundary) are necessarily
defined on open intervals? The reason I mentioned IRM is I also would like to know if assuming that maximal
integral curves are always defined on open intervals will get me into trouble
in IRM.","['smooth-manifolds', 'differential-geometry']"
4563403,Multiple Solutions? Suppose ${x^2}+{y^2} = 45$ and $x=2y$ ... find $\frac{dy}{dt}$,"Suppose ${x^2}+{y^2} = 45$ and $x=2y$ for positive values of $x$ and $y$ find $\frac{dy}{dt}$ when $\frac{dx}{dt}=2$ I am new to implicit differntiation and related rates. When I attempted to solve this problem, I was met with multiple solutions. It is my first time working with two seperate equations and was wondering why two solutions is possible and what they would mean in context. Thank you. Solution 1: $$\frac{d}{dt}[x=2y]$$ $$\implies\frac{dx}{dt}=2\frac{dy}{dt}$$ $$\implies2=2\frac{dy}{dt}$$ $$\implies\frac{dy}{dt}=1$$ Solution 2: $$\frac{d}{dt}[{x^2}+{y^2} = 45]$$ $$\implies2x\frac{dx}{dt}+2y\frac{dy}{dt}=0$$ $$\implies2(2y)(2)+2y\frac{dy}{dt}=0$$ $$\implies4+\frac{dy}{dt}=0$$ $$\implies\frac{dy}{dt}=-4$$ Solution 3: (admittedly the same as sol. 2) $${x^2}+{y^2} = 45 \quad \Bbb{and} \quad x=2y$$ $$\implies{(2y)^2}+{y^2} = 45$$ $$\implies {5y^2} = 45$$ $$\implies {y} = 3 \Bbb {\quad [ignore\, \pm\, because\, of\, original\, question]}$$ $$\Bbb{and}\quad{x=6}$$ $$\Bbb{we\,recall} \quad 2x\frac{dx}{dt}+2y\frac{dy}{dt}=0$$ $$\implies 2(6)(2)+2(3)\frac{dy}{dt}=0$$ $$\implies \frac{dy}{dt}=-\frac{24}{6}=-4$$","['related-rates', 'calculus', 'implicit-differentiation', 'derivatives']"
4563405,Topological space where continuous functions to itself are exactly the constant functions and the identity,"In any topological space $X$ , the identity function on $X$ and any constant function $X\rightarrow X$ are necessarily continuous. Does there exist an infinite topological space such that these functions are the only continuous functions $X\rightarrow X$ ? I require the space to be infinite since there are finite examples such as the one-point space, and the space $\{1,2\}$ with open sets $\{\emptyset,\{1\},\{1,2\}\}$ . Although I am not aware of any finite examples with more than two points, so those could be of interest to me too. The only further progress I've made is that such a space must be connected: otherwise write $X$ as a disjoint union of nonempty open sets $U\cup V$ . A map sending $U$ to one point and $V$ to a different point is then continuous.","['continuity', 'general-topology']"
4563516,Evaluate $\int_0^1 \cos^{-1} x\ dx$ by first finding $\frac{d}{dx}(x\cos^{-1} x)$,"Question Evaluate $$\int_0^1 \cos^{-1} x\ dx$$ by first finding the value of $$\frac{d}{dx}(x\cos^{-1} x).$$ My Working As the question said to evaluate $$\frac{d}{dx}(x\cos^{-1} x),$$ I used the product rule to differentiate. We first have to let $u=x$ and $v=\cos^{-1} x$ , so \begin{align}
& \quad\frac{d}{dx}(x\cos^{-1} x)\\
&=u^\prime v+v^\prime u\\
&=1\cdot \cos^{-1}x + x\cdot\frac{-1}{\sqrt{1-x^2}}\\
&=\cos^{-1}x-\frac{x}{\sqrt{1-x^2}}
\end{align} Unfortunately, after that, I have no idea about how to proceed, but I think that we should go somewhere from $$\int\left[\frac{d}{dx}(x\cos^{-1}x)\right]\ dx+\int\frac{x}{\sqrt{1-x^2}}\ dx=\int \cos^{-1}x???$$ Thank you for your help!","['integration', 'trigonometric-integrals', 'derivatives']"
4563520,"Finding recursive formulas for $\int_0^{\pi/2}\sin^nx\,\sin(nx)\,dx$ and $\int_0^{\pi/2}\sin^nx\,\cos(nx)\,dx$","As part of my homework, the teacher tasked us with finding recursive formulas/recurrence relations for the following integrals (I guess without refrencing I in J or J in I): $$I_n =\int_{0}^{\frac{\pi}{2}} \sin^nx\cdot \sin(nx)\ dx \ \ \ \ \ (1) \\ J_n = \int_{0}^{\frac{\pi}{2}}\sin^nx\cdot \cos(nx) \ dx \ \ \ \ \ (2)$$ The constraints are to use integration by parts and elementary operations (such as writing $x^n$ as $x^{n-1}\cdot x$ and then integrating). The teacher also gave us $(1)$ but only with $\cos$ and $(2)$ but with $\sin$ and $\cos$ switched $(\cos^nx\cdot\sin(nx))$ . These I was able to solve either by started from the $n-1$ term which then turned into the $n$ term or by integrating by parts. However, these other two seem a lot harder and, for instance in the case of $(1)$ , I get stuck because I somehow reach an equation that includes $(2)$ : $$I_n = \int_{0}^{\frac{\pi}{2}} \sin^nx\cdot\sin(nx) \ dx = -\frac{\cos\left(\frac{n\pi}{2}\right)}{n}+ \int_{0}^{\frac{\pi}{2}}\sin^{n-1}x\cdot\cos((n-1)\cdot x)\ dx - \underbrace{\int_{0}^{\frac{\pi}{2}}\sin^{n-1}x\cdot\sin nx\cdot\sin x \ dx}_{=I_n} \iff \\ \iff 2\cdot I_n =  -\frac{\cos\left(\frac{n\pi}{2}\right)}{n}+ \underbrace{\int_{0}^{\frac{\pi}{2}}\sin^{n-1}x\cdot\cos((n-1)\cdot x)\ dx}_{=J_{n-1}}$$ Ideally, I would like just a hint if I'm close with my attempt. Thank you!","['integration', 'real-analysis', 'calculus', 'trigonometric-integrals', 'trigonometry']"
4563546,Compactness: open cover vs. limit point,"I've been studying analysis (and some topology),
and I recently read an article about the history of compactness. First, the usual definition of compactness is defined via open covers: A set $X$ is compact if every open cover of $X$ has a finite subcover. Also, while learning about limit points,
we come with limit-point compactness (also known as the Bolzano-Weierstrass property): A set $X$ is limit-point compact if every infinite subset of $X$ has a limit point in $X$ . I've done some reading and get that these two are equal in metric spaces;
but surely they would differ in more general topological spaces.
Some topological spaces may be compact but not limit compact, and vice versa. So if open-cover compactness and limit-point compactness are different,
why would the open-cover definition be the ""standard"" definition for compactness?
In other words, what are the aspects(theorems, ideas, etc) of open-cover compactness
that makes it more useful than limit-point compactness?
For instance, in terms of generalization, arguments simply saying
that open-cover compactness is more general than limit-point compactness
seems unsatisfying to me;
I want the details about it. I hope my questions are not too vague, and appreciate every feedback if it feels so. Thanks.","['compactness', 'general-topology', 'analysis', 'terminology']"
4563573,On a solution of a fractional integral equation,"I am looking for the solution of $$\frac{d^\alpha}{d x^\alpha}f(x)=g(x)f(x),$$ where $\alpha \in (0,1)$ and $\frac{d^\alpha}{d x^\alpha}$ is the Caputo derivative. A series of Jumarie's papers, ""2005On the solution of the stochastic differential equation of exponential growth driven by fractional Brownian motion"", ""2005On the representation of fractional Brownian motion as an integral with respect to and $(dt)^\alpha$ "" and ""2006Modified Riemann-Liouville derivative and fractional Taylor series of nondifferentiable functions further results"", and many other later papers, the author claim the solution is $$
f(x)=f(0)E_\alpha\left(\alpha \int_0^x (x-y)^{\alpha-1}g(y)dy\right),
$$ where $E_\alpha$ is the Mittag-Leffler function. Apart from the idea provided in these papers, do we have other ways to prove it? By the way, the author also apply one result of the Mittag-Leffler function, $$
E_\alpha\left((x+y)^\alpha\right)=E_\alpha(x^\alpha)E_\alpha(y^\alpha).
$$ May I ask what is the condition for this to be true? At least, Wolfram Mathematica does not support this equation. Many thanks in advance.","['special-functions', 'ordinary-differential-equations', 'mittag-leffler-function', 'fractional-calculus', 'fractional-differential-equations']"
4563577,How restricted is the curvature of a manifold by choice of topology keeping the underlying set fixed?,"Suppose we have a topological manifold, then by varying the connection on the manifold, we can varying the properties related to curvature of the manifold as curvature is solely a property of the connection. This led me to wonder, is there a precise way to describe how limited we are in varying the curvature properties of a topological space as we vary it's connection while keeping the underlying set fixed? The motivation comes from this post where I ask if it possible to do GR on the basic levels by only using $R^4$ as the base set
. I had the thought after reading what I considered to be a profound point by user Peek-a-Boo: There is no connection ∇ on the sphere $S^2$ such that the Riemann curvature $R^∇$ of the connection vanishes identically. In other words, the sphere does not admit a flat connection. The plane $R^2$ obviously has a flat connection. So, there are genuine differences in these manifolds; this is just one instance where the topology has implications for the curvature",['differential-geometry']
4563582,Solutions of a set of trigonometric equations,"I am trying to find maxima of a linear combination of functions $\text{trig}(x)\text{trig}(y)\text{trig}(z)$ , where $\text{trig}$ is $\sin$ or $\cos$ (which of course gives 8 such terms): $$
f(x,y,z) = 
A\cos{x}\cos{y}\cos{z}
+B\cos{x}\cos{y}\sin{z}
+C\cos{x}\sin{y}\cos{z}
+D\cos{x}\sin{y}\sin{z}\\
+E\sin{x}\cos{y}\cos{z}
+F\sin{x}\cos{y}\sin{z}
+G\sin{x}\sin{y}\cos{z}
+H\sin{x}\sin{y}\sin{z}
$$ Coefficients of this linear combination are arbitrary. After a series of substitutions, I was able to reduce it to maximizing the following function: $$
g(u,v,w)=K\cos(u+v+w+e) + L\cos u + M\cos v + N\cos w.
$$ Equating its gradient to 0, we are presented with a set of equations: $$
\begin{cases}
K\sin(u+v+w+e) + L\sin u = 0, \\
K\sin(u+v+w+e) + M\sin v = 0, \\
K\sin(u+v+w+e) + N\sin w = 0.
\end{cases}
$$ Unfortunately I am not able to proceed further. Do you have any ideas how to find a solution? Analytical solution would be great, however in the end it is used in computer calculations, so numerical solutions are also accepted, however they should be stable and work for arbitrary coefficients. For some specific values of free parameters maxima can be lines or planes, so these cases have to be detected (I am probably able to figure it out myself). Thanks.","['trigonometry', 'systems-of-equations', 'nonlinear-optimization', 'numerical-optimization']"
4563600,"If you take the tangent of a matrix, how can you visualise geometrically what is happening? I.e. $ \tan \begin{pmatrix} a&b \\ c & d \end{pmatrix}$","If you take a tangent of a matrix, how can you visualise what is happening geometrically? E.g. for $$ \tan \theta =3 $$ You could envision a right triangle with an angle $\theta$ and a opposite side that is $3$ times bigger than the adjacent. Now imagine taking the tangent of a matrix with the use of a power series: $$\tan x = x + \dfrac 1 3 x^3 + \dfrac 2 {15} x^5 + \dfrac {17} {315} x^7 + \dfrac {62} {2835} x^9 + \cdots$$ So for matrixes, e.g. $$ \tan \begin{pmatrix}
a & b \\
c & d 
\end{pmatrix}$$ : $$\tan A = A + \dfrac 1 3 A^3 + \dfrac 2 {15} A^5 + \dfrac {17} {315} A^7 + \dfrac {62} {2835} A^9 + \cdots$$ Is there any way to connect this to triangles etcetera?","['trigonometry', 'linear-algebra']"
4563609,Understanding Adelic Hilbert modular forms.,"I am reading about adelic Hilbert modular forms. Let us fix notation as in Shih .
I am having difficulty understanding the definition of Hecke operators. These are defined on the group of cusps $C_\mathfrak n$ of $K(\mathfrak n )$ as follows. First, we say that for each prime $\mathfrak p_v$ we have \begin{equation} K_1(\mathfrak n)\begin{pmatrix} \varpi _v & 0 \\ 0 & 1 \end{pmatrix} K_1 (\mathfrak n) = \sqcup _i \gamma _i K_1(\mathfrak n ) =\sqcup _j K_1(\mathfrak n)\beta _j  \quad (1)\end{equation} and then define $T(\mathfrak q ).c = \sum _i c\gamma _i$ . Where does $(1)$ come from? (this could probably be Bruhat decomposition but at this moment I do not know almost anything about it) Similar equation appears with $\beta _j$ replaced with $\gamma _i$ . At another place there is similar equation \begin{equation} K_1(\mathfrak np^r)\begin{pmatrix} \varpi _v & 0 \\ 0 & 1 \end{pmatrix} K_1 (\mathfrak np^r) = \sqcup _{u\in \mathcal O_v /\varpi _v} \begin{pmatrix} \varpi _v & u \\ 0 & 1 \end{pmatrix} K_1(\mathfrak np^r )  \quad (2)\end{equation} Any help is appreciated and feel free to provide any reference. Please let me know if should provide more background or/and notation.","['number-theory', 'modular-forms']"
4563613,Determining the limit of the sequence $a_{n+1}=-ta_n^2+(t+1)a_n$,"Let $t\in(0,1]$ , $a_0\in (0,\frac{1}{t}+1)$ and $a_{n+1}=-ta_n^2+(t+1)a_n$ . Does $\lim\limits_{n\to\infty}a_n$ exist for all $\,t\in(0,1]\,$ and $\,a_0\in\big(0,\frac{1}{t}+1\big)\,$ ? If yes, determine the limit. I already showed that $a_n$ is bounded and I think the limit exists and is one. Now I have problems to show that $a_n$ is monotone increasing/decreasing, because it is either increasing or decreasing or nothing (for $t=0.8$ and $a_0=2.24$ ) it is not decreasing and not increasing. I also tried the Banach-fixed-point theorem but I think I can't use it here.","['calculus', 'convergence-divergence', 'recurrence-relations', 'sequences-and-series']"
4563618,"Prove or disprove: If $f(x)$ is continuous in $(0,1]$ and $f(x)\to\infty$ as $x\to 0^+$, then $\lim_{n\to\infty}\sum_{k=1}^n f(k/n)$ does not exist.","I'm trying to prove or disprove the following conjecture: If $f(x)$ is continuous in $(0,1]$ and $f(x)\to\infty$ as $x\to 0^+$ then $L=\lim\limits_{n\to\infty}\sum\limits_{k=1}^n f\left(\frac{k}{n}\right)$ does not exist. My attempt I tried proof by contradiction. Asssume $L$ exists. $L=\lim\limits_{n\to\infty}n(\frac{1}{n})\sum\limits_{k=1}^n f\left(\frac{k}
{n}\right)=\left(\lim\limits_{n\to\infty}n\right)\int_{0}^1 f(x)dx$ (EDIT: As mentioned by @FShrike in the comments, the previous step is not valid.) $\therefore \int_{0}^1 f(x)dx=0$ There are functions $f(x)$ , continuous in $(0,1]$ , such that $f(x)\to\infty$ as $x\to 0^+$ and $\int_{0}^1 f(x)dx=0$ . For example, $f(x)=-\ln{x}-1$ , in which case $L$ does not exist, by Stirling's approximation . But I do not see why all such functions $f(x)$ would imply that $L$ does not exist. Context: I am interested in geometrical infinite products ( example1 , example2 ). The conjecture in this question, via the substitution $f(x)=-\ln{g(x)}$ , is equivalent to: If $g(x)$ is continuous in $(0,1]$ and $\lim\limits_{x\to 0^+}g(x)=0$ then $\lim\limits_{n\to\infty}\prod\limits_{k=1}^ng\left(\frac{k}{n}\right)$ either equals $0$ or does not exist, which stands in interesting contrast with the fact that infinite products of lengths or areas, that tend to $0$ , can equal a positive number. EDIT2: I'm not sure if this is helpful, but I have noticed that $L_2=\lim\limits_{n\to\infty}\sum\limits_{k=1}^n f\left(\frac{k-1/2}{n}\right)$ can exist. For example, $\lim\limits_{n\to\infty}\sum\limits_{k=1}^n \left(-\ln{\left(\frac{k-1/2}{n}\right)}-1\right)=-\frac{\ln{2}}{2}$ . (Another question of mine yielded methods for dealing with the sum $\sum\limits_{k=1}^n \ln{(k-\frac12)}$ .) I do not understand why replacing $k$ with $k-\frac12$ seems to make the limit existable (if that's a word).","['conjectures', 'real-analysis', 'sequences-and-series', 'infinite-product', 'limits']"
4563674,Perturbation of identity still surjective?,"Let $f : \mathbb{R^n}\mapsto \mathbb{R^n}$ a smooth function. Can we give a condition for the application $F=I+f$ , where $I$ is the identity, to be surjective ? I know that if the operator norm of the differential of $f$ is small, $\vert Df\vert <= 1/2$ , say, then $F$ is a submersion, but it does not tell me that it is surjective. On the other hand, if we look at the problem for $n=1$ , then we have $F'>1/2$ , which of course implies that $F$ is surjective. In other words we avoid counter-examples like $arctan$ , which are not surjective submersions. Can such a result be extended to higher dimensions ? Edit : Another way to formulate this, is that $f$ is $1/2$ -Lipschitz. Any additionnal hypothesis on $f$ is welcomed Edit 2 :  More precisely, wlog suppose that $f(0)=0$ , then the function $F$ is a quasi isometry in the sens that $\frac{1}{2}\vert\vert F(x) - F(y)\vert\vert \leq \vert\vert x - y\vert\vert \leq 2\vert\vert F(x) - F(y)\vert\vert$ . It is known that an isometry of $\mathbb{R^n}$ must be surjective, see for instance Isometries of $\mathbb{R}^n$","['multivariable-calculus', 'calculus', 'differential-geometry']"
4563763,"Prove that if $A$ has integer entries, $|\det A| = 1$, then the polyhedron formed by $A$ does not contain integer points.","Given $n$ vectors $v_1 , v_2 , v_3 , \dots, v_n \in \mathbb{R}^n$ with integer entries in each vector. Prove that if $|\det(v_1 , v_2 , \dots , v_n)| = 1$ , then the polyhedron $Ov_1v_2\dots v_n$ does not have any points with integer coordinates inside it, except the vertices. For example, My idea Use determinant to prove that $$\det A =  \text{Volume of the paralelipiped spanned by }A $$ and because $\det A$ has integer value, we have $\min|\det A| = 1$ . Then conclude that the parallelepiped spanned by $A$ is the smallest. So, if $A$ has any other integer points inside it, it will contain another smaller parallelepiped, which is conflicted with the previous statement. But here we have to consider the polyhedron, which is something I'm stuck with.","['determinant', 'volume', 'integer-lattices', 'matrices', 'linear-algebra']"
4563799,What is $x^\bot$? Is $\zeta(\bot)=\bot$ for Riemann's zeta function $\zeta$ and wheel theory's $\bot$?,"Background: A wheel is an algebraic structure $(W,0,1,+,\cdot, /)$ where: $W$ is a set, $0,1\in W,$ $+$ and $\cdot$ are binary operations, $/$ is a unary operation, and $+,\cdot$ are associative, commutative, and with identities $0$ and $1$ , respectively, $//x=x$ , $/(xy)=/x/y$ , $xz+yz=(x+y)z+0z$ , $(x+yz)=x/y+z+0y$ , $0\cdot 0=0$ , $(x+0y)z=xz+0y$ , $/(x+0y)=/x+0y$ , $0/0+x=0/0$ . We denote $0/0$ by $\bot$ . The final axiom can be written as $$\bot+x=\bot.$$ See What are the mathematical properties of ⊥ in wheel theory? Therefore, $$\sum_{i=1}^\infty a_i=\bot\tag{$\Sigma$}$$ is $\bot$ whenever $a_i=\bot$ for at least one $i\in\Bbb N$ . The Question: Can we go any further than $(\Sigma)$ ? What is $x^\bot$ ? In particular, is $$\zeta(\bot)=\bot$$ for Riemann's zeta function? Thoughts: Due to the argument in the question linked to, my intuition is that, yes, we can go further; for instance, $$\prod_{i=1}^\infty a_i=\bot\tag{$\Pi$}$$ whenever $a_i=\bot$ for at least one $i\in\Bbb N$ , where $\Pi$ is defined in the obvious manner; but $$
\zeta(\bot)
:=\sum_{n=1}^\infty 1\cdot/(n^\bot)
$$ requires some notion of what $n^\bot$ means. I guess it should be $$x^\bot=\bot.\tag{$\bot$}$$ But breaking this down: $$
x^\bot =x^{0/0}
=x^{0\cdot /0}
=(x^0)^{/0}
=1^{/0},$$ which has me stumped. Should we define $$1^{/0}:=\bot?\tag{1}$$ Further Context: This is just for fun. I don't think anything deep is going on here. I have no formal training in wheel theory. Please help :)","['exponentiation', 'infinite-product', 'wheel-theory', 'riemann-zeta', 'sequences-and-series']"
4563823,The role of the Wronskian,"I am a physics student taking ODE this semester. Let's consider an initial value problem. Consider a homogenous second-order linear differential equation. Suppose we have two solutions $\varphi_1(x)$ and $\varphi_2(x)$ . To my understanding, we check the Wronskian to confirm whether we can span the entire solution space of the differential equation with just those two solutions. This is because if the Wronskian is zero, we know that the Wronskian matrix is non-invertible and so is inconsistent or has multiple solutions. Intuitively, I thought we'd just need to check that $\varphi_1$ and $\varphi_2$ are linearly independent. However, checking the Wronskian seems to impose stricter requirements, i.e., that the vector $(\varphi_1 \ \varphi_2)$ is linearly independent from $(\partial_x\varphi_1 \ \partial_x\varphi_2)$ and equivalently (it seems) that $\partial_x\varphi_1$ is not a multiple of $\partial_x\varphi_2$ and that $\varphi_1$ is not a multiple of $\varphi_2$ (other than trivially when $x_1 = x_2 = 0$ ). Where the latter statement is what I intuitively think is all that need be checked. Why do we need to check this stricter Wronskian requirement as opposed to the linear independence of our solutions? Does it have to do with the fact that we need to allow freedom in what the initial value of the first derivative of a solution is? And thus is not about the nature of linear independence, but more about the fact that we're dealing with an initial value problem?",['ordinary-differential-equations']
4563831,"Compute the triple integral over the region $x^2+y^2+z^2 \leq 2x$, $z\leq 0$","Compute the triple integral over the region $D = \{x^{2} + y^{2} + z^{2} \leq 2x,\, z\leq 0\}$ : $$
\iiint_{D}\left(y^{2}z + x\right){\rm d}V
$$ I'm struggling a great deal with setting up the integration bounds. From playing around, I think the best way to go about it is using spherical coordinates as opposed to cylindrical coordinates. It's easy to make a quick sketch of the $xy$ plane to deduce that we have to be below the line $y=2x$ , however then we must find the angle of intersection with the line $y=2x$ with the circle $x^2+y^2=1$ , and using polar coordinates, we can find that it corresponds to $\arctan2$ and then of course $\arctan2 + \pi$ , and by $z \leq 0$ , we ought to obtain that $\frac{\pi}{2}\leq\phi \leq \pi$ . I'm unsure about the $R$ bound (and everything previously stated to be honest), but using the provided inequality, we would obtain that $R \leq2\cos\theta \sin\phi$ , but by my sketch it would make more sense to have $0 \leq R \leq1$ . Thus, my suggested integral would look something like: $$\int_{\arctan{2}+\pi}^{\arctan{2}}d\theta\int_{\frac{\pi}{2}}^{\pi}d\phi\int_{0}^1(R^2 \sin{\phi})(R^3\sin^2{\theta}\sin^2{\phi}\cos{\phi+R\cos{\theta}\sin{\phi}})dR$$ which is obviously a nightmare. Any help/ hints on how to establish the bounds would be very appreciated!","['integration', 'definite-integrals', 'multivariable-calculus', 'calculus', 'multiple-integral']"
4563874,Finding the derivative of an exponential function without the chain rule,"Given $f(x) = a^x$ , one can compute the derivative of $f(x)$ using the chain rule quickly by noticing that $f(x) = a^x = \left(e^{ln(a)}\right)^x$ . But how would you go about computing the derivative of $f(x)$ without the chain rule, with just the $f'(x) = \lim_\limits{h \to 0} \frac{f(x + h) - f(x)}{h}$ or the $f'(x) = \lim_\limits{x \to a} \frac{f(x) - f(a)}{x - a}$ definition of a derivative and the fact that $\lim_\limits{h \to 0} \frac{e^h - 1}{h} = 1$ ? $f'(x) = \lim_\limits{h \to 0} \frac{a^{x + h} - a^x}{h} = a^x \cdot \lim_\limits{h \to 0} \frac{a^h - 1}{h} = a^x \cdot \lim_\limits{h \to 0} \frac{\left(e^{ln(a)}\right)^h - 1}{h} = a^x \cdot \lim_\limits{h \to 0} \frac{(e^h)^{ln(a)} - 1}{h}$ . How would you proceed from here?","['calculus', 'derivatives', 'exponential-function']"
4563894,Geometric Intuition behind Chebyshev's Inequality?,"I understand the proof behind this, and I've read a bunch of intuition behind it posts, but I don't think I completely understand what's happening. I also found a geometric intuition behind Markov's Inequality post and that made it easier to understand, so is there a geometric intuition behind this? Markov's Inequality: $P(X \ge a) \le \frac{E[X]}{a}$ where $X > 0$ Chebyshev's Inequality: $P(|X - E[X]| \ge a) \le \frac{\sigma^{2}}{a^{2}}$","['inequality', 'probability']"
4563895,Sequence of polynomials given by induction,"Consider a sequence of polynomials $$
\Phi_0(x)=x
$$ $$
\Phi_{k+1}(x)=x+\Phi_k(x)^2\quad\quad(k\ge0).
$$ It is easy to see that the equation $\Phi_k(x)=1$ has exactly one positive root. Let us denote it by $\xi_k$ . I am interested in the asymptotics of this root, as exact as possible. It is not difficult to see that $\Phi_k(\frac14) < \frac12$ for all $k$ , whence $\frac14 < \xi_k$ . On the other hand, I am able to get an upper bound of the form $\xi_k < \frac14+\frac{c}k$ for some positive constant $c$ . It is sufficient for my purposes, but numerical data suggest that $\xi_k$ is close to $\frac14+\frac{\pi^2}{k^2}$ as $k\to\infty$ . Is it possible to prove it? Or, perhaps, such a sequence of polynomials has already been discussed somewhere? An additional question for reference: consider a power series for the function $$
\frac1{1-\Phi_k(x)}
$$ in a neighborhood of zero. Its nth coefficient is equivalent to $C\xi_k^{-n}$ for some $C > 0$ , which can be deduced from the standard theory of linear recurrent equations. However, I think that such statements should follow from some well-known theorems. Does anyone know any useful links (preferably in English)? P.S. It is worth noting that for large $k$ , the first terms of the power series are Catalan numbers, but after them there is a long “tail” with smaller coefficients.","['power-series', 'polynomials', 'sequences-and-series']"
4563921,What is the reason that equations such as $\tan x = 2x$ can only be solved with the help of algorithms?,"This is my first StackExchange question: What is the reason that equations such as $\tan x = 2x$ , $\cos x = x$ , $\sin(x) = x^2$ and other questions that involve the same variable within a trigonometric function and outside the trigonometric function can only be solved with computer algorithms and have extremely complex closed forms; such as the Dottie number, the root of $\cos x = x$ , having the mind-blowing closed form $\sqrt{1-\left(2I_{\frac{1}{2}}^{-1}\left(\frac{1}{2},\frac{3}{2}\right)-1\right)^2}\,,$ which is really fascinating to me. For $\cos x = x$ , I tried solving the equation using the complex definition of $\cos x$ (aka. the cooler version of cosine), $\frac{e^{ix}+e^{-ix}}{2} = x$ but after using a quadratic formula to solve for $e^{ix}$ , I found that I just ended up with $x$ being equal to the complex definition of inverse cosine (arccos) in the formula $x = -i\ln(x + \sqrt{x^2-1})$ and I had gone around in circles, I thought ""Is this really an impossible equation to solve for $x$ ?"" The sum inside the natural logarithm, the $i$ being present in the equation even though the Dottie number is a real number approximately $0.739085$ ... and the $\sqrt{x^2-1}$ , I had seen that thing everywhere in Pythagoras and trigonometric calculus. It's as if mathematics had put as many barriers around the $x$ as possible to prevent you from solving for $x$ . And I had a similiar problem with $\sin x = x$ , I knew for a fact that the solution was definitely $0$ and yet the ""solution"" I got was total garbage that looked nothing like $0$ . And apparently this equation also had infinitely many complex solutions as well, which I don't grasp at all. These equations look so simple from first glance and yet are mathematically impossible for a human to solve for an exact form, but why is that? is it something to do with ""transcendental numbers""? Does it have any applications in trigonometry and calculus?","['complex-analysis', 'calculus', 'transcendental-numbers', 'transcendental-equations', 'trigonometry']"
4563954,How to concceptually think about sub-sigma algebras?,"I am trying to gain intuition on sub-sigma algebras, and how to think of them in a probabilistic context as information. Let $(\Omega,\mathcal{F})$ be a measurable space and $\mathcal{F'}\subset \mathcal{F}$ be a sub-sigma algebra. Then $\mathcal{F}'$ is conceptually some sort of partial information. For example, if $X$ were a random variable, $\sigma(X)$ would be the sub-sigma algebra generated by this random variable or the one which contains the ""information"" contained in the random variable $X$ . So if I have some piece of information $\mathcal{F}'$ , say the outcome of an experiment, how should I imagine this in my head? What I am thinking is that, if I know $\mathcal{F}'$ , then I have some partial information on $\mathcal{F}$ . Therefore, when the goddess of chance Tyche selects a $w\in \Omega$ , I know for any particular $A\in \mathcal{F}'$ whether or not $\omega$ is in the set or not. Is this the correct way of thinking about it? I'm also thinking about this in a gambling scenario. Suppose I am in a poker game and I have information on my opponent's emotions. Knowing this piece of information might give me some information on their hand, but I wouldn't be able to definitively say what the hand would be (I only know the information contained in this sub-sigma-algebra, and the sub-sigma-algebra is closed under the operations). So I could say when Tyche selects my $\omega \in \Omega$ , then since I am observing my opponents, I know maybe $\omega \in \{\text{Player 1 is nervous}\}$ $\omega \notin \{\text{Player 1 is not nervous}\}$ or for another example $\omega \in \{\text{Player 2 is calm}\}\cap \{\text{Player  1 is nervous}\}$ . So I can kind of act like an oracle for this $\sigma$ -algebra, telling you whether something happened in this outcome or not, but I can't say anything in a finer setting unless I know that information as well. Is there a different way to think about this? Any sources I can read to help my understanding? I am trying to not develop the wrong intuition here but I want to learn how to think probabilistically.","['statistics', 'analysis', 'real-analysis', 'probability-theory', 'probability']"
4564001,smooth points on variety of linear subspaces intersecting a given subspace,"$\newcommand{\Ind}{\operatorname{Ind}} \newcommand{\Gr}{\operatorname{Gr}} \newcommand{\Hom}{\operatorname{Hom}} \newcommand{\R}{\mathbb{R}} \newcommand{\GL}{\operatorname{GL}} \newcommand{\codim}{\operatorname{codim}}$ Let $\Gr_k$ be the Grassmannian manifold of $k$ -dimensional subspaces in $\R^n$ . Let $\GL(n)$ act on $\Gr_k$ in the natural way. For an arbitrary such subspace $V \in \Gr_k$ , let $\varphi_V \colon \GL(n) \to \Gr_k$ take $\varphi_V(g) = g V$ . This is a surjective map with surjective differential. Differentiating $\varphi_V$ at the identity element $e \in \GL(n)$ gives a map $d \varphi_V \colon \Hom(\R^n, \R^n) \to T_V \Gr_k$ , and its kernel are the maps $f$ that stabilize $V$ , in the sense that $f(V) \subseteq V$ . Since the map $\eta_V \colon \Hom(\R^n, \R^n) \to \Hom(V, \R^n / V)$ defined by $\eta_V(f) = \pi_V \circ f \circ \iota_V$ has the same kernel, this establishes an isomorphism $T_V \Gr_k \cong \Hom(V, \R^n / V)$ . When $W$ is some subspace, define $\Ind_k(W)$ to be the subset of elements $V \in \Gr_k$ that intersect $W$ in dimension at least one. In the literature, this is a special case of a ""Schubert variety."" I strongly suspect that $\Ind_k(W)$ is an embedded submanifold of $\Gr_k$ in a neighborhood of an element $V$ where $\dim V \cap W = 1$ . Furthermore, I believe its tangent space at such an element is composed, under the isomorphism above, of the maps $f$ for which $f(V \cap W) \subseteq W / V$ . However, I'm having trouble proving this rigorously. One idea is to consider the function $F(g) = g V \wedge W$ , viewing $V$ and $W$ as arbitrarily scaled elements of the exterior algebra $\Lambda(\R^n)$ . The system of $k$ -degree polynomial relations $F(g) = 0$ cuts out the preimage of $\Ind_k(W)$ under $\varphi_V$ . We can also differentiate $F$ at the identity in the following way. Since $V \cap W$ is a one-dimensional subspace, we have a basis $v_1, \ldots, v_k$ for $V$ with $V \cap W = \langle v_1 \rangle$ . For $A \in \Hom(\R^n, \R^n)$ , differentiating gives \begin{align*}
d F_e(A) & = \frac d{dt}_{t = 0} e^{t A} V \wedge W = \frac d{dt}_{t = 0} \left (\bigwedge_{i = 1}^k e^{t A} v_i \right) \wedge W \\ 
& = \sum_{i = 1}^k (-1)^{i + 1} A v_i \wedge \bigwedge_{\substack{j = 1 \\ j \neq i}}^k v_j \wedge W  = A v_1 \wedge v_2 \wedge \ldots \wedge v_k \wedge W,
\end{align*} where the last equality follows because $v_1 \wedge W = 0$ . In particular, we conclude that the kernel of $dF$ are the maps $f$ for which $f(V \cap W) \subseteq V + W$ . The image of $\ker dF_e$ under $d \varphi_V$ coincides with the description of $T_V \Ind_k(W)$ that I have conjectured. Unfortunately, I believe that $F$ does not have constant rank near the identity. How can I easily show that $F^{-1}(0)$ is an embedded submanifold near this point, with tangent space given by the kernel of $dF$ ?","['grassmannian', 'schubert-calculus', 'differential-geometry']"
4564007,"find the maximum possible product of two positive integers whose digits form a permutation of $\{1,\cdots, 8\}$","What is the maximum possible value of a product of two numbers that use the digits $1,\cdots, 8$ exactly once and no other digits? I know how to obtain the minimum possible product. Similar to above, we must have that both numbers have digits in ascending order. Let $10b + c$ and $a$ be the two numbers, where $c$ is a digit. Then if $10b+c < a, $ since $(10b+c)a > (10a+c)b,$ moving the last digit from the smaller number results in a smaller number. Hence the smallest product is obtained when one number has one digit, which implies the other has 7 (otherwise we could decrease the product with the above method). First note that for the largest possible product, the two numbers must have their digits in descending order. We have 256 * 2519 > 2569 * 251, so it is not generally true that removing the last digit from the larger factor and appending it to the smaller one yields a larger product. Or if we want to satisfy the conditions of the problem we also have the example 253 * 1468 > 2538 * 146. For simplicity, consider the case where the two numbers have four digits. Then one number must have 8 as the first digit. The other number can't have 5 as the first digit (the largest digit) as then the maximum product would be $8761\cdot 5432 < 8321 \cdot 7654 = 63688934.$ So the second number must have $6$ or $7$ as the first digit. Then note that $\overline{87pq} \cdot \overline{6mcd} < \overline{8mrs}\cdot \overline{67pq} < \overline{8mrs}\cdot \overline{76pq},$ where the variables are digits. For instance, $\overline{87pq} \cdot \overline{6mcd} - \overline{8mrs}\cdot \overline{67pq} =(8700+10p+q)(6000+100m+10c+d)-(8000+100m+10r+s)(6700+10p+q),$ and a tedious calculation yields the desired inequality.","['contest-math', 'elementary-number-theory', 'recreational-mathematics', 'discrete-mathematics', 'inequality']"
4564032,Summing the kth-nacci sequences over k,"I've been playing around with an open problem I found in Peter Winkler's puzzle book. Roughly, it is Let $C_p(n)$ be the expected length of the longest common subsequence of two random coin flip sequences of length $n$ , with a coin that gives heads with probability $0<p<1$ . Let $C_p=\lim_{n\to\infty}C_p(n)/n$ . Compute $C_{1/2}$ , or at least prove $C_p$ is minimized when $p=1/2$ . I'm attempting to compute $C_{1/2}$ . Using some fishy recursive stuff, I've essentially reduced it to computing $\sum_{k=2}^{n-1}F_n^{(k)}$ or at least $\lim_{n\to\infty}\frac{1}{2^n}\sum_{k=2}^{n-1}F_n^{(k)}$ , where $F_n^{(k)}$ is the $n$ th term of the $k$ -nacci sequence, see https://en.wikipedia.org/wiki/Generalizations_of_Fibonacci_numbers#Higher_orders . I've wondered if anyone has studied this sum in the past or if there are any conjectures involving it.","['expected-value', 'combinatorics', 'open-problem']"
4564045,How to show that some number is not a limit of a function by the negation of the definition of limits,"The negation of the definition of limit of functions is $\exists\epsilon>0\forall\delta>0\exists x\neq a(|x-a|<\delta \text{ and } |f(x)-f(a)|\geq\epsilon)$ . How do we use this to show for example that $lim_{x\rightarrow 3}x\neq 6$ or $lim_{x\rightarrow 3}x^2\neq 18$ ? From the first limit we have that the following must apply $\exists\epsilon>0\forall\delta>0\exists\neq 3(0<|x-3|<\delta \text{ and } |x-6|\geq\epsilon)$ . I get stuck at $\forall\delta>0$ since for me it implies that $x\in\mathbb{R}$ but $x\neq 3$ and with this there can not be any $\epsilon>0$ such that $|x-6|\geq \epsilon$ . Edit: So the negation of the definition should be $\exists\epsilon>0\forall\delta>0\exists x\neq a(0<|x-a|<\delta \text{ and } |f(x)-f(a)|\geq\epsilon)$ I think. I'm going to try to work with this but I appreciate answers. Edit 2: This doesn't seem trivial at all. If we want to show that the negation of the definition applies to the first limit then we need to show that that there exists a $\epsilon>0$ such that for all $\delta>0$ there is a $x\neq 3$ such that the conditions are met. But the problem for me is $\delta>0$ , with that I can't pick a $x$ since I can always make $\delta$ smaller such that the $x$ is not valid anymore.","['limits', 'calculus', 'real-analysis']"
4564055,Probability of sampling an element in this list,"Let $A$ be a list of $n$ distinct integers. Suppose we pick uniformly at random $k$ distinct elements from $A$ and call $B$ the list obtained. Now we sample one element $x$ uniformly at random from $B$ . Let $A'$ be the input list $A$ but in sorted increasing order. What is the probability of choosing $x$ as $i$ -th term in $A'$ given that $x$ lies in the middle third of $B$ ? This is my attempt. Assuming that $k$ is a multiple of 3 we can argue that the probability is 0 for $i= 1, 2, \dots, \frac{k}{3}$ and for $i = n, n - 1, \dots, n - \frac{k}{3}$ . For any other case we can get $$ \mathbb P(x \text{ is the $i$-th element in $A'$}) = \sum^{\frac{k}{3} - 1}_{j=0}\frac{{i - 1 \choose \frac{k}{3} + j}\times{n-i \choose \frac{2k}{3}- j - 1}}{n \choose k}$$ Is this correct? Is there a way to simplify or bound  this probability?","['discrete-mathematics', 'combinatorics', 'probability', 'real-analysis']"
4564080,Question about Exercise 17 in Hugo Duminil-Copin's lecture notes: Introduction to Bernoulli percolation,"The problem is:Show that the existence of two edge-disjoint self-avoiding paths of open edges starting from 0 has a probability which is either 0 or 1. My question is: do we require the path to be infinite? otherwise the probability would be $1-(1-p)^{2d}-2dp(1-p)^{2d-1}$ right? If it is infinite, how to prove that? I try to show for any $x$ , we have $\mathbf{P}(A\cap A_x)\approx\mathbf{P}(A)$ and then we can approximate $A$ by $B$ which only depends on finitely many edges, finally pick large enough $x$ to make $B$ and $B_x$ independent, by $\mathbf{P}(B\cap B_x)=\mathbf{P}(B) \mathbf{P}(B_x)\approx \mathbf{P}(A) \mathbf{P}(A_x)=\mathbf{P}(A)^2$ , we can prove the statement. However I find it hard to show $\mathbf{P}(A\cap A_x)\approx\mathbf{P}(A)$ . Does my idea make sense? or any other way to show that?","['percolation', 'discrete-mathematics', 'probability-theory', 'probability']"
4564131,"Given $A,B$ are $n \times n$ matrices, $(A+B)^2=A+B,r(A+B)=r(A)+r(B)$. Prove: $A^2=A,B^2=B$","Given $A,B$ are $n \times n$ matrices, $(A+B)^2=A+B,r(A+B)=r(A)+r(B)$ . Prove: $A^2=A,B^2=B$ I don't know how to use $r(A+B)=r(A)+r(B)$",['linear-algebra']
4564149,what is bridge between symbolic notation of a generalized function and functional notation of the same generalized function？,"Generalized function theory bothers me from time to time, I used to put aside and not delve into it, but this time I encountered it again with annoyance and wanted to understand it to some extent. Below is my current core questions. Generalized functions are continuous linear functionals defined on test functions space with compact support, which have two notations, symbolic(eg 𝛿(x)) and functional(eg 𝛿[φ]). The pdf( https://www.cs.odu.edu/~mln/ltrs-pdfs/tp3428.pdf ) I have read do not elaborate on this point further, and I have the following questions: Can any given continuous linear functional on D give a symbolic notation of it? If yes, how to give? What is the general bridge between the symbolic notation and the functional notation? For common operations such as multiplication, differentiation, limit, integral, etc. what are the correspondences/relations between these two notation-systems? For example, if I derive the symbolic (functional) form, what is derivatives of the functional (symbolic) form? why generalized function always equal to the generalized derivatives of an ordinary function? can you give me some easy examples to explain it? I'm not a math-majored student, so I'm not greedy to understand from underlying, I just want to master operations of generalized functions and understand it from relations of the two notation-systems.","['dirac-delta', 'functional-analysis', 'real-analysis']"
4564153,"A problem from Stein and Shakarchi complex analysis (problem 5, Chapter 3)","The origin question is below:
Let $$g(z)=\frac{1}{2\pi i}\int_{-M}^M\frac{h(x)}{x-z}dx$$ where $h$ is continuous and supported in $[-M,M]$ . Prove that the function $g$ is holomorphic in $\mathbb{C}\backslash[-M,M]$ , and vanished at infinity, that is $\lim_{|z|\to\infty}|g(z)|=0$ . Moreover, the ""jump"" of $g$ across $[-M,M]$ is $h$ , that is $$h(z)=\lim_{\varepsilon\to0+}g(x+i\varepsilon)-g(x-i\varepsilon).$$ If $h$ satisfies a mild smoothness condition, for instance a Hölder condition with exponent $\alpha$ , then $g(x+i\varepsilon)$ and $g(x-i\varepsilon)$ converge uniformly to functions $g_+(x)$ and $g_-(x)$ as $\varepsilon\to0$ . Then, $g$ can be characterized as the unique holomorphic function that satisfies: $g$ is holomorphic outside $[-M,M]$ , $g$ vanished at infinity, $g(x+i\varepsilon)$ and $g(x-i\varepsilon)$ converges uniformly to the functions $g_+(x)$ and $g_-(x)$ with $$g_+(x)-g_-(x)=h(x)$$ . The first problem is easy as long as one notice that $g(x+i\varepsilon)-g(x-i\varepsilon)=h*K_\varepsilon$ , where $K_\varepsilon(x)=\frac{\varepsilon}{\pi(x^2+\varepsilon^2)}$ is a good kernel. I found it difficult to prove that $g(x\pm i\varepsilon)\rightrightarrows g_\pm(x)$ . As a matter of fact, the real part of $g_\varepsilon^\pm$ is nothing but $\pm\frac{1}{2}(g_\varepsilon^+-g_\varepsilon^-)$ which had been proved to converge uniformly to $\pm\frac{1}{2}h(x)$ , but the imaginary part is propotional to $$\int_{-M}^Mh(t)\frac{t-x}{(t-x)^2+\varepsilon^2}dt.$$ I even cannot prove that it does converge to some function. and I didn't know how to use the Hölder condtion as well. I saw that follows from this condition, given $\varepsilon>0$ , one have $g_\varepsilon^\pm(x):=g(x\pm i\varepsilon)$ also satisfies the Hölder condition. But what can I do with it?",['complex-analysis']
4564208,"How to show $\exists M, \forall n: |\overset{n}{\underset{k = 1}{\sum}}\cos{(k + \frac{1}{k})}| \leq M$?","How to show that $\exists M, \forall n: |\overset{n}{\underset{k = 1}{\sum}}\cos{(k + \frac{1}{k})}| \leq M$ ? I tried to prove by finding real part of $\overset{n}{\underset{k = 1}{\sum}}e^{i(k + \frac{1}{k})}$ , but it didn't work out. Also since $|\overset{n}{\underset{k = 1}{\sum}}\cos{(k + \frac{1}{k})}| = 
|\overset{n}{\underset{k = 1}{\sum}}(\cos{k}\cos{\frac{1}{k}} - \sin{k}\sin{\frac{1}{k}})| \leq 
|\overset{n}{\underset{k = 1}{\sum}}\cos{k}\cos{\frac{1}{k}}| + |\overset{n}{\underset{k = 1}{\sum}}\sin{k}\sin{\frac{1}{k}}|
$ , I tried to find upper bounds for each module, but unsuccessfully.","['calculus', 'trigonometry']"
4564270,How to solve a system of 2 unknows with radical from the Vietnamese University Entrance exam?,"I am running into a problem of solving the following system of 2 equations and 2 unknows $x,y$ over the real $x \left(4 x^2+1\right)+(y-3) \sqrt{5-2 y}=0$ and $4 x^2+2 \sqrt{3-4 x}+y^2-7=0$ This problem belong to the Vietnamese University Entrance exam of Block A (Math, Physic and Chemistry) in 2010 My questions are: 1/ How to solve this challenging system a/ Exactly in a systematic way b/ Using numerical method 2/ Is there a general way to solve system with radical like this ? Note that the solution is $(x,y)=(\frac{1}{2} , 2)$ The link to the full exam paper is https://toanmath.com/2015/07/de-thi-va-dap-an-mon-toan-khoi-a-nam-2010.html Thank you for your enthusiasm Edit: To solve this system exactly, one can follow the method dictate from this post: General Principles of Solving Radical Equations","['contest-math', 'algebra-precalculus', 'systems-of-equations']"
4564271,Why does solving a derivative of sec(x) via power rule gets me a wrong value?,"I’m trying to get a derivative of $\sec(x)$ with respect to x. The correct derivative is $\dfrac{\sin(x)}{\cos(x)^2}$ , though this is not match the value that I was trying to solve. Since $\sec(x) =\dfrac{1}{ \cos(x)}, \sec(x)’ =\bigg(\dfrac{1}{\cos(x)}\bigg)’ =  \dfrac{-1}{\cos(x)^2}$ But when I applied a random value, such as $\frac{\pi}{3}$ , to the equation, the first (correct) derivative gets me 3.46 while the second one gets me -4. I wonder what I’m making a mistake on. I think the problem is I used power rule instead of quotient rule, but am not sure why power rule here gives me the wrong value. In fact, I tried to solve $x^{-1}$ using both quotient rule and power rule, both got me $\dfrac{-1}{x^2}$ .","['calculus', 'solution-verification', 'derivatives', 'trigonometry']"
4564284,Can a manifold have two different dimensions.,"We say that a manifold M is n-dimantional if it is locally Euclidean of dimension n, specifically if a
point p in M has a neighborhood $U_p$ such that there is a homeomorphism f from $U_p$ onto an open subset of $\mathbb{R}^n$ . My question is, can it be n-dimensional in some neighborhood and m-dimensional in another neighborhood. Are there such manifolds? How can we constract one?","['manifolds', 'geometric-topology', 'riemannian-geometry', 'differential-geometry']"
4564290,Find the length $x$ in $cm$ in the quadrilateral $ABCD$. [duplicate],"This question already has answers here : A geometry problem (length of side of a quadrilateral) (2 answers) Closed 1 year ago . This problem appeared in a remedial math class from my college last week. Someone I know, who attended the class, sent me this problem claiming that it was the toughest problem on the test. I'm sharing this problem here to see if there are any solutions that can be simpler than mine, which I'll also post. Edit: While I'm aware of a similar question already having been asked. The issue is that it is a general case, unlike this version of the problem, and thus lacks a Euclidean geometrical approach as I have demonstrated in my answer.","['contest-math', 'euclidean-geometry', 'geometry', 'trigonometry', 'algebra-precalculus']"
4564308,An interesting Legendre symbol identity: $\left (\frac{a}{p} \right ) = \prod_{h\in\mathscr{H}}^{}\frac{\sin(2\pi ah/p)}{\sin(2\pi h/p)}$,"If we call $\mathscr{H}$ a one-half set of reduced residues (mod $p$ ), $p$ is  a prime,  if $\mathscr{H}$ has the property that: $h \in \mathscr{H}$ if and only if $-h \notin \mathscr{H}$ Let $\mathscr{H}$ and $\mathscr{K}$ be two complementary one-half sets. They form the reduced residue system modulo $p$ . There are some propositions about $\mathscr{H}$ and $\mathscr{K}$ : if $(a, p) = 1$ . Let $\nu$ be the number of $h \in \mathscr{H}$ for which $ah \notin \mathscr{H}$ . That is $h \in \mathscr{H}$ but $ah \in \mathscr{K}$ . Then we can get: \begin{split}
   (-1)^{\nu} = \left(\frac{a}{p}\right)
  \end{split} $\left(\frac{a}{p}\right)$ is the Legendre symbol $(a, p) = 1$ , $a \mathscr{H}$ and $a\mathscr{K}$ are complementary one-half sets. That is $a \mathscr{H}$ and $a\mathscr{K}$ are disjoint and form the reduced residue system modulo $p$ . I wonder how to get the following equation: \begin{split}
\left(\frac{a}{p}\right)  = \prod_{h\in\mathscr{H}}^{}\frac{\sin(2\pi ah/p)}{\sin(2\pi h/p)} 
\end{split} for any integer $a$ and odd prime $p$ . Here are the hints: Notice that $a\mathscr{H} = (a\mathscr{H} \cap \mathscr{H}) \cup(a\mathscr{H} \cap \mathscr{K})$ . Consider the product of elements in $\mathscr{H}$ and $(\mathscr{H} \cap a\mathscr{H}) \cup(\mathscr{H} \cap a\mathscr{K})$ respectively, and they are equal.","['number-theory', 'trigonometry', 'quadratic-residues', 'elementary-number-theory']"
4564349,Cauchy-Schwarz inequality and Holder’s inequality,"Let $f, g \in L^2([-\pi , \pi ], \mu , \mathbb{R} )$ then I have already showed that $$ \int |fg| \,{\rm d} \mu \leq \|f\|_2 \|g\|_2 $$ and I have shown that this is an equality if and only if $|f|=c|g|$ almost everywhere or $\|f\|_2 \|g\|_2 =0$ . Now I have showed that $$ \left| \int fg \,{\rm d} \mu \right| \leq \|f\|_2 \|g\|_2 $$ and I am trying to show that this is an equality if and only if $f=cg$ almost everywhere or $\|f\|_2 \|g\|_2 =0$ . Now I know that $$\left| \int fg \,{\rm d} \mu \right| \leq \int |fg| \,{\rm d} \mu \leq \|f\|_2 \|g\|_2$$ and so these all must be equalities so I know that from the equality on the right, we must have $ |f|=c|g| $ almost everywhere or $\|f\|_2 \|g\|_2 =0$ but then with the equality on the right hand side I need to show that this means that $f=cg$ almost everywhere but I’m not sure how.","['cauchy-schwarz-inequality', 'measure-theory', 'lebesgue-measure', 'lebesgue-integral']"
4564355,Some properties of constant functions,"Let $\mathcal F(X, \mathbb R)$ be a collection of real-valued functions defined on a non-empty set $X$ . For each $k \in \mathbb R$ , let $\hat k \in \mathcal F(X, \mathbb R)$ with $\hat k(x) = k$ for all $x \in X$ . (1) Show $\mathcal C = \{\hat k: k \in \mathbb R\}$ is a linear subspace of $\mathcal F(X, \mathbb R)$ (2) Let $\alpha: \mathcal C \to \mathbb R$ as $\alpha(\hat k) = k$ . Show $\alpha$ is bijective and for any $k, k' \in \mathbb R, \ \alpha(\hat k + \hat {k'}) = \alpha(\hat k) + \alpha(\hat {k'})$ (1) I just want to see if I understand what they are asking and see if I can do it. By definition, $\hat k$ is in the set of real-valued functions on $X$ and so $\mathcal C \subseteq \mathcal F(X, \mathbb R)$ . Now we just have to show $\mathcal C$ satisfies all the axioms of the real valued vector space. For example, we must show $a \cdot (\hat j + \hat {j'}) = a \cdot \hat j + a \cdot \hat {j'}$ for $a \in \mathbb R, \hat j, \hat {j'} \in \mathcal C$ which is true because by definition of operations on real valued functions $a \cdot (\hat j + \hat {j'})(x) = a((\hat j + \hat {j'})(x)) = a(\hat j(x) + \hat {j'}(x)) = a\hat j(x) + a\hat {j'}(x)$ and $(a \cdot \hat j + a \cdot \hat {j'})(x) = (a \cdot \hat j)(x) + (a \cdot \hat {j'})(x) = a\hat j(x) + a\hat {j'}(x)$ . We check the rest of the axioms in a similar manner. Does that make sense ? (2) Suppose $\hat k \ne \hat {k'}.$ Then $k \ne k'$ meaning $\alpha(\hat k) \ne \alpha(\hat {k'})$ and so $\alpha$ is injective. By definition, $\hat k$ is defined for all reals and so if $y \in \mathbb R$ , there's always $\hat k(x) \in \mathcal C$ that maps to $y$ implying $\alpha$ is surjective. Now, $\alpha(\hat k + \hat {k'})(x) = \alpha(\hat k + \hat {k'})(x)) = \alpha(\hat k(x) + \hat {k'}(x)) = \alpha(\hat k(x)) + \alpha(\hat {k'}(x)) = k + k'$ and $\alpha(\hat k)(x) + \alpha(\hat {k'})(x) = \alpha(\hat k(x)) + \alpha(\hat {k'}(x)) = k + k'.$ Do these make sense ?","['elementary-set-theory', 'linear-algebra']"
4564379,Who first noted that entries in the powers of an adjacency matrix of a graph count the number of walks on the graph?,"The Wikipedia article on powers of an adjacency matrix presently (as of 2022) notes the neat combinatorial fact that, given an adjacency matrix $A$ of some graph, entries of the $n$ th power of the adjacency matrix, $A^n_{ij}$ , count the number of $n$ -length walks from $i$ to $j$ .  The Wikipedia article further relates this to the problem of counting the number of triangles in said graph by dividing the trace of $A^3$ by $6$ , and determining the distance between two nodes in an undirected, unweighted graph. The Wikipedia article does not name these as lemmas or theorems or corollaries, and states them with only the briefest outline of the proof. Are these folk results, or is there any other interesting history behind who first formulated and proved them? These are very nice and fun statements to prove, but I'm curious to know if there's anything else to say about their history. (I am especially interested in how quantum computers could efficiently explore spectral properties of certain large adjacency matrices of certain large graphs, as, by linearity, exponentiation of the spectrum corresponds to exponentiation of the given adjacency matrix - which then corresponds to counting various walks on the graph.)","['graph-theory', 'adjacency-matrix', 'matrices', 'algebraic-graph-theory', 'math-history']"
4564433,Verifying my proof of the intersection of $\sigma$-algebras is also a $\sigma$-algebra,"It has been a while since I've done proofs so I would like to verify if my proof is correct. I feel like I cheated or skipped a step but I am not sure how. Here is what I have to prove: Let $F_1$ and $F_2$ be two $\sigma -$ Algebras over a set $\Omega$ . Show that $F_1 \cap F_2$ is also a $\sigma -$ Algebra over a set $\Omega$ Claim: $F_1 \subset F_2$ or $F_2 \subset F_1$ or $F_1 \cap F_2 = \{\emptyset, \Omega \}$ Clearly if $F_1 \cap F_2 = \{\emptyset, \Omega \}$ then it is a $\sigma -$ Algebra over a set $\Omega$ Now, for the nontrivial case, WLOG, I claim $F_1 \subset F_2$ Assume by contradiction this is not the case. Let $A \subset F_1$ non-empty such that $A \cap F_2 = \emptyset$ so that $F_1 \backslash A \subset F_2$ $\quad$ ( $F_1$ minus $A$ ) $\therefore \quad (F_1 \backslash A)^c \subset F_2$ as $F_2$ is closed under set complements $\therefore \quad (F_1 \cap A^c)^c \subset F_2$ $\therefore \quad (F_1^c \cup A) \subset F_2$ $\therefore \quad A \subset F_2$ CONTRADICTION $\therefore \quad F_1 \subset F_2$ $\therefore \quad F_1 \cap F_2 = F_1$ which is $\sigma -$ Algebra over a set $\Omega$ Any help would be greatly appreciated, thank you!","['measure-theory', 'solution-verification']"
4564448,Params in change of variables in ODEs,"Let $\frac{dx}{dt} = x(a-bx)$ be a ODE with $a, b > 0$ . Considering the change of variables $s = \alpha t$ and $y = \beta x$ . I need to find $\alpha, \beta$ that transforms the equation into $\frac{dy}{ds} = y(1-y)$ . Appling the chain rule, I obtain $$
\frac{dy}{ds} = \frac{\frac{dy}{dt}}{\frac{ds}{dt}} = \frac{\beta}{\alpha} \frac{dx}{dt} = \frac{\beta}{\alpha} x (a-bx)
$$ And replacing $y = \beta x$ and simplifing I get $$
1 - \beta x = \frac{\beta}{\alpha}x(a-bx)
$$ How can i continue?",['ordinary-differential-equations']
4564480,How to take a Fourier transform of a $\text{sinc}$ function in the complex plane.,"Full disclosure: This is technically a ""homework"" question but not really. What I mean is that my professor gave us free reign to use Mathematica to simply get the answer to the integral but I am trying to go the extra mile and understand the full derivation, but I'm stuck. The problem is solving the Laplace equation for a finite strip. The solution which I've already derived is: $$V(x,y)=\frac{1}{2\pi}\int_{-\infty}^{\infty}\frac{2\sin{k}}{k}e^{ikx}e^{-|k|y}dk\tag{1}$$ He asks us to try to solve this integral by hand (and if we can't, to feel free to simply use Mathematica to get the answer) which I've been working on for a couple of hours. I've gotten as far as changing the integral to: $$V(x,y)=2\int_{0}^{\infty}dk\frac{\sin{k}}{k}e^{ikz}-2\int_{0}^{-\infty}dk\frac{\sin{k}}{k}e^{ikz^*}\tag{2}$$ Where $z\equiv(x+iy)$ . This is something like the Fourier transform that takes $\text{sinc}(k)\rightarrow\tilde{\text{sinc}}(z)$ but I've never evaluated a Fourier transform in the complex plane. I know I'm on the right track as the correct answer is: $$V(x,y)=-\frac{2}{\pi}\Im(\text{arctanh}(z^{-1}))\tag{3}$$ But I'm nevertheless stuck and would appreciate a hint or a nudge in the correct direction so that I see how to proceed. I have an inkling that the answer involves expressing $z^{-1}$ as $z^{-1}=\frac{d}{dz}\ln{z}$ and then evaluating the integral until you get something like $\frac{1}{z^*}-\frac{1}{z}$ and expressing that as $\frac{d}{dz}(\ln(z^*)-\ln(z))=\frac{d}{dz}\ln{\frac{z^*}{z}}$ which is closely related to arctan functions as discussed here but I don't quite see how to get there.","['complex-analysis', 'fourier-transform', 'ordinary-differential-equations']"
4564484,Stable under finite intersection,"Let $X$ a set, $\mathcal{P}(X)$ its power set and $\mathcal{T} \subset \mathcal{P}(X)$ . Is it true that $\mathcal{T}$ stable under finite intersection (i.e. $\forall A, B \in \mathcal{T}, A \cap B \in \mathcal{T}$ ) implies $X \in \mathcal{T}$ ? Since $|\emptyset| = 0$ and $\cap_{i \in \emptyset}A_{i} = X$ ?",['elementary-set-theory']
4564593,Banach space is separable iff Borel $\sigma$-algebra coincides with $\sigma$-algebra generated by open balls,"The question is essentially in the title. Let $X$ be a Banach space, $\mathcal B(X)$ be a Borel $\sigma$ -algebra, $\Sigma$ be a $\sigma$ -algebra generated by the collection of all open balls. Is it true that $X$ is separable $\Leftrightarrow$ $\Sigma=\mathcal B(X)$ ? ""If"" ( $\Rightarrow$ ) part is pretty straightforward and was already covered on this site numerous times: separability of $X$ implies that any open set is a union of at most countable number of open balls, so $\Sigma$ contains the whole topology of $X$ and, consequently, $\mathcal B(X)$ . I'm having trouble establishing the ""if only"" ( $\Leftarrow$ ) part. My attempt was to assume $X$ to be non-separable, so we can construct an open set $U$ which is a union of uncountably many pairwise disjoint open balls of equal radius ( see here ). It now seems reasonable to conclude that since $U$ can't be represented as a countable union of open balls this means (?) that $U\notin\Sigma$ . But I'm not sure whether this is even true: for example, is complement of a point a countable union of open balls if $X$ is non-separable? In other words, is any open set in $\Sigma$ indeed a countable union of open balls? I'd be glad for any hints for this question. Update (4th November, 2022) Following some references from this question on MathOverflow I've found the article by D. H. Fremlin where a similar question was posed and answered for the cylindrical $\sigma$ -algebra $\hat{\mathcal C}(X)$ generated by the dual space $X'$ . The following statement was proved there: $l^1(\aleph_1)$ is not separable, but $\mathcal B(l^1(\aleph_1))=\hat{\mathcal C}(l^1(\aleph_1))$ . More specifically, the following lemma was stated and proved: Lemma: If $X$ is an infinite set such that $2^{X\times X}=2^X\otimes2^X$ , then $\mathcal B(l^1(X))=\hat{\mathcal C}(l^1(X))$ . Here $\times$ denotes the Cartesian product and $\otimes$ denotes the product of $\sigma$ -algebras . Fremlin then refers to $2^{\aleph_1\times \aleph_1}=2^{\aleph_1}\otimes2^{\aleph_1}$ as a known result in set theory (I assume in ZFC), but his reference had not yet appeared in print when this article came out, so I'd have to search for it separately. All of this might be related to my question since $\Sigma$ can also be realised as a cylindrical $\sigma$ -algebra. I've yet to read the proof of the Lemma and see whether it could be adapted to answer my question. I hope this update will be usefull for others when thinking about this problem.","['banach-spaces', 'general-topology', 'measure-theory']"
4564768,Compute the following integral over a closed curve,"Let $\gamma$ denote the unit circle center at origin. compute the following integral. $$\int_\gamma \frac{e^z-e^{-z}}{z^4}dz$$ I guess I can solve this by integral by parts, $$\int_\gamma \frac{e^z-e^{-z}}{z^4}dz=\int^{2\pi}_0 \frac{e^{e^{it}}-e^{-e^{it}}}{e^{3it}}dt=\int^{2\pi}_0 \frac{e^{e^{it}}}{e^{3it}}dt-\int^{2\pi}_0 \frac{e^{-e^{it}}}{e^{3it}}dt$$ we first compute $\int^{2\pi}_0 \frac{e^{e^{it}}}{e^{4it}}dt$ . Let $u=e^{it}\implies du=ie^{it}dt$ and $dv=e^{3it}\implies v=e^{3it}/3i$ ,
hence we have $$[\frac{e^{it}e^{3it}}{3i}]^{2\pi}_0-\frac{1}{3}\int^{2\pi}_0e^{4it}dt=0$$ Similarily, $\int^{2\pi}_0 \frac{e^{-e^{it}}}{e^{3it}}dt=0$ Hence, we have the integral to be zero. But I was wondering if I can use any propositions relating to holomorphic functions on a disc to conclude that the above integral is zero since $\gamma $ is a closed curve. If I want to compute the integral this way, how should I begin? Thanks!",['complex-analysis']
4564769,Generating functions are functions?,"On this Wikipedia page it says the following: ""in fact, the generating function is not actually regarded as a function"". This comment is made only because we don't need convergence in a generating function?  I feel a bit confused, since for example, there are cases in which we must derive the generating function.  I would like to have a more formal idea of ​​this comment. Or it could be the case that Wikipedia is wrong","['definition', 'functions', 'generating-functions']"
4564806,first order quadratic ode,"I was given the ODE $$x'(t)=a^2-b^2x(t)^2$$ with $x(0) = 0$ and $a,b>0$ . From WolframAlpha I know that a solution is $x(t) = \frac{a\tan(ab(c+t))}{b}$ ignoring $x(0) = 0$ for now. I have tried to ""reverse engineer"" this solution. For instance, since I don't own WolframAlpha Pro, but I can see the first two steps of the solution, WolframAlpha rewrites the equation to $$\int \frac{\frac{dx}{dt}}{a^2-b^2x^2}dt = \int 1 dt.$$ I know that physicists often use a trick and cut "" $dt$ 's"" with one another like $\frac{dx}{dt} \cdot dt = dx$ . But that does not seem to help me. Another idea that didn't bring me far was to rewrite my ode to $$x'=(a-bx)(a+bx),$$ where I could use integration by parts. Here the problem is I am integrating with respect to t and I don't know anything about $x(t)$ . Help is appreciated.","['integration', 'ordinary-differential-equations']"
4564809,Prove solutions for $y'' = -y^3$ are periodic,"In physics, the equation $y''=-y^3$ represents the motion of a non-harmonic oscillator (for example, a mass between two walls with two springs that oscillates parallel to the walls). The solution is not given by elementary functions. I am trying to prove that the two solutions for this equation are periodic, without actually solving the equation. I tried to mimic the steps used to show that solutions to $y''=-y$ are periodic, but these heavily rely on the linearity of the equation (to solve by power series), as shown e.g. here . Proving  the solutions are bounded is pretty straightforward - Suppose we have initial conditions $y(0)=a, y'(0) = b$ . Multiplying our ODE by $y'$ yields $$
y'y'' = -y'y^3 \Longrightarrow \frac{1}{2}\frac{d}{dx}\left({y'}^2\right) = -\frac{1}{4}\frac{d}{dx}\left(y^4\right)\Longrightarrow{y'}^2+\frac{1}{2}y^4 = C
$$ where $C$ is some constant. Then by the intial conditions, $C = b^2 + \frac{1}{2}a^4$ , and we can see that $y$ is bounded by $\pm\left(2C\right)^{1/4}$ . But this still doesn't mean the solution oscillates periodically between $\pm(2C)^{1/4}$ .","['periodic-functions', 'ordinary-differential-equations']"
4564820,"For elliptic curve $E/{\overline k}, ~j(E)\in k\iff E$ can be defined over $k$?","Sorry for my bad English. Let $k$ be a field of any characteristic, and $E$ be an elliptic curve over $\overline{k}$ where $\overline{k}$ is an algebraic clouser of $k$ . Then we have the $j$ -invariant $j(E)\in \overline{k}$ . Now I want to know relationship between a condition $j(E)\in k$ and if $E$ can be defined over $k$ ; there is an elliptic curve $E'/k$ s.t. $E'\times_k \operatorname{Spec}\overline{k}\cong E$ over $\overline{k}.$ Especially, I want to know the case $k=\mathbb{F}_q$ for a prime power $q$ . Please give me hint, fact, paper, proof, or link.","['finite-fields', 'algebraic-geometry', 'elliptic-curves']"
4564842,Dividing bars of chocolate.,"Say you have $n$ people and $m$ bars of chocolate (of the same size) and you want to distribute the bars evenly among these $n$ people. But you're only allowed to cut a bar one time (in any way you want). Find all $m,n\ge 1$ such that you can do this. When $m\ge n$ we can group all the bars of chocolate in in a straight line and then cut the line by a ratio of $m/n$ . This way we're guaranteed to cut every bar at most once because if a bar has been cut more than one time then the distance between these two cuts is less that $1$ which impossible since $m\ge n$ . Now the problem is when $n>m$ . I saw an approach using graph theory but I don't know the theory very well. Is there any other way? I can solve $m=n-1$ we cut the bars in ratio of $1/n$ and $(n-1)/n$ . so that every person gets $(n-1)/n$",['combinatorics']
4564844,How can I prove that $X_n$ is a martingale iff $\Bbb{E}(X_T)=0$ for all bounded stopping times $T$,"Let me consider $(\Omega, F,(F_n)_n, \Bbb{P})$ . Let $(X_n)_n$ be an adapted process at $0$ . I need to show that $(X_n)_n$ is a martingale iff $\Bbb{E}(X_T)=0$ for all bounded stopping times $T$ . My idea was the following: $\Rightarrow$ Let me assume $X_n$ is a martingale and pick a bounded stopping time $T$ . Then from the stopping theorem we can immediately deduce that $$\Bbb{E}(X_T)=\Bbb{E}(X_0)=\Bbb{E}(0)=0$$ $\Leftarrow$ Now in the other direction I have some problems. I know that I want to show that $\Bbb{E}(X_{n+1}|F_n)=X_n$ but this is by definition equivalent to show that for all $B_n\in F_n$ we have $$\Bbb{E}(X_{n+1}\Bbb{1}_{B_n})=\Bbb{E}(X_{n}\Bbb{1}_{B_n})~~~~~~~~~~(1)$$ So it would be enough to show $(1)$ . But now I don't see how to do this. I somehow need to construct a bounded stopping time to use that $\Bbb{E}(X_T)=0$ . Could maybe someone help me further? What I found out in the mean time is that if $(B_n)$ is a disjoint collection of elements in $(F_n)_n$ then $T=\sum_{l=0}^\infty k\Bbb{1}_{B_k}$ is a stopping time.","['conditional-expectation', 'martingales', 'stopping-times', 'probability-theory', 'probability']"
4564873,Salt concentration differential equation,"There is a 100 liter container full with a 10 kg salt solution. There
is a 10% salt solution going into the container with 5liter/min speed,
which dissolves instantly with the solution in the container. The
solution exits the container at the bottom with the same speed. How
much salt will there be in the container after 2 hours? My solution goes like: Let $x(t)$ be the salts amount in the tank after t time $x(0) = 10 (kg)$ $t \Rightarrow t+Δt$ $x(t+Δt)-x(t) =$ ""The amount that flows in - The amount that flows out"" Flows in: 5l/min of 10% salt solution $\Rightarrow$ 0.5 kg of salt/min Flows out: $5l/min -> \frac{5}{100}$ x( t ) = $\frac{x(t)}{20}$ in $Δt$ minutes $Δt$ $\times$ $5l$ $\Rightarrow  \frac{Δt \times x(t)}{20}$ So the whole equation looks like this: ${x(t+Δt)-x(t)} = 0.5-\frac{Δt \times x(t)}{20}$ My question really is if this thought process for solving this is good, or if not where have I made a mistake? Also sorry for the terrible translation of the exercise.",['ordinary-differential-equations']
4564878,A geometric problem with families of congruent curves.,"Consider the following mapping: In a square grid on a unit disk we shift the angles between intersecting segments, every shift in general different at different $(x,y)$ points. Take the continuum limit. The image of the gridlines (i.e. the blue lines below) will be curves with the same lengths, but will be contained in a different domain $D$ (shaded blue below right). Moreover, each family (i.e. verticals and horizontals in the disk), is composed of congruent curves (meaning that they differ just by a translation and, or, a rotation; equivalently, that they have the same curvature). The question is Show that Perimeter $\left(D\right)<2\pi$ . Analytically, it can be re-formulated as follows. Let's call $0<\gamma(x,y)<\pi$ the shift angle at every point. Since the image curves are congruent within each family, we have that $\gamma(x,y)=\psi(x)-\phi(y)$ , being $\psi$ and $\phi$ arbitrary, not even functions (satisfying the condition on $\gamma$ for every $(x,y)\in\:$ Disk). Then \begin{align}
\text{Perimeter}\left(D\right)=\int_0^{2\pi}\mathbb{d}t\sqrt{1-2\sin t \cos t \cos\gamma(t)},
\end{align} with $\gamma(t)=\gamma(x=\cos t,y=\sin t)=\psi(\cos t)-\phi(\sin t)$ . The integrand in general varies between $0$ and $\sqrt{2}$ , so it is not immediate to establish that $\text{Perimeter}\left(D\right)<2\pi$ . Expanding the square root one can show that the quadratic terms satisfy some inequalities, but the linear term has no definite sign for any pair $\psi,\:\phi$ . So I don't think that handling this integral expression may lead to an answer, but rather some geometrical proof/analysis using the fact the curves are congruent.","['analytic-geometry', 'plane-curves', 'curves', 'geometry', 'real-analysis']"
4564890,Formula I don't understand in a textbook by L. Harwood Clarke: $\tan (A+B+C + \cdots) = \frac {s_1 - s_3 + s_5 - \cdots} {1 - s_2 + s_4 - \cdots}$,"I'm going through L. Harwood Clarke's A Notebook in Pure Mathematics from 1953 (William Heinemann Ltd.) and I find this in part $\text V$ : ""Trigonometry"" (Formula 21): $$\tan (A + B + C + \cdots) = \dfrac {s_1 - s_3 + s_5 - \cdots} {1 - s_2 + s_4 - \cdots}$$ stated with no comments. The interesting thing is that he has not defined $s_1$ , $s_2$ , $s_3$ , etc. I've looked through the rest of the book and can't find anything that suggests what they might be. The only thing that rings a bell is that the shape of the expressions on top and bottom of the RHS are reminiscent of the power series expansions of the sine and cosine functions respectively. Context: This is not me trying to get someone to do my homework for me, honest, I'm not trying to cheat on my degree course or anything, please believe me. I was given this book by my wife who found it while going through her parents' things while trying to get their house on the market. She thought her father would have liked me to have it, so she gave it to me.",['trigonometry']
4564940,Evaluate the limit of a sequence by Riemann sums and mean value theorem,"Calculate: $\displaystyle \lim_{n \rightarrow \infty} \left( \frac{n \pi}{4} - \left( \frac{n^2}{n^2+1^2} + \frac{n^2}{n^2+2^2} + \cdots \frac{n^2}{n^2+n^2} \right) \right)$ . I solved it by taking into account that $\displaystyle \int_0^{1} \frac{1}{1+x^2} \mathrm{d}x = \frac{\pi}{4}$ and let the given sequence be: $a_n= \displaystyle \frac{n \pi}{4} - \left( \frac{n^2}{n^2+1^2} + \frac{n^2}{n^2+2^2} + \cdots + \frac{n^2}{n^2+n^2} \right)$ Let $f(x) = \frac{1}{1+x^2}$ , then: $a_n = \displaystyle \frac{n \pi}{4} - \sum_{i=1}^n \frac{1}{1+\left( \frac{i}{n} \right)^2} = n \int_0^{1} f(x) \mathrm{d}x - \sum_{i=1}^n f\left( \frac{i}{n} \right) = n \sum_{i=1}^n \int_{\frac{i-1}{n}}^{\frac{i}{n}} f(x) \mathrm{d}x - n \sum_{i=1}^n \int_{\frac{i-1}{n}}^{\frac{i}{n}} f\left( \frac{i}{n} \right) \mathrm{d}x = n \sum_{i=1}^n \int_{\frac{i-1}{n}}^{\frac{i}{n}} \left( f(x)- f\left( \frac{i}{n} \right) \right) \mathrm{d}x$ Using Mean Value Theorem and doing a lot of calculations, I finally get that the limit is $\displaystyle \frac{1}{4}$ . Is it correct? Is there an easier method to solve the problem?","['limits', 'riemann-sum', 'mean-value-theorem', 'sequences-and-series']"
4564949,"An unfriendly question about ""friendly"" binary sequences","Question(IOQM-2022) : A binary sequence is a sequence in which each term is equal to $0$ or $1$ . A binary sequence is called friendly if each term is adjacent to at least one term that is equal to 1. For example, the sequence $0,1,1,0,0,1,1,1$ is friendly. Let $F_n$ denote the number of friendly binary sequences with $n$ terms. Find the smallest positive integer $n\geq 2$ such that $F_n>100$ . What I have tried till now: 1.We note that the second and the penultimate term of a friendly sequence must be $1$ as the end terms must be adjacent to $1$ for the sequence to be friendly. We can't construct new seqences out of those $n-length$ sequences that end with $0$ , since we already figured out that the number at penultimate place has to be 1. 2. Suppose we have an $n$ -length friendly sequence that ends with $1$ . We can construct two new friendly sequence of length $n+1$ by appending a $1$ and $0$ . Using these tw0 observations, I tried to calculate $F_n$ for small values of $n$ . $F_2=1$ $F_3=3$ $(1,1,0),(0,1,1),(1,1,1)$ are the terms here. We note that we have got an extra term other than thoe that 1. and 2. made us construct. This is (0,1,1). Note the tranformation: $(1,1,1)\rightarrow (0,1,1)$ . 3. Thus, we can take the $(n+1)$ sequences created in step 2. that end in $1$ and take the $n-1$ th term(which is $1$ here) from step 1 and replace it by zero. Thus, if $x$ is the number of $n$ -friendly sequences ending with $1$ , then $F_{n+1}=2.x+x=3x$ . Further, the number of $n+1$ -length friendly sequences ending with zero
will always be half the number of those ending with one. Further, if $x=\frac{2F_n}{3}$ , then, we get, $F_{n+1}= 2F_n$ And $x=2\frac{F_n}{3}$ for $n=3$ and thus, we can proceed by induction to obtain: $F_{n+1}=F_n.2$ for $n\geq 3$ I am skeptical about my deductions. Can anybody help me solve this problem?","['permutations', 'combinatorics', 'contest-math']"
4564959,Can any posterior follow given an appropriate prior?,"Let's assume we are given some observation $x$ , and two distributions $p(x | \theta)$ and $p(\theta | x)$ . What are the necessary conditions that allow a prior $p(\theta)$ to exist, such that Bayes' Theorem holds and $p(\theta|x)$ is the correct posterior following $p(\theta | x) = p(\theta) p(x | \theta) / p(x)$ ? I have only ever seen Bayes' rule in terms of probability densities but I guess you could think of it in terms of general probability measures $\mathcal{M}(\theta)$ on $\theta$ . So for an experiment with fixed observation $x_0$ and likelihood $p(x|\theta)$ we could think of it as an operation $\mathcal{B}_{x_0, p(x_0|\theta)}: \mathcal{M}(\theta) \rightarrow \mathcal{M}(\theta)$ that takes in a prior and updates our beliefs into a posterior. Are there any results what properties this operation has? Philosophically, I guess this question translates into: Can two persons who agree about the state of the world (i.e. $x$ ) and the way the world works (i.e. $p(x|\theta)$ ) come to arbitrary different conclusions (i.e. any posterior $p(\theta|x)$ ) if they only start with different opinions (i.e. $p(\theta)$ ) or are there some conclusions that you should never reach regardless of your prior opinion.","['probability-theory', 'probability-distributions', 'bayesian', 'bayes-theorem', 'probability']"
4564989,"An unfriendly question about ""friendly"" binary sequences","Question(IOQM-2022) : A binary sequence is a sequence in which each term is equal to $0$ or $1$ . A binary sequence is called friendly if each term is adjacent to at least one term that is equal to 1. For example, the sequence $0,1,1,0,0,1,1,1$ is friendly. Let $F_n$ denote the number of friendly binary sequences with $n$ terms. Find the smallest positive integer $n\geq 2$ such that $F_n>100$ . What I have tried till now: 1.We note that the second and the penultimate term of a friendly sequence must be $1$ as the end terms must be adjacent to $1$ for the sequence to be friendly. We can't construct new seqences out of those $n-length$ sequences that end with $0$ , since we already figured out that the number at penultimate place has to be 1. 2. Suppose we have an $n$ -length friendly sequence that ends with $1$ . We can construct two new friendly sequence of length $n+1$ by appending a $1$ and $0$ . Using these tw0 observations, I tried to calculate $F_n$ for small values of $n$ . $F_2=1$ $F_3=3$ $(1,1,0),(0,1,1),(1,1,1)$ are the terms here. We note that we have got an extra term other than thoe that 1. and 2. made us construct. This is (0,1,1). Note the tranformation: $(1,1,1)\rightarrow (0,1,1)$ . 3. Thus, we can take the $(n+1)$ sequences created in step 2. that end in $1$ and take the $n-1$ th term(which is $1$ here) from step 1 and replace it by zero. Thus, if $x$ is the number of $n$ -friendly sequences ending with $1$ , then $F_{n+1}=2.x+x=3x$ . Further, the number of $n+1$ -length friendly sequences ending with zero
will always be half the number of those ending with one. Further, if $x=\frac{2F_n}{3}$ , then, we get, $F_{n+1}= 2F_n$ And $x=2\frac{F_n}{3}$ for $n=3$ and thus, we can proceed by induction to obtain: $F_{n+1}=F_n.2$ for $n\geq 3$ I am skeptical about my deductions. Can anybody help me solve this problem?","['permutations', 'combinatorics', 'contest-math']"
4565003,Extending holomorphic 1-forms,"I'm working on the following problem: The holomorphic $1$ -form $\frac{dz}{1+z^2}$ ,
defined on $\mathbb{C}\setminus\{\pm i\}$ , can be extended to a
holomorphic $1$ -form $\omega$ on $\mathbb{P}^1\setminus\{\pm i\}$ . My idea is to choose two coordinate neighborhoods of $\mathbb{P}^1\setminus\{ \pm i\}$ (with one of them being a subset of $\mathbb{C} \setminus \{\pm i\}$ ), write down a holomorphic 1-form in each local coordinate, and show that they agree on the overlap. In particular, consider the coordinate patches $(U_1,z)$ and $(U_2, \frac{1}{z})$ where $U_1 = \mathbb{C} \setminus \{ \pm i\}$ and $U_2 = \mathbb{P}^1 \setminus \{0, \pm i\}$ . Let $w = \frac{1}{z}$ , then $f(w)dw = -\frac{1}{1 + w^2}dw$ is a holomorphic 1-form on $U_2$ . On $U_1 \cap U_2$ , one has \begin{equation*}
    f(w)dw = f(\frac{1}{z})\frac{\partial w}{\partial z}dz = (-\frac{z^2}{z^2 + 1})\cdot (-\frac{1}{z^2})dz = \frac{dz}{z^2 + 1}
\end{equation*} so one can patch $-\frac{dw}{1 + w^2}$ and $\frac{dz}{1+ z^2}$ together to obtain a holomorphic 1-form on $\mathbb{P}^1 \setminus \{ \pm i\}$ . I'm wondering whether this is correct? I'm not so sure because when I compute the pullback form $\tan^{*}(\omega)$ with respect to the map $\tan: \mathbb{C} \to \mathbb{P}^1 \setminus \{ \pm i\}$ , I don't get a unique expression. Specifically, the pullback form on $U_1$ is $dz$ , while the pullback form on $U_2$ is $-\frac{1}{1 + \tan(z)^2}\sec^2(z)dz = -dz$ , so I made at least one conceptual mistake.","['complex-analysis', 'riemann-surfaces', 'differential-geometry']"
4565008,"If a fair die (with 6 faces) is cast twice, what is the probability that the two numbers obtained differ by 2?","Don't think that this is my homework. Also, I do not have my graduation in mathematics. I was looking at different exams and their sample papers and came across this question... If a fair die (with 6 faces) is cast twice, what is the probability that the two numbers obtained differ by 2? (A) 1/12 (B) 1/6 (C) 2/9 (D) 1/2 I believe the answer is 2/9 and I want to find out if I am correct. For the first time rolling the dice, probability would be 1/6 (as per my knowledge)  there are 8 possible combinations for rolling the dice for the second time and difference between two numbers is equal to 2 1 -> 3

2 -> 4


   |-> 1
3 -|
   |-> 5

   |-> 2
4 -|
   |-> 6

5 -> 3

6 -> 4 And thus, final probability as per my knowledge should be (1/6)(8/6) = 2/9 Am I correct? Also I would welcome better approaches that can solve this problem more quicker.",['probability']
4565029,Question regarding convergence in the pth mean,"Here's what I am trying to prove: Let $\Omega = [0,1]$ , $1<p <\infty$ . Let $\{ f_n \}$ be a sequence in $L^p [0,1]$ such that $f_n \to f$ almost everywhere and $f \in L^p [0,1]$ . Suppose that there is some $M \in \mathbb R$ such that $\lVert f_n \rVert _p \le M$ for all $n$ . Prove that for $g\in L^q [0,1]$ where $1/p + 1/q =1$ , we have $\lim \int f_n g  d\lambda = \int fg d\lambda$ . Here $\lambda$ is the Lebesgue measure. Here's my poor attempt: Let $\{ f_n  \}$ be a sequence of functions in $L_p [0,1]$ . Since $\lVert \cdot \rVert _p$ is a continuous function on $L^p [0,1]$ and $\lVert f_n \rVert _p \le M$ for all $n$ , we have that $\lVert f \rVert _p \le M$ . If we try to estimate $\lvert \int f_n g d\lambda - \int fg d\lambda \rvert \le \lVert f_n -f \rVert _p \lVert g \rVert _q$ . If we could somehow how that $\lVert f_n - f \rVert _p \to 0$ as $n \to \infty$ , we will be done. There are certain things that I observe: we have a finite measure space and so almost everywhere convergence implies convergence in measure. However, convergence in measure will not possibly imply convergence in the $p$ th mean. So we are hopeless at this certain point.  However, I notice that I am not using the fact that $\lVert f_n \rVert \le M$ and $\lVert f \rVert \le M$ for each $n \in \mathbb N$ . I do not see how to use it as well. I am looking for hints that could possibly lead me to a solution to this problem. Any series of hints will be appreciated.","['measure-theory', 'real-analysis']"
4565059,What is the prerequisite trigonometry knowledge required to understand 2D vector rotation?,"I am trying to understand the why of $\,2$ D vector rotation. I know that I can use the following matrix to rotate a vector: $$
\begin{bmatrix}
\cos\theta & -\sin\theta \\
\sin\theta & \cos\theta \\
\end{bmatrix}
$$ I do not understand why this works; I know that trigonometry is involved (where my level of knowledge is basically to fallback to ""SOH CAH TOA"" to remember which function to use). I can identify the first column as being similar to how a point on a circle is calculated i.e. $$r\!\cdot\!\cos\theta\,,\;r\!\cdot\!\sin\theta$$ But as for the second column I am lost. I have been reading up on trigonometric addition which seems like the area I need to focus on, but I have not been able to map the formula to the matrix form.","['matrices', 'trigonometry', 'linear-transformations']"
4565098,Find slope of the tangent line of $4\sqrt x + 2e^\frac {3x-12}{x+2}$ at $ x_0$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question Find the slope and the equation of the tangent line to the
graph $y = f(x)$ at $x_0=4$ , $$4\sqrt x + 2e^\frac {3x-12}{x+2} $$ $$\lim_{h\to 0}\tfrac{4\sqrt {4+h} + 2e^\frac {12+3h-12}{4+h+2} - 10}{h} = \lim_{h\to 0}\frac{4\sqrt {4+h} + 2e^\frac {3h}{6+h} - 10}{h} $$ I am stuck at this part","['limits', 'calculus', 'slope']"
4565104,"Two non-comparable metrics on $X=C[0,\pi]$","Problem: Show that the two metrics $$d_1(x,y)=\sup_{[0,\pi]}t^2\lvert {x(t)-y(t)}\rvert\text{ and }d_2(x,y)=\sup_{[0,\pi]}\sin(t)\lvert {x(t)-y(t)}\rvert$$ are not comparable on the set $X=C[0,\pi]$ of real valued continuous function defined on $[0,\pi]$ . In particular, find a set $A\subset{X}$ that is open with the metric $d_1$ but not open with $d_2$ . Here, comparable means convergence of a sequence in one metric implies the convergence of it in the other with the same limit. Since this convergence relation can be characterized by means of being open, problem asks me to show it using open sets. Now, I find it very difficult to construct such a set $A\subset{X}$ . I believe it must be about the relation between the functions $sin(t)$ and $t^2$ . For instance, I tried $A=\{x(t)\in{X} \lvert x(\pi)\gt{0}\}$ and showed that this set is open with respect to $d_1$ . However, I do not know whether it is also open with respect to $d_2$ or not, and even if it is not open, it confuses me a lot, how to show it? Any comment/idea is highly appreciated.","['metric-spaces', 'real-analysis', 'function-spaces', 'functional-analysis', 'general-topology']"
4565199,"Evaluating $\int{\sqrt{x^2+4x+13}\, dx}$","I was trying to calculate with $\sinh$ : $$\begin{align}I&=\int{\sqrt{x^2+4x+13}\, dx}\\&=\int{\sqrt{(x+2)^2+9}\, dx}\end{align}$$ Now with $x+2=3\sinh(u)$ , $dx=3\cosh(u)\,du$ $$\begin{align}I&=3\int{\left(\sqrt{9\sinh^2(u)+9}\, \right)\cosh(u)\, du}\\&=9\int{\cosh(u)\sqrt{\sinh^2(u)+1}\, du}\\&=9\int{\cosh^2(u)\,du}\\&=\frac{9}{2}\int{\cosh(2u)+1\, du}\\&=\frac{9}{2}\left(\frac{1}{2}\sinh(2u)+u\right)+C\end{align}$$ How can I rewrite the $\frac{1}{2}\sinh(2u)$ in terms of $x$ ? I tried with the double angle formula, but this seemingly just complicates things by introducing $\cosh(u)$ also.","['integration', 'calculus']"
4565235,Concentration inequalities for random measures,"For random variables $X_1,\dots,X_n$ with common mean $\mathbb{E}[X_i]=\mu$ and common bounds $a\leq X_i\leq b$ , we have the very useful Hoeffding's inequality: $$\mathbb{P}\left(\left|\mu -\frac1n\sum_iX_i \right|\geq t\right)\leq 2\exp\left(-\frac{2nt^2}{(b-a)^2}\right).$$ I am interested in the following case: let $\nu_1,\dots,\nu_n$ be random measures (that is $\nu_i:\Omega \to \mathscr{P}(\mathbb{R})$ ), such that $\mathbb{E}[\nu_i]=\nu$ (where $\mathbb{E}(\nu_i):= \sum_{\omega\in \Omega} \mathbb{P}(\omega)\nu_i(\omega)$ ). Moreover, we have a similar boundedness assumption, $\text{supp}(\nu_i)\subseteq[a,b]$ . Is there a similar concentration inequality such as Hoeffding's that can be applied in this case? In particular, I am interested in whether one can say $$\mathbb{P}\left(\mathcal{W}\left(\nu,\frac1n\sum_i\nu_i \right)\geq t\right)\leq 2\exp\left(-\frac{2nt^2}{(b-a)^2}\right),$$ where $\mathcal{W}$ is the Wasserstein distance.","['random-measures', 'concentration-of-measure', 'wasserstein', 'probability-theory']"
4565307,Asymptotic solution of matrix differential equation expanded in powers of $1/x$,"Consider the differential equation $$
\frac{\text{d} y}{\text{d} t} = \left(c_0 + c_1 t^{-1} + c_2 t^{-2} + \dots c_n t^{-n} \right) y ;\quad y(1) = y_0 > 0; t \geq 1.
$$ where $c_i > 0$ for each $i$ . This can be solved directly and we find, for some $\alpha \neq 0$ , that $$
y(t) \sim  \alpha t^{c_1} e^{c_0 t}.
$$ where $f(t) \sim g(t)$ if $\lim_{t \to \infty} y(t)/g(t) = 1$ . I'm interested in the generalization of this result to the case of a system of differential equations. Basically, I think something like the following is probably true or almost true: Prop. 1 . Let $A_0$ be a $d \times d$ non-negative irreducible matrix with Perron-Frobenius eigenvalue $\lambda$ , and let $A_1, A_2 \dots A_n$ be nonnegative $d \times d$ matrices. Then, the system $$ \frac{\text{d} \mathbf{y}}{\text{d} t} = \left(A_0 + A_1 t^{-1} + A_2 t^{-2} + \dots A_n t^{-n} \right) \mathbf{y} ;\quad \mathbf{y}(1) = \mathbf{y}_0 > \mathbf{0}; t \geq 1. $$ has, for some $\alpha_i \neq 0$ and some $\beta_i$ , $$ |\mathbf{y}_i(t)| \sim \alpha_i t^{\beta_i} e^{\lambda t} \quad 1 \leq i \leq d. $$ Question : I'm looking for a reference which shows that Prop. 1 is true, or true provided with some other technical condition. It seems similar to Theorem 19.1 of Asymptotic Expansions for Ordinary Differential Equations by Wasow but I don't fully see the connection.","['lyapunov-exponents', 'asymptotics', 'ordinary-differential-equations', 'reference-request']"
4565321,Trajectories with predator-prey population in $xy$-plane,"I've been solving a predator-prey population DE successfully with programming. But I don't understand exactly what a trajectory in $xy$ -plane should look like or if I have done it correctly.
The predator-prey function looks like: $$\begin{cases}
\dfrac{dx}{dt} = x(1-  y) \\
\dfrac{dy}{dt} = y(0.9 x  - 1)
\end{cases}$$ I have reformulated the DE to the dynamic system: $$C = \ln(y) + \ln(x) - y - 0.9x$$ I ""replaced"" $C$ to the function and plotted it in the $xy$ -plane. But I'm not sure I have come up with a satifying answer to the question.","['ordinary-differential-equations', 'dynamical-systems']"
4565330,Strictly convex renorming of Banach space,"Banach space $X$ (or its norm) is said to be strictly convex if its unit sphere $S_X$ does not contain any nontrivial line segment. There is also stronger notion of uniform convexivity. We say that space $X$ is uniformly convex if for any $\varepsilon > 0$ there exists $\delta > 0$ such that for any $x,y \in S_X$ $$ \|x - y\| \geq \varepsilon \implies \Bigl \|\frac{x+y}{2} \Bigr \| \leq 1 - \delta. $$ It follows from parallelogram identity that every inner product space is uniformly convex. Moreover, it is known that $L_p$ spaces are uniformly convex for $1 < p < \infty$ . On the other side there are classical spaces, such as $C[0,1], L_1, c_0, c$ , which are not strictly convex (when equiped with their standard norms). Some of these spaces admit equivalent and strictly convex renorming. For example in $c_0$ space there is norm $$ \|x\|_{sc} = \sup_{n \in \mathbb{N}}|x_n| + \Bigl( \sum_{n=1}^{\infty} \frac{1}{2^n} |x_n|^2 \Bigr)^{\frac{1}{2}}$$ which is strictly convex and equivalent to the classical norm $\|x\| = \sup_{n \in \mathbb{N}} |x_n|$ . $\textbf{My questions}:$ Does every Banach space admit strictly convex (not necessarily equivalent) renorming? If not, is there some class of B spaces, for which such renorming exists? What about uniformly convex renorming?","['banach-spaces', 'functional-analysis']"
4565337,An application of the pigeonhole principle on a $7\times 7$ board,"Before moving on to my main question, I would like to write the basic question that I know the solution method well. Basic Question: Prove that no matter how $50$ points are chosen from inside or over a square with a side length of $7$ units, there are two points with a distance is $\leq \sqrt{2}$ between them. Solution: Let's split the board in $7\times 7$ type. So we have $49$ unit squares. According to the pigeonhole principle, $ \left\lfloor\dfrac{50}{49}\right\rfloor + 1 = 2$ points are in or on the same square. The distance between them is $\leq \sqrt{2}$ . At this stage, the following question came to my mind: Main Question: No matter how $n$ points are taken from inside (or over) a square with side lengths of $7$ units, there can always be a pair of points whose distance is $\leq \sqrt{2}$ unit. What is the smallest value of $n$ that makes this condition possible? At first I thought the answer would simply be $50$ . I tried to place the points as close to each other as the distance between them was slightly greater than $\sqrt{2}$ . I got $32$ points. So I feel that $n = 32+1=33$ is the minimum desired value. I have no rigorous proof. Thank you for your advice and assistance.","['pigeonhole-principle', 'combinatorics']"
4565430,"Classify all matrices $A,B$ such that $AB\ne BA$, but there is some $n>1$ such that $(AB)^n=(BA)^n$","Recently when teaching the basics of matrices, a student asked if there are matrices $A,B$ for which $AB\ne BA$ , but for some $n>1$ we have $(AB)^n = (BA)^n$ ? I was able to come up with a few cases where the answer is yes. If both $AB$ and $BA$ are nilpotent, then the result is obvious; take $n$ to be the maximum power that kills both. Another nice case is if $A,B$ are rotation matrices in dimension $d\ge 3$ (so they don't commute) and are both rotations by rational multiples of $2\pi$ . In particular, the case where $d=3$ and $A$ is a rotation about the $x$ -axis by $\pi/2$ and $B$ is a rotation about the $y$ -axis by $\pi/2$ readily gives $AB\ne BA$ but $(AB)^3=(BA)^3=I$ . The student is a fan of Rubik's Cubes so I think this will make a nice example. My gut says other geometric-flavored matrices (i.e., reflections) will also have this property. However, I want to ask a follow-up question, namely to classify all such matrices with this property. Writing $A=PS P^{-1}$ and $B=PT P^{-1}$ for some matrix $P$ is intractable, as we have $$
(AB)^n = P (ST)^n P^{-1} ; (BA)^n = P(TS)^n P^{-1},
$$ which gets us nowhere. Is there some nice classification of these matrices?","['matrices', 'linear-algebra', 'rotations']"
4565434,"Characterizing continuous, open and closed maps via interior and closure operators","A function $f :X \to Y$ between topological spaces $X,Y$ is defined to be continuous if $f^{-1}(V)$ is open in $X$ for all open $V \subset Y$ , open if $f(U)$ is open in $Y$ for all open $U \subset X$ , closed if $f(C)$ is closed in $Y$ for all closed $C \subset X$ . Many questions in math.stackexchange deal with alternative characterizations of these properties in terms of the behavior of the operators $\operatorname{int}$ (interior) and $\operatorname{cl}$ (closure) with respect to $f$ and $f^{-1}$ . A recent example is Characterization of Continuous, Closed and Open maps . In virtually all textbooks on general topology one can find theorems about such characterizations, but it seems that a complete list is not available. There are eight properties which can be formulated in terms of interior and closure: For all $A \subset X$ resp. $B \subset Y$ (1) $f(\text{int} A) \subset \text{int} f(A)$ (2) $f(\text{int} A) \supset \text{int} f(A)$ (3) $f^{-1}(\text{int} B) \subset \text{int} f^{-1}(B)$ (4) $f^{-1}(\text{int} B) \supset \text{int} f^{-1}(B)$ (5) $f(\operatorname{cl} A) \subset \operatorname{cl} f(A)$ (6) $f(\operatorname{cl} A) \supset \operatorname{cl} f(A)$ . (7) $f^{-1}(\operatorname{cl} B) \subset \operatorname{cl} f^{-1}(B)$ (8) $f^{-1}(\operatorname{cl} B) \supset \operatorname{cl} f^{-1}(B)$ . Question: Try to identify each of these properties with $f$ being continuous, open or closed.","['closed-map', 'continuity', 'general-topology', 'open-map']"
4565438,Probability of this event,"Let $S$ be a set of 27 pairwise different numbers. Let $T$ be a set of 9 elements chosen from $S$ uniformly at random (no repetitions). Let $u$ be an element sampled uniformly at random from $T$ . Let $S'= \{s_1, s_2, \dots, s_{27}\}$ be the sequence of elements in $S$ but in increasing order. Given that $u$ is in the middle third of $T$ , what is the probability that the $i$ -th element from $S'$ was selected. This is my attempt. On the one hand, I’m not sure if $\mathbb P(u = s_i) = 1/21$ , where $i = 4, 5, \dots, 24$ , and 0 otherwise. On the other hand, I don’t know if the answer should be $$\mathbb P( u = s_i) = {27\choose 9}^{-1}\times\sum^{8}_{j=0} {{i-1}\choose{9+j}}\cdot{{27-i}\choose{18-j-1}},$$ where $i = 4, \dots, 24$ and 0 otherwise.","['discrete-mathematics', 'probability']"
4565477,Intuition behind the Riemann curvature as a map $\bigwedge^2 T^*M\to \bigwedge^2 T^*M$?,"Given a (pseudo)-Riemannian manifold $(M^n ,g)$ , one can naturally define the Levi-Cevita connection $\nabla_g: \Gamma(TM)\to \Omega^1(M,TM)$ as the unique metric-compatible, torsion-free connection on $TM$ . This allows us to define the Riemann Tensor: $R: TM\otimes TM\to \mathrm{End}(TM)$ by $$R(\xi_1,\xi_2)(\xi_3):=([\nabla_{g,\xi_1}, \nabla_{g,\xi_2}]-\nabla_{[\xi_1,\xi_2]})\xi_3.$$ Since the map $(\xi_1,\xi_2,\xi_3,\xi_4)\mapsto \langle R(\xi_1,\xi_2)\xi_3,\xi_4\rangle$ is antisymmetric in the first and second slots, as well as in the third and fourth slots, it descends to a map $\bigwedge^2TM\to \bigwedge^2 T^*M$ or equivalently $\bigwedge^2 T^*M\to \bigwedge^2 T^*M$ by precomposition by the correct bundle isomorphism induced by $g$ . Is there a nice way to think of this endomorphism, i.e. as some sort of shearing/rotation of oriented planes, or is it just a mathematical mirage?","['curvature', 'riemannian-geometry', 'differential-geometry']"
4565483,"Asymptotic expansion of $\small\sum_{k=1}^n H_k^{-1}$, where $\small H_k$ are harmonic numbers","I'm interested in an asymptotic expansion of $\,\sum_{k=1}^n H_k^{-1}$ for $\,n\to\infty$ , where $H_k=\sum_{m=1}^km^{-1}$ are harmonic numbers. I would like all terms in the expansion to use $H_n$ rather than $\log n$ to avoid irrational numbers where possible. So far, I have figured the two initial terms by replacing the harmonic numbers with their asymptotic expansion $H_n\sim\log n+\gamma+O\!\left(n^{-1}\right)$ and approximating the sum by the corresponding integral. If I haven't made any mistakes, then $$\sum_{k=1}^n H_k^{-1}\sim n\,H_n^{-1}+n\,H_n^{-2}+O\!\left(n\,H_n^{-3}\right).$$ But computations become more complicated after that, so I couldn't make any further progress. Could you propose an approach that allows to compute more terms, or find a general formula for them?","['harmonic-numbers', 'sequences-and-series', 'asymptotics', 'real-analysis']"
4565504,Analytic equivalent on the extended complex plane,"I'm confused because, in class, we've started working in the extended complex plane and just assuming all the properties we've worked with in the normal complex plane carry over. Here are the properties I'm confused with in particular: Analyticity: I don't think this is equivalent to being holomorphic, because I can't see any way we can create a power series centered around infinity. Holomorphicity: Maybe we can call a function holomorphic at infinity if it's differentiable for all complex numbers of a certain magnitude or greater, but I don't know how to make that rigorous, especially since a circle around infinity is normally thought of as a straight line. Conformal maps: What would it even mean to have angles conserved for curves going through infinity. If it helps, what got me thinking about this was when we were talking about the conformal automorphisms on the extended complex plane and our definition for an automorphism was an analytic, invertible map from a set to itself. My question is how these properties are dealt with in the extended complex plane? Can we define them, and, if not, what do we use instead?","['complex-analysis', 'analysis']"
4565508,How many arrangements of the word $ABBBCCDD$ contain the subword $BCD$?,"Context: While brushing up on some combinatorics, I came across a problem that I couldn't get the correct answer to. After looking at this question , I saw that I was double counting some cases, so I have tried to fix my reasoning. It would be nice to get confirmation as to whether or not my reasoning is now correct. The problem: How many arrangments of the word $ABBBCCDD$ contain the subword $BCD$ ? My approach: There are 6 ways to place the subword $BCD$ . Let's say we have the following $$\#\#\color{blue}{BCD}\#\#\#$$ Next, there are $C(5,2)$ ways to place the remaining $B$ 's, and then $3!$ ways to place the remaining letters. Say we get the arrangement $$\color{red}{AB}\color{blue}{BCD}\color{red}{BCD} \ \ \ (*)$$ In total, we have $$6 \cdot C(5,2) \cdot 3! = 360$$ arrangements, however we have overcounted. The problem is that we could have obtained the arrangement in $(*)$ another way; initially placing $BCD$ at the end, and then filling in the rest of the letters. Thus, arrangements with two occurrences of $BCD$ get double counted. Conversely, if $BCD$ only occurs once, that arrangement does not get double counted, so we need to subtract the number of arrangements with $BCD$ occuring twice from $360$ . There are $C(4,2) \cdot 2$ arrangements with two occurences of $BCD$ , so the final answer is $$360 - C(4,2) \cdot 2 = 348.$$ My question: Is my approach okay? Am I missing any over/under counts?","['permutations', 'combinations', 'combinatorics']"
4565535,Proving that $\ln\frac{1-x}{\sqrt{1-2\delta(1-x)}-x}$ is convex with respect to $x$,"I am working on an optimisation problem and I am trying to prove that a binary function is convex for one of its independent variables. The function is: $$f(x,\delta)=\ln \frac{1-x}{\sqrt{1-2\delta(1-x)}-x},$$ where $x \in [0,1]$ and $\delta \in \left[0,\dfrac{1}{2}\right]$ . I want to prove that $f(x,\delta)$ is a convex function of $x$ . Actually, I have learned that it is true using Mathematica by graphing it, except at the point that $x=1$ . However, I do not know how to prove it mathematically. I have already tried to prove it by calculating $\dfrac{\partial^2 f}{\partial x^2}$ , which is $$-\frac{1}{(-1+x)^2}+\frac{\left(-1+\frac{\delta}{\sqrt{\smash[b]{1-2(1-x) \delta}}}\right)^2}{(-x+\sqrt{1-2(1-x) \delta})^2}+\frac{\delta^2}{(1-2(1-x) \delta)^{3 / 2}(-x+\sqrt{1-2(1-x) \delta})}.$$ However, I cannot prove that it is always larger than $0$ . I hope someone can give me some help. Thanks in advance!","['multivariable-calculus', 'convex-analysis']"
4565562,Bijective function between $\mathbb{R}^n$ and $\mathbb{R}^m$,"I suspected that it was not possible to define a bijection $f \colon \mathbb{R}^m \to \mathbb{R}^n$ where $m,n \in \mathbb{N}$ and $m>n$ . After coming across Why are the cardinality of $\mathbb{R^n}$ and $\mathbb{R}$ the same? , I now suspect that it is in fact possible to define a bijection $f \colon \mathbb{R}^m \to \mathbb{R}^n$ . My reasons for believing that such a bijection exists: This being established, we can say that there exists a bijection $g \colon \mathbb{R}^m \to \mathbb{R}$ . By the same argument, there exists a bijection $h \colon \mathbb{R} \to \mathbb{R}^n$ . Thus the function $h \circ g \colon \mathbb{R}^m \to \mathbb{R}^n$ is bijective. Can I now conclude that $\mathbb{R}^m$ and $\mathbb{R}^n$ have the same cardinality. So, does the set of all $m$ tuples with real entries have the same number of elements as the set of all $n$ tuples with real entries, even when $m\neq n$ ?","['elementary-set-theory', 'real-numbers', 'cardinals']"
4565589,Show that $\int_0^1 (\sin{x}-4/9)^3dx<0$ without a calculator.,"In this age of electronic devices, sometimes I like to challenge myself to find clever ways to find solutions to math problems that seem to require a calculator, without a calculator. ( Here is a favorite example.) I recently came up with this: Without a calculator, show that $$\int_0^1 \left(\sin{x}-\frac{4}{9}\right)^3dx<0$$ It's a pretty close shave: my computer says the LHS $\approx −0.0000050...$ . The exact value of the LHS is: $$\frac{1}{729}\left(972(2+\cos{1})\sin^4{0.5}-243(2-\sin{2})+432(1-\cos{1})-64\right)$$ I tried to use Maclaurin series, but that seems to be futile. I also tried to find some kind of useful symmetry of the graph of $y=\sin{x}-\frac{4}{9}$ , but to no avail. Any clever way to do this? Just curious.","['integration', 'calculus', 'inequality']"
4565610,Proof of an upper bound of the product of binomial coefficients on a same row of Pascal triangle [duplicate],"This question already has an answer here : A product inequality with binomial coefficients [duplicate] (1 answer) Closed 1 year ago . We have to prove the following inequality: $$\forall n \in \mathbb{N}, n \ge 2, \ \ \Pi_{k=0}^n \binom{n}{k} \le \left(\frac{2^n-2}{n-1}\right)^{n-1}$$ the progress where I am at, is visible in the following picture: I'm especially confused, since the term (2*((n-1)/n)) has the limit zero when calculated to infinity and the other term diverges to infinity when calculated there.
so the first question would be, if these two terms are multiplied, which limit comes out as a result? the second question would be simply how to continue on from there, or if you know a better way to approach this inequality proof. I am very thankful for your helpful answers.","['inequality', 'solution-verification', 'induction', 'analysis']"
4565626,Planar Quartic Curve invariants for number of connex components,"I have some affine planar quartic curves over $\mathbb{R}$ (of the general form $a x^4 + b x^3y + c x^2 y^2 + d xy^3 + e y^4 + fx^3 + g x^2y + h xy^2 + i y^3 + j x^2 + k xy + l y^2 + m x + n y + p= 0$ with $(a,b,c,d,e,f,g,h,i,j,k,l, m,n,p)\in \mathbb{R}^{15}$ ) that I know for sure describes either: The empty set 1 point 2 points 3 points 4 points This is the case because it is the sum of the square of two different conics, so it describes the intersection which cannot be a full overlap. I would like to count those points (using a closed form if possible). I thought about finding some invariant describing the number of connected component of the curve or something like that (maybe the number of bitangent too, knowing that not every quartic get 28 bitangents), but I could not find a reference listing the known invariants of the planar quartics and describing them. Does anyone have a reference of that sort?","['plane-curves', 'algebraic-geometry', 'reference-request']"
4565641,Can one deduce $\lim_{n\rightarrow\infty}P(X_n>1)=0$ from $P(X_n>1+\frac{x}{2\log n})\leq e^{-x}\quad\forall x$,"I want to control the tail probability of some random variable $(X_n)_n$ . (In particular, $X_n = \max_{1\leq i\leq n} N_i$ , where $N_i$ are independent standard normal)
I come up with the following two upper bounds:
(1) $$P(\frac{X_n}{\sqrt{2\log n}}>1+\frac{x}{2\log n})\leq e^{-x}\quad\forall x>0.$$ Can I deduce $\lim_{n\rightarrow\infty}P(\frac{X_n}{\sqrt{2\log n}}>1)=0$ from it? I only know that for every $\epsilon_1,\epsilon_2>0$ , there exists $N_1$ such that for every $n>N_1$ , we have $$P(\frac{X_n}{\sqrt{2\log n}}>1+\epsilon_1)\leq \epsilon_2.$$ I have no idea how to do next. (2) $$P(\frac{X_n}{\sqrt{2\log n}}\leq \alpha)\leq (1-n^{-\alpha+o(1)})^n\quad 0<\alpha< 1 .$$ Can I deduce $\lim_{n\rightarrow\infty}P(\frac{X_n}{\sqrt{2\log n}}< 1)=0$ from it? I only know $\lim_{n\rightarrow\infty}(1-n^{-\alpha+o(1)})^n=0$ . Don't know how to deal with $\alpha$ inside the probability. (3) Suppose we have $$P(\frac{X_n}{\sqrt{2\log n}}>1+\frac{x}{2\log n})\leq e^{-x}\quad\forall x>0.$$ and $$P(\frac{X_n}{\sqrt{2\log n}}\leq \alpha)\leq (1-n^{-\alpha+o(1)})^n\quad 0<\alpha< 1 .$$ Can we deduce $\frac{X_n}{\sqrt{2\log n}}\rightarrow 1$ in distribution?","['limits', 'probability-theory']"
4565650,"Hidden property of the graph of $y=\tan{x}$: infinite product of lengths of zigzag line segments converges, but to what?","On the graph of $y=\tan{x}$ , $0<x<\pi/2$ , draw $2n$ zigzag line segments that, with the x -axis, form equal-width isosceles triangles whose top vertices lie on the curve. Here is an example with $n=6$ . It seems that, as $n\to\infty$ , the product of their lengths converges to a positive number. The limit is: $$L=\lim\limits_{n\to\infty}\exp{\sum\limits_{k=1}^n}\ln{\left(\left(\frac{\pi}{4n}\right)^2+\tan^2{\left(\frac{2k-1}{4n}\pi\right)}\right)}$$ Desmos suggests that $L\approx 2.50917847$ . I am looking for a closed form for this limit. I've been trying to apply what I learned about sums of logs in a previous question of mine, but I still have not been able to evaluate this one. If we change the graph to $y=\tan{\left(\frac{\pi}{2}x\right)}$ , $0<x<1$ , the corresponding limit seems strikingly similar to $\frac{1}{2}\left(e+\frac{1}{e}\right)$ , based on computer calculation. So, assuming that is the correct limit in that case, I would expect the limit in this question, $L$ , to look something along those lines. I find it interesting that a geometrical infinite product, that is neither $0$ nor $\infty$ , exists in such a simple geometrical construction, without needing to make any modifications. EDIT: Thanks to @Jean Marie's comment, I am very confident that $L=\cosh{(\pi/2)}$ . But how to prove this?","['closed-form', 'sequences-and-series', 'infinite-product', 'limits', 'trigonometry']"
4565670,How can differential entropy be negative?,"Entropy is defined as $$H(x) = E_{x\sim p(x)}[ - \log p(x)]$$ and $- \log p(x) \geq 0$ so it makes sense that the expectation is always non-negative, here is a proof . However, Wikipedia says the entropy of a normal distribution is $\tfrac{1}{2} \ln(e2\pi\sigma^2 $ ), which means that the entropy can be negative for some values e.g. $\sigma = 0.01$ but how can be this be the case and how can it be interpreted?","['probability', 'information-theory']"
