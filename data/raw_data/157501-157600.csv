question_id,title,body,tags
2691062,"Sum of functions, maximum property","so i came along the following post Maximization of sum of two functions and I would like to know how for any given functions $f(x),g(x)$ we can prove that: $\max(f+g)<=\max f+ \max g$ I do have a small hint about triangle inequality but i am not sure. Any ideas?",['functions']
2691090,Are all power automorphisms of a finite abelian group of the form $f(x)=x^n$?,"An example of a universal power automorphism, that is automorphisms of the form $f(x)=x^n$, is easy to find in an abelian group. Any power $n$ will work as long it is relatively prime to the orders of all elements of the group. More generally, a power automorphisms sends any $g \in G$ to a power of $g$. Equivalently, it maps all subgroups $H$ of $G$ to H. My hunch is that any power automorphism of an abelian group must be a universal power automorphism. Is this true? (In general, power automorphisms that aren't universal power automorphisms do exist for finite groups. See my question here . The example in that case is non-abelian, however.)","['finite-groups', 'power-automorphism', 'group-theory', 'automorphism-group']"
2691154,Intuition behind the conditional distribution of sum of two Poisson random variables,"Let $X$ and $Y$ be two independent random variables, where $X\sim \operatorname{Pois}(\lambda_1)$ and $Y\sim \operatorname{Pois}(\lambda_2)$. It's fairly straightforward to show mathematically that $$P(X=x\mid X+Y=n) = \binom n x \left(\frac{\lambda_1}{\lambda_1+\lambda_2}\right)^x \left(\frac{\lambda_2}{\lambda_1+\lambda_2}\right)^{n-x},$$ which shows that given $X+Y=n$, $X\sim \operatorname{Binom}\left(\frac{\lambda_1}{\lambda_1+\lambda_2},n\right)$. Is there any intuitive way to understand this result in terms of Poisson point processes, or is this simply a convenient mathematical property?","['statistics', 'probability', 'probability-distributions']"
2691198,Calculating the Moore-Penrose inverse of an incidence matrix,"I'm trying to understand a method for calculating the
Moore-Penrose inverse of an incidence matrix of a graph
as outlined in ""Graphs and Matrices"" (you can find the
book here: https://link.springer.com/book/10.1007/978-1-4471-6569-9 ).
I can execute all the steps for calculating the inverse but
I haven't yet fully understood why the method works: The line I don't understand is on page 20 and reads
""By Lemma 2.14 it follows that $Y=D'X$."" I don't see how
Lemma 2.14 is connected to this statement and would appreciate
it if anyone could help me understand this line. If you cannot access the book or don't want to get familiar with
the notation the author uses, here's a summary of what I don't
understand which hopefully includes all the relevant information: Summary of the problem The transpose of a matrix $A$ will be denoted by $A'$. Consider a connected directed graph $G$ with vertices
$V=\left\{1,\ldots,n\right\}$ and edges
$E=\left\{e_1,\ldots,e_m\right\}$ with the edges ordered in such
a way that $\left\{e_1,\ldots,e_{n-1}\right\}$ form a spanning
tree of $G$. Let $Q$ be the $n\times m$ incidence matrix of $G$.
To cite ""Graphs and Matrices"", ""the rows and the columns of $Q$
are indexed by $V$ and $E$, respectively. The $\left(i,j\right)$-
entry of $Q$ is $0$ if vertex $i$ and edge $e_j$ are not incident,
and otherwise it is $1$ or $-1$ according as $e_j$ originates or terminates at $i$, respectively."" See the following example where the spanning tree is highlighted
in red: Now, one wants to calculate the Moore-Penrose inverse $Q^+$ of
$Q$ (which implies that the following four conditions hold:
(1) $QQ^+Q=Q$, (2) $Q^+QQ^+=Q^+$, (3) $\left(QQ^+\right)'=QQ^+$,
(4) $\left(Q^+Q\right)'=Q^+Q$). To do so, the author partitions $Q$ as $Q=\begin{bmatrix}
	U & V
\end{bmatrix}$ where $U$ is $n\times\left(n-1\right)$ and $V$ is
$n\times\left(m-n+1\right)$ and $Q^+$ as $Q^+=\begin{bmatrix}
	X \\ Y
\end{bmatrix}$ where $X$ is $\left(n-1\right)\times n$ and $Y$ is
$\left(m-n+1\right)\times n$. He then notes that ""there exists an
$\left(n-1\right)\times\left(m-n+1\right)$ matrix $D$ such that
$V=UD$."" I still understand why this is the case. However, I'm stuck
at the next sentence, which says ""By Lemma 2.14 it follows that
$Y=D'X$."" Lemma 2.14 says: If $A$ is an $m\times n$ matrix, then for an $n\times1$ vector $x$,
  $Ax=0$ if and only if $x'A^+=0$. I don't see how the Lemma can be applied to see that $Y=D'X$. I tried a few approaches but none led to any result and I don't want
to list them all here. Just leave a comment for more details. Maybe I'm missing something obvious but I really can't seem to find a way to reach the same conclusion as the author. Thanks in advance for any help!","['matrices', 'graph-theory', 'pseudoinverse', 'linear-algebra']"
2691206,Could anyone pass me some survey or books that display what is known about the surfaces of constant mean curvature?,"Could anyone pass me some article (survey) or books that display what is known about the surfaces of constant mean curvature? Preferably to articles or books with a lighter reading, otherwise you can send what you have. ;) I have searched the internet, but I find little of what I want.","['riemannian-geometry', 'reference-request', 'book-recommendation', 'differential-geometry', 'surfaces']"
2691222,Solving recurrence relation with floor and square root,"I would like to solve the following recurrence:
$$a_0 = 1$$
$$a_n = a_{n-1} + \lfloor\sqrt{a_{n-1}}\rfloor$$
Some observations I've made: The sequence increases by a sequence of increasing numbers (obviously), with each positive integer being the difference between the terms of the sequence either twice or thrice, since $\frac{(m+1)^2 - m^2}{m} = 2 + \frac{1}{m}$ If $a_n = m^2$, then the relation above means means that $a_{n+k} = m^2 + km$, for $k = 0, 1, 2, 3$ However I cannot see how to generalize those observations further to get a closed form of the recurrence.","['recurrence-relations', 'sequences-and-series', 'discrete-mathematics']"
2691230,How can I solve the following ode,"$$C\frac{dT}{dt}=-\sigma T(t)^{4}+(1-\alpha)Q$$ I need help to solve the above pde where $C,\alpha ,Q$ are constants, I'm really unsure on how to even start to solve it","['partial-derivative', 'ordinary-differential-equations']"
2691291,Fourier series of the inverse of a function,"Suppose you have a function $F:[-\pi,\pi]\to [-\pi,\pi]$ that is strictly increasing, has a continuous derivative, and we know its Fourier coefficients (so we know also the Fourier coefficients of the derivative). Is there a way to find the Fourier series of the inverse function $F^{-1}$? 
(Note: the inverse, not the reciprocal) I tried to compute them, but I get nested trigonometrical function like $\cos(n\cos(kx))$ and there seem not to be a wayout... My approach: suppose that 
$$F(x) = a_0 + \sum a_n\cos(nx) + b_n\sin(nx) $$
and try to compute the coefficients of the inverse. If $F[-\pi,\pi] = [a,b]\subseteq [-\pi,\pi]$, then you get (up to constants)
$$\int_a^b F^{-1}(x)\cos(nx) dx = \int_a^b F^{-1}(F(y))\cos(nF(y)) dF(y)$$
$$
= \int_{-\pi}^\pi y\cos(nF(y)) F'(y)dy.
$$
Using the linearity of the integral, one can split the $F'$ into cosines and sines, so we have to compute, for example (and still up to constants)
$$
\int_{-\pi}^\pi y\cos(nF(y)) \cos(my)dy.
$$
and here is where I get stuck","['derivatives', 'fourier-series', 'inverse-function']"
2691312,Can one construct a monotone law of large numbers?,"let $X_1, X_2, \dots$ be a sequence of IID random variables defined on a probability space $( \Omega, F, P)$ with mean $E[X_1] = \mu $, define $$\bar{X}_n = \frac{1}{n}(X_1+ \dots+ X_n)$$ then $\bar{X}_n \xrightarrow{a.s.} \mu$. This is the standard strong law of large number, the almost sure convergence implies that given an $\omega \in \Omega \setminus A$ (where $A$ is the set of probability zero for which the law of large numbers does not work) there always exists a monotone subsequence of $\bar{X}_n( \omega)$, that we call $\hat{X}_n(w)$, s.t.  $\hat{X}_n(w) \rightarrow \mu$, correct? I was wondering if we can always mimic this sequence by eliminating the values that would break the monotonicity of $\bar{X}_n( \omega)$ and if the direction of the monotonicity implies that we are overestimating or underestimating the mean , e.g. assume we are tossing fair coins and we obtain a sample $\{ 1,1,0,1,0,0 \}$, where $1$ represents a tails outcome and $0$ represents a heads, here we would have that $\{ \bar{X}_1 = 1, \bar{X}_2 = 1, \bar{X}_3 = 2/3, \bar{X}_4 = 3/4, \bar{X}_5 = 3/5, \bar{X}_6= 1/2 \}$ so we can construct the decreasing  subsequence $\{ \hat{X}_1 = 1, \hat{X}_3 = 2/3,  \hat{X}_5 = 3/5, \hat{X}_6= 1/2 \}$ can we be sure then that the sequence $\hat{X}_n$ will eventually overestimate the mean with probability one? (we choose to construct $\hat{X}_n$ with the same monotonicity of the tail of the $\bar{X}_n$). My attempted solution to my own doubt: I think the answer is yes because the set of sequences of counterexamples shrinks in size as $n$ increases. To prove this I would proceed by cases: If we fix an $\omega$ s.t. the sequence  $X_1(\omega) , X_2(\omega), \dots$ oscillates around $\mu$ forever then there exists $n_1 \in N$ s.t. the sequence has oscillated around $\mu$ twice. Thus for every $n > n_1$ the monotone sequence $\hat{X}_n$ always overestimates or underestimates the mean (notice that we could construct  $\hat{X}_n$ as decreasing or increasing in this case but for the construction to not be ambiguous in the upcoming second case we need to construct $\hat{X}_n$ with the same monotonicity as the tail of the sample). If we fix an $\omega$ s.t. the sequence  $X_1(\omega) , X_2(\omega), \dots$ oscillates around $\mu$ for a fixed $n_2 \in N$ number of times then there exists a $n_3 \ge n_2$ s.t. for every $n > n_3$ the sequence $\bar{X}_n$ is monotone so the construction of $\hat{X}_n$ will be correctly overestimating or underestimating after $n_3.$ I think with that I have exhausted all the cases, so if this construction of $\hat{X}_n$ is always possible and correct(?), after a certain sample size, why is it not more used? I would assume knowing if one is likely to be underestimating or overestimating the mean is valuable information. EDIT: added that $\omega \in \Omega \setminus A$ and not only $\omega \in \Omega$.","['law-of-large-numbers', 'probability-theory', 'sequences-and-series']"
2691331,Is it always possible to calculate the limit of an elementary function.,"Let be more precise: define an ""strong elementary function"" by only admitting rational for the ""constant function"" in the usual definition of ""elementary"" function (see for example: https://en.wikipedia.org/wiki/Elementary_function ). Let $a$ be an ""elementary real"" if the constant function $f(x)=a$ is a strong elementary function. With this definition some non rational reals are elementary (for example $\pi = 4\cdot \arctan(1)$); but there are reals that are not elementary. Now let $f(x)$ be a strong elementary function defined in an open interval of an elementary real $a$ with the possible exception of $a$. Suppose that $$\lim_{x\rightarrow a} f(x)$$ exists. Is this limit necessarily an elementary real? The idea behind this question is the following: when we learn to calculate limits in elementary calculus, it seems that there is always a method to do it. By calculating a limit we mean to define it by means of the rationals and elementary functions. But is there a general argument that prove that it is always possible?","['calculus', 'limits']"
2691417,Isogeny problem for elliptic curves over the rationals,"Let $E$ and $E'$ be two elliptic curves over the rationals. How do we solve the $\mathbb{Q}$-isogeny problem Is there an isogeny $\phi: E \to E'$ defined over $\mathbb{Q}$? I do only know some very basic elliptic curve theory. Hence I am interested in some theoretical answers (what are the standard references here?). Moreover, I would like to know if there is some deterministic algorithm solving this problem (again, I would appreciate any references!) If there are, then do they compute such an isogeny?","['algebraic-curves', 'elliptic-curves', 'algebraic-geometry']"
2691433,What property of modules ensures that module lattice is uniquely complemented?,"Background: If a module $M$ is semisimple then every submodule $N \subseteq M$ is
  a direct summand. In other terms, there exists a submodule $H \subseteq M$ such that $N \cap H = \{0\}$ and $N+H = M$. Given the lattice of submodules $L(M)$ (where the infimum is $\cap$ and the supremum is $+$), we may consider what property can we impose on the module $M$ so that $L(M)$ is complemented (for each $N$ there exists $H$ such that $N \cap H = \{0\}$ and $N+H = M$). In particular, the lattice of submodules of a semisimple module is complemented iff the module is semisimple. One can further impose the complement to be unique. Question: What property do I need on $M$ so that $L(M)$ is uniquely complemented? Examples: For instance, $\mathbb{Z}_2 \oplus \mathbb{Z}_2$ has a lattice of submodules given by: \begin{matrix}
 && \mathbb{Z}_2 \oplus \mathbb{Z}_2 & \\
&\huge\diagup & \huge| & \huge\diagdown \\
(0,1) && (1,0) && (1,1) \\
&\huge\diagdown & \huge| & \huge\diagup \\
&& 0
\end{matrix} so we don't have the unique complement property. On the other hand, $\mathbb{Z}_2 \oplus \mathbb{Z}_3$ has a lattice of submodules given by: \begin{matrix}
 && \mathbb{Z}_2 \oplus \mathbb{Z}_3 & \\
&\huge\diagup && \huge\diagdown  \\
(1,0) &&& (0,1) \\
&\huge\diagdown && \huge\diagup  \\
&& 0
\end{matrix} which is uniquely complemented.","['abstract-algebra', 'ring-theory', 'modules', 'group-theory']"
2691470,cycle type of commutator,"Let $\sigma=(1,2,...,n)$ be a long cycle in the permutation group $S_n$. Let $\lambda\vdash n$ be a certain partition. My question is: when $\pi$ runs over the group $S_n$, how often will the comutator $\pi\sigma\pi^{-1}\sigma^{-1}$ have cycle type $\lambda$? I have observed that cycle type $\lambda$ only happens if its length $\ell(\lambda)$ is of the same parity as $n$. How to prove this?","['permutations', 'group-theory']"
2691492,Probability of Barcelona playing Real Madrid in Champions League Quarterfinals,"The $2018$ Champions League quarterfinal draw will take place on Friday, March $16^{th}, 2018$ and I wanted to know what is the likelihood that Barcelona will get paired up with Real Madrid ? There are $8$ teams left in the pool so a total of $4$ draws will be made. I think that the number of ways to pairing Barcelona v Real Madrid is $^8C_2$ but I am stuck on how many possible draws there are. Isn't it $\dfrac{^8C_2}{\text{total # of draws}}$? If someone can walk me through the solution to this problem that would greatly be appreciated. Probability has always given me trouble...",['probability']
2691505,Structures with $x*(y*z) = y*(x*z)$,"In reading http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=182143561104878BDABB72258DA254D0?doi=10.1.1.18.2521&rep=rep1&type=pdf , they mentioned an interesting relation -- they had a magma $(X,*)$ with the property $x*(y*z) = y*(x*z)$. Their specific example was to start with a set $S$ , and build your structure on its power set $X=P(S)$; then take the vector space $\mathbb{R}^{P(S)}$. Their operation acted on vectors in this space: for two vectors $x$ and $y$ , the element of their product indexed by $I \subseteq S$ is given by $(x*y)(I) = \sum_{K \subseteq S} x(K)y(I\cup K)$. I think this is an interesting relation, because it's so ""close"" to several other nice properties. If you had any right identity, then $x*y = x*(y*e) = y*(x*e) = y*x$, so the structure is commutative. If you had commutativity, then $ x*(y*z) = x*(z*y) = z*(x*y) = (x*y)*z $, so you'd have associativity. Thus just a right identity is enough to imply that you're a full-on commutative monoid. There is a weak reverse, that associativity implies $(x*y)*z = (y*x)*z$, which is like a weak version of commutativity: $x*y\simeq y*x$ in the sense that are equivalent under maps $(- * z)$ for all $z$. So I want to know what these structures look like when you don't have a right identity. Their example does have a left identity, the vector I'll call $1_0$, with $1_0(\emptyset)=1$ and all other elements of the vector equal to zero. If we restrict our structure to just the vectors $v$ such that $v(\emptyset)\neq 0$, then we are still closed under $*$, and get a notion of inverse: for any vector $v$, we can define the vector $v^{-1}$ by $v^{-1}(\emptyset) = \frac{1}{v(\emptyset)}$ and $v^{-1}(K)=0$ for all other $K$. Then $v*v^{-1} = 1_0$, so in this sense we get an inverse to the left-identity. So we can have a left-identity and an inverse, without the right-inverse/associativity/commutativity properties. I could only think of three other examples of such a structure. One is to take any commutative semigroup. It doesn't have an identity necessarily, but it still has the commutativity and associativity. The second is based on Boolean logic: in some set of axioms and with some set of statements $X$, we can determine $*$ as implication $\to$ in the sense of ""$X\to Y$ means $Y$ can be proven from $X$ in this system"". Then $x\to(y\to z)$ is equivalent to the statement $y\to(x\to z)$, thus ""equal"" in this structure. This still has left-identity given by TRUE, as $TRUE\to X$ is equivalent to $X$. The third is to take a semilattice $(X,\wedge,\le)$, together with a negation map $\neg$ such that $x\le y \implies \neg y\le \neg x$. Then you can get the type of structure described above by taking $x*y = \neg x \wedge y$: We know that $x*(y*z)$ is the greatest lower bound of $\neg x$, $\neg y$, and $z$. As a concrete example, we can take $X = \mathbb{Z}\setminus \{0\}$ and $\wedge$ as $\max$: then we don't have any absorbing elements or identities. I suspect this might be related to the second example above through Heyting algebras somehow. Are there any names for such structures? Are there any classification theorems for them? They seem so ""close"" to such nice structures, I really feel that there should be some sort of results! :) Thank you for any information!","['abstract-algebra', 'magma', 'lattice-orders', 'binary-operations']"
2691510,"Show that $(C([a,b]),\|{\cdot}\|_2)$ is not a complete normed vector space","Problem: Show that $(C([a,b]),\|{\cdot}\|_2)$ is not a complete normed vector space. I have tried to proceed along the lines given in the accepted answer, and subsequent comment, to this question: Example of a non complete normed vector space. Although, I am running into difficulties and wondering if the example really generalises so well when we have a general $[a,b]$ . Is the Cauchy sequence I have chosen below a valid one, or have I overlooked a much simpler example to use in this case? Attempt: In order to show that $(C([a,b]),\|{\cdot}\|_2)$ is not a complete normed vector space we need to show that there is some Cauchy sequence that does not converge to it's limit in $C([a,b])$ . In particular, it will suffice to show that our chosen Cauchy sequence converges under $\|\cdot\|_2$ to a discontinuous function. Consider the following sequence of functions, $(f_n)_{n=1}^\infty\subset C([a,b])$ , given by, $$f_n(x)=\begin{cases}
0,\,\text{when}\,\,x\in[a,\frac{b-a}2-\frac{2^{-n}}{b-a}] \\[2ex] 
1,\,\text{when}\,\,x\in[\frac{b-a}2+\frac{2^{-n}}{b-a},b] \\[2ex] 
\frac{(2x-b+a)(b-a)-2^{-n+1}}{2^{-n+2}},\,\text{when}\,\,x\in[\frac{b-a}2-\frac{2^{-n}}{b-a},\frac{b-a}2+\frac{2^{-n}}{b-a}]
\end{cases}
$$ The definition of $f_n(x)$ when $x\in[\frac{b-a}2-\frac{2^{-n}}{b-a},\frac{b-a}2+\frac{2^{-n}}{b-a}]$ is the linear interpolant over that particular subinterval of $[a,b]$ . I claim that this is a Cauchy sequence. We consider: $$\|f_n-f_m\|_2^2=\int_a^b|f_n(x)-f_m(x)|^2dx$$ $$=\int_a^{\frac{b-a}2-\frac{2^{-n}}{b-a}}|f_n(x)-f_m(x)|^2dx+\int_{\frac{b-a}2-\frac{2^{-n}}{b-a}}^{\frac{b-a}2+\frac{2^{-n}}{b-a}}|f_n(x)-f_m(x)|^2dx+\int_{\frac{b-a}2+\frac{2^{-n}}{b-a}}^b|f_n(x)-f_m(x)|^2dx$$ $$=0+\int_{\frac{b-a}2-\frac{2^{-n}}{b-a}}^{\frac{b-a}2+\frac{2^{-n}}{b-a}}|f_n(x)-f_m(x)|^2dx+0$$ The $0$ 's for the first and last integrals because we have $f_n(x)-f_m(x)=0-0$ and $f_n(x)-f_m(x)=1-1$ on each respectively. As to the middle integral, here is what I've gotten so far: $$\int_{\frac{b-a}2-\frac{2^{-n}}{b-a}}^{\frac{b-a}2+\frac{2^{-n}}{b-a}}|f_n(x)-f_m(x)|^2dx=\int_{\frac{b-a}2-\frac{2^{-n}}{b-a}}^{\frac{b-a}2+\frac{2^{-n}}{b-a}}|(2x-b-a)(b-a)(2^{n-2}-2^{m-2})|^2dx$$ Based in the example I am following, supposing that $m\ge n$ , I think that I should be able to argue that the whole thing is bound above by $\frac{2^{-n}}{b-a}$ which would mean that $\|f_n-f_m\|_2^2\le\frac{2^{-n}}{b-a}\to0$ as $n\to\infty$ . I don't quite see how I'm meant to bound it above by $\frac{2^{-n}}{b-a}$ , as I keep tripping up over applying that $m\ge n$ , leading me to question whether the approach I have employed here is a fruitful one after all.","['functional-analysis', 'normed-spaces', 'real-analysis', 'banach-spaces']"
2691518,"Evaluate $\int_0^1\frac{\sin (\pi xs)\sin\left(\pi x (1-s) \right)}{\sin(\pi s)}\,ds$","Based on the context of this question about the successive derivatives of $\tanh$, we can show the identity
\begin{equation}
I(x):=\int_0^1\frac{\sin (\pi xs)\sin\left(\pi x (1-s) \right)}{\sin(\pi s)}\,ds=\frac{\cos \pi x}{\pi}\sum_{n=1}^\infty \left( 2^{2n+1}-1 \right)\zeta(2n+1)x^{2n}
\end{equation} 
which connects an integral to a summation of the Riemann Zeta function for odd-integer arguments. Moreover, by using the generating functions for integer and even-integer arguments of the Zeta function, one may express the result as
\begin{equation}
I(x)=\frac{1}{2}\sin(\pi x)-\frac{\cos(\pi x)}{\pi}\left( \psi\left( x+\frac{1}{2} \right)+\gamma+2\ln 2 \right)
\end{equation} 
where $\gamma$ is the Euler's constant and $\psi$ is the digamma function. To derive the expression of $I(x)$, I used the generating function of the polynomials defined in the linked question, an integral representation of $(\ln t)^{-1}$ and a Mellin transform (more details can be added if needed). As the proof is rather long and very indirect, the question is to find alternative or shorter proofs of one of the above identities.","['alternative-proof', 'closed-form', 'generating-functions', 'integration', 'riemann-zeta']"
2691520,"In a Zener card test using a 25 -card pack and no replacement, what is the expected score if we try to minimise correct guesses?","The Zener cards were invented by Karl Zener and used by J B Rhine in his experiments on extrasensory perception (ESP) at Duke University in the 1930s. They comprise cards of each of five types, showing a square, circle, star, cross, or wavy lines: A standard pack contains 25 cards, five of each type. A run consists of a subject trying to guess each card in a pack in turn. If we replace and shuffle after each guess, his expected score is 5. In another question I asked what the expected score is if we don't replace, and if instead we keep a record (or just remember) how many cards of each type have already come up. The answer turns out to be $\frac{23148348523}{2677114440}=8.65$ to 2 decimal places. What is the expected score if we try to minimise it? If we guess randomly for the first 21 cards we will know for certain at least one shape that does not appear in the next 4, and so we can make sure we get our last 4 choices wrong, which will give us an expected score of $\frac{21}{5}=4.2$. On average we can get lower still, because sometimes after guessing randomly for only 20 cards we will know that the remaining cards are not all different, in which case we will know at least one shape that doesn't appear in those 5 and we will get an expected score of $\frac{20}{5}=4$. So the answer is certainly less than 4.2.","['combinatorics', 'card-games']"
2691593,General Cauchy-Schwarz for adjoint positive operators,"I'm trying to prove the next inequality, like Cauchy-Schwarz standard inequality: $$|\langle Tx,y\rangle |\leq\langle Tx,x\rangle ^{1/2}\langle Ty,y\rangle ^{1/2}\space\forall x,y\in\mathcal{H},$$ where $\mathcal{H}$ is a complex Hilbert space, $T$ bounded linear operator, $T\geq 0$ and $T=T^{*}.$ If we consider that, for $t\in\mathbb{R},$ 
$$0\leq\langle T(y-tx),y-tx\rangle =\langle Ty,y\rangle -2t\mathcal{Re}(\langle Ty,x\rangle )+t^{2}\langle Tx,x\rangle :=P(t),$$ then $P(t)$ is a polynomial of second grade, so its discrimante have to be 
$$\mathcal{Re}^{2}(\langle Ty,x\rangle )\leq\langle Tx,x\rangle \langle Ty,y\rangle ,$$
but I would like to conclude that $$|\langle Ty,x\rangle |\leq\langle Tx,x\rangle \langle Ty,y\rangle ,$$ How can we conclude the desire inequality? Is there something wrong?","['functional-analysis', 'cauchy-schwarz-inequality', 'operator-theory', 'adjoint-operators']"
2691627,Smallest prime of the form $68^k+k!+1$?,"Let $f(n)$ be the smallest integer $k\ge 1$ such that $$n^k+k!+1$$ is prime or undefined if no such $k$ exists. I determined the values $f(n)$ for the even numbers $2,4,6,\cdots $ and $f(56)$ turned out to be $2138$ giving the huge prime $$56^{2138}+2138!+1$$ with $6194$ digits found by the PFGW-program (a software checking large numbers for primality). The first even $n$ for which I do not know whether $f(n)$ is defined is $n=68$ Is there a prime of the form $68^k+k!+1$ with integer $k\ge 1$ ? If such a $k$ exists , it must be greater than $24\ 000$.","['factorial', 'prime-numbers', 'functions']"
2691629,A very basic question about the derivative of a quotient,I have a quotient function of following type $$h(x)=\frac{f(x)}{g(x)}$$ I know that $f(x)$ increases with $x$ and $g(x)$ decreases with $x$ so can we conclude that the derivative of $h(x)$ is positive? Thanks in advance,"['derivatives', 'calculus']"
2691638,Proving equality between sets (elementary set theory),"Prove that: $$A \cup B = A \cup C \text{ and } A \cap B = A \cap C \implies B = C$$ Proof: Suppose  $A \cup B = A \cup C \text{ and } A \cap B = A \cap C$ but $B \neq C$. Then either $B \not\subset C$ or $C \not\subset B$. Let $w \in B$ such that $w \notin C$. Then $w \in A \cup B$, which implies, by hypothesis, that $w \in A \cup C$. But $w \notin C$, so it must be that $w \in A$, therefore we have that $w \in A\cap B$, which again implies that $w \in A \cap C$, a contradiction. Therefore no such $w$ exists and $B \subset C$. Second case: Let $w \in C$ such that $w \notin B$. Then $w \in A \cup C$, so $w \in A \cup B$
. Since $w \notin B$, then, similarly to the first case, we have $w \in A \cap C$, which again implies $w \in A \cap B$, a contradiction. Therefore $C \subset B$. Since $B \subset C$ and $C \subset B$, then $B = C$. Unfortunately I'm just getting the hang of this now, so I still must defer to other people to check my work. Is everything correct? Could my writing or anything else be improved? Any help would be appreciated.",['elementary-set-theory']
2691644,Singular points of orders of a number field,"Let $K$ be a number field (finite field extension of $\mathbb{Q}$) and let $\mathcal{O}_{K}$ be its ring of integers (integral closure of $\mathbb{Z}$ in $K$). We know that $\mathcal{O}_{K}$ is a free $\mathbb{Z}$-module of rank $n=[K:\mathbb{Q}]$, and we know that it is a Dedekind domain. Hence $\operatorname{Spec}(\mathcal{O}_{K})$ is a regular curve. Let $\beta_{1},\ldots,\beta_{n}\in \mathcal{O}_{K}$ be a basis of $K$ over $\mathbb{Q}$. Then $\mathcal{O}=\mathbb{Z}[\beta_{1},\ldots,\beta_{n}]\subseteq \mathcal{O}_{K}$ is by definition an order of $K$ [ Remark (thanks to Hurkyl): we really want the $\beta_{i}$ to be a basis of $\mathcal{O}$ as a free $\mathbb{Z}$-module, see the comments below]. We also know that orders of $K$ are one-dimensional noetherian domains. So the only thing that stops $\mathcal{O}$ from being a Dedekind domain (and hence being equal to the maximal order $\mathcal{O}_{K}$) is that $\mathcal{O}$ may not be integrally closed. This means that $\operatorname{Spec}(\mathcal{O})$ is a curve which may have a bunch of singular points, and $\mathcal{O}=\mathcal{O}_{K}$ if and only if $\operatorname{Spec}(\mathcal{O})$ is a regular curve (we go from $\operatorname{Spec}(\mathcal{O})$ to $\operatorname{Spec}(\mathcal{O}_{K})$ by normalizing). We want to determine whether $\mathcal{O}=\mathcal{O}_{K}$ or not, and for this we have the following proposition: Equality holds if and only if for every prime $p$ such that
  $$ p^{2} | \operatorname{disc}(\beta_{1},\ldots,\beta_{n})=\det(\operatorname{Tr}_{K/\mathbb{Q}}(\beta_{i}\beta_{j}))$$
  we have that $\bar{\beta_{1}},\ldots,\bar{\beta_{n}}\in \mathcal{O}_{K}/p\mathcal{O}_{K}$ are linearly independent over $\mathbb{F}_{p}$. Given the previous geometric interpretation, I was hoping that what this proposition really does is ""looking for singularities"" in the curve $\operatorname{Spec}(\mathcal{O})$. So I tried to show that if the projections of the $\beta_{i}$ are linearly dependent over $\mathbb{F}_{p}$, then there is a prime $\mathfrak{p}$ above $p$ in $\mathcal{O}_{K}$ such that the localization $\mathcal{O}_{K,\mathfrak{p}}$ is not a discrete valuation ring. But I don't really see how to relate both things, and the proof of the proposition also doesn't help me see any connection. Any hints? And in particular is there any geometric interpretation of this proposition, say, in terms of Zariski (co)tangent spaces? Sketch the proof I know, in case it helps: We know an integral basis exists, so we may write our basis in terms of this integral basis. Since the discriminant of our basis is the discriminant of the integral basis times the square of the determinant of the transition matrix, equality holds if and only if the determinant of the transition matrix is plus or minus one. So if our basis is not an integral basis, some prime $p$ divides the determinant of the transition matrix (which implies that its square divides the discriminant of our basis). This means that the reduction modulo $p$ of the matrix has non-trivial kernel, and then any non-trivial element in the kernel gives us a non-trivial linear combination of the $\bar{\beta_{i}}$ which is equal to zero. So the $\bar{\beta_{i}}$ are not linearly independent over $\mathbb{F}_{p}$. Conversely, suppose there exists a $p$ such that we can find a non-trivial linear combination of the $\bar{\beta_{i}}$ equal to zero, hence a non-trivial element in the kernel of the reduction modulo $p$ of the transition matrix. Then the determinant of the transition matrix is divisible by $p$, and hence our basis is not an integral basis.","['algebraic-geometry', 'abstract-algebra', 'algebraic-number-theory', 'number-theory', 'arithmetic-geometry']"
2691656,Books on logic and ZFC set theory for physicist,"I am undergraduate student in physics with not that many mathematics courses done in my career. Nevertheless, I am very interested in mathematical physics. I started studying from the lectures ""Geometrical anatomy of theoretical physics"" which can be found at https://youtu.be/V49i_LM8B0E . From the lectures I have gained some sort of intuition but I feel that for my satisfaction I want to learn a little bit more. For you to better understand my interests, I want to mention what kind of things I would like to learn next. The general idea is that I do not want to go very deep in these exciting and interesting topics but I want to know enough so that I can learn topics like topology, manifolds, bundles and so on that are necessary for physics without stumbling across things that come from logic or set theory. For example, while I can prove basic things in topology (which basically just use set-theoretical arguments), I am sometimes dissatisfied because I can prove things ""intuitively"" but if some day I wanted to make my proofs formal, I am afraid that I couldn't. This is certainly something I would like to change. Propositional and predicate logic. Proofs and rules of inference. I feel satisfied with classical logic which defined proposition and predicate in an intuitive way and which defined operators using truth tables. This is enough rigor for me and I am willing to accept this. I am also willing to accept the philosophy that logic goes first and then I use it to tell what set theory is. The thing I have the most problems with in logic is how to make formal proof. In the lectures I heard the recipe (proof is sequence of propositions which are either axioms, tautologies or ""modus ponens""), but I have trouble proving many things as I am unsure if I am doing it right. I would be happy for some reference that could show some examples on how to make formal proofs, so that I would have a nice feeling that if someone in the future would not believe my proof then I could go back to logic and write a nice, billion lines long formal proof. ZFC set theory. My whole life I have been using ""naive set theory"" without a doubt but once I got introduced to Russell's paradox I feel uneasy about it. That is indeed possible that in my whole physics career I will always be able to prove and write everything in terms of naive set theory, but something just feels wrong. That being said, I would like to receive some reference about ZFC set theory for beginners. I am not interested in some deep topics in the set theory - I just want to be sure that I know what axioms are (that are now considered to be consistent) so that I could consult them whenever I get too confused in my mathematical journey. I would appreciate any suggestions and/or comments from your personal experience!","['reference-request', 'book-recommendation', 'logic', 'elementary-set-theory']"
2691665,In what algebraic structure does repeated addition equal multiplication?,"I'm trying to figure out for which algebraic structure $$\underbrace{a+a+\cdots+a}_{n \text{-times}} = a * n$$ is true. Now I know the question ' Is all multiplication repeated addition? ' has been asked many times with the answer: NO because you cannot express non-integer (such as fractions or complex numbers) multiples as repeated addition.  However I'm pretty sure that the reverse is true; that ' Repeated addition is always multiplication ' So my first thought was that Rings would be the appropriate algebraic structure for this, seeing that they have both addition and multiplication. However, the definition of a ring does not mention this property. So I was thinking about this property and it seems like it holds for many rings, including the following: Integers Rationals Reals Complex numbers $m\times m$ Matrix Ring Polynomials where multiplication is scaling by a number But... Then I ran into the Boolean ring where $\lor$ is the addition in the ring, and $\land$ is the multiplication. So... $$???\,\,\underbrace{a\lor a\lor\cdots\lor a}_{n \text{-times}} = a \land n \,\,???$$ Now the problem is the type of the entity is totally different (true/false values). This doesn't even make sense; or does it? If this isn't true, then I'm not sure where that leaves me then, since it would imply that this property doesn't hold for rings in general.  But then what does it hold for? Any insight would be greatly apprecitated. :)","['abstract-algebra', 'ring-theory', 'products']"
2691739,How many number of bracelets of length $n$ with black-white beads?,"How many number of bracelets of length $n$ with black-white beads? I'm trying to find a formula for counting the number of such bracelets. What i've done so far is to think of the bracelets as binary strings with periods. I've noted that the total number of length $n$ bracelets is $2^n$ and that $2^n=\displaystyle\sum_{d|n}B_d$, where $B_d$ is a bracelet with period $d$. By Mobius Inversion, I have that $B_n=\displaystyle \sum_{d|n}\mu(n/d)2^d$. So $c_n= \displaystyle \frac{1}{n}\sum_{d|n}\mu(n/d)2^d$ gives the number. But when I test it for $n=5$, I get $c_5=6$ when i'm expecting $8$. (i.e. $00000,00001,00011,01001,00111,01101,01111,11111$ as distinct necklaces).","['combinatorics', 'mobius-inversion', 'necklace-and-bracelets']"
2691752,Is it possible to solve this ODE by separation of variables?,Consider the equation $ydx +3xdy =14y^4dy$. Is there a clever trick which would allow to solve this equation by the method of separation of variables?,['ordinary-differential-equations']
2691767,Probability that A wins a best of 7 (4 matches),"$A$ and $B$ play a series of best of $4$. The probability that $A$ wins a given game is $p$. Assume that the games are independent of each other. What is the probability that $A$ wins? Let $A_{i}$ be the event that $A$ wins the series in $i$ matches.
Then, the book states, $$P(A) = P(A_{4}) + P(A_{5}) + P(A_{6}) + P(A_{7}) = p^{4} + \binom{4}{3}p^{4}q + \binom{5}{3}p^{4}q^{2} + \binom{6}{3}p^{4}q^{3}.$$ I am having a bit of trouble understanding the calculation. I am trying to be a bit more formal here. As an example, lets concentrate on $A_{5}$. It really is $A \cap G_{5}$ where $G_{i}$ is the event that $i$ matches were played in the series. Then, $$P(A_{5}) = P(A \cap G_{5}) = P(A|G_{5})P(G_{5}) = \binom{5}{4}p^{4}qP(G_{5}).$$ Now, we equate this term to $P(A_{5})$ to get $\binom{5}{4}p^{4}qP(G_{5}) = \binom{4}{3}p^{4}q$, from which we get, $$P(G_{5}) = \frac{\binom{4}{3}}{\binom{5}{4}}.$$
Is this complete nonsense? If not, can someone give me an intuition for $P(G_{5})$? It just doesn't click in my head right now. To rephrase, $P(A_{5}) = \binom{4}{3}p^{4}q$ was given in the answer, but in my attempt, I have this $P(G_{5})$ term which I am not sure how to find without the equation $\binom{5}{4}p^{4}qP(G_{5}) = \binom{4}{3}p^{4}q$.","['probability-theory', 'probability', 'statistics']"
2691786,Are there discussion sites online for university level mathematics?,"I have been trying to learn maths on my own for a while, I've realised most of the problems that stump me would be solved in 5 seconds, if I had a mentor. Of course, learning on your own teaches you problem solving, but too often I'm banging my head against the wall on something I was not ready for. Teaching yourself math is like fumbling around in the dark. It is clear that my highschool math curriculum has not prepared me for the advanced math I am trying to learn. Most books I've come across seem to assume a classroom setting, there are solutions missing, the language too terse. I know StackExchange is a question and answer site, not for discussions. So where could a math autodidact go online to discuss math? Preferably with others who are also self learning higher level mathematics or those who are knowledgeable about mathematics and can act as mentor. I don't mind paying a subscription, if there is such a service.","['self-learning', 'abstract-algebra', 'calculus', 'probability', 'combinatorics']"
2691799,Problem of book ODE and dynamical systems gerald teschl,"Problem 1. Consider again the exact model from the previous problem
  and write $$
\ddot{r} = -\frac{\gamma M \epsilon^2}{(1 + \epsilon r)^2}, ~~~\epsilon = \frac{1}{R}
$$ It can be shown that the solution $r(t) = r(t,\epsilon)$ to the above initial conditions is $C^{\infty}$ (with respect to both $t$ and $\epsilon$). Show that $$
r(t) = h - g\left[1 - 2\frac{h}{R} \right]\frac{t^2}{2} + \mathcal{O}\left(\frac{1}{R^4}\right), ~~~ g = \frac{\gamma M}{R^2}
$$ The initial condition reads $r(0)=h$ and $\dot{r}(0)=0$ (Hint: Insert $r(t,\epsilon) = r_0(t) + r_1(t)\epsilon + r_2(t)\epsilon^2
 + r_3(t)\epsilon^3 + \mathcal{O}(\epsilon^4)$ 
  into the differential equation and collect powers of $\epsilon$. Then solve the corresponding differential equations for $r_0(t)$, $r_1(t)$, $\cdots$ and note that the initial conditions follow from $r(0, \epsilon) = h$ respectively $\dot{r}(0, \epsilon) = 0$. A rigorous justification for
  this procedure will be given in Section 2.5.). Remark: $\dot{r}$ and $\ddot{r}$ are derivatives of first And Second  order.
how to solve this problem following is hint? What does these ($r_0$, $r_1$, $r_2$, $r_3$) mean? the derivatives? This problem be in book book ODE and dynamical systems gerald teschl on introduction.","['ordinary-differential-equations', 'analysis', 'systems-of-equations']"
2691838,How do you get to $e^x$ from $e$'s definition?,"$$e=\lim_{n\to\infty}\left(1+\frac 1n\right)^n$$ This is based on Bernoulli's compound interest definition. But let's say we want to find $e^x$ now. $$e^x=\lim_{n\to\infty}\left(1+\frac 1n\right)^{nx}$$ Let $m = nx$ so $n = m/x$. As $n$ goes to infinity, so does $m$, so: $$e^x=\lim_{m\to\infty}\left(1+\frac xm\right)^{m}$$ This now looks like the definition you usually see but apparently this is an invalid proof of the fact because $n$ is supposed to be an integer(??) and $m/x$ may not be. How are you supposed to get from one to the other then?","['limits', 'exponential-function', 'calculus', 'proof-explanation', 'definition']"
2691839,"$p(x)x^n+q(x)(1-x)^n=1$ for some $p(x), q(x)\in \mathbb{Z}[x]$, what explicitly $p(x), q(x)$ are?","Because $x^n$ and $(x-1)^n$ are relatively prime in $\mathbb{Z}[x]$, so 
$p(x)x^n+q(x)(1-x)^n=1$ for some $p(x), q(x)\in \mathbb{Z}[x]$. What are the explicit formulas of $p(x), q(x)$?","['abstract-algebra', 'ring-theory', 'polynomials']"
2691947,Derivative of $(Ax) \otimes y$ with respect to $x$,"Suppose $A$ is an $ n \times n$ matrix and suppose that
$x,\, k$ are  $n \times 1$ vectors. Also suppose that
$k$ is a constant vector. let
$$
y : = \left( Ax \right) \otimes k
$$
Note that by $\otimes$ in this context we mean the outer product of
two vectors given as $v\otimes u = vu^\top$. I would like to find $\frac{\partial y}{\partial x}$. By this symbol
I mean to find the derivative of each entry of $y$ with respect
to each entry of $x$. I know that, $$
\mathrm{d}(x \otimes y) = (\mathrm{d}x)\otimes y +
x \otimes (\mathrm{d}y)
$$ Therefore (at least formally) we would have
\begin{align}
\frac{\partial y}{\partial x} = A \otimes k \label{A}
\end{align} But then what I don't understand is (if the way I have found the
derivative is correct) what is meant by $A \otimes k$?. Does it mean
the Kronecker product of $A$ and $k$ in the usual sense? Can someone please clarify?. Better yet, how does one find this
derivative? EDIT $Ax k^\top$ is an $n \times n$ matrix.","['matrices', 'kronecker-product', 'derivatives']"
2692005,Additive inverse of a number vs multiplying by $-1$,"To give the context, I've been trying to look at different ways to convince myself how $-\times - = +$ Additive inverse of $a$ is written as $-a$ As an example the additive inverse of $-3$ is written as $-(-3)$ Also $-1$ times $-3$ is written as $(-1)\times (-3)$ Both above expressions evaluate to the same quantity $3$. I guess it is easy to see why the additive inverse of $-3$ equals $3$ simply by staring at the equation $3+(-3) = 0$ However it must be very difficult to convince oneself why the second expression  $(-1)\times (-3)$ evaluates to $3$ too. Both these operations seem related. I'm trying to figure out  connection/intuition behind taking additive inverses and multiplying by $-1$. Help is appreciated. Thanks!","['algebra-precalculus', 'arithmetic']"
2692014,"Ideal $(y^2-x^3-x^2)$ is a prime ideal in $k[x,y]$","I have been able to show that $(y^2-x^3-x^2)$  is a prime ideal in $k[x,y]$. However I am not so sure if the quotient ring is integrally closed in its field of fractions. I have done a proof using the fact that $k[x,y]$ is a UFD. Is my result about it being integrally closed right?","['algebraic-geometry', 'commutative-algebra']"
2692021,No mid points implies measure $0$,"Let $E$ be a Lebesgue measurable set in $\mathbb R$ such that $x \in E, y\in E, x\neq y$ implies $\frac {x+y} 2 \notin E$. Show that $m(E)=0$ where $m$ is the Lebesgue measure on $\mathbb R$ I believe this result is interesting enough to the MSE community so I am posting the question as well as the answer. The proof may also benefit those who are beginning to learn measure theory.",['measure-theory']
2692080,"Conjecture over this series, and its generalisation","PART I The following series, according to W. Mathematica, does converge to $$\sum_{k = 1}^{+\infty} \frac{e^{-k}}{k^k \sqrt{k}} = 0.3929049383779132(...)$$ The previous result can be written in terms of elementary numbers plus the Euler constant, as follows: $$0.3929049383779132 \approx \frac{-92-95 e+86 e^2}{2 \left(130-4 e+33 e^2\right)}$$ Question Is that conjecture true? Probably it's a lack of mine but I cannot manage to make W. Mathematica to spit out more digits of the previous number. PART II The previous series was actually a special case for $x = 1$ of the more general series: $$\sum_{k = 1}^{+\infty} \frac{x^k e^{-k}}{k^k \sqrt{kx}}$$ Question : Is there a close form for this? I tried with many values of $x$ and the series always gets a numerical result, but Mathematical cannot give me a close form. I am not assuming a priori it does exist, but many times people found out close forms whereas software could not.","['number-theory', 'conjectures', 'sequences-and-series']"
2692081,"Show that $\mathcal{A}$ is dense in $C([0,2016])$.","Exercise: Let $\mathcal{A}$ be the family of functions $f:[0,2016]\to\mathbb{R}$ that can be written as $$f(x) = a_0 + a_1x^4 + a_2x^8 + a_3x^{12} + \ldots + a_nx^{4n}$$ with $a_0,a_1,\ldots,a_n\in\mathbb{R}$ and $n\in\mathbb{N}$.
Formulate the algebra version of the Stone-Weierstrass approximation theorem and show that $\mathcal{A}$ is dense in $C([0,2016])$. What I've tried: The algebra version of the Stone-Weierstrass approximation theorem says the following: Let $X$ be a compact metric space and let $\mathcal{A}$ be a subalgebra of $C(X)$. If $\mathcal{A}$ separates points in $X$ and vanishes at no point in $X$ then $A$ is dense in $C(X)$. So I think I need complete the following steps: 1) Show that $[0,2016]$ is compact. 2) Show that $\mathcal{A}$ is a subalgebra of $C([0,2016])$ 3) Show that $\mathcal{A}$ separates points in $X$. 4) Show that $\mathcal{A}$ vanishes at no point in $X$. Every closed interval in $\mathbb{R}$ is compact so $[0,2016]$ is compact, this satisfies 1). I don't know how to satisfy 2) unfortunately. To show that $\mathcal{A}$ separates points in $X$ consider the function $f(x) = a_0 + a_1x^4$; for every $x,y\in[0,2016], x\neq y$ we have that $f(x) \neq f(y)$. To show that $\mathcal{A}$ vanishes at no point in $X$ consider the function $f(x) = a_0$ with $a_0 \neq 0$. Then $f(x) \neq 0$ for every $x\in[0,2016]$. Question: How do show that $\mathcal{A}$ is dense in $C([0,2016])$ by showing that $\mathcal{A}$ is a subalgebra of $C([0,2016])$? Thanks!","['general-topology', 'real-analysis', 'metric-spaces']"
2692107,Combinatorial proof or interpretation of Bezout relation between $(1-p)^n$ and $p^m$?,"Let $T_{n,m}(p)=\sum_{j=0}^{m-1} \binom{n+j-1}{j}p^j$. In answering a recent question , I discovered the identity $$
(1-p)^n T_{n,m}(p)+ p^m T_{m,n}(1-p)=1 \tag{1}
$$ Is there a nice combinatorial proof or interpretation of (1) ? ($p$ looks a lot like the probablity of something in this formula, doesn't it.)
I've got a feeling that this question is a duplicate of an already existing question, but my search was unsuccessful. UPDATE : as explained in orangeskid's answer to the abovelinked question, (1) can be nicely derived by expanding Newton's binomial in $(p+(1-p))^{n+m-1}=1$.  But this is still more computational than really combinatoric/probabilistic, I'm still waiting for a more direct interpretation of $T_{n,m}(p)$ and (1).","['polynomials', 'combinatorics', 'probability', 'probability-distributions']"
2692123,"Inverse of $f(x,y)=(x^2+y^2,x^2-y^2$)","Let $f:[0,1]\times[0,1]\to\mathbb{R}^2$ be given by $f(x,y)=(x^2+y^2,x^2-y^2)$. Am I correct in thinking that $f$ has no inverse? I can show that $f$ is one-to-one but $f$ is not onto since for $(1,2)$ in the codomain, there is no $(x,y)$ in the domain such that $f(x,y)=(1,2)$. So $f$ does not have any inverse.",['multivariable-calculus']
2692141,$Var(aX) = a^2Var(X)$ but $Var(X+Y) = Var(X) + Var(Y)$. How does this make any sense?,"Apologies for the less than clear question, I wasn't quite sure how to phrase it. Say you have a random variable $X ~ N(5, 10^2)$. Say you have another random variable $Y ~ N(5, 10^2)$. Var(2X) = 4Var(X) = 4*10^2 But: $Var(X+Y) = Var(X) + Var(Y) = 2\times 10^2$ But now a question arises: what?! X = Y so Var(2X) = Var(X+X) = Var(X+Y) and yet two different answers are reached using the two distinct accepted formulas. How does this make any sense? What's going wrong? It shouldn't matter what we call the random variables, and yet it seems as if it does.","['variance', 'probability']"
2692157,The Gauß map of a minimal surface: is it holomorphic or antiholomorphic?,"I'm reading A survey on classical minimal surface theory , by William H. Meeks and Joaquín Pérez. In the early beginning, they start giving eight definitions of minimal surfaces. The last of them is Definition 2.1.8 A surface $M\subset \Bbb R^3$ is minimal if and only if its stereographically projected Gauß map $g:M\to \Bbb{C}\cup \{\infty\}$ is meromorphic with respect to the underlying Riemann surface structure. The authors try to justify this definition as follows: a previous definition of minimal surfaces says that a surface $M\subset \Bbb R^3$ is minimal if it has indentically zero mean curvature. So, if $N:M\to \Bbb S^2\subset \Bbb R^3$ is the usual Gauß map, we know that $-dN_p:T_pM\to T_p\Bbb S^2\cong T_pM$ is a linear symmetric operator $\forall p\in M$ and, therefore, choosing an orthonormal basis for $T_pM$,
$$-dN_p=\begin{pmatrix} a&b\\b&c\end{pmatrix},$$
a symmetric matrix. Since $$H=\text{arithmetic average of principal curvatures} = \frac{1}{2}\mathrm{trace} (-dN_p),$$ we must have $c=-a$, in order to get a minimal surface. Then they say that, identifying $\Bbb S^2$ with the Riemann sphere $\Bbb C\cup \{\infty\}$ together with the Cauchy-Riemann equations , this would show that the Gauß map $g:M\to \Bbb C\cup\{\infty\}$ must satisfy the definition above. My doubt is: the matrix
$$-dN_p=\begin{pmatrix} a&b\\ b&-a\end{pmatrix}$$
does not satisfy Cauchy-Riemann equations. For this, it should have the form
$$\begin{pmatrix} a&-b\\ b&a\end{pmatrix}.$$ However, if I invert the orientation of $\Bbb C\cup\{\infty\}$ and ""pretend"" I did nothing, the matrix gets that form and Cauchy-Riemann equations are indeed satisfied. Furthermore, other sources (like this Handbook of Differential Geometry ) says in page 228 that such Gauß maps of minimal surfaces are indeed anti -holomorphic. Which definition is correct?","['minimal-surfaces', 'riemannian-geometry', 'differential-geometry', 'definition']"
2692174,Second Order D.E with non-constant (trig-functions) coefficients,"This is not a homework exercise. I am just making it clear. I have the following second-order differential equation. $$\frac{4 q'(z)^3 \sin ^3(q(z))}{z^2 \left(z^2 q'(z)^2+1\right)^{3/2}}+\frac{3 \sin ^2(q(z)) \cos (q(z))}{z^5
   \left(z^2 q'(z)^2+1\right)^{3/2}}+\frac{3 q'(z) \sin ^3(q(z))}{z^4 \left(z^2 q'(z)^2+1\right)^{3/2}}+\frac{3
   q'(z)^2 \sin ^2(q(z)) \cos (q(z))}{z^3 \left(z^2 q'(z)^2+1\right)^{3/2}}-\frac{q''(z) \sin ^3(q(z))}{z^3
   \left(z^2 q'(z)^2+1\right)^{3/2}}=0$$ I know that the solution to the above is $ArcCos(m z)$, and this is something easily verifiable using a simple Mathematica code. My question is the following: How would I go about solving this by hand if I didn't have the solution? From my undergraduate studies, I remember that $2^{nd}$ order D.E's with non-constant coefficients are used by applying the Frobenius Method; notes on the Frobenius method . However I seem to be stuck with this, so any suggestions would be more than helpful. Thanks in advance. P.S: I am not asking anyone to solve it for me, just some recommendations would be nice. In particular, if I apply the Frobenius method, what do I do with the trig functions, as this is something I've never done before. P.S: The simplified version is $$-q''(z)+4 z q'(z)^3+\frac{3 q'(z)}{z}+3 q'(z)^2 \cot (q(z))+\frac{3 \cot (q(z))}{z^2} = 0$$","['frobenius-method', 'ordinary-differential-equations']"
2692259,How might I prove that LCM$(m) \geq 2^m$?,"Denoting by LCM$(m)$ the lowest common multiple of the first $m$ numbers, can anyone suggest a way in which I might prove that, for $m \geq 7$,
$$
\text{LCM}(m) \geq 2^m
$$ I believe that a proof of this may be found within the proof of Theorem 2 of the paper 'On Chebyshev-Type Inequalities for Primes' by M. Nair, but I am currently struggling to follow this.","['number-theory', 'least-common-multiple', 'proof-explanation']"
2692278,Plotting the set $\left\{ z\in \mathbb{C} : \left| z+i \right| =2\left| z \right| \right\} $,"I have a question which can be simple, though I couldn't catch the idea. Consider the Set given below: $$E=\left\{ z\in \mathbb{C} : \left| z+i \right| =2\left| z \right|  \right\} $$ I have to find its graph to plot. The Answer is the following: the Set $E$ is a circle, centred at $i/3$ and of radius $2/3$ I was not able of visualizing this set, I absurdly thought about a spiral. Any calculations neither didn't lead me to a solution. And especially, my conclusion was that this graph couldn't be a circle at all. Thanks for helping me in advance.","['complex-analysis', 'complex-geometry', 'graphing-functions']"
2692284,Kac's Lemma for integrable return times,"Kac's Lemma in ergodic theory tells us that given an ergodic measure preserving transformation $T$ of a probability space $(X,\mathcal{B},\mu)$, and a measurable subset $A\in\mathcal{B}$ with $\mu(A)>0$, we have $\int\limits_Ar_A\,d\mu=1$ where $r_A(x)=\inf\{n\geq 1 \mid T^nx\in A\}$ is the first return to $A$. This incorporates the idea that if a set has large measure, the return time would be small, and if the set has small measure, the return time would be large. Now, suppose we have a measurable partition of $A$, say $P$, where $\mu(p)>0$ for all $p\in P$. Suppose we have an integrable (not necessarily first) return time $t_A:A\to \mathbb{Z}^+$ which is constant on partition elements. Is there an analogue of Kac's lemma for this return time? A guess would be $\frac{1}{\mu(p)}\leq t_A(p)$ for all $p\in P$, but I am not sure if this is true. This does seem to capture the intuition given in the second paragraph. Edit: It seems my guess can't be true, due to integrability of $t_A$. I can however show that $\mu(p)t_A(p)\leq \left\|t_A\right\|_1$. Is it possible to get anything better? Thanks!","['ergodic-theory', 'measure-theory']"
2692316,Is there any decomposition theorem for permutation groups?,I know that there is decomposition theorem for finite abelian groups. Is there any known theorem for decomposition of permutation groups? Here decomposition means any permutation group can be written as a direct product of smaller groups.,['group-theory']
2692367,Examples of a group $G$ with a non-trivial homomorphism $f:G \to Z(G)$,"I recently learned that if $f: G \to Z(G)$ is a homomorphism of $G$ to its center, then $g:G \to G$ defined as $g(x)=f(x)x$ is an endomorphism of $G$. I am having trouble thinking of examples of a (finite) group with a non-trivial homomorphism from itself to its center. This excludes trivial centers and abelian groups. Can someone give me at least two examples? EDIT: It occurs to me that if $G=H \times A$ for some group $H$ with non-trivial center and abelian group $A$, then the map $f:(x,y) = y$ is a homomorphism. In essence, the automorphism $g$ is then $g(x,y) = (x,y^2)$. An example where $G$ cannot be decomposed as such would be appreciated. EDIT: I think I have some confusion about the properties of $f$ in order that $g$ must be an automorphism. That is, I am unsure if the image of $f$ must be the entire center or not.","['finite-groups', 'group-theory', 'automorphism-group']"
2692374,Different combinations without replacement and indistinguishable objects,"I'm a bit of a math novice, but have been trying to come up with an answer to a question involving my favorite game: Magic the Gathering. I am wondering how many different combinations of 7 cards can I draw from a deck of 60 cards comprised of 4 indistinguishable copies of 15 different cards. I've been able to use number combinations to get 60 pick 7 being 386,206,920 but thought that assumed that each card was unique. Thank You,
WJ","['combinations', 'combinatorics']"
2692405,every open set in the extended real line ($\overline{\mathbb R}$) is a countable union of segments,"I know that every open set in $\mathbb R$ is a countable union of open intervals, c.f. Any open subset of $\Bbb R$ is a at most countable union of disjoint open intervals. [Collecting Proofs] .  However, I'm not so sure what would be a good way to prove this in $\overline{\mathbb R}$, the extended real line.  According to Rudin's Real and Complex Analysis , the topology $\tau$ in $\overline{\mathbb R}$ consists of sets of the form $(a,b), [-\infty, a), (a, \infty]$ and any union of segments of this type, where $a,b \in \mathbb R$ are arbitrary real numbers.  I list my proof below, and would appreciate it if someone can confirm its validity, or point out where I'm mistaken, or provide a better proof. My Attempted Proof: Suppose $V\in \tau$, i.e. $V=\bigcup_{t\in S} A_t$ is an open set in $\overline{\mathbb R}$, where $A_t$ is a segment of the form $(a,b), [-\infty, a), (a, \infty]$.  If $-\infty\notin V$ and $\infty \notin V$, then the proof is the same as that in $\mathbb R$. Otherwise, suppose $-\infty\in V$.  Then some $A_t$ must be of the form $[-\infty, a_t)$.  Let $S_0$ be the set of all such $t$'s, and $V_0=\bigcup_{t \in S_0}A_t$.  It follows that $V_0=[-\infty, a_0)$, where $a_0=\sup_{t\in S_0} a_t$.  By the same token, if $\infty \in V$, then let $S_1=\{t:A_t=(a_t, \infty]\}$ and $V_1=\bigcup_{t \in S_1}A_t=(a_1, \infty]$, where $a_1=\inf_{t\in S_1} a_t$. Now let $S_2=S\setminus(S_0\cup S_1)$ and $V_2=\bigcup_{t \in S_2}A_t$.  Note that $V_2$ is an open set in $\mathbb R$, so it must be an at most countable union of segments of the form $(a,b)$.  The proof is hence completed by noting that $V=V_0\cup V_1\cup V_2,$ so it must be an at most countable union of segments of the form $(a,b)$, $[-\infty, a),$ or $(a, \infty]$. Is this proof correct?  Are there better/simpler ways to prove this?  Thanks a lot!","['general-topology', 'real-analysis', 'proof-verification']"
2692408,Standard short exact sequences in Algebraic Geometry,"Exact sequences seem to have a key role throughout Algebraic Geometry in general. For example to deduce vanishings in cohomology and so on. And there seems to be a series of standard short exact sequences which are widely and frequently used again and again. So the motivation for this post should be clear: I thought it would be very nice to have a list of as many standard short exact sequences as possible, providing if possible some short motivation or intuition for each of them. I have looked for such a list already but I haven't found anything. If anyone knows of a reference with such a list, it would also be very appreciated. Here are the standard short exact sequences that I have come across so far: The Euler sequence and its dual $$ 0\to \mathcal{O}_{\mathbb{P}^{n}} \to \mathcal{O}_{\mathbb{P}^{n}}(1)^{\oplus n+1 } \to \mathcal{T}_{\mathbb{P}^{n}} \to 0$$ Sequence associated to an effective Cartier divisor $$ 0\to \mathcal{O}_{X}(-D) \to \mathcal{O}_{X} \to \mathcal{O}_{D} \to 0$$ and the analog sequence for differential $k$ -forms $$ 0\to \Omega^{k}_{X}(-D)\to \Omega^{k}_{X}\to \Omega^{k}_{D} \to 0 $$ Relative cotangent sequence and its dual (I only write the easier to remember geometric version that can be pictured esily for $\pi \colon X\to Y$ smooth varieties and $Z$ a point, as suggested by Vakil in his notes) $$ 0\to \mathcal{T}_{X/Y} \to \mathcal{T}_{X/Z}\to \pi^{*}\mathcal{T}_{Y/Z} \to 0$$ Relative conormal sequence and its dual (again, the easier to picture/remember geometric version when $i\colon Y\to X$ is a closed immersion of smooth varieties) $$ 0\to \mathcal{T}_{Y} \to \mathcal{T}_{X}\mid_{Y} \to \mathcal{N}_{Y/X} \to 0$$ The exponential sequence (in the analytic topolgoy) $$ 0\to \mathbb{Z} \to \mathcal{O}_{X} \to \mathcal{O}_{X}^{\times} \to 0 $$ P.S. I am not sure this if this is a valid question or not. One could say ""don't be lazy and go through the literature yourself to find the answer"". But experience so far shows that this takes a huge amount of time and that invariantly new ""standard"" short exact sequences keep popping out every now and then. I know that this last impression is just because I only started studying Algebraic Geometry recently, and hence I still have a lot to learn (including a lot of exact sequences). But I feel like my study of this area would be much more efficient if I had always with me such a list from the beginning, and maybe other people share this opinion too.","['reference-request', 'big-list', 'algebraic-geometry']"
2692434,Given a smooth function $f$ for which $\lim_\limits{x\to\pm \infty}f^{(n)}(x)=0.$ Do the derivatives of $f(1/x)$ also tend to $0$ as $x\to0$?,"Suppose $f:\mathbb{R} \to \mathbb{R}$ is $C^\infty$ and has the property that, for all $n \ge 0,$ the $n$th derivative $f^{(n)}(x)\to0$ as $x \to \pm\infty$.  If we now define $g(x)=f(1/x)$ for nonzero $x$ and $g(0)=0,$ does it follow that for all $n \ge 0$ we have $g^{(n)}(0)=0$? This came up for me when trying to verify the function $f(x)=e^{-1/x^2}$  for nonzero $x$ with $f(0)=0$ had the property that it is not equal to its power series, since the latter is the zero function. Taking the derivative of this particular $f$ using the chain and product rules became quickly involved, and then I thought that if my question above had answer ""yes"" it would make this (and other) example(s) easier to verify.","['functions', 'limits']"
2692455,Let a and b be such that $-2A^2 + 4A -3I_2 = aA + bI_2$. To find $a + b$.,$A \in M_2$ with characteristic polynomial $p(x) = x^2 -3x - 5$. Let a and b be such that  $-2A^2 + 4A -3I_2 = aA + bI_2$. To find $a + b$.,"['matrices', 'linear-algebra', 'proof-verification']"
2692518,Calculate $ \arctan(x_{1}) \cdot \arctan(x_{2}) $,Let $ x_{1} $ and $ x_{2} $ be the roots of the equation : $ x^2-2\sqrt{2}x+1=0 $ Calculate $ \arctan(x_{1}) \cdot  \arctan(x_{2}) $ The answer should be $ \dfrac{3\pi^2}{64} $ . How does the fact that $ x_{1} $ = $ 1 + \sqrt2 $ = $ \dfrac{1}{x_{2}} $ help?,"['roots', 'trigonometry', 'quadratics']"
2692529,"No simple group of order $1,000,000$","Problem : Prove there are no simple groups of order $1,000,000$. So, I have used Sylow's Theorem to get that the number of Sylow $5$-subgroups is either $1$ (and we're done) or $16$. I am assuming we have $16$, and let $H$ and $K$ be two of these Sylow $5$-subgroups. I'm trying to show $H \cap K$ is normal in $G$. So, $|H\cap K| = |H||K|/|HK| > |H||K|/|G| \approx 244.14$ So since $H\cap K<H$, $|H\cap K|$ divides $|H|$. Thus, $|H \cap K| = 625$ or $3125$. IF $|H\cap K| = 3125$, then $[H \cap K:H] = 5$ which is the smallest prime divisor of $15625$. So $H \cap K$ is normal in $H$ and normal in $K$. This forces $HK$ to be contained in the normalizer of $H \cap K$. Since the normalizer of $H \cap K$ is a subgroup of $G$, then its order must divide $G$. The size of $HK$ is $3125^2$, which is contained in the normalizer. So $3125^2$ must divide $1,000,000$. Contradiction. So the normalizer of $H \cap K$ is all of $G$, and $H \cap K$ is normal. I am completely stuck on what to do if $H \cap K$ has order $625$. Any help would be much appreciated.","['abstract-algebra', 'group-theory', 'sylow-theory']"
2692579,Is Lipschitz norm the other name for Lipschitz constant?,I am seeing the term Lipschitz norm used in some papers and denoted by $$\|\cdot\|_{Lip}$$ Is it the other name for Lipschitz constant?,"['functional-analysis', 'lipschitz-functions', 'terminology']"
2692608,"Finding the surface area of a ""slanted"" solid","How can I find the surface area of this solid? I know that the area of the front and back is $8·10$ , and that the area of the top and bottom is $8·6$ , but I'm not sure how to find the area of the right and left sides. Thanks.","['solid-geometry', 'geometry']"
2692631,Solve $3x^2+2=0$ for $ x$?,"Here is the full question: $ f(x) = x^3 + 2λx $ where $\lambda $ is a real parameter. Find its stationary point(s) and discuss the nature of the stationary point(s), in the case where $\lambda > 0$ , $\lambda  = 0$ , and $\lambda < 0$ . I tried to solve $3x^2 + 2 = 0$ for $x$ , but I can only get $\sqrt{-\frac 23}$ as a root. So I don't know how to find stationary points of $f$ .","['algebra-precalculus', 'quadratics', 'calculus', 'derivatives']"
2692678,Why Does the Definition of a Topology via Neighborhoods Include This Axiom,"My question concerns the Definition via Neighborhoods of a topological space. I am having trouble seeing why $(4)$ is necessary in the definition, which I'll briefly run through below. Let $X$ be a set and define a function $\mathcal{N}:X \to \mathcal{P}(X)$ which assigns to each $x \in X$ a nonempty collection of subsets of $X$, which we call neighborhoods of $x$, satisfying the following properties: If $N \in \mathcal{N}(x)$ then $x \in N$. If $N,M \in \mathcal{N}(x)$ then $N\cap M \in \mathcal{N}(x)$. If $N \in \mathcal{N}(x)$ then any set $Y\supseteq N$ is also in $\mathcal{N}(x)$. If $N \in \mathcal{N}(x)$ then there exists an $M \subseteq N$ in $\mathcal{N}(x)$ such that $N \in \mathcal{N}(y)$ for all $y \in M$. Define a set $U \subseteq X$ to be open in $X$ if $U$ is a neighborhood of all of its points. As I mentioned above, I am not sure why we need $(4)$ because (I think) I can recover the standard definition of a topology via open sets just from $(1)$ through $(3)$. Assuming the definition of an open set given above we see that clearly $\varnothing$ is open because it is vacuously a neighborhood of all of its points. Moreover, $X$ is open by $(3)$. Finite intersections of open sets are open by $(2)$, and arbitrary unions of open sets are open by $(3)$. Wikipedia mentions that $(4)$ ""has a very important use in the structure of the theory"", but I don't see how this is possible if I can recover the standard definition of a topology via open sets without it. I feel that I must be missing something simple. Have I made a mistake? Do you actually need $(4)$ to recover the standard definition of a topology via open sets? If not, then how is $(4)$ important?","['general-topology', 'definition']"
2692720,Existence of another critical point,"I would like some input in my proof on this question: Let $f:\mathbb{R} \to \mathbb{R}$ smooth, with local minimum at $x=0$, and suppose that this minimum it is not global. Show that there is another critical point besides $x=0$. My answer: Suppose $x=0$ is not a global minimum, hence, $\exists x_{1} \in \mathbb{R}:f(x_{1}) \lt f(0).$ Without loss of generality, suppose $x_{1} \lt 0$. By the Mean Value Theorem, $\exists c \in (x_{1},0):f'(c)=\frac{f(0)-f(x_{1})}{x_{1}} \gt 0$. But $x=0$ is local minimum, therefore, $\exists \delta \gt 0:y \in (-\delta,\delta) \implies f(y) \geq f(0)$. Consider the closed interval $[-\delta,0]$. By the Mean Value Theorem, $\exists k \in (-\delta,0): f'(k)=\frac{f(0)-f(-\delta)}{\delta} \lt 0$. Since $f$ is smooth, it is continuous in $\mathbb{R}$. Therefore, we have $c,k \in (x_{1},0)$ and $f'(c) \gt 0$ and $f'(k) \lt 0$, hence, $\exists z \in (c,k): f'(z) =0$ and $z$ is a critical point of $f$.","['derivatives', 'real-analysis', 'continuity', 'proof-verification']"
2692724,Is the expectation of the minimum of a function equal to the minimum of the expectation?,"Given two random variables $X$ and $Y$ and a differentiable function let $f(Y|X=x)$ be a function of Y for fixed values of $X$. Furthermore let $$\tilde{Y} = \text{argmin}_Y \ [f(Y|X=x)]$$ so that $f(\tilde{Y}|X=x) = \text{min} \ f(Y|X=x)$. Denote the expectation of $f(Y|X)$ over $X$ as $$E_X[f(Y|X)]=\int_X f(Y|X)p(X)dX.$$ Is $$\text{min} \ E_X[f(Y|X)] =\int_X f(\tilde{Y}|X)p(X)dX, $$
that is, is the minimum of the expectation of $f$ across $X$ equal to the expectation of the pointwise minimized function?","['expectation', 'statistics', 'optimization']"
2692763,Solve the equation $\log_2(\frac{8}{2^x}-1)=x-2$,"This equation comes from the book of Prilepko. It looks sufficiently simple but I want to know if my solution is correct. $\log_2(\frac{8}{2^x}-1)=x-2$ I have only been able to transform into this: $\log_2(\frac{8-2^x}{2^x})=x-2$ $\iff$ $\log_2(8-2^x)=2x-2$ $\iff$ $8-2^x=2^{2x-2}$ $\iff$ $32-4.2^x-2^{2x}= 0$ Let $t=2^x$ $-t^2-4t+32=0$ This equation will produce $t=-8$ and $t=4$ Therefore $x=2$. Another question that I wish to ask is when solving these logarithmic equations, one very often substitute a dummy variable to overcome the restriction caused by the order of operations. For example, you cannot do much directly with $5^{2x}-130.5^x+625$. But let $t=5^x$, then you can easily factorize the this equation into $(t-125)(t-5)=0$, hence $(5^x-125)(5^x-5)=0$. Isn't this a sort of manipulating symbols according to certain prescribed rules? Is there any logical difficulty with this kind of operation? Since by substituting a new variable, it means that this variable must inherit all properties which the object of the substitution originally possesses. For example, if $a^x$ is the object of substitution for $t$, then if $a<0$ and x can assumed a form of rational power, doesn't this make no sense at all? Do you know any example in elementary mathematics where this method of substitution can yield contradictory result?",['algebra-precalculus']
2692782,The Chinese Remainder theorem is a geometric fact (Vakil 4.4.11),"I am reading Ravi Vakil's foundation of algebraic geometry, 4.4.11. He views the Chinese Remainder theorem
$$\mathbb Z/60 \cong \mathbb Z/4 \times \mathbb Z/3 \times \mathbb Z/5$$ by using scheme theory. We look at the structure sheaf of $\operatorname{Spec}(\mathbb Z/60)=\{(2),(3),(5)\}$(easy to see it has the discrete topology). He claims that the stalk of the structure sheaf at those three points are $\mathbb Z/4, \mathbb Z/3, \mathbb Z/5$ respectively. I have trouble verifying this. By his exercise 4.3.F, we know these stalks should be $(\mathbb Z/60)_{(2)}, (\mathbb Z/60)_{(3)}, (\mathbb Z/60)_{(5)}$ (localizations at the primes ideals) respectively. But how to show for example $$(\mathbb Z/60)_{(2)}\cong \mathbb Z/4$$ Please let me know if I interpret his meaning wrongly.","['abstract-algebra', 'algebraic-geometry']"
2692820,The vanishing scheme of for a graded ring generated by elements of degree 1 (Vakil 4.5.P),"I am working on the following exercise of Ravi Vakil's Foundations of algebraic geometry. 4.5.P. EXERCISE. If $S_•$ is generated in degree 1, and $f ∈ S_+$ is homogeneous,
  explain how to define $V(f)$ “in” $\text{Proj} S_•$, the vanishing scheme of $f$. (Warning: f in general isn’t a function on $\text{Proj} S_•$. We will later interpret it as something close:a section of a line bundle, see for example §14.1.2.) Hence define $V(I)$ for any homogeneous ideal I of $S_+$. I guess as a set $V(f)=\{P\in \operatorname{Proj} S_•: f\in P\}$.
But I think this problem shouldn't be this trivial and he probably wants us to construct a scheme structure on it and I don't see how to do it. I guess we need to use the condition ""$S_•$ is generated in degree $1$"" (i.e. generated by degree $1$ elements as an algebra) and construct a structure sheaf on it ( really ?). Let me know if you think I interpret it wrongly.","['projective-schemes', 'algebraic-geometry']"
2692853,Conormal sheaf and ideal sheaf both isomorphic to O(-D)?,"Let $i: D\hookrightarrow X$ be a closed subscheme which we can think of as an effective Cartier divisor. Then Hartshorne 6.18 claims that $\mathscr{J}_D\cong \mathscr{O}(-D)$, where the LHS is the ideal sheaf of the closed embedding $D\hookrightarrow X$, and the RHS is the invertible sheaf associated to the divisor $-D$. But Vakil 21.2.H claims that in fact $\mathscr{N}^\vee_{D/X}\cong \mathscr{O}(-D)|_D$, where the LHS is the conormal sheaf, namely $i^*(\mathscr{J}_D/\mathscr{J}_D^2)$. Doesn't this imply that $i^*(\mathscr{J}_D) \cong i^*(\mathscr{J}_D/\mathscr{J}_D^2)$? (Which doesn't make sense because it would imply $i^*(\mathscr{J}_D^2)=0$).",['algebraic-geometry']
2692881,Simple proof of $\ln x \leq x-1$,"Is this simple proof for $\ln x \leq x-1$ valid? Proof: Since $\ln$ is concave, let $y, x \in \mathbb{R}_{++}.$ We have that $\ln(y) \leq \ln(x) + \frac{d\ln x}{dx}(y-x)$. Since this is valid $\forall x, y \in \mathbb{R}_{++}$, it must be valid for an arbitrary $y$ and $x=1$. Then, we get that $\ln(y) \leq \frac{1}{x}(y-x) \Rightarrow \ln(y) \leq y-1$. Thanks","['logarithms', 'functions', 'proof-verification']"
2692897,What are some mathematical topics that involve adding and multiplying pictures?,"Let me give you an example of what I mean. Flag algebras are a tool used in extremal graph theory which involve writing inequalities that look like: (It's not too important to my question what this inequality means, but let me give you some context. Informally, the things we're adding and multiplying are probabilities that a random group of vertices in a large graph will induce some specific small subgraph. To make some manipulations rigorously justified, this is not precisely what we mean; instead, they are the limits of such probabilities over a convergent sequence of graphs.) Aside from being potentially useful in solving math problems I'm curious about, I enjoy using, thinking about, and even looking at statements about flag algebras, because these equations and inequalities just look so cool! Instead of multiplying, adding, and comparing letters and numbers, we get to do the same thing to pictures of things. So my question is: what are some other topics in mathematics where we get to do the same thing? Obviously, you can always give any name you like to a variable, like those math problems you see on facebook where cherry plus banana is equal to three times hamburger. I'm not interested in examples like this, because there's nothing special about those variable names. Instead I'm interested in cases satisfying the following conditions: Mathematicians actually working with these objects commonly represent the things they are adding or multiplying or whatever (in general, performing algebraic manipulations on) by pictures. The pictures used to represent these objects are actually helpful for understanding what the objects are. It's okay if it's not adding or multiplying specifically we're doing, as long as we're manipulating the pictures in ways traditionally reserved for numbers or variables. For example, the things represented by pictures could be elements of some algebraic object (group, ring, etc.)","['abstract-algebra', 'notation', 'soft-question']"
2692913,"$x_{1}$ and $x_{2}$ roots of $f$ with $f'(x_{1}) \gt 0$ and $f'(x_{2}) \gt 0$. Existence of another root between $(x_{1},x_{2})$.","I'm struggling with this question. I tried proving by contradiction but I don't know if I'm doing it right. Any help is highly appreciated! Let $f:\mathbb{R} \to \mathbb{R}$ be smooth such as $f'(x_{1}) \gt 0$ and $f'(x_{2}) \gt 0$ for $x_{1} \lt x_{2}$ roots of $f$. Show that $f$ has at least one root in $(x_{1},x_{2})$. My atempt: By Rolle's Theorem, $\exists c \in (x_{1},x_{2}):f'(c)=0$, therefore, $f(c) \gt 0$. Suppose by contradiction that $\nexists k \in (x_{1},x_{2}):f(k)=0.$ Therefore, $\forall x \in (c,x_{2}), f'(x) \lt 0$. Since $f$ is smooth, $f'$ is continuous. So, $\exists \delta \gt 0: f'(y) \gt 0, \forall y \in (x_{2}-\delta,x_{2}+\delta)$. Let $y=x_{2}-\frac{\delta}{2}$. Since $y \in (c,x_{2}) \implies f'(y) \lt 0$. Contradiction.","['derivatives', 'real-analysis', 'continuity', 'proof-verification']"
2692915,Twice differentiable function not equal to $0$,"This is a question in the undergraduate-level textbook ""Advanced Calculus"" by Fitzpatrick. Suppose that a function $f:\mathbb{R}\rightarrow\mathbb{R}$ is twice differentiable such that for $\forall x$, $f'(x)\leq f(x)$, and $f(0)=0$. Then is $f$ the zero function? The answer to this is not true as I was able to find a counter-example $f^*(x)= 1- e^x$. However we have only just learned about differentiation, the mean-value theorem and how to find extremes using 1st and 2nd derivatives, and we have only seen derivatives of polynomials so far, but I don't know how to disprove the above statement by using these. (EDIT) For $1−e^x$ to be a valid counter-example, I need to ""officially know"" that the exponential function's derivative is equal to itself. But exponential functions are in the next chapter. Therefore unless I want to ""cheat"", I need to think of another function.","['derivatives', 'real-analysis', 'calculus']"
2693008,"If two meromorphic function fields on compact riemann surfaces isomorphic, then they are isomorphic","This is related to Forster Riemann surface Ex 8.1 Let $X,Y$ be two compact riemann surfaces. Let $M(X)$ and $M(Y)$ be meromorphic function fields of $X$ and $Y$ respectively. If $M(X)\cong M(Y)$, then $X\cong Y$ holomorphically. $Q1:$Hint says represent $X$ and $Y$ by algebraic functions. I do not have $GAGA$ at disposal. If I can use $GAGA$, then I am done as I obtain birational map first and extend by singularity having codimension less than 2. How do I represent $X,Y$ by algebraic functions? Since the book does not assume algebraic geometry, I guess there should be a way without resorting to algebraic geometric argument. $Q2:$ I tried the following take any $f\in M(X)$ and its image $f'\in M(Y)$. I can construct algebraic surface $\tilde{X},\tilde{Y}$covering $X,Y$ respectively. Then I can replace $\tilde{Y}$ by $\tilde{X}$ via direct construction through holomorphic sheaf's etale espace of $Y$ and $X$ and matching the fiber to identify. This process can be reversed. Thus $\tilde{Y}\cong\tilde{X}$. I want to descend this biholomorphism down to $X\to Y$. How should I proceed?","['riemann-surfaces', 'complex-analysis', 'complex-geometry']"
2693033,Definite integral: $\int_0^\infty \frac{x dx}{(1+x^2)(1+e^{\pi x})}$,"I need help computing the value of the following definite improper integral:
$$\int_0^\infty \frac{x dx}{(1+x^2)(1+e^{\pi x})}=\text{?}$$
Here are my thoughts and attempts: I tried using the Laplace Transform identity for definite integrals, with no luck (since I can only compute the Laplace Transform of $\frac{1}{e^{\pi x}+1}$ in terms of the digamma function... yuck) I can't use the residue theorem, since the integral is from $0$ to $\infty$ and the integrand is not an even function I would like to expand $\frac{x}{1+x^2}=\frac{1/x}{1-(-1/x^2)}$ as a geometric series, but it wouldn't always converge since $x$ goes from $0$ to $\infty$ CONTEXT: The integral came up in Jack D'Aurizio's answer to this question. Any ideas?","['real-analysis', 'complex-analysis', 'improper-integrals', 'integration', 'definite-integrals']"
2693053,Statistical error associated with a bin count,"I have a collection of data points. I have computed the histogram of this data to create the empirical distribution. How can estimated the error in the value at each bin. Based on the the total number of data points and the counts at each bin. The data comes from chemical random reactions, between two states. The total number of events may vary according to the lifetime of chemicals used, but considerable big >>5000 data points. The number of bins used is 100 and of homogeneous width.  The intention of estimate the error is to propagate this error trough an equation that depends on the distribution of the process and therefore estimate the error of the quantity computed from this histogram.","['statistics', 'error-propagation', 'standard-error']"
2693066,Inverse bin ball problem,"(Sorry for the title. I has difficulty summarising this problem. I am open to suggestions for a new title.) Suppose there are a random number of bins of random discrete sizes, each of which contain a random number of balls. Every ball has size 1. The setup is as follows: Bin $i$ has size $S_i$ and contains $K_i$ balls. The total number of balls, $B$, is given by $\sum_{i=1}^N K_i$. The combined volume of all bins, $V$, is given by $\sum_{i=1}^N S_i$. Assume the following are given: $P(S_i = s)$ for all $s \in \{1, 2, 3,...\}$ $P(K_i = k | S_i = s)$ for all $k,s \in \{1, 2, 3,...\}$ $P(B = b)$ for all $b \in \{1, 2, 3,...\}$ $P(V = v)$ for all $v \in \{1, 2, 3,...\}$ You may also assume that none of the above variables can take the value $0$. The problem is this. In terms of the above, find an expression for: $P(N=n)$, the probability that the number of bins is $n$.","['combinations', 'probability-theory', 'probability-distributions', 'probability', 'combinatorics']"
2693074,Unit ball in $l^{2}$ is bounded and closed but not compact.,"I was told that the answer I gave to this question didn't actually show that the unit ball wasn't closed. Could someone please help me figure out how to do this? this is the original answer I gave ($S$ refers to the unit ball). ""We consider $S$ as stated. Clearly, $e_{i} \in \ell^{2}$ and $\|e_{i}\|_{2} = 1$ for all $e_{i}$, so $S$ is bounded and closed. .But since for $i \neq j$ $\|e_{i} - e_{j}\| = \sqrt{2}, $ the sequence $(e_{i})_{i=1}^{\infty}$ can not possibly have any convergent sub-sequences as they will not be Cauchy, so it is not compact.""","['functional-analysis', 'lp-spaces', 'compactness', 'general-topology', 'metric-spaces']"
2693076,Simplifying square of integral in general,"For a real-valued function $f=f(x)$, over the real variable $x$, with the following integral $$ \left[ \int_{a}^{b} f(x)dx \right]^{2}, $$ is there a known general method/approach to handle this as to remove the squaring from over the integral, say by making changes to the integrand and/or interval, and then proceed with a form like $\int g(x)dx$ afterwards, were $g(x)$ is some other function?","['real-analysis', 'calculus', 'functional-analysis', 'integration', 'analysis']"
2693086,Why are continuous partial derivatives a sufficient condition for differentiability?,"$\mathbf {Theorem}$: if $\ f$ is a function of $\ x$ and $\ y$, where $\ f_{x}$ and $\ f_{y}$ are continuous in an open region $\ R$, then $\ f$ is differentiable on $\ R$. Proof:Let $\ S$ be a surface defined by $\ z=f(x,y)$, where $\ f$, $\ f_{x}$, and $\ f_{y}$ are continuous at $\ (x,y)$. Let $\Delta z$ be the total change in $\ f$ from two points on the surface $\ S$ , let $\Delta z_{x}$ be the change in $\ f$ when $\ y$ is held constant and let $\Delta z_{y}$ be the change in $\ f$ when x is held constant. 
$$\Delta z=f(x+\Delta x, y+\Delta y)-f(x,y)$$
$$\Delta z= [f(x+\Delta x,y)-f(x,y)]+[f(x+\Delta x, y+\Delta y)-f(x+\Delta x,y)]$$
$$\Delta z= \Delta z_{x}+\Delta z_{y}$$ By the Mean Value Theorem there is some $\ x_{1}$ between $\ x$ and $\ x+\Delta x$ and some $\ y_{1}$ between $\ y$ and $\ y+\Delta y$ such that
$$\Delta z_{x}=f_{x}(x_{1},y)\Delta x$$
$$\Delta z_{y}=f_{y}(x+\Delta x,y_{1})\Delta y$$ If you define $\epsilon_{1}$ and $\epsilon_{2}$ as
$$\epsilon_{1}=f_{x}(x_{1},y)-f_{x}(x,y)$$
$$\epsilon_{2}=f_{y}(x+\Delta x, y_{1})-f_{y}(x,y)$$ It follows that
$$\Delta z=\Delta z_{x}+\Delta z_{y}=[f_{x}(x,y)\Delta x + f_{y}(x,y)\Delta y]+\epsilon_{1}\Delta x + \epsilon_{2}\Delta y$$ By the continuity of $\ f_{x}$ and $\ f_{y}$ and the fact that $\ x\le x_{1}\le x+\Delta x$, and $\ y\le y_{1}\le y+\Delta y$, it follows that
$$\epsilon_{1}\rightarrow 0\ \ \text{and}\ \ \epsilon_{2}\rightarrow 0\ \ \text{as}$$
$$\Delta x\rightarrow 0\ \ \text{and}\ \ \Delta y\rightarrow 0$$ Therefore, by definition, $\ f$ is differentiable. My question is, why do the continuity of the partial derivatives $\ f_{x}$ and $\ f_{y}$ and the intervals that $\ x_{1}$ and $\ y_{1}$ lie on imply that $\ f$ is differentiable?","['multivariable-calculus', 'partial-derivative', 'continuity']"
2693088,prove that for any nonsingular matrix $A$ there exist $X$ such that $X^2=A$,"Prove that given any  matrix A, where $$\det(A)\neq0$$ $$A\in M_{n,n}(\mathbb C)$$
the following equation
$$X^2=A$$
always has a solution.
Should I do something with Jordan Normal form?
Any help will be appreciated","['matrices', 'jordan-normal-form', 'linear-algebra']"
2693111,"When can we interchange $\partial/\partial x$ with integral sign, or commute two such operators in general?","In applied mathematics, when can we assume that we are allowed to do this: $$ \frac{\partial}{\partial x}\int_{x}\int_{y}\cdots\int f(x, y,\cdots)\ dx\ dy\ d(\cdots)= \int_{x}\int_{y}\cdots\int \frac{\partial}{\partial x}\left[f(x, y,\cdots)\right]\ dx\ dy\ d(\cdots),$$ where $f(x,y,\cdots)$ is a general continuous and differentiable function over the domain of the variables $(x, y, \cdots)$? If we view differentiation and integral here as operators, then a more general question would be about the conditions (or properties) that would make two general operators $T_{1}[\cdot]$ and $T_{2}[\cdot]$ commute? I am interested here in applying such rules to practical calculations (e.g. in physical sciences), so any relevant practical notes or observations about such conditions would be nice.","['real-analysis', 'operator-theory', 'calculus', 'functional-analysis', 'integration']"
2693128,Showing that an injective $^*$-homomorphism between two $C^*$-algebras is isometric.,"Problem: ""Let $(A,\|\cdot\|)$ and $(B,\|\cdot\|)$ be unital $C^*$-algebras and let $\phi:A\to B$ be an injective $^*$-homomorphism. Show that $\phi$ is isometric. Hint : Treat the case of self-adjoint elements firstly and use the fact that it suffices to consider the case when $A$ and $B$ are commutative."" I'll collect together the key facts that, I think, I need to use: For $C^*$-algebras $(A,\|\cdot\|),(B,\|\cdot\|)$ we call $\phi: A\to B$ a $^*$ -homomorphism if (i) $\phi$ is linear, (ii) $\phi(a_1a_2)=\phi(a_1)\phi(a_2)\,\forall a_1,a_2\in A$, and (iii) $\phi(a^*)=\phi(a)^*\,\forall a\in A$. For $C^*$-algebras $(A,\|\cdot\|),(B,\|\cdot\|)$ and $\phi: A\to B$ we have that $r(a)=\|a\|\,\forall a\in A: a=a^*$, where $r(a)$ is the spectral radius of $a\in A$. Attempt: I've made multiple attempts at this problem, and I'm not sure which, if any, are going to yield any fruit. I know that in order to show that this injective $^*$-homomorphism is isometric I need to show that $\|a\|=\|\phi(a)\|,\,\forall a\in A$. Consider firstly those $a\in A:a=a^*$. Then we know that by the $C^*$ -property $\|a\|^2=\|a^*a\|$ for self-adjoint $a\in A$. Then: $$\|a\|^2=\|a^*a\|=r(a^*a)=r(a^*)r(a)=r(a)^2$$ But I don't see that this gets me anywhere, other than reiterating what I already know. Is there a connection between $r(a)$ and $\phi(a)$ that I can make use of? It seems to me, that in some sense, if the properties above for $\phi$ held for $r$ I might be able to get somewhere. Alternatively, since we have an injective homomorphism we know that $\phi$ maps the identity element in $A$ to the identity element in $B$. Then, consider: $$1=\|e_B\|=\|\phi(e_A)\|=\|\phi(a^*a)\|=\|\phi(a^*)\phi(a)\|=\|\phi(a)^*\phi(a)\|$$ And then $\phi(a)^*=b^*$ for some $b\in B:b=b^*$. Then we have that, $$\|\phi(a)^*\phi(a)\|=\|b^*b\|=\|b\|^2$$ This, again, doesn't tell me anything that I already know. Can anybody direct me on how best to proceed? In particular, in accordance with the hint, what exactly am I being told when hinted that ""it suffices to consider the case when $A$ and $B$ are commutative?","['c-star-algebras', 'banach-algebras', 'operator-theory', 'functional-analysis', 'operator-algebras']"
2693138,What does $x^TAx$?,What does the following mean? I know that $x^Tx$ is the magnitude of $x$. What does the following formula represent intuitively? $x$ is a vector and $A$ is some scaling matrix. The given is $x^T A x i$ (Ignore the i) I'm learning about positive definiteness.,['matrices']
2693226,"Prove that if $G$ is a $k$-edge-connected graph, then $G+K_1$ is $(k+1)$ -edge-connected (my proof)","I have a proof that is different from the ones proposed previously and I want to see if my proof works as well. I want to do my proof by contradiction. First, let $H= G +K_1$ and suppose for the sake of contradiction that it is not $(k+1)$-edge-connected. Let $X$ be a vertex-cut of $H$ where $|X|=k$. Also, let $v$ be the vertex of $K_1$ in $H$. Case 1: If $v\notin\ X$, then since $v$ is adjacent to all other vertices in G, there is an edge from each vertex in $H-X$ to $v$. Thus, $H-X$ is connected, which is a contradiction. Case 2: If $v\in\ X$, then $H-X= G- (X-{v})$. However since $G$ is $k$-edge-connected and $|X-v|=k-1$, then $G- (X-{v})$ is still connected because we have not removed enough vertices in order for sufficient edges to be removed to disconnect the graph. This is a contradiction. Then, $H$ is $(k+1)$-edge-connected. I was going to do an edge-cut instead but I am not sure how to fix it to make it work that way. For the first case, if I instead look at this as $X$ is an edge-cut can I say this is the case where no edge in the set is adjacent to $v$ , but then $G-X$ is still connected because of the remaining edges, there is an edge connecting every vertex of $G$ to $v$?","['graph-theory', 'connectedness', 'proof-verification', 'proof-writing', 'discrete-mathematics']"
2693228,Distance between a point and a line and between two lines,"Let $P = (-5, 3, 4)$ , $Q = (-6, 0, 3)$ , $R = (-7, 1, 6)$ and $S = (-4, 2, 2)$ . Let $A$ be the line passing through $P$ and $Q$ , and let $B$ be the line passing through $R$ and $S$ . a) What is the distance between $R$ and $A$ ? b) What is the distance between $A$ and $B$ ? I am quite confused on how to start with this problem. Firstly, I am not entirely sure how I will find the distance between the point and the line. Would that distance simply be the normal vector multiplied by the projection? If so, how exactly would I calculate the projection here? No equations for the lines are given so I am quite confused. Also, for the shortest distance between two lines, will it be a similar approach of finding the normal vector and projection? I am not entirely sure how to proceed here. Any help would be highly appreciated!","['linear-algebra', 'geometry']"
2693230,Flipping a set of unfair coins [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Let's say I have $5$ unfair coins. Each with an independent, known, probability of landing on heads. I flip each coin once. How can I find the probability that I get $3$ or more heads? Example: $P(H_1) = .38$ $P(H_2) = .18$ $P(H_3) = .71$ $P(H_4) = .66$ $P(H_5) = .29$","['generating-functions', 'statistics', 'probability']"
2693243,Is $x^2 \equiv 1 \pmod{p^k} \iff x \equiv \pm 1 \pmod {p^k}$ for odd prime $p$?,"Problem: As the title says, is $x^2 \equiv 1 \pmod {p^k} \iff x \equiv \pm 1 \pmod {p^k}$ for odd prime $p$? If not, is it at least true that there are two solutions to the congruence equation? Attempt: I am a beginner in number theory, and I am not sure if the statement in question is true. The following is my attempt. Assume $x^2 \equiv 1 \pmod {p^k}$. Then $p^k | (x-1)(x+1) \Rightarrow p^k|(x-1)$ or $p^k|(x+1)$, because if $p^k$ can divide both, then $p^k|2$ which is false. This shows the forward direction. The converse is easy. For any $y^2 \equiv 1 \pmod {p^k}$, $y^2 \equiv x^2 \pmod {p^k}$ which yields the conclusion before, so $\pm 1$ are the only solutions $\pmod {p^k}$.","['number-theory', 'quadratic-residues', 'elementary-number-theory']"
2693302,Intouch and Extouch triangles - An Interesting Result,"Consider a ∆ABC. Let the triangle formed by the points of contact of the sides of a given triangle with the excircles corresponding to these sides be called the extouch triangle; and let the triangle formed by joining, the points of contact of the three sides with the inscribed circle be called the intouch triangle. Prove that these two triangles have equal areas, and that the midpoint of their centroids is the centroid of ∆ABC. Attached is a proof I found: Check Page 3 of this PDF I've been trying really hard for an analytical proof, one using only coordinate geometry - but haven't been able to get anywhere. Could someone please help me with a proof using coordinate geometry only? Assuming coordinates for ∆ABC and then finding the vertices of the intouch and extouch triangles will definitely solve the problem, but it's getting really lengthy and cumbersome. (The areas can be proved equal using the determinant, and calculation of centroid is easy) Is there anything I'm missing? 
Could someone help me find the vertices of the intouch and extouch triangles? ( the result should be interesting, for the midpoint of the two centroids coincides with the centroid of ∆ABC ) A detailed solution, or guidance in the right direction would help! (The former, preferably) Thanks! P.S. You can find a neat diagram on Page 4 of the PDF, I'll add it here to the question if need be.","['circles', 'coordinate-systems', 'analytic-geometry', 'triangles', 'geometry']"
2693323,When to use cumulative moving average vs a simple moving average?,"After reviewing the Wikipedia page on moving averages , the difference between the simple moving average and cumulative moving average are clear: 1) Simple moving average only considers the last n observations, and for every additional observation added to the average, the oldest one gets dropped 2) Cumulative moving average considers all prior observations However, I am confused as to which moving average to use to smooth out data and identify trends. As seen in the linked picture above, the cumulative moving average is quite distinctly different from both the observations themselves and the 4 period moving average. Is there a rule of thumb of when to use one or the other?","['statistics', 'data-analysis']"
2693362,Prove that $ \int_{0}^{c} \frac{\sin(\frac{x}{2})x~dx}{\sqrt{\cos(x) - \cos(c)}} = \sqrt{2} \pi \ln(\sec(\frac{c}{2}))$,"As the title says, I want to find a way calculate the following integral$ \int_{0}^{c} \frac{\sin(x/2)x~dx}{\sqrt{\cos(x) - \cos(c)}}$, which I know is equal to $\sqrt{2} \pi \ln(\sec(\frac{c}{2}))$. At first glance, I thought this would not be very difficult to prove (and maybe it isn't), but after some straighforward manipulations, I was unable to make the $\pi$ factor appear. Obs: $ 0<c < \pi$.","['integration', 'definite-integrals', 'trigonometric-integrals']"
2693400,"If a plane curve has curvature bounded from below, is it contained in a disk?","Let $\gamma: (0,1) \to \mathbb{R}^2$ be a $C^\infty$ regular plane curve, and suppose that its curvature is at least $k_0$ everywhere. Is the image of $\gamma$ contained in disk of radius $\frac{1}{k_0}$? Intuitively, it seems likely to be true. If we choose $p$ at a distance of $\frac{1}{k_0}$ from and perpendicular to $\gamma(0)$, then it seems like the curve will be inching towards $p$. However, I can't seem to prove that this is the case. If the image of $\gamma$ is in $\mathbb{R}^3$ (or $\mathbb{R}^n$ for any $n > 2$), then I believe the result is false, since we can just take tightly wound helix that travels upwards very high. Therefore, if the result is true in $\mathbb{R}^2$, then I think it really uses the $2$-dimensional-ness of the space. One thing I know is that if $|\gamma(t)|$ is maximized when $t = t_0$, then $|k(t_0)| \ge \frac{1}{|\gamma(t_0)|}$. Maybe we can translate the curve so that the $p$ defined above is the origin, and then use something like this somehow? The inequality goes in the wrong direction, so we probably need some sort of opposite result, but I'm not sure what that result would be.","['differential-geometry', 'plane-curves']"
2693418,PDE - Wave Equation,"Let $A(x) = (a^{ij}(x))_{ij}$ , $i, j = 1, 2, 3$ be a smooth matrix-valued function on $\mathbb{R}^3$ such that $a^{ij} = a^{ji}$ , and there exists constants $c, C$ such that $c|\zeta|^2 \le \langle A(x)\zeta, \zeta \rangle \le C|\zeta|^2$ for all $(x, \zeta) \in \mathbb{R}^3$ x $\mathbb{R}^3$ . Show that if $u$ is a smooth solution to the variable-coefficient wave equation: $\partial_t ^2 u$ - div $(A \nabla u) = 0$ , such that $u$ and its derivatives decay rapidly as $|x| \rightarrow \infty$ (say, bounded by $|x|^{-3/2 - \epsilon}$ for some $\epsilon > 0$ ), then: $E(t) := \frac{1}{2} \int_{\mathbb{R}^3} (|\partial_t u|^2 + \langle A \nabla_x u, \nabla_x u \rangle) dx$ is conserved. This is what I've done so far: $E(t) := \frac{1}{2} \int_{\mathbb{R}^3} (|d_t u|^2 + \langle A \nabla u, \nabla u \rangle) dx$ = $\int_{\mathbb{R}^3}(u_t u_{tt} + \frac{1}{2} [A \nabla u_t \cdot \nabla u + A \nabla u \cdot \nabla u_t])dx$ = $\int_{\mathbb{R}^3} (u_t \nabla \cdot (A \nabla u) + \frac{1}{2}[A \nabla u_t \cdot u + A \nabla u \cdot \nabla u_t])dx$ But I don't know where to go for the next step. I am honestly completely stuck on this part. Any help/guidance on where to go next would be great. Thank you.","['multivariable-calculus', 'wave-equation', 'partial-differential-equations']"
2693429,Inequality of determinant and product of diagonal elements of a matrix [duplicate],"This question already has an answer here : If $M$ is positive definite, then $\operatorname{det}{(M)}\leq \prod_i m_{ii}$ (1 answer) Closed 4 years ago . Let $A$ be a symmetric, positive definite matrix. Is is true that the det $ A$ (which is the product of eigenvalues) is smaller or equal to the product of diagonal elements of $A$ ? I could not prove it, and not even sure if the inequality above is true.","['positive-definite', 'linear-algebra', 'determinant']"
2693470,Limit at odd integer for $x$,"$$\lim_{x\to a}\frac{1}{(a^2-x^2)^2}\cdot\left(\frac{a^2+x^2}{ax}-2\sin\frac{a\pi}{2}\sin\frac{\pi x}2\right)=?$$ if $a$ is an odd integer. The way I set out is first assuming $a=1$ and seeing if I can spot some pattern. Now, if I rewrite this limit out as: $$\lim_{x\to 1}\frac{1}{(1-x^2)^2}\cdot\left(\frac{1+x^2}{x}-2\sin\frac{\pi x}2\right)=?$$ Now, you can clearly see that the denominator is of the form $0^4$ (due to the $(1-x^2)^2$), whereas the numerator is, at max, $0^2$ (due to the $x^2$). Since denominator has a higher power of zero than the numerator, I believe that the limit won't exist. However, my textbook says this limit exists and has a finite value. So, I wish to ask what is the fault in my reasoning.",['limits']
2693471,epimorphism of fppf sheaves is an fppf morphism,Suppose $0\to F\to G \to H\to 0$ is an exact sequence of group schemes (over some base scheme $S$) by which I mean that the corresponding sequence of fppf-sheaves is exact. I read somewhere that the surjectivity of the sequence of fppf-sheaves is equivalent to the fact that the morphism $G\to H$ is fppf (faithfully flat and locally of finite presentation). I was able to prove one of the directions: If $G\to H$ is fppf then the sequence of fppf-sheaves is surjective. I'm not sure how to prove the other direction. Any help/reference would be much appreciated.,"['category-theory', 'sheaf-theory', 'topos-theory', 'algebraic-geometry']"
2693481,Why did this extraneous root creep into the solution?,"I was solving this equation and proceeded as follows: $$\arcsin (1-x) - 2\arcsin (x) = \frac{π}{2}$$ $$\implies \arcsin(1-x) = \frac{π}{2} + 2\arcsin (x)$$
$$\implies \sin (\arcsin (1-x)) = \sin \left( \frac {π}{2} + 2\arcsin (x)\right)$$
 $$\implies (1-x) = \cos \left(2\arcsin(x)\right)$$
 $$\require{cancel}\implies \cancel{1}-x =\cancel{1}- 2 \left(\sin\arcsin (x)\right)^2$$
 $$\implies -x = -2x^2$$
$$\therefore x = 0$$
 Or $$ x=\frac{1}{2}$$ However, $x=\frac{1}{2}$ doesn't satisfy the original equation. I understand that extraneous roots do creep in while solving inverse trig problems, but I wonder why it crept in here. If possible (if it doesn't make the question too broad), I'd like to know the general causes for the occurrence of extraneous roots in inverse trig equations, too.",['trigonometry']
2693503,When are the Laws of Exponents correct?,"The rules of powers are in highschool books often briefly stated in the following way: $\displaystyle a^n \cdot a^m = a^{n+m}$ $\displaystyle \frac{a^n}{a^m} = a^{n-m}$ $\displaystyle \left (a\cdot b\right )^n = a^n \cdot b^n $ $\displaystyle \left(\frac{a}{b}\right)^n = \frac{a^n}{b^n}$ $\displaystyle \left(a^n\right )^m = a^{n\cdot m}$ I sometimes try to explain to my highschool students that those rules are not always true. For example, $0^{-2} \cdot 0^{2} = 0^0$ or I give other 
 interesting false deductions such as: $$\left(-1\right)^3=(-1)^{6\cdot \frac{1}{2}}=\left((-1)^{6}\right)^{\frac{1}{2}}=\sqrt{1}=1 $$ However I could not find an exact reference to where those rules are true. Steward's Review of Algebra states that those rules are true if $a$ and $b$ are positive (real) numbers, and $n$ and $m$ are rational numbers. This is of course very conservative. Those rules are also true if $a\ne$, $b\ne 0$ and $n,m$ integers. Besides that I think many of those rules are also true if $n,m$ are real numbers. So my question is, when are the above rules correct?",['algebra-precalculus']
2693544,Expected number of times an object is picked from a randomly ordered list of distinct objects,"There are $x$ subscribers to a weekly reading list which contains $y$ distinct articles. The subscribers are sent the exact same list of articles but each subscriber receives the weekly list in random order. Each article $y_i$ in the list has an estimated reading time $r_i$ associated with it. It is estimated that, on average, a subscriber reads the articles in the order listed on the her/his list and spends $z$ minutes per week reading the articles on the list, where $z < r_1 + r_2 + \dots + r_y$. Let $y_e$ be an article in the weekly list. What's the shortest way to compute the expected value of the number of subscribers who get to read article $y_e$?","['combinatorics', 'probability']"
2693655,Fermat–Torricelli point for polygons,The Fermat–Torricelli point of a triangle is a point which minimizes the total distance from the point to the vertices. The geometric method of finding the Fermat–Torricelli point for triangles is well known. We may apply Lagrange Multipliers to find such a point for polygons. Is there a geometric construction of Fermat–Torricelli point for polygons ??,['geometry']
2693687,Mistake in this calculation of limits,"I want to calculate $\lim_{n\to\infty}\frac{\log n!}{n\log n}$. I know this is a duplicate and I read its equal to $1$, however I can't seem to find the problem in the below calculation: $$\lim_{n\to\infty}\frac{\log n!}{n\log n} = \lim_{n\to\infty} \frac{\log1 +\log2+\dots+\log n}{n\log n}$$ Now  if we split the limits, we get: $$\lim_{n\to\infty} \frac{\log1}{n\log n}+\dots+\lim_{n\to\infty} \frac{\log n}{n\log n}$$ Then each term will give $0$, and thus answer should be $0$.","['logarithms', 'discrete-mathematics', 'limits-without-lhopital', 'limits']"
2693706,Why is gradient in the direction of ascent but not descent?,"I understand that differentiation of a function ($\mathbb{R} \rightarrow \mathbb{R} $) at a point is the rate of change in the output for a slight nudge in the input. And this rate of change could be negative or positive. There is no concept of direction for the single-variable function as obvious. Now, my doubt is in the case of the multivariate function ($\mathbb{R}^n \rightarrow \mathbb{R}$) where differentiation is a gradient. And this gradient representing partial differentiation w.r.t. to each basis becomes a direction. This direction is a direction of ascent but not descent, why?. Why it is a direction is of ascent. My question is not at all related to steepest ascent , about which one can find many answers on this forum and read elaborately at this link . An intuitive explanation would be preferable than mathematical at this link .","['multivariable-calculus', 'intuition', 'vector-analysis']"
2693731,Induced Borel $\sigma$-algebra.,"Suppose that $X$ is a topological space equipped with the Borel $\sigma$-algebra $\mathcal{B}_X$. Let $Y$ be a Borel subset of $X$, $Y\in \mathcal{B}_X$. In particular, $Y$ is a topological space with respect to the induced topology and therefore it has it's own Borel $\sigma$-algebra $\mathcal{B}_Y$. My question: Let $A\in\mathcal{B}_X$, is it necessarily true that $A\cap Y\in \mathcal{B}_Y$? Some observations: Clearly, $A\cap Y\in \mathcal{B}_X$. Also if $A$ is closed/ open, then $A\cap Y$ is closed/open and the claim is trivial.","['borel-sets', 'general-topology', 'measure-theory']"
2693800,Probability that two consecutively generated integers with normal distribution are the same,"Given a random number generator that generates numbers $x\in\mathbb{R}$ with a normal probability distribution, with mean $\mu$ and standard deviation $\sigma$, and then rounds these numbers to the closest integer $y=\lfloor x+\frac{1}{2}\rfloor$. I'd like to know if there's a way (other than simulation) to calculate the probability that two consecutive values generated by the generator are the same? For example, if $\mu = 100.0$, $\sigma = 50.0$ and $y = 123$, what's the probability of this occurrence? That is to say, what's the combined probability of two two consecutively generated raw numbers of the generator to be in the range $[y-\frac{1}{2},y+\frac{1}{2})$? I'm guessing something like $(\Phi(y-\frac{1}{2})-\Phi(y+\frac{1}{2}))^2$ or a scaled version thereof?","['statistics', 'normal-distribution']"
