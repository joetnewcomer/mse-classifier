question_id,title,body,tags
2440541,Calculate eigenvalues and eigenvectors,"I have this matrix below, and I need to find the eigenvalues.\begin{bmatrix}
        2 & -1 & 0 \\
        5 & 2 & 4 \\
        0 & 1 & 2 \\
        \end{bmatrix}
This is what I have done so far:
I used $\det(A-λI)=0$ and reached this form \begin{bmatrix}
        2-λ & -1 & 0 \\
        5 & 2-λ & 4 \\
        0 & 1 & 2-λ \\
       \end{bmatrix}
I have done some simplifications: $(2-λ)[(2-λ)(2-λ)-4]-5(-(2-λ))=0$ $(2-λ)[(2-λ)(2-λ)-4]-5(-1)=0$ $(2-λ)[4-4λ+λ^2-4+5]=0$ $(2-λ)[λ^2-4λ+5]=0$ $λ^2(2-λ)-4λ(2-λ)+5(2-λ)=0$ $2λ^2-λ^3-8λ+4λ^2+10-5λ=0$ $-λ^3+6λ^2-13λ+10=0$ or $-λ(λ^2-6λ+13)+10=0$ $-λ (λ-(3+{\sqrt 22})) (λ+(3-{\sqrt 22}))+10=0$ Am I doing it right and if so: I checked the answer on Symbolab and it was $2,2-i,2+i$, How so? and what 
is $i$? And is the matrix will be like this when I want to calculate the eigenvector for $2-i$ ??\begin{matrix}
        i & -1 & 0 \\
        5 & i & 4 \\
        0 & 1 & i \\
       \end{matrix}","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2440542,"A Local Connectedness Condition for Compact, Connected Metric Spaces","I am having trouble proving a result from a paper, which of course includes no proof.  I wonder if the author had a simple - but flawed - argument in mind, or if I'm just being a dunce.  It is Theorem 3 here: https://www.jstor.org/stable/2372339 It involves the following property: If $X$ is a metric space and $x, y \in X$, then we say that $X$ is aposyndetic at $x$ with respect to $y$ if there is a compact, connected neighborhood of $x$ not containing $y$.  Let $A(x)$ be the set of points $y$ such that $X$ is not aposyndetic at $y$ with respect to $x$ - that is to say, the points $y$ all of whose closed, connected neighborhoods also contain $x$. The following is what I'm trying to prove:
If $X$ is a compact, connected metric space and $x \in X$ is a point, then $A(x)$ is connected. In fact it's also closed, which I can show.  Maybe it is something very simple, but I'm just not seeing it.  It may be a useful fact that the nested intersection of compact, connected subsets of $X$ is also connected.  Does anyone see the proof?","['connectedness', 'continuum-theory', 'compactness', 'general-topology', 'metric-spaces']"
2440632,When does $2^{2m}+2^m+1$ divide $10^{2m}+10^m+1$?,"For what values of $m\in \Bbb N$ is it true that $2^{2m}+2^m+1$ divides $10^{2m}+10^m+1$? I have it false for $m=1,3 $ and true for $m=2,4$ This arises from my thoughts on the question How to find all binary numbers in base $10$ s.t. that its divisible by its own numerical value in base $2$?","['number-theory', 'elementary-number-theory']"
2440634,Calculate a double integral,"Why does the following identity hold?
$$\int_0^{2\pi}\int_0^{2\pi}\arcsin(k\cdot \cos(\theta-\phi))e^{i(\theta-\phi)} \, d\theta \, d\phi=2\pi\int_0^{2\pi}\arcsin(k\cdot \cos x)e^{ix} \, dx$$
where $k\in[-1,1]$ is a constant. I'm trying to use substitution $x=\theta-\phi$ but it still needs some tricks. Thanks!","['complex-analysis', 'calculus', 'analysis']"
2440655,Diophantine equation and regular polygons,"Consider Diophantine equation: $$(m-4)n=2m.$$ It can be rewritten as: $$\frac{1}{n}+\frac{2}{m}=\frac{1}{2}.$$ If we search for positive solutions only, we have at least $4$ pairs: $$(m,n)\in\{(5,10);(6,6);(8,4);(12;3)\}$$ They can be illustrated in the following way using regular polygons: How are the equation and the polygon combinations related? Do we have any other positive solutions?","['diophantine-equations', 'polygons', 'elementary-number-theory', 'geometry', 'discrete-mathematics']"
2440663,How can we find functions that satisfy $f(x\cdot y)=f(x)f(y)$? [duplicate],"This question already has answers here : If $f(xy)=f(x)f(y)$ then show that $f(x) = x^t$ for some t (3 answers) Closed 6 years ago . Today I've encountered a question like The following; If function $f$ satisfies $f(xy)=f(x)f(y)$ and $f(81)=3$ then find The value of $f(2)$? 
What baffles me about this question is that I have to find The equation of the function in order to find $f(2)$ because $2$ is not a divisor of $81$ , using The property I found out that $f(3)=\sqrt[4]{3}$ and wondered if the function could be $f(x)=\sqrt[4]{x}$ (it satisfies the equation up there) but I do not know whether f gives $2$ a value like this or not. And there are many other functions that can be found. So The question is how can İ get myself out of this ugly situation, and how can I find other $f$ functions that satisfy the constraints? What I am asking is not to prove that these functions are in type of $x^n$ I am trying to get what $f(2)$ is and see also whether this question is deficient ör cannot ve solved with The given details. Thank you:)","['algebra-precalculus', 'radicals', 'functions']"
2440688,"Can we find $c_n$ to make $X_nc_n \rightarrow 0$ almost surely, even if $EX_n > \infty$?","Let $X_n$ be a sequence of random variables. Can we find $c_n$ (positive constants) so that $X_nc_n \rightarrow 0$? It is easy with Markov's equality + Borel Cantelli, with assumptions on expectations, but what if we don't know anything about expectations?","['probability-theory', 'convergence-divergence']"
2440691,Counterexample for $(a*b)^2=a^2*b^2$,"I'm stuck on finding a counterexample for the following problem, If $G$ is a group with operation * and $a$ and $b$ belong in $G$, then $(a*b)^2=a^2*b^2$. I think it's false because the law of exponents only works if the group is Abelian and they never stated whether this group was Abelian. My line of thought is that I shouldn't use multiplication or addition as my operation since they are commutative but I don't know where to go from there.","['abstract-algebra', 'examples-counterexamples', 'group-theory']"
2440715,Problem with the definition of a discrete topology,"In wikipedia I've read that the discrete topology on X is defined by letting every subset of X be open (and hence also closed), and X is a discrete topological space if it is equipped with its discrete topology ""hence also closed""? I couldn't get that part. If you let every subset of $X$ to be open, how come that makes them closed? I know that $\emptyset$ and $X$ are open (hence closed), called ""clopen"". But for a point $x \in X$ if I let it to be open in the topological space (I also didn't understand what ""letting"" procedure is, $x \in X$ is clearly closed, since it is a point), how come it becomes closed?",['general-topology']
2440750,Symmetry Of Fractal Objects,"I'm interested in knowing whether there has been any study of the symmetries of fractal objects. The symmetries acting upon an object usually, if not always, form a group to my knowledge, but I was wondering whether the same could be said in the case of fractal objects, which often have non-integer dimensions. I'll try and describe a couple of possible fractal objects that might have some interesting properties. For example, let me make a construction using the sierpinski gasket . Label the corners $0$ (at the origin), $A$ (the point with the highest $y$ value), and $B$ (the point with the highest $x$ value). Say that $A$ has co-ordinates $(\frac{X}{2},Y)$, and hence $B$ has co-ordinates $(X,0)$. Then make a copy of the gasket and translate it by $(X,0)$, and then make another copy of the original gasket and translate it $(\frac{X}{2},Y)$. Then you have made a dilated copy of the gasket. Iterate this process ad infinitum. Then you have the first object I would like to look at. Now, the contraction mappings used to create the Sierpinski Gasket all fix this new object, as do their inverses. Furthermore, the reflection which maps $0$ to $0$ and $A$ to $B$ is fixes this new object too. Unlike the original gasket, however, as well as any triangle, the other elements of $Dih(3)$ don't fix this new object, because the two other reflections and the non-trivial rotations can't be defined. So for an initial problem, could anyone tell me what the symmetry group of this object is isomorphic to, and does anyone else have any experience with this area? EDIT: I realised that only one of the three contractions on the Sierpinski Gasket is well-defined on this new object so the group of symmetries on it is just $\mathbb{Z}_2\times\mathbb{Z}$. Are there more interesting examples maybe?","['symmetry', 'group-theory', 'fractals']"
2440768,Tangent space to a product manifold using curves,"This is an exercise from An introduction to Manifolds by Loring Tu. If $M,N$ are manifolds, let $\pi_1:M\times N\rightarrow M$ and $\pi_2:M\times N\rightarrow N$ be two projections. Prove that for $(p,q)\in M\times N$, $$(\pi_{1*},\pi_{2*}):T_{(p,q)}(M\times N)\rightarrow T_pM\times T_qN$$
  is an isomorphism. Let $X_{(p,q)}\in T_{(p,q)}M\times N$ i.e., there exists $c:(-\epsilon, \epsilon)\rightarrow M\times N$ such that $c(0)=(p,q)$ and $c'(0)=X_{(p,q)}$. We have composition maps $c_1=\pi_1\circ c:(-\epsilon,\epsilon)\rightarrow M$
and $c_2=\pi_2\circ c:(-\epsilon,\epsilon)\rightarrow N$ such that $c_1(0)=p$ and $c_2(0)=q$. So, we have $c_1'(0)\in T_pM$ and $c_2'(0)\in T_qN$. So, we define the map $T_{(p,q)}(M\times N)\rightarrow T_pM\times T_qN$
as $X_{p,q}=c'(0)\mapsto (c_1'(0),c_2'(0))=(X_p,X_q)$. It remains to prove that this map is an isomorphism. Let $(X_p.Y_q)\in T_pM\times T_qN$ i.e., there exists $\tau_1:(-\epsilon,\epsilon)\rightarrow M$ such that 
$\tau_1(0)=p,\tau_1'(0)=X_p$ and $\tau_2:(-\epsilon,\epsilon)\rightarrow N$ such that 
$\tau_2(0)=p,\tau_2'(0)=Y_q$. This $\tau_1,\tau_2$ gives $c:(-\epsilon,\epsilon)\rightarrow M\times N$ defined as 
$t\mapsto(\tau_1(t),\tau_2(t))$ and $c(0)=(\tau_1(0),\tau_2(0))=(p,q)$ and 
$$((\pi_1\circ c)'(0),(\pi_2\circ c)'(0))=(\tau_1'(0),\tau_2'(0))=(X_p,Y_q).$$
So, the above map is surjective. Let $c:(-\epsilon,\epsilon)\rightarrow M\times N$ with
$c'(0)\in T_{(p,q)}(M\times N)$ be such that 
$$((\pi_1\circ c)'(0),(\pi_2\circ c)'(0))=(0,0).$$
We need to prove that $c'(0)=\in T_{(p,q)}(M\times N)$  i.e., to prove 
$c'(0)(f)=0$ i.e., $$\frac{d}{dt}\bigg|_0 (f\circ c)=0$$
for all $f\in C_{(p,q)}^{\infty}(M\times N)$. Given $f\in C_{(p,q)}^{\infty}(M\times N)$ we have $f_1:M\rightarrow \mathbb{R}$ defined as $m\mapsto f(m,q)$ and 
$f_2:N\rightarrow \mathbb{R}$ defined as $n\mapsto f(p,n)$. Then, $f_1\in C_p^\infty M$ and $f_2\in C_q^\infty N$.
As $(\pi_1\circ \eta_1)'(0)=0$, we have $(\pi_1\circ c)'(0)(f_1)=0$
i.e., $$\frac{d}{dt}\bigg|_{t=0}(f_1\circ \pi_1\circ c)=0.$$
Similarly, we have $$\frac{d}{dt}\bigg|_{t=0}(f_2\circ \pi_2\circ c)=0.$$ I am stuck here. Any suggestion for this approach is welcome.","['manifolds', 'differential-geometry']"
2440770,"Are the digits of a real number i.i.d. $Unif(\{0,\ldots,9\})$?","Suppose $X$ is has a uniform distribution on $[0,1]$. Let $X_i$ be the random variable that denotes the $i$th digit in the decimal expansion of $X$, i.e. if $x$ is a realization of $X$ with decimal expansion $0.x_1x_2x_3\ldots$, then $X_i=x_i$. Intuitively, it should hold that the $X_i $ are i.i.d. $Unif(\{0,\ldots,9\})$. Is this true? If yes, how would one show this rigorously?","['probability-theory', 'real-numbers', 'probability']"
2440778,In what kind of space does this object live?,"Let me quickly build up some background. One way to build a hypercube is to take cubes, and start gluing them together, face to face, such that each edge is shared by $3$ cubes. You complete the hypercube with $8$ cubes. This involves rotating cubes in $4$ dimensions, but if you forget about the geometry, you can still do this abstractly. Separately, lets take a torus that is made from 5 squares, like this: where you identify opposite sides in the usual way to make a torus. Now, lets combine these concepts. Let's take these tori and (abstractly?) glue them together, square face to square face, such that each edge is shared by 3 tori. It turns out this only takes $6$ of these tori. My question is this: where the hypercube lives nicely in $4$-space, is there a nice, familiar, space where this clump of tori lives? Is there a nice way to think about this kind of object? EDIT:
As requested in the comments, here is a gluing diagram for what I am proposing: The numbers and colors mean the same thing, they identify square faces to be glued together. The letters correspond to the vertices, so one knows the orientation of the squares to be glued.","['manifolds', 'low-dimensional-topology', 'polytopes', 'geometry']"
2440795,"Let $p(n)$ is the biggest prime divisor of $n$. Prove that, exist infinite $n \in N$ satify : $p(n) <p(n+1)<p(n+2)$","Let $p(n)$ denote the biggest prime factor of $n$. Prove that, there are infinite $n \in N$ satisfy : $p(n) <p(n+1)<p(n+2)$ My idea is finding some special consequences like $a_n=2^{2^m+1}$ and $n=a_n$ $p(n+1) \geq 3>2=p(n)$ and $p(n+2)=2(2^{2^m}+1)$ where $2^{2^m}+1$ is Fermat number If there are infinite Fermat number the problem is solved. (but this statement is more difficult than the problem), Thank you for helping, Finally I solved it With same previous idea . Let p are odd prime Exist $k_0 = \inf \{k \in N| P(p^{2^k}+1) > p\} ; k_0 < \infty .$ ($P(n)$ same meaning with $p(n)$) By using Lemme : $P(p^{2^{k_0}}+1) \equiv 1 (\mod 2^{k_0+1})$ And then , we prove : $P(p^{2^{k_0}}-1)<P(p^{2^{k_0}})< P(p^{2^{k_0}}+1).$","['number-theory', 'prime-numbers']"
2440799,The difference between standard topology and discrete topology (both on $R$),"Is discrete topology finer than the standard topology on $R$? What I understood is the following In discrete topology, we are making every element $x \in R$ an open set. Whereas in the standard topology we are sticking with the previous openness definition defined on $R$",['general-topology']
2440814,prove $x^2 = 4 c(y+c)$ is self orthogonal trajectory,Can someone come up with a proof with this $$x^2 = 4 c(y+c)$$ to be self orthogonal? I know in have to put $-dx/dy$ instead of $dy/dx$ but I cant solve it,"['orthogonality', 'ordinary-differential-equations', 'geometry']"
2440821,How is the set $\emptyset^\emptyset$ defined? [duplicate],This question already has answers here : It is posible to have a function $f$ with the following property? (4 answers) Closed 6 years ago . By $\emptyset^{\large\emptyset}$ i mean the set of functions from $\emptyset$ to $\emptyset$. Is it the empty set or the set containing the empty set? I just dont know how to prove it.,"['elementary-set-theory', 'functions']"
2440844,Does the relation algebra have a sole sufficient operator?,"In brief, does the relation algebra (defined here axiomatically) have a sole sufficient operator? Given a set $D$, define operators $^{-}$, $\wedge$,  $^{c}$, $\bullet $ on the set $\mathcal{P}(D^{2})$ as follows: $$
\begin{align}
R^{-} &= \{ (x,y) \in D^{2} : (x,y) \notin R \}  \\
R \wedge S &= \{ (x,y) \in D^{2} : (x,y) \in R \wedge (x,y) \in S \} \\
R^{c} &= \{ (x,y) \in D^{2} : (y,x) \in R \} \\
R \bullet S &= \{ (x,y) \in D^{2} : \exists z \in D ( (x,z) \in S \wedge (z,y) \in R ) \} 
\end{align}
$$ Also define $$I = \{ (x,y) \in D^{2} : x = y \} $$ Is there a binary operator which (for any set $D$) can be combined with itself to produce $^{-}$, $\wedge$,  $^{c}$, $\bullet $ and $I$, analogous to how the Sheffer stroke can produce any Boolean operator? Alternatively, is there a proof that no such operator exists? If none exists, what is the smallest functionally complete set of operators? Thoughts so far I'm aware that the modal logics S4 and S5 have sole sufficient operators (I was a little surprised at this), but I'm not so familiar with the intuition behind their construction. Potentially a better understanding of them might help with constructing an SSO for the relation algebra. I don't know whether the modal logic K has a sole sufficient operator, but I suspect it doesn't. If there's a proof out there that K doesn't have a sole sufficient operator, it could be applied to the relation algebra. The relation algebra seems on a crude intuitive level to be a lot more complicated than K. When Post looked at the Boolean operators and how they relate to each other, he looked at properties of the operators preserved under composition (e.g. monotonic operators composed with themselves result in monotonic operators). A strategy for showing no sole sufficient operator exists for the relation algebra would be to find two mutually exclusive properties which are preserved under composition and possessed by at least one of $^{-}$, $\wedge$, $^{c}$, $\bullet$ and $I$.","['abstract-algebra', 'logic', 'relations', 'algebraic-logic']"
2440865,Evaluate $\lim_{x\to 0}\frac{(\tan x)^{2008}-(\arctan x)^{2008}}{x^{2009}}$ without using Taylor series.,"Evaluate $$\lim_{x\to 0}\frac{(\tan x)^{2008}-(\arctan x)^{2008}}{x^{2009}}$$ without using Taylor series. I have a solution using  $\lim_{x\to 0}\frac{\tan x-\arctan x}{x^2}=0$, but I would really like to see a different idea.","['calculus', 'limits']"
2440866,GCD of sums of n consecutive n-th powers,"It is an easy exercise to show that all sums of 3 consecutive 3rd powers are divisible by 9. (e.g. by induction or modular arithmetic) Experimentation in Mathematica suggests that more generally, for all odd $n\in\mathbb{N}$ the numbers $
a^n+(a+1)^n+\dots+(a+n-1)^n,\qquad a\in\mathbb{N}
$ are divisible by $n^2$. Actually, the stronger statement that $n^2$ is the GCD seems to be true. Any ideas on how to approach this?",['number-theory']
2440883,Pascal's Identities for $q$-binomials,"The recursive identity for building Pascal's triangle is $$ \binom{n}{k}=\binom{n-1}{k}+\binom{n-1}{k-1}. \tag{$\circ$}$$ This has a simple combinatorial interpretation: every $k$-subset of $\{1,\cdots,n\}$ is either a $k$-subset of $\{1,\cdots,n-1\}$ or it's a $(k-1)$-subset of $\{1,\cdots,n-1\}$ with $\{n\}$ adjoined. From Wikipedia there are two analogous identities for $q$-binomials: $$ \left[\begin{array}{c} n \\ k \end{array}\right]_q = q^k\left[\begin{array}{c} n-1 \\ k \end{array}\right]_q + \left[\begin{array}{c} n-1 \\ k-1 \end{array}\right]_q, \tag{I}$$ $$ \left[\begin{array}{c} n \\ k \end{array}\right]_q=\left[\begin{array}{c} n-1 \\ k \end{array}\right]_q + q^{n-k} \left[\begin{array}{l} n-1 \\ k-1 \end{array}\right]_q. \tag{II}$$ (We interpret the $q$-binomial as the number of $k$-dimensional subspaces of $\mathbb{F}_q^n$.) The first identity $(\mathrm{I})$ has a $\mathbb{F}_q$-interpretation as follows: we have two cases, The subspace $V$'s projection into $\mathbb{F}_q^{n-1}$ is still $k$-dimensional, in which case it is determined by its image $W$ under the projection and the corresponding section $W\to V$, and that section is the sum of the identity map on $W$ and an arbitrary linear map $W\to\mathbb{F}_qe_n$. The subspace $V$ is a direct sum of a $(k-1)$-dim subspace of $\mathbb{F}_q^{n-1}$ and $\mathbb{F}_qe_n$. However I can't figure out a $\mathbb{F}_q$-interpretation of the second identity $(\mathrm{II})$. What is it? Surely I'm missing something obvious. Presumably it involves taking a complementary subspace to a $k$-dim subspace and then using another linear map from/to it.","['finite-fields', 'combinatorics', 'q-analogs', 'binomial-coefficients']"
2440894,Transformation of a differential equation,"Say I have a differential equation, $$
\dddot x = 4 \omega^2 (1 + \epsilon \cos (\Omega t)) \dot x-2 \epsilon \Omega \omega^2 \sin (\Omega t) x
$$ Here $\epsilon \ll 1$ and $\Omega \gg \omega$. I want to tranform the above to this form, $$
\dddot x = -\Omega_{eff}^2 \dot x
$$ Is there a way to transform such an equation. If yes can someone cite me some reference?",['ordinary-differential-equations']
2440926,measurable functions and existence decreasing function,"Let $f(t)$ be a measurable and almost everywhere finite function, defined on the closed interval 
$E = [a, b]$. Prove the existence of a decreasing function $g (t)$, defined on [a, b], which satisfies the relation $m(E \cap \left \{ x: {g > x} \right \}) = m(E \cap \left \{ x: {f > x} \right \}) $ for all real x. I'm not sure I can use the theorem: Let $f(x)$ be defined on the entire real line $\mathbb{R}$ and be measurable and finite 
almost everywhere. Then, for every $\varepsilon > 0$ and $\alpha> 0$, there exists a continuous function 
$g (x)$ defined on the entire line such that $m(\mathbb{R}\cap x:|f-g| \geq \alpha)<   \varepsilon$. Thanks.","['real-analysis', 'lebesgue-measure', 'measure-theory', 'analysis']"
2440932,Prove the unit circle is uncountable,"This is a homework problem, so avoid giving the answer. I think a discussion of my attempt at a proof would be more appropriate. The problem goes as follows: Let $S$ be the circle of unit radius in the Euclidean plane:
$$S = \{ (x,y) \in \mathbb{R}^2:   x^{2} + y^{2}=1 \}$$
Prove that $S$ is uncountable. This is my attempt at a proof. I don't know if it is valid, or if my logic, and for that matter my approach to the proof, is correct. Feedback/comments/thoughts of any kind are welcome. Let $G^{+} = \{(x,y)\in G: y \geq0\}$ and $G^{-} = \{(x,y)\in G: y \leq 0 \}.$These are the upper and lower segments of the unit circle. Notice that $G^{+}\subset S$ and $ \hspace{1mm}G^{-}\subset S$, so $S=G^{+} \cup G^{-}.$ Let $f: G^{+} \rightarrow [-1,1],$ where $f(x,y)=x$. This can be thought of as a projection of the semi-circle onto the $x$-axis. Since the image of $G^{+}$ under $f$ is equal to the codomain; i.e., $f(G^{+})= [-1,1]$, then $f$ is surjective. Now since for every $(x,y) \in G^{+}$ we have the cardinality $|f(x,y)|=1$, there exists an inverse function $f^{-1}:[-1,1] \rightarrow G^{+}$ defined by $f^{-1}(x) = (x,\sqrt{1-x^{2})}$. Thus, there exists a bijection between $G^{+}$ and $[-1,1].$ Similarly we have the same argument for $G^{-}.$ Let $g:G^{-} \rightarrow [-1,1]$ then $ g(G^{-})=[-1,1]$ (surjective) $|g(x,y)|=1 \hspace{4mm}  \forall (x,y)\in G^{-}$ (one-to-one) $g^{-1}: [-1,1] \rightarrow G^{-}, \hspace{4mm} g^{-1}(x)= (x,-\sqrt{1-x^{2}})$ (inverse) which shows the bijection. Since the set of real numbers $[-1,1]$ is uncountable as can be shown by Cantor diagonalization, and we have $G^{+} {\raise.17ex\hbox{$\scriptstyle\sim$}} [-1,1]$ and  $G^{-} {\raise.17ex\hbox{$\scriptstyle\sim$}} [-1,1]$, then that implies that $G^{+}$ and $G^{-}$ are uncountable. Therefore $S= G^{+} \cup G^{-}$ must also be uncountable. q.e.d. One other approach I thought about was to think of the semicircles as intervals in their own right, where the length of the upper semicircle would be $[0,\pi]$ and the interval of the lower semicircle would be $[\pi,2\pi],$ and I suppose the metric would be the arc length. So essentially you take the arc length and straighten it out, but I didn't know how to approach it or even formalize it. However, I think it is essentially the same thing as what I did in my proof.",['real-analysis']
2440985,Function that visually looks smooth but is not,"I am wondering how closely our intuition for ""smooth"" aligns with the mathematical definition of smooth. To that end I was wondering if there is any function that looks ""smooth"" (i.e. could reasonably be called ""smooth"" by even a non-mathematical person at any scale) but is not infinitely differentiable (smooth).","['real-analysis', 'calculus', 'functions']"
2441043,What is the difference between linear approximation and a differential?,"From my understanding, linear approximations and differentials both use the tangent line to a function to estimate the value of the function at a point. I understand that their respective equations are different - but conceptually how are they different?","['multivariable-calculus', 'linear-approximation']"
2441058,Can I compute $\frac{dy}{dx}$ of $y=x\sqrt{3x+1}\sqrt{x+1}$ by taking $ln$ on both sides,"My teacher has suggested that to compute $\frac{dy}{dx}$ of $y=x\sqrt{3x+1}\sqrt{x+1}$, it's better to take $ln$ on both sides of the equation $y=x\sqrt{3x+1}\sqrt{x+1}$, and try taking derivative of logarithms on both sides, and then solve for $\frac{dy}{dx}$. But I am confused because when you consider the function $y=x\sqrt{3x+1}\sqrt{x+1}$,  $y \lt 0$ for $-1/3 \lt x \lt 0$, so $ln(y)$ is not defined for $-1/3 \lt x \lt 0$, i.e. we cannot take logarithm for entire domain in which $y=x\sqrt{3x+1}\sqrt{x+1}$ is defined for. In this case, can we still compute $\frac{dy}{dx}$ by taking $ln$ on both sides, like my teacher is suggesting? Thank you,","['derivatives', 'calculus']"
2441060,Intersection between two conjugates of a maximal subgroup.,"Let $G$ be a non-abelian finite group such that every proper subgroup of $G$ is abelian. Suppose $M$ is a maximal subgroup of $G$ which is not normal in $G$. I was asked to show that $\bigcup_\limits{g \in G} gMg^{-1}$ has at least $ 1 + |G|/2 $ many elements. We can show that $N_G(M) = M$ and $|M| \geq 2$. I was considering the intersection between $M$ and $gMg^{-1}$, where $g \notin M$. If the intersection is trivial we are done. However, I could not prove whether it is true. Let's say if $g$ is a nontrivial element in the intersection, then we can find $m$ and $m'$ in $M$ such that $m = g m' g^{-1}$. What can we say about it? Is it the right way to tackle this question? Thank you very much.","['finite-groups', 'maximal-subgroup', 'group-theory']"
2441101,Weighted polynomial approximation on the half-line,"Let's $w : \mathbb R_+ \to \mathbb R_+^*$ a continuous function (I will only be interested in the case $w : t \mapsto e^{-t}$). We use $w$ to define the Banach space $C^0_w(\mathbb R_+)$ of continuous functions $f : \mathbb R_+ \to \mathbb R$ such that $fw \xrightarrow[+\infty]{}0$, endowed with the norm $\| f \| = \|fw\|_\infty = \sup_{\mathbb R_+} |fw|$. I want to prove that, when $w: t \mapsto e^{-t}$, the space of polynomials is dense in this Banach space. I think this is a special case of Bernstein's approximation problem, but I haven't found an explicit elementary proof with these keywords. Because of Weierstraß's approximation theorem and a small change of variables, it is enough to show that the functions $e_d : t \mapsto e^{-dt}$ ($d \in \mathbb N$) are in the closure of the space of polynomials. It is relatively easy to show this for $e_1$, because you can show that
$$ \|e_1 - P_n \| = \|e_1(e_1 - P_n)\|_\infty = O\left(\frac 1{\sqrt n}\right),\tag{$*$}$$
where $P_n$ is the degree-$n$ Taylor polynomial of $e_1$ at $0$. If we denote by $\mathscr F$ the closure of the space of polynomials in our Banach space, we have proved $e_1 \in \mathscr F$. It seems that not much is needed to prove an equivalent result for the approximation of $e_d$. For instance, it would be enough to prove that all the $f_k : x \mapsto x^k e^{-x}$ are in $\mathscr F$ to kickstart a proof by induction: suppose all the $(f_k)$ are in $\mathscr F$ (so all the $\text{polynomial} \times e_1$ functions are, by linearity) and that $e_p$ is in $\mathscr F$ (so that we have a sequence of polynomials $(Q_n)_n$ converging to it w.r.t. the $\|\cdot\|$ norm). We then have
$$\|e_1 Q_n - e_{p+1}\| = \|e_1(e_1 Q_n - e_{p+1})\|_\infty \leq \|e_1 Q_n - e_{p+1}\|_\infty = \|Q_n - e_p\| \xrightarrow[n\to\infty]{} 0.$$ However, I'm unable to prove that the $f_k$'s belong to $\mathscr F$, or more generally to make any significant progress on $e_1 \in \mathscr F$. Basically, $(*)$ doesn't give much maneuvering space... I'm under the impression that there are much more sophisticated approaches to this problem, but I would really appreciate any help towards an elementary proof of the result.","['functional-analysis', 'approximation-theory']"
2441114,mgf of an infinite sum of independent random variables,"It is known that if $S_n = \sum_{i=1}^{n} X_i$, where the $X_i$ are independent random variables, then  the moment-generating function for $S_n$ is given by
$M_{S_n}(t)=\prod_{i=1}^{n}M_{X_i}(t)$. Now suppose that we have infinitely many random variables $X_i,i\in\mathbb{N}$, and suppose that the moment-generating function exists for each random variable $X_i,i\in\mathbb{N}$. Denote $S = \sum_{i=1}^{\infty} X_i$. Then do we have that (maybe under some additional conditions)
$
M_{S}(t)=\prod_{i=1}^{\infty}M_{X_i}(t)$? If so then how can we prove it? I really tried hard to find out such a formula for the mgf of an infinite sum of independent random variables but all the lecture notes and books that I dipped into only present the formula for finite case.","['statistics', 'probability', 'probability-distributions']"
2441248,"Bounded derivative has a fixed point at [0,1].","$f$ is differentiable at $[0,1]$, and $0 \le f'(x) \le 1$. Show that there exists $x\in[0,1]$ such that $f'(x) = x$. So far I've got that if $f'(0)=0$ || $f'(1)=1$ we are done. Otherwise, $f'(0) > 0$ and $f'(1) < 1$. The thing is that $f'$ is not necessarily continuous, therefore I cannot define a continuous $H(x) = f'(x) - x$
and use the Intermediate Value Theorem.","['derivatives', 'real-analysis', 'calculus']"
2441265,What is the locus of the points satisfying $|z-\alpha|/|z+\alpha| = c$?,"What is the locus of the points $z\in\mathbb{C}$ satisfying
  $$\left|\frac{z-\alpha}{z+\alpha}\right| = c,$$ where $\alpha\in\mathbb{C}, c\in\mathbb{R}$? Plotting some examples by assigning values to $\alpha$ and $c$, I see that it is a conic section (it was a hyperbola in my example). But just writing $z = x+iy$ and $\alpha = a+ib$ the calculations get too long to carry and to organize in such a way that I could see what kind of curve it is in general. There is a ""less painful"" way to answer the question?","['complex-analysis', 'complex-numbers']"
2441280,What matrix corresponds to differentiation?,"Today, in my linear algebra class, we discussed how differentiation of polynomials of degree at most $4$ can be defined using the following matrix $$\begin{bmatrix}
0 & 1 & 0 & 0 & 0 \\
0 & 0 & 2 & 0 & 0 \\
0 & 0 & 0 & 3 & 0 \\
0 & 0 & 0 & 0 & 4\end{bmatrix}$$ since differentiation is a linear transformation. My question is the following Is there a way to represent differentiation using a matrix when we consider the space of all differentiable functions with domain and codomain $\mathbb{R}$? Note: I've studied set theory, so if the matrix has uncountably many entries, that's fine. Axiom of choice is fine as well.","['derivatives', 'matrices', 'functional-analysis', 'linear-transformations', 'linear-algebra']"
2441282,Geometric proof of uniqueness and existence of ordinary differential equations,"In Arnold's book on ordinary differential equations, he proves the existence and uniqueness of one dimensional ordinary differential equations of the form $$ \frac{dx}{dt} = v(x) $$ by first showing that at poins with $v(x_0) \neq 0$, we have unique solutions described by the equation $$ t - t_0 = \int_{x_0}^x \frac{dy}{v(y)} $$ and for $v(x_0) = 0$, assuming $v$ is Lipschitz here, the function approaches $x_0$ too slowly, and as such integral curves approaching $x_0$ take infinite time to reach $x_0$ (the integral formula above diverges if we let $x_0$ converge to a point where the vector field vanishes). Arnold later indicates in an exercise that this is an idea behind a general method for proving the uniqueness of differential equations. However, I can't seem to prove the method in general myself, and it seems every reference I find relies on Picard's method for iteratively constructing a differential equation. Would anyone be able to tell me if I'm going in the wrong direction, or point me to a source with this result if I do?",['ordinary-differential-equations']
2441363,Covering of a set with its subsets,"Let $N$ be a finite set and $D=\{K_1,\ldots, K_m\}$ be a set containing subsets of $N$. It is given that every element of $N$ is covered by at least $\gamma$ elements of $D$. I am trying to find estimation for minimal covering of $N$ using subsets in $D$. I have seen this result: There exists a covering with no more than $\frac{(1+ln(\gamma)|N|)}{\gamma}+1$ elements but can't find the proof. I am not sure if it is correct. Can anyone help on this problem?","['combinatorics', 'extremal-combinatorics', 'optimization', 'discrete-mathematics']"
2441384,$f(n)/g(n) \rightarrow 1$ implies $h(f(n))/h(g(n)) \rightarrow 1$?,"Let $f: \mathbb{N} \rightarrow \mathbb{R}_{>0}$ and $g: \mathbb{N} \rightarrow \mathbb{R}_{>0}$ where $\lim_{n \rightarrow \infty} f(n) = \infty$ and $\lim_{n \rightarrow \infty} g(n) \rightarrow \infty$ and $$\lim_{n \rightarrow \infty} \frac{f(n)}{g(n)} = 1.$$ 
Further let $h: \mathbb{R} \rightarrow \mathbb{R}$ be an increasing function. What further conditions do we need on $h$ in order to conclude
$$
\lim_{n \rightarrow \infty}\frac{h(f(n))}{h(g(n))} = 1 \text{ ?}
$$","['real-analysis', 'limits', 'asymptotics', 'calculus', 'sequences-and-series']"
2441498,"If $f_n \to f$ uniformly and $g_n\to g$ uniformly, then $f_n\circ g_n \to f\circ g$ uniformly?","Assume that $f_n, g_n$ are continuous. If $f_n \to f$ uniformly and $g_n\to g$ uniformly. Does it imply that $f_n\circ g_n \to f\circ g$ uniformly? I think it is true but I have no idea to prove it. Can anyone help me? Thank you in advance! Edit: Is it true that $f_n\circ g_n \to f\circ g$ pointwise?","['real-analysis', 'uniform-convergence', 'limits', 'calculus', 'analysis']"
2441506,"Proving the function $f:t\mapsto (\cos t,\sin t)$ is differentiable","I want to prove that $f$ is differentiable. I use the principle of differentiability that says that $f$ is differentiable if there exists an A such that: $$\lim \cfrac{\|f(t)-f(\xi)-A(t-\xi)\|}{\|t-\xi\|}=0, t\rightarrow \xi$$ I know that $A$ is the derivative of $f$ thus $A=(-\sin t, \cos t)$. But when I substitute this in the equation I get that: $$\lim \cfrac{\|(\cos t,\sin t)-(\cos\xi,\sin\xi)-(-\sin(t-\xi),\cos(t-\xi))\|}{\|t-\xi\|} = $$ $$\lim \cfrac{\|(\cos t - \cos\xi + \sin(t-\xi), \sin t-\sin\xi-\cos(t-\xi))\|}{\|t-\xi\|} = $$ $$\lim\cfrac{\|(\cos t - \cos\xi + \sin t\cos\xi-\cos t\sin\xi, \sin t- \sin\xi - \cos t\cos\xi-\sin t\sin\xi)\|}{\|t-\xi\|}$$ I don't really know where to go from here can anyone help me with this?","['derivatives', 'limits']"
2441518,"What about $\int_0^1\int_0^1\frac{\text{gd}(\log(xy))}{1-xy}dxdy,$ where $\text{gd}(z)$ is the Gudermannian function?","This morning I was thinking in integrals of the kind $$\int_0^1\int_0^1\frac{\text{Numerator}(x,y)}{1-xy}\,dxdy,$$ where $\text{Numerator}(x,y)$ is a function of $x$ and $y$ involving special functions. Then as a particular case of these I am trying to think if Question. Is it possible to calculate an expression (a series, a closed-form involving special functions or a very good approximation) for $$\int_0^1\int_0^1\frac{\text{gd}(\log(xy))}{1-xy}\,dxdy,$$ where $\text{gd}(z)$ is the Gudermannian function? What are your calculations and approach? If you don't know this special function see this MathWorld . Thanks in advance. Notice that I've choose this example with the purpose to combine with the expression involving the Guermannian function and the inverse tangent function, $(4)$ in previous reference. Then using a Cauchy product I wrote 
$$\int_0^1\int_0^1\frac{\text{gd}(\log(xy))}{1-xy}\,dxdy=2\sum_{k=0}^\infty\sum_{l=0}^k\frac{(-1)^l}{(2l+1)(l+k+2)^2}-\frac{\pi^3}{12}.$$ On the other hand Wolfram Alpha online calculator knows how calculate indefinite integrals as int arctan(xy)/(1-xy)dx but with my standard time of computation and code I am not able to calculate a closed-form for our integral in the Question.","['multivariable-calculus', 'integration', 'definite-integrals', 'sequences-and-series']"
2441519,Unsure about the proof that a module is finitely generated if its localizations are finitely generated,"Let $A$ be a ring and $M$ be an $A$-module. Suppose that the collection $\{ g_{i} \}_{i=1}^{m}$ generate the unit ideal of $A$. I want to show that if for each $g_{i}$, the localization $M_{g_{i}}$ is finitely generated as an $A_{g_{i}}$-module, then $M$ is finitely generated as an $A$-module. I wanted to see if someone could check if what I have seems ok. The proof here is from EGA II (6.1.4.1) (which can be found here ) and I just wanted to make sure I haven't made any mistakes in translation. In fact, one part I am particularly uncomfortable with is the summation I have labeled $(*)$. Grothendieck has this sum over $i$, and I am not sure why. It seems like it should be over $j$, since we are in a particular localization and generated by the generators indexed by $j$, right? Or have I missed something? Suppose we have a system of generators for each $M_{g_{i}}$ given by a collection 
$$
\left\lbrace \frac{m_{ij}}{g_{i}^{n_{ij}}}  \right\rbrace_{i=1}^{m}
$$
But since the index sets of both $i$ and $j$ are finite, we can choose a sufficiently large integer $N$ so that we we have generating sets
$$
\left\lbrace \frac{m_{ij}}{g_{i}^{N} } \right\rbrace_{ j \in J_{i} }
$$
for each $M_{g_{i}}$. We claim that the collection of all the $\{ m_{ij} \}$, which is a finite collection, generates $M$ as an $A$-module. Let $M'$ be the $A$-submodule of $M$ generated by this collection. Now let $m \in M$ be any element. We will show that $m \in M'$. Denote the localization maps
$$
\phi_{i}: M \longrightarrow M_{g_{i}}.
$$
Then since we have generating sets for any $M_{g_{i}}$, we have that
$$
\phi_{i}(m) = \frac{m}{1} = \frac{\left( \sum_{j} a_{ij}m_{ij} \right)}{g_{i}^{p}} \qquad (*)
$$
Then for a sufficiently large power $r$, we have $g_{i}^{r}m \in M'$. But note that the collection $\{ g_{1}^{r}, g_{2}^{r}, \ldots , g_{m}^{r}  \}$ also generates $A$. This has the geometric interpretation that if the $D(g_{i})$ cover $\text{Spec }A$, then so do the $D(g_{i}^{r})$ as distinguished open affines. So then we can find elements $b_{i} \in A$ so that
$$
1 = \sum_{i=1}^{m} b_{i}g_{i}^{r}.
$$
But then we have
$$
m = 1 \cdot m= \left( \sum_{i=1}^{m} b_{i}g_{i}^{r} m \right) \in M'.
$$
So we have shown that $M \subseteq M'$ which proves the result.","['modules', 'algebraic-geometry', 'localization', 'proof-verification', 'commutative-algebra']"
2441560,Total number of injective functions,"The number of injective functions possible from A to B such that  p'th element of A cannot map with p'th element of B where |A|=3 and |B|=5 is ? My attempt:- Total number of injective functions possible from A to B = 5!/2! = 60. 1) Number of ways in which one element from set A maps to same element in set B is 
   (3C1)*(4*3) = 36. 2) Number of ways in which two elements from set A maps to same elements in set B is 
  (3C2)*(3) = 9. 3)Number of ways in which three elements from set A maps to same elements in set B is 1 So, answer should be 60-(36+9+1) = 14. But it seems that my answer is wrong. Can someone point out the mistake in my approach ?","['permutations', 'combinatorics', 'functions']"
2441573,"What is the domain of the function $f(x) = \sqrt{\frac{x+1}{x}}$ , and what are its points of discontinuity?","$f(x) = \sqrt{\frac{x+1}{x}}$ I typed this function into a graphing program and it gives me a domain of 
$\Bbb R\setminus(-1,0]$ I tried to find it myself: let the denominator = $0$ $ x= 0$ is a V.A , and thus is excluded from the domain $\frac{x+1}{x} \ge 0$ If $x \lt 0 \Rightarrow x+1 \le 0 $ $x \le -1 $ If $ x \gt 0 \Rightarrow x+1 \ge 0 $ $ x \ge -1$ I know that the last part is wrong, but I don't know how to fix it. Also, this function has an interval , rather than just a point over which it's discontinuous. Do I say that the points of discontinuity lay at $x=0$ and $x =-1$ or is that wrong? Thanks for the help.","['continuity', 'functions']"
2441628,Measure theory with algebraic point of view,"When I was reading one mathematician's blog (I forgot his name by now), I encountered with the opinion that the measure theory should be studied without any $\sigma$-algebras and so on. Instead one should use the language of commutative Von Neuman algebras. I am not suggesting to discuss this opinion I rather want to ask if there are some textbooks treating measure theory in such a way.","['reference-request', 'measure-theory', 'von-neumann-algebras']"
2441643,"Show that $f(x)=\mu((A+x) \cap B)$ is continues, where $A,B \subset \Bbb R$ are measurable sets with a positive and finite measure","Let $A,B \subset \Bbb R$ be measurable sets with a positive and finite measure, and let $\mu$ be the Lebesgue measure.
Define $f(x)=\mu((A+x) \cap B)$. Show that $f$ is continues. I'm not sure how to approach this. Any clues?","['lebesgue-measure', 'measure-theory']"
2441646,Limits and algebraic simplification,"Please let me know what is wrong in the following algebraic simplification which gives a wrong limit value. $$\lim_{x \to \infty} (\sqrt {x^2 - 4x} - x)=\lim_{x \to \infty} (\sqrt {x^2 (1 - 4/x)} - x) $$ $$= \lim_{x \to \infty} (x\sqrt {1 - 4/x} - x)= \lim_{x \to \infty} x(\sqrt {1 - 4/x} - 1) $$ When $x$ tends to infinity, $4/x$ will be negligible and hence $$= \lim_{x \to \infty} x(\sqrt {1 - 0} - 1)=\lim_{x \to \infty} x(1 - 1)=0 $$","['infinity', 'calculus', 'limits']"
2441648,Contraction Property of Conditional Expectation,"Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space with $\Omega$ finite. From Jensen's inequality
$$\big|\; \mathbb{E}[X|\mathcal{G}] \;\big|^{p} \;\leq\; \mathbb{E}\big[\, |X|^{p}\,|\,\mathcal{G}\,\big] \quad\mathbb{P}\text{-a.s.}$$
for $p\geq 1$, $\mathcal{G}\subset\mathcal{F}$ and $X:\Omega\rightarrow\mathbb{R}$. By taking expectations, this directly gives the famous contraction property
$$\big\|\; \mathbb{E}[X|\mathcal{G}] \;\big\|_{p} \;\leq\; \|\; X \;\|_{p}$$
for $p\geq 1$, $\mathcal{G}\subset\mathcal{F}$ and $X:\Omega\rightarrow\mathbb{R}$, where $\|X\|_{p}:=\mathbb{E}\big[\,|X|^{p}\,\big]$. Is it possible to generalize this result to arbitrary norms $\|\cdot\|$ on $\mathbb{R}^{d}$, where $d=|\Omega|$? Can somebody contruct a counter example? Thanks!","['conditional-expectation', 'lp-spaces', 'probability']"
2441661,Prove that $\lim\limits_{n\to\infty}\left(\sum_{k=0}^{n}\lambda_k\right)\left(\sum_{k=0}^{n}\frac{\lambda_k }{a_k}\right)^{-1}= \lim_{n\to\infty} a_n$,"Suppose that, $a_n\to \ell\neq 0$ is a converging sequence of non vanishing` complex numbers and $\{\lambda_n\}$ is a sequence of positifs real numbers such that $\sum\limits_{k=0}^{\infty}\lambda_k = \infty$ Then, show that, 
$$\lim_{n\to\infty}\left(\sum_\limits{k=0}^{n}\lambda_k\right)\left(\sum_\limits{k=0}^{n}\frac{\lambda_k }{a_k}\right)^{-1}= \ell =\lim_{n\to\infty} a_n$$ I have no clue on how to start.","['real-analysis', 'sequences-and-series', 'convergence-divergence', 'limits']"
2441672,Show that $\lim_{n\to\infty}\sqrt[\sum_\limits{k=0}^{n}\lambda_k]{\prod_\limits{k=0}^{n}a_k^{\lambda_k} }= \ell =\lim_{n\to\infty} a_n$,"Suppose that $a_n\to \ell\neq 0$ is a converging sequence of positive real numbers and $\{\lambda_n\}$ is a sequence of positive real numbers such that $\sum\limits_{k=0}^{\infty}\lambda_k = \infty$. Then show that, 
$$\lim_{n\to\infty}\sqrt[\sum_\limits{k=0}^{n}\lambda_k]{\prod_\limits{k=0}^{n}a_k^{\lambda_k} }= \ell =\lim_{n\to\infty} a_n$$ I have no clue on how to start.","['real-analysis', 'sequences-and-series', 'convergence-divergence', 'limits']"
2441678,Understanding part of a proof for Stolz-Cesaro Theorem,"I'm trying to understand a step from a proof of the Stolz-Cesaro Theorem. Let ${\left\{ {{b_n}} \right\}_{n \in {\Bbb N}}}$ is a positively strictly increasing unbounded sequence. If ${\left\{ {{a_n}} \right\}_{n \in {\Bbb N}}}$ is another sequence and $$\mathop {\lim }\limits_{n \to \infty } \frac{{{a_{n + 1}} - {a_n}}}{{{b_{n + 1}} - {b_n}}} = l $$ then $$\mathop {\lim }\limits_{n \to \infty } \frac{{{a_n}}}{{{b_n}}} = l$$ The proof I'm trying to understand is here . I can't seem to understand the last step, i.e. why: $$(l-\epsilon)(1-\frac{b_{N(\epsilon)}}{b_{k+1}})+\frac{a_{N(\epsilon)}}{b_{k+1}} < \frac{a_{k+1}}{b_{k+1}}<(l+\epsilon)(1-\frac{b_{N(\epsilon)}}{b_{k+1}})+\frac{a_{N(\epsilon)}}{b_{k+1}} \implies\\ \implies l-\epsilon<\frac{a_{k+1}}{b_{k+1}} < l + \epsilon$$ How is that true and how can one write that more formally and detailed? Thanks in advance!","['cesaro-summable', 'real-analysis', 'sequences-and-series', 'limits']"
2441686,"For $f(x)=\sin(x^2-y^2)$, sketch a picture showing regions in $\mathbb{R}^2$ where the expression is positive or negative.","For $f(x)=\sin(x^2-y^2)$, sketch a picture showing regions in $\mathbb{R}^2$ where the expression is positive or negative, zero, or not defined. $z=\sin(x^2-y^2)$ $z=0\to x^2 = y^2$, its a $\times$ at the origin, two crossed lines If $z\neq 0$, then we get the form $\sin(x^2-y^2)=c$, where $c$ is either positive or negative. Notice that $-1\leq c \leq 1$. So then we get that $x^2-y^2=\sin^{-1}(c)$ If the $\sin^{-1}(c)>0$, then we have a hyperbola facing sideways, and if $\sin^{-1}(c)<0$, we have hyperbola facing up/down. So our contour plot is something like this. $z=0$ when we are in those ""crossed lines at the origin"" What about when $z>0, z<0$, this how do I find out? How do I show the values where $\sin^{-1}c > 0$, and $\sin^{-1}c < 0$?","['trigonometry', 'calculus', 'multivariable-calculus', 'contour-integration', '3d']"
2441832,Finding $\lim_{n\to\infty}\frac{1^p+3^p+...+(2n+1)^p}{n^{p+1}}$,"I'm trying to solve the following problem: Find $$\lim_{n\to\infty}\frac{1^p+3^p+\ldots+(2n+1)^p}{n^{p+1}}$$ What I've got so far: My idea is to use Stolz-Cesaro theorem, which implies that: $$
\lim_{n\to\infty}\frac{1^p+3^p+\ldots+(2n+1)^p}{n^{p+1}}=\lim_{n\to\infty}\frac{(2n+3)^p}{(n+1)^{p+1}-n^{p+1}}
$$ From there: $$\frac{(2n+3)^p}{(n+1)^{p+1}-n^{p+1}}=\frac{(2n+3)^p}{(2n+1)^{\frac{p+1}{2}}}$$ So, if my calculations are correct I only have to find the limit of the term in the RHS on the last line, that's unless the approach is somewhere entirely different. Thanks in advance!","['cesaro-summable', 'real-analysis', 'sequences-and-series']"
2441855,Do All Subsets of $\Bbb N$ Have Predicates?,"I have a question: Is it true that for any subset $S$ of $\mathbb N$, there is a predicate $φ(x)$ in this language $S$ such that $S$ = $\{n\in \mathbb N | φ(n)\}$? Here's my thought process so far. If everything that's $\in$ $\mathbb N$ has some predicate, the number of predicates of the language (POL) must be equal to the number of sets of $\mathbb N$. So, |POL| = | $P(\mathbb N) |$. Now, POL $\subseteq$ WFF But the |WFFs| = |$\mathbb N$| And |$\mathbb N$| $\ne$ $P(\mathbb N) |$. Does it thereby follow that |POL| $\ne$ |$P (\mathbb N)|$? Any advice, tips, tricks or suggestions about how to answer this question would be greatly appreciated.",['elementary-set-theory']
2441942,Why is $\sqrt[3]{18+5\sqrt{13}} + \sqrt[3]{18-5\sqrt{13}} = 3$?,"How to show that $$\sqrt[3]{18+5\sqrt{13}} + \sqrt[3]{18-5\sqrt{13}} = 3?$$ This equality comes from solving $$t^3 - 15 t - 4 = 0$$ using Cardanos fomula and knowing the solution $t_1=4$. I have attempted multiplying the whole thing with $(\sqrt[3]{18+5\sqrt{13}})^2 - (\sqrt[3]{18-5\sqrt{13}})^2$, but no success. Then I have solved for one cubic root and put all to the third power. Also no success.","['radicals', 'substitution', 'factoring', 'algebra-precalculus', 'nested-radicals']"
2441965,How can I solve this equation for real numbers?,"How can I solve this equation for real numbers?
$$(x+2)^4+x^4=82.$$ I tried $(x+2)^4+x^4-82=
2x^4 + 8 x^3 + 24 x^2 + 32 x - 66=0$ It is very difficult to continue.","['algebra-precalculus', 'polynomials']"
2442005,Intuition on Limit Sup and Inf for sequences of sets,"So if $(x_n)_{n=1}^{\infty}$ is a sequence in $\mathbb{R}$, then we can define
$$a_n = \sup\{x_k, k \geq n\}$$
Then $\limsup_{n \to \infty}x_n = \lim_{n\to\infty}a_n$, similarly we can do the same thing for infimum. So now suppose $(X_n)_{n=1}^{\infty}$ is a sequence of sets. Since sets are partially ordered, I think a reasonable way to define a supremum is the smallest set that contains them all. So something like $A_n = \bigcup_{k \geq n}X_k$. Based on this, that I think it is reasonable to define $\limsup_{n \to\infty}X_n = \lim_{n\to\infty}A_n$. But the actually definition is this
$$\limsup_{n \to\infty}X_n = \bigcap_{n \geq 1}A_n.$$
So what's the intuition behind the actual definition? I mean I understand that both definition would lead to the same thing. But the ""official"" definition just doesn't look like the limit of anything...","['measure-theory', 'definition']"
2442016,Convergence of complex series $\sum_{n=1}^{\infty}\frac{i^n}{n}$,"Prove that the series $\displaystyle \sum_{n=1}^{\infty}\frac{i^n}{n}$ converges. Optional. find it's sum, if possible . Comments. I am aware of the general result about the convergence (not absolute)
of $\displaystyle \sum_{n=1}^{\infty}\frac{z^n}{n}$ , for $z\neq 1$ . But i feel that the answer to the above problem can be more trivial, although have not made any interesting approach so far. Thank you in advance!","['complex-analysis', 'sequences-and-series', 'complex-numbers']"
2442017,Can we always find a measure for a measurable space?,I'm new to the Measure Theory. I was wondering can we always find a measure for a measurable space? It would be better to explain in details.,['measure-theory']
2442042,What is a subsequence in calculus?,"For example, if I have the sequence $(1,2,3,4,5,6,7,8,\ldots)$ i.e $x(n) = n$ for all natural numbers, then is the subsequence $(1,1,1,1,1...)$ valid? Or can I only take one element from the sequence once? Would the subsequence $(1,2,1,2,1,2...)$ be a valid subsequence? Thanks.","['real-analysis', 'sequences-and-series', 'calculus', 'limits']"
2442078,Prove $\lim_{x\to 0}\frac{\ln(\cos x)}{\ln\left(1-\frac{x^2}{2}\right)}=1$ without L'Hopital,"Prove that: $$\lim_{x\to 0}\frac{\ln(\cos x)}{\ln\left(1-\frac{x^2}{2}\right)}=1$$ without L'Hopital's rule. I don't know if this is possible. WolframAlpha agrees with this limit . There's a similar limit without L'Hopital's rule $\lim_{x\to 0^+}\frac{\ln(\sin x)}{\ln (x)}=1$ , which is easier to prove and some proofs can be seen in this question . In $\lim_{x\to 0^+}\frac{\ln(\sin x)}{\ln (x)}=1$ you can see $x\to 0^+$ , which is important, but in this case $\frac{\ln(\cos x)}{\ln\left(1-\frac{x^2}{2}\right)}$ is an even function and we can use $x\to 0$ . I've tried some of the methods given in the linked question and none of them worked. I first saw this problem in this answer, where I also discussed the methods I've tried to solve this. We could use $\lim_{x\to 0}\frac{\cos x}{1-\frac{x^2}{2}}=1$ . Edit: I've noticed that also $$\lim_{x\to 0}\frac{\cos (\cos x)}{\cos\left(1-\frac{x^2}{2}\right)}=1$$ See WolframAlpha here. And also $$\lim_{x\to 0}\frac{\sin (\cos x)}{\sin\left(1-\frac{x^2}{2}\right)}=1$$ See WolframAlpha here. And also $$\lim_{x\to 0}\frac{\tan (\cos x)}{\tan\left(1-\frac{x^2}{2}\right)}=1$$ See WolframAlpha here. . And also $$\lim_{x\to 0}\frac{\arcsin(\cos x)}{\arcsin\left(1-\frac{x^2}{2}\right)}=1$$ See WolframAlpha here. Etc.","['limits', 'logarithms', 'trigonometry', 'calculus', 'limits-without-lhopital']"
2442091,A Ramanujan sum,"I happened to see this in one of the Ramanujan's notebooks - $$ \sum_{n=0}^\infty{\left(\sqrt{n+1} - \sqrt{n}\right)^4}$$ In general, $$ \phi(s) = \sum_{n=0}^\infty{\left(\sqrt{n+1} - \sqrt{n}\right)^s}$$ for a real $s$. There was a closed form(I don't remember)for some $s$. Can anyone give me a hint on how to approach it? Update In Ramanujan's notebook, the following two closed forms were given (I am sorry about $\phi (4)$) $\phi(3) = \frac{3}{2\pi} \zeta\left(\frac{3}{2}\right)$ $\phi(5) = \frac{15}{2\pi^2} \zeta\left(\frac{5}{2}\right)$","['convergence-divergence', 'sequences-and-series', 'calculus']"
2442137,Algebraic functions - $\sin{x}$,"I would like to know an appropriate response to this question: An algebraic function is defined as a function which solves a polynomial equation $p(x,f(x))=0$.
Show that the function $f(x) = \sin{x}$ is not algebraic. This is my response: We can observe that $p(x,0)=0$ must have finitely many solutions, unless it is identically $0$, neither of which cases includes $\sin(x)$. is it good?","['abstract-algebra', 'functions']"
2442143,Show that $\Sigma_{i=1}^{n}(x_i - \bar x_n )^2$ can be calculated with a recursion,Specifically with the recursion $$\Sigma_{i=1}^{k+1}(x_i - \bar x_{k+1} )^2 = \Sigma_{i=1}^{k}(x_i - \bar x_k )^2 + \frac{k}{k+1}(x_{k+1} -\bar x_k)^2 $$ for $k = 1...n-1$. I know that $$\bar x_{k+1} = \frac{k}{k+1}\bar x_k + \frac{k}{k+1}\bar x_{k+1}$$ but after that I'm not sure. I showed that it's true for $k = 2$ but after that I'm stuck. I tried opening up the right hand side but just ended up in a morass of equations.,"['real-analysis', 'summation', 'probability', 'statistics']"
2442152,Why must the Pythagorean Theorem contain squared values? Is there a relationship between sides prior to squaring them?,"In a way it is self-evident that the sides of a right triangle have a special relationship to one another; visual proofs illustrate this. However, I am at a loss for how to describe this relationship without squares, and cannot articulate why squares are used other than they make the math simpler. My intuition tells me that, if the relationship exists after an operation, then it must exist before the operation.  However,  $A^2 + B^2 = C^2$ , but
$A+B ≠ C $ Is my intuition wrong? I suspect there is a lesson to be learned as to the nature of exponents and their relationship to their roots. It seems as though the sides simply exist as square roots a priori.  As if the way they were generated - within the system - defines them as such. But I can’t describe this process, and I feel as though it would give me a greater intuition into the theory if I did. Please note that I only have a basic math education.  I have yet to take calculus.  It may well be that the tools needed to articulate an answer require a more advanced math education.  If so I apologize for being inarticulate.  I’m doing the best with the concepts/tools I have available.",['trigonometry']
2442171,Compact Hausdorff under both $\mathcal{T}$ and $\mathcal{T'}$,"Show that if $X$ is compact Hausdorff under both $\mathcal{T}$ and $\mathcal{T'}$, then either $\mathcal{T}$ and $\mathcal{T'}$ are equal or not comparable. My solution: So, we have to show $\mathcal{T}\subset \mathcal{T'}$ and $\mathcal{T}\supset\mathcal{T'}$. First of all, we know that every subspace of compact Hausdorff is closed. Suppose $\mathcal{T}\subset\mathcal{T'}$. Then, compactness under the topology $\mathcal{T'}$ (trivially) implies compactness under the topology $\mathcal{T}$. Again, every closed set under the topology $\mathcal{T}$ can be written as finite union of closed sets under the topology $\mathcal{T'}$. Hence $\mathcal{T}\supset\mathcal{T'}$. Is my argument ok? Thanks. Edit: Sorry for your inconvenience for the statement ""...compact Hausdorff is closed."" I meant:- ""Every compact subspace of a Hausdorff space is closed""(Munkres Topology Thrm.: 26.3) Sorry for the second part too (The statement: ""every closed set under the topology $\mathcal{T}$ can be written as finite union of closed sets under the topology $\mathcal{T'}$""). I wanted to say ""Since $\mathcal{T}\subset\mathcal{T'}$, every closed set under the topology $\mathcal{T'}$ can be written as finite union of closed sets under the topology $\mathcal{T}$"". Then let $X-A_1,X-A_2,\dots, X-A_k\in \mathcal{T}$, and $\mathcal{A}_1,\mathcal{A}_2,\dots, \mathcal{A}_k$ are the open covering of $A_1,A_2,\dots,A_k$ respectively, so that $\bigcup_{i=1}^{k}A_i=B$, where $X-B\in \mathcal{T'}$. Then the union of finite subcollections that covers $A_1,A_2,\dots, A_k$ will cover $B$. Then compactness under the topology $\mathcal{T}$ implies compactness under the topology $\mathcal{T'}$. Then $\mathcal{T}\supset\mathcal{T'}$.","['general-topology', 'compactness']"
2442234,Prove $\frac{1}{2}\sum_p \frac{1}{p^2}+\frac{1}{3}\sum_p \frac{1}{p^3}+\cdots$ converges,"Prove $$\frac{1}{2}\sum_p \frac{1}{p^2}+\frac{1}{3}\sum_p \frac{1}{p^3}+\cdots$$ converges, where the sums are for all primes $p$. I've found in this link that $$\frac{1}{2}\sum_p \frac{1}{p^2}+\frac{1}{3}\sum_p \frac{1}{p^3}+\cdots$$ converges to $K$, where $K<1$. I know that $\sum_p \frac{1}{p^2}\le \sum_{n=1}^{\infty} \frac{1}{n^2}=\frac{\pi^2}{6},$ because see Basel problem and specific values of Riemann zeta function . Therefore also $$\sum_p \frac{1}{p^k}\le \sum_p \frac{1}{p^2}\le\sum_{n=1}^{+\infty}\frac{1}{n^2}=\frac{\pi^2}{6}$$ for all $k\ge 3$, $k\in\mathbb Z.$","['convergence-divergence', 'prime-numbers', 'sequences-and-series', 'calculus']"
2442242,"What is meant by $d(x,y)$ in Fubini’s theorem?","According to Wolfram MathWorld , Fubini’s theorem takes a multiple integral over a region $R=\{(x,y):x\in[a,b]\wedge y\in[c,d]\}$ and turns it into an iterated integral by the relationship $$\iint_Rf(x,y)\,d(x,y)=\int_a^b\int_c^df(x,y)\,dy\,dx$$ I have never seen the differential $d(x,y)$ before. Normally, I see something of the nature $dA=dx\,dy$. Could someone explain what $d(x,y)$ means and whence it came?","['multivariable-calculus', 'multiple-integral', 'iterated-integrals']"
2442249,logic equivalence question?,"I am trying to prove how these 2 formulas are equivalent using logical equivalence laws. (p ↔ q) → r     =    (¬p∧q)∨(¬q∧p)∨r For  (p ↔ q) → r, What I tried to do was (p → q) ∧ (q → p) V r  (Bi conditional law) (p v ¬q) ∧ (q V ¬p) v r  (conditional law) (¬q v p) ∧ (¬p v q) v r (commutative law) From there I got stuck as I wasn't sure for the next equivalence law. What would be next? Thanks.","['boolean-algebra', 'propositional-calculus', 'logic', 'discrete-mathematics']"
2442259,A median of a triangle is the geometric mean of the adjacent sides; find the cosine of one angle in terms of the others,$AD$ is a median of $\triangle ABC$. $|AD|$ is the geometric mean of $|AB|$ and  $|AC|$. Find $1+\cos A$ in terms of $\cos B$ and $\cos C$. Edit This is the second part of the question Also prove that 1+cosA=√2|cosB-cosC|.,"['trigonometry', 'euclidean-geometry', 'triangles', 'absolute-value', 'geometry']"
2442310,Relationship between Diagonally dominant and Well Conditioned matrices,"While solving linear systems by iterative methods is common pay attention to Diagonally dominant matrices, equivalently when studying stability of interpolation methods (and other kind of approximations) we look for well conditioned matrices to avoid huge oscillations with a small  change in the system. I'm looking for any relationships between well-conditioned matrices and diagonally dominant matrices and for bounds in $\kappa$ constant. For sake of completeness I will define the subjects involved in my question Definition 1 (Well conditioned matrix) : Let $A$ be a matrix, and $\|\cdot\|$ a matrix norm. We call $A$ well conditioned if: $$
\kappa_{\| \cdot \| }(A) = \| A \| \cdot \|A^{-1} \| \approx 1
$$ When $\kappa_{\| \cdot \| } \gg 1 $ we call it ill conditioned . And $\kappa_{\| \cdot \| }(A)$ is the condition number related to the matrix $A$ and the norm. Definition 2 (Diagonally dominant matrix) : Let $A$ be a square matrix rank $n$, we  call it diagonally dominant if for each $i$ row: $$
|a_{ii}| \ge \sum_{i \ne j}^n | a_{ij} | \; \forall i
$$","['matrices', 'numerical-methods', 'numerical-linear-algebra']"
2442316,convergent subsequence in $S$ versus in $\overline{S}$,"I am reading equivalent definition of a precompact set $S\subset H$ , where $H$ is a Banach space.
We have $S\subset H$ is precompact iff every sequence in $S$ has a convergent subsequence. But shouldn't it be stated as iff every sequence in $\overline{S}$ (closure of $S$ ) has a convergent subsequence? Because precompactness requires $\overline{S}$ to be compact? My hypothesis: Does it use the fact (which I don't know how to prove, or even whether it is true or not) that every sequence in $S$ has convergent subsequence iff every sequence in $\overline{S}$ has convergent subsequence? By the way, I assume 'convergence' here means converges to some element in $H.$ Then $S\subset \overline{S}$ implies one direction of my hypothesis, but the other direction remains unclear to me yet.","['functional-analysis', 'compact-operators', 'compactness']"
2442394,A question about the Laplace transform of the probability distribution function,"I am an undergraduate, who has just begun getting into probability theory. Recently we learned of the moment generating function of a random variable can be used to find moments, and the moment generating function is defined as $$ MGFx(t) =  E[e^{tX}] =\begin{cases} \sum e^{tx}p(x), & \text{if X is discrete}\\ \int e^{tx}f(x)dx,\ & \text{if X is continuous} \end{cases}$$ 
The moment generating function can also be viewed as a Laplace transform of the probability density function of the random variable X, by replacing s with -t , $${\scr L}(pdf(X))=M_X(t)=\int_0^\infty f(x)e^{xt}\,dt$$ From here, one may take derivations with respect to t of $M_x(t)$, and then evaluate the derivative at t = 0, to find the respective moment of the probability distribution function, i.e. $$ \frac{d^{n}}{dt^{n}}\ M_x(t) = M^n_X(t) $$
$$ M^n_X(0) = E[X^n], n =1,2,3,...$$
When I have dealt with the Laplace transform of a function in the past, for differential equations, the text stated that the transform redefines a function $f(t)$ such that the function is now defined by a complex variable s, where $s = \sigma +i\omega$, and $${\scr L}(f(t))=\int_0^\infty f(t)e^{-st}\,dt =F(s)$$ For the majority of differential equations that I have dealt with, that involve a Laplace transform to solve, we are converting to from a function of time(t) to one of frequency(s), and the transformed function now has computation done on it in the complex frequency domain until the transform is reversed. My question is that for the Laplace transform of a probability distribution function, what does the complex domain that the function is transformed to represent? More specifically what is the variable ""t"" that is introduced, and what is the meaning of the derivative of the moment generating function, with respect to t? Is the variable t arbitrary or is it the representation of something? Thank you.","['statistics', 'moment-generating-functions', 'laplace-transform', 'random-variables']"
2442396,Probability of $2$ people being together out of a group of $4$.,There were $2$ people who wanted to be in a group together. Those $2$ people were in a pool of $4$ people. Someone would randomly select $2$ people in a row and those people would be in a group together. The remaining $2$ would also be in a group. What the probability of those $2$ people who wanted to be in the same group actually being in the same group? What I tried Lets assume that the $2$ who want to be together are person A and B respectively and person C and D are the other $2$. The probability of choosing person A and B is $\dfrac 14 \cdot \dfrac 13 = \dfrac 1{12}.$,"['combinations', 'probability']"
2442415,Exhibit a one-to-one correspondence between the set of positive integers and the set of integers not divisible by $3$.,"I'm working on a math problem and I'm kind of stuck. I have to show whether a set is countable or uncountable, and then as the title implies I have to exhibit a one-to-one correspondence between that set and the set of positive integers. The set I'm given is: Integers not divisible by 3. So far I've worked out that with these two cases I can map all positive integers that are divisible by 3 to the positive integers (Z+): Case n odd: 3((n-1)/2)+1

Case n even: 3(n/2)+2 However I'm missing all the negative integers that are divisible by 3, and I'm struggling to figure out how to map those to Z+.",['discrete-mathematics']
2442421,Decomposition of Algebraic Numbers into Sets of Real and Rational Numbers,"Show that a real number $\alpha$ is algebraic of degree at most $n$ if and only if there are real numbers $\{a_1, a_2, ..., a_n\}$ such that for every $k \in \mathbb{N}$ there exist rational numbers $\{b_{1,\space k}, ..., b_{n, \space k}\}$ such that $\alpha^k = a_1b_{1,\space k} + ... + a_nb_{n,\space k}$. There are two hints: For the forward assertion use the Euclidean Algorithm and for the reverse use linear algebra. I have been staring at this problem for hours and all of my attempts have led me nowhere. I would appreciate any suggestions on how to proceed or any other references. One failed attempt: I tried to argue that $\alpha^k$ = $(\alpha^{n})^{k/n}$ and from here I tried to exponentiate $p(\alpha) - \alpha^n$ and proceed inductively. I ended up with a mess and did not think it would get me anywhere","['abstract-algebra', 'real-analysis', 'linear-algebra', 'analysis']"
2442425,Non-differentiable points in a graph: Vertical Tangent vs Vertical Asymptote,"Can someone help me understand the difference between the two? Vertical tangent at $x = a$: $f$ is continuous at a but $f'(a)$ blows up.
· How is this different from a vertical asymptote?","['derivatives', 'continuity', 'functions']"
2442461,"Zero derivative implies constant function (No MVT, Rolle's Theorem, etc.)","I'm working through Foundations of Mathematical Analysis by Johnsonbaugh.
The following problem is given before MVT is proven. However, we do know about compactness, completeness, continuity, intermediate value theorem, metric spaces, sequences, etc. I am trying to find a proof that does not use MVT. This question seems similar to mine, but they end up using something equivalent to Rolle's theorem in the answer. Problem: Suppose $f'(x) = 0$ for all $x \in (a,b)$. Prove that $f$ is constant on $(a,b)$. Attempt: Let $x,y \in (a,b)$. We have $$f'(x) = \lim_{z \to x} \frac{f(z)-f(x)}{z-x} = 0$$ and $$f'(y) = \lim_{z \to y} \frac{f(z)-f(y)}{z-y} = 0$$","['derivatives', 'real-analysis', 'continuity']"
2442538,Suspicious proof of continuous mapping theorem on random variables,"My textbook has this theorem: Suppose that $X_1,X_2,\cdots$ converges in probability to a random variable $X$ and that $h$ is a continuous function. Then $h(X_1), h(X_2),\cdots$ converges in probability to $h(X)$ Failed to come up with a proof immediately, I looked at the proof provided in the solution : If $h$ is continuous, given $\epsilon > 0$ there exits $\delta>0$ such that $|h(x_n)−h(x)| < \epsilon$  for $|x_n−x| < \delta$. Since $X_1,\cdots, X_n$ converges in probability to the random variable $X$, then $\lim_{n\to\infty} P(|X_n − X| < \delta) = 1$. Thus $\lim_{n\to\infty} P(|h(X_n) − h(X)| < \epsilon) = 1$. The part follows ""since"" does not really make sense to me. I think the subtly lies in the fact that $X_n$ is a random variable (that is, a function defined on some sigma-algebra $\Omega$). So for a given $\omega \in \Omega$, for a given $n$, and for a given $\epsilon >0$, we indeed can find $\delta$ such that
$$|X_n( \omega) - X (\omega)| < \delta \text{ implies that } |h(X_n( \omega) - h(X (\omega))|<\epsilon$$ , but the choice of such $\delta$ seems to depend on $\omega$ and $n$? My expectation was that, in the end, we want something like
$$\{\omega\in \Omega: |X_n(\omega) - X(\omega)|<\delta\} \subset \{ \omega\in\Omega: |h(X_n(\omega) - h(X(\omega))| < \epsilon\}$$","['probability', 'measure-theory', 'analysis']"
2442574,How to use a tangent circle in a numerical method for complex-valued differential equation,"If you solve the equation $$\frac{dz}{dt}=-i\omega z$$ with initial value $z(0)=1$ you get $$z = e^{-i\omega t}$$ which traces a circle in the complex plane with angular speed $-\omega$.  If you try to the Euler method of approximating the solution, it diverges because $$z_1 = z_0 + h(-i\omega)z_0 = (1-ih\omega)z_0$$ and $$|z_1| = |1-ih\omega| = \sqrt{1+(h\omega)^2}$$ for $h,\omega >0$.  Likewise $|z_{n+1}|>|z_n|$ for each $n\in\mathbb{N}$. I'm trying to think of ways to fix this, so that $|z_{n+1}| \leq |z_n|$ and preferably with equality.  I tried using the second term of the Taylor series so that the approximation didn't merely make a linear approximation, but the same problem persisted. It occurs to me that a better method might be to approximate this not with a polynomial but with a circle.  I recall from calc 3 the osculating circle, but that was for a curve whose parameterization we already knew, so I'm not sure if I can leverage that.  Another thought is that rather than the scheme $$y_{n+1}=y_n+hy'_n$$ which moves from $y_n$ linearly by adding a multiple of $h$, I might want to rotate using complex multiplication, something like $z_{n+1}=z_nr_ne^{i\omega_nh}$ where $r_n\in\mathbb{R}$ would be the radius of the rotation, larger for when larger curvature is appropriate, and $\omega_n$ controlling the speed and direction--again, of course, $h$ serving as the step-size.  I probably would need to do something to deal with the issue of locating the center of the rotation. I know what I've done is not quite right because I'd have to also account for the center of the rotation, but before going down that road I wanted to know if what I'm attempting is even workable.  The big hurdle I can't quite figure out is how I might decide $r_n$ and $\omega_n$ at each stage, using only the derivative information.  If I understand it correctly, $\frac{dz}{dt}$ gives only the linear approximation of the direction of the complex number, like with a vector.","['numerical-methods', 'ordinary-differential-equations', 'approximation']"
2442592,Conditional Probability of Train Arriving on Time,"Suppose that a train is scheduled to arrive at its destination at noon. Also suppose that if it experiences no major problems it will arrive before noon with probability $0.9$, if it experiences one major problem it will arrive before noon with probability $0.5$, if it experiences two major problems it will arrive before noon with probability $0.1$, and if it experiences more than two major problems it will not arrive before noon. If the probability of no major problems is $0.5$, the probability of one major problem is $0.2$, the probability of two major problems is $0.2$, and the probability of more than two major problems is $0.1$, given that the train will arrive before noon, what is the probability of no major delays? Attempted Solution: P(no major problems | arrives before noon) = P(no major problems $\cap$ arrives before noon)/P(arrives before noon) $${.5(.9)\over .5(.9)+.2(.5)+.2(.1)+.1(0)} = .7895$$ Did I do this correctly?","['statistics', 'probability']"
2442603,Product and Intersection of n ideals,"I am trying to prove that the product of $n$ pairwise coprime ideals is their intersection. I can easily do the proof for $n=2$, and I see how to generalize the argument but there are details I don't know how to handle. Here's my attempt: Let $R$ be a commutative ring, $I_1,\dots,I_n$ be a collection of ideals such that $I_i+I_j=R$ for all $i\neq j$. Then $\cap_i I_i\subseteq\prod_i I_i$. For all $i\neq j$ I can find elements $a_{ij}\in I_i$, $a_{ji}\in I_j$ such that $a_{ij}+a_{ji}=1$. Thus if $x\in \cap_i I_i$, it can be written as \begin{equation}
x=\prod_{i\neq j} (a_{ij}+a_{ji}) x. \end{equation}
My problem is: how to write the above product as a sum of products of elements of each ideal. I can see it works, but the product gets super-messy already with $n=3$, so I don't see how to write it in  close form.","['abstract-algebra', 'ring-theory', 'ideals']"
2442613,Find the coefﬁcient of $x^{17}$ in $(x^2+x^3+x^4+x^5+x^6+x^7+...)^3.$,"This is #5 from Section 6.2 of Applied Combinatorics by Alan Tucker : Find the coefﬁcient of $x^{17}$ in $(x^2+x^3+x^4+x^5+x^6+x^7+...)^3.$ The books answer: $C(11+3−1,11)−C(3,1)×C(5+3−1,5)$. I'm not sure where the second term comes from? Here is my work: $$\begin{array}{l}
(x^2+x^3+x^4+x^5+x^6+x^7+\ldots)^3\\
=x^6(1 + x + x^2 + \ldots)^3\\
=x^6\dfrac{1}{(1-x)^3}\\
=x^6\left(1 + C(1+3-1,1)x + C(2 +3-1,2)x^2+C(3+3-1,3)x^3+ \ldots \right)
\end{array}$$ So, the coefficient of $x^{17}$ is really going to be the coefficient of $x^{11}$. So our answer is: $$C(11+3-1,11).$$ But that's only half the book answer stated above. Why?","['generating-functions', 'combinatorics', 'binomial-coefficients']"
2442718,How to find values such that the curves $y=\frac{a}{x-1}$ and $y=x^2-2x+1$ intersect at right angles?,"Problem: Find all values of $a$ such that the curves $y = \frac{a}{x-1}$ and $y = x^2-2x+1$ intersect at right angles. My attempt: First, I set the two curves equal to each other: $ \frac{a}{x-1} = x^2 - 2x + 1 $ $ \frac{a}{x-1} = (x-1)^2 $ $ \frac{a}{x-1}(x-1) = (x-1)^2(x-1) $ $ a = (x-1)^3 $ $ \sqrt[3] a = x-1 $ $ \sqrt[3] a + 1 = x $ ​
I found the derivative of the first curve: $ y = \frac{a}{x-1} $ $ y = a(x-1)^{-1} $ $ y' = -a(x-1)^{-2} $ $ y' = \frac{-a}{(x-1)^{2}} $ Then I found the derivative of the second curve: $ y = x^2 - 2x + 1 $ $ y' = 2x - 2 $ Next, I multiplied them together and set them equal to -1: $ \frac{-a}{(x-1)^{2}} ⋅ 2x - 2 = -1 $ $ \frac{-2ax + 2a}{(x-1)^2} = -1 $ $ \frac{-2a(x-1)}{(x-1)^2} = -1 $ $ \frac{-2a}{x-1} = -1 $ $ \frac{-2a}{x-1} ⋅ (x-1) = -1(x-1) $ $ -2a = -x+1 $ $ a = \frac{-x+1}{-2} $ Now I am unsure how to finish the problem. Do I substitute what I found for $x$ into $ a = \frac{-x+1}{-2} $? But my problem shows that there are two possible answers for $a$ so I am confused. Any help would be appreciated! Thank you in advance!","['derivatives', 'calculus']"
2442734,Number of three-term arithmetic progressions in [n],"Three numbers are chosen at random between 1 and $n$ (say $n=500$).What will be the probability of those numbers to be in arithmetic progression? I don't know how to count the number of favorable events.
Sample space={(1,2,3),(4,5,6),(18,20,21)........} 
favorable events={(2,4,6),(8,12,16),(10,20,30),(50,100,150... and many more)}
I can count the sample space but how do i count the favorable events.
Some insight could help?","['combinatorics', 'arithmetic-progressions', 'probability']"
2442873,How to interpret the action of a projective linear group on a projective space?,"Refer to: To complete the proof that $\operatorname{PSL}(2,\Bbb F_5)\cong A_5$ . I'm starting to understand the group action of a projective linear group of degree $2$ on $\Bbb P^1(\Bbb F_q)$. But that's because I've already learnt about Möbius transformations, i.e. actions of $\operatorname{PSL}(2,\Bbb C)$ on $\Bbb{\widehat C}$, when I was studying non-Euclidean geometry before. So I just need to change the field in question from $\Bbb C$ to a finite one. I want to know more about the structure of projective linear groups of higher degree, e.g. $\operatorname{PGL}(3,\Bbb F_q)$ and $\operatorname{PSL}(3,\Bbb F_q)$. I have no prior knowledge in projective geometry (at least I think so). Can someone give a quick explanation to me what is $\Bbb P^k(\Bbb F_q)$, or how does it look like? https://en.wikipedia.org/wiki/Projective_space gives a definition like $\Bbb P^k(\Bbb F_q):=(\Bbb F_q^{k+1}-\{(0,0,\dots,0)\})/\sim$ which they say identifies points which lie on the same line passing through origin as in the same equivalence class. That's fine. But I can't visualize it, especially in the context of finite fields. Also https://en.wikipedia.org/wiki/PSL(2,7) says that $$\text{For}\space\gamma=\begin{pmatrix}a&b&c\\d&e&f\\g&h&i\end{pmatrix}\in\operatorname{PSL}(3,\Bbb F_2)\space\text{and}\space\mathbf x=\begin{pmatrix}x\\y\\z\end{pmatrix}\in\Bbb P^2(\Bbb F_2),\space\gamma.\mathbf x=\begin{pmatrix}ax+by+cz\\dx+ey+fz\\gx+hy+iz\end{pmatrix}$$ Why does $\gamma$ acts on $\mathbf x$ like this?? I can only see why the elements of $\Bbb P^2(\Bbb F_2)$ are represented as three-dim. vectors. And now I have another serious problem: I can't recover the way I interpret the action of $\operatorname{PSL}(2,*)$ on $*\cup\{\infty\}$ from what I've learnt today! I know that (from what I've learned in Möbius geometry) for $\gamma=\begin{pmatrix}a&b\\c&d\end{pmatrix}\in\operatorname{PSL}(2,\Bbb F_q)$ and $x\in\Bbb F_q\cup\{\infty\}$, $\gamma.x=\frac{ax+b}{cx+d}$. Now I realized that $\Bbb P^1(\Bbb F_q)$ is actually $\Bbb F_q\cup\{\infty\}$. Why can the $x$ not be represented as a two-dim. vector, but just a scalar here? and the $\frac{ax+b}{cx+d}$: neither does it look like a two-dim vector. I'm sure that what I learnt about Möbius transformations can't be wrong, neither can the description of linear fractional transformations as an element of $\operatorname{PSL}(2,*)$ acting on $x$ by $x\mapsto\frac{ax+b}{cx+d}$ be. Just how to reconcile my intepretation with the new one derived from the definition of a projective line? I think I'm writing too much. I must stop here.","['finite-groups', 'abstract-algebra', 'projective-geometry', 'projective-space', 'group-theory']"
2442916,Definition of Method of Moments,"In the mathematical literature, I have found two definitions for the Method of Moments so far: The first definition concerns a method for estimating the parameters of a population. This method is described, for instance, in Wikipedia: https://en.wikipedia.org/wiki/Method_of_moments_(statistics) In probability theory, the Method of Moment concerns a result which allows to prove the convergence in distribution of a sequence of random variables. There is another Wikipedia entry for this method: https://en.wikipedia.org/wiki/Method_of_moments_(probability_theory) My question is whether these two meanings are somehow related, or whether ""Method of Moment"" is indeed used to describe two unrelated methods?","['probability-theory', 'statistics']"
2442937,Sum of $\sum_{n=1}^{\infty}\frac{n}{2^n}$. [duplicate],"This question already has an answer here : Limit of the infinite sum of $\frac{n}{2^n}$? [duplicate] (1 answer) Closed 6 years ago . I was trying to find the sum of $\sum_{n=1}^{\infty}\frac{n}{2^n}$. I tried like this $S = \sum_{n=1}^{\infty}\frac{n}{2^n} = \sum_{n=1}^{\infty}(\frac{n+1}{2^n} - \frac{1}{2^n}) = 2\sum_{n=2}^{\infty}\frac{n}{2^n} - 1$ So,$S = 2(S - \frac{1}{2}) - 1$ Implying $S =2$. EDIT: Also from many posts in the comment below I found a method of looking at the sum $\sum x^n$ and differentiating and plugging for $x$. Is there any other method of looking at the problem and calculating the sum apart from the above method,may be it would be interesting to see different approaches to the same problem which may be used to visualize other problems based on summation of series?","['sequences-and-series', 'calculus']"
2442948,$\dim V = \dim V/U+\dim U$,"Is the following Proof Correct? Theorem. Given that $U$ is a subspace of $V$ and $\{v_1+U,v_2+U,\ldots,v_m+U\}$ is a basis for $V/U$ and $\{u_1,u_2,...,u_n\}$ is a basis for $U$ prove that $\{v_1,v_2,\ldots,v_m,u_1,u_2,\ldots,u_n\}$ is a basis for $V$ . Proof. We know that the dimension of a quotient space is determined as follows $$\dim V/U = \dim V-\dim U$$ which implies that $\dim V = \dim V/U+\dim U$ therefore the list $v_1,v_2,\ldots v_m,u_1,u_2,\ldots,u_n$ is of the right length i.e. $m+n$ . To establish that the list is a basis we need only prove that either the list is linearly independent or spans $V$ , we choose the latter option. Let $v\in V$ be arbitrary, evidently $v+U\in V/U$ and therefore for some $\alpha_1,\alpha_2,\ldots,\alpha_m\in\mathbf{F}$ $$v+U = \sum_{j=1}^{m}\alpha_j(v_j+U) = \left(\sum_{j=1}^{m}\alpha_jv_j\right)+U$$ which may be equivalently stated as follows $$v-\left(\sum_{j=1}^{m}\alpha_jv_j\right)\in U$$ and consequently for some $\beta_1,\beta_2,\ldots,\beta_n\in\mathbf{F}$ we have $$v-\left(\sum_{j=1}^{m}\alpha_jv_j\right) = \sum_{i=1}^{n}\beta_i u_i$$ which implies that $$v = \sum_{j=1}^{m}\alpha_jv_j+\sum_{i=1}^{n}\beta_i u_i$$ since $v$ was arbitrary it follows that $\operatorname{span}\{v_1,v_2,\ldots,v_m,u_1,u_2,\ldots,u_n\} = V$ . $\blacksquare$","['linear-algebra', 'solution-verification', 'vector-spaces']"
2442950,"What is a ""finite $\sigma$-algebra""?","I have an exersice which is outlined as follows Suppose $G_{i}$ where $i=0 \ldots n$ is a disjoint union of $\Omega$. Prove that the family of unions of these $G_{i}$ is a sigma algebra on $\Omega$. Also prove that any ""finite sigma algebra"" $\mathcal{F}$ on $\Omega$ is of this form. My guess is that a finite sigma algebra is a sigma algebra with finite number of sets but I am not sure. I cant find the definition anywhere, does anyone know where I can find it?","['probability-theory', 'measure-theory']"
2442967,How to evaluate $\lim_{x\to0}\frac{\sin^2\left(\frac x2\right)-\frac{x^2}4}{e^{x^2}+e^{-x^2}-2}$?,"$$\begin{align*}
\lim_{x \to 0} \frac{\sin^2 \left(\frac{x}{2}\right) - \frac{x^2}{4}}{e^{x^{2}} + e^{-x^{2}} - 2} &\overset{L}{=} \lim_{x \to 0} \frac{\sin \frac{x}{2} \cos \frac{x}{2} - \frac{1}{2}x}{2xe^{x^{2}} + (-2x)e^{-x^{2}}} \\
&= \lim_{x \to 0} \frac{\sin \frac{x}{2} \cos \frac{x}{2} - \frac{1}{2}x}{2xe^{x^{2}} -2xe^{-x^{2}}} \\
&\overset{L}{=} \lim_{x \to 0} \frac{\frac{1}{2}\cos^2 \frac{x}{2} - \frac{1}{2}\sin^2 \frac{x}{2} - \frac{1}{2}}{(2x)(2x)e^{x^{2}} - (2x)(-2x)(e^{-x^{2}})} \\
&= \lim_{x \to 0} \frac{\frac{1}{2}\cos^2 \frac{x}{2} - \frac{1}{2}\sin^2 \frac{x}{2} - \frac{1}{2}}{4x^2 e^{x^{2}} + 4x^2 e^{-x^{2}}} \\
&\overset{L}{=} \lim_{x \to 0} \frac{\frac{1}{2}\left( -\sin \frac{x}{2} \cos \frac{x}{2} \right) - \frac{1}{2} \left( \sin \frac{x}{2} \cos \frac{x}{2} \right)}{(4x^2)(2x)e^{x^{2}} + (4x^2)(-2x)(e^{-x^{2}})} \\
&= \lim_{x \to 0} \frac{-\sin \frac{x}{2} \cos \frac{x}{2}}{8x^3e^{x^{2}} - 8x^3 e^{-x^{2}}} \\
\end{align*}$$ After evaluating the limit as $x \to 0$, I noticed that the problem comes up to be in an indeterminate form of $0/0$. I immediately utilized the L'Hospital Rule by differentiating both the numerator and denominator. However, after using L'Hospital rule for 5-6 times, I noticed that the question will go through a loop of $0/0$ indeterminants. In my second attempt,
I have tried multiplying $\exp(x^2)$ in both the numerator and denominator with hopes to balance out the $\exp(x^{-2})$. However, an indeterminant is $0/0$ still resulting. Any help would be appreciated, thank you all!",['limits']
2442974,Treasures from the OEIS Plot 2,"The On-Line Encyclopedia of Integer Sequences provide us a tool with the link Plot 2 . With this tool one can perform comparisons between two different sequences of positive integers. In number theory seems that there are some remarkable questions when one works with a sequence $A(n)$ of positive integers: defining and studying its   arithmetic mean and as a consequence the average order of $A(n)$; the order or magnitude of $A(n)$, or some notion of density for the terms of our sequence $A(n)$ (for example defining an asymptotic density, or well studying how fast goes to infinite  $\sum_{n=1}^N\frac{1}{n}$ versus $\sum_{n=1}^\infty\frac{1}{n^2}<\infty$, more examples with primes or different sequences of positive integers are well known). Also as an aside aslo if the terms of our sequence of positive integers satisfy remarkable congruences, recurrences or diophantine equations. Question. I would like to know if comparing a well known sequence of positive integers $A(n)$ with a little-known sequence of positive integers $\hat{A}(n)$ you can tranfer some remarkable knowledges from $A(n)$ to $\hat{A}(n)$ using this tool Plot 2 . Is it feasible? If yes, how does work your example? That is, how do you explore a little-known sequence $hat{A}(n)$ from The On-Line Encyclopedia of Integer Sequences using Plot 2 by means of a comparison with a well known $A(n)$? Thanks in advance. Only are required didactic tips, but if for your example you can set good statements or conjectures using this tool Plot 2, it  is appreciated. In your example feel free to change your input $A(n)$ to make multiple comparisons but always for a same $\hat{A}(n)$.","['analytic-number-theory', 'number-theory', 'soft-question', 'oeis', 'sequences-and-series']"
2442978,"A question regarding $\forall a,b\in \mathbb{Q}\enspace\exists x,y \in \mathbb{Z}:\operatorname{gcd}(a,b)=xa+yb$","I'm  currently reading a book on discrete mathematics, more specifically I'm having a look at the chapter that covers some elementary number theory. There I read about something called Euclid's algorithm which can be used to find the greatest common divisior of two numbers. It was claimed that if this algorithm is used in reverse then it can be shown that $\forall a,b\in \mathbb{Q}\enspace\exists x,y \in \mathbb{Z}:\operatorname{gcd}(a,b)=xa+yb$. The proof of this was omitted and only a special case was demonstrated. I however am not entirely convinced that this theorem holds true just from observing a special case. I am unable to run the algorithm in reverse in my head in the case where the numbers are arbitrary. Can anyone help me prove this theorem? How can I consider the aformentioned argument in order to be convinced that the theorem ought to be true? Any help is appreciated.","['euclidean-algorithm', 'elementary-number-theory', 'rational-numbers', 'integers', 'discrete-mathematics']"
2443048,Automorphism group of the Leech lattice,"I have seen that the automorphism group of the Leech lattice is the Conway group $\ Co_0$, which is a finite group. But for example the lattice $\mathbb Z^n$ has an infinite automorhism group. Can anyone explain me, what is the difference between these two lattices, that results in the (in)finiteness of their respective automorphism  groups?","['integer-lattices', 'group-theory']"
2443062,Help proving that an finite morphism of schemes is a closed map,"I am trying to prove that a finite morphism $f: X \longrightarrow Y$ of schemes is a closed map. That is, that the image of a closed set is closed in $Y$. I am a little unsure about the proof that I have, and I am very new to this stuff so am prone to missing subtleties. I would really appreciate if anyone could glance through what I have and see if my argument is valid. One thing I am a particularly curious about is in the second last paragraph. Do I need to specifically choose the ideal $\mathcal{I}$ to give $Z$ the reduced subscheme structure or not? The following is my attempt at a proof: We will first show the following lemma: Let $f: \text{Spec }  A \longrightarrow \text{Spec }  B$ be a finite morphism of affine schemes corresponding to a morphism $\phi: B \longrightarrow A$ of rings. Then $f(\text{Spec } A)$ is closed in $\text{Spec } B$. To show this, first note that if $f$ is a finite morphism, then $\phi$ is a finite morphism of rings. This implies that $\phi: B \longrightarrow A$ is integral. That is, that $A$ is an integral extension of $\phi(B)$. We have the surjective morphism
$$
\pi: B \longrightarrow B / \ker\phi
$$
from which we get a morphism of schemes 
$$
\iota: \text{Spec }  (B / \ker \phi) \longrightarrow \text{Spec } B
$$
which is a homeomorphism onto a closed subset of $\text{Spec }  B$. The morphism $f: \text{Spec }  B \longrightarrow \text{Spec }  A$ factors as
$$
\text{Spec }  A \stackrel{\tilde{\phi}^{*}}{\longrightarrow} \text{Spec }  (B / \ker \phi) \stackrel{\iota}{\longrightarrow} \text{Spec }  B.
$$
So to show that $f(\text{Spec }  A)$ is closed in $\text{Spec } B$, we need only show that $\tilde{\phi}^{*}$ is surjective. But $\tilde{\phi}^{*}$ is induced by the injective morphism of rings
$$
\tilde{\phi}: B / \ker(\phi) \longrightarrow A,
$$
which corresponds to an integral extension $B / \ker(\phi) \subseteq A$. Surjectivity then follows by the Going-Up Theorem. We will now show that $f: \text{Spec }  A \longrightarrow \text{Spec } B$ is a closed map. Let $Z \subseteq \text{Spec } A$ be any closed subset of $\text{Spec }  A$ corresponding to an ideal $\mathcal{I} \subseteq A$ so that $Z = \text{Spec }  (A / \mathcal{I})$. But since $A$ is finite over $B$ via $\phi$, we also have $A / \mathcal{I}$ is finite over $B$. Then by the above result, we have that $f(\text{Spec }  (A /\mathcal{I}))$ is closed in $\text{Spec }  B$. Finally, for the general case of a finite morphism $f: X \longrightarrow Y$ of schemes, we use the fact that $Z \subset X$ is closed precisely if it is closed in the induced topology of any affine open in $X$. Similarly, $f(Z)$ is closed in $Y$ precisely if it is closed in the induced topology of any affine in $Y$. The result then follows from the above on affines.","['integral-extensions', 'modules', 'algebraic-geometry', 'closed-map', 'proof-verification']"
2443076,How to prove escalation to infinity (+ or -) for a few numbers with cases n/3 and 4n+1.,"How do I prove that following numbers 45, 61, 101 and -59 are going up to infinity, but -155 falls into a loop. f(n)=
\begin{cases}
n/3, & \text{if $n≡ 0$ $(mod$ $3)$}  \\
4n+1, & \text{if $n≢ 0$ $(mod$ $3)$}
\end{cases} Example: 45 - 15 - 5 - 21 - 7 - 29 - 117 - 39 - 13 - 53 - 213 - 71 - 285 - 95 - 381 - 127 - 509 - 2037 - 679 - 2717 - 10869 - 3623 - 14493 - 4831 - 77301 - 25767 - etc.","['sequences-and-series', 'analysis', 'elementary-number-theory']"
2443080,"The number of functions from $[5]$ to $[5]$ such that $f(f(x)) \neq x $ for $ x=1, \ldots 5$ is $44$","True or false: The number of functions from $[5]$ to $[5]$ such that $f(f(i)) \neq i $ for $ i=1, \ldots 5$ is $44.$ (Here $[5] = \{1,2,3,4,5\}.)$ The number of derangements on $5$ elements is $44$ but the functions in question are clearly not just derangements, since the existence of $x, y$ such that $f(x)=y$ and $f(y)=x$ is also prohibited. Further, there is no restriction on $f$ to be bijective. My attempt: for each function $f,$ define $g= f^2$ and count functions $g: [5] \to [5]$ such that $g(i) \neq i$ by inclusion-exclusion as follows: $5^5 -\binom{5}{1}(4^4) + \binom{5}{2}(3^3)- \ldots $ and so on. The problem though is that the set of $g's$ aren't in bijective correspondence with the set of $f's$ and I'm not convinced that the expression I have above is right because the resultant answer is too large. Any help would be appreciated.",['combinatorics']
2443105,Lebesgue integral of $x^2$,"Let $g:\mathbb{R} \rightarrow [0,\infty)$, where $g(x)=x^2$. Calculate $\int gd\lambda$, where $\lambda$ is the lebesgue measure. I've done the following, but I am not sure if this is correct: $$\int x^2d\lambda =\lim_{n\rightarrow \infty}\int x^21_{[-n,n]}d\lambda=\lim_{n\rightarrow \infty}R\int_{-n}^{n}x^2dx=\lim_{n\rightarrow \infty}\left(\frac{n^3}{3}-\frac{-n^3}{3}\right)=\infty$$","['lebesgue-integral', 'measure-theory']"
2443161,Proving $\int_{0}^\pi \frac{2\cos 2\theta + \cos 3\theta}{5+4\cos\theta} = \frac{\pi}{8}$,"Given that $$\int_{|z|=1|}\frac{z^2}{2z+1} dz = \frac{i\pi}{4}$$, show $$\int_{0}^\pi \frac{2\cos 2 \theta + \cos 3\theta}{5+4\cos\theta} = \frac{\pi}{8}$$. I saw the bounds of the latter integral and thought that I should try and parametrize using $z = e^{2i\theta}$ where $\theta \in [0,\pi]$.
This doesn't seem to simplify easily. i saw this thread: Show that $\int_0^\pi\frac{2\cos(2\theta)+\cos(3\theta)}{5+4\cos(\theta)}d\theta=\frac{\pi}{8}$ and the top answer says: $$\begin{align}
\int_0^\pi \frac{2\cos(2\theta)+\cos(3\theta)}{5+4\cos(\theta)}\,d\theta&=\frac12\text{Re}\left(\oint_{|z|=1}\frac{2z^2+z^3}{5+2(z+z^{-1})}\,\frac{1}{iz}\,dz\right)\\\\\end{align}$$ which I don't understand. How does multiplying a half to the integral with contour $|z|=1$ (parametrized by $z = e^{i\theta}, \theta\in [0,2\pi]$) give the LHS? I tried looking at it by taking the latter integral and using the substitution $u=\pi + \theta$, in hopes that the integrand simplifies to stay the same but it doesn't, so I can't see why the integral with bounds $0,\pi$ is half the integral that would have bounds $0,2\pi$ (since we would use the parametrization $z=e^{i\theta}$).",['complex-analysis']
2443185,An inequality involving irrational numbers,"Let $x > 1$ be an irrational number , then how to show that there exist $y \in (1,2)$ such that $0<yx^n-[yx^n]<\dfrac 1{x-1} , \forall n\in \mathbb N$ ? , here $[.]$ denotes the greatest integer function .","['number-theory', 'real-analysis', 'inequality', 'irrational-numbers']"
2443221,Trying to formalise intuition into a proof that symmetric (hermitian) matrices are diagonalisable,"The other day I stumbled upon LittleO's answer in this question . To make reading it easier I did a straight copy-and-paste here: Here's some intuition (but not a rigorous proof). If $A$ is hermitian (with entries in $\mathbb C$), you can easily show that the eigenvalues of $A$ are real and that eigenvectors corresponding to distinct eigenvalues are orthogonal. Typically, all the eigenvalues of $A$ are distinct.  (It is in some sense a huge coincidence if two eigenvalues turn out to be equal.) So, typically $A$ has an orthonormal basis of eigenvectors. Even if $A$ has some repeated eigenvalues, perturbing $A$ slightly will probably cause the eigenvalues to become distinct, in which case there is an orthonormal basis of eigenvectors.  By thinking of $A$ as a limit of slight perturbations of $A$, each of which has an ON basis of eigenvectors, it seems plausible that $A$ also has an ON basis of eigenvectors. While this idea struck me as very ingenious and intuitive, I'm really having difficulty formalising it into a real proof. The major obstacles are: 1). How to perturb an hermitian $A$ while keeping its eigenvalues distinct? In particular, how to find an hermitian sequence $A_n$ that have distinct eigenvalues and converge to $A$ in some norm? 2). Based on 1), how to continuously associate the eigenvector family $V_n:=[v_{n,j},j=1,\cdots,d]$ (corresponding to $A_n$, assuming $A_n$ are $d$ by $d$) to $A_n$? Having solved this I would have $V:=[v_j,j=1,\cdots,d]$ (corresponding to $A$) are the limits of $\{v_{n,j},j=1,\cdots,d\}$ respectively and hence $V^HV = \lim_{n\to\infty} V_n^HV_n = I$ and we are done.","['eigenvalues-eigenvectors', 'linear-algebra']"
2443276,Maximum value of a function with condition,"Hello everybody I have a question about this : Let a function $f$ with domain $]0,+\infty[$ and codomain $]0,+\infty[$ and twice differentiable with the following inequality :
  $$f'+f''\geq f^2>0$$ Furthermore we now this about $f$ and this condition : 1)$\lim\limits_{x \to \infty}f(x)=0$ 2)$f(x)$ is convex for all $x>0$ or $f'<0$ for all $x>0$ 3)$\lim\limits_{x \to 0}f(x)=\infty$ 4)If we make this substitution $f(x)=ln(g'(e^{-x}))$ so we have (if we apply the inequality) :
$$e^{-2x}[\frac{g'''(e^{-x})}{g'(e^{-x})}-\frac{g''(e^{-x})^2}{g'(e^{-x})^2}]\geq ln(g'(e^{-x}))^2>0$$ So there is a link with the Schwarzian derivative 5)We can find $\alpha$ such as we have :
 $$\frac{ln(-e^{-\alpha x }+1)}{-\alpha x}\leq f_{\alpha}(x)$$ So now my question is: what's the maximal value of $f(n)$? Second Edit :Geometrically speaking If you take the osculating circle of a function $f(x)$ what's the maximum value that can be taken by the osculating circle of minimum radius ? Finally I give you some examples of functions wich verify the inequality :
$$f(x)=\frac{ln(-e^{-\alpha x }+1)}{-\alpha x}$$ for all $\alpha\geq 1$
$$f(x)=ln(|\frac{e^{x^2}-1}{e^{x^2}+1}|)^2$$
$$f(x)=\frac{e^{-x}}{x^2}$$ Edit : Furthermore we know that we have under the initial inequality $f'(x)^2\leq f(x)f''(x)$ for all $x>0$ so this paper could be useful . Third edit : I found a 'maximal' function (maybe there exists an another that's all the question ) wich is : $$M(x)=\frac{3 e^{-x}(x^2+2)}{x^2}+7e^{-2x}+3e^{-3x}$$ So for the moment I can't find better than this : $f(1)\leq M(1)$ If we put the following substitution $f(x)=g''(1-e^{-x})$ we get : $$e^{-2x}g^{(iv)}(1-e^{-x})\geq g''(1-e^{-x})^2$$ So this paper is interesting if we assume that $\lim\limits_{x \to 0}f(x)=l$ where $l$ is a real positive number . We get : $$g^{(iv)}(0)\geq g''(0)^2$$ wich corresponds to $d=1$ in the paper . Thanks a lot .","['functional-analysis', 'real-analysis', 'inequality']"
