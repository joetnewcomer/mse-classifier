question_id,title,body,tags
1953058,Are there infinitely many primes of the form $12345678901234567890\dots$,"Related to this question, What is the smallest prime number made of sequential number? are there infinitely many primes of the following form ( OEIS A057137 )? $1, 12, 123, 1234, 12345, 123456, 1234567, 12345678, 123456789, 1234567890, 12345678901, 123456789012, 1234567890123, 12345678901234, 123456789012345, 1234567890123456, 12345678901234567, 123456789012345678, 1234567890123456789, \dots$ The first five such primes are fairly easy to find via brute force with the aid of a computer and have the following lengths: $171, 277, 367, 561, 567$ The sixth term comes after a bit of a gap with length $18881$ (see OEIS A120819 ), which takes a significant amount of computation time to reach, even just testing integers ending in $1$ and $7$. Are there infinitely many such primes? Edit : For such numbers ending in $1$, we can write $$x_n = 10^{10n} + 2345678901 \cdot \frac{10^{10n}-1}{10^{10}-1}$$ and for such numbers ending in $7$, we can write $$y_n = 1234567 \cdot 10^{10n} + 8901234567\cdot \frac{10^{10n}-1}{10^{10}-1}$$","['number-theory', 'prime-numbers', 'sequences-and-series']"
1953068,Probability Question About Basketball Free Throws and Distributions [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed last year . Improve this question I was trying to solve the following question from the Harvard Stat $110$ course, from the book Introduction to Probability by Blitzstein and Hwang, but could not wrap my head around it. Any and all help is appreciated, especially with part (b): A certain basketball player practices shooting free throws over and over
  again. The shots are independent, with probability p of success. (a) In $n$ shots, what is the expected number of streaks of $7$ consecutive successful shots?
  (Note that, for example, $9$ in a row counts as $3$ streaks.) (b) Now suppose that the player keeps shooting until making $7$ shots in a row for the first time. Let $X$ be the number of shots taken. Show that $E(X) â‰¤ 7/p^7.$ Hint: Consider the first $7$ trials as a block, then the next $7$ as a block, etc.","['probability-theory', 'probability', 'statistics', 'probability-distributions']"
1953109,$C^\infty$ functions with all derivatives in $L^p$,"Let $1\le p<\infty$ and $f\in C^{\infty}(\mathbb{R})$ be such that its all derivatives $f^{(n)} \in L^p(\mathbb{R})$ for every $n\in \mathbb{N} \cup \{0\}$. 
Is it true that $f\in L^\infty(\mathbb{R})$?
If it is true, do we have a generalization in $\mathbb{R}^n$? My partial answer for $p=1$: For $p=1$ and  $t\in \mathbb{R}$, we have
$$
|g(t)|=
|\int_{0}^{t} g'(x) \ dx+g(0)|
\le
\int_{0}^{t}
|g'(x)| \ dx
+|g(0)|
\le 
\|g'\|_{L^1}
+|g(0)|.
$$ 
Thus, $g\in L^\infty(\mathbb{R})$ with 
$\|g\|_{L^\infty} \le \|g'\|_{L^1}+|g(0)|$. Thanks for help and hint.","['real-analysis', 'calculus', 'functional-analysis', 'lebesgue-integral', 'sobolev-spaces']"
1953135,$\sigma$-algebra generated by a sum of functions,"Is the $\sigma$-algebra generated by a finite sum of functions the same one as that generated by the set of those functions ? I'm trying to work it out but all I can get is stuff like $(X+Y)^{-1}(]-\infty,a[)=\displaystyle \cup_{t\in \mathbb{R}} (X^{-1}(\lbrace{t}\rbrace) \cap Y^{-1}(]-\infty, a-t[))$ which is already a bit of a mess since my reunion is uncountable.",['measure-theory']
1953185,Tensors and matrices multiplication,"I have to prove an equality between matrices $R=OTDO$ where $R$ is a $M\times M$ matrix $O$ is a $2\times M$ matrix $T$ is a $M\times M\times M$ tensor $D$ is a diagonal $2\times 2$ matrix The entries of the matrices and the tensor are probabilities so the result should somehow be the consequence of Bayes formula. The problem is that I have no idea how to compute that because I don't know how to use tensors. I had an algebra course about tensor products of vector spaces a long time ago but it was very abstract so I don't know how to multiply tensors in practice. I'm surprised because the first matrix of the product has $2$ rows, the last one has $M$ columns and yet the result is a $M\times M$ matrix. Could you explain how to do this? For example, what's the dimension of $OT$? I am familiar with the Kronecker product of matrices, is it useful here? EDIT Stupid me... I've spent hours trying to understand this product and... this was a typo. It was $O^TDO$ and the equality was straightforward... I've been confused by the fact that the tensor $T$ did exist and there could be and equality involving it. At least I've learnt a few things about tensors, thank you again for the answers!","['matrices', 'tensors']"
1953202,Architecture of Cantor's proof,"Cantor's diagonal argument consists of two parts: bijection and the extraction of the new number. If he shows that a given architecture of bijection doesn't work, why does it imply that any other architecture of bijection should not work either? Just an addendum to make my point clearer: Another possible architecture that comes to my mind is to write real numbers in the table and correspond them to the nth power of 2. Then we start to construct new numbers that weren't listed in our table and correspond them with powers of 3. After that we construct new numbers from the table of power of 3 (even if without checking we had them in the first table) we correspond them to the nth power of 5, and so on and so forth.
It is easy to notice that this is a poor bijection architecture as you can put them back into one list and just repeat the construction of the new number.
Why can it be mapped back to a simple list for any architecture? On the other hand we can easily think of correspondence of natural numbers to itself, in a way that we will end up having extra unlisted numbers.E.g.(1->2,2->4, etc...). Obviously it doesn't imply that there are more natural numbers than 'natural numbers'.",['elementary-set-theory']
1953218,"Is ""The empty set is a subset of any set"" a convention?","Recently I learned that for any set A, we have $\varnothing\subset A$. I found some explanation of why it holds. $\varnothing\subset A$ means ""for every object $x$, if $x$ belongs to the empty set, then $x$ also belongs to the set A"". This is a vacuous truth, because the antecedent ($x$ belongs to the empty set) could never be true, so the conclusion always holds ($x$ also belongs to the set A). So $\varnothing\subset A$ holds. What confused me was that, the following expression was also a vacuous truth. For every object  $x$, if $x$ belongs to the empty set, then $x$ doesn't belong to the set A. According to the definition of the vacuous truth, the conclusion ($x$ doesn't belong to the set A) holds, so $\varnothing\not\subset A$ would be true, too. Which one is correct? Or is it just a convention to let $\varnothing\subset A$?","['logic', 'elementary-set-theory']"
1953256,The Velocities of the Contact Points of Two Rolling Curves are Equal at the Instant of Contact,"Consider two 2-Dimensional rigid bodies surrounded by two planar smooth curves. Suppose that the two bodies are in the same plane and in contact with each other such that they are rolling with respect to each other. To demonstrate the meaning of rolling , suppose that the points $C_1$ and $C_2$ in the figure below are the contact points at the present time and the points $B_1$ and $B_2$ are the points that will be in contact after some time. Then the rolling condition is defined as $s_1=s_2$. So our definition of rolling is Definition . Two smooth curves are said to be rolling with respect to each other if the length of their contacted portions during a time interval is equal. Now, the main question is to prove the following theorem Theorem . Two smooth curves are rolling with respect to each other if and only if the velocity vectors of the contact points are equal to each other at the instant of contact. So the theorem is expressing an equivalent condition for rolling . Simple versions of the theorem are rolling of a circle over a straight line , inclined line, another circle, ellipse or parabola (See the animation below). Taking a look at the links will help you to visualize better. Without loss of generality you can assume that curve $2$ is still and curve $1$ is rolling on it. This is a well-known theorem that is taught to mechanical engineering students in a Machine Dynamics course without a proof! I was not able to find the proof anywhere in the engineering, physical or mathematical texts. I would be happy to see a full detailed answer but I do not expect one. Also, I have not defined the problem rigorously so if you see flaws you can modify it as you wish. But I think you can imagine what I mean by the examples and links I provided. Any guidance, help or hint is welcome and appreciated. This animation is made by J. M. and is included for better visualization.","['multivariable-calculus', 'differential-geometry', 'vector-analysis', 'geometry']"
1953270,Coins in the till and arithmetic progressions,"A person starts saving money by depositing 5 coins in his till on the first day. After that, every day, he deposits 2 more coins than the amount he deposited in the till on the previous day. However, so that 1100 coins may be in the till on day 30, he deposits $x$ coins more than the amount he deposited on the previous day from day 27 onwards. What is $x$ ? Use arithmetic progressions and the formula $S_n=\frac{n}{2}\left(2a_1+(n-1)d\right)$ . What I have tried: $$S_{26}=\frac{26} {2} \left\{2*5+(26-1)2 \right\}$$ $$S_{26}=13 \left\{10+50\right\}=780$$ The total in the till on the 30th day would then be $$S_{30}=\frac{30} {2} \left\{2*5+(30-1)2 \right\}$$ $$S_{30}=15 \left\{10+58 \right\}=1020$$ but isn't $S_{30}=1100$ ?","['algebra-precalculus', 'arithmetic-progressions']"
1953298,"What is the probability that in a group of $n$ people, every month of the year has at least one birthday.","What is the probability that in a group of $n$ people, every month of the year has at least one birthday. This is my approach: We have 12 months, and the probability that a month has at least one birthday = $1-(11/12)^n$ . And to find the probability that every month has at least 1 birthday I am trying to use the inclusion exclusion formula. But I am not able to proceed for the probability that there is at least one birthday for each of 2 months. Is my approach correct?","['birthday', 'coupon-collector', 'probability-theory', 'probability']"
1953302,Does randomness exist in computers and in nature?,"In the programming language Python, you can import random and then with random.random() you can get a random number between $0$ and $1$. But is it truly random or are there constraints in how computers are built that makes them not truly random number generators?
For instance, could there be a bias around the first value generated or value already in memory?
How would one figure out the difference?","['statistics', 'philosophy', 'random']"
1953304,Asymptotic formula for $n^{th}$ square-free,"I face an exercise : Find asymptotic formular for the $n^{th}$ square-free number with the error $O(n^{1/2}).$ I don't quite understand the question. What is the $n^{th}$ square-free number ? I guess it is primorial ? Like $2$ is the first, $2 \times 3$ second, $2 \times 3 \times 5$ third , ... (although I do not sure if it includes the number like $2 \times 5$ since $3$ is missing, and if it includes, what should be the third square-free number ? $2 \times 3 \times 5$ or $2 \times 5$.) Let assume that I want to find an asymptotic formula for $p_1...p_k$ where $p_k$ is the $k^{th}$ prime. So I need to find $g$ such that $$\lim_{x \rightarrow \infty} \frac{\prod_{p \leq x} p}{g(x)} = 1.$$ Basically, asymptotic $\sim$ can be related to little $o$, but this question mention something about error term $O(n^{1/2})$. How can asymptotic relate to big $O$ ? That makes me confused. For the method, I see that the primorial can be related to $e^{\theta(x)}$, where $\theta$ is the Chebyshev function. But I do not know how to do $\sim$ with big $O(n^{1/2}).$","['number-theory', 'analytic-number-theory', 'prime-numbers']"
1953307,$E|A_1|<\infty$ and i.o events for $\left\{A_n\right\}$ are iid,"Given $\left\{A_n\right\}$ are i.i.d. Show that $E(|A_1|)< \infty$ $\iff \ P\left\{|A_n| > n \ \ \text{i.o}\right\} = 0$. My attempt: ($\Rightarrow$) Assume $E(|A_1|)< \infty$. Since $\left\{A_n\right\}$ are i.i.d, by the Strong Law of Large Number, $\frac{1}{n}\sum_{i=1}^{n} |A_i|\rightarrow E(|A_1|)$ almost surely. This is equivalent to $\forall\  \epsilon > 0$, $\lim_{n\rightarrow \infty} P(\cup_{k\geq n}|(\frac{1}{k}\sum_{i=1}^{k} |A_i|)-E(|A_1|)|\geq \epsilon)= 0$. This implies for sufficiently large $k$, $\frac{1}{k}\sum_{i=1}^{k} |A_i| - E(|A_1|)\ <\ \epsilon$. Since we don't know whether $E(|A_1|) > 1$ or not, we cannot choose $\epsilon = 1-E(|A_1|)$ to get $|A_k|$ bounded above by $k$. Could someone please help with this part? ($\Leftarrow$) If $P\left\{|A_n| > n \ \ \text{i.o}\right\} = 0$, this implies for sufficiently large $k$, $k$ is fixed, $|A_k|< k$. This implies $E(|A_k|) = E(|A_1|) < E(k) = k < \infty$ (the first equality is due to $\left\{A_n\right\}$ are iid). My question: Could someone help complete my ""solution"" above for the forward direction? If I'm on the wrong track, please help point that out to me.","['real-analysis', 'independence', 'probability-theory', 'borel-cantelli-lemmas', 'measure-theory']"
1953360,Calculate present value of a continuous stream of payments with variable force of interest.,"The continuous rate of payments is $\rho(t)= \begin{cases} 
      0 & t< 1 \\
      12 & 1\leq t\leq 2 \\
      10+t & 2\leq x\leq 5 \\
      15 & 5\leq t\leq 6 \\
      0 & t>6
   \end{cases},
$ and the force of interest is $\delta(t)= \begin{cases} 0.08 & t\leq 2 \\ \frac{1}{10+t} & 2<t\leq 5 \\ 0.06 & t>5 \end{cases} $. The question is: What is the present value of the payments at time, $t = 0$? I know that the present value is: $$\int_{0}^{T} \rho(s) e^{ -\int_0^s \delta(u) du} ds$$
However, I cannot figure out how to evaluate this integral using the two piecewise functions. The main problem is understanding which part of $\delta(t)$ function I should use in the exponent and how to integrate from $0$ to $s$ when we don't know what the value of $s$ is. Thanks for any help.","['statistics', 'finance', 'definite-integrals', 'actuarial-science']"
1953363,Exercise II-3 from Eisenbud & Harris' The Geometry of Schemes,"I am having difficulty with the following exercise and would appreciate any help and explanations. Exercise II-3 on page 52 of The Geometry of Schemes by Eisenbud and Harris, but I give the setup first. The setup: We have $K$ -algebra inclusions $K[x,y] \hookrightarrow K[x,y]_{(x,y)} \hookrightarrow K[[x,y]]$ , where $K[x,y]$ is the commutative polynomial ring over $K$ in two variables, $K[x,y]_{(x,y)}$ is the polynomial ring localised at the maximal ideal $(x,y)$ , and $K[[x,y]]$ the commutative formal power series ring in two variables. These maps induce maps on the spectra as follows: $$\operatorname{Spec}K[[x,y]]\to\operatorname{Spec}K[x,y]_{(x,y)}\to\operatorname{Spec}K[x,y].$$ Consider the prime ideal $(y^{2}-x^{3}-x^{2})$ of $K[x,y]$ . This is still prime in $K[x,y]_{(x,y)}$ . However, in $K[[x,y]]$ we now have $$y^{2}-x^{3}-x^{2}=(y-u)(y+u)$$ where $u=x+\frac{1}{2}x^2 - \frac{1}{8}x^3 + \frac{1}{16}x^4 - \cdots$ . Exercise II-3. (a) With $u=\sqrt{x^2 +x^3}$ as above, what is the image of $[(y-u)]$ in $\operatorname{Spec}K[x,y]$ ? (Hint: it's a prime ideal containing $y^2 -x^3 -x^2$ .) (b) Show that the image of the point $(y-\Sigma_{n\geq 1}\frac{x^n}{n!})$ of $\operatorname{Spec}K[[x,y]]$ is the generic point of $\mathbb{A}^2_K = \operatorname{Spec}K[x,y].$ My attempt for (a): $K[x,y]_{(x,y)}$ is local with unique maximal ideal $(x,y)K[x,y]_{(x,y)}$ and has Krull dimension $2 = \operatorname{ht}(x,y)$ . $(y-u)\cap K[x,y]_{(x,y)}$ is a prime ideal containing the prime ideal $(y^2 -x^3 -x^2)$ , so we have the following chain of primes: $$(0)\subsetneq(y^2 -x^3 -x^2)\subseteq (y-u)\cap K[x,y]_{(x,y)}\subseteq (x,y)K[x,y]_{(x,y)}.$$ As this is happening in a ring of Krull dimension 2, this means we have only two options: either $(y^2 -x^3 -x^2)= (y-u)\cap K[x,y]_{(x,y)}$ or $(y-u)\cap K[x,y]_{(x,y)}= (x,y)K[x,y]_{(x,y)}$ . Now I claim that $$(y-u)\cap K[x,y]_{(x,y)} \neq(x,y)K[x,y]_{(x,y)}. $$ If we did have $(y-u)\cap K[x,y]_{(x,y)} =(x,y)K[x,y]_{(x,y)}$ , then we would have $x\in(y-u)\cap K[x,y]_{(x,y)},$ so that $x\in ((y-u)\cap K[x,y]_{(x,y)})\cdot K[[x,y]]\subseteq (y-u)$ . This would also yield $y= y-u+u= y-u +x+\frac{1}{2}x^2 - \frac{1}{8}x^3 + \frac{1}{16}x^4 - \cdots=y-u +x(1+\frac{1}{2}x - \frac{1}{8}x^2 + \frac{1}{16}x^3 - \cdots)\in (y-u).$ Therefore, we would have $(x,y)\subseteq (y-u)$ and hence $(x,y)=(y-u)$ as $(x,y)$ is maximal in $K[[x,y]].$ But $$ K[[x]] \cong K[[x,y]]/(y-u) = K[[x,y]]/(x,y) \cong K $$ yields a contradiction. Thus, $(y-u)\cap K[x,y]_{(x,y)} \neq(x,y)K[x,y]_{(x,y)}$ and so we must have $(y^2 -x^3 -x^2)= (y-u)\cap K[x,y]_{(x,y)}$ . Finally, contracting back to $\operatorname{Spec}K[x,y]$ we have that $(y-u)\cap K[x,y]=(y^2 -x^3 -x^2)\cap K[x,y]=(y^2 -x^3 -x^2).$ My question: is my argument correct? If so, great. If not, could you explain why and what the correct answer is? For part (b) I don't know how to solve it and would appreciate any help with that.","['schemes', 'commutative-algebra', 'algebraic-geometry', 'proof-verification']"
1953364,What method should I apply to solve this differential equation?,"What method should I use to solve the following differential equation? $$\frac{dx}{dt}+x=\frac{dy}{dt}$$ Where $x,y$ are functions of $t\in[0,1].$ I know I should know how to do this, but it has been a while since I had to solve any ODE's.","['derivatives', 'real-analysis', 'ordinary-differential-equations']"
1953388,"Find all solutions of the equation $\sin x-\frac{6}{x}=0$ for $x\in[0,12\pi]$","I need to solve the equation $\sin x-\frac{6}{x}=0$ for $x\in[0,12\pi]$. I tried substituting $\sin x=\frac{e^{ix}-e^{-ix}}{2i}$ and solving the quadratic but it did not lead to anything. It has 10 solutions but I do not know how to get the exact values.",['trigonometry']
1953394,Lipschitz continuity and $l^1$ norm,"Let $f: \mathbb{R}^2 \to \mathbb{R}^2$ be a function defind as follows:
$$
f(x) = 
\begin{cases} 
  x,        & \|x\| \leq 1 \\ 
  x/ \|x\|, & \|x\| > 1 \end{cases}
$$
where $\| \cdot \|$ is the $l^1$ norm. Then it can be shown, that $\|f(x) - f(y)\| \leq 2\|x-y\|$. I need to prove, that $2$ cannot be improved. How can I do that?","['functional-analysis', 'normed-spaces', 'lipschitz-functions']"
1953424,Optimizing a matrix multiplication,"Given the following operation:
$$ \left(\begin{array}{c} f(1) \\ f(2) \\ \ldots \\ f(n)\end{array}\right) \begin{pmatrix} 1^{-1} & 1^0 & \cdots & 1^{n-2}\\ 2^{-1} & 2^0 & \cdots & 2^{n-2}\\ \vdots & \vdots & & \vdots \\ n^{-1} & n^0 & \cdots & n^{n-2}\end{pmatrix}$$ So a $n\times 1$ vector multiplied by a $n\times n$ matrix. As an example the $n=4$ matrix would be $$\begin{pmatrix} 1 & 1 & 1 & 1\\ 1/2 & 1 & 2 & 4 \\ 1/3 & 1 & 3 & 9 \\ 1/4 & 1 & 4 & 16\end{pmatrix}$$ I'm looking for anything I can take advantage of to reduce the complexity of this operation from $$O(n^2)$$ down to something better. Performing a Discrete Fourier Transform (DFT) for example uses the cyclic property of the exponential in a Fourier transform to reduce the operation. That doesn't apply here, since I am not using a sinusoid, but I'm wondering if there is anything that can achieve the same effect for this matrix.","['matrices', 'numerical-linear-algebra', 'fourier-transform']"
1953443,Unit square inside triangle. [duplicate],This question already has answers here : Smallest possible triangle to contain a square (2 answers) Closed 7 years ago . Some time ago I saw this beautiful problem and think it is worth to post it: Let $S$ be the area of triangle that covers a square of side $1$ . Prove that $S \ge 2$ .,"['geometric-inequalities', 'euclidean-geometry', 'triangles', 'geometry', 'area']"
1953518,Gradient of $\log(\det(AX))$,"How to calculate the gradient with respect to $A$ of $\log(\det(AX))$? Here, $X$ and $A$ are positive definite matrixes, and $\det$ is the determinant. How to calculate this? Or, what is the result? Thanks!","['derivatives', 'matrices', 'matrix-calculus', 'determinant', 'vector-analysis']"
1953519,The 'Square root' Function,"$G := \{f : f:[0,1] \rightarrow [0,1]$ such that it is bijective function  and strictly increasing } Now the question is For any $ h \in G,$does there exist $g \in G$ such that $h=g \circ g $? Is such a $g$, if it exist , unique? My observation : $G$ is a group under function composition.(Is it helpful?) Every function in $G$ is continuous. Conjecture: if $h \in G$ has $n \in \mathbb{N}$ fixed points in (0,1) then it has $n+1$ 'square root' functions.
Please help me to solve the question!","['real-analysis', 'functions']"
1953562,What arithmetic corresponds to minimal logic?,"Starting from classical logic (Peano arithmetic, PA ): Remove the law of excluded middle and we get intuitionistic logic (Heyting arithmetic, HA ) Remove the principle of explosion and we get minimal logic (but what arithmetic?)","['number-theory', 'logic', 'proof-theory']"
1953580,Why do convex and concave function have their own name like that not the opposite?,"Here is the definition for each kind of function https://i.sstatic.net/dMWb1.jpg And here is the definition for the words ""concave and convex"" in dictionary, with convex means curving out and concave means curving in. https://i.sstatic.net/99SkU.jpg In my logic, the convex function should be called concave func, and concave the opposite, because from the graph, I see a rumble strip bar, going up a little bit and down, like a concave function, but I think the rumble strip bar is described as ""convex"", here it's a little difficult for you to see my logic about it, but I don't understand why we call those function like that, not the opposite.
Sorry because i'm not in an English speaker country. Thanks for your explaination!","['convex-geometry', 'functions']"
1953593,"$|G|=p(p+1)$ for $p$ prime, then $G$ has a normal subgroup of order $p$ or $p+1$","I am trying to solve the above question, as an application of Sylow's theorem. 
Let $P$ be the p-Sylow subgroup. Then $n_p | (p+1)$ and $n_p \equiv 1 \pmod{p}$. If $n_p =1$, $P$ is normal and we are done, else $n_p = p+1$. Now, \begin{equation}
1+n_p(p-1) = 1 + (p+1)(p-1) = p^2,
\end{equation}
is the total number of elements in the p-Sylow subgroups.
So if $n_p = p+1$, that means the number of elements not in any p-Sylow subgroup is $|G|-p^2=p$. If these $p$ elements and the identity form a subgroup then its a subgroup of the smallest prime index, so we are done. But how do I show that all the elements not in the p-Sylow subgroups form a subgroup, i.e. the subgroup generated by these elements has trivial intersection with the $p-$Sylow subgroups?","['sylow-theory', 'group-theory']"
1953628,"$20$ people are sitting around a (circular) table. How many ways can we choose $3$ people, no two of whom are neighbors?","0 choices for the 1st person. 
17 choices for the 2nd person (must exclude 1st and his/her two neighbours) For 2 of these choices of 2nd person, there is one shared neighbour, so 15 remaining choices. (e.g. if they are numbered 1 to 20 in a circle, 1st person is #1, 2nd is #3, then people 20,1,2,3,4 are excluded). 
For the other 15 choices of 2nd person, there are no shared neighbors, so 14 remaining choices. So if order matters, total is $20 \cdot (2 \cdot 15 + 15 \cdot 14) $
but since order does not matter, divide by $3! = 6$ to account for the permutations in order of the 3 people. 
So total = $20 \cdot \frac{2 \cdot 15 + 15 \cdot 14}{6}$ just redid it; does this make any sense?",['combinatorics']
1953633,Asymptotic evaluation of $\int_0^{\pi/4}\cos(x t^2)\tan^2(t)dt$,"In Bender-Orszag's Advanced Mathematical Methods for Scientists and Engineers on page 313 we encounter the following integral $$
I(x)=\int_0^{\pi/4}\cos(x t^2)\tan^2(t)dt
$$ and it is asked to derive the first two terms of the asymptotic expansion of $I(x)$ as $x\rightarrow +\infty$ . Setting $x=i y$ and analytically continuing at the end of the calcultion I was able to show that $$
I(x)\sim 2\frac{\sin(\frac{x\pi^2}{16})}{\pi x}+\mathcal{O}(x^{-2})
$$ using standard Laplace method. Despite the fact that this seems to fit comparsion with numerical data, I am not satisfied by this approach for three reasons: 1) It is quiet cumbersome (at least for me) to derive higher order terms with my method. Is there a fast way to do so? 2) The question can be found in relation with ""Method of steepest descent"" so I suppose one should attack it by this method. How can it be applied? I somehow fail here 3) I am not totally satisfied by my analytic continuation argument. How can this made rigourous? I am grateful to anyone who can shed light on any of my questions!","['complex-analysis', 'integration', 'asymptotics', 'contour-integration']"
1953645,Zeta function of smooth conic?,Let $k$ be a finite field of characteristic different from $2$. Let $X = V(x^2 + y^2 + z^2) \subset \mathbb{P}_k^2$ be the smooth conic. What is the zeta function of $X$?,"['number-theory', 'arithmetic-geometry', 'zeta-functions', 'algebraic-geometry']"
1953651,Difference between line integral and Lebesgue integral over set containing the line in $\mathbb{R}^2$,"It has been awhile since I last did any vector calculus, but this question got me thinking about line integrals and how they differ from Lebesgue integrals over sets containing the line. Considering the function given in the linked post,
$$ f(x,y)=\begin{cases} xy \ \ \text{if}\ \  x=y\\
0 \ \ \ \ \text{if}\ \ x\neq y\end{cases}$$
 suppose we want to calculate the line integral of $f$ along the line $x=y$ from $(0,0)$ to $(1,1)$, call the curve $\Gamma$. We can use standard techniques to find that the answer is given by
\begin{align*}
\int_\Gamma f(x,y)ds & =\sqrt2\int_0^1t^2dt \\
& =\frac{\sqrt{2}}{3}.
\end{align*} Now the Lebesgue integral in the linked post is
$$\int_Afd\mu$$
where $A$ is the unit square $[0,1]\times[0,1]$ in $\mathbb{R}^2$. Now I understand that because the measure of the subset of $A$ on which is $f$ is non-zero is $0$ the integral is $0$, but in some way I can't help thinking that this is equivalent to integrating the function $f(x,y)=xy$ over the line $\Gamma$. Obviously this is not the case, but I don't really understand why as I'm quite a novice when it comes to measure theory. If someone could explain where my intuition is going wrong I'd be very appreciative. EDIT: Levap's brilliant answer aided me in coming up with an intuitive feeling for why the 2 are different. The line integral can intuitively thought to be the ""area"" of the function under the curve. If the curve is non-zero and not symmetric obviously the area will also be non-zero. The general integral (Riemann or Lebesgue) over a subset of $\mathbb{R}^2$ can intuitively thought to be the volume underneath the function over an area in $\mathbb{R^2}$. However, as function is only non-zero underneath a one-dimensional line the integral is actually giving the volume underneath a line, which is obviously $0$ because one of the values for the three ""dimensions"" used to calculate volume is $0$. This corresponds nicely with the standard Lebesgue measure in $\mathbb{R^2}$ of a line being $0$.","['integration', 'lebesgue-integral', 'measure-theory', 'line-integrals']"
1953658,Finding $\det(B)$ in terms of $\det(A) $ for matrices $A$ and $B$,"Q: Let the rows of $A \in M_{n \hspace{1mm}\mathbb x \hspace{1mm}n }$ ( $\mathbb F)$ be $a_1,a_2,...,a_n$ , and let $B$ be the matrix in which the rows are $a_n,a_{n-1} ,...,a_1$ . Calculate $\det(B)$ in terms of $\det(A)$ . A: $\det(B) = (-1)^{\frac{n(n-1)}{2}}\det(A)$ . I thought of applying row interchange but in doing so I can't see how I can derive te desired result as given above. Any suggestions as to how I can approach this question?","['matrices', 'linear-algebra']"
1953690,"Let $S = \{1,2,3,4\}$. How many nonstrict monotonic increasing functions $f:S\to S$ are there?","Let $S = \{1,2,3,4\}$. Let $f:S\to S$ be a function such that $f(x) \le f(y)$ if $x<y$. How many such $f$ are there? How should I proceed? $f(1)$ has $4$ choices. But the number of possible values of $f(2)$ depends on $f(1)$. For example, if $f(1) =1$ then $f(2)$ can be $1,2,3,4$. But if $f(1)=2$, then $f(2)$ cannot be $1$.","['combinatorics', 'discrete-mathematics']"
1953724,Show that for every $\epsilon>0$ there exists a dense open subset $V$ of $\mathbb{R}$ such $m(V) = \epsilon$.,"I need to show that for every $\epsilon>0$ there exists a dense open subset $V$ of $\mathbb{R}$ such $m(V)=\epsilon$ . Here, $m$ is the Lebesgue measure. Prior to this, I showed that for every $\epsilon>0$ there exists a dense open subset $U$ of $\mathbb{R}$ such $m(U) \le \epsilon$ . I showed the latter statement by taking $U$ to be the union of the open intervals $I_{n}=(a_{n}-\frac{\epsilon}{2^{n+2}}, a_{n}+\frac{\epsilon}{2^{n+2}})$ . Then $m(U)=m(\cup I_{n}) \le \sum m(O_{n})=\frac{\epsilon}{2}<\epsilon$ . However, I don't know how to prove the first statement. Any hints?",['measure-theory']
1953736,Show that for any arc length parameterized curve there is a vector $Ï‰(s)$ that satisfies the following equations,"I'm trying to solve the following question Show that for any arc length parameterized curve there is a vector
  $Ï‰(s)$ that satisfies $$T'(s) = Ï‰(s) Ã— T (s)$$ $$N'(s) = Ï‰(s) Ã— N(s)$$ $$B'(s) = Ï‰(s) Ã—
> B(s)$$ HINT: Consider $Ï‰(s) = a(s)T (s) +b(s)N(s) +c(s)B(s)$ (where $T$, $N$,
  $B$ are the unit tangent, normal and binormal vectors) and find the
  coefficients $a$, $b$, $c$ that work. I managed to get 
$$a(s) = T(s) \cdot Ï‰(s)$$
$$b(s) = N(s) \cdot Ï‰(s)$$
$$c(s) = B(s) \cdot Ï‰(s)$$ But I don't know how to proceed from this. What direction should I be going in.","['differential-geometry', 'vectors', 'vector-analysis']"
1953768,Explicit formula for higher order derivatives in higher dimensions,"Let $f:\mathbb{R}^n\to\mathbb{R}^m$ be a function at least $C^k$ and fix some point $x_0\in\mathbb{R}^n$. I want an explicit formula for its derivatives of higher order. I already read this threads: What are higher derivatives? Using higher order derivatives One thing is clear, $D^kf(x_0)$ is a $k$-linear map from $\underbrace{\mathbb{R}^n\times\ldots\times\mathbb{R}^n}_{k \text{ times}}$ to $\mathbb{R}^m$. Yet, the answers given do not address my question, they only give the abstract description but I want a concrete description. For $k=1$ we have that $Df(x_0)v = [Df(x_0)]\cdot v$, where $ [Df(x_0)] = \left(\frac{\partial f_i(x_0)}{\partial x_j}\right)$ stands for the Jacobian matrix of $Df(x_0)$. So we have an explicit formula. For $k\geq 2$, it's not clear how to get an explicit formula for $D^kf(x_0)(v_1,\ldots,v_k)$ from the definition and the case $k=1$. There must be some way to do this. I hope you can help me. Thank you very much.","['multivariable-calculus', 'multilinear-algebra', 'derivatives']"
1953769,Expectation of summation squared,"I'm studying the Rayleigh distribution given by
$$ f_v(x) = \frac{x}{v} \ \exp(-\frac{x^2}{2v}) \ \mathbb{1}\{x \geq 0\}$$ and found an estimator (using method of moments) to be
$$ \tilde{v} = \frac{2}{\pi n^2} \left(\sum_{i=1}^{n} X_i \right)^2$$ Now I want to know whether it's biased or not, but I get stuck when I try to compute the expectation of $\tilde{v}$. I have
$$ \mathbb{E}[\tilde{v}] = \frac{2}{\pi n^2} \mathbb{E}\left[\left(\sum_{i=1}^{n} X_i \right)^2\right]$$ I tried stating that $\mathbb{E}[X] = \frac{1}{n}\sum_{i=1}^{n} X_i$, which yields $\left(\sum_{i=1}^{n} X_i \right)^2 = n^2 \mathbb{E}[X]^2$ and an unbiased estimator. However, that seems wrong, as that statement is exactly what I used to get the estimator in the first place, so it seems like I'm reasoning in circles here. Is it wrong? If so, how else could I get the bias? Thanks in advance!","['statistics', 'expectation', 'parameter-estimation']"
1953830,How can I guess particular solution of a Riccati differential equation?,I am given the two following differential equations. $$y'=6+5y+y^2$$ $$y'=9+6y+y^2$$ I have learned how to solve one with a given particular solution but cannot seem to get my head around this. I need help with guessing the particular solution of both of these.,['ordinary-differential-equations']
1953833,How does topology on a space relate to differentiation?,"I read in Chapter 1 of Lee's Introduction to Smooth Manifolds that there's no way to define a purely topological property that would serve as a criterion for smoothness. So, I tried to think about the meaning of this sentence and I couldn't really link topology to differentiation! I mean derivatives of functions are defined on open domains, and openness is a topological abstract concept. But how are the two related? I mean assume that I change the topology of the real line from the Euclidean metric to some other topology. For example, discrete topology or the topology generated by half-open intervals $[a,b)$. How will the notion of differentiation change then? I assume we have to study functions defined on $\mathbb{R}$ to answer this. So, some examples of functions that are differentiable with respect to the Euclidean topology but fail to be differentiable in some other topology or vice versa are appreciated.","['manifolds', 'general-topology', 'differential-topology']"
1953843,What will be the value of the following determinant without expanding it?,"$$\begin{vmatrix}a^2 & (a+1)^2 & (a+2)^2 & (a+3)^2 \\ b^2 & (b+1)^2 & (b+2)^2 & (b+3)^2 \\ c^2 & (c+1)^2 & (c+2)^2 & (c+3)^2 \\ d^2 & (d+1)^2 & (d+2)^2 & (d+3)^2\end{vmatrix} $$ I tried many column operations, mainly subtractions without any success.","['linear-algebra', 'determinant']"
1953865,Prove that the perimeter of any quadrilateral is greater than twice the length of any of its diagonal,"I am stuck with the following problem that says : Prove that the perimeter of any quadrilateral is greater than twice the length of any of its diagonal. My try: 
........ For any quadrilateral $ABCD\,,$ we can easily prove that 
$$AB+BC+CD+DA \gt AC+BD......\tag{1}$$ Now, three cases arise. Either, $$AC=BD\,\,or AC \gt BD\,\, or  AC \lt BD$$. If $AC=BD$,then the result follows from (1). If $AC \gt BD \implies AC+BD \gt 2BD $  and then the result follows from (1). If $ BD \gt AC \implies AC+BD \gt 2AC $  and then the result follows from (1). Can someone take some time to check if I made any mistake or is there any better way to tackle the problem. Thanks in advance for your time.","['quadrilateral', 'geometry']"
1953879,"$\text{null}\,T^k\subsetneq\text{null}\,T^{k+1}$ and $\text{range}\,T^k\supsetneq\text{range}\,T^{k+1}$ for all $k\in\mathbb{N}$","Let $V$ be a vector space over $\mathbb{F}=\mathbb R$ or $\mathbb C$ and $T$ an operator on $V$. It is well known that $$\forall k\in\mathbb{N},\,\text{null}\,T^k\subseteq\text{null}\,T^{k+1}\,\land\,\text{range}\,T^{k+1}\supseteq\text{range}\,T^k$$ Exercise $21$ page $251$ in Sheldon Axler's Linear Algebra Done Right is: Find a vector space $W$ and $T\in\mathcal{L}(W)$ sich that $\text{null}\,T^k\subsetneq\text{null}\,T^{k+1}$ and $\text{range}\,T^k\supsetneq\text{range}\,T^{k+1}$ for every positive integer $k$. It is well known that if $\dim V=n$ is finite then $$\text{null}\,T^n=\text{null}\,T^{n+1}=\text{null}\,T^{n+2}=\cdots$$ and that $$\text{range}\,T^n=\text{range}\,T^{n+1}=\text{range}\,T^{n+2}=\cdots$$ Therefore we must choose an infinite dimensional vector space. I chose $W=\mathbb{F}^\infty$ the set of all sequences $(a_1,a_2,\cdots)$ over $\mathbb F$. Consider $\mathcal{B_c}=\{e_1,e_2,\cdots\}$ its canonical basis. When we define $T$ such as $T(a_1,a_2,\cdots)=(a_2,a_3,\cdots)$ we have $\forall k\in\mathbb{N}\backslash\{0\},\,\text{null}\,T^k=\text{span}\{e_1,\cdots,e_k\}\,\land\,\text{range}\,T^k=\mathbb F^\infty$, which satisfies only one condition. On the other hand, defining $T$ by $T(a_1,a_2,\cdots)=(0,a_1,a_2,\cdots)$ gives $\text{null}\,T^k=\{0\}\,\land\,\text{range}\,T^k=\text{span}\{e_{k+1},e_{k+2},\cdots\}$, $T$ satisfies the other. Projections are no good as $T=T^2$ and I tried some few other examples but I couldn't find a good one. The idea I kept in mind while looking for an example is that as we move on from $T^k$ to $T^{k+1}$, one vector is ""transported"" from $\text{range}\,T^k$ to  $\text{null}\,T^k$. Unfortunately, I failed to find such an operator. Could you please provide me with some examples?","['linear-algebra', 'linear-transformations']"
1953892,Projection of closed convex sets,"I have a simply formulated geometric question that I was not able to find an answer to. Any help/references/conjectures on the topic will be highly appreciated. Let us consider two convex closed sets in a Euclidean space. Assume they have non-empty intersection. Let us consider a projection that transforms both sets to some subspace of a smaller dimension. When is the projection of the intersection of two closed convex sets coincides with the intersection of projections? One trivial answer when this is the case for any possible projector operator is when union of the two sets is also convex. Unfortunately, this answer is not sufficient for my applications (for mathematical economics). My applications consider two specific convex closed sets (one is polyhedron, the other is a cone) and a specific projection operator. I want to understand/derive some intuitive sufficient conditions on both sets and the projection operator that guarantee that the projections of the intersection equal the intersection of projections. Any help would be appreciated. Thank you, Alex","['convex-analysis', 'geometry']"
1953900,How to prove that $\mathrm{SL}_{2} (\mathbb F_{3})$ is not isomorphic to $S_{4}$?,"How to prove that $\mathrm{SL}_{2} (\mathbb F_{3})$ is not isomorphic to $S_{4}$?
They are both group of order $24$ and both groups have elements of order $2, 3$ and $4$.
I don't know how to work from here.","['linear-groups', 'abstract-algebra', 'group-isomorphism', 'group-theory', 'symmetric-groups']"
1953903,"If $\mathfrak{Y}$ is a closed subspace of a reflexive Banach space $\mathfrak{X}$, then is $\mathfrak{Y}$ reflexive too?","Exercise 2.4.8 in Analysis Now by Pedersen: If $\mathfrak{Y}$ is a closed subspace of a reflexive Banach space $\mathfrak{X}$, show that $\mathfrak{Y}$ and $\mathfrak{X}/\mathfrak{Y}$ are reflexive using the following theorem: 2.4.13. Proposition. Consider a closed subspace $\mathfrak{Y}$ of a normed space $\mathfrak{X}$. Let $I:\mathfrak{Y}\to \mathfrak{X}$ denote the inclusion map and $Q:\mathfrak{X}\to\mathfrak{X}/\mathfrak{Y}$ denote the quotient map. Then we may identify $Q^\ast$ with the inclusion map of $\mathfrak{Y}^\perp$ into $\mathfrak{X}^\ast$ and $I^\ast$ with the quotient map of $\mathfrak{X}^\ast$ onto $\mathfrak{X}^\ast/\mathfrak{Y}^\perp$.","['functional-analysis', 'topological-vector-spaces', 'alternative-proof', 'analysis']"
1953910,Hellinger-Toeplitz Theorem and Uniform Boundedness Principle [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question The question is prove the Hellinger-Toeplitz theorem, using the uniform boundedness principle. All hints are welcome",['functional-analysis']
1953920,"Partial differential equation $[\partial_t + v(x)\partial_x - \rho(x)] D(t,x) = 0$","I'm stuck with the following problem I found (without a proof) in the Peskin and Schroeder textbook on quantum field theory (the differential equation mentioned below is equivalent to the Callan-Symanzik equation describing the evolution of the n-point correlation functions under variation of the energy scale at which the theory is defined): Show that the solution of the equation
$$
[\partial_t + v(x)\partial_x - \rho(x)] D(t,x) = 0
$$
has the form
$$
D(t,x) = D(0,X_t(x)) \exp\left(\int_0^t d t' \rho(X_{t'}(x)) \right),
$$
where $X_t(x)$ is the solution of the equation
$$
\partial_t X_t(x) = - v(X_t(x))
$$
with the initial condition
$$
X_0(x) = x.
$$ Let's compute e.g. $$
\partial_t \left[D(0,X_t(x)) \exp\left(\int_0^t d t' \rho(X_{t'}(x)) \right) \right]= \left[\partial_t D(0,X_t(x))\right] \exp\left(\int_0^t d t' \rho(X_{t'}(x)) \right)  + D(0,X_t(x)) \rho(X_t(x)) \exp\left(\int_0^t d t' \rho(X_{t'}(x)) \right) 
$$ I don't see any possible simplifications with other terms. I wonder how to show that the solution of the mentioned differential equation is indeed of the above form.","['partial-derivative', 'ordinary-differential-equations', 'mathematical-physics', 'partial-differential-equations']"
1953935,Least upper bound property implies Cauchy completeness,"Given an ordered field $F$, the following two statements are equivalent: $F$ has the Least-Upper-Bound property. $F$ is Archimedean and $F$ is ""sequentially complete""/""Cauchy complete"" (all Cauchy sequences in $F$ converge). For some reason I have been unable to find a proof of this result on the web.","['real-analysis', 'real-numbers', 'ordered-fields']"
1953964,Does there exist $\alpha \in \mathbb{R}$ and a field $F \subset \mathbb{R} $ such that $F(\alpha)=\mathbb{R}$?,"I was thinking what would be the opposite of a field extension and I suppose it might be this: A field $F$ can have the element $\alpha$ deleted if there exists a subfield $E=F$ such that $E(\alpha)=F$. You might call $F\setminus(\alpha)$ something like a deletion. The thing about this is that you can then undo any field extension. That is, $F(\alpha) \setminus (\alpha)=F$. Does this concept have a name? So naturally, I am wondering if any elements can be ""deleted"" in this manner from $\mathbb{R}$. I realized that for $\alpha=\sqrt{2}$, there is no such field $E$ such that $E(\alpha)=\mathbb{R}$. If there was, there would be $a,b \in E$ such that $2^{1/4}=a+b\sqrt{2}$ as $\mathbb{R}$ is an extension of $E$ and the fourth root is in $\mathbb{R}$. Squaring, and with some algebra (being careful with avoiding division by zero), one gets the contradiction that $\sqrt{2} \in E$. I haven't thought this through carefully, but I believe for any algebraic number we have a similar failure. That is, there is a polynomial of degree $n$, $p \in E(x)$, with $p(\alpha)=0$. Then in particular $\alpha^{1/k} = p_k(\alpha)$ for $p_k$ of degree $n$. Raising to the $k$th power we get $\alpha = q_k(\alpha)$ for $q_k$ polynomial of degree $n$. This gives a linear system in $\alpha^k$ and my hunch it is nonsingular or the singular cases can be dealt with. The above is for algebraic numbers. I think the above can be used to show, for instance, that $\pi$ cannot work as it is likely algebraic over $E$ as $E$ contains many transcendental numbers. This is much more murky to me but makes me think that there is no element you can delete from $\mathbb{R}$. So my question: Does there exist $\alpha \in \mathbb{R} \setminus \mathbb{Q}$ and a field $F \subset \mathbb{R}$ such that $F(\alpha)=\mathbb{R}$? More specifically, I want $F$ with $\alpha \notin F$.","['abstract-algebra', 'transcendental-numbers', 'extension-field', 'field-theory']"
1953966,Why take the dual cone when constructing toric variety?,I am reading an introduction to toric varieties. I don't understand why we are taking the monoid associated to the dual cone instead of simply taking the monoid associated to the cone. Is there any conceptual/pratical reason to do this ?,"['toric-varieties', 'algebraic-geometry', 'toric-geometry']"
1954042,Finding the sum $\frac{x}{x+1} + \frac{2x^2}{x^2+1} + \frac{4x^4}{x^4+1} + \cdots$,"Suppose $|x| < 1$. Can you give any ideas on how to find the following sum?
$$
\frac{x}{x+1} + \frac{2x^2}{x^2+1} + \frac{4x^4}{x^4+1} + \frac{8x^8}{x^8+1} + \cdots
$$","['power-series', 'summation', 'sequences-and-series', 'calculus']"
1954044,Convergence of Riemann Zeta Function for Normed Arguments,"My question is concerned with the convergence of the sum $$\displaystyle \sum_{\substack{\ \ m \in \mathbb{Z}^d} \\ {\ \  \ m \neq 0}} \frac{1}{\|m\|_{d}^s},$$ where $d \in \mathbb{N}$, and $\|m\|_d := \sqrt{|m_1|^2 + ... + |m_d|^2}$ denotes the usual Euclidean norm on $\mathbb{R}^d$. Is it true that this sum converges whenever $\mathrm{Re}(s) > d$? Obviously, when $d = 1$, we get the usual definition of the Riemann zeta function, which we know converges for $\mathrm{Re}(s) > 1$ and admits an analytic continuation to the rest of the complex plane. The convergence of similar sums has been investigated -- for instance, see this question on the convergence of the Riemann zeta function in higher dimensions, and there are similar results out there for modified zeta functions such as the so-called Barnes zeta function . These two results intuitively seem to suggest that one might expect the sum to converge for $\mathrm{Re}(s) > d$. Mathematica does not seem to be able to deal with the sum for $d \geqslant 2$. Can anyone confirm if this is true (or if it is false, provide conditions under which this sum does converge)? Moreover, does anyone know of any reference where this question has been discussed?","['real-analysis', 'analytic-number-theory', 'reference-request', 'number-theory', 'riemann-zeta']"
1954047,"If a sequence of measurable functions converges to $f_âˆ—$ a.e. and to $g_âˆ—$ in metric, then $f_* = g_*$ a.e.?","Let $X$ be the space of all measurable functions $f: \Omega \to \mathbb{R}$ from $\Omega \subseteq \mathbb{R}^n$ to $\mathbb{R}$ and $(X,d)$ be a metric space with the metric $d:X \times X \to \mathbb{R}$. Suppose that $\{f_j \in X\}_{j=1}^\infty$ be a sequence that converges to some function $f_*$ a.e. and at the same time converges to $g_* \in X$ in metric $d$, i.e., 
\begin{equation}
   \lim_{j \to \infty} d(f_j,g_*) = 0.
\end{equation}
Then, can we conclude that both types of convergence have the a.e. same limit point, i.e., $f_* = g_*$ a.e.? I know that if $d$ is induced from $L^p$-norm ($1 \leq p< \infty$):
\begin{equation}
   d(f,g) := \Big ( \int_\Omega |f(x) - g(x)|^p \; d\mu(x) \Big )^{1/p},
\end{equation}
where $\mu$ is a measure on (a $\sigma$-algebra of) $\Omega$, then there is a subsequence $f_{j_n}$ that converges to $g_*$ a.e., and by the a.e. convergence $f_j \to f_*$, it is true that $f_* = g_*$ a.e.. Some related post for $p = 2$: Can a sequence of functions converge to different functions pointwise and on average? In my post here, however, I am seeking the general answer, where the metric $d$ is not a form of $L^p$-norm, but just arbitrarily given. Can you give a counter-example if it is not true? Or, can you give a specific required condition or form (perhaps on the metric $d$) for $f_* = g_*$ a.e. to be true? For your reference, this post is the general and refined version of the statement ( If a sequence of continuous functions converges to $f_*$ pointwisely and to $g_*$ in metric, then $f_* = g_*$? ) I previously posted, which turns out to be trivially NOT TRUE.","['real-analysis', 'functional-analysis', 'general-topology', 'metric-spaces', 'convergence-divergence']"
1954069,Finding length of a side to make two other sides perpendicular,"I am trying to solve this problem but the steps are not so obvious to me. So to my understanding, if $CD\perp AB$ means that $\triangle ADC$ and $\triangle BDC$ will be right triangles but I do not know how to progress from that.",['geometry']
1954070,"Finding that a two variable limit does not exist trouble: $\lim_{(x, y) \to (0, 0)} \frac{y^2 \sin^2 x}{x^4 + y^4}$ [duplicate]","This question already has an answer here : How to evaluate $ \lim_{(x,y)\to(0,0)}\frac{y^2\sin^2x}{x^4+y^4} $ (1 answer) Closed 3 years ago . I have $$ \lim_{(x, y) \to (0, 0)} \frac{y^2 \sin^2 x}{x^4 + y^4} $$ I've tried setting $y= 0, x=0, y=mx, y=x$, and lots of other things but because of the $\sin$ I keep getting a limit of zero. How do you show this doesn't exist?","['multivariable-calculus', 'limits']"
1954108,cardinality of the Borel $\sigma$-algebra of a second countable space,"Second countability by itself doesn't restrict the cardinality of a topological space, since every set with the trivial topology is a second countable space, but it seems natural to ask whether second countability restricts the cardinality of the Borel $\sigma$-algebra of the space. Can the cardinality of the Borel $\sigma$-algebra of a second countable space be arbitrarily big? If this is the case is there a simple construction for a second countable space with an arbitrarily big Borel $\sigma$-algebra?","['general-topology', 'second-countable', 'measure-theory']"
1954167,Do positive semidefinite matrices have to be symmetric?,"Do positive semidefinite matrices have to be symmetric? Can you have a non-symmetric matrix that is positive definite? I can't seem to figure out why you wouldn't be able to have such a matrix, but all my notes specify positive definite matrices as ""symmetric $n \times n$ matrices."" Can anyone help me with an example of a non-symmetric positive definite matrix, or some insight into a proof for why it would need to be symmetric should that be the case? Thanks!","['matrices', 'positive-definite', 'symmetric-matrices', 'positive-semidefinite', 'linear-algebra']"
1954214,Greatest open ball in the unit $n$-cell,"Let $n\geq2$ be an integer, let $C=[-1,1]^n$ and let $A$ be the set of all real numbers $r$ such that $r$ is the radius of some open ball $V$ such that $V$ is contained in $C$ and $V$ is disjoint to the open ball whose center is $\bf 0$ and radius is $1.$ Find $\sup A.$ I think the problem of finding $y=\sup A$ (without proof) isn't very difficult, because we can look at the case when $n=2$ and then ""generalize"" (graphically and using the pythagorean theorem and to generalize, we use the pythagorean theorem in $n$ dimensions). I found that $y=(\sqrt n-1)/(\sqrt n +1)$ I intituively see that a point $x$ (there are exactly $2^n$ such points) at which we can center an open ball $V$ of radius $y$ such that $V\subseteq C$ and $V\cap B(\mathbf{0},1)=\varnothing$ belongs to the line connecting the vector $\bf 0$ and the vector $\bf 1$, all of whose coordinates are $1.$  Thus $x=t\mathbf{1}$ for some real $0<t<1$ and also $|x|>1$ (because $x\notin B(\mathbf{0},1)$ and also $x$ must be an interior point of the complement of this ball). But then I don't know what to do. I would like to be as rigorous as possible. Thank you for any help.","['general-topology', 'real-analysis', 'metric-spaces']"
1954221,Proving the Product of Unitary Matrices is also Unitary,"This is my attempt so far:
Suppose I have two unitary matrices, A and B, such that $A^*A=I$ and $B^*B=I$. We want to show that $(AB)^*(AB)=I$. So we have that
$$(AB)^*(AB)=B^*A^*AB=B^*IB=I.$$
Does this work as a proof? Do I need to show anything else?",['linear-algebra']
1954248,Best way to learn maths - proofs or exercises? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 7 years ago . Improve this question My question is regarding the most effective way to learn maths? Should one concentrate on churning through the exercises or is it better to concentrate on understanding and reproducing the proofs? I understand that ideally one would do both however my time is limited, (father of two children under 3, run a small business, full course load). I am in the first year of doing a mathematics degree an am struggling. I go to the lectures religiously and ask question, however more often than not I leave not fully understanding the subject matter. I usually end up poring over the textbooks, scouring the internet or harassing the teaching assistants till I understand, but this eats into the time I have left to do the exercises and review the proofs. Any advice or insights gratefully accepted!","['learning', 'linear-algebra', 'calculus']"
1954273,Explicit example of non constant linear functional $f: \mathbb R \to \mathbb Q$?,Recall that $V=\mathbb R$ is a uncountably dimension vector space over $\mathbb Q$ as countable dimension vector space over $\mathbb Q$ is itself countable. Is there any explicit example of a non constant linear functional $f: \mathbb R \to \mathbb Q$ ? Existence of such linear functional is almost trivial but can we give the explicit example of such $1$-form? Also it is clear that under usual topology such a map $f$ cannot be continuous as $\mathbb Q$ is totally disconnected.,"['linear-algebra', 'linear-transformations', 'vector-spaces']"
1954278,"How does one prove $\int_0^\infty \frac{\log(x)}{1 + e^{ax}} \, dx = -\frac{\log(2)(2\log(a) + \log(2))}{2a}$ for $a > 0$?","Link to WolframAlpha's assertion . Here's my attempt. Using the substitution $t = ax$, we can show the integral is equal to 
$$ \frac{1}{a} \int_0^\infty \frac{\log(t)}{1 + e^t}\, dt -\frac{\log(a)}{a} \int_0^\infty \frac{dt}{1 + e^{t} } .$$ The second integral is equal to $\log(2)$ using another substitution $v = e^t$ and partial fractions. So I'm left with the first integral. I'll switch to complex variables for notation. I make two observations: (I) The denominator has simple poles when $z = t = (2k-1)\cdot i \pi, \, k \in \mathbb{N}.$ (II) The numerator has a branch point $z = 0$.","['real-analysis', 'complex-analysis', 'integration', 'definite-integrals', 'power-series']"
1954313,Homology of $S^n-$(Topologist's Sine curve)?,"I'm self-studying Munkres' ""Elements of Algebraic Topology"". And I'm thinking Section36 Exercise #2 and looking for hints or solution. Here it goes, Section36 Exercise#2 Let $$Y=\{0\}\times [-1,1]\bigcup\{(x,\sin{\frac{1}{x}})\colon x\in(0,1]\}$$ $$Z=\textit{Union of }\space Y\textit{ and an arc that intersects }Y\textit{ only in the points }(0,-1)\textit{ and }(1,\sin{1})$$ Then, verify following statements (a) If $h\colon Y\rightarrow S^n$ is an imbedding, then $S^n-h(Y)$ is acyclic.(i.e, every reduced singular homology group is trivial.) (b) If $h\colon Z\rightarrow S^n$ is an imbedding, then reduced singular homology group $\widetilde{H}_i(S^n-h(Z))$ is infinite cyclic if $i=n-2$ , and vanishes otherwise. (c) If $h\colon Z\rightarrow S^2$ is an imbedding, then $S^n-h(Z)$ has precisely two components, of which $h(Z)$ is the common boundary How can I approach these three problems? -It seems above exercises are all somehow related to Jordan curve theorem and its related theorem.(anyhow, Section36 is about Jordan curve theorem). However, $Y$ is not homeomorphic to $[0,1]$ and $Z$ is not homeomorphic to $S^1$ . So we cannot directly apply those theorems to here. Thanks for any help in advance.","['algebraic-topology', 'general-topology', 'homology-cohomology']"
1954346,"If we have a full rank positive semi-definite symmetric matrix, will any square partition be full rank as well?","Suppose we have a matrix of $n$ by $n$ dimension $M$ is that is full rank , symmetric, and positive semi-definite , in that $z^TMz \geq 0$ for all $z \in \mathbb{R}^p$. This can be thought of as a covariance matrix in statistics. If I were to take a square partition, would that square partition still be full rank? In example, suppose that: $$
M = \begin{pmatrix}
a_{11} \ldots a_{1n}\\
\ldots\\
a_{n1} \ldots a_{nn}\\
\end{pmatrix}
$$ Then a square partition might be: $$
M_{33} = \begin{pmatrix}
a_{33} \ldots a_{3n}\\
\ldots\\
a_{n3} \ldots a_{nn}\\
\end{pmatrix}
$$ Where I took the bottom right side of the original matrix $M$. Would this be full-rank as well?","['statistics', 'linear-algebra']"
1954350,How to calculate gradient for vector function,"I just want to calculate the gradient of $$f(x)=\frac{||Ax-b||_2^2}{c^Tx+d}$$ where $x,b\in R^n,A\in R^{n\times n},c,d\in R$. I guess the value should be like
$$\nabla f(x)=(2A^T(Ax-b)(c^Tx+d)-c||Ax-b||_2^2)/(c^Tx+d)^2$$
By viewing x as scalar and do the calculation, and finally consider about the dimension of each variable. However, I want to know how exactly to do this. I also notice a lot of rules for scalar has a analogous form for vector also. Is there a formula list for this or a conclusion/theorem about this? It would be awesome if someone can share me this. Thanks.","['multivariable-calculus', 'gradient-descent', 'calculus', 'vector-analysis']"
1954394,Show that $S$ is non-orientable,"Let $S$ be a regular surface covered by coordinate neighborhoods $V_1$ and $V_2$. Assume that $V_1\cap V_2$ has two connected components, $W_1$, $W_2$, and that the Jacobian of the change of coordinates is positive in $W_1$ and negative in $W_2$. Show that $S$ is non-orientable. I know that, if a regular surface $S$, can be covered by two coordinate neighborhoods, whose intersection is connected, then the surface is orientable. Furthermore, if $f:S\subset\mathbb{R}^3\to\mathbb{R}$ is a continuous function, in a connected surface $S$, then $f$ doesn't change of sign on $S$. Can give any hint! Thanks!",['differential-geometry']
1954423,Obtain different answers if we change the order of integration,"In Wolfram alpha, it gives us $$\int_0^1 \int_0^1 \frac{x-y}{(x+y)^3} dydx=\frac{1}{2}$$
$$\int_0^1 \int_0^1 \frac{x-y}{(x+y)^3} dxdy=-\frac{1}{2}$$ Why do we have two different answers if we perform the order of integration differently? I tried to look up the Fubini's theorem condition, but to no avail. Because the integral above satisfies Fubini's theorem. Did I miss up something?","['multivariable-calculus', 'multiple-integral']"
1954425,Simplifying $\frac{\;\frac{x}{1-x}+\frac{1+x}{x}\;}{\frac{1-x}{x}+\frac{x}{1+x}}$,"$$\frac{\;\;\dfrac{x}{1-x}+\dfrac{1+x}{x}\;\;}{\dfrac{1-x}{x}+\dfrac{x}{1+x}}$$ I can simplify this using the slow way ---adding the numerator and denominator, and then dividing--- but my teacher told me there is another way. Any help?","['algebra-precalculus', 'fractions']"
1954455,Simplifying nested fractions,No juicy title this time :( $$1+\dfrac1{1+{\dfrac1{1+\dfrac1{1+\dfrac1x}}}}$$ Is there a special trick for solving this type of problem?,"['algebra-precalculus', 'fractions']"
1954467,Associanize a magma,"This is a thing I have been thinking on and gotten a bit frustrated so I share my thoughts here in hope for clarification. Let $M$ be a magma, that is a set with an underlying binary operation which we denote $\cdot$. The binary operation is not necessarily associative, that is we do not necessarily have 
$$a\cdot (b\cdot c)=(a\cdot b)\cdot c$$
Here is the issue at hand, in group theory we can ""make"" a group abelian by taking the quotient with its commutator subgrouop, $G/[G,G]$, which is abelian, I am wondering if there is something similar for magmas but for associativity. Of course having dealt with universal algebra, semirings and semigroups (which is the target here in a way) what I need to work with is a relation, more specificly a congruence relation so I figured I would start defining it as such. So I started by saying that $e \mathrel{R} f$, or $(e,f)\in R$, if there exists some $a,b,c\in M$ such that $(a\cdot b)\cdot c = e$ and $a\cdot (b\cdot c) = f$, seemed like a good place to start for me in my quest, only that I realized that there is not necessarily a unit in a magma so we do not have $x \mathrel{R} x$ which is a requirement, well let's just throw those in too then I thought. Which is the reflexive closure of $R$, that is $\text{Cl}_\text{ref}(R)$ from before. Next I thought about transitivity which is required and I got absolutely nowhere there in my attempts primarily because I could not find anyway to proceed after setting up the equalities with elements and all. I pretty much felt it was impossible so I figured ""Let's just do the congruence closure and call it a day"" $\text{Cl}_\text{cng}(R)$. Which would of course be a congruence by the very definition but I feel it's a bit ""cheap"" so to speak. And quite frankly I am not entirely certain that it will yield satisfactory results. So the question is more ""is there a way to make a magma associative that is better than this?"".","['congruence-relations', 'abstract-algebra', 'magma', 'semigroups', 'relations']"
1954539,Cosets Intuitively Explained,"I'm having a bit of trouble understanding what cosets actually mean, and the textbook (Fraleigh - Abstract Algebra) doesn't really seem to help much either. I know that the formal definition of a coset is: $aH$  = $\{ah | h \in H\}$ = the left coset of H. $Ha$ = $\{ha | h \in H\}$ = the right coset of H. What do these ""actually mean""? Any kind of ""dumbed down"" explanation would be tremendously helpful. Thank you.","['abstract-algebra', 'group-theory']"
1954611,"If $f\ge0$ and $ \int_{0}^{1} f(x)^kdx$ does not depend on $k\geq 1$ then $f=\mathbf 1_A$ almost everywhere, for some measurable subset $A$ of $[0,1]$","If $ \int_{0}^{1} (f(x))^k dx= C$ for all $k\geq 1$, then there exists a measurable subset A of [0,1] where $f(x)=1_{A}(x)$ for almost every x Note that $ f:[0,1] -> R^{+}$ I am stuck on this problem. Here is what I have done so far..
We know $\int_{0}^{1} f(x) dx = \int_{0}^{1} f^2(x) dx $ which implies $\int (f-f^2) dx= 0$ which implies $f(x)-f^2(x)= 0$ almost everywhere on [0,1], which implies $f(x)(1-f(x))=0$ a.e. on [0,1] hence f(x)= 0 or 1 for a.e. x on [0,1]. Where do I go from here? Is this correct so far? How do I know that the set of points where $f(x)=1$,call it A, will be measurable necessarily? Also how do I use the other powers of f? I feel I am missing something.","['real-analysis', 'lebesgue-integral', 'measure-theory', 'lebesgue-measure']"
1954652,How can I write this differential equation system in MATLAB?,"I am newbie MATLAB user. How to write this equation system in MATLAB? $$\frac{dN_{ik}}{dt}=\sum_{j=i}^{n}\sum_{l=1}^{n}\beta_{jl}b_{ikjl}S_{jl}N_{jl} - S_{ik}N_{ik}$$ Here, I want to know if I take $n=3$ or any constant number what kind of equation system will I have? How can i run this loop without entering $\beta$, $b$ and $S$ functions. I just want to see matrix form of this system. Sorry for my bad English,  thanks for help.","['matlab', 'ordinary-differential-equations']"
1954692,Why does the sum of inverse squares equal $\pi^2/6$? [duplicate],This question already has answers here : Different ways to prove $\sum_{k=1}^\infty \frac{1}{k^2}=\frac{\pi^2}{6}$ (the Basel problem) (54 answers) Closed 7 years ago . I've heard that $1+1/4+1/9+1/16+1/25+...$ converges to $\pi^2/6$. This was very surprising to me and I was wondering if there was a reason that it converges to this number? I am also confused why $\pi$ would be involved. If someone could provide a proof of this or a intuitive reason/ derivation I would appreciate it. I am only able to understand high school maths however (year 12).,"['sequences-and-series', 'pi']"
1954709,Why isn't $\arccos(\cos x)$ equal to $x$?,How did we get $2\pi - x$? Kindly provide a general answer because many other similar questions have the same issue.,"['trigonometry', 'inverse-function', 'calculus']"
1954713,Finding $E(X)$ and $Var(X)$ of a uniformally distributed continuous variable,"I am having a problem finding E(X), Var(X) of a uniformly distributed variable. Can someone please help or correct me. The question and solution is below. Thanks","['uniform-distribution', 'expectation', 'probability', 'proof-verification']"
1954714,Derivatives of a vector and its transpose,"Assuming that $f(x)=x^Tx-k^2=0$ holds for some $k$ and vector $x$, is it possible to derive that
$$
u \nabla f = uIx
$$
where $I$ is the identity matrix and $u$ is a lagrange multiplier? If I simply derive $f$ with respect to $x$, I get
$$
u\left( Ix + x^T\right)
$$
where I use that $\frac{d}{dx}x^T=I$, but it gives me that annoying extra term $ux^T$. I don't know if I'm doing something wrong or missing a trick where you can somehow ignore the last term. I'm a bit insecure in all of this, so any help is greatly appreciated!","['multivariable-calculus', 'matrix-calculus', 'calculus']"
1954726,Question about homomorphisms between symmetric groups,"Let $f: S_A \to S_B$ be a homomorphism from the symmetric group on $A$ to the symmetric group on $B$, where $A$ and $B$ may be infinite. For $X\subseteq A$ and $b_1,b_2\in B$, say that $b_1\sim_X b_2$ if and only if $f(g)(b_1)=b_2$ for some $g$ s.t. $g(x) = x$ for all $x\in X$. Define $h: \mathcal{P}(B)\to\mathcal{P}(\mathcal{P}(A))$ s.t. $h(Y)=\{X: Y\text{ is closed under }\sim_X\}$. Call $Y$ principal if $\bigcap h(Y)\in h(Y)$ and boring if $\emptyset\in h(Y)$. Question 1 : Is it possible that every principal $Y\subseteq B$ be boring but not every $Y\subseteq B$ be boring? Question 2 : More generally, could there be a complete proper subalgebra of the power set algebra $\langle\mathcal{P}(B),\cap,\cup\rangle$ that contains all principal elements of $\mathcal{P}(B)$? (""More generally"" because an affirmative answer to Question 1 implies that the boring subsets of $B$ form such a subalgebra.) Question 3 : Is there standard terminology for and/or standard results about the notions defined above?","['permutations', 'group-actions', 'group-theory']"
1954739,Trace in Riemannian geometry,"The first time I met the definition of the trace of the Ricci curvature $Ric$ on a Riemannian manifold (M^n,g), it was formulated thanks to local orthonormal coordinates: if $(x_{1}, \cdots, x_{n})$ are local orthonormal coordinates (i.e. $g\left(\frac{\partial}{\partial x^i},\frac{\partial}{\partial x^j}\right)=\delta_{ij}$), then the trace of $Ric$ is $$Ric\left(\frac{\partial}{\partial x^i},\frac{\partial}{\partial x^i}\right)$$ using the Eistein summation convention.
Then I met an other definition. If $g=g_{ij}dx^i dx^j$ in local coordinates (note necessarly orthonormal), $$Tr_{g}(Ric)=g^{ij}Ric_{ij},$$ where $g^{ij}$ is the $(i,j)$ coefficient of the inverse of the matrix $(g_{ij})_{1\le i,j \le n}$. I denote this matrix $G$ in the sequel. According to this definition, the trace of $Ric$ can be understood as $$Tr\left((G^{-1})^{t}M_{Ric}\right),$$ where I write $M_{Ric}$ for the matrix $(Ric_{ij})_{1\le i,j \le n}$, and $(G^{-1})^t$ for the transpose of the matrix $G^{-1}$. My question is: why $G^{-1}$ and why not $G$? In orthonormal coordinates these matrices are the same, equal to the identity, so it has no incidence on the first definition I learnt, but still, I don't understand. Is there any deep raison for this choice?","['tensors', 'riemannian-geometry', 'differential-geometry', 'curvature']"
1954745,Why is interchanging the order of limits in this situation equivalent to asking for continuity?,"The following is an excerpt from Rudin's book in mathematical analysis. Here he states: The part highlighted in red is the one I can't seem to wrap my head around. I thought that if we wanted to know whether the limit, say $f$, of a sequence of functions, say $f_n$, is continuous or not then we would just need: $$\lim_{t\to x} (\lim_{n \to \infty}f_n(t)) = f(x)$$ I.e. just that the limit of functions $f_n$, assumed to be $f$, is continuous by definition. So I don't understand the right hand side of the equation in red. Can somebody explain this?",['analysis']
1954758,Steady-state solution and initial conditions,"Let's say that we have the following first order differential equation:
$$\frac{d \rho(t)}{d t}=F(\rho(t))$$
with some given initial condition $\rho(0)$. I am interested in the steady-state solution $\rho_{ss}$, and to find it we set $\left.\frac{d\rho(t)}{d t}\right|_{t_{ss}}=0$ and solve the algebraic equation 
$$F(\rho_{ss})=0$$ However, how in this situation do we account for the initial condition $\rho(0)=\rho_0$, without solving the full differential equation? After solving the algebraic equation I get infinetely many solutions (actually two distinct solutions, but their superposition is also a solution). P.s. I don't know if this helps, but in my case there is a conserved quantity $Q$, which is the same for $\rho(0)$ and $\rho_{ss}$.","['steady-state', 'ordinary-differential-equations', 'initial-value-problems']"
1954766,"$E(X)$, $Var(X) $, and $Mgf_x(t)$ of a continuous uniform random variable on $[a,b]$","I am wondering if I have found the $Var(X), E(X), Mgf_x(t)$ for a continuous uniform random variable on [a,b] correctly. My solution is below, could someone check whether its correct and correct me if needs be. Thanks","['statistics', 'proof-writing', 'probability']"
1954785,Convergence of the 2-sample Kolmogorov-Smirnov,"Here is my problem, I have two empirical distribution functions $F_n(x)$ and $G_n(x)$ constructed from two data sets with $n$ points each and I estimate their 2-sample Kolmogorov-Smirnov (2-KS) statistic as $D_n \equiv \sup_x \{F_n(x) - G_n(x) \}$. By the Glivenko-Cantelli theorem, the sequence $D_n$ converges uniformly to a value $D_{\infty}$ almost surely. If $F_n$ and $G_n$ are realisations of the same underlying distribution, then $D_{\infty} = 0$ otherwise we have $D_{\infty} > 0$. My problem is to know whether I can say anything about $D_{\infty}$ if I know only the values of $D_n$ for $n \in I = [1,n_{max}]$...because in practice I cannot generate infinite amount of data. In particular, I had the (possibly wrong) ""feeling"" that if $D_n \leq a$ for almost all $n \in I$ and if $D_n$ has a decreasing trend on $I$, then I could say that $D_{\infty} \leq a$ in some sense or with some confidence. I have no problem if this is only true with some probability but I do not know how to formulate such a statement rigorously, if it has any chance of holding at all of course.","['statistics', 'probability', 'convergence-divergence']"
1954805,Uniform boundedness principle on dense subspace,"In my thesis I encountered the following problem: Let $X,Y$ Banach spaces and $Z\subset X$ a norm-dense subspace. Suppose we have operators $\left\{T_n:n\in\mathbb{N}\right\}$ such that for all $x\in Z$ it holds that $\left\{\left\lVert T_nx\right\rVert:n\in\mathbb{N}\right\}$ is bounded. Can I somehow use the Uniform Boundedness principle to conclude that $\left\{\lVert T_n\rVert:n\in\mathbb{N}\right\}$ is bounded? Thanks in advance!","['functional-analysis', 'banach-spaces', 'operator-theory']"
1954814,Example of non-nuclear C*-algebra,"A C*-algebra $A$ is called nuclear iff there is a unique cross C*-norm on the algebraic tensor product $A\otimes B$ for any other C*-algebra $B$. It is equivalent that the minimal (spatial) and maximal norms on $A\otimes B$ coincide. I know (cf. this MathOverflow question ) that an example of a non-nuclear C*-algebra ist $C_r^\ast(\mathbb F_2)$ where $\mathbb F_2$ is the free group on two generators and $C_r^\ast(\mathbb F_2)$ denotes its reduced group C*-algebra. Now my question is: Is there an explicit example of a C*-algebra $B$ such that the minimal and maximal norms on $C_r^\ast(\mathbb F_2)\otimes B$ do not coincide? With explicit I mean that one can write down both norms and see that they are different, e.g. by evaluating them on some specific element. Are there easier examples for other C*-algebras instead of $C_r^\ast(\mathbb F_2)$?","['functional-analysis', 'c-star-algebras', 'operator-algebras']"
1954820,Is a transitive and Euclidean relation necessarily symmetric?,"The Wikipedia article on Euclidean relation reads: A transitive relation is Euclidean only if it is also symmetric. Only a symmetric Euclidean relation is transitive. It seems to be claimed that every transitive and Euclidean relation is symmetric. However, consider the following relation, where $a$, $b$, and $c$ are distinct elements: $R = \{\langle a, b \rangle, \langle a, c \rangle, \langle b, b \rangle, \langle b, c \rangle, \langle c, b \rangle, \langle c, c \rangle\}.$ I think $R$ is transitive and Euclidean but not symmetric, so the claim appears to be wrong to me. This version of the Wikipedia article is due to the edit done on March 8, 2016, and the version before the edit seems correct and precise. Am I correct or mistaken?","['relations', 'logic', 'elementary-set-theory']"
1954822,How can the surd $\sqrt{2-\sqrt{3}}$ be expressed?,"I was wondering how $\sqrt{2-\sqrt{3}}$ could be expressed in terms of $\frac{\sqrt{3}-1}{\sqrt{2}}$.
I did try to solve both the expressions separately but none of them seemed to match. 
I would appreciate it if someone could also mention the procedure","['algebra-precalculus', 'nested-radicals', 'arithmetic']"
1954840,Find all functions $f:\mathbb Z \rightarrow \mathbb Z$ such that $f(0)=2$ and $f\left(x+f(x+2y)\right)=f(2x)+f(2y)$,"Find all functions $f:\mathbb Z \rightarrow \mathbb Z$ such that $f(0)=2$ and
  $$f\left(x+f(x+2y)\right)=f(2x)+f(2y)$$
  for all $x \in \mathbb Z$ and $y \in \mathbb Z$ My work so far: 1) $x=0$ $$f\left(f(2y)\right)=f(2y)+2$$ 2) $y=0$ $$f\left(x+f(x)\right)=f(2x)+2$$ 3) Let $n\ge 0$. Use induction we have If $f(2n)=2n+2$ then $$f(f(2n))=f(2n+2)=2n+2+2=2n+4$$
Hence, if $k=2m\ge0$ then $f(k)=k+2$ 4) $n<0$ I need help here","['functions', 'functional-equations']"
1954845,Bezier curvature extrema,"For a planar cubic Bezier curve $B (x(t),y(t))$, I would like to find the values of parameter $t$ where the curvature (or curvature radius) is greatest/smallest. The formula for curvature is: $$r = \dfrac{(x'^2+y'^2)^{(3/2)}}{x' (t) y''(t) - y'(t) x''(t)}$$ The problem is that there is that square root in it so I was wondering whether it is not possible to express the curvature extrema by some combination of the curve derivatives? The idea is that for finding, say, the values where the slope of the curve is parallel to x-axis one needs to solve the quadratic function of the curve's first derivative. So I thought that maybe the extremes are in fact the values where the acceleration along the curve (or something similar) is greatest/smallest and I hoped that it would be possible to write it down as a polynomial.","['spline', 'bezier-curve', 'polynomials', 'geometry']"
1954846,"Prove that the space of square integrable martingales with time domain $[0,\infty)$ is a complete semi-normed space","Let $E$ be a separable$^1$ Banach space $(\Omega,\mathcal A,\operatorname P)$ be a probability space $(\mathcal F_t)_{t\ge 0}$ be a filtration of $(\Omega,\mathcal A)$ $I_{t_0}:=[0,t_0]$ for $t_0\ge 0$ and $I_\infty:=[0,\infty)$ Let $$\mathcal M^2_{t_0}:=\left\{X\subseteq\mathcal L^0(\operatorname P,E):X\text{ is an }\mathcal L^2(\operatorname P,E)\text{-bounded}^2\text{ right-continuous }(\mathcal F_t)_{t\in I_{t_0}}\text{-martingale with }\operatorname P[X_0=0]=1\right\}$$ be equipped with $$\left\|X\right\|_{\mathcal M^2_{t_0}}:=\left(\sup_{t\in I_{t_0}}\left\|X_t\right\|_{\mathcal L^2(\operatorname P,\:E)}\right)^{\frac12}\;\;\;\text{for }X\in \mathcal M^2(\mathcal F,\operatorname P,E)\tag 1$$ for $t_0\in[0,\infty]$. Note that if $X\subseteq\mathcal L^2(\operatorname P,E)$ is a right-continuous $\mathcal F$-martingale with $\operatorname P[X_0=0]=1$, then $$(X_t)_{t\in [0,\:t_0]}\in\mathcal M^2_{t_0}\;\;\;\text{for all }t_0\ge 0\tag 2$$ by Doobâ€™s inequality . Now, there are many textbooks which prove that $M^2_{t_0}$ is a complete seminormed space, for all $t_0\ge 0$. Can we use this fact to prove that even $\mathcal M^2_\infty$ is a complete seminormed space? My idea is the following: Let $(X^n)_{n\in\mathbb N}\subseteq\mathcal M_\infty^2$ be Cauchy $\mathcal M_{t_0}^2$ is complete $\Rightarrow$ $\exists Y^{t_0}\in\mathcal M_{t_0}^2$ with $$\left\|(X_t^n)_{t\in[0,\:t_0]}-Y^{t_0}\right\|_{\mathcal M_{t_0}^2}\xrightarrow{n\to\infty}0\tag 3$$ for all $t_0\ge 0$ It's easy to see that $Y^{s_0}$ and $(Y_t^{t_0})_{t\in[0,\:s_0]}$ are indistinguishable, i.e. $$\left\|Y^{s_0}-(Y_t^{t_0})_{t\in[0,\:s_0]}\right\|_{\mathcal M_{s_0}^2}=0\;,\tag 4$$ for all $t_0\ge s_0\ge 0$ Now, let $$X_t:=Y_t^t\;\;\;\text{for }t\ge 0$$ Then, $$\left\|(X_t^n)_{t\in[0,\:t_0]}-(X_t)_{t\in[0,\:t_0]}\right\|_{\mathcal M^2_{t_0}}\xrightarrow{n\to\infty}0\;\;\;\text{for all }t_0\ge 0\tag 5$$ However, we need to conclude that $$\left\|X^n-X\right\|_{\mathcal M^2_\infty}\xrightarrow{n\to\infty}0\;.\tag 6$$ Note that $(6)$ would yield $X\in\mathcal M_\infty^2$ by the triangle inequality. So, how can we show $(6)$? $^1$ I don't see where we need the separability of $E$. Maybe someone can write the reason for this assumption into the comment section. $^2$ i.e. $$\sup_{t\ge 0}\left\|X_t\right\|_{\mathcal L^2(\operatorname P,\:E)}<\infty\;.$$","['stochastic-processes', 'probability-theory', 'martingales']"
1954852,Entropy of the multinomial distribution,"What is the entropy of the multinomial distribution? To fix notation, let us define $n > 0$ as the number of trials, $p_1, \ldots, p_k$ as the probabilities of each of the $k$ possible outcomes and $X_1, \ldots, X_n$ as the outcomes. Recall that the pmf of the multinomial distribution is given by $f(x; n,p) \equiv f(x_1,\ldots, x_k; n, p_1, \ldots, p_k) = \cases{ \frac{n!}{x_1! \ldots x_k!} p_1^{x_1} \ldots p_k^{x_k} \hspace{1cm} \text{if }\sum_{i=1}^{k} x_i = 1 \\ 0 \hspace{4cm} \text{otherwise} }$ The (Shannon) entropy of a distribution measures the amount of stored information or the uncertainty and for this distribution takes the form $H = - \sum f(x; n,p) \log{f(x; n,p)} = E[-\log{f(x; n,p)}]$, where the sum is over all $x = (x_1, \ldots, x_n)$ for which $\sum_{i=1}^{n} x_i = n$. The entropy for the binomial distribution can be calculated (see linked question). However, for the multinomial distribution it has only been shown that the entropy is maximized when $p_i = \frac{1}{k}$ for all $i$ [1, 2]. There is a recent paper [ 3 ] which sets upper and lower bounds on the entropy. However, a closed-form expression for the entropy seems not to have been derived yet. My questions are:
(A) Is there a closed form for the special case  $p_i = \frac{1}{k} \hspace{0.5cm} \forall i$ ?
(B) Are there other special cases for which the entropy can be calculated? 
(C) Why is it so difficult to obtain a closed-form solution for this? Linked questions Entropy of a binomial distribution References [ 1 ]: P. Mateev, On the entropy of a multinomial distribution, Teor.
Veroyatnost. i Primenen., 1978, Volume 23, Issue 1, 196â€“198, link . [ 2 ]: L.A. Shepp, I. Olkin, Entropy of the Sum of Independent Bernoulli Random Variables and of the Multinomial Distribution, Technical Report, 1978, link . [ 3 ]: Yuichi Kaji, Bounds on the entropy of multinomial distribution, 2015 IEEE International Symposium on Information Theory (ISIT), link .","['multinomial-distribution', 'closed-form', 'information-theory', 'entropy', 'probability']"
1954872,"Let $f$ a function which is differentiable on $[a,b]$ such that $f(a)=f(b)=f^\prime(a)=0$","Let $f$ a function  which is differentiable on $[a,b]$ such that $f(a)=f(b)=f^\prime(a)=0$ Prove that: $\exists c\in ]a,b[$ : $$f^\prime(c)=\frac{f(c)}{c-a}$$ I tried to use Rolle theorem but i can't find the result","['functions', 'functional-equations']"
1954885,Solve this problem for a unit circle,"Given $541$ points in the interior of a circle of unit radius, show that there must be a subset
of $10$ points whose diameter (the maximum distance between any pair of points) is less
than $\sqrt{2}/4$.","['circles', 'geometry']"
1954901,"Rings with a given number of (prime, maximal) ideals","Given three cardinal numbers $1â‰¤aâ‰¤b<c$ , I would like to know if we can find a commutative ring $R$ (with unit) such that the number of ideals of $R$ is $c$ the number of prime ideals of $R$ is $b$ the number of maximal ideals of $R$ is $a$ For instance, for $a=b=c=\aleph_0$ , the ring $R=\Bbb Z$ provides an example. I'm particularly interested in the case where $a,b,c$ may be infinite. If $c$ is finite, then either $a=b=1$ and $c=2$ or $R$ is not an integral domain (see here ). In any finite ring, prime ideals are maximal (because a finite integral domain is a field, see here ), so that possible examples for $a \neq b$ must be infinite. If $c=3$ , then $a=1$ (see here ). If $a=b$ and $c=2^a$ is finite, then I think that we can consider $R=\Bbb Z/p_1 \cdots p_a \Bbb Z$ where $p_1, \dots, p_a$ are distinct primes. I wasn't able to solve the case $c=5,a=b=3$ for instance. Maybe there are conditions on $a,b,c$ for such a ring to exist, at least when $c$ is finite. Possibly related: (1) , (2) , (3) . Thank you very much for your help!","['abstract-algebra', 'ring-theory', 'ideals', 'commutative-algebra']"
1954936,Number of extreme points of a function on the bounded interval,"How many extremum  points (local maximums and minimums) can a continuous and differentiable function have on the bounded interval. My guess it is still countable many. If so what extra condition can we impose on the function that the number of extremum points is at most finite? Basically, if we show that $A=\{x: f'(x)=0 \}$ is finite should be enough. I would like to clarify that we look for extremum points and not critical points. That is points at which the derivative is zero but around which the derivative is not zero.  That is we  exclude constant functions and functions constant on some intervals.","['real-analysis', 'functions']"
1954938,Significance and application of Riesz Decomposition Theorem,"The Riesz Decomposition Theorem in Operator Theory is given as:
Let $a \in \mathcal{A}$ (for unital Banach algebra $\mathcal{A}$) Suppose $\sigma(a) = \sigma_1 \cup \sigma_2$ where $\sigma_1 \cap \sigma_2 = \emptyset$. Then: $\exists$ non-trivial idempotents $E_1~,E_2 \in \mathcal{A}$ such that $E_1 + E_2 = 1$. If $\mathcal{A} \subset \mathcal{L(X)}$ ($X$ Banach space) then $E_1X, ~E_2X$ are closed subspaces invariant  for $a$ and $E_1X \oplus E_2X = X$. If $a_k = aE_k$ then $\sigma(a_k) = \sigma_k$ (for $k=1,2$) and for any $f \in Hol(a)$ we have $$f(a_k) = f(a)E_k.$$ Question: What is the significance of these results, how is it most commonly used? At the moment it seems like an arbitrary collection of results, but as I understand it is an important result in operator and spectral theory. Also, what are the applications in quantum mechanics? Thanks.","['banach-algebras', 'operator-theory', 'functional-analysis', 'spectral-theory', 'applications']"
1954972,"If $f:X\to Y$ is continuous, then the induced map $F:K(X)\to K(Y)$ is continuous wrt the Vietoris topology","Let $X,Y$ be topological spaces, $f:X\to Y$ a continuous map, and denote by $K(X)$ [resp. $K(Y)$] the set of compact subsets of $X$ [resp. $Y$]. We can endow $K(X)$ with a topology (the Vietoris topology) generated by the sets: $$\{K\in K(X): K\subset U\}$$ $$\{K\in K(X):K\cap U \neq\emptyset\}$$ where $U\subset X$ ranges on all open subsets of $X$. It is then natural to ask whether the induced map $F:K(X)\to K(Y)$ given by $F(K)=f[K]=\{f(x):x\in K\}$ is continuous. It suffices to see what happens to members of the sub-basis. Fixing $U$ open in $Y$, $F^{-1}(\{K:K\subset U\})=\{K:F(K)\subset U\}=\{K:f(K)\subset U\}=\{K:K\subset f^{-1}(U)\}$ which is obviously open in $K(X)$ since $U$ is open in $Y$ and $f$ is continuous. $F^{-1}(\{K:K\cap U\neq\emptyset\})=\{K:f(K)\cap U\neq\emptyset\}=\{K:K\cap f^{-1}(U)\neq\emptyset\}$. To see the last equality, note that:
$$f(K)\cap U\neq\emptyset \iff \exists y(y\in f(K)\wedge y\in U)\iff \exists x (x\in K\wedge f(x)\in U)$$
and
$$K\cap f^{-1}(U)\neq\emptyset \iff \exists x (x\in K\wedge f(x)\in U).$$ Is this correct? In Kechris' Classical Descriptive Set Theory , he leaves this as an exercise, but asks that $X$ and $Y$ be metrizable, which I have not used in the argument above.","['descriptive-set-theory', 'general-topology', 'proof-verification']"
1955061,Equation with double absolute value,"I have problem with solving the following equation. $$2x - |5-|x-2|| = 1$$ How to handle absolute value in absolute value?
I have tried multiple times to solve it but I get no solution.","['algebra-precalculus', 'absolute-value']"
1955070,Questions regarding definitions of reduction of structure group of a Principal/Fiber/Vector bundle?,"Let $P,B$ be algebraic varieties and $G$ be an algebraic group. Borel Construction :Let $p:P\rightarrow B$ be a principal $G$-bundle. Suppose $G$ acts on the left on a variety $F$. One can define a Borel Construction $P\times_G F$ to be the quotient of $P\times F/ \sim$ where $(x,f)\sim (xg,g^{-1}f)$. We have a natural projection from $q:P\times_G F\rightarrow X$ by defining $[x,f]\mapsto p(x)$. Then $q:P\times_G F\rightarrow X$  is a fiber bundle over $B$ with fiber $F$ and structure group $G$ which has the same transition function. Now let us start with a $q:Q\rightarrow B$ a principal $H$ bundle such that there is a morphism from $H\rightarrow G$. Take $F=H$, notice $H$ acts on $G$ from the left. Applying the Borel Construction  we get $p:Q\times_H G\rightarrow X$ a fibre bundle with fiber $G$ and structure group $H$, via the morphism $H\rightarrow G $ we can think the transition functions taking value in $G$. Hence we get a Principal $G$ bundle. Definition(Reduction of structure group): Given a principal $G$-bndle $p:E\rightarrow B$ we say that the structure group $G$ can be reduced to $H$ for some algebraic group $H$ with a morphism $H\rightarrow G$ if there exists a principal $H$-bundle $Q\rightarrow B$ and a $G$-equivariant morphism $\tau : Q\times_H G\rightarrow E$ so that the map is $\tau$ is $G$-equivariant. Question 1-Why don't we require $\tau$ to be an isomorphism? Question 2- Why cannot we simply say that ""Given a principal $G$-bndle $p:E\rightarrow B$ we say that the structure group $G$ can be reduced to $H$ if the transition functions factor through a map $U_{\alpha}\cap U_{\beta}\rightarrow H$"" Question 3- One usually defines reduction of a structure group of a fiber bundle by defining it to be the reduction of the structure of group of the associated Principal bundle. If the 'definition' in Question-2 is a valid one, then one can define reduction of a structure group of a fiber bundle similar to that, that is the transition functions (or may be another set of equivalent transition fucntion) factors through $H$. Question 4- Bott and Tu defines a vector bundle to have reduction of structure group to $H$, if there is a equivalent transition function which takes values at $H$. But if we think a vector bundle as a fibre bundle, we have another definition- 'The vector bundle is said to have a reduced structure groupp $H$ if the associated Principal Bundle have a reduced structure group H.' Are these two definitions equivalent? Note: I am not demanding the action of the algebraic group $G$ on the fiber $F$ to  be faithful. So that I don't have to necessarily to talk about reduction of structure group into a subgroup f $G$.","['fiber-bundles', 'differential-topology', 'algebraic-geometry', 'principal-bundles', 'vector-bundles']"
1955090,Double completion of measure space,"Let $(X,\mathscr{A},\mu)$ be a measure space. The completion of $\mathscr{A}$ with respect to $\mu$ is defined as
$$\mathscr{A}_\mu :=\left\{A\subseteq X\mid \exists E,F\in \mathscr{A} : E\subseteq A\subseteq F, \mu(F\setminus E)=0 \right\}.$$
The completion of $\mu$ is defined as a function
$\overline{\mu}:\mathscr{A}_\mu\to[0,\infty]$ by
$$\overline{\mu}(A) :=\sup\left\{\mu(B)\mid B\in\mathscr{A}:B\subseteq A\right\}.$$
The triple $(X,\mathscr{A}_\mu,\overline{\mu})$ now forms a complete measure space. I am trying to show that if we again complete this completion, we obtain the same measure space. Specifically, I am trying to show that $(\mathscr{A}_\mu)_{\overline{\mu}}=\mathscr{A}_\mu$ (and $\overline{\overline{\mu}}=\overline{\mu}$). My observations so far: The inclusion $\mathscr{A}_\mu\subseteq(\mathscr{A}_\mu)_{\overline{\mu}}$ follows easily. So, suppose that $A\in (\mathscr{A}_\mu)_{\overline{\mu}}$. Then we can find $E,F\in\mathscr{A}_\mu$ so that $E\subseteq A\subseteq F$ and $\overline{\mu}(F\setminus E)=0$. We need to find two sets $E', F'\in\mathscr{A}$ so that $E'\subseteq A\subseteq F'$ and $\mu(F'\setminus E')=0$. Since $E,F\in \mathscr{A}_\mu$ we can find $E_1,E_2,F_1,F_2\in\mathscr{A}$ so that $$E_1\subseteq E\subseteq E_2 \quad \text{and}\quad\mu(E_2\setminus E_1)=0,$$
and
$$F_1\subseteq F\subseteq F_2 \quad\text{and}\quad\mu(F_2\setminus F_1)=0.$$ 
We now have the chain of inclusions $E_1\subseteq E\subseteq A\subseteq F\subseteq F_2$. Setting $E'=E_1$ and $F'=F_2$ seems the obvious next step, but then we need to show that $\mu(F_2\setminus E_1)=0$. However, I don't see why this should be true. On the other hand, we may set $E'=E_1\cup F_1$ and $F'=E_2\cup F_2$, so that
$$0\leq \mu((E_2\cup F_2)\setminus(E_1\cup F_1))\leq \mu((E_2\setminus E_1)\cup (F_2\setminus F_1)) \leq 0.$$
But now $E_1\cup F_1$ may not be contained in $A$, because $F_1$ may not be contained in $A$. We may modify our choice to $E'=E_1\cap F_1$, which is contained in $A$. However, now: 
$$\mu((E_2\cup F_2)\setminus (E_1\cap F_1))\leq \mu(E_2\setminus F_1) + \mu(F_2\setminus E_1),$$
which does not tell us anything because the terms on the right hand side are unknown. I am a bit stuck. Perhaps another possible approach would be using the fact that $B\in\mathscr{A}_\mu$ if and only if $\mu_\ast(B)=\mu^\ast(B)$, where $\mu_\ast$ and $\mu^\ast$ are the inner- and outer measures induced by $\mu$, respectively. Any hints would be greatly appreciated!",['measure-theory']
1955120,Equation of a line passing through the origin,"I have the question ""Write down the equation of the line passing through the origin and perpendicular to y = 2X + 3"". I know that the equation of a line is y = mx + c and that the origin is (0,0). However, I am not sure how I would start this.",['geometry']
1955154,Find the probability that the hand contain at least two cards of the same rank.,"5 cards are randomly selected (without replacement) from a standard deck of 52 playing cards (13 ranks: 2, 3, 4, ..., 10, J, Q, K, A, and 4 suits: S, H, D, C).
Find the probability that the hand contain at least two cards of the same rank (e.g. {2, 2, 6, A, Q}, {J, J, K, 4, J}, {8, 8, A, A, 6}, ...). I know that I can use $$1 - \frac{\binom{13}{5}\binom{4}{1}^5}{\binom{52}{5}}$$ Is there any other way to do this if I don't want to use $1 -$ (something).","['statistics', 'poker', 'probability']"
