question_id,title,body,tags
1115455,Why is $\frac{\sqrt{x+1}-1}{x}$ equal to $\frac{1}{\sqrt{x+1}+1}$?,"I'm working with the expression $$\frac{\sqrt{x+1} - 1}{x}.$$ According to Wolfram Alpha ""alternate form"" section ( http://www.wolframalpha.com/input/?i=%28%28x%2B1%29%5E1%2F2-1%29%2Fx ) it is equal to $$\frac{1}{\sqrt{x+1} + 1}.$$ How can I go from one expression to the other?","['radicals', 'fractions', 'algebra-precalculus']"
1115471,Induction on the size of the set?,"Show that every non-empty finite set of real numbers has a maximum. (Hint: induction on the size of set). I'm not exactly sure how to approach this. I'm familiar with induction, but I don't know where I am supposed to apply it. Right now, I have: $P(n)$ : Every set $S = \{a_1, ... , a_n\}$ has a maximum. $P(n+1)$ : Every set $S = \{a_1, ..., a_n, a_{n+1}\}$ has a maximum. This doesn't really seem like a rigorous argument, nor do I think it proves the claim. I think I am supposed to do something with the cardinality of  set, but we haven't covered it in this course. I remember this property (of power sets, I believe) from a previous course: $$|2^S| = 2^{|S|}.$$ Any ideas on which direction I should head in?","['proof-writing', 'elementary-set-theory']"
1115475,$\det(I+\epsilon V)=1+\operatorname{trace}(V)\epsilon+O(\epsilon^2)$,"How to show that
$$\det(I+\epsilon V)=1+\operatorname{trace}(V)\epsilon+O(\epsilon^2)$$
for any $n\times n$ real matrix $V$? This is used a lot in the theory Lie groups, but I never saw a proof of it.",['linear-algebra']
1115482,"Let $A, B$ be sets. Show that $\mathcal P(A ∩ B) = \mathcal P(A) ∩ \mathcal P(B)$. [duplicate]","This question already has an answer here : Does $\wp(A \cap B) = \wp(A) \cap \wp(B)$ hold? How to prove it? (1 answer) Closed 9 years ago . Let $A, B$ be sets. Show that $\mathcal P(A \cap B) = \mathcal P(A) \cap \mathcal P(B)$. I understand what this question is asking. The power set of an intersection equals the intersection of two power sets. I just have no idea how to prove it.",['elementary-set-theory']
1115484,Finding orthogonal matrix that maps one vector to another,"Let $w, v \in \mathbb{R}^k$ be two known vectors such that $||w|| = ||v||$ ($|| . ||$ is the usual Euclidean norm). My questions are related with the problem of finding $Q$ orthogonal such that $v = Q w$. I know that if we take $u = (w-v)/||w-v||$, then $Q = I-2uu'$ (Householder reflection) will be a solution. My questions are: 1) Is there any explicit way to characterize the solutions $Q$? For instance, what would be another concrete ""formula"" for a solution $Q$, different than the Householder reflection above? 2) Say that we have a matrix with eigenvalues $\Lambda$. If $Q_1$ is another solution (i.e. $Q_1$ is orthogonal and $v = Qw = Q_1 w$, $Q_1 \neq Q$), is it true that $Q D Q' = Q_1 D Q_1'$? 3) In essence, does the restriction $Q w = v$ for $Q$ orthogonal ""tie down"" the structure/properties of $Q$ in any interesting way? Any reference or pointers are much appreciated... Thanks in advance!","['matrices', 'linear-algebra', 'orthogonality', 'geometry']"
1115491,How to go about solving this inequality question?,"$\cos(3x-\pi/3) \leq (1/2).$ Here is what I have done so far... Let $3x-\pi/3 = X$. So I need to solve $\cos(X) \leq 1/2$. Which is all $X$ from $\pi/3$ to $5\pi/3$, so-- $\pi/3 \leq X \leq 5\pi/3 \quad\longrightarrow\quad \pi/3 \leq 3x-\pi/3 \leq 5\pi/3.$ So should I now solve for $x$? or...","['inequality', 'trigonometry', 'algebra-precalculus']"
1115524,"How do I compare student pre-test scores with post-test scores to evaluate whether or not they ""learned""?","We need to track student advancement in a topic based on pre and post test scores.  That is, we give a pre-test on day 1 of class, then on the last day we give the exact same test, renamed as a post-test.  Somehow we have to take the first score and assign a target number for the second number to show improvement.  This second number has to be higher than the first number.  Students who hit this number, or above, on the post test are considered a success.  Students who do not are counted as a failure.  Based on the percent of students who are ""success"" we get evaluated as how well the students learned.  My problem is trying to figure out how to calculate how well the students did, or did not, improve. My first thought was simply take the difference in scores and calculate a percentage change.  But how do I then measure student success?  A change in 50% of their score?  This seems somewhat easy for people who did rather poor on their pre-test, but those who did rather well it seems to penalize.  That is, jumping from 0% to 50% is great, but jumping from 75% to 85% is does not seem as good if we just measure %change.  The first student would be a ""success"" even failing the course, but the second student would be considered a ""failure"" even passing the course rather well. If it helps, here are the pre-test scores for one class: 20
40
44
12
48
32
24
44
28
0
36
40 and pre-test scores from another...
76
40
40
32
60
64
68
48
36
72
56
20
24
36
52 the exact same method must be used in each class to show ""success"" versus ""failure"".",['statistics']
1115525,Show that the set of unitary matrices is not an affine algebraic variety in complex space $C^{n^2}$.,"This is an exercise from An Invitation to Algebraic Geometry by Karen Smith. It asks to show that the set of unitary matrices $U_n$ is not an affine algebraic variety in complex space $C^{n^2}$. However it is a real algebraic variety. The second part is pretty easy. I expanded the complex variables into $a+bi$ and make them two real variables. Using the equations $\Sigma_j^{n} x_{ij} \bar{x_{jk}}=1$ when $i=k$ and $\Sigma_j^{n} x_{ij} \bar{x_{jk}}=0$ when $i\neq k$, I got a bunch of polynomials in terms of the $2n^2$ variables. So the zero set must be an affine algebraic variety in reals. For the first part, I think it has something to do with the fact that $f(z)=\bar{z}$ is not analytic. But how to show that the zero set cannot come from polynomials? Thanks for any help!",['algebraic-geometry']
1115545,Lines in the projective plane,"In my lecture notes we have the following: The set $$\mathbb{P}^2(K)=\{[x, y, z] | (x, y, z) \in (K^3)^{\star}\}$$ is called projective plane over $K$ . There are the following cases: $z \neq 0$ $$\left [x, y, z\right ]=\left [\frac{x}{z}, \frac{y}{z}, 1\right ]$$ $$\mathbb{P}^2(K) \ni \left [x, y, z\right ] \to \left (\frac{x}{z}, \frac{y}{z}\right ) \in A^2(K)$$ These points are the finite points of $\mathbb{P}^2(K)$ . $z=0$ The points $\left [x, y, 0\right ]$ are called points at infinity of $\mathbb{P}^2(K)$ . The finite points $\left [x, y, 1\right ] \in \mathbb{P}^2(K)$ geometrically correspond to the intersection points of the lines from $(0,0,0)$ with the plane $z=1$ . The points at infinity $\left [x, y, 0\right ]$ geometrically correspond to the lines of the plane $x0y$ that pass through $(0, 0, 0)$ . We define as line in $\mathbb{P}^2(K)$ each equation of the form $$ax+by+cz=0, (a,b,c) \neq (0,0,0)$$ that means the set $$E=\{\left [x, y, z\right ] \in \mathbb{P}^2(K) | ax+by+cz=0, (a, b, c) \neq (0,0,0) \}$$ If $z \neq 0$ : $\left [x, y, z\right ]=\left [x, y, 1\right ]$ , that means that the equation is written $$ax+by+c=0$$ (and if $ab \neq 0$ then it is the known affine line) $$$$ Can you explain to me what $$\mathbb{P}^2(K) \ni \left [x, y, z\right ] \to \left (\frac{x}{z}, \frac{y}{z}\right ) \in A^2(K)$$ means? Also, at the end, why does it stand that $\left [x, y, z\right ]=\left [x, y, 1\right ]$ ? At the beginning didn't we have that $\left [x, y, z\right ]=\left [\frac{x}{z}, \frac{y}{z}, 1\right ]$ ?","['projective-space', 'algebraic-geometry', 'abstract-algebra']"
1115562,Evaluate $\lim_{n \rightarrow \infty} \frac {[(n+1)(n+2)\cdots(n+n)]^{1/n}}{n}$ [duplicate],This question already has answers here : How to prove that $\lim \frac{1}{n} \sqrt[n]{(n+1)(n+2)... 2n} = \frac{4}{e}$ (5 answers) Closed 4 years ago . Evaluate $$\lim_{n \rightarrow \infty~} \dfrac {[(n+1)(n+2)\cdots(n+n)]^{\dfrac {1}{n}}}{n}$$ Attempt: Let $$y=\lim_{n \rightarrow \infty} \dfrac {[(n+1)(n+2)\cdots(n+n)]^{\dfrac {1}{n}}}{n}$$ $$\implies \log y = \lim_{n \rightarrow \infty} \dfrac {1} {n} [\log (n+1) +\cdots+log(n+n)-log(n)] $$ How do I move forward? Thank you very much for your help.,"['sequences-and-series', 'calculus', 'real-analysis']"
1115637,Determining uniform convergence of complex power series,"I'm working on some practice problems for my complex analysis course, and I'm having trouble with uniform convergence. The question asks whether the following series converges uniformly for $|z|<1$:
$$
\sum_{n=1}^{\infty} \frac{z^n}{n^2}
$$
I'm not really sure how to proceed with this question. I know that the Weierstrass M test would give me uniform convergence if I could find a series of real numbers that are always larger than the magnitude of the terms in my complex series, but I the only series I can think of is $\sum_{n=1}^{\infty} \frac{1}{n} > \sum_{n=1}^{\infty} |\frac{z^n}{n^2}|$ and that diverges. Any suggestions would be greatly appreciated.","['power-series', 'complex-analysis']"
1115650,Find a parametrization of the intersection curve between two surfaces in $\mathbb{R^3}$ $x^2+y^2+z^2=1$ and $x^2+y^2=x$.,"Find a parametrization of the intersection curve between two surfaces in $\mathbb{R}^3$
$$x^2+y^2+z^2=1$$ and $$x^2+y^2=x.$$ I know that $x^2+y^2+z^2=1$ is a sphere and that $x^2+y^2=x$ is a circular cylinder. Any help is greatly appreciated, thank you.",['differential-geometry']
1115663,Can $f(g(x))$ be a polynomial?,Let $f(x)$ and $g(x)$ be nonpolynomial real-entire functions. Is it possible that $f(g(x))$ is equal to a polynomial ? edit Some comments : I was thinking about iterations. So for instance $f(f(x)) = $ some polynomial. However such $f$ are usually (Always ?) not entire because of the fact that a non-linear polynomial has more than 1 fixpoint. This lead me to consider adding the strong condition $(f(g(x)) - g(f(x)))^2$ is not indentically $0$. But I guess that is a followup question. edit 2 Real-entire means entire and real-analytic.,"['taylor-expansion', 'function-and-relation-composition', 'complex-analysis', 'polynomials']"
1115667,Calculation of Conditional Expectation $\Bbb E[f(X)\mid Y]$,"$\newcommand{\Cov}{\operatorname{Cov}}$and thank you for taking the time to read this. :) My question is about evaluating $\Bbb E[f(X) \mid Y]$ (a random variable in $Y$). There's plenty online (and in my first year lecture notes) about $\Bbb E[X\mid Y]$ and $\Bbb E[f(X)]$, but not $\Bbb E[f(X)\mid Y]$. I appreciated that if you know the pdf of $f(X)$, then this is easy (set $X^* = f(X)$ and just do normally). Is there some special way that I can do this (similar to the $\Bbb E[f(X)] = \int_\Bbb R f(x)p(x) \, dx$, where $p$ is the pdf - if the pdf exists, of course!)? For a bit of background, I was trying to show that, for $(X,Y)$ jointly Gaussian,
$$\Cov(f(X),Y) = \Bbb E[f'(X)] \Cov(X,Y)$$
for any ""nice"" function $f$. I was attempting this using ""iterated expectation"":
$$\Cov(f(X),Y) = \Bbb E[(f(X) - \mu)(Y - \nu)] = \Bbb E[\Bbb E[(f(X)-\mu)(Y-\nu)\mid Y]] \\
= \Bbb E[(Y-\nu)\Bbb E[f(X) - \mu \mid Y]],$$
then using the fact that we know that $X\mid Y\sim N(\mu + \rho\sigma(Y-\nu)/\tau, \sigma^2(1-\rho^2))$ (with the usual symbol conventions). Unfortunately, I couldn't get anywhere with this. I'm not even sure if this is the right method, as I didn't know how to convert this to using $f(X)$ instead of $X$. Any help would be most appreciated! Thanks! :) [PS - if someone with lots of SE-experience thinks that I should make this two questions, please just let me know - they are directly related though! :)] Update 1: Consider $Y = aX + bZ$ where $X$ and $Y$ have mean 0 and variance 1 and $Z$ ~ $N(0,1)$ is independent of $X$; so $\Cov(X,Y) = a$, by independences. So
$$\Cov(f(X),Y) = \Cov(f(X),aX + bZ) = a\Cov(f(X),X)$$
as $X$ and $Z$ are independent, so $f(X)$ and $Z$ are also. Further, earlier in the question we showed that
$$\Bbb E[g(R)(R-\mu)] = \sigma^2 \Bbb E[g'(R)]$$
where $g$ is a ""nice"" function and $R$ ~ $N(\mu,\sigma)$. Applying this, we have, for $g(X) = f(X) - \Bbb E[f(X)]$ and using the fact that X has mean 0 and variance 1, that
$$\Cov(f(X),X) = \Bbb E[g(X)X] =  \Bbb E[g'(X)] = \Bbb E[g'(X)],$$
as required. However, this is only for $Y$ in the form given. I need to consider general $(X,Y)$ jointly Gaussian. I'm not 100% clear on what 'jointly Gaussian' is - I just used it as having pdf given by
$$p_{X,Y}(x,y) = \exp \left( -{1 \over {2(1-\rho^2)}} \left( \left( {{x - \mu} \over \sigma} \right)^2 ... \right) \right).$$
Is this the right definition?","['probability-theory', 'conditional-expectation', 'random-variables', 'expectation']"
1115688,"How to approach this proof problem, what proof to use, what assumption to use?","This is a problem from Discrete Mathematics and its Applications Here is the definition of rational that my book uses Usually when I approach this type of a problem, I can find a type of proof to use and what assumption to make. But for this one I can't find one that works First I tired a direct proof. That is, I assumed $r$ is irrational or there do not exists integers $p$ and $q$ with $q\neq 0$ such that $r = \frac{p}{q}$. But I couldn't go from that to saying $|r - n| < \frac{1}{2}$ where $n$ is some integer. I also tried proof by contradiction. The initial problem is proving $p \to q$ so proof by contradiction would be showing that $\neq (p\to q)$ or $p\land \neg q$ leads to a contradiction. I didn't know how to get from $r$ being a rational number to there not being an integer $n$ for which $|r - n| < 1/2$. Lastly, I tried proof by contraposition, which would be $\neg q \to \neg p$. If there is not a unique integer $n$ such that the distance between $r$ and $n$ is less than $1/2, r$ is rational. But how would you get from for all integers $|r-n| \geq 1/2$ to $r$ is rational?","['proof-writing', 'discrete-mathematics', 'proof-verification']"
1115743,Prove that the probability of two event sets are equal,"Consider this problem: Let $A_1, A_2,...$ be an arbitrary finite sequence of events. Let $B_1, B_2,...$ be another finite sequence of events defined as follows: $B_1 = A_1, B_2 = A^c_1 >\cap A_2, B_3 = A^c_1 \cap A^c_2 \cap A_3,.. $ Prove: $P(\bigcup^n_{i=1} A_i) = \sum^n_{i=1}P(B_i)$ Proof using Induction: For $\mathbf{n=1}$ $$P(\bigcup^1_{i=1} A_i) = P(A_1) \ \text{and} \ \sum^1_{i=1}P(B_i) = P(B_1) $$ $$ \text{Given} \ A_1 = B_1 \ \text{it follows that} \ P(A_1) = P(B_1)$$ Inductive step: Assumption:
$$\forall n \in N \ | \ P(\bigcup^n_{i=1} A_i) = \sum^n_{i=1}P(B_i)$$
prove that:
$$P(\bigcup^{n+1}_{i=1} A_i) = \sum^{n+1}_{i=1}P(B_i)$$ Prove: $$P(\bigcup^{n+1}_{i=1} A_i)$$
$$ \iff P(\bigcup^{n}_{i=1} A_i \cup A_{n+1})$$
$$\iff P(\bigcup^{n}_{i=1} A_i) + P(A_{n+1}) - P(\bigcup^{n}_{i=1} A_i \cap A_{n+1})$$ $$ \iff P(\bigcup^{n}_{i=1} A_i) + P(A_{n+1} \cap (\bigcup_{i=1}^n A_1)^c)$$ Applying De Morgan Law $$\iff  P(\bigcup^{n}_{i=1} A_i) + P(A_{n+1} \cap (\bigcap_{i=1}^n A_1^c))$$ Due to preexistence of  $B_n = \bigcap_{i=1}^{n-1} A_i^c \cap A_{n} \ \text{for} \ n > 1 $ and therefore  $B_{n+1} = \bigcap_{i=1}^n A_i^c \cap A_{n+1} $ it follows that $$ \iff P(\bigcup^{n}_{i=1} A_i) + P(B_{n+1})$$ Employing our inductive assumption for $\forall n \in N$ it follows: $$\iff \sum^n_{i=1} P(B_i) + P(B_{n+1}) \iff \sum^{n+1}_{i=1} B_i$$ The proof at some stages does make sense in my head. Could someone please tell me  whether those steps are consistent? Thank you.",['probability']
1115747,"If $x$ is a boundary of $S$ in $\mathbb{R}$, then $x$ must contain both interior points and exterior points of $S$","Above is the statement that I am given to prove or disprove. I think it is false. For $Q$ a rational number, there is no interior point nor exterior point. so every point in $Q$ is boundary point, but every ball of any point in $Q$ does not contain both interior and exterior points of $S$. Is it valid counter-example to it? And I am wondering if $Q$ consists of $\textrm{int} S + \textrm{ext} S + \textrm{boundary} S$, where $S$ is subset of $Q$. It is true for $R$, but not sure whether it still hold for $Q$.",['multivariable-calculus']
1115767,Power Set Explanation,"The following is from the Wikipedia page on the Power set : By identifying a function in $2^S$ with the corresponding preimage of $1$, we see that there is a bijection between $2^S$ and $\mathcal P(S)$, where each function is the characteristic function of the subset in $\mathcal P(S)$ with which it is identified. I don't understand the start of the sentence,""By identifying a function in $2^S$ with the corresponding preimage of $1$"".  I can make out some sense out of the rest.  Please help.",['elementary-set-theory']
1115777,Defining a distribution,"We fix the space $\mathcal{D}=\mathcal{C}^\infty_0(\mathbb{R}^n)$ as space of testfunctions. Let $(f_n)$ be a sequence of distributions with $\lim_{n\to\infty} f_n(\varphi)$ existing for all $\varphi\in\mathcal{D}$. Define $f(\varphi):=\lim_{n\to\infty} f_n(\varphi)$. Then the claim is that $f$ is also a distribution.
My question: For proving that this holds, how to see that $f$ is continuous w.r.t convergence in $\mathcal{D}$?
(We define a sequence $(\varphi_n)$ in $\mathcal{D}$ to converge to some $\varphi\in\mathcal{D}$ iff there is some compact set $K\subset\mathbb{R}^n$, s.t. $\mathrm{supp}(\varphi_n)\subset K$ for each $n\in\mathbb{N}$ and $\|D^k\varphi_n-D^k\varphi\|_\mathrm{sup}\to 0$ as $n\to\infty$ for each $k\in\mathbb{N}_0^n$.)
Thanks!","['distribution-theory', 'functional-analysis', 'partial-differential-equations']"
1115788,do you need $P$ prime to show that $R/P$ is a PID if $R$ is a PID?,"My question relates to this question , which is exercise 3 in Section 8.2 of Dummit and Foote. They ask to prove that a quotient of a PID by a prime ideal is again a PID. The answers to the previous question point out that in a PID $R$ a prime ideal is maximal, the quotient is a field, and any field is a PID since its only ideals are $0=(0)$ and $R=(1)$. Fine, but before I turned to SE I undertook to answer this is on my own, and I came up with the following argument: Let $P$ be an ideal of PID $R$, $\bar R=R/P$ the quotient, $\bar I$ any ideal of $\bar R$ and $\varphi$ the natural homomorphism from $R\to\bar R$. By the lattice isomorphism theorem $I=\varphi^{-1}(\bar I)$ is an ideal of $R$ that contains $P$. Since $R$ is a PID, there is an $a\in R$ such that $I=(a)$. Now let $\bar b$ be any element of $\bar I$, and $b$ a representative of $\bar b$ in $R$. Then there is some $r\in R$ such that $b=ra$. Since $\varphi$ is a homomorphism, $\varphi(b)=\bar b=\varphi(r)\varphi(a)=\bar r\bar a$. Therefore $\bar I=(\bar a)$, and $\bar I$ is principal. Since this argument placed no restrictions on $\bar I$, every ideal of $\bar R$ is principal. $\square$ I was bothered by this because I have always learned that if you don't use everything you're given when solving a problem, you're probably missing something, and I made no use of the information that $P$ is a prime ideal. So here's my question: do you need the fact that $P$ is prime to prove that $R/P$ is a PID? If so, where did I go wrong? Can someone give me a counterexample so I can see where the argument fails? Muchas gracias!","['principal-ideal-domains', 'maximal-and-prime-ideals', 'abstract-algebra']"
1115813,Triple Angle Condition,"Let $ABC$ be a triangle with integral side lengths such that $\angle A=3\angle B$. Find the minimum value of its perimeter. Essentially we want sinb, sin3b, sin4b to have rational ratios (manipulate the sine law). But then we don't actually need sinb to be rational, so that's pretty mysterious. Afterwards just make them integers by multiplying by LCM of denominator.","['geometry', 'trigonometry']"
1115820,$B - A \in S^n_{++}$ and $I - A^{1/2}B^{-1}A^{1/2} \in S^n_{++}$ equivalent?,"Define $S^n_{++}$ to be the set that contains all the positive definite matrices. That is, if $A \in S^n_{++}$, then $A$ is a positive definite matrix. Now suppose that $A,B \in S^n_{++}$ are two positive definite matrices.
How to prove that
$$B - A \in S^n_{++}$$
if and only if
$$I - A^{1/2}B^{-1}A^{1/2} \in S^n_{++}?$$","['matrices', 'linear-algebra', 'svd']"
1116793,A numerical evaluation of $\sum_{n=1}^{\infty}(-1)^{\frac{n(n+1)}{2}}\frac1{n!}\int_0^1x^{(n)} dx$,"I would like to obtain a numerical evaluation of the series
$$S=\sum_{n=1}^{\infty}(-1)^{\frac{n(n+1)}{2}}\frac1{n!}\int_0^1x(x+1)\cdots(x+n-1)\: dx$$ to five significant digits. I've used Mathematica, but some results puzzle me:
$$\text{NSum}\left[(-1)^{\frac{n*(n+1)}{2}}*\frac{\int_0^1 \text{Pochhammer}[x,n] \, dx}{n!},\{n,1,23\}\right]=-0.530724...$$
$$\text{NSum}\left[(-1)^{\frac{n*(n+1)}{2}}*\frac{\int_0^1 \text{Pochhammer}[x,n] \, dx}{n!},\{n,1,24\}\right]=-0.298186...$$
Any help is welcome.","['sequences-and-series', 'calculus', 'integration', 'mathematica', 'numerical-methods']"
1116794,Is the distribution of the orders of the cyclic groups generated by elements of $S_n$ known?,"A week ago I was playing around with a card-shuffle method corresponding to an element of $S_{52}$ , and the order of the cyclic group generated was 272 (ie, 272 shuffles returns the deck to original order). I was curious as to whether this was higher or lower than expected. A full calculation would require computing the orders of the cyclic groups generated by all $52!$ elements of $S_{52}$, which is computationally infeasible, so instead I ran a Monte-Carlo simulation of the orders of the cyclic groups generated by uniformly-distributed randomly-chosen elements of $S_{52}$: dat52 = ParallelTable[
   GroupOrder[PermutationGroup[{RandomPermutation[52]}]], {10^6}]; Here is a coarse log-$x$-axis histogram of the results: Histogram[dat52, ""Log""] The spike near 40 is not a statistical artifact; the results are only perturbed by $1/\sqrt{N}$ noise, which in this case is astronomically tiny (see the $y$-axis). I was curious to see if there was any finer structure, so I made the following histogram-like image (right-click and open in a new tab to see large 4320 x 2320 pixel image): The $x$-axis is logarithmic as before, and the $y$-axis goes up to about 24,000 counts (not labeled). As you can see, there is a lot of fine structure in the distribution of group orders. Similarly, here is the histogram profile of the group orders of the elements of $S_{51}$ (full-size is 4320 x 2320 pixels): Here is $S_{53}$ (full-size is 4580 x 2020 pixels): And here is $S_{256}$ (full-size is 10020 x 4020 pixels): Naturally, I'm curious whether there is anything known about these distributions, either structurally (ie, an explicit formula for the distribution counts of $S_n$), or asymptotically (ie, the smoothed profile tends towards so-and-so distribution as $n\to\infty$). Does anyone know, or is this beyond current mathematics? From the comments in this question , it seems like this is a hard problem, but I was still curious as to what extent the structure is explainable.",['group-theory']
1116801,Where can the knight be?,The answer is 33. I get $24$. Because of $8 \cdot 3 = 24$? How can I do this using combinatorics?,"['elementary-number-theory', 'contest-math', 'combinatorics']"
1116850,Connection between the Laplace transform and generating functions,"As I was sitting through a boring lecture rehashing basic techniques to solve ordinary differential equations, I began thinking about the Laplace transform and scribbled down a few ideas that I've copied below. Consider the Laplace transform $\mathfrak{L}\{f\}:=\int_0^\infty e^{-st}f(t)~dt$ on a smooth function $f$ such that there exists some $s_0\in\mathbb{C}$ such that $e^{-s_0t}f(t)\to0$ as $t\to\infty$ (I believe it is sufficient to require $f$ is of exponential type). By integration by parts, it follows $$\mathfrak{L}\{f\}=s^{-1}f(0)+s^{-2}f'(0)+s^{-3}f''(0)+\dots=s^{-1}\sum_{n=0}^\infty f^{(n)}(0)~s^{-n}$$ In other words, the Laplace transform behaves like a map from $f$ to the generating function of $(f^{(n)}(0))_{n\in\mathbb{N}}$ at $t=0$. For example, consider a straightforward linear constant-coefficient ODE in $f$, say $f''-2f'+f=0$. 'Applying' the Laplace transform, we get: $$s^{-1}\sum_{n=0}^\infty f^{(n+2)}(0)~s^{-n}-2s^{-1}\sum_{n=1}^\infty f^{(n+1)}(0)~s^{-n}+s^{-1}\sum_{n=0}^\infty f^{(n)}(0)~s^{-n}=0\\s^{-1}\left(s^2\sum_{n=2}^\infty f^{(n)}(0)~s^{-n}\right)-2s^{-1}\left(s\sum_{n=1}^\infty f^{(n)}(0)~s^{-n}\right)+s^{-1}\sum_{n=0}^\infty f^{(n)}(0)~s^{-n}=0\\s\left(\sum_{n=0}^\infty f^{(n)}(0)~s^{-n}-f(0)-f'(0)s^{-1}\right)-2\left(\sum_{n=0}^\infty f^{(n)}(0)~s^{-n}-f(0)\right)+s^{-1}\sum_{n=0}^\infty f^{(n)}(0)~s^{-n}=0\\(s^2-2s+1)s^{-1}\sum_{n=0}^\infty f^{(n)}(0)~s^{-n}=sf(0)+f'(0)+2f(0)\\s^{-1}\sum_{n=0}^\infty f^{(n)}(0)~s^{-n}=\frac{sf(0)+f'(0)+2f(0)}{s^2-2s+1}$$ This so far agrees with the elementary result found using the basic properties of the Laplace transform and, in fact, with the standard method of solving recurrence relations using generating functions. Indeed, it seems as though the Laplace transform is simply the method of generating functions applied to the sequence $(f^{(n)}(0))_{n\in\mathbb{N}}$ (over which the ODE reduces to a recurrence relation). However it seems almost necessary that for this interpretation to work, the function's behavior over the domain of interest must be fully described by its derivatives at $t=0$, i.e. $f$ must be analytic. What can be concluded from the above? Is this a valuable approach to looking at the Laplace transform?","['generating-functions', 'ordinary-differential-equations', 'laplace-transform', 'recurrence-relations']"
1116873,"Integrating $\int_{\sqrt{2}}^2 \frac{1}{t^3\sqrt{t^2-1}}\,dt$.","I am trying to compute
$$
\int_{\sqrt{2}}^2 \frac{1}{t^3\sqrt{t^2-1}}\,dt.
$$ This is what I got so far: $t=\sec(x)$ and $dt=\sec(x)\tan(x)x\,dx$ So plugging this in gives me 
$$
\int \frac{1}{\sec^3(x)}\cdot\sqrt{\sec^2(x)-1}\sec(x)\tan(x)\,dx.
$$
By my trig property $1+\tan^2(x)=\sec^2(x)$, I get
$$
\int \frac{1}{\sec^3(x)\tan(x)}\sec(x)\tan(x)\,dx.
$$
Then I simplify and get
$$
\int \frac{1}{\sec^2(x)}\,dx.
$$
By the trig property I get
$$
\int\cos^2(x)\,dx.
$$
Then I get $(x/2)+(1/4)\sin(2x).$ So now I need to get back to my original variable so I solve for $x$: $t=\sec(x)$ and $x=\mathrm{arcsec}(t)$. It's this part I'm confused about. I don't know what step to take next. I know I am supposed to draw my triangle, I just don't know how to get there.","['definite-integrals', 'trigonometry', 'calculus', 'integration']"
1116893,Origin of $\sigma$-algebra,"In what paper, article or book was the notion of an $\sigma$-algebra first defined or mentioned? Or at least how far could this concept traced back?","['probability-theory', 'measure-theory', 'reference-request']"
1116911,Difference between total orthonormal set and basis,"I'm learning about Hilbert spaces and related things from the book ""Introductory functional analysis with applications"". Now I just read the following sentence, which I don't quite understand: ""A total orthonormal family in $X$ is sometimes called an orthonormal basis for $X$. However, it is important to note that this is not a basis, in the sense of algebra, for $X$ as a vector space, unless $X$ is finite dimensional."" But I think that a total orthonormal sequence must be a Schauder basis, basically just from the definition. So does the author just mean that the basis is not a Hamel basis? Or is there something more subtle going on here that I'm not seeing?","['hilbert-spaces', 'functional-analysis']"
1116928,Counterexample for generating function?,"This is Exercise 3.1.2 from Achim Klenke: »Probability Theory — A Comprehensive Course«. Exercise: Give an example for two different probability generating functions that coincide at countably many points $x_i \in (0,1), i \in \mathbb{N}$. I have no idea how this example should look like. To remind you, a generating function $\psi_X$ of a random variable $X$ is defined as
\begin{align*}
  \psi_X&\colon [0, 1] \rightarrow [0,1] \\
  z & \mapsto \sum_{n=0}^\infty \mathbf{P}[X=n]\, z^n \,.
\end{align*} I believe this exercise hasn't that much to do with probability theory. Just imagine the $\mathbf{P}[X=n]$ are numbers in $[0, 1]$, all adding up to 1, then it's a real analysis question. Can anyone help me? Thank you!","['probability-theory', 'power-series', 'generating-functions', 'real-analysis']"
1116949,Courant minimax principle on block matrix,"in going through some books about numerical mathematics I found the following exercise: Let $A,B \in \mathbb{R}^{n\times n}$ with $A$ symmetrical and rank( $A$ ) = rank(B) = $n$ . Define $M =
\left[\begin{matrix}
A & B \\
B^T & 0
\end{matrix}\right]
$ . The statement now is, that $M$ has exactly $n$ positive and $n$ negative eigenvalues. And to prove it one should use the Courant minimax principle. First we can see, that $M$ ist symmetrical, so Courant minimax principle is actually applicable for $M$ . As the eigenvalues given by the minimax principle are ordered ( $\lambda_1 \geq \lambda_2 \geq \dots \geq \lambda_{2n}$ ) we only have to consider two of them: $\lambda_n$ and $\lambda_{n+1}$ . If $\lambda_n$ is positive and $\lambda_{n+1}$ negative, then the statement is proven right. And this is where my problems begin. The Courant minimax principle gives that $\lambda_k = \max\limits_{U \in \mathcal{U}_k} \min\limits_{x \in U, ||x|| = 1}{x^T M x}$ , where $\mathcal{U}_k = \{ U \subset \mathbb{R}^{2n} | \dim{U} = 2n + 1 -k\}$ . I can't figure out how to make any kind of estimate for the value of $\lambda_k$ (in particular for $k = n$ and $k = n+1$ ) given how little we know about the matrix $M$ or it's components $A$ , and $B$ .","['eigenvalues-eigenvectors', 'symmetric-matrices', 'matrices', 'linear-algebra', 'block-matrices']"
1116954,All Two by Two Matrices Satisfy a Certain Property Problem,"Show that if $A$, $B$ are $2 \times 2$ matrices over $\mathbb{R}$ then there exists a real number $\lambda$ so that $$ (AB-BA)^2 = \lambda I $$ I can do this problem using brute force (i.e. looking at $A$ and $B$ element-wise), but I know there has to be a different, clever way. It was on an old qualifier, and I know they would not be looking for a solution using element wise entries.","['matrices', 'linear-algebra']"
1116974,Why it's true? $\arcsin(x) +\arccos(x) = \frac{\pi}{2}$,"The following identity is true for any given $x \in [-1,1]$:
$$\arcsin(x) + \arccos(x) = \frac{\pi}{2}$$ But I don't know how to explain it. I understand that the derivative of the equation is a truth clause, but why would the following be true, intuitively? $$\int^{x}_{C1}\frac{1\cdot dx}{\sqrt{1-x^{2}}} + \int^{x}_{C2}\frac{-1 \cdot dx}{\sqrt{1-x^{2}}} =\\
 \arcsin(x) - \arcsin(C1) + \arccos(x) - \arccos(C2) = 0 \\
 \text{while } \arcsin(C1) + \arccos(C2) = \frac{\pi}{2}$$ I can't find the right words to explain why this is true? Edit #1 (25 Jan, 20:10 UTC): The following is a truth clause:
$$
\begin{array}{ll}
\frac{d}{dx}(\arcsin(x) + \arccos(x)) = \frac{d}{dx}\frac{\pi}{2} \\
\\
\frac{1}{\sqrt{1-x^{2}}} + \frac{-1}{\sqrt{1-x^{2}}} = 0
\end{array}
$$ By integrating the last equation, using the limits $k$ (a constant) and $x$ (variable), I get the following: $$
\begin{array}{ll}
\int^x_k\frac{1}{\sqrt{1-x^{2}}}dx + \int^x_k\frac{-1}{\sqrt{1-x^{2}}}dx = \int^x_k0 \\
\\
\arcsin(x) - \arcsin(k) + \arccos(x) - \arccos(k) = m  \text{ (m is a constant)}\\
\\
\arcsin(x) + \arccos(x) = m + \arcsin(k) + \arccos(k) \\
\\
\text{Assuming that } A = m + \arcsin(k) + \arccos(k) = \frac{\pi}{2} \text{ ,for } x \in [-1,1]
\end{array}
$$
Using Calculus , why is that true for every $x \in [-1,1]$? Edit #2: A big mistake of mine was to think that $\int^x_k0 = m \text{ (m is const.)}$, but that isn't true for definite integrals. Thus the equations from ""Edit #1"" should be as follows:
$$
\begin{array}{ll}
\int^x_k\frac{1}{\sqrt{1-x^{2}}}dx + \int^x_k\frac{-1}{\sqrt{1-x^{2}}}dx = \int^x_k0 \\
\\
\arcsin(x) - \arcsin(k) + \arccos(x) - \arccos(k) = 0\\
\\
\arcsin(x) + \arccos(x) = \arcsin(k) + \arccos(k) \\
\\
A = \arcsin(k) + \arccos(k) = \frac{\pi}{2} \text{ ,for } x \in [-1,1]
\end{array}
$$","['definite-integrals', 'calculus']"
1116982,Definition of gradient?,"Reference: A primer of nonlinear analysis - Antonio & Giovanni Let $H$ be a hilbert space over $\mathbb{K}$ and $U$ be open in $H$ and $p\in U$ and $f:U\rightarrow \mathbb{K}$ be a functional Fréchet differentiable at $p$. By Riesz Representation theorem, there exists a unique $y\in H$ such that $\forall x\in H$, $Df(p)(x)=<x,y>$. Is $y$ the gradient of $f$ at $p$?","['functional-analysis', 'definition']"
1117029,Properties of the matrix square root,"In a paper I am reading, it is claimed that if $A, B \in \mathbb{R}^{n \times n}$ are positive definite, then
$$ A^{1/2} (A^{−1/2} B A^{−1/2})^{1/2} A^{1/2} = A (A^{-1}B)^{1/2} $$
because of the properties of the principal matrix square root, but I am not sure how this equality can be proved. Has anybody got a hint?","['matrix-equations', 'matrices']"
1117032,Elementary proof of compact space = exhaustible space?,"(This is a repost of a question I asked last year on cs.stackexchange .) The work of Martín Escardó has demonstrated close parallels between classical topology on one hand and computability on the other hand.  (See for example "" Infinite sets that admit fast exhaustive search "" 22nd Annual IEEE Symposium on Logic in Computer Science (2007)  443–452)
Escardó identifies continuous functions with computable functions, and open sets with recursively enumerable sets. Another identification is between the exhaustible sets on one hand and compact sets on the other.  A set $S$ is exhausible if, given a total predicate $P:S\to\mathbf{Bool}$, one can always decide whether $P$ holds for every element of $S$.  According to Escardó, there is a close relationship between exhaustible and compact sets.  For example: Finite sets are both compact and also obviously exhaustible. The natural numbers are not compact and are not exhaustible. (If they were, we could solve the halting problem.) But the one-point compactification of the naturals is exhaustible. The Cantor set of all sequences of booleans, that is all functions $f:\Bbb N\to\mathbf{Bool}$ is both compact and exhaustible. I have found the discussion of compactness in Escardó's papers very hard to follow, with many forward references.  The nearest thing to a proof that I can identify is in section 8 of his notes on "" synthetic topology of data types "". The proof in chapter 8 is very advanced.  In these notes compactness is initially defined to be exhaustibility, which doesn't make it easier to follow what is going on. My question is: I keep hoping for an elementary proof, one which relates the conventional definition of compactness, in terms of open covers, to exhaustibility. I have not been able to find one myself and I have not been able to extract one from Escardó's papers.  Is there such a proof?","['general-topology', 'type-theory', 'computer-science', 'compactness']"
1117061,Finding all possible combination **patterns** - as opposed to all possible combinations,"I start off with trying to find the number of possible combinations for a 5x5 grid (25 spaces), where each space could be a color from 1-4 (so 1, 2, 3, or 4) I do 4^25 = 1,125,899,906,842,624 different combinations However, now I'm trying to change the number of combinations to account for grids with the same number pattern, for example: { 1 1 1 1 1 } { 3 3 3 3 3 } { 4 4 2 2 3 } { 4 3 2 1 1 } { 2 2 1 2 3 } 1 is now 2, 2 is now 4, 3 is now 1, 4 is now 3 { 2 2 2 2 2 } { 1 1 1 1 1 } { 3 3 4 4 1 } { 3 1 4 2 2 } { 4 4 2 4 1 } I'm having trouble trying to come up with an equation I can use to solve this for a (x * y) grid where each space could be a color from 1 to (c).",['combinatorics']
1117070,Finding $\mathbf{10}\otimes \mathbf{8}\otimes \mathbf{8}\otimes \mathbf{8}$ in $SU(3)$,"I know that in $SU(3)$
$$\mathbf{8}\otimes \mathbf{8} = \mathbf{27}+\mathbf{10}+\mathbf{\bar{10}}+\mathbf{8}+\mathbf{8}+\mathbf{1}. $$ How can one use this to compute $$\mathbf{10}\otimes \mathbf{8}\otimes \mathbf{8}\otimes \mathbf{8}?$$ Can one start with simplifying (dropping the bold notation) $$\tag{1} \mathbf{10}\otimes \mathbf{8}\otimes \mathbf{8} = 10\otimes27
\\
+10\otimes10
\\+10\otimes\bar{10}
\\+10\otimes8
\\+10\otimes8
\\+10\otimes1?$$ Is $(1)$ even ok?","['young-tableaux', 'representation-theory', 'group-theory', 'physics']"
1117072,Blockwise Symmetric Matrix Determinant,"This question arises from another one of mine , but separate enough that I feel it deserves its own thread. Wikipedia says that $$det\begin{bmatrix}A&B\\B &A \end{bmatrix} = det(A+B)det(A-B)$$ Regardless of whether or not A and B commute. Using the general formulation $$det\begin{bmatrix}A&B\\C &D \end{bmatrix} = det(A)det(D - CA^{-1}B)$$ We see that this becomes $$det(AD- ACA^{-1}B)$$ Or for my original matrix, $$det(AA - ABA^{-1}B)$$ I see how this becomes det((A-B)(A+B)) if A and B commute, but how is it valid if they don't commute? Can anyone prove this please?","['matrices', 'linear-algebra', 'proof-verification', 'determinant']"
1117074,Moving the integral $Q(x) = -\frac{e^{-1/2x}}{4i}\int_{1/2-i\infty}^{1/2+i\infty} \zeta(s)\Gamma(\frac{s}{2})\pi^{-s/2}e^{xs} ds$ past Re(s) = 1.,"Given the integral $$Q(x) = -\frac{e^{-1/2x}}{4i}\int_{1/2-i\infty}^{1/2+i\infty} \zeta(s)\Gamma(\frac{s}{2})\pi^{-s/2}e^{xs} ds,$$ I know that the integrand is holomorphic except for simple poles at s = 0 and s =1.  Supposedly, after accounting for the residue at s = 1, for all $\sigma > 1$, the integral can be moved, from Re(s) = 1/2 to Re(s) = $\sigma$ so that $$Q(x) = -\frac{e^{-1/2x}}{4i}\int_{\sigma - i\infty}^{\sigma + i\infty} \zeta(s)\Gamma(\frac{s}{2})\pi^{-s/2}e^{xs} ds + \frac{e^{-1/2x}}{4i}2\pi iRes[\zeta(s)\Gamma(\frac{s}{2})\pi^{-s/2}e^{xs}].  $$ I understand the Residue Theorem, but I still do not understand understand why we can move the integral from Re(s) = 1/2 to Re(s) = $\sigma$. My guess is that if we consider rectangular contour shown in the picture below, then we want to show that as $T \to \infty$, that the integrals over the horizontal sides of the rectangle approach 0. If that is the case, then the statement follows from the Residue Theorem.  Those latter details I have already worked out.  Can anyone help?  Is there an upperbound for $\zeta(s)$ and $\Gamma(\frac{s}{2})$ in this region that I am missing?","['riemann-zeta', 'zeta-functions', 'analytic-number-theory', 'gamma-function', 'complex-analysis']"
1117083,Show an $R$-module is a direct limit,"This is a scenario I've encountered in my class on $p$-adic L functions.  Let $G$ be a profinite group which is the inverse limit of a system $(G_i, f_{ij})$ of discrete finite topological groups.  For a commutative ring $R$, let $C(G_i,R)$ be the $R$-module of functions $G_i \rightarrow R$, and let $C^{\infty}(G,R)$ be the $R$-module of continuous functions from $G$ to $R$ which are everywhere locally constant (for each $x \in G$, there is a neighborhood of $x$ on which $f$ is constant; this is the same thing as saying that $f$ takes only finitely many values). For the projections $\pi_i:G \rightarrow G$, one takes the map $\phi_i: C(G_i,R) \rightarrow C^{\infty}(G,R)$ given by $\phi_i(\alpha) = \alpha \circ \pi_i$ (it's easy to see that $\alpha \circ \pi_i$ is actually locally constant), and for the maps $f_{ij}: G_j \rightarrow G_i$ for $i \leq j$, one takes the corresponding $R$-module homomorphisms $\tau_{ij}: C(G_i,R) \rightarrow C(G_j,R)$. The claim is that $C^{\infty}(G,R)$ is the direct limit of the direct system $(C(G_i,R), \tau_{ij}$) But I don't know where to start.  With the universal mapping property, it's not obvious how to define a map from $C^{\infty}(G_i,R)$.","['general-topology', 'homological-algebra', 'group-theory', 'p-adic-number-theory']"
1117124,Obtaining a single-valued branch of $\ln \left( \frac{z-a}{z-b} \right)$ with a branch cut,"It is rather easy to see that the function $$f(z) = \ln \left( \frac{z-a}{z-b} \right)$$ has branch points at $z=a$ and $z=b$, My question is why considering a branch cut ""connecting"" $a$ and $b$ makes this function single-valued ? For simplicity suppose $a=1$ and $b=-1$ are both real. a  real number $c=2$ which is bigger than $a$ and $b$ , hence, does not lie on the branch cut, therefore it is not a singular value of $f(z)$ ! (I can not understand this, because $z=2$ can be represented in so many ways for $\theta_1 := \arg (z-1)$ and $\theta_2 = \arg (z+1)$) Is this onkay, only because we can define sheets in a way that, on each sheet everything works nicely...? Let me try that, suppose we consider a branch cut which connects $1$ to $-1$ and consider the following sheets for the Riemann surface of $f(z)=\ln \left( \frac{z-1}{z+1} \right)$: first sheet : $ - \pi < \theta_1 \leq \pi$ and $ 0 \leq \theta_2 < 2\pi$ second sheet : $  \pi < \theta_1 \leq 3\pi$ and $ 2 \pi \leq \theta_2 < 4\pi$ and so on ... If I consider $z=2$ on the first sheet : $\theta_1 = \theta_2 = 0$, so $\arg(\frac{2-1}{2+1}) = 0-0 =0$ If I consider $z=2$ on the second sheet : $\theta_1 = \theta_2 = 2\pi$, so $\arg(\frac{2-1}{2+1}) = 2\pi-2\pi =0$ Therefore for a very special way of defining the sheets $z=2$ is a regular point for $f(z)$, right ? I would be very thankful if you correct any incorrect statement/conclusion in what I wrote above.","['riemann-surfaces', 'complex-analysis']"
1117139,What exactly are pseudovectors and pseudoscalars? And where could I read about them?,"I can't find good information on the internet. In my mathematical physics class the definition of a vector was given as: That object with magnitude and direction which doesn't change under inversions. Pseudovectors do change. Scalars are that magnitude that don't change with inversions. Pseudoscalars do change. Inversions were loosely defined as inverting all components of a vector. The examples were given as: Say $\vec{A}=\vec{B}\times\vec{C}$; under the inversion it becomes $\vec{-B}\times\vec{-C}$ which is again, $\vec{A}$ which then has to be a pseudovector. Say $A=\vec{a}\cdot\vec{b}\times\vec{c}$ then under inversion $\vec{-a}\cdot\vec{-b}\times\vec{-c}$, which is $-A$ and has to be a pseudoscalar. I don't get it though. Why are inversions done on the individual vectors and not to the whole product? What really is an inversion? Where could I read more about this? Thanks.","['mathematical-physics', 'linear-algebra', 'vector-analysis']"
1117168,Independence of a Stochastic Process at Distinct Time,"Suppose $X_t$ is a stochastic process of $t$ on $[0,\infty)$ with almost surely continuous sample path. Does $X_t$ have to be almost surely deterministic and almost surely continuous in $t$ so that $X_{t_1}$ and $X_{t_2}$ are independent of each other for arbitrary and distinct $t_1$ and $t_2$ ?","['probability-theory', 'stochastic-processes']"
1117170,Extending Taylor's theorem from one to several variables,"In my calculus class we are dealing with Taylor´s theorem in several variables. When we were looking at the function $f(x,y)=\sin(xy)$ my teacher said that instead of applying the theorem in several variables we can just apply Taylor´s theorem in one variable and then replace the variable by $xy$: $$\sin(t)=t-{t^3\over 3!}+{t^5\over 5!}+ R_5(t)$$ which yields: $$\sin(xy)=xy-{(xy)^3\over 3!}+{(xy)^5\over 5!}+ R_5(xy)$$ My question is: when can we do this kind of replacement? What conditions does the function must satisfy? Or we just do it whenever we can? I would really appreciate your help :)","['multivariable-calculus', 'taylor-expansion']"
1117187,Can we find the inverse for a vector?,"Can we invert a vector like we do with matrices, and why? I didn't see in any linear algebra course the concept of the ""vector inverse"", and I was wondering if there is any such thing, and if not, why.","['matrices', 'linear-algebra', 'inverse', 'vectors']"
1117196,What is the derivative of the floor function? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question What is the derivative of the following equation? $$f(x) = \left \lfloor \frac{c}{x} \right \rfloor$$ $c,x$ are positive integers, and $\lfloor \cdot \rfloor$ is the floor function. Does the floor function play any role here? Will it be equal to the floor of the derivative?","['derivatives', 'ceiling-and-floor-functions']"
1117224,Paul Erdős showed a simple estimate for $\pi(x) \ge \frac{1}{2}\log_2 x$; is it possible to tweak his argument to improve the estimate?,"Paul Erdős gave a simple argument to show that $\pi(x) \ge \dfrac{1}{2}\log_2 x$. Is it possible to tweak the argument and get a better estimate?  I am wondering how good an estimate for $\pi(x)$ can be achieved using a variation of his reasoning. I explored the possibility of changing $m^2$ to $m^3$ so that we have for any $y \le x$, we have: $y = p_1^{e_1}p_2^{e_2}\ldots p_n^{e_n}m^3$ and $e_i\in\left\{0,1,2\right\}$ and $m \in \mathbb{Z}$ But this gets us to:  $m \le \sqrt[3]{x}$ so that $3^n\times \sqrt[3]{x} \ge x$ and $\pi(x) \ge \dfrac{2}{3}\log_3 x$ which is weaker than $\pi(x) \ge \dfrac{1}{2}\log_2 x$ Has anyone thought of other creative tweaks that can improve the result?","['prime-numbers', 'number-theory']"
1117232,Any advice on simplifying this nasty integral,"Can anyone think of any smart way of approximating this nasty integral
$$F = \int_{-c}^c f_X(x) \, dx $$ where $c$ is a non-negative constant (for example $\frac{1}{64}$) and where the integrand is given by $$f_X(x)= \int_{\max\{-1,-1-x\}}^{\min\{1,1-x\}} \left( \frac{1}{\pi^2\sqrt{1-(x+y)^2}} \frac{1}{\sqrt{1-y^2}}\right) \, dy$$ I would really like to avoid numerical integration. Can anyone think of any simplifications that can reduce the complexity of my problem. Please read comments below on why I have such a problem in the first place... Thanks",['integration']
1117241,Propositional Logic : Absorption - Why is it so?,Why is the Absorption Law of Propositional Logic so ? p $\lor (p \land q) \equiv$ p Would appreciate an intuitive explanation and not one using a Truth Table,"['logic', 'propositional-calculus', 'discrete-mathematics']"
1117261,Prove that $7n^2 + 2n + 3 = O(n^2)$ using the definition of O notation.,"Prove that $7n^2 + 2n + 3 = O(n^2)$ using the definition of O notation. I need to use two constants and prove that they satisfy the O definition. I'm new to big O and want to know whether I am approaching the problem the right way. Is below how I prove the problem? If not, what do I need to keep in mind or what should I do differently? I'm basing my answer off of what I've been reading, so I could be way off. Proof: by the big-oh definition, $T(n)$ is $O(n^2)$  if $T(n) \leq c * n^2$ for some $n \geq n_0$ . Let us check this condition: if $7n^2 + 2n + 3 \leq c * n^2$ then $7 + 2/n^2 + 3/n^2 \leq c.$ Therefore, the big oh condition holds for $n \geq n_0 = 1$ and $c \geq 12 (= 7 + 2 + 3)$","['asymptotics', 'discrete-mathematics']"
1117281,"Where is the ""thread"" of a river?","Lawyers speak of the ""thread"" of a river.  When the boundary between two counties or states is a river, it is usually the ""thread"" of the river, a path running along the center of the river.  (In England, I suspect this has applied primarily to boundaries between counties.)  If a line is drawn from a point on one bank to a corresponding point on the opposite bank, one can take the midpoint to be a point on the ""thread"", but which point on the opposite bank is the corresponding point when the river meanders erratically, as they all do (but some more than others) ? I am inclined to doubt that lawyers have clearly answered this, and to suspect that some substantial components of any reasonable answer can be contributed only by mathematicians. Exceptions include: The northern boundary of Kentucky.  The whole of the Ohio River is in Kentucky; the states north of it, Ohio, Indiana, and Illinois, begin at the north bank.  I think this goes back to an act of Parliament after the Seven Years' War in 1763, declaring the Ohio to be the southern boundary of Canada, which became an English colony at that time.  (This is alluded to in the language about a ""fit instrument"" in the Declaration of Independence.) The boundary between Delaware and New Jersey, which puts the Delaware River entirely in Delaware, so that New Jersey begins at the west bank. The boundary between Vermont and New Hampshire (surely the most colorful story of weird politics in the history of the U.S.A., if not of the Universe).  The Connecticut River is in New Hampshire; Vermont begins at the west bank.  On July 20, 1764, King George III decreed this after a scandalously ex-parte hearing, with the later result that the half of the Constitution of Vermont before its amendment-in-its-entirety in 1793 was a list of grievances against the government of New York, and the further later result that in a lawsuit that lasted from 1915 through 1933, a federal court ended up upholding the King's decision. But dozens of boundaries between states in the U.S.A. follow the ""thread"" of a river, if I'm not mistaken.","['cartography', 'geometry']"
1117282,When is the symmetric algebra of a vector bundle finitely-generated?,"Let $X$ be a projective variety over a field $k$, and $\mathcal L$ a vector bundle on $X$, i.e. a locally free $\mathcal O_X$-module of finite rank. For each $n\geq 0$, $\text{Sym}^n \mathcal L$ is a vector bundle on $X$, hence $H^0(X, \text{Sym}^n \mathcal L)$ is a finite-dimensional $k$-vector space. Consider the graded $k$-algebra $$(\text{Sym } \mathcal L) (X) := \bigoplus_{n=0}^\infty H^0(X, \text{Sym}^n \mathcal L).$$ What kind of conditions on $X$ and $\mathcal L$ ensure that this algebra is finitely-generated? Is it always the case?","['algebraic-geometry', 'vector-bundles']"
1117298,Is annihilator of maximal submodule is a maximal ideal?,"Let $R$ be a commutative ring with identity element and $M$ is an $R$-module. We know the annihilator of a submodule $N$ of $M$ ($I=(N:M)$) is an ideal in $R$. If $N$ is a maximal submodule of $M$, is ideal $I$ (annihilator of $N$ in $M$) maximal in $R$?","['modules', 'maximal-and-prime-ideals', 'abstract-algebra']"
1117299,Change of variables in multi-variable calculus?,"About the last equality, I know it is change of variables. Let $\xi=x+t,\eta=-x+t$, but I don't know how to get the integration domain? I have been thinking for an hour and I can't get the result? Can anyone help me about this? Thanks so much!","['multivariable-calculus', 'calculus']"
1117304,Composed of non differentiable functions,It will be possible to find a function $f:\mathbb{R}\rightarrow \mathbb{R}$ non-differentiable at zero such that $f\circ g$ is differentiable at zero where $g:\mathbb{R}\rightarrow \mathbb{R}$ is $g(s)=\sqrt[3]s$? I appreciate any suggestion,"['functions', 'calculus', 'real-analysis', 'analysis']"
1117306,When is the probability of countable union equal to the limit of probabilities of finite unions?,"Lets say there are arbitrary sequence of sets $A_i$. When does the following below equation hold?, i.e., what specific properties of $A_i$ would make it invalid $$P\left(\lim_{n \to \infty} \bigcup_{i=1}^{n} A_i\right) = \lim_{n \to \infty}P\left(\bigcup_{i=1}^{n} A_i\right)$$","['probability', 'limits']"
1117323,The definition of continuously differentiable functions,"When we say $f \in C^1$ , we mean that $f$ is continuously differentiable. Isn't the continuity a redundant word? I mean, we have a theorem that says if $f$ is differentiable then it is continuous. So why in most of the textbooks they always mention them two? So these are all equivalent: $f \in C^1$ $f$ is continuously differentiable $f'$ exists","['continuity', 'derivatives', 'real-analysis', 'definition']"
1117366,How to compute the sum of geometric distribution [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 9 years ago . Improve this question How to compute the sum of random variables of geometric distribution
$X_{i}(i=0,1,2..n)$ is the independent random variables of geometric distribution, that is, $P(X_{i}=x)=p(1-p)^{x}$, then how to compute the PDF of $\sum_{i=1}^{n}X_{i}$ a negative binomial distribution $P(Y)=\binom{r+y-1}{y}p^{r}(1-p)^{y}$, 
Prove that sum of random variables of geometric distribution become a negative binomial distribution?
how to do this deduction?? can help here? Thanks!!!","['statistics', 'probability-distributions', 'random-variables']"
1117370,"How to draw a contour map of $ f(x,y)=x^2+y^2+xy$","I have used a program to see that it is an ellipse but I want to know the process of thinking to actually draw the contour map myself. $x^2+y^2+xy=C$ for $C=0,1,2,3,...$ I can't seem to get it into an ellipse form. What should I do?
Thanks!",['multivariable-calculus']
1117376,variations of Kuratowski closure complement theorem,"I have been reading about the Kuratowski closure-complement theorem from the paper ""THE KURATOWSKI CLOSURE-COMPLEMENT THEOREM  by B.J. Gardner and M. Jackson'. It states that: If $(X,\tau)$ is a topological space and $A \subseteq X$ then at most 14 sets can be obtained from $A$ by taking closures and complements.
Also a direct consequence of this theorem is given which says: When we apply closure and interior on $A \subseteq X$ we get at most 7 sets.This is due to the simple relation $i=kck$ where $i,k,c$ denotes interior,complement,closure operators respectively. Also a figure is given on page 7 of above mentioned paper depicting the interrelationship between the different sets generated. Presently I was interested in knowing some variations of this theorem. I went through the paper by ""VARIATIONS ON KURATOWSKI’S 14-SET THEOREM by DAVID SHERMAN"" along with the above mentioned paper.I came across the following result: If $(X,\tau)$ is a topological space and $A \subseteq X$ then at most 35 sets can be obtained from $A$ by taking closures, interiors, unions, intersections.
Also a diagrammatic representation was given in the paper by Gardener and Jackson on page 36 which depicts the interrelationship between the various sets generated by applying closure, intersection, unions, interior. It shows the containments between the different sets while moving from bottom to top.I have been completely stuck at this figure. I cannot proceed to recognize the various points which correspond to the various operators that are obtained by composing $c,i,\wedge,\vee$ where $\wedge,\vee$ denotes the meet and join operators used to represent the intersection and union of sets respectively. If anyone could please help me to proceed with the figure?",['general-topology']
1117388,number of solutions of these equations.,"Find the number of solution for this equation without drawing graph?! Total number of solutions for  $2^{\cos x}=|\sin x|$ in $[-2\pi,5\pi]$ a) $14$ b) $15$ c) $16$ d) $17$ [ans given : $14$] How to solve this type of question within few seconds? Because in competitive exams we will be having too much more to deal with. In some books where quick solving is given for problems, they just draw graph and solutions are considered where curves intersect. And I am not good at drawing more complex graphs. Please solve the given problem step by step. Also give some ideas on quick graph drawing to more difficult equations like the one above, and these given below:- $1$. $\sin\{x\} = \cos\{x\}$ where $\{x\}$ represents fractional part of $x$ in $[0, 2\pi]$ $2$. Number of roots of the equation $x+2\tan x = \dfrac{\pi}{2}$ in the interval $[0, 2\pi]$ $3$. Total number of solutions of $\sin x = \dfrac{|x|}{10}$ How to find solution by graph analysis within few seconds?","['trigonometry', 'algebra-precalculus', 'contest-math']"
1117432,Integral principal value with $\cos$ and $x^2$,"Could you tell me how to solve this integral? $$\int_0^{\infty} \frac{\cos x -1}{x^2}dx$$ I think I should focus on this integral $$\int_{\Gamma} \frac{e^{iz}-1}{z^2+ \varepsilon^2}$$ where $\Gamma$ is a curve = semicircle with radius $R \cup $ segment $[-R, R]$ The integral vanishes on the semicircle. The poles of  $\frac{e^{iz}-1}{z^2+ \varepsilon^2}$ are $\varepsilon i, - \varepsilon i$. So $$\int_{\Gamma} \frac{e^{iz}-1}{z^2+ \varepsilon^2} = 2 \pi i \cdot res_{\varepsilon i} \left(\frac{e^{iz}-1}{z^2+ \varepsilon}\right) = 2 \pi i \frac{e^{- \varepsilon}-1}{2 \varepsilon i} = \frac{\pi (e^{- \varepsilon}-1)}{\varepsilon}$$ We have $\frac{0}{0}$ situation, so we can use de l'Hospital theorem: $$\lim_{\varepsilon \rightarrow 0}  \frac{\pi (e^{- \varepsilon}-1)}{\varepsilon} = \lim _{\epsilon \rightarrow 0}\pi \frac{- \varepsilon e^{- \varepsilon}}{1}$$ But the answer is $\frac{- \pi}{2}$ Could you tell me what I'm doing wrong?","['complex-analysis', 'contour-integration']"
1117435,Integer solutions to $\prod\limits_{i=1}^{n}x_i=\sum\limits_{i=1}^{n}x_i^2$,"Given integers $x_1,\dots,x_n>1$. Let's assume WLOG that ${x_1}\leq\ldots\leq{x_n}$. I want to prove that the only integer solutions to any equation of this type are: $x_{1,2,3  }=3\implies\prod\limits_{i=1}^{3}x_i=\sum\limits_{i=1}^{3}x_i^2=27$ $x_{1,2,3,4}=2\implies\prod\limits_{i=1}^{4}x_i=\sum\limits_{i=1}^{4}x_i^2=16$ I have a partial proof below, but there are a few holes in it that I would be happy to get help with. For $n=1$: $x_1<x_1^2$ $\color{green}{\text{Done.}}$ For $n=2$: ${x_1x_2}\leq{x_2x_2}={x_2^2}<{x_1^2+x_2^2}$ $\color{green}{\text{Done.}}$ For $n=3$ and $x_1=2$: $\color{red}{\text{This seems to be the most difficult case.}}$ $\color{red}{\text{I suspect that there might even be a solution here.}}$ For $n=3$ and $x_{1,2,3}=3,3,3$: $\prod\limits_{i=1}^{3}x_i=27=\sum\limits_{i=1}^{3}x_i^2$ $\color{blue}{\text{This is a solution.}}$ For $n=3$ and $x_{1,2,3}=3,3,4$: $\prod\limits_{i=1}^{3}x_i=36>34=\sum\limits_{i=1}^{3}x_i^2$ $\color{red}{\text{How do we prove that it holds for every }x_i\text{ being replaced with a larger value?}}$ For $n=4$ and $x_{1,2,3,4}=2,2,2,2$: $\prod\limits_{i=1}^{4}x_i=16=\sum\limits_{i=1}^{4}x_i^2$ $\color{blue}{\text{This is a solution.}}$ For $n=4$ and $x_{1,2,3,4}=2,2,2,3$: $\prod\limits_{i=1}^{4}x_i=24>21=\sum\limits_{i=1}^{4}x_i^2$ $\color{red}{\text{How do we prove that it holds for every }x_i\text{ being replaced with a larger value?}}$ For $n>4$ and $x_{1,\dots,n}=2,\dots,2$: $\prod\limits_{i=1}^{n}x_i=2^n>4n=\sum\limits_{i=1}^{n}x_i^2$ can prove by induction $\color{red}{\text{How do we prove that it holds for every }x_i\text{ being replaced with a larger value?}}$ UPDATE: Based on @sciona's comments: For $n=3$ and $x_1=2$, we can show that there are no solutions: $\sum\limits_{i=1}^{n}x_i^2-\prod\limits_{i=1}^{n}x_i=4+x_2^2+x_3^2-2x_2x_3=4+(x_2-x_3)^2>0$ $\sum\limits_{i=1}^{n}x_i^2-\prod\limits_{i=1}^{n}x_i>0\implies\sum\limits_{i=1}^{n}x_i^2>\prod\limits_{i=1}^{n}x_i\implies\sum\limits_{i=1}^{n}x_i^2\neq\prod\limits_{i=1}^{n}x_i$ We can use the solution $(3,3,3)$ in order to generate infinitely many more: If $(a,b,c)$ is a solution, then so is $(b,c,bc-a)$ For example, $(3,3,3)\rightarrow(3,3,6)\rightarrow(3,6,15)\rightarrow\dots$ We can use the solution $(2,2,2,2)$ in order to generate infinitely many more: If $(a,b,c,d)$ is a solution, then so is $(b,c,d,bcd-a)$ For example, $(2,2,2,2)\rightarrow(2,2,2,6)\rightarrow(2,2,6,22)\rightarrow\dots$ So my question narrows-down to proving that there are no other types of solutions.","['sums-of-squares', 'vieta-jumping', 'number-theory']"
1117446,Find the limit without using Maclaurin series,"Find a limit,
$$\lim_{x\to 0} \frac{1-\cos{(1-\cos{(1-\cos x)})}}{x^8}$$
without using Maclaurin series. My attempt was to use L'hopital's rule but that's just too much, and chances of not making a mistake trough repetitive differentiation are very low.","['derivatives', 'real-analysis', 'limits']"
1117488,Number of onto and into group homomorphisms between $\mathbb Z$ and $\mathbb Z$,"How many homomorphisms are there of $\mathbb Z$ onto $\mathbb Z$ $\mathbb Z$ into $\mathbb Z$ These two questions are from exercise 13, from book by John B. Fraleigh. Answer of 1. is ""two homomorphisms"" and 2. is ""infinite number of homomorphisms"". I want to know difference between these, how to approach these problems.",['group-theory']
1117524,Slutsky for joint convergence,"I am interested whether Slutsky's Theorem also holds in the case of joint convergence. Let $(X_n,Y_n)$ be random variables with $(X_n,Y_n) \rightarrow (X,Y)$ in distribution for $n \to \infty$. Furthermore, let $(a_n,b_n) \rightarrow (1,1)$ a.s. for $n \to \infty$. Does also $(X_n*a_n,Y_n*b_n) \rightarrow (X,Y)$ hold in distribution for $n \to \infty$? Many thanks in advance!","['probability-theory', 'weak-convergence']"
1117527,"the boundary value problem: $u''(x)+\lambda u(x)=0,x\in (0,1),$ $u(0)=u(1); u'(0)=u'(1).$","Find all possible $(\lambda,u)$ where $\lambda \in \mathbb R$ and $u\ne0$, to the boundary value problem: $u''(x)+\lambda u(x)=0,x\in (0,1),$ $u(0)=u(1); u'(0)=u'(1).$ My Effort: for $\lambda>0,u(x)=A_n\cos\sqrt\lambda_nx+B_n\sin\sqrt\lambda_nx$, where$\lambda_n=4n\pi^2$(After Calculation), $n=\pm1,\pm2,....$
is it correct? Please verify.What will be the case if $\lambda<0$. I am confused. Please help.","['boundary-value-problem', 'ordinary-differential-equations']"
1117541,Program to find closest function to fit arbitrary data,"I've wanted this for years, but have never come across anything; a program for Windows to find the closest function to fit arbitrary data. The data I feed it is simple: A table with two columns comprising an initial number on the left side, and the converted number on the right. This below is a very simple example. The program should easily be able to see the pattern: 10 -> 110 20 -> 410 30 -> 910 40 -> 1610 So there, the program would find the formula to be x^2+10. More complicated may be something like this: 5 -> 16 7 -> 23 15 -> 250 25 -> 300 35 -> 30000 I made those numbers up. Before anyone brings it up, I know there are an infinite number of functions which will successfully work with the above data (if I didn't say that, I just know someone would jump on my toes for it). However, I want a program, perhaps using genetic programming or advanced B-spline/NURB curve type math to find an accurate (doesn't have to be a perfect) fit, and if at all possible, a small and simple function . The winning function can use addition, multiplication, exponentiation, double exponentiation, or basically anything it fancies to find the function. If the program uses genetic programming, then the GP's fitness function will take into account the simplicity/mathematical steps as a component of overall fitness. Ideally, the program would allow two or more inputs (rather than one) for each output, but I'd be grateful for something which just works with a single input and output as demonstrated in the two examples above. The program should be so simple that even a child could use it.","['regression', 'spline', 'algebraic-curves', 'functions']"
1117561,Does pigeonhole principle apply for all groups (and monoids)?,"I'm reading Rosen 's book and it has a proof to show that a finite subgroup (set) is closed under a composition law. It says for some $i$ and $j$, $i < j$, $a^i = a^j$ i.e, $a^i = a^i \circ a^{j-1}$. I really don't get it. How is this equal? Is the pigeonhole principle applicable to all groups?","['elementary-set-theory', 'pigeonhole-principle', 'group-theory']"
1117583,closed form for a double sum,"How can I prove that $$\underset{k\geq1}{\sum}\left(\underset{m=-\infty}{\overset{\infty}{\sum}}\frac{\left(-1\right)^{m}}{\left(2k-1\right)^{2}+m^{2}}\right)=\frac{\pi\log\left(2\right)}{8}\,?$$I tried possion summation but it seems doesn't work.","['closed-form', 'summation', 'sequences-and-series']"
1117587,Flat algebra over a Dedekind domain,"Let $B$ be a flat algebra over a Dedekind domain $A$. Let $f\in B$ be such that for every maximal ideal $\mathfrak m$ of $A$, the image of $f$ in $B/\mathfrak mB$ is not a zero divisor. How can I show that $B/fB$ is flat over $A$? (Liu, Algebraic Geometry and Arithmetic Curves , Exercise 2.12.)","['maximal-and-prime-ideals', 'abstract-algebra', 'flatness', 'dedekind-domain', 'commutative-algebra']"
1117632,Prove that in a C*-algebra only orthogonal projections can sum to a projection,"Let $A$ be a $C^*$-algebra, and let $p_1, \ldots, p_n \in A$ be projections, meaning $p_i = p_i^* = p_i^2$. Now assume that the sum $p = p_1 + \ldots + p_n$ is also a projection. How can one show that this implies that the $p_i$'s must be orthogonal, i.e. $p_ip_j = 0$ whenever $i \neq j$?","['c-star-algebras', 'functional-analysis', 'projection']"
1117658,Closed form for the summation $\sum_{k=1}^n\frac{1}{r^{k^2}}$,"Is there any closed form for the finite sum $$\sum_{k=1}^n\dfrac{1}{r^{k^2}}$$ or infinite sum ( when $|r|<1$) $$\sum_{k=1}^\infty\dfrac{1}{r^{k^2}} ?$$ While solving this problem, I found this type of finite series. But I have no idea about attempt to this problem. Thank you.","['closed-form', 'sequences-and-series', 'algebra-precalculus', 'real-analysis']"
1117660,How can we think and/or write rigorously about integration by substitution?,"Define a function $I:\mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}$ as follows. $$I(a,b)=\int_a^b \sin t \cos t \,d t$$ Then we can find a more explicit description of $I$ using integration by substitution. So let $u = \sin t$. Then $d u = \cos t \,dt$. Therefore: $$I(a,b) = \int_a^b \sin t \cos t \,d t = \int_{t=a}^{t=b}udu = \left[\frac{1}{2}u^2\right]_{t=a}^{t=b} = \left[\frac{1}{2} \sin^2 t\right]_{t=a}^{t=b}  = \frac{1}{2}\left(\sin^2b-\sin^2 a\right)$$ I'm not confident in our final answer, though; there's just too many dodgy things going on. These include both general issues with integration by substitution, and issues that are somewhat more specific to this problem. General Issues. I've always been a bit uncomfortable with this ""let $u=\sin t$"" stuff, since we never said anything like ""let $t$ denote a fixed but arbitrary real number,"" so the meaning of $t$ is ambiguous. This isn't easily fixed though; we don't want to say ""let $t$ denote a fixed but arbitrary real number"" because moments later, we're going to quantify over $t$ by integrating, so clearly it wasn't fixed. Another general issue is that I don't really know what expressions like $du = \cos t dt$ mean. Under the usual semantics for equations, we would think of this as being true for some pairs $(u,t)$ and false for others. Here, that semantics doesn't work, so its not at all clear to me what is being asserted. Particular Issues. In this particular case, since the function $t \in [a,b] \mapsto \sin t \in \mathbb{R}$ isn't injective for a sufficiently large gap between $a$ and $b$, I'm not even sure we're allowed to perform integration by substitution here. (Are we?) The notation $\int_{t=a}^{t=b}udu$ and $\left[\frac{1}{2}u^2\right]_{t=a}^{t=b}$ just kind of seems kind of ambiguous to me. Does this really make sense? If so, how does one formalize the meanings of these expressions? Question. Suppose we want to conceptualize integration by substitution rigorously, and to apply it rigorously (using unambiguous notation) to find $I(a,b)$ explicitly. How can we do this? Please don't post answers that cleverly avoid using integration by substitution. I want to understand it, not avoid it.","['proof-writing', 'calculus', 'integration', 'definition']"
1117666,"If $\{X_n\}$ converges in probability to $1$, where does $\{1/X_n\}$ converge to?","Without using the continuous mapping theorem, I want to show that, given $\{X_n\}$ is a sequence of random variables converging in probability to $1$, $\{1/X_n\}$ converges in probability to $1$. The place where I am stuck is: how do I know that probabilistically , $1/X_n$ converges? Because after I know that if $1/X_n\overset{p}\to a$ where $a$ is a real number, then I can use the fact that if $X_n$ and $Y_n$ converge in probability to $x$ and $y$ respectively, then $X_nY_n\overset{p}\to xy$. Then taking $Y_n=1/X_n$ the result will be immediate. But how do I know that the new sequence $1/X_n$ converges at all? I would love to use results in real analysis but I am sure they cannot be applied here.","['probability-theory', 'convergence-divergence', 'probability']"
1117679,"Let $G$ be a connected graph, then $G$ is a tree iff $G$ has no cycles","Prove the following: Let $G$ be a connected graph, then $G$ is a tree $\iff$ $G$ has no cycles. $\Rightarrow$ If $G$ is connected and a tree then by the definition of tree it has no cycles. $\Leftarrow$ $G$ is connected and acyclic, prove $G$ is a tree. Suppose $G$ isn't a tree, then it must be either disconnected or has cycles which contradicts the given. It seems too easy so I'm doubting myself... Definition for a tree: If $n=1$ then $G$ is a tree. If $|V|>1$ then $G$ is a tree if G is given from from a tree $T$ by adding $1$ vertex and $1$ edge connected to it.","['graph-theory', 'trees', 'discrete-mathematics', 'proof-verification']"
1117694,Differential equation degree doubt,"$$\frac{dy}{dx} = \sin^{-1} (y)$$ The above equation is a form of $\frac{dy}{dx} = f(y)$, so degree should be $1$.  But if I write it as $$y = \sin\left(\frac{dy}{dx}\right)$$ then degree is not defined as it is not a polynomial in $\frac{dy}{dx}$. Please explain?",['ordinary-differential-equations']
1117704,Chevalley's theorem proof,"I'm trying to prove Chevalley's theorem stating that $$ \text{If } f \in \mathbb{Z}[x_1, \dots, x_n] \text{ is a form of degree } r < n \text{,}$$
$$ \text{then there exists a nonzero solution of }  f = 0 \pmod{p}$$ To do that, it is sufficient to prove that in this situation the equation can't have exactly one solution (since $ f $ is a form, it has one zero solution). I know that for every polynomial (considered $ \pmod{p} $) there exists exactly one polynomial $ \overline{f} $ satisfying: (a) $ f = \overline{f} $ on all points in $ \mathbb{Z}_p^n $ (b) in all monomials in $ \overline{f} $ the variables $ x_i $ are in powers smaller than $ p $ (c) $\deg \overline{f} \leq \deg f$ Knowing that, I can continue the proof by contradiction: Suppose we have exactly one solution $ a = (a_1, \dots, a_n) $ of $ f = 0$. Then the polynomial $$ g = 1 - f^{p-1} $$ Has the property that admits the value $ 1 $ in $ a $ and $ 0 $ everywhere else in $ \mathbb{Z_p} $. I can write down another polynomial with this property: $$ h = \prod\limits_{i=1}^n \left(1 - (x_i - a_i)^{p-1}\right) $$ It also satisfies condition (b) from the previous lemma. If I knew for certain that $ h = \overline{g} $, then the proof would be complete (since $ n(p-1) \leq r (p-1) $ and it's a contradiction). But I'm confused here - is it true that if a polynomial satisfies (a) and (b) then it must satisfy (c)? Or is it so just in that case? Or maybe I'm approaching it all wrong. I would appreciate a hint.","['polynomials', 'number-theory']"
1117725,Why does $\sqrt{x} / y =\sqrt{x/y/y}$?,"Sorry for the awkward title, hard to to sum a mathematical problem with words alone. Having said that, I recently learned that the root of any value, $x$, and then that over value $y$, is identical to the root of $x/y/y$, as in $\sqrt{x/y/y}$. For e.g, $\sqrt{35} / 7 = \sqrt{5/7}$, and I cannot logically deduce why. So far, I know that:
$$
35 = 7 \times 5 \\
\frac{\sqrt{35}}{7} = \frac{\sqrt{7} \times \sqrt{5}}{7}
$$ And somehow this being equal to: √(5/7) So it seems that we divided the numerator, √35 by √5 to give √7. However, 7/√7 is not √7! Yet, apparently it is? So, a fraction is of course equal to itself if scaled up or down by the same amount, in that 10/2 is the same as 5/1, or 5. So scaling down √35 by √5 makes sense, as it only leaves √7, but it seems that the same cannot be said for the denominator, 7. 7/√7 = √7!? Yet, the two expressions really are the same, √35/7 and √(5/7). Thanks for any help in advance. P.S This works for any values, so it's no coincidence.","['radicals', 'fractions', 'algebra-precalculus']"
1117750,How to solve differential equation $\frac{d}{dx}\left(\frac{\lambda y'}{\sqrt{1+y'^2}}\right)=1$,"My task is to solve for $y$ from: $$\frac{d}{dx}\left(\frac{\lambda y'}{\sqrt{1+y'^2}}\right)=1$$ I have been given the answer, but I would like to calculate this myself also. $\lambda$ is a constant. How should I proceed? The answer according to source material: Integrating with respect to $x$ we get: $$x+C_1= \lambda\sin(\theta)$$ $$y=-\lambda\cos(\theta)+C_2$$",['ordinary-differential-equations']
1117751,"Given a solution of a differential equation, determine the differential eqution itself","Sorry if my layout is bad, I'm new.
So this question was asked a couple of years ago on an exam about differential-equations.
Suppose you have a third order differential-equation with the following general solution: $c_1J_2+c_2Y_2+\frac {c_3}{x^2}$ where $J_2$ is the Bessel function of the first kind and $Y_2$ one of the second kind, then what is the differential-equation?
I really don't know how to start, I'm guessing order reduction has something to do with it, but can someone give me a hint to start. Thank you!","['ordinary-differential-equations', 'calculus']"
1117754,Calculus of Variations: Understanding functional derivative,"I am trying to understand the basics of the Calculus of Variations and the first thing to understand is the functional derivative. I failed to find a good introductory material, so I am trying to make sense out of various sources I found on the internet. Now, $F[y]$ is a functional, dependending on the function $y(x)$ on an interval $[a,b]$. The most explanatory resources I have came across builds the functional derivative from the definitions of multivariable calculus, so we divide the interval $[a,b]$ into $N$ subintervals and assume that $F$ depends on values of $y$ at such interval points. So we have a multivariable function: $F(y_0,y_1,y_2,\dots, y_N)$ where $y_i = y(a + i(\dfrac{b-a}{N}))$. Then we make a small displacement $\epsilon \vec{d} $ from the point $\{y_0,\dots,y_N\}$ and obtain: $$F(y_0 + \epsilon d_0 ,y_1 + \epsilon d_1,y_2+ \epsilon d_2,\dots, y_N+ \epsilon d_N) = F(y_0,y_1,y_2,\dots, y_N) + \epsilon\sum_{i=0}^N\frac{\partial F}{\partial y_i}d_i + O(\epsilon^2)$$ $O(\epsilon^2)$ shows that the residue is on the order of $\epsilon^2$. Now, how can I approach from here and obtain the formula for the functional derivative? What I have in mind is to refine the number of subintervals on $[a,b]$; make denser and denser meshes which results in taking the limit $N \to \infty$. But I don't know how to apply this idea in a correct way. The term $\epsilon\sum_{i=0}^N\frac{\partial F}{\partial y_i}d_i$ should turn into a definite integral if I take this limit, but $\frac{\partial F}{\partial y_i}d_i$ is not a proper continuous function to begin with. So I need help in understanding this derivation. Edit: The end result I am trying to reach is $ F [y (x) + \epsilon n (x)] = F [y (x)] + \epsilon \int \dfrac {\delta F}{\delta y (x)}n (x) dx +O (\epsilon^2) $","['multivariable-calculus', 'calculus', 'calculus-of-variations']"
1117755,Rotating an inscribed square in Geogebra,"I am trying to figure out how to rotate the inside square so that the sides lengthen based on the degree of rotation. For example, after rotating 90 degrees in either direction, it should precisely match the outside square. Thank you. 1 ![inscribed square]",['geometry']
1117818,"Let $H$ be a subgroup of the group $(R, +)$ such that $H$ $∩$ [-1,1] is a finite set containing a non zero element. Show that $H$ is cyclic.","Observations: Since $H$ is a subgroup of $(R, +)$ so $0 \in H.$ If $1 \in H,$ then all positive integers belong to $H.$ But $H$ is closed wrt addition, so the negative integers must belong to $H$ as well. Similarly, for $-1.$ Thus if $1$ or $-1 \in H$, then the whole set of integers belongs to $H.$ If $1/n$ is in $H$ (where $n$ is a positive integer), then $n.(1/n) = 1$ also belongs to $H,$ which in turn ensures that all integers belong to $H.$
Something similar can be said about $-1/n$. So it is observed that $H$ will contain the entire set of integers.
But how do I conclude that in every case $H$ is isomorphic to $\mathbb Z$, and hence is cyclic?","['finite-groups', 'group-theory', 'abstract-algebra']"
1117845,Central limit theorem with Lyapunov condition,"$Z_1, Z_2,...$ are iid uniformly distributed on $[-1;1]$, $\lim_{n \to \infty} a_n=0$ and $\lim_{n \to \infty} na_n=\infty$ also $a_n>0$ $\forall n$, $X_{n,j}= \frac{1}{a_n}I(|Z_j| \le a_n)$ $\forall j = 1,...,n$ where $I$ is the indicator function, $S_n=\sum_{j=1}^{n}X_{n,j}$. One needs to show that $(S_n-n)\sqrt{\frac{a_n}{n}} \to N(0,1)$ in distribution. Easy to show that: $E[S_n]=n$ if $n$ large enough, also $Var[S_n]= \frac{(1-a_n)n}{a_n}$ if $n$ large enough, and the Lyapunov condition is satisfied for $\delta=2$, i.e. $$\lim_{n \to \infty} \sum_{j=1}^{n} \frac{1}{Var(S_n)^2}E[|X_{n,j}-E(X_{n,j})|^4]=0.$$ But then it follows that $\frac{S_n-E[S_n]}{\sqrt{Var(S_n)}}=(S_n-n)\sqrt{\frac{a_n}{n(1-a_n)}} \to N(0,1)$ in distribution. What am I doing wrong? Reaction to Did's comment: $Z_n=(S_n-n)\sqrt{\frac{a_n}{n(1-a_n)}}$ and $Y_n=Z_n*\sqrt{(1-a_n)}$, Clearly if $F_{Z_n}(x)$ is a cdf for $Z_n$, then $F_{Z_n}(\frac{x}{\sqrt{1-a_n}})$ is the cdf for $Y_n$. Now we need to prove that $\lim_{n \to \infty}F_{Z_n}(\frac{x}{\sqrt{1-a_n}})=\Phi(x)$ $\forall x$. And here I am stuck.","['probability-theory', 'central-limit-theorem', 'probability-distributions', 'probability']"
1117846,"If all the roots of a polynomial P(z) have negative real parts, prove that all the roots of P'(z) also have negative real parts","If all the roots of a polynomial $P(z)$ have negative real parts, prove that all the roots of the derivative $P'(z)$ also have negative real parts. Could anyone provide a proof for this please?","['analyticity', 'complex-analysis', 'polynomials']"
1117868,Image sheaf is the sheafification of the image presheaf,"This is an exercise in Vakil's notes on foundations of algebraic geometry. Suppose $\Phi:\mathscr{F}\to\mathscr{G}$ is a morphism of sheaves of abelian groups, show that the image sheaf Im $\Phi$ is the sheafification of the image presheaf. My solution We use the key fact that in an abelian category, there is a natural isomorphism (preserving the arrow $\mathscr{F}\to \cdot $) between 
  $$\text{Im }\Phi := \ker\text{coker}\,\Phi \cong \text{coker}\ker \Phi$$
  Therefore we have 
  $$ \text{Im }\Phi \cong \text{coker}\ker \Phi = (\text{coker}_{pre} \ker \Phi)^{sh} = (\text{coker}_{pre} \ker_{pre} \Phi)^{sh} \cong (\text{Im}_{pre}\Phi)^{sh} .$$ Is this solution correct? To be rigorous, I must define a map between Im$_{pre} \Phi\to $Im $\Phi$.","['category-theory', 'sheaf-theory', 'algebraic-geometry', 'abstract-algebra']"
1117874,Numbers that are divisible by the number of primes smaller than them,"Let $\pi(n)$ denote the number of primes less than or equal to $n$ (a.k.a the prime-counting function ). For certain values of $n$, the value of $\frac{n}{\pi(n)}$ is integer. Here are the first few examples: $n=  8,\pi(n)= 4,\frac{n}{\pi(n)}=2$ $n= 27,\pi(n)= 9,\frac{n}{\pi(n)}=3$ $n= 30,\pi(n)=10,\frac{n}{\pi(n)}=3$ $n= 33,\pi(n)=11,\frac{n}{\pi(n)}=3$ $n= 96,\pi(n)=24,\frac{n}{\pi(n)}=4$ $n=100,\pi(n)=25,\frac{n}{\pi(n)}=4$ $n=120,\pi(n)=30,\frac{n}{\pi(n)}=4$ $n=330,\pi(n)=66,\frac{n}{\pi(n)}=5$ $n=335,\pi(n)=67,\frac{n}{\pi(n)}=5$ $n=340,\pi(n)=68,\frac{n}{\pi(n)}=5$ $n=350,\pi(n)=70,\frac{n}{\pi(n)}=5$ $n=355,\pi(n)=71,\frac{n}{\pi(n)}=5$ $n=360,\pi(n)=72,\frac{n}{\pi(n)}=5$ $\textbf{Has it been proved that }\mathbf{\forall{k>1},\exists{n}:\frac{n}{\pi(n)}=k}$? Two aspects which ""intuitively"" support this statement are: The prime-number theorem , which implies $\frac{n}{\pi(n)}\approx\ln{n}$. There seem to be several such values of $n$ for each value of $k$. But I'm not sure how either one of them can be used in order to establish a proof.","['prime-numbers', 'number-theory']"
1117901,"Terence Tao, Analysis 1. Exercise 5.3.2. Real Numbers and Cauchy Sequences.","Let $ x = \lim_{n\rightarrow\infty}a_n, y = \lim_{n\rightarrow\infty}b_n$, and $ x' = \lim_{n\rightarrow\infty}a'_n$ be real numbers. Then $xy$ is also a real number. Furthermore, is $x=x'$, then $xy = x'y$. Here is my attempt. We need to show that $xy = \lim_{n\rightarrow\infty}a_n b_n$ is a real number. from the hypothesis we know that $a_n$ and $b_n$. are eventually $\delta$ -steady sequences for every $\delta> 0 $. so we can choose $a_n$ and $b_n$ to be eventually $\sqrt{\epsilon}$-steady sequences. since $(a_n)_{n=1}$ is eventually $\sqrt{\epsilon}$-steady, we know there is an $N \geq 1$ such that $d(a_n,a_m) < \sqrt{\epsilon}$  for every $n,m > N$. By a similar argument we can say the same for $(b_n)_{n=1}$. by proposition 4.3.7 (h). $d(a_nb_n,a_mb_m) < \sqrt{\epsilon}|b_n| + \sqrt{\epsilon}|a_n| + \epsilon $ From here i am not sure where to go, I am pretty sure i am going the right way, as this sort of resembles the definition of a cauchy sequence that is eventually $\sqrt{\epsilon}|b_n| + \sqrt{\epsilon}|a_n| + \epsilon $-close. I think I require something that just involves epsilon. The second part of the question I havent attempted yet, but I thought I'd include it just in case anyone would like to lend a helping hand. by the way propostion 4.3.7 (h). states that if x and y are $\epsilon$-close and z and w and $\delta$ close then xz and yw are $(\epsilon|z| + \delta|x| + \epsilon \delta$)-close. EDIT. A real number is defined to be an object of the form $ x = \lim_{n\rightarrow\infty}a_n$, where $a_n$ is a cauchy sequence of rational numbers.",['analysis']
1117973,Does $\sin(x+iy) = x+iy$ have infinitely many solutions?,"How to prove that $\sin(x+iy) = x+iy$ has infinitely many solutions? I know how to prove that $\sin(x) = x$ has only one solution, but I do not know how to extend this to complex analysis.","['trigonometry', 'complex-numbers', 'complex-analysis']"
1117980,If $a_n$ and $b_n$ are equivalent sequences and $a_n$ is bounded then so is $b_n$.,"This is what i know; If $(a_n)$ is an infinite sequence of which is bounded then we can say; $|a_i| < M $ for all $i \geq 0.$ since $a_n$ and $b_n$ are equivalent sequences, we can say that for every rational $\epsilon >0$, there exists $ N \geq 0$ such that $|a_i-b_i| < \epsilon $ for all $i \geq N$. I would like to show that $b_n$ is bounded. now using the triangle inequality we obtain, $|b_i| = | b_i - a_i + a_i| \leq |b_i - a_i| + |a_i| \leq \epsilon + M$ and hence the sequence is bounded above by $M' = max\{\epsilon, M\}$. I feel like there is something missing at the end, could someone lend a helping hand please.","['sequences-and-series', 'analysis']"
1117983,Solve system of 3 equations,$x+y+z=0$ $x^2+y^2+z^2=6ab$ $x^3+y^3+z^3=3(a^3+b^3)$ this is what i reasoned out so far; $xyz=a^3+b^3$ $x^2+zx+z^2=3ab$ $y^2+zy+z^2=3ab$ $x^2+xy+y^2=3ab$ $y^2=3ab+zx$ $x^2=3ab+zy$ $z^2=3ab+xy$ I'd prefer a hint rather than a full answer - and how should I solve this kind of systems?,"['algebra-precalculus', 'systems-of-equations']"
1117986,Why is arcsin represented with the ^(-1) notation?,"So in trigonometry, we have sin, secant (which is one over sin) and arcisn. Why is arcsin sometimes represented with sin^-1? sin^2 means sin to the second power, but sin^-1 explicitly does not mean sin to the negative first power, as that would be the secant, not the arcsin.
Why this confusion in notation?","['notation', 'trigonometry']"
1118001,Group of order $pqr$ and cyclic subgroup,"Let $G$ be group of order $pqr$, when $p,q,r$ are different prime numbers. Does $G$ must have normal cyclic subgroup $H$ such that $G/H$ is cyclic too ? I know that $G$ has normal sylow subgroup of order $p$ or $q$ or $r$, and that $G$ is solvable, but I can't see why there is a cyclic quotient. Edit: Attempt for solution - 
If $G$ is abelian, then $G\cong \mathbb{Z}_{p}\oplus\mathbb{Z}_{q}\oplus\mathbb{Z}_{r}\cong \mathbb{Z}_{pqr}$, hence cyclic and it's clear.
If not, then $G'\neq \left\{ e\right\}$. If $\left|G'\right|=p$, then $G/G'\cong \mathbb{Z}_{qr}$ (because $G'/G$ is abelian), both cyclic. and the other cases are symetric.
$G'\neq G$ because $G$ is solvable.","['finite-groups', 'group-theory']"
1118062,How prove $\sin \left( \alpha+\frac{\pi }{n} \right) \cdots \sin \left( \alpha+\frac{n\pi }{n} \right) =-\frac{\sin n\alpha}{2^{n-1}}$?,"How prove 
$$\prod_{k=1}^{n}\sin \left( \alpha+\frac{\pi k }{n}\right) =-\frac{\sin n\alpha}{2^{n-1}}$$ 
for $n \in N$?",['trigonometry']
1118068,Finitely Many Extensions of Fixed Degree of a Local Field,How does one show that there are only finitely many degree $n$ extensions of a local field? I understand how this follows from class field theory in the Abelian case but don't understand how to do the non-Abelian case.,"['galois-theory', 'local-field', 'abstract-algebra', 'number-theory']"
1118120,"Diophantine equation not solvable in $\mathbb{Q}$, but in $\mathcal{O}_p$","I'm trying to think of an example of a diophantine equation which can be solved in $ \mathcal{O}_p$ (meaning it can be solved $\mod p^k$ for all $ k $) for all prime $ p $'s, but not in $\mathbb{Q}$ I don't really think that's such an easy task - and probably there is some classic answer, but I can't think of one. I would appreciate some help","['diophantine-equations', 'p-adic-number-theory', 'number-theory']"
1118147,Understanding the Jacobian past calculus,"What's taught in calculus: In the calculus of multiple variables I learned that the Jacobian $$\textbf J=\frac{\partial(x_1,\ldots,x_n)}{\partial(t_1,\ldots,t_n)}=\left(\begin{array}{ccc}\frac{\partial x_1}{\partial t_1}&\cdots&\frac{\partial x_1}{\partial t_n}\\\vdots&\ddots&\vdots\\\frac{\partial x_n}{\partial t_1}&\ldots&\frac{\partial x_n}{\partial t_n}\end{array}\right)$$ gives me a means of obtaining differentials $dt_1,\ldots,dt_n$ from $dx_1,\ldots,dx_n$. Geometric intuition is provided: The collection $dt$ is the volume/area element of an infinitesimal portion to be integrated. The equation for each member of $dx$ expressed as a vector is $$d\textbf x_k=\sum_{i=0}^n\frac{\partial x_k}{\partial t_i}d\textbf t_i$$ and in a two-dimensional system, we have $$d\textbf x_k=\left<\frac{\partial x_k}{\partial t_1}dt_1,\frac{\partial x_k}{\partial t_2}dt_2,0\right>$$ Then we find the area element with $dx$ corresponding to $dt$ $$|d\textbf x_1\times d\textbf x_2|=\left|\frac{\partial x_1}{\partial t_1}\frac{\partial x_2}{\partial t_2}-\frac{\partial x_1}{\partial t_2}\frac{\partial x_2}{\partial t_1}\right|dt_1dt_2$$ which is the same as $|\det\textbf J|=\left|\det\frac{\partial(x_1,x_2)}{\partial(t_1,t_2)}\right|$, which concludes the motivation for the Jacobian in basic calculus. I'm confident the same exercise as above could be performed in 3D, except with $d\textbf x_1\cdot(d\textbf x_2\times d\textbf x_3)$ for my volume element, but that's where it ends, since there's no notion of cross products above 3D in calculus. My questions: Cross products don't extend to above three dimensions. So far I've had 3D Jacobians explained. What about $n$-dimensional Jacobians? What about coordinate transformations with $T:(t_1,\ldots,t_m)\to(x_1,\ldots,x_n)$ and $n\neq m$? Is the motivation given in calculus at all rigorous? I'm still not certain exactly what a differential is, and why I can manipulate them as above.","['differential', 'multivariable-calculus', 'vectors', 'soft-question']"
1118148,Prove that any set of 2015 numbers has a subset who's sum is divisible by 2015,"I assume this is correct to any size set, not 2015 in particular... it's obviously true for 2. I know from pen and paper it's true for 3, and 4.... I understand that I should look at the reminders, and build pigeonholes from them. 
If one of the numbers has a 0 reminder obviously the entire set is divisible,
so the possible reminders go from 1 to (n-1). i have n numbers hence one of the reminders repeats. the sums of the reminders go from 1 to n*(n-1).... And that's it... Any and all help would be appreciated. Of course I mean non empty set...","['pigeonhole-principle', 'elementary-number-theory', 'combinatorics']"
