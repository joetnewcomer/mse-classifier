question_id,title,body,tags
146716,separation theorem for probability measures,"Suppose I have a probability measure $\nu$ and a set of probability measures $S$ (all defined on the same $\sigma$-algebra).  Are the following two statements equivalent? (1) $\nu$ is not a mixture of the elements of $S$. (2) There is a random variable $X$ such that the expectation of $X$ under $\nu$ is less than 0, and the expectation of $X$ under all of the members of $S$ is greater than 0. If not, is something similar true, or true in a special case? Is the situation the same for merely finitely additive probability measures?","['probability-theory', 'measure-theory', 'functional-analysis']"
146723,Question about Fredholm operator,"$X,Y$ are Banach spaces and $A\in B(X,Y)$ is a Fredholm operator (that is, the dimensions of ker($A$) and coker($A$) are both finite), then are closed linear subspaces ker($A$) and Im($A$) complemented? (A closed linear subspace $H$ in a Banach space $Z$ is called complemented iff there is a closed linear subspace $G$ such that $H+G=Z$ and $H \cap G=0$)","['operator-theory', 'functional-analysis', 'banach-spaces']"
146724,Coordinate functions of Schauder basis,"If $X$ is a Banach space admitting a Schauder basis, then can we choose a set $\{e_1,e_2,e_3 \cdots \}$ as the basis such that there are bounded linear functional $f_i$ such that $f_i(e_j)=\delta_{ij}$?","['schauder-basis', 'functional-analysis', 'banach-spaces']"
146727,The norm-closed unit ball of $c_0$ is not weakly compact,Show that the norm-closed unit ball of $c_0$ is not weakly compact; recall that $c_0^*=\ell_1$.,['functional-analysis']
146741,"Using contour integration, or other means, is there a way to find a general form for $\int_{0}^{\infty}\frac{\sin^{n}(x)}{x^{n}} \, dx$?","While studying some CA, I ran across methods of evaluating $$\int_0^\infty \frac{\sin x}{x} \, dx, \;\ \int_0^\infty \frac{\sin^2 x}{x^2} \, dx, \;\ \text{and} \ \int_0^\infty \frac{\sin^3 x}{x^{3}} \, dx.$$ Is there a way to find a closed form for $$\int_0^\infty \frac{\sin^n x}{x^n} \, dx, \ n \in \mathbb{N}_{>0}  ?$$ Rather it be contour integration or some clever method using real analysis.","['integration', 'contour-integration']"
146770,Basic angle geometry question,"I've faced a question that needed to find angle $\gamma$ as a part of it and the solution came from $\gamma= \beta - \alpha$. How did the book arrive to such conclusion, and does this apply for every similar case?",['geometry']
146774,Khan academy for abstract algebra,"I am looking for instructional videos for abstract algebra, specifically topics including group theory, ring theory, isomorphic and homomorphic structures, and properties of groups and rings, and hopefully basic proofs with narations. Does anybody have links where I could find anything like this? KA and youtube have yield poor to no results. Thanks,
Tom","['ring-theory', 'group-theory', 'abstract-algebra']"
146776,A problem about a sequence and prime factorization,"A long time ago I solved the following theorem Let $p_1,p_2,\ldots,p_k$ be distinct primes. Let
  $\{a_i\}^\infty_{i=1}$ be the increasing sequence of positive integers
  whose prime factorization contains only these primes (not necesarily
  all). Show that $\forall c>0\exists n\in \mathbb{N}:a_{n+1}-a_n>c$ Solution. Let $m$ be an integer such that $p^m_i>c$ for all $i=1,2,\ldots,k$. Let $a_n=(a_1a_2\ldots a_k)^m$. As $a_{n+1}>a_n$, there exist a prime $p_j$ such that $p_j^m|a_{n+1}$. Then $p^m|a_{n+1}-a_n$ from which $a_{n+1}-a_n>c$. Then a friend told me that this stronger version is also true. Let $p_1,p_2,\ldots,p_k$ be distinct primes. Let
  $\{a_i\}^\infty_{i=1}$ be the increasing sequence of positive integers
  whose prime factorization contains only these primes (not necesarily
  all). Show that $\forall c>0\exists n_c\in \mathbb{N}:n>n_c\implies a_{n+1}-  a_n>c$ I've tried to solve it but I couldn't. I'm 90% sure that the stronger version is also true. I'm interested in elementary solutions but a complex one is also welcome.","['prime-numbers', 'number-theory']"
146785,How did they get this result?,"Please, explain these computations: 1) $-\left(\frac{1}{2}\right)^2 +1 =  \cos^2x$ $\frac{\sqrt{3}}{2}  =  \cos x$ How did we get  $\frac{\sqrt{3}}{2}$   from   $-\left(\frac{1}{2}\right)^2 +1$? 2) $-\left(\frac{\sqrt{2}}{2}\right)^2 +1 = \cos^2x$ $\frac{\sqrt{2}}{2} = \cos x$ How did we get $ \frac{\sqrt{2}}{2}$   from  $-\left(\frac{\sqrt{2}}{2}\right)^2 +1 $?",['algebra-precalculus']
146798,Intersection of irreducible components of a smooth curve,"Say $V$ is a smooth projective curve. Is it true that the irreducible components of $V$ don't meet? I've heard something along the lines of ""a point contained in two components can't be smooth"", but I'm failing to see why this is true. Thanks!",['algebraic-geometry']
146802,Probability of $5$ fair coin flips having strictly more heads than $4$ fair coin flips,"Person A has 5 fair coins and Person B has 4 fair coins. Person A wins
  only if he flips more heads than B does. What is the probability of A
  winning? When I initially thought about the problem, I thought of it as if both had 4 coins, then they would on average get the same number of heads. If Person A had one more coin, then it would be a 50/50 shot for Person A to have more each time. But the more I think about this, its making less sense to me as an explanation, or at least it is incomplete. Logically as I think about it if you have 2 people with the same amount of coins, they both have the same chance of winning, although that percent is less than 50 for each person because of the chance of them tying. When you give a person an extra coin, that reduces the probability of tying by half (one half is tie when the guy flips tails with his extra and the other half is when the guy flips and gets heads and get an extra point). I'm not sure how to justify the thought that the original percentage of winning + the extra gain from the tie scenarios given by the extra coin = 50%. I guess I'm just looking for any tips on how to think about this problem so I can more fully understand it. Thanks","['recreational-mathematics', 'probability']"
146804,Understanding fundamental principles of counting,"There are two fundamental principles of counting; Fundamental principle of addition and fundamental principle of multiplication. I often got confused applying them. I know that if there are two jobs, say $m$ and $n$ , such that they can be performed  independently in $m$ and $n$ ways respectively, then either of the two jobs can be performed in $m+n$ ways and when two jobs are performed in succession, they can be performed in $m\times n$ ways. My question is how to identify whether jobs are independent or in succession? Is there any simple way to identify this? Are there any keywords?","['permutations', 'combinatorics']"
146808,Calculating $\tan15\cdot \tan 30 \cdot \tan 45 \cdot \tan 60 \cdot \tan 75$,"What is $\tan15\cdot \tan 30 \cdot \tan 45 \cdot \tan 60 \cdot \tan 75$  equal to (in degrees)? Here is how I tried to solve it: I assumed $x = \tan 15 (x= 0.27)$, so I rewrote it as: $x\cdot 2x \cdot 3x \cdot 4x \cdot 5x = 120x^5$ $0.27^5 = 0.001323$ $120 \cdot 0.001323 = 0.16$ But Google Calculator gives me  $-1.19576279$ What is the right way to calculate this  trig expression?",['trigonometry']
146826,Expected Number of Convex Layers and the expected size of a layer for different distributions,"It is well-known that the expected number of vertices on the convex hull of random set of points in the plane distributed uniformly within a $k$-gon is $O(k\log n)$ and within a smooth shape (e.g. a disk) is $O(n^{1/3})$. These bounds also extend to $\mathbb{R}^d$ with arbitrary $d$, by tacking on a $d-1$ exponent. But, I'm only interested in $\mathbb{R}^2$ for now. My question is: What is wrong with the following argument for the number of layers in a $k$-gon to be $\Theta(n/\log n)$, taking $k$ as a constant: In $\mathbb{R}^2$, the number of vertices of $conv(P)$ is $\Theta(\log n)$. After peeling off $i$ layers, the points $P_{i+1}$ enclosed by layer $L_i$ are also
independently and uniformly distributed, so their convex hull $conv(P_{i+1})$ should also have $\Theta(\log |P_{i+1}|) = O(\log n)$. I'm aware of the following result by Dalal : In this paper, we show that the expected number of layers of a convex
  hull onion for n uniformly and independently distributed points in a
  disk is $\Theta(n^{2/3})$. Additionally, we show that in general the bound is
  $\Theta(n^{2/(d+1)})$ for points distributed in a $d$-dimensional ball. 
  Further, we show that this bound holds more generally for any fixed, bounded, 
  full-dimensional shape with a nonempty interior. I guess my question could also be put more simply as this: Why is the expected number of layers for $k$-gons not $O(n/\log n)$? Why is there a difference in the size of the convex hull between the case when the random points are drawn from a polygon and smooth shapes, but there is no such difference in the expected number of layers, based on Dalal's result (unless I misunderstand his claim)? An intuitive reason should do, but a formal argument or a pointer to one will be great!","['probability-theory', 'geometric-probability', 'combinatorial-geometry', 'computational-geometry']"
146829,Why is there exactly one non-solvable group of order 180?,"My homework assignment for next week has the following problem in it. Show that there exists a non-solvable group of order 180. The problem is easy to solve given that we have already proven that $A_5$ is not solvable. Since the product of two groups is solvable iff both groups are solvable, $A_5\times\mathbb Z/3\mathbb Z$ isn't solvable, and it's clear that its order is 180. However, I thought it would be cool to see if there are others. I found a page on the internet which says that that aren't, but without proof. I know little group theory and I'm not used to working in groups -- last time I spent a significant amount of time on groups was during my first year. This makes me completely unable to think of a way to prove this statement, or even estimate its difficulty. Could you help me with this? I don't want to specify what kind of answer I want (a proof or a hint), because I don't know what is best for me. I would like to ask you to judge what kind of answer would be best in this case.",['group-theory']
146844,How to divide aleph numbers,"Recently, I was wondering how division of aleph numbers would work. First, I thought about how finite cardinality division would work. What I came up with was that the result of $A/B$ where $A$ and $B$ are both cardinalities, is the number of times that each element of $B$ had to be mapped to an element of $A$ in order to ensure that all elements of $A$ were mapped to. Extending this to aleph numbers, specifically, I thought that $\aleph_1/\aleph_0$ would be $\aleph_1$. The reasoning behind this is that there are an infinite ($\aleph_1$) number of real numbers between any two natural numbers. As such, that mapping would need to be applied. Can anyone validate this idea? Is this how division of aleph numbers actually works, or am I totally off base? Thanks.","['cardinals', 'elementary-set-theory']"
146845,Definition of metrizable topological space,"I am learning a bit about Topology through independent study. I am using Bert Mendelson's ""Introduction to Topology - 3rd Edition"". I have a question on one of the book's example and related exercise. Example 7, pg. 72 Let $Z$ be the set of positive integers. For each positive integer $n$, let $O_n = \{n, n+1, n+2, \cdots\}$. Let $\mathcal{J} = \{\emptyset,O_1,O_2,\cdots\}$, then $(Z,\mathcal{J})$ is a topological space. Excercise 1 on pg. 74 asks us to prove that the topological space defined in example 7 is ""non-metrizable"". The book so far has no specific definition of metrizable vs. non-metrizable topological spaces. However, it does mention that ""some topological spaces cannot have risen from a metric space"", citing example 7 as one of these cases. Here is my question: Does metrizable refer to the ability of defining some metric space of $\mathcal{J}$? In other words, is there some function $d:\mathcal{J} \times \mathcal{J} \rightarrow \mathcal{R}$, satisfying the conditions: Let $a,b,c \in \mathcal{J}$ $d(a,b) \geq 0$ $d(a,b) = 0$ iff $a =b$ $d(a,b) = d(b,a)$ $d(a,b) \leq d(a,c) + d(c,b)$ In this case if we define a function: For $a,b \in \mathcal{J}$ $d'(a,b) = \left\{ \begin{array}{c c l} 
0 & \text{if } & a = b \\
1 & \text{if } & a \neq b 
\end{array}\right.$ Will $(\mathcal{J},d')$ not be a metric space? I would appreciate any insight.","['general-topology', 'metric-spaces']"
146871,"If $G$ is abelian, then the set of all $g \in G$ such that $g = g^{-1}$ is a subgroup of $G$","Prove that if $G$ is abelian then the set $H$ of all elements of $G$ that are their own inverses is a subgroup of $G$. Naturally in an abelian group, $ab = ba$ for $a, b \in G$, however I'm not sure how to show the set elements that are their own inverses is a subgroup of $G$ using arbitrary elements.","['group-theory', 'abstract-algebra', 'abelian-groups']"
146885,"Procedure for evaluating the hypergeometric series $_2F_1\left\{\frac{v+2}{2},\frac{v+3}{2};v+1;z\right\}$","I'm trying to work out the procedure to get the following hypergeometric series into a simpler form, for all postive integer $v$:
$$ _2F_1\left\{\frac{v+2}{2},\frac{v+3}{2};v+1;z\right\}$$ For example, plugging this into Wolfram Alpha gives for $v$ = 1,
$$\frac{1}{(1-z)^{3/2}}$$
for $v$ = 2,
$$\frac{4 (2 \sqrt{1-z} \,(z-1)-3 z+2)}{3 \sqrt{1-z}\, (z-1) z^2}$$
for $v$ = 3,
$$-\frac{2 (3 z^2+4 (2 \sqrt{1-z}-3) z-8 \sqrt{1-z}+8)}{(1-z)^{3/2} z^3}$$
and so on. I'm guessing a transformation is repeatedly applied until a terminating form of the hypergeometric series is obtained. For $v$ = 1, applying Euler's transformation, 
$$_2F_1 (a,b;c;z) =
(1-z)^{c-a-b}{}_2F_1 (c-a, c-b;c ; z)$$
gives the correct form; however, I cant work out what is used for $v$ = 2 and higher.","['special-functions', 'sequences-and-series']"
146887,What's the difference between a monoid and a group?,"What's the difference of a monoid and a group? I'm reading this book and it says that a group is a monoid with invertibility and this property is made to solve the equation $x \ast m=e$ and $m \ast x=e$ for $x$, where $m$ is any element of the structure. I got confused because it's similar to the monoid's commutativity property which says that $m \ast n=n*m$ for all $m, n \in M$.","['group-theory', 'monoid']"
146893,How to Characterize Gradient Vector Fields?,Let $V$ be a vector field on a smooth manifold $M$. Are there nice conditions under which there exists a (Riemannian) metric on $M$ such that $V$ is the gradient of some smooth function on $M$? One obstruction is that gradient vector fields have no closed integral curves (since a function is increasing on integral curves of its gradient).,"['differential-topology', 'differential-geometry']"
146895,"Given a victory condition and a set strategy, what are the chances of winning on a given turn in a game of Magic: The Gathering?","Tl;DR :  You have winning cards. To win, you must be able to play those cards, and have them in your hand. Your hand is randomly drawn. When might you win? How could find the answer to this (very complex) problem? (I realize that my question isn't very formal, but I'm not exactly sure how to correctly pose the question. Feel free to edit. Also, draw3cards or Boards & Games don't like math questions) The decklist (If you know  magic, you should skip the next section, and probably the one after that, too) Basic Rules You have a 60-card deck, which has just been shuffled. At the beginning of the game, you draw 7 cards. From then on, each turn you draw one card. All cards except lands require mana to play. Mana is drawn from your mana pool. A land card on the field can be tapped (used) to add a mana of a color to your mana pool. (Mana either has a color, or is uncolored. Islands for blue mana, Swamps for black). Colored mana can always be turned into uncolored mana. Each turn, you may put no more than one land from your hand onto the field. It can immediately be tapped for mana. Combo explanation You have your Myr. As the decklist shows, you have Silver and Leaden myr, which can be tapped for Blue or Black mana, respectively. They cost two mana each, of any color. In the same vein, Alloy Myr grants one mana of any color, and Palladium Myr grants two uncolored mana You also have the Myr Galvanizer. For one mana and being tapped, it untaps all other Myr. If you have one Galvanizer, and your mana-myr can be tapped for more than one, you can get an extra mana If you have two Galvanizers, and your mana-myr can be tapped for more than one, you can have infinite mana If you have infinite mana, you can win with Exsanguinate (which requires two black mana - so if you have two Galvanizers and a Palladium Myr, but only one swamp, you can't win with Exsanguinate) ...or you could win with Blue Sun's Zenith, which requires 3 blue mana. It can also be useful without infinite mana, since it allows you to draw cards (one card for every mana of any color you pay beyond 3 blue) You also have three shapeshifters - Cackling Image (one mana of any color, two blue mana), Cryptoplasm (same), and Evil Twin (two uncolored, one black, one blue). All of these can make a copy of a creature on the field You also have Diabolic Tutor, which gives you any card you want for two black mana, two uncolored mana The other cards are irrelevant. Question Given that you try to get mana-myr on the field first, what chances are there of winning on what turn? I realize that this is a very tricky question that probably involves quite a bit of work, so an explication of how to get an answer is almost as good an answer itself. Also really useful would be a generalization of this. For extra points, ideas about finding the optimal number of each card (keeping the irrelevant defensive cards, and no more than 70 cards) would be very appreciated.","['game-theory', 'recreational-mathematics', 'statistics', 'probability-distributions', 'probability']"
146903,Finding roots of unity?,"The $n$th roots of unity are the complex numbers: $1, w,w^2,...,w^{n-1}$, where $w=e^{\frac{2\pi i}{n}}$. Why is this true? I understand why $w$ is 1 root of unity, but why are $w^0,..., w^{n-1}$ the other roots of unity? Why do the roots of unity consist of the exponents of $w$? I am only aware that: The $n$th roots of unity roots of unity are: $\sqrt[n] 1 = \sqrt[n]r\left(\cos\frac{2\pi }{n} + i\sin\frac{2\pi k}{n}\right)$","['complex-numbers', 'complex-analysis']"
146907,Constant functions,"Let $f$ , $g$ , $h$ be three functions from the set of positive real numbers to itself satisfying $$f(x)g(y) = h\left((x^2+y^2)^{\frac{1}{2}}\right)$$ for all positive real numbers $x$ , $y$ . Show that $\dfrac{f(x)}{g(x)}$ , $\dfrac{g(x)}{h(x)}$ and $\dfrac{h(x)}{f(x)}$ are all constant functions . I have proved that $\dfrac{f(x)}{g(x)}$ is constant and can see that proving either of the last two will prove the final one , but I am not able to prove any of the last two . Thanks for any help .",['analysis']
146910,Does the open mapping theorem imply the Baire category theorem?,"A nice observation by C.E. Blair 1, 2, 3 shows that the Baire category theorem for complete metric spaces is equivalent to the axiom of (countable) dependent choice . On the other hand, the three classical consequences of the Baire category theorem in basic functional analysis — the open mapping theorem , the closed graph theorem and the uniform boundedness principle (as well as Zabreiko's lemma ) — are equivalent to each other in Zermelo–Fraenkel set theory without choice: that is to say, if one is added as an axiom to ZF then the others follow 4 . Each of these results has a more or less direct proof from the Baire category theorem and all the proofs “avoiding Baire” I'm aware of 5 involve dependent choice in a way that doesn't seem to be replaceable by weaker forms of choice. Hence I'm asking about the converse: Does the open mapping theorem imply the Baire category theorem? If not, is it at least true that the open mapping theorem implies the axiom of dependent choice for subsets of the reals? I imagine that applying any of the above results to a judiciously chosen space and/or operator(s) might yield the desired conclusion, similarly to what happens in Bell's and Fremlin's geometric version of the axiom of choice 6 . Unfortunately, I couldn't find a promising place to start. Needless to say that I checked numerous things on the web form of Howard and Rubin's book Consequences of the Axiom of Choice , but without much success: The only articles that I found this way are J.D. Maitland Wright's articles 7 . Footnotes and References: 1 Charles E. Blair, The Baire category theorem implies the principle of dependent choices , Bull. Acad. Polon. Sci. Sér. Sci. Math. Astronom. Phys. 25 (1977), no. 10, 933–934. 2 Since Blair's article is hard to find, the proof can be found in the notes to chapter 9 , page 95 of John C. Oxtoby, Measure and Category , Springer GTM 2, Second Edition, 1980. 3 Here's the idea of Blair's argument for the implication Baire Category Theorem $\Rightarrow$ Dependent Choice: let $S$ be a set and let $R \subset S \times S$ be a relation such that for all $s \in S$ there exists $t \in S$ such that $(s,t) \in R$. Equip $S^{\mathbb{N}}$ with the complete metric $d(f,g) = 2^{-\min\{n\,:\,f(n)\neq g(n)\}}$, put
$$
U_n = \bigcup_{m = n+1}^{\infty} \bigcup_{(s,t) \in R} \{f \in S^{\mathbb{N}}\,:\,f(n) = s, \,f(m)=t\},
$$
observe that $U_n$ is open and dense and use $f \in \bigcap_{n=1}^\infty U_n$ and the well-order on $\mathbb{N}$ to find a strictly increasing sequence $k_1 \lt k_2 \lt \cdots$ such that the sequence $(x_n)_{n=1}^\infty$ given by $x_n = f(k_n)$ satisfies $(x_n, x_{n+1}) \in R$ for all $n \in \mathbb{N}$. 4 See e.g. E. Schechter, Handbook of Analysis and its foundations , 27.27, pp. 734 ff. 5 A good example for this is Sokal's A Really Simple Elementary Proof of the Uniform Boundedness Theorem , The American Mathematical Monthly
Vol. 118 , No. 5 (May 2011), pp. 450–452, ArXiV Version . While admittedly it is beautifully simple and elementary, it involves a plain application of dependent choice in the main argument. 6 Bell and Fremlin, A Geometric Form of the Axiom of Choice , Fund. Math. vol. 77 (1972), 167–170. 7 The full list of relevant articles can be obtained with this ZBlatt query two of which appeared in rather obscure proceedings, so I couldn't get my hands on them, yet. The third article is J. D. Maitland Wright, All operators on a Hilbert space are bounded , Bull. Amer. Math. Soc. 79 (1973), 1247–1250.","['set-theory', 'banach-spaces', 'axiom-of-choice', 'baire-category', 'functional-analysis']"
146912,Comparing the growth rates,"How can I go about comparing the growth rate of the following functions? $$\sqrt n,\quad
10^n,\quad
n^{1.5},\quad
2^{\sqrt{\log n}},\quad
n^{5/3}.$$ I am looking for a more generic answer on how do we go about comparing growth rate of functions and a small example demonstrating it on this set of functions would be really helpful.Any links or references explaining the topic would also be very helpful.",['functions']
146927,Relation between rank and number of distinct eigenvalues of a matrix,"Let $T : V\to V$ be a linear transformation such that $\dim\operatorname{Range}(T)=k\leq n$ , where $n=\dim V$ . Show that $T$ can have at most $k+1$ distinct eigenvalues. I can realize that the rank  will correspond to the number of non-zero eigenvalues (counted up to multiplicity) and the nullity will correspond to the 0 eigenvalue (counted up to multiplicity), but I cannot design an analytical proof of this. Thanks for any help .","['vector-spaces', 'linear-algebra']"
146933,Number of partitions contained within Young shape $\lambda$,"It is well known that the number of partitions contained within an $m\times n$ rectangle is $\binom{m+n}{n}$. Furthermore, it is not difficult to calculate the number of partitions contained within a Young shape $\lambda$, where $\lambda $ is also a partition, for ""small"" $\lambda$ by recursively counting lattice paths with steps up and to the right. For example, the number of partitions contained within the shape $\lambda = (3,2,1,1)$ is 19. $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$ Is there a simpler way to determine the number of partitions contained within the shape $\lambda=(\lambda_1,\dots,\lambda_n$)?","['integer-partitions', 'combinatorics']"
146937,modular forms and line bundle,"Let $\Gamma \leq SL_2(\mathbb{Z})$ be a congruence subgroup, $X$ the corresponding compact modular curve. I often see the statement (for example, in many posts here on SE) that modular forms (of weight $k$) $M_k(\Gamma)$ can be interpreted as being global sections of a line bundle $\mathcal{L}$ on $X$. However I am getting confused between two meanings of this: For each $k \in \mathbb{N}$, there is a line bundle $\mathcal{L}_k$ such that $M_k = H^0(X,\mathcal{L}_k)$ There exists a line bundle $\mathcal{L}$ such that for each $k \in \mathbb{N}$, we have $M_k = H^0(X, \mathcal{L}^{\otimes k})$ Clearly 2 implies 1. But when are these statements true? Is 1 always true, for instance? Or do we need further conditions on $\Gamma$, concerning for example, elliptic elements and irregular cusps? I've seen it also stated in some places (for example, Eyal Goren's lectures , also Milne's notes construct the line bundle assuming free action of $\Gamma$) that the existence of a line bundle in the sense of 1 requires $\Gamma$ not to have elliptic elements or irregular cusps. 
But in other places I just see the assertion that this line bundle exists, with no conditions on $\Gamma$. Some people use the canonical bundle on $X$ and assert that this gives the modular forms as global sections in the sense of 2. But for some reason I find it hard to believe that this is always true; in any case, I couldn't find any clear reference about it. I would greatly appreciate any help to clear away my confusion. Most references I was able to find about this are very sketchy and confusing. Does anyone know a good place to look it up?","['algebraic-geometry', 'number-theory']"
146938,uniform continuity of linear functions,"I've just proved the fact that every linear function on a finite dimensional normed vector space is uniformly continuous. Because, let $T:U\to V$ be a linear function on $U$ with basis : $(u_1,u_2,\dots,u_n)$ and suppose that $\|\cdot\|_u$, $\|\cdot\|_v$ be the respective norms associated with $U$ and $V$. Setting $M= \max(\|Tu_1\|_v,\dots,\|Tu_n\|_v)$, we have $$\|Tu\|_v=\|a_1Tu_1 + a_2Tu_2 +\dots+ a_nTu_n\|_v \le |a_1|\cdot\|Tu_1\|_v+\dots+|a_n|\cdot\|Tu_n\|_v \le M\|u\|_1,$$ where $\|u\|_1=|a_1|+\dots+|a_n|$. Since all norms on $U$ are equivalent, we have $\|Tu\|_v\le C\|u\|_u$ for some $C>0$. Thus, $\|Tx-Ty\| \le C\|x-y\|$ for all $x$, $y$ in $U$, thereby satisfying Lipschitz' condition. My questions are: Is it true that a linear function from one vector space to another is always continuous? (finite dimension not assumed) If so, or else, is a continuous linear map always uniformly continuous?","['linear-algebra', 'functional-analysis']"
146944,Exposition on Modular Curves,"I was recently reading this paper by Weston , whereby he talks about the modular curves $X_0(11)$ and $X_1(11)$. I was wondering if anyone can recommend a more general exposition of modular curves (specifically ones that are related to elliptic curves)?","['elliptic-curves', 'reference-request', 'number-theory']"
146946,Set and its Complement are Measure Dense,I'm going over old comprehensive exams and part of one question is giving me a bit of trouble. It asked for an example of a subset of the real numbers such that the set and its complement were measure dense (with respect to the Lebesgue measure). A set is measure dense if its intersection with any open interval has positive measure. Any help would be greatly appreciated.,"['measure-theory', 'real-analysis']"
146951,"If the localization of a ring $R$ at every prime ideal is an integral domain, must $R$ be an integral domain?","Let $R$ be a commutative ring. Suppose that for every prime ideal $\mathfrak p$ of $R$, the localization $R_{\mathfrak p}$ is an integral domain. Must $R$ be a integral domain? I was trying to think of counter-examples, but kept getting $R_{(0)}$ = the zero ring, which is not a domain. Any guidance would be much appreciated. Thanks.","['commutative-algebra', 'ring-theory', 'ideals', 'abstract-algebra']"
146973,Expected Value of the maximum of two exponentially distributed random variables,"I want to find the expected value of $\text{max}\{X,Y\}$ where $X$ ist $\text{exp}(\lambda)$-distributed and $Y$ ist $\text{exp}(\eta)$-distributed. X and Y are independent.
I figured out how to do this for the minimum of $n$ variables, but i struggle with doing it for 2 with the maximum. (The context in which this was given is waiting for the later of two trains, with their arrival times being exp-distributed). Thanks!","['statistics', 'probability']"
146974,Converging sequence and subsequences,"How might we rigorously argue that if we have a sequence $\{x_n\}\subset X$ such that every subsequence of it has a convergence subsequence that tends to $a$ and $X$ is a compact set then $\{x_n\}$ converges to $a$? In my mind, I am thinking that if otherwise then then we can pick a subsequence with such that all terms lie at least a finite distance away from $a$ then there will be no subsequence that converges to $a$. Is this a valid argument? How might I make it ""rigorous""? Thank you.",['analysis']
146993,homotopy direct limits,"$X$ is said to be the homotopy direct limit of the sequence of subsets $X_1\subset X_2\subset ...$ if the projection $\cup_i X_i\times [i,i+1] \rightarrow X$ is a homotopy equivalence. The following is true: Suppose $X, Y$ are homotopy direct limits of the sequences $X_1\subset X_2 \subset ...$ and $Y_1 \subset Y_2 \subset ...$ respectively. Then if $f: X\rightarrow Y$ and each $f|_{X_i}: X_i \rightarrow Y_i$ is a homotopy equivalence then $f$ itself is a homotopy equivalence. My Question:  Does anyone know off the top of his or her head whether the map $f$ can be replaced by a sequence of homotopy equivalences $f_i: X_i \rightarrow Y_i$ where the resulting diagram is homotopy commutative (i.e. $(Y_i\subset Y_{i+1})\circ f_i$ is always homotopic to $f_{i+1}\circ (X_i\subset X_{i+1})$)? I.e. are the spaces still homotopy equivalent? Thanks!","['general-topology', 'homotopy-theory', 'algebraic-topology']"
146995,How do I prove that a complex number equals infinity? [closed],Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 years ago . Improve this question I need to prove that $z=x+iy$ equals infinity is equivalent to $x = \infty$ and $y=\infty$. I also have to give an example of a complex number $z$ so that $\sin(z)=\infty$.,"['trigonometry', 'complex-numbers']"
146998,Quotients and continuous maps,"Suppose $f:\mathbb R\times \mathbb R\to \mathbb R/\mathbb Z\times \mathbb R/\mathbb Z$ where the domain is given the usual topology and the latter the quotient topology. Why then is the restriction $f|_S:S\to f(S)$, where $S=\{(x,\sqrt{5} x): x\in \mathbb R\}$ not continuous with continuous inverse? If I am not wrong, the quotient topology is comprised of sets whose preimages are open. I can prove that $f|_S^{-1}$ is well-defined by showing that $f|_S$ is bijective, but I don't know why they are not continuous.","['general-topology', 'functions']"
147009,Problem on the maximum of the function involving Stirling numbers of the second kind,"When reading about the Coupon collector’s problem (CCP), I just came up with the following problem which I found very curious about, though it seems to have neither relation to the CCP nor practical value. First, denote $S^{(k)}_n$ as a Stirling number of the second kind, a.k.a a number of ways to partition a set of $n$ labelled objects into $k$ nonempty unlabelled subsets. (This is the definition from the Wikipedia article: http://en.wikipedia.org/wiki/Stirling_number_of_the_second_kind ) The problem: Let $n$ be a fixed positive integer. Find the value of the positive integer $x$ such that the function
$$f(n,x) = \frac{S^{(n-1)}_{x-1}}{n^x}$$
reaches its maximum. Note: In fact, $n! f(n,x)$ is the probability of that the number of trials needed to collect all of the $n$ different coupons is $x$. I haven’t had any ideas to solve the problem so far. (Actually, I had one, which was so naive and impractical) However, after several trials, I guess the function with the fixed $n$ will increase, reach its maximum and decrease to asymptotically zero while $x$ increases in the range of $\mathbb{Z^+}$. Anyone has any ideas to solve the problem, please share. Thank you. P.S: Sorry for my bad English.","['probability', 'functions', 'combinatorics']"
147047,Shorter proof of $R/I$ is a field if and only if $I$ is maximal,"Here is a proof I saw somewhere of the fact $R/I$ is a field if and only if $I$ is maximal: $\implies$ Suppose that $R/I$ is a field and $B$ is an ideal of $R$ that properly contains $I$. Let $b \in B$ but $b \notin I$. Then $b + I$ is a nonzero element of $R/I$ and therefore there exists an element $c + I$ such that $(c + I)(b + I) = 1 + I$. Since $b \in B$ we have $bc \in B$. Because $1 + I = (c + I)(b + I) = bc + I$ we have $1 - bc \in I \subset B$. So $1 = (1-bc) + bc \in B$. Hence $B = R$. $\Longleftarrow$ Now suppose $I$ is maximal and let $b \in R$ but $b \notin I$. Consider $B = \{br + a \mid r \in R, a \in I \}$. This is an ideal properly containing $I$. Since $I$ is maximal, $B = R$. Thus $1 = bc + a^\prime$ for some $a^\prime \in I$. Then $1 + I = bc + a^\prime + I = bc + I = (b + I)(c + I)$. I thought this was fairly long so I tried to come up with a shorter proof. Can you tell me if this is right: $\implies$ Assume that $R/I$ is a field and $I$ is not maximal. Then there exists an $x \in R - I = I^c$ that is not a unit (otherwise $I$ would be maximal). Then $x + I$ does not have an inverse hence $R/I$ is not a field. $\Longleftarrow$ Assume $I$ is maximal and $R/I$ is not a field. Then there is an $x$ such that $x + I \neq 0 + I$ does not have an inverse. This $x$ is not in $I$ and $x$ is not a unit. Hence $I \subsetneq I + (x) \subsetneq R$. Which contradicts $I$ being maximal.","['ring-theory', 'maximal-and-prime-ideals', 'abstract-algebra', 'proof-verification', 'ideals']"
147056,Is a basis for the Lie algebra of a Lie group also a set of infinitesimal generators for the Lie group?,"Let $G$ be a (EDIT: connected) Lie group of dimension $n$, and let $\mathfrak{g}$ be the associated Lie algebra. If $x_1,\ldots,x_n$ is a basis for $\mathfrak{g},$ is it necessarily true that the 1-parameter subgroups $e^{tx_1},\ldots,e^{tx_n}$ generate $G$? Note: It is sufficient to show that the subgroup generated by the 1-parameter subgroups is closed, since it follows that it is a Lie subgroup of dimension $n$. In particular, it must contain a neighborhood of the identity, which generates $G$. Also, note that it is not always true that the subgroup generated by 1-parameter subgroups is a Lie subgroup; consider the 1-parameter subgroup of the 2-torus that is a line with irrational slope.","['lie-algebras', 'lie-groups', 'differential-geometry']"
147073,Slick proof the determinant is an irreducible polynomial,"A polynomial $p$ over a field $k$ is called irreducible if $p=fg$ for polynomials $f,g$ implies $f$ or $g$ are constant. One can consider the determinant of an $n\times n$ matrix to be a polynomial in $n^2$ variables. Does anyone know of a slick way to prove this polynomial is irreducible? It feels like this should follow quite easily from basic properties of the determinant or an induction argument, but I cannot think of a nice proof. One consequence of this fact is that $GL_n$ is the complement of a hypersurface in $M_{n}$. Thanks.","['linear-algebra', 'algebraic-geometry', 'determinant']"
147074,Product of positive definite and seminegative definite matrices,Let $A$ a spd (symmetric positive definite) matrix and $B$ a symmetric seminegative definite matrix. Is tr $AB \leq 0$ and more general is $AB$ seminegative definite? I know that tr $AB \leq 0$ follows from $AB$ seminegative definite since the eigenvalues $\lambda$ of $AB$ are nonpositve and hence tr $AB=\sum_{\lambda \in spec\ A} \lambda \leq 0$. But I don't know how to find something out about the definitness of $AB$. I think in general there is nothing you can say about the eigenvalues of $AB$. Thanks in advance!,"['numerical-linear-algebra', 'matrices', 'linear-algebra']"
147077,Online videos on Measure theory.,"I am looking for lecture videos on Measure Theory. I am not able to find any. 
Looking forward for your response.","['online-resources', 'measure-theory', 'education']"
147084,Slutsky's theorem for random matrices,This image is from Applied Multivariate Analysis . In this image plim means convergence in probability. I could not find the reference about the statement for random matrices. I'd highly appreciate if you cite the reference or give the proof. Thanks,"['probability-theory', 'matrices', 'random-matrices']"
147089,Translation invariant measures on $\mathbb R$.,What are all the translation invariant measures on $\mathbb{R}$? Except Lebesgue measure on $\mathbb R$ I didn't find any translation invariant measure. So I put this question? I know that if $\mu$ is a measure then $c \times \mu$ is again a measure where $c>0$.,"['measure-theory', 'real-analysis']"
147109,Showing this sequence converges.,"Given a sequence $x_n=\left(\dfrac{2n^3+n}{n^3} \right)+ i\left(\dfrac{3n}{n+1}\right)$, how would I show it converges? How would I choose $N$? I did the following. Given $\epsilon >0,$ choose $N>[?]$. Then for $n>N$ \begin{align}
\left \lvert x_n-(2+3i) \right \rvert & = \left \lvert \frac{2n^3+n}{n^3}-2 \right \rvert+ \lvert \frac{3n}{n+1}-3 \rvert\\
& = \left \lvert \frac{1}{n^2} \right \rvert+ \left \lvert -\frac{3}{n+1} \right \rvert\\
& =\frac{1}{n^2}+\frac{3}{n+1} \\
& = \frac{n+1+3n^2}{n^2+n^3} <?<\epsilon
\end{align} Hence $x_n \rightarrow 2+3i$.","['sequences-and-series', 'analysis']"
147118,Is the boundary of a clopen set the empty set?,"If a set $X$ is closed then $\overline{X} = X$ and if it is open then $X^o = X$, so does this mean that for a subspace $X$ of a topological space which is both open and closed (for example in a partition) the boundary given by $\overline{X} \backslash X^o$ is just the empty set? Conversely does this mean that all sets, in which the boundary is the empty set, are clopen sets?",['general-topology']
147147,What was Ramanujan's solution to the House Number Problem?,"The wikipedia entry on Ramanujan contains the following passage : One of his remarkable capabilities was the rapid solution for
problems. He was sharing a room with P. C. Mahalanobis who had a
problem, Imagine that you are on a street with houses marked $1$ through $n$ . There is a house in between $(x)$ such that the sum of the
house numbers to left of it equals the sum of the house numbers to its
right. If $n$ is between $50$ and $500$ , what are $n$ and $x$ ? This is a
bivariate problem with multiple solutions. Ramanujan thought about it
and gave the answer with a twist: He gave a continued fraction. The
unusual part was that it was the solution to the whole class of
problems. Mahalanobis was astounded and asked how he did it. ""It is
simple. The minute I heard the problem, I knew that the answer was a
continued fraction. Which continued fraction, I asked myself. Then the
answer came to my mind,"" Ramanujan replied. What was the continued fraction, and how did it give all solutions to the problem? Most importantly, how could someone derive such a solution? Do similar problems also have continued fractions that describe all solutions? This seems like an interesting and powerful method, and I would like to learn more about it.","['algebra-precalculus', 'continued-fractions', 'elementary-number-theory', 'math-history', 'problem-solving']"
147157,Liminf and Limsup of a sequence of sets,"I am attempting to learn some measure theory and am starting with liminf and limsup of sequences of sets. I found an example that is as follows: $$A_n=\left\{\frac0n, \frac1n, \dots , \frac{n^2}n\right\}$$ and I am trying to find the limsup and liminf. My understanding is that both deal with the tail sequences, and that limsup involves values that appear ""infinitely often"" and liminf covers values that appear ""all but finitely often"". Also I understand that $\liminf A_n\subset\limsup A_n$. For the above example, if I enumerate the first few sets, it is clearly evident that ${0}$ appears i.o. It also seems (to me) that as $n\to\infty$, all of the positive rational numbers appear. I am having trouble seeing the limits. For example, no matter how large I choose $N$, there is some $n\ge N$ in which all of the rationals appear, right? Obviously I am confused (this is all self-taught), so any explanation would be greatly appreciated. I seem to be able to make sense of liminf and limsup when the sequence is of a form similar to $[0, n/(n+1))$ and other examples, but I'm struggling with this example. One simple question: does an event have to ""not"" show up sometimes to be part of the liminf, or is it just that it is allowed to be missing finitely often? Assuming for a moment that the former is true, it appears to me that {0} is definitely in both liminf and limsup: that is, no matter how large I select N, {0} is in some (in this case, all) A_n with n>N. Moving on from there, it is clear to me that the integers begin to appear over and over again, and as n-->infinity, the rationals begin to ""fill out"" as well. Where I seem to be getting stuck is that the integers only show up equal to ""n"" and it is not clear to me how to handle the fact that the sequence is unbounded. Intuitively, all of the (positive) integers eventually show up (always), but they are far from the only values that do. {1/2} shows up always, for example. I'm not sure if {Q_+} eventually shows up, and this may be due to a lack of formal construction of Q in my past. What I recall is that Q is essentially all real numbers that can be expressed as m/n with m and n members of Z. Thank you.","['measure-theory', 'probability']"
147172,How are the sum and product of root formulas derived?,"For a polynomial of degree n,say 
$$F(x)=a_{0}+a_{1}x+a_{2}x^2+a_{3}x^3+....+a_{n}x^n$$ The sum of roots is $-\frac{a_{n-1}}{a_n}$ and the product of roots is $(-1)^n \frac{a_{0}}{a_n}$ where the $a_i%$ are the coefficients of the polynomial. I've been using these formulas for some problems, but I don't get why they are true. How are they derived? Thanks.","['algebra-precalculus', 'roots', 'polynomials']"
147180,Surjective map on coordinate rings implies the map is injective,Let $X$ and $Y$ be affine varieties and $f: X \rightarrow Y$ a polynomial map. If the induced map on coordinate rings $K[Y] \rightarrow K[X]$ is surjective why this implies that $f$ is injective?,['algebraic-geometry']
147186,"Prove that if $a\in [0,1]$, then $\lim\limits_{x \to a} f(x) =0$","Supose that for any natural number $n$, $A_n$ is a finite set of numbers from $[0,1]$, and that $A_m$ and $A_n$ have no common elements if $m \neq n$, ie $$m \neq n \Rightarrow A_n\cap A_m=\emptyset$$ Let $f$ $$f(x)=  \begin{cases} 1/n & \text{for } x \in A_n \cr 0 & \text{for } x \notin A_n \text{ for any }n \end{cases}$$ I guess the definition is clear: If $x$ is in some of the $A_n$ then we map it to $1/n$, and if $x$ is in no $A_n$ the function is zero. It's like a modified characteristic function. $$f(x) =\sum_{n \in \Bbb N} \frac 1 n  \chi_{A_n}$$ (Thanks Asaf) I have to prove that $$\lim_{x \to a }f(x)=0$$ for all $a$ in $[0,1]$ This is my inutuitive interpretation of the problem. Since all the $A_n$ are finite sets, the union  $S= \bigcup_{n \in \Bbb N}A_n$ of the sets is countably infinite. (Maybe this has to be proven before, but I think it is true.) This means that $f(x)\neq 0$ for countable infinite many $x$. But then the set of $x$ such that $f(x)=0$ is uncountable, since $[0,1]$ is uncountable so $f$ is $0$ almost everywhere in $[0,1]$. Although this is not homework, I'd like you to help me find the way to the ""solving argument"", maybe show how it can be done for $a=1/2$. This is from Spivak's Calculus, so all the set theoretic things I wrote don't really apply, it should probably be proven by some basic set arguments and the definition of the limit. Attempt of proof: DEFINITION : $$\lim_{x \to a}f(x)=L$$ if $\forall \epsilon >0 \exists \delta >0 : 0<|x-a|<\delta \Rightarrow |f(x)-L|<\epsilon$. This is Spivak's definition. Note that $0<|x-a|$ means the limit excludes the point $a$. Suggested by t.b. is the notation $$\lim_{\substack{x \to a \\ x \neq a}} f(x)$$ T Let $f : [0,1] \to \mathbb Q$ such that $$f(x) = \sum_{n \in \Bbb N} \frac{\chi_{A_n}(x)}{n}$$ then $$a \in [0,1] \Rightarrow \lim_{x \to a} f(x) = 0$$ P (Based on Zhang's idea). Since $A_1$ is finite, there exists a $\delta_1 >0$ such that no $x \in A_1$ is in $(a-\delta_1,a)\cup (a,a+\delta_1)$. Thus, $|f(x)|< \dfrac 1 2$ for $0<|x-a|<\delta_1$. Similarily, $\exists \delta_2 >0 : x\in A_2 \wedge x \notin (a-\delta_2,a)\cup (a,a+\delta_2) $ so $|f(x)|< \dfrac 1 3 $ for $0<|x-a|<\delta_2$. Analogously, $$\exists \delta_n >0 : x\in A_n \wedge x \notin (a-\delta_n,a)\cup (a,a+\delta_n) $$, so $$|f(x)|< \dfrac 1 n \text{ for } 0<|x-a|<\delta_n$$ Revised: Let $\epsilon>0$ be given. Let $N\in \mathbb N$ such that $1/N < \epsilon$. Let $n \geq N$, and $$\delta = \min    \{ \delta_1,\cdots,\delta_n\}$$ Then $$0<|x-a|<\delta \Rightarrow |f(x)|<\epsilon$$  ∎. Today I was discussing this problem with a professor and at first glance he thought it was the case that $$S= \bigcup_{n \in \Bbb N}A_n= [0,1]$$ I provided the following explanation. By Cantor's proof, $[0,1]$ is uncountable. I'll use $\sim$ to say there is a bijection between two sets $A$ and $B$. Since all the $A_n$ are finite, their cardinality is a natural number, so $$A_1 \sim \left \{ 1,2,\cdots, |A_1| \right \}$$ $$A_2 \sim \{ |A_1|+1,\cdots, |A_1|+|A_2| \}$$ $$\cdots$$
$$A_n \sim \left\{ \sum_{k <n}|A_k|+1,\cdots, \sum_{k \leq n} |A_k|\right\}$$ Then, taking the union produces
 $$\bigcup_{n \in \Bbb N}A_n\sim  \Bbb N$$ so the set $S$ is countable and thus can't be $[0,1]$. So far, I have these satisfactory ideas, but I want to write an acceptable proof. anon : If $g$ and $f$ differ at only a finite number of points then $\lim f = \lim g$. We define a useful $g_m$ such that it differs with $f$ at only a finite amount of points, and we show $0 \leq g_m \leq 1/m$. I got this one and hope I can devise a proof. Levon/Glouglou/Zhang Show that for any sequence $x_n$ s.t. $x_n \to a$, there exists an $n_0$ such that $$\{ x_k \}_{k \geq n_0}\cap A_n=\emptyset$$ for all $n \in \Bbb N$. This means that for a suitable $\delta$, the set $M=\{ x : x \in [a-\delta,a+\delta]\}$ contains no $x \in A_n$, so $f(x) < \epsilon$ (actually it is strictly $0$) in that neighborhood of $a$.","['calculus', 'elementary-set-theory', 'limits']"
147191,Show either $f$ is constant or $g(z)=0$ for all $z$ in the region,"let $G$ be a region, and $f$ and $g$ be holomorphic function on $G$. if $\bar{f}\cdot g$ is holomorphic, show that either $f$ is a constant or $g(z)=0$ for all $z$ in $G$.",['complex-analysis']
147202,Show that an entire function $f$ s.t. $|f(z)|>1$ for $|z|>1$ is a polynomial,"I have been struggling on the following problem. Suppose $f$ is an entire analytic function such that $|f(z)|>1$ if $|z|>1$. Show that $f$ is a polynomial. My idea is as followed: all zeros of $|f(z)|$ lie inside $|z|\leq 1$. Applying Argument Principle, we can show that number of zeros of $f$ is bounded. So we can assume $f(z)=(z-z_1)...(z-z_M)g(z)$ where g is entire analytic without any zeros.
Then I would like to apply Liouville's Theorem: the point is that it isn't too clear to me why $|\dfrac{1}{g(z)}|$ is a bounded function.",['complex-analysis']
147211,Topological proof of Bolzano-Weierstrass,"Below is my attempt to prove the topological version of the Bolzano-Weierstrass Theorem.  Is it an effective proof?  I'd appreciate any comments on it.  The book gave a hint to use a nested sequence of half-intervals.  The idea is pretty intuitive...I'll explain it if anyone would like me to. Bolzano-Weierstrass Theorem: ""Every bounded, infinite subset of $\mathbb{R}$ has a limit point."" ""Let $A$ be a bounded, infinite subset of $\mathbb{R}$.  Then since $A$ is bounded, it is a subset of some closed interval $[a,b]$.  Take a sequence of half-intervals of $[a,b]$, $\{[a_n,b_n]\}_{n=1}^\infty$ where $[a_1,b_1]=[a,b]$.  By Cantor's Nested Intervals Theorem $\displaystyle\bigcap_{n=1}^\infty [a_n,b_n]$ is nonempty and since $\mbox{diam}([a_n,b_n]) \to 0$ as $n \to \infty$, the intersection contains exactly one element, say $p$.  Since $p \in \displaystyle\bigcap_{n=1}^\infty [a_n,b_n]$ and every $[a_n,b_n]$ contains infinitely many elements of $A$*, so does $(a_n,b_n)$.  Since $\mbox{diam}(a_n,b_n) \to 0$ as $n \to \infty$, every open set containing $p$ also contains some $(a_n,b_n)$, so $p$ is a limit point of $A$."" *Intuitively, if we cram an infinite number of points into a bounded interval, they will be 'dense' in that interval (I haven't formally learned what 'dense' means yet), but how do we prove it?","['general-topology', 'metric-spaces']"
147243,Homogenous localization and usual localization in graded rings,"Let $R$ be a graded ring. There are two ways to take the localization of $R$ . Let $\mathfrak{p}$ be a homogeneous prime ideal, $T$ be the set of all homogenous elements of $R\setminus \mathfrak{p}$ . Then $R_{(\mathfrak{p})}$ , the subring of $T^{-1}R$ consisting of all $\dfrac{f}{g}$ where $f$ and $g$ are homogeneous of the same degree, is called homogeneous localization of $R$ . Let $R$ be a graded ring, $S\subset R$ is a multiplicative closed subset of $R$ . For any $f\in R, g\in S$ define the degree of $\dfrac{f}{g}$ to be $\deg f-\deg g$ . Then it is not hard to check that this is well defined. The localization $S^{-1}R$ is a graded ring. My question are the following: What is the difference between these two localizations? What are the applications of them in higher commutative algebra ?","['commutative-algebra', 'abstract-algebra']"
147246,Does $\int_0^\infty\frac{\cos^2x}{x^2+5x+11}dx$ converge or diverge?,"When I'm learning convergence, my teacher just show me about condition to convergence or not. But I haven't meet a function that contain both trigonometric and normal polynomial. When I asked one of my friends, he tell me that using Taylor to developed $\cos x$, but I'm afraid that is not the good solution. $$\int_0^\infty\frac{\cos^2(x)}{x^2+5x+11}dx$$ Thanks :)","['convergence-divergence', 'integration']"
147247,Constructing the reals from fractions of ordinals,We can construct the positive rationals from ratios of positive integers (and thus from pairs of finite ordinals). Can we analogously construct the reals from pairs of countable ordinals?,"['set-theory', 'ordinals', 'abstract-algebra']"
147267,Is the determinant of a matrix lower when all its elements are lower?,"Problem Consider a generic matrix $A$, we are going to think of a simple case by taking into consideration a $3 \times 3$ matrix: $$
A = \begin{pmatrix}
a_{1,1} & a_{1,2} & a_{1,3}\\
a_{2,1} & a_{2,2} & a_{2,3}\\
a_{3,1} & a_{3,2} & a_{3,3}\\
\end{pmatrix}
$$ Consider now having $A'$ as: $$
A' = \begin{pmatrix}
a'_{1,1} & a'_{1,2} & a'_{1,3}\\
a'_{2,1} & a'_{2,2} & a'_{2,3}\\
a'_{3,1} & a'_{3,2} & a'_{3,3}\\
\end{pmatrix}
$$ The following holds: $$a'_{i,j} \leq a_{i,j}$$ Question I would like to know if the following: $$|A'| \leq |A|$$ If it holds, can you prove it? Another problem What if we considered: $$
a_{i,j} \leq 1, a'_{i,j} \leq 1
$$ Considering also that $A$ is a stochastic matrix? This does not mean that both $A$ and $A'$ are stochastic. I am considering $A$ stochastic and $A'$ obtained as a reduced version of $A$ so that $A'$ is not stochastic but its values are all between 0 and 1.","['matrices', 'linear-algebra', 'determinant']"
147297,"If $M$ is complete and $f : (M,d)\to(N,p)$ is continuous, then $f(M)$ is complete?","Prove or disprove: If $M$ is complete and $f:(M, d )\to (N, p)$ is continuous, 
then $f(M)$ is complete.","['general-topology', 'metric-spaces', 'real-analysis']"
147311,Generalizations of equi-oscillation criterion,"When constructing minimax (sup-norm) polynomial approximations of real-valued functions, well-known results say (roughly speaking) that optimal solutions are characterized by the fact that they have equi-oscillatory errors. Are there generalisations of this result to other kinds of approximations? I'm especially interested in minimax approximations of curves in two or three dimensions. Take for example the circle $x^2 + y^2 = 1$, or its first quadrant. I have constructed very good approximations using polynomials $P(t) = (x(t), y(t))$, and I find that they are equi-oscillatory. I'd like to know if there's any theory that supports this experimental finding. Of course, I could just write the circle quadrant as $x=\cos t$, $y=\sin t$, and approximate the sine and cosine functions. But this is a different problem, and this approach gives circle approximations that are significantly inferior to the ones I constructed. So, decomposing the 2D problem into two 1D ones is not what I'm after. In three dimensions, my ""curve"" would be given by a pair of equations $f(x,y,z)=0$ and $g(x,y,z)=0$. In this case, I don't even know how to define ""equi-oscillatory"" or even ""oscillation"". Thanks.","['geometry', 'plane-curves', 'approximation-theory']"
147324,"Min/Max of $f(x,y) = e^{xy}$ where $x^3+y^3=16$","Use Lagrange multipliers to find the maximum and minimum values of the function :$$f(x,y)=e^{xy}$$ 
constraint $$x^3+y^3=16$$ This is my problem in my workbook. When I solve, I'm just have one solution, so I cannot find other. Here is my solution: $$f(x,y) = e^{xy}$$
$$g(x,y) = x^3+y^3-16$$
$t(x,y) = f(x,y) + \lambda*g(x,y)$
So we will have three equations by Lagrange Multiplier: $$(1) y*e^{xy} + 3*\lambda*x^2 = 0$$
$$(2) x*e^{xy} + 3*\lambda*y^2 = 0$$
$$(3)x^3+y^3 = 16$$ If $x=0$ or $y=0$ $==>$ $y=0$ or $x=0$ --> false
if $t=0$ $==>$ $x=y=0$ ---> false So, $x$,$y$ and $t$ cannot equal to 0. So, we have from (1) (2) and (3):
$$\frac{e^{xy}}{-3*\lambda} = \frac{x^2}{y}$$
$$\frac{e^{xy}}{-3*\lambda} = \frac{y^2}{x}$$
$$==> x= y $$
==>$$ x = y = 2 $$ That is my solution. I just have one no, so I cannot find both min and max. Maybe something wrong with my solution. Please helps me. Thanks :)","['inequality', 'analysis']"
147332,Can a Herglotz-Nevanlinna function attain real values?,"Let $\mathbb{H}^+=\{z \in \mathbb{C}\mid \Im(z)>0\}$. We say that an analytic $F\colon \mathbb{H}^+\to\overline{\mathbb{H}^+}$ is a Herglotz-Nevanlinna 's function. Question Can it be that $F(z)\in \mathbb{R}$ for some $z \in \mathbb{H}^+$? I guess that the answer is no, because if this happened then we could find a small loop $\gamma$ around $z$ such that $F\circ \gamma$ slips outside $\overline{\mathbb{H}^+}$, but I'm not sure this is true and how to formalize this little argument. Thank you.",['complex-analysis']
147342,Backwards induction to show that $x_1\cdots x_n \leq ((x_1+\cdots+x_n)/n )^n$,"This question is from ""Concrete Mathematics"", by Knuth. Sometimes it's possible to use induction backwards, proving things from $n$ to $n-1$ instead of vice versa! For example, consider the statement $P(n)$ : $\displaystyle x_1x_2\cdots x_n \leq \left( \dfrac{x_1+x_2+\cdots+x_n}{n} \right)^n$ , if $x_1,\cdots,x_n\geq 0$ . This is true when $n = 2$ , since $(x_1 + x_2)^2 - 4x_1x_2 = (x_1 - x_2)^2 \geq 0$ . a. By setting $x_n = (x_1 + \cdots + x_{n-1})/(n - 1)$ , prove that $P(n)$ implies $P(n-1)$ whenever $n > 1$ . b. Show that $P(n)$ and $P(2)$ imply $P(2n)$ . c. Explain why this implies the truth of $P(n)$ for all $n$ . I will post an answer to this question with my attempt at a solution. I would like to know if my solution is correct and consistent, or if there is a better way of solving it.","['induction', 'discrete-mathematics']"
147356,Proof of the L'Hôpital Rule for $\frac{\infty}{\infty}$,"I ask for the proof of the L'Hôpital rule for the indeterminate form $\frac{\infty}{\infty}$ utilizing the rule for the form $\frac{0}{0}$. Theorem: Let $f,g:(a,b)\to \mathbb{R}$ be two differentiable functions such as that: 
$\forall x\in(a,b)\ \ g(x)\neq 0\text{ and }g^{\prime}(x)\neq 0$ and $\lim_{x\to a^+}f(x)=\lim_{x\to a^+}g(x)=+\infty$
If the limit $$\lim_{x\to a^+}\frac{f^{\prime}(x)}{g^{\prime}(x)}$$ exists and is finite, then
 $$\lim_{x\to a^+}\frac{f(x)}{g(x)}=\lim_{x\to a^+}\frac{f^{\prime}(x)}{g^{\prime}(x)}$$ My attempt: 
Since $\lim_{x\to a^+}f(x)=+\infty$, $$\exists \delta>0:a<x<a+\delta<b\Rightarrow f(x)>0\Rightarrow f(x)\neq 0$$ 
Let $F,G:(a,a+\delta)\to \mathbb{R}$, $F(x)=\frac{1}{f(x)}$, $G(x)=\frac{1}{g(x)}$. Then by the hypothesis $\lim_{x\to a^+}F(x)=\lim_{x\to a^+}G(x)=0$, $$\forall x\in(a,b)\ \ G(x)\neq 0\text{ and }G^{\prime}(x)=-\frac{1}{g^2(x)}g^{\prime}(x)\neq 0$$
The question is, does the limit $$\lim_{x\to a^+}\frac{F^{\prime}(x)}{G^{\prime}(x)}=\lim_{x\to a^+}\frac{-\frac{1}{f^2(x)}f^{\prime}(x)}{-\frac{1}{g^2(x)}g^{\prime}(X)}=\lim_{x\to a^+}\frac{g^2(x)f^{\prime}(x)}{f^2(x)g^{\prime}(x)}$$ exist? The limit $$\lim_{x\to a^+}\frac{f^{\prime}(x)}{g^{\prime}(x)}$$ exists by the hypothesis but we don't know if the limit $\displaystyle\lim_{x\to a^+}\frac{g^2(x)}{f^2(x)}$ exists to deduce that the limit $$\lim_{x\to a^+}\frac{F^{\prime}(x)}{G^{\prime}(x)}$$ exists to use the L'Hôpital Rule for the form $\frac{0}{0}$. EDIT: After discussing it with other users in the site, we came to the conclusion that this proof is only partial and can't logically be continued to yield the Theorem. 
As a result, the rule for the $\frac{0}{0}$ form can't be used to proove the rule for the  $\frac{\infty}{\infty}$ form.
Mr. Tavares and myself have already given two different proofs (with the pretty much the same main idea) of the Theorem in question using Cauchy's Mean Value Theorem. You can read them below. You can also read the proof Rudin gives for a stronger version of the Theorem (that does not suppose that $\lim_{x\to a^+}f(x)=+\infty$) in his book Principle of Meathematical Analysis. If you have any objections in either proofs please let me know. Thank you.","['real-analysis', 'limits']"
147370,Commutative matrices are multiples of the identity,"Assume M is a $2 \times 2$ real matrix such that $MX = XM$ for all real $2\times2$
  matrices $X$. Show that $M$ must be some real multiple $q$ of $I$. I can see that this is logical and have tried a few examples where I have multiplied $qI$ by some random $2\times2$ matrix from both sides and get the same matrix in both cases. How would I go about showing this though? Surely a few examples aren't actually showing anything for the general case, right? Also, does the property shown in the question hold for all square matrices, or just $2\times2$ ones?","['matrices', 'linear-algebra']"
147376,Symmetric Matrix as the Difference of Two Positive Definite Symmetric Matrices,"Prove that any real symmetric matrix can be expressed as the difference of two
  positive definite symmetric matrices. I was trying to use the fact that real symmetric matrices are diagonalisable , but the confusion I am having is that 'if $A$ be invertible and $B$ be a positive definite diagonal matrix, then is $ABA^{-1}$ positive definite' . Thanks for any help .","['matrices', 'linear-algebra']"
147377,Other functional equations for $\zeta(s)$?,"For the Riemann zeta function, we know of the standard functional equation that relates $\zeta(s)$ and $\zeta(1-s)$. I wanted to know whether there are functional equations that relates $\zeta(s)$ and $\zeta(s-1)$? EDIT: My main motivation behind asking this question is I have found such an equation, but I do not know whether such an equation exists in literature. Also, I do not want to appear as if I am promoting my formula here, but rather I am more interested in the works that have been done in such directions. As per @lhf's request here is my formula, for $\Re(s) > 1$
$$ \zeta(s) + \frac{2}{s-1}\zeta(s-1) = \frac{s}{s-2} - s\int_1^\infty \frac{\{x\}^2}{x^{s+1}} dx$$ where $\{x\}$ is the fractional part of x.","['analytic-number-theory', 'riemann-zeta', 'complex-analysis']"
147378,Solving non homogeneous differential equation,"I have the following equation: $$\frac{dx}{dt}+x=4\sin(t)$$ For solving, I find the homogenous part as:
$$f(h)=C*e^{-t}$$ Then finding $f(a)$ and $df(a)$:
$$f(a)=4A\sin(t)+4B\cos(t)$$
$$df(a)=4A\cos(t)-4B\sin(t)$$ Substituting in orginal equation: $$4A\cos(t)-4B\sin(t)+4A\sin(t)+4B\cos(t)=4\sin(t)$$ I have to find numerical values of $A$ and $B$ but I absoloutly have no idea how can I solve this, I am also not sure if the steps I did are correct or not. Would somone please help with this equation? The final answer should be substituted in:
$$x=f(h)+f(a)$$","['linear-algebra', 'calculus', 'ordinary-differential-equations']"
147381,Why do we essentially need complete measure space?,"While reading the motivation of complete measure space on Wikipedia , what I concluded was, 
completeness is not really necessary when we define on one measure space  and it is necessary when we want to measure on product of measure spaces (is it true ?).  If $\lambda$ is measure on $X$ and $Y$ then is it true that $\lambda^2$ is measure of $A$x$B$ and how ? 
I am not able to understand that $\lambda^2(A\times B)=\lambda(A)\times\lambda(B)$ ? 
Essentially what is the flaw in the measure without being complete ? 
Waiting for response. Thanks!","['measure-theory', 'real-analysis']"
147384,Free subgroup of an amalgamated free product,"I have the following question: Let $G=A\underset{C}\star B$ be the free product of two groups $A$ and $B$ with amalgam $C$, such that $C\cap vCv^{-1}=1$ for all reduced words $v$ in G with length $\geq k$. Let $w\in G$ be a reduced word of length $\geq 2k+1$.
I want to show that $\langle A,wAw^{-1} \rangle\cong A\star A$. How can i show that $A\cap wAw^{-1}=1$?
Thanks for help!","['geometric-group-theory', 'group-theory']"
147386,regular functions: two definitions,"Let $X$ be an (affine) algebraic set i.e. the zeros' locus of a set of polynomial $S\subseteq k[X_1,\ldots,X_n],$ Let's look at these two definitions: 1) A regular function in $p\in X$, is an element of the following ring:
$$\mathcal O_{X,\,p}=\{\frac{f}{g}\;:\;f,g\in k[X_1,\ldots,X_n]/I(X),\;g(p)\neq 0\}$$ Moreover a regular function on $U\subseteq X $ open (respect the Zariski toplogy?) is an element of the ring
$$\mathcal O_X(U)=\bigcap_{p\in U} \mathcal O_{X,\,p}$$ 2) If $U\subseteq X$ is open (respect the Zariski toplogy?), a set theoretic function $\phi:U\rightarrow k$ is regular at a point $p$ if exists a neighborhood $V$ of $p$ such that there are polynomials $f,g\in k[X_1,\ldots,X_n]$ with $g(q)\neq 0$ and $\phi(q)=\frac{f(p)}{g(q)}$ for all $q\in V$. It is called regular on $U$ if it is regular at every $p\in U$. Now i have two questions: a) Stupid question: When we talk about neighborhoods and open sets in $X$, do we refer to the Zariski topology? b) Important question: If $X$ is irreducible, (so $k[X_1,\ldots,X_n]/I(X)$ is a domain) one can show that the two definitons are equivalent. But if $X$ is NOT irreducible we have that $2)\nRightarrow 1)$. Is it correct?",['algebraic-geometry']
147395,Application of Stone-Weierstrass Theorem,"Suppose that $f \colon [0,1] \rightarrow \mathbb{R}$  is a continuous function on $[0,1]$ with $$\int_0^1 f(x)\ dx  = \int_0^1 f(x)(x^n+x^{n+2})\ dx$$ for all $n=0,1,2, \dots$. Show that $f\equiv 0$. Can someone help me with this question? Is this one of the questions where we apply the Stone-Weierstrass Theorem? Thanks",['real-analysis']
147401,Does the contraction from the localized ring preserve colon ideals and ideal sums/products?,"Let $A$ be a commutative ring and $B = S^{-1}A$ be its localization with respect to a certain multiplicative subset of $A$. Consider the contraction (in $A$) of colon ideals and ideal sums and ideal products (in $B$) as long as they make sense. Do contracted ideals still possess the original characteristics? That is, will the contraction of colon ideals (resp. of sums, resp. of products) in $B$ be colon ideals (resp. sums, resp. products) of the corresponding contracted ideals in $A$? I suspect there are counterexamples if $A$ is not noetherian, but I have no idea how to tackle this. (Thanks for pointing out obscurity. I hope this time it is more legible.)","['localization', 'commutative-algebra', 'ideals', 'abstract-algebra']"
147414,Determine variance & mean,"I am not sure how to determine the variance and mean for the following equation system. I'd greatly appreciate your help! $
  f_\xi(x) = \left\{
  \begin{array}{l l}
    10k_1x & \quad \text{for $0<x<1$}\\
    0 & \quad \text{for other}\\
  \end{array} \right.
$ $
  f_\eta(x) = \left\{
  \begin{array}{l l}
    4k_2x & \quad \text{for $0<x<1$}\\
    4k_2(2-x) & \quad \text{for $1\leq x<2$}\\
  \end{array} \right.
$ I have determined the following: $k_1 = \frac{1}{5}$ $k_2=\frac{2}{7}$ ... and I believe to have found their individual variance and mean: $E_\xi(x)=\frac{2}{3}$ $V_\xi(x)=\frac{1}{18}$ $E_\eta(x)=\frac{22}{21}$ $V_\eta(x)=\frac{145}{882}$ Now to the gist of my question: how do I calculate the variance and the mean for $10\xi+2\eta$? Thank you!","['statistics', 'integration']"
147423,"Modified two child problem. Find the probability that both are girls, given that at least one is a girl born in March.","A family has two children. Assume that birth month is independent of gender, 
with boys and girls equally likely and all months equally likely, and assume that the 
elder child’s characteristics are independent of the younger child’s characteristics). What is the probability that both are girls, given that at least one is a girl who was 
born in March.",['probability']
147432,Quasi-Isometry [Geometric Group Theory],"How can I prove that if $S,S'$ are two different finite generating sets of a group $G$ , then the metric spaces induced by the ""word metric"" are quasi-isometric? The definition of quasi-isometry is:
Let $X,Y$ be compact metric spaces, and $f:X \to Y$ a map. We say that $f$ is a quasi-isometry if there exist $L,A>0$ such that for every $x_1 ,x_2 \in X$ , $y \in Y$ : 
$ \frac{1}{L} d(x_1, x_2) -A \leq d(f(x_1), f(x_2)) \leq Ld(x_1,x_2) +A$  and $d(y, f(X))\leq A$ . [The first condition is the problematic one... How can we find proper constants L, A ? ] 
Thanks in advance !","['geometric-group-theory', 'metric-spaces', 'group-theory']"
147438,$3^2 \ 5^2 \ldots (p-2)^2 \equiv (-1)^{\frac{p+1}{2}} \ (\mathrm{mod} \ p)$ [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: Why is the square of all odds less than an odd prime $p$ congruent to $(-1)^{(p+1)/(2)}\pmod p$? Why is $3^2 \  5^2 \ldots (p-2)^2 \equiv (-1)^{\frac{p+1}{2}} \ (\mathrm{mod} \ p)$, where $p$ is an odd prime? I can't seem to figure it out. Any help would be appreciated. Thanks!",['number-theory']
147443,"Conceptual proof that $p\choose k$ ($1 < k < p$) is divisible by $p$ when $p$ is prime? (I.e., no equations).","If $n,k\in \mathbf{N}$, then one defines $n\choose k$ to be the number of ways to choose $k$ elements from a set of size $n$. One can then show (by a combinatorial argument) that $${n\choose k} = \frac{n!}{k!(n-k)!}$$
whenever $n\choose k$ is defined. In particular, since this expression is an integer for all $n$ and $k$, when $n=p$ is a prime, $p\mid{p\choose k}$ when $1< k<p$. I've wondered sometimes if there is also a proof of this fact which does not use the formula above; i.e., maybe one can see it by using the definition of $n\choose k$? What do you think?","['divisibility', 'elementary-number-theory', 'prime-numbers', 'binomial-coefficients', 'combinatorics']"
147446,Completeness of $\ell^2$ space,"I was reading up and it says that $(\ell^2,\|.\|_2)$ is complete. I know that a metric space $X$ in which every Cauchy sequence converges to an element of $X$ is called complete. And I know that a sequence is Cauchy if given $\epsilon$, there exists $N \in \mathbb{N}$ such that $|x_m-x_n|<\epsilon$ for all $n,m>N$. I was reading the proof that  $(\ell^2,\|.\|_2)$ is complete, but I don't understand where does the $x_k^n$ comes from. What does it mean when it writes $x_k^n$? Let $(x_n)$ be Cauchy in $\ell^2$, i.e. $\forall \epsilon>0$ there exists $N \in \mathbb{N}$ such that $\sum_{k=1}^\infty|x_k^n-x_k^m|^2 <\epsilon^2$ for $n,m>N$. For any fixed $k_0$, $|x_{k_0}^n-x_{k_0}^m|<\epsilon$ for $n,m >N$. So $(x_{k_0}^n)$ is Cauchy in $\mathbb{K}$ ($\mathbb{R}$ or $\mathbb{C})$ and converges to say $y_{k_0}$. Also, why did they square $\sum_{k=1}^\infty|x_k^n-x_k^m|^2 <\epsilon^2$?","['lp-spaces', 'metric-spaces', 'functional-analysis', 'banach-spaces']"
147470,Projective Space orientation,"I'm trying to prove that the projective plane $\mathbb{P}^n$ is orientable is and only if $n$ is odd. To do that that, I have a hint,to prove that the antipodal map is orientation preserving if only if $n$ is odd, I've done that, but it don't know how to conclude the result.",['differential-geometry']
147475,Proving that the maximum of two convex functions is also convex,"Here's a homework question I'm struggling with: Let $f,g$ two convex functions. Prove that $h(x)=\max\{f(x),g(x)\}$ is
also convex I don't know where to begin. The only thing I had in mind was was to try proving that if a function is convex on two sets $A$ and $B$ , it is also convex on their union. That does not seem right though, for example, if I glue together $f(x)=x^2, g(x)=\frac{x^2}{1000}$ where $f$ is defined on $[0,1]$ and $g$ on $(1,2]$ . Anyway, that was the only thing I thought about. Any better ideas? thanks!",['calculus']
147501,Prove Continuous functions are borel functions,"Take $f: (a,b) \to \mathbb{R}$ , continuous for all $x_{0}\in (a,b)$ and take $(Ω = (a,b) , F = ( (a,b) ⋂  B(\mathbb{R}))$ where $B(\mathbb{R})$ is the Borel $\sigma$-algebra. Prove $f$ is a borel function by showing that $\{x \in(a,b): f(x) < c \}$ is in $F$. I know that continuity of f means that for all $x\in(a,b)$ and all $\varepsilon>0$ there exists a $\delta>0$ such that $|x-x_{0}| < \delta$ implies $|f(x)-f(x_{0})| < \varepsilon$. But Then I am stuck, how would I use these facts to help me ? Thanks in advance for any help",['measure-theory']
147515,Help understanding proof of Schwarz Inequality,"I'm working through Spivak's Calculus over the summer, and I'm currently on problem 19 of Chapter 1, which involves proving the Schwarz inequality. The first two parts of the proof are fairly straightforward, but I don't understand the last part. Spivak gives the inequality: $0<\lambda^2(y_1^2+y_2^2)-2\lambda(x_1y_1+x_2y_2)+(x_1^2+x_2^2)$ and suggests using the quadratic formula (I'm not sure I understand this part, since the equation is greater than zero, how can there be any solutions?) to arrive at the Schwarz inequality. In the answer key, the following is given. $\displaystyle\left[\frac{2(x_1y_1+x_2y_2)}{(y_1^2+y_2^2)}\right]^2-\frac{4(x_1^2+y_1^2)}{(y_1^2+y_2^2)}<0$ I'm not really sure how this follows since I can't get it just by trying to find the roots of the equations vis a vis the quadratic formula.","['inequality', 'calculus', 'analysis']"
147526,Expected Value of the Difference between 2 Dice,"What is the expected value of the absolute difference between 2 N
  faced dice? What about the difference between 2 dice one with N faces
  and one with M faces? While finding the expected value of 2 random variable sums or differences are simple enough, how do you deal with absolute value of differences? Thanks","['dice', 'puzzle', 'recreational-mathematics', 'probability']"
147528,How can you have a density function that depends on a parameter?,"Let $X_1,...,X_n$ be a random sample from a distribution with mass/density function $f_X$ that depends on a (possible vector) parameter $\theta$. Then $f_{X_1}(x_1) = f_X(x_1;\theta)$ so that $f_{X_1,...,X_k}(x_1,...,x_k) = \prod_{i=1}^kf_X(x_i;\theta).$ Could someone please explain what the significance of $\theta$ is in the above definition. I've never seen this before. Is it the mass/density function that depends on the parameter or is it the random sample that depends on the parameter.","['statistics', 'probability-distributions']"
147529,Solving the ODE $x''=\frac{1}{3x}$,"I am studying ODE and I just started learning about second order ODE. The question I'm trying to solve is somewhat of a physics problem (but a very simple physics, the hard part is the ODE involved). It is
$$x'' = \frac{1}{3x}.$$ Considering $x(t)$ as the distance between two bodies ($x'(t)$ is the velocity) I am giving the initial conditions : $x(0)=4,x'(0)=v(0)=-2$. I whish to find the value of $x(t)$ s.t $x'(t)=0$ (i.e where $v(t)=0$) and when does this happen (i.e find t s.t $v(t)=0$). I would appriciate any help on this, I didn't really try anything because I don't know how to proceed.",['ordinary-differential-equations']
147530,Normal Subgroups that Intersect Trivially,"Let $H$ and $K$ be normal subgroups of a group $G$ such that they intersect trivially. Why is it then the case that $$hk=kh;\;\;\;\; \forall h\in H,\;\forall k\in K?$$","['normal-distribution', 'group-theory', 'abstract-algebra']"
147548,Determining a finite set is a group from its multiplication table.,"At the end of page 4 of this document , it is proved from the multiplication table that $a^{-1}(ab)=b$. The point is to prove associativity, so I don't see how the conclusion that $a^{-1}(ab)=b$ follows. Can someone explain what the author is pointing at?","['group-theory', 'abstract-algebra']"
147561,Sheaves and complex analysis,"A complex analysis professor once told me that ""sheaves are all over the place"" in complex analysis. Of course one can define the sheaf of holomorphic functions: if $U\subset \mathbf{C}$ (or $\mathbf{C}^n$) is a nonempty open set, let $\mathcal{O}(U)$ denote the $\mathbf{C}$-vector space of holomorphic functions $f:U\to\mathbf{C}$, and we let $\mathcal{O}(\varnothing)=\{0\}$. The restriction maps are given by restriction holomorphic functions to open subsets.  This defines a sheaf on $\mathbf{C}$ with respect to its usual topology. Here are my questions: Are there interesting re-interpretations of well-known results in basic complex analysis in the language of sheaf theory (just to get one thinking about how things might translate)? Are there interesting new geometric insights that one gains by introducing this structure? (Feel free to reformulate the context of the question if 2 doesn't make sense). I guess I find it counter-intuitive that sheaves should say anything interesting about complex analysis, while it seems natural that they should say things about the geometry of the space on which they're defined.","['sheaf-theory', 'geometry', 'complex-analysis']"
147563,Prove that curve lies on a cone?,"I have a curve given by this equation:
$$c(t) = (t\cos t,t \sin t,t)$$ I need to prove that this curve lies on a cone, and draw that cone and curve in Sage. I've read somewhere that I could prove it by taking some random point and then put it into equation. But is there a more general proof, formal way of proving it lies on a cone? How should I prove it (the easiest way?)","['sagemath', 'geometry', '3d']"
147592,"What are all these ""visualizations"" of the 3-sphere?","a 2-sphere is a normal sphere.  A 3-sphere is $$
x^2 + y^2 + z^2 + w^2 = 1
$$ My first question is, why isn't the w coordinate just time? I can plot a 4-d sphere in a symbolic math program and animate the w parameter, as w goes from .1 to .9: Isn't that what it means to have a 4th dimension?  Just add time? Apparently not. This image is from wikipedia, The caption says that this is a ""Stereographic projection of the hypersphere's parallels (red), meridians (blue) and hypermeridians (green)"".  I don't get that at all.  What is a parallel, meridian, hypermeridian?  Why can't we just There is an article here which talks about the 3-sphere in terms of Poincare's Conjecture. Here there is an image of the ""Hopf fibration of the 3-sphere"". This looks very cool and there are formulas that break down the Hopf fibration into understandable algebra , but what does this mean, at a high level ? Edit: I am looking at the dimensions videos and they are actually very good.","['general-topology', 'geometry', 'visualization', 'hopf-fibration']"
147595,How would one rescale the variance and standard deviation of a set of data?,"I have a set of data with a certain mean, variance, and standard deviation. I centered the mean around the origin the standard way by subtracting it from the data. Now how do I modify the data to make variance = 1?","['statistics', 'probability-distributions', 'probability']"
147599,Continuous maps from products of topological spaces,"Let $X,Y,Z$ be topological spaces. It is well-known that if $F:X\times Y\to Z$ is a continuous map, we can define a map $$\overline{F}:X\to C(Y,Z) \\\overline{F}(x)(y)=F(x,y)$$ where $C(Y,Z)$ is the topological space of all continuous maps from $Y$ to $Z$ equipped with the compact-open topology, and this induced map is continuous. If $Y$ is locally compact Hausdorff, the converse holds, i.e. if a function $\overline{F}:X\to C(Y,Z)$ is continuous, and related to $F$ by the equation above, then $F$ is also continuous. This converse seems a bit unsatisfying, so I was wondering: Does the converse also hold under some weaker assumptions? What is the best known theorem in this regard? Also, I suspect the problem might be with the choice of topology on $C(Y,Z)$. As nice as the compact-open topology might be, I imagine there might be some other (more or less natural) choice of topology availible for which the continuity of $F$ and continuity of $\overline{F}$ would be equivalent. Does there exist such a topology?","['general-topology', 'continuity', 'product-space']"
147610,$\mathcal{H}$ is relatively compact iff every sequence in $\mathcal{H}$ has a convergent subsequence?,"I'm trying to prove that Let $(Y,\rho_{Y}),(K,\rho_{K})$ a complete metric space and a compact metric space, respectively. Let, as well, $Z=\mathcal{C}^{0}(K,Y)$ the metric space of continuous fuctions, such that $K\longrightarrow Y$, with the uniform metric and $\mathcal{H}\subset Z$. $\mathcal{H}$ is relatively compact in $Z$ iff for every $\{f_{k}\}$, such that $f_{k}\in\mathcal{H}$, there is a subsequence $\{f_{k_{j}}\}$ that converges in $Z$, that is $f_{k_{j}}\rightarrow\varphi\in Z$. The proof I'm trying reads: Suppose $\mathcal{H}$ is relatively compact in $Z$. Then $\overline{\mathcal{H}}$ is compact. Therefore, every sequence in $\overline{\mathcal{H}}$ has a subsequence that converges in $\overline{\mathcal{H}}$. That, particularly, means that every sequence in $\mathcal{H}$, that is a sequence in $\overline{\mathcal{H}}$, has a subsequence that converges in $\overline{\mathcal{H}}$. Then, for every $\{f_{k}\}$, such that $f_{k}\in\mathcal{H}$, there is a subsequence $\{f_{k_{j}}\}$ that converges in $Z$, that is $f_{k_{j}}\rightarrow\varphi\in\overline{\mathcal{H}} \subseteq Z$. Conversely, suppose that for every $\{f_{k}\}$, such that $f_{k}\in\mathcal{H}$, there is a subsequence $\{f_{k_{j}}\}$ that converges in $Z$, that is $f_{k_{j}}\rightarrow\varphi\in Z$. We want to show that $\mathcal{H}$ is relatively compact, or what is the same, show that $\overline{\mathcal{H}}$ is compact. Now $\overline{\mathcal{H}}\subset Z$, but $Z$ is complete and $\overline{\mathcal{H}}$ is closed (since closure is closed), therefore $\overline{\mathcal{H}}$ is complete. Then it only remains to show that $\overline{\mathcal{H}}$ is totally bounded, for if it is then $\overline{\mathcal{H}}$ is compact. My question is how to show this using the hypothesis that every sequence has a subsequence that converges in $Z$? Thanks to the answers of @BrianMScott and @BenjaminLim. In the next lines I complete the proof I was doing with their useful hints, comments are welcome Proof: Suppose $\mathcal{H}$ is relatively compact in $Z$. Then $\overline{\mathcal{H}}$ is compact. Therefore, every sequence in $\overline{\mathcal{H}}$ has a subsequence that converges in $\overline{\mathcal{H}}$. That, particularly, means that every sequence in $\mathcal{H}$, that is a sequence in $\overline{\mathcal{H}}$, has a subsequence that converges in $\overline{\mathcal{H}}$. Then, for every $\{f_{k}\}$, such that $f_{k}\in\mathcal{H}$, there is a subsequence $\{f_{k_{j}}\}$ that converges in $Z$, that is $f_{k_{j}}\rightarrow\varphi\in\overline{\mathcal{H}} \subseteq Z$. Conversely, suppose that for every $\{f_{k}\}$, such that $f_{k}\in\mathcal{H}$, there is a subsequence $\{f_{k_{j}}\}$ that converges in $Z$, that is $f_{k_{j}}\rightarrow\varphi\in Z$. We want to show that $\mathcal{H}$ is relatively compact, or what is the same, show that $\overline{\mathcal{H}}$ is compact. Now $\overline{\mathcal{H}}\subset Z$, but $Z$ is complete and $\overline{\mathcal{H}}$ is closed (since closure is closed), therefore $\overline{\mathcal{H}}$ is complete. Then it only remains to show that $\overline{\mathcal{H}}$ is totally bounded, for if it is then $\overline{\mathcal{H}}$ is compact. But, for that, we need only to prove that $\mathcal{H}$ is totally bounded, since closure of a totally bounded set is totally bounded. Suppose that $\mathcal{H}$ is not totally bounded, then exists $\epsilon>0$ such that there isn't a finite covering of balls, for $\mathcal{H}$, of the form $\{B_{g_{i},\epsilon}^{\rho_{\infty}}\}$ with $g_{i}\in\mathcal{H}$. Therefore, we can choose a $f_{1}\in\mathcal{H}$ and there will be a $f_{2}\in\mathcal{H}$ such that $f_{2}\notin B_{f_{1},\epsilon}^{\rho_{\infty}}$. In the same way there will be a $f_{3}\notin B_{f_{1},\epsilon}^{\rho_{\infty}}\cup B_{f_{2},\epsilon}^{\rho_{\infty}}$ and in general there will be $f_{k}\notin\bigcup_{i=1}^{k-1}B_{f_{i},\epsilon}^{\rho}$. Hence, we have defined, inductively, a sequence that there is $\epsilon>0$ such that $\rho(f_{k},f_{\ell})\geq\epsilon$ for every $k\neq\ell$, since if $\rho(f_{k},f_{\ell})<\epsilon$ for sufficiently large $k,\ell$ therefore $f(k)\in B_{f_{\ell},\epsilon}^{\rho_{\infty}}$ which contradicts the former construction. Therefore, every subsequence is not Cauchy and therefore none of them has the chance to converge. But by hypothesis, every sequence in $\mathcal{H}$ has a convergent subsequence, and supposing that $\mathcal{H}$ was not totally bounded has led us to contradiction. Therefore $\mathcal{H}$ is totally bounded in $Z$ and, hence, $\overline{\mathcal{H}}$. It proves that, since $\overline{\mathcal{H}}$ is complete and totally bounded, $\overline{\mathcal{H}}$ is compact. Finally, $\mathcal{H}$ is relatively compact.",['analysis']
147612,Discontinuity points of a Distribution function [duplicate],"This question already has an answer here : Closed 11 years ago . Possible Duplicate: Distribution Functions of Measures and Countable Sets The question at hand is: Let F be a distribution function on $\mathbb{R}$. Prove that F has at most countably many discontinuities. My attempt at a solution: $\textrm{F is non-decreasing by assumption}\\
F(\varphi ^-)=\lim_{t \uparrow \varphi}F(t),F(\varphi ^+)=\lim_{t \downarrow \varphi}F(t)\\
\textrm{The above limits exist and discontinuity points occur where}\\
F(\varphi^-)\neq F(\varphi)=F(\varphi^+)\\
\textrm{let (a,b] be a ﬁnite interval with n discontinuity points such that: }
\\
a<\varphi_1<...< \varphi_n < b \Rightarrow \sum_{\varphi =1}^{n}P(\varphi_k) \leq F(b)-F(a)\\
\textrm{therefore the number of discontinuity points is at most: } \frac{1}{\varepsilon }F(b)-F(a)$ As is (painfully) evident, I am just learning these concepts on my own and have little background in rigorous proof writing. I think all I have done is restrict the # of discontinuities of size $\frac{1}{\epsilon}$, and I'm not sure this does much for me. Any help would be greatly appreciated, as always.","['probability-theory', 'measure-theory']"
147632,"Isomorphisms: preserve structure, operation, or order?","Everyone always says that isomorphisms preserve structure... but given the (multiple) definitions of isomorphism, I fail to see how the definitions equate with the intuitive meaning, which is that two sets are ""basically the same if you ignore naming and notation"". Here are the different definitions I've come across: Order Isomorphism Let $A$ be a (totally) ordered set with ordering $\le$ and $B$ be a (totally) ordered set with ordering $\preceq$ . An isomorphism of $A$ onto $B$ is a bijection $f:A\mapsto B$ that satisfies $$a \le b \iff f(a) \preceq f(b)$$ for all $a,b \in A$ . Group Isomorphism Let $A$ be a group with operation $\ast$ and $B$ be a group with operation $\#$ . An isomorphism of $A$ onto $B$ is a bijection $f:A\mapsto B$ that satisfies $$a \ast b = c \iff f(a) \# f(b) = f(c)$$ rather, put simply, $$f(a\ast b) = f(a) \# f(b)$$ for all $a,b,c \in A$ . Field Isomorphism Let $A$ be a field with operations $\#$ and $\ast$ and $B$ be a field with operations $+$ and $\times$ . An isomorphism of $A$ onto $B$ is a bijection $f:A\mapsto B$ that satisfies $$f(a \# b) = f(a) + F(b)$$ and $$f(a \ast b) = f(a) \times F(b)$$ for all $a,b,c \in A$ . Homomorphism The same as an isomorphism but not necessarily a bijection. An example of why this is confusing:
It is technically not the case that $\mathbb{N}\subseteq\mathbb{Z}$ . For example, in the Natural Numbers, $0$ is the empty set $\varnothing$ , which has no elements, however in the integers, $0$ is the equivalence class $[(0,0)]$ of ordered pairs whose components are natural numbers that are equal, and it has infinitely many elements. These sets are not by any means equal , but for all intents and purposes, we consider $\mathbb{N}$ to be a subset of $\mathbb{Z}$ , because the set of non-negative integers is ""basically the same as"" the set of natural numbers. That is, the natural numbers have ""isomorphic copies"" in the integers. The question is, which type of isomorphism? Which of these definitions of isomorphism is ""correct"", and how does it equate to the intuitive meaning that the two sets are ""basically the same""? Furthermore, what's the point of homomorphism, why is it useful, and how is its intuitive meaning similar or different from the intuitive meaning of isomorphism?","['order-theory', 'group-theory', 'abstract-algebra', 'field-theory']"
147642,"If a group satisfies $x^3=1$ for all $x$, is it necessarily abelian?","I know that any group satisfying $x^2=1$ for all $x$ is abelian. Is the same true if $x^3=1$? I don't think it is, but I can't find a basic counterexample.",['group-theory']
147648,How come the Euclidian distance for n-space involves only squares?,"I'm just beginning to learn topology, and there's something that I realize has been nagging at me since roughly the eight grade. Why does the Euclidean distance in N-dimensional space involve a bunch of squaring and square-rooting? I understand it, mind you. In 1-space the ""distance"" is $\sqrt{\Delta x^2}$ is which is just $\Delta x$. In two-space, you're doing the Pythagorean theorem. In 3-space, I visualize it like this: you want to find the distance $\Delta x, \Delta y, \Delta z$ so you: let $a = \sqrt{\Delta x^2 + \Delta y^2}$, $a$ is the distance along the $x, y$ plane the total distance is $\sqrt{a^2 + \Delta z^2}$ the above expands to $\sqrt{\Delta x^2 + \Delta y^2 + \Delta z^2}$ To generalize, faced with $n$ dimensions, you pick two, find the distance along those two dimensions, plop a point down there, and repeat (until you have only one dimension left, at which point you're done.) However, I don't understand why distance in n-space requires repeated squaring. Shouldn't there be a distance formula that requires cubing and the cube-root in three-space, or quading (is that a thing) and quad-roots in four-space, and so on? Just in the interest of symmetry, it seems weird that squares get special treatment. I know this is a very philosophical question, but is there a way to find Euclidean distances in n-space that involves taking the nth power and nth root instead of repeatedly projecting down a dimension?","['general-topology', 'geometry']"
