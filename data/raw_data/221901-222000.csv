question_id,title,body,tags
4547920,Convergence in distribution of $S_n/\sqrt{n} - S_{2n}/\sqrt{2n}$,"Suppose $X_1,X_2,...$ are i.i.d with $\mathcal{N}(0,1)$ . Denote $S_n=X_1+...+X_n$ . I am trying to determine if the sequence of random variables defined as: $$\frac{S_n}{\sqrt{n}} -\frac{S_{2n}}{\sqrt{2n}}$$ converges in distribution and if so, what is the limiting distribution. Here is my thinking so far of which I tend to be doubtful. Rewriting the above I get: $$\frac{X_1+...+X_n}{\sqrt{n}}-\frac{X_1+...+X_n}{\sqrt{2n}}-\frac{X_{n+1}+...+X_{2n}}{\sqrt{2n}}=$$ $$\frac{(1-\frac{1}{\sqrt{2}})(X_1+...+X_n)}{\sqrt{n}} -\frac{(\frac{1}{\sqrt{2}})(X_{n+1}+...+X_{2n})}{\sqrt{n}}$$ If I start taking large $n$ , then by the central limit theorem the distributions of both rv's $\frac{X_1+...+X_n}{\sqrt{n}}$ and $\frac{X_{n+1}+...+X_{2n}}{\sqrt{n}}$ will be closer and closer to $\mathcal{N}(0,1)$ . Furthermore, for any fixed $n$ they are independent rv's. So for large $n$ , I am effectively dealing with a linear combination of two independent $\mathcal{N}(0,1)$ rv's. Hence, I get $$\frac{(1-\frac{1}{\sqrt{2}})(X_1+...+X_n)}{\sqrt{n}} -\frac{(\frac{1}{\sqrt{2}})(X_{n+1}+...+X_{2n})}{\sqrt{n}}\sim\mathcal{N}(0,(1-\frac{1}{\sqrt{2}})^2+(\frac{1}{\sqrt{2}})^2)$$ and consequently: $$\frac{S_n}{\sqrt{n}} -\frac{S_{2n}}{\sqrt{2n}}\xrightarrow{d} \mathcal{N}(0,(1-\frac{1}{\sqrt{2}})^2+(\frac{1}{\sqrt{2}})^2) $$ I am aware that this is not a rigorous proof, but is my intuition correct or is it misleading me completely? Will highly appreciate any help with this problem.","['central-limit-theorem', 'normal-distribution', 'convergence-divergence', 'probability', 'random-variables']"
4548000,How to show that sampling from correlated fraction PDFs does not reproduce correlations?,"Let's assume that we have $N$ layers over which a quantity X is distributed, i.e. $X = \sum_{i=1}^{N} X_i$ for each 'data point'. Now, we know how the Probability Density Function $f(X)$ of the overall quantity as well as the Probability Denity Function of the fraction in each layer $g(X_i^{\mathrm{frac}})$ with $X_i^{\mathrm{frac}}=\frac{X_i}{X}$ look. We also know that the correlations of $X_i$ are not zero, i.e. $\rho(X_i, X_j) \neq 0$ . How can I concisely show that if I would just sample data from the fraction PDFs $g(X_i^{\mathrm{frac}})$ and the total PDF $f(X)$ with the constrain of the fractions always summing up to $X$ , it would not be possible to reproduce the original correlations. Hope this was clear!","['correlation', 'statistics', 'probability-distributions', 'probability']"
4548012,determining the start velocity and angle based on the goals(End point) angle and coordinates.,"======== I'm trying to figure out the start angle and velocity of an parabola, When i know only the start coordinates and the end point coordinates and the angle which it reaches the endpoint. I'm tasked with figuring this out by using derivative method. So the known parameters are: Start point (0,0) end point (6,4) end point angle (-18) unknown are: velocity = unknown. start angle =unkown. This is a homework assiment thats been bothering me for months now. Here is a picture of what i've been working with:","['conic-sections', 'derivatives']"
4548021,Frechet derivative of Integral operator,"In the following let $g(x,r,u)$ be a continuous function $g:[a,b]\times \mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}$ . Furthermore we assume that the partial derivative $\frac{\partial g}{\partial u}$ exists and is also continuous. Now I want to calculate the Frechet derivative $DG$ of the operator $G: \mathcal{C}[a,b] \rightarrow \mathcal{C}[a,b]$ defined by: $$G(u)(x) = u(x) - \int_{a}^{b} g(x,s,u(s)) ds$$ As a guess for $DG$ I use the Gateaux derivative of $G(u)(x)$ . Which I calculate according to the definition as follows: $$\frac{1}{t}\left(G(u+th)-G(u)\right) = h(x) - \frac{1}{t}\int_{a}^{b}g\left(x,s,u(s)+th(s)\right)-g\left(x,s,u(s)\right)$$ Now we can do a Taylor expansion of the integrand in the third argument: $$g(x,s, z(t)) = g(x,s,z(0)) + \frac{\partial g(x,s,u(s))}{\partial z}\dot{z}(0) \left(z(t)-z(0)\right) + \mathcal{O}(t^{2})$$ Where $z(t) = u(s) + th(s)$ . Using this expansion in the above integral we end up with the following expression for the Gateaux derivative: $$\lim\limits_{t\to 0}\frac{1}{t}\left(G(u+th)-G(u)\right) = h(x) -\int_{a}^{b}\frac{\partial g}{\partial u}h(s)^{2} ds$$ Now we have to show that: $$\lim\limits_{\lVert h \rVert \rightarrow 0}\frac{\lVert G(u+h) - G(u) - DG(u) \rVert}{\lVert h \rVert} = 0$$ Using the Gateaux derivative from above for $DG$ and working out the numerator I get: $$\lVert G(u+h) - G(u) - DG(u) \rVert = \lVert \int_{a}^{b}\frac{\partial g}{\partial u} h(s)^{2} ds ~ - ~ \int_{a}^{b} \left(g\left(x,s,u(s)+h(s)\right) - g(x,s,u(s))\right) ds  \rVert$$ For the first term I can  use: $\lVert \int_{a}^{b}\frac{\partial g}{\partial u} h(s)^{2} ds \rVert \leq \lVert h\rVert^{2} \int_{a}^{b}\frac{\partial g}{\partial u} ds$ And the fact the the partial derivative is continuous, hence bounded on $[a,b]$ am I right? But I can't see how to proceed with the second term. Above $\lVert . \rVert$ is the sup-norm. Is this the right way to calculate $DG$ or am I completely wrong with my approach?","['frechet-derivative', 'banach-spaces', 'functional-analysis', 'calculus-of-variations']"
4548033,Reference request: Bundles in Algebraic Geometry,"I heard many times that quasi-coherent sheaves of $\mathcal O_X$ -modules are morally the same thing as the sheaves of sections of a bundle $V\to X$ over $X$ . We think of a ring $A$ as of the ring of functions of the imagined space $\newcommand{\Spec}{\operatorname{Spec}}\Spec A$ , and of an $A$ -module $M$ as of a sheaf sections of some vector bundle with locally varying dimensions over $\Spec A$ . I like to find references which make this concrete and discuss some of those bundles $V\to X$ in detail, preferably in the functor of points approach to algebraic geometry. Here are examples of the kind of results I am interested in: In this answer Martin Brandenburg defines a pre-vector bundle on a scheme $X$ to be a morphism of schemes $V\to X$ together with a $\mathcal O(T)$ -module structure on $\text{Hom}_X(T,V)$ for each scheme $T\to X$ over $X$ which varies naturally with restriction maps. A morphism of pre-vector bundles is a map over $X$ which respects the extra structure. Every pre-vetor bundle gives me a sheaf of $\mathcal O_X$ -modules through taking sections. Which sheaves of $\mathcal O_X$ -modules arise this way? Is there a construction in the other direction? Is there an adjunction? Where can I read more? It is shown in many algebraic geometry books that locally free rank $r$ sheaves of $\mathcal O_X$ -modules are in equivalence with ank $r$ vector bundles on the scheme $X$ . Here is an example. It is also an exercise in Harthshorne. One can associate two $X$ -schemes $\underline{\Spec}_X(\operatorname{Sym}\mathcal E)\to X$ and $\underline{\Spec}_X(\operatorname{Sym}\mathcal E^\vee)\to X$ to a quasi-coherent sheave $\mathcal E$ of modules on $X$ . The sheaf of sections of the first one is naturally isomorphic to the dual $\mathcal E^\vee$ , and consequently the sheaf of sections of the second one is naturally isomorphic to $(\mathcal E^\vee)^\vee$ . Is there a way to construct a bundle $V(\mathcal E)\to X$ such that its sheaf of sections is $\mathcal E$ for any quasi-coherent sheaf $\mathcal E$ ? The two constructions are discussed in this question , but I like to learn more. Here is an example of something I like: Let $D = \Spec \mathbb Z[\varepsilon]/(\varepsilon^2)$ be the space of dual numbers. Then $\mathbb Z[\varepsilon]/(\varepsilon^2)\to \mathbb Z$ (sending $\varepsilon$ to zero) yields a map $D\to \mathbf 1$ and thus a map $X^D\to X$ . This is the tangent bundle in synthetic differential geometry, and it turns out that it is also the tangent bundle in algebraic geometry. See here and here . Which other important quasi-coherent sheaves in algebraic geometry come from a bundle $V\to X$ ? When we increase the space we have from the category of schemes to the category of sheaves on the big Zariski site, can we make interesting bundle constructions $V\to X$ which may not exist in $\operatorname{Sch}$ ? There is a nice chapter in the Algebraic Geometry book by Görtz and Wedhorn which shows that the category of quasi-coherent sheaves on a scheme is contravariantly equivalent to a category of quasi-coherent bundles on $X$ . But their category of quasi-coherent bundles is made just so that it works out. The definition is not geometrically motivated in the book. Also the pseudo-invers is not the sheaf of sections construction, which is dissatisfying. (Chapter 11 in Görtz & Wedhorn's Algebraic Geometry I: Schemes ) I am aware that a quasi-coherent sheaf on a scheme $X$ is equivalent to a collection of modules, one for each generalised point $r:\Spec R \to X$ which vary pseudo-functorially. This is in line with the intuition that a quasi-coherent sheaf is a vector space attached to each (field-valued) point of $X$ . But I am specifically interested in a global approach $V\to X$ from which I can extract the fibres by pullbacks. I am familiar with the internal language of the big Zariski topos (as discussed in the second chapter of Ingo Blechschmidt's PhD thesis . If there is a characterisation of those $X$ schemes $V\to X$ which are in some sense locally non-trivial bundles of vector spaces in the internal language, then I am more than happy to learn it! Moerdijk and Reyes define vector bundles on page 195 of their book Models of smooth infinitesimal Analysis . The definition works in any smooth topos , of which the gros Zariski topos Sh(Aff,Zar) is, according to the nLab, probably an example. What does their definition mean in the context of algebraic geometry? Can we characterize the sheaves of section which come from vector bundles in the sense of Moerdijk and Reyes? Most algebraic textbooks which I find just introduce the theory of sheaves of $\mathcal O_X$ -modules without a lot of geometric explanation. Where can I find books/texts/papers which discuss bundles $V\to X$ of schemes and their connections to quasi-coherent sheaves in detail? Edit. I want to provide evidence for my extraordinary claim that $QCoh(X)$ embeds in two ways fully faithfully into a category of $\mathbb A_X$ modules. The first construcion is one that I did not mention in the previous version of my question, because I did not know about it. It works as follows. You pick a scheme $X$ and view as an object in one of the big topoi via the functor of points approach. For simplicitly, let me take the big Zariski topos $Zar$ . There is a local geometric morphism $\pi: Zar/X \to Sh(X)$ from the big topos of $X$ to the little. Its pushforward part $\pi_\ast$ takes a space over $X$ to its sheaf of section. It has a left adjoint $\pi^{-1}$ and one defines a fully faithful covariant functor $\pi^\ast:Mod(\mathcal O_X)\to Mod_{Zar/X}(\mathbb A_X)$ by setting $\pi^\ast\mathcal F = \pi^{-1}\mathcal F\otimes_{\pi^{-1}\mathcal O_X}\mathbb A_X$ . A detailed construction and a proof that this functor is fully faithful can be found at the beginning of part 2 of Ingo Blechschmidt's PhD thesis. In fact, $\pi_\ast \pi^\ast = id$ . The second construction is already mentioned above. It is contravariant and works only for quasicoherent modules, but it always produces an $\mathbb A_X$ -module which is a scheme. Given an quasicoherent $\mathcal O_X$ -module $\mathcal F$ , we let $V(\mathcal F)$ be the $X$ -scheme $Spec_X(Sym(\mathcal F))\to X$ , where we now use the relative spec construction. The $\mathcal O_X$ -algebra $Sym(\mathcal F)$ is $\mathbb N$ -graded, and hence we get an $(\mathbb A_X,\cdot)$ -monoid action on $V(\mathcal F)$ . This is the first part of what we need to turn $V(\mathcal F)$ into an $\mathbb A_X$ -module. What is left is to define the addition map. For that we switch to a local chart affine chart $U$ of $X$ . We need a morphism $$ +: Spec(\,Sym(\mathcal F(U)))\times_U Spec(Sym(\mathcal F(U)))\to Spec(Sym(\mathcal F(U))) 
$$ relative $U$ . This is the same thing as an $\mathcal O(U)$ algebra map $$Sym(\mathcal F(U))\to Sym(\mathcal F(U)) \otimes_{\mathcal O(U)} Sym(\mathcal F(U))$$ which in turn is the same thing as an $\mathcal O(U)$ -module map $$\mathcal F(U) \to Sym(\mathcal F(U))\otimes_{\mathcal O(U)} Sym(\mathcal F(U))$$ We take the map which sends $f$ to $f\otimes 1 + 1\otimes f$ and we are done. We have a functor $V:QCoh(\mathcal O_X)^{op} \to Mod_{Sch/X}(\mathbb A_X)$ . There is a construction $L$ in the opposite direction which takes an $\mathbb A_X$ -module to its sheaf of linear functions. We have that $LV = id$ , and this shows that $V$ is fully faithful.","['quasicoherent-sheaves', 'reference-request', 'vector-bundles', 'algebraic-geometry', 'schemes']"
4548053,"In how many ways can six letters be removed from ""SIXSIXSIX"" to make the string ""SIX""?",My answer: 10 My reasoning: I used a decision tree to list all of the possible ways and counted them. SIX______ SI___X___ SI______X S___IX___ S___I___X S______IX ___SIX___ ___SI___X ___S___IX ______SIX Is there a more mathematical way of getting this result?,['combinatorics']
4548058,Swapping numbers to maintain difference,"Non-negative real numbers $x_1,\dots,x_n$ are written on the left side of the board, and $y_1,\dots,y_n$ on the right side. Each number is at most $1$ . It is known that $|\sum_i x_i - \sum_i y_i| \le 1$ . Is it certain that we can swap $n$ pairs of numbers, one after another, so that the difference between the sums of the two sides remains at most $1$ throughout, and at the end all numbers from the left side end up on the right and vice versa? A possible approach is to use induction, by showing that we can make the first swap and maintaining the difference of $\le 1$ . If $\sum_i x_i \ge \sum_i y_i$ , there is some pair $(x_j,y_k)$ such that $x_j \ge y_k$ , but swapping these two does not guarantee that the difference will remain $\le 1$ .",['combinatorics']
4548086,"find all $n\ge 2$ so that $(x_1+x_2+\cdots + x_n)^2 \ge n(x_1x_2+x_2x_3+\cdots + x_nx_1)\,\forall x_1,\cdots, x_n\in \mathbb{R}_{\ge 0}$.","Determine all the values of the positive integer $n\ge 2$ so that $(x_1+x_2+\cdots + x_n)^2 \ge n(x_1x_2+x_2x_3+\cdots + x_nx_1)$ for all nonnegative real numbers $x_1,\cdots, x_n$ . Denote the LHS by $F(x_1,\cdots, x_n)$ and the RHS by $G(x_1,\cdots, x_n)$ . Obviously $n=2$ works since $(x_1+x_2)^2 \ge 4x_1x_2 = G(x_1,x_2)$ . Note that the expression $(x_1+\cdots + x_n)^2 - n(x_1x_2+\cdots + x_nx_1)$ is convex in each $x_i$ . For convenience, let $x_{i+n} = x_i$ for any integer i, so on any bounded closed interval it would achieve its maximum or minimum at a boundary point. As a specific example, take $n = 3.$ Then we need to satisfy $(x_1+x_2+x_3)^2 \ge 3(x_1x_2+x_2x_3+x_3x_1)$ for all nonnegative real numbers $x_1,\cdots, x_n$ . This holds by adding $2(x_1x_2+x_1x_3+x_2x_3)$ to both sides of $x_1^2 + x_2^2+x_3^2 \ge x_1x_2+x_1x_3+x_2x_3$ . For $n=4,$ we must satisfy that for all real numbers $x_1,\cdots, x_n, (x_1+x_2+x_3+x_4)^2 \ge 4(x_1x_2+\cdots + x_4x_1)$ . I think one can induct on $m$ to show that for all nonnegative real numbers $x_1,\cdots, x_m, (x_1+\cdots + x_m)^2 \ge 4(x_1x_2+\cdots + x_{m-1}x_m +x_mx_1).$ It holds for $m=1$ and $m=2$ so suppose it holds for all $m < k,$ some $k\ge 3$ . Then by cyclically shifting we may assume WLOG that $x_k\le x_1,\cdots, x_{k-1}$ . If we have $(x_1+\cdots + x_k)^2 = (x_1+\cdots + x_{k-1})^2 + 2x_k (x_1+\cdots + x_{k-1})+x_k^2 \ge 4(x_1x_2+\cdots + x_{k-1}x_1) + 4x_1(x_k-x_{k-1})+4x_{k-1}x_k,$ we're done but I'm not sure how to prove this.
I'm not sure about the general case for $n\ge 5$ though, though I think that as n gets larger the inequality will be less likely to hold. It might be useful to convert the inequality to a sum of squares somehow.","['contest-math', 'inequality', 'induction', 'linear-algebra', 'algebra-precalculus']"
4548169,Two non isometric Hilbert space which are isomorphic as two Banach spaces,"I wonder  if  there is an obvious  example of two  non isometric  Hilbert  spaces $H, K$ which  are isomorphic  Banach spaces?","['hilbert-spaces', 'banach-spaces', 'functional-analysis']"
4548195,Greatest and smallest value of a function in $\mathbb{R}^2$,"Does the function $$ f(x,y) = 2x+2y $$ have a greatest or smallest value in $\mathbb{R}^2$ ? I thought that since $$ \lim_{x \to \infty} f(x,0) = \infty $$ $$\lim_{x \to -\infty} f(x,0) = -\infty $$ then the function can be infinite great and small, am I thinking right?","['limits', 'multivariable-calculus', 'maxima-minima', 'optimization']"
4548205,Is the product $\sigma$-algebra the tensor product over $\mathbb{Z}$?,"This question is inspired by Folland’s notation for the product of $\sigma$ -algebras using the $\otimes$ symbol. More precisely, given a family $(\mathcal{M}_\alpha)_{\alpha\in I}$ of $\sigma$ -algebras on some sets $(X_\alpha)_{\alpha\in I}$ , the product $\sigma$ -algebra $\bigotimes_{\alpha\in I} \mathcal{M}_\alpha$ on $\prod_{\alpha\in I} X_\alpha$ is the smallest $\sigma$ -algebra generated by the measurable cylinders: $\{\pi_\alpha^{-1}(E_\alpha) : E_\alpha \in \mathcal{M}_\alpha\}$ , where $\pi_\alpha : \prod_{\beta\in I} X_\beta \to X_\alpha$ is the canonical projection. One can show that each $\mathcal{M}_\alpha$ is a commutative Boolean ring with identity, under symmetric difference (addition) and intersection (multiplication). Therefore each $\mathcal{M}_\alpha$ is a $\mathbb{Z}$ -algebra in the abstract-algebraic sense. This means we can take the $\mathbb{Z}$ -algebra tensor product of the $\mathcal{M}_\alpha$ . My question is thus: is the product $\sigma$ -algebra isomorphic (as a $\mathbb{Z}$ -algebra, or at least as a module) to this tensor product? To show this, one would have to generate a $\mathbb{Z}$ -linear map $g : \prod_{\alpha\in I} \mathcal{M}_\alpha \to \bigotimes_{\alpha\in I} \mathcal{M}_\alpha$ so that for any $\mathbb{Z}$ -module N and any $\mathbb{Z}$ -linear  map $f : \prod_{\alpha\in I} \mathcal{M}_\alpha \to N$ , there exists a unique module homomorphism $f’ : \bigotimes_{\alpha\in I} \mathcal{M}_\alpha \to N$ such that $f = f’ \circ g$ . I think $g$ ought to be the map $g((E_\alpha)_{\alpha\in I}) = \prod_{\alpha\in I} E_\alpha$ , at least when $I$ is countable. But I am not very good at tensor products, so I’m not sure how to define the homomorphism $f’$ . Does this approach work? If so, how do we define $f’$ ?","['measure-theory', 'tensor-products', 'commutative-algebra']"
4548208,Tips to solve limits of 2 variables,"Anyone got a tips on solving this type of limits $$ \lim_{(x^2 + y^2) \to \infty} \frac{e^{x^2+xy+y^2}-1}{e^{x^2+y^2}-1}$$ I'm always having a trouble finding a good method to solve for limits of 2 variables approaching infinity, usually I'd either use Taylor (mostly if limit approaches 0) or Polar coordinates, but I tried both here without any results, what is the way to think here?","['multivariable-calculus', 'calculus', 'polar-coordinates', 'taylor-expansion', 'limits']"
4548212,What set of angles uniquely defines a convex quadrilateral?,"I am trying to characterize the set of angles in a (convex) quadrilateral that distinguishes it from any other quadrilateral that is not similar to it. Such a set will be said to uniquely define a quadrilateral up to similarity. For the rest of the question, this will be the definition of ""uniquely defines"". Also, ""quadrilateral"" will mean a convex one. Absolutely no assumptions may be made on any of the angles, they are completely generic, as in the image below. Of course general truths may be deduced, for example that $y=180-a-b$ . I have marked all $12$ (or $16$ with the vertices angles $A,B,C,D)$ angles for ease of reference. For example, the set $\{ A,B,C,D\}$ does not uniquely define a quadrilateral. This MSE link Shows an example where this set is identical, but $2$ non-similar quadrilaterals can be formed from the exact same set. Considering instead the $4$ -tuple $(A,B,C,D)$ (where the order of angles matters), rather than the set, does define uniqueness in the above link's example, but still does not uniquely define a quadrilateral. Take any square with the tuple $(90,90,90,90)=\{90\}$ . Then any rectangle with exactly $2$ different sides will have the exact same tuple/set, however it will not be similiar to that square. So the set/tuple $(A,B,C,D)/\{A,B,C,D\}$ do not uniquely define the quadrilaterals (up to similarity). Just to further explain the meaning of this in terms of the sketch below, this means of course that the set $\{e+d,c+b,a+h,g+f\}$ does not define a quadrilateral. Obviously, the set $\{w,x,y,z\}=\{x,y\}=\{x,180-x\}$ neither defines a quadrilateral. It is important to note once again, that I am looking for uniqueness up to similarity The quadrilateral to start with has no special traits, it is completely generic. Separation to cases may be considered. I am only considering euclidean geometry here in the plane It may be assumed that all angles in the figure below are known It is best if angles only from the $16$ marked below will be included. What combination of these angles will define a quadrilateral? I am really insisting on a set (or multiple sets) here. What I mean by that, is that given this set of angles of the quadrilateral, then another quadrilateral may not be similar to it unless it possesses the exact same set. That way, the order of the elements does not matter, because any set that differs by even one angle (or by the size of the set), cannot be similar to it anyway. If no such set exists, I'd like to know why, and rather than that I'd like to know what $n$ -tuple of angles uniquely defines a quadrilateral. If non exists, then what algorithm/set of examinations will distinguish any $2$ quadrilaterals?","['geometry', 'combinatorics', 'algorithms', 'optimization', 'trigonometry']"
4548248,Sum of i.i.d. variables can be bounded a.s.,"If $\{X_n\}_{n=1}^\infty$ are i.i.d. random variables where $E[X_n] = 0$ for all $n \geq 1$ . Then there is $K > 0$ such that $P(|X_1 + \cdots + X_n| \leq K \text{ i.o.}) = 1$ . I thought we could use contradiction. Say for all $K > 0$ we get that $$P(|X_1 + \cdots + X_n| \leq K \text{ i.o.}) < 1,$$ then $$0 < P(|X_1 + \cdots + X_n| > K \text{ for large n}) \leq \liminf_{n \to \infty} P(|X_1 + \cdots + X_n| > K) \\
\leq \frac{1}{K} \liminf_{n \to \infty} E(|X_1 + \cdots + X_n|).$$ If I could bound the limit we are done since $K \to 0$ finishes the contradiction. But I do not think we can calculate this easily. Edit: Do I need another condition on my $X_n$ ?","['random-variables', 'probability-theory', 'probability', 'real-analysis']"
4548276,Why do the composition of relations and the matrix product look so alike?,"For reference: Matrix product: $A : X\times Y \rightarrow R$ $B : Y\times Z \rightarrow R$ $AB := (x,z) \mapsto \int_{y\in Y} A(x,y)B(y,z) d\mu : X\times Z \rightarrow R$ To make the pattern clearer I generalized matrices $A$ and $B$ over any (semi-)ring $R$ to have indices ranging over arbitrary sets instead of just finite ones. In this case we need to give $Y$ a measure. What you get is the $L^2$ inner product. Relation composition: $S \subseteq X\times Y$ $T \subseteq Y\times Z$ $S \circ T := \{(x,z)\ |\ \exists y \in Y.\ (x,y) \in S\ \land\ (y,z) \in T\} \subseteq X\times Z$ Thinking in terms of monoids might be an easy way out, but we are losing a lot of structure doing that and I believe that if there's anything deep going on here, it lies in the $\ \exists \leftrightarrow \int\ $ , $\ \land \leftrightarrow \cdot\ $ connection. What is the thing that generalizes both of these? What is going on here? Thanks in advance!","['matrices', 'abstract-algebra', 'category-theory']"
4548287,Show that every complex number $c$ with $|c|\leq n$ can be written as $c=a_1+a_2+\cdots + a_n$ where $|a_j|=1$ for every $j$.,"Let $n\ge 2$ be a positive integer. Show that every complex number $c$ with $|c|\leq n$ can be written as $c=a_1+a_2+\cdots + a_n$ where $|a_j|=1$ for every $j$ . I think one can come up with a continuous complex-valued function that is the sum of n terms all of which have absolute value 1 so that it contains all the complex numbers from 0 to n in its range. Consider $f(t) = \sum_{j=0}^{n-1} \mathrm{sign}((-1)^j t)e^{ijt}$ , where $sign(0):=1$ and $sign(x) = \dfrac{x}{|x|}$ for any other x. $f(0) = n,$ but even though f is continuous it might not have all the numbers from 0 to n in its range. Maybe if I could write a sum of trig functions as a sum of complex exponentials it might be useful? For instance, the Dirichlet kernel satisfies this property. Every $|c|\leq n$ can be written as $x+iy$ for some $x^2 + y^2 \leq n$ and in particular if $r = |c|$ then $c = re^{i\theta}$ for some $\theta \in [0,2\pi)$ .","['summation', 'complex-analysis', 'continuity', 'calculus', 'inequality']"
4548345,Undecidability of simple-connectedness of a special class of simplicial complexes.,"It's a well known fact that determining simple-connectedness of a CW-complex is in general undecidable, but I'm interested whether that's also true in the following class of topological spaces. Let $\Delta_n$ be a simplex with vertices $\{1, 2, \dots, n\}$ , where we view $\Delta_n$ as a $(n - 1)$ -dimensional simplicial complex. Now let $Y \subseteq \Delta_n$ be a $2$ -dimensional simplicial subcomplex of $\Delta_n$ , such that $Y$ contains all $0$ -faces and all $1$ -faces of $\Delta_n$ (that is, $Y$ contains the $1$ -skeleton of $\Delta_n$ ). Does there exists an algorithm that would in general determine whether $Y$ is simple-connected?
If not, what would be the counterexample? My first thought was to check whether every $3$ -cycle of a complete graph $K_n$ is contractible in $Y$ , but I don't know how you would do that (at least semi-efficiently).","['general-topology', 'algebraic-topology']"
4548362,How to bound $\sum_{n=1}^\infty \frac{n^{4k-1}}{e^{2\pi n}-1}$ where $k\in\mathbb{N}$,"By using this answer ( On proving that $\sum\limits_{n=1}^\infty \frac{n^{13}}{e^{2\pi n}-1}=\frac 1{24}$ ), I found that $$2\frac{1-2^{-4k-2}}{1-2^{-4k-1}}\frac{(4k+2)!}{(2\pi)^{4k+2}(8k+4)}\lt \sum_{n=1}^\infty \frac{n^{4k+1}}{e^{2\pi n}-1}\lt \frac{2}{1-2^{-4k-1}}\frac{(4k+2)!}{(2\pi)^{4k+2}(8k+4)}$$ where $k\in\mathbb{N}$ . Are there some known bounds (useful for approximations) for the similar series $$\sum_{n=1}^\infty \frac{n^{4k-1}}{e^{2\pi n}-1}$$ where $k\in\mathbb{N}$ ?","['inequality', 'sequences-and-series', 'real-analysis']"
4548387,Polar coordinates question (integration),"Coming to the end of a question on Polar Coordinates and I have come across this integral which I cannot seem to evaluate. Upon expanding the entire expression, I'm not sure how to use the formula $cos^2(\theta) = \frac{1 +cos(2 \theta)}{2}$ in order to integrate the powers without everything becoming absurdly messy. Happy to accept hints. Book is Calculus of Several Variables by Serge Lang",['multivariable-calculus']
4548402,"find positive integers $a,b,c,d,e$ so that $a,b^2,c^3,d^4,e^5$ form a nonconstant arithmetic progression","Find any positive integers $a,b,c,d,e$ so that $a,b^2,c^3,d^4,e^5$ form a nonconstant arithmetic progression. Suppose integers $a,b,c,d,e$ are such that $a,b^2,c^3,d^4,e^5$ forms a nonconstant arithmetic progression with common difference $h \neq 0.$ Then $2b^2 = c^3 + a, 2d^4 = c^3 + e^5, 2c^3 = d^4+b^2, 2c^3 = a+e^5\tag{1}.$ Obviously the nonconstant condition is crucial because otherwise we could just take $a=b=c=d=e=1.$ Observe that all elements in $\{a,c,e\}$ and $\{b,d\}$ have the same parity.  Note that none of $b,c,d$ can equal 1, for otherwise the sequence, being nonconstant, would decrease from the previous term to the term equal to 1 and then the next term will be nonpositive. First try $a=1$ . We need $2b^2=c^3 +1 = (c+1)(c^2 - c+1)$ . If $c$ is even, then $c^3+1$ is odd, a contradiction. So $c=2c_1+1$ for some positive integer $c_1$ . Then $2b^2 = (2c_1+2)((2c_1+1)^2 - (2c_1+1) + 1) = 2(c_1+1)(4c_1^2+2c_1+1) \Rightarrow $ So perhaps . Now suppose $e = 1$ . Then the sequence is necessarily decreasing and we have from (1) that $c^3 = \dfrac{a+1}2, 2d^4 = c^3 + 1= \dfrac{a+3}2\Rightarrow d^4 = \dfrac{a+3}4, 2b^2 = \dfrac{a+1}2 +a\Rightarrow b^2 = \dfrac{3a+1}4$ . And we also have from (1) that $a+1 = \dfrac{a+3}4 + \dfrac{3a+1}4.$ Trying $c=3$ gives $a=53, b^2 = 40 = 5\cdot 2^3, c=5\Rightarrow a=249 = 3\cdot 83, b^2=187, c=7\Rightarrow a=514=2\cdot 257, c=9\Rightarrow a = 1457, b^2=1093$ . There doesn't seem to be any good pattern with the $b^2$ 's produced that gives away a modular arithmetic argument. I think a lot of small possibilities won't work; for instance $e = 3$ implies $d\ge 4,$ but $d=4,5,6$ all fail to work.","['contest-math', 'elementary-number-theory', 'recreational-mathematics', 'discrete-mathematics']"
4548418,Finding point in a plane at fixed distances from 2 other points in the plane,"This is a version of an inverse kinematics question where a robotic arm has fixed length upper and lower arms and you are provided with the shoulder and wrist locations but need to calculate the elbow position that is closest to the ground.
So, there are three 3D points defining a plane, P1(x1,y1,z1) P2(x2,y2,z3) and P3(x3,y3,z3) (where P1 is the shoulder, P2 is the wrist and P3 is the ""ground"" in my example). I need to find another point A on that plane which is L1 length from P1 and L2 length from P2 and closest to P3 (out of the 2 possible positions that exist). I have found a solution for this in 2D ( https://www.hindawi.com/journals/jr/2010/984823 ) but I am having difficulty extending it to 3D. function calculatePointFromLengths(p1,p2,l1,l2) {
  let L = sqrt((p2.x-p1.x)*(p2.x-p1.x)+(p2.y-p1.y)*(p2.y-p1.y));
  let angleP1P2 = Math.atan((p2.y-p1.y)/(p2.x-p1.x));
  let theta1 = Math.acos(l1*l1+l2*l2-l2*l2)/(2*l1*L) + angleP1P2;

// now calculate the point using the angle

return( {
    x: p1.x + l1 * Math.cos(theta1);
    y: p1.y + l1 * Math.sin(theta1);
});","['kinematics', 'geometry', '3d']"
4548424,Determine a volume on the first octant using triple integrals,"Consider the surface delimited by $z=9-y^2$ , $y=2x$ and $x=6$ on the first octant.
How to find its volume using triple integrals? Seems like $x$ goes from $0$ to $6$ , $y$ goes from $0$ to $2x$ , and then $z$ goes from $0$ to $9-y^2$ .  In such case the integral would be $$\int_0^6 \int_0^{2x} \int_0^{9-y^2} dz\ dy\ dx$$ Which can be easily calculated. Are those limits correct? attaching a picture",['multivariable-calculus']
4548503,Understanding differential forms on manifolds (Bachman example 52),"In David Bachman's ""A Geometric Approach to Differential Forms"", in example 52, he lists what integrating a particular 1-form is like on $S^1$ . My question is, how does he calculate the ranges for the integrals that he does? Example 52 Let $S^1$ , $U_i$ , $\phi_i$ , and $w$ be defined as in Examples 49 and 50. A partition of unity subordinate to the cover ${\phi_i(U_i)}$ is as follows. \begin{align*}
f_1(x,y) = y^2 \text{ if } y \geq 0 & \text{ else } 0
\\
f_2(x,y) = y^2 \text{ if } y < 0 & \text{ else } 0
\\
f_3(x,y) = x^2 \text{ if } x \geq 0 & \text{ else } 0
\\
f_4(x,y) = x^2 \text{ if } x < 0 & \text{ else } 0.
\end{align*} (Check this!) Let $\mu: [0, \pi] \rightarrow S^1$ be defined by $\mu(\theta) = (\cos(\theta), \sin(\theta))$ . Then the image of $\mu$ is a 1-cell, $\sigma$ , in $S^1$ . Let's integrate $w$ over $\sigma$ . $$
\int_\sigma \omega = \sum_{i=1}^4 \int_{\phi^{-1}(\sigma)} \phi_i^*(f_iw).
$$ In the next step he shows, $$
\int_{-(-1,1)} -\sqrt{1-t^2}dt + 0 + \int_{[0,1)} \sqrt{1-t^2}dt + \int_{-[0,1)} -\sqrt{1-t^2}dt.
$$ In general, I do not understand how he gets the range of the four integrals. I would expect it to all be $(-1,1)$ . Since $\sigma$ is the entire $S^1$ image and the partitions of unity would limit the integrand to be valid only for the points in $S^1$ that each $\phi_i$ outputs to, I don't see why it wouldn't always be $(-1,1)$ . References $$
\omega = -y\ dx + x\ dy
$$ Let $U_i = (-1,1)$ for $i=1,2,3,4$ . \begin{align*}
\phi_1(t) ={} & (t, \sqrt{1-t^2}) \\
\phi_2(t) ={} & (t, -\sqrt{1-t^2}) \\
\phi_3(t) ={} & (\sqrt{1-t^2}, t) \\
\phi_4(t) ={} & (-\sqrt{1-t^2},t).
\end{align*} \begin{align*}
\phi_1^* \omega = \phi_4^* \omega  ={} & \frac{-1}{\sqrt{1-t^2}}dt
\\
\phi_2^* \omega =\phi_3^* \omega ={} & \frac{-1}{\sqrt{1-t^2}}dt.
\end{align*}","['differential-forms', 'differential-geometry']"
4548511,"An inequality equivalent to Hörmander's condition $\sup_{y\in\mathbb R^n}\int_{\{x: |x|>2|y|\}}|K(x-y)-K(x)|\,dx<\infty$","Let $K\in L_{\text{loc}}^1(\mathbb R^n\setminus\{0\})$ . Prove that $$\sup_{y\in\mathbb R^n}\int_{\{x: |x|>2|y|\}}|K(x-y)-K(x)|\,dx<\infty\label{1}\tag{1}$$ if and only if $$\sup_{r>0}\frac1{r^n}\int_{B(0,r)}\int_{\{x: |x|>2r\}}|K(x-y)-K(x)|\,dx\,dy<\infty.\label{2}\tag{2}$$ This is an old exam problem on Harmonic Analysis. Formula \eqref{1} is called the Hörmander's condition for singular integrals. The proof of \eqref{1} $\Rightarrow$ \eqref{2} is quite easy: assume $$\int_{\{x: |x|>2|y|\}}|K(x-y)-K(x)|\,dx\leq M,\qquad \forall y\in\mathbb R^n,$$ then for $r>0$ and $y\in B(0,r)$ we have $\{x: |x|>2r\}\subset \{x: |x|>2|y|\}$ , so $$\int_{\{x: |x|>2r\}}|K(x-y)-K(x)|\,dx\leq \int_{\{x: |x|>2|y|\}}|K(x-y)-K(x)|\,dx\leq M,$$ hence $$\frac1{r^n}\int_{B(0,r)}\int_{\{x: |x|>2r\}}|K(x-y)-K(x)|\,dx\,dy\leq \frac1{r^n}\int_{B(0,r)}M\,dy=M|B(0,1)|,\ \ \ \forall r>0.$$ This completes the proof of \eqref{1} $\Rightarrow$ \eqref{2}. However, for \eqref{2} $\Rightarrow$ \eqref{1}, I don't know how to start. Any help would be appreciated!","['harmonic-analysis', 'singular-integrals', 'real-analysis']"
4548535,"Limits of the sum of two sets, and the sum of two limits of sets.","If I have two sets $A,B$ such that $A=\bigcap_{n\geqslant1}A_n$ and $B=\bigcap_{n\geqslant1}B_n$ where $A_n\supset A_{n+1}$ and $B_n\supset B_{n+1}$ for all $n$ , and if $A_n+B_n=\{a+b:a\in A_n,b\in B_n\}=C$ for all $n\geqslant1$ and some constant bounded set $C$ : can I say that $A+B=\bigcap_{n\geqslant1}(A_n+B_n)=C$ ?  Clearly $A=\lim_{n\to\infty}A_n$ and $B=\lim_{n\to\infty}B_n$ , but can I bring this limit outside?","['elementary-set-theory', 'analysis', 'real-analysis']"
4548536,Can every non-hermitian matrix be written as a sum of hermitan matrices?,"If $X$ is non- hermitian i.e., $X^\dagger = (X^*)^T \ne X$ , can one express it as $X = \sum_i \alpha_i Y_i$ where $\alpha_i$ is a complex scalar and $Y_i$ is hermitian?","['matrices', 'hermitian-matrices']"
4548559,Prove $f(x+y)=f(x) + y' \nabla f(x) + \frac{1}{2} y' ( \int_0^1 ( \int_0^t \nabla^2 f(x+ \tau y) d \tau)dt)y$ when f twice differentiable over sphere,"In the book http://www.athenasc.com/nonlinbook.html by Dimitri P. Bertsekas, there is a proposition A.23(a) in Appendix A without proof that : I am able to prove the other two statements (b) and (c) which use Taylor series but unable to prove this one. How can this statement be proved?","['derivatives', 'taylor-expansion']"
4548648,limits of 2 variables with trigonometric terms,"I'm trying to determine the following limit $$ \lim_{(x,y) \to (0,0)} \frac{x^2-\sin(x^2y^2)+y^2}{x^2+\sin(x^2y^2)+y^2}$$ I tried to use polar coordinates and then Taylor and got $$ \lim_{r \to 0} \frac{2-2 \cdot \cos^2(\theta) \cdot \sin^2(\theta) \cdot \cos(r^2\cos^2(\theta)\sin^2(\theta))}{2+2 \cdot \cos^2(\theta) \cdot \sin^2(\theta) \cdot \cos(r^2\cos^2(\theta)\sin^2(\theta))}$$ Which does not say anything I guess? How can I solve this type of questions?","['multivariable-calculus', 'limits', 'calculus', 'polar-coordinates']"
4548651,Showing that the intersection of two subgroups is a product of subgroups.,"Let $U, V$ be subgroups of a group $G$ and $N, M$ be normal subgroups of $U, V$ respectively. Consider the following diagram: Every 'node' in the diagram is a subgroup of $G$ . We see that if node $A$ is connected to node $B$ by an edge moving upwards, then $A < B$ . In addition, I've been told the following statements are also true: The intersection of two downward-sloping line segments is the intersection of the two nodes the segments originate from. The intersection of two upward-sloping line segments is the product of the two nodes the segments originate from. I've managed to convince myself that statement 1. is true for all but the $(N\cap V)(U\cap M)$ node, i.e I wish to show: $$ \left( N(U\cap M) \right) \cap \left( (N\cap V)M \right) = (N\cap V)(U\cap M).$$ It's clear that the RHS lies inside the LHS ( $N$ contains $N\cap V$ for example), but I haven't been able to show that LHS $\subset$ RHS. My attempt so far has mostly been playing with the definitions to get: Let $g \in N(U\cap M)$ and assume $g \in (N\cap V)M$ , then we can write $$ g = n u_M = v_N m $$ for $n \in N, u_M \in U\cap M, v_N \in V\cap N, m \in M$ . One way to move forward is to find $v_N' \in N\cap V, u_M' \in U\cap M$ such that $g = v_N'u_M'$ , although I do not know how to define these elements $u_N', v_M'$ . Alternatively, if I could reason that $n$ must lie in $V$ (or $m$ must lie in $U$ ) then I would also have the result. Unfortunately, I haven't been able to take either of these approaches sufficiently far. Any recommendations on how I should proceed? Perhaps the normality of $N, M$ in $U, V$ can help since I haven't used those yet? For context: the diagram and the setting are from pages 20-21 of Lang's Algebra, with the notation changed slightly (he uses $u = N \vartriangleleft U$ and $v = M \vartriangleleft V$ ), and this is used to prove the Butterfly Lemma.","['normal-subgroups', 'group-theory', 'abstract-algebra']"
4548671,Complex analysis on how to find the proper function satisfying the condition,"$f$ and $g$ are both holomorphic in $\Bbb{C}$ , and for every $z$ in $\Bbb{C}$ , $$f(z)^2+g(z)^2=1$$ please help me prove there is a $h(z)$ which is holomorphic in $\Bbb{C}$ , such that $f(z)=\cos(h(z)), g(z)=\sin(h(z))$ . I try to suppose the conclusion is wrong, but I failed to find any contradiction here.",['complex-analysis']
4548726,Generalized Ramsey number bound,"In the linked paper by Vaclav Chvatal and Frank Harary, they conjecture that the Ramsey number of two general graphs $F_1,F_2$ satisfies $$r(F_1,F_2) \ge \min\left( r(F_1,F_1), r(F_2,F_2) \right)$$ This paper is really old, im wondering if someone knows if this conjecture has been (dis)proven (or any progress on it)? (PS I'd really appreciate if someone could comment below any other references about generalised ramsey numbers. For example, I already saw Chvatal's proof of the $r(T,K_n)$ an the proofs of $r(Q_n,K_t)$ )","['graph-theory', 'combinatorics', 'ramsey-theory', 'reference-request']"
4548804,Relationship between Fisher Test and Student Test,"When performing linear regression with one explanatory variable (predictor), one can compute Fisher's test with value $F$ , and derive Student's test $T=\sqrt{F}$ . When there is more than one explanatory variable (predictor), the relationship $T=\sqrt{F}$ no longer holds. Is there a relationship between $F$ and the different student tests $T_i$ (one for each variable)? Perhaps a system of equations? Note : I am referring to F test in Excel's linear regression report:","['statistics', 'probability', 'hypothesis-testing']"
4548816,Billingsley Problem 9.4: Applications of the law of iterated logarithms,"Here is question from Billingsley Problems 9.4. Let $\{X_n\}_n$ be i.i.d. simple random variables with mean $0$ and variance $1$ . Then law of iterated logarithms holds. Set $S_n = X_1 + \cdots + X_n$ . From $$P\bigg(\limsup_{n} \frac{S_n}{\sqrt{2n\log\log(n)}} = 1\bigg) = 1$$ and $$P\bigg(\liminf_{n} \frac{S_n}{\sqrt{2n\log\log(n)}} = -1\bigg) = 1,$$ together with the uniform bounded-ness of the $X_n$ , deduce that with probability $1$ the set of limit points of the sequence $$\bigg\{\frac{S_n}{\sqrt{2n\log\log(n)}}\bigg\}$$ is the closed interval from —1 to + 1. I am not sure where to start. Assumptions tell you where you the smallest and largest the limit can be, but takeng $x \in [-1,1]$ , how do I build a sequence of the form $$\{x_k\}_{k} = \bigg\{\frac{S_{n_k}}{\sqrt{2n_k\log\log(n_k)}}\bigg\}_{k}$$ such that $x_k \to x$ ? Maybe this is not a good way to approach the problem.","['probability-theory', 'probability', 'real-analysis']"
4548850,Find the area of the shaded region in the $\Delta ABC$,"$ABC$ is a right-angled triangle at $A$ . $AB=3cm$ , $BC=5cm$ , $CD=1cm$ . If $BE=EC$ , then what is the area of the shaded region? I could solve some parts of this question but got stuck and was able to find the following: $AC=4cm$ , $AD=3cm$ I also did two constructions. They were: Drawing a line $DG \parallel AB$ and $HE \parallel AB$ . $HE$ intersects $BD$ at $O$ . Through these and using similarity, I found the area of $\Delta DCG=\frac{3}{8} cm^2$ and quadrilateral $DGEO=\frac{5}{8} cm^2$ . This question was on an olympiad website. I am unable to find the area of $\Delta OFE$ . Can someone please help me out? It would be very helpful. Thank you.",['geometry']
4548891,Understanding Representation theory and group actions,"This might be a silly question, but I need help understanding an example of a representation of a group ,the following example is from Yvette Kosmann-Scwartbach's book called Groups and Symmetries: ''Let $t\in S_3 $ be the transposition $123\to 132$ and $c$ the cyclic permutation $123\to 231$ that generates $S_3$ .We set $j=e^{2i\pi/3}$ ,so that $j^2+j+1=0$ .We can represent $S_3$ on $\mathbb{C}^2 $ by defining $ρ(e)=I_2$ , $ρ(t)=\begin{pmatrix}
0 & 1 \\
1 & 0 \\
\end{pmatrix}$ and $ρ(c)=\begin{pmatrix}
j & 0 \\
0 & j^2 \\
\end{pmatrix}$ ''. My understanding is that $ρ_g , (ρ_g=ρ(g))$ is defined by the action of $S_3$ on $\mathbb{C^2}$ and so for $ρ(e)=I_2$ we get $ρ(e)=[a_{e(1)},a_{e(2)}]$ ,where $e$ the ''neutral'' permutation and $a=\{a_1,a_2\}=\{(1,0),(0,1)\}$ a basis of $\mathbb{C^2}$ and thus $ρ(e)=[a_1,a_2]=I_2 $ ,since $e:123 \to 123$ . That kind of logic doens't seem to work on the rest.What am I missing and how does the author introduce $j$ on the matrices? Thank you in advance !","['matrices', 'group-theory', 'group-actions', 'representation-theory']"
4548915,$\int_{1}^{\infty}\frac{[3x]}{[x]!}dx$,I saw an interesting definite integral at somewhere and would like to share. $$\int_{1}^{\infty}\frac{[3x]}{[x]!}dx$$ The solution given is $$\int_{1}^{\infty}\frac{[3x]}{[x]!}dx=\lim_{n \to \infty}\sum_{k=1}^{n-1}\int_{k}^{k+1}\frac{[3x]}{[x]!}dx$$ $$=\lim_{n\to \infty}\sum_{k=1}^{n-1}\left ( \int_{k}^{k+\frac{1}{3}}\frac{3k}{k!}dx+\int_{k+\frac{1}{3}}^{k+\frac{2}{3}}\frac{3k+1}{k!}dx+\int_{k+\frac{2}{3}}^{k+1}\frac{3k+2}{k!}dx \right )$$ $$=\lim_{n \to \infty}\sum_{k=1}^{n-1}\left ( \frac{1}{3}\left ( \frac{3k}{k!} \right )+\frac{1}{3}\left ( \frac{3k+1}{k!} \right ) +\frac{1}{3}\left ( \frac{3k+2}{k!} \right )\right )=\lim_{n \to \infty}\sum_{k=1}^{n-1}\frac{3k+1}{k!}=3\sum_{k=1}^{\infty}\frac{1}{(k-1)!}+\sum_{k=1}^{\infty}\frac{1}{k!}$$ $$=3e+e-1=4e-1$$ I wonder is there another way to solve this definite integral?,"['integration', 'calculus', 'definite-integrals']"
4548940,How to prove that generalized Vandermonde matrix is invertible?,"Given $$A = \left( z_i^{\lambda_k}\right)_{i,j = 1,\ldots, n} = 
\begin{pmatrix}
z_1^{\lambda_1} & z_1^{\lambda_2} & \cdots & z_1^{\lambda_n} \\
z_2^{\lambda_1} & z_2^{\lambda_2} & \cdots & z_2^{\lambda_n} \\
\vdots  & \vdots  & \ddots & \vdots  \\
z_n^{\lambda_1} & z_n^{\lambda_2} & \cdots & z_n^{\lambda_n} 
\end{pmatrix}.$$ with $z_1 < z_2 < ... < z_n \in \mathcal{R}_+$ and $\lambda_1 < \lambda_2 < ... \lambda_p \in \mathcal{R}$ ,  how to show that A is invertible? I think I probably need to show that the determinant is not zero but I am not sure how. I do some derivation and get Not sure how to continue. Also not sure if this is the right way. There is a similar question here Generalized Vandermonde-Matrix but the conditions are different.","['matrices', 'matrix-analysis', 'determinant', 'linear-algebra']"
4548962,"Spivak, Ch. 20, Problem 18: Use Taylor's Theorem to prove that $\lim\limits_{x\to a} \frac{f(x)-P_{n,a}(x)}{(x-a)^n}=0$","The following is a problem from Spivak's Calculus Chapter 20, Problem 18 : Deduce Theorem $1$ as a corollary of Taylor's
Theorem, with any form of the remainder. (The catch is that it will be
necessary to assume one more derivative than in the hypotheses for
Theorem 1). Here is Theorem $1$ Theorem 1 Suppose that $f$ is a function for which $$f'(a),...,f^{(n)}(a)$$ all exist. Let $$a_k=\frac{f^{(k)}(a)}{k!}, 0\leq k\leq n$$ and define $$P_{n,a}(x)=a_0+a_1(x-a)+...+a_n(x-a)^n$$ Then $$\lim\limits_{x\to a} \frac{f(x)-P_{n,a}(x)}{(x-a)^n}=0$$ and here is Taylor's Theorem Theorem 4 (Taylor's Theorem) Suppose that $f',...,f^{(n+1)}$ are defined on $[a,x]$ , and that $R_{n,a}(x)$ is defined by $$f(x)=f(a)+f'(a)(x-a)+...+\frac{f^{(n)}(a)}{n!}(x-a)^n+R_{n,a}(x)$$ Then $$R_{n,a}(x)=\frac{f^{(n+1)}(t)}{(n+1)!}(x-a)^{n+1},\text{ for some }
 t \text{ in } (a,x)$$ (Lagrange form of the remainder). My primary question is: why can or can't we use the following proof Assume we know Taylor's theorem is true and assume the first $n+1$ derivatives of $f$ exist on $[a,x]$ . Taylor's theorem tells us that $$f(x)-P_{n,a}(x)=R_{n,a}(x)=\frac{f^{(n+1)}(t)}{(n+1)!}(x-a)^{n+1},
 \text{ for } t\in (a,x)$$ Then, $$\lim\limits_{x\to a}
 \frac{f(x)-P_{n,a}(x)}{(x-a)^n}=\lim\limits_{x\to a}
 \frac{f^{(n+1)(t)}}{(n+1)!}(x-a)=0$$ In addition, let me just show the solution manual solution and my own understanding of it in more steps Solution Manual Suppose $|f^{(n+1)}|$ is bounded, by some $M$ , on some interval around $a$ . Then for $x$ in this interval we have $$|R_{n,a}(x)|=\frac{|f^{(n+1)}(t)|}{n!}|x-a|^{n+1}\tag{1}$$ so $$\frac{|R_{n,a}(x)|}{|x-a|^n}\leq M|x-a|\tag{2}$$ so $$\lim\limits_{x\to a} \frac{R_{n,a}(x)}{(x-a)^n}=0\tag{3}$$ A similar proof works for the integral form of the remainder and for
the Cauchy form. Here is my understanding of this proof in more steps Suppose we know Taylor's theorem is true, and assume the assumptions
of that theorem are true on some interval $[a,x]$ . One of those assumptions is that $f',...,f^{(n+1)}$ are defined on $[a,x]$ . Thus, $f^{(n+1)}$ is continuous on $[a,x]$ , and
hence bounded on this interval. Thus, there exists some $M>0$ , such that for any $x_1\in[a,x]$ we
have $|f^{(n+1)}(x_1)|\leq M$ . In addition, Taylor's theorem tells us that there is some $t\in
 (a,x)$ such that $$R_{n,a}(x)=\frac{f^{(n+1)}(t)}{(n+1)!}(x-a)^{n+1}\tag{4}$$ Second question: why does $(1)$ have the denominator as $n!$ and not $(n+1)!$ as in $(4)$ ? Now we take the absolute value of both sides of $(4)$ $$|R_{n,a}(x)|=\frac{|f^{(n+1)}(t)|}{(n+1)!}|(x-a)|^{n+1}$$ $$0\leq \frac{|R_{n,a}(x)|}{|x-a|^{n}}=\frac{|f^{(n+1)}(t)|}{(n+1)!}|x-a|$$ $$\leq \frac{M}{(n+1)!}|x-a|\leq M|x-a|$$ Hence $$\lim\limits_{x\to a}
 \frac{|R_{n,a}(x)|}{|x-a|^{n}}=\lim\limits_{x\to a}
 \frac{|f(x)-P_{n,a}(x)|}{|x-a|^{n}} =0$$ $$\implies \lim\limits_{x\to a} \frac{f(x)-P_{n,a}(x)}{(x-a)^{n}} =0$$ which is the result of Theorem 1.","['calculus', 'solution-verification', 'taylor-expansion', 'limits', 'derivatives']"
4548994,Independent sub σ-algebra measured by the same random variable,"Let $(\Omega,\mathcal{A},Pr)$ be a probability space and let $\mathcal{F}$ and $\mathcal{G}$ be two sub- $\sigma$ -algebras of $\mathcal{A}$ . Suppose that they are independent, and suppose that 𝑋 is real valued random variable on $\Omega$ which is measurable with respect to both $\mathcal{F}$ and $\mathcal{G}$ . Show that 𝑋 is almost surely constant; that is there is real number $c \in \mathbb{R}$ , so that $Pr(X=c)=1$ . Firstly, I am not sure what independent $\sigma$ -algebra means here and how I can connect the independence of $\sigma$ -algebra with random variable. Secondly, since $\mathcal{F}$ and $\mathcal{G}$ are different $\sigma$ -algebra, is it allowed to be measured by the same random variable? What does this imply? Maybe my question is a little bit vague, but I always think that different $\sigma$ -algebra should be measured by different random variable somehow. And I don't even know why I take it as granted. There is a solution somewhere. But I feel it makes no sense.","['measure-theory', 'independence', 'probability-distributions', 'probability', 'random-variables']"
4548995,Find all $\mathbb{Q}$-linear maps $\phi : \mathbb{Q}[x]\to\mathbb{Q}[x]$ that send irreducible polynomials to irreducible polynomials,"Let $\mathbb{Q}[x]$ denote the vector space over $\mathbb{Q}$ of polynomials with rational coefficients in $x$ . Find all $\mathbb{Q}$ -linear maps $\phi : \mathbb{Q}[x]\to\mathbb{Q}[x]$ that send irreducible polynomials to irreducible polynomials. If $\mathbb{K}$ is a field over which a vector space $V$ is defined and $W$ is a vector space, a $\mathbb{K}$ -linear map $T :V \to W$ satisfies $T(cx+y) = cT(x)+T(y).$ In particular, for any such linear map $T, T(0) = T(0)+T(0)\Rightarrow T(0)=0$ . Also, linear maps are uniquely determined by their values on a countable or finite basis, since if $\{a_1,a_2,\cdots\}$ is a basis for $V$ and $T:V\to W$ is a linear map, for any $x\in V, T(x) = \sum_{i=1}^k b_i T(a_{j_i})$ where $x = \sum_{i=1}^k b_i a_{j_i}$ is the unique representation of $x$ as a linear combination of basis vectors. In particular, $\{1,x,\cdots\}$ is a countable basis for $\mathbb{Q}[x]$ so it suffices to find the values of $\phi(x^i)$ for all $i\ge 0$ .
Note that in $\mathbb{C}[x]$ , the only irreducible polynomials are the polynomials of degree $1$ since it is known that every polynomial of degree $n\ge 1$ has a complex root. In $\mathbb{R}[x]$ , every odd degree polynomial has a real root since complex roots come in pairs. Hence no odd degree polynomial with degree at least 3 is irreducible. Note that the set of units in $\mathbb{K}[x]$ for a field $\mathbb{K}$ is precisely $\mathbb{K}\backslash \{0\}$ , since for any two elements $f,g \in R[x]$ where R is a ring and $f$ and $g$ have leading coefficients that are units, $\deg(fg) = \deg(f) + \deg(g)$ . In general for any ring $R$ and $f,g\in R[x], \deg(fg)\leq \deg(f)+\deg(g)\tag{1}$ . In $\mathbb{Q}[x]$ , any polynomial of degree $1$ is irreducible and the polynomials of degree $2$ that are irreducible are precisely those without rational roots. Also, by Gauss' lemma, in a unique factorization domain (UFD) $R$ , if $\mathbb{K}$ is the field of fractions of $R$ then if $f \in R[x]$ equals $gh$ for some $g,h \in \mathbb{K}[x],$ there exists a unit $u \in \mathbb{K}$ so that $ug, u^{-1} h \in R[x].$ In particular for the UFD $\mathbb{Z}$ , its field of fractions is $\mathbb{Q}$ so if a polynomial with integer coefficients can be written as a product of two nonconstant polynomials with rational coefficients, then it can also be written as a product of two nonconstant polynomials with integer coefficients. Also, if $f\in R$ is irreducible, then $f$ is also irreducible in $R[x]$ whenever $R$ is an integral domain as then (1) always holds with equality. For the given problem, it might be the case that if $f + cg$ is irreducible (in $\mathbb{Q}[x]$ ) for all $c\in\mathbb{Q}$ , then either $g=0$ and $f$ is irreducible or $f$ is of degree 1 and g is a constant or g is linear. If this claim holds, if $f,g$ are polynomials so that $f+cg$ is irreducible for all $c\in\mathbb{Q},$ then since $\phi(f+cg) = \phi(f)+c\phi(g),\phi(f) + c\phi(g)$ are irreducible for all $c\in\mathbb{Q}$ . Hence $\phi(g) = 0$ or $\phi(f)$ has degree $1$ and $\phi(g)$ is a constant or linear. As an attempt to prove the claim, I think one can proceed using a proof by contradiction. Suppose $f(x)$ has degree $1$ and $g$ is nonzero. Write $f(x)=dx+e, d,e\in\mathbb{Q}$ . If $g$ has degree 2, say $g = ax^2+bx+c$ for some $a,b,c\in\mathbb{Q}$ , then $f(x)+rg(x) = rax^2 + (rb+d)x+(rc+e)$ . We need to choose $r$ so that this quadratic has a rational root, which will be the case provided its discriminant is the square of a rational number. But I'm not sure how to find such an $r$ or if it (always) exists.
The product of two irreducible polynomials is obviously reducible but the sum may or may not be irreducible. For instance, $x+x^2+x+1$ is reducible even though both $x$ and $x^2+x+1$ are irreducible over $\mathbb{Q}[x]$ . Every polynomial in $\mathbb{Q}[x]$ or $\mathbb{R}[x]$ can be written (uniquely) as a product of irreducibles (note that every Euclidean domain is a PID and every PID is a UFD).","['vector-spaces', 'ring-theory', 'linear-algebra', 'polynomials', 'linear-transformations']"
4549011,If 10 items were chosen at random (with replacement) how many combinations are there to draw exactly x of the n items?,"I'm sure this has been asked in this forum before but I don't even know where to begin wording the question to find it. Here's what I'm trying to do: We have n number of items of one color and m number of items of another color. If y items are chosen at random (with replacement) how many combinations are there to draw exactly x of the n items? x < y. I found the formula for combinations with replacement is (𝑛+𝑘−1 choose 𝑘) but how does this formula apply if, for example, x = 3 and y = 10? Because 10 items are chosen out of n+m total items, but we only care about the combinations of the 3 items, not of the other 7.","['permutations', 'statistics', 'probability', 'combinations']"
4549021,"Prove that there exists $\xi \in (a,b)$ such that $f(a)-2f(\frac{a+b}{2})+f(b)=\frac{1}{4}(b-a)^2f''(\xi) .$ [duplicate]","This question already has answers here : Proving a 2nd order Mean-Value theorem [closed] (2 answers) Closed 1 year ago . Given that f is twice differentiable on $[a,b]$ , prove that there exists $\xi \in (a,b)$ such that $$f(a)-2f\left(\frac{a+b}{2}\right)+f(b)=\frac{1}{4}(b-a)^2f''(\xi) .$$ This problem was given in a book and the hint was to consider the following auxiliary function, and apply Rolle's Theorem: $$F(t) = f(t) +f(a) -2f\left(\frac{t+a}{2}\right) - \lambda\cdot\frac{(t-a)^2}{4}$$ Where $$\lambda = \frac{f(a)+f(b)-2f\left(\displaystyle\frac{a+b}{2}\right)}{\displaystyle\frac{(b-a)^2}{4}}.$$ I tried and got stuck. My attempt: Notice that $F(a) =  F(b) = 0$ , by Rolle's Theorem, there exists $\xi_1 \in (a,b)$ such that $F'(\xi_1)=0$ . After differentiation, we obtain $$F'(t) = f'(t)-f'\left(\displaystyle\frac{t+a}{2}\right)-\lambda\cdot\displaystyle\frac{t-a}{2}$$ We find that $F'(a) = 0$ , thus applying Rolle's Theorem again, there exists $\xi_2 \in (a,\xi_1)$ such that $F''(\xi_2) = 0$ Therefore $$0=f''(\xi_2)-\frac{1}{2}f''\left(\frac{\xi_2+a}{2}\right) - \frac{\lambda}{2}$$ and $$\lambda = 2f''(\xi_2) - f''\left(\frac{\xi_2+a}{2}\right).$$ I got stuck here and was unable to proceed. I did consider using Darboux's Theorem but I don't think that it is applicable here.","['rolles-theorem', 'analysis', 'real-analysis']"
4549043,A likelihood problem with a biased coin but with missing data,"I'm trying to build up an intuition about likelihoods and have come up with a few problems. This one builds on top of a previous problem: A likelihood problem with a biased coin Suppose an unknown number of people flip an unfair coin $k$ times and $Z_i$ is the number of people who landed $i$ heads where $i\in{0,1,...,k}$ . Now suppose only $Z_0$ is unknown (so we know $Z_1,...Z_k$ ). I would like to find the likelihood $l(Z_1,...,Z_k|p)$ and so used the following argument: Let $X_j ∼ Bin(N,π)$ where $X_j$ is the number of heads person $j$ landed. Suppose that observations are available for $Y_j = X_j| {X_j >0}$ ( $Y_j$ follows a truncated binomial distribution). Consequently, we have the following probability mass for the observations $j =1, 2, . . . , N:$ $P(X_j=j|X_j>0)=\frac{{N \choose j}p^j(1-p)^{N-j}}{1-(1-p)^N}$ And so (I think): $l(Z_1,...,Z_k|p)={\sum_{j=1}^kZ_j \choose Z_1,Z_2,...,Z_k}\Pi_{i=1}^k\Big({k \choose i}{\frac{ p^i(1-p)^{k-i}}{1-(1-p)^k}}\Big)^{Z_i}$ Is this correct?","['statistics', 'probability', 'maximum-likelihood']"
4549098,Outer Measure limit equality,"Suppose M is the class of measurable sets with respect to an outer measure $\mu^*$ defined on the subsets of $\Omega$ . Take { $E_n$ } to be a monotone increasing sequence of sets in M and A any set in $\Omega$ . Prove that: lim $\mu^*( A \cap E_n)$ = $\mu^*($ lim $A \cap E_n)$ (the limits are taken with $n$ going to $\infty$ ) I could prove ""less or equal"" using monotonicity of the outer measure, but I'm having a bit of trouble with the other side. This is exercise 8 from section 4.1 of S. J. Taylor's Introduction to Measure and Integration Edit: $\mu^*$ here is any outer measure, not necessarily an induced one. In such manner, we can't say that for every set $A$ there exists a measurable set that covers it and has the exact same measure. When this property holds, Taylor refers to $\mu^*$ as a ""regular outer measure"".","['measure-theory', 'outer-measure']"
4549143,Precise assumption in spectral theorem of unbounded operators,"The most general version of the spectral theorem I am aware of is the spectral theorem for unbounded normal operators (firstly proven by von Neumann in 1932, I think). An operator $T:\mathcal{D}(T)\to\mathcal{H}$ in some Hilbert space $\mathcal{H}$ is called normal, if $$TT^{\ast}=T^{\ast}T.$$ Note that this is an equlity on the level of operators, which means that we require that $$\mathrm{D}(TT^{\ast})=\{\psi\in\mathcal{D}(T^{\ast})\mid T\psi\in\mathcal{D}(T)\}\stackrel{!}{=}\{\psi\in\mathcal{D}(T)\mid T\psi\in\mathcal{D}(T^{\ast})\}=\mathcal{D}(T^{\ast}T)$$ as well as $$TT^{\ast}\psi=T^{\ast}T\psi,\hspace{2cm}\forall \psi\in\mathcal{D}(TT^{\ast}).$$ Roughly speaking, the spectral theorem for general normal (possibly unbounded) operators states in its measure-theoretic formulation the following: Let $T$ be a normal operator $T:\mathcal{D}(T)\to\mathcal{H}$ . Then
there exists a unique spectral measure $P:\mathcal{B}(\sigma(T))\to\mathcal{B}(\mathcal{H})$ , where $\mathcal{B}(\sigma(T))$ denotes the Borel $\sigma$ -algebra on the spectrum $\sigma(T)$ and $\mathcal{B}(\mathcal{H})$ the set of bounded operators on $\mathcal{H}$ , such that $$\mathcal{D}(T)=\bigg\{\psi\in\mathcal{H}\,\bigg\vert\,\int_{\sigma(T)}\,\vert\lambda\vert^{2}\,\mathrm{d}\langle\psi,P_{\lambda}\psi\rangle\bigg\}$$ and $$T=\int_{\sigma(T)}\,\lambda\,\mathrm{d}P_{\lambda}.$$ Now, unfortunately, it is quite hard to find a discussion of the spectral theorem in this general version in the literature and hence, I am unsure about the precise requirements: In particular, I have the following short questions: Does one have to assume separability of the Hilbert space $\mathcal{H}$ ? Shouldn't one assume more precisely that $T$ is
closed and densley-defined? As far as I know, there is a theorem
stating that if $T$ is densely-defined and closed, then $TT^{\ast}$ is itself densely-defined and self-adjoint and I guess that this is
what we need in order to proof the spectral theorem. Is there any other requirement for the theorem to hold? Does one have a good literature, which treats the spectral theorem in this level of generality?","['operator-theory', 'hilbert-spaces', 'functional-analysis', 'unbounded-operators', 'spectral-theory']"
4549145,"Is the curve i get from a circle drawn on a paper rolled into a cylinder, after unrolling a cylindrical piece of paper, an ellipse?","Say I have a cylindrical can of beans. If I try to draw a 'circle' on the label of the can by using a compass and then flatten the label into a plane, will the 3D 'circle' originally on the cylinder  label become an ellipse. I tried to solve it using analytical geometry but it turned out to be somewhat difficult.  It sure looks like an ellipse but I got an expression for the semi-major axis that contains the arcsin function involving the radius of the compass and that of the cylindrical  can. Can anybody provide an intuitive answer please?",['geometry']
4549146,The Borel $\sigma$-algebra generated by the product topology coincides with the product of Borel $\sigma$-algebras: where did I get wrong?,"Let $(\Omega_n, \tau_n)_n$ be a sequence of metrizable topological spaces. Let $\sigma (\tau_n)$ be the Borel $\sigma$ -algebra on $\Omega_n$ . Let $\Omega :=\prod_{n =1}^\infty \Omega_n$ and $\pi_n: \Omega \to \Omega_n$ be the canonical projection map. Let $\bigotimes_n \sigma (\tau_n)$ be the smallest $\sigma$ -algebra on $\Omega$ such that all maps $\pi_n$ 's are measurable. $\sigma (\bigotimes_n \tau_n)$ be the Borel $\sigma$ algebra on $\Omega$ that is generated by the product topology $\bigotimes_n \tau_n$ on $\Omega$ . It follows from this answer that below theorem is false without the assumption that each $\tau_n$ is second-countable. However, I manage to ""prove it"" without this assumption. False Theorem: $\bigotimes_n \sigma (\tau_n) = \sigma (\bigotimes_n \tau_n)$ . Could you elaborate on where I made a mistake? Thank you so much! My attempt: We have $\bigotimes_n \tau_n$ is metrizable and thus perfectly normal. Hence $\sigma (\bigotimes_n \tau_n)$ is the smallest $\sigma$ -algebra on $\Omega$ such that every continuous function whose domain is $\Omega$ is measurable. We have $\pi_n$ is continuous w.r.t. $\bigotimes_n \tau_n$ . Hence $\pi_n$ is measurable w.r.t. $\sigma (\bigotimes_n \tau_n)$ . It follows that $$
\bigotimes_n \sigma (\tau_n) \subset \sigma (\bigotimes_n \tau_n).
$$ Let's prove the reverse, i.e., $$
\sigma (\bigotimes_n \tau_n) \subset \bigotimes_n \sigma (\tau_n).
$$ Let $$
\mathcal C := \{\pi^{-1}_n(A_n) \mid n \in \mathbb N, A_n \in \sigma (\tau_n)\}.
$$ Then $\bigotimes_n \sigma (\tau_n) = \sigma (\mathcal C)$ . So we want to prove $$
\sigma (\bigotimes_n \tau_n) \subset \sigma (\mathcal C).
$$ Let $$
\mathcal D := \{\pi^{-1}_n(A_n) \mid n \in \mathbb N, A_n \in \tau_n\}.
$$ Then $\bigotimes_n \tau_n$ is the topology on $\Omega$ generated by $\mathcal D$ .  This also means that $\mathcal D$ is a subbase of $\bigotimes_n \tau_n$ . This implies $$
\sigma (\bigotimes_n \tau_n) = \sigma (\mathcal D) .
$$ The claim then follows trivially by the fact that $\mathcal D \subset \mathcal C$ .","['general-topology', 'second-countable', 'measure-theory']"
4549194,Is the expectation operator an open map?,"Let $\Delta [0,1]$ denote the set of Borel probability measures on $[0,1]$ . $\Delta [0,1]$ endowed with the Prokhorov metric is a metric space, as we know. My question is, does the expectation operator map an open set of measures in $\Delta [0,1]$ to an open interval in $[0,1]$ ? In other words, is expectation an open map? I found this related question, but I'm not able to easily apply related arguments to verify if this claim is true. I'm very new to open maps. Any help is most appreciated. Edit: In the earlier version of this question I mistakenly said ""Borel measures"" instead of ""Borel probability measures"".","['measure-theory', 'open-map', 'metric-spaces', 'expected-value', 'linear-transformations']"
4549300,Here is a linear algebra problem from an interview and I have no clue.,"Matrix C of size n $\times$ n is symmetric . Zero is a simple eigenvalue of C. The associated eigenvector is q. For $\epsilon$ >0, the equation $Cx+\epsilon x=d$ in x, where x and d are n-dimensional Column vectors and d is known, has a solution that depends on $\epsilon$ . Call this solution $x(\epsilon)$ . Express $ \lim\limits_{\epsilon \to 0^+} \epsilon x(\epsilon)$ in terms of vectors q and d. I have some inspirations: When $\epsilon \to 0$ , $\epsilon q$ also comes to $0$ . So we have: $C(x+q)+\epsilon (x+q)=d$ Since C is a symmetrix matrix, we use diagonalization like: $U\Lambda U^Hx+\epsilon x=d$ But to be honest, I have no clue on this and it bothers me a lot. I can't figure out how to use these conditions we have. Thank you for reading my question! Could you give me some clues on this problem?","['limits', 'linear-algebra', 'eigenvalues-eigenvectors']"
4549329,Probability of red balls present in the urn,"There are n total balls in the urn containing red and blue colors with unknown ratios. k red balls can be anywhere from 0 to n being equally likely and the remaining n - k will be blue balls. What is the probability of k red balls in the urn if the first ball drawn is red? What is the probability of k red balls in the urn if the first ball drawn is red without replacement and the second ball drawn is blue? I know that Bayes's rule will be applied to find out the probability of red balls present in the given. I think P(k red balls) = 1/( n +1) and P( n - k blue balls) = n / n +1 Further, Bayes's formula will be applied so that P( k red balls|ball drawn is red) = {P(ball drawn is red | k red balls)*P( k red balls)}/P (ball drawn is red) But I am stuck as to how to use this to find the answer.",['probability']
4549350,Double integral objective question.,"Let $G(t,x):[0,1]\times [0,1]\to\mathbb R$ be defined as $$
G(t,x)=\begin{cases}
t(1-x)& \text{if $t\leq x\leq 1$ }\\
x(1-t) & \text{if $x\leq t\leq 1$}
\end{cases}
$$ For a continuous function $f$ on $[0,1]$ define $$I(f)=\int_0^1\int_0^1G(t,x)f(t)f(x)dtdx$$ Which of the following is true? $1$ . $I(f)>0$ if $f$ is not identically zero. $2.$ $I(f)=0$ for some non-zero $f$ . $3.$ $I(f)<0$ for some non-zero $f$ . $4$ . $I(sin(\pi x))=1.$ It’s single option correct question. How to solve it ? $G(t,x)$ is clearly non negative as given, but value of $f$ is not given so  value of $f(t)f(x)$ in integrand can be negative? If minimum value of $f$ is positive then I can say that Integral will be positive . One way can be think about this question as the given function $G(t,x)$ is green function corresponding to ODE $$y’’=-f(x), y(0)=y(1)=0$$ Please help . Thank you.","['multivariable-calculus', 'multiple-integral']"
4549376,Range of an analytic function on a unit disc,Let $f(z)$ be an analytic function on an open set of the complex plane containing the closed unit disc $D=\{z\in \mathbb{C}:|z|\leq 1\}$ . Let $m$ be the minimum of $\{f(z)\ |\ z\in D\}$ and $M$ be the minimum of $\{|f(z)|\ |\ z\in C\}$ where $C=\{z\in \mathbb{C}:|z|=1\}$ of $D$ . Assume that $m<M$ . Then state whether the following are true or false? (i) $f(z)$ admits a zero on $D$ . $(ii)$ $f(z)$ attains every complex number $w$ on $D$ such that $|w|<M$ . My attempt: I know that statement $(i)$ is true because of the Minimum modulus principle. But I am not able to find the explanation of statement $(ii)$ . Please help.,"['complex-analysis', 'derivatives']"
4549382,Understanding if the integral expression obtained is correct and if its (incorrect ) mistake in the approach to get that result,"The integral was: $$\int_{0}^{\frac{\pi}{2}} \frac{\cos^2x}{(a^2+b^2\sin^2x)^{3/2}}\;dx= \frac{\pi}{2ab^2} (1-\frac{a}{\sqrt{a^2+b^2}}).$$ I encountered this integral while trying to show amperes law working in an EM (electromagntism) problem . My progess: I tried substituting $a^2 + b^2 \sin^2x = t^2 $ but that doesnt help much. Next I tried writing $\cos^2x$ in terms of $\sin^2x$ and then separately do the integration for two parts in the expression but that I wasnt able to show. Any help greatly appreciated. The setup was this (figure added ) : a semi infinite wire straight current $I$ being given to a plane sheet ( current flows radially there )  . Find magnetic field at a general point . (By some symmetry reasons one compute it to be $B = \frac{u_°I}{2\pi r}$ $\hat{k}$ at a point $(r,h,0)$ by Amperes Law,  the plane being $y=0$ and semi infinite line being the y axis , current direction in that in $-y$ direction . Now by integration approach ( figure added ) i first find the magentic field due to a current dI = $\frac{I}{2\pi} d\theta$ between $\theta$ and $\theta +d\theta$ angle in the plane at that point,  it comes out to be $\frac{u_°I}{4\pi(h^2 + r^2sin^2\theta)} (1+ \frac{rcos\theta}{\sqrt(h^2 + r^2 sin^2\theta)})$ ( $hsin\theta \hat{i} - rsin\theta \hat{j} + hcos\theta \hat{k})$ Now integrating in limits $0$ to $2\pi$ the $\hat{i}$ and $\hat{j}$ components goes to zero and we are left with. $\int_{0}^{\pi}\frac{u_°I}{4\pi(h^2 + r^2sin^2\theta)} (1+ \frac{rcos\theta}{\sqrt(h^2 + r^2 sin^2\theta)}) (2 hcos\theta \hat{k})$ This with the straight wire current magentic field which is standard integral ( means easily evalualted) should result in what we get from amperes law as net magnetic field at that point . On comparing we arrived at the result i mentioned at first . Now if there is any mistake in my approach that would also be fine as acceptable answer . If the calculation and approach is fine then only share the method for evaluating that integral .","['integration', 'calculus', 'electromagnetism']"
4549408,"""Generalised Isotropy""","Let $G\subseteq S_N$ be a finite permutation group and $\mathcal{P}=\bigsqcup_{i=1}^nX_i$ a partition of $\{1,\dots,N\}$ . We can define a subgroup $G_{\mathcal{P}}\subseteq G$ by: $$G_{\mathcal{P}}:=\{\sigma\in G\,\colon\,\sigma(X_i)=X_i\}.$$ In particular, the isotropy subgroup $G_i$ is given by $G_{\mathcal{P}_i}$ where $\mathcal{P}_i:=\{i\}\sqcup(\{1,\dots,N\}\backslash \{i\})$ . Question: has such a construction $G_{\mathcal{P}}\subseteq G$ got a name in the literature? If not known, can be come up with a better name than ""generalised isotropy"". Perhaps something with ""orbits"" I see the same construction here .","['permutations', 'finite-groups', 'reference-request', 'group-theory', 'group-actions']"
4549461,evaluation of a definite integral involving inverse hyperbolic functions,The following integral appears during the analysis of statistical mechanical models. $$\int\limits_0^{\pi /2}{\operatorname{arctanh} \left[ {\sqrt {1 - \sin (x)\sin (x){a^2}} } \right]dx} $$ Is there a closed form solution for the integral?,"['integration', 'improper-integrals', 'approximation', 'analysis', 'calculus']"
4549499,"What are the advantages of ""modern"" differential geometry to solve ODEs","I am currently learning ""modern"" differential geometry (i.e. in terms of vector fields, differential forms, etc, in a coordinate-free way). I know that the study of ODEs can be rewritten in those terms, see for instance this math.se question . However, I don't really understand yet what is gained in using this language compared to what one learns in the first few years of undergrad. I am looking for a good reference that would describe in detail how this modern view of differential geometry can be used to solve flows induced by vector fields (in particular, the existence of fixed points, perturbations of those, etc), and/or one that explains the advantages of that approach. Skimming through Lee's introduction to differential geometry (p. 333), it seems that I am looking for a reference for ""smooth dynamical systems"" in this language, but I can't find something relevant online.","['dynamical-systems', 'ordinary-differential-equations', 'differential-geometry']"
4549501,"Question regarding proof, concerning finite groups and definite hermitian forms.","I have a question regarding the proof of theorem 4.8 on p.336 in the following paper . I try to give an short outline. In the second part of the proof, the author wants to show, that the group $H$ is finite. Therefore he constructs a diagonal embedding $$\phi : H \to \prod_{k \in (\mathbb{Z}/h\mathbb{Z})^*}H_k$$ and shows, that the image of $H$ is contained in $GL(mn,\mathbb{Z})$ and also leaves invariant a definite hermitian form on $\mathbb{C}^{mn}$ . He then directly cocludes, that $H$ has to be finite, what i dont understand . What we have: Well, we have that $H$ is isomorphic to a subgroup $im(\phi) \subset GL(mn,\mathbb{Z})$ and a hermitian form $F$ on $\mathbb{C}^{mn}$ invariant under $H$ . So up to isomorphism, we have $$H \subset U_F(\mathbb{Z}) = \{X \in GL(mn,\mathbb{Z})\mid X^t F \overline{X}=F\}.$$ Also $F$ being definite means, that $H \subset U(mn,\mathbb{Z})$ . But what is the relation now, between definite hermitian forms an finite groups?","['group-theory', 'abstract-algebra']"
4549550,"I just built a non-measurable set without the axiom of choice, where is my mistake?","Suppose $p \in \mathbb{R}$ . Let us define $p_k$ the $k\text{-th}$ decimal. Let us define, whet it exists, the limit of the mean of the $k\text{-th}$ first decimal. $$c_p = \lim_{n \rightarrow \infty} \frac{\sum_{1}^{n}{p_k}}{n}$$ Let us define $$R_5 = \{r \in [0, 1] | c_r = 5\}$$ $R_5$ is not empty, since $0.55555... \in R_q$ . It is also dense in $[0,1]$ . (if $x < y$ , you can find the first different decimal, and replace the end with 55555... on either $x$ or $y$ , depending on their next decimal : e.g. if $x=0.4566666..$ , $y=0.457777...$ , choose $0.457555...$ ). $R_5$ is uncountable, since you can use the Cantor diagonalization process, and build the $q_k$ decimal as 5 if the $q_k$ decimal of the number it is compare to is not a 5, and alternate between 1 and 9 if it is a 5. $R_5^{c}$ is also uncountable and dense in $[0, 1]$ , and even in every $[a, b]$ , with $0 \le a < b \le 1$ . Since I can build some $R_p$ for each $p \in ]1, 8[$ using a similar trick, and they are trivially disjoint, $\mu(R_p) = 0$ is the only possible solution. But since it is dense and uncountable, I cannot apply a similar trick as what is used to measure the Cantor's set or the rational set. It seems like $R_5$ is not Lebesgue-measurable (the outer Lebesgue measure is not equal to the inner Lebesgue measure), and was designed without the use of the axiom of choice. But, as said in a lot of answer, this is impossible (with the ZF axioms alone, every set of $\mathbb{R}$ is measurable), see e.g. https://en.wikipedia.org/wiki/Non-measurable_set . So, where is my mistake ?","['measure-theory', 'lebesgue-measure']"
4549566,Find solution set of $\mathbb{C}$-valued equation $y^{(4)}=2y^{(3)}-y''$,"Problem: $\text{Find the solution set of this } \mathbb{C}\text{-valued equation }$ $$y^{(4)}=2y^{(3)}-y''$$ $\text{So we have } y^4=2y^3-y^2 \implies y=1\lor y=0$ . As the solution said, we have $\phi_1(x)=1, \phi_2(x)=x, \phi_3(x)=e^x, \phi_4(x)=xe^x$ and they are linearly independent . $\mathscr{H}=\{c_1\phi_1+c_2\phi_2+c_3\phi_3+c_4\phi_4|c_1,c_2,c_3,c_4\in\mathbb{C}\}$ I have no idea where those $\phi$ come from, it'll be great, if some one could explain it. Thanks in advance!",['ordinary-differential-equations']
4549591,ODE with inequality constraint,"I have the Lagrangian $L(u,u';z)$ where $D$ is the spacetime dimension, $m_0$ is some initial mass (constant), and $C$ is another constant. $$L = \frac{1}{z^{D-1}}\sqrt{-u'(z) \left( f(u,z) u'(z) + 2\right)}$$ where $$f(u,z) = 1 - m(u) z^{D}, \qquad m(u) = \left(\frac{D}{C u(z) + D\;m_0^{-1/D} }\right)^D, \qquad \frac{du}{dz} = u'$$ The Euler-Lagrange equation leads to a 2nd-order ODE (most likely nonlinear), $$\frac{d}{dz} \frac{\partial L}{\partial u'} = \frac{\partial L}{\partial u} \quad \rightarrow \quad \mathbb{2nd -order \: ODE}$$ with boundary conditions $u(0) = a$ and $u'(z_s) = \infty$ , where $a$ is some fixed number while $z_s$ is a parameter that I want to vary in the end to see how $u(z)$ changes. Typically, the boundary points of u(z) are specified at some known boundary $z$ points. Here, I only know for sure that one endpoint is at $z=0$ but the other is at $z=z_s$ for which $z_s$ can be varied to study how $u(z)$ changes, specifically I want to find which $z_s$ will give a minimum solution for $u(z)$ , i.e. you could say that the minimum out of the set of minimum solutions that came from the E-L equation for a set of specified $z_s$ . In addition to the 2nd-order ODE, there is also an inequality constraint, $$\frac{D}{C} \left( z_s - m_0^{-1/D}\right) > u(z)$$ I have scanned the web for some information about this including adding a slack and converting an inequality to an equality constraint. However, material is quite scarce when it comes to ODEs, or maybe I'm just ignorant of some things. When thinking about constraints, the Lagrange multiplier immediately comes to mind, however, for the E-L equation the multiplier method does not work for inequality constraints. My questions are, Suppose I choose a particular $z_s$ to completely fix the bc condition, how can I solve an ODE with inequality constraint? Is there a more general method that incorporates the variability of $z_s$ ? *I can work with Mathematica and have some basic understanding of say, the shooting method.","['boundary-value-problem', 'numerical-optimization', 'ordinary-differential-equations']"
4549597,"Find $\lim\limits_{n\to\infty}\left(\frac{(2n+1)!}{(n!)^2}\right)^2\int_0^1 \int_0^1 (xy(1-x)(1-y))^n f(x,y)dxdy$","Note: even though this is technically a duplicate of this post , I'd like further justification on what exactly the claim about ""convergence in distribution"" in @JackD'Aurizio's answer means, and, if possible, a proof as to why that claim holds. Let $f\colon [0,1]^2\to\mathbb{R}$ be a continuous function. Find $$\lim\limits_{n\to\infty} \left(\dfrac{(2n+1)!}{(n!)^2}\right)^2\int_0^1 \int_0^1 (xy(1-x)(1-y))^n f(x,y)\ \mathrm dx\mathrm dy.$$ I think it might be useful to first consider the case where $f$ is a polynomial. By the linearity of integrals, it suffices to consider the case where $f(x,y)=x^ky^l$ for all x,y. Also, Stirling's formula might be useful. There's probably a general formula for evaluating the double integral $I(n,k,l) := \int_0^1 \int_0^1 x^{n+k} y^{n+l} (1-x)^n (1-y)^n dxdy.$ It seems possible but tedious to evaluate the latter integral using the Binomial theorem. Alternatively it might be possible to use induction if one can guess the general formula for the integral. For instance in the specific case that $n=0,$ we have the integral $\int_0^1 \int_0^1 x^k y^l dxdy = \dfrac{1}{(k+1)(l+1)}$ . By the linearity of the integral we also have $I(n,k,l) = I(n-1,k+1,l+1) -I(n-1,k+2,l+1)-I(n-1,k+1,l+2)+I(n-1,k+2,l+2).$ Also a special case of the Stone-Weierstrass theorem says that every continuous function $f:[0,1]^2\to\mathbb{R}$ can be uniformly approximated by polynomials. But I'm not sure if one can reduce to the case of polynomials.","['integration', 'real-analysis', 'continuity', 'binomial-coefficients', 'limits']"
4549647,Description of the Functor of Points of Commutators of Algebraic Groups,"Let $k$ be a field and consider an algebraic group $G/k$ (i.e. an affine $k$ -group scheme of finite type).
Furthermore, suppose we are given two algebraic subgroups $H_1, H_2 \subseteq G$ .
Then the commutator group $[H_1, H_2]$ is defined to be the smallest algebraic subgroup $K \subseteq G$ such that $[H_1(R), H_2(R)] \subseteq K(R)$ for all $k$ -algebras $R$ (compare for example with J.S. Milne's book 'Algebraic Groups'). My question is now if this is the same thing as taking the commutator 'in the category of fppf-sheaves over $k$ '. More precisely: Given $g \in [H_1, H_2](R) \subseteq G(R)$ for some $k$ -algebra $R$ , does there always exist an fppf map of $k$ -algebras $R \to R'$ such that the image of $g$ in $G(R')$ is actually contained in $[H_1(R'), H_2(R')]$ ? Milne remarks in his book that this indeed holds true, but I don't see why. In their book 'Groupes Algebriques, Tome 1', Demazure and Gabriel show it when $H_1$ and $H_2$ are both smooth and one of them is connected (see II.5.4.9). There is also an article by Battiston (see https://arxiv.org/abs/1803.06965 ) that gives a similar result in a slightly orthogonal situation.","['group-theory', 'algebraic-geometry', 'algebraic-groups']"
4549656,Calculating expected value of choosing red ball from 5 bins of different sizes,"MY ATTEMPT AT SOLUTION: $P(win)=P(draw.at.least.3. red)=P(draw 3 R)+P(draw 4 R) + P(draw 5 R)$ Using the law of total probability: $=P(bin1)*P(draw.3|bin1)+P(bin2)*P(draw.3|bin2)+P(bin3)*P(draw.3|bin3)+P(bin4)*P(draw.3|bin4)+P(bin5)*P(draw.3|bin5)+P(bin1)*P(draw.4|bin1)+P(bin2)*P(draw.4|bin2)+P(bin3)*P(draw.4|bin3)+P(bin4)*P(draw.4|bin4)+P(bin5)*P(draw.4|bin5)+P(bin1)*P(draw.5|bin1)+P(bin2)*P(draw.5|bin2)+P(bin3)*P(draw.5|bin3)+P(bin4)*P(draw.5|bin4)+P(bin5)*P(draw.5|bin5)$ Factoring this all out I simplify to get: $P(bin1)*(P(draw.3|bin1)+P(draw.4|bin1)+P(draw.5|bin1))
+P(bin2)*(P(draw.3|bin2)+P(draw.4|bin2)+P(draw.5|bin2))
+P(bin3)*(P(draw.3|bin3)+P(draw.4|bin3)+P(draw.5|bin3)
+P(bin4)*(P(draw.3|bin4)+P(draw.4|bin4)+P(draw.5|bin4))
+P(bin5)*(P(draw.3|bin5)+P(draw.4|bin5)+P(draw.5|bin5))$ Since we are given the ratios of the sizes of the bins I tried to find the probability that way. So bin 5 is the smallest. $P(bin1)=5*P(bin5)$ $P(bin2)=4*P(bin5)$ $P(bin3)=3*P(bin5)$ $P(bin4)=2*P(bin5)$ $P(bin5)=1*P(bin5)$ since the probabilities of all the bins need to add to 1 we have $1=15*P(bin5) \implies P(bin5)=\frac{1}{15}$ Then I can calculate the remainder probabilities of bins. $P(bin1)=1/3$ $P(bin2)=4/15$ $P(bin3)=1/5$ $P(bin4)=2/15$ $P(bin5)=1/15$ Then calculating $P(draw.3|bin1)=\frac{{12\choose 3}{13\choose 2}}{{25 \choose 5}}$ So I did these calculations for the remainder probabilities and got something around 0.58. So the probability of winning 10 is 0.58 and the probability of losing $p$ is 0.42. So then I set $E[X]=0$ and solved for how much you would lose if playing the game. $10(0.58)+p(0.42)=0$ $p=-13.8$ This makes no sense. I'm losing more than I would win by playing the game? I have a feeling I did this question all wrong. Can someone please help me with the solution?",['probability']
4549661,Question about elementary set theory (related to database design theory),"Definition :
Let $U$ and $D$ be sets. For $X, Y \subseteq U$ and $I \subseteq D^U(:=\{f \mid \text{$f$ is a map from $U$ to $D$}\})$ , we define an 3-ary predicate $P(I, X, Y)$ as follows: $$ P(I, X, Y) \text{ if and only if for every $s, t \in I, s|_X = t|_X$ implies $s|_Y = t|_Y$}.$$ Futhermore, for a family $F := \{(X_\lambda, Y_\lambda)\}_{\lambda \in \Lambda}$ of pairs of subsets of $U$ , we define a predicate $I \vDash F$ as follows: $$ I \vDash F \text{ if and only if for every $(X, Y) \in F, P(I, X, Y)$}.$$ Question :
Let $U$ be a finite set, $D$ a set, $F :=\{(X_\lambda, Y_\lambda)\}_{\lambda \in \Lambda}$ a finite family of pairs of subsets of $U$ , and $a \in U \setminus \cup_{\lambda \in \Lambda} (X_\lambda \cup Y_\lambda)$ and suppose $K (\subseteq U)$ satisfies that for any finite subset $I$ of $D^U$ , $I \vDash F$ implies $P(I, K, U)$ . Then $a \in K$ ? Thank you in advance. To those who know database design theory :
This question can be explained in the language of database design theory as follows: $$ \text{
If $a$ is an attribute that does not occur in a set of functional dependencies $F$, does a  superkey $K$ always contain $a$?
}$$",['elementary-set-theory']
4549674,Finding area of rectangle with height 'x' enclosed within triangle of height 'h' and base 'b',A rectangle with a height x is drawn with its base lying on the base of the triangle. The triangle has an altitude with height h and the length of its base is b . How can I calculate the area of the enclosed rectangle in terms of these three variables?,"['rectangles', 'triangles', 'area', 'geometry']"
4549687,Green function of non self adjoint differential equation.,"How to find Green function of the ODE $$y’’-\frac{1}{x}y’=1, y(0)=0,y(1)=0$$ As given ODE is not Self Adjoint . Should I change it into self adjoint? Corresponding self adjoint equation is $$\frac{1}{x}y’’-\frac{1}{x^2}y’=\frac{1}{x}$$ Now boundary conditions will be same ? Or there is other way to find Green function  for this problem? Thank you.","['greens-function', 'ordinary-differential-equations']"
4549700,Does the zero locus of a real analytic function have a smooth point?,"Let $F \colon \mathbb{R}^m \to \mathbb{R}^n$ be a real analytic function (i.e., each of its component functions is real analytic).  Does the set $$Z = \{x \in \mathbb{R}^m : F(x) = 0\}$$ have a smooth point?  If not, what is an explicit example of such a set with no smooth points?  Assume $Z$ is not empty. By $x \in Z$ is a smooth point, I mean there is an open set $U \subset \mathbb{R}^m$ containing $x$ such that $Z \cap U$ is a smooth manifold. [Comments: I know this is true if $F$ is a polynomial map (and so $Z$ is an affine variety).]","['systems-of-equations', 'algebraic-geometry', 'analyticity', 'differential-geometry']"
4549707,Find an example where bounded difference inequality is useful,"Question: Is there an example, where the bounded difference property gives better concentration than what we get from using the sub-gaussian bound? I could not find any examples myself. But I believe there must exist some, otherwise I see no point in introducing the bounded difference concentration inequality. Definitions: Bounded difference property. We say that $f:\mathbb{R}^n\rightarrow\mathbb{R}$ satisfies the bounded difference property, if for all $k\in[n]$ there exists a $L_k\geq 0$ , such that for all $x\in\mathbb{R}^n$ and any $t\in\mathbb{R}$ it holds that $|f(x)-f(x+te_k)|\leq L_k$ .
Here, $e_k\in\mathbb{R}^n$ is the $k$ -th unit vector. One can show that $f$ satisfies the bounded difference property, if and only if $\|f\|_\infty<+\infty$ .
To be specific, if $f$ is bounded, using the triangular inequality, $$
|f(x)-f(x+te_k)|\leq 2\|f\|_\infty
$$ On the other hand, suppose that $f$ satisfies the bounded difference inequality.
Let $x^k:=(x_1,\ldots,x_k,0,\ldots,0)$ . Then: $$
|f(x)|= \left|f(0)+\sum_{k=1}^n f(x^k)-f(x^{k-1})\right |\leq |f(0)|+\sum_{k=1}^nL_k
$$ Since the choice of $0$ was arbitrary, we find: $$
\|f\|_\infty\leq \inf_{y\in\mathbb{R}} |f(y)|+\sum_{k=1}^nL_k
$$ The following is Corollary 2.21 in Wainwright's ""High-Dimensional Statistics"": Concentration from bounded difference property. Suppose that $f$ satisfies the bounded difference property, and that the random vector $X:=(X_1,\ldots,X_n)$ has independent components.
Then, for all $t>0$ , $$
\mathbb{P}\left[
|f(X)-\mathbb{E}[f(X)]|\geq t\right]
\leq 2\exp\left(-\frac{2t^2}{\sum_{k=1}^n L_k^2}\right).
$$ On the other hand, as we have shown above, any $f$ which satisfies the bounded difference property is also bounded.
Hence, we can directly use a sub-gaussian tail bound.
From (2.11) in Wainwright's ""High-Dimensional Statistics"", we get the following. Sub-gaussian concentration for bounded random variables. If there exist $a,b>0$ , such that $a<f(x)<b$ , then, for all $t>0$ : $$
\mathbb{P}\left[|f(X)-\mathbb{E}[f(X)]|\geq t\right]\leq 2\exp\left(-\frac{2t^2}{(b-a)^2}\right)
$$","['inequality', 'concentration-of-measure', 'probability-theory', 'probability']"
4549731,Doubt regarding notation of functions and relations,"In the notation $f : A \rightarrow B$ , $A$ is the domain of $f$ and $B$ is the codomain. What actually is the codomain? Defining it as the set into which all outputs of the function are constrained to doesn't seem very solid to me. Is it wrong to say that for the function $x \mapsto x+1, x \in \mathbb{Z}$ , one may say that the codomain is $\mathbb{R}$ or $\mathbb{Z}$ or any other superset of $\mathbb{Z}$ ? Let's say I define sets $A = \{1,2,3,4,5\}$ and $B =  \{2,4,6,8,10\} $ , and a relation, $R:A \to B$ (which means domain is $A$ and codomain is $B$ ), such that $R = \{(1,2),(2,4),(3,6),(4,8)\} $ . In this case, $R$ is a subset of $A \times B$ , and I've always thought that this means $R$ is a relation from A to $B$ . But if $A$ is the domain, then that means $A$ should be the set of all first elements of all ordered pairs in $R$ . But clearly in this case, the element $5$ is in $A$ but it is not the first element of any ordered pair in $R$ . So my question is, is it valid to say that $R$ is a relation from $A \to B$ , purely from the fact that $R \subset A \times B$ ? Does this not contradict the fact that the $R:A \to B$ notation says that $A$ is the domain ?",['functions']
4549741,Show that all the eigenvalues of a matrix but one (which is null) have negative real part,"I have a situation where a matrix $A=[a_{ij}]$ arises. From the physics of the problem, I expect this matrix to have one null eigenvalue, while the remaining eigenvalues have negative real part.
However I have not been able to prove the second part of the statement. I appreciate any help / hint /guidance on how to approach the problem. The off-diagonal elements are given by $$
a_{ij} =
\begin{cases}
n_{ji}, & \text{if } j<i \\
n_{ji}+1, & \text{if } j>i
\end{cases}
$$ Whereas the diagonal elements are given by $ a_{ii} = -\sum_{k \neq i =1}^N a_{ki} $ . It is clear that the row vector of all-ones $\mathbb 1_N$ is always a left eigenvector with null eigenvalue. Furthermore, the $n_{ij}$ are such that: $\bullet$ $ n_{ij}>0 $ $\bullet$ $ n_{ij} $ increase with $i: n_{ij} < n_{(i+1)j}$ $\bullet$ $ n_{ij} $ decrease with $j: n_{ij} > n_{i(j+1)}$ Case N=2 $$
\begin{bmatrix}
-n_{12} & 1+n_{12} \\
n_{12} & -1-n_{12} \\
\end{bmatrix}
$$ The eigenvalues are $0$ and $-1-2 n_{12}$ . Case N=3 $$
\begin{bmatrix}
-n_{12}-n_{13} & 1+n_{12} & 1+n_{13} \\
n_{12} & -1-n_{12}-n_{23} & 1+n_{23} \\
n_{13} & n_{23} & -2-n_{13}-n_{23} \\
\end{bmatrix}
$$ The non-zero eigenvalues are given by (after some messy computations, or after asking Wolfram Mathematica): $$
(-3 - 2 n_{12} - 2 n_{13} - 2 n_{23} \pm \sqrt{1 - 4 n_{12} + 4 n_{12}^2 - 4 n_{12} n_{13} + 4 n_{13}^2 + 4 n_{23} - 4 n_{12} n_{23} - 4 n_{13} n_{23} + 4 n_{23}^2})/2
$$ We can see that the real part must be negative by noting that $(3 + 2 n_{12} + 2 n_{13} + 2 n_{23})^2$ is strictly greater than $(1 - 4 n_{12} + 4 n_{12}^2 - 4 n_{12} n_{13} + 4 n_{13}^2 + 4 n_{23} - 4 n_{12} n_{23} - 4 n_{13} n_{23} + 4 n_{23}^2)$ . As $N$ increases, the eigenvalue computations becomes messier... Is there a simpler way to show that they will be negative?","['linear-algebra', 'control-theory', 'eigenvalues-eigenvectors']"
4549816,How do you calculate how long until a drug reaches its steady state?,"I encountered a mathematically intriguing conundrum, in that it's related to medicine but is centered around mathematics. Suppose drug A has a half-life in the body of 30 hours. The patient takes 40mg once per day. How long is it then until the patient then reaches steady-state dosage in the body (within some tolerance interval)? The answer should be about one week, but I'm trying to understand the math behind ""why"".","['algebra-precalculus', 'mathematical-biology', 'ordinary-differential-equations']"
4549837,How to describe or name this group?,"Consider the group $G$ defined as following: elements $(a,n)\in\mathbb{Z}/2\mathbb{Z}\times\mathbb{Z}$ and a commutative product is defined by $$(0,n)+(0,m)=(0,m+n)\\
(0,n)+(1,m)=(1,m+n)\\
(1,n)+(1,m)=(0,m+n+1)$$ This is an abelian group with zero element $(0,0)$ , and unique inverses given by $$-(0,m)=(0,-m)\\
-(1,m)=(1,-m-1)$$ How can I name or describe this group?",['group-theory']
4549838,"If a set is infinite, I will never run out of elements to choose from other than the ones already picked before","There is a small induction argument in the proof of the following Lemma: Essentially, we want to show that you never run out of elements to choose. My proof goes like this: For the base case it is sufficient to note that $X \setminus \{f(0)\} = \emptyset$ implies $X=\{f(x)\}$ . But then X would be finite, which is a contradiction. The induction step essentially comes down to the same thing, i.e. assume that $Y = X \setminus \{f(0),...,f(n)\} \neq \emptyset$ . Now if $X \setminus \{f(0),...,f(n),f(n+1)\} = \emptyset$ , then $Y = X \setminus \{f(0),...,f(n)\} = \{f(n+1)\}$ . But then $X = Y \cup \{f(n+1)\} = \{f(0),...,f(n),f(n+1)\}$ , i.e. X would be finite (contradictions). What makes me a bit uneasy is that I'm not really using the induction hypothesis. Is my proof fine like this? Thank you. Edit: Adding the definition of finite as requested:","['elementary-set-theory', 'induction', 'solution-verification']"
4549915,Continous functions on cofinite topology,"Let $X$ be the cofinite topology and let $f\colon X\to X$ a non-constant function. Show that $f\colon X\to X$ is continuous iff for every inifinite subset $A\subseteq X$ , $f(A)$ is infinite. I am lost with this problem and don't even know if it's true. For the implication from left to right, I supposed that $f(A)$ is finite, so there is a infinite subset of $A$ , $B$ , such that there are not elements in $X$ that their image lies in $B$ . But from here, how does the continuity help us? $A$ is not necessarily an open set, so don't know how to proceed.",['general-topology']
4549969,Non-negative integer matrix representations of finite groups,"I wanted to know all the non-negative integer matrix (NIM) irreducible representations (irrep) of finite groups i.e. the homomorphisms $\varphi : G \to GL(n,\mathbb{Z}_{\geq 0})$ . By irreducible NIM rep (or NIM irrep), I mean that we can't write it into a direct sum of smaller NIM reps. Edit: This proof shows that $GL(n,\mathbb{Z}_{\geq 0}) = S_n$ which simplifies things a lot. For context: I am a physics grad student and these representations are called NIM reps in the physics literature. These NIM reps are useful when we study the action of topological defect lines on boundary states of 2D CFTs. I state the things I am able to prove in chronological order: Every matrix $M \in GL(n,\mathbb{Z}_{\geq 0})$ such that $M^m = I$ for some $m\in\mathbb{Z}_{+}$ is a permutation matrix. ( Proof ) This implies that matrices in NIM reps of finite groups are permutation matrices. For the cyclic group of order prime $\mathbb{Z}_p$ , the only non-trivial NIM irrep is the regular representation of $\mathbb{Z}_p$ . (Here, irreducible = not a direct sum of smaller NIM reps) For a group $\mathbb{Z}_n$ , for every factor $k$ of $n$ , there is a NIM irrep of $\mathbb{Z}_n$ which is the regular representation of $\mathbb{Z}_k$ . Also, these are the only NIM irreps of $\mathbb{Z}_n$ . I would show my work, but it is too long to write here (there may be a shorter version out there) although the steps are elementary. If there is some obvious mistake in the three claims above, I  would be more than happy to correct myself. For non-abelian finite groups, I don't know how to proceed and how hard the problem is. My question: Is the classification of NIM irreps of abelian and non-abelian finite groups known already? Could you state the results if possible or could you refer me to some literature on this? Thanks.","['permutation-matrices', 'representation-theory', 'finite-groups', 'matrices', 'group-theory']"
4549977,Bayesian posterior probability and conditional probability,"This is a homework exercise but I am stuck, and I believe there is something basic that is still confusing me. This is the problem: There is a test for a new illness. The lab who developed did the following: To determine the false positive rate they tested 3000 known negative samples and got 15 positive results. To determine the false negative rate they tested 200 known positive samples and got 30 negative results. Then they tested 4000 people and got 60 positive results. Determine the posterior distribution on the true incidence, marginalizing over false positive and false negative rates. Assume flat priors on all parameters. My work From point (1) I can easily get a posterior distribution on the false positive rate, $p_{fp}$ : $$
f(p_{fp}|\text{data}) = \frac{P(\text{data}|p_{fp})}{\int_0^\infty P(\text{data}|p_{fp})}
$$ where $P(\text{data}|p_{fp})$ is just a binomial distribution with 15 successes, 3000 trials, and probability of success $p_{fp}$ . I can then do exactly the same and get a posterior distribution for the false negative rate. My problem is that I don't know how to move forward )use this information) to get the posterior on the true incidence. Is this what I am supposed to compute? $$
P(N \text{ positive}|\text{60 positive out of 4000}) = \frac{P(\text{outcome}|\text{incidence})}{\sum_{n=0}^{4000}P(\text{outcome}|\text{incidence})}
$$ If this is truly what I need to calculate, how do my posterior distributions on false-positive and false-negative used here? I think I am a bit confused on how to proceed, but hopefully I am not too lost.","['conditional-probability', 'statistics', 'bayesian', 'bayes-theorem']"
4550024,Peculiar pattern in the Collatz sequence,"I created a simple visualizer to better understand the Collatz sequence beginning at each natural number. The 'redder' a color is, the quicker the starting value reaches $1$ and the ""bluer"" the number, the longer it takes. I have also displayed the actual number on the square itself. The following image is mod $32$ . I am curious if anyone can explain the ""chunks"" of the exact same value. Clearly, some are $2$ -wide and some are $3$ -wide. I couldn't find anything at all online about this pattern. Here is the same image with starting values. It seems incredible that numbers directly next to each other (and thus vastly different paths) for some reason have the same step number to reach $1$ !","['collatz-conjecture', 'number-theory', 'visualization', 'pattern-recognition']"
4550067,Is analytic continuation the same as solving a PDE boundary problem with Cauchy Riemann,"I was considering the idea of analytic continuation: Let $ U \subseteq \mathbb{R}$ be a subinterval (perhaps all of R). Then suppose we have some smooth function defined $f: U \rightarrow \mathbb{R}$ and we want to ""analytically continue"" this function to the complex plane. We could look at the power series of the $f$ and set up sheafs and start expanding to find an analytic continuation OR... We could ask ""what is a holomorphic function equal to this function on the interval $U$ ?"" I.E. we want find $u(x,y), v(x,y)$ satisfying $$ \frac{ \partial u}{\partial x} = \frac{\partial v}{\partial y} \\ \frac{ \partial u}{\partial y} = - \frac{\partial v}{\partial x}  \\ u(x,0) = f(x), x \in U $$ Would there be a unique such $u,v$ pair? If there is such a unique pair would it then be THE ""analytic continuation"" of $f$ to the complex plane?","['divergent-series', 'analytic-continuation', 'complex-analysis', 'multivariable-calculus', 'partial-differential-equations']"
4550148,Evaluating $\lim_{x\to0}{{\left(\frac{\tan{(1+\tan x)}}{\tan{(1+\sin x)}}\right)}^{1/x^3}}$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question I am working on $$\lim_{x\to0}{{\left(\frac{\tan{(1+\tan x)}}{\tan{(1+\sin x)}}\right)}^{1/x^3}}$$ I can see a successful strategy is to take $\ln$ first and then use L'Hospital rule for 3 times. However, I wonder if there are simpler methods. Any ideas would be appreciated!","['limits', 'limits-without-lhopital', 'real-analysis']"
4550156,Hitting Time of Random Walk On A Free Group,"Consider a free group with generators $a$ and $b$ . A word comprises a product of symbols, where a symbol is one of $a$ , $b$ or their respective inverses, $a^{-1}$ and $b^{-1}$ . We denote $1$ as the empty word. A reduction operation $f$ removes sucessive instances of a symbol and its inverse from a word until no more remain, so $f(1a)=a$ and $f(bb^{-1})=1$ . Define $(X_n)$ as follows: Sample $\xi_n$ uniformly from $\{a,a^{-1},b,b^{-1}\}$ Set $X_n=f(X_{n-1},\xi_n)$ , i.e we multipltly $\xi_n$ on the right of $X_{n-1}$ and the perform reduction via $f$ . Let $g$ be the function counts the number of symbols in a word. $g(a,a,b)=3$ , but $g(1)=0$ , i.e. the empty word has $0$ length. Set $Y_n:=g(X_n)$ . Define $T:=\inf\{n\geq1:Y_n=5\}$ , the question is how to calculate $\mathbb{P}(X_T=a,a,a,b,b)$ starts form $X_0=1$ . In my opinion, this probability is equal to starts from $X_0=a,a,a,b,b$ then the empty words reoccurs. However, the length of $X_n$ should not exceed $5$ . So how can I take care of this boundary condition?","['stochastic-processes', 'probability-theory', 'random-walk']"
4550160,Proof of Global Rank theorem on Lee's Smooth manifolds,"There's a theorem named 'Global Rank theorem' in Lee's smooth manifold textbook which states that: Let $M$ and $N$ be smooth manifolds, and suppose $F:M\to N$ is a smooth map of constant rank. (1) If $F$ is surjective then it's a smooth submersion. (2) If $F$ is injective then it's a smooth immersion. (3) If $F$ is bijective then it's a diffeomorphism. The proof of (1) uses the Baire category theorem which is not quite intuitive to me. I wonder if this argument works: Since $F$ has a constant rank, say $r$ , if $p\in M$ then we can find a smooth chart $(U,\varphi)$ at $p$ and $(V,\psi)$ at $F(p)$ s.t. with respect to these coordinates, $F$ has a representation $\hat{F}(x_1,...,x_r,...,x_m)\to (x_1,...,x_r,0,...,0)$ where $m$ is the dimension of $M$ (and denote the dimension of $N$ by $n$ ). Since $\varphi,\psi$ are bijective, $\hat{F}$ should be surjective by assumption. Hence, $r = n$ .
Hence, taking the differentials to $\varphi,\psi,\hat{F}$ , we conclude $dF_p$ is surjective. A similar argument shows (2). Does it work? Proof given in Lee's textbook.","['solution-verification', 'smooth-manifolds', 'differential-geometry']"
4550197,Definition of meromorphic function on complex manifolds,"There are typically four(or more?) definition of meromorphic function on Riemann surface and three definitions of meromorphic function on complex manifolds, I want to show they are equivalent (I will not consider the additional one on Riemann surface as it's specified for that case): Definition 1 Define the sheaf of meromorphic function to be $$\mathcal{M}_X=\coprod_{x \in X} \mathcal{M}_{X, x}$$ with topology that open sets are union of $\{G_x/H_x\mid x\in V\}\subset \mathcal{M}_X$ with $V$ open and $G,H \in \mathcal{O}_X(V)$ . Meromorphic function is the section of the sheaf above. Definition 2 the sheaf of meromorphic function is sheafification of the following sheaf: Let $U$ be an open subset $U = \cup U_i$ for $U_i$ connected component then we have the presheaf $$U\mapsto \Pi_i \text{ Frac}(\mathcal{O}_X(U_i))$$ it's not hard to show the sheaf in definition 1is the Etale space assciated to this presheaf. Definition 3 Let $U \subset \mathbb{C}^n$ be open. A meromorphic function $f$ on $U$ is a function on the complement of a nowhere dense subset $S \subset U$ with the following property: There exist an open cover $U=\bigcup U_i$ and holomorphic functions $g_i, h_i: U_i \rightarrow \mathbb{C}$ with $\left.\left.h_i\right|_{U_i \backslash S} \cdot f\right|_{U_i \backslash S}=\left.g_i\right|_{U_i \backslash S}$ . I was trying to show that definition 3 are equivalent to 1 (and 2), however I don't have good idea. I see the point is the section of the sheaf, is a continuous map from $X\to \mathcal{M}_X$ , with the topology, contains all the $$[(U,G/H)]=\{G_x/H_x \mid x \in U\}$$ being open in the etale space topology. Therefore if $s:X\to \mathcal{M}_X$ such that $s_x = G_x / H_x$ then locally for where $G$ and $H$ are defined, $s_y = G_y/H_y$ for $y\in U$ (that's guaranteed by the continuity of the section). Therefore, locally the information of the section is equivalent to the information of pair $(G,H)$ , definition 3 use that locally information $(G_\alpha,H_\alpha)$ to define the section. And you see that $U_i$ in definition 3 are the sets of open subsets that the representative element $(G,H)$ are defined.","['complex-geometry', 'smooth-manifolds', 'complex-analysis', 'meromorphic-functions', 'differential-geometry']"
4550228,"Making an ODE exact, when formula's of exactness do not provide a solution","I have $$\left(2x+ 1-\frac{y^2}{x^2}\right)dx+ \frac{2y}{x}dy= 0$$ which is not exact.  However, it could be made exact by using the formula for integrating factors. I have two ways, With $$M=\left(2x+ 1-\frac{y^2}{x^2}\right)$$ and $$N=\frac{2y}{x}$$ we can form the following integrating factors: $$\phi(x)=\frac{N_x-M_y}{M}=-\frac{\frac{4y}{x^2}}{2x+1-\frac{y^2}{x^2}}$$ or $$\psi(x)=\frac{M_y-N_x}{N}=\frac{ (x^3 - x^2 + y^2)}{yx^2}$$ Then multiplying these in, should give an exact form of the ODE. But neither of the two make the ODE exact. Are there other formulas one can use? Thanks",['ordinary-differential-equations']
4550229,Are there any known NP-hard group theoretic problems?,"Are there any known NP-hard group theoretic problems which take as input finite groups given as Cayley tables (that is, not as a list of generators and product relations)? I'm talking about abstract groups, not permutation groups. It seems that all known group theoretic problems that are hard seem to be variations of the word problem (in which case, the group is infinite) or computing distances between a permutation and a subgroup of the symmetric group (see Buchheim, Cameron, Wu https://webspace.maths.qmul.ac.uk/p.j.cameron/preprints/sd.pdf ).","['group-theory', 'computational-complexity']"
4550281,R.S.A. Encryption: find $d$ if we know $n$ and $e$,"If an R.S.A. system has $n=55$ and the encryption key is 13 Do I choose $p$ and $q$ as 5 and 11
so $n = 5 \times 11$ and then $\varphi(n) = (5-1) \times (11-1) = 40$ Is this the correct start? Will that mean the public key is (13,77) and to find the decryption key $d$ I take the inverse of 13 in $\mathbb{Z}_{40}$ ?","['cryptography', 'number-theory', 'discrete-mathematics']"
4550284,"How to find a function that goes linear at the beginning, slows halfway in and then converges to 1?","I’m in C.S. and I need a function f(x) that calculates the value for brightness. Its values goes from 0 to 1, in the beginning it progresses linearly, then it starts slowing down halfway and keeps slowing down the closer it goes to 1. What is a function that looks similar to this?",['functions']
4550316,How to prove that the circle is not a function in the language of set theory,"Could you please explain to me why the circle defined by the equation $x^2+y^2=1$ is not considered a function by using the language of set theory ? And why should we want that one x defines exactly one y, what is the problem with the fact that one x defines multiples y ? The motivation is that a function is defined to be the set of ordered pairs so it seems to me that it is valid to have at the same time the pairs $(x=0;y=1)$ and $(x=0; y=-1)$ in the set which defines the function. And by accepting the fact that there can be several y corresponding to one x, we don't need to bother whether a ""function"" is really a function or not ? Thanks for your help!","['elementary-set-theory', 'functions']"
4550343,Coordinate-free definition of the symplectic form on the cotangent bundle,"Say we have a manifold $M$ with local coordinates $q_i$ . Then, $T^{\star}M$ has elements of the form $\sum_i p_i \mathrm{d}q_i$ , for $p_i \in \mathbb{R}$ ; so $T^{\star} M$ has local coordinates $(q_i, p_i)$ . Now, we define the $1$ -form $\lambda = \sum_i p_i \mathrm{d} q_i$ on $T^{\star} M$ (which means that $\lambda$ is a section of $T^{\star} T^{\star} M$ ), and $\mathrm{d}\lambda$ turns out to be symplectic.
Now, nlab contains a coordinate-free definition , stating that $\lambda$ as above, is determined uniquely by the fact that for every $1$ -form $\sigma$ on $X$ , we have: \begin{equation*}
\sigma^{*}\lambda = j\sigma
\end{equation*} Where $j$ is the natural isomorphism $j : \Gamma(T^{\star} M) \overset{\sim}{\longrightarrow} \Omega^1(M)$ (where $\Gamma$ denotes the space of sections, and $\Omega^1(M)$ the space of $1$ -forms on $M$ )). I am trying to start from the coordinate expression of $\lambda$ ; to show that this holds (or the other way around, really. I'm trying to understand why these two definitions are equivalent). My working: Take $\sigma$ an arbitrary $1$ -form on $M$ . So $\sigma : M \to T^{\star}M$ ; and hence induces $\sigma^{\star} : \Omega^1(T^\star M) \to \Omega^1(M)$ . Now, an element of $\Omega^1(T^\star M)$ is a section of $T^\star T^\star M$ , hence a map $\alpha : \big(T^\star M \ni y \mapsto (\alpha_y : T_y T^\star M \to \mathbb{R})\big)$ . The natural way of pulling it back through $\sigma$ , should give us something like: $\sigma^{*} \alpha : M \to T^\star M : x \mapsto \alpha\big(\sigma(x)\big)$ Now, this is where I am getting a bit lost; I think I am getting confused between the different cotangent bundles. Ultimately, I want to show that this pullback above coincides with $j\alpha$ iff $\alpha = \lambda$ ; but I'm unsure how to proceed. I am mostly confused as to what the isomorphism $j : \Gamma(T^\star M) \to \Omega^1(M)$ looks like. In my head, I have always identified $\Gamma(T^\star M)$ and $\Omega^1(M)$ as being the same space; so unless $j$ is the identity (lol), I'm not really sure what it represents. Are $\Gamma(T^\star M)$ and $\Omega^1(M)$ ""presented differently"", even though they correspond to the same concept, which is why we need $j$ to bridge the gap between them?","['differential-topology', 'symplectic-geometry', 'differential-geometry']"
4550359,Finding a relationship between coefficients to solve a cubic polynomial,"From E.J Barbeau's Polynomials, the question states: Find the relationship between $p$ and $q$ in order that the equation $x^3 + px + q$ may be put into the form $x^4 = (x^2 + ax + b)^2$ . Hence, solve the equation $8x^3 - 36x + 27 = 0$ . I have no clue where to start on this. Could anyone assist me with this problem? The answer ( $p^3 + 8q^2 = 0$ ) seems rather random and I don't understand how one could have obtained such a relationship.","['cubics', 'algebra-precalculus', 'polynomials']"
4550384,Limits of multivariable functions : How to find sequences that disprove their existence.,"I understand that to check whether a multivariable function $f$ has a limit or is continuous for some coordinates - let's call them $x$ - one must find that : $$\forall(x_n)_n \vert \lim_{n\rightarrow+\infty}{x_n}=x : \lim_{n\rightarrow+\infty}{f(x_n)=f(x)}$$ However, I must say I do not understand the process of finding such $(x_n)_n$ when disproving the existence of such a limit ; and our teacher has made no attempt to explain. When giving the solutions to such problems, he just pulls a solution out of his hat and explains why it works. Which in my opinion completely fails to address the actual problem, checking that a solution works is usually trivial . So how would you go about finding such a sequence ? In essence what I'm asking is not ""What is the solution to such a problem"" but ""What is the process by which a solution is produced"". There is perhaps a funny parallel to $P$ vs $nP$ where solutions to $nP$ problems are easy to check but hard to find. For those that would prefer a concrete example, here is one. Study the existence of the following limit : $$\lim_{(x,y)\rightarrow(0,0)\,,\,(x, y)\ne(0, 0)}\frac{x^2y}{x+y}$$ ( You should find that such a limit does not exist, however what I am interested in is how you will go about finding two sequences such that they converge to $(0,0)$ but make the function itself converge to two different values )","['limits', 'multivariable-calculus']"
4550426,Solve a non-exact ODE by a different method,"The following equation $$(x^3+2xy)dx-x^2dy=0$$ is not exact, since $$\frac{\partial M}{\partial y}=2x\ne\frac{\partial N}{\partial x}=-2x$$ I wanted to try the following then, $$-x^2dy=-(x^3+2xy)dx$$ $$\frac{dy}{dx}=\frac{x^3+2xy}{x^2}$$ $$dy=\frac{x^3+2xy}{x^2}dx$$ $$\int dy=\int xdx+ \int \frac{2y}{x}dx$$ But the last integral, according to what I suspect does not make any sense for finding a solution to the original problem. That would mean that the answer by this approach is: $$y=\frac{x^2}{2}+2y\ln x$$ However, this is not correct. Any ideas how to solve this? Thanks",['ordinary-differential-equations']
4550440,proper notation for derivatives and differential,"This is a simple question (perhaps pedantic) about basic differentiation in real coordinate space.  In practice, I don't ever have issues using or carrying out differentiation in $\mathbb{R}^m$ . But I'm pretty sure I frequently and severely abuse notation and I'm trying to improve. question 1: Let $f:\mathbb{R}^m \to \mathbb{R}^n$ be some smooth map between real coordinate spaces. It maps some point $x\in\mathbb{R}^m$ to $y\;\dot{=}\;f(x)\in\mathbb{R}^n$ .  What is the proper way to write the derivative of $f$ (Jacobian)? $$
 df \quad, \quad \frac{\partial f}{\partial x} \quad, \quad \frac{\partial f(x)}{\partial x}  \quad, \quad
 \frac{\partial y}{\partial x} \qquad ?
$$ does $\frac{\partial f}{\partial x}$ even mean anything or do we need to ""feed"" $f$ some input before we can differentiate as $\frac{\partial f(x)}{\partial x}$ ? In the last of the above, $y$ is just a point, $y=f(x)\in\mathbb{R}^n$ , not a function, that can be expressed in terms of $x$ . Can we differentiate a point as $ \frac{\partial y}{\partial x}$ or is this simply a common abuse of notation? question 2: continuing the above, what is the proper way to write the derivative of $f$ at a particular point, say $p\in\mathbb{R}^m$ ?  which of the following are correct, incorrect, or equivalent? $$
 df(p) \quad, \quad \frac{\partial f}{\partial x}\big|_p \quad, \quad \frac{\partial f(x)}{\partial x}\big|_p   \quad, \quad \frac{\partial f(p)}{\partial p} 
\qquad?   
$$ I have a hunch that the ""proper"" notation for the derivative of some $f:\mathbb{R}^m \to \mathbb{R}^n$ is just $df$ and this is defined such that, at any arbitrary point $x\in\mathbb{R}^m$ , it is given by $df(x)=\frac{\partial f(x)}{\partial x}$ .  Is this correct? context: I posed this question in the context of real coordinate space(s), but I'm asking it with differential geometry in mind. My background is not in math and I recently started teaching myself some differential geometry and quickly realized I don't have a great grasp of proper mathematical notation. edit: This question is related to one I asked on the physics page at this link","['partial-derivative', 'jacobian', 'derivatives', 'differential-geometry']"
4550451,Justifying definitions of a group action.,"Definition: Let $G$ be a group and $A$ a set. We say that $G$ acts on $A$ if there is a map $G\times A \rightarrow A$ denoted by $g \ast a$ satisfying $1 \ast a = a$ for all $a \in A$ and $g_1 \ast (g_2 \ast a) =(g_1g_2)\ast a$ for all $g_1,g_2 \in G$ and $a \in A$ . I've also seen that you can define a group action of $G$ on $A$ to be any homomorphism from $G \rightarrow S_{A}$ ; i.e a homomorphism from $G$ into the set of bijections of $A$ . We also know that for each $g$ in $G$ we can specify $\sigma(g):A \rightarrow A$ by $a \mapsto g \ast a$ , I wanted to understand why both definitions are the same, and I believe it follows from the following claim. Claim : Let $G$ act on $A$ . The map $\varphi:G \rightarrow S_A$ defined by $g \mapsto \sigma_g$ is a homomorphism. Conversely, given any homomorphism $\phi:G \rightarrow S_A$ , the map $G \times A \rightarrow A$ by $g \ast a = \phi(g)(a)$ is a group action. The proof is straightforward, Want to show that $\varphi:G \rightarrow S_A$ ; where recall $S_A$ is the set of all bijections of $A$ , defined by $g \mapsto \sigma_g$ is a homomorphism. Let $g_1,g_2 \in G$ , then for any $a \in A$ , \begin{align*}
		\varphi(g_1g_2)(a) & = \sigma_{g_1g_2}(a) \\
		& = (g_1g_2) \ast a \\
		& = g_1 \ast (g_2 \ast a) \\
		& = g_1 \ast (\sigma_{g_2}(a)) \\
		& = \sigma_{g_1}(\sigma_{g_2}(a)) \\
		& = (\sigma_{g_1} \circ \sigma_{g_2})(a) \\
		& = (\varphi(g_1) \circ \varphi(g_2))(a).
	\end{align*} Therefore the map $\varphi:G \rightarrow S_A$ by $g \mapsto \sigma_g$ is a homomorphism. Next let $\phi:G \rightarrow S_A$ be a homomorphism, we want to show that $g \ast a = \phi(g)(a)$ is an action of $G$ on $A$ . Because $\phi$ is a homomorphism we know that $\phi(1_G) = 1_{S_A}$ and so $1 \ast a = 1(a) = a$ , next let $g_1,g_2 \in G$ and \begin{align*}
		(g_1g_2)\ast a &= \varphi(g_1g_2)(a)\\
		&=(\varphi(g_1) \circ \varphi(g_2))(a) \\
		& = \varphi(g_1)(\varphi(g_2)(a)) \\
		& = g_1 \ast (\varphi(g_2)(a)) \\
		& = g_1 \ast(g_2 \ast a).
	\end{align*} So we conclude that any homomorphism from $G \rightarrow S_A$ gives rise to a valid action of $G$ on $A$ by $g \ast a = \varphi(g) (a)$ . So what is this really saying? I understand that if we have a homomorphism from $G$ into the symmetric group on $A$ we have a valid action, but don't we also need that any action is a homomorphism? I don't see why the map $\varphi:G \rightarrow S_A$ by $\varphi(g) = \sigma_g$ is the group action. I suppose my question is why is this claim enough to conclude that both definitions are equivalent. Thanks in advance for the clarification.","['group-actions', 'group-theory', 'abstract-algebra']"
4550484,prove that $|x^y - y^x| > 2$,"Prove that for any integers $x\neq y ,x,y>2, |x^y-y^x|>2$ . I know that the function $f(x) = \dfrac{\ln x}{x}$ is increasing for $x<e$ and decreasing for $x > e$ . So $|x^y-y^x| = x^y - y^x \ge 1$ if $x < y$ . I was thinking of proving something involving ratios (e.g. $f(x)/f(y)$ for $x < y$ ). I could possibly consider the case where x and y are consecutive and I could assume WLOG that $y>x$ so that it suffices to prove $x^y > y^x+2$ for $y>x>2.$ The inequality seems to be fairly weak; even for the smallest possible values of x and y, $y=4,x=3,$ we have $x^y = y^x+17.$ I think the sequence $\dfrac{x^{x+1}}{(x+1)^x} = x(1-\dfrac{1}{x+1})^x$ is an increasing function of x, and one could prove this using derivatives. Source: A PuMAC 2008 problem.","['contest-math', 'inequality', 'derivatives', 'real-analysis']"
4550525,"show there is no function $f:\mathbb{R}\to\mathbb{R}$ so that $f(0) > 0$ and $f(x+y)\ge f(x)+yf(f(x))\,\forall x,y\in\mathbb{R}$","Show there is no function $f:\mathbb{R}\to\mathbb{R}$ so that $f(0) > 0$ and $f(x+y)\ge f(x)+yf(f(x))\,\forall x,y\in\mathbb{R}.$ I think one can show that $f(f(z))$ is positive for some $z$ and that $f(x)\to\infty$ as $x\to \infty$ . Then one might be able to find some $a$ with $f(a) \ge a+1$ . To show $f(f(z))$ is positive for some z, suppose for all $z, f(f(z)) \leq 0.$ Then for all $y\le 0$ , $$f(x+y)\ge f(x) + yf(f(x)) \ge f(x)$$ implying that $f(x)$ is decreasing. If $f(f(x)) < 0$ for some $x$ , then $$f(x+y) \ge f(x) + yf(f(x))$$ for all $y\leq 0,$ so $f(z)$ tends to infinity as $z$ tends to $-\infty$ . Similarly, $f(z)$ tends to $-\infty$ as $z\to\infty.$ If $f(f(0)) = 0,$ then $f(y) \ge f(0) > 0$ for all $y.$ We know $f$ is decreasing so $f(y) \leq f(0)$ for $y\ge 0$ and hence for all $y\ge 0, f(y) = f(0).$ In particular, $f(f(0)) = f(0),$ so we get that for $y\in\mathbb{R}$ $$f(y) \ge f(0) + yf(0) = f(0)(1+y).$$ This contradicts the fact that $f(y) \leq f(0)$ for $y > 0$ . Hence we must have $f(f(0)) < 0$ by assumption. But I'm not sure how to continue from here.","['contest-math', 'functional-equations', 'calculus', 'limits', 'inequality']"
4550533,Proof: Non-negative integer matrix representations (NIM Rep) of a finite group are always permutation matrices.,"Let $G$ be a finite group. Definition: Non-negative integer matrix representation (NIM rep) of a finite group $G$ is a group homomorphism $\varphi : G \to GL(n,\mathbb{Z}_{\geq 0})$ . Prove that every matrix in the representation i.e. $\varphi(g)$ for every $g \in G$ is always a permutation matrix. Phrased another way: Let $M \in  GL(n,\mathbb{Z}_{\geq 0})$ . If $M^k = I$ for some $k \in \mathbb{Z}_{\geq 0}$ , then prove that $M$ is a permutation matrix. Edit: The answer by Qiaochu Yuan proves that $GL(n,\mathbb{Z}_{\geq 0}) = S_n$ which is even stronger than what is asked to be proven.","['matrices', 'representation-theory', 'finite-groups']"
4550554,Are trace of powers of linear combinations of self-adjoint matrices a complete invariant?,"Consider $A_1, \dots, A_N$ self-adjoint $d \times d$ matrices. I was wandering if the knowledge of the polynomials $$ P_k(x_1,\dots,x_N) = \mathrm{Tr} \left( (x_1A_1 + \dots + x_NA_N)^k \right) $$ for every integer $k \geq 1$ suffices to determine $(A_1,\dots,A_N)$ up to rotation. That is, if another $N$ -tuple of self-adjoint matrices $B_1,\dots,B_N$ gives the same sequence of polynomials $(P_k)_{k \geq 1}$ , does it follow that $B_i=UA_iU^{-1}$ for some orthogonal matrix $U$ ? This is easy for $N=1$ and I also checked it for $d=2$ .","['matrices', 'linear-algebra']"
4550622,"Is it possible to construct $GF(4)$ with two different multiplication operations mod n and mod m as ""addition"" and ""multiplication""?","I found that it's possible to construct multiplication and addition tables for $GF(2)$ and $GF(3)$ in that way, but I still can't find ones for $GF(4)$ . Is it possible at all? $GF(2)$ can be constructed with elements $\{21, 7\}$ and operations $* \bmod42$ and $* \bmod28$ $GF(2)$ multiplication: \begin{array}{c|cc}
\ * \bmod42 & 21 & 7  \\ 
\hline
21 & 21 & 21  \\ 
7 & 21 & 7  \\ 
\end{array} $GF(2)$ addition: \begin{array}{c|cc}
\ * \bmod28 & 21 & 7  \\ 
\hline
21 & 21 & 7  \\ 
7 & 7 & 21  \\ 
\end{array} $GF(3)$ can be constructed with elements $\{10, 16, 4\}$ and operations $* \bmod30$ and $* \bmod18$ $GF(3)$ multiplication: \begin{array}{c|ccc}
\ * \bmod30 & 10 & 16 & 4    \\ 
\hline
10 & 10 & 10 & 10   \\ 
16 & 10 & 16 & 4\\
4  & 10 & 4 & 16\\ 
\end{array} $GF(3)$ addition: \begin{array}{c|ccc}
\ * \bmod 18 & 10 & 16 & 4    \\ 
\hline
10 & 10 & 16 & 4   \\ 
16 & 16 & 4 & 10\\
4  & 4 & 10 & 16\\ 
\end{array} [Edit] Adding the following for clarity because users well versed in algebra can make mistakes here. Judging from the OP's examples and comments, mod should be the binary mod . In other words, $ab\bmod A$ is the remainder of the product $ab$ when divided by a positive integer $A$ . This translates to the usual congruence only when both moduli are larger than all the elements of the ""field"", JL [/Edit]","['finite-fields', 'abstract-algebra']"
4550638,show that n is a power of 2 given it satisfies a combinatorial property,"Let $\{a_1,\cdots, a_n\}$ and $\{b_1,\cdots, b_n\}$ be two distinct sets of positive integers such that any integer can be written as $a_i+a_j$ with $i\neq j$ in exactly as many ways as it can be written as $b_i+b_j$ with $i\neq j$ . Show that $n$ is a power of $2$ . It might be useful to use generating functions to count useful objects for this problem. Let $f(x) = \sum_{i} x^{a_i}, g(x) = \sum_{i} x^{b_i}.$ Note that $f(x)^2 - f(x^2) = g(x)^2-g(x^2).$ To show this, we have that $f(x)^2 = \sum_{i,j} x^{a_i + a_j}$ and $f(x^2) = \sum_{i} x^{2a_i}$ , so $f(x)^2 - f(x^2)$ has as the coefficient of $x^k$ the number of ways to write $k$ as $a_i+a_j$ with $i\neq j$ . Similarly, the coefficient of $x^k$ in $g(x)^2-g(x^2)$ counts the number of ways to write k as a sum $b_i+b_j$ where $i\neq j$ . Hence by the problem's assumption $f(x)^2 - f(x^2) = g(x)^2-g(x^2)\tag{1}$ We now need to conclude that $n$ is a power of 2 somehow. Suppose not, and write $n=2^k q$ for some odd $q>1.$ We need to derive a contradiction somehow (likely by showing that $(1)$ does not hold).","['contest-math', 'elementary-number-theory', 'combinatorics', 'polynomials', 'generating-functions']"
4550703,"given $xf''(x) + f'(x)+f(x)\leq 0\,\forall x > 0.$ Find $\lim\limits_{x\to\infty} f(x)$.","Let $f:\mathbb{R}^+\to\mathbb{R}^+$ be a twice-differentiable function so that $xf''(x) + f'(x)+f(x)\leq 0\,\forall x > 0.$ Find $\lim\limits_{x\to\infty} f(x)$ . It may be useful to consider a function $g(x)$ defined in terms of $f,f',$ and/or $f''$ . We have $(\dfrac{f'(x)}{f(x)})' = \dfrac{f''(x)f(x)-f'(x)^2}{f(x)^2}, (x\dfrac{f'(x)}{f(x)})' = \dfrac{f'(x)}{f(x)} +x\dfrac{f''(x)f(x)-f'(x)^2}{f(x)^2} = \dfrac{f'(x)f(x) + xf''(x)f(x)-f'(x)^2 x}{f(x)^2}.$ Adding 1 to the latter derivative gives $\dfrac{f(x)(xf''(x)+f'(x)+f(x)) - f'(x)^2 x}{f(x)^2}.$ The MVT or Taylor's theorem might be useful too. I was also thinking of finding specific functions that actually satisfy the inequality to have a better idea of what approach to use. Note that no linear polynomial or constant $f(x)$ satisfies the inequality in the question. If $f=ax^2 + bx+c$ then $xf''(x) + f'(x) + f(x) = x(2a) + 2ax+b + ax^2 + bx+c$ and so by the inequality we must have $a < 0.$ But this is impossible since $f(x)>0\,\forall x.$ Hence f cannot be a quadratic either.","['real-analysis', 'continuity', 'calculus', 'limits', 'derivatives']"
