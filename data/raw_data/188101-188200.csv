question_id,title,body,tags
3503550,"Prove or disprove: if A, B, and C are sets where A-C = B-C, then A = B.","This is my first disproof and I have a couple of questions. Can you just disprove with a counterexample? The question doesn't say ""for all"", does that mean I automatically imply that the claim is ""true"" for every set? If someone can critique my proof writing and see if there's a better way of writing this proof? My working: A = {0,1,2,3,4}
B = {0,1,2,3,4,5,6,7,8} A $\neq$ B C = {4,5,6,7,8} A-C = {0,1,2,3}
B-C = {0,1,2,3} A = B Proof: We will show that claim is false. By negating the initial claim, we can rewrite it as A-C = B-C ^ A $\neq$ B. Let us consider a set A = {x $\in \mathbb N$ | x $\le$ 5}, B = {x $\in \mathbb N$ | x $\le$ 8} and C = {x $\in \mathbb N$ | x $\ge$ 5 $\cap$ x $\le$ 8}. By performing A - C we result with a set where A-C={x $\in \mathbb N$ | x $\le$ 4}. Similarly consider the set B-C = {x $\in \mathbb N$ | x $\le$ 4}. This leads to the conclusion that the claim is false, since the we have proved the negation equivalent as true.","['solution-verification', 'discrete-mathematics']"
3503622,In which case these integrals are equal?,"Let $f\in C^1([0,\infty[$ such that $f(0)=0$ and $\forall x \in R^+_0$ , $0\le f'(x)\le1$ . Prove that $$\bigg(\int_0^x f(t) dt\bigg)^2\le\int_0^x f^3(t)dt$$ and find the cases that are equal. I already prove inequality but I can't find the cases for the equality.","['integration', 'integral-inequality', 'real-analysis']"
3503690,"Justify the term ""face lattice"": When is an abstract polytope an order-theoretic lattice?","The abstract combinatorial structure of a polytope is sometimes called its ""face lattice"". For example, see this or this . But this is not always a lattice . In a digon, the two edges are different upper bounds for the set of vertices, so there is no unique least upper bound. In a hemicube , a pair of vertices ( $a,b$ in the wiki image) has an edge ( $1$ ) and a face ( $III$ ) as two incomparable upper bounds. What conditions on the polytope are necessary or sufficient for it to be a lattice? For example, I suppose convexity is sufficient; and the ""atomistic"" property looks relevant.","['polyhedra', 'polytopes', 'geometry', 'order-theory', 'lattice-orders']"
3503692,How does one lift higher-order ODEs (and PDEs) on Manifolds?,"In a course on Manifolds its often emphasized that [integral curves of] vector fields are the right way to do ODE theory without coordinates.  I'd say that ODEs and vector fields are morally the same.  My understanding is that integral sub-manifolds of distributions are essentially first-order PDEs. But we also like to study ODEs and PDEs of arbitrary order.  Do these have their own place on a manifold?  There's a couple objects one could write down whose coordinate representations will involve higher derivatives, such as $\nabla_v\dot{x}$ , or $(\nabla_v)^n\dot{x}$ .  Probably if you write down the coordinate equation for an integral curves of a section in $TTTTTT\dots TM$ it will also involve higher derivatives. Nothing stands out as nearly so obvious as in the first-order case.","['manifolds', 'vector-fields', 'ordinary-differential-equations', 'partial-differential-equations']"
3503707,Components of shape operator in graph coordinates,"Suppose $M \subset \mathbb R^{n+1}$ is the graph of a function $f : U \to \mathbb R$ , for some open subset $U \subset \mathbb R^n$ . I'm trying to find the coefficients of the matrix of the shape operator $s : T_p M \to T_p M$ (for $p \in M$ ) in terms of graph coordinates. These are global coordinates of $M$ given by $\phi : M \to U$ , $\phi(u, f(u)) = u$ . What I've tried. Letting $(x^1, \ldots, x^{n+1})$ denote the usual Cartesian coordinates in $\mathbb R^{n+1}$ , the coordinate tangent vectors of $M$ in graph coordinates are related to the coordinate tangent vectors of $\mathbb R^{n+1}$ via $$
\frac{\partial}{\partial u^j} = \frac{\partial}{\partial x^j} + \frac{\partial f}{\partial x^j} \frac{\partial}{\partial x^{n+1}}
$$ (This can be seen by considering the map $\phi^{-1} : U \to M$ , $\phi^{-1}(u) = (u, f(u))$ and explicitly calculating $\frac{\partial\left(\phi^{-1}\right)^j}{\partial u^i} \frac{\partial}{\partial x^j}$ .) The upward unit normal field of $M$ is given by $$
N = \frac{\mathrm{grad} F}{|\mathrm{grad} F|},
$$ where $F : \mathbb R^{n+1} \to \mathbb R$ is the function $F(x,x^{n+1}) = x^{n+1} - f(x)$ (so $M$ is the level set of $F$ for $0$ ). Therefore, $$
N = \left(1+\sum_{i=1}^n \left(\frac{\partial f}{\partial x^i}\right)^2\right)^{-1/2}\left(-\sum_{i=1}^n \frac{\partial f}{\partial x^i}\frac{\partial}{\partial x^i} + \frac{\partial}{\partial x^{n+1}}\right) = -\sum_{i=1}^n \frac{\partial f/\partial x^i}{|\mathrm{grad} F|} \frac{\partial}{\partial x^i} + \frac 1{|\mathrm{grad} F|} \frac{\partial}{\partial x^{n+1}}
$$ In particular, if we denote $N = N^i \frac{\partial}{\partial x^i}$ , then $\frac{\partial}{\partial x^{n+1}} N^i \equiv 0$ for every $i$ , and thus $\overline\nabla_{\partial/\partial x^{n+1}} N = 0$ (where $\overline\nabla$ is the Levi-Civita connection of the Euclidean metric on $\mathbb R^{n+1}$ ). Meanwhile, by direct computation, for $1 \leq i, j \leq n$ , $$
\frac{\partial}{\partial x^j} N^i = -\frac 1{|\mathrm{grad} F|^3} \frac{\partial f}{\partial x^i}\sum_{k=1}^n \frac{\partial f}{\partial x^k} \frac{\partial^2f}{\partial x^k \partial x^j} + \frac{1}{|\mathrm{grad} F|} \frac{\partial^2 f}{\partial x^i \partial x^j}
$$ and $$
\frac{\partial}{\partial x^j} N^{n+1} = -\frac 1{|\mathrm{grad} F|^3}\sum_{i=1}^n\frac{\partial f}{\partial x^i}\frac{\partial^2 f}{\partial x^i \partial x^j}
$$ The Weingarten equation for hypersurfaces says $sX = -\overline\nabla_X N$ for $X \in \mathcal X(M)$ . So using what we just calculated, \begin{align}
s\frac{\partial}{\partial u^j} &= -\overline\nabla_{\partial/\partial x^j} N - \frac{\partial f}{\partial x^j} \overline\nabla_{\partial/\partial x^{n+1}} N = -\overline\nabla_{\partial/\partial x^j} N = -\sum_{i=1}^n \left(\frac{\partial}{\partial x^j} N^i\right) \frac{\partial}{\partial x^i}\\
&= \sum_{i=1}^n\left(\frac 1{|\mathrm{grad} F|^3} \frac{\partial f}{\partial x^i}\sum_{k=1}^n \frac{\partial f}{\partial x^k} \frac{\partial^2f}{\partial x^k \partial x^j} - \frac{1}{|\mathrm{grad} F|} \frac{\partial^2 f}{\partial x^i \partial x^j}\right)\frac{\partial}{\partial x^i} \\
&\qquad \qquad \qquad + \frac 1{|\mathrm{grad} F|^3} \sum_{i=1}^n \frac{\partial^2 f}{\partial x^i \partial x^j} \frac{\partial f}{\partial x^i} \frac{\partial}{\partial x^{n+1}} \\
&= \frac 1{|\mathrm{grad} F|^3} \sum_{i=1}^n \left[ \left(\frac{\partial f}{\partial x^i}\sum_{k=1}^n \frac{\partial f}{\partial x^k} \frac{\partial^2f}{\partial x^k \partial x^j} - |\mathrm{grad}F|^2 \frac{\partial^2 f}{\partial x^i \partial x^j}\right)\frac{\partial}{\partial x^i} +\frac{\partial^2 f}{\partial x^i \partial x^j} \frac{\partial f}{\partial x^i} \frac{\partial}{\partial x^{n+1}} \right]
\end{align} My problem: In principle, I should be able to now express $s\frac{\partial}{\partial u^i}$ in terms of the basis of coordinate vector fields given by $\frac{\partial}{\partial u^j} = \frac{\partial}{\partial x^j} + \frac{\partial f}{\partial x^j} \frac{\partial}{\partial x^{n+1}}$ . This will give me the coefficients for $s_{ij}$ I need. But it's not clear to me that I'm able to do that given what I just found. On the other hand, I'm reasonably sure that the expression I've found is orthogonal to $N$ , so it lies in the tangent space of $M$ at each point $p \in M$ . Am I going wrong somewhere? Is there a better way to find the coefficients of the shape operator? EDIT: I now see I was trying to plug a round peg into a square hole. My computations were correct, and agree with the answer below (though are written less elegantly). The coefficients in graph coordinates are $$
s_{ij} = \frac 1{|\mathrm{grad} F|^3} \frac{\partial f}{\partial x^i}\sum_{k=1}^n \frac{\partial f}{\partial x^k} \frac{\partial^2f}{\partial x^k \partial x^j} - \frac{1}{|\mathrm{grad} F|} \frac{\partial^2 f}{\partial x^i \partial x^j}
$$ since $\frac{\partial}{\partial u^j} = \frac{\partial}{\partial x^j} + \frac{\partial f}{\partial x^j} \frac{\partial}{\partial x^{n+1}}$ . In particular, comparing this coordinate expression to the $\frac{\partial}{\partial x^{n+1}}$ term above implies $$\sum_{i=1}^n s_{ij} \frac{\partial f}{\partial x^i} = \frac 1{|\mathrm{grad}F|^3} \sum_{k=1}^n \frac{\partial f}{\partial k} \frac{\partial^2 f}{\partial x^k \partial x^j}$$ although explicitly writing out why the above is true would be rather challenging.","['submanifold', 'riemannian-geometry', 'curvature', 'smooth-manifolds', 'differential-geometry']"
3503771,Why this special method introduce a nowhere vanishing form on $\mathbb{S^1}$?,"I'm studying ""An Introduction to Manifolds, Loring W. Tu"". In page 216 of it, Loring W. Tu introduces a method to find a nowhere vanishing form on $\mathbb{S}^1$ as follows: To find a nowhere-vanishing 1-form on $\mathbb{S}^1$ , we take the exterior derivative of both sides of the equation $$x^2 + y^2 = 1.$$ Using the antiderivation property of $d$ , we get $$2xdx+2ydy=0.(*)$$ Of course, this equation is valid only at a point $(x,y) \in \mathbb{S}^1.$ Let $U_x =\{(x,y)∈\mathbb{S}^1|x \not=0\}$ and $U_y =\{(x,y)∈\mathbb{S}^1 |y\not=0\}.$ By $(*)$ , on $U_x \bigcap U_y$ : $$\frac{dy}{x} = -\frac{dx}{y}$$ Define a 1-form $\omega$ on $\mathbb{S}^1$ by $$\omega =\begin{cases} 
       \frac{dy}{x}& on  \space U_x \\
      -\frac{dx}{y} &  on \space U_y\\
   \end{cases}
$$ I know this form is well defined and smooth, but I have two questions: $1$ -Why this method makes a ""nowhere vanishing form""? $2$ -Suppose $f:\mathbb{R}^3\rightarrow \mathbb{R}$ be smooth and $f^{-1}(0)$ is a regular level set.How can I generalize this method for manifold $f^{-1}(0)$ and find a nowhere-zero 2 form?","['differential-forms', 'smooth-manifolds', 'differential-geometry']"
3503797,Supremum of a set and equivalence class,"In my textbook we got the following question: Consider the order relationship ⊆ over P (A), with A = {1, 2, 3, 4,
  5}. What is the supremum of {{1}, {3, 4}}? My thought process is to find the supremum of each subset so the supremum of {1} and {3,4} which are (I think) 1 and 4. So my solution would be {1,4}. But this isn't the correct answer it seems. Another question I don't seem to understand is: Let S = {a, A, b, B, c, C} a collection of letters, and x ∼ y means
  that x and y are both vowels are or both consonants. Which of the
  following sets is an equivalence class for ∼?
  1. {a, A} 
  2. {a, b, c} 
  3. {a, A, b, B} 
  4. {b, B} I thought the equivalence class would always be given for a certain term, so for instance [A], but in this case they don't? Any help is appreciated.","['logic', 'discrete-mathematics']"
3503830,Showing Independence of $S^2$ and $\bar{X}$ if variance is unknown,"I have a question regarding the use of Basu's Lemma. Assume that $$X \sim N(\theta, \sigma^2).$$ In that case, we can use Basu's Lemma to show that $$\bar{X}$$ and $$S^2= \frac{1}{n-1}\sum(X_i-\bar{X})^2$$ are independent, if we show that $T:=\bar{X}$ is complete and sufficient (e.g. by the definition of exponential families) and that the distribution of $S^2$ does not depend on $\theta$ which is the case here. However, when $\sigma^2$ would be unknown as well, the distribution of $S^2$ would depend on $\theta$ . Can we still use Basu's Lemma somehow to show independence in that case ? I was confused by the following statement in the book Statistical Inference by Casella and Berger on p.289:","['independence', 'statistics', 'probability-distributions', 'normal-distribution']"
3503844,Derivative of matrix exponential of linear combination,"Let's say $t$ is a real parameter and $\textbf{A}$ is $n \times n$ matrix. I know that $$\frac{d}{dt} \exp(t\textbf{A}) = \textbf{A} \exp(t\textbf{A})$$ But what if there are multiple parameters $t_1, ..., t_n$ and multiple matrices $\textbf{A}_1, \dots , \textbf{A}_n$ that don't commute , does the same relation, namely $$\frac{\partial}{\partial t_k}\exp \left(\sum_{i=1}^n t_i \textbf{A}_i \right) = \textbf{A}_k \exp \left(\sum_{i=1}^n t_i \textbf{A}_i\right)$$ still hold? If not, is there a closed form for the derivative?","['matrices', 'matrix-calculus', 'derivatives', 'matrix-exponential']"
3503851,Construct probability measures to get the desired probability distributions of random variables.,"Here is a problem from an exam I just took several days ago. Let $(\Omega, \mathcal{F}, P)$ be a probability space. Let $X:\Omega\to\mathbb R$ be a random variable with $X>0$ a.s. and $EX=1$ . Define $$Q(A)=E[X1_A],\ \ \forall A\in\mathcal{F}.$$ Show that $Q$ is a probability measure on $(\Omega, \mathcal{F})$ and $Q\sim P$ , i.e. $Q<<P$ and $P<<Q$ . Suppose that $X\sim N(\mu,\sigma^2)$ under $P$ where $\mu\neq0$ , $\sigma>0$ and $\sigma\neq1$ . Try to construct a probability measure on $(\Omega, \mathcal{F})$ such that $X\sim N(0,1)$ under $Q$ . Suppose that $X\sim Poisson(\lambda)$ under $P$ where $\lambda>0$ and $\lambda\neq1$ . Try to construct a probability measure on $(\Omega, \mathcal{F})$ such that $X\sim Poisson(1)$ under $Q$ . The first part is standard and easy for me. But the next two parts stuck me. I have never met and thought those questions before. For the second part, if we introduce $Y=\frac{X-\mu}{\sigma}$ , then $Y\sim N(0,1)$ under $P$ , which is well-known. But how can I use this and the first part to construct such a probability measure $Q$ ? I cannot move on the third part, too. Any help would be appreciated.","['probability-distributions', 'probability-theory']"
3504005,"Let f(x) be a derivable function, $f'(x) > f(x)$ and $f(0) = 0$. What can be said about the sign of $f(x)?$","Let $f(x)$ be a derivable function, $f'(x) > f(x)$ and $f(0) = 0$ . Then (A) $f(x) > 0$ for all $x > 0$ (B) $f(x) < 0$ for all $x > 0$ (C) no sign of $f(x)$ can be ascertained (D) $f(x)$ is a constant function Since the mean value theorems are not applicable where do I start?
I tried this: $f'(x)>f(x)$ $=> f'(0)>f(0)$ $=> f'(0)>0$","['calculus', 'functions']"
3504028,Find the number of solutions of the equation $e^{4x}+e^{3x}-4e^{2x}+e^x+1=0$,"Based on pure intuition, the root is 0. It’s very obvious. But what is the proper way to solve it? Also how do we know it’s the only possible root (the answer is 1 root only, but how can I confirm?)",['functions']
3504033,Branch points of $f(z)= \frac{\sqrt{z} \log(z)}{(1+z)^2}$,How does one go about finding the branch points/holomorphic branches of a multi-function composed of several other multi-functions? Here is an example of what I mean: Let $f(z)= [\frac{\sqrt{z} \log(z)}{(1+z)^2}]$ be a multifunction. Identify the branch points and find a holomorphic branch. I have no idea how to approach this if $\sqrt{z}$ and $\log(z)$ are considered multi-functions themselves. Can someone help me out here? Thanks!,"['complex-analysis', 'branch-cuts', 'branch-points', 'complex-numbers']"
3504091,Inner product of Killing vector field and unit normal satisfies Jacobi equation,"Let $(M^{n+1},\bar{g})$ be a space form (i.e. a Riemannian manifold with constant sectional curvature, says $K\in\mathbb{R}$ ). Let $\Sigma$ be an orientable hypersurface in $M$ , with induced metric $g$ and unit normal vector field $\nu$ . Let $X$ be a Killing vector field on $M$ (i.e. $\mathcal{L}_X\bar{g}=0$ ). It is known that if $\Sigma$ has constant mean curvature, then the function \begin{align}
f:=\langle X,\nu\rangle
\end{align} (I will often use $\langle,\rangle$ to denote $\bar{g}$ ) satisfies the Jacobi equation : \begin{align}
\Delta_{\Sigma}f+\big(|A|^2+\overline{Ric}(\nu,\nu)\big)f=0
\end{align} where $\Delta_{\Sigma}$ is the Laplacian on $\Sigma$ in the induced metric, $A=(h_{ij})$ is the second fundamental form of $\Sigma$ , and $\overline{Ric}$ is the Ricci curvature of $(M,\bar{g})$ . This result seems to be quite standard. However I fail to find any reference that gives a proof on it, so I try to prove it by myself as an exercise. Fix a point $p\in\Sigma$ and choose a local orthonormal frame $\{e_i\}_{i=1}^n$ around $p$ such that \begin{align}
\nabla_{e_i}e_j\big|_p=0 & & (1)
\end{align} where $\nabla$ is the Levi-Civita connection of $(\Sigma,g)$ and I will denote $D$ the Levi-Civita connection of $(M,\bar{g})$ . Then we will have, at point $p$ , \begin{align}
\Delta_{\Sigma}f=\sum_{i=1}^n\langle D_{e_i}(D_{e_i}X),\nu\rangle
+2\sum_{i=1}^n\langle D_{e_i}X,D_{e_i}\nu\rangle
+\sum_{i=1}^n\langle X,D_{e_i}(D_{e_i}\nu)\rangle
\end{align} I can show that the 2nd term on R.H.S. vanishes and the 3rd term gives $\langle X,\nabla H\rangle-|A|^2\langle X,\nu\rangle$ , so that with $H\equiv const$ and rearrange the equation, we get that at $p$ , \begin{align}
\Delta_{\Sigma}f+|A|^2f=\sum_{i=1}^n\langle D_{e_i}(D_{e_i}X),\nu\rangle & & (2)
\end{align} Now I would like to know how to obtain $-\overline{Ric}(\nu,\nu)\langle X,\nu\rangle$ from the 1st term (the R.H.S. of (2)). Of course, since $(M,\bar{g})$ is a space form, this term is also equal to $-\overline{Ric}(X,\nu)$ . It would perhaps be too long to include my full computation here (surely, I am ready to provide them per request). In short, first using the Killing property of $X$ and (1), I am able to compute that at $p$ , \begin{align}
\sum_{i=1}^n\langle D_{e_i}(D_{e_i}X),\nu\rangle=-\sum_{i=1}^n\langle D^2_{e_i,\nu}X,e_i\rangle
\end{align} then we can use the definition of Riemann curvature tensor to yield an $\overline{Rm}$ -term, which then yields $\overline{Ric}(X,\nu)$ after taking trace. However, the other terms seems to give an extra term, so that in summary, I get \begin{align}
-\overline{Ric}(X,\nu)
+\sum_{i=1}^n\langle D_{[\nu,e_i]}X,e_i\rangle
\end{align} where $[,]$ is the Lie bracket on $(M,\bar{g})$ . I wonder how do we get rid of this extra last term. Any hint, comment and answer are welcomed and greatly appreciated. Any reference which contain a proof of it will also be great.","['curvature', 'riemannian-geometry', 'differential-geometry']"
3504118,Definition of Higgs bundle,"I currently try to deal with the definition of a Higgs bundle: The definition is: $(E, \varphi)$ is called a Higgs bundle, if $E$ is a holomorphic vector bundle and $\varphi$ is a holomorphic 1-form with values in $End(E)$ , s.t. $\varphi \wedge \varphi=0$ Now I am not sure what holomorphic 1-form with values in $End(E)$ . Is it a section of $T^{*}M \otimes End(E)$ ? Since the definition of a 1-form in general is that it is a section in $T^{*}M$ . Also, I am reading a paper where it says 'Because $\varphi$ takes values in the adjoint
representation, we can think of it locally as an $n \times n$ matrix of holomorphic one-forms –
which we can take to act on the fiber of $E$ .' I don't understand what 'takes values in the adjoint
representation' means here and how it is related to the above definition. Thanks in advance for any help!","['vector-bundles', 'holomorphic-bundles', 'differential-forms', 'differential-geometry']"
3504127,Showing a subgroup of $\mathbb{Z}\times\mathbb{Z}$ is cyclic.,"In the group $G = \mathbb{Z}\times\mathbb{Z}$ , consider the subgroup $H$ generated by $(-5,1)$ and $(1,-5)$ . I want to show that $G/H$ is cyclic and find the standard cyclic group it is isomorphic to. I haven't much group theory experience, but understand that $G$ is a group. Firstly what is meant by $H$ being generated by the mentioned elements of $G$ ? I know it's the intersection of all subgroups that contain those two particular elements, but can it be thought of as all the multiples and linear combinations of the two? And I am also confused about the rest of the question. Edit: I think confusion lies with the definition of 'generated by'. I understand its the intersection of all these subgroups that contain the set of elements (or generators) but is there a more useful equivalent definition.","['group-theory', 'cyclic-groups', 'abelian-groups', 'group-isomorphism']"
3504133,Positive functions which doesn't get multiplied too fast/doesn't grow too fast,"What could be some non-trivial examples of positive valued continuous functions $f: \mathbb{R_{+}}\to \mathbb{R_{+}}$ so that: $\forall x, y \in \mathbb{R_{+}}, x<y$ , $f(x) \geq \frac{1}{2}f(y)$ ? Of course, the constant and monotone non-increasing functions satisfy this property trivially. Also we note that locally ,  when $x, y$ are close enough, this property is valid, since for close enough $x,y$ , $f(x)$ is approximately equal to $f(y)$ , hence $f(x) \geq \frac{1}{2}f(y)$ . I'm looking for other examples, or rather a class of examples, or a way to construct the examples globally. See below. For a non-constant example, one can define: $f: (0,\frac{\mu}{\lambda})\to \mathbb{R_{+}}$ by: $f(x)= \lambda x + \mu$ , and this will satisfy the desired property. But $f$ won't satisfy the desired property when $x > \frac{\mu}{\lambda}$ , so the definition of $f$ needs to be modified on $[\frac{\mu}{\lambda}, \infty)$ .","['functions', 'real-analysis']"
3504203,"Given a number $N$, count all the ways to split $N$, so that each part is at most $K$.","I am trying to find an algorithm to do this, this is what I have so far: We know that the total number of ways to split a number $N$ is $2^{n-1}$ , where $n$ is the number of digits of that number $N$ . Knowing this, we can try to find all invalid ways of splitting the number and subtracting from the total, I did it by a recursive approach. It worked however is a bit slow. I am looking to solve this problem for really large numbers like $10^{100}$ without waiting an eternity. Example: For $N = 123, K = 8$ , we have four ways to split $123$ : $123, 1-23, 12-3, 1-2-3$ since $k = 8$ , only the last one is valid. Answer: 1","['combinatorics', 'discrete-mathematics']"
3504278,Functional derivative where the functional is not an integral,"Let $\phi(f)=F(f(x_1),f'(x_2),...,f^{(n)}(x_{n+1}))$ be a functional defined on $C^n([a,b])$ : here $F$ is a given (say) smooth function and $x_1,...,x_{n+1}$ are given points in $[a,b]$ . What is the functional derivative of $\phi$ ? I'm asking this question since usual texts about functional derivatives deals with functionals given as an integral.","['frechet-derivative', 'functional-analysis', 'analysis']"
3504294,Martingale convergnce theorem application,"I'm trying to solve the following exercise which requires the application of martingale convergence thm. Let $(M_n)_n$ be a martingale w.r.t $(F_n)_n$ and let $$C_n = M_n - M_{n-1}, \quad n \in \mathbb{N}$$ Prove that if $E[M_0^2] < \infty$ and $\sum_{n \in \mathbb{N}} E[C_n^2] < \infty$ , then there exists a r.v. $M$ such that $M_n \rightarrow M$ a.s. and in $L^2$ . What I need to do is to show that $\sup_{n \in \mathbb{N}}E[M_n^2] < \infty$ , in order to apply the theorem mentioned above. I've seen on the inernet that if $(M_n)_n$ is a square integrable martingale, then the increments $C_n$ are orthogonal in $L^2$ and I can write $$E[M_n^2] = E[M_0^2] + \sum_{k=1}^n  E[C_n^2] , \quad (\star)$$ . If I know this, of course I'm done since I can take the supremum both sides and use the convergence of the series and the finitess of $E[M_0^2]$ and I get the thesis. So, my questions are: Is my martingale square integrable? I can't show it. How the independence of the increments imply ( $\star$ ) ? Are there other ways to attack the problem?","['expected-value', 'stochastic-processes', 'martingales', 'convergence-divergence', 'probability-theory']"
3504299,Determine the probability that the group will score more than 80 points,"A group of $20$ students take the exam. The probability that the student will receive a grade of $2$ - $0.1$ , grade $3$ - $0.3$ , grade $4$ - $0.4$ , grade $5$ - $0.2$ . Determine the probability that the group will score more than $80$ points. Can you tell me in which direction I should think to solve the problem because I have no ideas yet. Thanks in advance!",['probability']
3504309,Convergence in distribution-topological interpretation,"There are various definitions of convergence of measurable functions: some of them have clear topological interpretation (as coming from suitable norm or metric-for example convergence in $L^p$ or convergence in probability) while some of them not (convergence almost surely does not come from any topology). I would like to understand the notion of convergence in distribution from the point of view of topology. Some properties which shows that one has to be careful are as follows: -one can have two different random variables $X,Y$ which have the same distributions: thus the sequence $X,Y,X,Y,X,Y,...$ would be convergent and have two limits $X,Y$ -this contradicts Hausdorff property (or even being $T_1$ ) -one can have even two different measure spaces $(\Omega_1,\mathcal{F}_1,P_1),(\Omega_2,\mathcal{F}_2,P_2)$ on which $X$ and $Y$ are defined and still they can have the same distribution. Therefore it is not clear on which space should those random variables act (should it be fixed or not?). So to summarize: Does convergence in distribution comes from some topology (Hausdorff topology?) and if the answer is ,,yes'' what is the underlying set on which this topology is defined?","['general-topology', 'probability-distributions', 'probability', 'random-variables']"
3504322,"Number of ways to form hexagons by joining vertices of a convex 20-gon, such that no side of a hexagon is common with a side of the polygon?","If hexagons are formed by joining the vertices of a 20 sided convex polygon such that no side of  hexagon is common with side of the polygon, then how many possible ways are there? I have no idea where to start. I actually have difficulties when I deal with geometric applications of permutations and combinations. My approach: Choose 1 point (20 ways), then leave two adjacent points and choose 1 out of the remaining 17 (17 ways) and so on. But I think I can't use the multiplication principle without double counting and even if I double count, I can't find the method to remove those cases.
Would someone please help me to solve this question?","['combinatorics', 'geometry']"
3504366,Can you help me with this question about permutation?,"Example: A garden has 4 types of flowers: roses, lilies, tulips and sunflowers. Flowers of the same type are considered identical. In how many ways can we make a bouquet of 10 flowers, if we must have at least 2 roses and 1 tulip? my answer: $$C(n+r-1,r)=C(4+7-1,7)=\frac{10!}{7!(10-7)!}=120$$ is it correct??",['discrete-mathematics']
3504478,A ring with $8$ elements,"Let $(A,+,\cdot)$ be a unitary ring with 8 elements. Prove that : $a)8=0$ and $k\neq 0$ , for any odd $k$ . b)If $\exists a\in A$ such that $a^3+a+1=0$ , then $a\neq 0$ , $a\neq 1$ , $2=0$ , $a^7=1$ and $A$ is a field. a) is pretty straightforward, it is obvious that $8=0$ from Lagrange's theorem in the additive group $(A,+)$ , and then if we had some odd $k$ such that $k=0$ then we would have that $1=0$ , which is a contradiction to $|A|=8$ . For b) the most difficult part is showing that $\operatorname{char}A=2$ . The fact that $a\neq 0$ and $a\neq 1$ is really trivial. Proving that $a^7=1$ is easy as well if we know that $2=0$ . From here we easily get that $A$ is a field and we are done. The only progress I made towards showing that $2=0$ was that $a$ is invertible(I guess it might help) because we have that $a(-a^2-1)=(-a^2-1)a=1$ . Obviously, we also have that $\operatorname{char}A\in \{2,4,8\}$ , but I didn't get any further.","['ring-theory', 'abstract-algebra']"
3504498,Joint distribution of random variable with an order statistic,"Let $X_1,...,X_n$ be i.i.d. with the distribution of the $X_i$ being nice and continuous.  I'm interested in the expression of the CDF $F_{X_{(1)},X_j}(u,v)$ . To be clear $X_{(1)} = min(X_i)$ and $X_j$ just one of the n i.i.d. random variables. I'm wondering if the following derivation is correct? $$F_{X_{(1)},X_j}(u,v) = P(X_{(1)}\leq u, X_j\leq v)$$ Partition the probability by whether or not $X_j$ is the minimum $$=P(X_{(1)}\leq u,X_j\leq v,X_{(1)}= X_j)+P(X_{(1)}\leq u,X_j\leq v,X_{(1)}\neq X_j)$$ The first probability reduces down as follows $$P(X_{(1)}\leq u,X_j\leq v,X_{(1)}= X_j)$$ $$=P(X_{(1)}\leq min(u,v), X_{(1)}= X_j)$$ The above is the probability that $X_j$ is minimum of the n i.i.d. random variables and it is less than both $u$ and $v$ . Since the distribution of the $X_i$ is continuous we can compute this directly as $$=\int_{-\infty}^{min(u,v)}{f_X(x)[1-F_X(x)]^{n-1}dx}$$ $$=\frac{1-[1-F_X(min(u,v))]^{n}}{n}$$ The last equality comes from integrating by substitution. Returning to the other probability we have $$P(X_{(1)}\leq u,X_j\leq v,X_{(1)}\neq X_j)$$ $$=P(X_{(1)}\leq min(u,v),X_j\leq v,X_{(1)}\neq X_j)$$ Since the $X_i$ are i.i.d., the above is equivalent to the probability that $$P(X_j\leq v, X'_{(1)}\leq min(u,v),X'_{(1)}\leq X_j )$$ where $X'_{(1)}$ is the minimum of the other $n-1$ random variables, so that $X_j$ and $X'_{(1)}$ are independent. The probability above can be written as $$\int_{-\infty}^{min(u,v)}{[F_X(v)-F_X(x)]f_{X'_{(1)}}(x)dx}$$ Using the fact that $f_{X'_{(1)}}(x)=(n-1)f_X(x)[1-F_X(x)]^{n-2}$ we have the the above probability can be computed as $$\int_{-\infty}^{min(u,v)}{[F_X(v)-F_X(x)](n-1)f_X(x)[1-F_X(x)]^{n-2}dx}$$ To compute the above integral, let $s=min(u,v), b=F_X(v),$ and use the substitution $y=1-F_X(x)$ so that the above integral becomes $$\int_{1}^{s}{-(n-1)(b-1+y)(y)^{n-2}dy}$$ $$=-(n-1)\int_{1}^{s}{[(b-1)y^{n-2}+y^{n-1}]dy}$$ $$=-(n-1)\int_{1}^{s}{[(b-1)y^{n-2}+y^{n-1}]dy}$$ $$=(n-1)\int_{1}^{s}{[(1-b)y^{n-2}-y^{n-1}]dy}$$ $$=(1-b)y^{n-1}-y^{n}\frac{(n-1)}{n}\Big|_1^s$$ $$=[1-F_X(v)]([1-F_X(s)]^{n-1}-1)+\frac{(n-1)}{n}(1-[1-F_X(s)]^{n})$$ So, both parts together give us $$=\frac{1-[1-F_X(s)]^{n}}{n}+[1-F_X(v)]([1-F_X(s)]^{n-1}-1)+\frac{(n-1)(1-[1-F_X(s)]^{n})}{n}$$ $$=[1-F_X(v)]([1-F_X(s)]^{n-1}-1)+(1-[1-F_X(s)]^{n})$$ and finally, with $s=min(u,v)$ : $$F_{X_{(1)},X_j}(u,v) = [1-F_X(v)]([1-F_X(s))]^{n-1}-1)+(1-[1-F_X(s)]^{n})$$",['probability']
3504534,Show $\mathbb Z[x]/(x^2-cx) \ncong \mathbb Z \times \mathbb Z$.,"For integers $c \ge 2$ , prove $\mathbb Z[x]/(x^2 - cx) \ncong \mathbb Z \times \mathbb Z$ . (Hint: for a ring $A$ , consider $A/pA$ for a suitable prime $p$ .) I'm not entirely sure what the hint means, and I don't really have an idea for an approach.  For context, this is part (c) of a question; part (a) was to show that $\mathbb Z[x]/(x^2) \ncong \mathbb Z \times \mathbb Z$ , and part (b) was to show $\mathbb Z[x]/(x^2 - x) \cong \mathbb Z \times \mathbb Z$ .  I was able to do both, though my approaches for those questions don't seem to apply for this one.  Any help is greatly appreciated.","['ring-theory', 'abstract-algebra', 'polynomial-rings', 'ideals']"
3504560,$S^2$ is not a countable union of embedded circles $S^1$,"I have two questions in point-set topology. How can I show that $S^2$ is not a countable union of embedded circles $S^1$ ? How can I show that if $m>n$ then every nonempty open set $U$ in $\Bbb R^m$ is cannot be contained in a union of finitely many hyperplanes in $\Bbb R^m$ of dimension at most $n$ ? I think I have to use some topological invariants, maybe homology, for example. Any hints? Thanks in advance.","['general-topology', 'homology-cohomology', 'algebraic-topology']"
3504581,Find $a_n:a_{n+1}$ if $a_n=\int_0^{\pi/2}\cos^nx.\cos nx.dx$,"Find $a_n:a_{n+1}$ if $a_n=\int_0^{\pi/2}\cos^nx.\cos nx.dx$ Attempt 1 \begin{align}
&a_{n+1}=\int_0^{\pi/2}\cos^{n+1}x.\cos(n+1)x.dx\\
&=\frac{\sin (n+1)x}{n+1}.\cos^{n+1}x-(n+1)\int\cos^{n}x.\frac{\sin (n+1)x}{(n+1)}.dx\\
&=\frac{\sin (n+1)x}{n+1}.\cos^{n+1}x-\int\cos^{n}x.{\sin (n+1)x}dx\\
&=\frac{\sin (n+1)x}{n+1}.\cos^{n+1}x-\bigg[\frac{-\cos(n+1)x}{n+1}.\cos^nx\\
&\quad\quad\quad\quad\quad\quad\quad\quad-n\int\cos^{n-1}x.\frac{-\cos(n+1)x}{n+1}.dx\bigg]\\
&=\frac{\sin (n+1)x}{n+1}.\cos^{n+1}x+\frac{\cos(n+1)x}{n+1}.\cos^nx\\
&\quad\quad\quad\quad\quad\quad\quad\quad+\frac{n}{n+1}\int\cos^{n-1}x.\big(\cos nx.\cos x-\sin nx\sin x\big)dx\\
&=\frac{\sin (n+1)x}{n+1}.\cos^{n+1}x+\frac{\cos(n+1)x}{n+1}.\cos^nx\\
&\quad\quad\quad\quad\quad\quad\quad\quad+\frac{n}{n+1}\bigg[\color{red}{\int\cos^nx\cos nxdx}+\int\cos^{n-1}x.\sin x.\sin nx.dx\bigg]\\
&=\frac{\sin (n+1)x}{n+1}.\cos^{n+1}x+\frac{\cos(n+1)x}{n+1}.\cos^nx\\
&\quad\quad\quad\quad\quad\quad\quad\quad+\frac{n}{n+1}\bigg[\color{red}{a_n}+\int\cos^{n-1}x.\sin x.\sin nx.dx\bigg]
\end{align} I don't think it is leading anywhere, is there any trickier way to see the solution ? Note: The solution given in my reference is $2:1$ and I understand that $$
\int_0^{\pi/2}\sin^nx.dx=\int_0^{\pi/2}\cos^nx.dx=\begin{cases}
\dfrac{(n-1)(n-3)....2}{n(n-2)....1}\quad\text{if $n$ is odd}\\
\dfrac{(n-1)(n-3)....1}{n(n-2)....2}\quad\text{if $n$ is even}
\end{cases}
$$ Thanks @Math1000, Attempt 2 \begin{align}
a_n &= \int_0^{\frac\pi2}\cos^n x\cos nx\ \mathsf dx = \frac{1}{2.2^n} \int_0^{\frac{\pi }{2}} \left(e^{i x}+e^{-i x}\right)^n \left(e^{i n x}+e^{-i n x}\right) \, dx\\
I_1&=\int_0^{\frac{\pi }{2}} \left(e^{i x}+e^{-i x}\right)^n e^{i n x}.dx\\
&=\bigg[(e^{i x}+e^{-i x})^n\frac{e^{inx}}{in}\bigg]_0^{\pi/2}-n\int(e^{i x}+e^{-i x})^{n-1}\frac{e^{i n x}}{in}.dx\\
&=\frac{1}{in}-n\int(e^{i x}+e^{-i x})^{n-1}\frac{e^{i n x}}{in}.dx\\
I_2&=\int_0^{\frac{\pi }{2}} \left(e^{i x}+e^{-i x}\right)^n e^{-i n x}.dx\\
&=\bigg[(e^{i x}+e^{-i x})^n\frac{e^{-inx}}{-in}\bigg]_0^{\pi/2}-n\int(e^{i x}+e^{-i x})^{n-1}\frac{e^{-i n x}}{-inx}.dx\\
&=\frac{-1}{in}+n\int(e^{i x}+e^{-i x})^{n-1}\frac{e^{-i n x}}{in}.dx\\
a_n&=\frac{i}{4}\bigg(\int_0^{\pi/2}(e^{i x}+e^{-i x})^{n-1}e^{i n x}.dx-\int_0^{\pi/2}(e^{i x}+e^{-i x})^{n-1}e^{-i n x}.dx\bigg)\\
&=\frac{i}{2^{n+1}}\int_0^{\pi/2}(e^{i x}+e^{-i x})^{n-1}\Big(e^{i n x}-e^{-i n x}\Big).dx
\end{align}","['integration', 'definite-integrals', 'sequences-and-series']"
3504604,How to apply squeeze theorem to this limit.,"I'm trying to solve $$\int_0^∞ e^{-x} \cos(x)\,dx$$ It is not hard to find that $$\int e^{-x} \cos(x)=\frac{1}{2}(e^{-x} \sin(x)-e^{-x} \cos(x))+C$$ From all this follows that $$\lim_{t\to\infty}\int_0^te^{-x} \cos(x) \, dx = \frac{1}{2}\lim_{t\to\infty}(e^{-t} \sin(t) - e^{-t} \cos(t))+\frac{1}{2}$$ Notice that I have simplified already a lot the expression we are taking the limit of. I have not been able to find this limit; a collegue student told me that I had to use the squeeze theorem, but I do not find how nor where. Any guides on how the theorem can help with this limit?","['integration', 'limits', 'definite-integrals', 'improper-integrals']"
3504608,Constructing analytic solutions to the delay differential equation $f'(x) = x f(x-1) - f(x)$,"While working on my answer to another question, I noticed that the function $$
f(x) = \int_0^\infty t^{x-t} dt
$$ satisfies the delay differential equation $$
f'(x) = x f(x-1) - f(x)
$$ for $x>0$ . To prove this, observe that $f'(x) = \int_0^\infty (\log t) t^{x-t} dt$ . The equation rearranges to give $0 = xf(x-1) - f(x) - f'(x) = \int_0^\infty t^{x-t}\left(\frac{x}{t} - 1 - \log t)\right)dt$ . This integrates to 0 because the integrand is $\frac{d}{dt} t^{x-t}$ . Is there a way that you could construct the function $f$ from this equation? What about other analytic solutions? In the case of ordinary differential equations, I know there are some tricks, and in general $f'(x) = g(x,f(x))$ has a 1-parameter solution space. For DDEs it's a lot more complicated. Typically you're given an initial condition and you solve by piecewise extensions. If you're interested in analytic solutions and you don't care about initial conditions, that's not much help though. My question is: can you construct an analytic solution to a delay differential equation? In this example, given the equation $f'(x) = x f(x-1) - f(x)$ , is there a way to arrive at an analytic solution that's not guess-and-check? Furthermore, it seems intuitive that if one analytic solution exists, there should be an infinite dimensional family of solutions (similar to how the family of solutions to the difference equation $f(x) = x f(x-1)$ is essentially parametrized by 1-periodic functions). For example, solutions to $f'(x) = f(x-1)$ have a Fourier series-like form $$f(x) = \sum_{\{c \space:\space c e^c = 1\}} a_c e^{c x}$$ For $f'(x) = xf(x-1) - f(x)$ , I have discovered one particular solution. How would you going about constructing other analytic solutions? Is there anything analogous to $e^{c x}$ for $f'(x) = f(x-1)$ ? Update (5/2/2020): As I suspected, there is an infinite dimensional space of solutions, which can be naturally parametrized by 1-periodic functions. Given any 1-periodic function $g$ , then $$
f_g(x) = \int_0^\infty t^{x-t} g(x-t) dt
$$ solves the same DDE. (This can be proven similarly to above). It's clear that $f_g$ is going to be analytic if $g$ is. I suppose showing only if wouldn't be difficult either. So that answers one part of the question. I'm still curious how one would arrive at this solution from the equation directly. It's easy to show this function solves the DDE, but how would one construct $f$ given $f'(x) = xf(x-1) - f(x)$ .","['integration', 'delay-differential-equations', 'real-analysis']"
3504612,Applications of the Mecke formula,"The Mecke formula as defined in the book Lectures on the Poisson Process (page 27) is: The text states (bottom of page 26) ""This equation is a fundamental tool for analysing the Poisson process and can be used in many specific calculations."" I can see that this is an interesting characterization of Poisson processes in the larger class of point processes, but I'm curious if the formula (4.2) has applications in problems of independent interest, say, in integral geometry or physics. Question. Should one think of this Mecke formula mostly as a tool to answer the question ""is some point process $\eta$ a Poisson process""? Or does it have ""computational value""? I.e. is it valuable in computations where one has a Poisson process $\eta$ and a map of interest $f$ ? If it has ""computational value"" then I'd like to know applications of this formula with ""(geometrically) meaningful"" maps $f$ where one side of the equation seems hard to compute and the other side is more tractable. The text provides a multivariate generalization of this formula (page 30) and I'd be happy with applications of that too.","['poisson-process', 'probability-theory', 'applications', 'reference-request']"
3504643,"Does this ""reverse distributivity"" ever occur: $a \circ (b\times c) = (a \times b) \circ (a \times c)$?","I was reading a book containing a typo to the effect that they defined the distributive property as: $$
a \circ (b\times c) = (a \times b) \circ (a \times c) \tag{*}\label{*}
$$ which is wrong of course. I will call the property (*) ""reverse distributivity"" for now. It got me wondering: Are there any examples of structures with this ""reverse distributivity""? What can we say about such a structure? And are there names for these things? Some findings so far: If we assume the existence of neutral elements, then things quickly degenerate. Assume that $(M, \circ, 1_\circ, \times, 1_\times)$ is an algebraic structure with two binary operators satisfying (*), and where $1_\circ$ and $1_\times$ are neutral elements. Then we have: $$
1_\circ  = (1_\circ \times 1_\times) \circ (1_\circ \times 1_\times)
\stackrel{\eqref{*}} = 1_\circ \circ (1_\times \times 1_\times)
= 1_\times
$$ so the identity elements are in fact equal. Let $1 := 1_\times = 1_\circ$ . Then, for any $a,b\in M$ : $$
a \times b = 1 \circ (a \times b) \stackrel{\eqref{*}} =
(1 \times a ) \circ (1 \times b) = a \circ b
$$ so in fact the two compositions are the same. In this case (*) becomes $$
a \circ (b\circ c) = (a \circ b) \circ (a \circ c)
$$ which seems to be known as self-distributivity and shows up in a number of places (e.g. group conjugation and logical implication). But if we want two (different) compositions that satisfy (*), then this shows that they at least cannot both have neutral elements. (If we only assume the existence of $1_\times$ , then we can show that $a \circ a = a \circ 1_\times$ for all $a$ ). I haven't gone much further than this.","['universal-algebra', 'abstract-algebra', 'axioms']"
3504653,Need help in proving an inclusion between some subspaces of operators,"Let $V$ be a closed subspace of $B(H,K)$ such that $xy^*z \in V$ for all $x,y,z \in V$ . Let $I$ be an ideal $(IV^*V+VV^*I \subset I)$ of $V$ . Let $C(I)$ denote the $C^{\ast}$ -algebra generated by $II^{\ast}$ . In a paper the following inclusion is stated without proof: $VI^{\ast} \subset C(I)$ I don’t see how this can be true, since $C(I)$ is generated by $II^{\ast}$ therefore how could $VI^*$ be included inside $C(I)$ ?","['c-star-algebras', 'operator-theory', 'functional-analysis']"
3504656,Probability of drawing a white ball given optimal distribution of balls [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Suppose you have 10 white balls, 10 black balls, and 2 baskets. You may place some of the balls into one basket and the remaining balls into the other basket however you wish. After you are done, your friend Janelle will flip a fair coin to select one of the baskets, then randomly select one ball from it. If you want to maximize the probability that Janelle will select a white ball, how should you distribute the 20 balls into the 2 baskets, and for that distribution, what is the probability that Janelle draws a white ball?",['probability']
3504666,"If $f$ is a polynomial in one variable with real coefficients which has all its roots real, then its derivative $f'$ has all its roots real","Is  the following statement  true/false ? If $f$ is  a polynomial in one variable  with real coefficients which  has  all its roots real, then  its derivative $f'$ has all its roots real as  well My attempt  : I think  this  statement is false. Take $f(x) =  \frac{1}{3} x^3 + x$ and now $f'(x) = x^2 + 1  $ , $x^2+ 1=0 $ implies $x= i,-i$ which does not belong to $\mathbb{R}$ ,   so given the above question statement is false Edits  :another  counter example $f(x) = x+1$ , but $f'(x) =1$ has  no root in $\mathbb{R}$ Is  its  true ?","['derivatives', 'polynomials', 'real-analysis']"
3504677,$\phi:\mathbb{R}^n\rightarrow\mathbb{R}$ with a given condition is measurable.,"$\phi:\mathbb{R}^n\rightarrow\mathbb{R}$ is continuous at all points in $\mathbb{R}^n-Y$ with $Y\subset\mathbb{R}^n$ of measure zero. Then $\phi$ is measurable. In the problem, the measure is the Lebesgue measure. Proof) Let $c\in\mathbb{R}$ . We prove $E:=\{x\in\mathbb{R}^n:\phi(x)>c\}=(E-Y)\cup(E\cap Y)$ is measurable. First, $(E\cap Y)\subset Y$ , so $m^*(E\cap Y)\leq m^*(Y)=0$ and $E\cap Y$ is measurable as it is measure zero. Next, for all $x\in E-Y$ , $\phi$ is continuous at $x$ , so $\exists\delta>0$ such that $B_{\delta}(x)\subset E$ . Then $E-Y=(\bigcup\limits_{x\in E-Y}B_{\delta}(x))-Y=(\bigcup\limits_{x_n\in E-Y}B_{\delta}(x_n))-Y$ . For the last equality, we used the Lindeloff covering theorem to take countable balls. Then $E-Y$ is measurable as open sets are measurable, the union of countably many open sets is measurable, $Y$ is measurbale and the difference bewteen measurable sets is measurable. I was wondering if this solutions is correct.","['measure-theory', 'solution-verification', 'measurable-functions', 'real-analysis']"
3504694,Linear operator continuous if and only if bounded; explanation of idea of proof,"Proposition. Let $E_{1}$ and $E_{2}$ be normed spaces and $A: E_1 \rightarrow E_2, x \mapsto Ax$ a linear operator. Then, $A$ is continuous if and only if A is bounded. I was able to follow the proof given by Kreyszig in his book Introductory Functional Analysis with Applications. I was able to prove this direction by myself bounded $\implies$ continuous. $A$ bounded $\iff$ $||Ax|| \leq ||A|| ||x||$ where $||A|| = sup \frac{|Ax|}{||x||}$ for $x \neq 0$ . My thoughts were $\forall \epsilon>0 \exists \delta >0 : ||x - x_0|| \implies ||Ax - Ax_0|| < \epsilon$ . So I have to find the $\delta$ . Thus I used $||Ax - Ax_0|| = ||A(x - x_0)|| \leq ||A|| ||x - x_0|| < ||A|| \delta$ . And now I recalled that I want to find the $\delta$ , so I looked what fits my needs and chose $\delta = \frac{\epsilon}{||A||}$ for $||A|| \neq 0$ . Choosing $\epsilon$ and $x_{0}$ arbitrary shows continuity for the case $||A|| \neq 0$ . Now, the case $||A|| = 0$ is trivial. The proof by Kreyszig starts with choosing the $||A|| \neq 0$ and the $\delta = \frac{\epsilon}{||A||}$ . Now, I understand that this is how we are taught to present proofs. But this does not seem like ""intuitive discovery"" for me. I.e. whenever I reconstruct this proof as a repetition exercise to prepare in case this question gets asked on the oral exam, I always start how I explained the proof above and not how Kreyszig starts. Now, for the continuous $\implies$ bounded. I tried doing this interplay of what is given and what has to be proved. But it got me only as far as unwrapping the definition of bounded and continuous. I know I have to find a $c$ such that $||Ax|| \leq c ||x||$ . I got stuck for some time here and then I looked at the book. The idea/trick was to define for any $y \neq 0$ $$x = x_0 + \frac{\delta}{||y||}y.$$ From here I was able to take over and finish the proof. But the choice of choosing the above as was chosen did not occur to me. How does one ""discover"" this choice that is needed for the proof? Is it intuition? To me this choice seems mysterious. If someone could explain it to me would be nice. My follow up questions are: Since I have an oral exam upcoming that includes proving the standard theorems of the material in functional analysis, how do I remember the proofs which I cannot discover by myself using this interplay of ""what is given and what is needed to be proven""? Do I simply rote memorize the key ""tricks"" and then rely that I can piece it together from there? Is this even an efficient method? Also what is the purpose of such examinations where one has to basically memorize a proof or some parts of it, then present them to the examinator, pass the course and never use the proof idea ever again?","['proof-explanation', 'operator-theory', 'proof-writing', 'solution-verification', 'functional-analysis']"
3504732,Volume of decreasing diameter,"A sphere's volume decreases at a rate of $1$ cm $^3$ /min. Find the instantaneous rate of which diameter decreases with respect to time when diameter is 10 units. First, I know radius is $d/2$ , so $v=\cfrac{\pi d^3}{6}$ . I also know that $\cfrac{dv}{dt}=-1$ . Finding the derivative of $v$ I get $$\cfrac{\pi d^2}{2}$$ And at this point is where I'm confused. The expressions here are all in terms of $d$ , but I'm taking the derivative with respect to $t$ (time) even though $t$ is nowhere to be found here, so it's throwing me off. I would prefer your solution to be written with Leibniz's notation.","['spheres', 'volume', 'calculus', 'related-rates', 'derivatives']"
3504759,Translating the following sentence to set theory.,"Question: Answer each of the following questions by writing an expression using set theory notation but without using plain English, without using set-builder notation, without introducing any new variables, and without using propositional or first-order logic. Let's say that a committee is a group of people, which we can think of as being represented by the set of people that comprise it. Let's have $S$ represent the set of all students at a school and let $F$ represent the set of all faculty at the school. Write an expression representing the set of all committees you can make from school students and faculty that contain one student and at least one faculty member. You can assume no one is both a student and a faculty member. My working: $\mathscr P (S \cup T) - $ ( $\mathscr P (S) \cup \mathscr P (T) $ ) Now i'm not sure if this is correct, as it took me quite some time to reach this conclusion. And if anyone has a different way of writing this please feel to write it down below as I've been looking for other ways to solve this.","['elementary-set-theory', 'discrete-mathematics']"
3504877,Find the maximum number of draws in a tournament.,"Consider a round robin tournament between 8 teams. A win gives 3 points, tie gives 1 point (to both teams) and loss gives 0 points. If the match between two teams, say A & B, is a tie, then A & B can't end up with the same number points after the tournament. The task is to find the maximum number of ties in the tournament. I have no idea other than bashing all the cases. Please help me how to do it?","['graph-theory', 'combinatorics']"
3504879,Prove $\sum_{n=0}^\infty(-1)^n(\overline{H}_n-\ln2)^3=-\frac5{16}\zeta(3)$,"How to prove that $$S=\sum_{n=0}^\infty(-1)^n(\overline{H}_n-\ln2)^3=-\frac5{16}\zeta(3)$$ where $\overline{H}_n=\sum_{k=1}^n\frac{(-1)^{k-1}}{k}$ is the alternating harmonic number. I came up with this problem after I solved a similar one here . I managed to prove the equality above but I am not happy with my solution as I used Mathematica for calculating the blue integral below, so any better ideas and without using softwares? Thank you, My solution: In page $105$ of this paper we have $$\overline{H}_n-\ln2=(-1)^{n-1}\int_0^1\frac{x^n}{1+x}dx$$ $$\Longrightarrow S=-\int_0^1\int_0^1\int_0^1\frac{1}{(1+x)(1+y)(1+z)}\sum_{n=0}^\infty(xyz)^n\ dx\ dy\ dz$$ $$=-\int_0^1\int_0^1\int_0^1\frac{dx\ dy\ dz}{(1+x)(1+y)(1+z)(1-xyz)}$$ $$=-\int_0^1\int_0^1\frac{dx\ dy}{(1+x)(1+y)}\left(\int_0^1\frac{dz}{(1+z)(1-xyz)}\right)$$ $$=-\int_0^1\int_0^1\frac{dx\ dy}{(1+x)(1+y)}\left(-\frac{\ln(1-xy)-\ln2}{1+xy}\right)$$ $$=\int_0^1\frac{dx}{1+x}\left(\int_0^1\frac{\ln(1-xy)-\ln2}{(1+y)(1+xy)}dy\right)$$ Mathematica gives $$\color{blue}{\int_0^1\frac{\ln(1-xy)-\ln2}{(1+y)(1+xy)}dy}$$ $$\small{=\frac{1}{x-1}\left[\frac{\pi^2}{12}+\frac12\ln^22-\ln(1-x)\ln\left(\frac{2x}{1+x}\right)+\operatorname{Li}_2\left(\frac{1}{1+x}\right)-\operatorname{Li}_2\left(\frac{1+x}{2}\right)-\operatorname{Li}_2\left(\frac{1-x}{1+x}\right)\right]}$$ giving us $$ S=-\int_0^1\frac{\frac{\pi^2}{12}+\frac12\ln^22-\ln(1-x)\ln\left(\frac{2x}{1+x}\right)+\operatorname{Li}_2\left(\frac{1}{1+x}\right)-\operatorname{Li}_2\left(\frac{1+x}{2}\right)-\operatorname{Li}_2\left(\frac{1-x}{1+x}\right)}{1-x^2}dx$$ By integration by parts and some simplifications, we get $$S=\underbrace{2\int_0^1\tanh^{-1}x\frac{\ln(1-x)-\ln2}{1+x}dx}_{\Large\mathcal{I}_1}-\underbrace{\int_0^1\frac{\tanh^{-1}x\ln(1-x)}{x}dx}_{\Large\mathcal{I}_2}$$ For $\mathcal{I}_1$ we know that $\tanh^{-1}x=-\frac12\ln\left(\frac{1-x}{1+x}\right)$ , so set $\frac{1-x}{1+x}=u$ $$\Longrightarrow \mathcal{I}_1=\int_0^1\ln u\frac{\ln(1+u)-\ln u}{1+u}du=\boxed{-\frac{13}{8}\zeta(3)}$$ For $\mathcal{I}_2$ use $\tanh^{-1}x=\sum_{n=0}^\infty\frac{x^{2n+1}}{2n+1}$ $$\Longrightarrow \mathcal{I}_2=\sum_{n=0}^\infty\frac1{2n+1}\int_0^1 x^{2n}\ln(1-x)\ dx=-\sum_{n=0}^\infty\frac{H_{2n+1}}{(2n+1)^2}$$ $$=-\sum_{n=0}^\infty\frac{H_{n+1}}{(n+1)^2}\left(\frac{1+(1)^n}{2}\right)=-\sum_{n=1}^\infty\frac{H_{n}}{n^2}\left(\frac{1-(1)^n}{2}\right)$$ $$=-\frac12\sum_{n=1}^\infty\frac{H_n}{n^2}+\frac12\sum_{n=1}^\infty\frac{(-1)^nH_n}{n^2}=\boxed{-\frac{21}{16}\zeta(3)}$$ where we used $\sum_{n=1}^\infty\frac{H_n}{n^2}=2\zeta(3)$ and $\sum_{n=1}^\infty\frac{(-1)^nH_n}{n^2}=-\frac58\zeta(3)$ Combine the boxed results, we get the claimed closed form of $S$ .","['integration', 'alternative-proof', 'harmonic-numbers', 'calculus', 'sequences-and-series']"
3504928,Shortcut for finding local extrema of a multivariable function,"I am trying to find the local extrema of this function: $f(x,y)=e^{\frac{1}{x^2 + 2 + \cos^2 y-2 \cos y}}$ I know what I am supposed to do (finding critical points and studying the Hessian). But, since the derivatives of this function are quite long, I was wondering if there might be a more efficient way to do it. I have thought that, since $g(t)=e^t $ strictly increasing and $h(t)=\frac{1}{t}$ is decreasing, I may just study the critical points of the function $l(x,y)=x^2 + 2 + \cos^2 y-2\cos y$ . However, I am not sure whether this would be correct, my main concern is with saddle points. It would be very helpful if anyone could tell me if that way of doing things is correct and, in case it is not correct, why so. Thanks","['maxima-minima', 'multivariable-calculus']"
3504955,Probability about combinatorics,"I came across these 2 problem about combinatorics which I originally thought they were basically the same. However, the solution key told me otherwise. Question 1 Question 2 My answer to Q1 is 0.18 which is correct, I then use the same way to solve Q2, where the solution is 0.2105. I wonder why there is such difference?","['permutations', 'combinatorics', 'probability-theory', 'probability']"
3505005,Does the cancellation property for a group mean something different than the cancellation property for an integral domain?,"I recently started learning about rings and some of their elementary characteristics / basic properties. One of the concepts that sort of caught me off guard was the statement that infinite ordered integral domains are not necessarily fields. I thought about it and saw that $\mathbb Z$ was a concrete example of this because other than the elements $1, -1$ , no other elements have multiplicative inverses. Integral domains are defined as: a commutative ring with unity having the cancellation property $\iff$ commutative ring with unity having no divisors of $0$ Fields are defined as: a commutative ring with unity in which every nonzero element is invertible From prior learning about groups, the proof that groups exhibit the cancellation product employed a strategy that invoked inverse elements. (i.e. $ax=bx \implies axx^{-1}=bxx^{-1} \implies a=b$ ) If a particular integral domain is not a field (and therefore exhibits the cancellation property but not all elements have multiplicative inverses), does that mean that the cancellation property of some integral domains is fundamentally different than the cancellation property of a group ? I ask this because the proof strategy for demonstrating that such an integral domain exhibits the cancellation property must be fundamentally different from the strategy that is used in the group-proof (because invertible elements are generally absent).","['ring-theory', 'group-theory', 'abstract-algebra', 'integral-domain']"
3505021,Matrix with even integers entries doesn't have odd eigenvalue,Let $A \in M_n(\mathbb{Z})$ with even entries. Prove that $A$ doesn't have odd eigenvalue.,"['integers', 'linear-algebra', 'eigenvalues-eigenvectors']"
3505074,Finding general term for a given sequence,"I am solving a combinatoric question in which I am getting this recurrence relation $$\color{red} {P(n) = 2P(n-1)+\sum_{k=3}^{n-2}P(k)P(n+1-k)}\ \ \ \ \ \ \ \ \ \  \forall n>3$$ $$P(3)=1$$ It is to be shown that the general term is $$P(n)=\dfrac{\binom{2n-3}{n-1}}{2n-3}\ \ \ \ \ \ \ \ \ \forall n\ge3$$ My attempts: I tried induction but the sum is creating problem. Also, the sum suggests using generating functions (because it is like the coefficient of $x^{n+1}$ when multiplying two polynomials) but I failed here also. Please help EDIT As suggested by S.Dolan in the answer, $P(n)=C_{n-2}$ . The post on Wikipedia about Catalan number aptly explains the proof by generating functions. So the question now reduces to How to prove the formula for Catalan numbers by using induction? Catalan numbers are defined using $C_0=1 $ and $$C_{n+1}=\sum_{r=0}^nC_iC_{n-i}$$","['recurrence-relations', 'combinatorics', 'discrete-mathematics', 'generating-functions', 'induction']"
3505125,Dimension of $l(nP)$ Riemann-Roch space,"Let $C$ be $$C=\{[X,Y,Z] \in \mathbb{P}^2_\mathbb{C} \mid X^4-Y^4+Z^4=0\}$$ and $p=[0,i,1]$ . Compute $l(np)$ for $n\geq0$ . My attempt: For $n\geq5$ we have $l(np)=n-2$ by the riemann roch theorem. Since the curve has degree 4 the tangent in $p$ , which is $4iY+4Z=0$ and has degree 1, intersects the curve in $4p$ . So we have that $4p$ is canonical and thus $l(4p)=3$ . This also gives us $l(0p)=1$ . I'm at a loss on how to proceed in the remaining cases. I've tried to find a base of $L(1p)$ , $L(2p)$ and $L(3p)$ by hand but it's proving to be a somewhat difficult process (and one that can't really be extended to other situations elegantly). Is there any general way to deal with these situations? I've tried looking up what's written in this answer but while I understood some of it I didn't actually manage to apply it to the problem in exam here.","['algebraic-curves', 'algebraic-geometry']"
3505184,"Find the values for which $A^2 = I_2$, A is a matrix, with $A \neq I_2$ and $A \neq -I_2$","First I tried to find $A^2$ with $$
    A=\begin{bmatrix}
    \alpha & \beta\\
    \delta & \gamma\\
    \end{bmatrix}
$$ I multiplied this by itself and got: $$
    \begin{bmatrix}
    \alpha^2+\beta\delta& \beta(\alpha + \gamma)\\
    \delta (\alpha + \gamma) & \delta\beta+\gamma^2\\
    \end{bmatrix}
$$ I put this in a system: $$
\left\{ 
\begin{array}{c}
\alpha^2+\beta\delta = 1 \\ 
\beta(\alpha + \gamma) = 0 \\ 
\delta (\alpha + \gamma) = 0  \\
\delta\beta+\gamma^2 = 1 \\
\end{array}
\right. 
$$ I tried to solve for $\beta$ first and right away got an issue: $$\beta = \frac{1-\alpha^2}{\delta}$$ One solution given by my book is: $$
    \begin{bmatrix}
    1& 0\\
    0 & -1\\
    \end{bmatrix}
$$ So $\delta$ can be zero but according to my system it can't. How is this possible?","['matrices', 'linear-algebra']"
3505234,black and white grid [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . The community reviewed whether to reopen this question 2 years ago and left it closed: Original close reason(s) were not resolved Improve this question Some squares of a $n \times n$ table ( $n>2$ ) are black, the rest are white. In every white square, we write the number of the black squares having at least one vertex with it. Find the max possible sum of these numbers. What I did until now was just trying for small n and did not catch anything generalizable.","['graph-theory', 'combinatorics', 'extremal-combinatorics']"
3505247,"Languages, students, interpretation of $AA^{\tau}\;\&\;A^{\tau}A$","Student $A$ speaks French & German, student $B$ speaks English, French
  & Italian, student $C$ speaks English, Italian & Spanish and student $D$ speaks all the languages mentioned except French. Write a matrix
  such that rows represent those $4$ students, while columns represent
  the languages they speak. If a person $i$ speaks a language $j$ , set $a_{ij}$ =1, otherwise set $a_{ij}=0$ . Interpret the meaning of the
  matrices $AA^{\tau}\;\&\;A^{\tau}A$ . My attempt: columns are: $E,F,G,I\;\&\;S$ One of my dilemmas is if the symmetry of $AA^{\tau}\;\&\;A^{\tau}A$ is relevant here and how to use what I've gotten: $$A=\begin{bmatrix}0&1&1&0&0\\1&1&0&1&0\\1&0&0&1&1\\1&0&1&1&1\end{bmatrix},A^{\tau}=\begin{bmatrix}0&1&1&1\\1&1&0&0\\1&0&0&1\\0&1&1&1\\0&0&1&1\end{bmatrix}$$ $$AA^{\tau}=\begin{bmatrix}2&1&0&1\\1&3&2&2\\0&2&3&3\\1&2&3&4\end{bmatrix},\;A^{\tau}A=\begin{bmatrix}3&1&1&3&2\\1&2&1&1&0\\1&1&2&1&1\\3&1&1&3&2\\2&0&1&2&2\end{bmatrix}$$ I've already read posts and articles on the topic of Gramian matrix , but we haven't covered it this semester yet. I translated this from Croatian word by word and thought the interpretation should be some kind of a relation or number of combinations I'm not able to see at the moment. I'm not sure if this task explicitly involves the $\text{Gramian matrix}$ .
How to interpret the given matrices in the context of students and languages they speak?","['matrices', 'linear-algebra']"
3505267,Is there any special names for the straight lines on a curved surface?,"I am not sure whatever I am talking even makes any sense. I am thinking of a straight line on a curved surface. Actually the term 'straight' here means the line should move in same direction along the surface of the body. For simplicity you can imagine of a long straight wire and you bend it around a solid body without bending       it laterally. The resulting line of wire is the one I am talking about. I have some questions about such line but at first I need to be sure that such a thing can be actually defined properly. My question is are such lines previously defined, if yes what are those lines called, if not can it be defined ? [It can also be thought as an extended geodesic since geodesic is just the shortest line segment between two points.But I think of an infinitely long(may be closed-loop) line not just a segment.]","['geometry', 'terminology', 'differential-geometry']"
3505294,Mathematical symbol to show one mathematical structure represents another,"Is there a particular symbol that can be used to show that one mathematical structure is a representation of another? For example, I want to state that the relation $R$ is represented by the connection matrix $M_{R}$ . Is there a symbol I can use to communicate this in a concise manner? For instance, if the symbol were #, then I would say $R$ # $M_{R}$ . Or does it simply suffice to say $R = M_{R}$ or $R \Leftrightarrow M_{R}$ , although I don't think these statements are completely accurate.","['notation', 'discrete-mathematics']"
3505396,Complete Sufficient Statistic for double parameter exponential,"I am trying to show that $(X_{(1)}, \sum_{i=1}^{n}(X_i-X_{(1)})$ are joint complete sufficient for $(a,b)$ where $\{X_i\}_{i}^{n}\sim exp(a,b)$ . I know the joint pdf is $$\prod_{i=1}^{n}\frac{1}{b}e^{(X_i-a)}\chi_{>a}(x_i)=\frac{1}{b}^{n}e^{\sum_{i=1}^{n}(X_i-a)}\chi_{>a}(x_{(1)})$$ By adding a zero in the form of $nX_{(1)}-nX_{(1)}$ the above can be rearranged to: $$e^{-\sum_{i=1}^{n}(X_i-X_{(1)})+nX_{(1)}+na-nlog(b)}\chi_{>a}(x_{(1)})$$ I know since $T(X)=((X_{(1)}, \sum_{i=1}^{n}(X_i-X_{(1)}))$ then it is a complete sufficient statistic but I am having trouble in getting rid of $\chi_{>a}(x_{(1)})$ to get it into proper exponential family form i.e $h(x)=\chi_{>a}(x_{(1)})$ only dependent on the data. Any help?","['statistical-inference', 'statistics', 'exponential-distribution', 'sufficient-statistics']"
3505487,"$\{\emptyset\} \cup \{a, b\} = \{a, b\}$ is this true?","I am really confused about the empty set. Does any set contain the empty set in general? Is $\{\emptyset\} \cup \{a, b\} = \{\emptyset, a, b\}$ ? if so then it is not equal to $\{a, b\}$ ? then the statement is false?",['elementary-set-theory']
3505612,Solve $y' + y^2 = \frac{1}{x^2}$ by introducing $z = xy$ as a new function.,"Question: Solve the equation: $$y' + y^2 = \frac{1}{x^2},~~~~~~~~~x > 0$$ by introducing $z = xy$ Attempted answer: $z = xy \Rightarrow y = \frac{z}{x}$ Taking the derivative of $y$ with respect to $x$ using he product rule: $$y' = \frac{z'}{x} - \frac{z}{x}$$ Adding this into the original equation: $$\frac{z'}{x} - \frac{z}{x^2} + \frac{z^2}{x^2} = \frac{1}{x^2}$$ Putting $z$ and $x$ on each side: $$\frac{z'}{1-z^2 + z} = \frac{1}{x}$$ Integrating on each side: $$\int \frac{1}{1-z^2 + z}dz = \int \frac{1}{x} dx$$ This produces $$z(x) = \frac{(1+\sqrt{5})c_1x^{\sqrt{5}}+1-\sqrt{5}}{(2c_1 x^{\sqrt{5}}+2)}$$ Substituting back to $y$ : $$y(x) = \frac{(1+\sqrt{5})c_1x^{\sqrt{5}}+1-\sqrt{5}}{x(2c_1 x^{\sqrt{5}}+2)}$$ This seems all and well, but the expected answer contains yet another solution: $$y = \frac{1\pm\sqrt{5}}{2x}$$ How does this second solution arise? Since there is an $x^2$ in the question, I think that a solution might have been dropped at some point.","['calculus', 'ordinary-differential-equations']"
3505655,Inverse Laplace Transform of $\frac{1}{s+1}$ using Mellin's Inverse Formula,"I am trying to compute the inverse Laplace Transform of $F(s)=\frac{1}{s+1}.$ I know that it is supposed to be $f(t)=e^{-t}$ , but I am specifically trying to get that result using Mellin's Inverse Formula, according to which: $$f(t)=\mathcal{L}^{-1}[F(s)](t)=\frac{1}{2\pi i}\int_{\sigma-i\infty}^{\sigma+i\infty}\frac{e^{st}}{s+1}\ ds$$ According to the formula, I need to choose $\sigma>-1$ (since $s_0=-1$ is the singularity of $F(s)$ and $\Re{\{s_0\}=-1}$ ) and to integrate on the line $\Re{\{s\}}=\sigma$ . I chose $\sigma=0$ , thus a proper parametrization would be $s=ix$ when $x\in\mathbb{R}$ : $$f(t)=\frac{1}{2\pi}\int_{-\infty}^{\infty}\frac{e^{ixt}}{1+ix}\ dx$$ (I also checked that $F(s)$ is bounded on the line, and it is indeed).
I have no idea how to compute this integral. If I were to use the Residue Theorem, I would have ended up with a complex integral again. Another problem that I have: It doesn't even seem like the integral is convergent. Plugging $t=0$ , the result of the integral should be $1$ , but the integral I got doesn't seem convergent at all: $$f(0)=\frac{1}{2\pi}\int_{-\infty}^{\infty}\frac{1}{1+ix}\ dx=\frac{1}{2\pi}\int_{-\infty}^{\infty}\frac{1-ix}{1+x^2}\ dx=\frac{1}{2\pi}\left[\left.\arctan(x)\right|_{-\infty}^{\infty}-\frac{i}{2}\left.\ln(1+x^2)\right|_{-\infty}^{\infty}\right]$$ The integral does not converge because of the imaginary part (the logarithm). But, even if for some reason I should take only the real part, it wouldn't correlate with the desired answer, since I would get $\frac 12$ instead of $1$ . I must be missing something here.","['integration', 'definite-integrals', 'laplace-transform', 'complex-analysis', 'integral-transforms']"
3505691,Number of solutions via generating function,How to find generating function for number of solutions $x_1+x_2+x_3=n$ in set of positive integers such that $x_1 \ge x_2 \ge x_3$ and $x_1<x_2+x_3$ .,"['integer-partitions', 'discrete-mathematics', 'generating-functions']"
3505715,What do the derivative and integral notations mean?,"I have only recently began studying calculus at school, so a non-technical answer would be greatly appreciated. While I understand the techniques for differentiation and integration, I still feel as if I don't understand why they work. Part of this bewilderment stems from the notation (and the language used to describe the notation). For example, $$
\frac{dy}{dx}(x^2+5)=2x
$$ I have heard spoken aloud as ""the rate of change of y of $x^2+5$ with respect to $x$ is $2x$ "". I am not completely clear on what ""with respect to $x$ "" means, but I think it means that the derivative is telling you what the rate of change for each value of $x$ is. For example, when $x=5$ , the gradient is $10$ . If, however, you were looking at the derivative with respect to $y$ , then the gradient function would tell you what the gradient is for each $y$ -value. From what I understand, $\frac{dy}{dx}$ is also just a  shorthand for a more formal limit expression rather than a ratio: $$
\frac{dy}{dx}(f(x))=\lim\limits_{h\to0}\frac{f(x+h)-f(x)}{h}
$$ However, while the notation for differentiation is somewhat intuitive, I still find the integral notation baffling: $$
\int f(x)dx=2x
$$ Why is there no "" $dy$ "" in this notation, but there is one in the derivative notation? When the "" $dx$ "" is adjacent to the gradient function, what does it stand for? And what does the integral sign actually mean? I feel completely stuck, so it would be helpful if someone could walk me through the notation step-by-step.","['integration', 'notation', 'calculus', 'indefinite-integrals', 'derivatives']"
3505739,J-invariant and isomorphism of elliptic curves over $\mathbb{Q}$,"If two elliptic curves share the same j-invariant then they may not be isomorphic to each other over $\mathbb{Q}$ . Example: $E_1: y^2 = x^3 + x$ j-inavriat: $1728$ Torsion points: $[(0 : 0 : 1), (0 : 1 : 0)]$ Rank $0$ . $ $ $E_2: y^2 = x^3 + 3 x$ j-inavriat: $1728$ Torsion points: $[(0 : 0 : 1), (0 : 1 : 0)]$ Rank $1$ - generator point $[(1 : 2 : 1)]$ Is there some other invariant or can we define a new type of invariant that if two elliptic curves share the same such invariant then they are isomorphic over $\mathbb{Q}$ ? (they can be birationally transformed to each other over $\mathbb{Q}$ )","['number-theory', 'elliptic-curves']"
3505781,Finding extreme points of closure of convex hull,"Let H be a infinite dimensional Hilbert space with orthonormal basis $(e_n)_{n\geq 1}$ . Let $f_N=N^{-\frac{1}{2}}\sum_{n=1}^Ne_n$ for all $N\geq 1$ and let K be the norm closure of the convex hull of $\{f_N : N\geq 1\}$ . I need to show that the extreme points of K are $\{0\} \cup \{f_N:N\geq 1\}$ . I have already shown that the $f_N$ 's are extreme points, but I do not know how to show that 0 is an extreme point. I also can't figure out how to show that these are the only extreme points. I have shown that K is weakly compact, so following the converse to Krein-Milman i know that $\text{Ext}(K)\subset \overline{\{f_N:N\geq 1\}}^\tau$ , where $\tau$ is the weak topology. But I do not know how to show that $\overline{\{f_N:N\geq 1\}}^\tau\subset \{0\} \cup \{f_N:N\geq 1\}$ . One way could be to consider all possible nets in $\{f_N:N\geq 1\}$ , but this has not yet proven fruitful. Any help is much appreciated","['convex-hulls', 'hilbert-spaces', 'weak-topology', 'functional-analysis', 'convex-analysis']"
3505790,Trying to prove a subset is ideal of a $C^{\ast}$-algebra.,"Let $V$ be a closed subspace of $B(H,K)$ such that $xy^*z \in V$ for all $x,y,z \in V$ . Let $I$ be an ideal $(IV^*V+VV^*I \subset I)$ of $V$ . Let $C(V), D(V)$ denotes the $C^{\ast}$ -algebra generated by $VV^{\ast}$ and $V^*V$ respectively. We define $A(V)$ , the linking $C^*-$ algebra of $V$ as follows: $$A(V) = \begin{bmatrix}
     C(V) &  V\\
    V^* & D(V)
\end{bmatrix}$$ Is $A(I)$ ideal of $A(V)$ ? Note that $$A(I)A(V) = \begin{bmatrix}
     C(V)C(I)+VI^* & C(V)I+VD(I)\\
    V^*C(I)+D(V)I^* & V^*I+D(V)D(I)
\end{bmatrix}$$ The main issue is with entries which lies on main diagonal.Anti diagonal entries are controllable.","['c-star-algebras', 'functional-analysis', 'operator-algebras']"
3505797,"Combinatorics: Bijective proof for ${n + t - 1 \choose t - 1} = \sum_{k=0}^n{n-k+t-2 \choose t-2}$ for integers ${n\ge 1}$, ${t\ge 2}$","I am, generally speaking, having issues with proving combinatorics questions using bijective proofs, so any help explaining how to do that in general would be greatly appreciated. I understand why bijective proofs work, but I never know how to start a proof for it. Do I have to define a specific function and then show that it's one-to-one and onto, or is it enough to say that such a function exists? How can I show that it's bijective? A specific question that I was having issues with is as follows For integers ${n\ge 1}$ , ${t\ge 2}$ , use a bijection to prove that: $${n + t - 1 \choose t - 1} = \sum_{k=0}^n{n-k+t-2 \choose t-2}$$ I tried breaking it down: the LHS is just the number of possible multisets with n elements of $t$ types (or the number of $t-1$ element subsets of a set with $n+t-1$ elements). 
The RHS, on the other hand, for a fixed $k$ gives the number of multisets with $n-k-1$ elements with $t-1$ types. Now this is where I am unsure of how to continue, i.e. how to define a bijection between these two sets. Some ideas I had: Let $S$ be the set of all possible $(t-1)$ -element subsets of $S' = \{1, 2,\ldots, n+t-1\}$ . This represents the LHS. Then let $A$ be the set of all possible $(t-2)$ element subsets of $A' = \{k+1, k+2,\ldots, n + t - 1\}$ . Clearly when $k = 0$ then the $A' = S'$ . But clearly $|S| \gt |A| $ since $ t-1 \gt t-2$ so I'm not really sure how to continue here. I suppose $ S' = \{1, 2, \ldots , k\}\cup A'$ but I'm not really sure if that helps me. Any help/hints would be appreciated. Thanks!","['combinatorics', 'combinatorial-proofs']"
3505803,Multivariable Calculus: Equation satisfied by partial derivatives implies existence of a function,"Im stuck in this question: Suppose $f:\mathbb{R}^{2}\setminus\{0\} \to \mathbb{R}$ is a differentiable function whose gradient is nowhere zero and that satisfies: $$-y\dfrac{\partial f}{\partial x} + x\dfrac{\partial f}{\partial y}=0$$ everywhere. Show that there is a differentiable function $F:(0,+\infty)\to \mathbb{R}$ so that $f(x)=F(||x||)$ . Geometrically, if the partial derivatives of $f$ satisfies the given condition, I get that the gradient vector in any point $(x,y)$ must be orthogonal to the vector $(-y,x)$ , which is the rotation of $90$ degrees counterclokwise of $(x,y)$ . So, $\nabla f \,(x,y)$ will be a scalar multiple of $(x,y)$ . Anyhow, this isn't helping me out to construct the desired function $F$ . Any tips?","['multivariable-calculus', 'calculus', 'real-analysis']"
3505809,Integral $\int_0^1\frac{\operatorname{Li}_2(x^2)}{1-x^2}\left(\frac{\ln(1+x)}{x}-\ln2\right)\ dx$,"I am trying to evaluate $$I=\int_0^1\frac{\operatorname{Li}_2(x^2)}{1-x^2}\left(\frac{\ln(1+x)}{x}-\ln2\right)\ dx$$ I encountered this integral while I was trying to calculate the integral $$\int_0^1\int_0^1\int_0^1\int_0^1\frac{1}{(1+x) (1+y) (1+z)(1+w) (1+ x y z w)} \ dx \ dy \ dz \ dw$$ First of all we can not split the integrand due to divergence, so I used $\sum_{n=1}^\infty H_n^{(2)}x^{n}=\frac{\operatorname{Li}_2(x)}{1-x}$ which gives us $$I=\sum_{n=1}^\infty H_n^{(2)}\int_0^1 \left(x^{2n-1}\ln(1+x)-\ln 2 \ x^{2n}\right)\ dx$$ $$I=\sum_{n=1}^\infty H_n^{(2)}\left(\frac{H_{2n}-H_n}{2n}-\frac{\ln2}{2n+1}\right)$$ and I don't know how to proceed. I also tried Abel's summation but it got even more complicated. any idea? All different methods are appreciated, Thank you.","['integration', 'harmonic-numbers', 'calculus', 'closed-form', 'sequences-and-series']"
3505841,"Showing $\langle x,y\mid x^p=y^p=(xy)^p=1\rangle$ is infinite if $p>2, p$ prime.","Let $p$ be a prime. Prove that the group $\langle x,y\mid x^p=y^p=(xy)^p=1\rangle$ is infinite if $p>2$ , but that if $p=2$ , it is a Klein 4-group. Let $G$ be the group in the problem statement.   The case $p=2$ I could prove it. Let $V=\langle a,b\rangle$ be the 4-group, $F$ free on $X=\{x,y\}, f:X\to V, x\mapsto a, y\mapsto b$ . Then there exists $\varphi:F\to V$ such that $\varphi\mid X=f$ . $\varphi$ is onto because $V=\langle a,b\rangle$ . Let $\Delta=\{x^2,y^2,(xy)^2\}$ . Then $x^2\varphi=a^2=1, y^2\varphi=b^2=1, (xy)^2\varphi=[(xy)\varphi]^2=(ab)^2=1$ . So $\Delta \subseteq$ ker $\varphi$ and $R=\Delta^F\le$ ker $\varphi\le F$ . By the third isomorphism theorem, there is an epimorphism $\phi:F/R\to F/$ ker $\varphi$ . But $F/$ ker $\varphi \simeq V$ . So we have an epimorphism $\theta:G=F/R\to V$ and $\mid G\mid \ge\mid V\mid =4$ . On the other hand, $xyxy=(xy)^2=1, yx=x^{-1}y^{-1}=xy$ . So every element in $G$ can be written as $x^i y^j, 0 \le i,j\lt 2$ , stictly speaking as $x^i y^j R$ . So $\mid G\mid \le 4$ and $\mid G\mid = 4$ . So we have that $V$ is generated by two elements satisfying the same relations as in $G$ and that the two groups have the same order, proving that $G\simeq V$ . The case $p=3$ has been posted here: Presentation $\langle x,y \mid x^3=y^3=(xy)^3=1\rangle\cong\langle t\rangle\ltimes A$ I think the present problem is a generalization of this problem. That is the problem in the link is a particular case of the title problem. So for the general case I could try to find a normal abelian subgroup as in the hint to the problem in the link. To begin with, I could look for two words in $F$ that commute. I tried with $\langle xyx,x^{p-1}y\rangle$ but I failed. I think the problem is really difficult. Could you give me a hint?","['combinatorial-group-theory', 'group-presentation', 'group-theory']"
3505852,The Stable Party Problem,"Here are some definitions in general: Choose any $2$ people $p_1,p_2$ , The relationship from $p_1$ to $p_2$ is one of the following: $1.p_1$ like $p_2$ and $p_1$ dislike $p_2$ , or $2.p_1$ not like $p_2$ and $p_1$ dislike $p_2$ , or $3.p_1$ like $p_2$ and $p_1$ not dislike $p_2$ , or $4.p_1$ not like $p_2$ and $p_1$ not dislike $p_2$ A stable party is a group of people whose all members either $\color{red}{1.}$ have no person they dislike in the group, or $\color{red}{2.}$ have exactly one disliked person in the group while also having a person that they like. A unstable party is a group of people with a member who either $\color{orange}{1.}$ doesn’t like another party member and has no friend to compensate, or $\color{orange}{2.}$ has at least two persons that she doesn’t like in the same party A compact stable party is a stable party that for any people that not in the party, if we add him/her to the party, the party will become unstable. A strictly stable party is a stable party whose members have no one they dislike in the group (equal to condition $1$ of stable party). A compact strictly stable party is a strictly stable party that for any people that not in the party, if we add him/her to the party, the party will become not strictly stable. We denote $x$ Like/Dislike $y$ as $L(x,y)/D(x,y)$ then: $$\forall x(\underset{\text{$\color{red}{1.}$}}{\underline{\forall y~\neg D(x,y)}}\lor\underset{\text{$\color{red}{2.}$}}{\underline{\exists^{!1}y ~D(x,y)\land \exists z~L(x,z)}})\tag*{Stable}$$ $$\forall x\underset{\text{$\color{red}{1.}$}}{\underline{\forall y~\neg D(x,y)}}\tag*{Strictly stable}$$ $$\exists x(\underset{\text{$\color{orange}{1.}$}}{\underline{\exists y~D(x,y)\land\forall z~\neg L(x,z)}}\lor\underset{\text{$\color{orange}{2.}$}}{\underline{\exists^{\ge2}y~D(x,y)}})\tag*{Unstable}$$ The problem I need to solve is: Given $n$ people with random relationship, is there an algorithm to find: $1.$ All possible compact strictly stable parties $?$ $2.$ All possible compact stable parties that not strictly stable $?$ My attempts: I think this is a graph coloring problem, for part $1$ : Step $1$ : Check if there is anyone dislike himself/herself, take them out. Step $2$ : Use the rest people as vertices, connect two vertices if one of them dislike another. Step $3$ : Pick a sufficiently large $n$ , find all possible $n$ -coloring of this graph Step $4$ : Each color in each $n$ -coloring stand for a strictly stable party Step $5$ : Make a set of all strictly stable party from Step $4$ , called it $S$ Step $6$ : For each party in $S$ If it's a proper subset of another party in $S$ , take it out. Step $7$ : The resulting set is all possible compact strictly stable parties. I still have something not sure about this algorithm: For $n$ in step $3$ , how large is sufficiently large $?$ Here is an old example problem from Mount&Blade , The dislike relations are showed in the following graph: (An edge between two vertices $v_1,v_2$ means $v_1$ dislike $v_2$ or $v_2$ dislike $v_1$ ) If we pick $n=2$ , resulting set only gives all $4$ largest strictly stable parties with $8$ members, Instead if we let $n=3$ , the resulting set is all $85$ compact strictly stable parties. In this case we say $3$ is sufficiently large for $n$ . This algorithm can also be done by computer, here is my code with sagemath in python: ( Result ) from sage.graphs.graph_coloring import all_graph_colorings
G = {'Alayen':['Marnid','Nizar'],
          'Artimenner':['Jeremus','Klethi'],
          'Baheshtur':['Katrin','Marnid'],
          'Borcha':['Deshavi','Klethi'],
          'Bunduk':['Lezalit','Rolf'],
          'Deshavi':['Borcha','Rolf'],
          'Firentis':['Nizar','Katrin'],
          'Jeremus':['Artimenner','Matheld'],
          'Katrin':['Firentis','Baheshtur'],
          'Klethi':['Borcha','Artimenner'],
          'Lezalit':['Ymira','Bunduk'],
          'Marnid':['Alayen','Baheshtur'],
          'Matheld':['Ymira','Jeremus'],
          'Nizar':['Firentis','Alayen'],
          'Rolf':['Deshavi','Bunduk'],
          'Ymira':['Matheld','Lezalit']}

def comb(G,n):# Graph G with n-coloring
    G = Graph(G)
    G.show()
    L1 = []# list that contains all possible coloring
    L2 = []# Result list
    L3 = []# Sorted Result list
    for C in all_graph_colorings(G,n, hex_colors=True):
        for i in C:
            if C[i] not in L1:
                L1.append(C[i])
    for i in L1:
        c = True# Check if we should append i to result list L2
        for j in L1:
            if set(i).issubset(set(j)) and set(i) != set(j):
            # If it's a proper subset of some set in L1
                c = False
                # Then we don't append it
        for j in L2:
            if set(i) == set(j):
            # If it's already in L2
                c = False
                # Then we don't append it
        if c:
            L2.append(i)
    for i in L2:
        L3.append([len(i),i])
    L3.sort()
    print('Total:'+str(len(L3)))
    for i in L3:
        print(i)
comb(G,2)
comb(G,3) But for the second part: All possible compact stable parties that not strictly stable, I still don't know where to start. Any help or hint or suggestion would be appreciated.","['coloring', 'graph-theory', 'combinatorics', 'discrete-mathematics', 'algorithms']"
3505853,Please check my solution: probability that there is at least $2 \times 2$ square of just black squares,"Suppose I had a $4\times4$ grid. Each square can be colored white, black, or gray. If a grid is colored at random, what is the probability that there is at least one $2\times2$ square of just black squares? Here's my attempt at a solution: There are a total of $3^{16}$ possible colorings. There are also 9 $2\times2$ squares in a $4\times4$ grid. Without loss of generality, assume that the top left square is black. Then there are $3^{12}$ ways that the other squares can be colored. Multiplying, we get $9*3^{12}$ possibilities. Thus, we get the probability $\frac{1}{9}$ . This solution seems too easy, and the probability seems a bit too high. Can someone please help?",['probability']
3505861,We roll a fair die until a $5$ appears. What is the expected value of the minimum value rolled?,"Question: Given a fair dice, we roll until we get a $5.$ What is the expected value of the minimum value rolled? Answer is $\frac{137}{60}.$ There is a similar question asked in MSE but I do not understand the method used by Henry. In particular, if we let $X$ be the minimum value rolled up to and including $5$ , then $$E(X) = \sum_{x=1}^5 xP(X=x) = 1 \times \frac12 + 2 \times \frac16 + 3 \times \frac1{12}+4 \times \frac{1}{20}+5 \times \frac15 = \frac{137}{60}.$$ It seems that we are using the fact that $$P(X=x) = \frac{1}{x(x+1)}.$$ I do not understand how to obtain the equation above.","['expected-value', 'probability']"
3505954,Distinct $3$-Sylow subgroups of $S_6$ intersect trivially,"Let $S$ and $T$ be distinct $3$ -Sylow subgroups of the symmetric group $S_6$ . Prove that $S$ and $T$ intersect trivially. Here are my thoughts so far: I figured the Sylow Theorems could give us some insight here. Let $G = S_6$ . Then $G$ has order $6! = 720 = 2^4 \cdot 3^2 \cdot 5$ . It follows that any $3$ -Sylow subgroup of $G$ must have order $9$ , and that, denoting $n_3$ by the number of $3$ -Sylow subgroups of $G$ , $n_3 | 80$ and $n_3 \equiv 1$ (mod $3$ ) $\Rightarrow$ $n_3 = 1, 4, 10, 16, 40$ . I'm not sure how to proceed from here. There's a long list of possibilities of possible orders for the $5$ -Sylow and $2$ -Sylow subgroups 0f $G$ -- so it doesn't seem like we can get away with a counting argument here, showing that if $3$ -Sylow subgroups of $G$ intersect non-trivially, we end up with more than $720$ elements in our group, contradicting the order of $G$ . How can I reach a contradiction? I appreciate all the help. Thanks!","['symmetric-groups', 'group-theory', 'abstract-algebra', 'sylow-theory']"
3505966,Derivative of $\log(r)$ with respect to $x$,"$r$ is a polar radius coordinate, $x$ is a horisontal cartesian coordinate. Going one way, i get: $\log(r)_x=\log(\sqrt{z\bar{z}})_x$ = $\frac{ (\sqrt{z\bar{z}})_x }{ \sqrt{z\bar{z}}}= \frac{0.5((\bar{z})_xz+ \bar{z}z_x) }{ \bar{z}z } = \frac{x}{r^2} $ . This is correct. But going other way, i get: $\log(r)_x=\log(r)_rr_x= \frac{r_x}{r}= \frac{1}{r} $ , since $x=re^{i0}=r$ in polar coordinates. My question is, why is the second way wrong, and are there any easier methods to arrive at $\log(r)_x= \frac{x}{r^2}$ , without using complex numbers perhaps?","['coordinate-systems', 'complex-analysis', 'polar-coordinates', 'implicit-differentiation', 'derivatives']"
3505969,"Find all natural solutions $(a, b)$ such that $(ab - 1) \mid (a^2 + a - 1)^2$.","Find all natural solutions $(a, b)$ such that $$\large (ab - 1) \mid (a^2 + a - 1)^2$$ We have that $$(ab - 1) \mid (a^2 + a - 1)^2 \implies (ab - 1) \mid [(ab)^2 - ab^2 - b^2]^2$$ $$\iff (ab - 1) \mid (ab^2 + b^2 + 1)^2 \iff (ab - 1) \mid (b^2 + b + 1)^2$$ I'm trying to prove that $(ab - 1) \mid (a + b - 1)^2$ , yet I don't know how with the information presented. Assuming that I know how to determine that $(ab - 1) \mid (a + b - 1)^2$ . Let $$(a + b - 1)^2 = k(ab - 1), k \in \mathbb Z^+ \tag 1$$ where $(a, b)$ is the solution in which $a + b$ is at its minimal value. $$\iff a^2 - [(k - 2)b + 2]a + [(b - 1)^2 + k] = 0$$ We have that the equation $$x^2 - [(k - 2)b + 2]a + [(b - 1)^2 + k] = 0$$ has two solutions $x = a$ and $x = a'$ such that $$a + a' = (k - 2)b + 2, aa' = (b - 1)^2 + k$$ It can easily be deduced that $a' \in \mathbb Z^+ \implies (a', b)$ is a solution to $(1)$ $\implies a' + b \ge a + b \iff a' \ge a \implies \dfrac{(b - 1)^2 + k}{a} \ge a \iff (b - 1)^2 + k \ge a^2$ It seems to me that there are infinitely many solutions, which are all consecutive elements in a sequence. Furthermore, the assumption that $(ab - 1) \mid (a + b - 1)^2$ is incorrect. So I don't know what to begin from here.","['number-theory', 'vieta-jumping']"
3505989,What's the inverse of $x^5 +3x^3 + 2x + 1$?,"Let $f$ be a one-to-one function whose inverse is given by: $f^{-1}(x)=x^5+3x^3+2x+1$ Compute $f^{−1}(1)$ . My attempt at this yielded a very straightforward answer: $f^{-1}(1)=1^5+3(1)^3+2(1)+1\\
f^{-1}(1)= 7$ Compute $f(1)$ . I have searched around on this Stack Exchanged and discovered that finding the inverse of a degree 5 polynomial is not viable using only algebra level math. I would greatly appreciate it if someone was able to point me in the right direction. Thanks in advance.","['algebra-precalculus', 'inverse-function', 'polynomials']"
3505997,Prove that $\det(AB - BA) = \frac{1}{3}\left(\mathrm{Trace}(AB - BA)^3\right)$,"I want a correct and feasible answer to this question. 
So does anyone have any creative ideas to prove this equation? $A$ and $B$ are $3\times3$ matrices. $\det(AB - BA) = \dfrac{1}{3}\operatorname{Trace}\left((AB - BA)^3\right)$ Answer: We can write and compute both sides to prove it but this is not a good solution!","['matrices', 'determinant', 'linear-algebra']"
3506014,How many subsets of a well ordered set are isomorphic to the whole set?,"Could you please help me to solve following problem from an exam. Suppose $\langle A,\prec \rangle$ is well orderered set whose ordinal is $\alpha$ . What is the cardinal of set of all subsets of $\langle A,\prec \rangle$ that are similar (have the same ordinal) to $\langle A,\prec \rangle$ . My try so far: If $\alpha$ is finite ordinal, than there exists only one subset of $\langle A,\prec \rangle$ that is similar to $\langle A,\prec \rangle$ , $\langle A,\prec \rangle$ itself. if $\alpha=\omega$ , then $\langle A,\prec \rangle$ is similar to $\langle N,< \rangle$ , and there are at least $\aleph_0$ subsets of $\langle N,< \rangle$ that are similar to $\langle N,< \rangle$ , for example, set of all natural numbers that are divided by any natural number greater than 1. Can we find more than $\aleph_0$ such sets ? But how to proceed and form a valid argument about any ordinal $\alpha$ ? Thank you.","['elementary-set-theory', 'well-orders']"
3506026,"Vector Spaces, Normed Vector Spaces and Metric spaces","I've already studied real analysis and I've just finished studying linear algebra (the source I've used did not cover norms, but I have some basic understanding about them). Now I know that there are normed vector spaces and they have a lot of applications. From my understanding the reason for defining them is that it is a way to give a vector space some additional structure to be able to consider things like convergence and continuity. This is because a norm induces a metric, and therefore all the metric space theorems are applicable. Now I've got two questions: 1) Although I can mathematically understand that a norm induces a metric and it also intuitively makes sense in euclidean spaces since the norm can be interpreted as length which makes the connection to the metric or distance obvious (We can just draw two vectors in $\mathbb{R}^{2}$ and then it is easy to see the that the relation follows by the Pythagorean Theorem.) However, I was wondering why this holds for any normed vector space. In general, the norm can be seen as magnitude or size of an object while the metric measures similarity. Can someone give me an intuition about the connection between norm and metric in a broader context? 2) As mentioned above the ultimate goal of defining the norm is to introduce a metric space structure. I've read different posts on this topic and it seems that we want ""the metric space structure to play nice with the vector space structure"" ( Metric spaces and normed vector spaces ). Can someone give me an example of an application where this goes wrong and what the consequences are? Translation invariance and homogeneity seem to be important properties for this ( What's the need of defining notion of distance using norm function in a metric space? ).","['vector-spaces', 'examples-counterexamples', 'real-analysis', 'linear-algebra', 'functional-analysis']"
3506039,Why is $\sum_{k=1}^\infty \frac{1}{(b+1)^k}=\frac{1}{b}$?,"I was looking through in stack math and got this answer: Prove that $e$ is irrational by Yiorgos S. Smyrlis . (This answer is copied below).
Since I cannot comment I can only ask here. Here is the information provided. Hints. We first show that $2<\mathrm{e}<3$ (see below), and hence $\mathrm{e}$ is not an integer. Next, following up OP's thought, assuming $\mathrm{e}=a/b$ , we multiply by $b!$ and we obtain $$
\sum_{k=0}^\infty \frac{b!}{k!}=a\cdot (b-1)! \tag{1}
$$ The right hand side of $(1)$ is an integer. The left hand side of $(1)$ is of the form $$
\sum_{k=0}^b \frac{b!}{k!}+\sum_{k=b+1}^\infty \frac{b!}{k!}= p+r.
$$ Note that $p=\sum_{k=0}^b \frac{b!}{k!}$ is an integer, while $$
0<r=\sum_{k=b+1}^\infty \frac{b!}{k!}=\frac{1}{b+1}+\frac{1}{(b+1)(b+2)}+\cdots<\sum_{k=1}^\infty \frac{1}{(b+1)^k}=\frac{1}{b}<1.
$$ Note. The fact that $\mathrm{e}\in (2,3)$ can be derived from the inequalities $$ 
\left(1+\frac{1}{n}\right)^{\!n}<\mathrm{e}<\left(1+\frac{1}{n}\right)^{\!n+1},
$$ for $n=1$ for the left inequality and $n=5$ for the right inequality.","['proof-explanation', 'real-analysis', 'sequences-and-series', 'geometric-series', 'geometric-progressions']"
3506043,an arithmetic sum and product puzzle,"Assume that $X$ and $Y$ are positive integers with $1<X<Y$ . Mr. S knows the value $X+Y$ , and Mr. P knows the value $XY$ . They then have the following conversation.
Mr. S says to Mr. P : ""You do not know the value of $X$ and $Y$ ""
Mr. P responds to Mr. S: ""Now that you said this to me, I know the values of $X$ and $Y$ .""
Mr. S then responds : ""So do I"".
Find $X$ and $Y$ . My (very inadequate!) thoughts on this puzzle so far are as follows. It is clear that $X$ and $Y$ cannot be two distinct primes-else P would know their values instantly. I also thought (assuming Goldbach's conjecture (is this legit?!) that $X+Y$ cannot be even. Because if $X+Y$ were even, Mr. S could not rule out the possibility that $XY$ is the product of two distinct primes. Thus, all even numbers in $[1,Y]$ can be ruled out. The same reasoning also rules out odd positive integers that are of the form $2$ added to an odd prime, and squares of primes in $[1,Y]$ .
The problem as stated did not give a numerical bound on $Y$ . If it had-like (say) $Y=100$ , I would be tempted to try cases and see which integers can be ruled in-many seem to be ruled out, and there could well be more than one solution. Is there a general argument that works for any positive integer $Y$ that I am missing?",['number-theory']
3506074,Set-builder notation for vector in $\Bbb{R}^3$,"I have $\Bbb{R}^3$ domain, so it's a 3-dimensional Cartesian coordinate system with $x, y, z$ axes. I need to define a set in this domain that contains only vectors $\mathbf{v}$ that consists of components $v_x, v_y, v_z$ with limitations: $$ x_{min} < v_x < x_{max}; y_{min} < v_y < y_{max}; z_{min} < v_z < z_{max}. $$ I've started with $S = \{\mathbf{v} \in \Bbb{R}^3 | x_{min} < v_x < x_{max}, y_{min} < v_y < y_{max}, z_{min} < v_z < z_{max}\}$ I don't think it's correct. Also, it's a very long string. What if I need to define set in $\Bbb{R}^{10}$ ? How to define the set? P.S. Feel free to point out to my another mistakes in defining problem.","['elementary-set-theory', 'notation']"
3506091,Solve $2^m=7n^2+1$,"Solve $2^m=7n^2+1$ with $(m,n)\in \mathbb{N}^2$ Here is what I did:
First try, I have seen first that the obvious solutions are $n=1$ and $m=3$ , and $n=3$ and $m=6$ , then I proved by simple congruences that $m$ must be divisible by $3$ so $m=3k$ , If we add $27$ to the equation we will have $2^{3k}+3^3=7(n^2+2^2)$ , but unfortunately I tried to do something with Legendre symbol or the multiplicative order but I found nothing interesting. Second try,I let $n=2k+1$ then I worked in $\mathbb{Z}\left[ \frac{-1+\sqrt{-7}}{2} \right] $ and the equation becomes $7\times 2^{m-2}=\left( 7k+4+\frac{-1+\sqrt{-7}}{2} \right) \left( 7k+3-\frac{-1+\sqrt{-7}}{2} \right) $ but I didn't find something interesting because the two factors are not coprime.","['contest-math', 'number-theory', 'algebraic-number-theory', 'elementary-number-theory']"
3506111,Limit of an integral in the form of $\lim_{x\to 0} g(x) \int_{0}^{x} f(t) dt$,"while preparing my next exam I found this exercise in the exam of two years ago: $$\lim_{x\to 0} \frac{\sinh(x)}{\cos(x)-1}  \int_{0}^{x} \sqrt{e^t-t^4} dt$$ I first thought to use de L'Hopital rule, but it didn't feel right so I tried another way. I decided to try to expand the function inside the integral using McLaurin series. So the function became: $$\lim_{x\to 0} \frac{\sinh(x)}{\cos(x)-1}  \int_{0}^{x} (1+\frac t 2 + \frac {t^2} 4+ \frac {t^3} {12} + \frac {25t^4}{48}+\mathcal{o}(t^4)) dt$$ After expanding $\frac{\sinh(x)}{\cos(x)-1}$ and integrating and some other algebric steps, it came down to $$\frac{x^2} {\frac{-x^2} 2}$$ the result was -2.
My problem is that I'm not sure I could actually do everything I did. I someone could explain to me whether I'm right or not, and maybe also explain to me how to approach this type of exercises I would be extremely thankful. I would like to apologize already for the spelling mistakes I made for sure, but I'm not a native English speaker.","['calculus', 'real-analysis']"
3506172,What's the number of sequences containing $10$ ones and $20$ zeroes that don't have adjacent ones.,"How many sequences containing 10 ones and 20 zeroes don't have adjacent ones? So I'm kinda lost here. Which way do I go? Do I find all combinations, then subtract the number of sequences that have adjacent ones, that seems like an option, but then I am not quite sure how to find all sequences with adjacent ones. Any help is very much appreciated!","['combinatorics', 'discrete-mathematics', 'sequences-and-series']"
3506310,"Maximum odd number of subsets, each intersects exactly half of the others","Find the largest positive integer $k$ with the following property $-$ there exist $2k+1$ distinct subsets of $\{1,\ldots,20\}$ such that each such subset intersects precisely $k$ of the other $2k$ subsets. The original problem I saw also insisted on each set to have $7$ elements (which makes things much easier $-$ it is easy to obtain $k\leq 2$ ) but what would happen if the do not have such a restriction? I cannot obtain anything apart from the fact that $k$ is even (since the number of intersecting pairs is $\frac{k(2k+1)}{2}$ ). Any help appreciated!","['combinatorial-geometry', 'combinatorics', 'extremal-combinatorics']"
3506336,find the region for CDF,"Let $X$ and $Y$ be two random variables with the following density function: $$f(x)=
\begin{cases}
6x(1-x),  & \text{if   } 0\le x\le 1 \\
0, & \text{otherwise}  \\
\end{cases} \\ g(y)=\begin{cases}
3y^2,  & \text{if   } 0\le y\le 1 \\
0, & \text{otherwise}  \\
\end{cases}$$ If $X$ and $Y$ are independent find the pdf of random variables $Z=\frac{X}{Y}\text{ and }U=XY$ . As $X$ and $Y$ are independent then the joint pdf is, $$f_{X,Y}(x,y)=\begin{cases}
18xy^2(1-x),  & \text{if   } 0\le x\le 1,0\le y\le 1 \\
0, & \text{otherwise}  \\
\end{cases}$$ $(1)$ Let $F_Z(z)$ is the CDF of Z, $$F_Z(z)=P(Z\le z)=P\left(\frac{x}{y}\le z\right)\stackrel{(a)}{=}P(x\le zy)$$ As $0\le y\le 1$ , our inequality didn't change in $(a)$ . Now it's time to draw the region, $$F_Z(z)=\int_0^1\int_0^{zy}f_{XY}(x,y)\:dx\:dy$$ I can do the rest. Can anyone tell me Am I correctly done everything until here $?$ $(2)$ Let $F_U(u)$ is the CDF of U, $$F_U(u)=P(U\le u)=P(xy\le u)$$ From here I can't image the region. Can Anyone help me to figure it out. Any solution or hint will be appreciated. Thanks in advance.","['statistics', 'probability-distributions']"
3506375,Are there any known Collatz-like results?,"The usual argument in favor of the Collatz conjecture (or at least in favor of there being no unbounded trajectories) essentially argues that, if we have the ""shortcut"" function defined by: $$f(2x)=x$$ $$f(2x+1)=3x+2$$ then the parity of a number in the trajectory $x,\,f(x),\,f^2(x),\ldots$ of iterates of the Collatz function should be randomly distributed and therefore that the geometric mean of the ratios $\frac{f^n(x)}{f^{n+1}(x)}$ should be $\sqrt{3/4}$ unless $x$ is small - which suggests that the sequence should not grow without bound. This is famously an open question - but there's an obvious generalization of the same reasoning: fix some natural number $m$ and some sequence of integers $a_k$ and $b_k$ indexed over the set $\{0,\ldots,m-1\}$ . Define a function by the rule: $$g(mx+k)=a_kx+b_k$$ where $x$ is an integer and $k$ is an integer in $[0,m)$ . Let's say that $g$ is Collatz-like if: $\gcd(m,a_k)=1$ for every $k$ . $\prod_{k=0}^{m-1}\frac{a_k}m$ < 1. There is some $k$ such that $\frac{a_k}m > 1$ . The first condition enforces that the proportion of integers $x$ with a prescribed sequence of mod $m$ residues for $x,\,f(x),\,f^2(x),\ldots,\,f^{\ell}(x)$ is exactly $1/m^{\ell}$ , which justifies treating these residues somewhat randomly. The second enforces that the logs of large numbers are expected to decrease. The last is a non-triviality condition, since any function violating it clearly has no unbounded trajectories. Is there any example of a Collatz-like function $g$ for which it is known whether $g$ has an unbounded trajectory?","['collatz-conjecture', 'number-theory']"
3506406,Proving the inequality $\prod_{n=1}^\infty \left( 1+\frac1{n^2+\ln n} \right) < \frac72$,"I am struggling to prove $$\prod_{n=1}^k \left( 1+\frac1{n^2+\ln n} \right) < \frac72$$ For all $k \geq 1$ . Clearly, this is true for $k=1$ , so it suffices to show $$\prod_{n=1}^\infty \left( 1+\frac1{n^2+\ln n} \right) < \frac72$$ The obvious way to show this would be to evaluate the product directly, though I don't think that is feasible. I am not sure how else to approach this product. This would be a ( much ) tighter upper bound than $$\exp\left ({\sum_{n=1}^k} \frac1{n^2+\ln n} \right )$$ Which comes from the monotone convergence theorem.","['inequality', 'real-analysis', 'sequences-and-series', 'infinite-product', 'convergence-divergence']"
3506412,"Prove if $X$ is an integrable errv, then $X\geq 0$ a.s iff $\int_{A} XdP\geq 0$","I am trying to prove this question: If $X$ is an integrable errv then $X\geq 0$ a.s iff $\forall A\in \Omega$ , $\int_{A} XdP\geq 0$ Can you give me any hint to construct a proof? I know that $E(X)=\int_{A} XdP +\int_{A^c} XdP$ and $\int_{A} XdP = \int \mathbb{1}_A XdP$ Do I have to use those equation, or am i wrong?","['integration', 'measure-theory', 'probability-theory']"
3506427,Doubt in solution of an exercise related to Dirichlet theorem on primes in AP which proves infinitely many solutions by Chinese reminder theorem.,While trying exercises from Apostol introduction to Analytic number theory I am struck on this problem of chapter -Dirichlet theorem on primes in Arithmetic Progression. I am adding its image Fortunately I could find its solution on internet but I have one doubt in its solution. Image of solution-> I have following doubt in its solution -> I have studied Chinese remainder theorem from Apostol and it is used to determine whether solution exists and then solution is proved to be unique. But how does here Chinese reminder theorem is used to prove existence of infinitely many solutions? Can someone please explain how Chinese reminder theorem implies here that infinitely many solutions exist,"['analytic-number-theory', 'number-theory', 'chinese-remainder-theorem']"
3506439,How can I find the smoothest transition between two straight lines?,"Let's say I have the function $$f(x)=\begin{Bmatrix}
x & \textrm{,} & \textrm{if } x\leqslant 1.5\\ 
\frac{x}{3}+1 & \textrm{,} & \textrm{otherwise}
\end{Bmatrix}$$ which has a sharp edge at 1.5, i.e. a discontinuity in the first derivative. I would like to smooth that transition with some other function. In practice I would like to set a window around the sharp edge in which the transition happens: $$f(x)=\begin{Bmatrix}
x & \textrm{, } & \textrm{if } x\leqslant 1.5-t\\
s(x) & \textrm{, } & \textrm{if } 1.5-t\leqslant x\leqslant 1.5+t\\
\frac{x}{3}+1 & \textrm{, } & \textrm{otherwise}
\end{Bmatrix}$$ with s(x) being my transition function and t being half the window width. I could choose a quadratic but that would create a sharp edge in the first derivative (i.e. a discontinuity in the second derivative). I'd like a function f(x) that ends up with no discontinuities in any of the derivatives and is monotonically nondecreasing. If anyone can point me in the right direction of what I'm looking for, I'd be thankful.",['derivatives']
3506442,Combinatorics problem with connecting computers,"A system administrator has to connect 16 computers to 4 network switches. Exactly 3 computers must be connected to the first network switch. Show that there must exist a switch that has at least 5 connected
computers. In how many ways can we connect the computers if we know that they
are all different? In how many ways can we connect the computers if we know that they
are all the same? I tried solving the third question with first finding the $3$ -combinations for all $16$ computers: $\binom{16+3-1}{16} = 153$ ways and then for the remaining $3$ switches I used the equation: $x_1+x_2+x_3=13$ , with $x_1$ having at least $5$ connected computers, meaning $x_1>4$ . The solution I got was $84$ ways. $153+84$ ways $= 237$ ways. I don't know if this is the right approach. I would like to know if I am on the right path and what am I doing wrong.","['combinatorics', 'discrete-mathematics']"
3506445,Solving coupled differential equation via perturbation method,"In the paper by Caroli, de-Gennes and Matricon on Bound fermion state in superconductor, they have reached a system of first order differential equation which reads roughly as: \begin{align}
-i\hbar v_F\frac{df}{dr}+\Delta(r)g(r)&=(\epsilon+\frac{\mu\hbar^2}{2mr^2})f(r) 
\\
i\hbar v_F\frac{dg}{dr}+\Delta(r)f(r)&=(\epsilon+\frac{\mu\hbar^2}{2mr^2})g(r) 
\\[.5em]
v_F&=\frac{\hbar k_F}{m}
\end{align} $f(r),g(r), \Delta(r)$ are functions of $r$ . $\mu$ is an integer and $\epsilon$ is a small number and can be treated as a small perturbation. What I fail to understand is how they are able to solve the above system by treating the right hand side as a small perturbation, to first order, and obtain the following results: \begin{align}
f(r)&=e^{\frac{1}{2}i\psi(r)-K(r)}\\
g(r)&=-ie^{-\frac{1}{2}i\psi(r)-K(r)}
\end{align} where $$K(r)=\frac{\int_{0}^{r}\Delta(r')dr'}{\hbar v_F}$$ and $$\psi(r)=-e^{2K(r)}\int_{r}^{\infty}e^{-K(r')}(\frac{2\epsilon}{\hbar v_F}+\frac{\mu}{k_Fr'^2})dr'$$ If someone can explain briefly the procedure to get to the final results, it would be very helpful. Thanks in advance for anyone willing to answer.","['ordinary-differential-equations', 'perturbation-theory']"
3506580,Optimize area of football field within running track of 400 meters in perimeter,"I'm trying to solve the following problem: We are projecting a running track. The running area consists of two
  parallel lines and two semicircles connecting them. The perimeter of
  the running track is 400 meters. We want to have a football playground
  (a rectangle) inside the running track with the biggest possible area.
  What dimensions do we have to choose in order to have the biggest
  area? I know how to optimize using the derivative, however I don't know how to form the function. Could you help me with that? Thanks","['optimization', 'calculus', 'derivatives']"
3506602,Inertia and Decomposition fields,"I am having trouble understanding part of the proof of Theorem 28 from Marcus's Number Fields. Let $L$ be a normal extension of $K$ (both number fields), let $R$ and $S$ be their respective integer rings, and let $Q$ be a prime ideal of $S$ lying over $P$ . Let $L_H$ denote the fixed field of a subgroup $H$ , and more generally for a set $X$ we write $X_H=X\cap L_H$ . Let $G=\mathrm{Gal}(L/K)$ and $E=\{\sigma\in G\mid \sigma(\alpha)\equiv\alpha\text{ for all }\alpha\in S\}$ . The claim is that $f(Q, Q_E)$ , the inertia degree of $Q$ over $Q_E$ , is $1$ . Equivalently $S/Q$ is the trivial extension of $S_E/Q_E$ . It is sufficient to show the Galois group of $S/Q$ over $S_E/Q_E$ is trivial. To do this, we can show that for each $\theta\in S/Q$ the polynomial $(x-\theta)^m$ has coefficients in $S_E/Q_E$ for some $m\geq 1$ . The line I'm having trouble with: ""Fix any $\alpha\in S$ corresponding to $\theta\in S/Q$ . Then the polynomial $g(x)=\prod_{\sigma\in E}(x-\sigma\alpha)$ has coefficients in $S_E$ ."" Why is this true? I know that the coefficients will be sums of products of the form $\sigma\alpha$ , which are sums and products of conjugates of $\alpha$ , and so they will lie in $S$ . However, $\alpha\in S$ means that $\sigma(\alpha)\equiv\alpha\mod Q$ for all $\sigma\in E$ , not $\sigma(\alpha)=\alpha$ , right? What am I missing?","['number-theory', 'algebraic-number-theory']"
3506628,Check on distribution of $X-Y$ and $W_s - W_t$ for a Brownian motion,"if $X,Y$ are two independent normal random variables, we know that $$X+Y$$ is still $N(u_x+u_y, \sigma^2_x + \sigma^2_y)$ , and that's fine. (I proved it via characteristic function) Now I want to find the distribution of $X-Y$ . By independence, and looking at the generating function: $$E[e^{z(X-Y)}]= E[e^{zX} e^{zY}] = E[e^{zX}] E[e^{-zY}] = e^{z(u_x - u_y)} \cdot e^{\frac{z^2}{2} (\sigma_x^2 + \sigma_y^2)}$$ and since this is the moment generating function of a $N(u_x - u_y, \sigma_x^2 + \sigma_y^2)$ I conclude that $$X-Y$$ is distributed as $N(u_x - u_y, \sigma_x^2 + \sigma_y^2)$ Is my argument okay?","['normal-distribution', 'expected-value', 'moment-generating-functions', 'solution-verification', 'probability-theory']"
3506684,What is the mistake in my derivation of cosine,"In a triangle $ABC$ let's let $\overrightarrow{a}=\text{vector }\overrightarrow{BC}$ , let $\overrightarrow{b}=\text{vector }\overrightarrow{CA}$ , and let $\overrightarrow{c}=\text{vector }\overrightarrow{BA}$ ,. Let's let $\gamma=\text{angle }ACB$ . Then; $$\overrightarrow{c}=\overrightarrow{a}+\overrightarrow{b}$$ $$\overrightarrow{c}\cdot\overrightarrow{c}=\left(\overrightarrow{a}+\overrightarrow{b}\right)\cdot\left(\overrightarrow{a}+\overrightarrow{b}\right)$$ $$\overrightarrow{c}\cdot\overrightarrow{c}=\overrightarrow{a}\cdot\overrightarrow{a}+\overrightarrow{b}\cdot\overrightarrow{b}+2\overrightarrow{a}\cdot\overrightarrow{b}$$ $$|c|^2=|a|^2+|b|^2+2|a||b|\cos(\gamma)$$ But, the cosine law says: $|c|^2=|a|^2+|b|^2-2|a||b|\cos(\gamma)$ . So I guess I made a mistake somewhere in the process. What was my mistake?","['trigonometry', 'vectors']"
3506698,I need a francophone book of mathematics of 1st and 2nd year of university,"I am from Algeria and I'm on 2nd year on a preparatory class for engineers. We took calculus and algebra and statistics/probabilities in the 1st year, and now we study calculus and ""analyse numérique"". I was always searching for books or any source that covers our program with full proofs but I didn't find any. They are just explaining courses without proving them. Could you help me? We study with the french language here but I would be happy if an English book does contain what I want.","['statistics', 'reference-request', 'calculus', 'linear-algebra', 'probability-theory']"
3506714,How many ways to have a perfect game of snake?,I've been playing snake.  Online there are videos of people playing a perfect game and filling up the board. How many ways are there to fill an n x m rectangle with a snake of length n*m?,['combinatorics']
3506730,The Yosida transform and its properties.,"Let $\lambda \gt 0$ and $f:\Bbb R \to \Bbb R$ . Define the Yosida transform of $f$ by $$T_\lambda f(x) = \inf_{y \in \Bbb R}\{f(y) +\lambda |x-y|\}$$ So far I have showed that $T_\lambda f = \max\{g:g\le f$ and g is $\lambda$ -Lipschitz $\}$ . Now, I want to show a few things about this operator: if $f_n\to f$ pointwise on $\Bbb R$ then $T_\lambda f_n\to T_\lambda f$ pointwise on $\Bbb R$ . if $f_n$ has a growth condition such as $f_n(x)\ge c|x|^p$ for some $p\gt 1$ and $f_n$ is convex for each $n$ then the convergence is uniform. Suppose $f$ is convex and have the same growth as in (2). I'm wondering whether or not $T_\lambda f \to f$ as $\lambda \to \infty$ . I would really appreciate any help since I wasn't able to prove either claims. My attempt: let $x\in \Bbb R$ we want to show that $\lim_n T_\lambda f_n(x) = T_\lambda f(x)$ . For each $n\in \Bbb N$ by the definition of the infimum, there is $(y_k^n)_{k=1}^{\infty}$ such that $\lim_{k \to \infty}(f(y_k^n) +\lambda |x-y_k^n| )= T_\lambda f_n(x)$ . I thought maybe looking at the ""diagonal"" $(y_n^n)_{n=1}^{\infty}$ but not sure if that helps since im not sure if this sequence converge. Thanks for helping.","['calculus', 'analysis']"
3506862,Radon–Nikodym Derivative and Bayes' Theorem,"Theorem 1.3.1. (Bayes' theorem): Suppose that $X$ has a parametric family $\mathcal{P}_0$ of distributions with parameter space $\Omega$ .
  Suppose that $P_\theta \ll \nu$ for all $\theta \in \Omega$ , and let $f_{X\mid\Theta}(x\mid\theta)$ be the conditional density (with respect to $\nu$ ) of $X$ given $\Theta = \theta$ .
  Let $\mu_\Theta$ be the prior distribution of $\Theta$ .
  Let $\mu_{\Theta\mid X}(\cdot \mid x)$ denote the conditional distribution of $\Theta$ given $X = x$ .
  Then $\mu_{\Theta\mid X} \ll \mu_\Theta$ , a.s. with respect to the marginal of $X$ , and the Radon–Nikodym derivative is $$
\frac{\mathrm d\mu_{\Theta\mid X}}{\mathrm d\mu_\Theta}(\theta \mid x)
= \frac{f_{X\mid \Theta}(x\mid \theta)}{\int_\Omega f_{X\mid\Theta}(x\mid t) \, \mathrm d\mu_\Theta(t)}
$$ for those $x$ such that the denominator is neither $0$ nor infinite.
  The prior predictive probability of the set of $x$ values such that the denominator is $0$ or infinite is $0$ , hence the posterior can be defined arbitrarily for such $x$ values. I tried to derive the right hand side of the Radon–Nikodym derivative above but I got different result, here is my attempt: \begin{equation} \label{eq1}
\begin{split}
\frac{\mathrm d\mu_{\Theta\mid X}}{\mathrm d\mu_\Theta}(\theta \mid x) &= f_{\Theta\mid X}(\theta\mid x) \mathrm \space \space \space[1]\\
&=\frac{f_{X\mid \Theta}(x\mid \theta) \cdot f_{\Theta}(\theta)}{f_X(x)}\\
&=\frac{f_{X\mid \Theta}(x\mid \theta) \cdot f_{\Theta}(\theta)}{\int_\Omega f_{X\mid\Theta}(x\mid t) \, \cdot f_{\Theta}(t) \space \mathrm dt}\\
&=\frac{f_{X\mid \Theta}(x\mid \theta) \cdot f_{\Theta}(\theta)}{\int_\Omega f_{X\mid\Theta}(x\mid t) \, \mathrm d\mu_\Theta(t)}
\end{split}
\end{equation} but now, where does $f_{\Theta}(\theta)$ go? for $[1]$ see slide $10$ of the following document: http://mlg.eng.cam.ac.uk/mlss09/mlss_slides/Orbanz_1.pdf Thanks in advance.","['measure-theory', 'probability-theory', 'probability']"
3506928,Can we deduce the characteristic polynomial for this matrix?,"Given a square $n \times n$ matrix $A$ that satisfies $$\sum\limits_{k=0}^n a_k A^k = 0$$ for some coefficients $a_0, a_1, \dots, a_n,$ can we deduce that its characteristic polynomial is $\sum\limits_{k=0}^n a_k x^k$ ?","['matrices', 'linear-algebra', 'characteristic-polynomial']"
