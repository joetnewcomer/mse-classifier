question_id,title,body,tags
3183474,Proving that $\sum_{n=1}^\infty \frac{\sin^2 n}{n^2}=\sum_{n=1}^\infty \frac{\sin n}{n}$.,"Proving that $$\sum_{n=1}^\infty \frac{\sin^2 n}{n^2}=\frac{\pi -1}{2}$$ I've known a similar conclusion $$ \sum_{n=1}^\infty \frac{\sin nx}{n}= \begin{cases}
\dfrac{\pi - x}{2} & x \in (0, 2\pi),\\ 
\quad 0 & x = 0, \\
f(x+2\pi) & x \in \Bbb{R}.
\end{cases} $$ And one of my classmates found the equation mentioned above by mathematica. I was amazed by the equation $$
\sum_{n=1}^\infty \frac{\sin^2 n}{n^2}=\sum_{n=1}^\infty \frac{\sin n}{n}
$$ My attempt \begin{align}
\sum_{n=1}^\infty \frac{\sin^2 n}{n^2}
& = \sum_{n=1}^\infty \frac{1-\cos 2n}{2n^2} \\
& = \sum_{n=1}^\infty \int_0^1 \frac{\sin 2n\theta}{n} d\theta \\
& = \int_0^1 \sum_{n=1}^\infty \frac{\sin 2n\theta}{n} d\theta \\
& = \int_0^1 \frac{\pi}{2}-\theta \,d\theta \\
& = \frac{\pi-1}{2}
\end{align} Oh. Actually I hadn't solved it before I edited this question, but I seemed to have worked it out. So is there any other method to solve this problem? And deeper insights? I've heard that it can be worked out via complex analysis and fourier analysis. Thanks in advance! Added Thanks for your comments! Here is another possible generalization $$
\sum_{n \in \mathbb{Z} } \left[\frac{\sin (n \alpha + \theta)  }{ n \alpha + \theta} \right]^2 = \frac{\pi}{\alpha} \,\, \forall \alpha , \theta \in \mathbb{R}
$$ I got stuck on it. For $\theta=0$ we can use the following equation $$
\sum_{n \in \mathbb{Z} }  \frac{\cos n\theta}{n^2} = \frac{\pi^2}{6}-\frac{\pi \theta}{2} + \frac{\theta^2}{4} \,\, \theta \in [0,2\pi]
$$ But how to deal with the situation that $\theta \ne 0$ ? Can you give me some hints? Thanks in advance!","['real-analysis', 'complex-analysis', 'sequences-and-series', 'power-series', 'fourier-series']"
3183515,"Verify proof that $\lim_{(x,y) \to (0,0), x+y \neq 0}{\frac{\ln(1-x-y)}{x+y} } = -1$ [duplicate]","This question already has an answer here : Evaluate $\lim_{(x,y) \to (0,0), x+y \neq 0}{\frac{\ln(1-x-y)}{x+y} } $ (1 answer) Closed 5 years ago . I asked this question a while ago, but got no answer. Eventually I answered it myself, but I'm not completely sure whether my answer is correct or not. I don't know if it is correct to post another question about it, but I'd like my proof to be verified. So here it is: We want to show that $\forall \epsilon \gt 0 : \exists \delta \gt 0 : ||(x,y)||< \delta \implies |\frac{\ln(1-x-y)}{x+y}+1| \lt \epsilon$ . Fix $\epsilon \gt 0$ . We know that $\lim_{\phi \to 0} \frac{ln(1+\phi)}{-\phi} = -1$ . So there's $\delta_1 \gt 0$ such that $|\phi| \lt\delta_1 \implies |\frac{ln(1+\phi)}{-\phi}+1| \lt \epsilon$ . Let $\delta = \delta_1$ and $\xi = -x-y$ . Suppose $||(x,y)|| \lt \delta $ . Since all norms in $R^n$ are equivalent we can use the norm of the sum. Then: $||(x,y)|| = |x|+|y| \geq |x+y| = |\xi|$ . Since $|\xi| < \delta_1 $ , then $|\frac{ln(1+\xi)}{-\xi}+1| < \epsilon$ therefore $|\frac{ln(1-x-y)}{x+y}+1| < \epsilon  $ . So $\lim_{(x,y) \to (0,0), x+y \neq 0}{\frac{\ln(1-x-y)}{x+y} } = -1$ Q.E.D.","['multivariable-calculus', 'proof-verification']"
3183518,"Why is $X_{n-k,n}$ a good estimator for $U(\frac{n}{k})$?","I'm learning about Extreme Value Theory. In my class we're discussing the $U(t)$ -tail quantile which has the following definition: For a distribution function $F$ , the tail quantile function $U(t)$ is defined such that $$
P(X> U(t) ) = 1 - F(U(t)) = \frac{1}{t}, \,t\geq 1
$$ Suppose that you have a sample $X_1,\ldots, X_n$ from distribution function $F$ . Estimation of $U(\frac{1}{p})$ is based on the following result: For $F\in D(G_\gamma)$ , for $\gamma>0$ , iff $$
\lim_{t\to\infty}\dfrac{U(tx)}{U(t)} = x^\gamma,
$$ $U(tx)\approx U(t)x^\gamma$ . Now let $tx = \frac{1}{p}$ , and $t = \frac{n}{k}$ , where $k$ is a large integer but much smaller than $n$ . We then have $$
U\bigl(\frac1p \bigr) \approx U\bigl(\frac{n}{k} \bigr)\bigl( \frac{k}{np}\bigr)^\gamma
$$ I think that I understand all this. Now comes the part that I'm having trouble with to grasp: Let $X_{1,n}, \ldots, X_{n,n}$ be the order statistics of the sample $X_1, \ldots, X_n$ . $U(\frac{n}{k})$ can be estimated by the empirical quantile $X_{n-k,n}$ . (Why is this a good estimator? Think about the empirical distribution function $\hat{F}(x) = \frac{1}{n}\sum_{i = 1}^n I(X_i\leq x).)$ Question: Why is $X_{n-k,n}$ a good estimator for $U(\frac{n}{k})$ ? Intuitively I understand that it might would be a good estimator, since $P\bigl( X > U(\frac1p) \bigr) = p$ so that $U\bigl(\frac1p \bigr) = x_{1 -p}$ . Hence you would get that $P\bigl( X > U(\frac{n}{k}) \bigr) = \frac{k}{n}$ and $U(\frac{n}{k}) = x_{1 - k/n}$ . A sensible estimator for $x_{1 - k/n}$ would then be $X_{n-k, n}$ . I don't find this satisfying though, especially since I supposedly have to think about the empirical distribution function to understand why this would be a good estimator.","['statistics', 'probability-distributions', 'probability-theory', 'probability']"
3183677,Show that there exist $f \in L^1$ but $f^*$ is not integrable over the unit ball .,"In Stein's functional analysis, for some $0\lt t\le 1$ he defined $$
f(x)=
\begin{cases}
|x|^{-d}\log\left(\dfrac{1}{|x|}\right)^{-1-t}&\text{whenever }0\le |x| \le \frac{1}{2}\\ 
\\
f(x)=0 &\text{ otherwise}
\end{cases}
$$ and he state that $$
f^*(x)\ge c|x|^{-d}\log\left(\frac{1}{|x|}\right)^{-t},
$$ then $f^*(x)$ is not integrable over the unit ball. However, I can prove this only when $d=1$ . My attempt : When $d=1$ , $$\int\limits_0^{\frac12} \frac cx \log\left(\frac1x\right)^{\!-t-1} \mathrm{d}x =c \frac{(\log 2) ^{-t}}{t}$$ so $f \in L^1$ , and also we have $$
f^*(y) \ge \frac1y\int\limits_0^y \frac cx \log\left(\frac1x\right)^{\!-t-1} \mathrm{d}x=\frac{c'}{y} \log\left(\frac1y\right)^{\!-t}
$$ whenever $y \in \left(0,\frac12\right)$ and RHS is not integrable over the unit ball . However, when $d \neq 1$ , we can not use the relation $$
\int \frac{f(x)}{x} \mathrm{d}x =\int f(x)\, \mathrm{d} \log(x),
$$ so how to deduce the desired conclusion?","['functional-analysis', 'real-analysis']"
3183681,Find Fraction of the Area of Square Shaded With Pink,"From the image below, the given and question is: They are two identical squares and four identical pink triangles. $'A'$ is the midpoint, what fraction of the square on the right is shaded pink? Now, I can very much understand that since $A$ is the midpoint, each of the $4$ identical triangles is split into a total of $8$ triangles with a {height:width}= ${4:1}$ and that the sides of the square is split into two lengths with ratio $1:3$ on where the pink lines intersect with it. However, with those I have no idea what to do next. Can anyone confirm the answer of $\frac{2}{5}$ and a solution?","['euclidean-geometry', 'geometry']"
3183718,Simplest ODE - Unique solution explanation,"Looking at Differential Equations, Dynamical Systems, and Linear Algebra, they introduce us to ODEs with this equation: $$\frac{dx}{dt} = ax$$ This can be re-written as: $$x'(t) = ax(t)$$ And the solution to this equation is: $$f'(t) = aKe^{at} = af(t)$$ They claim that there are no other solutions, and they support this claim with the following equation. Let $u(t)$ be any solution and compute the derivative of $u(t) e^{-at}$ : $$\begin{align} \frac{d}{dt}(u(t) e^{-at}) &= u'(t) e^{-at} + u(t)(-ae^{-at}) \\ &= au(t)e^{-at} - au(t) e^{-at} =0\end{align}$$ I do not follow how they go from $u'(t) e^{-at}$ to $au(t)e^{-at}$ Also, why are they proving that there are no other solutions by taking the solution that we found and multiplying it by some function $u(t)$ ?","['derivatives', 'ordinary-differential-equations']"
3183728,Proving Trigonometric “Definitions” [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 5 years ago . Improve this question The expression trigonometric “definitions” refers here, rather narrowly, to statements expressing stable relations between the sides of right triangle. Thus, for instance, the traditional definition of sine supposes that one has a demonstration that the ratios between opposite side and hypothenuses are independent of the size of the right triangle and are dependent instead on the amplitude of the angles of the right triangle. My question is the following: How these stable relations, simply assumed by most trigonometric “definitions,” can actually be demonstrated? A very similar question has been posted here but I remain unsatisfied by most answers — which seem to convoke either unnecessary complex mathematical objects or simplistic historical accounts. I guess, what I am looking for, is something like a geometrical proof — but am open to others!","['trigonometry', 'proof-writing', 'definition']"
3183737,A Problem on Tightness of Measures,"Can someone provide an example of probability measures $\{\mu_n\}$ and $\{\nu_n\}$ such that although $\int_{\mathbb{R}}f d\mu_n - \int_{\mathbb{R}}f d\nu_n \rightarrow 0$ for all continuous real-valued functions with compact supports, for no finite interval $I=(a,b)$ does it hold that $\mu_n(I)-\nu_n(I) \rightarrow 0$ . Taking the probability measures as delta functions would probably help meet the first requirement, but if both such sequences of delta functions march off to infinity, then the second requirement will get violated. Any suggestions would be appreciated.","['measure-theory', 'probability-theory', 'weak-convergence']"
3183772,Hartshorne Exercise III 3.2: $X$ is affine iff every component is affine,"I'm trying to solve the following exercise frome Hartshorne's Algebraic Geometry : Exercise III 3.2. Let $X$ be a reduced noetherian scheme. Show that $X$ is affine if and only if each irreducible component is affine Clearly, if $X$ is affine, the compoents are closed subschemes so affine as well. For the converse, I guess one  has to use the following Proposition, because the chapter is rather short, but contains this strong criterion to be affine: Proposition III 3.7. A noetherian scheme $X$ is affine iff $H^1(X, \mathcal{I}) = 0$ for every (coherent) sheaf of ideals $\mathcal{I} \subset \mathcal{O}_X$ iff $H^1(X, \mathcal{F}) = 0$ for all quasi-coherent sheaves $\mathcal{F}$ . But I don't know how to relate sheaf cohomology on $X$ to the cohomology the components. Two thoughts I had: If $i: Z \hookrightarrow X$ is an irreducible compoent with ideal sheaf $I_Z \subset \mathcal{O}_X$ , then the cohomology of the quotient sheaf $i_*\mathcal{O}_Z = \mathcal{O}_X / I_Z$ vanishes, because I can take an injective resolution $\mathcal{O}_Z \to \mathcal{I}^*$ on $Z$ , and take the push-forward $i_*\mathcal{I}^*$ of this. Then the sheaves $i_*\mathcal{I}^k$ remain flasque, and I still get a resolution of $i_*\mathcal{O}_Z$ , which can be checked on the stalks. So we can use this resolution to commute the cohomology groups of $i_*\mathcal{O}_Z$ on $X$ , which will be the same as cohomology of $\mathcal{O}_Z$ on $Z$ , i.e. $0$ . Is that reasoning correct? Do I have to use Exercise 2.3 and 2.4? That seems to give a tool to compute cohomology on $X$ , when cohomology on the components can be computed, but I'm not sure what the relation between $H^i_Y(X, \cdot)$ and $H^i(Y, \cdot)$ is. If part 1. here is correct, then I think $$H^i_Y(X, i_*\mathcal{F}) = H^i(Y, \mathcal{F}) = H^i(X, i_*\mathcal{F})$$ is true, because all three groups can by computed by taking the resolution $i_*\mathcal{I}$ . But even if 1. and 2. work out, I still don't know how to show that $H^1(X, I) = 0$ for all ideal sheaves $I$ .","['sheaf-cohomology', 'noetherian', 'affine-schemes', 'algebraic-geometry', 'schemes']"
3183780,Find the $P(\theta - 0.1 \leq MLE \leq \theta + 0.1)$,I have a continuous random variable with density: $f(x|\theta) = \frac{\theta}{x^{\theta+1}}$ . I have calculated the MLE( $\hat\theta$ ) as: $\frac{n}{\sum_{i}^{n}log(x_i)}$ I am stuck on figuring out how to estimate $P(\theta - 0.1 \leq \hat\theta \leq \theta + 0.1)$ ? Thank you.,"['statistics', 'probability', 'maximum-likelihood']"
3183789,How many degrees of freedom in 4D space,"In 1D there is 1 translational and 0 rotational d.o.f. In 2D there are 2 translational and 1 rotational d.o.f. In 3D there are 3 translational and 3 rotational d.o.f. this would suggest there are 4 translational and 6 rotational d.o.f in 4D My query is, is that all? Are there other other types of d.o.f. that are neither rotational nor translational? If there are no others, is there any reason why degrees of freedom only depend on 1 or 2 axes? Presumably, in ND we have  d.o.f. $= \binom{N}{1} + \binom{N}{2}$ for $N \geq 2$ Thanks in advance for any help. I don't know what tag to give this.",['combinatorics']
3183809,Probability and Statistical Modelling Proof (Negative Binomial into Poisson),"The Negative Binomial RV $X$ models the number of trials until the $r$ -th success in a sequence of independent Bernoulli Trials with probability of success $p$ in each trial. So, if $q = 1 - p$ , $$P(X = k)= \begin{pmatrix} k-1 \\r-1 \end{pmatrix}p^rq^{k-r},k=r,r+1,\dots.$$ Let $Y = X - r$ . Suppose that $r\to\infty$ and $q\to 0$ so that $rq\to\lambda$ . Show that, for fixed $m=0,1,\dots$ $$P(Y=m)\longrightarrow\frac{\lambda^m}{m!}e^{-\lambda}.$$ So what I did so far was Let $r=\frac{\lambda}{q}$ ,with $q\to 0$ Then $P(Y=m) = P(X=r+m)$ So I got $$P(X = r+m)=\begin{pmatrix}\frac{\lambda}{q}+m-1\\ \frac{\lambda}{q}-1 \end{pmatrix} p^{\frac{\lambda}{q}}q^{m}, m=0,1,\dots.$$ and I don't know what to do next, can someone help me out ?","['statistics', 'negative-binomial', 'poisson-distribution', 'binomial-distribution', 'probability']"
3183831,Find function $f$ such that $(p*f)(x) = xf(x)$,"Question: The function $p(x)$ is defined as $p(x) = e^{-x}$ for $x>0$ and $p(x) = 0$ for $x<0$ .
  Find the Fourier Transform of $p(x)$ and use the convolution theorem to find $f(x)$ such that: $$\int_0^{\infty} p(y)f(x-y) dy = xf(x)$$ My attempt: I have found $\hat{p}(k) = \frac{1}{1 + ik}$ . I took the convolution of both sides and obtained the ODE $$\hat{f}(k) = i(1 + ik)\hat{f}'(k)$$ which I solved to yield $$\hat{f}(k) = \frac{1}{A(1 + ik)}$$ where $A$ is an arbitrary constant. After inverting this using the expression for $\hat{p}(k)$ earlier, and substituting into the original question, I get the left hand side integral diverging to infinity. I cannot find my mistake and am unsure how to progress. Could someone please point me in the right direction?Thank you.","['convolution', 'fourier-analysis', 'fourier-transform', 'ordinary-differential-equations']"
3183911,Is there a formula for $[F_n : V_{\{x^3\}}(F_n)]$?,"Suppose $F_n$ is a free group of rank $n$ . It is a rather well known fact, that $b_3(n) = [F_n : V_{\{x^3\}}(F_n)]$ is finite for all $n \in \mathbb{N}$ .  Is there a some sort of formula for $b_3(n)$ ? Here $V_Q$ is the verbal subgroup for the collection of group words $Q$ . The solution of a similar problem for $b_2(n) = [F_n : V_{\{x^2\}}(F_n)]$ is quite obvious: $b_2(n) = 2^n$ (as $C_2^n$ is the only $n$ -generated group of exponent $2$ ) However, similar considerations do not work for $b_3$ (as, for example $C_3 \times C_3$ and $UT(3, 3)$ are both $2$ -generated groups with exponent $3$ , but have different orders). However, using that method a lower bound can be constructed: $$b_3(n) = [F_n : V_{\{x^3\}}(F_n)] \geq [F_n : V_{\{x^3, [x, y]\}}(F_n)] = 3^n$$ Attempting to find an upper bound on $b_3(n)$ by counting cube-free words (something similar can also be done to $b_2(n)$ ) is doomed to fail too, as even for $n = 2$ , there are infinitely many of them: For what $n$ is $W_n$ finite?","['verbal-subgroups', 'combinatorial-group-theory', 'abstract-algebra', 'free-groups', 'group-theory']"
3183916,Number of points inside a shape on the Cartesian plane,"I was wondering if there is a formula which can help in finding number of points on a shape on the Cartesian plane, knowing that the shape isn't a rectangle nor a square. For example: consider an ellipse of equation $ax^2 + by^2 \le c$ , Calculate number of points inside that ellipse (number of integer solutions for the equation).","['algebra-precalculus', 'functions']"
3183997,"Can the distinction between membership and inclusion be used to answer the question "" how could a line be made of indivisible points""? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 5 years ago . Improve this question A little dialogue aiming at explaining the question: A - What is a line ? B - A set of points that has no width, no depth, but has length, "" a line is a breadthless length"" ( Euclid, Bk1, Df2) A - What is a point? B - Something indivisible, ""that which has no part"" ( Bk1, Df1) says Euclid,  no ""extension"". A - How could a line be extended in length  if its parts have absolutely no length? For, having no part, points certainly  have no length either. B - I said a line is a set of points .  But did I say that these points were the parts of the line? (The context of this question is basic geometry. ) My question: how to caracterize the mistake made by person A? is person B right when she explains the mistake in terms of membership/ inclusion confusion? Can one clarify the loose expression ""being made of points"" by saying (1) yes a line is made of points as elements ( = members)  , but(2) it is not made of points as parts ( the parts of the line being not points, but subsets of points)?","['elementary-set-theory', 'geometry']"
3184022,Computing the expectation of the number of balls in a box [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question There are $r$ boxes and $n$ balls. Each ball is placed in a box with equal probability, independently of the other balls. For each $1 \leq i\leq r$ , let $X_{i}$ be the number of balls in box $i$ . Compute $\mathbb{E}\left[X_{i}\right],\ \mathbb{E}\left[X_{i}X_{j}\right]$ . I am preparing for an exam, and I have no idea how to approach this problem. Can someone push me in the right direction? Symmetry reasoning makes it clear that $\mathbb{E}\left[X_{i}\right]$ doesn't depend on $i$ . Likewise, $\mathbb{E}\left[X_{i}X_{j}\right]$ doesn't depend on the concrete values of $i$ and $j$ but only (if at all) on whether $i=j$ or $i\neq j$ . But this doesn't actually compute these expectations.",['probability-theory']
3184078,Question about Kallenberg's proof of Doob-Dynkin Lemma,"The following is the proof for the Doob Dynkin Lemma from Kallenberg's Foundations of Modern Probability. In the theorem, $(S,\mathscr{S})$ is assumed to be Borel, i.e. Borel isomorphic to a Borel subset of $[0,1]$ . Thus, it is natural to assume that $S \in \mathscr{B}([0,1])$ . But how can we modify $h$ , to further reduce to the case when $S = [0,1]$ ?","['borel-sets', 'measure-theory', 'analysis', 'real-analysis']"
3184115,Solutions of the differential equation $\dot{x}^2-2x=1$,"I am studying how to solve certain nonlinear differential equations and am currently trying to solve the equation $\dot{x}^2-2x=1$ , where $x$ is a function of $t$ , with initial condition $x(1)=1$ . My method is as follows: Solving for $x$ in this equation gives $x=\frac{1}{2}(\dot x-1)$ . Let $p=\dot x$ , then differentiating with respect to $t$ gives $\frac{d}{dt}x=\dot x=\frac{d}{dt}\frac{1}{2}(\dot x-1)=\frac{1}{2}(2\ddot x\dot x)$ by chain rule, so we get the first-order differential equation $p=pp'$ . If $p\equiv0$ then we get the solution $x(t)\equiv C$ . Otherwise, dividing by $p$ gives $p'=1$ , so $p=t+c_1$ and $x=\frac{t^2}{2}+c_1t+c_2$ . Plugging back into the original equation: $$(t+c_1)^2-2(\frac{t^2}{2}+c_1t+c_2)=1$$ $$t^2+2c_1t+c_1^2-t^2-2c_1t-2c_2=1$$ $$c_1^2-2c_2=1$$ $$c_1^2=1-2c_2$$ $$c_1=\pm\sqrt{1-2c_2}$$ Now applying the initial condition $x(1)=1$ : $$1=\frac{1}{2}\pm\sqrt{1-2c_2}+c_2$$ Solving this equation for $c_2$ I get $c_2=-\left(\sqrt5+\frac 5 2\right)$ and $c_2=\sqrt5-\frac 5 2$ . Therefore, the solution is $$x(t)=\frac{t^2}{2}\pm \sqrt{1+2(\frac 5 2\pm\sqrt5)}-\frac{5}{2}\pm\sqrt5$$ But according to WolframAlpha the solutions are $$x(t)=\frac{1}{2}\big(t^2\pm2(1+\sqrt3)t\mp(2\sqrt3)+3\big)$$ Where am I going wrong in my approach? Did I make an algebraic mistake or is there something more deeply wrong with this method?","['calculus', 'ordinary-differential-equations']"
3184175,Dinner party courses needed to have everyone sit with everyone else (repeats allowed),"There are a large number of similar questions on this site, but most of them seem to have an additional constraint that I do not have. I am organizing a dinner party for $P$ people sitting at $T$ tables, with an equal number of people sitting at each table. (Feel free to assume that $P$ is a multiple of $T$ .) For each of $C$ dinner courses everyone moves to a new table (prescribed by me). What is the least number of dinner courses needed for everyone to sit at a table at least once with everyone else? Unlike the Social Golfer Problem, it is acceptable to have arrangements of tables where a subset of the guests have sat together in a prior course. I have a simulated annealing system that attempts to solve this via brute force and luck. However, given a party of 40 people split into 4 tables, eating 6 courses total, the best results I've produced so far have every person each missing 4 or 5 other guests. Due to separate constraints that are outside the scope of this discussion (see below), I'm not actually looking to generate a perfect dinner party, nor to extend $C$ until everyone meets. Instead, I'm trying to find out if the $\{P=40, T=4, C=6\}$ setup is fundamentally incapable of having everyone sit together. Some related questions I've found: Social Golfer Problem - Quintets Split a large team into standup groups so that everyone talks to everyone else once a week Repeatedly assigning people to subgroups so everyone knows each other 25 people seated at five tables of five. How rotate so that everyone meets, but nobody meets twice? Everyone meets everyone else. Rearrangement of groups such that no two members meet again Number of meetings needed for everyone to know everyone (For the curious, the background is that this actually a sports league of $P$ players, $T$ teams, and $C$ rounds of play. There are constraints on the team composition beyond just the social: balanced player gender, skill, height, experience, and so forth. I have no control over $P$ , $T$ , or $C$ , and I have to use the simulated annealing system to help balance all factors. I'd like to be able to defend—or not—why each person in the social league did not get to play with about 10% of the other players.)","['combinatorial-designs', 'combinations', 'combinatorics']"
3184205,Is ${\lim\limits_{x \to 0}} \frac{f(x^2+1)}{x^2+2} = {\lim\limits_{t \to 1}} \frac{f(t)}{2}$ always true?,"Is ${\lim\limits_{x \to 0}} \frac{f(x^2+1)}{x^2+2} = {\lim\limits_{t \to 1}} \frac{f(t)}{2}$ always true? My math teachers were arguing today if the statement is always true. One teacher gave a counterexample of where $f(x) = \sqrt{x-1}$ . Eventually, they said that it came down to different textbook definitions of continuity and limits. Is there any other reasoning to prove this to be true or false?","['limits', 'calculus', 'continuity']"
3184251,Problem related to fixed point on $S^1$,"Suppose $f:S^1\rightarrow S^1$ is a map not homotopic to the identity map. Show there exists $x,y\in S^1$ such that $f(x)=x$ and $f(y)=-y$ ? 
(If there are no fixed points, then $f$ is homotopic to the identity map? and if no such $y$ exists then $f$ is homotopic to the identity? How can I show this?)","['general-topology', 'algebraic-topology']"
3184282,Asymptotic expansion of the confluent Heun function,"Is the asymptotic expansion of the confluent Heun function known?? The confluent Heun's differential equation is given by \begin{equation}
 y''(z) + \left( \epsilon + \frac{\gamma}{z}+ \frac{\delta}{z-1} \right) y'(x) + \left(\frac{\alpha z-q}{z(z-1)} \right) y(z)=0
\end{equation} One of the solution, $Hc(\epsilon,\delta,\gamma,\alpha,q;z)$ , is defined by $$ Hc(\epsilon,\delta,\gamma,\alpha,q;z=0) = 1 ,\\
 Hc'(\epsilon,\delta,\gamma,\alpha,q;z=0) = -\frac{q}{\gamma}.$$ I wonder if the asymptotic expansion of this function at $z\to -\infty$ is known. Thank you so much!","['special-functions', 'ordinary-differential-equations']"
3184335,Does this proof that $\mathbb{D}$ is countable work?,"I am trying to prove that the set $\mathbb{D}$ of finite decimals is countable. My proof seems too simple to work out - I simply list the all of the decimals with $N$ digits for all $N\geq 1$ , starting with $N=1$ and working up from there. It seems like I would reach every single decimal eventually and end up with a bijection with $\mathbb{N}$ , as there are only a finite number of decimals with $N$ digits. Does this proof work?",['elementary-set-theory']
3184336,"$\varphi_{X+Y}(t)=\varphi_X(t) \cdot \varphi_Y(t)$, but X and Y are not independent","Consider $X,Y$ random variables with joint distribution: $$f_{X,Y}(x,y)=\begin{cases}
\frac14\left[ 1+xy(x^2-y^2)\right] &  |x|\leq 1,\;|y|\leq 1  \\
0 & \text{otherwise}
\end{cases}$$ Proof $\varphi_{X+Y}(t)=\varphi_X(t) \cdot \varphi_Y(t)$ , but $X$ and $Y$ are not independent. Here $\varphi_V(t)$ denotes a characteristic function of random variable $V$ . My step-by-step calculation is shown below, but I think something is wrong. 1. $f_X(x)=\frac{1}{2}$ if $|x|\leq 1$ 2. $f_Y(y)=\frac{1}{2}$ if $|y|\leq 1$ 3. $f_{X,Y}(x,y)\neq f_X(x)f_Y(y)$ implies X and Y are not independent 4. $\varphi_X(t)=\frac{1}{2it}(e^{it}-e^{-it})$ 5. $\varphi_Y(t)=\frac{1}{2it}(e^{it}-e^{-it})$ 6. $\varphi_{X+Y}(t)=\frac{1}{2it}(e^{it}-e^{-it})$ Obviously I got $\varphi_{X+Y}(t) \neq \varphi_X(t) \cdot \varphi_Y(t)$ . What went wrong?","['characteristic-functions', 'probability']"
3184350,Prove that the rotation of sums is equal to the rotation of products,"So the question starts off: Prove $$\ e^{t_1+t_2} = e^{t_1}e^{t_2}$$ E(t) is a unique solution to $\dot{E} = E, E(0) = 1$ .
Let $E_1(t) = E(t_1 + t)$ , and E_2(t) = E(t_1)E(t) $$\dot E_1 (t) = \dot E_1 (t_1 + t) = E(t_1+t) = E_1 (t); E_1(0) = E(t_1)$$ $$\dot E_2 (t) = E(t_1)\dot E (t) = E(t_1)E(t) = E_2(t); E_2(0) = E(t_1)$$ Therefore(by uniqueness and existence theorem I think): $$E_1(t) = E_2(t)$$ Which implies: $$E(t_1+t) = E_1(t) = E_2(t) = E(t_1)E(t)$$ Then by setting $t = t_2$ we get our desired result. Then the question asks to prove: $$R(t_1+t_2) = R(t_1)R(t_2)$$ where $$R(t) = \begin{bmatrix}\cos(t)&-\sin(t)\\\sin(t)&\cos(t)\end{bmatrix} $$ Given: $R_1(t) = R(t+t_2)$ and $R_2(t) = R(t)R(t_2)$ Prove by a similar argument to the one above. Any suggestions on how to approach this?","['matrices', 'linear-algebra', 'ordinary-differential-equations', 'rotations']"
3184351,Limit superior and inferior when one part diverges,"How can I find the limit superior and inferior of given sequence: $x_n = (1 + \frac{1}{2n})\cos{\frac{n\pi }{3}}$ as $ n \in \mathbb N $ I did the following: since $\lim_{n\to\infty}(1 + \frac{1}{2n}) = 1$ and the second term' limit oscillates between -1 and 1, I decided that the supremum should be $1$ and infimum should be $-1$ .
But this is an incorrect answer. What I do wrong? Thank you. UPD: It is a task from the online-courses site and there is an automatic answer checking system. So, as I said in my question, answer $-1$ and $1$ not passed and there is no explanation why. I believe there should be used Bolzano–Weierstrass theorem to find all possible convergent subsequences, and then find limits for each of them...","['limits', 'calculus', 'limsup-and-liminf']"
3184446,Cantor Set Homeomorphic to Inverse Limit Space,"For each positive integer $n$ let $X_n = \left\{1, 2, 3, ..., 2^n \right\}$ with the discrete topology and let $f_n : X_{n+1} → X_n$ be the function defined by: $f_n(i) = i$ for $1 ≤ i ≤ 2^n$ $f_n(i) = 2^{n+1} − i + 1$ for $2^n < i ≤ 2^{n+1}$ Then $X = lim_{←} \left\{X_i, f_i \right\}_{i=1}^{\infty}$ is homeomorphic to the Cantor set. I've been trying to find a homeomorphism for this for way too long... anyone know what it would be? 
I can take care of proving it's a homeomorphism once I have the function. Typically when finding a homeomorphism between a set and the Cantor set, I use the fact that a point of the Cantor set can be written as $\sum_{i=1}^{\infty} \frac{a_i}{3^i}$ for $a_i \in \left\{ 0, 2 \right\}$ .","['general-topology', 'cantor-set']"
3184449,Is there a way to generate individual uniformly distributed points on a sphere from a fixed amount of random real numbers per point? [duplicate],"This question already has answers here : How to generate random points on a sphere? (6 answers) Closed 5 years ago . The obvious solution of Lattitude & Longitude doesn't work because it generates points more densely near the poles, and the other thing I came up with (Pick a random point in the unit cube, if it's in the unit sphere map it to the surface, and restart if it's outside) doesn't always find a point within a fixed number of tries.",['geometry']
3184458,"If $\sum_{n=1}^\infty E(X_n-X_{n-1})^2/b_n^2 < \infty$, then $X_n/b_n \rightarrow 0$ a.s.","This is Durrett Exercise 5.4.9. I'm trying to show that if $X_n$ is a martingale, and $b_m \uparrow \infty$ , $\sum_{n=1}^\infty E(X_n-X_{n-1})^2/b_n^2 < \infty$ , then $X_n/b_n \rightarrow 0$ a.s.. If $X_n \in L^2$ , I can show that this reduces to Durrett Exercise 5.4.8, which I have solved, since the above also gives us that the the sum of $\sum_{n=1}^\infty E\left(\frac{X_n}{b_n}-\frac{X_{n-1}}{b_{n-1}}\right)^2<\infty$ , and then I can use orthogonality of martingale increments, and $L^p$ convergence theorem to conclude that it converges in almost surely and in $L^2$ , although I'm not sure that I can show it converges to 0. But, in this case, I am stuck and unable to proceed","['martingales', 'convergence-divergence', 'probability-theory']"
3184487,How to quickly solve partial fractions equation?,"Often I am dealing with an integral of let's say: $$\int\frac{dt}{(t-2)(t+3)}$$ or $$\int \frac{dt}{t(t-4)}$$ or to make this a more general case in which I am interested the most: $$\int \frac{dt}{(t+\alpha)(t+\beta)} \quad \quad \alpha, \beta \in \mathbb{R}$$ Basically any integral with decomposed polynomial of second degree in the denominator. Obviously this leads to sum of two natural logarithms. What I do is write down partial fractions equation and then solve system of linear equations (2 variables here): $$\frac{1}{(t+\alpha)(t+\beta)} = \frac{A}{t+\alpha} + \frac{B}{t+\beta}$$ After solving this I end up with some $A, B$ coefficients and I can solve the integral. Is there faster way to find $A, B$ ? Some algorithm or anything that I can follow and would always work for such case? Surely, solving that does not take much time but I just wonder if it could be done even faster. (bonus question: what if there were more variables, like 3 variables?) I would greatly appreciate all feedback as it could help me save countless number of minutes in the future.","['integration', 'calculus', 'partial-fractions', 'indefinite-integrals', 'quadratics']"
3184519,"Under what circumstances is a finite group uniquely determined by its ""conjugation table""?","Let $a\mathop{.}b \stackrel{\text{def}}{=} aba^{-1} $ denote conjugation by $a$ Suppose we define a matrix $M$ , the ""conjugation table"", associated with our finite group $G = (X,*_{\small{G}})$ as follows. (I'm considering the cells of $M$ to be formal sums of group elements (with the product of monomials defined in terms of the group operation), but I'm only using that machinery to talk about equivalence up to relabeling.) $$ M_{ij} \stackrel{\text{def}}{=} x_i \mathop{.} x_j = x_i x_j x_i^{-1} $$ I'm also thinking of two matrices $M$ and $M'$ as equivalent if they only differ by a permutation / relabelling, so $$ M \sim M' \stackrel{\text{def}}{\iff} MP=M'  \;\;\text{where $P$ is a permutation matrix} $$ or equivalently $$ M \sim M' \stackrel{\text{def}}{\iff} M_{ij} = M'_{\sigma i \sigma j} \;\;\text{where $\sigma$ is a permutation} $$ I can think of a case where an $M$ does not uniquely identify a group and a case where an $M$ does uniquely identify a group. I think a group is Abelian if and only if the following holds. (The ""if"" direction is trivial). $$ x_i \mathop{.} x_j = x_j \;\;\forall i,j $$ So, if $G$ has four elements and is Abelian, then it could be the cyclic group on four elements $Z_4$ or the Klein four group $V_4$ . $Z_4$ and $V_4$ are indistinguishable by their ""conjugation tables"". However, if $G$ has three elements, it can only be $Z_3$ since there's only one group of order 3. So, there are at least some circumstances under which a given $M$ is associated with exactly one group. Do we know what those circumstances are?",['group-theory']
3184598,"Prove $\sin(x) > x - \frac{x^3}{3!} $ on $(0, \sqrt{20})$","I'm having a bit of trouble with this because my attempted proof breaks down. Proof:
It is sufficient to show that $f(x) =  \sin(x) - x + \frac{x^3}{3!} > 0$ on $I = (0, \sqrt{20})$ . This is true if $f'(x)$ is strictly increasing on the interval and $f(0) \geq 0$ . We can apply this property on the first and second derivatives as well. We note $f^{(3)}(x) = -\cos(x) + 1$ . However I can only show that $f^{(3)}(x) \geq 0$ on $I$ since at $x = \frac{3\pi}{2}$ $f^{(3)}(x) = 0$","['trigonometry', 'taylor-expansion', 'inequality', 'real-analysis']"
3184675,Evaluating $\sum_{n=1}^\infty\frac{(H_n)^2}{n}\frac{\binom{2n}n}{4^n}$,"Question: How can we evaluate $$\sum_{n=1}^\infty\frac{(H_n)^2}{n}\frac{\binom{2n}n}{4^n},$$ where $H_n=\frac11+\frac12+\cdots+\frac1n$ ? Quick Results This series converges because $$\frac{(H_n)^2}{n}\frac{\binom{2n}n}{4^n}=O\left(\frac{\ln^2n}{n^{3/2}}\right).$$ My Attempt Recall the integral representation of harmonic number $$H_n=\int_0^1\frac{1-x^n}{1-x}d x$$ we have $$
S=\sum_{n=1}^\infty\frac1n\frac{\binom{2n}n}{4^n}\iint_{[0,1]^2}\frac{(1-x^n)(1-y^n)}{(1-x)(1-y)}d xd y\\
=\tiny\iint_{[0,1]^2}\frac{x y \log (4)-2 x y \log \left(\sqrt{1-x}+1\right)-2 x y \log \left(\sqrt{1-y}+1\right)+2 x y \log \left(\frac{1}{2} \left(\sqrt{1-x y}+1\right)\right)}{\left(\sqrt{1-x y}-1\right) \left(\sqrt{1-x y}+1\right)}dxdy\\
$$ This integral is too hard for me and Mathematica to compute. Numerical integration returns $12.6178$ , it agrees with the numerical summation of the original series. I tried to integrate with respect to $x$ , but failed.","['harmonic-numbers', 'calculus', 'definite-integrals', 'sequences-and-series']"
3184764,Taking the derivative of a differential equation,"My book jumps from $$\frac{\partial f}{\partial x}(x, g(x)) + \frac{\partial f}{\partial y}(x, g(x))g'(x) = 0 $$ to $$\frac{\partial^2 f}{\partial x^2}(x, g(x)) + 2 \cdot \frac{\partial f}{\partial x \partial y} (x, g(x))g'(x) + \frac{\partial^2 f}{\partial y^2}(x, g(x))(g'(x))^2 + \frac{\partial f}{\partial y}(x, g(x))g''(x) = 0.$$ It is left as an exercise to verify that this new equality can be obtained by differentiating both sides of the first equation. I've been trying to do this, but I haven't been able to get to the desired result. I'm sort of new to partial derivatives, and I would really appreciate it if someone can show me the steps that are taken when differentiating the first equation. I'm pretty sure my setup itself is wrong. I've looked at many examples now, but I still haven't been able to get anywhere, since they are not too similar to what I have I would really appreciate any help. Thanks My try: $$\frac{\partial}{\partial x}\left(\frac{\partial f}{\partial x}(x, g(x)) + \frac{\partial f}{\partial y}(x, g(x))g'(x)\right) $$ $$= \underbrace{\frac{\partial}{\partial x}\left(\frac{\partial f}{\partial x}(x,g(x)) \right)}_{\text{Term 1}} + \underbrace{\frac{\partial}{\partial x}\left(\frac{\partial f}{\partial y}(x, g(x))g'(x)\right)}_{\text{Term 2}}$$ Now computing Term 1: $$\frac{\partial}{\partial x}\left(\frac{\partial f}{\partial x}(x,g(x)) \right) = \frac{\partial^{2}f}{\partial x^{2}}(x, g(x)) \cdot \text{ some chain rule term} $$ What would the chain rule term be? I know in single-variable calculus, if you're doing the derivative of $f(g(x))$ , then you need to multiply by $g'(x)$ . But here, there are two variables.","['partial-derivative', 'multivariable-calculus', 'derivatives']"
3184782,"Prob. 1, Sec. 29, in Munkres' TOPOLOGY, 2nd ed: The subspace $\mathbb{Q}$ of $\mathbb{R}$ is not locally compact","Here is Prob. 1, Sec. 29, in the book Topology by James R. Munkres, 2nd edition: Show that the rationals $\mathbb{Q}$ are not locally compact. My Attempt: Here the topology on the set $\mathbb{Q}$ of rational numbers is the same as the subspace topology that $\mathbb{Q}$ inherits from the standard topology on the set $\mathbb{R}$ of real numbers. As the standard topology on $\mathbb{R}$ has as a basis the collection of all the open intervals of the form $(a, b)$ , where $a, b \in \mathbb{R}$ and $a < b$ , so by virtue of Lemma 16.1 in Munkres the subspace topology on $\mathbb{Q}$ has as a basis the collection of all the intersections $(a, b) \cap \mathbb{Q}$ , where $a, b \in \mathbb{R}$ and $a < b$ . Let $q$ be any point of $\mathbb{Q}$ . Let us suppose that $\mathbb{Q}$ is locally compact at $q$ . Then there exists a neighborhood $U$ of $q$ in $\mathbb{Q}$ and a compact subspace $C$ of $\mathbb{Q}$ such that $$ U \subset C. \tag{0} $$ As $U$ is open in $\mathbb{Q}$ , so $$U = V \cap \mathbb{Q} \tag{1} $$ for some open set $V$ in $\mathbb{R}$ . Now as $q \in V$ and as $V$ is open in $\mathbb{R}$ , so there exists an open interval $(a, b)$ on the real line such that $$q \in (a, b) \subset V. \tag{2}$$ Thus we have $$ a < q < b. $$ Let us choose some irrational numbers $c$ and $d$ such that $$ a < c < q < d < b. \tag{3}$$ Then by (2) above we have $$ q  \in  (c, d) \subset (a, b) \subset V,$$ and then by (1) above we also have $$q \, \in \,  (c, d) \cap \mathbb{Q} \,  \subset \, (a, b) \cap \mathbb{Q} \, \subset \,  V \cap \mathbb{Q} \,  = \,  U, $$ that is $$ q \, \in \,  (c, d) \cap \mathbb{Q} \,  \subset \, U, \tag{4}$$ and also $$ (c, d) \cap \mathbb{Q} \ = \  [c, d] \cap \mathbb{Q}, \tag{5} $$ because the endpoints $c$ and $d$ either interval are not in either of the two sets involved. Thus from (0), (4), and (5) above we also have $$q \,  \in \, [c, d] \cap \mathbb{Q} \, \subset \,  C. \tag{6}$$ Now $C$ is a compact subspace of $\mathbb{Q}$ ; moreover $\mathbb{Q}$ , being a metrizable space, is also a Hausdorff space, by the discussion in the third paragraph of Sec. 21 in Munkres. So by Theorem 26.3 in Munkres $C$ , being a compact subspace of the Hausdorff space $\mathbb{Q}$ , is also closed in $\mathbb{Q}$ . Therefore using (6) above we can also conclude that $$ [c, d] \cap \mathbb{Q} = \big( [c, d] \cap \mathbb{Q} \big) \cap C$$ is also closed in $C$ . Thus we have seen that $[c, d] \cap \mathbb{Q}$ is a closed subset of the compact space $C$ . So by Theorem 26.2 in Munkres the subspace $[c, d] \cap \mathbb{Q}$ is also compact (as a subspace of $C$ ); but since $C$ is a subspace of $\mathbb{Q}$ , therefore $[c, d] \cap \mathbb{Q} = (c, d) \cap \mathbb{Q}$ is also a compact subspace of $\mathbb{Q}$ . Therefore every open covering of $[c, d] \cap \mathbb{Q}$ has a finite sub-collection that also covers $[c, d] \cap \mathbb{Q}$ . However, as $c$ and $d$ are irrational numbers [Please refer to (3) above.], so we now show that what has stated in the preceding paragraph is not true. In what follows, the set $\mathbb{N}$ denotes the set of all the positive integers, namely, $1, 2, 3, \ldots$ . Let us consider the collection $$ \left\{ \ \left( c + \frac{d-c}{n+2},\,  d - \frac{d-c}{n+2} \right) \cap \mathbb{Q} \ \colon \  n \in \mathbb{N} \   \right\}. \tag{A} $$ This collection is an open covering of $[c, d]\cap \mathbb{Q}$ such that no finite subcollection of this collection can cover $[c, d] \cap \mathbb{Q}$ ; for if $$ \left\{ \ \left( c + \frac{d-c}{n_1+2}, \,  d - \frac{d-c}{n_1+2} \right) \cap \mathbb{Q},\  \ldots, \ \left( c + \frac{d-c}{ n_r + 2 }, \, d - \frac{d-c}{n_r +2} \right) \cap \mathbb{Q} \ \right\} \tag{B} $$ is any finite sub-collection of the collection in (A) above, where $n_1, \ldots, n_r \in \mathbb{N}$ such that $n_1 < \cdots < n_r$ , then \begin{align}
& \ \ \ \bigcup_{j=1}^r \left[ \left( c + \frac{d-c}{n_j + 2}, \, d - \frac{d-c}{n_j +2} \right) \ \cap \ \mathbb{Q} \right] \\ 
&= \left[ \bigcup_{j=1}^r  \left( c + \frac{d-c}{n_j + 2}, d - \frac{d-c}{n_j +2} \right) \right] \ \cap \ \mathbb{Q}  \\ 
&=  \left( c + \frac{d-c}{n_r + 2}, \,  d - \frac{d-c}{n_r +2} \right) \ \cap \ \mathbb{Q} \\ 
&\subsetneqq [c, d] \cap \mathbb{Q}. 
\end{align} thus showing that $[c, d] \cap \mathbb{Q}$ or $(c, d) \cap \mathbb{Q}$ [Refer to (5) above.] is not compact. Thus we have reached a contradiction. Therefore our supposition that $\mathbb{Q}$ is locally compact at $q$ is wrong. Hence $\mathbb{Q}$ is not locally compact at any point $q \in \mathbb{Q}$ . Is my proof correct in each and every detail? If so, then is my presentation clear enough too? If not, then where are the issues?","['general-topology', 'solution-verification', 'rational-numbers', 'compactness']"
3184784,Topology of a free group,I wonder is there any general properties/ restrictions to the possible topologies of a free group (to make it a topological group ofc). More generally do such restrictions exist for any group written as presentation?,"['geometric-group-theory', 'general-topology', 'topological-groups', 'group-theory']"
3184787,What is the tail $\sigma$-field?,"In the book ""probability : example and application"", they define a tail $\sigma$ -field as $\mathcal T=\bigcap_{n=1}^\infty \mathcal F_n'$ where $\mathcal F_n'=\sigma (X_n,X_{n+1},...)$ . They call $\mathcal t$ remote future and say that $A\in \mathcal T$ if and only if changing a finite number of value do not affect the occurrence of the event. I don't really understand what they want to say by this last sentence. Changing an infinite value of what ? of $A$ ? Could someone explain me better what represent $\mathcal T$ and in hat it is interesting ? I have as example, If $B_n\in \mathcal B(\mathbb R)$ , then $\{X_n\in B_n\ \ i.o.\}\in \mathcal T$ , but I don't really understand why. Also, if $S_n=X_1+...+X_n$ , then $\{\lim_{n\to \infty }S_n\ exist\}\in \mathcal T$ but $\{\limsup_{n\to \infty }S_n>0\}\notin \mathcal T$ , and I also don't understand why.",['probability']
3184802,"Are $C^\infty$ Functions with all derivatives positive on [a,$\infty$),a$\gt$0 always made of exponential?","Are there any $C^\infty$ real functions except the exponential family and gamma function family which has all the derivatives of same sign on an interval [a, $\infty$ ) with a $\gt$ 0 ?
I speculate the function is always uses exponential as building blocks and it is unique defining property of exponential functions. Please provide some instances otherwise. I have not been able to find any so far.","['exponential-function', 'derivatives', 'taylor-expansion', 'analytic-functions']"
3184838,Prove that $(A\setminus B)\cup (B \setminus A)\subseteq (A\cup B)\setminus(A\cap B)$,"I am asked to prove that $$
(A\setminus B)\cup (B\setminus A)\subseteq (A\cup B)\setminus(A\cap B)
$$ where $A$ and $B$ are sets. Could someone please check my solution and see if it is correct? I suppose that sets $A$ and $B$ are subsets of a global set $X$ . Fix $x\in (A\setminus B)\cup (B\setminus A)$ . Then $$
\begin{align}
x\in (A\setminus B)\cup (B\setminus A)&\Rightarrow
x\in A\setminus B\text{ or }x\in B\setminus A\\
&\Rightarrow
(x\in A\text{ and }x\not\in B)\text{ or }(x\in B \text{ and }
x\not\in A)\\
&\Rightarrow
[(x\in A\text{ and }x\not\in B)\text{ or }x\in B]\text{ and }
[(x\in A\text{ and }x\not\in B)\text{ or }x\not\in A]\\
&\Rightarrow
[(x\in A\text{ or }x\in B) \text{ and }
(x\in B\text{ or }x\not\in B)]\text{ and }\\
&\qquad
[(x\in A\text{ or }x\not\in A)\text{ and }
(x\not\in A\text{ or }x\not\in B)]\\
&\Rightarrow
[(x\in A\cup B \text{ and }
(x\in B\text{ or }x\in X\setminus B)]\text{ and }\\
&\qquad
[(x\in A\text{ or }x\in X\setminus A)\text{ and }
\neg(x\in A\text{ and }x\in B)]\\
&\Rightarrow
[x\in A\cup B \text{ and }
x\in B\cup(X\setminus B)] \text{ and }\\
&\qquad
[x\in A\cup(X\setminus A)\text{ and }\neg(x\in A\cap B)]\\
&\Rightarrow
[x\in A\cup B \text{ and }x\in X]\text{ and }
[x\in X\text{ and }x\not\in A\cap B]\\
&\Rightarrow x\in A\cup B\text{ and }
x\not\in A\cap B\\
&\Rightarrow x\in(A\cup B)\setminus(A\cap B)
\end{align}
$$","['elementary-set-theory', 'proof-verification', 'discrete-mathematics']"
3184883,The behaviour of $\operatorname{Im}(!n)$,"What's going on with the behaviour of the subfactorial's imaginary part? Background: Out of curiosity I tried to construct some recurrence relations using the Pochhammer symbol and out of those came some subfactorials. For example: $$a_{n+1}=a_n+(3)_n=a_n+3(3+1)(3+2)...(3+n-1).$$ Mathematica gave me: $a_n$ = $1/2 (-1)^n$ Gamma [ $n+3$ ] Subfactorial [ $-n-3$ ] $-$ Subfactorial [ $-3$ ]. Not having seen seen negative subfactorials before I googled ""negative subfactorial"" or ""subfactorial of negative numbers"" and some similar phrases, which gave 0 hits. Here's a plot: I also plotted the Gamma function (just to have something to relate to). So, I don't understand the behaviour of the imaginary part. Looking closer at the values of $\operatorname{Im}(!n)$ it appears that $$\sum _{n=-\infty}^0 \operatorname{Im}(!n)=-\frac{\pi}{e^2}.$$ Anyone who can shed some light on this? Some intuition? Better methods of visualization?","['pochhammer-symbol', 'factorial', 'sequences-and-series']"
3184886,When Bochner and Pettis integrals coincide?,"A well-known fact is that if a space $X$ is reflexive, then Dunford and Pettis integrals coincide. But I'm inerested in the relation between Bochner and Pettis integral. It seems obvious that if a function is Bochner integrable, then it is Pettis integrable as well. What are the necessary conditions so that they coincide? I thought that $X$ being separable is enough. Then the function we integrate becomes strongly measurable. Is it enough, or maybe separability is too much?","['integration', 'functional-analysis', 'real-analysis']"
3184889,Probability not to get a coupon : Coupon Collector's Problem,"We buy coupons for $m$ rounds (no matter if we have already collected them all or not and  we buy one coupon each round). What is the probability that we will not get the coupon number 1 in any of the $m$ rounds? Assume we have the Coupon Collector's Problem with $1 \dots n$ Coupons. Assume the event $X_1 = \text{""We don't get the first coupon""}$ so i think $X_1 \sim Bernoulli(1 - \frac{1}{n})$ . And after $m$ rounds we have the probability of $(1 - \frac{1}{n})^m$ to get not the first coupon - right ? And with the bernoulli's inequality we get $(1 - \frac{1}{n})^m \geq 1 - \frac{m}{n} $ . How can I calculate the expected value of the  number of  coupons that have not yet been collected after $m = n \cdot ln(n) + t$ round ( with m is an integer) ?  Is it $ E \geq m \cdot (1 - \frac{m}{n})$ ?","['probability-distributions', 'probability-theory', 'probability']"
3184902,Find the limit $\lim_{x\to 0} ((9+x)^x-9^x)^x$,Find the limit $$\lim_{x\to 0} \Big((9+x)^x-9^x\Big)^x$$ I simply cannot solve this limit. L'Hospital rule is useless(if you extract for example $9^x$ and rewrite) and there is nothing to gain if you consider $x$ as $1/n$ in order to somehow use the known limit $(1+1/n)^n \rightarrow e$,"['limits', 'calculus', 'real-analysis']"
3184930,Spherical mean property,"Let $ u(x)$ a continuos function over a domain $\Omega$ . Let $N\omega_n r^{N-1}$ the area of sphere in $R^N$ .
I don't understand the reason of this limit: $$ \dfrac{1}{N \omega_n \epsilon^{N-1}} \int_{\partial B_{\epsilon}(y)}u(x) d\sigma  \rightarrow u(y)$$ for $\epsilon \rightarrow 0$ . P.S. $u(x)$ is not an harmonic function.",['analysis']
3184949,Proof of an alternative form of expectation of a function of a random variable.,"How to prove the following statement? Let X be a positive r.v. and $f : \mathbb{R}^{+} \rightarrow \mathbb{R}$ a differentiable function
with continuous derivative and such that $f(X)$ is integrable. Then $\mathrm{E}[f(X)]=f(0)+\int_{0}^{+\infty} f^{\prime}(t) \mathrm{P}(X \geq t) d t$ The hint is to use Fubini Theorem or Tonelli's theorem for the third equality of the following equations. $\begin{array}{c}{\mathrm{E}[f(X)]=\int_{0}^{+\infty} f(x) d \mu(x)=\int_{0}^{+\infty} d \mu(x)\left(f(0)+\int_{0}^{x} f^{\prime}(t) d t\right)} \\ {=f(0)+\int_{0}^{+\infty} f^{\prime}(t) d t \int_{t}^{+\infty} d \mu(x)=f(0)+\int_{0}^{+\infty} f^{\prime}(t) \mathrm{P}(X \geq t) d t}\end{array}$ But I can't verify the conditions. The Lebesgue measure and probability measure are both $\sigma$ -finite. But I don't know how to do with the rest about integrability or non-negativeness. Is this statement true or we really need additional conditions?","['measure-theory', 'probability-theory']"
3184951,Smooth covering maps and the fundamental group,"Let $M$ be a smooth, connected and locally path-connected manifold, and let $\pi: \tilde{M}\to M$ be its universal cover. Let $\text{Aut}_\pi(\tilde{M})$ be the group of smooth covering transformations. We know that in the continuous case, the group of (not necessarily smooth) covering transformations of the universal cover is isomorphic to the fundamental group $\pi_1(M, q)$ (see for example [LeeTM, Cor. 11.32]). However, I do not understand whether we still have such a group isomorphism when restricting ourselves to smooth covering transformations. So my question is: What is the relationship between the fundamental group of a smooth manifold and the group of smooth covering transformations on its universal cover? [LeeTM] John Lee. Introduction to Topological Manifolds. (2000) Springer.","['automorphism-group', 'covering-spaces', 'smooth-manifolds', 'differential-geometry']"
3184969,$|x_{n + 1} - x_n| < \frac{1}{2^n} \Rightarrow (x_n)$ is Cauchy [duplicate],"This question already has answers here : How to show if $|a_{n+1} - a_{n}| \le \frac{1}{2^n}$ then the sequence is Cauchy. (3 answers) Closed 5 years ago . Let $(x_n)$ be a real sequence with the property that for all $n \in \mathbb{N}$ , $$|x_{n + 1} - x_n| < \frac{1}{2^n}$$ I want to show, using the definition of a Cauchy sequence, that $(x_n)$ must be Cauchy. I have found that the property implies that for any $(m, n) \in \mathbb{R}^2$ , assuming without loss of generality that $m > n$ , it must be true that $$|x_n - x_m| \leq \sum\limits_{i = n}^m \frac{1}{2^i}$$ How can I proceed from there ? Is this even the right way to approach this problem?","['cauchy-sequences', 'analysis', 'sequences-and-series']"
3185010,Positive and increasing function?,"Let $f:\mathbb{R}_+\to\mathbb{R}_+$ with $f(0)=0$ and $f\geq 0$ . 
There exists a constant $\varepsilon \in (0,1)$ such that $f(y)\geq \varepsilon \left( \frac{y}{x}\right) f(x)$ for every $y\geq x\geq 0$ . 
Is it possible to conclude that $f$ is increasing?","['functions', 'real-analysis']"
3185053,Prove that $f$ is bijective.,"We have that $f:\mathbb{R} \to \mathbb{R}$ is continuous and that $|f(x) - f(y)| \geq |x-y|$ for all $x,y \in \mathbb{R}$ . How do I show that $f$ is bijective? Injective is easy to show because if $f(x) = f(y)$ then $0 \geq |x-y|$ so $x=y$ . How do I show surjective?","['functions', 'analysis']"
3185071,Identifying the group in GAP,"I am defining a matrix group in GAP . I know that its a finite group, and can compute its order. Using sonata package and commands like AllGroups( Size( G ) ) and IsIsomorphicGroup( G, H ) commands, I can find the Group-ID in the GAP database. I would like to identify this group with a well-known group like Dihedral, Quaternion, Cyclic, etc. Is there any way to achieve this? m1 := [[0,-1],[1,0]] ;
m2 := [[0,1],[1,0]] ;
G := Group( m1, m2 );
Size( G ); One option I can think is to define these standard groups and check if $G$ is isomorphic to any of them! For example, IsCyclic( G ); # This is easy!
Q := QuaternionGroup( Size( G ) );
IsIsomorphicGroup( G, Q );
D := DihedralGroup( Size( G ) );
IsIsomorphicGroup( G, D ); I know the term well-known is a vague, but these are the groups, I would understand from my textbook! A possible (vague) general question can be asked, are there named groups in GAP?","['gap', 'group-theory', 'computer-algebra-systems']"
3185074,Circular reasoning in L'Hopital's rule,"Suppose we have a function $f(x)$ that satisfies: $$\lim_{x\to\infty}f(x)=L$$ Where $L\in\mathbb{R}$ . Is this true? $$\lim_{x\to\infty}f'(x)=0$$ My approach was simply this: $$\lim_{x\to\infty}f(x)=\lim_{x\to\infty}\frac{xf(x)}{x}=L$$ And applying L'Hospital's rule we have: $$\lim_{x\to\infty}\frac{xf(x)}{x}=\lim_{x\to\infty}\frac{f(x)+xf'(x)}{1}=L$$ $$\lim_{x\to\infty}f(x)+xf'(x)=L+\lim_{x\to\infty}xf'(x)=L$$ And finally: $$\lim_{x\to\infty}xf'(x)=0$$ Now, the only way this is possible is if $\lim_{x\to\infty}f'(x)\neq\infty$ and $\lim_{x\to\infty}f'(x)\neq A\in\mathbb{R}$ , because otherways the $\lim_{x\to\infty}xf'(x)$ would go to infinity. In conclusion, $\lim_{x\to\infty}f'(x)=0$ Is this in any way circular reasoning? I'm especially worried about the part when we apply the L'Hospital's rule.","['limits', 'derivatives']"
3185086,Geometric problem about ratios of line segments: How to transform the limiting case method to a rigorous answer?,"In $\triangle ABC$ , $D, E, F, G$ are points on the sides of the triangle such that $BD:DE:EC=1:2:3$ , $AF:CF=1:1$ , and $AG:BG=2:3$ . Find the ratio $FH:DH$ . My classmate has come up with a brilliant way to do this. He argued that if we let $$AC=1, AB=5,BC=6,$$ The triangle will collapse into a straight line. We can observe directly $$FH:DH=2.5:2=5:4$$ Despite the lack of rigor, this method successfully computes the right solution. My question is: Can we transform the limiting case method (as I would call it) to a rigorous answer?","['triangles', 'geometry', 'ratio']"
3185168,Arrange points such that translates of orthants separate subsets of them,"Is it possible to arrange $n$ distinct points $A = \{x_1, \ldots, x_n\} \subseteq \mathbb R^k$ so that every subset $B \subseteq A$ could be written as $$
 (y_B + \mathbb R_{\ge 0}^k) \cap A
$$ for some point $y_B \in \mathbb R^k$ , i.e., $B = (y_B + \mathbb R_{\ge 0}^k) \cap A$ . In some sense this means that the translates of the orthants $y_B + \mathbb R_{\ge 0}^k$ separate all subsets of $A$ . Is this possible if $k < n$ ? If $k = n$ (or more generally $k \ge n$ ) this is possible. Let us denote the $j$ -the coordinate of some point $x$ by $\pi_j(x)$ , for example $\pi_2((1,2,3)) = 2$ .
Now let $A = \{x_1, \ldots, x_{n-1}\}$ be some such arrangement in $\mathbb R^{n-1}$ . Then we can 
embed this into $\mathbb R^{n-1} \times\{0\} \subseteq \mathbb R^n$ , hence we suppose the $n$ -coordinate of the $x_i$ is zero, and also of the $2^{n-1}$ points $y_B$ for $B \subseteq A$ too. 
Let $x := \max_{B\subseteq A} \max_{j=1,\ldots,n-1} \pi_j(y_B)$ .
Set $x_n = (x,\ldots,x,-1)$ .
Then $x \notin y_B + \mathbb R_{\ge 0}^n$ for all $B \subseteq A$ . Now consider $y_{B \cup \{x_n\}} := (\pi_1(y_B), \ldots, \pi_{n-1}(y_B), -1)$ ,
we have $$
 (y_{B\cup \{x_n\}} + \mathbb R_{\ge 0}^n) \cap (A \cup \{x_n\}) = B \cup \{x_n\}.
$$ Noting that for $n = 1$ everything is trivial so we can inductively find such an arrangement of $n$ points in $\mathbb R^n$ . I somehow think it is not possible if $k < n$ (for example you cannot do it if $k = 1$ ). But I do not have an argument for this...","['discrete-geometry', 'combinatorics', 'geometry', 'discrete-mathematics']"
3185187,Is there a good way to show that the order of element in $S_7$ are at most $12$?,The only solution would be going through all cycle types of all permutations which is a lot of work. Is there any smarter solution than this one? Thank you in advance!,"['permutations', 'finite-groups', 'abstract-algebra', 'symmetric-groups', 'group-theory']"
3185211,What does QR decomposition have to do with least squares method?,"I know that QR decomposition is a mean to solve a system $Ax=b$ by doing $A = QR$ and then solving $Qy = b$ and then $Rx=y$ . I know that the least squares method is used to find $\min ||Ax-b||$ , that is, it can find the $x$ that is closest to solve $Ax=b$ or that solves it exactly. I often see QR decomposition in context of least squares but I can't see what they have in common.","['numerical-linear-algebra', 'numerical-methods', 'linear-algebra']"
3185235,"An infinite $\sigma$-algebra contains a infinite sequence of disjoint nonempty sets, my attempt.","As stated in the title the question is ""Show that an infinite $\sigma$ -algebra contains a infinite sequence of disjoint nonempty sets"". I've seen this question asked a lot here, many with different answers. I'd like to know if my approach to it is correct. Consider $\mathcal{A}$ an infinite $\sigma$ -algebra on $X$ and define $$\mathfrak{C}=\{\mathcal{C}\subset \mathcal{A}-\{\emptyset\},\, \mathcal{C}\text{ is a disjoint collection of subsets} \}$$ Let show that there exists finite $\mathcal{C}\in\mathfrak{C}$ of arbitrarily large size. If this wasn't the case, take $N=\max\{|\mathcal{C}|,\,\mathcal{C}\in \mathfrak{C}\}$ , there exists $\mathcal{C}_0$ such that $|\mathcal{C}_0|=N$ and therefore $\mathcal{C}_0=\{E_1,\dots,E_N\}$ . If $\bigcup_{n=1}^N E_n \neq X$ then $\mathcal{C}_0$ would not be maximal as $\mathcal{C}_0\cup \{X-\bigcup_{n=1}^N E_n\}$ would be a collection of $N+1$ disjoint subsets, therefore we have $\bigcup_{n=1}^N E_n = X$ . Now consider $\mathcal{A}'$ , the $\sigma$ -algebra generated by $\mathcal{C}_0$ , $\mathcal{A}'$ will be finite due to $\mathcal{C}_0$ being finite. Since $\mathcal{A}$ is infinite there exists $E\in \mathcal{A}-\mathcal{A}'$ . For some $n_0$ we must have $E_{n_0}\not\subset E$ and $E_{n_0}\cap E\neq \emptyset$ , otherwise we would have that for all $n$ either $E_n\subset E$ or $E_n\cap E=\emptyset$ meaning $$E=\bigcup_{E_n\cap E\neq \emptyset} E_n\in \mathcal{A}'$$ Now, set $E'_{n_0}:=E_{n_0}\cap E\in \mathcal{A}-\{\emptyset\}$ and $E_{N+1}:=E_{n_0}-E'_{n_0}\in \mathcal{A}-\{\emptyset\}$ . We have $E_{n_0}=E'_{n_0}\cup E_{N+1}$ where the union is disjoint, moreover $$\mathcal{C}:=\{E_1,\dots,E'_{n_0},\dots,E_N,E_{N+1}\}\in \mathfrak{C}$$ and $|\mathcal{C}|=N+1$ . This contradicts the maximality of $N$ , therefore there exists finite $\mathcal{C}\in\mathfrak{C}$ of arbitrarily large size. EDIT: As detailed in the comments there was a mistake, I'll try to see if I can salvage part of this proof.","['elementary-set-theory', 'measure-theory', 'proof-verification', 'real-analysis']"
3185304,A sequence which converges for an infinity of $x$'s,"Consider the real sequences $(a_n) _{n\ge 1}$ , $(b_n) _{n\ge 1}$ , $(c_n) _{n\ge 1}$ and $p_n(x) =(x-a_n) (x-b_n) (x-c_n)$ . Prove that if $p_n(x) $ converges for an infinity of values of $x$ , then it converges $\forall x\in \mathbb{R} $ . My idea was to consider the set $M=\{x\in \mathbb{R}| \lim\limits_{n\to \infty} p_n(x) \in \mathbb{R} \} $ . Obviously, there exist $a=\sup M$ and $=\inf M$ . From here, I think that I should either prove that $a=\infty$ and $b=-\infty$ or that $p_n(x) $ is bounded and then use this somehow. Anyway, I can't make any progress on this.","['sequences-and-series', 'polynomials', 'real-analysis']"
3185323,Riemannian distance via exponential map,"Let $(M,g)$ be a Riemannian manifold, compact if need be.
Take an arbitrary $(p,v)\in TM$ and consider the geodesic starting at $p$ in direction $v$ , i.e., $\gamma\colon I\to M, t\mapsto \exp_p(tv)$ . Is it true that \begin{align*}
  \operatorname{dist}_g(p, \exp_p(tv)) = t|v|_g
\end{align*} for all $t\in I$ ? How about t=1? I've tried calculating the length of $\gamma$ via $\gamma'(t) = d(\exp_p)_{tv}(v)$ but couldn't arrive anywhere.","['riemannian-geometry', 'differential-geometry']"
3185354,Decomposing the space of modular forms into $\chi$-eigenspaces via representation theory,"I'm reading Diamond and Shurman's introductory book on modular forms and, in chapter 4.3, they give a decomposition of $M_k(\Gamma_1(N))$ as a direct sum of eigenspaces defined for Dirichlet characters. Specifically, if $\chi$ is a Dirichlet character mod $N$ they define the $\chi$ -eigenspace of $M_k(\Gamma_1(N))$ by $$
M_k(N,\chi)=\{f\in M_k(\Gamma_1(N))\mid f[\gamma]_k=\chi(d_\gamma),\, \,\, \forall \gamma\in \Gamma_0(N)\}, 
$$ where $d_\gamma$ is the lower right entry of $\gamma$ . They then state that $M_k(\Gamma_1(N))=\oplus_\chi M_k(N,\chi)$ and mention (as a hint in the back of the book) that this decomposition follows from ""a standard result from representation theory"". What result are they referring to here? In other words, how would I set up this problem (proving that $M_k(\Gamma_1(N))=\oplus_\chi M_k(N,\chi)$ ) in the context of representation theory, and what 'basic' result am I meant to apply?","['number-theory', 'modular-forms', 'representation-theory', 'reference-request']"
3185389,Codes that maximize average minimum distance from any tuple?,"Inspired by this question . I'd wish to know about binary codes that seek to maximize, not the distance from each codeword to the nearest codeword, but the average distance from any vector ( $n-$ tuple) to the nearest codeword (or if both things are somewhat equivalent). More in detail: Let $T=\{0,1\}^n$ be the set of all $n-$ binary tuples. Let's call $C \subset T $ , with $|C|=M<2^n$ , a ""codebook"" (with each element being a ""codeword""). Let $$d_m^C=\min_{c_i, c_j \in C} d(c_i,c_j)\tag1$$ where $d()$ is the Hamming distance. In the theory of linear error correcting codes, one clasically wants to design a $(n,k)$ code (with $M=2^k$ and $C$ being a vector subspace) which has a big $d_m^C$ . One could also be interested in the average distance from a each codeword to the nearest different codeword $$d^C_a= \frac{1}{M}\sum_{c_i \in C} \min_{c_j \in C,j \ne i} d(c_i,c_j) \tag2$$ ... but for a linear code, $d^C_a=d^C_m$ , because all terms inside the sum are equal. Now suppose we are interested in computing the average distance to the nearest codeword, not from another codeword, but from each of the $2^n$ tuples: $$d^T_a= \frac{1}{2^n}\sum_{x_i \in T} \min_{c_j \in C} d(x_i,c_j) \tag3$$ Again, we wish to design a $C$ (linear or not) that attains a big $d^T_a$ , that is, that covers as evenly as possible (in this sense) the whole space. Has this been studied? Some bounds or asymptotics?
In particular: are the usual codes, designed for high $d^C_a$ , expected to perform well also with regards to $d^T_a$ ? Some preliminary (mostly numerical) work of mine (for the other question) seems to suggest that a random code performs better than a (say) BCH code, which surprised me a bit. Also, it would seem that there is a computable asymptotical value, and that the random code attains it. I'd appreciate any pointers or answer.","['coding-theory', 'discrete-mathematics']"
3185390,Find the minimum of $\space\frac{1}{x}+\frac{1}{y}+c\cdot xy\space$ subject to $\space x+y-c=0$,"Let $f(x,y):\mathbb{D}\rightarrow\mathbb{R}$ be the function: $$f(x,y)=\frac{1}{x}+\frac{1}{y}+c\cdot xy\space\space|\space\space c\in(0,\sqrt[4]8)\text{ $\space$constant}$$ $$\mathbb{D}=\{(x,y)\space|\space x>0,\space y>0\}$$ Find the point $P$ where $f$ gets its minimum value, subject to the equality: $$x+y-c=0$$ I tried : 1) Lagrange multipliers. Unfortunately, they don't seem to help since I get equations I cannot solve (5th degree). 2) Substituting $y=c-x$ to $f$ in order to solve $\frac{d}{dx}f(x,c-x)=0$ . That wasn't helpful either, from the same reasons. Final Solution : The final solution should be $(\frac{c}{2},\frac{c}{2})$ ; However I could not figure out how to find it by myself. Thanks!","['lagrange-multiplier', 'maxima-minima', 'multivariable-calculus', 'optimization', 'derivatives']"
3185391,Inequality regarding sample mean,"I was looking at the book ""Asymptotic Theory of statistics and probability, DasGupta A., 2008"" and in one point of a proof they use an inequality which I have not been able to understand. Given that $X_i, i \in \{1,...,n\}$ are independent and identically distributed random variables, with mean $\mu$ , and with sample mean $\overline{X}_n $ , they state that $$ \sum_{i=1}^n |X_i - \overline{X}_n|^3 \leq 2³\left( \sum_{i=1}^n |X_i - \mu|^3  + n|\mu - \overline{X}_n|^3 \right)$$ I don't know how the 2³ term appears. I've tried adding and substracting $\mu$ but I have not been able to proof the inequality. It would be perfect if you could lend me a hand. Thanks","['statistics', 'means', 'bootstrap-sampling', 'inequality', 'random-variables']"
3185410,What's the derivative of $\underbrace{x^{x^{x^{x^...}}}}_n$? Are my calculations right?,"The problem: To make things easier on us so we don't have to use an underbrace, I'm going to declare: $$\Psi(x,n) := \underbrace{x^{x^{x^{x^{\dots}}}}}_n$$ And we evaluate $f$ from the topright to the bottom left (like a calculator does). Question: What is $$\Psi'(x,n) = \frac{\partial}{\partial x}\Psi(x,n) = \text{?}$$ My attempt: Since we know that $$\begin{align}\frac{\partial}{\partial x}f(x)^x &= \frac{\partial}{\partial x} e^{x \ln f(x)} = \\ &= e^{x \ln f(x)} \left(\frac{x f'(x)}{f(x)} + \ln f(x)\right) = \\ &= f(x)^x \left(\frac{x f'(x)}{f(x)} + \ln f(x)\right),\end{align}$$ We can substitute $$f(x) := \Psi(x,n-1).$$ So we get $$\begin{align}
\frac{\partial}{\partial x}\Psi(x,n) &= \frac{\partial}{\partial x}\Psi(x,n-1)^x = \\ &= \Psi(x,n-1)^x \left(\frac{x \cdot \frac{\partial}{\partial x} \Psi(x,n-1)}{\Psi(x,n)} + \ln \Psi(x,n-1)\right) = \\ &= \Psi(x,n) \left(\frac{x \cdot \frac{\partial}{\partial x} \Psi(x,n-1)}{\Psi(x,n)} + \ln\underbrace{x^{x^{x^{x^{\dots}}}}}_{n-1}\right) = \\ &= x \cdot \frac{\partial}{\partial x} \Psi(x,n-1) + \Psi(x,n)x^{n-2}\ln x
.\end{align}$$ We were able to reduce $n$ by one and get the derivative for $\Psi(x,n)$ in terms of $\Psi(x,n-1)$ . If we keep repeating this for $n-1,n-2,\dots,2,1$ , we should get the full derivative. However, this is what I'm not quite sure of: $$\begin{align}
\frac{\partial}{\partial x}\Psi(x,n) &= x \cdot \frac{\partial}{\partial x} \Psi(x,n-1) + \Psi(x,n)x^{n-2}\ln x = \\ &= x \cdot \frac{\partial}{\partial x} \Psi(x,n-2) + x \cdot \Psi(x,n-1)x^{n-3}\ln x + \Psi(x,n)x^{n-2}\ln x = \dots \\ \dots &= x \cdot \frac{\partial}{\partial x} \Psi(x,1) + \Psi(x,2)x^{n-2}\ln x + \dots + \Psi(x,n)x^{n-2}\ln x = \\ &= x + \ln x \cdot x^{n-2} \cdot \sum_{k=2}^n \Psi(x,k) = x + \ln \Psi(x,n-1) \sum_{k=2}^n \Psi(x,k)
\end{align}$$ So rewriting it with the underbrace notation we get: $$\frac{\partial}{\partial x} \underbrace{x^{x^{x^{x^{\dots}}}}}_n = x + \ln \underbrace{x^{x^{x^{x^{\dots}}}}}_{n-1} \sum_{k=2}^n \underbrace{x^{x^{x^{x^{\dots}}}}}_k$$ Questions: $1$ . Is this correct? Are my calculations right? $2$ . Is there a better way to write the final answer? $3$ . Is there a name for this $(\Psi)$ function? $4$ . Can we generalize $\Psi(x,n)$ for rational (and perhaps irrational) $n$ 's? $5$ . What could be the derivative of $\Psi(x,n)$ for such rational / irrational $n$ 's?","['exponentiation', 'real-analysis', 'calculus', 'algebra-precalculus', 'derivatives']"
3185442,Why is this limit evaluated like so?,"Question: If $$\lim_{x \to 0}{\frac{-1 + \sqrt{(\tan x - \sin x) + \sqrt{(\tan x - \sin x) + \sqrt{(\tan x - \sin x) + \cdots \infty}}}}{-1 + \sqrt{x^3 + \sqrt{x^3 + \sqrt{x^3 + \cdots \infty}}}}} = \frac{1}{k}$$ Then find the value of $k$ . The way I approached the problem was by substituting $x = 0$ in the limit: $$\frac{-1 + \sqrt{(\tan 0 - \sin 0) + \sqrt{(\tan 0 - \sin 0) + \sqrt{(\tan 0 - \sin 0) + \cdots \infty}}}}{-1 + \sqrt{0^3 + \sqrt{0^3 + \sqrt{0^3 + \cdots \infty}}}} = \frac{1}{k}$$ $$\implies \frac{-1 + \sqrt{0 + \sqrt{0 + \sqrt{0 + \cdots \infty}}}}{-1 + \sqrt{0 + \sqrt{0 + \sqrt{0 + \cdots \infty}}}} = \frac{1}{k}$$ $$\implies \frac{-1}{-1} = \frac{1}{k}$$ $$\implies \frac{1}{1} = \frac{1}{k}$$ $$\implies k = 1$$ But according to the given solution, the answer is 2. I did find this question, but I do not understand why I cannot just put $x = 0$ in the limit. Any help is appreciated.","['limits', 'trigonometry', 'sequences-and-series']"
3185456,Fractional parts of square roots of primes,"To avoid confusion with other uses of braces, let $F:\Bbb R\to[0,1)$ be the fractional part function (usually noted as $\{\cdot\}$ ), so $F(x)=x-\lfloor x\rfloor$ . It is known that the set $S:=\{F(\sqrt n):n\in\Bbb N\}$ is dense in $[0,1]$ , because $S$ contains, for example, $\{F(n\sqrt 2):n\in\Bbb N\}$ . But is the set $$\{F(\sqrt p):p\text{ prime}\}$$ also dense in $[0,1)$ ? I had been thinking on it, and my intuition says that it is, but I'm clueless about how to prove it. (In fact, I'm not sure even about the most appropriate tags for this question).","['number-theory', 'radicals', 'prime-numbers']"
3185459,Real Analysis: Prove this function must change sign around some point,"I am trying to prove the following question: Suppose $f : \mathbb{R} → \mathbb{R}$ satisfies $\lim_{x \to \infty} f(x) = \infty$ and $\lim_{x \to -\infty} f(x) = -\infty$ . Prove
that there exists a number $\beta$ such that for all $\epsilon > 0$ there exists an $r \in (0, \epsilon)$ such that $f(\beta − r) \leq 0 ≤ f(β + r)$ . What I have right now: If the function $f$ is continuous, then it is easy by using IVT. If $f$ is not continuous, I was thinking about setting $$
\beta = \sup\{x: f(x) \leq 0\}.
$$ But this does not seem to work since if $$
f(x) = x, \ x \in (-\infty, 1) \cup (1, \infty)
$$ and $$
f(1) = -1, 
$$ then $\beta = 1$ and there is a neighborhood of $\beta$ where the required condition is not satisfied. Can anybody think of another route? Thanks a lot!","['functions', 'real-analysis']"
3185570,How to solve this first order differential separable equation that has an $xy^2$ term?,"Solve: $$(1+x+xy^2)dy+(y+y^3)dx=0$$ I know it's separable, I've tried transforming it with a variable $v = y/x$ , but I can't get it to separate for integration. Help much appreciated.",['ordinary-differential-equations']
3185592,$\operatorname{Frac}(A)/A$ as an $A$-module,"I am wondering about a question: We know that $\mathbb{Q}/\mathbb{Z}$ is torsion group and $\mathbb{Q}/\mathbb{Z}=\bigoplus_{p\text{ prime}}\mathbb{Q}/\mathbb{Z}(p)$ where $\mathbb{Q}/\mathbb{Z}(p)=\{\bar{\frac{a}{p^{\alpha}}\mid a\wedge p=1 \text{ and } \alpha\in\mathbb{N}}\}$ Can we generalize this result as follows? Let $A$ be a ring.
  Consider $\operatorname{Frac}(A)/A$ as $A$ -module, I proved that $\operatorname{Frac}(A)/A$ is a torsion module like we do in $\mathbb{Q}/\mathbb{Z}$ . I want to prove that is direct sum of something which is a generalization of primes. I think about the coprime ideal, but I can not found a similar result. My question is: is this generalization valid or not, and if yes can we construct  submodules that give the whole module via the direct sum?","['torsion-groups', 'modules', 'ring-theory', 'abstract-algebra', 'group-theory']"
3185610,Very indeterminate form: $\lim_{x \to \infty} \left(\sqrt{x^2+2x+3} -\sqrt{x^2+3}\right)^x \longrightarrow (\infty-\infty)^{\infty}$,"Here is problem: $$\lim_{x \to \infty} \left(\sqrt{x^2+2x+3} -\sqrt{x^2+3}\right)^x$$ The solution I presented in the picture below was made by a Mathematics Teacher I tried to solve this Limit without using derivative (L'hospital) and Big O notation. Although I get the answer, I don't know if the technique I'm using definitely correct. And here is my method: $$\begin{align*}\lim_{x \to \infty} \left(\sqrt{x^2+2x+3} -\sqrt{x^2+3}\right)^x&=\lim_{x \to \infty} \left(\frac {2x}{\sqrt{x^2+2x+3} +\sqrt{x^2+3}}\right)^x\\&=\lim_{x \to \infty}\frac{1}{ \left(\frac {\sqrt{x^2+2x+3} +\sqrt{x^2+3}}{2x}\right)^x}\end{align*}$$ Then, I define a new function here $$y(x)=\sqrt{x^2+2x+3} +\sqrt{x^2+3}-2x-1$$ We have $$\begin{align*}
\lim _{x\to\infty} y(x)&=\lim_{x \to \infty}\sqrt{x^2+2x+3} +\sqrt{x^2+3}-2x-1\\
&=\lim_{x \to \infty}(\sqrt{x^2+2x+3}-(x+1))+(\sqrt{x^2+3}-x)\\
&=\lim_{x \to \infty}\frac{2}{\sqrt{x^2+2x+3}+x+1}+ \lim_{x \to \infty}\frac{3}{\sqrt{x^2+3}+x}\\
&=0. 
\end{align*}$$ This implies that $$\lim_{x \to \infty}\frac{2x}{y(x)+1}=\infty $$ Therefore, $$\begin{align*}
\lim_{x \to \infty}\frac{1}{ \left(\frac {\sqrt{x^2+2x+3} +\sqrt{x^2+3}}{2x}\right)^x}&=\lim_{x \to\infty} \frac{1}{ \left(\frac{y(x)+2x+1}{2x} \right)^x}\\
&=\lim_{x \to\infty} \frac{1}{ \left(1+\frac{y(x)+1}{2x} \right)^x}\\
&=\lim_{x \to \infty}\frac{1}{\left( \left( 1+\frac{1}{\frac{2x}{y(x)+1}}\right)^{\frac{2x}{y(x)+1}}\right)^{\frac{y(x)+1}{2}}}\\
&
\end{align*}$$ Here, we define two functions: $$f(x)=\left( 1+\frac{1}{\frac{2x}{y(x)+1}}\right)^{\frac{2x}{y(x)+1}},\quad
g(x)=\frac{y(x)+1}{2}.
$$ We deduce that, $$
\lim_{x\to\infty} f(x)=e>0,\quad \lim_{x\to\infty} g(x)=\frac 12>0.
$$ Thus, the limit $\lim_{x\to\infty} f(x)^{g(x)} $ exists and is finite. Finally we get, $$\begin{align*} 
\lim_{x \to \infty}\frac{1}{\left( \left( 1+\frac{1}{\frac{2x}{y(x)+1}}\right)^{\frac{2x}{y(x)+1}}\right)^{\frac{y(x)+1}{2}}}
&=\frac{1}{\lim_{x \to \infty}\left( \left( \left( 1+\frac{1}{\frac{2x}{y(x)+1}}\right)^{\frac{2x}{y(x)+1}}\right)^{\frac{y(x)+1}{2}}\right)}\\
&=\frac{1}{\left(\lim_{x\to\infty} \left( 1+\frac{1}{\frac{2x}{y(x)+1}} \right)^{\frac{2x}{y(x)+1}}\right)^{ \lim_{x\to\infty} \frac{y(x)+1}{2}}}\\ 
&=\frac {1}{e^{\frac12}}=\frac{\sqrt e}{e}.\\&&
\end{align*}$$ Is the method I use correct? I have received criticisms against my work. What can I do to make the method I use, rigorous? What are the points I missed in the method? Thank you!","['proof-verification', 'limits-without-lhopital', 'alternative-proof', 'calculus', 'limits']"
3185629,Does it suffice to check the normal subgroup property for the generators?,"Let $G$ be a group generated by a subset $S$ and $H$ be a subgroup of $G$ generated by a subset $T$ . To check whether $H$ is a normal subgroup of $G$ or not, we must check the following statement: $$
\forall g \in G \: \forall h \in H: \: g^{-1} h g \in H.
$$ Question : Does it suffice to check $$
\forall s \in S \: \forall t \in T: \: s^{-1} t s \in H?
$$ I assume that this is true, but the proof of that seems to be really technical. Could you please help me by answering and explaining my question? Any help is really appreciated!","['normal-subgroups', 'group-theory', 'abstract-algebra']"
3185630,Are there continuous functions who are the same in an interval but differ in at least one other point?,"You are given a function $f: \mathbb{R}\rightarrow \mathbb{R}$ . Every derivative $\frac{d^n}{dx^n}(f(x)), \,n >0$ of the function is continuous. Is there a function $g: \mathbb{R}\rightarrow \mathbb{R}$ , for which every derivative $\frac{d^n}{dx^n}(g(x)), \,n >0$ is also continuous, such that: $$\forall x\in[a,b]: \, g(x) = f(x)\land \, \exists x \notin [a,b]: f(x) \neq g(x),\, a \neq b$$ Thanks! Edit: I asked the question because I intuitively wondered if there would be functions, which could behave like ""the same"" in a given interval, but then behave differently so that they start diverging or at least stopped being the same the anymore. The answer to this question gave me a bigger understanding of real analysis. If you would like to know which made me think about such a problem: Although this is a vague formulation, generally, this question asks if two (completely) different things can develop (themselves) to be exactly equal in at least one part of there whole existence...","['calculus', 'real-analysis']"
3185649,Example of compact Riemannian manifold with only one closed geodesic.,"The Lyusternik-Fet theorem states that every compact Riemannian manifold has at least one closed geodesic. Are there any easy-to-construct 1 examples of compact Riemannian manifolds for which it is easy to see they only have one closed geodesic? 2 If there aren't any such examples, are there any easy-to-construct examples that only have one closed geodesic but where proving this might be difficult? And if there aren't any examples of this , are there any examples at all of compact manifolds with only one closed geodesic? 1 Of course, the $1$ -sphere $S^1$ contains just one closed geodesic, but I'm interested in examples besides this one. 2 By the theorem of the three geodesics , this example cannot be a topological sphere.","['geodesic', 'examples-counterexamples', 'differential-geometry']"
3185681,Applying functional calculus to the bounded operator $(T \pm iI)^{-1} $,"This is the context: What I wish to prove: 2.3 page 16. Let $T$ be an essentially self-adjoint operator on a Hilbert space $H$ . (Now we take its closure) There is a unique homomoprhism of $C^*$ algebras from the algebra of continuous, bounded functions on $\Bbb R$ into the algebra of bounded operators on $H$ which maps the functions $(x \pm i)^{-1}$ to the operators $(T \pm iI)^{-1}$ . I have proven that $T$ satisfying the condition implies $(T\pm iI)^{-1}$ is a bounded operator normal operator. The proof given in the text is as follows. The spectral theorem is proven by observing $(T\pm iI)^{-1}$ generate a commutative $C^*$ algebra of operators. By Gelfand Naimark theorem, every commutative $C^*$ -algebra is isomoprhic to $C_0(X)$ for some locally compact space $X$ . ** In this case $X$ may be identified with a closed subset of $\Bbb R$ (the spectrum of $T$ ) in such a way that the operators $(T\pm i I)^{-1}$ correspond to the functions $(x \pm iI)^{-1}$ . I am fine until $**$ . I don't see how the identification works, especially when we are applying to $(T+ I)^{-1}$ , so the by GN we should have isomoprhism with $C(\sigma( (T + iI)^{-1})$ .","['operator-theory', 'functional-analysis', 'functional-calculus', 'operator-algebras']"
3185690,Real Examples of Misleading Statistics,"I need to give a presentation to a group of students on Tuesday about why one needs to be careful when examining statistics or mathematical results in the media or online. In his book How Not To Be Wrong , Jordan Ellenberg provides a few examples that I planned on using as case studies to present to the students Wisconsin governor in 2011 claims, since there was a net 18,000 jobs added in 2011 and 9,000 were in Wisconsin, that implies that Wisconsin is doing something right. Failed to mention that net jobs added included states that lost jobs, which reduces the net rate. Mathematicians find proof that the Torah sends messages to the future by looking at sequences of characters that correspond to rabbi names and said rabbi birth/death dates. However, these results only held in the event of very specific names and dates; using any other accepted names or dates for each rabbi resulted in failed tests. If anyone knew of any other good real world examples of misleading statistics or mathematics. I know of a many examples due to variability in sample size, but the more intricate and (potentially) nefarious, the better. Thank you!","['statistical-inference', 'statistics', 'descriptive-statistics', 'big-list', 'soft-question']"
3185691,Absolute Value within an Epsilon Delta Problem,"I'm having trouble with an epsilon-delta proof. I'm asked to prove the limit as $x$ goes to $-2$ of $f(x)=|x^2-9|/(x^2+3x+1)$ is $-5$ , so we have $|(|x^2-9|/(x^2+3x+1))-5|<ϵ$ . I've seen that $|x^2-9|$ is $|x-3||x+3|$ but I'm not really sure how to proceed to 
""obtain"" the desired $|x-a|=|x+2|<δ$ . Am I supposed to place a limitation on either $|x-3|$ or $|x+3|$ ? Or is there some other way to handle this problem? Thanks in advance.","['limits', 'epsilon-delta', 'real-analysis']"
3185707,How to numerically set up to solve this differential equation?,"I have a 1-d differential equation: $$\frac{\mathrm{d}f}{\mathrm{d}\theta} = c(\mathrm{max}(\sin\theta,0)-f^4)~.$$ I am given periodic boundary condition, i.e. $f(\theta) = f(2\pi+\theta)$ . How would I set up a discretised form of this equation to solve for $f(\theta)$ ?","['numerical-methods', 'ordinary-differential-equations']"
3185741,Is the limit of a sequence of square integrable holomorphic functions also holomorphic?,"Suppose we have a convergent sequence of square integrable holomorphic functions $\{f_n\}$ defined on a domain $D$ : they converge to a function $f$ . Does $f$ have to be holomorphic too? This wikipedia article says that $f$ does indeed have to be holomorphic, and that this follows from the fact that for all $f_n$ , we have $$\sup\limits_{K}f_n(z)\leq C_K\|f_n\|_{L^2(D)}$$ where $K\subset D$ is any compact subset of the domain. How does this prove that the limit of the sequence of functions has to be holomorphic?",['complex-analysis']
3185755,Parallelogram Law Geometric Proof,"So, I've dealt with the parallelogram law in various ways a bunch of times now. And algebraically (or maybe I mean arithmetically) it makes perfect sense to me--I can prove it, understand it, and I accept it. However, most authors make an appeal to a picture of a parallelogram with diagonals or vectors draw in, like this one from Wikipedia : This sort of makes sense to me but at the end of the day, the parallelogram law is relating squares of these line segments not the segments themselves (directly), so I don't really gain any intuition from this diagram. Can somebody spread some geometric light on this without appealing to algebra (or with minimal appeal)? If it's the standard proof (i.e. similar to the Wikipedia proof), I'm not interested. Alternatively, if someone can show why my request isn't possible that would cool too. Thank you.","['alternative-proof', 'euclidean-geometry', 'quadrilateral', 'geometry']"
3185844,Determinant of a matrix with positive diagonal entries is greater than 1,Let $A$ be a $n\times n$ matrix with entries on its diagonal are positive and other entries are negative with sum of entries in every column is 1. Prove that $\det(A) > 1.$ I got no idea to begin with. Any suggestion or hint?,"['matrices', 'determinant', 'linear-algebra']"
3185860,"If $A\in\Bbb R^{3\times3}$ is an invertible matrix such that $A^2=A$, then $\det(2A)=8$","True or false? ""If $\pmb{A\in\Bbb R^{3\times3}}$ is an invertible matrix such that $\pmb{A^2=A}$ , then $\pmb{\det(2A)=8}$ "". True. Proof. We start from $\det(2A)$ . Then, $2^3\det(A)$ . But we know that $A^2=AA=A$ , so $A=AA^{-1}$ because $A$ is an invertible matrix, hence $$8\det(A)=8\det(AA^{-1})=8\det(A)\det(A^{-1})=8\det(A)(\det(A))^{-1}=8\det(A)\frac{1}{\det(A)}=8,$$ which is where we wanted to go. $\square$ Is it correct? Thanks!!","['matrices', 'proof-verification', 'determinant']"
3185881,Convergence of $\sum_{n=1}^\infty\frac{\cot \varphi\pi n}{n^s}$,"Question: $s\in\mathbb C$ , Is $$\sum_{n=1}^\infty\frac{\cot \varphi\pi n}{n^s}$$ absolutely convergent, conditionally convergent     or divergent, where $\varphi=\frac{1+\sqrt5}2$ ? TL;DR, my progress It is absolutely convergent if $\Re s>2$ and is divergent if $\Re s\le 1$ . I don't know how to do when $\Re s\in(1,2]$ . Detailed progress From Roth's theorem we can deduce that $\mu\left(\varphi\right)=2$ , where $\mu$ denotes the irrationality measure. If $\Re s\le 1$ , the summand does not tend to $0$ . (We can even find the limsup and the liminf of the summand when $s=1$ .) Hence the sum diverges. I have deleted my wrong ""proof"" of the convergence of the series when $\Re s>2$ . I will fix it and add it to the question if I can. I believe there is only a little mistake in it and it can be fixed easily. EDIT . Numerical experiment EDIT 2 . Numerical calculation suggests $\sum_{n\le x}|\cot\varphi\pi n|=\Theta(x\log x)$ . If we can prove this conjecture, we can obtain the absolute convergence of the series with condition $\Re s>1$ by using Abel's transformation.","['diophantine-approximation', 'number-theory', 'dirichlet-series', 'sequences-and-series', 'convergence-divergence']"
3185886,"If $f$ measurable and $E \subset \mathbb{R}^n$ measurable, when will the set $f(E)$ be measurable?","If $f : \mathbb{R}^n \to \mathbb{R}$ measurable and $E \subset \mathbb{R}^n$ measurable, examples show that $f(E) = \{ f(x) : x \in E \}$ may be unmeasurable. My confusion is that under what assumptions about $f$ will the conclusion hold, i.e., $f(E)$ will be measurable. And is there an equivalence condition for this problem?","['measure-theory', 'real-analysis']"
3185894,How to prove Leibniz rule for exterior derivative using abstract index notation,"I want to prove Leibniz rule for exterior derivative of wedge product using abstract index notation : For $\omega\in \Omega^k(U),\eta\in\Omega^l(U)$ , d $(\omega\wedge\eta)=\text{d}\omega\wedge\eta +(-1)^k\omega\wedge\text{d}\eta$ . My proof is given in the answer below.","['differential-geometry', 'exterior-algebra', 'solution-verification', 'derivatives', 'index-notation']"
3185927,Compact Hausdorff space is metrizable if there countable separating continuous functions,"Proposition: Let $X$ be a compact Hausdorff space. Suppose there are countable real valued continuous functions $\{f_n\}_{n \in \mathbb{Z}_+}$ separating $X$ i.e. for all $x, y \in X$ with $x \neq y$ , $\exists k:=k(x,y) \in \mathbb{Z}_+$ , $f_k(x)\neq f_k(y)$ . Let $$
d(x,y):=\sum_{n=1}^\infty \frac{\min\{|f_n(x)-f_n(y)|, 1\}}{2^n}
$$ Then $X$ is metrizable by $d$ . I want to prove that, for all open set $U$ and $x \in U$ , there exists $B(x;r)$ s.t. $B(x;r)\subset U$ and for all $B(x;r)$ , there exists an open set $U$ s.t. $U\subset B(x;r)$ . Here, $B(x;r):=\{y\in X| d(x,y)<r\}$ .
I know $B(x;r)\supset \bigcap_{n \in \mathbb{Z}_+} \{y \in X |f_n(x)-f_n(y)|<r\}$ , 
but right term is not open. How to prove this proposition?","['general-topology', 'metric-spaces', 'compactness']"
3185959,"Moment estimator $\hat{\theta}$ of $\mathrm{Beta}(\theta,1)$ and bias of $\hat{\theta}$","I'm trying to find the moment estimator for the density function $$f(y)=\theta y^{\theta-1}$$ and check whether this is biased. I know this is a $Beta(\theta,1)$ distribution and it looks like I only need to find the first moment in order to find the estimator. For $Y\sim \mathrm{Beta}(\theta,1)\implies\bar{Y}=\frac{\theta}{\theta+1}$ $$\theta\bar{Y}+\bar{Y}=\theta \implies \hat{\theta}=\frac{\bar{Y}}{1-\bar{Y}}$$ I'm pretty sure I've got that correct but I have no idea how to check whether this is biased or not. Finding the convolution isn't panning out too well and I can't seem to figure out a way to manipulate the expression in $\bar{Y}$ to give me anything to work with. Any pointers towards answering this would be greatly appreciated.","['expected-value', 'statistics', 'parameter-estimation', 'estimation']"
3185967,Questions regarding the complex integral $\int_{\gamma} \frac{1}{(z-a)(z-b)} dz$,"I don't know Cauchy's integral formula and the book I'm learning complex analysis from asks to prove $\int_{\gamma} \frac{1}{(z-a)(z-b)} dz = 2\pi i$ where $\gamma$ is a circle centered at origin with radios $|a| < R < |b|$ . The complex integral of $f(z)$ over a path $\gamma$ parametrized by $\tau(t), t \in I \subset \mathbb{R}$ is defined as $\int_I f(\tau(t)) \tau'(t) dt$ Here's my progress: So we parametrize $\gamma$ as $\tau(\theta) = Re^{i \theta}, \theta \in [0, 2 \pi]$ . Using the identity $\frac{1}{(z-a)(z-b)} = \frac{1}{b-a} [ \frac{1}{z-a} - \frac{1}{z-b}]$ , we integrate each part separately. $\int_{\gamma} \frac{1}{z-a} dz = \int_{0}^{2 \pi} \frac{Rie^{i \theta} d\theta}{Re^{i \theta} - a}$ . Now I don't know how to evaluate it. If this was real, i.e to integrate $\int_{0}^{2\pi} \frac{Re^\theta d \theta}{Re^\theta - 1}$ , I would just substitute $u  = Re^{\theta} - 1$ , then the integral is $\int_{R-1}^{Re^{2\pi} - 1} \frac{du}{u} = \ln(\frac{Re^{2\pi} - 1}{R-1})$ , but then several problems arise when I try to mimmick that appraoch: -- In this if you substitute $u = Re^{i \theta} - 1$ case both upper and lower limits are same ! Maybe this can be fixed by integrating $\int_{0}^{2\pi - \epsilon} \frac{Re^\theta d \theta}{Re^\theta - 1}$ and letting $\epsilon \rightarrow 0$ , but I'm not sure whether thta would give the correct answer (because as long as $\epsilon \neq 0$ the path is a not a proper loop) -- Even if you ignore the issue of the limits, why $\int_{a}^{b} \frac{1}{u(t)} u'(t) dt$ should be equal to $\ln(b) - \ln(a)$ when $a,b$ are complex ? Also which value of $\ln(a)$ hsould be taken and why not the other values ?","['complex-analysis', 'contour-integration']"
3186005,Implicit function theorem for discrete function,"I have a function in two variabels $f(n,x)$ , one of the two variabels is discrete (i.e. $n\in\mathbb{N}$ ). I want to solve the function/equation $f(n,x)=0$ wrt. $x$ , i.e. $x=x(n)$ using the implicit function theorem and then find the dependence of $x$ on $n$ .
For a continuous variable this would be no problem with the implicit function theorem, i.e. $$\frac{dx}{dn}=-\left(\frac{\partial f}{\partial n}\right)^{-1}\cdot \frac{\partial f}{\partial x}$$ Is there any discrete analogus to this theorem? E.g. $$ x(n)-x(n-1) = -\frac{\frac{\partial f}{\partial x}}{f(n,x)-f(n-1,x)}$$ The proof for the existence of the function is not a problem I can show this independently from such a theorem (but would be nice to have of course)","['implicit-function-theorem', 'discrete-mathematics', 'real-analysis']"
3186028,What are the possible periods of the solutions to this ODE?,"Consider the non-autonomous equation $$\ddot x + x = \epsilon f(x,\dot x) + \epsilon \sin(3t)$$ Assume that this equation has (a) periodic solution(s). What are the possible periods? I need to assume that this equation has (a) period solution(s), e.g., solutions $x = \phi(t)$ for which $\phi(t + T) = \phi(t)$ for some $T$ and I need to find for which $T$ this is possible. As a start I entered $\ddot x + x = \epsilon\sin(3t)$ ( $f(x,\dot x) = 0$ ) in Wolfram for different $\epsilon$ and it seems as if $\epsilon$ doesn't have an impact on the period of the solution for this equation. I therefore think that the possible periods depend on the function $f(x,\dot x)$ , but I'm not really sure which options for $f(x,\dot x)$ I should consider. Furthermore, I think that I should do something with $\sin(3t)$ since I think this term will definitely have an impact on the possible periods. My Question: I really have no clue how I should solve this problem, and I'm not necessarily looking for the direct solution. I would like to know where to start and which questions I should ask so that I can find the solution by myself. Thanks in advance!",['ordinary-differential-equations']
3186038,Convergence of quantiles based on estimates,"Let $D_\theta$ denote a distribution with parameter $\theta$ , that has density wrt. Lebesgue measure. Let $X$ have distribution $D_\theta$ and let $\hat{\theta}_n$ be a sequence of estimates of $\theta$ , converging to $\theta$ in probability (or almost surely if that is required). Let $Q_\theta(p)$ denote the quantile function of $D_\theta$ . Do we have $$
P(X \in [Q_{\hat{\theta}_n}(p_1), Q_{\hat{\theta}_n}(p_2)]) \to P(X \in [Q_\theta(p_1), Q_\theta(p_2)])
$$ for every $p_1 \leq p_2$ ? If not, what further assumptions do we need? Continuity of $Q$ in $\theta$ seems like it might do the trick but can we infer that from simply knowing that $D_\theta$ is absolutely continuous wrt. Lebesgue measure? Any ideas?","['statistics', 'probability']"
3186113,Prove that $x_n$ and $n$ are coprimes,"I'm here again with a problem of Italian National Math Olympiads 2007. Given the following subcession: Given the following succession $$\left\{\begin{matrix} 
x_1=2\\  x_{n+1}=2x_n^2-1
 \end{matrix}\right.$$ Prove that $\gcd(x_n,n)=1 \ \ \ \forall n> 1$ My attempt I thought that maybe, having the close formula for $x_n$ could simplify the problem. I noticed the the recursion formula is analogous to the cosine duplication formula: $$\cos(2x)=2\cos^2(x)-1$$ So basically at each iteration step we are duplicating the cosine and: $$x_n=\cos(2^{n-1}\arccos(x_1))=\cos(2^{n-1}\arccos(2))$$ Calculating $\arccos(2)$ is equivalent to this equation: $$\cos(x)=2$$ $$\frac{e^{ix}+e^{-ix}}{2}=2$$ Substituting $e^{ix}=t$ : $$t+\frac 1t=4$$ $$t^2-4t+1=0$$ $$t=2\pm \sqrt{3}$$ $$e^{ix}=2\pm \sqrt{3}$$ $$x=\frac{\ln(2\pm \sqrt{3})}{i}$$ So: $$x_n=\cos\left(2^{n-1}\frac{\ln(2\pm \sqrt{3})}{i}\right) $$ By Euler's formula: $$x_n=\frac{e^{i2^{n-1}\frac{\ln(2\pm \sqrt{3})}{i}}+e^{-i2^{n-1}\frac{\ln(2\pm \sqrt{3})}{i}}}{2}$$ $$x_n=\frac{(2\pm \sqrt{3})^{2^{n-1}}+(2\pm \sqrt{3})^{-2^{n-1}}}{2}$$ The signs can be determined by checking some values. In the end: $$x_n=\frac{(2+\sqrt{3})^{2^{n-1}}+(2+ \sqrt{3})^{-2^{n-1}}}{2}$$ $$x_n=\frac{(\sqrt{3}+2)^{2^{n-1}}+(2-\sqrt{3})^{2^{n-1}}}{2}$$ So now we have to proof that if $p|n$ then $p \nmid \frac{(\sqrt{3}+2)^{2^{n-1}}+(2-\sqrt{3})^{2^{n-1}}}{2} $ with $p\in \Bbb{P} $ . If $p=2$ the proof is trivial because clearly $x_n \equiv 1 \pmod{2} \ \ \ \ \forall n\geq 2$ . So we can limitate us to study the simplified expression: $$(\sqrt{3}+2)^{2^{n-1}}+(2-\sqrt{3})^{2^{n-1}}$$ Then I don't know how to continue :( I tried using Newton binomial we obtain: $$(\sqrt{3}+2)^{2^{n-1}}+(2-\sqrt{3})^{2^{n-1}}= \sum_{i=0}^{2^{n-1}} {2^{n-1}\choose i} (\sqrt{3})^i 2^{2^{n-1}-i}+\sum_{i=0}^{2^{n-1}} (-1)^i{2^{n-1}\choose i} (\sqrt{3})^i 2^{2^{n-1}-i}$$ Notice that if $i\equiv 1 \pmod{2}$ the terms get simplified so: $$\sum_{i=0}^{2^{n-2}} {2^{n-1}\choose 2i} 3^{i} 2^{2^{n-1}-2i+1} $$ But then I can't see the pattern :( Can you help me, I would like to know how to solve this problem and if possible how to continue my solution. Thank you for your time","['number-theory', 'recurrence-relations']"
3186151,Hopping to infinity along a string of digits,"Let $s$ be an infinite string of decimal digits, for example: \begin{array}{cccccccccc}
 s = 3 & 1 & 4 & 1 & 5 & 9 & 2 & 6 & 5 & 3 & \cdots
\end{array} Consider a marker, the head , pointing to the first digit, $3$ in the above example. Interpret the digit under
the head as an instruction to move the head $3$ digits to the right, i.e., to the $4$ th digit. Now the head is pointing to $1$ . Interpret this as an instruction to move $1$ place to the left. Continue in this manner, hopping through the string, alternately moving right and left. Think of the head as akin to the head of a Turing machine, and $s$ as the tape of instructions. There are three possible behaviors.
(1) The head moves off the left end of $s$ : \begin{array}{cccccccccc}
 3 & 1 & 4 & 1 & 5 & 9 & 2 & 6 & 5 & 3 \\
 \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} \\
 3 & 1 & 4 & 1 & 5 & 9 & 2 & 6 & 5 & 3 \\
 \text{} & \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} \\
 3 & 1 & 4 & 1 & 5 & 9 & 2 & 6 & 5 & 3 \\
 \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} \\
 3 & 1 & 4 & 1 & 5 & 9 & 2 & 6 & 5 & 3 \\
 \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} \\
 3 & 1 & 4 & 1 & 5 & 9 & 2 & 6 & 5 & 3 \\
 \text{} & \text{} & \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} & \text{} & \text{} \\
 3 & 1 & 4 & 1 & 5 & 9 & 2 & 6 & 5 & 3 \\
 \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{ ${}^{\wedge}$} \\
 3 & 1 & 4 & 1 & 5 & 9 & 2 & 6 & 5 & 3 \\
 \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} \\
 3 & 1 & 4 & 1 & 5 & 9 & 2 & 6 & 5 & 3 \\
 \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} \\
 3 & 1 & 4 & 1 & 5 & 9 & 2 & 6 & 5 & 3 \\
 \text{} & \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} \\
 3 & 1 & 4 & 1 & 5 & 9 & 2 & 6 & 5 & 3 \\
 \text{} & \text{} & \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} & \text{} & \text{}
\end{array} (2) The head goes into a cycle, e.g., when the head hits $0$ : \begin{array}{cccccccccccccc}
 6 & 4 & 5 & 7 & 5 & 1 & 3 & 1 & 1 & 0 & 6 & 4 & 5 & 9 \\
 \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} \\
 6 & 4 & 5 & 7 & 5 & 1 & 3 & 1 & 1 & 0 & 6 & 4 & 5 & 9 \\
 \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} \\
 6 & 4 & 5 & 7 & 5 & 1 & 3 & 1 & 1 & 0 & 6 & 4 & 5 & 9 \\
 \text{} & \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} \\
 6 & 4 & 5 & 7 & 5 & 1 & 3 & 1 & 1 & 0 & 6 & 4 & 5 & 9 \\
 \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} \\
 6 & 4 & 5 & 7 & 5 & 1 & 3 & 1 & 1 & 0 & 6 & 4 & 5 & 9 \\
 \text{} & \text{} & \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} \\
 6 & 4 & 5 & 7 & 5 & 1 & 3 & 1 & 1 & 0 & 6 & 4 & 5 & 9 \\
 \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} & \text{} 
\end{array} (3) The head moves off rightward to infnity: \begin{array}{ccccccccccccc}
 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 \\
 \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} \\
 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 \\
 \text{} & \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} \\
 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 \\
 \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} \\
 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 \\
 \text{} & \text{} & \text{} & \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} \\
 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 \\
 \text{} & \text{} & \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} \\
 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 \\
 \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} & \text{} & \text{} \\
 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 \\
 \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} \\
 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 \\
 \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} \\
 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 \\
 \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} & \text{} & \text{} & \text{} \\
 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 & 1 & 3 \\
 \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{} & \text{ ${}^{\wedge}$} & \text{} \\
\end{array} This last string could be viewed as the decimal expansion of $31/99 = 0.3131313131313\cdots$ . Q1 . What is an example of an irrational number $0.d_1 d_2 d_3 \cdots$ whose string $s=d_1 d_2 d_3 \cdots$ causes the head to hop rightward to infinity? Q1.5 . ( Added ). Is there an explicit irrational algebraic number with the hop-to- $\infty$ property? I'm thinking of something like $\sqrt{7}-2$ , the 
2nd example above (which cycles). Q2 . More generally, which strings
  cause the head to hop rightward to infinity? Update (summarizing answers, 13Apr2019). Q1 . There are irrationals with the hop-to- $\infty$ property
(@EthanBolker, @TheSimpliFire),
but explicit construction requires using, e.g., the 
Thue-Morse sequence (@Wojowu). Q1.5 . @EthanBolker suggests this may be difficult, and @Wojowu suggests it may be false (b/c: nine consecutive zeros): Perhaps no algebraic irrational has the hop-to- $\infty$ property. Q2 . A partial algorithmic characterization by @TheSimpliFire.","['irrational-numbers', 'turing-machines', 'decimal-expansion', 'recreational-mathematics', 'sequences-and-series']"
3186189,$\lim\limits_{n \to \infty}\sqrt{1+\sqrt{\frac{1}{2^2}+\sqrt{\frac{1}{3^2}+\cdots+\sqrt{\frac{1}{n^2}}}}}.$,"Problem Evaluate $\lim\limits_{n \to \infty}T_n$ where $$T_n=\sqrt{1+\sqrt{\frac{1}{2^2}+\sqrt{\frac{1}{3^2}+\cdots+\sqrt{\frac{1}{n^2}}}}}.$$ Analysis It's obvious that $T_n$ is increasing with a greater $n$ , since \begin{align*}
T_{n+1}&=\sqrt{1+\sqrt{\frac{1}{2^2}+\sqrt{\frac{1}{3^2}+\cdots+\sqrt{\frac{1}{n^2}+\sqrt{\frac{1}{(n+1)^2}}}}}}\\
&>\sqrt{1+\sqrt{\frac{1}{2^2}+\sqrt{\frac{1}{3^2}+\cdots+\sqrt{\frac{1}{n^2}+0}}}}\\
&=T_n.
\end{align*} Moreover, we can prove that $T_n$ is bounded upward, since \begin{align*}
T_n&=\sqrt{1+\sqrt{\frac{1}{2^2}+\sqrt{\frac{1}{3^2}+\cdots+\sqrt{\frac{1}{n^2}}}}}\\
&\leq \sqrt{1+\sqrt {1+\sqrt{1+\cdots+\sqrt{1}}}} \\
&\to \frac{\sqrt{5}+1}{2}.
\end{align*} Therefore, $T_n$ is convergent as $n \to \infty$ , by the monotonicity convergence theorem. But where does it converge to on earth? Does the limit have a excact value? I have already computed the value using the former $20$ terms by Mathematica, it output:","['nested-radicals', 'limits']"
3186199,Topological invariance of compactly supported de Rham cohomology,"It is well-known that if we are given two smooth manifolds (without) boundary, whose underlying topological spaces are homotopic, then the de Rham cohomologies $H^k_{dR}$ of $M$ and $N$ are isomorphic for all $k\geq 0$ [See Theorem 17.11 in Lee's smooth manifolds book]. I was wondering if a similar result holds for the compactly supported de Rham cohomologies $H^k_c(M)$ and $H^k_c(N)$ . I know that such a result doesn't hold if we only demand a standard homotopy relation. However Lee mentions shortly in his book that proper smooth maps induce maps between the compactly supported groups. In Exercise 6-8 of Lee's book
 we are asked to show that every proper continuous map is homotopic to a proper smooth map, but I'm not sure if the homotopy is in fact proper, which according to this thread Invariance of de Rham cohomology with compact support and the cited book by Michor seems to be what we need in order to establish the result. Strangely enough I couldn't find any reference which explicitly states that the compactly supported de Rham cohomology groups are isomorphic for homeomorphic manifolds. To explicitly state my question: If the underlying topological spaces of two smooth manifolds (without boundary) $M$ and $N$ are homeomorphic, are their compactly supported de Rham cohomologies isomorphic? Kind regards","['de-rham-cohomology', 'smooth-manifolds', 'differential-topology', 'differential-forms', 'differential-geometry']"
3186245,An expression for computing second order partial derivatives of an implicitely defined function,"Let $\Phi(x,y)=0$ be an implicit function s.t. $\Phi:\mathbb{R}^n\times \mathbb{R}^k\rightarrow \mathbb{R}^n$ and $\det\left(\frac{\partial \Phi}{\partial 
 x}(x_0,y_0)\right)\neq 0$ . This means that locally at $(x_0,y_0)$ we can express $x_i$ as functions of $y$ . Next, we can compute partial derivatives of $x$ as \begin{equation}\tag{*}\frac{\partial x_i}{\partial y_j}=-\frac{\det\left(\left[\frac{\partial \Phi}{\partial 
 x_1},\dots,\frac{\partial \Phi}{\partial 
 x_{i-1}}, \frac{\partial \Phi}{\partial 
 y_j}, \frac{\partial \Phi}{\partial 
 x_{i+1}},\dots, \frac{\partial \Phi}{\partial 
 x_n}\right]\right)}{\det\left(\frac{\partial \Phi}{\partial 
 x}\right)}.\end{equation} This is known. What I wonder is: Q: is it possible to compute second order partial derivatives in a systematic way? I tried to differentiate determinants using the Jacobi formula, but this leads to very complicated expressions that I cannot handle. I also expanded the determinants in ( $*$ ) along the $i$ column (by which the respective matrices differ) and tried some other approaches, but they do not seem to bring me any further. On the other hand, if a go a straightforward way and differentiate $\Phi(x,y)$ twice, I get expressions involving tensors or rather multiindex notations, because neither second order partial derivatives, nor the derivatives of type $\frac{\partial x^i}{\partial y^j}$ are actually tensors. My hope is that maybe it is still possible to extract some nice tractable expression similar to how we got ( $*$ ) from $\frac{\partial x}{\partial y}=-\left[\frac{\partial \Phi}{\partial x}\right]^{-1}\frac{\partial \Phi}{\partial y}$ ? Here is a related question . UPDATE: It seems that the problem turned out to be more difficult than I expected (although many people told me that it must have been solved by somebody). Since the hope for getting a resolutive answer fades and the bounty will expire in a couple of days, I'd gladly grant it to anybody who could point out a way to approach (if not solve) this problem. UPDATE 2: Let me expand a bit on the above. To illustrate my problem let's differentiate $\left[\frac{\partial \Phi}{\partial x}\right]^{-1}$ w.r.t. $y_i$ : \begin{multline*}\frac{\partial}{\partial y_i}\left[\frac{\partial \Phi}{\partial x}\right]^{-1}=-\left[\frac{\partial \Phi}{\partial x}\right]^{-1}\frac{\partial}{\partial y_i}\left[\frac{\partial \Phi}{\partial x}\right]\left[\frac{\partial \Phi}{\partial x}\right]^{-1}\\
=-\left[\frac{\partial \Phi}{\partial x}\right]^{-1}\left[\frac{\partial^2 \Phi}{\partial x\partial x}\right]\frac{\partial x}{\partial y_i}\left[\frac{\partial \Phi}{\partial x}\right]^{-1}-\left[\frac{\partial \Phi}{\partial x}\right]^{-1}\left[\frac{\partial^2 \Phi}{\partial y_i\partial x}\right]\left[\frac{\partial \Phi}{\partial x}\right]^{-1}.\end{multline*} So, what is $\left[\frac{\partial^2 \Phi}{\partial x\partial x}\right]\frac{\partial x}{\partial y_i}$ ? A 3D matrix multiplied with a vector? How to treat these expressions? To make the things even more complicated we should now substitute $\frac{\partial x}{\partial y_i}$ with the respective expression for the first order partial derivatives. It becomes completely obscure and I cannot recognize any structure in it.","['reference-request', 'multivariable-calculus', 'implicit-differentiation', 'partial-derivative', 'derivatives']"
3186329,Having trouble solving this separable differential equation,I am having some trouble with the following separable differential equation $$\frac{dx}{dt} = x(x-1)(x-3)$$ with initial condition $x(0) = 2$ . What is $\displaystyle\lim_{t \to \infty} x(t)$ ? I am having some trouble with the logarithmic laws when solving for $x(t)$ .,"['stability-in-odes', 'ordinary-differential-equations']"
3186343,Finding degree of a finite field extension,"Let $x=\sqrt{2}+\sqrt{3}+\ldots+\sqrt{n}, n\geq 2$ . I want to show that $[\mathbb{Q}(x):\mathbb{Q}]=2^{\phi(n)}$ , where $\phi$ is Euler's totient function. I know that if $p_1,\ldots,p_n$ are pairwise relatively prime then $[\mathbb{Q}(\sqrt{p_1}+\ldots+\sqrt{p_n}):\mathbb{Q}]=2^n$ . But how to proceed in the above case? I could not apply induction also. Any help is appreciated. The assertion is false. Actually $[\mathbb{Q}(x):\mathbb{Q}]=2^{\pi(n)}$ , where $\pi(n)$ is the number of prime numbers less than or equal to $n$ .","['galois-theory', 'abstract-algebra', 'extension-field']"
3186380,"The steps to get $\beta$ in Least Square Estimation, why $x_i$ was removed?",Please see the following steps Get $\beta$ in Least Square Estimation:,"['regression', 'statistics', 'least-squares']"
3186412,"Is there a version of the Arzelà–Ascoli theorem capturing $C([0,\infty))$?","I only know the Arzelà–Ascoli theorem for continuous functions on a compact topological space. However, in the context of characterizing weak convergence of probability measures on $C([0,\infty))$ , I've seen that the following version is used (without proof): If $N,\delta>0$ and $f\in C([0,\infty))$ , let $$V^N(f,\delta):=\sup\left\{|f(t)-f(s)|:|t-s|\le\delta,s,t\le N\right\}.$$ Then $F\subseteq C([0,\infty))$ is relatively compact if and only if $\left\{f(0):f\in F\right\}$ is bounded and for all $N>0$ , $$\lim_{\delta\to0+}\sup_{f\in F}V^N(f,\delta)=0\tag1.$$ Does any body know a reference for a version of the Arzelà–Ascoli theorem which captures this case? Remark : Obviously, $(1)$ is equivalent to the uniform equicontinuity of $F$ . EDIT : There is the following version which can be found in Theorem 4.43 in the book of Folland: Theorem 4.43 : If $X$ is a compact Hausdorff space and $\mathcal F\subseteq C(X)$ is equicontinuous $^1$ and pointwise bounded $^2$ , then $\mathcal F$ is totally bounded (with respect to the supremum metric) on $C(X)$ and relatively compact. I guess the situation in the question can somehow be generalized in the following way: If $X$ is a Hausdorff space, $\mathcal F\subseteq C(X)$ and ${\mathcal F}_K:=\left\{\left.f\right|_K:f\in\mathcal F\right\}$ is equicontinuous and pointwise bounded for all compact $K\subseteq X$ , then ... Maybe someone could elaborate on what exactly we can conclude and which additional assumption on $X$ we need. I know almost nothing about general topology, but I could imagine that we can consider $C(X)$ above as being equipped with the topology induced by the family of metrics $$d_{\infty,\:K}(f,g):=\sup_{x\in K}d(f(x),g(x))\;\;\;\text{for }f,g\in C(X)$$ for compact $K\subseteq X$ , which should yield a sequentially complete space. $^1$ i.e. for all $x\in X$ and $\varepsilon>0$ , there is a neighborhood $N$ of $x$ with $f(N)\subseteq B_\varepsilon(f(x))$ for all $x\in X$ . $^2$ i.e. $\left\{f(x):f\in F\right\}$ is bounded for all $f\in\mathcal F$ .","['arzela-ascoli', 'functional-analysis', 'general-topology', 'equicontinuity', 'compactness']"
3186449,Volume of a truncated paraboloid,"A body is surrounded by its lateral faces: $$z(x,y) = h \left(1 - \left(\frac{x}{a}\right)^2 - \left(\frac{y}{b}\right)^2 \right)$$ and $$z(x,y)=0$$ It should be a paraboloid, right? How can I calculate its volume via integration over $x$ and $y$ in Cartesian coordinates? Thanks a lot in advance!","['integration', 'multivariable-calculus', 'definite-integrals', 'volume']"
