question_id,title,body,tags
1037736,valid proof of series $\sum \limits_{v=1}^n v$,"$$\sum \limits_{v=1}^n v=\frac{n^2+n}{2}$$ please don't downvote if this proof is stupid, it is my first proof, and i am only in grade 5, so i haven't a teacher for any of this 'big sums' proof: if we look at $\sum \limits_{v=1}^3 v=1+2+3,\sum \limits_{v=1}^4 v=1+2+3+4,\sum \limits_{v=1}^5 v=1+2+3+4+5$ i learnt rainbow numbers in class three years ago, so i use that knowlege here: $n=3,1+3=4$ and $2$. $n=4,1+4$ and $2+3$ $n=5,1+5$ and $2+4$ and $3$ and more that i have done on paper that i don't wanna type. we can see from this for the odd case that we have $(n+1)$ added together moving in from the outside, so we get to add $(n+1)$ to the total $\frac{(n-1)}2$ times plus the center number, which is $\frac{n+1}2$.. giving $\frac{n-1}2(n+1)+\frac{n+1}2=\frac{(n+1)(n-1)}{2}+\frac{n+1}{2}$ and i can get $\frac{n^2-1}2+\frac{n+1}2=\frac{n^2+n}2$ which is what we want. so odd are proven. for even we have a simplier problem: we have $n+1$ on each pair of numbers going in. since we are even numbers, we have $1+n=n+1$ , with $n$ even, $2+(n-1)=n+1$ and we can see this is good for all numbers since we increase one side by one and lower the other by 1. so we get $\frac{n}2$ times $n+1$ gives $\frac{n^2+n}{2}$ thus is proven for all cases. thus is is proven","['alternative-proof', 'proof-writing', 'algebra-precalculus', 'proof-verification']"
1037738,Prove that an involutory matrix has eigenvalues $\pm 1$,"I'm trying to prove that an involutory matrix (a matrix where $A=A^{-1}$ ) has only eigenvalues $\pm 1$ . I've been able to prove that $\det(A) = \pm 1$ , but that only shows that the product of the eigenvalues is equal to $\pm 1$ , not the eigenvalues themselves. Does anybody have an idea for how the proof might go?","['eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'involutions', 'determinant']"
1037764,Decomposition of analytic functions,"Given two open overlapping sets $\Omega_1$, $\Omega_2$ and an analytic function $f$ on $\Omega_1\cap\Omega_2$, how does one prove that there are analytic functions $g_1$ on $\Omega_1$ and $g_2$ on $\Omega_2$ such that $f=g_1+g_2$ on $\Omega_1\cap\Omega_2$ ?",['complex-analysis']
1037768,"Integration $\frac{1}{2\pi}\int_{-\pi}^{\pi}(x-a)^ke^{-i\omega x}dx, \ \ \ \ a\in\mathbb R$.","Give a compact form for the solution of integral:
$$\frac{1}{2\pi}\int_{-\pi}^{\pi}(x-a)^ke^{-i\omega x}dx, \ \ \ \ a\in\mathbb R,k\in\mathbb N$$
any suggestions please?","['definite-integrals', 'closed-form', 'calculus', 'integration']"
1037775,How to prove that solution of ODE is even function?,"Could you please give me some hint how to prove this statement: If $f(x)$ is solution of $y'=4x^3e^{-|y|}$ then $f(x)$ is even function.
It is obvious that $f(x)$ increasing for all $x>0$ and decreasing for all $x<0$,
so there are $a<0,b>0$ such as $f(a)=f(b)$, but how to prove that $a=-b$ ? Thanks.","['ordinary-differential-equations', 'functions']"
1037786,"If $n$ is even, every skew-symmetric $n\times n$ matrix $A$ can be factored as $A=SBS^T$","If $n$ is even, every skew-symmetric $n\times n$ matrix $A$ can be factored as $A=SBS^T$ where $S$ is a invertible matrix and $B$ has the form $B = \left( \begin{array}{ccc}
0 & a_1 & 0 & 0 &0&0\\
-a_1 & 0 &0&0 &0&0\\
0&0&0&a_{2}&0&0\\
0 & 0&-a_{2}&0&0&0\\
0&0&0&0&0&a_{n/2}\\
0&0&0&0&-a_{n/2}&0 \end{array} \right)$ The $a_{n/2}$ is supposed to represent that $B$ can be any even $n\times n$ size (the size of $A$). So my book shows this result without proving it, and I was wondering why it's true. It doesn't seem clear to me why this specific factorization holds. How can you prove that it's true? What would $S$ or $S^T$ look like? Some useful results: If $E$ is an elementary matrix obtained from $I_n$ by carrying out one
  elementary row operation on $I_n$, then $EA$ is a matrix obtained by
  carrying out a single elementary row operation on $A$, and $AE$ is a
  matrix obtained by carrying out a single elementary column operation
  on $A$. $A$ is invertible iff it can be factored as a product of elementary
  matrices: $A = E_1...E_m$.","['matrices', 'linear-algebra']"
1037797,Very ample divisors and the Riemann-Roch theorem,"What is the easiest way to prove that a divisor $D$ is very ample if and only if $l(D - P - Q) = l(D) - 2$ for all points $P, Q \in C$. It seems like it might be a consequence of the Riemann-Roch theorem, but I am not sure how to deduce this from the said theorem.",['algebraic-geometry']
1037813,Subfield Criteria - Proof or Counterexample,"I am interested in whether the following claim is true for all fields $F$: Conjecture :
A subset $X\subset F$ is a subfield if and only if (1) $1\in X$, (2) $x,y\in X\Rightarrow x-y\in X$; and (3) $x\in X\setminus\{0\}\Rightarrow x^{-1}\in X$. It isn't too hard to prove true if char$F\neq2$, and I can also show it holds if $F$ is finite. The case of an infinite field of characteristic $2$ remains elusive, though. I can neither prove it nor find a counterexample. Can anyone else give it a go? Some notes: conditions (1), (2) and (3) are certainly independent, hence my interest in the problem. The following are consequences of the conditions: If $x,y\in X$ then $(xy)^2,xy^2\in X$ If $x\in X$ then $x^n\in X$ for all $n\in\mathbb{Z}$ In case you were after the work so far: Clearly conditions (1) and (2) imply $X$ is a subgroup. Suppose $x\in X$. If $x\in\{0,1\}$ then $x^2=x\in X$. If not, $x^{-1},(1-x)^{-1}\in X$, so $x^2=x-[x^{-1}+(1-x)^{-1}]^{-1}\in X$. Hence $X$ is closed under squares. Assume char$F\neq2$. Then if $x,y\in X$, $2xy=(x+y)^2-x^2-y^2\in X$, so either $xy=0\in X$ or $(2xy)^{-1}\in X$, in which case $xy=[(2xy)^{-1}+(2xy)^{-1}]^{-1}\in X$. This proves the conjecture if char$F\neq2$. Assume char$F=2$. Then if $x,y,z\in X$ with $x\notin\{y^{-1},z^{-1}\}$ and $y,z,0$ all distinct, we have $\omega:=(x+y^{-1})^{-1}+(x+z^{-1})^{-1}\in X$. Simplifying gives $\omega=[y(1+xz)+z(1+xy)][(1+xy)(1+xz)]^{-1}=(y+z)[1+x(y+z)+x^2yz]^{-1}$, and so
$$f(x,y,z):=x^2yz(y+z)^{-1}=\omega^{-1}-x-(y+z)^{-1}\in X$$
for all $x,y,z\in X$. Thus if $x,y\in X$, we have
$$x^2y(y+1)=f(x,y,y+1)\in X,\quad y(x^2+y)=f(x,y,x^2+y)\in X\Rightarrow x^2y\in X\Rightarrow x^2y^2\in X.$$
If $|F|<\infty$, then $|F|=2^n$ for some $n$ and $F\setminus\{0\}$ is a multiplicative group of order $2^n-1$. Since $X$ is closed under squares, induction gives us
$$xy=(xy)^{2^n}\in X.$$
If $|F|=\infty$, I'm stuck. Since $x\in X$, $x^3=x^2x\in X$, and if $x^{n-2}\in X$ then $x^n=x^{n-2}x^2\in X$. Hence by induction $x^n\in X$ for all $n\in\mathbb{N}$ (since $X$ is closed under squares and cubes), and so by taking inverses $x^n\in X$ for all $n\in\mathbb{Z}$.","['abstract-algebra', 'field-theory']"
1037815,Probability that last child is a boy,"Johnny has 4 children. It is known that he has more daughters
than sons. Find the probability that the last child is a boy. I let A be the event that the last child is a boy, P(A) = $\frac{1}{2}$.
and B be the event that he as more daughters than sons. But im not sure how to calculate P(B) and what are the subsequent steps to take after. Appreciate any help. Thanks",['probability']
1037837,Automorphism group of a topological space,"Let $G$ be any group. Is there a topological space $(X,\tau)$ such that the automorphism group $\textrm{Aut}(X,\tau)$ is isomorphic to $G$?","['general-topology', 'group-theory']"
1037857,Very basic question about set theory: unions and intersection,"Let $\{ E_n \}_{n=1}^{\infty} $ be a collection of countable sets and let $$ F_k = E_k \setminus ( \bigcup_{j=1}^{k-1} E_j )  $$ Then $F_k$ are pairwise disjoint and $\bigcup^{\infty} F_k = \bigcup^{\infty} E_k $ Attempt Write $$ F_k = E_k \cap ( \bigcup_{j=1}^{k-1} E_j )^c $$ say $l \neq k$ we show $F_k \cap F_l = \varnothing $ . WLOG we can assume $l < k $ and write $$ F_k \cap F_l = E_k \cap ( \bigcup_{j=1}^{k-1} E_j )^c \cap E_l \cap ( \bigcup_{j=1}^{l-1} E_j )^c$$ By Demorgans we get all intersections: $$ F_k \cap F_l = E_k \cap ( E_1^c\cap ... \cap E_{k-1}^c) \cap E_l \cap ( E_1^c \cap ... \cap E_{l-1}^c)$$ Since $l < k$ , then $E_k^c $ must be somewhere in $( E_1^c \cap ... \cap E_{l-1}^c)$ and since $E_k \cap E_k^c = \varnothing $ we have $$ F_k \cap F_l = \varnothing $$ as desired. As for the other part of the problem, If $x \in \bigcup^{\infty} F_k$ , then $x \in F_{k_0}$ for some $k_0$ . But $F_{k_0} \subset E_{k_0} \subset \bigcup^{\infty} E_k $ . So, $$ \bigcup F_k \subset \bigcup E_k $$ Next, notice $$ F_k = E_k \cap ( \bigcup_{j=1}^{k-1} E_j )^c \implies E_k = F_k \cap ( \bigcup_{j=1}^{k-1} E_k )$$ and so by the same argument as above we get the equality of the unions. Is this a correct approach? or is it unnecessary long? I know it is a trivial result, but I would like to get feedback. Thanks","['elementary-set-theory', 'proof-verification']"
1037877,How to partial differentiate a total differential and be rigorous on all the notion?,"Start with $$dS=\left(\frac{\partial S}{\partial T}\right)_VdT+\left(\frac{\partial S}{\partial V}\right)_TdV$$ Using the notes shown here Method 1: i) Divide both sides by dV $$\frac{dS}{dV}=\left(\frac{\partial S}{\partial T}\right)_V\frac{dT}{dV}+\left(\frac{\partial S}{\partial V}\right)_T\frac{dV}{dV}$$ ii) and at const. P $$\left(\frac{dS}{dV}\right)_P=\left(\frac{\partial S}{\partial T}\right)_V\left(\frac{dT}{dV}\right)_P+\left(\frac{\partial S}{\partial V}\right)_T\left(\frac{dV}{dV}\right)_P$$ $$\left(\frac{dS}{dV}\right)_P=\left(\frac{\partial S}{\partial T}\right)_V\left(\frac{dT}{dV}\right)_P+\left(\frac{\partial S}{\partial V}\right)_T$$ Question 1: but how does $$\left(\frac{dS}{dV}\right)_P=\left(\frac{\partial S}{\partial T}\right)_V\left(\frac{dT}{dV}\right)_P+\left(\frac{\partial S}{\partial V}\right)_T$$ becomes $$\left(\frac{\partial S}{\partial V}\right)_P=\left(\frac{\partial S}{\partial T}\right)_V\left(\frac{\partial T}{\partial V}\right)_P+\left(\frac{\partial S}{\partial V}\right)_T???$$ Using the notes shown here Method 2: Differentiate both side wrt V, holding P const. and use product rule $$\frac{\partial}{\partial V}\left(dS\right)_P=\frac{\partial}{\partial V}\left(\left(\frac{\partial S}{\partial T}\right)_VdT\right)_P+\frac{\partial}{\partial V}\left(\left(\frac{\partial S}{\partial V}\right)_TdV\right)_P$$ $$\left(\frac{\partial dS}{\partial V}\right)_P=\left(\left(\frac{\partial^2 S}{\partial V \partial T}\right)_V\right)_PdT+\left(\frac{\partial S}{\partial T}\right)_V\left(\frac{\partial dT}{\partial V}\right)_P+\left(\left(\frac{\partial^2 S}{\partial V^2}\right)_T\right)_PdV+\left(\frac{\partial S}{\partial V}\right)_T\left(\frac{\partial dV}{\partial V}\right)_P$$ Question 2: I got so many extra terms, and how to deal with these $$\left(\frac{\partial \text{ d blah}_1}{\partial \text{ blah}_2}\right)_{\text{blah}_3}$$ terms? Tl:dr How to partial differentiate a total differential rigorously?","['multivariable-calculus', 'homogeneous-equation']"
1037879,Definition of No Tear and No Paste,"Topologists often mention an example beginning by ""If there is no tear and no paste, then ..."". As a student, I am confused with this ""term"", and I want to know the exact mean of it. First of all, what are tear and paste? Assume there is a quotient map from $X$ to $Y$, then can we call $Y$ is pasted by $X$, and $X$ is teared from $Y$? I have searched for http://en.wikipedia.org/wiki/Ambient_isotopy . I think the term ""no tear and no paste"" may be related with an ambient space, but I cannot figure out what its exact mean is or what the relationship is between the term and the concept of paste and tear. Any advice is helpful. Thank you.","['general-topology', 'terminology', 'definition']"
1037898,"Is $\int_1^\infty \frac{\log(x-1)}{x(x-1)}\,dx$ convergent?","Does given integral $$\int_1^\infty \frac{\log(x-1)}{x(x-1)}\,dx$$ converge? If it is convergent can we evaluate it's value?","['convergence-divergence', 'calculus', 'integration', 'definite-integrals', 'analysis']"
1037930,prove the limit of $k^{1/k}$ is $1$ [duplicate],This question already has answers here : How to show that $\lim_{n \to +\infty} n^{\frac{1}{n}} = 1$? (13 answers) Closed 9 years ago . I want to prove that the limit of the sequence $k^{1/k}$ is $1$ as $k$ tends to infinity without using advanced rules such as L'Hospital's Rule and just using the basic rules in real analysis. How would I go about doing this?,"['limits-without-lhopital', 'sequences-and-series', 'real-analysis', 'limits']"
1037933,Proof by induction for $ \sum_{n}^{M} \cos(2n) = \frac{\sin(M) \cos(M+1)}{\sin(1)} $,"Can someone show me an induction for $$ \sum_{n}^{M} \cos(2n) = \frac{\sin(M) \cos(M+1)}{\sin(1)} $$? My problem is doing that induction with $M$, I am not sure how to proceed to get the right side of equation.","['induction', 'discrete-mathematics']"
1037969,"Maximum of parabolas at interval $[0,1]$","A family of parabolas $p(x)$ is given for $x \in [0,1]$
by coefficients $(a,b,c)$ , everything real-valued:
$$
p(x) = a x^2 + b x + c
$$
The area of the parabolas is normed: $\int_0^1 p(x)\, dx = 1$ ;
they have a minimum: $a > 0$ ; and they do not intersect the x-axis: $b^2 - 4ac < 0$ .
So the maximum values must be at $x=0$ or $x=1$ . What is the upper bound of these maximum values ?","['functions', 'real-analysis']"
1037989,Fourier transform inversion formula for $f\in L_1(\mathbb{R}^n)$ and Dini condition,"Let us define the Dini condition for a function $f\in L_1(-\infty,\infty)$, i.e. Lebesgue summable on $\mathbb{R}$, as Given an $x\in\mathbb{R}$ there is a $\delta>0$ such that the Lebesgue integral $\int_{[-\delta,\delta]}|\frac{f(x+t)-f(x)}{t}|d\mu_t$ exists. In all the post the integrals are to be intended as Lebesgue integrals. I know (p. 423, here , of Kolmogorov-Fomin's Элементы теории функций и функционального анализа ) that, if $f\in L_1(-\infty,\infty)$ satisfies the Dini condition in $x\in\mathbb{R}$, then the inversion formula for the Fourier transform holds: $$f(x)=\frac{1}{2\pi}\lim_{N\to+\infty}\int_{[-N,N]}\Bigg(\int_{\mathbb{R}}f(t)e^{-i\lambda t)}d\mu_t\Bigg)e^{i\lambda x} d\mu_\lambda.$$ The same famous text proves ( p. 437-438 ) a similar theorem for functions $f\in L_1(\mathbb{R}^n)$, under conditions that I do not fully understand, stated in the following way: Let function $f(x_1,x_2,\ldots,x_n)$ ne integrable on the whole space $\mathbb{R}^n$ and let it satisfy the conditions:
  $$|f(x_1+t_1,x_2,\ldots,x_n)-f(x_1,x_2,\ldots,x_n)|\leq C|t_1|^a,$$ $$|f(x_1,x_2+t_2,\ldots,x_n)-f(x_1,x_2,\ldots,x_n)|\leq C(x_1)|t_2|^a,$$$$\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots$$$$|f(x_1,x_2,\ldots,x_n+t_n)-f(x_1,x_2,\ldots,x_n)|\leq C(x_1,x_2,\ldots,x_{n-
> 1})|t_n|^a,$$where $0\le a\le1,\quad\int_{\mathbb{R}}C(x_1)d\mu_{x_1}<\infty,\ldots,\quad\int_{\mathbb{R}}\ldots\int_{\mathbb{R}}C(x_1,\ldots,x_{n-1})d\mu_{x_1}\ldots d\mu_{x_{n-1}}<\infty.$
  Then $$(2\pi)^nf(x_1,x_2,\ldots x_n)=$$$$=\lim_{N_1\to\infty}\int_{-N_1}^{N_1}\Big(\ldots\lim_{N_{n-1}\to\infty}\int_{-N_{n-1}}^{N_{n-1}}\Big(\lim_{N_n\to\infty}\int_{-N_n}^{N_n}g(\lambda_1,\ldots,\lambda_n)e^{ix_n\lambda_n }d\mu_{\lambda_n}\Big)e^{ix_{n-1}\lambda_{n-1}}d\mu_{\lambda_{n-1}}...\ldots\Big)e^{ix_1\lambda_1}d\mu_{\lambda_1} $$ where the integrals are Lebesgue integrals and $g(\lambda_1,\ldots,\lambda_n):=\int_{\mathbb{R}}\ldots\int_{\mathbb{R}}f(x_1,\ldots,x_n)e^{-i\sum_{k=1}^nx_k\lambda_k}d\mu_{x_1}\ldots d\mu_{x_n}$. The theorem is precisely stated in this way in the book (I've only changed some notation to clearly show the integrals are Lebesgue integrals), but I am not sure to understand what are $a$ and the $t_k$ in this wording. Does anybody passing by know the theorem and what the inequalities mean: must they hold for some $a\in[0,1]$ or for all $a\in[0,1]$? As to the $t_k$, $k=1,\ldots ,n$ must they satisfy the inequality for some $\delta>0$ such that $t_1,\ldots,t_n\le\delta$? The proof seems to use the fact that the function $f(-,x_2,\ldots ,x_n)$ as a function of $x_1$ satisfies the above defined Dini condition: does it? Why can we see that? In particular, I am not convinced that $a=0$ could guarantee the Dini condition ($\int_{0}^1 x^{-1}dx=+\infty$). I think that my greatest problem is that I do not understand the conditions in the theorem's statement... Thank you so much for any explanation!","['lebesgue-integral', 'fourier-analysis', 'functional-analysis', 'real-analysis']"
1037999,"Let $\mathcal H$ be a Hilbert space. If $\mathcal H$ is not finite-dimensional, then $B := \{x \in \mathcal H : ||x|| \le 1\}$ is not compact.","Let $\mathcal H$ be a Hilbert space. Consider $B := \{x \in \mathcal H : ||x|| \le 1\}$. I've proven that $B$ is closed and bounded with respect to the metric $\rho(x,y) = || x -y ||$. Now I want to show that if $\mathcal H$ is not finite-dimensional, then $B$ is not compact. For this I've considered the ortonormal system $\{e_n : n \in \mathbb N\}$. I must show that there exist a sequence $(x_n)$ in $B$ such that no subsequence $(x_{n_i})$ of $(x_n)$ is convergent in $B$ ? How can this be done ? Finally, I've tried to find an example of a Hilbert space $\mathcal H$, where $B$ is not compact.","['measure-theory', 'real-analysis']"
1038007,"Let $A_{j,k} = \langle x_j, x_k\rangle$. Show $A$ is invertible if and only if $x_1, \ldots, x_n$ are linearly independent.","Let $V$ be a vector space over $\mathbb C$ with inner product $\langle, \rangle$ and let $x_1, \ldots, x_n$ be vectors in $V$. Consider the $n \times n$-matrix $A$ with entries $A_{j,k} = \langle x_j, x_k\rangle$. I want to show that $A$ is invertible if and only if $x_1, \ldots, x_n$ are linearly independent. I know that orthogonal vectors are linearly independent, so if $x_1, \ldots, x_n$ where orthogonal the result is easily proven. However, the general case I'm stuck at.","['vector-spaces', 'matrices', 'linear-algebra', 'inner-products']"
1038017,In how many ways 3 persons can solve N problems.,"There are $3$ friends $(A,B,C)$ preparing for math exam. There are $N$ problems to solve in $N$ minutes. It is given that: Each problem will take $1$ minute to solve. So all $N$ problems will be solved in exactly $N$ minutes. Only $1$ person will solve a problem, that is if a problem $xyz$ is solved by $A$ , then $B$ and $C$ need not to solve it. Only one person will solve a problem in any given time. That is if $A$ is solving a problem at any given time, then $B$ and $C$ should remain idle(This will ensure that $N$ problems will be solved in exactly $N$ minutes). Now there are some constraints : $A$ being a lover of the number $k$ has decided that the total number of problems solved by him will be a multiple of $k$. (If $k=2$ then $A$ will solve $0$ or $2$ or $4$... problems) $B$ is a lazy guy. So he will not solve any problem in consecutive minutes. He needs rest after solving $1$ problem. $C$ will solve atleast $1$ problem. Determine the number of ways they can solve the problems. Example: if $N=3$ and $k=0$ , then $A$ will not solve any problem, so there are $4$ ways:($B$ solve $1$st, $C$ solve $2$nd and $3$rd)  or ($B$ solve $2$nd, $C$ solve $1$st and $3$rd) or ($B$ solve $3$rd and $C$ solve $1$st and $2$nd) or ($B$ solve $1$st and $3$rd and $C$ solve $2$nd) Given: $0\le k\le10$","['permutations', 'combinatorics']"
1038040,"If $A^2$ is diagonalizable, must $A$ be such as well?","Given a diagonalizable matrix $A^2$, must the matrix $A$ be diagonalizable as well? I can prove that this is true for when $A\in M_{n\times n} (\mathbb{C})$ by using the theorem that the Minimal polynomial for $A^2$ is expressed as a multiplication of linear attributes, and we can simply take $\pm \sqrt{\lambda_i}$ and show that $A$'s minimal polynomial is also a multiplication of linear attributes, thus making $A$ diagonalizable as well. The problem is that I do now know whether or not this statement is correct for $A\in M_{n\times n} (\mathbb{R})$, I know my proof won't work for when $\lambda_i < 0$, but perhaps there is another proof for this? Or a counterexample?",['matrices']
1038054,Evaluation of $\prod_{n=1}^\infty e\left(\frac{n}{n+1}\right)^{n}\sqrt{\frac{n}{n+1}}$,"During my calculations I ended up with the following product:
$$P=\prod_{n=1}^\infty e\left(\frac{n}{n+1}\right)^{n}\sqrt{\frac{n}{n+1}}$$
I tried to express it in terms of series by taking the logarithm 
$$S=\ln P=\sum_{n=1}^\infty \ln\left(e\left(\frac{n}{n+1}\right)^{n}\sqrt{\frac{n}{n+1}}\right)$$
but I also got stuck. Numerical calculation suggests that it is equal to
$$P\stackrel{?}=\frac{\sqrt{2\pi}}{e}$$
but I am not able to prove the conjecture. Any idea about how to evaluate the product? Any help would be appreciated. Thanks in advance.","['sequences-and-series', 'infinite-product', 'calculus', 'products', 'real-analysis']"
1038061,Find the Fourier transform of $u(x) = \frac{x \cos(2x)}{(1+x^2)^2}$,"Find the Fourier transform of $$u(x) = \frac{x \cos(2x)}{(1+x^2)^2}$$ My work Okay so we want $$\int_\mathbb R \frac{e^{-ixt}x\cos(2x)}{(1+x^2)^2}dx$$
Of course we want to apply the residue theorem on the function $\displaystyle f(z) = \frac{e^{-izt}z\cos(2z)}{(1+z^2)^2}$ But on which path?
I thought; let $z = \rho (\cos \theta + i \sin \theta)$, we know  that we will want eventually $\rho \to \infty$ to find our integral over $\mathbb R$. But $$|f(z)| \le \frac{e^{(t-2)\rho\sin\theta} + e^{(t+2)\rho\sin\theta}}{2\rho^3}$$ So if $t < -2$, we can integrate over the positive semicircle as we see that $|f(z)| \to 0$ If $t > 2$, we can integrate over the negative semicircle; again $|f(z)| \to 0$. But if $-2 < t < 2$? Circles are out of the question; our only hope is to maintain $\rho \sin \theta = \text{Im }(z)$ bounded, so the function still tends to $0$ as those exponential are bounded. So I thought: let's take the rectangle $[-R, R] \times [0, \frac 12]$. The contour integral will be $0$.
I think I also know how to show that it vanishes over the vertical lines, but I'm having trouble in calculating the upper integral. My questions 1) Is this line of thinking useful? I mean looking when the modulus of $f$ vanishes to find proper path over which integrating 2) How to finish the exercise? Integrating on the upper part seems a mess. 3) Are there easier ways to find this Fourier transform?","['residue-calculus', 'improper-integrals', 'fourier-analysis', 'complex-analysis', 'contour-integration']"
1038071,Reduce matrix to Smith Normal form.,"I've been given the finitely generated abelian group: $$\langle x_1, x_2 \mid 6x_1-6x_2, -6x_1-12x_2, 4x_1-8x_2\rangle$$ and written the corresponding matrix: $$A=\begin{pmatrix}
  6 & -6  \\ -6 & -12 \\ 4 & -8 \end{pmatrix}$$ I now need to reduce this to Smith Normal form using the unimodular elementary row and column operations. I keep running into difficulties that are usually because I'm not allowed to multiply rows or columns by fractions. How do I do it?","['matrix-decomposition', 'matrices', 'smith-normal-form', 'linear-algebra']"
1038076,Eisenstein integers and applications to Diophantine equations,"Solve the equation $7\times 13\times 19=a^2-ab+b^2$ for integers $a>b>0$. How many are there such solutions $(a,b)$? I know that $a^2-ab+b^2$ is the norm of the Eisentein integer $z=a+b\omega$, but how can I make use of this? Thank you so much.","['diophantine-equations', 'algebraic-number-theory', 'number-theory']"
1038109,Prove that $13\vert(3^{n+1} +3^{n} +3^{n-1})$,Prove that $3^{n+1} +3^{n} +3^{n-1}$ is divisible by $13$ for all positive integral values of $n$,"['algebra-precalculus', 'divisibility', 'number-theory']"
1038118,Bilinear Map vs Inner Product,What is the difference between a Bilinear Map and a Inner Product?,"['linear-algebra', 'inner-products', 'terminology']"
1038174,27 lines on Fermat cubic,"Fermat cubic is $S=\{(x:y:z:w)|x^3+y^3+z^3+w^3 =0\} \in \mathbb{P}^3$. It is obvious that 27 lines on Fermat cubic are represented by $(x,ax,z,bz)$ for cube root $a,b$ of $-1$ and their conjugates. But is there any way to find them by resultant? I tried to follow Hulek's book but it starts by defining $P \in S$ such that $T_P S \cap S=C_P$ has a cusp. Unfortunately, $(1:-1:0:0)$ and some trivial points on $S$ seem to not satisfy that.",['algebraic-geometry']
1038194,Book for Hilbert spaces.,"Which book either on functional analysis or specifically for Hilbert spaces has the best way of explaining with most examples and to the point without much applications. I studied Limaye's book and Kreyszig's book but all the books on functional analysis are too clumsy for me. I want to mainly study eigenspectrums, and compact operators and Hilbert spaces for an exam. So any book, that will help me through it. Thanks!","['book-recommendation', 'reference-request', 'hilbert-spaces', 'functional-analysis']"
1038197,Show that the series $\sum \frac{\sin \left(\frac{\left( 3-4n \right)\pi }{6}\right) }{2^{n}}$ converges?,"Using the addition formula for the sine function I have managed to reduce this to a simpler form:
$$\sum \frac{\cos \frac{2n\pi }{3}}{2^{n}}$$
It is obvious here that it passes the n-th term convergence test. But what next?
I have applied Cauchy's root test, this is the result:
$$\lim_{x\rightarrow \infty }\sqrt[n]{\frac{\cos \frac{2n\pi }{3}}{2^{n}}}$$
For the numerator  being  a ""constant"", I have gotten that the limit is 
$\frac{1}{2}$, which in turn means that the series is convergent. Is my reasoning behind this correct?","['summation', 'sequences-and-series', 'cauchy-sequences', 'limits']"
1038219,Secret Santa Perfect Loop problem,(n) people put their name in a hat. Each person picks a name out of the hat to buy a gift for. If a person picks out themselves they put the name back into the hat. If the last person can only pick themselves then the loop is invalid and either . start again . or step back until a valid loop can be reached. What is the probability that if n is 33 that the chain creates a perfect loop? An example of a perfect loop where n is 4: A gives to B B gives to C C gives to D. D gives to A. An example of a valid but not perfect loop where n is 4: A gives to B B gives to A C gives to D. D gives to C.,"['graph-theory', 'recreational-mathematics', 'probability']"
1038233,"""Subset of above not equal to"" $ \subsetneqq $ Symbol","I was reviewing my Algebra diary, and I noticed a symbol that I was not familiar to: $ \subsetneqq $ . After some research on the internet I eventually found it (through UNICODE), and found that the name was ""Subset of above not equal to"", but I don't understand it. After some more search, I eventually find something here on stackexchange, but I find some conclusions a bit confusing for me. If it means ""Subset of above not equal to"", how can it also mean ""Subset properly included in""? Can we say that the symbol $ \subsetneqq $ equals the symbol $ \subset $ ? Thanks in advance.","['notation', 'elementary-set-theory']"
1038236,How do I show that the derivative of the path $\det(I + tA)$ at $t = 0$ is the trace of $A$? [duplicate],"This question already has answers here : derivative of a determinant of matrix (2 answers) Closed 8 years ago . Here, I'm taking $A$ to be a linear operator on $\mathbb R^n$ for $n>1$. Can you please tell me how to solve such a problem?",['linear-algebra']
1038263,Calculation of $\int_0^{\pi} \frac{\sin^2 x}{a^2+b^2-2ab \cos x}\mathrm dx$,"Calculate the definite integral $$
I=\int_0^{\pi} \frac{\sin^2 x}{a^2+b^2-2ab \cos x}\;\mathrm dx
$$ given that $a>b>0$. My Attempt: If we replace $x$ by $C$, then $$
I = \int_{0}^{\pi}\frac{\sin^2 C}{a^2+b^2-2ab\cos C}\;\mathrm dC
$$ Now we can use the Cosine Formula ($A+B+C=\pi$). Applying the formula gives $$
\begin{align}
\cos C &= \frac{a^2+b^2-c^2}{2ab}\\
a^2+b^2-2ab\cos C &= c^2
\end{align}
$$ From here we can use the formula $\dfrac{\sin A}{a} = \dfrac{\sin B}{b} = \dfrac{\sin C}{c}$ to transform the integral to $$
\begin{align}
I &= \int_{0}^{\pi}\frac{\sin^2 C}{c^2}\;\mathrm dC\\
&= \int_{0}^{\pi}\frac{\sin^2A}{a^2}\;\mathrm dC\\
&= \int_{0}^{\pi}\frac{\sin^2 B}{b^2}\;\mathrm dC
\end{align}
$$ Is my process right? If not, how can I calculate the above integral?","['definite-integrals', 'trigonometry', 'calculus', 'integration']"
1038266,"Suppose that $[G:H]$ is a prime integer, and that $g \notin H$. Prove that H is normal in G.","Let H be a subgroup of a group G. Let $k,g \in G$ such that $gH = Hk$.
Suppose further that $[G:H]$ is a prime integer, and that $g \notin H$. Prove that H is normal in G. I have totally no idea at all how to do this question. Can someone tell me how to start?",['abstract-algebra']
1038270,Does this non-negative non-increasing function eventually attain $0$,"Let $\phi(z): \mathbb{R}\rightarrow [0,B]$, with $B>0$,  be a non-negative and non-increasing  function such that $\phi(0) = B$ and
  \begin{align}
\phi(z) = \max(0, E[\phi(z+X)]+a\mu - c),
\end{align}
  where $X$ is a random variable with mean $E[X]=\mu>0$ such that $c - a\mu=\epsilon > 0$ and finite second moment. Show that $\phi(z_0) = 0$ for some sufficiently large $z_0$. I came across this argument in a paper by Thomas Ferguson about optimal stopping rules [1]: Suppose $\phi(z)>0$ for any $z$, then $E[\phi(z+X)] > c - a\mu = \epsilon > 0$, which since $\phi$ is non-increasing implies $\phi(z)>\epsilon$, which in turn implies that $E[\phi(z+X)]>2\epsilon$ for sufficiently large $z$, etc. Eventually this would imply that $E[\phi(z+X)]>B$, a contradiction. However, it is not clear to me, how one can infer that $E[\phi(z+X)]> \epsilon$ implies $\phi(z)>\epsilon$ when there are no additional constraints on $X$ such as boundedness. [1] Thomas S. Ferguson, ""Some Time-invariant Stopping Rule Problems"".","['probability', 'real-analysis']"
1038286,Acyclic chain complex and contracting chain homotopy,"Let $R$ be a Ring and $(C_k, d_k)_{k\geq0}$ an acyclic chain complex of free modules,  meaning $im(d_{k+1})=\ker(d_k)$ for all $k$. I want to show that there is a family of R-module homomorphisms $s_k: C_k \rightarrow C_{k+1}$ so that $$s_{k-1}d_k-d_{k+1}s_k=id_{C_k}.$$
I don't know how to get $s_k$. By definition $d_1$ is surjective and $C_0$ a free module, so I can find a R-module homomorphism $f_1:C_0 \rightarrow C_1$ so that $s_0f_1=id_{C_0}$ but this doesn't work in all the other cases. Thank you.","['homological-algebra', 'algebraic-topology', 'abstract-algebra']"
1038292,Why can we use flabby sheaves to define cohomology?,"In my algebraic geometry class, we defined sheaf cohomology using flabby sheaves, and the functor on the category of sheaves on a space $X$: $$
D: \mathcal F \mapsto D\mathcal F
$$ where $$
D\mathcal F(U)=\left\{s:U\to \bigsqcup_{p\in X}\mathcal F_p\middle| s(p)\in\mathcal F_p\right\}
$$ $D\mathcal F$ is then a flabby sheaf containing $\mathcal F$. But when I did some further research into derived functor cohomology, it became clear that the important property you need is that sheaf categories 'have enough injectives' - so every sheaf is a subsheaf of some injective sheaf.  At first I thought that flabby sheaves and injective sheaves were the same thing, but then I found out that in fact, being injective is a stronger property: every injective sheaf is flabby, but not every flabby sheaf is injective. How then, were we able to develop the cohomology theory using flabby sheaves, when one in general needs to consider injective objects?","['sheaf-theory', 'algebraic-geometry', 'sheaf-cohomology', 'abelian-categories']"
1038305,Function in Lipschitz space,"I'm looking for a function that is in $W^{1,1}(0,1)$ but only in the Lipschitz space $\mathrm{Lip} (\alpha, L_2(0,1))$ for $0<\alpha < 1$. $\mathrm{Lip}(\alpha, L_2(0,1))$ is defined as the set of all functions $f\in L_2(0,1)$ for which $|| f(\cdot + h) - f(\cdot)||_{L_2(0,1-h)} \le C h^{\alpha}$  for every $1 > h > 0$. I thought about $f(x) = x^{\alpha}$ which is in $L(\alpha, L_{\infty}(0,1))$ but not in higher spaces. But some numerical experiments show that this function is possibly in $\mathrm{Lip}(1,L_2)$ and not only in $\mathrm{Lip}(\alpha, L_2(0,1))$. Can someone help me?","['lipschitz-functions', 'special-functions', 'examples-counterexamples', 'functions', 'analysis']"
1038315,Inequalities with arctan,"I don't understand how to solve inequalities with arctan, such as: $$\arctan\left(\frac{1}{x^2-1}\right)\ge \frac{\pi}{4} $$ If someone could solve this and give me a very brief explanation of what they did, I'd be thankful.","['trigonometry', 'inequality']"
1038320,Line with two origins is a manifold but not Hausdorff,"The line with two origins is $(\mathbb{R} \times \{0,1\})/\sim$ where $(x,0)\sim(x,1)$ for $x\neq 0$. I can see that it is not Hausdorff, since we cannot separate the points $(0,0)$ and $(0,1)$. However, I'm not quite clear on why it is a manifold, in particular why it is locally Euclidean. Please help me understand why this is so.","['general-topology', 'manifolds']"
1038384,Question about solutions of $x''+(1+r(t))x=0$ when $\int_1^\infty |r(t)| dx <\infty$ .,"Let $x''+(1+r(t))x=0$ where $r(t)$ is continous and $\int_1^\infty |r(t)| dx <\infty$  show that the equation has solutions $\phi_1$ and $\phi_2$ such that $$\lim_{t\to\infty} [(\phi_1(t)-e^{it})=0$$ and $$\lim_{t\to\infty} [(\phi_1'(t)-ie^{it})=0$$
and $$\lim_{t\to\infty} [(\phi_2(t)-e^{-it})=0$$ and $$\lim_{t\to\infty} [(\phi_2'(t)+ie^{-it})=0$$ I don't know how to start to solve. I need some hint. thanks.","['dynamical-systems', 'ordinary-differential-equations', 'analysis']"
1038391,Concrete Mathematics Josephus Problem: How to prove 1.17 & 1.18,"On the last page of the Josephus problem where things get really general, we're shown the pretty slick radix changing recurrence & solution 1.17 & 1.18 f(j) = a j , for 1 <= j <= d; f(dn + j) = cf(n) + B j , for 0 <= j < d and n>=1; & f((b m b m-1 ...b 1 b 0 ) d ) = (a b m B b m-1 B b m-2 ...B b 1 B b 0 ) c but we're not shown how they are proved, only that we start in radix d and end in radix c. How can one go about proving these, based on what has been presented thus far in the problem?  Sorry for the typesetting I'm new to this.","['recurrence-relations', 'discrete-mathematics']"
1038396,Solve $\lfloor \sqrt x \rfloor = \lfloor x/2 \rfloor$ for real $x$,"I'm trying to solve $$\lfloor \sqrt x \rfloor = \left\lfloor \frac{x}{2} \right\rfloor$$ 
for real $x$.
Obviously this can't be true for any negative reals, since the root isn't defined for such. My approach is the following: Let $x=:n+r$, $n \in \mathbb{N}_0, 0\leq r < 1$. For the left hand side $\lfloor \sqrt {n+r} \rfloor = \lfloor \sqrt {\lfloor n+r\rfloor} \rfloor = \lfloor \sqrt n \rfloor$ holds (without further proof). $$\left\lfloor \frac{x}{2} \right\rfloor = \left\lfloor \frac{n+r}{2} \right\rfloor = \left\{ \begin{array}{l l} \frac{n}{2} & \quad \text{for n even} \\ \frac{n-1}{2} & \quad \text{for n odd} \end{array}\right.$$ Now I don't really know if that'd lead me in the right direction, but I'll write my thoughts down anyways. Let $\sqrt n =: n'+r'$, $n \in \mathbb{N}_0, 0\leq r < 1$. Therefore $\lfloor n'+r' \rfloor = n'$. And $n = (n'+r')^2 = n'^2 +2n'r' +r'^2$ For which $n',r'$ holds $$ n' < n'^2 + 2n'r' + r'^2.$$ Well and now I'm stuck and don't know how to proceed. I'd appreciate any help.","['discrete-mathematics', 'ceiling-and-floor-functions']"
1038422,Hausdorff dimension of $\lim_{n\to\infty}\sin(2^nx)$,"Calculate the Hausdorff dimension,$\dim_H$ of $$S=\{x\in(0,1):\lim_{n\to \infty}\sin2^nx=0\}$$ By definition We need to find the minimal $\alpha$ s.t $\sum_{i\in I}|U_i|^\alpha$ is minimal where $U_i$ is an open cover for the set. On the other hand, I'm not sure it exists since the function diverges when $n\to\infty$. How can I find the dimension or prove that it doesn't exist?","['general-topology', 'dimension-theory-analysis', 'functions', 'real-analysis']"
1038430,"Euler characteristic, genus and cohomology: a deep connection?","For a smooth projective curve $V$ over the complex numbers, the algebraic genus, defined as the dimension of the linear system $L(\omega)$, where $\omega$ is the canonical divisor, coincides with the topological genus of the curve, found by counting holes via homology/cohomology groups or by triangulating the curve and computing the Euler characteristic.  According to Hulek's 'Elementary Algebraic Geometry', this is a deep fact. Here is another deep fact: given a complex quasi-projective variety, the simplicial (we may substitute singular) cohomology coincides with the de Rham cohomology on the Riemann surface induced by the variety.  Since the algebraic version of genus involves divisors given by differentials (measured by the de Rham cohomology) and the topological version can be read off from the singular cohomology groups (or found by counting faces, edges and vertices in a suitablevsimplicial complex), it is very tempting to jump to the conclusion that these two deep facts are closely related.  Are they? Follow-up: Can one derive interesting alternative versions of the genus by considering sheaf cohomology, Čech cohomology (induced by either the Zariski or the classical topology) and other cohomology theories on algebraic varieties?","['big-picture', 'differential-geometry', 'homology-cohomology', 'algebraic-geometry', 'algebraic-topology']"
1038446,Difference between Integral Domains and Fields.,"Can someone please help me in figuring out how all fields are integral domains but not all ID are fields? 
My course assumes IDs to be commutative with unity but fields require all elements to have a unit.
I can't seem to grasp their concepts.",['abstract-algebra']
1038478,Why use the Lefschetz Zeta function?,"Given a compact, triangulable space $X$ and a continuous function $f: X\rightarrow X$, then we define the Lefschetz number $\Lambda_{f}$ by $$\Lambda_{f} = \sum_{k\geq0}(-1)^{k}Tr(f_{\ast}\vert H_{k}(X,\mathbb{C}))$$ If $f$ has only finitely many fixed points, then  by the Lefschetz-Hopf theorem $$\Lambda_{f}=\sum_{x=f(x)}i(f,x)$$ where $i(f,x)$ is the fixed point degree of the fixed point $x$. The fixed point degree at a point can loosely be thought of as the multiplicity of the map at that point. We define the Lefschetz Zeta function by $$\zeta_{f}(z)=\exp\left(\sum_{n=1}^{\infty}\Lambda_{f^n}\frac{z^n}{n}\right)$$ and we see using the Lefschetz Hopf theorem that $$\zeta_{f}(z)=\prod_{i=0}^{n}\det(1-zf_{\ast}\vert H_{i}(X,\mathbb{C}))^{(-1)^{i+1}}$$ Now this is all very well and good, but as far as I can tell there is nothing new to be gained from $\zeta_{f}(z)$. It seems to be specifically constructed so that the Lefschetz Hopf theorem can simplify it. Am I wrong? Does $\zeta_{f}(z)$ actually help us retireive informatin about $f$? Do the coefficients of $\zeta_{f}(z)$ correspond to anything? When would I actually learn anything by constructing this function?","['dynamical-systems', 'fixed-point-theorems', 'zeta-functions', 'general-topology', 'algebraic-topology']"
1038504,When does the limit of the ratio of consecutive terms of a sequence exist?,"I am trying to understand and obtain some sufficient conditions under which the limit of the ratio of consecutive terms of a sequence exists. Let $x_n$ be a sequence of positive integers, such that $\displaystyle\lim_{n\rightarrow \infty} x_n =\infty$. When does $\displaystyle\lim_{n\rightarrow \infty} \dfrac{x_{n+1}}{x_n}$ exist? If we assume that $\displaystyle\lim_{n\rightarrow \infty}\root n \of {x_n}=a$, then I can show that the required limit, if it exists, is equal to $a$. I don't want to ask the question in extreme generality, so I am assuming that the sequence $x_n$ grows at most exponentially. For instance, since $y_n:=\frac{x_{n+1}}{x_n}$ is bounded (when the growth is at most exponential), one such condition is monotonicity of the sequence $y_n$, which gives me the condition $x_{n+1}x_{n-1}\geq x_n^2$. One of my questions is whether the limit in question exists for exponentially growing sequences. Also, what sufficient conditions are there for sub-exponential sequences? Any help appreciated!","['sequences-and-series', 'real-analysis']"
1038524,possible pizza orders,"You are ordering two pizzas. A pizza can be small, medium, large, or extra large, with any combination of 8 possible toppings (getting no toppings is allowed, as is gettting all 8). How many possibilities are there for your two pizzas? Would it be ${\large[}4{\large[}{8\choose8}+{8\choose7}+{8\choose6}+{8\choose5}+{8\choose4}+{8\choose3}+{8\choose2}+{8\choose1}+{8\choose0}{\large]}{\large]}^2$",['combinatorics']
1038535,When is a vector field on a manifold restricted to a submanifold $X$ a vector field on $X$?,"Let $X$ be an embedded submanifold of $M$ and let $V$ be a vector field on $M$. One can restrict $V$ to $X$, but it may not define a vector field on $X$. Example: The vector field $x^i\partial_i$ on $\mathbb{R}^n$ does not define a vector field when restricted to $S^{n-1}$. Given a vector field $V$ on $M$ and an embedded submanifold $X$, is there a way to determine whether $V|_X$ is a vector field on $X$? One can define the projection of the restricted vector field. Choose a Riemannian metric on $M$ and let $NX$ be the normal bundle of $X$ in $M$, then $TM|_X = TX\oplus NX$. Let $p : TM|_X \to TX$ be projection onto the first factor, then we obtain a vector field on $X$ given by $p\circ V|_X$. Note, this does not depend on the choice of Riemannian metric. If we were to perform this construction for the above example, the vector field we obtain on $S^{n-1}$ is the zero vector field. It is clear that $V|_X$ is a vector field on $X$ if and only if $p\circ V|_X = V|_X$. This doesn't satisfy me though as it is rather tautological.","['vector-fields', 'differential-geometry']"
1038565,Spherical geometry vs elliptic geometry,"Wikipedia says that ""spherical geometry"" and ""elliptic geometry"" are both the geometry of the surface of a sphere. It also asserts that these two geometries are not the same — but neglects to explain what the actual difference is. Does anybody know how these two systems are actually different?","['geometry', 'terminology']"
1038625,How can I prove the last two digits of $1+2^{2^{n}}+3^{2^n}+4^{2^n}$ always are $54$,How can I prove the last two digits of  $$1+2^{2^{n}}+3^{2^n}+4^{2^n}$$ are $54$ when $n$ is a positive integer number if $n>1$,['number-theory']
1038646,"Measurability of $f:X\times Y\to\mathbb{K}$ and $f(-,y):X\to\mathbb{K}$","Let $(X,\mu_x)$ and $(Y,\mu_y)$ be two measure spaces endowed with $\sigma$-additive compete measures $\mu_x$ and $\mu_y$, respectively. Let $\mu:=\mu_x\otimes\mu_y$ be the Lebesgue extension of measure $\mu_x\times\mu_y$ defined by $(\mu_x\times\mu_y)(A\times B)=\mu_x(A)\mu_y(B)$ for any two measurable sets $A\subset X$, $B\subset Y$. I wonder what we can say about the the $\mu$-measurability of a function $f:X\times Y\to\mathbb{K}$, where $\mathbb{K}=\mathbb{R}$ or $\mathbb{K}=\mathbb{C}$, if we know the $\mu_x$-measurability of $f(-,y):X\to\mathbb{K}$ for all $y\in Y$ and the $\mu_y$-measurability of $f(x,-):Y\to\mathbb{K}$ for all $x\in X$, and vice versa . Does any implication between the two exist? The issue has arisen in my mind because I found the statement in problem 6 here that if $\int_X (\int_{A_x}|f(x,y)| d\mu_y)d\mu_x$, where $A_y=\{y\in Y:(x,y)\in A\}$, exists then $\int_A fd\mu$ does. I think it is implicitly intended that $f:A\to\mathbb{K}$ is measurable, but I think it would be interesting to explore the possibility of reciprocal implications. Thank you very much for any answer!","['lebesgue-integral', 'measure-theory', 'lebesgue-measure', 'real-analysis']"
1038660,without using l'hopital rule,"Can someone give me please some guidance hoe to solve the following limit, without using L'Hopital rule? $$\lim\limits_{n \to \infty } \frac{n}{\ln\left(\frac{3n}{5}\right)}$$ Thanks a lot!","['limits-without-lhopital', 'calculus', 'limits']"
1038694,Find the chance that $a^3 + b^3 \equiv 0 (\mod 3)$,"We are given set of integer numbers $\{1,2, \dots N\}$. $N \ge 3$ Then perform a drawing with replacement of two elements $a$ and $b$. Problem is to find the probability of following statement holding true: $a^3 + b^3 \equiv 0\space (\mod 3)$ Solution draft I believe Little Fermat theorem will be of help here, $ a^3 \equiv a \space(\mod 3)$. From there we conclude that either $a$ and $b$ both must be divisible by 3, or one must have residue 1 and other must have 2. Total amount of possible $a$ and $b$ pairs is $n^2$. Case when $3|a$ and $3|b$ is achievable for ${\lfloor \frac n 3 \rfloor}^2$ pairs. Last case holds for the same amount of pairs. Hence, answer would be $\frac {2{\lfloor \frac n 3 \rfloor}^2} {n^2} = \frac 2 9$ Is that a correct answer and is that legal to drop lowerbound around $\frac n 3$ here?
Thanks! Edit Solution above is wrong. Suppose, $N=4$ than (3,3) (2,1) (2,4) (1,2) (4,2) fits, hence $P= \frac 5 {16}$. I would appreciate some suggestions. Edit 2 $$
    P = \begin{cases}
    \frac 1 3 & if N \equiv 0 (\mod 3 )\\
    \frac {{\lfloor \frac n 3 \rfloor}^2 + 2 \cdot \lfloor \frac n 3 \rfloor \lceil \frac n 3 \rceil}{n^2} & N \equiv 1 (\mod 3 )\\
\frac {{\lfloor \frac n 3 \rfloor}^2 + 2 \cdot \lceil \frac n 3 \rceil \lceil \frac n 3 \rceil}{n^2} & N \equiv 2 (\mod 3 )
\end{cases}$$","['elementary-number-theory', 'probability', 'proof-verification', 'combinatorics']"
1038703,"Find a bijection, check if a given set is a function","I have problems with two exercises: $1)$ Find a bijection between $A$ and $B$. $$A=[0,1) \times[0,1)$$
$$B=\{{<x,y>}\in \mathbb R^2: x,y>0,\ x+y<1\}$$ $2)$ Decide if the given set is a function. $$\{<x,f>: x\in \mathbb R \ \ \wedge f: \mathbb R\to \mathbb R \ \ \wedge \forall _{r \in \mathbb R} [f(r)=x] \}$$","['elementary-set-theory', 'functions']"
1038712,Linear functional $f$ is continuous at $x_0=0$ if and only if $f$ is continuous $\forall x\in X$?,"Let $f$ be a linear functional on a normed space $(X, \|\cdot\|)$. Prove that $f$ is continuous at $x_0=0$ if and only if $f$ is continuous at every $x\in X$. I understand that the $\Leftarrow$ is trivial but what about the other way?","['continuity', 'functional-analysis']"
1038713,General form of a Möbius transformation sending two points to two points and a circle to another.,"Suppose I am given a circle $C$ in $\Bbb C^*$  and two points $w_1,w_2$. Given another circle $C'$ and points $z_1,z_2$, what is the procedure to find a Möbius transformation that sends $C\to C'$, $w_i\to z_i,i=1,2$? Here $z_1\in C\not\ni z_2$; $w_1\in C'\not\ni w_2$. For example, take $|z|=2$, $w_1=-2,w_2=0$. Then, the transformation $T(z)=-\dfrac{z+2}{2}$ sends $|z|=2$ to $|z+1|=1$, $-2$ to $0$, and $0$ to $-1$. Hence, I need to find a transformation that fixes $|z+1|=1$ and $0$, and sends $-1$ to $i$. I know that if $|\alpha|\neq 1$, the transformation $$T(z)=\frac{z-\alpha}{1-z\bar \alpha}$$ fixes $|z|=1$, sends $\alpha$ to $0$ and has fixed points $\sqrt{\dfrac{\alpha}{\bar\alpha}}$. I obtained $T$ using $4$ successive transformations $T_1=-(z+2)$, $T_2=\dfrac{z}{z+2}$, $T_3=-z$ and $T_4=-\dfrac{z}{z+1}$, which seems a bit ineffective. How can I generally find $T$ given $(C,C',(z_1,z_2),(w_1,w_2))$?",['geometry']
1038735,Is there a linear order with this property,I was trying and failing to construct a linear order L each of whose uncountable subsets contains an uncountable well ordered subset but L is not a countable union of well ordered subsets. Is this possible? Thanks for any ideas!,"['elementary-set-theory', 'order-theory']"
1038749,do discrete probability distribution functions need a countable number of outcomes?,"Everywhere I see on the internet they say that discrete probability distribution functions have a countable number of outcomes, and continuous have uncountable infinite number of outcomes. However if your domain is infinite dimensional with finite number of elements in each dimension, then clearly there is uncountable infinite many outcomes but discrete. An example is a single experiment of flipping a coin infinite number of times. So what am I missing?",['statistics']
1038771,Rank of a matrix $A^2$ without calculating the square,"I have a matrix $A=\begin{bmatrix}
2 & 0 & 4\\ 
1 & -1 & 3\\ 
2 & 1 & 3
\end{bmatrix}
$
with rank 2.
How do I prove that the matrix $A^2$ has also rank 2 without actually calculating $A^2$. I know that $rank(AB)\leq min(rank(A), rank(B))$, and so $rank(A^2) \leq 2$, but I still don't have enough information. Thanks!","['matrices', 'linear-algebra']"
1038784,"If $\sum{a_k}$ converges, then $\lim ka_k=0$. [duplicate]","This question already has answers here : If $x_{n}$ is decreasing and $\sum x_{n}$ converges, prove that $\lim nx_{n} = 0$ [duplicate] (2 answers) Closed 9 years ago . I want to prove the following statement: Suppose that $\displaystyle\sum_{k=1}^{\infty}a_k$ converges, where $(a_k)_{k\in\mathbb{N}}\subseteq\mathbb{R}$ is monotone. Then $\displaystyle\lim_{k\to\infty}ka_k=0$. I believe we have several cases. For example, if $(a_k)_{k\in\mathbb{N}}$ is monotone increasing and there exists $k$ such that $a_k>0$, then obviously $\displaystyle\sum_{k=1}^{\infty}a_k$ is not convergent. Then, we could conclude that if some $a_k>0$ then we can suppose that $(a_k)_{k\in\mathbb{N}}$ is monotone decreasing. By the same argument, we can conclude that if some $a_k<0$ then $(a_k)_{k\in\mathbb{N}}$ must be monotone increasing. So, I believe we only need to take care of the case where $a_k\ge 0$ for each $k\in\mathbb{N}$ and $(a_k)_{k\in\mathbb{N}}$ is monotone decreasing (the other case would be symmetric). Any hint to prove this? I have been thinking a lot ot time... Thanks.",['real-analysis']
1038786,Existence of projectives in the category of torsion abelian groups,"Consider the category of torsion abelian groups. This category doesn't have enough projectives by the following argument. Suppose $C_2$ (cyclic group of order 2) is the homomorphic image of a projective $P$, where $x\in P$ maps to the generator of $C_2$. There is a surjective map $C_{2^k}\to C_2$ by sending one generator to the other. Since $P$ is projective, it lifts to a map $P\to C_{2^k}$ sending $x$ to some generator. Hence $x$ has order at least $2^k$. Since $k$ is arbitrary, $x$ has unbounded order, a contradiction since $P$ is torsion. Question : does this category have any (non-trivial) projectives? If so, what is an example?","['homological-algebra', 'category-theory', 'abstract-algebra', 'abelian-groups']"
1038797,Kinematics of gravity in a non uniform field,"I am a first year physics student. I am trying to figure out how to compute position in terms of time for an object falling through non uniform gravity towards the earth, and by extension towards any body.
There are two formulas that can help with this:
$$-{GM_E \over r^2}={d^2 r \over dt^2} $$ which is a second order differential equation. A presumably simpler approach would be to use the energy formula for velocity, that is  $$K = {GM_{E}m} {\left({1 \over r} -{1\over r_i} \right)}={1 \over2}mv^2 $$
Solving for velocity would yield the first order differential equation :
$$v={dr\over dt}=\sqrt{{2GM_{E}} {\left({1 \over r} -{1\over r_i}  \right)}} $$
Apparently, however, there is no elementary function that can be used as an anti derivative for this function. I searched the internet far and wide, but I could not find any straightforward answer to this.Obviously the answer is far from straightforward, otherwise it would be taught in physics texts. However, it appears to be far too fundamental a concept to not have a known solution for. P.S. If the answer involves anything such as Lagrange multipliers and the like, if whoever answers this question doesn't mind, please provide at least a basic explanation of it, because I haven't yet taken anything beyond second year calculus. Thank you.","['dynamical-systems', 'ordinary-differential-equations', 'physics']"
1038847,Is the intersection between two $n$-spheres an $(n-1)$-sphere?,Is it true that the intersection between two $n$ -sphere in $\mathbb{R}^n$ is a $(n-1)$ -sphere if is not empty or a single point? I have tried to prove it but my only idea is to work with equations and apparently is not a good idea.,"['geometry', 'linear-algebra', 'hilbert-spaces']"
1038863,How is Riemann–Stieltjes Integration insufficient for developing modern probability theory?,"If we consider Riemann–Stieltjes integration then it can perfectly account for mixed probability distribution (a continuous R.V with some point mass). So why would we still need Lebesgue Integration theory? Is it because the Riemann integrable class is not large enough, or is it because under Riemann integration interchanging limits and integration is too hard(usually requiring uniform convergence)?","['lebesgue-integral', 'probability', 'integration']"
1038881,"Every $\sigma-$finite measure is semifinite. $(X, \mathcal{M}, \mu)$ is a measure space.","Definition 1: Say $X = \bigcup_{n=1}^{\infty} E_n $ where $E_n \in \mathcal{M}$ and $\mu( E_n ) < \infty $ for all $n$ , we call $\mu$ $\sigma$ -finite. More generally, if $E = \bigcup^{\infty} E_n $ where $E_n \in \mathcal{M}$ for all $n$ and $\mu(E_n) < \infty $ for all $n$ then $E$ is said to be $\sigma-$ finite for $\mu$ . Definition 2: If for each $E \in \mathcal{M}$ with $\mu(E) = \infty$ , there exists $F \in \mathcal{M}$ with $F \subset E $ and $0 < \mu(F) < \infty$ , then we cal $\mu$ semifinite. Problem: Every $\sigma-$ finite measure is semifinite. Attempt Let $\mu$ be a $\sigma-$ finite measure on $X$ . Take $E \in \mathcal{M}$ arbitrary with $\mu(E) = \infty $ . Write $$ E = \bigcup^{\infty} E_n \; \; \; \; E_n \in \mathcal{M} \; \; forall \; \; n $$ (Here is where I am not sure I am doing the problem correctly. Can I assume that I can write $E$ in such a form? ) Next, there is some $k$ such that $E_k \subset E $ . Hence by monotonicity, $$ 0 \leq \mu(E_k) < \mu(E) = \infty $$","['measure-theory', 'proof-verification', 'real-analysis']"
1038904,Do primes modulo k form a normal sequence?,"For some $k>2$, form a sequence whose nth term is the nth prime that is not a divisor of $k$ modulo $k$. e.g. for $k=4$ the sequence would be 1,3,1,3,3,1,1,3,3,1,3,1... Is this sequence normal, in the sense that every string of length $w$ consisting of numbers in $\{1..k\}$ coprime to $k$ occurs as a block of consecutive terms with asymptotic density $\frac{1}{\phi(k)^w}$? Note that the case $w=1$ is equivalent to Dirichlet's theorem.","['prime-numbers', 'ergodic-theory', 'number-theory']"
1038917,Geometric interpretation of ${\partial f\over \partial x}= {\partial f \over \partial y}$,"I know that $${\partial f\over \partial x}= {\partial f \over \partial y}$$ iff there exists a differentiable function $g$ (of one variable) such that $g(x+y)=f(x,y)$ (where $f : D\subseteq \mathbb R^2 \to \mathbb R$ and $D$ is an open set), but I don´t know what is the geometric interpretation of this fact. So I would really appreciate if you can help me with this","['differential', 'multivariable-calculus', 'partial-derivative']"
1038951,"Continuous increasing bounded function, derivative","Is it true that a differentiable (and hence continuous) increasing bounded function $f:\mathbb{R} \to \mathbb{R}$ has derivative $f'$ that must go to zero as $x \to \infty$. If it is, could someone supply a proof? This is just something I wanted to prove another result with, I discovered the original thing I wanted to prove was false, but I am still interested in this.","['calculus', 'analysis']"
1038953,How many permutations do we need before we're in $SU\left( n\right)$?,"Let $\mathcal{L}\subseteq \mathfrak{su}\left( n\right)$ be a Lie algebra for $n \geq 2$ with Lie group $G = e^{\mathcal L}$, and let $X \in G$ be represented by an $n\times n$ matrix (I prefer fixing a basis to work with something tangible). Suppose $P_1, P_2, \ldots , P_k \in G$ are permutation matrices. What are the necessary conditions on $\left\{ P_k\right\}$ to guarantee that $G = SU\left( n\right)$? Do such conditions even exist? This question arises in the context of a larger control problem as follows: Let $n = 4$ and $G \subsetneq SU\left( n\right)$ by assumption. Let the group action on $X_1, X_2 \in G$ be the matrix product $X_1 X_2$. Suppose we can generate any element of a group $G_1 \subset G$: $${G_1} = SU\left( 3 \right) \oplus 1 = \left\{ {X = \left[ {\begin{array}{*{20}{c}}
  U&{} \\ 
  {}&1 
\end{array}} \right],\,\,U \in SU\left( 3 \right)} \right\}$$ and let us consider the group $G_2 \subset G$: $${G_2} = \left\{ {Y = \left[ {\begin{array}{*{20}{c}}
  {{y_{11}}}&{{y_{12}}}&{}&{{y_{13}}} \\ 
  {{y_{21}}}&{{y_{22}}}&{}&{{y_{23}}} \\ 
  {}&{}&1&{} \\ 
  {{y_{31}}}&{{y_{32}}}&{}&{{y_{33}}} 
\end{array}} \right],\,\,\left[ {\begin{array}{*{20}{c}}
  {{y_{11}}}&{{y_{12}}}&{{y_{13}}} \\ 
  {{y_{21}}}&{{y_{22}}}&{{y_{23}}} \\ 
  {{y_{31}}}&{{y_{32}}}&{{y_{33}}} 
\end{array}} \right] \in V} \right\},\,\,V \subseteq SU\left( 3 \right)$$ It is easily seen that if we can generate the permutation matrix $${P_{\left( {3,4} \right)}} = \left[ {\begin{array}{*{20}{c}}
  1&{}&{}&{} \\ 
  {}&1&{}&{} \\ 
  {}&{}&{}&1 \\ 
  {}&{}&1&{} 
\end{array}} \right]$$ then we can generate elements of $G_2$ such that $V = SU\left( 3\right)$. In general, the converse doesn't hold. That is, $V = SU\left( 3\right) \not\Rightarrow P_{\left( {3,4} \right)} \in G$. We see that $G_1$ ""comprises"" rows $1, 2, 3$, and $G_2$ comprises rows $1,2,4$. This concepts extends to general $n$, for groups comprising $2 \leq m < n$ rows, where we call such groups ""$m$-subgroups"" of $G$. An identical derivation shows that if any such $m$-subgroup $G_a \sim SU\left( m\right)$ can be generated for row tuple $a = \left( a_1, a_2, \ldots , a_m\right)$, along with the permutation matrix $P_{a\rightarrow b}$, this implies that $m$-subgroup $G_b$ for row tuple $b = \left( b_1, b_2, \ldots , b_m\right)$ is also isomorphic to $SU\left( m\right)$. In this way, the $SU$-isomorphism of an $m$-subgroup extends to all $m$-subgroups we can reach via the set of permutations we can generate in $G$. Thus if we know the group $P$ of permutations that can be generated in $G$ (or in particular, a set of permutations $\left\{ P_k\right\}$ that generates this group), this saves us a considerable bit of work in checking each $m$-subgroup for isomorphism. In the process of systematically determining $\left\{ P_k\right\}$, the issue then arises that we've assumed $G \subsetneq SU\left( n\right)$, hence if the set of $P_1, P_2, \ldots , P_k \in G$ implies $G = SU\left( n\right)$ at any point during the construction, we've violated our assumption. In the context of this control problem, this means that determining $SU$-isomorphism of the $m$-groups is moot and we needn't bother checking.","['matrices', 'permutations', 'group-theory', 'lie-groups']"
1038955,Evaluate $\sum\limits_{n=1}^{\infty} \frac{2^n}{1+2^{2^n}}$,How to evaluate the infinite series: $$\sum\limits_{n=1}^{\infty} \frac{2^n}{1+2^{2^n}}$$,"['sequences-and-series', 'real-analysis']"
1038966,"If nonnegative $f: [0,1] \rightarrow \mathbb{R}$ has a continuous $f''$, then $\int_0^1 \Big| \frac{f''(x)}{f(x)} \Big| \,dx >4$","Assume that $f: [0,1] \rightarrow \mathbb{R}$ has a continuous $f''$ and $f$ is positive on the interval $(0,1)$ and $0$ at the endpoints. I want to prove that $$\int_0^1 \Big| \frac{f''(x)}{f(x)} \Big| \,dx >4. $$ I could not make any progress. Since the unit interval is compact, we know that the continuity of $f, f'$ and $f''$ are uniform and they attain their maximum and minimum values. Moreover, I tried to apply the Mean Value Theorem but I failed.","['integration', 'continuity', 'real-analysis', 'derivatives', 'uniform-continuity']"
1038994,Prove $\cos x = \frac{8}{\pi}\sum_n \frac{n\sin 2nx}{4n^2-1}$ with Fourier series,"I want to prove $$\cos x = \frac{8}{\pi}\sum_n \frac{n\sin 2nx}{4n^2-1}\;x\in(0,2\pi)\;\;\;\;[1]$$ I have two questions regarding this: $(1)$ How can I find a function $f$ such that the former series can be obtained using the Fourier series of $f$? I know the Fourier series will be given by $$f(x)=a_0+\sum_n\left(a_n\cos\frac{n\pi x}{L}+b_n\sin\frac{n\pi x}{L}\right)$$ then should I asssume that the $\cos$ in the left hand side of $[1]$ is the $\cos$ inside the latter series? Since no $\pi$ appear in the denominator of $[1]$, and $n\sin 2nx=n\sin nx\cos nx$ I thought that could $a_n=n\sin nx$ or $b_n =n\cos nx$ but these terms are given by definite integrals so no $x$ term can appear in them. An alternative approach could be using $L=\pi/2$, then it must be $b_n=\frac{n}{4n^2-1}$, but this would imply $\frac{n}{4n^2-1}=\int_0^{\pi/2}f(x)\sin nx dx$, and I'm having some issues to get ride of the sine. $(2)$ In the general case, given any series how can I proceed to find the function $f$?","['fourier-series', 'sequences-and-series']"
1039001,Every skew-symmetric matrix has a non-negative determinant,"Let $A$ be a skew-symmetric $n\times n$-matrix over the real numbers. Show that $\det A$ is nonnegative. I'm breaking this up into the even case and odd case (if $A$ is an $n\times n$ skew-symmetric matrix). So when $n$ is odd, we have: $\det(A)=\det(A^T)=\det(-A)=(-1)^n\det(A)\Rightarrow \det(A)=-\det(A)\Rightarrow \det(A) = 0$ So $\det(A)$ is non-negative when $n$ is odd. When $n$ is even, we have: $\det(A)=\det(A^T)=\det(-A)=(-1)^n\det(A)\Rightarrow \det(A)=\det(A)$ But why can't $\det(A)$ be negative in this case?","['matrices', 'linear-algebra', 'skew-symmetric-matrices', 'determinant']"
1039007,Proving uniqueness of $e$ [duplicate],"This question already has answers here : Proving that a definition of e is unique (3 answers) Closed 9 years ago . Let's define $e$ as the number $a$ such that $\frac {d}{dx} a^x = a^x$.  I'm trying to prove that this $a$ has to be $e$.  I don't see any way of proceeding from here except by the limit definition (I'm not assuming I know what the $\ln$ function is, or else there'd be a much easier definition of $e$ to be had). $$\frac {d}{dx} a^x=\lim_{h\to 0} \frac {a^{x+h}-a^x}{h}=\lim_{h\to 0} a^x\frac{a^h-1}{h}=a^x\left(\lim_{h\to 0} \frac{a^h-1}{h}\right)$$ So clearly $e$ must be the number that makes that limit on the far right equal to $1$.  I'm not sure how to evaluate this. Using L'Hopital's rule, I just get $\lim_{h\to 0} \frac {d}{dh} a^h$, which doesn't particularly help. So my question: How can I prove that there is a unique number such that $\lim_{h\to 0} \frac {a^h-1}{h}=1$?","['exponential-function', 'limits']"
1039023,Is the determinant of this matrix positive or negative?,"$\left( \begin{array}{ccc}
1 & 1000 & 2 & 3 &4\\
5 & 6 &7&1000 &8\\
1000&9&8&7&6\\
5 & 4&3&2&1000\\
1&2&1000&3&4\\ \end{array} \right)$ When I compute the determinant online, I find that it is positive, but I'm supposed to ""see"" something about the matrix that allows me to know the determinant is positive. What properties does this specific matrix have that allow you to deduce the determinant will be positive?","['linear-algebra', 'determinant']"
1039037,"With $N$ a constant $>0$, show $\prod_{p<x}\frac{1}{p^{N+1}-1}>\frac{0.2}{\log^2 x}$.","Related . Show that if $x$ is large enough,$$\prod_{\substack{p<x \\ p \ \text{prime}}}\frac{1}{p^{N+1}-1}>\frac{0.2}{\log^2 x}.$$
Speaking of which, Theorem 6.12, and maybe others, of this paper might be useful.
If $N$ cannot be arbitrarily large for the inequality to hold, any conditions for truthfulness regarding its value are welcome.","['products', 'number-theory', 'real-analysis', 'prime-numbers', 'proof-writing']"
1039064,"$f \in L^1$, but $f \not\in L^p$ for all $p > 1$","""Find an $f \in [0,1]$ such that $f \in L^1$ but $f \not\in L^p$ for any $p > 1$."" I've thought about doing something like $$f(x) = \frac{1}{x}$$ where $|f|^p = \frac{1}{x^p}$ doesn't converge when $p > 1$.  But this function isn't itself in $L^1$.  Could someone please give me a hint for how to solve this problem?  I wish there were a situation where you had convergence on the closed half disc $[0,1]$ and divergence on $(1, \infty)$, rather than my current predicament where I have convergence on the open half-disc $[0, 1)$ and divergence on $[1, \infty)$.","['lebesgue-integral', 'lp-spaces', 'real-analysis']"
1039072,How to simpify $\cos x - \sin x$,"How does one simplify $$\cos x - \sin x$$ I tried multiplying by $\cos x + \sin x$, but that just gets me $$\cos x - \sin x = \frac{\cos 2x}{\cos x + \sin x}$$ which is worse. Yet wolframalpha gives me $\cos x - \sin x = \sqrt{2}\sin\left(\dfrac{\pi}{4}-x\right)$. How does one obtain this algebraically?",['trigonometry']
1039106,How prove this diophantine equation $x^2+y^2+z^3=n$ always have integer solution,"show that: For any postive ineteger $n$,then the equation 
  $$n=x^2+y^2+z^3$$
  always have integer solution My idea: such as $n=1$,then we have
$$1=0^2+0^2+1^3$$
$$2=0^2+1^2+1^3$$
$$3=1^2+1^2+1^3$$
$$4=2^2+0^2+0^3$$
$$5=1^2+2^2+0^3$$
$$6=1^2+2^2+1^3$$
$$7=2^2+2^2+(-1)^3$$
$$8=0^2+0^2+2^3$$
$$9=1^2+0^2+2^3$$
$$10=1^2+1^2+2^3$$
$\cdots\cdots\cdots$ But for  general $n$, How prove it?",['number-theory']
1039108,Calculating Hydrodynamic Interaction Tensor,"I'm a bit of a newbie when it comes to Tensor calculus. Please excuse me as I learn... Given the Oseen tensor, $\mathbf{T}(\mathbf{R}) = (8\pi \eta R)^{-1} \left[ \mathbf{I} + (\mathbf{R}\mathbf{R}/R^2) \right]$ (1) the velocity perturbation $\mathbf{v}(\mathbf{R})$ caused by a point force $\mathbf{F}$ can be determined, or if you like, $\mathbf{v}(\mathbf{R}) = \mathbf{T}(\mathbf{R}) \cdot \mathbf{F}$ (2) If the single point force $\mathbf{F}$ is distributed uniformly over a spherical surface of radius $a$ , then the corrected (via Taylor series expansion) hydrodynamic interaction tensor is $\mathbf{P}(\mathbf{R}) = \mathbf{T}(\mathbf{R}) + \frac{1}{6} a^2 \nabla^2 \mathbf{T}(\mathbf{R})$ (3) where we have neglected higher order terms. Substituting (1) into (3), we obtain $\mathbf{P}(\mathbf{R}) =  (8\pi \eta R)^{-1} \left\lbrace \left[ \mathbf{I} + (\mathbf{R}\mathbf{R}/R^2) \right] + (a^2/R^2) \left[ \frac{1}{3} \mathbf{I} - (\mathbf{R}\mathbf{R}/R^2) \right] \right\rbrace $ (4) Now, here are my silly questions... How $\frac{1}{6} a^2 \nabla^2 \mathbf{T}(\mathbf{R})$ becomes $(a^2/R^2) \left[ \frac{1}{3} \mathbf{I} - (\mathbf{R}\mathbf{R}/R^2) \right]$ ? I feel stupid for asking this one. Seems like it should be easy enough but I'm going around in circles at the moment. If I wanted to calculate $\left(1 + \frac{1}{6} a^2 \nabla^2  \right)^2\mathbf{T}(\mathbf{R})$ , how would I go about calculating? Do I need to numerically find $\nabla^4$ ? Essentially I'm trying to construct the Rotne-Prager tensor ( $M_{\alpha \beta}^{RP}$ )in this paper: http://authors.library.caltech.edu/3142/1/ICHpof01.pdf Any pointers appreciated... EDIT (03/12/2014): I've managed to calculate the hydrodynamic interaction forces. I've just approached it numerically which answers question 2. Brief steps of what I've done is below for anyone interested (more for my own reference he he) I have assumed a polystyrene bead of radius $a=1 \mu \mathrm{m}$ is suspended in water ( $\eta = 1.002 \times 10^{-3}$ ) and subjected to a force $\mathbf{F} = 1 \times 10^{-9}N \mathbf{\hat{x}}$ . Eq. (2) is then calculated using Eq. (4) and shown in Fig. 1. (source: torrkish.com ) Figure 1. I've compared this with Comsol Multiphysics and it seems right. Now consider the system with two particles $\alpha$ and $\beta$ . Faxen's law states that the force experienced by $\alpha$ due to the velocity perturbation caused by $\beta$ is $\mathbf{F}_{\alpha} = 6 \pi \eta a \left[ \left(1 + \frac{a^2}{6}\nabla^2 \right) \mathbf{v}(\mathbf{R}_{\alpha}) - \mathbf{U}_{\alpha} \right]$ (5) where $\mathbf{U}_{\alpha}$ is the translational velocity of particle $\alpha$ , and $\mathbf{v}(\mathbf{R}_{\alpha})$ is the velocity field in which particle $\alpha$ is immersed. Written more explicitly, this is $\mathbf{F}_{\alpha} = 6 \pi \eta a \mathbf{v}(\mathbf{R}_{\alpha}) + \pi \eta a^3 \nabla^2 \mathbf{v}(\mathbf{R}_{\alpha})$ (6) The omitted term $6 \pi \eta a \mathbf{U}_{\alpha}$ is the force required to move $\alpha$ with velocity $\mathbf{U}_{\alpha}$ . In my case this is an external optical force derived from Maxwell's tensor. The first term in Eq. (6) is a simple scaling of the velocity field in Figure (1b). The second term can be calculated numerically (discretize, etc, etc), and its contribution is shown in Fig. (2). (source: torrkish.com ) Figure 2. Calculating Eq. (6) for all $\mathbf{R}_{\alpha}$ the individual components of $\mathbf{F}$ are shown in Fig. 3 and 4. (source: torrkish.com ) Figure 3. $\mathbf{F} \cdot \mathbf{\hat{x}}$ (source: torrkish.com ) Figure 4 $\mathbf{F} \cdot \mathbf{\hat{y}}$ Obviously, we have violated some overlap rules here. Two particles need to be at least $2a$ distance from each other. Naturally, there was a strong singularity when $r < a$ which is why I have omitted that region. Next we must apply the Method of Reflections which is an iterative process which in summary is: $\mathbf{F}_{\beta}^{(i)} = 6 \pi \eta a \left[ \left(1 + \frac{a^2}{6}\nabla^2 \right) \mathbf{v}_{\alpha}^{(i-1)} \right]$ If we assume $\alpha$ is always positioned at the origin and apply an external force $\mathbf{F} = 1 \times 10^{-9}N \mathbf{\hat{x}}$ , and $\beta$ is placed in various positions, the hydrodynamic interaction forces on $\alpha$ and $\beta$ are shown in Fig. (5). Generally, convergence criteria was met within less than 20 iterations. (source: torrkish.com ) Figure 5. Hydrodynamic force components in the (a) x-direction $\mathrm{log}_{10}(F_x)$ and in the (b) $\mathrm{log}_{10}(F_y)$ y-direction for a particle $\alpha$ centered at the origin as a function of the $(x,y)$ position of particle $\beta$ . That'll do for now. EDIT 9th December 2014 (source: torrkish.com ) Squeeze flow between two 1micron spheres","['multivariable-calculus', 'tensors', 'physics']"
1039111,Number of sets of vertices whose union of neighbours contains exactly $k$ vertices,"Suppose a bipartite graph $g$ consisting of $2n(n-1),n\in\Bbb N,n>1$ vertices, is divided equally into two colors: red and blue, and is constructed as follows: For example, $g$ for $n=3$: If I choose a set of vertices exclusively from one color, I could find the set of vertices from the other color that is a neighbour to at least one vertex in my set. For example, if I choose the following solid red vertices from the graph $n=3$, the set of unique neighbours to these vertices are highlighted in solid blue: In this case, there are five unique blue neighbours. How could I go about finding the number of unique sets of red vertices such that the number of unique blue neighbours is exactly $k,2≤k≤n(n-1)$? I know that finding the number of unique blue neighbours depends on the location of each red vertex (corner, edge or interior) and the location of each vertex with respect to the others (directly horizontally- and vertically- adjacent vertices will share two blue neighbours, while diagonally-adjacent vertices will share one), but I'm having a hard time conceptualizing a general approach much more sophisticated than brute force.","['graph-theory', 'coloring', 'combinatorics']"
1039134,What is the approximation of trigonometric function by simple function,"for $f(x)=\sin x$, $g(x)=\cos x$, $h(x)=\tan x$, What is the approximation of each function by using simple function?","['trigonometry', 'approximation', 'approximate-integration', 'trigonometric-series']"
1039155,Derivation of the integral,"Evaluate
  $$\large\frac{d}{dx}\int_{0}^{\large\int_0^{e^x}{\cos (s)\,\mathrm  ds}}\sec(t^2)\,\mathrm dt$$ I got the answer to be $$e^x\cdot\sec(\sin^2(e^x))\cdot \cos(e^x)$$ but do not know if this is correct and if not some suggestions?","['calculus', 'integration', 'derivatives']"
1039182,Number of real solutions of the equation $1+8^x+27^x = 2^x+12^x+9^x$,"Find the number of real solutions $x\in\mathbb{R}$ of the equation
  $$
1+8^x+27^x = 2^x+12^x+9^x
$$ My Attempt: Let $2^x=a>0$ and $3^x=b>0$ where $x\in \mathbb{R}$. This allows us to change the equation to $$
1+a^3+b^3 = a+a^2b+b^2
$$ This can be rewritten as $$
(a+b)^3-3ab(a+b)+1 = a+ab(a+b)
$$ How can I solve the problem from this point?","['exponential-function', 'algebra-precalculus']"
1039193,Intuition behind Strassen's theorem,"Currently I am dissecting a proof of Strassen's theorem, which states the following: Suppose that $(X,d)$ is a separable metric space and that $\alpha,\beta>0$.
  If $\mathbb{P}$ and $\mathbb{Q}$ are probability measures on $X$ satisfying
  $$
\mathbb{P}(E) \le \mathbb{Q}(E^\alpha) + \beta
$$
  for any Borel-measurable set $E \subset X$, then for any $\varepsilon>0$ there
  exist two nonnegative measures $\mu,\nu$ on $X\times X$ such that $\mu + \nu$ is a law on $X\times X$ with marginals $\mathbb{P}$ and $\mathbb{Q}$. $\mu \{(x,y)\in X\times X: d(x,y) > \alpha + \varepsilon \} = 0$ $\nu(X\times X) \le \beta + \varepsilon$ Here $X$ is endowed with the Borel $\sigma$-algebra arising from the metric topology, and $E^\alpha = \{x \in X : d(x,y) < \alpha \text{ for some } y \in E\}$ is the $\varepsilon$-enlargement of $E$. Right now I'm mainly concerned about the intuition behind this theorem and how it relates to things I've recently learned (say, the Prokhorov and Ky-Fan metrics and various metrizations of convergences we care about when dealing with random variables.) My understanding of it so far is that, if we have a generalized notion of the Prokhorov distance constraining $\mathbb{P}$ in terms of $\mathbb{Q}$, then we can always find a probability measure on the product space that in some sense ""couples"" $\mathbb{P}$ and $\mathbb{Q}$ and does so in a way that concentrates mass close to the diagonal. Admittedly though, this is a stretch of the imagination -- would more experienced probabilists please elucidate this result? I'd also love to know specific places where one might find occasion to use this.","['probability-theory', 'measure-theory']"
1039207,"Find sequence of differentiable functions $f_n$ on $\mathbb{R}$ that converge uniformly, but $f'_n$ converges only pointwise","Question: Find a sequence of differentiable functions $f_n$ on $\mathbb{R}$ that converge uniformly to a differentiable function $f$, such that $f'_n$ converges pointwise but not uniformly to $f'$. Attempt: I have tried a number of possibilities, such as $f_n=x^n$ or $f_n=\frac{x^n}{n}$ but I don't know what the right approach is to construct the function. I am initially thinking that it's easiest to construct such a sequence of functions on the interval $[0,1]$ so that in the limit of $n$, part of the function goes to $0$ and the other part goes to $1$. However, this would make the resulting $f$ non-differentiable.",['real-analysis']
1039210,Joint probability distribution,"$Y_1$ and $Y_2$ are jointly distributed with density $f(y_1,y_2)=4y_2^2 \qquad 0 \leq y_1 \leq y_2 \leq 1$ Determine the following: $P(\text{max} \{Y_1,Y_2\} <1/2) = \int_{y_2=0}^{1/2}\int_{y_1=0}^{y_2}4y_2^2dy_1dy_2  \approx 0.0625$ 
$P(Y_1+Y_2 < 1/2) = \int_{y_1=0}^{1/4}\int^{1/2-y_1}_{y_2=y_1}4y_2^2dy_2dy_1 \approx 0.0182292$ 
$P(Y_1Y_2 <1/2) = \int_{y_2=0}^{\sqrt{1/2}}\int_{y_1=0}^{y_2}4y_2^2dy_1dy_2 + \int_{y_2=\sqrt{1/2}}^{1}\int_{y_1=0}^{1/(2y_2)}4y_2^2dy_1dy_2 = 1/4 + 1/2 = 0.75$ 
$P(Y_1/Y_2<1/2) = \int_{y_2=0}^{1}\int_{y_1=(1/2)y_2}^{y_2}4y_2^2dy_1dy_2 = 0.5$ 
$P(Y_2-Y_1 < 1/2) = \int_{y_2=0}^{1/2}\int_{y_1=0}^{y_2}4y^2_2dy_1dy_2 + \int_{y_2=1/2}^{1}\int_{y_1=y_2-(1/2)}^{y_2}4y^2_2dy_1dy_2 \approx 0.583333+0.0625 = 0.645833$ 
$P(\text{min} \{Y_1,Y_2\}<1/2) = \int_{y_2=1/2}^{1}\int_{dy_1=0}^{y_2}4y^2_2dy_1dy_2 \approx 0.9375 $","['statistics', 'probability-distributions']"
1039332,Combinatorial identity with sum of binomial coefficients,"How to attack this kinds of problem? I am hoping that there will some kind of shortcuts to calculate this. $$\sum_{k=0}^{38\,204\,629\,939\,869} \frac{\binom{38\,204\,629\,939\,869}{k}}{\binom{76\,409\,259\,879\,737}{k}}\,.$$ EDIT: As I see, the numerator is $n \choose k$ and the denominator is ${2n-1} \choose k$, where $n =38\,204\,629\,939\,869$. i.e $$\sum_{k=0}^n {\frac {n \choose k} {{2n-1} \choose k}} = 2.$$",['combinatorics']
1039428,Finite difference method,"I wanted to ask something regarding the finite difference approximation. I used the finite difference to calculate the numerical derivatives of my function. The finite difference is given by the following formula: \begin{equation}
\frac{f(x+h)-f(x)}{h}
\end{equation} The value of $h$ is questionable. In theory we should take it as small as possible, but I am not sure if we can just pick random different values for $h$ and try to see which one works better or if there is any ""rule"" or constraint to pick up a good value of $h$. With Thanks","['optimization', 'derivatives', 'numerical-methods']"
1039482,How to evenly space a number of points in a rectangle?,"Say I have a rectangle, with variable width and height, for example lets use: width = 20
height = 30 I would like to put n amount of evenly spaced points inside this rectangle: no of points = 400 How could I calculate the x and y coordinates of each point? Note, that I would like the borders to also have points. Very rough example, I needed 12 points (but I could have wanted more or less):","['geometry', 'rectangles', 'coordinate-systems']"
1039487,Quadratics with roots as integers; possible values of a,"Suppose $a$, $b$ are real numbers such that $a+b=12$ and both roots of the equation $x^2+ax+b=0$ are integers. Determine all possible values of $a$. I don't know how to go about doing this without long, messy casework.  I tries $(x-s)(x-r)=x^2+ax+b$ and got $-r-s=a$ and $rs=b$, but was unable to find all solutionss based on only these and $a+b=12$.  Could someone help me finish up?  Thanks.","['elementary-number-theory', 'algebra-precalculus']"
1039488,What does 'express in terms of $x$' mean?,For the following question : $f(x) = 2x^2 + 4x $ It asks me to express the following in terms of $x$: $f(-2x)$ What does the question mean by this? Does it mean make $x$ the subject?,"['quadratics', 'functions']"
1039528,Least number of weights required to weigh integer weights,"In a number theory book, I found the following problems, ""What is the least number of weights required to weigh any integral number of pounds up to 63 pounds if one is allowed to put weights in only one pan of a balance?"" and ""Determine the least number of weights required to weigh any integral number of pounds up to 80 pounds if one is allowed to put weights in BOTH pans of a balance"". Now, I realize these are very simple questions, I know the answers, and I know that I can find similar questions here. 
BUT THIS QUESTION IS NOT A DUPLICATE. I know, its easily solved by using bases 2 and 3 to write the maximum weight to be measured. What I don't understand is why? 
I must be overlooking a simple fact. 
Could someone explain me the reasoning primarily?",['number-theory']
1039530,New proof about normal matrix is diagonalizable.,I try to prove normal matrix is diagonalizable. I found that $A^*A$ is hermitian matrix. I know that hermitian matrix is diagonalizable. I can not go more. I want to prove statement use only this fact. I need you help. (professor said that we can prove only use this fact.,"['matrix-decomposition', 'eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'diagonalization']"
1039535,Exercise from Norris' book on Markov chains,"Let $(X_n)$ be a Markov chain on $\mathbb{N}$ with transition probabilities satisfying: $$p_{0,1}=1,\quad p_{i,i-1}+p_{i,i+1}=1,\quad p_{i,i+1}=\left(\frac{i+1}{i}\right)^{\alpha}p_{i,i-1}$$ The exercise asks to find $\mathbb{P}(X_n\to \infty\;\text{as}\;n\to\infty)$ The problem is that I am having real trouble getting started off, because I cannot express the event $X_n\to\infty$ in a more suitable form. Any help on this would be greatly appreciated. My first thought was: $$\mathbb{P}(X_n\to\infty)=\prod_k\mathbb{P}(X_n\geq k\;\text{eventually})=\prod_k \mathbb{P}(X_n \neq 0,\cdots X_n\neq k-1\;\text{eventually})$$ But I am having trouble with translating ""eventually"".","['markov-chains', 'probability-limit-theorems', 'probability']"
1039552,Factorising quadratics - coefficient of $x^2$ is greater than $1$,"In factoring quadratics where the coefficient of $x^2$ is greater than $1$, I use the grouping method where we multiply the coefficient and constant together and then factor. My question is can someone explain the math behind that? Example: $5x^2+11x+2,\quad  5\cdot2=10$ $5x^2+10x+x+2$ $5x(x+2)+1(x+2)$ $(5x+1)(x+2)$",['algebra-precalculus']
