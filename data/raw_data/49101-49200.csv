question_id,title,body,tags
499038,"Text with alternative definition of ""derivative""?","Instantaneous rates of change are conventionally defined as limits of difference quotients. Rates of things moving at constant speed are definable without delicate issues.  If I pass someone moving at constant speed at a particular point in time, it doesn't mean I'm going faster at that instant than he is; it might only mean that for a short time before and after that instant I'm going faster than he is.  But it does mean that that instant I'm not going more slowly than he is.  A similar criterion tells me I'm not going faster than some other, slower things moving at constant speed.  The boundary between those whose speed I do not exceed and those whose speed does not exceed mine is my speed at that instant. More abstractly, if a line crosses a curve going from below it to above it as the independent variable increases, then at that point the curve is not steeper than the line; and similarly one can say that at that point the curve is not less steep than certain other lines.  The unique point on the boundary between those two sets of slopes is the slope of the curve at a point. I recall that somebody mentioned this characterization of slope of a curve at a point on stackexchange within the past year. Has a textbook been written that defines derivatives that way and gives proofs of the usual rule based on that definition?  If not, do those proofs appear in the literature or on the web or otherwise in public?","['calculus', 'reference-request', 'derivatives']"
499039,How many compatible group structures does a topological space admit?,"Suppose I have a topological space $(G,\tau)$ and am interested in whether there exists a topological group $(G,*,\tau)$. In other words, can we assign a binary operation $*$ to $(G,\tau)$ which satisfies the group axioms, and under which the functions $x \mapsto x^{-1}$ and $(x,y) \mapsto x*y$ are continuous? If so, how many non equivalent ways can we do this? And what would a sensible form of equivalence be? For example we can give $\mathbb R$ the standard additive group structure, but we could equally inter it ""backwards"" in the group and define $x*y = \begin{cases} x \cdot y & \mbox{if } x,y \le 0\\ -(x \cdot y) & \mbox{if } x \le 0 \mbox{ and } y \ge 0 \\ -(x \cdot y) & \mbox{if } x \ge 0 \mbox{ and } y \le 0\\ x \cdot y, & \mbox{if } x, y \ge 0 \end{cases}$ Here negation is used in the context of $\mathbb R$. It does not represent the inverse with respect to $*$. Clearly $\tau$ has to satisfy a lot of conditions for this to even stand a chance at being possible. In a topological group the map $x \mapsto a*x$ is a homeomorphism for each $a \in G$ and a result of this is the topology ""looks the same"" at any given point. If this is not true then there definitely is no $(G,*,\tau)$. But I'm sure this condition isn't enough, so are there any properties of the topology that can be reasonable computed which necessitate a compatible structure to exist? There is a similar question, which I know has a lot of theory behind it: Can we determine whether a topological group $(G,*,\tau)$ admits a Lie group structure by only looking at $(G,*,\tau)$? There is yet another question I found on StackExchange which is asking the opposite of me: How many agreable topologies can we assign an abstract group which make the group operations continuous? I would guess that problem is easier than mine. But I am not interested in either of these at the moment.","['general-topology', 'topological-groups', 'group-theory', 'abstract-algebra']"
499041,Probability density of Continuous uniform distribution over the unit circle,"If we want to chose a point $(x,y)$ uniformly at random from a unit circle in a plane, why is the joint probability density of the random variable $f(x,y) = \frac{1}{\pi}$ for $x^2+y^2\leq1$? The question linked simply states this but doesn't prove it. Can someone give an explanation please? Continuous uniform distribution over a circle with radius R","['probability-theory', 'uniform-distribution', 'probability', 'random']"
499042,How to convert between the hyperboloid model and the Poincare patch for $\mathbb{H}_n$?,"This question is motivated by the results in this paper, http://calvino.polito.it/~camporesi/JMP94.pdf In this paper some of its most important results about the asymptotics of symmetric traceless transverse harmonic rank-s tensors on $\mathbb{H}_n = EAdS_n$ in equations 2.27, 2.28, 2.88, 2.89 are all given in hyperbolic coordinates. But for reasons of physics one wants to write $\mathbb{H}_n$ in the Poincare patch! How does one convert between the two? 
Is there a known transformation? In the hyperbolic model of $\mathbb{H}_n$ the space is thought of a zero-set in $\mathbb{R}^{n+1}$ of the equation, $x_0^2 - \sum_{i=1}^n x_i ^2 = a^2$ and then one uses the coordinates $y \in [0,\infty)$ and and $\vec{n} \in S^{n-1}$ to write, $x_0 = a cosh y$ and $\vec{x} = a \vec{n} sinh y$ and then the metric is, $ds^2 = a^2 [ dy^2 + sinh ^ 2 yd\Omega_{n-1}^2]$ Here $d\Omega_{n-1}^2$ is the standard metric on $S^{n-1}$. (..and this is the metric in equation 2.15 in the linked paper..) In the Poincare patch model of $\mathbb{H}_n$ it is thought of as the half-space $x_n > 0$ in $\mathbb{R}^n$ with the metric,  $ds^2 = \frac{a^2}{z^2}(dz^2 + \sum_{i=1}^{n-1}dx_i^2 )$ I would like to know the transformation and the relation between these two models. I believe that there is some function connecting the $y$ and the $z$ and then I can substitute that into 2.28 and 2.89 of the paper to see the asymptotics in the Poincare patch. I am hoping the relationship is such that it relates large $y$ to small $z$...","['hyperbolic-functions', 'differential-geometry', 'hyperbolic-geometry', 'riemannian-geometry', 'spectral-theory']"
499058,Gradient of a scalar function with respect to a matrix,"I need to calculate $\dfrac{\partial}{\partial K}f(K)$, with:
$$
f(K)=-\frac{1}{2}(u-Kx)^T\Sigma^{-1}(u-Kx)$$
$K$ and $\Sigma$ are $n\times n$ matrices, $\Sigma$ is symmetric, $u$ and $x$ are column vectors of size $n$. The result should be a matrix like:
$$
\begin{bmatrix}
\frac{\partial f(K)}{\partial k_{11}} & \frac{\partial f(K)}{\partial k_{12}} & \ldots
\\
\frac{\partial f(K)}{\partial k_{21}} & \ldots & \ldots
\\
\ldots & \ldots & \ldots
\end{bmatrix}
$$
Am I right? Following Petersen's Matrix Cookbook, I obtain the following matrix:
$$
\Sigma^{-1}(u-Kx)x^T
$$
My problem is that, choosing both $K$ and $\Sigma$ $2 \times 2$ diagonal, I get two different results: if I derive it step by step, that is finding the scalar $f(K)$ and then deriving wrt of all $k_{ij}$ I obtain this matrix:
$$
\begin{pmatrix}
\frac{(u_1-k_1x_1)x_1}{\sigma_1^2} & 0
\\
0 & \frac{(u_2-k_2x_2)x_2}{\sigma_2^2}
\end{pmatrix}
$$ following Petersen's formula:
$$
\begin{pmatrix}
\frac{(u_1-k_1x_1)x_1}{\sigma_1^2} & \frac{(u_1-k_1x_1)x_2}{\sigma_1^2}
\\
\frac{(u_2-k_2x_2)x_1}{\sigma_2^2} & \frac{(u_2-k_2x_2)x_2}{\sigma_2^2}
\end{pmatrix}
$$
What am I doing wrong?","['matrices', 'partial-derivative', 'calculus', 'derivatives']"
499072,Beta distribution questions,"Just a simple beta distribution question just to be sure that I understand it. Say we do experiments, and we expect a proportion  $\theta$ of people having a specific property (which means $\theta \in [0,1]$) Assume we have a prior beta ""belief"" that $\theta = 0.3$ and we are very certain. The question now is, what should $a$ and $b$ be, if we define $$f(\theta, a, b) = \frac{\theta ^{a-1}(1-\theta)^{b-1}}{B(a,b)}$$ I would say, using the fact that the mean is $m =  \frac{a}{a+b}$, solving for $a$ and $b$ : 
$$ a=mn; b=(1-m)n$$ If I am very sure that $\theta$ is $0.3$, then $a= mn = 0.3 \cdot25 =7.5$ and $b$ would be $0.7\cdot 25 = 17.5$ Is this good reasoning? I took the number $n$ quite randomly, but the idea is I guess that if you are very sure, $n$ should be big whereas if you are not that sure, $n$ should be quite low.","['statistics', 'bayesian', 'probability']"
499087,Direct proof set theory.,"Okay, I am in a first year Discrete Math course in university and struggling to keep up, and need some additional help. We are learning about proving set relations and I just can't keep up with my professor's pace. I'll just get right to the problem I can't seem to understand. (I don't know how to show the proper notation but I think this explanation in words will be clear enough, it's pretty simple) ""Let A and B be sets. Prove that A union B equals A if and only if B is a subset of A."" The way my professor chose to solve this was by splitting the biconditional into its two implications, and proving them separately. This splitting up is straightforward; I understand that. The two implications are ""if A union B equals A, then B is a subset of A"", and ""if B is a subset of A, then A union B equals A"". Then my professor says that to prove each implication, we will assume that the antecedent (hope that's the right word) is true and then see if the consequent is true. She describes this as a direct proof. This is what I don't understand. I can't seem to reason out in my mind why this method works, or how to actually implement it. I'm sure it's simple, but my professor just talks too fast for me to follow what she's saying, and I can't seem to figure this out on my own. So if what little I understand is correct, then I should first assume that ""A union B equals A"" is true, and see if it follows that ""B is a subset of A"" is also true. But to put it simply, I haven't got a clue what to do from here. I understand this sounds like ""Please do my homework for me"" but really I'm asking ""Please teach me how to tackle problems like this so I can do it on my own in future.""","['logic', 'elementary-set-theory']"
499101,Example of a function that has the Luzin $n$-property and is not absolutely continuous.,"The Banach–Zaretsky theorem ( page 196 ) says that a continuous function $f:[a,b]\to\mathbb{R}$ of bounded variation is absolutely continuous if and only if $$E\subset I \text{ has zero Lebesgue measure }\Rightarrow f(E) \text{ has zero Lebesgue measure }\;\;[\#]$$ I would like see an example of a function that satisfies $[\#]$ but is not absolutely continuous. Thanks.","['examples-counterexamples', 'measure-theory', 'absolute-continuity', 'continuity', 'real-analysis']"
499125,Existence of a specific type of ultrafilter,"Does there exist an ultrafilter $\omega$ on $N$ with the following property: $\forall A \in \omega$ we have that $kA \in \omega$ for a fixed $k \in N$. Where $kA = \{ka : a \in A\}$. I do not believe there is such an ultrafilter, but could not immediately see why one does not exist. An answer that shows there is one would be highly welcomed. Thanks for the any help.","['general-topology', 'filters', 'set-theory']"
499127,"1965 Putnam, B2","The problem statement: Suppose $n$ players engage in a tournament in which each player plays every other player in exactly one game, to a win or a loss. Let $w_i$ and $l_i$ denote the wins and losses of the $i$ th competitor, $i = 1, 2, ... n$ . Prove that $\sum {w_i}^2 = \sum {l_i}^2$ . A rather un-illuminating proof of this is the following (WLOG we treat $n= 4$ ): Each player has exactly $4-1 = 3$ wins and losses total, so $w_i + l_i = 3$ , and there will be an equal number of wins and losses total as well (in fact, $4 \choose 2$ ). Thus $${w_1}^2 - {l_1}^2 + {w_2}^2 - {l_2}^2 + {w_3}^2 - {l_3}^2 + {w_4}^2 - {l_4}^2 = 0$$ $$ \iff 3 (w_1 - l_1 + w_2 - l_2 + w_3 - l_3 + w_4 - l_4) = 0$$ which is true. I wanted to ask: is there a combinatorial proof of this which explains it better? Something with pigeonholing? (This might be pointless, but I still don't ""get"" this problem. Perhaps there's nothing else to ""get"".)","['contest-math', 'combinatorics']"
499138,Minimal polynomial of restriction to invariant subspace divides minimal polynomial,I'm trying to prove this: $T : V \to V$ linear transformation. $W$ subspace of $V$. If $W$ is $T$-invariant then the minimal polynomial for the restriction operator $T|_W$ divides the minimal polynomial for $T$.,"['linear-transformations', 'linear-algebra', 'minimal-polynomials']"
499147,Integrate $\frac{5x^3 +2}{\sqrt{x^3+1}}$,"$$\int\frac{5x^3+2}{\sqrt{x^3+1}}\,\mathrm{d}x$$ Sad to say this has really stumped me and nothing I have tried has worked. I used Wolfram Alpha to find that the answer is simply $2x\sqrt{x^3+1}$ but it says the method is unavailable and I have no idea which method to use. Hints would be appreciated.",['integration']
499172,How prove this limit,"If $\phi $ is an irrational number the following limit holds $$\lim_{n \to \infty } \left( \left( \sum_{k = 0}^{[n\phi ]} \frac{1}{[ k\phi^{-1}] + 2}  \right) - \left( \sum_{k = 0}^n \frac{[k\phi ]}{( k + 1)( k + 2)} \right) \right) = \frac{1}{2} + \phi \tag 1$$ Here $[x]$ is the gauss floor  function. How can we prove $(1)$? Thank you. (It is amazing since it doesn't  remain  true if $ \phi $  is a rational number.
 As we know, the Polygamma functions  define a class of  limits of harmonic sums. The following limit can be regard as a  kind of a generalization) $$\lim_{n \to \infty } \left( \sum\limits_{k = 0}^{[n\phi ]} \frac{1}{\left[ k\phi^{-1} \right] + x} - \phi \ln n \right)$$","['summation', 'sequences-and-series', 'limits']"
499181,$GL(-)$ as a k-group functor,"My question is essentially may lye simply in a notational obstruction. For a k-algebra M, Jantzen J. defines the k-group functor $GL(M)$ as:
$GL(M)(A):=(End_A(M\otimes_{\mathbb{k}} A)^*$.  My question is what does the subscripted A mean? I would understand $GL(M)(A)$ to be defined as $(End_{\mathbb{k}-Mod}(M\otimes_{\mathbb{k}} A)^*$.","['algebraic-geometry', 'group-schemes', 'abstract-algebra', 'category-theory', 'algebraic-groups']"
499187,Existence of a Minimal Cover,"I'm well aware that for the sequence $x_n=\frac{1}{n}$, $\text{inf }x_n=0$ but $0 \notin (x_n)$. This made me think about something similar but when we are no longer thinking about existence of a number in a sequence but something a bit different. Consider the definition of exterior measure for a set $E \subset\mathbb{R}^d$, $$m_*(E)=\text{inf }\sum_{j=1}^\infty |Q_j|$$ where the infimum is taken over all countable coverings $E\subset \bigcup_{j=1}^\infty Q_j$ by closed cubes. Does this necessarily imply there is a cover $\{Q_\alpha^*\}_\alpha$ such that $$\text{inf }\sum_{j=1}^\infty \left|Q_j\right|=\sum_{j=1}^\infty \left|Q_j^*\right|$$ I suspect this is not always the case. I'm wondering about the following: $1.$ Can one find examples of a set $E\subset \mathbb{R}^d$ (nonfinite) such there is such a ""minimal"" cover $\{Q_\alpha^*\}$? $2$. What conditions - if any - on $E$ force there to always be such a ""minimal"" cover? $3$. What about when one removes the restriction of $E \subset \mathbb{R}^d$? Are there cases where one clearly can/can't find such ""minimal"" covers for general metric spaces?","['general-topology', 'covering-spaces', 'measure-theory', 'real-analysis']"
499218,Recommended books on knot invariants,"I've been reading the books ""An introduction to knot theory"" by Lickorish and ""Knots, Links, Braids and 3-Manifolds"" by Prosolov and Sossinsky, and while both seem to me as good books, sometimes I'd like to get a different perspective on certain topics. I would be glad to get some recommendations on books dealing with knot invariants, in particular the Arf invariant and the Alexander polynomial (I've noticed there are several approaches to define the former). Thanks in advance!","['knot-invariants', 'low-dimensional-topology', 'general-topology', 'knot-theory', 'reference-request']"
499254,How find the $\angle B$,"In $\Delta ABC$ such $I$ is incentre,and $$\angle A=80^{0},AI+IB=BC$$,
find the $\angle B$ my idea:let $AB=c,AC=b,BC=a$ then we have
$$\dfrac{AI}{ID}=\dfrac{AB}{AD}=\dfrac{AC}{DC}=\dfrac{AB+AC}{AD+DC}=\dfrac{b+c}{a}$$
and
$$AD^2=AB\cdot AC-BD\cdot DC=bc-BD\cdot DC$$
$$BD=\dfrac{ac}{b+c},DC=\dfrac{ab}{b+c}$$
$$\Longrightarrow AD=\sqrt{bc-\dfrac{a^2bc}{(b+c)^2}}$$
so
$$AI=\dfrac{b+c}{a+b+c}AD$$
and 
$$BI=\dfrac{a+c}{a+b+c}BE$$
so
$$AI+BI=BC\Longleftrightarrow \dfrac{b+c}{a+b+c}AD+\dfrac{a+c}{a+b+c}BE=a$$
 then I have ugly,and can't work,Thank you someone can have other methods.",['geometry']
499264,Projective space is not affine,"I read a prove that the projective space $\mathbb P_{R}^{n}$ is not affine (n>0): (Remark 3.14 p72 Algebraic Geometry I by Wedhorn,Gortz). It said that the canonical ring homomorphism $R$ to $\Gamma(\mathbb P_{R}^{n}, \mathcal{O}_{\mathbb P_{R}^{n}})$ is an isomorphism. This implies that for n>0 the scheme $\mathbb P_{R}^{n}$ is not affine, since otherwise $\mathbb P_{R}^{n}=Spec R$. I am not clear about why is it impossible to have $\mathbb P_{R}^{n}=Spec R$?
And is what sense does the $=$ mean here?",['algebraic-geometry']
499273,subgroup definition,"$H \subseteq \text{group  } G $, $H$ is not empty. If for any $a,b \in H$, we have $a^{-1}b^{-1} \in H$ , is it possible to deduce that $H$ is a subgroup of $G$ ? I feel like this is not necessarily true because the identity can't be proven to be in $H$, but I can't find an counterexample.","['group-theory', 'abstract-algebra']"
499299,The use of individuals in set theory,"I wonder if there is some advantage in using individuals when defining set theory and if this has something to do with the use of classes. This is essentially because I have seen that some books start by defining the empty set whereas others consider it to be a primitive symbol. In the first case there are only sets in the domain of discourse, but in the second there are also what they call individuals. What is the purpose of using individuals compared to the other alternative? Also, the way I understand individuals is that they are entities at the begining of the hierarchy, at the same level of the empty set, but maybe I'm misundersanting this. Could you guys please help me claryfy this...","['logic', 'elementary-set-theory']"
499310,"Law of Cosines for very acute angles, round-off error","We have
$$
c^2 = a^2 + b^2 - 2ab\cos(\gamma)
$$ If $a \approx b$ and $\gamma$ is very small, then the above formulation has quite a bit of round-off error. Is there a better formulation that would help to reduce some of the error?","['trigonometry', 'numerical-methods']"
499321,Why is the determinant zero iff the column vectors are linearly dependent?,"The determinant of a square matrix is zero if and only if the column vectors are linearly dependent. I see a lot of references to this all over the web, but I can't find an actual explanation for this anywhere.","['matrices', 'linear-algebra', 'determinant']"
499326,Prove a lower semi-continuous and coercive function attains its infimum and is bounded below.,"A function $f:\mathbb{R}\rightarrow\mathbb{R}$ is $coercive$ if $$ \lim_{||x||\rightarrow\infty} f(x) = \infty.$$ Explicity, this condition means that for any $M>0$ there is an $R>0$ such that $||x||>R$ implies $f(x)\geq M$. Prove that if $f:\mathbb{R}^n\rightarrow \mathbb{R}$ is lower semi-continuous and coercive then $f$ is bounded from below and attains its infimum. The definition I am using for LSC is: A function $f$ is lower semi-continuous on $X$ if for all $x\in X$ and every sequence $x_n\rightarrow x$, we have $$\lim_{n\rightarrow\infty} \inf f(x_n) \geq f(x). $$ This is my solution: Let $M>0$. Then since $f$ is $coercive$ there is an $R>0$ such that $||x||>R$ implies that $f(x)\geq M$. Let $x_n$ be a sequence such that $x_n\rightarrow x$. Since $f$ is LSC we have that $$ f(x)\leq \lim_{n\rightarrow\infty} \inf f(x_n)$$ which implies $$ M\leq f(x) \leq \lim_{n\rightarrow\infty}\inf f(x_n). $$ Hence $f$ is bounded below and attains its infimum.","['continuity', 'analysis']"
499337,The set of all continuous functions on a locally compact Hausdorff space.,I am reading a book about C*-algebra. There is a example that i could not understand. Let $X$ be a locally compact Hausdorff space and $C_{0}(X)$ be the set of all continuous functions vanishing at infinity. Define $f^{*}(t)=\overline{f(t)}$ (for $t\in X$). It is known that $C_{0}(X)$ is a *-algebra. And then $C_{0}(X)$ is unital if only if X is compact. I do not know how to explain this proposition.,"['general-topology', 'operator-algebras', 'functional-analysis', 'c-star-algebras']"
499347,Lie bracket is a connection?,"In Road to Reality , section 14.6 on Lie derivative Penrose writes: Now $\epsilon^2 [j,h]$ corresponds to an
  $O(\epsilon^2)$ gap in the ‘parallelogram’ whose initial sides are $e_j$ and $e_h$ at
  the origin I. The relevant notion of ‘parallelism’ comes from the group
  action, supplying the needed notion of ‘parallel transport’, which actually gives a connection with torsion but no curvature.[14.17] and poses the the exercise: [14.17] Try to explain why there is torsion but no curvature. I find it surprising that one could get a connection just from the Lie bracket,
since connections depend on additional structure like the metric tensor,
while Lie brackets do not. One forum has a proposed answer giving the Lie bracket itself as the connection $\nabla_{L}M = [L, M]$
if I understood it correctly.
The proof proposed there convincingly shows that there would be torsion & no curvature,
but the proposed answer does not seem to be a connection in the first place
since multiplying the the vector fields $L$ and $M$ by a scalar field $\phi$  does not satisfy a condition required given earlier in the book: linearity in $L$ : $\nabla_{\phi L}M = \phi\nabla_{L}M$ Treating veactors as directional derivative operators on scalar field shows how
linearity in $L$ fails $$\begin{align} [\phi L, M](\psi) &= \phi L(M(\psi)) - M(\phi L(\psi)) \\
   &=  \phi L(M(\psi)) - (M(\phi)L(\psi) + \phi M(L(\psi))) \\
   &= \phi[L, M](\psi) -  M(\phi)L(\psi)
\end{align}$$ because of the additional $M(\phi)L(\psi)$ term. Also if it is possible to define a connection just from the Lie bracket,
why is it usually said that you need additional structure to define parallel transport? Is it just that the all torsion no curvature property stops this connection from being useful, so people disregard it?
So what is Penrose getting at?
Am I missing something? EDIT From the answers it seems that the Lie bracket really is a connection, just not a linear or affine one. The book does not formally define what a connection is in general or specify the type of connection is intended when the term is used without qualification. It only gives the derivative style algebraic laws connections a connection must satisfy, including linearity wrt $L$ above. So the Lie bracket does seem to be not a connection in the sense the term used in the rest of the book. That is what I was trying to figure out I am still curious why it is so frequently claimed that connections, parallel transport and covariant derivatives (which I in my understanding are equivalent concepts) require extra structure on a manifold while Lie derivatives do not, if the Lie bracket is a connection and this connection is hardly ever mentioned. Also is there a name for the Lie derivative as a connection? Lie connection??","['riemannian-geometry', 'manifolds', 'self-learning', 'differential-geometry']"
499367,condition for a cubic polynomial to have a real root,"Let $a,b \in R$ and assume that $x=1$ is a root of the polynomial $p(x)= x^4+ax^3+bx^2+ax+1$. Find the ranges of values of $a$ for which $p$ has a complex root which is not real. Here first I factored out $x-1$ which left me with a cubic polynomial and then i thought of using the discriminant of a cubic polynomial, $\Delta= 18abcd -4b^3d + b^2c^2 - 4ac^3 - 27a^2d^2$ $< 0$ to get the condition on a. But I don't know how this discriminant is derived. And I want to know if there is another method where we don't need to use the discriminant.",['algebra-precalculus']
499395,How to best understand Euclid's definition of equal ratios? How does it relate to Dedekind cuts?,"This is something I've been wondering about. When I think of ""ratios"" $x/y$ and $z/w$ as being ""equal"", with $x$, $y$, $z$, and $w$ being real numbers, this means the results of dividing the real numbers $x$ by $y$ and $z$ by $w$ are equal. Or that $xw = yz$, from manipulation of the fractions. Intuitively, we may say this means the ""scale factor"" going from $y$ to $x$ is the same as that going from $w$ to $z$, or that $x$ has as many ""units"" of size $y$ (allowing for non-integral numbers of units) as $z$ has of size $w$. Yet, Euclid (~300 BCE) did not have real-number arithmetic to work with. Instead he had various kinds of ""magnitudes"", like line segments and shapes with areas and other things that had a kind of ""size"" to them. So he had to do something else, and this I don't get. If we have ""magnitudes"" $x$, $y$, $z$, and $w$, which for modern purposes could be taken as nonnegative real numbers, then we say $x/y = z/w$ iff for every pair of nonzero natural numbers $m$ and $n$, $mx < ny \rightarrow mz < nw$, $mx = ny \rightarrow mz = nw$, and $mx > ny \rightarrow mz > nw$. But how does one intuitively grasp this definition? How does it relate to our modern one? On Wikipedia, it says also ""There is a remarkable similarity between this definition and the theory of Dedekind cuts used in the modern definition of irrational numbers."" How exactly does this relate to Dedekind cuts? (this last bit is why I also file this under real analysis)","['fractions', 'arithmetic', 'real-analysis']"
499446,Is 'every exponential grows faster than every polynomial?' always true?,"My algorithm textbook has a theorem that says 'For every $r > 1$ and every $d > 0$, we have $n^d = O(r^n)$.' However, it does not provide proof. Of course I know exponential grows faster than polynomial in most cases, but is it true for all case? What if the polynomial function is something like $n^{100^{100}}$ and exponential is $2^n$? Will the latter outgrow the former at some point?","['asymptotics', 'algorithms', 'discrete-mathematics', 'functions']"
499480,How to solve the matrix equation $ABA^{-1}=C$ with $\operatorname{Tr}(A)=a$,"I have the following matrix equation:
$$ABA^{-1}=C$$
with $B$ and $C$ given and $A$ unknown.
The constraint on $A$ is $\operatorname{Tr}(A)=a$ with $a\in\mathbb{R}$.
The matrices are $N\times N$.","['matrix-equations', 'matrices']"
499503,How to show that $p-$Laplacian operator is monotone?,"Define 
$$\langle -\Delta_p u, v \rangle_{(W^{1,p})', W^{1,p}} = \int_{\Omega}|\nabla u |^{p-2}\nabla u \nabla v.$$ How do I show that this operator is monotone? I get
$$\langle-\Delta_p u_1 - \Delta_p u_2, u_1-u_2\rangle = \int(\nabla u_1 - \nabla u_2)(|\nabla u_1|^{p-2}\nabla u_1 - |\nabla u_2|^{p-2}\nabla u_2) $$
Now adding and subtracting $|\nabla u_1|^{p-2}\nabla u_2$ in the brackets still doesn't help with one of the terms.. (Recall an operator is monotone if $\langle Tx - Ty, x-y\rangle \geq 0.$)","['sobolev-spaces', 'monotone-operator-theory', 'functional-analysis']"
499529,$|f|$ constant implies $f$ constant?,If $f$ is an analytic function on a domain $D$ and $|f|=C$ is constant on $D$ why does this imply that $f$ is constant on $D$? Why is the codomain of $f$ not the circle of radius $\sqrt{C}$?,"['analyticity', 'complex-analysis']"
499544,Expressing the values of a matrix at pow N,"I have a square matrix (that comes from a Markov Chain) that looks like that: $$Q = \begin{bmatrix}
0 & 1& 0    & 0 & .. & 0 & 0\\
0 & a & 1-a & 0 & .. & 0 & 0\\
0 & 0 & b   & 1 - b & .. & 0 & 0\\
.. & .. & .. & .. & .. & .. & .. \\
0 & 0 & 0   & 0 & .. & 0 & 1
\end{bmatrix}$$ with $a, b, c,$ etc. real numbers between $0$ and $1$ included. I am interested in the values of the first line of the matrix $Q^N$. Currently, I am using a library (numpy) that allows me to compute $Q^N$ and then I read the first line of this matrix. But with large matrices ($> 500 \times 500$) and large values of $N$ (~ 10000), it is a bit too slow for my usage. By curiosity, I have plotted $Q^N_{0,j}$ for $N$ between 1 to 1000 and I found that they follow something that looks like a Poisson distribution or similar (but I don't know if it's only due to my specific input matrix $Q$ or not). My question is, given such a matrix Q, is there a way to get the values of $Q^N_{0,j}$ without having to compute $Q^N$? Edit: the terms on the diagonal are such as: 0 <= a <= b <= c <= ... < 1 Edit2: It appears that if I can diagonalize $Q$, I can use $Q^n = P D^n P^{-1}$ which is faster for large values of $n$ than an exponentiation by squaring (as used by numpy).
Problem is that I am not sure it is possible for any matrix $Q$. And if it's not possible, I'd accept a slight modification of $Q$, $P$ or $D$ if the result is close enough. Edit3: The values of the first line of $Q^N$ for $N \in [1,100]$: Edit4: it's $a <= b$ and not $a < b$, sorry!","['matrices', 'exponentiation']"
499547,"If $\sum_{n=1}^{\infty} a_n$ is absolutely convergent, will $\sum_{n=1}^{\infty} a_n$ and $\sum_{n=1}^{\infty} |a_n|$ converge to the same limit?",Suppose we have a series $\sum_{n=1}^{\infty}a_n$ such that it is both convergent and absolute convergent. Will the series $\sum_{n=1}^{\infty}a_n$ and $\sum_{n=1}^{\infty}|a_n|$ converge to the same value ?,"['sequences-and-series', 'real-analysis']"
499599,Proof that the space of infinite 01-sequences (Cantor-space) is totally disconnected,"I want to proof that the space $\{0,1\}^{\mathbb N}$ of infinite binary sequences with the product topology is totally disconnected. I know that this space has a basis consisting of clopen sets and is $T_2$, so it follows already that it is totally disconnected. But I tried to proof it directly using the definition. Def: A topological space $X$ is totally disconnected iff only the singletons are connected, i.e. if for every set $Y$ with more than two elements there exists two nonempty separated sets $X_1, X_2$ such that $Y = X_1 \cup X_2$. Proof: Let $Y \ne X$ be a set with more than one element. Then if $Y$ is finite, select some $y \in Y$, and because for finite sets $M$ it holds that $cl(M) = M$ it follows that $Y = \{y\} \cup Y\setminus\{y\}$ is a separation. Otherwise $Y$ is infinite if we can select a point $y$ which is not a limit point of $Y$ and we can write again $Y = \{y\} \cup Y\setminus\{y\}$. I am not sure if it is always possible to select a point which is not a limit point of $Y$, but I had sets like $Y = \{ ab^{\mathbb N}, aab^{\mathbb N},aaab^{\mathbb N},\ldots \}$ in mind, which has limit point $a^{\mathbb N}$. Is there a way to proceed along the lines of this proof and construct for every $Y$ such a partition into separated sets?","['general-topology', 'connectedness', 'descriptive-set-theory', 'analysis']"
499607,Why does Cantor's Proof (that R is uncountable) fail for Q?,"Why doesn't the ""diagonalization argument"" used by Cantor to show that the reals in the intervals [0,1] are uncountable, also work to show that the rationals in [0,1] are uncountable? To avoid confusion, here is the specific argument. Cantor considers the reals in the interval [0,1] and using proof by contradiction, supposes they are countable. Since this set is infinite, there must be a one to one correspondence with the naturals, which implies the reals in [0,1] admit of an enumeration which we can write in the form x$_j$ = 0.a$_{j1}$ a$_{j2}$ a$_{j3}$... (for j $\in$ $\mathbb{N}$). Now Cantor constructs a number x* where the jth digit of x* is (a$_{jj}$+2) mod 10 (I know there are other schemes; this is the one my professor used). The observation that x* $\neq$ x$_j$ $\forall$ j $\in$ $\mathbb{N}$, leads us to the conclusion that x* is not in this list, and hence the reals in [0,1] cannot be enumerated, and so [0,1] is not countable (which implies that the real numbers are not countable). I asked my professor and she was unable to tell me why this same argument couldn't be used to prove that the rationals in [0,1] are also uncountable. It seems the argument would have to somehow show that the number you constructed using Cantor's method must be either a terminatingor repeating decimal, but I can't see how to prove this Matt","['foundations', 'elementary-set-theory', 'real-analysis']"
499613,Logic for decomposing a permutation into different products composed of transpositions,"I know that any permutation cycle can be decomposed into transpositions as follows: $(a_1,a_2...,a_n) = (a_1,a_{n-1})...(a_1,a_2)$ But in my book there is an example of the following form $(1,2,3,4,5) = (5,4)(5,2)(2,1)(2,5)(2,3)(1,3)$ I verified that it holds true. But I cant seem to figure out how the author came up with that. Also, What is the generic algorithm to produce all decompositions of permutation in terms of transpositions.","['permutations', 'symmetric-groups', 'group-theory', 'abstract-algebra']"
499629,Taylor series of $\arctan(x+2)$ at $x=\infty$,"The simple question is: what is the correct way to calculate the series expansion of $\arctan(x+2)$ at $x=\infty$ without strange (and maybe wrong) tricks? Read further only if you want more details. The first (obvious) problem is that infinite is not a number, thus $\sum_{k=0}^{\infty}\frac{f^{(k)}(\infty)}{k!}(x-\infty)^k$ doesn't make sense. So I've tried to solve $\lim_{x_0\to \infty} ({\sum_{k=0}^{\infty}\frac{f^{(k)}(x_0)}{k!}(x-x_0)^k})$ one term at a time. The first term (with $k=0$) can be easily calculated and the second term is:
$$\lim_{x_0\to \infty} (\frac{x-x_0}{1+(x_0+4x_0+4)} \sim -\frac{x_0}{x_0^2}=\frac{-1}{x_0}) = 0$$ The asymptotic function $\frac{-1}{x_0}$ is similar to what I should get as the second term (which is $\frac{-1}{x}$). But to get the correct result I should do some dangerous stuff: I should replace $x_0$ with $x$ (why?) and do not calculate the limit (otherwise I cannot get the desired precision of the series expansion). I've also tried to solve $\arctan(1/t+2)$ with $t=0$, but the argument of arctg is still an infinite and the difficulties I encounter are the same. Is there any way to calculate the series expansion of $\arctan(x+2)$ at $x=\infty$ in a cleaner way without all these problems?","['taylor-expansion', 'asymptotics', 'analysis']"
499646,How can I show that $\begin{pmatrix} 1 & 1 \\ 0 & 1\end{pmatrix}^n = \begin{pmatrix} 1 & n \\ 0 & 1\end{pmatrix}$?,"Well, the original task was to figure out what the following expression evaluates to for any $n$. $$\begin{pmatrix} 1 & 1 \\ 0 & 1\end{pmatrix}^{\large n}$$ By trying out different values of $n$, I found the pattern:
$$\begin{pmatrix} 1 & 1 \\ 0 & 1\end{pmatrix}^{\large n} = \begin{pmatrix} 1 & n \\ 0 & 1\end{pmatrix}$$ But I have yet to figure out how to prove it algebraically. Suggestions?","['matrices', 'linear-algebra']"
499652,$\tan{\alpha} \approx \alpha$ if $\alpha$ is small,I saw this a lot in physics textbook but today I am curious about it and want to know if anyone can show me a formal mathematical proof of this statement? Thanks!,['trigonometry']
499730,How to solve this multiple integral of Hypergeometric function?,"Sorry for the typeset in the previous post, could you please help me with this integral? kind regards Ara $$ \int _0^{2\pi }d\phi \int _0^{1}du\left(u\cos^2(\phi )-1\right) \,_2F_1\left(1,\Delta +3,5/2,\cos^2(\alpha )\left(1-u\cos^2(\phi )\right)\right) $$","['general-topology', 'multivariable-calculus', 'calculus', 'integration']"
499733,Increasing and bounded sequence proof,"Prove that the sequence $a_n= 1+ \frac 12+ \frac 13+\cdots+ \frac 1n-\ln(⁡n)$ is increasing and bounded above. Conclude that it’s convergent. This what I got so far Proof: Part 1: Proving $a_n$ is increasing by induction. Base: 
$a_1=1$ $a_2=1+\frac 12= \frac 32$ $a_1≤a_2$ So the base case is established. Induction step: We assume that $a_{n-1}≤a_n$. We will show that $a_n≤a_{n+1}$.
Since $a_{n-1}≤a_n$ $$1+ \frac 12+ \frac 13+\cdots+ \frac{1}{(n-1)}-\ln(n-1) \leq 1+ \frac 12+ \frac 13+\cdots+ \frac 1n-\ln n$$ How should I continue?","['calculus', 'proof-writing']"
499734,"Integrating $\int\frac{\sin^3x}{\cos x}\,\mathrm dx.$","How would I integrate the following: .$$\int\frac{\sin^3x}{\cos x}\,\mathrm dx.$$ I am not sure what to do. I could split $\sin^3x=(1-\cos^2x)(\sin x)$ Then get $\int \tan(x)(1-\cos^2x)$ But would this be the right way to go.","['calculus', 'integration', 'indefinite-integrals']"
499745,Inner and outer Lebesgue measure,"For any subset $E\subseteq I=[0,1]$ define the inner Lebesgue measure by $m_{*}(E):=1-m^*(I\setminus E)$, where $m^*$ is the outer Lebesgue measure. Show that 
    $$
E\subseteq I \mbox{ is }m^*- \mbox{measurable }\Leftrightarrow m_*(E)=m^*(E).
$$ ""$\Rightarrow$"" Let $E\subseteq I$ be measurable relating to $m^*$, that means
$$
m^*(Q)=m^*(Q\cap E)+m^*(Q\cap E^C)~\forall Q\subseteq I.
$$
Choose $Q=I$. Then
$$
m_*(E)=1-m^*(I\setminus E)\\=1-m^*(I\cap E^C)\\1-(m^*(I)-m^*(I\cap E))\\=1-m^*(I)+m^*(E).
$$
When I look athe the definition of $m^*$ then 
$$
m^*(I)=\inf\left\{\sum\limits_{n\geq 1}\lambda(A_n): A_n\subseteq\mathcal{I},n\in\mathbb{N},I\subset\bigcup\limits_{n\geq 1}A_n\right\},
$$
where $\lambda$ is the Lebesgue content on the half ring $\mathcal{I}=\left\{(a,b],a,b\in\mathbb{R},a\leq b\right\}$ and the infimum is taken over the covers of $I$. And this infimum is 1 - the left boundary going from the left side to 0. So it follows
$$
m_*(E)=1-m^*(I)+m^*(E)=1-1+m^*(E)=m^*(E).
$$ My problem is to show the direction ""$\Leftarrow$"". Can you give me a help how to show that direction please?",['measure-theory']
499746,"Intuition: Power Set of Intersection/Union (Velleman P77 & Ex 2.3.10, 11)","Source: How to Prove It, 2nd Ed by Velleman. $\mathcal{P}(...) =$ power set of ... & $A, B$ are any sets: Ex 2.3.10: $\qquad \qquad \qquad \qquad \qquad \qquad \mathcal{P}(A \cap B) = \mathcal{P}(A) \cap \mathcal{P}(B)$ Ex 2.3.11 = Chartrand Ex 7.55: $ \qquad \qquad \color{ 	#0070FF}{\mathcal{P}(A \cup B)} \neq \color{green}{\mathcal{P}(A) \cup \mathcal{P}(B)}$ What are the intuitions? Where did your intuitions originate from? No proofs please. I compassed to grok this by writing everything out explicitly. For instance, for Ex 2.3.11, because $\color{ 	#0070FF}{\mathcal{P}(A \cup B) = \{\color{green}{subsets}, A \cup B\}}$, but $\color{green}{\mathcal{P}(A) \cup \mathcal{P}(B) = \{subsets\}}$, thus (UNintuitively) $\color{ 	#0070FF}{\mathcal{P}(A \cup B)}  = \color{green}{\mathcal{P}(A) \cup \mathcal{P}(B)} \cup (A \cup B)$.","['intuition', 'elementary-set-theory']"
499765,Does differentiation symbol need parentheses or?,"Suppose I have this expression:
$$\frac{d}{dx}(e^{x})^2 + 6$$ Does it mean to differentiate $6$ too or just the first term? This is an exercise on a calculus course that I'm doing on Coursera.
Unfortunately anything printed has a weight greater than the onlooker's intelligence. It's beyond me how people on the course forum including the two professors who happen to be doctors can't understand the basic and obvious meaning of parentheses.","['notation', 'calculus', 'derivatives']"
499773,A problem regarding rational and irrational numbers.,"Let $n$ be a positive integer greater or equal to $2$. Prove that there are infinitely many irrational numbers $a$ such that $a+a^2+\cdots+a^n$ is rational. Well, let $p$ be a prime. We consider the equation:
$x^n + x^{n-1} +\cdots+ x=1/p$, which is equivalent to:
$px^n+px^{n-1}+\cdots+px-1=0$
We can prove that the equation has a solution $a$ in the interval $I=(0, 1/p)$ using continuity and that the solution is not rational. But, is there another solution without using continuity? Thanks!",['algebra-precalculus']
499779,What does it mean for a surface to evolve with divergence-free velocity?,"Suppose we have an evolving hypersurface which evolves with a velocity field $V$, such that $\nabla_S \cdot V = 0$ where $\nabla_S$ is the surface or tangential gradient. What does this mean? What does it mean physically for example?","['surfaces', 'functional-analysis', 'differential-geometry']"
499783,Conjugate subgroups and conjugate elements,"While trying to prove that the alternating group $A_5$ is a simple group, I came across two assertions I see as contradicting, that is : the 5-cycles are not all conjugate to each other (proven here : Show that not all 5 cycles in $A_5$ are conjugate in $A_5$ ) if $\sigma$ and $\sigma'$ are 5-cyles, then by one of the Sylow theorems, $<\sigma>$, which is a 5-Sylow is conjuguate to $<\sigma'>$, another 5-Sylow Can anyone demystify this ?","['abstract-algebra', 'sylow-theory', 'finite-groups', 'symmetric-groups', 'group-theory']"
499795,Monotone convergence theorem (almost everywhere concept),"Could someone enlighten me. Monotone convergence theorem says: if $f_{n},f\in L^{+}$ i.e measurable functions, such that $f_{n}\uparrow f$ pointwise then $\int f_{n}\uparrow \int f$. But then my teacher says we can relax the condition, using almost everywhere. We can assume that $f_{n}\uparrow f$ a.e $\Rightarrow \int f_{n}\uparrow \int f$ and then he does something I don't get. He asks the question: ''Is it true $f_{n}\to f$ a.e $\Rightarrow \int f_{n}\to \int f$?'' what does the horizontal arrow mean in this case? (does he also mean converge to but almost everywhere?) Here is his counterexample 
$(X,\mathcal{M},\mu)=(\mathbb{R},\mathcal{L},m)$ and we let $f_{n}=\chi_{[n,n+1]}$ then $\int \chi_{[n,n+1]}dm=m([n,n+1])=1$ but $f_{n}\to 0$ pointwise Is the horizontal and the vertical arrow meaning the same (''converge to'')? Why do the characteristic functions converge pointwise??","['measure-theory', 'real-analysis']"
499802,pullback and pushforward examples,Where can I find some simple examples of pullbacks and pushforwards between manifolds. Specifically examples that show the details of the computations.,['differential-geometry']
499822,Is $e = \sum_n 1/n!$ the most efficient sequence of denominators for rational series for $e$?,"The classical series $e = \lim_{n \to \infty} X_n$ where $X_n = \sum_{k=0}^n 1/k!$ is incredibly efficient. But is it known to be the most efficient series in terms of denominators for using fractions in the sum? In other words, is it known whether there is another series of fractions $e = \lim_{n \to \infty} Y_n$ where $Y_n = \sum_{k=0}^n a_k/b_k$ ($b_k > 0$, $a_k,b_k$ integers) where $\lim_{k \to \infty} b_k/k! \leq 1$ and $\lim_{n \to \infty} |(Y_n - e)/(X_n -e)| < 1$?","['approximation', 'sequences-and-series', 'real-analysis']"
499823,Using Central Limit Theorem when we NON-IID sample,"I'm trying to solve a CLT question and I've got some issues. I appreciate if you could help me on that. Consider the question below: $\epsilon_i$ 's are iid random variables with finite mean and variance. $X_i$'s are defined as: $$X_i = \frac{\epsilon_i + \epsilon_{i + 1} + \epsilon_{i + 2}}{3}$$
$$ S_n = \sum_{j =1}^{n} X_j$$ I need to find constants $a_n$ and $b_n$ such that $\frac{S_n - a_n}{b_n} \rightarrow N(0,1)$. Here is what I've done so far: Considering $S_{1,n} = \sum_{j = 1}^{n} \epsilon_j$, we can simply use CLT. We can also do the same for $S_{2,n} = \sum_{j = 2}^{n} \epsilon_j$ and for $S_{3,n} = \sum_{j = 3}^{n} \epsilon_j$. The issue is how to combine these three terms together. Obviously, there are some common terms when we combine all these three together which makes observations not to be IID anymore and that's the main challenge.","['weak-convergence', 'probability-limit-theorems', 'probability-distributions', 'probability', 'limits']"
499826,Homeomorphic to the disk implies existence of fixed point common to all isometries?,"A fellow grad student was working on this seemingly simple problem which appears to have us both stuck. (The problem naturally came up in his work so isn't from the literature as far as we know). Let $M$ be a metric space homeomorphic to the closed unit disk $D^n\subset \mathbb{R}^n$. We call such a metric space an $n$-cell . Let $\mbox{Isom}(M)$ be the group of bijective isometries $M\rightarrow M$. If $M$ is an $n$-cell, does there exist a point $p\in M$ such that $\varphi(p)=p$ for all $\varphi\in \mbox{Isom}(M)$? Clearly such a $p$ need not be unique. So far, the best attempt has been to consider a set which is invariant under isometries, as follows. Let $\partial M$ be the boundary of $M$ and define a function $f\colon M\rightarrow \mathbb{R}$ by $f(x)=\sup_{y\in\partial M}\{d(x,y)\}$ which is continuous, and as $M$ is compact must attain its minimum say $m$. Then, let $$A=\{p\in M\mid f(p)=m\}.$$ That is, $A$ is the (non-empty) set of points in $M$ which minimise the maximum distance to the boundary of $M$. It should be clear that if $\varphi$ is an isometry on $M$, then $\varphi(A)=A$, and one would hope that $A$ is in fact a single point (or at least fixed pointwise instead of just setwise). However, proving this is not clear. There is obviously something else missing here as the topology on the $n$-cell is crucial. For instance an annulus has no such fixed point and the set $A$ would be the inner boundary circle. It's possible the above set up isn't the right way to tackle the problem. It's also possible that there exists a counterexample and there is some $M$ with no fixed point. Any help is appreciated.","['general-topology', 'fixed-point-theorems', 'metric-spaces']"
499848,Coordinates in a torus eversion,"(This may be a somewhat vague question.) If the circle $(y-R)^2+z^2=1$ ($R>1$) is revolved about the $z$-axis, the surface generated is a torus that can be parametrized by longitude $\alpha$ and latitude $\beta$ as follows:
$$
\begin{align}
x & = (R+\cos\beta)\cos\alpha, \\
y & = (R+\cos\beta)\sin\alpha, \\
z & = \sin\beta.
\end{align}
$$
The names of the two parameters make sense since curves of constant latitude are circles parallel to each other and curves of constant longitude are circles in planes intersecting in a line through the center of the torus and orthogonal to planes containing circles of constant latitude. Now consider the surface
$$
\begin{align}
u & = (R-\cos\alpha)\cos\beta, \\
v & = (R-\cos\alpha)\sin\beta, \\
w & = \sin\alpha.
\end{align}
$$
On this surface $\beta$ is the longitude and $\alpha$ is the latitude rather than vice-versa.  A one-to-one correspondence between this surface and the other one is identified by this transposition of variables.  We have turned the torus inside-out (or ""everted"" it, if you like that word).  Also, the minus sign where a plus sign had appeared means that a point on the inner equator is now on the outer equator (this aspect of the situation didn't need to be there to justify the conclusion that we have turned the torus inside-out, but I want it because of a geometric problem I'm thinking about). My question is whether some particular one of the six correspondences between the variables $x,y,z$ and the variables $u,v,w$ should be preferred by reason of convention or of aesthetics or of mathematics?",['geometry']
499854,Problem regarding the fitting cube into sphere,"I was solving the following problem Suppose I have a sphere of radius 1 metre.
The sphere is colored with red and blue such that it has disconnected regions of red and blue colors. Now I have to make a cube that fits in the sphere such that 
Each vertex of the cube touches a red-colored region. This is possible if one of the following option is true a) The aggregate area of red part is $11 m^2$ . b) The aggregate area of red part is $10 m^2$ . c) The aggregate area of red part is NOT $11 m^2$ . Answer given was (a) Where aggregate area is the sum of areas of all regions.
Well I approached by calculating total surface area 
 of sphere = $12.56 m^2$ So subtracting from $11m^2$ gives me the minimum residue and so the answer follows. Is my reasoning correct or any other explanation for this the answer??","['geometry', 'puzzle']"
499885,Question about proof of Countable subadditivity of Lebesgue outer measure,"I'm studying real analysis from the Terence Tao book. In Exercise 1.2.3. (iii) they ask the reader to prove subadditivity of Lebesgue outer measure. It mentions the proof should use the axiom of choice, Tonelli's theorem for series, and $\epsilon/2^n$ trick. The proof I came up with used only tonelli's theorem, and seemed almost immediate. So there's probably something wrong with it... Given $\{E_n\}_{n=1}^\infty$ sets in $\mathbb{R}^d$ $$m^*(\cup_{n=1}^\infty E_n) = \inf \sum_{n=1}^\infty |B_n| $$ over all covers of $\cup_{n=1}^\infty E_n$ by a countable set of boxes $\{B_n\}_{n=1}^\infty$ . Given any cover of each of individual sets $E_n$ by a sequence of boxes $\{B_{n,m}\}_{m=1}^\infty$ , we have $\cup_{n=1}^\infty E_n \subseteq \cup_{n,m=1}^\infty B_{n,m}$ making it a cover included in the infimum above. Therefore $$ 
\inf \sum_{n=1}^\infty |B_n| \le \inf \sum_{n,m=1}^\infty |B_{n,m}| = \inf \sum_{n=1}^\infty \sum_{m=1}^\infty |B_{n,m}| = \sum_{n=1}^\infty m^*(E_n)
$$ The inequality is due to the right side infimum being over the same function but over a set contained in the one considered by the left side infimum. The first equality is due to Tonelli's theorem for series. The second equality is direct from the definition of $m^*$ .","['measure-theory', 'real-analysis']"
499902,"How to generate a good guess from other guesses, if the average has already been taken?","There are votes two days from now* and someone made an excel sheet where people at work would make their guesses on the outcome. Since I'm not from this country, I had no idea what to do and decided to be super clever and make my collumn just the average of the others. Well, it turned out that I'm not the only foreigner and a college did just that before me. I tested to see what excel would do if I take the average anyway and not surprisingly the program killed both entries, which tried to compute an average $m_1$ from other entries of which one is average $m_1$ involving $m_2$ itself. So what I ended up with manipulating his entry to exclude mine and added a positive epsilon so there is a 50%-50% change I'm closer. So much for the motivation. Now this got me thinking: Lets say $n+2$ people, the last two being called Alice and Bob, respectively make a guess $G_i$ on the outcome of some experiment. They make their guesses publicly, one after the other, and say for all $i\in \{1,2,3,\dots,n-1,n,n+1,n+2\}$, the guess $G_i$ is some rational number. 
Now after the first $n$ people have publicly made their guess, alice thinks she's clever and just chooses to make a guess which is just the average of all other guesses, including bob who still has to guess: $G_{n+1}:=\frac{(\sum_{i=1}^n G_i)+G_{n+2}}{n+1}$. Bob thinks taking an average will be a good move, but now that this is done he tends to make a slightly bigger guess than what he sees the average to be. He will give a procedure to compute his $G_{n+2}$ which shall be slightly above $G_{n+1}$. The task is to compute a number which is as close to $G_{n+1}$ as possible but not equal to it. He can only use one additional number $\varepsilon$ and there is a smallest value for this $\varepsilon$ he can manually enter into the code. So again: You can use the program to compute a number involving one instance of $+\varepsilon$ with fixed positive value at some point, and for $\varepsilon=0$ you naturally want the computed function to coincide with the average (Alice guess). Now I've had two ideas which both seem natural: Either set $G_{n+2}:=G_{n+1}+\varepsilon$, or set $G_{n+2}:=\frac{(\sum_{i=1}^n G_i)+G_{n+1}}{n+1}+\varepsilon$.
I tried some random numbers for $n$, $\sum_{i=1}^n G_i$ and $\varepsilon$ and the second approach for $G_{n+2}$ seems to be quite closer to $G_{n+1}$, but moreally, I don't really know why. Does anyone see why the one approach turns out to be superiour to the other, and are there better places to put the $\varepsilon$. *Merkel will win again.",['statistics']
499905,"Is $(x^2+y^2-1,z-iy)$ a prime ideal in $\mathbb C[x,y,z]$?","Is $(x^2+y^2-1,z-iy)$ a prime ideal in $\mathbb C[x,y,z]$? How can I prove it? I need this to decompose the algebraic set $V(x^2+y^2-1,x^2-z^2-1)$ into irreductible components.","['commutative-algebra', 'ideals', 'algebraic-geometry', 'abstract-algebra']"
499917,Example of an infinite group where every element except identity has order 2,"Find an infinite group, in which every element g not equal identity (e) has order 2 Does this question mean this: the group that fail condition (2) which is no inverse and also that group must have the size 2 My answer: Z*","['infinite-groups', 'group-theory']"
499926,Evaluating the series $\sum\limits_{n=1}^{\infty} \frac{1}{n^{3} \binom{2n}{n}} $,"Wolfram MathWorld states that $$ \sum_{n=1}^{\infty} \frac{1}{n^{3} \binom{2n}{n}} = \frac{ \pi \sqrt{3}}{18} \Bigg[ \psi_{1} \left(\frac{1}{3} \right) - \psi_{1} \left(\frac{2}{3} \right) \Bigg]- \frac{4}{3} \zeta(3) \, , $$ where $\psi_{1}(x)$ is the trigamma function . I'm having difficulty getting the result in that form. Using the Taylor expansion $$ \arcsin^{2}(x) = \frac{1}{2} \sum_{n=1}^{\infty} \frac{1}{n^{2} \binom{2n}{n}} (2x)^{2n},$$ I get $$ \sum_{n=1}^{\infty} \frac{1}{n^{3} \binom{2n}{n}} = 4 \int_{0}^{\frac{1}{2}} \frac{\arcsin^{2}(x)}{x} \, \mathrm dx. $$ Then I integrating by parts, I get $$ \begin{align} &4 \int_{0}^{\frac{1}{2}} \frac{\arcsin^{2}(x)}{x} \, \mathrm dx \\ &=  \frac{\pi^{2}}{9} \ln \left(\frac{1}{2} \right) - 8 \int_{0}^{\frac{1}{2}} \frac{\arcsin (x) \ln (x)}{\sqrt{1-x^{2}}} \, \mathrm dx \\ &= - \frac{\pi^{2}}{9} \ln 2 - 8 \int_{0}^{\frac{\pi}{6}} u \ln (\sin u ) \, \mathrm du \\ &= - 8 \ln 2 \int_{0}^{\frac{\pi}{6}} u \, \mathrm  du - 8\int_{0}^{\frac{\pi}{6}} u \ln (\sin u ) \, \mathrm du \\ &= - 8 \int_{0}^{\frac{\pi}{6}} u \ln ( 2 \sin u ) \, \mathrm du  \\ &= -8 \ \text{Re} \int_{0}^{\frac{\pi}{6}} u \ln (1-e^{2iu}) \, \mathrm du \\ &= 8 \ \text{Re} \int_{0}^{\frac{\pi}{6}} u \sum_{n=1}^{\infty} \frac{e^{2in u}}{n} \, \mathrm du  \\ &= 8 \ \sum_{n=1}^{\infty}  \frac{1}{n} \int_{0}^{\frac{\pi}{6}} u \cos (2nu) \, du \\ &= \frac{2 \pi}{3} \sum_{n=1}^{\infty} \frac{\sin (\frac{n \pi}{3})}{n^{2}} + 2 \sum_{n=1}^{\infty} \frac{\cos (\frac{n \pi}{3})}{n^{3}} - 2 \zeta(3) \\ &= \frac{2 \pi}{3} \Bigg( \frac{\sqrt{3}}{2} \sum_{n=0}^{\infty} \frac{1}{(6n+1)^{2}} + \frac{\sqrt{3}}{2} \sum_{n=0}^{\infty} \frac{1}{(6n+2)^{2}} - \frac{\sqrt{3}}{2} \sum_{n=0}^{\infty} \frac{1}{(6n+4)^{2}} - \frac{\sqrt{3}}{2} \sum_{n=0}^{\infty} \frac{1}{(6n+5)^{2}} \Bigg) \\ &+ \  2  \Bigg( \frac{1}{2} \sum_{n=0}^{\infty} \frac{1}{(6n+1)^{3}} - \frac{1}{2} \sum_{n=0}^{\infty} \frac{1}{(6n+2)^{3}} - \sum_{n=0}^{\infty} \frac{1}{(6n+3)^{3}} - \frac{1}{2} \sum_{n=0}^{\infty} \frac{1}{(6n+4)^{3}} \\ &+ \frac{1}{2} \sum_{n=0}^{\infty} \frac{1}{(6n+5)^{3}} + \sum_{n=1}^{\infty} \frac{1}{(6n)^{3}} \Bigg) - 2 \zeta(3) \\ &= \frac{\pi \sqrt{3}}{108} \Bigg( \psi_{1} \left(\frac{1}{6} \right) + \psi_{1} \left(\frac{1}{3} \right) - \psi_{1} \left(\frac{2}{3} \right) - \psi_{1}\left(\frac{5}{6} \right) \Bigg) + \frac{1}{432} \Bigg( - \psi_{2} \left(\frac{1}{6} \right) + \psi_{2} \left(\frac{1}{3} \right) \\ &-28 \zeta(3)  + \psi_{2} \left(\frac{2}{3} \right) - \psi_{2} \left(\frac{5}{6} \right) + 4 \zeta(3)\Bigg) - 2 \zeta (3) .\end{align}$$ But from here I've been going in circles trying to get the result in the form given on the Wolfram MathWorld site. EDIT : Using the duplication formula for the trigamma function (i.e., $ \displaystyle 4 \psi_{1}(2x) = \psi_{1}(x) + \psi_{1} \left(x + \frac{1}{2} \right) $ ), I get $$ \begin{align} &\psi_{1} \left(\frac{1}{6} \right) + \psi_{1} \left(\frac{1}{3}  \right) - \psi_{1} \left(\frac{2}{3} \right) - \psi_{1}\left(\frac{5}{6}  \right) \\ &= 4 \psi_{1} \left(\frac{1}{3} \right) -\psi_{1} \left(\frac{2}{3} \right) +  \psi_{1} \left(\frac{1}{3} \right) -\psi_{1} \left(\frac{2}{3} \right) - 4  \psi_{1} \left(\frac{2}{3} \right) + \psi_{1} \left(\frac{1}{3} \right) \\ &= 6 \psi_{1} \left(\frac{1}{3} \right) - 6 \psi_{1} \left(\frac{2}{3} \right). \end{align}$$ Therefore, $$ \begin{align} \sum_{n=1}^{\infty} \frac{1}{n^{3} \binom{2n}{n}} &= \frac{\sqrt{3} \pi}{18} \Bigg( \psi_{1} \left(\frac{1}{3} \right) - \psi_{1} \left(\frac{2}{3} \right) \Bigg) + 
\frac{1}{432} \Bigg( - \psi_{2} \left(\frac{1}{6} \right) + \psi_{2} \left(\frac{1}{3} \right) \\ &+ \psi_{2} \left(\frac{2}{3} \right) - \psi_{2} \left(\frac{5}{6} \right) - 2 \zeta(3)\Bigg) - 2 \zeta (3). \end{align}$$ So it comes down to somehow showing that $$-\psi_{2} \left(\frac{1}{6} \right) + \psi_{2} \left(\frac{1}{3} \right) + \psi_{2} \left(\frac{2}{3} \right) - \psi_{2} \left(\frac{5}{6} \right) = 312 \zeta(3) .$$ SECOND EDIT : Using the duplication formula for $\psi_{2}(x)$ , I get $$ \begin{align} &-\psi_{2} \left(\frac{1}{6} \right) + \psi_{2} \left(\frac{1}{3} \right) + \psi_{2} \left(\frac{2}{3} \right) - \psi_{2} \left(\frac{5}{6} \right) \\ &= -8 \psi_{2} \left(\frac{1}{3} \right) +\psi_{2} \left(\frac{2}{3} \right) +  \psi_{2} \left(\frac{1}{3} \right) +\psi_{2} \left(\frac{2}{3} \right) - 8 \psi_{2} \left(\frac{2}{3} \right) + \psi_{2} \left(\frac{1}{3} \right) \\ &= -6 \psi_{2} \left(\frac{1}{3} \right) - 6 \psi_{2} \left(\frac{2}{3} \right) . \end{align}$$ And then using the triplication forumula , I get $$ \psi_{2} \left(\frac{1}{3} \right) + \psi_{2} \left( \frac{2}{3} \right) + \psi_{2}(1) = 27 \psi_{2} (1) .$$ Therefore, $$  -6 \psi_{2} \left(\frac{1}{3} \right) - 6 \psi_{2} \left(\frac{2}{3} \right) = -156 \psi_{2} (1) = 312 \zeta(3) .$$","['special-functions', 'sequences-and-series', 'gamma-function', 'binomial-coefficients', 'complex-analysis']"
499959,Recommendation for a good book on equation solving theory from the basics,I'm relearning calculus but I often find myself applying algebraic operations to equations mechanically without having a solid understanding of the side-effects of those operations. Such as extra or reduced number of roots when squaring both sides or taking the square root of both sides. What book do you recommend for properly learning the theory of solving equations in depth? A simple example is solving for y in $y^2=x^2$. I'd like a book that discusses solving such an equation and other forms starting from first principles and stating definitions and proving theorems on the way.,"['elementary-number-theory', 'algebra-precalculus', 'problem-solving']"
499963,Smooth torus eversion,"I asked a vague question about torus eversion earlier, with no hard math, so while I'm at it, how about this one, which may involve hard math: ""Everybody knows"" that Stephen Smale showed us how to evert a sphere without tearing or creasing: http://www.youtube.com/watch?v=R_w4HYXuo9M Has anyone done the same with a torus?","['geometry', 'homotopy-theory']"
499995,"Question regarding disjoint unions, sequential compactness, and Dedekind-finiteness","I have proved the following two results: $[\mathsf{ZF}]$ The disjoint union of a Dedekind-finite family of sequentially compact topological spaces is again sequentially compact. $[\mathsf{ZF}+\text{Countable Choice}]$ If the disjoint union of a family of topological spaces is sequentially compact, then the family is finite, and each member of the family is sequentially compact. I've further been able to show that the latter fails if there is an infinite, Dedekind-finite set--if $X$ is such a set, topologize $X$ discretely, which is the same as topologizing $X$ as the disjoint union of an infinite, Dedekind-finite family of singleton spaces, each of which is sequentially compact, and since sequences of points of $X$ will necessarily have only finitely-many distinct points by Dedekind-finiteness, we have that $X$ is also sequentially compact. I'd like to be able to weaken the second result to the following Claim : If the disjoint union of a family of topological spaces is sequentially compact, then the family is Dedekind-finite, and each member of the family is sequentially compact. Ideally, I'd like to do it in a setting without Countable Choice, but I just don't see a way out of it. Showing that each member of the family is sequentially compact is simple, and I can readily conclude that a sequence of points of the larger space must lie strictly outside all but finitely-many members of the family of smaller spaces, since otherwise, we can build a new sequence with no two points lying in the same member of the family of smaller spaces, which can have no convergent subsequence. However, while Dedekind-finiteness of the family is sufficient to ensure that this doesn't happen, I cannot see why it should be necessary. If the family is Dedekind-infinite, then we have a countably-infinite subfamily, but without a choice function, I see no way to choose a single point from each member of the subfamily to make a sequence without convergent subsequence. (Of course, I could fix this if I added the hypothesis that the family of topological spaces had a choice function, but I'd like to avoid this, if possible.) Edit : It is consistent with $\mathsf{ZF}$ that there is a countably-infinite set $X$ of $2$ -element sets whose union is Dedekind finite. Considering the two-element sets in the indiscrete topology, each of them is readily sequentially compact, and the disjoint union is sequentially compact by virtue of its Dedekind-finiteness. Thus, my claim clearly need not hold in $\mathsf{ZF}$ alone. Is there some weaker Choice principle than Countable Choice that will allow me to prove it? (It occurs to me that this might be a better fit at Math.Overflow, but I thought I'd try it here, first.)","['general-topology', 'set-theory', 'compactness', 'axiom-of-choice']"
499996,"Number of elements in the resulting set of ""subtraction game""","You have the following game: You start with a set $S$ with a number $n$ of positive integer elements, $n \ge 2$.
At each step, you add to the set any new number $i$, as long as $i = |a-b|$ and $a$ and $b$ already belong to the set, $a \neq b$. Repeat this until no more new numbers can be added to the set. Now, given a initial set $S$, how can you calculate the number of members of the set after the game is over? (Assume you will add all possible elements). Some background on the question: I know this sounds like homework, but it's not. The question appeared after solving a problem in codeforces, a programming competition website - http://codeforces.com/problemset/problem/346/A (The contest in which this problem appeared is over and now you are allowed to discuss it :) I managed to solve the problem and get my solution accepted on the website, therefore I already know the formula that answers this question. The problem is: it was just a guess. Although I've tried a lot to devise some reasoning that would lead me to the answer, I could not. So I am more interested in how do you arrive to the solution, rather than the solution itself . (Also, I thought about asking ""how do you prove that the final number of elements is equal the formula"", but the reasoning required to achieve this would be different, although I couldn't prove it too :( )","['elementary-number-theory', 'elementary-set-theory']"
500009,For a set $A$ what is $A^0$?,"$A^0 = \varnothing$ seems wrong because then $A^1 \times A^0 = A \times \varnothing = \varnothing \neq A^{1 + 0}$. A singleton set seems more sensible, but is there a ""canonical"" singleton set to use? (Ie, maybe just the set $1 = \{0\} = \{\varnothing\}$ ?)",['elementary-set-theory']
500015,Implicit differentiation issue,"I am trying to implicitly differentiate $$\sin(x/y) = 1/2 $$
The solution manual says Step 1. $$\cos(x/y)\cdot\frac{y-x\frac{dy}{dx}}{y^2} = 0 $$ But I don't understand how they arrive at this next part: Step 2. $$y-x\frac{dy}{dx}=0$$ Is $\cos(x/y) = y^2$?","['trigonometry', 'implicit-differentiation', 'calculus', 'algebra-precalculus']"
500024,Discrete Math - Set Theory - Power Set,"I am stuck on a problem in my discrete mathematics textbook at the moment. The problem, as written in the textbook, is: For a certain set $A$, the power set of $A$ is $\mathcal{P}(A) = \{\aleph_0, \{0\}, B\}$, where $B$ is a set. What is $A$? My confusion here is that I was under the impression that for any set, let's say $D$, that $|\mathcal{P}(D)| = 2^n$. If this is the case, I don't really understand how the power set of $A$ from the problem above can contain only three elements. If set $A$ has two elements, then its power set will have fourelements. If set $A$ has one element, then its power set will have two elements. I know I missing something here, and I appreciate any hints, help, or guidance.","['discrete-mathematics', 'elementary-set-theory']"
500033,"Integrate $\int\frac{Cx}{(\sin x^2)^2}\,\mathrm dx.$","Have been a doing a reduction of order ODE problem and this integral comes up at the last step. Not sure how to go about integrating it. The answers give $\cos x^2$ as the answer. Here's the original question:
Verify that $u_1=\sin x^2$ is a solution to the equation $$xu''-u'+4x^3u=0$$ and use reduction of order to find a second, linearly independent solution. I've called the second solution $v$ and as far as I can tell, everything is good with my previous working. The only remaining bit is to integrate $$v'=\frac{Cx}{(\sin x^2)^2}\Leftrightarrow v=\int\frac{Cx}{(\sin x^2)^2}\,\mathrm dx.$$
Integration by parts didn't really help. I think there might be a substitution that I'm missing/forgetting.
Thanks.","['trigonometry', 'ordinary-differential-equations', 'integration']"
500065,Real solutions of $x$ in $\{x\} = \{x^2\} = \{x^3\}$,"Calculate real values of $x$ in $\{x\} = \{x^2\} = \{x^3\}$ , where $\{x\}$ is the fractional part of $x$. My Attempt: Let $\{x\} = \{x^2\} = \{x^3\} = k$. Because the fractional part of $X$ is given by $\{X\} = X-\lfloor X \rfloor$, we know the following to be true: $$
0\leq \{x\} <1\\
0\leq \{x^2\} <1\\
0\leq \{x^3\} <1\\
$$ Using the definition of the fractional part, our equation becomes $$
x-\lfloor x \rfloor = x^2-\lfloor x^2 \rfloor = x^3-\lfloor x^3 \rfloor = k
$$ I'm not sure how to proceed from here.",['algebra-precalculus']
500114,"Prove: If $E$ is a nonempty subset of natural numbers, then there exists an element $k$ in $E$ such that $k\in m$ for any $m$ in $E$ and $m \ne k$","Prove: If $E$ is a nonempty subset of natural numbers, then there exists an element $k$ in $E$ such that $k\in m$ for any $m$ in $E$ and $m \ne k$ This is an exercise of Paul Halmos' text, Naive set theory , page 49 . I proved that when $0 \in E$ as $k=0$ , but  when $0 \notin E$ , I faced difficulties. As I understand, the exercise asks me to prove that for any nonempty of subset of natural number , there is a number which is less than any other number (minimal number) which is the principle of well-ordering. So I have to use induction. I look for a hint ? I think, I should find a method which enable me to get a minimal element of the subset $E$ from arbitrary element $n$ in $E$",['elementary-set-theory']
500117,Expected Value of Number of Tails Minus Number of Heads,"I have the following problem where, given $X_n$ is a random variable that equals the number of tails minus the number of heads when n fair coins are flipped, what is the expected value of $X_n$? I am having a difficulty getting started on this problem.  Could someone offer a suggestion as to how this problem should be modeled?",['probability']
500120,"Prove $(a^m)^n=a^{mn}$ for all $a\in G$ and $m,n\in\mathbb{Z}$","I have to prove  $(a^m)^n=a^{mn}$ for all $a\in G$ and $m,n\in\mathbb{Z}$ where $G$ is a group. Is it enough to just expand $(a^m)^n=(a^m***a^m)$- $n$ times. And then from here we can expand it a bit more to there there are $mn$ amount of $a's$? Or do I need to break it up into cases. I felt if I did I'll have atleast 3 cases and a few subcases. As of right now I have two cases one where $m=n=0$ and the other where $a,b\neq 0$. Here is what I have so far. New proof #2 Case 1: Let $m>0$ and $n>0$ We will proceed by induction. We fix m and induct on n. 
  Base case: Let n=1. We see that $a^m=a^m$. 
  Inductive case: Suppose that $(a^m)^k=a^{mk}$ We shall prove $(a^m)^{k+1}=a^{m(k+1)}$.
  It follows immediately from assumption that $(a^m)^{k+1}=a^{m(k+1)}$. Case 2: $m=n=0$. It is immediately obvious that  $(a^m)^n=a^{mn}$ Case 3: $m<0$ and $n<0$.  Let $m=-t$ and $n=-r$ where $t,r>0$. Then $(a^m)^n=(a^{-t})^{-r})=(a^{-1})^t)^r)^{-1}=(a^{-1})^{rt})^{-1}=(a^{-nt})^{-1}=(a^{nt})^{-1}=a^{n*(-1)t}=a^{mn}$",['abstract-algebra']
500132,Find the number of distinct real roots of $(x-a)^3+(x-b)^3+(x-c)^3=0$ [duplicate],"This question already has answers here : How many real roots does $(x-a)^3+(x-b)^3+(x-c)^3$ have? (3 answers) Closed 10 years ago . Problem :Find the number of distinct real roots of $(x-a)^3+(x-b)^3+(x-c)^3=0$ where $a,b,c$ are distinct real numbers Solution : $(x-a)^3+(x-b)^3+(x-c)^3=0$ $3x^3-3x^2(a+b+c)+3x(a^2+b^2+c^2)-a^3-b^3-c^3=0$ By Descartes rule of sign,number of positive real roots $=3$ But are they distinct $?$ Answer :- number of distinct real roots $ =1$","['real-analysis', 'analysis']"
500144,Need help on Stokes Theorem in surface integral,"Hello and how you doing today? I just came across a problem which need to use Stokes theorem. The problems says: Evaluate the surface integral $$
\int_{S}\nabla\times\vec{F}\cdot{\rm d}\vec{S}
$$ where F(x,y,z)=$(y^2)i$ + $(2xy)j$+$(xz^2)k$ and S is the surface of the paraboloid $z=
x^2+y^2$ bounded by the planes $x=0,y=0$ and $z=1$ in the first quadrant pointing upward. I got $\nabla F$ which is $(-z^2)j$ So, I stuck at here because I dont know the boundary C in order to use Stokes theorem. So could someone please help me to start? By the way thank you very much for taking your time and consideration to help me on this problem.",['multivariable-calculus']
500170,Rational solutions of $x^3+y^3=2$,"I came along the problem of finding three perfect cubes that are consecutive numbers of an arithmetic progression, i.e: $a^3-b^3=b^3-c^3$, where $a>b>c$ (to avoid trivial solutions). Clearly it is equivalent to solve $x^3+y^3=2$ over the rationals. This is something I tried: Consider the curve $x^3+y^3=2$ in te plane. I looked for a rational parametrisation of it. Ok, maybe looking for a rational parametrisation won't give all solutions (I'm not sure about that) but it's a start and we'll see what it leads us to. I tried considering the intersection points with the line $y=tx+(1-t)$, since we now $(1,1)$ is such a point. (And I had seen a similar approach to find solutions to $x^2+y^2=1$.) Solving the system for $x$ gave me (after factoring out the superfluous factor $x-1$) a quadratic in $x$ with discriminant $-3(t+1)^4+36t^2-4$. So it suffices to figure out when this is the square of a rational. Let's write it as $-3(p+q)^4+36p^2q^2-4q^2=d^2$, where $p=qt$. And here's where I can't continue. Any proceeding of this method or other methods are welcome. P.S: This is not homework, it's just a question out of curiosity.","['rational-numbers', 'number-theory']"
500211,Surjectivity of a function that maps three subsets to their union,"Let $E$ be a set and $A,B,C$ three subsets of $E$.
Consider the function
$$f:\mathcal{P}(A)\times \mathcal{P}(B)\times \mathcal{P}(C)\rightarrow \mathcal{P}(E);\; (X,Y,Z)\mapsto X\cup Y\cup Z$$ I want to show that if $f$ is surjective then $E\subset A\cup B\cup C$. Let $x\in E$ then the singleton $\{x\}\in \mathcal{P}(E)$ and by surjectivity there exists 
$(X,Y,Z) \in \mathcal{P}(A)\times \mathcal{P}(B)\times \mathcal{P}(C)$ such that $  X\cup Y\cup Z=\{x\}$
Hence $X=\{x\}$ or  $Y=\{x\}$ or  $Z=\{x\}$ so $\{x\}\in \mathcal{P}(A)$ or $\{x\}\in \mathcal{P}(B)$ or $\{x\}\in \mathcal{P}(C)$ hence $x\in A$ or $x\in B$ or $x\in C$ so $x\in A\cup B\cup C$.
Is this correct? and is there any other simpler way to do this? thank you for your help!!",['elementary-set-theory']
500212,Show that ideal is a subring,"I'm experimenting around with ring ideals (perhaps ideals is always for rings, so when speaking of ideals we always refer to these ring subsets?), and my book gives me the definition that an ideal $I$ is a subset of a ring $R$, for which the elements are closed under addition and $ra\in I$ for all $r\in R$ and $a\in I$. Wikipedia say that an ideal is an additive subgroup which I clearly see, but I suspect that $I$ is also a subring to $R$. I cannot find any info on this in my book, but I tried to apply the ""subring criterion"" theorem (let $S$ be a subset of a ring $R$): (i) additive and multiplicative closures, (ii) if $a\in S \implies -a \in S$ and (iii) $S$ contains the identity. This is what I did: (i) addition follows from the definition, but for multiplication let $a,b \in I$ then for any $r_1,r_2 \in R$ we get $r_1ar_2b = (r_1ar_2)b \in I$ because $r_1ar_2 \in R$. Same argument for $a$, thus closure for multiplication. (ii) This holds from definition of a ring. (iii) $I$ is an additive subgroup hence $0\in I$. So, does my ""proof"" hold? Is it really true that an ideal is always a subring? If it is not true, ca anyone illustrate some counter example? Best regards,","['ideals', 'abstract-algebra']"
500224,Is this a recurrence for the characteristic sequence of composite numbers?,"The characteristic sequence of composite numbers is equal to 1 if $n$ is not a prime number and equal to 0 if $n$ is a prime number, starting: $$1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,...$$ where the zeros are at positions of prime numbers: $2,3,5,7,11,...$ Is this a recurrence for the characteristic sequence of composite numbers: $$t(\text{n},1)=1$$ $$t(1,\text{k})=1$$ $$t(n,k)=\text{If} \; n\geq k: 1-\prod _{i=1}^{k-1} t(n-i,k) \;\text{else}: 1-\prod _{i=1}^{n-1} t(k-i,n)$$ which is a matrix $t$ starting: $$t=\left(
\begin{array}{cccccccccccc}
 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 \\
 1 & 1 & 0 & 1 & 1 & 0 & 1 & 1 & 0 & 1 & 1 & 0 \\
 1 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 1 \\
 1 & 1 & 1 & 1 & 0 & 1 & 1 & 1 & 1 & 0 & 1 & 1 \\
 1 & 0 & 0 & 0 & 1 & 1 & 1 & 1 & 1 & 0 & 1 & 1 \\
 1 & 1 & 1 & 1 & 1 & 1 & 0 & 1 & 1 & 1 & 1 & 1 \\
 1 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0 & 1 & 1 \\
 1 & 1 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0 \\
 1 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 1 & 1 & 1 & 1 \\
 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0 & 1 \\
 1 & 0 & 0 & 1 & 1 & 1 & 1 & 1 & 0 & 1 & 1 & 1
\end{array}
\right)$$ where the main diagonal is a sequence $t(n,n)$ starting: $$t(n,n) = 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,...$$ I realize that there is multiplication by zero, and recurrence might be the wrong word. Mathematica 8: Clear[nn, t, n, k, i];
nn = 90;
t[n_, 1] = 1;
t[1, k_] = 1;
t[n_, k_] := 
  t[n, k] = 
   If[n >= k, 1 - Product[t[n - i, k], {i, 1, k - 1}], 
    1 - Product[t[k - i, n], {i, 1, n - 1}]];
Table[t[n, n], {n, 1, nn}] A simpler program for a more Riemann zeta like table is possible: Clear[t, n, k, i, nn];
nn = 105;
t[n_, k_] := 
  t[n, k] = 
   If[n == k, 1, 
    If[k == 1, 1 - Product[t[n, k + i], {i, 1, n - 1}], 
     If[Mod[n, k] == 0, t[n/k, 1], 1], 1]];
Table[t[n, 1], {n, 1, nn}] which gives a table $t$ starting: $$t = \left(
\begin{array}{cccccccccccc}
 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
 1 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
 1 & 0 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
 1 & 1 & 1 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
 1 & 1 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
 1 & 0 & 1 & 1 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
 1 & 1 & 1 & 0 & 1 & 0 & 1 & 1 & 1 & 1 & 1 & 1
\end{array}
\right)$$ Edit 5.7.2014:
Just for memory: Clear[t];
nn = 94
t[1, 1] = 1;
t[n_, k_] := 
  t[n, k] = 
   If[n == k, n*(1 - Product[t[n, k - i], {i, 1, k - 1}]), 
    If[n > k, t[n - k, k], 1]];
Table[t[n, n], {n, 1, nn}] Output: {1, 0, 0, 4, 0, 6, 0, 8, 9, 10, 0, 12, 0, 14, 15, 16, 0, 18, 0, 20, 21, 22, 0,...}","['prime-numbers', 'recurrence-relations', 'sequences-and-series']"
500234,conditional probability question from sheldon ross,"In any given year a male automobile policyholder will make a claim with probability $p_{m}$, and a female policyholder will make a claim with probability $p_{f}$, where $p_{f} \neq p_{m}$. The fraction of the policyholders that are male is $\alpha, 0 < \alpha < 1$. A policyholder is randomly chosen. If $A_{i}$ denotes the event that this policyholder will make a claim in year $i$, show that $P(A_{2}\mid A_{1}) > P(A_{1})$. It appears that $A_{2}$ and $A_{1}$ are independent events, hence I don't understand why the inequality should hold. Can anybody please help? Thanks a lot.","['probability-theory', 'probability']"
500254,Is $\mathbb{Z}[x]$ a principal ideal domain?,Is $ \mathbb{Z}[x] $ a principal ideal domain? Since the standard definition of principal ideal domain is quite difficult to use. Could you give me some equivalent conditions on whether a ring is a principal ideal domain?,"['principal-ideal-domains', 'ring-theory', 'ideals', 'abstract-algebra']"
500269,Gamma Type Integral,"I was hoping someone could help me with a question I came across recently: essentially it's a gamma type integral that your asked to evaluate/reduce: P=$\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-\frac{x^{2}}{2}-\frac{cx^{4}}{4}}dx$ where c is a constant. The way your asked to evaluate it is to reduce the integrand using a taylor expansion to order 1 for the exponential function and then use the fact that $\int_{-\infty}^{\infty}e^{-\frac{x^{2}}{2}}dx=\sqrt{2\pi}$ I can't come to any plausible solutions to this problem. I mean you could say that 
$e^{-\frac{x^{2}}{2}-\frac{cx^{4}}{4}}\approx1-\frac{x^{2}}{2}-\frac{cx^{4}}{4}+\dots$ but to order 1 this would just result in the integrand becoming 1 and this doesn't make sense? If the question said using the exponential to order 2 then the integral would evaluate to $\sqrt{2\pi}$ and thus P itself would be 1 but my thoughts are that the reduced P is wanted in terms of c? Can someone please provide some guidance or a possible way to reduce P. Thanks very much.","['integration', 'exponential-function', 'functions', 'gamma-function', 'taylor-expansion']"
500272,Definition of real projective line,"On  $\mathbb R^2-(0,0)$ we define the following equivalence relation:
Two points $(x,y)$ and $(x_0,y_0)$ in $\mathbb R^2-(0,0)$ are equivalent if there exists $a\in \mathbb R^*$ such that 
$$x=ax_0,\; y=ay_0$$ Let $D_{x_0y_0}$ be the line passing through the points $(0,0)$ and $(x_0,y_0)$.
Then the equivalence class of $(x_0,y_0)\in \mathbb R^2-(0,0)$ is the set $D_{x_0y_0}-(0,0)$. My question: I read that $\mathbb RP^1$ is the set of equivalence classes of points $(x,y)\in \mathbb R^2-(0,0)$ and this we just showed is the set of subsets $D_{xy}-(0,0)$. My question is why we say that  $\mathbb RP^1$ is the set of lines $D_{xy}$ through the origin instead of saying the set of subsets $D_{xy}-(0,0)$ ?","['general-topology', 'elementary-set-theory', 'projective-space']"
500303,How Find the $f(x)$ such $\lim_{x\to 1^{-}}\frac{\sum_{n=0}^{\infty}x^{n^2}}{f(x)}=1$,"find the value $f(x)$ such $$\lim_{x\to 1^{-}}\dfrac{\displaystyle\sum_{n=0}^{\infty}x^{n^2}}{f(x)}=1$$ This problem is china (2009College students' mathematical contest
  comption)  I have consider sometimes, and we know  we can't find this sum
$$\sum_{n=0}^{\infty}x^{n^2}$$
Thank you someone have nice methods",['limits']
500315,"Working out the normalization of $\mathbb C[X,Y]/(X^2-Y^3)$","I'm trying to identify the normalization of the ring $A := \mathbb C[X,Y]/\langle X^2-Y^3 \rangle$ with something more concrete. First, $X^2-Y^3$ is irreducible in $\mathbb C[X,Y]$, making $\langle X^2-Y^3\rangle$ prime, so $A$ is a domain and it makes sense to talk about its normalisation, i.e., its integral closure in $\mathrm{Frac}(A)$. Then, we try to understand $\mathrm{Frac}(A)$: the composite arrow
$$ \mathbb C[X,Y] \twoheadrightarrow A \hookrightarrow \mathrm{Frac}(A) $$
maps every element not in $\langle X^2-Y^3 \rangle$ to an invertible one in $\mathrm{Frac}(A)$. By the universal property of the localization, it defines an arrow $h : \mathbb C[X,Y]_{\langle X^2-Y^3\rangle} \to \mathrm{Frac}(A)$ making the following diagram commute :
$$ \begin{matrix}
\mathbb C[X,Y] & \twoheadrightarrow & A & \hookrightarrow & \mathrm{Frac}(A) \\
\downarrow &&&& \| \\
\mathbb C[X,Y]_{\langle X^2-Y^3\rangle} & &\stackrel h \longrightarrow & & \mathrm{Frac}(A).
\end{matrix}$$ The arrow $h$ is onto: for $P,Q \in \mathbb C[X,Y], Q \notin \langle X^2-Y^3 \rangle$, $h(P/Q) = \pi(P) // \pi(Q)$ (denoting '/' the fraction of the left localization, '//' the one in $\mathrm{Frac}(A)$, and $\pi \colon \mathbb C[X,Y] \twoheadrightarrow A$). Then, we have a description of the fraction field of $A$ as
$$\mathrm{Frac}(A) \simeq \mathbb C[X,Y]_{\langle X^2-Y^3\rangle} \,\big/\, \ker (h) \simeq \{P/Q \in \mathbb C(X,Y) \mid Q \notin \langle X^2-Y^3\rangle\} \,\big/\, \langle X^2 - Y^3 \rangle.$$ Am I correct so far ? If so, I'm having trouble to determine algebraic integers in this $A$-algebra. Any hint ?","['commutative-algebra', 'algebraic-geometry', 'integral-dependence']"
500325,$\displaystyle\sum_{k=0}^n \frac{\cos(k x)}{\cos^kx} = ?$,"Prove that (not use induction)
$\displaystyle\sum_{k=0}^n \frac{\cos(k x)}{\cos^kx} = \frac{1+(-1)^n}{2\cos^nx} + \dfrac{2\sin\big(\lfloor\frac{n+1}{2}\rfloor x\big) \cos\big(\lfloor\frac{n+2}{2}\rfloor x\big)} {\sin x\cos^n x} \qquad\qquad (\frac{2x}{\pi}\not\in \mathbb Z)$","['trigonometry', 'summation', 'calculus']"
500336,What is the math behind the game Spot It?,"I just purchased the game Spot It . As per this site , the structure of the game is as follows: Game has 55 round playing cards. Each card has eight randomly placed symbols. There are a total of 50 different symbols through the deck. The most fascinating feature of this game is any two cards selected will always have ONE (and only one) matching symbol to be found on both cards. Is there a formula you can use to create a derivative of this game with different numbers of symbols displayed on each card. Assuming the following variables: S = total number of symbols C = total number of cards N = number of symbols per card Can you mathematically demonstrate the minimum number of cards (C) and symbols (S) you need based on the number of symbols per card (N)?","['card-games', 'recreational-mathematics', 'combinatorics']"
500345,Difference between group homomorphism and homomorphism,What is the difference between a group homomorphism and a homomorphism?,"['group-theory', 'abstract-algebra']"
500359,How do I solve for $x$ in $\ln(x)\ln(x) = 2 +\ln(x)$,How do I solve for $x$? $$\ln(x)\ln(x) = 2 +\ln(x)$$,"['logarithms', 'algebra-precalculus']"
500432,Characterising spaces of linear recurrent sequences.,"Let $K$ be a field and $\def\N{\mathbf N}K^\N$ the infinite dimensional space of all sequences of elements of$~K$. Any linear recurrence relation of order $d$ with constant coefficients
$$
a_{i+d} = c_0a_i+c_1a_{i+1}+\cdots c_{d-1}a_{i+d-1}
  \qquad\text{for all $i\in\N$,}
$$
defines a $d$-dimensional subspace $V$ of $K^\N$. In studying these sequences one introduces the shift operator $T:(a_0,a_1,a_2,\ldots)\mapsto(a_1,a_2,a_3,\ldots)$, which defines an endomorphism of $V$, and whose (generalised) eigenspace decomposition is useful for describing linear recurrent sequences explicitly. The shift operator $T$ is actually well defined on all of $K^\N$, and can be used for instance to characterise geometric sequences as its eigenvectors. For the indicated application to linear recurrences, it is of vital importance that each space$~V$ defined by a specific recurrence relation is $T$-stable, and this is indeed always the case for the recurrence relations considered (the fact that the coefficients of the recurrence relation are constant is essential for this). Now I was just wondering if this precisely describes the finite dimensional $T$-stable subspaces of $K^\N$: If $V$ is a finite dimensional $T$-stable subspace of $K^\N$, does there exist a linear recurrence relation$~R$ of order $\dim V$ with constant coefficients such that $V$ consists of all sequences in$~K^\N$ satisfying$~R$? I think the answer should be affirmative; maybe there is some elegant way to see this easily.","['linear-algebra', 'recurrence-relations']"
500439,Gauss-Bonnet Theorem in dimension four,"I've read that the generalized Gauss-Bonnet theorem states that $$\int\limits_{M}Pf(\Omega)=(2\pi)^n\chi(M)$$ where, $M$ is a 2n-dimensional compact orientable Riemannian manifold without boundary $\Omega$ is the curvature form and $Pf(\Omega)$ is the Pfaffian of $\Omega$, $Pf(\Omega)$ is a 2n-form. How can I prove that in dimension four is valid: $$\chi(M)=\frac{1}{32\pi^2}\int\limits_M(|Rm|^2-4|Ric|^2+R^2)\,d\mu$$ where, $Rm$ is the Riemannian curvature tensor, $Ric$ is the Ricci curvature tensor ans $R$ is then scalar curvature. Tahnks in advice.","['differential-topology', 'pfaffian', 'riemannian-geometry', 'differential-geometry']"
500441,"Prove that $k[x,y,z,w]/(xy-zw)$, the coordinate ring of $V(xy-zw) \subset \mathbb{A}^4$, is not a unique factorization domain","I want to show that $k[x,y,z,w]/(xy-zw)$, the coordinate ring of $V(xy-zw)\subset\mathbb{A}^4$, is not a unique factorization domain. Morally, all we need to do is find some nonzero element that can be written in two distinct ways as a product of irreducible elements, but nothing is coming to mind immediately. Thoughts?","['commutative-algebra', 'algebraic-geometry', 'unique-factorization-domains', 'abstract-algebra']"
500442,On the roots of $t^4-6\sqrt3t^3+8t^2+2\sqrt3t-1=0$,"The Problem Prove that $\tan \frac{\pi}{15}$ is a root of the equation $t^4-6\sqrt3t^3+8t^2+2\sqrt3t-1=0$, and find the other roots. Source: Question 17 from the complex numbers chapter from Bostock's Further Pure Mathematics Thoughts Using the identity $\tan 5\theta =\frac{5\tan\theta-10\tan^3\theta-\tan^5\theta}{1-10\tan^2\theta+5\tan^4\theta}$, I can show that $\tan \frac{\pi}{15}$ is a root of $t^5+5\sqrt3t^4+10t^3-10\sqrt3t^2-5t+\sqrt3=0$, but it isn't clear how to proceed. Alternatively, I can derive and use a formula for $\tan 4\theta$ to obtain a quartic equation as desired, but that will require me to find $\tan \frac{4\pi}{15}$ which I cannot. I suspect this is not difficult though I can't see how to proceed. Hints would be appreciated.",['trigonometry']
500450,Determine the stability property of the critical point at the origin ($x=y=0$) for the following system.,"Determine the stability property of the critical point at the origin ($x=y=0$) for the following system: I have an example:
$$\begin{cases}
 & \mathrm{  } \dot{x}= \tan(y-x)\\ 
 & \mathrm{  } \dot{y}= 2^y-2\cos(\dfrac{\pi}{3}-x)
\end{cases} \tag{1}$$ I use the matrix $A=\dfrac{\partial F}{\partial x}\mid_{x=0}$ then we have 
$$A=\begin{pmatrix}
 & -1&1\\ 
 & -\sqrt{3}&\ln 2
\end{pmatrix}$$ where $\tan(y-x)\approx y-x$ Since $\det(A-\lambda I)=0$ implies the equation:
$$\lambda^2+(1-\ln 2)\lambda+\sqrt{3}-\ln 2=0$$ We have $a_1=1-\ln 2>0$ and $a_0=\sqrt{3}-\ln 2>0$. By The Hurwitz criterion, $x \equiv 0$  is Asymptotically Stable. ================================================ I have a problem: Determine the stability property of $x=y=0$? a/ $$\begin{cases}
 & \mathrm{  } \dot{x}= e^{x+2y}-\cos 3x\\ 
 & \mathrm{  } \dot{y}= 2\sqrt{1+2x}-2e^y
\end{cases} \tag{a}$$ b/ $$\begin{cases}
 & \mathrm{  } \dot{x}= -3x+4y+\sin^3x -y^2\\ 
 & \mathrm{  } \dot{y}= -2x+\sin y+e^yx^2
\end{cases} \tag{b}$$ Any help will be appreciated. Thanks!","['dynamical-systems', 'control-theory', 'ordinary-differential-equations']"
500456,How to calculate this complex integral $\int_0^\infty \frac{1}{q+i}e^{-(q+b)^2}\text{d}q$? (Please Help),"I want to carry out the following integration $$\int_0^\infty  \frac{1}{q+i}e^{-(q+b)^2}\text{d}q$$ which is trivial if calculated numerically with any value for b. But I really need to get an analytic expression for this integral. I would really appreciate it if you can help with this integral. Or if you can tell it's not possible to carry it out analytically, that is also helpful. Thanks in advance Huijie","['complex-integration', 'integration', 'complex-analysis']"
500466,What is the solution for $u(x)=x+\int_0^x (t-x)u(t)dt$,"So I am studying for the GRE right now and came across the problem from one of the UCLA's workshops online. The problem is stated as, Which of the following is the solution of
$u(x)=x+\int_0^x (t-x)u(t)dt$ (a) $\sin(x)$ (b) $x\cos(x)$ (c) $\ln(1+x)$ (d) $xe^{-x}$ (e) $xe^x$ The answer is (a). My intial appraoch was to take derivatives of both sides, apply FTC and then solve the DE. But my problem is that I am not sure how to take the derivative of the integral since it contains an $x$ term in it. Can someone work out the problem, or offer a hint? Thanks in advanced.","['ordinary-differential-equations', 'calculus']"
500470,Prove that these two angles are equal,"An inner circle touches the outer one at point P. BC is any chord of the inner circle, which when extended, cuts the outer circle at points A and D. That is, the line segment ABCD is a chord of the outer circle. Prove that $\angle APB = \angle DPC$. I've attached a (fancy) drawing of the problem. I extended PB and PC to cut the outer circle at E and F respectively. It feels like $\triangle PAE \sim \triangle PDF$ (it would suffice for the proof), but I've been unable to prove so. This is my progress: $\angle PEA = \angle PDA = \angle PDC$ (same chord PA subtends equal angles on same side of circumference) $\angle PAD = \angle PAB = \angle PFD$ (chord PD) And this is where I'm stuck. :(",['geometry']
500481,Weak convergence of measures on a discrete probability space,"What follows are two different question on weak convergence on a discretization of a probability space and applying some standard probability theory on such a discretization. Let $(\Omega:=\mathbb{R}_+^d,\mathcal{F}_T)$, $T\in \mathbb{N}$ be a measurable space. We have the canonical processes $X_l(\omega)=\omega_l$, where $\omega\in\Omega$ and $\omega_l$ is the $l$-th coordinate. The time parameter for the processes $X$ is $\{0,\dots,T\}$. The filtration $\mathcal{F}_l$ is generated by $X_0,\dots,X_l$. We discretize our space, i.e. we let $A_n:=\{\delta k,k=0,\dots\}$ for $\delta = \frac{1}{n}$ and look at $\Omega_n:=A_n^d\subset\Omega$. My first question is of very general nature. Suppose we are given probability measure $\mu_n$ on $\Omega_n$. Note we didn't specify the $\sigma$-algebra on $\Omega_n$, so please motivate your choice. How can we say that $\{\mu_n\}$ is tight, since they are not defined on the same space. Assuming they are tight, we want to apply Prohorov's theorem to conclude that $\mu_n$ converges weakly to $\mu$ on a subsequence, where $\mu$ should be a probability measure on $\Omega$. Again how can we talk about weak convergence, if the measures are defined on different spaces? Suppose we are allowed to do the above. 
Let $g$ be a continuous function with $g(x)\le K(1+x^r)$ for some $r>1$  and a constant $K$. We denote with $f_n$ the restriction of $g$ onto $A_n$ and $g_n$ the linear interpolation of $f_n$. Let's assume that $$\sup_{x\in A_n}\{\frac{|f_n(x)|}{(1+x)^r}\}\le n $$ We clearly have that $g_n$ converges pointwise to $g$. By continuity of $g$ we also have $g(x)=\lim f_n(x_n)$ for any sequence $x_n\to x$. 
We want to make use of the Skorohod representation theorem, in fact we want to establish the following equality $$ E_\mu[g(X_k)]=\lim E_{\mu_n}[f_n(X_k)] $$ The second question is, why is the above equality true? Thanks in advance for the help","['probability-theory', 'measure-theory']"
500499,Complement of a line in $\mathbb{A}^2$ as an algebraic variety,"I just started reading notes from an algebraic geometry course, and I'm curious about whether the complement of a line in $\mathbb{A}^2$ is always an algebraic variety. If so, what does it's coordinate ring look like. On a side note, does this in any way generalize to higher dimensions? I.e., what properties does the complement of a hyperplane have in $\mathbb{A}^n$?","['affine-geometry', 'algebraic-geometry']"
500505,Proof of the finite number of Bravais lattices?,"I've been taught that there are a finite number of Bravais lattices in 1, 2 and 3 dimensions. I am wondering if there is a proof of this fact. Maybe this is obvious and I am only missing certain key assumptions that are made in setting the problem?","['geometry', 'integer-lattices', 'linear-algebra']"
500511,Dimension of the sum of two vector subspaces,"$\dim(U_1+U_2) = \dim U_1 +\dim U_2 - \dim(U_1\cap U_2).$ I want to make sure that my intuition is correct. Suppose we have two planes $U_1,U_2$ though the origin in $\mathbb{R^3}$. Since the planes meet at the origin, they also intersect, which in this case is a one-dimensional line in $\mathbb{R^3}$. To obtain the dimension of $U_1$ and $U_2$, we add the dimensions of the planes (4), and the subtract the dimensions of the line (1), which results in (3). *additional question(s): Can we generalize this notion to $\mathbb{F^{n}}$? Suppose we have an additional case where $U_1$ and $U_2$ are planes in $\mathbb{R^3}$, but $U_1 \subseteq U_2$. In this instance, $dim(U_1 + U_2) < 3$, because the first two-dimensional plane is contained in the second and as a result, the dimensions of the subspaces when summed cannot exceed two. Since both subspaces $U_1,U_2$ are two dimensional and $U_1 \subseteq U_2$, then their intersection is also two-dimensional, concluding $dim(U_1+U_2)=2+2-2 = 2$. Is this proper intuition?",['linear-algebra']
