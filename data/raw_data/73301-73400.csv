question_id,title,body,tags
903332,When is a polynomial map proper?,"Let $f\in \mathbb C[x_1,\dots,x_d]$ be a (nonconstant) polynomial. Of course it can be viewed as a (surjective) regular map $$\tilde f:\mathbb A^d_\mathbb C\to \mathbb A^1_\mathbb C.$$ Question . When is $\tilde f$ proper? The map $\tilde f$ being finite type and separated, the question asks: when is $\tilde f$ universally closed? When is it such? Can one say anything through the valuative criterion?",['algebraic-geometry']
903346,Is Cauchy's formula apt for evaluating this integral,"I'm trying to evaluate the following.
$$\frac{1}{2i}\int_{-\infty}^\infty \frac{s \sin{(sr)}}{(s-k)(s+k)}\mathrm{d}s,$$
with $k$ and $r$ being real constants. The integral could be written as
$$\int_{-\infty}^\infty \frac{s e^{isr}}{(s-k)(s+k)}\mathrm{d}s-\int_{-\infty}^\infty \frac{s e^{-isr}}{(s-k)(s+k)}\mathrm{d}s,$$
which makes it nicer, as it looks appropriate to use Cauchy's integral formula.
But the problem I have is that the poles lie right on the real interval, so is it possible to exploit Cauchy's formula in such a case?","['improper-integrals', 'complex-analysis']"
903360,Integral ring extensions and finitely generated as a module,"Let $A \subset B \subset C $ be rings. Suppose that $A$ is Noetherian and $C$ is finitely generated as an $A$-algebra. I want to show that $C$ is finitely generated as a $B$-module $ \iff $ $C$ is integral over $B$. I have the following propositions: Proposition 5.1: The following are equivalent for rings B $\subset$ C i) $x \in C $ is integral over B ii) B[x] is a finitely generated B-module iii) B[x] is contained in a subring C' of C at C is a finitely generated B-module Corollary 5.3 Let $x_1, ... x_n \in C $ be integral over B. Then the ring $B[x_1, ... x_n] $ is a finitely-generated B-module.","['ring-theory', 'abstract-algebra', 'noetherian']"
903365,Show that it is an algebra.,"This excercise is a little struggling for me. The part I need help with is showing that $D$ is closed under complements. Let $C$ denote the collection of all intervals on $\mathbb{R}$, including degenerate intervals of the form $[a,a]$ and $(a,a)$. And let $D$ be the collection of finite disjoint unions of members of $C$. Prove that $D$ is an algebra. Hint: First show that $D$ is closed under intersection and then under complementation. Now, here is my attempt to show it is closed under complementation. Let $A \in D$. Then $A = A_1\cup A_2....\cup A_{N_A}$. Where each $A_i$ is an interval, and all of them are disjoint. We have that $A^C=A_1^C\cap A_2^C....\cap A_{N_A}^C$.  But I need to show that $A^C$ is a finite union of disjoint intervals. I can see it drawing that it must be so, because if we have $N_A$ original intervals we can see that the remaining part of $\mathbb{R}$ also must be disjoint intervals. But is this enough of a mathematical proof?","['general-topology', 'elementary-set-theory', 'real-analysis']"
903368,Ellipse like on sphere,"Find the locus of all points on a sphere such that the sum of  geodesic distances from two fixed points $F_1$ and $F_2$ on it is a constant, less than its diameter. ( When radius of sphere goes to infinity, it would look like an ellipse). Following is image after Equn  ($1$) in achille hui note",['geometry']
903382,What advanced methods in contour integration are there?,"It is well known how to evaluate a definite integral like
$$
\int_{0}^\infty dx\, R(x),
$$
where $R$ is a rational function, using contour integration around a semicircle or a keyhole.
Most complex analysis books only treat well-known and easy examples like this. What I am looking for is examples of integrals that can be evaluated using contour integration, but require more creative tricks, unusual contours, etc. and are not treated in common textbooks. Useful answers are applicable not just to one integral, but are somewhat general. Needless to say, answers do not have to include the full computation to be useful.","['definite-integrals', 'big-list', 'complex-analysis', 'contour-integration']"
903425,Eliminating parameter to get Cartesian equation,$x = \sin(t/2)$ $y = \cos(t/2)$ $-\pi \le t \le \pi$ How would I go about getting the Cartesian equation of these?,"['trigonometry', 'calculus']"
903438,Forcing series convergence,"I am trying to figure this out: $\mathscr{S}=\big\{(a_n),(b_n),\dots \big\}$ is a finite set of real, null sequences. Does there exist a sequence $(\epsilon_n)$ , where $\epsilon_k=\pm 1$ for each $k$ , such that: $$\forall\;(x_n)\in\mathscr{S}:\quad \sum_n \epsilon_n x_n<\infty\;?$$ A special case of this problem was posed by one of my lecturers: does every null sequence in $\mathbb{C}$ admit a sequence $(\epsilon_n)$ of signs such that $\sum\epsilon_nz_n$ converges? The answer is yes. We can always choose signs so that $|\epsilon_1z_1+\cdots\epsilon_nz_n|\leq \sqrt{3}$ for all $n$ , with some assumptions on $|z_n|$ . The geometric nature of the proof prevents me from generalising though. Any ideas how to deal with the general case?","['convergence-divergence', 'sequences-and-series', 'real-analysis', 'analysis']"
903440,Why is the integral of any orientation form over $\mathbb{S}^1$ non zero?,"I am trying to understand the proof of Theorem 17.21 in Lee's Introduction to smooth manifolds; however I am finding myself stuck right at the beginning. The statement I am having trouble with is:
""For $n=1$, note first that any orientation form on $\mathbb{S}^1$ has non-zero integral."" Lee defines an orientation form as a non-vanishing $n$-form on an $n$-dimensional manifold. I can understand why it is not necessarily zero as the circle is not contractible; however I am having trouble seeing why it can't be zero in any case. My attempts at a solution don't seems to be leading me in the right direction; however, I have considered using stokes theorem and the fact that the circle is the boundary of a closed ball and I having considered saying: if the integral is zero I can break the circle into two pieces, which means the integral along the two pieces have to be equal. Is there some way to use this to show that the $1$-form can be zero nowhere? Any advice is much appreciated :)","['integration', 'differential-geometry']"
903448,Proving that homotopic maps have the same degree,"Let $M, N$ be compact, connected, oriented manifolds. The degree of a map $f:M \rightarrow N$ is defined as the integer $k$ which satisfies $\int_{M} f^{*}\omega  = k\int_{N}\omega$. Using the fact that homotopic maps, say $f, g$ induce the same map on the De Rham cohomology, we have $\int_{M} f^{*}\omega - \int_{M} g^{*}\omega = \int_{} d\nu$ for $\nu$ some $n-1$ form. Now if the manifold has empty boundary, we can use Stokes's theorem to conclude that this equals 0. However, what about when the manifold does not have empty boundary? A proof that I found relies on the fact that if you have a homotopy $H(x,t)$ then $t \mapsto H_{t}^{*}\omega$ is continuous, and then using the continuity of the integral, concluding that (since the degree is always an integer), $k(t)=\frac{\int_{M}H_{t}^{*}\omega}{\int_{N}\omega}$is also continuous, hence constant. 
    Is there any other way of proving this?","['algebraic-topology', 'differential-geometry']"
903464,Convergence of $\sum \frac{1}{\ln n}(\sqrt{n+1} - \sqrt{n})$,"Show that 
$$ \sum\frac{1}{\ln n}(\sqrt{n+1} - \sqrt{n})$$ Converges. I've tried the telescopic property or even write it as $$\sum \frac{1}{\ln n (\sqrt{n+1}+\sqrt{n})}$$ But didnt help. Thanks in advance!",['sequences-and-series']
903476,How to find the domain and range of $f(x) = \sqrt{x^2-2x+5}$?,"This is the function: $$f(x) = \sqrt{x^2-2x+5}$$ Edit: normally what I would do is this: Since it's a square root function, the thing inside the root has to be $\ge 0$. So, $(x^2 - 2x+5)\ge 0$. Then I would factor the stuff in the brackets so that I get ( ) (__ ). But since this has complex roots, I don't know what to do Edit: Thanks for the help with the domain! For the range, I found the inverse of the function and did this: $$x = \sqrt{(y-1)^2 +4}$$ 
$$x^2 -4 = (y-1)^2 $$
$$\sqrt{x^2 -4}+1 = y$$ And then proceeded to find the domain of the inverse: $$x^2 -4 \ge 0$$
$$x^2 \ge 4$$
$$x \ge  +-2$$ Is this correct? How do I know if it is correct without graphing it out?","['algebra-precalculus', 'functions']"
903481,$n$th derivative of $f(x)$ using limit definition,"After playing around with the limit definition of the derivative for higher order derivatives, I noticed the following odd relationship to determine it for an nth order derivative: Let $F^n=f(x+nh)$ (is there a way to write this properly as an operator on $f(x)$?), then $$f^{(n)}(x)=\lim_{h\to0}\frac{(F-1)^n}{h^n}=\left(\lim_{h\to0} \frac{F-1}{h}\right)^n$$ Expanding the middle equality gives it in terms of $f(x+nh)$s. Notice that the inside of the bracket on the RHS is equal to $f'(x)$ (sort of). I have actually proven that this is indeed true using repeated use of L'Hopital's law and proof by induction, but I am unsatisfied. The result in the form above seems almost magical, and makes me think there is a very elegant reason why. Can someone explain why? Based on the result, I suspect umbral calculus gives a nice explanation, but I do not know a lot about it.  So can someone explain why the above has such an elegant form? NOTE : I realise that this is similar to this question , but that question is asking about if it's true; I already know it's true, but I'm asking why it's true based on the magical form above. Also, I don't care that this evaluates certain derivatives that shouldn't exist (but does correctly evaluate those that do), so do not worry about that.","['calculus', 'operator-theory', 'derivatives', 'limits']"
903484,Dual norm intuition,"The dual of a norm $\|\cdot \|$ is defined as: $$\|z\|_* = \sup \{ z^Tx \text{ } | \text{ } \|x\| \le 1\}$$ Could anybody give me an intuition of this concept? I know the definition, I am using it to solve problems, but in reality I still lack intuitive understanding of it.","['normed-spaces', 'convex-analysis', 'functional-analysis']"
903492,I need compute a rational limit that involves roots,"I need compute the result of this limit without l'hopital's rule, I tried different techniques but I did not get the limit, which is 1/32, I would appreciate if somebody help me. Thanks. $$\lim_{y\to32}\frac{\sqrt[5]{y^2} - 3\sqrt[5]{y} + 2}{y - 4\sqrt[5]{y^3}}$$","['calculus', 'limits']"
903504,Sum of an unorthodox infinite series,"$ \frac{1}{2^1}+\frac{3}{2^2}+\frac{5}{2^3}+\frac{7}{2^4}+\cdots $ This is a pretty unorthodox problem, and I'm not quite sure how to simplify it.  Could I get a solution?  Thanks.","['sequences-and-series', 'number-theory']"
903528,Rate Of Change Of Shadow,"A spotlight on the ground shines on a building $12m$ away. If a man $2m$ tall walks from the spotlight towards the building at a speed of $1.6m/s$, how fast is the length of his shadow on the building decreasing when he is $4m$ from the building? This is my diagram of the scenario: Please have a look at my solution and confirm if correct and if not, give me a hint as to what I'm doing wrong. $H =$ height of the shadow on the building $h = $height of the man $X = $distance from building to the man $x = $distance from spotlight to the man From the diagram $x + X = 12, $ and $h = 2$ $x(t) = 1.6t$, with $t$ in $seconds$. $\frac{dx}{dt} = 1.6$ By similar triangles: $\frac{h}{H} = \frac{x}{x+X} \Leftrightarrow H = \frac{(x+X)h}{x} = \frac{(12)(2)}{x} = \frac{24}{x}$ $\Rightarrow \frac{dH}{dt} = \frac{d}{dt}(\frac{24}{x})  = -\frac{24}{x^2}\frac{dx}{dt}$ When the man is $4m$ from the building, $x = 12 - 4=8 \Rightarrow \frac{dH}{dt}  = -\frac{24}{8^2}(1.6) = -\frac{3}{5}m/s$",['calculus']
903532,Number of channels required to provide access to subscribers 80% of the time,"A multichannel microwave link is to provide telephone communicationto a remote community having 12 subscribers, each of whom uses the link 20% of the time during peak hours. How many channels are needed to make the link available during peak hours to: a. Eighty percent of the subscribers all of the time? b. All of the subscribers 80% of the time? For the a) part I came up with answer 10 channels which is correct according to my TA but I am not sure about the procedure I followed (I just found out what is eighty percent of 12) I have no clue what b part means",['statistics']
903554,First order ODE: $y^2+2yy'x+2xy'+y=0$,"$$y^2+2yy'x+2xy'+y=0$$
I really have no idea how to do this, I cant fit it into any of the schemes I already know. Also nothing factors out. Maybe should I try differentiating both sides?",['ordinary-differential-equations']
903573,Initial value problem for 2nd order ODE $y''+ 4y = 8x$,How can I go about solving this equation $y''+ 4y = 8x$ ? Progress I found  the general solution for its homogeneous form. What I don't know is how to find its particular solution.,"['ordinary-differential-equations', 'calculus']"
903593,Sum of Catalan numbers,"What is $C_1 +C_2 + C_3 +... + C_n$, where each $C_i$ is Catalan number? 
I want to know if we can bound this sum by some function of $n$. I am looking for an upper bound.
For sure it is less than $2^{2n}$.
Can we say it is less than $2^{\log_2(2n)}=2n$?","['catalan-numbers', 'combinatorics']"
903596,Filtration from a Brownian Motion,"The textbook I am reading defines the filtration induced from a Brownian Motion as follows. Let $\{B(t): t \geq 0\}$ be a Brownian Motion defined on some probability space, then we can define a filtration $(\mathcal F^0(t): t\geq0)$ by letting $$
\mathcal F^0(t) := \sigma(B(s): 0\leq s\leq t)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  (*)
$$ be the $\sigma$-algebra generated by the random variables $B(s)$ for $0 \leq s\leq t$. My question is whether I can understand the above definition $(*)$ as follows. \begin{equation}
\mathcal F^0(t) := \sigma(B(s): 0\leq s\leq t) = \sigma\left(\cup_{0\leq s\leq t} \sigma(B(s))\right).
\end{equation} Thank you!","['measure-theory', 'self-learning', 'probability-theory', 'brownian-motion', 'probability']"
903599,Can the winding number be infinite?,"Let $z$ be a point in the complex plane, and $\gamma$ be a closed curve. Is it possible that 
$$n(\gamma,z) =  \frac{1}{2\pi i}\int_\gamma \frac{dw}{w-z}$$
becomes unbounded? In other words, is it possible to find a curve $\gamma$ such that it winds around a fixed point infinitely many times?",['complex-analysis']
903633,Openness of a subset in complex 2-plane,"Let   $U$ be a subset of $\mathbb{C}^{2}$ containing the origin $0$.  Assume that for  any curve $C$ (an affine variety of dimension 1, maybe singular) passing through $0$ we have $U \cap C$ is Zariski open in $C$. Is $U$  Zariski open in $\mathbb{C}^{2}$? Or at least, is there a Zariski neighborhood $V$ of $0$ with $V\subset U$?  Thanks!","['general-topology', 'algebraic-geometry', 'several-complex-variables']"
903643,What is the mathamatical term for this programming concept?,"In python's itertools, there is a function called permutations. It returns the number of ways to arrange x number of variables into a given space. For example, permutations(""ABC"", 2) == [('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'C'), ('C', 'A'), ('C', 'B')] The first argument is the number of variables, and the second is the size of each group. This concept is similar to factorial, but you don't use every variable in each group. Side question: Is there a mathematical term for all of the differnt permuation size added up all the way to factorial, e.g, permutations(""ABC"", 1)+permutations(""ABC"", 2)+permutations(""ABC"", 3) Sorry if this is a silly question. I am just a HS student.","['factorial', 'computer-science', 'terminology', 'combinatorics']"
903645,Existence of a Set Function Axiom of Choice,"I have the following problem. Let $A$ be a set and $B\neq\emptyset$ be a proper subset. Prove the existence of a function $f:A\to A$ such that $f\circ f=f$ and $\text{im}~f=B$. In the case where $A$ is finite, it suffices to pick a point of $B$, say $x$, and define $f(A)=\{x\}$ while $f_{|B}=\text{id}_{B\to B}$. If $A$ is infinite, I do not know if this argument carries over, as I am very unfamiliar with all possible uses of Axiom of Choice. Thanks for any advice!","['elementary-set-theory', 'axiom-of-choice']"
903649,Does my proof of $|x+y| \le |x| + |y|$ make sense? How do I conclude a proof?,"Thank you for reading it. I know I made a lot of mistakes. This is my first ever proof that I have attempted. Another note is that I only have been studying proofs for about a week. Any advice will be helpful. prove: $|x+y| ≤ |x| + |y|$ Case 1: ∀ values of x<0 and y<0, the function will decrease: 
$|x+y| \overset{x<0}= |y\pm x|$ $|x+y| \overset{y<0}= |-y+x)|$ $A=|-x+y|$ –-—-> $∂A/∂X=-1$ $B=|-y+x|$           $∂B/∂Y=-1$ Case 2: In the case of (x,y)>0, the two functions opposite of the inequalities are equal. {|x+y|⇔ |x|+|y|: x>0 and y>0} This is a normal property of the absolute value theorem. Notation: {|x+y|∀ values of x and y = |x|+|y| ∀ for all values of x and y} Case 3: Case 3 proves that the values of |x|+|y| are unaffected by values less than zero $|x| = 
\begin{cases}
x,&\text{if }x\ge 0\\
-x,&\text{if }x<0
\end{cases}$ $|y| = 
\begin{cases}
y,&\text{if }y\ge 0\\
-y&\text{if }y<0
\end{cases}$ ⇔$|X|+|y|>0$ when $(x,y)≠0$ Note: I don’t know if I properly stated the ∀correctly; however, I meant it as “for all“ Thank you for reading it. I know I made a lot of mistakes. This is my first ever proof that I have attempted. Another note is that I only have been studying proofs for about a week. Any advice will be helpful. ***Edited","['absolute-value', 'inequality', 'proof-verification', 'derivatives']"
903666,Cardinal Arithmetic and a permutation function.,"I am working on the following problem and am having difficulties getting started: We define a permutation of $K$ to be any one-to-one function from $K$ onto $K$. We can then define the factorial operation on cardinal numbers by the equation $K!$ =  card$\{f \ | \ f$ is a permutation of $K\}$, where $K$ is any set of cardinality $\kappa$. We show that $\kappa !$ is well defined, i.e., the value of $\kappa !$ is independent of just which set $K$ is chosen. The idea I have so far is to try the following. Let $|K_0| = \kappa$ and $|K_1| = \kappa$, where $K_0 \neq K_1$ and are arbitrary sets. We show that $K_0! = K_1! = \kappa !$. To do this, we must demonstrate a bijection between $K_0!$ and $K_1!$. That is, we must construct a bijective function $f: K_0 \rightarrow K_1$. Any advice would be appreciated. Thank you in advance.","['permutations', 'cardinals', 'elementary-set-theory']"
903676,$\lim_{N\to \infty} \sum_{n=N}^{2N} c_n = 0$ $\Rightarrow \sum_{n=1}^{\infty} c_n$ converges?,"If $\lim_{N\to \infty} \sum_{n=N}^{2N} c_n = 0$ do we have that $\sum_{n=1}^{\infty} c_n$ converges? At first this did not seem true($\sum_{n=N}^{2N} (-1)^n$ is $0$ when N is odd), but I've failed to find a proper counter-example. I've tried thinking in terms of partial sums to prove that is it true but have had no luck. Can someone help?",['sequences-and-series']
903687,A non-UFD such that $a^2 \mid b^2$ does not lead to $a\mid b$,"Is there any non-UFD that is a commutative ring such that $a^2 \mid b^2$ does not always lead to $a\mid b$? It would be preferable if examples are something that does not involve monomials/polynomials, and there are some integer parts in the non-UFD (for example, gaussian integers have integer parts, though gaussian integer is UFD).","['examples-counterexamples', 'divisibility', 'number-theory', 'ring-theory', 'abstract-algebra']"
903694,Folland's proof of the Hahn Decomposition. Minor error?,"Theorem 3.3 of Folland's Real Analysis (ed 2) is the Hahn decomposition theorem. In the proof he assumes that the signed measure $\nu$ he is considering does not take the value $-\infty$. Then he argues: Let $m$ be the supremum of $\nu(E)$ as $E$ ranges over all positive
  sets; thus there is a sequence $\{P_j\}$ of positive sets such that
  $\nu(P_j) \to m$. Let $P = \cup_1^\infty P_j$. By Lemma 3.2 and
  Proposition 3.1, $P$ is positive and $\nu(P)=m$; in particular, $m < \infty.$ The justification for the claim that $m<\infty$ is not clear to me. Could it be the case that Folland wanted to assume that $\nu$ does not take on the value $\infty$ in which case I think that the rest of the proof would work. Or am I missing something?","['measure-theory', 'real-analysis']"
903707,Sheaf of sections vanishing at a point is $\Gamma(E) \otimes I_p$,"Notation: $E$ is a vector bundle with sheaf of sections $\Gamma(E)$. $I_p$ is the sheaf of regular functions on the base space vanishing at a point $p$. $\Gamma_p(E)$ is the sheaf of sections of $E$ which vanish at a point $p$. Is it true that $\Gamma_p(E) \simeq \Gamma(E) \otimes I_p$? How about in the case where the base space is an algebraic curve? I tried to define a map $I_p\otimes \Gamma(E) \rightarrow \Gamma_p(E)$ by $f\otimes s \mapsto fs$ but it's not clear to me that it's an isomorphism. I also tried seeing $\Gamma_p(E)$ as the kernel of the evaluation map $\Gamma(E) \rightarrow E$. The resulting quotient is a skyscraper sheaf supported at $p$, right? Does that mean anything? Context: I'm looking through a proof of Grothendieck's Splitting Theorem, in C. Okonek's book Vector Bundles on Complex Projective Spaces . The base space is $\mathbb{P}^1$, and he has a global section $s$ with $s(p)=0$. He  claims that $s$ ""is"" in $H^0(\Gamma(E)\otimes I_p)$. Note that in this case, $I_p \simeq \mathcal{O}(-1)$, which maybe makes a difference.","['sheaf-theory', 'algebraic-geometry', 'vector-bundles']"
903727,"If each uncountable set $T$ has a countable subset, can we form $T$ by a union of countable subsets?","I was working my way through the set theory chapter in my Analysis textbook when I stumbled across these two theorems: Every infinite set has a countable subset A union of countable subsets is countable My question is: Given an uncountable set $T$, can we partition it into a collection of countable subsets $C_1, C_2, ..., C_n$ such that $$\bigcup_{i=1}^n C_i = T$$
implying that $T$ is countable by Theorem 2? Now, obviously, the answer is no. But why?","['elementary-set-theory', 'analysis']"
903834,Geometry problem involving infinite number of circles,What is the sum of the areas of the grey circles? I have not made any progress so far.,"['geometry', 'sequences-and-series', 'circles']"
903875,"Evaluating the limits $\lim_{(x,y)\to(\infty,\infty)}\frac{2x-y}{x^2-xy+y^2}$ and $\lim_{(x,y)\to(\infty,8)}(1+\frac{1}{3x})^\frac{x^2}{x+y}$","I got the following problem: Evaluate the following limits or show that it does not exist: $$\lim_{(x,y)\to(\infty,\infty)}\frac{2x-y}{x^2-xy+y^2}$$ and $$\lim_{(x,y)\to(\infty,8)}\left(1+\frac{1}{3x}\right)^\frac{x^2}{x+y}$$ I tried for an hour and half evaluating each of those limits but I failed and I got nothing useful to share. Some hints will be appreciated.
Thanks.","['multivariable-calculus', 'calculus', 'limits']"
903892,A counter example of Brownian Motion,"Here is an example in my textbook to illustrate why we need the continuous sample path in the definition of Brownian motion. Let $(B_t)$ be a Brownian motion and $U$ be a uniform random variable on $[0,1]$. Define $(\tilde B_t)$ by $$
\tilde B_t = \begin{cases} B_t & \mbox{if } t\neq U, \\ 0 & \mbox{if } t = U. \end{cases} 
$$ Then it is claimed that $\tilde B_t$ has the same finite-dimensional distribution as $B_t$ but with discontinuous sample path if $B(U)\neq 0$. I do not understand this example. To be more specific, What does it mean by $t \neq U$ or $t=U$, please? Here, $t$ is a deterministic time and $U$ is a random variable. How can we talk about whether the two are equal or not? Since I do not get the definition of $\tilde B_t$, I cannot see why it has the same finite dimensional distribution and discontinuous sample path. Could anyone explain this with more detail, please? Thank you!","['measure-theory', 'self-learning', 'probability-theory', 'brownian-motion', 'probability']"
903893,Finding an analytic function such that real part is the given function.,"I am reading the book Complex Analysis by Lars V Ahlfors. In the book he uses a nice method without involving integration to evaluate $f$ given that the real part of the function is $U$. The method is as follows: The conjugate function $\overline {f(z)}$ has the derivative zero with respect to $z$ and we may therefore consider it as a function of $\overline z$. Call this function $g(\overline z)$.$$u(x,y)=\frac{1}{2}[f(x+iy)+g(x-iy)]$$
If we substitute $x=z/2,y=z/2i$, we obtain$$u(z/2,z/2i)=\frac{1}{2}[f(z)+g(0)]$$ Here in this he assumes he can substitute complex values for $x$ and $y$. So I want to prove that the function $f$ obtained as above is analytic and has the real part as $u(x,y)$. I concluded that since the function $f=2u(z/2,z/2i)+c$ is not a function of $\overline z$, if $u(x,y)$ is rational function then $f $ so derived will be analytic except at poles.  But now I am unable to show that $u(x,y)$ is the real part of the function $f$. If anyone can help in solving this it would be great. Thanks.","['proof-verification', 'complex-analysis']"
903928,Test the convergence of a series,"To test the convergence of a series: $$
\sum\left[\sqrt[3]{n^3+1}-n\right]
$$ My attempt: Take out $n$ in common: $\displaystyle\sum\left[n\left(\sqrt[3]{1+\frac{1}{n^3}}-1\right)\right]$. So this should be divergent. But, the given answer says its convergent.",['sequences-and-series']
903961,Proving that three events are mutually independent,"Suppose that: the events $A$ and $B\cap C$ are independent. the events $B$ and $A\cap C$ are independent. the events $C$ and $A\cap B$ are independent. the events $A$ and $B\cup C$ are independent. $P(A),P(B),P(C)$ are nonzero. Prove that $A,B,C$ are mutually independent. I've noticed that $P(A\cap B \cap C)=P(A)P(B\cap C)=P(B)P(A\cap C)=P(C)P(A\cap B)$ . What then? I'm new to probability, and I may be missing some standard trick...","['probability-theory', 'probability']"
903966,If $x^n=y^n$ and $n$ is odd then $x=y$,"Here, we suppose that $x,y\in\mathbb{R}$ and that $x^n=y^n$, where $n$ is odd. I want to prove that $x=y$. Maybe we can use that $x^n-y^n=(x-y)(x^{n-1}+x^{n-2}y+...+xy^{n-2}+y^{n-1})$ So, it suffices to show that if $x^n=y^n$ then $x^{n-1}+x^{n-2}y+...+xy^{n-2}+y^{n-1}\neq 0$ Any hint?",['algebra-precalculus']
903973,The Cantor set is not strong measure zero,"$A \subseteq \mathbb R$ is strong measure zero if given any sequence $( \epsilon_n )_{n \in \mathbb N}$ of positive reals there is a sequence $( I_n )_{n \in \mathbb N}$ of open intervals such that $I_n$ has length at most $\epsilon_n$ for each $n$, and $A \subseteq \bigcup_{n \in \mathbb N} I_n$. I have read that the Cantor set is an example of a null set which is not strong measure zero. Can anyone explain why or direct me to a reference which contains a proof?","['general-topology', 'descriptive-set-theory', 'cantor-set']"
904008,Differences between large numbers with many factors has little factors,"I apologise beforehand for the informality and lack of precision in this question but it is that way because it comes from only an intuition, nothing more than a heuristic argument. Say one has two large, relatively coprime numbers relatively close to each other ( relative to their own size) so that both numbers have a large amount of prime factors( large relative to the usual amount for numbers of that size) in their factorisations. Then, their difference is relatively small and cannot be divisible by any prime within the factorisations of the two large numbers. Hence, it seems reasonable that this small number must have a small amount of prime factors(relative to the usual amount for numbers of that size), since there are several primes it cannot be divisible by. Computing several such examples, I find that this is indeed mostly the case. Often, the difference of the two numbers is prime. What I am wondering is whether there are some rigorous ways to express this fact. I'm thinking maybe it would involve something about the distributions of the values of some function like the divisor function, the sum of divisors function, or the amount of prime factors function or something of the sort. Any further loose thoughts and ideas that add to this are welcome. 
Thanks.","['prime-numbers', 'number-theory']"
904041,First order ODE: $tx'(x'+2)=x$,"$$tx'(x'+2)=x$$
First I multiplied it:
$$t(x')^2+2tx'=x$$
Then differentiated both sides:
$$(x')^2+2tx'x''+2tx''+x'=0$$
substituted $p=x'$ and rewrote it as a multiplication
$$(2p't+p)(p+1)=0$$
So either $(2p't+p)=0$ or $p+1=0$ The first one gives $p=\frac{C}{\sqrt{T}}$
The second one gives $p=-1$. My question is how do I take the antidervative of this in order to get the answer for the actual equation?",['ordinary-differential-equations']
904056,"If $a,b,c$ are positive, then $(a+b+c)(1/a+1/b+1/c)\ge 9$ [duplicate]","This question already has answers here : Given that a,b,c are distinct positive real numbers, prove that (a + b +c)( 1/a + 1/b + 1/c)>9 (4 answers) Closed 7 years ago . The question asks to prove that if  ""$x_1,x_2,x_3$ are positive numbers show that:
$$(x_1+x_2+x_3) \left(\frac{1}{x_1}+\frac{1}{x_2}+\frac{1}{x_3} \right)\ge 9$$ I've tried to use the fact that the arithmetic mean is greater than the harmonic mean since it looks like it's kind of in that form but it doesn't seem to work. I tried expanding it too and simplifying a little to get:
$$ x_1^2(x_2+x_3)+x_2^2(x_1+x_3)+x_3^2(x_1+x_2)\ge 6 x_1x_2x_3$$ but I can't seem to see anyway to further get it into a form that easily proves the required inequality. Any hints as to a way to do this?","['inequality', 'means', 'algebra-precalculus']"
904087,How to prove the following defined collection is a sigma algebra?,"Let $\mu$ and $\lambda$ be two measures on a $\sigma$-algbra $\mathfrak{F}$ on $\Omega$, such that $\mu (A)=\lambda(A)$ for any $A\in \mathfrak C$, where $\mathfrak C\subset\mathfrak{F}$ is a collection having property if $A$ and $B$ are in $\mathfrak C$, then so is $A\cap B$. Assume there is $A_i\in \mathfrak C$, such that $\bigcup_{i=1}^\infty A_i=\Omega$ and $\mu(A_i)<\infty$ for all $i$. Then prove $\{A\in\sigma(\mathfrak C), \mu(A)=\lambda(A)\}$ is a $\sigma$-algebra. This is one question from my homework. At first sight, it's easy. But actually, I have tried much time. I doubt that this question might be wrong.","['measure-theory', 'elementary-set-theory']"
904088,Why is this answer wrong? (rational expressions),"Simplify the following expression: $$q=\frac { z+9 }{ 5 } +10$$ this is what I got: $$q=\frac { z+9 }{ 5 } +\frac { 50 }{ 5 } $$
$$ q=\frac { z+9+50 }{ 5 } $$ This answer is wrong:
$$q=\frac { z+59 }{ 5 } $$",['algebra-precalculus']
904093,Limit of a sequence of averages (three variables),"Let $a_0 = 0$, $a_1 = 0$, $a_2=1$ and for $n>2$, $a_n = \dfrac{a_{n-1}+a_{n-2}+a_{n-3}}{3}$. Consider $\lim\limits_{n \to +\infty} a_n$. Using a python script I found that $a_n$ tends to $\frac{1}{2}$ as $n \to +\infty$. However I don't know how to prove this...I tried the approach from this question that I asked here a while back, but I couldn't anything like it to work because the differences between terms kept altering between positive and negative in an unpredictable fashion (i.e. -+-++-++-++-+--+--...) and the absolute value of the differences did not always decrease as $n$ increased ($|a_7-a_8| < |a_8-a_9|$). (Source: the python code, which I can include if that helps...) Another approach I tried was to use induction to try to prove the general case that if the first $k$ terms $a_0,\cdots,a_{k-1}$ are given where $a_0,\cdots,a_{k-2} = 0$ and $a_{k-1} = 1$ and for $n>k-1$, $a_n = \dfrac{\sum\limits_{i=1}^k a_{n-i}}{k}$ then that $\lim\limits_{n \to +\infty} a_n = \dfrac{2}{k+1}$ (this is just a guess after the first five or six terms), but I also made no progress there. Could anybody help point me in the right direction? How do I prove this? (The $k=3$ case is enough; proving the general case was just an idea.)","['induction', 'sequences-and-series', 'limits']"
904101,If $p\mid|G|$ then how many elements of order $p$ are there in $G$?,"Let $G$ be a finite group and $p$ be a prime such that $p\mid|G|$ , then obviously $G$ has an element of order $p$ (by Cauchy's theorem) ; I would like to know exactly how many elements of order $p$ are there in the group ? Please help","['finite-groups', 'group-theory']"
904135,Skewed Trigonometric Function,"What would be an expression for a periodic function (period $2\pi$) that essentially behaves just like a negative sine function, but it has the following quirk: It's $0$s lie on the usual places (even integer multiples of $\frac \pi 2$), but it's maximum and minimum values (of $\pm 1$), instead of lying on odd integer multiples of $\frac\pi 2$, lie deviated by an angle $\alpha$ from the even integer multiples of $\frac \pi 2$. These are it's only maximums and minimums. It's maximums and minimums can be graphically represented as follows: In Orange we can see the function $-\sin (x)$, and the Red points represent the maximums and minimums of the function (the Gray lines just represent connections between the points, not the actual function). Much appreciated.",['trigonometry']
904143,Confusing about the domain of $f(x)=(x+|x|)\sqrt{x\sin^2(\pi x)}$,"What is the domain of $f(x)=(x+|x|)\sqrt{x\sin^2(\pi x)}$? A nice plot of $f(x)$ shows that the domain is $\mathbb{R}$ but we see that $x$ should be non-negative at the first sight. Of course, I see that when $x<0$ then the part $x+|x|$ gets vanished and so there is no worry about the another part. Can you help me? Thank you!","['calculus', 'functions']"
904150,radius of convergence for $\sum_{n=1}^{\infty} \frac{z^{n} n^{n}}{n!}$ and $\sum_{n=1}^{\infty} z^{n!}$,"Exercise 4:10 in John D'Angelo's text is to find the radius of convergence for : A) $\sum_{n=1}^\infty \frac{z^n n^n}{n!}$ and B)  $\sum_{n=1}^\infty z^{n!}$ I got half of an answer for A) which I wanted to check and I got totally stuck on B). Thanks for the help. I know from the Theorem in the section that $\frac{1}{R} = \limsup |a_n|^{\frac{1}{n}}$ where $R$ is the radius of convergence. So, for A: $$\frac{1}{R} = \frac{n}{n!^{\frac{1}{n}}}\text{ so }\frac{1}{R} = \limsup \frac{n!^\left({\frac{1}{n}}\right)}{n}$$ which I think is $0$ but I'm not positive. I doubt this is correct because that would mean that the radius of convergence is $\infty$ which seems wrong. for B: $z^{n!} = z^{(n \times(n-1)!)}$ but I don't know how to eliminate the $(n-1)!$ so I
can just have a $z^{n}$ so that I can use the theorem above regarding $R$. Thanks again. Oh, I know I asked this before but if anyone knows of a solution manual to this text, I'd appreciate it. I'm not a student so not trying to cheat on the homework but rather just trying to understand the basics.",['complex-analysis']
904152,Prove $\int_0^1 \frac{\ln(1+t^{4+\sqrt{15}})}{1+t}\mathrm dt= -\frac{\pi^2}{12}(\sqrt{15}-2)+\ln (2) \ln(\sqrt{3}+\sqrt{5})+\ln(\phi) \ln(2+\sqrt{3})$,"Prove that: \begin{equation}
\int_0^1 \frac{\ln\left(1+t^{4+\sqrt{15}}\right)}{1+t}\mathrm dt= -\frac{\pi^2}{12}(\sqrt{15}-2)+\ln (2) \ln(\sqrt{3}+\sqrt{5})+\ln(\phi) \ln(2+\sqrt{3})
\end{equation} where $\phi$ is the golden ratio. My friend gave me this challenging problem but I cannot prove it into the given expression. She doesn't know either how to approach this problem. I have tried to use a substitution to obtain the improper integral so that I can use the derivative of beta function but it failed. I also tried to use Taylor series for $\frac{1}{1+t}$ and $\ln\left(1+t^{4+\sqrt{15}}\right)$ but I am unable to derive the result from double sums of series. Could anyone here please help me how to prove it? Any method is welcome and also any help would be greatly appreciated. Thank you.","['calculus', 'integration', 'definite-integrals', 'real-analysis', 'complex-analysis']"
904156,How to bound the following sum,I am interested in bounding the sum $$S(x)=\sum_{i\leq x}\vert\{x/i\}-\{x/(i+1)\}\vert$$ where $\{x\}$ is the fractional part of $x$. A calculation on MATHEMATICA seems to suggest $$S(x)=O(x^\theta)$$ where $\theta$ is some real number less than 1. Question: Is there any theoretical evidence for such a conjecture?,['number-theory']
904172,How to find a 4D vector perpendicular to 3 other 4D vectors?,"In 3 dimensions it is possible to find a vector c (one of infinitely many) perpendicular to two vectors a and b using the cross product. Is there any way of extending this to 4 dimensions, i.e. given three vectors a , b , and c finding a vector d perpendicular to all of them? I realize that this can be done by solving the equation system: dot(a, d) = 0
dot(b, d) = 0
dot(c, d) = 0 and imposing an additional constraint, for instance setting the length of d to or one of its components to 1, but is there a way of doing this that does not involve solving an equation system?",['geometry']
904197,Resultants of two polynomials over a ring,"Let $k$ be a field $f,g\in k[x,y]$ be two polynomials. The resultant $R\in k[x]$ is a polynomial function of the coefficients of $f$ and $g$, such that $f$ and $g$ gave a common zero (in an extension) if and only if $R(a)=0$. Further it is know that there are polynomials $A$ and $B$ of degrees in $y$, one less that those of $g$ and $f$ respectively such that $Af+Bg=R$. My question is 
$$k[x,y]/(f,g) \cong k[x]/(R) ?$$","['commutative-algebra', 'algebraic-geometry', 'abstract-algebra']"
904223,Changing local coordinates on a manifold by a diffeomorphism,"This is the set up of my problem: Let $M$ be a manifold with local coordinates $x^1,\dots, x^n$. Let $x^1,\dots,x^n,\xi_1,\dots,\xi_n$ denote the induced coordinates on $T^\ast M$. Let $f:M\to M$ be a diffeomorphism and consider the induced map $$F:T^\ast M \to T^\ast M \ , \ (p,\xi)\mapsto (f(p),(f^\ast)^{-1}(\xi)).$$ This is the inverse of the pullback map. We get a new local coordinate system on $T^\ast M$ given by $\widetilde x^i=f(x^i)$ and $\widetilde\xi_i=(f^\ast)^{-1}_x(\xi_i)$ I know the chain rule gives $$\frac{\partial}{\partial x_i}=\frac{\partial \widetilde x^j}{\partial x^i}\frac{\partial}{\partial\widetilde x^j}.$$For simplicity let $x=(x^1,\dots,x^n)$ and $\xi=(\xi_1,\dots,\xi_n)$. I know that if the $\xi$'s were coordinates on the tangent bundle we would have $$\xi_i=\frac{\partial\widetilde x^j}{\partial x^i}\widetilde\xi_j$$ but I am not sure if this is true as coordinates on the cotangent bundle. Anyway, I was told that since $(f^\ast)^{-1}(x,\xi)=\widetilde\xi$ it follows that $$\widetilde\xi_i=\frac{\partial x^j}{\partial \widetilde x^i}\xi_j$$I am hoping that someone can explain it to me. I know it has something to do with the inverse transpose of the change of basis matrix. That is, working with induced coordinates $x^1,\dots,x^n,v^1,\dots,v^n$ on the tangent bundle we get the formula $$v^j=\frac{\partial\widetilde x^i}{\partial x^j}\widetilde v^i$$so that $$\frac{\partial \widetilde v^j}{\partial v^i}=\frac{\partial \widetilde x^j}{\partial x^i}$$and we are flipping the roles of $i,j$ and the tildes.","['manifolds', 'coordinate-systems', 'linear-algebra', 'differential-geometry']"
904231,Differential of the inversion of Lie group [duplicate],"This question already has answers here : Pushforward of inverse map at the identity? (2 answers) Closed 9 years ago . Let $G$ be a Lie group and $\iota \colon G\to G$ denote the inversion. If $e$ is the identity of $G$, prove that: $$\text d \iota _e = -\text {id} _{T_e G}.$$
I understand that the differential at $e$ should be an involution, since $$\iota \circ \iota = \text{id}_G$$
implies that $$\text d \iota _e \circ \text d \iota _e=\text d (\iota \circ \iota)_e=\text d(\text {id} _G)_e=\text {id} _{T_e G}.$$
However I don't know how to conclude the thesis from this. Any hint?","['lie-groups', 'differential-geometry']"
904233,Interior and exterior of a polygon in Hilbert axioms,"I can't prove one theorem from Hilbert's ""Foundations of Geometry"". Here is the quote: Theorem 6. Every simple polygon, whose vertices all lie in a plane $\alpha$, divides
  the points of this plane, not belonging to the broken line constituting the sides
  of the polygon, into two regions, an interior and an exterior, having the following
  properties: If $A$ is a point of the interior region (interior point) and $B$ a point of
  the exterior region (exterior point), then any broken line joining $A$ and $B$ must have
  at least one point in common with the polygon. If, on the other hand, $A$, $A'$ are
  two points of the interior and $B$, $B'$
  two points of the exterior region, then there are
  always broken lines to be found joining $A$ with $A'$ and $B$ with $B'$ without having a
  point in common with the polygon. There exist straight lines in the plane $\alpha$ which
  lie entirely outside of the given polygon, but there are none which lie entirely within
  it. This theorem can be proved with Hilbert's axioms of connection and order. No need to use congruence, parallel or continuity axioms. Hilbert writes this theorem may be obtained without serious difficulty with the aid of this theorem: Theorem 5. Every straight line $a$, which lies in a plane $\alpha$, divides the remaining
  points of this plane into two regions having the following properties: Every point $A$
  of the one region determines with each point $B$ of the other region a segment $AB$
  containing a point of the straight line $a$. On the other hand, any two points $A$, $A'$
  of the same region determine a segment $AA'$
  containing no point of $a$. but for me it's not so obvious. I had a few ideas to prove it but none of them was successful. I tried to indicate these regions as a sum of intersections of families of some half-planes and its complement. I also tried to show that a binary relation defined this way: $A\sim B \iff$ there exists a broken line joining $A$ and $B$ which has no point in common with the polygon is an equivalence relation with exacly two equivalence classes. I also tried to do this using induction. Can you help me?","['axiomatic-geometry', 'geometry']"
904246,A subset that is closed under multiplication but not addition? [duplicate],"This question already has an answer here : About closure under + (1 answer) Closed 9 years ago . I can't get my head around subspaces despite having studied on them quite a lot. Here goes: The problem statement, all given variables and data Give an example of a non-empty subset U of R^2 such that U is closed under scalar multiplication but is not a subspace of R^2. Attempt at a solution So a set such as [x1, x2] | x1 >= 0 is NOT closed under scalar multiplication but is closed under addition. I get this but I cannot find an answer in reverse. A wild guess is x1 + x2 + 2 = 0. I could multiply it and 2x1 + 2x2 + 4 = 0 would still hold true. However, if I wish to perform an addition on it, I don't exactly understand what I add to what equation exactly.. it's all so bogged up. Help would be appreciated. :-)","['vector-spaces', 'matrices', 'linear-algebra']"
904252,Find the value of : $\lim_{n\to\infty} \left( \left(\sum_{k=n+1}^{2n}2\sqrt[2k]{2k}-\sqrt[k]{k}\right)-n\right)$,"Find $$\lim_{n\to\infty} \left( \left(\sum_{k=n+1}^{2n}2\sqrt[2k]{2k}-\sqrt[k]{k}\right)-n\right).$$ I have tried rewriting the sum in a clever way, applying the Mean Value Theorem or Stolz-Cesaro Lemma somehow but haven't found anything fruitful. Can someone please share a hint/trick to evaluate this? Thank you.","['sequences-and-series', 'calculus']"
904254,Symmetric Borel sets in the plane,"How will I show that the sigma algebra consisting of all Borel sets in the plane, which are symmetric about the line $y=x$, is generated by sets of the form $(a,b) \times (a,b)$? I could show upto the fact that any set in the $\sigma$-algebra generated by sets of the form $(a,b) \times (a,b)$ is a Borel set, symmetric about $y=x$. But I am totally confused about the part that any symmetric Borel set is generated in such a way. Any help will be greatly appreciated!",['measure-theory']
904260,What is the limit of the following sum,"$$\lim_{n\to\infty}\sum_{k=1}^n \ln\Big(1+\frac{k}{n^2}\Big)$$ According to me, the answer is $0$. I'm curious as to what answers might others come up with, as well as the method of reasoning.","['summation', 'calculus', 'limits']"
904288,Proof $p(A)=0$ without Cayley-Hamilton theorem when $A$ is upper triangular,"I need help proving $p(A)=0$ without Cayley-Hamilton theorem when $A$ is upper triangular, as part of the proof of the Cayley-Hamilton theorem The result makes a lot of sense but I can't prove it properly If $A \in \Bbb C^{n \times n }$ is upper triangular then its characteristic polynomial is $p= (x-c_1)^{r _1}...(x-c_k)^{r_k}$ then $p(A)$ will be the product of $k$ upper triangular matrices with interspersed zeros on the diagonal...","['matrices', 'linear-algebra']"
904296,How to find $\int \frac{x\ln(x+\sqrt{1+x^2})}{\sqrt{1+x^2}}\mathrm dx$,"$$I=\int x.\frac{\ln(x+\sqrt{1+x^2})}{\sqrt{1+x^2}}\mathrm dx$$ Try 1: Put $z= \ln(x+\sqrt{1+x^2})$, $\mathrm dz=1/\sqrt{1+x^2}\mathrm dx$
$$I=\int \underbrace{x}_{\mathbb u}\underbrace{z}_{\mathbb v}\mathrm dz=x\int zdz-\int (z^2/2)\mathrm dz\tag{Wrong}$$ Try 2: Put 
$z= x+\sqrt{1+x^2}$
$$\implies x-z
=\sqrt{1+x^2}\implies x^2+z^2-2xz
=1+x^2\implies x
=\frac{z^2-1}{2z}$$ 
$$\mathrm dz
=\left(1+\frac{x}{\sqrt{1+x^2}}\right)\mathrm dx
=\frac{z\mathrm dx}{x-z}=\frac{-2z^2\mathrm dx}{1+z^2}$$
$$I
=\int\frac{(z^2-1)\ln z}{2z}.\frac{(1+z^2)\mathrm dz}{-2z^2}$$
$$=\int\frac{(z^4-1)\mathrm dz}{4z^3}
=\frac14\int\left(z-\frac1{z^3}\right)\mathrm dz
=z^2/2+2/z^2+C\tag{Wrong}$$ Try 3: Put 
$z
=\sqrt{1+x^2},\mathrm dx
=x/\sqrt{1+x^2}\mathrm dx$
$$I
=\int \ln(x+z)\mathrm dz
=\int \ln(z+\sqrt{z^2-1})\mathrm dz$$
Don't know how to solve this integral. [Note that if I take $u=z+\sqrt{z^2-1}$, it is $=\sqrt{1+x^2}+\sqrt{1+x^2-1}=x+\sqrt{1+x^2}$; same as first try.] What's wrong in try 1 & 2, how to further solve try 3 and the best method to solve this question? Update: Sorry, I don't know hyperbolic/inverse hyperbolic trigonometry.","['calculus', 'integration', 'indefinite-integrals']"
904320,Improper integral containing $\sqrt{\cos x-\frac1{\sqrt 2}}$ in the denominator,How do I find the value of this integral-- $$I=\displaystyle\int_{0}^{\pi/4} \frac{\sec^2 x \ dx}{\sqrt {\cos x-\dfrac{1}{\sqrt 2}}}$$ I came across this integral too in physics.,"['definite-integrals', 'improper-integrals', 'integration']"
904323,Derivation of Lagrange-Charpit Equations [duplicate],"This question already has an answer here : How to take this exterior derivative of the expression $du - \sum_i p_i dx_i$? (1 answer) Closed 6 years ago . I am working through the derivation of the Lagrange-Charpit equations presented in this Wikipedia article: http://en.wikipedia.org/wiki/Method_of_characteristics#Fully_nonlinear_case I am interested in the ""fully"" nonlinear case. Where we have: $$F(x_1,...,x_n,u,p_1,...,p_n)=0  $$
And $$ p_i=\frac{\partial u}{\partial x_i} $$ I am fine with the derivation up until the point where they say that (Also, $\dot{x_i}=dx_i/ds$): $$\sum_i(\dot{x}_idp_i-\dot{p_i}dx_i)=0 $$ Follows from taking the exterior derivative of: $$ du-\sum_ip_idx_i=0  $$ From the little I know about exterior derivatives, it seems like doing this would give (for the two dimensional case): $$0=\left(\frac{\partial p_2}{\partial x_1}-\frac{\partial p_1}{\partial x_2}\right)dx_1\wedge dx_2 $$ Because $ddu=0$ and the anti-symmetry of the wedge product.  I don't see how this result leads to the one given.  Could someone help me out? I feel like there is something very simple that I am missing.","['ordinary-differential-equations', 'partial-differential-equations']"
904340,Special solutions to Ax = 0,"I solved most of it, just not sure about one point. The problem statement, all given variables and data Suppose A is the matrix shown below: $$
        \begin{pmatrix}
        0 & 1 & 2 & 2 \\
        0 & 3 & 8 & 7 \\
        0 & 0 & 4 & 2 \\
        \end{pmatrix}
$$ Find all special solutions to Ax = 0. Attempt at a solution So after some elimination, I acquired the matrix below. $$
        \begin{pmatrix}
        0 & 1 & 0 & 1 \\
        0 & 0 & 1 & -1/2 \\
        0 & 0 & 0 & 0 \\
        \end{pmatrix}
$$ According to what I read online, there must be special solutions as many as the number of free variables. You go through the free variables one by one, making one of them equal to 1 and the rest equal to 0. So my first free solution is below: Let $x_4 = 1$. $\Rightarrow x_1 = ?$ (there is no $x_1$), $x_2 = -1$, $x_3 = -\frac{1}{2}$ and $x_4 = 1$ Let $x_1 = 1$ (but there is no $x_1$) $\Rightarrow x_1 = ?$, $x_2 = 0$, $x_3 = 0$, $x_4 = 0$ I am not entirely sure if I concluded the answer correctly. I would appreciate if someone could wrap it up. If I don't have a variable in my system at all, like $x_1$ here, then what exactly do I put in its place? How do I represent it?","['matrices', 'linear-algebra']"
904343,What is the difference between Average and Expected value?,"Question : What is the difference between Average and Expected value? I have been going through the definition of expected value on Wikipedia beneath all that jargon it seems that the expected value of a distribution is the average value of the distribution. Did I get it right ? If yes, then what is the point of introducing a new term ? Why not just stick with the average value of the distribution ?","['average', 'expected-value', 'probability', 'definition']"
904371,"Arithmetic Mean, Geometric Mean, Harmonic Mean and their relations","If $a$ be the arithmetic mean between $b$ and $c$, $b$ be the geometric mean between $c$ and $a$ then prove that $c$ is the harmonic mean between $a$ and $b$. I expressed $a$ as $$a=\frac{(b+c)}{2}$$ $$b=\sqrt {ac}$$ . I solved the equations but I could not evaluate for $c$","['means', 'algebra-precalculus', 'systems-of-equations']"
904390,Proving that $\int \frac{1}{x} \mathrm dx = \ln(|x|) + C_1$,"In all textbooks and online notes, there is always a table of antiderivatives and it always says $\int \frac {1}{x} \mathrm dx = \ln(|x|)+C_1$ but there is nowhere a proof. I found some proofs online but there is too much circular logic, assuming unproven hypothesis to reach the conclusion. Differentiating $\ln(x)$ can't be the most rigorous proof out there...","['proof-writing', 'calculus', 'integration']"
904424,Why is $ A_1 x + ... + A_n x^n $ a solution of $ \sum_0^{n} (-1)^n \frac{x^n}{n!} \frac{d^n y}{d x^n} = 0 $?,"I was playing(/fiddling) around with some maths and I saw this pattern(
where $ A_n $ is a constant.): $ A_1 x $ is a soultion of:
$$ \frac{y}{x} - \frac{dy}{dx} = 0 $$ $ A_1 x + A_2 x^2 $ is a solution of:
$$ \frac{y}{x} - \frac{dy}{dx} + \frac{x}{2!} \frac{d^2y}{dx^2} =0 $$ $ A_1 x + A_2 x^2 + A_3 x^3 $ is a solution of:
$$ \frac{y}{x} - \frac{dy}{dx} + \frac{x}{2!} \frac{d^2y}{dx^2} - \frac{x^2}{3!} \frac{d^3y}{dx^3} =0 $$ It continues so on. Can someone prove the solution of 
$ A_1 x + A_2 x^2 + A_3 x^3 + ... + A_n x^n $ is: $$ \sum_{k=0}^{n} (-1)^k \frac{x^{k-1}}{k!} \frac{d^k y}{d x^k} = 0 $$","['ordinary-differential-equations', 'sequences-and-series', 'pattern-recognition']"
904429,Characterization of measurability by closed sets.,"If $E \subseteq \Bbb R$ is measurable, then for all $\epsilon > 0$, exists $F \subseteq \Bbb R$ closed such that $F \subseteq E$ and ${\frak m}^*(E \setminus F) < \epsilon$. I have already made the characterization by open sets, that is, if $E$ is measurable, for all $\epsilon > 0$, exists $O \subseteq \Bbb R$ open, such that $E \subseteq O$ and ${\frak m}^*(O \setminus E) < \epsilon$. For that characterization, I used that for all $A \subset \Bbb R$, given $\epsilon > 0$, exists $O \subseteq \Bbb R$ open such that ${\frak m}^*O < {\frak m}^*A + \epsilon$. Just take intervals $(I_j)_{j \geq 1}$ covering $A$ such that $\sum_{j \geq 1} \ell (I_j) < {\frak m}^*A + \epsilon$, so let $O = \bigcup_{j \geq 1} I_j$ if ${\frak m}^*A < +\infty$, and $O = \Bbb R$ if ${\frak m}^*A = +\infty $. I was trying to ""copy"" this proof, and so I would begin proving the lemma (which I firmly believe that is true): For all $A \subseteq \Bbb R$, given $\epsilon > 0$, exists $F \subseteq \Bbb R$ closed such that ${\frak m}^*A < {\frak m}^*F + \epsilon$. Well, if ${\frak m}^*A = 0$, take $F = \varnothing$. But apart from this, my attempt isn't going well. Surely, if ${\frak m}^*A > 0$, we can take intervals $(I_j)_{j \geq 1}$ covering $A$ such that $\sum_{j \geq 1} \ell (I_j) < {\frak m}^*A - \epsilon$, but so what? Infinite union of closed sets need not be closed. Another idea is to use the result of open sets for $A^c$, so that $A^c \subseteq O \implies O^c \subseteq A $, then take $F = O^c$. But I don't see quickly how to get the relation between the measures. Am I going in the right way? Can someone help me please?","['measure-theory', 'lebesgue-measure', 'real-analysis']"
904477,Simplify exponential sum over $\mathbb{F}_p$ to prove identity,"I have a sum involving  $p$-th roots of unity (where $\frac{1}{t}$ is to be understood as the field inverse $t^{-1} \bmod p$ etc.) of the form $\begin{align*}
&d_{j,k}=\sum_{a,b,c \in \mathbb{F}_p}\omega^{\frac{1}{12}(a^3-c^3)+(\frac{b}{2}+\frac{1}{8})(a^2-c^2)+(\frac{b}{2}+b^2)(a-c)+kc-ja}\end{align*}$ where $\omega=\exp(2 \pi i/p)$ is a primitive $p$-th root of unity and $p$ is a prime greater than 3. With the aid of a computer, I can confirm the above expression obeys $\begin{align*}d_{j,k\neq j}=p^2 \sum_{r  \in \mathbb{F}_p}\omega^r=0
\end{align*}$ I have checked this for $5\leq p \leq 17$ and am confident this holds for all prime $p>3$. Question: 
How can I manipulate the expression for $d_{j,k}$ in order to see that all $d_{j,k\neq j}$ (with $j,k \in \mathbb{F}_p$) evaluate to zero?","['exponential-sum', 'finite-fields', 'number-theory']"
904483,Solid angle: integration,"Can somebody explain the equivalence between integrating over the surface of a unit sphere and integrating over solid angle? I have been trying to understand the following transformation using a Jacobian but have been unsuccessful: $$\iiint dr\ d\theta\ d\phi\ r^2 \sin \theta\ f(r,\theta,\phi) = \iint dr\ d\Omega\ r^2 f(r,\Omega)$$ I believe my confusion is that the solid angle is a surface area in a certain sense, and so I am confused as to how integrating over these surface area values recovers integrating over the full surface area of the sphere. I am also confused because one typically sees a Jacobian determinant employed for such transformations but determinants are defined only for square matrices and the number of variables in these two integrals are not the same.","['geometry', 'spherical-trigonometry', 'integration', 'solid-angle']"
904493,Geometric interpretation of complex path integral,"Let's say that we want to make sense of integrating a function $f: \mathbb{C}\rightarrow\mathbb{C}$ over some path $\gamma$.  I can imagine two reasonable ways of doing it.  First, there's the way that we all know and love: $$\int_\gamma f := \int_a^b f(\gamma(t))\gamma'(t)\,dt$$ where $\gamma(t)$ parametrizes $\gamma$. Alternatively, we could say, ""We already have a nice formulation of line integrals for paths in $\mathbb{R}^n$, and $\mathbb{C}$ is essentially just $\mathbb{R}^2$.""  So we decide that we'll define the path integral like this: $$\int_\gamma f := \int_a^b f(\gamma(t))|\gamma'(t)| \,dt$$ like we might do for functions $f: \mathbb{R}^2 \rightarrow \mathbb{R}$.  This second definition has the nice property that $\int_\gamma f = \int_\gamma \text{Re}f + i \int_\gamma \text{Im}f.$ But of course we don't use the second formulation.  We stick with the first, and there are some nice utilitarian reasons for doing so (Cauchy's integral formula, etc.).  But are there more natural (geometric, preferably) reasons for using the first definition above? EXAMPLE For a simple example, let's say that $f(z) = i$ and I want to integrate $f$ along $\gamma$, the line from $0$ to $i$.  I'll choose the parametrization $\gamma(t) = it$, $t \in [0,1]$.  Then $\gamma'(t) = i$, and, using the first definition for our path integral, we get:  $$\int_\gamma f = \int_0^1 i \gamma'(t) \,dt = \int_0^1 i^2\, dt = -1.$$ Meanwhile, in the wayward world where we choose the second formulation for our path integrals, we have: $$\int_\gamma f = \int_0^1 i |\gamma'(t)| \,dt = i.$$  In essence, this second computation didn't care about the complex structure on $f$'s domain.  As far as this method was concerned, we integrated a constant function over a path of measure 1, so naturally we get that constant as our answer.  On the other hand, in the first computation, multiplying by $\gamma'$ carries some additional complex structure.  It knows the difference between integrating along lines from $0$ to $i$ or from $0$ to $1$, for example. Heuristically, it seems like the first definition allows the complex structures on $f$'s domain and range to interact (through the $\gamma'$ term), whereas the second definition neglects any complex structure on the domain of $f$ and is only concerned with stretching/reorientation caused by our choice of parametrization.  But why, a priori, are we interested in allowing $f$'s complex domain and range to interact in this way (if that's even the right way of framing it)?  Does this ""interaction"" have a geometric interpretation?  And is there a nice way of interpreting the line integral that makes the first definition obviously the more natural choice, or do we just go with it because it's useful? Thanks for reading!","['soft-question', 'complex-analysis']"
904504,Basic understanding of Log and $2 \log _3(x)+\log _9(x)=10$,"So this is what I have done so fare $$2 \log _3(x)+\log _9(x)=10$$ I know that $$\log _9(x)=\log _3\left(\sqrt{x}\right)$$ I therefore have $$\log _3\left(x^{5/2}\right)=10$$ However here is where I realise that I have not properly understood the underlying of log.
Since I know that the answer is 81 I was able to realise that $$\log _3(x)=4$$ Is the same as x==3^4, but I do not understand if Im dividing or multiplying or what is going on. I thought that $$\log _3(x)$$ meant that $$3^?=x$$ Basically trying to find the exponent? At least that is the dummed version that I got thought in class Could someone explain what is going on and what I do not understand , in such a way that I am able to grasp the concept.",['algebra-precalculus']
904512,Changing order of integration (multiple integral),"Prove $$ \int_0^a\left( \int_0^x \left( \int_0^y \left( \int_0^z f(u) \, du \right) dz \right) dy \right) dx = \int_0^a \frac {(a-t)^3}{3!} f(t) dt $$ where $a$ is constant. So I began with two most inner integrals i.e. the double integral $$ \int_0^y \left( \int_0^z f(u) du \right) dz $$ We are doing this over $0 \leq u \leq z \leq y \leq x \leq a$. So we want $$ \int_0^y \left( \int_0^z f(u) du \right) dz = \int_?^? \left( \int_?^? f(u) dz \right) du  $$ And immediately this problem got me stumped. How can one tell what the upper/lower bounds become? Keep in mind that drawing this region won't do much good as we are working in four dimensions. EDIT: Forgot something crucial, edited now!","['definite-integrals', 'multivariable-calculus', 'integration']"
904547,A sum of difference of floors,"I have the sum ( $M$ is any integer $> 1$ ): $$
\sum_{h = 1}^{M}\left(\,\left\lfloor\, 2M + 1 \over h\,\right\rfloor
-\left\lfloor\, 2M \over h\,\right\rfloor\,\right)
$$ and looking for a way to simplify it. In the sense of either finding a simple closed form or a good approximation for M large . This resembles my previous question involving the divisor summatory function. However, now this is different because the sum extends to $M$ (not $2M$) and now we have differences with at the numerators an odd number and the previous even number (which is $2$ times $M$), I was hoping some good simplification could be found in this case. The first terms are integers, so they pose no problems, I was mainly looking for some way to simplify the other differences. A tight upper bound would also be useful ( as well as references to similar well-known $\mbox{formulas )}$.","['closed-form', 'discrete-mathematics', 'elementary-number-theory', 'ceiling-and-floor-functions', 'summation']"
904558,Simplifying nested/complex fractions with variables,"I have the equation $$x = \frac{y+y}{\frac{y}{70} + \frac{y}{90}} $$ and I need to solve for x. My calculator has already shown me that it's not necessary to know y to solve this equation, but  I can't seem to figure it out. This is how I try to solve it:
$$
x = \frac{y+y}{\frac{y}{70} + \frac{y}{90}} = 2y\left(\frac{70}{y} + \frac{90}{y}\right) = 2y\left(\frac{90+70}{y}\right) = 2y\cdot\frac{160}{y} = \frac{320y}{y} = 320
$$
But according to my calculator, this is not correct. The answer should be 78.75, but I don't know why. Any help would be much appreciated.","['fractions', 'algebra-precalculus', 'problem-solving']"
904559,Convex interior topology,"I have found a fascinating example of topology on a vector space $V$, but I cannot prove its interesting properties to myself. Let $\mathcal{B}$ be the family of all convex symmetric (i.e. $\forall U\in\mathcal{B}\quad x\in U\Rightarrow-x\in U$) sets $U\subset V$ coinciding with its interior , defined as $\{x\in U:\quad\forall y\in V\quad\exists \varepsilon(y)=\varepsilon>0:\forall t\in\mathbb{R}(|t|<\varepsilon\Rightarrow x+ty\in U)\}$.
I read that $\mathcal{B}$ is a local basis for $0$ for a locally convex topology $\tau$ satisfying axiom $T_1$; $\tau$ is the strongest among locally convex topologies where the linear operations on $V$ are continuous; Any linear functional $V\to K$ (where I think $K$ can be both $\mathbb{C}$ or $\mathbb{R}$) is continuous with respect to $\tau$. I can find no on line resource on the issue and my book only has half a page on locally convex topological vector spaces. Can anyone help me in understanding these properties with links or proofs? I heartily thank you all!","['general-topology', 'functional-analysis']"
904568,When does a strictly diagonally dominant matrix have dominant principal minors?,"$A$ is an $N\times N$ matrix with diagonal elements $a_{ii}=1-s_{i}$, and off diagonal elements $a_{ij}=s_{i}w_{ij}$ for $i≠j$. Assume $0≤s_{i}<1/2$ and $\sum_{j≠i}w_{ij}=1$ for all $i$ and $0≤w_{ij}≤1$. As $1-s_{i}>∑_{j≠i}a_{ij}=s_{i}∑_{j≠i}w_{ij}$ for all $i$, matrix $A$ is strictly row diagonally dominant. Thus, $\det(A)>0$ and has positive principal minors, $M_{ii}$ where $ii$ is the submatrix from eliminating row $i$ and column $i$. (see Tsatsomeros 2002 ). There exists an inverse matrix $B=A^{-1}$. I want to show that the diagonal elements $b_{ii}=\frac{M_{ii}}{\det(A)} > 1$. I am able to show this for $N=3$ and $4$. For example, by expanding across the top gives $b_{11}>1$ as $M_{11}>-ω_{12}M_{12}+ω_{13}M_{13}-ω_{14}M_{14}$ , which follows from $M_{11}>‖M_{1j}‖_{j≠1}$. Here the results follows if the principal minor is dominant in the sense of being larger than the minors along the same row. I do not know how to extend this to $N>4$ and have not found the result in my imperfect search of the literature.",['matrices']
904592,After how many steps can compositions of $x\mapsto x+1$ and $x\mapsto x^2+1$ produce the same result starting from $1$ and $3$?,"This problem is from a Turkish contest: Let $P(x)=x+1$ and $Q(x)=x^2+1$. Consider all sequences $(x_k,y_k)$ such that $(x_1,y_1)=(1,3)$ and $(x_{k+1},y_{k+1})$ is either $(P(x_k),Q(y_k))$ or $(Q(x_k),P(y_k))$. Find all positive integers $n$ such that $x_n=y_n$ holds in at least one of these sequences. Clearly, $n=3$ is one possibility ($(x_2,y_2)=(2,4)$, $(x_3,y_3)=(5,5)$) and it seems to be the only one, but I don't know how to proceed in the general case. Any help would be appreciated, thanks.","['recurrence-relations', 'contest-math', 'number-theory']"
904594,Evaluate $\int\frac{8x+20}{5x^2+25x+20}dx$,"I tried to solve it and got $\frac{4}{5} \ln(4+5 x+x^2)+C$ as an answer, but my online homework program says it's incorrect.  What did I do wrong? I pulled out $\frac{4}{5}$ as a constant and saw that the numerator was the derivative of the denominator. So I put the denominator in a natural log.","['integration', 'indefinite-integrals']"
904599,Show that $f(x)=x/\sqrt{x^2+1}$ is a bijection of $\mathbb R$ onto $\{ y: -1<y<1\}$,"I am looking for help in regard to a practice question about functions. The question is Show that a function $f$, defined by $f(x)=x/\sqrt{x^2+1}$ , $x \in \Bbb R$ is a bijection of $\Bbb R$ onto $\{ y: -1<y<1\}$. So what I know that for it to be a bijection, it must be an injection and also a surjection.
So to proof this question, do I just need to prove both of those? So for injection, when $x_1=x_2$ $f(x_1)=f(x_2)$ To do this I wrote $$\frac{x_1}{\sqrt{x_1^2+1}}=\frac{x_2}{\sqrt{x_2^2+1}},$$ squared both sides and expanded to solve that $x_1=x_2$. Next for a surjection, must show that the range is contained, so the bottom cannot be $0$ or negative because cannot square root a negative and cannot divide by $0$.
I believe in this situation you are supposed to write it as $y=x/\sqrt{x^2+1}$ and solve for $x$ in terms of $y$ but I have trouble doing that. Or can I jsut do it by solving an inequality such as $\sqrt{x^2+1}>0$,","['functions', 'proof-verification', 'real-analysis']"
904624,A central division algebra is not its commutator,"In looking at old qualifying exam questions, I've come upon a question that has me stumped. Let $A$ be a central division algebra (of finite dimension) over a field $k$. Let $[A,A]$ be the $k$-subspace of $A$ spanned by the elements $ab-ba$ with $a, b \in A$. Show that $[A,A] \neq A$. If $\text{char } k \nmid [A:k]$, there is a very pleasant argument at hand: fix a basis of $A$ and define $\text{tr}(r)$ to be the trace of the matrix associated to the vector space endomorphism $a \mapsto ra$. It's easily seen that $\text{tr}(ab-ba) = 0$; but by our assumption on the dimension, $\text{tr}(1) \neq 0$, so that $[A,A] \neq A$. This argument fails spectacularly in general. I'd like to salvage it, but I'm not convinced that's possible. I would appreciate hints - if you give a full answer, I would appreciate it if you put it in spoiler boxes.","['noncommutative-algebra', 'ring-theory', 'division-algebras', 'abstract-algebra']"
904630,How to prove that $\int_{0}^{\infty}{\frac{e^{-nx}}{\sqrt{x}}}\mathrm dx$ exists,"I am trying to show that the integral $\int_{0}^{\infty}{\frac{e^{-nx}}{\sqrt{x}}}\mathrm dx$ exists ($n$ is a natural number). I tried to use the comparison theorem by bounding from above the integrand by another function which is integrable, but I wasn't successful. The same question for this integral as well : $\int_{0}^{\infty}x^2e^{-nx}\mathrm dx$ Any help is much appreciated? Thanks!","['improper-integrals', 'integration', 'real-analysis', 'analysis']"
904634,"How to find the integral $\int_0^{70 \pi} |\cos^{2}x\sin x|\,dx$?","I need help with this problem:
$$\int_0^{70 \pi} \left|\cos^{2}\!\left(x\right)\sin\!\left(x\right)\right| dx$$ My friend says it's 140/3 but I don't see how.","['definite-integrals', 'trigonometry', 'calculus']"
904635,probability that the white balls are left in the urn,"I don´t understand the solution of next problem: An urn contains n white balls and m black balls. The balls are withdrawn one at a time until only those of the same color are left. Show that with probability $$n\over m+n$$ they are all white The hint is: imagine that the experiment continues until all the balls are removed, and consider the last ball withdrawn. So if we take into account the hint, there are $(n+m)!$ outcomes of withdrawing all the balls from the urn (in order) and the event that the last ball removed is white has n(n+m-1)! possible outcomes hence the probability is $${n(n+m-1)!\over (n+m)!}= {n\over n+m}$$ The thing is that why do we have to consider the last ball withdrawn? why if the last ball drawn is white implies that all white balls are left in the urn? I don´t get it I was trying to do it like this: there are $(n+m)!$ outcomes of withdrawing all the balls and there are $m$ black balls wich wan be arrenged in $m!$ ways and the white balls can be arrenged in $n!$ ways so the probability is $$m!n!\over (n+m)!$$ but this is just my assumption. I know this is a silly question but can you please explain me why do we have to consider that the last ball withdrawn is white? and why does this implies that all the white balls are the left in the urn? Is there another way to solve this problem? I really would appreciate your help :D",['probability']
904655,Finding the limit of $\left(\frac{(1+2x)^{1/x}}{e^2}\right)^{1/x}$ at $x=0$,I can't seem to find a solution to this. $$\lim_{x\to0} \left(\frac{(1+2x)^{1/x}}{e^2}\right)^{1/x}$$ i tried to manipulate to apply Lhopitals rule but i can't see to do it,['limits']
904658,Symbolic solution to a nonlinear ordinary differential equation problem,"Suppose $y=y(x)$ is infinite continuous in $\mathbb{R}$, and $y(-1)=0$, how can we obtain the analytic solution in closed form to the following nonlinear ordinary differential equation: $$
\left((x-10)^2+y^2\right)\left(x^2+y^2y'^2+2xyy'+2yy'+2x+1\right)=\left(x^2+y^2\right)\left(x^2+y^2y'^2+2 x y y'-20y y'-20x+100\right)
$$ The resulted solution should be in implicit form. 
Is there any general approach in solving such kind of ODE's? Update: What I am asking is actually: is it possible to establish ellipse equation from only one of its properties as shown in the figure below. The light rays from one fixed point $F_1$ being reflected by the curve always focus on another fixed point $F_2$ and vice versa. Suppose we don't know the curve is ellipse, then is it possible for us to obtain ellipse formulation only from the above relationship when being given $F_1$, $F_2$ and a point $A$ or $B$ on the curve? I think the key now becomes how to establish the nonlinear ordinary equations or nonlinear systems to solve in polarized coordinate frame or just Descartes' frame. What should I do?","['ordinary-differential-equations', 'symbolic-computation']"
904660,"How many boolean functions $F(x, y, z)$","Question: How many boolean functions $F(x, y, z)$ are there so that $F(\bar{x}, y, z) = F(x, \bar{y}, z) = F(x, y, \bar{z})$ for all values of the Boolean variables $x, y,$ and $z$? I'm at loss on where to start.",['discrete-mathematics']
904662,Composition and Limits at Infinity,"It is a well known result that if a function $f$ is continuous at $b$ and $\lim_{x\rightarrow a} g(x)=b$, then $\lim_{x\rightarrow a} f(g(x))=f(b)$. When does this hold at infinity? If $f$ is continuous and $\lim_{x\rightarrow \infty} g(x)=b$, is it true that $\lim_{x\rightarrow \infty} f(g(x))=f(b)$?","['real-analysis', 'limits']"
904689,"Is calling a linear-equation a linear-function, misnomer or completely wrong?","From my college life, I remember many professors used to call a linear-equation a linear-function, however: A standard definition of linear function (or linear map) is: $$f(x+y)=f(x)+f(y),$$
$$f(\alpha x)=\alpha f(x).$$ Where as linear equation is defined as: $$f(x)=mx+b.$$ So, linear-equation is NOT a linear-function, according to the definitions defined above. Though, for $b=0$ the linear-equation becomes a linear-function, but it is not true in general. Question: Is it misnomer to call a linear-equation a linear-function, or it is completely wrong to say that? And linear-equation must be considered strictly as an affine-mapping.","['linear-algebra', 'terminology', 'soft-question']"
904693,Is there an easier way to find $\frac{\mathrm d^9}{\mathrm dx^9}(x^8\ln x)$ than using the product rule repeatedly?,"Find $\dfrac{\mathrm d^9}{\mathrm dx^9}(x^8\ln x)$. I know how to solve this problem by repeatedly using the product rule, but I was wondering if there is a short cut. Thanks.","['calculus', 'derivatives']"
904702,What's wrong with solving absolute value equations in this way?,"Say I have $3x-2 = |x|$. Why can't I just do this: $3x - 2 = -x$ and $3x - 2 = x$ and then get two values for $x$: $1$ and $0.5$? I know the answer $0.5$ doesn't work if you plug this in. However, I don't understand why we can't solve the equation like this?","['absolute-value', 'algebra-precalculus']"
904711,"The system $\dot{x}=x^2$, $\dot y=-y$, has infinitely many (local) center manifolds","Consider the system, \begin{align}
\dot{x}&=x^2 \\
 \dot y&=-y
\end{align} I am trying to show that this system has infinitely many local center manifolds. Here is what I have done so far : Clearly the system has a rest point at the origin. I linearized the system at the origin and got that $\lambda=0$ and $\lambda=-1$ to be the eigenvalues of the linearized operator. Turns out that the 
corresponding eigenvectors are $(1,0)^T$ and $(0,1)^T$ respectively. So solutions of the linearized system can be written as follows. \begin{align}
x&=c_1\\
y&=c_2e^{-t}
\end{align} When $c_1=0$, $y\to0$ as $t\to \infty$. Thus, by definition of the stable manifold
the $y$ axis must be a stable manifold. Also the unstable manifold is the trivial set $(0,0)$. Questions : How do I go about showing that there are infinitely many center manifolds?. Does solving the system explicitly have anything to do with answering this question?. In particular any orbit of the system not on the stable manifold $(0,y)$ satisfies an equation of the form $\displaystyle y=c_2e^{\frac{1}{x}-c_1}$. I feel like I am not seeing something simple. Can somebody give an explanation? Context : In the ODE book I am using ( C. Chicone ) this problem is given as an example to show that the center manifold need not be unique. (After proving the invariant manifold theorem).","['dynamical-systems', 'ordinary-differential-equations', 'manifolds']"
904719,How do you solve for x in this equation?,"I tried expanding, but I still can't get rid of the exponents to isolate x. $$\frac{(1+x)^4-1}{x}=4.374616$$ Thank you in advance for your help.",['algebra-precalculus']
904734,Number of solutions of $x_1 + x_2 + x_3 + x_4 = 14$ such that $x_i \le 6$,"Let $x_1, x_2, x_3, x_4$ be  nonnegative  integers. (a) Find the number of solutions to the following equation: 
              $$ x_1 + x_2 + x_3 + x_4 = 14 $$ I got $17 \choose 3$ for this. Is that correct? (b) Find the number of solutions if we add the restriction that $x_i \le 6$ for
       $1 \le i \le 4$",['combinatorics']
904763,Proof that Every Positive Operator on V has a Unique Positive Square Root,"Suppose $V$ is a finite-dimensional, nonzero, inner-product space over $\Bbb{F}$, and $\Bbb{F}$ denotes $\Bbb{R}$ or $\Bbb{C}$. My thought is : suppose $T$ is a positive operator; thus, $T$ is self-adjoint. Every self-adjoint operator on $V$ has a diagonal matrix with respect to some orthonormal basis of $V$. But this doesn't tell me that $T$ has distinct eigenvalues. It tells me that $V$ has an orthonormal basis consisting of eigenvectors of $V$, of course, they are linear independent, but it doesn't tell me each vector from the basis has a unique eigenvalue. It seems that, without distinct eigenvalues, I can't prove the uniqueness of positive square root.",['linear-algebra']
904782,Is there a general way to parameterize all implicit functions?,"We all know some curves can be described by $y=f(x)$ and some surfaces can be described by $z=f(x,y)$ However, there exists curves and surfaces which cannot be described by those, such as a circle and a sphere. Therefore, we introduce parameterized vector equations, which can describe them. For example, circle: $\vec r(t)=r\cos(t)\hat i+r\sin(t)\hat j$ sphere: $\vec r(u,v)=\rho\cos(u)\sin(v)\hat i+\rho\sin(u)\sin(v)\hat j+\rho\cos(v)\hat k$ However, all curves described by $y=f(x)$ and  $z=f(x,y)$ can be parameterized. For curves, $$\vec r(t)=t\hat i+f(t)\hat j$$
For surfaces, $$\vec r(u,v)=u\hat i+v\hat j+f(u,v)\hat k$$
Therefore, I think this suggests the set of all parameterized surfaces (or curves) is the super-set of the set of all surfaces (or curves) described by $z=f(x,y)$ (or $y=f(x)$). Is that correct? Now, here comes the the real challenge. A curve can also be described by an implicit function $f(x,y)=0$ and a surface can also be described by an implicit function $f(x,y,z)=0$ I have 3 questions regarding this. Can all surfaces (curves) described by an implicit function be parameterized? (If yes, then what is the general way?) Can all surfaces (curves) described by parametric vector equations be represented using implicit function? (If yes, then what is the general way?) Compare the set of all parameterized surfaces (curves) and the set of all surfaces (curves) represented by implicit function. (which is which super-set?) Sorry for the use of nontechnical terms. I use them because I don't know the technical ones. I have only started learning vector calculus last year in university. EDIT: I think my question is not too clear, so I will give an example of writing the surface $f(x,y,z)=0$ into $\vec r(u,v)$ We want to parameterize a sphere.
$$x^2+y^2+z^2-\rho^2=0$$ Let $x=\rho\cos(u)\sin(v)$, $y=\rho\sin(u)\sin(v)$, $z=\rho\cos(v)$,
$$\rho^2\cos^2(u)\sin^2(v)+\rho^2\sin^2(u)\sin^2(v)+\rho^2\cos^2(v)-\rho^2$$
$$=\rho^2\sin^2(v)(\cos^2(u)+\sin^2(u))+\rho^2\cos^2(v)-\rho^2=\rho^2-\rho^2=0$$
I want to know if there is a general way of finding $x=x(u,v)$, $y=y(u,v)$ and $z=z(u,v)$ for any given $f(x,y,z)=0$","['algebraic-geometry', 'parametric']"
