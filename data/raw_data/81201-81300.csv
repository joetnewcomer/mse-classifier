question_id,title,body,tags
1054826,"Show all roots of $\sum_{k=0}^n 2^{k(n-k)} x^k$ are real (December 6, 2014 Putnam problem)","Show that for each positive integer n, all roots of the polynomial $\sum_{k=0}^n 2^{k(n-k)} x^k$
are real numbers. I have no idea where to start. From this year's Putnam, problem B4.","['summation', 'roots', 'real-analysis', 'polynomials']"
1054870,Suppose that $G$ is a group of order $30$ and has a Sylow $5$-subgroup that is not normal.,"Suppose that $G$ is a group of order $30$ and has a Sylow $5$-subgroup that is not normal. Find the number of elements of order $1$, order $2$, order $3$, and order $5$. But this scenario can't happen. Why not? Let $G$ be a group of order $30=2 \cdot 3 \cdot 5$. The number of Sylow $2$-subgroup $n_2$ divides $15$ and has the form $n_2=2k+1$ by the Sylow theorems. Therefore $n_2=1,3,5,15$. The number of Sylow $3$-subgroup $n_3$ divides $10$ and has the form $n_2=3k+1$ by the Sylow theorems. Therefore $n_3=1,10$. The number of Sylow $5$-subgroup $n_5$ divides $6$ and has the form $n_5=5k+1$ by the Sylow theorems. Therefore $n_5=1,6$. However, since Sylow $5$-subgroup isn't normal $n_5 \neq 1$. \begin{array}{|c|c|c|c|}
\hline
n_2 & n_3 & n_5 & number \,of \,elements & Possible \\ \hline
1  & 1  & 6 & 1+1\cdot2+6\cdot4=26     & Yes \\ \hline
1  & 10 & 6 & 1+10\cdot2+6\cdot4=45    & No  \\ \hline
3  & 1  & 6 & 3+1\cdot2+6\cdot4=29     & Yes \\ \hline
3  & 10 & 6 & 3+10\cdot2+6\cdot4=47    & No  \\ \hline
5  & 1  & 6 & 5+1\cdot2+6\cdot4=31     & No  \\ \hline
5  & 10 & 6 & 5+10\cdot2+6\cdot4=49    & No  \\ \hline
15 & 1  & 6 & 15+1\cdot2+6\cdot4=41    & No  \\ \hline
15 & 10 & 6 & 15+10\cdot2+6\cdot4=59   & No  \\ \hline
\end{array} Where do I go from here?",['group-theory']
1054873,Marginally continuous measures,"Consider a continuous density f
  on $\mathbb{R}^{2}$, and suppose that $\mu$
  is the corresponding Lebesgue-Stieltjes measure on the product space $\left(\mathbb{R}^{2},\,\mathcal{B}\left(\mathbb{R}^{2}\right)\right)$. Suppose that the respective marginals are given by $\mu_{1}$, and $\mu_{2}$, also representing the continuous marginal densities of f. Is it true that the measure $\mu$
  is absolutely continuous with respect to the product measure $\mu_{1}\times\mu_{2}$? I've been able to work out that this is true on cylinder sets, and have seen it stated as being true elsewhere without details, but cannot work it out completely. Any help would be appreciated. Thank you.","['probability-theory', 'measure-theory', 'probability', 'real-analysis']"
1054887,geometric interpretation of $\vec v \cdot \operatorname{curl} \vec v = 0 $,"There is a family of surfaces orthogonal to the vector field $\vec v \in \mathbb R^3$ iff $\vec v \cdot  \operatorname{curl} \vec v = 0 $. Now the necessity part is trivial, but the proof of sufficiency I have seen in physics textbooks, e.g. Kestin: Thermodynamics, is kind of mindless integration similar to the one usually offered to prove Poincare's lemma as in Flanders, or just asserted as in Born&Wolf: Optics. Is there an intuitive and geometric interpretation of this condition that would make it obvious why its sufficiency must be true?",['differential-geometry']
1054903,How do you work with the space of circles on the sphere considered as the projective line?,"I'm trying to prove some things about the action of the Möbius group on the ""circlines"" in the extended complex plane, ie. circles on $\mathbb{C}P^1$. I find that while I have a good grip on Möbius transformations (as $PSL(2, \mathbb{C})$), I don't really know how I'm supposed to treat circles. Points on the sphere are lines in $\mathbb{C}^2$, so I'm wondering if there's a way to represent circles as things in $\mathbb{C}^2$. More concretely, let $X$ be a circle in $\mathbb{C}P^1$, and $\pi : \mathbb{C}^2 \setminus 0 \to \mathbb{C}P^1$ the quotient map. What is $\pi^{-1}(X)$? EDIT : Many thanks to John Hughes for helping me figure out some of the earlier parts of my question: Abstractly speaking, is the space of circles on the sphere a manifold?
  Or maybe some sort of space with singularities? What dimension is it?
  How do I work with it? It seems that circles on the sphere do in fact form a manifold which is double covered by $S^2 \times (-1,1)$ or $S^2 \times [-1,1]$ depending on whether degenerate circles (=points) are allowed. The space of circles is one of the above manifolds quotiented by the relation $(x,y) \sim (-x,-y)$. The quotient of the former becomes a manifold, and the quotient of the latter becomes a manifold with boundary.","['differential-topology', 'geometry', 'projective-geometry']"
1054907,How to integrate $\int \frac{1}{\sqrt{1+29x^2+100x^4}}dx$ and $\int \frac{1}{\sqrt{1-2x^2-8x^4}}dx$ using elliptic functions?,"How to integrate $$\int \frac{1}{\sqrt{1+29x^2+100x^4}}dx$$ and $$\int\frac{1}{\sqrt{1-2x^2-8x^4}}dx$$  using elliptic functions? I have tried to use them, but I got incorrect formula $$\frac{1}{\sqrt{2}}F(arctan(\sqrt{2}x)∣3)$$ for the first one (second argument should be less or equal 1). Could anyone solve it? Thanks","['calculus', 'integration', 'indefinite-integrals']"
1054917,"Is $SL(2, 3) $ a subgroup of $SL(2, p)$ for $ p>3$?","As the title says, I was wondering whether $SL(2,3)$ is a subgroup of $SL(2,p)$ for $p>3$.  I know that it is for $p=5$ (it can be found explicitly using the quaternionic representation), and I have some evidence that it is for the other $p$'s, but I'm not sure how I would go about proving it, or indeed if it's true! If anybody knows one way or another, please let me know.  If it's true, it would be helpful to give a hint about how I might think about proving it, but please don't give a proof as I'd like to figure it out myself.","['finite-groups', 'group-theory', 'representation-theory']"
1054921,Algebraic function $u\in C^\infty(\Bbb R^n)$,Suppose $u\in C^{\infty}(\mathbb{R})$ is an algebraic function that has no singularities. Can it be said that $u$ is a polynomial? If instead $u\in C^\infty(\Bbb R^n)$ and is an algebraic function. Is it also a polynomial?,"['algebraic-geometry', 'real-algebraic-geometry']"
1054926,Induced Lie group action on a tangent bundle $TG\times TM\to TM$ and an example concerning Adjoint action,"Suppose I have a Lie group action 
$$
G\times M\to M, (g,m)\mapsto g\cdot m.
$$ 
which is transitive on $M$, then the tangent functor $T$ induces a corresponding map:
$$
TG\times TM\to TM, (\delta g,\delta m)\mapsto \delta g\cdot m+g\cdot\delta m.
$$
Note that given the group operation of $G$:
$$
G\times G\to G, (g,h)\mapsto g\cdot h.
$$
$TG$ can be induced a Lie group structure by:
$$
\delta g\star\delta h:=\delta (g\cdot h)=\delta g\cdot h+g\cdot\delta h.
$$
The group axioms can be verified as follows: closure: trivial; identity: $0_e$ where $e$ is the identity of $G$; inverse: $(\delta g)^{-1}=\delta(g^{-1})$; associativity: 
$$
(\delta g\star\delta h)\star\delta k=\delta(g\cdot h)\star\delta k=\delta (g\cdot h\cdot k)=\delta g\star\delta(h\cdot k)=\delta g\star(\delta h\star\delta k).
$$
Under this particular group operation of $TG$, the induced map $TG\times TM\to TM$ defines a Lie group action of $TG$ on $TM$, which is evident from Leibniz rule. And in particular it should be transitive too. Questions: I would like someone to verify for me my above claims first. If there is a good reference about it, I would very much like to know. Is it possible to define an induced action $TSO(3)\times TS^2\to TS^2$ from:
$$
SO(3)\times S^2\to S^2, (R,r)\mapsto Rr
$$ 
such that it corresponds exactly to the Adjoint action $SE(3)\times se(3)\to se(3)$? (see the comments below) Some follow-up comments: One of the main applications is a generalization of the action $SO(3)\times S^2\to S^2$ (with $SO(3)$ considered as a Lie subgroup of $SE(3)$) to the whole of $SE(3)\simeq TSO(3)$ on $TS^2$:
$$
\begin{split}
\psi:SE(3)\times TS^2&\to TS^2, \\
(\hat pR,\delta r)&\mapsto \hat pRr+R\delta r.
\end{split}
$$
where $p\in\mathbb R^3, R\in SO(3), r\in S^2$ and $\wedge$ is defined by:
$$
\wedge:(x,y,z)^T\mapsto\left[\begin{array}{ccc}
0 & -z & y\\
z & 0 & -x\\
-y & x & 0
\end{array}\right]
$$
and investigate its connection to Adjoint transformation:
$$
Ad:SE(3)\to\mathfrak{gl}(se(3))
$$
To see the connection, define a $\xi\in se(3)$ for $\delta r\in TS^2$ by:
$$
\xi:=\left[\begin{array}{cc}\hat r & r\times\delta r\\
0 & 0 
\end{array}\right], r\in S^2.
$$ Unfortunately, the induced action $TSO(3)\times TS^2\to TS^2$ is not consistent with the Adjoint action. I am looking for an alternative action $TSO(3)\times TS^2\to TS^2$ such that it is.","['lie-groups', 'differential-geometry']"
1054934,Is there always a mapping from invertible $A$ to any $B \in M_n(\Bbb R)$?,"Let $A, B$ be $n\times n$ matrices, then $1)$ If $A$ is invertible then for every $B$ exists a matrix $X \in M_n(\Bbb R)$ such that $AX = B$. $2)$ If for every $B$ there exists a matrix $X \in M_n(\Bbb R)$ such that $AX = B$ then $A$ is invertible. For $1)$ I started with: $AX=B \implies X=A^{-1}B$ But I'm not sure I can do this: $$A(A^{-1}B)=B$$
$$(AA^{-1})B=B$$ --> not sure about this $$ IB = B $$ Am I right about the first part? How should I prove the second part? thanks","['matrices', 'linear-algebra']"
1054939,Generalization of Central Limit Theorem?,"In my probability class we learned the Central Limit Theorem in the following form. Theorem: Let $\{X_i\}_{i=1}^\infty$ be a sequence of independent identically distributed random variables and suppose that $E(X_i)=\mu$, $\operatorname{Var}(X_i)=\sigma^2<\infty$. Then, $$\sqrt{n}\frac{\frac{1}{n}\sum_{i=1}^nX_i-\mu}{\sigma}\stackrel{P}{\longrightarrow}N(0,1),\quad\text{as }n\to\infty$$ in probability, where the notation $N(\mu,\sigma^2)$ means normal distribution of mean $\mu$ and variance $\sigma^2$. Now, if we remove $\sigma$ and $\mu$, do we get
$$\sqrt{n}\frac{1}{n}\sum_{i=1}^nX_i\stackrel{P}{\longrightarrow}N(\mu,\sigma^2)?$$
This seems very natural, but I cannot prove it. Is it true? I think I can prove it by removeing only $\sigma$, but I am not sure for $\mu$.",['probability']
1054954,Sturm-Liouville problem and periodic boundary conditions,"I was wondering about this: I know that if a 1-d Sturm-Liouville operator is limit circle or limit point then the eigenvalues are simple ( so no degenerated spectrum). But in the case of periodic boundary conditions it is actually possible that two eigenvalues agree, that's why people talk about spectral gaps, I think. Now if I have a regular Sturm-Liouville problem, then my operator is l.c. at both end-points, right?-So my spectrum should be simple. Thus, I have troubles to understand how the fact that two eigenvalues may agree for periodic boundary conditions fits into this l.c. and l.p. picture?","['operator-theory', 'spectral-theory', 'real-analysis', 'analysis', 'functional-analysis']"
1054971,The measure of the boundary being zero implies the set is measurable.,"Assuming our set, $E\subset\mathbb{R}^2$ such that $m(\partial E)=0$ (where $m$ is Lebesgue measure), why does this imply that $E$ is Lebesgue measurable?","['measure-theory', 'real-analysis']"
1054976,Help with understanding this proof in discrete mathematics?,"This is the question and solution: Q: Prove that for any integer $a$, $2a + 1$ and $4a^2$ + 1 are relatively prime.
A: Since $4a^2 + 1 = (2a − 1)(2a + 1) + 2$, any common divisor of $2a + 1$ and $4a^2 + 1$
must be a divisor of $2$ . This means that $d=1$ or $d=2$. However, $2$ is not a common divisor as both $2a + 1$ and $4a^2 + 1$ are odd. Therefore, the greatest common divisor must be $1$. Can someone explain how they knew that the common divisor of $2a + 1$ and $4a^2 + 1$ would be a divisor of $2$ (the bolded portion)? Is this some number theory that I just don't know? 
Also, this topic is $\gcd$ (greatest common divisor in discrete mathematics). Thanks in advance.","['elementary-number-theory', 'divisibility', 'discrete-mathematics']"
1054992,"Uniqueness of conformal mappings with different normalizations: three boundary points, or an interior point","Some stuff I've seen in lecture but am still a little shaky on: 1)  To determine my mapping explicitly, it suffices to know where 3 distinct points on my pre-image object, say, the unit circle, gets mapped to.  Say I construct my mapping so that 3 points, 1,0,-1 goes to 1,0,-1, respectively.  Why is this enough?  I've done some problems, using the cross-ratio and solving for my mapping, w(z), but I don't know with confidence why mapping 3 points is enough. 2)  Sticking with the example above, how come knowing where just one point on the interior of the pre-image circle gets mapped to...tells us where all of the interior of the pre-image circle gets mapped to - in this case, it would be either the interior of the image circle or the exterior of the image circle.  I vaguely know that this comes from a connectedness argument from introductory real analysis (advanced calculus); that a continuous mapping maps connected sets to connected sets - as well as compact sets to compact sets.  I feel like ...if most of the interior of the pre-image disk gets mapped to the interior of the image disk, but some of the pre-image points in the disk gets mapped to ...the exterior of the image disk, isn't the image...still connected / path-connected? I know that LFTs must map circles and lines to circles or lines.  Is this the key point that I am not considering? That perhaps...the boundary, i.e., the circle ""separates"" the image plane into two disjoint sets, so if preimage points land on the exterior of the image disk, then, in fact, my image is not path-connected?","['conformal-geometry', 'complex-analysis']"
1055004,How does algebra on differential forms work?,"Let $\omega$ be a 1-form such that:
$\omega = a\,dx + b\,dy$
and $\eta$ is a 0-form. I've seen a lot of times where $\eta \wedge \omega$ is written as $\eta \omega$... which kind of makes sense as $\eta \wedge \omega = (\eta a)\,dx  + (\eta b)\,dy$. But is the first term, $(\eta a)\,dx$, the same thing as $\eta (a\,dx)$? Also, is $a\,dx = a \wedge dx$? Is $dx$ a 1-form?
In general, if $\eta$ is a 0-form, does that mean $\eta \wedge \omega = \eta \omega$? I'm just really confused about the algebraic structure of differential forms, and this notation doesn't really help. I've been told to treat the wedge product of two forms like multiplying polynomials with the $dx_i$ being ""wedged"" and the ""coefficients"" simply being multiplied together, so: $$(a\,dx+b\,dy) \wedge (e\,dx+f\,dy) = ae \,dx \wedge dx + af\, dx \wedge dy + be\, dy \wedge dx + bf\, dy \wedge dy$$
Can't we derive this somehow by considering $a\,dx$ as $a \wedge dx$ along with anticommutativity and associativity, instead of defining this case separately? What exactly is the interplay between this multiplication implicit in $a\,dx$ and the wedge product? Is $dx$ itself a 1-form, or do we just treat it as just some ""thing""? Does it really make a difference in anything? Also, if someone could give me a reference to any text regarding this, that would be great.",['multivariable-calculus']
1055006,Deciding whether series containing $a_n$ are convergent knowing that $\lim_{n\rightarrow\infty}\frac{\frac{(-1)^n}{\sqrt{n}}}{a_n}=1$,"We know the following thing about sequence ${a_n}$: $$\lim_{n\rightarrow\infty}\frac{\frac{(-1)^n}{\sqrt{n}}}{a_n}=1$$ And now the problem asks us whether it's true for every such $a_n$ that: $\sum_{n=1}^{+\infty} a_n$ is convergent $\sum_{n=1}^{+\infty} \frac{a_n}{n}$ is convergent $\sum_{n=1}^{+\infty} \frac{a_n}{n}$ is absolutely convergent So even though the upper statement looks like we should do something with limit comparison test, I think we cannot do that as we know  that $a_n > 0$ is not true for every such $a_n$. Intuitevely all of these points should be true but what should I use in order to prove that?","['convergence-divergence', 'sequences-and-series', 'summation', 'limits']"
1055021,"In a game, $0.38$ buy hotdogs, how large an order should she place if she wants to have no more that a 20% chance of demand exceeding supply?.","A sell-out crowd of 42,200 is expected at Cleveland's Jacobs Field for next Tuesday's game with the Baltimore Orioles, the last before a long road trip. The ballpark's records from games played either in the season, she knows that, on the average, 38% of all those in attendance will buy a hot dog. How large an order should she place if she wants to have no more that a 20% chance of demand exceeding supply?. Attempt: Let $X$ = amount of order. Here X is a binomial distribution with $p = 0.38$ and $n = 42,200$. Then $P(X > x) = 0.20$  $\rightarrow$ $P(X \leq x) = 0.80$. Then from the continuity correction we have $P(X \leq x)$ = $P(\frac{(x - np)}{\sqrt{np(1-p)}} \leq \frac{(X - 42,200(0.38))}{\sqrt{42,200(0.38)(1-0.38)}}) = 0.80$ Then putting $P( z \leq \frac{(x - 42,200(0.38))}{\sqrt{42,200(0.38)(1-0.38)}}) = P(z  \leq \frac{x - 16036}{99.7111}) = 0.80$ I know I have to use the standard normal table to determine where $\frac{x - 16036}{99.7111}$ is about the standard normal table, then solve for $x$. But I don't know how to continue. Can anyone please help? Any feedback/help can help.
Thank you.","['statistics', 'normal-distribution', 'probability', 'random-variables']"
1055041,Nonlinear Differential Equation question,"I have a nonlinear Diffeq: $$\frac{d^2x}{dt^2}+\beta \frac{dx}{dt}+\epsilon \times e^{- \lambda x} = f(t) $$ where $f(t)$ is a function that is known, and $\beta$ and $\lambda$ are constants that are known. Also, we know that $\epsilon$ is a constant parameter that is small. I first need to obtain the zero order solution $x_0$, before finding the first order solution $x_1$ The first thing that I need to do is to use asymptotic expansions to obtain solutions of order $\epsilon=0$ and (TYPO) Note that general solution for f(t) that will have two unknown constants. UPDATE: After the first order term is solve, it needs to be plugged back in. The exponential needs to be linearized and things should start cancelling out. I am not sure how to do this, I just know this is what needs to be done. UPDATE2: Correction, $\epsilon = 1$ was a typo. It should be $\epsilon^1$
I need to find a solution in the form: $$x(t)=x_0(t)+\epsilon^1x_1(t)+\epsilon^2x_2 (t) + ... $$ So initially, $\epsilon$ needs to be set to 0 in order to obtain $x_0$. To find $x_1$, I need $\epsilon^1$ UPDATE3: I know now that I need to plug: $$x=x_0+\epsilon_1x_1 $$ back into the original equation Thus: $$\frac{d^2}{dt^2}(x_0+\epsilon_1x_1) + \beta\frac{d}{dt}(x_0+\epsilon_1x_1)+\epsilon \times exp(-\lambda(x_0+\epsilon_1x_1))  $$ Then $$\frac{d^2}{dt^2}x_0+\frac{d^2}{dt^2}\epsilon_1x_1+\beta \frac{d}{dt}x_0 +\beta \frac{d}{dt}\epsilon_1 x_1+\epsilon \times exp(-\lambda x_0))+\epsilon \times exp(-\lambda \epsilon_1 x_1)$$ I think then the $x_0$ terms may cancel with f(t) or something like that? It may be some sort of approximation. I still need to linearize the exponential. Any help is appreciated. Update4: Taking the solution a little but further... We know that: $$\frac{d^2x_0}{dt^2}+\beta \frac{dx_0}{dt} = f(t) $$ So, those terms all cancel. And now we have:
$$\frac{d^2}{dt^2}\epsilon_1x_1 +\beta \frac{d}{dt}\epsilon_1 x_1+\epsilon \times exp(-\lambda(x_0+\epsilon_1x_1))=0$$ But we dont want $\epsilon^2$ terms, to part of the exponential goes away as well. We are left with:
$$\frac{d^2}{dt^2}\epsilon_1x_1 +\beta \frac{d}{dt}\epsilon_1x_1+\epsilon \times exp(-\lambda x_0)=0$$ Where we know $x_0$. This now means that the exponential is no longer a function of arbitrary x. I feel like the solution should be trivial now, but I am having a hard time finding it. Any ideas? Can this be solved with the method of undetermined coefficients? UPDATE5: Well I have updated this problem several times with very little response. As a latch ditch effort, is there anyone who can offer any advice on how to solve: $$\frac{d^2x_1}{dt^2}  +\beta \frac{dx_1}{dt} +  exp{-\lambda x_0}=0$$ where $x_0$ is known",['ordinary-differential-equations']
1055046,"Show that $\|B^{-1/2}AB^{-1/2} - I\| >1/2$, when $\|A\|>2\|B\|$","Let $A,B$ be two positive-definite matrices. Suppose that $\|A\|>2\|B\|$. Is it possible to show that $\|B^{-1/2}AB^{-1/2} - I\| >1/2$, where $I$ is an identity matrix and the norm is the supremum norm.","['matrices', 'operator-theory']"
1055064,Simply-connected Lorentzian manifold and event horizon,Can a simply connected Lorentzian manifold admit an event horizon? Or does the event horizon makes it non-simply connected?,"['mathematical-physics', 'differential-geometry', 'general-relativity']"
1055087,Chess board combinatorics,"STATEMENT: A dolphin is a special chess piece that can move one square up, OR one square right, OR one square diagonally down and to the left. Can a dolphin, starting at the bottom-left square of a chessboard, visit each square exactly once? QUESTION: How would one approach this type of problem. It seems that whatever way the dolphin moves the maximum moves always involve the dolphin to traverse an 6x8 square.","['problem-solving', 'combinatorics']"
1055100,How to use Cauchy-Scharw inequality to prove continuity of a function?,"I'm attempting to understand how to prove the function f such that $$f(x,y)=\frac{x^3y}{x^4+y^2}\;if\;(x,y)\neq (0,0)$$ $$f(x,y)=(0,0)\;if\;(x,y)=(0,0)$$
is continuous in $\mathbb R^2$.
The solution provided says to use the Cauchy-Schwarz inequality to show that $|x^3y|=|x^2yx|\le \frac{(x^2)^2+y^2}{2}|x|$, and thus the function is lesser than or equal to $\frac{|x|}{2}$, and thus the limit goes to 0 as (x,y) goes to to (0,0).  I understand the limit part, but not the use of the inequality.  How do I use Cauchy-Schwarz to obtain this inequality","['inequality', 'multivariable-calculus', 'calculus', 'continuity']"
1055114,Mangoldt Lambda Sum Rearrangement (from proof of Logarithmic Derivative of Riemann zeta function),"Also, we have by the definition of Λ, $$\sum_{n\geq 1} \Lambda(n) n^{−s} = \sum_p(\log p) \sum_{n \geq 1}p^{−ns}$$ (From https://proofwiki.org/wiki/Logarithmic_Derivative_of_Riemann_Zeta_Function ) This step is apparently so trivial that it needn't be included in the proof, but I cannot work out how it works. I know that it's a relatively straightforward step, but I have no idea...","['analytic-number-theory', 'complex-analysis']"
1055116,Operator topologies and examples,"In class we covered several operator topologies: the weak topology,  the weak* topology,  the weak operator topology, and the strong operator topology.  The first two are defined on a normed vector space $V$ and its dual $V$* resp., and the latter two are defined on $L(X,Y)$ for Banach spaces $X$ and $Y$. However, I wasn't in class when we covered this so I'd like to ask: what motivates the above topologies, and are there any (relatively elementary) examples?  The relevant section in Folland does not say much outside of describing convergence and Alaoglu's theorem.","['general-topology', 'topological-vector-spaces', 'functional-analysis']"
1055188,"Why is the extension $k(x,\sqrt{1-x^2})/k$ purely transcendental?","Consider the function field $k(x,\sqrt{1-x^2})$ of the circle over an algebraically closed field $k$. Is $k(x,\sqrt{1-x^2})$ a purely transcendental extension over $k$? I'm curious because I was reading the answer here . The proof shows $k(x+\sqrt{1-x^2})=k(x,\sqrt{1-x^2})$. However, there is line which says, 
$$
(x+\sqrt{1-x^2})^2 = x^2 + 2 \sqrt{1 - x^2} + (1 - x^2) = 2 \sqrt{1-x^2} + 1.
$$
But I think
$$
(x+\sqrt{1-x^2})^2 = x^2 + 2x\sqrt{1 - x^2} + (1 - x^2)=2x\sqrt{1-x^2}+1
$$
so, assuming $\operatorname{char}(k)\neq 2$, I believe at most one can conclude is $x\sqrt{1-x^2}\in k(x+\sqrt{1-x^2})$. I've been struggling to salvage this. How can you show $k(x,\sqrt{1-x^2})$ is a purely transcendental extension over $k$? Is the extension still purely transcendental when $\operatorname{char}(k)=2$?","['algebraic-geometry', 'extension-field', 'algebraic-curves', 'abstract-algebra', 'field-theory']"
1055209,"Let $M(n,\mathbb R)$ denote set of all $n\times n$ matrices over $\mathbb R$.Which are true:","Let $M(n,\mathbb R)$ denote set of all $n\times n$ matrices over $\mathbb R$.Which are true: 1.If $A\in M(2,\mathbb R)$ is nilpotent and non-zero ,then there exists a matrix $B\in M(2,\mathbb R)$ such that $B^2=A$ 2.If $A\in M(n,\mathbb R)$ is symmetric  and positive definite  ,then there exists a symmetric matrix $B\in M(n,\mathbb R)$ such that $B^2=A$ 3.If $A\in M(n,\mathbb R)$ is symmetric  ,then there exists a symmetric matrix $B\in M(n,\mathbb R)$ such that $B^3=A$ I dont know how to approach these?",['linear-algebra']
1055225,random walk on finite cyclic group,"Suppose that I have a random walk on the finite cyclic group of order $d > 2$, where the initial probability distribution $Q$ assigns the values $p, q, r$ to $-1, 0, 1$, respectively, where $p + q + r = 1$. I understand the behavior quite well when $p, q, r$ are taken to be all ${1\over3}$, but I don't understand it as well here. For which values of $p, q, r$ does the corresponding random walk converge to the uniform distribution? When we do have convergence, what is the rate of convergence? For which values of $p, q, r$ is this rate maximized? Minimized?","['random-walk', 'representation-theory', 'probability-theory', 'group-theory', 'combinatorics']"
1055241,"From the viewpoint of modern geometry, is there a ""best"" definition of the term ""triangle""?","I can think of at least six different possible definitions of the term ""triangle"" in Euclidean geometry. a subset of $\mathbb{R}^n$ that can be expressed as the convex hull of three or fewer points. a subset of $\mathbb{R}^n$ that can be expressed as the convex hull of three points, but no fewer. A function $\{0,1,2\} \rightarrow \mathbb{R}^n$. A function $\{0,1,2\} \rightarrow \mathbb{R}^n$ whose multiset image is an affinely independent subset of $\mathbb{R}^n$. A point $p \in \mathbb{R}^n$ together with two vectors in $T_p,$ the tangent space at $p$. A point $p \in \mathbb{R}^n$ together with two linearly independent vectors in $T_p$. From the viewpoint of modern geometry, is there a ""best"" definition of the term ""triangle"" that generalizes most easily to e.g. Riemannian manifolds and beyond? And what framework (e.g. Riemannian manifolds) does this definition belong to?","['geometry', 'definition']"
1055248,$G/Z(G)$ is cyclic useful for proving groups abelian?,"It's a common exercise to prove in an abstract algebra book that if $G/Z(G)$ is cyclic then $G$ must be abelian. But I've always found the exercise strange because if $G$ is abelian then $Z(G)=G$ and the quotient is trivial. Is there a specific example of this being a useful technique to proving a group is abelian? As it seems  you must know enough about a specific group $G/Z(G)$ to proves it's cyclic, but not enough to notice that it the trivial group, which would prove the commutativity of $G$ immediately.","['group-theory', 'abstract-algebra', 'abelian-groups']"
1055286,Prove that $n^2 > n+1 \quad\forall n \geq 2$ using mathematical induction,"Prove $n^2 > n+1$ for $ n \geq 2$ using mathematical induction So I attempted to prove this, but I'm not sure if this is a valid proof. Base case, $n = 2$
$$
2^2 > 2+ 1 
$$
$n = k + 1$, induction on $n$
$$
(k+1)^2 > k + 2
$$
$k^2 + 2k + 1 > k + 2$ and by assumption, we know that $k^2 > k + 1$. so we can now write:
\begin{gather}
k^2 + 2k + 1 > 2k + 2\\
k^2 + 1 > 2\\
\end{gather}
$k^2 -1 > 0$ and since $n$ has to be $\geq 2$, the left hand side of the inequality will always be positive, making the statement a tautology. Does this prove the original statement? If not, how do you do it?","['inequality', 'induction', 'discrete-mathematics', 'proof-verification']"
1055302,"$M \times N$ orientable if and only if $M, N$ orientable [duplicate]","This question already has answers here : Product of manifolds & orientability (2 answers) Closed 5 years ago . For two manifolds $M$ and $N$ I'm trying to prove that $M \times N$ is orientable if and only if $M$ and $N$ are orientable. My attempt so far: $\impliedby)$ Assume $M, N$ are orientable. Then $\widetilde{M}$ and $\widetilde{N}$ the orientation double covers of $M$ and $N$ are disconnected. But $\widetilde{M} \times \widetilde{N}$ is the orientation double cover for $M \times N$. Since $\widetilde{M}, \widetilde{N}$ are disconnected certainly $\widetilde{M} \times \widetilde{N}$ is disconnected. Therefore, $M \times N$ is orientable. $\implies)$ Proceed by contradiction. Assume $M \times N$ is orientable and WLOG $M$ is nonorientable. Then the orientation double cover $\widetilde{M\times N}$ is disconnected.
Now note that $\widetilde{M}$ is connected since $M$ is nonorientable. So $\widetilde{M} \times \widetilde{N}$ is connected since the product of a connected space and a disconnected space is connected. But $\widetilde{M\times N} = \widetilde{M} \times \widetilde{N}$, so $\widetilde{M\times N}$ is connected. But this is a contradiction, therefore it must be that $M$ is orientable. This completes our proof. The validity of this proof hinges on two assumptions that I'm unsure about:
1. $\widetilde{M\times N} = \widetilde{M} \times \widetilde{N}$
2. The product of a connected space and a disconnected space is connected. Are these two facts true? Is my proof valid? How do I go about proving these two necessary assumptions if they are indeed true? If I'm totally going the wrong way could someone send me in the proper direction? Thanks","['general-topology', 'principal-bundles', 'manifolds', 'algebraic-topology']"
1055317,"If $g(x) = \max(y^2-xy)(0 \leq y\leq 1)\;,$ Then minimum value of $g(x)$","If $g(x) = \max\limits_{0 \leq y\leq 1}(y^2-xy)$, then minimum value of $g(x)$ $\bf{My\; try::}$ We can write  $\displaystyle f(y) = y^2-xy = y^2-xy+\frac{x^2}{4}-\frac{x^2}{4} = \left(y-\frac{x}{2}\right)^2-\frac{x^2}{4}$ Now when $y=0\;,$ Then expression $f(0) = y^2-xy=0$ Now when $y=1\;,$ Then expression $f(1) = (1-x).$ So $\displaystyle g(x) = \max\left(f(0)\;,f(1),f\left(\frac{x}{2}\right)\right)$. Now How can i solve after that, Help me Thanks",['algebra-precalculus']
1055318,Solving $2\cos^2 x-2\sin^2 x-2\cos x=0$,"$$f(x) = 2\cos^2 x-2\sin^2 x-2\cos x$$ Need values of x that which make $f(x) = 0$ Tried $a^2-b^2 = (a+b)(a-b)$ with no luck Really just need a hint that could bring me in the right direction Thanks EDIT: Solution thanks to everyones help! :D 
$$f(x) = 2\cos^2 x-2\sin^2 x-2\cos x$$
$$0 = 2\cos^2 x-2 + 2\cos^2 x-2\cos x$$
$$0 = 4\cos^2 x-2\cos x - 2$$
$$\cos x = 2\pm \sqrt {-2^2-4(4)(-2)\over8}$$
$$\cos x =  {2 \pm 6\over 8}$$
$$\cos x = {-1\over2}, 1$$
$$x = 2n\pi \pm{2\pi\over3}$$ Thank you!","['trigonometry', 'algebra-precalculus']"
1055333,Summable family in a normed linear space,"I learnt a definition: Let $X$ be a normed linear space and $J$ be a non-empty set. A family $x:J\rightarrow X$ is summable with sum $\overline{x}$ if for all $\epsilon>0$, there exists a finite subset $M_0$ of $J$ such that whenever $M_0\subset M\subset J$ with $M$ finite, $$\|\overline{x}-\sum_{j\in M}x_j\|<\epsilon.$$ I wondered whether this definition extended the usual notion of the convergence of a series. This is what I thought: Let $J=\mathbb{N}$. If $x_1,x_2,\dots$ is summable with sum $\overline{x}$ as in the above definition, then $\sum_{n=1}^\infty x_n=\overline{x}$ in the usual sense. However, $\sum_{n=1}^\infty x_n$ being convergent does not imply that  $x_1,x_2,\dots$ is summable as in the above definition. For example, take $X=\mathbb{R}$ and take $x_n=(-1)^nn^{-1}$. However, if $X$ is complete and $\sum_{n=1}^\infty x_n$ is absolutely convergent i.e. $\sum_{n=1}^\infty \|x_n\|<\infty$, then $x_1,x_2,\dots$ is summable as in the above definition. So $x_1,x_2,\dots$ being summable is weaker than $\sum_{n=1}^\infty \|x_n\|<\infty$, but is ""strictly stronger"" than  $\sum_{n=1}^\infty x_n$ being convergent. Does anyone know if $x_1,x_2,\dots$ being summable is equivalent to $\sum_{n=1}^\infty \|x_n\|<\infty$?","['functional-analysis', 'banach-spaces']"
1055340,"How many critical values does $f$ have on $(0,10)$, given $f '(x)=\frac{\cos^2 x}{x} -\frac{1}{5}$?","How many critical values does $f$ have on open interval $(0, 10)$ given $$f'(x) = \frac{\cos^2x}{x} - \frac{1}{5}$$ I'm in calculus AB and this is a review question. I think the next step is to make it
$$\cos x = \sqrt{\frac{x}{5}}$$ But I am not really sure.","['calculus', 'derivatives']"
1055351,Problem about cyclic quadrilaterals,"In cyclic quadrilateral ABCD,
let E, F, G, H be the orthocenters of triangles BCD, CDA, DAB, ABC, respectively. Prove that EFGH is cyclic. Progress So far, found that if  E   is orthocenter of BCD and F is orthocenter of CDA, then EF||AB.","['geometry', 'quadrilateral', 'circles']"
1055352,How to solve $x^{2/3}=4$?,"OK I know this sounds pretty stupid, but I am stuck on solving $x^{{2}/{3}}=4$. I rewrote it to $\sqrt[3]{x^2}=4$, but I don't know what to do next. Would the radical go away if I took the $\sqrt[3]{x^2}=4$ by the $3$rd power? Then it would become $ x^6=64$?","['radicals', 'algebra-precalculus']"
1055379,Evaluating a product of tangents,"(1) Evaluation of $\displaystyle \tan \left(\frac{\pi}{7}\right)\cdot \tan \left(\frac{2\pi}{7}\right)\cdot \tan \left(\frac{3\pi}{7}\right) = $ (2) Evaluation of $\displaystyle \tan\left(\frac{\pi}{11}\right)\cdot \tan\left(\frac{2\pi}{11}\right)\cdot \tan\left(\frac{3\pi}{11}\right)\cdot \tan\left(\frac{4\pi}{11}\right)\cdot \tan\left(\frac{5\pi}{11}\right) = $ $\bf{My\; Try::(1):}$ Let $\displaystyle \frac{\pi}{7} = \theta\Rightarrow \pi = 7\theta\Rightarrow (\pi-3\theta) = 4\theta\Rightarrow \tan(\pi-3\theta) = \tan(4\theta)$ So $\displaystyle \tan (3\theta) = -\tan (4\theta)\Rightarrow \frac{3\tan \theta - \tan^3\theta}{1-3\tan^2 \theta} = -\left(\frac{2\tan 2\theta}{1-\tan^2 2\theta}\right) = \frac{4\tan^3 \theta-4\tan \theta}{1+\tan^4 \theta-6\tan^2 \theta}$ So $\displaystyle \left(\frac{3-\tan^2 \theta}{1-3\tan^2 \theta}\right) = \left(\frac{4\tan^2 \theta-4}{1+\tan^4 \theta-6\tan^2 \theta}\right)\Rightarrow \tan^6\theta-21\tan^4 \theta+21\tan^2 \theta-7=0$ Now Let $\displaystyle \tan \theta = y\;,$ then eqn. convert into $\displaystyle y^6-21y^4+21y^2-7=0$ and equation has a roots $\displaystyle y = \tan \left(\frac{\pi}{7}\right)\;,\tan \left(\frac{2\pi}{7}\right)\;,\tan \left(\frac{3\pi}{7}\right)\;,\tan \left(\frac{4\pi}{7}\right)\;,\tan \left(\frac{5\pi}{7}\right)\;,\tan \left(\frac{6\pi}{7}\right)\;$ . So Product of Roots is $\displaystyle \tan \left(\frac{\pi}{7}\right)\cdot \tan \left(\frac{2\pi}{7}\right)\cdot \tan \left(\frac{3\pi}{7}\right)\cdot \tan \left(\frac{4\pi}{7}\right)\cdot \tan \left(\frac{5\pi}{7}\right)\cdot \tan \left(\frac{6\pi}{7}\right) = -7$ Now $\displaystyle \tan\left(\frac{4\pi}{7}\right) = \tan\left(\pi-\frac{3\pi}{7}\right)=-\tan\left(\frac{3\pi}{7}\right)$ Similarly $\displaystyle \tan\left(\frac{5\pi}{7}\right) = -\tan\left(\frac{2\pi}{7}\right)$ and $\displaystyle \tan\left(\frac{6\pi}{7}\right) = -\tan\left(\frac{\pi}{7}\right)$ So $\displaystyle \tan\left(\frac{\pi}{7}\right)\cdot \tan\left(\frac{2\pi}{7}\right)\cdot \tan\left(\frac{3\pi}{7}\right)=\sqrt{7}$ I did not understand how can i calculate $(2)$ one using the same method:, bcz it is very lengthy can we solve the $(1)$ and $(2)$ question any other method. If yes then plz explain me, Thanks :: Thanks",['trigonometry']
1055413,Find sectors in a racing line.,"Consider the following photo: To magnify image, right click and select open-image in new tab or something similar The photo above is a random race circuit data I've collected. What I'm trying to do is find the corner entry , and corner exit . The path in the middle would be known as sector . The corner entry and exits are labelled in green in the following image, (Note where they are position in the road is the job of my AI algorithm thus for this, we are placing these entry and exit points in the middle). The following are the observations I made for the entry/exist points: entry have close to zero slope and then a change of slope. exit have changing slopes before it until a point with zero slopes is hit. For corners with ""S"" like formation, the inflection point is both an entry/exit point. Also we are ignoring z-axis. My plan so far is the following: take the first derivative of each point via parametric derivative, $\dfrac{dy}{dx} = \dfrac{\dfrac{dy}{dt}}{\dfrac{dx}{dt}}$. From (1), I will take the vertices that have the last 0 slope prior to change of slope (indicating corner entry). From (1), I will take the vertices that is the first 0 slope after a sequence of non-zero slope, indicating corner exit. (Note that the first derivative also takes in inflection points, since inflection points have 0 slope). Problem: My plan seems to not work and places corner exit and entry in wrong places (e.g. lump in straight aways). Considering that corner entry often have gentle slopes, this sometimes doesn't place the entry point until we are deep in the corner (which is bad). I've been debugging this problem for quite a while so before I go on I have two main questions: If my idea is right (or close to right), could it be that my implementation is wrong? If you have a better method of finding corner sectors , can you share it with me? Edit: I thank both answers. My level is too low to thumbs up so I have to use prng to select one answer. Anyway, the program is working perfectly. The following is the line graph generated by curvature along the circuit: Basically, the local minimums corresponds to straight-away. It even captures the big irregular hairpin with smaller straight away. One could even incorporate filtering to avoid the noise. Again, I thank all of the answers.","['geometry', 'artificial-intelligence']"
1055438,What is the probability that a Poisson random variable is prime?,"Let $X \sim Poisson(\lambda)$, and let $k \in \mathbb{N}$. Consider the quantity $Q(\lambda,k) = P\left( X+k \in Primes\right)$. Obviously $0 < Q(\lambda,k) < 1$. How does $Q(\lambda,k)$ behave with respect to $\lambda$ and $k$? For example, is there any asymptotic behavior as $\lambda \rightarrow \infty$? Is $Q(\lambda,k)$ sensitive to the value of $k$ when $\lambda$ is large enough?","['prime-numbers', 'probability-distributions', 'probability']"
1055468,Integral: $\int_{-\infty}^{\infty} \frac{dx}{(e^x+x+1)^2+\pi^2}$,"I am looking for real analytic methods to prove the following:
$$\int_{-\infty}^{\infty} \frac{dx}{(e^x+x+1)^2+\pi^2}=\frac{2}{3}$$
I have seen a similar problem on the website but if I remember correctly, the posted solution uses contour integration. Using $\int_0^{\infty} e^{-ax}\sin(bx)\,dx=\frac{b}{a^2+b^2}$, I wrote the integral as: $$\frac{1}{\pi}\int_{-\infty}^{\infty} \int_0^{\infty} e^{-(e^x+x+1)t}\sin(\pi t)\,dt\,dx=\frac{1}{\pi}\int_0^{\infty} e^{-t}\sin(\pi t)\left(\int_{-\infty}^{\infty} e^{-e^x t}e^{-xt}\,dx\right)\,dt$$
Next, I tried the substitution $e^{x}t=y$ but that didn't make things easier. Any help is appreciated. Thanks!","['definite-integrals', 'improper-integrals', 'integration']"
1055501,Why are integers subset of reals?,"In most programming languages, integer and real (or float, rational, whatever) types are usually disjoint; 2 is not the same as 2.0 (although most languages do an automatic conversion when necessary). In addition to technical reasons, this separation makes sense -- you use them for quite different purposes. Why did they choose to say $\mathbb{Z} \subset \mathbb{R}$ in math? In other words, why are 2 and 2.0 considered the same? When you are working in $\mathbb{R}$, does it make any difference whether some elements, eg. 2.0, also belong to $\mathbb{Z}$ or not?","['integers', 'real-numbers', 'math-history', 'elementary-set-theory']"
1055542,Taking the Derivative: Power Rule with Respect to Vector,"I'm trying to take the derivative of
\begin{equation}
\phi\left(\mathbf{x}\mathbf{\theta}\right)\mathbf{x}^{\top} \left(\frac{y-\Phi\left(\mathbf{x}\mathbf{\theta}\right)}{\Phi\left(\mathbf{x}\mathbf{\theta}\right)\left[1-\Phi\left(\mathbf{x}\mathbf{\theta}\right)\right]}\right)
\end{equation}
with respect to $\mathbf{\theta}$, where
$\mathbf{\theta}$ is a $p \times 1$ column vector, $\mathbf{x}$ is a $1 \times p$ row vector, (so that $\mathbf{x}\mathbf{\theta}$ is a scalar), $\Phi$ is a function (representing the normal CDF but this doesn't matter) with derivative $\phi$. So I'm trying to compute
\begin{equation}
\nabla_{\mathbf{\theta}} \phi\left(\mathbf{x}\mathbf{\theta}\right)\mathbf{x}^{\top} \left(\frac{y-\Phi\left(\mathbf{x}\mathbf{\theta}\right)}{\Phi\left(\mathbf{x}\mathbf{\theta}\right)\left[1-\Phi\left(\mathbf{x}\mathbf{\theta}\right)\right]}\right)
\end{equation}
I know that the answer ends up being
\begin{equation}
\frac{-[\phi(\mathbf{x}\mathbf{\theta})]^2\mathbf{x}^{\top}\mathbf{x}}{\Phi\left(\mathbf{x}\mathbf{\theta}\right)\left[1-\Phi\left(\mathbf{x}\mathbf{\theta}\right)\right]}+\mathbf{L}(\mathbf{x},\mathbf{\theta})[y-\Phi(\mathbf{x}\mathbf{\theta})]
\end{equation}
where $\mathbf{L}(\mathbf{x},\mathbf{\theta})$ is the Jacobian of \begin{equation}
\frac{\phi(\mathbf{x}\mathbf{\theta})\mathbf{x}^{\top}}{\Phi\left(\mathbf{x}\mathbf{\theta}\right)\left[1-\Phi\left(\mathbf{x}\mathbf{\theta}\right)\right]}
\end{equation}
However I try to get to the answer and get overwhelmed with the problem. Any help? Thank you very much!","['matrices', 'derivatives', 'multivariable-calculus', 'vectors']"
1055558,Evaluate $\int_2^3 {\text{d}x\over x \log(x + 5)}$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question I have this integral to solve. I have tried both integration by substitution and integration by parts but couldn't solve it. $$\int_2^3 {\text{d}x\over x \log(x + 5)}$$ How do i solve this?","['definite-integrals', 'calculus', 'integration']"
1055559,Why möbius transformation is isomorphic to projective linear group?,I saw on my complex analysis book that linear fractional transformation is isomorphic to the group of invertable $2\times 2$ matrix such that identify scalar multiplication. Verifying that was easy but I want to know whether there is some intuition or underlying principles why this is happening. I was curious about it since high school. (at that time it was about real fractional transformation) In fact I didn't take modern algebra and I do not know much about group things.(Just learn a little when taking topology class). Can someone explain the reasons?,"['complex-analysis', 'mobius-transformation', 'abstract-algebra']"
1055590,y' = y^3 - y stable points,"So I have this differential equation:
$$y' = y^3 - y$$
And I need to find out which of the points (0, 1, -1) are stable. So here we go: $$y = \pm \frac{1}{\sqrt{e^{2x+c}+1}}$$ (solution to differential equation without y=0) Assume that
$y = y^*(x, y_0^*)$ is a solution which satisfies $y(x_0) = y_0$ then:
$$y_0^* = \pm \frac{1}{\sqrt{e^{2x_0+c}+1}}$$
$$c = \frac{1-y_0^*{^2}}{y_0^*{^2}}e^{-2x_0}$$ $$y^*(x, y_0^*) = \pm\frac{y_0^*{^2}}{(1-y_0^*{^2})e^{2(x-x_0)}+y_0^*{^2}}$$ Firstly, let examine point 0 using Lyapunov's stability definition: $$\forall \varepsilon \gt 0 : \exists  \delta(\varepsilon) \gt  0 :  |y(x_0) - y^*(x, y_0^*)| \lt \varepsilon, |y_0 - y_0^*| \lt \delta$$ $$|0-y^*(x, y_0^*)| = \frac{y_0^*{^2}}{|(1-y_0^*{^2})e^{2(x-x_0)}+y_0^*{^2}|} \le \frac{y_0^*{^2}}{|1-y_0^*{^2}|}e^{-2(x-x_0)} \le \frac{y_0^*{^2}}{|1-y_0^*{^2}|} \lt \varepsilon, 1-y_0^*{^2} \gt 0$$
And $$\pm\lim_{x\to \infty}\frac{y_0^*{^2}}{(1-y_0^*{^2})e^{2(x-x_0)}+y_0^*{^2}} = 0$$
so it means that point 0 is asymptotical stable. Now, let examine points 1 and -1:
$$|\pm 1-y^*(x, y_0^*)| = \left\lbrace\frac{|1-y_0^*{^2}|e^{2(x-x_0)}}{|(1-y_0^*{^2})e^{2(x-x_0)}+y_0^*{^2}|} \le 1 \lt \varepsilon; \frac{|1-y_0^*{^2}|e^{2(x-x_0)}+2y_0^*{^2}}{|(1-y_0^*{^2})e^{2(x-x_0)}+y_0^*{^2}|} \le 1+\frac{2y_0^*{^2}}{|1-y_0^*{^2}|}e^{-2(x-x_0)} \le 1+\frac{2y_0^*{^2}}{|1-y_0^*{^2}|} \lt \varepsilon \right.$$
That means that in general 
$$1+\frac{y_0^*{^2}}{|1-y_0^*{^2}|} \lt \varepsilon, 1-y_0^*{^2} \gt 0$$ is that mean that 1 and -1 are stable points (but not asymptotical)? Or where am I doing it wrong?
And what about my assumption $$1-y_0^*{^2} \gt 0$$","['differential', 'ordinary-differential-equations', 'stability-in-odes']"
1055623,Does weak convergence in $L^{q}$ imply weak convergence in $L^{p}$,"Assume we have $u_{k} \rightharpoonup u$ in $L^{q}(\Omega)$, does it then follow that $u_{k} \rightharpoonup u$ in $L^{p}(\Omega)$, given that $q > p$ and $\Omega \subset \mathbb{R}^{n}$ is bounded? I know strong convergence $u_{k} \rightarrow u$ in $L^{q}(\Omega)$ implies strong convergence $u_{k} \rightarrow u$ in $L^{p}(\Omega)$ given that $\Omega \subset \mathbb{R}^{n}$ is bounded. (using Jensen's Inequality to prove) Thanks.","['functional-analysis', 'convergence-divergence', 'weak-convergence', 'real-analysis', 'lp-spaces']"
1055638,Solving $3x\equiv 4\pmod 7$,"I'm trying to learn about linear congruences of the form ax = b(mod m). In my book, it's written that if $\gcd(a, m) = 1$ then there must exist an integer $a'$ which is an inverse of $a \pmod{m}$. I'm trying to solve this example: $$3x \equiv 4 \pmod 7$$ First I noticed $\gcd(3, 7) = 1$. Therefore, there must exist an integer which is the multiplicative inverse of $3 \pmod 7$. According to Bezout's Theorem, if $\gcd(a, m) = 1$ then there are integers $s$ and $t$ such that $sa+tm=1$ where $s$ is the multiplicative inverse of $a\pmod{m}$. Using that theorem: $\begin{align}7 = 3\cdot2 +1\\7 - 3\cdot2 = 1 \\-2\cdot3 + 7 = 1\end{align}$ $s=-2$ in the above equation so $-2$ is the inverse of $3 \pmod{7}$. The book says that the next step to solve $3x \equiv 4 \pmod{7}$ is to multiply $-2$ on both sides. By doing that I get: $\begin{align}-2\cdot3x \equiv -2\cdot4 \pmod 7\\-6x\equiv -8 \pmod 7\end{align}$ What should I do after that? I am working on this problem for hours. Thanks :)","['modular-arithmetic', 'discrete-mathematics']"
1055646,What is the chance that a PDF with compact support is concave?,"Relevant questions and answers, in chronological order: When do equations represent the same curve? Find a smooth function with prescribed moments Does a sequence of moments determine the function? All of the questions and answers are related to the Moment problem .
The functions considered have compact support (hope this terminology is correct).
More specifically, the above Q & A list is related to the Hausdorff moment problem ;
without loss of generality, the bounded interval is taken as $[0,1]$ .
As pointed out in the Wikipedia reference, the following integral sheds more light
on properties of the moments. Let $f(x)$ be real, integrable and positive with area
$\,m_0 = 1\,$ equal to one - in short: $f(x)$ resembles a Probability Density Function (PDF) - then:
$$
\int_0^1 f(x) x^n (1-x)^k dx > 0 \quad \Longrightarrow \quad \left\{
\begin{array}{l} m_0 > 0 \; , \; m_1 > 0 \; , \; m_2 > 0 \\
m_0 > m_1 \; , \; m_2 > m_1 \\
m_0 - 2 m_1 + m_2 > 0 \end{array}\right.
$$
Attention will be restricted to the first few moments : $m_1,m_2$ .
If we put $\;x = m_1/m_0=m_1\;$ and $\;y = m_2/m_0=m_2\;$ then it follows that all $(x,y)$
values are within the $\color{silver}{silver}$ triangle with vertices
$(0,0),(0,1/2),(1,1)$ , as shown in the picture at the bottom.
$$
y > 0 \quad ; \quad y < x \quad ; \quad y > 2 x - 1
$$
Schwarz' inequality gives rise to a somewhat more restrictive condition: all $(x,y)$
values are within the $\color{gray}{gray}$ area between a parabola and a straight line:
$$
y < x \quad ; \quad y > x^2 
$$
This is as far as I have been able to go with general considerations about moments.
But if someone knows better, I'm eager to learn about it. Special theories Couldn't proceed with the general, so I've tried some special cases. Because I think it's better to be successful
with something special than to fail with anything general. This is the reason why I've
payed so much attention to extremely simple PDF-functions, sample functions namely that
are completely determined by their first few moments. Among these are: histograms consisting of three blocks with the same width Please read the reference, because the argumentation shall not repeated here. The three moments $\,m_0,m_1,m_2\,$ are linear in the three function values
$f_0,f_1,f_2$ and vice versa. Meaning that there is a one-to-one mapping between
function space and moment space $\,(x=m_1/m_0,y=m_2/m_0)\,$ where $m_0 = 1$ .
The moment space of 3-histograms is in the picture below. If the only
requirement is that the histogram is just positive (and with area $= 1$) then
what we have is the $\color{blue}{blue\; triangle}$. If an additional requirement
is that the histogram is concave then we have the $\color{green}{green\; triangle}$ as a proper part of the blue one. Let's formulate this as follows. Consider the
universe of all PDF 3-histograms, what then is the chance that such a histogram
is concave ? The answer must be the quotient of the areas of
the green and the blue triangle. With the above reference that is: $\,(4/243) / (1/27) = 4/9$ .
With other words: $\large 4/9$ of all histograms in our special universe are concave. But this is indeed a very simple example. A couple of questions arise: In general, has an idea like this been launched before? If not in general, do there exist other special examples of PDF universes where the question ""what is the chance that a PDF is concave"" makes sense?","['functions', 'area', 'probability', 'real-analysis']"
1055651,Probability that a random 13-card hand contains at least 3 cards of every suit?,"A random 13-card hand is dealt from a standard deck of cards. What is the probability
  that the hand contains at least 3 cards of every suit? (Introduction to Probability, p.36) My solution: There are $\binom{52}{13}$ possible hands. Because there are 13 cards for the hand, to obtain at least three cards of one suit per hand, we need to have exactly three cards of one suit per hand plus one additional card of any suit, thus $\binom{13}{3}^4 * 4 \binom{10}{1}$ Result: $\frac{40*\binom{13}{3}^4}{\binom{52}{13}} = 0.4214$ However, simulating it in R yields: deck <- rep(1:4, 13)
out <- replicate(1e5,{
  hand <- sample(deck, size=13, replace=FALSE)
  all(table(hand) >= 3)
})
mean(out)
> 0.14387 Can anybody tell me what is wrong? EDIT I'm afraid, the correct code should be. deck <- rep(1:4, 13)
out <- replicate(1e5,{
  hand <- sample(deck, size=13, replace=FALSE)
  length(table(hand))==4 & all(table(hand) >= 3 )
})
mean(out)
> 0.10639","['card-games', 'probability', 'combinatorics']"
1055665,Convergence of truncation in $L^{p}$,"If you have a truncation $T_{k}u$ defined as: $$
T_{k}u :=  \begin{cases} u,&  \text{ if }~ |u(x)| \leq 1\\ k\frac{u}{|u(x)|}, &   \text{ if }~|u(x)| > k  \end{cases} 
$$ If you consider the truncation of a function $u \in L^{p}(\Omega)$, $p > 1$ and $\Omega$ is bounded. Then how would you show that $T_{k}u \rightarrow u$ in $L^{p}(\Omega)$. It is clear that $T_{k}u \rightarrow u$ pointwise a.e. and by the Dominated convergence Theorem you could show that $T_{k}u \rightarrow u$ in $L^{1}(\Omega)$. I'm finding it hard to show convergence of truncation in $L^{p}(\Omega)$. Does anyone have any idea how this can be shown?","['lp-spaces', 'convergence-divergence', 'functional-analysis', 'real-analysis']"
1055736,What is the answer for this aptitude question?,"If $13!/2^x$ is an integer, which of the following represents all possible values of $x$? a) $0 \le x \le 10$ b) $0 < x < 9$ c) $0 \le x < 10$ d) $1 \le x \le 10$ e) $1 < x < 10$ The book says d). But why can't it be a)? Since $13!/2^0$ is also an integer, right?","['arithmetic', 'algebra-precalculus']"
1055740,Find value of sum of reciprocals of powers of a number,"Is there a simple way to find the value of the following expression?
$$\frac1x+\frac1{x^2}+\frac1{x^3}+\cdots$$ On trial and error, I was getting $\frac1{x-1}$, but I'm looking for a mathematical proof to it. Please don't use complicated notation like summation unless absolutely necessary, because I'm not too familiar with it. Edit: I tried another method. Let the answer be $a$. If we calculate $ax$, we get what appears to be $1+a$.
$$ax=1+a$$
$$ax-a=1$$
$$a(x-1)=1$$
$$a=\frac1{x-1}$$ Is that sufficient to prove the answer?",['sequences-and-series']
1055878,Example of convergence in probability to a non-degenerate rv,"Suppose the sequence of random variables, X$_n$, converges in probability to another random variable X. The condition requires that for any arbitrary distance, $\epsilon$, the probability that the X$_n$ can be further than $\epsilon$ from X eventually goes to zero. Although one can think of many examples where the random variable X is a degenerate rv (i.e. a constant), is there an example of where X is not? If we suppose X is a non-degenerate rv that has some distribution as do the X$_n$, it is hard for me to see an example of where the probability that the X$_n$ would eventually have to be within any arbitrary distance from X could be made to go to zero (considering that the rv X itself has dispersion). Sorry, I'm not saying this very well, as I am a student, but my textbook and the others I've consulted, give no such examples. Thank you, Matt","['statistics', 'convergence-divergence', 'probability', 'probability-theory']"
1055894,"Is there any ""randomness"" in a random variable?","I've been using probability theory (, statistics, bayesian inference) for a while - and I find it very useful and mathematically elegant, but I still can't get where is the hidden ""randomness"" in a formal definition of random variable. I guess, there must be some ""God with a Dice"" that chooses which $\omega \in \Omega$  like ""is going to realize"". Or there's no such a thing and we always operate (and think of it as) just with numbers weighted by measure of corresponding (exists due to $\Omega$/$\mathcal B (\mathbb R)$ measurability of random variable) elements of $\Omega$ and no ""dice inside""? Or, in other words: how can something deterministic model something random? And if it can, where in formal definition that ""randomness"" is?",['probability-theory']
1055902,"Prove the following inequality: $\int_{(a,b)}f\ d\lambda\cdot\int_{(a,b)}\frac{1}{f}d\lambda≥(b-a)^2$","Assignment: Let $-\infty < a < b < \infty$ and $f: (a,b) \rightarrow (0,\infty)$ be measurable, such that $f$ and $\frac{1}{f}$ are Lebesgue integrable. Prove the following inequality:
  $$\int_{(a,b)}f\ d\lambda\cdot\int_{(a,b)}\frac{1}{f}d\lambda≥(b-a)^2$$
  Hint: Consider the integral
  $$\int_{(a,b)^2}\frac{f(x)}{f(y)}+\frac{f(y)}{f(x)} \ d\lambda_2(x,y)$$ Thoughts: We have a theorem that says for an integrable sequence of functions $(f_n)_{n\in\mathbb{N}}$ that the new function $f(x_1,...,x_n) = f_1(x_1)\ \cdot...\cdot\  f_n(x_n)$ defined as the product of the single functions is integrable as well with the value of the integral of $f$ being the product of the integrals of $f_n$. This approach yields the equality, since, I think, I actually assume $x_1 = x_2$ and don't let the $x_i$ vary. About the hint: The hint, I thought, suggests using Fubini, but since $f$ is random, I cannot simplify the integral at all. Also, using the theorem I referred to earlier, only yields, that the integral of the hint is the left side of the inequality times two, which doesn't help at all. I'm stuck in a dead end right now, could anyone give me hint (or explain the hint given)?","['lebesgue-integral', 'measure-theory', 'lebesgue-measure', 'real-analysis']"
1055908,How to evaluate $\displaystyle\lim_{x\to0^+}\left(\frac{\ln(4^x-3^x)-\ln(4^x-1)}{x}\right)(4^x-1)$?,"How to evaluate
$$L:=\lim_{x\to0^+}\left(\frac{\ln(4^x-3^x)-\ln(4^x-1)}{x}\right)(4^x-1)$$? My solution:
$$\begin{align}
L&=\lim_{x \to 0^+} \frac{\ln\left(\frac{4^x-3^x}{4^x-1}\right)}{x}(4^x-1)=\\
&=\lim_{x \to 0^+} \frac{ \ln\left(1-\frac{3^x-1}{4^x-1}\right)}{\frac{3^x-1}{4^x-1}}\times  \frac{3^x-1}{4^x-1}\times  \frac{4^x-1}{x}
\end{align}$$ How to continue from here?","['calculus', 'limits']"
1055953,How to show the covering space of an orientable manifold is orientable,"I'm trying to prove this using purely topological arguments, no differential geometry as I haven't been exposed to it. I've been playing around with definitions a bit and here's what I have so far. Let $M$ be an orientable manifold. Let $N$ be its covering space. Then we have an orientation function $\mu : M \rightarrow \{\pm 1\}$ that satisfies: $\forall x \in M, \exists U \cong D^n$ an open neighborhood of $x$ and $\mu_u$ a generator of $H_n(M, M-U) \cong \mathbb{Z}$ such that $\forall y \in U$ $H_n(M, M - {y}) \longleftarrow H_n(M, M - U) \longrightarrow H_n(M, M-{x})$ where each map is an isomorphism. Now since $N$ is the covering space of $M$ we know that there is a function $p: N \rightarrow M$ surjective and continuous s.t. $\forall x \in U$ open, $p^-1(U)$ is a disjoint union of open sets $v_i \in N$ s.t. $p(v_i)$ is homeomorphic to $U$. My conjecture is that $\mu \circ p$ is an orientation function on $N$ satisfying the compatibility conditions i.e. $\forall x \in N, \exists U \cong D^n$ an open neighborhood of $x$ and $\mu_u$ a generator of $H_n(N, N-U) \cong \mathbb{Z}$ such that $\forall y \in U$ $H_n(N, N - {y}) \longleftarrow H_n(N, N - U) \longrightarrow H_n(N, N-{x})$ where each map is an isomorphism. I need some help moving forward from here. Is it perhaps true because for $x \in N$ we can choose a neighborhood $V$ s.t. $V$ is one of the open sets which maps homeomorphically onto some neighborhood $U$ of $x' \in M$ and we know that the compatibility conditions are true for any $y' \in U$ so it must be true for any $y \in V$?","['general-topology', 'manifolds', 'algebraic-topology']"
1055959,Weak principle of induction for $5+10+15+\ldots+5n= \frac{5n(n+1)}{2}$,"Show that $$5+10+15+\ldots+5n= \frac{5n(n+1)}{2}$$ Proving the base case $n(1)$ : $5(1)= \frac{5(1)(1+1)}{2}$ $5 = \frac{5(2)}{2}$ $5 = 5$ Induction hypothesis: $n = k$ $5+10+15+\ldots+5k = \frac{5k(k+1)}{2}$ Induction step (adding $k+1$ ): $5+10+15+\ldots+5k+5k+1 = \frac{5k+1(k+1+1)}{2}$ Substituting $\frac{5k(k+1)}{2}$ for $5k$ : $\frac{5k(k+1)}{2}+5k+1 = \frac{(5k+1)(k+1+1)}{2}$ Simplifying: $\frac{5k(k+1)+2(5k+1)}{2} = \frac{(5k+1)(k+2)}{2}$ $\frac{5k^2+5k+10k+2}{2} = \frac{5k^2+10k+k+2}{2}$ These aren't equal, so what did I do wrong here?","['induction', 'discrete-mathematics']"
1055965,"Determine whether $\sum\limits_{n=1}^\infty \frac{1}{n^x}$ converges uniformly on $(1,\infty)$","Detemine whether $\sum\limits_{n=1}^\infty \frac{1}{n^x}$ converges
  uniformly on $(1,\infty)$. My attempt: Upon attempting to use the Weierstrauss M-test I get $$0\leqslant\|f_n(x)\|_\infty=\sup_{x\in (1,\infty)}|\frac{1}{n^x}|\leqslant\frac{1}{n}=M_n$$ But by definition, $\sum\limits_{n=1}^\infty M_n=\sum\limits_{n=1}^\infty \frac{1}{n}$ diverges. So the Weierstrauss M-test is not useful here. Is there some way I could possibly use the uniform Cauchy principle? Thanks for the help.","['cauchy-sequences', 'uniform-convergence', 'real-analysis', 'analysis']"
1055984,Commutative artinian ring is noetherian,Suppose R is a commutative Artinian ring then R is Noetherian. I am aware of the proof which uses the idea of filtration. But I would like to prove this fact without that idea but haven't got far enough. Is there any reference for such a proof? or is anyone aware of one?,"['ring-theory', 'abstract-algebra', 'alternative-proof', 'noetherian', 'commutative-algebra']"
1056001,How to define a vector field passing through a given point.,Given a manifold $M$ we can consider its tangent bundle $TM$. Fix $m \in M$ and $v \in TM$. Is it always possible to define a vector field $F$ such that $F(p)=v$?,['differential-geometry']
1056023,How to prove that sections of family of curves do not exist (exercise 4.7 in Harris' Algebraic Geometry)?,"In exercise 4.7 of his book Algebraic Geometry , Prof. Harris asked to show that there is no local section of the universal hyperplane section of a smooth plane conic or the twisted cubic. The question is about local sections of the projection on the space of hyperplanes, that is to say the dual of respectively $\Bbb{P}^2$ and $\Bbb{P}^3$ Edit More precisely, it is asked to show that, for a conic $X$ for instance, there is no open subset $U$ of $(\Bbb{P}^2)^*$, the space of hyperplanes of $\Bbb{P}^2$, such that there is a regular map from $U$ to $$\Omega_X=\{(x,H)\in X\times (\Bbb{P}^2)^* : x\in H\cap X\}$$ that is section of the second projection of $\Omega_X$ on $(\Bbb{P}^2)^*$ I could not find a proof without using equations and coordinates for the plane conic or the twisted cubic. Is there a less pedestrian & more geometric proof in the spirit of this book ? For instance, Prof. Harris mentioned that this result is an immediate consequence of his Theorem 11.14, which says that the domain of a regular map between projective varieties is irreducible if it has irreducible fibers with constant dimension and an irreducible image. I failed to see why !? Edit Following the comment of Georges, the reference to Theorem 11.14 is just to show that $\Omega_X$ is irreducible",['algebraic-geometry']
1056026,Maximum area of a isosceles triangle in a circle with a radius r,"As said in the title, I'm looking for the maximum area of a isosceles triangle in a circle with a radius $r$. I've split the isosceles triangle in two, and I solve for the area $A=\frac{bh}{2}$*. I have made my base $x$, and solve for the height by using the Pythagorean theorem of the smaller triangle (seen in picture). $h=r+\sqrt{r^2-x^2}$ So my the formula, I think, for both triangles should be $A=x(r+\sqrt{r^2-x^2})$ But after I solved for the derivative, when put ""$= 0$"", and checked on my calculator, I got the maximum to be about $4.3301r$, which differs a lot from my book's answer of $\frac{3\sqrt{3}}{4}r^2$*. Is my formula for the area right? Am I going about this the wrong way, or is it just my derivative that is wrong? Thanks in advance * Edited from original post $A=rx+x\sqrt{r^2-x^2}$ $A'=r+x(\frac{1}{2})(r^2-x^2)^{-\frac{1}{2}}(-2x)+\sqrt{r^2-x^2}$ $r+\sqrt{r^2-x^2}=\frac{x^2}{\sqrt{r^2-x^2}}$ $r\sqrt{r^2-x^2}+(r^2-x^2)=x^2$ $r^2+r\sqrt{r^2-x^2}=2x^2$ $r^2(r^2-x^2)=(2x^2-r^2)^2$ $r^4-r^2x^2=4x^2-4x^2r^2+r^4$ $4x^4=3x^2r^2$ $x=\frac{\sqrt{3}}{2}r$","['optimization', 'calculus']"
1056038,Probability of exactly one empty box when n balls are randomly placed in n boxes. [duplicate],"This question already has answers here : Probability: $n$ balls into $n$ holes with exactly one hole remaining empty [duplicate] (4 answers) Closed 9 years ago . Each of $n$ balls is independently placed into one of $n$ boxes, with all boxes equally likely. What is the probability that exactly one box is empty? (Introduction to Probability, Blitzstein and Nwang, p.36). The number of possible permutations with replacement is $n^n$ In order to have one empty box, we need a different box having $2$ balls in it. We have $\dbinom{n}{1}$ choices for the empty box, $\dbinom{n-1}{1}$ choices left for the box with $2$ balls, and $(n-2)!$ permutations to assign the remaining balls to the remaining boxes. Result: $$\frac{\dbinom{n}{1} \dbinom{n-1}{1} (n-2)!}{n^n}$$ Is this correct?","['probability', 'combinatorics']"
1056045,Prove using induction $2^{3n}-1$ is divisble by $7$ for all $n$ $\in \mathbb N$,"Show that $2^{3n}-1$ is divisble by $7$ for all $n$ $\in \mathbb N$ I'm not really sure how to get started on this problem, but here is what I have done so far: Base case $n(1)$: $\frac{2^{3(1)}-1}{7} = \frac{8-1}{7} = \frac{7}{7}$ But not sure where to go from here.  Tips?","['induction', 'discrete-mathematics']"
1056074,What is the difference between Eigenvectors and the Kernel or Null Space of a matrix?,"I am just wondering what is the difference between Eigenvectors and the Kernel or Null Space of a matrix? The kernel for matrix A is x where, Ax = 0
Isn't that what Eigenvectors are too?",['linear-algebra']
1056088,Equivalence of weak $L^p$ norms,"I'm kind of new to the subject of weak $L^p$ spaces. The definition of the (quasi-)norm in weak $L^p$ ($p\in(0; \infty)\,$) over $\sigma$-finite measure space $(X, \mu)$ I use is $||f||_{L^{p, \infty}} = \sup_{t\in\left(0, \infty\right)} t^{\frac{1}{p}}f^*\left(t\right)$, where $f^*(t)=\inf\{\lambda>0; \mu_f(\lambda)\leq t\}$ and $\mu_f(\lambda) = \mu(\{x\in X; |f(x)|>\lambda\})$.
However, when studying another article regarding weak $L^p$ spaces, I came across this definition $||f||_{L^{p, \infty}} = \sup_{\lambda\in\left(0, \infty\right)} \lambda (\mu_f(\lambda))^\frac{1}{p}$. Somehow I forced myself to believe $\sup_{t\in\left(0, \infty\right)} t^{\frac{1}{p}}f^*\left(t\right) = \sup_{\lambda\in\left(0, \infty\right)}\lambda(\mu_f\left(\lambda\right))^\frac{1}{p}$. Today I decided to prove it rigorously. To my surprise, I've been struggling to prove it. I proved that $f^*(\mu_f(\lambda))\leq\lambda$ (if $\mu_f(\lambda)<\infty$) and $\mu_f(f^*(t))\leq t$ (if $f^*(t) < \infty)$ but I failed in using it to prove the equality. Does the equality really hold? I believe I must be missing some simple thing(s) but after spending hours trying to prove it I find myself really desperate. Thank you for any help!","['measure-theory', 'supremum-and-infimum', 'weak-lp-spaces', 'lp-spaces', 'functional-analysis']"
1056105,Elliptic curves as cubics as discussed in Ravi Vakil's notes,"I was reading the section of Ravi Vakil's Algebraic Geometry notes where he discusses elliptic curves. If we let an elliptic curve be $(E,p)$ (Where $p$ is the distinguished point), we have $\mathcal{O}(3p)$, which has $3$ sections, which gives us a closed embedding into $\mathbb{P}^2$. In the next sentence Ravi Vakil writes Thus we have a closed embedding $E\hookrightarrow \mathbb{P}^2_k$ as a cubic curve. My question is how does he know that it must be cubic, and what does this depend on (like in what way if any does it depend on the fact that $k$ is a field)? Thank you for any help or advice.","['algebraic-geometry', 'elliptic-curves']"
1056119,"How to show that $\tan(n), n\in \mathbb{N}$ is not bounded",I'm struggling on how to show that the sequence of $\tan(n)$ is not bounded. Can you please give me some help?,"['sequences-and-series', 'analysis']"
1056136,Curvature of De Sitter's space: where does the sign comes?,"Consider $\Bbb L^3 = (\Bbb R^3, {\rm d}s^2)$, where: $${\rm d}s^2 =  {\rm d}x^2 + {\rm d}y^2 - {\rm d}z^2.$$ We have both the hyperbolic space : $$\Bbb H^2(-1) = \{(x,y,z) \in \Bbb L^3 \mid x^2+y^2-z^2 =- 1\},$$ which has constant Gaussian Curvature $K = -1$, and the De Sitter's space : $$\Bbb S^2_1(1) = \{(x,y,z) \in \Bbb L^3 \mid x^2+y^2-z^2 = 1\},$$ which has Gaussian Curvature $K=1$. My problem is: I'm trying to actually compute these curvatures, and I'm getting $K=-1$ for both of them. I'm using connection forms just like in $\Bbb R^3$ and bi-dimensional Riemannian manifolds, but I think stuff is going wrong because the De Sitter's space is a timelike surface, while the hyperbolic space is spacelike.. I have not seen a rigorous treatment of this in semi-Riemannian surfaces, so I would like to know exactly where my calculations are failing. Additional explanations would be very welcome, too. Enough talk, let's go to the action: Rotating a hyperbola, we parametrize the De Sitter's space by $${\bf x}(u,v) = ( \cosh u \cos v, \cosh u \sin v, \sinh u),$$ and so: $$\begin{align} {\bf x}_u(u,v) &= (\sinh u \cos v, \sinh u \sin v, \cosh u) \\ {\bf x}_v(u,v) &= (-\cosh u \sin v, \cosh u \cos v, 0) \end{align}.$$ Dropping the point $(u,v)$ from now on, we have: $$E = -1 \quad F = 0 \quad G = \cosh^2u.$$ So, we can take a frame $$E_1 = {\bf x}_u \quad E_2 = \frac{{\bf x}_v}{\cosh u},$$ with dual forms $$\theta_1 = {\rm d}u \quad \theta_2 = \cosh u \ {\rm d}v.$$ So $ {\rm d}\theta_1 = 0 $ and $ {\rm d}\theta_2 = \sinh u \ {\rm d}u \wedge {\rm d}v.$ Now I need the connection form $\omega_{12}$. Write: $$\omega_{12} = \alpha \ {\rm d}u + \beta \ {\rm d}v.$$ Since ${\rm d}\theta_1 = \omega_{12} \wedge \theta_2$, we get $\alpha = 0$. And from $ {\rm d}\theta_2 = - \omega_{12} \wedge \theta_1$, we obtain: $$\begin{align} \sinh u \ {\rm d}u \wedge {\rm d}v &= -(\beta \ {\rm d}v)  \wedge {\rm d}u \\ \sinh u \ {\rm d}u \wedge {\rm d}v &= \beta \  {\rm d}u \wedge {\rm d}v \end{align},$$ so $\beta = \sinh u$. Now $\omega_{12} = \sinh u \ {\rm d}v$ gives us $ {\rm d}\omega_{12} = \cosh u \ {\rm d}u \wedge {\rm d}v$. Rewriting: $$ \cosh u \ {\rm d}u \wedge {\rm d}v = \cosh u \ \theta_1 \wedge \left(\frac{\theta_2}{\cosh u}\right) = -(-1) \ \theta_1 \wedge \theta_2, $$ and ${\rm d}\omega_{12} = -K \ \theta_1 \wedge \theta_2$ wields $K=-1$. What is going wrong? The same calculation gives the right answer for the hyperbolic space. Where does the causal character comes in? Please help. Edit : I have redone the calculations using $E_1 = \frac{{\bf x}_u}{\rm i}$ instead of my previous $E_1$, and I got the right answer. However, using complex numbers felt like cheating, so I'll rephrase my question: is there any way that I can avoid this approach? From what I've studied about $\Bbb L^3$ so far, complex numbers weren't used, so I reckon that must be another way to tackle this.","['hyperbolic-geometry', 'riemannian-geometry', 'semi-riemannian-geometry', 'differential-geometry']"
1056187,Why does this sequence converge?,"I have to deal with the following sequence : $\lim \limits_{x \to \infty}\sqrt{x+\sqrt{x}} - \sqrt{x}$ If I factorize it to $\sqrt{x}(\sqrt{\sqrt{x}+1}-1)$, I would say it diverges since both factors diverge: $\lim \limits_{x \to \infty}\sqrt{x}= \infty  $ and $\lim \limits_{x \to \infty} \sqrt{\sqrt{x}+1} = \infty$ But if I type it in WolframAlpha, I get $\frac12$ as limit. Can you help me out?","['sequences-and-series', 'real-analysis', 'limits']"
1056194,How to find cosh(arcsinh(f(x)))?,"With the regular trig functions, if I ever end up with something like $\operatorname{trig}_1(\operatorname{arctrig}_2(f(x))$, where $\text{trig}_1$ and $\text{trig}_2$ are two arbitrary trigonometric functions, I can draw a right triangle to find a formula for this that doesn't involve any trigonmetric functions. How do I find a similar result for hyperbolic functions?  For instance, when working a problem recently, I ended up with $\cosh(\operatorname{arcsinh}(3x))$.  WolframAlpha told me that it was $\sqrt{1+9x^2}$, but how do I figure that out? What picture can I draw?  I'm not sure of the geometry here.  I'm pretty sure that hyperbolic functions are related to hyperbolas the way that trig functions are related to circles, but I don't figure out the trig(arctrig) expressions by looking at circles -- I draw a triangle.  Is there something similar I can do with hyperbolic functions?","['geometry', 'trigonometry', 'hyperbolic-functions']"
1056240,Two (strictly related) proofs by induction of inequalities.,"This is a question I originally asked on MSE, receiving no answer, even with a bounty (which expired) on it. Therefore I am crosslinking in order to prevent duplication of effort: see here for the original question. Predictably, I am stuck with the inductive steps.
Let $a_n=\prod_{i=1}^m p_i^{b_i}$, where $b_1=9;b_2=5;b_3,b_4=3;b_5,b_6=2;b_7,\ldots ,b_{m}=1$, $p_i$ is the $i$-th prime and set $\lim_{n\to \infty}\frac{\log a_n}{p_m}=1$. Suppose also this ratio converges to $1$ faster than $\displaystyle\frac{p_{m(n)+1}}{p_{m(n)}}$, so that if $n$ is large enough, we always have $\log a_n<p_{m+1}$. I want to prove that for sufficiently large $n$, with $c$ being a constant and $q(n)<m$, if $$\frac{c}{\log \log a_n}<\frac{\left(1+{\prod_{i=1}^m\left(p_i^{b_i+1}-1\right)^{1/m}}\right)^m}{\prod_{i=1}^m\left(p_i^{b_i+1}-1\right)}, \tag{1}$$ then the following statements are true: $$ \frac{c}{\log \left(\log a_n+\log p_q\right)}<\\\frac{\left(1+\prod_{i=1}^{q-1}\left(p_i^{b_i+1}-1\right)^{1/m}\cdot\left(p_q^{b_q+2}-1\right)^{1/m}\cdot\prod_{i=q+1}^{m}\left(p_i^{b_i+1}-1\right)^{1/m}\right)^m}{\prod_{i=1}^{q-1}\left(p_i^{b_i+1}-1\right)\cdot\left(p_q^{b_q+2}-1\right)\cdot\prod_{i=q+1}^{m}\left(p_i^{b_i+1}-1\right)}; \tag{2}$$ $$ \frac{p_{m(n)+1}}{p_{m(n)+1}-1}\frac{c}{\log \left(\log a_n+\log p_{m(n)+1}\right)}<\frac{\left(1+\prod_{i=1}^{m(n)+1}\left(p_i^{b_i+1}-1\right)^{1/(m(n)+1)}\right)^{m(n)+1}}{\prod_{i=1}^{m(n)+1}\left(p_i^{b_i+1}-1\right)}. \tag{3}$$ To clear it up, in $(2)$ we have $a_n\cdot p_q=a_{n+1}$, in $(3)$ instead $a_n\cdot p_{m(n)+1}=a_{n+1}$. Namely, we're considering two different cases of how the sequence $a_n$ evolves: in $(3)$ the $n+1$-th term is given by the product of the $n-$th term times the $n+1$-th prime; in $(2)$ the $n$-th term is multiplied by a prime less than the $n+1$-th. $(2)$ is fairly intuitive, as the LHS goes to $0$ as $n\to \infty$ while the RHS goes to $1$, but that doesn't tell me so much since if the former is larger than $1$ and slightly smaller than the latter, I cannot say a priori that the LHS is sufficiently fast in its convergence to $0$, to be always less than the RHS.
On the other hand, it is only my istinct that says $(3)$ holds, but I might be wrong. Here is how I tackled both inequalities, hoping to simplify things a bit (and not ""too much""). Call $L_t$ and $R_t$ respectively the LHS and RHS of $(1)$, $(2)$ and $(3)$. So $(2)$ is the same as $$ L_1 \frac{L_2}{L_1}<R_1\frac{R_2}{R_1},$$ and since $L_1<R_1$ by hypothesis, $(2)$ is implied by $$ \frac{\log \log a_n}{\log \left(\log a_n+\log p_q\right)}<\\ \frac{p_q^{b_q+1}-1}{p_q^{b_q+2}-1}\left(\frac{1+\prod_{i=1}^{q-1}\left(p_i^{b_i+1}-1\right)^{1/m}\cdot\left(p_q^{b_q+2}-1\right)^{1/m}\cdot\prod_{i=q+1}^{m}\left(p_i^{b_i+1}-1\right)^{1/m}}{1+{\prod_{i=1}^m\left(p_i^{b_i+1}-1\right)^{1/m}}}\right)^m.\tag{4}$$
Similarly, $(3)$ follows from $$ \frac{p_{m+1}}{p_{m+1}-1}\frac{\log \log a_n}{\log \left(\log a_n+\log p_{m+1}\right)}<\\ \left(1+\prod_{i=1}^{m+1}\left(p_i^{b_i+1}-1\right)^{1/(m+1)}\right)\left(\frac{1+\prod_{i=1}^{m+1}\left(p_i^{b_i+1}-1\right)^{1/(m+1)}}{1+{\prod_{i=1}^m\left(p_i^{b_i+1}-1\right)^{1/m}}}\right)^m.\tag{5}$$
This said, I do not know how to prove $(4)$ and $(5)$ either. Any ideas? Thanks in advance. EDIT : I have succeeded in making sufficient to prove the inequalities having $p_{m+1}-1$ instead of $p_m$, which somewhat might be a tiny bit easier.","['products', 'logarithms', 'real-analysis', 'prime-numbers', 'induction']"
1056282,Trigonometric identity expressed as a sum of fractions.,"I am just trying to figure out why this happens:
$$
\cos x + \frac{\sin ^2 x}{\cos x} =  \frac{\cos^2x +\sin^2 x}{\cos x}
$$
How do we get $\cos^2x$ in the numerator on the right-hand side? I just don't get it.",['trigonometry']
1056291,Unconventional (but instructive) proofs of basic theorems of calculus,"Inspired by this questions asked on MathOverflow , I would like to ask if you know some ""sophisticated"" proofs of the basic theorems in a calculus course (that is, the ones that you can find, for instance, in Spivak's Calculus ). In this case, by ""sophisticated"", I do not mean awfully complicated, but unexpected, extremely clever and unconventional (and hopefully instructive), either because they use concepts from other areas of mathematics or because they enlighten a theorem by tackling it from a non-obvious and by no means standard(ized) perspective.","['big-list', 'calculus', 'examples-counterexamples', 'real-analysis']"
1056337,Simplifying the sum $\sum\limits_{i=1}^n\sum\limits_{j=1}^n x_i\cdot x_j$,"How can I simplify the expression $\sum\limits_{i=1}^n\sum\limits_{j=1}^n x_i\cdot x_j$? $x$ is a vector of numbers of length $n$, and I am trying to prove that the result of the expression above is positive for any $x$ vector.  Is it equal to $\sum\limits_{i=1}^n x_i\cdot \sum\limits_{j=1}^n x_j$? If it is then my problem is solved, because $\left(\sum\limits_{i=1}^n x_i\right)^2$ is non-negative (positive or zero).","['algebra-precalculus', 'vectors', 'matrices', 'linear-algebra', 'summation']"
1056387,Limit of a sequence containing root of n!-th degree - how to deal with that?,"Here is a sequence the limit of which I'm trying to find as $n$ goes to infinity: $$a_n=\sqrt[n!]{\frac{1}{2^{n!}}-\frac{1}{3^{n!}}}$$ Here is what I've done: $a_n=\sqrt[n!]{\frac{1}{2^{n!}}(1-\frac{2^{n!}}{3^{n!}})}=\frac{1}{2}\sqrt[n!]{1-(\frac{2}{3})^{n!}}$ Intuitevely this should converge to $\frac{1}{2}$ because as $n$ becomes large $(\frac{2}{3})^{n!}$ becomes closer and closer to $0$ so this expression under the root basically becomes $\sqrt[n!]{1}$ which is equal to $1$. I don't think I'm allowed to finish solving the problem now (as I am aware such operations can be quite risky, for example limit of $(1+\frac{1}{n})^n$ evaluates to $e$ even though $\frac{1}{n}$ becomes closer and closer to $0$ as $n$ becomes large). So how to prove it formally?","['sequences-and-series', 'limits']"
1056416,Importance of Gödel Numbering System,"How important is Gödel numbering to his incompleteness proofs, set theory, logic theory in general and proofs employing ZFC? Can we use some other numbering or 'meta' programming? How about if one uses a more efficient numbering system? How efficient can the numbering system be in order for his proofs to work?","['logic', 'incompleteness', 'elementary-set-theory']"
1056439,Solve for $x: \sin 2x = - \frac 12$,"I am trying to solve the following trigonometric equation algebraically, where $0\leq \displaystyle x \leq2 \pi$ $$\sin2x = -\frac{1}{2}.$$ My answer must be an exact solution. Here is what I have tried: If $\displaystyle \sin(30°) = \frac{1}{2}$, then $\displaystyle \sin (2\times 15°) = \frac{1}{2}$. Sin is negative in quadrants III and IV, so with a reference angle of $15°$ degree, $x$ can equal $180°+15°=\bf{195°}$, and $360°-30°=\bf{345°}$ Feeling confident about my answer, I checked the solution with my graphing calculator. The graph intersects the x-axis at $345°$ ($6.021$ rad), but it doesn't intersect the graph at $195°$. Where did I make my mistake? I know I can work backwards, by taking the radian values from the graph and finding their ""degree equivalents"", but I need to be able to solve this algebraically. Edit 210 degrees/2 = 105 degrees 330 degrees/2 = 165 degrees 210+360/2 = 285 degrees 330+360/2 = 345 degrees Answer: x= 105˚, 165˚, 285˚, 345˚",['trigonometry']
1056450,Integral form of this IVP,"How do I show that the following initial value problem
$$
xu''+u'+xu=0,\quad  u(0)=1,\quad u'(0)=0
$$
has the following integral form:
$$
u(x)=1+\int_{0}^{x} t\ln(t/x)u(t)\,dt
$$
I am stuck because if I divide both sides of both ODE by $x$
$$
u'+\frac{1}{x}u+u=0
$$
$\frac{1}{x}$ is undefined at $0$.","['ordinary-differential-equations', 'integral-equations', 'analysis']"
1056461,Number of rational points on a curve and genus of a curve,"I've just started with algebraic geometry, so i apologize in advance if my question is too easy to show. Given is a curve $\Gamma $ in $\mathbb{P}^{2}(\mathbb{F_{q^{m}}})$ defined by $X^{q}Z+XZ^{q}-Y^{q+1}=0$. Find the number of the rational points and the genus $g$ of this curve. Well, i see that the curve is already homogenized and the degree of it is $d=q+1$. I know that the genus can be at most $g=\frac{(d-1)(d-2)}{2}$ according to the general formula of genus. This is only in case i have a smooth curve. Here i see immediately that the points $(1,0,0)$ and $(0,0,1)$ are singular and they reduce the genus. How can i find the other singular points and the number of points on the curve? Can somebody help me with this question? Thanks in advance!","['algebraic-geometry', 'algebraic-curves']"
1056469,question about double sums,Suppose we have an expression $$ \sum_{1 \leq k < j \leq n } f(k)f(j) $$ Can we express this as a double sum like $$ \sum_{k=1}^n \sum_{j=1}^n f(k)f(j) $$ ???,['algebra-precalculus']
1056479,Laurent series of $f(z)=\frac{1}{z(z-1)}$ given four different conditions,"Expand $f(z)=\frac{1}{z(z-1)}$ in a Laurent series valid for the follwing annular domains. $a)0\lt \vert z \rvert \lt 1 \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,b)1\le\lvert z \rvert\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,c)0\le \lvert z-1 \rvert \lt1\,\,\,\,\,\,\,\,\,\,\,\,\,d) 1\le \lvert z-1 \rvert$ Ok, so here are some things I know, There are singularities at $z_0=0$and $z_0=1$ a) is the unit circle, shaded inside.$f(z)=\frac{1}{z(z-1)}=\frac{1}{z}*\frac{1}{z-1}=\frac{-1}{z}*\frac{1}{1-z}=\frac{-1}{z}*\sum_{n=0}^\infty Z^n=\frac{-1}{z}[z^0+z^1+z^2...]=\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,f(z)=\frac{-1}{z}-1-z-z^2-...\,$ which converges for $0\lt \vert z\rvert \lt 1$ b)is the unit circle shaded outside the circle. $f(z)=\frac{1}{z(z-1)}$$=\frac{1}{z}*\frac{1}{z-1}$$=\frac{1}{z}*\frac{1}{z(1-1/z)}=\frac{1}{z^2}*\frac{1}{1-1/z}=\frac{1}{z^2}*\sum_{n=0}^\infty(\frac{1}{z})^n=\frac{1}{z^2}[\frac{1}{z}^0+\frac{1}{z}^1+\frac{1}{z}^2+...]=\frac{1}{z^2}+\frac{1}{z^3}+\frac{1}{z^4}+...$ c)is a circle with r=1, shaded inside. Here, Im not so sure how to manipulate the function and have gotten stuck d)is a cirlce with r=1, shaded outside","['laurent-series', 'sequences-and-series', 'complex-analysis']"
1056480,"Probability: 6 Dice are rolled. Which is more likely, that you get exactly one 6, or that you get 6 different numbers?","Here's the question: 6 Dice are rolled. Which is more likely, that you get exactly one 6, or that you get 6 different numbers? Here's what I've done: The number of possible outcomes is $6^6 = 46656$. The probability of rolling exactly one 6 = $\frac{1}{6}\times(\frac{5}{6})^5 = \frac{3125}{46656}$ The probability of getting six different numbers is: $C(6,1)\times C(5,1)\times C(4,1)\times C(3,1)\times C(2,1)\times C(1,1) = \frac{720}{46656}$ Therefore if everything I've said above is true, then it is more likely that you will roll exactly one six. However I'm really not sure about the last part. Is this correct way to solve this type of problem and can the combinations part be simplified? EDIT: Since I'm also looking for a better idea of how to solve this type of problem, rather than just this specific case, so could you please include how to solve this problem for rolling 5 dice, as well as/or instead of 6 dice in your answer, so that I can see the pattern of what is happening? Many thanks.","['probability', 'combinatorics']"
1056486,"If $f_1(k)=\sum_{i=1}^k\frac{1}{i}$ and $f_n(k)=\sum_{i=1}^kf_{n-1}(i)$, then what is $f_n(n)$?","Let
$$f_1(k)=\sum_{i=1}^k\frac{1}{i},$$
and define inductively
$$f_n(k)=\sum_{i=1}^kf_{n-1}(i).$$
So,
$$f_2(k)=\sum_{i_2=1}^k\sum_{i_1=1}^{i_2}\frac{1}{i_1},\quad f_2(k)=\sum_{i_3=1}^k\sum_{i_2=1}^{i_3}\sum_{i_1=1}^{i_2}\frac{1}{i_1},$$
and so on. Question: What is $f_n(n)$ for all $n\in\mathbb{N}$? The first few terms are
$$1,\frac{5}{2},\frac{47}{6},\frac{319}{12},\frac{1879}{20},\ldots$$
but I find difficult to find the general pattern. Added: The numerators appear to be the coefficients in the power series of
$$-\ln(1+x)\ln(1-x).$$
This is very interesting...","['recurrence-relations', 'sequences-and-series']"
1056504,Can quaternions be useful for integrals?,Lets assume we want to find a closed form for $\int_0^1 f(x) dx$ where $f(x)$ is a real-analytic function. There are many techniques to find that. Some include contour integration on the complex plane. But I wonder : Can quaternions be useful for integrals ?,"['quaternions', 'integration']"
1056531,Help me finding closed form of sum of 4 elements,"I've been reading Wilf's Gfology and tried to calculate some complicated sum
Let's say $0<k \le n$
$$f(k,n) = \sum_{i} i(-1)^i \binom{n}{i} \binom{i}{k-i}  $$
I will write down my calculations, i hope there is no mistake. 
I want to calculate generating function of $f(k,n)$ it is $F(k,n) = \sum_{n} f(k,n) x^n$
$$\sum_{n}x^n \sum_{i} i(-1)^i \binom{n}{i} \binom{i}{k-i}=$$
$$\sum_{i} i(-1)^i \binom{i}{k-i} \sum_{n} \binom{n}{i} x^n=$$
$$\sum_{i} i(-1)^i \binom{i}{k-i} \frac{x^i}{(1-x)^{i+1}}=$$
$$\frac{1}{1-x} \sum_{i} i(-1)^i \binom{i}{k-i} \left(\frac{x}{(1-x)}\right)^i$$
I don't really know how to proceed with this sum. 
I'd like to solve it with generating functions if it's possible. 
I will be greatful for any hints or solutions to this.","['summation', 'discrete-mathematics']"
1056542,Prove $\{g(x_n)\}_{n=1}^\infty$ converges,"Let $g : (a, b) → R$ be uniformly continuous on $(a, b)$. Let $\{x_n\}_{n=1}^\infty$ be a sequence in $(a, b)$ converging to $a$. Prove that $\{g(x_n)\}_{n=1}^\infty$ converges. The general idea here is to use the uniform continuity of g as well as the fact that since the $\{x_n\}$ converges it is Cauchy and to prove that $\{g(x_n)\}_{n=1}^\infty$ is Cauchy. From uniform continuity we have $\forall\epsilon > 0, \exists\delta > 0$ such that $|x - y| < \delta$ with $x,y \in (a,b)$ then $|g(x) - g(y)| < \epsilon$. And since $\{x_n\}_{n=1}^\infty$ is Cauchy we have $\forall\epsilon > 0, \exists N \in J$ such that $\forall n,m \ge N$ then $|x_m - x_n| < \epsilon$. However, I'm not sure how to combine these two given properties in order to get the Cauchy property for $\{g(x_n)\}_{n=1}^\infty$. Thanks for the help!","['sequences-and-series', 'cauchy-sequences', 'real-analysis', 'analysis', 'uniform-continuity']"
1056545,Solve for $x$ in the following trigonometric equation,"$$\sqrt 2\cos^2 x-\cos x=0$$
Solve for $x$ algebraically, where $x$ is greater than or equal to zero, and less than $2\pi$. Answer must be an exact solution. To be honest, I don't know where to start with this one. I know I need to isolate $\cos x$, but I have little idea as to what I need to do to get there. Is subtracting $\cos x$ from both sides the best way to go about this? Here is one thing I tried. Am I completely on the wrong track here? EDIT: $\sqrt{2}\cos x - 1 = 0$ $\cos x = \dfrac{1}{\sqrt{2}}$ $\dfrac{1}{\sqrt{2}} = 45^\circ$ $360 - 45 = 315^\circ = \dfrac{7\pi}{4}$ $\cos x = 0$
$x = 0$ at $90^\circ$, or $\dfrac{\pi}{2}$ and $270^\circ$ or $\dfrac{3\pi}{2}$ So: $x = \dfrac{\pi}{2}, \dfrac{\pi}{4}, \dfrac{3\pi}{2}, \dfrac{7\pi}{4}$",['trigonometry']
1056556,Particular $L^p$ space,"I am confusing some definitions. Suppose we have a Cauchy sequence $(f_n) \subset L^2(\Omega,C^0([0,1],\mathbb{R}))$, where $\Omega$ is a measurable space with measure $\mu$ and $C^0([0,1],\mathbb{R})$ is equipped with the uniform norm (that is a Banach space..). What can we conclude and how ? 1) $(f_n)\,\,$converges to a function $f \in L^2(\Omega,C^0([0,1],\mathbb{R}))$ because it is a complete space ? (But I do not know why is it.. I know for $L^p([a,b], \mathbb{R})$). 2) For each $\omega \in \Omega$, $f(\omega)$ is a continuous function on $[0,1]$, because $C^0([0,1],\mathbb{R})$ is a complete space (with the uniform norm) ? If these two conclusions are true, could someone write explicitly what we need to prove to get these two conclusions ? I think it is $\int_{\Omega} \sup\limits_{t\in[0,1]} \{(f_n(\omega)(t) - f_m(\omega)(t))^2\} d\mu(\omega) \stackrel{n,m\rightarrow\infty}{\longrightarrow}0$, but I am not sure and even if it is true, I do not understand why.. 
Could someone help me to clarify these few points, I am really confused for a few days ? Thank you so much. Marcus","['measure-theory', 'functional-analysis', 'lp-spaces', 'analysis']"
1056558,quadratic form corresponding to function at critical point is positive definite implies local minimum,"Let $f: \mathbb{R}^n \to \mathbb{R}$ be a $C^3$ function. Have $x_0$ be a critical point of $f$. How would I go about proving that if the quadratic form $q(h)$ corresponding to $f$ at $x_0$ is positive-definite, then $f(x_0)$ is a local minimum? I think I will probably have to push some epsilons and utilize some form of Taylor's theorem. Any help would be appreciated. Thanks!","['multivariable-calculus', 'calculus', 'linear-algebra', 'vector-analysis', 'real-analysis']"
1056607,Subsubsequence converges $\implies$ sequence converges [duplicate],"This question already has answers here : Every subsequence of $x_n$ has a further subsequence which converges to $x$. Then the sequence $x_n$ converges to $x$. (4 answers) Closed 6 years ago . Prove that if $\left\{ x_n \right\}$ is an infinite sequence of real numbers, $x \in \mathbb{R}$, and every subsequence $\left\{ x_{n_k} \right\}$ has a subsequence $\left\{ x_{n_{k_j}} \right\}$ with $x_{n_{k_j}} \rightarrow x$, then $x_n \rightarrow x$. I know that if every subsequence of a sequence converges to the same number, then the sequence converges to that same number. But I don't know if the same can be applied to subsubsequences. So for this problem, can I safely state that because $x_{n_{k_j}} \rightarrow x$, it is also true that $x_{n_k} \rightarrow x$? If this is true, then does that mean every subsequence $\left\{ x_{n_k} \right\}$ also converges to $x$?",['sequences-and-series']
1056611,Proof of the law of large numbers for higher moments,"Let us work on some probability space $<\Omega,\mathscr{A},\mathbb{P}>$: I'm looking for (independent) proofs of two proofs, of the generalised weak and strong law of large numbers respectively. That is I'm looking for proofs that the sample moments are consistency estimators of the moments of the distribution in question (given appropriate conditions thereon).
In symbols: I'm looking for two proofs that: $m_k\overset{D}{\rightarrow} \mu_k$ and $m_k\overset{as}{\rightarrow} \mu_k$ (where m_k is the $k^{th}$sample moment and $\mu_k$ is the k$^{th}$ (assuming at-most that $\mu_{k+1}<\infty$)? It would be preferable if the proof of the weak law relied on characteristic functions. Thanks in advance","['fourier-analysis', 'statistics', 'probability-theory', 'law-of-large-numbers', 'probability']"
1056623,"Is it true for every sequence $a_n$ that if $\sum a_n$ is absolutely convergent, then $\sum (-1)^n a_n$ is convergent?",The problem is in the title. I must answer the question whether it's true for every sequence $\{a_n\}_{n\geq 1}$ that if $\sum_{n=1}^{\infty} a_n$ is absolutely convergent then $\sum_{n=1}^{\infty} (-1)^n a_n$ is convergent. Here is what I came up with: $\sum_{n=1}^{\infty} |(-1)^n a_n|=\sum_{n=1}^{\infty} |a_n|$ which is convergent by assumption. So  $\sum_{n=1}^{\infty} (-1)^n a_n$ is absolutely convergent which implies that it is convergent as well. Is it correct?,"['sequences-and-series', 'calculus', 'limits']"
1056646,"If $\tan x = -1$, simplify $\tan(\pi/3+x)$","If $\tan x = -1$, simplify $\tan(\pi/3+x)$. Progress so far: See new expression in top right. What do I do to rationalize this fraction's denominator? Do I multiply the fraction by 1+sqrt3/1+sqrt3? EDIT: Okay, I'm a little confused as to what my 'final answer' will be.. mfl's answer seems as if it should be simplified. If so, which answer below is correct? Or is mfl's answer to be left as is?","['trigonometry', 'algebra-precalculus']"
1056649,Deriving Thue's lemma from Minkowski's convex body theorem,"I'm trying to find an alternative proof of Thue's lemma, stating that for $ p \in \mathbb{N}, a \in \mathbb{Z}_p^* $ $$ \text{The congruence } x \equiv ay \pmod{p} \text{ has a non-zero solution such that } |x|,|y| <\sqrt{p}$$ So I tried using Minkowski's convex body theorem in the following formulation: $$ \text{Let } L \text{ be a lattice in } \mathbb{R^d} \text{ and } K \text{ - a convex set symmetric w.r. to 0} $$ $$ \text{If } \lambda(K) \geq 2^d\text{Vol}(L) \text{, then } K \text{ has a non zero lattice point} $$ By lattice I mean an additive group generated by some vectors spanning $\mathbb{R}^d $ and its volume - an absolute value of the determinant of a matrix spanned by those vectors. Of course the set $ \{(x,y)\in \mathbb{R}^2 : ~|x|,|y| \leq \sqrt{p}\} $ is both convex and symmetric with respect to 0. Its volume is $ 4p $. Now all I need to do is find two vectors $ \alpha=(\alpha_1,\alpha_2), \beta=(\beta_1,\beta_2) $ such that the determinant: \begin{vmatrix} \alpha_1 & \alpha_2 \\ \beta_1 & \beta_2 \end{vmatrix} is not greater than $ p $ and that if $$(x,y) = n\alpha + m\beta ~~\text{ for some integers }n,m$$ then  $x -ay \equiv 0 \pmod{p}$. The problem is I can't think of a good way to find such vectors. I would appreciate any help",['number-theory']
1056671,A question (more like three) about a topological space of ordinals.,"I've been struggling with these for a while now, if anyone is willing to offer a hint I'll be more than grateful. Given an ordinal $\varepsilon$, consider the topological space $L_{\varepsilon}$ whose points are the ordinals below $\varepsilon$ and whose topology is generated by the open intervals of the form 
$$
(\alpha,\beta)=\{\gamma < \varepsilon \, :\, \alpha < \gamma < \beta \}.
$$ (a.) Determine the ordinals $\varepsilon$ for which $L_{\varepsilon}$ has the property that any two closed sets of cardinality $|\varepsilon|$ are homeomorphic. (b.) Determine the ordinals $\varepsilon$ for which $L_{\varepsilon}$ is countably compact (that is, each countable cover of $L_{\varepsilon}$ has a finite subcover). (c.) Suppose $\varepsilon$ is a cardinal. Determine the supremum among the cardinals $\lambda < \varepsilon$ such that any intersection of less than $\lambda$ closed sets of cardinality $\varepsilon$ is nonempty.","['general-topology', 'elementary-set-theory']"
1056677,Use Laplace Transform to solve the following IVP:,"I know that this is a somewhat simple problem but I have been having trouble coming up with the little ""tricks"" that help with Laplace. The problem is: $y''+2y' +5y = e^{-t}\sin(2t)$ where $y(0) = 2, y'(0) = -1$ Attempt at Solution $(s^2+2s+5)Y = \frac{2}{(s+1)^2+4} + (s+2)(2) + 1(-1)$ $Y = \frac{2}{(s^2+2s+5)^2}+\frac{2s+3}{s2+2s+5}$ $Y = \frac{2}{(s^2+2s+5)^2}+2(\frac{s+1}{s^2+2s+5})+\frac{1}{s^2+2s+5}$ $Y = \frac{2}{(s^2+2s+5)^2}+\frac{1}{2}\sin(2t)+2e^{-t}\cos(2t)$ And I am stuck here. The answer given in the book is as follows: Y = $\frac{5}{8}e^{-t}\sin(2t)+2e^{-t}\cos(2t)-\frac{1}{4}te^{-t}\cos(2t)$ Any help would be greatly appreciated.","['ordinary-differential-equations', 'laplace-transform']"
