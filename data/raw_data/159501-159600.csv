question_id,title,body,tags
2748558,How to evaluate $\int_{0}^{\infty} \int_{0}^{\infty} \frac{\sin(x) \sin(y) \sin(x+y)}{x y(x+y)} ~{\rm d}x ~{\rm d}y$?,"I came across the problem of evaluating the double integral:
$$\int_{0}^{\infty} \int_{0}^{\infty} \frac{\sin(x) \sin(y) \sin(x+y)}{x y(x+y)} ~{\rm d}x ~{\rm d}y$$
My attempt at this was to substitute $\sin(x) \cos(y) + \cos(x) \sin(y)$ for $\sin(x+y)$, although I had no clue where to go from there. My second attempt was to use trigonometric identities to rewrite the integral as:
$$\frac{1}{4} \int_{0}^{\infty} \int_{0}^{\infty} \frac{\sin(2x) + \sin(2y) - \sin(2x + 2y)}{x^2 y + x y^2} ~{\rm d}x ~{\rm d}y$$
Which didn't seem to help, so I continued to get:
$$\frac{1}{2} \int_{0}^{\infty} \int_{0}^{\infty} \frac{\sin(2x) \sin^2 (y) + \sin(2y) \sin^2 (x)}{x^2 y + x y^2} ~{\rm d}x ~{\rm d}y$$
I am sure I am missing something, but I am unsure how to integrate this. Any help or advice is appreciated.","['real-analysis', 'multiple-integral', 'multivariable-calculus', 'integration', 'improper-integrals']"
2748582,"Why is the cosine of a right angle, 90 degrees, equal to zero?","Why the cosine of an angle of 90 degree is equal to zero? By definition we know that:
$$\text{cos } \alpha = \frac{\text{adjacent}}{\text{hypotenuse}}.$$ If we want to apply the definition to the situation in the image below: we have that:
$$\text{cos } 90° = \frac{?}{h} .$$
How can I say that it is equal to $0$ if I don't know anything about the other two sides, or about the other two angles? I have been able to always find a value, even without the unit circle, in situations like $\text{csc } 90°, \text{sec } 0°$, etc...,  But not in the above situation. Why? Please, can you suggest me anything? So, I make an addition also based on suggestions provided.
My main error was to start to consider the right angle, instead I have to start considering $\theta = \alpha°$, and increse it till $\theta = 90°$, one side become smaller till zero, and the other side become bigger till equal to $h$, therefore $\text{cos } \alpha = \frac{0}{h} = 0$",['trigonometry']
2748621,Ext functor in derived categories,"For any abelian category $A$ (with enough injectives), consider its derived category $D^b(A)$. Suppose we have a complex of this form $$0\to F\to L^{n+1}\to ... \to L^{1} \to G\to 0$$
which is exact. Furthermore we have $Ext^i(G,F)=0$, for $i>n$. I want to conclude that $G\oplus F[-(n+1)]\cong [L^{n+1}\to ... \to L^{1}]$. It is said that this is implied by the vanishing of the $Ext$ functor, but I don't see why the vanishing of the $Ext$ functor is necessary . There is a canonical map $G\oplus F[-n+1]\to L^{n+1}\to ... \to L^{1}$, which is a quasi-isomorphism, so the $Ext$ shouldn't be involved here? EDIT: I was mistaken as pointed out in the comments, so I somehow need the $Ext$ vanishing. Maybe it might be helpful to know that $Ext^i(G,F)=Hom_{D(A)}(G,F[i])$? Maybe we can also consider the roof $G\leftarrow [ F\to L^{n+1}\to ... \to L^{1}]\to [0\to L^{n+1}\to ... \to L^{1} ] $, the left map being a quasi-isomorphism.","['category-theory', 'derived-functors', 'derived-categories', 'algebraic-geometry']"
2748658,Number of $4 \times 4$ matrices with sum along row or column $0$,Find the number of $4 \times 4$ matrices whose entries are each $2018$ or $—2018$ such that the sum of the  entries in each row and in each column is $0$. Now to get sum $0$ along a row we need two $2018$ and two $-2018$ and number of arrangement will be $\frac{4!}{2! 2!}$ but how adjust column while adjusting the rows or vice-versa? Could someone help me with this,"['matrices', 'permutations']"
2748749,Why small p-value rejects $H_0$,"I can't understand why people seek small $p$-value. I mean, $p$-value is the smallest level at which $H_0$ can be rejected. Making level small we minimize the probability of type $1$ error, which as I think means that we are getting more evidence against $H_0$, since now the probability of accidentally rejecting $H_0$ when it is true decreases $=>$ probability of accepting $H_0$ when it is true is becoming bigger, because $P_{H_0}(test = 1)=1-P_{H_0}(test = 0)$ When $p$-value is small we reject $H_0$, but it seems to me that when $p$-value is small it must be vice versa, because the small $p$-value corresponds to the higher probability of accepting $H_0$ when it is true. I saw the answers that you suggested... but none of them helps. I know the 'interpretation' of p-value, I can imagine it as an area under curve too, but I can't understand the relation to what I wrote above.","['statistics', 'probability']"
2748783,Investigate maxima of Gaussian integral over sphere.,"Let $\alpha>0$ be a positive parameter and consider the function $$f(x) = \int_{\mathbb S^{n-1}} e^{-\alpha \left\lVert x-y \right\rVert^2} dS(y)$$ for $x \in \mathbb R^n.$ So, since this was asked, although we integrate over the unit sphere, the function ""lives"" on $\mathbb R^n.$ This function is clearly rotationally symmetric. I would like to show that the global maxima are attained at one single radius $r$ , only. The rotational symmetry implies that we can consider it as a one-dimensional function by choosing $x=(x_1,0....,0)$ , this way the exponent simplifies to $e^{-\alpha \left\lVert x-y \right\rVert^2}=e^{-\alpha (x_1-y_1)^2+1-y_1^2}.$ If anything is unclear about this question, then please let me know. I am happy to hear about any ideas how to approach this problem. EDIT: Thanks to some interesting comments below, one can say that the global maximum is always attained at some radius $r \in [0,1]$ where for small $\alpha$ it seems to be attained close to zero and for large $\alpha$ it is attained closer to one. The question remains however why is there only one radius at which the global maximum is attained? -In fact as George Lowther points out in the comments, for $\alpha \le n/2$ the unique maximum is attained at $r=0$ which leaves the case $\alpha >n/2$ when this does not hold true.","['real-analysis', 'surface-integrals', 'multivariable-calculus', 'maxima-minima', 'analysis']"
2748784,Inequality related to spectral radius,"Let $\mathcal{L}(E)$ the algebra of all bounded linear operators from $E$ to $E$. For $A = (A_1,\cdots,A_d)\in\mathcal{L}(E)^d$, the algebraic spectral radius of $A$ was given by
$$
r_a(A)=\inf_{n\in \mathbb{N}^*}\left\|\sum_{f\in F(n,d)} A_f^* A_f\right\|^{\frac{1}{2n}} =\lim_{n\to+\infty}\left\|\sum_{f\in F(n,d)} A_f^* A_f\right\|^{\frac{1}{2n}} ,
$$
where $F(n,d):=\{f:\,\{1,\cdots,n\}\longrightarrow \{1,\cdots,d\}\}$ and $A_f:=A_{f(1)}\cdots A_{f(n)}$, for $f\in F(n,d)$. I don't understand why if $n=1$, we have
  $$r_a(A)\leq  \|A\|:=\displaystyle\sup_{\|x\|=1}\bigg(\displaystyle\sum_{k=1}^d\|A_kx\|^2\bigg)^{\frac{1}{2}}?$$","['functional-analysis', 'operator-algebras']"
2748789,"Let $M$ is compact Riemann surface, if $\omega$ is a 2-form and $\int_{M} \omega =0$ then there exists a smooth function $f$ such that $\omega=d*df$","I want to show that: $(*)$If $\omega \in \Omega^{2}(M)$, which $M$ is compact Riemann surface and $\Omega^{2}(M)$ means 2-form, and $\int_{M} \omega =0$, then there exists a smooth function $f$(i.e. $f\in \Omega^{0}(M)$) such that $\omega=d*df$ . I try to imitate the method of proof of the $\textbf{Hodge Decomposition}$: Let $\omega \in A^1(\Sigma)$, then $$\omega=\omega_{h}+df+*dg,$$
  where $\omega_{h}\in H^1$ and $f,g\in A^0(\Sigma).$ The proof of the Hodge Decomposition as following Three Steps: Step 1. To establish a complete Hilbert space Step 2. To seek $df, *dg$ (Similar to the existing of the solution of PDE) Step 3. regularity. (To use the Weyl Lemma.) Define $X=\{\phi \in \Omega^{0}(M): \int_{M} \phi d\sigma=0\}$ with $\int_{M}d\sigma=1$ and $\forall \psi, \phi \in X$, define the inner product, $$(\psi,\phi)=\langle d\psi, d\phi\rangle=\int_{\Sigma} d\psi \wedge *d\phi.$$ We could show that $\bar{X}$ is a complete Hilbert space. Moreover, if $f\in \bar{X}$, then $f\in X$(i.e. $\bar{X}\subset L^2(X,d\sigma)$). Then $\forall \phi \in C^{\infty}(X)$, we seek $g$ s.t. 
$$ \int_{\Sigma}d\phi \wedge \omega =\int_{\Sigma}d\phi \wedge *dg.$$
Here we could define a bounded linear functional $l$, which 
$$l: X\rightarrow \mathbb{C}$$
$$\phi \longmapsto  \int_{\Sigma}d\phi \wedge \omega$$ Using the Resiz representation theorem, $\exists g\in \bar{X}$, s.t.
$$l(\phi)=\langle \phi, \bar{g}\rangle, \forall g\in \bar{X}.$$
where using the regularity implies $g\in X$. In the next, 
$$\int_{M}\phi \omega= \int_{M} f d*d\phi=\int_{M} d\phi \wedge *df \ (*),$$
we get 
$$ \int_{M} \phi (\omega-d*df)=0, \forall \phi \in C^{\infty}(X),$$
Hence, $\omega-*dg$ is closed form. Finished the proof of Hodge theorem. How to construct similarly of such linear functional to prove the problem $(*)?","['riemann-surfaces', 'partial-differential-equations', 'manifolds', 'hodge-theory', 'differential-geometry']"
2748802,Show that $\int_\Omega(\sum_{n=1}^{\infty}f_n)d\mu = \sum_{n=1}^{\infty}\int_\Omega f_nd\mu$ without monotone convergence,"Let $f_n,\,n\geq1$, non-negative functions and $\mathcal{F}$-measurable in $(\Omega,\mathcal{F},\mu)$. Show that $$\int_\Omega(\sum_{n=1}^{\infty}f_n)d\mu = \sum_{n=1}^{\infty}\int_\Omega f_nd\mu$$ I supposed first that $f_n$ are simple functions, so
$f_n(\omega)=\sum_{i=1}^kx_{n,i}I_{A_{n,i}}(\omega),\,\omega\in\Omega$ So,
$$\int_\Omega(\sum_{n=1}^{\infty}f_n)d\mu = \sum_{i=1}^k\sum_{n=1}^\infty x_{n,i}\mu(A_{n,i})=\sum_{n=1}^\infty\sum_{i=1}^k x_{n,i}\mu(A_{n,i})=\sum_{n=1}^{\infty}\int_\Omega f_nd\mu$$
But, I can only do that if the sum to infinity converges. My first question is, how do I prove the case when the sum doesn't converge? Now, for general $f_n$, I can use
$$\int_\Omega f_nd\mu = \sup\bigg\{\int_\Omega\psi_n d\mu:0\leq\psi_n\leq f_n, \psi_n: simple\bigg\}$$
Then
\begin{split}
\int_\Omega\sum_n f_nd\mu &= \sup\bigg\{\int_\Omega\sum_n\psi_n d\mu:0\leq\sum_n\psi_n\leq\sum_nf_n, \psi: simple\bigg\}\\
&=\sum_n\sup\bigg\{\int_\Omega\psi_n d\mu:0\leq\psi_n\leq f_n, \psi_n: simple\bigg\}\\
&=\sum_n\int_\Omega f_nd\mu
\end{split}
Can I do that? Won't I have the same problem with the non-convergence? Someone could help, please?","['probability-theory', 'lebesgue-integral', 'measure-theory']"
2748870,Finding a metric to make a certain curve a circle,"Given a  simple closed, regular $C^\infty$ curve $\phi$ in $U\subset\mathbb{R}^n$ naturally parametrized (by it's arc length), is there any way to
obtain a Riemaniann manifold $(S,g)$ of dimension 2 without boundary (isometrically embedded in $\mathbb{R}^m$ equipped with the standard metric) such that there is a geodesic circle in this surface that is equal to the curve (meaning that it is mapped by the embedding to $\phi$ )? Two examples: $1)\gamma(t)=\begin{pmatrix} \left(\frac{\sin(20\pi t)}{10}+1\right)\sin(2\pi t)\\ \left(\frac{\sin(20\pi t)}{10}+1\right) \cos(2\pi t)\\ \sin(2\pi t)\end{pmatrix}\\
2)\gamma(t)=\begin{pmatrix} \left(\frac{\sin(20\pi t)}{10}+1\right)\sin(2\pi t)\\ \left(\frac{\sin(20\pi t)}{10}+1\right) \cos(2\pi t)\end{pmatrix}$ One possibility, considering $\gamma \in \mathbb{R}^2$ , is to use the Riemann smooth mapping theorem in such a way to obtain a complex diffeomorphism $\phi$ between $\gamma\bigcup \text{Int}(\gamma)$ and the closed unitary disk $D$ . In this way, we might define the metric tensor on $S=\phi^{-1}(D)$ as the pullback of the euclidean metric tensor restricted to the unitary disk, but that leaves us with a manifold with boundary. We may try to extend it, but such a subject is quite technical, and I would not know how to proceed. Even if this idea was succesful This method would work only in $\mathbb{R}^2$ , leaving open the question for $n>2$ . The questions are thus:
1) Is my idea efficient to solve the problem in $\mathbb{R}^2$ ? If so, how to remove the boundary? 2)How to attack the problem if $\gamma \subset \mathbb{R}^n$ with $n>2$ (as an example, see the first example)?","['circles', 'metric-spaces', 'differential-geometry', 'differential-topology']"
2748886,Generalizing $ \frac{a^2+b^2+c^2}{2} \times \frac{a^3+b^3+c^3}{3} = \frac{a^5+b^5+c^5}{5}$,"If $a+b+c=0$ as discussed in this , this , and this post, then, $$ \frac{a^2+b^2+c^2}{2} \times \frac{a^3+b^3+c^3}{3} = \frac{a^5+b^5+c^5}{5}\tag1 $$
$$ \frac{a^3+b^3+c^3}{3} \times \frac{a^4+b^4+c^4}{2} = \frac{a^7+b^7+c^7}{7}\tag2 $$
$$ \frac{a^2+b^2+c^2}{2} \times \frac{a^5+b^5+c^5}{5} = \frac{a^7+b^7+c^7}{7}\tag3 $$
Using these basic identities, we can prove the nice squared identities here , 
$$ \frac{a^3+b^3+c^3}{3}\times \frac{a^7+b^7+c^7}{7} = \left(\frac{a^5+b^5+c^5}{5}\right)^2 $$ and here for $(a^7+b^7+c^7)^2$. Some investigation shows that, $$\frac{(a^5+b^5+c^5)}{5\times18}\times\big(9(a^6+b^6+c^6) -(a^3+b^3+c^3)^2\big)=  \frac{a^{11}+b^{11}+c^{11}}{11}\tag4$$
$$\frac{(a^7+b^7+c^7)}{7\times18}\times\big(9(a^6+b^6+c^6) +(a^3+b^3+c^3)^2\big)=  \frac{a^{13}+b^{13}+c^{13}}{13}\tag5$$ Q: What would be the corresponding identities, as concise as possible, for $p=17$ and $p=19$?","['algebra-precalculus', 'number-theory']"
2748901,Solution of ${x}^{2} \dfrac {d^{2}y}{dx^{2}}+ x \dfrac{dy}{dx}+y=0 $,"Find the general solution of $${x}^{2} \dfrac {d^{2}y}{dx^{2}}+ x \dfrac{dy}{dx}+y=0 $$ $$$$ This is an example of a Cauchy-Euler equation. However I'm interested in solving it without assuming a solution of the form $y=x^m$ $$$$ I tried as follows: Let $D=\dfrac{dy}{dx}$ . $$$$ Thus $$x^2\dfrac{dD}{dx}+xD+y=0$$ Differentiating wrt $x$ , $$x^2\dfrac{d^2D}{dx^2}+2x\dfrac{dD}{dx}+D+x\dfrac{dD}{dx}+D=0$$ $$x^2\dfrac{d^2D}{dx^2}+3x\dfrac{dD}{dx}+2D=0$$ Could somebody please suggest how I could go about solving this?","['complex-analysis', 'ordinary-differential-equations', 'calculus']"
2748907,"If $\frac{\cos^4 \alpha}{x}+\frac{\sin^4 \alpha}{y}=\frac{1}{x+y}$,prove that $\frac{dy}{dx}=\tan^2\alpha$","If $\frac{\cos^4 \alpha}{x}+\frac{\sin^4 \alpha}{y}=\frac{1}{x+y}$,prove that $\frac{dy}{dx}=\tan^2\alpha$ It is very long to direct differentiate it.Can someone help me?","['derivatives', 'trigonometry']"
2748911,Sum of infinitely many integrals over a bounded interval,"Recalling from my days in Calc BC that if we have some integrable function $\ f\colon \mathbb R \to \mathbb R, x \mapsto f(x)$, three numbers $\ a,b,c \in \mathbb R,a \lt b \lt c$ and we know $\int_a^c f(x)\, dx=A$, then it follows that $\int_a^b f(x)\, dx +\int_b^c f(x)\, dx =A$, too. This always bothered me, because it seems like we're double counting at b. To take the above property to its extreme, I wondered what would happen if we start dividing up the interval $[a,c]$ into smaller and smaller chunks and then summing up the integrals over said smaller and smaller chunks. In mathematical notation, I believe the above would be expressable as follows – define some $N \in \mathbb N$ and let $c-a=N\epsilon$, and take $$\displaystyle\lim_{N \to \infty} \displaystyle \sum_{j=0}^{N-1} \int_{a+j\epsilon}^{a+(j+1)\epsilon} f(x)\, dx.$$ My question is, can this above expression ever $\ne A$? If not, why does double counting a point on an integral an infinite number of times not affect its net value? As a follow up, what could happen if we let the various limits of integration overlap on some small interval larger than a point? Thanks!","['real-analysis', 'measure-theory', 'calculus', 'analysis']"
2748927,Curve dense inside the unit circle,"For $\alpha$ a real, irrational number, I have been to prove that any point $(x,y)$ such that $x^2 + y^2 \leq 2$ can be written as $$(x,y) = (\cos( u) + \cos( \alpha u), \ \sin( u) + \sin(\alpha u)) $$  for some $u \in \mathrm{R}$. It is easy to show that this is not true if $\alpha$ is rational. In that case, the vector function is periodic, and the curve it traces is closed. It is also easy to see that the function is not periodic if $\alpha$ is rational. What is less trivial to argue, however, is that the curve fills the full circle.","['real-analysis', 'functions', 'parametric', 'parametrization', 'graphing-functions']"
2748955,Weak derivative of $|x|^\alpha$ in $\mathbb{R}^N \setminus \{0\}$,"I want to generalize the fact that the weak derivative of $|x|$ is $sgn(x)$. The expected result should be $\frac{d|x|^{\alpha}}{dx_i} = \alpha x_i |x|^{\alpha - 2}$. A way to do this is found in page 50 of these notes . However, I don't have the tools to believe that: $|x|^{\alpha}$ is weakly differentiable provided that the pointwise derivative,
  which is defined almost everywhere, is locally integrable So I would like to do it without using this fact. The domain I think weak derivatives have a dependence on the domain so I specify that I want the derivative of $|x|^{\alpha}$ in $\mathbb{R}^N \setminus \{0\}$ The computation $\int |x|^{\alpha} \frac{d\phi}{dx_i} d(x_1,\ldots,x_N)$, $\phi \in \mathcal{C}_0^{\infty}$, by Fubini's theorem (?) I can write: $\int_{\mathbb{R}^{N-1} \setminus \{0\}} (\int_{\mathbb{R} \setminus \{0\}} |x|^{\alpha} \frac{d\phi}{dx_i} dx_i) d(x_1,\ldots,x_{i-1},x_{i+1},x_N)$ integrating by parts $\int_{\mathbb{R} \setminus \{0\}} |x|^{\alpha} \frac{d\phi}{dx_i} dx_i$ and using that $\phi \in \mathcal{C}_0^{\infty}$: $\int_{-\infty}^0 |x|^{\alpha} \frac{d\phi}{dx_i} dx_i = 
-\int_{-\infty}^0 \alpha x_i |x|^{\alpha-2} \phi dx_i$, analogously, $\int_{0}^\infty |x|^{\alpha} \frac{d\phi}{dx_i} dx_i = 
-\int_{0}^\infty \alpha x_i |x|^{\alpha-2} \phi dx_i$ so that I get the result equal to: $-\int_{\mathbb{R}^N \setminus \{0\}} \alpha x_i|x|^{\alpha}\phi dx_i$ The only thing to finish the proof would be to see where I missed the - sign.","['real-analysis', 'proof-verification', 'multivariable-calculus', 'weak-derivatives', 'sobolev-spaces']"
2748973,Are vectors and the derivative of $\left|x\right|$ related?,"So, in our lesson about derivatives, we learnt that $$\frac{\mathrm{d}\left|x\right|}{\mathrm{d}x}=\frac{x}{\left|x\right|}$$ This is just an application of the chain rule, since $\left|x\right|=\sqrt{x^2}$. The above looks suspiciously similar to the formula for a unit vector, which is$$\hat{x}=\frac{\vec{x}}{\left|\vec{x}\right|}$$ and in fact, if $\vec{x}$ is a one dimensional vector (on the real number line), $x$ can be taken to be just a number, which gives us the first relation. Is it right to reason that this can be extended to the complex numbers as well? That would mean if $$x=a+bi$$ then $$\frac{\mathrm{d}\left|x\right|}{\mathrm{d}x}=\frac{a+bi}{\sqrt{a^2+b^2}}$$ or in general, $$\frac{\mathrm{d}\left|\vec{x}\right|}{\mathrm{d}x}=\hat{x}$$ Am I right? Or is there a flaw in my reasoning? I'm asking because it's just an observation. I would be glad if someone could explain this.","['derivatives', 'vectors', 'calculus']"
2749067,Disprove $m!=100x^2+20x$ using an estimation for factorial. [duplicate],"This question already has answers here : $n!+1$ being a perfect square (3 answers) Closed 4 years ago . $\newcommand{\floor}[1]{\lfloor #1 \rfloor}$
I have the equation $m!=100x^2+20x$ where $x$ and $m$ are real non-negative integers. I wish to disprove for when $m\geq20$ how can I do this?
I had an idea that is based on ending digits. For example m! can be divided by $10^{\floor{\frac{m}{5}}-1}$ and still end in a $0$. I was wondering if one could put an argument for that the equation doesn't exist. Using iteration.
For example if I substitute  $x$ with $10x_1+5$(other correct substitution is $10x_1+10$ one gets $m!/200=50x_1^2+51x_1+13$ then one can proof that $x_2$ ends in a $7$ so $\therefore$ I can substitute $ x_1$ for $10x_2+7.$ Can one prove the following equation doesn't equal possibly using a lower bound on the approximation of the factorial function. My method $\sqrt{2\pi}m^{m+0.5}e^{-m}$is the lower bound for $m!$","['number-theory', 'factorial', 'open-problem', 'ceiling-and-floor-functions']"
2749078,Definition of the twist of varieties,"Suppose $k$ is a field and $K$ is a Galois extension of $k$. If $X$ is a variety defined over $k$, let $\text{Aut}(X/k)$ be the group of $k$ automorphisms of $X$, i.e. isomorphisms from $X$ to $X$ in the category of $k$-varieties,
$\require{AMScd}$
\begin{CD}
    X @>f>> X\\
    @V V V @VVV\\
    \text{Spec}\,k @>>\text{Id}> \text{Spec}\,k
\end{CD}
Then a twist of $X$ is a variety $X'$ over $k$, such that there is a $K$-isomorphism $\phi$
$\require{AMScd}$
\begin{CD}
    X' \times_{\text{Spec}\,k} \text{Spec}\,K @>\phi>> X\times_{\text{Spec}\,k} \text{Spec}\,K\\
    @V V V @VVV\\
    \text{Spec}\,K @>>\text{Id}> \text{Spec}\,K
\end{CD}
Then from literatures (e.g. Chapter X of The Arithmetic of Elliptic Curves by Silverman), there is a map associated to $\phi$ defined by
\begin{equation}
\xi: \text{Gal}(K/k) \rightarrow \text{Aut}(X/k),~\sigma \rightarrow \phi^\sigma \circ \phi^{-1}
\end{equation} Question 1 : What is $\phi^{\sigma}$? Is it given by the composition
\begin{equation}
X' \times_k K \xrightarrow{\sigma} X' \times_k K \xrightarrow{\phi} X \times_k K
\end{equation}
where the first morphism is given by $\sigma$ acting on the second factor of $X' \times_k K $?  If so, how to see $\phi^\sigma \circ \phi^{-1}$ is a $k$-automorphism of $X$? Question 2 : In Silverman's book, it says that $\xi$ measures $\phi$'s failure to be defined over $k$, could anyone explain the intuitions behind this statement? any interesting examples?","['number-theory', 'elliptic-curves', 'algebraic-geometry']"
2749084,tangent of the evolute is normal to curve and compute the length of the evolute,"Let $s : (a,b) \rightarrow \mathbb{R^2} $ be a regular parameterized curve ( arc length parameterized) with curvature  $k(x) \neq 0 \forall x\in (a,b) $. We define the evolute of $s$ $e(x) :=s(x)+\frac{1}{k(x)}n(x),\quad x\in (a,b)$ $1)$
Show that the tangent at $x$ of the evolute of $s$ is the normal to $s$ at $x$. $2)$ Now assume that $k'(x) < 0 \forall x \in(a,b) $  and show that: $$L( e_{[i,j]}) =  \frac{1}{k(j)} - \frac{1}{k(i)}$$ for $ a < i \leq j < b $. For $1)$:  I know that we have to show: $\langle e'(x),s'(x)\rangle = 0 $. $e'(x) = s'(x)-\frac{k'(x)}{k(x)^2}n(x)+\frac{1}{k(x)}n'(x). $ Now I read that I have to use: $\langle s''(x), n(x) \rangle = - \langle s'(x),n'(x) \rangle $ and  $s''(x) = k(x)n(x) $ . I have already shown both equations but how can I use them to solve this exercise? For $2)$ $L( e_{[i,j]}) = \int_{i}^{j} ||e'(x)|| dx = \int_{i}^{j} ||s'(x)-\frac{k'(x)}{k(x)^2}n(x)+\frac{1}{k(x)}n'(x)|| dx $ but what can I do now? We know that $k'(x) < 0 $ and maybe we can use $1)$ ?","['curves', 'differential-geometry', 'curvature']"
2749209,Why is a term that comes out of a variance bracket is squared?,I am in a course on data analysis. The following statement is made in the notes made available to us by our professor: $$ \text{Var}[a] = \text{Var}[\bar{y} -b\bar{x}] = \text{Var}[\bar{y}]  + \text{Var}[b\bar{x}] = \dfrac{\sigma^2}{n} + {\color{red}{(\bar{x}^2)}}\text{Var}[b]$$ I have marked the place where I have doubt in red. This is the expression to determine the variance of point estimates in a simple linear regression model. Thank you.,"['regression', 'statistics', 'linear-regression']"
2749244,"Prob. 10, Sec. 3.5, in Bartle & Sherbert's INTRO TO REAL ANALYSIS: If $x_1 < x_2$ are arbitrary real numbers and . . .","Here is Prob. 10, Sec. 3.5, in the book Introduction to Real Analysis by Rovert G. Bartle and Donald R. Sherbert, 4th edition: If $x_1 < x_2$ are arbitrary real numbers and $x_n \colon= \frac{1}{2} \left( x_{n-2} + x_{n-1} \right)$ for $n > 2$, show that $\left( x_n \right)$ is convergent. What is its limit? My Attempt: As $x_1 < x_2$, so 
  $$ x_1 < \frac{1}{2} \left( x_1 + x_2 \right) < x_2, $$
  that is, 
  $$ x_1 < x_3 < x_2. \tag{1} $$
  And also 
  $$ \left\lvert x_3 - x_2 \right\rvert = x_2 - x_3 = \frac{1}{2} \left( x_2 - x_1 \right). \tag{2} $$ Now as $x_3 < x_2$, so 
  $$ x_3 < \frac{1}{2} \left( x_3 + x_2 \right) < x_2, $$
  that is, 
  $$ x_3 < x_4 < x_2. \tag{3} $$ 
  And also 
  $$ \left\lvert x_4 - x_3 \right\rvert = x_4 - x_3 = \frac{1}{2} \left( x_2 - x_3 \right) = \frac{1}{2} \left\lvert x_2 - x_3 \right\rvert = \frac{1}{2^2} \left( x_2 - x_1 \right). \tag{4} $$ Now as $x_3 < x_4$, so 
  $$ x_3 < \frac{1}{2} \left( x_3 + x_4 \right) < x_4, $$
  that is, 
  $$ x_3 < x_5 < x_4. \tag{5} $$
  And also 
  $$ \left\lvert x_5 - x_4 \right\rvert = x_4 - x_5 = \frac{1}{2} \left( x_4 - x_3 \right) = \frac{1}{2} \left\lvert  x_4 - x_3 \right\rvert = \frac{1}{2^3} \left( x_2 - x_1 \right). \tag{6} $$ Now as $x_5 < x_4$, so 
  $$ x_5 < \frac{1}{2} \left( x_5 + x_4 \right) < x_4, $$
  that is, 
  $$ x_5 < x_6 < x_4. \tag{7} $$
  And also 
  $$ \left\lvert x_6 - x_5 \right\rvert = x_6 - x_5 = \frac{1}{2} \left( x_4 - x_5 \right) = \frac{1}{2} \left\lvert x_5 - x_4 \right\rvert = \frac{1}{2^4} \left( x_2 - x_1 \right). \tag{8} $$ From (1), (3), (5), and (7), we get 
  $$ x_1 < x_3 < x_5 < x_6 < x_4 < x_2. \tag{9} $$ Now let $k \in \mathbb{N}$ such that $k \geq 3$, and suppose that 
  $$ x_1 < x_3 < x_5 < \cdots < x_{2k-1} < x_{2k} < x_{2k-2} < \cdots < x_4 < x_2. \tag{10} $$
  And suppose also that 
  $$ \left\lvert x_{2k} - x_{2k-1} \right\vert = \frac{1}{ 2^{2k-2} } \left( x_2 - x_1 \right). \tag{11} $$ Then as $x_{2k-1} < x_{2k}$, so 
  $$ x_{2k-1} < \frac{1}{2} \left( x_{2k-1} + x_{2k} \right) < x_{2k}, $$
  that is, 
  $$ x_{2k-1} < x_{2k+1} < x_{2k }. \tag{12} $$
  And also 
  $$ \left\lvert x_{2k+1} - x_{2k} \right\rvert = x_{2k}  - x_{2k+1} = \frac{1}{2} \left( x_{2k} - x_{2k-1} \right) = \frac{1}{2} \left\lvert  x_{2k} - x_{2k-1} \right\rvert = \frac{1}{ 2^{2k-1} } \left( x_2 - x_1 \right). \tag{13}  $$ Now as $x_{2k+1} < x_{2k}$, so 
  $$ x_{2k+1} < \frac{1}{2} \left( x_{2k+1} + x_{2k} \right) < x_{2k}, $$
  that is, 
  $$ x_{2k+1} < x_{2k+2} < x_{2k}. \tag{14} $$ From  (10), (12), and (14), we can conclude that 
  $$ x_1 < x_3 < x_5 < \cdots < x_{2k-1} < x_{2k+1} < x_{2k+2} < x_{2k} < \cdots < x_6 < x_4 < x_2 \tag{15} $$
  for all $k \in \mathbb{N}$. [I'm not really sure what to do with this relation though.] Also from (11) and (13), we can conclude that 
  $$ \left\lvert x_{n+1} - x_n \right\rvert = \frac{1}{2^{n-1} } \left( x_2 - x_1 \right). \tag{A} $$
  for all $n \in \mathbb{N}$ such that $n \geq 2$. So for any natural numbers $m$ and $n$ such that $m > n$, we obtain
  $$
\begin{align}
\left\lvert x_m - x_n \right\rvert &\leq \left\lvert x_m - x_{m-1} \right\rvert + \cdots + \left\lvert x_{n+1} - x_n \right\rvert \\
&= \left( \frac{1}{2^{m-2} } + \cdots + \frac{1}{2^{n-1} } \right) \left( x_2 - x_1 \right) \\
&= \left( \frac{1}{2^{n-1} } + \frac{1}{2^{n} } \cdots + \frac{1}{2^{m-2} } \right) \left( x_2 - x_1 \right) \\
&= \frac{1}{2^{n-1}} \left( 1 + \frac{1}{2} + \cdots + \frac{1}{2^{m-n-1}} \right) \left( x_2 - x_1 \right) \\
&= \frac{1}{2^{n-1}} \frac{ 1 - \frac{1}{2^{m-n}} }{ 1 - \frac{1}{2} } \left( x_2 - x_1 \right) \\
&= \frac{1}{2^{n-2}} \left( 1 - \frac{1}{2^{m-n}} \right) \left( x_2 - x_1 \right) \\
&< \frac{1}{2^{n-2}}  \left( x_2 - x_1 \right). \tag{B}
\end{align}
$$ So, given $\varepsilon > 0$, if we choose a natural number $N$ so that 
  $$ N > \frac{ 4 \left(x_2 - x_1 \right)  }{ \varepsilon }, $$ then 
  $$ 2^N > N > \frac{ 4 \left(x_2 - x_1 \right)  }{ \varepsilon }, $$
  and so 
  $$ \varepsilon > \frac{ 4 \left( x_2 - x_1 \right) }{ 2^N}.$$
  and then we see from (B) that, whenever $m$ and $n$ are any natural numbers such that $m > n > N$, we have 
  $$ \left\lvert x_m - x_n \right\rvert < \frac{1}{2^{n-2}} \left( x_2 - x_1 \right) = \frac{4 \left( x_2 - x_1 \right) }{ 2^n} < \frac{4 \left( x_2 - x_1 \right)}{2^N} < \varepsilon. $$ Thus our sequence is a Cauchy sequence of real numbers. Therefore, this sequence is convergent. Let $x$ be the limit of this sequence. Then the subsequences 
  $\left( x_{2k-1} \right)_{k \in \mathbb{N}}$ and $\left( x_{2k } \right)_{k \in \mathbb{N}}$ also converge to this same limit $x$. Now $$ x_3 = \frac{x_2 + x_1 }{2}, $$
  and so $$ x_4 = \frac{x_3 + x_2}{2} = \frac{ \frac{x_2 + x_1 }{2} + x_2  }{2} = \frac{ 3x_2 +  x_1 }{4},$$
  and hence $$ x_5 = \frac{ x_4 + x_3 }{2} = \frac{ \frac{ 3x_2 +  x_1 }{4} + \frac{x_2 + x_1}{2} }{2} = \frac{ 5 x_2 + 3 x_1 }{8}. $$ Thence $$ x_6 = \frac{ x_5 + x_4 }{2} = \frac{ \frac{ 5 x_2 + 3 x_1 }{8} + \frac{ 3 x_2 +  x_1 }{4} }{2} = \frac{ 11 x_2 + 5 x_1 }{16}, $$
  and so 
  $$ x_7 = \frac{ x_6 + x_5 }{2} = \frac{ \frac{ 11 x_2 + 5 x_1 }{16} + \frac{ 5 x_2 + 3 x_1 }{8} }{2} = \frac{ 21 x_2 + 11 x_1 }{32}. $$
  Then 
  $$ x_8 = \frac{ x_7 + x_6 }{2} = \frac{ \frac{ 21 x_2 + 11 x_1 }{32} + \frac{ 11 x_2 + 5 x_1 }{ 16 } }{2} = \frac{ 43 x_2 + 21 x_1 }{ 64}, $$
  and so 
  $$ x_9 = \frac{ x_8 + x_7 }{2} = \frac{ \frac{ 43 x_2 + 21 x_1 }{64} + \frac{ 21 x_2 + 11 x_1 }{32} }{2} = \frac{ 85 x_2 + 43 x_1 }{128}. $$ Generalising from these formulas for $x_3$ through $x_9$, we suppose that $k \in \mathbb{N}$ such that $k > 1$ and that 
  $$ x_{2k - 1} = \frac{ \frac{ 2^{2k-2} - 1}{3} x_2  +  \frac{ 2^{2k-3} + 1}{3}  x_1  }{ 2^{2k-3} } = \frac{  \left( 2^{2k-2} - 1 \right) x_2 + \left( 2^{2k-3} + 1 \right) x_1   }{ 3 \times 2^{2k-3} }, $$
  and 
  $$ x_{2k} = \frac{ \frac{ 2^{2k-1} + 1}{3} x_2 + \frac{ 2^{2k-2} - 1}{3}  x_1  }{2^{2k-2}} = \frac{  \left( 2^{2k-1} + 1 \right) x_2 + \left( 2^{2k-2} - 1 \right)  x_1  }{ 3 \times 2^{2k-2} }. $$ Then we find that 
  $$
\begin{align}
x_{2k+1} &= \frac{ x_{2k} + x_{2k-1} }{2} \\ 
&= \frac{ \frac{  \left( 2^{2k-1} + 1 \right) x_2 + \left( 2^{2k-2} - 1 \right)  x_1  }{ 3 \times 2^{2k-2} } +  \frac{  \left( 2^{2k-2} - 1 \right) x_2 + \left( 2^{2k-3} + 1 \right) x_1   }{ 3 \times 2^{2k-3} } }{2} \\
&= \frac{ \left( 2^{2k-1} + 1 \right) x_2 + \left( 2^{2k-2} - 1 \right)  x_1  + 2 \left( 2^{2k-2} - 1 \right) x_2 + 2 \left( 2^{2k-3} + 1 \right) x_1   }{ 3 \times 2^{2k-1} } \\
&= \frac{ \left( 2^{2k} - 1 \right) x_2 + \left( 2^{2k-1} + 1  \right) x_1  }{ 3 \times 2^{2k-1} },  
\end{align}
$$ 
  and hence 
  $$
\begin{align} 
 x_{2k+2} &= \frac{ x_{2k+1} + x_{2k} }{2} \\
&= \frac{ \frac{ \left( 2^{2k} - 1 \right) x_2 + \left( 2^{2k-1} + 1  \right) x_1  }{ 3 \times 2^{2k-1} }  + \frac{  \left( 2^{2k-1} + 1 \right) x_2 + \left( 2^{2k-2} - 1 \right)  x_1  }{ 3 \times 2^{2k-2} } }{2}  \\
&= \frac{ \left( 2^{2k} - 1 \right) x_2 + \left( 2^{2k-1} + 1  \right) x_1   + 2 \left( 2^{2k-1} + 1 \right) x_2 + 2 \left( 2^{2k-2} - 1 \right)  x_1  }{ 3 \times 2^{2k}  } \\
&= \frac{ \left( 2^{2k+1} + 1 \right) x_2 + \left( 2^{2k} - 1 \right)x_1 }{ 3 \times 2^{2k} }. 
\end{align}
$$ Thus the induction is complete, and so we can conclude that, for every natural number $k > 1$, we have 
  $$ x_{2k-1} = \frac{  \left( 2^{2k-2} - 1 \right) x_2 + \left( 2^{2k-3} + 1 \right) x_1   }{ 3 \times 2^{2k-3} } = 
\frac{1}{3} \left[  \left( 2 - \frac{1}{2^{2k-3}} \right) x_2 + \left( 1 + \frac{1}{2^{2k-3}} \right) x_1 \right], \tag{C} $$
  and 
  $$ x_{2k} = \frac{  \left( 2^{2k-1} + 1 \right) x_2 + \left( 2^{2k-2} - 1 \right)  x_1  }{ 3 \times 2^{2k-2} } = \frac{1}{3} \left[ \left( 2 +  \frac{1}{2^{2k-2}} \right) x_2 + \left( 1 - \frac{1}{ 2^{2k-2} } \right) x_1  \right]. \tag{D} $$ Now as 
  $$ \lim_{k \to \infty} \frac{ 1 }{2^{2k-2} } = 0 = \lim_{k \to \infty} \frac{1}{2^{2k-3}}, $$
  so from formulas (C) and (D), we can conclude that 
  $$ \lim_{k \to \infty} x_{2k-1} = \frac{ 2x_2 +  x_1 }{3} = \lim_{ k \to \infty} x_{2k}. $$
  Therefore, 
  $$ \lim_{n \to \infty} x_n = \frac{ 2x_2 +  x_1 }{3}. $$ Is what I've done correct? I know I have protracted my solution way way beyond the solution expected, but what is the shorter approach to it, I wonder?","['real-analysis', 'sequences-and-series', 'convergence-divergence', 'limits']"
2749278,Presentations of Amalgamated Free Products of Two Groups.,"Suppose we have an amalgamated free product $H\ast_LK$ of groups $H$ and $K$ with respect to a (normal) subgroup $L$ (of both $H$ and $K$ ), where $H\equiv\langle X\mid R\rangle$ and $K\equiv\langle Y\mid S\rangle$ . What is a presentation for $H\ast_LK$ in terms of $\langle X\mid R\rangle$ and $\langle Y\mid S\rangle$ ? I've looked in (the old version of) ""Presentation (sic) of Groups,"" by D. L. Johnson; ""Combinatorial Group Theory: Presentations of Groups in Terms of Generators and Relations,"" by Magnus et al. ; and ""Combinatorial Group Theory,"" by Lyndon et al. It doesn't seem to be anywhere obvious online. My main issue is that I'm not working with a definition of amalgamated free products of groups, only a vague understanding; the definition on Wikipedia (in the generalisation section of the article on free products) is satisfactory, I guess, but I could do with an equivalent definition (if there be such) from a combinatorial group theoretic perspective rather than a categorical one - and I think answering the question here will provide one. (Thus I've added the definition tag.) I don't have a copy of the latest ""Presentation $\color{red}{s}$ of Groups,"" by D. L. Johnson but, apparently, it's in there somewhere, so please don't just cite the book unless there's a Google books page of the presentation or something like that.","['free-product', 'combinatorial-group-theory', 'group-presentation', 'group-theory', 'definition']"
2749300,Isolating $a_n$ in a recursive formula,"I have three equations with three sequences, $a_n, b_n, c_n$.
I tried to isolate $a_n$ with no luck. $$a_n = 2b_{n-1}+c_{n-1}$$
$$b_n=2a_{n-1}+2b_{n-1}+c_{n-1}$$
$$c_n = 4a_{n-1}+4b_{n-1}$$ Is it even possible to get an expression based only on $a_n$ terms here?","['recursion', 'sequences-and-series']"
2749318,Modulus of Analytic Function is Bounded Above,"I have the following problem that I am stuck on: Let $f$ be analytic in $D=\{z\in\mathbb{C}\::\:|z|<1\}$ and suppose that $|f(z)|<M$ for all $z\in D$ . (a) If $f(z_{k})=0$ for $1\leq k\leq n$ , show that $$|f(z)|\leq M\prod_{k=1}^{n}\frac{|z-z_{k}|}{|1-\bar{z}_{k}z|}$$ for $|z|<1$ . (b) If $f(z_{k})=0$ for $1\leq k\leq n$ , each $z_{k}\neq 0$ , and $f(0)=Me^{i\alpha}(z_{1}z_{2}\cdots z_{n})$ , find a formula for $f$ . I honestly have no idea of where to begin with this problem. I think that Schwarz's Lemma may be needed somewhere? Thanks in advance for any help!","['complex-analysis', 'analytic-functions']"
2749324,Does a finite state machine have to use all the input?,"I'm trying to make a finite automata but am unsure about this detail. If the machine reaches the goal state before the input is finished, can the machine accept or does it have to continue going if possible?","['automata', 'discrete-mathematics']"
2749345,Irreducible representation and base change of fields,"Let $G$ be a group, $k$ an algebraically closed field, and $V$ be a finite dimensional irreducible $k$-representation of $G$. Consider a field extension $L/k$, must $V_L=V \otimes_k L$ still be irreducible? Motivation: this is a continuation of this question , from which we know $\operatorname{Hom}_G(V,V) \otimes_k L= \operatorname{Hom}_G(V_L,V_L)$ i.e $End_G(V_L)=L$ hence $V_L$ is indecomposible. If $V$ is semisimple (for example when $k=\Bbb C$ and $G$ is finite) then we know $V$ is irreducible. I am interested in the general case, and without loss of generality we can assume $G$ is closed subgroup of $GL(V)$ over $k$.","['representation-theory', 'group-theory', 'algebraic-geometry']"
2749359,Proving $\int_0^\infty e^{-(1-a^2)x^2} \cos(2ax^2)dx = \frac{\sqrt{\pi}}{2(1+a^2)}$,"I try show, that the following integral (for $0<a<1$) gives: $\int_0^\infty e^{-(1-a^2)x^2} \cos(2ax^2)dx = \frac{\sqrt{\pi}}{2(1+a^2)}$ I guess the way to go is complex Integration and using the fact, that this is the same as 
$\frac{1}{2}\int_{- \infty}^\infty e^{-(1-a^2)x^2} \cos(2ax^2)dx $ First I tried to use a rectangular shaped path in the complex plane, which I sucessfully used at a similar problem a while ago. Poorly I didn't remember, that this only seems to work for a linear term $2ax$ i the cosine. EDIT: This way is shown in a very similar way as I did in: Evaluatig: $\int_{0}^{\infty}{e^{ax^2}\cos(bx)dx}$ But as mentioned - this doesn't seem to work in my case... My second idea was to get some hints for the path I should use via concerning the given result. So I guess (because there is $(1+a^2)$ in the denominator) I need to integrate $e^{-(1+a^2)^2x^2}$ to get this term via using the Gaussian integral $\int_{-\infty}^{\infty} e^{-bx^2} dx = \sqrt{\frac{\pi}{b}}$.
Although  I tried to find some complete square I wasn't able to produce the necessary terms (without getting loads of waste, which makes it difficult again) I would be very grateful, if anyone could help me or give me a hint how to solve this integral! Thanks!","['gaussian-integral', 'complex-analysis', 'integration']"
2749389,Determine invariant subfield and order in $\operatorname{Aut}(L)$,"I'm trying to determine some explicit invariant subfields of $L=\mathbb{Q}(X)$. We have defined $\sigma_i\in$ Aut$(L)$ with $$\sigma_1(X)=1/X,\  \sigma_2(X)=1-X.$$ We are now asked to determine the invariant subfields $L^{\langle\sigma_i\rangle}$ for i=1,2. Also we must show that $\rho=\sigma_1\sigma_2$ has order 3 in Aut$(L)$ and we have to determine $L^{\langle\rho\rangle}$. For the first part I think it's almost complete.$$\text{Claim:}\ L^{\langle\sigma_1\rangle}=\mathbb{Q}(X+1/X).$$ We know $\langle\sigma_1\rangle=\{id,\sigma_2\}$ and by our definition of $L$ that $\mathbb{Q}(X+1/X)\subseteq L^{\langle\sigma_1\rangle}\subseteq \mathbb{Q}(X)$. We now say the minimum polynomial of $1/X$ is $f_{\mathbb{Q}(X+1/X)}^{1/X}=T^2-(X+1/X)T+1\in \mathbb{Q}(X+1/X)[T]$. Because the degree of $f_{\mathbb{Q}(X+1/X)}^{1/X}$ is 2, $[\mathbb{Q}:\mathbb{Q}(X+1/X)]=2$. We also know that $X\notin L^{\langle\sigma_1\rangle}$ so $L^{\langle\sigma_1\rangle}\neq\mathbb{Q}(X).$ Hence the claim is true. $$\text{Claim:}\ L^{\langle\sigma_2\rangle}=\mathbb{Q}(X(1-X)).$$ The claim is a guess because I suppose by $\sigma_2$ we have that $X\mapsto1-X$ and conversely $1-X\mapsto X$ (so together they make $X$?). Lastly, because in Aut$(L)$ we have that $X\mapsto1$ and therefore $$\rho^3=(\sigma_1\sigma_2)^3=(1/X-1)^3=1/X^3-3/X^2+3/X-1=1-3+3-1=0$$ and the order of $\rho$ is 3. Am I thinking on the right path or is this not even close? All hints and/or answers are highly appreciated!","['galois-theory', 'galois-extensions', 'automorphism-group', 'abstract-algebra', 'group-theory']"
2749422,Probability of choosing ace of spades before any club,"From a deck of $52$ cards, cards are picked one by one, randomly and without replacement. What is the probability that no club is extracted before the ace of spades? I think using total probability for solve this $$P(B)=P(A_1)P(B\mid A_1)+\ldots+P(A_n)P(B\mid A_n)$$ But I am not sure how to solve this. Can someone help me?","['probability', 'card-games']"
2749425,How to change the order of integration for this?,"So I can change order of integration for simple functions through the use of diagram but how do i do it for $$\int_{0}^{\pi}\int_{0}^{\sin x}f(x, y)dydx?$$ So y goes from 0 to 1 but the functions needs to be split at $\pi/2$ when we consider the $x$ direction so in the $x$ direction it goes from $x=\sin^{-1}y$ to $\pi/2$ and then $\pi/2$ to $x=\sin^{-1}y$ or something? This question has been asked before but i don't think the asker does it the way i do so didn't see a good answer","['multivariable-calculus', 'integration']"
2749445,"Is $\lim_{x\to \infty}{\sum_{i,h=1}^x \frac{1}{i^h} - x-\ln{x}}$ equal to $\gamma$, the Euler-Mascheroni constant? If so, why?","I was looking at the sum $\sum_{i,h=1}^x \frac{1}{i^h}$ on Desmos, and I realized it seemed to converge to the line $y=x$. When I subtracted x from it and increased the bounds, it seemed to be converging close to the Euler-Mascheroni constant. Unfortunately, it quickly gets difficult to calculate for large x, so the best estimate I could get with Desmos was for $x=10000$, for which $\sum_{i,h=1}^x \frac{1}{i^h} - x-\ln{x}$ is approximately 0.577165, which is very close to the Euler-Mascheroni constant. Is this actually converging to the constant, or just to something close to it? I would guess that it does, due to this series's clear similarity to the harmonic series, however it is interesting that the constant still appears even with the added exponentiation in the denominator. For clarity, an alternate notation for the sum above would be $${\sum_{i=1}^x}{\sum_{h=1}^x {1\over i^h}}$$","['sequences-and-series', 'euler-mascheroni-constant']"
2749464,Is Schur complement better conditioned than the original matrix?,"Consider the following linear system (in block form) with s.p.d. matrix:
$$
\begin{pmatrix}
A & B\\
B^\top & C
\end{pmatrix}
\begin{pmatrix}
x\\y
\end{pmatrix}
=
\begin{pmatrix}
f\\g
\end{pmatrix}
$$
I'm wondering if elimination of some variables does improve conditioning of the system matrix. If we eliminate $y$ first, by substituting $y = C^{-1}g - C^{-1}B^\top x$ the following system is obtained:
$$
(A - BC^{-1}B^\top) x = f - BC^{-1}g.
$$
The matrix of the new system is simply the Schur complement of the block $C$. The question is whether the conditioning number of the resulting system is less than the conditioning number of the original one? The case $C = I$ is particularly interesting. I've tried using formula
$$
0 = \det
\begin{pmatrix}
A - \lambda I& B\\
B^\top & C - \lambda I
\end{pmatrix} = 
\det(C - \lambda I) \det(A - \lambda I - B (C - \lambda I)^{-1}B^\top),
$$
but with no luck, though $A - B (C - \lambda I)^{-1}B^\top$ seems to be quite close to $A - BC^{-1}B^\top$. Numerical experiments show that the Schur complment is always better conditioned than the original matrix, here's my code . Experiments also show that not only s.p.d, but also diagonally dominant M-matrices share this property.","['matrices', 'condition-number', 'block-matrices', 'schur-complement']"
2749486,Vector space of matrices of rank $\le r$,"Let $F$ be a field, and $M_{n\times n}(F)$ be the set of $n\times n$ matrices with entries in $F$. Let $V$ be a subspace of $M_{n\times n}(F)$ where every matrix in $V$ has rank at most $r$. Prove that $\dim V\le nr$. This is a puzzle I found on the internet which I am having trouble solving. I suppose I am not even sure if the result is correct, but it seems so. It is easy to come up with subspaces of dimension $nr$, like the set of matrices where all but $r$ columns are zero, but these examples are all tight. I have been able to find literature on subspaces of matrices of rank $\ge r$, but not of rank $\le r$. I would appreciate any hints, references, or even solutions which require $F=\mathbb R$ or $\mathbb C$. Here is a failed attempt that might serve for inspiration: Let $t=\dim V$, and assume $t=nr+1$. By using Gaussian elimination, we can find a basis $A^1,\dots,A^t$ for $V$ such that for each $1\le k\le t$, there exists a position $(i(k),j(k))$ where $A^k_{i(t),j(t)}=1$, while $A^\ell_{i(t),j(t)}=0$ for all $\ell\neq k$. These positions are the ""leading ones"" found by Gaussian elimination, and when choosing a matrix in $V$, the entries in these positions can be chosen independently of each other. Since there are $nr+1$ leading ones, there exists $r+1$ leading ones which are in pairwise different rows and columns (this follows from a pigeonhole argument). I was hoping to leverage this to show how to that the $(r+1)\times(r+1)$ sub-matrix where these rows and columns intersect could be chosen to have rank $r+1$ by an appropriate choice of the leading ones. This fails, because there is no control over the other entries in the sub-matrix, and they can get in the way. Many thanks!","['matrix-rank', 'linear-algebra']"
2749507,Matrix decomposition into 2x2 elementary transforms,"Rotation matrices can be decomposed into a product of $\frac{n(n-1)}{2}$ elementary rotations operating on only two coordinates. Similarly, can any square matrix be decomposed into a product of $\frac{n(n-1)}{2}$ linear transforms operating on two coordinates only each? Note: $ n(n-1) $ can be done by reversing Gaussian elimination.","['matrices', 'matrix-decomposition']"
2749515,"We lost two cards from a deck of $52$ cards. If we extract a card of this deck, what is the probability we get a diamond?","We lost two cards from a deck of $52$ cards. If we extract a card of this deck, what is the probability we get a diamond? I'm confused here. Suppose we lost two diamonds, then $$P(\text{we get a diamond})=\frac{11}{50}$$ but, if we lost two cards of the other suits, we have $$P(\text{we get a diamond})=\frac{13}{50}$$ if we lost one of the diamonds and one card from the other suits, we have: $$P(\text{we get a diamond})=\frac{12}{50}$$ but here I'm not sure, can someone help me?",['probability']
2749521,"If $f:\mathbb{R}^2\to\mathbb{R}^1$ is of class $C^1$, show that $f$ is not one-to-one.","If $f:\mathbb{R}^2\to\mathbb{R}^1$ is of class $C^1$, show that $f$ is not one-to-one. [Hint: If $Df(x) = 0$ for all $x$, then $f$ is constant. If $Df(x_0)\neq0$, apply the implicit function theorem.] Clearly there are two cases, if $Df(x)=0$ for all $x\in \mathbb{R}^2$ then $f$ is constant and therefore can not be one to one. If there is a $x_0\in\mathbb{R}^2$ such that $Df(x_0)\neq 0$ then how can I use the implicit function theorem knowing that in order to apply it I have to ensure that $f(x_0)=0$ but this is not given in the problem? Here is the version of the theorem of the implicit function that I am using, thank you very much.","['multivariable-calculus', 'real-analysis', 'calculus', 'vector-analysis']"
2749522,Generating function for number of $r$-disjoint subsets each of size $k$,"Fix $n, k$. Then $$
C^{n,k}_r =\frac{1}{r!} \binom{n}{\underbrace{k, \ldots, k}_{\text{r times}}, n-rk} = \frac{n!}{r!(k!)^r(n - kr)!}
$$ is the number of ways to form $r$ disjoint subsets each of size $k$, of $\{1 \ldots n\}$. Is there a closed form expression for its generating function $g(t) = \sum_{r=0}^{\infty} C^{n, k}_r t^r$ ? EDIT: I should explain my motivation for this problem. Let $\mathcal{C}$ be a (possibly empty) random collection of $k$-sized disjoint subsets of $\{ 1 \ldots n\}$. That is: Let $\mathcal{P}_{n, k} = \{ A \, | \, A \subseteq \{ 1 \ldots n\}, |A|=k\}$ Then $\mathcal{C} = \{A_1, A_2 \ldots A_r\} \subseteq \mathcal{P}_{n, k}$ 
so that $A_i \cap A_j = \emptyset$ when $i \neq j$. $\mathcal{C}$ is random. If we assume that: $\mathbb{P}(A \in \mathcal{C}) = \alpha$ for any $A \in \mathcal{P}_{n,k}$. Whenever we have a collection of disjoint sets $A_1, A_2, \ldots, A_r \in \mathcal{P}_{n,k}$ the events $\{ A_i \in \mathcal{C} \}$ are independent, i.e. $$
\mathbb{P}(A_1 \in \mathcal{C}, A_2 \in \mathcal{C}, \ldots, A_r \in \mathcal{C}) = \prod_{i=1}^r \mathbb{P}(A_i \in \mathcal{C}) = \alpha^r.
$$ Then $$
\begin{align}
\mathbb{P}(\mathcal{C} \neq \emptyset) &= \mathbb{P}(\bigcup_{A \in \mathcal{P}_{n,k}} \{ A \in \mathcal{C}\})\\
    &= - \sum_{r=1}^{\infty} C^{n,k}_{r} (-\alpha)^{r}. \tag{By inclusion exclusion formula} 
\end{align}
$$","['generating-functions', 'combinatorics', 'probability']"
2749527,Julius König's proof of Schröder–Bernstein theorem,"I found that Julius König's proof is short and simple to understand, but Wikipedia only provides a sketch and omits details. Here I present a proof with full detail. Please have a check on it! Thank you so much! Theorem: Let $f:A \to B$ and $g:B \to A$ be injections. Then there exists a bijection from $A$ to $B$ . Proof: Without loss of generality, we can safely assume that $A \cap B=\varnothing$ . For any $x \in A \cup B$ , we can form a unique sequence by repeatedly applying $f$ and $g$ to go right, and $g^{-1}$ and $f^{-1}$ to go left whenever $g^{-1}(x)$ and $f^{-1}(x)$ are defined. Such sequence looks like: $$\cdots \rightarrow f^{-1}(g^{-1}(x)) \rightarrow g^{-1}(x) \rightarrow x \rightarrow f(x) \rightarrow g(f(x)) \rightarrow \cdots$$ For any particular $x$ , the sequence may terminate to the left or not, at a point when $f^{-1}$ or $g^{-1}$ is not defined. Since $f$ and $g$ are injective, each $x$ is in exactly one such sequence to within identity (if an element occurs in two sequences, all elements to the left and to the right must be the same in both. So these two sequences are identical). Therefore, the sequences form a partition of $A \cup B$ . Call a sequence an A-stopper if it stops at an element of $A$ , or a B-stopper if it stops at an element of $B$ . Otherwise, call it doubly infinite . It suffices to generate bijection for each sequence as follows. A-stopper Let $A_1$ be the set of its elements in $A$ , $B_1$ be the set of its elements in $B$ . Let $h:A_1 \to B_1$ such that $h(a)=f(a)$ for all $a \in A_1$ . $h(a_1)=h(a_2) \implies f(a_1)=f(a_2) \implies a_1=a_2$ [Since $f$ is injective] $\implies h$ is injective. For $b \in B_1$ , there exists $x=f^{-1}(b) \in A_1$ [If not, this sequence will stop at $b \in B$ , which contradicts to the fact that it is A-stopper ). $h(x)=f(f^{-1}(b)=b \implies h$ is surjective. Thus $h:A_1 \to B_1$ is bijective. B-stopper Let $A_2$ be the set of its elements in $A$ , $B_2$ be the set of its elements in $B$ . Let $k:B_2 \to A_2$ such that $k(b)=g(b)$ for all $b \in B_2$ . $k(b_1)=k(b_2) \implies g(b_1)=g(b_2) \implies b_1=b_2$ [Since $g$ is injective] $\implies k$ is injective. For $a \in A_2$ , there exists $y=g^{-1}(a) \in B_2$ [If not, this sequence will stop at $a \in A$ , which contradicts to the fact that it is B-stopper ). $k(y)=g(g^{-1}(a)=a \implies k$ is surjective. Thus $k:B_2 \to A_2$ is bijective. Then $k^{-1}:A_2 \to B_2$ is bijective. Doubly infinite Let $A_3$ be the set of its elements in $A$ , $B_3$ be the set of its elements in $B$ . Let $t:A_3 \to B_3$ such that $t(a)=f(a)$ for all $a \in A_3$ . $t(a_1)=t(a_2) \implies f(a_1)=f(a_2) \implies a_1=a_2$ [Since $f$ is injective] $\implies t$ is injective. For $b \in B_3$ , there exists $x=f^{-1}(b) \in A_3$ [If not, this sequence will stop at $b \in B$ , which contradicts to the fact that it is doubly infinite ). $t(x)=f(f^{-1}(b)=b \implies t$ is surjective. Thus $t:A_3 \to B_3$ is bijective.","['proof-writing', 'elementary-set-theory', 'proof-verification']"
2749560,Arc contribution in $\int_{-\infty}^\infty \mathrm{d}z \frac{e^{-z^2}}{z-1}$,"Consider an improper integral with a pole on the integration contour at say $z=1$, $$
 \tag{1} I = \int_{-\infty}^\infty \mathrm{d}z\ \frac{e^{-z^2}}{z-1+i\epsilon},~~~~~\epsilon>0. 
$$
Let $$f(z) = \frac{e^{-z^2}}{z-1+i\epsilon}$$
then 
$$
\sum_{residues~inside~\Gamma} = 0 = \oint_\Gamma f(z) = I+\left(\int_{\Gamma_\epsilon}+\int_{\Gamma_\infty} \right) f(z), 
$$
where the total contour is $\Gamma\equiv (-R,R)+\Gamma_\epsilon+\Gamma_\infty$ with $R\rightarrow \infty$. Thus 
$$
 I = - \left(\int_{\Gamma_\epsilon}+\int_{\Gamma_\infty} \right) f(z). 
$$
The contour $\Gamma_\epsilon$ is a semicircle centered about $z = 1$ of radius $\epsilon$. Its contribution is given by 
$$
\int_{\Gamma_\epsilon} \mathrm{d}z ~f(z) = i (\theta_2-\theta_1)~ \mathrm{Res}(f;z=1) = \frac{-i\pi}{e}. 
$$ Evaluating $(1)$ in Mathematica and taking the $\epsilon\rightarrow 0 $ limit gives 
$$
I = e^{(\epsilon +i)^2} \left(-\pi  \text{erfi}(1-i \epsilon )+\log (-1+i \epsilon )+\log
   \left(\frac{i}{\epsilon +i}\right)-2 i \pi \right)
\\
\longrightarrow 
-\frac{\pi  (\text{erfi}(1)+i)}{e}~~~(\text{as}~ \epsilon \rightarrow 0). 
$$ Thus apparently, 
$$ \tag{2}
\int_{\Gamma_\infty} \mathrm{d}z \, f(z) = \frac{2\pi i}{e}+\frac{\mathrm{erfi}(1)}{e}. 
$$ Can anyone derive this contribution from the semicircle at infinity? I.e. is $(2)$ correct and how about generalizations of $(1)$ to integrals of the form $$\tag{3}
I = \int_{-\infty}^\infty \mathrm{d}z\ \frac{z^n e^{-z^2}}{(z-a+i\epsilon)(z-b-i\epsilon)},~~~~~\epsilon>0,a,b\in\mathbb{R},n\in \mathbb{N}. 
$$ Note, erfi is defined as
$\mathrm{erfi}(z) \equiv \mathrm{erf}(iz)/i$ with the familiar error function.","['residue-calculus', 'complex-analysis', 'improper-integrals', 'integration', 'contour-integration']"
2749584,Does local stability of a unique equilibrium in a bounded region implies global stability?,"If I have a non-linear system of ODE's, $\dot{\mathbf{x}} = f(\mathbf{x})$, where $f(\mathbf{\cdot})$ is a smooth non-linear function. Additionally, I know that $\mathbf{x}$ is bounded and the system has only a unique steady state that is locally asymptotically stable, $\mathbf{x}^*$. Is it wrong to conclude that $\mathbf{x}^*$ is globally asymptotically stable? I feel like it is too naive.","['ordinary-differential-equations', 'dynamical-systems']"
2749601,Generalization of Cramer Rao Lower Bound.,"Let $B(p)$ be a Bernoulli R.V. with mean $p$. Using the Cramer-Rao lower bound we have that for every unbiased estimator $\hat{\theta}$ of the parameter $p$ it holds $$
E[(\hat{\theta}_n - p)^2] = Var[\hat{\theta}_n] \geq \frac{p (1-p)}{n}
$$ Let now $\hat{\theta}$ be an estimator such that \begin{equation}
\lim_{n \to \infty} E[ (\hat{\theta}_n - p)^2] = 0.  \qquad    (1)
\end{equation} Can we show a (Cramer-Rao style) lower bound for the error of these estimators?
I would even be happy with a statement such as: Let $\hat{\theta}$ be an estimator of $p$ such that (1) holds for all $p \in (0,1)$. Then 
$$
 \lim_{n \to \infty} n E[(\hat{\theta}_n - p)^2] > 0.
$$
This would mean that the rate of convergence of all such estimators is greater than $C/n$ for a constant $C$.","['probability-theory', 'statistics', 'statistical-inference']"
2749623,Find the length and width of rectangle when you are given the area,"The area of a rectangle is $x^2 + 4x - 12$. What is the length and width of the rectangle? The solution says the main idea is to factor $x^2 + 4x -12$. So, since $-12 = -2 \times 6$ and $-2 + 6 = 4$, it can be written as $x^2 + 4x - 12 = (x - 2)(x + 6)$
since the length is usually the longer value, the length is $6$ and the width is $-2$. I don't understand the logic to this solution at all. I understand $\text{length} \times \text{width} = \text{area}$, but outside of this information I don't understand how they got to this solution from the given information in the problem.","['algebra-precalculus', 'area', 'geometry']"
2749671,Applying Green's theorem on scalar fields,"Consider the vector field $\mathbf F =  \langle x+x^3e^y, -3x^2e^y \rangle$ and let $C$ be the circle $x^2 +y^2=5^2$. Let $\mathbf u$ be the unit vector $\dfrac{1}{\sqrt{x^2+y^2}}\langle x,y\rangle$ and $f(x,y) = \mathbf F  \cdot \mathbf u$. Evaluate the line integral:
$$\int_C f(x,y) \,\mathrm{d}s,$$
where $\mathrm{d}s=\Vert\mathbf r'(t)\Vert \,\mathrm{d}t$. So I noticed that this is a integral for a scalar field, which then I decided to parameterise the curve $C:\mathbf r(t)=\langle 5\cos(t),5\sin(t)\rangle,t\in[0,2\pi]$, then $\mathbf r'(t)=\langle -5\sin(t),5\cos(t)\rangle $ and $\Vert\mathbf r'(t)\Vert=5$. So,$$
\int_C f(x,y)\,\mathrm{d}s = \int_{0}^{2\pi}\frac{1}{\sqrt{x^2+y^2}}\langle x,y\rangle\cdot\langle x+x^3e^y, -3x^2e^y\rangle \Vert\mathbf r'(t)\Vert\,\mathrm{d}t.$$ Simplification yields:$$
\int_{0}^{2\pi}(25\cos^2(t)+625\cos^4(t)e^{5\sin(t)} -375\cos^2(t)\sin(t)e^{5\sin(t)}) \,\mathrm{d}t,$$
which is kind of impossible to integrate. I am not sure if there is an easier way to do this question. Upon checking the answer I noticed that Green's theorem was used, I am not sure on how Green's theorem is applicable to a line integral on a scalar field. (I was only thought on how to apply it onto a vector field). Any help on this clarification is really appreciated!","['multivariable-calculus', 'scalar-fields', 'greens-theorem', 'vector-analysis']"
2749672,"If the total differential is a scalar, how can it also be a covector used to calculate the directional derivative at a point?","In multivariable calculus, the gradient of a function $f(x,y)$ at a given point is the covariant vector: $$\vec\nabla_f=\begin{bmatrix}\frac{\partial f}{\partial x},\frac{\partial f}{\partial y}\end{bmatrix}$$ while the corresponding contravariant vector of differentials is $$\mathrm  d\vec x=[\mathrm dx, \mathrm dy]$$ Their dot product results in the total differential of the function at that given point: $$\mathrm df=\frac{\partial f}{\partial x}\mathrm dx+\frac{\partial f}{\partial y}\mathrm dy.$$ So far, so good. Except that this last calculation is supposed to yield a scalar value according to Reflections on Relativity by Kevin Brown (*): ""dy [read df for notational consistency] equals the scalar (dot) product of these two vectors... The scalar quantity dy is called the total differential of y."" At the same time, this last calculation is also referred to as a 1-form ; a (0,1)-tensor; or a covector (actually an element of the cotangent space), thus enabling the calculation of the directional derivative at the point under consideration, and in the direction of a vector $\mathbf {\vec v}$ in the tangent space , as the dot product: $$\langle \mathrm df , \mathbf{\vec v}\rangle\to\mathbb R.$$ The question: Since $\mathrm df$ cannot be a scalar and a covector at the same time, which one is it, and what's wrong in the above definitions that explains this apparent contradiction? (*) Please note that this seems to be a slight of hand (or possible in-correction in the quoted source after the accepted answer and its associated comment: "" Mathematically, total differentials are covectors (or covector fields) . You may apply them to vectors (or vector fields) in order to obtain scalars (or scalar fields). But they themselves should not be thought as scalars."" In the accepted answer the total differential is referred to as the ""differential operator at $p$ of $f.$ """,['multivariable-calculus']
2749688,"Convexity of $\frac x{\sin x},\,\forall x\in[0,\pi)$","How would one prove the following statement? $f(x)=\frac x{\sin x}$ is convex in $[0,\pi)$. After having posted the question, I came upon two proofs which I have now posted in the answer below.  I would like to know other proofs as well, even the brute force ones. Can we utilize the identity $\frac{\pi x}{\sin(\pi x)}=\Gamma(1+x)\Gamma(1-x)$ where $\Gamma$ is the gamma function ? How about the fact that $f$ is the reciprocal of the sinc function with all the nice properties? Or can we represent $f$ by an integral $\int g(t,x)d\mu(t)$ where $g(t,x)$ is convex with respect to $x$ for every $t$ and $\mu(t)$ is a measure of $t$?","['real-analysis', 'inequality', 'trigonometry', 'convex-analysis', 'complex-analysis']"
2749708,Are two proportions significantly different? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question everyone! The questions below I need help from are from 3-6. Here it is: Risk Factors for Low Birth Weight: Rates of infant mortality, birth defect, and premature labor are high for babies with low birth weight. There are many factors that may contribute to low birth weight. In this activity, we use data from a random sample of women who participated in a study in 1986 at the Baystate Medical Center in Springfield, MA. (Source: Hosmer and Lemeshow (2000), Applied Logistic Regression: Second Edition.) For the 30 women in the study with a history of premature labor, a proportion of 18/30 = 0.60 (60%) had babies with low birth weight. For the remaining 159 women, a proportion of 41/159 = 0.26 (26%) had babies with low birth weight. We now investigate the following research question: do the data provide evidence that the proportion of babies born with low birth weight is higher for women with a history of premature labor? This question is answered with a hypothesis test. To conduct the test we use a 1% level of significance. Question 3: We will test the claim that the proportion of women with low birth weight babies is higher among women with a history of premature labor. What are the null and alternative hypotheses? Question 4: Are the criteria for approximate normality satisfied? Question 5: State the test statistic and P-value. Interpret these values. Question 6: Give a conclusion in context, and discuss whether a causal conclusion is appropriate.","['statistics', 'statistical-inference']"
2749723,Matrix notation for element-wise raising to the power of $n$,"The Hadamard product $A \odot B$ gives the element-wise multiplication of matricies $A$ and $B$. How do I denote the raising a matrix to the power $n$, element-wise?","['matrices', 'notation', 'hadamard-product']"
2749742,Figuring out a group in a short exact sequence,"I am going through the http://www.maths.ed.ac.uk/~v1ranick/papers/wallhomgroup.pdf page 179.proof (ii) $\implies$ (iii). My question given a short exact sequence $1\rightarrow \mathbb{Z}  \rightarrow X \rightarrow \mathbb{Z}_2 \rightarrow 1,$ What can the group  X be? Are there only really two options  $\mathbb{Z}_2 *\mathbb {Z}_2$ and an abelian one (i am presuming it is the direct(semi?) of these two things).I want to conclude that it is indeed $\mathbb{Z}_2 *\mathbb {Z}_2$ if i rule out the abelian case. There is a lot more setting in the proof ,but i ""believe"" my question is this.I might be missing important pieces of the puzzle.","['abstract-algebra', 'exact-sequence', 'group-theory', 'geometric-topology']"
2749771,There does not exist any continuous function $f : \mathbb R → \mathbb R$ such that $f(x)$ is rational if and only if $f(x + 1)$ is irrational,"Prove that there does not exist any continuous function $f : \mathbb R → \mathbb R$ such that $f(x)$ is rational if and only if $f(x + 1)$ is irrational.
What theorems can I use to prove the statement?","['continuity', 'real-analysis']"
2749823,Prove that $\mathscr{L}^{-1}\{\frac{1}{(s+\alpha)(1-e^{-Ts})}\}=e^{-\alpha t} \left[ \frac{e^{(m+1) \alpha T}-1}{e^{ \alpha T}-1}\right]$,"Prove that the inverse laplace transform of :
$$G(s) = \frac{1}{(s+\alpha)(1-e^{-Ts})}$$ equals
$$g(t) = e^{-\alpha t} \left[ \frac{e^{(m+1) \alpha T}-1}{e^{ \alpha T}-1}\right]$$ for : 
$$mT<t<(m+1)T \:\:\:\: , \:\:\:\: m=0,1,2,...,$$ I can't understand what is meant by the the two conditions above. What I could do with this problem is : Write $\frac{1}{1-e^{-Ts}}$ as a power series :
$$\frac{1}{1-e^{-Ts}} = \sum_{n=0}^{\infty}(e^{-Ts})^{n} \:\:\:\: , \:\:\:\: |e^{-Ts}|<1$$ Then : 
$$G(s) = \frac{1}{s+\alpha}\sum_{n=0}^{\infty}e^{-nTs} = \sum_{n=0}^{\infty}\frac{1}{s+\alpha}e^{-nTs}$$ Taking the inverse laplace transform :
$$g(t) = \sum_{n=0}^{\infty}e^{-\alpha(t-nT)}u(t-nT)$$ And I could show that : 
$$\frac{e^{(m+1) \alpha T}-1}{e^{ \alpha T}-1} = \left[1-e^{(m+1) \alpha T}\right]\frac{1}{1-e^{ \alpha T}} \:\:\:\: , \:\:\: |e^{- \alpha T}|<1$$ $$= \left[1-e^{(m+1) \alpha T}\right]\sum_{n=0}^{\infty}(e^{\alpha T})^{n}$$
$$ = \sum_{n=0}^{\infty}e^{n \alpha T}-\sum_{n=0}^{\infty}e^{(n+m+1) \alpha T}$$
$$= \sum_{n=0}^{\infty}e^{n \alpha T}-\sum_{n=m+1}^{\infty}e^{n \alpha T} = \sum_{n=0}^{m}e^{n \alpha T}$$ And stopped here .","['laplace-transform', 'real-analysis', 'ordinary-differential-equations', 'calculus']"
2749855,Derivatives for non Real/Complex functions,"I recently started on my journey into Abstract Algebra and am interested in learning about derivatives in a generalised sense. By that I mean all of my current understanding (or the overwhelming majority) about derivatives is in terms of Real and Complex Valued functions. I'm curious about what restrictions must exists so that we can define a functional limits on a given ordered Field $F$. It would seem that it must be ordered and complete, but how does continuity/limits come into play for functions of the following form $f:F \longrightarrow F$ I was wondering if anyone knew of any good papers/textbooks/etc that speak to this. Thanks in Advance, David","['derivatives', 'abstract-algebra', 'ordered-fields']"
2749878,How to calculate the Fourier transform of the Poisson kernel,"We know that the Fourier transform of the Poisson kernel $P(x,t)$
\begin{equation}
\frac{\Gamma(\frac{(n+1)}{2})}{\pi^{\frac{(n+1)}{2}}}\frac{t}{(t^2+\lvert x\rvert^2)^{\frac{(n+1)}{2}}}
\end{equation}
is the Abel kernel $K(x,t)$
\begin{equation}
e^{-2\pi t \lvert \xi \rvert}.
\end{equation}
However, I have just seen one method of proving it from Stein's Introduction to Fourier Analysis on Euclidean Spaces. The key of the proof is to use
\begin{equation}
e^{-\beta}=\frac{1}{\sqrt \pi} \int_0^\infty \frac{e^{-u}}{\sqrt u} e^{-\frac{\beta^2}{4u}} \, \mathrm{d} u.
\end{equation}
And it start with the Abel kernel to Poisson kernel. But I feel that this proof is a little trick. So is there any other proof of it? Thank you very much!","['harmonic-analysis', 'real-analysis', 'integration', 'calculus']"
2749880,Why is the sample variance unbiased? [duplicate],"This question already has answers here : Mean of $ \sum (X_i - \bar{X})^2$ (3 answers) Closed 4 years ago . Let $X_1,X_2,...,X_n$ be independent normal distributions with a common variance $\sigma^2$. The usual definition of sample variance is $S^2:=\frac{\Sigma_{i=1}^{n} (X_i-\bar{X})^2}{n-1}$. I want to show that $E[S^2]=\sigma^2$, i.e. the population variance. My attempt at proof: $\frac{n-1}{\sigma^2}E[S^2] = E[\frac{(n-1)S^2}{\sigma^2}] = E[\frac{\Sigma_{i=1}^{n}(X_i-\bar{X})^2}{\sigma^2}]=n$, This is because for each $i$, $\frac{(X_i-\bar{X})}{\sigma}$ has a $N(0,1)$ distribution, so $\frac{(X_i-\bar{X})^2}{\sigma^2}$ has a Chi-squared distribution, each has an expected value of $1$. But then $E[S^2]=\frac{n}{n-1}\sigma^2\neq 1$.","['statistics', 'probability', 'statistical-inference']"
2749930,Roots of polynomials with bounded integer coefficients,"For $a\in\mathbb N$ , let $R_a\subseteq\mathbb{R}$ be the set of real roots of polynomials whose coefficients are integers with absolute value at most $a$ . $$R_a=\left\{r\in\mathbb{R}\middle|\sum_{i=0}^na_ir^i=0,n\in\mathbb N,a_i\in\mathbb Z,|a_i|\leq a, a_n\neq 0\right\}$$ (Note that the degrees of the allowed polynomials aren't bounded.) I want to know which numbers can be arbitrarily well approximated by such roots. In particular, is $R_a$ dense on some interval for any $a$ ? Discussion: If $r\in R_a$ and $r\neq 0$ then $1/r\in R_a$ , since by reversing the order of the coefficients of the polynomial of which $r$ was a root one obtains a polynomial of which $1/r$ is a root. In the comments, mathworker21 noted that by considering the polynomial $1 - aX -\dots-aX^n$ one can show that every nonzero $r\in R_a$ satisfies $|r|>\frac{1}{a+1}$ . Therefore we also have $|r|<a+1$ , so $R_a$ is bounded. We could also ask about the set $R_a^\mathbb C$ of the roots of such polynomials in $\mathbb C$ . John Baez has a page about such sets here , which contains some beautiful pictures. He's also written a paper , which gives a reference to a paper by Thierry Bousch in which it is proved that the roots of the Littlewood polynomials (those with coefficients $\pm1$ only) are dense on the annulus $2^{-1/4}<|z|<2^{1/4}$ . Since $\{-1,1\}\subseteq\{-1,0,1\}$ , this answers the complex analogue of my question: the set $R_1^\mathbb C$ is dense on some ball. Unfortunately the paper is written in French, so I can't tell if the proof generalises to the reals. (The real result isn't an immediate corollary of the complex version, because there might be a sequence in $R_a^\mathbb C$ tending to $x\in\mathbb R$ without there being such a sequence in $R_a^\mathbb C\cap\mathbb R$ .)","['real-analysis', 'polynomials', 'roots', 'mathematical-french']"
2749966,Understnading left vs. right-handed systems,"so I'm kind of unsatisfied with my knowledge about left and right-handed coordinate systems. I keep finding these hand-rules as an explanation whereas I'd have to like something which actually gives me a motivation for the definition and also gives me a more mathematical definition. And maybe some intuition. E.g. I'd like to actually understand what right-handed means, like what are the implications of it and also be able to determine if 2 given vectors in a 3D space are making up a left or right-handed system. Could someone explain it to me, without using one of the many hand rules? That's something one can do when I actually understood the basic concept, which I don't at the moment. Thanks - Please throw as much math at me as you like :p",['geometry']
2750011,"Stuck at this definite integration: $\int_ {0} ^ {\infty} \frac {\log(x)} {x^2 + 2x + 4} \, \mathrm dx$","If $$\int_ {0} ^ {\infty} \frac {\log(x)} {x^2 + 2x + 4} \, \mathrm dx \ $$ is equal
to $\pi \ln p/ \sqrt {q} \ $ , where $p$ and $q$ are coprimes, then
what is the value of $p + q$ ? Ok, so I am stuck with this problem. It was in my exam. The question was a very long one. After solving and simplifying, I was stuck with this definite integration. The options were $27$ and $29$ . I had no idea how to proceed further.
I tried substituting various things, such as $x+1$ to $\tan A$ etc., but nothing seems to work. I hope someone can help shed some light on the problem.
If you want the full question, comment and I will post it.","['integration', 'definite-integrals', 'calculus']"
2750014,Does non vanishing Jacobian implies injectivity?,"Let $F:\mathbb{R}^{2}\to \mathbb{R}^{2}$ be a smooth map where its Jacobian
$$
Jf(x, y) = \det\begin{pmatrix}\frac{\partial F_{1}}{\partial x} & \frac{\partial{F_{1}}}{\partial y}  \\ \frac{\partial F_{2}}{\partial x} & \frac{\partial F_{2}}{\partial y}\end{pmatrix}
$$
is nonzero everywhere. Is it true that $F$ is injective? Also, if it is true, if $F$ is homeomorphism, then is it diffeomorphism? This is true for smooth maps $F:\mathbb{R}\to \mathbb{R}$, but I believe there exists counterexamples for higher dimensional case. But I can't find it.",['differential-geometry']
2750106,Is $G/H\times H\simeq G$ topologically?,"It is not true for $G/H\times H\simeq G$ to hold for a subgroup $H\leq G$ when we talk about group isomorphisms. However, what about topological groups and a homeomorphism in the above? (without being a group morphism)","['general-topology', 'topological-groups', 'group-theory']"
2750160,Prove that the sum of two continuous functions is continuous,"$$\lim _{x\rightarrow a} f(x)+g(x) = f(a)+g(a)$$ Let $\epsilon>0$ be given Since $f$ and $g$ are continuous, $|f(x)-f(a)|< \epsilon$ when $0<|x-a|< \delta_f $ and $|g(x)-g(a)|< \epsilon$ $\ $ when $0<|x-a|< \delta_g$ Let $\delta_h$ be defined as $\min(\delta_g ,\delta_f)$ and $h(x)$ be defined as $f(x)+g(x)$ $$\ |f(x)-f(a)|+|g(x)-g(a)|< 2\epsilon\tag{1}$$ $$\ |f(x)-f(a) + g(x)-g(a)|< 2\epsilon$$ $$\ |h(x)-h(a)|< 2\epsilon$$ We can replace $\delta_f$ and $\delta_g$ by $𝛿_h$ to get $|f(x)-f(a)| < \epsilon$ when $0<|x-a|<\delta_h$ and $\ |g(x)-g(a)|< \epsilon$ when $0<|x-a|<\delta_h$ Since (1) is true when $0<|x-a|<\delta_h$ , we can find a $\delta_h$ for every value of $2ε$ for every $2\epsilon>0$ there is a $\delta>0$ such that $|x−a|<\delta\implies ∣h(x)−h(a)∣<2\epsilon$ and for every $2\epsilon$ there exists an $\epsilon$ so for every $\epsilon$ there exists a $\delta$ . Is the proof logically correct and is it worded correctly?","['real-analysis', 'calculus', 'continuity', 'epsilon-delta', 'solution-verification']"
2750195,Must the dimensions of $V$ and $U$ be equal for $f: U \mapsto V$ to be a diffeomorphism?,"Suppose we have $U, V \subset \mathbb{R}^{n}$, and a map $f: U \mapsto V$. If $f$ is a diffeomorphism, must the dimensions of $U$ and $V$ be equal? I'm thinking this is true since the tangent map $Df_{x}: T_{x}U \mapsto T_{f(x)}V$ has to be a linear isomorphism if $f$ is a diffeomorphism.","['multivariable-calculus', 'differential-geometry', 'analysis']"
2750271,The relative de Rham complex,"Here (at the bottom of page 13) it's stated that for a smooth map $f:X\to S$, the relative Spencer complex
$$\Omega_{X/S}^\bullet \otimes_{f^{-1}\mathcal{O}_S} D_X$$
is a resolution of the transfer module
$$D_{S\leftarrow X} \ = \ f^{-1}(D_S \otimes_{f^{-1}\mathcal{O}_S} \Omega_S^{-1}) \otimes_{f^{-1}\mathcal{O}_S} \Omega_X$$
by left $f^{-1}D_S$-modules. Why is this a resolution? Is there a similar resolution in the case where some fibres of $f$ are singular? If so, what can we say about it? $$\text{}$$ It's easy to show that $\Omega_{X/S}^\bullet \otimes D_X$ is a complex, but I'm not sure exactly how to get a map
$$\Omega_{X/S} \otimes_{f^{-1}\mathcal{O}_S} D_X\longrightarrow D_{S\leftarrow X}$$
of left $f^{-1}D_S$-modules. I know it should be a trivial consequence of $\Omega_X\otimes_{f^{-1}\mathcal{O}_S} f^{-1}\Omega_S\simeq \Omega_{X/S}$, but for some reason  I can't get it to work. I would guess something like
$$\omega \otimes P \longrightarrow \phi(P) \otimes \omega$$
might work for an appropriate map $\phi:D_X\to f^{-1}D_S$. I'm also curious about what happens when the map $f$ is smooth except at a point where the fibre is singular.","['d-modules', 'algebraic-geometry']"
2750276,Monotone approximating sequence for measurable function,"Let $f\in L^2(K)$ (with values in $\mathbb{R})$, where $K\subseteq\mathbb{R}^n$ is compact. Then one knows that there exists a sequence $f_n$ of continuous functions on $K$ that converges pointwise almost everwhere to $f$. For example one can get this by judiciously taking a subsequence of a sequence of continuous functions converging to $f$ in $L^2(K)$. I'm wondering, is it possible to get a sequence of continuous functions $f'_n$ that converges to $f$ pointwise almost everywhere, with the property that $f'_n(x)\geq f'_m(x)$ whenver $n\geq m$? Thanks!","['real-analysis', 'measure-theory', 'analysis']"
2750295,How many different patterns to transport load with these condition?,"(I am not expert in English. I will write as well as I can.) To transport load, you have to put load into trailer cart and transport it in rounds. (I will improve this part (if I can. I am not expert in English.) but I think you can under stand the question from an example.) There are 5 sizes of carts which are 5,4,3,2,1 unit. Conditions: 1.Each round must have at least one cart, for example (total load is 2 unit) Round 1: 1/5 1/4 (mean ""Round 1 : Use 5-unit cart with 1 unit of load , Use 4-unit cart with 1 unit of load"") / , count as a pattern Round 1: 1/5     Round 2: 1/4 / , count as a pattern Round 1: 1/5 1/4     Round 2: x , doesn't count as one pattern 2.Load in each cart must be positive integer, for example (total load is 2 unit) Round 1: 1.5/5 0.5/4 x , doesn't count as a pattern Round 1: 2/5 0/4 x   doesn't count as a pattern 3.Each round must't have 2 or more same size cart, for example (total load is 2 unit) Round 1: 1/5 1/5 x , doesn't count as a pattern 4.Larger size cart must be in earier order, for example (total load is 2 unit) Round 1: 1/4 1/5 x , doesn't count as a pattern For total load is 5 unit, example of patterns (1) Round 1: 1/5 1/4 Round 2: 1/5 1/4 Round 3: 1/5 / , count as one different pattern (2) Round 1: 1/5 1/4 Round 2: 2/5 Round 3: 1/5 / , count as one different pattern (3) Round 1: 1/1 Round 2: 2/5 Round 3: 2/5 / , count as one different pattern (4) Round 1: 3/5 Round 2: 2/5 / , count as one different pattern (5) Round 1: 2/5 Round 2: 3/5 / , count as one different pattern ... If I give number of total load is 20 unit, how many patterns to transport load with these condition ? (I think I don't forgot some condition.)","['permutations', 'combinatorics', 'discrete-mathematics']"
2750296,"$G'$ is the smallest normal subgroup of $G=\langle K\rangle$ that contains $[K,K]$.","I am a bit stuck with this problem. It seems like a sensible statement but I cannot prove it. What I have to prove is that if $G$ is generated by a generating set $K$ then $G' = [G,G]$ is the smallest normal subgroup of $G$ that contains $[K,K]$. I can see that the smallest normal subgroup of $G$ that contains $K$ is $\langle K \rangle$, i.e. $G$ itself. However, I am not sure this implies directly the result I am looking for. Thanks in advance.","['abstract-algebra', 'normal-subgroups', 'group-theory']"
2750345,Infinite product with non homogenous recurrence relation,Let $a_1=1$ and $a_n=n(a_{n-1}+1)$ Define $$P_n=\prod_{i=1}^n(1+\frac1{a_i})$$ Find $P_n$ as n approaches $\infty$ I'm not sure where to start tbh. I don't know how to solve the recurrence relation because of the '$n$' Any help is appreciated!,"['infinite-product', 'sequences-and-series']"
2750363,"Does the equation have a unique solution, if..?","I have an statement thay says: The equation: $\frac{bx}{a} = \frac{ax + b^2}{a} - b, a \neq 0$, have
  unique solution if: I) $a = b$ II) $a > b$ III) $a \neq b$ I know the properties to analyze the solutions of a first degree equation, $ q \neq 0 $ have unique solutions
$ A = 0, B = 0 $ have infinite solutions $ A = 0, B \neq 0 $ not have solutions, I also know formula, $ X = - \frac {B} {A} $, but I can not find a way to address this problem, could you help me? The correct answer is $ D) $, but that does not interest me, I'm interested in learning it. PD: I get that $(x -b)(b-a) = 0$, but i not know how it could help me.",['algebra-precalculus']
2750373,Examples of interesting rings to study during an undergraduate course in non-commutative rings.,"I'm taking a course on Modern Algebra at my university and my professor keeps asking us to look for examples of rings that may be interesting to discuss in class. For instance, he dedicated some time today to discuss upper triangular rings which has been discussed a lot here. See for instance here . He discussed the submodules of this ring $A = \begin{bmatrix}
R & M \\
0 & S \\
\end{bmatrix}$, writing them as tuples $(M_1,M_2,\phi)$ where $M_1$ is a right $R$-module, $M_2$ is a right $S$-module and $\phi:M_1 \times M \to M_2$ is bilinear. So my question is, can you propose any interesting rings assuming the contents that I leave indicated below? Any ring that you specially like? Maybe a ring that has not been fully studied? Brief history of Modern and Abstract Algebra and Category Theory. Rings and ring constructions. Artinian and noetherian rings. Ring decompositions. Idempotent elements. Prime rings and ideals. Radical
  is prime. Semiprime artinian rings. Artin-Wedderburn theorem. Right
  primitive rings. Jacobson density theorem. Jacobson radical. Essential
  extensions and inyective hulls. Application to noetherian rings. Modules and non-commutative rings representations. Bilateral modules, tensor product. Lattice of submodules. Finitely generated
  modules. Artinian and noetherian modules. Free modules. Semisimple
  modules. Generation and cogeneration. Generators and cogenerators in
  modules. Projective and injective modules. Indecomposable modules. Categories. Functors. Direct sum. Direct product. Equivalencies of modules categories. Characterization of equivalences between module
  categories. Equivalent rings. Please note I'm using the soft-question tag and feel free to suggest any improvement in the above.","['modules', 'abstract-algebra', 'ring-theory', 'soft-question', 'category-theory']"
2750388,Is this Theorem equivalent to Axiom of Choice?,"From your answer, I know that they are equivalent and I tried to give a proof that AC $\implies$ this Theorem and that this Theorem $\implies$ AC. Can you please check the correctness of my proofs? Thank you for your answers so much! Axiom of Choice: Let $\mathcal{F}$ is a collection of non-empty disjoint sets. Then there exists a choice function $f:\mathcal{F} \to \bigcup \mathcal{F}$ such that $f(A) \in A$ for all $A \in \mathcal{F}$. The Theorem: For any set $\mathcal{F}$, there exists a function $g:\bigcup \mathcal{F} \to \mathcal{F}$ such that $a \in g(a)$ for all $a \in \bigcup \mathcal{F}$. Proof that AC implies this Theorem: Let $R(a)=\{A \in \mathcal{F}\mid a \in A\}$ and $W=\{\{a\} \times R(a)\mid a \in \bigcup \mathcal{F}\}$. Then $W$ is a collection of non-empty disjoint sets. Apply AC, we have a function $f:W \to \bigcup W$ such that $f(\{a\} \times R(a)) \in \{a\} \times R(a) \implies f(\{a\} \times R(a))=(a, A_a)$ where $a \in A_a \in R(a)$. So the set $\{(a,A_a) \mid a \in \bigcup \mathcal{F}\}$ or equivalently $\{f(\{a\} \times R(a)) \mid a \in \bigcup \mathcal{F}\}$ represents the desired function $g$. Proof that this Theorem implies Axiom of Choice - Approach 1 : Let $W=\{\{\mathcal{F} \times A,a\} \mid a \in A \in \mathcal{F}\}$. $\mathcal{F} \times A \neq b$ for all $A \in \mathcal{F}$ and $b\in \bigcup \mathcal{F}$. Assume that $\mathcal{F} \times A = b$ where $b \in B \in \mathcal{F}$, and that $a \in A$. Then $b \in B \in \{B\} \in \{\{B\},\{B,a\}\}=(B,a)\in \mathcal{F} \times A=b$. This contradicts to Axiom of Regularity. We generate function $f$ as follows: Apply this Theorem, there exists a function $g:\bigcup W \to W$ such that $a \in g(a) \in W$. $f:\mathcal{F} \to \bigcup \mathcal{F}$ such that $f(A)=g(\mathcal{F} \times A) \setminus \{\mathcal{F} \times A\}$ for all $A \in \mathcal{F}$. Proof that this Theorem implies Axiom of Choice - Approach 2 : Let $R(x)=\{A \in \mathcal{F} \mid x \in A\} \cup \{\mathcal{F} \times \{x\}\}$ and $W=\{R(x) \mid\ x \in \bigcup \mathcal{F}\}$. $\mathcal{F} \times \{x\} \neq A$ for all $A \in \mathcal{F}$ and $x \in \bigcup \mathcal{F}$. Assume that $\mathcal{F} \times \{x\} = A$ where $A \in \mathcal{F}$ and $x \in \bigcup \mathcal{F}$. Then $A \in \{A\} \in (A,x) \in \mathcal{F} \times \{x\}=A$. This contradicts to Axiom of Regularity. Thus $\mathcal{F} \times \{x\}$ is an distinct indicator of $R(x)$. As a result, $R(a) \neq R(b)$ whenever $a \neq b$, or equivalently $R(x)$ is injective for all $x \in \bigcup \mathcal{F}$. We generate function $f$ as follows: Apply this Theorem, there exists a function $g:\bigcup W \to W$ such that $x \in g(x) \in W$. It is clear that $A \in W$ for all $A \in \mathcal{F}$. Let $f(A)=R^{-1}(g(A))$ for all $A \in \mathcal{F}$.","['proof-writing', 'axiom-of-choice', 'elementary-set-theory', 'proof-verification']"
2750390,Inverse L'hospital.... does it exist?,"Say we have a function $f:\mathbb{R}\to\mathbb{R}$, differentiable such that $\lim_{x\to\infty}f(x)=a, a\in\mathbb{R}$ and $\exists\lim_{x\to\infty}xf'(x).$ And I have to calculate: $$\lim_{x\to\infty}xf'(x)$$ ...First let's rewrite this as: $\lim_{x\to\infty}\frac{f'(x)}{\frac 1x}$. Now... Can I use ""inverse l'hospital""? and what I mean by that is... to integrate the top and bottom and have: $\lim_{x\to\infty}\frac{f(x)}{ln(x)}$ and use the fact that $\lim_{x\to\infty}f(x)=a$.... so my limit would be $\lim_{x\to\infty}\frac {a + c_1}{ln(x)+c_2}=0?$ And if I can't do this,  how can I solve this problem?","['derivatives', 'real-analysis', 'limits', 'calculus', 'integration']"
2750396,How to interpret $\int_0^\infty \exp(ikx) dx$ in distribution theory?,"It is well known that $F(k):=\int_{-\infty}^\infty \exp(ikx) dx=2\pi\delta(k)$. Upon expanding out definitions, this is nothing but a peculiar way to state the inversion formula for the Fourier transform. What about $G(k):=\int_0^\infty \exp(ikx) dx$? The only obvious property I see is that that $G(k)+\overline{G}(k)=2\pi\delta(k)$, thus $\mathrm{Re}(G(k))=\pi\delta(k)$. But does it have an imaginary part? To put it another way, I am asking for a distributional interpretation of $\int_0^\infty \sin(kx) dx$.","['complex-analysis', 'distribution-theory', 'fourier-transform']"
2750429,"""Schäffer's conjecture"" on equation $1^k+2^k+\cdots+x^k=y^n$","In 1956 J. J. Schäffer proved that the equation 
$$1^k+2^k+\cdots+x^k=y^n$$
for fixed integers $k\ge1,n\ge2$ has only finitely many solutions in positive integers unless $(k,n)\in\{(1,2),(3,2),(3,4),(5,2)\}$ [see Theorem 2, p. 27 in the file's numbering of pages]. Furthermore, he conjectured the equation has only trivial solution $x=y=1$ except $(k,n,x,y)=(2,2,24,70)$ (and excluding those four pairs of $(k,n)$). I was able to find partial results, that the conjecture is true for $k\le11$ [see this] $n=2,k\le58$ [mentioned there as well] $k<170$ odd and even $n$ [see this one] The newest paper (3.) was published in 2007 and I didn't find newer articles.
So here is my question, is Schäffer's conjecture still an open problem?","['conjectures', 'diophantine-equations', 'reference-request', 'number-theory', 'perfect-powers']"
2750445,Matrix Notation Form of Roots of a Quadratic Equation,"We know that the quadratic equation 
$$f(x)=ax^2+bx+c=0$$
 has roots 
$$x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}=-\frac b{2a}\pm \frac 1a\sqrt{-\left(ac-\frac {b^2}4\right)}$$ Also, $f(x)$ can be written in matrix notation as follows:
$$f(x)=
\left(\begin{matrix}x&1\\\end{matrix}\right)
\left(\begin{matrix}a&\frac b2\\\frac b2&c\end{matrix}\right)
\left(\begin{matrix}x\\1\end{matrix}\right)=\mathbf{x^T Q x}$$
where the determinant of $\mathbf Q$ is $\left(ac-\frac {b^2}4\right)=-\frac 14\left(b^2-4ac\right)$, where coincidentally the familiar $(b^2-4ac)$ is the discriminant of the quadratic $f(x)$. Hence the roots of the quadratic $f(x)=0$ may be written as
$$x=-\frac b{2a}\pm \frac 1a\sqrt{-\det(\mathbf Q)}$$
This is equivalent to
$$\left(x+\frac b{2a}\right)^2=\frac {-\det(\mathbf Q)}{a^2}$$
Or in neater form, 
$$\left(ax+\frac b{2}\right)^2={-\det(\mathbf Q)}$$ Question Can the roots of $f(x)=0$ be derived and written completely in matrix notation, given the link between the determinant and discriminant as shown above?","['matrices', 'quadratics', 'discriminant', 'determinant']"
2750473,"$A,B$ are orthogonal projections and $\|Ax\|^2+\|Bx\|^2=\|x\|^2$ show $A+B=I$","Here is the problem : $A,B:\mathbb{C}^n\to\mathbb{C}^n$ are two orthogonal projections satisfying for any $x\in\mathbb{C}^n$, $$\|Ax\|^2+\|Bx\|^2=\|x\|^2$$ Show that $A+B=I$. I know that $\|Ax\|^2+\|Bx\|^2=\|x\|^2$ tells that $(Ax,Ax)+(Bx,Bx)=(x,x)$. Since $$\|(A+B)x\|^2=((A+B)x,(A+B)x)$$$$=(Ax,Ax)+(Bx,Bx)+(Ax,Bx)+(Bx,Ax)$$$$=(x,x)+(Ax,Bx)+(Bx,Ax)$$ It remian to show that $(Ax,Bx)+(Bx,Ax)=0$, but I am not sure how to show it. Please help, thanks a lot!","['matrices', 'projection-matrices', 'linear-algebra', 'inner-products']"
2750534,Pontryagin duality of finite groups,"I have a question related to this question in stack exchange.
By the above question, if $G$ is finite abelian group then its Pontryagin dual $\hat{G}=\operatorname{Hom}(G, \mathbb{Q}/\mathbb{Z})$ is finite. Now if $M$ is a discrete $p$ -primary abelian group or a compact pro- $p$ abelian group, we can define $\hat{M}=\operatorname{Hom}(M,\mathbb{Q}_p/\mathbb{Z}_p)$ . Then,  in the Iwasawa theory, $\hat{M}$ is also called the Pontryagin dual of $M$ . This definition in mostly used in the context of Selmer groups of Elliptic curves by Greenberg. My question: Assume that $M$ is finite. Does it imply that $\hat{M}$ is finite? (I suppose not)","['p-adic-number-theory', 'duality-theorems', 'finite-groups', 'abstract-algebra', 'abelian-groups']"
2750560,"Is a distribution part of the exponential family if the support depends on the parameter? (namely, $f_\theta (x)=e^{-(x-3\theta)}, 3\theta<x<\infty$)","I have trouble verifying is the distribution $$f_\theta (x)=e^{-(x-3\theta)}\qquad\qquad for \ \ 3\theta<x<\infty$$ Is part of the exponential family. In particular, one can rewrite the above as: $$f_\theta (x)=e^{-(x-3\theta)}I_{(3\theta,\infty)}(x)$$ If one would like to write $f_\theta(x)$ as $$f_\theta(x)=c(\theta)h(x)e^{\sum_{j=1}^{p}q_j(\theta)T_j(x)}$$ One should manipulate $I_{(3\theta,\infty)}(x)$ as follows $$I_{(3\theta,\infty)}(x)=e^{log(I_{(3\theta,\infty)}(x))}$$ Now sustituting $$f_\theta(x)=e^{-(x-3\theta)}e^{log(I_{(\theta,\infty)}(x))}=e^{-x+3\theta+log(I_{(3\theta,\infty)}(x))}$$ Now, I find it quite dificult to factorize the function $log(I_{(3\theta,\infty)}(x))$ as a product of two functions that depend only on $x$ and $\theta$ respectively. That may indicate that its not an exponential-family-type distribution; however, I don't know how to prove that I am not smart enough to see it. Thanks in advance for your collaboration.","['statistical-inference', 'probability-theory', 'probability-distributions', 'statistics', 'probability']"
2750563,"If $x\mapsto \lim_{h\to 0} \frac{f(x+h) - 2f(x) +f(x-h)}{h^2}$ is continuous, then $f\in C^2$","Let $a<b$ and $f:(a,b)\to \mathbb R$ be continuous and such that for all $x\in (a,b)$,  $\lim_{h\to 0} \frac{f(x+h) - 2f(x) +f(x-h)}{h^2}$ exists. Let $\beta:x\mapsto \lim_{h\to 0} \frac{f(x+h) - 2f(x) +f(x-h)}{h^2}$. If $\beta$ is continuous over $(a,b)$, prove that $f\in C^2((a,b))$ (i.e. $f$ is twice continuously differentiable) I'm aware that if $f$ is twice differentiable, then $\beta = f''$. I'm also aware that the mere existence of $\beta$ does not guarantee that $f$ is twice differentiable. The strong assumption in this problem is that $\beta$ be continuous. The continuity assumption on $f$ should also come into play somewhere... I've seen this problem asked at an oral exam and I find it quite interesting. I've been thinking about it for a few days but I have made zero progress towards a solution ...","['derivatives', 'real-analysis']"
2750584,Probability the driver has no accident in the next 365 days,"The time until the next car accident for a particular driver is
exponentially distributed with a mean of 200 days. Calculate the
probability that the driver has no accidents in the next 365 days, but
then has at least one accident in the 365-day period that follows this
initial 365-day period. Attempt Let $T$ be the time it takes for a driver to have a car accident. We are given $T$ is $exp( \lambda = 1/200 )$ . We need to find $$ P(T > 365) = 1 - F(365) = 1 - 1 + e^{-365/200} = 0.1612 $$ Is this correct? MY answer key says the correct answer should be $\boxed{0.1352}$ . What am I missing here?",['probability']
2750595,Integral with constant u-substitution,"This is a simple integral. $$
\int \frac{1}{3x}dx
$$ with an equally simple solution of $$
\frac{1}{3}\ln|x| +c
$$ My question is that if you chose to use u-substitution and used u = 3x, the solution appears to work out as follow: $$
\int \frac{1}{u} \frac {du}{3}
$$
$$
\frac{1}{3} \ln|3x|+c
$$ which seems correct as well. Is this in fact correct? The 2 graphs appear nothing alike.",['integration']
2750606,$\lim_{h\to 0} \frac{ f(a+ h) - 2f(a) + f(a-h) }{h^2}$ and a polynomial function with degree at most 2,"Let $f_1(x)$ be a contionous polynomial funtion $f:\mathbb{R}\to\mathbb{R}$ with degree at most 2. Let
$$\lim_{h\to 0} \frac{ f_1(a+ h) - 2f_1(a) + f_1(a-h) }{h^2}=f_2(a).$$ Prove that if the limit above exist for all $a$s, then $f_2(a)$ is constant! This problem comes from a problem also posted in this site. But I can't prove it even with the solutions posted to this: a similar problem Please help! I am very thankful for every solution!!","['functional-analysis', 'real-analysis', 'polynomials', 'derivatives']"
2750608,"Number of ways to color the numbers from 1 to 9 choosing from 3 colors for each one, such that no two numbers whose sum is odd are the same color","I've realised that odd and even numbers cannot have the same color, but two odds or two evens can. I tried counting like this:
For number 1 we can choose from 3 colors, for 2 we have 2 colors, and for 3 we have two possibilities: if you choose the same color as number 1 (one color left, the same as number 1), there are 2 colors for number 4; if you choose a different color for number 3 (not the same color as number 1, also only one color left) there is only one color for number 4, 6 and 8, and all the other odd numbers 5, 7 and 9 have two colors each. Let's call this when you choose a different color than the color for the number one ""locking"". You can lock the colors at the numbers 3, 5, 7 or 9. If you lock it at 3, the number of ways are $3*2*1*1*2*1*2*1*2$, at 5 $3*2*1*2*1*1*2*1*2$, at 7 $3*2*1*2*1*2*1*1*2$ and for 9 $3*2*1*2*1*2*1*2*1$, in each case 48, so $48*4=192$, but this is already over the solution. Why is this wrong, what have I double counted?",['combinatorics']
2750647,Linear Combination independent Random Variables,"Let $Y$ and $Z$ two independent real valued random variables with values in $\mathbb{R}$ and let $f_Y(x)$ and $f_Z(x)$ their distributions. Let $a, b \in \mathbb{R}$. 
How can the distibution $f_{aY + bZ}(x)$ of the linear combination $aY + bZ$ be simplified? My ideas:
If $a, b = 1$ I know that we have the folding formula $f_{Y + Z}(x) = f_Y * f_Z(x)$. Futhermore, what about $f_{aY}(x)$? 
Does $f_{aY}(x)= f_Y(x/a)$ or $f_{aY}(x)= f_Y(ax)$ hold? Can I combine this results in some way?","['stochastic-processes', 'probability-theory', 'probability']"
2750654,"Function with roots at $1, \frac{1}{2}, \frac{1}{3}, \frac{1}{4}, ...$?","I am searching for a function $~f : \mathbb{R}\rightarrow \mathbb{R}$ with
$$ f\left(\frac{1}{k}\right) = 0 ~\forall k\in\mathbb{N}. $$
This function has to be smooth ! First approach: I have tried $f(x) = \sin(\pi/x)$. This works, however, this function is not smooth (as far as I am concerned?). Context: The overall aim is to find two functions $f,g$ such that $f\neq g$ but $f(1/k) = g(1/k) ~\forall k\in\mathbb{N}$. EDIT: Smooth means $f\in C^\infty$. $~f$ has to be at least defined on $(0,1]$.","['real-analysis', 'functions']"
2750729,Independent brownian motions with different $B_1$,"I am asked to compare two Brownian Motions which both start at 0, where one is conditioned on the event $B_1 \leq 5$ and one conditioned on $B_1 \geq 5$. After a short amount of time, on, say $[0,dt]$, are you able to tell which is which? Can I use the independent normal property of Brownian increments to inspect this? If someone could give me some insight if, they were the same conditions but one brownian motion was $B_t$ and one was a sped of version of that, $B_{\lambda t}$ I'd appreciate it.","['stochastic-processes', 'probability-theory', 'brownian-motion']"
2750734,On Proposition 2.6 Gualtieri Thesis Generalized complex geometry,"I'm working with Gualtieri's thesis about Generalized complex Geometry and I don't understand the proof of the Proposition 2.6 (p. 7). It says Every maximal isotropic subspace (maximal totally null subspaces) of $V\oplus V^*$ can be express as $L(E,\alpha)$ for some appropriate $E\subseteq V$ and 2-form $\alpha\in\Lambda^2(E)$ . (Recall $$
L(E,\alpha)=\{X+\xi\in E\oplus V^* : \xi|_E = i_\alpha X \}. 
$$ In the proof, he defines $E=\pi_V (L)$ and \begin{array}{rcl}
\alpha: E & \longrightarrow & E^* \\
X & \longmapsto & \Psi(\pi_{V^*}(\pi_V^{-1}(X)\cap L)) ,
\end{array} where $\pi$ are the canonical projections onto $V$ and $V^*$ and $\Psi:E^*\rightarrow V^*/\operatorname{Ann} E$ is the isomorphism he mentions (he doesn't use the isomorphism explicitly even they says it is necessary). I don't understand what the map does so I can't prove it is skew. Can you help me? I wish to understand what the map does, but my actual goal is to prove it is skew $$ \alpha(X)(Y)+\alpha(Y)(X)=0 \qquad \forall X,Y\in E $$ (I've picked some tags but the real ones don't exist. We have neither Generalize geometry and Dirac structures) EDIT: I haven't done any progress but I can show some example I have thougt about to show you I'm working in it. Let $V$ be a 3-dimensional vector space spanned by $\{E_i\}$ and let $\{\epsilon_j\}$ be its dual basis ($\epsilon_j(E_i)=\delta_{ij}$). The set $\{E_i,\epsilon_j\}$ is a basis for $V\oplus V^*$. Here we consider the indefinite product $$\langle X+\xi, Y+\eta \rangle = \eta(X)+ \xi (Y) . $$ The subspaces $$  L_1 = \operatorname{span} \{E_1+\epsilon_2, E_1+\epsilon_3, \epsilon_3 \}$$ and $$  L_2 = \operatorname{span} \{E_1+\epsilon_3, E_2+\epsilon_3, \epsilon_3 \}$$ are both maximal isotropic subspaces. The problem in both cases is $L$ can be descomposed into $W\oplus \operatorname{Ann}W$, $W=\pi_V(L)$. So it is easy to see $\alpha=0$. This kind of examples are very easy and I can't think of anythinc more avdanced. Some ideas? SOLUTION? I think I can give an alternative proof which constructs explicitly such a form. Ii would be like this: Let $L$ be a maximal isotropic subspaces spanned by the vectors $\{E_1+\xi_1,E_2+\xi_2,\dots ,E_n+\xi_n\}$. As above, define $W=\pi_V(L)$. This subspaces will be spanned by some of the $E_i$'s. Call $B$ sucha set. For the shake of simplicity also call $$ I=\{i: E_i\in B\} $$ Let $\{\theta_i\}$ be a dual basis for $B$: $$\theta_i(E_j)= \delta_{ij} \qquad  \forall i,j\in I $$ Now, define $\alpha\in\Lambda^2(W)$ as follows: For $E_1$: if $E_1\in B$, let $\alpha_1= \iota^*(\epsilon_1)\wedge\theta^1$, where $\iota^*:V^*\rightarrow W^*$ is the dual of the inclusion. Otherwise $\alpha_1=0$. Next, if $E_2\in B$ let $\alpha_2=\alpha_1+ \iota^*(\epsilon_2)\wedge \theta_2 $. If moreover $E_2=E_1$, set $\alpha_2 = \frac{1}{2}\alpha_1 + \frac{1}{2}\iota^*(\epsilon_2)\wedge \theta_2. $ At the end we should have a $2$-form $$\alpha= \sum_{i\in I} w_i \iota^*(\epsilon_i)\wedge \theta_i, $$ where $w_i$ is 1 over the times each $E_i$ appears in the span of $L$. I claim this $\alpha$ is what I'm looking for, but I don't know how to prove it. My problem is I need to show that, if $E_1+\epsilon_1$ and $E_1+\epsilon_2$ span $L$, then $\iota^*(\epsilon_1)=\iota^*(\epsilon_2)$. Clearly, for each $i\in B$, $\epsilon_i=i_{E_i}\alpha$.","['spin-geometry', 'differential-geometry', 'quadratic-forms', 'linear-algebra']"
2750737,Identity involving sums of binomial coefficients,"I'm trying to prove the following: $$\sum_{k=0}^n 2^k\binom{2n-k}{n}=4^n$$ I've thought about induction, but there's not a very nice way to change the LHS from the $n$ case to the $n+1$ case by multiplying by $4$, at least, none that I can see. I've also thought about trying to put a combinatorial argument together, by somehow arguing that the LHS counts $n$-letter words made from a $4$-letter alphabet, but I can't get the set being counted to partition in a way that sensibly represents the different terms of the sum. I believe the identity is true, not only because I've tried a few small values of $n$, but also because Wolfram Alpha simplifies it for me. It just won't tell me how. Thanks in advance for any insights. Additional context: This identity arose while studying answers to this probability question: Expected number of draws to find a match","['combinatorics', 'summation', 'binomial-coefficients']"
2750758,Closed form for the integral $\int_0^1 \frac{dy}{1+y^2} \tanh^{-1} \frac{1}{\sqrt{3+y^2}}$,"This integral (in a slightly different form) appeared in the book of Borwein and Devlin with a remark that no closed form exists for it so far: $$I=\int_0^1 \frac{dy}{1+y^2} \tanh^{-1} \frac{1}{\sqrt{3+y^2}}$$ It was even named among ""impossible integrals"" (page 58). I have spent several hours on this integral and found no closed form of course, but I don't think it's hopeless. With the most obvious series expansion and some work (and liberal use of Mathematica), I have obtained the following explicit series for the integral: $$I= \log(1+\sqrt{2})\arctan \frac{1}{\sqrt{2}}- \frac{1}{6} \sum_{n=0}^\infty \frac{1}{(2n+1)2^n}\sum_{l=0}^{n-1} \left(\frac{2}{3} \right)^l \sum_{k=0}^{l} \frac{(-1)^k}{(2k+1)4^k} \binom{l}{k}$$ The series has good convergence, by the way: Is there a more simple series expression for the integral, or, who knows, maybe even a closed form was found after the book was published?","['integration', 'definite-integrals', 'sequences-and-series']"
2750777,spectral gap of an operator,"I'm trying to show that the spectral gap of an operator $L = -\Delta + x\cdot\nabla$ in $L^2\left(\mathbb{R}^n, d\gamma\right)$ is bounded by $1$ from below. $d\gamma$ is standard Gaussian measure and I want to use Poincare inequality: 
$$\int_{\mathbb{R}^n}f^2\,d\gamma - \left(\int_{\mathbb{R}^n}f\,d\gamma\right)^2 \le \int_{\mathbb{R}^n}\lVert\nabla f\rVert^2 d\gamma.$$ Notice that we can assume that $\int_{\mathbb{R}^n}f\,d\gamma=0$ and (I'm not writing the constant):$$\nabla\left(f\nabla f e^{-\frac{\vert x \vert^2}{2}}\right) = \nabla f\cdot \nabla f e^{-\frac{\vert x \vert^2}{2}} + f\Delta fe^{-\frac{\vert x \vert^2}{2}}  - f x\cdot\nabla f  e^{-\frac{\vert x \vert^2}{2}}= \lVert\nabla f\rVert^2e^{-\frac{\vert x \vert^2}{2}} - fLfe^{-\frac{\vert x \vert^2}{2}}.$$ I wanted to integrate by parts now and everything would be ok if I knew that $\int_{\partial B\left(0,R\right)}f\nabla f e^{-\frac{\vert x \vert^2}{2}}\cdot \eta  dS_x \to 0$ as $R\to\infty$. (boundary measure, $\eta$ is normal vector) Is it true or do I need more assumptions about $f$? Maybe I can assume $f$ is smooth or/and bounded and use some density argument? I guess it is true, because in books they write like that, but I couldn't find detailed proof.","['spectral-theory', 'measure-theory']"
2750817,What is the history of the homomorphism concept?,"What is the history of the homomorphism concept and who coined the term? I seem to be thinking it arose in abstract algebra and groups/rings/fields, but at what time and by whom? People like Galois and Cauchy pioneered these fields but I understand the concept of function itself wasn't even that precise until Dedekind who was much later than them.","['abstract-algebra', 'math-history', 'soft-question']"
2750880,Consequences of being both independent and conditionally independent?,"Suppose $A$, $B$, and $C$ are random variables. If $A$ and $B$ are independent, and they are also conditionally independent given $C$, can we conclude that either $A$ and $C$ are independent or $B$ and $C$ are independent? Or is there a case where given the constraints, $C$ can still be dependent to both $A$ and $B$? This question was inspired from Bayesian network configurations. I was trying to prove the former with no luck, and I wasn't able to find anything online that helped, so I figured that it might not even be true. Could someone please provide either a proof or a counterexample (or some other reasoning to why it's false)?",['probability']
2750883,Study the existence of directional derivatives at a point and determine if it is differentiable,"I have the following function: $$f(x,y)=\begin{cases}x^2+y&\wedge&x\geq 1\\3x-y&\wedge&x<1\end{cases}$$ and they ask me the following: Continuity domain Existence of directional derivatives in the point $(1,1)$ in all directions $\vec v=(a,b)$ What can you say about the differentiability of the function at that point? I made the map of continuity of $f$ and the differents directions of the unit versor $\vec v$ in $(1,1)$: $D_f=\mathbb R^2$. We need to calculate $f'((1,1);(a,b))$ (if exists): $\color{red}{(1)}$ If $a=0\;\;(b=\pm 1):\displaystyle\lim_{h\to 0}{\dfrac{1^2+(1+hb)-2}h}=\boxed b$ $(2)$ If $-1\leq a<0\;\;(\forall b):\displaystyle\lim_{h\to 0}{\dfrac{3+3ha-1-hb-2}h}=\displaystyle\lim_{h\to 0}{\dfrac{h(3a-b)}h}=\boxed{3a-b}$. $\color{blue}{(3)}$ If $0<a\leq 1\;\;(\forall b):\displaystyle\lim_{h\to 0}{\dfrac{{(1+ha)}^2+(1+hb)-2}h}=\displaystyle\lim_{h\to 0}{\dfrac{h(2a+ha^2+b)}h}=\boxed{2a+b}$. With this I can affirm that $f$ has directional derivatives in the point $(1,1)$, which are $$\boxed{\begin{array}{llll}
f'((1,1);(0,\pm 1))&=&b&\\
f'((1,1);(a,b))&=&3a-b&\text{ if }a\in[-1,0)\\
f'((1,1);(a,b))&=&2a+b&\text{ if }a\in(0,1].
\end{array}}$$ EDIT : I'm going to skip some steps and I'll go directly to calculate the formal limit. For that I need the partials, which are $${f'}_x(1,1)=2\qquad{f'}_y(1,1)=1.$$ So by definition: $$\displaystyle\lim_{(x,y)\to (1,1)}{\dfrac{x^2+y-[2+2(x-1)+(y-1)]}{\sqrt{{(x-1)}^2+{(y-1)}^2}}}=\displaystyle\lim_{(x,y)\to (1,1)}{\dfrac{x^2+1}{\sqrt{{(x-1)}^2+{(y-1)}^2}}}=\ldots$$ and now I don't know how to proceed :( . Is it okay or did I lose my head? Thanks!","['multivariable-calculus', 'limits']"
2750885,Theory of Autonomous Differential Equations in $\mathbb{R}^n$,"Finals are coming up and my (graduate-level) Ordinary Differential Equations professor has gone off script for about half the class. Normally, we use the text ""Nonlinear Ordinary Differential Equations"" by Roger Grimshaw. However, when beginning the section of the course on autonomous systems, the professor has been going off of his own notes rather than the textbook, and I can't find any resources for the material. It appears to be a somewhat theoretical approach to autonomous systems in $\mathbb{R}^n$ rather than plane autonomous systems (in $\mathbb{R}^2$) as is covered in Grimshaw and most other texts. The general autonomous ODE material I know of is from my Dynamics classes, covering mostly bifurcations and types of attractors in a more computational way using perturbative methods. To give some broad strokes of the kinds of things the professor covered in this class: 1) If $\phi(t)$ is a solution, then $\phi(t-\tau)$ is a solution for all $\tau \in \mathbb{R}$. 2) If $\Gamma_1$ and $\Gamma_2$ are phase curves, then either they don't intersect or they conincide. 3) Any phase curve is a point, a closed curve, or a non-self-intersecting curve 4) Rectification Theorem: There is a smooth change of coordinates from $x$ to $y(x)$ such that $\frac{dy_i}{dt} = 0$ for $i$ from $1$ to $n-1$ and $\frac{dy_n}{dt} = 1$ in a neighborhood of a given (non-fixed) point. 5) If $x(t;y)$ solves $x' = f(x)$ with $x(0)=y$, then $\log\det\frac{\partial x}{\partial y}(t;y) = \text{div}f(x(t;y))$ 6) Liouville's Theorem: If $D_t$ is the time evolution of a domain in phase space with volume (area/length/measure) $V_t$, then $\frac{dV_t}{dt} = \int_{D_t} \text{div}f(x)dx$. Corollary: Hamiltonian systems conserve phase volume since divergence is $0$. 7) Lie derivative of function with respect to vector field (derivative along trajectories) is invariant w.r.t. smooth change of variables 8) First integrals are functions which are constant along trajectories (Lie derivative is 0), and every non-fixed point has a neighborhood with $n-1$ independent first integrals. 9) The actions $g^{t_0}(x_0)= \phi(t_0;x_0)$, where $\phi(t_0;x_0)$ is a solution to $x'=f(x)$ with $x(0) = x_0$ at time $t_0$, form a group under composition. These are the main things that were covered. I can locate some (but very few) of these ideas in other resources, but mostly I'm coming up with nothing. It seems like this should all be covered in a single text, and I would be interested in hearing about which texts could give me some more insight on this view of autonomous systems.","['reference-request', 'ordinary-differential-equations']"
2750896,Weak convergence of a sequence of probability measures implies integrability of the limiting probability measure,"Let $(X_{n})_{n \in \mathbb{N}}$ be a sequence of uniformly integrable random vectors with values in some normed vector space $V$ with $\mathbb{E}[\|X_n\|] < \infty$. This means that
$$
\lim_{C \to \infty} \sup_{n \in \mathbb{N}} \mathbb{E}[ \| X_{n} \|  \mathbb{1}_{\{\| X_{n} \| > C\}} ] = 0.
$$
Furthermore, suppose that $\mu$ is a probability measure on $V$ and the sequence $(X_{n})_{n \in \mathbb{N}}$ converges weakly to $\mu$. This means that for every bounded Lipschitz continuous function $f \colon V \rightarrow \mathbb{R}$ it holds 
$$
\lim_{n \rightarrow \infty} \int_{V}f dP_{X_{n}} = \int_{V} f d\mu.
$$
How can I show that then $\int_{V} \| x \| d\mu(x) < \infty$?","['uniform-integrability', 'probability-theory', 'weak-convergence', 'probability', 'measure-theory']"
2750931,Is there a name for a matrix formed by multiplying a column and a row?,"I'm in the process of exploring Bra Ket notation.  In it, I often find operators in the form $\lvert a\rangle\langle b\rvert$, which can be thought of as multiplying a row vector $a$ with a column vector $b$. This strikes me as a construction which should probably have a name that I can research to understand the properties of matrices formed this way, but I'm having trouble finding sources that name such matrices. What is it called when a matrix can be decomposed into a row vector and a column vector?  I'd like to look up the properties of such a matrix. $$M=\begin{pmatrix}
    a_0 \\
    a_1 \\
    \vdots \\
    a_n \\
    \end{pmatrix}
    \begin{pmatrix}
    b_0 & b_1 & \ldots & b_n \\
    \end{pmatrix}$$",['matrices']
2750964,Maximum number of circles tangent to two concentric circles,"In a recent math contest, the following question arose: Two concentric circles of radii 1 and 9 make a ring. In the interior of this ring $n$ circles are drawn without overlapping, each being tangent to both of the circles of the ring. What is the largest possible value for $n$? I solved it like this: The radius of each of the small circles must be $(9-1)/2=4$. I connected the centres of two of the small circles together, and also to the centre of the large circle. Let the central angle be $\theta$. The triangle formed has side lengths $4+1=5$, $4+1=5$, and $4+4=8$. This can be split in two to get two 3-4-5 triangles. Since these triangles are right, we can solve for $\theta$: $$
\begin{align}
\sin\frac{\theta}{2}&=\frac{4}{5}\\
\frac{\theta}{2}&=\arcsin{\frac{4}{5}}\\
\theta&=2\arcsin\frac{4}{5}.
\end{align}
$$ Now the answer to the question is simply $\left\lfloor\frac{2\pi}{\theta}\right\rfloor=3$. However, this contest was a no calculator contest, and thus I was not able to compute $\arcsin(4/5)$ for the answer. How do you solve this question without a calculator?","['contest-math', 'geometry']"
2751032,Group theory conjectures,"After completing the following problem, 
 ''if $\phi$ is a homomorphism from $\mathbb{Z}_{30}$ onto a group of order $5$, determine $\ker(\phi)$,""
 I have made two conjectures I would like some feedback on. If you are very confident in group theory please feel free to skip to the bulleted conjectures at the end. Recall the definition of the kernel of a group homomorphism $\phi$: the kernel of $\phi$ is $ker(\phi)=\{g\in G \text{ : } \phi(g)=e_H\}$ where $e_H$ is the identity in H. So to determine the $ker(\phi)$, we find all elements mapped to $0$ by $\phi$. Consider the fact that there can certainly be more than one group homomorphism $\phi$ that maps $\mathbb{Z}_{30}$ onto a group of order $5$. However, note that a group of prime order, which $5$ is, is cyclic. There exists only one cyclic group of finite order, $\mathbb{Z}_n$. Hence the group homomorphism $\phi$ maps $\mathbb{Z}_{30}$ onto $\mathbb{Z}_5$. Recall the example in counting homomorphisms done at the end of class. We stated that homomorphisms between cyclic groups are completely determined by where it sends the generators. Note that any $m<n$ is a generator of $\mathbb{Z}_n$ if $(m,n)=1$, i.e. $m,n$ are relatively prime. Hence every element in $\mathbb{Z}_5$ is a generator for $\mathbb{Z}_5$ since $5$ is prime. Recall that if $\phi \text{ : }G\rightarrow H$ is a group homomorphism and $G,H$ are cyclic, then $\phi$ sends a generator of a $G$ to a generator of a group $H$. Since there are only $5$ possible generators for $\mathbb{Z}_5$ we check the $5$ possible homomorphisms. Let the generator of concern for $\mathbb{Z}_{30}$ be $1_{30}$. We will be utilizing a subscript with elements to denote where the element lives, $x_{30}$ for $x\in \mathbb{Z}_{30}$ and $x_5$ for $x\in \mathbb{Z}_{5}$. The $5$ possible homomorphisms send,
\begin{eqnarray*}
\phi_0 \text{ : }   1_{30} &\longmapsto& 0_5 \\ 
\phi_1 \text{ : } 1_{30} &\longmapsto& 1_5 \\ 
\phi_2  \text{ : } 1_{30} &\longmapsto& 2_5 \\ 
\phi_3 \text{ : } 1_{30} &\longmapsto& 3_5 \\
\phi_4 \text{ : } 1_{30} &\longmapsto& 4_5,
\end{eqnarray*} where the subscript on the homomorphisms indicates where $\phi(1)$ is sent. Consider the trivial homomorphism $\phi_0$ that maps $\mathbb{Z}_{30}$ onto $\mathbb{Z}_5$, $\phi_0 = \left(
                                                     \begin{array}{cccccccccccccc}
                                                       0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & \dots & 28 & 29 \\
                                                       0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \dots & 0 & 0 \\
                                                     \end{array}
                                                   \right)$ For the four remaining homomorphisms, we proceed by trial and error: Consider $\phi_1$ to be the group homomorphism that maps $\mathbb{Z}_{30}$ onto $\mathbb{Z}_5$ in the following way: $\phi_1 = \left(
                                                     \begin{array}{cccccccccccccc}
                                                       0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & \dots & 28 & 29 \\
                                                       0 & 1 & 2 & 3 & 4 & 0 & 1 & 2 & 3 & 4 & 0 & \dots & 3 & 4 \\
                                                     \end{array}
                                                   \right)$ We see that $ker(\phi_1)=\{0,5,10,15,20,25\}$. Also this is a homomorphism since:  $\phi_1(e_G)=e_H$ where $G=\mathbb{Z}_{30}$ and $H=\mathbb{Z}_5$, and also $\phi_1(a+b)=\phi_1(a)+\phi_1(b)$ for all $a,b \in \mathbb{Z}_{30}$. Consider $\phi_2$ to be the group homomorphism that maps $\mathbb{Z}_{30}$ onto $\mathbb{Z}_5$ in the following way: $\phi_2 = \left(
                                                     \begin{array}{cccccccccccccc}
                                                       0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & \dots & 28 & 29 \\
                                                       0 & 2 & 4 & 3 & 0 & 1 & 2 & 4 & 3 & 0 & 1 & \dots & 3 & 0 \\
                                                     \end{array}
 \right)$ $\phi_2$ is not a homomorphism since $\phi_2(3+4)=\phi_2(7)=4$, but $\phi_2(3)+\phi_2(4)=3$. However, consider a  different $\phi_2$. Let $\phi_2$ be the group homomorphism that maps $\mathbb{Z}_{30}$ onto $\mathbb{Z}_5$ in the following way: $\phi_2 = \left(
                                                     \begin{array}{cccccccccccccc}
                                                       0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & \dots & 28 & 29 \\
                                                       0 & 2 & 1 & 4 & 3 & 0 & 2 & 1 & 4 & 3 & 0 & \dots & 4 & 3 \\
                                                     \end{array}
                                                   \right)$ We see that $ker(\phi_2)=\{0,5,10,15,20,25\}$. Also this is a homomorphism since:  $\phi_2(e_G)=e_H$ where $G=\mathbb{Z}_{30}$ and $H=\mathbb{Z}_5$, and also $\phi_2(a+b)=\phi_2(a)+\phi_2(b)$ for all $a,b \in \mathbb{Z}_{30}$. Note the difference between the two $\phi_2$ homomorphisms. Of the first five numbers, none are mapped to themselves as occurred in the first $\phi_2$. However this may not be the only requirement of the homomorphism. Consider $\phi_2$ to be the group homomorphism that maps $\mathbb{Z}_{30}$ onto $\mathbb{Z}_5$ in the following way: $\phi_2 = \left(
                                                     \begin{array}{cccccccccccccc}
                                                       0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & \dots & 28 & 29 \\
                                                       0 & 2 & 1 & 4 & 3 & 2 & 1 & 4 & 3 & 2 & 1 & \dots & 3 & 2 \\
                                                     \end{array}
                                                   \right)$ $\phi_2$ is not a homomorphism since $\phi_2(6+3)=\phi_2(9)=2$, but $\phi_2(6)+\phi_2(3)=5$. Now note the difference between the successful $\phi_2$  and the non successful. The $\phi_2$ that is a homomorphism sends the identity to the identity, the generator to the generator, but also, each element of the codomain $\mathbb{Z}_5$ occurs the same amount of times. This occurs since the results of the homomorphism, ``cycle"" in a sense, through the values of the codomain. Notice that the unsuccessful $\phi_2$ directly above does not do this. It maps the identity to the identity but then the identity never appears again. If we combine this property with the property discovered above, that the first five numbers of the domain need to not be sent to themselves, we begin to see that the kernel of these homomorphisms must always be $\{0,5,10,15,20,25\}$. The same property comes up with a homomorphism $\phi_3$. We have, $\phi_3 = \left(
                                                     \begin{array}{cccccccccccccc}
                                                       0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & \dots & 28 & 29 \\
                                                       0 & 3 & 1 & 4 & 2 & 0 & 3 & 1 & 4 & 2 & 0 & \dots & 4 & 2 \\
                                                     \end{array}
                                                   \right)$ As predicted $ker(\phi_3)=\{0,5,10,15,20,25\}$. Also this is a homomorphism since:  $\phi_3(e_G)=e_H$ where $G=\mathbb{Z}_{30}$ and $H=\mathbb{Z}_5$, and also $\phi_3(a+b)=\phi_3(a)+\phi_3(b)$ for all $a,b \in \mathbb{Z}_{30}$. The same property comes up with a homomorphism $\phi_4$. We have, $\phi_4 = \left(
                                                     \begin{array}{cccccccccccccc}
                                                       0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & \dots & 28 & 29 \\
                                                       0 & 4 & 1 & 2 & 3 & 0 & 4 & 1 & 2 & 3 & 0 & \dots & 2 & 3 \\
                                                     \end{array}
                                                   \right)$ As predicted $ker(\phi_4)=\{0,5,10,15,20,25\}$. Also this is a homomorphism since:  $\phi_4(e_G)=e_H$ where $G=\mathbb{Z}_{30}$ and $H=\mathbb{Z}_5$, and also $\phi_4(a+b)=\phi_4(a)+\phi_4(b)$ for all $a,b \in \mathbb{Z}_{30}$. Hence, barring the the trivial homomorphism $\phi_0$, we see that the kernel of all other homomorphisms is $\{0,5,10,15,20,25\}$. Note that with is isomorphic to $\mathbb{Z}_6$. We know that the kernel of a group is a subgroup, and this checks out Based on the above exploration, we make the following claims: Let $f$ be an onto homomorphism between two finite cyclic groups, $f
   \text{ : } \mathbb{Z}_n \rightarrow \mathbb{Z}_m$, where $m<n$ and
$(m,n)\neq 1$. Then we have that $ker(f)=\{0+mx\}$ for some $x\in
   \mathbb{Z}$ and $mx<n$. The number of homomorphisms between two finite cyclic groups,
$\mathbb{Z}_n \rightarrow \mathbb{Z}_m$, where $m<n$ and $(m,n)\neq
   1$, is equal to $(m,n)$.",['group-theory']
2751035,Evaluating Trig Integrals with Residues,"Use residue theorem to establish the integration formula:
  $$\int_0^{2\pi} \frac{\cos^2(3\theta)}{5-4\cos(2\theta)}d\theta = \frac{3\pi}{8}$$ Hi, so I'm stuck on this question. I've gotten up to computing the residues as being $z_{+/-} = 1/\sqrt2$ and $z = 0$ though I'm not sure how to go from here. EDIT: Okay I've gotten to the point of knowing that the value of the integral is equal to the sum of the residues at each singularity, though I am having difficulty with computing the residue at $z = 0$. That is the only issue I'm having left.","['residue-calculus', 'complex-integration', 'complex-analysis', 'definite-integrals', 'contour-integration']"
2751060,"If $a X_n + b Y_n$ converges in distribution for every $a \geq 0$ and $b \geq 0$, then $(X_n,Y_n)$ converges in distribution?","Suppose that $(X_n,Y_n)$ is a sequence of random variables with $X_n \geq 0$ and $Y_n \geq 0$ for all $n$. Also, suppose that $a X_n + b Y_n$ converges in distribution for every $a \geq 0$ and $b \geq 0$. Does this imply that $(X_n,Y_n)$ converges in distribution? The result is obviously true if the weak convergence of $a X_n + b Y_n$ holds for all $a$ and $b$. However, we are given this information only for all non-negative $a$ and $b$, but note that our random variables in question are also non-negative. I am curious to know if the result is true, and if so, why.","['weak-convergence', 'probability-theory', 'probability-distributions']"
2751087,Devising an equivalence relation with exactly two (or three) equivalence classes,"I'm very stuck on a simple problem, asking me to devise an equivalence relation on R that has exactly two equivalence classes. I've been struggling to think of a relation that has only two classes while maintaining the symmetry, reflexivity, and transitivity necessary for an equivalence relation. I at first thought to define it as aRb if a = 5 or something similar, but none of these are equivalence relations. I've also tried to think in terms of deriving an equivalence relation from a partition, but for example making the two partitions the positive and negative sides of the real number line seem to resemble a partial ordering rather than an equivalence relation. Is there anything else I should be thinking about? (I don't really know how to approach the second part of the problem, the same but with three classes, either). Is my idea of how partitions work wrong? It just seems very unintuitive for an equivalence relation to only have two classes when it is on R .","['equivalence-relations', 'relations', 'discrete-mathematics']"
2751106,Notation of an element of a tuple,"Suppose $F$ a set of $n$ fruit baskets $$F = \{f_1, f_2, ..., f_n\}$$ The baskets can contain up to 3 types of fruits where: $P$: Number of peaches $B$: Number of bananas $A$: Number of apples Each basket contains a different number of fruits and can be represented as a tuple:
$$f_n = (P, B, A)$$ My question is: If I want to get the number of Apples in the basket $f_2$ or if I want to get the number of Peaches in the basket $f_3$: Can I represent them as $A(f_2)$ and $P(f_3)$ respectively? Or how is the correct way to get specific elements of tuples with that letters?",['elementary-set-theory']
