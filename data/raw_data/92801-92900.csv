question_id,title,body,tags
1264647,What Method is used for Projecting the Rauzy Fractal?,"I am trying to construct the Rauzy Fractal ( http://en.wikipedia.org/wiki/Rauzy_fractal ), I have a Tribonacci word generator and have the stairs constructed but I can't seem to get the projection onto a 2D plane correct. On the 4th slide of this: http://kmwww.fjfi.cvut.cz/jn08/slides/Thuswaldner.pdf they depict a bounding cube, my assumption was that I would project each point (x,y,z) onto (x',y') along the line (xMax, yMax, zMax)->(0,0,0). But they mention a Contracting Plane what does this terminology mean? Are all points projected along the same line or each to their own? For this I am using the unit cube orthogonal projection matrix shown on the wiki: http://en.wikipedia.org/wiki/Orthographic_projection with Ortho(-1, 1, -1, 1, 1, -1) being my cube and (x/xMax, y/yMax, z/zMax) being my normalised point to be projected. I think I've got this part completely wrong. The result would agree... Code: https://bitbucket.org/snippets/NeuralOutlet/8qEa/rauzy-fractal-problem Should I even be using the projection matrix?","['projective-geometry', 'fractals', 'matrices']"
1264658,"Does the random variable $f(\tau)M_\tau$, where $M$ is a martingale and $\tau$ is a stopping time, have zero expectation?","Suppose that $M:=\{M_t\}_{t\geq0}$ is a martingale adapted to some filtration $\mathcal{F}:=\{\mathcal{F}_t\}_{t\geq0}$ with $M_0\equiv0$ and that $\tau$ is an $\mathcal{F}_t$-stopping time. Suppose that $f:[0,\infty)\to[0,\infty)$ is a function of time. Is it ever the case that $$\mathbb{E}\left[f(\tau)M_\tau\right]=0?$$ My thinking is that if we define a process $N_t:=f(t)M_t$, then even though $N$ is no longer a martingale, since $$\mathbb{E}[N_t|\mathcal{F}_s]=N_s+(f(t)-f(s))M_s,$$ it does have zero mean at every point in time. I'm particularly concerned with the case $f(t)=1/t$. Any references, or key-words to search for are very welcomed (I'm really not sure where to start here). Many thanks in advanced.","['probability-theory', 'martingales', 'stochastic-processes']"
1264677,Standard deviation of the mean of sample data,"I can't quite understand what this formula means: $$\sigma_{\overline{x}}=\frac{\sigma}{\sqrt n}$$ I know what standard deviation $\sigma$ is - it's the average distance of my data points (samples) from the mean. But this part is confusing: For example, suppose the random variable $X$ records a randomly selected
  student's score on a national test, where the population distribution
  for the score is normal with mean $70$ and standard deviation $5$
  ($N(70,5)$). Given a simple random sample (SRS) of $200$ students, the
  distribution of the sample mean score   has mean $70$ and standard
  deviation $$\frac{5}{\sqrt{200}} \approx \frac{5}{14.14} \approx 0.35$$ Source I thought the standard deviation $\sigma = 5$ means that if I take the scores of all students and calculate the mean, then the average distance of a score from that mean will be equal to $5$. The set of all scores is called the 'population', right? But here it says the more students' scores I take, the lower the standard deviation - thus the closer the number of samples gets to the size of population, the lower the standard deviation (and its get further from $5$).","['statistics', 'standard-deviation']"
1264681,How to smoothly approximate a sign function,"I have a function that defined as following $$f(x) =
\begin{cases}
1,  & \text{if $x > 0$ } \\
0, & \text{if $x=0$ } \\
-1, & \text{if $x<0$ }
\end{cases}$$ In practice, the $f(x)$ is approximated by a smooth $\tanh(kx)$ or Heaviside function as bellow figure. Could you have other way to represent the $f(x)$ function? What are the benefits of your way? Update : $\tanh(kx)$ function $k$ controls the smoothness of the sign function. As $k \to \infty$ , the function defined in $f(x)=\tanh(kx)$ converges to standard sign function. Similarly, the derivative of $\tanh(x)$ also converges to Dirac delta function as $k \to \infty$ . If $k$ is too small, the evolution equation for $x$ acts locally only on a few values around $\{x=0\}$ . Hence, the $\tanh(kx)$ function is sensitive with parameter $k$ . The parameter $k$ must be chosen carefully. Hence, My purposed want to reduce/ignore the affect of k, but remains the above smoothly approximation.","['trigonometry', 'calculus', 'functional-analysis', 'functions']"
1264698,"What does $\sim$ in $X\sim \mathcal{N}(\mu,\sigma^{2})$ really mean?","This is a bit of a silly question, but I can't seem to find the answer anywhere. I feel like $X\sim \mathcal{N}(\mu,\sigma^{2})$ means that $\sim$ is a relation, but if it is a relation, what precisely is this relation? If this is a relation, could I instead write $X\in \mathcal{N}(\mu,\sigma^{2})/ \sim$? One definition I think would be reasonable is to say that $X \sim Y$ if $X$ and $Y$ have the same characteristic or moment generating function, but it seems a little heavy handed to be the ""right"" definition. Another definition I would guess is to put a topology on something which characterizes the random variables and say $X\sim Y$ if they satisfy a homeomorphism? From the homeomorphism viewpoint, I would want to conclude that if $X$ is a random variable whose image is always non-negative, then $X^{2}$ could be normally distributed since you can take the positive square root and exhibit a bijection between $X$ and $X^{2}$ without going into $\mathbb{C}$, but I know this to not be true since it is Chi-Squared, so this can't be a reasonable definition.","['probability-theory', 'notation', 'random-variables']"
1264716,"Let $R$ be a finite ring (with unity) and $S$, $T$ be subrings of $R$. Is $S \cup T$ a subring of R?","Let $R$ be a finite r i ng (with unity) and $S$, $T$ be subrings of $R$. Is $S \cup T$ a subring of R? (Counterexamples are easy to find to me when $R$ is an infinite ring or a finite rng .) P.S. I am self-learning undergraduate level mathematics. Sorry if the question is trivial or stupid. Thanks for all answers!","['abstract-algebra', 'self-learning', 'ring-theory']"
1264741,Deriving the MSE [mean squared error],"The above image is from wikipedia. I'm having troubles with the third line to the 4th: question 1): How did they get from $2E[(\hat{\theta} - E(\hat{\theta})(E(\hat{\theta}) - \theta)]$ to $2(E(\hat{\theta}) - \theta)E(\hat{\theta} - E(\hat{\theta}))$? I thought $E(XY) = E(X)E(Y)$ if and only if $X,Y$ are independent random variables? qeustion 2) Furthermore, why does $E(\hat{\theta} - E(\hat{\theta})) = E(\hat{\theta}) - E(\hat{\theta})$? question 3) from the 4th to the 5th line they have for the last term: $E[(E(\hat{\theta}) - \theta)^2]$ but that is not equal to $\text{Bias}(\hat{\theta},\theta)^2$. I have $\text{Bias}(\hat{\theta},\theta)^2 = (E(\hat{\theta}) - \theta)^2$?",['probability']
1264751,Let $A = \{1- \frac 1n : n \in \mathbb Z ^+\}$ is closed under certain topologies on $\mathbb R$.,"Let $A = \{1 - \frac 1n : n \in \mathbb Z ^+\}$ is closed under certain topologies on $\mathbb R$. I am supposed to figure out if this set is closed under certain topologies.  I know that means I need to show the complement of the set is open.  I am having a lot of difficulty with two things: 1. figuring out what this set actually is 2. figuring out the differences between the different topologies. I know for it to be false I need to just show one counterexample.  For it to be true I am going to have to show that all three conditions of a topology are met: the set and the complement are in the topology, the union of any collection of sets is in the topology and the finite intersection of sets is in the topology. I am supposed to look at the three following topologies for this set all in $\mathbb R$ The usual topology: is just the three conditions listed above. The half open interval topology : The collection of $\mathfrak H$ of all subsets of $U$ such that either $U = \emptyset$ or for each $ x \in U$ there is an interval of the form $[a, b) \subseteq U$ is a topology for $\mathbb R$ The countable complement topology $ \{ U: \mathbb R - U$ is countable$\} \cup \{ \emptyset, \mathbb R\}$ I would appreciate help in just being able to wrap my brain around the different topologies and what this set might actually look like.","['elementary-set-theory', 'general-topology', 'proof-writing']"
1264766,Improper integral from 1 to infinity $\Rightarrow$ integrated function converges towards zero?,"Let $f: [1, \infty) \to \mathbb{R}$ be a continuous function such that the improper integral $$\int_1^\infty f(x) \ dx$$ exists. Show or disprove that $\lim \limits _{x \to \infty} f(x) =0$. Our professor said that there are counterexamples but after frying my brain out I still could not find any. It does sound logical.","['analysis', 'improper-integrals']"
1264784,"Existence of $x \in [0, 2]$ such that $f(x) = x^2$","Let $f : [0, 2] → \mathbb R$ be continuous and $f(2) = 0$. If $\lim \limits _{x \to 1} \frac {f(x) − 2} {\sqrt x − 1} = 1$, then prove that there exists $x \in [0, 2]$ such that $f(x) = x^2$. I tried to use L'Hopital's rule to get $f'(1)=\frac 1 2$. But for the foolwing steps I have no idea. Please help!!","['continuity', 'limits']"
1264848,Sum of i.i.d. random variables is a markov chain,"I think I have some problem understanding markov chains, because we defined them as abstract objects but our professor does proofs with them as if they where just elementary conditional probabilities. This is our definition of a markov chain : Given prob. space $(\Omega, \mathcal{A}, \mathbb{P})$, standard borel space $(S, \mathcal{S})$ and a sequence of random variables $X_n: \Omega \to \mathcal{S}, n \in \mathbb{N}$. $(X_n)_{n\in \mathbb{N}}$ is called markov chain if 
$$\forall B \in \mathcal{S}: \mathbb{E}[\mathbb{1}_B(X_n)|\sigma(X_0, ..., X_{n-1})] = \mathbb{E}[\mathbb{1}_B(X_n) |\sigma(X_{n-1})]$$ So far, so good. But now we've got the following preposition : Given $(\xi_i)_{i\in \mathbb{N}}$ iid rv on $\mathbb{R}^d$ and random variable $X_0$ independent of $(\xi_i)_{i \in \mathbb{N}}$ (also on $\mathbb{R}^d$) we define $X_n := X_0 + \sum_{i=1}^n \xi_i$. Then $(X_n)_{n \in \mathbb{N}_0}$ is a markov chain. Proof : $$P(X_n \in B | X_0 = x_0, ..., X_{n-1} = x_{n-1}) = $$ $$= P(\xi_n + x_{n-1} \in B | X_0 = x_0, X_0 + \xi_1 = x_1, ..., X_0 + \sum_{i=1}^{n-1}\xi_i = x_{n-1}) = $$ $$=_{independce} P(\xi_n + x_{n-1} \in B) = ... = P(X_n \in B | X_{n-1} = x_{n-1})$$
Why do we start treating these conditional expectations just like elementary conditional probability for events? Sorry for the awful formatting of the proof","['probability-theory', 'conditional-expectation', 'probability', 'markov-chains']"
1264851,What is the difference between a scalar and a vector field?,"Could someone please indicate precisely the difference between a scalar and a vector field? I find no matter how many times I try to understand, but I always am confused in the end. So what exactly makes them different?","['calculus', 'multivariable-calculus']"
1264854,Combinatorics proof $\binom{2n}{2}=2\binom{n}{2}+n^2$,"The problem is prove that $$\binom{2n}{2}=2\binom{n}{2}+n^2$$
by showing that each side counts the same collection of subsets. I am trying to study for a final exam and this is a question from a previous midterm. I literally have no way of going about solving this problem because I've learned absolutely nothing this semester and I only know the formula for n choose k and that's as far as my knowledge goes.",['combinatorics']
1264922,What really is a path-ordered exponential?,"In some texts about gauge theories in Physics I've found one object called a path-ordered exponential which I'm not sure what it means. As I understood, the idea is as follows: let $G$ be a Lie group with Lie algebra $\mathfrak{g}$ and let $L_g : G\to G$ be the left translation by $g$, i.e. $L_g(g') = gg'$. If $\gamma : I\subset \mathbb{R}\to G$ is a curve in $G$ then by virtue of left translation we have the following: $$\gamma'(t) = (L_{\gamma(t)})_{\ast} \beta(t)$$ where $\beta : I\to \mathfrak{g}$ is defined by $$\beta(t) = (L_{\gamma(t)^{-1}})_\ast \gamma'(t).$$ So given $\gamma$ we can find $\beta$. Now, if someone gives $\beta$ and wants to find $\gamma$, then $\gamma$ is the curve satisfying the differential equation $$\gamma'(t) = (L_{\gamma(t)})_{\ast} \beta(t)$$ and then as I understand, the solution to this equation is the path-ordered exponential. If $G$ is the multiplicative group of real numbers, then $\mathfrak{g}$ is also the real numbers. In that case $\gamma(t) = f(t)$ is a real function and so is $\beta(t) = g(t)$. The differential equation is then $$f'(t) = f(t) g(t)$$ whose solution is just the usual exponential $$f(t) = C\exp\left(\int g(t)dt\right).$$ Now I simply can't understand what is this path-ordered exponential. What this path-ordered exponential really is, and how can one show that it is the solution to that differential equation?","['lie-groups', 'lie-algebras', 'mathematical-physics', 'ordinary-differential-equations']"
1264972,Is it true that $\sum_{n=0}^{\infty}\frac{1}{n^2+2an+b}\in \Bbb Q \iff \exists k\in \Bbb N^+$ such that $a^2-b=k^2 $?,"This is a curiosity question: Question Given two positive integers $a$ and $b$ do we have the following equivalence:
  $$\sum_{n=0}^{\infty}\frac{1}{n^2+2an+b}\in \Bbb Q \iff \exists k\in \Bbb N^+\text{ such that } a^2-b=k^2\ ?$$ My attempt $(\Leftarrow)$ Assume that $a^2-b=k^2$ ave $k>0$ then :
$$\begin{align}\sum_{n=0}^{\infty}\frac{1}{n^2+2an+b}&=\sum_{n=0}^{\infty}\frac{1}{(n+a)^2-k^2}\\ \\
&=\frac{1}{2k}\sum_{n=0}^{\infty}\left(\frac{1}{n+a-k}-\frac{1}{n+a+k}\right)\\ \\
&=\frac{1}{2k}\sum_{i=0}^{2k-1}\frac{1}{i+a-k} \end{align}$$ $(\Rightarrow)$ I don't know how to approach this implication, but I know for example that if $a^2-b=0$ then using the sum:
$$\sum_{n=0}^{\infty}\frac{1}{(n+a)^2}=\frac{\pi^2}{6}-\sum_{i=1}^{a-1}\frac{1}{i^2}\notin \Bbb Q $$ How can I approach the second implication, I don't know even if it's true or not but it seems when $\sqrt{a^2-b}\in \Bbb N$ that the implication would be true, for instance I don't know what would be the value of:
$$\sum_{i=0}^\infty\frac{1}{(n-a)^2+3} \text{ or } \sum_{i=0}^\infty \frac{1}{(n-a)^2-3}.$$","['square-numbers', 'contest-math', 'number-theory', 'sequences-and-series', 'rationality-testing']"
1264975,What is the Hessian matrix of $x\mapsto f(Ax+b)$?,Let $A\in\mathbb{R}^{n\times n}$ and $b\in\mathbb{R}^n$ $f\in C^2(\mathbb{R}^n)$ and $\tilde{f}(x):=f(Ax+b)$ for $x\in\mathbb{R}^n$ It's easy to prove that $$\nabla\tilde{f}(x)=A^T\nabla f(x)$$ But I'm not able to prove that the Hessian matrix $$\nabla^2\tilde{f}(x)=A^T\nabla^2 f(x)A$$ Shouldn't we have $$\nabla^2\tilde{f}(x)=\left(\begin{matrix}\frac{\partial}{\partial x_1}\\\vdots\\\frac{\partial}{\partial x_n} \end{matrix}\right)A^T\nabla f(x)=A\left(\begin{matrix}\frac{\partial}{\partial x_1}\\\vdots\\\frac{\partial}{\partial x_n} \end{matrix}\right)\nabla f(x)=A\nabla^2f(x)\;?$$,"['analysis', 'calculus', 'multivariable-calculus', 'derivatives']"
1264977,How can I finish integrating $\int {\sqrt{x^2-49} \over x} $ using trig substitution?,"$$\int {\sqrt{x^2-49} \over x}\,dx $$
$$ x = 7\sec\theta$$
$$ dx = 7\tan\theta \sec\theta \,d\theta$$
$$\int {\sqrt{7^2\sec^2\theta - 7^2} \over 7\sec\theta}\left(7\tan\theta \sec\theta \,d\theta\right) = \int \sqrt{7^2\sec^2\theta - 49} \left(\tan\theta d\theta\right)$$
$$ \int\sqrt{7^2(\sec^2\theta - 1)} (\tan\theta \,d\theta) = 7\int\sqrt{\sec^2\theta - 1} (\tan\theta \,d\theta)$$
$$ 7\int \tan^2\theta \,d\theta = 7\int \sec^2\theta - 1 \,d\theta  $$
$$ 7\int \sec^2\theta - 7\int d\theta $$ 
$$ 7\tan\theta - 7\theta + C  = 7(\tan\theta - \theta) + C$$ This makes: $$ \theta = \sec^{-1}\left(x \over 7\right)$$ And plugging back in to the indefinite integral: $$ 7\left(\left(\sqrt{x^2-49} \over 7 \right) - \sec^{-1}\left(x \over 7 \right)\right) + C $$ My question really is, how can I evaluate $\sec^{-1}\left(x \over 7 \right)$ ?","['calculus', 'integration']"
1265026,Correct to write $\vec{F}:\mathbb{R}^3\rightarrow\mathbb{R}^3$?,"Suppose I have some vector field
\begin{align}
\vec{F}\left(x\left(t\right),y\left(t\right),z\left(t\right)\right)&=G\textbf{i}+H\textbf{j}+T\textbf{k}.\tag{1}
\end{align}
Would it be correct for me to say
\begin{align}
\mathbb{R}^3\overset{\vec{F}}{\longrightarrow}\mathbb{R}^3\;?\tag{2}
\end{align}","['vector-spaces', 'notation', 'functions']"
1265046,"How do I find nine messages which are unchanged by RSA encryption using the public key $(3869, 3)$.","I understand how RSA crytosystem works, however I am not sure how to apply it to answer these questions. Can someone explain please? Let $N=3869$ and be the product of two distinct unknown odd prime numbers $p$ and $q$ such that $(p − 1)(q − 1)$ is not divisible by $3$. Show that there are exactly nine messages which are unchanged by RSA encryption using the public key $(N, 3)$. Also explain how to find p and q if at least four of these messages are known.","['cryptography', 'discrete-mathematics']"
1265061,"if $P$ is a prime ideal of $O_K$, then $O_K/P$ is finite","let $P$ be a non-zero prime ideal of $O_K$ , where $K$ is a number field (i.e. the degree $[K:\mathbb{Q}]$ is finite) then $O_K/P$ is finite. I'm working through a proof for this claim, however there is some group theory used in the proof which I don't understand. Choose $\alpha\in P$ , such that $\alpha\neq 0$ , then $N=|Nm(\alpha)|=\alpha\Pi_{i=2}^d \phi_i(\alpha)$ where $\phi_i$ are the embeddings for $\alpha$ , letting $\phi_1$ be the identity map. So $N=\alpha\beta$ , where both $\alpha,\beta\in O_k$ . Therefore $N\in P$ , by definition of an ideal. So $\langle N\rangle\subseteq P$ and $(O_K/P)\subseteq (O_K/\langle N\rangle)$ . I understand everything up until this point, but now $O_K\cong \mathbb{Z}^d$ , where $d$ is the degree of the minimal polynomial of $\alpha$ . But I don't understand where this result comes from. Next the proof says that $(O_K/\langle N\rangle)\cong(\mathbb{Z}/N\mathbb{Z})^d$ , which is finite, hence $(O_K/P)\subseteq (O_K/\langle N\rangle)$ must also be finite. Since $\langle N\rangle = NO_K$ , does this mean that $\langle N\rangle\cong N\mathbb{Z}^d$ , and then can we jump to the conclusion that $(O_K/\langle N\rangle)\cong(\mathbb{Z}/N\mathbb{Z})^d$ .","['number-theory', 'field-theory', 'group-theory']"
1265067,Prove there exists a $c$ such that $-f'(c)=\frac{f(c)}c$,"Let $f: \Bbb{R} \longrightarrow \Bbb{R}$ be a continuous function on $[0,2]$ and differentiable on $(0,2)$. $f(2)=0$. Prove there exists a $c \in (0,2)$ such that $-f'(c)=\frac{f(c)}c$. What I did: 1) From MVT: $\exists c_2 :f'(c_2)=\frac{f(2)-f(0)}{2-0}=\frac{-f(0)}2$ As $-f'(c)=\frac{f(c)}c \iff -f'(c_2)=\frac{f(c_2)}{c_2}$ I can replace $f'(c_2)$ to get: $\frac{f(0)}{2}=\frac{f(c_2)}{c_2}$ . 2) This last statement is equivalent to prove that: $$
g(x)=xf(0)-2f(x)
$$ Has a root on $(0,2)$ As:
$g(0)=-2f(0)$ and $g(2)=2f(0)$, if $f(0)\neq0$ I can say that due to Rolle's theorem has a root, but what if $f(0)=0$? Is my reasoning so far correct?","['analysis', 'proof-verification']"
1265071,Which matrices are covariances matrices?,"Let $V$ be a matrix. What conditions should we require so that we can find a random vector $X = (X_1, \dots, X_n)$ so that $V = Var(X)$? Of course necessary conditions are: All the elements on the diagonal should be positive The matrix has to be symmetric $v_{ij} \le \sqrt{v_{ii}v_{jj}}$ (Because of $Cov(X_i, X_j) \le \sqrt{Var(X_i) Var(X_j)})$ But I am sure these are not sufficient as I have a counterexample. So what other properties we should require on a matrix so that it can be considered a covariance matrix?","['probability-theory', 'matrices', 'random-variables', 'covariance', 'linear-algebra']"
1265148,Expected number of trails to get $n$ heads in a row with an increasing biased coin.,"Assume that we have a biased coin with probability $p_1$ of getting H and $1−p_1$ of getting T on the first trial, $p_2$ of getting H and $1−p_2$ of getting T on the second trial and so on such that
$2/3<p_1<p_2<p_3...<p_n<1$. The probability $p_i$ of getting H increases as long as we get head in a row. If a tail appears, then we reset to probability $p_1$ of getting H in the next trail and so on. What is the expected number of trials to get $n$ H in a row?","['probability-theory', 'probability', 'combinatorics']"
1265151,Dynamical System transformation,"How can the system $$\frac{dx}{dt}=-y+\epsilon x(x^2+y^2)$$$$\frac{dy}{ dt}=x+\epsilon y(x^2+y^2)$$ be transformed into $$\frac{dr}{dt}=\epsilon r^3$$ $$\frac{d\theta}{dt}=1$$ via polar coordinates? I sub in $x=r\cos(\theta)$ and $y=r\sin(\theta)$ into both of the original equations, but there are $\frac{dr}{dt}$ and $\frac{d\theta}{dt}$ terms in both equations then. And adding/subtracting the equations doesn't seem to produce anything 'nice'.","['transformation', 'dynamical-systems', 'polar-coordinates', 'ordinary-differential-equations']"
1265152,A uniform bound by an integrable function for a Fourier series' partial sums.,"Consider
  \begin{equation}
    \sum\limits_{n=1}^\infty\frac{\cos(nx)}{n}=-\log|2\sin x/2|~~~ \big(x\in(0,2\pi)\big),
  \end{equation}
and its $2\pi$-periodic extension $f$ (for a proof of the above identity see this MSE post .) Notice that $f\in L^1(0,\pi)$, since $f(x)\sim\log(x)~(x\rightarrow0)$. This Fourier series is not absolutely or uniformly convergent. My problem is to show that every one of the partial sums
  \begin{equation}
    s_N(x)=\sum\limits_{n=1}^N\frac{\cos(nx)}{n}
  \end{equation}
is bounded in absolute value by the same function $h\in L^1(0,\pi)$. I.e., $|s_N(x)|\leq h(x)$ for every $N\in\mathbb{N}$ and $x\in(0,\pi)$. The various things I have tried so far mostly involve writing the partial sums using the Dirichlet kernel \begin{equation}
    D_N(x)=\frac{\sin(N+1/2)x}{2\sin x/2}=\frac{1}{2}+\sum_{n=1}^N\cos(nx).
  \end{equation}
Then, using that $f$ is even and $2\pi$-periodic,
  \begin{align}
    \pi s_N(x) &=\int_{-\pi}^\pi f(t)D_N(t-x)\text dt \\
               &=\int_0^\pi\big(f(y+x)+f(y-x)\big)D_N(y)\text dy \\
               &=\int_0^\pi \underbrace{\log\left|\frac{\sin(y-x)/2}{\sin(y+x)/2}\right|}_{\displaystyle{:=g(x,y)}}
                  D_N(y)\text dy.
  \end{align}
We may differentiate $g$ to find
  \begin{equation}
    \partial_yg(x,y)=\frac{\sin x}{\cos x-\cos y}.
  \end{equation}
Hence, integrating by parts,
  \begin{align}
    \pi s_N(x)=\left[g(x,y)\int_x^yD_N\right]_{y=0}^{y=\pi} -\int_0^\pi\frac{\sin x\int_x^yD_N}{\cos x-\cos y}\text dy.
  \end{align}
The boundary terms vanish since $g(x,y)$ vanishes when $y=0,\pi$, so if we write $\int_x^yD_N=K_N(x,y)$ then
  \begin{equation}
    \pi s_N(x)=-\int_0^\pi K_N(x,y)\partial_yg(x,y)\text dy.
  \end{equation} Observe that $\partial_yg(x,y)$ is singular as $y\rightarrow x$, and indeed, by Taylor-expanding $\cos y$ around $x$, behaves like
  \begin{equation}
    \frac{1}{y-x}\big(1+O(y-x)\big).
  \end{equation}
Clearly, then, one needs to prove that $K_N(x,y)$ will ""kill"" $(y-x)^{-1}$ in some uniform fashion as $y\rightarrow x$ (and $N\rightarrow\infty$!). Unfortunately using the $\sin$-representation of $D_N$ to Taylor-expand $K_N$ around $y=x$ gives
  \begin{equation}
    K_N(x,y)=D_N(x)\int_x^y\big(1+N\cdot O(t-x)\big)\text dt=
             D_N(x)(y-x)\big(1+N\cdot O(y-x)\big),
  \end{equation}
where I have left out the factor $N$ from the $O$-term to illustrate the non-uniformity of the convergence. There are a couple of other failed attempts I made in a similar vein (for example using the $\cos$-representation of $D_N$), but for fear of making this post too long, I will leave them out. Any ideas on how to proceed would be greatly appreciated, though I would prefer them left as ideas, and not fully fleshed-out answers. Thanks in advance!","['fourier-series', 'fourier-analysis', 'real-analysis', 'functional-analysis']"
1265257,Analytic approximation of $\ddot x+\gamma sign(\dot x)+x=0$,"I am trying to find an analytic approximation to this non-linear differential equation.
$$
\ddot x+\gamma sign(\dot x)+x=0
$$
 $\gamma$ is a very small parameter. The solution I am getting is 
$$
x(t)=a_{0}e^{\frac{-2\gamma t}{\pi}}\cos t
$$ 
When I compare this to a numerically approximated solution in Mathematica it is clear that my approximation is incorrect. I can't seem to figure out what term is responsible for the ending behavior or the numerically calculated blue line. The orange line is my approximation. 
Can anyone help show me where I went wrong. Any help would be appreciated.Thanks.",['ordinary-differential-equations']
1265277,Finding all functions f(y) such that a differential equation becomes exact,"Can somebody help me with this question? Find all functions f(y) for which the differential equation becomes exact: $$ x^2 + \frac {f(y)}{xy} + ln |xy| \frac {dy}{dx} = 0 $$ If I set $P(x,y)=x^2 + \frac{f(y)}{xy}$ and $Q(x,y)= ln |xy|$, I get $\frac{\partial P}{\partial y}=\frac{f'(y)}{xy}-\frac{f(y)}{xy^2}$ and $\frac{\partial Q}{\partial x}=\frac {1}{x}$. The differential equation is exact when $\frac{\partial P}{\partial y}=\frac{\partial Q}{\partial x}$. How do I go about finding all equations f(y)?",['ordinary-differential-equations']
1265287,Challenging recurrence relation problem,"I am starting out with the following: $$
\frac{d^n}{dx^n}[g(x)^{f(x)}] = \sum_{c=0}^n g(x)^{f(x)-c}\lambda_{n,c}(x)
$$ Therefore: $$
\frac{d^{n+1}}{dx^{n+1}}[g(x)^{f(x)}] = \sum_{c=0}^{n+1}g(x)^{f(x)-c}\lambda_{n+1,c}(x) = \frac{d}{dx}\sum_{c=0}^n g(x)^{f(x)-c}\lambda_{n,c}(x)
$$ $\lambda_{n,c}(x)$ is defined like so: $$
\lambda_{n,c}(x) = \sum_{k=c}^n \sum_{j=0}^{k-c} {k-c \choose j} \ln(g(x))^{k-c-j} \frac{d^j}{df^j}[f(x)_c] B_{n,k}^{(f \diamond g)^c}(x)
$$ My goal is to find a recurrence relation for $B_{n,k}^{(f \diamond g)^c}(x)$ by setting the two expressions equal to eachother. This is my work so far: $$
\frac{d}{dx}[g(x)^{f(x)-c} \lambda_{n,c}(x)] = \left((f(x)-c)\frac{g'(x)}{g(x)} + \ln(g(x)) f'(x)\right)g(x)^{f(x)-c} \lambda_{n,c}(x) + g(x)^{f(x)-c} \frac{d}{dx}[\lambda_{n,c}(x)]
$$
Note from now on i will denote $\frac{d^j}{df^j}[f(x)_c] = f_c^{(j)}$
$$
\frac{d}{dx}[\lambda_{n,c}(x)] = \sum_{k=c}^n \sum_{j=0}^{k-c} {k-c \choose j} \left(\frac{g'(x)}{g(x)}(k-c-j) \ln(g(x))^{k-c-j-1} f_c^{(j)} B_{n,k}^{(f \diamond g)^c} + \ln(g(x))^{k-c-j} \frac{d}{dx}[f_c^{(j}B_{n,k}^{(f \diamond g)^c}]\right)
$$ Now, for me to find an expression that will result in a recurrence relation i am going to attempt to group all the $\ln(g(x))^{k-c-j}$ together and set all these terms equal to: $$
\sum_{c=0}^{n+1} g(x)^{f(x)-c} \lambda_{n+1,c}(x)
$$ By doing this i will have found a way to isolate the $g(x)^{f(x)-c}$ terms as well as the $\ln(g(x))^{k-c-j}$ terms. To do this i will seperate each individual term and attempt to manipulate it in order to fit these conditions: $$
A = f'(x) \ln(g(x)) \lambda_{n,c}(x) = f'(x) \sum_{k=c}^n \sum_{j=0}^{k-c} {k-c \choose j} \ln(g(x))^{k-c-j+1} f_c^{(j)} B_{n,k}^{(f \diamond g)^c}(x) = f'(x) \sum_{k=c+1}^{n+1} \sum_{j=0}^{k-c-1} {k-c-1 \choose j} \ln(g(x))^{k-c-j} f_c^{(j)} B_{n,k-1}^{(f \diamond g)^c}(x)
$$
Now,for $B$ i will shift over a step backwards so that instead of $c$ we will be dealing with $c-1$, this is because of the differentiation of the natural log which in turn results in $\frac{g'(x)}{g(x)}$. When we multiply $\frac{g'(x)}{g(x)}$ with $g(x)^{f(x)-c}$ we will get $g'(x) g(x)^{f(x)-c-1}$ therefore by evaluating the expression at $c-1$ we will be evaluating the part of the summation that is dealing with $g(x)^{f(x)-c}$ instead of dealing with the summation that deals with $g(x)^{f(x)-c-1}$. If there is any questions about this please do not hesitate to ask in the comments.
$$
B = g'(x) (f(x)-c+1) \lambda_{n,c-1}(x) = g'(x) (f(x)-c+1) \sum_{k=c-1}^n \sum_{j=0}^{k-c+1} {k-c+1 \choose j} \ln(g(x))^{k-c-j+1} f_{c-1}^j B_{n,k}^{(f \diamond g)^{c-1}}(x) = g'(x) (f(x)-c+1) \sum_{k=c}^{n+1} \sum_{j=0}^{k-c} {k-c \choose j} \ln(g(x))^{k-c-j} f_{c-1}^j B_{n,k-1}^{(f \diamond g)^{c-1}}(x)
$$
Now, for $C$ and $D$ i will split up the two parts in the part where i differentiated the $\lambda_{n,c}(x)$, in variable $C$ we will be using the same logic as i used for ""shifting"" the $c$ variable to $c-1$. $$
C = \lambda_{n,c}'(x)_{part \space 1} = g'(x)\sum_{k=c-1}^{n} \sum_{j=0}^{k-c+1} {k-c+1 \choose j} (k-c-j+1) \ln(g(x))^{k-c-j} f_{c-1}^{(j)} B_{n,k}^{(f \diamond g)^{c-1}}(x) = g'(x)\sum_{k=c}^{n+1} \sum_{j=0}^{k-c} {k-c \choose j} (k-c-j) \ln(g(x))^{k-c-j} f_{c-1}^{(j)} B_{n,k}^{(f \diamond g)^{c-1}}(x)
$$
Now for $C$ i did a little bit of trickery, first of all, when $k=c-1$ the term is equal to zero due to the $(k-c+1)$ term and when $j = (k-c+1)$ the term is equal to zero due to the $(k-c-j+1)$ term.
$$
D = \lambda_{n,c}'(x)_{part \space 2} = \sum_{k=c}^n \sum_{j=0}^{k-c} {k-c \choose j} \ln(g(x))^{k-c-j} \frac{d}{dx}[f_c^{(j)} B_{n,k}^{(f \diamond g)^c}(x)]
$$ Now the problem arises when i try to add $A+B+C+D$ and set it equal to $\lambda_{n+1,c}(x)$. i have attempted to do this many times but i have hit some points where it becomes troubling or that the identity does now work at all. If someone can please help me with the issue it would be alot of help to me. Thank you all for reading this if you have gotten this far, i appreciate it a lot.","['calculus', 'recurrence-relations', 'generating-functions', 'combinatorics', 'derivatives']"
1265300,A ring without the Invariant Basis Number property,"I was reviewing my homework and it seems I overlooked something crucial while proving some ring has no Invariant Basis Number property. This is exercise VI.1.12 in Aluffi's Algebra: Chapter 0 The setup: $V$ is a $k$-vector space and let $R = \mathrm{End}_{k}(V)$. Prove that $\mathrm{End}_{k}(V\oplus V) \cong R^4$ as an $R$-module Prove that $R$ doesn't satisfy the IBN property if $V = k^{\oplus \mathbb N}$. For the first, I used to the fact that $V \oplus V$ is both the product and coproduct (in $k$-Vect) of $V$ with itself to get the isomorphism. What I just realized is I only showed that the two are isomorphic as groups not $R$-modules. So what would be the $R$-module structure on $\mathrm{End}_{k}(V \oplus V)$? For the second, I used the fact that $V = k^{\oplus \mathbb N}$ implies $V \cong V \oplus V$ which in turn implies $R = \mathrm{End}_{k}(V) \cong \mathrm{End}_{k}(V \oplus V)$. Again, I just realized that I only showed the latter two are isomorphic as groups. It may be obvious (and maybe why my professor let it pass?) but I can't come up with a good $R$-module structure that makes the two group isomorphisms $R$-linear. Edit: Explicitly, these are the isomorphisms I'm dealing with. Let $\pi_j, i_j$ be the natural projection/inclusion maps of the $j$-th factor resp. and $\psi: k^{\oplus \mathbb N} \oplus k^{\oplus \mathbb N} \to k^{\oplus \mathbb N}$ the isomorphism given by $\psi(e_i, 0)=e_{2i-1}$ and $\psi(0, e_i)=e_{2i}$. Then the first isomorphism $\mathrm{End}_k(V \oplus V)\to R^4$ is given by $\varphi \mapsto (\pi_1\varphi i_1,\pi_2\varphi i_1,\pi_1\varphi i_2,\pi_2\varphi i_2)$ The second isomorphism $R \to \mathrm{End}_k(V \oplus V)$ is given by $\alpha \mapsto \psi^{-1} \alpha \psi$ The composition doesn't seem to be $R$-linear if I use the obvious $R$-module structure on $R$ and $R^4$.","['abstract-algebra', 'linear-algebra', 'modules']"
1265320,homomorphism between smooth algebraic groups of the same dimension,"For Lie groups, we have a theorem: Suppose $G$ and $G'$ are Lie groups of the same dimension, $G'$ is connected, and $f : G \to G'$ is a homomorphism of Lie groups with discrete kernel. Then, $f$ is surjective. (In particular, $G$ is a covering of $G'$.) Clearly, this also works for algebraic groups in characteristic $0$. My question is does a similar statement hold for smooth algebraic groups in arbitrary characteristic?","['algebraic-groups', 'algebraic-geometry', 'lie-groups']"
1265351,Diameter of the Grassmannian,"Just an interesting question that came to my mind while studying(!): Since the Grassmannian $G(k,\mathbb{C}^n)$ is a compact manifold, what do we know about its diameter? Do we know any estimate? Thank you.","['complex-geometry', 'differential-geometry', 'riemannian-geometry', 'grassmannian']"
1265360,$A \subseteq B$ if and only if $B' \subseteq A'$?,"I have already tried to prove it in my own way and would like to share my results in hope that a mathematician somewhere can tell if I am correct. I believe that the proof consists of 2 parts: First, prove left to right that $A \subseteq B \implies B' \subseteq A'$ . Second, prove right to left that $B' \subseteq A' \implies A \subseteq B$ . In the first part, we assume $A \subseteq B$ . We have $x \in A' \implies x \not \in A$ and since $A \subseteq B$ , then $x \not \in B$ . On the other hand, $x \in B' \implies x \not \in B$ and $x \in A'$ therefore $A' \cap B' = B'$ which means $B' \subseteq A'$ . The second part of the proof is more or less the same. Is my approach correct? Thanks.",['elementary-set-theory']
1265371,Why represent a complex number $a+ib$ as $[\begin{smallmatrix}a & -b\\ b & \hphantom{-}a\end{smallmatrix}]$? [duplicate],"This question already has answers here : Why is the complex number $z=a+bi$ equivalent to the matrix form $\left(\begin{smallmatrix}a &-b\\b&a\end{smallmatrix}\right)$ [duplicate] (8 answers) Closed 9 years ago . I am reading through John Stillwell's Naive Lie Algebra and it is claimed that all complex numbers can be represented by a $2\times 2$ matrix $\begin{bmatrix}a & -b\\ b & \hphantom{-}a\end{bmatrix}$. But obviously $a+ib$ is quite different from $\begin{bmatrix}a & -b\\ b & \hphantom{-}a\end{bmatrix}$, as the latter being quite clumsy to use and seldom seen in any applications I am aware of. Furthermore, it complicates simple operations such as matrix multiplication whereby you have to go one extra step and extract the complex number after doing the multiplication. Can someone explain what exactly is the difference (if there is any) between the two different representations? In what instances is a matrix representation advantageous?","['lie-groups', 'linear-algebra', 'complex-numbers', 'matrices']"
1265379,Prerequisites to reading *Convergence of Probability Measures* by Patrick Billingsley.,I want to improve myself in asymptotic theory regarding the realm of probability. I tried reading Convergence of Probability Measures by Patrick Billingsley but right off the bat the De Moivre-Laplace limit theorem is mentioned. I have yet to prove this theorem. So I was wondering if there was a text recommended to read before approaching Convergence of Probability Measures by Patrick Billingsley?,"['probability-theory', 'book-recommendation', 'reference-request', 'asymptotics']"
1265458,"Why can we consider the Brownian motion as being a mapping into the space of continuous functions, even though its paths are only a.s. continuous?","Let $B=(B_t)_{t\ge 0}$ be a Brownian motion on a probability space $(\Omega,\mathcal{A},\operatorname{P})$. By definition of $B$, for $\operatorname{P}$-almost every $\omega\in\Omega$ $$[0,\infty)\to\mathbb{R}\;,\;\;\;t\mapsto X_t(\omega)\tag{1}$$ is continuous. Generally, a stochastic process $X=(X_t)_{t\in I}$ on $(\Omega,\mathcal{A})$ with $I\subseteq\mathbb{R}$ can be viewed as a mapping $$X:\Omega\mapsto\mathbb{R}^I\;,\;\;\;\omega\mapsto \left(t\mapsto X_t(\omega)\right)\tag{2}$$ I've frequently read that $B$ is considered to be a mapping $\Omega\to C\left([0,\infty)\right)$, where $C(I)$ is the space of continuous functions $I\to\mathbb{R}$. Why can we do that? Clearly, there exists a $\operatorname{P}$-null set $N\subseteq\mathcal{A}$ such that $(1)$ is continuous for all $\omega\in\Omega\setminus N$. Moreover, I know that we can alter measurable functions on null sets without changing their measure related properties. However, is it guaranteed that we can alter $B$ on all null sets on which $(1)$ is not continuous such that $(1)$ is continuous for all $\omega\in\Omega$? Remark: Maybe we can use the Kolmogorov-Chentsov theorem to prove that $(1)$ can indeed be assumed as continuous for all $\omega\in\Omega$. The theorem can be formulated as follows: Let $X=(X_t,t\ge 0)$ be a real-valued stochastic process such that for all $T>0$, there exists $\alpha,\beta,C>0$ with $$\operatorname{E}\left[\left|X_t-X_s\right|^\alpha\right]\le C|t-s|^{1+\beta}\;\;\;\text{for all }s,t\in [0,T]]$$ Then, there exists a modification of $X$ which is locally Hölder-continuous of order $\gamma\in \left(0,\frac \beta\alpha\right)$. Stochastic processes $X,Y$ are called modifications of each other, if $X_t=Y_t$ almost surely.","['brownian-motion', 'stochastic-calculus', 'probability', 'stochastic-processes']"
1265466,"The autocovariance function of ARMA(1,1)","So I am reading Brockwell and Davis introduction to Time Series analysis on page 89 where he derives the ACVF of an $ARMA(1,1)$ given by: $X_t - \phi X_{t-1}=Z_t+\theta Z_{t-1}$ with ${Z_t}$ is $WN(0,\sigma^2)$ and $\mid \phi \mid < 1$ What is first told is that by causality assumption, the autocovariance at lag $h$ is: $\gamma(h)=\sigma^2\sum_{j=0}^\infty\psi_j \psi_{j+\mid h \mid}$ So this at lag $h = 0$ is becomes: $\gamma (0) = \sigma^2 \sum_{j=0}^\infty \psi_j^2$ How can this then be shown that $\sigma^2 \sum_{j=0}^\infty \psi_j^2 = \sigma^2 \Big[ 1 + \frac{(\theta+\phi)^2}{1-\phi^2} \Big]$ ? And in the same way for $\gamma(1) = \sigma^2 \Big[ \theta + \phi + \frac{(\theta+\phi)^2\phi}{1-\phi^2} \Big]$? I know that there is a definition of the function $\psi (z) = \sum_{j=0}^\infty\psi_j z^j = \frac{\theta(z)}{\phi(z)}$, $\mid z \mid\leq 1$. In what can this be applied here?","['power-series', 'time-series', 'summation', 'covariance', 'statistics']"
1265472,Smooth chart in what sense?,"I have a question concerning smooth manifolds. As far as I've understand a smooth manifold is a pair of a manifold and a smooth atlas. Where smooth atlas means that the transition functions defiened on overlapping charts are smooth from $\mathbb{R}^n$ to $\mathbb{R}^n$. In particular a chart in a smooth atlas is (in some sense) only a homeomorphism. Still it seems like the smooth charts are in them selves to be smooth? My concern relates to Lee J.M Introduction to smooth manifolds, where he defines the smooth atlas $x\rightarrow x^3$ from $\mathbb{R}$ to $\mathbb{R}$. and states that it is not smoothly equivalent to the identity. I.e this is an example of a smooth chart that is not given by a smoothly invertible function (in the usual sense). This makes me confused, since in the same book it is stated that the coordinate charts are local diffeomorphisms between $\mathbb{R}^n$ and some open nbh of the manifold. When we say that the coordinate charts locally gives a diffeomorphism do we mean this with respect to the very same coordinate functions, i.e we are saying that a chart is a diffeomorphism because composing it with its inverse gives us the identity, which is a diffeomorphism? Any comments or clarifications are welcome!",['differential-geometry']
1265519,Approximation of combination $ {n \choose k} = \Theta \left( n^k \right) $?,"Is it a valid to say 
$$
{n \choose k} = \Theta \left( n^k \right)
$$
for any $n$ and $k$? If so, how to prove it? Note: $k$ is not a function of $n$. Note: Observed it here (page 5): http://www.cs.berkeley.edu/~sinclair/cs271/n6.pdf","['asymptotics', 'combinations', 'computational-complexity', 'combinatorics']"
1265525,Using trigonometry to predict future position,"Intro I'm currently creating an AI for a robot whose aim is to shoot another robot. All I want to do is to be able to calculate at what angle to shoot my bullet, so that it hits my enemy, with the assumption that the enemy continues moving at the same bearing and velocity. Variables Here are the variables that are known Bullet speed is: $bulletSpeed$ m/s $x$ and $y$ coordinates of both mine $(x_1, y_1)$ and the
enemy robot $(x_2, y_2)$ The angle between me and the enemy: $a^\circ$ The heading of the enemy robot: $b^\circ$ The distance between me and the enemy robot: $d$ metres The velocity of the robot: $v$ m/s [Note: this may be more information than needed. Also all angles range from 0 to 360, where North is $0^\circ$ and East is $90^\circ$ and so on] Diagram Here's a diagram to help illustrate the problem, where the arrows show what direction each robot is facing and $travel$ is the distance of the robot has travelled and $bullet$ is the distance the bullet has travelled in $t$ time: Objective I wish to find the angle: $\theta$ to shoot my bullet such that it hits the robot and in the minimum amount of time. The answer should be a formula such that $\theta$ is the subject, so I can substitute the $bulletSpeed$, $a^\circ$, $b^\circ$, $x_1$, $y_1$, $x_2$ and/or $y_2$ to get an answer for $\theta$. i.e.: $$ \theta = ... $$ What I got so far Here's what i have got so far:
$$bullet = bulletSpeed * t $$
$$travel = v * t $$ As you can see its not much. Please help, as I really need to get this section of my AI done by the end of today and really struggling. Please also explain your solution so I can understand it. Many Thanks","['coordinate-systems', 'trigonometry']"
1265531,A coin is flipped ten times. What is the probability that the first three are heads if an equal number of heads and tails are flipped?,"I understand the question but I am not sure how to solve it. For example, if we flip HHHTTTTT then the next three must be heads because of the question. This however seems counterintuitive. I believe that there are $2^{10}$ possible strings, but I am unsure of how to count all possible strings that begin with HHH.",['probability']
1265532,shifted exponential distribution with inter-arrival time,"Given that time interval $T^*$ in seconds between certain events has a negative exponential distribution. The instrument cannot detect intervals which are less than $\delta$ seconds. Let $T_1, ..., T_n$ be a sample of independent intervals measyred by the instrument. The distribution of one of those observation $T_i$ is the conditional distribution of $T^*$ given that $T^*>\delta$ In this question, if I want to find the probability density function of $T_i$, should I consider the shifted exponential distribution such that:
$$f_T(t) = \begin{cases} \lambda e^{-\lambda (t- \delta)} & t>\delta, \\ 0 & otherwise \end{cases}$$ with $E(T)=\delta + \frac{1}{\lambda}$ and $Var(T) = \frac{1}{\lambda ^2}$ Thank you","['probability', 'statistics', 'probability-distributions']"
1265551,How to verify whether R^2 is a subspace of the complex vector space C^2?,"It's an exercise of the book Linear Algebra Done Right.
I'm not clear about how to prove these problems, would you please offer me some suggestion about how to improve this kind of ability, thanks a lot.",['linear-algebra']
1265557,"Triangles, sine and cosine problem",Hi everyone I tried solving this countless times but I always get the wrong answer! what I did first is 600/tan(46) - 600/tan(40) and that sounded reasonable to find the answer! but I keep getting it wrong :( there was a similar question but I got it right. Thank you.,"['algebra-precalculus', 'trigonometry']"
1265558,Find the sum of the following series 3 - 3/2 + 3/4 - 3/8 + 3/16 - 3/32 + ...,"The problem is an alternating series, that looks like this: I am given the series: The book mentions the Alternating Series Estimation Theory, however it seems like there is a definite answer by the wording of the question.","['sequences-and-series', 'calculus']"
1265561,Prove that the graph is connected,"I was wondering if someone can help me understand how prove that this graph is connected. Given a graph with n vertices, prove that if the degree of each vertex is at least $(n − 1)/2$ then the graph is connected. So far I know that about connected graphs: An undirected graph is called connected if there is a path between
every pair of distinct vertices of the graph The distance between two vertices in a graph is the length of
the shortest path between them. The diameter of a graph is the distance between the two vertices
that are farthest apart.","['graph-theory', 'connectedness', 'discrete-mathematics']"
1265577,"Basic integration question: integration bounds for $\iint x^2y^2 \ dx\,dy$","I have the integral
$$\iint x^2y^2 \ dx\,dy$$
but I am meant to evaluate it at the limits $0<y<1$ and $-2y<x<2y$. I am wondering what terminals of integration I should put in for $x$. Do I evaluate between $x=-2y$ and $x=2y$ or between $x=-2$ and $x=2$?","['multivariable-calculus', 'definite-integrals', 'integration']"
1265614,Is there any short proof of this classical problem?,"Let $X,Y$ be two i.i.d. r.v.'s with zero mean and unit variance. If $X+Y$ and $X-Y$ are independent, then $X$ and $Y$ are both standard normal distributed. Is there any short proof for this problem?","['probability-theory', 'characteristic-functions', 'probability', 'probability-distributions']"
1265648,"What is a good book for reviewing high school math, and preparing for university? [duplicate]","This question already has answers here : Textbook recommendations for self-studying high school math? (7 answers) Closed last year . I'm signing up for University soon (Compsci program) as a mature student. It's been a long time since I've done any math, and I went as far as grade 11 in high school. So, I'm looking for a book that will review the essentials of high school math, starting from the basics, and prepare me for Uni. Any recommendations? I know many of you recommended ""Mathematics: Its Content, Methods and Meaning"" in the past, but I'm not sure if it's beginner-friendly. Perhaps I should buy one of those GED preparation books?","['computer-science', 'calculus', 'discrete-mathematics', 'self-learning', 'book-recommendation']"
1265658,Characterizing a union of intervals.,"Find the measure of the set of real numbers in $(0,1)$ whose binary expansions contains zeroes in the odd positions, such that $x = 0.k_1k_2k_3\ldots$ Checking odd positions one at a time: If $k_1 = 0, x \in (0,\frac12)$. If $k_1,k_2 = 0, x \in (0,\frac{1}{8}) \cup (\frac{2}{8},\frac38)$. If $k_1,k_2,k_3 = 0, x \in (0,\frac{1}{32}) \cup (\frac{2}{32},\frac{3}{32}) \cup (\frac{8}{32},\frac{9}{32}) \cup (\frac{10}{32}.\frac{11}{32})$. I'm at a loss for characterizing this in a more concise way, akin to the Cantor set, to the union containing all $x$ such that $k_1,k_2,\ldots,k_n = 0$.","['cantor-set', 'measure-theory']"
1265673,The set of points of continuity of a real-valued function on a metric space is a $G_\delta$ set,Let $f$ be a real-valued function on a metric space $X$. Show that the set of points at which $f$ is continuous is the intersection of a countable collection of open sets. I know lots of other properties of continuous function  but in order to prove the above which is applied. any hints are welcomed.,"['metric-spaces', 'continuity', 'general-topology']"
1265679,Why are eigenvalues of nilpotent matrices equal to zero? [duplicate],"This question already has answers here : Prove that the only eigenvalue of a nilpotent operator is 0? (2 answers) Closed 7 years ago . If $A$ is a $ \displaystyle  10 \times 10 $ matrix such that $A^{3} = 0$ but $A^{2}  \neq 0$ (so A is nilpotent) then I know that $A$ is not invertible, but why does at least one eigenvalue of $A$ have to be equal to zero? How would one show that all eigenvalues of $A$ are equal to zero?","['linear-algebra', 'nilpotence', 'matrices']"
1265698,"Chromatic number $\chi(G)=600$, $P(\chi(G|_S)\leq 200) \leq 2^{-10}$","I am learning martingale and Hoeffding-Azuma inequality recently but do not how to apply the those inequality or theorem here. Let $G=(V,E)$ be a graph with chromatic number 600,i.e. $\chi(G)=600$. Let $S$ be a random subset uniformly chosen from $V$. Denote $G|_S$ the induced subgraph of $G$ on $S$. Prove that 
$$P(\chi(G|_S)\leq 200 )\leq 2^{-10}.$$ I am not sure how to approach ones, especially for the condition $\chi(G)=600$. I am thinking that for a 600 vertices complete graph, the probability to be computed is just the ratio $$\frac{\sum_{i=0}^{200}C_i^{600} }{2^{600}},$$ meaning the ratio btween the number of all subgraph with vertices number less than 200 and the total number of subset of $V$. But is it enough?  Even this ratio is hard to compute.","['probability-theory', 'coloring', 'graph-theory', 'martingales']"
1265703,Prove a function $f(x)$ has a limit as $x$ approaches $1$.,"I am trying to prove the function $f(x) = (1-x)/(1-\sqrt{x})$ has a limit as $x$ approaches 1 using an epsilon definition. I've gotten as far as finding the limit is $2$ by factoring the numerator, as well as setting up the proof, which is as follows: Let $\epsilon>0$ be given. Then there exists $\delta>0$ such that $|(1-x)/(1-\sqrt{x}) - 2| < \epsilon$ if $0 < x-1 < \delta$, $x$ element of the domain, and $1$ is an accumulation point. Now, simplifying the absolute value gives $\left|\frac{(1-x) - 2(1-\sqrt{x})}{1-\sqrt{x}}\right| < \epsilon$, but now I do not know how to proceed.","['limits', 'real-analysis']"
1265705,Dominated positive operator,"I want that if $H$ Hilbert space where $A$, $B$ are positive operators on $H$ Hilbert space, $0 \leq (Ax|x) \leq (Bx | x)$ $\forall x$, does this mean $(A^2x|x) \leq (B^2x|x)$? Thank you",['functional-analysis']
1265743,"locally ringed space $(X,\mathcal{O}_X)$ isomorphic as Ringed Spaces to $Spec(A)$ but not isomorphic as Locally Ringed Spaces.","I'm starting studying Hartshorne Chapter II and is the first time that I'm studying Schemes. I'm looking for some intuition viewing some examples. I'm looking for an example of a locally ringed space $(X,\mathcal{O}_X)$ such that is isomorphic as Ringed space to the Spectrum of some ring $A$ but not isomorphic as Locally ringed spaces. I think that some examples must exist but my intuition on ringed spaces is (at least right now) to vague. Thanks!","['algebraic-geometry', 'ringed-spaces']"
1265746,Show $HK \leq G$,"Let $G$ be a group, let $H$ be a subgroup of $G$ and $K$ be a normal 
  group of $G$, Show $HK \leq G$, where $HK=\{hk\vert h \in H, k\in K\}$ Proof: Since $H$ and $K$ are subgroup of $G$, $\exists e\in H,K$ , so $ee=e\in HK$.Thus, $HK$ is not empty. Let $x,y\in HK$,$x=h_1k_1,y=h_2k_2$ and $h_1,h_2\in H, k_1,k_2\in K$, apply the 1-step subgroup text, $\begin{align} xy^{-1}= &(h_1 k_1)(h_2 k_2)^{-1}\\ =&(h_1 k_1)(k_2^{-1} h_2^{-1})\\ =& h_1ek_1k_2^{-1} h_2^{-1}\\ =&h_1h_2^{-1}h_2k_1k_2^{-1} h_2^{-1}\\=& h_1h_2^{-1}k_1k_2^{-1}\in HK\end{align}$ since $h_1h_2^{-1}\in H,k_1k_2^{-1}\in K$ and $K$ is normal to $G$ Hence, $HK\leq G$ Can anyone check where I did incorrect? Thanks","['abstract-algebra', 'group-theory']"
1265753,Spivak Calculus on Manifolds: Problem 2-13,"I'm going through Spivak's Calculus on Manifolds, and I'm currently working on Problem 2-13 part (b). The problem statement is If $f,g: \mathbb{R} \rightarrow \mathbb{R}^{n}$ are differentiable and $h: \mathbb{R} \rightarrow \mathbb{R}$ is defined by $h(t) = \langle f(t),g(t)\rangle$, show that
  $h'(a) = \langle f'(a)^T,g(a) \rangle + \langle f(a),g'(a)^T \rangle.$ What's confusing me is that $f'(a)$ is a vector in $\mathbb{R}^{n}$ and taking its transpose yields a vector in the dual space to $\mathbb{R}^{n}$, so taking the inner product with $g(a)$, which is a vector in $\mathbb{R}^{n}$ yields a scalar in $\mathbb{R}$, corresponding to the left term in the equation. Whereas the right term in the equation is an outer product, so it sends a vector and a dual vector to a linear map in Hom($\mathbb{R}^{n}$), since the vector $f(a)$ is $n\times 1$ and the dual vector $g'(a)^T$ is $1\times n$ so their product is $n\times n$. How can these two terms be added to yield a scalar in $\mathbb{R}$?","['linear-algebra', 'multivariable-calculus']"
1265775,A formal proof that the function $ x \mapsto x^{2} $ is continuous at $ x = 4 $.,"Problem: Show $f(x)=x^2 $ is continuous at $ x = 4$. That is to say, find delta such that: $ ∀ε>0$ $ ∃δ>0 $ such that $ |x-a|<δ ⇒ |f(x)-f(a)|<ε$ Where $a=4$, $f(x)=x^2$,and $f(a)=16$. So in order to do to do these delta/epsilon proofs, I was originally taught to solve |f(x)-f(a)|<ε by setting it as: $-ε < f(x) - f(a) < ε$ Which, in this case would be: $-ε < x^2-16 < ε$ $16-ε < x^2 < 16+ε$ $\sqrt{16-ε} < x< \sqrt{16+ε}$ Now, since we're looking for |x-a|<δ, set $δ=\sqrt{16+ε}-4$ from the equation above. For the proof itself: For $ ∀ε>0$, choose $δ=\sqrt{16+ε}-4$ and then $δ>0$ exists and implies: $|x-a|<δ$ $ |x-4|<δ= \sqrt{16+ε}-4$ $|x-4|+4<\sqrt{16+ε}$ $|x|<\sqrt{16+ε}$ $|x^2|<16+ε$ $|x^2-16|<ε$ Q.E.D. The problems i'm running into are mainly with the last step. In the solutions, it uses the method of splitting up $|x^2-16|<ε$ into $|(x-4)(x+4)|<ε$ and then going from there in order to get $δ=min(1,ε/9)$. I understand how their solution works but as I was taught my way a long time ago, I'm trying to figure out why mine does/doesn't work and if it doesn't if there's a way to modify it so that it does. Thanks for your help!","['continuity', 'functions']"
1265777,"In Neutral Geometry, prove that the opposite sides of a rectangle are congruent.","I'm having some trouble proving a theorem of Neutral Geometry. First, allow me to clearly state what we are allowed to assume in Neutral Geometry: Hilbert's incidence axioms Hilbert's order axioms Hilbert's congruence axioms We are $\textbf{NOT}$ allowed to assume Hilbert's Euclidean parallel postulate (which means we cannot use the converse of the AIA theorem) and we are $\textbf{NOT}$ allowed to assume Dedekind's Axiom (which means we cannot draw a bijection between angle sizes and real number degree measures). Every proof I have found from searching online involves implicitly assuming one of those two axioms, but they don't necessarily hold in Neutral Geometry. Having said that, here's the theorem I'm trying to prove: If $\square ABCD$ is a rectangle, then $\overline{AB}\cong\overline{DC}$ and $\overline{AD}\cong\overline{BC}$. Here's my attempted proof: $\textit{proof}$: Suppose $\square ABCD$ is a rectangle. $\overline{AD}\cong\overline{AD}$ because $\cong$ is reflexive. $\sphericalangle A\cong\sphericalangle D$ because $\sphericalangle A$ and $\sphericalangle D$ are right angles and all right angles are congruent. $\textbf{Suddenly, a miracle occurs, and we find that}$ $\sphericalangle CAD\cong\sphericalangle BDA$. By 2, 3, 4, and the ASA criterion for triangle congruence, we find that $\triangle CDA\cong\triangle BAD$. By 5, $\overline{AB}\cong\overline{DC}$. Use a similar argument to show that $\overline{AD}\cong\overline{BC}$ $\blacksquare$ Can someone help me fill in the justification for step 4? Is it even possible to justify step 4 in Neutral geometry? Thanks for your help, Jay","['euclidean-geometry', 'rectangles', 'geometry', 'noneuclidean-geometry']"
1265779,Investigating the bijectivity of $ 2 x + |\cos(x)| $.,"The question asks if the function
$$
f(x) = 2 x + |\cos(x)|
$$
if (one-one, onto), (many-one, onto) or (one-one, into). After a long process of plotting the graph, I managed to guess it’s one-one and onto. The textbook answer says it’s many-one and onto. I was unable to find any direct algebraic method (I tried to find the inverse function and find its domain) to prove my answer, so I can’t be sure. Any help in showing how it’s many-one is appreciated. Edit: The function is defined from $ \Bbb{R} $ to $ \Bbb{R} $.","['trigonometry', 'functions']"
1265848,mean value theorem sin(b) - sin(a),"It's too much hassle to post it here as latex, to so here's the screenshot . I don't understand why |cos(c)| = 1 Why 1? Why not $\frac {\sqrt{3}}{2}$? Why absolute value assumes the max value a function can take?
Shouldn't it be like: $\cos(c) > 0$ and $-\cos(c) < 0$ ?","['calculus', 'absolute-value', 'derivatives']"
1265869,"A continuous bijection from the Cantor Set to [0,1]","If $C$ is the Cantor Set, I am asked to show that there exists a continuous bijection, say $f$, that maps $C \to [0,1]$. My best guess thus far has been the Cantor Function, however (using this construction ) it doesn't appear to me to be a bijection, specifically not injective. If this is the case, is it possible for me to modify the Cantor Function to get a bijection? Thanks in advance for any advice!","['real-analysis', 'measure-theory']"
1265870,Convergence of a sequence by convergence of sub-subsequence,"Suppose that $\{p_n\}_{n \in \mathbb{N}}$ is a sequence in a metric space $X$. Assuming that every subsequence of $\{p_n\}_{n \in \mathbb{N}}$ has itself a subsequence that converges, say, to $p$, show that $\{p_n\}_{n \in \mathbb{N}} \to p$. Solution Attempt : Take $ \mathbb{N} \supset K := \{n,n+1,n+2, \ldots\}$ for $n \in \mathbb{N}$ to be our subsequence. Now, there exists $J_1 \subset K \subset \mathbb{N}$ so that $\{p_j\}_{j \in J_1} \to p$. If $J_1 = K$, we're done, otherwise assume $J_1 \subset K$. Thus, $K \setminus J_1$ is non-empty, take it to be our subsequence. Thus, there exists $J_2 \subset (K \setminus J_1)$ so that $\{p_j\}_{j \in J_2} \to p$. If $J_2 = (K \setminus J_1)$, we're done, otherwise assume $J_2 \subset (K \setminus J_1)$ so that the next iteration is non-empty. Inductively let, $$K \setminus \bigcup_{i=1}^{k} J_i$$ be our next subsequence so that there exists $$J_{k+1} \subset \Big(K \setminus \bigcup_{i=1}^{k} J_i \Big)$$ so that $\{p_j\}_{j \in J_{k+1}} \to p$. It is possible that we are left with a finite set $B \subset K$ so that $B$ is never in $J_k$. In this case, set $m = \max\{B\}$, so that the original sequence converges above $m$. Thus, $\{p_n\}_{n \in \mathbb{N}} \to p$ as desired. Is this a correct proof? I proved the statement by contradiction rather easily, but I wanted to try my hand at a direct proof. Any comments are appreciated.","['analysis', 'proof-verification', 'real-analysis', 'proof-writing']"
1265913,Almost sure convergence and L1 convergence,"I am preparing myself for the mid-term exam of my probability theory exam, and am solving questions from previous years exams. One of these questions I couldn't answer, and so far I haven't found anything similar online. Suppose that $X_n \rightarrow  X$ a.s. as $n \rightarrow \infty$. Prove or disprove that, if $\lim_{n \rightarrow \infty} \mathbb{E}|X_n| \rightarrow \mathbb{E}|X| < \infty$, then $X_n \rightarrow X$ in $L^1$ i.e. $\Bbb E[|X_n-X|] \to 0$. Here's my current approach:
Given \begin{equation}\mathbb{P}(\omega \in \Omega: \lim_{n \rightarrow \infty}X_n = X) = 1 \Leftrightarrow X_n \rightarrow X\text{ a.s.}\end{equation} NTS: \begin{equation} \lim_{n \rightarrow \infty}\mathbb{E}|X_n| \rightarrow E|X|<\infty \Rightarrow \lim_{n\rightarrow \infty}\mathbb{E}[|X_n - X|^1 ] =0.\end{equation}
Since $X_n \rightarrow X$ almost surely, $X_n \rightarrow X$ in probability. $L^1$ convergence is implied by convergence in probability + uniform integrability, so it suffices to show that $(X_n)$ is uniformly integrable. To show uniform integrability, I then define a function $f$ that is bounded and continuous, so that $f \circ X_n \rightarrow f \circ X$ in probability, and therefore $\mathbb{E}[f \circ X_n] \rightarrow \mathbb{E}[f \circ X]$, which (together with the assumption that $\mathbb{E}X_n \rightarrow \mathbb{E}X$) implies that $\mathbb{E}[X_n - f \circ X_n] \rightarrow \mathbb{E}[X - f \circ X]$. Last, fix some $\varepsilon <0$ and use the fact that X is integrable to show that the expectation of X over some interval of the function tends to 0. For more details, the proof is also given in the book ""Probability and Stochastics"" by Erhan Cinlar (page 108f, Theorem 4.9). However, this proof seems a little indirect because I am not ""really"" using the almost sure convergence, but rather am just working with convergence in probability. Is there any better (i.e more direct) approach?","['probability-theory', 'convergence-divergence']"
1265920,Domain of the function $f(x) = \sqrt{\frac{3^x-4^x}{x^2-4x-4}}$ will be?,"I tried solving this question by $1.$ $-1$ and $4$ will not be in domain because denominator can not be zero . $2.$ Either both denominator and numerator will be positive or negative so that whole term in root becomes positive. But I am not able to solve the upper part , can it be done by taking $\log$ ?","['logarithms', 'principal-ideal-domains', 'inequality', 'functions']"
1265976,Find number of circular arrangements possible,"If 20 persons were invited for a party, in how many ways will two particular persons be seated on either side of the host in a circular arrangement? According to me the answer should be $17!.2!$. But the given answer is $18!.2!$. If we consider the guest and the host as one unit and let them take the first three chairs the other 17 can be occupied by 17! ways and the two particular persons can then rearrange them by 2! ways. What am i doing wrong?","['discrete-mathematics', 'probability', 'combinatorics']"
1266043,Boy and girl paradox is driving me crazy,"I know this question is asked over and over, but I still can't understand anything. Say I'm introduced to a random father of two and I want to know what's the probability that both his children are boys. Currently: BB BG GB GG ⇢ 1/4 Where the first letter represents the younger sibling and the second letter represents the older sibling. So far so good. (1) Now the father tells me that his youngest child is boy: BB BG GB GG ⇢ 1/2 (2) If, instead, he told me that at least one of his children is a boy: BB BG GB GG ⇢ 1/3 Makes sense, kind of. (3) But if the father brought one of his children with him without telling whether he's the younger child or the older child and that child happened to be a boy, I think I could have still honestly arrived to the 50/50 probability: BB BG GB GG ⇢ 1/2 Where the first letter represents the boy I've just seen and the second letter represents his sibling. Now, say, the father first told me that he has at least 1 boy. That's the case (2). Then the father called (one of) the boy(s) here, and somehow the situation turned into the case (3)! What exactly has changed? What kind of new information did I just get? OK, I've seen (one of) the boy(s), but the only thing it tells me is that one of the children is a boy, which I already knew from the father's own words. It seems to me that anything he could bring that has some kind of relationship to (one of) the boy(s) so as to allow me to uniquely identify him would work: a photo, a footprint on a beach, etc. Even if he simply told me that he has just thought about one of his children who is a boy, I think I could still have done this: BB BG GB GG ⇢ 1/2 Where the first letter represents the boy the father has thought about at XX/XX/XXXX XX:XX:XX UTC, and the second letter represents his other child. Is this magic? Or am I just stupid? Can't I simply construct such a way of identification myself? For example, let the first letter represent the youngest boy (the only boy if there's just one), and let the other letter represent the other child. Since the father is not an abstract entity, this would uniquely identify some child. I don't see how changing the representation changes things. Say I saw one of the father's on a photo behind a thick blurry glass that doesn't let me see whether it's a girl or a boy. Therefore: BB BG GB GG ⇢ 1/4 Where the first letter represents the child on the photo and the second letter represents the other child. Now the glass is removed and I can see the photo clearly and it's indeed a boy: BB BG GB GG ⇢ 1/2","['paradoxes', 'probability']"
1266062,what is the lowest point of a tilted elliptical plate?,"I'd like to know the lowest point $z_\min$ of an ellipse with radius $r_x, r_y$ in (Euclidian) XY that's tilted in XYZ - first rotated around X axis by $\gamma$, then rotated around Y axis by $\alpha$. If it's only tilted around one axis, it's easy. $$-z_\min = r_x|\sin(\alpha)|$$ (tx for pointing out Achille) For the case $\alpha \neq 0$ and $\gamma \neq 0$, I thought about identifying the new direction and corresponding radius that lead to lowest point, but not sure exactly how to go about it. What's the way to find $z_\min$ with both $\alpha \neq 0$ and $\gamma \neq 0$?","['euclidean-geometry', 'trigonometry']"
1266111,Does L'hopital work for one sided limits?,"Simple question, to which I don't know the answer. Does it work the same even if we are only interested in one-sided limits, and it won't cause problems that the actual limit doesn't exist?",['limits']
1266124,Finding the characteristic timescale of a first-order nonlinear ODE,"I know that to find the timescale of a first order linear equation $$\frac{dX(t)}{dt} + aX(t) = b$$ you just take the inverse of the integrating factor, so $$t_x = \frac{1}{a}$$ Henning and joriki provide mathematical definitions of the characteristic timescale . I have a system of coupled ODEs. I want to find the timescale for the generation of one of the species, $X$, whose derivative is of the form $$\frac{dX(t)}{dt} + aX(t) = bY(t)Z(t)$$ Firstly, am I right in saying this is a first order non-linear ODE? Secondly, does anyone have any pointers for how to find its timescale? Many thanks.","['nonlinear-system', 'ordinary-differential-equations']"
1266125,Computing $\int_{0}^{\infty} \frac{x^2}{(x^2 + a^2)^2}dx$,"I want to compute  $$\int_{0}^{\infty} \frac{x^2}{(x^2 + a^2)^2}dx$$ and have tried applying trig substution with $x = a\tan(t)$, but things get a bit messy at the very end. I get
$$ \left [ \frac{1}{3}\tan^3(\arctan(\frac{x}{a}) - \tan(\arctan(x/a)) + \arctan(\frac{x}{a})) \right ]_{0}^{\infty}$$ Can anyone confirm that this is what we get? Or offer a better way?","['calculus', 'complex-analysis']"
1266138,"Construct a non-linear function that shows that the intervals $[2,4]$ and $[10,22]$ have the same cardinality","Using something other than a linear function, show the intervals $[2,4]$ and $[10,22]$ have the same cardinality. I don't quite know where to start with this problem, or what key factor is necessary to perceive the function that will satisfy the given problem.","['infinity', 'functions']"
1266158,Prove $\bigcap S$ exists for all $S \ne \emptyset$. Where is the assumption $S \ne \emptyset$ used in the proof?,"I know that $\bigcap S = \{x : \forall A \in S, x \in A \}$ Here if $S = \emptyset$ then there is no $A$ which satisfies the property. However, why is it then that it defaults to every possible $x$, that is the $\bigcap S$ becomes the set of all sets, as opposed to just saying the property no longer holds?",['elementary-set-theory']
1266203,Calculating eigenvalues of the induced action on $H^0(2 K_C)$,"Given a (smooth) curve $C$ and an automorphism $\phi$ of $C$. In the first part of their paper On the Kodaira dimension of the moduli space of curves Harris and Mumford calculate the eigenvalues of the induced action of $\phi$ on $H^0(2 K_C)$ (to study the singularities of $\mathcal{M}_g$). They don't do those calculations, instead only state the results and I seem to be missing something to understand how this is done in principle. To be more concrete, the easiest example they consider is (p. 31): $C$ given as $y^2 = (x^3 - 1) (x^3 - a)$ with automorphism $\phi(x,y) = (\zeta_3 x, - y)$, where $\zeta_3$ is a primitive third root of $1$. $C$ has genus $2$, so $H^0(2 K_C)$ has dimension $3$. The automorphism is of order six, so the eigenvalues are given as $\zeta_6^{a_i}$, $i = 1,2,3$ with $\zeta_6$ a primitive sixth root of $1$. They state that the $a_i$ are given as $0,2,4$. How to calculate those? The only thing I see is that $a_i = 0$ gives an eigenvalue: Considering $C \rightarrow C/\phi$, we get a six to one cover of $\mathbb{P}^1$ with four branch points of profile $(2,2,3,3)$. Now a quadratic differential on $C$ has eigenvalue one iff it is the lift of a quadratic differential under this map. There are no smooth quadratic differentials on $\mathbb{P}^1$. But if a quadratic differential on $\mathbb{P}^1$ has a zero of order $m$ at $p$, its lift to $C$ has a zero of order $m k + 2(k-1)$ (where negative numbers denote poles) at a point in the fiber over $p$, at which locally the cover is given as $z \rightarrow z^k$.
So in this example, a quadratic differential with simple poles at the branch points lifts to a smooth quadratic differential on $C$ (with prescribed zeroes at four of the ten ramification points). Now the space of quadratic differentials on $\mathbb{P}^1$ with poles at at most four points is one dimensional and in this way we get the one-dimensional eigenspace corresponding to the eigenvalue $1$. Is that right? Is it possible to calculate the other eigenvalues in a similar manner?","['algebraic-geometry', 'moduli-space', 'algebraic-curves']"
1266206,find $\lambda$ such that the integral has a solution.,I have the integral equation: $u(x) = f(x) + \lambda \int_0^{\frac{1}{2}}u(y)dy$ I have to find $\lambda$ such that the integral has a solution. How to approach such problems?,"['calculus', 'linear-algebra', 'integration', 'operator-theory', 'ordinary-differential-equations']"
1266208,Problem with statement of Needham's Visual Complex analysis exercise 15 chapter 3 page 185,"The exercise 15 and accompanying diagram above show 3 clockwise points $q, r, s$ on a circle and a 4th point $z$ on the circle between $q$ and $s$, and a second diagram with the same three points $q, r, s$ but with $z$ on the circle again but this time between $q$ and $r$. $\angle qrs$ is shown as positive and equal to $\phi$ and $\angle qzs$, shown as positive in the first diagram and negative in the second diagram and equal to $\theta$. The exercise says:
Show that in both of the figures Arg$[z,q,r,s]=\theta+\phi$.
where $[z,q,r,s]$ is the cross ratio. This seems strange to me since in the first diagram $\theta+\phi$ is always equal to $\pi$ and in the second diagram $\theta$ is always equal to $\phi$. As far as the last part about deducing (31) is concerned,  (31) in the book says: A point $p$ lies on the circle $C$ through $q,r,s$ if and only if
Im$[p,q,r,s]=0$. I don't think this last part is relevant to understanding the exercise as stated, but I may be wrong.
What do you think?",['complex-analysis']
1266210,Number of ways in which a batsman can score 14 runs in 6 balls not scoring more than 4 runs in any ball.,"Hello everybody my query is regarding the number of positive integral solution. In the sport of cricket, find the number of ways in which a batsman can score $14$ runs in $6$ balls not scoring more than $4$ runs in any ball.","['combinatorics', 'permutations']"
1266211,"On the existence of a continuous bijection $f\colon [0,1]\to [0,1]\times [0,1]$","Let $f$ be a continuous function on $[0,1]$ such that $f([0,1])=[0,1]\times[0,1].$ Then show that $f$ is not one-one. Hints will be appreciated.",['real-analysis']
1266232,Explaining intersections to a 6th grader,"$A=\{1,2,3,4,5\}$ $B=\emptyset$ How to explain to a learner from 6th grade the result for $A \cap B$ ? For a 6th grade student, it could be difficult to understand why the result is $\emptyset$. Most of them might think like this: ...well, the result is what both $A$ and $B$ have, but does the $A$ set contain the $\emptyset$ ? It will be great to explain with some day-by-day examples, examples from real life and so on.","['education', 'elementary-set-theory', 'learning']"
1266236,General solution for differential equation,"I have the following differential equation ; $$\frac{dx\left(t\right)}{dt}=ay\left(t\right)-bx\left(t\right)$$ where $a$ and $b$ are positive constant terms. $t$ indicates time. I am trying to solve in the following manner ; First, I put $bx(t)$ in the LHS and multiply two sides by $e^{bt}$ ; $$\frac{dx\left(t\right)}{dt}e^{bt}+bx\left(t\right)e^{bt}=ay\left(t\right)e^{bt}$$ After, I write ; $$\frac{d\left(x\left(t\right)e^{bt}\right)}{dt}=ay\left(t\right)e^{bt}$$ My objective is to solve this integral between time $0$ and $\infty$ ; $$\int_{0}^{\infty}\frac{d\left(x\left(t\right)e^{bt}\right)}{dt}=\int_{0}^{\infty}ay\left(t\right)e^{bt}$$ which yields $$\left[x\left(t\right)e^{bt}\right]_{0}^{\infty}=\int_{0}^{\infty}ay\left(t\right)e^{bt}$$ The problem is that the left hand side explodes and goes to infity. How can I solve this differential equation in a correct way ?","['calculus', 'ordinary-differential-equations']"
1266271,Changing limits in absolutely convergent series,"Let $\sum_{n=0}^\infty f(n,m)$ be a real series. Suppose the series converges absolutely. Can we do the following?
$$
\lim_{m\to\infty}\sum_{n=0}^\infty f(n,m)=\sum_{n=0}^\infty \lim_{m\to\infty}f(n,m)\quad
$$ I thought about some series, but all of them fit. Is there any counterexample? We suppose that all limits exist.","['sequences-and-series', 'calculus', 'real-analysis']"
1266302,Error term of a Tauberian theorem and lattice points in circles,"Suppose $\{a_n\}$ is a sequence of non-negative real numbers, $a_n = O(n^M)$ for a positive number $M$ and it's Dirichlet series $L(s)=\sum \frac{a_n}{n^s}$ has an analytic continuation to a meromorphic function on $\mathbb C$ with only a simple pole at a positive real number $a$ with residue $A$. Using a standard Tauberian theorem (if I'm not forgot a necessary condition) one can conclude that:
$$\sum_{n\leq x} a_n = Ax^a + O(x^{a-\delta}). $$ My question is: What is the maximum value of $\delta$ for which the above asymptotic formula works? My motivation for this question was an effort to finding out the asymptotic of the number of lattice points in a circle with radius $\sqrt{N}$ with center at the origin which is closely related with Dedekind zeta function of $\mathbb Q[i]$. It turns out that this zeta function satisfies all of the above conditions for $a=1$ and $A=\frac{\pi}{4}$. So what is the best result one can obtain in this way?","['complex-analysis', 'analytic-number-theory']"
1266313,A problem in definite integral.,"What will be the value of $a$ for which the integral 
$$\int \limits^{\infty }_{0}\frac{dx}{a^{2}+(x-\frac{1}{x})^{2}} =\frac{\pi}{5050}$$ where $a^{2}\geq0$ It seems like a standard integral but $x-\frac{1}{x}$ creating all the problem. I tried substituting $x-\frac{1}{x}=t$ and then differentiating and squaring and then rearranging but it leads us to nowhere. I couldn't find any other substitution to solve this problem. Any hint will be of great help. Please do not provide the complete solution.","['definite-integrals', 'algebra-precalculus', 'integration']"
1266337,Link between harmonic and holomorphic functions on a non-simply connected domain.,"There is a theorem that states that if a function $h$ is harmonic on a simply connected domain, there exists a holomorphic function $f$ such that $h = Re f$. Now, I am having a problem with the statement of this exercise: Let $h$ be a function harmonic on $\{z\in\mathbb{C}: \rho_1 < |z| < \rho_2\}$. Using the fact that $h_x - ih_y$ is holomorphic, prove that... What we need to prove is not important, I've already done that. The question is about the fact mentioned in the statement: that $h_x - ih_y$ is holomorphic. The domain is not simply connected. Normally, we need a simply connected domain to prove that $h_x - ih_y$ is holomorphic, because we use the path-independence of an integral of the form $h(z_0) + \int_{z_0}^z (h_x - ih_y)(w)dw$. Is there another proof that $h_x - ih_y$ is holomorphic in a non-simply connected domain? 
Or did I misread the statement and this is just an additional condition on our function $h$?","['harmonic-functions', 'complex-analysis']"
1266338,To show $X$ and $|X|$ are not jointly continuous,"Suppose $X\in N(0,1)$. Show that $X$ and $|X|$ are not jointly continuous. I am not sure how I can approach this problem. But the following method seems plausible to me: $$P(X\leq x||X|=u)=\lim_{a\to0}\dfrac{P(X\leq x,|X|\in (u-a,u+a))}{P(|X|\in (u-a,u+a))}$$ Of course we must have $u>0$. Now let $-u<x<u$ then after some stage, I will get $a$ so small that $x$ will not belong to $(u-a,u+a)$ or $(-u-a,-u+a)$. In that case, the intersection of $(-\infty,x)$ and $(-u-a,-u+a)\cup(-u-a,-u+a)$ will be $(-u-a,-u+a)$ due to which the result becomes: $$\lim_{a\to0}\dfrac{P(X\in(-u-a,-u+a))}{P(X\in(-u-a,-u+a))+P(X\in(u-a,u+a))}=\lim_{a\to0}\dfrac{\Phi(-u+a)-\Phi(-u-a)}{\Phi(-u+a)-\Phi(-u-a)+\Phi(u+a)-\Phi(u-a)}=0.5$$ Now for $x<-u$, the intersection $\{X\leq x\}$ with $\{|X|\in(u-a,u+a)\}$ is null, hence the numerator is $0$, so the probability is $0$. If $x>u$ then the probability is $1$. Hence $P(X\leq x||X|=u)=0$ if $x<-u$, is $0.5$ if $-u<x<u$ and is $1$ if $x>u$. So it has two jumps and cannot be a continuous distribution function, and hence cannot have a density. But this density is precisely the conditional density of $X$ on $|X|$, which therefore does not exist. This can happen only when $f_{X,|X|}(x,u)$ does not exist, which shows there is no joint density of $X$ and $|X|$.","['probability-theory', 'probability', 'probability-distributions']"
1266410,Prove matrices are of equal rank,"Suppose $P$ and $Q$ are $n \times n$ matrices of real numbers such that $P^2 = P$, $Q^2=Q$ and   $I-P-Q$ is invertible, where $I$ is the $n × n$ identity matrix. Show that $P$ and $Q$ have the same rank. Since $I-P-Q$ is invertible, it has rank $n$. Also, $det(I-P-Q) \neq 0$. Can we get the result from these facts?","['matrix-rank', 'linear-algebra', 'matrices']"
1266450,Can we derive the PDE followed by a marginal transition probability density?,"A pair of correlated stochastic processes follow the SDEs
\begin{align}
dX_t&=a(t,X_t)\,b(t,Y_t)\,dt+c(t,X_t)\,d(t,Y_t)\,dW_t, &&X_0=\bar{x}\\
dY_t&=f(t,Y_t)\,dt+g(t,Y_t)\,dZ_t, &&Y_0=\bar{y}
\end{align}
where $W_t$ and $Z_t$ are correlated Brownian motions with constant correlation $\rho$ and $a,b,c,d,f,g$ are smooth functions. We know that the probability density $p(t,x,y)$ of the process reaching the state $X_t=x$, $Y_t=y$, given the initial condition at $t=0$ satisfies the forward Kolmogorov equation (also known as Fokker Planck equation):
$$
  p_t=-(abp)_x-(fp)_y+\frac{1}{2}(c^2d^2p)_{xx}+\frac{1}{2}(g^2p)_{yy}+\rho(cdgp)_{xy}
$$ Let $h(t,x)$ be the marginal probability distribution of the process $X_t$, i.e.
$$h(t,x)=\int_y p(t,x,y)dy$$
is it possible to write the partial differential equation in the variables $x$ and $t$ that $h(t,x)$ must satisfy?","['stochastic-calculus', 'stochastic-processes', 'ordinary-differential-equations', 'partial-differential-equations']"
1266475,Number field attached to a finite group.,"Let $G$ be a finite group. I know that the set of irreducible representations of $G$ over the complex numbers (up to isomorphism) is finite. Let us fix our attention on some irreducible representation of $G$ over $\Bbb{C}$ 
$$\rho: G \longrightarrow GL_n(\Bbb{C})$$
My intuition tells me that there exists some finite extension $K \supset \Bbb{Q}$, and some irreducible representation
$$\sigma:G \longrightarrow GL_n(K)$$
such that $\rho = i \circ \sigma$, where $i: GL_n(K) \longrightarrow GL_n(\Bbb{C})$ is the inclusion (every matrix with entries in $K$ has entries also in $\Bbb{C}$). For example, if $G=C_2$ is the group with two elements, we can think the two irreducible representations of $C_2$ as $\sigma_1, \sigma_2 : C_2 \longrightarrow GL_1(\Bbb{Q})$, so $K=\Bbb{Q}$. However I don't know if this is true for any finite group  (but I strongly believe that this is true, maybe you can give me some reference). My question is: given $G$ a finite group, can we find some number field $K$, such that all irreducible representations of $G$ over the complex numbers can be thought as irreducible representations over $K$ (i.e. all involved matrices actually have entries in $K$)? Can we find a minimal such number field?","['number-theory', 'representation-theory']"
1266512,"5 pears and 1 apple cost as much as 2 pears and 2 apples. If each apple costs $0.75,find the total cost of 100 pears and 450 apples.",I know it's in algebra based on the context and the next question is also algebra. This is what I could do: $y + $0.75 = $x $d + $1.50 = $x I don't know what to do next.,"['word-problem', 'algebra-precalculus']"
1266528,Solving an SDE: $dX=-Xdt+e^{-t}dW$,"I have the following problem which comes with the solution, but I am unable to obtain the solution... Any help would be greatly appreciated - I am preparing for finals :( Thanks a lot! The SDE that I need to solve is $dX=-Xdt+e^{-t}dW$. The solution is $X(t)=(X_0+W(t))e^{-t}$ I have noticed that 
$$dW=e^{t}dX+e^{t}Xdt=d(e^tX)$$ So I have tried with $Z=e^tX$ and get $dZ=2e^t(dX+X)$, but I am stuck there now :/ (and I am not sure if that $dZ$ is correct either because we are not shown how the professor got the final result).","['stochastic-differential-equations', 'ordinary-differential-equations']"
1266550,Compute $\lim\limits_{n\to \infty}\frac{\prod\limits_{k=1}^{n}a_k}{2^n}$,"Compute $$\lim\limits_{n\to\infty}\frac{\prod\limits_{k=1}^{n}a_k}{2^n}$$ where $a_k=\sqrt{2+a_{k-1}}$ and $a_1=\sqrt{2}$. I proved $\lim\limits_{n\to\infty}a_n$ exists and found it (it's 2), but $\lim\limits_{n\to\infty}\frac{\prod\limits_{k=1}^{n}a_k}{2^n}$ is much more challenging for me.","['sequences-and-series', 'calculus']"
1266552,Can a function be differentiable while having a discontinuous derivative?,"Recently I came across functions like $x^2\sin(1/x)$ and $x^3\sin(1/x)$ where the derivatives were discontinuous. Can there exist a function whose derivative is not conitnuous, and yet the function is differentiable? If yes, please provide some examples.","['derivatives', 'continuity', 'limits', 'functions']"
1266593,Markov chain ergodicity,"$(X_n)_n$ is a discrete-time, time-homogenous Markov chain. I have have the following transition matrix and  want to show whether the chain is ergodic. $$P = \begin{pmatrix}
\frac{1}{2} & 0 & 0 & \frac{1}{2}\\
0 & \frac{1}{2} & \frac{1}{2} & 0\\
0 & \frac{1}{2} & \frac{1}{4} & \frac{1}{4}\\
\frac{1}{2} & 0 & 0 & \frac{1}{2}\end{pmatrix}$$ I tried to compute $P^2 P^3 $.... I don't have all coefficients $>0$. There is a unique stationary distribution [$\frac{1}{2},0,0,\frac{1}{2}$] so I can't prove this is not ergodic. More over, I can't prove that the distribution is periodic for example $P=P^5$ . I tried to show that the matrix is irreducible with $A=(A+ \, \text{Id})^n$ ( find a n with all coefficients >0). I am quite stuck now, thanks for your help","['probability-theory', 'markov-chains', 'matrices']"
1266610,"What are ""tan"" and ""atan""?","As the title says, I'm confused on what tan and atan are. I'm writing a program in Java and I came across these two mathematical functions. I know tan stands for tangent but if possible could someone please explain this to me. I have not taken triginomotry yet (I've taken up to Algebra 1) so I don't really need a very in depth explanation since i wouldnt understand but just a simple one so i could move on with my program would be great! Thanks in advanced. Also if possible could someone possibly give me a link to an image/example of a tangent and atan.","['notation', 'trigonometry']"
1266614,Reduce PDE to ODE,"Maybe you don't want to check all the details, but could look at a few equations here. Would you mind leaving a comment that you at least some part looks okay?- This way, I know that at least somebody checked it, too (although maybe not every step). I want to reduce the PDE $$ \sum_{i=1}^{n} \partial_i \left( \frac{\partial_i u(x)}{\sqrt{1+ \sum_{j=1}^{n} ( \partial_j u(x)^2 ) }} \right)=0$$ to an ODE by looking at solutions of the form $u(x):=f(||x||).$ We have $\partial_i u(x) = f'(||x||) \frac{x_i}{||x||}$
and $\partial_{i,j}u(x) = f''(||x||) \frac{x_i x_j}{||x||^2} + f'(||x||) \frac{\delta_{i,j}||x||^2 - x_j x_i }{||x||^3}.$ Applying the product rule to the PDE and multiplying by the square root in the demoninator, I get $$ \left(\sum_{i=1}^{n} \partial_i^2 u(x) \right) \left(1+ \sum_{j=1}^{n} ( \partial_j u(x)^2)  \right) - \left(\sum_{i,k=1}^n \partial_i u(x) \partial_k u(x) \partial_{i,k} u(x) \right) =0$$ Rewriting gives $$\left(\sum_{i=1}^{n} \partial_i^2 u(x) \right) = f''(||x||)+f'(||x||) \frac{(n-1)}{||x||}$$ $$\left(1+ \sum_{j=1}^{n} ( \partial_j u(x)^2)  \right) = 1+f'(||x||)^2$$ and finally $$ \left(\sum_{i,k=1}^n \partial_i u(x) \partial_k u(x) \partial_{i,k} u(x) \right) = f'(||x||)^2 f''(||x||).$$ Is this all correct?","['calculus', 'real-analysis', 'analysis', 'ordinary-differential-equations', 'partial-differential-equations']"
1266621,Zorn's Lemma's chain condition,"Zorn's Lemma requires that every chain in a partially ordered set $X$ has an upper bound. In this article Gowers uses Zorn's Lemma to find a maximal linearly independent (over $\mathbb{Q}$) subset of $\mathbb{R}$. He does this by looking at the set of all linearly independent subsets of $\mathbb{R}$ with the partial order $\subset$. He checks that every chain has an upper bound by considering a collection $Y$ of nested linearly independent subsets of $\mathbb{R}$. He defines the upper bound as their union. Thus every chain has an upper bound and Zorn's lemma can show that a basis for $\mathbb{R}$ over $\mathbb{Q}$ exists. But what if $Y$ is infinite? It's not too hard to think of a chain in this case that has no upper bound- just keep adjoining appropriately chosen irrational numbers to get another subset of $\mathbb{R}$ linearly independent over $\mathbb{Q}$. The chain of such subsets has no upper bound, right? In general, when you prove that every chain in $X$ has an upper bound, you need to consider finite and infinite chains, right? So how come Gowers, in paragraph 24 (below), implicitly assumed that $Y$ is a finite collection? Obviously it is easy to find the upper bound of a finite chain. All we have to do if we want to apply Zorn’s lemma is check that every chain has an upper bound. So let us imagine that we have a collection $Y$ of linearly independent subsets of $\mathbb{R}$ and that for any two of those sets one is contained in the other. What could serve as an upper bound? By definition it has to be a set that contains all the sets in $Y$, so it has to contain their union. We want it to be linearly independent, so the smaller it is, the better. So there is basically only one candidate to try: the union itself. Is the union linearly independent? Well, if $t_1,\dots,t_n$ belong to the union, then each $t_i$ belongs to some linearly independent set $L_i\in Y$. Because $Y$ is a chain, one of these sets $L_i$ contains all the others. If that is $L_j$, then the linear independence of $L_j$ implies that no non-trivial linear combination of $t_1,\dots,t_n$ can be zero, which proves that the union of the sets in $Y$ is linearly independent, just as we wanted. Therefore, by Zorn’s lemma, there is a maximal linearly independent set.","['elementary-set-theory', 'vector-spaces', 'axiom-of-choice']"
1266639,"What does $x_e$ mean in $I(x_e,y_0)$?","A book I am using has a problem which includes two points on the graph of $y=\ln x$, $M_1(x_1, y_1)$ and $M_2(x_2, y_2)$ and identifies the middle of the chord $M_1 M_2$ between them as $I(x_e, y_0)$. What do you suppose is meant by $x_e$ in this case? Is it $x=e$ or $x$ such that $y=e$ or ?  I could put the whole problem here, but I hope to solve it myself once I understand the notation. Update: the whole problem (please don't solve it yet or I won't get to. I would like to understand the problem better. I've done some thinking and computing and have some good ideas, but I don't understand the problem fully. Thus, hints would be more appreciated than an answer.): Klein & Reeb, Problem I.1.10 Soient $M_1(x_1,x_y)\,M_2(x_2,y_2)$ deux points du graphe de $y=\ln x$. Soit $I(x_e,y_0)$ le milieu de la corde $M_1 M_2$. D'aprés la
concavité du graphe $y_0 < \ln x_0$; en déduire: $2 \sqrt{x_1 x_2} < x_1 + x_2$. My translation: $M_1(x_1,x_y)\,M_2(x_2,y_2)$ are two points on the graph of $y=\ln x$.
$I(x_e,y_0)$ is the middle of the chord $M_1 M_2$. According to the
concavity of the graph  $y_0 < \ln x_0$; deduce $2 \sqrt{x_1 x_2} < x_1 + x_2$. Update: given GPerez's comment below which agrees with a thought I had too about $x_e$, I'd say it's possible (but not yet conclusive in my mind) the book has a typo and $x_0$ was meant instead. Update: my thought process on solving the problem was approximately thus: since $y=\ln x$ is concave, if $M_1$ is negative, then $0<x_1<1$ since $\ln x < 0$ for $0 < x < 1$. If $x_e$ wasn't a typo, I had supposed that, since it was the x-coordinate of the midpoint of $M_1 M_2$ it might mean that $M_2$ had to be located to the right of either where $y$ attains the value $e$ or where $x=e$, and knowing this would indicate that $M_2$ is to the right of that point since it is the right endpoint. From these facts, we would then deduce that $0<x_1<1$ and (for the case where we suppose $x_e$ means $x=e$:) $e<x_2<\cdot$ where $\cdot$ here is some value to the right of $x_2$ or (for the case where we suppose that $x_e$ means $y=e$:) $1<x_2<\cdot$ where $\cdot$ here is some value to the right of $x_2$. Then using the rules of logarithmic manipulation we could expand the LHS and RHS of the inequality given and compare term by term to prove it based on our knowledge of the range of possible values for $x_1$ and $x_2$ supposed above. That was my plan, but given the uncertainty of the notation and the incompletion, as of yet, of my computations, I've not concluded the solution.","['analysis', 'geometry', 'notation']"
1266669,All entire functions which satisfying : $f(2z)=f(z)^{2}$,I want to solve following question: Find all entire functions satisfying the condition that $f(2z)=f(z)^{2}$ and $f(0)\ne 0.$ I know the function $f(z)=\mathbb e^{wz}$ for every $w$ is a solution. Is there another entire function by above property?,['complex-analysis']
1266675,Finding the bounds of a solid for triple integrals,"Ok, so I have an answer, most likely the wrong one. The question being asked is: Using polar coordinates find the volume of the solid bounded below by the $xy–plane$ and above by the surface $x^2 +y^2 +z^6 =5$. First off I found the bounds for $x,y$ and $z$. These are $x \space [0,\sqrt{5}], \space y \space[0, \sqrt{5}],  \space z \space[0, 5^{\frac{1}{6}}]$ I use these bounds and integrate the function $x^2 +y^2 +z^6 =5$ I realise this is not right, but I am unsure why? Could someone explain this to me. I know I have to write the bounds in terms of the unused variables, otherwise it wouldn't ask for polar coordinates. The best I could come up with was this: $ y \space [0, \sqrt{5}], \space x \space[0, \sqrt{5-y^2-z^6}], \space z \space [0, (5-y^2-x^2)^{\frac{1}{6}} ]$ Afterwards we multiply the integral by 4. I have 2 bounds with 2 variables and 1 bound with none. I know this can't be right, we should have 3,2,1. But I am having trouble figuring out what exactly the bounds should be. If someone could explain to me how I can find these bounds so I could use them for general questions that would be great!. I'm also pretty sure I can integrate by converting to polar coordinates, I am just having trouble with the bounds, that is all. Thanks for any help !","['polar-coordinates', 'multivariable-calculus', 'integration']"
1266689,Distance from a point to the involute of a circle,"I know that the involute of circle of radius $r$ centered at $(0,0)$ is given by the following parametric form:
$$\begin{cases}
x(\theta) = r \big(\cos(\theta) + \theta\ \sin(\theta) \big),\\
y(\theta) = r\big(\sin(\theta) - \theta\ \cos(\theta) \big),
\end{cases}$$
with $\theta\in\mathbb{R}$. Given a point $(a,b)\in\mathbb{R}^2$, I would like to compute its distance to the involute (or the closest point on the involute). Given the parametric form I can compute the normal direction to the involute at a point and, thus, I need to compute a $t\in\mathbb{R}$ such that 
$$(a,b) = \big(x(\theta),y(\theta)\big) \ + \ t\ \big(-y'(\theta),x'(\theta)\big).$$
I guess that now the easiest way consists on computing $\theta$ first, which gives the closest point:
$$\frac{x(\theta)-a}{y'(\theta)}-\frac{b-y(\theta)}{x'(\theta)}=0.$$
It is obvious that one needs iterative solvers to approximate the solution (I have already tried Newton-Raphson). The main problem is that the function to be minimized is highly oscillating and it can be difficult to give a good approximation for the initialization of the algorithm. In fact, it seems that this should also depend on the radius $r$. Any help or suggestion is really welcome: from a geometrical point of view (a way to simplify the computations, an already computed formula...), from a numerical point of view (other algorithms) or from the implementation point of view.","['euclidean-geometry', 'geometry', 'numerical-methods']"
