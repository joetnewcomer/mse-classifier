question_id,title,body,tags
299387,Automorphism of the function field and birational map,"Let $X$ be a projective complex manifold and $\mathbb{C}(X)$ its function field i.e. field consisting of meromorphic functions on $X$. Is it true that any $\phi\in \mathrm{Aut}(\mathbb{C}(X))$ induces a birational map $\tilde{\phi} \in \mathrm{Bir}(X)$? i.e. $\phi=\tilde{\phi}^*$. I am aware that the converse is always true. If the above assertion is true, how can one prove it?","['algebraic-geometry', 'complex-geometry']"
299399,Using the alternative formula to find the derivative of a function?,"I'm attempting to find the derivative of the function:
$$f(x) = 4x^2+3x+5$$
Using the alternative formula:
$$\frac{f(z)-f(x)}{z-x}$$ Here are my steps so far:
$$\frac{4z^2+3z+5-(4x^2+3x+5)}{z-x}$$
$$\frac{4(z^2-x^2)+3(z-x)}{z-x}$$ I have no idea where to go from this point. I've tried several different things to come up with the correct answer - which I know is $8x+3$. Can someone please guide me through this problem? I'm completely stuck.
Also, sorry about the formatting. I'm using this editor http://www.codecogs.com/latex/eqneditor.php?lang=en-en and don't have it completely figured out yet.","['calculus', 'derivatives']"
299404,Please help me to solve this equation $3x+3^{\ln{x}}-4=0$,"Please help me to solve this equation 
$$3x+3^{\ln{x}}-4=0$$ I found $x = 1$ in a plot W.A, but can I find x by Algebraic solution? Thanks",['algebra-precalculus']
299409,Is $\sqrt 7$ a sum of roots of unity?,"Let $a_1,\dots,a_n$ and $b_1,\dots,b_n$ be two sequences of rational numbers. Is it possible that $\sqrt 7 = \sum_{m=1}^{n} a_m (-1)^{b_m}$ ? Is it possible that $\sqrt{17}$ = $\sum_{m=1}^{n} a_m (-1)^{b_m}$ ? How to prove or disprove these ?","['cyclotomic-fields', 'roots-of-unity', 'abstract-algebra', 'field-theory']"
299423,Is the diagonal set a measurable rectangle?,"Let $\Sigma$ denotes the  Borel $\sigma$-algebra of $\mathbb{R}$ and $\Delta=\{(x,y)\in\mathbb{R}^2: x=y\}$. I am trying to clarity the definitions of $\Sigma\times\Sigma$ (the sets which contains all measurable rectangles) and $\Sigma\otimes\Sigma$ (the $\sigma$-algebra generated by the collection of all measurable rectangles). My question is (1) does $\Delta$ belong to $\Sigma\times\Sigma$? (2) does $\Delta$ belong to $\Sigma\otimes\Sigma$? I am thinking that (1) would be no (since a measurable rectangle can be arbitrary measurable sets which are not required to be intervals?) and (2) would be yes (can we write $\Delta$ like countable unions of some open intervals? I cannot find a one at time).","['probability-theory', 'measure-theory']"
299452,Math symbol for approximation of probability distribution by arbitrary function?,"I want to use a symbol between two functions; $$p\text{ (symbol) }f$$ such that $p$ is a probability function and $\text{(symbol)}$ implies: we do not have access to $p$ but we approximate it with a function $f$ which is not a probability function (i.e. although it produces values between $0$ and $1$, its values do not sum up to $1$). Any ideas?","['probability', 'functions']"
299459,"Does $Ax=x$ imply $A^* x=x$, if $A^*$ is the conjugate transpose of $A$?","I have a fairly simple question. If $A$ is a matrix and $A^*$ denotes its conjugate transpose, is it true that if $Ax = x$ , then $A^*x = x$ ? The matrix $A^*$ will certainly have $1$ as an eigenvalue, but will it be with the same eigenvector? And if not, what is the relation between the eigenvector of $A$ and the one of $A^*$ ?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
299484,Composition of orthogonal projections,"I need to prove the following result: Suppose $P_1$ and $P_2$ are orthogonal projections onto closed subspaces $V_1$ and $V_2$, then $P_1P_2x = x$ if and only if $x\in V_1\cap V_2$. But it seems to me that if you take two parallel lines $V_1$, $V_2$ in $\mathbb R^2$, and $x\in V_1$, then $P_1P_2x =x$, but $x\not\in V_1\cap V_2$. Can you please tell me what is wrong with my intuition? Thanks!",['linear-algebra']
299509,Show that the ideal of all polynomials of degree at least 5 in $\mathbb Q[x]$ is not prime,"Let $I$ be the subset of $\mathbb{Q}[x]$ that consists of all the
  polynomials whose first five terms are 0. I've proven that $I$ is an ideal (any polynomial multiplied by a polynomial in $I$ must be at least degree 5), but I'm unsure to how to prove that it is not a prime ideal.  My intuition says that its not, because we can't use $(1)$ or $(x)$ as generators. I know that $I$ is a prime ideal $\iff$ $R/I$ is an integral domain.
Again, I'm a little confused on how represent $\mathbb{Q}[x]/I$","['ring-theory', 'abstract-algebra', 'polynomials', 'commutative-algebra', 'ideals']"
299518,"Find sets $E_1, E_2,\dots$ of finite outer measure s.t. $E_k \searrow E$ and $\lim |E_k|_e > |E|_e$","I am trying to show existence of sets $E_1, E_2,\ldots$ s.t. $E_k \searrow E$, $|E_k|_e$ (outer measures of $E_k$'s) are finite and $\lim |E_k|_e > |E|_e$ strictly. I took a nonmeasurable subset of $[0,1)$ and tried to find a sequence of nonmeasurable sets decreasing to empty set. We know that all these sets have positive outer measure, but is it possible that their limit is positive? (or is there such a decreasing sequence?)","['measure-theory', 'real-analysis']"
299521,Fuzzy Venn diagram regions labeled in ternary,"I have a couple of questions about the Venn diagrams object : Words from the binary alphabet with n letters label each region of an order-n Venn diagram. Is there any more profound connection between binary representations and say the way Venn diagrams should be laid out with respect to neighbors (Hamming distance between labels, say)? What are the consequences if we consider 'fuzzy' sets, say a type of set with a inclusion metric that is ternary (0,out),(1,inbetween),(2,in) , and we label the 'regions' of some kind of Venn diagram using words of n letters from the ternary alphabet?","['graph-theory', 'inclusion-exclusion', 'elementary-set-theory', 'visualization']"
299530,Regular cardinals and unions,"If a cardinal $\kappa$ is regular then it cannot be written as a union of fewer than $\kappa$ sets, each of size less than $\kappa$. This seems to be a very useful characterization.  I have seen a proof or two, but can't grasp all the details... I am horrible with ordinal and cardinal arithmetic.  Could someone please give an elementary (as much as possible) proof of this theorem for me?","['cardinals', 'elementary-set-theory']"
299573,"How to show that $C[a,b]$ is infinite dimensional?","How can we give a rigorous proof of the fact that the space $C[a,b]$ of all continuous real (or complex)-valued functions defined on a closed interval $[a,b]$, where $a$, $b$ are any two given real numbers such that $a<b$, is infinite-dimensional? We of course take the following norm: $$ ||x|| := \max_{a\leq t \leq b} |x(t)|$$ for any $x \in C[a,b]$, the vector addition and saclar multiplication being defined pointwise as usual.","['normed-spaces', 'functional-analysis']"
299592,Justification behind changing coordinates of a differential operator,"On many websites focused on physics, (say http://skisickness.com/2009/11/20/ ) they like to represent differential operators in different coordinates. I.e. going from the standard basis to polar coordinates they would write:
$$\frac{\partial }{\partial x} = \frac{\partial r}{\partial x} \frac{\partial }{\partial r} + \frac{\partial \theta}{\partial x} \frac{\partial }{\partial \theta}.$$
Here is my understanding and I would like some validation or corroboration: 
If our function $f$ is assumed to be independent of coordinates (and so it should be in a real life application such as in physics), then the derivatives of $f$ in different basis relate to each other. We know that $x=r\cos\theta$ and $y= r\sin\theta$ and so in an abuse of notation we may write
$$f(x,y) = f(r\cos\theta,r\sin\theta) :=g(r,\theta)$$
and rename the $g$ to $f$ in an abuse of notation because we are identifying them as the same output (but with a different basis representing their domains). If the maps between the coordinates are smooth enough (and in this case away from 0), we may use the chain rule to compute
$$ \frac{\partial f}{\partial x} = \frac{\partial f}{\partial r}\frac{\partial r}{\partial x}+\frac{\partial f}{\partial \theta}\frac{\partial \theta}{\partial x}$$
By plugging in for $r_x$ and $\theta_x$ and ""erasing""  the $f$ from both sides, we obtain the ""change of variables"" for the differential operator. Now because we know by definition of applying the operator,
$$(\frac{\partial r}{\partial x} \frac{\partial }{\partial r} + \frac{\partial \theta}{\partial x} \frac{\partial }{\partial \theta})f =  \frac{\partial f}{\partial r}\frac{\partial r}{\partial x}+\frac{\partial f}{\partial \theta}\frac{\partial \theta}{\partial x},$$
does this serve as sufficient justification for this notation? Further why may we them use such methods algebraically such 
$$\frac{\partial^2}{\partial x^2}=(\frac{\partial r}{\partial x} \frac{\partial }{\partial r} + \frac{\partial \theta}{\partial x} \frac{\partial }{\partial \theta})(\frac{\partial r}{\partial x} \frac{\partial }{\partial r} + \frac{\partial \theta}{\partial x} \frac{\partial }{\partial \theta})$$
and expanding keeping in mind left and right multiplication (composition!) may not be commutative?","['differential-operators', 'derivatives', 'analysis']"
299598,Combinatorial argument for the identity $k\binom{n}{k} = n\binom{n-1}{k-1}$,"I am looking for the combinatorial argument for the identity: \begin{equation}
k\binom{n}{k} = n\binom{n-1}{k-1}
\end{equation} This is easy to show algebraically as: \begin{equation}
\binom{n}{k} = \dfrac{n(n-1)(n-2)(n-k+1)}{k(k-1)!}
\end{equation} What is the combinatorial argument? What are some general ideas to get started? Here is a clarification of 2. From what I have seen so far, proving (combinatorially) an identity with an addition sign usually implies that we need to partition a set (this makes sense because of the addition rule and provides a nice visual). On the contrary, the previous observation leads me to believe that multiplication in identities can be resolved with the multiplication principle, but what is the ""visual/interpretation"" for this? Could someone provide such an interpretation for the example identity given above?","['binomial-coefficients', 'combinatorics']"
299604,For infinite series convergence/divergence: Why doesnt meeting the conditions of the Divergence test imply the Cauchy Convergence Critierion,"Assume that the limit of the sequence is zero, $\lim_{n\to\infty}a_n=0$. So its not plainly obvious if the series $\sum a_n$ converges or diverges. I have wondered for some time.  If $\lim_{n\to\infty}a_n=0$ then it must be the case that $\lim_{n\to\infty}a_{n+1}=0$ and $\lim_{n\to\infty}a_{n+2}=0$ and so on. Does it not make sense then that
$\lim_{n\to\infty}a_n + a_{n+1} + a_{n+2}=0$ Cauchy's Convergence test basically says this, does it not?
$$\lim_{\substack{m\to\infty\\n\to\infty} }\sum_{k=m}^{m+n}a_k = 0$$ I realize that Cauchy's Convergence Criterion is a necessary and sufficient condition for convergence and divergence, while the Divergence test is just necessary for convergence.  That said, I am wondering why .  Why doesnt meeting the divergence test imply meeting Cauchy's convergence criterion?","['divergent-series', 'convergence-divergence', 'sequences-and-series']"
299616,Compute $\lim\limits_{n\to\infty} \left[\ln\left(\frac{1}{0!}+\frac{1}{1!}+\cdots+\frac{1}{n!}\right)\right]^n$,"Compute
$$\lim_{n\to\infty} \left[\ln\left(\frac{1}{0!}+\frac{1}{1!}+\cdots+\frac{1}{n!}\right)\right]^n$$
If you have some nice proofs and you're willing to share them, then I thank you and you definitely  have my upvote!","['sequences-and-series', 'calculus', 'real-analysis', 'limits']"
299626,"The Center of $\operatorname{GL}(n,k)$","The given question: Let $k$ be a ﬁeld and $n \in \mathbb{N}$. Show that the centre of $\operatorname{GL}(n, k)$ is $\lbrace\lambda I\mid λ ∈ k^∗\rbrace$. I have spent a while trying to prove this and have succeeded if $ k \subseteq \mathbb{R}$. So I imagine there is a nicer way to go about this. I have seen people saying take matrices where every element except one is zero in proving similar results but such matrices are not in $\operatorname{GL}(n,k)$ as they are not invertible. What I have done. I have said let $B \in$ Center then $B$ commutes with everything in $\operatorname{GL}(n,k)$. So take a permutation matrix, $P$ which swaps rows $i,j$ $P \neq I$. From this you can deduce that $B^T = B$ and that $B_{ii} = B_{jj}$. We can use the fact that $B$ is symmetric to find an orthogonal diagonalisation of $B$ by the spectral theorem. This gives $QBQ^T = D \rightarrow B=D$. And as $B_{ii} = B_{jj}$ we can say $B = k * I$. But the spectral theorem requires $B$ to be a real matrix. How do I prove this for a general $k$?.","['abstract-algebra', 'matrices', 'linear-algebra', 'group-theory', 'linear-groups']"
299640,$AB-BA$ is a nilpotent matrix if it commutes with $A$,"I saw this in a MathOverflow post and am putting it here for posterity. Problem: Let $A$ and $B$ be square matrices and set $C=AB-BA$ . If $AC=CA$ , prove $C$ is nilpotent.","['matrices', 'linear-algebra']"
299646,Expression as a product of disjoint cycles,"Let $\alpha = (9312)(496)(37215) \in S_n, n \ge 9$. Express $\alpha$ as a product of disjoint cycles. I know this is probably a really easy question, but my professor didn't elaborate on how to exactly do this and neither does my assigned text. If anyone could elaborate on the algorithm of going about this I would really appreciate it. Thanks you","['permutations', 'abstract-algebra', 'finite-groups', 'symmetric-groups', 'permutation-cycles']"
299651,Square matrices satisfying certain relations must have dimension divisible by $3$,"I saw this tucked away in a MathOverflow comment and am asking this question to preserve (and advertise?) it. It's a nice problem! Problem: Suppose $A$ and $B$ are real $n\times n$ matrices with $A^2+B^2=AB$. If $AB-BA$ is invertible, prove $n$ is a multiple of $3$.","['matrices', 'linear-algebra', 'contest-math']"
299652,"Let the matrix $A=[a_{ij}]_{n×n}$ be defined by $a_{ij}=\gcd(i,j )$. How prove that $A$ is invertible, and compute $\det(A)$?","Let $A=[a_{ij}]_{n×n}$ be the matrix defined by letting $a_{ij}$ be the rational number such that $$a_{ij}=\gcd(i,j ).$$ How prove that $A$ is invertible, and compute $\det(A)$? thanks in advance","['matrices', 'linear-algebra', 'contest-math', 'determinant']"
299658,Combinatorial reasoning for linear binomial identity,"I have the following equation: \begin{equation}
m^4 = Z{m\choose 4}+Y{m\choose 3}+X{m\choose 2}+W{m\choose 1}
\end{equation} I iteratively took $m=1$ to $m=4$ to solve for the coefficients. I got the following values: $Z=24$, $Y=36$, $X=14$ and $W=1$. I then checked the equation with $m=5$ and ""verified"" the identity. However, what is the interpretation of these values? I am looking for a combinatorial argument of this equation. What do the values of W, X, Y, and Z mean here? I do not see any similarities/patterns between W, X, Y, and Z. What is the combinatorially interpretation of these values Is there a better way to look at this problem or enumerate? What else can I try? All help is greatly appreciated!","['binomial-coefficients', 'combinatorics']"
299667,Irreducibility of $x^2+x+4\in {\Bbb Z}_p[x]$ over ${\Bbb Z}_p$?,The following is an exercise in abstract algebra. Show that $x^2+x+4$ is irreducible over ${\Bbb Z}_{11}$. One test all the elements in ${\Bbb Z}_{11}$ to show that $x^2+x+4$ has no zeros in ${\Bbb Z}_{11}$. Here is my question : Can one know the irreducibility of $x^2+x+4\in{\Bbb Z}_p[x]$ for the general field ${\Bbb Z}_p$ where $p$ is prime?,"['ring-theory', 'abstract-algebra']"
299669,Total variation,"I cannot decide if the next function has bounded variation:
in the segment $(0,1)$ $$f(x)=\begin{cases}
\frac{1}{m^{2} n^{2}},&\text{if $x$ is rational}\\\\
0,&\text{otherwise}.
\end{cases}$$
the rational $x$ is $m/n$ and it is the reduced form. so far  showed  it is not absolute continuous thanks","['lebesgue-integral', 'measure-theory']"
299671,Fibonacci numbers that are powers?,"The Fibonacci sequence is: $$\left(f_n\right) = \left(0,1,1,2,3,5,8,13,21,34,55,89,144,\dots\right)$$
where we start with $0$ and $1$ and each term in the sequence is the sum of the two previous terms. Starting the index at $n=0$, I noticed that $f_0=0$, $f_5=5$, and $f_{12}=144$. Let's just say informally that $0^0=0$ for now. I know this is a controversial issue, but here's a quick argument: the sequence $a_n=0^{1/n}$, converges to $0$ as $n\to\infty$ (and it's obvious that $\frac{1}{n}\to 0$). So to make the pattern clear, $$f_0=0^0 \qquad f_5=5^1 \qquad f_{12}=12^2$$ There exists an $n_0\in\mathbb{N}$ such that $f_{n_0}=\left(n_0\right)^0$, there exists an $n_1\in\mathbb{N}$ such that $f_{n_1}=\left(n_1\right)^1$, and there exists an $n_2\in\mathbb{N}$ such that $f_{n_2}=\left(n_2\right)^2$. (1) Does there exist an $n_3\in\mathbb{N}$ such that $f_{n_3}=\left(n_3\right)^3$? (2) In general, for all $k\in\mathbb{N}$, does there exist some $n_k\in\mathbb{N}$ such that $f_{n_k}=\left(n_k\right)^k$? (For those of you who don't buy that $0^0=0$, just take $0$ out of $\mathbb{N}$ and start with $f_1 = 1$ and $f_2 = 1$.)","['fibonacci-numbers', 'sequences-and-series', 'number-theory']"
299681,is matrix invertible?,"The characteristic polynomial of a $3\times3$ matrix $A$ is given by $$
\chi_A(x) = x^3 + ax^2 +bx +c
$$ and takes the values $\chi_A(-1) = 4$, $\chi_A(2)=4$ and $\chi_A(-3) = -16$. 
Is $A$ invertible? I got $0$ points at this question on a quiz and I want to understand why. What is the correct way to do this question? Thanks so much.","['matrices', 'linear-algebra']"
299682,"If $p$ is an odd prime, does every Sylow $p$-subgroup contain an element not in any other Sylow $p$-subgroup?","Suppose that $p$ is an odd prime. Does every Sylow $p$-subgroup of a finite group contain an element that is not contained in any other Sylow $p$-subgroup? Or does there exist a group $G$ with Sylow $p$-subgroups $P, P_1, \ldots, P_s$ such that $P$ is contained in $P_1 \cup \ldots \cup P_s$? One immediate observation here is that if a Sylow $p$-subgroup contains an element that is not contained in any other Sylow $p$-subgroup, then the same is true for every other Sylow $p$-subgroup since they are conjugate. Hence we only need to check the statement for one Sylow $p$-subgroup. I've tried different approaches to this problem but I don't think I have found out anything useful so far. Some special cases where the statement is true is when there are $\leq p + 1$ Sylow $p$-subgroups, or when the Sylow $p$-subgroups are cyclic. The reason I am assuming that $p$ is odd because there are counterexamples when $p = 2$. One example is given by $\operatorname{PSL}(2,11)$, where every element of a Sylow $2$-subgroup is contained in at least two Sylow $2$-subgroups. Plenty of more examples can be found with GAP, the smallest example seems to be of order $108$. I have checked all groups of order $\leq 1000$ except for those of orders $576$ and $864$. All the examples I've found so far are given by $2$-sylow subgroups.","['finite-groups', 'group-theory', 'abstract-algebra']"
299714,Calculate an integral involving Hermite polynomials,"I have to calculate the integral $$\frac{1}{\sqrt{2^nn!}\sqrt{2^ll!}}\frac{1}{\sqrt{\pi}}\int_{-\infty}^{+\infty}H_n(x)e^{-x^2+kx}H_l(x)\;\mathrm{d}x$$ where $H_n(x)$ is the $n^{th}$ Hermite polynomial and prove that it equals $$\sqrt{\frac{m_<!}{m_>!}}\left(\frac{k}{\sqrt{2}}\right)^{|n-l|}L_{m_<}^{|n-l|}\left(-\frac{k^2}{2}\right)\exp\left(\frac{k^2}{4}\right)$$ where $m_<$ and $m_>$ denote the smaller and the larger respectively of the two indices $n$ and $l$ and where $L_n^m$ are the associated Laguerre polynomials. The last term is $\exp(k^2/4)$, hence I suppose that I begin with $$\frac{1}{\sqrt{2^nn!}\sqrt{2^ll!}}\frac{1}{\sqrt{\pi}}\int_{-\infty}^{+\infty}H_n(x)e^{-x^2+kx-\frac{k^2}{4}}e^{\frac{k^2}{4}}H_l(x)\;\mathrm{d}x$$
$$\frac{1}{\sqrt{2^nn!}\sqrt{2^ll!}}\frac{1}{\sqrt{\pi}}e^{\frac{k^2}{4}}\int_{-\infty}^{+\infty}H_n(x)e^{-(x-\frac{k}{2})^2}H_l(x)\;\mathrm{d}x$$ but here I'm stuck...
Thanks for your help!","['special-functions', 'orthogonal-polynomials', 'calculus', 'integration']"
299735,On the norm of a quotient of a Banach space.,"Let $E$ be a Banach space and $F$ a closed subspace. It is well known that the quotient space $E/F$ is also a Banach space with respect to the norm 
$$
\left\Vert x+F\right\Vert_{E/F}=\inf\{\left\Vert y\right\Vert_E\mid y\in x+F\}.
$$
Unfortunately in a set of lecture notes on (Lie) group representations (material for our study group) the author accidentally used here $\min$ instead of $\inf$. Probably a mostly harmless booboo, because at that point it was only needed to get a Banach space structure on the quotient, and we will probably be concentrating on Hilbert spaces anyway, where the problem does not arise. Namely from Rudin's Functional Analysis I could not find a proof that the minimum should always be attained. Except in the case of a Hilbert space, where an application of parallelogram law (the sum of the squared norms of the two diagonals of a parallelogram equals that of the four sides) allows us to find a Cauchy sequence among a sequence of vectors $(y_n)\subset x+F$ such that 
$$\lim_{n\to\infty}\left\Vert y_n\right\Vert_E=\left\Vert x+F\right\Vert_{E/F}.$$ But anyway, the suspicion was left that the infimum is there for a reason (other than conveniently allowing us to sweep this detail under the rug at that point of the development of theory), so in the interest of serving our study group I had to come up with a specific example, where the minimum is not achieved. It's been 25 years since I really had to exercise the Banach space gland in my brain, so it has shrunk to size of a raisin. Searching this site did help, because I found this question . There we have $E=C([0,1])$, the space of continuous real functions on $[0,1]$ equipped with the sup-norm. If we denote by $\Lambda$ the continuous functional
$$
\Lambda: E\to\mathbb{R},f\mapsto\int_0^{1/2}f-\int_{1/2}^1f
$$
and let $F=\ker\Lambda$, then the answer to the linked question proves that there is no minimum sup-norm function in the coset $\Lambda^{-1}(1)$. So I have a (counter)example, and the main question has evolved to: When can we use minimum in place of infimum in the definition of the quotient space norm? My thinking: It seems to me that the answer is affirmative, if $F$ has a complement, i.e. we can write $E=F\oplus F'$ as a direct sum of two closed subspaces such that the norm on $E$ is
equivalent to the sum of the norms on $F$ and $F'$-components. But the first point also raises the suspicion that the question may be a bit ill-defined (and uninteresting) in the sense that the answer might depend on the choice of the norm $\left\Vert\cdot\right\Vert_E$ among the set of equivalent norms. However, if we, for example, perturb the sup-norm of $C([0,1])$ in the above example by multiplying the functions with a fixed positive definite function before taking the sup-norm, the argument seems to survive, so may be replacing the norm with an equivalent one is irrelevant? So to satisfy my curiosity I also welcome ""your favorite example"" (one with a finite-dimensional $F$ would be nice to see), where we absolutely need the infimum here. Bits about any sufficient or necessary conditions for the minimum to be sufficient or (as a last resort :-) pointers to relevant literature are, of course, also appreciated.","['normed-spaces', 'quotient-spaces', 'functional-analysis', 'banach-spaces']"
299736,Calculate : $\int_1^{\infty} \frac{1}{x} -\sin^{-1} \frac{1}{x}\ \mathrm{d}x $,"Find : $\displaystyle \int_1^{\infty} \frac{1}{x} -\sin^{-1} \frac{1}{x}\ \mathrm{d}x $. I've done some work but I've got stuck, you may try to help me continue or give me another way , in both cases try to give me just hints (not the full solution), Thank you. My  work : setting : $x^{-1}=t$, we get : $\displaystyle \int_{0}^{1} \frac{t-\sin^{-1}t}{t^2}\ \mathrm{d}t$. for $|t|\leq 1 $, we have : $\displaystyle \sin^{-1}t =\sum_{k=0}^{\infty}\frac{(2k)!z^{2k+1}}{4^k (k!)^2(2k+1)}.$ with some simplification : $\displaystyle \int_{0}^{1} \frac{t-\sin^{-1}t}{t^2}\ \mathrm{d}t=-\sum_{k=1}^{\infty} \frac{(2k-1)!}{4^k (k!)^2(2k+1)}$. The first problem is that I don't have any idea how to prove the Taylor series (in the general form ) for $\sin^{-1} t$ and it seem quite complicated, I just have it in my book. The second problem is that I don't know how to evaluate the last sum. I hope you can have an easier solution.","['definite-integrals', 'sequences-and-series', 'integration', 'real-analysis']"
299750,Isomorphism between the group of upper triangular matrix in $\mathbb{F}_3$ and $(‎\mathbb{Z}_{3}‎\times\mathbb{Z}_{3})‎\rtimes\mathbb{Z}_{3}$,"By a‎ ‎well ‎known ‎fact ‎we ‎have: ‎
‎
\begin{equation}
\left\{ \left(\begin{array}{ccc}
1 & a & b\\
0 & 1 & c\\
0 & 0 & 1
\end{array}\right)‎‎\vert‎‎‎a,b,c\in‎\mathbb{F}_{3}\right\} ‎‎\cong(‎\mathbb{Z}_{3}‎\times\mathbb{Z}_{3})‎\rtimes\mathbb{Z}_{3}
\end{equation}
‎
Now I have two questions:‎‎ 1) What is the action of ‎$‎‎‎\mathbb{Z}_3‎‎$‎ on ‎$‎\mathbb{Z}_3 ‎\times \mathbb{Z}_3‎‎$‎?‎‎ 2) Under which isomorphism these two groups are isomorphic?‎ Many thanks.",['group-theory']
299758,Closed formula for linear binomial identity,"I have the following identity: \begin{equation}
m^4 = Z{m\choose 4}+Y{m\choose 3}+X{m\choose 2}+W{m\choose 1}
\end{equation} I solved for the values and learned of the interpretation of W, X, Y, and Z in my last post: Combinatorial reasoning for linear binomial identity Now, I am interested in using the above to find a closed form solution for:
\begin{equation}
\sum\limits_{k=1}^nk^4 \\
\end{equation} I do not see how to get a closed form solution to the above sum. What steps can I take? I especially would like to use the work from my last post . Thanks!","['problem-solving', 'discrete-mathematics', 'binomial-coefficients', 'combinatorics']"
299765,What does the topology on $\operatorname{Spec}(R)$ tells us about $R$?,"Let $R$ be a commutative ring with a unit. $\newcommand{\spec}{\operatorname{Spec}}\spec(R)$ denotes the set of all prime ideals in $R$, and it can be topologized using the Zariski topology. Last year I took a course in commutative algebra, and we had some exercises proving that $\spec(R)$ is always $T_0$, and sometimes is or is not $T_1$. And I had spent a good deal of brain cycles in understanding how convergence looks like in $\spec(\Bbb Z)$ (not because anyone asked, I just wanted to figure this out). We never really went anywhere deeper than a few homework questions about the possible topological structure of $\spec(R)$ and $\spec_\max(R)$. But now I am wondering, what does the topology tell us about $R$? Does the fact that a certain net of ideals converges tells us anything useful? Or are there general constructions in algebra which exploit certain properties of the topology on $\spec(R)$ for one thing or another?","['general-topology', 'commutative-algebra', 'ring-theory']"
299774,Volume form on Hamiltonian level surface,"Assume we have a Hamiltonian system on $(\mathbb{R}^{2n},\omega)$ with Hamiltonian $H = H(q,p)$. In a paper I read, it says, without clarification, that the natural Liouville measure $\mu$ obtained by the volume form $\Omega = \omega \wedge \cdots \wedge \omega $ restricts on the energy level surfaces $N = \left\{(q,p) \in \mathbb{R}^{2n}: H(q,p) = c\right\}$ to $$\iota(F(q,p))\Omega$$ where F(q,p) is a function that satisfies $\omega(X_{H},F(q,p)) = dH(F(q,p)) = 1$ and $\iota(\cdot)$ is the interior product. A possible choice would be $F(q,p) = \frac{grad H}{\|grad H\|}$. Why is this so? Thanks in advance!","['dynamical-systems', 'measure-theory', 'differential-geometry']"
299784,Limit of occupation times for Brownian motion,"Let $B_t$ be a standard Brownian motion on $\mathbb R$ started at $0$. For $A\subset\mathbb R$ Lebesgue measurable, let $\mu_T(A) = \frac{1}{T} m(t \leq T: B_t \in A)$, where $m$ is Lebesgue measure. Then $\mu_T$ is a random measure on $\mathbb R$. Do the random measures $\mu_T$ converge, in any reasonable sense, as $T\rightarrow \infty$? If so, what is the limit measure? I know that the event that $\mu_T \rightarrow \mu$ for some fixed deterministic measure $\mu$ is a tail event (it is in the intersection of the $\sigma$-algebras $\sigma(B_t : t \geq s)$). Therefore its probability is either 0 or 1. Beyond that, however, I do not have any real ideas as to how to approach this.","['probability-theory', 'measure-theory', 'brownian-motion']"
299789,How to show that the unit ball of the dual norm is also polytope?,Assuming a unit ball for the p-norm that is a convex polytope. How can one show that the unit ball of the dual's norm is a convex polytope?,"['vector-spaces', 'matrices', 'normed-spaces', 'linear-algebra', 'polytopes']"
299799,Solve $y'' + 4y = e^{-x^2}$ using Fourier transforms,I need to solve the equation $y'' + 4y = e^{-x^2}$ using Fourier transforms.  I was able to take the Fourier transform of both sides and solve for $\hat y$.  I have $\hat y = \frac{e^{-k^2/4}}{\sqrt{2}(4-k^2)}$.  I presumably need to take the inverse Fourier transform of both sides.  How exactly would I go about doing this?,"['ordinary-differential-equations', 'fourier-analysis']"
299801,Evaluate $\lim_{x\to\infty}\left(1+\frac{\ln x}{f(x)}\right)^{f(x)/x}$,"Let's consider the function $f:\mathbb{R}\rightarrow(0,\infty)$ , with $f(x)\cdot \ln f(x)=e^x$ , $\forall x \in \mathbb{R}$ . Then compute $$\lim_{x\to\infty}\left(1+\frac{\ln x}{f(x)}\right)^{\dfrac{f(x)}{x}}$$ The first solution Since $$f(x)\cdot \ln f(x)=e^x, \forall x \in \mathbb{R}$$ we may easily deduce that $$\lim_{x\to\infty}f(x)=\infty$$ On the other hand $$f^2(x)> f(x)\cdot \ln f(x)=e^x$$ $$f(x)> e^{x/2}$$ and then $$0\le\lim_{x\to\infty} \frac{\ln x}{f(x)}\le\frac{\ln x}{e^{x/2}}\rightarrow 0$$ $$\lim_{x\to\infty} \frac{\ln x}{f(x)}=0$$ $$\lim_{x\to\infty} \displaystyle\frac{e^{x/2}}{x} \le \lim_{x\to\infty} \displaystyle\frac{f(x)}{x}=\infty$$ At this point we recognize that our limit case is $1^{\infty}$ , and have $$\lim_{x\to\infty}\left(1+\frac{\ln x}{f(x)}\right)^{\displaystyle\frac{f(x)}{x}}=\lim_{x\to\infty}e^{\displaystyle \frac{\ln x}{x }}=e^0=1$$ The second solution (from a brilliant friend of mine - - so sorry I missed this way) Let's take log of both sides of the limit $$\ln L = \lim_{x\to\infty} \frac{f(x)}{\ln x} \ln \left(1+\frac{\ln x}{f(x)}\right)\times \lim_{x\to\infty} \frac{\ln x}{x}=1\times 0=0$$ that is simply justified by the fact that $f(x)>>x$ (see $f(x)> e^{x/2}$ ) Question : how would you approach this question? Thank you.","['contest-math', 'calculus', 'real-analysis', 'limits']"
299816,Torsion-free divisible group,"I have some confusion. Let $G$ be a torsion-free divisible abelian group. Then, $G$ is a $\mathbb Q$ -vector space. If $G$ has a finite dimension as a vector space then can we write $G$ as a finite direct sum of copies of $\mathbb Q$ ?","['linear-algebra', 'group-theory']"
299818,Entire function with prescribed values,"I am trying to solve the following problem from Ahlfors' Complex Analysis Chapter 5, Section 2.3: Suppose that $\{a_n\}$ is a sequence of distinct complex numbers such that $a_n\to \infty$ and let $\{c_n\}$ be a sequence of arbitrary complex numbers. Show that there exists an entire function $f(z)$ satisfying $f(a_n)=c_n$. The hint that is in Ahlfors' book is to let $g(z)$ be a function with simple zeros at each $a_n$. Such a function exists by Weierstrass' Theorem. Then, the hint says to look for appropriate $\gamma_n$ such that the following series converges
$$
\sum_1^\infty g(z)\frac{e^{\gamma_n(z-a_n)}}{z-a_n}\frac{c_n}{g'(a_n)}.
$$ I have been playing around with this for a while. I know that I need to find the $\gamma_n$ so that on any compact ball, $|z|\leq R$, the values $$
\left|g(z)\frac{e^{\gamma_n(z-a_n)}}{z-a_n}\frac{c_n}{g'(a_n)}\right|
$$
are bounded by some values $M_n(R)$ so that for each $R>0$, the sum $\sum M_n(R)$ converges. If I can do this then I know that the sum will converge uniformly on compact subsets, and so I know that the sum will be an analytic function, and then it will clearly have the right properties. However, I am having difficulty figuring out what I am supposed to choose for $\gamma_n$. I tried expressing $g$ as a Taylor series around each $a_n$ and then finding some upper bound of the terms in the sum which depended only on $R$, but have had no luck so far. Can anyone provide a hint about how to go about finding such $\gamma_n$?",['complex-analysis']
299826,Explicit conjugacy on 2 linear systems involving flow.,"We need to find an explicit conjugacy between the flows of these 2 systems 1st system $X'$ = $AX$ and second system $Y'$ = $BY$ A = $$\begin{bmatrix} -1 & 1 \\ 0 &2\end{bmatrix}$$ B= $$\begin{bmatrix} 1 & 0 \\ 1 &-2 \end{bmatrix}$$ I have tried by finding the 2 eigen values of both and solving both systems. then applying a Mapping H such that $X(0)$ = $X_{0}$= $(x_{0},y_{0})$ so that $HAX$ = $ BY(h_{1},h_{2})$ we want $Y(0)$ = $Y_{0}$= $(h_{1} x_{0}, h_{2}y_{0})$ my text book has no examples. their should be a capital Theta showing the flow of theta A and Flow of theta B such that their must some mapping $H$ that acts differently on y then x to that they are the same. Any anything welcome especially considering i don't expect you to understand what i am talking about cause i don't. for $X'$ eigenvalues  $a_{1}$=-1 and $a_{2}$=2 and vectors $v_{1}$= <1,0> $v_{2}$= <1,3> for $Y'$ eigenvalues  $b_{1}$=-2 and $b_{2}$=1 and vectors $w_{1}$= <0,1> $w_{2}$= <3,1> we have $C_{a1}$ = $x_{0}$ - $y_{0}/3$ and $C_{a2}$ = $y_{0}/3$ $C_{b1}$ = $y_{0}$ - $x_{0}/3$ and $C_{b2}$ = $x_{0}/3$ $h_{1}$ $C_{a1}$ + $h_{1}$ $C_{a2}$ + $h_{2}$ 3$C_{a2}$ needs to equal
$h_{1}$ $C_{b1}$ + $h_{2}$ [3 $C_{b1}$ + $C_{b1}$] and we need to make the 2 equal by guessing  h1 and h2","['matrices', 'ordinary-differential-equations']"
299841,What is the name of the $\in$ symbol and where does it come from?,"It looks like a lower-case epsilon, but the Wikipedia page on epsilon states that they are not the same. Does this symbol have a typographic identification outside of mathematics? Where did the symbol come from?","['notation', 'math-history', 'elementary-set-theory']"
299854,"For any $n$, $G^\dot{n}$ is a subgroup of $G$. Is $G$ abelian?","Let $G$ be a group such that for each $n$:
$$G^\dot{n}=\{a^n|a\in G\}$$
is a subgroup of $G$. Is $G$ abelian?","['group-theory', 'abelian-groups']"
299874,name this function,"Is there a function that has these properties? Points: $f(1)=\tfrac{1}{2}$ $f(-1)=-\tfrac{1}{2}$ $f(0)=0$ Bounds: $f$ is bounded between $(-1,1)$: $\forall x\in\mathbb{R}: -1 < f(x) < 1$ $\lim_{x\to \infty} f(x)=1$ $\lim_{x\to -\infty} f(x)=-1$ Slopes: $f$ is strictly increasing for all $x\in\mathbb{R}$ and at $x=0$, $f'(x)=1$: $$\frac{d}{dx}f(x)=\begin{cases}0<f'<1&:x<0\\1 &:x=0\\0<f'<1&:x>0 \end{cases}$$ Concavity: $$\frac{d^2}{dx^2}f(x) = \begin{cases}>0 &:x<0\\ 0 &:x=0\\ <0 &:x>0 \end{cases}$$ Smoothness: $f$ is infinitely differentiable and every derivative is continuous (or perhaps uniformly continuous): $$\forall n\in\mathbb{N} : \forall x\in\mathbb{R} : \exists y\in\mathbb{R} : f^{(n)}(x) = y$$ I've tried $\tanh(x)$, $\frac{2}{\pi}\arctan(x)$, $\text{erf}(x)$, and others, but all of them were missing at least one of the properties listed above. Is there one that satisfies ALL those properties? If so, prove it or show an example. Below is a graph (in red) of the type of function I'm looking for. The derivative is in green and the 2nd derivative is in blue. (The function shown is $\arctan x$ so it's not exactly what I'm looking for.)","['calculus', 'functions']"
299882,Is there a simple and a non-simple group with same numbers of elements of each order.,"Are there finite groups $G$ and $H$ such that: $n:=|G|=|H|$. $G$ is simple. $H$ is not simple. for every $d\mid n$, $G$ and $H$ have the same number of elements of order $d$.
?","['finite-groups', 'group-theory', 'simple-groups']"
299917,What are some interesting coding projects (doable in Java) that relates to group theory?,"I would like some ideas of possible programs I can write in Java that involves some computational aspects of group theory.  My only ideas so far is to write a program that computes the product of two elements of $S_n$, but this is too easy.  Any suggestions/ideas will be greatly appreciated.","['computer-science', 'group-theory', 'abstract-algebra']"
299922,Bayes Estimator,"Let $X_{1},...,X_{n}$ be a random sample of size n from the continuous distribution with pdf: $f_{X}(x|\alpha,\beta) = \frac{2*\beta^{\alpha}}{\Gamma(\alpha)}*(\frac{1}{x})^{2*\alpha+1}*\exp({\frac{-\beta}{x^{2}}})*I_{(0,\infty)}(x)$ where $\alpha$ > 0 is fixed and $\beta$ > 0. Assume the prior distribution on $\beta$ has the pdf: $\pi(\beta|\lambda) = \lambda*e^{-\lambda*\beta}$ where $\lambda$ > 0 is fixed. Find the Bayes estimator of $\beta$. So to find the Bayes estimator of $\beta$ I know I need to find the posterior distribution, which I did, and I got $\pi(\Theta|X)$ = $e^{\frac{\lambda*\beta*x^{2}-\beta}{x^{2}}*2*\beta^{\alpha}}$ which I am questioning if it is right, especially since I'm not sure my marginal distribution of x is right, either, but I thought that since both $\alpha$ and $\lambda$ were fixed, then I could treat them like constants, but I wasn't sure what I need to replace in the joint to make sure that it integrated to 1 so then it just 'disappeared' because it integrated to 1. Also, to find the Bayes estimator I also know that I need to take the conditional expected value of the posterior distribution, but when I'm not sure if my posterior is correct, I didn't want to start that. Any help would be greatly appreciated!","['statistics', 'estimation', 'bayesian', 'probability-theory']"
299929,Proving the unboundedness of a particular real-valued sequence.,"Proposition Suppose that $ (x_{n})_{n \in \mathbb{N}} $ is a sequence in $ \mathbb{R} $ such that
  $$
\forall m,n \in \mathbb{N}: \quad m > n ~~ \Longrightarrow ~~ |x_{m} - x_{n}| > \frac{1}{n}.
$$
  Then $ (x_{n})_{n \in \mathbb{N}} $ is unbounded. I can somehow show that $ \displaystyle \text{Diam} \left( \{ x_{n} \}_{n=1}^{N} \right) > \sum_{n=1}^{N} \frac{1}{n} $ for all $ N \in \mathbb{N} $, but the details are messy. Might there be a slicker proof? Thank you very much!","['sequences-and-series', 'real-analysis']"
299934,Prove that a group $G$ is not cyclic if and only if $G$ is a union of proper subgroups.,Can anyone please help me prove this question? Question: So first we can assume that $G$ is not cyclic. Then we need to show that $G$ is a union of proper subgroups. How can I do this?,"['cyclic-groups', 'group-theory']"
299938,Countable Sequence of Events,"My Question: Let $(\Omega,\mathcal{F},\textbf{P})$ be a probability triple such that $\Omega$ is ${countable}$. Prove that it is impossible for there to exist a sequence $A_1,A_2,\ldots \in \mathcal{F}$ which is ${independent}$ such that $\textbf{P}(A_i)=\frac{1}{2}$ for each $i$. Hint: First prove that for each $\omega\in \Omega$, and for each $n\in \mathbb{N}$ we have $P(\{\omega\})\leq \frac{1}{2^n}$. Then derive a contradiction. My Work: Let $\omega \in \Omega$ be arbitrary. Then since $\textbf{P}(\Omega)=\textbf{P}(\bigcup \{\omega\})=1$, and $(\Omega,\mathcal{F},\textbf{P})$ is a valid probability triple, then $\textbf{P}$ is countably additive, so that $\textbf{P}(\bigcup \{\omega\})=\sum\limits_{n=1}^\infty \textbf{P}(A_n)$. Here I am not sure where to go. 
My problem: I am really not seeing how to go about this problem. Any help is appreciated.","['measure-theory', 'probability']"
299959,How do I write a vector as a linear combination of other vectors.,"Write $\begin{pmatrix} 5  \\ 3 \\15 \end{pmatrix}$ as a linerar combination of the following vectors:  $u=\begin{pmatrix} 1  \\ 2 \\5 \end{pmatrix}$, $v=\begin{pmatrix} 3  \\ -4 \\-1 \end{pmatrix}$, $w=\begin{pmatrix} -1  \\ 1 \\1 \end{pmatrix}$. My attempt: $$\begin{bmatrix}
1 & 3& -1 & 5\\
2 & -4 & 1& 3\\
5&-1&1&15\\
 \end{bmatrix}\sim\to\begin{bmatrix}
1 & 0& 0 & 3\\
0 & 1 & 0 & 1\\
0&0&1&1\\
\end{bmatrix}$$ Obviously I skipped a lot of reduction steps, because it's a pain to type matrices here, but I was wondering if I even did the right thing.","['matrices', 'linear-algebra']"
299969,Help with combinatorial proof of binomial identity: $\sum\limits_{k=1}^nk^2{n\choose k}^2 = n^2{2n-2\choose n-1}$,"Consider the following identity: \begin{equation}
\sum\limits_{k=1}^nk^2{n\choose k}^2 = n^2{2n-2\choose n-1}
\end{equation} Consider the set $S$ of size $2n-2$. We partition $S$ into two sets $A$ and $B$, each of size $n-1$. Now, we further partition $S$ into $n$ parts: $C_0, C_1, \ldots C_{n-1}$ By the addition principle we have ${2n-2\choose n-1} = \sum\limits_{k=0}^{n-1}C_k$ Additionally, each $C_k$ is given by ${n-1\choose k}{n-1\choose n-1-k}={n-1\choose k}^2$ since $k$ of the elements will be in $A$ and $n-1-k$ elements will be in $B$. Thus we have:
\begin{align}
\sum\limits_{k=0}^{n-1}{n-1\choose k}^2 =&{2n-2\choose n-1} 
\end{align}
Reindexing:
\begin{equation}
\sum\limits_{k=1}^{n}{n-1\choose k-1}^2 = {2n-2\choose n-1} 
\end{equation} Here is where I am lost. I cannot think of a combinatorial argument for the $n^2$ and what remains on the left. If you have better ideas skip this! My first thought is the following: \begin{equation}
\sum\limits_{k=1}^{n}n{n-1\choose k-1}^2 = n{2n-2\choose n-1}
\end{equation}
This is counting the same thing, but what is $n$? The reason I do this is because now all I need is a $k$ in the sum on the LHS: \begin{equation}
\sum\limits_{k=1}^{n}kn{n-1\choose k-1}^2 = \sum\limits_{k=1}^{n}k^2\dfrac{n}{k}{n-1\choose k-1}^2 = \sum\limits_{k=1}^{n}k^2{n\choose k}^2
\end{equation} And somehow this is equivalent to the RHS $n^2{2n-2\choose n-1}$ Again though, what is the combinatorial argument? Thanks for all the help!","['combinatorial-proofs', 'discrete-mathematics', 'binomial-coefficients', 'combinatorics']"
300013,"A integral from ""irresistible integrals""","Evaluate :
$$\int_0^1\frac{x}{(1-x+x^2)^2}\ln \ln \frac{1}{x}\text{d}x$$
The answer on the book is 
$$-\frac{\gamma}{3}-\frac13\ln\frac{6\sqrt{3}}{\pi}+\frac{\pi\sqrt{3}}{27}\left(5\ln 2\pi-6\ln \Gamma\left(\frac16\right)\right)$$
Could anyone show a proof?
Refers to chapter 12 of the book pg237.","['sequences-and-series', 'calculus', 'integration', 'real-analysis']"
300019,"Complex Integration of $\int_0^\infty e^{-ax}\cos(bx)\,dx$","Out of Stein's book, we're asked to show find a formula for $$\int_0^\infty e^{-ax}\cos(bx)\,dx,\quad a>0.$$While this is very doable via integration by parts, I'm asked to use contour integration, where we're suggested to integrate over a sector with angle $\omega$ such that $\cos(\omega)=a/\sqrt{a^2+b^2}.$ I've attempted this multiple times, and I keep having trouble with some integrals. I've set the contour up so that on the first segment, it's on the real axis, so we have the integral $$\int_0^R e^{-az}\cos(bz)\,dz.$$ Then I parameterize the arc as $z(\theta)=Re^{i\theta}$ for $0\leq\theta\leq \omega$, so the second integral becomes $$\int_0^\omega e^{-a(Re^{i\theta})}\cos(b(Re^{i\theta}))\left(iRe^{i\theta}\right)\,d\theta.$$The final segment I parameterized as $z(t)=Re^{i\omega}(1-t)$ and set up the final integral as $$\int_0^1e^{-a(Re^{i\omega}(1-t))}\cos\big(b(Re^{i\omega}(1-t))\big)(-Re^{i\omega})\,dt.$$I've tried finding some way to bound one of the last two integrals so that I can show one of them goes to $0$ as $R\to\infty$, but I've not had any luck. Will someone make a suggestion if my approach and parameterizations are correct? Thanks! Update : My thoughts are really that the integral which goes to zero is the arc. I keep working it down in the following way; we know that it is 
\begin{align}
&\leq R\int_0^\omega\left|e^{-aR(\cos\theta+i\sin\theta)}\cdot\left(\frac{e^{ibRe^{i\theta}}+e^{-ibRe^{i\theta}}}{2}\right)\right|\,d\theta\\
&\leq\frac{R}{2}\int_0^\omega\left|e^{-aR\cos\theta}\cdot\left(e^{ibR(\cos\theta+i\sin\theta)}+e^{-bR(\cos\theta+i\sin\theta)}\right)\right|\,d\theta\\
&\leq\frac{R}{2}\int_0^\omega\left|e^{-aR\cos\theta-bR\sin\theta}\right|+\left|e^{-aR\cos\theta+bR\sin\theta}\right|\,d\theta.
\end{align}
At this point, it is easy to show that the first term tends to zero, since $(-aR\cos\theta)<0$ and $bR\sin\theta>0$ (since $b$ and $\sin\theta$ have the same sign). The second term, however is what causes me trouble. I just finished working it out again, and I get that it only goes to zero if $a^2>b^2$, which isn't necessary in the general formula when achieved by integration by parts. I am really at a loss... Added Solution : See the solution I've posted and please leave comments on your thoughts about it. Thanks!",['complex-analysis']
300024,Formal Definition of the Divergence of a Vector Field,"I recently completed an introductory course on multivariate calculus, and I'm still trying to come to grips with the concepts taught in the vector calculus segment. Right now, I'm reviewing the concept of divergence. I understand the lexical definition of divergence, that (in $\mathbb{R}^3$ at least) it's the volumetric density of the outward flux of a vector field. The formulaic definition that Wikipedia and Wolfram offer makes similar sense:
$$\mathrm{div}\,\mathbf{F}=\lim_{V \to 0}{\iint_S{\frac{\mathbf{F}\cdot\mathbf{n}}{V}dS}}$$ What I don't understand, however, is how 
$\mathrm{div}\,\mathbf{F}=\nabla\cdot\mathbf{F}$ follows from the above statement. Something like $\mathrm{div}\,\mathbf{F}=|\nabla\mathbf{F}|$ seems to make more sense to me, because $\mathrm{div}\,\mathbf{F}=\nabla\cdot\mathbf{F}$ just adds up the partials in what are essentially three random directions ($\mathbf{i},\,\mathbf{j},\mathbf{k}$, after all, are the conventional basis vectors for $\mathbb{R}^3$), whereas $\mathrm{div}\,\mathbf{F}=|\nabla\mathbf{F}|$ isn't as... arbitrary? I suppose. In short: how do you proceed from the formal definition of divergence as the limit of flux over volume as volume goes to zero to getting that divergence is equal to the dot product of nabla and the vector field?",['multivariable-calculus']
300026,Number of Permutations with $k$-inversions and with a single clamped value,"Let $S_n$ be the symmetric group. Recall that the number of inversions of a permutation $\sigma\in S_n$ is the number of ordered pairs $i<j$ with $\sigma(i)>\sigma(j)$. Now, call the number of permutations with $k$-inversions $I_n(k)$. It's easy to see that going from $n-1$ to $n$ we can insert $n$ into spot $j$ to add $n-j$ inversions: $$I_n(k)=I_{n-1}(k)+I_{n-1}(k-1)+\ldots +I_{n-1}(0).$$ If we let $G_n(t)=\sum_{k=0}^{\binom{n}{2}}I_n(k)t^k$, then the above gives $G_n(t)=(1+t+t^2\ldots+t^{n-1})G_{n-1}(t)$, and it quickly follows that $G_n(t)=\prod_{j=1}^n\frac{1-x^j}{1-x}$. I am interested in something more complicated. Let $I^{\sigma(y)=x}_n(k)$ count the number of permutations $\sigma$ of length $n$ such that for a given (fixed) $x,y$ we have $\sigma(y)=x$. In other words I am forcing $y$ to be in bin $x$. Proceeding by similar lines to the above, I get: \begin{eqnarray*}
I_n^{\sigma(y)=x}(k)&=&\ \ \ \ I_{n-1}^{\sigma(y)=x}(k)+I_{n-1}^{\sigma(y)=x}(k-1)+\ldots+I_{n-1}^{\sigma(y)=x}(n-y)\\
&&+I_{n-1}^{\sigma(y-1)=x}(k-y+2)+I_{n-1}^{\sigma(y-1)=x}(k-y+1)+\ldots+I_{n-1}^{\sigma(y-1)=x}(0)
\end{eqnarray*} where similar logic was used as before, except now we have to be careful whether we are inserting $n$ to the right/left respectively (inserting to the left shifts $x$ up one bin). Before going on, I was hoping to confirm that the above is exactly
  correct with no fudges in indices. Assuming the above is right, is it at all tractable to derive
  an asymptotic formula for $I_n^{\sigma(y)=x}(k)$, as $n\rightarrow\infty$? As far as I understand, the way to derive asymptotics for $I_n(k)$, one needs something akin to the Knuth-Netto Formula: $$I_{n}(k)=\binom{n+k-1}{k}+\sum_{j=1}^\infty (-1)^j\binom{n+k-u_j-j-1}{k-u_j-j}+\sum_{j=1}^\infty(-1)^j\binom{n+k-u_j-1}{k-u_j},$$ where the $u_j=3(3j-1)/2$ are pentagonal numbers. The above can be ""simplified"" using Stirling's approximation and a bunch of careful arithmetic to give asymptotics. Here is a reference for such a calculation. Naively, the above formula comes from the Euler pentagonal number theorem . I would think one needs a specialized form of this theorem for what I am interested in. Can such a similar asymptotic feat be accomplished for $I_n^{\sigma(y)=x}(k)$?","['permutations', 'generating-functions', 'combinatorics']"
300041,Set of rational numbers and its interior and closure,"for the set of rational numbers, what would be its interior? And what is its interior's closure? If one says that a set's closure has empty interior, what does it mean? So it means that all elements of a set are limit points? By ""limit points"", how are they exactly defined? Can't real number be also limit point?",['general-topology']
300061,A log improper integral,"Evaluate :
$$\int_0^{\frac{\pi}{2}}\ln ^2\left(\cos ^2x\right)\text{d}x$$
I found it can be simplified to
$$\int_0^{\frac{\pi}{2}}4\ln ^2\left(\cos x\right)\text{d}x$$
I found the exact value in the table of integrals:
$$2\pi\left(\ln ^22+\frac{\pi ^2}{12}\right)$$
Anyone knows how to evaluate this?","['sequences-and-series', 'fourier-analysis', 'calculus', 'integration', 'real-analysis']"
300074,How to calculate this limit ? $\lim_{n\to\infty}\sum_{k=1}^{2n}(-1)^k\left(\frac{k}{2n}\right)^{100}$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question How to calculate this limit? $$\lim_{n\to\infty}\sum_{k=1}^{2n}(-1)^k\left(\frac{k}{2n}\right)^{100}$$
use integration  but difficult/",['limits']
300081,How to find the exact value of $ \cos(36^\circ) $? [duplicate],"This question already has answers here : Exact value for $\cos 36°$ (8 answers) Closed 5 years ago . The problem reads as follows: Noting that $t=\frac{\pi}{5}$ satisfies $3t=\pi-2t$, find the exact value of 
  $$\cos(36^\circ)$$ it says that you may find useful the following identities:
$$\cos^2 t+\sin^2 t = 1,\\
\sin 2t = 2\sin t\cos t,\\
\sin 3t = 3\sin t - 4\sin^3 t.
$$ Do I have to do a system of linear equations in function of ..what? $t$? $\cos$? Thanks in advance :)",['trigonometry']
300113,What About The Converse of Lagrange's Theorem?,"Given a positive integer $n$, a group $G$ of order $n$, and a divisor $d$ of $n$, in what cases can we be assured of the existence of a subgroup $H$ of $G$ of order $d$? What's the situation in the case of the symmetric group on $m$ letters or for the alternating group? What's the most general statement in each case?","['finite-groups', 'group-theory', 'abstract-algebra']"
300122,"For $n >1$,let $\displaystyle f(n)$ be the number of $n \times n$ real matrices $A$ such that $A^2+I=0.$","I came across the following problem that says: For $n >1$,let $\displaystyle f(n)$ be the number of $n \times n$ real matrices $A$ such that $A^2+I=0.$ Then which of the following options is correct? $1.\displaystyle f(n) \equiv 0$ $2.\displaystyle f(n) \equiv \infty$ $3.\displaystyle f(n)=0$ iff $n$ is even $4.\displaystyle f(n)=0$ iff $n$ is odd. Can someone throw light on it?  Thanks in advance for your time.","['matrices', 'linear-algebra']"
300134,An entire function with finite covering group is a polynomial.,"Let $f$ be an entire function. Think of it as a covering space of $\mathbb{C}$ (perhaps with isolated punctures) to $\mathbb{C}$ (perhaps with isolated punctures). Suppose we know there is only a finite number of covering transformations, $\{\varphi\}_{i=1}^n$:
$$ f(\varphi_i(z)) = f(z).$$
How to show $f$ is a polynomial ? Partial answer: The function $\frac{f(z)-f(w)}{z-w}$ is entire in both variables. It is only zero when $z=\varphi_i(w)$ for some $i$, so we may write 
$$\frac{f(z)-f(w)}{z-w} = e^{g(z,w)} \prod_{i=1}^n (z-\varphi_i(w)).$$
Now setting $w=0$, and denoting $w_i = \varphi_i(0)$, we obtain:
$$\frac{f(z)-f(0)}{z} = e^{g(z,0)} \prod_{i=1}^n (z-w_i)=$$
$$ e^{g(z,0)} (z^n - (\sum w_i) z^{n-1} + \ldots + (-1)^n \prod w_i). $$
To show this is a polynomial amounts to showing $g(z,0)$ is a constant.","['covering-spaces', 'complex-analysis']"
300135,2013th derivative of a trigonometric function,"Take the function $f(x) = \sin(2x) \cdot \cos(x)$ Find the 2013 th derivative What I have found so far: $f''(x)= -4\sin(x) \cdot \cos(2x) - 5f(x)$ I am assuming I need to find a relationship such as the above in order to just apply it again and again, however I can't seem to do so. Any help is appreciated. Thank You. ============================= EDIT: @Ihsan and Babak Utilising this result, results in: $f''(x) = -8\sin(3x) - f(x) $ And I'm not sure how to make recur this 1006 times!","['trigonometry', 'calculus']"
300145,What exactly are eigen-things?,"Wikipedia defines an eigenvector like this: An eigenvector of a square matrix is a non-zero vector that, when multiplied by the matrix, yields a vector that differs from the original vector at most by a multiplicative scalar. So basically in layman language: An eigenvector is a vector that when you multiply it by a square matrix, you get the same vector or the same vector multiplied by a scalar. There are a lot of terms which are related to this like eigenspaces and eigenvalues and eigenbases and such, which I don't quite understand, in fact, I don't understand at all. Can someone give an explanation connecting these terms? So that it is clear what they are and why they are related.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
300154,example of morphism of affine schemes,"Let $X={\rm Spec}~k[x,y,t]/<yt-x^2>$ and let $Y={\rm Spec}~ k[t]$.
Let $f:X \rightarrow Y$ be the morphism determined by $k[t] \rightarrow k[x,y,t]/<yt-x^2>$. Is f surjective> If f is surjective, why??",['algebraic-geometry']
300165,Flat torsionfree connection in Kähler manifold,"If $\nabla$ is a flat torsionfree connection and $J$ is a complex structure, we define
\begin{align}
d^{\nabla}J(X,Y)=(\nabla_{X}J)Y-(\nabla_{Y}J)X.
\end{align}
Why flatness of $\nabla$ means $d^{\nabla}=0$, and $\nabla$ is torsionfree means $(d^{\nabla })^{2}(\mathrm{id})=0$?","['complex-geometry', 'connections', 'differential-geometry', 'kahler-manifolds']"
300173,Is $\mathbb{R}^\omega$ in the uniform topology connected?,"Let $\mathbb R^\omega$ be the set of all (infinite) sequences of real numbers. Then is this space connected in the uniform topology? How to determine this? The uniform metric $p \colon \mathbb R^\omega \times  \mathbb R^\omega \to \mathbb R$ is defined as follows: $$p((x_n),(y_n)) := \sup_{n\in\mathbb Z^+} \min\{|x_n-y_n|,1\}$$ for sequences $(x_n)$ , $(y_n)$ of real numbers.","['general-topology', 'connectedness', 'metric-spaces', 'analysis']"
300201,Easy to state high-dimensional consequences of Bezout theorem,"A classical consequence of Bezout's theorem for plane curves is Pascal's theorem . I am curious if there are some other statements that you find pretty that can be formulated (almost) as elementarily as Pascal's theorem and proven using higher dimensional Bezout's theorem? For example, is there some statement that involves quadrics, planes and lines (cubics?...)? I ask this question since I want to finish to teach my (introductory) course in algebraic geometry by higher-dimensional Bezout theorem (using Hilbert polynomials, ect), and I would be extremely happy to give some pretty application :)
(to give you an idea of the level of the course, the course is very close to some bits of Harris book ""algebraic geometry first course"", and covers some bits of it)",['algebraic-geometry']
300208,lim inf $|a_n|=0 \implies \sum_{k=1}^\infty a_{n_k}$ converges,Let $(a_n)_{n\in\mathbb{N}}$ be a sequence such that lim inf $|a_n|=0$. Prove that there is a subsequence $(a_{n_{k}})_{k\in\mathbb{N}}$ such that $\sum_{k=1}^\infty a_{n_k}$ converges. I'm thought about showing that you can make a subsequence that is smaller then $1/n^2$. Is this the right strategy ? Any hints ? Should I use the Cauchy criterion ?,"['sequences-and-series', 'real-analysis', 'limsup-and-liminf']"
300228,Rubik Cube finite non-abelian group,"I was reading the following paper from MIT: http://web.mit.edu/sp.268/www/rubik.pdf The paper is not difficult to understand, it is more or less a short introduction into group theory, taking the Rubik's Cube as an example of a finite, non-abelian group. My question: How can I use this fact to find possible ways for solving the cube, if you know what I mean? There are several ways for solving the cube, which seem to me more intuitive rather than a direct result of the group properties. So if somebody would ask you ""It is nice that Rubik's Cube can be seen as an example of a finite group, but what can I do with this knowledge? "", what would you answer?","['rubiks-cube', 'finite-groups', 'group-theory', 'abstract-algebra']"
300240,Is my answer to this combinatorics question correct? Counting the number of functions where $F(a) = F(b)$?,"Let $A = \{a, b, c, d, e, f\}$ and $B = \{1, 2, 3, 4, 5\}$. How many functions $F$ from $A$ to $B$ are there such that $F(a) = F(b)$. I looked at it like this: If $F(a)$ and $F(b)$ are equal, that means a and b must map to the same value in $B$. So that basically means they're considered one entity, and $A = \{ab, c, d, e, f\}$ so the new size is $5$. Matching, there would be $5$ choices for $ab$, $5$ choices for $c$, for $d$, for $e$, for $f$, so $5^5$ is the answer. Is that right? (Also, why is it not $6^5$? For a function, could it not match with none of them? Would $c$ not have the option of matching with $1, 2, 3, 4, 5$ or none of them ($6$ options)?)","['statistics', 'permutations', 'discrete-mathematics', 'combinatorics']"
300243,Does the series $\sum\limits_{n=1}^\infty \frac{1}{n\sqrt[n]{n}}$ converge?,"Does the following series converge? $$\sum_{n=1}^\infty \frac{1}{n\sqrt[n]{n}}$$ As $$\frac{1}{n\sqrt[n]{n}}=\frac{1}{n^{1+\frac{1}{n}}},$$
I was thinking that you may consider this as a p-series with $p>1$. But I'm not sure if this is correct, as with p-series, p is a fixed number, right ? On the other hand, $1+\frac{1}{n}>1$ for all $n$. Any hints ?","['sequences-and-series', 'real-analysis']"
300250,Is it a continuous function on $\mathbb{R}^{2}$?,"Prove or disprove: let $f : \mathbb{R}^{2} \to \mathbb{R}$ be a mapping with the following properties: for each $y \in \mathbb{R}$ the function $x\mapsto f\left(x,y\right)$ is continuous on $\mathbb{R}$, and for each $x\in\mathbb{R}$ the function $y\mapsto f\left(x,y\right)$ is continuous on $\mathbb{R}$. Then $f$ is continuous on $\mathbb{R}^{2}$. My intuition says it's not true, but I can't think of a simple counterexample.","['multivariable-calculus', 'calculus', 'continuity']"
300276,When is a $*$-homomorphism between multiplier algebras strictly continuous?,"The strict topology on the multiplier algebra $M(A)$ of a C*-algebra $A$ is that generated by the seminorms $$ x\mapsto \| ax \|\qquad x\mapsto\| xa \| \qquad (x\in M(A), a\in A) $$ Whereas a $*$-homomorphism $\phi : M(A)\to M(B)$ between two multiplier algebras is necessarily norm-continuous, if I understand things correctly it will not always be continuous with respect to the strict topologies on either side. Does anyone have a good reference for this? On the other hand an easily-proven theorem states that $\phi$ is strictly continuous if the image of $\phi$ contains $B$.  This is not necessary, however; take $\phi : \mathcal{B}(\ell^2)\to \mathcal{B}(\ell^2)$ to be the map $x\mapsto sxs^*$ where $s$ is the unilateral shift.  This is strictly continuous even though its image doesn't contain $\mathcal{K}(\ell^2)$. Are there other conditions which guarantee $\phi$ to be strictly continuous? I'm particularly interested in the case where $\phi$ maps $A$ into $B$, and both are nonunital.  Is this enough to show that $\phi$ is strictly continuous?","['general-topology', 'operator-algebras', 'functional-analysis']"
300281,"Let $m \in \mathbb{Z^+} , n \in \mathbb{Z^+}$ and let $d=\gcd(m,n)$. Prove that $m\mathbb{Z}+n\mathbb{Z}=d\mathbb{Z}$","Let $m \in \mathbb{Z^+} , n \in \mathbb{Z^+}$ and let $d=\gcd(m,n)$. Prove that 
$$
m\mathbb{Z}+n\mathbb{Z}=d\mathbb{Z}.
$$ 
My attempt is use inclusion to show. Let $a \in m\mathbb{Z}+n\mathbb{Z}$. Then we have $a=ms+nt$. Since $d=\gcd(m,n)$, by Bézout's Lemma, we have $d=ms+nt$ for some integers $s$, $n$. Hence, we have $a=ms+nt=d \in d\mathbb{Z}$. Let $a \in d \mathbb{Z}$. Then we have $a=db=msb+ntb \in m\mathbb{Z}+n\mathbb{Z}$. Is my proof valid? Remark: the following is the part 2 of the question. Prove that $m\mathbb{Z}\cap n\mathbb{Z}=\frac{mn}{d}\mathbb{Z}$. This one I have no idea how to start","['elementary-number-theory', 'abstract-algebra', 'gcd-and-lcm']"
300282,Another improper integral,"Show that :
$$\int_0^1\frac{(\sin ^{-1}x)^2}{x}\text{d}x=\frac{\pi ^2\ln 2}{4}-\frac78\zeta(3)$$
This integral is in ""irresistible integrals"" on page 122. I can't prove this one.","['sequences-and-series', 'riemann-zeta', 'calculus', 'integration', 'real-analysis']"
300290,Divisor class group on blowup of nodal surface,"All varieties will be over $\mathbb{C}$ and projective unless stated otherwise. In Beauville - complex algebraic surfaces, the following is described: Let $S$ be a smooth surface and $p \in S$ a point. Let $\epsilon: \tilde S \rightarrow S$ be the blowup at $p$ and $E$ the resulting exceptional curve. Then
$$
\text{Pic}(\tilde S) \cong \epsilon^* \text{Pic}(S) \oplus \mathbb{Z} E
$$
With $\text{Pic}$ i mean either the group of invertible sheaves or those of Cartier divisors modulo equivalence. Question 1: I was wondering about the situation when $p$ is a simple double singularity, a node, instead of being smooth and the rest of $S$ is smooth. Does the same formula hold? If not, is there is a similar formula that describes $\text{Pic}(S)$ as a direct summand of $\text{Pic}(\tilde S)$? Question 2: Does anybody know a reference for this situation: relationship of Picard groups of singular surfaces (or varieties in general) with their smoothification? My guess and thoughts so far: My first guess was that the same would hold, but i think that is false. The question is treated locally in Hartshorne example 6.5.2, which examines 
$$
\text{Spec}(\mathbb{C}[x,y,z]/(xy - z^2))
$$
The Weil class group of this affine variety is $\mathbb{Z}/2\mathbb{Z}$ and is generated by a ruling of the cone. This ruling is not a Cartier divisor and the cartier divisor class group is trivial. This makes me conjecture:
\begin{align*}
\text{WCl}(\tilde S) &\cong \epsilon^* \text{Wcl}(S) \oplus \mathbb{Z} E\\
\text{Pic}(\tilde S) &\cong \epsilon^* \text{Pic}(S) \oplus \mathbb{Z} R \oplus \mathbb{Z} E
\end{align*}
where $R$ corresponds to a ruling of the cone, which was a weil divisor on the singular variety but after the blowup corresponds to a Cartier divisor as well. $\text{WCl}$ means the group of Weil divsors modulo equivalence. This is just an intuitive guess coming from Hartshorne's example so please please correct me if i'm wrong. Thanks!","['blowup', 'complex-geometry', 'algebraic-geometry', 'reference-request', 'surfaces']"
300291,Let $\{E_k\}^{\infty}_{k=1}$ be a countable disjoint collection of measurable sets. Prove that for any set A...,"Let $\{E_k\}^{\infty}_{k=1}$ be a countable disjoint collection of measurable sets. Prove that for any set A, $m^*(A \cap \cup^{\infty}_{k=1})$ = $\sum^{\infty}_{k=1} m^*(A\cap E_k)$ My answer: I tried to prove this by induction: We know that if k=1, $m^*(A \cap E) = m^*(A \cap E)$. So now if we assume that for some n, $m^*(A \cap \cup^{n}_{k=1})$ = $\sum^{n}_{k=1} m^*(A\cap E_k)$. Now we have to prove that it is true for n+1.  $m^*(A \cap \cup^{n+1}_{k=1}) \leq m^*((A \cap \cup^{n}_{k=1} E_k) + m^*(A \cap E_{n+1})$ So now I have to prove the reverse inclusion, right?...But I'm kind of stuck here...","['measure-theory', 'real-analysis']"
300299,Evaluating $\sqrt{1 + \sqrt{2 + \sqrt{4 + \sqrt{8 + \ldots}}}}$,"Inspired by Ramanujan's problem and solution of $\sqrt{1 + 2\sqrt{1 + 3\sqrt{1 + \ldots}}}$, I decided to attempt evaluating the infinite radical
$$
\sqrt{1 + \sqrt{2 + \sqrt{4 + \sqrt{8 + \ldots}}}}
$$
Taking a cue from Ramanujan's solution method, I defined a function $f(x)$ such that
$$
f(x) = \sqrt{2^x + \sqrt{2^{x+1} + \sqrt{2^{x+2} + \sqrt{2^{x+3} + \ldots}}}}
$$
We can see that
$$\begin{align}
f(0) &= \sqrt{2^0 + \sqrt{2^1 + \sqrt{2^2 + \sqrt{2^3 + \ldots}}}} \\
&= \sqrt{1 + \sqrt{2 + \sqrt{4 + \sqrt{8 + \ldots}}}}
\end{align}$$
And we begin solving by
$$\begin{align}
f(x) &= \sqrt{2^x + \sqrt{2^{x+1} + \sqrt{2^{x+2} + \sqrt{2^{x+3} + \ldots}}}} \\
f(x)^2 &= 2^x + \sqrt{2^{x+1} + \sqrt{2^{x+2} + \sqrt{2^{x+3} + \ldots}}} \\
&= 2^x + f(x + 1) \\
f(x + 1) &= f(x)^2 - 2^x
\end{align}$$
At this point I find myself stuck, as I have little experience with recurrence relations. How would this recurrence relation be solved? Would the method extend easily to
$$\begin{align}
f_n(x) &= \sqrt{n^x + \sqrt{n^{x+1} + \sqrt{n^{x+2} + \sqrt{n^{x+3} + \ldots}}}} \\
f_n(x)^2 &= n^x + f_n(x + 1)~\text ?
\end{align}$$","['nested-radicals', 'recurrence-relations', 'algebra-precalculus', 'real-analysis']"
300315,Motivation behind the definition of Zariski tangent space,"Intuitively, I think of tangent space at a point as the set of all points lying in the tangent plane passing through that point. Here is the definition of the Zariski tangent space: Let $X$ be an algebraic variety and $p \in X$ .
The tangent space of $X$ at point $p$ is defined as $$T_pX= \operatorname{Der}_k(O_{X,p},k).$$ How does the above definition match with my intuition?
Or more specifically,
can someone give a one-one correspondence between $T_pX$ and the set of all points lying in the tangent plane passing through $p$ ?","['commutative-algebra', 'algebraic-geometry', 'differential-geometry']"
300318,What's the optimal strategy of this dice game?,"I'm working on a dynamic programming problem. I want to find the optimal strategy and simulate it. The game's description: The player rolls two dice. If the numbers shown by the two dice are different then the player will add the sum given ($2+3$ for example) to the cumulative rewards he has. If the numbers shown by the two dice are equal then the player will loose all his reward. I started modeling the problem. The state of the system is as follow: 
I chose one random number (300 for example) that may be the maximum reward for $N$ rounds game. The state is $V_k(S,D)$ where $S$ is the cumulative sum and $D$ is the sum of the two numbers shown on the two dice. If we suppose that the numbers of rounds is finite, what will be the optimal strategy in a simple form? In the case of infinite game what's the mean of the reward? Reference : http://people.brandeis.edu/~igusa/Math56aS08/Math56a_S08_notes041.pdf Thank you in advance guys :)","['dice', 'dynamic-programming', 'probability']"
300328,How to evaluate $\xi(0)$?,"How do I evaluate $\xi(0)$ for the Riemann xi function? I know $\xi(0) = \xi(1)$ and $\xi(0) = \tfrac{1}{2} \cdot 0 \cdot (-1) \cdot \Gamma(0) \cdot \zeta(0)$ $\xi(1) = \tfrac{1}{2} \cdot 1 \cdot 0 \cdot \Gamma(\tfrac{1}{2}) \cdot \zeta(1)$ and $\zeta(0) = -\frac{1}{2}$, $\Gamma(\tfrac{1}{2}) = \sqrt{2\pi}$ but $\Gamma(0) = \infty$ and $\zeta(1) = \infty$ so I don't know how to evaluate it.","['riemann-zeta', 'complex-analysis']"
300329,Reduction of algebraic groups,"Let $G$ be an algebraic group over $\mathbb{Z}_p$ embedded in $GL_n$. Let's say that $G$ is a family of equation $f \in \mathbb{Z}_p[(X_{i,j})_{i,j}]$ such that the set of invertible matrices satisfying the equations form a subgroup. Is the natural projection $G(\mathbb{Z}_p) \rightarrow G(\mathbb{F}_p)$ surjective ? If not, is there a criterion ? For example it is true for $G=GL_n$ and $SL_n$. Note that $GL_n(\mathbb{Z}) \rightarrow GL_n(\mathbb{Z}/ N \mathbb{Z})$ is not surjective. For $G=Sp_n$, $O_n$, $SO_n$... I don't know.","['algebraic-groups', 'group-theory']"
300347,Definition(s) of Stack,"I've started to learn about stacks, and a question arose in my attempts of looking at the very definition of a stack by several points of view. First, I recall some background and fix the notation (which is a mix of Fantechi's Stacks for everybody , Edidin's Notes on the construction of the moduli space space of curves , and my personal notation: I'm sorry about that). Let $\mathfrak S:=\underline S:=Sch/S$ be the ""base"" category of schemes over a fixed scheme $S$, and let $Gpd$ be the category of groupoids.
We say that a groupoid fibration $\pi:\mathfrak X\to \mathfrak S$ is a stack if two things happen: $(i)$ every descent datum is effective, and $(ii)$ isomorphisms are a sheaf for $\mathfrak X$ (with respect to the étale topology). (It may help rephrase $(ii)$ as follows: for every $S$-scheme $B$ and for every two objects $X,Y$ in the fiber $\mathfrak X_B$, the presheaf $\mathcal I_B^{X,Y}:\underline B\to \textrm{Sets}$ is a sheaf on the (big) étale site associated to $B$. Here $\mathcal I_B^{X,Y}$ takes a $B$-scheme $f:B'\to B$ to the set of isomorphisms $f^\ast X\cong f^\ast Y$ in $\mathfrak X_{B'}$.) My question : can we say that to give a stack is the same as to give a sheaf of groupoids $\mathcal F:\mathfrak S\to Gpd$ on the étale site associated to $S$? My attempts . I'll sketch how I began to prove that the answer is yes , and convince myself that the answer is no . First, given $\mathcal F$, we construct a groupoid fibration $\pi:\mathfrak X\to\mathfrak S$ fiberwise, by attaching $\mathfrak X_B:=\mathcal F(B)$ over $B\in\mathfrak S$. We then need to check $(i)$ and $(ii)$. Ok, let us stop here for the moment. Conversely, if we have $\pi$, we may define $\mathcal F$ by $\mathcal F(B):=\mathfrak X_B$ on objects and by $\mathcal F(f:B'\to B)=(f^\ast:\mathfrak X_B\to\mathfrak X_{B'})$ on arrows. This seems to be natural. Let us stop here. In both directions, there is a problem: I have to use (or prove) exactness of the sequence
$$
\mathcal F(B)\to\prod_i\mathcal F(B_i)\rightrightarrows \prod_{i,j}\mathcal F(B_i\times_BB_j),
$$
for $\{B_i\to B\}$ a covering of $B$. But does exactness make sense in $Gpd$? For instance, is $Gpd$ abelian? Also, it seems to me that $(i)$ has nothing to do with the sheaf condition: I feel like $(i)$ doesn't help me to prove anything when it is assumed, and cannot be proven when starting with $\mathcal F$. Any correction/insight is welcome. Thank you!","['sheaf-theory', 'algebraic-geometry']"
300351,De Rham cohomology of $\mathbb R^3$ without lines and a circumference,"I am trying to calculate De Rham cohomology of the following spaces: $X=\mathbb R^3\setminus r$ where $r$ is a line; $Y=\mathbb R^3\setminus (r \cup \gamma)$ where $r$ is a line and $\gamma$ is a circumference which concatenates the line; $Z=\mathbb R^3\setminus (r_1 \cup r_2 \cup \gamma )$ where $r_1,r_2$ are disjoint lines and $\gamma$ is a circumference which concatenates only $r_1$. Well, about (1) I do not have many doubts: we observe $X$ has $\mathbb R^2 \setminus \{0\}$ as deformation retract hence - by homotopy invariance - we have that $H^{\bullet}(X) \cong H^{\bullet}(\mathbb S^1)$. Is it correct? Now, what about $Y,Z$? I don't know how to start. Are there any ""nice"" deformation retracts? Perhaps, $Y$ retracts on $\mathbb R^2$ minus a point and a circumference, but how can I find the cohomology of this space? The only thing I know are homotopy invariance, Mayer-Vietoris long exact sequence and Kunneth theorem. Thanks in advance.","['homology-cohomology', 'differential-geometry']"
300375,Prove that $\int_a^cf(x)\mathrm{d}x+(c-a)g(c)=\int_c^bg(x)\mathrm{d}x+(b-c)f(c)$,"Let $f$ , $g$ be real continuous functions in $[a,b]$. Prove that there is $c\in(a,b)$ such that $$\int_a^cf(x)\mathrm{d}x+(c-a)g(c)=\int_c^bg(x)\mathrm{d}x+(b-c)f(c)$$ What would you suggest me to do here? Thanks.","['definite-integrals', 'calculus', 'integration', 'real-analysis']"
300376,Is $\overline{D}\subseteq D\circ D$ in a uniform space?,"Suppose $(X,\mathcal{D})$ is a uniform space and $D\in\mathcal{D}$. Is it true that 
$$\overline{D}\subseteq D\circ D,$$? here we use the product topology to define $\overline{D}$.","['general-topology', 'uniform-spaces']"
300377,Partial derivative respect to random variable - How does one compute this?,"CLARIFICATION: If someone could please help me understand the following:  When examining the expected value in this specific situation, how is the distribution of $\theta$ relevant?    What difference would it make whether $\theta$ is $10^{10}$ or $10^{-10}$, $-3$, or normal or not? How does one take a partial derivative with respect to a random variable? For an assignment, I need to find $E_{Y\mid\theta} \left[- \dfrac{\partial^2}{\partial^2\theta} \ln[P(y\mid\theta)] \right]$,  where $Y \sim N(\theta, 1)$  and  $\theta\sim N(0, \delta^2)$, $\delta$ is known And I realized I do not know how to compute $\dfrac{\partial^2}{\partial^2\theta} \ln[P(y\mid\theta)]$ If I treat $\theta$ as a standard variable and take the second partial derivative of $\ln[P(y\mid\theta)]$ I get a value of $-1$.  This does not make sense to me as a correct solution as I would get the same result regardless of $\theta$'s distribution. I am bit confused and any clarification or assistance would be appreciated. Thank you.","['probability-theory', 'stochastic-calculus', 'random-variables', 'derivatives']"
300378,Narrow convergence determining classes of sets,"Notation used: $S$- Seperable metric space $\mathcal{C}_u(S)$- Class of uniformly continuous functions from $S$ into $\mathbb{R}$ $\mathcal{P}(S)$- Space of probability measures on $(S,\mathcal{B}(S))$, where $\mathcal{B}(S)$ is the Borel $\sigma$-algebra on $S$ How do I prove the following statement (any references ?):- There exists a countable subset $\mathcal{C}_0$ of $\mathcal{C}_u(S)$ such that for every sequence $(\nu_n)$ in $\mathcal{P}(S)$
\begin{equation}
\lim\limits_n\int\limits_Sc \ d\nu_n=\int\limits_S c\ d\nu_0, \text{ for every } c\in\mathcal{C}_0
\end{equation}
implies that $\nu_n$ converges narrowly to $\nu_0$ in $S$. In particular, $\mathcal{C}_0$ seperates the points of $\mathcal{P}(S)$.","['general-topology', 'weak-convergence', 'measure-theory', 'probability-theory']"
300379,Prove the determinant of this matrix,"We have an $n\times n$ square matrix $\left(a_{i,j}\right)_{1\leq i\leq n, \ 1\leq j\leq n}$ such that all elements on main diagonal are zero, whereas the other elements are defined as follows: $$a_{i,j}=\begin{cases}
1,&\text{if } i+j \text{ belongs to the Fibonacci numbers,}\\
0,&\text{if } i+j \text{ does not belong to the Fibonacci numbers}.\\
\end{cases}$$ We know that when $n$ is odd, the determinant of this matrix is zero. Now prove that when $n$ is even, the determinant of this matrix is $0$ or $1$ or $-1$. (Use induction or other methods.) Also posted on MO .","['matrices', 'linear-algebra', 'determinant']"
300393,Group tables for a group of four elements.,"I should consider group tables obtained by renaming elements as essentially the same and then show that there are only two essentially different groups of order 4. There seems to be so many different possible group tables for all the different binary operations - which is why I'm confused. I was thinking about using Cayley's table to show their commutativity but I'm really not too sure. Any help please! Edit: After all of your help, I completely understand how to show that there are only two different groups of order four. Thank you. The only thing which I am still unclear of is how to note down the 'other tables' before stating that they are essentially the same as one of the other tables - meaning that there are just two different ones. It's pointless work but I think it's what the question requires. Answer: After a bit of playing around - I've realised that there are four different tables, however, 3 tables are the same as each other, just with different values (the Klein 4 Group with 3 different generators). Hence there are two tables.","['finite-groups', 'group-theory', 'abstract-algebra', 'abelian-groups']"
300398,Closed form expression for the sum of a product of binomials,"I'm wondering if a closed form expression, not involving the hypergeometric function, exists for the following sum $$
\sum_{k=0}^{n}\binom{n}{k}\binom{q-k}{r}
$$ where $q \geq n$, and $n,k,q,r$ are all non-negative integers, and $\binom{0}{r}=1$ if $r$ is $0$, and $0$ otherwise. It's not amenable to a Vandermonde convolution due to $k$ appearing in both the upper and lower indices, and upper negation has not proved useful. I could not find any related identities in Concrete Mathematics or in Henry W. Gould's collected identities involving binomial coefficients. If no closed form exists this information will also be valuable to me. Any hints or suggestions are greatly appreciated.",['combinatorics']
300412,Transform $3^{n} \mod 7 $ to $ n \mod 7$ form,"I want to go from that form $3^{n} \mod 7 $ to something that doesn't use exponent. 
it says, hint : you should use $ n \mod 7$ I listed the values from $3^0 \mod 7 $ to $ 3^{10} $ $$
3^0  \mod 7 = 1\\
3^1  \mod 7 = 3\\
3^2  \mod 7 = 2\\
3^3  \mod 7 = 6\\
3^4  \mod 7 = 4\\
3^5  \mod 7 = 5\\
3^6  \mod 7 = 1\\
3^7  \mod 7 = 3\\
3^8  \mod 7 = 2\\
3^9  \mod 7 = 6\\
3^{10} \mod 7 = 4\\
$$ Then I want to find a way to get to the values with $n \mod 7$ I tryed with $ 3n \mod 7$ , $3 (n-1) \mod 7$ , 
Also tryed with the gcd(a,n)
also tryed with something like $3(n * n) \mod 7$",['discrete-mathematics']
300414,Proof of inequality $e^x + e^{-x} \leq 2e^{x^2}$,"How would I prove that
$$e^x + e^{-x} \leq  2e^{x^2}, \quad  \text{for all real $x$}?$$ I narrowed it down to proving for $x \in (-1,1)$. I observed that for $(0,1)$ and for $(-1,0)$ I may need to use different approximations. I tried using Taylor polynomials and Lagrange remainder but to no avail, would be interested in the solution using a Taylor series or Taylor polynomial if such exists.","['inequality', 'exponential-function', 'algebra-precalculus']"
300418,Is every Artinian module over an Artinian ring finitely generated?,"I know that if $R$ is Artinian, then a f.g. $R$-module is Artinian. Is f.g. a necessary condition?","['commutative-algebra', 'abstract-algebra']"
300424,"How to prove that exists distinct $x_1,x_2 \in(a,b)$ such that $f '(x_1)f '(x_2)=1$?","Assume $f:[a,b]\to[a,b]$ be continuous and differentiable on $(a,b)$ and $f(a)=a$, $f(b)=b$. How to prove that exists distinct $x_1,x_2 \in(a,b)$  such that $f '(x_1)f '(x_2)=1$? Thanks in advance.","['contest-math', 'analysis']"
300435,Is duality an exact functor on Banach spaces or Hilbert spaces?,"Let $V,V',V''$ and $W$ be vector spaces over $k$. Then, it is known that $\operatorname{Hom}(\cdot,V)$ is a contravariant exact functor, i.e. for each exact sequence $0\to V'\to V\to V'' \to 0$, and each $W$, the induced sequence $0\to \operatorname{Hom}(V'',W)\to\operatorname{Hom}(V,W)\to\operatorname{Hom}(V',W)\to 0$ is exact. But what if all spaces involved are Banach spaces (over $\mathbb{C}$ or $\mathbb{R}$) and if we replace $\operatorname{Hom}(\cdot,V)$ by $\operatorname{L}(\cdot,V)$, i.e. the continuous linear maps with domain $V$? Is this functor still exact? What if we restict ourselves even stronger to Hilbert spaces? I'm particularly interested in the specialization of $W=\mathbb{R}$ or $W=\mathbb{C}$, where we get the dual spaces (again, only continuous maps considered in the Banach- or Hilbert case). I'm learning for an exam and the books I've been reading say nothing about it... Thank you!","['banach-spaces', 'abstract-algebra', 'category-theory', 'hilbert-spaces', 'functional-analysis']"
300443,Convergence/Divergence of Sequence defined by a recurrence relation,"Given the following sequence:
$$
 a_{n+1} = a_n(2 - a_n)
$$
for which values $a_1 \in \mathbb{R}$ does this sequence converges or diverges. By trial and error I found that for $a_1 \in (0, 2)$ it converges to $1$, for $a_1 \in \{ 0 , 2 \}$ it converges to $0$ and for all other values it goes to $-\infty$. But how can we prove these facts? If a limit exists then I can show that it must be $1$ or $0$ by the following calculation. It holds
\begin{align*}
 \lim_{n \to \infty} a_{n+1} = \lim_{n\to \infty} a_n(2-a_n)
\end{align*}
So if $\lim_{n\to \infty} a_n = a$, then 
$$
 a = 2a - a^2 \Leftrightarrow a^2 = a \Leftrightarrow a = 1 \lor a = 0.
$$
But how to show that a limit exists when $a_1 \in (0,2)$, and there is no limit when $a_1 < 0$ or $a_1 > 2$?","['limits', 'sequences-and-series', 'analysis']"
