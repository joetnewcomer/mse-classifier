question_id,title,body,tags
557457,Proving the limits of the sum of two functions is equal to the sum of the limits,"I am new to proving in math so I want to know if this informal proof of limits is possible: Theorem: If $\lim_{x \to a}f(x)=A$ and $\lim_{x \to a}g(x) = B$ , then $$\lim_{x \to a}[f(x)+g(x)]=A+B$$ $\lim_{x \to a}[f(x) + g(x)] = A + B$ is the same as $\lim_{x\to a}[(f(x)-A) + (g(x) - B)]=0$ . Also, $$0 \le |(f(x)-A) + (g(x) - B)| \le |f(x)-A| + |g(x) - B|.$$ Since $\lim_{x\to a} f(x)-A=0$ and $\lim_{x\to a}g(x)-B=0$ , we know $$0 \le \lim_{x\to a}|(f(x)-A) + (g(x) - B)| \le 0.$$ So, $\lim_{x\to a}[(f(x)-A) + (g(x) - B)] = 0.\ \square$ If my proof is wrong what is wrong with it and how can I correct it? Also, why is the proof in Apostol II on page 248 of limits correct? Why didn't he use limits ( $\epsilon,\delta$ ) as he did in Apostol I on page 132? Also, why did he assume that the limits A and B are 0 then say that proves it for all cases? This is Apostol's proof(Theorem 8.1) in vector valued functions of vector variables. Is this proof also valid for real valued functions of vector variables(scalar fields) ? Why didn't he use $\epsilon,\delta$ ?","['multivariable-calculus', 'calculus', 'proof-verification', 'alternative-proof', 'limits']"
557467,Second longest prime diagonal in the Ulam spiral?,"Given the Ulam spiral with center $c = 41$ and the numbers in a clockwise direction, we have, $$\begin{array}{cccccc} 
\color{red}{61}&62&63&64&\to\\
60&\color{red}{47}&48&49&50\\
59&46&\color{red}{\small{c=\,}41}&42&51\\
58&45&44&\color{red}{43}&52\\
57&56&55&54&\color{red}{53}&\downarrow\\
\end{array}$$ The main diagonal is defined by Euler's polynomial $F(n) = n^2+n+41$, and yields distinct primes for 40 consecutive $n = 0\,\text{to}\,39$. If we let $c = 3527$ as in this old sci.math post , we get, $$\begin{array}{cccccccc}
\color{blue}{3569}&3570&3571&3572&3573&3574&\to\\ 
3568&\color{red}{3547}&3548&3549&3550&3551&3552\\
3567&3546&\color{red}{3533}&3534&3535&3536&3553\\
3566&3545&3532&\color{red}{\small{c=\,}3527}&3528&3537&3554\\
3565&3544&3531&3530&\color{red}{3529}&3538&3555\\
3564&3543&3542&3541&3540&\color{red}{3539}&3556\\
3563&3562&3561&3560&3559&3558&\color{red}{3557}&\downarrow\\
\end{array}$$ The polynomial is  $G(n) = 4n^2-2n+3527$ and is prime for 23 consecutive $n = -2\,\text{to}\,20$. Its square-free discriminant is $d = -14107$ and has class number $h(d) = 11$. This is the 3rd largest (in absolute value) with that $h(d)$. The blue number, $G(-3)=3569$ is not prime. Question : For $F(n) = n^2+n+p$, the record is held by Euler's polynomial. For the form $G(n) = 4n^2\pm 2n+p$, is there a better one? P.S. Other polynomials such as $F(n) = 6n^2+6n+31$ are prime for $n=0\,\text{to}\,28$, but are not diagonals in the Ulam spiral.","['number-theory', 'quadratics', 'class-field-theory', 'prime-numbers', 'diophantine-equations']"
557475,"$E[X]=1.8$, where $X$ is the total number of successes of 3 trials. What is the largest/smallest $P\{X=3\}$ can be?","Since each trial has the same probability of success, $p$, can you not uniquely solve for $p$? I.e: Let, $X_{i} = 1$ if the $i^{th}$ trial is a success ($0$ otherwise). Then, $X=\sum_{i=1}^{3}X_{i}$, and $E[X]  = E[\sum_{i=1}^{3}X_{i}] = \sum_{i=1}^{3}E[X_{i}] = \sum_{i=1}^{3}p =3p =1.8$ So, $p=0.6$, and $P\{X=3\}=0.6^{3}$ I thought what I did was sound, but the textbook says the answer to (a) is $0.6$ and (b) is $0$. Their reasoning (for (a)) is as follows: However, how can the above be true if all three trials have the same probability of success? That is, how can $P\{X=1\}$ and $P\{X=2\}$ be zero, when $P\{X=3\}$ is nonzero?","['probability', 'expectation']"
557484,"Dual spaces of cartesian products, direct sums and tensor products","For any topological linear space $X$, let $X^*$ denote its dual space of continuous linear functionals. Let $X \times Y$ denote the Cartesian product of two TVS's, and let $X \oplus Y$ denote their direct sum. Is there a characterization of the dual spaces $(X \times Y)^*$ and $(X \oplus Y)^*$ in terms of $X^*$ and $Y^*$? Suppose furthermore that the topologies on $X$ and $Y$ are locally convex. Let $X \otimes_p Y$ denote the projective tensor product, and let $X \otimes_i Y$ denote the injective tensor product (as defined here ). There is a natural map $X \otimes_p Y \to X \otimes_i Y$. Is there a characterization of the dual spaces $(X \otimes_p Y)^*$ and $(X \otimes_i Y)^*$ in terms of $X^*$ and $Y^*$?","['tensor-products', 'functional-analysis']"
557486,theorem of existence and uniqueness for first order linear differential equation,"The theorem of existence and uniqueness is: 
Let $ y'+p(x)y=g(x) $, $ y(x_{0})=y_{0} $ be a first order linear differential equation such that $ p(x) $ and $ g(x) $ are both continuous for $ a<x<b $. Then there is a unique solution that satisfies it. When a differential equation has no solution that satisfies $ y(x_{0})=y_{0} $, what does this mean?? Can the theorem be verified??",['ordinary-differential-equations']
557496,"Continuous bijections between $\mathbb{R}^2$ and $\mathbb{R}^2 \setminus \{(0,0)\}$","It is well-known that $\mathbb{R}^2$ is not homeomorphic to $\mathbb{R}^2 \setminus \{(0,0)\}$. I have two questions. a) Does there exist a continuous bijection $f: \mathbb{R}^2 \to \mathbb{R}^2 \setminus \{(0,0)\}$ ? b) Does there exist a continuous bijection $g: \mathbb{R}^2 \setminus \{(0,0)\} \to \mathbb{R}^2$ ? Thank you very much for your answers in advance!","['general-topology', 'real-analysis']"
557507,"How to find a transformation matrix, given coordinates of two triangles in $R^2$","I am an undergraduate student, and today I was given two triangles, $T_1$ (green) and $T_2$ (blue) in $R^2$: I was then asked to find the transformation matrix transforming $T_1$ to $T_2$. 
What I understand from this is, that I need to find $F$ in the following matrix equation: $T_2 = F \cdot T_1$. where $T_1= \begin{bmatrix}2&6&8\\2&-2&6\end{bmatrix}$ $T_2= \begin{bmatrix}-2&-10&-14\\-2&-4&10\end{bmatrix}$ which are the coordinates of the corners of the triangles. The above matrix equation however, is inconsistent, so how can I find $F$? It has to be a linear mapping, not an affine one. Have tried a lot, any help greatly appreciated!","['matrices', 'linear-algebra']"
557537,$QR$ decomposition of rectangular block matrix,So I am running an iterative algorithm. I have matrix $W$ of dimensions $n\times p$ which is fixed for every iteration and matrix $\sqrt{3\rho} \boldsymbol{I}$ of dimension $p\times p$ where the $\rho$ parameter changes at every iteration. And for every iteration I need to evaluate the QR decomposition of the matrix:   $$\widetilde{W} = \left[\begin{array}{c} W \\ \sqrt{3\rho} \boldsymbol{I} \end{array} \right] $$ which is a matrix of dimension $(n+p)\times p$. Since $W$ is fixed I wondering if there is any easy way to evaluate the QR decomposition of the matrix $\widetilde{W}$ by just looking at the QR decomposition of $W$? I hope to avoid evaluating the QR decomposition wach time for each different $\rho$.,"['matrix-decomposition', 'matrices', 'linear-algebra']"
557543,Is it possible that all subseries converge to irrationals?,"Does there exists a positive decreasing sequence $\{a_i\}$ with $\sum_{i\in\mathbb{N}} a_i$ convergent, such that $\forall I\subset\mathbb{N},\sum_{i\in I}a_i$ is an irrational number? Such an example would give rise to a closed perfect set containing no rationals . I can only do it for infinite $I$ (for example let $a_i=10^{-p_i}$, where $p_i$ is the $i$th prime.), but the set of infinite sums is not closed.",['real-analysis']
557591,Determinants and cofactors?,"My professor gave us this definition for determinants for a $n \times n$ matrix $A$: $$\det(A) = a_{11}C_{11} + a_{12}C_{12} ... + a_{1n}C_{1n} $$ where $C_{1j}$ is the cofactor of $A$ on $a_{ij}$. He also said that this can be generalized to: $$\det(A) = a_{q1}C_{q1} + a_{q2}C_{q2} ... + a_{qn}C_{qn} $$ for any row or column $q$. He didn't give us a proof of the above statement, because he said it was too complicated. Out of curiosity, could someone give me a proof of the above statement? I would appreciate a proof instead of a tip , because of me being completely new to this and the proof being way too advanced for my skills. What I know so far: Row Reduction, Basis ( not change of basis however), Linear Independence, Span, Transformations, Inverses, Subspaces and Dimensions. Please try to keep proofs within my what I know. Thank you.","['matrices', 'linear-algebra', 'determinant']"
557599,Prove that $|f''(\xi)|\geqslant\frac{4|f(a)-f(b)|}{(b-a)^2}$,"Let ${\rm f}:\left[a, b\right]\to\mathbb{R}$ be twice differentiable, and suppose $$\lim_{x\to a^{+}}
\frac{{\rm f}\left(x\right) - {\rm f}\left(a\right)}{x - a}
=
\lim_{x\to b^{-}}\frac{{\rm f}\left(x\right) - {\rm f}\left(b\right)}{x - b}
=0
$$ Show that there exists $\xi \in \left(a, b\right)$ such that
$\displaystyle{%
\left\vert\vphantom{\Large A}\,{\rm f}''\left(\xi\right)\right\vert
\geq
\frac{4\left\vert\vphantom{\Large A}%
\,{\rm f}\left(a\right) - {\rm f}\left(b\right)\right\vert}
{\left(b - a\right)^{2}}}$. I don't know how to start. Any hints ?.","['calculus', 'real-analysis', 'analysis']"
557617,Product of submanifolds is a submanifold,"Suppose that $X_1$ is an $n_1$-dimensional submanifold of $\mathbb{R}^{N_1}$, and $X_2$ is an $n_2$-dimensional submanifold of $\mathbb{R}^{N_2}$. Prove that $X_1\times X_2\subseteq \mathbb{R}^{N_1}\times\mathbb{R}^{N_2}$ is an $(n_1+n_2)$-dimensional submanifold of $\mathbb{R}^{N_1}\times\mathbb{R}^{N_2}$. Suppose $q=(r,s)\in X_1\times X_2$, where $r\in X_1$ and $s\in X_2$. By definition of a submanifold, there exists a neighborhood $V_r\in\mathbb{R}^{N_1}$, and an open subset $U_1\in\mathbb{R}^{n_1}$ and a diffeomorphism $\phi_1:U_1\rightarrow X_1\cap V_r$. Similarly, there exists a neighborhood $V_s\in\mathbb{R}^{N_2}$, and an open subset $U_2\in\mathbb{R}^{n_2}$ and a diffeomorphism $\phi_2:U_2\rightarrow X_2\cap V_s$. (Edited to take user103402's comment into account) Now, I could take the neighborhood $V_r\times V_s\in\mathbb{R}^{N_1}\times\mathbb{R}^{N_2}$ and the open subset $U_1\times U_2\in\mathbb{R}^{n_1}\times\mathbb{R}^{n_2}$. I want to define the map $\phi:U_1\times U_2\rightarrow(X_1\times X_2)\cap (V_r\times V_s)$. Note that  $$(X_1\times X_2)\cap (V_r\times V_s)=(X_1\cap V_r)\times(X_2\cap V_s).$$ So the map $\phi$ is simply given by $\phi(u_1,u_2)=(\phi_1(u_1),\phi_2(u_2))$ for $u_1\in U_1,u_2\in U_2$. Now, why is $\phi$ a diffeomorphism between $U_1\times U_2$ and $(X_1\cap V_r)\times(X_2\cap V_s)$? Even though $\phi_1$ is a diffeomorphism between $U_1$ and $X_1\cap V_r$, and $\phi_2$ is a diffeomorphism between $U_2$ and $X_2\cap V_s$, it does not seem clear to me that $\phi$ should be a diffeomorphism.","['manifolds', 'real-analysis']"
557623,Computing derivative of function between matrices,"Let $M_{k,n}$ be the set of all $k\times n$ matrices, $S_k$ be the set of all symmetric $k\times k$ matrices, and $I_k$ the identity $k\times k$ matrix. Let $\phi:M_{k,n}\rightarrow S_k$ be the map $\phi(A)=AA^t$. Show that $D\phi(A)$ can be identified with the map $M_{k,n}\rightarrow S_k$ with $B\rightarrow BA^t+AB^t$. I don't really understand how to compute the map $D\phi(A)$. Usually when there is a map $f:\mathbb{R}^s\rightarrow\mathbb{R}^t$, I compute the map $Df(x)$ by computing the partial derivatives $\partial f_i/\partial x_j$ for $i=1,\ldots,t$ and $j=1,\ldots,s$. But here we have a map from $M_{k,n}$ to $S_k$. How can we show that $D\phi(A)\cdot B=BA^t+AB^t$?","['matrices', 'derivatives', 'real-analysis']"
557653,Show that $\frac{a+b}{2} \ge \sqrt{ab}$ for $0 \lt a \le b$,"I have to prove that $$\frac{a+b}{2} \ge \sqrt{ab} \quad \text{for} \quad 0 \lt a \le b$$ The main issue I am having is determining when the proof is complete (mind you, this is my first time). So I did the following steps: $$\begin{align}
\frac{a+b}{2} &\ge \sqrt{ab} \\
\left(\frac{a+b}{2}\right)^2 &\ge \left(\sqrt{ab}\right)^2 \\
\frac{a^2+2ab+b^2}{4} &\ge ab \\
a^2+2ab+b^2 &\ge 4ab \\
a^2-2ab+b^2 &\ge 0\\
(a-b)^2 &\ge 0 \\
\end{align}$$ Now this is where I stopped because if I square root each side, I will be left with $a-b \ge 0$ or in other words, $a \ge b$ which doesn't make a whole lot of sense to me. So ultimately the question is: how do I know when I'm done? and is what I did above correct? Thanks!","['inequality', 'algebra-precalculus', 'proof-verification']"
557662,Tangent space for product of submanifolds,"Suppose that $X_1$ is an $n_1$-dimensional submanifold of $\mathbb{R}^{N_1}$, and $X_2$ is an $n_2$-dimensional submanifold of $\mathbb{R}^{N_2}$, and let $X=X_1\times X_2$. Let $p_1\in X_1$ and $p_2\in X_2$. Describe the tangent space $T_pX$ in terms of the tangent spaces $T_{p_1}X_1$ and $T_{p_2}X_2$, where $p=(p_1,p_2)$. By this question we have that $X$ is an $(n_1+n_2)$-dimensional submanifold of $\mathbb{R}^{N_1+N_2}$. By definition of submanifold, for every $p\in X$, there exists an open set $U\in\mathbb{R}^{n_1+n_2}$ and a neighborhood $V_p$ of $p$ in $\mathbb{R}^{N_1+N_2}$ and a diffeomorphism $\phi: U\rightarrow X\cap V_p$. Let $q=\phi^{-1}(p)$. The derivative at $q$ is a map $d\phi_q:T_q\mathbb{R}^n\rightarrow T_p\mathbb{R}^N$. Basically, this takes a point $(q,v)$ to $(p,D\phi(q)v)$. and the tangent space $T_pX$ to $X$ at $p$ is the image of this linear map. So this image consists of all $(p,w)$ where $w=D\phi(q)v$ for some $v\in\mathbb{R}^n$. I am trying to prove that $T_pX=T_{p_1}X_1\oplus T_{p_2}X_2$, but I don't quite see how that will go.","['manifolds', 'real-analysis']"
557680,Map to symmetric matrices is surjective.,"Let $M_{k,n}$ be the set of all $k\times n$ matrices, $S_k$ be the set of all symmetric $k\times k$ matrices, and $I_k$ the identity $k\times k$ matrix. Suppose $A\in M_{k,n}$ is such that $AA^t=I_k$. Let $f:M_{k,n}\rightarrow S_k$ be the map $f(B)=BA^t+AB^t$. Prove that $f$ is onto (surjective). (Note: all matrices have entries in $\mathbb{R}$.) Clearly the matrix $BA^t+AB^t$ is symmetric, since $$(BA^t+AB^t)^t=(BA^t)^t+(AB^t)^t=AB^t+BA^t.$$ We want to show that for every $C\in S_k$, there exists $B\in M_{k,n}$ such that $$C=BA^t+AB^t.$$ How can we do that?","['matrices', 'linear-algebra']"
557686,Convergence of a sequence involving the maximum of i.i.d. Gaussian random variables,"It's well known that, for a sequence of $n$ i.i.d. standard Gaussian random variables $X_1,\ldots,X_n$, where $X_\max=\max(X_1,\ldots,X_n)$, the following convergence result holds: $$P\left(\lim_{n\rightarrow\infty}\frac{X_\max}{\sqrt{2\log n}}=1\right)=1$$ or, $\frac{X_\max}{\sqrt{2\log n}}\rightarrow1$ almost surely (for a proof of this convergence, see Example 4.4.1 in Galambos ""Asymptotic Theory of Extreme Order Statistics""). I am wondering what happens to the following limit: $$L=\lim_{n\rightarrow\infty}\left[\left(\frac{X_\max}{\sqrt{2\log n}}-1\right)f(n)\log(n)\right]$$
where $f(n)=o(1)$. Is $L=0$ or infinite?  Does it depend of $f(n)$?  I am not sure how to deal with the indeterminate form here...","['probability-theory', 'normal-distribution', 'sequences-and-series', 'limits']"
557700,Demonstrating that $f(x) = x^2 + 1$ is bijective and calculating $f \circ f^{-1}(x)$,"I did this exercise. I am not sure if my surjective proof is right - is it good? In fact, I'm not even sure what exactly am I trying to prove (I know that surjective means that each element in the codomain should have a preimage in the domain, but I don't really see how to prove that - I was just mimicking some example I had seen before). Could you give more insight on how to prove a function surjective? The rest of the exercise is here as well, in case I did a related mistake. Let $f:[0,+\infty[ \rightarrow [1,+\infty[$ defined by $$f(x) = x^2 + 1$$ Demonstrate that it is bijective. Injective $$f(a) = f(b)$$ $$a^2+1 = b^2 + 1$$ $$a^2 = b^2$$ Since $a,b >= 0$, it is safe to affirm that $$a = b$$ Surjective $$b = f(a)$$ $$b = a^2 + 1$$ $$b - 1 = a^2$$ $$a = \sqrt{b - 1}$$ Calculate $f^{-1}$ and verify that $f \circ f^{-1}(x) = x$. $$f^{-1}(x) = \sqrt{x - 1}$$ And $$f \circ f^{-1}(x)$$ $$f(f^{-1}(x))$$ $$(\sqrt{x - 1})^2+1$$ $$x - 1 + 1$$ $$x$$","['discrete-mathematics', 'functions']"
557704,In a triangle $\angle A = 2\angle B$ iff $a^2 = b(b+c)$,"Prove that in a triangle $ABC$, $\angle A = \angle 2B$, if and only if: $$a^2 = b(b+c)$$ where $a, b, c$ are the sides opposite to $A, B, C$ respectively. I attacked the problem using the Law of Sines, and tried to prove that if $\angle A$ was indeed equal to $2\angle B$ then the above equation would hold true. Then we can prove the converse of this to complete the proof. From the Law of Sines, $$a = 2R\sin A = 2R\sin (2B) = 4R\sin B\cos B$$ $$b = 2R\sin B$$ $$c = 2R\sin C = 2R\sin(180 - 3B) = 2R\sin(3B) = 2R(\sin B\cos(2B) + \sin(2B)\cos B)$$ $$=2R(\sin B(1 - 2\sin^2 B) +2\sin B\cos^2 B) = 2R(\sin B -2\sin^3 B + 2\sin B(1 - \sin^2B))$$ $$=\boxed{2R(3\sin B - 4\sin^3 B)}$$ Now, $$\implies b(b+c) = 2R\sin B[2R\sin B + 2R(3\sin B - 4\sin^3 B)]$$ $$=4R^2\sin^2 B(1 + 3 - 4\sin^2 B)$$ $$=16R^2\sin^2 B\cos^2 B = a^2$$ Now, to prove the converse: $$c = 2R\sin C = 2R\sin (180 - (A + B)) = 2R\sin(A+B) = 2R\sin A\cos B + 2R\sin B\cos A$$ $$a^2 = b(b+c)$$ $$\implies 4R^2\sin^2 A = 2R\sin B(2R\sin B + 2R\sin A\cos B + 2R\sin B\cos) $$ $$ = 4R^2\sin B(\sin B + \sin A\cos B + \sin B\cos A)$$ I have no idea how to proceed from here. I tried replacing $\sin A$ with $\sqrt{1 - \cos^2 B}$, but that doesn't yield any useful results.","['geometry', 'trigonometry']"
557721,How to solve coupled linear ODE?,"I wan to solve the following ODE's:- 
$$L_1 q''(t)+R_1q'(t)+\frac 1C_1 q(t)-Mq_2''(t)=V\sin(\omega t)$$
$$L_2 q_2''(t)+R_2q_2'(t)+\frac 1C_2 q_2(t)-Mq''(t)=V\sin(\omega t)$$
$L,C,R,V>0$, 
I already know how to solve linear non-homogenous and non-coupled ODE, using the homogenous solution plus the particular solution found by using a trial function. How can I reduce the given equations to non=coupled form so as to
  apply similar methodologies to solve them? I just know the basic methods to solve simple ODE's.
I am comfortable with solving simple coupled ODE such as 
$$y_1'(t)=Ay_2(t)\text{ and } y_2'(t)=B+Cy_1(t)$$
by simple substitution. (The physics tag is added because these equations describe the behaviour of coupled RLC circuit with an application in metal detectors)","['ordinary-differential-equations', 'calculus', 'physics']"
557728,"if $f(\frac{x+y}{2})=\frac{1}{2}[f(x)+f(y)], f(0)=0,f(1)=1$ then$f(\frac{1}{22})=?$","let function $f:[0,1]\to [0,1]$,and such $f(0)=0,f(1)=1$,
and foy any $0\le x\le y\le 1$,then we have
$$f\left(\dfrac{x+y}{2}\right)=\dfrac{1}{2}[f(x)+f(y)]$$ Question 1 Find the value $f(\dfrac{1}{22})$ Qusetion 2 : Find the 
$$f(\dfrac{1}{n})=\dfrac{1}{n}?,n\in N^{+}$$ My try: Now I have solve question 1: since
$$f\left(\dfrac{x+y}{2}\right)=\dfrac{1}{2}[f(x)+f(y)]$$
then let $x=0$,we have
$$f(y)=2f(\dfrac{y}{2})$$
let $f(\dfrac{1}{22})=a$,then
$$f(\dfrac{1}{11})=f(\dfrac{2}{22})=2f(\dfrac{1}{22})=2a,f(\dfrac{2}{11})=4f(\dfrac{1}{22})=4a,f(\dfrac{4}{11})=8f(\dfrac{1}{22})=8a$$
and $$f(\dfrac{8}{11})=16f(\dfrac{1}{22})=16a$$
and note
$$f(\dfrac{6}{11})=f(\dfrac{\dfrac{1}{11}+1}{2})=\dfrac{1}{2}(f(\dfrac{1}{11}+1)=\dfrac{1}{2}(2a+1)$$
and other hand
$$f(\dfrac{6}{11})=f(\dfrac{4}{11}+\dfrac{8}{11}/2)=\dfrac{1}{2}(8a+16a)$$
so
$$\dfrac{1}{2}(8a+16a)=\dfrac{1}{2}(2a+1)\Longrightarrow a=\dfrac{1}{22}$$
so
$$f(\dfrac{1}{22})=\dfrac{1}{22}$$ But question 2,How prove it? Thank you",['functions']
557744,why this puzzle works?,"Think of a positive integer, call it X.  Shuffle the decimal digits of X, call the resulting number Y.  Subtract the smaller of X,Y from the larger, call the difference D.  D has the following property:  Any non-zero decimal digit of D can be determined from the remaining digits.  That is, if you ask someone to hide any one of the non-zero digits in the decimal representation of D, then you can try to impress the other person by figuring out the hidden digit from the remaining digits.  How is this done?  Why does it work?","['puzzle', 'number-theory']"
557758,$\mathcal{C}_1 \subseteq \mathcal{C}_2 \implies \sigma( \mathcal{C}_1) \subseteq \sigma( \mathcal{C}_2) $,"$\mathcal{C}_1$, $\mathcal{C}_2$ are collections of subsets of $X$,then Im having hard time seeing why the  following is true. Can someone explain them to me? $\mathcal{C}_1 \subseteq \mathcal{C}_2 \implies \sigma( \mathcal{C}_1) \subseteq \sigma( \mathcal{C}_2) $ $\sigma(\sigma( \mathcal{C} )) = \sigma( \mathcal{C} ) $ where $\sigma( \mathcal{F} ) $ is the sigma field generated by the collection $\mathcal{F}$ of subsets of $X$ thanks","['measure-theory', 'real-analysis']"
557762,Question on series,Suppose $ a_i $ be a sequence of positive real numbers such that $ \sum_{i=1}^{\infty}a_i < \infty $. Is it true that $ \sum_{i=1}^{\infty} \log(i) \cdot a_i < \infty $? Thanks,"['sequences-and-series', 'analysis']"
557764,Demonstrate that if $f$ is surjective then $X = f(f^{-1}(X))$,"I haven't been able to do this exercise: Let $f: A \rightarrow B$ be any function. $f^{-1}(X)$ is the inverse
  image of $X$. Demonstrate that if $f$ is surjective then $X = f(f^{-1}(X))$ where $X \subseteq B$. Since $X \subseteq B$, all the elements in $X$ belong to the codomain of $f$. Since $f$ is surjective, it means that all elements in the codomain $B$ have some preimage in $A$. Given that $X \subseteq B$, all elements in $X$ must also have a preimage in $A$. Have $\triangle = f^{-1}(X)$, $\triangle$ is now a set containing the preimages of the elements in $X$. Because of this, $\triangle \subseteq A$. If we evaluate $f(\triangle)$, we...... nope, I don't know what I'm doing now. What do you think?","['discrete-mathematics', 'elementary-set-theory', 'functions']"
557792,How to define Surface Laplacian on the sphere with radius 1,"The simbol $\nabla_s f$ appears in a problem of my homework, and my professor thinks it means $$\nabla_s f:= \nabla f - \hat{n}(\hat{n} \cdot \nabla f )$$
or 
$$ \nabla_s := (I - \hat{n}\hat{n}^T )\nabla $$ (the surface gradient of a function defined on a surface), where $f$ is a scalar field and $\hat{n}$ is the normal  surface vector (in this case the sphere of radius 1) My question is, how can I define the ''surface Laplacian operator'' ($\nabla_s^2f$)  from the above definition? I need to find a way to calculate the following integral $$ \int \int_{S^2} (u \nabla_s^2 v +\nabla_su\cdot\nabla_sv)dS$$ and I don't know how to calculate $\nabla_s^2 v $ for a given scalar field $v$ to (defined over the sphere) Thanks for your help!","['multivariable-calculus', 'differential-geometry']"
557815,Homeomorphism between $\{x\in\mathbb{R}^2: 1<\|x\|<2\}$ and $\{x\in\mathbb{R}^2: \|x\|>1\}$,Is $\{x\in\mathbb{R}^2: 1<\|x\|<2\}$ homeomorphic to $\{x\in\mathbb{R}^2: \|x\|>1\}$ ?,"['general-topology', 'real-analysis']"
557826,Is the restriction map of structure sheaf on an irreducible scheme injective?,"Suppose $X$ is an irreducible scheme, $U \subset V$ open subsets of $X$, does it hold that $\rho_U^V:O(V)\to O(U)$ injective? Generally under what conditions does it hold? Actually it is related to an exercise in Liu Qing's book p67,Ex4.11: Let $f：X\to Y $ be a morphism of irreducible schemes, show that the following are equivalent: (2)$f^{\#}:O_Y \to f_*O_X$ is injective (3)for every open subset $V$ of $Y$ and every open subset $U\subset f^{-1}(V)$, the map is injective. to deduce (3) from (2) I had hoped the restriction map should be injective. But now I don't know how to deal with it..",['algebraic-geometry']
557846,If $G$ and $H$ are nonisomorphic group with same order then can we say that $\operatorname{Aut}(G)$ is not isomorphic to $\operatorname{Aut}(H)$?,"We know that nonisomorphic groups may have isomorphic automorphism groups. As an example, you can think klein four group and $S_3$ since their automorphism group is isomorphic to $S_3$. Now,I wonder If  $G$ and $H$ are nonisomorphic group with same order  then can we say that $\operatorname{Aut}(G)$ is not isomorphic to $\operatorname{Aut}(H)$ or can we find two nonisomorphic groups with same order and their
automorphism groups are isomorphic?",['group-theory']
557921,Independence implies constancy,"Given a probability space $(\Omega,\mathcal{F},P)$ on which we define two random variables $X_1$ and $X_2$. From the following two independence conditions $X_1-X_2$ and $X_1$ are independent $X_1-X_2$ and $X_2$ are independent How could we deduce that $X_1 - X_2$ is constant almost surely? I only managed to deal with the case when both $X_1$ and $X_2$ are square integrable: \begin{align}
E[(X_1 -X_2)^2] &= E[(X_1 -X_2)X_1] - E[(X_1 -X_2)X_2] \\ &= E[X_1-X_2]E[X_1] - E[X_1 -X_2]E[X_2] \\&= (E[X_1 -X_2])^2
\end{align} which means the variance of $X_1 -X_2$ is zero, so $X_1 -X_2$ is a constant almost surely. But in general, without assumption of integrability on $X_1$ and $X_2$, how could we prove the conclusion? Or is the conclusion still true?","['probability-theory', 'measure-theory', 'probability']"
557925,Functional equation: $f\left(\frac{x-1}{x}\right)+ f\left(\frac{1}{1-x}\right)= 2- 2x$,"There is a function given $f\left(\dfrac{x-1}{x}\right)+ f\left(\dfrac{1}{1-x}\right)= 2- 2x
,f\colon \Bbb R\setminus\{0,1\}\to \Bbb R$ How many fuction exist? I have no idea how to start","['functions', 'functional-equations']"
557935,Linear connection on a manifold: Math vs. Physics,"I have learned some Riemannian Geometry in a strongly mathematical framework, precisely from the book ""J.M.Lee -  Riemannian Manifolds: An introduction to Curvature"". Now I'm trying to learn Relativity from the Wald's book, but I have many problems to match the Riemannian Geometry notions from the mathematical framework to the physical one. Consider the notion of linear connection: For me a linear connection $\nabla$ is a function
$$\nabla:\mathcal T(M)\times\mathcal T(M)\longrightarrow\mathcal T(M)$$
$$(X,Y)\longmapsto \nabla_XY$$
where $\mathcal T(M)$ is the $C^\infty(M)$-module of sooth vector fields (sections of the tangent bundle). This function $\nabla$ has certain properties that allow to write $\nabla_XY$ in local coordinates. I know that exists an essentially unique way to define a  (Koszul) connection $\overline\nabla$ on an tensor field starting from $\nabla$ and with  the connection $\overline\nabla$ I can define a total covariant derivative for tensor fields. All these reasonings are done  without computations in coordinates, but using strongly the ""Tensor Characterization Lemma"". Wald instead says that a covariant derivative is a way to associate to a tensor field $T\in\mathcal T^{(k,\ell)}(M)$ another tensor field $\nabla T\in T^{(k,\ell+1)}(M)$ written in the index notation as
$$\nabla_c{T^{a_1,\ldots,a_k}}_{b_1,\ldots,b_\ell}$$
such that it satisfies certain conditions. Now even if I understand the abstract index notation (infact I recognize that $\nabla_c{T^{a_1,\ldots,a_k}}_{b_1,\ldots,b_\ell}$ is a $(k,\ell+1)$-tensor) I don't understand how this approach coincides with the above one. Thanks in advance.","['riemannian-geometry', 'differential-geometry']"
557947,What are some strong algebraic number theory PhD programs? [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 9 years ago . Improve this question I am currently applying for PhD programs in the US. My main interests are number theory and algebra. More specifically, I am interested in algebraic number theory (number fields, Galois groups, elliptic curves); but I still don't know enough to make any definite statements. I have done a good amount of research on the different graduate schools, but I am hoping for some advice from people more involved in the field. What are some universities with good graduate programs in mathematics, and in particular algebra and algebraic number theory? Where is the interesting research going on in those fields? I have seen the US News list on best algebra/number theory/algebraic geometry grad schools. And have looked into the research in Princeton, MIT, UC San Diego, Stanford, Berkeley, Brown, University of Chicago. So I was hopping for answers of less known universities, or more information about the known ones which is not easily available.","['number-theory', 'education', 'algebraic-number-theory', 'soft-question', 'advice']"
557975,Solving $\cos x=x$ [duplicate],"This question already has answers here : What is the solution of $\cos(x)=x$? (13 answers) Closed 9 years ago . I would like to know how can we solve the equation $\cos x = x$, without graphing. I know that  there would only be one solution, that is obvious, that too in between $0$  and $\frac{\pi}{2}$. Is there any real expression in finite terms [perhaps we call that closed form, I am not sure] that could give $x$ or $\cos x$. Although I have not studied Taylor series, I know that it only gives an infinite series, which is not what I want. I suspect that it could not be done, but can anyone explain me why? Just for completeness, Wolfram Alpha, gives the approximate answer $x = 0.7390851332151606416553120876738734040134$, but fails to give a exact solution.",['trigonometry']
557976,"Show that $\{1, \sqrt{2}, \sqrt{3}\}$ is linearly independent over $\mathbb{Q}$.","My apologies if this question has been asked before, but a quick search gave no results.  This is not homework, but I would just like a hint please.  The question asks Show that $\{1, \sqrt{2}, \sqrt{3}\}$ is linearly independent over $\mathbb{Q}$. To begin, I consider some linear relation $a + b \sqrt{2} + c \sqrt{3} = 0$, where $a, b, c \in \mathbb{Q}$.  There are several cases to consider. If $c = 0$, then it must be the case that $a = b = 0$, because $\sqrt{2}$ is not rational.  Similarly, if $b = 0$, then $a = c = 0$ because $\sqrt{3}$ is not rational.  If $a = 0$, then we must have that $b = c = 0$ because $\frac{\sqrt{2}}{\sqrt{3}}$ is not rational (because $\sqrt{6}$ is not rational). My issue is drawing a contradiction when $a$, $b$, and $c$ are all nonzero.  It is not always the case that the sum of two irrational numbers is irrational (e.g. $1 - \sqrt{2}$ and $\sqrt{2}$).  Hints or suggestions would be greatly appreciated!","['radicals', 'linear-algebra', 'irrational-numbers', 'rational-numbers']"
557982,Proving combinatorial identity $\sum_s (-1)^s\binom{p+s-1}{s}\binom{2m+2p+s}{2m+1-s}2^s=0$,"I need to prove following combinatorial identities: $$
\sum\limits_s(-1)^s\binom{p+s-1}{s}\binom{2m+2p+s}{2m+1-s}2^s=0
$$ $$
\sum\limits_s(-1)^s\binom{p+s-1}{s}\binom{2m+2p+s-1}{2m-s}2^s=(-1)^m\binom{p+m-1}{m}
$$ given the fact that $$
(1-x)^{2k}\left(1+\frac{2x}{(1-x)^2}\right)^k = (1+x^2)^k
$$ for either $k=p$ or $k=-p$. And for the first one I cannot understand where $\binom{2m+2p+s}{2m+1-s}$ is emerging from (different signs for $s$ on top and bottom seem strange to me). I'm trying to prove first identity as following: if we transform given equation and let $k=p$ we get something like this: $$
(1-x)^{2p}(1+2x+4x^2+\dots)^p=(1+x^2)^p
$$ Let's find coefficient for $x^{2m+1}$ for both sides. For the right side it is always equal to $0$, as only even powers are present there. For the left side let's take $x^s$ from second bracket and $x^{2m+1-s}$ from first. Getting $x^s$ from second bracket is equal to splitting $s$ into $p$ addends with zeroes allowed, so the coefficient is equal to $2^s\binom{p+s-1}{p-1} = 2^s\binom{p+s-1}{s}$. So we get some of needed multipliers for our identity. But now if we take $2m+1-s$ from first bracket we get coefficient like $(-1)^{2m+1-s}\binom{2p}{2m+1-s} = (-1)^s\binom{2p}{2m+1-s}$. And the final result is: $$
\sum\limits_s(-1)^s\binom{p+s-1}{s}\binom{2p}{2m+1-s}2^s=0
$$ And I see no way to transform it to required identity. For the second equality I do not even understand where right side is taken from. Thanks in advance for any help.","['summation', 'binomial-coefficients', 'combinatorics']"
557987,Zeros of complex function sequence (Application of Rouche's Theorem).,"For a given sequence of complex functions: $\phi_n(z)= 1+\frac1n-z-e^{-z}$; here $z\in${$z| Rez>0$}. I want to prove that : (1).
$\phi_n $ has a unique zero $z_n$ in the half plane. (i.e. there exists a unique $z_n$ in half plane {$z| Rez>0$} s.t $\phi_n(z_n)=0)$. [Some how by Rouche's theorem, I almost proved that the function $1+\frac1n-z-e^{-z}$
    has only one zero in half plane {$z| Rez>0$}. But I don't know how to show that $z_n$ is unique s.t. $f_n(z_n)=0$ ] (2).
 And further more, I have to show that $z_n\in \Bbb R$. (3).
 Does $lim_{x\to \infty} z_n$ exist? And If limit exists then what is it? (I don't have any idea about last two parts.) Thanks in advance.","['complex-numbers', 'several-complex-variables', 'complex-analysis', 'analysis']"
557994,What am I doing wrong? Integration and limits,"I need some help identifying what I'm doing wrong here.. What is the limit of $y(x)$ when $x→∞$ if $y$ is given by: $$y(x) = 10 + \int_0^x \frac{22(y(t))^2}{1 + t^2}\,dt$$ What i've done: 1) Integrating on both sides(and using the Fundamental Theorem of Calculus): $$\frac{dy}{dx} = 0 + \frac{22(y(x))^2}{1 + x^2}$$ 2) $$\frac{-1}{22y} = \arctan x$$ And after moving around and stuff I end up with the answer: $\quad\dfrac{-1}{11 \pi}.$ What's wrong?","['calculus', 'integration', 'limits']"
558005,The largest value of $f(n) $,Let us consider a function $ f:\mathbb{N}_0 \to \mathbb{N}_0  $ following the relations: $ f(0)=0$ $f(n) = n+f\left(\left\lfloor \frac{n}{p} \right\rfloor\right)$ when the $n$ is not divisible by $p$ $ f(np) = f(n) $ Here $p>1$ is a positive integer .$ \mathbb{N}_0 $ is the set of all non-negative integers and let $  a_k $ be the maximum value of $ f(n) $ for $ 0<n \leq p^k $ . How can I find the value of $ a_k  ?$,['functions']
558017,How to show that $\frac{\partial}{\partial y}\left(\int_{0}^{y}\frac{1}{x+it-2}dt\right)=\frac{1}{x+iy-2}$,I'm trying to show that $$\frac{\partial}{\partial y}\left(\int_{0}^{y}\frac{1}{x+it-2}dt\right)=\frac{1}{x+iy-2}$$ In an area that doesn't contain the point $2+0i$. If the function under the integral was a real function then it would have been immediate from the Fundamental Theorem but I haven't studied of an equivalent result for a complex function. I need to somehow show this result through a direct computation of some sort. Edit: I would prefer not to use complex logarithms since I'm not really familiar with the subject but I do know it differs quite a bit from the real logarithm. Help would be appreciated.,"['partial-derivative', 'derivatives', 'complex-analysis']"
558028,Limit of product with unbounded sequence $\lim_{n\to\infty} \sqrt{n}(\sqrt[n]{n}-1)=0$ [duplicate],"This question already has answers here : How to prove $\lim_{n \to \infty} \sqrt{n}(\sqrt[n]{n} - 1) = 0$? (4 answers) Closed 7 years ago . I have to show that $\lim_{n\to\infty} \sqrt{n}(\sqrt[n]{n}-1)=0$ We proofed that $\lim_{n\to\infty} \sqrt[n]{n}=1$ My problem is, that I do not know how to solve that. That $\lim_{n\to\infty}(\sqrt[n]{n}-1)=0$ is clear. But $\lim_{n\to\infty} \sqrt{n}$ is not bounded. So I can not simply calculate: $\lim_{n\to\infty}\sqrt{n}\cdot \lim_{n\to\infty}(\sqrt[n]{n}-1)$ right? I would be thankfull for every hint. :-)","['radicals', 'limits']"
558042,Proving that there exists a local minimum between two local maximums of a continuous function,Suppose f is a continuous function that has local maximums at points $x_{1}$ and $x_{2}$. How do I prove that there is a third point between these two points which is a local minimum of f? Need some help thanks.,"['functions', 'real-analysis']"
558043,Independent sequences,"Let $\{x_i\}_{i = 1, ...,n}$ , $\{y_i\}_{i = 1, ...,n}$ be sequences generated by a pseudo-random number generator using different seed keys, for example $ x_0$ and $y_0$. Are $\{x_i\}$ and $\{y_i\}$ independent? If not, under what conditions can I say $\{x_i\}$ and $\{y_i\}$ are independent?","['statistics', 'sequences-and-series', 'probability', 'random']"
558044,$f^*f_*(\mathcal{F})$ is surfective if $\mathcal{F}$ is generated be global sections,"Suppose $\mathcal{F}$ is a sheaf of module on $X$,$f:X\to Y$,suppose $\mathcal{F}$ is generated by global sections. Is $f^*f_*(\mathcal{F})\to \mathcal{F}$ is surjective ? To check on stalks, $f^*f_*(\mathcal{F})_x \cong f_*(\mathcal{F})_{f(x)} \to \mathcal{F}_x$, and it became messy.. And is there counterexample or is this condition necessary?",['algebraic-geometry']
558077,Is there any handwavy argument that shows that $\int_{-\infty}^{\infty} e^{-ikx} dk = 2\pi \delta(x)$?,It should not be a good argument but rather a short one and one that convinces a physicist ( so no need for mathematical rigor ) that shows that $\int_{-\infty}^{\infty} e^{-ikx} dk = 2\pi \delta(x)$ holds? It should only refer to basic calculus (especially no fourier transform ) since I am supposed to give a proof of a related relationship about fourier transforms on a physics homework sheet.,"['fourier-analysis', 'calculus', 'real-analysis', 'analysis', 'functional-analysis']"
558138,Simplest way to determine if a number is a member of the Mandelbrot set?,"I'm writing JavaScript code to plot the Mandelbrot set on an HTML5 Canvas element.  (That's probably not relevant to the answer to this question). A core part of the problem is to write a simple function that returns true if a number is a member of the Mandelbrot set and false otherwise.  Since JavaScript has no complex numbers in its built-in libraries, I simply represent a complex number as a two-element array with the first element being the real part and the second element being the imaginary part. I know that if any iteration of the function z^2 + c returns a value with absolute value greater than two, then z is definitely not a member of the Mandelbrot set.  If no iteration of z^2 + c returns a value greater than two, then z is a member of the Mandelbrot set, but it's impossible to iterate the function to infinity. Therefore, I tried iterating the function 1000 times and assuming that if it takes more than 1000 iterations, the function doesn't diverge to infinity.  This is a disaster.  The plot produced contains many points that are definitely not in the Mandelbrot set by comparison to references on the internet. function isInMandelbrot(z) {
            var i, a;
            a = z;
            for (i = 0; i < 1000; i++) {
                a = helper(a);                    
                if (a[0] > 2 || a[0] < -2 || a[1] > 2 || a[1] < -2)
                    return false;
            }
            return true;

            // Compute z^2 + c
            function helper(a) {
                var raisedToPower, sum;
                raisedToPower = square(a);
                sum = [raisedToPower[0] + z[0], raisedToPower[1] + z[1]];
                return sum;
            }
        }

        function square(z) {
            var rResult, iResult;
            rResult = z[0] * z[0] - z[1] * z[1];
            iResult = 2 * z[0] * z[1];
            return [rResult, iResult];
        } Increasing the limit to 10,000 instead of 1000 produces almost exactly the same plot and takes lots longer.  This makes me wonder if I could be running up against the precision limits of how JavaScript computes calculations.  There's an explanation here: http://www.yuiblog.com/blog/2009/03/10/when-you-cant-count-on-your-numbers/ I think that in order to plot the Mandelbrot set, I need a better way of determining set membership.  How might I do this? The answer should not depend on what language the computation is done in unless floating-point precision is the issue. Edit: I tried rendering the image at 16000*16000 and I noticed a fascinating result: The points outside the Mandelbrot set that are wrongly identified as points inside the Mandelbrot set... clump together into clumps shaped like the Mandelbrot set!  You can't make this stuff up! Edit again: Okay, I think I see what the problem is!  I think that the darkened points are actually in the Mandelbrot set.  I erroneously assumed that they were too far from the main ""blob"" to be part of the set, but after looking at some other plots, I think that there is a connection that is too small to render, as in this plot: http://en.wikipedia.org/wiki/File:Mandel_zoom_01_head_and_shoulder.jpg","['complex-dynamics', 'fractals', 'complex-analysis']"
558153,Conformal map between annulii,Is there any conformal map between $D_1= \lbrace z \in \mathcal{C} \; ; \; 1 \leq |z| \leq 2 \rbrace$ and $D_2 = \lbrace z \in \mathcal{C} \; ; \; 1 \leq |z| \leq 3 \rbrace$. By the Schottky theorem there is not. But I am looking for some other  way. Some hints will be usefull.,['complex-analysis']
559193,Why this two spaces do not homeomorphic?,Consider $\Bbb Q$ with subspace topology and $\Bbb Q\times \Bbb Q$ with product topology. Why this two spaces are not homeomorphic?($\Bbb Q$ is the rational numbers),['general-topology']
559201,chameleon puzzle- modified one,"In one island there are 3 colors of chameleon 12 blue,15 green and 7 red. When two different color’s chameleon meet together , they convert into third color. What is the number of minimum no. of meeting required to convert all chameleon into same color?","['puzzle', 'number-theory']"
560218,Poles of abelian differentials,"Let $X$ be a smooth projective curve of genus $g$ over an algebraically closed field $k$. As a corollary of the Riemann-Roch theorem we know that for every abelian differential $\omega$ on $X$ we have
$$ \deg(\omega) = 2g - 2. $$ Now assume that $g\geq 2$, then $\deg(\omega)\geq 0$.  Does this imply that an arbitrary differential has no poles on the whole $X$?
I guess no: a priori this just means that the number of zeros (with multiplicity) is greater than the number of poles. But anyway, is it always possible to find a function $f\in k(X)$ such that the form $f \omega$ has no poles? Any idea or clarification is welcome!","['differential-forms', 'algebraic-geometry', 'algebraic-curves']"
560228,Solving the differential equation $y'' + 2y' + 2y = 0$ given constraints,"How can I solve this initial value problem? $$ y'' + 2y' + 2y = 0,$$ given $y\,(\pi/4)=2$ and $y'(\pi/4)=0$. I've found $y(t)=e^{-t} \left(C_1\cos t + C_2\sin t \right)$ but I wasn't able to find $C_1$ and $C_2$. How can I find them?","['complex-numbers', 'ordinary-differential-equations']"
560239,Proof of the properties of limits of CDFs,"The cumulative distribution function is defined as $F(a) = \mu((-\infty,a])$ where $\mu$ is a probability measure on $(\mathbb{R},\mathcal{B}(\mathbb{R}))$. Given this definition, it is easy to prove right-continuity (I think). We have also: $$\lim_{a\to -\infty} F(a) = 0$$
$$\lim_{a\to\infty} F(a) = 1$$ By using the above definition, I want to prove these properties. Some people on the web state things like following: Since $(-\infty,a] \to \emptyset$ as $a \to -\infty$, and since $\mu(\emptyset) = 0$, then we are done. Same thing can be written for $a \to \infty$. However, this type of proof makes me feel that something is problematic, i.e., not rigorous albeit intuitively makes sense. What is the rigorous proof of these properties?","['probability-theory', 'measure-theory']"
560293,"If a Banach space $X$ is isometric to its first dual $X^*$, must $X$ be reflexive?","Suppose that $X$ is a Banach space such that there exists a linear isometry $X \rightarrow X^*$. Must $X$ be reflexive? Of course, this implies that $X$ is isometric with its second dual $X^{**}$. But with this alone it is not possible to conclude that $X$ is reflexive, James space is the famous counterexample for this. So a negative answer to my question should be at least as difficult as finding an example like the James space.. so probably not very easy.","['functional-analysis', 'banach-spaces']"
560307,"Prove that $\sqrt{x}$ is continuous on its domain $[0, \infty).$","Prove that the function $\sqrt{x}$ is continuous on its domain $[0,\infty)$ . Proof. Since $\sqrt{0} = 0, $ we consider the function $\sqrt{x}$ on $[a,\infty)$ where $a$ is real number and $a \neq 0.$ Let $\delta=2\sqrt{a}\varepsilon.$ Then, $\forall x \in \mathit{dom},$ and $\left | x-x_0\right | < \delta \Rightarrow \left| \sqrt{x}-\sqrt{x_0}\right| = \left| \frac{x-x_0}{ \sqrt{x}+\sqrt{x_0}} \right| < \left|\frac{\delta}{2\sqrt{a}}\right|=\varepsilon.$ Can I do this?",['real-analysis']
560315,Elementary proof that $\pi < \sqrt{5} + 1$,"I wanted to show that 
$$ \frac{\pi}{4\phi} < \frac{1}{2} $$
Where $\phi$ is the golden ratio. I have confirmed the results numerically, and by
simple algebra the inequality simplifies down to
$$
\pi < \sqrt{5} + 1
$$
This is a weaker relation than what was shown here. Prove that $\dfrac{\pi}{\phi^2}<\dfrac{6}5 $ .
By squaring my inequality (valid since both sides are positive), and dividing by $6$ I obtain. 
$$ \frac{\pi^2}{6} < 1 + \frac{\sqrt{5}}{3} $$
Where the left handside has a very neat series representation, alas the same does not hold for the right handside. However this is far from an elementary solution. Does someone have a relative simple proof for the equality? To be precise something that is not using advanced knowledge of series. =)","['calculus', 'algebra-precalculus']"
560371,"Orbit space of a free, proper G-action principal bundle","Let $G$ be a topological group and let $r \colon E \times G \to E$ be a continuous right-action on a topological space $X$. If $p\colon E \to B$ is a continuous map into a topological space $B$ such that $(p, r)$ is a principal $G$-bundle, then it follows that $B \cong E/G$ where $E/G$ is the orbit space of the action, and that $p$ is essentially the projection map $\pi\colon E \to E/G$. It follows further that the action must be free. I'm interested in the opposite direction, i.e. the question when the projection $E \to E/G$ determines a principal $G$-bundle. In the beginning lines of this article I found the assertion that it is sufficient for the action of $G$ on $E$ to be free (this is obviously necessary) and proper. However, no proof is provided. If $G$ is discrete, then one can show that the action is proper precisely if every $x \in E$ has a neighbourhood $U$ such that $Ua \cap U = \emptyset$ whenever $a \neq 1$, $a \in G$. Indeed, $V := \pi(U)$ is then the sought-after open neighbourhood of $xG \in E/G$ such that $\pi^{-1}(V) \cong V \times G$. It's not difficult to define a suitable $G$-homeomorphism. If $G$ is locally compact, $X$ is Hausdorff, and the action is proper, then there is a similar result, for then every $x \in E$ has a neighbourhood $U$ such that $\{a \in G \mid Ua \cap U \neq \emptyset\}$ is contained in a compact set $K \subset G$. I was wondering if this could be used for a proof. If anyone could help me with other ideas, I'd be very glad to hear them. PS: I edited this post a bit as I didn't want to submit essentially the same question again.","['general-topology', 'principal-bundles', 'group-theory']"
560380,Is there ever a requirement to change the limits of integration?,"I don't have issues with doing integration problems, but occasionally I see the solution changing the limits of integration whenever a $u$-substitution is done. I obviously don't have a problem doing this, and I just recently noticed my book doing this under the chapter involving ""area of surface of revolution."" My question is did I develop a bad habit by never changing the limits of integration, or is it a best practice to always change limits of integration? My teacher said on a test, and in general, if we do not change the limits of integration then we should be signifying this by labeling our limits of integration $x=$ lower-limit and $x=$upper-limit. EDIT EXAMPLE INCLUDED After further investigation, my confusion is because of the two below equations: Find the exact area of the surface obtained by rotating the curve about the x-axis $$y=\sqrt{1+4x}, 1\le x\le 5$$ The limits of integration were changed in the solution to this problem. The given curve is rotated about the y-axis.  Find the area of the resulting surface. $$y=x^\frac{1}{3}, 1\le y \le 2$$ The limits of integration were NOT changed in the solution to this problem.","['calculus', 'integration', 'limits']"
560383,Defining irreducible polynomials recursively: how far can we go?,"Fix $n\in\mathbb N$ and a starting polynomial $p_n=a_0+a_1x+\dots+a_nx^n$ with $a_k\in\mathbb Z\ \forall k$ and $a_n\ne0$. Define $p_{n+1},p_{n+2},\dots$ recursively by $p_r = p_{r-1}+a_rx^r$ such that $a_r\in \mathbb N$ is the smallest such that $p_r$ is irreducible over $\mathbb Q$. It should not be too hard to prove (but how?) that there will always be an $r_0$ such that $a_r=1\ \forall r>r_0$. Let $r_0$ be smallest possible. E.g. for $n=0$ and $p_0\equiv 1$, we have to go as far as $r_0=11$, getting before that $(a_0,\dots,a_{11})=(1,1,1,2,2,3,1,2,1,3,1,2)$. Questions (apart from proving the existence of $r_0$): Is it possible to construct, for a certain $n$, a polynomial $p_n$ such that $a_{n+1}$ is bigger than $3$ or even arbitrarily large? (From the above example, for $n=4$ and $p_n=1+x+x^2+2x^3+2x^4$, we get $a_5=3$, likewise for $n=8$ and $p_n=1+x+x^2+2x^3+2x^4+3x^5+x^6+2x^7+x^8$, we get $a_9=3$.) Is it possible to construct, for a certain $n$, a polynomial $p_n$ such that $r_0-n$ is bigger than $11$? If so, how big can $r_0-n$ be?","['factoring', 'polynomials', 'combinatorics']"
560388,This limit: $\lim_{n \rightarrow \infty} \sqrt [n] {nk \choose n}$.,"I was given as HW to calculate:
$\lim_{n \rightarrow \infty} \sqrt [n] {nk \choose n}$. I tried to use a theorem that says:
if $\lim_{n \rightarrow \infty} \frac{a_{n+1}}{a_n}=L$ then $\lim_{n \rightarrow \infty} \sqrt [n] {a_n}=L$. It's still too complicated. Thank you.","['calculus', 'limits']"
560414,"Question on geometrically reduced, geometrically connected.","I have a question from a book which I am trying to attempt. Let $k$ be a field not of characteristic 2 and let $a\in k$ be not a square (i.e. for all $b\in k$, $b^{2}\neq a$). I want to show that $X=\mbox{Spec}(k[U,T]/(T^{2}-aU^{2}))$ is geometrically reduced and geometrically connected. My attempt is as follows: I am hoping to show that if $\overline{k}$ denotes the algebraic closure of $k$, then $X_{\overline{k}}$ is reduced. Since we have $X_{\overline{k}}=\mbox{Spec}(k[U,T]/(T^{2}-aU^{2})\otimes_{k}\overline{k})=\mbox{Spec}(\overline{k}[U,T]/(T^{2}-aU^{2}))$, and I need to show that this is reduced. To do this, I will have to show that localisation of $A=\overline{k}[U,T]/(T^{2}-aU^{2})$ at any prime ideal is a reduced ring. I was actually hoping to show that $A$ is a reduced ring (since then localisation of a reduced ring is also reduced), but algebraically I am not sure how to do it. I have no idea how to start on proving geometrically connectedness. Glad if someone can give me some hints. Thanks! (Will update this page if I have ideas on proving geometrically connectedness)","['affine-schemes', 'algebraic-geometry', 'schemes']"
560425,"Show that if $a \sim b$, then $C(a) = C(b)$ where $C(x)$ is the equivalence class containing $x$.","I'm working through a textbook on my own, so I don't want the full answer. I'm only looking for a hint on this problem. Show that if $a \sim b$, then $C(a) = C(b)$ where $C(x)$ is the equivalence class containing $x$. I'm reading through Paul Sally's Tools of the Trade , and he gives this problem as an example in a theorem. An equivalence class is defined like this: If $a \in X$, then we write $C(a) = \lbrace b \in X \mid b \sim a \rbrace$. The proof is as ""Transitivity"" and that's it, but I'm not sure how to use transitivity to prove it. Here's what I have so far: Let $a, b \in X$ be arbitrary elements of $X$. If $a \sim b$, then $a \in C(b)$ by definition. But, if $a \sim b$, then $b \sim a$ by symmetry, so $b \in C(a)$. This is where I get stuck. Since $a, b$ are arbitrary elements in $X$, can I just immediately conclude that $C(a) = C(b)$ for any $a,b \in X$ where $a \sim b$. I'm not sure how to use transitivity here.","['self-learning', 'elementary-set-theory', 'equivalence-relations']"
560433,Is $A + A^{-1}$ always invertible?,"Let $A$ be an invertible matrix. Then is $A + A^{-1}$ invertible for any $A$? I have a hunch that it's false, but can't really find a way to prove it. If you give a counterexample, could you please explain how you arrived at the counterexample? Thanks. This isn't HW, and I don't really have any work to show.","['matrices', 'linear-algebra', 'inverse']"
560436,Is my proof correct for: $\sqrt[7]{7!} < \sqrt[8]{8!}$,"I have to show that $$\sqrt[7]{7!} < \sqrt[8]{8!}$$ and I did the following steps \begin{align}
	\sqrt[7]{7!} &< \sqrt[8]{8!} \\
	(7!)^{(1/7)} &< (8!)^{(1/8)} \\
	(7!)^{(1/7)} - (8!)^{(1/8)} &< 0 \\
	(7!)^{(8/56)} - (8!)^{7/56} &< 0 \\
	(8!)^{7/56} \left(\left( \frac{7!}{8!} \right)^{(1/56)} - 1\right) &< 0 \\
	\left(\frac{7!}{8!}\right)^{(1/56)} - 1 &< 0 \\
	\left(\frac{7!}{8!}\right)^{(1/56)} &< 1 \\
	\left(\left(\frac{7!}{8!}\right)^{(1/56)}\right)^{56} &< 1^{56} \\
	\frac{7!}{8!} < 1 \\
	\frac{1}{8} < 1 \\
\end{align} Did I do this properly? Is this way the best way or is there another much easier way? Thanks a bunch!","['alternative-proof', 'algebra-precalculus', 'proof-verification']"
560441,Probability that three randomly chosen points on a circle provides an acute triangle,"In trying to solve the classic problem -- ""Find the probability that three randomly chosen points on a circle provides an acute triangle"" I came across this page that seems to have a good explanation. However, I do not understand how they came up with the probability as 
$\int_{0}^{\pi }{\frac{1}{\pi }\cdot \frac{\theta }{2\pi }\cdot d\theta }$ I understood that the probability is the length of sector of the circle between the two dotted lines divided by the total circumference, but do not see how/why the integral is needed.","['calculus', 'probability']"
560486,Uniform continuity of $f(x) = x \sin{\frac{1}{x}}$ for $x \neq 0$ and $f(0) = 0.$,"For the $f(x) = x \sin{\frac{1}{x}}$ for $x \neq 0$ and $f(0) = 0,$ my text book asks the following questions. (b) Why is $f$ uniformly continuous on any bounded subset of $\mathbb{R}$? (c) Is $f$ uniformly continuous on $\mathbb{R}$?? The graph for the function is this. For the question (b), if I take subset between $[0.2,0.6]$ or the subset where the slope is steep, I don't think the function is uniformly continuous because I think for a given $\epsilon>0$, there is no unique $\delta >0$ for the bounded subset. Therefore, it also cannot be uniformly continuous on $\mathbb{R}.$ However, the questions sounds like the function is uniformly continuous and the book says that it is uniformly continuous. The answer on the book says something but I need more explanation. Thanks.","['real-analysis', 'uniform-continuity']"
560489,Unitary invariance,"Why is it that for any non-negative matrix $M$ and unitary matrix $U$, we have $$\sqrt{UMU^\dagger}=U\sqrt{M}U^\dagger$$? This question has to do with Problem 2c from this sheet . I think I am allowed to assume the ""fact"" but I'd like to know why.","['linear-algebra', 'quantum-mechanics']"
560509,Is the set of rational numbers a vector space?,"Is the set of all rational numbers $\mathbb{Q}$ a vectorspace? I assumed no, because if
$$\vec{x} \in \mathbb{Q}$$ 
$$\pi \vec{x} \notin \mathbb{Q}$$ failing scalar mult closure This was a question out of my linear algebra book, looking at the solutions says that it is a vectorspace. Am I making an incorrect assumption?","['vector-spaces', 'linear-algebra']"
560522,walks on hypercubes,"Let's say I start at the $(0,0,...,0)$ vertex of $n$-dimensional hypercube. After each unit of time $l$, I either stay where I am with probability $p$, or move to an adjacent vertice with probability $q = \frac{1-p}{n}$. What is the probability I end up back where  I started after $l$ units of time? Having difficulty wrapping my head around this question... If $p = 0$, then the answer is simply $$ \frac{1}{2^n n^l}\sum \limits_{i = 0}^{n}\binom{n}{i}(n-2i)^l$$ messing around with $n=2$ I found that for general $p$: $P(0) = 1, P(1) = p, P(2) = p^2 + 2q^2, P(3) = p^3 + 2p^2q + 4pq^2, P(4) = p^3 + 11p^2q^2 + 7q^4$. I'm not seeing any obvious pattern here, and I'm not sure how to proceed to figure out a closed form for general $n$.","['probability', 'combinatorics']"
560537,"If $A^2+A=0$,then $\lambda=1$ cannot be an eigenvalue of A.","Prove the following statement: If $A^2+A=0$ ,then $\lambda=1$ cannot be an eigenvalue of A. I've been struggling on this question for a couple of hours and don't know how to approach it.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors', 'vectors']"
560562,An application of Fubini-Tonelli,"Let $f$ be a nonnegative measurable function which is finite $\mu$ almost everywhere.  Suppose that $\mu(E_t) < \infty$ for all $t>0$, where $E_t = \{x: f(x)>t\}$. Let $\lambda$ be another measure, where $\lambda((a,b]) = \mu(E_a) - \mu(E_b)$ for all $a<b<\infty$.  It is true that $\lambda$ is a Lebesgue-Stieljes measure though it is not necessary to prove (though the proof is straightforward - right continuity follows from continuity from above which is applicable since $\mu(E_t)$ is finite. Prove that $\int f\,d\mu = \int_{(0,\infty)} \mu(E_t)\,dm(t) = \int_{(0,\infty)} t\,d\lambda(t)$. Here $m$ is Lebesgue measure. I was able to successfully prove the first equality in the case where $f$ is a simple function, and unsuccessfully do anything else. I wasn't able to conclude anything about $f$ in general because it's not clear how any convergence theorem would be applied.  So maybe what I need to do is somehow prove the second equality in general and then use it with a convergence theorem? Any tips appreciated. I will also post a solution if I find one. Thanks.",['measure-theory']
560604,Derivative of trig function,Find the second derivative of $ \arcsin(2x^3) $ The solution says for the first derivative : $ \dfrac{1}{\sqrt{1-(2x^3)^2}} \cdot 6x^2 = \dfrac{6x^2}{\sqrt{1-4x^6}}  $ When i answered the first derivative i got to : $ \dfrac{\cos(2x^3) \cdot 6x^2}{\sin^2(2x^3)} $ So what am i missing ?,"['trigonometry', 'calculus', 'derivatives']"
560624,"Is it true that for infinitely many values of $n$, the sum of digits of $2^n$ is greater than for $2^{n+1}$?","Let $S(n)$ denote the digit sum of the integer $n$, using base $10$.
How to prove that there exist infinitely natural numbers such that $S(2^n)>S(2^{n+1})$? Remarks (by Deven Ware): This is not true in base $2$, because then the sum of digits is always $1$. $S(2^n)$ is never equal to $S(2^{n+1})$ because the powers differ $\bmod 3$.",['number-theory']
560639,show that $E(X|G)=\int_0^{\infty}P[X>t|G]dt$,"For $0\le X \in L_1$,  $X$ is a random variable on $(\Omega,B,P)$, and G is a $\sigma$-algebra and $G \subset B$, show almost surely
$$E(X|G)=\int_0^{\infty}P[X>t|G]dt$$
Here is my try:
This is about conditional expectation. By the definition of the conditional expectation $E(X|G)$ has two requirements:
$$E(X|G) \in G$$ 
And for all  $ A \in G$
$$\int_AE(X|G)dP=\int_AXdP $$
It's easy to get the second equation. That is 
$$
\begin{align}
\int_A\int_0^\infty P[X>t|G]dtdP &= \int_0^\infty \int_A P[X>t|G]dPdt \;\;(Fubini) \\ 
&= \int_0^\infty \int_A E(1_{[X>t]}|G)dPdt 
\\&=\int_0^\infty \int_{A} 1_{[X>t]}dPdt
\\&=\int_{A} \int_0^\infty  1_{[X>t]}dtdP \;\; (Fubini)
\\&=\int_A X dP
\end{align}
$$ But I tried a lot, still cannot prove the first one, because it's contained in the integral. Anyone has any idea? Thank you!","['measure-theory', 'probability']"
560652,Can we prove that every ordered space is normal without choice?,"In ZFC, every linear ordered space with respect to the order topology is completely normal. I saw the this proof and proof of this statement in the book ""Counterexamples of topology"" (Example 39). But as I have seen every proof of this statement uses choice. Even if (as I know) the proof of ""Every linear continuum is normal"" uses the axiom of choice. So I think that choice is essential to prove this statement. That is true? Thanks for any help.","['general-topology', 'set-theory', 'axiom-of-choice']"
560665,4th order differential equations with Bessel Function solutions,"I am working on a a 4th order linear PDE coming from the modified wave equation of a stiff material. I have radial symmetry which has lead me to a 4th order ODE in $r$: $r^3 R''''(r) + 2r^2 R'''(r) - rR''(r)+R'(r) = m^4 r^3 R$ where $m^4$ is a constant. This ODE is subject to boundary conditions: $|R(0)|<\infty$, $|R'(0)|<\infty$, $R''(R)=0$, $R'''(R)=0$, where $R$ is the radius of my circle. I know that the solution should be in terms of Bessel functions as is typical of problems of this type. Mathematica gives solutions in terms of Bessel functions and Meijer G functions. Looking at the basic formulation (from wikipedia) of the Meijer G functions I do not see how this is obviously a solution (not implying it is obvious, I am implying that I do not see how it fits). My first question is if someone can help me get to the Meijer G formulation or present to me useful information on how this DE relates to Meijer G functions. Secondly, is there anyway to rewrite this to get it in terms of Bessel functions (I do not think this is the case because they fulfill second order ODEs). Is the analytic solution of this easy (easy in terms of doable at a beginning graduate level) or is it very convoluted? EDIT: I went back to the original formulation of the problem and found: $\left( \frac{1}{r}\frac{d}{dr} \left\{ r \frac{d}{dr} \right\} \right) R(r) = m^4 R(r)$. Now, instead of expanding, I found that I can consider this as two PDEs: $\left( \frac{1}{r}\frac{d}{dr} \left\{ r \frac{d}{dr} \right\} \right) R(r) = k^2 R(r)$ and $\left( \frac{1}{r}\frac{d}{dr} \left\{ r \frac{d}{dr} \right\} \right) R(r) = -k^2 R(r)$. From this standpoint the solution becomes much easier to understand in terms of Bessel Functions. I will be posting a solution below.","['ordinary-differential-equations', 'special-functions']"
560711,Find the maximum and minimum values of $A \cos t + B \sin t$,"Let $A$ and $B$ be constants. Find the maximum and minimum values of $A \cos t + B \sin t$. I differentiated the function and found the solution to it as follows: $f'(x)= B \cos t - A \sin t$ $B \cos t - A \sin t = 0 $ $t = \cot^{-1}(\frac{A}{B})+\pi n$ However, I got stuck here on how to formulate the minimum and maximum points. Any explanation would be appreciated.","['trigonometry', 'calculus', 'maxima-minima']"
560712,"A question regarding $\,3 \times 4$ matrices","Good day, I'm currently studying for an exam and need to learn about matrices too. Well, since I'm not good at English I'll just write what I've done so far. Below is a photo showing the full sheet of paper with the steps I did so far. The thing I'm wondering about is, that I'd have four unknown variables $(w, x, y, z)$ after writing down the equations, but my matrix has got 3 rows only. Therefor I'm wondering how I'm supposed to find a generic solution for A*x = b $$A=\begin{bmatrix}0&2&-2&3\\ 1&3&-1&2\\ 2&3&1&0 \end{bmatrix} , b=\begin{bmatrix}-1\\ -2\\ 0 \end{bmatrix}$$ $$A=\begin{bmatrix}1&3&-1&2&-2\\ 0&1&-1&3/2&-1/2\\ 0&0&0&1/2&-3/2 \end{bmatrix} $$ $$z=-3 $$ 
$$\operatorname{rank}(A)=3 $$ So I actually solved for $z$ but I can't seem to solve for the other unknown variables (or can I?). The thing that confuses me is the fact this matrix is $3 \times 4$ now instead of $3 \times 3$. Any tips would be very much appreciated! Click image with middle-mouse-button for full size.",['matrices']
560736,What is a $0\times0$ or $0\times3$ matrix?,"In the comments to another question , the following exchange was noted: ... wait until you see a 0×0 matrix. and ... or worse, a 0×3 matrix! What are these things? Do they have a name or any special proprieties? Where are they used?","['matrices', 'linear-algebra']"
560746,Max length possible,"I have a cabinet that has 15"" door. I can use $3$ baskets of $15 \times 15$ in the cabinet. I will like to know if there is any possibility that $15 \times 20$ or bigger basket can fit in this cabinet. The problem is, it will not turn inside the cabinet if it is too large. Is there any mathematical way to find out the maximum length possible in this case?",['geometry']
560747,Borel sets and metric exterior measure (abstract measure spaces),"An exterior measure $\mu_*$ on $X$ is called a metric exterior measure if it satisfies $\mu_* (A\cup B)=\mu_*(A) + \mu_*(B)$ whenever the distance between $A$ and $B$ is positive. Now this theorem says that if $\mu_*$ is a metric exterior measure on a metric space $X$, then the Borel sets in $X$ are measurable. The proof proceeds by mentioning that it suffices to prove that closed sets in $X$ are Caratheodory measurable in view of the definition of a Borel set. I am not quite sure why the last statement is true. I know that if we can show that a closed set $F$ is Caratheodory measurable then so it it's complement (i.e. an open set). But a Borel set is an element of the Borel sigma algebra that is the intersection of all sigma algebras that contain the open sets. Certainly, Borel sets are not necessarily open so how will I use the fact that a closed set is Caratheodory measurable? Thanks - help appreciated!","['measure-theory', 'real-analysis']"
560757,Finding recurrence relation given the generating function,"So I'm given the generating function $F(x)={1+2x\over1-3x^2}$
I'm supposed to find the recurrence relation satisfied by fn.
I managed to get it into 2 separate geometric series and derive $f_n = {5(3^n)-(-3^n)\over6}$
but can't derive it in terms of past values of $f_n$.
Help please, I have exam tomorrow!!! EDIT: I just realised the $f_n$ I derived is wrong, ignore that.","['generating-functions', 'recurrence-relations', 'discrete-mathematics']"
560772,Interesting inequality $\|F\|_p\le \frac{\pi}{\sin(\pi/p)}\|f\|_p$ over $L^p$,"Consider the function $$F(x)=\int_0^\infty \frac{f(y)}{x+y} \, dy, \quad0<x<\infty$$ Prove that if $1<p<\infty$, $$\|F\|_p\le \frac{\pi}{\sin(\pi/p)}\|f\|_p$$ and show that the constant is the best possible. Since this problem came from a chapter on convolution, I think it might help to rewrite the integral in the form of a convolution over $\mathbb{R}$. I'm thinking of setting $z=x+y$ so that $y=z-x$. Also, to evaluate the constant, this might be helpful: for $0<a<1$, $$\int_0^\infty \frac1{(1+x)x^a} \, dx=\frac{\pi}{\sin\pi a}$$ Somewhat related: Prove $ F(x)=\int_0^{\infty}\frac{f(y)}{x+y}dy $ is continuous on $(0,\infty)$ and differentiable, and have $\lim\limits_{x\to \infty} F(x)=0$.","['convolution', 'inequality', 'measure-theory', 'real-analysis', 'analysis']"
560784,Holomorphic function having finitely many zeros in the open unit disc,"Suppose $f$ is continuous on the closed unit disc $\overline{\mathbb{D}}$ and is holomorphic on the open unit disc $\mathbb{D}$. Must $f$ have finitely many zeros in $\mathbb{D}$? I know that this is true if $f$ is holomorphic in $\overline{\mathbb{D}}$ (by compactness of the closed unit disc), but I'm not sure of what happens when I just consider $\mathbb{D}$.",['complex-analysis']
560788,Deriving Fourier inversion formula from Fourier series,"Let $g\in C_0^{\infty}(\mathbb{R})$ (infinitely differentiable with compact support), and let $$\hat{g}(y)=\int_{-\infty}^\infty g(x)e^{-ixy}dx$$ Assume that $\hat{g}$ is in the Schwartz class. Prove that $$g(x)=\frac{1}{2\pi}\int_{-\infty}^{\infty}\hat{g}(y)e^{ixy}dy$$ We may use the result that if $f\in C^{\infty}(\mathbb{R})$ is a periodic function of period $2L$ , then $$\hat{f}(x)=\sum_{n=-\infty}^\infty \left(\dfrac{1}{2L}\int_{-L}^Lf(y)e^{-in\pi y/L}dy\right)e^{i\pi nx/L}$$ I'm trying to follow Steven Stadnicki 's hint. Since $g$ has compact support, let $N$ be such that $g(x)=0$ for all $|x|>N$ . Choose $L>N$ , and let $f_L(x)=g(x)$ for $|x|\leq N$ and extend $f_L(x)$ periodically with period $2L$ to all of $\mathbb{R}$ . Then we have $$\hat{f_L}(x)=\sum_{n=-\infty}^\infty \left(\dfrac{1}{2L}\int_{-L}^Lf(y)e^{-in\pi y/L}dy\right)e^{i\pi nx/L}$$ If I send $L$ to $\infty$ , in some sense I get the function $g$ . But I'm still confused how the Fourier coefficients of $f_L$ will translate to the coefficients of $g$ .","['fourier-analysis', 'integration', 'real-analysis']"
560801,Sigma field generated by Borel sets is the same as sigma field generated by intervals,"Let $\mathcal{R} = \{ B_1 \times B_2 : B_1,B_2 \in \mathcal{B} \} $ where $\mathcal{B}$ is the sigma field of Borel sets. Let $\mathcal{I} = \{ I_1 \times I_2 : I_1,I_2 \; \; \text{are intervals} \} $. We want to show that $\sigma(\mathcal{R}) = \sigma( \mathcal{I} )$. My try: We know that the Borel sets are generated by intervals, hence we must have $\mathcal{I} \subseteq \mathcal{R} $. Therefore, $\sigma( \mathcal{I} ) \subset \sigma( \mathcal{R} ) $. I am kind of stuck trying to prove the other direction. Can someone help me? It would be really appreciated. Thanks.","['measure-theory', 'elementary-set-theory', 'real-analysis']"
560816,Find the sum of the series $\sum \frac{1}{n(n+1)(n+2)}$,"I got this question in my maths paper Test the condition for convergence of $$\sum_{n=1}^\infty \frac{1}{n(n+1)(n+2)}$$
  and find the sum if it exists. I managed to show that the series converges but I was unable to find the sum. Any help/hint will go a long way. Thank you.",['sequences-and-series']
560885,How can I solve system of linear equations over finite fields in WolframAlpha?,"Is it possible to solve system of linear equations over finite fields using Wolfram Alpha? If yes, how can I do that? Let us take a system $x+y+z=0$, $2x+y+2z=0$, $x+3y+z=0$. If I want to solve this linear system over $\mathbb Z_7=\mathbb Z/(7)$, one thing I can do is to type (x+y+z) mod 7=0, (2x+y+2z) mod 7=0, (x+3y+z) mod 7=0 into WA, here is a link . (This approach was suggested in an answer to this question .) WA can solve this, but a solution is given by enumerating the residue classes. I would prefer some more compact notation, for example something similar like what WA does for the same system over real numbers , i.e., when I type x+y+z=0, 2x+y+2z=0, x+3y+z=0 into WA. (Getting a basis for a solution space would be nice, but even expression in the form given in this case seems somehow better than listing all residue classes.) Would I be able to solve system linear equations over finite fields $G(p^n)$? (For example if I chose the representation $GF(4)=\mathbb Z_2/(x^2+x+1)$ and tried to solve the above system in this field?) Is it possible to obtain some kind of more compact notation at least in the case of fields of the form $\mathbb Z_p=\mathbb Z/(p)$ (where $p$ is some prime number)?","['modular-arithmetic', 'finite-fields', 'linear-algebra', 'wolfram-alpha']"
560886,Find number of Cuboids in a larger Cuboid,"This is a question posed to my brother in Grade 5. What would be the general approach to solve- How many cuboids of dimensions $a*b*c$ are there in a cuboid of dimension $d*e*f$? My brothers approach: Just get the ratio $\frac{d*e*f}{a*b*c}$ and round it off. My approach: Check 1 : Each of $d$, $e$, $f$ must be larger than $a$, $b$, $c$ Check 2 : Each of $d$, $e$, $f$ must be divisible by $a$ or $b$ or $c$. That is $\frac{a}{d}=0$, $\frac{b}{e}=0$, $\frac{c}{f}=0$. So my answer would be:
$$\frac{24\times 30\times 28}{3\times 5\times 2}=672$$","['geometry', 'volume']"
560929,How to divide a circle with two perpendicular chords to minimize (and maximize) the following expression,"Consider a circle with two perpendicular chords, dividing the circle into four regions $X, Y, Z, W$(labeled): What is the maximum and minimum possible value of $$\frac{A(X) + A(Z)}{A(W) + A(Y)}$$ where $A(I)$ denotes the area of $I$? I know (instinctively) that the value will be maximum when the two chords will be the diameters of the circle, in that case, the area of the four regions will be equal and the value of the expression will be $1$. I don't know how to rigorously prove this, however. And I have absolutely no idea about minimizing the expression.",['geometry']
560950,"How to evaluate $ \int_0^1 {\log x \log(1-x) \log^2(1+x) \over x} \,dx $ [duplicate]","This question already has answers here : A Challenging Logarithmic Integral $\int_0^1 \frac{\log(x)\log(1-x)\log^2(1+x)}{x}dx$ (4 answers) Closed 9 years ago . Solve that the following integral:
$$ \int_0^1 {\log x \log(1-x) \log^2(1+x) \over x} \,dx. $$ I haven't solved it yet.","['calculus', 'integration']"
560952,Differentiation in several variables using projection,"Could you tell me how to differentiate a function with several variables? Our teacher gave us an example: $\pi_1 : (x,y) \rightarrow x, \ \ \ \pi_2: (x,y) \rightarrow y$ - these are differentiable, because they are linear, Consider $f(x,y) = e^x \cos y$ Let $f_1: t \rightarrow e^t, \ \ \ f_2: t \rightarrow \cos t$. Now $f(x,y) = F(f_1 \circ \pi_1, f_2 \circ \pi_2$), where $F(x,y)=xy$, So $F'(x,y)(h,k) = F(x,k) + F(h,y) = xk+hy$, so $f'(x,y)(h,k)=he^x \cos y - k e^x \sin y$. I understand this, because we had this theorem on the analysis lecture: If $E_1, E_2, F$ - Banach spaces, $\phi \in \mathcal{L}(E_1, E_2; F)$ - linear and continuous, then $\phi$ is $C^1$ and $d_{(a_1, a_2)}\phi.(h_1, h_2) = \phi'(a_1,a_2)(h_1,h_2) = \phi(a_1, h_2) + \phi(h_1, a_2), \ \ (a_1, a_2), (h_1, h_2) \in E_1 \times E_2$. My problem is - what should I do when I have three, four variables.
Is there any other way to quickly and safely determine derivatives? When doing it by calculating partial derivatives I first need to check if they are continuous and then $d_af = (\frac{ \partial f }{\partial x_1 }, ..., \frac{ \partial f }{\partial x_1 })$ where $\frac{ \partial f }{\partial x_1 } = d_af.e_i$ or $d_af = \sum _{i=1} ^m \frac{\partial f}{\partial e_i}(a) \circ \pi _i$, where $e_i$ is the standard basis. Is this the correct approach? I'd really appreciate all your help here Thank you a lot.","['multivariable-calculus', 'partial-derivative', 'derivatives', 'real-analysis']"
560963,Adjoint of a Matrix Definition,"Tom M. Apostol in his book ""calculus Vol. 2"" page 122 (see image below) defines adjoint of a matrix as the transpose of the conjugate of the matrix. Is this definition always correct ? Does it agree with the adjoint defined here , i.e. transpose of the cofactor matrix?","['matrices', 'linear-algebra', 'terminology', 'definition']"
560971,Limit and ln switch,"Why is $$\lim_{x\to\infty}\ln\left(\frac{x+1}{\sqrt{x^2-x+1}}\right)=\ln\left(\lim_{x\to\infty}\frac{1+1/x}{\sqrt{1-1/x+1/x^2}}\right) ?$$  I've seen this way of rewriting, but I can't see why it's equal.","['calculus', 'limits']"
560978,What is Topology of compact-convergence?,"Munkres - Topology p. 283 Definition Let $(Y,d)$ be a metric space and $X$ be a topological space. Define $B_C(f,\epsilon)$ as the set $\{g\in Y^X : \sup\limits_{x\in C} \operatorname{d}(f(x),g(x)) < \epsilon \}$ for a given compact subspace $C$ and $\epsilon >0$ and $f\in Y^X$ . Then, the topology generated by all $B_C(f,\epsilon)$ is called the ""Topology of compact convergence"". How does this is a well-defined definition? Munkres mentioned in his book that we need some topology on $Y^X$ making $C(X,Y)$ closed which is stronger than the product topology. Then, he defined 'the topology of compact convergence' as given above. Since he considers a topology on $Y^X$ , he didn't assume functions to be continuous, hence not bounded. Well, if functions are not continuous, then compactness of $C$ no more gurantees that $\sup_{x\in C} d(f(x),g(x))$ exists even when $C$ is nonempty , and of course it does not exist when it is empty. Is he taking the supremum over the extended real ? Or, should i take $d$ as a bounded metric? What would be the definition of this that makes sense? Off the topic, i feel like munkres define topologies that nobody uses but really useful. An example is the uniform metric. And i think 'topology of compact convergence' would be the one too. There's no definition for this topology in wikipedia..",['general-topology']
560984,Multivariable calculus- Two tangent circles,"Another question from a midterm: Let $f:\mathbb{R}^3 \to \mathbb{R} $ be differentiable. 
It is also given that $f$ is constant on the following two spheres:
$ S_1 = \{(x,y,z)|x^2 + y^2 +z^2 =1\} $ and $ S_2 = \{(x,y,z)| (x-1)^2 + (y-1)^2 + (z-1)^2 =1\} $ 
 . A. prove that on every point $(x,y,z)\in S_1 $ we have that $\nabla f(x,y,z)$ is a scalar multiple   of $(x,y,z)$ . B. Prove that there must exist a point on $S_1 \cup S_2 $ on which $\nabla f =0$ . Will someone please help me ? Thanks !",['multivariable-calculus']
561012,Prove that $\operatorname{trace}(ABC) = \operatorname{trace}(BCA) = \operatorname{trace}(CAB)$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Prove that $\operatorname{trace}(ABC) = \operatorname{trace}(BCA) = \operatorname{trace}(CAB)$ if $A,B,C$ matrices have the same size.","['trace', 'matrices']"
561032,$\nabla \cdot \hat n$ where $\hat n$ is a unit vector normal to a cylinder of radius $R$ and with a length $L=\infty$,I'd like to calculate $\nabla \cdot  \hat n$ where $\hat n$ is a unit vector  normal  to a  cylinder of radius $R$ and with a length $L=\infty$. What I've thought of is: $\hat n= \hat R $ and using: $\nabla \cdot \vec v = \frac{1}{s} \frac{\partial }{\partial s}(s v_s)+\frac{1}{s} \frac{\partial }{\partial \phi }( v_\phi )  + \frac{\partial }{\partial z}v_z$ giving: I would get: $\nabla \cdot  \hat n=\frac{1}{R} \frac{\partial }{\partial R}(R \cdot 1)=1/R$ Is this a correct way or how should I do it differently?,"['multivariable-calculus', 'calculus']"
561033,Evaluate $\int_0^1\int_p^1 \frac {x^3}{\sqrt{1-y^6}} dydx$,"I have been working on this sum for a while. The question asks to evaluate the double integral.
$$\int_0^1\int_p^1 \frac {x^3}{\sqrt{1-y^6}} dydx$$
where $p$ is equal to $x^2$. I know that I have to solve the $y$ integral first and then the $x$. But I don't know how to solve the root integral. Applying the formula $$\int \frac{1}{\sqrt{1-t^2}}dt$$ where $t=y^3$ isn't working. Any ideas as to how I must proceed with the integral? Once I get the integral, I must substitute the limits and then the integral would be in terms of $x$ and I must integrate it. Am I correct?",['multivariable-calculus']
561047,Find the inverse of a matrix with a variable,"$$X=
\begin{pmatrix}
2-n & 1 & 1 & 1 & \ldots & 1 & 1 \\
1 & 2-n & 1 & 1 & \ldots & 1 & 1 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
1 & 1 & 1 & 1 & \ldots & 2-n & 1 \\
1 & 1 & 1 & 1 & \ldots & 1 & 2-n\end{pmatrix}_{n\times n}
$$ Which means that the matrix with the size of $n\times n$ have $n-2$ along the diagonal and $1$ everywhere else. 
Help please, I am stuck with this problem.","['matrices', 'inverse']"
561064,convergence on $L^p$ space,"Let $ \displaystyle{ f \in L^p (\mathbb R^n), 1\leq p <\infty }$ and
  let $ \upsilon \in \mathbb R^n$. For $h>0$ define $\displaystyle{
 f_h(x) = \frac{1}{h} \int_0^h f(x+s \upsilon) ds }$. Prove that: $\displaystyle{ f_h \to f}$, in $L^p (\mathbb R^n)$ as $h
 \to 0^+ .$ I tried to do it by approximating $f$ by functions of compact support, but I didn't succeed to end it. I also tried to use to estimate using the operator $\tau_\alpha f (x):= f(x+ \alpha \upsilon)$ and then using Jensen's inequality and Fubini's theorem, I got to that: $\displaystyle{ \| f_h -f\|_{L^p}^p \leq \int_0^1 \|\tau_{sh} - f\|_{L^p}^p ds }$ I think that it isn't that hard, but I am missing something...","['lebesgue-integral', 'measure-theory', 'lp-spaces', 'real-analysis']"
