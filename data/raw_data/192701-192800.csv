question_id,title,body,tags
3677389,"Is the intersection of two ""sausage"" languages also a ""sausage"" language?","Let's define a deterministic sausage automaton as a sextuple $V = (A, Q_L, Q_R, \phi, q, F)$ , where $A$ is a finite input alphabet , $Q_L$ and $Q_R$ are left-states and right-states respectively, $\phi: (Q_L \cup Q_R) \times A \to (Q_L \cup Q_R)$ is transition function , $q \in (Q_L \cup Q_R)$ is the initial state and $F \subset (Q_L \cup Q_R)$ is the set of terminal states . We will define the automata function $\overline{\phi}: (Q_L \cup Q_R) \times A^* \to (Q_L \cup Q_R)$ using the following recurrence: $$\overline{\phi}(q', \Lambda)=q'\forall q' \in (Q_L \cup Q_R)$$ $$\overline{\phi}(q', a \alpha)=\overline{\phi}(\phi(q', a), \alpha) \forall q' \in Q_L a\in A \alpha \in A^*$$ $$\overline{\phi}(q', \alpha a)=\overline{\phi}(\phi(q', a), \alpha) \forall q' \in Q_R a\in A \alpha \in A^*$$ We then say that the language accepted by $V$ is $L := \{\alpha \in A^*|\overline{\phi}(q, \alpha) \in F\}$ . We call a formal language a sausage language iff it is accepted by some deterministic sausage automaton. It is not hard to see, that all regular languages are sausage languages. However, the class of sausage languages is much larger (for example, the language of even-length palindromes is a sausage language but neither a regular language, nor even a deterministic context-free language). It is also not hard to see, that the complement of  a sausage language is also a sausage language. But what's about the intersection? Is the intersection of two sausage languages also a sausage language?","['elementary-set-theory', 'formal-languages', 'automata', 'discrete-mathematics']"
3677418,"If $U_n\to U$ in probability, then for all countinuous function $L:\mathbb R\to \mathbb R$, $L(U_n)\to L(U)$ in probability. Proof unclear.","Let $(U_n)$ a sequence s.t. $U_n\to U$ in probability. Let $L:\mathbb R\to \mathbb R$ be a continuous function. Prove that $L(U_n)\to L(U)$ . The proof goes as follow : Step 1 : Suppose $L$ is Lipschitz on $\mathbb R$ . Let $\varepsilon >0$ . Then, there is $\delta >0$ s.t. $$|L(x)-L(y)|>\varepsilon \implies |x-y|>\delta \tag{E}.$$ Therefore, $$\mathbb P(|L(U_n)-L(U)|>\varepsilon )\leq \mathbb P(|U_n-U|>\delta )\underset{n\to \infty }{\longrightarrow }0.$$ Therefore $L(U_n)\to L(U)$ in probability. Step 2 : Suppose $L$ is continuous but not uniformly continuous. Let $\varepsilon  >0$ , $\eta>0$ and $K>0$ s.t. $$\mathbb P(|U|\geq K)\leq \eta.$$ Since $L$ is uniformly continuous on $[-K,K]$ , then $(E)$ hold whenever $|U|\leq K$ . Question : Why is this true ? Don't we need that $U\in [-K,K]$ and $U_n\in [-K,K]$ for all $n\geq N$ for some $N\in\mathbb N$ ? Then, they conclude : therefore, $$
\mathbb P(|L(U_n)-L(U)|>\varepsilon )
$$ $$=\mathbb P(|L(U_n)-L(U)|>\varepsilon , |U|<K)+\mathbb P(|U|\geq K)
$$ $$\leq \mathbb P(|U_n-U|>\delta )+\eta\underset{n\to \infty }{\longrightarrow }\eta.
$$ The claim follow. So the thing I really don't understand is the question in bold. If $U_n\notin [-K,K]$ for all $n$ from a certain rang, $(E)$ doesn't hold. Any idea on why (E) is true then ?","['convergence-divergence', 'uniform-continuity', 'probability-theory', 'probability']"
3677451,What exactly is the way to find Projection of a surface on to a Plane,"I was trying to find the surface integral of the surface defined by equation of plane passing through the points $(0,0,2)$ , $(0,1,0)$ and $(2,1,0)$ over the vector field $\vec{F}=x\vec{i}+y^3\vec{j}+\vec{k}$ My try: The equation of the plane is $2y+z=2$ whose unit outward normal being: $$\hat{n}=\frac{2\vec{j}+\vec{k}}{\sqrt{5}}$$ So the surface integral is now: $$\int\int_{S}\vec{F}.\hat{n}dS=\int\int_{S}\frac{2y^3+1}{\sqrt{5}}dS$$ Now how to start the procedure of projection? the book has projected the surface on $x-z$ plane, but i am not clear the concept behind this projection","['multivariable-calculus', 'multiple-integral', 'surface-integrals']"
3677458,UMP test with two distributions derivation,"Suppose X has distribution in $\mathcal{P}=\{B(10, \frac{1}{2}), P(1)\}$ (Binomial and Poisson respectively). Let $H_0 := X \stackrel{D}{=} B(10, \frac{1}{2})$ and $H_1 := X \stackrel{D}{=}P(1)$ . Derive an UMP test for $H_0$ with $\alpha = 0.1$ There is also a hint to use tables of Poisson or Binomial distribution. I know $\alpha$ = $\mathbb{P}_0(f_1(x) > cf_0(x)) + \gamma \mathbb{P}_0(f_1(x)=cf_0(x)$ . I calculated $f_1(x) > c f_0(x)$ as $$
\frac{1}{e x!} > c \frac{10!}{(10-x)!x!}2^{-10} \\
\frac{2^{10}}{e} > c 10^{\underline{x}} \\
\frac{2^{10}}{e 10^{\underline{x}}} > c 
$$ When I plug that in $$
\alpha = \mathbb{P}_0(f_1(x) > cf_0(x)) + \gamma \mathbb{P}_0(f_1(x)=cf_0(x)  = \\
=  \mathbb{P}_0(\frac{2^{10}}{e 10^{\underline{x}}} > c) + \gamma \mathbb{P}_0(\frac{2^{10}}{e 10^{\underline{x}}} = c)
$$ Here I got stuck. I know that I need to assume the $H_0$ is true so $X \stackrel{D}{=} B(10, \frac{1}{2})$ but I have $10^{\underline{X}}$ here. Surely I must be missing something. I usually used CLT here but I have no idea how to do it here. Thank you for any insights.","['statistics', 'probability', 'hypothesis-testing']"
3677473,Proving the area of circle and hyperbolic function is the same,"I am an A-level student and due to the schools being closed down, I am reading ahead in Further Maths. I am stuck on a question regarding integrating an area due to a hyperbolic function. The question is below: I know how to find the area of the circle but I am stuck on the rectangular hyperbola. I have tried to integrate the function $$
y=\sqrt{a^2+x^2}
$$ by substituting in: $$
\frac{x}{a}=\sinh{u}
$$ However, that doesn't seem to prove it. I then tried to also tried to integrate it parametrically by using $$
x=\cosh{\theta}
$$ $$
y=\sinh{\theta}
$$ But I still haven't been able to prove it. Could you help?","['integration', 'definite-integrals', 'hyperbolic-functions', 'conic-sections', 'calculus']"
3677501,Lemma 4.14 Heat Kernels and Dirac Operators,"I am trying to work out Lemma 4.14 of the book ""Heat Kernels and Dirac Operators"" by Berline and Getzler. I am stuck with the proof. For the sake of brevity I am uploading a picture from the book before showing what I have tried. Here's what I have proved. Let $M$ be a Riemannian manifold and $V\rightarrow M$ be a complex vector bundle. Then we fix a point $q_0$ and trivialize $E$ on a geodesic-ally convex neighbourhood using normal co-ordinates and parallel transport as has been done in this section. Let $\nabla$ be a connection on $V$ and we can write on the trivializing neighbourhood $\nabla s_\alpha=\sum_\beta \omega_{\beta \alpha}\otimes s_\beta$ where $d$ is the trivial connection in terms of the local frame field $\{s_\alpha \}_\alpha$ obtained by parallel transporting a frame at the point $0$ . Then we have $\omega(0)=0$ Let $F_{\nabla}=\displaystyle{\sum_{i<j}}F_{ij}dx_i\wedge dx_j$ where $F_{ij}(x)=F_\nabla(\partial^i,\partial^j)(x)$ . Then we get around $0$ , $$\omega(x)=-\frac{1}{2}\sum_{i,j}F_{ij}(0)x_jdx_i+O(|x|^2)$$ $\nabla_{\partial^i}=\partial^i-\displaystyle{\frac{1}{2}\sum_{j=1}^n}{F_\nabla(\partial^i,\partial^j)_0}x_j+O(|x|^2)$ Using this I am trying to get the more precise asymptotic result for a Dirac bundle $\mathcal E$ on $M$ with a compatible Clifford connection $\nabla^\mathcal E$ . It will be great if someone can explain the proof to me or help me complete the proof. Thanks a lot in advance.","['clifford-algebras', 'riemannian-geometry', 'differential-geometry']"
3677505,Question about the proof of Tietze extenstion theorem,"In the book ""An Introduction to Mathematical Analysis for Economic Theory and Econometrics"" by Dean Corbae, I saw the proof for Tietze extension theorem, which states that ""If $M$ is a metric space , $F$ is a closed set in $M$ and $g \in C_b(F)$ , then there is a continuous extension $G \in C_b(M)$ such that $\|G \|_{\infty}=\|g \|_{\infty}.$ "" They consider the following extension: $$G(x)=\begin{cases} g(x) &\text{ if } x \in F \\ \sup_{t \in F}\dfrac{g(t)}{(1+d(t,x)^2)^{1/d(x,F)}}& \text{ if } x\notin F \end{cases}$$ For proving $G(x)$ is continuous at $x \in \partial F$ , they consider a sequence $x_n \subset F^c$ which converges to $x$ . For $t \neq x$ , $\dfrac{1}{(1+d(t,x_n)^2)^{1/d(x_n,F)}} \overset{n \to \infty}{\longrightarrow} 0$ and $\dfrac{1}{(1+d(x,x_n)^2)^{1/d(x_n,F)}} \overset{n \to \infty}{\longrightarrow} 1$ . They mention to use the property: $\lim_{s \to 0}f(s)=1$ , where $f(s)$ is strictly decreasing function $$f:(0,+\infty) \to (0,1): s \mapsto f(s)=\dfrac{1}{(1+s^2)^{1/s}}$$ Then $G(x_n)\overset{n \to \infty}{\longrightarrow} G(x)$ . My question is that how they use above property of $f(s)$ to prove $a_n = \dfrac{1}{(1+d(x,x_n)^2)^{1/d(x_n,F)}} \overset{n \to \infty}{\longrightarrow} 1$ . I know that both two terms $d(x,x_n)$ and $d(x_n,F)$ converge to $0$ but they are not the same "" $s$ "" as in function $f(s)$ . Any other way to prove continuity of $G(x)$ is good too. Thanks in advance.","['proof-explanation', 'metric-spaces', 'analysis', 'continuity', 'limits']"
3677516,What is the projection matrix of reverse (Byzantine) perspective?,"I would like to construct a projection matrix for reverse perspective.
I'm using OpenGL and tried to modify concepts from this excelent tutorial . I came up with: $$
\begin{bmatrix}
2\frac{(\text{near}-M)}{\text{right}-\text{left}} &  0  & \frac{\text{right} + \text{left}}{\text{right}-\text{left}} & M\frac{\text{right} + \text{left}}{\text{right}-\text{left}}\\
0  &  2\frac{(\text{near}-M)}{\text{top}-\text{bottom}} & \frac{\text{top} + \text{bottom}}{\text{top}-\text{bottom}} & M\frac{\text{top} + \text{bottom}}{\text{top}-\text{bottom}}\\
0 & 0 & \frac{2M-\text{near}-\text{far}}{\text{far}-\text{near}} & \frac{2(M-\text{far}) \cdot \text{near}}{\text{far}-\text{near}} + M\\
0 & 0 & -1 & -M
\end{bmatrix}
$$ $$ \text{Variables define viewing frustum. }M \text{ is the tip; point } (0,0,-M) \text{ in eye space.}$$ To avoid ambiguity near point M I put far plane closer to the camera. To debug this, I inverted points from NDC [-1,1] cube and they seem to fit the desired frustum. Sadly my models don't render correctly when using this matrix. They don't show up when they clearly are in the viewing frustum. I verify this by rendering the scene from other cameras using regular perspective or orthographic projection. To clarify, what kind of perspective I'm talking about, here are links: https://en.wikipedia.org/wiki/Reverse_perspective True Reverse Perspective Code in c++ using glm: template <typename T>
auto frustum(T left, T right, T bottom, T top, T near, T M, T far) {
    glm::tmat4x4<T, glm::defaultp> result(0);
    result[0][0] = (static_cast<T>(2) * (near - M)) / (right - left);
    result[2][0] = (right + left) / (right - left);
    result[3][0] = (right + left) / (right - left) * M;

    result[1][1] = (static_cast<T>(2) * (near - M)) / (top - bottom);
    result[2][1] = (top + bottom) / (top - bottom);
    result[3][1] = (top + bottom) / (top - bottom) * M;

    result[2][2] = ((static_cast<T>(2) * M) - near - far) / (far - near);
    result[3][2] = static_cast<T>(2) * (M - far) * near / (far - near) + M;

    result[2][3] = static_cast<T>(-1);
    result[3][3] = static_cast<T>(-M);
    return result;
}","['projection-matrices', 'geometry', 'computer-vision']"
3677552,Phase angles of a complex eigenvector,"I have the following system for $\lambda \in \Bbb C, \lambda \neq 0$ and $\pmb{p},\pmb{q} \in \Bbb C^n$ , $(\pmb{p}^T, \pmb{q}^T)\neq0$ : $$\begin{cases} F(\lambda) \pmb{p} - g(\lambda) \pmb{q} - \lambda \alpha\beta M^{-1}C \pmb{q} 
 = 0 \ , \\  g(\lambda) \pmb{p} + F(\lambda) \pmb{q} + k \alpha\beta M^{-1}C \pmb{p} 
 = 0 \ . \end{cases} $$ Where $F(\lambda) = \lambda^3 I + \lambda^2(\alpha I + \beta D) + \lambda \alpha \beta D$ , $g(\lambda) =  \lambda^2\beta + \lambda \alpha \beta$ , $\alpha, \beta, k$ are positive scalars, $D,M$ are $n\times n$ diagonal matrices with positive elements on its diagonals, $C$ is $n\times n$ real positive semi-definite matrix (non-diagonal). For which matrix $D$ phase angles of $\pmb{p}$ are opposite to $\pmb{q}$ (namely, $p_k = |p_k|e^{i\phi_k}$ and $q_k = |q_k|e^{-i\phi_k}, \ k=1,\cdots,n$ )? I suspect it is valid only if $D = dI$ . Because in this case, $F(\lambda) = [\lambda^3 + \lambda^2(\alpha + \beta d) + \lambda \alpha \beta d]I = f(\lambda)I$ and $\pmb{p}$ will be an eigenvector of $M^{-1}C$ . Further, $\pmb{q}= -\frac{g(\lambda) + k\alpha\beta\mu}{f(\lambda)} \pmb{p}$ , where $\mu$ is the correspoding eigenvalue of $M^{-1}C$ such that difference between phase angles of $\pmb{p}$ and $\pmb{q}$ is $\phi_0 = \angle  \frac{g(\lambda) + k\alpha\beta\mu}{f(\lambda)}$ , and the pair $(\pmb{p} = e^{-i\frac{\phi_0}{2}}\pmb{\psi}, \pmb{q}= - e^{-i\frac{\phi_0}{2}}\frac{g(\lambda) + k\alpha\beta\mu}{f(\lambda)}\pmb{\psi})$ with $M^{-1}C$ eigenvector $\pmb{\psi} \in \Bbb R^n$ will have the opposite phase angles. I do not know how to show $D=dI$ is necessary or find conterexample with $D\neq d I$ .","['linear-algebra', 'complex-numbers', 'eigenvalues-eigenvectors']"
3677614,A question about an example of integral notherian scheme that is not a finite type over K,"While reading up on ' finite type over $k$ ' on Hartshorne, algebraic geometry, I have tried to understand the following example : Example ) If $P$ is a point of a variety of $V$ , with local ring $\mathcal{O}_P$ , then $\operatorname{Spec} \mathcal{O}_P$ is an integral noetherian scheme , which is not in general of finite type over $k$ . However, I have not yet digested this example. The following texts are the way where I saw this example: When considering the definition of point of variety $V$ , I think that the local ring $\mathcal{O}_P $ is indeed a field of fractions of $V$ . Since $\mathcal{O}_P $ is anyway a field (or, equivalently, a unique maximal ideal), I think that $X:=\operatorname{Spec} \mathcal{O}_P$ is merely singleton set (actually, $X=\{(0)\}$ ?) Then, my rough sketch is here, i) $\mathcal{O}_X(U)$ is an integral domain. ii) $X$ is covered by a finite collection of $\operatorname{Spec} A_i $ (where $A_i$ 's
  are noetherian) iii) let $f:X \to Y$ be a morphism of schemes (  where $X=\operatorname{Spec} \mathcal{O}_P, Y=\operatorname{Spec} \mathcal{O}_Q$ ). 
  Then, for each i, $f^{-1}(\operatorname{Spec} {B}_i$ ) is cannot be covered finite number of $U_{ij}=\operatorname{Spec} A_{ij} $ However, everything is not easy now ... Above all, I wonder whether or not iii) is the right idea. When considering the definition 'a finite type over $k$ ', essentially there is a morphism of schemes. Thus, by setting another point $Q$ of variety of $V$ , and then gave a morphism $f: \operatorname{Spec} \mathcal{O}_P \to \operatorname{Spec} \mathcal{O}_Q$ ... but I am not sure whether this is the right way...","['algebraic-geometry', 'schemes']"
3677621,Probability of crossing $n\times n$ grid with random diagonals; and bond percolation critical threshold $p_c$,"You can always cross an $n\times n$ grid with random diagonals, from one side of the grid to the opposite side of the grid. So the probability of this crossing is $1$ . Here random diagonals means you have an $n\times n$ grid and you draw at random one diagonal in each of the 1×1 unit squares of the grid. Then you can always find a connected path using these small diagonals that goes from one side of the grid to the opposite side, up to down or left to right. (You can prove that by contradiction that makes repeated use of the Lemma of Sperner. In these two posts, you can find a related discussion and several different proof ideas https://math.stackexchange.com/a/3677664/782412 and https://mathoverflow.net/q/112067/156936 .) I have two questions about the crossing probability (1) Can we use the symmetry to conclude that the probability of crossing from top to down is $1/2$ ? My thinking is that this follows directly from the symmetry, and from the fact that the unrestricted (up-down or left-right) probability is $1$ . I have seen such a symmetry argument in the post of user joriki here https://math.stackexchange.com/a/3641146/782412 , but I wanted to ask for confirmation that the symmetry arguments is also valid for my problem. (2) Bond percolation critical probability threshold $p_c$ ? Assuming the answer to my question is $1/2$ , i.e. probability of crossing the grid top-down, this reminds me of an introductory article about percolation theory here https://en.wikipedia.org/wiki/Percolation_theory , following a comment from user joriki (thank you for that!). In particular, I am refering to bond percolation, i.e. percolating from the top side down to the bottom side. The article says that for the infinite square lattice $\mathbb Z^2$ in two dimensions, the critical probability threshold $p_c$ for bond percolation is $1/2$ . My question, is crossing the grid along random diagonals in fact EQUIVALENT to bond percolation on a square grid? In this case, my crossing problem could be related to $p_c$ for the finite case of an $n \times n$ grid? Is the finite $n\times n$ case an established and known result? I am not sure, and maybe I am misunderstanding the concept of $p_c$ . I would be grateful if someone could help me clarify and answer this.","['discrete-geometry', 'combinatorics', 'discrete-mathematics', 'percolation', 'probability']"
3677676,Does $\lim\int f_n=\int f$ imply $\lim\int|f_n|=\int|f|$?,"Suppose that $\{f_n\}$ is a sequence complex measurable functions on a measurable space $(X,\Omega,\mu)$ .
Let $f$ be the pointwise limit of $f_n$ .
Does (1) implies (2)? where $$\lim_{n\to\infty}\int_Xf_n\,d\mu=\int_Xf\,d\mu.\tag{1}$$ $$\lim_{n\to\infty}\int_X|f_n|\,d\mu=\int_X|f|\,d\mu.\tag{2}$$ [EDIT] I don't know if the above statement is valid or not.
So please give me a counterexample if it is false. My trial:
(1) implies $$\lim_{n\to\infty}\int_X(f_n-f)\,d\mu=0.\tag{3}$$ $$\lim_{n\to\infty}\int_X|f_n-f|\,d\mu=0.\tag{4}$$ $$\lim_{n\to\infty}\int_X\Big||f_n|-|f|\Big|\,d\mu=0.\tag{5}$$ $$\lim_{n\to\infty}\int_X|f_n|-|f|\,d\mu=0.\tag{6}$$ So (2) follows.
I'm not certain whether (3) implies (4).
That is to say that (7) implies (8) where $g_n\to0$ and $$\lim_{n\to\infty}\int_Xg_n\,d\mu=0.\tag{7}$$ $$\lim_{n\to\infty}\int_X|g_n|\,d\mu=0.\tag{8}$$ Let $A_n=\{x\in X:|u_n(x)|\ge |v_n(x)|\}$ and $B_n=X\setminus A_n$ .
Then $$\int_X|g_n|\,d\mu
=\int_X\sqrt{(u_n(x))^2+(v_n(x))^2}\,d\mu
\le\int_{A_n}\sqrt2|u_n|\,d\mu+\int_{B_n}\sqrt2|v_n|\,d\mu
\le\sqrt2\int_X|u_n|\,d\mu+\sqrt2\int_X|v_n|\,d\mu$$ So, it is enough to consider ""(7) implies (8)"" for real $g_n$ .","['measure-theory', 'lebesgue-integral']"
3677735,Symmetric coefficients imply symmetric solutions?,"Let us consider any one-diomensional ODE of the form: $$
\dfrac{d^{2}y}{dx^{2}}+a(x)y(x)+b(x)=0,
$$ where $a,b:\mathbb{R}\to\mathbb{R}$ are both even functions. Does these hypothesis implies that the solution $y(x)$ must to be even, regardless what $a(x)$ and $b(x)$ actually? Are there some non-symmetric solution for some specific even functions $a(x)$ and $b(x)$ ? Same question if I change the hypothesis on $b(x)$ for odd function. Does that implies that the solution must to be odd? Edit: I just realize that $y(x)$ could be odd, even if $a(x)$ is even just by assuming $b(x)\equiv0$ . But, what about if I add the hypothesis of $y(x)>0$ for all $x\in\mathbb{R}$ ?","['analysis', 'ordinary-differential-equations', 'real-analysis']"
3677779,Second order ODE of unknown format problem,"I'm looking for a Real function $R(r)$ that satisfies: $$r^2R''+R'+m^2 rR=0$$ where $m\in\Bbb R$ . It looks a bit like an Euler DE but it isn't, and a bit like a Bessel DE but isn't either. Wolfram alpha (link to the ODE) doesn't recognise it and provides no solution unfortunately. I think I need a substitution like $r=f(u)$ to get going. Any help is appreciated. A little background - The equation is the radial equation of two ODEs obtained after separation of variables, of a heat conduction problem (a very thin disk of radius $R_1$ ). Boundary conditions are: $$R(R_0)=0$$ $$R'(R_1)=0$$ I upvoted the first answer because it looked like a good idea but it turned out to be incorrect, as I showed in my comment. In response to commenter 'tomasliam', the Sturm Liouville form of the DE is: $$\frac{\text{d}}{\text{d}r}\left[e^{-1/r}R'(r)\right]+\frac{e^{-1/r}m^2R(r)}{r}=0$$ On request of @themaker: A very thin disc of radius $R_1$ is at temperature $T_i$ . It is insulated on both sides, as well as the outer edge. At $t=0$ the area $[0,R_0]$ is suddenly heated to $T_0$ . What is the temperature evolution $T(t,r)$ of the disc (on $[R_0,R_1]$ )? Fourier heat equation for the disc, taking symmetry into account: $$T_t=\frac{\alpha}r\frac{\partial}{\partial r}\Big(r\frac{\partial T}{\partial r}\Big)$$ $$\frac{T_t}{\alpha}=\frac1r(T_{r}+rT_{rr})$$ For homogeneity, we make a substitution: $$u(t,r)=T(t,r)-T_0$$ $$\frac{u_t}{\alpha}=\frac1r(u_{r}+ru_{rr})$$ Initial: $$u(0,r)=T_i-T_0$$ Boundaries: $$u(t,R_0)=0$$ $$u_r(t,R_1)=0$$ Ansatz: $$u(t,r)=\Theta (t)R(r)$$ Substitute, then divide by $u$ : $$\frac{\Theta'}{\alpha \Theta}=\frac{1}{r}\frac{R'}R+\frac{R''}R=-m^2$$ $$\frac{1}{r}\frac{R'}R+\frac{R''}R=-m^2$$ $$rR''+R'+m^2 rR=0$$ So it looks an error was made in setting up the original ODE! Mea culpa.
The solution of the last equation is: $$R(r)=c_1J_0(mr)+c_2Y_0(mr)$$",['ordinary-differential-equations']
3677783,Find the smallest value $n$ such that there exists a non-empty subset of any set of n positive integers whose sum is divisible by 1001,"Find the smallest value of $n$ such that for any set of $n$ positive integers, there exists a non-empty subset of the set whose sum is divisible by $1001$ This is sort of a follow up on my last post which turned out to be a duplicate. My first intuition was that it's $1001$ , but then when I tried to think about using similar methods as the solution to the previous problem, I found out that it couldn't be applied in this case as it isn't sufficient. Therefore, I think an alternate approach is required but I can't figure out any ways to approach this question systematically. If this post turns out to be a duplicate of another one, please tell me and I'll refer to that one instead. Thank you! Edit: Is it possible to generalize the result for values other than 1001? If so please try to include it in your answer. Thank you so much!","['elementary-set-theory', 'elementary-number-theory', 'algebra-precalculus', 'divisibility']"
3677788,Can we show $\mu(gX) = \mu(X)$ if integral is translation invariant?,"Let $\mu$ be a Radon probability measure on the compact Hausdorff topological group $G$ such that $$\int_G f(g) \mu(dg) = \int_Gf(hg) \mu(dg)$$ for all $h \in G$ and for all $f \in C(G)$ . Can I deduce that $\mu(hX) = \mu(X)$ for a Borel set $X$ and $h \in G$ ? Attempt: $$\mu(hX) = \int_G I_{hX}(g) \mu(dg) = \int_G I_{X}(h^{-1}g) \mu(dg)\stackrel{(?)}= \int_G I_{X}(g) \mu(dg) = \mu(X)$$ Now, I try to explain $(?)$ . Maybe I can approximate with continuous functions or something like that?","['measure-theory', 'locally-compact-groups', 'functional-analysis', 'topological-groups']"
3677837,Tighter upper bound on $x$ where $2^x \leq \sum_{i=0}^m{{x \choose i}\lambda^i}$,"We have the following inequality: $$2^x \leq \sum_{i=0}^m{{x \choose i}\lambda^i}$$ All the variables are in $\mathbb{N}_{>0}$ I need to find a tight upper bound for $x$ using $m,\lambda$ . In the case of $\lambda = 1$ we can use the binomial theorem to show $x \leq m$ . However for $\lambda>1$ I have no idea how to find a tight upper bound for this. It can be shown that: $$2^x \leq \sum_{i=0}^m{{x \choose i}\lambda^i} \leq \left(\frac{\lambda e x}{m}\right)^m$$ And then we can use the solution from here: Upper bound $2^x \leq (ax)^c$ But I need a tighter bound than this. Is there any way to bound $x$ directly from this partial binomial theorem sum? I thought of maybe doing something like this: $$2^x = (1 + \lambda)^{x\log_{1 + \lambda}(2)}=(1 + \lambda)^{\frac{x}{\log_2(1 + \lambda)}}=\\ \sum_{i=0}^{{\frac{x}{\log_2(1 + \lambda)}}}{{{\frac{x}{\log_2(1 + \lambda)}} \choose i}\lambda^i} \leq \sum_{i=0}^m{{x \choose i}\lambda^i}$$ But I'm not sure how to continue from here (or if it even helps).","['binomial-coefficients', 'combinatorics', 'binomial-theorem']"
3677858,$\exists$ injective map but no bijective map from $A$ to $B$ $\implies |A|<|B|$,"$|A|$ is the cardinality of $A$ which is defined to be the least ordinal such that there exists bijective map between $A$ and $|A|$ There exists an injective map but no bijective map from $A$ to $B$ $\implies |A|<|B|$ ( $<$ is the ordering between ordinals by $\in$ or equivalently $\subsetneq$ ). Proof) Since there doesn't exist a bijective map from $A$ to $B$ , $|A|\neq|B|$ . And since $|A|,|B|$ are ordinals, either $|A|<|B|$ or $|A|>|B|$ . Suppose $|A|>|B|$ . Then there exists an injective map from $B$ to $A$ . Then by Cantor-Bernstein theorem, there exists a bijective map from $A$ to $B$ and $|A|=|B|$ , a contradiction. So $|A|<|B|$ . I was wondering if this is a correct proof.","['elementary-set-theory', 'solution-verification']"
3677860,Need help with an integral in quantum mechanics,"I'm studying many-electron atoms without e-e repulsion, in particular, an atom with two electrons and Z protons. Once we get the wave function for the ground state, which (in atomic units) is $$\psi (r_1,r_2)= {Z^3 \over \pi } e^{-Z(r_1+r_2)},$$ we want to approximate how much the e-e interaction would contribute to the energy. For that purpuse, we calculate the expected value of the potential energy $ ~  U_{ee} ={1 \over | \bf r _1 -  r_2 |} $ (again in atomic units), in the state given by the previous wave function. The integral to be calculated is: $$ \int d ^3 {\bf r } _1 d ^3 {\bf r } _2 ~ \psi ^* (r_1,r_2) {1 \over | \bf r _1 -  r_2 |} \psi  (r_1,r_2) = {Z^6 \over \pi^2} \int d ^3 {\bf r } _1 d ^3 {\bf r } _2 ~ { e^{-2Z(r_1+r_2)} \over | \bf r _1 -  r_2 |} $$ Now, it's been a while since I took a course in multivariable calculus, but I gave it a try... and couldn't do it. I know that the integral in cartesian coordinates is $${Z^6 \over \pi^2} \int _{-\infty} ^\infty \int _{-\infty} ^\infty\int _{-\infty} ^\infty\int _{-\infty} ^\infty\int _{-\infty} ^\infty\int _{-\infty} ^\infty  { e^{-2Z \left(\sqrt{x_1^2+y_1^2+z_1^2}+\sqrt{x_2^2+y_2^2+z_2^2} \right) } \over \sqrt{(x_1-x_2)^2+(y_1-y_2)^2+(z_1-z_2)^2}}dx_1dy_1dz_1dx_2dy_2dz_2 ,  $$ and that, in order to compute it, you'd need to do the six iterated integrals. Mathematica can't do that in a reasonable time, and neither can I (I doubt there is a closed form for most of them). So instead I tried two sets of spherical coordinates: $$ x_1=r_1 \sin \theta _1 \cos \phi _1 ~~~~~~~~ x_2=r_2 \sin \theta _2 \cos \phi _2  \\ y_1=r_1 \sin \theta _1 \sin \phi _1 ~~~~~~~~~ y_2=r_2 \sin \theta _2 \sin \phi _2 \\ z_1=r_1 \cos \theta _1 ~~~~~~~~~ z_2=r_2 \cos \theta _2 $$ I used mathematica to calculate the Jacobian determinant and it turns out it's just the product of the two individual Jacobians (which should have been obvious but I'm a bit dumb). After calculating that denominator, the integral that needs to be done is: $$ {Z^6 \over \pi ^2} \int ^{2\pi} _0 \int ^{2\pi} _0 \int ^\pi _0 \int ^\pi _0 \int ^\infty _0 \int ^\infty _0 {e^{-2Z(r_1+r_2)} r_1^2r_2^2 \sin \theta _1 \sin \theta _2 \over \sqrt{r_1^2+r_2^2-2r_1r_2 (\sin \theta _1 \sin \theta _2 \cos (\phi _1 - \phi _2)+\cos \theta _1 \cos \theta _2)}} dr_1dr_2d\theta_1d\theta_2d\phi_1d\phi_2$$ ...which looks... better? Mathematica still hangs up if I try to do the whole integral. Integrating first in $r_1$ or $r_2$ seems impossible analytically. Trying to integrate first in the rest of variables gives a closed answer, but it's in terms of hypergeometric functions or elliptic integrals (and it's absurdly complicated). And the thing is: the answer to this integral is suposedly ${5 \over 8}Z$ . Is it really necessary to do six integrals involving hypergeometric functions and elliptic integrals to get such a simple answer? I wouldn't know how to continue anyways, because well... I don't know how to integrate eliptic integrals composed with other complicated functions and it seems mathematica doesn't know either. What should I do here? Edit: I swear the integrals fit in one line when I was writing.","['integration', 'quantum-mechanics']"
3677921,Partial Derivatives and Differentiability of a piecewise defined function,"this is my first post on this wonderful forum.
I'd like to thank all of you for the help you're going to give me. 
I was doing an exercise, but I'm not sure the solution is entirely correct. 
I should discuss the continuity, the existence of partial derivatives and the differentiability of this function on every point of its domain. 
The function is: $f(x,y)=\left\{\begin{matrix} \frac{1}{y^3}\cdot ln(1+x^3\cdot y) \: \: \: if \: \:  y\neq 0
 &  & \\ x+|x| \: \: \: \: \: \: \: \: \: \: \: \: \: \: \: \: \: \: if \: \: y=0
 &  & 
\end{matrix}\right.$ The domain is clearly: $domf=\left \{ (x,y)\: \in \: \mathbb{R}^2 \: : \: 1+x^3\cdot y>0) \right \}$ I show you my try: The function is differentiable $\forall (x,y)\in \mathbb{R}^2 : y\neq 0 \: \: and \: \: x\neq 0$ , because it's a composition of differentiable functions. I put $x\neq 0$ cause the absolute value in the second equation will almost certainly give some problems. For these values the function is also continue and partial derivable, since its differentiable. We should check the continuity: $\lim_{y \to 0}f(x,y)=\lim_{y \to 0}\frac{1}{y^3}\cdot ln(1+x^3\cdot y)=\lim_{y \to 0}\frac{x^3}{y^2}=\left\{\begin{matrix} +\propto \: \: if \: \: x>0
 &  & \\ 0 \: \: if \: \: x=0
 &  & \\ -\propto \: \: if \: \: x<0
 &  & 
\end{matrix}\right.$ So the function is not continuous for the point of the form $(x,0)$ with $x\neq 0$ , so it is not differentiable on the y-axis (except for the origin, which we'll check later). Now I should check if the function has partial derivatives for the points of the form $(x,0)$ , which I excluded before. $\frac{\partial f}{\partial x}(x,0)=\lim_{t \to 0} \frac{f(x+t,0)-f(x,0)}{t}=\lim_{t \to 0} \frac{x+t+|x+t|-x-|x|}{t}=\left\{\begin{matrix} 2 \: \: if \: \: x>0
 &  & \\ \nexists \: \: if \: \: x=0 
 &  & \\ 0 \: \: if \: \: x<0
 &  & 
\end{matrix}\right.$ $\frac{\partial f}{\partial y}(x,0)=\lim_{t \to 0}\frac{f(x,t)-f(x,0)}{t}=\frac{\frac{1}{t^3}\cdot ln(1+x^3\cdot t)-x-|x|}{t}=\left\{\begin{matrix}\nexists \: \: (=\pm\propto) \: \: if \: \: x\neq 0
 &  & \\ 0 \: \: if \: \: x=0
 &  & 
\end{matrix}\right.$ Since $(0,0)$ doesn't admit both partial derivatives, we can conclude that the function is not differentiable in the origin. Can you please tell me if I solved the exercise correctly? I would really appreciate you're help. Thank you. P.S: Sorry if I made some english mistakes.","['limits', 'derivatives', 'real-analysis']"
3677966,English translation of Bourbaki's Theory of Sets differs from French,"While reading Bourbaki's Theory of Sets in English, I came across something which seems to be inconsistent. On page 19, the discussion on Formative Constructions starts thus: (1.) ""Some of the specific signs of a theory are called relational , and the others are called substantific ."" The fact is that this sentence is absent in French edition of the book. The difficulty arises when it says: (2.) ""An assembly is said to be of the first species if it begins with a τ, or with a substantific sign, or if it consists of a single letter; otherwise it is of the second species ."" And On line 4 of the next page it says: (3.) ""The assemblies of the first species (resp. of the second species) which appear in the formative constructions of T are called terms (resp. relations ) in T."" (I numbered the quotes for convenience) My questions are: a. Does ""resp."" mean 'respectively'? And does respectively in this case mean 'in order?' b. If yes, then, the order changed between quotes 1 and 3. Is there any reason for it? Am I reading it incorrectly, or my copy of the book contains an error? c. If you allow me I would like to make a supplementary question. In page 19, condition (b) of Formative Constructions states that ""(b) There is in the sequence an assembly B of the second species, preceding A , such that A is ¬B ."" What I understood is thus: there would be a B somewhere in the assembly, and after it, there would be a ¬B . Is this interpretation correct? Is 'B' a substantific sign, and '¬B' is relational? I am attaching pictures of both versions here. English French",['elementary-set-theory']
3677979,Using a solution to show no others are possible in positive odd integer,"If I have an equation say $$3(1+x+x^2)(1+y+y^2)(1+z+z^2)+1=4x^2y^2z^2 \quad (1)$$ and I know a non negative integer solution $x=4, y=64, z=262144$ then no odd positive integer solutions can possibly exist. I know that one way to show it for this example would be to compute but I am looking for a proof that does not rely on computation like using wolfram as I want to generalize this. I will happily award the bounty to anyone who can prove it.
What I have tried is minimal. I suppose that $p,q,r \in \mathbb N$ and they satisfy equation $(1)$ . I think if we let $p$ be the smallest integer of the solution $p<4$ is impossible so assume that $p\ge 5$ but this might lead to a contradiction since the coefficient of $4p^2q^2r^2 \quad $ is $4<5$ and that might be impossible?","['number-theory', 'derivatives', 'diophantine-equations']"
3677982,"How can I prove that I can assume $\sin{x}, \tan{x}$ to be x when $x \rightarrow 0$","I know the proof of $\lim_{x\rightarrow 0}{\frac{\sin{x}}{x}}=1$ and $\lim_{x\rightarrow 0}{\frac{\tan{x}}{x}}=1$ . However, I do not think that this means that I can change every $\sin{x}$ and $\tan{x}$ inside a limit to x and solve the problem, because the rule of limits can only be apllied if both limits exist, and it also does not mention anything about composite functions (for example $\sin{(\sin{(x)})}$ ) Is it possible to prove that every $\sin(x)$ and $\tan(x)$ can be canged into x no matter its location if $x\rightarrow 0$ Without Taylor Expansion","['limits', 'trigonometry', 'limits-without-lhopital']"
3678030,Sum of series with conditional convergence,"Sorry for this question, but for some reason I'm stuck on this for few hours already. Before I solved more complex ( I think ) problems, but can't solve this. The only thing I know that this series converge conditionally, but that is just thing you can tell immediately. ${ 1 + \frac{1}{2} + \frac{1}{3} - \frac{1}{4} - \frac{1}{5} - \frac{1}{6} + \frac{1}{7} +\frac{1}{8} + \frac{1}{9} - \frac{1}{10} - \frac{1}{11} - \frac{1}{12} + ... }$ I will be really grateful if someone at least give me hint how to do it. P.S. In task book where I got this problem it was said I need to use harmonic series partial sum formula, but I cannot find the way to use it here.","['conditional-convergence', 'harmonic-numbers', 'sequences-and-series']"
3678044,"Geometry, triangles, and lengths","I'm a highschooler and this is the question: ""In a right triangle $\triangle ABC$ , in which $\angle C = 90°$ and $\mid BC\mid < \mid AC \mid$ , a line was constructed to go through point $C$ and crossing the hypotenuse in point $D$ , $\mid AD\mid : \mid DB\mid = 2:1$ . Given that $\mid BC\mid = \sqrt3$ and $\angle DCB = 30°$ , calculate $\mid AB\mid$ ."" This is an image I have done to illustrate the question I have tried to do it through many ways in the last few hours, like using the cosin theorem, using areas, I have even tried constructing right triangles inside the $\triangle ABC$ scaled 1:3 and 2:3 with the original one, but nothing worked for me. Every time I fail on calculating $\mid CD\mid$ , and I might have done a calculational error. Can someone please help me? Sorry for any mistakes, this is my first post and English is not my first language.","['triangles', 'trigonometry', 'geometry']"
3678075,"Orthonormal basis of $L^2(0,1)$","Show that the only functions that satisfy $f''(\xi) = \lambda f(\xi)$ , $f'(0) = f(1) = 0$ , $\|f\|_2 = 1$ for some $\lambda \in \mathbb{R}$ are the functions: $$ \phi_n(\xi) = \sqrt{2}\cos\left(\frac{(2n-1)\pi}{2}\xi\right),  \quad n =1,2,\dots $$ thus making them an orthonormal basis of $L^2(0,1)$ It's obvious to me why this family of functions satisfy the conditions $f'(0) = f(1) = 0$ and $\|f\|_2 = 1$ . What confuses me is the constant $\lambda$ . I fail to see why for every $\lambda$ the solutions are $\phi_n$ . Won't positive $\lambda$ 's give exponential functions as solutions? It'd be very helpful if someone could elaborate on how this family of functions is yielded from the original equation $f''(\xi) = \lambda f(\xi)$ .","['calculus', 'orthonormal', 'ordinary-differential-equations']"
3678077,"Morphism between quotient sheaf ($K_{X}/\mathcal{O}_{X}$) and $\bigoplus_{x\in\mathcal{X}}i_{x,*}(K(X)/\mathcal{O}_{X,x})$","Consider an integral scheme $X$ of finite type over $k$ of dimension $1$ . Then $X$ consists of one generic point $\eta$ and the rest of the points are closed points. We call the set of closed points $\mathcal{X}$ . Let $K_{X}$ be the constant sheaf with value $K(X)(=\mathcal{O}_{X,\eta})$ . I want to show that the map $$K(X)\rightarrow \bigoplus_{x\in\mathcal{X}}K(X)/\mathcal{O}_{X,x}, \qquad [U,f]\mapsto ([U,f] + \mathcal{O}_{X,x})_{x\in\mathcal{X}}$$ is a well-defined map of $k$ -vectorspaces. Background information: By showing that this is a well-defined map of $k$ -vectorspaces one can actually show that the quotient sheaf $K_{X}/\mathcal{O}_{X}$ is isomorphic to the direct sum sheaf $\bigoplus_{x\in\mathcal{X}}i_{x,*}(K(X)/\mathcal{O}_{X,x})$ induced by the inclusion $i_{x}:\{x\}\rightarrow X$ . It is clear that this particular direct sum sheaf is flasque. We can thus find a canonical flasque resolution of $\mathcal{O}_{X}$ to compute the cohomology groups of $\mathcal{O}_{X}$ . Problems: 1. To show that this map is well-defined we need for every $[U,f]\in K(X)$ that for only finitely many $x\in\mathcal{X}$ , $[U,f]\neq 0$ . But I don't see why this has to be the case. 2 I struggle with the scalar multiplication inside $K(X)$ . I know that $\mathcal{O}_{X,\eta}\cong \mathcal{O}_{\operatorname{Spec}(R),\eta} = \operatorname{Frac}(R)$ for some finitely generated $k$ -algebra $R$ by the fact that $X$ is of finite type over $k$ . Thus $K(X)$ indeed is a field and has a $k$ -structure on it. But I don't understand the structure well enough to show (formally) that the map indeed preserves the scalar multiplication. Any help would be appreciated!","['algebraic-geometry', 'schemes', 'commutative-algebra']"
3678113,Trigonometry parametric equation $\sin(\sqrt {ax-x^2})=0 $,This is the hardest problem on Georgian (country) high school math exam. Find all values for parameter a for which the sum of all the roots of the equation $\sin(\sqrt {ax-x^2})=0 $ equal to 100.,"['trigonometry', 'parametric']"
3678174,Applying the Lambert W function for a new equation,"I am a physical chemist, and we are trying to model a simple process.  We ended up arriving at the following equation. \begin{align}
ax^{-7/2}e^{-bx(ln(cx)-1)}=1
\end{align} We'd like to solve for $x$ .  All constants ( $a$ , $b$ , $c$ ) are real, positive. a is on the order of 31 and b and c are on the order of the -3. I have found the following relationship from the following: (Edwards, https://arxiv.org/pdf/1902.08910.pdf ) \begin{align}
y=ax^be^{cx^d}+f
\end{align} Can be inverted into \begin{align}
x=\left[\frac{b}{cd} W\left(\frac{cd(y-f)^{\frac{d}{b}}}{ba^{\frac{d}{b}}}\right)\right]^{1/d}
\end{align} Where W is the Lambert W function. But obviously I have a $\ln(x)$ in the exponential function. We'd love to find a good expression for x, either exact, or approximate through expansion.  We can check it against a numerical solution. Any ideas?  Thanks all!","['functions', 'special-functions']"
3678230,Is this another definition for inverse relation?,"We know that if $R\colon A\to B$ , we can define the inverse relation as follows: $$R^{-1}=\{(y,x)\in B\times A\mid(x,y)\in R\}.$$ Now I want to know if this set, let's call it $R\:'^{-1}$ , is the same as $R^{-1}$ : $$R\:'^{-1}=\{(x,y)\in R\mid(y,x)\in B\times A\}.$$ I think $R^{-1}\neq R\:'^{-1}$ so I picked an example. I tried with $A=\{1,2\}$ , $B=\{3,4\}$ , so $B\times A=\{(3,1),(3,2),(4,1),(4,2)\}$ . Let's pick $R=\{(3,1),(4,1)\}$ . Then, by definition, $$R^{-1}=\{(1,3),(1,4)\}.$$ But if we look at the definition of $R\:'^{-1}$ , I think it says ""All the elements of $(x,y)\in R$ such that the pair $(y,x)$ is in $B\times A$ "". Hence, $R\:'^{-1}=\emptyset$ , because we know, for example, that $R$ has $x=3$ and $y=1$ , so $(3,1)\in R$ , but this proposition: $(y,x)=(1,3)\in B\times A$ is false. Thus $R^{-1}\neq R\:'^{-1}$ . Are my understanding of $R\:'^{-1}$ and counterexample correct?","['elementary-set-theory', 'solution-verification', 'relations']"
3678244,If series is absolutely convergent then $\sum \limits_{n\in I}a_n=\sum \limits_{k=1}^{\infty}\sum \limits_{n\in I_k}a_n.$,"Suppose that the series $\sum \limits_{n=1}^{\infty}a_n$ is absolutely convergent and let $I\subseteq \mathbb{N}$ such that $I=\bigsqcup\limits_{k=1}^{\infty}I_k$ . Then show that $$\sum \limits_{n\in I}a_n=\sum \limits_{k=1}^{\infty}\sum \limits_{n\in I_k}a_n. \qquad (*)$$ I don't have any idea how to solve it. I do know that in any absolute convergent series permutation of terms does not change the sum and I guess it should be used somehow in order to prove equality $(*)$ . Can anyone show the rigorous proof of equality $(*)$ , please?","['sequences-and-series', 'real-analysis']"
3678308,The worker with two bags problem.,"A worker carries two bags. Each of the bags initially contains N nails. Whenever the worker needs a nail, he takes it from a bag picked at random. At some point the worker picks an empty bag. Find the probability that the other bag contains exactly m nails. My reasoning: The desired probability: $C_2^1 \cdot P(|A| = 0\ and\ |B| = m)$ , where A, B - sets of nails in each bag.
Then we can ""divide"" this probability (I suppose that I deal with independent events): $P(|A| = 0\ and\ |B| = m) = P(|A| = 0) \cdot P(|B| = m);$ $P(|A| = 0) = (\frac{1}{2})^N$ , where $|A| = |B| = N$ (initial condition). $P(|B| = m) = (\frac{1}{2})^{N - m}$ Result: $C_2^1 \cdot P(|A| = 0\ and\ |B| = m)$ = $C_2^1 \cdot (\frac{1}{2})^{2N - m}$ Am I wrong or it is correct?",['probability-theory']
3678340,(geometric) intuition behind divisor class group,"I'm taking classes in algebraic geometry and riemann surfaces, and in both these classes the divisor class group of a (certain kind of) scheme/riemann surface $X$ is defined roughly by ""divisors mod linear equivalence"". I'm looking for a clear intuition/motivation for defining such a group $\text{Cl}(X)$ , because I can't really seem to find it anywhere. Any help is appreciated :)","['riemann-surfaces', 'divisors-algebraic-geometry', 'algebraic-geometry']"
3678343,$T_1$ spaces where the closure of a compact set is not compact,"I have many problems with this exercise: Give an example of $T_{1}$ Topological Space $(X,\tau)$ and a subset $Y\subset X$ compact such that $\bar{Y}$ is not compact. Now, honestly, I know this example: $X= A\sqcup B$ where $A$ and $B$ are infinite sets, and $\tau_{X} = \lbrace\emptyset\rbrace\cup\lbrace \mathcal{U}\in X\mid A\setminus\mathcal{U}$ is finite $\rbrace$ But I'd like to find other examples... the problem is that I don't know much Topologies $T_{1}$ but not $T_{2}$ ; I know Cofinite Topology and Zariski Topology but these examples don't work, I know that the Alexandroff extension of $\mathbb{Q}$ is $T_{1}$ but not $T_{2}$ , but I don't think that it's work. Can someone help me?","['general-topology', 'examples-counterexamples', 'compactness']"
3678402,What is a suitable Lyapunov function for this system?,"I have verified using the eigenvalue method that around $(0,0)$ the system \begin{align}\dot x&=y - 3x - x^3 \\ \dot y &= 6x - 2y \end{align} is stable. However, I have been trying to find a suitable Lyapunov function $V$ but from the expressions I have come up with so far, I cannot definitively deduce that the derivative is less than zero. I have tried the classical $V = x^2 + y^2$ and tried changing up the coefficients and exponents so that I can have some cancellations of the odd terms. It has been several hours now and still no luck. Any hints will be much appreciated.","['ordinary-differential-equations', 'lyapunov-functions', 'stability-in-odes', 'stability-theory', 'dynamical-systems']"
3678480,When is relative Hilbert scheme $\text{Hilb}_{X/S}^{p(t)}$ flat over $S$?,"Let $S$ be a scheme of finite type over the complex numbers $\mathbb{C}$ and let $X\subset S\times\mathbb{P}^r$ be a projective family over $S$ . In the book ""Geometry of Algebraic Curves Volume II"" by Arbarello, Cornalba and Griffiths, Chapter 1, Section 7 it is described how to construct the relative Hilbert scheme $\text{Hilb}_{X/S}^{p(t)}$ parametrizing pairs $(s,Y)$ of a points $s\in S$ and a subscheme $Y\subset X_s$ with Hilbert polynomial $p(t)$ . It is described as a closed subscheme of $S\times \text{Hilb}_r^{p(t)}$ so, in particular, it comes with a projection $\text{Hilb}_{X/S}^{p(t)}\to S$ . Now my question is, under which circumstances is $\text{Hilb}_{X/S}^{p(t)}$ flat over $S$ ? For example, is this true if $X$ is flat over $S$ ? In the specific example I'm trying to work out, $S=\mathbb{P}^N$ is the projective space parametrizing degree $d$ curves in $\mathbb{P}^2$ , $X\subset S\times\mathbb{P}^2$ is the universal family over $S$ and $p(t)\equiv n$ is constant, so the fiber of $\text{Hilb}_{X/S}^n$ over $[C]\in S$ is the Hilbert scheme of $n$ points in the curve $C$ . Is this true in this case?","['algebraic-curves', 'algebraic-geometry', 'flatness', 'schemes']"
3678534,What's the meaning of $\tilde{y}$?,"In Linear Algebra by Liesen, J. and Mehrmann, V. , the following notation is used: This chapter is about Maps in Set Theory. The authors explain the meaning of each symbol, nevertheless, they missed this one. I did some research in Wolfram Math World , but none of the examples of how the tilde is used throughout math seems promising for this example (at least none that I can make sense of). Here is a screenshot of where it is first used in the book:","['elementary-set-theory', 'notation']"
3678544,Proof using Fundamental Theorem of Calculus (Showing RHS = LHS),"Question: Prove that $\int^x_0\big[\int^u_0 f(t) dt\big] du = \int^x_0f(u)(x-u) du$ where $f$ is a continuous function. Attempt: My lecturer hinted that it'd be helpful to apply the fundamental theorem of calculus to $F(u) = u \int^u_0f(t) dt$ . I know that I can apply the FTC to $F(u)$ since $f$ is continuous, meaning it is also a Riemann integrable function and thus the conditions of the FTC are met. To find $F'(u)$ , I will let $G(u) = u$ and $H(u)=\int^u_0f(t) dt$ be functions such that $F(u)=G(u)H(u)$ . 
Thus, $G'(u)=1$ and, applying the FTC, $H'(u)=f(u)$ . Using the product rule, $F'(u)=G(u)H'(u)+G'(u)H(u)=uf(u)+\int^u_0f(t) dt$ . However, this is where I get stuck and am not sure how to use this to prove the initial equation. Any help would be greatly appreciated.","['integration', 'proof-writing', 'real-analysis', 'calculus', 'derivatives']"
3678565,How to find a function whose limit points identify $\mathbb{C}$ with a cylinder?,"I was considering the set of mobius transformations $$ \frac{a+bx}{c+dx} $$ A property they have is that if you consider any line $x(t) = e^{i\theta} t $ then: $$ \lim_{t \rightarrow \infty} \frac{a + bx(t)}{c+dx(t)} =  \frac{a+be^{i\theta}t}{c+de^{i\theta t}} = \frac{b}{d}  $$ Where curiously $\frac{b}{d}$ is COMPLETELY independent of $e^{i\theta}$ . In some sense the ""limit"" points of the mobius transformation, identify every direction with the same complex value, and you might even go as to say the ""limit points"" identify $\mathbb{C}$ as a sphere. All this obvious, but now suppose we turn the question around a bit, How do we find a complex function whose set of limit points identify something other than a sphere. The Question: I wanted to start with something simple like a cylinder. In this case we are trying to find a complex function $f$ such that if $\frac{\pi}{4} < s < \frac{3\pi}{4} $ Then: $$  \lim_{t \rightarrow \infty} f(e^{is}t) = f(e^{-is}t) $$ However we don't want over identification, that is for distinct $\frac{\pi}{4} < s < \frac{3\pi}{4} $ it should be that $\lim_{t \rightarrow \infty} f(e^{is}t)$ is distinct Moreover it also must be the case that any $s \in (-\frac{\pi}{4}, \frac{\pi}{4}) \cup (\frac{3\pi}{4}, \frac{5\pi}{4}) $ it should be that $  \lim_{t \rightarrow \infty} f(e^{is}t)  $ takes on unique values. A strategy: So, if we forget that we are working in $\mathbb{C}$ we can just consider the unit disk in $\mathbb{R}^2$ and from here find a function $f: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ which behaves in the expected way on the unit disk [identifying it with a cylinder]. Now the next step would be to find another function $g: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ whose limit points in each direction are the coordinates the unit circle corresponding to that direction. Then $f(g)$ is a function $\mathbb{R}^2 \rightarrow \mathbb{R}^2$ that behaves how we want and we just try our luck in checking if $f(g)$ obeys the Cauchy-Riemann Equations to give rise to a complex function.","['complex-analysis', 'multivariable-calculus']"
3678566,"Inverse Function Theorem for functions $f(x,y)$ and $\int\limits_0^1\frac{\partial f}{\partial x}(tx,y)dt$","I'm struggling with the following problem: Let $f\colon\mathbb{R}^2\to\mathbb{R}$ be a twice continuously
  differentiable function satisfying $$f(0,y)=0\mbox{ for
 all }y\in\mathbb{R}$$ (a) Show that $f(x,y) = xg(x,y)$ for all pairs $(x,y)\in\mathbb{R}^2$ ,
   where $g$ is the function given by $$g(x,y) =
 \int\limits_0^1\frac{\partial f}{\partial x}(tx,y)dt$$ (b) Show that $g$ is continuously differentiable and that for all $x\in\mathbb{R}$ $$g(0,y) = \frac{\partial f}{\partial
 x}(0,y),~\frac{\partial g}{\partial y}(0,y) = \frac{\partial^2
 f}{\partial x\partial y}(0,y)$$ (c) If $\frac{\partial f}{\partial x}(0,0)\neq0$ there is a
  neighborhood $V$ of $(0,0)$ in $\mathbb{R}^2$ such that $f^{-1}(0)\cap
 V = V\cap \{x=0\}$ (d) If $\frac{\partial f}{\partial x}(0,0) = 0$ and $\frac{\partial^2
 f}{\partial x\partial y}(0,0)\neq0$ there is a neighborhood $V$ of $(0,0)$ in $\mathbb{R}^2$ such that $f^{-1}(0)\cap V$ consists of the
  union of the set $V\cap\{x=0\}$ with a curve through $(0,0)$ , whose
  tangent at $(0,0)$ is not vertical (not parallel to the $y$ -axis) Here are my attempts: (a) Note that $\frac{\partial f}{\partial x}(tx,y) = \frac{t}{x}\cdot\frac{\partial f}{\partial t}(tx,y)$ and so using the integration by parts $$g(x,y) = \int\limits_0^1\frac{\partial f}{\partial x}(tx,y)dt = \int\limits_0^1 \frac{t}{x}\cdot\frac{\partial f}{\partial t}(tx,y)dt = \frac{1}{x}\left(f(x,y) - \int\limits_0^1 f(tx,y)dt\right)$$ it suffices to show that $\int\limits_0^1 f(tx,y)dt = 0$ , however, I can't see how to proceed with it. (b) Expressions for $g(0,y)$ and $\frac{\partial g}{\partial y}(0,y)$ is the result of a straightforward calculation using the definiton of $g(x,y)$ , but I have troubles showing that $g$ is continuously differentiable. What am I supposed to do -- prove that the partial derivatives exist and they are continuous? If so, can someone write down the details? (c) One can fix $y=0$ and consider a function $f(x,0)\colon\mathbb{R}\to\mathbb{R}$ . Then, since $\frac{\partial f}{\partial x}(0,0)\neq0$ , the Inverse Function Theorem says that there exists a neighborhood $U$ of $0\in\mathbb{R}$ such that $f\colon U\to f(U)$ is the bijection. Denote $V = U\times\{0\}$ , so $V\subset\mathbb{R}^2$ and we are done. Am I right here? (d) It seems like using the result of part (b) we can do the same trick with the function $g(0,y)\colon\mathbb{R}\to\mathbb{R}$ , but I can't finish the proof. Any help will be really appreciated. Thanks a lot in advance.","['derivatives', 'inverse-function-theorem', 'analysis', 'real-analysis']"
3678584,$\lim_\limits{x \to \infty} \frac1x \sum_\limits{n\leq x}\mu(n)=0 \iff$ Prime Number Theorem,"I'm reading Analytic Number theory from Tom. M. Apostol's Introduction to Analytic Number Theory.
In the fourth Chapter of the book he proves the equivalence of Prime number theorem with the asymptotic average of the Mobius function being zero. 
i.e $$\lim_\limits{x \to \infty} \frac1x \sum_\limits{n\leq x} \mu(n)=0 \iff \lim_\limits{x \to \infty} \frac{\pi(x)\log(x)}{x}=1  $$ I understand the formal working of the proof, but this beautiful statement seems to be unmotivated and out of the blue in the presentation of the text. It would be great if someone can explain me what led mathematicians to believe that the above statement is equivalent to the Prime number theorem.","['analytic-number-theory', 'number-theory', 'math-history', 'prime-numbers']"
3678585,Proof verification: Composition of maps is associative,"Theorem. Let $f: W \rightarrow X, g : X \rightarrow Y, h: Y \rightarrow Z$ be maps. Then (1) $h \circ ( g \circ f) = (h \circ g) \circ f$ , i.e., the composition of maps is associative. Proof is left as an exercise. My attempt: Proof: By definition of map composition $h \circ ( g \circ f) = (h \circ g) \circ f$ $h \circ (W \rightarrow Y) = (X \rightarrow Z) \circ f $ $W \rightarrow Y \rightarrow Z = W \rightarrow X \rightarrow Z$ $W \rightarrow Z = W \rightarrow Z$ $\blacksquare$ I'd like to know, if either the proof and the way of writing it are correct. Or, if there's a more elegant way to write the proof (if correct). Liesen, J., Mehrmann, V. 2015. Linear Algebra. Berlin, Germany.: Springer.","['elementary-set-theory', 'solution-verification']"
3678605,"Choosing one of each letter from a string of repeated ""ABCD""s such that it is in order of ""ABCD""","Question: Given a string of letters with $n$ repeated ""ABCD""s (ABCDABCD...ABCD n times), how many ways are there to choose one 'A', one 'B', one 'C' and one 'D' such that when the chosen letters are read left to right, it is in order of ""ABCD""? My solution: I considered the different ways we could choose the letter 'A', and then their respective possible combinations, and reduced the problem step by step with some logical deduction. Then transforming my logical reasoning into math expressions, I got this triple summation: $$\sum_{x=1}^{n}\sum_{y=1}^{n+1-x}\sum_{z=1}^{n+2-x-y}𝑛+3−𝑥−𝑦−𝑧$$ This result seemed to be correct when I tried it for small values of $n$ and when I plugged it into wolfram alpha, I found this equivalent form: $$\frac{1}{24}n(n+1)(n+2)(n+3)$$ And it seemed to not be a coincidence as there are $4$ letters and $4!=24$ . Therefore I think my approach to the problem isn't efficient enough and there is an easier approach, but I couldn't figure out how. Can someone explain why we can get such a ""combinatoric style"" result from an ugly summation and state a better and simpler method to arrive at the final result without going through the triple summation? Edit: The logical reasoning I used to get to the triple summation is that once the letter 'A' is chosen, we can ignore all other 'A's and we know that the 'B' that can be chosen must be on it's right. I reapeated this process for all the letters and arrived at the triple summation.","['algebra-precalculus', 'combinatorics', 'summation']"
3678612,Is the sequence $x_n=\dfrac{1}{\sqrt{n}}\left(1+\dfrac{1}{\sqrt{2}}+\dfrac{1}{\sqrt{3}}+\ldots+\dfrac{1}{\sqrt{n}}\right)$ monotone?,"Observe that $x_1=1$ and $x_2=\dfrac{1}{\sqrt{2}}\left(1+\dfrac{1}{\sqrt{2}}\right)>\dfrac{1}{\sqrt{2}}\left(\dfrac{1}{\sqrt{2}}+\dfrac{1}{\sqrt{2}}\right)=1$ . Thus, $x_2>x_1$ . In general, we also have $x_n=\dfrac{1}{\sqrt{n}}\left(1+\dfrac{1}{\sqrt{2}}+\dfrac{1}{\sqrt{3}}+\ldots+\dfrac{1}{\sqrt{n}}\right)>\dfrac{1}{\sqrt{n}}\left(\dfrac{1}{\sqrt{n}}+\dfrac{1}{\sqrt{n}}+\dfrac{1}{\sqrt{n}}+\ldots+\dfrac{1}{\sqrt{n}}\right)=1$ . Thus, $x_n\geq 1$ for all $n\in \mathbb{N}$ . Also, we have, $x_{n+1}=\dfrac{1}{\sqrt{n+1}}\left(\sqrt{n}x_n+\dfrac{1}{\sqrt{n+1}}\right)=\dfrac{\sqrt{n}}{\sqrt{n+1}}x_n+\dfrac{1}{n+1}$ . Is it true that $x_{n+1}>x_n$ ? Edit : 
Thanks to the solution provided by a co-user The73SuperBug. Proving $x_{n+1}-x_n>0$ is equivalent to proving $x_n<1+\dfrac{\sqrt{n}}{\sqrt{n+1}}$ . This is explained below : \begin{equation}
\begin{aligned}
&x_{n+1}-x_n>0\\
\Leftrightarrow & \dfrac{\sqrt{n}}{\sqrt{n+1}}x_n+\dfrac{1}{n+1}-x_n>0\\
\Leftrightarrow & \left(1-\dfrac{\sqrt{n}}{\sqrt{n+1}}\right)x_n-\dfrac{1}{n+1}<0\\
\Leftrightarrow & x_n<\dfrac{1}{(n+1)\left(1-\dfrac{\sqrt{n}}
{\sqrt{n+1}}\right)}\\
\Leftrightarrow & x_n<1+\dfrac{\sqrt{n}}{\sqrt{n+1}}.
\end{aligned}
\end{equation}","['riemann-sum', 'sequences-and-series']"
3678616,Does the set of real numbers with bounded partial quotients have positive measure?,"We say a real number $x$ has bounded partial quotients if its continued fraction expansion $[a_0; a_1, a_2 \cdots]$ is bounded by some constant $M=M(x)$ . The set $A$ consisting of those numbers whose partial quotients are bounded forms a dense, uncountable subset of $\mathbb{R}$ which includes the algebraic numbers of degree $\leq 2$ . It appears that it is an open problem whether or not $A$ contains any algebraic numbers of degree $>2$ . Question : Is it known whether or not the set $A$ has measure zero? The reason this question is interesting has to do with Diophantine approximation. We say a real number $x$ is badly-approximable if there exists a positive constant $C=C(x)$ such that $$\left|x-\frac{p}{q}\right|>\frac{C}{q^2}$$ for all rational $p/q \neq x$ . Here, the name fits, since for any irrational $x$ , $|x-p/q|<\frac{1}{q^2}$ for infinitely many pairs $(p,q)$ , and badly-approximable numbers are precisely those for which we cannot do better than this, i.e., merely scaling the numerator by a certain constant $C$ ruins everything. It turns out that the property defining the set $A$ discussed earlier (i.e., bounded partial quotients) is in fact completely equivalent to this property of being badly-approximable. Thus asking about the size of $A$ is essentially asking about the size of the set of worst-approximable real numbers.","['continued-fractions', 'diophantine-approximation', 'real-analysis']"
3678628,Can't understand the solution given on logical equivalence,"I'm working on this question:
Use Theorem 2.1.1 to verify the logical equivalence $∼(∼p ∧ q) ∧ (p ∨ q) ≡ p.$ I'm guessing that I either have a flawed understanding either about the distributive law or absorption law or both. These were my steps and was stuck: $∼(∼p ∧ q) ∧ (p ∨ q) ≡ (∼(∼p) ∨ ∼q) ∧ (p ∨ q)$ <--By De Morgan’s laws $≡ (p ∨ ∼q) ∧ (p ∨ q)$ <--by the double negative law $≡{ ( (p ∨ ∼q) ∧ p ) ∨ ( (p ∨ ∼q) ∧ q ) }$ <--By distributive law $≡{ p ∨ ( (p ∨ ∼q) ∧ q }$ <--By absorption law $≡{ p ∨ ( (q ∧ p) ∨ (q ∧ ∼q) ) }$ <--By distributive law $≡{ p ∨ ( (q ∧ p) ∨ 0 ) }$ <--By negation law $≡{ p ∨ (q ∧ p) }$ <--By identity law $=p$ <--By adsorption law (Edited after a comment, thus I have edited the question) The answer was: $∼(∼p ∧ q) ∧ (p ∨ q) ≡ (∼(∼p) ∨ ∼q) ∧ (p ∨ q)$ by De Morgan’s laws $≡ (p ∨ ∼q) ∧ (p ∨ q)$ by the double negative law $≡ p ∨ (∼q ∧ q)$ by the distributive law $≡ p ∨ (q ∧ ∼q)$ by the commutative law for ∧ $≡ p ∨ c$ by the negation law $≡ p$ by the identity law So my question how did the solution jump from $(p ∨ ∼q) ∧ (p ∨ q)$ to $p ∨ (∼q ∧ q)$ just using distributive law?","['logic', 'discrete-mathematics']"
3678666,Determining all $f : \mathbb R \to \mathbb R$ that satisfy $xf(x) - yf(y) = (x-y)f(x+y)$,"Determine all $f : \mathbb R \to \mathbb R$ that satisfy $$xf(x) - yf(y) = (x-y)f(x+y) ; \ \forall x , y \in \mathbb R$$ I tried reform the equation to $$f(x) + f(-x) = 2f(0)$$ and $$f(x) + f(3x) = 2f(2x).$$ Also, $f$ is injective if $f$ isn't constant. Can anyone give me some hints please. Thank you very much!","['contest-math', 'functional-equations', 'functions']"
3678736,Michael Spivak Calculus Limits problem proof verification,"I would like to know whether my answer to the following exercise problem in Calculus by Spivak is correct. The statement of the problem is: Prove that if $f(x)=x$ for rational $x$ , and $f(x) = -x$ for irrational $x$ , then $\lim_{x\to a}f(x)$ does not exist when $a\neq0$ My answer: Proof by contradiction: Let $\lim_{x\to a}f(x)=L$ Case 1: When $a > 0 $ , $\exists\  \delta > 0 $ such that $0<|x-a|<\delta \implies |f(x)-L|<a$ Let $x_1 \in \mathbb{Q}$ and $x_2 \in \mathbb{R-Q}$ such that $x_1,x_2 \in (a, a+\delta)$ , then $|f(x_1)-L|<a$ and $|f(x_2)-L|<a$ and hence by the triangle inequality we have $|f(x_1) - f(x_2)|=|f(x_1)-L-(f(x_2)-L)| \leq |f(x_1) - L| + |f(x_2) - L| < a + a = 2a$ Therefore we have $|f(x_1)-f(x_2)| < 2a$ But, $f(x_1)=x_1 > a$ and $f(x_2)=-x_2 < -a$ Therefore $f(x_1) - f(x_2) = x_1 + x_2 > 2a > 0 \implies |f(x_1) - f(x_2)| > 2a$ , a contradiction. The case when $a<0$ is very similar, we just set $\epsilon = -a$ in the definition of the limit and let $x_1,x_2 \in (a-\delta, a)$","['epsilon-delta', 'limits-without-lhopital', 'calculus', 'solution-verification', 'limits']"
3678792,Uniqueness of PDE via energy functional,"Assume the pde: $$
u_{tt}(t,x) = c^2u_{xx}(t,x) + \sigma u_{txx}(t,x) -\mu u_{t}(t,x), \quad x \in [0,L], t>0
$$ $$
u_x(t,0) = u(t,L) = 0
$$ $$
u(0,x) = \phi(x), u_t(0,x) = \theta(x), x\in[0,L]
$$ $$
\phi(L) = \theta(L) = 0, \phi'(0) = \theta '(0) = 0.
$$ and the energy functional: $$
V(t) = \int_{0}^L\frac12u_t^2(t,x) + \frac{c^2}{2}u_x^2(t,x)dx
$$ To prove uniqueness we'll assume $u_1$ , $u_2$ are both solutions and then define $u$ as $u := u_1 - u_2$ . Then, we observe that $$u(0,x) = u_1(0,x) - u_2(0,x) = \phi(x) - \phi(x) \equiv 0$$ $$u_t(0,x) = u_{1,t}(0,x) - u_{2,t}(0,x) = \theta(x) - \theta(x) \equiv 0$$ So $u_x(0,x) = u_t(0,x) = 0$ . Thus we have $$
V(0) = \int_0^L 0 \, dx = 0
$$ Also, I have already shown that $V(t) \leq V(0)$ so $$
V(t) \leq 0
$$ and since $V(t) \geq 0$ , we have $V(t) \equiv 0$ . Then since the integrand is non-negative: $$
\frac12u_t^2(t,x) + \frac{c^2}{2}u_x^2(t,x) \equiv 0 \quad \quad (1)
$$ Question: Does $(1)$ guarantee that $u \equiv 0$ and why?","['boundary-value-problem', 'calculus', 'partial-differential-equations']"
3678805,Is it true that a multivariate function is differentiable if it's components are?,"For example, if I had $f : \mathbb{R}^n \to \mathbb{R} = x_1^2 + x_2^2 + ... + x_n^2$ , would it follow that $f$ is differentiable from the fact that $g: \mathbb{R} \to \mathbb{R} = x^2$ is differentiable? Why?","['multivariable-calculus', 'derivatives', 'real-analysis']"
3678864,Example of a Riemann-integrable function and non-Borel-measurable,"It is known that if $f$ is Riemann integrable function then it is Lebesgue integrable, in particular $\ f:\left(\mathbb{R},\mathcal{L}\left ( \mathbb{R} \right),\lambda \right) \longrightarrow \mathbb{R}  \ \ $ is measurable. In the proof of this theorem the completeness of $\mathcal{L} \left ( \mathbb{R} \right)$ is important. My question: Is there any Riemann intagrable function $f:\left(\mathbb{R},\mathcal{B}\left ( \mathbb{R} \right), \lambda \right) \longrightarrow \mathbb{R}  \ \ $ wiche is not $\mathcal{B}\left ( \mathbb{R} \right)$ -measurable ? Note that $\mathcal{B}\left ( \mathbb{R} \right)$ is not complet with respect to $\lambda$ .","['measure-theory', 'riemann-integration', 'measurable-functions']"
3678982,Evaluate this limit involving e,"I am solving this limit, but cannot find a satisfactory solution: \begin{align}
\lim_{\alpha\to\infty}\frac{\ln(1+e^\alpha)}{\alpha} 
\end{align} I have tried substitution like $y = e^\alpha$ and $y = 1+ e^\alpha$ but nothing seems to work.","['limits', 'calculus', 'algebra-precalculus']"
3679002,Conditions for obtaining the characteristic function from MGF,"Notation used is taken from Gallager's text on stochastic processes. For a random variable $X$ , let $g_X(r)=\mathbb{E}[\exp(rX)]$ be its moment generating function where $r$ is a real number. Similarly, let $g_X(i\theta) = \mathbb{E}[\exp(i\theta X)]$ where $\theta$ is a real number and $i=\sqrt{-1}$ . In a footnote, the author warned that the notation is slightly dangerous because $g_X(i\theta)$ cannot be simply obtained from the MGF with $r=i\theta$ . So far, I have only used MGFs and characteristic functions for (jointly) Gaussian random variables, and for that class of rvs, the ""substitution"" seemed to be work, e.g. for $X\sim \mathcal{N}(0,\sigma^2)$ , the MGF is $g_X(r)=\exp(r^2 \sigma^2 /2)$ and the characteristic function is $g_X(i\theta)=\exp(-\theta^2 \sigma^2 /2)$ . My question is: for which random variables will using $r=i\theta$ on MGFs correctly give the characteristic function?","['moment-generating-functions', 'characteristic-functions', 'probability-theory', 'random-variables']"
3679005,What makes the elements of sigma algebra measurable (and measurable w.r.to which measure)?,"I'm familiar with the definition of sigma algebra defined over a set, which is a collection of subsets that is closed under countable unions and also under complements. While reading about probability theory, it was mentioned that by limiting ourselves to the sigma-algebra, we are avoiding some pathological behaviours caused by what are called as non-measurable sets. From the definition of sigma algebra, I don't see how it only consists of measurable sets. Is it an implication of the definition? If yes, how is it avoiding admitting non-measurable sets into sigma algebra? When they say measurable/non-measurable, what is the measure they are talking about? Lebesgue, counting, probability? It seems there is an implicit measure every time someone says a set is measurable/non-measurable. Can anyone give an example of a set which is measurable w.r.to one measure but not w.r.to another measure? How important is it to really worry about sigma algebras and measurable/non-measurable sets?
Most of the continuous distributions are defined on real line and almost every subset of real line that I can think of is a part of sigma algebra and has a definite measure on it.  It feels like these concepts are mostly used in definitions to have a concrete theory of probability. I don't remember needing any of those concepts while working with probability/random variables. Are these concepts only useful in developing further theory of probability?","['general-topology', 'probability-theory', 'measure-theory']"
3679128,Deducing function of two variables from its partial derivatives,"I am fighting with a very simple system of linear PDEs, which solution I think it is straightforward, however, I cannot write it down in a formal way. $$ \left\{ \begin{array}{c}
\frac{\partial X\left(x_{1},x_{2}\right)}{\partial x_{1}}=f\left(x_{1},x_{2}\right)\\
\frac{\partial X\left(x_{1},x_{2}\right)}{\partial x_{2}}=g\left(x_{1},x_{2}\right)
\end{array}\right. $$ I would like to write the solution as an integral of $f$ and $g$ . In this way I can also work out the boundary conditions. Can I write it as some sort of $X\left(x_{1},x_{2}\right)=\int\ ?\ dx_{1}\ dx_{2}+ Constant$ ? Just to give an idea, at the end, a boundary condition could be e.g. $X(x_1=0,x_2) = 0$ but I'd like to be general.","['linear-pde', 'multivariable-calculus', 'systems-of-equations', 'partial-differential-equations']"
3679144,Prove the following inequality $\sum_{i<j<k}\frac{a_ia_ja_k}{(n-2)(n-1)n}\le \bigg(\sum_{i<j}\frac{a_ia_j}{(n-1)n}\bigg)^2+\frac{1}{12}$,"For positive integer $n \ge 3$ , prove the following inequality $$\sum_{i<j<k}\frac{a_ia_ja_k}{(n-2)(n-1)n}\le \bigg(\sum_{i<j}\frac{a_ia_j}{(n-1)n}\bigg)^2+\frac{1}{12}$$ where $a_1+a_2+\cdots +a_n=0$ I noticed that $$(n-2)(n-1)n=6{n \choose 3}$$ and $$(n-1)n=2{n \choose 2}$$ After many arithmetics and research I got: $$(n-1)\sqrt[3]{\sum_{i<j<k}\frac{a_ia_ja_k}{n \choose 3}}+\sqrt{\frac{\sum a_i^2}{n}} \le \sum a_i =0$$ Does it help? Maybe after plugging them into the initial expression, it comes down to apply some famous inequalities that I don't know. Any help is greatly appreciated.","['uvw', 'summation', 'multivariable-calculus', 'symmetric-polynomials', 'inequality']"
3679155,Combinatorics - in how many ways question,"A store sells shirts, 3 different brands, 5 different sizes, 4 different colors. 
(Sizes and colors are similar to 3 brands, example: all brands have sizes from 1 to 5.) 1) How many ways a customer can buy 3 different shirts? 2) How many ways 3 customers can buy 3 shirts? (one shirt for each)? 3) How many 3 customers can buy 3 different shirts? (one for each)? Answers: 1) $C^{60}_3$ 2) $60^3$ 3) $P^{60}_3$ My question is: How can we distinguish which formula to use for each? how can we figure out when is order is important, or if there is a repeating ?","['combinations', 'combinatorics', 'discrete-mathematics']"
3679173,On the proof of classification of finitely generated abelian groups,"My question: How $K = d_1 \mathbb{Z} \times d_2 \mathbb{Z} \times \dots d_s \mathbb{Z}$ especially when ${\{x_1,x_2, \dots, x_n}\}$ is not a basis that we choose arbitrarilry, i.e. it is such a basis such that some basis of any subgroup of it to turn out to be of the form ${\{d_1 x_1,d_2 x_2, \dots, d_s x_s}\}$ ? Please help. Thanks! Added for clarity: I need rigorously prove $K = d_1 \mathbb{Z} \times d_2 \mathbb{Z} \times \dots d_s \mathbb{Z}$ which I can't.","['proof-explanation', 'abstract-algebra', 'normal-subgroups', 'group-theory', 'abelian-groups']"
3679218,Refinement of two stratifications of an algebraic variety,"Let $(X,\mathscr{O}_{X})$ be a separated $\mathbb{C}$ -scheme of finite type. A locally finite decomposition $X=\coprod_{i\in I}X_{i}$ into locally closed subschemes is said to be a stratification of $X$ , if each $X_{i_{0}}$ is smooth and for all $i_{0}\in I$ there exists a subset $I_{i_{0}}\subseteq I$ such that $\overline{X_{i}}=\coprod_{i\in I_{i_{0}}}X_{i}$ . Now given two such stratification $X=\coprod_{i\in I}X_{i}$ and $X=\coprod_{j\in J}Y_{j}$ of $X$ , one might wonder whether there exists a stratification $X=\coprod_{k\in K}Z_{k}$ refining both, i.e. each $X_{i}$ and each $Y_{j}$ is a union of some subsets $Z_{k}$ respectively. The most straightforward candidate seems to me to take the decomposition $X=\coprod_{i\in I,j\in J}X_{i}\cap Y_{j}$ into locally closed subsets. Is there any hope that $X_{i}\cap Y_{j}$ can be equipped with the structure of a locally closed subscheme of $X$ ? Here are my thoughts about this: If $\mathscr{I}$ and $\mathscr{J}$ is a quasi-coherent sheaf of ideals of $\mathscr{O}_{X}$ defining $X_{i}$ and $Y_{j}$ , one could try to prove that $\mathscr{I}+\mathscr{J}\subseteq\mathscr{O}_{X}$ is a quasi-coherent sheaf of ideal defining $X_{i}\cap Y_{j}$ . Now we can observe that $supp(\mathscr{O}_{X}/\mathscr{I}+\mathscr{J})\subseteq supp(\mathscr{O}_{X}/\mathscr{I})\cap supp(\mathscr{O}_{X}/\mathscr{J})=X_{i}\cap Y_{j}$ , but I don't see if the converse inclusion is true in general. Am I on the right track and if so, does anyone see how to continue?","['algebraic-geometry', 'schemes']"
3679238,Name for an intersection of open subset and closed subset,"Is there an established name for a subset of the form $U \cap V$ where $U \subset X$ is open and $V \subset X$ is closed? For example, locally compact subspaces of a locally compact Hausdorff space are exactly of this kind. If there are no existing names, I welcome suggestions for good names (in comments, because that does not fit the question-answer format).",['general-topology']
3679276,Expected number of people seated between A and B,"$N (\ge 3)$ people sit at a round table. Every seating is equiprobable. Among those people are $3$ called $A$ , $B$ and $C$ . Let $X$ be a number of people siting between $A$ and $B$ (on the arc which does not include $C$ ). What is the expected value and variance of $X$ ? I've tried some combinatorics, but I can't seem to stop overcounting.","['expected-value', 'combinatorics', 'variance', 'probability']"
3679288,Regarding evaluation of the limit of the sequence $\Bigl(\frac{1}{n}\Bigr)^n+\Bigl(\frac{2}{n}\Bigr)^n+ \cdots \Bigl(\frac{n}{n}\Bigr)^n$ [duplicate],"This question already has answers here : How to evaluate $ \lim \limits_{n\to \infty} \sum \limits_ {k=1}^n \frac{k^n}{n^n}$? (6 answers) Closed 4 years ago . The problem states as, Prove the sequence $$S_n= \Bigl(\frac{1}{n}\Bigr)^n+\Bigl(\frac{2}{n}\Bigr)^n+ \cdots \Bigl(\frac{n}{n}\Bigr)^n$$ converges to $\frac{e}{e-1}$ . A simple (possibly wrong) solution: We can  also write the sequence as $$S_n=\Bigl(\frac{n}{n}\Bigr)^n+ \Bigl(\frac{n-1}{n}\Bigr)^n+\Bigl(\frac{n-2}{n}\Bigr)^n+ \cdots +\Bigl(\frac{2}{n}\Bigr)^n+\Bigl(\frac{1}{n}\Bigr)^n$$ Where we just rearranged the terms of the sequence. Since the series $\lim \limits_{n \to \infty} S_n$ is absolutely convergent, the rearrangement will not affect the value of the limit. Now by passing the limit to $S_n$ $$\lim \limits_{n \to \infty}S_n=\lim \limits_{n \to \infty}\Bigl(\frac{n}{n}\Bigr)^n+ \lim \limits_{n \to \infty}\Bigl(\frac{n-1}{n}\Bigr)^n+\lim \limits_{n \to \infty}\Bigl(\frac{n-2}{n}\Bigr)^n+ \cdots $$ or, $$\lim \limits_{n \to \infty}S_n=1+e^{-1}+e^{-2}+\cdots$$ or, $$\lim \limits_{n \to \infty}S_n= \frac{e}{e-1}$$ Why I'm considering it wrong: I know the basic limit theorem $\lim(X_1+X_2)=\lim X_1+\lim X_2$ and by mathematical induction, the theorem is true for sum of any finite number of $X_n$ 's. However, the theorem does not hold good if $n \to \infty$ . For example, let us take a sequence $$a_n= \frac{1}{n^2}+\frac{2}{n^2}+\cdots \frac{n}{n^2}$$ Where $\lim\limits_{n \to \infty}a_n=\frac{1}{2}$ , although if we take limit term by term in the summand (i.e expression of $a_n$ ), we would get $\lim\limits_{n \to \infty}a_n=0$ . Now coming back to our original sequence of concern, it is fairly easy to show that $\lim\limits_{n \to \infty}S_n \leq \frac{e}{e-1}$ , since the function $f(x)=\Bigl(1-\frac{k}{x} \Bigr)^x$ is monotonically increasing $\forall x \geq 1$ and $\forall k \in \Bbb N$ . Now we got somehow to show $\lim\limits_{n \to \infty}S_n \geq \frac{e}{e-1}$ , in order to use the squeeze theorem to get the desired result.  However, I'm unable to make any significant progress to find the same.
So my questions are, i) How to show $\lim\limits_{n \to \infty}S_n \geq \frac{e}{e-1}$ or what can be some alternate method to find the desired limit of the sequence? ii) Moreover, are there any general results when $\lim(X_1+X_2+ \cdots) = \lim X_1+ \lim X_2+ \cdots$ holds even when the number of terms in the summand are infinity?","['limits', 'sequences-and-series', 'real-analysis']"
3679294,Edge-chromatic numbers of infinite vertex transitive graphs,"Let $\Gamma$ be an infinite locally-finite and vertex-transitive graph. This means all vertices are of the same finite degree, say $d$ . This means that, following Vizing's theorem, all finite subgraphs of $\Gamma$ can be edge-coloured by at most $d+1$ colours. Now using Erdos - de Bruijn theorem we see that actually $\Gamma$ itself can be edge-coloured by at most $d+1$ colours. My question is the following. Is there an example of a connected infinite locally-finite vertex transitive graph $\Gamma$ such that all vertices in $\Gamma$ have degree $d$ but the edge chromatic number of $\Gamma$ is $d+1$ , meaning that $\Gamma$ cannot be edge-coloured by $d$ colours?","['graph-theory', 'group-theory']"
3679317,Coupon collector with arbitrary duplicates,"What is the expected number of tickets in the coupon collector's problem where duplicates are allowed, but some tickets have a different, arbitrary number of duplicates required until the collector's job is finished? Example: Pool of five different tickets where each ticket has their own number of duplicates: $1, 2, 4, 6, 7$ tickets each. So having only one of each ticket is not enough, but specific tickets need multiple. Of course, each ticket still has the same probability to draw throughout.","['coupon-collector', 'probability']"
3679331,How to derive the probability density function (PDF) of a continuous random variable from a set of data?,"I am interested to derive an expression for the probability density function (PDF) of a continuous random variable from a given set of data. To further explain, let us consider that we have the data of time spent by visitors to a web page for a 24 hours period. At certain hours, say during the busy hours of day, the time spent on the web page is short. However, in the afternoon the time spent is long. I would like to derive an expression for the PDF of the continuous random variable X representing the time spent by the visitor, such as, $$
f_X(x)=
\begin{cases} 
24x-x^2, \quad x > 0\\
0, \quad\quad\quad\quad \text{otherwise.}
\end{cases}
$$ This is only an assumed PDF. I have tried to search but did not find an appropriate answer to this question. Most of the books on probability teach you how to derive probability values when given a PDF and all other sorts of things. However, the PDF is always given or assumed. So, my questions are: Do we always assume or try to map a suitable PDF from the set of popular distributions, such as Gaussian, exponential, log normal and so on for a given set of data? If yes, is there any standard way to do this? Is it possible to derive a mathematical equation for the PDF of the random variable from a given set of sample data? If yes, how this could be done? Is there any branch of Statistics and Probability Theory dealing with this? I would much appreciate any answers to these questions. Pointers to any resources or books or chapters will also be helpful. Thanks in advance for help.","['statistics', 'random-variables', 'probability-distributions', 'sampling', 'density-function']"
3679351,Determine the number of homomorphisms from $S_{3} \rightarrow \Bbb Z_{2} \times \Bbb Z_{4}$.,"Determine the number of homomorphism from $S_{3}  \rightarrow \Bbb Z_{2} \times \Bbb Z_{4}$ . My attempt: A homomorphism from $S_{3}  \rightarrow \Bbb Z_{2} \times \Bbb Z_{4}$ is a homomorphism into an abelian group. Therefore, ${\rm hom}(S_{3},\Bbb Z_{2} \times \Bbb Z_{4})= {\rm hom}\left(\frac{S_{3}}{[S_{3},S_{3}]},\Bbb Z_{2} \times \Bbb Z_{4}\right)$ , where $[S_{3},S_{3}]$ is the normal subgroup of $S_{3}$ generated by the elements of the form $aba^{-1}b^{-1}$ and $[S_{3},S_{3}]=A_{3}$ . ${\rm hom}(S_{3},\Bbb Z_{2} \times \Bbb Z_{4})= {\rm hom}(\Bbb Z_{2},\Bbb Z_{2} \times \Bbb Z_{4})$ . Next my idea is to calculate the number of elements in $\Bbb Z_{2} \times \Bbb Z_{4}$ whose order is divisible by 2. I get 4 elements of order 4, 3 elements of order 2, and one element of order 1. Anyone can please suggest to me, is this direction correct to think this question?","['group-homomorphism', 'group-theory', 'abstract-algebra']"
3679425,Find a closed surface for which $\iint_S \textbf{F} \cdot d\vec{S}$ is negative.,"$\text{div}\textbf{F} = x^2+y^2+1$ . Find a closed surface for which $$\iint_S \textbf{F} \cdot d\vec{S}$$ is negative or otherwise state why it's not possible. $\textbf{My attempt}$ : If $S$ and $D$ are a domain such that $\textbf{F}$ is continuous and differentiable on $S \cup D$ , then by the divergence theorem: $$\iint_S \textbf{F} \cdot d\vec{S} = \iiint_D  x^2+y^2+1 \ dV $$ The integral on the right is always positive and therefore there exists no such surface $S$ for which the flux integral becomes negative. Can anyone confirm that my approach is correct? Also, what if $S \cup D$ has singularities? Can we use the extended form of the divergence theorem: $$\iint_S \textbf{F} \cdot d\vec{S} = \iint_{S'} \textbf{F} \cdot d\vec{S} +\iiint_{D'}  x^2+y^2+1 \ dV $$ and conclude that there may exist such a surface for which $$\iint_S \textbf{F} \cdot d\vec{S} < 0$$ $S'$ encloses the singularity.","['divergence-theorem', 'multivariable-calculus', 'calculus', 'vector-analysis']"
3679491,Manifold that's not $\aleph_1$-separable,"I know that there are manifolds that are not separable, such as the long line $\omega_1 \times [0, 1) \setminus \{(0, 0)\}$ . Is there any manifold with no uncountable dense set of cardinality $\aleph_1$ ? A line $\omega_2 \times [0, 1) \setminus \{(0, 0)\}$ wouldn't work since no neighborhoods of $(\omega_1, 0)$ are homeomorphic to $\mathbb{R}$ . Would something else work?","['manifolds', 'general-topology', 'cardinals']"
3679540,Counting a walk $i \rightarrow j \rightarrow k \rightarrow j \rightarrow l \rightarrow j$ in a graph,"This paper gives a procedure for counting redundant paths (which I will refer to as walks ) in a graph using its adjacency matrix. As an exercise, I want to count only the walks of the form $i \rightarrow \color{blue}j \rightarrow k \rightarrow \color{blue}j \rightarrow l \rightarrow \color{blue}j$ from node $i$ to node $j$ , with $ i \neq j \neq k \neq l$ . Also see this post . Let $A$ be the adjacency matrix. The notation I use below is: "" $\cdot$ "" for usual matrix multiplication, "" $\odot$ "" for element-wise matrix product, ""d $(A)$ "" for the matrix with the same principal diagonal as $A$ and zeros elsewhere, and $S = A \odot A^T$ . The matrix for $i \rightarrow \color{blue}j \rightarrow k \rightarrow \color{blue}j \rightarrow l \rightarrow \color{blue}j$ will have its $i$ , $j$ entry: $a_{ij}\cdot a_{jk}\cdot a_{kj}\cdot a_{jl}\cdot a_{lj}$ . I have found this to be: $$
A \cdot (d(A^2))^2
$$ However, $i \rightarrow \color{blue}j \rightarrow k \rightarrow \color{blue}j \rightarrow l \rightarrow \color{blue}j$ also includes the following walks which repeat undesired nodes and should be subtracted: $$
\color{red}i \rightarrow j \rightarrow \color{red}i \rightarrow j \rightarrow l \rightarrow j \tag{1} $$ $$ \color{red}i \rightarrow j \rightarrow k \rightarrow j \rightarrow \color{red}i \rightarrow j \tag{2} $$ $$ i \rightarrow j \rightarrow \color{red}k \rightarrow j \rightarrow \color{red}k \rightarrow j \tag{3} $$ $$\color{red}i \rightarrow j \rightarrow \color{red}i \rightarrow j \rightarrow \color{red}i \rightarrow j \tag{4} $$ My calculations for $(1) - (4)$ are: $$ S \cdot \text{d}(A^2) \tag{1} $$ $$ \text{d}(A^2) \cdot S \tag{2} $$ $$ A \cdot \text{d}(A^2) \tag{3} $$ $$ S \tag{4} $$ Every time one of $(1) - (3)$ is subtracted, $(4)$ is subtracted as well, since it is included in all three. Since it is not desired in the end, it is added back 2 times. Overall: $$ A \cdot (d(A^2))^2 - S \cdot \text{d}(A^2) - \text{d}(A^2) \cdot S - A \cdot \text{d}(A^2) + 2S$$ However, this is wrong and gives incorrect counts, even negatives. What am I missing here?","['graph-theory', 'adjacency-matrix', 'matrices', 'combinatorics', 'discrete-mathematics']"
3679547,"When calculating integrals, why replacing factorials with $\Gamma$ so often works?","There are lots of definite integrals that depend on a parameter $n \in \mathbb N$ and whose result contains factorials of $n$ or some simple functions of it. For instance, $$ \int\limits_{-\infty}^\infty \frac{\mathrm{d} x}{(1+x^2)^n} = \pi \frac{(2n-2)!}{2^{2n-2} [(n-1)!]^2} \qquad (n \in \mathbb N),$$ but there are loads and loads of similar ones. Now let's say we allow $n$ to be a real number instead of a natural number. It looks like that in most of those cases, it's enough to replace the factorials with gamma functions, giving generalizations like $$ \int\limits_{-\infty}^\infty \frac{\mathrm{d} x}{(1+x^2)^\alpha} = \pi \frac{\Gamma(2\alpha-1)}{2^{2\alpha-2} \Gamma(\alpha)^2} \qquad (\alpha \in \mathbb R),$$ and a quick numeric integration for a couple of $\alpha$ shows that this could be correct. And if it works, then it will work for complex $\alpha$ as well. The question(s): Why this works so often? Obviously the integral should depend on $\alpha$ continuously, so it makes sense to replace the factorial with some function that extends it continuously. However there are many of those. What's so special about $\Gamma$ that those integrals seem to generalize only to expressions with $\Gamma$ and not with any other possible factorial extension? I know that $\Gamma$ is the only factorial extension that is log-convex, but I can't see how it connects to this. Would anybody be able to show a counterexample where this simple replacement with $\Gamma$ 's fails? Is there any theorem that would give conditions for this to work? Thanks!","['integration', 'definite-integrals', 'analysis']"
3679574,"Ranks of $\mathbb{Z},\mathbb{Q}$ and $\mathbb{R}$","We have the following definitions of the rank of a set in the von Neumann hierarchy: $$\mathrm{rank}(x)=\sup\{(\mathrm{rank}\,y)^+:y\in x\}.$$ I now want to find the ranks of $\mathbb{Z},\mathbb{Q}$ and $\mathbb{R}$ . $\mathbb{Z}$ can be realised as a subset of $2\times \omega$ , each element having finite rank (regardless of implementation details like pairing method). Hence I get that the rank of $\mathbb{Z}$ is $\omega$ as well. Similarly, $\mathbb{Q}$ can be thought of as a subset of $\mathbb{Z}\times \mathbb{Z}$ , and again, regardless of implementation details, each element in this set has finite rank, hence I get that the rank of $\mathbb{Q}$ is $\omega$ . We construct $\mathbb{R}$ as subsets of $\mathbb{Q}$ (e.g. the lower part of Dedekind cuts), the relevant subsets having rank $\omega+1$ . Hence the rank of $\mathbb{R}$ as defined like this is $\omega+2$ . My questions are: Some other answers seemed to suggest that the ranks of $\mathbb{Z}$ and $\mathbb{Q}$ depend on implementation details - however, with the argument above, I find this hard to see. So are the ranks both $\omega$ in most cases, or have I missed something? Is it true that, defined like this, the rank of $\mathbb{R}$ is $\omega+2$ ? Other relevant links: The real numbers and the Von Neumann Universe Rank of $\mathbb Z$ and $\mathbb Q$",['elementary-set-theory']
3679601,"Why does the Wronskian satisfy $W(yy_1,\ldots,yy_n)=y^n W(y_1,\ldots,y_n)$?","The Wronskian of smooth functions $y_1,\ldots,y_n$ is defined by the determinant $$W(y_1,\ldots,y_n):=\det \left(y_i ^{(j)}\right).$$ It can be verified by a messy induction that the Wronskian satisfies the identity $$W(yy_1,\ldots,yy_n)=y^n W(y_1,\ldots,y_n)$$ for every smooth function $y$ . What is a conceptual proof of this fact? Why should we ""expect"" the result to be true? Note that it is not just multiplying each column by the same scalar. There are many cross-terms coming from the Leibnitz rule for derivatives. For example, $n=2$ is the assertion $$yy_1(yy_2)'-yy_2(yy_1)'=y^2(y_1y_2'-y_2y_1').$$ The Wronskian has intuitive meaning as the volume spanned by solutions to an ODE of order $n$ after converting it to a system of first-order equations. The identity is true for all functions that are differentiable $n-1$ times, but giving a proof just in the case that they solve an ODE will also be great.","['determinant', 'wronskian', 'ordinary-differential-equations']"
3679673,"Hoeffding for bounded random variables, extension of Rademacher case","In Vershynin's High-Dimensional Probability , he first proves the Hoeffding bound on page 17 $$\mathbb{P}\left\{\sum_{i=1}^N a_iX_i \geq t\right\} \leq \exp \left(
 -\frac{1}{2} \frac{t^2}{\|a\|^2_2} \right)$$ for $X_i$ being Rademacher random variables and $(a_1, \dotsc, a_N) \in \mathbb{R}^N$ . Then he gives an exercise to extend it to bounded random variables. Exercise 2.2.7 : Prove that for $X_i$ independent and bounded, where $m_i \leq X_i \leq M_i$ almost surely, we have for any $t \geq
 0$ , $$\mathbb{P}\left\{ \sum_{i=1}^N (X_i - \mathbb{E}X_i) \geq t \right\}
 \leq \exp\left( -\frac{2t^2}{\sum_{i=1}^N (M_i - m_i)^2} \right)$$ perhaps with some absolute constant other than 2 in the tail. I'm not seeing what he wants here. Is he perhaps saying to compare it to a sum of linearly translated sum of Rademacher variables? He doesn't explicitly say to use the Rademacher case, but I assume that's what he means. It looks like he wants $a$ to be a vector in the $M_i - m_i$ , translating the Rademacher random variables. What I'm missing is how to link the general bounded case to the translated-Rademacher case. To be clear, I am aware of other proofs of Hoeffding for the bounded case; I am interested in a simple-ish way to leverage the linear-combination-of-Rademacher case to get this result.","['statistics', 'large-deviation-theory', 'asymptotics']"
3679707,Expected maximum of beta random variables,"Let $Y = \max_i X_i$ where $X_i \sim \text{Beta}(\alpha_i, \beta_i)$ independently. What is $\operatorname*{E} Y$ ? Let $[\cdot]$ denote the CDF of a random variable at $x$ . Since $Y \geq 0$ , \begin{align}
\operatorname*{E} Y
&= \int_0^\infty (1 - [Y]) \,\mathrm{d}x \\
&= \int_0^1 (1 - [Y]) \,\mathrm{d}x \\
&= 1 - \int_0^1 [Y] \,\mathrm{d}x \\
&= 1 - \int_0^1 \left[\max_i X_i\right] \,\mathrm{d}x \\
&= 1 - \int_0^1 \prod_i [X_i] \,\mathrm{d}x \\
&= 1 - \int_0^1 \prod_i I_x(\alpha_i, \beta_i) \,\mathrm{d}x \\
\end{align} where $I_x$ is the regularized incomplete beta function . Is there a closed form for this integral, perhaps in terms of transcendental functions?","['statistics', 'definite-integrals', 'probability-distributions', 'expected-value', 'beta-function']"
3679761,"Which field property enables us to multiply on both sides by the same value, while preserving equality? [duplicate]","This question already has answers here : Is there a law that you can add or multiply to both sides of an equation? [duplicate] (9 answers) Closed 4 years ago . I am currently reading through Rudin's Principles of Mathematical Analysis and I am learning about fields and their properties. Note that this is the initial chapter - I am just starting off. I was wondering which field property enables us to multiply on both sides of an equation and still preserve equality. There is a very clear proposition stated in the book that gives me this for inequalities: $$
\text{If} \ \ x > 0 \ \ \text{and} \ \ y < z \ \ \text{then} \ \ xy<xz.
$$ However, the only proposition that seems useful for this in the case of equalities, is stated as an implication and not an equivalence: $$
\text{If} \ x\not= 0 \ \ \text{and} \ \ xy=xz \ \ \text{then} \ \ y=z.
$$ Any help would be much appreciated.","['field-theory', 'real-analysis']"
3679879,Probability - Book with typos problem,"In a book, $250$ printing errors are randomly and independently distributed on $500$ pages. What is the probability that there will be at least three printing errors on page $317$ ? Is binomial distribution a good way to tackle this problem? My second idea was to use Poisson distribution to approximate the probability. What is the better approach? Any help would be much appreciated.","['probability-distributions', 'probability']"
3679957,A homogeneous cubic polynomial with no non-trivial zero over $\mathbf{F_7}$,"I met a problem in class which I cannot solve: Find a homogeneous cubic polynomial of three variables $x, y, z$ that has no non-trivial zero over $\mathbf{F_7}$ . Homogeneous cubic polynomial means each monomial term of the polynomial has degree 3. I do not have many thoughts and just attempted with trials but did not have any right candidate. I know the third power of any element in $\mathbf{F_7}$ is $\pm 1$ or $0$ so I tried to consider the sum of three cubic elements like $(x-y)^3+(x+z)^3+(y+z)^3$ but none of them worked. Is there any systematic way to approach it? Any hint or thought is appreciated!","['number-theory', 'abstract-algebra', 'algebraic-geometry']"
3680009,On some Hahn-Banach equivalents,"This question is about some equivalents of the Hahn-Banach theorem in $\textsf{ZF}$ set theory. As far as I know, the definitive reference for this sort of thing is Howard & Rubin's Consequences of the Axiom of Choice , which I refer to below. (The Hahn-Banach theorem is ""Form 52"" in the book.) The starting point of my questions about this topic is the following equivalent of Hahn-Banach: [52D] Let $\mathcal B_0$ be a subalgebra of a Boolean algebra $\mathcal B$ , and let $m_0$ be a real-valued finitely additive probability measure defined on $\mathcal B_0$ . Then there is a real-valued finitely additive probability measure $m$ that is an extension of $m_0$ from $\mathcal B_0$ to $\mathcal B$ , and the range of $m$ is contained within the closed convex hull of $m_0$ . The first question I had is: To what extent are abstract Boolean algebras necessary in [52D]? In particular, if we require only that [52D] hold for Boolean algebras of subsets, as in [52?] below, does the equivalence with Hahn-Banach still hold? In case you are tempted to appeal to Stone's representation theorem here, note that that theorem is stronger than Hahn-Banach, so we are not free to invoke it. There are known measure-theoretic equivalents of Hahn-Banach that don't require abstract Boolean algebras. For instance: [52C] For every nonempty set $X$ and every proper ideal $\mathcal I$ over the powerset of $X$ , there is a real-valued finitely additive probability measure $m$ defined on every subset of $X$ such that $m(I)=0$ for every $I \in \mathcal I$ . Now, [52C] is clearly implied by the conjunction of [A] For every nonempty set $X$ and every proper ideal $\mathcal I$ over the powerset of $X$ , there is a real-valued finitely additive probability measure $m$ defined on $\mathcal A(\mathcal I)$ such that $m(I)=0$ for every $I \in \mathcal I$ , where $\mathcal A(\mathcal I)$ is the algebra of subsets of $X$ generated by $\mathcal I$ and [52?] For every set $X$ , every algebra $\mathcal A_0$ of subsets of $X$ , and every real-valued finitely additive probability measure $m_0$ on $\mathcal A_0$ , there is a real-valued finitely additive probability measure $m$ that is an extension of $m_0$ from $\mathcal A_0$ to the powerset of $X$ . But it seems to me that [A] is a theorem of $\textsf{ZF}$ . Indeed, every set in $\mathcal A(\mathcal I)$ is of the form $$\bigcup_{i=1}^n\bigcap_{j=1}^{m_i}A_{ij},$$ where every $A_{ij}$ is in $\mathcal I$ or its complement is. Thus, setting $m(I)=0$ for all $I \in \mathcal I$ uniquely determines a 0-1 valued probability measure on $\mathcal A(\mathcal I)$ . If that's right, then [52?] implies [52C]. And clearly [52D] implies [52?]. So [52?] is actually equivalent to Hahn-Banach, even though it looks quite a bit weaker than [52D]. Final questions: Is this reasoning correct? If so, is there a reference for this result (it seems very likely that it's been noticed before, if true)?","['measure-theory', 'functional-analysis', 'axiom-of-choice', 'hahn-banach-theorem', 'set-theory']"
3680101,Leapfrogs puzzle -- Least number of moves needed to interchange the pegs,"This is a question from the book ""Thinking Mathematically"" by Burton and Mason. Question: Ten pegs of two colors are laid out in a line of 11 holes as shown below. I want to interchange the black and white pegs, but I am only allowed to move pegs into an adjacent empty hole or to jump over one peg into an empty hole. Find the minimum number of moves necessary to make the change and generalize it to a case where there are $2n+1$ holes. Related thread: There's an existing thread here that already explains as to why it takes $n^2+2n$ moves to make the change which is something I easily figure out on my own. Please note that in that thread, a peg can move over another peg only if it is of the opposite color whereas the problem in the book does not stipulate that condition. I made the same assumption to arrive at the answer. The part that I'm stuck with is to show that there can't be any other strategy where it takes less than $n^2+2n$ moves to make the change. Assume for instance that I represent a black peg by 'B', a white peg by 'W', and the hole by 'H'. I assumed that the number of moves involves interchanging 'B' and 'H', and then moving the pegs in only one direction towards the destination. However, how can I show, that it is never possible to have a pattern like 'BBH' changing to a 'HBB' so that the black peg moves by two holes towards its destination? This way, it can further reduce the number of steps needed. My hunch is that with a pattern like 'HBB', any 'W' stuck to the right of the black pegs will remain there unless the black peg is made to move left, which effectively nullifies the advantage of having moved two steps to the right. However, this explanation is very loose. What if there are no white pegs to the left of the black peg in the 'HBB' part of the board? More importantly, how can I make it mathematically rigorous that there should never be a pattern like 'HBB' or 'WWH' during the process of transformation assuming the 'B's and 'H's need to be moved further to reach the goal? My failed approaches and current thought process: Such problems, from my past experience, have a slick solution where some invariant or a monovariant is used to prove the optimality of the algorithm. I tried many but I simply could not go anywhere with it. Another strategy is the same as that used in the Tower of Hanoi solution, which is an inductive argument, where you show that there's is an algorithm to make the optimal transformation in the $2n+1$ case, by using the optimal transformation in the $2n-1$ case, and there is no way around it. This seems possible as I was able to prove the number of moves needed to make the transformation is $n^2+2n$ using this strategy. However, it would be simply fantastic to figure out as to why we can never get a pattern like 'HBB' or 'WWH' assuming that both the pegs need to be further moved in order to reach the final goal. I would greatly appreciate it if you can provide the argument for me.","['recreational-mathematics', 'puzzle', 'combinatorics', 'algorithms']"
3680110,Summation of nonnegative numbers over countably infinite set,"Suppose that $T_1,T_2\subset \mathbb{N}$ and $a_i\geq 0$ . I need to prove that $$\sum \limits_{i\in T_1\cap T_2}a_i+\sum \limits_{i\in T_1\cup T_2}a_i=\sum \limits_{i\in T_1}a_i+\sum \limits_{i\in T_2}a_i.$$ I do not know how to prove this fact at all because I even don't know what is the definition of $\sum \limits_{i\in K}a_i$ for $K\subset \mathbb{N}$ . I will highly appreciate if someone will explain my questions, please! EDIT: Also I assume that $\sum \limits_{I\in T_1}a_i<\infty,\sum \limits_{I\in T_2}a_i<\infty$ and as I said above $a_i\geq 0$ .",['sequences-and-series']
3680146,"Prove or disprove: If $\sum a_n$ converges conditionally, then $\sum n^2 a_n$ diverges","Intuitively my guess is that the statement is true but i've struggled to find a way to show it rigorously. The reason I believe it to be true is since $\sum n^2 a_n$ converging seems like a ""strong"" condition and for some obvious candidates that satisfy this (e.g. $\sum \frac{1}{n^4}$ ), $\sum n^2 a_n$ converging usually meant that that $\sum a_n$ converges absolutely. This line of thought led me to attempting to prove the contrapositive instead; that if $\sum n^2a_n$ converges, then $\sum a_n$ converges absolutely (and thus not conditionally).
I've tried to show this using the Cauchy criterion, which eventually brought me to attempting to prove the following inequality: $$|a_{n+1}| + |a_{n+2}| + \cdots + |a_m| \le |(n+1)^2a_{n+1} + \cdots + m^2a_m|$$ For $m > n \ge N$ for some $N \in \mathbb{N}$ but i've struggled to make meaningful progress past this point. My main issue with the inequality above being that I don't have any guarantee that each of the terms $a_n$ have the same sign, which made it difficult to work with the expression on the right. Is there something fundamentally wrong with my line of thought above? Any hints on how I might better approach the problem would be really appreciated.",['real-analysis']
3680186,Show that $( A \setminus B) \oplus C = ( A \oplus C) \oplus ( A \cap B)$,"Use any method you wish to verify the following identities: $( A \setminus B) \oplus C = ( A \oplus C) \oplus ( A \cap B)$ I chose to define $( A \oplus C) = \psi$ , $( A \cap B) = \phi$ , and $(A \setminus B) = \pi$ , trying to break down the expression; expression now looks like $ \pi \oplus C = \psi \oplus \phi$ . LHS--abitrary choice-- \begin{align*}
\pi \oplus C &:= (\pi \setminus C) \cup ( C \setminus \pi) \\ &\equiv (x \in \pi \wedge \neg (x \in C)) \vee ( x \in C \wedge \neg ( x \in \pi)) \\ &\equiv ( x \in A \wedge \neg (x \in B) \wedge \neg (x \in C)) \vee( x \in C \wedge \neg (x \in A \wedge \neg ( x \in B))) .
 \end{align*} Now the RHS: \begin{align*}
\psi \oplus \phi :=&( \psi \setminus \phi) \cup ( \phi \setminus \psi) \\ &\equiv ( x \in \psi \wedge \neg( x \in \phi)) \vee ( x \in \phi \wedge \neg ( x \in \psi)) \\ 
&\equiv ((((x \in A \wedge \neg ( x \in C)) \vee ( x \in C \wedge \neg( x \in A))) \wedge \neg ( x \in A \wedge x \in B)) \vee ((( x \in A \wedge x \in B) \wedge \neg ( x \in A \wedge \neg ( x \in C)) \vee ( x \in C \wedge \neg( x \in A))
\end{align*} I stopped here. I tried looking at ways to simplify the LHS and RHS, but I didn't see anything. Did I make a mistake somewhere? or am I not recognizing a way to simplify? If you decide to reply, could you reply with a similar method like the one I tried using? Thanks, for future refrence.","['elementary-set-theory', 'logic']"
3680328,Is the partial derivative of a constant always zero?,"I'm trying to get my head round using the multivariable chain rule to find exact derivatives. For example I want to find the exact derivative(using partial derivatives) of, $$r^2=x^2+y^2$$ Where r is initially a constant. I now assign $f(x,y)=r^2$ , then it follows $$\frac{\partial f}{\partial x}=2x, \frac{\partial f}{\partial y}=2y$$ Then from the multivariable chain rule, $$\frac{df}{dx}=\frac{\partial f}{\partial x}*1 + \frac{\partial f}{\partial y} \frac{dy}{dx}$$ Now I substitute in what is known and can simplify to reach the answer, $$0=2x+2y\frac{dy}{dx} \ \ \ \ \ (*)$$ This leads to the correct answer, but I'm certain that my reasoning must be wrong. In $(*)$ , I asserted that $\frac{dr^2}{dx}=0$ , which is obvious. However, does this not also mean that the partial derivatives must be 0 instead of $2x$ , $2y$ ? It does not make any intuitive sense to me how the partial derivative of a constant can be non-zero, and I am certain this cannot be the case.","['partial-derivative', 'multivariable-calculus']"
3680334,"If $f$ is uniformly continuous on two open sets with a non-empty intersection, then $f$ is uniformly continuous on their union","There is a problem when I am solving this question:- Suppose $a<b<c<d$ . Prove that if $f$ is uniformly continuous on $(a,b)$ and on $(c,d)$ then $f$ is uniformly continuous on $(a,b)\cup(c,d)$ . I solve the question like this: $\forall \epsilon>0$ . As $f$ is uniformly continuous on A, then $\exists\delta_1>0\ni\forall x,y\in (a,b),|x-y|<\delta_1\implies|f(x)-f(y)|<\epsilon$ Also, $f$ is uniformly continuous on (c,d), then $\exists\delta_2>0\ni\forall x,y\in (c,d),|x-y|<\delta_2\implies|f(x)-f(y)|<\epsilon$ Take $\delta$ = $\min(\delta_1,\delta_2),\forall
x,y\in(a,b)\cup(c,d),|x-y|<\delta\implies |f(x)-f(y)|<\epsilon$ . But when I see the solution, it is given as Take $\delta$ = $\min(\delta_1,\delta_2, c-b)$ .
  Then $\forall x,y \in (a,b)\cup(c,d)$ , $|x-y|<\delta \implies x,y \in (a,b) \text{ or } x,y \in (c,d),\text{ and } |x-y|<\delta_1\text{ and }\delta_2$ $\implies|f(x)-f(y)|<\epsilon$ $\therefore f$ is uniformly continuous on $(a,b)\cup (c,d)$ . But why they take $c-b$ in the expression of $\delta$ ? And how does it guarantee that $x,y\in(a,b)$ or $(c,d)$ not something like $x\in(a,b)$ and $y \in (c,d)$ or vice versa? Why we can't take $x\in(a,b)$ and $y\in(c,d)$ to prove uniform continuity on $(a,b)\cup(c,d)$ ?","['proof-explanation', 'uniform-continuity', 'real-analysis']"
3680383,A theorem of Lutz about the structure of the points of an elliptic curve over a finite extension of $\mathbb{Q}_p$,"Reading the article of Greenberg ""Iwasawa Theory for Elliptic Curves"", he cites (p.13) a theorem of Lutz that says: Theorem: Let $E/K$ be an elliptic curve defined over a finite extension $K$ of $\mathbb{Q}_p$ . Then \begin{equation}
E(K)\cong \mathbb{Z}_p^{[K : \mathbb{Q}_p]}\times U
\end{equation} as a group, with $U=E(K)_{tors}$ finite. I couldn't find this theorem in books or on the internet. Anyone knows some references or a proof?","['elliptic-curves', 'abelian-varieties', 'number-theory', 'p-adic-number-theory', 'local-field']"
3680392,Proving that $F(x)=\sum\limits_{k=1}^{p-1}\left(\frac{k}{p}\right)x^k$ has at least $\frac{p-1}{2}$ different complex roots,"Let $p$ be odd prime number. Show that $$F(x)=\sum_{k=1}^{p-1}\left(\frac{k}{p}\right)x^k$$ has at least $\dfrac{p-1}{2}$ different complex roots $z$ with $|z|=1$ ,
where $\left(\dfrac{k}{p}\right)$ is Legendre's symbol. I try: since $F(1)=\sum\limits_{k=1}^{p-1}\left(\dfrac{k}{p}\right)=0$ ,so $1$ is a one complex root in $M:=\{z\mid z\in \mathbb C,\ |z|=1\}$ . If $p\equiv 1\pmod 4$ , then we have $$F'(1)=\sum_{k=1}^{p-1}k\left(\frac{k}{p}\right)=\sum_{k=1}^{p-1}(p-k)\left(\frac{p-k}{p}\right)\\
=(-1)^{\frac{p-1}{2}}\sum_{k=1}^{p-1}(p-k)\left(\frac{k}{p}\right)=-(-1)^{\frac{p-1}{2}}F'(1).$$ Since $p\equiv 1\pmod 4$ , so we have $F'(1)=0$ . But I can't continue solving this problem.","['number-theory', 'polynomials']"
3680397,"A Combinatorics Question: Why Is My Solution Wrong, And The Given Solution Correct?","I have encountered this problem: ""A circular table has 60 chairs around it. There are N people seated at this table so that the next person seated must sit next to someone. Find the smallest possible value of N"". I'm struggling to understand why my solution is wrong, and why the given solution is correct. My proof is, given N people, if we leave 1 seat to the left of each person blank, then no one has to sit next to each other, however the next person who sits has to sit next to someone. We then proceed to find the number of people this arrangement will need. Since the number of occupied and unoccupied seats must add up to 60, 2N=60. Therefore, N = 30 people can be seated. However, the solution given is 20. The explanation is ""If every third seat is occupied, filling 20 seats, then every unoccupied seat has a person sitting next to it, so N could be 20. To see that N must be at least 20, note that any seating which satisfies the conditions cannot contain a gap of more than 2 unoccupied seats between any occupied seats. If we regard adjacent
occupied seats as having a gap of 0 between them, every seating of N people contains N gaps, all of which must be less than 2. Thus N+2N = 3N is at least as big as the sum of N and all the which is 60, therefore 3N ≥ 60 and N ≥ 20.Note that there are simpler arguments that work when there are 60 seats around the table, but this proof has the advantage of working just as well when the number of seats is not a multiple of 3 (e.g. for 59 seats N must still be at least 20
since 3N ≥ 59, and for 61 seats 3N ≥ 61 implies N ≥ 21)."" I don't understand why my reasoning is false, and why their reasoning is correct. Could someone explain this to me? Thanks in advance.","['proof-explanation', 'combinatorics']"
3680507,"How to use the Lie derivative to ""perform"" a parallel transport along a curve","Setup Consider a metric, for example that of a sphere with fixed radius $R$ , i.e. $$ds^2 = R^2 d\theta^2 + R^2\sin^2\theta^2d\varphi^2,$$ and a curve on that sphere $\gamma = (\theta_0, \varphi)$ , where $\theta_0 = const.$ and $\varphi\in[0,2\pi)$ , together with a vector $X_0=(X^\theta_0,X^\varphi_0)$ . I can parallel transport this vector and in this specific example even determine its components at every specific point of the curve (for a derivation see Section 2 of these lecture notes ), with the result $$
\begin{aligned} 
X^{\theta}(\varphi) &=X_{0}^{\theta} \cos \left(\varphi \cos \theta_{0}\right)+X_{0}^{\varphi} \sin \theta_{0} \sin \left(\varphi \cos \theta_{0}\right), \\ 
X^{\varphi}(\varphi) &=X_{0}^{\varphi} \cos \left(\varphi \cos \theta_{0}\right)-\frac{X_{0}^{\theta}}{\sin \theta_{0}} \sin \left(\varphi \cos \theta_{0}\right). 
\end{aligned}
$$ My Question: In an exam I was asked to reproduce the above result using the Lie derivative. I think the principle behind this is to use the fact that the Lie derivative can be seen as the infinitesimal generator of the push-forward, since by definition $$(L_YT)_p := \left.\frac{d}{dt}(\varphi_{-t}^*T_{\varphi_t(p)})\right|_{t=0},$$ if $Y$ is the vector field which generates the flow $\varphi_t$ . Intuitively I would say that one can now take the above vector $X$ and just ""push it forward"" using the Lie derivative in the direction of the curve, i.e. in the direction of the vector field $\frac{d\gamma}{dt} = (0, d\varphi/dt)$ . The issue is that I don't really know how one is supposed to do that explicitly. How exactly do I act with the Lie derivative on $X$ and what am I supposed to do with this expression? Side note: It's been a while since the exam, so I had time to think about the problem. Unfortunately I don't really see how this is supposed to work. I always thought of parallel transport and Lie derivative as two distinct things that each on their own have applications for certain problems.","['transport-equation', 'lie-derivative', 'differential-geometry']"
3680523,Rigorous proof of surface area formula,"The surface integral over surface $S$ (which is given by $z=f(x,y)$ , where $(x,y)$ is a point from the region $D$ in the $xy$ -plane) is: $$ \iint\limits_{S} g(x,y,z)\ dS = \iint\limits_{D} g(x,y,f(x,y))\ {{\sqrt {\,{{\left[ {{f_x}} \right]}^2} + {{\left[ {{f_y}} \right]}^2} + 1} \,dA}}$$ Does there exist a rigorous proof of this formula in real analysis.","['real-analysis', 'jacobian', 'multivariable-calculus', 'calculus', 'multiple-integral']"
3680610,Double Integral $(x^2+y^2)$ over region $x^4+y^4 \le 1$,"I have calculus exercise to calculate double integral of function $f(x)=x^2+y^2$ over the area enclosed inside curve $x^4+y^4=1$ . I have tried with polar coordinates: $$
\iint_D f(\phi,r)r \,d \phi\,dr = 4\int_{0}^{\pi/2} \int_{0}^{[1/(\cos^4\phi+\sin^4\phi)]^{1/4}} r^3 d\phi dr
$$ Although this seems to be the right way (I get the right result with Wolfram Mathematica), it leads to the integral $$
\int_{0}^{\pi/2}\frac{dx}{\cos^4x+\sin^4x}
$$ which I don't know how to easily execute. I was wondering if there is any trick to use diferent new coordinate systems or integration by substitution? Is there any general trick to integrate a function ower the area of this curve, because it appears quite often in exercises?","['integration', 'multivariable-calculus']"
3680650,"Given $\phi$ a mapping. Prove that for each $\mathit{i}$, $\sum_{j=1}^n \partial_{x_j}(\mathbf{cof} \mathit{D} \phi)_{ji} \equiv 0$","Let $\phi \in \mathit{C}^2 (\mathbb{R}^n , \mathbb{R}^n)$ . Let $\mathbf{cof} \mathit{D} \phi$ be the cofactor of $\mathit{D} \phi$ (the Jacobian matrix of $\phi$ ). i.e. $$(\mathbf{cof} \mathit{D} \phi)_{ij} =(-1)^{i+j}*(\mathit{D} \phi)_{ji}$$ where $(\mathit{D} \phi)_{ji}$ is the determinant of the submatrix of $\mathit{D} \phi$ obtained by deleting the $\mathit{j}$ th row and $\mathit{i}$ th column. Prove that for each $\mathit{i}$ , $$\sum_{j=1}^n \partial_{x_j}(\mathbf{cof} \mathit{D} \phi)_{ji} \equiv 0$$ I tried many ways, but all failed. And I think this problem may have something to do with closed differential forms, but I can't give a proof.","['partial-derivative', 'jacobian', 'multivariable-calculus', 'differential-forms']"
3680689,"When will the sequence $x_i = g^{x_{i-1}} \mod p$, $p$ prime, repeat?","Assume the following sequence: $$x_i = g^{x_{i-1}} \mod p$$ where $p$ prime, $g$ is a generator of the group $\mathbb{Z}_p^*$ , and $x_1 \in \mathbb{Z}_p^*$ (sequence starts with $x_1$ ). I want to know for which $i$ , does the sequence start to repeat? I assume that somehow depends on the order of $g$ (which is $p-1$ , correct?) but I could not figure out in which way exactly, since I worked through a few examples and it seems to be lower than the order of $g$ . How would I go about solving this problem? Edit It was pointed to me in the comments that the sequence might repeat if it ""returns"" to a previous value. I amended the question.","['group-theory', 'discrete-mathematics', 'sequences-and-series']"
3680732,"Solving the system $a_1\sin x_1+b_1\cos x_2=c_1$, $a_2\cos x_1+b_2\sin x_2=c_2$","Does the following system of equations have a closed-form solution? If so, how can I solve it? $$\begin{align}
a_1\sin(x_1) + b_1\cos(x_2) &= c_1 \\
a_2\cos(x_1) + b_2\sin(x_2) &= c_2
\end{align}$$ where $a_1$ , $a_2$ , $b_1$ , $b_2$ , $c_1$ and $c_2$ are constants. (I'm not looking for numerical solution.)","['trigonometry', 'systems-of-equations']"
3680736,Non continuous solutions to $f(\lambda x)=f(x)$,"I know that the only continuous solutions to the equations $f(x)=f(\lambda x)$ for $x\in[0,1],\lambda\in(0,1)$ where $\lambda$ is given - are the constant functions. Are there non trivial solutions which are not equivalent to some constant function in $L^2[0,1]$ ?","['functional-equations', 'functional-analysis']"
3680740,Solving $\sin(4k-22) = \cos(6k-13)$,"My niece asked for help with an SAT prep question. We are given that $$\sin a = \cos b$$ where the angles are both acute and $a=4k-22$ and $b=6k-13$ . The only way we could think to solve it is by plotting and using fzero. But since it's an SAT problem, I assume there should be an approach that doesn't require a calculator. Is there some trig identity I'm overlooking?",['trigonometry']
3680759,Finding $\liminf\limits_{ r \to 1^{-}}$ and $\limsup\limits_{ r \to 1^{-}} \sum\limits_{k=0}^\infty (-1)^k r^{2^k}$,"In an answer last year to another question , I implicitly asserted as an aside that that $\lim\limits_{r \to 1^-} \sum\limits_{k=0}^{\infty} (-1)^k r^{2^k}$ seemed empirically to be close to $\frac12$ .  I now think that there is not a limit, but that there are a limit inferior and a limit superior.  So my question here is about finding $$\liminf\limits_{ r \to 1^{-}} \sum\limits_{k=0}^\infty (-1)^k r^{2^k} \text { and }\limsup\limits_{ r \to 1^{-}} \sum\limits_{k=0}^\infty (-1)^k r^{2^k}$$ Empirically, I now think the limit inferior seems to be about $0.497250779$ and approached when $r$ is close to $1-\frac{0.6982}{2^{2n}}$ for increasing integers $n$ the limit superior seems to be about $0.502749221$ and approached when $r$ is close to $1-\frac{0.6982}{2^{2n+1}}$ for increasing integers $n$ If it helps, the terms of the series can be made positive with $\sum\limits_{k=0}^{\infty} (-1)^k r^{2^k} = \sum\limits_{m=0}^{\infty} r^{4^m}\left(1-r^{4^m}\right)$ Is there an analytical method for finding these values?","['limsup-and-liminf', 'sequences-and-series']"
3680790,Deformations of K3 surface is again a K3 surface,"I define a $K3$ surface as a smooth complex manifold of dimension two which is simply-connected and such that the canonical bundle is trivial. I know that two $K3$ surfaces are always deformation equivalents and I know that $K3$ surfaces are Kähler.
Conversely, if a deformation $X$ of a $K3$ surface is Kähler, then Hodge structure is preserved so $X$ is again simply-connected, and the symplectic form on the $K3$ surface extends to $X$ so the canonical bundle of $X$ is trivial too. Hence $X$ is a $K3$ surface. How about non-Kähler deformations of a $K3$ surface? If they exists they aren't $K3$ surfaces, but do they exists? Thank you!","['k3-surfaces', 'algebraic-geometry', 'deformation-theory', 'kahler-manifolds']"
3680799,Poisson bracket of function of coordinates in terms of canonical brackets,"Suppose that we work with a general Poisson structure where we are given the Poisson brackets of the individual coordinates. In practise, how would we be able to use these to determine the Poisson bracket of some more complicated function of the coordinates? To illustrate the question let us work with coordinates $ (x, y, z ,t) $ . Suppose we are given the relations $ \{ x, y \} = a, \{z, t \} = b $ for some constants $ a $ and $ b $ and all brackets other than permutations of the above are taken to be zero. Define the functions $ F = x^2 + y^2 + z^2 + t^2 $ and $ G = e^{(x-y)^2} + e^{(z-t)^2} $ - how would we go about calculating $ \{F, G \} $ ? Since we are only given the abstract definition of the Poisson bracket, we cannot use the standard approach that applies to functions on phase space and must only proceed from the axioms (bilinearity, skew symmetry, Jacobi identity and the Leibniz property). In the case that the given functions are polynomials in the coordinates I imagine we could repeatedly apply the Leibniz rule to eventually express $ \{ F, G \} $ in terms of the given brackets but I can't see how to proceed in the more general case other than attempting to express everything in terms of power series - this definitely doesn't seem like the most elegant approach to take...","['classical-mechanics', 'dynamical-systems', 'lie-algebras', 'differential-geometry']"
3680802,Solutions to differential equation $\nabla f(x)=f(x)x$,"Let us consider the differential equation  given by $\nabla f(x)=f(x)x$ , where $f:\mathbb{R}^n\to \mathbb{R}$ . I have found that $f(x)=K\exp(|x|^2/2)$ is a solution, but are all solution of this form?","['ordinary-differential-equations', 'real-analysis', 'linear-pde', 'functional-analysis', 'partial-differential-equations']"
3680803,"True or false: $\frac{\mathrm d}{\mathrm dx}(\int _2^{\:e^x}\:\ln t \,dt)=x-\ln 2$. Support with a proof","True or false: $\frac{d}{dx}(\int _2^{\:e^x}\:\ln t \,dt)=x-\ln 2$ . Support with a proof I think it is false. I used the Fundamental Theorem of Calculus: $$\int _2^{\:e^x}\:\ln t\,dt\:=\:\int _0^{e^x}\ln t\:-\:\int _0^2\ln t\,dt$$ The second integral $\frac{d}{dx}\left(\int _0^2\ln t\right)dt=\ln 2$ The first integral $\frac{d}{dx}\left(\int _0^{e^x}\ln t\:\right)=\frac{d\left(e^x\right)}{dx}\frac{d}{d\left(e^x\right)}\int _0^{e^x}\ln t\:=e^xx$ Combining the terms $$\frac{d}{dx}\left(\int _2^{\:e^x}\:\ln t\,dt\:\right)=e^xx-\ln 2,$$ I saw the solution of the same question on a website , and its answer is different from mine. Is my solution wrong?","['integration', 'calculus', 'solution-verification', 'derivatives']"
