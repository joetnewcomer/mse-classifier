question_id,title,body,tags
915372,Generating Functions and Linear Diophantine Inequalities,"The following exercise is from Analytic Combinatorics by Philippe Flajolet and Robert Sedgewick, page 46. A $k$-composition of $n$ is an ordered $k$-tuple of non-negative integers whose sum is $n$. Consider the class $\mathcal{F}$ of compositions of integers into four summands $(x_1, x_2, x_3, x_4)$ such that
  $$ x_1 \ge 0, \, x_2 \ge 2 x_1, \, x_3 \ge 2 x_2, x_4 \ge 2 x_3,$$ 
  where the $x_j$ are in $\mathbb{Z}_{\ge 0}$.The ordinary generating function is
  $$F(z) = \dfrac{1}{(1 − z)(1 − z^3)(1 − z^7)(1 − z^{15})}.$$ Generalize to $r \ge 4$ summands and a similar system of inequalities. Work out elementarily the OGFs corresponding to the following systems of inequalities:
  $$\{x_1+x_2 \le x_3\},\,\, \{x_1 + x_2 \ge x_3\},\,\, \{x_1+x_2 \le x_3 + x_4\}, \,\,\{x_1 \ge x_2, x_2 \ge x_3,x_3 \le x_4\}.$$
  More generally, the OGF of compositions into a fixed number of summands (in $\mathbb{Z} \ge 0$), con- strained to satisfy a linear system of equations and inequalities with coefficients in $\mathbb{Z}$, is rational; its denominator is a product of factors of the form $(1 − z^j)$. I am looking for help developing a systematic approach to determine the generating functions of these types of inequalities. I have tried working out the first two, and my proposed OGF's are respectively $$\dfrac{1}{(1-z)(1-z^2)^2}$$
and
$$\dfrac{1 + z + z^2}{(1-z)(1-z^2)^2}$$ However, I did not use the so-called symbolic method , instead I looked at a few elementary cases and then reasoned about what the coefficients should be in a combinatorial manner. If you are experienced with generating functions, I would truly appreciate any insight you could shed on these problems. Even if you approach the problem differently than Sedgewick, but can still give combinatorial interpretations of each of the generating functions corresponding to the above restricted partitions, I would accept your answer. All I really want is help building intuition on this subject. Thank you.","['analytic-combinatorics', 'generating-functions', 'diophantine-equations', 'combinatorics']"
915373,"Evaluate the integral $\iiint\limits_E x^2 \,\, \mathrm{d}V$","Where E is the region bounded by the xz-plane and the hemispheres $y=\sqrt{9-x^2-z^2}$ and $y=\sqrt{16-x^2-z^2}$. This is an exercise from my professor guide. What I tried so far: These exercise is obviously easier using spherical coordinates, with that in mind I've come up with the following limits: $
3 \le \rho \le 4 \\
0 \le \phi \le \pi \\
0 \le \theta\ \le \pi
$ That is, the sphere cap formed by the 2 semi-spheres, more or less the volume described between the 2 surfaces in the image: With the limits already established, I constructed the following integral: $\int_0^\pi \int_0^\pi \int_3^4 \, \cos^2{(\theta)} \sin^3{(\phi)} \, \rho^4 \,\, \mathrm{d}\rho \, \mathrm{d}\phi \, \mathrm{d}\theta$
$= \frac{1562}{15}\pi$ However, the solution tha appears in the guide says that the result is: $\frac{3124}{15}\pi$ Is there anything I'm doing wrong? I checked the exercise twice and I get the correct result IF I set the limits of $\theta$ from $0$ to $2\pi$, but that is the whole spherical surface not just the half described by the exercise. Best regards,
Daniel Rivas.","['multivariable-calculus', 'integration', 'definite-integrals', 'volume', 'spherical-coordinates']"
915375,"About a Property of maximal solutions of separable ODE's $y'=g(x)h(y)$ for locally Lipschitz $h : U\to\mathbb R$, $U$ open","Theorem: Let $\varphi : (a,b) \to \mathbb R$ be a maximal solution of the IVP
$$
 y'(x) = g(x) \cdot h(y(x)), \quad y(x_0) = y_0 \quad (1)
$$
with continuous functions $g : I \to \mathbb R$ and $h : U \to \mathbb R$ with open intervals $I, U$ and $(x_0, y_0) \in I \times U$. Let $h : U \to \mathbb R$ be locally Lipschitz-continuous. If $b$ is not the right endpoint of the interval $I$, then there exists for every $\beta < b$ and every compact set $K \subseteq U$ a $\xi \in (\beta; b)$ with $\varphi(\xi) \notin K$. An analogous result holds for the left endpoint $a$ of $I$. Said differently: If $(a,b) \ne I$, then $\varphi$ leaves every compactum, or if all values of $\varphi$ are contained in a compact set, then $\varphi$ is defined on the whole interval $I$. I know that the IVP (1) has, in a sufficiently small open interval around $x_0$, a solution (existence result), and further if $h : U \to \mathbb R$ locally Lipschitz, then on every interval around $x_0$ the IVP (1) has at most one solution (uniqueness result). Also a solution $\varphi : (a,b) \to \mathbb R$ of the IVP (1) is called maximal , if for every other solution $\psi : (\alpha, \beta) \to \mathbb R$ we have: i) $(\alpha,\beta) \subseteq (a,b)$ and ii) $\psi(x) = \varphi(x)$ for $x \in (\alpha,\beta)$. For $h : U \to \mathbb R$ locally Lipschitz, then it has at most one maximal solution. In my textbook the following picture is given: And below it is written that all those solution curves go from ""boundary to boundary"", meaning the property mentioned in the above Theorem. But as I understand it, the lowermost curve does not fulfills the property, because it's ""range"" is contained in a compact set, or have I misunderstood something? I am still a little bit intimidated by this Theorem; for what is it used, what is its essential meaning? Has anybody examples or something for illustration? In my textbook after this Theorem the chapter closes and nothing more is mentioned... Thanks!","['dynamical-systems', 'ordinary-differential-equations', 'intuition', 'analysis', 'functional-analysis']"
915394,"Solve $dX_t = (\sqrt{1+X_t^2} + \frac{1}{2}X_t) \, dt + \sqrt{1+X_t^2} \, dW_t$ explicitly","Solve explicitly the 1-dimensional equation: $dX_t = (\sqrt{1+X_t^2} + \frac{1}{2}X_t)dt + \sqrt{1+X_t^2}dW_t$ I have hopelessly been guessing solutions to this. Does anyone know how to solve this or, more importantly, know a good general approach for attacking something like this? Thanks","['stochastic-processes', 'probability-theory', 'stochastic-calculus', 'probability', 'stochastic-differential-equations']"
915420,Every non-empty subset of the integers which is bounded above has a largest element.,"I was reading a proof about every non-empty subset of the integers which is bounded above
has a largest element, but i have troubles in one step. Here is the proof: Since $S$ is a non-empty subset of $\mathbb{Z}$(hence $\mathbb{R}$) which is bounded above,
by the supremum property $sup S$ exists. Let $w=supS$, then we have to show that $w \in S$, so we suppose $w \notin S$, then we have $w-1<w$, then exists $m\in S$ such that $w-1<m<w$(here is my problem, why can we take $m\in S$ such that happens? we are in $\mathbb{Z}$, so that does not happens). Then he takes $n\in S$ such that $w-1<m<n<w$. The inequality $n<w$ implies that $-w<-n$, and $w-1<m$, if we add up both inequalities we have $-1<m-n$ implies $n-m<1$, then $0<n-m<1$ which is a contradiction because there are no integers between $0$ and $1$
Can anybody explains me if that step is right?? How can I prove this if there is a problem with that step?
Thanks!","['elementary-set-theory', 'calculus', 'algebra-precalculus', 'abstract-algebra']"
915434,Is this a valid proof of $(A∧B’) ∧C↔(A∧C) ∧B’$?,"So I am supposed to prove $(A∧B’) ∧C↔(A∧C) ∧B’$ using wffs and equivalence rules. I have never done such proof, and I want to check if my steps are correct. This assignment is only graded based off of completion, but I want to be sure I am understanding the concepts correctly. Thanks for all the help in advance. Prove
       (A∧B’) ∧C↔(A∧C) ∧B’
       (A∧B’) ∧C = P
       (A∧C) ∧B’ = Q

       1. (A∧B’)          hyp
       2. C               hyp
       3. (A∧C)           hyp
       4. B’              hyp
       5. A ,B’,C         1,2 sim
       6. P,Q             5,  sim
       7.  P∧S            6, con
       8.  S∧P            7, comm
       9. (P→Q)∧(Q→P)     7,8 equ
       10. P↔Q            9 equ","['logic', 'propositional-calculus', 'discrete-mathematics', 'proof-verification']"
915447,What is the use of scheme theory?,"I should preface this by saying that my background in Algebraic Geometry is (more or less) the content of Vakil's notes up through Chapter 4 (i.e. through the definition of a scheme and several examples, I haven't yet read carefully about Proj). I am finding myself unmotivated to move further on in these notes, since I don't so much see the point of scheme theory. I am not stupid enough to think that there isn't a point, so I was wondering if someone could motivate (even briefly) the study of this (admittedly difficult) abstraction. I am only vaguely familiar with the classical case, so perhaps that has something to do with it. Thanks.","['algebraic-geometry', 'soft-question']"
915456,Simplifying the sum of powers of the golden ratio,I seem to have forgotten some fundamental algebra. I know that: $(\frac{1+\sqrt{5}}{2})^{k-2} + (\frac{1+\sqrt{5}}{2})^{k-1} = (\frac{1+\sqrt{5}}{2})^{k}$ But I don't remember how to show it algebraicly factoring out the biggest term on the LHS gives $(\frac{1+\sqrt{5}}{2})^{k-2}(1+(\frac{1+\sqrt{5}}{2}))$ which doesn't really help,"['golden-ratio', 'algebra-precalculus']"
915466,How to solve the ODE $y(y'(x)+a)=bx$,"I've been very frustrated attempting to separate this guy. Since there are three separate items when you multiply through by the y, it is very difficult to make all sides work out to forms $f(y)dy$ and $f(x)dx$. I've attempted the trick of getting it in the form $y'dx/y$ to get the integral to be $\log(y)$, but haven't successfully separated it yet. Any help would be appreciated, I want to understand your attempt, not just apply it if you know what I mean. Also, initial condition is: $ y(0)=0$ EDIT: we can try $y=Cx$ and find that it is a valid solution for specific C values.",['ordinary-differential-equations']
915540,How find the value $\beta$ such $\left|\frac{p}{q}-\sqrt{2}\right|<\frac{\beta}{q^2}$,"Find all positive real number $\beta$,there are infinitely many relatively prime integers $(p,q)$ such that 
$$\left|\dfrac{p}{q}-\sqrt{2}\right|<\dfrac{\beta}{q^2}$$ maybe this problem background is Hurwitz's theorem :
$$\left|\sqrt{2}-\dfrac{p}{q}\right|<\dfrac{1}{\sqrt{5}q^2}$$ so I guess my problem ?  $\beta\ge\dfrac{1}{\sqrt{5}}$ and this problem is Germany National Olympiad 2013 last problem (1), see: http://www.mathematik-olympiaden.de/aufgaben/52/4/A52124b.pdf","['diophantine-approximation', 'number-theory']"
915541,Contradictory recursion,"I encountered this problem which I find very contradictory to my intuition. Could anyone enlighten me why my recursive formulation is wrong? ""Roll a fair dice until the game stops. The game stops when you get a 4, 5, or 6. For every 1, 2, or 3 your score increases by +1. If the game stops with a 4 or 5, you get paid the accumulated score. If the game stops with a 6 you get nothing. What is the expected payoff of this game?"" Here, my recursive formulation. Let $E$ denote the expected score. First three terms denote the event for 1,2,3 respectively, the fourth and the fifth term denote the event 4,5, the last term is for the event 6. $$E = \frac{1}{6} \left( E + 1 \right) + \frac{1}{6} \left( E + 1 \right) + \frac{1}{6} \left( E + 1 \right) + \frac{1}{6} E + \frac{1}{6} E + \frac{1}{6}\cdot 0\\
= \frac{1}{2}\left( E + 1 \right) + \frac{1}{3} E$$ Solving for $E$, I get $E = 3$. I don't want to take the Markov chain approach with infinite sums. I'd like to take the approach with intuitive recursive equation. The solution guide I have takes a two-step approach of first calculating the expected number of tosses of $\{1,2,3\}$ before the game stops and then computes the expected score conditioning on the output $\{4,5\}$ versus $6$. This approach (while somewhat makes sense) ends up with $\frac{2}{3}$. Could anyone please enlighten me what the problem in my recursive formulation is?","['probability-distributions', 'probability', 'expectation']"
915551,It's the discrete topology.,"I have to proof that if I have $(X,\tau)$ and $(Y,\delta)$ two topological spaces, if every function $f:X\longrightarrow Y$ is continuos then $\tau$ is the discrete topology. I don't know what is the way to solve this. Thanks!","['general-topology', 'functional-analysis']"
915567,Proving that a relation is an equivalence relation,"I am having difficulties proving the relation IS an equivalence relation. Let $f: X\longrightarrow Y$ be a function from a set $X$ onto a set $Y$. Let $R$ be  the subset of 
$X \times X$ consisting of those pairs $(x, x')$such that $f(x)= f(x')$. Prove that $R $ is an  equivalence relation. Let $ \pi: X\longrightarrow X/R$ be a projection. Verify that, if $ \alpha \in X/R$ is an equivalence class, to define $F(\alpha) = F(a)$, whenever $\alpha = \pi (a)$, establishes a well-defined function $F: X/R \longrightarrow Y$ which is one-to-one and onto.","['discrete-mathematics', 'equivalence-relations', 'elementary-set-theory', 'functions', 'relations']"
915598,"Evaluating $\int \frac{1}{x\sqrt{9x^2-1}}\,dx$","I try to integrate $$\int \frac{1}{x\sqrt{9x^2-1}}\,dx$$ let $u=x^2,\quad \quad du=2x\,dx,\:\quad \:dx=\frac{1}{2x}\,du$ $$
\begin{align}
& \int \frac{1}{x\sqrt{9u-1}}\frac{1}{2x}\,du \\[8pt]
= {} & \int \frac{1}{2x^2\sqrt{9u-1}} \, du \\[8pt]
= {} & \frac{1}{2}\int \frac{1}{u\sqrt{9u-1}}\, du
\end{align}
$$ now let $v=\sqrt{9u-1},\quad \quad dv=\frac{9}{2\sqrt{9u-1}}du,\quad \:dv=\frac{9}{2v}du,\:\quad \:du=\frac{2v}{9}dv$ $$\frac{\int \frac{1}{uv}\frac{2v}{9}dv}{2} = \frac{\int \frac{1}{u}dv}{9}$$ let $v=\sqrt{9u-1},\:u=\frac{v^2+1}{9}$ $$\frac{\int \frac{9}{v^2+1}dv}{9} = \int \frac{dv}{v^2+1}$$ since $\int \frac{1}{v^2+1}\,dv=\arctan(v)$ substitute back $v$ and $u$, then i get $$\arctan \left(\sqrt{9x^2-1}\right)$$ this is my answer, but i'm not sure if my answer is correct or not. Please if you have a better calculation than mine, i would be really happy if you want to show me and correct my answer. Thank you so much.","['trigonometry', 'integration']"
915625,Evaluate the following integral: $\int_0^{\pi} \sqrt{\frac{2}{\pi}}\sin(nx)\sqrt{\frac{2}{\pi}}\sin(mx) dx$,"Show that for $n,m = 1,2,3, ...$ : $$\int_0^{\pi} \sqrt{\frac{2}{\pi}}\sin(nx)\sqrt{\frac{2}{\pi}}\sin(mx) dx = \delta_{mn},$$ where $\delta_{mn}=\begin{cases} 0 & m \neq n \\ 1 &m=n \end{cases}$ . No matter how hard I try, I cannot get to prove it. I understand we have to use the factor formula of trigonometry. But I still can't prove it.","['trigonometry', 'calculus', 'integration']"
915640,Rudin Principles of mathematical analysis p307,"""For if $ A=\bigcup A^{'}_{n}$ with $A^{'}_{n} \in M_F(\mu)$, write $A_1=A^{'}_{1} $, and
$$ A_n=(A^{'}_1\cup ...\cup A^{'}_n)-(A^{'}_n \cup ... \cup A^{'}_{n-1})$$ $(n=2,3,4,...)$. Then 
$$ A=\bigcup_{n=1}^{\infty}A_n$$
I can't understand why $A_n$ is expressed like the above? Should the correct one be 
$$ A_n=A^{'}_n-(A^{'}_1 \cup ... \cup A^{'}_{n-1})$$",['analysis']
915656,Proof for a rank-one Decomposition theorem,"Consider the following result which I recently came across in a research paper in my area (Signal Processing) Let $X$ be a $N\times N$ positive semidefinite (psd) matrix whose rank
  is $r$. Let $A$ be any symmetric $N\times N$ matrix. Then, there exist
  a set of vectors $x_1,\dots,x_r$ such that \begin{align} X & =
 \sum_{i=1}^{r}x_ix_i^T \\ x_i^TAx_i &=
 \frac{\mbox{trace}\{AX\}}{r},~~~\forall i \end{align} The following is the proof for it which I can't verify. Proof: Consider the following step-wise procedure whose inputs are $X$ and $A$. $~~$0.$~~$ Inputs are $X$ (given $X\geq 0$, $rank(X)=r$) and $A$ (symmetric). Decompose $X=RR^T$. Generate the eigen decomposition $R^TAR=U\Lambda U^T$. Let $h$ be any $N\times 1$ vector such that $\lvert h_i\rvert=1$ (each entry of $h$). Generate the vector $x_1$ and matrix $X_1$ as 
\begin{align}
x_1&=\frac{1}{\sqrt{r}}RUh \\
X_1&=X-x_1x_1^T 
\end{align} Outputs are $X_1$ and $x_1$. The paper then claims that $X_1$ is psd and has rank $r-1$ $x_1^TAx_1=\frac{1}{r}trace(AX)$ While I am able to verify the second claim, am not able to verify the first one? How is it true? If this can be done, the rest of the proof is straight forward. I am looking for a rigorous proof. Read this if you are interested to know where this proof heads. Now do the stepwise algorithm earlier with inputs $X_1$ and $A$ to get $x_2$ and $X_2$ such that \begin{align}X_2&=X_1-x_2x_2^T\\&=X-x_1x_1^T-x_2x_2^T\end{align} and $$x_2^TAx_2=\frac{1}{r-1}trace(AX_1)=\frac{1}{r}trace(AX)$$ Then the result of the paper is that you can do this procedure $r$ times and get a rank-one decomposition $$X=\sum_{i=1}^{r}x_ix_i^T$$ with the property $$x_i^TAx_i\,=\,\frac{1}{r}trace(AX),~\forall i$$for any given psd X with rank $r$ and any symmetrix $A$.","['matrices', 'linear-algebra']"
915687,Does $\forall x\ne 0: x^TAx>0$ means all eigenvalues of $A$ are real?,"Let $A\in\mathbb{R}^{n\times n}$ Does $\forall x\ne 0,x\in \mathbb{R}^n: x^TAx>0$ means $A$ has only real eigenvalues (roots of the characteristic polynomial are all real)?",['linear-algebra']
915707,A question from Gathmann's notes on Algebraic Geometry.,"This is question from Gathmann's notes on Algebraic Geometry. Let $$C_n=\{(x,y)\in\Bbb{C}^2;y^2=(x-1)(x-2)\dots(x-2n)\}\subset\Bbb{C}^2$$ Gathmann says that if we go in a circle around any of the points $1,2,3\dots,n$, ""we go from one copy of the plane to another"". I don't know what that means. $y$ clearly has two values for every single value of $x$. So this might mean that we travel from one value of $y$ to another. I can picture this happening for the polynomial $C_1$, but the picture is too complicated for me for $C_r$ where $r>1$.",['algebraic-geometry']
915710,"""Proof"" that $1-1+1-1+\cdots=\frac{1}{2}$ and related conclusion that $\zeta(2)=\frac{\pi^2}{6}.$","Sorry if this has been posted before. Can somebody please tell me whether this result is correct, and give explanation as to why or why not? I'm not good at the formal side of maths. Start here: $$\sum\limits_{k=0}^{\infty}e^{ki\vartheta}=\frac{1}{2}+\frac{i}{2}\cot\frac{\vartheta}{2},~0<\vartheta<2\pi.$$ Then equate the real and imaginary parts, so $$\begin{align*}\sum\limits_{k=1}^{\infty}\cos k\vartheta &=-\frac{1}{2},\\
\sum\limits_{k=1}^{\infty}\sin k\vartheta &=0.\end{align*}$$
For $\varphi=\vartheta+\pi$ for $-\pi<\varphi<\pi$ we could write the cosine equation as $\frac{1}{2}-\cos\varphi+\cos 2\varphi-\cdots=0$ which would mean
$$1-1+1-1+\cdots=\frac{1}{2}.$$
I'm not a mathematician - is this valid? Edit: For context, here is why I want this result. If the cosine formula holds and we can integrate it twice to some angle $0<\varphi<\alpha$ then get this interesting result
$$\sum\limits_{k=1}^{\infty}(-1)^{k+1}\frac{1-\cos k\alpha}{k^2}=\frac{\alpha^2}{4}$$ which for the angle of $\pi$ would imply that
$$\sum\limits_{k=1}^{\infty}\frac{1}{(2k-1)^2}=\frac{\pi^2}{8}=\zeta(2)-\sum\limits_{k=1}^{\infty}\frac{1}{(2k)^2}=\frac{3}{4}\zeta(2)$$ and finally we get
$\zeta(2)=\frac{\pi^2}{6}.$ It's interesting that such a pretty result comes out of what is essentially crappy maths. Also has that 
$$1-\frac{1}{4}+\frac{1}{9}-\cdots=\frac{\pi^2}{12}$$ by the way.",['sequences-and-series']
915778,And another real integral to be solved by contour integration,"I want to solve $$\int_0^\infty\frac{1}{x^3+x^2+x+1}dx$$ and i have really learned a lot already by failing to solve it.
I want to solve it using a clever contour. It is possible to do it using partial fractions (gives me $\frac{\pi}{4}$), but i´d rather not, since the residues seem quite nice. Obviously, poles are at $-1,i,-i$, with residues being $\frac{1}{2},-\frac{1}{4}+\frac{i}{4},-\frac{1}{4}-\frac{i}{4}$. Here´s what ive tried:
I cant get it to be from $-\infty$ to $\infty$ since its not even or anything.
I tried a contour that looks like about a big slice of a pie, but theres no angle for the ""way back in"" that gives back the original equation (i hope you know what i mean).
I know a theorem that would help me if it wasnt for the real root, so that doesnt help either. Is there really no clever contour or do i fail to see it...","['integration', 'complex-analysis', 'contour-integration']"
915779,Books on differential geometry in the cases $n=2$ and $n=3$,"I'm interested in learning the differential geometry of standard, ""physical"" space, that is $\mathbb R^2$ and $\mathbb R^3$. The sort of problems that were studied in the 18th and 19th century... curvature and so on. NJ Wildberger's lectures give an idea of the sort of content I'm looking for. I'm interested in books with a very down-to-earth, physical way of approaching things. Books that encourage thinking of a curve as a line through physical space, rather than a particular set of ordered triples, if you see what I mean. To give a better idea of my needs, I've been struggling with multivariable calculus because all the definitions are in the context of $\mathbb R^n$ for arbitrary $n$, and I find it all very abstract and unmotivated. I feel I would get a better grip on the situation if I spent some time really deepening my appreciation for the concepts as they apply to familiar $2$ and $3$ dimensional geometry.","['multivariable-calculus', 'book-recommendation', 'reference-request', 'differential-geometry']"
915789,Convergence of expected values as random variables converge almost surely,Let I have a sequence of random variables $X_n$ that converges to random variable $X$ almost surely as $n\to\infty$. How can I proof that $\lim_{n\to\infty}\mathcal{E}[X_n]=\mathcal{E}[X]$ where $\mathcal{E}[\cdot]$ stands for expected value?,"['probability-theory', 'probability-distributions', 'probability']"
915790,Expectation of Square of Stopping Time,"Let $B_t$ be standard Brownian motion and $a < 0 < b$. Define stopping time $T$ as follows. $$T = \min \{t \geq 0: B_t \in \{a, b\} \}.$$ The expectation of $T$ is $\mathbb ET = |a|b$ and can be found here . The question now is how to find the expectation of the square of $T$, i.e., $\mathbb E T^2$. Following the hint, one also needs the iterated law of expectations.","['stochastic-processes', 'martingales', 'stochastic-analysis', 'probability-theory', 'brownian-motion']"
915802,Can the transpose of a matrix be expressed in row/column operations?,"Suppose that $A$ is a matrix, can we get its transpose, $A^T$, by performing row and/or column operations to $A$?",['linear-algebra']
915846,Find a real entire function $f(z)$ asymptotic to $\ln(x^2+1)$ for real $x$.,Find a real entire function $f(z)$ asymptotic to $\ln(x^2 +1)$ for real $x$. More specific I want $f(0)=0$ and $\frac{1}{2} \ln(x^2+1) < f(x) < 2 \ln(x^2+1)$. Or prove it does not exist.,"['asymptotics', 'logarithms', 'complex-analysis']"
915885,Second derivative expression,"I have $f:\mathbb R^n\to \mathbb R$ and $\gamma:\mathbb R \to \mathbb R^n$, which are both $\mathrm C^2$. Considering $g=f\circ \gamma$, how could I express $g''$, second derivative of $g$ in terms of partial derivatives of $f$ and $\gamma$?. The first I know is that 
$$ \mathrm Dg(a) = \mathrm Df(\gamma(a)) \circ D\gamma(a), $$
so I consider $Dg:x\mapsto Dg(x)$, but this gets complicated. Thanks in advance. Edit: I know what is the Hessian matrix, I would like to apply it here. Edit II: Well, it is clear that
$$ g'(a) h = \langle \nabla  g(a), h\rangle = \langle \nabla f(\gamma(a)), \langle \nabla \gamma(a),h\rangle\rangle $$
so, what now?","['multivariable-calculus', 'derivatives']"
915914,What is the difference between congruency and equality?,What is the difference between equality and congruency? When should I say that two figures are congruent and when that they are equal?,"['geometry', 'congruences-geometry']"
915948,Is root of a function differentiable?,"Let's assume a function $f(\alpha,\theta)$ always has a single zero wrt $\alpha$: $\forall \theta, \exists \hat\alpha_\theta$ such that $f(\hat\alpha_\theta,\theta)=0$. Let's now consider this root as a function of $\theta$: $$g(\theta)=\hat\alpha_\theta$$ Assuming $f$ is differentiable wrt both its variables, is $g(\theta)$ differentiable ? Thanks a lot for your hints !","['calculus', 'functions']"
915975,"If $T$ is self-adjoint, is the set of power series in $T$ closed?","If $T$ is a bounded self-adjoint operator on a Hilbert space, is the set of convergent power series in $T$ closed in the norm topology? I ask because I'm reading some spectral theorems and I was wondering what the space $\overline{ \mathbb{C}[T] }$ is like.  It would be nice if it were just the set of convergent power series in $T$. Edit: Actually this seems sort of unlikely since then every complex valued continuous functions on the spectrum of $T$ would be given by a power series, but I still haven't seen enough examples of spectra to rule this out. Even a self adjoint $T$ whose spectrum has a limit point would suffice to rule it out.","['operator-theory', 'functional-analysis', 'analysis']"
916026,Prove the exsistence of 3 zero points of a function,"Assuming $a<b$, function f(x) is continous at [a,b], and we have $\int_a^bf(x)dx=\int_a^bxf(x)dx=\int_a^bx^2f(x)dx=0$ Prove that $\exists \ x_1,x_2,x_3\text {(different from each other)}  \in(a,b)$ satisfying $f(x_1)=f(x_2)=f(x_3)=0$. I have proved the existence of one zero point by differential mean value theorem, but have no idea about going on. Thanks for any solution or hint.",['calculus']
916050,How would I normalize the slope of a line?,"Assuming I have different lines with different slopes, I would like to compare the slope of each line as relative to one another. 
The program I am currently writing needs to compare the slopes of the lines on a 0 to 1 basis (1 being very steep, or equivalent of a slope of infinity and 0 being equivalent to a slope of 0) 
However, right now I have the values of the slope in absolute form, going from 0 to infinity. May I know how to accurately map these slopes to a scale of 0 to 1?","['geometry', 'trigonometry', 'graphing-functions']"
916051,Proof of trigonometric identity using vector calculus,"Question:
Using vector calculus, show that $\sin (A+B) = \sin A \cos B + \cos A \sin B$ I have no idea how to even attempt the question. A small hint to help me get started would be greatly appreciated!","['trigonometry', 'vector-analysis']"
916070,Why is the Leibniz rule a sufficient ingredient in the construction of the tangent space?,"This is a very soft question, but I am wondering if anyone can shed light on why it is that the product rule (and linearity) provide exactly the right requirement for the space of derivations to be the tangent space? A similar dependence on the product rule seems to pop up if you want to define the cotangent space at p as $m_p / m_p^2$ in the stalk at p of the sheaf of differentiable functions. What is it that makes the product rule the identifying feature of differentiation among all linear functions?","['soft-question', 'algebraic-geometry', 'differential-geometry']"
916076,Equivalence in Portmanteau's lemma,"I'm trying to understand the proof of one of the equivalences in Portmanteau's lemma. The equivalence (or implication rather, as that's what I'm trying to prove) is this: For any random vectors $X_n$ and $X$, the following statements are equivalent: (i) $P(X_n\leq x) \to P(X\leq x)$ for all continuity points of $x \mapsto P(X\leq x)$; (ii) $Ef(X_n)\to Ef(X)$ for all bounded, continuous functions $f$. The proof I'm trying to understand is for showing that (i) implies (ii). It starts like this. First, we assume that the distribution function of $X$ is continuous.
  Then for every rectangle $I$, condition (i) implies that $P(X_n\in
> I)\to P(X\in I)$. We choose a (sufficiently large) compact rectangle
  $I$ with $P(X \not\in I)<\epsilon$. A continuous function $f$ is
  uniformly continuous on the compact set $I$, and there exists a
  partition $I=\cup_j I_j$ into finitely many rectangles $I_j$ such that
  $f$ varies at most $\epsilon$ on every $I_j$. We take a point $x_j$
  from each $I_j$ and define $f_\epsilon=\sum_j f(x_j)1_{I_j}$. Then
  $|f-f_\epsilon|<\epsilon$ on $I$. At this point, my book says "" whence if $f$ takes its values in $[-1, 1]$ "" which I'm uncertain how to interpret. In any case, this leads to the following:
$$
|Ef(X_n)-Ef_\epsilon(X_n)|\leq \epsilon + P(X_n\not\in I)\\
|Ef(X)-Ef_\epsilon(X)|\leq \epsilon + P(X\not\in I)<2\epsilon,\\
|Ef_\epsilon(X_n)-Ef_\epsilon(X)|\leq \sum_j|P(X_n\in I)-P(X\in I_j)||f(x_j)|\to 0.
$$ My problem is how to show how the first (and second) line arise. Mainly, I am a bit confused as to how the function $f_\epsilon$ should be treated. From my lecture notes I have the following:
$$
|Ef(X_n)-Ef_\epsilon(X_n)|\leq\int_I|f(X_n)-f_\epsilon(X_n)|dP^{X_n}+\int_{I^c}|f(X_n)-f_\epsilon(X_n)|dP^{X_n}
$$
where the first term is said to be $\leq \epsilon$ and the second $\leq P(X_n\in I^c)$. But how do I show this? From the construction of $f_\epsilon$ we know that $|f-f_\epsilon|<\epsilon$ on $I$, but does that really mean that the integral on $I$ is $\leq \epsilon$? Furthermore, am I right in saying that $f_\epsilon(X_n)$ in the second integral is $0$ since we're outside of $I$? If someone could help me with that first inequality I would be very grateful, as I think that would clarify a lot for me. An attempt, please correct me if I'm wrong. For the first part of the inequality, we know that $|f-f_\epsilon|<\epsilon$ on $I$. Hence, $\epsilon$ is the maximum distance and thus
$$
\int_I |f(X_n)-f_\epsilon(X_n)|dP^{X_n}\leq \int_I\epsilon dP^{X_n}=\epsilon P(X_n\in I)\leq \epsilon.
$$
For the second part, the ""$f$ takes values in $[-1, 1]$"" comes into play, since
$$
\int_{I^c}|f(X_n)-f_\epsilon(X_n)|dP^{X_n}=\int_{I^c}|f(X_n)|dP^{X_n}\leq P(X_n\in I^c)
$$
by a similar argument (i.e. |$f(X_n)$| is at most $1$).","['probability-theory', 'convergence-divergence', 'proof-verification']"
916077,Bochner Integral: Integrability,"Attention This question has been slightly modified!! Reference It is related to: Bochner Integral: Axioms Problem Given a measure space $\Omega$ and a Banach space $E$. Consider Bochner measurable functions $F\in\mathcal{B}$. Then integrability is given by:
$$\int\|F-S_n\|\mathrm{d}\mu\to0\iff\int\|F\|\mathrm{d}\mu<\infty$$ On the one hand it holds:
$$\int\|F\|\mathrm{d}\mu\leq\int\|F-S_N\|\mathrm{d}\mu+\int\|S_N\|\mathrm{d}\mu<1+\infty$$ What about the converse? Addendum There's another didactic definition of integrability:
$$F\in\mathcal{L}:\iff\int\|S_m-S_n\|\mathrm{d}\mu\to0\quad(S_n\to F)$$
Certainly, one has for a suitable approximation:
$$S_n\to F:\quad\int\|S_m-S_n\|\mathrm{d}\mu\leq\int\|F-S_m\|\mathrm{d}\mu+\int\|F-S_n\|\mathrm{d}\mu\to0$$
But what about the converse here? Caution Although an integral gives the impression of measurability one should keep in mind that:
$$\int\|F-S_n\|\mathrm{d}\mu\to0\quad\nRightarrow\quad F\in\mathcal{B}$$ (For a counterexample see: Bochner Integral: Approximability )","['functional-analysis', 'measure-theory', 'integration']"
916085,"Prove that $\int_0^{\pi/2}\ln^2(\cos x)\,dx=\frac{\pi}{2}\ln^2 2+\frac{\pi^3}{24}$","Prove that \begin{equation}
\int_0^{\pi/2}\ln^2(\cos x)\,dx=\frac{\pi}{2}\ln^2 2+\frac{\pi^3}{24}
\end{equation} I tried to use by parts method and ended with
\begin{equation}
\int \ln^2(\cos x)\,dx=x\ln^2(\cos x)+2\int x\ln(\cos x)\tan x\,dx
\end{equation}
The latter integral seems hard to evaluate. Could anyone here please help me to prove it preferably with elementary ways (high school methods)? Any help would be greatly appreciated. Thank you. Addendum: I also found this nice closed-form
\begin{equation}
-\int_0^{\pi/2}\ln^3(\cos x)\,dx=\frac{\pi}{2}\ln^3 2+\frac{\pi^3}{8}\ln 2 +\frac{3\pi}{4}\zeta(3)
\end{equation}
I hope someone here also help me to prove it. (>‿◠)✌","['improper-integrals', 'calculus', 'integration', 'definite-integrals', 'real-analysis']"
916095,Characterizing functions which satisfy de Moivre's theorem,"Let $f$ and $g$ be two non-zero functions $ \mathbb R \to \mathbb R $ which are continuous and differentiable everywhere. Furthermore, say that for all integer $n$: $$ (f(\theta) + i g(\theta))^n = f(n\theta) + ig(n\theta) \tag{de Moivre's Theorem}$$ Does it follow that $f(\theta) = e^{bx} \cos a\theta$ and $g(\theta) = e^{bx} \sin a\theta$ for some $a$ and $b$? If not, can we characterize all pairs of functions $f$ and $g$ satisfying this identity? ( edit : changed conjectured forms for $f$ and $g$) I have derived some facts about $f$ and $g$: $$ f(0) = 1 \text{ and } g(0) = 0 $$
$$ f(\theta)^2 + g(\theta)^2 = 1 $$
$$ f(n\theta) = f(\theta)f((n-1)\theta) - g(\theta)g((n-1)\theta)$$
$$ g(n\theta) = g(\theta)f((n-1)\theta) + f(\theta)g((n-1)\theta)$$","['trigonometry', 'functional-equations']"
916121,Partial Derivative of the one variable function,"This is from my exam: 1) Calculate partial derivative $f'(10)$ of the function: $$f(x)=\frac{1-\log x}{1+\log x}.$$ This is a function of only one variable, why do they use the term 'partial' ?
Are the terms derivative and differential interchangeable for one variable functions.
Is it correct to write (for this example): $f'(10)=\frac{\mathrm{d}f}{\mathrm{d}x}(10)$ or $f'(10)=\frac{\partial f}{\partial x}(10)$",['derivatives']
916151,"If $G$ is complete, then the holomorph of $G$ is isomorphic to $G\times G$.","Question- If $G$ is complete, then the holomorph of $G$ is isomorphic to $G\times G$ . I am studying semidirect products for the first time, and in some notes I found this exercise. As far as I know about this problem, if $G$ is a group then let $H={\rm Aut}(G)$ and let $\phi:H \to{\rm Aut}(G) $ be the identity map, i.e. all elements go to itself, then Holomorph of $G$ is $G \rtimes_\phi{\rm Aut}(G)$ . Now if $G$ is complete then its outer automorphism group is identity, then $G \cong{\rm Aut}(G)$ so Holomorph is $G \rtimes_\phi G$ but $G \rtimes_\phi G \cong G\times G$ when $\phi$ is the trivial homomorphism i.e. everything goes to $1$ . So what am I missing here?","['holomorph', 'group-isomorphism', 'complete-groups', 'direct-product', 'group-theory']"
916173,Tensor product of injective ring homomorphisms,"What is an example of two injective homomorphisms $R \to A$, $R \to B$ of commutative rings such that $R \to A \otimes_R B$ is not injective? Of course neither $R \to A$ nor $R \to B$ can be flat in this example (but this is not enough for an example). A geometric reformulation is the following: What is an example of two morphisms of affine schemes $X \to S$, $Y \to S$ which are scheme-theoretical dense, but $X \times_S Y \to S$ is not? Bonus question: What is an example where $R \neq 0$ but $A \otimes_R B=0$?","['commutative-algebra', 'affine-schemes', 'algebraic-geometry', 'examples-counterexamples']"
916192,Proving any linear transformation can be represented as a matrix,"I'm trying to prove that Theorem. Consider a linear transformation $T : \mathbb R^n \to \mathbb R^n$ .
  The transformation $T$ can be represented as a matrix product $\mathbf x \mapsto A \mathbf x$ , for some matrix $A \in \mathbb R^{n \times n}$ . Here's my attempt at a constructive proof. Proof. Consider a matrix $\mathbf x \in \mathbb R^n$ given by \begin{align*}
  \mathbf x &=
  \begin{bmatrix}
    x_1 \\
    x_2 \\
    \vdots \\
    x_n
  \end{bmatrix}.
\end{align*} We will construct a matrix $A \in \mathbb R^{n \times n}$ such that $T(\mathbf x) = A \mathbf x$ . The vector $\mathbf x$ can also be written as \begin{align*}
  \mathbf x &=
  x_1
  \begin{bmatrix}
    1 \\
    0 \\
    \vdots \\
    0
  \end{bmatrix}
  +
  x_2
  \begin{bmatrix}
    0 \\
    1 \\
    \vdots \\
    0
  \end{bmatrix}
  + \dotsb +
  x_n
  \begin{bmatrix}
    0 \\
    0 \\
    \vdots \\
    1
  \end{bmatrix} \\
  &= x_1 \mathbf{e}_{1} + x_2 \mathbf{e}_{2} + \dotsb + x_n \mathbf{e}_{n} \\
  &= \sum_{i=1}^{n} x_i \mathbf{e}_{i},
\end{align*} where $\mathbf{e}_{i}$ are the standard basis vectors in $\mathbb R^n$ . Consider the transformation $T(\mathbf x)$ .
  Rewriting $\mathbf x$ as above, we have \begin{align}
  T(\mathbf x) &= T \left( \sum_{i=1}^{n} x_i \mathbf{e}_{i} \right) \\
  &= \sum_{i=1}^{n} T(x_i \mathbf{e}_{i}) \\
  T(\mathbf x) &= \sum_{i=1}^{n} x_i T(\mathbf{e}_{i}). \tag{1}
\end{align} Let the matrix $A \in \mathbb R^{n \times n}$ be defined by \begin{align*}
  A &=
  \begin{bmatrix}
    T(\mathbf{e}_{1}) &
    T(\mathbf{e}_{2}) &
    \cdots &
    T(\mathbf{e}_{n}) &
  \end{bmatrix} \\
  &=
  \begin{bmatrix}
    a_{11} & \cdots & a_{1n} \\
    \vdots & \ddots & \vdots \\
    a_{n1} & \cdots & a_{nn}
  \end{bmatrix},
\end{align*} where each $T(\mathbf{e}_{i})$ is a column of $A$ , and each $a_{ij} = T(\mathbf{e}_{i}) \cdot \mathbf{e}_{j}$ is the $j$ th component of $T(\mathbf{e}_{i})$ .
  Then, by the definition of matrix-vector multiplication, we have \begin{align*}
  A \mathbf x &=
  \begin{bmatrix}
    a_{11} & \cdots & a_{1n} \\
    \vdots & \ddots & \vdots \\
    a_{n1} & \cdots & a_{nn}
  \end{bmatrix}
  \begin{bmatrix}
    x_1 \\
    \vdots \\
    x_n
  \end{bmatrix} \\
  &=
  \begin{bmatrix}
    x_1 a_{11} + \dotsb + x_n a_{1n} \\
    \vdots \\
    x_1 a_{n1} + \dotsb + x_n a_{nn} \\
  \end{bmatrix} \\
  &=
  x_1
  \begin{bmatrix}
    a_{11} \\
    \vdots \\
    a_{n1}
  \end{bmatrix}
  + \dotsb +
  x_n
  \begin{bmatrix}
    a_{n1} \\
    \vdots \\
    a_{nn}
  \end{bmatrix} \\
  &= x_1 T(\mathbf{e}_{1}) + \dotsb + x_n T(\mathbf{e}_{n}) \\
  A \mathbf x &= \sum_{i=1}^{n} x_i T(\mathbf{e}_{i}). \tag{2}
\end{align*} Therefore, by eqs. (1) and (2), we have that \begin{align*}
  T(\mathbf x) &= \sum_{i=1}^{n} x_i T(\mathbf{e}_{i}) &
  A \mathbf x &= \sum_{i=1}^{n} x_i T(\mathbf{e}_{i}),
\end{align*} and we reach $T(\mathbf x) = A \mathbf x$ , as was to be shown. Any thoughts or suggestions would be appreciated.","['vector-spaces', 'linear-algebra', 'solution-verification']"
916204,Integral of inverse of square root of quartic function with real roots,"I was doing a physics problem and in order to finish it, I need to prove that: $$\int_{x1}^{x2}\frac{dx}{{((x1 - x)(x - x2)(x - x3)(x - x4))}^{1/2}} = \int_{x3}^{x4}\frac{dx}{{((x1 - x)(x - x2)(x - x3)(x - x4))}^{1/2}}$$ Where all the roots of the polynomial are real and $x1 < x2 < x3 < x4.$ I don't know the range of validity of my claim, however I do have tested this using mathematica and it was true for all the cases.
Also, I know that I can change the integrand using some transformations to get an elliptic integral of first kind. However, I think it will be a lot of work and will not pay the price (maybe I'm wrong), so I'm looking to a more elegant and direct proof.","['elliptic-integrals', 'integration']"
916213,Integration by Parts: When can you not use the Table Method. Why?,"I'm learning about integration by parts, primarily from Stewart's text (7th edition). In a supplemental book I have it brings up something called the Table Method. I really find this method appealing because it looks easier and quicker on many problems. But I find it doesn't seem to work at all on some problems (maybe I'm wrong?). For example, consider: $\int ln(x)\space dx $ (I realize this is an easy one, but I wanted to try the Table Method on it). Using the table method I get: \begin{array}{|c|c|c|} \hline u& dv & \pm \\ \hline ln(x)& dx & +1\\ \hline 1/x & x & -1 \\ \hline -1/x^2 & x^2/2 & +1 \\ \hline & & -1 \end{array} It's apparent that u will never differentiate to zero. I do however see the start of the right answer in this problem using the first diagonal: ($x \ln x$). It seems that in other problems of this type I can do something special with the last full row when I can't get to zero. I can simply integrate the product of the first two cells of that row. So this would give me first diagonal, plus second diagnal, plus integral product: $x \ln x - {1 \over 2}x + \int-{1\over2}\space dx$ This then works out to $x \ln x - x + C$, which is the correct answer. I started writing this question thinking that $\int ln(x)\space dx $ can't be solved with the Table Method, but in the process of composing this question it appears it can be in a  similar way $\int e^x \cos x \space dx$ can be solved (at least with regards the handling of the last full row going across as an integral instead of diagonal as a non-integral). It took me a while to type all this so I thought I'd still go ahead and post it. I have some question though: Please verify if I'm correct. When you realize the u column will never hit zero, when do you stop? From what I can read it seems you stop once you try differentiating twice. Is this always the case? I would also like to know if there are problems for which this method cannot work. For example when I try $\int \arctan x \space dx$ I get a mess that doesn't appear to work (but maybe it does and I just don't see how).","['calculus', 'integration']"
916218,Understanding the integrating factor,"I'm trying to understand solving ordinary linear differential equations by using integrating factor. I dont have my book yet so I'm reading from wikipedia https://en.wikipedia.org/wiki/Integrating_factor#Use_in_solving_first_order_linear_ordinary_differential_equations but I really don't get it. I have my equation $y' + P(x)y = Q(x)$
, I multiply on both sides with my integrating factor $e^{\int{P(x)}dx}$. If I now integrate on both sides with respect to x and then I'm magically seems to get something simpler. Can someone please help me understand whats happening in the transformation of the left hand side of the equation when it goes from a partial to  a total derivative? Why does this work?",['ordinary-differential-equations']
916220,Is there an equation to find the angle of the diagonal in a rectangle?,If we have a rectangle of length 5 and height 5 the angle of the diagonal would be 45°. We know this is true but how can we arrive at this conclusion mathematically?,"['geometry', 'trigonometry', 'rectangles']"
916245,Calculate wine volume in a horizontal barrel using a dipstick,"I suck at math, but still need a way to mark a dipstick to measure the volume of wine in a barrel. This question has been asked, but the only answer is to cryptic for me to understand! My barrel has a Height of 430 mm, Small radius of 136 mm and large radius of 175mm. Could someone show me how to calculate the volume in this barrel at Depth of 5, 10, 15 mm....? A spreadsheet would be nice (I don't know how to do Integrations!) Someone pointed to this as a possible solution, but the French and the math is above my grade!","['geometry', 'trigonometry', 'volume', 'integration']"
916251,Check proof of union of denumerable sets is denumerable too,"I need to prove: If $A$ and $B$ are denumerable sets then so is their union $A\cup B$. In this case, denumerable is defined as: A set $X$ is said to be denumerable if there is a bijection $\mathbb{Z}^+\rightarrow X$. My attempt: $A \text{ denumerable } \implies  f:\mathbb{Z^+} \rightarrow A$ $B \text{ denumerable } \implies  g:\mathbb{Z^+} \rightarrow B$ I need to construct a bijective function, $h:\mathbb{Z}^+\rightarrow A\cup B$. So, define $h$: $h(i)=\left\{ \begin{align}
& f(n+1), & \text{ if } i=2n+1, \text{ for } n \in \{0,1,2,\dots\} \\
& g(n), & \text{ if } i=2n, \text{ for } n \in \{ 1,2,3,\dots\}
\end{align} \right.$ Then, $h$ is bijective because both $f$ and $g$ are bijective by definition. Hence, $A \cup B$ is denumerable, as required. However, this only works if $A$ and $B$ are disjoint. So, in the case that $A$ and $B$ are not disjoint: $A\cup B = A \cup (B-A)$ and $A \cap (B-A) = \emptyset$ I'm not sure what to do next. If I can show that $B-A$ is denumerable, then I can use the above workings to conclude that $A\cup B$ is denumerable too. So I will attempt to construct a bijection $\mathbb{Z}^+\rightarrow B-A$: I know that $(B-A)\subset B$, so, there exists an inclusion function $i:(B-A)\rightarrow B$, which is an injection. I thought of $g^{-1}\circ i$ but that's just an injection $(B-A) \rightarrow \mathbb{Z^+}$. How can I build the required bijection ? I also would like to seek feedback if there are other parts of my work that could be written better.","['elementary-set-theory', 'proof-writing', 'proof-verification', 'functions']"
916338,Why should the generalization of a 'sequence' be called a 'net'?,"The title says it all, really. Reading through Reed & Simon's book on functional analysis, I have now reached the chapter on topological spaces, and the notion of a net is introduced there to handle things that 'sequences' can't quite manage. It's just not clear to me why it should be called 'net'. I'm interested in this since it may help me develop my intuition for the concept.","['nets', 'general-topology', 'terminology', 'soft-question', 'intuition']"
916347,Can a countable group have uncountably many distinct Hausdorff group topologies?,"Question. Can a countable group have an uncountable number of distinct Hausdorff group topologies? By a group topology one understands a topology with respect to which the group operations are continuous.  By distinct I mean non-isomorphic as topological groups. Motivation. The examples I have in mind are the pro-$p$ topologies on (e.g.) free groups, which typically yield an infinite (but countable) number of distinct topologies.  We can take the uncountably many subsets $\varpi$ of the primes and look at the pro-$\varpi$ topologies, but I'm not certain that they are all distinct. Note that a countable set can be topologised in uncountably many ways . (Interestingly, it seems that a kind of dual question has been asked before, which popped up in the list of similar questions.)","['topological-groups', 'group-theory']"
916356,Existence of an exponential double integral (for the probabilists: Are the $L^p$-norms of Brownian local time integrable in the space variable?),"I have encountered the following integral and, with a lot of handwaving and some identities for Gaussian integrals (see for example https://en.wikipedia.org/wiki/List_of_integrals_of_Gaussian_functions ) I think that it is finite. Is there a ""simple"" way to prove this? The integral is as follows: $$\int_{0}^{\infty} x^{1+1/p} \left(\int_{1}^{\infty} \mathrm{e}^{- x^2y^2/(2t)} (y-1)^p \mathrm{d}y \right)^{1/p} \mathrm{d}x,$$ where $t>0$ and $p > 1$. For the probabilists: Up to a constant (depending on $t$), the above integral is equal to
$$ \int_{-\infty}^{\infty} \operatorname{E}[(L_t^x)^p]^{1/p} \mathrm{d}x,$$
where $L_t^x$ is the local time of Browian motion in $x$ and at time $t$. The separate $L^p$-norms, i.e. the integrals $\operatorname{E}[(L_t^x)^p]$ and $\int_{-\infty}^{\infty} (L_t^x)^p \mathrm{d}x$ are both finite, but when combining the two as above things seem to become a bit more difficult, especially because of this pesky exponent $1/p$. Is the finiteness some ""well-known"" result? Can it be deduced by a simple probabilistic argument? Thanks for your help!","['multivariable-calculus', 'calculus', 'probability', 'real-analysis']"
916365,Cardinal numbers with countable cofinality,"What does this assumption mean: Let $k$ be any cardinal number with uncountable cofinality Which cardinals have countable cofinality? I know the definition of cofinality, but I'd like to see some examples of both countable and uncountable cofinality.","['cardinals', 'elementary-set-theory']"
916366,Exponents with Logs,"Could someone show work for why $e^{2\ln(x)}$ = $x^2$ ? I ran across this while solving an ODE but have completely forgotten the rules used here. I hate to ask it, but i'd rather ask it this once than go on in ignorance.",['algebra-precalculus']
916367,Caratheodory: Measurability,"Let $\mathcal{A}$ be an algebra over $X$ and $\mu:\mathcal{A}\to[0,\infty)$ a finite, positive and countably additive set function. Consider the induced outer measure:
$$\mu^*(A):=\inf_{A\subseteq\bigcup_k E_k}\sum_k\mu(E_k)$$ Then the following are equivalent:
$$\forall B\subseteq X:\mu^*(A\cap B)+\mu^*(B\setminus A)=\mu^*(B)$$
$$\mu^*(A)+\mu^*(X\setminus A)=\mu^*(X)$$ How do I prove this and what happens if the assumption of an algebra is dropped? Besides, the statement becomes wrong for noninduced outer measures:
$$X=\{1,2,3\}:\quad\mu^*(\varnothing)=0,\mu^*(X)=2,\mu^*(A)=1\text{ for }A\neq\varnothing,X$$",['measure-theory']
916383,Probability generating function of the sum of two random variables,"Let two $\mathbf{N}$-valued random variables $X$ and $Y$ be given, and let $\phi_X(s) = \sum_k \mathbf{P}(X = k) s^k$ and $\phi_Y(s) = \sum_k \mathbf{P}(Y = k) s^k$ be their respective probability generating functions. It is stated in Probability and Statistics by Example , Suhov and Kelbert, p. 59, that the following two conditions are equivalent. (i) $X$ and $Y$ are independent. (ii) $\phi_{X + Y}(s) = \phi_X(s) \phi_Y(s)$. I don't have a problem with the fact that (i) implies (ii). However, I don't understand why the converse is true. The only justification offered in the book is that it follows from the uniqueness of the coefficients of a power series. But I don't understand why the fact that $X + Y$ has the same distribution as if $X$ and $Y$ were independent ought to imply that they are in fact independent. Can anybody fill in the details of the argument, or else refer me to an easily accessible source? Thanks.","['probability-theory', 'generating-functions']"
916394,"Prove $\alpha \in\mathbb R$ is irrational, when $\cos(\alpha \pi) = \frac{1}{3}$","I am trying to prove: If $\cos(\pi\alpha) = \frac{1}{3}$ then $\alpha \in \mathbb{R} \setminus \mathbb{Q}$ So far, I've tried making it into an exponential, since exponentials are easier to manipulate (at least for me), when compared to $\cos$ or $\sin$. So: $$\cos(\pi\alpha)^2 + \sin(\pi\alpha)^2 = 1$$
$$\Big(\frac{1}{3}\Big)^2 + \sin(\pi\alpha)^2 = 1$$
$$\sin(\pi\alpha)^2 = \frac{8}{9}$$
$$\sin(\pi\alpha) = \frac{\sqrt{8}}{3}$$
$$\sin(\pi\alpha) = \frac{2\sqrt{2}}{3}$$ Then we can use Euler's formula: $$e^{i\pi\alpha} = \cos(\pi\alpha) + i\sin(\pi\alpha) = \frac{1}{3} + i\frac{2\sqrt{2}}{3} = \frac{1+i2\sqrt{2}}{3}$$ Now take the log of both sides: $$ \ln(e^{i\pi\alpha}) = \ln(\frac{1+i2\sqrt{2}}{3}) = \ln(1+i2\sqrt{2}) - \ln(3) = i\pi\alpha$$ $$\therefore \alpha = \frac{\ln(1+i2\sqrt{2}) - \ln(3)}{i\pi}$$ But, here I get stuck, and don't know how to show it is irrational, any ideas? (Even though it looks pretty darn irrational to me...) Should I be trying something else? I'm so lost...","['trigonometry', 'irrational-numbers']"
916407,Converse to the Jordan-Brouwer separation theorem,"By the Jordan curve theorem, if $C \subset S^2$ is (the image of) a simple closed curve, then $S^2 \setminus C$ has precisely two connected components. This statement admits the following ""converse"". Converse of Jordan curve theorem: Suppose $M$ is a closed, connected surface such that, if $C \subset M$ is a simple closed curve, then  $M \setminus C$ has precisely two connected components. Then, $M$ is homeomorphic to $S^2$. This statement is a corollary of the classification of surfaces . Multiple tori have handles, and it's easy to see that deleting a loop which ""grasps"" a handle leaves a connected complement. Any non orientable surface contains a Mobius band, and the Mobius band minus its ""equator"" is connected. Thus, any closed, connected surface $M$, besides $S^2$, admits a simple closed curve $C \subset M$ such that $M \setminus C$ is connected. My question is whether this also works in higher dimensions. Does the following ""converse"" to the Jordan-Brouwer separation theorem hold? Converse of Jordan-Brouwer separation theorem: Suppose $M$ is a compact, connected $n$-dimensional manifold without boundary. Suppose that, for every embedded copy $C \subset M$ of $S^{n-1}$, it occurs that $M \setminus C$ has precisely two connected components. Does it then follow that $M$ is homeomorphic to $S^n$?","['general-topology', 'manifolds', 'algebraic-topology']"
916457,Understanding a problem in Munkres,"This problem is from Chapter 2, Section 16, number 5 in Munkres' Topology. This is not a homework problem, but I'm trying to complete all problems from the sections covered in class. Let $X$ and $X'$ denote a single set in the topologies $\mathcal T$ and $\mathcal T'$, respectively; let $Y$ an $Y'$ denote a single set in the topologies $\mathcal U$ and $\mathcal U'$, respectively. Assume these sets are nonempty. (a) Show that if $\mathcal T' \supset \mathcal T$ and $\mathcal U' \supset \mathcal U$, then the product topology on $X' \times Y'$ is finer than the product topology on $X\times Y$. The way that I would like to prove this is to show that a basis element of the product topology on $X \times Y$ is also a basis element of the product topology on $X' \times Y'$. A basis element for $X\times Y$ is of the form $(A\cap X) \times (B\cap Y) = (A\times B) \cap (X\times Y)$ for some $\mathcal T$-open set $A$ and some $\mathcal U$-open set $B$. I'm not sure how I can show that this is also a basis element of the product topology on $X' \times Y'$ if I don't know the relationship between $X$ and $X'$ or $Y$ and $Y'$.",['general-topology']
916480,independent increments property implies Markov property,"Let $\{X_t\}_{t\in\mathbb R^+}$ be a stochastic process with values in $\mathbb R$. Suppose that $\{X_t\}$ has independent increments, namely for every $t_1<t_2<\ldots<t_k$ the random variables $X_{t_2}-X_{t_1}$, $X_{t_3}-X_{t_2}$, $\ldots,X_{t_k}-X_{t_{k-1}}$ are independent. I have to prove the Markov property, that is
$$P(X_t\in B\,|\, \mathcal F_s)=P(X_t\in B\,|\, X_s)$$
for $s<t$, $B$ measurable and $\mathcal F_s=\sigma(X_s:s\le t)$. Can you help me in order to formalize the details of this proof? Thanks in advance.","['stochastic-processes', 'probability', 'conditional-probability']"
916481,Diffucult Tautology to Prove,"I'm trying to show that the following is a tautology: $(p \vee q) \wedge (\neg p \vee r) \Rightarrow (q \vee r)$ Can anyone help, as far as I can get is to the following: $[(\neg p \wedge q) \vee (p \wedge \neg r)] \vee (q \vee r)$","['propositional-calculus', 'discrete-mathematics']"
916547,Prove that if $z_n \rightarrow z$ then $\theta_n \rightarrow \theta$ and $r_n \rightarrow r$.,"Suppose that $z_n,z \in G = \mathbb{C} - \{z:z\leq 0\}$ and $z_n=r_ne^{i\theta_n}, z = re^{i\theta}$ where $- \pi < \theta_n,\theta< \pi$. Prove that if $z_n \rightarrow z$ then $\theta_n \rightarrow \theta$ and $r_n \rightarrow r$.","['complex-numbers', 'complex-analysis']"
916569,What's an intuitive explanation for integration?,"I have never taken a formal calculus course, however I know some of the basics like differentiation and limits. I'm currently reading a book that is mathematically intensive, and I come across integration notation quite often but lack an intuitive understanding to be able to apply it to the physical world, or in this case to understand what is going on. I have read online explanations and it seems that they discuss finding the area under the curve but lack a fundamental explanation. I would appreciate if someone could explain integration to me for the sake of gaining an intuitive understanding of it so I can apply it to physical concepts.","['intuition', 'calculus', 'integration']"
916583,"Find a meromorphic function $f$ with poles at $\dots,-3,-2,-1$","I need help with the following problem: Find a meromorphic function $f:\mathbb{C}\longrightarrow \mathbb{C}$ whose only singularities are simple poles at $\dots,-3,-2,-1$ with residues $n$ at $z=-n$. Any hint would be appreciated.","['functions', 'complex-analysis']"
916594,Evaluating $\int \:x\csc \left(x^2\right)\cot \left(x^2\right)dx$,"I try to evaluating $\int \:x\csc \left(x^2\right)\cot \left(x^2\right)dx$ let $u=x^2,\quad \quad du=2xdx,\:\quad \:dx=\frac{1}{2x}du$ then i get $\int \:x\csc \left(u\right)\cot \left(u\right)\frac{1}{2x}du$
$=\frac{1}{2}\int \:\csc \left(u\right)\cot \left(u\right)du$ I'm stuck here, I've tried to evaluate the integrand but it seems like I can't find the right solution to continue finishing this problem. Please anyone help me, I would be really happy if you want to give me an advice to make this problem clear. I know the answer would be (according to table of integral) $-\frac{1}{2}\frac{1}{\sin \left(x^2\right)}+C$ but I want to know how to find the answer from scratch. >.< EDIT : thank you everyone, finally i found the right answer through $v\:=\:csc\left(u\right)$ then $dv\:=\:-csc\left(u\right)cot\left(u\right)du$ so, $=-\frac{1}{2}\int dv\:=\:-\frac{v}{2}\:+\:C\:$ substitute back u and v then i get $-\frac{1}{2}\frac{1}{\sin \left(x^2\right)}+C$ Thank you so much for your help & advice. :)","['trigonometry', 'integration']"
916609,Finding the limit of $F(x)=\frac{x^2-4}{|x+2|}$,"Let $F(x)=\dfrac{x^2-4}{|x+2|}$ and find the following limits $(a) \; \; \lim_{x \to -2^-}F(x)=$ $(b) \; \; \lim_{x \to -2^+}F(x)=-4$ $(c) \; \; \lim_{x \to -2}F(x)=DNE$ I substituted $-2$ to find $(b)$ and I guessed on $(c)$. I don't know how to solve for $(a).$ How do I go about solving this? 
I'm also confused a little on how to graph this function. I did factor it as: $F(x)=\dfrac{(x+2)(x-2)}{(x+2)}$ and then I canceled similar terms. Thank you.","['absolute-value', 'calculus', 'functions', 'limits']"
916612,Complex solutions to $ x^3 + 512 = 0 $,"An algebra book has the exercise $$ x^3 + 512 = 0 $$ I can find the real solution easily enough with $$ x^3 = -512 $$
$$ \sqrt[3]{x^3} = \sqrt[3]{-512} $$
$$ x = -8 $$ The book also gives the complex solutions $$ 4 \pm 4\sqrt{3}i $$ But I don't understand how to find these answers. Having completed the chapter on complex numbers I can find square roots of negative numbers easily, but cube (or higher) roots are never explained.","['complex-numbers', 'algebra-precalculus']"
916656,what is the solution for this EDO y'y'' = 1,"I´ll appreciate any help with this EDO y'y''=1, In some posts on internet theres a trick: multiply on each side y' and integrate but im not capable of doing that Thanks, sorry if my english is bad.",['ordinary-differential-equations']
916659,45 degree rotation of the line $y=-3x+1$?,"Currently working on problems in a textbook for Senior Maths (Year 11 Maths C, named 'Maths Quest - Maths C for Queensland), however I'm currently at a problem where my answer, despite attempting it multiple times, is incorrect to the textbook's result.
The question is, what the image of the line $y=-3x+1$ would be under the rotation of 45 degrees. It sounds like I am making a simple mistake somewhere, but I'm not sure where, therefore can't identify my mistake. $$\begin{bmatrix} x' \\ y' \end{bmatrix} = R_{45^\circ} \begin{bmatrix} x \\ y \end{bmatrix}$$$$\begin{bmatrix} x \\ y \\ \end{bmatrix}=R_{45^\circ}^{-1}\begin{bmatrix} x' \\ y' \end{bmatrix}$$$$R_\theta=\begin{bmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \\ \end{bmatrix}$$$$R_{45^\circ}=\begin{bmatrix} \cos45 & -\sin45 \\ \sin45 & \cos45 \\ \end{bmatrix}$$$$=\begin{bmatrix} \frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}}\end{bmatrix}$$
$$_\text{The error occurred here, I didn't use the inverse}$$$$\begin{bmatrix} x \\ y\end{bmatrix}=\begin{bmatrix} \frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}}\end{bmatrix}\begin{bmatrix}x'\\y'\end{bmatrix}$$$$\therefore x=\frac1{\sqrt2}x' - \frac1{\sqrt2}y'$$$$ \space y=\frac1{\sqrt2}x' + \frac1{\sqrt2}y'$$$$\text{Sub x and y into original equation...}$$$$\frac1{\sqrt2}x' + \frac1{\sqrt2}y'=-3(\frac1{\sqrt2}x' - \frac1{\sqrt2}y')+1$$$$=\frac{-3}{\sqrt2}x'+\frac{3}{\sqrt2}+1$$$$\frac1{\sqrt2}y'=-\frac4{\sqrt2}x'+\frac3{\sqrt2}y'+1$$$$\frac{-2}{\sqrt2}y'=\frac{-4}{\sqrt2}x'+1$$$$\frac2{\sqrt2}y'=\frac4{\sqrt2}x'-1$$$$y'=\frac{4\sqrt2}{2\sqrt2}-\frac{\sqrt2}{2}$$$$y'=2x'-\frac{\sqrt2}2$$
All of the above methods used are simply multiplication, division, addition, and subtraction. I have tried this in a variety of orders, getting similar (once the same, however with $-\frac{\sqrt2}{2}$ instead of $\frac{\sqrt2}{2}$), however the textbook declares that the answer should be $y'=\frac{x'}2+\frac{\sqrt2}{4}$. Where have I gone wrong? While keeping it roughly as simple as my own working out, any help is appreciated, especially other working out.","['analytic-geometry', 'matrices', 'rotations']"
916665,Why are Banach manifolds not so popular?,"Why are Banach and Frechet manifolds studied not even remotely as much as Euclidean manifolds? I assume like many other mathematical subjects, theory of manifolds has been developed much more than the real world needs. So perhaps applicability is not a factor and there are some mathematically intrinsic reasons for unpopularity of Banach manifolds comparing to ordinary manifolds.","['geometry', 'manifolds', 'soft-question']"
916679,tangent line to the graph,"this is the problem, I reached pi/6 & -pi/6 each time yet the website is saying my answer is incorrect. steps i took. 1) derivative of 4t-3tant/4t+3tant 
2)yeilds 4+3sec^2(x) on bottom 
3) set to 0
4) get +/-= sec = sort(-4/3) 
5) cos = sqrt(3) /2 which => pi/6 or -pi/6 ??? any ideas where I'm messing up? thank you!","['multivariable-calculus', 'calculus']"
916680,Is Minkowski space locally Euclidean?,"The Minkowski spacetime $\mathbb{R}^{1,3}$ is said to be a manifold (isomorphic to $SO^{1,3}$. But according to the definition of a manifold it should be locally euclidean. However, this seems to be wrong, in general relativity your pseudo riemmanian manifold is locally minkowskian, if the above statement was true, it would also be possible to make it locally euclidean. I think I am missing a major point in connecting, ""A manifold is a locally Euclidean topological space"" and ""Minkowski space is a manifold"".","['differential-geometry', 'mathematical-physics', 'special-relativity', 'differential-topology', 'smooth-manifolds']"
916682,Comparison and maximum principle for parabolic pde,"I was told the comparison principle can also be understood as the fact that the difference between a subsolution and a supersolution satisfies the maximum principle. I also know comparison principle can be regarded as the nonlinear version of maximum principle. I am vague about distinguishing these two theorem in a precise manner. Here is a version of weak MP from Evans p.368 Assume $u\in C^{(2,1)}(\Omega_T)\cap C(\bar{\Omega}_T)$ and 
\begin{equation}
	c\equiv 0\quad\text{in }\Omega_T
\end{equation} If
    \begin{equation}%\label{subconw1}
		u_t+Lu\le 0\quad\text{in }\Omega_T
	\end{equation}
    then
    \begin{equation*}		\max_{\substack{\bar{\Omega}_T}}u=\max_{\substack{\bar{\Gamma}_T}}u
	\end{equation*}
 Likewise, if
    \begin{equation}%\label{supconw1}
		u_t+Lu\ge 0\quad\text{in }\Omega_T
	\end{equation}
    then
    \begin{equation*}
\min_{\substack{\bar{\Omega}_T}}u=\min_{\substack{\bar{\Gamma}_T}}u		
	\end{equation*} I would like a comparison principle theorem by modifying above. Please help!
(This is what I know https://www.ma.utexas.edu/mediawiki/index.php/Comparison_principle#Parabolic_case )","['maximum-principle', 'regularity-theory-of-pdes', 'functional-analysis', 'partial-differential-equations']"
916688,Discrete mathematics subsets,"Suppose I have two sets A and B: $$ A = \lbrace 2k-1 : k \in \mathbb{Z}\rbrace$$ 
$$ B = \lbrace 2l+1 : l \in \mathbb{Z}\rbrace$$ I need to prove that A = B. I know that to prove equality between two sets I need to prove both: $$ A \subseteq B $$ and $$ A \supseteq B $$ I tried to start with something like : Suppose x is an element of A, then 
$$ x = 2k - 1 $$ EDIT : Which we can rewrite as $$ x = 2k + 1 - 2$$
$$ x  = 2(k-1) + 1$$ Because $$ (k-1) \in \mathbb{Z} $$ We know that x is also in B. Is this the correct way of approaching this problem?","['discrete-mathematics', 'elementary-set-theory']"
916698,$\mathbb S_n$ as semidirect product,"In this note, I've read that $\mathbb S_n$ is a semidirect product of the alternating group $A_n$ by $\mathbb Z_2$. So I am trying to define a morphism $\rho: \mathbb Z_2 \to Aut(A_n)$ to show that $\mathbb S_n \cong A_n \rtimes Z_2$. I would appreciate suggestions on how could I define the morphism. Thanks in advance.","['semidirect-product', 'group-theory', 'abstract-algebra']"
916705,$D_6$ is not a subset of $D_8$,"I came across an example in Chapter-2 of Dummit and Foote(page-47) which says :$D_6$ is not a subgroup of $D_8$ ,the former is not even a subset of latter.I can't understand why is it not the subset of $D_8$?
How do we define one group as a subset of another?","['finite-groups', 'group-theory']"
916715,Counting graph isomorphisms and entropy,"Question: If all graphs on $n$ vertices are given equal probability, what does the induced probability distribution on the graph isomorphism classes look like? Are there any patterns that emerge as $n$ becomes large? Are there some concentration results saying that the probability tends to cluster around certain isomorphism classes? Has this sort of thing been studied, if so what are some good references? Motivation: In statistical mechanics, a large number of indistinguishable ""microstates"" of a system may correspond to a single ""macrostate"", and the entropy of that macrostate is defined as the log of it's number of microstates. The motivation is to define an analogous entropy for graphs, where the microstates are the graphs and the macrostates are the isomorphism classes. The entropy $H$ is then defined as,
$$H(\text{isomorphism class}) = \log \left(\frac{\text{# of graphs in the class}}{\text{total number of graphs}}\right)$$ Example: Since I don't know the right terms to search for or words to use, the best I can do is try to illustrate by example. Take all 4-vertex graphs (64 of them) and consider enumerating all graphs in the various isomorphism classes; there is 1 graph with no edges, the entropy of this class would be $H = \log(1/64)$: 6 isomorphic graphs with one edge, the entropy of this class would be $H = \log(6/64)$: 12 isomorphic graphs with two edges that are connected, $H = \log(12/64)$: 3 isomorphic graphs with two edges that are disconnected, $H = \log(3/64)$: and so on. For completeness, the rest of the isomorphism classes are: 4 isomorphic graphs with three edges that are cyclic with one disconnected vertex: 12 isomorphic graphs with three edges that form a ""chain"": 4 isomorphic graphs with three edges that ""fan out"" from one vertex: 3 isomorphic graphs with four edges that form a big loop: 12 isomorphic graphs with four edges that have a small loop with one edge offshoot: 6 isomorphic graphs with five edges: 1 complete graph: These counts form a distribution on the ""meta-graph"" where nodes are isomorphism classes, and edges are present whenever one isomorphism class can be transformed into another by adding or removing a single edge: This problem seems like it should be well studied, but I don't know enough about the field to know the terms to search for or literature to look through. Searching for ""graph ismorphism"" and the like is such a broad topic. It's easy to find information about counting how many isomorphism classes there are, but I can't find much about counting the number of graphs within the isomorphism classes. Edit: I computed the isomorphism counts for all 5-vertex graphs, and made the following plot. Can't see much of a pattern though.","['graph-theory', 'entropy', 'combinatorics']"
916727,Proof for the distribution of a two-sample t-test with unequal population variances.,"I am having trouble finding documentation showing a proof, or at least some outline for it, illustrating how to derive the distribution and degrees of freedom of the test statistic for a two-sample t-test when the population variances are assumed to be different, $\sigma_1^2\ne \sigma_2^2$. If $ \overline{X}=\frac{1}{n_1}\sum\limits_{i=1}^{n_1}X_i$ where $X_1, \ldots, X_{n_1}$ are i.i.d. $\text{N}\left(\mu_1, \sigma_1^2 \right)$, $ \overline{Y}=\frac{1}{n_2}\sum\limits_{i=1}^{n_2}Y_i$ where $Y_1, \ldots, Y_{n_2}$ are i.i.d. $\text{N}\left(\mu_2, \sigma_2^2 \right)$, $S_1^2$ and $S_2^2$ are the unbiased sample variances for $X_i$ and $Y_i$ respectively, the t-statistic is: $$\frac{(\overline{X}-\overline{Y})-(\mu_1-\mu_2)}{\sqrt{\frac{S_1^2}{n_1}+\frac{S_2^2}{n_2}}}\sim t(\nu) $$ which has a t-distribution with $\nu$ degrees of freedom equal to: $$\Large \nu=\frac{\left(\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2} \right)^2}{\frac{\left(\frac{s_1^2}{n_1} \right)^2}{n_1-1}+\frac{\left(\frac{s_2^2}{n_2}\right)^2}{n_2-1}}  $$
Actually, I read that this statistic only approximates a t-distribution. Regardless, is there any resource where I can read more about this? I only see resources citing this result with no references giving/outlining a proof for this.","['statistics', 'probability-distributions']"
916731,"Extreme points of the unit ball of $l^1(\mathbb{Z^+})$ and $L^1[0,1]$","Determine the extreme points of the unit ball of $l^1(\mathbb{Z^+})$ and $L^1[0,1]$. My attempt: I know the definition but  I don't know how to find these extreme points.Please help me to solve this problem.Thanks in advance. Extreme point:An element $f$ of the convex subset $K$ of $X$ is said to be an extreme point of $K$ if for no distinct pair $f_1$ and $f_2$ in $K$ is $f=\frac{f_1+f_2}{2}$ Edit: The answer is the extreme points of  the unit ball of $L^1[0,1]$ are the delta functions and the unit ball of  $l^1(\mathbb{Z^+})$ has no extreme points . 2nd Edit: $l^1(\mathbb{Z^+})$ denote the collection of all complex functions $f$ on $\mathbb{Z^+}$ such that $\sum_{n=0}^{\infty}|f(n)|<\infty$.It is exercise number 9 of first chapter of Banach algebra techniques in operator theory by Douglas. 3rd Edit: My previous answer was wrong,the correct answer is  the extreme points of  the unit ball of that $l^1(\mathbb{Z^+})$ are the delta functions and the unit ball of  $L^1[0,1]$ has no extreme points .Can now someone prove this?",['functional-analysis']
916740,Question on Partial Derviatives,"For function $f(x,y) = x^2 y$ The partial derivatives for $x$ is $2.x.y $. I'm new to such math equation and i'm learning them now. 
May i know why is it so? Thanks!","['multivariable-calculus', 'derivatives', 'functions']"
916768,"How to solve such a nonlinear ODE, the analytical solution of which is known!","I have the following ODE with initial/boundary value conditions: $$\left. \begin{aligned}
\left(x^2-10 x-y^2\right)y\, y'(x)+(x-5) y^2 y'(x)^2-(x-5) y^2=0
;\qquad (\text{ODE})\\
y(0)^2=25;\qquad y'(0)^2=\frac{3-\sqrt{5}}{2} \qquad\qquad\qquad (\text{IBCs})
\end{aligned}
\right\}
$$ How to solve such a nonlinear ODE? Additionally, how can I verify whether a special function is a potential solution or not, e.g., the one in implicit form as below: $$\left(\sqrt{5}-1\right)\left(x-5\right)^2+2 y^2=25\left(\sqrt{5}+1\right)$$ UPDATE$^{(1)}$ By substituting $y^2$ and $y\,y'(x)$ obtained from the special solution into the original ODE and its IBCs, it seems this is the solution to the original nonlinear ODE problem. So the only question remaining is how to solve it to obtain the known solution. UPDATE$^{(2)}$ Below is another solution to the same ODE with the same IBCs: $$\left(\sqrt{5}+1\right)\left(x-5\right)^2-2 y^2=25\left(\sqrt{5}-1\right)$$ The problem has double solutions:","['ordinary-differential-equations', 'analysis']"
916776,What does $\mathbb{P}(d\omega)=dw$ actually mean?,"I am currently reading S. Shreve's book Stochastic Calculus II, and I have a question regarding Example 1.6.4 (p.35-36) which describes a change of measure, but I am puzzled by the notation. $\Omega=[0,1], \mathbb{P}$ is the uniform measure and 
$$\tilde{\mathbb{P}}[a,b]=\int_a^b 2\omega d\omega=b^2-a^2$$
for $0\le a\le b \le 1$. The first step is: We may use the fact that $\mathbb{P}(d\omega) = d\omega$ to rewrite the equation above as
  $$\tilde{\mathbb{P}}[a,b]=\int_a^b 2\omega d\mathbb{P}(\omega).$$ I have several questions regarding this statement: $\mathbb{P}$ is a probability measure from $\mathcal{F}\rightarrow\mathbb{R}$, I cannot find a clear definition in the book what $\mathbb{P}(d\omega)$ actually means. Is $d\omega$ actually an event? Why does this $\mathbb{P}(d\omega) = d\omega$ help in rewriting, shouldn't we need $d\mathbb{P}(\omega) = d\omega$? What does $\mathbb{P}(d\omega) = d\omega$ even mean, and why is this true?","['notation', 'measure-theory', 'probability']"
916779,Contour integration with branch points inside the contour.,"In my scientific research I ran into an unpleasant situation with specific type of contour integrals. Being more specific I have problems not with integrals themselves (I can use various numeric integration techniques, which work perfectly) but rather with the procedure of their evaluation. For example let's assume that I need to compute something like:
  $$I=\int _0^{\infty }Q_m\left(\sqrt{2 \lambda },\sqrt{2 t}\right)e^{-\alpha  t}t^{\nu }\mathrm dt. \tag{1}$$ where $Q_m\left(a,b\right)$ is the Marcum Q-function . For the first step I'll use its' contour integral representation (can be foud for example in J.Proakis, Digital Communications. New York: McGraw-Hill ):
$$Q_m(a,b)=e^{-\frac{1}{2} \left(a^2+b^2\right)}\oint _{\gamma }\frac{\exp  \left(\frac{a^2}{2 p}+\frac{b^2 p}{2}\right)}{(1-p) p^m}\mathrm dp$$
where $\gamma$ - any contour (running counter clockwise) encircling singularity at $p=0$ (since $m\in \mathbb{Z}$ it is a pole) and not including the singularity at $p=1$: usually a circle with radius $0<r<1$ around $p=0$ is chosen. Everything is fine at this step: I can deform the contour of integration if needed, since I have only poles. On the second step I plug it in, change the order of integration and get:
$$I=e^{-\lambda }\oint _{\gamma }\frac{e^{\lambda  p}}{(1-p) p^m}\left(\int_0^{\infty } t^{\nu } e^{-\left(1+\alpha -\frac{1}{p}\right)t} \,\mathrm  dt\right)\mathrm dp \tag{2}$$ Then inner integral can be treated as the Laplace transform at $s=1+\alpha -\frac{1}{p}$, so:
$$\int_0^{\infty } t^{\nu } e^{-\left(\alpha -\frac{1}{p}+1\right)t} \,\mathrm  dt=\mathcal{L}\left(t^{\nu };s=1+\alpha -\frac{1}{p}\right)=\frac{\Gamma  (\nu +1)}{\left((1+\alpha )-\frac{1}{p}\right)^{\nu +1}}$$ Combining it all together:
$$I=\frac{e^{-\lambda }\Gamma  (\nu +1)}{(1+\alpha)^{\nu +1}}\oint _{\gamma }\frac{e^{\lambda  p}}{(1-p) p^{m-\nu -1}\left(p-\frac{1}{\alpha +1}\right)^{\nu +1}}\mathrm dp \tag{3}$$
And now, since $(m-\nu-1\notin \mathbb{Z})\vee (\nu+1\notin \mathbb{Z})$ and $\frac{1}{1+\alpha}<1$ I'm in a big trouble because for any initially chosen contour there is a branch point inside it ($p=0$), which means that I can not deform it any more as I wished to do. Moreover, with a bad choice of $\gamma$ there can be one more branch point $p=\frac{1}{1+\alpha}$. So, the questions are: how should I proceed next and is there any way (or maybe some trick) to cope with the last integral in view of the brunch points? UPDATE It seems that like I accidentally (as a chain of completely wrong and illegal steps) found something that looks suspiciously similar to the solution: $$
\begin{eqnarray}
I\!\!&=&\!\!\!\frac{e^{-\lambda }\Gamma  (\nu +1)}{(1+\alpha)^{\nu +1}}\!\!\left[\!\mathcal{L^{-1}}\!\!\!\left(\!\!\frac{1}{(1-p) p^{m-\nu -1}\!\left(p-\frac{1}{\alpha +1}\!\!\right)^{\nu +1}}\!;\!t\!=\!\lambda\!\!\right)\!\!-\!\underset{p=1}{\mathrm{Res}}\!\!\left(\!\!\frac{e^{\lambda  p}}{(1-p) p^{m-\nu -1}\!\left(\!p-\frac{1}{\alpha +1}\!\!\right)^{\nu +1}}\!\right)\!\!\right]\!=\!\\
&=&-\frac{\Gamma(\nu+1)}{\Gamma(m+1)}\frac{\lambda^m e^{-\lambda}}{(1+\alpha)^{\nu+1}}\Phi_2\left(\nu+1,1,m+1;\frac{\lambda}{1+\alpha},\lambda\right)+\alpha^{-\nu-1}\Gamma(\nu+1)
\end{eqnarray}
 $$ where $\Phi_2(b_1,b_2,c;x,y) = \sum_{m,n=0}^\infty \frac{(b_1)_m (b_2)_n} {(c)_{m+n} \,m! \,n!} \,x^m y^n $ - is the Humbert series . The obtained ""candidate"" for a solution nicely coincides with numeric integration for various sets of parameters. 
As an example I've set $\lambda=0.1, \ m=5$ and got the following comparison: Here dots represent the obtained solution and solid lines - numeric integration in $(1)$. This solution makes me think that I have to deform (somehow) the contour $\gamma$ to get Bromwich contour. But how can this be, since the deformation is illegal in presence of branch points inside it?","['laplace-transform', 'special-functions', 'integration', 'complex-analysis', 'contour-integration']"
916821,Almost sure limit of $\log(X_1 + X_2 + ... + X_n) - \log(n)$,"Let $X_n$ be an i.i.d. sequence of positive random variables with expectation 2 and variance 1. What is the almost sure limit of
$$\log(X_1 + X_2 + ... + X_n) - \log(n)$$ 
as $n \to \infty$ Would it be just $$\log \left( \frac{X_1 + X_2 + ... + X_n}{n} \right)$$ which by strong law of large numbers is  then $$\log(\mu) = \log(2)$$","['probability-theory', 'law-of-large-numbers', 'random-variables']"
916830,"Minimum prerequisites for Basic Complex Analysis by J. Marsden, M. Hoffman","I want to self study Basic Complex Analysis by J. Marsden, M. Hoffman but I don't know much real analysis and not very interested in learning real analysis. I know single and multivariable calculus, linear algebra and differential equations so is that good enough?","['soft-question', 'book-recommendation', 'complex-analysis']"
916853,A closed-form of product the gamma functions containing $\pi$ and $\phi$,"Playing with gamma functions by randomly inputting numbers to Wolfram Alpha , I got the following beautiful result \begin{equation}
\frac{\Gamma\left(\frac{3}{10}\right)\Gamma\left(\frac{4}{10}\right)}{\Gamma\left(\frac{2}{10}\right)}=\frac{\sqrt[\large5]{4}\cdot\sqrt{\pi}}{\phi}
\end{equation} where $\phi$ is golden ratio. Could anyone here please help me to prove it by hand? I mean without using table for the specific values of $\Gamma(x)$ except for $\Gamma\left(\frac{1}{2}\right)$. As usual, preferably with elementary ways (high school methods)? Any help would be greatly appreciated. Thank you.","['special-functions', 'gamma-function', 'closed-form', 'calculus']"
916854,Taking Calculus in a few days and I still don't know how to factorize quadratics,Taking Calculus in a few days and I still don't know how to factorize quadratics with a coefficient in front of the 'x' term. I just don't understand any explanation. My teacher gave up and said just use the formula to find the roots or something like that.. Can someone explain to me simply how I would step by step factorize something like $4x^2 + 16x - 19$ ?,"['factoring', 'algebra-precalculus', 'quadratics']"
916857,Is it possible that a left coset of $H$ contains more than one right coset of $H$?,Let $H$ be a subgroup of group $G$. Is it possible that a left coset of $H$ contains more than one right coset of $H$? It is clear to me that the answer is 'no' if we deal with finite groups.,"['infinite-groups', 'group-theory']"
916858,Spectrum of an integral operator.,"For any $f\in C([0,1],\mathbb{R})$ set
$$
Tf(x) = \int_0^1 [\min\{x,y\}\cdot f(y)]dy.
$$
I have just proved that $T$ is a compact operator from  $C([0,1],\mathbb{R})$ into itself. I would like to know how to calculate his spectrum. (Since $T$ is compact I know that his spectrum is made of only eigenvalues.) Thank you for your help.","['compact-operators', 'spectral-theory', 'functional-analysis']"
916859,How is the formal inverse of a power series with constant term developed ( for instance $\cosh^{-1}(x)$)?,"In an older question here in MSE I've asked for the term for the ""slicing"" of a power series in partial series and have learned that it is ""multisection"". I' ve been looking at the behaviour of the threefold-multisection of the exponential series
$$ \begin{eqnarray}
 g_0(x) &=& \sum_{k=0}^\infty {x^{3k} \over (3k)!} \\ 
 g_1(x) &=& \sum_{k=0}^\infty {x^{3k+1} \over (3k+1)!} \\ 
 g_2(x) &=& \sum_{k=0}^\infty {x^{3k+2} \over (3k+2)!} \\ 
\end{eqnarray} \\
 g_0(x)+g_1(x)+g_2(x) = \exp(x) $$ I've just stepped into my older exercises with this and this time I want to work with the inverses of that functions. I know meanwhile how to invert a power series without constant but with linear term and can sometimes invert other powerseries using the recentering around one of its fixpoints. But I don't see how this can be done for $g_0(x)$ and for $g_2(x)$ . A very nice example for the inversion of such a series is that for the inverse of the $\cosh()$ function: $\cosh^{[-1]}(x)$ Its powerseries appears as very nice and smooth and I have no idea how this could have been made. 
So my question is mainly a: for the method: how to develop the inverse of such a powerseries
  (with constant term, here having the unit as value, or without constant and without linear term as in $g_2(0)$) b: but of course also simply for the solution for $g_0(x)$ and $g_2(x)$ if the methods need more then I can do myself. If I got a view into an article in the internet so far correctly a possible solution might have used the fact that for the cos and sin-function by periodicity $\cos(x) = \sin(\pi/2 + x)$ (at least over the reals) then the inverse for the $\cos()$ taken by the inverse of the powerseries of $\sin(x)$ and then drifted to the conversion of arguments between $\cosh(x)=\cos(i x)$, but I'm not yet sure about this and have to examine the argumentation step-by-step. Anyway, this does not yet help for my problem in question because I've not yet a transfer-function for the arguments of the $g_0(x)$ and the $g_1(x)$-function. If this of some help, there is a representation in terms of the exponential-function itself: $ \displaystyle 
\text{ let } a=- \frac12 \text{ and } b= {\sqrt3 \over 2} \text{ such that over the complex } z=a+b \mathcal i \text { and } z^3 = 1 \text{ then } \\
\begin{eqnarray} 
 \qquad \qquad g_0(x) &=& { 1\over 3} \big( e^x +2e^{ax} \cos(bx)  \big) \\
 \qquad \qquad  g_1(x) &=& { 1\over 3} \big( e^x +2e^{ax}\big( a\cos(bx)+b\sin(bx) \big) \big) \\
 \qquad \qquad  g_2(x) &=& { 1\over 3} \big( e^x +2e^{ax}\big( a\cos(bx)-b\sin(bx) \big) \big) \\
\end{eqnarray}$ and also we have the circular relations of derivatives: $ \qquad \qquad g_0'(x)=g_2(x) \qquad g_1'(x)=g_0(x) \qquad g_2'(x) = g_1(x) $ . Here is a picture of $g_{0}(x)$  over the reals: The picture shows already that like with the $\cos^{[-1]}(x)$ and $\cosh^{[-1]}(x)$ we'll have very limited ranges for the inversion due to its multivaluedness and singularities in its derivatives.","['sequences-and-series', 'complex-analysis', 'taylor-expansion']"
916861,Asymptotic uniform integrability and moments of Student's $t$,"I am working on an exercise where I am trying to show that the moments of a $t$ distribution converge in probability to the moments of a standard normal. I'm in need of help with what I think is the trick of the solution, namely uniform integrability. The question is this: If $X_n\sim t(n)$, then $X_n \to_d N(0, 1)$. Does it follow that $EX_n^p \to EN(0, 1)^p$ for every $p\in\mathbb N$? Is this true? I know convergence in distribution does not imply convergence in probability of the moments, but I haven't done anything more formal than that for the first question. For the second, I'm guessing it is true and that I have to use asymptotic uniform integrability, due to this theorem: Theorem. Let $f: \mathbb R^k\mapsto\mathbb R$ be measurable and continuous at every point in a set $C$. Let $X_n\to_d X$ where $X$ takes its values in $C$. Then $Ef(X_n)\to Ef(X)$ if and only if the sequence of random variables $f(X_n)$ is asymptotically uniformly integrable. So I'm pretty sure I have to show that $X^p_n$ is uniformly integrable asymptotically, but I am not quite certain how to do that. In particular, how do I do that for all $p$?","['probability-theory', 'weak-convergence', 'uniform-integrability', 'convergence-divergence']"
916886,Consistency of kernel density estimator with constant bandwidth,"Let ($x_1, ..., x_n$) be i.i.d. samples drawn from some distribution $P$ with an unknown probability density function $f$. Its kernel density estimator is
\begin{align}
    \hat{f}_h(x) = \frac{1}{n}\sum_{i=1}^n K_h (x - x_i) \quad = \frac{1}{nh} \sum_{i=1}^n K\Big(\frac{x-x_i}{h}\Big),
\end{align}
where $K$ a symmetric non-negative function that integrates to one. All consistency proofs ( 1 , 2 ) require that $h(n) \to 0$ for $n \to \infty$ and I think remember that this is a necessary condition for strong and even weak consistency. Are there any analysis about what happens when the bandwidth $h$ is a constant? Maybe error some bounds on the convergence to $f$?","['statistics', 'measure-theory', 'probability-theory']"
916894,"Why is an image called an ""image""?","Given a function $f : A \to B$, the image, denoted by $\operatorname{Im}f$ is the set of all $f(x)$ where $x \in A$. Why do we call this set the image? When was it first used, and what motivated its name? I would imagine that it is related to the idea that the function values show us what the function ""looks like""; otherwise, I suspect it may be related to the etymological history of image as ""imitation"" or ""representation"" in that the primary features of interest, the values, of a function are copied by isolating the function values from the domain. I'm not sure, though, and I don't have sources.","['math-history', 'elementary-set-theory', 'functions', 'soft-question', 'terminology']"
916906,Expectation and best strategy for a dice game,"I am somewhat stuck on this problem, it should be straightforward but I cannot find a clearly explained solution: A single dice is rolled as many times as you want. For each throw, you receive n dollars if dice shows $n$, if $n<6$. If dice shows $6$, you lose all the money accumulated and the game stops. What is the expectation and the best strategy for this game?","['dice', 'probability']"
916911,map between classifying spaces induced by group homomorphism,"Let $\Sigma_n$ be the permutation group of order $n$. Then the regular representation of $\Sigma_n$ gives an injective homomorphism $f:\Sigma_n\to O(n)$. Why $f$ induces a map between their classifying spaces
$$ F: B\Sigma_n\to BO(n)?$$ In general, let $\phi: G\to H$ be a homomorphism of Lie groups. Does $\phi$ always induce a map between their classifying spaces $$ \Phi: B G\to B H?$$","['differential-geometry', 'fiber-bundles', 'algebraic-topology', 'abstract-algebra', 'group-theory']"
916948,Do $\mathbb{R}^n$ and $\mathbb{C}^n$ valued ordinarily measureable functions form a Banach space under p-norm?,"By measureable function I mean an ""ordinarily"" measureable function, that is measureable in a sense of this definition: a function between measurable spaces is said to be measurable if the preimage of each measurable set is measurable. Let $(X,\ \mathcal{F},\ \mu)$ be a measure space and let $V$ be either $\mathbb{R}^n$ or $\mathbb{C}^n$ with a standard norm $\|v\|=(\sum_{k=1}^n|v_k|^2)^\frac{1}{2}$ for $v=(v_1,\ ...,\ v_n)$ in $V$. Do the measureable functions (where $V$ is equipped with a $\sigma$-algebra of Borel sets of either $\mathbb{R}^n$ or $\mathbb{C}^n$) form a vector space? Let $1\leq p \leq \infty$. For a measureable function $f: X\to V$ we define $$\|f\|_p=(\int\limits_X \|f\|^p\mathrm{d}\mu)^\frac{1}{p}.$$ Do the measureable functions $f$ such that $\|f\|_p<\infty$, after we identify those that are equal almost everywhere, form a Banach space under norm $\|\cdot\|_p$? I ask, because I know this is not true in the case of functions with values in infinite dimensional Banach spaces. There a notion of Bochner measurable function is introduced.","['vector-spaces', 'measure-theory', 'functional-analysis', 'lp-spaces']"
916951,$\int_{0}^{\infty} \frac{\cos(x)}{1+x^2} dx$ and $\int_{0}^{\infty} \frac {\ln(x)}{x^2+b^2} dx$,"Prove that $$\int_{0}^{\infty} \frac{\cos(x)}{1+x^2} dx = \frac {\pi}{2e}$$
My approach would be $$\lim_{n \to \infty} \int_{0}^{n} \frac{\cos(x)}{1+x^2} dx$$ and evaluate the limits of the sine and cosine integral functions, but I'm pretty sure there is an easier way. The second integral is $$\int_{0}^{\infty} \frac {\ln(x)}{x^2+b^2} dx, b > 0$$
My approach; Let $f$ be an analytic function $$f(z)=\frac {\ln(z)}{z^2+b^2}$$ then the poles of $f$ would be at $$z=ib, z=-ib$$
Now I don't know what contour to draw and what would be inside it.","['improper-integrals', 'integration', 'complex-analysis', 'contour-integration']"
916966,How to find the area of a quadrilateral given only the length of its sides?,"How do you find the area of a convex quadrilateral $ABCD$ , given only the length of its sides $a$ , $b$ , $c$ and $d$ . If the length of a single diagonal is given, I could easily find its area by dividing it into two triangles and applying Heron's formula to each. I encountered this problem while trying to find the area of a patch of land. Sometimes, the area maybe approximated by a rectangle or a trapezium or some other simple figure, but in general opposite sides are not parallel. All the formulas I have so far seen includes knowing at least one angle or a diagonal. So is there a formula (even a complicated one maybe) that gives the area of a quadrilateral given only its side lengths?","['geometry', 'quadrilateral', 'area']"
916967,How do you solve $f'(x) = f(f(x))$?,A friend told me to solve the following differential equation: $$f'(x)=f(f(x))$$ I have no idea how to solve this! This doesn't seem to be an ordinary differential equation and I can't even solve this numerically! I think my friend is trolling me.,"['ordinary-differential-equations', 'functional-equations']"
916987,a 2-regular graph is cyclic or not?,"We know the common result : - If every vertex of a graph G has degree at least2, then G contains a cycle. Can I conclude that 2-regular graphs are cycles where degree is exactly two of every vertex? I am not getting any contradictory example. Please help me if am wrong. Need some help. I worked like this: If the graph G has n vertices of degree two. Let us assume that all vertices have degree two except two vertices, say vertex v and u . now to make degree two of vertex v and u , we must attach them with other vertices. only possible case is to make vertices u and v together. otherwise if we make them adjacent to some other vertex, then degree of that vertex will be three or more. Contradiction. Is my conclusion right? NOTE: $G$ is a connected graph.","['graph-theory', 'discrete-mathematics', 'combinatorics']"
916999,Minimum number of guesses on sum and product required to find two numbers.,"I have a series of numbers 1 to N. A system randomly picks up two numbers and computes their sum and product. I have to guess the sum and product, The system will tell if the sum and product are larger or smaller. What is the optimal strategy to find the numbers in minimal number of guesses.","['puzzle', 'number-theory']"
