question_id,title,body,tags
3096500,Prove that if $P[X\leq Y] =1$ then $E[X]\leq E[Y]$,I would like to prove/disprove that following claim: Prove that if $P[X\leq Y] =1$ then $E[X]\leq E[Y]$ How can it be done?,"['expected-value', 'probability']"
3096509,Is there a holomorphic function such that $(f(z))^3=z-z^2$,"Is there a holomorphic function $f:C-[0,1]$ such that $(f(z))^3=z-z^2$ for all $z\in C-[0,1]$ My intuition tells me that not really, for instance $$(z-z^2)^{\frac{1}{3}}$$ does not have a unique branch on this set, but I do not know how to formally prove it.","['complex-analysis', 'complex-numbers']"
3096511,Number of $k$-sets in $[n]$ so that any two of them share at most 2 elements?,"Let $[n]$ be $\{1,2,\dots,n\}$ . Let \begin{align}T_\ell:=\Big|\Big\{&\{K_1,\dots,K_m\} \text{ is ""maximal""}:\\ &\text{each $K_i$ is a $k$-subset of $[n]$, and $|K_i\cap K_j|\le \ell$ for all $1\le i<j\le m$} \Big\}\Big|,\end{align} where ""maximal"" means you cannot find one more $k$ -subset $K_{m+1}$ so that $\{K_1,\dots,K_{m+1}\} \text{ satisfies that each $K_i$ is a $k$-subset of $[n]$, and $|K_i\cap K_j|\le \ell$ for all $1\le i<j\le m+1$}$ . We can assume $1\ll k\ll n$ . I am interested in an upper bound on $T_2$ . It seems this problem is related to partition, especially when $\ell=0$ ?","['number-theory', 'combinatorics', 'discrete-mathematics']"
3096530,Show that $e^{X^2/2} \in L^1$ iff $e^{XY} \in L^1$ iff $e^{|XY|} \in L^1$,"let $X, Y$ be two identically distributed (both are $\mathcal{N}(0,1)$ ) independent random variables show that $e^{\frac{X^2}{2}} \in L^1 \iff e^{XY} \in L^1 \iff e^{|XY|} \in L^1$ . my attempt : 1st equivalence : $$\begin{align}
\mathbb{E}[e^{XY}] &= \frac{1}{2\pi}\int_{\mathbb{R}}\int_{\mathbb{R}}e^{xy}e^{-\frac{x^2}{2}}e^{-\frac{y^2}{2}}dydx =\frac{1}{2\pi}\int_{\mathbb{R}}e^{-\frac{x^2}{2}}\int_{\mathbb{R}}e^{xy-\frac{y^2}{2}}dydx \\
&=\frac{1}{2\pi}\int_{\mathbb{R}}e^{-\frac{x^2}{2}}\int_{\mathbb{R}}e^{\frac{x^2}{2}}e^{-\frac{(x-y)^2}{2}}dydx \\
&= \frac{1}{\sqrt{2\pi}}\int_{\mathbb{R}}e^{\frac{x^2}{2}}e^{-\frac{x^2}{2}}\int_{\mathbb{R}}\frac{1}{\sqrt{2\pi}}e^{-\frac{u^2}{2}}dudx \\
& = \mathbb{E}[e^{\frac{X^2}{2}}]
\end{align} $$ I mean yeah this kinda proves that $e^{\frac{X^2}{2}} \in L^1 \iff e^{XY} \in L^1 $ but something is bothering me, because $\mathbb{E}[e^{\frac{X^2}{2}}] = \frac{1}{\sqrt{2\pi}}\int_{\mathbb{R}}dx = +\infty$ Q1 : can't we just say that $e^{\frac{X^2}{2}} \in L^1$ is a false claim therefore it can imply anything we desire ? second equivalence : from the fact that $0< e^{XY} \leq e^{|XY|}$ we conclude that $ e^{|XY|} \in L^1 \implies e^{XY} \in L^1$ $$\begin{align}
\mathbb{E}[e^{|XY|}] &= \frac{1}{2\pi}\int_{\mathbb{R}}\int_{\mathbb{R}}e^{|xy|}e^{-\frac{x^2}{2}}e^{-\frac{y^2}{2}}dydx \\
&=\frac{1}{2\pi}\int_{\mathbb{R}}e^{-\frac{x^2}{2}}(\int_{0}^{+\infty}e^{|xy|}e^{-\frac{y^2}{2}}dy +\int_{-\infty}^{0}e^{|xy|}e^{-\frac{y^2}{2}}dy)dx \\
&= \frac{1}{2\pi}[\int_{0}^{+\infty}e^{-\frac{x^2}{2}}(\int_{0}^{+\infty}e^{xy}e^{-\frac{y^2}{2}}dy +\int_{-\infty}^{0}e^{-xy}e^{-\frac{y^2}{2}}dy)dx +\int_{-\infty}^{0}e^{-\frac{x^2}{2}}(\int_{0}^{+\infty}e^{-xy}e^{-\frac{y^2}{2}}dy +\int_{-\infty}^{0}e^{xy}e^{-\frac{y^2}{2}}dy)dx]\\
& \leq \text{Constant}[\mathbb{E}[e^{XY}] + \mathbb{E}[e^{-XY}] ] = \text{Constant}_2[\mathbb{E}[e^{XY}]] 
\end{align} $$ I used the fact that $-X$ and $Y$ are independant and that $X = -X\, \text{in distribution}$ Q2 : was my attempt at proving 2nd equivalence correct ? thanks ! edit 1 : pic of the original problem (it's in french)","['expected-value', 'lp-spaces', 'probability-theory']"
3096584,"How to check whether a set belongs to a $\sigma$-algebra? Not understanding ""a Borel function""","Hello fine ladies and gentlemen, Now, I have never been very good with measure theory and I am struggling to be able to do the exercise. My definition of a sigma-algebra is the following.
(Definition) Let $X$ be a set. A collection of $\Sigma$ subset of $X$ is called a sigma-algebra if (i) $\phi \in \Sigma$ (ii) $E \in \Sigma$ implies $X \setminus  E \in \Sigma$ (iii) $E_n \in \Sigma, n\geq 1$ implies $U_{n=1}^{\infty}E_n \in \Sigma$ . I am not sure about what comes beneath the line ""As a $\sigma$ -algebra $\mathcal{T}( \mathbb{R}_{\geq 0}, \mathbb{R}^d)$ is also generated by the following families... And I am struggling with the exercise! Also, I would like a more intuitive understanding to explain the natural events part.","['borel-sets', 'measure-theory', 'real-analysis']"
3096598,Number of automorphisms of some principal $G$-bundles.,"Let $M$ be a manifold and let $G$ be a finite group. Let $P \to M$ be a principal $G$ -bundle. I have some basic questions regarding the automorphism group of $P$ as a principal $G$ -bundle over $M.$ . These are basically sanity checks. I do not need a proof, if what I am saying is true actually is true, just a confirmation. If the statements are false however, I would appreciate the correct statements. If $M$ is a point and $P$ is the trivial $G$ -bundle, is it true that $Aut(P) \cong G?$ . Let $M$ be the circle and let $P$ be a principal bundle corresponding to a morphism $f:\pi_1(M,m) \to G.$ Such a morphism gives an element $g \in G.$ Is it true that $Aut(P) \cong C_G(g)?$ Here $C_G(g)$ is the centralizer of $g$ in $G.$ .","['gauge-theory', 'differential-geometry']"
3096620,"Continuity of partial derivatives at (0,0)","For the function $$f = \begin {cases} \frac{xy}{x^2+y^2}, \text{if } (x,y) \neq (0,0) \\ 0, \text{if } (x,y) = (0,0) \end {cases}$$ show that $\frac{\partial f}{\partial x}$ and $\frac{\partial f}{\partial y}$ are not continuous at (0,0). My attempt: I found $$\frac{\partial f}{\partial x}(x,y)=\frac{y^3-x^2y}{(x^2+y^2)^2}$$ At $(x,y)=(0,0)$ $$\frac{\partial f}{\partial x}(0,0)=\lim_{t\rightarrow 0}\frac{f(0+t,0)-f(0,0)}{t}=0.$$ Similarly $\frac{\partial f}{\partial y}(0,0)=0$ Then $$\lim_{(x,y)\rightarrow(0,0)}\frac{\partial f}{\partial x}(x,y)=\lim_{(x,y)\rightarrow(0,0)}\frac{y^3-x^2y}{(x^2+y^2)^2}= \text{ (consider restriction to the line } x = my) = \lim_{y\rightarrow 0}\frac{y^3-m^2y^3}{(m^2y^2+y^2)^2}=\lim_{y\rightarrow 0}\frac{y^3(1-m^2)}{(m^2+1)^2y^4}=\infty \neq \frac{\partial f}{\partial x}(0,0).$$ Thus $\frac{\partial f}{\partial x}$ is not continuous at (0,0). Similarly, for $\frac{\partial f}{\partial y}.$ Is it correct? Also is it sufficient to show the inequality of the limit and the value of the partial, considering only one restriction to the line (in this case $x=my$ )? Or should we consider other restrictions as well?","['partial-derivative', 'multivariable-calculus', 'real-analysis']"
3096628,"Definitions of pyramid (eg, tetrahedron as ""$1$-fold $3$-pyramid"" vs ""$3$-fold pyramid"")","My lecture note and my textbook offer slightly different definitions of pyramid. Here's the one from the lecture: And here's the one from the textbook: I just want to make sure I interpret the two statements correctly. Am I right to assume that, according to the first definition, a tetrahedron would be called a 1-fold 3-pyramid, while according to the second definition, it is a 3-fold pyramid? ================================================================== Edit 1 : the reason for the above question is because in our class we also have a lemma. Lemma: Let P be an r-fold d-pyramid over Q, then the number of k-face of P is $f_k(P) = \sum_{i=0}^r \binom{r}{i}f_{k-i}(Q).$ Taking the tetrahedron as an example, this formula only works if we see it as a 1-fold 3-pyramid, but not a 3-fold pyramid. Edit 2 : so far I haven't been able to find a lot of examples of pyramids according to the first definition. If possible please show me a few examples with different r's.","['discrete-geometry', 'geometry']"
3096639,Partial derivatives are 0 iff the function is constant,"Let $f:\mathbb R^2\rightarrow \mathbb R$ has first partial derivatives and $\frac{\partial f}{\partial x}=\frac{\partial f}{\partial y}=0, \text{for all } (x,y)\in\mathbb R^2$ . Show that $f$ is constant. (Hint: Show that the restriction of $f$ to a line parallel to one of the coordinate axes is constant). My attempt: Following the hint, consider the restriction of $f$ to a line $y=c$ , then $\frac{\partial f}{\partial x} (x,c) = f_x(x,c)=0$ . Pick 2 points a and b, then by mean value theorem there is $x_0$ , such that $f_x(x,c) = \frac{f(b,c)-f(a,c)}{b-a}=0 \implies f(b,c)-f(a,c)=0 \implies f(b,c)=f(a,c)\implies f(x,c)=const.$ We can show the same way that $f(c,y)=const$ . Am I thinking in the right direction? If so, can I just combine $f(x,c)=const$ and $f(c,y)=const$ to get $f(x,y)=const$ ? Did I miss something?","['partial-derivative', 'multivariable-calculus', 'real-analysis']"
3096675,"Given a line segment, a line parallel to it, and a straightedge, divide the segment into $n$ equal segments","Given a line segment, a line parallel to it, and a straightedge, how to divide the segment into $n$ equal segments? (With a straightedge, you are allowed only to draw straight lines. You are not allowed to mark off distances on the straightedge.)","['euclidean-geometry', 'projective-geometry', 'geometry', 'geometric-construction']"
3096741,"without computing it, show that $I = \mathbb{E}[e^{XY} |X] \geq 1$","$X, Y$ are two independent $\mathcal{N}(0,1)$ random variables this question was a follow up question of this one I honestly don't know if that series of equivalences could be of any help. my reasoning was as follows : $ \mathbb{E}[I] =  \mathbb{E}[e^{\frac{X^{2}}{2}}] = +\infty$ now let's assume that $I<1$ because $e^{XY} \geq0$ then $0\leq I<1   $ this gives $0\leq \mathbb{E}[I]<1  $ contradiction ! is this it ?","['conditional-expectation', 'proof-verification', 'probability-theory']"
3096756,Finding slope m of tangent to curve,"been years since I took calculus and am currently struggling with how to properly work out the following: Using the tanget line slope formula: My understanding is that I would need to find the slope with the following approach: Now, at this point, don't I want to rationalize the numerator? Or the denominator? If I go with rationalizing the numerator (multiplying by the conjugate), I do the following, but end up with a denominator that looks really overly complicated: What am I doing wrong here?","['calculus', 'derivatives', 'slope', 'tangent-line']"
3096817,"If $X,Y$ are two equivalent vector fields in two open sets $A$ and $B$, such that $A\cup B = M$. Are $X$ and $Y$ equivalent?","Let $X$ and $Y$ be smooth vector fields on $\mathbb{T}^2$ . Definition 1: Let $A$ be an open subset of $\mathbb{T}^2$ , we say that $X$ and $Y$ are equivalent in $A$ , if there exists a homeomorphism $h: A \to A$ such that maps orbits of $\left.X\right|_{A}$ in orbits of $\left.Y\right|_A$ , preserving the orientation of the orbits. Definition 2: We say that $X$ and $Y$ are equivalent if $X$ and $Y$ are equivalent in $\mathbb{T}^2$ . Then my question arises My Question: If there exists $A,B \subset \mathbb{T}^2$ open subsets of $\mathbb{T}^2$ such that: $X$ and $Y$ are equivalent in $A$ and $B$ . $A \cup B = \mathbb{T}^2$ . Is it true that $X$ and $Y$ are equivalent? This seems true but I wasn't able to find a way to prove this proposition. Can anyone help me?","['vector-fields', 'ordinary-differential-equations', 'dynamical-systems']"
3096840,The physical meaning of a symplectic form.,"So I've studied a bit about symplectic geometry, and I know that phase space is a symplectic manifold, and the symplectic form induces a poisson bracket. However, what is the physical meaning of the symplectic form? Perhaps it's simply the same as asking what the meaning is of the poisson bracket. What does the poisson bracket say about a system? And what is the physical meaning of observables?","['classical-mechanics', 'symplectic-geometry', 'differential-geometry']"
3096844,Showing commutator subgroup is a subgroup,"Now, the common introduction question to a commutator subgroup $G'$ is showing that it is normal in the group $G$ . However, I'm having a problem with something even more basic than this. Let $[a,b],[c,d] \in G'$ , Then we have: $[a,b][c,d]=a^{-1}b^{-1}abc^{-1}d^{-1}cd$ I don't see an easy to conclude that this of the form $[g,h]=g^{-1}h^{-1}gh$ for $g,h \in G$ . What am i missing here? $G' \neq \{ a^{-1}b^{-1}ab : a,b \in G \}$ $G' = \{ \langle a^{-1}b^{-1}ab \rangle : a,b \in G\}$","['derived-subgroup', 'group-theory']"
3096866,"In the triangle $\triangle ABC$, $|AB|^3 = |AC|^3 + |BC|^3$. Prove that $\angle ACB > 60^\circ$.","The following was a question in the final of the Flanders Mathematics Olympiad 2018 : In the triangle $\triangle ABC$ , $|AB|^3 = |AC|^3 + |BC|^3$ . Prove that $\angle ACB > 60^\circ$ . In this competition, points are assigned for formulating a rigorous and mathematically sound proof. I proved the above by contradiction. Let $\alpha = \angle BAC, \beta = \angle CBA, \gamma = \angle ACB$ . Suppose $\gamma \le 60^\circ$ : $$\gamma \le 60^\circ \iff \sin(\gamma) \leq \frac{\sqrt{3}}{2}$$ Applying the sine rule: $$\frac{\sin(\alpha)}{|BC|} = \frac{\sin(\beta)}{|AC|} = \frac{\sin(\gamma)}{|AB|}$$ $$\iff\frac{|AC|^3}{|AB|^3} + \frac{|BC|^3}{|AB|^3} = \frac{\sin^3(\alpha) + \sin^3(\beta)}{\sin^3(\gamma)} = 1$$ $$\iff \sin^3(\alpha) + \sin^3(\beta) = \sin^3(\gamma) \le \left( \frac{\sqrt{3}}{2} \right)^3$$ $$\iff\sin(\alpha) \le \frac{\sqrt(3)}{2}, \, \sin(\beta) \le \frac{\sqrt(3)}{2}\tag{1}$$ We also know that: $$\alpha + \beta = 180^\circ - \gamma \ge 120^\circ\tag{2}$$ $$\alpha + \beta < 180^\circ\tag{3}$$ Without loss of generality, assume $\alpha \ge \beta$ . From $(1)$ , $(2)$ and $(3)$ , it then follows that: $$a \ge 120^\circ, \, \beta \le 60^\circ$$ $$\implies |BC| > |AB| \qquad \unicode{x21af}$$ Is this answer adequate enough? Can the notation be improved? Are there any alternative approaches to solve this problem?","['contest-math', 'proof-writing', 'proof-verification', 'geometry', 'alternative-proof']"
3096941,A strange inconsistency between a calculation and a simulation of a TASEP,"Consider the following stochastic process, called a totally asymmetric simple exclusion process (TASEP), on the integers $\mathbb{Z}$ : The process evolves over discrete time steps $T = 1, 2, \ldots \infty$ .
Denote the contents of the integer $n$ as $x(n)$ . Initially, at every integer $n$ , $x(n)=1$ with probability $0.5$ and otherwise $x(n)=0$ . If for some $n$ we have that $x(n)=1$ and $x(n+1)=0$ , then with probability $0.5$ , at the next time step we will have $x(n)=0$ and $x(n+1)=1$ . (In other words, every $1$ moves right with probability 0.5, assuming there isn't a $1$ blocking it in its new target position). It's simple to see that the initial distribution (where we have $1$ with probability $0.5$ ) is stationary. (Edit: Based on page 2 of this paper https://arxiv.org/abs/cond-mat/0101200 ), this means that in expectation we should expect the number of $1$ s passing through $n=0$ to be $T/4$ , where $T$ is the number of time steps that have passed. Now consider the following program, which I simulated on my computer: Initialize a 0-1 array a[-1000,1000] such that a[n] = 1 with probability 0.5. Simulate the above Stochastic process for 100 iterations. Count the number of times a[0] goes from 0 to 1. The result of this program is consistently around $15$ , but by the above reasoning we would expect $25$ . In fact, it seems it will always be on average a $0.15$ fraction of the number of iterations (even doing 200, or 300 iterations at a time). So is the math wrong, or is my simulation idea wrong? Actual code I used: https://pastebin.com/iPz1S1fK (""count"" is the number that comes out as 15; prob(50) means ""with probability 50""; Update() performs a single iteration of the TASEP)","['stochastic-processes', 'markov-process', 'probability']"
3096955,Average area of a rectangle inside the unit square,"I recently came across this problem while toying with the problem of the average distance between 2 points in the unit square . These two points also define a rectangle, so I was wondering: What is the expected value of the area of that rectangle? I took this problem to Python and it turns out to be somewhere around one-ninth. However, I have no idea where to start actually calculating the exact value. If someone could share how to get a more exact answer (more efficiently, obviously) via computer science, or how to get the precise answer with calculus, that would help out a bunch.","['analytic-geometry', 'python', 'geometry', 'multivariable-calculus', 'probability']"
3097047,Does every non-compact Riemann surface embed holomorphically into $\mathbb{C}^2$?,"Question: Can every non-compact Riemann surface be holomorphically embedded into $\mathbb{C}^2$ ?  If not, what are some (all?) of the obstructions to such an embedding? This question is partially inspired by the Wikipedia page on Stein manifolds , which taught me two things: Behnke-Stein Theorem (1948): Every non-compact Riemann surface is Stein, hence can be holomorphically embedded in some $\mathbb{C}^N$ . Every Stein manifold of complex dimension $n$ can be embedded into $\mathbb{C}^{2n+1}$ by a biholomorphic proper map.  (It would be nice to have a citation for this.) Together, these two theorems imply that every non-compact Riemann surface holomorphically embeds into $
\mathbb{C}^3$ .  This raises the question of embedding into $\mathbb{C}^2$ .","['complex-analysis', 'complex-manifolds', 'algebraic-geometry', 'several-complex-variables']"
3097058,"Find maximum of $\cos(x)\cos(y)\cos(z)$ when $x + y + z = \frac{\pi}{2}$ and $x, y, z > 0$","Find maximum value of P = $\cos(x)\cos(y)\cos(z)$ , given that $x + y + z = \frac{\pi}{2}$ and $x, y, z > 0$ . Effort 1. I drew a quarter-circle, divided the square angle into three parts, and attempted to derive the expression, but it went to nowhere.","['jensen-inequality', 'real-analysis', 'maxima-minima', 'optimization', 'trigonometry']"
3097078,Integral $\int\frac{2x^2}{2x\cos(2x)+(x^2-1)\sin(2x)} \mathrm d x$,Integrate $\displaystyle\int\dfrac{2x^2}{2x\cos(2x)+(x^2-1)\sin(2x)} \mathrm d x$ I tried dividing by $\cos^2(x)$ and then substituting $\tan(x)=t$ .,"['integration', 'indefinite-integrals', 'derivatives', 'real-analysis']"
3097134,Why isn't $\zeta(3) = 2^3\pi ^{3-1}\sin\left( \frac{\pi 3}{2}\right)\Gamma(1-3)\zeta(1-3) = 0$?,"The zeta function (for $\Re(s)>1$ ) is given by the definition: $\zeta(s) = \sum _{n=1}^{\infty} \left [\frac{1}{n^s} \right]$ The zeta function also can be given by the following functional equation: $\zeta(s) = 2^s\pi ^{s-1}\sin\left( \frac{\pi s}{2}\right)\Gamma(1-s)\zeta(1-s)$ Using the above functional equation, we also know than for all negative even integers (i.e. $s=-2, -4, -6...$ ) the zeta function has trivial zeroes i.e. $\zeta(-2) = 0$ , $\zeta(-4) = 0$ , $\zeta(-6) = 0$ and so on. Substituting $s=3$ in the functional equation we have: a. $\zeta(3) = \sum _{n=1}^{\infty} \left [\frac{1}{n^3} \right]$ b. $\zeta(3) = 2^3\pi ^{3-1}\sin\left( \frac{\pi 3}{2}\right)\Gamma(1-3)\zeta(1-3)$ Since, $\zeta(1-3)=\zeta(-2)=0$ ,  using this in the R.H.S of the functional equation (b.) seems to state that $\zeta(3) = 0$ . But, using (a.) we know that the $\zeta(3)$ is convergent but not equal to zero. So, these two values are different. What is it that I am missing in the functional definition and where is the discrepancy? P.S. I am from a C.S. background and a beginner in analysis still trying to learn.","['complex-analysis', 'riemann-zeta', 'real-analysis']"
3097138,Extreme points and closure of a set in $l^2(\mathbb{N})$,"Consider the subset C of the banach space $l^2(\mathbb{N})$ defined by \begin{equation}
C = \left\{ x \in l^2(\mathbb{N}) \,\Bigg|\, \sum_{n = 0}^{\infty} (n+1) x(n) = 1, \, \, x(n) \geq 0 \, \forall  n \in \mathbb{N} \right\}
\end{equation} It is easy to prove this set is convex. If $x, y \in C$ then $\lambda x + (1-\lambda)y \in C$ for $\lambda \in [0,1]$ since \begin{align}
\sum_{n = 0}^{\infty} (n+1)(\lambda x(n) + (1-\lambda)y(n)) &= \lambda \sum_{n = 0}^{\infty} (x+1)x(n) + (1-\lambda) \sum_{n = 0}^{\infty} (n+1)y(n) \\&= \lambda + (1- \lambda) = 1.
\end{align} It is given that it's extreme points are the following elements \begin{equation}
\delta_n: \mathbb{N} \to \mathbb{C}: m \mapsto \begin{cases} \frac{1}{n+1} \,\, &\text{for} \,\, m = n\\
0 \,\, &\text{else}\end{cases}
\end{equation} My question is: how does one prove these are the only extreme points of $C$ . And also what is the closure of $C$ ?",['functional-analysis']
3097144,"Baby Rudin (""Principles of Mathematical Analysis""), chapter 3 exercise 3 [duplicate]","This question already has answers here : Prob. 3, Chap. 3 in Baby Rudin: If $s_1 = \sqrt{2}$, and $s_{n+1} = \sqrt{2 + \sqrt{s_n}}$, what is the limit of this sequence? (3 answers) Closed 5 years ago . If $s_1=\sqrt 2$ ,
and $$s_{n+1}=\sqrt {2+\sqrt{s_n}}$$ Prove that ${s_n}$ is converging, and that $s_n<2$ for all $n=1,2\ldots$ My attempt to use mathematical induction: if $s_n<2$ then I use $s_{n+1}=\sqrt {2+\sqrt s_n}$ , to prove $s_{n+1}<\sqrt {2+2}=2$ .
I guess $s_n$ is an increasing sequence, I can use the $s_n$ is bounded and increasing, and then prove that $s_n$ converges.","['analysis', 'real-analysis', 'calculus', 'sequences-and-series', 'limits']"
3097187,Finding $\int^{\infty}_{0}\frac{\ln^2(x)}{(1-x^2)^2} dx$,Calculate $$\int^{\infty}_{0}\frac{\ln^2(x)}{(1-x^2)^2}dx$$ I have tried to put $\displaystyle x=\frac{1}{t}$ and $\displaystyle dx=-\frac{1}{t^2}dt$ $$ \int^{\infty}_{0}\frac{t^2\ln^2(t)}{(t^2-1)^2}dt$$ $$\frac{1}{2}\int^{\infty}_{0}t\ln^2(t)\frac{2t}{(t^2-1)^2}dt$$ $$ \frac{1}{2}\bigg[-t\ln^2(t)\frac{1}{t^2-1}+\int^{\infty}_{0}\frac{\ln^2(t)}{t^2-1}+2\int^{\infty}_{0}\frac{\ln(t)}{t^2-1}dt\bigg]$$ How can I solve it?,"['integration', 'definite-integrals']"
3097206,"Where does $\Gamma \left( \frac{3}{2} \right) = \int _0 ^{+\infty}\! \mathrm e ^{-x^2} \, \mathrm d x$ come from?","My teacher solved this problem in class but I don't get how one step is justified. Prove that $$\int_0 ^{+\infty} \! \mathrm e ^{- x^2 } \, \mathrm d x = \dfrac{\sqrt{\pi}}{2}$$ using this relation $$\int_0 ^{+\infty} \! \int_0^{+\infty} \! y \,\mathrm e ^{-(1+ x^2 )y} \, \mathrm d y \, \mathrm d x = \dfrac{\pi}{4}.$$ Using Fubini's theorem we switch integrals: $$\int_0 ^{+\infty} \! y\, \mathrm e ^{-y} \left( \int_0 ^{+\infty} \! \mathrm e ^{-x^2 y} \, \mathrm d x \right) \mathrm d y = \dfrac{\pi}{4}.$$ Let us compute first: $$\int_0 ^{+\infty} \! \mathrm e ^{-x^2 y} \, \mathrm d x =\int _0 ^{+\infty} \! \dfrac{\mathrm e ^{-t ^2}}{\sqrt y}\, \mathrm d t= \dfrac{\mathcal E}{\sqrt y},$$ where we have made the change $x\sqrt y =t $ and $\mathcal E$ is the integral that we want to compute. Then $$\int _0 ^{+\infty} \! y \, \mathrm e ^{-y} \dfrac{\mathcal E}{\sqrt y} \, \mathrm d y = \mathcal E \int _0 ^{+\infty} y ^{\frac{1}{2}} \, \mathrm e ^{-y} \, \mathrm d y = $$ $$=\mathcal E \int _0 ^{+\infty} y ^{\frac{3}{2}-1} \, \mathrm e ^{-y} \, \mathrm d y = \mathcal E \, \Gamma \left( \frac{3}{2} \right) \color{red}{\stackrel{?}{=}} $$ $$\color{red}{\stackrel{?}{=}} \mathcal E \int_0 ^{+\infty} \mathrm e ^{-s ^2} \, \mathrm d s = \mathcal E ^2 = \dfrac{\pi}{4},$$ therefore $$\mathcal E = \dfrac{\sqrt \pi}{2} = \int _0 ^{+\infty}\! \mathrm e ^{-x^2} \, \mathrm d x.$$ What I don't get is how does he relate $\mathcal E$ with the gamma function, that is, $$\Gamma \left( \frac{3}{2} \right) = \int _0 ^{+\infty}\! \mathrm e ^{-x^2} \, \mathrm d x = \mathcal E.$$ I have seen that $\Gamma \left( \frac{3}{2} \right) = \dfrac{\sqrt \pi }{2}$ , but since we don't know the value of $\mathcal E$ yet (as this is what we are trying to prove), this is not a way to relate them. Thank you for your help.","['integration', 'improper-integrals', 'gamma-function']"
3097209,Visual representations of groups (in their symmetric groups) [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 5 years ago . Improve this question Given a group $G$ , left and right multiplications establish the subgroups $\Theta:=\lbrace \theta_a \mid a \in G \rbrace \le \operatorname{Sym}(G)$ and $\Gamma:=\lbrace \gamma_a \mid a\in G \rbrace \le \operatorname{Sym}(G)$ , such that: $G \cong \Theta$ ; $G \cong \Gamma$ ; $\theta_a\gamma_b=\gamma_b\theta_a, \forall a,b \in G$ and then $\Theta\Gamma=\Gamma\Theta \le \operatorname{Sym}(G)$ ; $Z(G) \cong \Theta \cap \Gamma$ ; $\Theta \unlhd \Theta\Gamma$ and $\Gamma \unlhd \Theta\Gamma$ . Besides, coniugacy establishes the subgroup $\Phi:=im_\varphi = \lbrace \varphi_{a} \mid a \in G\rbrace \le \operatorname{Aut}(G) \le \operatorname{Sym}(G)$ . It turns out that $ker_\varphi=Z(G)$ , whence $\Phi \cong G/Z(G)$ (fundamental homomorphism theorem), and finally: $G$ abelian $\Leftrightarrow Z(G)=G \Leftrightarrow \Phi= \lbrace \iota_{\operatorname{Sym}(G)} \rbrace$ ; $G$ centerless ( $Z(G)=\lbrace e \rbrace$ ) $\Leftrightarrow \Phi \cong G$ . REMARK. $\Phi$ is nothing else but the group of inner automorphisms of $G$ , differently denoted by $\operatorname{Inn}(G)$ or $\mathscr{I}(G)$ . Proposition 0. $\Phi \unlhd \operatorname{Aut}(G)$ . Proof. $\forall a,b \in G, \forall \sigma \in \operatorname{Aut}(G)$ , we get: $(\sigma^{-1}\varphi_a\sigma)(b)=\sigma^{-1}(\varphi_a(\sigma(b)))=\sigma^{-1}(a^{-1}\sigma(b)a)=$ $\sigma^{-1}(a^{-1})b\sigma^{-1}(a)$ ; call $\tau:=\sigma^{-1} \in \operatorname{Aut}(G)$ , then $(\sigma^{-1}\varphi_a\sigma)(b)=\tau(a^{-1})b\tau(a)=\tau(a)^{-1}b\tau(a)=$ $\varphi_{\tau(a)}(b)$ , so that $\sigma^{-1}\varphi_a\sigma=\varphi_{\sigma^{-1}(a)} \in \Phi$ . $\blacksquare$ REMARK. $\operatorname{Out}(G):=\operatorname{Aut}(G)/\Phi$ is the (factor) group of outer automorphisms of $G$ . Proposition 1. $\Phi \le \Theta\Gamma$ . Proof. By definition of $\varphi_a$ , $\theta_b$ and $\gamma_c$ , it is $\varphi_a=\theta_ {a^{-1}}\gamma_a$ , and then $\Phi \subseteq \Theta\Gamma$ . $\blacksquare$ Proposition 2. $\Phi \cap \Theta = \Phi \cap \Gamma = \lbrace \iota_{\operatorname{Sym}(G)}\rbrace$ . Proof. $\varphi_a \in \Theta \Leftrightarrow \exists b \in G \mid \varphi_a = \theta_b \Leftrightarrow \varphi_a(c) = \theta_b(c), \forall c \in G \Leftrightarrow a^{-1}ca=bc, \forall c \in G \Rightarrow$ (take $c=a$ ) $a=ba \Rightarrow b=e \Rightarrow \varphi_a=\theta_e=\iota_{\operatorname{Sym}(G)}$ . Equivalently, $\theta_a$ is a homomorphism (and then an automorphism of $G$ ) iff $\theta_a(bc)=\theta_a(b)\theta_a(c)$ iff $abc=abac$ iff $a=e$ iff $\theta_a=\theta_e=\iota_{\operatorname{Sym}(G)}$ . $\blacksquare$ Proposition 3. $\Phi = \Theta\Gamma \cap \operatorname{Aut}(G)$ . Proof. $\theta_a\gamma_b \in \operatorname{Aut}(G)$ iff $(\theta_a\gamma_b)(cd)=(\theta_a\gamma_b)(c)(\theta_a\gamma_b)(d)$ iff $acdb=acbadb$ iff $e=ba$ iff $\theta_a\gamma_b=\theta_{b^{-1}}\gamma_b$ iff $\theta_a\gamma_b \in \Phi$ . $\blacksquare$ It seems to me that Proposition 3 makes the wording ""inner automorphisms"" plausible: they are precisely the only automorphisms that lie inside the ""widest border of $G$ in $\operatorname{Sym}(G)$ "", namely $\Theta\Gamma$ . All what above, has brought me to envisage the following pictures of ""limit"" and ""in between"" situations: I haven't got a specific question to ask, but rather if you can see some other ""nice feature"" I could add, or amend, on the picture.","['symmetric-groups', 'group-theory', 'abstract-algebra', 'visualization']"
3097220,Norm in Sequence Space such that Convergence in Norm does not imply Pointwise Convergence,"I'm wandering if there exist a norm defined on the sequence space $\mathbb{F}^{\omega}$ such that there exist a sequence that converges in norm but it doesn't converge pointwise, element by element. The same thing is asking for a sequence whose norm converges to $0$ but whose elements does not converge to $0$ : $$\exists \{x^{(n)}\}, k \mid \lVert x^{(n)} \lVert \rightarrow 0, \ x^{(n)}_k \nrightarrow 0$$ I couldn't find any example.","['convergence-divergence', 'normed-spaces', 'functional-analysis']"
3097225,"If $a_0 = -1$ and $\sum_{k=0}^n\frac{a_{n-k}}{k+1}=0$, then show $a_n = \int_{1}^{\infty}{\frac{dt}{t^n({\pi}^2+\log^2(t-1))}}$","Bonjour. The following is from IMO 2006: The sequence $(a_n)$ is defined recursively by $a_0=-1$ and $$\sum_{k=0}^{n}{\frac{a_{n-k}}{k+1}}=0, n\geq 1. $$ In the shortlist, the commentator said that this relation holds: $$a_n=\int_{1}^{\infty}{\frac{dt}{t^n({\pi}^2+\log^2(t-1))}} \qquad\forall n\geq 1 \tag{1}$$ Question: How to show the relation $(1)$ ?","['integration', 'analysis', 'complex-analysis', 'calculus', 'combinatorics']"
3097234,Morphisms with connected fibers,"Let $f\colon X\to Y$ be a morphism of schemes. I am interested in the following property (too long for the title): $$ f_{*}\mathcal{O}_{X}=\mathcal{O}_{Y} \quad \text{(P)}$$ Under very reasonable assumptions ( $f$ projective between noetherian schemes), this implies that the fibers are connected (see Corollary III.11.3 in Hartshorne's Algebraic Geometry ). Under still reasonable assumptions ( $f$ proper over a field of characteristic zero with $X$ noetherian and $Y$ noetherian and normal), having connected fibers implies (P) (see Section 1.13 in Debarre's Higher-Dimensional Algebraic Geometry ). Hence the title. What can we say about morphisms with property (P) in general? Does (P) have any nice stability properties? Is there a name for them? I could not find much in the literature. Do we need some extra assumptions to make property (P) interesting? For example, in Lazarsfeld's Positivity in Algebraic Geometry I , he defines an algebraic fibre space as a surjective projective mapping $f\colon X\to Y$ between varieties (reduced and irreducible) with property (P). Then he lists some nice properties of algebraic fibre spaces. This makes me think that property (P) alone may not be that interesting. [P.s. in the previous definition of algebraic fibre space, doesn't surjective follow from projective and (P)? If the image of $X$ is a proper closed subset of $Y$ , then $\mathcal{O}_{Y}$ would have no global sections over the dense open subset $Y\setminus f(X)$ , right?]","['quasicoherent-sheaves', 'algebraic-geometry', 'reference-request']"
3097265,"Is $\mathbb{Z}[x]/\langle 4,x^2+x+1 \rangle$ a field?","I know that $\mathbb{Z}[x]/\langle4, x^2+x+1\rangle$ is isomorphic to $(\mathbb{Z}/4\mathbb{Z})[X]/\langle x^2+x+1\rangle $ . Since $(\Bbb Z/4\Bbb Z)[X]$ is not a PID, irreducibility/reducibility of $x^2+x+1$ is not enough to say whether or not this is a field. My idea is to prove that this ring is not a domain. For example, $(\mathbb{Z}/4\mathbb{Z})[X]/\langle x^2+x+1\rangle$ is not a domain if $2$ is not in the ideal $\langle x^2+x+1\rangle$ but I can't prove this.","['ring-theory', 'abstract-algebra']"
3097342,"Showing $\min\limits_{j=1,\dots,n}|\lambda-\lambda_j|\le ||C||_p||C^{-1}||_p||B||_p$","Let $A$ be a diagonalizable $n\times n$ matrix with eigenvalues $\lambda_1,\dots, \lambda_n$ , $B$ an $n\times n$ matrix, and $\lambda$ an eigenvalue of $A+B$ . Show that $$\min\limits_{j=1,\dots,n}|\lambda-\lambda_j|\le ||C||_p||C^{-1}||_p||B||_p$$ where $C$ is a nonsingular matrix such that $C^{-1}AC$ is diagonal and $p=1,2,\infty$ . I'm having difficulty figuring out where to start. If given some guidance I'm sure I can easily get the rest. I know that under the assumption $A$ is diagonalizable gives $C^{-1}AC=diag(\lambda_1,\dots,\lambda_n)$ , but I am failing to see how I will use the other assumptions. Any input would be greatly appreciated!","['numerical-linear-algebra', 'functional-analysis', 'eigenvalues-eigenvectors']"
3097345,The ant and the rubber string.,"We have an ant on the tip of a horizantal rubber string of length say $\text{10 cm}$ .
The ant moves $\text{5 cm}$ each second, and the rubber string is stretched $\text{100 cm}$ each second. Will the ant ever reach the end of the rubber string? (The numbers ofcourse aren't specific they are just an example) As the first thought  it is impossible, but note that the stretching of the rubber also affects the position of the ant, i.e. if the ant moves its first $\text{5 cm}$ it will be at the half way of the string, then we elongate the string till it becomes $\text{110 cm}$ and now the ant is still at the half way of the string and that is at $\text{55 cm}$ . For example, if $x_i$ represents the position of the ant at the $i^{th}$ second and $y_i$ represents the elongation of the string at the $i^{th}$ second. So in our example $\text{$x_1=5   \qquad       y_1=10$}$ $\text{$x_2=60     \qquad     y_2=110$}$ $\text{$x_3=119.55  \qquad  y_3=210$}$ .... I tried to work that  into equations and sequences, and I came up with this $$x_i=\frac{x_{i-1}}{y_{i-1}} × y_i +5$$ and ofcourse $$y_i=y_{i-1}+100$$ So the question now becomes could $x_i=y_i$ at a certain $i$ ? Is my work correct? 
Any other proved solution is also appreciated... Actually the real paradox is that if we are elongating the rubber string $\text{1 km}$ each second and the ant is still moving at the rate $\text{5 cm}$ each second.
Will the ant ever reach the end of the string?","['convergence-divergence', 'puzzle', 'paradoxes', 'sequences-and-series']"
3097351,Solving equations involving square roots,I am a student and I often encounter these type of equations: $$\sqrt{x^2 + (y-2)^2} + \sqrt{x^2 + (y+2)^2} = 6$$ I usually solve these by taking one term ( $\sqrt{x^2 + (y-2)^2}$ for example) to the right hand side but this seems to take more time. Please suggest me some methods which can help me solve these types of problem quickly. Thanks,['algebra-precalculus']
3097365,Confusion about real separable normed space problem,"Suppose that $X$ is a real separable vector space, and $W$ a closed linear
  subspace of $X$ . Show that there exists a sequence $(z_j )\in X$ such that $z_{j+1} \notin W_j := \mathrm{span} \ W \cup \{z_1, . . . , z_j\}$ and if we define $W_\infty = \mathrm{span} \ W \cup \{z_j\}_{j=1}^\infty$ then $\overline{W_\infty} = X$ . This is a problem in a (non-credit) example sheet I am working on currently. After spending some time trying it I have realised that it is probably incorrect as it stands, but I am not sure. I think that (even with the necessary assumption that $W$ is a proper subspace), $W=\mathbb{C}$ (over $\mathbb{R}$ ) is a counterexample? Maybe there is some implicit assumption in the problem that I am missing. I would appreciate if someone could clarify what the correct version of the problem would be. Please do not give me answers to the problem though, as I would like to first try it myself.","['separable-spaces', 'normed-spaces', 'functional-analysis']"
3097366,Why do these two sequences end in an increasing number of zeroes?,"The trimorphic numbers are integers whose cubes end in the digits of the integers themselves, such as ${\sf{49}}^3=1176\sf{49}$ , and I have discovered something interesting about such integers that end in $9$ and $1$ . The OEIS sequence A224473 is a sequence of trimorphic numbers congruent to $9\pmod{10}$ and has formula $a_1(n)=2\cdot5^{2^n}-1\pmod{10^n}$ for a natural number $n$ . The sequence is $\{9,49,249,1249,\cdots\}$ . If we denote $b_1(n)=a_1(n)^2-1$ , we see the following. $$b_1(1)=80\\b_1(2)=2400\\b_1(3)=62000\\b_1(4)=12560000\\\cdots$$ That is, $b_1(n)\equiv0\pmod{10^n}$ . Furthermore, A224474 is a sequence of trimorphic numbers congruent to $1\pmod{10}$ with formula $a_2(n)=2\cdot16^{5^n}-1\pmod{10^n}$ , and the first few values are $\{1,51,751,8751,\cdots\}$ . If we denote $b_2(n)=a_2(n)^2-1$ , we observe a similar thing. $$b_2(1)=0\\b_2(2)=2600\\b_2(3)=564000\\b_2(4)=76580000\\\cdots$$ That is, $b_2(n)\equiv0\pmod{10^n}$ . Questions . How can it be proved that $b_1(n)$ and $b_2(n)$ are divisible by $10^n$ ? Is the fact that they are all trimorphic numbers just a coincidence, or does this behaviour occur due to that property?","['modular-arithmetic', 'divisibility', 'elementary-number-theory', 'oeis', 'sequences-and-series']"
3097372,Give the standard matrix of the projection $T:\Bbb R^3 \to \Bbb R^3$ that projects a vector on the plane $x+y+z=0$,"I'm trying to figure this one out guys with no luck. Give the standard matrix of the projection $$
T:\Bbb R^3 \to \Bbb R^3
$$ that projects a vector on the plane $x+y+z=0.$ I tried to make a basis $B$ , for instance $(-1,0,1)$ and $(0,1,-1)$ then make them orthogonal using Gram-Schmidt, then make the projection $$\frac{(x,y,z) \cdot (-1,0,1)}{(-1,0,1)\cdot(-1,0,1)} + \frac{(x,y,z) \cdot (0,1,-1)}{(0,1,-1)\cdot(0,1,-1)}$$ After this I'm lost I'm taking a linear algebra course, so an answer in that field would be much appreciated prefferably using the method I used. Thanks in advance!","['matrices', 'projection']"
3097385,Why don't we use closed covers to define compactness of metric space?,"I'm a beginner in metric space. So many books I've read, there is only the notion of open covers. I want to know why do we worry about open covers to define the compactness of metric spaces and why don't we use closed covers? What is the problem in defining closed cover of a set? Can we use the alternative definition of compactness: ""Every closed cover has a finite subcover""?","['general-topology', 'metric-spaces', 'compactness', 'real-analysis']"
3097413,"$f(1+\frac{1}{n})=1$ for all integers $n$ , then find $f""(1)$","Let $f:\mathbb{R} \rightarrow \mathbb{R} $ be a non-constant, three times differentiable function. If $f(1+\frac{1}{n})=1$ for all integers $n$ , then find $f''(1)$ . I could find $f'(1)=\lim_{n \rightarrow \infty} \frac{f(1+\frac{1}{n})-f(1)}{\frac{1}{n}}$ .
Now, $f(1)=1$ due to continuity of $f$ at $1$ .
But the expression of $f''(1)$ is becoming overtly complicated.
Please help.","['continuity', 'functions', 'derivatives', 'real-analysis']"
3097427,Characterizations of Riemannian Volume Form,"I'm trying to understand how some characterizations of the Riemannian volume form $dV$ are equivalent on an oriented Riemannian manifold of dimension $n$ . I'm a bit new to Riemannian geometry (and self-studying it), and I can tell that it should just come down to a straightforward calculation, but I'm stuck for some reason. Characterization 1: If $(\omega^1,...,\omega^n)$ is a local oriented orthonormal coframe for the cotangent bundle, then $dV=\omega^1\wedge...\wedge\omega^n$ . Characterization 2: If $(y^1,...,y^n)$ are oriented local coordinates, then $dV=\sqrt{\det(g_{ij})}dy^1\wedge...\wedge dy^n$ where $g_{ij}$ is the representation of the Riemannian metric in local coordinates. I'm guessing that the square root of the determinant factor shows up from something involving $\det(A)=\sqrt{\det(A A^t)}$ for a suitable matrix $A$ . I have a hunch that using uniqueness of the form (which follows for e.g. characterization 1 from the fact that you can cover the manifold with charts that have local oriented orthonormal coframes) might be important? Any help is very much appreciated!","['differential-forms', 'riemannian-geometry', 'differential-geometry']"
3097448,A woman selects balls from a bowl at random …,"A bowl contains 10 red balls, 10 blue balls and 10 black balls. A woman selects balls at random without looking at them: a) How many balls must she select to be sure of having at least three balls of the same color? b) How many balls must she select to be sure of having at least three blue balls? My solutions: a) $N=30$ , $k=2$ , $[N/2]\ge 3$ so $N=2\cdot(3-1)+1= 5$ b) 23, because if she select 10 red balls and 10 black balls, than she must select those 3 blue balls to be sure that they are at least three of them blue.. Second question: A bowl contains 15 red balls and 15 black balls. A woman selects balls at random without looking at them: a) How many balls must she select to be sure of having at least three balls of the same color? b) How many balls must she select to be sure of having at least three black balls ? My solutions: a) $N=30$ , $k=2$ , $[N/2]\ge 3$ so $N=2\cdot (3-1)+1= 5$ b) $18$ , because if she select 15 red balls, than she must select those 3 black balls to be sure that they are at least three of them black.. Please correct me if I'm wrong!","['pigeonhole-principle', 'discrete-mathematics']"
3097514,closed form for $\int_0^1\frac{\mathrm{Li}_s(x-x^2)}{x-x^2}\mathrm dx$,I am trying to evaluate $$F(s)=\sum_{n\geq1}\frac1{n^{s+1}{2n\choose n}}$$ I started off by noting that $$\frac1{n{2n\choose n}}=\frac12\int_0^1\left[x-x^2\right]^{n-1}\mathrm dx$$ So $$F(s)=\int_0^1\sum_{n\geq1}\frac{\left[x-x^2\right]^{n-1}}{n^s}\mathrm dx$$ And when we recall the definition of the polylogarithm function $$\mathrm{Li}_s(z)=\sum_{n\geq1}\frac{z^n}{n^s}$$ It becomes apparent that $$F(s)=\int_0^1\frac{\mathrm{Li}_{s}(x-x^2)}{x-x^2}\mathrm dx$$ Which I do not know how to deal with. Could I have some help evaluating this integral? Thanks.,"['integration', 'special-functions', 'polylogarithm', 'closed-form', 'sequences-and-series']"
3097543,Eratosthenes' experiment on a flat earth versus on a spherical earth,"On a flat earth we assume that the sun is a point and that it is a distance $H$ from the ground. We put three sticks in the ground, all of height $h$ . The rays of the sun will be lines from the sun to the tip of the stick and a shadow is defined as a line segment from the bottom of the stick where it was put in the ground to the intersection point of the sun ray with the ground. On a spherical earth the sticks are stuck in the ground such that they are normal to the earth. The rays are parallel lines that go through the tips of the sticks, and the shadow is defined as the arc between the bottom point of the stick to the intersection point of the sun ray with the ground Neil Tyson demonstrated this with wells in this video: https://youtu.be/hLPPE3_DVCw?t=318 He said that the angles somehow aren't the same when we add a third stick on a spherical and on a flat earth. I've tried to convince myself that these two models wouldn't produce the same angles this way: Consider a stick stuck in one place on a spherical earth. The angle between the stick and the ray is $x_2$ . Now consider a stick stuck at the same place the first one was stuck, but longer. The angle between the new stick and the new ray would still be $x_2$ since the two rays are parallel. Now consider the same setup on a flat earth. The angles formed by two sticks and two rays wouldn't be the same. Therefore, these two models aren't equivalent. Another way I tried was to calculate those angles. On a spherical earth the angle $x$ formed by any stick and a ray would be $x = d/r$ , where $d$ is the distance from that stick to a point where the ray falls on the earth at a right angle and $r$ is the radius of the earth. On a flat earth the angle would be $tan^{-1}(\frac{d}{H-h})$ . Since on a spherical earth the angle depends only on $d$ (since $r$ is constant), and on a flat earth the angle depends on the height of the stick $h$ , these two models cannot be equivalent. Are these two justifications correct? If not, what would be the correct one?","['euclidean-geometry', 'trigonometry', 'proof-verification', 'geometry']"
3097573,"Angle bisector in triangle, quick question: $|AE| = \frac{bc}{a+c}$","Triangle $ABC$ ; $AB=c, BC=a, AC=b$ ; angle bisector of angle $(c, a)$ cuts $AC$ in point $E$ . Why is the following true? $$|AE| = \frac{bc}{a+c}$$ Where does that come from?","['triangles', 'trigonometry', 'geometry']"
3097599,Help understanding a little Jacobians lemma,"This was used as lemma in a bigger proof. Let $A ⊆ ℝ^m$ be an open set, $f = (f_1,…,f_m) : A → ℝ^m$ a $C^1$ function, and $p ∈ A$ . If $det[Df(p)] ≠ 0$ , then there is an open ball $B ⊆ A$ of center $p$ such that $f|_B$ is injective. proof: The function $x ↦ det[Df(x)]$ is continuous, so there is an open ball $B ⊆ A$ , of center $p$ , such that $x ∈ B ⇒ det[Df(x)] ≠ 0$ . Let $a$ and $b$ be two points of $B$ . By the mean value theorem we have $f_i(b) - f_i(a) = Df_i(c_i)⋅(b-a)$ for some $c_i ∈ \{ta + (1-t)b : t \in [0,1]\}$ , this means that $$f(b) - f(a) = \begin{bmatrix}Df_1(c_1)\\\vdots\\Df_m(c_m)\end{bmatrix}⋅(b-a).$$ But $det[Df(c_i)] ≠ 0$ so $f(b) = f(a) ⇒ b = a$ . The last step is where I have troubles, it seems to me that we need $$det\begin{bmatrix}Df_1(c_1)\\\vdots\\Df_m(c_m)\end{bmatrix} ≠ 0$$ and it's not clear how this follows from $det[Df(c_i)] ≠ 0$ .","['multivariable-calculus', 'calculus', 'linear-algebra']"
3097721,"Why, in topology, is continuity defined with inverse images? [duplicate]",This question already has answers here : Why aren’t continuous functions defined the other way around? (7 answers) Closed 5 years ago . In topology we defined a continuous map to be a map between 2 spaces $f: X \mapsto Y$ such that if $U\subset Y$ is open then $f^{-1}(U)$ is open. Why did we use the preimage; why not say 'a continuous map always maps open sets to open sets'?,['general-topology']
3097750,The sum of the series $ \cos(x)-\cos(2x)+\cos(3x)-...$,"In the book ""The spirit of mathematical analysis"" of Martin Ohm, the author gives an example of differentiating an infinite series and obtaining an absurd result (page 2) From the series $\frac{x}{2}=\sin(x)-\frac{1}{2}\sin2x+\frac{1}{3}\sin(3x)-...$ (1) If one differentiate terms by terms, one obtains this series $\frac{1}{2}=\cos(x)-\cos(2x)+\cos(3x)-...$ (2) The author said the last series is divergent, therefore this result is nonsensical. My question is how does one obtain the first series? What transformation do you perform to obtain $\frac{x}{2}$ on the left hand side. My second question how can we prove that the second series is divergent?",['calculus']
3097907,Derivative of power series :,"If $ m  ∈ ]0,1[ $ and $ f(x)=\sum_{k>=1}\frac{m^kx^k}{k}$ , $-1/m < x < 1/m,$ then $ f'(1)$ equals to: a) $m$ b) $0$ c) $m/(1+m)$ d) $1/(1-m)$ e) $m/(1-m)$ I tried solving it and got $$ f(x)=\sum_{k\geq 1}\frac{m^kx^k}{k},$$ $$ f'(x)=\sum_{k\geq 1}\frac{m^kkx^{k-1}}{k},$$ $$ f'(1)=\sum_{k\geq 1}{m^k1^{k-1}}$$ Now, what should I do? Can someone help me, please?","['calculus', 'derivatives', 'sequences-and-series']"
3097947,Is it valid to define $\binom{n}{n+k} = 0$,"Is it valid to define $$\binom{n}{n+k} = 0$$ where $k$ is an integer in $\{k < -n\}\cup\{k > n\}$ ? I couldn't find anything on this notation via a quick google search, but I ran into it in the induction step of the proof that $$\sum_{k=0}^n{\binom{n}{k}} = 2^n \tag{$\star$}$$ where the following is obtained by Pascal's identity: \begin{align}
\sum_{k=0}^{n+1}{\binom{n+1}{k}} &= \sum_{k=0}^{n+1}{\binom{n}{k-1}} + \sum_{k=0}^{n+1}{\binom{n}{k}} \\ \\
&= \binom{n}{-1} + \sum_{k=1}^{n+1}{\binom{n}{k-1}} + \sum_{k=0}^{n}{\binom{n}{k}} + \binom{n}{n+1} \\ \\
&= 0 + \sum_{k=0}^{n}{\binom{n}{k}} + \sum_{k=0}^{n}{\binom{n}{k}} + 0 \\ \\
&= 2\cdot 2^n 
\end{align} where this approach only makes sense if those aforementioned forms are zero. To me it seems to intuitively makes sense, since there are zero ways to do either of those things, since they are impossible. I'm skeptical that this definition is valid because I saw a proof of $(\star)$ where those expressions were avoided by other reasoning.","['notation', 'binomial-coefficients', 'combinatorics', 'combinatorial-proofs']"
3097953,I can only show $|X_{n}-X||Y_{n}-Y|\xrightarrow{P} 0$ for $0<\delta<1$,"Say $X_{n}\xrightarrow{P} X$ and $Y_{n}\xrightarrow{P} Y$ (*) I want to show that: $|X_{n}-X||Y_{n}-Y|\xrightarrow{P} 0$ My ideas: Let $0<\delta\leq1$ $P( |X_{n}-X||Y_{n}-Y| \geq \delta )\leq P(|X_{n}-X|\geq\delta)+P(|Y_{n}-Y|\geq\delta)\xrightarrow{n\to \infty}0$ But I do not have any sensible ideas on how to show that this is the case for $\delta > 0$ Let me perhaps explain the background of the question: I want to show under condition (*) that $X_{n}Y_{n}\xrightarrow{P}XY$ and as a hint, I am given that $X_{n}Y_{n}-XY=(X_{n}-X)(Y_{n}-Y)+X(Y_{n}-Y)+Y(X_{n}-X)$ So in order to show convergence in probability, I need to show it for $\delta > 0$ and not $0<\delta \leq 1$ , correct?","['probability-theory', 'probability', 'random-variables']"
3097974,Understanding the inverse limit and universal property of topological spaces,"Let $\{X_i, \varphi_{ij},I\}$ be an inverse system of topological space index by a directed poset $I$ .
Now I would like to understand the proof for the existence of an inverse limit $(X,\varphi_i)$ . We define $$X = \left\{ (x_i)\in \prod_{i \in I} X_i \: \middle|\: \varphi_{ij}(x_i) = x_i \text{ whenever } i \succeq j \right\} $$ and $\varphi_i: X \to X_i$ be the restriction of the canonical projection $\pi_i: \prod_{j \in I} X_j \to X_i$ on $X$ . Since the $\pi_i$ are continuous by the definition of the product topology, the $\varphi_i$ must be continous too (as restrictions of continous maps are continuous). By construction, the maps $\varphi_i$ are compatible, i.e. for $i \succeq j$ we have $ \varphi_{ij} \circ \varphi_i = \varphi_j $ . Now I need to show that the universal property is satisfied: Let $Y$ be a topological space and $\psi_i: Y \to X_i$ be a set of compatible continuous mappings. We can define a map $\psi:Y \to X$ as follows: If $y \in Y$ , then define $\psi(y) = x$ where is the element $x = (x_i) \in X$ defined by $x_i = \psi_i(y)$ for each $i \in I$ . By construction, we have $\varphi_i \circ \psi = \psi_i$ . But but I did not understand yet why $\psi$ is continuous : Let $O \subseteq X$ be an open subset. Then I need to show that $\psi^{-1}(O)$ is open too. If only we could we find a way to describe $O$ with $\varphi_i^{-1}(O_i)$ for open sets $O_i \subseteq X_i$ , then that would be nice because then $\psi^{-1} ( \varphi_i^{-1}(O_i) ) = \psi_i^{-1}(O_i)$ which is open because $\psi_i$ is continous by assumption. Could you please help me with this problem? Thank you in advance!","['limits-colimits', 'proof-explanation', 'category-theory', 'universal-property', 'general-topology']"
3097998,Conditional probability given only an average,"I’ve been working on this question, which I found on physics.SE. Unfortunately it was closed because it’s a homework question, but I’d like to get more of a hint than the original poster got. I know that I’m supposed to use Bayes’ Theorem, but I don’t see how I’m supposed to use the fact that $\bar{N}$ is known. Every effort so far has yielded an unwieldy fraction that can’t be simplified. Edit: Apparently I'm supposed to copy/paste the question. Here it is: This is one of the exercises of Barnett's book on quantum information . A particle counter records counts with an efficiency $\eta$ . This means that each particle is detected with probability $\eta$ and missed with probability $1-\eta$ . Let $N$ be the number of particles present and $n$ be  the number of detected. 
Then: \begin{equation}
P(n|N)=\frac{N!}{n!(N-n)!}\eta^n (1-\eta)^{N-n}
\end{equation} I know the mean number of particle present is: \begin{equation}
\bar{N}=\sum N P(N)
\end{equation} I want to calculate $P(N|n)$ . I'm stuck here by a while, so I do not know how to proceed. Edit 2: I'm adding a screenshot of the question in question:","['conditional-probability', 'quantum-information', 'bayes-theorem', 'probability']"
3098000,"If R is not an equivalence relation, then its classes do not form a partition?","True or false: if X is a set and R is a relation on X which is not an equivalence relation,
then {[x]R : x ∈ X}
is not a partition of X. After some fruitless efforts, it dawned on me to take the contrapositive: If {[x]R : x ∈ X} is a partition of X, then R is an equivalence relation on X. Is this indeed the contrapositive statement, and, if so, is its proof any easier than that of the original statement? Because I wasn't making any progress with that.",['elementary-set-theory']
3098028,Probability that an irreducible polynomial has a root modulo a prime $p$,"Let $q$ be an irreducible polynomial over $\mathbb{Z}.$ What is the probability that $q$ has at least one root modulo a prime $p?$ For quadratic $q,$ the probability should be about a half by quadratic reciprocity in combination with completing the square. The probability that a general function from $\mathbb{F}_p$ to itself has a root is about $\frac{e-1}{e}.$ Therefore, one would guess as the degree of the polynomial goes to infinity, that the probability approaches this number.","['irreducible-polynomials', 'number-theory', 'algebraic-number-theory']"
3098099,"If 2x2 real matrices $A$, $B$ and $A-B$ are all idempotent, does this imply $AB=BA$?","I am not sure if this is true. If $2 \times 2$ real matrices $A$ , $B$ and $A-B$ are all idempotent, does this imply $AB=BA$ ?   I can't yet complete the proof nor find a counter example.","['abstract-algebra', 'linear-algebra']"
3098132,"Prove that $\lim_{(x,y)\to (0,0)}\frac{x^{2}+xy+y^{2}}{\sqrt{x^{2}+y^{2}}}=0$.","Prove that $\displaystyle \lim_{(x,y)\to (0,0)}\frac{x^{2}+xy+y^{2}}{\sqrt{x^{2}+y^{2}}}=0$ . This has been my rough work so far, but I am not sure how to go further or if I am doing it the wrong way... $\displaystyle|f(x,y)-L|=\left |\frac{x^{2}+xy+y^{2}}{\sqrt{x^{2}+y^{2}}}  \right | \leq \frac{|x^{2}+xy+y^{2}|}{\big|\sqrt{x^{2}+y^{2}}\big|}\cdot \frac{\sqrt{x^{2}+y^{2}}}{\sqrt{x^{2}+y^{2}}} = \frac{\big(\sqrt{x^{2}+y^{2}}\big)|x^{2}+xy+y^{2}|}{|x^{2}+y^{2}|}$ I wanted the square root on top to help determine what I should set my $\delta$ as. Any ideas on how to finish this or do it in a better way?","['limits', 'multivariable-calculus', 'epsilon-delta']"
3098165,Smooth basis of $L^2$ with uniformly controlled derivatives,"Is there a basis $\{f_i\}_{i\in\mathbb{N}}$ of $L^2[0,1]$ , where each $f_i$ is smooth and the second derivative of $f_i$ is uniformly bounded in $i$ ? Thoughts: I have a vague feeling that the existence of such basis might make it impossible to approximate certain functions in $L^2[0,1]$ with rapid variation. However, I'm not able to give a rigorous proof of this (or give an example of such a basis if it does exist).","['lebesgue-integral', 'functional-analysis', 'analysis']"
3098179,Properties of Miquel point,"Let $ABCD$ be a quadrilateral with $P=AD \cap BC$ and $Q=AB\cap CD$ . Let $M$ be the miquel point of the quadrilateral. Prove the following- $\text{1)}$ If $O_1$ and $O_2$ be the centres of $\triangle PAB$ and $\triangle PDC$ then $MO_1O_2 \sim MAD$ . $\text{2)}$ $O_1,O_2$ and the circumcircles of $\triangle QBC$ and the circumcircle of $\triangle QAD$ are concyclic.","['euclidean-geometry', 'geometry']"
3098180,"Is there a function $f:[0;1]\rightarrow \Bbb R ^n$ of class $C^ \infty$ with $f^{(i)}(0)=10^i.f^{(i)}(1) \, \forall \, i \in \Bbb N_0$","I have the function $g:\Bbb R_{>0} \rightarrow [0.1;1)$ given by $$g(x)=10^{-1-\lfloor \log_{10} (x) \rfloor}.x$$ Which kind of ""erase"" the coma in the decimal expresion of $x$ . For example $$g(123,539)=0,123539 \qquad; \qquad g(0,00012)=0,12$$ And I'm trying to find a function $f:[0.1;1]\rightarrow \Bbb R ^n$ of class $C^ \infty$ such that $f  \circ g$ is a function of class $C^ \infty$ (because $g$ it's not a pretty function and I want to make it pretty in order to be able to work with it). I've managed to prove $f  \circ g$ is $C^ \infty$ if and only if $f$ satisfy the following property $$f^{(i)}(0.1)=10^i.f^{(i)}(1) \, \forall \, i \in \Bbb N_0$$ I've also manage to prove this is equivalent to finding a function $h:[0;1]\rightarrow \Bbb R ^n$ of class $C^ \infty$ with the same property $$h^{(i)}(0)=10^i.h^{(i)}(1) \, \forall \, i \in \Bbb N_0$$ Because we can take $f(x)=h((10x-1)/9)$ and it will satisfy the property we were looking for. In order to avoid trivial solutions such as $h$ beeing constant, I will also ask for the following property $$x\neq y \qquad h(x)=h(y) \Rightarrow x=0 \; , \; y=1$$ So $h$ is injective in $(0;1)$ . I haven't been able to find such a function and I don't know how to search for one so I'm kind of lost.","['derivatives', 'analysis']"
3098188,Behavior of $f(x)=(-1)^x$,"For what $x$ is $f(x)=(-1)^x$ a real number, and when is it a complex number? When I graph it online, the graph glitches out and has points all over the place.","['functions', 'complex-numbers']"
3098211,"What is the notation for alternating series with ""$\cdots$""?","I know that the notation isn't very important, but I am curious. If I have the following alternating series: $$
\sum_{n=0}^{\infty} \frac{(-1)^n}{n!}
$$ Which of the following notations is the most correct (or the best) for represent the previous series? \begin{align}
&\frac{1}{0!}-\frac{1}{1!}+\frac{1}{2!}-\frac{1}{3!}+\frac{1}{4!}+\cdots \tag{1} \\[6pt]
&\frac{1}{0!}-\frac{1}{1!}+\frac{1}{2!}-\frac{1}{3!}+\frac{1}{4!}-\cdots \tag{2} \\[6pt]
&\frac{1}{0!}-\frac{1}{1!}+\frac{1}{2!}-\frac{1}{3!}+\frac{1}{4!}\pm\cdots \tag{3} \\[6pt]
&\frac{1}{0!}-\frac{1}{1!}+\frac{1}{2!}-\frac{1}{3!}+\frac{1}{4!}+-\cdots \tag{4} \\[6pt]
&\frac{1}{0!}-\frac{1}{1!}+\frac{1}{2!}-\frac{1}{3!}+\frac{1}{4!}\cdots \tag{5} \\
\end{align} I think that is the equation $(3)$ , but I am not sure.","['notation', 'sequences-and-series']"
3098232,"How can $f(x,y)$ be written as a function of $g\left(\frac{y}{x}\right)$?","If $f(tx,ty)=f(x,y)$ , how does it imply that: $$f(x,y)=g\left(\dfrac {y}{x}\right)$$ Yesterday I asked a question on ordinary differential equations and got an answer. The answerer used the above stated ""theorem"" but I didn't understand why it is always true. Also why is $t$ (which is a constant) set to $1/x?$ Why can't we set $t=1/(x^2+1)$ or anything else? Is it that we can set $t$ to any function of $x$ that makes my life easy? Why is it so?","['calculus', 'functions', 'ordinary-differential-equations', 'substitution']"
3098233,Is there a functional (i.e. infinite-dimensional) generalization of the second partial derivative test?,"For a smooth function $f: \mathbb{R}^n \to \mathbb{R}$ , we can (usually) test whether a critical point ${\bf x}_0$ (at which ${\bf \nabla} f({\bf x}_0) = {\bf 0}$ ) is a local maximum, minimum, or saddle point via the second partial derivative test , which considers the signs of the eigenvalues of the Hessian matrix $H_{ij} := \partial_i \partial_j f$ . This result can be generalized to successively more general domains of $f$ : If the domain of $f$ is an arbitrary Riemannian manifold, then the test still works, but we instead consider the eigenvalues of the tensor $H^i_{\ \ j} = g^{ik} H_{kj}$ , where $H_{kj}$ is the Hessian tensor $H_{ij} := \nabla_i \nabla_j f = \partial_i \partial_j f - \Gamma_{ij}^k \partial_k f$ , where $\Gamma_{ij}^k$ are the Christoffel symbols (of the second kind). If the domain of $f$ is an arbitrary smooth manifold with a torsion-free connection, then the Hessian (as defined directly above) is a rank- $(2,0)$ tensor rather than a rank- $(1,1)$ tensor, so we can't talk about its eigenvalues. But we can still talk about the signature of the corresponding quadratic form by Sylvester's law of inertia , so I believe the test still works. If the domain of $f$ is an arbitrary smooth manifold without a connection, then there's no natural way to define a Hessian tensor away from the critical points. But at a critical point the Hessian tensor becomes independent of the connection, so we can define it (in local coordinates) by the usual Euclidean-space formula $H_{ij} := \partial_i \partial_j f$ and use Sylvester's law of inertia as above. Now if $f$ (which I will rename $S$ ) is a smooth functional $S[q]$ , then its domain is an infinite-dimensional space of functions $q(t)$ . In this case we can still talk about critical ""points"" of the functional, which are functions $q_0(t)$ at which $S[q]$ is stationary. For example, if $S$ takes the form $$S[q] = \int_a^b L \left( q(t), \frac{dq}{dt}, t \right) dt$$ for some constants $a$ and $b$ and differentiable function $L: \mathbb{R}^3 \to \mathbb{R}$ , then the critical ""points"" $q_0(t)$ are given by the Euler-Lagrange equation $$\frac{\partial L}{\partial q} - \frac{d}{dt} \frac{\partial L}{\partial \dot{q}} = 0.$$ Is there a functional generalization of the second partial derivative test that tests whether these critical functions $q_0(t)$ are local minima, local maxima, or saddle points of the functional $F[q]$ ? (I don't know anything about quadratic forms on infinite-dimensional vector spaces, so I have no idea if there's any notion of a signature, etc.)","['quadratic-forms', 'functional-analysis', 'stationary-point', 'calculus-of-variations']"
3098234,"Proving ${u_k}\to u$ given $\lim_{k\to\infty}\langle u_k,v\rangle=\langle u,v\rangle$ for $u\in \mathbb{R}^n,\forall v\in \mathbb{R}^n$","I'm having trouble solving the following problem. Problem. Prove ${u_k}\to u$ given $\lim_{k\to\infty}\langle u_k,v\rangle=\langle u,v\rangle$ for $u\in \mathbb{R}^n$ , $\forall v\in \mathbb{R}^n$ The textbook introduces the $i^{\text{th}}$ component function $p_{i} : \mathbb{R}^{n} \to \mathbb{R}$ for $1 \leq i \leq n$ by $p_{i}(u) = u_{i}$ , where $u \in \mathbb{R}^{n}$ . Using this definition, I can express any vector $u \in \mathbb{R}^{n}$ by $u = (p_{1}(u), \ldots, p_{n}(u))$ . I know that this function is linear.
The book also tells us that a sequence $\{u_{k}\}$ converges to $u$ in $\mathbb{R}^{n}$ if and only if it converges componentwise (i.e. for each $1 \leq i \leq n$ , $\lim_{k\to\infty} p_{i}(u_{k}) = p_{i}(u)).$ The book provides a hint to define the point $e_{i} \in \mathbb{R}^{n}$ whose $i^{\text{ith}}$ component is equal to $1$ and every other component equals $0$ . This way, $p_{i}(u) = \langle u, e_{i}\rangle$ for each point $u \in \mathbb{R}^{n}$ . I've been working with this component function and don't seem to be making any progress. Any help is appreciated Note: $\langle u,v\rangle$ denotes $u\cdot v$ , u and v are points in $\mathbb{R}^n$ , $u_k$ is a sequence in $\mathbb{R}^n$ . My attempt: Letting $u_k=(u_1^k,u_2^k,...u_n^k)$ with the $k$ representing the $k$ -th term in the sequence $u=(u_1,u_2,...u_n)$ . Then $\lim_{k\to\infty}u_i^k=u_i$ $\forall i$ . $\lim_{k\to\infty}\langle u_k,v\rangle=\langle u,v\rangle$ for any given $v\in\mathbb{R}$ , let $v=e_i$ then $\lim_{k\to\infty}\langle u_k,e_i\rangle=\langle u,e_i\rangle$ . Before proceeding we establish $\langle e_i, e_i\rangle=1$ and $\langle e_i,e_j\rangle=0$ assuming $i\neq j$ . \begin{align*}
\lim_{k\to\infty} \langle u_k,e_i\rangle
&= \Big< \lim_{k\to\infty} u_k, e_i \Big>
 = \Big< \lim_{k\to\infty}(u_1^k, u_2^k, \cdots, u_n^k),e_i \Big> \\
&= \Big< \Big( \lim_{k\to\infty}u_1^k, \lim_{k\to\infty}u_2^k, \cdots, \lim_{k\to\infty}u_n^k \Big),e_i \Big>
 =\lim_{k\to\infty} u_i^k
\end{align*} Now we have $$\lim_{k\to\infty}\langle u_k,e_i\rangle
= \lim_{k\to\infty}u_i^k
= \langle u,e_i\rangle=\langle (u_1,u_2,...u_n),e_i\rangle
= u_i, \ \forall i \quad \Box$$","['real-analysis', 'linear-algebra', 'sequences-and-series', 'limits', 'convergence-divergence']"
3098252,Summation of series using definite integral,"I learned that definite integral gives the signed area under a curve by dividing the curve into small rectangular strips and ""making"" its width shrink to zero. Using this knowledge summation of certain series can be found. I converted definite integral in this form $$ \int_{a}^{b} f(x) \, \mathrm{d}x = \lim_{n\to\infty} \frac{b-a}{n} \sum_{r=1}^{n} f\left( a + \left(\frac{b-a}{n}\right)r \right) $$ However, another equivalent form is known to exist, provided below, and I find it much more convenient to use that form. I tried to manipulate the sum to arrive at the equivalent form but so far I've not able to succeed. $$ \int_{a}^{b} f(x) \, \mathrm{d}x = \lim_{n\to\infty} \frac{1}{n} \sum_{r=g(n)}^{h(n)} f\left(\frac{r}{n}\right),
\quad \text{where } \begin{cases}
\lim_{n\to\infty} \frac{g(n)}{n} = a, \\ 
\lim_{n\to\infty} \frac{h(n)}{n} = b.
\end{cases} $$ Can someone help (give me a hint perhaps) on how to convert to the second much more convenient expression. I find second expression much more convenient because the limits of integration can be very easily found using it. Any help will be appreciated. EDIT: I've still not able to derive the equivalent relation mentioned above. Can someone hint me?","['integration', 'summation', 'definite-integrals', 'calculus', 'limits']"
3098301,"Is there a theory of ""hybrid"" geometries?","Standard 2D geometries, elliptic, Euclidean and hyperbolic, can be all derived from the same basic idea: start with projective geometry formed by lines and planes through origin in $R^3$ and then put some quadric in its way. $x^2 + y^2 + z^2 = 1$ for elliptic, $z^2 = 1$ for Euclidean, and $x^2 + y^2 - z^2 = 1$ for hyperbolic. This can be rewritten as $1x^2 + 1y^2 + z^2 = 1$ , $0x^2 + 0y^2 + z^2 = 1$ , and $(-1)x^2 + (-1)y^2 + z^2 = 1$ . I tried to vary the parameters for the projection surface and found some possibilities for hybrid geometries that are no longer isotropic because they contain non-isomorphic lines. Cylinder $x^2 + z^2 = 1$ leads to a hybrid of elliptic and Euclidean geometry, hyperbolic cylinder $x^2 - z^2 = 1$ to a hybrid of Euclidean and hyperbolic geometry and one-sheet hyperboloid $x^2 - y^2 + z^2 = 1$ to a hybrid of elliptic and hyperbolic geometry. If we consider elliptic geometry to contain no ideal points, Euclidean geometry to contain an ideal line (line at infinity), and hyperbolic geometry to contain an ideal conic (the absolute), then these three hybrids have a single ideal point, two ideal lines that intersect, and an ideal conic, respectively. The difference between the last one and hyperbolic geometry is that hyperbolic geometry has real points inside the conic and ultra-ideal points outside of it, while the elliptic/hyperbolic hybrid is reversed: its real points are outside the conic. This is as far as I got -- there should be a way to impose metric on these geometries so that straight lines would be shortest distances between points. I'd be interested in knowing whether someone has studied this further?","['hyperbolic-geometry', 'geometry']"
3098324,"If $\omega \in \bigwedge^k\mathbb{R}^d$ is decomposable over $\mathbb C$, is it decomposable over $\mathbb R$?","Let $k,d$ be positive integers, and let $\omega \in \bigwedge^k\mathbb{R}^d$ be decomposable in $ \bigwedge^k\mathbb{C}^d$ . Is $\omega$ decomposable in $\bigwedge^k\mathbb{R}^d$ ? Edit: Let me be more careful about the formulation of this question, as $\bigwedge^k\mathbb{C}^d$ can have two different non-isomorphic interpretation: $\bigwedge^k_{\mathbb{R}}\mathbb{C}^d$ : Here we take exterior power over $\mathbb R$ . In particular, we think of $\mathbb{C}^d$ as a real $2d$ -dimensional vector space. In that case $\mathbb{R}^d$ is a vector subspace (over $\mathbb{R}$ ), and so we have the general   claim that “being decomposable” is a property which remains invariant under passing to a subspace. So, in that case, the answer is positive. Sasha's answer refers to this interpretation of the question. $\bigwedge^k_{\mathbb{C}}\mathbb{C}^d$ : Here we take exterior power over $\mathbb C$ , and we think of $\mathbb{C}^d$ as a complex vector space. In this case $\mathbb{R}^d$ is not a (complex) vector subspace of $\mathbb{C}^d$ , but we can still view $\bigwedge^k\mathbb{R}^d$ as a subspace of $\bigwedge^k_{\mathbb{C}}\mathbb{C}^d$ , via complexification . This because complexification commutes with exterior powers , so $(\bigwedge^k\mathbb{R}^d)^{\mathbb C}=\bigwedge^k_{\mathbb{C}}((\mathbb{R}^d)^{\mathbb C})=\bigwedge^k_{\mathbb{C}}\mathbb{C}^d.$ Any real vector space $V$ can be viewed as a subspace of its complexification $V^{\mathbb C}=V \otimes_{\mathbb R}C$ via the map $v \to v \otimes 1$ . Thus, we can consider in this way $\bigwedge^k\mathbb{R}^d$ as a subspace of $(\bigwedge^k\mathbb{R}^d)^{\mathbb C}=\bigwedge^k_{\mathbb{C}}\mathbb{C}^d.$ Now we are given an element $\omega \in \bigwedge^k\mathbb{R}^d$ , which is decomposable as an element in $\bigwedge^k_{\mathbb{C}}\mathbb{C}^d$ , and we ask whether or not it is decomposable as an element in $ \bigwedge^k\mathbb{R}^d$ . What is the answer for this second variant of the question? Comment: Perhaps there is a way to view $\bigwedge^k_{\mathbb{C}}\mathbb{C}^d$ as a subspace of $\bigwedge^k_{\mathbb{R}}\mathbb{C}^d$ in a way which preserves decomposability, and the ""real copy"" $\bigwedge^k_{\mathbb{R}}\mathbb{R}^d$ , thus reducing the second problem to the first one. I asked about the possible existence of such an embedding here . So far, I only know that the answer is positive for $k=2$ : Let $\omega \in \bigwedge^2\mathbb{R}^d$ be decomposable in $\bigwedge^2\mathbb{C}^d$ . $\omega$ can be written as $$\omega=(u_1+iv_1) \wedge (u_2+iv_2), \tag{1}$$ where $u_1,u_2,v_1,v_2 \in \mathbb R^d$ . Since $$ \omega=(u_1 \wedge u_2 - v_1 \wedge v_2)+i (v_1 \wedge u_2+u_1 \wedge v_2), $$ $\omega \in \bigwedge^2\mathbb{R}^d$ if and only if $$v_1 \wedge u_2=-u_1 \wedge v_2, \tag{2}$$ where this is an equality in $\bigwedge^2\mathbb{R}^d$ . Suppose that $\omega \in \bigwedge^2\mathbb{R}^d$ . If $\dim(\text{span}_{\mathbb R}(u_1,u_2) \cap \text{span}_{\mathbb R}(v_1,v_2)) \ge 1$ then $\omega=u_1 \wedge u_2 - v_1 \wedge v_2$ is decomposable in $\bigwedge^2\mathbb{R}^d$ . Otherwise, $u_1,u_2,v_1,v_2$ are linearly independent over $\mathbb R$ , which violates equation $(2)$ . I don't see an immediate generalization of this proof for $k \ge 3$ . By expanding $$\omega=(u_1+iv_1) \wedge (u_2+iv_2) \wedge \dots \wedge (u_k+iv_k)$$ we get more than two summands in the real part.","['differential-geometry', 'complex-geometry', 'algebraic-geometry', 'real-algebraic-geometry', 'exterior-algebra']"
3098347,"False proof that $\langle\chi,1_G\rangle$ need not be an integer.","I'd like to know where the following calculation has gone wrong. I'm sure it is a silly error. Let $G$ be a finite group acting on the right cosets $G/H$ of $H\le G$ . Let $\chi$ be the character of the permutation representation of $G$ defined by this action. Let $1_G$ be the trivial character of $G$ . Then for $g\in G$ we have that $\chi(g)$ is the number of points in $H/G$ fixed by $g$ . But $g$ fixes $Hx$ if and only if $G\in H^x$ so $\chi(g)$ is the number of conjugates $K$ of $H$ with $g\in K$ . Denoting by $Cl(H)$ the set of subgroups of $G$ conjugate to $H$ and $$(x,K)=\cases{1 & $x\in K$ \\ 0 & $x\notin K$}$$ we have $$\begin{array}{ll}
\langle \chi, 1_G\rangle & =\frac{1}{|G|}\sum\limits_{g\in G}\chi(g) \\
 & =\frac{1}{|G|}\sum\limits_{g\in G}\sum\limits_{K\in Cl(H)}(g,K) \\
 & =\frac{1}{|G|}\sum\limits_{K\in Cl(H)}\sum\limits_{g\in G}(g,K) \\
 & =\frac{1}{|G|}\sum\limits_{K\in Cl(H)}|K| \\
 & =\frac{1}{|G|}|Cl(H)||H| \\
 & =\frac{|H|}{|N_G(H)|} \\
\end{array}$$ This is clearly not always an integer, when $\langle \chi, 1_G\rangle$ is. Where is the error?","['characters', 'proof-verification', 'finite-groups', 'fake-proofs', 'group-theory']"
3098350,$\int_0^{\infty} \frac{x^{k_1}}{\left(x^{n_1} + a_1 \right)^{m_1}} \cdot \frac{x^{k_2}}{\left(x^{n_2} + a_2 \right)^{m_2}}\:dx$,"Recently I was able to find a result to a common definite integral: \begin{equation}
 J(n_1, k_1, m_1) = \int_0^{\infty} \frac{x^{k_1}}{\left(x^{n_1} + a_1 \right)^{m_1}}\:dx = \frac{a^{\frac{k_1 + 1}{n_1} - m_1}}{n_1}\Gamma\left(m_1 - \frac{k_1 + 1}{n_1}\right)\Gamma\left(\frac{k_1 + 1}{n_1}\right)
\end{equation} The advantage with this integral is that if you can introduce a free parameter into your integral (ala Feynman's Trick) then under a given transformation using that parameter (i.e. derivatives, Laplace Transform, Fourier Transforms) that you can isolate out the parameter. This makes taking the inverse transform quite easy in most cases. I'm hoping to expand this method to cater to more difficult integrals where multiple parameters are introduced. In doing so, I've come this very similar but much more complicated integral. \begin{equation}
 H\left(a_1, a_2,n_1,n_2,k_1,k_2,m_1,m_2\right)= \int_0^{\infty} \frac{x^{k_1}}{\left(x^{n_1} + a_1 \right)^{m_1}} \cdot \frac{x^{k_2}}{\left(x^{n_2} + a_2 \right)^{m_2}}\:dx
\end{equation} Where $a_1, a_2,n_1,n_2,k_1,k_2,m_1,m_2 \in \mathbb{R}^{+}$ Unfortunately I'm stuck with this one and am interested to find out if anyone has encountered this form before and if so, if they know a method to find a solution expressed in terms of elementary or non-elementary functions. Any starting points would be greatly appreciated. Also, if the solution can be represented with certain restrictions on the parameters, please post up. The only absolute conditions are $a_{1},a_{2},m_{1},m_{2} \gt 0$ . Keen on all solutions restricted or not. Edit - Just thinking now that the one thing that can be done to simplify the integral is to let $u = x^{n_1}$ or $u = x^{n_2}$ . Here I will use the later to render the integral as \begin{align}
 &H\left(a_1, a_2,n_1,n_2,k_1,k_2,m_1,m_2\right)= \int_0^{\infty} \frac{\left( u^{\frac{1}{n_2}}\right)^{k_1}}{\left(\left( u^{\frac{1}{n_2}}\right)^{n_1} + a_1 \right)^{m_1}} \cdot \frac{\left( u^{\frac{1}{n_2}}\right)^{k_2}}{\left(u + a_2 \right)^{m_2}}\frac{1}{n_2}u^{\frac{1 - n_2}{n_2}}\:du\\
\quad& = \frac{1}{n_2}\int_0^{\infty} \frac{u^{\frac{k_1 + k_2 + 1 - n_2}{n_2}}}{\left( u^{\frac{n_1}{n_2}} + a_1 \right)^{m_1}} \frac{1}{\left(u + a_2\right)^{m_1}}\:du = \frac{1}{n_2}\int_0^{\infty} \frac{u^{k_3}}{\left(u^{n_3} + a_1\right)^{m_1}} \frac{1}{\left(u + a_2\right)^{m_2}}\:du
\end{align}","['integration', 'definite-integrals']"
3098352,Miranda - Classification of Curves of Genus 4,"I'm trying to understand pag. 207 of Miranda's book ""Algebraic Curves and Riemann Surfaces"" where it is explained which homogenous polynomial equations define a Riemann Surface of Genus Four  embedded in $\mathbb{CP}^3$ by the canonical map. We will call $X$ the embedded Riemann Surface. We recall that the degree of this curve is $6$ . Miranda first observes that there exists at least one quadratic polynomial $F$ vanishing on $X$ . I'm stuck with understanding that in fact there no exists $F_1$ quadratic homogenous polynomial such that $F$ and $F_1$ are linearly independent. The book proceeds this way: it is taken a general hyperplane $H \simeq \mathbb{CP}^2$ (i.e. an hyperplane such that the intersection with $X$ consists of exactly $6$ points.) and the author observes that restricting $F$ and $F_1$ to $H$ the intersection $\{F=0\} \cap \{F_1=0\} \cap \{H=0\} $ consists of at most $4$ points because of Bézout's theorem. In this way it immediately follows the conclusion. I'm having some trouble in understanding why we can in fact use Bézout theorem. In fact in order to apply Bézout Theorem I think that one should prove first that the restriction of $F$ and $F_1$ to $H$ which are homogenous polynomials of degree $2$ in $3$ variables of $H$ have no non-trivial common factor. I have proved that $F$ and $F_1$ are irreducible if it can help. Could someone give me some suggestions?","['algebraic-curves', 'riemann-surfaces', 'algebraic-geometry']"
3098355,Laplacian of the Euclidean Norm,"Let $r:\mathbb{R}^n \rightarrow \mathbb{R}$ be defined by $r(x)=\|x\|,$ where $\large\|x\|=(x_1^2+\dots+x_n^2)^{\frac{1}{2}}.$ Compute $\nabla^2r,$ the Laplacian of $r.$ I perform the following computations, $$\large\partial_{x_i}r(x)=\frac{1}{2} \cdot \frac{2x_i}{(x_1^2+\dots+x_n^2)^{\frac{1}{2}}}=\frac{x_i}{r(x)},$$ so that we get $$\large\partial_{x_i}\partial_{x_i}r(x)=\frac{r(x)-\frac{x_i^2}{r(x)}}{r(x)^2},$$ and putting these together yields \begin{align*}\large\nabla^2r(x)
&=\large\partial_{x_1}^2r(x)+\dots+\partial_{x_n}^2r(x) \\
&=\large\frac{r(x)-x_1^2\cdot r(x)^{-1}}{r(x)^2}+\dots+\frac{r(x)-x_n^2\cdot r(x)^{-1}}{r(x)^2}\\
&=\large\frac{n\cdot r(x)-r(x)^{-1}\cdot r(x)^2}{r(x)^2}\\
&=\frac{n-1}{r(x)}.\\
\end{align*} Is the above computation correct? I checked the calculation several times, but still have a feeling that I made a mistake somewhere","['partial-derivative', 'multivariable-calculus', 'calculus']"
3098370,Computing the differential of a Lie group action,"(Ex. 27.4 page 252 Loring Tu) (The differential of an action). Let $\mu: P \times G \rightarrow P$ . For $g \in G$ , the tangent space $T_gG$ may be identified with $l_{g*} \mathfrak{g} $ , where $l_g:G \rightarrow G$ is left multiplication by $g \in G$ and $\mathfrak g = T_eG$ is the Lie algebra of $G$ . An element of the tangent space $T_{(p,g)}P \times G$ is of the form $$(X_P, l_{g*} A)$$ for $X_p \in T_pP$ and $A \in \mathfrak g$ . The differential is given by $$ \mu_*= \mu_{*,(p,g)} :T_{(p,g)}(P \times G) \rightarrow T_{pg} P$$ is given by $$ \mu_*(X_p, l_{g*} A) = r_{g*} (X_p) + \underline{A}_{pg} $$ Definition: $\underline{A}$ is the fundamental vector field on $P$ associated to $A \in \mathfrak{g}$ , $$ \underline{A}_p  = \frac{d}{dt}\Big|_{t=0} p \cdot e^{tA} \in T_pP$$ I am struggling in writing out the proof rigorously and neatly. I would be greatful if someone may spell this out.","['lie-algebras', 'principal-bundles', 'differential', 'lie-groups', 'differential-geometry']"
3098386,Relation of complete homogeneous symmetric polynomials and the elementary symmetric polynomials,"I was reading about the symmetric polynomials and saw the following relation: $$\sum _{{i=0}}^{m}(-1)^{i}e_{i}(X_{1},\ldots ,X_{n})h_{{m-i}}(X_{1},\ldots ,X_{n})=0\text{ for } m>0$$ The proof is constructed by using a generating function with respect to the variable $t$ , in Symmetric Functions and Hal Polynomials , SECOND EDITION I. G. MACDONALD, page 21. ( Question ) I was wondering if this relation still holds for any length $k$ , i.e. $$\sum _{{i=0}}^{m}(-1)^{i}e_{i}(X_{1},\ldots ,X_{n})h_{{m-i}}(X_{1},\ldots ,X_{k})=0\text{ for }k \in \{1,...,n\}$$ P.S. I tried cases and it holds for any case.","['abstract-algebra', 'symmetric-polynomials', 'commutative-algebra']"
3098470,"Problem about Borel-measurability, pushforward measure and $L^1$ spaces.","I am trying to solve this exercise. I get stuck in the last part, but I write all the exercise for context. Also, I am not sure that some explanations I give are enough to justify these results. (Sorry for my poor English) Let $\varphi: \mathbb R \to \mathbb R$ be the function given by $$\varphi (x) = \dfrac{2x}{x-1} \chi _{(-\infty, -1)} (x) + \chi _{[-1,1]} (x) + \dfrac{2x}{x+1} \chi _{(1,+\infty)} (x), \quad x \in \mathbb R.$$ Prove that $\varphi$ is Borel-measurable over $\mathbb R$ . Let $m$ be the Borel-Lebesgue measure in $\mathbb R$ . Find the pushforward measure $\varphi (m)$ over the $\sigma$ -algebra of the borel sets of $\mathbb R$ and its Lebesgue decomposition with respect to $m$ . Let $$f(y) = \sqrt{2-y} \, \arctan (2-y) \, \chi _{(0,2)} (y), \quad y \in \mathbb R.$$ Show that $f\in L^1 (\varphi (m))$ . Since $\varphi$ is continuous, it is Borel-measurable. (I feel that I have been lucky with this. What would I have to do to prove Borel-measurability if it wasn't continuous?) Drawing $\varphi(x)$ I find that the support of $\varphi(m)$ is $[1,+\infty)$ . Let $E\subseteq (-\infty, 1)$ , then $\varphi(m)(E)=0$ . Also, $$\varphi(m) (\{ 1 \})= m (\varphi ^{-1} (1)) = m ([-1,1]) =2.$$ Let $(a,b)\subset (1,+\infty)$ , then $$\varphi^{-1}((a,b))=\left( \frac{b}{b-2}, \frac{a}{a-2} \right) \cup \left( \frac{a}{2-a}, \frac{b}{2-b} \right).$$ Then $$m(\varphi ^{-1} ((a,b)))=\left( \frac{a}{a-2}- \frac{b}{b-2} \right) + \left( \frac{b}{2-b}-\frac{a}{2-a} \right)=$$ $$=2\left( \frac{a}{a-2}- \frac{b}{b-2} \right)=-2\left( \frac{b}{b-2}- \frac{a}{a-2} \right)=$$ $$=-2\int _a ^b \! \left( \frac{t}{t-2} \right) ' \, \mathrm d t=-2\int _a ^b \! \frac{-2}{(t-2)^2} \, \mathrm d t=4\int _a ^b \! \frac{1}{(t-2)^2} \, \mathrm d t.$$ Therefore we can write (is this correct?) $$\varphi (m) ((a,b))= \underbrace{2 \delta _{\{1\}}}_{\varphi(m)_s}+\underbrace{4\chi_{[1,+\infty)}\int _a ^b \! \frac{1}{(t-2)^2} \, \mathrm d t}_{\varphi(m)_a},$$ where $\varphi(m)_s \perp m$ and $\varphi(m)_a \ll m$ . Thus we have found its Lebesgue decomposition. I don't know how to solve this part. The only thing that crosses my mind is that $f\in L^1 \varphi(m)$ if and only if $$\int \vert f \vert \, \mathrm d \varphi (m)=\int (\vert f \vert \circ \varphi) \mathrm d m \in \mathbb R.$$ But it seems hard to compute that integral and maybe is there something easier that I am not thinking. Thank you for your help.","['integration', 'measure-theory', 'lebesgue-measure', 'lebesgue-integral']"
3098530,Solve for the angle x?,"The problem seems really impossible to me, despite solving many problems on triangles. So I hope that you can solve it. src: https://www.instagram.com/p/BtUNj3IBIW5/","['triangles', 'angle', 'geometry']"
3098535,A variant of Kronecker's approximation theorem?,"Let $\tau,\sigma\in(0,\infty)$ with $\frac{\tau}{\sigma}\notin\mathbb Q$ . By Kronecker's approximation theorem, we know: (1) For each $x\in \mathbb R$ and $\epsilon>0$ , there are $m,n\in\mathbb N$ such that $|x+n\tau-m\sigma|<\epsilon$ . In other words, if you keep adding $\tau$ to $x$ , you will eventually come arbitratily close to the set $\sigma\mathbb N$ . But what happens if you keep adding values that are just approximately $\tau$ ? To make this a precise question, let $(\tau_n)_{n\in\mathbb N_0}\subset (0,\infty)$ with $$ \tau_{n+1}-\tau_n \xrightarrow{n\to\infty}\tau.$$ Then, the according conjecture is: (2) For each $x\in \mathbb R$ and $\epsilon>0$ , there are $m,n\in\mathbb N$ such that $|x+\tau_n-m\sigma|<\epsilon$ . If one assumes that $$ \sum_{n=0}^\infty \left((\tau_{n+1}-\tau_n)-\tau \right) \text{ converges in $\mathbb R$,}$$ it is indeed relatively easy to deduce (2) from (1). QUESTION: If $\sum_{n=0}^\infty \left((\tau_{n+1}-\tau_n)-\tau \right)$ diverges, does (2) still hold? My ad hoc ideas didn't quite work out and before I start to think deeper about it, I thought I might ask if anyone here knows of any result in this direction. Thanks a lot in advance!","['real-numbers', 'approximation', 'diophantine-approximation', 'real-analysis', 'sequences-and-series']"
3098538,"If $TS=ST$, then $S=\alpha T+\beta$.","Let $T=\begin{pmatrix}a&b\\c&d\end{pmatrix}$ be a non-scalar matrix. If $S=\begin{pmatrix}e&f\\g&h\end{pmatrix}$ be such that $TS=ST$ . Why there exists $\alpha,\beta\in \mathbb{C}$ such that $$S=\alpha T+\beta I\;?$$ Note that $TS-ST=0$ is equivalent to $$\begin{bmatrix}bg-fc & af+bh-eb-fd\\
ce+dg-ga-hc & fc-bg\end{bmatrix} = \begin{bmatrix}0 & 0\\0 & 0\end{bmatrix}$$ This implies that $$\begin{cases}
bg-fc = 0,\\
af+bh-eb-fd = 0,\\
ce+dg-ga-hc = 0,\\
fc-bg = 0.
\end{cases}$$ Since $T$ is non scalar, then $b\neq 0$ or $c\neq 0$ or $a\neq d$ . However, I cannot find $\alpha$ and $\beta$ .",['linear-algebra']
3098561,Fundamental group of uncountable space with cofinite topology,"So it is easy to show that such a space is path connected (assuming CH, injective maps $f:I \rightarrow X$ are continuous) but I'm not sure how to start computing the fundamental group. Will it depend on the cardinality? Thank you","['general-topology', 'fundamental-groups', 'algebraic-topology']"
3098569,Question about the Definition of Smoothness at a Point,"Suppose $M$ and $N$ are smooth manifolds. Let $F:M \to N$ be any map. The definition of smoothness of $F$ is the following: Def: We say that $F$ is smooth if for each $p\in M$ there exist $(U,\phi)$ smooth chart for $M$ in $p$ and $(V,\psi)$ smooth chart for $N$ such that $F(U) \subseteq V$ and $\psi^{-1} \circ F \circ \phi:\phi(U)\to \psi(V)$ is smooth in $\phi(U)$ in the sense of Ordinary Calculus. However, if I want to give a definition of smoothness at a point , I see at least two possible ways to do so: Let $p\in M$ . Definition 1) I say that $F$ is smooth at $p$ if there exist $(U,\phi)$ smooth chart for $M$ in $p$ and $(V,\psi)$ smooth chart for $N$ such that $F(U) \subseteq V$ and $\psi^{-1} \circ F \circ \phi:\phi(U)\to \psi(V)$ is smooth in $\phi(U)$ in the sense of Ordinary Calculus. Definition 2) I say that $F$ is smooth at $p$ if there exist $(U,\phi)$ smooth chart for $M$ in $p$ and $(V,\psi)$ smooth chart for $N$ such that $F(U) \subseteq V$ and $\psi^{-1} \circ F \circ \phi:\phi(U)\to \psi(V)$ is smooth in $\phi(p)$ in the sense of Ordinary Calculus. Are they equivalent? If not, which one is the correct? I noticed that: Pros of Definition 1) 1) $F:M \to N$ is smooth (in M, according to the ""Def"" above) if and only if $F$ is smooth at $p$ for each $p$ in $M$ . Cons of Definition 1) 1) Smoothness of $F$ at $p$ implies smoothness of $F$ in an entire neihborhood of $p$ (which seems a too strong requirement) 2) In Ordinary Calculus the definition of smoothness at a point does not imply the smoothness in an entire neighborhoods of that point. Pros of Definition 2) 1) It seems more similar to the definition of smoothness at a point given in Ordinary Calculus Cons of Definitions 2) 1) I don't know if $F:M \to N$ is smooth (in M, according to the ""Def"" above) if and only if $F$ is smooth at $p$ for each $p$ in $M$ .","['multivariable-calculus', 'smooth-functions', 'smooth-manifolds', 'differential-geometry']"
3098652,"If $f(x,y) = g(r)$, where $r=(x^2+y^2)^{1/2}$, prove $\frac{\partial^2f}{\partial x^2} + \frac{\partial^2f}{\partial y^2} = \frac 1r g'(r)+ g''(r).$","Consider a scalar field defined in $\mathbb{R}^2$ such that $f(x,y)$ depends only on the distance $r$ of $(x,y)$ from the origin, say $f(x,y) = g(r)$ , where $r=(x^2+y^2)^{1/2}$ . a) Prove that for $(x,y) \ne (0,0)$ , we have $$\frac{\partial^2f}{\partial x^2} + \frac{\partial^2f}{\partial y^2} = \frac 1r g'(r)+ g''(r).$$ b) Now assume further that $f$ satisfies Laplace's Equation, $$\frac{\partial^2f}{\partial x^2} + \frac{\partial^2f}{\partial y^2} = 0. $$ Use part (a) to show that $f(x,y) = a \log(x^2+y^2) +b$ for $(x,y) \ne (0,0),$ where $a$ and $b$ are constants. What I've tried: I think we can express $g'(r)$ as $$\frac{d}{dr}g(r) = \frac{\partial g}{\partial x} \frac{\partial x}{\partial r} + \frac{\partial g}{\partial y} \frac{\partial y}{\partial r},$$ but I'm confused as to how to determine $\frac{\partial x}{\partial r}$ and $\frac{\partial y}{\partial r}$ since $r$ is in terms of both $x$ and $y$ .","['partial-derivative', 'multivariable-calculus', 'derivatives', 'ordinary-differential-equations']"
3098681,Showing that an integral operator on $L^p$ spaces has a certain norm,"Let $X$ be a sigma-finite measure space, and let $k$ be a measurable function on $X\times X$ .  Suppose that $F(x)=\int |k(x,y)| dy$ and $G(y)=\int |k(x,y)| dx$ are in $L^\infty$ .  Let $1<p<\infty$ and let $K:L^p\rightarrow L^\infty$ be defined by $K(f)(x)=\int k(x,y) f(y) dy$ .  Show that $K$ is bounded with operator norm less than or equal to $||F||_\infty^{1/p}||G||_\infty^{1/q}$ , where $\frac{1}{p}+\frac{1}{q}=1$ . I’m not sure how to approach this.  I need to show that for any $f\in L^p$ , we have $||K(f)||_\infty\leq||F||_\infty^{1/p}||G||_\infty^{1/q}||f||_p$ .  I was thinking of using Holder’s inequality, since that involves $p$ and $q$ , but we have an $L_\infty$ norm here rather than an $L_1$ norm.","['measure-theory', 'operator-theory', 'lp-spaces', 'functional-analysis', 'holder-inequality']"
3098697,Is a dense set always infinite?,"Learning about dense sets the classical example is that of $\mathbb Q$ , the rationals, in $\mathbb R$ .  The same interpretation is valid for irrationals in $\mathbb R$ . I was wondering if a dense set needs to be infinite, because this is what intuition would suggest. Moreover, are dense sets always countably infinite?","['general-topology', 'real-analysis']"
3098730,List of small rings,"Where can I find a list of small rings? (like the one Wikipedia has for groups ) (obviously I  don't expect it to be as comprehensive given how many rings there can be for certain orders, but if there's a list out there that at least covers a fair few of the easier sizes of a ring to deal with, that'd be great)","['ring-theory', 'abstract-algebra', 'reference-request']"
3098739,How to compare and rank Radar (Spider) Charts?,"Say I have a bunch of radar charts, how do I compare them? What I want to do is 'rank' a bunch of spider charts by their overall 'coverage'. Each chart is a Pentagonal spider chart. My first guess was to compare areas, since that's what coverage is, but there isn't an easy formula to do that. One I know of is $$
S = \frac{p \star r} 2
$$ where $ r $ is the radius of an inscribed circle and $ p $ is the perimeter of the pentagon. The problem with this is you cannot really do (or at least I don't know how to do) that with raw data like this 1 0.1
2 0.98
3 0.53
4 0.01
5 0.6 where the first column is the 'vertex' of the chart and the second column is the point to draw on the chart. Points will always be between 0 and 1. Something like this So I was wondering, is there a better way of comparing spider/radar charts?","['trigonometry', 'graphing-functions', 'geometry']"
3098741,Proof that a standard Brownian motion visits zero infinitely often at the beginning,"Let $B_t, t\ge0$ be a standard Brownian motion that starts at 0. Prove that, for any $\epsilon > 0$ , $$P(\#\{t\in(0,\epsilon]\mid B_t = 0\}=\infty)=1.$$ This is a well-known fact, but surprisingly I cannot find a single proof on this site. The closest I get is this question , which proves the zero set of a standard Brownian motion restricted to $[0,1]$ is homeomorphic to the Cantor set. However, this proof seems to have utilised unfamiliar properties such as the ternary-expansion construction of the zero set. Does there exist an elementary proof that only uses the familiar properties of the Brownian motion (normality, independent increments etc.)?","['stochastic-processes', 'brownian-motion', 'probability-theory']"
3098782,Is the transition semigroup of the solution of an SDE with Lipschitz coefficients strongly continuous on $C_b$?,"Let $(\Omega,\mathcal A,\operatorname P)$ be a probability space $b,\sigma:\mathbb R\to\mathbb R$ be Lipschitz continuous (and hence at most of linear growth) and $$Lf:=bf'+\frac12\sigma^2f''\;\;\;\text{for }f\in C^2(\mathbb R)$$ $W$ be a Brownian motion on $(\Omega,\mathcal A,\operatorname P)$ $(X^x_t)_{(t,\:x)\in[0,\:\infty)\times\mathbb R}$ be a continuous process on $(\Omega,\mathcal A,\operatorname P)$ with $$X_t^x=x+\int_0^tb(X^x_s)\:{\rm d}s+\int_0^t\sigma(X^x_s)\:{\rm d}W_s\;\;\;\text{for all }t\ge0\text{ almost surely for all }x\in\mathbb R\tag1$$ and $$(\kappa_tf)(x):=\operatorname E\left[f(X^x_t)\right]\;\;\;\text{for }x\in\mathbb R$$ for any bounded Borel measurable $f:\mathbb R\to\mathbb R$ and $t\ge0$ If $f\in C_b(\mathbb R)$ , are we able to conclude $\left\|\kappa_tf-f\right\|_\infty\xrightarrow{t\to0+}0$ ? Assume first that $f\in C^2_b$ . Fix $(t,x)$ . Since $f'$ is bounded, $$(\kappa_tf)(x)=f(x)+\text E\left[\int_0^t(Lf)(X^x_s)\:{\rm d}s\right].\tag2$$ The crucial question seems to be whether we're allowed to apply Fubini's theorem to the second term on the rhs. By Jensen's inequality, $$\text E\left[\sup_{s\le t}|X^x_s|\right]^2\le\text E\left[\sup_{s\le t}|X^x_s|^2\right]<\infty\tag3$$ (where the finiteness of the rhs follows from the Lipschitz assumption) and by the linear growth assumption for some $$\text E\left[\int_0^t|(Lf)(X^x_s)|\:{\rm d}s\right]\le ct\left(1+\text E\left[\sup_{s\le t}|X^x_s|\right]\right)\left\|f'\right\|_\infty+\frac c2t\left(1+\text E\left[\sup_{s\le t}|X^x_s|^2\right]\right)\left\|f''\right\|_\infty<\infty\tag4$$ for some $c\ge0$ . So, we should be able to apply Fubini's theorem and obtain $$(\kappa_tf)(x)=f(x)+\int_0^t(\kappa_s(Lf))(x)\:{\rm d}s.\tag5$$ So, we should have $$|(\kappa_tf)(x)-f(x)|\le t\left\|Lf\right\|_\infty.\tag6$$ The only problem is that $Lf$ might be unbounded. So, I guess we need to assume $f\in C_c^2(\mathbb R)$ (since I don't see that a larger class ensures that $Lf$ is bounded). This allows us to conclude the claim for such a $f$ and, by density, for $f\in C_0(\mathbb R)$ . Is it possible to extend the result to $f\in C_b(\mathbb R)$ ?","['stochastic-analysis', 'stochastic-processes', 'markov-process', 'stochastic-differential-equations', 'probability-theory']"
3098790,"Can we ""mod out"" a common subspace in the Grassmannian inside the exterior algebra?","While reading this paper , I have seen the following claim stated without a proof: Let $V$ be an $n$ -dimensional vector space over a field, and let $\alpha,\beta \in \bigwedge^k V$ be decomposable and non-zero. Suppose that $$\alpha=(u_1 \wedge \dots \wedge u_r) \wedge v_1 \wedge \dots \wedge v_{k-r},\beta=(u_1 \wedge \dots \wedge u_r) \wedge w_1 \wedge \dots \wedge w_{k-r},$$ where $$\text{span}(u_1 ,\dots,u_r)=\text{span}(u_1 ,\dots,u_r,v_1\dots v_{k-r}) \cap \text{span}(u_1 ,\dots,u_r,w_1\dots w_{k-r}) $$ (i.e. $\text{span}(u_1 ,\dots,u_r)$ is the intersection of the subspaces corresponding to the decomposable tensors $\alpha,\beta$ .) Then, if $\alpha+\beta$ is decomposable and non-zero, then so is $  v_1 \wedge \dots \wedge v_{k-r}+ w_1 \wedge \dots \wedge w_{k-r} $ . In other words, we can ""mod out"" the ""common intersection"" of $\alpha$ and $\beta$ . How to prove this statement? Here is my failed attempt: We can write $$\tilde u_1 \wedge \dots \wedge \tilde u_k=\alpha+\beta=(u_1 \wedge \dots \wedge u_r) \wedge \gamma, \tag{1}$$ where $\gamma=v_1 \wedge \dots \wedge v_{k-r}+ w_1 \wedge \dots \wedge w_{k-r} $ . By wedging this equality with $u_i$ , we see that $\text{span}(u_1,\dots,u_r) \subseteq \text{span}(\tilde u_1,\dots,\tilde u_k)$ . Thus, we can assume W.L.O.G that $\tilde u_i=u_i$ for $1 \le i \le r$ . Rewriting, we have $$ u_1 \wedge \dots \wedge  u_k=\alpha+\beta=(u_1 \wedge \dots \wedge u_r) \wedge \gamma, \tag{2}$$ Now, it suffices to prove that $\gamma \wedge u_j=0$ for $k <  j \le r$ , since this would imply that the dimension of the subspace of $V$ annihilating $\gamma$ is at least $r-k$ . Since it is also not greater than $r-k$ , it must be $k$ . This implies that $\gamma$ is decomposable. So, we now prove that $\gamma \wedge u_j=0$ for $k <  j \le r$ : We can complete $(u_1,\dots,u_k)$ into a basis $(u_1,\dots,u_n)$ of $V$ . Now we write $\gamma=\sum a^{i_1,\dots,i_{r-k}}u_{i_1} \wedge \dots \wedge u_{i_{r-k}}$ . Since $\alpha+\beta \neq 0$ , there is at least one summand in $\gamma$ that is not composed entirely from wedge of $u_1,\dots,u_r$ .... (I don't see how to continue). In fact, it seems that equation $(2)$ should imply that $\gamma$ is not necessarily decomposable, since it is not uniquely determined by it: Indeed, if we modify $\gamma$ by adding decomposable elements which involve  any of the $u_1,\dots,u_r$ , the RHS does not change, so the equation still holds. It seems to me then, that we should be able to convert $\gamma$ to be a non-decomposable element.","['tensor-decomposition', 'multilinear-algebra', 'exterior-algebra', 'differential-geometry']"
3098798,Perimeter of orthic triangle,"If $DEF$ is the orthic triangle of $\triangle ABC$ , then prove that $$\frac{\text{Perimeter of }\triangle DEF}{\text{Perimeter of }\triangle ABC} = \frac{r}{R} $$ where $r$ and $R$ are the inradius and the circumradius of $\triangle ABC$ . My attempt is very simple , I put the side length of orthic triangle in terms of $\cos$ and the side length of $\triangle ABC$ but I can't get the required answer.","['triangles', 'euclidean-geometry', 'trigonometry', 'geometry']"
3098799,Can I estimate this integral like that?,"I have the following integral $ \int_{2}^{\infty} \frac{1}{\sqrt[3]{x^{3}-1}} d x $ and I should solve it without calculate it directly.
So if I find two function which is smaller and bigger than $ \int_{2}^{\infty} \frac{1}{\sqrt[3]{x^{3}-1}} d x $ and those converges, then my integral has to converge too. So i would like to choose $ 0 \le  \frac{1}{\sqrt[3]{x^{3}-1}} d x \geq   \frac{1}{\sqrt[3]{x^{5}}} $ is this possible ?","['integration', 'calculus', 'estimation']"
3098818,Sum and minimum in $3\times 3$ table,"A $3\times 3$ table is filled with non-negative real numbers so that each row sums to $1$ . A subset of cells is called admissible if it has size $3$ and the three cells all lie in different rows and columns. For each admissible set $A$ , let $s(A)$ be the sum of the numbers in the three cells and $m(A)$ be the minimum of those numbers. There must be an admissible set $A$ with $s(A)\geq 1$ . (Just take three disjoint admissible sets; since the total sum is $3$ , one set must have sum at least $1$ .) Is it true that there is always an admissible set $A$ such that $s(A)\geq 1$ , and $m(A)$ is the highest among all admissible sets?","['combinatorics', 'extremal-combinatorics']"
3098857,Exponentiation in Non-Commutative Rings,"I'm fairly new to abstract algebra and in an exercise I was asked under which conditions it is true that $(ab)^n = a^nb^n$ , for $a,b \in R$ and $n$ a positive integer, where $R$ is a ring. It can be easily shown that the statement holds if $R$ is commutative but I am stuck on the reverse implication. I have shown that if $R$ contains no zero divisors then the statement implies commutativity. Indeed, taking $n = 2$ $$(ab)^2 = abab = a^2b^2 \Leftrightarrow a(ba-ab)b = 0 \Leftrightarrow ba = ab$$ Does there exist non-commutative rings with zero divisors such that $(ab)^n =a^nb^n$ or is this property equivalent to commutativity?","['ring-theory', 'abstract-algebra', 'noncommutative-algebra']"
3098869,Does probability theory suffer from Gödel's incompleteness theorem?,"Let us consider the following two theorems by Gödel: Any consistent formal system $F$ within which a certain amount of elementary arithmetic can be carried out is incomplete; i.e., there are statements of the language of $F$ which can neither be proved nor disproved in $F$ ; For any consistent system F within which a certain amount of elementary arithmetic can be carried out, the consistency of F cannot be proved in $F$ itself. Like others, probability theory is also an axiom-based system with 3 axioms and supports minimum arithmetic. From the above information, it looks like probability theory also suffers from Gödel's incompleteness theorem. Can't it? If not, then where I am going wrong? Thus is there a possibility that there may exist two statements in probability theory that contradict each other and the existence of unprovable facts?","['incompleteness', 'soft-question', 'probability-theory']"
3098870,Is a connected set always an uncountably infinite set?,"I'm trying to understand the concept of a connected set. The classic example which is presented is that of $\Bbb R$ or any interval of $\Bbb R$ with the usual topology. Moreover, I heard that to a certain extent connected sets can be considered opposite to discrete sets. They are sometimes indicated as representing the idea of a continuum. So, intuitively, shouldn't they always be uncountable sets?","['connectedness', 'general-topology', 'real-analysis']"
3098873,Calculating probability using joint density,"I'm given the family $(X, Y)$ of random variables with join density: $$f^{X, Y}(x, y) := 2 \cdot e^{-(x+2y)} \cdot 1_{[0,\infty)}(x) \cdot 1_{[0, \infty)}(y)$$ and I'm required to calculate $P(X > Y)$ . I already calculated the marginal density $f^X, f^Y$ and established that $X$ and $Y$ are independent, but didn't use this information, but calculated: $$\int_{\{(x, y)\,\in\,\mathbb{R}^2 : x\,>\,y\}} f^{X, Y}(x,y) \,d(x,y) \\ = \int_\mathbb{R}\int_\mathbb{R} 2\cdot e^{-(x+2y)} \cdot 1_{[0, \infty)}(x) \cdot 1_{[0, x)}(y) \,dy\,dx \\= \int_\mathbb{R} 1_{[0, \infty)}(x) \int_0^x 2e^{-(x+2y)} dy\,dx \\= \int_0^\infty e^{-x} - e^{-3x}dx = 1 - \frac{1}{3} = \frac{2}{3}$$ Is this approach correct? Do I need to change $x$ in the second equality (since it's part of the bounds) or is it fine, since I integrated $dy$ ? Can this problem be solves quicker using $f^X, f^Y$ and independence?","['integration', 'probability-theory', 'density-function']"
3098903,$f_n \in L^{\infty}(\mathbb R)$ such that $f_n \to f$ and ${f_n}^2 \to g$ weakly$^*$ with $f^2 \neq g$,"The exercise metioned in the title was a part of my exams in Functional Analysis, which took place the previous week. Unfortunately I wasn't able to think of a sequence $f_n\in L^{\infty}(\mathbb R)$ such that $f_n \to f$ weakly $^*$ ${f_n}^2 \to g$ weakly $^*$ but $f^2 \neq g$ . However, I would like to know the answer. I believe that such a sequence might be the product of a trigonometric sequence and the indicator sequence but I haven't managed to proceed. Any help is much appreciated! Thanks in advance","['functional-analysis', 'weak-convergence']"
3098914,Is the sequence $\big(f(n)-f(n+1)\big)$ convergent?,"Let $f:\mathbb{R}\to[0,+\infty)$ be a function such that $\int_{-‎\infty‎}^{+\infty}f(x)\,dx=1$ . My question is: Is the sequence $\big(f(n)-f(n+1)\big)$ convergent? I found that there exist some $f$ such that the sequence $f(n)$ is not convergent, but in my research I arrived at the mentioned question.  I tried  to make contradiction with the definition of improper integral by using the property $f$ ""positive"". but I could not achieve the goal. Any help is appreciated.","['sequences-and-series', 'probability-theory', 'probability', 'real-analysis']"
3098921,"If $C$ is infinite and $B$ is finite, then $C\setminus B$ is infinite.","If $C$ is infinite and $B$ is finite, then $C\setminus B$ is infinite. Proof: Suppose $A=C\setminus B$ is finite. Then since $C$ is infinite, $$C=(C\setminus B)\cup(C\cap B)=A\cup(C\cap B)$$ is also infinite. This implies three separate cases: $A$ is finite and $C\cap B$ is infinite, $A$ is infinite and $C\cap B$ is finite, or $A$ and $C\cap B$ are infinite. We already asssumed that $A$ was finite, so case (1) applies. Hence $C\cap B$ is infinite and so is $(C\cap B)\cup B=B$ , but we assumed B was finite. This is a contradiction and so we conclude our assumption that $A$ was finite is false; $A$ must be infinite. $\square$ I was hoping someone could verify if this proof is valid or not. Thanks in advance!","['elementary-set-theory', 'proof-verification']"
3098964,How to read the expression of an affine connection: $\nabla_X Y$?,"I am studying Riemannian Geometry from the textbook Riemannian Geometry by do Carmo (English edition). In section 2 of chapter 2, page 50, he defines an affine connection as follows: 2.1 Definition. An affine connection $\nabla$ on a differentiable manifold $M$ is a mapping $$
\nabla : \mathfrak{X}(M) \times \mathfrak{X}(M) \to \mathfrak{X}(M)
$$ which is denoted by $(X,Y) \overset{\nabla}{\to} \nabla_X Y$ and which satisfies the following properties: $\nabla_{fX + gY} Z = f \nabla_X Z + g \nabla_Y Z$ . $\nabla_X(Y+Z) = \nabla_X Y + \nabla_X Z$ . $\nabla_X (fY) = f \nabla_X Y + X(f) Y$ , in which $X,Y,Z \in \mathfrak{X}(M)$ and $f,g \in \mathcal{D}(M)$ . Here, $M$ is a smooth manifold, $\mathfrak{X}(M)$ is the set of all smooth vector fields on $M$ , and $\mathcal{D}(M)$ is the ring of real-valued smooth functions on $M$ . My question is, how do I speak (or read) the affine connection $\nabla$ , or $\nabla_X Y$ ? do Carmo does not give any suggestions, and I was unable to find any details on Wikipedia or in Google searches with terms like affine connection pronounce/pronunciation affine connection how to speak affine connection how to read I could not find any related question on this Stack Exchange either. I am aware that the $\LaTeX$ command for $\nabla$ is \nabla . In my undergraduate classes, I encountered this symbol as a gradient operator, where we called it ""grad"", and also sometimes ""del"". Can someone tell me what is (or what are) the standard pronunciation(s) for the affine connection $\nabla$ in Riemannian Geometry? To be precise, how do I read the symbol(s) $\nabla$ or $\nabla_X Y$ when I encounter them in the text, for instance in an expression like $\nabla_{X_i} X_j = \sum_k \Gamma_{ij}^k X_k$ ? Thanks in advance.","['pronunciation', 'connections', 'riemannian-geometry', 'differential-geometry']"
3098992,"Functors between sets, posets, and groups","I found the following statements in some lecture notes in category theory: A functor between sets $S$ and $T$ is a function from $S$ to $T$ A functor between two groups $G$ and $H$ is a group homomorphism from $G$ to $H$ A functor between two posets $P$ and $Q$ is a monotone function from $P$ to $Q$ Consider the second statement. A group was defined as a category with one object in which every arrow is an isomorphism. Then what is the definition of a group homomorphism in this setting? What exactly do I need to check to establish the claim?
Here is what I have. Suppose $G$ is the category with object $\ast$ and $H$ is a category with object $\clubsuit$ and let $\alpha:G\to H$ be a functor. By the definition of a functor, $\alpha(\ast)=\clubsuit$ , and if $g:\ast\to \ast$ is an arrow in $G$ , then $\alpha(g):\clubsuit\to \clubsuit$ is an arrow in $H$ . The remaining conditions on $\alpha $ are: $\alpha(g_1\circ g_2)=\alpha(g_1)\circ \alpha(g_2)$ and $\alpha(id_\ast)=id_\clubsuit$ .  But without knowing the definition of a group homomorphism when a group is defined as a category, I don't know how to proceed. A poset can also be considered as a skeletal preorder. (A preorder is a category in which there is at most one arrow between any two objects.) In this definition, what is the definition of a monotone map between such categories? A set is a category where the objects are the elements of a set and the only arrows are the identity arrows. What is a function between such categories?","['elementary-set-theory', 'abstract-algebra', 'category-theory']"
3098993,Topology of $x^2+y^2 = 1$ over $\mathbb{C}^2$,"I am trying to prove that $$V=\{(x,y) \in \mathbb{C}^2| \ x^2+y^2 = 1\} \simeq \mathbb{C}^* = \mathbb{C}\setminus \{0\}$$ where $\simeq$ is to be intended as homeomorphic. Fix $y\neq \pm 1$ then $x^2 = 1-y^2$ gives me two distinct solutions for $x$ . It follows that $V$ will contain two disjoint copies of $\mathbb{C}\setminus \{\pm 1\}$ . Now  it remains to see if there is any solution of the form $(x,\pm 1)$ . 
There are exactly two solutions $\{(0, \pm 1)\}$ .
Then it seems reasonable to me that $V$ is obtained filling the two points in the two  copies of $\mathbb{C}\setminus \{\pm 1\}$ and identifying the points $\pm 1$ , more explicitely $$V = \frac{(\mathbb{C}\setminus \{\pm 1\} )\times \{a,b\}}{\sim}$$ where $(+1,a)\sim (+1,b)$ and $(-1,a) \sim (-1,b).$ The problems is that this is not the cylinder $\mathbb{C}^*$ , indeed if we remove the two points $[(\pm 1,a)]$ we disconnect $V$ while $\mathbb{C}^*$ remains connected. what is wrong?","['analytic-geometry', 'general-topology', 'algebraic-geometry', 'polynomials']"
