question_id,title,body,tags
2925298,"If a fair die is rolled 3 times, what are the odds of getting an even number on each of the first 2 rolls, and an odd number on the third roll?","If a fair die is rolled 3 times, what are the odds of getting an even number on each of the first 2 rolls, and an odd number on the third roll? I think the permutations formula is needed i.e. $n!/(n-r)!$ because order matters but I'm not sure if n is 3 or 6 and what would r be? Any help would be much appreciated!","['permutations', 'probability']"
2925300,Heisenberg uncertainty principle: a proof for a beginner,"Scrolling in a book on real analysis I found, as a last exercise, the request to prove the Heisenberg uncertainty principle. The exercise states Let $f\in \mathcal L_{1}^{2}(\mathbb R)$ , such that $\|f\|_{2}=\|\hat f\|_{2}=1$ . Prove that $$\left(\int_{\mathbb R}|x|^{2}|f(x)|^{2}\,\mathrm dx\right)\cdot\left(\int_{\mathbb R}|\xi|^{2}|\hat f(\xi)|^{2}\,\mathrm d\xi\right)\geq \frac{1}{(4\pi)^{2}}$$ Hint : suppose that $f\in C_{c}^{\infty}$ and use the following identities: $$\int_{\mathbb R}x\overline{f}(x)f'(x) = -{1\over 2} \|f\|_{2}^{s}$$ Plancherel's identity and Cauchy-Schwarz inequality. The book states that $$\mathcal L^2_s(\mathbb R^d) := \{f:\mathbb R^d\rightarrow\mathbb C \text{ measurable} \text{ : }(1+|x|^2)^{s\over 2}f\in L^2(\mathbb R^d)\}$$ which calles it weighted $L^2$ spaces . I was very curious on how to solve this problem because I don't have nearly as much knowledge as it's needed to solve this! So I'm here to ask you if you could give me the solution. I can't give you my working because, as just stated, I don't know much about real analysis and I was just very curious to see the solution! Probably I'll understand it if I see one but searching on the internet didn't gave me any help.","['physics', 'real-analysis']"
2925313,Mathematical notation for identity relation.,"For an identity relation, are the following mathematical notations correct? ∀a,b ∈ A : aRa ∧ ∄ aRb : a ≠ b R = { (a,a) : a ∈ A } What i want to say in first notation is for every a and b in A , a is related to itself, and there does not exist a relation between a and b , where a is not equal to b .","['elementary-set-theory', 'relations']"
2925316,Linear combination of Pauli matrices and projectors,"Premise: this is exercise 2.60 of Quantum Computation and Quantum Information , by Nielsen and Chuang, where I'm currently stuck. Suppose $\vec{v}$ is any real three-dimensional unit vector, and $\sigma_{i}$ with $i \in \{1,2,3\}$ represents the Pauli matrices. Then we can define an Hermitian operator: $$
\begin{aligned}
\vec{v}\cdot\vec{\sigma} &\equiv \sum_{i=1}^{3}v_{i}\sigma_{i} \\
&= v_{1} \sigma_{1} + v_{2} \sigma_{2} + v_{3} \sigma_{3}.
\end{aligned}
$$ Show that: $\vec{v}\cdot\vec{\sigma}$ has eigenvalues $\lambda_{\pm 1}=\pm 1$ . the projectors onto the corresponding eigenspaces are given by $P_{\pm}=(I \pm \vec{v}\cdot\vec{\sigma}) / 2$ . My straightforward idea was to develop the observable: $$
\begin{aligned}
\vec{v}\cdot\vec{\sigma} &\equiv v_{1} X + v_{2} Y + v_{3} Z \\
&= v_{1} \left[\begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix}\right] + v_{2} \left[\begin{matrix} 0 & -i \\ i & 0 \end{matrix}\right] + v_{3} \left[\begin{matrix} 1 & 0 \\ 0 & -1 \end{matrix}\right] \\
&= \left[\begin{matrix} v_{3} & v_{1}-i v_{2} \\ v_{1}+i v_{2} & -v_{3} \end{matrix}\right]
\end{aligned}
$$ From which it is very easy to see that the eigenvalues are $\lambda_{\pm 1}=\pm 1$ and the corresponding eigenvectors are: $$
\lvert \lambda_{-1} \rangle = \left[ \begin{array}{c} -\frac{v_{1}-i v_{2}}{1+v_{3}} \\ 1 \end{array}\right]; \quad \lvert \lambda_{+1} \rangle = \left[ \begin{array}{c} \frac{v_{1}-i v_{2}}{1-v_{3}} \\ 1 \end{array}\right]
$$ And then I would have constructed the projectors. My question is: from the eigenvectors I can see that the first component of $\lvert \lambda_{-1} \rangle$ is going to diverge when $v_{3}=-1$ , and also the first component of $\lvert \lambda_{+1} \rangle$ is going to diverge when $v_{3}=1$ . I'm losing generality in the definition of the vector $\vec{v}$ . This suggests my approach is wrong, and it is where I am stuck. Is there any other approach I could try to prove the given form of the projectors?","['projection', 'linear-algebra', 'quantum-mechanics', 'quantum-information', 'quantum-computation']"
2925323,Ramification degree of field extension of the 5-adic field obtained by adjoining a primitive third root of unity,"Let $K = \mathbb{Q}_5$ and $K' = \mathbb{Q}_5(\xi_3)$ where $\xi_3$ is a primitive third root of unity , i.e. $\xi_3, \xi_3^2 \neq 1$ but $\xi_3^3=1$ .
The minimal polynomial of $\xi_3$ over $K$ is $x^2+x+1$ , so the degree of $K'/K$ is 2. This means that the ramification index of $K'/K$ is either $1$ or $2$ , i.e. it is either unramified or totally ramified. Question : Which case is true? Ideas and Thoughts : My thought is that $K'/K$ is going to be unramified. I think this is true because the minimal polynomial of $\xi_3$ , namely $x^2+x+1$ , is not an Eisenstein polynomial over $\mathbb{Z}_5$ . But maybe there might be a weird linear combination $a + b \xi_3$ with $a,b \in \mathbb{Q}_5$ whose minimal polynomial is indeed an Eisenstein polynomial. I don't know if that is possible thuogh. If $K'/K$ was totally ramified, then there must be an $x=a + b \xi_3$ with $a,b \in \mathbb{Q}_5$ such that the valuation is $1/2$ , i.e. $v_K'(x) = \frac{1}{2}$ .
We have the general formula $$v_K'(x) = \frac{1}{2}v_5(N_{K'/K}(x)) = \frac{1}{2}v_5(a^2-ab+b^2)$$ ,
so we have to check if $a^2-ab +b^2 = 0$ has a solution over $\mathbb{F}_5$ . Is there a good way to check quickly (other than try out all possibilities) if it has a solution? I know that there is a unique unramified extension of $K$ of degree 2 which can be obtained by adjoining a primitive $(5^2-1)$ -th root of unity, say $\xi_{24}$ . So we could check if $\xi_3 \in \mathbb{Q}_5(\xi_{24})$ . But this also seem to be really tedious. Could you explain me what the best way is to approach this problem? Thank you!","['algebraic-number-theory', 'ramification', 'p-adic-number-theory', 'abstract-algebra', 'extension-field']"
2925338,Intuition: Why chance of getting at least one ace when rolling a dice six times is not close to $1$?,"So probability of getting $1$ ace (the one dot in dice) = $1/6$ i.e. in one out of six times we will get an ace. But when we calculate the probability of getting at least one ace in six rolls, we get $$= 1-\left(\frac{5}{6}\right)^6$$ $$= 0.665$$ I understand how the value is derived. But what is intuitive explanation for the same? Since it is so close to $68\%$ , the percentage of population within $1$ standard deviation of normal distribution, does it have any relationship with normal distribution?","['statistics', 'probability-distributions', 'dice', 'probability-theory', 'probability']"
2925346,Second order homogenous differential equation with variable coefficients,"I have a complicated non-linear first order homogeneous differential equation for coherent states $\psi(t)$ . Via perturbation theory I obtained a linear non-homogeneous first order recursive differential equation \begin{align}
(1)\qquad\frac{d}{dt}\psi^n&=-i\omega\psi^n+f^{n-1}\\
\end{align} where $n$ denotes the order of perturbation and the functions $g^{n-1}$ and $f^{n-1}$ consist of the previous solutions up to $n-1$ -th order and some other functions $\phi^i(t)$ from another differential equation I solved, so they are known. I solved these via matrix calculus for $n=0,1$ and obtained the following solutions $$
(1.1)\qquad\psi^0=A^0e^{-i\omega t}\qquad \psi^1=A^1(e^{i\omega t}-e^{-3i\omega t})\, .
$$ In case of $n=0$ , one can directly read out the dispersion $\omega$ because the amplitude is time-independent. In case of $n=1$ , it is not possible to read out the dispersion directly since it is a combination of $\omega$ and $3\omega$ . My goal is to write the first order solution such that one can read out the dispersion directly. To this end, I separated the real and imaginary parts and wrote the polar form: $$
\psi^1=2A^1sin(2\omega t)e^{icot(\omega t)}\, .
$$ Now, the time dependence entered into the amplitude, which is qualitatively different from the $n=0$ case, such that the exponent is not the dispersion anymore. To find an expression similar to the zeroth order case, I reformulated the differential equation while knowing the solutions $\psi^1$ which I then again solved and hoped for a ""nice"" result. Because it is $A^1=A^1(A^0)$ , one cane write $\psi^0$ in terms of $\psi^1$ and consequently it is $f^1=p(t)\psi^1$ . And plug this into the differential equation gives: $$
(2)\qquad\frac{d}{dt}\psi^1=-i\omega\psi^1+f=(-i\omega+p(t))\, \psi^1.
$$ Here, I solved the equation and obtained: $$
(2.1)\qquad\psi^1=A'^{1}sin(2\omega t)e^{-i\omega t}\, .
$$ Unfortunately, the amplitude is still time-dependent. So I again reformulated the differential equation and obtain several other forms of differential equations hoping to encounter a desired solution. One of the other differential equations had the following form ( $y\equiv\psi\, ,x\equiv t$ ): $$
x^2 y^{\prime\prime}(x)+2xy^{\prime}(x)-2y+axy(x)+bx^2y(x)=0\,
$$ where $y: \mathbb{R}\rightarrow\mathbb{C}$ and $a,b\in\mathbb{C}$ . After several failed attempts, I found out about the Laplace transform. So I transformed it to: $$
(s^2+b)Y''(s)+(2s-a)Y'(s)-2Y(s)=0\, 
$$ where $Y(s)=\int_0^{\infty}e^{-sx}y(x)dx$ . The solutions to this equation as mentioned by @paulplusx is even worse. Now this brings me to the following two questions: 1.) How can I get the desired structure, i.e., $\psi^1\sim e^{-i\omega' t}$ ? (maybe this is not even possible, after all if $z=r(t)^{i\theta(t)}$ , then why should I always be able to find a $\theta'$ such that $z=const.\,  e^{i\theta'(t)}$ , $r$ and $\theta$ are independent.) If not possible, how can I obtain the dispersion of $\psi^1$ ? 2.) Is the way, I was proceeding even consistent, I have strong doubts? Meaning: If I have a recursive differential equation $(1)$ that I solved at $n$ -th order. Then take the solution at $n-1$ -th order and rearrange it by writing it in terms of the $n$ -th order solution. Then obtain the differential equation $(2)$ and then solve it. It seems as if the two differential equations, do not have the same set of solutions because the solutions in $(2.1)$ does not solve $(1)$ , even though $(2)$ was derived from $(1)$ . I hope this is not too lengthy,....","['mathematical-physics', 'laplace-transform', 'ordinary-differential-equations', 'perturbation-theory']"
2925360,Inheriting complex structure from a covering space (Griffiths and Harris),"On page 16 of Griffiths and Harris' Principles of algebraic geometry ,  they write In general, if $\pi: M\to N$ is a topological covering space and $N$ is a complex manifold, then $\pi$ gives $M$ the structure of a complex manifold as well; if $M$ is a complex manifold and the deck transformations of $M$ are holomorphic, then $N$ inherits the structure of a complex manifold from $M$ . My question is  for the last statement does one need more assumptions on the covering $\pi: M\to N$ ? Or could anyone please explain to me how to construct the complex structure on $N$ ?","['complex-geometry', 'covering-spaces', 'differential-geometry']"
2925419,Simplest Unhalvable Shape,"Consider a connected 3D-printable shape such as the below. It appears that any plane passing through the centroid will divide the shape into more than two pieces.  Define a shape with this property unhalvable . Would the simplest unhalvable shape be topologically equivalent to a sphere, a torus, or something else? What are some simple unhalvable shapes? Is the below embedding of the Trefoil knot unhalvable?","['solid-geometry', 'general-topology', '3d', 'recreational-mathematics']"
2925421,Use cosine rule to determine the length of a side of a triangle. Cannot replicate textbook solution,"Given a triangle of lengths $4$ , $5$ and $x$ , where the sides of length $4$ and $5$ meet at an angle of $60^{\circ}$ , I must calculate the length of side $x$ . The cosine rule is: $$a^2 = b^2 + c^2 - 2bc\cos(\alpha)$$ So, applying to my problem: $$\begin{align}
a^2&=b^2+c^2-2bc\cos(\alpha) \\
x^2&=4^2+5^2-2(4)(5)(\cos(60^{\circ})) \\
x^2&=16+25-40\cos(60^{\circ}) \\
x^2&=41-40\cos(60^{\circ}) \\
x^2&=41-40(0.9524) \\
x^2&=41-38.1 \\
x^2&=2.9 \\
x&=\sqrt{2.9}
\end{align}$$ The textbook solution says I should arrive at $x = \sqrt{21}$ , not $x=\sqrt{2.9}$ . The textbook does not provide working to the solution, only the final answer. Where did I go wrong?","['trigonometry', 'triangles']"
2925500,How do I evaluate the following derivative?,"How can I evaluate the derivative $$\left. \frac{d}{dx} \left( x \, \ln(x^5) \right)\right|_{x=1} \, ?$$ I have this math problem, and the biggest thing I do not understand, is which derivative rule do I need to apply, and what does the vertical bar mean in this problem? Solution $$\left. \frac{d}{dx} \left( x \, \ln(x^5) \right)\right|_{x=1} = 5.$$","['calculus', 'derivatives']"
2925521,The definition of a smooth morphism is too abstract. Can we make it simpler in a special case?,"The definition of a smooth morphism of schemes $f:X \rightarrow S \space$ given here on stacks project  is so abstract that it is intractable to me. $f$ is called smooth if for every point $x$ of $X$ , there exists an affine open neighborhood $U$ of $x$ , and an affine open set $V$ of $S$ , with $f(U) \subset V$ , such that the induced ring homomorphism $\mathcal O_S(V) \rightarrow \mathcal O_X(U)$ is a smooth ring homomorphism.  A smooth ring homomorphism is defined in terms of the ""naive cotangent complex."" I just have no idea how to think about or work with this definition.  So let me consider a more special case: let $R$ be a discrete valuation ring with quotient field $K$ and residue field $k$ .  Let $X = \operatorname{Spec} A$ be a scheme of finite type over $R$ , say $X \subset \mathbb A_R^n$ . What does it mean to say that $X$ is smooth over $R$ ?  Can we give a simpler criterion than the one given on stacks project?  I'm sure a necessary condition is that $A$ is a flat $R$ -algebra.    Can we talk about the smoothness of $X$ over $R$ in terms of the smoothness of the generic and special fibres?  That is, in terms of $X_K = \operatorname{Spec} A \otimes_R K$ and $X_k = \operatorname{Spec} A \otimes_R k$ being smooth varieties over $K$ and $k$ ?",['algebraic-geometry']
2925553,Diameter of the Symmetric group,"If $G$ is a finite group and $A \subseteq G$ a set of generators, the diameter $diam(G,A)$ is the least integer $d$ such that $A^d=G$ . Now consider the symmetric group $S_n$ and the subset $A_n = \{(12...n), (12) \}$ . It is known that $diam(S_n,A_n) \asymp n^2$ . There exist a set of generators $A_n$ of bounded cardinality such that $diam(S_n,A_n) \ll n \log n$ ?","['symmetric-groups', 'finite-groups', 'group-theory', 'combinatorics']"
2925576,"$\text{SL}(2,\mathbb{R})$ acts on the hyperbolic space by isometries","Let $H:=\{(x_0,x_1,x_2)\in\mathbb{R}^3\mid -x_0^2+x_1^2+x_2^2=-1\}$ be the hyperbolic space with metric $g_{hip}$ induced by the Lorenz inner product $g_{Lor}=-dx_0^2+dx_1^2+dx_2^2$ . Find a bijection between $H$ and $X:=\{M\in\mathbb{R}^{2\times 2}\mid M^t=M,\,\det(M)=1\}$ and show that $\text{SL}(2,\mathbb{R})$ acts on $H$ by isometries. I've found the following correspondence: $(x_0,x_1,x_2)\in H\mapsto\left(\begin{array}{ll}(x_0+x_1) & x_2\\x_2 & (x_0-x_1)\end{array}\right)\in X$ and conversely $\left(\begin{array}{ll}a & b\\b & c\end{array}\right)\in X\mapsto\left(\frac{a+c}{2},\frac{a-c}{2},b\right)\in H$ , which are mutually inverse. I've also defined an action on $X$ given by: \begin{align*}
\rho:\text{SL}(2,\mathbb{R})&\to \text{Bij}(X)\\
M&\mapsto (A\mapsto M^tAM)
\end{align*} I've checked that $\rho$ is indeed a group action, but I don't know how to prove that this will be translated into an isometry of $H$ . Any suggestions?","['group-actions', 'hyperbolic-geometry', 'riemannian-geometry', 'differential-geometry']"
2925631,error sensitivity analysis of Runge - Kutta method,"In Runge - Kutta - Fehlberg methods, sometimes and in some cases the answer depends on the method we define the error and also on the magnitude of the error. In the case I am working on, there are several ""zero crossings""; which is problematic for 'scaling' in the definition of precision. Besides, the solution depends on the steplength; surprisingly, not its precision, but its behavior! So, the numerical method is not reliable at all. How can I define error and control the sensitivity of the numerical method to be reliable? I saw in the literature some different methods for defining the error and controlling the steplength. Kash and Carp happens to be the most famous. But the problem is the way all these methods 'scale' the precision. I need the step correction method to be 'robust' enough. The most weird case is that in some time-steps the error (i.e., the difference between the 4th order estimation and the 5th order solution) becomes zero! The zero error causes the corrected steplength to become Inf! How can I write the steplength correction to overcome this problem? Also, if anyone knows any useful reference please announce me. Thanks in advance","['runge-kutta-methods', 'numerical-methods', 'ordinary-differential-equations']"
2925633,Resolution of first order differential equation,"I have difficulties to solve these two differential equations: 1) $ y'(x)=\frac{x-y(x)}{x+y(x)} $ with the initial condition $ y(1)=1 $ .I'm arrived to prove that $$ y=x(\sqrt{2-e^{-2(\ln x+c)}}-1) $$ but I don't know if it's correct. If it's right, how do I find the constant $ c $ ? Because WolframAlpha says that the solution is $ y(x)=\sqrt{2}\sqrt{x^2+1}-x $ . 2) $ y'(x)=\frac{2y(x)-x}{2x-y(x)} $ . I'm arrived to prove that $ \frac{z-1}{(z+1)^3}=e^{2c}x^{2} $ but I don't know if it's correct. If it's right, how do I explain $ z $ to substitute it in $ y=xz $ ? Then, how do I find the constant $ c $ ? Thanks for any help!","['integration', 'indefinite-integrals', 'ordinary-differential-equations']"
2925697,Difference between $\operatorname{Var}(Y)$ and $\operatorname{Var}(Y\mid X)$?,"What is the difference between $\mathrm{var}(Y)$ and $\mathrm{var}(Y\mid X)$ ? If $Y = c + \beta X$ and $\operatorname{var}(X)=\sigma^2$ , won't both come out to be the same, i.e., $\beta^2\sigma^2$ ?","['statistics', 'variance']"
2925711,Number of Arrangements of Couples,Here's the problem: Five couples sit randomly in a row during a movie. What is the probability that at least four couples sit next to each other. My denominator is $10!$ The number of ways for all five couples to sit next to each other is $5!\cdot2^5$ . The number of ways for exactly four couples to sit next to each other is $(6!-5!\cdot2)\cdot2^4\cdot5$ . The $6!-5!\cdot2$ is the number of ways for two specific people and four couples to arrange themselves minus the number of ways the two specific sit next to each other. Then I multiplied by $2^4$ to rearrange the people in the four couples. Then I multiplied by five to account for which of the five couples is split up. Can someone check my logic? My class wants me to double-check with experts because I'm not sure about my answer.,"['permutations', 'combinatorics']"
2925740,Derivative of a function from real number space to Wasserstein space,"I'm not really having a good background in math, so please correct me if I say something very vague or even wrong. Suppose a function $\rho=f(\theta):\mathbb{R}\to\mathcal{W}_p(\mathbb{R}^d)$ .
I would like to calculate a sort of derivative $\tilde{\frac{d}{d\theta}}\rho=f'(\theta)$ , which magnitude corresponds to $$
\left\vert \tilde{\frac{d}{d\theta}}\rho \right\vert
=\lim_{\Delta\theta\to0}\frac{\mathcal{W}_p[f(\theta+\Delta\theta),f(\theta)]}{\Delta\theta}.
$$ Although, at this point I'm not at all clear about (1)what kind of quantity $\tilde{\frac{d}{d\theta}}\rho$ is, and (2)what kind of norm $\vert\cdot\vert$ we use here. For example a common point-wise derivative $$
\frac{d\rho}{d\theta}(x) = \lim_{\Delta\theta\to0}\frac{\rho(x;\theta+\Delta\theta) - \rho(x;\theta)}{\Delta\theta}
$$ with its $L_2$ -norm definitely does not correspond to such quantity. So the question is, is there any concept that corresponds to or similar at all to this kind of derivative?","['calculus', 'optimal-transport', 'derivatives', 'differential-geometry']"
2925744,Estimate gradient of a function,"Let $\mathbb{D}:= \{(x,y)\in \mathbb{R}^2:x^2+y^2<1\}$ , $S$ is open and $\mathbb{\bar{D}}\subset S$ . Let $F:S\to \mathbb{R}$ is differentiable and $|F(x)|\leq 1$ for all $x\in \mathbb{D}$ . Prove that there exists $\theta \in S$ such that $|\triangledown F(\theta )| < 4$ . I think it may be easier to solve if it is continuously differentiable. In this condition, $\triangledown F(x)$ can be seen as a $C^1$ vector field and I can find a integral curve originated from $(0,0)$ . When it is differentiable, what I know is only ""The differential mean value theorem"": $F(y)-F(x)=\triangledown F(\xi )\cdot (y-x)$ . It is hard to consider directions of these two vectors.","['multivariable-calculus', 'calculus', 'vector-analysis']"
2925810,Solution to an ODE with every $n$-moment finite.,"Let $f$ be a differentiable function from $[0, \infty]$ to $\mathbb{R}$ satisfying the following: $$
f'(x)=f(2x)-f(x),
$$ $$
M_n=\int_0^\infty x^n f(x) \ dx < \infty.
$$ Show that there exists a non null function that satisfies the hypothesis and then enumerate all the sequences $(a_n)_{n \in \mathbb{N}}$ such that $a_n=M_n, \ \forall n \in \mathbb{N}$ . My approach was to search a function of the type $$
f(x) = \sum_n a_n  e^{b_n x}
$$ with $a_n \ne 0, b_n <0$ , since such a function converges to a $\mathcal{C}^1$ function as the series converges uniformly. However doing some computation I imagine that $b_n$ as to be something like $-2^n$ , but I do not have many arguments to state that formally, let us say that I only hope it has to be something like that since no polynomial satisfies the hypothesis. Any suggestions? And moreover in such a problem how do I establish a candidate to such condition instead of strongly hoping to have at least a function that is very similar to its derivative?","['calculus', 'analysis', 'ordinary-differential-equations', 'real-analysis']"
2925825,Find derivative of gas pressure formula,"I did really well with derivatives until I hit this question. I'm not sure how to treat the different variables which are considered constants. I keep getting zero. Can anyone give me a pointer or just start it for me so I can see how to begin and take it from there? If gas in a cylinder is maintained at a constant temperature​ T, the pressure P is related to the volume V by a formula of the form $$P=\frac{nRT}{V-nb}-\frac{an^2}{V^2}$$ , 
in which​ a, b,​ n, and R are constants. Find $\frac{\partial P}{\partial V}$ .","['physics', 'calculus', 'derivatives']"
2925835,Finding the minimum or maximum of a bivariate function when $f_{xx}\times f_{yy}-f_{xy}^2=0$.,"I see that when $f_{xx}\times f_{yy}-f_{xy}^2<0$ then it is a saddle point.
Also when $f_{xx}\times f_{yy}-f_{xy}^2>0$ then it is a minima or maxima.
What is exactly happening when $f_{xx}\times f_{yy}-f_{xy}^2=0$ ?","['optimization', 'multivariable-calculus', 'maxima-minima']"
2925898,"Why are the laws of sines/cosines ""laws"" and not ""theorems""?","So in logic we have every line of a proof being either an axiom or a theorem -- but then why do we have concepts like the ""law of sines"" and the ""law of cosines""? Are these technically ""theorems"" as well? How is ""law"" being used here? Is there a mathematical reason? A historical one?","['axioms', 'logic', 'definition', 'trigonometry', 'math-history']"
2925940,Prove Cauchy-Schwarz with AM-GM for three variables,"I want to extend CS from two to three variables. Here's a Cauchy-Schwarz proof with two variables, which is proof 4 from here Let $A = \sqrt{a_1^2 + a_2^2 + \dots + a_n^2}$ and $B = \sqrt{b_1^2 + b_2^2 + \dots + b_n^2}$ . By the arithmetic-geometric means inequality (AGI), we have $$
\sum_{i=1}^n \frac{a_ib_i}{AB} \leq \sum_{i=1}^n \frac{1}{2} \left( \frac{a_i^2}{A^2} + \frac{b_i^2}{B^2} \right) = 1
$$ so that $$
\sum_{i=1}^na_ib_i \leq AB =\sqrt{\sum_{i=1}^na_i^2} \sqrt{\sum_{i=1}^n b_i^2}
$$ How would I extend this method for three variables, i.e. to get the following? $$
\sum_{i=1}^na_ib_i c_i \leq \sqrt{\sum_{i=1}^na_i^2} \sqrt{\sum_{i=1}^n b_i^2}  \sqrt{\sum_{i=1}^n c_i^2}
$$ Somehow I don't think it's as trivial as the first method, i.e. simply defining $C$ the same way does not seem to work. Maybe there is a better approach?","['cauchy-schwarz-inequality', 'inequality', 'proof-writing', 'linear-algebra']"
2925959,"Can a set of vectors be linearly independent in one vector space, but be linearly dependent in another vector space?","For example, let S = { $(x_1, x_1)| x_1 \in \mathbb R$ } be a subspace of $\mathbb R^2$ . By definition, dim(S) = 1, and dim( $\mathbb R^2$ ) = 2. Then the set {(1, 1)} only has one vector, so is it linearly independent in S, but is linearly dependent in $\mathbb R^2$ ? I know this doesn't make any sense, but we learned in class that a set of vectors can only be linearly independent if it spans the vector space that it is in. Since (1,1) is in both S and $\mathbb R^2$ , but the set {(1, 1)} only spans S, how come it is not only linearly independent in S and linearly dependent in $\mathbb R^2$ (since {(1,1)} does not span $\mathbb R^2$ ). Sorry for this stupid question",['linear-algebra']
2925980,Smoothing non-differentiable manifolds?,"i recently started studying differential topology and smooth manifolds. I'm really new to this area but a frequent question that came to my mind quite often is the following consider a topological manifold $M$ that is not smooth (maybe lots of sharp edges on its surface). Are there any ways to ""smoothen"" such manifolds such that they become differentiable at every point ? If the answer is yes, under what circumstances i.e. what are the requirements for $M$ and how can this be done? I already figured out that if $X$ is a topological space, $Y$ a differentiable manifold and there is a homeomorphism $$ \phi:X \to Y$$ $X$ can be equipped with a differentiable structure. However, is there more to discover? I really do not know what exactly to search for or what books i should look for. I highly appreciate any suggestion about keywords/theorems or preferably books that cover similar topics. Thank you very much.","['general-topology', 'differential-topology', 'differential-geometry']"
2926000,Simplify $\frac{5}{6}\log\left(\frac{5}{4}\right) - \frac{1}{6}\log(2)$ to $\log\left(\frac{5}{4}\right) - \frac{1}{6}\log\left(\frac{5}{2}\right)$,I'm trying to bring this expression: $$\frac{5}{6}\log\left(\frac{5}{4}\right) - \frac{1}{6}\log(2)$$ To this one: $$\log\left(\frac{5}{4}\right) - \frac{1}{6}\log\left(\frac{5}{2}\right)$$ Where $\log$ is the natural algorithm. I know the two expressions are equal (checked with wolfram) but I really can't find the correct passages... Could you please help me?,"['algebra-precalculus', 'logarithms']"
2926021,regularity of finite type $k$-schemes by base changing to $\bar{k}$ and an equality of dimensions of tangent spaces,"For reference I'm trying to understand section 12.2.16 of Vakil's FOAG. Let $X$ be a finite type $k$ -scheme and $p$ a closed point with residue field $k'/k$ , a finite separable extension of degree $d$ . Let $\pi: X_{\bar{k}} \to X$ be the projection morphism. It's easy to see that $k' \otimes_k \bar{k} \cong \bar{k}^d$ as rings, so the fibre over $p$ is $\pi^{-1}(p) = \sqcup_d \mathrm{Spec}(\bar{k})$ . Call these $d$ pre-images $p_1, \dots, p_d$ . For the sake of this question, since regularity can be checked pointwise, we may assume $X = \mathrm{Spec} A$ and $p$ corresponds to a maximal ideal $\mathfrak{m}$ of $A$ . One can show that the fibre is the closed subscheme defined by $\mathrm{Spec}((A \otimes_k \bar{k})/(\mathfrak{m} \otimes_k \bar{k}))$ . Vakil claims we have the equality $$
\sum_{i=1}^{d} \dim_{\bar{k}}(T_{X_{\bar{k}}, p_i}) = d \cdot \dim_{k'}(T_{X, p}).
$$ I can't figure out how to prove it. Write $r := \dim_{k'}(T_{X, p})$ . He suggests using the fact that $$(\mathfrak{m} \otimes_k \bar{k})/(\mathfrak{m}^2 \otimes_k \bar{k}) \cong \mathfrak{m}/\mathfrak{m}^2 \otimes_k \bar{k} = \bar{k}^{dr},$$ which means I only have to show that the dimension of $(\mathfrak{m} \otimes_k \bar{k})/(\mathfrak{m}^2 \otimes_k \bar{k})$ as a $\bar{k}$ -module is the same as the sum of the dimensions of the tangent spaces of the preimages of $p$ . Does anyone have any hints? I would like to understand intuitively why this equality of dimensions should be true. Once I figure this out, I can conclude that $X$ is regular at $p \iff X_{\bar{k}}$ is regular at $p_1, \dots, p_d$ !",['algebraic-geometry']
2926040,"""Except"" in predicate logic","I have a phrase that I am trying to translate into predicate logic. The phrase is as follows: All lions except old ones roar So far I have written down that: $∀x((L(x) \land \lnot O(x)) \to R(x))$ Where $L(x)$ is "" $x$ is a lion"", $O(x)$ is "" $x$ is old"", and $R(x)$ is "" $x$ roars"". I am wondering if this is correct notation. I am mostly confused about the ""except"" in the phrase because as I have translated states that all lions who are not old roar. Does any one have any thoughts about the notation for this phrase?","['predicate-logic', 'first-order-logic', 'logic', 'discrete-mathematics', 'logic-translation']"
2926067,Geometric intuition for torsion in $H_{2}$ of non-orientable $3$-manifold,"Let $M$ be a compact, connected $n$ -manifold. Consider the homology groups $H_n(M)$ with coefficients in $\mathbb{Z}$ . It is well known that if $M$ is not $\mathbb{Z}$ -orientable, then we have $H_n(M) =0$ and $H_{n-1}(M) = \mathbb{Z}/2 \oplus \mathbb{Z}^i$ for some $i \ge 0$ . The proofs are clear for me (remark: the main instruments used in the proof are the Universal Coefficients Theorem and the existence of an orientable double cover of $M$ ), but I'm quite curious if there exists a geometric/intuitive explanation for the torsion summand $ \mathbb{Z}/2$ of $H_{n-1}(M)$ . Can this phenomenon be visualized in the case of a non-orientable $3$ -manifold or is this a purely algebraic result?","['compact-manifolds', 'general-topology', 'visualization', 'algebraic-topology']"
2926069,"Show that $\dim_k(\mathfrak m^n / \mathfrak m^{n+1})=n+1$ whenever $0\leq n<m_P$, where $(\mathcal O,\mathfrak m)$ is the local ring of $P$","Let $F$ be an irreducible polynomial in $k[x,y]$ with $k$ an algebraically closed field, and $P=(0,0)$ a zero of the polynomial. Let $(\mathcal O_P(F),\mathfrak m)$ be the local ring at $P$ , and let $m_P$ be the multiplicity of the curve defined by $F$ at $P$ . Show that $\dim_k(\mathfrak m^n / \mathfrak m^{n+1})=n+1$ whenever $0\leq n<m_P$ . For reference, this is exercise 3.13 from Fulton's Algebraic Curves. I tried doing an induction: the case $n=0$ is easy. For the induction step, I tried replicating the Theorem 2 from earlier in the chapter: There is a short exact sequence $$\mathfrak m^n / \mathfrak m^{n+1}\to\mathcal O_P(F) /\mathfrak m^{n+1}\to \mathcal O_P(F)/\mathfrak m^n$$ From which we get that $\dim_k(\mathfrak m^n/\mathfrak m^{n+1})=\dim_k(\mathcal O_P(F)/\mathfrak m^{n+1})-\dim_k(\mathcal O_P(F)/\mathfrak m^n)$ . We can compute the latter term using the induction hypothesis, so I need to find $\dim_k(\mathcal O_P(F)/\mathfrak m^{n+1})$ . Fulton uses the following series of identifications: Let $I=(x,y)$ be an ideal. Then we have that $\mathfrak m^n=I^n\mathcal O_P(F)$ , so that: $$\mathcal O_P(F)/\mathfrak m^{n+1}\cong \mathcal O_P(F)/I^{n+1}\mathcal O_P(F)\cong \mathcal O_P(\mathbb A^2)/(F,I^{n+1})\mathcal O_P(\mathbb A^2)\cong k[x,y]/(F,I^{n+1})$$ (This skips a lot of detail, but it is all justified). But now, I am having trouble computing the dimension of the latter term. In the book, Fulton uses the fact that $n\geq m_P$ to create a short exact sequence, but here it doesn't seem to work.","['algebraic-geometry', 'commutative-algebra']"
2926120,The homology class associated to a hypersurface?,"Let $X$ be a compact complex manifold of dimension $n$ and $Z$ be a hypersurface. I want to know about its homology class $[Z]\in H_{2n-2}(X)$ . Some methods I know to define $[Z]$ : Find a line bundle $L$ which has a holomorphic section vanishing precisely on $[Z]$ , and $c_1(L)\in H^2(X)$ . Then its Poincare duality gives $[Z]\in H_{2n-2}(X)$ . (This is equivalent to the definition of fundamental class. This is the part I can understand) The image of $1\in H^0(Z)$ in the composition $$H^0(Z)\xrightarrow[\text{ isomorphism}]{\text{Thom}} H^2(X,X-Z) \to H^2(X)$$ defines a class in $H^2(X)$ and then its Poincare duality gives $[Z]\in H_{2n-2}(X)$ . My questions: Both methods need to define the cohomology class first and use Poincare duality. Is there a direct way to define $[Z]\in H_{2n-2}(X)$ ? Why the two definitions are compatible?","['algebraic-geometry', 'homology-cohomology', 'algebraic-topology']"
2926127,"I don't understand the result of this: $\int e^x\cos(2x) \, dx$","Sorry for the simple question, I think when I find the answer I'll be like ""ow how I didn't notice this..."" Unfortunately I'm bad at math and i need help on this. 
So I don't understand the result of this: $$\int e^x\cos(2x)\,dx$$ Okay I integrated by parts twice and got this: $$e^x\cos(2x)-\left( -2e^x\sin(2x)+4\int e^x\cos(2x)\,dx \right)$$ So we found our inital integral here and so we can isolate it. But the result is: $$\int e^x\cos(2x)\,dx = \frac{2e^x\sin(2x)+e^x\cos(2)}5 +C$$ I'm having problem isolating our integral. I have no idea what happened to the 4 multiplying the integral and I have no idea where this $5$ came from.","['integration', 'indefinite-integrals']"
2926134,Comparison of the mod p etale cohomology of special fiber and generic fiber,"I am new to etale cohomology theory and recently learnt some base change theorems like proper base change and smooth base change. However, I am somehow confused about the etale cohomology group of $\Bbb Z/p\Bbb Z$ after base change. For example, asssume we have a scheme $X$ proper smooth over $\Bbb Z_p$ , where $\Bbb Z_p$ means the $p$ -adic integer ring. What is the relation between $H^i_{et}(X_{\Bbb F_p},\Bbb Z/p\Bbb Z)$ and $H^i(X_{\Bbb Q_p},\Bbb Z/ p\Bbb Z)$ ? Must them have the same dimension as $\Bbb F_p$ -vector space?","['etale-cohomology', 'p-adic-number-theory', 'algebraic-geometry']"
2926168,Evaluate $\ \int_{|z|=2}\frac{z^2+1}{(z-3)(z^2-1)}\ dz$,"I am trying to solve $$\ \int_{|z|=2}\frac{z^2+1}{(z-3)(z^2-1)}\ dz,$$ using Cauchy's Integral Formula. My attempt: $$I=\int_{|z|=2}\frac{z^2+1}{(z-3)(z^2-1)}\ dz=\int_{|z|=2}\frac{z^2+1}{(z-3)(z-1)(z+1)}\ dz$$ Now, $I$ has singularities $\pm 1, 3$ , but only $\pm 1$ lie inside the circle $|z|=2$ . Now if we draw the following We see that $f(z)=\frac{z^2+1}{(z-3)(z-1)}$ and $g(z)=\frac{z^2+1}{(z-3)(z+1)}$ are holomorphic outside the green and blue ball respectively. Now, i've been told that we can use a corollary of the Cauchy-Goursat theorem to show that $$I=\int_{a} \frac{f(z)}{z+1}\ dz+\int_{b} \frac{g(z)}{z-1}\ dz,$$ where $a$ and $b$ are the contours of the green and blue cirlces respectively. But I don't understand why this is ? I can solve beyond this point.","['complex-analysis', 'contour-integration', 'proof-verification', 'cauchy-integral-formula']"
2926174,"Suppose that $f:A\to B$ is a mapping, that $A,B$ are finite, and that $|A| > |B|$. Then $f$ is not injective","Does this proof look fine or contain gaps? Do you have suggestions? Many thanks for your dedicated help! Suppose that $f$ is a mapping from a set $A$ to a finite set $B$ . If $A$ is finite and $|A| > |B|$ , then $f$ is not injective. If $A$ is infinite, then there exists $b \in B$ such that $f^{−1}[\{b\}]$ is infinite. If $A$ is finite and $|A| > |B|$ , then $f$ is not injective Lemma: Suppose that $B$ is finite and that $g:B\to A$ is surjective. Then $A$ is finite and $|A|\le|B|$ . (I presented a proof here ) Assume the contrary that $f$ is injective. We define a mapping $g$ from $B$ to $A$ by $g(b)=f^{-1}(b)$ for all $b\in\operatorname{ran}f$ and $g(b)=\bar a$ for all $b \in B\setminus \operatorname{ran}f$ for some $\bar a \in A$ . We have $f^{-1}[\operatorname{ran}f]= \operatorname{dom}f$ $=A$ . Thus $g[\operatorname{ran}f]=A$ . Hence $g:B\to A$ is surjective. Moreover, $B$ is finite, then $A$ is finite and $|A|\le|B|$ by Lemma . This contradicts the fact that $|A|>|B|$ . Hence $f$ is not injective. If $A$ is infinite, then there exists $b \in B$ such that $f^{−1}[\{b\}]$ is infinite Lemma: Finite union of finite sets is finite Assume the contrary that $f^{−1}[\{b\}]$ is finite for all $b\in B$ . It's clear that $\bigcup\limits_{b\in B}f^{−1}[\{b\}]=A$ . Furthermore, $\bigcup\limits_{b\in B}f^{−1}[\{b\}]$ is a finite union of finite sets. It follows from the Lemma that $A=\bigcup\limits_{b\in B}f^{−1}[\{b\}]$ is finite. This contradicts the fact that $A$ is infinite. Hence there exists $b\in B$ such that $f^{−1}[\{b\}]$ is infinite.","['elementary-set-theory', 'proof-verification']"
2926196,"What is meant by ""infinitely often"" in this problem on Borel sets?","As the title suggests, I am having some trouble understanding an exercise regarding   Borel sets.  In particular I am trying to Show that the set of real numbers that have a decimal expansion with
  the digit $5$ appearing infinitely often is a Borel set. My question here is what is meant by the phrase ""infinitely often"" in this case?  I have never seen this phrase before in a formal context. This attempt of mine is horrific so don't butcher me, but I tried starting out in the following way: Let $\mathcal{A}_5$ denote the set of real numbers that have a decimal expansion with the digit $5$ appearing infinitely often, i.e. every $a\in\mathcal{A}_5$ can be written as $$a=\ldots+ 5\cdot10^n+5\cdot10^{n-1}+\ldots+5\cdot 10 +5+5\cdot10^{-1}+\ldots 5\cdot10^{-m-1}+5\cdot10^{-m}+\ldots$$ Am I interpreting ""infinitely often"" correct here?  If not, what is it trying to say?","['borel-sets', 'measure-theory', 'real-analysis']"
2926270,Prove by induction that $\sqrt{1}+\sqrt{2}+...+\sqrt{n} \geq \frac{2}{3}n\sqrt{n}$,The base step is pretty obvious: $1 \geq \frac{2}{3}$ . Then we assume that $P(k)$ is true for some $k \in \mathbb{Z}^{+}$ and try to prove $P(k+1)$ . So I have $ \sqrt{1}+\sqrt{2}+...+\sqrt{k} + \sqrt{k+1} \geq \frac{2}{3}k\sqrt{k}+\sqrt{k+1}$ by the induction hypothesis. But I'm not too sure how to proceed to prove that this is also greater than $\frac{2}{3}(k+1)\sqrt{k+1}$ . Would appreciate any help!,"['inequality', 'summation', 'induction', 'discrete-mathematics', 'radicals']"
2926272,4-adic numbers and zero divisors,"The $p$ -adic numbers form an integral domain provided that $p$ is prime. Let's look at the $n$ -adic numbers when $n$ is not prime. Case $n = 10$ There are zero divisors.  See this previous question . Case $n = pq$ where $p$ and $q$ are coprime (not necessarily prime but not $1$ ). There are also zero divisors.  A similar construction works. Case $n = p^k$ where $p$ is prime and $k > 1$ I have not figured this one out yet, not even the simplest case of $n = 4$ .  The construction in the previous question above does not work and I have not found an alternative yet.  Looking at approximations in $\mathbb{Z}_4$ , $\mathbb{Z}_{16}$ , $\mathbb{Z}_{64}$ , etc just leads me to zeros divisors ending in zeroes suggesting, but not proving, that there are none. Note that I am using $\mathbb{Z}_n$ for the integers modulo $n$ and not the $n$ -adic numbers.  I think that I have seen it used for both.  What is usual if you want discuss both at the same time? Another previous question asks why $4$ -adic numbers are not possible.  The answer seems to be that they are possible but a norm cannot be defined.  So, it leaves the existence of zero divisors open. Are there zero divisors in the $4$ -adic numbers?
Are there idempotents in the $4$ -adic numbers? I have not looked at $9$ -adic or other prime powers yet. Please don't answer directly but some hints would be appreciated.","['number-theory', 'p-adic-number-theory']"
2926293,A specific homogeneous polar differential equation,"In an assignment of our school, we are asked to solve $$\frac{\mathrm{d}y}{\mathrm{d}x} = \frac{x + y - 3}{x - y - 1}$$ by turning it into a homogeneous polar differential equation (equation of the form $\displaystyle \frac{\mathrm{d}y}{\mathrm{d}x} = F\left(\frac{y}{x}\right)$ ) using substitutions $x = X + a$ , $y = Y + b$ . My solution was: Firstly, I determined substitutions $x = X + 2$ , $y = Y + 1$ , such that $$\frac{\mathrm{d}Y}{\mathrm{d}X} = \frac{X + Y}{X - Y}$$ Then, let $Y = Xv$ , thus $$\begin{aligned}
v + X\frac{\mathrm{d}v}{\mathrm{d}X} &= \frac{X + Xv}{X - Xv} \\
\int \frac{1 - v}{1 + v^2}\ \mathrm{d}v &= \int \frac{\mathrm{d}X}{X}
\end{aligned}$$ The left-hand side, specifically, gives $$\int \frac{\mathrm{d}v}{1 + v^2} - \int \frac{v}{1 + v^2}\ \mathrm{d}v = \tan^{-1} v - \frac{\ln \left(1 + v^2\right)}{2} + \mathrm{constant}$$ Therefore, $$\tan^{-1} v - \frac{\ln \left(1 + v^2\right)}{2} = \ln \left|X\right| + \mathrm{constant}$$ i.e. $$2\tan^{-1} \frac{y - 1}{x - 2} = \ln \left[1 + \frac{\left(y - 1\right)^2}{\left(x - 2\right)^2}\right] + \ln \left(x - 2\right)^2 + \mathrm{constant}$$ However, our assignment didn't come with a standard solution, so I verified my answer with Wolfram Alpha, which gives $$
2 \tan^{-1}\left(\frac{y(x) + x - 3}{-y(x) + x - 1}\right) = c_1 + \ln\left(\frac{x^2 + y(x)^2 - 2 y(x) - 4 x + 5}{2 \left(x - 2\right)^2}\right) + 2 \ln\left(x - 2\right)$$ which is different from my solution in the fraction inside function $\tan^{-1}$ is vastly different the denominator given by Wolfram Alpha inside the first $\ln$ is twice the denominator I gave the $x - 2$ in the last $\ln$ has no absolute value sign around it, but this seems a common problem of Wolfram Alpha solutions, so we can overlook it for the second May I know whether I'm wrong, or that this is a problem of the Wolfram Alpha solution? (or that the two solutions are actually equivalent, though seemingly very unlikely?)","['wolfram-alpha', 'ordinary-differential-equations']"
2926296,Weak convergence of measures implying almost sure convergence of random variables,"Suppose $\mu,\mu_n$ are Borel probability measures on $\mathbb{R}$ with $\mu_n$ converging weakly to $\mu$ . I am asked to find some probability space $(\Omega,\mathcal{F},\mathbb{P})$ and random variables $X,X_n$ such that $X$ has law $\mu$ , $X_n$ has law $\mu_n$ and $X_n \to X$ almost surely as $n \to \infty$ . So far I tried to let $(\Omega,\mathcal{F},\mathbb{P}) = ((0,1),\mathcal{B}_{0,1},\text{Lebesgue})$ and defined $X_n$ as for $\omega \in (0,1)$ we let $X_n(\omega) = \inf\{x \in \mathbb{R}: \omega \in \mu_n((-\infty,x])\}$ . Then $\mathbb{P}(X_n \in (-\infty,x]) = \mathbb{P}(X_n^{-1}((-\infty,x])) = \mu_n((-\infty,x])$ so $X_n$ has law $\mu_n$ and similarly for $X$ . However I am not able to prove that $X_n \to X$ almost surely. I have tried using contradiction, if $X_n \not\to X$ almost surely then we have that $|X_n-X| \geq 0$ and this does not converge to 0 almost surely. So the integral of this does not converge to $0$ as $n \to \infty$ . However at this point I get stuck. I can't see where I should bring in the fact that $\mu_n \to \mu$ weakly. How should I proceed?","['measure-theory', 'weak-convergence', 'almost-everywhere', 'sequences-and-series', 'convergence-divergence']"
2926305,"Differentiation operator is closed on $L^2[0,1]$?","Proposition. Let $\mathcal{H}=L^2[0,1]$ with a differentiation operator $T=i\frac{d}{dt}$ on it, whose domain $D(T)$ consists of all the absolutely continuous functions in $\mathcal{H}$, and the derivatives of those functions is still $L^2$. Then $T$ is a closed operator. (which means its graph is closed in $\mathcal{H}\times\mathcal{H}$) Here is my try so far.
Let $\{u_n\}$ be a sequence of $L^2$ functions in $\mathcal{H}$ converging to $u\in\mathcal{H}$. Also, $Tu_n$ converge to another $v\in\mathcal{H}$.
It suffices to show that $Tu=v$, which is to say, $\| Tu-v\|=0$. Since
$$\|Tu-v\|\le\|Tu-Tu_n\|+\|Tu_n-v\|$$
and $\|Tu_n-v\|\rightarrow 0$, we only need to prove that $\|Tu-Tu_n\|\rightarrow 0$.
$$\lim_{n\rightarrow\infty}\|Tu-Tu_n\|^2=\lim_{n\rightarrow\infty}\int \left|i\frac{d}{dt}(u-u_n)\right|^2dx.$$
Ideally, we “may” swap the “limits” with the “integral” and “derivative” and the “proof” is finished. However, it seems to me not very clear that theorems from real analysis allow me to do so. I’ve been stuck here for a long time. Any hints?","['functional-analysis', 'real-analysis']"
2926317,"Is there any $a, b \in \mathbb R, b \ne 0$ such that $\Gamma(a+bi)$ can be evaluated manually?","Is there any $a, b \in \mathbb R, b \ne 0$ such that $\Gamma(a+bi)$ can be evaluated manually? (Like $\Gamma(\frac 12)$) If there is/are, could you show me how to calculate it? I found that $\Gamma(i)$ cannot be calculated by hand, but only can be calculated using computer. Of course I tried $\Gamma(i+1)=\displaystyle\int_0^\infty x^i~e^{-x}~dx$, and then use $x^i=e^{i\ln x}=\cos\ln x+i\sin\ln x$. But still no clue.. Thanks.","['integration', 'complex-analysis', 'gamma-function', 'complex-integration', 'complex-numbers']"
2926381,while solving LDE why do we need to get the equation in the resolved form,"It's most of the time quite easy to solve linear differential equations (LDE) thanks to all the result we have in linear algebra. Yet there is something I don't understand, let's say we have the following LDE : $$a_n(t)y^{(n)} +...+ a_0(t)y = b(t)$$ where $a_i$ are continuous functions. Then in my book they always put this equation in the following ""resolved form"" : $$y^{(n)} + \frac{a_{n-1}(t)}{a_n(t)} y^{(n-1)} +...+ \frac{a_0(t)}{a_n(t)} y = \frac{b(t)}{a_n(t)}$$ I am wondering why this is useful to get the equation in this form? I mean are there theorems in linear algebra that doesn't apply or techniques that don't work if we let the equation in the form : $$a_n(t)y^{(n)} +...+ a_0(t)y = b(t)~?$$ Thank you!","['linear-algebra', 'ordinary-differential-equations']"
2926390,"(Combinatorial?) Proof of the identity $\sum_{k=1}^n \frac {(-1)^k}{k\,(k+1)}\binom nk = \frac 12 + \frac 13 + \dots + \frac 1{n+1}$?","Recently I've come across an interesting identity: $$
\frac 1{1\cdot 2}\binom n1 - \frac 1{2\cdot 3}\binom n2 + \frac 1{3\cdot 4}\binom n3 - \dots + \frac {(-1)^n}{n\cdot (n+1)}\binom nn =
\frac 12 + \frac 13 + \dots + \frac 1{n+1}.
$$ Does anyone have an idea how to prove this? PS. It'd be of special interest if someone could provide a combinatorial approach to this problem, although I'm not sure if that'd make sense since this is an identity for non-integer. Edit: Perhaps my question was worded in a way that seems trivial since there's a vote to close this question. I should have mentioned that I can prove it by expanding $\frac 1{k(k-1)}$ and do some further calculation. What I want is a clever way to interpret it, e.g. using combinatorics or some kind of generating function or integration.","['summation', 'number-theory', 'harmonic-numbers', 'combinatorics', 'probability']"
2926400,What is a possible substitution to this ODE?,"I have to solve this ODE: $$
(y-2x)\frac{dy}{dx}=3y-6x+1
$$ I have to make it in a form of separable variable equation and for that I have tried the following substitutions: $$
u=y-2x
$$ and $$
u=3y-6x+1
$$ But none made it ""solvable"", for example in the first I get to a point where I have this: $$
\frac{e^{y-2x}}{|y-2x|}=x+K
$$ where K is any constant. At this point I am unable to solve for y. Can anyone help me solve this?",['ordinary-differential-equations']
2926431,Obtaining the adjacency matrix of Cayley graphs,"Is it possible to obtain the adjacency matrix of a Cayley graph of $Z_3 \times Z_5$ ? (Manually or by using a software like GAP). Will there be a pattern for adjacency matrices of Cayley graphs for a particular type of groups considered (i.e. if we consider Cayley graphs of the groups $Z_p \times Z_q$ , where p,q are distinct primes, will the adjacency matrices obtained for various choices of p and q  be related to each other by some pattern)? I know we obtain different Cayley graphs for different generating sets chosen to construct the Cayley graph. So if the adjacency matrix is difficult to be taken due to this reason please mention at least for one generating set chosen. Thanks a lot in advance.","['graph-theory', 'gap', 'group-theory', 'adjacency-matrix']"
2926477,Exercise 4.E - The Elements of Integration and Lebesgue Measure by Bartle,"$4.E.$ Let $f,g\in M^{+},$ let $\omega\in M^{+}$ be a simple function such that $\omega\leq f+g$ and let $\phi_{n}(x)=\sup\{(m/n)\omega(x): 0\leq 
m\leq n, (m/n)\omega(x)\leq f(x)\}$ . Also let $\psi_{n}(x)=\sup\{(1-\frac{1}{n})\omega(x)-\phi_{n}(x),0\}$ . Show that $(1-\frac{1}{n})\omega\leq\psi_{n}+\phi_{n}$ , $\phi_{n}\leq f$ , $\psi_{n}\leq g$ . I was able to prove the first two inequalities, it's just use the definition of $\phi_n$ and $\psi_n$ and observe that $f$ is an upper bound for the set $\{(m/n)\omega(x): 0\leq 
m\leq n, (m/n)\omega(x)\leq f(x)\}$ , but I'm stuck in prove that $\psi_n \leq g$ . Can anyone give me a hint in order to prove this inequality? $\textbf{P.S.: read the comments of mojobask's answer.}$",['measure-theory']
2926509,To draw a graph with only two eccentricties.,"I was trying to convert graphs $C_8$ and $C_9$ into graphs $A$ and $B$ , by adding two extra vertices, such that both $A$ and $B$ contains exactly two vertices with eccentricity three and rest with eccentricity four, and $C_8$ is induced in $A$ and $C_9$ is induced in $B$ . Kindly help me to get the graph ( may be by adding 3 vertices ). Any hint or suggestion will be helpful. Following is my (failed) attempt. Graph $A$ Graph $B$","['graph-theory', 'combinatorics', 'discrete-mathematics']"
2926531,First order non linear ODE with Bernoulli,"I have a problem with this equation: $ y'(x)-xy(x)=-xy^4(x) $ with initial condition $ y(x_{0})=y_{0}$.
I'm arrived to prove that $ y_{0}= (Ce^{-\frac{3}{2}x_{0}^{2}}+1)^{-3} $ but now i can't move on. Moreover, WolframAlpha's solution is next to impossible… Thanks for any help!",['ordinary-differential-equations']
2926589,"Why in the limit ,$[\frac{1}{n},1+\frac{1}{n}]$ is half-open?","Let $A_n=\left[\frac{1}{n},1+\frac{1}{n}\right]$ $\lim_{n\to\infty} A_n=(0,1]$ we are dealing with $\left[0+\frac{1}{n},1+\frac{1}{n}\right]$ Question : Why is the interval closed at one but not at zero? Thanks in advance!","['elementary-set-theory', 'calculus', 'real-analysis']"
2926610,$A^TA$ eigenvalues,"Let $A\in M_{1,3}(\mathbb{R})$ be any $1\times 3$ matrix. Find the eigenvalues of $A^{T}A$ . I understand that this will obviously be a symmetric matrix, but I still can't see the solution. Also, is there any way to see the eigenvalues of symmetric matrices in general? EDIT:
I tried some examples and it turns out that the first two eigenvalues are 0 and 0 and the third one is $$a_{11}^{2}+a_{12}^{2}+a_{13}^{2}.$$ Any way to show this is true in general?","['matrices', 'linear-algebra']"
2926652,Extending Cauchy-Schwarz,"Is it valid to extend Cauchy-Schwarz to the 3 variable case with the following proof: $$
\sum_{i=1}^n(a_ib_i) c_i \leq \sqrt{(\sum_{i=1}^{n}a_i^2b_i^2)(\sum_{i=1}^{n}c_i^2) } \leq \sqrt{\sum_{i=1}^{n}a_i^2} \sqrt{\sum_{i=1}^{n}b_i^2} \sqrt{\sum_{i=1}^{n}c_i^2}
$$ The first inequality simply applies Cauchy-Schwarz to the two variable case. The last inequality assumes $\sum_{i=1}^{n}a_i^2b_i^2\leq (\sum_{i=1}^{n}a_i^2)(\sum_{i=1}^{n}b_i^2)$ . Is this a valid assumption?","['inequality', 'proof-verification', 'linear-algebra']"
2926696,Rotation matrix along a custom axis,"For a certain software that I'm developing, I need to create a rotation matrix for a custom axis, and being almost completely self-taught in math, I am trying to wrap my mind around it, yet failing horribly. This is the simple rotation matrix for rotation along Z axis: $$\begin{pmatrix}
    \cos\theta& -\sin\theta& 0\\
    \sin\theta& \cos\theta&  0\\
    0&    0&     1
\end{pmatrix}$$ Can someone explain how to I modify this matrix for use with a custom axis, which is offset from the Z axis by n degrees (and on the YZ plane)? I went at this problem for 2 days now, and I still can't solve it, no matter how many times I read the wiki article about rotation matrices... Attaching a picture to help you visualize the problem. Thank you in advance.","['matrices', 'coordinate-systems', 'trigonometry', 'rotations']"
2926713,What does oplus symbol ⊕ do for 2 images in Convolution Neural Networks,"So I'm reading this paper on optical flow prediction from two image frames, and I'm having a difficult time finding what this operator does. This paper, and some other ones uses it on the outputs of convolution neural networks. http://openaccess.thecvf.com/content_cvpr_2017/papers/Ranjan_Optical_Flow_Estimation_CVPR_2017_paper.pdf I looked up math symbols and saw that it was an xor operator in logic, but that doesn't make any sense to me in this context. I would also like to know what to call this symbol for future reference.","['matrices', 'image-processing', 'neural-networks']"
2926717,Eigenvalues of the second exterior power of a linear operator,"Let $K$ be a field of characteristic zero and $V=K^n$ . Let $T: V \to V$ be a linear map with eigenvalues $\lambda_1,...,\lambda_n \in K$ , not necessarily all distinct. Let $\wedge^2 V$ be the second exterior power of $V$ and $\wedge^2T: \wedge^2 V \to \wedge^2 V$ is the linear map defined as $\wedge^2T(x\wedge y)=T(x)\wedge T(y),\forall x,y\in V$ and extend it to whole of $\wedge ^2V$ linearly. What are all the eigenvalues of $\wedge^2T$ ? I can easily show that  all $\lambda_i\lambda_j$ s , with $i\ne j$ , are eigenvalues of $\wedge^2T$ ; my question is: are there any other eigenvalues ? EDIT: I would accept an answer even if just for the $K=\mathbb C$ case","['linear-algebra', 'exterior-algebra', 'linear-transformations', 'eigenvalues-eigenvectors']"
2926721,solve this 1st order linear equation,$$(x+3)^2\frac{dy}{dx}=6-12y-4xy=6-y(12+4x)$$ a. Write it in standard form. $$\frac{dy}{dx}+\frac{12+4x}{(x+3)^2}y=\frac6{(x+3)^2}$$ b. What is the integrating factor? $$\frac{12+4x}{(x+3)^2} = \frac14x+\frac34 \implies$$ $$IF=e^{\int{\frac14x+\frac34}}=e^{\frac18x^2+\frac34x}$$ c. Integrate the DE subject to $y(0)=1$ . $$e^{\frac18x^2+\frac34x}\frac{dy}{dx}+ye^{\frac18x^2+\frac34x}(\frac14x+\frac34)=\frac{6e^{\frac18x^2+\frac34x}}{(x+3)^2} \implies$$ $$ye^{\frac18x^2+\frac34x}=\int{\frac{6e^{\frac18x^2+\frac34x}}{(x+3)^2}}+c$$ I have done this problem a few times and now getting kind of stuck. Please check my standard form and integrating factor. Right now if everything else is correct I cannot solve the integral. Any help appreciated.,"['integration', 'ordinary-differential-equations']"
2926749,"Suppose that a bowl contains 100 chips: 30 are labelled 1, 20 are labelled 2, and 50 are labelled 3.","The chips are thoroughly mixed, a chip is drawn, and let $X$ be the number on the chip. 1) Compute $P(X = x)$ for every real number $x$ . 2) Suppose the first chip is replaced, a second chip is drawn, and let $Y$ be the number on the second chip. Compute $P(Y = y)$ for every real number $y$ . 3) Let $W = X + Y$ and compute $P(W = w)$ for every real number $w$ . I have the solution for this: I understand part 1 and 2, but not 3. We define $W = X+Y$ , and so this means that $W(w)=X(w)+Y(w), \forall w\in\mathbb{R^1}$ First my question is, why do we not consider $W(1)$ ? We have defined $X(1)$ and $Y(1)$ , so why not $W(1)$ ? Secondly, and probably the most important question is, how do they get $W(2)=0.12$ ? From the equation $W(2)=X(2)+Y(2)=0.2+0.2 = 0.4$ . But they don't follow the equation. Why? There's two questions I'm asking here.","['probability-theory', 'probability']"
2926782,"""categorical"" proof of a seemingly symmetric statement about Noetherian/Artinian modules","There are two statements which to me seem rather symmetric: Let $A$ be a ring, $M$ an $A$ -module, and $f : M \to M$ . If $M$ is Noetherian and $f$ is surjective, then $f$ is injective. If $M$ is Artinian and $f$ is injective, then $f$ is surjective. The proofs also seem symmetric in a sense: in the first case one constructs the increasing chain of ideals $0 \subset \ker f \subset \ker f^2 \subset \dots$ which is strict when $f$ is surjective but not injective. In the second case one uses the injectivity of $f$ to construct the decreasing chain of ideals $M \supset im \, f \supset im \, f^2 \supset \dots$ which is strict when $f$ is injective but not surjective. However, some symmetry is lost in the assertion of the last part (""which is strict when $f$ is __ but not __""). In the first case I use the fact $\ker f^n = \ker f^{n+1}$ implies that $f$ is injective on $im \, f^n = M$ . In the second case I use the fact that $M \supsetneq im \, f$ would imply that $im \, f^n \supsetneq im \, f^{n+1}$ because injective maps preserve strict inclusions. My question is, is there a way to prove one of the statements in the appropriate category/framework such that the other follows from some kind of formulaic reversal of arrows? This is definitely more of a soft question because I'm not sure what this might mean, but the two situations seem symmetric enough that this might be plausible.","['artinian', 'noetherian', 'category-theory', 'modules', 'abstract-algebra']"
2926811,$f$ is differentiable and satisfies $f(t\vec{x})=t^pf(\vec{x})$ prove $\vec{x} \cdot \nabla f(\vec{x}) = pf(\vec{x})$,"let the three-variable function $f$ be differentiable and satisfy $f(t\vec{x})=t^pf(\vec{x})$ for all $,\vec{x} \in \Bbb{R^3}, t \in \Bbb{R}$ and where $p$ is a constant. How would you prove that $\vec{x} \cdot \nabla f(\vec{x}) = pf(\vec{x})$ I am very confused for this question and have no idea on how to use the information given to reach a conclusion.","['multivariable-calculus', 'calculus', 'chain-rule']"
2926857,"Proving f is onto given if $g \circ f = h \circ f$, then g = h","I realize that there has already been an answer to this problem. But I want to know if my proof was correct. Thank you for your time. Problem Suppose A,B, and C are sets and $f: A \rightarrow B$ Suppose that C has at least two elements, and for all functions $g$ and $h$ from B to C, if $g \circ h = h \circ f$ then $g = h$ . Prove that $f$ is onto. Proof Suppose f is not onto. Then there is $b_1$ such that for all $a \in A$ , $f(a) \neq b_1$ . Suppose $(b_1, c_1) \in g$ and $(b_1, c_2) \in h$ . For the assumption that $g \circ h = h \circ f$ then $g = h$ to be true, $(b_1, c_1) = (b_1, c_2)$ whenever $g \circ f = h \circ f $ . Assume $g \circ f = h \circ f$ . Since $b_1 \notin Ran(f)$ , $(a,c_1) \notin g \circ f$ and $(a,c_2) \notin h \circ f$ . This means that as long as there are at least two elements in C, it is possible that $(b_1, c_2) \neq (b_1, c_2)$ while $g \circ f = h \circ f$ . (Even if $c_1 \neq c_2$ , it can still be true that $g \circ f = h \circ f$ since $c_1$ and $c_2$ are not in the range of $g \circ f$ and $h \circ f$ .) This is a contradiction, hence $f$ is onto.","['proof-writing', 'proof-verification', 'function-and-relation-composition', 'functions', 'elementary-set-theory']"
2926947,A possible generalization of Wilson's theorem using the determinant of a matrix,"I am not sure if the following result is known or an equivalent result is  known. I think, if the result holds then this could be used an elementary number theory exercise. Let $k \in \mathbb{Z} \setminus \{0\}$ be fixed. For $n\in \mathbb{N} $ , let $A_{n,k}=[a^{nk}_{ij}]$ be a $n\times n$ matrix such that $$
a^{nk}_{ij}=
    \begin{cases}
      i & i= j \\
      k & \text{otherwise}
\end{cases}
$$ As a matrix, $A_{n,k}$ has the following form $$
A_{n,k}=\left[ \begin{matrix}
1 &  k  & \ldots & k\\
k  &  2 & \ldots & k\\
\vdots & \vdots & \ddots & \vdots\\
k  &   k       &\ldots & n
\end{matrix} \right]
$$ Conjecture: Let $n\geq |k|$ . If $k$ is odd , then $n$ is  prime number if and only if $$|{\det(A_{n,k})}|\equiv -|{k}| \mod n $$ and if $k$ is even then $n$ is  prime if and only if $$|{\det(A_{n,k})}|\equiv  -k \mod n .$$ It is easy to figure out for $k\geq 1$ , $\det A_{n,k}=(k-1)!(n-k)!$ . Thus, for $k=1$ , you basically get $\det A_{n,1}=(n-1)!$ which is equivalent to Wilson's theorem. For $k>1$ , we get $n$ prime iff $(k-1)!(n-k)!\equiv (-1)^k \mod n.$ I wrote a Matlab code to check and it seems to be true. Does anyone have a counterexample or know how to prove it? The Gauss's generalization of Wilson's theorem seem to be related to this but that only considers(as far as I know) integers less than and  that are co-prime to $n$ . P. S. For $k=-1$ , I calculated the determinant in a non trivial way and got $\det A_{n,-1}={n!\big(n-(1+n)(\mathcal{H}_n-1)\big)}$ where $\mathcal{H}_n$ is the $n$ th harmonic number so the determinant of this matrix seem to relate the $n$ -harmonic number with prime numbers as well.","['number-theory', 'elementary-number-theory', 'prime-numbers']"
2926962,Graph $r=\cot(\theta)\csc(\theta)$.,"So I am stuck on a graphing question in polar coordinates.  I am not sure how to graph the equation even after writing down a few points: $\cot(0)\csc(0) $ DNE $\cot(\dfrac {\pi}{4})\csc(\dfrac {\pi}{4})= \sqrt{2}$ , $\cot(\dfrac {\pi}{2})\csc(\dfrac {\pi}{2})= 0,$ $\cot(\dfrac {3\pi}{4})\csc(\dfrac {3\pi}{4})= -\sqrt{2}$ , $\cot(\pi)\csc(\pi) $ DNE, and so on. Obviously I can just graph it online, but can someone explain the mechanics to how to graph it without using a graphing calculator or desmos?  Thanks!","['multivariable-calculus', 'polar-coordinates']"
2926974,"$P(x,y) = n$ iff $n$ is NOT a perfect square","Does there exist a two variable polynomial $P(X,Y)$ with integer coefficients such that a positive integer $n$ is a perfect square iff there do not exists a tuple $(X,Y)$ of positive integers such that $P(X,Y)= n$ ? Spoiler: There does exists a three variable polynomial $P(X,Y,Z)$ such that an integer $n$ is a perfect square iff there do not exists a tuple $(X,Y,Z)$ of positive integers such that $P(X,Y,Z) = n$ . This extremely tricky construction appeared in USA 2013 IMO TST P8 (see the thread for two constructions). On that thread a certain user raises the question about the nonexistence of such polynomial for two-variable cases, but since that's not answered there I'm asking it here.","['number-theory', 'algebraic-number-theory', 'polynomials']"
2927004,Predicate Is Before The Subject Is This The Correct Translation?,"I'm trying to figure out what the proper translation in predicate logic would be for the example below, I'm confused because the predicate comes before the subject. So i'm wondering if I need to include it into the domain, or make it a separate domain predicate. Example: ""All orange basketballs are round."" I was thinking that I could translate this in one of two ways, which one of these would be correct? ""All orange basketballs are round."" Domain: O(x) - x is Orange Basketballs R(x) - x is Round Answer 1- (∀x)(O(x)-->R(x) OR ""All orange basketballs are round."" Domain: B(x) - x is Basketball O(x) - x is Orange R(x) - x is Round Answer 2- (∀x)(B(x)-->O(x)-->R(x)) I'm under the assumption that answer 1 seems more sound, but any advice is appreciated!","['predicate-logic', 'logic', 'discrete-mathematics', 'logic-translation']"
2927018,Can a non-constant solution of DE intersect an equilibrium solution.,"Consider the autonomous DE; $$\frac{dy}{dx}=\frac{y^3-9y}{e^y}$$ Find the equillibrium solutions and classify each as stable, unstable or semi-stable. Can a non-constant solution of this differential equation intersect an equillibrium solution? Justify why or why not. I am have issues with the second part, but here is all of my work. My Attempt: $$\frac{dy}{dx}=0=\frac{y(y+3)(y-3)}{e^y} \implies$$ Equillibrium solutions are $y=0,-3,3$ From what I get; $$y=-3, \text{unstable}$$ $$y=0, \text{stable}$$ $$y=3, \text{unstable}$$ Through separation of variables I get; $$\frac{e^y}{y^3-9y}dy=dx$$ Assuming I am correct up to here, do I need to integrate to answer the question?(If so how can I do that? It looks like a very challenging integral.) Is it based on the points being stable or unstable? I am not sure how to answer; ""Can a non-constant solution of this differential equation intersect an equillibrium solution? Justify why or why not."" Thanks in advance!",['ordinary-differential-equations']
2927049,Random walk Catalan sum,"Starting at $0$ on the number line, you go right $1$ unit with probability $p$ and left $1$ unit with probability $1-p$ . What's the probability of ever getting to $n>0$ , and how many steps are expected? Let $q_k$ be the probability of ever getting to $k\ge 0$ . $q_k=q_1^k$ since you ever get to $1$ with probability $q_1$ , and the first time you get to $1$ the probability becomes $q_{k-1}$ . $$q_1=pq_0+(1-p)q_2=p+(1-p)q_1^2$$ so $$q_1\in\left\{1,\dfrac{p}{1-p}\right\}$$ If $p\ge\tfrac{1}{2}$ , then $\tfrac{p}{1-p}\ge 1$ , so $q_1=1$ , so $q_n=1$ . If $p<\tfrac{1}{2}$ , I don't know which root to pick. Let $x_k$ be the expected number of steps to get to $k\ge 0$ . By similar reasoning, $x_k=kx_1$ . $$x_1=1+px_0+(1-p)x_2=1+(1-p)2x_1$$ so $x_1=\tfrac{1}{2p-1}$ . If $p\le\tfrac{1}{2}$ , then $$1=(2p-1)x_1\le 0$$ so the expected number of steps is infinite. If $p>\tfrac{1}{2}$ , $x_n=\tfrac{n}{2p-1}$ . We can also sum the probability of getting to $1$ in exactly $2k+1$ steps using Catalan numbers to get $q_1$ , and sum the probability times $2k+1$ to get $x_1$ . The last step must be right and the remaining $2k$ steps can be rearranged in $C_k=\tfrac{1}{k+1}\tbinom{2k}{k}$ ways, so $$q_1=\sum_{k=0}^\infty\dfrac{1}{k+1}\dbinom{2k}{k}p^{k+1}(1-p)^k$$ and $$x_1=\sum_{k=0}^\infty\dfrac{2k+1}{k+1}\dbinom{2k}{k}p^{k+1}(1-p)^k=\sum_{k=0}^\infty\dbinom{2k+1}{k}p^{k+1}(1-p)^k$$ which I have no ideas to compute. How do you compute the sums? Can you show that $q_1<1$ if $p<\tfrac{1}{2}$ without computing the sum? Are there other ways to answer the original question?","['markov-process', 'probability-theory', 'random-walk']"
2927060,Solution to this Differential Equation $f''(x)=f(x)f'(x)$ needed,"I came up with this differential equation and I don't know how to solve it. $$f''(x)=f(x)f'(x)$$ I attempted to solve it several times, but they were all fruitless. Wolfram Alpha says that the solution is $$f(x)=\sqrt{2a} \tan\left({\frac{\sqrt{2a}}{2} \cdot (x+b)}\right),$$ where $a$ and $b$ are constants. How does one get this solution?","['calculus', 'ordinary-differential-equations']"
2927062,Find constant $a$ in way that $\lim_{x\rightarrow -2} \frac{3x^2+ax+a+3}{x^2+x-2}$ has limit,Problem If there exists $a \in \mathbb{R}$ such that: $$ \lim_{x\rightarrow -2} \frac{3x^2+ax+a+3}{x^2+x-2} $$ has limit in $-2$ . If such $a$ exists what is limit in $-2$ ? Attempt to solve My idea was first to try factorize denominator and then find factor of nominator in a way that these two cancel each other. factorizing denominator gives: $$ \lim_{x \rightarrow -2}\frac{3x^2+ax+a+3}{(x-1)(x+2)} $$ Now if it is possible to find solution to $3x^2+ax+a+3=0$ when $x=-2$ $$ 3(-2)^2+a(-2)+(-2)+3=0 $$ $$ 12-2a-2+3=0 $$ $$ 2a=13 \iff a = \frac{13}{2} $$ factorizing nominator gives: $$ 3x^2+\frac{13x}{2}+\frac{19}{2}=0 $$ $$ x= \frac{-\frac{13}{2}\pm \sqrt{(\frac{13}{2})^2-4\cdot 3 \cdot (\frac{19}{2})}}{2\cdot 3} $$ Only problem is this equation is never zero with $x\in \mathbb{R}$ since there is negative value under square root. Now there is contradiction between $a=\frac{13}{2}$ and that equation $3x^2+ax+a+3=0$ when $a=\frac{13}{2}$ and $x=-2$ $$ 3(-2)^2+\frac{13}{2}\cdot (-2)+\frac{13}{2}+3 \neq 0 $$ There is clearly something wrong but i cannot see where this went wrong.,['limits']
2927102,Verify a Matrix Proof Given $A = A^2$,"Problem Given an arbitrary matrix $ A = A^2 $ , prove that $ I - 2A = (I - 2A)^{-1}.$ Attempt $$ I - 2A = (I - 2A)^{-1} $$ $$ (I - 2A)(I - 2A) = (I - 2A)(I - 2A)^{-1} $$ $$ (I - 2A)(I - 2A) = I $$ $$ (I - 2A)^2 = I $$ This is where I'm not sure if the distributive property can be applied to the following equation. Assuming it can be, $$ (I - 2A)^2 = I $$ $$ I^2 - 4A + 4A^2 = I $$ $$ I^2 - 4A + 4A = I $$ $$ I^2 = I $$ $$ I = I $$ $$ [LHS] = [RHS] $$ Notes Is it possible to prove this property is satisfied without using the distributive property as I did above? And what would be an actual example of such a matrix A that satisfies this property? Solution to Proof After reviewing and understanding multiple solutions, including that of @JMoravitz, I've come to the following solution. Consider $ (I - 2A)^{2} $ . We must first show that $ (I - 2A)^{2} = I$ . $$ (I - 2A)^2 = (I - 2A)(I - 2A) $$ $$ (I - 2A)^2 = I^2 - 4A + 4A^2 $$ $$ (I - 2A)^2 = I^2 - 4A + 4A $$ $$ (I - 2A)^2 = I^2 $$ $$ (I - 2A)^2 = I $$ Therefore, $ I - 2A $ is the inverse of $ I - 2A $ , by the definition of matrix inversion. An example of such a matrix that satisfies this property is the $ I_{2 \times 2} $ matrix, which is an idempotent matrix . \begin{bmatrix} 
1 & 0 \\
0 & 1 
\end{bmatrix}","['matrices', 'proof-verification', 'linear-algebra']"
2927134,"Find $I_n=\int_{\gamma} e^zz^n \ dz, \ n\in\mathbb{Z}$","Let $\gamma$ be the unit circle $\{e^{i\theta}:-\pi\leq\theta\leq\pi\}$ . Using the Cauchy integral formula to find, $$I_n=\int_{\gamma} e^zz^n \ dz, \ n\in\mathbb{Z}.$$ Hence evaluate the corresponding real integrals. My attempt: Consider if $n\in\mathbb{Z^+}$ . If $n\in\mathbb{Z^+}$ , then $e^zz^n$ is entire $\implies$ $I_n=0$ by the Cauchy-Goursat theorem. Now consider if $n\in\mathbb{Z^-}$ . If $n\in\mathbb{Z^-}$ , then: \begin{align}
I_n&=\int_{\gamma} \frac{e^z}{z^{|n|}} \ dz \\
&=\int_{\gamma} \frac{e^z}{(z-0)^{(|n|-1)+1}} \ dz 
\end{align} Now, regardless if $n$ is odd or even, $$I_n=\frac{2\pi i}{(|n|-1)!} \ \ \ \ \ \ \text{(Cauchy Integral formula)}.$$ Hence, $$I_n= \begin{cases} 
      0 & n\in\mathbb{Z^+} \\
      \frac{2\pi i}{(|n|-1)!} & n\in\mathbb{Z^-} \\
   \end{cases}
$$ Is this correct? I am unsure about the $n\in\mathbb{Z^-}$ case.","['complex-analysis', 'proof-verification', 'cauchy-integral-formula']"
2927141,"Limits, derivatives, and dividing by zero. [Contradiction in derivative defintions?]","In the limit definition where the denominator is $x - a$ , and we take the limit as $x$ approaches $a$ , we assume that this denominator is not equal to zero. Where (besides the fact that it is necessary to avoid division by zero) does this assumption come from? Why is this not in direct contradiction with the definition of continuity, stating that when a function is continuous the limit as $x$ approaches $a$ will equal $f(a)$ so long as the range around $f(a)$ is not infinite. If $f(x) = x$ , and the limit as $x$ approaches $a$ equals $f(a)$ , why in the limit definitions are we allowed to make the assumption that the limit of term $x$ as $x$ approaches $a$ will not simply lead to $a - a$ , or even more simply the limit as $h$ approaches $0$ will not simply equal $0$ ? How is computing the limits of the $x$ or $h$ term in the derivative formulas different than computing a limit of a linear function?","['indeterminate-forms', 'limits', 'derivatives']"
2927156,What is wrong with this reasoning in with respect to working with differential of z,"I know implicit differentiation. Just playing around with the differential of $z$ I did something like this, which I am sure is wrong somewhere. I want to know where I am wrong. Given a function $z = f(x,y)$ , its differential is \begin{align}
\delta z &= \frac{\partial z}{\partial x} \cdot \delta x + \frac{\partial z}{\partial y} \cdot \delta y
\end{align} Now dividing by $\delta x$ throughout and taking the limit $\delta x$ , $\delta y$ , $\delta z$ tending to zero, I get something like \begin{align}
\frac{\partial z}{\partial x} &= \frac{\partial z}{\partial x} \cdot 1 + \frac{\partial z}{\partial y} \cdot \frac{\partial y}{\partial x}
\end{align} Cancelling the $\frac{\partial z}{\partial x}$ term, I get $\frac{\partial z}{\partial y} \cdot \frac{\partial y}{\partial x} = 0 $ , which is not an identity. My question is, where am I wrong?","['partial-derivative', 'calculus', 'derivatives', 'differential-forms']"
2927170,Are the sample space for one and multiple coin tosses the same?,"I am reading 'All of Statistics by Larry Wasserman'. I am at the first chapter and reading about sample space, sample outcome and events. I am a bit confused with one of the examples the author provided when explaining sample space. Definition of sample space from the book: The sample space $\Omega$ is the set of possible outcomes of an experiment. Here is what I understood: If our experiment is a coin toss, then the outcome of the experiment is either head or tail. So our sample space is $\Omega = \{H, T\}$ Also since sample space is a set it can not contain duplicate values. Then the book goes on and gives us an example: If we toss a coin forever , then the sample space is the infinite set, $\Omega = \{\omega = (\omega_1, \omega_2, \omega_3, . . . , ) : \omega_i ∈ {H, T}\}$ But this contradict with my understanding. Because in the example, both $\omega_1$ and $\omega_2$ can be H, and duplicate values are not allowed in a set . My understanding is that, regardless of how many times we toss the coin(once or forever), the sample space will always contain two values( $\Omega = \{H, T\}$ ) and not an infinite number of values, as the book says - because of the definition of set. Can someone help me clear our my confusion.",['statistics']
2927231,Solving $e^{t/\!\ln(x)}=x$ for $x$,"How do you solve the equation: $e^{t/\!\ln(x)}=x$ for $x$ ? Here $t=1,2,3,\dotsc$ This is what I did: $\ln(e^{t/\!\ln(x)})=\ln(x), $ $t/\!\ln(x)=\ln(x),$ $t=(\ln(x))^2,$ $x=e^\sqrt{t},e^{-\sqrt{t}}.$ Is this correct? What kinds of numbers are the solutions?","['algebra-precalculus', 'transcendental-numbers']"
2927240,Finding the PMF of a Binomial Distribution with $Y=\sqrt{x}$.,"Let $X$ be a random variable with pmf $$ f(x) = \begin{cases} \binom nxp^x (1-p)^{n-x}, & \text{if } x=0,1,2,...,n \\ 0, & \text{elsewhere} \end{cases} $$ Find the pmf of $Y=\sqrt{X}$ . My attempt: $$F(Y) = P(Y\le y) = P(\sqrt{X}\le y) = P(X\le y^2) =\binom n{y^2}p^{y^2} (1-p)^{n-y^2}  $$ Am I on the right path?","['statistics', 'probability-distributions', 'probability']"
2927260,Trying to arrange sums in neat way,I am trying to write the following summations as compactly as possible using summation and enumeration: $$\frac{y_1}{1+y_2+y_3+y_4+y_5}+\frac{y_2}{1+y_3+y_4+y_5}+\frac{y_3}{1+y_4+y_5}+\frac{y_4}{1+y_5} \leq 1$$ $$\frac{y_1+y_2}{1+y_3+y_4+y_5}+\frac{y_2+y_3}{1+y_4+y_5}+\frac{y_3+y_4}{1+y_5} \leq 1$$ $$\frac{y_1+y_2+y_3}{1+y_4+y_5}+\frac{y_2+y_3+y_4}{1+y_5}\leq 1$$ $$\frac {y_1+y_2+y_3+y_4}{1+y_5}\leq 1$$ I wrote it as following: $$\sum_{k=1}^4 \frac {y_k}{1+y_{k+1}+...+y_5} \leq 1$$ $$\sum_{k=1}^3 \frac {y_k+y_{k+1}}{1+y_{k+2}+...+y_5} \leq 1$$ $$ \sum_{k=1}^2 \frac {y_k+y_{k+1}+y_{k+2}}{1+y_{k+3}+...+y_5} \leq 1$$ $$ \frac {\sum_{k=1}^4 y_k}{1+y_5} \leq 1$$ Is there any enumeration to combine the $4$ summations?,"['calculus', 'summation']"
2927270,The pdf of $\tan X$ when $X$ is Uniform,"Let $X$ be a random variable with pdf $$ f(x) = \begin{cases} \frac{1}{\pi}, & \text{if } -\frac{\pi}{2} < x <\frac{\pi}{2} \\ 0, & \text{elsewhere} \end{cases} $$ Find the pdf of $Y = \tan(x)$ . My attempt: $$F_Y(y) = P(Y\le y) = P(\tan(x)\le y) = P(x\le \tan^{-1}(y))=F_X(\tan^{-1}y) = \begin{cases} 0,&\text{if } x<-\frac{\pi}{2} \\  \frac{1}{\pi}{\tan^{-1}y}, & \text{if } -\frac{\pi}{2} \leq x <\frac{\pi}{2} \\ 1, & \text{if } x\geq \frac{\pi}{2} \end{cases}$$ $$ f_Y(y) = \begin{cases} \frac{1}{\pi} \frac{1}{1+x^2}, & \text{if } -\frac{\pi}{2} < x <\frac{\pi}{2} \\ 0, & \text{elsewhere} \end{cases} $$ Am I on the right path?","['statistics', 'probability-distributions', 'probability']"
2927278,"When does integration via u-substitution break down, equal limits of integration?","Edited: changed $\displaystyle\int_{a}^{b}f(g(t))g'(t) \, dt = \int_{g(a)}^{g(b)}f(x) \, dx$ TO $\displaystyle\int_{a}^{b}f(t) \, dt = \int_{f(a)}^{f(b)}u \, \frac{du}{f'(f^{-1}(u))}$ I am wondering about this idea in general, but for concreteness let's say I am attempting to numerically integrate the following: $$
\int_{-\pi}^{\pi} K\left(\sqrt{1-\frac{1}{4}\left(\sqrt{3}\varepsilon+\cos(x)\right)^2}\right)dx=\int_{-\pi}^{\pi} K\left(\alpha\right)dx
$$ Where $K$ is the elliptic integral of the first kind, $-\sqrt{3}<\varepsilon<\sqrt{3}$ is a parameter and for compactness I've defined $\alpha\equiv \sqrt{1-\frac{1}{4}\left(\sqrt{3}\varepsilon+\cos(x)\right)^2}$ . Let's say I want to make a change in variables before trying to crunch this numerically, for whatever reason. Let's also say I have settled on the substitution $u^3=\alpha-1$ . My question is how do I determine the bounds on the new integral? I know (thought I knew?) that in general I just solve $u^3=\alpha-1$ for $x=\pi$ and $x=-\pi$ to get my new bounds. In this case however, that results in both bounds being the same. No problem, I notice the integrand is symmetric in $x$ so I can do twice the integral from $0$ to $\pi$ , which gives me different $u$ -bounds. My question then is when are we allowed to apply: $$
\int_{a}^{b}f(t) \, dt = \int_{f(a)}^{f(b)}u \, \frac{du}{f'(f^{-1}(u))}\quad \text{  with } \ u=f(t) \to dt=\frac{du}{f'(f^{-1}(u))}
$$ if it doesn't work when $u(a)=u(b)$ ? Furthermore, even going from $0$ to $\pi$ I run into the same problem when $\varepsilon=0$ . I could again exploit symmetry to break up the integral, or scrap this idea entirely and try a different substitution, but I am looking for a more general method here or some insight into where this failure comes from. For example, if I let $|\varepsilon|\ll1$ my bounds in $u$ are different, but just barely. I would expect this to fail as well even though the bounds are different. It seems like there must be some need to take into account the shape of $g(t)$ , perhaps $g'(t)\geq0$ or $g'(t)\leq0$ for $a<t<b$ or something like that? Any insight is appreciated, thanks in advance!","['integration', 'definite-integrals', 'bounds-of-integration']"
2927306,Pawn visiting every square on a chessboard exactly once and returning to its right,"A pawn moves across $n\times n$ chesssboard so that in one move it can shift one square to the right, one square upward, or along a diagonal down and left. Can the pawn go through all the squares on the board, visiting each exactly once, and finish its trip on the square to the right of the initial one? I understood this to mean that the following are the three valid moves V for the pawn P: -------------
|   | V |   |
-------------
|   | P | V |
-------------
| V |   |
------------- I proved this situation to be impossible in this way: let the pawn's moves - up,  right, diagonal left - be represented by vectors on the 2D plane respectively: $\hat{A}=(0,1),~\hat{B}=(1,0),~\hat{C}=(-1,-1)$ , then their linear combination $a\hat{A}+b\hat{B}+c\hat{C}=(1,0)$ , which is the required net displacement for the pawn. Thus we see that $a=c$ and $b=c+1$ . Thus the total number of moves is $a+b+c=3c+1$ , which we know should be equal to $n^2-1$ . Thus, $n^2=3c+2$ which we know is impossible for integral $c,n$ . However, our Prof wishes us to do this question via invariant properties instead. I tried to make the  parity of the sum of the coordinates invariant. However, it changes to even on moving right or up, while remains same on moving diagonally. Hence, this property can't be invariant. I also tried to think of distances of point from origin, parity of difference of coordinates, ...without success. What invariant property am I missing? (only hints please)","['invariance', 'chessboard', 'discrete-mathematics']"
2927309,Whether 'min' and 'division' are metric,"Let $(X,d_1)$ and ( $X,d_2)$ be metric spaces. Whether the following are again metrics on $X$ ? a) $d(x,y)=\text{min}\;\{d_1(x,y),d_2(x,y)\}$ b) $h(x,y)=\Big(\frac{d_1}{d_2}\Big)(x,y)$ where $x \neq y$ and $h(x,x)=0$ Actually the answer for the first option is already available in this site. But I mention here is to check my example. Take $X=\Bbb{R}$ and $d_1(x,y)=\vert x -y\vert$ and $d_2(x,y)=\vert x^3-y^3\vert$ and take $x=0, y=1/2 ,z=1$ Now $$d(0,1)=\text{min}\;\{1,1\}=1$$ $$d(0,1/2)=\text{min}\;\{1/2,1/8\}=1/8$$ $$d(1/2,1)=\text{min}\;\{1/2,7/8\}=1/2$$ But $1=d(0,1) \leq d(0,1/2)+d(1/2,1)=1/8+1/2=0.625$ does't hold. Hence $d$ is not a metric! Is this correct? and what about b? Any help?",['real-analysis']
2927345,"Let $f$ be continuous on $[a,b]$, be differentiable on $(a,b)$.","Let $f$ be continuous on $[a,b]$ , be differentiable on $(a,b)$ . If $f$ is strictly increasing in a neighborhood of $a$ .  Can we show that $f'(x)$ is bounded in  a neighborhood of $a$ ? If $f$ is not strictly increasing in a neighborhood of $a$ . Then $f(x)=x \sin 1/x$ shows that it is wrong. However, if we add '' If $f$ is strictly increasing in a neighborhood of $a$ '', is it right then?","['continuity', 'calculus', 'derivatives']"
2927351,Transforming a matrix to diagonal matrix,"Show that the matrix $$A = \begin{bmatrix}a&h\\h&b\end{bmatrix} ,\quad a \ne b$$ is transformed to diagonal matrix $D = P^{-1}AP$ , where $$P = \begin{bmatrix}\cos x& -\sin x\\\sin x& \cos x\end{bmatrix}$$ and $$\tan2x=\frac{2h}{(a-b)}$$ I understand that a $n \times n$ matrix $A$ is diagonalizable if there is a diagonal matrix $D$ such that $A$ is similar to $D$ , that is, if there is an invertible matrix $P$ such that $P^{-1}AP= D$ . Also,  columns of $P$ are $n $ linearly independent eigenvectors of $A$ and the diagonal entries of $D$ are the eigenvalues of $A$ corresponding to the eigenvectors in $P$ in the same order. I am unable to proceed solving the above problem with these leads.","['matrices', 'linear-algebra']"
2927354,"Is the set $\mathcal{A}$ of all matrices whose trace is $0$ nowhere dense in $\mathbb{M}_n(\mathbb{R}),n \ge 2$?","Is the set $\mathcal{A}$ of all matrices whose  trace is $0$ nowhere dense in $\mathbb{M}_n(\mathbb{R}),n \ge 2$ ? My attempt  : my answer is False I take $A  = \begin{bmatrix} 1& n \\0&-1 \end{bmatrix}$ I know that set of all invertible matrix is  dense. You know that  my  given matrix $A$ in invertible,  so I  think statement must be false . Am I right or wrong? Thank you.","['matrices', 'general-topology', 'trace']"
2927380,Is this (conjectural) geometric property intrinsically related to the distribution of Primes?,"Given the series of prime numbers greater than 9, we can organize them in four rows, according to their last digit ( $1,3,7$ or $9$ ). The column in which they are displayed is the ten to which they belong, as illustrated in the following scheme. The blue points represent the primes, whereas the red points represent the integers that are located in the rows $1,3,7,9$ but that are not primes. For instance, in correspondence of the second ten ( $x$ -axis) we find two red points in the rows $1$ and $7$ ( $y$ -axis), because $20+1=21$ and $20+7=27$ are not primes. I have conjectured that given any two red points, it is always possible to find an ellipse with foci in these two points and passing through at least one blue point (a prime number) and at least another red point (a composite number). Here I show some examples: Similarly, it can be conjectured that given any two blue points, it is always possible to find an ellipse with foci in these points and passing through at least one prime and at least one composite. Here follows some examples: My question is: If true, is this property  related to the distribution of the prime numbers? Or it is only due to the particular reference system (lattice) I used to represent them? Thanks for your suggestions and comments, and sorry if the whole problem may be naive.","['euclidean-geometry', 'number-theory', 'integers', 'conic-sections', 'prime-numbers']"
2927384,Why does the Lagrange remainder work for multivariate functions?,"I am familiar with the proof of the Lagrange remainder for single-variable functions (see Theorem $4$ ), but why does this concept carry over to multivariate functions? If $\ f: \mathbb R^k\to \mathbb R$ is $n+1$ times differentiable, then there exists a point $\mathbf c$ , where $c_i$ is between $a_i$ and $x_i$ , such that $$R_n(\mathbf x,\mathbf a)=\sum_{|\alpha|=n+1}\frac {D^\alpha f(\mathbf c)}{\alpha!}(\mathbf x-\mathbf a)^\alpha$$ My attempt: From Wikipedia , $$R_k(\mathbf x,\mathbf a)=\sum_{|\alpha|=k+1}\left(\begin{matrix} k+1 \\ \alpha\end{matrix} \right)\frac{(\mathbf x-\mathbf a)^\alpha }{k!}
\int_0^1 (1-t)^k (D^\alpha f)(\mathbf a+t(\mathbf x-\mathbf a))\,dt\tag1$$ and using Theorem $2$ we get (?) $$\begin{align}
R_k(\mathbf x,\mathbf a)&=\sum_{|\alpha|=k+1}\left(\begin{matrix} k+1 \\ \alpha\end{matrix} \right)\frac{(\mathbf x-\mathbf a)^\alpha }{(k+1)!}
(D^\alpha f)(\mathbf c) \tag2\\
&=\sum_{|\alpha|=k+1}\frac {D^\alpha f(\mathbf c)}{\alpha!}(\mathbf x-\mathbf a)^\alpha
\end{align}$$ However, I don't think that it is possible to go from $(1)$ to $(2)$ because, when taking $(D^\alpha f)(\mathbf a+t(\mathbf x-\mathbf a))$ out of the integral, the value that $t\in(0,1)$ takes may change for each summand.","['multivariable-calculus', 'taylor-expansion']"
2927385,"The prime number theorem over a finite field - Lang's *Algebra*, Chapter V, Exercise 23(b)","This is Exercise 23(b) of Chapter V (Algebraic Extensions) from Lang's Algebra . Let $k$ be finite field with $q$ elements, and let $\pi_q(n)$ be the number of monic irreducible polynomials $p \in k[X]$ of degree $\leq n$ . Prove that $$
\pi_q(m) \sim \frac{q}{q-1} \frac{q^m}{m} \quad \text{for} \quad m \to \infty.
$$ I have tried a few things but I'm not making any progress at all. The hint given in class was to take the logarithmic derivative of the zeta function that was defined in part (a) of the same problem. We defined the zeta function to be $$
Z(t) = (1-t)^{-1} \prod_p (1-t^{\deg p})^{-1}.
$$ I computed this to be equal to the rational function $$
(1-t)^{-1}(1-qt)^{-1}
$$ on the region $|t| < q^{-1}$ . Taking the logarithmic derivative of $Z(t)$ , I get $$
\frac{Z'(t)}{Z(t)} = \frac{1}{1-t} + \frac{q}{1-qt} = \frac{1+q-2qt}{(1-t)(1-qt)} = (1+q-2qt)Z(t).
$$ I am not getting any further ideas at this point in how to use this to describe $\pi_q(n)$ . From Exercise 22 I know that if $\psi(d)$ denotes the number of monic irreducible polynomials of degree $d$ , then the total number of polynomials of degree $n$ , which is $q^n$ , can be expressed as $$
q^n = \sum_{d \mid n} d \psi(d).
$$ Using the Möbius inversion formula, I can deduce that $$
n\psi(n) = \sum_{d \mid n} \mu(d) q^{n/d},
$$ where $\mu$ is the Möbius function. Since $\pi_q(m) = \sum_{k=1}^m \psi(k)$ , I can use the above equation to write $$
\pi_q(m) = \sum_{k=1}^m \frac{1}{k} \sum_{d \mid k} \mu(d) q^{k/d}.
$$ My intuition is that the highest power of $q$ will dominate the sum, so the RHS is approximately $$
\frac{q^m}{m},
$$ so I get roughly what I'm asked to show in the problem. I'm having trouble refining my ideas any further. I have also looked at this question , which asks the same problem, but no answers or comments have been posted there. Lang remarks after stating the problem, ""This is the analogue of the prime number theorem in number theory, but it is essentially trivial in the present case, because the Riemann hypothesis is trivially verified.""
I have tried looking at the proof of the prime number theorem on the internet, but I haven't really understood it; and I certainly can't see how to deduce it from the Riemann hypothesis even in this case. Any help in solving this problem would be appreciated.","['number-theory', 'finite-fields', 'field-theory', 'abstract-algebra', 'zeta-functions']"
2927394,Further simplify $\tan(\alpha+\beta)-\tan(\beta)$,"I came up with the formula \begin{align*}
\tan(\alpha+\beta)-\tan(\beta)
\end{align*} but I keep wondering, whether it's possible to further simplify this, into for example only using the $\tan$ once. I tried using the addition theorems for trigonometry, but these just seem to complicate them further. I already tried something along this: \begin{align*}
r & =\tan(\alpha+\beta)-tan(\beta) \\
& = \frac{\tan\alpha + \tan \beta}{1 - \tan\alpha\tan\beta}-\tan\beta \\
& = \frac{\tan\alpha + \tan \beta}{1 - \tan\alpha\tan\beta}-\frac{(1-\tan\alpha\tan\beta)(\tan\beta)}{1 - \tan\alpha\tan\beta} \\
& = \frac{(\tan\alpha+\tan\beta)-(\tan\beta-\tan\alpha\tan^2\beta)}{1-\tan\alpha\tan\beta} \\
& = \frac{\tan\alpha+\tan\alpha\tan^2\beta}{1-\tan\alpha\tan\beta}
\end{align*} but at this point I am pretty stuck on what to try next.",['trigonometry']
2927535,How many $5$-digit numbers with distinct digits are divisible by 3 (and generalize),"I'm solving a problem which asks me to find how many 5-digit numbers with distinct digits are there which are also divisible by $3$ . I am familiar that there are $9\cdot9\cdot8\cdot7\cdot6=27216$ five-digit numbers with distinct digits. I know that a natural number $n$ is divisible by $3$ iff the digits sum up to a number divisible by $3$ . Now, brute-forcing by a computer algorithm, i found that the result is $20928$ . However, I am interested, if there is a mathematical solution for this. I know how to find amount of numbers divisible by $4$ or $5$ . We just fix some amount on the last two (or last one) digit. But criterion for divisibility by $3$ is very different from those and I have no idea how to start. Eventually, I would like to find a general formula for $n$ -digit numbers. Edit: Equivallently we want to find how many solution does the equation $a+b+c+d+e=3k$ for $a,b,c,d,e\in\{0,1,2,...,9\}$ , $a\neq 0$ also $a,b,c,d,e$ are all distinct and $k\in\mathbb{Z}$ (the highest possible $k$ is in this case $k=11$ , the smallest being $k=5$ ) Edit (2): According to the ideas from the answer. Make $A=\{0,3,6,9\},B=\{1,4,7\}, C=\{2,5,8\}$ . Let's go through the cases that in the number $n$ there are $0,1,2,3,4$ digits from $A$ . i) Suppose none of $A$ is in $n$ . We can't form a number divisible by three. We have to take 5 numbers, that is $3$ from $A$ and $2$ from $B$ or $2$ from $A$ and $3$ from $B$ . None of the expressions $3(3k+1)+2(3k+2)$ and $2(3k+1)+3(3k+2)$ are divisible by three. ii) Let $1$ digit from $A$ be in $n$ . The amount of ways to choose the digit is $5$ . Now we are left to choose $4$ digits. The only possible way is to choose $2$ from $A$ and $2$ from $B$ . The amount of ways to do this is ${3\choose 2}^2=9$ which together gives $5\times 9$ ways which can be permuted and alltogether $5\times 9\times 5!=5400$ possible ways. iii) Let $2$ digits from $A$ be in $n$ . The amount of ways to choose the digit is ${5\choose 2}=10$ . We are left with $3$ digits. Either all of them are from $A$ or all of them are from $B$ . That's $2$ possible ways and all together $20$ possible ways which we permute to obtain $20\times 5!=2400$ possible ways. iv) Let $3$ digits from $A$ be in $n$ . The amount of ways to choose the digits from $A$ is ${5\choose 3}=10$ . We are to choose $2$ digits. We must take exactly one from $B$ and exactly one from $C$ . The amount of ways to do this is ${3\choose 1}^2=9$ . Alltogether $9\times 10$ possible ways which we permute to get $90\cdot5!=10800$ possible ways v) In the last case where all four digits from $A$ are present, there is no way how to make the number divisible by $3$ . Summing this all up gives $5400+2400+10800=18600$ which is less than what my algorithm yielded. We also have to subtract these which begin with $0$ . Can anyone spot the mistake? (If i did any?)","['combinations', 'combinatorics']"
2927536,Extend $f(x )= \frac{|x^2-4|}{x^2-4}$ in a way that $f(x)$ is continuous,"Problem What is domain of $f$ when: $$ f(x)=\frac{|x^2-4|}{x^2-4} $$ Map $f: X \rightarrow Y$ where $X$ is domain (all values $x \in \mathbb{R}$ that are defined by $f$ ) of $f$ and $Y$ is codomain (all values of $f(x)$ ). Is it possible to extend $\forall x \not\in X$ in a way that $f$ is continuous ? Attempt to solve I made plot of $f(x)$ It is quite easily visible that $$ \lim_{x \rightarrow -2} f(x)= \text{""non existent two sided limit""} $$ $$ \lim_{x \rightarrow 2} f(x)=\text{""non existent two sided limit""} $$ I can define $X$ $$ x^2-4 \neq 0 $$ $$ x^2 \neq 4 \iff x \neq \pm 2 $$ which makes $X = \mathbb{R}\setminus \{-2,2\}$ $$ f: \mathbb{R}\setminus \{-2,2\} \rightarrow \{-1,1\} $$ Is it possible to extend $\forall x \not\in X = \{-2,2\}$ in way that $f$ would become continuous ? I would say this is not possible if I can only redefine values for $f(-2)$ and $f(2)$ . In order $f$ to be continuous is to redefine $f(x)$ when $x\in[-2,2]$ or $x\in(-\infty,2]\wedge x\in[2,\infty)$ . Since I could only redefine $f(x)$ when $x\in \{-2,2\}$ this is not possible.","['limits', 'continuity', 'real-analysis']"
2927548,Geometric interpretation of why some matrices don't have eigenvalues,"I don't understand how to geometrically interpret the formula $Av = \lambda v$ where $A$ is a matrix and $v, \lambda$ are the corresponding eigenvectors and eigenvalues. For instance, why does the matrix \begin{bmatrix}
    0       & 1\\
    -1     & 0 
\end{bmatrix} not have any eigenvalues? How can I explain this, geometrically without just saying it's not the case because $\lambda^2+1=0$ doesn't have any real solutions?","['linear-algebra', 'geometry', 'linear-transformations', 'eigenvalues-eigenvectors']"
2927568,Banach limit for Cesaro summable sequences,"I'm solving an exercise from Lax's Functional analysis. The section concerns generalized limits (more particularly, Banach limits), which are obtained by applying the Hahn-Banach theorem to the classical limit functional on $\ell^\infty$ . The exercise wants me to construct a Banach limit which agrees with the Cesaro limit of Cesaro summable sequences, that is, bounded sequences such that ""the arithmetic means of the partial sums converge."" If I understand this final sentence correctly (and wiki seems to confirm this), a sequence $(x_1,x_2,\ldots)$ is Cesaro summable if $$ \lim_{n\to\infty}\frac{1}{n}\sum_{k=1}^n s_k < \infty, \quad\text{where}\quad s_k = \sum_{j=1}^k x_j.  $$ On the other hand, in this post , another definition of Cesaro summability is used, namely there it is required that $$ \lim_{n\to\infty} \frac{1}{n}\sum_{k=1}^n x_k < \infty. $$ My problem is that I would like to dominate the Cesaro limit functional by the (subadditive and positive homogeneous) function $$ p(x) = \limsup_{n\to\infty} x_n, $$ which Lax uses to extend of the classical limit.
This is easily done if we use the latter definition, but I'm not sure how to do it (or if it's even possible) if we use the former definition. My other idea was to use $$ p(x) = \limsup_{n\to\infty} |s_n|, $$ but this is not even well-defined since we are dealing with general bounded sequences. How would you interpret the problem, i.e. which definition of Cesaro summability am I supposed to use? What is a good candidate for $p$ if we use the former definition?","['functional-analysis', 'cesaro-summable']"
2927605,Identifying ODE types for solving by hand and when to use computers instead,"So this questions relates to my specific ODE but also ODEs in general. I am a big fan of solving ODEs by hand, but I also know when to give up and use, say, Mathematica to solve it for me. Having said that, a lot of ODEs including nth-order linear ODEs such as an Euler-Cauchy type equation are often solvable by hand and aren't too lengthy. However, ODEs such as my 2nd-order nonlinear ODE $$xf(x)+af'(x) [f'(x)^2+bf''(x)^2)]^{1/2}=0$$ are not easily identified if DEs aren't your speciality. So my question is this, how does one go about deciding if a DE is solvable by hand, i.e. could I solve the above ODE by hand? If it is solvable by hand, how do we ""know""/""decide"" which method to use if it isn't obvious? Lastly, if we resort to using software and it fails to solve it analytically, does that necessarily imply that only a numerical solution exists? Many thanks for all the help and feedback Ken","['computational-mathematics', 'ordinary-differential-equations']"
2927614,$\sigma$-algebra generated by trace is trace of generated $\sigma$-algebra,"I started studying measure theory by myself using a book by D. Werner. One thing (apparently easy to prove) that I can't work out is the following ( ${\mathcal P}(S)$ denotes the power set of S): ${\bf Definition}$ : Let $S$ be  a set, $E \subset S$ and ${\mathcal E} \subset {\mathcal P}(S)$ . Define \begin{equation}
{\mathcal E}\cap E:=\{A \in {\mathcal P}(E): \exists F \in {\mathcal E} \text{ with } A = F\cap E  \}
\end{equation} to be the trace of ${\mathcal E}$ on $E$ . I could show that ${\mathcal E} \cap E$ is again a $\sigma$ algebra on $E$ , if ${\mathcal E}$ is a $\sigma$ -algebra on S, but for the following I am lost. The claim is: \begin{equation}
\sigma({\mathcal E \cap E}) = \sigma({\mathcal E}) \cap E
\end{equation} Maybe this is really trivial, but right now I have no clue how to start.",['measure-theory']
2927635,Minimum of $\left(\frac{1+\sin^2x}{\sin^2x}\right)^n+\left(\frac{1+\cos^2x}{\cos^2x}\right)^n$,"I would like to find the minimum of $$f(x)=\left(\frac{1+\sin^2x}{\sin^2x}\right)^n+\left(\frac{1+\cos^2x}{\cos^2x}\right)^n,$$ where $n$ is a natural number. I know there is possible by derivate, but $$f'(x)=n \left(\left(\cos ^2(x)+1\right) \sec ^2(x)\right)^{n-1} \left(2 \left(\cos ^2(x)+1\right)\tan (x) \sec ^2(x)-2 \tan (x)\right)+n \left(\left(\sin ^2(x)+1\right) \csc^2(x)\right)^{n-1} \left(2 \cot (x)-2 \left(\sin ^2(x)+1\right) \cot (x) \csc^2(x)\right).$$ I think this is not the best way.",['algebra-precalculus']
2927652,An unorthodox way of converting a recurrent sequence into a non-recurrent one,"The problem is: A sequence is given with: $$ a_1 = 2016, a_{n+1} = \sqrt{a_n^2 + 4 + \frac{1}{a_n^{222}}}$$ Find: $$ (a)  \quad \lim_{n \to \infty}{a_n} \quad (b) \lim_{n \to \infty}{\frac{a_n^2}{n}} \quad (c) \lim_{n \to \infty}{\frac{\sum_{k=1}^{n}{a_k}}{n \sqrt{n}}}$$ The (a) part I was able to solve by proving that the sequence is increasing and not bounded by above. Therefore $$ \lim_{n \to \infty}a_n = +\infty$$ Then for (b) I applied the Stolz theorem: $$ \lim_{n \to \infty}{\frac{a_n^2}{n}} = \lim_{n \to \infty}{\frac{a_{n+1}^2 - a_n^2}{n+1-n}} = \lim_{n \to \infty}{(a_n^2 + 4 + \frac{1}{a_n^{222}} - a_n^2)} = \lim_{n \to \infty}{(4 + \frac{1}{a_n^{222}})} = 4$$ But the (c) part is where I get confused. I've tried applying the Stolz theorem there as well but no luck since the n's don't cancel out like they did in (b). I did have one thing on my mind though but I'm not sure how formally correct it is.
Let's look at the first few sequence members: $$a_1 = 2016, a_2 = \sqrt{2016^2 + 4 + \frac{1}{2016^{222}}}, a_3 = \sqrt{2016^2 + 4 + \frac{1}{2016^{222}}+ 4 + \frac{1}{a_2^{222}}} = \sqrt{2016^2 + 8 + \frac{1}{2016^{222}} + \frac{1}{a_2^{222}}}$$ And now as we keep going we are going to get a new $$ \frac{1}{a_n^{222}}$$ member inside for each n. So that still makes this sequence recursive. But can I simply disregard that part since it obviously always converges to zero, not matter what the value of n is? Or maybe I could say something like $$ \text{Let } \frac{1}{a_n^{222}} = Z(n) \quad \text{ Then } \lim_{n \to \infty}Z(n) = 0 \quad (\forall n)$$ And now I rewrite my sequence as: $$ a_n = \sqrt{(2016)^2 + 4(n-1) + \sum_{i=1}^{n-1}Z(i)} \quad \forall n \geq 2$$ Now let's finally look at the (c) problem: $$\lim_{n \to \infty}{\frac{\sum_{k=1}^{n}{a_k}}{n \sqrt{n}}} = \lim_{n \to \infty}{\frac{a_1 + a_2 + ... +a_n}{n \sqrt{n}}} = \lim_{n \to \infty}{\frac{2016  + \sqrt{2016^2 + 4 + Z(1)} + ... + \sqrt{2016^2 + 4(n-1) + \sum{Z(n})}   }{n \sqrt{n}}}$$ And now I apply Stolz theorem: $$ = \lim_{n \to \infty}{\frac{\sqrt{2016^2 + 4n + \sum{Z(n+1)}}}{(n+1)\sqrt{n+1} - n\sqrt{n}}} = 0  $$ Since the top degree of $n$ is $\frac{1}{2}$ and the bottom one is $ \frac{3}{2}$ . So can anyone tell me whether this solutions is correct? If it isn't, how would you solve it? If it is correct but my process is wrong I'd also like to know where I went wrong. Thanks in advance.","['limits', 'convergence-divergence', 'real-analysis']"
2927701,A question on Voisin's book,"I got stuck at some point in Voisin's book Hodge theory and complex algebraic geometry II . It is on page 58, proof of lemma 2.26: Let $X \subset \mathbb {CP}^{N}$ be a $n$ -dimensional compact complex manifold, and $Y$ be a hyperplane section. Take any general hyperplane section $X_{\infty}$ , set $B= Y\cap X_\infty$ and let $\tilde X$ be blow up of $X$ along the $B$ . Then it claims $$ker(H_{n-1}(Y)\to H_{n-1}(X))=ker(H_{n-1}(Y)\to H_{n-1}(\tilde X-X_\infty))$$ I want to know why this is true?
(On the book it says this followes from corollary 2.23 but I didn't see how) My attempt Since there is a map $$\tilde X-X_\infty \hookrightarrow \tilde X \to X$$ we expect the composition induces the map on cohomology to be injective. Meanwhile, corollary 2.23 says $$H_{n-1}(\tilde X-X_\infty) \to H_{n-1}(\tilde X)$$ is injective. So only need to show the other map is injective. However, this seems not true. For instance, we can take $X=\mathbb{CP^3}$ and $\tilde X$ is blow up $\mathbb {CP^3}$ along a line. Then the blow down map will contract some $S^2$ , hence the induced map on $H_2$ cannot be injective.","['complex-geometry', 'algebraic-geometry', 'algebraic-topology']"
2927738,Most powerful test for discrete uniform,"Let $X$ be a random sample from a discrete distribution with the probability mass function $f(x, \theta) =\frac{1}{\theta} , x=1,2,...,\theta;= 0 \ \text{otherwise}   $ where $\theta \ \text {is either 20 or 40} $ is the unknown parameter. Consider testing $H_{0}: \theta = 40$ against $H_{1}: \theta = 20$ Find the uniformly most powerful level $\alpha=0.1$ test for testing $H_{0}$ vs $H_{1}$ I am new to construction of MP tests, and I was trying to use Neyman Pearson Lemma to construct the test but however the ratio is meaningless here as the support of the two distributions are different in the two hypotheses, so how will I tackle this problem?","['statistical-inference', 'statistics', 'uniform-distribution', 'hypothesis-testing']"
2927754,"What is the reason behind writing the symbol for the unit of area i.e. square meter, as $m^2$?","What I mean to say is as follows: Measuring the area of a surface is determining its ratio to a chosen surface called the unit of area and the chosen unit of area is a square whose side is a unit of length and if the unit of length be a metre, the unit of area will be called a square metre and similarly if the unit of length be a centimetre, the unit of area will be a square centimetre. Then why are we using these symbols like $m^2$ or $cm^2$ to represent the unit of area when they have nothing to do with the whole procedure of measuring the areas? What’s the reason behind such a representation? NOTE - I have asked many people the same thing and some of them gave me REASON 1 while others gave me REASON 2 but none of the reasons sounded to me accurate and I’ve explained why is it  so. REASON 1 : They said, “Area is measured by multiplying the length and the breadth, since both are measured in terms of the unit of length therefore by multiplying the units too we end up with $m^2$ as the units of the area.” Sounds Inaccurate Because : This can't be a reason behind such a representation, since area is not what we get by multiplying the length and the breadth (this is rather an analogue or to be more precise it’s something that we infer from the actual procedure of measuring the areas and that too is wrongly said as it's not the product of length and breadth, it's rather the product of their numerical values ONLY). REASON 2 : They said, “ $m^2$ is just a shorthand or an easy way to write square metre.” Sounds Inaccurate Because : Now this reason has two problems. 
Firstly, if it’s really just a shorthand then why do we chose SO SPECIFIC one and not choosing sq.m. as a shorthand (which sounds more logical and is more shorthand-oriented)? Secondly, in the context of areas, both square metre and $m^2$ represent totally different mathematical ideas (though they sound somewhat similar while pronouncing). Square metre represents the defined unit of area i.e. a square with side length equal to 1 metre WHEREAS $m^2$ represents an arithmetical operation wherein length of $1$ metre has been multiplied with another $1$ metre length (which has nothing to do with calculation of areas). PLEASE explain then what’s the accurate reason behind such a representation?","['dimensional-analysis', 'area', 'geometry']"
