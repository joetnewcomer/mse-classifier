question_id,title,body,tags
764312,$\displaystyle\Big(1-\frac{t}{n}\Big)^n$ is strictly increasing for $n>N$ and $t>0$,"Show that $\exists N\in\mathbb N$ such that, $\displaystyle\Big(1-\frac{t}{n}\Big)^n$ is strictly increasing for $n>N$ $(n\in\mathbb N, t>0)$ Bernoulli Inequality didn't help me I did; $\displaystyle\frac{\Big(1-\frac{t}{n+1}\Big)^{n+1}}{\Big(1-\frac{t}{n}\Big)^n}=\Big(1+\frac{t}{(n+1)(n-t)}\Big)^n\Big(1-\frac{t}{n+1}\Big)$ $\displaystyle\Big(1+\frac{t}{(n+1)(n-t)}\Big)^n\ge\Big(1+\frac{nt}{(n+1)(n-t)}\Big)$$\quad$ Bernoulli-Ineq. but $\displaystyle\Big(1+\frac{nt}{(n+1)(n-t)}\Big)\Big(1-\frac{t}{n+1}\Big)=1+\underbrace{\frac{nt}{(n+1)(n-t)}-\frac{t}{n+1}-\frac{nt^2}{(n+1)^2(n-t)}}_{\text{doesn't seem to be positive}}$ So it didn't work, do you have any ideas, thanks in advance.","['convergence-divergence', 'sequences-and-series']"
764314,Computing $\int_{\gamma} {dz \over (1-z)^3}$,"(a) Let $\gamma$ be the circle of radius ${1 \over 2}$ centered at the
  origin, oriented counter-clockwise. Compute $$ \int_{\gamma} {dz \over (1-z)^3} $$ (b) Same as above, except $\gamma$ is centered at $1$ with radius ${1 \over 2}$. Part (a) attempt: Let $\gamma$ be the counter-clockwise circle of radius ${1 \over 2}$ centered at the origin parameterized by $\gamma(t) = {1 \over 2}e^{-it}$ on $0 \le t \le 2 \pi$. Then we have $$
\int_\gamma {dz \over (1 - z)^3} = \int_{-\gamma} {(-1)^2 dz \over (z-1)^{2+1}} = {2 \pi i \over 2!} f^{(2)}(1) \text{ s.t. }f(z) = 1
$$ and since $f^{(2)}(1) = 0$ we have that our integral is equal to zero. Another way of seeing this integral is equal to $0$ is to observe that since $1$ is outside the circle $-\gamma$, we have that $n(-\gamma, 1) = 0$ by Cauchy's Theorem in a disk (i.e., $-\gamma$ is a closed curve inside an open disk of radius greater than $1/2$ s.t. $f(z)$ is completely analytic on this disk; hence $\int_{-\gamma} {dz \over 1 - z} = 0$ so that the integral above must also equal $0$). Part (b) attempt: Now if we assume that $\gamma$ is centered at $1$ with radius $1/2$, then we have that $n(-\gamma,1) = 1$ so that $-n(\gamma,1) = -1$.  This makes me suspect our integral in question isn't equal to zero. Yet we still seem to have $$
\int_\gamma {dz \over (1 - z)^3} = \int_{-\gamma} {(-1)^2 dz \over (z-1)^{2+1}} = {2 \pi i \over 2!} f^{(2)}(1) \text{ s.t. }f(z) = 1
$$ But it seems like this value is still $0$ since $f^{(2)}(1) = 0$ regardless of where $\gamma$ is centered. This doesn't seem right -- so I think I'm misapplying Cauchy's Integral Formula.  Is this the case?","['complex-analysis', 'analysis']"
764320,Primary descomposition of ideals,"I'd appreciate if someone could help me a bit with this problem. Considering $\mathfrak{p}=(x,y), \mathfrak{q}=(x,z)$ and $\mathfrak{m}=(x,y,z)$ ideals in $k[x,y,z], k$ field. Is $\mathfrak{p}\mathfrak{q}=\mathfrak{p}\cap \mathfrak{q}\cap\mathfrak{m}^2$ a minimal primary descomposition of $\mathfrak{p}\mathfrak{q}$ ? Which component is isolated and which are embbeded? I tell you what I've thought: It's known that $k[x,y,z]/\mathfrak{m}\cong k$ and $k$ field, so the ideal $\mathfrak{m}=(x,y,z)$ is maximal $\Rightarrow $ $\mathfrak{m}^k$ are $\mathfrak{m}$ -primary, so, particulary $\mathfrak{m}^2$ is $\mathfrak{m}$ -primary. $\mathfrak{p}, \mathfrak{q}$ are prime ideals in $k[x,y,z]$ , because it's known that ideals $(x_1,...,x_i), 1\leq i \leq n$ are prime in $k[x_1,...,x_n]$ . Hence $\mathfrak{p}, \mathfrak{q}$ are primary ideals. How could I continue? Thanks.","['commutative-algebra', 'ideals', 'abstract-algebra']"
764324,$\sqrt[\large m]{(x+y)}\over \sqrt[\large k]{(x+y)}$ $=\sqrt[\large m-k]{(x+y)} $?,"Is it always true that: $\sqrt[\large m]{(x+y)}\over \sqrt[\large k]{(x+y)}$ $=\sqrt[\large m-k]{(x+y)} $ where $m,k \in \mathbb N$ ? I tried it with a few numbers and it seems to work every time.","['radicals', 'fractions', 'calculus', 'algebra-precalculus']"
764339,Relationship between circles touching incircle,I am trying to derive a relation between radius of those outer circles and radius of the incircle. Those outer circles are tangent to the incircle and respective sides. I have tried and failed miserably. Any help will be appreciated.,"['geometry', 'triangles', 'circles']"
764342,Showing that $a$ is a removable singularity if $\mathrm{Im}(f(z))$ is bounded from above,"Problem: Suppose $f$ is analytic on the domain $\Omega$ except at the isolated
  singularity $a \in \Omega$.  Show that $a$ is a removable singularity
  if $\mathrm{Im}(f(z))$ is bounded from above. Attempt: We have that $a$ is a removable singularity if and only if we have that $$
\lim_{z\rightarrow a} (z-a)f(z) =0
$$ Since $\mathrm{Im}(f(z))$ is bounded from above, there exists some $M \in \mathbb{R}_{\ge 0}$ s.t. $\mathrm{Im}(f(z)) \le M$ for all $z \in \Omega$. If we could show $$
\mathrm{Im}(f(z)) \le M \implies |f(z)| \le M_1 \text{ for some } M_1 \in \mathbb{R}_{\ge 0}
$$ then we would immediately have (1) since $$
\lim_{z \rightarrow a}|(z-a)f(z)| \le \lim_{z \rightarrow a}|(z-a)|M_1 = 0
$$ Question: Is this the right approach?","['complex-analysis', 'analysis']"
764354,"""nice functions""","I see the statement of ""nice functions"" in textbooks and the authors usually don't need to give the definition of ""nice functions"". For example in a book which I read now the authors write ""Morrey spaces is not separable. A version of Morrey space where it is possible to approximate by ""nice functions"" is vanishing Morrey space."" and don't give the definition of ""nice functions"" anywhere in the book. I wonder in here what is the meaning of ""nice functions"" ? and Is there a fixed definition of ""nice functions"" ?","['functions', 'analysis']"
764365,Evaluating $\lim_{x\to 0}\left(\frac{1}{\sin x} - \frac{1}{\tan x}\right)$,"How to solve this limit
$$
\lim_{x\to 0}\left(\frac{1}{\sin x} - \frac{1}{\tan x}\right)
$$
without using L'Hospital's rule?","['limits-without-lhopital', 'calculus', 'limits']"
764380,A question of rationality,"This problem was asked to me by a friend and I simply have no idea about it. So I have not progressed a single bit. The problem is this: 
If $f :\mathbb{R}\to \mathbb{R}$ is an infinitely differentiable function and $f(x)\in\mathbb{Q} \;\forall x\in\mathbb{Q}$ then must $f'(x)$ be rational for all rational $x$ ?","['functions', 'calculus', 'real-analysis']"
764385,Every vector space has a basis using minimal spanning set.,"We have seen the argument for proving the above statment using Zorn's Lemma by asserting the existence of a maximal linearly independent set which serves a basis. In finite dimensional vector space, a basis is same as a maximal linearly independent and also same as a minimal spanning set. Does the notion of minimal spanning set make sense for arbitrary vector spaces? Moreover, can the statement that every vector space has a basis be proved using the partially ordered set $\Sigma = \lbrace  A \subset V \vert Span(A) =V \rbrace $ with the partial order $A \leq B$ iff $B \subset A $? Can one say intersection of a chain of spanning sets in this poset is also a spanning set?","['modules', 'linear-algebra', 'abstract-algebra']"
764403,"What does $f: 2^{\mathcal{S}}\rightarrow\,\mathbb{R}$ mean?","A function $f: \mathcal{S}^n\rightarrow\,\mathbb{R}$ This is I understand. $x\in\mathrm{dom}\,f$ means that $x$ is a vector of size $n$ where its elements are taken from the set $\mathcal{S}$. e.g., $\mathcal{S}=\{0, 1\}$, $n=3$, so $x$ could be equal $(1, 1, 0)^{\mathrm{T}}$. Am I right? A function $f: 2^{\mathcal{S}}\rightarrow\,\mathbb{R}$ This is I could not understand. What does it mean $x\in\mathrm{dom}\,f$?","['notation', 'elementary-set-theory']"
764405,Is the Neumann series a compact operator?,"Let $X$ be an infinite dimensional Banach space and $A:X\to X$ be a compact operator with the operator norm $\|A\|<1$. Then $I-A$ is invertible and the Neumann series 
$$
S_N = \sum_{k=0}^N A^k
$$
converges in the operator norm to $(I-A)^{-1}$:
$$
\|S_N-(I-A)^{-1}\| \to 0, \ \text{ as } \ N\to \infty
$$
Now I think all $S_N$ are compact operators hence the limit $(I-A)^{-1}$ is also compact. However this cannot be the case because then
$$
I=(I-A)(I-A)^{-1}
$$
would be compact, which is not possible for infinite dimension $X$. What is wrong in my argument?","['operator-theory', 'compact-operators', 'functional-analysis', 'banach-spaces']"
764437,the Gaussian integers are isomorphic to $\mathbb{Z}[x]/(x^2+1)$,"I am trying to prove that $\mathbb{Z}[i]\cong \mathbb{Z}[x]/(x^2+1)$. My initial plan was to use the first isomorphism theorem.  I showed that there is a map $\phi: \mathbb{Z}[x] \rightarrow \mathbb{Z}[i]$, given by $\phi(f)=f(i).$  This map is onto and homorphic.  The part I have a question on is showing that the $ker(\phi) = (x^{2}+1)$. One containment is trivial, $(x^2+1)\subset ker(\phi)$.  To show $ker(\phi)\subset (x^2+1)$, let $f \in ker(\phi)$, then f has either $i$ or $-i$ as a root.  Sot $f=g(x-i)(x+i)=g(x^2+1).$ 
How can I prove that $f \in \mathbb{Z}[x]\rightarrow g \in \mathbb{Z}[x]$?",['abstract-algebra']
764504,If $f$ is twice differentiable then $f^{-1}$ is twice differentiable,"$f:(a,b) \rightarrow (c,d)$ is a bijection and $f$ is differentibale with $f'(x) \neq 0$ for all $x \in (a,b)$, then $f^{-1}$ is also everywhere differentiable. Show that if $f$ is twice differentiable then so is $f^{-1}$ and write down the formula for    $(f^{-1})''$. Now my attempt at this question so far,
I do not know how to show that ths $f$ being twice differentiable implies that $f^{-1}$ is also twice differentiable. But I did attempt the second part of the question By inverse function theorem we know $$(f^{-1})'(f(x))= \dfrac{1}{f'(x)}$$ now differentiating by chain rule this we get $$f'(x)(f^{-1})''(f(x))=\dfrac{-f''(x)}{(f'(x))^{2}}$$ and rearranging; $$(f^{-1})''(f(x))=\dfrac{-f''(x)}{(f'(x))^{3}}$$ Any hints or help for the first part of th question would be much appreciated. REMARK; If somebody could advise me as to how to write fractions where the middle line isn't missing, I have tried \frac and \dfrac but both to no success.","['derivatives', 'real-analysis', 'analysis']"
764563,$p$ divides the sum of the quadratic residues $\bmod p$,"Could you help me at the following exercise? Show that, if $p>3$ is a prime,then $p$ divides the sum of the quadratic residues $\bmod p$.",['number-theory']
764581,Can Bezout's theorem be generalized to non algebraically closed fields?,"The Bezout's theorem says that the intersection of two curves in $\mathbb{P}^2_k$, (counting multiplicity, $k$ is algebraically closed) is equal to the product of their degrees. Can the theorem be generalized to non algebraically closed field? Where the intersection points are replaced by the intersection of schemes?",['algebraic-geometry']
764600,Is the set of convex bodies include in a closed ball compact?,"I consider the set $\mathcal{K}_B$ of convex bodies (convex and compact) which are include inside the unit closed ball of $\mathbb{R}^d$.
I endow this set with the Hausdorff distance.
Is it compact?","['general-topology', 'convex-analysis']"
764604,Approximate $\sqrt{e}$ by hand,I have seen this question many times as an example of provoking creativity. I wonder how many ways there are to approximate $\sqrt{e}$ by hand as accurately as possible. The obvious way I can think of is to use Taylor expansion. Thanks,"['sequences-and-series', 'calculus', 'algebra-precalculus', 'exponential-function', 'recreational-mathematics']"
764631,How does the chain rule work for more than one variable?,"I know that that $$\dfrac{d\sqrt{x}}{dt} = \dfrac{d\sqrt{x}}{dx} \dfrac{dx}{dt}$$ In this equation there you only have 1 variable, namely $x$. But why is the following correct?: $$T = \frac{1}{2} m \left(v_{x}^2 + v_{y}^2 + v_{z}^2 \right)$$ $$\dfrac{dT}{dt} = m \left( v_{x}  \dfrac{dv_{x}}{dt}  + v_{y}  \dfrac{dv_{y}}{dt} + v_{z}  \dfrac{dv_{z}}{dt}                \right)$$ How do you use the chain rule with this 3 variables and what is the mathematical proof for that?",['derivatives']
764643,Finding $\tan B$ and $\tan(A+B)$,"So I know that 
$$
\tan(A+B) = \frac{\tan(A) + \tan(B)}{1 - \tan(A) \tan(B)},
$$
but I don't know how to find $\tan(B)$ for the following problem: If $\tan A = 2/3$ and $\sin B = 5/\sqrt{41}$ and angles $A$ and $B$ are in Quadrant I, find the value of $\tan(A+B)$. Thanks in advance for any help.",['trigonometry']
764655,An application of Pigeon Hole Principle,"Prove that from any set of $11$ natural numbers, there exists 6 numbers such that their sum is divisible by $6$.",['combinatorics']
764661,Is $\sqrt{1-\sin ^2 100^\circ}\cdot \sec 100^\circ = 1$ or $-1$?,"The equation will simplify to \begin{align}
& = \sqrt{\cos^2 100^\circ}\cdot \sec100^\circ \\[8pt]
& = \cos100^\circ\cdot\sec100^\circ \\[8pt]
& = 1
\end{align} But the answer key says that the correct answer is $-1$?",['trigonometry']
764666,Limit of $f'(x) e^{-f(x)}$,"Let $f$ be a real function verifying $f''\geq C>0$, where C is a constant. Do we have : $\lim_{x\to +\infty}f'(x) e^{-f(x)}=0$ ?","['real-analysis', 'limits']"
764672,Counterexamples for Hölder's inequality when $p$ and $q$ are not conjugate.,"Hölder's inequality shows that, when $$ \frac{1}{p} + \frac{1}{q} = 1,$$ and $f\in L^p$ and $g\in L^q$, then $$\Vert f\,g\Vert_1 \le \Vert f \Vert_p \Vert g \Vert_q.$$
Is there an example of this inequality failing for $p=q=1$?  I have been unable to find one in the usual places (analysis texts, and various combinations of search terms online).","['examples-counterexamples', 'normed-spaces', 'real-analysis', 'analysis', 'banach-spaces']"
764677,Irreducible components of $Spec(A) $,"A topological space $X$ is called irreducible if given $A_{1}, A_{2} $ open sets $ \neq \emptyset $ then $A_{1} \cap  A_{2} \neq \emptyset$. The maximal irreducible topological subspaces of $X$ are called irreducible components. Let $A$ be a commutative ring with unit, $X = Spec(A) $ with the Zariski topology. I have to prove that the irreducible components are $\lbrace V(p) : p\subset A \ \text{minimal prime ideal} \rbrace$ where $V(P) =\lbrace q \ \text{prime ideal } \mid p\subset q\rbrace$. Any hint ?","['general-topology', 'ring-theory', 'abstract-algebra', 'commutative-algebra', 'ideals']"
764693,How to characterize rotations in $\mathbb{R}^n$?,"I am studying the performance of an optimizer algorithm to find the
$$
\textrm{argmin}_{x\in \mathbb{R}^n} f(x) \text{ where } f : \mathbb{R}^n \rightarrow \mathbb{R}
$$ I would like to test how the performance changes when I rotate the coordinate system . I need to do this in a systematic manner so that each rotation has ""same probability"". In the $n=2$ case this is relatively easy, since any 2-dimensional rotational matrix can be written as: \begin{pmatrix}
cos(\phi) & sin(-\phi) \\ 
sin(\phi) &  cos(\phi)
\end{pmatrix} The rotation is characterized by a single number $\phi$ so I can sample the $\phi$ uniformly (equidistantly) on $[-\pi; \pi]$. In the $n=3$ case things get more difficult. There are 3 axes by which I can rotate, but the composition of these rotations is not commutative. So I could get biased results when I sample these 3 rotations uniformly. I was thinking about using the Euler's rotation theorem : in 3D space, any two Cartesian coordinate systems with a common origin
  are related by a rotation about some fixed axis This means that the rotations in 3d are characterized by an axis and an angle. So, I could sample all possible axes of some fixed length and all possible rotations around such axis. But this approach is very nontrivial to generalize to arbitrary dimensions . How can I sample n-dimensional rotations uniformly?","['geometry', 'linear-algebra', 'probability-distributions']"
764715,How to find the second derivative?,"I use this article from Wikipedia to build it in my program. How to find the second derivative in $(x_i, y_i)$ point of this cubic interpolation, if I know other $(x_j, y_j)$ points?","['interpolation', 'cubics', 'derivatives']"
764720,What is so special about the Lebesgue-Stieltjes measure,"A measure $\lambda: B(\mathbb{R}^n) \rightarrow  \overline{{\mathbb{R_{\ge 0}}}}$ that is associated with a monotone increasing and right-side continuous function $F$ is called a Lebesgue-Stieltjes measure. But I am wondering, why it is not true that every measure $\lambda: B(\mathbb{R}^n) \rightarrow  \overline{{\mathbb{R_{\ge 0}}}}$ is a Lebesgue-Stieltjes measure?","['lebesgue-integral', 'measure-theory', 'lebesgue-measure', 'real-analysis']"
764748,Is the composition of monotone operators monotone?,"Let $H$ be a real Hilbert space with inner product $\langle\cdot, \cdot \rangle: H \times H \rightarrow \mathbb{R}$, and induced norm $\left\| \cdot \right\|: H \rightarrow \mathbb{R}_{\geq 0}$. Let $A, B : H \rightarrow H$ be monotone operators , that is (for both $A$ and $B$) 
$$ \langle A x - Ay, x-y\rangle \geq 0 \quad \forall x,y \in H$$ I am wondering if $A \circ B$ is monotone as well, that is, if 
$$ \langle A B x - A B y, x-y\rangle \geq 0 \quad \forall x,y \in H$$","['monotone-operator-theory', 'operator-theory', 'real-analysis', 'analysis', 'functional-analysis']"
764783,Extreme value Lagrange multiplier (max or min?),"I am to determine the the range of the volume of a tetrahedron enclosed by the coordinate axes and a tangentplane on the ellipsoid $x^2 + 2y^2 + 3z^2 = 1$. The volume of the tetrahedron can be derived to be given by $$V(x,y,z) = \frac 1{36xyz}.$$ The constraint is $g(x,y,z) = x^2 + 2y^2 + 3z^2 = 1$ and using Lagrange multiplies, we can arrive at the critical points $$ \left( \pm \frac 1{\sqrt 3}, \pm \frac 1{\sqrt 6}, \pm \frac 13 \right) $$ We can calculate $$ V\left(\frac 1{\sqrt 3}, \frac 1{\sqrt 6}, \frac 13\right) = \frac {\sqrt 2}4 $$ But it turns out that this is the smallest volume the tetrahedron can assume but Lagrange's multiplier-method does not give us this information. How can we ascertain that this indeed is a minimum and not a maximum point? Also one thing I wonder is whether there is any boundary to study, to me it appears there is no boundary but perhaps I am mistaken?","['multivariable-calculus', 'lagrange-multiplier']"
764824,"determinant inequality, $AB=BA$, then $ \det(A^2+B^2)\ge \det(2AB) $","$A$ and $B$ are two  $n\times n $ real matrices, $AB=BA$.  Can we conclude that $$ \det \Big(A^2+B^2\Big)\ge \det(2AB) $$ is right? Well, the inequality is interesting. if $A,B$ are upper triangular matrices, it is obvious right. If $AB\ne BA$, $ \det \Big(A^2+B^2\Big)\ge \det(AB+BA) $ is wrong.","['matrices', 'linear-algebra', 'inequality', 'determinant']"
764836,Determinant of a matrix with symmetric positive definite block,"In reviewing linear algebra for an exam, I encountered the following problem: Let $A \in \mathbb{R}^{n\times n}$ be symmetric positive definite. If $x$ is any nonzero vector, show that
  $$ \det\begin{pmatrix} a_{11} & \cdots & a_{1n} & x_1 \\ \vdots & \ddots & \vdots & \vdots \\ a_{n1} & \cdots & a_{nn} & x_n \\ x_1 & \cdots & x_n & 0\end{pmatrix} < 0$$ I solved the problem using this identity : $$ \begin{pmatrix}A& B\\ C& D\end{pmatrix} = \begin{pmatrix}A& 0\\ C& I\end{pmatrix} \begin{pmatrix}I& A^{-1} B\\ 0& D - C A^{-1} B\end{pmatrix} $$ Applied to the case above, the original determinant is equivalent to $\det(A)\det(-x^T A^{-1} x)$; since $A$ is symmetric positive definite, $A^{-1}$ is as well, so $x^T A^{-1} x$ is a positive number, and it follows that the expression is negative. Now to my question: is there another (better) way of solving this problem? My first thought was to approach the problem by induction, but that seemed to be a dead end. I had to look up the above identity which won't be an option for an exam.","['alternative-proof', 'matrices', 'linear-algebra', 'determinant']"
764841,"For what values of $\alpha,\beta$ is $x^{\alpha}\sin{x^\beta}\in L^1((0,1])$?","Let $E=(0,1]$. For every $\alpha,\beta\in\mathbb{R}$, let $f(x)=x^{\alpha}\sin{x^\beta}$. For what values of $\alpha,\beta$ is $f\in L^1(E)$? I think I know the answer: when $\alpha>-1$ or $\alpha+\beta>-1$. I don't know how to prove that $f$ is not integrable when neither of these inequalities hold. First suppose that $\alpha>-1$. Since $\left|\sin{x^\beta}\right|\leq 1$, we have that $\left|x^{\alpha}\sin{x^\beta}\right|\leq x^{\alpha}$. By the monotonicity of Lebesgue integration, the monotone convergence theorem, and the fact that the Lebesgue and Riemann integral of continuous functions over closed intervals are equal, we can see:
$$ \int_E\left|f(x)\right|\,d\lambda\leq\int_E\left|x^\alpha\right|\,d\lambda=\int_Ex^\alpha\,d\lambda=\lim_{n\to\infty}\int_{\frac{1}{n}}^1x^\alpha\,d\lambda=\lim_{n\to\infty}\int_{\frac{1}{n}}^1x^\alpha\,dx=\lim_{n\to\infty}\frac{1^{\alpha+1}-n^{-\alpha-1}}{\alpha+1}=\frac{1}{\alpha+1}$$ Now suppose that $\alpha+\beta>-1$. So $\underset{n\to\infty}{\lim}n^{-\alpha-\beta-1}=0$. Note that $\left|\sin{u}\right|\leq u$ for all $u\geq 0$. Thus, for $x>0$ we have that $\left|\sin{x^\beta}\right|\leq x^\beta$ and so $\left| f(x)\right|\leq x^{\alpha+\beta}$ for $x\in E$. Thus, we have:
$$\int_E\left|f\right|\,d\lambda\leq\int_E\left|x^{\alpha+\beta}\right|\,d\lambda=\int_Ex^{\alpha+\beta}=\lim_{n\to\infty}\int_{\frac{1}{n}}^1x^{\alpha+\beta}\,d\lambda=\lim_{n\to\infty}\int_{\frac{1}{n}}^1x^{\alpha+\beta}\,dx=\lim_{n\to\infty}\frac{1^{\alpha+\beta+1}-n^{-\alpha-\beta-1}}{\alpha+\beta+1}=\frac{1}{\alpha+\beta+1}.$$ That's all I have so far. If anyone can help me show that $f$ is not integrable when $\alpha\leq -1$ and $\alpha+\beta\leq -1$, I would be grateful. Or perhaps I am wrong and these are not the right constraints.","['lebesgue-integral', 'real-analysis']"
764875,Kernel of a morphism of regular rings.,"Let $k$ be a field and $f:  A \rightarrow B$ be a surjective ring morphism between smooth Noetherian $k$-algebras.  By smooth I mean that the module of Kahler Differentials $\Omega_{A|k}$ is a projective $A$-module (likewise with B). Why must each $Ker(f_{f^{-1}[\mathfrak{m}]})$ be generated by a regular sequence, where $\mathfrak{m}$ is a maximal ideal in B? The argument seems to boil down to two things: 1) Notherian + Smooth $\Rightarrow$ Regular 
(Without deviating from my definition os smoothness, I don't see how this follows) More importantly tho 2) The kernel of a morphism between regular local rings is generated by a regular sequence. (I've looked at some theory on this but it always seems to take a big detour and passes through more general objects like (CIs) which I am neither comfortable with, nor need.  My main issue would be to kind a simple, possibly bland proof of this fact) . Thanks in advance! :)","['modules', 'ring-theory', 'algebraic-geometry', 'abstract-algebra']"
764897,What does this $\asymp$ symbol mean? (subject: analytic number theory),"I'm reading a survey article by Andrew Granville on analytic number theory. On page 22 of the paper, there appears a strange looking symbol, undefined.  I've circled it in red in the screenshot below. Since it's not defined in the paper, I'm assuming it must be standard notation. From the context, I'm assuming it means something like ""as compared to"", or ""with reference to"", but that's just a guess. Can anyone identify the symbol, even better explain what it means and/or provide a reference?  Is there a name to speak the symbol? Thanks in advance.","['notation', 'asymptotics', 'analytic-number-theory', 'analysis']"
764928,Explain how the following is equal to $2\cos x$.,"The question was Prove $$\frac{1+\sin2x+\cos2x}{\cos x+\sin x}=2\cos x$$ I simplified it using several trigonometric identities, what I got is this ""$\dfrac{2\cos^2 x + 2\cos x \sin x}{\cos x + \sin x}$"" Please explain how can I get this to be to equal to $2\cos x $?","['trigonometry', 'trigonometric-series']"
764936,Lines covering points on napkin,"Suppose we place a $100\times 100$ napkin on an infinite lattice plane. What is the minimum number of lines that can always cover all the lattice points lying inside or on the border of the napkin, no matter the orientation of the napkin? Source: St. Petersburg Olympiad 2014","['polynomials', 'contest-math', 'combinatorics']"
764961,$L^{2}$ integrability implies $L^{1}$ integrability on sets of finite measure.,"Let $X$ be a measurable space with $m(X) < +\infty$. I think it's clear that if $f \in L^{2}(X)$ implies that $f \in L^{1}(X)$. But when $m(X) = +\infty$, the suppose $f(x) = \frac{1}{1+|x|}$ is supposed to serve as an example of an $L^{2}$ function but not $L^{1}$. How would I go about seeing this? I have seen a demonstration of this, but I didn't really get it. It was based on a proof of the first result, which I didn't follow. It went like this: Let $A = \{x: |f(x)| \leq 1\}$ and $B = \{x : |f(x)| > 1\}$. Then we can write $$|f| \leq \chi_{A} + \chi_{B} \cdot |f|^{2}$$ Which somehow proves the first result. I can prove the first part on my own, but I just don't get why you bound $|f|$ in that particular way. What justifies it? EDIT: The main part that I don't see is how $f \in L^{2}$, which is shown by writing $|f|^{2} \leq \chi_{[-1,1]} + \chi_{[1, \infty)} \cdot \frac{1}{x^{2}}$, but as in the first case, I don't see where this comes from.","['measure-theory', 'real-analysis']"
764973,"$y''+2y'+5y=0$, initial value problem with Laplace transform?","here is the question: $$
{\rm y}''\left(t\right) + 2\,{\rm y}'\left(t\right) + 5\,{\rm y}\left(t\right)
=
0;
\qquad\qquad
{\rm y}\left(0\right) = 2\,,\quad {\rm y}'\left(0\right) = -1.
$$ $\mathcal{L} (y''(t)) = s^2y(s) -s y(0) -y'(0)$ $\mathcal{L} (+2y'(t)) = 2(sy(s) -y(0))$ $\mathcal{L} (5y(t)) = 5y(s)$ I find that $y(t)=\dfrac{2s+3}{s^{2}+2s+5}$ It is irreducible, so I write the transform as a function of $\varepsilon = s + 1$. $y(t)=\dfrac{2\varepsilon+1}{\varepsilon^2+4}$ I apply fraction by parts then use laplace transform table and find the result: $y(t)=e^{-t} (2\cos{2t}+\sin{2t})$, but the result has $\frac{1}{2}$ before $\sin{2t}$. What am I missing here? Where does the $\frac{1}{2}$ come from?","['ordinary-differential-equations', 'laplace-transform']"
765020,What's the densitiy of the product of two independent Gaussian random variables?,"Suppose that $X,Y$ are two scalar independent normal random variables, $X \sim N(\mu_X,\sigma_X^2)$, $Y \sim N(\mu_Y,\sigma_Y^2)$. I'm particularly interested about the case where we don't assume $\mu_X = \mu_Y = 0$. I'm interested in the random variable $XY$. What can be said about its PDF? There's an existing question where an answer explains that $XY$ is the difference of two chi-squared variables . For the zero-mean case, we know that the PDF is the normal product distribution . Is there a non-zero-mean generalization of this? I know that there's a 1970 SIAM paper by Springer and Thompson , but I don't have access to this. Is the part which is relevant for my question publicly available somewhere? To add to my confusion, I found a note by Bromiley , where it is argued that the product of two normal independent random variables is a normal variable again - which I thought was not the case. The argument in the linked document goes like this: Products of gaussian PDFs are gaussian. The PDF of a product of two independent RVs is their convolution. The Fourier transform of a convolution is the product of the fourier transforms. Gaussians are mapped to gaussians under the (inverse) Fourier transform. Am I misunderstanding something? Is there something wrong with the proof?","['statistics', 'probability-distributions']"
765044,Challenge: Demonstrate a Contradiction in Leibniz' differential notation,"I want to know if the Leibniz differential notation actually leads to contradictions - I am starting to think it does not. And just to eliminate the most commonly showcased 'difficulty': For the level curve $f(x,y)=0$ in the plane we have $$\frac{dy}{dx}=-\frac{\dfrac{\partial f}{\partial x}}{\dfrac{\partial f}{\partial y}}$$ If we were to ""cancel"" the differentials we would incorrectly derive $\frac{dy}{dx}=-\frac{dy}{dx}$. Why does this not work? Simple: The ""$\partial f$"" in the numerator is a response to the change in $x$, whereas the ""$\partial f$"" in the denominator is a response to the change in $y$. They are different numbers, and so cannot be cancelled. Related: consult the answer to this previous question. The other part has been moved to a new post here .","['notation', 'calculus', 'math-history']"
765054,Are there any constants other than $\pi$ that give rational or known irrational values for $\cos(\theta)$?,For example: $\cos(\frac{\pi}{3}) = \frac{1}{2}$ $\cos(\frac{\pi}{4}) = \frac{\sqrt{2}}{2}$ Is there any other constant $\theta$ such that $\cos(k\theta)$ is rational or a known irrational where $k$ is not $0$ or something trivial like $\frac{\pi}{\theta}$?,['trigonometry']
765064,Squares modulo 2^n,"How many squares are there modulo $2^n$? If we would deal with $p^n$, where p an odd prime, then we could use Hensel's Lemma, which clearly doesn't work with $2^n$.","['number-theory', 'elementary-number-theory', 'analytic-number-theory', 'algebraic-number-theory', 'prime-numbers']"
765090,Unitary Farey Sequence Matrices,"Take the Farey sequence $\mathcal{F}_n$ with values $a_m\in \mathcal{F}_n$ and put them into a vector 
$$
\vec v_k=\frac1{\sqrt{|\mathcal{F}_n|}}\biggr(\exp(2\pi i k a_m)\biggr)_m
$$
The dimension of this vector is $|\mathcal{F}_n| = 1 + \sum_{m=1}^n \varphi(m). $
Let's call $k$ a root when $\vec v_k \cdot \vec v_0=0$. I tried for quite a while to get a set $OV$ of $v_k$, where $k$ can be $0$, positive or negative, such that the collection of vectors $\vec v_k$ creates a unitary matrix. 
The largest sets I found, have six elements, e.g. $n=40$: $OV=\{0, 1,-179,180,-29748,29749 \}$. I also found that the roots for even $n$ fall into certain categories. For $n=40$ we get: $2^23^25p$, e.g. $\color{red}{2^23\cdot 5=180}$ $2^23\cdot 37^np$, e.g. $\color{blue}{2^23\cdot 37\cdot 67=29748}$ $2^33\cdot 29^np$, e.g. $\color{green}{2^33\cdot 29\cdot 43=29928}$ $2^43\cdot 29^np$ $2^33\cdot 7^k23^np$, where $n,k>0$ and $p$ may be any prime larger than $40$. Roots of odd $n$ are products of primes larger than $40$. While analyzing this special set for $n=40$, I found that at least, either the sum or the difference of any pair would give rise to another root: $\vec v_0 \cdot \vec v_{(-\color{blue}{29748}-\color{red}{180})}=\vec v_0 \cdot \vec v_{-\color{green}{29928}}=0$, whereas $\vec v_0 \cdot \vec v_{(-29748+180)}\neq 0$. $\vec v_0 \cdot \vec v_{(29749\pm 180)}=0$, where $29749\pm 180$ is either prime or a product of primes larger than $40$. There seems to be kind of ""closed under addition/subtraction""-relation among the roots. Is this an equivalence class? My questions: Are these matrices already known? How/where are they used? How to create them? What about these closedness relations?","['matrices', 'equivalence-relations', 'farey-sequences', 'reference-request']"
765101,Almost perfect numbers,A positive integer $n$ is called almost perfect if the sum of its divisors smaller than $n$ is $n-1$. What are all almost perfect numbers $n$ such that some power $n^k$ is also almost perfect for at least one $k>1$? Source: St. Petersburg Olympiad 2014,"['elementary-number-theory', 'contest-math', 'number-theory']"
765106,How do I begin proving this binomial coefficient identity: ${n\choose 0} - {n\choose 1} + {n\choose 2} - {n\choose 3} + \dots = 0$,"This is a homework question. I'm asked to prove the identity: $${n\choose 0} - {n\choose 1} + {n\choose 2} - {n\choose 3} + \dots = 0$$ (The sum ends with ${n\choose n} = 1$, with the sign of the last term depending on the parity of n.) I recognize that the sequence:
 $${n\choose 0}, {n\choose 1}, {n\choose 2}, {n\choose 3}$$ corresponds to the binomial coefficients. That is, if I choose $n = 5$, I get the sequence $1, 5, 10, 10, 5, 1$. Working this out (or just looking at Pascal's triangle), it's obvious that this theorem is true. It looks like the triangle / the binomial coefficients are ""symmetric"", and so if you add one and subtract one and keep going, it's evident they will cancel out to be zero. But how do I prove this? Is there a set way? Are there multiple methods for proving this? How should I get started, or what are some names of proving methods I should look into to begin?","['binomial-coefficients', 'summation', 'proof-writing', 'combinatorics']"
765144,Is it possible to diagonalize a singular matrix?,"I have not seen anywhere written that it is impossible, but it seems impossible, so I want to check if I missed something. According to a theorem, an $n\times n$ matrix is diagonalizable if it has $n$ independent eigenvectors. Let's say, the matrix has $1$ row with only zeros (worst singular case). As it has one row with only zeros, it will zero out the corresponding row of any vector it is multiplied by. That means, the corresponding rows of its eigenvectors have to be zero. And if one of the rows is fixed, there cannot be n independent eigenvectors. Am I correct? Did I miss anything?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors', 'diagonalization']"
765198,Some users are mind bogglingly skilled at integration. How did they get there?,"Looking through old problems, it is not difficult to see that some users are beyond incredible at computing integrals. It only took a couple seconds to dig up an example like this . Especially in a world where most scientists compute their integrals numerically, I find it astounding that people exist that can solve these problems analytically. Sometimes it is a truly bizarre contour, some examples use auxiliary functions and differentiation under the integral sign in a way that feels more like integration by wizardry. Some of these users seem to have mastered an incredibly large number of special functions to a level of fluency that is almost unimaginable to me. Manipulations involving the error function almost looks like the work of an infant compared to some of these seemingly casual manipulations involving the Airy function, Barnes G function, the Legendre chi function and many more. Every time I read a post by them, it turns into an exercise in reading about yet another special function I have never heard of. My question is what sort of material do you have to study, or what kind of area do you have to work in to get so good? To me, it doesn't seem as obvious as saying something like, ""oh, they know this material because they are a topologist"".","['definite-integrals', 'integration', 'soft-question']"
765211,Why do folded concentric circles and rectangles form a hyperbolic paraboloid?,"Here is a ""self-forming"" origami that I made from folding concentric circles - it would also happen if I folded concentric rectangles. How can the fold shapes such a saddle-like geometry?","['origami', 'geometry', 'manifolds', 'physics']"
765216,Question on Intersection Theory of Effective Divisors,"I am reading Section 1.1C of Lazarsfeld ""Positivity in Algebraic Geometry I"" and I need help understanding one line. On Page 17, Remark 1.1.13(iii), he says the following: If $D_1,..., D_n$ are effective (Cartier) divisors that meet transversly at smooth points of $X$ (where $X$ is some irreducible complete variety), then $$(D_1 \cdot ... \cdot D_n) = \#\{D_1 \cap \cdots \cap D_n\}$$ I am trying to understand this statement. I guess first I need to understand the intersection of let's say, $2$ Cartier divisors, $D_1$ and $D_2$...and then go from there to $n$ divisors. Can someone please explain to me how the statement bolded above applies to two cartier divisors $D_1=\{(U_i,f_i)\}$ and $D_2 = \{(V_j, g_j)\}$?","['intersection-theory', 'algebraic-geometry', 'complex-geometry']"
765316,What is wrong with this exercise in do Carmo's Differential Geometry?,"This is an exercise in do Carmo's Differential Geometry: Let $\alpha : I \longrightarrow S$ be a curve parametrized by arc length $s$, with nonzero curvature. Consider the parametrized surface \begin{align}\textbf{x}(s,v)=\alpha(s)+vb(s), & s \in I, -\epsilon < v < \epsilon, \epsilon > 0\end{align}
  where $b$ is the binormal vector of $\alpha$. Prove that if $\epsilon$ is small, $\textbf{x}(I \times (-\epsilon, \epsilon)) = S$ is a regular surface over which $\alpha(I)$ is a geodesic ( thus, every curve is a geodesic on the surface generated by its binormals ). An errata online says that the first conclusion of this exercise is wrong: p. 262. Exercise 17: The first conclusion is false: It can happen that for all $\epsilon > 0$, the set $\textbf{x}(I \times (-\epsilon,\epsilon))$ fails to be a regular surface. (Consider a curve $\alpha : (0,1) \rightarrow \mathbb{R}^3$ such that $\alpha(s)$ approaches $(0,0,0)$ from the same direction as $s \rightarrow 0^+$ or $s \rightarrow 1^-$, and such that the part of $\alpha$ near $s=0$ is contained in a plane, and the part of $\alpha$ near $s=1$ is contained in a different plane.) I don't quite understand the counterexample in the errata. Can somebody help to explicitly construct the curve $\alpha$?",['differential-geometry']
765361,Tensor notation (practicing),"I'm praticing tensor notation, and I want to prove this way that given vectors $A,B,C,D$ then $(A \times B) \times (C \times D) = \det(A,C,D)B - \det(B,C,D)A$, where $\det$ means the triple product. I'm getting something different here, can someone check? Taking coordinates: $ ((A \times B) \times (C \times D))_i 
= \epsilon_{ijk} (A \times B)_j (C \times D)_k
= \epsilon_{ijk} \epsilon_{jlm} A_l B_m \epsilon_{kno} C_n D_o $ $= \epsilon_{ijk} \epsilon_{kno} \epsilon_{jlm} A_l B_m C_n D_o$ Here I used this nice little identity: $ = (\delta_{in} \delta_{jo} - \delta_{io} \delta_{jn}) \epsilon_{jlm} A_l B_m C_n D_o $ $= [\delta_{in} \delta_{jo} \epsilon_{jlm} A_l B_m C_n D_o] - [\delta_{io} \delta_{jn} \epsilon_{jlm} A_l B_m C_n D_o]$ Now I thought the following: since $i$ is a free index $\delta_{in}$ exchanges $n$ for $i$ in the first part, and $\delta_{io}$ exchanges $o$ for $i$ in the second part. Then: $= [\delta_{jo} \epsilon_{jlm} A_l B_m C_i D_o] - [\delta_{jn} \epsilon_{jlm} A_l B_m C_n D_i]$ Now, $\delta_{jo}$ and $\delta_{jn}$ make the double sum collapse into a single one, saving only the terms on which $j = o$ in the first part and $j = n$ on the second. I'll keep the index $j$. Then: $= \epsilon_{jlm} A_l B_m C_i D_j - \epsilon_{jlm} A_l B_m C_j D_i$ Now we see the definition of the cross products $= (A \times B)_j D_j C_i - (A \times B)_j C_j D_i$ $= \det(A,B,D) C_i - \det(A,B,C) D_i$ Where is my error?","['analytic-geometry', 'tensors', 'differential-geometry']"
765370,The derivative of $x^TAx$ w.r.t $t$,"Suppose $P = x^TAx$ How to find $\frac{dP}{dt}$? if $x' = Bx$   , where $B$ has the same dimension as $A$. How to find the final answer? my answer is: $$\frac{dP}{dt} = 2[(A+A^T)x]x' = 2[(A+A^T)x]Bx$$ However, it seems that $Bx$ is a $(n\times 1)$ vector and $x$ is also an vector so we cannot find the final answer. Is it true?","['matrices', 'derivatives']"
765455,How was this sequence discovered?,"Let $N$ be a positive integer and consider the following rational sequence for $n \ge 0$: $$
a_{n+1} = \frac{N a_n + N}{a_n + N},
a_0 \in \Bbb{Q}.
$$ If $-\sqrt{N} < a_0 < \sqrt{N}$, then $\{a_n\}$ is a monotone increasing rational sequence and converges to $\sqrt{N}$.
If $\sqrt{N} < a_0$, then $\{a_n\}$ is a monotone decreasing rational sequence and converges to $\sqrt{N}$. By using this sequence, we can easily prove that both $\max\{r |r \lt \sqrt{N}, r \in \Bbb{Q}\}$ and $\min\{r |r \gt \sqrt{N}, r \in \Bbb{Q}\}$ do not exist if N is not a square integer. This sequence is nice. How was this sequence discovered? Bill Trok, thank you very much. I cannot prove the fact about your sequence but thanks to your answer, I know that the above sequence is not special and I could find another similar sequence.
$$
a_{n+1} = \frac{-4 N^3 -4 N^2 -4 N}{(a_n + 2 N)^2 + 3 N} + N + 1,
a_0 \in \Bbb{Q}.
$$ If $-\sqrt{N} < a_0 < \sqrt{N}$, then $\{a_n\}$ is a monotone increasing rational sequence and converges to $\sqrt{N}$.
If $\sqrt{N} < a_0$, then $\{a_n\}$ is a monotone decreasing rational sequence and converges to $\sqrt{N}$. http://wolfr.am/1hoilfq","['sequences-and-series', 'calculus', 'analysis']"
765510,Harmonic conjugates on annulus slit,"Let $D$ be an annulus slit with $$D= \{a<|z|< b \}$$ 
excluding $(-b,-a)$. Show that any harmonic function on $D$ has a harmonic conjugate on $D$. The hint says to fix $c$ between $a$ and $b$ and then do a line integral along a radius and then along a circular arc. I did this, but I'm not sure why this proves the existence of a harmonic conjugate. I just integrated the differential $dv$ and used the Cauchy Riemann equations to get a line integral in terms of a harmonic function $u$. But what have I shown?","['harmonic-functions', 'complex-analysis']"
765537,What is a reducible algebra?,"In my matrix analysis book, a set of complex matrices is said to be an ""algebra"" if 1)it is a subspace, 2)whenever A and B are members, so is AB. Then it uses the terms reducible and irreducible algebra, without defining them. What are the definitions? EDIT: It's being used within the context of proving Burnside's theorem on matrix algebras... which is written here as... A set S of nxn complex matrices is irreducible if and only if it is the set of all nxn complex matrices.","['matrices', 'linear-algebra']"
765547,ODE using Weierstrass's P function,"I need a hint for the following problem. ""Solve $(x')^2=x^3 − 3x^2 − 4x + 12$ with the initial with initial condition $x(0)=3$"". I know I should somehow use Weierstrass's $P$ function because it satisfies the equation $(P')^2=4P^3+aP+b$. I tried first to obtain the lattice corresponding to the elliptic curve above but without and success.","['ordinary-differential-equations', 'elliptic-curves']"
765558,Equivalence relation to make a group commutative,"A while ago I was wondering if there is a ""natural"" way to make a commutative group out of an arbitrary one.  I played with the idea a bit and here is what I came up with. Define a binary relation $\sim$ on a group $G$ such that $x \sim y$ if $\exists a, b \in G$ such that $ab=x$ and $ba=y$. It's fairly easy to show this is an equivalence relation: Reflexivity: $xe = ex = x$, so $x\sim x$. Symmetry: obvious. Transitivity: Suppose $x \sim y$ and $y \sim z$.  Then $\exists a,b,c,d$ such that $ab=x$, $ba=cd=y$, and $dc=z$.  Let $e = ad^{-1}$ and $f=db$.  Then $ef = ad^{-1}db = ab = x$, and $fe = dbad^{-1} = dyd^{-1} = dcdd^{-1} = dc = z$.  So $x \sim z$. $\square$ Question: Let $[x]$ denote the equivalence class of $G/\mathord\sim$ containing $x$.  Suppose we let $[x][y] = [xy]$.  Is this operation well-defined? If so, then $G/\mathord\sim$ is clearly a group under this operation.  Furthermore, it is commutative, since $[x][y] = [xy] = [yx] = [y][x]$ (where the middle equality is by definition of $\sim$).","['group-theory', 'abelian-groups']"
765571,Line Spectra in Hydrogen atom,"Suppose you have a collection of large amount of Hydrogen atoms in $n$th state($n-1$th excited state). They have to go to their ground state($n$=1). Going from $n_1$ to $n_2$ makes a unique spectral line. An atom cannot raise its $n$, it can only decrease it.What is the minimum number of $H$ atoms needed to view all spectral lines? Although changing of $n$ is random, we may assume that we are lucky .e.g. for $n=3$ : We have to see $$3 \to 1,2\to 1, 3\to 2$$
Minimum number of atoms is $2$. One will go to $3 \to 2 \to 1$ and other will $3\to 1$. When $n=4$, We have to see $4\to 3,3\to 2,2\to 1,4\to 1, 4\to 2,3\to 1$
Minimum number is $4$ : $$4\to 1, 4 \to 3 \to 1,4\to 2\to 1,4\to3\to2\to1$$ How can we generalize it for any $n$? Please add appropriate tags.","['physics', 'combinatorics']"
765579,Why is $\displaystyle\int^{\infty}_{0}{(1-\cos x)\over{x^{2}}}dx = \frac\pi{2}$?,"I have been having trouble understanding Fourier series and analysis in one of my classes. This is one problem from the text and we have to show that this is true. I have done other problems related to this one, but they do not help me. I tried to solve this manually and it has come to naught. As there is already the answer, I would like an explanation so that I may understand this material better. Thanks for all the help. $$\int^{\infty}_{0}{(1-\cos x)\over{x^{2}}}dx = \frac\pi{2}$$ This is the integral for reference.","['definite-integrals', 'trigonometry', 'integration']"
765620,"Showing limit of sequence $\left(\frac{3}{10}, \frac{33}{100}, \frac{333}{1000}, \dots\right)$","I'm trying to calculate the limit of the following sequence: $$
(s_n) = \left(\frac{3}{10}, \frac{33}{100}, \frac{333}{1000}, \dots\right).
$$ Clearly, $(s_n) \to 1/3$, but I'm not sure how to show it rigorously. I need to be able to generate this to cases where $3$ is any integer $a \in \{ 1, 2, \dots, 9 \}$. I realize that the general limit would be $a/9$, but showing it is proving to be difficult. I'm looking for a way to express the numerator as a function of $n$, where $n$ is the ""length"" of the number. That is, if $a=4$ then $44$ corresponds to $n=2$ and $444$ corresponds to $n=3$. Any ideas?","['sequences-and-series', 'real-analysis', 'limits']"
765633,Why the class of all inductive sets is not a set?,"Page 66, Set Theory of - Herbert B. Enderton, Elements of Set Theory . It says ""but the class of all inductive sets is not a set.""",['elementary-set-theory']
765648,Convergence of $\sum^\infty_{n=1}\frac{a_n}{1+n^2a_n}$,"We have a positive series $\displaystyle\sum^\infty_{n=1}a_n$. is the following series converge or diverge ?$$\displaystyle\sum^\infty_{n=1}\frac{a_n}{1+n^2a_n}$$ Suppose $\displaystyle\sum^\infty_{n=1}a_n$ does converge, so by the comparsion test the given series also converge. Suppose $\displaystyle\sum^\infty_{n=1}a_n$ does not converge: If $a_n$ is a bounded sequence with a bound $M$ then: $\forall n \  a_n\le M \Rightarrow \large\frac{a_n}{1+n^2a_n}>\frac{a_n}{1+M}\to\infty$ So the given series diverge. If $a_n$ isn't bounded, it has a subsequence that tends to infinity, so we have: 
$\displaystyle\frac{a_{n_k}}{1+{n_k}^2a_{n_k}}\longrightarrow^{k\to\infty}\infty$ so the given series will diverge. (Couldn't find the tex for the limit with arrow)","['sequences-and-series', 'convergence-divergence', 'calculus', 'solution-verification']"
765652,Is there a name for this property: If $a\sim b$ and $c\sim b$ then $a\sim c$?,"Let $X$ be a set with a binary relation $\sim$, such that for all $a$, $b$, and $c$ in $X$: If $a\sim b$ and $c\sim b$ then $a\sim c$ Is anyone familiar with this property of a binary relation? Does it have a name? Does it have any interesting properties?","['relations', 'terminology', 'equivalence-relations', 'elementary-set-theory']"
765706,Limit of $x \ln^2|x|$ when $x\to 0$,"I want to evaluate this limit :$$\lim_{x\to 0}x\ln^2|x|$$ I wanted to use L'Hôpital's rule for this:  $\lim\limits_{x\to0-}\frac{\ln^2|x|}{\tfrac{1}{x}}$, but I don't know how to differentiate the  logarithm function, because of the absolute value. My other question: do I have to calculate the one sided limits first?","['calculus', 'derivatives', 'limits']"
765736,Source needed: Does asymptotic normality yield asymptotic unbiasedness and consistency?,"Assume that $$\sqrt{n}(\hat g - g(\theta)) \xrightarrow{d} Z, $$ where $Z$ is $N(0,\sigma^2)$. Does this already imply asymptotic unbiasedness and/or consistency, i.e., $$ E[\hat g] \rightarrow g(\theta) ~~~\mbox{and/or}~~~ \hat g \xrightarrow{P} g(\theta)?$$ I am aware of this post, but it does not answer my question as I do not know the distributions of $\hat g$ for finite $n$. Can anyone point to some literature that answers these questions positively or negatively? Any help is much appreciated!","['statistics', 'asymptotics', 'normal-distribution', 'probability-distributions']"
765744,Geometry after Khan academy's tutorials,"I always liked geometry at school, so by the side of my normal studies I've been going through the Khan academy videos. Could anyone suggest some good books that takes these geometry topics further? I'm not sure which subject area to look into now. Is the next thing manifolds? I should say that I've just finished my first year of calculus (economics), but as I'm not taking a maths degree, I won't be studying things like analysis or abstract algebra, etc, and I don't know if there are any prerequisites that I need to look into first, or really even what the next subject is, I just kinda like shapes and stuff! ;) Anyway thanks for the help.","['geometry', 'soft-question']"
765755,What is the answer to $\int x(t)dt$?,"$\int x(t)dt$? I'm trying to solve a differential equation, but I've hit a strange brick wall that I never used to have a problem climbing over. This question is about mechanics & the equation of motion. I'm trying to solve $\frac{dx}{dt}=-bx$ where $b>0$. So by integrating both sides, I get: $x=-\frac{1}{2}bx^2+C$, where C is the constant of integration. Am I doing this correctly, or is it supposed to be $x=-bxt$? I apologise for how simple this question is, but I can't get my head around it.","['classical-mechanics', 'ordinary-differential-equations', 'integration']"
765757,Is the determinant differentiable?,"I was wondering, given an $n \times n$ square matrix, let function $\det : \left(a_1,a_2,\ldots,a_{n^2}\right) \to \textbf{R}$ give the determinant, where $a_{k}$ 's are the entries of the $n \times n$ matrix. Is this function (determinant) a differentiable kind? If so, is the derivative continuous? That is, is $d\left(\det\right)$ a continuous function? Furthermore, if so, to what differentiability class does this $\det$ function belong? Thanks in advance.","['matrices', 'matrix-calculus', 'real-analysis', 'derivatives', 'determinant']"
765767,Conditional Probabilities,"I am faced with this question: $10$ % of all email you receive is spam. Your spam filter is $90$ % reliable, that is, $90$ % of the mails it marks as spam are indeed spam and $90$ % of spam mails are correctly labelled as spam. If you see a mail marked spam by your filter, what is the probability that it is really spam? This question was posed in a Chennai Mathematical Institute exam. This is how I'm trying it. $10$ % of all email you receive is spam $$
P(\text{spam}) = 0.1
$$ $90$ % of the mails it marks as spam are indeed spam $$
P(\text{spam|marked as spam}) = 0.9
$$ $90$ % of spam mails are correctly labelled as spam $$
P(\text{marked as spam|spam}) = 0.9
$$ By Bayes' Theorem, we have $$
P(\text{spam|marked as spam}) = \frac{P(\text{marked as spam|spam}) P(\text{spam})}{P(\text{marked as spam})}
$$ $$
0.9 = \frac{0.9 * 0.1}{P(\text{marked as spam})}
$$ Which is incorrect. I am not able to figure out what exactly I did wrong. The official solution goes like this Out of 100 mails, 10 are spam. The filter will label 9 or 10 spam as
  spam and 9 of 90 non-spam as spam. So 18 are labelled spam, of which 9
  are actually spam. Can somebody show the right way to solve this using conditional probabilities?",['probability']
765849,Definition of the integral of a vector field on Riemannian manifold and Euclidean spaces,"Given a compact Riemannian manifold $(M,g)$ and a vector field $X \in \mathfrak{X}(M)$, is it possible to define the integral of $X$ on $M$? What if $M$ is a Euclidean space? Clearly the definition by components works if we restrict ourselves to affine coordinates, but in general? Thanks for the help.","['integration', 'differential-geometry', 'vector-fields', 'manifolds', 'riemannian-geometry']"
765864,Localisation and prime ideals,"If $A$ is a ring and $S=\{1,f,f^2,f^3,...\}$ a multiplicative set of $A$, prove that $\mathrm{Spec}(A_f)=\mathfrak{V}((f))^c$. Notation: $A_f=S^{-1}A$ and $\mathfrak{V}((f))=\{P \in \mathrm{Spec}(A): P \supset (f)\}$ My attempt: On one hand, if $P \in \mathrm{Spec}(A)$ and $P \cap S$ is empty then we identify $\mathrm{Spec}(A_f)=\mathrm{Spec}(S^{-1}A)=\{P \in \mathrm{Spec}(A): P\cap S= \emptyset\}$. On the other hand, $\mathfrak{V}((f))^c=\{P \in \mathrm{Spec}(A): P \nsupseteq (f)\}$. So the exercise is equivalent to prove:
$$\{P \in \mathrm{Spec}(A): P\cap S =\emptyset\}=\{P \in \mathrm{Spec}(A): P \nsupseteq (f)\},$$
but I can't continue so I'd appreciate if somebody could help me. Thanks in advance.","['commutative-algebra', 'ring-theory', 'ideals', 'abstract-algebra']"
765885,Nice parameterization of $x^2 + y^2 - kx^2y^2 =1$,"Can anyone find a nice simple parameterization of this curve. Just the quarter where $x \ge0$ and $y \ge0$ would be fine. The parameterization should be ""nice"" in the sense that the first derivative vector should never be zero or infinite. You can assume that $0<k<1$. If it helps, the curve looks somewhat like an circle, but increasing the $k$ parameter makes the curve more square-ish, like a so-called super-ellipse . Parameterization using rational functions would be very nice, but trigonometric functions would be OK, too. I've tried the obvious trick: take a line at angle $\theta$ and find its intersection with the curve. This gives a parameterization in terms of $\theta$, but it's a mess. I'm hoping for something simpler. If it matters to you, this is not homework. This equation represents a part of an aircraft fuselage, and having a parametric representation for it would make certain applications easier. Like drawing it, for example.","['geometry', 'algebra-precalculus']"
765887,Confidence interval multiplication,"The question looks pretty simple but I can't get my hands on it: Say I have a probability which is the product of two other independent probabilities $p = p_1p_2$. I have estimated each probability $p_1$ and $p_2$ and found some $95\%$ confidence interval for each. How do I obtain a $95\%$ confidence interval for $p$? Taking the product of the bounds of the interval won't work as I would be taking $95\%$ of a $95\%$ confidence interval resulting in an approximately $90\%$ which is not what I want. So conversely I would be taking $97.5\%$ confidence interval for each and by multiplying the bounds I will obtain a $95\%$ confidence interval, is that right? I feel like something is going wrong. In my situation I deal with probabilities but it could be anything so this question can be generalised to any type of confidence intervals. If my reasoning is correct, could someone convince me that's the correct way of doing so?",['statistics']
765895,"Does the cross section of $[-1,1]^n$ on a $k$-dimensional subspace always contains a rotated image of $[-1,1]^k$?","This question is inspired by a recent bounty question , but the two questions are different and solving this one, I believe, will not lead to an answer of that bounty question. Suppose $n>k\ge1$ and $V\in M_{k,n}(\mathbb R)$ is the submatrix taken from the first $k$ rows of a real orthogonal matrix of size $n$. Does there always exist a real orthogonal matrix $R$ of size $k$ such that $\|Rv_j\|_1\le1$ for every $j$ (or equivalently, $\|RV\|_1\le1$ where $\|\cdot\|_1$ is the maximum column sum norm)? Numerical experiments suggest that the answer is negative in general, but affirmative when $k=2$. So, here is my main question: does the aforementioned $R$ always exist when $k=2$?","['matrices', 'linear-algebra']"
765962,Convergent series multiplied by $n$,"this one should be really simple... Let $\mathbb a_n$ be a sequence of strictly positive real numbers such that $\sum_{n\in\mathbb N}a_n$ is finite, i.e., the limit $\lim_{k\to\infty}\sum_{n=1}^ka_n$ exists. Then $a_n$ has to converge to zero, pretty quickly so. -- That much I do remember. Does it follow that $\lim_{n\to\infty}a_n\cdot n=0$ has to hold? Here is what I do (seem to) remember: If the limit exists, then $a_n$ has to converge to zero, ``quicker'' than $1/n$,
thus(???), there has to exist some $\epsilon>0$ such that $a_n$ goes to zero as fast as  $(1/n)^{1+\epsilon}$. --- But is this true? If this is in fact true, then $\lim_{n\to\infty}a_n\cdot n = 0$ does hold.","['sequences-and-series', 'calculus', 'limits']"
765972,Prerequisite for Petersen's Riemannian Geometry,"A professor recently told me that if I can cover the chapters on curvature in Petersen's Riemannian geometry book (linked here ) within the next few months then I can work on something with him. However, before I plan on reading this book I need to pick up some manifold theory. I plan on reading Lee's Smooth Manifolds book . Assuming I don't know anything covered in Lee's book and that I want to read it just to be able to read Petersen's can somebody recommend me what chapters I can skip. I know it'll be beneficial to read the whole book but I'll cover the whole book in a course next year and I just want to be able to read the rudiments of Riemannian geometry before then. Or if one can suggest a book better suited for this goal that would be appreciated too. Thank you.","['differential-geometry', 'manifolds', 'riemannian-geometry', 'reference-request', 'soft-question']"
765995,Frattini subgroup of a finite group,I have been looking for information about the Frattini subgroup of a finite group. Almost all the books dealing with this topic discuss this subgroup for $p$ -groups. I am actually willing to discuss the following questions: Let $G$ be a finite group. Is the Frattini subgroup of $G$ abelian? Why is the order of the Frattini factor divisible by each prime divisor of $|G|$ ?,"['reference-request', 'finite-groups', 'group-theory']"
766023,Extension of character in Banach algebras,"Let $A$ be a Banach algebra. The continuous linear functional $\phi:A\to\Bbb{C}$ is called character if it is non-zero multiplicative function i.e., for every $a,b\in A$ we have $\phi(ab)=\phi(a)\phi(b)$. The set of all character is shown by $\sigma(A)$. Now suppose that $A,B$ are Banach algebra such that $A$ is ideal of $B$. Let $\phi\in\sigma(A)$. Is there a $\psi\in\sigma(B)$ such that for all $a\in A, \psi(a)=\phi(a)$? If it exists, is it unique? If it doesn't exists ever, under which conditions it exists?","['c-star-algebras', 'banach-algebras', 'harmonic-analysis', 'functional-analysis']"
766062,Find the value of $(a+b+c)$ when $\cos\theta+\cos^2\theta+\cos^3\theta=1$ and $\sin^6\theta=a+b\sin^2\theta+c\sin^4\theta$,"Given: $\cos\theta+\cos^2\theta+\cos^3\theta=1$
and $\sin^6\theta=a+b\sin^2\theta+c\sin^4\theta$ Then find the value of $(a+b+c)$",['trigonometry']
766083,"Proof ""correctness"" : Cycle structure of conjugate permutations","My Algebra lecturer is a very strict about proofs(w.r.t Completeness , correctness and format ) more so than I have encountered in the past or any of my lecturers of the courses I am take concurrent. I do appreciate this as Mathematics along with other scientific disciplines are found on being as precise as possible. It does make it rather difficult to judge  what constitutes a proof, Which brings me onto my main topic The Question :
Suppose $f \in S_n$ and consists of a single cycle $( a_1 , a_2 ,...,a_r).$ Let $g\in S_n$ and show that  $gfg^{-1} = (g(a_1) , g(a_2) ,... ,g(a_r)) $ and furthermore show that $f$ and $gfg^{-1}$ has the same disjoint cycle structure My Proposed Proof : Suppose  $a_i \in \{a_1, a_2,...,a_r\}$ Let  $h = gfg^{-1}$.  Since $f(a_i) = a_{i+1}$ then $$ h(g(a_i) = gfg^{-1} g(a_i)$$
$$ = g(f(a_i)) = g(a_{i+1})$$ So $gfg^{-1} $ has a cycle $(g(a_1) , g(a_2) ,... ,g(a_r)) $ otherwise $a_i \in \{ a_{r+1} ,.., a_n\}$ Since  $f(a_i) =a_i$ then
 $$ h(g(a_i) = gfg^{-1} g(a_i)$$
$$ = g(f(a_i)) = g(a_{i})$$ So  $f$ and $gfg^{-1}$ has the same disjoint cycle structure If this proof correct, and if so any suggestions/comments about additions and changes that should be made in order to make the proof as complete , rigorous and properly formatted.","['permutations', 'group-theory', 'proof-verification']"
766152,Question about Hopf-Rinow theorem,"I'm studying Hopf-Rinow theorem and I don't see a step in the proof. Could someone help me, please? (Definition) Let's $(M, \langle,\rangle)$ an ANII(axiom numerability 2) and Hausdorff Riemannian manifold. If $M$ is connected and $p,q \in M$. We define: $$d_L:M\times M \longrightarrow [0,\infty)$$ $$(p,q)\longmapsto inf\{l(C)\}$$
where C is a piecewise differentiable curve joining $p$ and $q$ and $l$ is the length of the curve. I've proved that $d_L$ is a distance and that the topology induced by $d_L$ is the original topology on $M$. Considering  $(M, \langle,\rangle)$ an ANII and Hausdorff Riemannian manifold. If $M$ is connected and $p \in M$. Then prove that the following statements are equivalent: (a) If $A$ is a closed and bounded subset of $M$ then $A$ is compact. (b) $\exists \{K_n\}_{n\in \mathbb{N}}, K_n \subset M$ compact and $K_n \subset K_{n+1}, \forall n \in \mathbb{N}$ and $\bigcup_n K_n=M$ with the following property:
If $(q_n)_{ n \in \mathbb{N}}\subset M$ sequence / $(q_n)\notin K_n, \forall n \in \mathbb{N}\Rightarrow lim_{n\rightarrow \infty} d_L(q_n,p)=\infty$. Thanks.","['riemannian-geometry', 'differential-geometry']"
766185,Are there always nontrivial primitive elements in a Hopf algebra?,"Let $k$ be an algebraically closed field of arbitrary characteristic.  Let $H$ be a Hopf algebra over $k$.  We say $x\in H$ is a primitive element if $\Delta(x)=1\otimes x+x\otimes 1$, where $\Delta$ is the comultiplication in $H$.  The set of primitive elements in $H$, denoted $P(H)$, is a Lie subalgebra, with bracket given by the commutator. Is $P(H)$ always nontrivial?  If not, what is an example of a Hopf algebra with $P(H)=0$?  What if I require $H$ to be finite-dimensional, or finite-dimensional and local?  Do we have examples of such Hopf algebras with no nontrivial primitive elements?","['hopf-algebras', 'lie-algebras', 'abstract-algebra', 'coalgebras']"
766187,How does Wikipedia's definition of the Lebesgue integral relate to more common definitions?,"Wikipedia presents a definition of the Lebesgue integral (of a nonnegative function $f$ ) that I hadn't encountered before: Let $f^*(t)=\mu \left (\{x\mid f(x)>t\} \right )$ . The Lebesgue integral of $f$ is then defined by $\int f\,d\mu = \int_0^\infty f^*(t)\,dt$ where the integral on the right is an ordinary improper Riemann integral My question is, what is the relation between this definition and more standard definitions, like the supremum of $\int \phi\,d\mu$ over simple functions $\phi$ such that $0 \leq \phi \leq f$ ? I'm also interested in understanding the intuitive justification provided for this definition: Using the ""partitioning the range of $f$ "" philosophy, the integral of $f$ should be the sum over $t$ of the area of the thin horizontal strip between $y = t$ and $y = t + dt$ . This area is just $\mu \left (\{x\mid f(x)>t\} \right ) \,dt$ . I don't see why that's the area of the infinitesimal strip.  Clearly the width of the strip is $dt$ , but why is the length of the strip $\mu \left (\{x\mid f(x)>t\} \right ) \,$ ? Any help would be greatly appreciated. Thank You in Advance. EDIT:  It seems to me that the same reasoning that shows that the Lebesgue integral of $f$ can be expressed as $\int_0^\infty f^*(t)\,dt$ can also be used to express $f$ itself as $f(x) =  \int_0^\infty f^{**}(x,t)\,dt$ , where $f^{**}(x,t) = \chi_{\{s:f(s)>t\}}(x)$ .  Am I right about that?","['lebesgue-integral', 'measure-theory', 'lebesgue-measure', 'real-analysis']"
766212,Problem with infinite product measures,"Given some measurable space $\left(X,\mathcal{F}\right)$ and two probability measures $\mu$ and $\nu$ on this space one can define
$$H_{\theta}(\mu,\nu)=\int\left(\frac{d\mu}{d\lambda}\right)^{\theta}\left(\frac{d\nu}{d\lambda}\right)^{1-\theta}d\lambda
 $$ 
where $\theta\in[0,1]
 $ and $\lambda$ is any positive measure such that $\mu,\nu<<\lambda$ (it is in fact independent of the choice of this measure, and we can in fact assume it is also a probability measure). Now let $\mathbb{X}$ be a polish space, $\mathcal{F}=\mathbb{B}(\mathbb{X})
 $, and consider the countable product of measurable spaces $\left(\prod_{n}\mathbb{X},\otimes_{n}\mathcal{F}\right)
 $
, and the following measures $
\mu=\prod_{n}\mu_{n},\:\nu=\prod_{n}\nu_{n}
$, on this space. Where $\mu_{n}$ and $\nu_{n}$ are probability measures on $\left(\mathbb{X},\mathcal{F}\right)
 $. I wish to show that $H_{\theta}(\mu,\nu)=\prod_{n=1}^{\infty}H_{\theta}(\mu_{n},\nu_{n}).$ It is trivial for the case $\theta=0,1$, so assume $\theta\in(0,1)$. I can show that $H_{\theta}(\mu_{1}\times\mu_{2},\nu_{1}\times\nu_{2})=H_{\theta}(\mu_{1},\nu_{1})H_{\theta}(\mu_{2},\nu_{2})$ From which it follows that, $$H_{\theta}(\mu,\nu)=\prod_{n=1}^{N}H_{\theta}(\mu_{n},\nu_{n})H_{\theta}(\prod_{n=N+1}^{\infty}\mu_{n},\prod_{n=N+1}^{\infty}\nu_{n}).
 $$
And since (by Hölder's inequality), $$H_{\theta}(\prod_{n=N+1}^{\infty}\mu_{n},\prod_{n=N+1}^{\infty}\nu_{n})\leq1,$$
it only remains to show that $$H_{\theta}(\prod_{n=N+1}^{\infty}\mu_{n},\prod_{n=N+1}^{\infty}\nu_{n})\geq1.
 $$
Since then $$H_{\theta}(\mu,\nu)=\lim_{N}\prod_{n=1}^{N}H_{\theta}(\mu_{n},\nu_{n})\lim_{N}H_{\theta}(\prod_{n=N+1}^{\infty}\mu_{n},\prod_{n=N+1}^{\infty}\nu_{n})=\prod_{n=1}^{\infty}H_{\theta}(\mu_{n},\nu_{n}).
 $$
I am kind of stuck here. Maybe this idea is going nowhere. I am not very familiar with infinite product measures and their integrals. Any pointers would be appreciated.","['stochastic-processes', 'measure-theory', 'probability', 'analysis']"
766229,How to obtaining the lattice corresponding to an elliptic curve,"Let $C$ be a complex elliptic curve given by the quation $y^2=4x^3-g_2 x -g_3$.
How do I find the lattice $\Lambda$ such that $C \cong \mathbb{C}/\Lambda$?
I need the lattice (and corresponding Weierstrass $P$ function) but I don't know how to get it explicitly from the elliptic invaiants $g_2$ and $g_3$.","['vector-lattices', 'elliptic-functions', 'elliptic-curves', 'complex-analysis']"
766251,which of $\sqrt{5}+\sqrt{13}$ or $ \sqrt{34}$ is larger?,"which of $\sqrt{5}+\sqrt{13}$ or $ \sqrt{34}$ is larger?
 I tried to define $f= \sqrt{x}+\sqrt{x+8}+\sqrt{x+29}$ and use cslculus but have failed. please helps. Is there any non calculus solution? such as algebraic approach, thanks in advance.","['calculus', 'algebra-precalculus']"
766260,The Objectivity of Statistical Testing,"I have a very generic question about applied statistics. Suppose, to make things simple, we have a biased coin with probability $p$ of landing heads. We want to determine if our coin is truly fair - that is, if $p=1/2$. We can do this by flipping the coin several times, generating a sequence such as $$0,0,1,0,0,1,1,0,1,0,1,1,1,1,0$$ for example. Now we must determine if that sequence of numbers is ""random"". Typically statistical testing for randomness involves so-called ""suites"" or ""batteries"" which consist of several tests put together. For example, random.org list $15$ different tests on this page which are used to confirm the randomness of its number generator. My first question is: how on earth do they justify the use of all these tests simultaneously? Surely the $15$ tests are all interdependently correlated in a way that is hopelessly complicated? I don't see how it would be possible to make sense out of such a vast array of results. Secondly, and more importantly: let's say we are free to choose any statistical test we want (we can even make one up), after the sequence of coin flips has been generated . Is it always possible to cook up some unsavory mess of a function which returns $p$-values arbitrarily low? That is, can we fabricate a statistic such that its attaining the value for the given event of coin flips has (assuming randomness) probability smaller than any $\epsilon>0$ that is given? If so, what does this say about the objectivity of statistical testing. There are many different statistics which could be measured for a sequence of coin flips. Some of these, undoubtedly, will return very unlikely results. Humans are free to choose both which tests to use and what $p$-values to reject at - does this have implications for the practice of statistics? How can we measure the ""randomness"" of that sequences in an objective fashion, without incorporating human bias? EDIT: Nobody has yet touched on the question of whether, for any given sequence of $1$'s and $0$'s a statistic can be constructed such that $P(\text{stat outcome})$ is arbitrarily small. I believe this demonstrates a negative answer: Since there are $2^n$ possible sequences of length $n$, the statistic can take on at most $2^n$ different values over the event space. Therefore, the least possible probability would be the chance of getting that one outcome alone, which is $2^{-n}$. Therefore the $p$-value cannot be made smaller than any given $\epsilon>0$ - does this look correct?","['statistics', 'probability', 'random', 'statistical-inference']"
766270,Any rational as integer plus sum of $n$ reciprocals,"Does there exist an integer $n$ with the following property? For any rational number $r$, there exist integers $a,b_1,\ldots,b_n$ such that $r=a+\sum_{i=1}^n\frac1{b_i}$.","['elementary-number-theory', 'number-theory']"
766346,How to calculate the following sums?,"I would like to know of a way to evaluate the  following two for arbitrary $n$. $$\sum_{i=1}^ni!\,, \quad  \sum_{i=1}^n \frac{n!}{i!}. $$","['summation', 'combinatorics']"
766359,Different ways of picking a committee of $12$ women and $10$ men,"$12$ women and $10$ men are on the faculty. How many ways are there to pick a
committee of $7$ if (a) Claire and Bob will not serve together, (b) at least one woman must be chosen I'm not sure how to start a. Essentially I need to remove a woman and remove a man? For b, $\binom{22}{7}- \binom{10}{7}= 170424$ ways","['discrete-mathematics', 'combinatorics']"
766384,How to show a sequence converges given that $\lim_{n \to \infty} u_n + \frac{u_{2n}}{2} = 1$,Let $u_n$ be a bounded sequence of real numbers. Suppose that $$\lim_{n \to \infty} u_n + \frac{u_{2n}}{2} = 1$$ Show that $u_n$ converges. Can someone provide some hints or insight to this problem or similar? I don't really know where to start.,"['sequences-and-series', 'calculus', 'real-analysis', 'limits']"
766422,When does open and connected imply path-connected?,"It's well known that, in $\mathbb{R}^n$: (1) Open and Connected $\Rightarrow$ Path-connected The proof essentially goes through the fact that (2) Every path-connected component will be open . Using this fact, we arrive at a contradiction if we suppose there are more than one path-connected component. Well, trying to see where (1) would keep being valid, I arrived at the following: If $X$ is a locally convex topological vector space, then (1) is valid. But, to prove this, I proved (2). But for that, you use the (rather strong imo) convexity of a local base (to essentially repeat the argument for $\mathbb{R}^n$). But I'm not satisfied with this, as I think that we are using a lot of strong conditions (using the existence of a ""line segment"" to prove the existence of a ""curve"" seems very bazooka-like to me). Anyway, given the previous considerations, my questions are: Are there more general examples of spaces where (1) holds? Is there a characterization of spaces that satisfy this property? And bonus question, since (2) implies (1) if the set is open.: Are there more general examples of spaces where open sets satisfy (2)? Is there a characterization spaces that satisfy this property?","['general-topology', 'functional-analysis']"
766426,Calculation a closed form for the sum,"Please help me to calculate this sum in a closed form:
$$
\sum\limits_{1\ \leq\ i_{1}\ <\ i_{2}\ <\ \cdots\ <\ i_{k}\ \leq\ n}
\left(i_{1} + i_{2} + \cdots + i_{k}\right).
$$
Here $n$, $k$ are positive integer numbers; $k < n$. I think that it may be reduce to binomial coefficients, but I cannot understand how to do this. Thank you very much in advance for your help !.",['combinatorics']
766479,What is spectrum for Laplacian in $\mathbb{R}^n$?,"I know very well that Laplacian in bounded domain has a discrete spectrum. How about Laplacian in $\mathbb{R}^n$?(not in some fancy-shaped unbounded domain, but the whole domain) Where can I find such results? Moreover, is there a counterpart of Hilbert-Schmidt theorem for Laplacian in $\mathbb{R}^n$? Hilbert-Schmidt asserts there is a countable set of eigenfunctions $\phi_n$ so that $x=\sum \langle x,\phi_n\rangle \phi_n,\forall x\in H$. Is there a similar theorem saying $x=\int_0^\infty \langle x,\phi_\lambda\rangle \phi_\lambda\,\mathrm{d}\lambda,\forall x\in H$ where $\phi_\lambda$ is the eigenfunction of Laplacian to spectral value $\lambda$?","['eigenvalues-eigenvectors', 'partial-differential-equations', 'spectral-theory', 'reference-request', 'functional-analysis']"
766487,probability of sequence of integers,"Suppose you have numbers from 1 to 10. You can choose four of them but the contiguous numbers should have an absolute difference greater than 1. For example, you can choose
$$ 1-3-6-10$$
$$ 4-2-5-1$$
but you cannot choose
$$ 1-2-4-8$$
$$ 4-1-3-2$$
What is the probability that you choose an admissible sequence? I could not solve it mathematically so I wrote a short code in R require(gtools)
x=permutations(10 ,4)
y = abs(apply(x,1,diff))
cf = function(x){
  is.element(1,x)
}
z=apply(y,2,cf)
x[z==F,]
sum(z==F)/(dim(x)[1]) If I am not mistaken, you can choose an admissible sequence with $0.4861111$ probability. Can you show it mathematically?","['permutations', 'probability']"
766523,Examples of properties not preserved under homomorphism,"An isomorphism indicates that two structures are the same, using different names for the elements. Therefore it's obvious that every (algebraic) property of the first structure must be present in the second. However, homomorphisms only indicate that the two structures are ""similar"", so it's not quite as obvious that every property will be preserved. Yet all the properties I've ever seen are preserved under homomorphism: commutativity, cyclicality, solvability... What are some examples of properties of algebraic structures not preserved under homomorphism? Feel free to use any algebraic structures you like, but I'm particularly interested in your garden variety structures: group and rings, say.","['big-list', 'ring-theory', 'group-theory', 'abstract-algebra']"
766555,Solutions to $3\cdot 5 p_1 \pm 37^n p_2 =2^b\cdot 29^m p_3$,"Let $p_k$ be either primes larger than $40$ or equal to $1$. $n,m$ are larger than $0$ and $b$ is either $1$ or $2$.
I'm searching solutions for the following equation: 
$$
3\cdot 5 p_1 \pm 37^n p_2 =2^{b}\cdot 29^m p_3
$$
Are there any other methods than brute-force trial-and-error to get the set of solutions for such kind of equations?","['prime-numbers', 'number-theory']"
766563,"finding all functions: $f(\frac{x+a}{b})=f(\frac{f(x)+a}{b})$,$f:\mathbb{Q}\rightarrow \mathbb{Z}$","If i have this equation: $f(\frac{x+a}{b})=f(\frac{f(x)+a}{b})$ such that $x\in \mathbb{Q}$, $a\in \mathbb{Z}$ , $b\in\mathbb{N}$ and $f:\mathbb{Q}\rightarrow \mathbb{Z}$ Need to find all functions there are in this way. So i can choose $a=c-f(x)$ then $f( (x-f(x))/b + c/b ) = f(c/b)$ So adding $(x-f(x))/b$ doesn't changing the value in point $c/b$ and it's almost a general point. But i can't see how to to continue and if there any solution that is not constant. 
any ideas?",['functions']
766565,Find the axis of rotation of a rotation matrix by inspection (NOT by solving $Kv=v$),"$$K=\
\begin{pmatrix}
0 & 0 & 1\\ 
-1 & 0 & 0\\ 
0 & -1 & 0
\end{pmatrix}$$ Find the axis of rotation for the rotation matrix $K$ by INSPECTION . This is from my other thread click here to view it Everything you see below is me finding the axis of rotation by solving $Kv=v$ . Just to show you how much working it requires: Noting that the axis of rotation consists of vectors that remain unmoved. That is a vector $v$ satisfying $Kv = v$ . Or, $Kv - Iv=0$ where $I$ is the $3\times3$ identity matrix. For matrix $K$ after solving the homogeneous equations given by $(K-I)v=0$ and showing the working: $(K-I)v=0$ So $$K-I=\
\begin{pmatrix}
0 & 0 & 1\\ 
-1 & 0 & 0\\ 
0 & -1 & 0
\end{pmatrix}-\begin{pmatrix}
1 & 0 & 0\\ 
0 & 1 & 0\\ 
0 & 0 & 1
\end{pmatrix}=\
\begin{pmatrix}
-1 & 0 & 1\\ 
-1 & -1 & 0\\ 
0 & -1 & -1
\end{pmatrix}$$ therefore $$\begin{pmatrix}
-1 & 0 & 1\\ 
-1 & -1 & 0\\ 
0 & -1 & -1
\end{pmatrix}v=0$$ writing out the components for $v$ gives $$\begin{pmatrix}
-1 & 0 & 1\\ 
-1 & -1 & 0\\ 
0 & -1 & -1
\end{pmatrix}\begin{pmatrix}
x \\ 
y \\ 
z 
\end{pmatrix}=0$$ Multiplying out gives three equations $-x+z=0$ $-x-y=0$ $-y-z=0$ Since $$
v=\begin{bmatrix}x\\y\\z\end{bmatrix}
$$ Here's the solution parametrically in terms of $x$ \begin{align*}
z&= x\\
y&=-x\\
x&=x
\end{align*} Hence the axis of rotation is given by the line $$
\begin{bmatrix}
x\\-x\\x
\end{bmatrix}=x\begin{bmatrix}1\\-1\\1\end{bmatrix}\quad x\in\Bbb R
$$ That is, the axis of rotation is $$
\operatorname{Span}\left\{\begin{bmatrix}1\\-1\\1\end{bmatrix}\right\}
$$ As you can see this was a lot of work so i would be so grateful if someone could please explain in simple english how to get the answer: $$
\operatorname{Span}\left\{\begin{bmatrix}1\\-1\\1\end{bmatrix}\right\}
$$ by using Inspection? Many thanks to all that helped so far particularly Brian Fitzpatrick in the last thread","['matrices', 'linear-algebra']"
