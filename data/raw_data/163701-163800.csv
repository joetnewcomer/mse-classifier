question_id,title,body,tags
2847942,One Critical Value despite being on a compact set,"Let $\alpha > 1$ and $s >0$
find all the local extrema of $f: \mathbb R_{\geq 0} \times \mathbb R_{\geq 0}\to\mathbb R, f(x,y):=x^{\alpha}+y^{\alpha}$
under the constraint that $h(x,y):=x+y-s=0$ In the solutions we found that using lagrange multipliers $(\frac{s}{2},\frac{s}{2})$ is the only candidate, HOWEVER , defining $M:=\{(x,y)\in \mathbb R_{\geq 0}^{2}:x+y=s\}$, I would assume that $M$ is compact and therefore $f|_{M}$ needs to take on a minimum and a maximum, but I have only found one candidate, how can that be?","['multivariable-calculus', 'real-analysis', 'compactness', 'optimization']"
2847945,Determine the existence of a bijection and construction,"Sorry if it might be simple but I basically can't get my head around it. The question asks me to: If exists, construct a bijection between the sets $\mathbb R$ and $\mathbb R - \{0\}$ But I don't know how to handle it, I thought about the existence of a relationship but the absence of $\{0\}$ in the second set makes me feel lost and can't prove the existence of the bijection.","['abstract-algebra', 'functions']"
2847979,Proof Verification: Finding A Ball Strictly Contained In An Open Set Of A Metric Space,"Problem: Let $X$ be a metric space and let $A$ be an open set of $X$ containing a point $x \in X$. Prove that there exists an $\epsilon > 0$ such that $B_{\epsilon}(x)$ is strictly contained in $A$. Proof Attempt: Case 1: $\partial A = \emptyset$ Since $X$ is a metric space, this implies that $A$ is clopen. The only clopen sets of a metric space are $\emptyset$ and the entire space. $A$ contains $x$, so it cannot be empty and thus $A = X$, so any $\epsilon > 0$ will suffice. Case 2: $\partial A \neq \emptyset$ Let $\displaystyle \epsilon = \frac{1}{2}\inf_{p \in \partial A}{d(p,x)}$, where $d$ is the metric of $X$. Note that $\epsilon \neq 0$ or else this would imply that $x \in \partial A$, which contradicts the hypothesis that $A$ contains $x$ and that $A$ is an open set. So $\epsilon > 0$. Then $B_{\epsilon}(x)$ is strictly contained in $A$ (I'm not sure how to justify this part). $\blacksquare$ Is this proof correct? How do I finish the proof? Thanks.","['general-topology', 'metric-spaces', 'analysis']"
2847984,Does the uniform distribution minimize the expected value in the coupon collector's problem?,"Given a discrete probability distribution with $n$ possible outcomes and the task of repeatedly sampling until getting each outcome at least once, does the uniform distribution give the smallest expected value for the total number of samples?","['coupon-collector', 'probability', 'optimization']"
2847994,(Proof verification) Extension Lemma for Functions on Submanifolds,"There is a similar question about this lemma in Lee's book , but I wasn't really satisfied with the detail in the proposed solution. In particular, the OP of the linked question doesn't describe how to get the smooth maps which I am calling $f_p$ below. I am hoping someone can give critical feedback on this proof and point out where, if anywhere, I have erred. Lemma 5.34 (Extension Lemma for Functions on Submanifolds). Suppose $M$ is a smooth manifold, $S\subset M$ is a smooth submanifold,
  and $f\in C^\infty(S)$ . If $S$ is embedded, then there exist a neighborhood $U$ of $S$ in $M$ and a smooth function $\widetilde f\in C^\infty(U)$ such that $\widetilde f|_S = f$ . If $S$ is properly embedded, then the neighborhood $U$ in part (a) can be taken to be all of $M$ . Proof of 1: Let $n = \dim S$ and $m = \dim M$ . Since $S$ is embedded, each $p\in S$ is in the domain of
a slice chart $(U_p,\varphi_p)$ in $M$ such that $S\cap U_p$ is a single slice
in $U$ . Since $f$ is smooth, at each $p\in S$ we can find a slice chart so that $\mathbf{f}_p:= f\circ\varphi_p^{-1}\colon \varphi_p(S\cap
U_p)\to\Bbb R$ is smooth. Since $\varphi_p(S\cap U_p) = \{(x^1,\dots,x^n,0,\dots,0)\in
\varphi_p(U_p)\}$ , and $\mathbf{f}_p$ is smooth on this set, there is a smooth extension $\widehat f_p\colon V_p\subset\Bbb R^m\to \Bbb R$ of $\mathbf{f}_p$ , where $V_p$ is an open set in $\Bbb R^m$ containing $\varphi(p)$ . (Here is where I see a potential ""bug"" in this proof. By the definition of a smooth map on $S$ , the map $\mathbf{f}_p$ is ""smooth."" However, since $\mathbf{f}_p$ is defined on a set that is not an open subset of $\Bbb R^n$ , I believe, and please do address this point, ""smooth"" means that there is the extension I am calling $\widehat f_p$ .) The restriction of $\widehat f_p$ to the open set $W_p := \varphi_p(U_p)\cap V_p $ is still smooth and gives us a map $f_p\colon \varphi_p^{-1}(W_p)\to\Bbb R$ defined by $f_p(x) = \big(\widehat f_p|_{W_p}\big)\circ\varphi_p(x)$ . The collection of open sets $\varphi_p^{-1}(W_p)$ is an open cover of $S$ ,
so let $(\psi_p)_{p\in S}$ be a partition of unity subordinate to this cover. For any $x\in U:=\bigcup_{p\in S}\varphi^{-1}(W_p)$ , define $\widetilde f(x) = \sum_{p\in S}\psi_p(x)f_p(x)$ . If $x\in S$ , then $$
\widetilde f(x) = \sum_{p\in S}\psi_p(x) f(x) = f(x).
$$ Hence $\widetilde f$ is an extension of $f$ . Since the collection of supports of the $\psi_p$ is locally finite, each point in $U$ has a neighborhood in which the sum is finite, so this defines
a smooth map since every point has a neighborhood such that $\widetilde f$ restricted
to that neighborhood is smooth. Hence $\widetilde f\in C^\infty(U)$ is the desired
extension. $\square$ Proof of 2: In this case, the only thing that changes is that $S$ is actually closed in $M$ by a lemma in Lee's book. By appending $M\smallsetminus S$ to the collection $\{\varphi_p^{-1}(W_p)\}$ and taking a partition of unity $\{\psi_p: p\in S\}\cup\{\psi_0\}$ subordinate to this open cover of $M$ with $\operatorname{supp}\psi_0\subset M\smallsetminus S$ , 
define $\widetilde f(x) = \psi_0(x) + \sum_{p\in S}\psi_p(x)f_p(x)$ , where $f_p$ is
defined in the first part. $\square$","['smooth-manifolds', 'differential-geometry', 'proof-verification']"
2847996,Lebesgue measure of boundary of sets of roots,"Suppose $f:(0,1)^n\to \mathbb{R}$ is continuous. Does the boundary of the set  of its roots have Lebesgue measure 0? 
I guess the answer is negative, in that case, are there any reasonable conditions on $f$, e.g. Lipschitz continuity or (continuous) differentiability, that make the answer positive? Thanks a lot, I'd appreciate any input.","['roots', 'lebesgue-measure', 'measure-theory']"
2848006,Ratio of Perimeter^3 to the Area of an Isoceles Triangle.,"I am in trouble with the following question: QUESTION ABC is an isosceles triangle inscribed in a circle of radius $r$. If $AB=AC$ and $h$ is the altitude from $A$ to $BC$ and $p$ be the perimeter of $ABC$ then find out:
 $$\lim_{h\to0} \frac{\Delta}{p^3}$$
(where $\Delta$ is the area of triangle ) MY ATTEMPT First, let us try to understand what's happening during the limiting process $h\to0$: The base $BC$ is translated vertically upwards to the apex $A$, all the while staying horizontal. If I describe the various quantities playing a role here in terms of the half angle $\alpha$ at $A$ (which tends to ${\pi\over2}$ in the process). Then I obtained an expression $${\Delta \over p^3}=\Psi(\alpha)\ ,$$ and now I have to determine $\lim_{\alpha\nearrow{\pi\over2}}\Psi(\alpha)$, whereby $r$ is considered constant and $\Psi(\alpha)$ is a function of half-angle.
HENCE applying trigonometric identities will yield:
$$\lim_{\alpha\to\frac{\pi}{2}}  \frac{h^2\tan\frac{\alpha}{2}}{[2h(\sec\frac{\alpha}{2}+\tan\frac{\alpha}{2})]^3}=\frac{h^2}{8h^3} \lim_{\alpha\to\frac{\pi}{2}}\frac{\tan\frac{\alpha}{2}}{[\sec\frac{\alpha}{2}+\tan\frac{\alpha}{2}]^3}$$
$$=\frac{1}{8h}\frac{1}{(\sqrt{2}+1)^3}=\frac{1}{h(56+40\sqrt{2})}$$
at $\lim_{h\to0}$ i can replace h by r (from figure h=AO=radius of circle) HELP Please let me know whether it is the correct answer or not. I am kind of worried as the answer given in my book is $\frac{1}{128r}$. PLEASE EXPLAIN HOW TO GET THIS ANSWER *I am sorry for any kind of mistake, I am in high school and this is my first week on MSE.","['circles', 'limits', 'calculus', 'triangles', 'geometry']"
2848033,How is Hessian tensor on Riemannian manifold related to the Hessian matrix from calculus?,"From calculus, given a smooth function $f: \mathbb{R}^{n} \rightarrow \mathbb{R}$, the Hessian matrix is the $n\times n$ matrix of second partials: $${\rm Hess}(f)= \bigg( \frac{\partial^{2}f}{\partial x_{i} \partial x_{j}}\bigg)$$ On a Riemannian manifold, one way to define the Hessian tensor of a smooth function $f:M \rightarrow \mathbb{R}$ is by $${\rm Hess}(f)(X,Y)=X(Yf)-df(\nabla_{X}Y)$$ where $X$ and $Y$ are smooth vector fields on $M$. I would like to know what relationship the Hessian on a Riemannian manifold has with the Hessian matrix of a function on $\mathbb{R}^{n}$.","['riemannian-geometry', 'differential-geometry']"
2848061,Faltings theorem and number of singularities,The Faltings theorem states that the number of rationals over an algebraic curve is finite if the genus is greater than 1. The genus decreases by increasing the number of singularities. My question is this. Should one count only the rational singularities or all the singularities over the complex field?,['algebraic-geometry']
2848106,"Let $|E|_e$ denote the outer measure of a set $E$ in $\mathbb R^n$. If $E_k \nearrow E$, then $\lim_{k\to \infty} |E_k|_e = |E|_e$.",Why does the author let $V_m = \bigcap_{k=m}^\infty H_k$? I think $V_m = H_m$ so there is no need to define $V_m$. Can we just use $H_m$ and let $H=\bigcup H_m$?,"['real-analysis', 'measure-theory', 'proof-verification', 'proof-explanation']"
2848111,Measurability of conditional distribution,"Let $X,Y$ be discrete random variables from $(\Omega,\mathcal{A},\mathbb{P})$ to  $(\mathbb{R}^n,\mathcal{B}^n)$ and $(\mathbb{R}^m,\mathcal{B}^m)$ respectively. Define $Q:\mathcal{B}^m\times \mathbb{R}^n \rightarrow [0,1]$ as follows: $Q(B,x)=\mathbb{P}(Y^{-1}(B) \cap X^{-1}(x))/ \mathbb{P}(X^{-1}(x))$ if $\mathbb{P}(X^{-1}(x))\neq 0$ $Q(B,x)=P(B)$ otherwise ($P$ is a probability on $(\mathbb{R}^m,\mathcal{B}^m)$ Now for fixed $B\in\mathcal{B}^m$, is the function $x\mapsto Q(B,x)$ measurable? If yes, how can I prove it? (my background in measure theory is very limited) Thank you!","['probability-theory', 'measure-theory']"
2848135,A pattern appearing in the powers of $\phi$,"\begin{align}
\phi^5 &= 11,\underline{0}901699\cdots\\
\phi^6 &= 17,\underline{9}44271\cdots\\
\phi^7 &= 29,\underline{6}34441\cdots\\
\phi^8 &= 46,\underline{9}7871\cdots\\
\phi^9 &= 76,\underline{0}1315 \cdots\\
\phi^{10} &= 122,\underline{99}18\cdots\\
\phi^{11} &= 199,\underline{00}502\cdots\\
\phi^{12} &= 321,\underline{99}6894\cdots\\
\phi^{13} &= 521,\underline{00}191\cdots\\
\phi^{14} &= 842,\underline{99}881\cdots\\
\phi^{15} &= 1364,\underline{000}73\cdots\\
\phi^{16} &= 2206,\underline{999}54\cdots\\
\end{align} Why there is a $0$ $9$ patterns in the powers of the golden ratio","['number-theory', 'golden-ratio']"
2848140,Basic group theory question on the index of subgroups,"I'm doing some summer reading of Fraleigh's A First Course in Abstract Algebra and I came across this exercise in Section 10.  I'm trying to prove the following theorem and I'm wondering if I can get some feedback on my proof.  Note that $(G:H)$ refers to the index of $H$ in $G$. Theorem: Suppose $H$ and $K$ are subgroups of the group $G$ such that $K \leq H \leq G$ and suppose that $(H:K)$ and $(G:H)$ are finite.  Then $(G:K)$ is finite and $(G:K) = (G:H) (H:K)$. Proof: First, define $\{a_iH | i = 1, 2, \cdots, r\}$ and $\{b_jK | j = 1, 2, \cdots s\}$ to be the collection of distinct left cosets of H in G and K in H, respectively.  Note that since (H:K) and (G:H) are finite, we know that the size of these groups are finite and $r,s < \infty$.  Then $r = (G:H)$ and $s = (H:K)$.  Note that $\cup_{j=1}^s b_jK = H$, so $\{a_iH| i = 1, 2, \cdots, r\} = \{a_i(\cup_{j=1}^s b_jK)| i = 1, 2, \cdots, r\}$.  Similarly we have that $\cup_{i=1}^r\left[a_i\left(\cup_{j=1}^s b_jK\right)\right] = G$.  Note that for each $i$, we have $a_i\left(\cup_{j=1}^s b_jK\right)$ is distinct via assumption.  Now suppose that there exists integers $1\leq m < n \leq s$ such that $a_ib_mK = a_ib_nK$.  Since $a_i \in G$ and $G$ is a group, via group cancellation law we have $b_mK = b_nK$. This is a contradiction as we assumed the left cosets of $K$ are distinct.  Thus for all $i,j$ we have $a_ib_jK$ are distinct.  Therefore, as all are distinct and $\cup_{i=1}^r\cup_{j=1}^s a_ib_jK = G$, we see that $S = \{a_ib_jK | i=1,2,\cdots, r; j=1,2,\cdots, s\}$ is the collection of distinct left cosets of $K$ in $G$ and $(G:K) = |S|$ where $|S| = rs = (G:H)(H:K)$.  Thus $(G:K)$ is finite and $(G:K)=(G:H)(H:K)$. Any advice would be appreciated, thanks!","['abstract-algebra', 'group-theory']"
2848191,Number of triples of divisors who are relatively prime as a triple,"Given a number $n \in \mathbb{N}$, define $a(n)=\{(d_1,d_2,d_3): d_i|n,\ \gcd(d_1,d_2,d_3)=1,\ 1 \leq d_1 \leq d_2 \leq d_3\}$. What is $|a(n)|$? There were similar questions asked about pairs rather than triples here: Number of pairs of nontrivial relatively prime divisors and here: Number of Relatively Prime Factors but the addition of the third component seems to make the arguments used in these two questions obsolete. An example: Let $n=p$ for some prime $p$. Then the divisors of $n$ are $\{1,p\}$, and the triples of those divisors whom are relatively prime (order does not matter) as a triple are $\{(1,1,1),(1,1,p),(1,p,p)\}$. Thus we see that for any prime, the answer is $|a(n)|=3$. Similarly, (its not hard to check) for $n=p^2$, we have $|a(n)|=6$. In fact, if you let $n=p^k$ for $0 \leq k \in \mathbb{Z}$, it seems that $|a(n)|={{k+2} \choose {2}}$. Also for $n=pq$ where $p$ and $q$ are distinct primes, $|a(n)|=13$ (again, not hard to check). This leads me to believe that like in the other answers for the two referenced questions, the answer may be found using some nice combinatorics, but if looked at just right from a Number Theoretic perspective, may be a multiplicative function or composition of multiplicative functions, based on how the answers seem to only depend on the powers of the primes in the prime factorization of the number.","['gcd-and-lcm', 'number-theory', 'elementary-number-theory', 'combinatorics', 'combinatorial-number-theory']"
2848200,Degree of Field Extension $[\mathbb{Q}(\sqrt[3]{2}):\mathbb{Q}]$,"My problem is understanding how we relate field extensions with the same minimum polynomial. I am running into some problems understanding some of the details of the field extension $\mathbb{Q}(2^{\frac{1}{3}})$ over $\mathbb{Q}$ and similarly $\mathbb{Q}(2^{\frac{1}{3}}, \omega)$ over $\mathbb{Q}(2^{\frac{1}{3}})$. From my understanding of the degree of a finite field extension, the degree is equal to the degree of the minimum polynomial for the root $2^{\frac{1}{3}}$. Now this has the minimum polynomial $p(x) = x^3 - 2$. So by my understanding of the this definition, we should have $[\mathbb{Q}(2^{\frac{1}{3}}):\mathbb{Q}] = 3$. But $p(x)$ has two additional roots which do not exist in the field in $\mathbb{Q}(2^{\frac{1}{3}})$ but do exist in the field extension $\mathbb{Q}(2^{\frac{1}{3}}, \omega)$ where $\omega = e^{\frac{2}{3}\pi i}$. But then the minimum polynomial of $\mathbb{Q}(2^{\frac{1}{3}}, \omega)$ is still our $p(x) = x^3 - 2$. To me, this seems to imply that $[\mathbb{Q}(2^{\frac{1}{3}}, \omega):\mathbb{Q}] = 3$. I also know and understand that for finite field extensions that 
$$[\mathbb{Q}(2^{\frac{1}{3}}, \omega):\mathbb{Q}] = [\mathbb{Q}(2^{\frac{1}{3}}, \omega ):\mathbb{Q}(2^{\frac{1}{3}})][\mathbb{Q}(2^{\frac{1}{3}}):\mathbb{Q}]$$ But this seems to imply that when solving that $[\mathbb{Q}(2^{\frac{1}{3}}, \omega ):\mathbb{Q}(2^{\frac{2}{3}})] = 1$ which would also imply that $\mathbb{Q}(2^{\frac{1}{3}}, \omega )=\mathbb{Q}(2^{\frac{2}{3}})$. I am almost certain that the last statement is false, but I am unsure where I may be making mistakes with my definitions or applying theorems incorrectly, or if it is just a simple mistake on my part. Thanks!","['minimal-polynomials', 'abstract-algebra', 'extension-field', 'field-theory']"
2848208,"Show that the equation $2x^4-9x^2+4 = 0$ has at least one solution in $(0,1)$","Show that the equation $2x^4-9x^2+4 = 0$ has at least one solution in $(0,1)$. It is not possible to show it by Bolzano's theorem because neither 0 nor 1 are in the given interval, is it? Is there any way to do it other than solving it agebraically or analysing its graph? By the way, the root in $(0, 1)$ is $x = \frac{1}{\sqrt2}$. Thanks in advance.","['continuity', 'calculus', 'functions']"
2848227,Given normal subgroup $\cong \mathbb{Z}$ and Quotient $\cong\mathbb{Z}/n\mathbb{Z}$ determine $G$.,"Let $N$ be a subgroup of $G$ isomorphic to $\mathbb{Z}$. suppose $G/N$ is isomorphic to $\mathbb{Z}/n\mathbb{Z}$. prove that if $n$ is odd, $G$ is abelian. I’ve reduced the problem to showing that if $N$ is central, then $G$ is abelian simply by playing around with the elements. But from there I’m kind of stuck. My main issue is that I cannot find an example of what goes wrong when $n$ is not odd. The only examples for $G$ and $N$ that I can think of are the usual $\mathbb{Z}$ and $n\mathbb{Z}$ respectively, and direct sums like $\mathbb{Z}\times \mathbb{Z}/n\mathbb{Z}$ and $\mathbb{Z}\times ${1}$ respectively. Any help is appreciated.","['abstract-algebra', 'group-theory']"
2848283,Why are power series centered around 0,I was wondering if there was any particular reason that power series are centred around 0. $$\displaystyle f(x)=\sum_{k=0}^{\infty}c_{k}x^{k}\qquad \text{ vs  }\qquad\displaystyle f(x)=\sum_{k=0}^{\infty}c_{k}(x-a)^{k}$$ when using them to solve differential equations. I've tried looking online for a reason but so far have had no luck. This seems like a rather arbitrary choice that only conveniently simplifies our computation - eg. what if the function is not well-defined at 0 or deviates significantly away from 0? Apologies if this seems like a trivial question - I have not done a differential equations course yet that involves power series. Solutions involving only first-year university maths would be much appreciated.,"['ordinary-differential-equations', 'power-series']"
2848284,OEIS database download [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 5 years ago . Improve this question I am interested in downloading the first 25 integers of each sequence in the OEIS database. My reason for wanting to do so is to find the arithmetic mean of the first integers, the arithmetic mean of the second integers, etc. and then plot these values.  The hope is that there is a relatively smooth curve that emerges for the mean values even though many of these sequences are wildly chaotic.  Similarly I want to find the median, standard deviations, geometric mean and other statistics on these integers. In fact by rounding these values to integers, it would define a new sequence, call it the ""OEIS mean 2018 sequence"" and so forth. Over time the OEIS sequence would change as more sequences are added to the database, hence the date stamp. When I visit the site, I can only download one sequence at a time, which would be way too much effort for all 250,000 (+) sequences.  Is there a way to query the entire database at once?","['oeis', 'sequences-and-series']"
2848368,Why there are only $2$ roots for $f(x) = x^4 + x^2 + \sin x$?,Why there are only $2$ roots for $0 = x^4 + x^2 + \sin x$ ? It is obvious that $x = 0$ is one root but I couldn't prove that there is only one more root for this function,"['roots', 'polynomials', 'calculus', 'functions']"
2848384,How can I prove $\tan15^\circ=2-\sqrt3$ using the triple-angle formulas?,"Prove $\tan15^\circ=2-\sqrt3\,\,$ using following results $$\sin3x=3\sin{x}-4\sin^3x$$
  $$\cos3x=4\cos^3x-3\cos{x}$$ I know that if I substitute $x=15^\circ\,$I can write$$\sin45=3\sin15-4\sin^315$$ $$\cos45=4\cos^315-3\cos15$$ What can I do next? any hints?","['algebra-precalculus', 'trigonometry']"
2848410,"If a function on a product space is continuous in each variable, is it locally bounded?","Let $f : \mathbb R \times \mathbb R \to \mathbb R$ be continuous when we fix one variable. Then $f$ need not be continuous (see e.g. Functions continuous in each variable ). Does it imply that $f$ is locally bounded? I would be surprised, but couldn't immediately think of a counterexample. Context: I'm interested in $f : \mathbb R \times \mathbb C \to \mathbb C$ that are continuous in the first and analytic in the second variable. In this case, Cauchy's integral formula + Dominated convergence tells us that locally bounded implies jointly continuous.","['continuity', 'product-space', 'real-analysis']"
2848417,why the integral $\int_{n=0}^{\infty} \frac{dx}{x^8 + \sqrt{x}}$ is converge?,"How to show that this integral $\int_{n=0}^{\infty} \frac{dx}{x^8 + \sqrt{x}}$ is divergent? I try using $g(x)=\frac{1}{x^8}$ and then $\lim_{x \to {\infty}} \frac{\frac{dx}{x^8 + \sqrt{x}}}{\frac{1}{x^8}}$ = L (L-constant), but  $\int_{n=0}^{\infty} \frac{dx}{x^8}$ is divergent, so my answer is diverge, but the correct one is converge, Why?","['integration', 'infinity', 'calculus', 'limits']"
2848420,What is the easiest way to find the number of isomorphic subgroup?,"Find the number of subgroups of $\mathbb{Z}_{100}\times\mathbb{Z}_{500}$ are isomorphic with $\mathbb{Z}_{25}\times\mathbb{Z}_{25}$. Using the order of elements in $\mathbb{Z}_{100}\times\mathbb{Z}_{500}$, it  was so tedious work for me. Is there an another way to solve the above problem?","['abelian-groups', 'group-theory', 'group-isomorphism']"
2848441,Compute $\int_{0}^{\pi/4}\ln(1-\sqrt[n]{\tan x})\frac{dx}{\cos^2(x)}$,"I am trying to compute this $$
\int_{0}^{\pi/4}\ln(1-\sqrt[n]{\tan x})\frac{\mathrm dx}{\cos^2(x)},\qquad
(n\ge1).
$$ Making a transformation of $I$ to utilise a sub of $u=1-\sqrt[n]{\tan x}$ \begin{align}
I&=\int_{0}^{\pi/4}\frac{\sec^2(x)}{n\sqrt[n]{\tan x}}\cdot n\sqrt[n]{\tan x}\cdot\ln(1-\sqrt[n]{\tan x})\,\mathrm dx
\\[6px]
&\qquad\mathrm dx=-\frac{n\sqrt[n]{\tan x}}{\sec^2(x)}\,\mathrm du
\\[6px]
I&=n\int_{0}^{1}(1-u)^{n-1}\ln u \,\mathrm du
\end{align} This can be easily done by integration by parts, but I seem to shruggle in somewhere in evaluating it, $$
\int(1-u)^{n-1}\ln u \,\mathrm du=
n(1-u)^n\ln u-\frac{1}{n^2}\int \frac{(1-u)^n}{u}\,\mathrm du
$$","['integration', 'definite-integrals', 'trigonometric-integrals', 'calculus']"
2848504,Proof of lemma about power set and one question.,"I am new here. I am during my PhD studies in theoretical physics and in order to understand one property of given theory, I need to understand proof of lemma: $|P(A)|=|\{0,1\}^A|$. To understand topological aspects of filed theory, that I am investigating, I require more knowledge about set theory. Could you recommend me some books ? My passion is pure mathematical physics, so I am not afraid of advanced calculations, but I am type of person, who needs every proof written clearly. I have earned a Master's degree in technical physics ( although my thesis was about differential geometry in quantum systems) and sometimes I lack pure mathematical knowledge and have to fill the gap on my own. Thank you in advance.","['reference-request', 'elementary-set-theory']"
2848523,Counter example of Lusin's theorem,"The characteristic function of rationals in [0, 1] satisfies the hypothesis of Lusin's theorem. But it is no-where continuous on [0, 1]. But Lusin's theorem implies that it should be continuous on a positive measure subset of [0, 1]. What am I missing here?",['analysis']
2848543,"Is the set $\{(x,y)| x^2+y^2 = \frac{1}{n^2}, n \in \Bbb{N}, x\in \Bbb{Q}$ or $y \in \Bbb{Q}\}$ countable?","I was thinking about the set $\left\{(x,y)\,\middle|\,x^2+y^2 = \frac{1}{n^2}, n \in \Bbb{N}, x\in \Bbb{Q}\text{ or }y \in \Bbb{Q}\right\}$ Certainly, this set is non-empty as I can find a pair $\left(\frac{1}{n^2},0\right)$ or like $\left(\frac{1}{2n^2},\frac{1}{2n^2}\right)$ or in a more genral sense the points of the form $\left(\frac{a}{n^2},\frac{b}{n^2}\right)$ where $a+b = 1, a,b \in \Bbb{Q}$ , so hence I think it's a countable set? But there may be some irrational coordinates involved which can make the set uncountable?. Can we rule out this possibility?","['rational-numbers', 'elementary-set-theory']"
2848545,On the integral $\int_1^\infty\big(\{x\}^n-\frac1{n+1}\big)\frac{dx}x$,"According to Dirichlet's test (integral version), $$
I_n=\int_1^\infty\big(\{x\}^n-\frac1{n+1}\big)\frac{dx}x
$$ converges, where $n$ is a positive integer and $\{x\}$ denotes the fractional part of $x$ .  Using series, I found out the values of $I_1$ and $I_2$ . $I_1=\frac12\ln(2\pi)-1$ and $I_2=\frac12\ln(2\pi)-\frac12-2\ln A$ , where $A$ denotes Glaisher's constant. My Attempt to Generalize $I_n$ $$I_n=\sum_{m=1}^\infty\int_0^1\big(t^n-\frac1{n+1}\big)\frac{dt}{t+m}\\
=\sum_{m=1}^\infty P_n(m)-\frac1{n+1}\ln\big(1+\frac1m\big)+m^n(-1)^n\ln\big(1+\frac1m\big)\\
=\sum_{m=1}^\infty-\frac1{n+1}\ln\big(1+\frac1m\big)+\frac1{(n+1)m}-\frac1{(n+2)m^2}+\cdots\\
=\frac\gamma{n+1}+\sum_{k=2}^\infty\frac{(-1)^{k-1}\zeta(k)}{n+k}$$ where $P_n$ is a polynomial with $\deg P_n=n-1$ and $\gamma$ denotes Euler's constant. My questions are: (i) Is my answer right? (ii) If my answer is right, can I make it a little bit more
  simplified? (iii) How to find the value of $I_3$ ? Edit: the convergence test of $I_n$ Denote $F(x)=\int_1^x\{t\}^n-\frac1{n+1}dt$ , we have $$F(x+1)-F(x)=\int_x^{x+1}\{t\}^ndt-\frac1{n+1}=0.$$ Obviously, $F(x)$ is bounded in $[0,1]$ . So $F(x)$ is bounded in $\mathbb{R}$ . Also, $1/x$ is a decreasing function in $[1,+\infty)$ and $\lim_{x\to\infty}1/x=0$ Hence $I_n$ converges.","['riemann-zeta', 'summation', 'definite-integrals', 'calculus']"
2848599,Conditional Expectation and Probability Formulations of Markov Property and Strong Markov Property,"I have seen the Markov Property stated in a variety of ways. I'm trying find the equivalence between the two statements below, but I'm having a tough time: The Markov Property of Brownian Motion started at $a \in \mathbb{R}$ is  stated as:
  $$\mathbf{E}^a[B_{t+s}|\mathcal{F}_s] = \mathbf{E}^{B_s}[B_t]$$
  where the notation $\mathbf{E}^a$ means expectation with respect to $\mathbf{P}^a$. And separately: Fix $t_0 \in T \subset \mathbb{R}^{+}$ and consider a process:
  $$B'_t(\omega) = B_{t_0+t}(\omega) - B_{t_0}(\omega)$$
  Then $(B'_t)_{t \geq 0}$ is a Brownian motion and independant of $\mathcal{F}_{t_0}$. This is to say for any $A\subset \mathbb{R}^n, M \subset \mathcal{F}_{t_0},$ and any $0 \leq t_0 \leq t_1 \leq ... \leq t_k$:
  $$\textbf{P}(\{B'_{t_1},...,B'_{t_k}\} \in A \cap M) = \textbf{P}(\{B'_{t_1},...,B'_{t_k}\} \in A) \textbf{P}(M) = \textbf{P}(\{B_{t_1},...,B_{t_k}\} \in A) \textbf{P}(M)$$ I think this post is relevant, but I haven't able to get enough out of it: (Elementary) Markov property of the Brownian motion I have a similar question about the strong Markov property. Perhaps if someone offers a hint/suggestion/reference I'll try this myself before asking.","['stochastic-processes', 'probability-theory', 'markov-process', 'brownian-motion']"
2848607,"Calculate $E(\max (X,Y) \mid X) $ if $X$ and $Y$ are independent and exponential distributed","Let $X,Y$ be independent and both $\text{Exp}(\lambda)$ distributed. How does one calculate $$E(\max (X,Y)\mid X)\,?$$ By independence  $\max (X,Y)$ is $\text{Exp}(2\lambda) $ distributed but I do not see how to continue. I am aware of memorylessness of exponential distribution. Help is welcome!","['probability-theory', 'conditional-expectation', 'probability', 'probability-distributions']"
2848614,"If I know the law of $a X+bY$ for all $a,b \in \mathbb{R}$, do I know joint law of $(X,Y)$?","Given two random variables $X,Y$. Suppose that know the law of each $aX+bY$ for $a,b \in \mathbb{R}$. Can I recover their joint law? It is clear that the other way around is possible. If $(X,Y)$ is a Gaussian vector, I could compute their covariance using the trick
$$
   \mathbb{ E}(XY)= \frac{1}{4}E(X+Y)^2-\frac{1}{4}E(X-Y)^2,
$$
and as I know their marginal laws, I can characterise the whole vector. Can I somehow do the same in case $X,Y$ are not Gaussian? Maybe supposing that they have finite moments of every order, maybe even suppose they are the r.v's are bounded? EDIT: Can I extend this to $n$ random variables?","['probability-theory', 'probability', 'random-variables', 'probability-distributions']"
2848654,How can I apply the law of large numbers here?,"I have a finite set $\lbrace r_i \rbrace_{i \in \Lambda}$ with $0 < r_i < 1$ for each $i$. Each $r_i$ has a probability $p_i$ associated to it. I define 
$$
r = \prod_{i \in \Lambda}r_i^{p_i}
$$
so that $\log r = \sum_{i \in \Lambda} p_i \log r_i$. Then it is claimed that by the law of large numbers, with probability tending to $1$, the random element $r_I = r_{i_1} \cdot \ldots\cdot r_{i_n}$ chosen with probability $p_I = p_{i_1} \cdot \ldots \cdot p_{i_n}$ satisfies 
$$
r_I = r^{n(1 + o(1))}.
$$ In other words, we claim that when $n$ is large, $r_I = r^n$ almost surely. How can I see this? I can calculate the expected value of $\log r_I$ which is $\log r^n$ but does the law of large numbers not apply into the mean of a sum of random variables? How can I say anything about this single variable? (The notation $o(1)$ stands for a quantity tending to $0$ as $n \to \infty$.) EDIT: In which variables am I even using the law on? The conclusion is about $r_I$ which is a singe RV $I \mapsto \mathbb{R}$. Can I present it as a mean of some other variables with expected value $r^n$? EDIT2: $\log r_I = \sum_{k=1}^n \log r_{i_k}$ and since $\mathbb{E}(\log r_{i_k}) = \log r$, I have $\dfrac{\log r_I}{n} \to \log r$ a.s. EDIT3: Oh wait I solved it, never mind","['probability', 'measure-theory']"
2848662,Does $\int_{-x}^{x}f(t)dt=0$ implies $f$ to be an odd function?,"I know that for $\quad f:\mathbb{R}\rightarrow \mathbb{R}\quad$ continuous,     $$\int_{-x}^{x}f(t)dt=0 \quad \text{for all } x \in \mathbb{R} \implies f(-x)=-f(x) \quad \text{for all } x \in \mathbb{R}.$$
But is the above true for general function on $\mathbb{R}$? More precisely is the following true: Question: For any Riemann integrable function $\quad f:\mathbb{R}\rightarrow \mathbb{R}$, $$\int_{-x}^{x}f(t)dt=0 \quad \forall \quad x\in \mathbb{R} \implies f(-x)=-f(x) \quad \forall \quad x\in \mathbb{R}.$$
Thanks in advance for any help.","['real-analysis', 'calculus']"
2848672,Notation for a matrix populated with a Cartesian product of sets,"I have several sets, e.g. $$A_1 = \{1,2,3\}$$
$$A_2 = \{a,b,c\}$$
$$\vdots$$
$$A_P = \{\alpha,\beta\}$$ And their Cartesian product:
$$A_1 \times A_2 \times \dots \times A_P = \{(a_1,a_2,\dots,a_P) \mid  a_1 \in A_1, a_2 \in A_2, \dots, a_P \in A_P\}$$ What would be a proper way to indicate that the following matrix is populated by the ordered elements from the Cartesian product above? $E_{N\times P} = $ \begin{bmatrix} 
		\epsilon_{1,1} & \epsilon_{1,2}  & \dots & \epsilon_{1,P}\\
		\epsilon_{2,1} & \ddots  & &\epsilon_{2,P}\\
		\vdots &   &  &\vdots\\
		\epsilon_{N,1} & \epsilon_{N,2}  & \dots & \epsilon_{N,P}\\
\end{bmatrix} A concrete example with only the three sets above would lead to the following $18\times3$ matrix: \begin{bmatrix} 
		1 & a  & \alpha\\
		1 & a  & \beta\\
		1 & b  & \alpha\\
        1 & b  & \beta\\
		1 & c  & \alpha\\
        1 & c  & \beta\\
        2 & a  & \alpha\\
        \vdots&\vdots&\vdots\\
        3 & c  & \alpha\\
        3 & c  & \beta\\
\end{bmatrix} I'm looking either for a mathematical expression, or a simple sentence. So far I have: The rows of $E_{N\times P}$ are populated by the ordered elements in the
  Cartesian product of the sets $A_p, \forall p=1,...,P$. But I feel that's a bit heavy and perhaps incorrect (i.e. not sure how to express the idea of ""ordered elements"" referring to the order in the example).","['matrices', 'notation', 'elementary-set-theory']"
2848709,Largest power of $3$ that divides $999\dots 999$ ($300$ $9$'s),"What is the largest power of $3$ that divides $999\dots 999$ ($300$ $9$'s)? I have looked at the pattern of $9$, $99$, $999$, $9999$, $99999\dots 999999999$ and found the pattern that the largest power of $3$ that divides is: $2, 2, 3, 2, 2, 3, 2, 2, 4$ How would I work with prime factorization of this large power of $3$ that divides $999\dots 999$ ($300$ $9$'s)?",['number-theory']
2848713,Every sequence has a weakly convergent subsequence with limit,"Let $\mathbf{E}$ be a reflexive space and $\mathbf{A ⊂ E}$ be bounded and weakly closed. Show that $\mathbf{A}$ is sequentially compact, i.e., every sequence in $\mathbf{A}$ has a weakly convergent subsequence with limit in $\mathbf{A}$. This statement is a special case of the Eberlein-Smulian Thoerem, which you are not allowed to use in this task. Hint: First assume that $\mathbf{E}$ is separable. I just can solve it with this Eberlein Smulian Theorem and I think my other second approach is wrong... Has anybody a solution with an explication, why I should assume, that $\mathbf{E}$ is separable. I also saw a proof of this here Every bounded sequence has a weakly convergent subsequence in a Hilbert space , but there they start with a Hilbert space? Hilbert space is reflexive but not the other way. Or is there no connection?","['functional-analysis', 'reflexive-space', 'compactness', 'sequences-and-series']"
2848738,Vector fields on projective space,"Let $k$ be a field and $ X = \mathbb{P}^n_k $. I have read that every vector field on $ X $, i.e. every global section of $ \mathcal{T}_X = \mathbf{Hom}_{\mathcal{O}_X}(\Omega^1_{X/k},\mathcal{O}_X) $ is induced by a $ k $-derivation $ E : k(x_0,\dots, x_n) \to k(x_0,\dots, x_n) $ with $ E(x_i) $ being homogeneous linear for all $i$. Indeed given such a derivation on $ D_+( x_j ) \subset \mathbb{P}^n_k$ we can define a derivation on $$ k[x_0/x_i,\dots,x_n/x_i] \to k[x_0/x_i,\dots,x_n/x_i] \\  
 \frac{x_i}{x_j} \to \frac{x_j E(x_i) - x_i E(x_j)}{x_j^2} $$
and these glue together. However I don't know exactly how to  argue that all vector fields are induced this way. Given a vector field $V$ and $ f/g \in k(x_0,\dots,x_n)^0 $ ($f,g$ are homogeneous of same degree) let $ A = k[x_0,\dots,x_n,1/g]^0 $. 
Then $D_+(g) = \text{Spec}(A)$. We have 
$$ V(D_+(g)) \in \text{Der}_k(A,A) $$ We can see this for all $g$. Hence $V$ is induced by a $k$-derivation of $k(x_0,\dots,x_n)^0$. But why is this one induced by a derivation $ E $ of $ k(x_0,\dots,x_n) $ and why is $E(x_i) $ linear homogeneous?","['vector-fields', 'algebraic-geometry']"
2848745,Dirac Delta functions and Sobolev Embeddings,"This is a question about the action of the Dirac delta on Sobolev spaces $H^s(\mathbb{R}^d) = W^{s,2}(\mathbb{R}^d)$. We know that $\delta(\underline{x})\in H^s(\mathbb{R}^d)$ for $s<-d/2$. In 2D, consider $v \in H^2(\mathbb{R}^2)$. Since $\delta(\underline{x})\in H^{-2}(\mathbb{R}^2)$ (the dual of $H^2(\mathbb{R}^2)$), the Dirac delta acts on $v$ as
$$\int_{\mathbb{R}^2} \delta(\underline{x}) v(\underline{x}) \; \mathrm{d}\underline{x} = v(\underline{0}).$$
Furthermore, in 2D, we have the Sobolev embedding $H^2(\mathbb{R}^2) \subset C^0(\mathbb{R}^2)$, so the value of $v$ at $\underline{0}$ is well-defined. However in 3D I am a bit confused: Take $v \in H^2(\mathbb{R}^3)$, and we still have $\delta(\underline{x})\in H^{-2}(\mathbb{R}^3)$. The action of $\delta$ on $v$ should be well-defined as above. However, in 3D we know that $H^2(\mathbb{R}^3) \not\subset C^0(\mathbb{R}^3)$, so I can't see how the answer of $v(\underline{0})$ is well-defined as we shouldn't be able to talk about point values of $v$. Thanks.","['functional-analysis', 'real-analysis', 'sobolev-spaces', 'dirac-delta']"
2848759,When is a group isomorphic to the infinite cyclic group?,"I am learning algebra and I am a bit confused. Let's say I have a finitely presented group $G$, can anyone tell me if it is possible to find out if $G\cong \mathbb{Z}$? Thanks","['combinatorial-group-theory', 'abstract-algebra', 'group-theory']"
2848802,Number of possible functions,"The number of possible continuous functions $f(x)$ defined on $[0,1]$ for which $I_1 = \int_0^1 f(x)dx=1$, $I_2 = \int_0^1 xf(x)dx= a$ , $I_3=\int_0^1 x^2 f(x)dx= a^2$ is/ are? I have seriously no idea how to attempt this problem and find the number of functions. I was trying some integration by parts for I2, I3 but that really didn't help.","['integration', 'definite-integrals', 'functions']"
2848829,A convergent sum of a divergent and convergent sequence?,"Is the following argument correct? Sequences $(x_n)$ and $(y_n)$, where $(x_n)$ converges, $(y_n)$
  diverges, and $(x_n+y_n)$ converges. Proof. The request in question is impossible. Assume that we have sequences $(x_n)$ and $(y_n)$ such that $(x_n)\to \alpha$, $(y_n)$ diverges and yet $(x_n+y_n)\to\beta$ where $x,\alpha\in\mathbf{R}$. Then by combining the first two propositions of theorem $\textbf{2.3.3}$ we have $\lim(y_n) = \lim((x_n+y_n)-x_n) = \beta-\alpha$, contradicting our assumption that $(y_n)$ was not convergent. $\blacksquare$ Note: The propositions in question are that Given $(a_n)\to a$ and $(b_n)\to b$ it follows that $\lim ca_n = ca,\forall c\in\mathbf{R}$ and $\lim(a_n+b_n) = \lim a_n+\lim b_n$","['real-analysis', 'limits', 'sequences-and-series', 'proof-verification', 'convergence-divergence']"
2848845,Does existence of $\lim_{x \to 0} f(x)$ imply $\lim_{x \to 0} x f'(x) = 0$?,"Suppose we have a function $f : \mathbb{R}^+ \to \mathbb{R}$.  It seems intuitive to me that if $\lim_{x \to 0} f(x)$ exists, then $\lim_{x \to 0} x f'(x) = 0$.  I suspect that for real functions, there may be pathological counterexamples to this, but at least for analytic functions (where $0$ may be on the boundary of the analytic disk) then it should be true. In the analytic case, I can give an argument for this that would convince a typical physicist like myself.  $f(x)$ cannot have an essential singularity at $0$, because  $\lim_{x \to 0} f(x)$ would not exist.  So as $x \to 0$, it scales like $f(x) = c + O( x^\alpha )$ for some constant $c$ and $\alpha > 0$, since the limit exists.  Therefore, $x f'(x) = O( x^\alpha ) \to 0$. Two questions: Is this true, and if so, how generally valid is it? Is there a simpler proof that does not rely on scaling arguments?  This seems like the kind of problem that one would typically address with a fairly general theorem like L'Hospital's rule.  Another strategy is to write $xf'=(xf)'-f$, but this just shifts the burden of the problem to showing that $\lim_{x \to 0}[xf(x)]'=\lim_{x \to 0} f(x)$.  I am guessing that the solution is totally obvious and I am just not seeing it.","['real-analysis', 'limits']"
2848872,"If $F^*\alpha=\alpha$, then $F$ is the cotangent lift of some $\phi$","Let $Q$ be a smooth manifold, $\alpha\in\Omega^1(T^*Q)$ the tautological $1$-form and $\omega:=-d\alpha$. Suppose there is a diffeomorphism $F:T^*Q\to T^*Q$ such that $F^*\alpha=\alpha$. Prove there is a diffeomorphism $\phi:Q\to Q$ such that $F$ is the cotangent lift of $\phi$. Suggested plan: 1) Prove that the Euler field $X$ (defined by $i_X\omega =-\alpha$) is invariant under $F$, i.e., $dF(X)=X\circ F$. 2) If $\phi_t^X$ is the flow of $X$, prove that $\phi_t^X\circ F=F\circ\phi_t^X$ and that $\phi_t^X(x,\xi)=(x,e^t\xi)$ locally. 3) Verify that $F(\lambda m)=\lambda F(m)$ for all $m\in T_q^*Q$, $\lambda\in\mathbb{R}$. Conclude there exists $\phi$ such that $\phi\circ\pi=\pi\circ F$ and that $F$ is the cotangent lift of $\phi$. I've already gone through $1)$ and $2)$ but I'm stuck with $3)$. Here where I'm at: for $\lambda>0$, we have:
$$F(\lambda m)=F(x,\lambda\xi)=F(x,e^{ln(\lambda)}\xi)=F\circ\varphi_{ln(\lambda)}^X(x,\xi)=\varphi_{ln(\lambda)}^X\circ F(x,\xi)=\lambda F(m)$$
By continuity, that also covers the case $\lambda=0$, but I don't know what to do when $\lambda<0$. I tried doing $F(\lambda p)=F(-\lambda(-p))=-\lambda F(-p)$, but I can't prove $F(-p)=-F(p)$. I know how to prove that if such a $\phi$ exists it must be a diffeomorphism. My problem is to define $\phi$ and to check $F$ is its cotangent lift. If I could prove $F$ is linear on the fibers, then I could just define $\phi:=\pi\circ F\circ \eta$, where $\eta:Q\to T^*Q$ is any $1$-form in $Q$, but I wasn't able to prove the aditive property (i.e., $F(v+w)=F(v)+F(w))$. Besides, the exercise appararently suggests we only need the scaling property, which is also confusing me. For $F$ being the cotangent lift, I'm also stuck.","['symplectic-geometry', 'differential-geometry']"
2848875,Digits: Convergence of number of $00$,"Let $n\ge2$ and $X_1,X_2,\ldots,X_{n+1}$ be i.i.d  Bernoulli sequence $\mathcal{B}(\frac1{2}).$ Let $N=\sum_{i=1}^n Y_i$ be the number of $00$ in the sequence i.e. $Y$ is a discrete random variable such that $$Y_i=1 \;\mbox{if}\; X_{i}=0\;\mbox{and}\; X_{i+1}=0; \quad Y_i=0\; \mbox{otherwise}.$$ Does $$\frac{N-E(N)}{\sqrt{V(N)}}\overset{d,n\to\infty}{\to} \mathcal{N}(0,1)?$$ I cannot apply the CLT because $Y_i$ are dependent.","['probability-theory', 'normal-distribution', 'probability-distributions']"
2848881,the probability of those n broken parts of sticks to form a closed polygon? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question Suppose I have a stick of L length . It is divided into uniformly randomly into n parts. What is the probability of those n parts to form a closed polygon ? It will be helpful if anyone show the steps to proceed with this problem.","['probability', 'polygons']"
2848882,Is the spectrum of an unbounded self-adjoint operator always an unbounded set?,For a bounded self-adjoint operator $A$ on a Hilbert space $H$ we know that the spectrum is a compact subset of $\mathbb R$ with spectral radius given by the operator norm of $A$. Now assume that $A$ is a densely defined unbounded self-adjoint operator. Can we conclude that the spectrum of $A$ is an unbounded set of the reals?,"['functional-analysis', 'spectral-theory', 'operator-theory']"
2848891,Number of solutions of $\left\{x\right\}+\left\{\frac{1}{x}\right\}=1$,"Find the number of solutions of $$\left\{x\right\}+\left\{\frac{1}{x}\right\}=1,$$ where $\left\{\cdot\right\}$ denotes Fractional part of real number $x$. My try: When $x \gt 1$ we get $$\left\{x\right\}+\frac{1}{x}=1$$ $\implies$ $$\left\{x\right\}=1-\frac{1}{x}.$$ Letting $x=n+f$, where $n \in \mathbb{Z^+}$ and $ 0 \lt f \lt 1$, we get $$f=1-\frac{1}{n+f}.$$ By Hint given by $J.G$, i am continuing the solution: we have $$f^2+(n-1)f+1-n=0$$ solving we get $$f=\frac{-(n-1)+\sqrt{(n+3)(n-1)}}{2}$$ $\implies$ $$f=\frac{\left(\sqrt{n+3}-\sqrt{n-1}\right)\sqrt{n-1}}{2}$$ Now obviously $n \ne 1$ for if  we get $f=0$ So $n=2,3,4,5...$ gives values of $f$ as $\frac{\sqrt{5}-1}{2}$, $\sqrt{3}-1$, so on which gives infinite solutions.","['algebra-precalculus', 'ceiling-and-floor-functions', 'systems-of-equations']"
2848895,"What is a ""very bad"" singularity?","In page 94, example 4.42 of Milne's notes on algebraic geometry, he mentions that the singularity at $(0,0)$ is ""very bad"". The surface is $ V: Z^3 = X^2Y $, which has singular locus $ X = Z = 0 $. What does he mean by this? The tangent space is $ \mathbb{A}^3 $, does this have something to do with the tangent cone?",['algebraic-geometry']
2848928,Prove a rank equality for PSD matrices,"(To make things a bit easier perhaps, we assume that $A,B$ are symmetric at least. If you find out that this assumption can be dropped, please also give your stronger version of course.) Prove that: $B$ is PSD (positive semi-definite) iff for any $A$ PSD we have
$$r(A+B)=r([A |B])$$
where $r$ denotes the matrix rank and $|$ denotes matrix concatenation. This might be one of the few times that I haven't had any clue to the problem I'm asking on this site. Any help?","['matrices', 'positive-definite', 'linear-algebra']"
2848930,Question about conformal mapping,"Let $y_a(t):U \to \mathcal{C}$ be any comformal mappitn taking $U \in  \mathcal{C}$ (simply conected domeain ) into a unit disc $D$ and the a point $a\in U$ into its center, $y_a(a)=0$. Now define a relative diameter of a compact set $K$ with respect to set $U$ as 
\begin{align}
R(U,K)= \max_{a,t \in K} |y_a(t)|.
\end{align} My question: Let $U$ be a disc of radius $R$ centered at the orign and $K$  a disc of radius $r$ centered at the origin where $r<R$.  What is the value of $R(U,K)$? I think $R(U,K)$ is equal to $ \frac{2 r}{R}$. However, I am not sure how to start this problem. Specifically, I am not sure how to characterize the mapping $y_a(t)$. Edit: I would also be happy with an upper bound on $R(U,K)$.","['complex-analysis', 'analysis']"
2848941,What is the difference between Relation and Cartesian product?,"I'm confused with Cartesian product and Relation. As in Cartesian product, the number of ordered pair possible are $n(A)n(B)$. In relation the number of relation possible are $2^{n(A)  n(B)}$. Also, it is said that Relation is a subset of the Cross Product.
But what I see is the opposite. Ex: 
if $n(A) = 2$, $n(B) = 3$. then $n(A \times B) = 6$. Relation is $2^6 = 64$","['relations', 'elementary-set-theory']"
2848971,What is the measure-theoretic definition of the conditional Wiener measure?,"The Wiener measure $W$ on the space of (continuous, a posteriori) curves defined on $[0,t]$ is uniquely characterized by being Borel and having prescribed pushforwards (that I shall not write here). It is immediate that $W$ is concentrated on the space of curves that start in $0 \in \mathbb R^n$ at time $0$. What is the rigorous definition of the conditional Wiener measure? Intuitively, I understand the conditional Wiener measure $W_p$ to be a Borel measure, with very similar pushforwards (I know them, I shall not write them here), but concentrated on the curves that also have the endpoint fixed: at time $t$ they arrive in $p \in \mathbb R^n$. It follows that $\int _{\mathbb R^n} W_p (A) \ \mathrm d p = W(A)$ for all Borel subsets $A$ of the space of curves. The problem is that this cannot be a definition, because nothing guarantees the uniqueness (and pointwise existence) of the disintegration $p \mapsto W_p$ of $W$ like in the formula above (the disintegration theorem does provide uniqueness almost everywhere , but under assumptions about the pushforward of $W$ that are definitely not met here). (Please provide measure-theoretic explanations, not probabilistic ones, because I am not familiar with the probabilistic language.)","['stochastic-processes', 'probability-theory', 'probability', 'measure-theory', 'brownian-motion']"
2848999,"Density of the sequence $\sqrt2^{\,n}$ modulo 1","I want to know whether the fractional parts of the sequence $i\mapsto \sqrt{2}^i$ are dense in $[0, 1)$. Obviously this is the same as the sequence $i\mapsto \sqrt{2}\cdot2^i$. I did the obvious thing and recasted the problem as asking whether in the $\textit{binary expansion}$ of $\sqrt{2}$, $\exists$ L such that every finite string of $0$'s and $1$'s of length $\geq L$ appears somewhere in that expansion. I have no idea how to prove this, or what tools I have. I know that the normality of $\sqrt{2}$ is unproved as of yet, but normality is much stronger than what I want. Am I missing something obvious, or is this problem really nontrivial? EDIT: Here's a similar question with some more comments: The density --- or otherwise --- of $\{\{2^N\,\alpha\}:N\in\mathbb{N}\}$ for ALL irrational $\alpha$. . Can anyone explain to me why his theorem on $O_n$ is untrue for $n>2$?","['number-theory', 'ergodic-theory', 'irrational-numbers']"
2849013,Prove matrix $A$ is diagonalizable if and only if each eigenvalue has equal geometric and algebraic multiplicity.,"Prove: If $A$ is an $n\times n$ matrix with distinct eigenvalues $\lambda_1, \dots, \lambda_k$, then $A$ is diagonalizable if and only if $g_{\lambda_i}=a_{\lambda_i}$ for $1\le i \le k$. I have seen and understood a proof for $\sum g_{\lambda_i}=n=\sum a_{\lambda_i}$ but nothing for the equality of each distinct eigenvalue.","['matrices', 'diagonalization', 'eigenvalues-eigenvectors', 'linear-algebra']"
2849039,Why ordered n-tuple can be defined as a surjective function?,"I was doing this exercise and didn't understand why it specifically defined a ordered n-tuple as a surjective function rather than just a function or injective function?
The answer of this question mentioned this definition too, but I'm not sure whether I understood what this answer said. Ordered Pairs (Ordering multiple elements)","['elementary-set-theory', 'functions']"
2849050,"What is a pullback of a metric, and how does it work?","The term ""metric"" is familiar, but not the idea of a pullback on it. I have tried to find intuitive, beginner-friendly explanations of this concept without success. Your attempts would be appreciated. Pictures and concrete examples would be wonderful, if possible. I have not studied much topology or differential geometry before, but know some really early engineering/physics math (linear algebra, multivariate and vector calculus etc.) Analogies to these areas would be great.","['riemannian-geometry', 'curvature', 'pullback', 'metric-spaces', 'differential-geometry']"
2849071,How to prove that $\lim_{x \to \infty}\int_{x}^{x+1}\frac{{t^2}+1}{{t^2}+{20t}+8}dt=1$?,"What I did to prove that $\lim_{x \to \infty}\int_{x}^{x+1}\frac{{t^2}+1}{{t^2}+{20t}+8}dt=1$ is: Because in the integrals ${x \to \infty}$, then the constant & ${constant*t}$ will not impact the ${t^2}$ so we can eliminate them and we get $\lim_{x \to \infty}\int_{x}^{x+1}\frac{t^2}{t^2}dt=\lim_{x \to \infty}\int_{x}^{x+1}1dt= \lim_{x \to \infty}t|_{x}^{x+1}=lim_{x \to \infty}x+1 -x = lim_{x \to \infty}1 = 1$ Does my solution correct?","['polynomials', 'limits', 'calculus', 'integration', 'infinity']"
2849082,Show: If some $x_i \neq x_1$ occurs as $\sigma(x_1)$ for a $\sigma \in$ Gal$ (E:F)$ then each $x_i\neq x_1$ occurs as $\sigma(x_1)$,"I'm currently studying Galois Theory (or am trying to do so), and since almost two weeks I try over and over again to solve a particular question from a textbook (J. Stillwell, Elements of Algebra, p. 132). Task: Consider the extension $E=F(x_1)$ of $ F=\mathbb{Q}(a_0,...,a_4)$. $x_1$ is a root of the quintic $x^5+a_4 x^4 + ... + a_0 =0$ (the other four roots being depicted as $x_2$ to $x_5$). Show (i) $\sigma \in$ Gal$(E:F)$ is determined by the value $\sigma(x_1)$. (ii) $\sigma(x_1)$ is a root of $x^5+a_4 x^4 + ... + a_0 =0$, hence $|$Gal$(E:F)| <= 5$. (iii) If some $x_i \neq x_1$ occurs as $\sigma(x_1)$ for a $\sigma \in $ Gal$ (E:F)$ then each $x_i\neq x_1$ occurs as $\sigma(x_1)$ It turned out that irreducibility of the quintic over F, although not stated explicitly,
is absolutely necessary for claim (iii) to be true, see comments below. I had little trouble to show (i) and (ii), but (iii) is giving me a headache permanently. Here is what I tried: ==================================================================== (Trial A) Suppose $\sigma(x_1) = x_2$, and $\sigma \in $ Gal$(E:F)$. Then: $\Rightarrow \sigma(f) = f $ for all $ f\in F$ by definition of Galois Groups, and $x_i \in E$ since $\sigma$ is an automorphism on E. $\Rightarrow $ There must be a rational function $q$ of $x_2$ with $x_1 = q(x_2)$, because $x_1$ must be the result for one $\sigma(q(x_1)) = q(\sigma(x_1)) = q(x_2)$ $\Rightarrow x_2 = \sigma(x_1)=\sigma(q(x_2)) = q(x_1)$ and thus: $\sigma^2(x_1)=\sigma(x_2)=q(\sigma(x_1))=q(x_2)=x_1$. Thus $\sigma$ is its own inverse. This was not correct, see comment below. 
Thus the next conclusion is wrong, also. $\Rightarrow $ Now $\{1,\sigma\}$ is closed under multiplication, it is easy to see that it is a group. Although I don't know whether it actually *is* the Galois-Group of E over F, it could be. At least I don't see a reason from here why it shouldn't be fine, or why I would have to include more $x_i$ necessarily. EDIT#2: From this point I tried to construct a counterexample to the statement to be shown, in order to see which are the obstacles. If I have two roots $x_1$ and $x_2$ with a corresponding automorphism, I can choose the other three roots as definitely lying outside of $\mathbb{Q}(a_0,...,a_4,x_1)$. Then with
$ (x-x_1)(x-x_2)(x-x_3)(x-x_4)(x-x_5)$ I have a polynomial with three roots outside of $E$, contradicting the statement to be shown. Reason: if $x_i \notin  E$ there cannot be an automorphism $\sigma \in $ Gal$ (E:F)$ with $\sigma(e) = x_i$ for some $e \in E$. However, the field $F=\mathbb{Q}(a_0, ...a_4)$ is determined by the choice of $x_3, x_4$ and $x_5$, via the $a_i$. Thus it is still possible that I cannot find roots outside $F$ just by this feedback behavior. This would again point towards some argument of the kind: Because two roots are fixed, the others will be in $\mathbb{Q}(a_0, ...a_4)$ since they can be calculated by $x_1$, $x_2$ and the $a_i$. What to do from here...? ==================================================================== (Trial B) The next try was to go over the symmetric elementary polynomials $a_1,...,a_4$. If I assumed two roots $x_1$ and $x_2$ to lie in $E$, is it possible to calculate the other roots from the $a_i$? Well, it seems to be. That means that with $x_1$ and $x_2$ in $E$ all the others would lie in $E$, too, and it remains to show that the corresponding automorphisms exist. But I only could hack it with mathematica, and the result is rather complicated. I doubt that this was the authors intention. Additionally, I cannot see why then it shouldn't be possible to calculate four roots out of $x_1$, with the five elementary polynomials. EDIT#1: I discovered a serious misinterpretation in my Trial B. I can compute expressions $f(a_0, ...,a_4)$ for each $x_3, x_4$ and $x_5$, respectively. But they contain $\sqrt{}$ and $\sqrt[3]{}$ operations, and thus are not in $E = \mathbb{Q}(a_0,...,a_4,x_1)$. If I'm right, this rules out Trial B as an appropriate way to show what is asked. It must have something to do with the automorphisms in general, some symmetry-argument maybe, but I don't know. As I see it according to the solution of Jyrki, the a_i do indeed
determine which x_i are in E and what the automorphisms are. 
But this is shown via the general properties of E, not by direct calculation. Please, can someone help me?","['galois-theory', 'abstract-algebra', 'quintics', 'permutations', 'group-theory']"
2849126,Boil down the formal definition of Euler class,"I read the following formal definition of Euler class see below. Two questions: I suppose that $H^r(F, F \setminus F_0; \mathbf{Z})$ defines the relative cohomology --- why do we need this preciesly? Why do we need $(F, F \setminus F_0)$ to think about the orientation? How should I think about the induced map from $
(X, \emptyset) \hookrightarrow (E, \emptyset) \hookrightarrow (E, E \setminus E_0),
$
to
$
H^r(E, E \setminus E_0; \mathbf{Z}) \to H^r(E; \mathbf{Z}) \to H^r(X; \mathbf{Z})$? And what is the role of the zero section $E_0$ here? The Euler class ''e''(''E'') is an element of the integral [[cohomology]] group
  $$
H^r(X; \mathbf{Z}),
$$
  constructed as follows. An orientation of ''E'' amounts to a continuous choice of generator of the cohomology
  $$
H^r(F, F \setminus F_0; \mathbf{Z})
$$
  of each fiber ''F'' [relative cohomology to the complement ''F''\''F'' 0 of its zero element ''F'' 0 . From the Thom isomorphism, this induces an '''orientation class'''
  $$
u \in H^r(E, E \setminus E_0; \mathbf{Z})
$$
  in the cohomology of ''E'' relative to the complement ''E''\''E'' 0 of the zero section ''E'' 0 . The inclusions
  $$
(X, \emptyset) \hookrightarrow (E, \emptyset) \hookrightarrow (E, E \setminus E_0),
$$
  where ''X'' includes into ''E'' as the zero section, induce maps
  $$
H^r(E, E \setminus E_0; \mathbf{Z}) \to H^r(E; \mathbf{Z}) \to H^r(X; \mathbf{Z}).$$
  The '''Euler class''' ''e''(''E'') is the image of ''u'' under the composition of these maps.","['differential-topology', 'algebraic-geometry', 'characteristic-classes', 'geometric-topology', 'differential-geometry']"
2849165,"If $f^2=f$, then $f$ is of constant rank.","Let $f$ be a continuous function from $[0,1]$ to set of $n\times n$ matrices i.e. $M(n\times n,\mathbb{R})$ such that $f(t)^2=f(t)$ for all $t$. Then  $f(t)$ has a constant rank for all $t$. The only thing that I was able to guess conclude here that $f(t)$ has two eigenvalues, namely $0$ and $1$ with the minimal polynomial $x^2-x$, as if the minimal polynomial is $x$ or $x-1$, we are done. Now what to do afterwards?","['minimal-polynomials', 'real-analysis', 'linear-algebra']"
2849169,Expected number of cycles in random function,"Let f be a left-total function with a discrete domain and codomain both in the range of 0..N . The image of f is chosen randomly (with replacement). Given N, how many cycles is the function expected to contain? Edit: Here's the code from random import randint


def test(N):
    """"""Returns all cycles for a function over 0..N-1""""""
    edges = [randint(0,N-1) for n in range(N)]

    cycles = []

    def cycle(start):
        """"""Find a cycle from a given start point""""""
        current = start
        lst = []
        while True:
            if current in lst:
                lst = lst[lst.index(current):]
                break
            lst.append(current)
            current = edges[current]
        return lst

    # For every edge from domain to codomain:
    # append the cycle to the list if it isn't contained already
    for e in edges:
        c = cycle(e)
        #if c is not None:
        srt = sorted(c)
        if not srt in cycles:
            cycles.append(srt)

    #Print function
    #for i,e in enumerate(edges):
    #    print(f""{i} -> {e}"")

    # Print N and the number of cycles in this function
    #print(N, cycles)

    return len(cycles)

# Get the average number of cycles for N=1..200
for n in range(1,200):
    avg = []
    # 1000 random functions of size N
    for i in range(1000):
        avg.append(test(n))
    #print(avg)
    print(""%i\t%f"" % (n, sum(avg)/len(avg))) With values: 1   1.000000
10  1.966000
20  2.191000
30  2.356000
40  2.573000
50  2.635000
60  2.742000
70  2.762000
80  2.932000
90  2.851000
100 3.002000","['fixed-points', 'functions', 'probability', 'combinatorics', 'discrete-mathematics']"
2849184,"Question about a step in the proof of: If $f:\mathbb R \to \mathbb R$ is differentiable, then it is continuous.","If $f$ is differentiable at $x_0$,
$$\lim_{x\to x_0} \frac{f(x)-f(x_0)}{x-x_0}=f'(x_0).$$ So, $\lim_{x\to x_0} f(x)-f(x_0)=\lim_{x\to x_0} f'(x_0)(x-x_0)=0$. Thus, $\lim_{x\to x_0} f(x)=f(x_0)$. Thus, $f$ is continuous at $x_0$. Since $x_0$ was arbitrary, $f$ is continuous on $\mathbb R$. My question is: about the step going from $\lim_{x\to x_0} \frac{f(x)-f(x_0)}{x-x_0}=f'(x_0)$ to $\lim_{x\to x_0} f(x)-f(x_0)=\lim_{x\to x_0} f'(x_0)(x-x_0)$. How are we allowed to do this? Are we multiplying through by $x-x_0$? Is this allowed? Is it creating a new limit on the right side?","['derivatives', 'calculus', 'proof-explanation']"
2849206,What is the name for the third-order tensor of third-order partial derivatives?,"Given a sufficiently nice function $$f:\mathbb R^n\rightarrow\mathbb R$$ one can define a first-order tensor of all first-order partial derivatives in the standard way to obtain the gradient , and the same kind of idea allows one to construct a second-order tensor of all second-order partial derivatives to obtain the Hessian . Is there a name for the analogously obtained third-order tensor of third-order partial derivatives ? I'm writing a bit of code that uses that object to compute the Hessian of a matrix's eigenvalues with respect to some other voodoo that's probably irrelevant to this question, and if there is a standard nomenclature I'd prefer to use it.","['matrix-calculus', 'tensors', 'linear-algebra']"
2849239,Prove the roots of $p(z)+z^n\bar{p}(\frac{1}{z})$ lie on the unit circle,"I have to prove the following question from ""A course in complex analysis and riemann surfaces"": Let $p(z)=\sum_{i=0}^na_iz^u$ be a polynomial with all roots inside the (open )unit disk. Denote by $\bar{p}(z)$ the polynomial $\sum_{i=0}^n\bar{a_i}z^i$. Prove that the roots of $p(z)+z^n\bar{p}(\frac{1}{z})$ lie on the unit circle. Now it's not hard to see that if $r$ is a root of $p(z)$, then $\frac{1}{\bar{r}}$ is a root of $z^n\bar{p}(\frac{1}{z})$. But that's about as far as I got. I would like a hint on how to prove this.",['complex-analysis']
2849371,Comparing bounded and compact operators on $L^2$ to Roe algebras,"Suppose first that $M$ is a compact Riemannian manifold. Let $D^*(M)$ be the $*$-subalgebra of $\mathcal{B}(L^2(M))$ (the bounded operators on $L^2$) consisting of operators $T$ such that for all $f\in C_0(M)$, $fT - Tf$ is a compact operator on $L^2(M)$. Question 1: Is it true that $D^*(M)=\mathcal{B}(L^2(M))$? If not, what is an element of $\mathcal{B}(L^2(M))\backslash D^*(M)$? More generally, if $M$ is a non-compact Riemannian manifold, let $C^*(M)$ be the closure in $\mathcal{B}(L^2(M))$ of the set of operators $T$ such that: 1) For all $f\in C_0(M)$, $fT$ and $Tf$ are compact operators on $L^2(M)$; 2) $T$ has finite propagation. The second condition means that, for $f,g\in C_0(M)$, there is a constant $C$ such that $fTg=0$ whenever the supports of $f$ and $g$ are separated by a distance greater than $C$. Then $C^*(M)$ contains the finite-rank operators on $L^2(M)$, hence it contains the compact operators $\mathcal{K}(L^2(M))$ (which is the closure of such finite-rank operators). Question 2: How different are $C^*(M)$ and $\mathcal{K}(L^2(M))$? In particular, what is an example of an operator that is in $C^*(M)\backslash\mathcal{K}(L^2(M))$?","['riemannian-geometry', 'operator-theory', 'functional-analysis', 'operator-algebras', 'differential-geometry']"
2849388,What does interquartile range represent (real world scenario),"I wish to understand when will i use the concept of interquartile range in real world scenario. I can understand how to calculate interquartile range but i do not understand or make sense of the final answer. For example. Below are the list of scores. 81,82,83,83,84,84,84,1000 The interquartile range is 1.5 Now what does 1.5 actually represent in above ages ? Like if i change the 1000 score to 85 ; the ineterquartile range will still be the same because the way its calculated. So whats the application of interquartile range ?",['statistics']
2849394,How to find the point on a line which has the minimum length to three points?,"I've learnt some ways of finding a point on a line which can minimize the sum of length to other points. I want to generalize this to three points using geometric methods. Question: There're three points $(A,B,C)$ on same side of a line, finding a point on that line to minimize $PA+PB+PC$ . I know that the Lagrange Multiplier Method can solve such problems, but I want to find some geometric meaning. My Attempt Just like the two point case, let point $B$ go to another side. $P$ maybe lies on the intersection of $BA, BC$ with the x-axis. But I suddenly realized that the point of minimum total distance from the three vertices of the triangle is called Fermat–Torricelli Point ( $F$ on picture). But that point may not on the line. But we can get an intersection by connecting $BF$ . I can't prove which point is smaller, or there are other smaller points.","['geometric-construction', 'optimization', 'second-order-cone-programming', 'geometry']"
2849432,Is there a formula for calculating the sum of all products of $p$ different integers $\le n$?,"For example: $n=3, p=2$ then the sum I'm looking for is: $1.2+1.3+2.3$. Of course this can be easily calculated on a computer. But having a formula would allow me to use it in the derivation of other formulas.
So far I've found nothing on the internet. I have found this nice formula for the sum of all products of arbitrary many distinct integers : $1+2+3+1.2+1.3+2.3+1.2.3=4!-1=(n+1)!-1$ . But I would like to be able to separate this into the parts mentioned above. I hope someone can point me in the right direction. Thanks in advance!","['number-theory', 'combinatorics', 'sequences-and-series', 'elementary-number-theory']"
2849492,"Find the sum of all numbers greater than $10000$ formed by using all digits $0,1,2,4,5$","Find the sum of all numbers greater than $10,000$ formed by using all digits $0,1,2,4,5$ and no digit being repeated in any number. I could find that the number of such numbers are $96$ but I could not find their sum.","['algebra-precalculus', 'combinatorics']"
2849542,Mortivation for the definition of measurable function?,"1) We say that $f:\mathbb R^n\to \mathbb R$ is measurable if $$\{x\in\mathbb R^n\mid f(x)<\alpha \},\tag{D}$$
is measurable for all $\alpha $. What is the motivation for such definition ? We can define for example continuity as : $f^{-1}(O)$ is open in $\mathbb R^n$ for all open set in $\mathbb R$. A possible definition for measurability could be for example $f^{-1}(O)$ is measurable for all open of $\mathbb R$, no ? So what is the motivation for the definition (D) ? 2) In more abstract measurable spaces, $f:(X,\mathcal F)\to (Y, \mathcal G)$ we say that $f$ is measurable if $$f^{-1}(U)\in \mathcal F\tag{D'}$$ for al $U\in \mathcal G$. Is there a correlation with the definition (D) ? For example, if $Y$ is a space with an order $\mathcal R$, would it be equivalent to $$\{x\in X\mid f(x)\mathcal R\alpha \}\in \mathcal F,$$
for all $\alpha \in Y$ ? Because I unfortunately don't really see the relation between (D) and (D').","['measure-theory', 'motivation']"
2849549,Differentiability of a singleton set,Let $f$ be a function $ f:\{2\} \rightarrow\mathbb R$. Now absolutely $f$ is continuous. But what we can say about the differentiability of the function $f$ at $x=2$ ?,"['derivatives', 'real-analysis', 'absolute-continuity']"
2849587,$\lim_{n\to\infty}n^2\int_0^1x^nf(x)dx$ if $f(1)=0$,"Evaluate $\lim_{n\to\infty}n^2\int_0^1x^nf(x)dx$ if $f(1)=0$. I know that if $f$ is continuous then $\int_0^1x^nf(x)dx=0$ by applying substitution $u=x^n$ and using the same substitution $n\times\int_0^1 x^nf(x)dx \to f(1)$ as $n\to\infty$.But what happens if i still have an $n$left in the front from $n^2$ and $f(1)=0$.
My particular case is: $f(x)=(x-1)\times e^{-\frac{1}{x+5}}$. Any hints?","['integration', 'calculus', 'limits']"
2849590,How is this definition of differentiability for an arbitrary subset $S$ of $\mathbb{R}^n$ common and used?,"In the book of Analysis On Manifold by Munkres, at page 144, in the exercise 3.a, the author defines differentiability for an arbitrary subset $S$ of $\mathbb{R}^n$ as Let $S$ be an arbitrary subset of $\mathbb{R}^n$; let $x_0 \in S$. We
  say that $f:S \to \mathbb{R}$ is diff'able at $x_0$, of class $C^r$,
  provided that there is a a $C^r$ function $g: U\to \mathbb{R}$ defined
  in a neighbourhood of $U$ of $x_0$ in $\mathbb{R}^n$, such that $g$
  agrees with $f$ on the set $U \cap S$. However, considering the answers given to this question, how is the above definition common and used ?","['derivatives', 'real-analysis', 'calculus']"
2849627,"difference between $f^{-1}([-\infty ,a))$ and $f^{-1}(-\infty ,a)$?","In the book ""Real-Analysis"" of Stein and Shakarshi, they say that $f$ is measurable if $f^{-1}([-\infty ,\alpha ))$ is measurable for all $\alpha \in\mathbb R$ but in my course a function $f$ is said to be measurable if $f^{-1}((-\infty ,\alpha ))$ is measurable for all $\alpha \in\mathbb R$. Are both definitions equivalent? And if yes, why? Furthermore, what sets are open in $[-\infty ,\infty ]$? Are they the sets of the form $]a,b[$, $[-\infty ,a)$ and $(b,+\infty ]$? And in $[-\infty ,\infty ]$ is $(-\infty ,a)$ still open ?","['general-topology', 'measure-theory']"
2849643,How to find the general term of the following sequence?,"Consider the following recurrence problem:
\begin{align}
d_{i-1} &= 2\varphi_{i+1}+4\varphi_i + 8d_i-7d_{i+1} - F \left( \delta_{i,N} + \delta_{i,N+1} \right) \, , \\
\varphi_{i-1} &= -7\varphi_{i+1}-16\varphi_{i} + 24 \left( d_{i+1}-d_{i} \right) + F \left( \delta_{i,N} + \delta_{i,N+1} \right) \, , 
\end{align}
where $d_i, i \in \{2, \cdots , N+1\}$ represent displacements, $\varphi_i$ inclinations, and $F$ is a known force acting at the nodes $N$ and $N+1$. We require by the system symmetry that $d_{N+1}=d_N = d_\mathrm{C}$ and $\varphi_N = -\varphi_{N+1}= \varphi_\mathrm{C}$, where $d_\mathrm{C}$ and $\varphi_\mathrm{C}$ are still to be determined from the boundary conditions: $d_1 = 0$ (zero displacement) and $2\varphi_1+\varphi_2 = 3d_2$ (zero torque) In order to proceed, i have tried to first determine $d_{N-1}$ and $\varphi_{N-1}$ from the system above, and then $d_{N-2}$ and $\varphi_{N-2}$, etc... in a recursive way and then try to find out the general term of the resulting sequences. For the term $N-1$, we obtain
\begin{align}
d_{N-1} &= d_\mathrm{C}+2\varphi_\mathrm{C}-F \, \\
\varphi_{N-1} &= -9\varphi_\mathrm{C}+3F \, .
\end{align} Analogously, we get for the term $N-2$
\begin{align}
d_{N-2} &= d_\mathrm{C}-18\varphi_\mathrm{C}+4F \, \\
\varphi_{N-2} &= 89\varphi_\mathrm{C}-24F \, .
\end{align} I was wondering whether there is a particular way to figure out the general term of such sequence. Any help or suggestions are most welcome.","['recurrence-relations', 'sequences-and-series']"
2849646,Range of $(\sin x)^6+ (\cos x)^6$,"I need to find the range of the function $y = (\sin x)^6+ (\cos x)^6$ I did find the answer but working in a crude way rather than a methodical step by step approach. I give below the steps I used , please help with a methodical approach to such problems. 1) To find the max value of the function I noticed that in the range where x is $[0,2\pi]$ , when $\cos x$ hits $+1$ then $\sin x$ is $0$ , when $\cos x$ is $0$ 
 then $\sin x$ is $+1$ ..etc so the max value at any of these points could be either $1^6+0^6$ or $(-1)^6+0^6$ so the max value is 1. to find the minimum I differentiated the function $f' (x) = 6(\sin x)^5\cos x- 6(\cos x^5)\sin x =0$ , equating this to zero we have $(\sin x)^4 = (\cos x)^4 => x = \pi/4 =>$ min value of function is $(\sin(\pi/4))^6 + (\cos(\pi/4))^6 = 1/4$ . so the range is $(\frac{1}{4},1)$. Please can someone help with how can this type of problems be methodically approached ? - Thanks.","['algebra-precalculus', 'functions']"
2849652,Generalized eigenvector in a differential equation system,"This is the system:
$$\begin{cases}
\dot{x}=x+2y+e^{-t}\\
\dot{y}=2x+y+1
\end{cases}$$ Now I first solve the homogeneous one, without the vector $(e^{-t},1)$, so I have to find the eigenvalues of the matrix $$\begin{pmatrix}
1 & 2 \\
2 & 1
\end{pmatrix}$$
which are $(1-\lambda)^2-4=\lambda^2-2\lambda-3$ and $\lambda_1=3$, $\lambda_2=-1$. By the first one I obtain the eigenvector $u=(1,1)$ for example, for the second one I obtain the matrix
$$\begin{pmatrix}
0 & 2\\
2 & 0
\end{pmatrix}$$
that has null eigenvector. Now, I find the generalized eigenvector: $(A-\lambda I_d)u_1=u$ and obtain
$$\begin{cases}
2u_1^1=1\\
2u_2^2=1
\end{cases}$$ I chose the eigenvector $u_1=(\frac{1}{2},0)$ is it correct? I think no, because going on in the resolution of the equation I have to write the $A$ matrix of the system as a sum $A=P+N$ where $P=Sdiag[\lambda_i]S^{-1}$, $S=\begin{pmatrix}
1 & \frac{1}{2}\\
1 & 0\end{pmatrix}$ and $N$ is nihilipotent of order 2 and then:
$$e^{At}=e^{Pt}e^{Nt}=Sdiag[e^{\lambda_i}]S^{-1}(I_d+Nt)$$
I usually do like this when the eigenvalues of the matrix have multiplicity, is it correct to solve like this in this case? And if not, what is the correct method? Thanks and sorry for bad anglisk","['generalized-eigenvector', 'ordinary-differential-equations', 'systems-of-equations']"
2849661,Closed graph theorem seems to state that a closed operator has to be bounded?,"By the closed graph theorem an operator $T$ is continuous  (equivalently bounded) if and only if it its graph is closed. An operator with a closed graph is called a closed operator. So we have $$
T \ \text{bounded} \Longleftrightarrow T \ \text{continuous} \Longleftrightarrow T \ \text{has closed graph} \Longleftrightarrow T \ \text{closed}. \quad (*)
$$ But I often see closed operators mentioned in the context of unbounded operators. That is unbounded operators can be closed. But in $(*)$ above it seems that a closed operator is equivalent to a bounded operator?","['functional-analysis', 'operator-theory', 'closed-graph']"
2849670,Question on Local Maxima and Local Minima,"Find the set of all the possible values of $a$ for which the function $f(x) = 5 + (a-2)x + (a-1)x^2 - x^3$ has a local minimum value at some $x < 1$ and local maximum value at some $x > 1$ The first derivative of f(x) is : $f'(x) = (a-2) + 2x(a-1) -3x^2$ I do know the first derivative test for local maxima and local minima, but I can't figure out how I could use monotonicity to find intervals of increase and decrease of $f'(x)$ The expression for $f'(x)$ might suggest the double derivative test is the key, considering $f''(x) = 2(a-1) - 6x$  for which the intervals where it is greater than zero and less than zero can be easily found, but then again I can't think of a way how I could find a $c$ such that $f'(c) = 0$.","['derivatives', 'maxima-minima', 'calculus']"
2849687,Infinite series expansion of $\sin^2 \frac{x}{2}$,"Prove the formula $$\sin^2 \frac{x}{2} = \sum_{n=1}^\infty C_{n-1}
 \left ( \frac{\sin x}{2} \right )^{2n} $$ where $C_n = \displaystyle
 \frac{1}{n+1}{{2n}\choose{n}}$. I tried to use the Taylor series of sine function to obtain an infinite sum, but the exponent $2n$ is difficult to deal with.","['recurrence-relations', 'taylor-expansion', 'calculus', 'sequences-and-series', 'discrete-mathematics']"
2849720,what is the difference between isomorphic and birational?,"From Wikipedia : In algebraic geometry, a morphism between algebraic varieties is a function between the varieties that is given locally by polynomials. It is also called a regular map . A morphism from an algebraic variety to the affine line is also called a regular function . A regular map whose inverse is also regular is called biregular, and they are isomorphisms in the category of algebraic varieties. Because regular and biregular are very restrictive conditions – there are no non-constant regular functions on projective varieties – the weaker condition of a rational map and birational maps are frequently used as well. What is an example of two varieties $X$ and $Y$ over the field $k=\mathbb{Q}$ that are birational, but not isomorphic? just a few more details if possible? E.g. $X  = \{ y^2 - x^3 = 0 \} \subset \mathbb{A}^2 $ and $Y = \{ y -x^2 = 0 \} \subset \mathbb{A}^2 $. What would be the maps $f : X \to Y$ and $g: Y \to X$ ? Why are they birational and not inverse.","['category-theory', 'algebraic-geometry']"
2849736,No group has $\mathbf{N}_5$ as its lattice of subgroups,"Let $\mathbf{N}_5$ be the lattice in the picture: I'm asked to show that there is no group having this lattice as its lattice of subgroups. To start with, I know that infinite groups can be excluded, but this doesn't take me very far... My first thought was that, if $B \leq A$, then $BC \cap A = B(C \cap A)$. Since in this case $A \cap C = \{1\}$, this yields $BC \cap A = B$. I'm not sure this is any useful, because $BC$ doesn't have to be a subgroup (if it was, it would follow that $BC=B$, whence $C \subseteq B$, a contradiction). This also doesn't seem to follow by Lagrange's Theorem alone. I think it must be that $A = \langle a \rangle$ and $B = \langle a^r \rangle$, because from $A = \langle a, b \rangle$ and $B=\langle b \rangle$, it should follow that $\langle a \rangle$ is yet another subgroup of $A$. But then, taking $C = \langle c \rangle$, it's not clear why can't $\langle a^r,c \rangle = G$. In a tentative of showing this, I used the previous paragraph to claim that for $x \in A \setminus B$, there doesn't exist $b \in B$ and $c \in C$ such that $x = bc$. Now taking $x = a \in \langle a^r,c \rangle = B \vee C$,
$$a = a^{rs_1}c^{k_1}\cdot \cdots \cdot a^{rs_n}c^{k_n},$$
where $s_i$ and $k_i$ are any integers. Once again, if $a$ and $c$ don't commute, this doesn't seem to lead to any contradiction.","['abstract-algebra', 'lattice-orders', 'group-theory']"
2849749,Unitarily equivalent operators have unitarily equivalent spectral measures,"For every densely defined self-adjoint linear operator
$
A : \mathcal D(A) \subset H \to H
$
there is a unique spectral representation
$$
A = \int t \, dE_A(t)
$$
where $E_A$ is a spectral measure on $\mathbb R$. Now let $
B : \mathcal D(B) \subset H \to H
$ be another densely defined self-adjoint operator on $H$ with spectral measure $E_B$ which is unitarly equivalent to $A$ with unitary map $U$:
$$
AU=UB
$$ This page is stating that the spectral measures are unitarily equivalent as well but I don't know how to prove it. Can someone give me a hint?","['functional-analysis', 'spectral-theory', 'operator-theory']"
2849755,How many trials of flipping a coin are needed to be confident in getting very close to the same number of H/T?,"How many times one would need to flip a coin in order to be very confident of getting close to a $1:1$ ratio of Heads/Tails? By ""very confident"" I mean above $95$% sure, and by ""close to a $1:1$ ratio"" I'm thinking $55$%-$45$% H/T or T/H. I'm running of a simulation where two engines are playing a game against each other, and I'm wondering after how many games I should stop the simulation and check their match score (if the score is close to equal after X number of games, I would infer the engines are most likely equal in strength). I know this is a basic probability/statistics question, but I couldn't find a question addressing this anywhere else.","['statistics', 'probability', 'confidence-interval', 'statistical-inference']"
2849774,Classifying the groups of order 56,"I am trying to classify the groups of order $56=2^3\cdot 7$. I think I have successfully eliminated most of the cases, and I am left with the last: When the group of order 8 is normal and it is isomorphic to $Z_2\times Z_2\times Z_2$. So, we seek homomorphisms $\varphi:Z_7\to \mathrm{Aut}(Z_2\times Z_2\times Z_2)\cong \mathrm{GL}(3,\mathbb{Z}_2)$. $\varphi$ is completely determined by its action on $1\in Z_7$, and since its order is 7, a prime, its image, $\varphi(1)$, must have order 1 or 7. The former corresponds to the trivial product $Z_2\times Z_2\times Z_2\times Z_7$. The interesting one would arise from the latter, and here is where I am lost. Yes, $|\mathrm{GL}(3,\mathbb{Z}_2)|=168=2^3\cdot 3\cdot 7$, so by Cauchy, the existence of such an element (of order 7) is guaranteed. But how do I find it? In general, I seek advice on problems like this where the automorphism group is given by the general linear group. From here and there, I saw people using eigenvalues, but I am not familiar with that technique, given my training. If someone could be so kind as to explain that method in detail, it would be very greatly appreciated.","['abstract-algebra', 'group-theory']"
2849782,Path to Riemann Surfaces and Complex Geometry,"Right now I'm looking at finding a textbook on complex analysis that will be sufficient enough to prepare me for Riemann Surfaces and Complex Geometry. I'm currently looking at Zill's ""A First Course in Complex Analysis"", Joseph Bak's ""Complex Analysis"", Gamelin's ""Complex Analysis"" and Jerrold Marsden's ""Basic Complex Analysis"" and lastly Ravi Agarwal's ""An Introduction to Complex Analysis"". Which one of these texts or perhaps others will be very good and cover the right amount of material. At the moment I'm looking at Ravi Agarwal's ""An Introduction to Complex Analysis"", and Jerrold Marsden's ""Basic Complex Analysis"". Also what important concepts should I understand well enough to start studying Riemann Surfaces and Complex Geometry?","['riemann-surfaces', 'complex-geometry', 'reference-request', 'complex-analysis', 'book-recommendation']"
2849786,Is a subset of $\mathbb R^2$ homeomorphic to an open subset of $\mathbb R^2$ an open subset?,"Suppose $X\subset \mathbb R^2$ with the subset topology and $U\subset\mathbb R^2$ an open subset with the subset topology, if $X\cong U$ and we deduce $X\subset \mathbb R^2$ is also open? This is not true for general topological space, for example let $S=\{1,2\}$ with the topology
\begin{equation}
	\tau_S=\big\{\emptyset,\{1,2\},\{1\}\big\}
\end{equation}
then 
\begin{equation}
	\{2\}\cong\{1\}
\end{equation}
but $\{1\}\subset S$ is open and $\{2\}\subset S$ is not open.",['general-topology']
2849868,Derivative of norm 2,"I'm struggling a bit using the chain rule.
Given the function $\phi$ defined as: $\phi(x) = ||{A\bf{x}-b}||_2$ where $A$ is a matrix and $b$ is a vector. What is the gradient $\nabla\phi$ and how should I proceed to compute it?","['derivatives', 'normed-spaces', 'chain-rule']"
2849881,Implement genarating function for a combinatorial question,"I've tried to solve the following question by using generating functions.I know  It's pretty simple to do it with Inclusion–exclusion principle but I insist to solve it with other technique as well. Q: how many combination to spread 10 balls into 5 boxes when in each box there is at least one ball. A:
$
(x+x^2+x^3+x^4...)^5 = x^5(1+x+x^2+x^3...)^5 = x^5 \frac{1}{(1-x)^5} = x^5 \sum_{i=0}^\infty \binom{n+5-1}{5-1}x^n$ I want the coefficient of $x^{10}$ so $n=5$ which is $\binom{9}{4} = 126$ sadly it isn't the same answer like the Inclusion–exclusion principle, i guess my series isn't right but I can't see why.","['generating-functions', 'discrete-mathematics']"
2849893,Is any open subset of $R^n$ a union of countable hypercubes?,"I'm trying to extend the proof seen here that any open subset of $\mathbb{R}$ can be written as a countable union of disjoint open intervals.
Apparently it seems like an analogous proof for $\mathbb{R}^n$. However I can't think of any equivalence relation that would allow me to proceed with my sketch. The sketch is like: Define an equivalence relation $\sim$ on $\mathbb{R}^n$ Show that the equivalence class $\sim(x)$ is non-empty and open Prove that $\sim(x)\bigcap \sim(y) \neq \emptyset \Rightarrow \sim(x)=\sim(y)$ Demonstrate that $\sim(x)$ is an hypercube $\prod_{i=1}^N(a_i,b_i)$ Show that the set of equivalence classes D is countable Deduce that $\bigcup D$ is equal to our open subset","['general-topology', 'real-analysis', 'analysis']"
2849894,Help understanding/proving a simple claim about sinks and sources.,"I am reading an introductory differential equations text where the author makes a claim that I feel should be obvious, but I cannot prove to myself. The author proposes a  first-order, autonomous differential equation of the form $x' = f(x)$, where solution $x$ is a function of real variable $t$, possessing two equilibrium points, $x_l$ and $x_r$, such that $f'(x_l)>0$ and $f'(x_r)<0$. I assume these are derivatives w/ respect to $x$. Because of the sign of their derivatives, he says $x_l$ is a source and $x_r$ is a sink. Would someone please provide a hint on how to prove the previous statement?
I've tried working along the lines of
$$\frac{f(y)-f(x_l)}{y-x_l}=\frac{x'(y)-x'(x_l)}{y-x_l}=\frac{x'(y)}{y-x_l}>0$$
for all $y$ in some neighborhood of $x_l$, but now I'm unsure of how to work $t$ into the picture. The mixture of derivatives w.r.t $x$ and $t$ and the function $x$ being treated as a variable makes my head spin and blocks me from any good intuition. Apart from help with this specific problem, advice on how to think about/approach these problems would be welcome. Thanks in advance, Paul",['ordinary-differential-equations']
2849938,Generalization of Vitali-Hahn-Saks theorem for algebras,"By Vitali-Hahn-Sack theorem, we know that, if $(\mathbb{P}_n)_{n\in\mathbb{N}}$ is a sequence of probabilities defined on a $\sigma$-algebra $\mathcal{F}$ of subset of a set $\Omega$, such that for each $ F \in \mathcal{F}$ the sequence $(\mathbb{P}_n(F))_{n\in\mathbb{N}}$ converges, then the limit function is a measure on $\mathcal{F}$. I'm wondering if the same result holds true if $\mathcal{F}$ is just an algebra of subsets of $\Omega$ and $(\mathbb{P}_n)_{n\in\mathbb{N}}$ is a sequence of pre-measures defined on $\mathcal F$ with total mass 1, i.e. if also the limit function is a pre-measure. Can anyone give me an answer or provide any reference? Thanks in advance.","['probability-limit-theorems', 'probability-theory', 'measure-theory']"
2849945,Sum of sin waves with same frequency and different amplitudes and phase,"For the equation: $$A_1 \sin (\omega t + \theta_1) + A_2 \sin (\omega t + \theta_2) = A_3 \sin (\omega t + \theta_3)$$ I've been able to show that the amplitude of the sum is (I believe this is a standard problem): $$ A_3 = \sqrt{A_1^2 + A_2^2 + 2 A_1 A_2 \cos(\theta_1 - \theta_2)} $$ and the new phase is: $$ \theta_3 = \arctan \left(\frac{A_1 \sin \theta_1 + A_2 \sin \theta_2}{A_1 \cos \theta_1 + A_2 \cos \theta_2}\right) $$ My question is what happens when the phases $\theta_1$ and $\theta_2$ are zero (or just equal to each other). Most books and internet sites (eg http://mathworld.wolfram.com/HarmonicAdditionTheorem.html ) state that under these conditions: $$ A_3 = \sqrt{A_1^2 + A_2^2} $$ However, if I set $\theta_1$ and $\theta_2$ to zero one gets instead (Since $cos(0) = 1$): $$ A_3 = \sqrt{A_1^2 + A_2^2 + 2 A_1 A_2} $$ I've been staring at this for a while and I don't understand why the published answer is different from mine. I am sure it is something simple but I've not been able to spot it (Addendum: Wikipedia site: https://en.wikipedia.org/wiki/List_of_trigonometric_identities has the same result under section Linear Combinations).",['trigonometry']
2849967,"Can't prove this algebraically $\sum\limits_{i = 0}^n { n \choose i } \, !i = n! $","I'm stumped as to how to prove this formula 
$$
\sum\limits_{i = 0}^n { n \choose i } \, !i  = n! \tag{1}
$$
using only the ""algebraic"" properties of the binomial coefficient $ n \choose i $ and the subfactorial operator $!i$ (the number of derangements of $i$ elements.) There's an easy counting argument that proves the formula. (Each term in the sum is the number of permutations of $n$ elements that leave $(n-i)$ elements fixed.) But shouldn't we also be able to prove it algebraically using only the properties of the operators? Here are the three pertinent properties of $!i$ that I found at https://en.wikipedia.org/wiki/Derangement $$ !i = (i-1)(\, !(i-1) \,+\, !(i-2) ) \tag{2}$$
$$ !i = i! \, \sum\limits_{j = 0}^i {\frac{(-1)^j}{j!} } \tag{3}$$
$$ !i = i \,\cdot\, !(i-1)+(-1)^i \tag{4}$$ However, it seems like these properties of $!i$ are not enough to prove $(1)$. Help! Is it possible to have a formula that can only be proved with a ""counting argument"" and not ""algebraically""?","['binomial-coefficients', 'derangements', 'permutations', 'combinatorics', 'factorial']"
2849974,Sequences Eventually and Frequently in a Set,"A sequence $(a_n)$ is eventually in an set $A \subseteq \mathbb R$ if there exists an $N \in \mathbb N$ such that $a_n \in A$ for all $n \ge N.$ A sequence $(a_n)$ is frequently in an set $A \subseteq \mathbb R$ if, for every $N \in \mathbb N$ there exists an $n \ge N$ such that $a_n \in A$. Question: Which definition is stronger? Does frequently imply eventually or eventually imply frequently? Intuitively I am inclined to say that eventually implies frequently because from examples I reason that the sequence ${\lfloor \frac{5}{n}\rfloor}$ is eventually in $\{0\}$ and also frequently in $\{0\}$ but a sequence like $(-1)^n$ which is frequently in $\{1\}$ but not eventually. However from looking at the quantifiers it seems to me that the converse should be true for I reason $$\forall N \exists n(n \ge N \Rightarrow a_n \in A)$$ should imply 
$$\exists N \exists n(n \ge N \Rightarrow a_n \in A)$$ (i.e. frequnctly implies eventually)? Am I making a mistake with the quantifiers? Which one is correct? Thanks in advance.","['real-analysis', 'predicate-logic', 'logic', 'sequences-and-series', 'analysis']"
2849980,Is this class of series all demonstrably transcendental?,"Question: For a vector with integer entries $[a_0, a_1,  \dots, a_{k-1}]$ is it true that when $\sum_{n=1}^\infty{\frac{a_{n-1 \mod k}}{n}}$ is not divergent it limits to some transcendental number or zero? Musings: I will adopt something like the notation of this post. We might call these Weinberger series. Err... I dunno we might call them something else.
Let $\vec{v}=[a_0, a_1, \dots a_k]$ be a vector with integer entries. $ \sum{\vec{v}}=[\overline{a_0,a_1, \dots, a_{k-1}}]=\sum_{n=1}^\infty{\frac{a_{n-1 \mod k}}{n}}$. I should say that I suspect that when the sum of entries of $\vec{v}$ is not zero we have that $\sum{\vec{v}}$ is divergent. All the following have that property that the sum  of entries is zero (This makes the 4th entry not ambiguous). Let me show you a few! In this notation: $\begin{array}{lclr}
 \\
\frac{\pi\sqrt{2}}{4} & = & [\overline{1,0,1,0,-1,0,-1,0}] & \text{Why [1]}
\\
\frac{\pi\sqrt{3}}{9} & = & [\overline{1,-1,0}]  & \text{Don't [2]}
\\
\frac{\pi\sqrt{7}}{7} & = & [\overline{1,-1,-1,1,-1,1,0}] & \text{Hyperlinks [3]}
\\
\ln{k} & = & [\overline{1,1,\dots,1, 1-k}] & \text{Work[4]}
\\
\frac{\sqrt{3}\pi+3\ln\left(2\right)}{9}  & = & [\overline{1,0,0,-1,0,0}] & \text{In [5]}
\\
\frac{\pi+2\coth^{-1}\left(\sqrt{2}\right)}{4\sqrt{2}} & = & [\overline{1,0,0,0,-1,0,0,0}] & \text{Arrays [6]}
\end{array}
$ Why 1 don't 2 hyperlinks 3 work 4 in 5 arrays 6 ? I suspect that these are all transcendental when they are not $0$ or $\infty$. In fact! I am hoping to be able to say that they all fit neatly into some class. They all look to be $\alpha \pi+ \beta\ln(\gamma)+\delta$ for some algebraic constants $\alpha, \beta, \gamma, \delta$. But I would settle for just seeing that the guys need to be transcendental (or some clever counterexample that I am missing.) I suspect that their periodic nature should give rise to a demonstration that these are not algebraic numbers. How can I do that? Let me defend my use of $\vec{v}$. One should only use this notation if they are vectors is some sense. And they are. Note that we can define a type of scalar multiplication with the rationals so that $$\frac{3}{5}\ln(2)= \frac{3}{5} [\overline{1, -1}] = [\overline{0,0,0,0,3,0,0,0,0,-3}]$$ This is really not me saying much more than $$ \frac{3}{5}\sum_{n=1}^\infty{\frac{(-1)^{n+1}}{n}}=\sum_{n=1}^\infty\frac{3(-1)^{n+1}}{5n}$$ We have all the properties that one desires of a vector space: These values are closed under addition and have a type of multiplication with rational numbers. It leaves me wondering what the right type basis should be for this type of exploration.","['dirichlet-series', 'transcendental-numbers', 'sequences-and-series', 'analysis', 'vector-spaces']"
2849997,"If I'm given $\xi^b$, how do I calculate $\omega^{ab}$ given $\xi^b = \nabla_a \omega ^{ab}$? [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question I'm given a one-form, $\xi^b$. Then, I'm given a relation for a two-form, $\omega^{ab}$,  which says that $$ \xi^b = \nabla_a \omega^{ab}$$ How do I calculate $\omega^{ab}$ given this relation?","['differential-forms', 'differential-geometry']"
2850015,"Neutral geometry: If one triangle has angle-sum $180^\circ$, then all triangles have angle-sum $180^\circ$","One of the more interesting things we can say in neutral geometry (that is, without assuming the parallel postulate, but assuming e.g. the rest of Hilbert's axioms ) is the following: Suppose that a single triangle whose angles sum to $180^\circ$ exists. Then the sum of the angles in every triangle is $180^\circ$. (And therefore the parallel postulate holds.) Here is the outline of a proof. First, define the defect of a triangle to be $180^\circ$ minus the sum of its angles. It can be proved in neutral geometry that the defect is nonnegative, and that it's additive: if a triangle is chopped up into many smaller triangles, its defect is the sum of the smaller triangles' defects. In particular, if one triangle is contained inside another, its defect is less than or equal to that of the large triangle. We start with a triangle $\triangle ABC$ such that $\angle A + \angle B + \angle C = 180^\circ$. Simply by copying segments and angles (and the SAS triangle congruence axiom) we can tile the plane with copies of $\triangle ABC$. For any other triangle $\triangle XYZ$, we find a large triangle $\triangle A'B'C'$ which is made up of many copies of $\triangle ABC$ (and has the same angles), but contains $\triangle XYZ$. Then the defect of $\triangle XYZ$ is less than or equal to the defect of $\triangle A'B'C$, which is $0$. The incomplete step here is ""tile the plane"". We have a way to generate a finite tiling with arbitrarily many copies of $\triangle ABC$ in all directions; we need to show that we can extend it to cover an arbitrary point in the plane. This feels like an application of Archimedes's axiom . But how exactly do we get there using Archimedes?","['axiomatic-geometry', 'noneuclidean-geometry', 'geometry']"
2850020,Cohomology of Affine Schemes,"I am reading Hartshorne's thm. III.3.5 that an affine scheme $X=\mathrm{Spec}\,A$ over a noetherian ring $A$ has $H^i(X,\mathcal{F})=0$ for any quasicoherent sheaf $\mathcal{F}$ and $i>0$. I followed the proof (and the preceding results) fine until the last step. This is the proof: let $M=\Gamma(X,\mathcal{F})$ and $0\to M\to I^\bullet$ an injective resolution of $M$ as an $A$-module. Then $0\to\widetilde{M}\to\widetilde{I^\bullet}$ is exact (because localization is exact, and exactness of sheaves can be checked on stalks). He proves in prop. 3.4 that $\widetilde{I}$ of an injective module is flasque (for noetherian $A$), so this resolution of $\widetilde{M}=\mathcal{F}$ can be used to compute cohomology. The conclusion is: ""Applying $\Gamma(X,\cdot)$, we recover the exact sequence of $A$-modules $0\to M\to I^\bullet$. Hence, $H^0(X,\mathcal{F})=M$, and $H^i(X,\mathcal{F})=0$ for $i>0$."" I don't understand this last step at all and think I am missing something fundamental.","['sheaf-cohomology', 'algebraic-geometry']"
