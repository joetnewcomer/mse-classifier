question_id,title,body,tags
3761529,Trouble proving the equality when asked to compute the operator norm $\phi : \ell^{2} \to \mathbb R$ where $\phi(x)=\sum \frac{x_{n}}{n}$,"Compute the operator norm $\phi : \ell^{2} \to \mathbb R$ where $\phi(x)=\sum\limits_{n \in \mathbb N} \frac{x_{n}}{n}$ My proof so far: $\lvert \phi(x)\rvert=\lvert\sum\limits_{n \in \mathbb N} \frac{x_{n}}{n}\rvert\leq\sum\limits_{n \in \mathbb N} \rvert\frac{x_{n}}{n}\rvert \leq (\sum\limits_{n \in \mathbb N} x_{n}^2)^{\frac{1}{2}}\cdot (\sum\limits_{n \in \mathbb N} \frac{1}{n^2})^{\frac{1}{2}}\implies \lvert \lvert\phi\rvert\rvert_{*}\leq (\sum\limits_{n \in \mathbb N} \frac{1}{n^2})^{\frac{1}{2}}=:M$ Now, for me it always generally difficult to prove the reverse inequality, as I always need to normalize the the sequence, i.e. $(x^{n})_{n}\subseteq B_{1}^{\lvert \lvert \cdot \rvert \rvert_{2}}(0)$ . I cannot find a way to satisfy the restriction in the unit ball while still approximating $M$ . In other spaces like $\ell^{1}, \ell^{\infty}$ this is a lot easier. Any ideas/hints?","['banach-spaces', 'operator-theory', 'functional-analysis', 'dual-spaces', 'convergence-divergence']"
3761534,On injectivity of $F_N$,"I am interested in the following problem: Let $F_N:\mathbb{N}\to\mathbb{N}$ be the function that maps a natural number $a$ to the least natural number more than or equal to $a$ for which there exists a sequence of natural numbers $a=x_1 <x_2<\ldots < x_m=F_N(a)$ for some $m\in\mathbb{N}_0$ such that $$\prod_{i=1}^m x_i$$ is a perfect $N^{th}$ power. For what values of $N$ is $F_N$ a injective function? I have shown that $F_N$ is injective for $N=1,2$ however, I have no idea how do we decide if $F_N$ is injective for $N\geq 3$ . Here's an example: $F_2(2)=6$ because $6$ is the smallest integer greater than or equal to $2$ for which there is a sequence of $x_i$ between $2$ and $6$ for which their product is a perfect square as $2\times 3\times 6$ is a perfect square. Progress. So we know $F_1,F_2$ are injective and as noted out by @Ravi Fernando, $F_3$ is not injective as $F_3(6)=F_3(12)=18$ . Any help will highly be appreciated!","['number-theory', 'functions']"
3761549,Solving $\cos(z) = \frac{5}{2}$,I'm given $$\cos(z) = \frac{5}{2}$$ and I'm trying to solve for $z$ but I keep going in circles. I know $\cos z = 5/2 = 1/2(e^{iz}+e^{-iz})$ so then $e^{iz}+e^{-iz} = 5$ but then I'm stuck,"['trigonometry', 'complex-numbers']"
3761570,What is the probability distribution of the maximum cycle length in a permutation game?,"There is a ""classic"" counterintuitive scenario, in which you have $N$ boxes, $N$ players. Player $i$ has a dollar bill tagged with the number $i$ . Each player places their dollar bill into a box at random, where each box is tagged with a distinct number between $1$ and $N$ . Now each of the $N$ players gets to examine $n$ boxes ( $n<N$ ), and if all of them find their associated bill, then each player receives $R>1$ dollars. Otherwise they all lose their starting bill. The players can coordinate before the game starts but cannot communicate after they begin opening boxes. The ""winning strategy"", at least if $n$ is not too much smaller than $N$ , is for player $i$ to open box $i$ , then the box whose number is printed on the bill they found, etc. The idea is that if you connect $i$ to $j$ if and only if box $i$ contains bill $j$ , then you get a decomposition of $\{ 1,2,\dots,N \}$ into cycles. Now if all players are using this strategy, then they win if and only if the largest cycle contains at most $n$ boxes. This condition is sufficient for victory, because player $i$ will find bill $i$ when the procedure would instruct them to open box $i$ a second time. This condition is also necessary, because for every cycle there exists at least one player that will traverse it, and they will only win if they can get all the way to the end of the cycle before being stopped. What is counterintuitive is that, if all players use this strategy, then the group wins with a probability far greater than $(n/N)^N$ ; for example if $n=50,N=100$ then the winning probability is about 0.31 while the ""choose randomly"" strategy wins with probability $2^{-100} \approx 8 \cdot 10^{-31}$ . The usual intuitive explanation for how this can happen even though each player separately has only a probability of $n/N$ to find their bill is that the ""winning strategy"" makes it so that the players tend to either all find their bill or else many of them don't. And indeed, in support of that explanation, one can see that if any players don't find their bill, then at least $n+1$ players don't. The usual question is, given $n,N,R$ , and teammates that are perfect rational agents, do you take the bet? The additional information needed to answer that is the probability to win. With that in mind, my question is: is there an explicit formula for the probability that the players win this game as a function of $n$ and $N$ ? My question can be rephrased in math jargon as: given a random directed graph on $N$ vertices where each vertex has out-degree $1$ and in-degree $1$ , what is the probability distribution of the size of the largest cycle in the graph?","['graph-theory', 'probability-theory']"
3761571,Proof verification: A certain process of redistribution stops after a finite number of steps.,"QUESTION: There are $n\ge 3$ girls in a class sitting around a circular table, each having some apples with her. Every time the teacher notices a girl having more apples than both of her neighbours combined, the teacher takes away one apple from that girl and gives one apple each to her neighbours. Prove that, this process stops after a finite number of steps.
(Assume that, the teacher has an abundant supply of apples.) MY ANSWER: We define the girls as gears. Now, let any gear which has more number of apples than it's immediate neighboring gears rotate clockwise, and consequently the neighbors rotate counterclockwise.. (Note: The gears rotate only in groups of $3$ and the rotation of any group does not affect the other groups) Any clockwise rotation decreases the number of apples by $1$ and any counter rotation increases the number by $1$ . We define, a group of $3$ gears to be in a stationary state if the gear that is trapped on both the sides has $\leq$ number of apples than the sum of its neighboring gears. In such a case, the group does not rotate, and remains stationary.. Now, firstly, since we are considering positive integers, any group must come to a stationary state after finite number of rotations.. Define $\Omega_k = a_{1k}+a_{2k}+a_{3k}+....+a_{nk}$ as the sum of the number of apples in any $k^{th}$ step. Here each $a_{ik}$ denotes the number of apples possessed by the $i^{th}$ girl, at the $k^{th}$ step. Define $\Delta_k=max(a_{1k},a_{2k},.....,a_{nk})$ as the maximum number of apples possessed by some girl at any $k^{th}$ step. Say, $\Delta_0=a_j$ , for some $j\in\{1\leq{a}\leq{n}, a\in\Bbb{N}\}$ (where $\Delta_0$ represents the initial step) Define $V(a_g)$ to be the maximum number of apples possessed by some girl, which is $\leq$ girl $g$ , or in the set excluding girl $g$ . $\color{red}{Claim :}$ $\Delta_k\leq{a_j}$ , $\forall k \in \{1,2,3,......,n\}$ $\color{red}{Proof:}$ Let us start the process with the group $(a_{j-1},a_j,a_{j+1})$ .. Since, we have already proved that the number of rotations will be finite for this group to attain a stationary state. Let us say, after the $m^{th}$ step, $a_{jm}<V(a_j)$ From this step onwards until the completion of the last step (say $p$ ) of this group, $\Delta_k=V(a_j)$ , where $m\leq{k}\leq{p}$ And $\forall k<m$ , $\Delta_k$ was clearly $=a_j$ . Therefore, we see that in the whole process the value of $\Delta$ never increases.. So, following the same pattern, we can say, for any group which attains a stationary state, the value of $\Delta$ either remains same or decreases by $1$ . $\therefore \Delta_k\leq{a_j}$ , $\forall k \in \{1,2,3,......,n\}$ This completes the proof of our claim. $\blacksquare$ Hence, we can say, $\Delta_1\geq\Delta_2\geq.......\geq\Delta_n$ . This clearly proves $\Delta$ is a non-increasing function.. But, we also observe that the value of the sum $\Omega$ increases by $1$ after every step. $\Omega_{k}= a_{1k}+a_{2k}+.......+a_{nk}$ $\Omega_{k}<\Delta_{k}+\Delta_{k}+...... n$ times $\implies \Omega_{k}<n.\Delta_{k}$ . $\implies \Omega_{k}<n.\Delta_{0}$ But, $\Delta_{0}$ is a constant.. $\Omega$ increases constantly by $1$ . Hence, for this inequality to hold true, $\Omega$ cannot increase indefinitely, and therefore, the process must terminate after finite number of steps... Q.E.D. $\square$ Is my proof correct? If not, can someone please prove it in a more elegant way?","['alternative-proof', 'solution-verification', 'combinatorics']"
3761664,Using Haversine formula to solve for a single coordinate X miles away,"I am using the Haversine formula to calculate a distance in miles between two (lat, lng) coordinate pairs.  (Note: I am aware and okay with limitations in the formula related to the non-spheroidal (ellipsoidal) shape of the Earth.) I would like to use this formula to solve for either a single latitude or single longitude that is due north, east, west, or south of a given coordinate.  This is maybe best illustrated through a diagram; I have the central red point as given and am trying to solve for the 4 outer red points below : From the central coordinate of (38.0, -77.0), I want to solve ( individually ) for the 4 missing points at each side of the circle pictured, assuming a distance of 5 miles.  So in each equation, I am given a distance and 3 coordinates, and want to solve for the 4th coordinate. How can I rework Haversine formula to solve for an individual coordinate given the other 3? What I have tried is to use sympy , but the calculation seems to time out, unless I have a symbol wrong somewhere.  I've also tried to invert the formula, but have gotten stuck halfway. To use the top point ( lat2, -77.0) as an example, I'm given the formulas dlon = lon2 - lon1
dlat = lat2 - lat1
a = (sin(dlat/2))^2 + cos(lat1) * cos(lat2) * (sin(dlon/2))^2
c = 2 * atan2( sqrt(a), sqrt(1-a) )
d = R * c (where R is the radius of the Earth) 

lat1 = radians(38.0)
lon1 = radians(-77.0)
lon2 = radians(-77.0)
d = 5.0 And want to solve for lat2 .","['trigonometry', 'geometry']"
3761689,Why is my value for the length of daylight wrong?,"I was watching a YouTube video where it showed how length of daylight changes depending on the time of year, and I was curious and wanted to try calculating the value of how long the daylight is in the Tropic of Cancer (23.5 degrees latitude) during the winter solstice, apparently 10 hours and 33 minutes or so according to the video. Here is the timestamp for reference. This is my work (the yellow blobs represent 23.5 degrees and the pink blobs 43 degrees): $\sin(66.5 \text{ degrees}) = (\text{yellow leg + orange leg}) / r$ implies $0.917060r = \text{yellow leg + orange leg}$ $\cos(66.5 \text{ degrees}) = \text{purple leg} / r$ implies $0.398749r = \text{purple leg}$ $\tan(23.5 \text{ degrees}) = \text{orange leg / purple leg}$ implies $0.434812 \cdot \text{ purple leg} = \text{orange leg}$ Subbing in the value we already got from the purple leg, we get $0.173381r = \text{orange leg}$ That means the orange leg is $0.173381r/ 0.917060r$ fraction of the yellow and orange leg, about $0.189061784$ . This represents how much extra darkness there is along the line. Since this darkness is on both sides of the globe, I multiply it by two, to get $0.37812$ . So the daylight is about $37.81$ % shorter, down from $12$ hours to about $7.46$ hours. Way off compared to the video's $10$ hours $33$ minutes. Where is my mistake?","['trigonometry', 'algebra-precalculus', 'mathematical-astronomy', 'geometry']"
3761706,Evaluating a binomial summation,"I'm interested in evaluating the following summation, where the value of $n$ is known: $$\sum_{i = 0}^{2n} \sum_{j = \max(0, i - n)}^{\min(i, n)} {i \choose j}.$$ In case you're wondering where the summation comes from, it is the answer to the following question: ""How many binary strings of length $\leq 2n$ can you form with no more than $n$ ones and $n$ zeros?"". The summation in $i$ fixes the length of the string, and the summation in $j$ fixes the number of ones we use. By splitting the summation from $i = 0$ to $i = n$ and $i = n + 1$ to $i = 2n$ , I am able to rewrite the sum as follows: $$\sum_{i = 0}^{n}\sum_{j = 0}^{i} {i\choose j} + \sum_{i = n + 1}^{2n} \sum_{j = i - n}^{n} {i\choose j}.$$ Call the two summations $S_1$ and $S_2$ respectively. By the sum of binomial coefficients identity, I can evaluate $S_1$ as follows: $$S_1 = \sum_{i = 0}^{n}\sum_{j = 0}^{i} {i\choose j} = \sum_{i = 0}^{n} 2^{i} = 2^{n + 1} - 1.$$ Now, I'm having trouble evaluating $S_2$ . I've tried writing out the terms to find patterns. I've also tried using Hockeystick with no luck. I've also tried switching the order of summation, but this also led me nowhere. Can someone please help me solve this problem or provide me with a hint? When $n = 2$ , the summation evaluates to $19$ . When $n = 3$ , the summation evaluates to $69$ . When $n = 4$ , my computer program gave me $251$ . I think this is OEIS A030662 , which has a few closed forms, but I want to find it myself. One interesting closed form is ${2n\choose n} - 1$ . Thank you","['summation', 'binomial-coefficients', 'combinatorics']"
3761709,Is it possible to subdivide a regular polygon of side-length $n$ into equilateral polygons of side-length $1$?,"Suppose I have a regular polygon whose sides each measure $n$ . I want to cut it up into smaller equilateral (but not necessarily regular) polygons whose sides each measure $1$ . Is this possible? If yes, what's a simple (easy to implement) algorithm that can generate the subdivision?",['geometry']
3761716,"Is there an ""algebraic"" way to construct the reals?","It's possible to construct $\mathbb{Q}$ from $\mathbb{Z}$ by constructing $\mathbb{Z}$ 's field of fractions, and it's possible to construct $\mathbb{C}$ from $\mathbb{R}$ by adjoining $\sqrt{-1}$ to $\mathbb{R}$ . In both cases, the construction is done purely algebraically. I.e. we only rely on the operations of our given structure to build the new structure. But at no point do we have to rely on the order properties of $\mathbb{Z}$ or $\mathbb{R}$ to get to $\mathbb{Q}$ or $\mathbb{C}$ . Every construction of $\mathbb{R}$ that I'm familiar with ultimately comes down to endowing $\mathbb{Q}$ with its usual order, and then imposing the completeness axiom on it to recover the rest of the real numbers. Is it possible to get to $\mathbb{R}$ from $\mathbb{Q}$ without relying on the ordering properties of $\mathbb{Q}$ ? Alternatively (relatedly?): There is the notion of a greatest common divisor for an arbitrary ring. This notion doesn't rely on any ordering properties; just algebraic ones. Is it possible to recover an order relation on $\mathbb{Q}$ using the GCD relation on $\mathbb{Z}$ , then to impose completeness on $\mathbb{Q}$ and obtain $\mathbb{R}$ , and then subsequently re-cast completeness in some algebraic manner? Thus defining $\mathbb{R}$ in purely algebraic terms?","['real-numbers', 'abstract-algebra']"
3761723,Is this the right way of solving $\frac{d}{dx}(\sin(x)\cdot x^2)$,"I don't know much about theorems related to limits and I'm currently learning calculus from 3Blue1Brown's online series : Essence of Calculus . This example's generalization is what I'll use to derive the product rule. Now, if we have a rectangle with length and breadth equal to $\sin(x)$ and $x^2$ for some values of $x$ , then it's area will be : $\sin(x)\cdot x^2$ . Now, if we ""nudge"" the value of $x$ by some little amount, say, $dx$ , then there will be corresponding changes in the values of $\sin(x)$ and $x^2$ . Let the little change in $\sin(x)$ be $d(\sin(x))$ and the little change in $x^2$ be $dx^2$ . Now, the change in the value of $(\sin(x)\cdot x^2)$ i.e. $d(\sin(x)\cdot x^2)$ will be the sum of the three new strips of area. $$\therefore~ d(\sin(x)\cdot x^2) = \sin(x)\cdot dx^2+x^2\cdot d(\sin(x))+dx^2\cdot d(\sin(x))$$ .
Now, $dx^2 = 2x\cdot dx$ , $d(\sin(x)) = \cos(x)\cdot dx$ . $$\therefore~ \dfrac{d(\sin(x)\cdot x^2)}{dx} = \dfrac{\sin(x)\cdot dx^2+x^2\cdot d(\sin(x))+dx^2\cdot d(\sin(x))}{dx}$$ $$ = \dfrac{\sin(x)\cdot 2x\cdot dx + x^2\cdot\cos(x)\cdot dx + 2x\cdot dx\cdot \cos(x)\cdot dx}{dx}$$ $$ = \sin(x)\cdot 2x + x^2\cdot \cos(x) + 2x\cdot \cos(x)\cdot dx$$ Now, as $dx \rightarrow 0$ , $\dfrac{d(\sin(x)\cdot x^2)}{dx} \rightarrow \sin(x)\cdot 2x + x^2\cdot\cos(x)$ because anything in the form of $p(dx)^n$ , where $p \in \Bbb R$ and $n \in \Bbb Z^+$ will approach $0$ as well. So, we can say that $\dfrac{d(\sin(x)\cdot x^2)}{dx} = \sin(x)\cdot 2x + x^2\cdot\cos(x)$ as $$\dfrac{d}{dx} f(x) = \lim_{\Delta x \rightarrow 0}\dfrac{f(x+\Delta x) - f(x)}{\Delta x}$$ I want to know if I've done all of this correctly, without any conceptual mistakes. Thanks!","['calculus', 'solution-verification', 'derivatives']"
3761730,Using partial information to factor $x^6+3x^5+5x^4+10x^3+13x^2+4x+1.$,"I wish to find exact expressions for all roots of $p(x)=x^6+3x^5+5x^4+10x^3+13x^2+4x+1.$ By observing that for the roots $x_0 \pm iy_0, x_0 \approx -0.15883609808599033632, y_0 \approx 0.27511219196092896700,$ we have that $x_0$ is the unique real root of $r(x) = x^3+12x^2+8x+1,$ I was able to prove that all roots of the original sextic can be expressed in radicals. The process is as follows: Divide $p(x+iy)$ by $r(x)$ to get $\frac{1}{8}x^3 + \frac{3}{16}x^2 + x\left(\frac{7}{32}-\frac{15y^2}{8}\right) + \left(\frac{95}{32}-\frac{15y^2}{16}\right) + \frac{R(x,y)}{p(x)}$ where $R(x,y) = A(y)x^2 + B(y)x + C(y)$ and $A(y) = 15y^4 - \frac{15y^2}{4} - \frac{201}{16}, B(y) = 15y^8 - 30y^6 + 12y^4 + \frac{75y^2}{8} - \frac{767}{32}, C(y) = -y^6+5y^4-\frac{193y^2}{16}-\frac{63}{32}.$ The equation $R(x_0, y_0) = 0$ is a quartic in $y_0^2,$ which we can solve exactly to obtain $y_0^2$ and hence $y_0.$ Polynomial division reduces $p(x)$ to a quartic, and now we apply the quartic formula again to find the other $4$ roots. However, I don't want to perform the rest of the computations. Is there a cleaner way to use the observation that $r(x_0) = 0,$ perhaps in the realm of abstract algebra?","['cubics', 'roots', 'abstract-algebra', 'polynomials', 'algebra-precalculus']"
3761736,"If$|f(x)-f(y)|\le (x-y)^2$, prove that $f$ is constant","(Baby Rudin Chapter 5 Exercise 1) Let $f$ be defined for all real $x$ , and suppose that \begin{equation}\tag{1}
    |f(x)-f(y)|\le (x-y)^2
\end{equation} Prove that $f$ is constant. My attempt: Let $f$ be defined for all real-valued inputs. Let $x \in \mathbb{R}$ and $y \in \mathbb{R} \smallsetminus \{ x \}$ , and suppose that (1) holds.
Then, we have: \begin{align*}
        \left| \dfrac{f(x)-f(y)}{x-y}\right| \le (x-y)
    \end{align*} As $x\to y,  \lim\limits_{x \to y}\left| \dfrac{f(x)-f(y)}{x-y}\right| \le 0$ . Since it cannot be that $\left|f'(y)\right| < 0$ , we have that $\left|f'(y)\right| = 0 \implies f'(y) = 0$ . Can someone please read over my proof and let me know if it is correct?","['solution-verification', 'real-analysis']"
3761740,Can you find a function $\beta(x)$ where if $a+b=n^m$ then $\beta(\frac{a}{b})$ is irrational?,"Can you find a function $\beta(x)$ where if $a+b=n^m$ then $\beta(\frac{a}{b})$ is irrational but if $a+b$ isn't equal to $n^m$ then it is rational ( $a$ and $b$ are co-prime)? $n>0$ and $m>1$ $m$ and $n$ are integers When $x$ is an irrational number, $\beta(x)$ can be either rational or irrational. $\beta(0)=\pi$ $\beta(x)$ is differentiable everywhere.","['recreational-mathematics', 'perfect-powers', 'real-analysis']"
3761747,"Through two given points on a circle, construct two parallel chords with a given sum.","The problem is from Kiselev's Geometry exercise 317. Through two given points on a circle, construct two parallel chords with a given sum. Here is what I have tried so far: Mark the two points by $A$ and $C$ respectively. If we have constructed such two chords and marked the two other points by $B$ and $D$ , the quadrilateral $ABCD$ is an isosceles trapezoid where $AC$ is a diagonal and (without loss of generality) $AB$ and $CD$ are parallel. The midline of the bases measures half of the given sum, and it passes through the midpoint of the diagonal $AC$ . Unfortunately, I could not progress any further from here; I think I should utilize the fact that the 4 points are concyclic and $ABCD$ is an isosceles trapezoid, but I could not find usage of the fact. Any help would be much appreciated.","['euclidean-geometry', 'circles', 'geometry', 'geometric-construction']"
3761762,"How to solve $\int\frac{1}{\sqrt {2x} - \sqrt {x+4}} \, \mathrm{dx} $?","$$\int\frac{1}{\sqrt {2x}  -  \sqrt {x+4}} \, \mathrm{dx}$$ I have tried $u$ -substitution and multiplying by the conjugate and then apply $u$ -substitution. For the $u$ -substitution, I have set $u$ equal to each square root term, set $u$ equal to the entire denominator, and set $u$ equal to each expression in the radical. However, all my attempts have just made the integral more complex without an obvious way to simplify. Can someone provide insight please? Thank you.","['integration', 'indefinite-integrals', 'calculus']"
3761767,It is a valid approach to prove that the inverse of a inverse function is the function itself?,"In the question is assumed that the function $f$ is a one-to-one function from $A$ onto $B$ . Here is my atempt: By definition I have that: $f^{-1} = \{(x,y) : (y,x) \in f\}$ and from this I conclude that $(f^{-1})^{-1} = \{(x,y) : (y,x) \in f^{-1}\}$ First let some $t$ belong to $(f^{-1})^{-1}$ where $t=(a,b)$ , from this we have that $(b,a) \in f^{-1}$ , but if $(b,a)$ is in $f^{-1}$ , then $(a,b) = t \in f$ and from this $(f^{-1})^{-1} \subseteq f.$ Now let some $t$ belong to $f$ with $t=(u,v)$ , from this we have that $(v,u) \in f^{-1}$ and then $t = (u,v) \in (f^{-1})^{-1}$ and therefore $f \subseteq (f^{-1})^{-1}$ $$[((f^{-1})^{-1} \subseteq f) \land (f \subseteq (f^{-1})^{-1})] \Leftrightarrow (f^{-1})^{-1} = f$$ This question is under the exercises about composition of functions, should I have using some property of composition?","['elementary-set-theory', 'functions', 'solution-verification']"
3761774,An implementation of a general solution of Abel's equations,"Introduction An Abel equation of the second kind in its canonical form is writen as $$y(x)y'(x)-y(x)=f(x)\quad  (6)$$ for arbitrary $f(x)$ . This equation has a general solution derived by 1 2 (Check Wikipedia article for Abel equation of the first kind , which in some cases reduces to the above form) What I am trying to do is to solve the equation $$y(x)y'(x)-y(x)=Ax^2  $$ over the reals with $A$ constant. This equation does not appear in the tabulated solutions of Polyanin, Manzhirov , so I tried to implement the method from the paper 1 . However, I noticed that the solution does not agree with the numerics, so I tried to run my code on an equation that we know the solution to, which is: $$y(x)y'(x)-y(x)=x  $$ The result is summarised below using the language of Mathematica. As we can see, the analytical plot does not belong to the solution family seen in the second picture. Goal I am trying to write a code that would apply the method described in 1 to solve the general Abel equation. The solution can be applied in any programming language. Method Code (*Solving for y*)
ζ[x_] = Log[Abs[x + 2 λ]]
F[x_] = ζ[x]
G[ζ_] = 
1/16 ((ζ Sin[ζ] + Cos[ζ]) CosIntegral[ζ] + 
 Cos[ζ]^2)*(4 ζ CosIntegral[ζ] + 
  Cos[ζ] )/(ζ CosIntegral[ζ])^3 Exp[-ζ] - 
2 F[ζ]

a = -4;
b[ζ_] = 3 + 4 (G[ζ] + F[ζ]) Exp[-ζ]
c[ζ_] = - 4 (G[ζ] + 2 F[ζ]) Exp[-ζ]

p[ζ_] = -a^2/3 + b[ζ]
q[ζ_] = 2 (a/3)^3 - a b[ζ]/3 + c[ζ]
NN = Solve[Z^3 + p Z + q == 0, Z] /. {p -> p[ζ], 
 q -> q[ζ]} /. ζ -> ζ[x];
y = Table[
Table[1/2 (x + 2 λ) ((Z /. NN[[ii]]) + 1/3), {ii, 1, 
 3}], {λ, 1, 2}];

(*Benchmarking*)
DSolve[Y'[X] Y[X] - Y[X] == X, Y[X], X]

p1 = Plot[y, {x, 0, 10}]
p2 = Table[
ContourPlot[
1/10 ((5 + Sqrt[5]) Log[
      1 + Sqrt[5] - (2 Y)/X] - (-5 + Sqrt[5]) Log[-1 + Sqrt[5] + (
       2 Y)/X]) == II - Log[X], {X, 0, 10}, {Y, -10, 15}], {II, 0,
 3, 0.2}];
Show[p2] Plots The plots look not alike References Dimitrios E. Panayotounakos, ""Exact analytic solutions of unsolvable classes of first and second""
order nonlinear ODEs (Part I: Abel’s equations) Panayotounakos, Dimitrios E.; Zarmpoutis, Theodoros I, ""Construction of Exact Parametric or Closed Form Solutions of Some Unsolvable Classes of Nonlinear ODEs (Abel's Nonlinear ODEs of the First Kind and Relative Degenerate Equations)"".","['nonlinear-analysis', 'ordinary-differential-equations']"
3761776,"How can we combine ""cases"" of solutions to equations (eg, $\sin x=\sin\theta$) as a unified ""$x=\cdots$"" statement?","Suppose we were to solve the equation: $$\sin x=\sin \theta$$ After solving we obtain the following solutions: $$
\left\{ 
\begin{aligned}
x&=\theta +2k\pi \\ \mathbf {or}\\
x&=\pi -\theta + 2k\pi
\end{aligned}
\right.
$$ How do you rewrite the solutions using only one equation? In our particular case, we can write: $$x=k\pi + (-1)^k\theta
$$ for every integer $k$ . How would you derive this? I need a method capable of uniting any set of equations with some solutions into one equation with the same solutions.","['algebra-precalculus', 'trigonometry']"
3761785,A question of why these integrands can be taken out of the integrals.,"Rudin says that (2) can be rewritten as (4), as seen below. However, both integrands in (2) respectively depend on $x$ and $y$ , which implies that (2) could not be rewritten as (4). Is there any problem in my understanding? Thanks a lot.","['integration', 'measure-theory', 'lebesgue-integral', 'real-analysis', 'product-measure']"
3761814,How to evaluate $\int _0^{\infty }\frac{\ln \left(x^3+1\right)}{\left(x^2+1\right)^2}\:dx$ without complex analysis,"This particular integral evaluates to, $$\int _0^{\infty }\frac{\ln \left(x^3+1\right)}{\left(x^2+1\right)^2}\:dx=\frac{\pi }{8}\ln \left(2\right)-\frac{3\pi }{8}+\frac{\pi }{3}\ln \left(2+\sqrt{3}\right)-\frac{G}{6}$$ And its been proven here .
But i'd like to know how to evaluate this without complex analysis. One of the answers uses differentiation under the integral sign directly and partial fraction decomposition on a similar integral, but doing it that way doesnt help me with this case here
I tried to evaluate this way but got stuck, $$\int _0^{\infty }\frac{\ln \left(x^3+1\right)}{\left(x^2+1\right)^2}\:dx=\int _0^1\frac{\ln \left(x^3+1\right)}{\left(x^2+1\right)^2}\:dx+\int _1^{\infty }\frac{\ln \left(x^3+1\right)}{\left(x^2+1\right)^2}\:dx\:\:\:\:\:\: \text{then sub}\:\:x=\frac{1}{t}\:\:\text{for the 2nd integral}$$ $$=\int _0^1\frac{\ln \left(t^3+1\right)}{\left(t^2+1\right)^2}\:dt+\int _0^1\frac{t^2\ln \left(t^3+1\right)}{\left(t^2+1\right)^2}\:dt-3\int _0^1\frac{t^2\ln \left(t\right)}{\left(t^2+1\right)^2}\:dt$$ $$=\int _0^1\frac{\ln \left(t^3+1\right)}{t^2+1}\:dt+3G+3\int _0^1\frac{\ln \left(t\right)}{\left(t^2+1\right)^2}\:dt$$ I managed to evaluate the last integral expanding the denominator but i cant think of a way to evaluate the 1st integral, please help me.","['integration', 'definite-integrals']"
3761834,"Random Variables $X_n(\omega)=\sin(2\pi n\omega),\,n=1,2,\dots$ are Uncorrelated but not Independent","Problem: Let $\Omega=(0,1),\,\mathcal F=$ Borel sets, $P=$ Lebesgue measure. Define the sequence of random variables $X_n(\omega)=\sin(2\pi n\omega),\,n=1,2,\dots$ . Show that the random variables are
uncorrelated but not independent. Attempt: Let $n,m\in\mathbb N$ with $n\ne m$ . \begin{align}
E[X_nX_m]&=\int_0^1\sin(2\pi n\omega)\sin(2\pi m\omega)\,dP\\
&=\frac{1}{2}\int_0^1\cos[2\pi \omega(n-m)]-\cos[2\pi\omega(n+m)]\,dP\\
&=\frac{1}{2}\left[\frac{\sin[2\pi\omega(n-m)]}{2\pi(n-m)}-\frac{\sin[2\pi\omega(n+m)]}{2\pi(n+m)}\right]\Bigg\vert_0^1\\
&=0.
\end{align} Next, we have $$E[X_n]=\int_0^1\sin(2\pi n\omega)\,dP=-\frac{\cos(2\pi n\omega)}{2\pi n}\Bigg\vert_0^1=0.$$ It follows that $$E[X_nX_m]-E[X_n]E[X_m]=0.$$ Therefore, the random variables are uncorrelated. Now we prove that they are not independent. Let $n,m\in\mathbb N$ with $n\ne m$ . Then $X_n(\omega)=0$ for $\omega=k/2n$ where $k\in\mathbb N$ with $0\leq k\leq 2n$ . On this set, $X_m$ takes on
the values $\{y_0,y_1,\dots,y_{2n}\}$ . Now define $V_m=\bigcup_{j=0}^{2n}(y_i,y_i+\varepsilon)$ , where $\varepsilon>0$ is sufficiently small. Now let $a<b$ with $[a,b]\subset[0,1]\setminus V_m$ .
The continuity of the sine function implies that $$P(X_n\in[0,\varepsilon],X_m\in[a,b])=0<P(X_n\in[0,\varepsilon])\cdot P(X_m\in[a,b]).$$ It follows that the random variables are not independent. I am concerned about my work for the proof that the random variables are not independent. I graphed some examples and it seems to work, same as for the actual proof, but I have a hunch that it is not airtight. Could anyone please give me some feedback on the proof above and whether it is airtight or not? Any comments are most welcomed and appreciated. Thank you very much for your help.","['real-analysis', 'solution-verification', 'probability-theory', 'probability', 'random-variables']"
3761891,Chern classes and almost complex submanifolds,"Suppose $M$ is a manifold endowes with an almost complex structure, such that the Chern classes $c_i(M)$ of $M$ are defined. Can we say that the Poincare dual to $c_i(M)$ can be represented by an almost complex submanifold of $M$ ?","['differential-topology', 'almost-complex', 'algebraic-topology', 'differential-geometry']"
3761908,Does the Van der Pol equation with negative parameter explode outside a circle?,"Consider the Van der Pol system $$
\mathrm{\frac d {dt}}\begin{bmatrix}x\\y\end{bmatrix}
=
\begin{bmatrix}y\\\mu(1-x^2)y-x\end{bmatrix}
$$ with $\mu < 0$ . It attains an asymptotically stable equilibrium at the origin. Is there a circle centered at the origin such that for every trajectory that starts outside the circle, $\|x\| \to \infty$ as $t \to \infty$ ? It definitely looks like it, but I don't know how I'd prove it.","['stability-in-odes', 'stability-theory', 'ordinary-differential-equations']"
3761920,"if the lcm is simply the product, then the integers are pairwise prime","I am trying to prove that let $n_1,\ldots,n_k \in \Bbb Z\setminus\{0\}$ . then $\gcd(n_i,n_j)=1 \forall i\neq j$ iff $\operatorname{lcm}(n_1,\ldots,n_k)=n_1\cdots n_k$ I can prove "" $\Rightarrow$ "" this direction by the fact that $\gcd(n_1,n_1)\operatorname{lcm}(n_1,n_2)=n_1n_2$ and by induction on $k.$ But I do not know if the converse is true or not, it is obvious when $k=1$ , as $\gcd(n_1,n_1)\operatorname{lcm}(n_1,n_2)=n_1n_2$ . But I got stuck at extend $k$ from $2$ to any natural number. Any suggestion will be appreciated","['number-theory', 'gcd-and-lcm']"
3761936,"Solution to recurrence $c_{l+1,t}=c_{l,t+1}-c_{l-1,t+1}$.","I have the following recurrence: $$c_{l+1,t}=c_{l,t+1}-c_{l-1,t+1}\tag{1}$$ I know the initial conditions: $$c_{k,t}=0 \;\;\forall \;\; k<0$$ $$c_{0,t}=\frac{{2t \choose t}}{t+1}$$ I know the solution to the recurrence is: $$c_{l,t}={2t+l \choose t}\frac{l+1}{t+l+1}$$ How do I get this closed form expression (I can prove it with induction when I know the solution, but how would I have found it)? My attempt: Substitute $l=0$ in equation (1). $$c_{1,t}=c_{0,t+1}$$ Now substitute $l=1$ $$c_{2,t}=c_{0,t+2}-c_{0,t+1}$$ With $l=2$ $$c_{3,t}=c_{0,t+3}-2c_{0,t+2}$$ Going on like this, $$c_{4,t}=c_{0,t+4}-3c_{0,t+3}+c_{0,t+2}$$ $$c_{5,t}=c_{0,t+5}-4c_{0,t+4}+3c_{0,t+3}$$ $$c_{6,t}=c_{0,t+6}-5c_{0,t+5}+3c_{0,t+4}+2c_{0,t+3}$$ $$c_{7,t}=c_{0,t+7}-6c_{0,t+6}+4c_{0,t+5}+3c_{0,t+4}-c_{0,t+3}$$ I can't see any pattern (apart from $c_{l,t}=c_{0,t+l}-(l-1)c_{0,t+l-1}+<stuff>$ ) emerging.","['binomial-coefficients', 'recurrence-relations', 'sequences-and-series']"
3761983,Find the sum $\sum_{n=0}^{49} \sin((2n+1)x) $,This was an exercise in a chapter of a textbook on product to sum and sum to product trigonometric identities. The following question was asked with the given hint: $$\sum_{n=0}^{49} \sin((2n+1)x) $$ Hint: multiply this sum by $2\sin(x)$ My attempt $$\sum_{n=0}^{49} \sin((2n+1)x)=1/2\csc(x)\sum_{n=0}^{49} 2\sin(x)\sin((2n+1)x) $$ Using identity $2\sin(A)\sin(B)=\cos(A-B)-\cos(A+B)$ $$1/2\csc(x)\sum_{n=0}^{49} 2\sin(x)\sin((2n+1)x)=1/2\csc(x)\sum_{n=0}^{49} \cos(2nx)-\cos((2n+2)x)$$ How do I continue from here?,['trigonometry']
3761986,Integral: $\int \dfrac{dx}{(x^2-4x+13)^2}$?,"How can I integrate $$\int \dfrac{dx}{(x^2-4x+13)^2}?$$ Here is my attempt: $$\int \dfrac{dx}{(x^2-4x+13)^2}=\int \dfrac{dx}{((x-2)^2+9)^2}$$ Substitute $x-2=3\tan\theta$ , $\ dx=3\sec^2\theta d\theta$ \begin{align*}
&=\int \dfrac{3\sec^2\theta d\theta}{(9\tan^2\theta+9)^2}\\
&=\int \dfrac{3\sec^2\theta d\theta}{81\sec^4\theta}\\
&=\dfrac{1}{27}\int \cos^2\theta d\theta\\
&=\dfrac{1}{27}\int \frac{1+\cos2\theta}{2} d\theta\\
&=\dfrac{1}{54}\left(\theta+\frac{\sin2\theta}{2}\right)+C
\end{align*} This is where I got stuck. How can I get the answer in terms of $x$ ? Can I solve it by other methods?","['integration', 'indefinite-integrals', 'calculus', 'trigonometric-integrals']"
3762011,"""Not in set"" notation within the set definition","I am trying to define a set such that for two elements $a$ and $b$ , such that $a$ can only be in the set if $b$ is not. For example, lets say $a$ is a natural number and $b = 5 - a$ . I defined it as $S = \lbrace { a | \exists b: (a + b = 5) \wedge a \in \mathbb{N} \wedge b \notin S}\rbrace$ . My question is, can I use S on the right hand side of the definition of S itself? (The example is very trivial. It is just for clarity.)","['elementary-set-theory', 'notation']"
3762014,Evaluate $\displaystyle \sum_{n=1}^{89}\tan^2\bigg(\frac{n\pi}{180}\bigg)$.,"Find $\displaystyle \sum_{n=1}^{89}\tan^2\bigg(\frac{n\pi}{180}\bigg)$ . I didn't have any idea to solve this problem :/
Can someone give a hint for me? What is the best strategy to solve problems of the type $\displaystyle \sum_{k=1}^{n}\tan^2(k\theta)?$","['trigonometry', 'summation']"
3762021,"Given an $n\times n\times n$ cube, what is the largest number of $1\times 1\times 1$ blocks that a plane can cut through?","This question is of recreation nature, but could be made more serious. Given a $3\times 3\times 3$ cube, what is the maximum number of small $1\times 1\times 1$ blocks a plane could cut through? More generally, how about an $n\times n\times n$ cube? Is there general reference about this type of questions? Batominovski's edit: A Lower Bound Note that, in a $3\times 3$ square, it is possible to cut five $1\times 1$ cells with a line.  Therefore, it is possible to cut at least $3\cdot 5=15$ unit blocks of a $3\times 3\times 3$ cube with a plane.  Thus, $15$ is a lower bound for the correct answer. For the general case, it can be easily seen that we can cut an $n\times n$ square with a line that go through $2n-1$ unit cells.  Thus, in the $3$ -dimensional setting, we can cut an $n\times n\times n$ cube with a plane that go through $n(2n-1)$ unit blocks.  Hence, $n(2n-1)$ is a lower bound for the correct answer.","['combinatorial-geometry', 'recreational-mathematics', 'combinatorics', 'geometry']"
3762025,Prove that $\frac{1}{a_1 + 1} + \frac{1}{a_2 + 1} + \dots + \frac{1}{a_n + 1} < 2$ for all $n \ge 1.$,The sequence $a_n$ is defined by $a_1 = \frac{1}{2}$ and $a_n = a_{n - 1}^2 + a_{n - 1}$ for $n \ge 2.$ Prove that $\frac{1}{a_1 + 1} + \frac{1}{a_2 + 1} + \dots + \frac{1}{a_n + 1} < 2$ for all $n \ge 1.$,['algebra-precalculus']
3762053,Does the center of a perfect group not contain all elements of prime order?,Let $G$ be a finite perfect group (i.e. $G=G'$ ) and $Z(G)$ be its center. I don't know whether this statement is correct: There exists an element $x$ of prime order such that $x\notin Z(G)$ . A quick check on CFSG gives that this holds for every (quasi-)simple group. But what if $G$ is a general finite perfect group? Or is there any further descriptions on the center of perfect groups? Another description on this question is (also I don't know if this holds): Let $H$ be a center-less (insoluble) group (i.e. $Z(H)=1$ ). Then there always exists a prime divisor $p$ of $|H|$ such that the $p$ -part of the Schur multiplicator of $H$ is trivial. Is there any result on both?,"['group-theory', 'abstract-algebra', 'finite-groups', 'reference-request']"
3762080,"If $M$ is a domain of class $\mathcal C$, is $\partial M$ a $(d-1)$-dimensional $\mathcal C$-submanifold?","Let $\mathcal C$ be a class of functions between Banach spaces, $d\in\mathbb N$ and $k\in\{1,\ldots,d\}$ . We say that $M\subseteq\mathbb R^d$ is a $k$ -dimensional embedded $\mathcal C$ -submanifold of $\mathbb R^d$ if $M$ is locally $\mathcal C$ -homeomorphic $^1$ to $\mathbb R^k$ . On the other hand, we say $^2$ that $\partial M$ is of class $\mathcal C$ if for each $x\in M$ , there is an open neighborhood $\Omega$ of $x$ and a function $g:\mathbb R^{d-1}\to\mathbb R$ of class $\mathcal C$ with $$\Omega\cap M=\{x\in\Omega:x_d>g(x_1,\ldots,x_{d-1})\}.\tag1$$ And lastly, if $M$ is compact, I've seen that people say that $\partial M$ is of class $C^1$ if for each $x\in M$ , there is an open neighborhood $\Omega$ of $x$ and a $\psi\in C^1(U)$ with $\psi'(x)\ne0$ for all $x\in\Omega$ and $$\Omega\cap M=\{\psi\le0\}\tag2.$$ How do all these three (the first applied for $\partial M$ instead of $M$ ) come together? Can we given an equivalent characterization of the second, which does not rely on an appropriate coordinate transformation? And how can we show that if $\partial M$ is of class $\mathcal C$ , then $\partial M$ is a $(d-1)$ -dimensional embedded $\mathcal C$ -submanifold? (I'm willing to assume that $M$ is bounded and open for this implication to hold.) It is clear that if $\partial M$ is of class $C^1$ (in the sense of the third definition), then $\partial M$ is a $(d-1)$ -dimensional embedded $C^1$ -submanifold $^1$ i.e. for each $x\in M$ , there is an open neighborhood $\Omega$ of $x$ and a homeomorphism $\varphi$ from $\Omega$ onto an open subset of $\mathbb R^k$ so that $\varphi$ and $\varphi^{-1}$ are of class $\mathcal C$ . $^2$ see Definition 7.2.1 here . I'm not happy with this definition, since it implicitly assumes an appropriate coordinate transformation.","['manifolds', 'submanifold', 'smooth-manifolds', 'differential-geometry']"
3762090,Find the values of α and β for which this series converges.,"The given series is, $$\sum\limits_{n\geq 1}(\sqrt{n+1}-\sqrt{n})^{\alpha}(\ln(1+1/n))^{\beta}$$ With $\alpha, \beta \in \mathbb{R}$ . I don't know how to begin, noreven which criterion use to find the values of $\alpha$ and $\beta$ for which this series converges.","['convergence-divergence', 'sequences-and-series']"
3762141,"If $T:(\mathbb{R}^2,\|\cdot\|_p) \to (\mathbb{R}^2,\|\cdot\|_q)$ is an onto linear isometry, then must it be $p=q$?","Question: Let $p,q\in [1,\infty)$ and suppose that that $T:(\mathbb{R}^2,\|\cdot\|_p) \to (\mathbb{R}^2,\|\cdot\|_q)$ is an onto linear isometry. Must it be $p=q$ ? I think it is true as isometry preserves extreme points.
However, it would be good if there is an elementary arguments.","['isometry', 'lp-spaces', 'functional-analysis', 'real-analysis']"
3762194,"If $X$ and $X^2$ are identically distributed then $X \in \{0,1\} $ almost surely","If a random variable $X$ is identically distributed to its square than it is almost surely non-negative, further for the distribution function it follows, that $F_X(x)\overset{id}{=} F_{X^2}(x)= F_X(\sqrt{x})$ , so iteratively applied, one get $F_X(x)= F_X(x^{1/2n}) $ so in the limit $ n \to \infty $ we get $F_X(x) =F_X(1) \Leftrightarrow P(X\in [0, x])= P(X\in [0,1])$ . Further, for the survival function we have $P(X\in (x,\infty )) = P(X \in (1, \infty))$ .
No how did we see that $P(X \in \{0,1\})=1$ ?
How is $P(X \in (1, \infty))=0 $ and $P(X \in (0,1))=0$ (that $P(X<0)=0$ is clear)?","['probability-distributions', 'probability-theory']"
3762212,Inverse of function is itself?,"Let $f(x) =$ \begin{cases}
k(x) &\text{if }x>3, \\
x^2-6x+12&\text{if }x\leq3.
\end{cases} Find the function $k(x)$ such that $f$ is its own inverse. I thought that that inverse would just be the inverse of $x^2-6x+12$ would be $3+\sqrt{x-3}$ , however, after graphical analysis, I found the answer to be the conjugate: $3-\sqrt{x-3}$ .
Is this the right answer, and if so, why is it negative instead of positive?","['functions', 'inverse']"
3762229,Does a function which is oscillating have to have not-continuous derivative?,"If $f(x)$ is a differentiable function  which is not $0$ everywhere  and has the property that around any interval around $0$ , $f$ is neither fully positive or negative. Then it can be proven that $f(0)=0$ . An example of such a function is $$\begin{cases}x^2\sin({1\over x}) & \text{ for }x\neq 0,\\ 0 &\text{ for }x=0.\end{cases}$$ All such functions I have seen so far satisfy this. Q: Is it true that the derivative of such a function cannot be continuous or is there a counter-example? I feel that such a function exists and have tried a few examples but have been unable to find one.","['calculus', 'derivatives', 'examples-counterexamples', 'real-analysis']"
3762261,Intuition on spectral theorem,"In the last month I studied the spectral theorems and I formally understood them. But I would like some intuition about them. If you didn’t know spectral theorems, how would you come up with the idea that symmetric/normal endomorphisms are the only orthogonally diagonalizable endomorphisms in the real/complex case. How would you even come up with the idea of studying the adjoint?","['diagonalization', 'spectral-theory', 'linear-algebra', 'intuition']"
3762273,How do I prove a set is not simply connected?,"The set in question is the unit open disc $U$ with the origin omitted. I know that this set is not simply connected as the path, say the circle centred at the origin with a radius of 1/2 is not homotopic to any point in $U$ . However, how do I mathematically express this? Any help would be greatly appreciated.","['complex-analysis', 'general-topology', 'homology-cohomology']"
3762275,$p$-adic Numbers Textbook Suggestions,"I would like a challenging and complete introduction to $p$ -adic numbers (as I eventually plan to study $p$ -adic geometry). I understand that Gouvêa’s book is popular, however, I’m sure that there are lesser-known texts that are high quality as well.","['algebraic-number-theory', 'number-theory', 'p-adic-number-theory', 'book-recommendation', 'reference-request']"
3762286,Question about finding roots of a polynomial and studying the nature,"The number of real roots of the equation $1+\frac{x}{1}+\frac{x^{2}}{2}+\frac{x^{2}}{3}+\cdots+\frac{x^{7}}{7}=0$ (without factorial) is My work Let, $\mathrm{f}(\mathrm{x})=1+\frac{x}{1}+\frac{x^{2}}{2}+\frac{x^{3}}{3}+\cdots+\frac{x^{6}}{6}$ [ Let, f has a minimum at $x=x_{0},$ where then $f^{\prime}\left(x_{0}\right)=0$ ] $\Rightarrow 1+x_{0}+x_{0}^{2}+x_{0}^{3}+x_{0}^{4}+x_{0}^{5}=0$ $\Rightarrow \frac{x_{0}^{6}-1}{x_{0}-1}=0$ $\Rightarrow \frac{\left(x_{0}^{3}-1\right)\left(x_{0}^{3}+1\right)}{x_{0}-1}=0$ $\Rightarrow\left(x_{0}^{2}+x_{0}+1\right)\left(x_{0}^{2}-x_{0}+1\right)\left(x_{0}+1\right)=0$ Which has a real root $x_{0}=-1$ But, $f(-1)=1-1+\left(\frac{1}{2}-\frac{1}{3}\right)+\left(\frac{1}{4}-\frac{1}{5}\right)+\frac{1}{6}>0$ The $f(x)>0$ and hence $f$ has no real zeros.
Now let, $g(x)=1+\frac{x}{1}+\frac{x^{2}}{2}+\frac{x^{3}}{3}+\cdots+\frac{x^{7}}{7}$ An odd degree polynomial has at least one real root.
If our polynomial g has more than one zero, say $x_{1}, x_{2}$ Then by Role's theorem in $\left(x_{1}, x_{2}\right)$ we have $^{\prime} x_{3}$ ' such that $\mathrm{g}^{\prime}\left(x_{3}\right)=0$ $\Rightarrow 1+x_{3}+x_{3}^{2}+\cdots+x_{3}^{6}=0$ But this has no real zeros. Hence the given polynomial has exactly one real zero. correct me if i Am wrong","['calculus', 'solution-verification', 'polynomials']"
3762311,"How do I find all functions $F$ with $F(x_1) − F(x_2) \le (x_1 − x_2)^2$ for all $x_1, x_2$?","In calculus class we were given this so-called ""coffin problem"" originally from Moscow State University. Find all real functions $F(x)$ , having the property that for any $x_1$ and $x_2$ the
following inequality holds: $$F(x_1) − F(x_2) \le (x_1 − x_2)^2$$ I have the solution to this problem, which is supposed to make the question very intuitive once you see it. However, I still do not quite understand it, and I would appreciate your help. Solution: The inequality implies $$\frac{F(x_1) − F(x_2)}{|x_1 − x_2|} \le |x_1 − x_2|,$$ so the derivative of $F$ at any point $x_2$ exists and is equal to zero. Therefore,
by the fundamental theorem of calculus, the constant functions are exactly the
functions with the desired property. Based on this solution, I substituted $x_1=x_2+h$ and took the limit as $h$ approaches zero, therefore by first principles, the derivative of $F(x)$ at $x_2$ is less than or equal to zero. Where do I proceed from here?","['calculus', 'functional-inequalities', 'derivatives']"
3762356,"Sum $\sum_{(k_1, k_2, k_3): k_1+k_2+k_3=K, \,\, n_1+n_2+n_3=N}k_1^{n_1}\times k_2^{n_2} \times k_3^{n_3}$","Let $k_1, k_2, k_3$ be natural non-negative numbers such that $k_1+k_2+k_3=K$ . Let $n_1, n_2, n_3 \in \{0, \ldots, N\}$ and such that $n_1+n_2+n_3=N$ . Calculate $$
S=\sum_{(k_1, k_2, k_3): k_1+k_2+k_3=K, \,\, n_1+n_2+n_3=N}k_1^{n_1}\times k_2^{n_2} \times k_3^{n_3}
$$ My attempt: I am thinking on representing this sum as a chain of sums over each summand $k_j$ . For example, the interior sum would be: $
\sum_{k_3=0}^{K-k_1-k_2}k_3^{n_3}.
$ Using Sums of p-th powers formula we can get $$\sum_{k_3=0}^{K-k_1-k_2}k_3^{n_3}=\frac{B_{n_3+1}(K-k_1-k_2+1)-B_{n_3+1}}{n_3}.$$ So, the sum $S$ would be represented as a product of these ratios with Bernoulli numbers $B_n$ . Is there a better way on computing/estimating from above sum $S$ ?","['number-theory', 'elementary-number-theory', 'bernoulli-polynomials', 'combinatorics', 'bernoulli-numbers']"
3762430,Linear regression with non-fixed regressors and some properties,"I was talking to my teacher the other day about the OLS and linear regression model $Y = \beta X + \varepsilon$ . If the regressors X are fixed numbers and I don't have the normal condition on the errors, then in order to have the asymptotic distribution of the OLS estimator (CLT) I need the condition (this also appears in Thomas Ferguson) \begin{equation}
\frac{\max_i (X_i - \bar{X})^2}{n} \longrightarrow 0, n\rightarrow \infty.
\end{equation} But then in an e-mail I was asking about the case where $X$ is random, and I get the response If the errors are not normal and $X$ has finite fourth moment, since $X$ is random we automatically have $$\frac{\max_i (X_i - \bar{X})^2}{n} \longrightarrow 0, n\rightarrow \infty.$$ I'd like to understand this response without asking in another e-mail. Why do we have this property based on the randomness of the $X$ ?","['statistics', 'linear-regression', 'probability-theory', 'probability', 'random-variables']"
3762459,Cat's curve and some properties,"Well, it's my cat which inspired me today . The goal was :find a curve using elementary function which looks like my cat and I have found this : let $0<x<1$ the cat's curve is defined by the following function : $$f(x)=(1-x)^{\cos^2\Big(\frac{1}{x}\Big)}+x^{\cos^2\Big(\frac{1}{1-x}\Big)}-1$$ The graph looks like so : As far as I remenber it recall me a little bit the Cantor function in the neightborhood of zero or one .
Furthermore there is a big problem with the derivatives but I don't go further than the first .Maybe it's a little bit fractal . Do you know some others interesting properties of this curve ?
Exists there others curve of this kind ? Thanks in advance cheers .:-) Update: As heropup make a good remark I propose to prove that : $$\int_{0}^{1}f(x)dx<\frac{2}{3}$$ Moreover if we look at the graph of one summand I think it's hard to use taylor series (even unsuable maybe).So I don't know what tools use for.","['curves', 'soft-question', 'derivatives']"
3762470,"Find the value of $\lim _{a \to \infty} \frac{1}{a} \int_{0}^{\infty} \frac{x^{2}+a x+1}{1+x^{4}} \cdot \tan ^{-1}\left(\frac{1}{x}\right) \,d x $","Find the value of : $$
\lim _{a \rightarrow \infty} \frac{1}{a} \int_{0}^{\infty} \frac{x^{2}+a x+1}{1+x^{4}} \cdot \tan ^{-1}\left(\frac{1}{x}\right) \,d x
$$ I have tried to evaluate this integral by L'Hospitals rule, by separately diffrentiating the numerator and the denominator in the following steps: $$\int_{0}^{\infty} \frac{x^{2}+a x+1}{1+x^{4}} d x\cdot\dfrac{\pi}{2} (\text{by taking x=1/t and adding the integrands)}
$$ I end up converting the above integral in the form $(\text{by Leibnitz's integral rule})$ $$ \dfrac{\pi}{2}
\left(\int_{0}^{\infty} \frac{x}{1+x^{4}} d x\right)
$$ please provide an approach to this problem after this step.","['integration', 'limits', 'calculus', 'leibniz-integral-rule']"
3762533,About the hypotheses of Schauder Theorem,I know that Schauder Theorem says: $T: E \to F$ is an compact operator iff $T^{*}: F^{*} \to E^{*}$ is an compact operator. My doubt is: what are the hypotheses about $E$ and $F$ ? Is it enough that they are just normed spaces or do they need to be Banach spaces? Or $E$ normed and $F$ Banach? appreciate...,"['banach-spaces', 'compact-operators', 'functional-analysis']"
3762539,If Gal$(K/\mathbb{Q}) = S_5$ then $K$ is the splitting field of a degree $5$ polynomial,"Let $K$ be a Galois extension of $\mathbb{Q}$ whose Galois group is isomorphic to $S_5$ . Prove that $K$ is the splitting field of some polynomial of degree $5$ over $\mathbb{Q}$ . Since $K$ is a finite Galios extension over $\mathbb{Q}$ we know that $K$ is the splitting field of a separable polynomial $f$ over $\mathbb{Q}$ . Let $n$ be the degree of this separable polynomial. Since the Galois group acts on the roots $f$ via permutation we know that the Galois group is isomorphic to a subgroup of $S_n$ and hence $n \geq 5$ . Let $\alpha$ be a root of $f$ . Since since $|K : \mathbb{Q}| = |K :\mathbb{Q}(\alpha)| |\mathbb{Q}(\alpha):\mathbb{Q}| = n|K :\mathbb{Q}(\alpha)|$ , we have that $n|5! = 120$ . Therefore $n \in \{5, 6, 8, 10, 12, 15, 20, 24, 30, 40, 60, 120\}$ Any help would be appreciated.","['galois-theory', 'abstract-algebra', 'symmetric-groups', 'galois-extensions', 'extension-field']"
3762577,Integrate $\frac{\theta \sin \theta}{1+\cos^2 \theta}$ with respect to $\theta$,"Integrate : $$\int_0^\pi \frac{\theta \sin \theta}{1+\cos^2 \theta} d\theta$$ I tried to do a substitution by letting : $u=\cos \theta \implies  du=-\sin\theta\ d\theta$ But I have a problem with that $\theta$ , I don't know how to get bogged down in this variable, I tried some simplifications, but it gets complicated, here's what I've done : \begin{align}
\frac{\theta \sin \theta}{1+\cos^2 \theta}&=\frac{\theta \sin\theta}{1+\frac{1+\cos 2\theta}{2}}\\
&=\frac{2\theta \sin \theta}{3+\cos 2\theta}\\
&=\frac{\theta 2\sin \theta \cos\theta}{\cos\theta(3+\cos 2\theta)}\\
&=\frac{\theta \sin 2\theta}{\cos\theta(3+\cos 2\theta)}
\end{align} Any hints ? Thanks in advance !","['integration', 'calculus', 'definite-integrals', 'trigonometric-integrals']"
3762594,Prove an inequality by induction,"Let $a_0=1$ , $a_1=15$ , and $$a_n=a_{n-1}(a_{n-2})^2+1,\quad n\geq 2.$$ Show that $a_n<2^{2^{n+1}}$ , for all $n\geq 0$ . Using induction, I get stuck to prove the inductive case. I get that $$a_{n+1}-1<2^{2^{n+2}}.$$ and do not know hos to continue.
So the problem is to show that the difference between $a_n$ and $2^{2^{n+1}}$ is $\geq 1$ .
Is there another way to do it? Thank you","['induction', 'recurrence-relations', 'discrete-mathematics', 'inequality', 'exponential-function']"
3762663,Optimal Betting Strategy question,"I am preparing for an exam in probability theory and I bumped against a question I can't solve. Given are an integer starting capital $k$ , an end goal capital $m$ and a period of $n$ days. Each day I can bet some integer amount $X$ of my choosing $(X \leq k)$ on an unfair coin landing on heads. The probability the coin lands on heads is different each day, with $p_i$ denoting the probability of it landing on heads on day $i$ with $i \in (1,...,n)$ . If the bet is successful, I increase my capital by $X$ , if not I lose $X$ amount. (All probabilities $p_1, p_2,..., p_n$ are known before the betting process starts). The question is : With an optimal betting strategy, what is the probability of achieving capital at least equal to $m$ after $n$ days? An example input : $n = 5, k = 2, m = 20, p_1 = 0.3, p_2 = 0.5, p_3 = 0.2, p_4 = 0.7, p_5 = 1.0$ Though not from a homework, if this question falls under the category of questions one should solve by themselves or look for help from a tutor or elsewhere, please tell me, I will take it down. Any advice as to how to approach the problem would be awesome though.","['probability-theory', 'probability']"
3762691,The tropical integers,"Let \begin{align}
    \oplus_\mathbb{N} &= + \\
    0_\mathbb{N} &= 0 \\
    \odot_\mathbb{N} &= \cdot \\
    1_\mathbb{N} &= 1
\end{align} Then $(\mathbb{N}, \oplus_\mathbb{N}, 0_\mathbb{N}, \odot_\mathbb{N}, 1_\mathbb{N})$ is the ordinary rig of natural numbers. Let $\mathbb{Z} = \mathbb{N}^2 / \sim$ where \begin{align}
    (a_1, a_2) \sim (b_1, b_2) &\iff a_1 \oplus_\mathbb{N} b_2 =a_2 \oplus_\mathbb{N} b_1 \\
    (a_1, a_2) \oplus_\mathbb{Z} (b_1, b_2) &= (a_1 \oplus_\mathbb{N} b_1, a_2 \oplus_\mathbb{N} b_2) \\
    0_\mathbb{Z} &= [(0_\mathbb{N}, 0_\mathbb{N})]_\sim \\
    \ominus_\mathbb{Z} (a_1, a_2) &= (a_2, a_1) \\
    (a_1, a_2) \odot_\mathbb{Z} (b_1, b_2) &= ((a_1 \odot_\mathbb{N} b_1) \oplus_\mathbb{N} (a_2 \odot_\mathbb{N} b_2), (a_1 \odot_\mathbb{N} b_2) \oplus_\mathbb{N} (a_2 \odot_\mathbb{N} b_1)) \\
    1_\mathbb{Z} &= [(1_\mathbb{N}, 0_\mathbb{N})]_\sim
\end{align} Then $(\mathbb{Z}, \oplus_\mathbb{Z}, 0_\mathbb{Z}, \ominus_\mathbb{Z}, \odot_\mathbb{Z}, 1_\mathbb{Z})$ is the ordinary ring of integers. Suppose we let \begin{align}
    \oplus_\mathbb{N} &= \max \\
    0_\mathbb{N} &= 0 \\
    \odot_\mathbb{N} &= + \\
    1_\mathbb{N} &= 0
\end{align} instead. This makes $(\mathbb{N}, \oplus_\mathbb{N}, 0_\mathbb{N}, \odot_\mathbb{N}, 1_\mathbb{N})$ the tropical rig of natural numbers. Call $(\mathbb{Z}, \oplus_\mathbb{Z}, 0_\mathbb{Z}, \ominus_\mathbb{Z}, \odot_\mathbb{Z}, 1_\mathbb{Z})$ the ""tropical integers"". Which papers, if any, have studied this structure? Does it have a geometric or easily-visualizable interpretation?","['ring-theory', 'abstract-algebra', 'tropical-geometry']"
3762696,$q-p$ is a projection when $pq = p$,"Consider the following theorem in the book "" $C^*$ -algebras and operator theory"" written by Murphy. Questions : (1) Is the theorem talking about orthogonal projections? (as defined in the text above)? Or simply projections? (2) How to prove $(2) \implies (6)?$ I assume that the theorem talks about orthogonal projections, and then I have difficulties. I can prove that $(q-p)^2 = q-p$ but I do not succeed in proving that $q-p$ is orthogonal (when $p,q$ are).","['c-star-algebras', 'projection', 'operator-theory', 'hilbert-spaces', 'functional-analysis']"
3762718,"UMP Test for $f_{\theta}(x)=2\theta^{-2}(\theta-x)I_{(0,\theta)}(x)$","I am trying to find the UMP test for the following question: Let X be a sample of size 1 from a  Lebesgue pdf $f_{\theta}$ . Find a UMP test of size $\alpha$ for $$H_{o}:\theta=\theta_{0} \hspace{5mm}  H_{1}:\theta=\theta_{1}$$ when $$f_{\theta}(x)=2\theta^{-2}(\theta-x)I_{(0,\theta)}(x), \hspace{4mm} \theta_0<\theta_1$$ I propose the following test $$T(X) = 
     \begin{cases}
       1  & \theta_0<X<\theta_1 \\ 
       \gamma &  X<\theta_0\\
     \end{cases}$$ where $\gamma=\alpha$ to get the desired size. I reject $\theta=\theta_0$ with prob 1 when $\theta_0<X<\theta_1$ because it is not possible that our observation was produced from a r.v with $f_{\theta_0}$ distribution due to the support constraint. For the boundary randomization is required and therefore  since $X\sim f_{\theta_0}$ is a proper r.v then $P_{\theta_0}(X<\theta_0)=1$ and since $P_{\theta_0}(\theta_0<X<\theta_1)=0$ then $\gamma=\alpha$ to get desired size. Is this correct?","['statistics', 'hypothesis-testing']"
3762746,Heisenberg group modulo prime,"According to Wikipedia , the Heisenberg group modulo $p$ , where $p$ is an odd prime, has the presentation $$H(\mathbb{F}_p)=\langle x,y,z\mid x^p=y^p=z^p=1, \ xz=zx, \ yz=zy, \ z=xyx^{-1}y^{-1}\rangle.$$ I could even derive it, but the proof seems to work modulo any integer, not just an odd prime. Why should $p$ be an odd prime? (If it works modulo any integer, it seems a little strange that the Wikipedia article insists on $p$ being an odd prime.)","['heisenberg-group', 'group-presentation', 'group-theory', 'abstract-algebra']"
3762753,Integration of $\int_{\mathbb{R}} e^{-\pi(x+i\xi)^2} dx$?,"I am currently reading stein and shakarchi complex analysis, and he does an integration of: $\int_{\mathbb{R}} e^{-\pi(x+i\xi)^2} dx$ . Let $A$ be a rectangle with four vertices located at $(r,0), (r,i\xi), (-r,i\xi), (-r,0)$ . For conveniennce, assume that $\xi>0$ . He does a contour integration of $e^{-\pi z^2}$ over $\partial A$ , and I am confused when he integrates over the line segment $[(r,i\xi), (-r,i\xi)]$ : $\int_{r}^{-r} e^{-\pi(x+i\xi)^2} dx = e^{\pi \xi^2}\int_{r}^{-r} e^{-\pi x^2}e^{-2\pi i x\xi} dx =_{(*)} 
-e^{\pi \xi^2}\int_{-r}^{r} e^{-\pi x^2}e^{-2\pi x\xi i} dx$ . How does (*) makes sense? I tried change of variable $x \mapsto -x$ , but it only gives me an integration: $-e^{\pi \xi^2}\int_{-r}^{r} e^{-\pi x^2}e^{2\pi i x\xi} dx$ . Thank you very much in advance.",['complex-analysis']
3762773,Derivative of resultant axis-angle with respect to two consecutive axis-angle rotations,"I am recently stuck in a problem about derivative of axis angle rotations. I came up with a simplified problem description as below: We perform two consecutive rotations described in axis-angles as $\mathbf{\theta}^a, \mathbf{\theta}^b$ . Note that the rotations are of the magnitude of $||\mathbf{\theta}^a||$ and $||\mathbf{\theta}^b||$ around axes of $\bar{\mathbf{\theta}^a}=\frac{\mathbf{\theta}^a}{||\mathbf{\theta}^a||}$ and $\bar{\mathbf{\theta}^b}=\frac{\mathbf{\theta}^b}{||\mathbf{\theta}^b||}$ . We can result in a third rotation representing the two consecutive rotations above as $\mathbf{\theta}^c$ . The question is: how do we calculate the following derivatives? $$\frac{\partial \theta ^c _i}{\partial \theta ^a _j}, \frac{\partial \theta ^c _i}{\partial \theta ^b _j}$$ My original thought was to use rotation matrices and chain rules, because two consecutive rotations are simply matrix multiplication $\mathbf{R}^c=\mathbf{R}^b \mathbf{R}^a$ . However, this would require two derivatives: $$\frac{\partial R _{ij}}{\partial \theta _k}$$ $$\frac{\partial \theta _k}{\partial R _{ij}}$$ The top one from matrix to exponential coordinates are easy based on this paper: https://arxiv.org/abs/1312.0788 But the bottom one is much more trickier and I got stuck. Could anyone please help? Thank you! Best,
Shawn","['partial-derivative', 'derivatives', 'rotations', 'differential-geometry']"
3762807,Contrast between SO(n) and Spin(n) representation,"Earlier I asked this Comparison between SO(n) and Spin(n) representation theory which is closed. I think the question is certainly valid and a good one. But my comments are too many and too long, so someone did not like that or got bored. So let me focus on one thing ONLY this time. We know that $Spin(n)/\mathbb{Z}_2=SO(n)$ . The $SO(n)$ and $Spin(n)$ have the same Lie algebra. When it comes to the representation of $SO(n)$ and $Spin(n)$ , does it make any difference? Since Spin group is a double cover of SO group , how does this global structure being reflected in the case of representation? (if their representations are the same? or differed also by a double cover? perhaps the parameters of Lie group are ""doubled"" in some way?) Am I correct to say that SO group has integer spin representations , while Spin group has both integer and half-integer spin representations ? For example, the SO(3) group has a trivial representation, and other odd-rank dimensional matrix representation: $$
1,3,5,7,\dots.
$$ In contrast, the Spin(3) group has a trivial representation, and other odd and even-rank dimensional matrix representation: $$
1,2,3,4,5,6,7,\dots.
$$ The odd and even-rank dimensional matrix representation is related to what physicists call the integer and half-integer spin representations. How about the more general cases for $SO(n)$ and $Spin(n)$ , other than $n=3$ ?","['spin-geometry', 'representation-theory', 'group-theory', 'lie-groups', 'differential-geometry']"
3762835,Good problem books on martingales,"I am looking for a book with good collection of exercises in Martingale theory. So far I know Durrett and Billingsley, but I am looking for an even better collection of problems. Particularly on Optional Stopping theorem, Backward martingales, martingale convergence theorems, exchangeability, etc.","['martingales', 'measure-theory', 'probability-theory', 'book-recommendation']"
3762872,Zeno's Achilles & Tortoise - Where exactly is the proof wrong?,"(For those who don't know what this paradox is see Wikipedia or the Stanford Encyclopedia of Philosophy .) Let us define $a_i$ and $b_i$ recursively $$
a_0 = 0\\
b_0 = 1\\
a_i = a_{i-1} + (b_{i-1} - a_{i-1})\\
b_i = b_{i-1} + (b_{i-1} - a_{i-1})/2
$$ It is easy to prove that $b_i>a_i\  \forall i$ using induction. Thus while $|b_i-a_i|$ tends to $0$ , we will never have $a_i>b_i$ . We can now just replace $a_0$ as Achilles start position and $b_0$ as Tortoise start position. And then subsequent positions of Achilles is given by $a_i$ s (Achilles new position is = Tortoise old position, which is the $1^{st}$ recursion). And Tortoise is assumed to move at half the speed of Achilles. Tortoise positions are represented by $b_i$ s. (So, new position of Tortoise = Old Position + 1/2 the distance traveled by Achilles, which is the $2^{nd}$ recursion.) Given, we have proven $b_i>a_i\  \forall i$ , thus I claim Achilles will always be behind Tortoise (He will come closer and closer but will never overtake). Obviously, I'm wrong but exactly where / which step of the proof above ? (Please provide the exact mathematical step/argument where I went wrong.) Some further discussion :
Basis the responses I got (which I'm unable to find fully convincing - and it maybe just me that I don't understand them well enough) I would like to add - In my opinion, the way I have defined $a_i$ and $b_i$ it is just a subset of positions that Achilles and Tortoise can take. In that subset what I have proved is correct i.e. Achilles cannot overtake Tortoise . But just in that subset <- And I think this is the key Note that my $a_i$ and $b_i$ are all rational. I can embed infinite rationals between any 2 points on the real line. I think fundamentally the error in my proof is that I use induction on continuous variables . I'm not formally trained to express that mathematically in a precise way - Hence this question. My question is not to challenge/discuss that Achilles will overtake or not etc or to come-up with another proof - My precise question is where exactly is my proof wrong. Thanks","['paradoxes', 'infinity', 'sequences-and-series']"
3762878,Is it possible to justify these approximations about prime numbers?,"A recently closed question asked for a possible closed form of the infinite summation $$f(a)=\sum _{i=1}^{\infty } a^{-p_i}$$ for which I already proposed a first simple but totally empirical approximation. Since we quickly face very small numbers, I tried to find approximations of $$g(a)=\Big[\sum _{i=1}^{\infty } a^{-p_i}\Big]^{-1} \qquad \text{and} \qquad h(a)=\Big[\sum _{i=1}^{\infty } (-1)^{i-1} a^{-p_i}\Big]^{-1}$$ All calculations where done with integer values of $a$ for the range $2 \leq a \leq 1000$ . What I obtained is $$\color{blue}{g(a)\sim\frac{(a-1) (2a^3+2a-1)}{2 a^2}}\qquad \text{and} \qquad \color{blue}{h(a)\sim\frac{(a-1) \left(a^3+2 a^2+3 a+4\right)}{a^2}}$$ If the corresponding curve fits were done, in both cases we should have $R^2 > 0.999999999$ . For the investigated values of $a$ , $$\text{Round}\left[\frac{(a-1) (2a^3+2a-1)}{2 a^2}-{g(a)}\right]=0$$ $$\text{Round}\left[\frac{(a-1) \left(a^3+2 a^2+3 a+4\right)}{a^2}-{h(a)}\right]=0$$ Not being very used to work with prime numbers, is there any way to justify, even partly, these approximations ?","['summation', 'approximation', 'prime-numbers', 'sequences-and-series']"
3762881,Getting joint distribution from the distributions of linear combinations,"Let $X$ and $Y$ be two real-valued random variables. Let $Z_{a,b}=aX+bY$ for $a,b\in\mathbb{R}$ . Suppose that for all $a,b\in\mathbb{R}$ , the distribution of $Z_{a,b}$ is known. Then the joint distribution of $X$ and $Y$ is uniquely determined. This is because from the distributions of $Z_{a,b}$ , we get the characteristic function of $(X,Y)$ , which delivers the unique joint distribution. My question is that, if we only know the distributions of $Z_{a,b}$ for some pairs of $(a,b)$ , when can we recover a unique joint distribution of $(X,Y)$ ? Any reference for this type of question? In general, we can't. For example if we only know the distributions of $Z_{1,0}=X$ and $Z_{0,1}=Y$ , we can construct many different joint distributions. But what would happen if we know the distributions of many $Z_{a,b}$ ? in particular, infinitely many? For example, suppose we know the distributions of $Z_{a,b}$ for all $a\geq 0$ and $b\geq 0$ , can we recover the joint distribution? If not, what is the counter example?","['characteristic-functions', 'probability-distributions', 'probability-theory']"
3762923,Show that the formal power series $ Q(x)=\frac{x}{1-e^{-x}}$ has the property that the coefficient of $x^n$ in $Q(x)^{n+1}$ is always $1$,"When I am looking up the Wikipedia page for the definition of Todd class, it says that the formal power series defined by $$
Q(x)=\frac{x}{1-e^{-x}}=1+\frac{x}{2}+\frac{x^2}{12}-\frac{x^4}{720}+\cdots$$ has the property that the coefficient of $x^n$ in $Q(x)^{n+1}$ is always $1$ . It seems that this property does not immediately follow from the definition. How can we show that $Q(x)$ satisfies this property and if a power series satisfies this property, then it must be $Q(x)$ ?","['generating-functions', 'combinatorics', 'differential-geometry']"
3762995,Does this bound hold beyond the domain where the function is convex?,"Let $F:(0,\infty) \to [0,\infty)$ be a continuous  function satisfying $F(1)=0$ , which is strictly increasing on $[1,\infty)$ , and strictly decreasing on $(0,1]$ . Suppose also that $F|_{(1-\epsilon,1+\epsilon)}$ is convex and smooth for some $\epsilon>0$ . Choose some $\delta \in (0,1)$ , such that $F$ is convex at every point $y \in (\delta,1)$ , where by convexity at a point $y$ , I mean that that for any $x_1,x_2>0, \alpha \in [0,1]$ satisfying $\alpha x_1 + (1- \alpha)x_2 =y$ , we have $$
F(y)=F\left(\alpha x_1 + (1- \alpha)x_2 \right) \leq \alpha F(x_1) + (1-\alpha)F(x_2). \tag{1}
$$ Such a $\delta$ always exists. Question: Let $X$ be a probability space and let $g:X \to (0,\infty)$ be measurable. Suppose that $\int_X g < \delta$ . Is it true that $\int_X F \circ g \ge F(\delta)$ ? If $F$ were convex at the point $\int_X g$ , then by Jensen inequality, we would have $$
\int_X F \circ g \ge F(\int_X g) \ge F(\delta),
$$ where in the last step, we have used the fact that $$
0<\int_X g \le \delta<1
$$ together with the fact that $f$ is decreasing on $(0,1]$ . Since $F$ does not need to be convex at $\int_X g$ , I suspect that the answer can be negative in general.","['real-analysis', 'calculus', 'convex-analysis', 'probability', 'convexity-inequality']"
3763008,Can $\int \frac{\sec x \ \mathrm{d}x}{\sqrt{\sin(x+2A)+\sin(A)}}$ be evaluated using elementary functions?,"This question recently popped up on one of my tests and I still have no idea on how to even begin. I tried assuming $\sin(x+2A)+\sin(A)=t^2$ which did not help at all. Then I went on to multiply and divide by $\tan x$ to create a derivative on the numerator, still does not help. I even tried to expand $\sin(x+2A)$ which too does not seem to follow. I have also tried Approach $0$ and Wolfram Alpha  but they do not seem to help. and many more... Now I am stumped I have no idea as to how to even begin. I have tried everything that I could think of. Note that we are only familiar with basics of integration(no contour integrals ; no special functions etc..) $\bullet~\textbf{Question:}~$ ""Can the above integral be evaluated in elementary functions?"" If yes then how? If not , can we prove that it cannot be solved using elementary funcions?","['integration', 'indefinite-integrals', 'calculus', 'trigonometry']"
3763011,"Suppose $A$, $B$, and $C$ are sets. Prove that $A\Delta B$ and $C$ are disjoint iff $A\cap C=B\cap C$.","This is exercise $3.5.19$ from the book How to Prove it by Velleman $($$2^{nd}$ edition $)$ : Suppose $A$ , $B$ , and $C$ are sets. Prove that $A\Delta B$ and $C$ are disjoint iff $A\cap C=B\cap C$ . I am familiar with the proof by contradiction of the above theorem $($ in both directions $)$ but I was wondering whether we could prove the left-to-right direction of the above theorem as a direct proof in the following way: $(\rightarrow)$ Suppose $(A\Delta B)\cap C=\emptyset$ . Let $x$ be an arbitrary element of $A\cap C$ . This means $x\in A$ and $x\in C$ . From $(A\Delta B)\cap C=\emptyset$ and $x\in C$ , $x\notin A\Delta B$ . This means $x\notin A\cup B$ or $x\in A\cap B$ . Now we consider two cases. Case $1.$ Suppose $x\notin A\cup B$ and so $x\notin A$ which is a contradiction. Case $2.$ Suppose $x\in A\cap B$ and so $x\in B$ . Therefore $x\in B\cap C$ . From case $1$ or case $2$ we obtain $x\in B\cap C$ . Since $x$ is arbitrary, $\forall x(x\in A\cap C\rightarrow x\in B\cap C)$ and so $A\cap C\subseteq B\cap C$ . A similar argument shows that $B\cap C\subseteq A\cap C$ . Therefore if $A\Delta B$ and $C$ are dijoint then $A\cap C=B\cap C$ . $Q.E.D.$ Is my proof valid $?$ Thanks for your attention.","['elementary-set-theory', 'proof-writing', 'solution-verification']"
3763021,Find a regular function $\varphi$ which verifies the following conditions,"I am looking for a function $\varphi \in C^{\infty}(K)$ where $$K=\{(x,y,z) \in \mathbb{R}^3 \  | \ x^2+y^2 \leq 1/16 \ \ and \ \ 0 \leq z\leq 2\} \setminus B$$ with $B=\{(x,y,z) \in \mathbb{R}^3 \  | \ x^2+y^2+z^2 \leq h^2 \} \cup \{(x,y,z) \in \mathbb{R}^3 \  | \ x^2+y^2+(z-2)^2 \leq h^2 \}$ the union of two spheres of radius $1>h>\frac{1}{4}$ . You will find a drawing of the set $K$ below. Domain K The function $\varphi$ must verifiy $$\partial_{11} \partial_{33} \varphi = 0 \ \ on \ \ K$$ with the following boundary conditions on the side $\Sigma_1$ and $\Sigma_2$ , where we note $a=\sqrt{h^2-x^2-y^2}$ $$\varphi(x,y,a)= x a + f(y) \ \ and \ \ \partial_3 \varphi(x,y,a)=x$$ $$\varphi(x,y,2-a)= -x a + g(y) \ \ and \ \ \partial_3 \varphi(x,y,2-a)=x$$ for all $x,y$ such as $0 \leq x^2 + y^2 \leq \frac{1}{16}$ , where $f,g$ are two given functions of $y$ . The difficulty here is to deal with the cross derivatives condition $\partial_{11} \partial_{33} \varphi=0$ . I had to deal previously with the same kind of problem but with the condition $\partial_{3333} \varphi =0 \ \ on \ \ K$ and the construction was much more easier. Does anyone have any ideas or advices that could help me on that problem ? Please feel free to ask me questions if you need more details.","['calculus-of-variations', 'derivatives', 'partial-differential-equations']"
3763059,Multivariate Taylor series with Hessian evaluated at a linear combination of $x$ and $\Delta x$,"I found the following theorem, but I don't understand it and was unable to prove it. Is it true? Is there a proof for it? Theorem: Let $f : R^d → R$ be such that $f$ is twice-differentiable and
has continuous derivatives in an open ball $B$ around the point $x ∈ R^d$ . Then for any small enough $∆x ∈ R^d$ such that $x + ∆x$ is also contained in the ball $B$ , we have the following: $$
f(x + \Delta x) = f(x) + \Delta x^T\nabla f|_x + \frac{1}{2}(\Delta x)^T (\nabla^2f|_w)(\Delta x)
$$ Where $(\nabla^2f|_w)$ is the Hessian of $f$ evaluated at a point $w ∈ R^d$ that lies on the line connecting $x$ and $x + ∆x$ I understand that this is a second-order Taylor expansion of $f$ about $x$ , and I understand why it is in this form. But, I don't get is why the Hessian can be evaluated at the point $w$ rather than at $x$ . If it is a Taylor expansion about $x$ , shouldn't all derivatives be evaluated at $x$ ? Why is this expansion valid? For reference, this is where I found the theorem: https://www.cs.princeton.edu/courses/archive/fall18/cos597G/lecnotes/lecture3.pdf On page 2.","['multivariable-calculus', 'taylor-expansion']"
3763097,"Find $\iint_Ay\,dA$, where $A$ is defined by $z=x+y^2$,$0\le x\le 1$ and $0\le y\le2$","Can anyone help me to find the $\iint_Ay\,dA $ where $A$ is defined by $z=x+y^2$ and $0\le x\le1$ and $0\le y\le2$ What I was thinking to do is to put $y=\sqrt{z-x}$ but I am not sure that I am doing right because I cannot find the limits of the integral.","['integration', 'multivariable-calculus', 'multiple-integral']"
3763110,"How to evaluate $\int \frac{\tan^{3/2}\left(x\right)}{1 - \sin\left(x\right)} \,\mathrm{d}x$?","I am trying to evaluate $$
\int \frac{\tan^{3/2}\left(x\right)}
{1 - \sin\left(x\right)}\,dx
\label{1}\tag{1}
$$ I tried using Weierstrass substitution.
> **The Weierstrass substitution**, ( named after K.Weierstrass $\left(~1815~\right)$ ), is a substitution used in order to convert trigonometric functions rational expressions to polynomial rational expressions. Integrals of this type are usually easier to evaluate. This substitution is constructed by letting: $$t = \tan\left(\frac{x}{2}\right) \iff x = 2\arctan(t)  \iff dx = \frac{2}{t^2+1}$$ Using basic trigonometric identities it is easy to prove that: $$\cos x = \dfrac{1 - t^2}{1 +  t^2}$$ $$\sin x = \dfrac{2t}{1 + t^2}$$ Using this substitution we end up to this integral: $$ 2 \int \frac{(2t)^{\frac{3}{2}}(1+t^2)}{(1-t^2)^{\frac{3}{2}}(t^2-2t+1)}\,dt$$ Which is clearly not easier to evaluate than $(1)$ . I also tried other standard trigonometric substitutions such as $u = \cos(x)$ , $u = \sin(x)$ , $u=\tan(x)$ with no better luck. At last I can't see any trigonometric identities that could simplify the fraction. Any ideas on how to evaluate this integral?","['integration', 'indefinite-integrals', 'calculus', 'trigonometric-integrals']"
3763228,"In a queue for £1 tickets, there are $m$ people with a £1 coin and $n$ people with a £2 coin. What is the probability that everyone receives change?","I am selling raffle tickets for £1 per ticket. In the queue for tickets, there are $m$ people each
with a single £1 coin and $n$ people each with a single £2 coin. Each person in the queue
wants to buy a single raffle ticket and each arrangement of people in the queue is equally
likely to occur. Initially, I have no coins and a large supply of tickets. I stop selling tickets
if I cannot give the required change. Show that the probability that I am able to serve everyone in the queue is $\frac{m+1-n}{m+1}$ This problem comes from a STEP question ( see Q3 here ) where the solution is shown in the cases $n=1,2$ or $3$ . However they involve conditioning on permutations of the first couple of people in a way that I don't see how to generalise.",['probability']
3763239,How to show that $2\sum_{j=1}^{N}\cot(\frac{\pi j}{2N+1})$ is related to $(\frac{4 \text{N}+2}{\pi}) (H_{\text{N}}+\log (\frac{2}{\pi }))$?,"I have started with the following relation: $ 2\sum_{j=1}^{N}\frac{1}{\tan\left(\frac{\pi j}{2N+1}\right)}=\frac{4N+2}{\pi}H_N+2\sum_{j=1}^{N}\left[\frac{1}{\tan\left(\frac{\pi j}{2N+1}\right)}-\frac{1}{(\frac{\pi j}{2N+1})}\right]\tag1$ According to WolframAlpha, $\frac{1}{\tan(x)}-\frac{1}{x}$ can be integrated over interval $\left(0,\frac{\pi}{2}\right)$ to equal $\log \left(\frac{2}{\pi }\right)$ . So using $\log \left(\frac{2}{\pi }\right)$ in the right hand side of (1) gives: $(\frac{4 \text{N}+2}{\pi}) (H_{\text{N}}+\log (\frac{2}{\pi }))\tag2$ Empirically (1) seems to be related to (2). My questions are How do I show (1) is related to (2)? How can I prove this? How do I find bounds for any error? or does the harmonic number and nearer the $\tan$ part approximates simply reduce this error the larger N gets? If so then how do I prove this?","['integration', 'summation', 'trigonometric-series', 'sequences-and-series', 'limits']"
3763243,Remarkable logarithmic integral $\int_0^1 \frac{\log^2 (1-x) \log^2 x \log^3(1+x)}{x}dx$,"We have the following result ( $\text{Li}_{n}$ being the polylogarithm ): $$\tag{*}\small{ \int_0^1 \log^2 (1-x) \log^2 x \log^3(1+x) \frac{dx}{x} = -168 \text{Li}_5(\frac{1}{2}) \zeta (3)+96 \text{Li}_4(\frac{1}{2}){}^2-\frac{19}{15} \pi ^4 \text{Li}_4(\frac{1}{2})+\\ 12 \pi ^2 \text{Li}_6(\frac{1}{2})+8 \text{Li}_4(\frac{1}{2}) \log ^4(2)-2 \pi ^2 \text{Li}_4(\frac{1}{2}) \log ^2(2)+12 \pi ^2 \text{Li}_5(\frac{1}{2}) \log (2)+\frac{87 \pi ^2 \zeta (3)^2}{16}+\\ \frac{447 \zeta (3) \zeta (5)}{16}+\frac{7}{5} \zeta (3) \log ^5(2)-\frac{7}{12} \pi ^2 \zeta (3) \log ^3(2)-\frac{133}{120} \pi ^4 \zeta (3) \log (2)-\frac{\pi ^8}{9600}+\frac{\log ^8(2)}{6}- \\ \frac{1}{6} \pi ^2 \log ^6(2)-\frac{1}{90} \pi ^4 \log ^4(2)+\frac{19}{360} \pi ^6 \log ^2(2) }$$ This is extremely amazing : almost all other similar integrals are not expressible via ordinary polylogarithm. The solution is however non-trivial. There are two methods: first is to find enough linear relations between similar integrals, once the rank is high enough, solving the system gives $(*)$ ; second method is to convert the integral into multiple zeta values , then use known linear relations between them. None of these methods can explain the result's simplicity. Question: Is there a simpler method to prove (*), or a conceptual explanation of its elegance? Any thought is welcomed. Thank you very much. I wrote a Mathematica package, it can calculate the integral in subject and many similar ones. The following command calculates $(*)$ : MZIntegrate[Log[1-x]^2*Log[x]^2*Log[1+x]^3/x, {x,0,1}] It can also solve some other integrals. The package can be obtained here . I hope it can benefit those interested in related integral/series. Remarks on the question: It's known that $\zeta(\bar{3},1,\bar{3},1)$ is
very reminiscent to the RHS of $(*)$ . But both the simplicity of $\zeta(\bar{3},1,\bar{3},1)$ and its connection to the integral are
elusive to me. (Added by Iridescent) This contains nearly all known general formulas
of these log integrals. However it does not help much on solving OP's
problem.","['integration', 'polylogarithm', 'closed-form', 'sequences-and-series', 'zeta-functions']"
3763257,"Let $f:\mathbb{R}\to(0,\infty)$ be a differentiable function. For all $x\in\mathbb{R}$ $f'(x)=f(f(x)).$ Then show that such function does not exists [duplicate]",This question already has answers here : Looking for a function such that... (2 answers) Closed 3 years ago . What i have done is very small. $$f'(x)=f(f(x))\implies f(f'(x))=f(f(f(x)))$$ Now $$f(f(f(x)))=f'(f(x))$$ Hence $$f(f'(x))=f'(f(x))$$ Now i am blank. What to do for the proof,"['functional-equations', 'calculus', 'functions']"
3763266,Why does MINRES converge in 3 iterations on matrices of specific form?,"The MINRES algorithm for solving $Ax = b$ for symmetric $A$ can be described as follows: The $k$ -th iterate of the algorithm is $$x_k = \arg\min_{K_k(A)} \lVert Ax-b \rVert_2$$ where $K_k(A)=\text{span}\{A^ib\mid i < k\}$ is the $k$ -th Krylov subspace of $A$ By this definition, it is clear that it converges to the exact solution in $n$ iterations, if $A$ is an $n\times n$ matrix. By using this solver on matrices with a very specific structure, I noticed that in that case, the solver converges in just 3 iterations. The matrices are of the form $$
A = \begin{bmatrix}
I_{n-1} & v\\
v^T & 0
\end{bmatrix}
$$ where $v$ is a column vector and and $I_{n-1}$ is the $(n-1) \times (n-1)$ identity matrix. How can this early convergence be explained? My thoughts The matrix $A$ can in this case be seen as an Identity matrix plus 2 rank-one corrections: $$A = I_n +
\begin{bmatrix}
0 & v\\
0 & -\frac{1}{2}
\end{bmatrix} +
\begin{bmatrix}
0 & 0\\
v^T & -\frac{1}{2}
\end{bmatrix}$$ This means that we can exactly invert the matrix using the Sherman-Morrison formula twice. I currently avoid doing this explicitly as it leads to instabilities, while 3 MINRES iterations do not. Maybe MINRES algorithm implicitly exploits the fact that we are just a rank-two matrix away from the identity? You can verify this behaviour with this example python snipet .","['numerical-linear-algebra', 'sparse-matrices', 'linear-algebra']"
3763275,Impossible to pack Circles without gaps,"It is intuitively apparent that circles cannot be packed without any gaps. I thought this is easy to prove, but it turns out not to me. I have $2$ versions for this question, which likely to have opposite answers. $1:$ Is it possible to pack finitely many circles(of radius larger than 0) in the same size within a finite region. $2:$ is it possible to pack circles(of radius larger than 0) within a finite region. (Which means we can shrink the size of the circle as small as we want and there can be infinitely many of them). For $1$ , I thought it is obviously impossible, since no matter how we arrange the circles, there is always some rooms not included within the circles. I thought it is easy to prove until I realise that there can be more way than I thought to arrange the circles. (see the pictures: or maybe this is already a proof?) For $2$ , I think this is possible, just like pack any shape by rectangles like Riemann Integral, But I have not came up with a proof. I think these are not obvious questions and need some tools, which geometrists may have but I do not. Any ideas and suggestions will be appreciated.","['circles', 'geometry', 'packing-problem']"
3763305,Is a function of several variables convex near a local minimum when the derivatives are non-degenerate?,"Let $U \subseteq \mathbb R^n$ be an open subset, and let $f:U \to \mathbb R$ be smooth. Suppose that $x \in U$ is a strict local minimum point of $f$ . Let $df^k(x):(\mathbb R^n)^k \to \mathbb R$ be its $k$ ""derivative"", i.e. the symmetric multilinear map defined by setting $df^k(x)(e_{i_1},\dots,e_{i_k})=\partial_{i_1} \dots \partial_{i_k}f(x)$ . Assume that $df^j(x) \neq 0$ for some natural $j$ . Let $k$ be the minimal such that $df^k(x) \neq 0$ . Since $x$ is a local minimum, $k$ must be even. Suppose now that $df^k(x)$ is non-degenerate , i.e. $df^k(x)(h,\dots,h) \neq 0$ for any non-zero $h \in \mathbb R^n$ . (Since $x$ is a minimum, I think this is equivalent to $df^k(x)$ being positive-definite, i.e. $df^k(x)(h,\dots,h) > 0$ for any non-zero $h \in \mathbb R^n$ ). Question: Is $f$ is strictly convex in some neighbourhood of $x$ ? In the one-dimensional case, when $f$ is a map $\mathbb R \to \mathbb R$ , the answer is positive: We have $f^k(x)>0$ , and the Taylor expansion of $f''$ near $x$ is $$
f''(y) = {1 \over (k-2)!} f^{(k)}(x)(y - x)^{k-2} + O((y - x)^{k-1}).
$$ Thus, $f''(y)>0$ for $y \ne x$ sufficiently close to $x$ , so $f$ is strictly convex around $x$ . Returning back to the high-dimensional case, if $k>2$ , we have $\text{Hess}f(x)=df^2(x)=0$ , and I guess that we should somehow prove that $\text{Hess}f(y)$ becomes positive-definite for $y$ sufficiently close to $x$ . Perhaps we need to understand the Taylor's expansion of $\text{Hess}f$ around $x$ , similarly to the one-dimensional case, but I am not sure how to do that. Is there a nice way? Edit: It is certainly not enough to assume that $df^k(x)$ is non-zero. Indeed, consider $ f(x,y) = x^2 y^2 + x^8 + y^8$ . (I thank Robert Israel for this nice example). $f$ has a strict global minimum at $(0,0)$ . $$\det(\text{Hess}f(x,y))=3136 x^6 y^6 + 112 x^8 + 112 y^8 - 12 x^2 y^2,$$ which is negative when $x=y$ is small and nonzero. Thus, $f$ is not convex at a neighbourhood of zero. Note that $\text{Hess}f(0,0)=0$ ; The first non-zero derivative at $(0,0)$ is the fourth-order derivative $df^4(0)$ . It is not non-degenerate, however, since if $h=h^1e_1+h^2e_2$ then $df^4(0)(h,h,h,h)=4(h^1)^2(h^2)^2$ vanishes when either $h_i$ is zero. So, non-vanishing of some derivatives does not ensure convexity.","['real-analysis', 'maxima-minima', 'multivariable-calculus', 'optimization', 'convex-analysis']"
3763330,Charcteristic function not in a fractional Sobolev space,"I am trying to show that for any Lebesgue measurable set of finite positive measure $E$ , the characteristic function $\chi_E$ is not in $H^{\frac{1}{2}}(\mathbb{R}^n)$ . I found somewhere that it would be enough to show instead that $$ \int_{\mathbb{R}^n} \int_{\mathbb{R}^n} \frac{\vert \chi_E(x)-\chi_E(y) \vert^2}{\Vert x-y \Vert^{n+1}} dx dy $$ is infinite. I think that the numerator is simply the sum $$ \chi_{E\times E^c}(x,y)+\chi_{E^c\times E}(x,y) $$ which simplifies the problem to showing that $$ \int_{E} \int_{E^c} \frac{1}{\Vert x-y \Vert^{n+1}} dx dy + \int_{E^c} \int_{E} \frac{1}{\Vert x-y \Vert^{n+1}} dx dy $$ is infinite, and using Fubini, I think it is enough to show that the first term is infinite. However I am having trouble trying to simplify it further, and think that I should eventually use an integral of the form $\int_1^\infty \frac{1}{r^p}dr$ somehow. I would appreciate any hints or helpful remarks, including those telling me that this attempt is inherently flawed.","['measure-theory', 'change-of-variable', 'fractional-sobolev-spaces']"
3763347,Taylor coefficient of $f(z)=\exp\left\{\frac{z+1}{z-1}\right\}$,"I am trying to figure out the Taylor coefficient of $\exp\left\{\frac{z+1}{z-1}\right\}$ . My idea is as follows: $$f(z)=\exp\left\{\frac{z+1}{z-1}\right\}=\exp\left\{1+\frac{2}{z-1}\right\}=e\exp\left\{\frac{2}{z-1}\right\}.$$ Then we have $f(z)=e\sum_{n=0}^{+\infty}\frac{w^n}{n!}$ , where $w=\frac{2}{z-1}$ . Clearly, we have $$w^n=(-2)^n(1-z)^{-n}=(-2)^n\sum_{k=0}^{+\infty}\frac{\Gamma(n+k)}{k!\Gamma(n)}z^k.$$ It follows that $$f(z)=e\sum_{n=0}^{+\infty}\frac{w^n}{n!}=e\sum_{n=0}^{+\infty}\frac{(-2)^n}{n!}\sum_{k=0}^{+\infty}\frac{\Gamma(n+k)}{k!\Gamma(n)}z^k=e\sum_{k=0}^{+\infty}\sum_{n=0}^{+\infty}\frac{(-2)^n}{n!}\frac{\Gamma(n+k)}{k!\Gamma(n)}z^k.$$ Namely, the $n$ -th coefficient of $f$ is given by $$\widehat{f}(k)=e\sum_{n=0}^{+\infty}\frac{(-2)^n}{n!}\frac{\Gamma(n+k)}{k!\Gamma(n)}.$$ I have checked that $\widehat{f}(0)=f(0)$ and $\widehat{f}(1)=f'(0)$ . Moreover, the fact that $f''(0)=0$ implies that $\widehat{f}(2)$ should be zero. But in our result it seems that $$\widehat{f}(2)=e\sum_{n=0}^{+\infty}\frac{(-2)^n}{n!}\frac{\Gamma(n+2)}{2!\Gamma(n)}\neq 0.$$ What is wrong with my formula? Could you help me figure our the problem and tfind out the Taylor coefficient of the $f$ ? Thank you!",['complex-analysis']
3763350,"If $a, b, c\in\mathbb R^+,$ then prove that: $\sum_{cyc} \frac1{c-b}\left(\frac1{\sqrt{a+2b}}-\frac1{\sqrt{a+2c}}\right)\ge\frac3{\sqrt{(a+b+c)^3}}.$",We have: $$\sum_{cyc}\frac1{c-b}\left(\frac1{\sqrt{a+2b}}-\frac1{\sqrt{a+2c}}\right)\\\\=\sum_{cyc}\frac{\sqrt{a+2c}-\sqrt{a+2b}}{(c-b)\sqrt{a+2b}\sqrt{a+2c}}\\\\=\sum_{cyc}\frac{2(c-b)}{(c-b)\sqrt{a+2b}\sqrt{a+2c}\left(\sqrt{a+2c}+\sqrt{a+2b}\right)}\\\\=\underbrace{\sum_{cyc}\frac2{(a+2c)\sqrt{a+2b}+(a+2b)\sqrt{a+2c}}}_{=E\text{ (say)}}.$$ So we need to show that: $E\ge\frac3{\sqrt{(a+b+c)^3}}.$ I tried AM $\ge$ HM and obtained: $$E\ge\frac{18}{\sum_{cyc}\left\{(a+2c)\sqrt{a+2b}+(a+2b)\sqrt{a+2c}\right\}}.$$ But now I'm confused.  How to tackle it further!? Please suggest me what to do next.. Thanks in advance.,"['inequality', 'jensen-inequality', 'a.m.-g.m.-inequality', 'multivariable-calculus', 'algebra-precalculus']"
3763415,Find the matrix $A^{15}$.,"Let $I=
\begin{pmatrix}
1 & 0 \\
0 & 1 \\
\end{pmatrix}$ and $O=\begin{pmatrix}
0 & 0 \\
0 & 0 \\
\end{pmatrix}$ . 1.Let $A=\begin{pmatrix}
1 & 3 \\
3 & 5 \\
\end{pmatrix}$ and $ B=\begin{pmatrix}
x & 3 \\
3 & 6 \\ 
\end{pmatrix}$ . Find the value of $x$ which satisfies $AB=BA$ . $AB=\begin{pmatrix}
1 & 3 \\
3 & 5 \\
\end{pmatrix}\cdot\begin{pmatrix}
x & 3 \\
3 & 6 \\
\end{pmatrix}=\begin{pmatrix}
x+9 & 21 \\
3x+15 & 39 \\
\end{pmatrix}$ $BA=\begin{pmatrix}
x & 3 \\
3 & 6 \\
\end{pmatrix}\cdot\begin{pmatrix}
1 & 3 \\
3 & 5 \\
\end{pmatrix}=\begin{pmatrix}
x+9 & 3x+15 \\
21 & 39 \\
\end{pmatrix}$ .So that we get $3x+15=21 \Rightarrow x=2$ 2.Let $A=\begin{pmatrix}
1 & 2 \\
2 & 4 \\
\end{pmatrix}$ and $ B=\begin{pmatrix}
-2 & x \\
4 & y \\
\end{pmatrix}$ .Find the values of x and y which satify $BA=O$ . $BA=\begin{pmatrix}
-2 & x \\
4 & y \\
\end{pmatrix}\cdot\begin{pmatrix}
1 & 2 \\
2 & 4 \\
\end{pmatrix}=\begin{pmatrix}
-2+2x & 0 \\
4+2y & 8+4y \\
\end{pmatrix}=\begin{pmatrix}
0 & 0 \\
0 & 0 \\
\end{pmatrix}$ S0 that we can get $x=1,y=-2$ . 3.Let $A$ satisfying $A^2=A-I$ . Find $A^{15}$ . Please help to show me about this. Thank you in advance!","['matrices', 'matrix-equations']"
3763425,Is Basic Mathematics by Serge Lang rigorous?,"Does Basic Mathematics give a suitably rigorous treatment of algebra and geometry topics covered in high school? Does it prepare the reader for more difficult texts like Calculus by Spivak? I also found the trigonometry chapter to be too brief so, Is there a need for a supplemental book for trigonometry with Basic Mathematics ? Background- I am 13 years old and recently became interested in pure mathematics. I have completed Algebra by Gelfand. I was looking for a rigorous textbook that covers high school mathematics when I came across this book.","['algebra-precalculus', 'soft-question', 'book-recommendation', 'reference-request']"
3763442,"""sheaves of germs of differentiable functions are by no means coherent""?","This is related to a remark in Iitaka's algebraic geometry sec 1.12. ""...It should be noted that sheaves of germs of differentiable functions are by no means coherent. These facts seem to suggest coherence is linked with the property of being algebraic or analytic."" $\textbf{Q1:}$ What is the example of non-coherence for the differentiable case? First what is the sheaf of rings in the context? Is it ring of smooth functions? $\textbf{Q2:}$ If I recall correctly, there are analytic sheaves which are not coherent.(I do not think I will recall this correctly.) Coherence is related notion to algebraic for sure but I have to use GAGA to say it is analytic. However, in analytic setting, there are non-coherent sheaves as well. Should I naively interpret coherence is subcase of analytic or algebraic?(But not the reverse in general?)","['coherent-sheaves', 'algebraic-geometry', 'sheaf-theory', 'differential-geometry']"
3763446,"If $\frac{1}{1+a}+\frac{1}{1+b}+\frac{1}{1+c}\le 1$, prove that $(1+a^2)(1+b^2)(1+c^2)\ge 125$.","QUESTION: Let $a,b,c$ be positive real numbers such that $$\cfrac{1}{1+a}+\cfrac{1}{1+b}+\cfrac{1}{1+c}\le 1$$ Prove that $$(1+a^2)(1+b^2)(1+c^2)\ge 125$$ When does equality hold? MY APPROACH: Firstly, let's try to squeeze out all the information we can from what is given. $$\frac{(1+b)(1+c)+(1+a)(1+c)+(1+a)(1+b)}{(1+a)(1+b)(1+c)}≤1$$ Multiplying this out, we get $$3+2(a+b+c)+(ab+bc+ca)≤1+(a+b+c)+(ab+bc+ca)+abc$$ $$\implies 2+(a+b+c)≤abc$$ Also, since $$1≥\sum_{cyc}\frac{1}{1+a}$$ Therefore by AM-GM, $$1≥\sum_{cyc}\frac{3}{\sqrt[3]{(1+a)(1+b)(1+c)}}$$ $$\implies (1+a)(1+b)(1+c)≥27$$ That's all I ended up in.. At first, I thought Hölder's inequality could be employed, but that too requires the sum of the powers to be $=1$ .. and that is not going to be useful in $(1+a^2)(1+b^2)(1+c^2)$ , since here the sum of powers add up to $3$ .. I don't know what to do next.. Any help will be much appreciated..","['multivariable-calculus', 'tangent-line-method', 'a.m.-g.m.-inequality', 'inequality']"
3763458,Questions about definition of Quantile function,"Let $F$ be a distribution function. For $0<p<1$ , the $p$ -th quantile or fractile of $F$ is defined by $$\xi_p = F^{\leftarrow}(p) = \inf\{x:F(x)\geq p\}$$ my questions are following: Why we take $\inf$ ? If we take $\min$ then what kind of problem arise? Why we can not take $\sup$ ? If we take $\sup$ then which portion of the definition of the $F$ we have to modify? And what kind of problem arise when we take $\sup$ ? Suppose we want to study empirical quantile function using $\sup$ in the definition then what kind of problem arise? Any kind of help appreciable. Thanks in advance","['quantile-function', 'cumulative-distribution-functions', 'probability-theory', 'probability', 'random-variables']"
3763471,Calculating a limit with exponent and trig function,"I got this limit to calculate: $$
\lim_{x\to\frac{\pi}{2}}(\tan x)^\frac{1}{x-\frac{\pi}{2}}
$$ I'm trying to solve it with De L'Hopitals rule and the first step should be this, I guess: $$
\lim_{x\to\frac{\pi}{2}}e^\frac{\ln(\tan x)}{x-\frac{\pi}{2}}
$$ Then I'm trying to solve the limit of the exponent: $$
\lim_{x\to\frac{\pi}{2}}\frac{\ln(\tan x)}{x - \frac{\pi}{2}}
$$ In the last step I inversed the function in the denominator of the exponent. Next I do: $$
\lim_{x\to\frac{\pi}{2}}\frac{\frac{1}{\tan x}*\frac{1}{\cos^2x}}{1} = \lim_{x\to\frac{\pi}{2}}\frac{1}{\tan x\cos^2x}= \lim_{x\to\frac{\pi}{2}}=...
$$ Skipping a few calculations, in the end I get $$
\lim_{x\to\frac{\pi}{2}}\frac{1}{2\cos x\sin^3x}
$$ Which would mean the limit of the exponent = infinity, but the answer sheet says it's 2. I have a strong feeling I did something wrong in one of the first steps, however I'm unable to find out what exactly...","['limits', 'derivatives']"
3763473,Tricolorations of a flag,"Suppose that the there are 6 colors of the rainbow - red, orange, yellow, green, blue, and purple, in that order. (indigo is not included) Chan wants to design a vertical tricolor (a flag with equal vertical stripes of three different color) for a club. If Chan uses only uses the 6 rainbow colors and that the three colors appear in red-to-purple rainbow order from left to right, then how many different tricolors are possible? example that works: I know that the first section of the flag has 4 choices: red, orange, yellow, and green, because the 2 sections after it need to come after the color in rainbow order. So, the second section has 4-1 = 3 choices, and the third section has 3-1= 2 choices. But, I'm not sure if I am finding the right number of choices for sections 1 and 2 of the flag.","['combinations', 'combinatorics']"
3763508,How to obtain a solution for the following IBVP,"I am trying to solve the following advection-diffusion equation for transient flow conditions for radial flow. The governing equation is as follows. $$\frac{\partial T}{\partial t} = \frac{\partial^2 T}{\partial x^2} + \frac{1-2v(t)}{x} \frac{\partial T}{\partial x}$$ $$\frac{\partial T}{\partial t} = \frac{\partial^2 T}{\partial x^2} + \frac{f(t)}{x} \frac{\partial T}{\partial x}$$ where $$f(t)=1 -2 v(t)$$ Initial condition $$T(x,t=0)=0$$ BCs. $$T(x=0,t)=1$$ $$\lim_{x \to \infty} T(x,t)=0$$ I have tried to solve the problem using the following solution procedure. Assume the solution takes the following form. $$T(x,t)=\left ( e^{-\frac{x^2}{4t}}\right) F(t)$$ The similarity variable $-\frac{x^2}{4t}$ is appropriate selection for solving diffusion equation for radial flow. The partial derivatives of $T(x,t)$ are as follows. $$\frac{\partial T}{\partial x} =-\frac{x}{2t}\left ( e^{-\frac{x^2}{4t}}\right) F(t)$$ $$\frac{\partial^2 T}{\partial x^2} =F(t)\left( -\frac{1}{2t}\left ( e^{-\frac{x^2}{4t}}\right) + \left( \frac{x}{2t} \right)^2        \left ( e^{-\frac{x^2}{4t}}\right) \right)  $$ $$\frac{\partial T}{\partial t} = \left (\left( \frac{x}{2t} \right)^2 e^{-\frac{x^2}{4t}}\right)F(t) +  \left ( e^{-\frac{x^2}{4t}}\right)\frac{\partial F(t)}{\partial t} $$ By substituting into the governing equation, the following ODE in $F(t)$ is obtained. $$\frac{dF(t)}{dt}=-\left ( \frac{1 + f(t)}{2t}\right)F(t)$$ The solution of the ODE is as follow. $$F(t) = \exp\left ( -\int_{0} ^{t} \left ( \frac{1 + f(u)}{2u}\right) \, du\right)$$ Finally, the solution of the governing is as follow. $$T(x,t) =\left ( e^{-\frac{x^2}{4t}}\right) \exp\left ( -\int_{0} ^{t} \left ( \frac{1 + f(u)}{2u}\right) \, du\right)$$ This solution is the same as that given in Handbook of Linear Partial Differential Equations for Engineers and Scientists - Page 367 (when $a = 1$ )( https://www.taylorfrancis.com/books/9780429166464 ). Unfortunately, this solution satisfies the initial condition as well as the outer BC, however it doesn't satisfy the inner BC. When $x$ is put equals to zero, the resulting solution will be as follows. $$IBC \rightarrow T(x = 0,t) = \exp\left ( -\int_{0} ^{t} \left ( \frac{1 + f(u)}{2u}\right) \, du\right) ≠ 1$$ I was thinking of how to use the given solution to obtain a solution that satisfies the governing equations, initial conditions, and all boundary conditions of my problem. The resulting solution seems to be a solution of the same problem, however with time dependent inner BC. Duhamel's integral can be used to obtain a solution for time-dependent BC problem given the corresponding solution for constant BC problem, however the problem here seems to the opposite. Can anyone give me a hint of how to proceed to obtain the solution that satisfies the inner BC?","['ordinary-differential-equations', 'heat-equation', 'partial-differential-equations', 'boundary-value-problem', 'deconvolution']"
3763526,Bounded idempotent on Hilbert space has closed range.,"Let $H$ be a Hilbert space and $p\in B(H)$ an idempotent on $H$ , i.e. a continuous linear map satisfying $p^2 = p$ . Is it true that $p(H)$ is a closed subspace of $H$ ? Attempt : Consider a sequence $p(h_n) \to h $ . We show $h \in p(H)$ . By continuity, $$p(h_n) = p^2(h_n) = p(p(h_n)) \to p(h)$$ but also $p(h_n) \to h$ so we obtain $h = p(h) \in p(H)$ and we are done. Is this correct?","['projection', 'functional-analysis']"
3763528,Find limit of volume of n dimensional box in different unit.,Suppose we have a n dimensional box with length in each dimension = $50$ $cms$ . If we find the volumne where n tends to infinity we get its magnitude as infinity. But if we convert it to meters before finding the volume we get the magnitude to be $0$ . So does the box in the limiting case have any volume or not?,"['limits', 'sequences-and-series']"
3763546,Example of nonnegative random variables $X_n$ such that $\sum\limits_{n\ge1}X_n$ converges a.s. but $\sum\limits_{n\ge1}EX_n$ diverges.,"Utilize series of the form $\sum\limits_{n\ge1}\frac{1}{n^p}$ to construct independent, nonnegative random variables $X_n$ such that $\sum\limits_{n\ge1}X_n$ converges a.s. but $\sum\limits_{n\ge1}EX_n$ diverges. I am quite stumped on this one. I know $X_n=n\cdot\mathbb{1}_{(0,\frac{1}{n})}$ is a typical example of random variables such that \begin{align*}
\sum_{n\ge1}EX_n=\sum_{n\ge1}n\cdot P\big(\big(0,\frac{1}{n}\big)\big)=\sum_{n\ge1}(1)=\infty
\end{align*} However these random variables are not independent and I am not sure that $\sum\limits_{n\ge1}X_n$ converges a.s. If we let $A_n$ be disjoint intervals of length $\frac{1}{n}$ and set $X_n=n\cdot\mathbb{1}_{A_n}$ , then the $X_n$ are independent this time and $\sum_{n\ge1}EX_n=\infty$ again, as above. But I am not sure that $\sum\limits_{n\ge1}X_n$ converges a.s., if they do, is there an nice way to see this? Any help with this or any other example of $X_n$ 's that will satisfy the required properties would be greatly appreciated.","['convergence-divergence', 'probability-theory', 'sequences-and-series']"
3763589,Function with a parameter controlling its growth,"I am looking for a mathematical function with growth controlled by a parameter.
It would have two inputs: A growth scale, further called $w$ An input ranging from $0$ to $1$ , further called $x$ The function $f(x, w)$ should behave according to the following pattern. If $w$ equals $2$ , it would be a linear function (I think): if $x = \frac{1}{2}$ , then $f(x,w)$ should be $\frac{1}{2}$ if $x = 1$ , then $f(x, w)$ should be $\frac{2}{2}$ If $w$ equals $3$ , the growth increases: If $x = \frac{1}{2}$ , $f(x, w)$ should be $\frac{1}{3}$ If $x = \frac{3}{4}$ (or $\frac{1}{2} + \frac{1}{2} * \frac{1}{2}$ ), $f(x, w)$ should be $\frac{2}{3}$ If $x = 1$ , $f(x, w)$ should be $\frac{3}{3}$ If $w$ equals $4$ , the growth increases further: If $x = \frac{1}{2}$ , $f(x, w)$ should be $\frac{1}{4}$ If $x = \frac{3}{4}$ , $f(x, w)$ should be $\frac{2}{4}$ If $x = \frac{7}{8}$ , $f(x, w)$ should be $\frac{3}{4}$ If $x = 1$ , $f(x, w)$ should be $\frac{4}{4}$ This behaviour should continue infinitely as $w$ increases.
How would the function for this behaviour look like?",['functions']
3763594,"Shape derivative of a boundary integral with a continuously differentiable function on a ""tubular neighborhood""","Let $d\in\mathbb N$ . I want to compute the shape derivative of a shape functional $^1$ $$\mathcal F(\Omega):=\int_{\partial\Omega}f\:{\rm d}\sigma_{\partial\Omega}\;\;\;\text{for }\Omega\in\mathcal A$$ for some suitably integrable real-valued function $f$ on a suitable large subspace of $\mathbb R^d$ and $$\mathcal A:=\{\Omega\subseteq\mathbb R^d:\Omega\text{ is bounded and open and }\partial\Omega\text{ is of class }C^1\}.$$ If $\tau>0$ and $T_t$ is a $C^1$ -diffeomorphism on $\mathbb R^d$ for $t\in[0,\tau)$ with $T_0=\operatorname{id}_{\mathbb R^d}$ , $\Omega\in\mathcal A$ and $$\Omega_t:=T_t(\Omega)\;\;\;\text{for }t\in[0,\tau),$$ then we can show that $$\mathcal F(\Omega_t)=\int_{\partial\Omega}\left|\det{\rm D}T_t(x)\right|\left\|({\rm D}T_t(x)^{-1})^\ast\nu_{\partial\Omega}(x)\right\|(f\circ T_t)(x)\:\sigma_{\partial\Omega}({\rm d}x)\tag1$$ for all $t\in[0,\tau).$ Since $T_0=\operatorname{id}_{\mathbb R^d}$ , we can assume that $\tau$ is small enough to ensure $\det{\rm D}T_t(x)>0$ for all $(t,x)\in[0,\tau)\times\mathbb R^d$ . Ignoring rigor, we easily see that $$\frac{\mathcal F(\Omega_t)-\mathcal F(\Omega_0)}t\xrightarrow{t\to0+}\int_{\partial\Omega}(\nabla_{\partial\Omega}\cdot v_0)(x)f(x)\langle\nabla f(x),v_0(x)\rangle\:\sigma_{\partial\Omega}({\rm d}x)\tag2,$$ where $$(\nabla_{\partial\Omega}\cdot v_0)(x)=(\nabla\cdot v_0)(x)-\langle{\rm D}v_0(x)\nu_{\partial\Omega}(x),\nu_{\partial\Omega}(x)\rangle\;\;\;\text{for all }x\in\partial M.$$ My question is: Which assumptions on $f$ do we need to impose? Since all $\Omega\in\mathcal A$ are bounded, all the measures $\sigma_{\partial\Omega}$ are finite. So, it would be sufficient to assume that $f$ is a bounded function on all of $\mathbb R^d$ . However, this assumption might be too restrictive. And whatever we come up with, we need to assume that $f$ is continuously differentiable on the set it is defined and the derivative must be integrable as well. If we consider only the single fixed $\Omega$ , I've read that it's sufficient to assume $f\in C^1(U)$ for some tubular neighborhood of $\partial\Omega$ . How can we show that? Why is this a suitable assumption? $^1$ $\sigma_{\partial\Omega}$ denotes the surface measure on the Borel $\sigma$ -algebra $\mathcal B(\partial M)$ .","['nonlinear-optimization', 'numerical-optimization', 'manifolds-with-boundary', 'smooth-manifolds', 'differential-geometry']"
3763595,Showing that there is a point belonging to $2000$ sets.,"Question: Let $E_j\subset[0,1]$ be a sequence of measurable sets satisfying $$m(E_i\cap E_j)\geq\frac{1}{i^2+j^2}$$ for all $i,j\geq1$ .  Prove that there is an $x\in[0,1]$ belonging to at least $2000$ sets $E_j$ .  Does there exist an $x\in[0,1]$ belonging to infinitely many $E_j$ 's? My thoughts: If we consider the function $f=\sum_j \chi_{E_j}$ , then $f$ is a measurable function from $[0,1]$ to $[0,\infty]$ .  So, $f^{-1}([2000,\infty])$ is measurable, and $f^{-1}([2000,\infty])$ is the set of points $x\in[0,1]$ that belong in at least $2000$ of the $E_j$ 's. I'm not sure if what I have above is totally accurate, and for the second question, I am not sure if that would just, then, be obvious (well, I suppose, evidently not) or if there is a bit more to consider.  Moreover, I suppose I never really used the "" $m(E_i\cap E_j)\geq\frac{1}{i^2+j^2}$ for all $i,j\geq1$ "" part, so I feel like I have something incorrect here.... Any thoughts, suggestions, etc. are appreciated!  Thank you!","['measure-theory', 'lebesgue-measure', 'real-analysis']"
3763605,Does Jensen's inequality still hold in general finite measure space?,"I got some useful information from this Question: Jensen's inequality in measure theory Theorem 3.1 Jensen's Inequality Let $(X,\mathcal{M},\mu)$ be a probability space (a measure space
with $\mu(X) = 1$ ), $f: X \to \mathbb R \in L^1(X, \mu)$ , and $\psi:\mathbb R \to \mathbb R $ be a convex function, then $$\psi\int_X f d\mu \le \int_X (\psi \circ f)d\mu$$ And that question asked whether Jensen's inequality still hold in general finite measure space ?
A nice man d.k.o. answered: Yes. In this case for convex $\varphi$ : $$\varphi\left(\frac{1}{\mu(X)}\int fd\mu\right)\le \frac{1}{\mu(X)}\int \varphi\circ fd\mu$$ However, this result is basically rescale $\mu$ to a probability measure. So whether the following proposition hold? Let $(X,\mathcal{M},\mu)$ be a general measure space, and $\mu(X) < \infty $ , $f: X \to \mathbb R \in L^1(X, \mu)$ , and $\psi:\mathbb R \to \mathbb R $ be a convex function, then $$\psi\int_X f d\mu \le \int_X (\psi \circ f)d\mu$$","['measure-theory', 'jensen-inequality', 'convex-analysis', 'real-analysis']"
3763634,The signature of the tensor product of skew-symmetric non-singular matrices,"Let $X$ be a non-singular (real) symmetric matrix which is the tensor product of two (real) $n\times n$ skew symmetric non-singular matrices, i.e. $X=A\otimes B$ . Then how to see the number of negative eigenvalues of $X$ equals to the number of positive eigenvalues of $X$ . What I know is the eigenvalues of $X$ are the pairwise products of the eigenvalues of $A$ and $B$ and the eigenvalues of $X$ are purely imaginary. I wonder if it suffices to show the claim? If so, is that possible to show me a proof?","['matrices', 'linear-algebra']"
3763649,Does pairwise independence and same distribution imply trivial Invariant $\sigma$-algebra?,"I know that by Kolmogorov’s $0-1$ Law, that for independent r.v, the tail $\sigma$ -algebra is trivial (e.g all events have probability either $0$ or $1$ ). This coupled with the ergodic theorem, one can easily derive the Strong Law of Large Numbers for $X_i$ i.i.d. and finite expected value. I also know that there exists a stronger SLLN called Etemadi’s SLLN, which only requires finite expected value, and that $X_i$ have the same distribution and are pairwise independent. With this in mind, I was wondering if pairwise independence and same distribution imply trivial Invariant $\sigma$ -algebra? If it does, can anyone provide a proof or a reference to such proof? And if no, can one provide a counter-example?","['law-of-large-numbers', 'ergodic-theory', 'probability-theory']"
3763672,"Suppose $f(x)=xg(x)$, where $g$ is a continuous at $x_0=0$. Then $f$ is differentiable at $x_0=0$.","Justify: Suppose $f(x)=xg(x)$ , where $g$ is a continuous at $x_0=0$ . Then $f$ is differentiable at $x_0=0$ . I tried proving this by contradiction, but I'm not sure this is correct. My attempt: Supposed $f$ is not differentiable at $x_0=0$ . Then the following limit must not exist. $$\begin{align}\lim_{x\to0} \frac{f(x)-f(0)}{x-0} = \lim_{x\to0} \frac{xg(x)-0}{x-0} &= \lim_{x\to0} g(x)= g(0).\end{align}$$ That means $f'(0)=g(0)$ , which is a contradiction. Is this correct? If so, are there other ways to prove this?","['proof-writing', 'alternative-proof', 'calculus', 'solution-verification', 'derivatives']"
