question_id,title,body,tags
259901,How to find $f'$ from the definition of derivative?,"How to find the derivative of this function: $f(x) = e^{2x}$ - using definition of derivative: \begin{equation}
    f'(x) = \lim_{h\to0}\dfrac{f(x + h) - f(x)}{h}
\end{equation}",['derivatives']
259931,Solution of non linear ODE system is always positive if its initial valus is positive,"Given a system of nonlinear differential equation \begin{eqnarray}\frac{dx}{dt}=2x(3-y) \\ \frac{dy}{dt}=3y(4-x)\end{eqnarray}
If $r(t)=$($x(t)$,$y(t)$) is a solution of the system with initial value $x(0)>0$ and $y(0)>0$, would you help me to prove that $x(t)>0$ and $y(t)>0$ for all real $t$. Here is my argument:
I prove it by contradiction.
Let $r_1(t)=(x_1(t),x_2(t))$ be an orbit of the ODE with $x_1(0)=0$. Since, for $x=0$ we get $\frac{dx}{dt}=0$ then $x_1(t)=x_1(0)=0$. Thus, $x=0$ is an invariant manifold of the ODE. By the same argument, $y=0$ is also an invariant manifold. So the orbit that passing through a point in $x=0$ (resp $y=0$) always lies in $x=0$ (resp $y=0$).
Assume there is a $t_1$ such that $x(t_1) \leq 0$ then $r(t)$ must intersect an orbit in $x=0 $( or $y=0$) hence $r(t)$ must lies on $x=0 $ (or $y=0$), contradicting $x(0)>0$ and $y(0)>0$. Is there any a direct proof (or even elementary/simple proof)?","['dynamical-systems', 'ordinary-differential-equations']"
259936,Prove that $f'$ exists for all $x$ in $R$ if $f(x+y)=f(x)f(y)$ and $f'(0)$ exists,"A function $f$ is defined in $R$, and $f'(0)$ exist. Let $f(x+y)=f(x)f(y)$ then prove that $f'$ exists for all $x$ in $R$. I think I have to use two fact: $f'(0)$ exists $f(x+y)=f(x)f(y)$ How to combine these two things to prove that statement?","['functional-equations', 'derivatives', 'analysis']"
259949,Complex Functions Concept Questions,"My Engineering Mathematics teacher have a very novel method of teaching. He thinks that while it's all good and well to learn the analytical side of math, he stresses more on the theory, than the application. Thus he gave us these questions that we must answer without a single equation. It's new and I sure enjoy the concept, but I'm not sure if I got it right. Could someone check my answers for me? Thanks! 1. Why there are n solutions to the $n$th root of a complex number? Because if the solution is some number w to the power of n (a series of natural numbers) then for each value of w there is one and only one solution value. 2. If a complex function is analytic, the function needs to satisfy the Cauchy-Riemann equation. Outline the proof process of the necessary part of this argument. If a complex function is to be considered analytic, it must have a derivative at all points in its domain. Thus, if we assume a function has a derivative, then, according to the fundamental theorem of calculus, it can be expressed in terms of a limit. We can then divide the limit into real and imaginary components, since it is on a complex plane. And since the derivative exists, the limit also exists. This means that we can take the limit in any direction. If we approach it in a horizontal direction and in a vertical direction, we get two different equations for the derivative of the function. And since they are the meant to be equal, if we equate the real and imaginary terms of both equations, we get the two Cauchy-Riemann equations, thus showing that for a function to be analytic, it must satisfy the Cauchy-Riemann equations. This is the necessary condition for a function to be considered analytic. 3. Outline the proof process of the sufficient part of the argument in problem 2. The sufficient part of the argument outlined in problem 13-2 is that the partial derivative of the real part u of the function with respect to x is equal to the partial derivative of the imaginary part v of the function with respect to y. Additionally, the partial derivative of u with respect to y should be equal to the negative partial derivative of v with respect to x. Also, all partial derivatives of the function must be continuous. If we supply these substitutions in the Taylor series representation of the function and rearrange, then we can get the fundamental calculus definition of the derivative of the function with respect to a path z. If we substituted so that all partial derivatives are in respect of x, then we get the derivative of the function in the x-direction. The opposite is true if we substituted so that all partial derivatives are in respect of y. And since all the partial derivatives are continuous, the derivative of the function in both cases must exist. Thus, the function is differentiable, thus proving it’s analytic quality. Note that although the Cauchy-Riemann equations are satisfied, it is not compulsory that the function is analytic until the partial derivatives are continuous. 4. Describe the overall procedure of defining various complex functions: exponential, trigonometric, hyperbolic, logarithm, and general power. Discuss differences and similarities of the complex functions compared to real functions. From what I can observe, the general method of defining a complex function is to replace the x in the function’s real counterpart with a complex number. This method, armed with Euler’s equation, it becomes a simple matter or algebraic manipulation to get the complex functions. The complex exponential function is very similar to the real exponential function in that its derivative is itself and is even equal to the real function if the complex number has no imaginary part. Complex trigonometric functions, along with the hyperbolic functions, are also similar in that if the complex number has no imaginary part, the complex counterparts work exactly the same. Also, the complex trigonometric functions and the hyperbolic functions are entire, have the same derivative as their real counterparts and even hold the same general formulas as the real counterparts. However, the complex logarithmic and general power functions vary from their real counterparts. This is due to the fact that a complex exponential function has an infinite number of solutions, not allowing us to define a complex logarithmic function as we would a real logarithmic function. Thus, complex logarithmic functions differ in that while positive real values yield the same results, negative numbers do not. The same concept applies to complex general power functions (except that in this case the complex logarithmic function has infinitely many solutions) and thus some exponential laws cannot be carried out with complex power functions.",['complex-analysis']
259964,Almost sure convergence for a sequence of random variables,I have read in some book that in case of almost sure convergence of a sequence of random variable it possible that $|X_{n}(\omega) - X(\omega)|$ can be extremely large for $\omega$ in a small probability set. How is that possible ? Here the sequence {$X_{n}$} of random variables converges to $X$ in almost sure sense. By almost sure convergence we mean that $P(\omega : X_{n}(\omega)=X(\omega)$ as $n$->infinity)=1 i.e.$P(\omega$ : for any $\epsilon > 0 $there exist an $N$ such that for all $n>=N$  $|X_{n}(\omega)-X(\omega)| < \epsilon)$ = 1 . Then how can $|X_{n}(\omega) - X(\omega)|$ be extremely large for $\omega$ in a small probability set where $|X_{n}(\omega) - X(\omega)| < \epsilon$ with probability 1  ? confused.,['probability']
259968,Is compact metric space separable in ZF?,"Reference; http://www.samos.aegean.gr/math/kker/papers/CompactMetric.pdf The paper says ""Compact metric space is separable"" is unprovable in ZF $^0$ ( That is, ZF without axiom of regularity). And I know ""Limit point compact"" does not imply ""separable"" in ZF I searched for it, but couldn't find whether ""Compact metric space $\Rightarrow$ Separable"" Is it provable in ZF? Thank you in advance","['separable-spaces', 'general-topology', 'axiom-of-choice', 'metric-spaces', 'compactness']"
259989,derivative and cut off functions,"Is there any way of constuct a cut off function which is $1$ in $B(0,\epsilon)$ and zero outside the ball $B(0,2\epsilon)$ and it's first and second derivative is smaller than $1/|x|^a$ , with $a<1/4$?",['analysis']
259994,Omega limit set is invariant,"In the ODE where $y'=f(y(t))$ and $y(0)=y_0$ . The omega limit set $\omega(y_0)$ is positively invariant and also negatively invariant. I want to prove first that its positively invariant and then prove its negatively invariant. But how do I show that using a flow function $(\phi(y,t)$ ) given that I know only the definition and the identity of flow function and very little understanding of the concept of flow function. Thankyou for the help!","['dynamical-systems', 'ordinary-differential-equations', 'set-invariance', 'chaos-theory']"
259999,Variance formulae,"I know that the variance formula is
$$\sigma^2 = \frac{
   \left( x_1 - \bar{x} \right) ^2 +
   \left( x_2 - \bar{x} \right) ^2 +
   \dots +
   \left( x_n - \bar{x} \right) ^2
   }{n}$$
Where $\sigma^2$ is the variance; $x_1,\ x_2,\ \dots,\ x_n$ are the statistical data, and $n$ is the number of data. My question is: how can I expand that formula to get this equivalent one: $$ \sigma^2 = \frac{x_1^2 + x_2^2 + \dots + x^2_n}{n} -\bar{x}^2$$ ?",['statistics']
260031,Expectation of joint life span,"The life span of a particular mechanical part is a random variable described by the following PDF: If three such parts are put into service independently at t=0, determine a simle expression for the expected value of the time until the majority of the parts will have failed. I can get the PDF:
$$
f_L(l) = 0.4 (0 \leq l \leq 2) \\
f_L(l) = -0.4l + 1.2 (2 < l \leq 3)
$$
and the expectation:
$$
E(l) = \int_0^3 l f_L(l) dl \approx 1.27
$$ I think 'majority' means 2 or more, so we can focus on two parts of the three, and pay no attention to the third. The translation is $E(max(l1, l2))$, how will this be derived I currently have no idea. Sorry about the misleading remark ""$E(max(l_1, l_2))$"", it's wrong to neglect the third part, because if that one fails early, then we only need one of the rest to fail.",['probability']
260045,free group generated by polynomials,"Someone recently asked me how to proof that $x+1$ and $x^3$ generate a free group. A colleague has worked out a proof. I have a vague memory that this has been studied, maybe a Monthly problem? Does anyone know any history on this? Edit: Sorry for my omission of key point. The group operation here is function composition on the reals, or the integers. Each of the polynomials can be viewed as a permutation of Z = all integers (or on the reals). Viewed in that way, do they generate a free group (of rank two).","['free-groups', 'group-theory']"
260059,Hilbert transform and Hilbert matrix,"The Hilbert matrix is \begin{bmatrix} 
1 & \frac{1}{2} & \frac{1}{3} & \frac{1}{4} & \dots \\[4pt]
\frac{1}{2} & \frac{1}{3} & \frac{1}{4} & & \ddots \\[4pt]
\frac{1}{3} & \frac{1}{4} & & \ddots & \\[4pt]
\frac{1}{4} & & \ddots & & \\[4pt]
\vdots & \ddots & & & \end{bmatrix} I believe the Hilbert transform of a function $u$ on the circle $\mathbb T$ is, when it exists, the radial limit of the harmonic conjugate of u defined in the open disk $\mathbb D$. This conjugate limit exists in $L^p$ (it also exists pointwise a.e. for Lebesgue measure on $\mathbb T$ then) for all $u\in L^p, p>1$. Here we only need $L^2$. The Hilbert matrix is a bounded Hankel operator on $\ell^2$, whose entries are therefore the positive Fourier coefficients of some $L^\infty(\mathbb T)$ function. The function $\sum_{n\ge 0}\frac{z^n}{n+1}$ has those Fourier coefficients but is not bounded on the circle, we can add negative Fourier coefficients to obtain $ie^{-it}(\pi-t)$ which is bounded -i.e. in $L^\infty(\mathbb T)$. From this last function we get an $L^\infty$ symbol for the Hilbert matrix as a multiplication operator from Hardy space to negative Hardy space. The Hilbert transform is a multiplication operator (in $\hat{\ell^2}$, ""Fourier"" space) but from Hardy space ($H^2(\mathbb T)$) to itself because we just multiply the $n$th Fourier coefficients by $(-1)^{n-1}i$ -if I made no mistake. Hilbert arrived at both at different times in his career: In 1894 for the matrix, investigating a question of approximation by orthogonal polynomials, and 1905 for the transform, investigating the Riemann-Hilbert problem.
However I wonder if they may be related, because they connect to many related concepts. I may expand later, but if anyone has guesses or knows anything, I'd be glad to hear them.","['operator-theory', 'functional-analysis', 'complex-analysis']"
260065,The set of critical values of a polynomial $f: \mathbb{R}^n \rightarrow \mathbb{R}$ is finite,"I have result: measure of the set of critical values of $f$ is zero (by Sard's theorem), where $f: \mathbb{R^n} \rightarrow \mathbb{R}$ are polynomial functions. How do you show that the set of critical values of $f$ is finite?","['multivariable-calculus', 'polynomials']"
260072,What is the most unfair set of three nontransitive dice?,"In a set nontransitive dice , each die is superior to another die, but is inferior to a third.  It is similar to the game of rock-paper-scissors.  Here is one example: die A has sides: 2, 2, 4, 4, 9, 9
die B has sides: 1, 1, 6, 6, 8, 8
die C has sides: 3, 3, 5, 5, 7, 7 Die A has a 5/9ths chance of rolling a higher number than B, which itself has a 5/9ths chance of rolling a higher number than C, which itself has a 5/9ths chance of rolling a higher number than A.  It is a circle with no overall winner. Suppose there is a simple dice game where one person picks a die from the set of three nontransitive dice. A second person then picks another die from the set.  The players then roll their dice, and the person who rolls the higher number wins.  If there is a tie, the players simply roll again until there is a winner. If this game is played with the above set of dice, then the second player will always be able to pick a superior die, and will win the game 5/9ths of the time. What is one possible set of nontransitive dice that maximizes the unfairness of this game?  One additional requirement is that the second player's odds of winning must not be affected by the first player's choice of die.","['dice', 'recreational-mathematics', 'probability']"
260081,"Application of a result on some bounded functionals on a subspace of $C([0,1])$","The following result was proved in a previous post: Bounded functionals on Banach spaces. Let $(X, \|.\|)$ be a Banach space such that $X \subset C([0,1]) $ For every $r\in \mathbb{Q}\cap[0,1], f\mapsto f(r)$ defines a bounded linear functional on $X$. There exists a $C>0$ such that, for all $f\in X$, $$\sup_{x\in[0,1]} |f(x)| \leq C\|f\|.$$ Question: Does anyone know an example of space $X$ where this result is interesting? Indeed I feel that the example above could be a very nice application of the Banach-Steinhaus theorem, but the examples of spaces $X$ I thought of were too simple: One could easily prove the result without the Banach-Steinhaus theorem. The assumption on boundedness would be easy to prove for all $r$ in $[0,1]$. If someone has an example of space $X$ satisfing the first point, even without the second one, I am already interested.","['operator-theory', 'examples-counterexamples', 'functional-analysis', 'banach-spaces']"
260087,"Show $\lim_{n \to \infty} \min\{a_{n},b_{n}\} = \min\{a,b\}$","If $\lim_{n \to \infty} a_{n} = a$ and $\lim_{n \to \infty} b_{n} = b$, how can we show that $\lim_{n \to \infty} \min\{a_{n},b_{n}\} = \min\{a,b\}$? I say $\min\{a_{n},b_{n}\} $ has two cases: $a_{n}$ and $b_{n}$. So (1) $\lim_{n \to \infty} a_{n} = a$ and (2) $\lim_{n \to \infty} b_{n} = b$. Now I don't know how to imply the $\min\{a,b\}$.","['problem-solving', 'proof-writing', 'limits']"
260096,Find the coordinates of a point on a circle,"I have a circle like so Given a rotation θ and a radius r , how do I find the coordinate (x,y)?  Keep in mind, this rotation could be anywhere between 0 and 360 degrees. For example, I have a radius r of 12 and a rotation θ of 115 degrees. How would you find the point (x,y)?","['geometry', 'trigonometry', 'circles', 'rotations']"
260097,How to prove the derivative of position is velocity and of velocity is acceleration?,"How has it been proven that the derivative of position is velocity and the derivative of velocity is acceleration? From Google searching, it seems that everyone just states it as fact without any proof behind it.","['physics', 'derivatives', 'definition']"
260101,Writing the polar equations $r = 2\cos 3\theta$ in Cartesian form,"For an example problem, in my textbook, the author wanted to demonstrate how to graph a polar function. Deeming it most convenient, my author took the polar function $$r=2\cos 3\theta ,$$ and re-wrote it as the parametric equations $$\begin{cases}
x=2\cos 3\theta \cos \theta\\ y=2\cos 3\theta \sin \theta .\end{cases}$$ How did the author arrive at these equations?","['polar-coordinates', 'algebra-precalculus']"
260111,Proving Cauchy condensation test,"I have to prove the condensation test of Cauchy by tomorrow and I am really unconfident about what I did: $$\sum_{n=1}^\infty a_n\text{ converges } \iff
\sum_{n=1}^\infty 2^n a_{2^n}\text{ converges}$$ I did the following: Let $(b_n)$ be a sequence as follow: $b_{2^k+m}:=a_{2^k}$ with $k\in\mathbb N_0$ and $0\leq m<2^k$. It's $a_{n+1}\leq a_n$ and so $0\leq a_{n+p}\leq a_n$ for all $n,p\in\mathbb N$. So $\sum\limits_{n=1}^\infty b_n$ converges by the majorizing series $\sum\limits_{n=1}^\infty a_n$. And it's $\sum\limits_{n=0}^\infty b_n=\sum\limits_{n=0}^\infty\sum\limits_{m=0}^{2^n-1}a_{2^{n+1}}=\sum\limits_{n=1}^\infty 2^{n-1}a_{2^n}$ so $\Rightarrow$ is done. For $\Leftarrow$ consider $c_{2^k+m}:=a_{2^k}$ with $k\in\mathbb N_0$ and $0\leq m<2^k$. It's $|a_n|\leq c_n$ and $\sum\limits_{n=0}^\infty c_n=\sum\limits_{n=0}^\infty\sum\limits_{m=0}^{2^n-1}a_{2^{n}}=\sum\limits_{n=1}^\infty 2^{n}a_{2^n}$ and so $\sum\limits_{n=1}^\infty a_n$ converges by the majorizing series $\sum\limits_{n=0}^\infty c_n$. Is this in form and content correct?","['sequences-and-series', 'real-analysis']"
260119,$f$ continous at $x_0$ $⇒\lim_{h→0}∫_{x_0}^{x_0+h}\frac{f(t)}{h}=f(x_0)$,"The function $f:ℝ→ℝ$ is continuous on $x_0\inℝ$. 
Prove using the definition of a Darboux Integral that 
$$\lim_{h→0}∫_{x_0}^{x_0+h}\frac{f(t)}{h}=f(x_0)$$ I'm a first grade math student following an analysis course. The book that is used is Elementary Analysis by Ross . Definitions The upper Darboux sum $U(f,P)$ of $f$ with respect to a partition $P$ is the sum 
$$U(f,P)=∑_{k=1}^nM(f,[t_{k-1},t_k])(t_k-t_{k-1})$$ The lower Darboux sum $L(f,P)$ of $f$ with respect to a partition $P$ is the sum 
$$L(f,P)=∑_{k=1}^nm(f,[t_{k-1},t_k])(t_k-t_{k-1})$$ $f$ is continuous at $x_0$ ⇔ $∀ε>0,∃δ>0,(|x-x_0|<δ ⇒ |f(x)-f(x_0)|<ε)$ Let $f$ be a function defined on on $J-\{a\}$ for some interval $J$ containin $a$, and let $L$ be a real number. Then $ \lim_{x→a}f(x)=L$ if and only if
$$∀ε>0,∃δ>0,(0<|x-a|<δ⇒|f(x)-L|<ε)$$ Can someone check if this is an correct proof ? Proof Let $ε>0$. Then there exist an $δ>0$, such that: $|x-x_0|<δ ⇒ |f(x)-f(x_0)|<ε$. 
Let $0<|h-0|<δ$. If $x\in[x_0,x_0+h]$ then $x\in(x_0-δ,x_0+δ)$, then $|f(x)-f(x_0)|<ε$, then $|\frac{f(x)}{h}-\frac{f(x_0)}{h}|<\frac{ε}{h}$. Therefore: 
\begin{equation*} 
m ( \frac{f(x)}{h},[x_0,x_0+h]) \cdot (x_0+h - x_0) ≥ \frac{f(x_0)-ε}{h} \cdot h = f(x_0)-ε
\end{equation*}
\begin{equation*} 
M ( \frac{f(x)}{h},[x_0,x_0+h]) \cdot (x_0+h - x_0) ≤ \frac{f(x_0)+ε}{h} \cdot h = f(x_0)+ε
\end{equation*} Therefore we can conclude that for a partition $P$ of $[x_o,x_0+h]$ \begin{equation*} 
f(x_0)-ε< L(f,P)≤∫_{x_0}^{x_0+h}\frac{f(t)}{h}≤U(f,P)<f(x_0)+ε 
\end{equation*}
QED","['continuity', 'integration', 'real-analysis', 'limits']"
260124,Conjugate prior for noisy Bernoulli,"It is well known that the Beta distribution serves as a conjugate prior for the Bernoulli distribution, and that when you observe a Bernouilli random variable, you need only increment the appropriate hyperparameter of the Beta distribution. However when the Bernoulli distribution is ""noisy"" in the sense that you do not observe the the Bernoulli random variable directly, but instead observe a random variable that is equal to the Bernoulli random variable with probability 1-p and flipped with probability p, where p is known, and represents an error rate in observing the Bernoulli random variable, the posterior distribution obtained is a linear combination of two Beta distributions. In the case when p=0, p=.5, and p=1, the posterior distribution is again Beta, but for other values of p, this is not the case. In my particular application analytic tractability is important. Is there a conjugate prior that would be appropriate for this type of problem? Failing that, it seems there might be a sensible way to update the hyperparameters of the Beta distribution in an approximate sense. Intuitively, when you observe a Bernoulli random variable with error rate p, the information you have about the parameter theta of the Bernoulli distribution is nothing when p=.5 (observations are completely uninformative) and maximum when p=0 or p=1, and somewhere in between for other values of p. More specifically, in the case when p=1 or p=0, the sum of the hyperparameters of the beta in the posterior distribution is 1 greater than the sum in the prior, and for p=.5, the sum of the hyperparameters remains the same. For other values of p, the change in the sum of the hyperparameters should be intermediate, but I'm not sure how to best choose them.","['statistics', 'bayesian']"
260175,"Showing that $f(x)$ is increasing on $(0,+\infty)$","I am collecting some easy problems for my students and now I am facing to the following problem: Prove that the function $$f(x)=\left(1+\frac{1}{x}\right)^x$$ is increasing in   $(0,+\infty)$. Undoubtedly, they will solve it by using the logarithmic differentiation . I am wonder what can I do if someone wants me to verify it just by doing the definition of increasing function? I think , I am missing somethings here around. Light my way. Thanks!",['calculus']
260177,What is the maximum value of $|f(z)|$ on the unit disc $D=\{z \in \mathbb C:|z|\leq 1\}$?,"I am thinking about the following problem: Let $f(z)=2z^2-1.$ Then what is  the maximum value of $|f(z)|$ on the unit disc $D=\{z \in \mathbb C:|z|\leq 1\}$ ? I guess I have to use the maximum modulus principle.But  I also notice that $|f(z)|=|2z^2-1|\leq 2|z|^2+1\leq 2+1=3.$ So, is $3$ the maximum value of $|f(z)|?$ Can someone point me in the right direction? Thanks in advance for your time.",['complex-analysis']
260181,How does this textbook go from this step to the next in proving this?,Here's the picture of the question: How does it go from p v ~q to ~p -> ~q ?,"['logic', 'propositional-calculus', 'discrete-mathematics']"
260183,Number of polynomfunctions $\mathbb{Z}_3 \rightarrow \mathbb{Z}_3$,"I need to determine the number of polynomfunctions over $\mathbb{Z}_3 \rightarrow \mathbb{Z}_3$. I have no clue how to attempt this problem. I know that $\mathbb{Z}_3 =$ {0, 1, 2}. The polynomfunction is defined as: $f(x) = a_kX^k + ... a_1X^1 + a_0X^0$. Now in $\mathbb{Z}_3$ we get the following possible polynomfunctions: 1. $f(x) = a_0X^0$ 2. $f(x) = a_1X^1 + a_0X^0$ 3. $f(x) = a_2X^2 + a_1X^1 + a_0X^0$ 4. $f(x) = a_2X^2 + a_1X^1$ 5. $f(x) = a_2X^2$ 6. $f(x) = a_2X^2 + a_0X^0$ 7. $f(x) = a_1X^1$ Does anyone know how to calculate the number of possible polynomfunctions?",['discrete-mathematics']
260201,Is it viable to ask in an infinite set about the Cardinality?,"Can you ask given an infinite set about its cardinality? Does an infinite set have a cardinality? So, for example, what would be the cardinality of $+\infty$?","['cardinals', 'elementary-set-theory', 'infinity']"
260202,Proving that $(\mu^{*})^{*}=\mu^*$ for a measure $\mu$,"I am not sure I am using the standard definitions so I will open by
defining what I need: Let $X$ be a set, $\nu:\, \mathscr{P}(X)\to[0,\infty]$ will be called an external measure if $\nu(\emptyset)=0$ and for any
  $\{A_{i}\}_{i=1}^{\infty}\subseteq\mathscr{P}(X)$ (not neccesarily disjoint) it
  holds that
  $\nu(\cup_{i=1}^{\infty}A_{i})\leq\sum_{i=1}^{\infty}\nu(A_{i})$ Let $\nu$ be an external measure on a set $X$ then we say that a set $A$ is $\nu$ measurable if for any $E\subseteq X$: $\nu(E)=\nu(E\cap A)+\nu(E\cap A^{c})$ Let $\mu$ be a $\sigma$-additive measure on an algebra $A\subseteq X$, let $\mu^*$
be the outer measure on $X$ that comes from $\mu$. It was proven in another exercise that the set of $\nu:=\mu^{*}$
measurable sets, $M$, is a $\sigma$ algebra and that $\nu$ is $\sigma$-additive
on $M$. Since $\nu$ is also a measure on the algebra $M$ there is an outer
measure $\nu^*=(\mu^*)^{*}$. The exercise wishes to prove that $(\mu^{*})^{*}=\mu^*$. I don't really know how to even start here, what I first wanted to figure out is what is $M$. my intuition is that $A=M$ but I tried to prove it and couldn't start (I wrote the definitions but I couldn't see why if $B\in A$ it is $\nu$-measurable, not to mention the other direction which seems even harder). Can someone please help me get started on this problem ? maybe a hint or an observation that might help me figure out what to do? ADDED: by an outer measure that comes from a measure I mean $$\forall E\subseteq X:\,\nu(E):=Inf\{\sum_{i=1}^{\infty}\mu(A_{i})\,|\, A_{i}\in A,E\subseteq\cup A_{i}\}$$","['measure-theory', 'real-analysis']"
260210,Triple integral over a three dimensional region,"The integral $$\int_{-2}^2\int_{x^2}^4\int_0^{1-y/4} 1\ dz\ dy\ dx$$is a triple integral over a three dimensional region E,  Sketch E, and rewrite this integral with $y$ as a first variable and $z$ second variable and $x$ as a third variable. What I have done so far: $0\le z \le{1-y/4}$ $x^2\le y \le+4$ $-2 \le x\le+2 $","['multivariable-calculus', '3d', 'calculus', 'integration', 'definite-integrals']"
260223,$\mathrm{Aut}_\mathbb{Q}(\overline{\mathbb{Q}})$ is uncountable,How do you show that $\mathrm{Aut}_\mathbb{Q}(\overline{\mathbb{Q}})$ is uncountable ? Thanks in advance,"['galois-theory', 'abstract-algebra', 'field-theory']"
260250,Calculating an angle adjacent to hypotenuse given two points,"I'm working on a chapter in my book dealing with touch input, and my memory of high school trig (from circa 1988) is failing me. My search here has not yielded anything that I'm capable of applying to this particular problem. Description I have a ship on the screen. If the user touches the screen, I need
to turn the ship to align with that point (but over several steps, so
I'd do it in increments). To do this, I need to calculate the angle shown in the diagram below. Knowns The ship's current X and Y location. The touch point's X and Y location Can potentially calculate in case it helps Arbitrary points along the line starting at the current location and going out to the current heading, given a distance. Length of hypotenuse (I know the start and end points) What I need to calculate The Angle between the imaginary line which represents the current heading, and the touch point, with the vertex at the current location. This image shows what I'm looking for: I've been searching all day for anything which will (ahem) trigger a memory as to how to solve this, but I've been hitting nothing useful. Trig was never a strong skill for me in any case. Sin/Cos/Tan functions need more data than I currently have. I thought about doing something with line intersection to get the length of the opposite side so I could use the Sin function, but I couldn't figure out how to calculate the line perpendicular to the heading and passing through the known touch point. I'll take anything which works, but I'm doing this calculation frequently, so efficiency (for things which can be represented in code) is a plus. Thanks for your time here.","['geometry', 'triangles', 'trigonometry']"
260278,"When is $f^{-1}=1/f\,$?","I seem to remember a nice article that I read many years ago (perhaps in the American Mathematical Monthly ) which investigated the question, ""Under what conditions on $f:\mathbb{C}\to\mathbb{C}$ is $f^{-1}=1/f\,$?"" Despite my online searches, I cannot locate it. Does anyone have a reference? Or answer to the question---which to the best of my memory was nontrivial (and took a complex variables approach)? Edit: Just to set the record straight, the assumption the authors used in the article was actually this: ASSUMPTION. The function $f$ is one-to-one from the positive half-line $(0, \infty)$ onto itself and satisfies $f^{-1}(x)= 1/f(x)$ for all $x$ in $(0,\infty)$.","['reference-request', 'functions', 'functional-equations']"
260280,"What is a ""normalized valuation"" corresponding to a valuation ring?","I encountered the phrase ""normalized valuation"" similar to the following: Let $A_i$ be the valuation ring $k[x_1,...,x_n]_{\langle x_i\rangle}$ and $v_i$ be the normalized valuation defined by $A_i$. I didn't know this term before, and a short internet search did not help me. What I know: we can define a map $k[x_1,...,x_n]\smallsetminus\{0\}\to\mathbb{Z}$ by sending $f=gx_i^{n_f}$ with $x_i\nmid g$ to $n_f\in\mathbb{Z}$. Then extend this to $v:Q(k[x_1,...,x_n])^*=k(x_1,...,x_n)^*\to\mathbb{Z}$ via $\frac{f}{g}\mapsto n_f-n_g$, and this is a discrete valuation on $k(x_1,...,x_n)$ with $k[x_1,...,x_n]_v=k[x_1,...,x_n]_{\langle x_i\rangle}$ as its discrete valuation ring. Is the map $v$ already the $v_i$ mentioned above? Is it ""normalized"", and what does this mean? Also, the definition of the map $v$ relies on $k[x_1,...,x_n]$ being a UFD. So by the same argument, $R_{\langle p\rangle}$ is a DVR if $R$ is a UFD and $p\in R$ prime. So I guess this does no longer hold for rings of the form $R_\mathfrak{p}$ where $\mathfrak{p}\subset R$ is prime in general? What about $k[x_1,...,x_n]_{\langle x_1,x_2\rangle}$? Thank you!","['commutative-algebra', 'valuation-theory', 'abstract-algebra']"
260308,convex relaxations,"Is there a notion of ""best"" convex relaxation of a particular function in a normed vector space? For example, the $\ell^0$ pseudo-norm can be relaxed into the $\ell^1$ norm, and that allows us to solve sparse recovery problems. Is there a general recipe to construct such relaxations given an arbitrary function? Specifically, I have a function of the form
$f(x) = \|x\|_2\|x\|_1$, which is non convex. How would I go about relaxing this? Any resources/links I should look into?","['convex-analysis', 'functions']"
260315,"Is $\lim_{n \to \infty} \lim_{l \to \infty} \ a_{n,l} = \lim_{l \to \infty} \lim_{n \to \infty} \ a_{n,l}\;$?","Is $\lim_{n \to \infty} \lim_{l \to \infty} \ a_{n,l} = \lim_{l \to \infty} \lim_{n \to \infty} \ a_{n,l}\;$? What happens if I replace limits with lim sups? Thanks!",['analysis']
260323,Taking $e^{xn}=(e^x)^n$ a step further to rational numbers.,"Working on an assignment but I've run into a stumbling block!  I've got a couple of problems that I don't know how to do!  The problems are attempting to have you define the $\log$ and $\exp$ functions. Thanks in advance!  I can't wait to be done with this Analysis course! Things I have already proven: For any $ x \in (0,\infty)$, define $L(x)=\int_{1}^x {1\over t} dt$ $L(1/x)=-L(x)$ $L(x)$ is invertible and its inverse is $E(x)$ $E'(x)=E(x)$ $L(ax)=L(x)+L(a)$ $E(y+z)=E(y)E(x)$ Part A: Done Let $n$ be a positive integer.  Prove by induction that $E(nx)=E(x)^n$. Part B: Done Deduce from (a) that we also have $E(-nx)=E(x)^{-n}$, so (a) holds for all integers $n$. Part C: My Problem Child Deduce (give details) that for any rational number $r={m\over n}, $with $ n, m $ integers, $ m>0$, that $E(rx)=E(x)^r$ For this last part, I feel like I can just say something like let $r=n$, then the truth of Part A applies Part C, which implies that: $E(rx)=E(x)^r$, but that seems way to easy! Thanks for the help!","['calculus', 'algebra-precalculus', 'real-analysis', 'analysis']"
260324,Does $\mu^{*}(E)=1$ imply $\mu^{*}(E^{c})=0$ when $\mu$ is an outer measure and the measure of the space is $1$,"Let $(X,S,\mu)$ be a measure space s.t. $\mu(X)=1$. Let $\mu^{*}$ be defined on $X$ by: $$\forall E\subseteq X:\,\mu^{*}(E):=\text{inf}\left\{\sum_{i=1}^{\infty}\mu(A_{i})\,|\, A_{i}\in S,E\subseteq\cup A_{i}\right\}$$ I have a set $E$ s.t. $\mu^{*}(E)=1$, does this mean $\mu^{*}(E^{c})=0$? I have tried to work with the definition, given $\epsilon>0$ there
is $N\in\mathbb{N}$ and $\{A_{i}\}_{i=1}^{N}\subseteq S$ s.t. $\sum_{i=1}^{N}\mu(A_{i})\geq1-\epsilon$ and $E\subseteq\cup_{i=1}^{N}A_{i}$ I want to use the $A_{i}$'s to get some set $B$ s.t $E^{c}\subseteq B$
and $\mu(B)<\epsilon$, but I didn't manage to find such a set. Can someone please help me understand if this claim is true, and if so how to prove it?",['real-analysis']
260327,What are a list of helpful boolean identities for solving boolean functions?,"For instance, things like $P \Leftrightarrow Q \equiv (P \Rightarrow Q) \land (Q \Rightarrow P)$ is a very helpful formula to know, as is $P \Rightarrow Q \equiv \lnot P \lor Q$ is another helpful one. But for whatever reason, it seems like I'm discovering these random helpful things rather, well, randomly. And if I Google for a list of boolean identities, all I seem to find is pages describing DeMorgan's Law, Distributive Law and whatnot, which is not what I'm looking for. Can anyone offer me some formulas or a link to them?","['logic', 'propositional-calculus', 'discrete-mathematics']"
260346,Is $\sqrt{z}$ a meromorphic function?,"The literature seems rather coy on this point. While $\sqrt{z}$ is not meromorphic on the complex plane $\mathbb{C}$, can it be regarded as globally meromorphic on the appropriate Riemann surface (two branched copies of $\mathbb{C}$), or (equivalently?) locally meromorphic at $z=0$? Moreover, can the root of the function at $z=0$ be regarded as a zero of order $1/2$? And moreover, is $1/\sqrt{z}$ also meromorphic on the surface, and can it be regarded as having a pole of order $1/2$? EDIT: Clarified(?) that I was asking whether the function globally meromorphic on $2 \mathbb{C}$.","['riemann-surfaces', 'complex-analysis']"
260349,Clairaut's Equation Singular and General Solutions,"I want to know how one how one would prove that the singular solutions to Clairaut's equation are tangent to the General solutions. so I have here: $$y(x) = xy' - e ^{y'}$$ Differentiating $$y' = y' +xy'' - y''e^{y'}$$ $$0 =y''(x-e^{y'})$$ Therefore for the general solution, I have $y'' = 0 \implies y' = c_1 \implies y_g(x) = c_1x + c_2$ Okay thats all well and good. As for the singular solution. I'm still not quite sure how the singular solution differs from the general solution. All I know is it must envelope the family of general solutions as well as be tangent to them (For reasons unknown to me If someone could explain it I would be eternally grateful). The singular solution is found by: let us create some parameter $$y' = p \implies 0 = x-e^p \implies ln|x| = p$$ Plug this back into the original DE to get the singular solution of y: $$y_s(x) = xln|x| - x$$ I want to show that one is tangent to the other at some point (By the way a kind of side note, If the two equations exist at the same point, doesn't that mean that the solutions are NOT unique at that point?) $$y_g(x) = y_s(x) = c_1x + c_2 = xln|x| - x$$ Now what? I solve for some point (x,y)? Then how would I prove that they are tangent? I don't quite understand this part, assuming this is all correct. Thank you anyone for looking at this!","['singular-solution', 'ordinary-differential-equations']"
260352,what are conormal distributions?,"According to the first answer in this post, a conormal distribution $u$ on a manifold $X$ relative to a (closed, embedded) submanifold $Y$ is an element of a Banach (or Hilbert) space $H$ such that for any positive integer $k$, we have
$$
V_1\cdots V_k u \in H
$$
where $V_i$ denotes a vector field that is tangent to $Y$ (smooth and unconstrained away from $Y$). I would like to better understand these objects. Hence I was wondering whether somebody could suggest a good example for a conormal distribution, or more detailed explanation of what these distributions ""look like"" ?","['differential-geometry', 'partial-differential-equations', 'functional-analysis', 'real-analysis']"
260353,combinatorics - calculate the total number of combinations of a system,"I make an example but I need to understand the general formula. 
I have a system defined by rows as for instance: A1,A2,A3,A4
B1,B2,B3
C1,C2
D1
E1 And I need to find all possible combinations of elements choose by 2 (doubles) or I need to find all possible combinations of elements choose by 4 (4 fold) or trebles and so on. 
For instance valid doubles are: A1,C1
A2,E1
A3,C2
etc. but not A1,A2 (because from the same row). I need the same for trebles, for instance the following: A3,C1,D1
A2,C1,D1
etc. I know the C(n,k) in case the system is composed only by A1,B1,C1,D1,E1 but I cannot figure out how to include the fact that some of the rows can have different values. In general a system can be composed by n rows, with each row that can have a different number of elements (different columns), I need a formula to calculate the total number of combinations generated choosing the elements in groups of k and, if possible, a generalisation which permits to find the totals for multiple k's (like total number of combinations for 4-folds, 5-folds and doubles). Thank you very much in advance to who will help me. Highly appreciated.",['combinatorics']
260360,How does one see the topology of a Riemann surface from the graph (assuming one can picture $\mathbb R^4$)?,"Given a function $f:\mathbb C\to\mathbb C$ which we will assume is analytic, we have an embedding $f\subseteq\mathbb C\times\mathbb C\cong\mathbb R^4$ of a surface. My question is with regards to how to graphically (not necessarily actually with pictures, but in the same sense as topologists like to fiddle with pictures in their heads) turn such an embedding into a recognizable topology like $(S^1)^2$ or $S^2$ or $RP^2$? Specifically, how does one ""deform"": poles (single, double) essential singularities polynomial behavior at infinity exponential behavior at infinity root branch points logarithmic branch points zeros (I don't think these need special treatment, but we'll see...) For example, the behavior of $\sqrt z$ on the unit circle is a lot like the Möbius strip, but I'm not sure how the behavior near zero directs my mental arts-and-crafts, and I'm not sure about $\infty$ either. I know that we want $\infty$ to be identified in all directions, but what about when it $f(z)$ shoots off in different directions for different directions $z\to\alpha\infty$, or worse, when it goes to zero in other directions (as in $e^z$). I know that this isn't the first question on Riemann surfaces, but I want to emphasize the intuitive and geometrical/graphical aspects of dealing with the topologies of Riemann surfaces. I don't expect that a complete answer will be able to avoid algebraic manipulation of the functions under consideration, but what I don't want to see is ""function $\Rightarrow$ algebra $\Rightarrow$ the surface is genus 2"" or somesuch.","['general-topology', 'riemann-surfaces', 'reference-request', 'complex-analysis']"
260362,Can someone show me why this factorization is true?,"$$x^n - y^n = (x - y)(x^{n-1} + x^{n-2}y + \dots + xy^{n-2} + y^{n-1})$$ Can someone perhaps even use long division to show me how this factorization works? I honestly don't see anyway to ""memorize this"". I like to see some basic intuition behind this","['factoring', 'algebra-precalculus']"
260373,Finding two more vectors to make up an axis,"Given a vector $\vec{v} = (x, y, z)$, how do I find two vectors that make up an axis with $\vec{v}$? In other words, one of them is perpendicular and lies in the same plane and the other is normal to those two vectors.",['linear-algebra']
260382,Check $\;y=\dfrac{\sin x}{x}\;$ is solution of $\;xy'+y=\cos x\;$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question How can I check that $\;y=\dfrac{\sin x}{x}\;$ is a solution of $\;xy'+y=\cos x\;$?","['ordinary-differential-equations', 'calculus']"
260387,Determining sign(det(A)) for nearly-singular matrix A,"Motivation: determining whether a point $p$ is above or below a plane $\pi$, which is defined by $d$ points, in a $d$-dimensional space, is equivalent to computing the sign of a determinant of a matrix of the form A = $\begin{pmatrix}p_{1}^{\left(1\right)} & p_{1}^{\left(2\right)} & \cdots & p_{1}^{\left(d\right)} & 1\\
p_{2}^{\left(1\right)} & p_{2}^{\left(2\right)} & \cdots & p_{2}^{\left(d\right)} & 1\\
\vdots & \vdots & \ddots & \vdots & \vdots\\
p_{d}^{\left(1\right)} & p_{d}^{\left(2\right)} & \cdots & p_{d}^{\left(d\right)} & 1\\
p^{\left(1\right)} & p^{\left(2\right)} & \cdots & p^{\left(d\right)} & 1
\end{pmatrix}$ Notes - When I say sign, I mean either negative, positive, or exactly zero The entry ${p_i}^j$ means the $j$-coordinate (e.g., $x$, $y$ and $z$ when $d$=3) of the $i$'th point in my problem. The matrix is not a Vandermonde matrix. The resulting matrix is composed of floating-point numbers. It has no special structure, is not diagonally dominant, is not symmetric, and has no special reason to be positive-semidefinite. It might be sparse, though. It is, however, many times nearly singular. I'm interested in computing $\mbox{sign}(|A|)$ in a fast and robust way. Since this is Math-SE, I'm mainly asking if there are any spectral theorems which allow this computation without explicitly computing the determinant. For example, the Greshgorin Circle Theorem could be very useful if $A$ was diagonally-dominant. Alternatively, any cheap test to identify some cases would also be helpful.","['matrices', 'algorithms', 'determinant']"
260391,Central limit theorem confusion,"If a bunch of random variables $X_i$ are independently and identically distributed with an exponential distribution, their sum apparently follows a Gamma distribution. But doesn't the central limit theorem imply that (for $X_i$ of any distribution with mean zero and variance $\sigma^2$), the sum $\sum_{i=1}^n X_i$ will become approximately normally distributed $~N(0,n\sigma^2)$ for large enough $n$ ? Obviously I am missing something basic, but what's going on? How can the sum of i.i.d. exponential random variables have a Gamma distribution, but also be converging to normality?","['statistics', 'probability-distributions', 'probability']"
260403,Simple question about asymptotics of a ratio,What is the largest exponent $\alpha$ such that the ratio between $ n^{\alpha}$ and $ (\sqrt{n} / \log{ \sqrt n}) $ still remains asymptotically bounded (can assume $n$ positive integer) ?,"['asymptotics', 'functions']"
260422,Proving a Ring is commutative if every element is idempotent [duplicate],"This question already has answers here : How to show that every Boolean ring is commutative? (14 answers) Closed 11 years ago . I had this question on a final exam.  I was wondering if anyone knows a proof for it. Let R be a ring not necessarily with unity ($1 \neq 0$ and $x \in R$ so that $x*1=x=1*x$) and let R have the property that every element of R is idempotent that is $\forall x \in R\quad x*x=x$.  Prove that $R$ is commutative. Not to put my whole answer up because I know I was wrong.  I will put the part where I had trouble going to the next step. My argument went like this:  let $a,b \in R$ then $ab\in R$ cause $R$ is a ring.  Therefore $abab=ab$. Now $aabb=ab$ as well, so $$abab=aabb\ \Rightarrow abab-aabb=0 \Rightarrow\ a(ba-ab)b=0\ \because\text{ distributive property of $R$}.$$ Now because R is not a division ring then the element $a$ could be a divisor of zero or $b$ could be as well so you cannot just assume $ba-ab=0$.  This is where I am stuck.","['ring-theory', 'abstract-algebra']"
260426,Every finite extension of a finite field is separable,"I'm trying to prove that every finite extension of a finite field is separable. I found a solution on internet which says: Let $F$ be a finite field and $E$ be an extension of $F$ having  $p^n$
  elements. Then $E=F(\alpha)$, where $\alpha \in E$ and so
  $\alpha^{p^n} -\alpha=0$. This implies $\alpha$ is a separable
  element, and hence $F(\alpha)$ is a separable extension of F. I don't understand why $\alpha^{p^n} -\alpha=0$ and why $\alpha$ is a separable element, I need help. Thanks","['abstract-algebra', 'field-theory']"
260429,Let $f:\mathbb R \rightarrow \mathbb R$ be continuous with $f(0)=f(1)=0.$,"I was thinking about the following problem: Let $f:\mathbb R \rightarrow \mathbb R$ be continuous with $f(0)=f(1)=0.$ Then which of the following is not possible? (a) $f([0,1])=\{0\},$ (b) $f([0,1])=[0,1),$ (c) $f([0,1])=[0,1],$ (d) $f([0,1])=[-1/2,1/2].$ Can someone point me in the right direction? Thanks in advance for your time.","['real-analysis', 'analysis']"
260444,Localization at a Maximal Ideal,"While studying, I came across this question: If $A$ is a ring in which $x^n=x$ for all $x\in A$ (where $n$ is an integer greater than $1$ and may depend on $x$), show all prime ideals are maximal. I didn't find the solution too hard (if it is correct). We let $P$ be a prime ideal. That $A/P$ is an integral domain; if we can show it is also a field, we'll know that $P$ is maximal. To that end, we know $a^n+P=a+P$, and in particular, $(a+P)(a^{n-1}+P)=(a+P)(1+P)$. Since we're in an integral domain, the cancellation law applies, so we have $(a^{n-1}+P)=(1+P)$. Now we have $(a+P)(a^{n-2}+P)=(1+P)$, hence $(a+P)$ has an inverse, so $A/P$ is a field. The next question has me confused, though: Let $\mathbf{m}$ be a prime ideal in a ring in which $x^n=x$ for all $x\in A$ (where $n$ is an integer greater than $1$ and may depend on $x$). Show that $A_\mathbf{m}$ is a field. It seems like $A_\mathbf{m}$ should not be a field since $\frac{m}{1}$, $m\in\mathbf{m}$ wouldn't have an inverse, thus it would have to be in the equivalence class of $\frac{0}{1}$, but I don't see why that is true (if it indeed is true). Please help clear this up for me!","['ring-theory', 'ideals', 'abstract-algebra']"
260445,How to prove that construction of Farey sequence by mediant is coverage?,"Farey sequence of order $n+1$ ($F_{n+1}$) can be construct by adding mediant value (${a+c \over b+d}$) into $F_{n}$, where ${a \over b}$ and ${c \over d}$ are consecutive term in $F_{n}$, and  $b+d = n+1$. I've already prove that ${a \over b} < {a+c \over b+d} < {c \over d}$ $b+d$ always irreducible in ${a+c \over b+d}$. the middle of any 3 consecutive term in any $F_{n}$ are mediant. Number of new elements added is $\phi(n+1)$. Now I wonder does the construction by mediant value coverage all elements in $F_{n+1}$. It's easy to show that ${1 \over n+1}$ and ${n \over n+1}$ does involve in it, but I have no idea how to show that other ${m \over n+a}$, where $gcd(m, n+1) = 1$, are going to be constructed. Please give me a hint.","['fractions', 'farey-sequences', 'sequences-and-series']"
260446,How many ways can you create a password of 10 characters long that has at least one lowercase letter (a-z) and at least one number ($0-9$)?,Suppose you want to generate a password using ASCII  characters ($128$ characters.)How many ways can you create a password of 10 characters long that has at least one lowercase letter (a-z) and at least one number ($0-9$)? ** MY ANSWER: $26*10*(128)^{10}$** I don't understand why this is wrong? Can anybody help? Thanks!,"['faq', 'discrete-mathematics', 'combinatorics']"
260454,The radius of convergence of the power series $\sum_{0}^{\infty}P(n)x^n$,"I came across the following problem: Let $P(x)$ be a non-zero polynomial of degree $N.$ The radius of convergence of the power series $\sum_{0}^{\infty}P(n)x^n$ (a)depends on $N,$ (b)is $1$ for all $N,$ (c)is $0$ for all $N,$ (d)is $\infty$ for all $N.$ My attempts: I see that  $lim_{n\to\infty}P(n+1)/P(n)=1$,because if I take $N=2$,then we can take $P(n)=a_0+a_1n+a_2n^2$ and $P(n+1)=a_0+a_1(n+1)+a_2(n+1)^2$ and hence $\frac {P(n+1)}{P(n)}=1+\frac {a_1+(2n+1)a_2}{P(n)}$ which tends to $1$ as $n$ tends to $\infty$. From here,Can i say that (b)is the right choice? Am i going in the right direction? Please comment. Can someone point me in the right direction? Thanks in advance for your time.","['power-series', 'real-analysis', 'analysis']"
260463,Bounded convergence theorem,"Suppose that $f_n$ is a sequence of measurable functions that are all bounded by M, supported on a set E of finite measure, and $f_n(x)\to f(x)$ a.e. x as $n\to \infty$. Then f is measurable, bounded, supported on E for a.e. x, and $\int |f_n-f|\to 0 $ as $n\to\infty$ At here, I understand the restriction of E to be finite measure is because we need to use Egorov theroem. But what is the reason to assume $f_n$ to be bounded? I check the Egorov theorem, it does not require the squence that converge to $f$  to be bounded in order to find a smaller set differs from E by $\epsilon$ and converges uniformly to $f$ on that set.","['lebesgue-integral', 'real-analysis']"
260464,Intuition behind Cauchy Riemann equations and power series representation,"The Cauchy Riemann equations in effect say that a function $f(z) = u(z)+iv(z)$ can be approximated as roughly a scaled rotation $$f(c+h) \approx f(c) + f'(c)h = f(c) + \begin{bmatrix}u_x & -v_x\\v_x & u_x\end{bmatrix} \begin{bmatrix}h_x \\ h_y \end{bmatrix}$$ Informally, if $f$ has this kind of approximation at every point in a domain then it admits a power series representation at each point. Intuitively why should having the scaled rotation approximation give a full power series representation? Suppose at some point $c$ the Cauchy Riemann equations are satisfied but there does not exist a power series representation at $c$, then presumably there should be a geometric point of view to see that this is ridiculous and leads to $f$ not satisfying the Cauchy Riemann equations elsewhere.",['complex-analysis']
260471,Show that a sequence converges,"Suppose that $\{ x_n \}_{ n = 1 }^\infty$ is a converging sequence of real numbers with $\lim_{ n \to \infty } x_n = x$. Define
$$ y_n = \frac{ x_1 + \cdots + x_n }{ n } $$
Show that $\lim_{ n \to \infty  } y_n = x$. I'm not really sure where to start.","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
260487,Prove a set is at most countable,"Suppose that for each $\lambda$ in a set $\Lambda$ we have a positive real number $a_\lambda > 0$. Suppose also that for any natural number $n$ and any $\lambda_1, \cdots, \lambda_n \in \Lambda$ we have
$$ \sum_{ i = 1 }^n a_{ \lambda_i } < 1 $$
Prove that the set $\Lambda$ is at most countable. I know that every $0 < a_{ \lambda_i } < 1$. I was wondering if I could get a hint. Thanks!",['real-analysis']
260512,Find the determinant of $A$ satisfying $A^{-1}=I-2A.$,I am stuck with the following problem: Let $A$ be a $3\times 3$ matrix over real numbers satisfying $A^{-1}=I-2A.$ Then find the value of det$(A).$ I do not know how to proceed. Can someone point me in the right direction? Thanks in advance for your time.,"['linear-algebra', 'determinant']"
260537,How many ways are there to choose 10 objects from 6 distinct types when...,"(a) the objects are ordered and repetition is not allowed? (b) the objects are ordered and repetition is allowed? (c) the objects are unordered and repetition is not allowed? (d) the objects are unordered and repetition is allowed? I'm not really sure what it means for the objects to be ""ordered"" and repetition to be ""allowed.""  Can someone succinctly explain what happens in each case, and how this can be generalized to other problems of the same type?","['permutations', 'discrete-mathematics', 'intuition', 'combinatorics']"
260539,inverse limit realized as global section,"Does the construction (realization) below have some standard name? (Something I could search for?) Does it have any use? Suppose $I$ a directed set, and $(A_\alpha,\pi_{\alpha,\beta} \text{ for } \alpha > \beta \in I $) an inverse system of modules (or groups, or whatever). Put a topology on $I$ by declaring sets $D$ which are ""downwards closed"" (if $\alpha > \beta$ and $\alpha\in D$ then $\beta\in D$) to be open, so $\alpha\downarrow = \{\beta\in I \mid \beta \leq \alpha\}$ is a basis. Define a sheaf $S$ over $I$ with stalks $S_\alpha = A_\alpha$ ($\alpha\in I$). Toplogy on the stalk space: If $a\in S_\alpha$, an open nhbd is $\{\pi_{\alpha,\beta}(a)\mid \beta \leq \alpha\}$. Then $p:\Gamma S \rightarrow I$ defined by $p(a) = \alpha$ if $a\in S_\alpha$ is a local homemorphism. Addition on the stalk space should be continuous (haven't checked) Then the inverse limit of the original system is the same thing as the module of global sections. So any completion of a linear topology on a module could be realized in this way as well. Is this been used for anything I could read about somewhere?",['algebraic-geometry']
260555,Understanding the Banach fixed point theorem,"The Banach fixed point theorem is stated in my book ( Applied Asymptotic Analysis by Miller) as Let $\mathcal B$ be a Banach space with norm $\|\cdot\|$.  Let $X$ be a nonempty bounded subset of $\mathcal B$ and suppose that $T \colon X \to X$ is a mapping that satisfies, for some $0 < \rho < 1$, the inequality
  $$
\|T(f) - T(g)\| \leq \rho \|f-g\|
$$
  for all $f$ and $g$ in $X$.  Then there exists a unique element $f^\infty \in X$ such that (i) the sequence of iterates $\{T^k(f)\}_{k \geq 0}$ converges to $f^\infty$ whenever $f \in X$ and (ii) $f^\infty = T(f^\infty)$. I'm having some trouble understanding this result. Suppose $X_R$ is the ball of radius $R$, i.e.
$$
X_R = \{f \in \mathcal B \colon \|f\| \leq R\},
$$
and suppose that $T$ is a contraction mapping on $X_R$.  The theorem says that $T$ has a unique fixed point $f^\infty \in X_R$. But isn't $T$ also a contraction mapping in every ball $X_S$ with $0 < S < R$?  Does the theorem then imply that $T$ has a unique fixed point in $X_S$?  It then seems to me that we must have $\|f^\infty\| = 0$, for otherwise it would be outside of some such ball. Where am I going wrong?","['fixed-point-theorems', 'analysis']"
260562,"Solution book of John Kelley's , J.Munkres's [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 10 years ago . Improve this question I have so many difficult in solving problem in General Topology of John Kelley and Topology (second edition) of James R. Munkres. Does anyone know solution book of those? Just want to ask so many problem in there!","['general-topology', 'reference-request']"
260585,What to give as final lecture in a differential geometry class?,"During the fall semester, I had to give an exercise class to second year math students, as support for a theoretical class loosely based on the book `Differential geometry of curves and surfaces' by Do Carmo. Now and then I succeeded in squeezing in some fun topics not covered in the theory class, like the four-vertex theorem, minimal surfaces, de Rham cohomology of $\mathbb{R^{3}}$, ... Next week I have to give the last class, and I want to finish with some very nice theorem or set of ideas. Does anyone have any experience with this? Maybe someone was once in a class that tried to do something similar? There are a couple of criteria: It should take about an hour to explain It should only need the embedded definition of a variety, not the intrinsic one It is around the level of Do Carmo The prerequisites are the first and second fundamental form, normal and Gauss curvatures, the theorema egregium and basic ideas on geodesics and geodesic curvature. One of the physicists in the class asked me to say something about general relativity and differential geometry, but having looked through a number of references, this seems rather hard.","['education', 'differential-geometry']"
260589,How can I calculate the weak derivative of $\frac{1}{\sqrt{x}}$?,"Define a function $f(x)$ on $\mathbb{R}$ as: $$f(x) =\begin{cases}0&\text{for }x \le 0\\\\\frac{1}{\sqrt{x}}&\text{for }x > 0\;.\end{cases}$$ Then, how can I calculate the weak derivative(of course, distribution sense) of it? I roughly guess in $x>0$ region it becomes $\dfrac{-1}{2(\sqrt{x})^3}$; but I don't know how to deal with the neighborhood of $x=0$.",['functional-analysis']
260599,"Zeros of Fourier transform of a function in $C[-1,1]$","I am trying to prove the following: Let $g \in C[-1,1]$. Then the function $$G(z) = \int_{-1}^1 e^{itz}g(t)dt$$ has infinitely many zeros. I know that $G(z)$ is entire and $\lim_{x \to \pm \infty} G(x) = 0$. I have tried the following. Assume the contrary, that is, that $G(z)$ has only $n \in \mathbb{N}$ zeros. Then we can write it as
$$G(z) = e^{h(z)}P(z)$$
where $P(z)$ is a polynomial of degree $n$ and $h(z)$ is entire. The limit above implies that $h(x) + \log |P(x)| \to -\infty$, i.e. that $h(x) \to -\infty$ (on the real axis) faster than some asymptotically logarithmic positive function. Unfortunately the above does not seem to solve the problem, or at least I do not know how to continue. Asking for your guidance. EDIT: Other thought were: Approximate $g(t)$ with a step function $h_n(t)$ with $2^n$ steps. Define $H_n(z)$ as the transform of $h_n(t)$, show that $|G(z) - H_n(z)| < |H_n(z)|$ and apply Rouche's theorem. One problem is that $H_n(z)$ is also small on the boundary, and even if I could prove the inequality it is still unclear how infinity of zeros follows for $G(z)$. Show that $G(z)$ is of fractional order and apply Hadamard's theorem. This is clearly false since I can show that the order of $G(z)$ is bounded by $1$ from above, and, at least for some $g(t)$, the bound is achieved.","['fourier-analysis', 'roots', 'complex-analysis']"
260603,Understanding curvature,"I'm trying to understand how the Frenet frame is formed from the normal and tangent on a curve in $\mathbb{R}^3$. For a curve $\gamma (s)$ in $\mathbb{R}^3$ parameterised by arc length let $T(s) = \gamma' (s)$ be the unit tangent. From a previous questions, I understand that from $T . T = 1 $ we get $T . T' = 0$. Then this gives us that $T'(s) = \kappa (s) N(s)$ for $\kappa(s) \in \mathbb{R}$ for $N(s)$ the unit normal. BUT surely in $\mathbb{R}^3$ there are infinitely many normals as the vector can just 'rotate' round the curve whilst remaining perpendicular to the tangent and so I can't my head around how we can deduce $T'(s) = \kappa N(s)$ just from that fact $T . T' = 0$ ? Thanks!","['geometry', 'curvature']"
260614,Minimizing sequence,"This came up in a proof I was reading.
Define $$\inf_{z \in K} \|x-z\| = d$$ Let $y_n\in K$ be a minimizing sequence
How do we know that such a minimizing sequence exists?
Here K is a closed convex subset of a Hilbert space H.
Is this some axiom for from the reel numbers?","['hilbert-spaces', 'functional-analysis', 'real-analysis']"
260617,How to determine if Standard Deviation is high/low,"I have derived the following response time data for a performance test I am running: Min - 8sec
Max - 284sec
Average - 28sec
Standard Deviation - 27sec What does the standard deviation say about the response time data distribution? When you say low/high standard deviation, what does this actually mean? Is this in comparison to the Average/Min/Max? I know what standard deviation is and how it's computed. I'm just not sure how to tell if it is high or low.","['statistics', 'standard-deviation']"
260619,Exercise: Application of Hahn-Banach Theorem,"I'm working on this exercise (not homework) and I would gladly welcome some hints for how to solve it! Exercise: Let $\{x_1,\dots,x_n\}$ be a set of linearly independent elements of a normed vector space $X$. Let $c_1,\dots,c_n \in \mathbb{C}$. Show that there exists $f\in X^\ast$ such that $f(x_i)=c_i$. My idea: I consider $M = span\{x_1,...,x_n\}$, which is a subspace of $X$. Any $x\in M$ can be written $x=\sum_1^n \lambda_k x_k$, for some $\lambda_1,...,\lambda_n \in \mathbb{C}$. Define $f:M \rightarrow \mathbb{C}$ by $f(x_i)=c_i$ for $i=1,...,n$. Then $$f(x) = \sum_1^n \lambda_k f(x_k) = \sum_1^n \lambda_k c_k.$$ If I can find a semi-norm $p:X \rightarrow \mathbb{R}$ such that $|f(x)| \leq p(x)$ for any $x \in M$, then by Hahn-Banach Theorem we would be done. Thanks in advance!",['functional-analysis']
260621,Prove that $\int_0^{+\infty} \frac{\ln x}{a^2+x^2} dx = \frac{\pi\ln a}{2a}$,"Is that true $$\int_0^{+\infty} \cfrac{\ln x}{a^2+x^2} dx = \cfrac{\pi\ln a}{2a},$$ where $a>0$ ? And how to compute it?","['definite-integrals', 'improper-integrals', 'calculus', 'integration']"
260624,Proving that $\mu(A)=\mu(B)$ if $A\cap E=B\cap E$ and $\mu(E)=1$ where the measure of the space is $1$,"I have the following exercise I wish to solve: Let $(X,S,\mu)$ be a measure space s.t $\mu(X)=1$. Let $\mu^{*}$be defined on $X$ by: $\forall E\subseteq
 X:\,\mu^{*}(E):=\inf\{\sum_{i=1}^{\infty}\mu(A_{i})\,\mid\, A_{i}\in
 S,E\subseteq\cup A_{i}\}$ Let $E\subseteq X$ s.t $\mu^{*}(E)=1$, prove that if $A,B\in S,A\cap
 E=B\cap E$ then $\mu(A)=\mu(B)$ What I tried is to write $$A=(A\cap E)\cup(A\cap E^{c}),B=(B\cap E)\cup(B\cap E^{c})$$
and then apply $\mu^{*}$on both of them. Since $$A\cap E=B\cap E$$ I would have had $$\mu^{*}(A\cap E)=\mu^{*}(B\cap E)$$
and I hoped that $$\mu^{*}(E)=1\implies\mu^{*}(E^{c})=0$$ and from
$\mu^{*}$being monotone that means that $$\mu^{*}(A\cap E^{c})=\mu^{*}(B\cap E^{c})=0$$ hence $\mu^{*}(A)=\mu^{*}(B)$ but $A,B\in S$ hence $$\mu^{*}(A)=\mu(A),\mu^{*}(B)=\mu(B)$$
and than I would be done. But from this post is turns out that $\mu^{*}(E^{c})$ doesn't have to be $0$ and so my argument is not valid. Can someone please suggets how to solve this problem ? what I tried was my only idea.","['measure-theory', 'real-analysis']"
260655,Why is the hypergame not simply well founded?,"According to Cameron, the hypergame paradox proceeds as follows:
A game is considered as well founded if ANY play of the game ends in a finite number of moves. A hypergame is where the first player chooses well founded a game, and then the second player begins that game (the game is played with the roles reversed). Is the hypergame wf?
It should be, because the first player has to choose a wf game, and so it must end in a finite number of moves. But then, as it is well founded, the second player can choose the hypergame, and then the players can choose the hypergame ad infinitum, contradicting the hypergames wf-ness.
I do not see how this contradicts the hypergames wf-ness. The definition of a hypergame clearly sttaes that ANY play of the game ends in a finite number of moves. Well, the hypergame begins on the first go, and then if the second player chose tic-tac-toe (or any wf game except the hypergame), the game would be over in a finite number of moves in this case, making it well founded. Surely one case of the hypergame not ending in a finite number of moves does not contradict its wf-ness.
I feel like I am being incredibly stupid but I just can't see how this is a paradox.","['elementary-set-theory', 'paradoxes']"
260657,Why does this integral diverge: $\int_1^{\infty}\frac{x^6}{6x^6 − 1} dx$?,$$\int_1^{\infty}\frac{x^6}{6x^6 − 1} dx$$ I would assume it would converge but apparently it diverges. I know it has to do with improper integrals. Can anyone explain? Thank you for your time.,"['improper-integrals', 'convergence-divergence', 'calculus', 'integration']"
260666,Sum of binomial coefficients $\sum_{k=0}^{n}(-1)^k\binom{n}{k}\binom{2n - 2k}{n - 1} = 0$,"How do I prove the following identity: $$\sum_{k=0}^{n}(-1)^k\binom{n}{k}\binom{2n - 2k}{n - 1} = 0$$ I am trying to use inclusion-exclusion, and this will boil down to a sum like inclusion-exclusion, and the $\binom{2n-2k}{n-1}$ term wouldn't matter (it will be equivalent to set sizes). Is this a correct way to go?","['inclusion-exclusion', 'binomial-coefficients', 'combinatorics']"
260671,Question on Proposition Neukirch 10.3 - Splitting of prime ideals in $\Bbb{Q}(\zeta_n)$,"I am reading Proposition 10.3 of Neukirch which I have appended below: Proposition 10.3 (Neukirch): Let $n  = \prod_{p} p^{\nu_p}$ be the factorisation of the positive integer $n$ into prime numbers, and for every prime number $p$ denote by $f_p$ the multiplicative order of $p$ mod $n/p^{\nu_p}$. Then one has in $\Bbb{Q}(\zeta_n)$ the factorisation 
    $$p = (\mathfrak{p}_1\ldots \mathfrak{p}_r) ^{\varphi(p^{\nu_p})} \pmod{p}$$
    where the $\mathfrak{p}_i$ are distinct prime ideals of $\mathcal{o} = \Bbb{Z}[\zeta_n]$ lying over $(p)$, all of ramification index $f_p$. The idea of the proof is that it will suffice to show that $\phi_n(X)$, the minimal polynomial of $\zeta_n$ factors as $$\phi_n(X) = (p_1(X)\ldots p_r(X))^{\varphi(p^{\nu_p})} \pmod{p}.$$ Now let us write $n = p^{\nu_p}m$ with $(m,p) = 1$. I get how he deduces the congruence $$\phi_n(X) = \phi_m(X)^{\varphi(p^{\nu_p})} \pmod{p}.$$ The part where I don't understand next is where he says: Observing that $f_p$ is the smallest positive integer such that $p^{f_p} \equiv 1 \pmod{m}$, it is obvious that this congruence reduces us to the case where $p$ does not divide  $n$, and hence $\varphi(p^{\nu_p}) = \varphi(1) = 1.$ Why is it that in the case $p|n$ then the result follows? It seems to me he is claiming that when $p|n$ we have the polynomial $x^m-1$ having no multiples roots mod $p$. I don't understand the link between $p$ multiplicative order $f_p$ mod $m$ and the separability of $x^m - 1$ in the case $p|n$ Thanks.","['algebraic-number-theory', 'number-theory']"
260672,Showing that complicated mixed polynomial is always positive,"I want to show that $\left(132 q^3-175 q^4+73 q^5-\frac{39 q^6}{4}\right)+\left(-144 q^2+12 q^3+70 q^4-19 q^5\right) r+\left(80 q+200 q^2-243 q^3+100 q^4-\frac{31 q^5}{2}\right) r^2+\left(-208 q+116 q^2+24 q^3-13 q^4\right) r^3+\left(80-44 q-44 q^2+34 q^3-\frac{23 q^4}{4}\right) r^4$ is strictly positive whenever $q \in (0,1)$ (numerically, this holds for all $r \in \mathbb{R}$, although I'm only interested in $r \in (0,1)$). Is that even possible analytically? Any idea towards a proof would be greatly appreciated. Many thanks! EDIT: Here is some more information. Let
$f(r) = A + Br + Cr^2 + Dr^3 + Er^4$
be the function as defined above. Then it holds that $f(r)$ is a strictly convex function in $r$ for $q \in (0,1)$, $f(0) > 0$, $f'(0) < 0$, and $f'(q) > 0$. Hence, for the relevant $q \in (0,1)$, $f(r)$ attains its minimum for  some $r^{min} \in (0,q)$. $A$ is positive and strictly increasing in $q$ for the relevant $q \in (0,1)$, $B$ is negative and strictly decreasing in $q$ for the relevant $q \in (0,1)$, $C$ is positive and strictly increasing in $q$ for the relevant $q \in (0,1)$, $D$ is negative and non-monotonic in $q$, and $E$ is positive and strictly decreasing in $q$ for the relevant $q \in (0,1)$.","['inequality', 'calculus', 'algebra-precalculus']"
260674,An entire function with two periods,"Can anybody help me with this question: If $f(z)$ is an entire periodic function and it has to periods $2$ and $2i$, how can I find all other periods?",['complex-analysis']
260710,Chain rule and matrices - I'm confused,"I googled around and searched inside the forum but I'm still confused about a problem. I have 2 matrix functions $f,g : \mathbb{R}^{n \times n} \times \mathbb{R}^{a \times b} \rightarrow \mathbb{R}^{n \times n}$. Starting from this, I have the following expression: $$ t(Q, X, Y) = \text{tr}(f(g(Q, X),Y))$$ where $\text{tr}$ is the trace operator and $X, Y \in \mathbb{R}^{a \times b}$ and $Q \in \mathbb{R}^{n \times n}$. How do I evaluate $\frac{\partial t(Q,X, Y)}{\partial X}$ and $\frac{\partial t(Q,X, Y)}{\partial Y}$? I mean, I would like to know how to correctly apply the chain rule. * Addition * I will try to give more information about my problem.
Suppose that $a = b = n$ and that $f(A,B) = AB$ and $g(A,B) = BA + AB$ (actually this is only an example of possible functions $f$ and $g$).
Then I have that: $$f(g(Q,X),Y) = f(XQ + QX, Y) = XQY + QXY$$ Then, using matrix calculus (hoping there are no error!), I have that: $$ \frac{\partial t(Q,X,Y)}{\partial X} = QY + YQ\\
\frac{\partial t(Q,X,Y)}{\partial Y} = XQ + QX$$ I can easily compute the result if I know the form of $f$ and $g$. Notice that the derivatives I obtained are in a matrix form. 
But actually I need to deal with generic functions. And for this reason I need to use the chain rule.
The problem is that the chain rule formulas I know are helpful to derive the derivative with respect to a certain element of the matrix $X$ (or $Y$). In this case, I'm not able to have a matrix form of the derivatives. So, my question is... there is a chain rule formula I'm missing which let me describe these derivatives in a matrix form? * Addition 2 * The chain rule formulas that I know are reported here http://en.wikipedia.org/wiki/Matrix_calculus#Scalar-by-matrix_identities (see the 7th row of the table)","['matrices', 'derivatives']"
260716,Show the function $x_1\sin(1/x_2)+x_2\sin(1/x_1)$ is continuous everywhere,"I am learning continuous function, please help me.
Show that the following function is continuous everywhere:
$\vec{F}(x_1,x_2)=x_1\sin{\left(\frac{1}{x_2}\right)}+x_2\sin{\left(\frac{1}{x_1}\right)}$ if $x_1x_2\neq 0$
and $\vec{F}(x_1,x_2)=0$ if $x_1x_2 = 0$","['multivariable-calculus', 'continuity']"
260728,Why uniform closure $\mathscr{B}$ of an algebra $\mathscr{A}$ of bounded complex functions is uniformly closed?,"Let $\mathscr{A}$ be an algebra of bounded complex functions. (Or if necessary, continuous and domain of functions is compact) Definition: $\mathscr{B}$ is uniformly closed iff $f\in\mathscr{B}$ whenever $f_n\in \mathscr{B} (n=1,2,\cdot)$ and $f_n\rightarrow f$ uniformly. $\mathscr{B}$ is the uniform closure of $\mathscr{A}$ iff $\mathscr{B}$ is the set of all functions which are limits of uniformly convergent sequences of members of $\mathscr{A}$. ============ Let $\mathscr{B}$ be a uniform closure of $\mathscr{A}$. How do i prove that $\mathscr{B}$ is uniformly closed in ZF? Does Stone-Weierstrass theorem require choice since it is critical to prove Stone-Weierstrass Theorem?","['real-analysis', 'axiom-of-choice']"
260735,A quick question about proof of Bukovský-Hechler,"The following is an exercise in Just/Weese (page 179), Question 1: can you tell me if I got it right? Thank you! Question 2: Shouldn't it be equality rather than less equals in $\mu = \sum_{\alpha < \kappa} |\alpha|^\lambda \color{red}{\le}  |\alpha_0|^\lambda \cdot \kappa$? Assume $|\alpha_0|^\lambda < \kappa$. Then $|\alpha|^\lambda < \kappa$ for all $\alpha < \kappa$. Then $\displaystyle \sum_{\alpha < \kappa}|\alpha|^\lambda = |\alpha_0|^\lambda \cdot \kappa = \kappa$. We know that if $\kappa$ is an infinite cardinal then $\kappa$ is singular if and only if there exists an $\alpha < \kappa$ and a set  of cardinals $\{ \kappa_\xi :  \xi < \alpha \}$ such that $\kappa_\xi < \kappa$ for all $\xi < \alpha$ and $\kappa = \sum_{\xi < \alpha} \kappa_\xi$. Hence if $|\alpha_0|^\lambda < \kappa$, then $\kappa$ must be regular since there is no $\gamma < \kappa$ with $\sum_{\alpha < \gamma} |\alpha|^\lambda = |\alpha_0|^\lambda \cdot \gamma = \kappa$. But by assumption, $\kappa$ is singular.","['cardinals', 'elementary-set-theory']"
260766,Divergence of the sequence $\sin(n)$ [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: Prove the divergence of the sequence $(\sin(n))_{n=1}^\infty$. How can I show that the sequence
$$
 a_n = \sin(n)
$$
is divergent? I tried to show that $\sin(n+1) - \sin(n)$ get always larger than some constant, but I did not succeeded.","['trigonometry', 'analysis']"
260775,Convergence\Divergence of $\sum_{k=2}^{\infty} \frac{\cos(\ln(\ln k))}{\ln k}$,"Test for convergence the series 
$$\sum_{k=2}^{\infty} \frac{\cos(\ln(\ln k))}{\ln k}$$
My first thought was related to the use of the integral test, but things seem hard. Could we resort here to some nicers tools? Thanks","['sequences-and-series', 'convergence-divergence', 'calculus', 'real-analysis', 'divergent-series']"
260778,Matrix Representation of Integer Series,"I would like some feedback regarding this process or the meaning of
this process. Let say that I have a discrete time series: S = [1 2 3 4 5] And that I represent this serie by a stochastic matrix M (5x3): 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 This stochastic matrix come from the Matrix N (6x3), such that M(1,1:3) = N(2,1:3) - N(1,2:3) M(2,1:3) = N(3,1:3) - N(2,2:3) M(3,1:3) = N(4,1:3) - N(3,2:3) M(4,1:3) = N(5,1:3) - N(4,2:3) M(5,1:3) = N(6,1:3) - N(5,2:3) With N: 0 0 0 0 0 1 0 1 1 1 1 1 1 1 2 1 2 2 With Sum of Columns: 3 5 7 Now if you multiply S x M, the resulting vector is: 3 7 5 Note that this does not work for all matrices! e.g. 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 from 0 0 0 0 0 1 0 0 2 0 1 2 1 1 2 1 1 3 With Sum of Columns: 2 3 10 And if you multiply S x M, the resulting vector is: 4 3 8 So, if some of you could give me informations regarding
the meaning of this process, if it make sense, it it
mean something in mathematics! Thanks in advance","['permutations', 'sequences-and-series', 'discrete-mathematics', 'cyclic-groups', 'matrices']"
260794,Stone-Čech via $C_b(X)\cong C(\beta X)$,"I am having some trouble constructing the Stone-Čech compactification of a locally compact Hausdorff space $X$ using theory of $C^*$-algebras. I did some search but could not find a good answer on this. Let's focus on the case $X=\mathbb{R}$. The space of bounded complex-valued functions $C_b(\mathbb{R})$ is a commutative unital $C^*$-algebra hence $C_b(\mathbb{R})\cong C(\mathcal{M})$, where $\mathcal{M}$ is the maximal ideal space, which is compact and Hausdorff. It should be the case that $\mathcal{M}\cong\beta\mathbb{R}$, and it is not difficult to show that by identify $t\in\mathbb{R}$ with the evaluation at $t$, we have a homeomorphism between $\mathbb{R}$ and a subspace of $\mathcal{M}$. But we still need to show this subspace is dense in $\mathcal{M}$. This is where I am having troubles (and I guess this is the whole point of the proof). Can someone give a hint? Thanks!","['general-topology', 'banach-algebras', 'functional-analysis']"
260805,boundedness of an operator,"Define $T: L^2(\mathbb{R})\to L^2(\mathbb{R})$ by $(Tf)(x)=\int_{\mathbb{R}}\frac{f(y)}{1+|x|+|y|}dy$. Is this operator bounded? If it is, then is it also compact? I got stuck in simply applying Cauchy-Schwarz inequality to show it is bounded. Any hint on this problem? Thanks in advance! Remark: 1, I have tried to set $f_n(y)=\frac{1}{\sqrt{n}}1_{[0,n]}$, then $\{||Tf_n||_2\} $ are uniformly bounded, so I guess $T$ is a bounded operator. More details as following: As above, take $f_n(y)=\frac{1}{\sqrt{n}}1_{[0,n]}$, then $(Tf_n)(x)=\frac{1}{\sqrt{n}}\int_0^n\frac{1}{1+|x|+y}dy$, so $||Tf_n||_2^2=\int_{\mathbb{R}^1}\frac{1}{n}|\int_0^n\frac{1}{1+|x|+y}dy|^2dx=\int_{\mathbb{R}^1}\frac{1}{n}(ln(1+|x|+y)|_{y=0}^{y=n})^2dx=\int_{\mathbb{R}^1}\frac{1}{n}(ln(\frac{1+|x|+n}{1+|x|}))^2dx=\frac{2}{n}\int_0^{\infty}(ln(\frac{1+x+n}{1+x}))^2dx=\frac{2}{n}\int_1^{\infty}(ln(1+\frac{n}{y}))^2dy\overset{z=\frac{n}{y}}{=}2\int_{0}^n\frac{ln(1+z)^2}{z^2}dz\leq 2\int_{0}^{\infty}\frac{ln(1+z)^2}{z^2}dz$, while since $z\to 0, \frac{ln(1+z)^2}{z^2}\to 1; z\to\infty, \frac{ln(1+z)^2}{z^2}\leq \frac{1}{z^{1+\epsilon}}, \forall 0<\epsilon<1$, so value of this integral is finite. 2, Note that the kernel $K(x,y)=\frac{1}{1+|x|+|y|}$ appearing here does not belong to $L^2(\mathbb{R})$; otherwise, all the problems can be solved, for example, see Hilbert-Schmidt operator","['operator-theory', 'functional-analysis', 'real-analysis']"
260809,Show $ 1 + a + a^2 + a^3 + \ldots + a^n = \frac{a^{n+1}-1}{a-1}$ by induction,"How can we show by mathematical induction that the following holds for $ n \ge 0$ and $a \ne 1$? $$ 1 + a + a^2 + a^3 + \ldots + a^n = \frac{a^{n+1}-1}{a-1}$$ I understand the principle of mathematical induction, but I've no idea how to apply it here. 
I know in general I have to prove it for $n = 1$ and then assume $n = k$ is correct. Then prove $n = k+1$ is true.
But what about $a$? I've watched a load of YouTube videos on the subject, and I've read a few questions here but it's not helping. The videos make sense while I'm watching them, but I don't know how to apply it. 
This question appeared on my discrete math exam last week. I did not do well. I think I'm missing something fundamental in my understanding of this subject.","['induction', 'discrete-mathematics']"
260817,Analytic function in the punctured plane satisfying $|f(z)| \leq \sqrt{|z|} + \frac{1}{\sqrt{z}}$ is constant,I saw this question on my book (Complex Analysis/Donald & Newman): Let $f(z)$ be an analytic function in the punctured plane $\{ z \mid z \neq 0 \}$ and assume that $|f(z)| \leq \sqrt{|z|} + \frac{1}{\sqrt{|z|}}$. Show that $f$ is constant. How I can do it by Cauchy's formula?!,['complex-analysis']
260820,Solve $2x\equiv 18\ (\operatorname{mod} 50)$,How can we solve $2x\equiv 18\ (\operatorname{mod} 50)$? I'm not sure what to do when the item being modded on the right is not $1$.,['discrete-mathematics']
260841,How to implement birthday paradox continuation of elliptic curve factorization algorithm,"I have already implemented Lenstra's algorithm for factoring integers using elliptic curves; it is shown below, or you can run it at http://ideone.com/QEDmMY . Beware that my code is optimized for simplicity and clarity, not for speed. I would like to implement the second stage of elliptic curve factorization using the birthday paradox continuation, which I read about in Richard Brent's paper ""Some Integer Factorization Algorithms Using Elliptic Curves."" However, I don't understand Brent's algorithm, or perhaps just his notation. In Section 6, what is $Q_j^2$ in the definition of $Q_{j+1}$? Likewise, what is $Q_j^2 * Q$? Since $Q$ is just a point on the elliptic curve, how can it be squared or multiplied by another point? And how is $r$ computed? Brent discusses $r$ but never defines it. Many thanks, Phil # lenstra's algorithm

from random import randint
from fractions import gcd

def primes(n):
    b, p, ps = [True] * (n+1), 2, []
    for p in xrange(2, n+1):
        if b[p]:
            ps.append(p)
            for i in xrange(p, n+1, p):
                b[i] = False
    return ps

def bezout(a, b):
    if b == 0: return 1, 0, a
    q, r = divmod(a, b)
    x, y, g = bezout(b, r)
    return y, x-q*y, g

def add(p, q, a, b, m):
    if p[2] == 0: return q
    if q[2] == 0: return p
    if p[0] == q[0]:
        if (p[1] + q[1]) % m == 0:
            return 0, 1, 0 # infinity
        n = (3 * p[0] * p[0] + a) % m
        d = (2 * p[1]) % m
    else:
        n = (q[1] - p[1]) % m
        d = (q[0] - p[0]) % m
    x, y, g = bezout(d, m)
    if g > 1: return 0, 0, d # failure
    z = (n*x*n*x - p[0] - q[0]) % m
    return z, (n * x * (p[0] - z) - p[1]) % m, 1

def mul(k, p, a, b, m):
    r = (0,1,0)
    while k > 0:
        if p[2] > 1:
            return p
        if k % 2 == 1:
            r = add(p, r, a, b, m)
        k = k // 2
        p = add(p, p, a, b, m)
    return r

def lenstra(n, limit):
    g = n
    while g == n:
        q = randint(0, n-1), randint(0, n-1), 1
        a = randint(0, n-1)
        b = (q[1]*q[1] - q[0]*q[0]*q[0] - a*q[0]) % n
        g = gcd(4*a*a*a + 27*b*b, n)
    if g > 1: return g # lucky factor
    for p in primes(limit):
        pp = p
        while pp < limit:
            q = mul(p, q, a, b, n)
            if q[2] > 1:
                return gcd(q[2], n)
            pp = p * pp
    return False","['prime-numbers', 'factoring', 'number-theory']"
260842,The maximum of $|f|+|g|$ is in the boundary,"$f$ and $g$ are holomorphic functions in $G \subset \mathbb C$ and continuous on the boundary of $G$ . Prove that $|f| + |g|$ gets its maximum in the boundary of $G$ . I know this has something to do with the maximum principle, but I'd be happy for a hint.",['complex-analysis']
260849,Lifting étale sections,"Let $X$ be a scheme, $F$ and $G$ be sheaves in groups on $X$ for the étale topology and $f:F\rightarrow G$ a morphism of group sheaves. Assume that there exists an étale covering $i:U\rightarrow X$ such that the pullback $i^{*}f:i^{*}F\rightarrow i^{*}G$ admits a section, can I lift this section to a section of $f:F\rightarrow G$?","['arithmetic', 'algebraic-geometry']"
260855,Suppose the function $f:\mathbb R \rightarrow \mathbb R$ has left and right derivatives at $0$.,"I have been trying to solve the following problem: Suppose the function $f:\mathbb R \rightarrow \mathbb R$ has left and right derivatives at $0$.Then at $x=0$, which of the following options is correct? (a)$f$ must be continuous but may not be differentiable, (b)$f$ need not be continuous but must be left continuous  or right continuous, (c)$f$ must be differentiable, (d)if $f$ is continuous then $f$ must be differentiable. Could someone point me in the right direction.Thanks in advance for your time.","['continuity', 'derivatives', 'real-analysis', 'analysis']"
260864,How does one parameterize the surface formed by a *real paper* Möbius strip?,"Here is a picture of a Möbius strip, made out of some thick green paper: I want to know either an explicit parametrization, or a description of a process to find the shape formed by this strip, as it appears in the picture. Now before you jump up and declare, ""That's easy! It's just $\left(\left[1+u \cos \frac \theta2\right]\cos \theta,\left[1+u\cos\frac \theta2\right]\sin \theta,u\sin \frac \theta2\right)$ for $u\in\left[-\frac12\!,\frac12\right]$ , $\theta\in[0,2\pi)$ !"" Understand that this parametrization misses some features of the picture; specifically, if you draw a line down the center of the strip, you get a circle, but the one in the picture is a kidney-bean shape, and non-planar. What equations would I need to solve to get a ""minimum-energy"" curve of a piece of planar paper which is being topologically constrained like this? Is it even true that the surface has zero curvature? (When I ""reasonably"" bend a piece of paper into a smooth shape, will it have zero curvature across the entire surface, or does some of paper's resistance correspond to my imparting non-zero curvature to the surface?) This question is thus primarily concerned with the equilibrium shapes formed by paper and paper-like objects (analogous to minimal surface theory in relation to soap-bubble models). Anyone know references for this topic?","['ordinary-differential-equations', 'physics', 'minimal-surfaces', 'reference-request', 'differential-topology']"
260877,Useless math that became useful,I'm writing an article on Lychrel numbers and some people pointed out that this is completely useless. My idea is to amend my article with some theories that seemed useless when they are created but found use after some time. I came with some ideas like the Turing machine but I think I'm not grasping the right examples. Can someone point me some theories that seemed like the Lychrel numbers and then become 'useful'?,"['applications', 'number-theory', 'education', 'soft-question', 'recreational-mathematics']"
260902,Shortest triangulation is in general not a Delaunay triangulation,Let $P$ be a set of points. The minimal triangulation of $P$ is a triangulation $T$ of the points in $P$ such that the total length of the edges in $T$ is the smallest possible amongst all possible triangulations of $P.$ I am looking for the smallest (and most concise) example such that the Delaunay triangulation of $P$ is not equal to the minimal triangulation of $P.$ Anyone happens to have a good example of this?,"['geometry', 'computational-geometry', 'examples-counterexamples']"
260924,How is it that the derivative operator is a closed linear operator?,"By definition , if the derivative operator $D:C^1[-1,1]\to C^1[-1,1]$ is closed, then it should be the case that, given any sequence $\{x_n\}$ in $C^1[-1,1]$, and given that $x_n\to x$ as $n\to\infty$ for some $x\in C[-1,1]$, we should conclude that $x$ is in $C^1[-1,1]$. But it seems that this is not the case. Consider $x_n(t)=\sqrt{n^{-2}+x^2}$, clearly $x_n$ are in $C^1[-1,1]$, and we know that $x_n\to x(t)=|x|$, which is not in $C^1[-1,1]$, and doesn't it show that $D$ is not a closed linear operator?",['functional-analysis']
