question_id,title,body,tags
3840671,Spectral decomposition theorem,"I'm reviewing the spectral decomposition theorem. If $Y$ is a symmetric matrix, then $Y$ can be decomposed as $Y=Q\Lambda Q'$ , where the columns of $Q$ are the eigenvectors of $Y$ and $\Lambda$ is a diagonal matrix with the diagonal composed of the eigenvalues ​​of $Y$ . From some part of this theorem can it be concluded that $Q$ is an orthogonal matrix? I know that the eigenvectors of $Y$ are orthogonal, so can it be concluded that the matrix $Q$ is orthogonal?","['linear-algebra', 'matrix-decomposition']"
3840699,What is the best method to estimate a definite integral from given samples of the integrand?,"I need to calculate something of the form \begin{equation}
\int_{D} f(\mathbf{x}) d\mathbf{x}
\end{equation} with $D \subseteq \mathbb{R^2}$ , but I only have available $f(\mathbf{x})$ at given samples of points in $D$ . What do you suggest to do the estimate? For example, I think Monte Carlo integration doesn't apply directly because I can't evaluate $f(\mathbf{x})$ at arbitrary $\mathbf{x}$ . Maybe it could be some kind of combination of Monte Carlo and interpolation?","['integration', 'statistics', 'estimation', 'numerical-methods']"
3840704,What exactly do systems of equations represent?,"Systems of equations are taught pretty early in American curriculum. We are taught methods of substitution and methods of elimination in order to solve them. We are taught how to use matrices or graphs as alternative strategies to encode/visualize them. There are linear systems of equations...there are non-linear systems of equations...and there are systems of equations with 1 or many variables. However, to this day, I still do not really understand what systems of equations are . I've tried to find an abstract interpretation of systems of equations but without much success. I am very interested in figuring out this ""systems of equations abstraction"" because there are canonical statements (e.g. the classic ""You need as many equations as variables to find a solution"") that I would very much like to prove. I've tried myself to come up with some semblance of an abstraction but I have not made much progress. I will illustrate the case for one equation with one variable and two equations with two variables (which is where I run in to trouble). One Equation - One Variable Consider the purely arbitrary equation: $$a = b +\alpha x \ \text{ where}\  \alpha \neq 0$$ The effort to solve this equation can be rephrased as ""Find me the $x$ that maps to $a$ through the function $f(x) = b + \alpha x$ ."" In effect, therefore, this question is one requiring that we find the inverse function $f^{-1}$ that, when $a$ is given as input, $x$ will be output. Solving for $x$ by virtue of substracting $b$ from both sides and dividing both sides by $\alpha$ effectively amounts to determining the inverse function such that: $f^{-1}(x')=\frac{x' -b}{\alpha}$ ...for future purposes, also note that this can be denoted as $f^{-1}\big(f(x)\big)=\frac{f(x) -b}{\alpha}$ . Plugging in $a$ for $x'$ we arrive at the solution to this equation, which is $f^{-1}(a)=\frac{a-b}{\alpha}$ . So far, so good. Two Equations - Two Variables Consider the following two arbitrary equations of two variables: $$a=b+\alpha x + \beta y \ \text{ where}\  \alpha, \beta \neq 0$$ $$c=d +\gamma x + \delta y \ \text{ where}\  \gamma, \delta\neq 0$$ Following the same logic of the ""One Equation - One Variable"" section, solving for $x$ and $y$ can be viewed as constructing the inverse functions for the two above equations, which can be recast as specific instances of: $$g\big( (x,y) \big) = b+\alpha x + \beta y$$ $$h \big ( (x,y) \big ) = d +\gamma x + \delta y$$ As to how one solves for these inverses, I have not the faintest clue. Obviously, we could revert to the standard methods of substitution and arrive at the following bulky solutions: $$ y = \frac{\alpha \Big ( h \big((x,y)\big) -d \Big) -\gamma g\big( (x,y) \big)+\gamma b}{\delta \alpha - \beta \gamma}$$ and $$ x = \frac{g\big( (x,y) \big) -b - \beta y}{\alpha}$$ However, these are not inverses of the functions $g$ and $h$ . In fact...I don't really even know WHAT these equations represent. If you were to plug in the value of $y$ in the final equation for $x$ (I omitted that for brevity), you can see that the $y$ equation and the $x$ equation both have $g\big ( (x,y) \big)$ and $h \big ( (x,y) \big)$ in them ...so these equations are inverse-like . That is to say, determining $(x,y)$ requires information from both $g$ and $h$ , which provides the first clues as to how one might prove, ""You need as many equations as variables to find a solution."" Linking this back to the ""One Equation - One Variable"" section, recall that $f^{-1}\big(f(x)\big)=x = \frac{f(x)-b}{\alpha}$ depends on only one function in order to solve. Hopefully I did not completely botch this question and was able to sufficiently convey what I am after. Any insights would be greatly appreciated. Cheers~","['algebra-precalculus', 'systems-of-equations']"
3840747,Why is the power set monoid stable under the inclusion order?,"Background: On page 14 of Lang's Algebra , Lang makes the case, given subgroup $H$ of $G$ , that the condition $xH \subset Hx$ for all $x \in G$ is equivalent to $xHx^{-1} \subset H$ and that both are equivalent to the normal definition(s) of a normal subgroup. Below is an excerpt from George Bergman's Companion to Lang's Algebra . Excerpt: Discussion: I think I can see why the power set of a group or monoid, together with subset multiplication, forms a monoid. What I do not understand is why this is stable under the order relation of the power set. In other words, I think Bergman is saying the following: given monoid $M$ and subset multiplication $\bullet$ , $\big( \mathcal P(M), \bullet \big)$ forms a monoid, and furthermore, if $A, B, C \in \mathcal P(M)$ and $A \subset B$ , then $AC \subset BC$ . It's not clear to me why this is true. The way I justify the equivalence of $xH \subset Hx$ and $xHx^{-1} \subset H$ is as follows. Begin with the former expression and pick some $h \in H$ . The expression implies that $xh = h' x$ for some $h' \in H$ . Therefore $xhx^{-1} = h'$ which implies that any element from the set $xHx^{-1}$ is an element of $H$ , and thus $xHx^{-1} \subset H$ as desired. I appreciate any help.","['monoid', 'proof-explanation', 'group-theory', 'abstract-algebra']"
3840780,Prove that the diophantine equation $(xz+1)(yz+1)=az^{k}+1$ has infinitely many solutions in positive integers.,"Given two positive integers $a$ and $k>3$ : From experimental data, it appears the diophantine equation $(xz+1)(yz+1)=az^{k}+1$ has infinitely many solutions in positive integers $x,y, z$ . To motivate the question, it can easily be shown that if $k <3$ ,  the given diophantine equation has no solutions in positive integers $x, y ,z$ with $z>a$ . Proof: $(xz+1)(yz+1)=az^{k}+1$ may be simplified to $xyz^{2}+(x+y)z=az^{k}$ . If $k=1$ , this reduces to $xyz+x+y=a$ . Its clear that $a>z$ therefore there are no positive integral solutions in $x$ and $y$ when $z>a$ . if $k=2$ , we have the reduced equation $xyz+x+y=az$ . We have $z$ | $x+y$ , $z \le(x+y) \le xy$ .  Therefore $LHS=xyz+x+y>z^{2}$ . Because $RHS=az$ , we must have $a>z$ thus there are no solutions in positive integers $x ,y$ when $z>a$ . I would like to prove that given two positive integers $a$ and $k>3 $ , the diophantine equation $(xz+1)(yz+1)=az^{k}+1$ has  infinitely many positive integer solutions $x, y, z$ . I do not know how to start the proof.","['elementary-number-theory', 'diophantine-equations', 'real-analysis']"
3840796,Is the axiom of choice necessary to refer to a set $S$ if we already know that $S$ exists?,"Consider the equivalence relation on $[0,1]$ where $$x \sim y \iff x - y \in \mathbb{Q}.$$ Fix a set $S$ which contains exactly one representative from each equivalence class of the relation. It is well-known that constructing such a set requires the axiom of choice. However, I don't have an intuition for what breaks down if the axiom of choice is not assumed. If I don't assume the axiom of choice, what happens to $S$ ? Does it cease to exist? If not, then surely $S$ is some subset of $[0,1]$ , whether or not we invoke the axiom of choice, so why can't I refer to $S$ in a proof without choice, in the same way that I would refer to any other subset of $S$ ? I haven't studied set theory formally, so please excuse my ignorance.",['elementary-set-theory']
3840839,What types of integrals are these?,"What kind of integral is this? It pops up in Pattern Recognition and Machine Learning, Chapter 1.2, when the author is talking about multivariate probability densities. $$ \int p(\vec{x}) d\vec{x} = 1$$ The author states ""the integral is taken over the whole of $\vec{x}$ space."" I've heard of line integrals of vector fields and surface integrals of vector fields, are there other types of weird integrals that pop up where you are taking the integral with respect to a vector or matrix for example? Another integral (1.45) pops up again in Chapter 1.2 when the author is talking about Bayes theorem, the posterior, likelihood and prior. $$p(D) = \int p(D|\vec{w})p(\vec{w}) d\vec{w} $$ Is this different to the previous integral?","['integration', 'statistics', 'probability']"
3840841,$\lim_{x\rightarrow 0}(\ln x^{2})^{2x}$,"$\lim_{x\rightarrow 0}(\ln x^{2})^{2x}$ I felt the only approach to find the limits is taking log on both sides $y=\lim_{x\rightarrow 0}(\ln x^{2})^{2x}$ $\ln y=\lim_{x\rightarrow 0}2x \ln(\ln x^{2})$ Near $0$ , $\ln(\ln x^{2})$ will be $\ln(- \infty)$ . which is undefined. So shall i conclude that the limit does not exist ?","['limits', 'limits-without-lhopital']"
3840849,Prove that $\frac{\sin^22\alpha}{\sin(2\alpha+\beta)}=\frac{\sin^22\beta}{\sin(2\beta+\alpha)}$ is true only for $\alpha=\beta$,"Interesting trigonometric equation showed up while I was trying to solve a geometry problem: $$\frac{\sin^22\alpha}{\sin(2\alpha+\beta)}=\frac{\sin^22\beta}{\sin(2\beta+\alpha)}\tag{1}$$ ...under condition that $\alpha,\beta$ are angles of a triangle. The trick is to show that (1) is true only in trivial case $\alpha=\beta$ . I have tried to prove it in a brute-force style by getting rid of fractions and by expanding everything that I could expand. But the computation proved to be messy and I was not patiet enough to bring it to any conclusion. Any ideas how to tackle this kind of problem?","['euclidean-geometry', 'geometry', 'examples-counterexamples', 'triangles', 'trigonometry']"
3841001,Stopping Probabilities for Random Walk with Drift,"[EDIT] After the comments and answer I understood that my formation of the problem is incorrect. However I'm still interested in a stochastic solution to the original riddle. Please skip to the ""Background"" part of this question. And thanks for setting a bounty on this question!! Let $X_1,X_2,...$ be independent and identically distributed random variable. $X_i = 2$ or $X_i=-1$ each with 50% probability. And let $S_n = X_1+\cdots+ X_n$ be the associated random walk. So we can think of this as a random walk with drift $\mu = 0.5$ and step-length = $1.5$ For a given constant $m$ , suppose we define a stopping rule to stop when $S_n \leq -m$ or $S_n \geq K$ . How do we find $K$ , such that the probability of stopping at $S_n \geq K$ is equal to the probability of stopping at $S_n \leq -m$ ? When there is no drift the solution is trivial $K = m$ . I suspect this little modification should be a classical problem in stochastic process too? The solution is apparently $K \sim O(m^2)$ , but I'm looking for a stochastic explanation. see the background below. Background: I found this riddle and its solution . I reproduce the riddle here: At a pivotal moment in an epic battle between the living and the dead,
the Night King, head of the army of the dead, raises all the fallen
(formerly) living soldiers to join his ranks. This ability obviously
presents a huge military advantage, but how big an advantage exactly? Forget the Battle of Winterfell and model our battle as follows. Each
army lines up single file, facing the other army. One soldier steps
forward from each line and the pair duels — half the time the living
soldier wins, half the time the dead soldier wins. If the living
soldier wins, he goes to the back of his army’s line, and the dead
soldier is out (the living army uses dragonglass weapons, so the dead
soldier is dead forever this time). If the dead soldier wins, he goes
to the back of their army’s line, but this time the (formerly) living
soldier joins him there. (Reanimation is instantaneous for this Night
King.) The battle continues until one army is entirely eliminated. What starting sizes of the armies, living and dead, give each army a
50-50 chance of winning? So we can think of this riddle as above problem. Let $m$ be the size of dead army. Let $S_i$ be (current  difference in army sizes - initial difference of army sizes). For each step $S_i$ increments by either −1 or 2. If $S_n=−m$ , that means comparing to the initial state, the dead army is down by $−m$ , the battle ended. If $S_n=K$ , that means comparing to the initial state, the dead army is up by $K$ , the battle ended. The solution is apparently $K \sim O(m^2)$ . The combinatorial argument is nice, but the paper offers no stochastic explanation, which I am truly curious about. I am fine with an approximation solution. So if we replace $X_i$ with a normal random variable with non-zero mean is fine to me too, if that helps with the estimation. But I think for a large enough $n$ this probably doesn't matter anyways.","['random-walk', 'stochastic-processes', 'martingales', 'probability-theory', 'probability']"
3841054,Sum of resistors in parallel is smaller than resistance of smallest resistor,"The motivation of this question is that when you connect two or more resistors in parallel, then the total resistance is smaller than each of the resistors. So in general, I guess I want to prove that given a set of numbers $\{a, b, c, \cdots, n\}$ , $$\left(\frac{1}{a} + \frac{1}{b} + \frac{1}{c} + \cdots + \frac{1}{n}\right)^{-1} \leq \min\{a, b, c, \cdots, n\}$$ I'm not sure if the inequality can be strict and I am guessing that the numbers in the set must also be positive. For the case of two numbers, we have $$\left(\frac{1}{a} + \frac{1}{b}\right)^{-1} = \frac{ab}{a+b}$$ but it's not even obvious to me why this should be less than or equal to $a$ and $b$ .",['algebra-precalculus']
3841140,Meaning of curly brackets in $x\mapsto \{x\}$ vs. $x\mapsto x$?,"I have the following: The mapping $f: A \rightarrow B$ is defined by $x\mapsto \{x\}$ . I understand the meaning of the notation $f:A \rightarrow B$ . For instance, if the sets are $A=\mathbb R$ and $B=\mathbb R$ , we can have the function $ f:\mathbb R \rightarrow \mathbb R$ , defined by $x\mapsto f(x)=x$ . So if $x=4$ we have $f(4)=4$ , etc. But what is the meaning of the curly brackets around $x$ ? I.e. what is the difference between $$
f: A \rightarrow B, \quad x\mapsto \{x\} \tag 1
$$ and $$
f: A \rightarrow B, \quad x\mapsto x \tag 2
$$ ? Update: The notation $\{x\}$ is from the proof of Cantor's theorem . Here the co-domain is the power set. I'm not interested in this specific proof, so I tried to simplify my question because I'm just stuck at $\{x\}$ . Does my question still make sense if the co-domain isn't a power set?","['elementary-set-theory', 'calculus', 'functions', 'notation']"
3841234,Pairing higher forms of a Lie group with the universal enveloping algebra,"For a (compact) Lie group $G$ we have a pairing between its cotangent space $T^*$ and its Lie algebra $\frak{g}$ . What happens for higher forms? Do we have a pairing between $\Lambda(T^*)$ , the exterior algebra of $T^*$ , and some subalgebra of the universal enveloping algebra $U(\frak{g})$ ?","['lie-algebras', 'algebraic-geometry', 'differential-graded-algebras', 'lie-groups', 'differential-geometry']"
3841283,Extension of Definition of Concavity,"Question Suppose that the graph of a function $f$ is concave up on an open interval $I$ . Show that, for any $a, b \in I$ , where $a < b$ and $0 < \lambda < 1$ , $$(1 - \lambda)f(a) + \lambda f(b) > f((1 - \lambda)a + \lambda b).$$ My working From the definition of a function being concave up, $$f(b) - f(a) > (b - a)f'(a).$$ When $b = (1 - \lambda)a + \lambda b$ , $$f((1 - \lambda)a + \lambda b) - f(a) > ((1 - \lambda)a + \lambda b - a)f'(a)$$ $$\implies f((1 - \lambda)a + \lambda b) - f(a) > \lambda (b - a)f'(a)$$ This is where I am currently stuck at. I have a hunch that I am supposed to use the definition once more by substituting another set of values for $b$ and $a$ in order to get rid of the $f'(a)$ , but I cannot see what they are. Any intuitions will be greatly appreciated!","['calculus', 'derivatives', 'real-analysis']"
3841299,Grassmannian is a manifold in a specific case the $2$-planes in $\mathbb{R}^4$,"I want to show that Grassmannian is a manifold in a specific case the $2$ -planes in $\mathbb{R}^4$ . I'm in the following context: $G(2,4)$ are the $2$ -planes in $\mathbb{R}^4$ that we can identify with an matrix of two vectors that generate the plane (they are not unique). Considering $L(2,4)=\{A \in M_{4 \times 2 } : \text{rank} A =2\}$ and equivalence relation $A \sim B $ iff exist $g \in Gl_2(\mathbb{R})$ such that $B=Ag$ . $$G(2,4) \cong L(2,4)/\sim$$ Given $A \in M_{4 \times2}$ define $A_{ij}$ submatrix of $A$ eliminating rows $i$ and $j$ of $A$ and $V_{ij} = \{ A \in L(2,4)| A_{ij} \text{ is invertible}\}$ . We can see that $V_{ij}$ is open in $L(2,4)$ . Therefore $U_{ij}=\pi(V_{ij})$ is open in $G(2,4)$ , where $\pi$ is a natural projection in quotient. In this context we define the possible charts $(U_{ij}, \phi_{ij})$ , $\phi_{ij}: U_{ij} \to \mathbb{R}^4$ $$\phi_{ij}([A])=A_{kl}A_{ij}^{-1}$$ where $\{1,2,3,4\}=\{i,j,k,l\}$ . I'm having a hard time showing that it's a homeomorphism","['submanifold', 'grassmannian', 'manifolds', 'general-topology', 'differential-geometry']"
3841405,Show that $\lim\limits_{n\to\infty}n\cos(n)$ is divergent by definition of limit.,"I am trying to split it into two cases, (1) $\cos(n)\geq 0$ and (2) $\cos(n)<0$ . Then for (1), I would like to show the limit diverges to $+\infty$ , and $-\infty$ for (2). Then I tried to formulate the definition of limit diverging to $\pm\infty$ , by using the Archimedean property, but it seems not working. Here are the details: Say for (1): $n\in\left[ 2k\pi,\pi/4+2k\pi\right]\cup\left[ 3\pi/4+2k\pi, 2\pi+2k\pi\right]$ , and I want to get something like $$\forall M\in \mathbb{R},\exists K\in \mathbb{N} \text{ s.t. } n\cos(n) >M \text{ for every } n\geq K$$ Then by Archimedean property, $$ \forall M\in \mathbb{R}, \exists K=[N\cos(N)]\text{ s.t. } K>M$$ But $\cos(n)$ actually depends on $n$ . Say for $n\geq K$ , when $\cos(n)$ is very small, $n\cos(n)$ may not be greater than $M$ .  I am wondering if there is any other possible way to tackle this problem. Or is there any way to find two subsequences that converging to different limits? Since $n\in \mathbb{N}$ , I find it kinda subtle to deal with cosine.","['convergence-divergence', 'analysis', 'real-analysis']"
3841412,Geometrical difference between exact and inexact differentials,"Suppose we have a surface which has an explicit function $ z(x,y)$ then we can write the equation of surface around some point $ (x_o,y_o)$ as: $$ \Delta z = \frac{\partial z}{\partial x}_{y} \Delta x + \frac{ \partial z}{\partial y}_{x} \Delta y$$ The geometrical picture of this is as follows: Consider the $ z-x$ plane , in it we have a cross-section of the surface for a fixed $y$ value of $y_o$ , for this curve we can write the change in height as we move $\Delta x$ as $ (\frac{ \partial z}{\partial x})_y \Delta x$ and similarly we can argue for the idea behind addition second term in the sum by considering the $ z-y$ plane. Now, from my understanding if we have an inexact differential then it is an expression of form: $$ f(x,y) =  A dx + B dy$$ Then this can't really be considered as a differential because we can't find a surface given by an explicit function $z$ for which : $$ (\frac{\partial z}{\partial x})_y = A$$ and, $$ (\frac{ \partial z}{\partial y})_x = B$$ Now, we can figure out if a differential is exact or inexact by considering the mixed partial derivatives: $$ \frac{ \partial^2 z}{ \partial y \partial x} =  \frac{ \partial^2 z}{ \partial x \partial y}$$ If the above equality holds then it is exact and otherwise it isn't. An easy way that I got to think of this is by thinking of the differentials as the one forms of a vector field. Now, the vector field would only have a potential function if the differential is exact and this condition is equivalent to the vector field having zero curl. Now, what I don't understand is how the above idea above idea of curl, vector fields etc relate to the original idea of approximating the surface? What exactly is the nature of a surface given by an inexact differential, I mean I know a surface corresponding to it doesn't exist but what if we just 'welded' together all the approximation planes at different points $x$ and $y$ someway?","['multivariable-calculus', 'surfaces', 'differential-forms']"
3841461,When are definite integrals of continuous functions pairwise distinct?,"Let $f_1, \ldots, f_n : [0,1]\rightarrow\mathbb{R}_{>0}$ be a finite family of (positive) continuous functions. I was wondering about the weakest condition to impose on the $f_i$ so as to  guarantee that $$\tag{1}\exists\, \text 0\leq s < t \leq 1 \quad \text{ s.t. } \ \text{ the numbers} \quad q_i(s,t):=\int_s^t\!f_i(u)\,\mathrm{d}u, \ \ i=1,\ldots, n, \quad \text{ are pairwise distinct}? $$ (In case someone's in doubt: This is not a homework question.)","['integration', 'calculus', 'real-analysis']"
3841462,When we substitute variables do we compose functions?,"Suppose that we have the function $f(u)=2u+3$ and we define $u=2x$ . What of the below expressions are correct? $$f(u(x))=4x+3 \ \text{or} \ f(x)=4x+3 $$ Does the ""definition"" serves only as a substitution (shorthand) i.e. is "" $f$ "" still the same function or the composition of $f \circ u$ irrespective of the fact that we didn't write $u(x)=2x$ at first (abuse of notation)?","['notation', 'functions', 'change-of-variable']"
3841521,Which convex shapes are the hardest to bind together with a rubber band?,"Suppose I have a convex set $S\subset \mathbb{R}^2$ of unit area. In fact, I have two congruent copies of $S$ which I would like to bundle together with a rubber band, i.e. take the convex hull $C$ of a disjoint union of these two copies. Assuming I do this in an area-minimizing way, what is the worst case scenario for the area $A$ of the excess space $C\setminus(S\sqcup S')$ ? Which shapes attain or approach this upper bound? I can prove that one always has $A \le 1$ , by inscribing the set in a rectangle with its diameter spanning the long axis, placing the two rectangles side-to-side, and shaving the excess off of the outer end of each rectangle. It's easy to see that a circle forces $A=\frac{4-\pi}{\pi}\approx 0.2732$ . I believe that a hexagon yields $A=1/3$ , as realized by either of these configurations: Are there shapes that do worse? Better upper bounds on $A$ ? In the event that this question is resolved, what about the case of three dimensions or higher? In the case when both copies have the same orientation, and are simply translations of one another, I can prove $A$ is equal to the excess area of the smallest parallelogram containing $S$ . (As a consequence, better upper bounds on this excess area provide bounds on $A$ .) These questions seem adjacent to questions of packing density, as they approach such behavior in the limit as the number of copies ( $2$ here) goes to infinity. Update: Regular pentagons sharing an edge yield $A=\frac3{\sqrt{5}}-1\approx0.3416$ . I haven't proved this is optimal, though it's superior to meeting at a vertex; it's possible some better pentagon packing yields a lower $A$ (would love to see one if so!). Update 2020-10-28: After writing some code to compute excess areas for arbitrary convex polygons, I have become more optimistic that the pentagon (and some affine transformations thereof) are maximal for this problem; at the least, I do not think there are any local variations to the shape which make it harder to pack with itself. (I can also use this code to try various families of convex regions, and see if any exceed $0.3416$ - suggestions welcome.)","['convex-geometry', 'combinatorial-geometry', 'geometry']"
3841575,What does it mean for a polynomial to be the 'best' approximation of a function around a point?,"I think I understand how to use Taylor polynomials to approximate sine. For instance, if $$
\sin x \approx ax^2+bx+c
$$ and we want the approximation to be particularly accurate when $x$ is close to $0$ , then we could adopt the following approach. When $x=0$ , $\sin x = 0$ , and so $ax^2+bx+c=0$ , meaning that $c=0$ . Therefore we get $$
\sin x \approx ax^2+bx
$$ If we want the first derivatives to match, then $\frac{d}{dx}(ax^2+bx)$ should equal $1$ . Therefore, $b=1$ : $$
\sin x \approx ax^2+x
$$ Finally, if we want the second derivatives to match, then $\frac{d^2}{dx^2}(ax^2+x)$ should equal $0$ , and so $a=0$ . The small angle approximation for sine is $$
\sin x \approx x
$$ All of this makes sense to me. What I don't understand is when people try to put this on rigorous footing. I have often heard people say 'this shows that $x$ is the best quadratic approximation of $\sin x$ when $x$ is near to $0$ '. But what is meant by 'best', and 'near'? If the approximation suddenly became terrible when $x=0.5$ , then would this be considered close enough to $0$ for there to be a problem? It seems that there are formal definitions for these terms, but I don't know what they are.","['approximation', 'calculus', 'taylor-expansion', 'real-analysis']"
3841577,Prove $(A \cup B) \oplus A = A - B$,"I have to prove that $(A \cup B) \oplus A = A - B,$ where $\oplus$ is denoting the symmetric difference. I am trying to wrap my head around the problem and understand it but I am getting caught up on the fact that I can't properly visualize what $(A \cup B) \oplus A$ would look like. Any advice is appreciated. Edit: It is possible that this is a false proof and I would have to provide sets showing so.","['elementary-set-theory', 'discrete-mathematics']"
3841604,Solving cyclic infinite nested square roots of 2 as cosine functions,"Common infinite nested square roots of 2 are well known from school grade. We used to solve $$\sqrt{2+\sqrt{2+\sqrt{2+...}}}$$ as $x=\sqrt{2+x}$ which becomes $x^2 = x+2$ ==> $x^2-x-2=0$ The possible result is positive value which is $2$ . We also know similar negative infinite counterpart $$\sqrt{2-\sqrt{2-\sqrt{2-...}}}$$ as $x=\sqrt{2-x}$ which becomes $x^2 = 2-x$ ==> $x^2+x-2=0$ The possible result is positive value which is $1$ . Even we can solve alternate signs of nested radicals like $$ \sqrt{2-\sqrt{2+\sqrt{2-\sqrt{2+...}}}}$$ as $\sqrt5-1 \over 2$ and $$ \sqrt{2+\sqrt{2-\sqrt{2+\sqrt{2-...}}}}$$ as $\sqrt5+1 \over 2$ Now the question is, is it possible to solve infinite nested square roots of of 'm' positive signs and 'n' negative signs in the infinite nested square roots of 2 in cyclic manner Example 1 $$\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2-\sqrt{2-\sqrt{2+...}}}}}}$$ as [- - +] as infinite cycles Example 2 $$\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2+...}}}}}}}}$$ as [- - + +] as infinite cycles. To generalise the question how to solve $$\sqrt{2-\sqrt{2-...\text{m times} \sqrt{2+\sqrt{2+...\text{n times}}}}}$$ where $m, n \in {N}$ Is there anyway to solve?","['nested-radicals', 'trigonometry', 'sequences-and-series']"
3841637,Why doesn't trig substitution work for definite integrals?,"In the following example, I am attempting to find the area of a semicircle using calculus, which is obviously $\frac{\pi{r}^2}{2}$ . Effectively, I am trying to find $$\int_{-r}^r\sqrt{r^2-x^2}dx$$ Here goes:
Let $x=r\sin\theta$ : $$\frac{dx}{d\theta}=r\cos\theta\implies dx=r\cos\theta d\theta$$ When: $$x=r,  ~~~~\text{Then}~~~~\sin\theta=1\implies\theta=\frac{\pi}{2}$$ $$x=-r,  ~~~~\text{Then}~~~~\sin\theta=-1\implies\theta=-\frac{\pi}{2}$$ $$\therefore\int_{-r}^r\sqrt{r^2-x^2}dx=\int_{-\frac{\pi}{2}}^{\frac{\pi}{2}}r\cos\theta\sqrt{r^2-r^2\sin^2\theta} ~~d\theta$$ $$=\int_{-\frac{\pi}{2}}^{\frac{\pi}{2}}r^2\cos^2\theta~~d\theta=\frac{r^2}{2}\int_{-\frac{\pi}{2}}^{\frac{\pi}{2}}(1+\cos2\theta)~~d\theta=\frac{r^2}{2}\left[\theta+0.5\sin2\theta\right]_{-\frac{\pi}{2}}^{\frac{\pi}{2}}=\frac{r^2}{2}((\frac{\pi}{2}+0)-(-\frac{\pi}{2}-0))=\frac{\pi r^2}{2}$$ as required. BUT Back to the stage when I was working out the limits of the new integral with respect to $\theta$ . Let's say I wrote something like this: When: $$x=r,  ~~~~\text{Then}~~~~\sin\theta=1\implies\theta=\frac{5\pi}{2}$$ $$x=-r,  ~~~~\text{Then}~~~~\sin\theta=-1\implies\theta=-\frac{5\pi}{2}$$ Then , I would get an eventual answer of $$\frac{5\pi r^2}{2}$$ Where have I gone wrong? It seems to me that my logic is faultless, but the definite integral is simply ambiguous when using trig substitutions. This would apply to any integral involving trig substitutions; in short, can't all definite integrals computed using trig substitutions generate an incorrect answer? If so, isn't the maths of definite integrals faulty? Thanks for your help.","['integration', 'definite-integrals', 'fake-proofs', 'calculus', 'trigonometry']"
3841732,Mobile families of sets and pure subsets,"Exercise This is Bourbaki Theory of Sets Chapter 3 Section 4 Exercise 11, English version: Let $A$ be a set and let $\mathcal{R}$ be a subset of the set $\mathcal{F}(A)$ of finite subsets of $A$ . $\mathcal{R}$ is said to be mobile if it satisfies the following condition: (MO) If $X$ , $Y$ are two distinct elements of $\mathcal{R}$ and if $z\in X\cap Y$ , then there exists $Z\subseteq X\cap Y$ belonging to $\mathcal{R}$ such that $z\notin Z$ . A subset $P$ of $A$ is then said to be pure if it contains no set belonging to $\mathcal{R}$ . a) Show that every pure subset of $A$ is contained in a maximal pure subset of $A$ . b) Let $M$ ba a maximal pure subset of $A$ . Show that for each $x\in X\setminus M$ there exists a unique finite subset $E_{M}(x)$ of $M$ such that $E_{M}(x)\cup\{x\}\in\mathcal{R}$ . Moreover, if $y\in E_M(x)$ , the set $(M\cup\{x\})\setminus\{y\}$ is a maximal pure subset of $A$ . c) Let $M$ , $N$ be two maximal pure subsets of $A$ , such that $N\setminus M$ is finite. Show that $|M|=|N|$ . d) Let $M$ , $N$ be two maximal pure subsets of $A$ , and put $N'=N\setminus M$ , $M'=M\setminus N$ . Show that: $$M'\subseteq\bigcup_{x\in N'}E_M(x).$$ Deduce that $|M|=|N|$ . Question I was able to do all this exercise, but, in the French version, the exercise assumes only a weaker condition: (MO') If $X$ , $Y$ are two distinct elements of $\mathcal{R}$ and if $z\in X\cap Y$ , then there exists $Z\subseteq X\cup Y$ belonging to $\mathcal{R}$ such that $z\notin Z$ instead of (MO), and was able to do items (a) to (c), but I do not know how to do item (d). Attempt There is my solution to items (a) to (c) assuming only (MO') and item (d) assuming (MO). a) Straightforward application of Zorn's lemma. In fact, if $\mathcal{A}$ is the set of all pure subsets of $A$ containing a given pure subset $P$ , then for every totally ordered subset $\mathcal{C}$ of $\mathcal{A}$ , if $\bigcup\mathcal{C}$ is not pure, then it contains an $R\in\mathcal{R}$ , but $R$ is finite, say, $R=\{a_1,\dots,a_n\}$ , so for $i=1,\dots,n$ there is a $Q_i\in\mathcal{C}$ such that $a_i\in Q_i$ , then there is a $Q\in\mathcal{C}$ such that $Q_1,\dots,Q_n\subseteq Q$ , so $R\subseteq Q$ , contradicting the purity of $Q$ ; therefore $\bigcup\mathcal{C}\in\mathcal{P}$ . b) Because of maximality of $M$ , there is an $E\in\mathcal{F}(M)$ such that $E\cup\{x\}\in\mathcal{R}$ . If $F\in\mathcal{F}(M)$ , $F\neq E$ and $F\cup\{x\}\in\mathcal{R}$ , then $E\cup\{x\}\neq F\cup\{x\}$ and $x\in\left(E\cup\{x\}\right)\cap\left(F\cup\{x\}\right)$ , so by (MO') the set $\left(\left(E\cup\{x\}\right)\cup\left(F\cup\{x\}\right)\right)\setminus\{x\}$ is not pure, but: $$\left(\left(E\cup\{x\}\right)\cup\left(F\cup\{x\}\right)\right)\setminus\{x\}\subseteq E\cup F\subseteq M,$$ so $M$ will not be pure, a contradiction. Let $y\in E$ . If $R\subseteq(M\cup\{x\})\setminus\{y\}$ and $R\in\mathcal{R}$ , then $R\subseteq M\cup\{x\}$ , so, by purity of $M$ , $R=G\cup\{x\}$ for some $G\in\mathcal{F}(M)$ , and by (a) we have $G=E$ , but $y\notin G$ and $y\in E$ , a contradiction. Therefore $(M\cup\{x\})\setminus\{y\}$ is pure. Let $z\in A\setminus((M\cup\{x\})\setminus\{y\})$ , then $z=y\text{ or }(z\notin M\text{ and }z\neq x)$ . For the case $z=y$ , we have $((M\cup\{x\})\setminus\{y\})\cup\{y\}=M\cup\{x\}$ , that is not pure. For the case $z\neq y$ , then $z\notin M$ and $z\neq x$ , so there is a $H\in\mathcal{F}(M)$ such that $H\cup\{z\}\in\mathcal{R}$ , so: If $y\notin H\cup\{z\}$ , then: $$H\cup\{z\}\subseteq (M\cup\{z\})\setminus\{y\}\subseteq((M\cup\{x\})\setminus\{y\})\cup\{z\}.$$ If $y\in S$ , then $y\in(E\cup\{x\})\cap(H\cup\{z\})$ , so $((E\cup\{x\})\cup(H\cup\{z\}))\setminus\{y\}$ is not pure, and: $$((E\cup\{x\})\cup(H\cup\{z\}))\setminus\{y\}\subseteq((M\cup\{x\})\setminus\{y\})\cup\{z\}.$$ Therefore $((M\cup\{x\})\setminus\{y\})\cup\{z\}$ is not pure. So $(M\cup\{x\})\setminus\{y\}$ is maximal. c) Induction on $|N\setminus M|$ . If $|N\setminus M|=0$ , then $N\subseteq M$ , so by maximality of $N$ we have $N=M$ , so $|M|=|N|$ . If $|N\setminus M|>0$ , then there is a $m\in M\setminus N$ and there is an $n\in E_N(m)$ , so by item (b) the set $N'=(N\cup\{m\})\setminus\{n\}$ is pure maximal and $|N'\setminus M|<|N\setminus M|$ , so by induction hypothesis we have $|M|=|N'|$ , but $|N'|=|N|$ , so $|M|=|N|$ . d) If we assume (MO), then for $m\in M'$ we have $E_N(m)\cup\{m\}\in\mathcal{R}$ , so $E_N(m)\cup\{m\}\nsubseteq M$ , but $m\in M$ , so $E_N(m)\nsubseteq M$ , so there is an $x\in E_N(m)$ such that $x\notin M$ , so $x\in N'$ , and $E_M(x)\cup\{x\}\in\mathcal{R}$ , therefore: $$x\in(E_M(x)\cup\{x\})\cap(E_N(m)\cup\{m\}),$$ so we have two cases: If $E_M(x)\cup\{x\}=E_N(m)\cup\{m\}$ , then $x\in N'$ and $m\in E_M(x)$ . If $E_M(x)\cup\{x\}\neq E_N(m)\cup\{m\},$ then by (MO) the set $((E_M(x)\cup\{x\})\cap(E_N(m)\cup\{m\}))\setminus\{x\}$ is not pure, but it is contained in $M$ , a contradiction. Finally, by virtue of (c), we are reduced to the case where $M'$ and $N'$ are infinite, so: $$|M'|\leq|\bigcup_{x\in N'}E_M(x)|\leq\sum_{x\in N'}|E_M(x)|\leq\sum_{x\in N'}\aleph_0=|N'|\aleph_0=|N'|,$$ and analogously $|N'|\leq |M'|$ , so $|M'|=|N'|$ , and we conclude that $|M|=|N|$ .","['elementary-set-theory', 'combinatorics']"
3841733,Borel-Cantelli Lemma - is the measurability assumption necessary?,"I've seen this version of the Borel-Cantelli Lemma in Stein and Shakarchi: Let $(E_k)_{k=1}^{\infty}$ be a countable family of measurable subsets of $\mathbb{R}^d$ satisfying $$\sum_{k=1}^{\infty}m(E_k) < \infty$$ Let $E$ be the set of $x\in \mathbb{R}^d$ such that $x\in E_k$ for infinitely many $k$ . Then $E$ is measurable and $m(E) = 0$ . Now in proving this it seems straightforward enough to show that the tail of the sequence goes to $0$ , so for any $\varepsilon > 0$ , choose $K\in\mathbb{N}$ such that $\sum_{k=K}^\infty m(A_k) < \varepsilon$ . Now by definition of $E$ , we have $E\subset \bigcup_{k=K}^{\infty}E_k$ so by monotonicity and subadditivity of the exterior measure, $m_*(E) \leq \sum_{k=K}^\infty m(A_k) < \varepsilon$ which proves the result. But did we need the measurability assumption? I did not use it anywhere in this argument, so is that a mistake on my part or would this hold for a collection of sets which may not all be measurable, but the series of their exterior measures still converges.","['borel-cantelli-lemmas', 'measure-theory', 'outer-measure']"
3841811,What does it mean to differentiate $f(\theta_1)/f(\theta_2) = C$ with respect to theta?,"In the book I am reading, at one point they differentiate Snell's Law with respect to ${\theta}$ : $$\frac{d}{d\theta}\Bigl(\frac{\sin(\theta_{1})}{\sin(\theta_{2})}=\frac{\eta_{2}}{\eta_{1}}\Bigr),$$ which they claim gives the result: $$\frac{\cos(\theta_{1})d\theta_{1}}{\cos(\theta_{2})d\theta_{2}}=\frac{\eta_{2}}{\eta_{1}}.$$ I have no reason not to believe that this is true, but I really don't understand what it means to differentiate two different variables ( $\theta_{1}$ and $\theta_{2}$ ) with respect to a third variable ( $\theta$ ). I suppose the two variables aren't necessarily completely independent as they are both values on the axis of $\theta$ , but I can't really grasp it. $\frac{\eta_{2}}{\eta_{1}}$ is also a constant, so why would it not go to $0$ ? Here is a link to the section of the book in question: http://www.pbr-book.org/3ed-2018/Reflection_Models/Specular_Reflection_and_Transmission.html#eq:spherical-L-transmitted and their definition of Snell's Law: http://www.pbr-book.org/3ed-2018/Reflection_Models/Specular_Reflection_and_Transmission.html#eq:snells-law I am new here, so apologies in advance if I have done something incorrectly in this post. Any nudge in the right direction would be really appreciated! EDIT: Actually, $\theta_{1}$ and $\theta_{2}$ are just functions of $\theta$ aren't they? Oops. So I guess I need to think of it like this: $$\frac{d}{d\theta}\Bigl(\frac{f(g(\theta))}{f(h(\theta))}=C\Bigr),$$","['multivariable-calculus', 'calculus', 'physics']"
3841883,Simplify $(1+\sqrt{3}) \cdot \sqrt{2-\sqrt{3}}$,"Can someone help me simplify $(1+\sqrt{3})\times\sqrt{2-\sqrt{3}}$ ?
The end result is $\sqrt{2}$ , however, I honestly do not know how to get there using my current skills. I asked a teacher/tutor and he proposed setting the expression equal to X and working backwards, squaring both sides so that: $$X^2 = (1 + \sqrt{3})^2 \cdot (2 - \sqrt{3}) =(4+2\sqrt{3})(2-\sqrt{3}) =8-2\sqrt{3}^2 = 2 \require{cancel}$$ $$\Rightarrow X = \sqrt{2}$$ My main question is: What are the steps to simplify this without setting equal to X? I tried watching a youtube video, but had no success - is difference of squares applicable here? Thanks!","['nested-radicals', 'algebra-precalculus', 'radicals']"
3841890,"How to find $q,\beta$ such that $\nabla\cdot[\gamma\nabla u]=0\Leftrightarrow(-\Delta +q)v=0$ for some $v=\beta u $?","Let $\Omega$ be an open subset of $\mathbb R^n$ . Let $\gamma\in C^1(\Omega)$ be bounded away from zero. Find $q,\beta\in C^1(\Omega)$ such that \begin{equation*}
	\nabla\cdot[\gamma\nabla u]=0\Leftrightarrow(-\Delta +q)v=0 \text{ for some }v=\beta u 
\end{equation*} My attempt: $$
\begin{aligned}
0&=~ (-\Delta+q)\beta u\\
&=~-(u\Delta \beta+\beta\Delta u+2\nabla u\cdot\nabla \beta)+q\beta u\\
&=~-2\nabla u\cdot\nabla \beta+u(-\Delta \beta+q\beta)-\beta\Delta u
\end{aligned}$$ Also we have $$
\begin{aligned}
0&=~ \nabla\cdot(\gamma\nabla u)\\
&=~\nabla u\cdot \nabla \gamma+\gamma \Delta u
\end{aligned}
$$ I do not know how should I proceed now.","['inverse-problems', 'partial-differential-equations', 'functional-analysis', 'real-analysis']"
3841929,A generalization of Bottema's theorem,"Can you provide a proof for the following claim: In any triangle $ABC$ construct isosceles right triangles on sides $AC$ and $BC$ , with right angles at the points $A$ and $B$ . Let points $F$ and $G$ divide catheti $AE$ and $BD$ respectively in the same arbitrary ratio . The midpoint $H$ of the line segment that connects points $F$ and $G$ is independent of the location of $C$ . GeoGebra applet that demonstrates this claim can be found here . I tried to mimic a proof of Bottema's theorem given on this page but without success.","['euclidean-geometry', 'triangles', 'geometry', 'plane-geometry']"
3841952,Why is $\frac{d}{dx}\ln |x|=\frac 1x$,"Obviously, $x$ is always positive for the $\ln$ function. But the modulus allows $x$ to hold negative values as well. But why isn’t the derivative of the function $=\frac{1}{|x|}$ ? I understand the orignal function isn’t entirely differentiable, but I don’t see why it is possible to completely ignore the modulus.","['calculus', 'derivatives', 'logarithms']"
3841995,"Show that $(a, b) \mapsto a + b + pab$ makes $\mathbb{Z} / p^n \mathbb{Z}$ into a cyclic group.","I'd like to show that $(\mathbb{Z} / p^n \mathbb{Z}, \ast)$ is a cyclic group, where $\ast$ is defined by $$a \ast b = a + b + pab$$ I have already proved this, but in a way that is unsatisfying: I simply checked that the given operation satisfies the group axioms, and proved by tedious calculations the order of 1 with respect to this operation is equal to $p^n$ . I feel like there ought to be a way to simultaneously show that $\ast$ is a group operation and that the resulting group is cyclic. It reminds me of the following question: Show that $(\mathbb{R} \setminus \{-1\}, \star)$ is a group, where $\star$ is defined by $$a \star b = ab + a + b$$ where the ""right"" way to prove this is to observe that $ab+ a + b = (a+1)(b+1) - 1$ , and so $(\mathbb{R} \setminus \{-1\}, \star)$ is isomorphic to $(\mathbb{R} \setminus \{0\}, \times)$ but we have renamed $x$ to $x - 1$ . I wonder if there is a similar argument for the first question that avoids all of the manual work I did.","['group-theory', 'finite-groups']"
3842032,"Let $\{X_i\}_{i=1}^{\infty}$ be a sequence of iid random variables. If $P(X_i\geq0)=1$ and $P(X_i\neq0)>0$ for all $i$, then $\sum X_i=\infty$ a.s.","I came across a proposition, which is stated without proof. It appears in a section on the 0-1 Laws. Proposition. Let $\{X_i\}_{i=1}^{\infty}$ be a sequence of iid random variables on some probability space. If $P(X_i \geq 0) = 1$ and $P(X_i \neq 0) > 0$ for all $i$ , then the sum of the $X_i$ 's is $\infty$ a.s. (almost surely). This doesn't quite seem trivial to me. So, I try to prove it: Proof (so far): Let $S = \sum_{i=1}^{\infty} X_i$ . If $P(S = \infty) = 1$ , it follows that $S = \infty$ a.s. So, the problem boils down to showing that: $S \in \mathcal{T}$ , where $\mathcal{T}$ is the tail $\sigma$ -field, and $S$ is considered a tail event. Any $A \in \mathcal{T}$ has probability $P(A) \in \{0, 1\}$ . We need to show that specifically $P(S = \infty) = 1$ . Since $\{X_i\}_{i=1}^{\infty}$ iid, by Kolmogorov's 0-1 Law, there exists a $\mathcal{T}$ defined as in (1). Not sure how to show that $S$ is a tail event, and that $P(S = \infty) = 1$ ? Can we use the fact that $P(X_i \neq 0) > 0$ and $P(X_i \neq 0) > 0$ in some way to conclude this? I don't see how.","['measure-theory', 'convergence-divergence', 'probability-theory']"
3842073,showing tightness if $P_nf \to Pf $ for all continuous $f$ with compact support,"I'm studying Billingsley's convergence of probability measure, and I met this exercise Suppose $S$ is separable and locally compact (have metric). Assume $P_nf \to Pf$ for all continuous $f$ with compact support. Show $\{P_n\}$ is tight and $P_n$ weakly converge to $P$ . Assuming $\{P_n\}$ is tight, then in locally compact metric space, $K$ (compact set) is separating class, so we can prove $P_n$ weakly converge to $P$ . But I'm struggling with former problem, $\{P_n\}$ is tight. Firstly, I tried the function $f_\epsilon(x)  = (1-\frac{\rho(x, K)}{\epsilon})_+$ . Then we got ( $K_\epsilon$ denote that the set $\rho(x, K)<\epsilon$ ) $$P_n K \leq P_nf \to Pf \leq PK_\epsilon$$ then, as $\epsilon \to 0$ , $ PK_\epsilon \to K$ , but we must deal with $n$ , so it encounter the change of limit problem. Can you help me? Any other solution is OK.","['measure-theory', 'probability-theory', 'weak-convergence']"
3842124,Approximating $\int_1^\infty x^a (x-1)^b e^{cx}dx$,"After lengthy calculations, I arrived at \begin{align*}
\int_1^\infty x^a (x-1)^b e^{cx}dx,
\end{align*} which cannot be solved in closed-form. I thus seek to approximate the integral, potentially including special functions. The constants $a,b,c$ may be complex but are  chosen such that the integral exists. Any ideas how to approximate the integral? I thought of rounding the real and imaginary part of $a$ and $b$ to integers. Then, simplifying the first two terms and plenty of partial integrations should give a solution. But that seems to be a very naive idea.","['integration', 'definite-integrals', 'approximation', 'numerical-calculus', 'numerical-methods']"
3842175,How to find the locus of intersection of normals,"Given a parabola $y^2 = x$ , how can we find the equation of the curve formed by the intersection of normals drawn from different points? I have attached an image for reference. I tried taking two close points $x$ and $x+dx$ and tried finding the intersection of their normals and solving the differential equation to get the answer but I couldn't get it right. Could someone explain how to find this either using differential equations or by any other method.","['curves', 'locus', 'geometry', 'ordinary-differential-equations']"
3842216,Number of elements of a set: is my phrasing correct?,"Let $p$ be a prime number and let $A = \{k : k\in\Bbb Z^+, 1\le k\le p\}$ . I create a set called $B$ that contains every $(k,k+2)$ number pair. $B = \{(k, k+2), k\in A\}$ I want to define the number of elements in $A$ and in $B$ , using $k$ . For example if $p=5$ , then $A = \{1,2,3,4,5\}$ and $B=\{(1,3),(2,4),(3,5),(4,6),(5,7)\}$ . I want to say that $A$ has $p$ elements and $B$ has $p$ elements. Is $|A|$ = $p$ , because $k$ ∈ $Z^+$ , 1≤k≤p $|B|$ = $p$ , because $k$ ∈ $Z^+$ , 1≤k≤p mathematically correct, or if not, how should I formulate it?","['elementary-set-theory', 'elementary-number-theory']"
3842265,How can non-split automorphism extensions exist?,"Given a finite simple group $S$ , we can consider its automorphism group ${\rm Aut}(S)$ . Since ${\rm Inn}(S) \lhd {\rm Aut}(S)$ , and $S \cong {\rm Inn}(S)$ , we can ask whether $S$ has a complement in ${\rm Aut}(S)$ . I was very surprised to learn that this is not always the case. The reason I am surprised is as follows: if I take a simple group $S$ and an automorphism $\phi:S \to S$ , I can compute the order of $\phi$ (say it is $t$ ) and then form the semidirect product $S \rtimes C_t$ where a generator of $C_t$ acts as $\phi$ on $S$ . Since automorphism groups of simple groups are solvable, why can't I just do this process a certain number of times and obtain the whole ${\rm Aut}(S)$ ? I understand that if I just include a set of generators of all the automorphisms then I'd get the holomorph of $S$ , which is indeed $S \rtimes {\rm Aut}(S)$ ... but why can't I just take a set of generators of outer automorphisms? Is this the obstruction? I tried to look at ${\rm Aut}(A_6)$ , which I know to be not split, but it wasn't helpful. Any insight on the right way to think about this would be appreciated.","['automorphism-group', 'group-theory', 'finite-groups']"
3842292,"Prove that the diophantine equation $(xz+1)(yz+1)=az^{3} +1$ has no solutions in positive integers $x, y, z$ with $z>a^{2} +2a$.","Let $a$ be a positive integer that is not a perfect cube. From experimental data, it appears all solutions to $(xz+1)(yz+1)=az^{3} +1$ in positive integers $x, y, z$ occur when $z \le a^{2} +2a$ i.e it appears there are no solutions in $x, y,z$ with $z> a^{2} +2a$ . Can this observation be proved? To motivate the question, we shall prove that on the contrary if $a$ is a perfect cube, there are infinitely many positive integer solutions in $x, y, z$ . Proof.
Let $a=m^{3} $ for some integer $m$ . Using the identity $n^{3} +1 =(n+1)(n^{2}-n+1)$ , we see that $az^{3} +1=(mz)^{3} +1= (mz+1)((mz)^{2}-mz+1) $ . A family of solutions is then given by $x=m$ , $y=m^{2}z - m$ where $z$ takes on any positive integer. How do I go about proving the striking observation: There are no positive integer solutions $x, y, z$ with $z>a^{2} +2a$ when the integer $a$ is not a perfect cube? Is there any counterexample?","['elementary-number-theory', 'diophantine-equations', 'recreational-mathematics', 'real-analysis', 'algebra-precalculus']"
3842364,Why is this quotient of the punctured plane not Hausdorff (Hatcher 1.3.25)?,"This is from question 1.3.25 of Hatcher's Algebraic Topology : Let $\phi : \mathbb{R}^2 \to \mathbb{R}^2$ be the linear transformation $\phi(x,y) = (2x, y/2)$ . This generates an action of $\mathbb{Z}$ on $X = \mathbb{R}^2 - \{0\}$ . [...] Show that the orbit space $X/\mathbb{Z}$ is non-Hausdorff [...]. I think the idea is to note that $(1,1)$ and $(1,0)$ are in distinct orbits but that their orbits contain all points of the form $(2^n,2^{-n})$ and $(2^n,0)$ , respectively, for all $n \in \mathbb{Z}$ . Using the fact that the distance in $\mathbb{R}^2$ between $(2^n,2^{-n})$ and $(2^n,0)$ tends to $0$ , we should be able to conclude that the quotient is non-Hausdorff. However, I'm having trouble turning this into a rigorous proof. I don't see why this implies that there can't be neighbourhoods in the quotient that separate $[(1,1)]$ and $[(1,0)]$ .","['separation-axioms', 'general-topology', 'group-actions', 'quotient-spaces']"
3842388,Number of $n \to p \bmod n$ before getting to 0,"There isn't much background context, but is there any estimations on how many iterations of $n \to p\% n$ are needed before $n$ becomes 0? Percentage sign is modulo. ( $p$ is fixed, prime in my context but not sure if it matters). For example, when $p=10^9+7$ , the maximum number of iterations needed is $50$ . When $p=998244353$ (a common prime in competitive programming) the number of iterations is $45$ . I don't see any proof that it requires approximately $\log p$ , but it seems like so. Thank you for your time and help.","['number-theory', 'programming', 'elementary-number-theory']"
3842464,Compact operators and orthonormal basis for separable Hilbert space,"Is my conjecture true or false?  It seems it may be true based on the given proof. Conjecture: Let $T:H_1\rightarrow H_2$ be a bounded linear operator between Hilbert spaces $H_1$ and $H_2$ .  Assume $H_1$ is separable.  Suppose there exists an orthonormal basis $\{e_j\}$ so that $Te_j\rightarrow 0$ in norm as $j\rightarrow \infty$ .  Then $T$ is compact. Here is my proof:
Let $h_k\rightarrow 0$ weakly in $H_1$ as $k\rightarrow \infty$ .  Then write $h_k=\sum_{j=1}^{\infty}\langle h_k, e_j\rangle e_j$ .  And so let $\varepsilon>0$ .  Then there exists $j_{\varepsilon}\in \mathbb{N}$ and $j_{\varepsilon}>1$ so that for all $j\geq j_{\varepsilon}$ , $\|Te_j\|^2<\varepsilon $ .  Now we apply $T$ to the series representation for $h_k$ and split the series. \begin{align}
\|Th_k\|^2&< \sum_{j=1}^{j_{\varepsilon}-1}|\langle h_k, e_j\rangle |^2 \|Te_j\|^2+\varepsilon\sum_{j=j_{\varepsilon}}^{\infty}|\langle h_k, e_j\rangle|^2\\
&<\sum_{j=1}^{j_{\varepsilon}-1}|\langle h_k, e_j\rangle |^2 \|T\|^2+\varepsilon\sup_{k\in \mathbb{N}}\|h_k\|^2
\end{align} for all $k\in \mathbb{N}$ .  Since $h_k\rightarrow 0$ weakly as $k\rightarrow \infty$ , one can show that $\|h_k\|^2$ is a bounded sequence using the uniform boundedness principle.  Thus it remains to show that $\sum_{j=1}^{j_{\varepsilon}-1}|\langle h_k, e_j\rangle|^2$ can be made arbitrarily small for $k$ sufficiently large.  Because $h_k$ converges to $0$ weakly, for $\varepsilon>0$ and each $j\in \{1,2,..., j_{\varepsilon}-1\}$ there exists $k_{j,\varepsilon}\in \mathbb{N}$ so that $|\langle h_k, e_j\rangle |^2<\frac{\varepsilon}{j_{\varepsilon}-1}$ for $k\geq k_{j,\varepsilon}$ .  Then for $k\geq k_{\varepsilon}:=\max_{j\in \{1,2,...,j_{\varepsilon}-1\}}\{k_{j,\varepsilon}\}+1$ , we have $\sum_{j=1}^{j_{\varepsilon}-1}|\langle h_k, e_j\rangle|^2<\varepsilon$ .  This shows that $Th_k$ is strongly convergent to $0$ for any sequence $h_k$ weakly converging to $0$ .  Hence $T$ is compact.","['hilbert-spaces', 'solution-verification', 'compact-operators', 'functional-analysis']"
3842520,Minimum value of $\frac{\sin((2k+1)x)}{\sin(x)}$,"I'm need an approximation of the minimum of the function $\frac{\sin((2k+1)x)}{\sin(x)}, k\in\mathbb{N}$ .  I already tried to compute the zeros of the derivative but this looks impossible. If you plot for example the case $k=3$ so you can have an intuition of the situation you will see that it looks very evident that the minimum is reached on the first interval that the function crosses zero.","['optimization', 'calculus', 'trigonometry']"
3842527,Convergence on all the measurable set,"Problem On Probability space ( $\Omega$ , $\mathscr{A}$ ,P), I have sequence of $L_1$ non-negative function $f_i$ s.t. $\int_A f_i dP$ converge and $\int_A f_i dP$ is bounded by $1$ for every A $\in$ $\mathscr{A}$ . The problem is the only thing I know is convergence and I do not know whether or not it converge to $\int_A f dP$ for some $f$ . Is there any chance I can conclude $\int_A f_i dP$ converge to $\int_A f dP$ for some $f$ ? I have tried construct such $f$ by proving some subsequence of $f_i$ is pointwise convergence to some $f$ almost everywhere. prove $f_i$ is Cauchy in $L_1$ , so that this also imply existence of such $f$ by completeness and convergecne in $L_1$ gives us (1). construct $f$ using simple function, but this seems difficult in abstract space $\Omega$ . None of these successed. This might be a stupid question. Could anyone help me on this? Thanks！","['integration', 'measure-theory', 'cauchy-sequences', 'lp-spaces', 'pointwise-convergence']"
3842632,A smooth function $h: M \to \mathbb{R}$ from Partitions of Unity with $| h (x) - g (x) | <\epsilon$ for all $ x \in M​$.,"Let $ M $ a smooth manifold, $g: M \to \mathbb {R}$ any continuous function and $\epsilon> 0$ . Prove there is a smooth function $h: M \to \mathbb{R}$ with $| h (x) - g (x) | <\epsilon$ for all $ x \in M​​$ . In general, the idea is consider a partition of unity subordinate to coverage $ \{U_x: x \ in M ​​\}$ with $U_x = \{y \in M: | g (x) -g (y) | <\epsilon \}$ , but how do i build the $h$ function? My proof stars considering $f_x: M \to \mathbb{R}$ with $f_x (g) = | g (x) -g (y) |$ , so if $g$ is contiuous then $f_x$ is continuous. Now take $U_x = f^{- 1}_x ((- \infty, \epsilon)) \subset M $ an open set. Then $ U = \{U_x: x \in M ​​\} $ is an open cover of M, and exists a partition of unity $ \{\phi_x: x \in M ​​\} $ subordinate to $ U $ , where $$ \phi_x: M \to \Bbb R $$ $$ 0 \le \phi_x \le 1 $$ $$ \text{supp} (\phi_x) \subset U_x $$ $$ \sum_ {x \in M} \phi_x = 1 $$ Let $ h = \displaystyle \sum_ {x \in M} g(x) \cdot \phi_x $ smooth, then as $ g(x) $ is constant, we have $ g(x) \cdot \phi_x: M \to \Bbb R $ is smooth. but I don't know how to prove that $ | h (y) - g (y) | <\epsilon$ for all $y\in M ​​$ .","['manifolds', 'smooth-manifolds', 'differential-geometry']"
3842684,Double the value of a quadratic expression,"If I have this expression $f(x)=ax^2+bx+c$ and I want an expression for $2f(x)$ can I get that with a given change of $x$ ? For example, I have $f(x)=2x^2+3x+9$ and I want to find which factor for $x$ would make $f(x)$ twice the value at every point. Basically I'm looking for another function $g(x)$ so that I can use that and then $f(g(x))=2f(x)$ .","['functions', 'quadratics']"
3842780,Intuitive name for union of events in probability,"Update: cross-posted to English Stack Exchange . In probability, we often consider unions, intersections, and complements of events. While they can be named as such, it would be nice to have a nice informal/intuitive/non-jargony name for these events that reflects their status as things that happen , rather than just subsets of a sample space (other than the direct description "" $A \cup B$ means the event "" $A$ happens or $B$ happens"", "" $A \cap B$ "" means the event "" $A$ and $B$ both happen"", "" $A^c$ "" means "" $A$ doesn't happen""). I'm thinking of this in the context of explaining probability to someone else, Complement is easy as I can just describe it as the opposite of an event. The opposite of event $A$ happening, is event $A$ not happening, which is just $A^c$ . Makes sense. For the intersection of two events, I came up with their coincidence, which resonates on multiple levels and even has a good verb form: events $A$ and $B$ coincide iff their coincidence $A \cap B$ happens iff $A$ and $B$ both happen. (I'm using equality in the case where $A$ and $B$ are actually the same event i.e. describe the same set of outcomes, so there's little risk of confusion.) The union of two events, though, is harder to come up with a good informal name for. Terms like umbrella , compass , ambit , scope , range , orbit , menu which describe a list of possible selections sound weird when phrased as events that happen: ""the umbrella of $A$ or $B$ happens if..."" I thought of terms like participation , intervention , intrusion , inclusion , but these all have (literally) unwanted overtones and/or make the events sound personified in a weird way. Occurrence and instance sound better to describe ""at least one of these events happens"" but have the drawback that they apply to single events; there's no necessary reason for them to apply to a union of multiple events. Concurrence sounds like another description for intersection, as does conjunction , which is too jargony. Disjunction is also too jargony and sounds like "" $A$ or $B$ but not both"". Option and choice imply that someone in particular is picking which event happens. The least-bad idea that I came up with for union is alternative : the alternative of $A$ or $B$ happens iff $A \cup B$ happens iff at least one of $A, B$ happens. Could not be used as a verb ("" $A$ or $B$ alternate""??) but implies two or more possibilities without also implying that someone is picking which event happens, or that the events are like people ""participating"" or ""intruding"". Does anyone have a better one?","['elementary-set-theory', 'probability', 'terminology']"
3842870,Compute the preimage of dyadic interval via binary expansion map.,"I am working on an exercise about measure theory and I need to use the binary expansion of real number in the dyadic interval. Firstly, we know that the binary expansion of real number in $[0,1]$ is a map $f:\Omega\longrightarrow [0,1]$ maps $\omega=(x_{1},\cdots, x_{n},\cdots)$ to $$f(\omega):=\sum_{j=1}^{\infty}\dfrac{x_{j}}{2^{j}}.$$ My question is then how to express $f^{-1}(E)$ if $E=(\frac{k}{2^{j}}, \frac{k+1}{2^{j}})$ is the dyadic interval. This question is basically equivalent to finding a way to represent $x\in E$ in binary expansion. I am not really familiar with this material, so I read several online notes. For now, the only thing I know is that this map is well-defined since the series converges (comparison test), it is surjective since any real number in $[0,1]$ has a binary expansion, but it is not injective because not all real number has a unique binary expansion (the dyadic rationals have two expansion). I also tried to follow the post here how to find the binary expansion of any number in the unit interval [0,1] , but I got confused. The post identifying the measure $\lambda f^{-1}$ on the interval $[0,1]$ seems suggested that the binary expansion of points in the dyadic interval has only finitely many of entries, but I have no idea why it is true. From this, Whether a real number is a dyadic rational iff its binary expansion terminates? , I know that dyadic rational has terminating representation, but why does all the points in the dyadic intervals has finite length representation? For now, I can only say that since dyadic rational has terminating binary expansion, and the length is the same as $j$ . That is, $$\dfrac{k}{2^{j}}=0.x_{1}x_{2}\cdots x_{j}\ \ \text{and}\ \ \dfrac{k+1}{2^{j}}=0.y_{1}y_{2}\cdots y_{j}.$$ So, every $x\in E$ satisfies $$0.x_{1}x_{2}\cdots x_{j}<x<0.y_{1}y_{2}\cdots y_{j},$$ and thus $$f^{-1}(E)=f^{-1}(0.x_{1}x_{2}\cdots x_{j}, 0.y_{1}y_{2}\cdots y_{j}),$$ but then what does this mean in the space $\Omega$ ?.. It seems that we have many choices for the preimage.","['number-theory', 'measure-theory', 'probability-theory', 'real-analysis']"
3842920,Prove that $A \cup (B-C)=(A \cup B)-(A \cup C)$,"I want to prove that $$
A \cup (B-C)=(A \cup B)-(A \cup C)
$$ Here's my attempt $$
x \in A \cup (B-C)
\Leftrightarrow x \in A \lor (x \in B \land x \notin C)
\Leftrightarrow (x \in A \lor x \in B) \land (x \in A \lor x \notin C)
\Leftrightarrow x \in A \cup B \land x \notin A \cup C
$$ and therefore $x \in (A \cup B)-(A \cup C)$ by definition of set difference. However, I'm a bit unsure whether the following equaivance used in the proof is correct, namely: $$
x \in A \lor x \notin C \Leftrightarrow x \notin A \cup C
$$ Because if $x$ is in $A$ it's also in $A \cup C$ regardless of whether it's in $C$ or not. Am I missing something?",['elementary-set-theory']
3842922,Find matrix $A\in \mathcal{M}_n (\mathbb{N})$ such that $A^k =\left( \sum_{i=1}^{k}10^{i-1} \right)A$.,"I was watching this video by Flammable Maths about why $$
\begin{pmatrix}
3 &4\\
6&8
\end{pmatrix}^2 = \begin{pmatrix}
33 &44\\
66&88
\end{pmatrix}
$$ In the video, it is left as a challenge for the viewer to see if you can generalize the result as follows: Given some $k \in \mathbb{N}\cap[2,\infty), $ can you find a matrix $A\in \mathcal{M}_{n \times n} (\mathbb{N})$ such that $A^k =\left( \sum_{i=1}^{k}10^{i-1} \right)A$ ? I attempted a solution to this problem and did the following. I supposed (with the intention of hopefully simplifying calculations) that $A$ is diagonalizable. This means that I can write the equation we want as $$
PD^{k} P^{-1}= \left( \sum_{i=1}^{k}10^{i-1} \right)PD P^{-1}
$$ Now, taking the determinant on both sides I get that \begin{align*}
&|P||D|^k|P^{-1}| =  \left( \sum_{i=1}^{k}10^{i-1} \right)^n |P||D| |P^{-1}|\\
\implies & \left(\prod_{j=1}^n \lambda_j\right)^k =  \left( \sum_{i=1}^{k}10^{i-1} \right)^n\left(\prod_{j=1}^n \lambda_j\right)\\
\implies & \prod_{j=1}^n \lambda_j^{k-1} =  \left( \sum_{i=1}^{k}10^{i-1} \right)^n
\end{align*} where the $\lambda_j$ 's are the eigenvalues of $A$ . From here I think that if I find a set of eigenvalues that satisfy the above equation I can reconstruct a matrix which satisfies our original intended equation, however, I'm not sure if this is a good way to approach this problem. Does anyone know a better way to solve this? Or does anyone have any other ideas on how to tackle it? Ideally, I would like to find some patter or family of matrices which satisfy the desired property, buy any and all suggestions would be greatly appreciated. Thank you very much! Edit: As pointed out by levap in the comments, it's impossible to find a solution of a matrix made up of strictly positive integers for $k \ge 3$ . However, to not get rid of the possibility of other interesting solutions and/or observations, I'll clarify that other types of solutions with matrices in $\mathcal{M}_n (\mathbb{Z})$ , $\mathcal{M}_n (\mathbb{Q})$ or even in $\mathcal{M}_n (\mathbb{R})$ will happily be considered for the bounty if you think they're similar to the original problem. In short, if you find something you think is interesting, even if it's not too similar to $\begin{pmatrix}
3 &4\\
6&8
\end{pmatrix}$ , please post them nevertheless. Thank you!","['matrices', 'matrix-equations', 'linear-algebra']"
3843053,Geometric Motivation for Inner Product,"I think some background will make the kind of answer I'm looking for clearer. I'm trying to think of an elementary proof of the Pythagorean Theorem. I don't like the geometric proofs because they all seem to rely on some kind of trick or clever construction. In particular, they don't seem to shed any light on why we look at the square root of the sum of squares to find a distance. By contrast, the inner product seems like an elementary way to prove the Pythagorean theorem that does give us some understanding of why we should square and take square roots. Briefly: you use Gram-Schmidt to convert a basis to an orthonormal basis. Taking the inner product of a vector with itself in the orthonormal basis immediately gives you the Pythagorean theorem. This seems like a promising approach since the defining properties of an inner product (linearity, symmetry, and positive definitenes) are pretty basic. But, even though they're basic, I'm not sure how to motivate them geometrically. So, at the level of geometry, why should we want to consider an object like an inner product on a vector space? Of course, we know by Cauchy-Schwarz that the inner product helps us define magnitude and angle, but I don't think that's obvious from its defining properties. Perhaps the thing to do is to start with the relationship $\langle v, w \rangle = ||v || ||w|| \cos \theta$ , where $\theta$ is the angle between $w$ and $v$ , and then argue that $\langle \cdot, \cdot \rangle$ has the properties of an inner product.","['inner-products', 'gram-schmidt', 'motivation', 'geometry']"
3843061,Is there $k\in\mathbb{R}-\mathbb{Z}$ such that $2^k\in\mathbb{N}$ and $3^k\in\mathbb{N}?$,"Is there $k\in\mathbb{R}-\mathbb{Z}$ such that $2^k\in\mathbb{N}$ and $3^k\in\mathbb{N}?$ My guess is no such $k$ exists but seems hard to prove. Any ideas?
Thanks in advance","['logarithms', 'real-analysis']"
3843103,"Prove that $(0,1)\times(0,1) \subset R^2$ is an open set","I know how to prove that $(0,1) \subset R$ is an open set. But I can't apply the same logic to $R^2$ .
Here's what I tried: Take $x = (x_1,x_2)$ an arbitrary element from $(0,1)\times(0,1)$ Let $\epsilon = \min\{1 - x_1, x_1, 1 - x_2,x_2\}$ Take $y \in B_\epsilon(x)$ , arbtitrary. Now I need to prove that $y \in (0,1)\times(0,1)$ All I can use is $\displaystyle \sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2} < \epsilon$ , and I need to show that $0 < y_1 < 1$ and $0 < y_2 < 1$ I saw that question: Show that $(a,b)\times (c,d)$ is an open set in $\mathbb{R}^2$ with the Euclidian metric. but it doesn't help.","['general-topology', 'metric-spaces', 'real-analysis']"
3843195,Let $n=apq+1$. Prove that if $pq \ | \ \phi(n)$ then $n$ is prime.,"Let $p$ and $q$ be distinct odd primes and $a$ be a positive integer with $a<p<q$ . I need to prove that if $pq \ | \ \phi(n) $ then $n$ is prime.
The proof for the trivial case when $a=2$ is given below. Proof.  Let $n=2pq+1$ . Assume $pq \  | \ \phi(n)$ . We may write $\phi(n) = cpq$ for some positive integer $c \le 2$ . We know that $\phi(n)$ is even for all $n>2$ therefore we must have $c=2$ otherwise $\phi(n) $ is odd. $\phi(n) =2pq=n-1$ which shows that $ n $ is prime. This completes the proof for the trivial case $a=2$ . How do I prove that the proposition holds for an arbitrary positive integer $a$ ?","['number-theory', 'primality-test', 'elementary-number-theory', 'prime-numbers']"
3843208,Show that $A-$excircle is tangent to $(AST)$,"Elmo is now learning olympiad geometry. In triangle $ABC$ with $AB\neq AC$ , let its incircle be tangent to sides $BC$ , $CA$ , and $AB$ at $D$ , $E$ , and $F$ , respectively. The internal angle bisector of $\angle BAC$ intersects lines $DE$ and $DF$ at $X$ and $Y$ , respectively. Let $S$ and $T$ be distinct points on side $BC$ such that $\angle XSY=\angle XTY=90^\circ$ . Finally, let $\gamma$ be the circumcircle of $\triangle AST$ . (a) Help Elmo show that $\gamma$ is tangent to the circumcircle of $\triangle ABC$ . (b) Help Elmo show that $\gamma$ is tangent to the incircle of $\triangle ABC$ . Very Hard problem .. My Progress : WLOG $AB<AC$ . Define $N=BC\cap AY $ . Claim: $\angle ASX=\angle XST$ Proof: Since $\angle XSY=90$ , by lemma 9.18 from EGMO it's enough to show that $(A,N;X,Y)=-1$ . Now, note that $AEFD$ is a harmonic quad . So $(A,D;E,F)=-1$ . So projecting through $D$ on $AI$ , we get $(A,DD\cap AI=N;DE\cap AI=X,DF\cap AI=Y )=-1$ . So $\angle ASX=\angle XST$ . Similarly , we can get $\angle ATX=\angle XTN$ So we get $X$ and $Y$ as the incentre and $A$ -excentre of $\Delta AST$ respectively . Also we get $AS$ and $AT$ isogonals [ since $X$ is the incentre and $X\in AI$ ] Now, let $S'=AS\cap (ABC)$ , $T'=AT\cap (ABC)$ . By angle chase , we get $ST||S'T'$ and hence $AST~AS'T'$ and by homothety , we get $(AST)$ and $(ABC)$ tangent. This proves part $A$ . For Part $B$ : I applied inversion $\psi$ centered at $A$ with radius $\sqrt{AX\cdot AY}$ radius followed by reflection about the angle bisector of $\angle AST$ . Note that $\psi:X\leftrightarrow Y$ , $\psi:S\leftrightarrow T$ and $\psi:BC\leftrightarrow (AST)$ . Let us assume that $\angle AXB=\angle AYC=90$ [ I haven't got the proof of this , but it looks very true] Now, let $I-A$ be the $A$ -excentre of $\Delta ABC$ , $F^*$ be touch point of $A$ -excircle to line $AC$ , $E^*$ be touch point of $A$ -excircle to line $AB$ , And $K^*$ be touch point of $A$ -excircle to $BC$ . Note that $K^*,C,F^*,I-A$ is cyclic . But it's known that $\angle K^*CF^*=180-C\implies \angle CK^*F^*=\angle CF^*K^*=C/2$ . So $\angle XYF*=90+C/2$ . Also note that $\Delta DXC$ is isosceles , hence $\angle XEC=90-C/2$ . Hence $XEF^*Y$ is cyclic. Similarly we can get $XFE^*Y$ is cyclic [ $BK*I-AE*$ is cyclic] Hence $AX\cdot AY=AE\cdot AF^*=AF\cdot AE^*$ . So $\psi:E\leftrightarrow E^*$ and $\psi:F\leftrightarrow F^*$ . Define $D^*$ as the inverse image of $D$ by $\psi$ . Note that $(D^*E^*F^*)$ will be a circle tangent to $AB$ at $E^*$ , tangent to $AC$ at $F^*$ and $(AST)$ at $D^*$ . If I am able to show that $(D^*E^*F^*)$ is the $A$ -excircle , then I am done . So basically, I need to prove that Show that $A-$ excircle is tangent to $(AST)$ After Proofing the above statement , we get that $\psi:$ incircle of $ABC$ $\leftrightarrow$ $ A$ -excircle  of $ABC$ . Now since $A$ -excircle touches $BC$ at $K^*$ , and inversion preserves tangency , the inverted images will also be tangent to each other i.e incircle of $ABC$ is tangent to $(AST)$ and we will be done .. If possible can someone post solution using the way I have proceeded ( using $\sqrt{AX\cdot AY}$ ) ? Thanks in advance! Here's the ggb link for the diagram: https://www.geogebra.org/geometry/xzzqzmuh","['euclidean-geometry', 'inversive-geometry', 'geometry']"
3843224,Why do Pentagon tilings not solve the Einstein Problem?,"The einstein problem asks about the existence of a single prototile that by itself forms an aperiodic set of prototiles, that is, a shape that can tessellate space, but only in a nonperiodic way . (This Numberphile video has more context). Now there are pentagonal shapes that tile the plane in a non-periodic way . Why are these shapes no solution to the einstein problem? I suspect that I misunderstand some criteria of Aperiodic set of prototiles , but i cannot figure out what it is.","['discrete-geometry', 'geometry', 'tiling']"
3843275,Solving $\sin5x \cos3x = \sin6x \cos2x$ two ways gives different solutions. Which approach is correct?,"The question is: $$\sin5x \cos3x = \sin6x \cos2x$$ I had two approaches: $$\sin5x \cos3x = \sin6x \cos2x \\
   2\sin5x \cos3x = 2\sin6x \cos2x \\
   \sin8x+\sin2x=\sin8x+\sin4x \\
   \sin2x=\sin4x \\ \sin4x-\sin2x=0 \\
 2\sin x\cos3x=0  \\
\implies \sin x=0 \\ x=n\pi
\implies  \cos3x=0 \\ 3x={(2n+1)\pi}/2 \\
x={(2n+1)\pi}/6$$ These were the solutions in the first approach. $$\sin5x \cos3x = \sin6x \cos2x \\
   2\sin5x \cos3x=2\sin6x\cos2x \\
   \sin8x+\sin2x=\sin8x+\sin4x \\
   \sin2x=\sin4x\\ \sin4x-\sin2x=0 \\
   2\sin2x.\cos2x-\sin2x=0 \\
\sin2x(2\cos2x-1)=0 \\
\implies \sin2x=0 \\
x=n(π/2)\\
\implies 2\cos2x-1=0 \\
\cos2x=1/2 \\
2x=2n\pi\pm(\pi/3) \\
x=n\pi\pm(\pi/6)$$ These were my solutions in the second approach. This was also the approach given in the textbook for this question. My question is: Why do these solutions not match in the two cases? Have I made any mistake in the first approach?","['trigonometry', 'solution-verification']"
3843281,Prove that there are no composite integers $n=am+1$ such that $m \ | \ \phi(n)$,"Let $n=am+1$ where $a $ and $m>1$ are positive integers and let $p$ be the least prime divisor of $m$ . Prove that if $a<p$ and $ m \ | \ \phi(n)$ then $n$ is prime. This question is a generalisation of the question at Let $n=apq+1$. Prove that if $pq \ | \ \phi(n)$ then $n$ is prime. .
Here the special case when $m$ is a product of two distinct odd primes has been proven. The case when $m$ is a prime power has also been proven here https://arxiv.org/abs/2005.02327 . How do we prove that the proposition holds for an arbitrary positive integer integer $m>1 $ ? ( I have not found any counter - examples). Note that if $n=am+1$ is prime, we have $\phi(n)= n-1=am$ . We see that $m  \ | \ \phi(n) $ . Its the converse of this statement that we want to prove i.e. If $m  \ | \ \phi(n) $ then $n$ is prime. If this conjecture is true, then we have the following theorem which is a generalisation  ( an extension) of Lucas's converse of Fermat's little theorem. $\textbf {Theorem} \ \  1.$ $ \ \ \ $ Let $n=am+1$ , where $a$ and $m>1$ are positive integers and let $p$ be the least prime divisor of $m$ with $a<p$ . If for each prime $q_i$ dividing $m$ , there exists an integer $b_i$ such that ${b_i}^{n-1}\equiv 1\ (\mathrm{mod}\ n)$ and ${b_i}^{(n-1)/q_i} \not \equiv 1(\mathrm{mod}\ n)$ then $n$ is prime. Proof. $ \ \ \ $ We begin by noting that ${\mathrm{ord}}_nb_i\ |\ n-1$ . Let $m={q_1}^{a_1}{q_2}^{a_2}\dots {q_k}^{a_k}$ be the prime power factorization of $m$ . The combination of ${\mathrm{ord}}_nb_i\ |\ n-1$ and ${\mathrm{ord}}_nb_i\ \nmid (n-1)/q_i$ implies ${q_i}^{a_i}\ |\ {\mathrm{ord}}_nb_i$ . $ \ \ $${\mathrm{ord}}_nb_i\ |\ \phi (n)$ therefore for each $i$ , ${q_i}^{a_i}\ |\ \phi (n)$ hence $m\ |\ \phi (n)$ . Assuming the above  conjecture is true, we conclude that $n$ is prime. Taking $a=1$ , $m=n-1$ and $p=2$ , we obtain Lucas's converse of Fermat's little theorem. Theorem 1 is thus  a generalisation (an extension) of Lucas's converse of Fermat's little theorem. On recommendation by the users, this question has been asked on the MathOverflow site, https://mathoverflow.net/questions/373497/prove-that-there-are-no-composite-integers-n-am1-such-that-m-phin","['conjectures', 'number-theory', 'elementary-number-theory', 'totient-function', 'prime-numbers']"
3843305,Function of two sets,"Let $U$ be the set of all nonempty subsets of $[0,1]$ that are a union of finitely many  closed intervals (where an ""interval"" that is a single point does not count as an interval). Does there exist a function $f:U\times U\rightarrow U$ such that for any $A,B\in U$ : (a) $f(A,B) = f(B,A)$ (b) $f(A,B)$ has length (i.e. Lebesgue measure) less than $0.0001$ . (c) $f(A,B)\cap A$ has positive length. (d)  The length of $f(X,B)\cap A$ is maximized at $X=A$ . This is a variant of this question with more restrictive conditions, so my guess would be that the answer is no.","['optimization', 'lebesgue-measure', 'real-analysis']"
3843306,A new generalization of Bottema's theorem,"Is the  proof given below acceptable? Claim . In any triangle $\triangle ABC$ construct isosceles triangles $\triangle ACE$ and $\triangle BDC$ on sides $AC$ and $BC$ , with apices at points $A$ and $B$ , such that $\angle EAC+\angle CBD=180^{\circ}$ holds true. Let points $F$ and $G$ divide legs $AE$ and $BD$ respectively in the same arbitrary ratio . The midpoint $H$ of the line segment that connects points $F$ and $G$ is independent of the location of $C$ . GeoGebra applet that demonstrates this claim can be found here . The following proof is inspired by this answer to my previous question. Proof . Consider $A$ , $B$ , $C$ as complex numbers and choose a $\lambda \in \mathbb{R}$ . Denote $\angle EAC=\alpha$ and $\angle CBD=\beta$ . Then, $$F=A+\lambda(E-A)=A+\lambda(\cos \alpha +i \sin \alpha)(C-A)$$ $$G=B+\lambda(D-B)=B+\lambda(\cos (-\beta) +i \sin (-\beta))(C-B)$$ $$H=\frac{1}{2}(F+G)=$$ $$\frac{1}{2}(A+\lambda(\cos \alpha +i \sin \alpha)(C-A)+B+\lambda(-\cos \alpha -i \sin \alpha)(C-B))=$$ $$\frac{1}{2}(A+\lambda(\cos \alpha + i\sin \alpha)C-\lambda(\cos \alpha + i\sin \alpha)A+ $$ $$B-\lambda(\cos \alpha + i\sin \alpha)C+\lambda(\cos \alpha + i\sin \alpha)B)=$$ $$\frac{1}{2}(A(1-\lambda(\cos \alpha + i\sin \alpha))+B(1+\lambda(\cos \alpha + i\sin \alpha)))$$ This shows that $H$ is independent of the location of $C$ . Q.E.D. EDIT It is possible to generalize this claim even further. Claim .In any triangle $\triangle ABC$ construct triangles $\triangle ACE$ and $\triangle BDC$ on sides $AC$ and $BC$ such that $\frac{AE}{AC}=\frac{BD}{BC}$ and $\angle EAC+\angle CBD=180^{\circ}$ hold true. Let points $F$ and $G$ divide sides $AE$ and $BD$ respectively in the same arbitrary ratio . The midpoint $H$ of the line segment that connects points $F$ and $G$ is independent of the location of $C$ . GeoGebra applet that demonstrates this claim can be found here . Proof . Consider $A$ , $B$ , $C$ as complex numbers and choose a $\lambda \in \mathbb{R}$ . Denote $\angle EAC=\alpha$ , $\angle CBD=\beta$ and $\frac{AE}{AC}=\frac{BD}{BC}=k$ . Then, $$F=A+\lambda(E-A)=A+\lambda \cdot k(\cos \alpha +i \sin \alpha)(C-A)$$ $$G=B+\lambda(D-B)=B+\lambda \cdot k(\cos (-\beta) +i \sin (-\beta))(C-B)$$ $$H=\frac{1}{2}(F+G)=\frac{1}{2}(A+\lambda \cdot k(\cos \alpha +i \sin \alpha)(C-A)+$$ $$B+\lambda \cdot k(-\cos \alpha -i \sin \alpha)(C-B))=$$ $$\frac{1}{2}(A+\lambda \cdot k(\cos \alpha + i\sin \alpha)C-\lambda \cdot k(\cos \alpha + i\sin \alpha)A+$$ $$B-\lambda \cdot k(\cos \alpha + i\sin \alpha)C+\lambda \cdot k(\cos \alpha + i\sin \alpha)B)=$$ $$\frac{1}{2}(A(1-\lambda \cdot k(\cos \alpha + i\sin \alpha))+B(1+\lambda \cdot k(\cos \alpha + i\sin \alpha)))$$ This shows that $H$ is independent of the location of $C$ . Q.E.D.","['euclidean-geometry', 'geometry', 'solution-verification', 'triangles', 'plane-geometry']"
3843315,Infimum of right derivative and infimum of left derivative are equal?,"Suppose we have continuous function $f: [a,b] \to \mathbb{R}$ with right and left derivatives on $(a,b)$ . So would $$m_-=\inf\{f_+'(x):x \in (a,b)\}= \inf\{f_-'(x):x \in (a,b)\}=m_+ $$ take place? I tried to prove by contradiction. Suppose $m_-<m_+$ . Then exists $x_0 \in (a,b)$ , such that $f'_-(x_0)<0.5(m_++m_-)$ . Then if we take $\epsilon=0.25(m_+-m_-)$ , then exists $\delta > 0$ such that if $0<x_0-x<\delta$ then $|\frac{f(x)-f(x_0)}{x-x_0}-f'_-(x_0)|<\epsilon$ . Then I choose $y \in (x_0-\delta; x_0)$ . We have $$\frac{f(y)-f(x_0)}{y-x_0}<\epsilon+ f'_-(x_0)<0.75m_++0.25m_-$$ Then if $x_0 \to y+0$ , it appears that $f'_+(y)<m_+$ , which is contradiction. I don't know if it's correct, so I would be glad if you point me in the right direction.","['supremum-and-infimum', 'derivatives', 'real-analysis']"
3843344,Weierstrass's elliptic function's expansion,"I'm studying about elliptic functions. In Bergman's book (The Kernel function and conformal mapping - page 10), the author gave an expansion of the Weierstrass's $\wp$ function : $$\wp(u) = - \frac{\eta_1}{w_1}+(\frac{\pi}{2w_1})^2\frac{1}{\sin^2(\pi u/2w_1)}-2(\frac{\pi}{w_1})^2\sum_{n=1}^{\infty}\frac{nq^{2n}}{1-q^{2n}}\cos(\frac{n\pi u}{w_1})$$ where $w_1$ , $w_2$ are periods, $q = \exp(i\pi w_2/w_1)$ and $2\eta_1$ is the increment of Weierstrass's zeta function related to the period $w_1$ (this means $\zeta (z+2w_1) = \zeta(z)+2\eta_1$ , for more information, can see here . I do not know how to figure out this formula from the original formula : $$\wp(u)=\frac{1}{u^2}+\sum_{(m,n)\neq (0,0)} ((\frac{1}{u+mw_1+nw_2})^2-(\frac{1}{mw_1+nw_2})^2)$$ Any hints would be appreciated.","['complex-analysis', 'elliptic-functions']"
3843355,Is $\frac{1}{x} = 4$ strictly a linear equation (in one variable)?,"$$\frac1{x} = 4$$ If multiplied by $x$ both sides, $$1 = 4x$$ Then it looks like linear equation in one variable. But is such multiplication by variable on both sides allowed?",['algebra-precalculus']
3843375,Specific numerical scheme does not converge,"In my numerical analysis class we are studying numerical solutions to ODEs and we are looking at the equation $y'=-y$ and we want to test the explicit midpoint rule $y_{n+1}=y_{n-1}+2hf(y_n)$ where $f$ is the RHS of $y'=-y$ . The initial condition is $y_0=1$ and we take stepsize $h=0.2$ and we want to apply the scheme on the interval $[0,20]$ , and the index is interpreted as $y_n \approx y(t = nh)$ . And we are asked to take $ y_1 = e^{-h} $ . I tried coding the scheme in MATLAB but got the graph of something that oscillates after a certain point and does not look like the true solution at all, but in the smaller interval it does match $e^{-x}$ . I have attached the figures below. Can someone please explain why this is happening? I thank all helpers.","['numerical-calculus', 'numerical-methods', 'ordinary-differential-equations']"
3843394,Non-autonomous linear difference inequation,"Let $(a_n)_{n\in\mathbb{N}}$ be a positive sequence. Suppose that for all $n\geq 1$ $$
a_{n+1}\leq \frac{1}{n}a_n + \left(1-\frac{1}{n}\right)a_{n-1}.
$$ How to study the convergence of $(a_n)$ ? I suppose it converges, but don't know how to prove it.","['sequences-and-series', 'recurrence-relations', 'real-analysis']"
3843397,Use the Chernoff Inequality to bound a probability.,"A coin is equally likely to be either $B_{1/3}$ (Bernoulli distributed with $p=1/3$ ) or $B_{2/3}$ . To figure out the bias, we toss the coin 99 times and declare $B_{1/3}$ if the number of heads is less than 49.5 and $B_{2/3}$ otherwise. Bound the error probability using the Chernoff bound. The Chernoff inequality or bound states: $P(X\geq a) = P(e^{tX}\geq e^{ta}) \leq \frac{E[e^{tX}]}{e^{ta}}$ In the special case of a binomial distribrution the lower bound of the Chernoff inequality is given by: $P(X\leq(1-\delta)\mu) = e^{-\frac{\delta^2}{2}\mu}$ From the question I understand that we are looking for the bound prob that (1) choosing $B_{1/3}$ is wrong if we see 49.5 or less heads after the 99 tosses. (2) Or we choose $B_{2/3}$ if we see 49.5 or more heads after the 99 tosses. To calculate the first part (1):
I tried using the binomial case of the Chernoff inequality. First, calculating $\delta$ $$
P(X\leq(1-\delta)\mu) = P(49.5 \leq (1-\delta)E(X_{2/3}))\\
E(X_{2/3})=\frac{2}{3}99 = 66\\ 
\delta = 1-\frac{49.5}{66} = 0.25\\
$$ Then I plugged delta into the inequality to get the lower bound probability: $$
P(X\leq(1-0.25)66)\leq e^{-\frac{0.25^2}{2}66} =  0.1271
$$ for the second part (2):
first we need to use the binomial Chernoff upper bound inequality, which is: $P(X\geq(1+\delta)\mu) = e^{-\frac{\delta^2}{2+\delta}\mu}$ Again I calculte delta: $$
P(X\geq(1+\delta)\mu) = P(49.5 \geq (1-\delta)E(X_{1/3}))\\
E(X_{1/3})=\frac{1}{3}99 = 33\\ 
\delta = \frac{49.5}{33}-1 = 0.5\\
$$ Then I plugged delta into the inequality to get the upper bound probability: $$
P(X\geq(1+0.5)33)\leq e^{-\frac{0.5^2}{2.5}33} =  0.03688
$$ Finally, I add both upper and lower bound $P(wrong) = P(X\geq49.5)+P(X\leq49.5) = 0.1640189 $ However, this answer is wrong, and I am not sure what I am doing wrong. Maybe is the interpretation of the question? Any help or hint would be very appreciated!","['statistics', 'binomial-distribution', 'probability', 'random-variables']"
3843410,Understanding the definition of infinite Cartesian product,"This is the first time I have come across the following definition for the infinite Cartesian product. I somewhat understand it, however, below I have pointed out where I am getting confused. Definition for the infinite Cartesian product: $$\prod_{i \in \mathbb{N}}\mathbb{X}_i = \{f: \operatorname{dom}(f) = \mathbb{N} \wedge
\forall i, f(i) \in \mathbb{X}_i\}.$$ Here is where I am getting confused. Define the following: $$\mathbb{R}^2 = \mathbb{R} \times \mathbb{R} = \{(x,y): x \in \mathbb{R} \wedge y \in \mathbb{R}\} \quad (i)$$ $$\mathbb{R}^2 = \mathbb{R} \times \mathbb{R} = \prod_{i=1}^2\mathbb{R}_i = \{f: \operatorname{dom}(f) = \{1,2\} \wedge f(1) \in \mathbb{R}, f(2) \in \mathbb{R}\} \quad (ii)$$ Here is where I am getting confused. Lets say you want to write ""express"" the point where $x = 5$ and $y = \pi$ , then using $(i)$ you would simply write $(5,\pi)$ . How would you express the same for $(ii)$ ? In other words, I am just not sure how you would represent the same point using $(ii)$ . I know that a function is, itself, a set.","['elementary-set-theory', 'definition']"
3843423,How to prove $\int_Xexp(-\frac12X'AX)dX=(2\pi)^\frac{n}2{\lvert{A}\rvert}^{-\frac12}$ [duplicate],"This question already has answers here : If $A$ is positive definite, then $\int_{\mathbb{R}^n}\mathrm{e}^{-\langle Ax,x\rangle}\text{d}x=\left|\det\left({\pi}^{-1}A\right)\right|^{-1/2}$ (3 answers) Closed 3 years ago . I was studying a solution to a problem and this result was given without any explanation: If $X\sim{N}(0,I_n)$ & A is a symmetric positive definite matrix, $$
\int_X\exp\left(-\frac12X'AX\right)dX=(2\pi)^\frac{n}2{\lvert{A}\rvert}^{-\frac12}
$$ How can I prove this proposition?","['statistics', 'linear-algebra']"
3843436,Basis of $\{0\}$ set,"I am solving Linear Algebra and having a trivial doubt . Is W ={∅} i.e. an empty set a basis of 𝑉={0} ? I have read some solutions regarding the above and they imply that since W contains no vector , W  by definition is linearly independent .
I am not sure how W spans V. Can anyone explain this to me ? ""Every vector space has a basis."" Is the above statement true ?","['linear-algebra', 'vector-spaces']"
3843469,Shouldn't the ith root of the complex exponential function be equal to the natural exponential function?,"When i plug $\sqrt[i]{e^{ix}}$ into WolframAlpha it shows a rather weird function considering it should show the natural exponential function, since $\sqrt[i]{e^{ix}}=(e^{ix})^{\frac{1}{i}}=e^{\frac{ix}{i}}=e^{x}$ Is this a bug or am I wrong? Thanks in advance here's the link to the function in WolframAlpha: https://www.wolframalpha.com/input/?i=%5Csqrt%5Bi%5D%7Be%5E%7Bix%7D%7D And the code is \sqrt[i]{e^{ix}} if needed","['complex-analysis', 'radicals', 'wolfram-alpha', 'complex-numbers']"
3843570,The identity $\arctan(x) + \arctan(x^3) = \arctan(2x+\sqrt{3}) + \arctan(2x-\sqrt{3})$,"I came to this identity while doing some indefinite integrals. $\arctan(x) + \arctan(x^3) = \arctan(2x+\sqrt{3}) + \arctan(2x-\sqrt{3})$ Seems weird to me, no idea why it's correct but it is. I wonder if there's some geometric or trigonometric reasoning/insight behind it, say something which can be useful to high-school students for solving some problems. Any ideas?","['trigonometry', 'calculus', 'geometry', 'real-analysis']"
3843593,Lie algebra of a Lie group literature,"I'm currently writing my thesis and want to use the concept of Lie-algebras. I explained everything with the definitions of a lie-algebra that I had of an old lecture. There the lie-algebra of a lie-group is defined as the tangent space at the identity element.
I understand that there is an isomorphism between this tangent-space and the set of left-invariant vector-fields but I do not want to make things more complicated and just state it like this.
The script does not have literature advice and in the standard differential geometry literature that I know the definition is different. Can anyone advice me a citable document?","['lie-algebras', 'lie-groups', 'differential-geometry']"
3843640,Find the coefficient of ${x}^{20 }$ in ${({x}^{2}+{x}^{3}+{x}^{4}+{x}^{5}+{x}^{6})}^{5}$,"I saw a question in my textbook, the solution of this question exists in my textbook. However , its solution is very long.I tried to solve it in different way but i do not know whether it is true or not. The question: Find the coefficient of ${x}^{20 }$ in ${({x}^{2}+{x}^{3}+{x}^{4}+{x}^{5}+{x}^{6})}^{5}$ My solution: Step 1-) ${({x}^{2}+{x}^{3}+{x}^{4}+{x}^{5}+{x}^{6})}^{5}$ is equal to ${[{x}^{2}(1+{x}+{x}^{2}+{x}^{3}+{x}^{4})]}^{5}$ Step 2-) ${[{x}^{2}(1+{x}+{x}^{2}+{x}^{3}+{x}^{4})]}^{5}$ is equal to ${x}^{10}$ ${(\frac{1- {x}^{5}}{1-x})}^{5}$ Step 3-) We should ${x}^{10}$ in the expansion of ${(\frac{1- {x}^{5}}{1-x})}^{5}$ . We know that ${(\frac{1- {x}^{5}}{1-x})}^{5}$ is equal to ${{(1- {x}^{5})^{5}}({1-x})}^{-5}$ .So, we should find
the coefficient of ${x}^{2} $ in the expansion of $({1-x})^{-5}$ Step 4-) The formula for finding the coefficient is $C(5+2-1,2)=15$ Is my solution correct ? If it is not , can you give me hints ,shortcuts or full solution. Thanks for your helps..","['negative-binomial', 'multinomial-theorem', 'solution-verification', 'binomial-coefficients', 'discrete-mathematics']"
3843658,Alternative definition of limsup and liminf,"I am reading a Chinese textbook on Real analysis and it introduces the definition of limsup and liminf as the following: $$\varliminf A_n\equiv\liminf_{n} A_n\equiv\{x; \text{there exists finitely(*) many n, such that } x\notin A_n\}$$ $$\varlimsup A_n\equiv\limsup_{n} A_n\equiv\{x; \text{there exists infinitly many n, such that } x\in A_n\}.$$ Then it gives an example: Let $A_n=[\frac{1}{n},3+(-1)^n],n=1,2,3,...$ , we have that $\liminf_{n} A_n=(0,2], \limsup_n A_n=(0,4]$ . The notion that for any series of sets $A_1,A_2,...A_n,...$ we have: $$\liminf_n A_n=\bigcup^\infty_{m=1}\bigcap^\infty_{i=m} A_i$$ $$\limsup_n A_n=\bigcap^\infty_{m=1}\bigcup^\infty_{i=m} A_i$$ follows the example and is introduced as the property of liminf and limsup. It is really hard for me to understand how the example relates to the definition. It seems easy to see if $x\in(0,4]$ it satisfies the definition of limsup. But what if $x\in(0,2]$ , how do I connect it to the definition of liminf given in the text? (*) The original text is written in Chinese, so I am not sure if the word finitely is translated correctly. By direct translation, the text would be ""there is limited many n"", but I have never heard such term in English.","['elementary-set-theory', 'limsup-and-liminf', 'definition']"
3843670,Finding simple algorithm to combine students into different groups,"I'd like to find an algorithm as simple as possible to solve the problem below. The same seven students will each day be divided and meet into two groups, one with four students and one with three. The group with four students will be accompanied with the teacher. Each student should meet every other student as equally often as possible. All students should meet the teacher as equally often as possible. The number of subsequent days without the teacher should be as short as possible. The number of days is unknown and big. Background: This is a real problem. I'm a teacher and my students are divided into presentation groups each time I have them. I want them to have me as a teacher as much as possible, but I need to divide them because otherwise the presentations will take up too long time. This split up is the best solution. I just want to make sure each student gets to hear as many different presentations as possible and also gets my feedback as much as possible.","['combinations', 'combinatorics', 'discrete-mathematics', 'algorithms']"
3843707,Is the modulus of curvature the speed at which tangents change direction?,"I'm having trouble understanding an argument: the modulus of curvature it is the speed at which tangents change direction. Let $\alpha:I \rightarrow \mathbb{R}^2$ a plane curve arc length parametrized and $k(s)$ the curvature of $\alpha$ is $s$ . Consider the tangent vectors $\alpha'(s_0)$ and $\alpha'(s_0+h)$ , where $s_0 \in I$ is fixed and $s_0 + h \in I$ . Denote by $\phi(h)$ the angle between these two vectors, ie, \begin{equation}
\cos\phi(h) = \langle  \alpha'(s_0) ,\alpha'(s_0+h) \rangle.
\end{equation} (because $|\alpha'(s_0)| = |\alpha'(s_0+ h)| = 1$ ). The limit $\displaystyle \lim_{h \rightarrow 0} \frac{\phi(h)}{h}$ is the speed at which tangents change direction. We have \begin{equation}
 |\alpha'(s_0+h) - \alpha'(s_0)| = 2 \sin\frac{\phi(h)}{2}
\end{equation} for all $h$ and so \begin{equation}
|k(s_0)| = |\alpha''(s_0)| = \lim_{h \rightarrow 0} \frac{\phi(h)}{h}.
\end{equation} Comments: I'm not able to verify the last two equations: $$|\alpha'(s_0+h) - \alpha'(s_0)|^2 = |\alpha'(s_0+h)|^2 - 2 \langle \alpha'(s_0+h) , \alpha'(s_0) \rangle + |\alpha'(s_0)|^2 = 2 - 2\cos{\phi(h)}.$$ I don't know which trigonometric identity is being used. The last equation is also not being able to verify. Thank you for your help.","['trigonometry', 'geometry', 'differential-geometry']"
3843802,Differential equation\higher order,"I need help solving this task, if anyone had a similar problem it would help me. The task is: Find the general solution of the differential equation $$ y''-y' - 2y=e^{2x} \cos^2 x$$ For homogeneous I get: $$y_H=c_1e^{2x}+c_2e^{-x}$$ I have a problem with the particular, I tried: $$y=(A\sin^2x+B\cos^2x)e^{2x}\\y'=(2A\sin x \cos x + 2B \sin x \cos x) e^{2x} +(A\sin^2 x + B \cos ^2 x) 2e^{2x}\\y''=2e^{2x}(2A \sin x  \cos x - 2B \sin x \cos x + A\sin^2 x +B \cos^2 x)$$ I have no idea if this is correct? I don't know what's next from here .. Thanks in advance !",['ordinary-differential-equations']
3843808,Does the association $V \mapsto GL(V)$ define a functor?,"As is stated in the title: Question: for $k$ a field, does there exist a functor $F: k$ - $\mathrm{v.s.} \to \mathrm{Grp}$ which on objects is $V \mapsto GL(V)$ ? My guess is no, because it doesn't look to me like there's a sensible way to map the morphisms. However, I can't come up with a counterexample in a similar way to Arturo Magidin in Why is there no functor $\mathsf{Group}\to\mathsf{AbGroup}$ sending groups to their centers? . Here is my attempt at imitating his answer: take $f: k \to k^2$ , $f = \begin{pmatrix} 1 \\ 0 \end{pmatrix}$ , $g: k^2 \to k$ , $g = \begin{pmatrix} 1 & 0 \end{pmatrix}$ . Then $g \circ f = 1_k$ , so $F(f):k^{\times} \to GL_2(k)$ is injective and $F(g): GL_2(k) \to k^\times$ is surjective. On the other hand, $f \circ g = \begin{pmatrix} 1 & 0 \\ 0 & 0 \end{pmatrix}$ , but this doesn't really give me anything.","['general-linear-group', 'linear-transformations', 'linear-algebra', 'category-theory']"
3843817,Poker - Combination Questions,"I'm struggling a bit with this question so any help will be very much appreciated! The premise is that two people, call them A and B, are playing a variant of poker where there's 3 shared cards, and then they each draw 2 cards each. In this round, the 3 shared cards are an ace of hearts, a king of hearts and a queen of spades. Player A has an ace of diamonds and a queen of clubs, so he has two pairs. Question 1: How many different pairs can player B draw that will result in a better hand than player A's? Question 2: Assume another player joins in, how many different pairs of cards can they have so that both have a better hand than player A? Now for question 1 I got the answer 27, which I'm pretty sure is wrong cause I feel like there should be a lot more. For question 2 I'm not even sure where to start. The only way I can think of doing it now is to just list out all the combinations and see which ones don't overlap but that can't be how you're supposed to do it. Thanks! EDIT: Quick explanation of how I got 27, don't have access to my notes so can't send a picture. First I looked at which poker hands that are better actually are possible to get, and they should be straight, three of a kind and two pair (ace and king). So the straights would be with a jack and 10, which I calculated by taking ${4 \choose 1}^2 = 16$ . The two pair was ${3 \choose 1} \dot {2 \choose 1} = 6$ . Now for the three of a kind I first did ${3 \choose 1} \dot {4 \choose 2} = 18$ . I wasn't sure what the best way to calculate this was, but I came to the conclusion that 13 of those combinations would be missing due to some of the cards already being taken, so $18-3 = 5$ . Then add them all up: $16 + 6 + 5 = 27$","['combinations', 'combinatorics', 'card-games', 'discrete-mathematics', 'poker']"
3843846,"Is ""$--2$"" by itself a valid Math expression?","I inserted the following in the calculator: $$--2$$ and the calculator gave me a result of $2$ . Is $--2$ by itself a valid Math expression, or did the calculator added $0$ or something before it ( e.g. . the calculator might have turned $--2$ into $0--2$ )?",['algebra-precalculus']
3843903,Finitely presented group with intermediate Turing degree word problem,"Does there exist a finitely presented group with undecidable word problem, but so that an oracle to solve the word problem for this group wouldn't be sufficient to solve the halting problem in general? I'd imagine there's no known example, as there aren't ""natural"" problems we know of that are undecidable but less hard than the halting problem, although maybe there is some argument against that possibility here, or at least a reason we should expect things to go one way or another.","['combinatorial-group-theory', 'group-theory', 'abstract-algebra', 'computability']"
3843927,Which convex shape requires the longest slice to break in half?,"Suppose you are given a convex unit area region of the plane, and you wish to minimize the length of a line segment that cuts the shape into two regions of equal area. Which shape results maximizes this length, i.e., is the hardest to slice into two equal regions. Is it the circle? For generalizations, does anything change if we allow the slice to be any curve? What if we want to chop it into $n$ equal regions for $n>2$ ? What if we are minimizing the area of planes that slice higher dimensional regions in half? I'm curious in any generalizations along these lines.","['convex-geometry', 'geometry']"
3843938,Black and Scholes d1 derivation,"I viewed this derivation on the website and didn't understand the variable substitution made in order to find d1 in the calculus (line 6): \begin{align*}
F(t,s) & = e^{-r(T-t)}\int^\infty_{-\infty} \max\left[se^z-K,0\right]f(z)\,dz \\
\,\, & = e^{-r(T-t)}\left(\int^{\ln \frac{K}{s}}_{-\infty} 0\cdot f(z)\,dz + \int^{\infty}_{\ln\frac{K}{s}} \left(se^z-K\right)\,f(z)\,dz\right) \\
\,\, & = e^{-r(T-t)}\int^{\infty}_{\ln\frac{K}{s}}\left(se^z-K\right)\,f(z)\,dz \\
\,\, & = e^{-r(T-t)} \left(s\int^{\infty}_{\ln\frac{K}{s}} e^zf(z)\,dz -K\int^{\infty}_{\ln\frac{K}{s}}f(z)\,dz \right) \\
\,\, & = e^{-r(T-t)} \left(s\int^{\infty}_{\ln\frac{K}{s}} e^zf(z)\,dz -K\int^{\infty}_{\ln\frac{K}{s}}f(z)\,dz \right) \\
\,\, & = \frac{e^{-r(T-t)}}{\sqrt{2\pi}} \left(s\int^{\infty}_{\ln\frac{K}{s}}  e^{\left(r-\frac{\sigma^2}{2}\right)\left(T-t\right) + \sigma\sqrt{T-t}y}e^{-\frac{y^2}{2}}\,dy -K\int^{\infty}_{\ln\frac{K}{s}}e^{-\frac{z^2}{2}}\,dz \right)  \\
\,\, & = \frac{e^{-r(T-t)}}{\sqrt{2\pi}} \left(s\int^{\infty}_{\ln\frac{K}{s}} e^{\left(r-\frac{\sigma^2}{2}\right)\left(T-t\right) + \sigma\sqrt{T-t}y-\frac{y^2}{2}}\,dy\right) -Ke^{-r(T-t)}\Phi\left(-\frac{\ln\frac{K}{s}- \left(r-\frac{\sigma^2}{2}\right)\left(T-t\right)}{\sigma\sqrt{T-t}}\right) \\
\,\, & = \frac{e^{-r(T-t)}}{\sqrt{2\pi}}  e^{\left(r-\frac{\sigma^2}{2}\right)\left(T-t\right)}\left(s\int^{\infty}_{\ln\frac{K}{s}} e^{\sigma\sqrt{T-t}y-\frac{y^2}{2}}\,dy\right) -Ke^{-r(T-t)}\Phi\left(-\frac{\ln\frac{K}{s}- \left(r-\frac{\sigma^2}{2}\right)\left(T-t\right)}{\sigma\sqrt{T-t}}\right) \\
\,\, & =    \frac{e^{-\frac{\sigma^2}{2}\left(T-t\right)}}{\sqrt{2\pi}}  \left(s\int^{\infty}_{\ln\frac{K}{s}} e^{-\frac{1}{2}\left(y^2-2\sigma\sqrt{T-t} y+\sigma^2\left(T-t\right)\right)}e^{\frac{1}{2}\sigma^2\left(T-t\right)}\,dy\right)-Ke^{-r(T-t)}\Phi\left(\frac{\ln\frac{s}{K}+\left(r-\frac{\sigma^2}{2}\right)\left(T-t\right)}{\sigma\sqrt{T-t}}\right) \\
\,\, & = \frac{e^{-\frac{\sigma^2}{2}\left(T-t\right)}}{\sqrt{2\pi}}   \left(s\int^{\infty}_{\ln\frac{K}{s}} e^{-\frac{1}{2}\left(y-\sigma\sqrt{T-t}\right)^2+\frac{1}{2}\sigma^2\left(T-t\right)}\,dz\right)-Ke^{-r(T-t)}\Phi\left(\frac{\ln\frac{s}{K}+\left(r-\frac{\sigma^2}{2}\right)\left(T-t\right)}{\sigma\sqrt{T-t}}\right) \\
\,\, & = \frac{e^{-\frac{\sigma^2}{2}\left(T-t\right)}e^{\frac{\sigma^2}{2}\left(T-t\right)}}{\sqrt{2\pi}}   \left(s\int^{\infty}_{\ln\frac{K}{s}} e^{-\frac{1}{2}\left(y-\sigma\sqrt{T-t}\right)^2}\,dz\right)-Ke^{-r(T-t)}\Phi\left(\frac{\ln\frac{s}{K}+\left(r-\frac{\sigma^2}{2}\right)\left(T-t\right)}{\sigma\sqrt{T-t}}\right) \\
\,\ & = \frac{1}{\sqrt{2\pi}}   \left(s\int^{\infty}_{\ln\frac{K}{s}} e^{-\frac{1}{2}\left(y-\sigma\sqrt{T-t}\right)^2}\,dz\right)-Ke^{-r(T-t)}\Phi\left(\frac{\ln\frac{s}{K}+\left(r-\frac{\sigma^2}{2}\right)\left(T-t\right)}{\sigma\sqrt{T-t}}\right) \\
\,\, & = s\Phi\left(-\frac{\ln\frac{K}{s}-\left(r-\frac{\sigma^2}{2}\right)\left(T-t\right)}{\sigma\sqrt{T-t}}+\sigma\sqrt{T-t}\right)-Ke^{-r(T-t)}\Phi\left(\frac{\ln\frac{s}{K}+\left(r-\frac{\sigma^2}{2}\right)\left(T-t\right)}{\sigma\sqrt{T-t}}\right) \\
\,\, & = s\Phi\left(\frac{\ln\frac{s}{K}+\left(r+\frac{\sigma^2}{2}\right)\left(T-t\right)}{\sigma\sqrt{T-t}}\right)-Ke^{-r(T-t)}\Phi\left(\frac{\ln\frac{s}{K}+\left(r-\frac{\sigma^2}{2}\right)\left(T-t\right)}{\sigma\sqrt{T-t}}\right)
\end{align*} Could someone help me please","['integration', 'derivatives', 'finance']"
3843950,motivation for derived categories,"I am studying the theory of derived categories as it is presented by Murfet . The notes are quite satisfactory and i can understand all the proofs in detail but my problem is that i can't find any reason to REALLY study derived categories because i don't know exactly the reason why they were introduced by Verdier and Grothendieck. So, briefly, my question is what problems appeared to them and what they expected to solve with derived and triangulated categories.","['homological-algebra', 'derived-categories', 'triangulated-categories', 'algebraic-geometry', 'soft-question']"
3843961,"Any ""shortcuts"" to proving that $\frac{\sin(x)}2+\sin^2(\frac x2)\tan(\frac x2)\to\tan(\frac x2)$","I was working on simplifying some trig functions, and after a while of playing with them I simplified $$\frac{\sin(x)}{2}+\sin^2\left(\frac{x}{2}\right)\tan\left(\frac{x}{2}\right) \rightarrow \tan\left(\frac{x}{2}\right)$$ The way I got that result, however, was with what I think a very ""roundabout"" way. I first used the half-angle formulaes , then used $x=\pi/2-\beta$ , and that simplified to $$\frac{\cos(\beta)}{1+\sin(\beta)}$$ where I again used the coordinate change to get $$\frac{\sin(x)}{1+\cos(x)}\rightarrow\tan\left(\frac{x}{2}\right)$$ I tried using the online trig simplifiers but none succeeded. Of course, after you know the above identity, it's easy to prove by proving that $$\frac{\sin(x)}{2}=\tan\left(\frac{x}{2}\right)-\sin^2\left(\frac{x}{2}\right)\tan\left(\frac{x}{2}\right)$$ Is there a more direct way to get the identity? I guess what I'm asking is, am I missing any ""tricks"" or software that I could have on my toolbelt so that next time I don't spend hours trying to simplify trig identities?",['trigonometry']
3843969,A Few Conceptual Questions About Laplace Transforms and Moment Generating Functions,"I have a few quick questions designed to understand Laplace Transforms and Moment Generating Functions better. Is the formulaic way to go from a Moment Generating Function to a Probability Density Function or a Probability Mass Function a line integral in the complex plane, analogous to the Inverse Laplace Transform? Does taking the $n$ -th derivative of a Laplace Transform (such as in the context of Differential Equations) with respect to the frequency domain variable $s$ and evaluating the result at $s = 0$ yield anything interesting, analogous to how the Moment Generating Function yields raw moments? Is there a geometric intuition to explain why the way to invert an integral transform is another integral transform, rather than taking some sort of derivative (as the fundamental theorem of calculus would predict)?","['ordinary-differential-equations', 'probability-theory', 'laplace-transform', 'moment-generating-functions', 'integral-transforms']"
3844000,"$\!\!\bmod n\!:\,$ a polynomial has a root $\!\iff\!$ it has a root in a complete residue system","I'm reading some notes on discrete math and I can't follow this reasoning: Let's see if there exist $x \in \mathbb{Z}$ such that $4x\equiv 3\pmod 6$ . First let us observe that if $x\equiv x'\pmod 6$ , $4x\equiv 4x'\pmod 6$ and then $x$ is a solution if and only if $x'$ is a solution. Therefore, just look for solutions in the set { $0,1,2,3,4,5$ }. I don't understand how any of this $x\equiv x'\pmod 6$ , $4x\equiv 4x'\pmod 6$ and then $x$ is a solution if and only if $x'$ is a solution. is implying this just look for solutions in the set { $0,1,2,3,4,5$ } I would appreciate any help.","['elementary-number-theory', 'divisibility', 'modular-arithmetic', 'discrete-mathematics']"
3844003,"Numbers $+1$, $-1$ on a circle.","Let $n$ be a positive integer and that $2n$ numbers are arranged at different points around a circle, half of these numbers being $+1$ and half of being $-1$ . Moving clockwise around the circle from a given starting position, let $T_i$ be the total of the first $i$ numbers passed. $(i)$ Prove that there is a starting position on the circle for which no $T_i$ is negative. $(ii)$ For any starting position prove that $$n+\sum_{i=1}^{2n}T_i$$ is even. I have solved $(ii)$ . How can I approach the first one? Any help?","['combinatorics', 'modular-arithmetic', 'circles']"
3844015,Complicated Pigeonhole Principle Homework Problem [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question There are $n$ participants in a tournament, where $n \geq 1$ . In matches in the tournament, there is a clear winner and clear loser (no ties). A participant $x$ is a ""champion"" if for all other participants $y$ , either $x$ directly beat $y$ or $x$ directly beat some third participant $z$ who beat $y$ . Prove that at least one of the $n$ participants will be a ""champion"". I'm fairly certain this question requires some application of the Pigeonhole Principle, but I'm really not sure where to start. Any help would be really appreciated! Edit: Each person will play against every other participant exactly once.","['graph-theory', 'pigeonhole-principle', 'discrete-mathematics']"
3844103,Choosing equivalent quantifier expressions,"Which of the following expressions are equivalent to $∃x∀y(P(x,y)∧¬Q(x,y))$ $¬∀x∃y(¬P(x,y)∨Q(x,y))$ $∃x∀y¬(¬P(x,y)∨Q(x,y))$ $∀x∃y(P(x,y)∨¬Q(x,y))$ $∃x∀y(¬P(x,y)∨Q(x,y))$ I chose 1 and 2. 1 due to the negation in front of the first universal quantifier symbol and 2 because of the negation in front of $(¬P(x,y)∨Q(x,y))$ . Can someone verify my answers?","['quantifiers', 'calculus', 'discrete-mathematics']"
3844150,"How to know if a graph contains subdivisions of $K_{3,3}$ or $K_{5}$","I've been reading about planarity in graph theory and I am kind of a newbie. I know that according to Kuratowski's Theorem (1930) ""a graph is planar if and only if it contains no subdivision of $K_5$ or $K_{3,3}$ "". However, I was confused how do you actually check this? There are not very many examples online. I was thinking perhaps this could be checked with an adjacency matrix, but this sounds very tedious. Are there more efficient ways?","['graph-theory', 'discrete-mathematics', 'planar-graphs']"
3844155,"When does convergence in $L^2$ imply convergence in $C[0,1]$","Suppose $f_n: [0,1] \mapsto \mathbb{R} $ are continuous functions. I'm interested in knowing under what conditions does $f_n \stackrel{L^2[0,1]}{\to}f$ imply $\sup_{x \in [0,1]} |f_n(x)-f(x)| \to 0$ . Clearly one example that implies this is if each $f_n$ is uniformly bounded, and has uniformly bounded first and second derivatives (the result follows from Arzela-Ascoli in this case, Does Lp-convergence and uniform boundedness in $C^2$, imply $C^{1}$ convergence? ). Is this basically necessary and sufficient? Or are there weaker conditions under which convergence in mean-square implies convergence uniformly?","['probability-theory', 'functional-analysis', 'real-analysis']"
3844179,Finding an equivalent statement in english,"Let $P(x,y)$ stand for the statement “ $x$ is the parent of $y$ ”. Here, $x$ and $y$ each denote a human being. Which of the following is equivalent to the statement $\neg\forall x\forall yP(x,y)$ ? It is not the case that every human is the parent of every human. Every human has a human parent. There exists a human who is not the parent of any human. There exists a human who is the parent of every human. I got answer choice $3$ because I converted the statement to $\exists x \exists y\neg P(x,y)$ which in English is number $3$ . Can my answer be confirmed?","['quantifiers', 'discrete-mathematics']"
3844207,Two Uncountable Sets Making a Infinitely Countable Set,"I am trying to solve the following: $A$ and $B$ are uncountable sets, what is a infinite countable result from $A \oplus B$ where $\oplus$ is the symmetric difference. My solution : Define $A= \mathbb Q \cup \mathbb R$ and $B= \mathbb R$ Thus, $A \oplus B = \mathbb Q$ which is countably infinite. As you can tell, I am having a hard time justify my answers and the idea of what symmetric difference does with certain steps. Any help is greatly appreciated.","['elementary-set-theory', 'functions', 'solution-verification']"
3844265,Area of sub-triangle inside a triangle,"Let $ABC$ be a triangle of area $a$ . The segment $\overline{AB}$ is divided in $n$ equidistant points and segment $\overline{AC}$ is divided in $m$ equidistant points. Find the area $b$ of triangle $DEF$ in function of area $a$ (triangle $ABC$ ), where $D$ is one of the equidistant points in segment $\overline{AB}$ and $E$ , $F$ are two of the equidistant points in segment $\overline{AC}$ . The image below shows one example where, $n=3$ , $m=4$ , $D=2$ , $E=1$ and $F=2$ . The red triangle represents the area to be found in functions of larger triangle.","['triangles', 'area', 'geometry']"
3844281,Existence of the limit $\lim_{h\to0} \frac{b^h-1}h$ without knowing $b^x$ is differentiable,"When trying to derive, from first principles, the fact that exponential functions $a^x$ (where $a>1$ is real) are differentiable, we easily see that $$
\lim_{h\to0} \frac{a^{x+h}-a^x}h = a^x \lim_{h\to0} \frac{a^h-1}h,
$$ provided the latter limit exists . It's even pretty easy to see that $$
\lim_{h\to0} \frac{a^h-1}h = ( \log_b a ) \lim_{h\to0} \frac{b^h-1}h
$$ for any other real $b>1$ , provided the latter limit exists . (And then one can define $e$ to be the number such that $\lim_{h\to0} \frac{e^h-1}h = 1$ and continue.) So my question, which doesn't seem to have an answer on this site (though I'd be happy to be proved wrong) nor in the textbooks I've consulted: how can one justify the existence of any limit of the form $\lim_{h\to0} \frac{b^h-1}h$ $(b>1)$ , without using the as-yet-underived fact that $b^x$ is differentiable ? (Edited to add: I also want to avoid infinite series.)","['limits', 'calculus', 'derivatives', 'education']"
3844376,"Find $a,b,c$ such that if $(−a + b + c, a - b + c, a + b - c)$ is all positive the process is repeated indefinitely","Given a tern of real numbers $(a, b, c)$ , you build a new tern $(−a + b + c, a - b + c, a + b - c)$ . If all the elements are positive, then the process is repeated; otherwise it stops. Determine all triples of positive Reals (a, b, c) for which the
process never stops. I think the answer is that for any picked element $a$ cannot be larger than $b+c$","['combinations', 'discrete-mathematics', 'real-analysis']"
3844438,How to find the initial value of a solution to a differential equation in order to comply with certain limits,"For the IVP, $y'+\frac{2x^2-4xy-y^2}{3x^2}=0, x>0, y(1)=y_0$ I got this, once all the calculations have been done: $$y'=\frac{y_0^2(-2x^2+4x+1)+4y_0(x^2+x+1)-2(x^2+4x-2)}{(2+y_0-x(y_0-1))^2}$$ I am confident with this calculation, and I also verified with Wolfram Alpha. Then the question asked there is exactly one value of $y_0$ such that the IVP satisfied $\lim_{x\to 0}y'(x)\neq 1$ , while $\lim_ {x\to0}y'(x)=1$ for all other values of $y_0$ . What is this value of $y_0$ corresponding to the different limits? So I took the limit $$\lim_{x\to0}y'(x)=\frac{y_0^2+4y_0+4}{(2+y_0)^2}=1$$ So no matter what value of $y_0$ I have, the limit will always be 1. Where did I misunderstand or did wrong? Any help will be great, stuck about 2 days...","['initial-value-problems', 'limits', 'ordinary-differential-equations']"
3844452,Product Sphere Curvature Computation,"In Petersen's Riemannian geometry page 118 he computes the curvature operator on the product Riemannian manifold $S^n(1/a) \times S^m(1/b)$ . For my question the fact that it is a product of spheres does not seem relevant - it could be any product manifold. In his computation he lets $Y$ be a unit vector field on $S^n$ , $V$ a unit vector field on $S^n$ and $X$ be a unit vector field on either $S^n$ or $S^m$ that is perpendicular to $Y,V$ . He then computes that $g(\nabla_YX,V) = 0$ via the Koszul formula. This all seems fine to me. The part where I'm having trouble is he then claims that $g(\nabla_YX,V) = 0$ implies that $\nabla_YX = 0$ if $X$ is tangent to $S^m$ and $\nabla_YX$ is tangent to $S^n$ if $X$ is tangent to $S^n$ . I'm not exactly sure how this result follows from $g(\nabla_YX,V) = 0$ ? It seems like maybe he is using the fact that the Levi-Cevita connection for a product manifold is essentially the sum of the respective connections when acting on vectors fields tangent to the manifolds in the product, but if so, why the discussion on $g(\nabla_YX,V) = 0$ ?","['riemannian-geometry', 'differential-geometry']"
3844461,Proving inequality: $\sum_{i=1}^n \left(a_i^7+a_i^5\right) \geq 2(\sum_{i=1}^n a_i^3)^2$,"Let $a_i$ be distinct positive integers; prove that $$(a_1^7+a_2^7+\cdots + a_n^7)+(a_1^5+a_2^5+\cdots +a_n^5)\ge 2(a_1^3+a_2^3+\cdots + a_n^3)^2$$ I tried using some well known inequalities; obviously, since non homogenous and no obvious function, I don't expect either of AGM, Muirhead, CS, Jensen, Karamata, etc. should work, though I might be woefully wrong. After a while of experimentation I realized that this problem would likely be solved by either some tricky manipulations or a very obscure named inequality. Any helps? Thanks!","['contest-math', 'summation', 'induction', 'sequences-and-series', 'inequality']"
