question_id,title,body,tags
205737,Formal definition of *not* uniformly continuous,"The definition for uniform continuity for a function $f : X \to Y$ is that for all $\epsilon > 0$, there exists a $\delta > 0$ such that $d_Y(f(p),f(q)) < \epsilon$ for all $p,q \in X$ such that $d_X(p,q) < \delta$. Mathematically, we can write this definition as $\forall \epsilon > 0, \exists \delta > 0 \textrm{ such that } d_Y(f(p),f(q) < \epsilon\ \forall p,q \in X \textrm{ for which } d_X(p,q) < \delta.$ I have learned that when negating a statement, one switches the quantifiers, and reverses any equality/inequality statements in the conclusion. Following these rules, the definition for not uniformly continuous would be $\exists \epsilon > 0\ \forall \delta > 0 \textrm{ such that } d_Y(f(p),f(q)) \ge \epsilon\ \exists p,q \in X \textrm{ for which } d_X(p,q) < \delta.$ This, however makes little sense as written. I believe that I would be better served writing this as $\exists p,q \in X \textrm{ such that } \forall \delta > 0 \textrm { for which } d_X(p,q) < \delta, \exists \epsilon > 0 \textrm{ such that } d_Y(f(p),f(q)) \ge \epsilon.$ My question is: does my latter define criteria for which a function is not uniformly continuous? In other words, is this a proper negation of the definition? I believe that it should provide a criteria for a function not being uniformly continuous, but is this the same thing as the wholesale negation of the definition?","['continuity', 'real-analysis']"
205748,"Consider the sequence defined: $a_1=0, a_{n+1}=3+\sqrt{11+a_n}$, show that is bounded above and increasing using induction.","Consider the sequence defined: $a_1=0, a_{n+1}=3+\sqrt{11+a_n}$
a) Show, using induction, that this sequence is bounded above by 14; b) prove that the sequence is increasing; c) Why must it converge?; d)Find the limit. So for part a), I have: Let $P(n)$ be the statement that $a_n \leq 14$.
Consider $P(1)$, where $n=1$.  Then $0 \leq 14$, which is indeed true.
Now assume that $P(k)$ is true for some $k\in \mathbb{N}$, i.e. $a_k \leq 14$  Then for $P(k+1)$: $a_{k+1}=3+\sqrt{11+a_k}=3+\sqrt{11+14}=8 \leq 14$.  Thus the statement holds for $P(k+1)$ is true.  Therefore the statement holds for all $n \in \mathbb{N}$. For part b), I also use induction. Let $S(n)$ be the statement: $a_{n+1} \geq a_n, \forall n \in \mathbb{N}$.  Then for $n=1$, we have that $S(1)$ is $a_2=3+\sqrt{11} \geq a_1=0$, which is indeed true.  Assume $S(k)$ is true for some $k \in \mathbb{N}$, i.e. $a_{k+1} \geq a_k$.  Then for $S(k+1)$, $a_{k+2}=3+\sqrt{11+a_{k+1}} \geq 3+\sqrt{11+a_k}=a_{k+1}$.  Thus $S(k+1)$ is true.  Thus $S(n)$ is true for all $n \in \mathbb{N}$ c) The sequence must converge since this sequence is bounded and monotonically increasing.
d) For this part do I say that $L=3+\sqrt{11+L}$, and then solve for $L$? I just want to see if I am doing this correctly.  I think that part b is incorrect because of the induction step. Any help and feedback is appreciated. Thanks in advance.","['sequences-and-series', 'real-analysis']"
205767,Nth derivative can be expressed like that?,"$$
\frac{f^{(n)}(z_0)}{n!} = \lim_{z \rightarrow z_0} \frac{f(z) -f(z_0)}{(z-z_0)^n}
$$ Why is that nth derivative can be expressed like that limit of quotient? I can understand the meaning but I couldnt get closed form equation. Thanks.",['derivatives']
205769,Simplify a factorial,"I have the problem to evaluate the following: $$
(2n)!\over
2^n(n!)
$$ Does this reduce to anything in particular? I stuck it into a computer and it's 1: 1
2: 3
3: 15
4: 105
5: 945
6: 10395 No pattern immediately apparent.","['factorial', 'algebra-precalculus']"
205785,"""Proof"" that if f(x) ~x, e^f(x) ~ e^x","While it is not true that $f(x)\sim x \implies e^{f(x)}\sim e^x,$ I can't spot the error in this ""proof"" by induction--or at least I can't articulate it well. Let $f(x)\sim x$ and $x > 1$ P(1): $1 \sim 1, f(x) \sim x,$ and $\lim_{x \to \infty} \frac{1+f(x)}{1+x} = \frac{1}{1+x}+\frac{f(x)}{1+x} = 0 +1 = 1. $ Assume P(k): $$~\lim_{x \to \infty} \frac{\sum_0^{k-1}f(x)^{n}/n!~ + ~f(x)^k/k!}{\sum x^{n}/n!~ +~ x^k/k!} = 1$$ It implies P(k+1): $$~\lim_{x \to \infty} \frac{\sum_0^{k}f(x)^{n}/n!~ + ~f(x)^{k+1}/(k+1)!}{\sum x^{n}/n!~ +~ x^{k+1}/(k+1)!} = 1$$ Since P(k) implies P(k+1), and P(1) is true...? Thanks.","['asymptotics', 'induction', 'exponential-function', 'limits']"
205797,Differentiation under integral sign (Gamma function),"This might be a silly question, but I'm reading this article about differentiation under the integral sign, and I'm stumped by something that's written early on. The author is giving a derivation of the formula for $n!$ in terms of the gamma function. He shows how you can get $$\frac{n!}{t^{n+1}} = \int_0^{\infty}x^ne^{-tx}\,dx$$ by differentating under the integral sign of $\int_0^{\infty}e^{-tx}dx$. He then says that the above ""immediately implies"" the formula $$n! = \int_0^\infty x^ne^{-x}\,dx.$$ However, I can't for the life of me see how this follows. Multiplying the first equation by $t^{n+1}$ gives $n! = t^{n+1}\int_0^{\infty}x^ne^{-tx}$, so apparently $$t^{n+1}\int_0^\infty x^ne^{-tx} \, dx = \int_0^\infty x^ne^{-x} \, dx,$$ but I don't see how this is true. Can anyone explain this?","['gamma-function', 'analysis']"
205807,Finding vector subspaces,"I've got this problem: Let $H = \left \{ x \in \mathbb{R}^{4} \, \left| \, x_2 - x_3 + 2x_4 = 0 \right. \right \}$ Find, if possible, $a \in \mathbb{R}$ and $S, T$ vector subspaces so that $\dim(S) = \dim(T)$, $S + T^\perp = H$, $S \cap T = \left \langle (1, a, 0, -1) \right \rangle$ What I have is: Using the dimension theorem for vector spaces: $\dim(S+T^\perp) = \dim(S) + \dim(T^\perp) - \dim(S \cap T^\perp) = \dim(H)$. Since $H$ is a $\mathbb{R}^{4}$ vector subspace with one equation, $\dim(H) = 3$. So $\dim(S) = 2$, $\dim(T^\perp) = 2$ and $\dim(S \cap T^\perp)=1$. If $\dim(T^\perp) = 2$, then $\dim(T)$ must be 2 as well. So I've got $S=\left \langle s_1, s_2 \right \rangle$ and $T=\left \langle t_1, t_2 \right \rangle$ Let $s_1, s_2$ two linearly independent vectors from subspace $H$. Suppose $s_1 = (0,1,1,0), s_2 = (0,0,2,1)$. Then $S=\left \langle (0,1,1,0),(0,0,2,1) \right \rangle$. Let $t_1, t_2$ two linearly independent vectors from subspace $H$. Suppose $t_1 = (0,-2,0,1), t_2=(1,-1,1,1)$. Then $T^\perp=\left \langle (0,-2,0,1),(1,-1,1,1) \right \rangle$ Because $(T^\perp)^\perp = T \rightarrow T=\left \{ x \in \mathbb{R}^{4} / -2x_2 + x_4 = x_1 - x_2 + x_3 + x_4 = 0 \right \}$ S and T satisfies all the conditions the problem asks. I know how to find $S \cap T$, but I'm a bit disappointed finding $a$. Any suggestion would be appreciated! Thanks in advance!",['linear-algebra']
205820,"What is ment by: ""parallel transport preserves orientation""?",In my text its written that parallel transport on a Riemannian manifold preserves orientation. Can someone clarify what does that mean? I am confused about this notion.,"['riemannian-geometry', 'differential-geometry']"
205833,escape velocity using limits,"I have the formula for a rocket's escape velocity from earth, $V$ being velocity, $v$ being initial velocity, and $r$ being the distance between the rocket and the center of the earth. $$V = \sqrt{\frac{192000}{r}+v^2-48}$$ I am trying to find the value of $v$ for which an infinite limit for $r$ is obtained as $V$ approaches zero, this value of $v$ being the escape velocity for earth. I have solved for $v$ (with $V$ being $0$), as $v = \sqrt{48-\frac{192000}{r}}$, but do not know how to continue solving the problem. I thought setting it up as the limit of the square root of $48-\frac{192000}{r}$ as $r$ approaches infinity (to give $v$), but that doesn't seem right.","['calculus', 'physics', 'limits']"
205859,How do you solve this recurrence?,"I have been trying to practice recurrence relations that can be solved by the master theorem and came across this . Now the $4^{\textrm{th}}$ problem in that file is : $$T(n) = 2^n T\left(\frac{n}{2}\right) + n^n.$$ The solution says it can't be solved using Master theorem, which is true. But I want to know how to solve it. I tried thinking of some substitution but I'm not able to get anywhere since the recurrence contains terms $2^n$ and $n^n$ both. And if I expand the tree, it becomes really messy. Any solutions?","['recurrence-relations', 'discrete-mathematics']"
205860,the sum of a series,"I am stuck on the computation of the following sum: $$\sum_{k=0}^{\infty} {\Big( {\frac{q}{k+1}} \Big)}^k ,$$ where $k$ is a natural number, and $0<q<1$.","['sequences-and-series', 'power-series', 'algebra-precalculus']"
205868,Countable Dense Set of Discontinuities and Riemann-Integrability (Rudin Question) [duplicate],"This question already has an answer here : Closed 11 years ago . Possible Duplicate: Series with fractional part of $nx$ I am working through Question 10 from Chapter 7 in Baby Rudin and I am very confused. Letting (x) denote the fractional part of the real number $x$, consider the function $$f(x)=\sum_{n=1}^{\infty} \frac{(nx)}{n^2}, \; x \in \mathbb{R}$$ Find all discontinuities of $f$, and show that they form a countable dense set. Show that $f$ is nevertheless Riemann-integrable on every bounded interval. I have looked at the solution ( here ) and my question is the following: Why is $f(x)$ discontinuous on all rationals and continuous on all irrationals? If I can get a cogent explanation for this fact then I understand the question and the proof. Any help is greatly appreciated!","['functional-analysis', 'real-analysis']"
205871,Tensor product of monoids and arbitrary algebraic structures,"Question. Do you know a specific example which demonstrates that the tensor product of monoids (as defined below) is not associative? Let $C$ be the category of algebraic structures of a fixed type, and let us denote by $|~|$ the underlying functor $C \to \mathsf{Set}$. For $M,N \in C$ we have a functor $\mathrm{BiHom}(M,N;-) : C \to \mathsf{Set}$ which sends an object $K \in C$ to the set of bihomomorphisms $M \times N \to K$, i.e. maps $|M| \times |N| \to |K|$ which are homomorphisms in each variable when the other one is fixed. Then one can show as usual that $\mathrm{BiHom}(M,N;-)$ is representable and call the universal bihomomorphism $M \times N \to M \otimes N$ the tensor product of $M,N$. This is a straight forward generalization of the well-known case $C=\mathsf{Mod}(R)$ for a commutative ring $R$. Actually, this is a special case of a more general tensor product in concrete categories, studied in the paper ""Tensor products and bimorphisms"", Canad. Math. Bull. 19 (1976) 385-401, by B. Banaschewski and E. Nelson. Here are some examples: For $C=\mathsf{Set}$, the tensor product equals the usual cartesian product. This is also true for $C=\mathsf{Set}_*$. For $C=\mathsf{Grp}$, we get $G \otimes H \cong G^{\mathsf{ab}} \otimes_{\mathbb{Z}} H^{\mathsf{ab}}$, using the Eckmann-Hilton argument . (This differs from the ""tensor product of groups"" studied in the literature). The case $C=\mathsf{CMon}$ is very similar to the well-known case $C=\mathsf{Ab}$ and is spelled out here ; namely, we have internal homs and therefore a hom-tensor-adjunction. The same is true for $C=\mathsf{Mod}(\Lambda)$ for a commutative algebraic monad $\Lambda$, see here , Section 5.3. Note that the tensor product is commutative, and that it commutes with filtered colimits in each variable. However, the case $C=\mathsf{Grp}$ shows that it does not have to commute with coproducts. In particular, tensoring with some object is no left adjoint. Also, the free object on one generator is not a unit in general: Let us consider $C=\mathsf{Mon}$. Then, we have $\mathbb{N} \otimes M = M / \{ (mn)^p = m^p n^p \}_{m,n \in M, p \in \mathbb{N}}$ The usual proof of the associativity of the tensor product breaks down: There is a map $\beta : M \times (N \otimes K) \to (M \otimes N) \otimes K$ mapping $(m, n \otimes k) \mapsto (m \otimes n) \otimes k$, which is a homomorphism in the second variable. But what about the first variable? The equation $\beta(mm',t) = \beta(m,t) \beta(m',t)$ is clear if $t \in N \otimes K$ is a pure tensor. But for $t=(n \otimes k) (n' \otimes k')$ we end up with the unlikely equation $((m \otimes n) \otimes k) ((m' \otimes n) \otimes k) ((m \otimes n') \otimes k') ((m' \otimes n') \otimes k')$
$=((m \otimes n) \otimes k)  ((m \otimes n') \otimes k') ((m' \otimes n) \otimes k) ((m' \otimes n') \otimes k')$","['abstract-algebra', 'tensor-products', 'category-theory', 'monoid', 'universal-property']"
205875,Convex hull of an open set...,"Let $K$ be a compact convex subset of locally convex topological vector space $E$.
Let $U$ be an open subset of $K$. Is $conv(U)$ (the convex hull of $U$) an open subset of $K$ ? You see, it is well know that if $U$ is an open subset of $E$, then $conv(U)$ is an open subset of E. the argument for this is based on the fact that the addition is an open map for $E \times E$ to $E$, hence if you take $(a_1,...,a_n)$ such that $\sum a_i =1$, then the set of $\sum a_i u_i$ for $u_i \in U$ is an open set, and hence $conv(U)$ is an union of open set. But when we restrict ourselves to $K$ the former argument no longer hold : for exemple if $U = K$, $n=2$ and $a_1=a_2= \frac{1}{2}$, then the set of $\sum a_i u_i$ is the set of non-extremal point of $K$, which may be non open even in a finite dimensional case... but still i can't find any counterexample to my question. Note : Using local convexity we can show that it is enough to proove that if $U$ and $V$ are two open convex subset of $K$ then the set of $a u +(1-a)v$ with a in $[0,1]$ is open in $K$. Thanks !","['general-topology', 'convex-analysis', 'functional-analysis']"
205877,Complex structure on cotangent bundle,"If $M$ is a complex manifold with complex structure $J$, why does the cotangent bundle of $M$ carry a natural complex structure, and not an almost complex structure. Is that obvious?",['differential-geometry']
205883,Proving $\frac{e^{z^2}}{\sqrt{\pi}}\int_{-\infty}^{z}e^{-t^2}dt$ is bounded for $\Re(z) \leq 0$,"I've been given the following equations;
$$\psi_1(z)=\frac{e^{z^2}}{\sqrt{\pi}}\int_{-\infty}^{z}e^{-t^2}dt$$
(i.e. integrate over the straight line contour {$t + z: -\infty\lt t \lt 0 $})
$$\psi_2(z)=\frac{e^{z^2}}{\sqrt{\pi}}\int_{\infty}^{z}e^{-t^2}dt$$
(i.e. integrate over the straight line contour {$t + z: \infty\gt t \gt 0 $}) I am asked to show $\psi_1(z)$ is bounded for Re(z)$\leq$0 and similarly show $\psi_2(z)$ is bounded for Re(z)$\geq$0. Also I want to show the limit of $\psi_1(x)$ as $x\rightarrow -\infty$ and $\psi_2(x)$ as $x\rightarrow \infty$ What I have done so far is to show that these equations can be represented in terms of the error function, that is; \begin{align}
\psi_1(z)&=\frac{e^{z^2}}{2}(\operatorname{erf}(z)+1) \\
\psi_2(z)&=\frac{e^{z^2}}{2}(\operatorname{erf}(z)-1)
\end{align} Yet am having trouble finding an upper bound for the above functions.","['integration', 'complex-analysis']"
205894,Finding one value from a mean.,"7 boys have a mean height of  1.80m.
Peter joins the boys and now the mean height is 1.75m.
Find Peter's height.","['statistics', 'average']"
205898,How to show that $1 \over \sqrt{1 - 4x} $ generates $\sum_{n=0}^\infty \binom{2n}{n}x^n $,I need to find the values of $a$ and $n$ in the following $$ (1 + ax)^n  = \sum_{i=0}^\infty \binom{2i}{i}x^i$$ How can I compare things and show that $a=-4$ and $n = -{1 \over 2}$. It's easy to expand $1 \over \sqrt{1 -4x}$ see that it's valid but I'm looking other way around.,"['generating-functions', 'sequences-and-series']"
205925,Definite integral of tetration between $0$ and $1$,"In my old writes I've found the following formula, where ${_{}^2}x$ is tetration : $$\int_0^1 {_{}^2}x \ dx = \sum\limits_{i=1}^\infty \frac {(-1)^{i+1}} {{_{}^2}i} \approx 0.783430511\ldots$$ Now I am interested in series of generalized case of tetration: $$\int_0^1 {_{}^n}x \ dx = ?$$ Could anybody find out it with an explanation?","['power-series', 'sequences-and-series', 'integration', 'tetration']"
205927,Proving a property of Legendre polynomials containing its derivatives: $nP_n(x)=x{P_n^\prime(x)} - P^\prime_{n-1}(x)$,"I am trying to prove the following property of Legendre polynomials. 
$$nP_n(x)=x{P_n^\prime(x)} - P^\prime_{n-1}(x)$$
My guess is that I somehow have to use the Bonnets recursion formula 
$$(n+1)P_{n+1}(x)=(2n+1)xP_n(x)-nP_{n-1}(x)$$
which is proved using the generating function of the legendre polynomials. 
However, I am not being able to eliminate the derivative of $P_{n+1}$ from this formula. I am not being able to do problems of a similiar nature, of recursion relations between the derivative of legendre polynomials.","['mathematical-physics', 'orthogonal-polynomials', 'ordinary-differential-equations', 'special-functions']"
205957,Alternate definition for boundedness in a TVS,"Let $X$ be a topological vector space over $\mathbb R$ or $\mathbb C$. A subset $B\subset X$ is defined to be bounded if for any open neighborhood $N$ of $0$ there is a number $\lambda>0$
  such that $B\subset \mu N$ for any $\mu>\lambda$. I was wondering whether this notion of boundedness is equivalent to saying that for any open neighborhood $N$ of $0$ there is a $\mu>0$ such that $B\subset \mu N.$ By definition $\mu N:=\{\mu\cdot x\colon x\in N\}$.","['examples-counterexamples', 'topological-vector-spaces', 'functional-analysis', 'definition']"
205995,root of $x^3+x+1$ over $\mathbb{F}_5$,"What is the simplest radical expression of some root $a \in \overline{\mathbb{F}_5}$ of the polynomial $x^3+x+1  \in \mathbb{F}_5[x]$? I wonder if one can simplify the general formulas in this special case. I think $\sqrt[3]{\sqrt{2} - 3} - \sqrt[3]{\sqrt{2} + 3}$ is ok for the beginning, but this minus in the middle and the nested roots make it rather complicated.","['finite-fields', 'abstract-algebra', 'polynomials']"
205997,"Continuous function from $[0,1]$ to $[0,1]$ whose fibers are infinite [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Show that there exists a continuous function $f:[0,1]\rightarrow [0,1]$ such that  $\forall y\in[0,1]$, all the fibers $f^{-1}(\{y\})$ have infinite cardinality.",['functions']
206000,How to prove the equivalence between the two statements of ABC conjecture?,"The ABC conjecture stated by wikipedia says the following statements are equivalent: I.
For $\epsilon>0$, there are finite coprime triple $(a,b,c)$ satisfying $a+b=c$ such that $\mathrm{rad}(abc)^{1+\epsilon}<c$ II.
For  $\epsilon>0$, there exists $C_\epsilon>0$,such that for all coprime triple $(a,b,c)$ satisfying $a+b=c$, $C_{\epsilon}\mathrm{rad}(abc)^{1+\epsilon}>c$ holds. How to prove $II \implies I$? thanks.","['prime-numbers', 'conjectures', 'number-theory']"
206004,$\mathbb{CP}^3$ (Twistor space) as bundle space with base $\mathbb{CP}^1$ and fiber 4-D Minkowski space-time?,"Twistor space, as complex projective space $\mathbb{CP}^3$, is related to Minkowski 4-D space time (metric $1, -1,-1,-1$), by the incidence relation. Let  $Z = (v_a, u^{\dot{a}})$ a point in $\mathbb{CP}^3$, where $v_a$ and $u^{\dot{a}}$ are 2-complex components spinors. Let $x_{a\dot{a}} = \sum x^\mu (\sigma_\mu)_{a\dot{a}}$, where $\sigma_\mu$ are the Pauli matrices, and $x^\mu$ a point in Minkowski 4-D space-time. The incidence relation is then $v_a = x_{a\dot{a}} u^{\dot{a}}$ The representation of a space-time point, in the twistor space $\mathbb{CP}^3$, is a complex line $\mathbb{CP}^1$. So, $\mathbb{CP}^3$ may be seen as a bundle space, with base Minkowski space-time, and fiber $\mathbb{CP}^1$. But, is the inverse true, that is: could we see $\mathbb{CP}^3$ as a bundle space, with base $\mathbb{CP}^1$, and as fiber the 4-D Minkowski space-time?","['projective-space', 'differential-geometry', 'projective-geometry']"
206032,What is the integral of 1/x?,"What is the integral of $\frac{1}{x}$ ? Do you get $\ln(x)$ or $\ln|x|$ ? In general, does integrating $f'(x)/f(x)$ give $\ln(f(x))$ or $\ln|f(x)|$ ? Also, what is the derivative of $|f(x)|$ ? Is it $f'(x)$ or $|f'(x)|$ ?",['integration']
206034,Alternative proof that set of algebraic elements is a subfield,"Let $E/F$ be a field extension. Let $A$ be the set of all elements in $E$ that are algebraic over $F$. One can show that $A$ is a subfield of $E$. The proofs I read all argue as follows: Let $a,b \in A$. We want to show that $ab, a +b \in A$. To this end we show that $[F(a,b):F]$ is finite. Finite implies algebraic hence since $a+b, ab \in F(a,b)$, $a+b, ab$ are algebraic and hence in $A$. I understand this proof but I was wondering if the following argument also works or whether it is flawed: Let $a,b$ be algebraic over $F$. Then there exist $p,q \in F[x]$ with $p(a) = 0$ and $q(b) = 0$. Define $p' (x) = p(x-b)$ and $p''(x) = p(x b^{-1})$. Then $p'(a + b) = p(a) = 0$ and $p''(ab) = p(a) = 0$. Hence $ab, a+b$ are algebraic over $F$ (since $p', p'' \in F[x]$). Is this correct? Thanks for help!","['abstract-algebra', 'field-theory']"
206050,How do I tell if this function is a probability density function?,If I have $$f(x)=\sin(x\pi/10)\qquad\text{for}\;0\leq x\leq10.$$ How do I tell if it is a probability density function? And if it isn't how do I normalize it?,"['probability-theory', 'probability-distributions', 'probability']"
206063,Finding the derivative of $ h(x) = \dfrac {2\sqrt{x}}{x^2+2}$,"$ h(x) = \dfrac {2\sqrt{x}}{x^2+2}$ Find the derivative How do I tackle this? My answer is totally different from the correction model, but I have tried for half an hour to show my answer in lateX but I don't know how to, it's too complicated, so, can someone please give a step to step of the solution? the correction model's solution is $ \dfrac {2-3x^2}{\sqrt{x} (x^2+2)^2} $","['calculus', 'derivatives']"
206074,Visualizing Exterior Derivative,"How do you visualize the exterior derivative of differential forms? I imagine differential forms to be some sort of (oriented) line segments, areas, volumes etc. That is if I imagine a two-form, I imagine two vectors, constituting a parallelogram. So I think provided I can imagine a field of oriented line segments, with exterior derivative I should imagine an appropriate field of oriented areas.","['differential-forms', 'visualization', 'differential-geometry']"
206076,Show that the function $f(x)=\frac{1}{2}\sin 2x + x$ is invertible,"Show that $$
f(x)=\frac{1}{2}\sin 2x + x$$ is invertible. How do I continue with this? I've tried with taking the derivative and taken the fact that $$
f'(x)=\cos 2x +1 \ge 0.$$ Is this enough? I'm not sure since it can also equal $0$ ...","['calculus', 'functions', 'inverse-function']"
206083,Full rank vs short rank matrix,"I am given the definition: ""A matrix A is of full rank if and only if the vector $d$ for which $Ad=0$ is $d=0$."" I don't understand: if we have the matrix $$\begin{pmatrix}1&2&3\\  
4&5&6\\  
13&19&88\end{pmatrix}$$ It is not of full rank, but what number other than $0$ can we multiply it by to get $0$? The last line is just an example that is independent of the first two.",['matrices']
206095,Finding the Robot [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question There are five boxes in a row. There is robot in any one of these five boxes. Every morning I can open and check a box (one only). In the night, the robot moves to an adjacent box. It is compulsory that he moves. I need a method to ensure that I can catch the robot within ten days.
How to do so?","['logic', 'puzzle', 'algorithms', 'combinatorics']"
206099,What are normal schemes intuitively?,"A ring is called integrally closed if it is an integral domain and is equal to its integral closure in its field of fractions. A scheme is called normal if every stalk is integrally closed. Some theorems on normality: A local ring of dimension 1 is normal if and only if it is regular. (Serre's criterion) A scheme is normal if and only if it is nonsingular in codimension 0 and codimension 1 and every stalk at a generic point of an irreducible closed subset with dimension $\ge 2$ has depth at least 2. Every rational function on a normal scheme with no poles of codimension 1 is regular. (Zariski connectedness): If $f:X\rightarrow Y$ is a proper birational map of noetherian integral schemes and $Y$ is normal, then every fiber is connected. Normal schemes over $C$ are topologically unibranched. But the proofs I've seen are fairly ad-hoc, and I was wondering if there's some geometric perspective that would clarify these results. The only result here thats an ""iff"" is Serre's criterion, but I don't understand depth geometrically so I'm not sure how to interpret it. Is there some nice geometric perspective on normality?","['algebraic-geometry', 'schemes']"
206108,Showing the Cantor function is not Lipschitz.,This is one I am having a lot of difficulty with.  I'm not sure how to show that the Cantor function (or 'Devil's Staircase) is not Lipschitz.,['analysis']
206131,Help explaining the sign of a permutation,"I have a permutation that has been expressed in disjoint cycles (this isn't my actual question, this is an example done in lectures which I'm trying to understand): (a b c)(d e f g h i) Now the procedure taught to calculate the sign of the permutation is to multiply the signs of the disjoint cycles, but in the example it is written: $ (-1)^2 \cdot (-1)^5 = -1 $ Why is it being raised to the powers of 2 and 5? Should it not be 3 and 6 because that is the length of the cycles? Because when I try my question, I calculate the inversions of the permutation and using that gives me the sign to be negative, but the disjoint cycle has 8 ""elements"" so $ (-1)^8 = 1 $, which is not negative. So does that mean you always do $(-1)^{\mathrm{(Length\, \, of\, \, cycle\, \, - 1)}} $ and then multiply like this?","['permutations', 'group-theory', 'cyclic-groups']"
206145,Implicit Function Theorem: a counter-example,"The following theorem is stated in Spivak's ""Calculus on Manifolds"" as a follow-up on the Implicit Function Theorem: Theorem 2.13: Let $f: \mathbb{R}^n \to \mathbb{R}^p$ be continuously differentiable in an open set containing $a$, where $p \le n$. if $f(a) = 0$ and the $p \times n$ matrix $(D_jf_i(a))$ has rank $p$, then there is an open set $A \subset \mathbb{R}^n$ containing $a$ and a differentiable function $h: A \to \mathbb{R}^n$ with differentiable inverse such that $$f \circ h (x^1, \dots, x^n) = (x^{n-p+1}, \dots, x^n).$$ I don't see how this can be true. For a simple counter-example, let $f(x) = \sin(x)$ with $n=p=1$. Since $f'(2\pi)=1$, the theorem should hold at $a = 2\pi$, and since $a \in A$ we get for $x = a = 2\pi$: $$\sin(h(a)) = a = 2\pi,$$ which cannot be true for any $h$. Where is the mistake?",['multivariable-calculus']
206153,What would be a good method for finding the submatrix with the largest sum?,This question is from an ongoing contest which ends in 4 days.  It is this problem from the October Challenge . Given:A Matrix (Not necessarily square) filled with negative and positive integers.What will be good way of finding the sub matrix with the largest sum  and this sub matrix may not be contiguous such that you can select columns 1 and 3 and rows 1 and 3 and leave out column 2 and row 2? Any hints/suggestions/tricks will help a lot.,"['numerical-linear-algebra', 'linear-algebra', 'algorithms']"
206159,Sufficient condition for absolute continuity of measures,"Let $X=2^{\omega}$ (the space of one-way infinite binary sequences) and $\mathcal{P}(X)$ the space of Borel probability measures on $X$. A measure $\mu \in \mathcal{P}(X)$ is absolutely continuous with respect to $\nu \in \mathcal{P}(X)$, written $\mu \ll \nu$, iff for every $\epsilon>0$ there is a $\delta>0$ such that for every Borel $B$, if $\nu(B)<\delta$ then $\mu(B) < \epsilon$. Question 1 Does it suffice to check only cylinder sets? I.e. is it the case that $\mu \ll \nu$ iff for every $\epsilon>0$ there is a $\delta>0$ such that for every finite binary string $\sigma$ if $\nu([\sigma])<\delta$ then $\mu([\sigma]) < \epsilon$, where and $[\sigma] = \{ x \in X: \sigma \text{ is an initial segment of } x\}$? Question 2 Is there some countable collection $\mathcal{C}$ of Borel sets such that $\mu \ll \nu$ iff for every $\epsilon>0$ there is a $\delta>0$ such that for every $B \in \mathcal{C}$, if $\nu(B)<\delta$ then $\mu(B) < \epsilon$? Of course, an affirmative answer to Question 1 implies an affirmative answer to Question 2.","['probability-theory', 'measure-theory']"
206173,Find all real numbers $t$ such that the quadratic form $f$ is positive definite.,"Where $$f(x_1,x_2,x_3)=2x_1^2+x_2^2+3x_3^2+2tx_1x_2+2x_1x_3$$. This is a problem in my Matrix Analysis homework. Below is my effort. Let $x=(x_1,x_2,x_3)^T$, then we have $$f=x^*Sx$$, in which $$S=\left(\begin{matrix}2&t&1\\t&1&0\\1&0&3\end{matrix}\right)$$. $f$ is positive definite is equivalent to $S$ is positive definite which is equivalent to all the eigenvalues of $S$ is positive. The characteristic polynomial of $S$ is: $$\begin{align}|\lambda I-S|&=-\lambda^3+6\lambda^2+(3t^2-10)\lambda+(-3t^2+5)\\&=(-3+3\lambda)t^2+(-\lambda^3+6\lambda^2-10\lambda+5)\end{align}$$. Now the only problem left is that how do I find all the possible real values of $t$ that makes this polynomial of $\lambda$ only has positive roots?",['linear-algebra']
206180,Can all Hermitian matrices $H$ be written as $H=A^* A$?,"All the matrices below are square, complex matrices. 1) Is it true that, for every Hermitian matrix $H$, there exists $A$, that $A^*A=H$? 2) For any $A$, does $A^*A$ always have a square root? If it's not, is there any simple presumption of $A$ that makes $A^*A$ always have a square root?","['matrices', 'linear-algebra']"
206182,An Intuitive Explanation of the Transfer Homomorphism,"I just learned about the transfer homomorphism, and I am having trouble internalizing it. I am learning from 'A Course in the Theory of Groups', and I was hoping that perhaps someone had a more intuitive explanation of the transfer to supplement the book's construction.","['transfer-theory', 'group-theory', 'abstract-algebra']"
206225,Testing local freeness on curves,"Let $X$ be a smooth variety (over an algebraically closed field, if it makes a difference), and $\mathscr{F}$ a coherent sheaf on $X$. I have heard it claimed that $\mathscr{F}$ is locally free if and only if for all morphisms $f : C \to X$ with $C$ a smooth curve, the pullback $f^*\mathscr{F}$ is locally free. How does one prove such a thing? It is enough to show something like the following: if $M$ is a finitely generated module over a regular local ring $A$, and for every $A$-algebra $B$ which is a discrete valuation ring the tensor product $B \otimes_A M$ is free, then $M$ is free. But that's as far as I can see.","['algebraic-geometry', 'coherent-sheaves', 'algebraic-curves']"
206229,Arithmetic Mean & Geometric Mean,"Question 1: if the arithmetic mean of two numbers is twice of their geometric mean, their ratio of sum of numbers to the difference of numbers equals? Question 2: if the quadratic equation: $(b^2+c^2)x2-2(a+b)cx+(c^2+a^2)=0$ has equal roots then?what is its AP & GP? Question 3: If the expansion of: $(1+x)^{50}$ let S be the sum of the coefficient of the odd power of x, then S will be? Please help with this problems in brief.
-Thanks.","['means', 'algebra-precalculus']"
206243,Embeddings of bundles in projective space.,"Consider the projective variety $X = \mathbb{P}^2$, and the line bundle $\mathcal{O}_X(dH)$ where $H$ is a plane and $d \in \mathbb{N}$. Let $L$ be the total space of $\mathcal{O}_X(dH)$. I know how to form this in the following way: Let $U_i$ be the standard affine opens of $X$, then
$$
L = \coprod (U_i \times \mathbb{A}^1)/\sim
$$
where the equivalence is given by the glueiing matrices $A_{ij}= (x_j/x_i)^d$. I am pretty sure the total space is a quasi-projective variety. Can anybody give me an explicit embedding? For my purposes i am happy with the cased $d \in \{1,2\}$, but a general treatment would be nice. Thanks. Edit: Projective changed to quasi projective.","['algebraic-geometry', 'vector-bundles']"
206245,Singularities of $e^{z - \frac{1}{z}}$,I believe $e^{z - \frac{1}{z}}$ has essential singularities at $z = 0$ and $z = \infty$ (in both cases because of a $\frac{1}{z}$ in the exponent) but I'm having a hard time proving this. How can one show this?,"['power-series', 'singularity-theory', 'complex-analysis']"
206263,"If $a^3 b = ba^3$ and if $ a $ has order 7, show that $ab = ba$","In a lecture my professor quickly went over the problem: Let $ a $ and $ b $ be elements of a group G. If $ a^3 b = ba^3 $ and if a has order 7, show that $ ab = ba $ . The sketch of a proof he wrote out went like this (this is what I have in my notes) Does $ (a^3)^2 = a^6 $ commute with $ b $ ? Well, $ a^6 = a^{-1} $ because $ a^7 = e $ So $ a^{-1}b = b a^{-1} $ so $ b = aba^{-1} $ so $ ba = ab $ I don't completely follow. It seems like this should be basic, but it isn't for me. By writing out $ (a^3)^2 $ it seem to imply that he could substitute $ (a^3)^2 $ for $ a^3 $ and put it into the original equation. That doesn't make sense to me because I figured $ a^3 $ is a distinct element, not a variable. I am not sure how he is synthesizing the premises with $ a^6 = a^{-1} $ to find $ a^{-1}b = b a^{-1} $ . I am hoping for some help with that.","['group-theory', 'abstract-algebra']"
206284,Birational geometry as local algebraic geometry,"Technically birational geometry is local geometry of algebraic varieties, yet it feels completely different from local differential geometry, which is more or less trivial. Is there some subtle similarity between them?","['algebraic-geometry', 'differential-geometry']"
206299,What are the subsets of the unit circle that can be the points in which a power series is convergent?,"Let $A\subset\Bbb C$ be a subset of the unit circle. Consider the following condition on $A$. Cond. There exists a sequence $\{a_i\}_{i=1}^\infty$ of complex numbers such that $$\sum_{n=1}^\infty a_nz^n$$ is a power series with radius of convergence $1,$ and $A$ is exactly the subset of the unit circle in which the series converges. Are there any interesting conditions on a subset $A$ of the unit circle which imply, are implied by or are equivalent to Cond. ? I think all finite subsets of the circle have this property. What about the countable subsets? Does it have anything to do with measurability?","['power-series', 'circles', 'complex-analysis']"
206303,"Prove that if $X$ and $Y$ are Normal and independent random variables, $X+Y$ and $X-Y$ are independent","If $X \sim \mathrm{Normal}(\mu,\sigma^2)$ and $Y \sim \mathrm{Normal}(\mu,\sigma^2)$ are independent random variables, how do I prove that $X+Y$ and $X-Y$ are also independent? What happens with the independence between $X+Y$ and $X-Y$ when $X \sim \mathrm{Normal}(\mu_x,\sigma_x^2)$ and $Y \sim \mathrm{Normal}(\mu_y,\sigma_y^2) $ Thank you","['probability-theory', 'normal-distribution', 'probability-distributions', 'probability']"
206315,Linear Systems - Matrix Powers - Determinants,"Is there a simple way of determining the determinant of a matrix of the following form? $$
P=\left[x \mid Ax \mid A^2x \mid \cdots \mid A^{(n-1)}x \right]
$$ Here $A$ is an $n\times n$ matrix and $x$ is a $n\times 1$ vector. Can we represent $\det(P)$ as a function of $A$ and $x$?",['matrices']
206317,How old are they?,One man speaking to other: When you were born I was 20 years old. Today I am twice the age you were when I was the age you are now. What are the ages of both of them?,"['puzzle', 'algebra-precalculus']"
206343,"A tourist in France wants to visit 12 different cities, find the probability.","The Question : A tourist in France wants to visit 12 different cities. If the route is randomly selected, what is the probability that she will
  visit the cities in alphabetical order? I thought about this in two ways and I got two different answers, both of them look correct to me ! but only one is correct. 1/144 (12 cities times 12 times to make the arrangement) 1/479001600 (which is generated by the permutation 12 P 12) Which one is correct? and is there a better answer? Please explain how do you know if the problem is permutation or combination or just simple multiplication.",['statistics']
206344,Is the integral of a measurable function measurable?,"Let $f(t,x):(0,\infty) \times \mathbb{R}^d \rightarrow \mathbb{R}$ be a bounded and $\mathcal{B}([0,\infty))\otimes \mathcal{B}(\mathbb{R}^d)$-measurable function. Is the function
$$g(t,x) = \int_0^t f(s,x) ds $$
a $\mathcal{B}([0,\infty))\otimes \mathcal{B}(\mathbb{R}^d)$-measurable  function? Why?","['measure-theory', 'integration']"
206358,Characterizing the eigenvalues of matrix powers,"I can see that if $c$ is an eigenvalue of a matrix $A$, then $c^k$ will be an eigenvalue for the matrix $A^k$, but I'm curious about the reverse case. I checked for a simple rotation matrix counterclockwise by $180$ with single eigenvalue $-1$ that the rotation matrix counterclockwise by $\pi/2$ has eigenvalues $\pm i$. I don't expect it to be the case, though, that if $c$ is an eigenvalue for $A^k$ ($k > 1$), that $c^{1/k}$ are eigenvalues of $A$. The example I think of to contradict this is taking a $2 \times 2$ rotation matrix by $\pi / 3$, $A$, whose cube will have eigenvalue $-1$, which has three cube roots, which exceeds the possible number of eigenvalues of $A$. Is there, however, a more intuitive way to see this, or a weaker result which holds relating the eigenvalues in the reverse direction?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
206362,Smoothness and decay property of Fourier transformation,"If my memory serves I have heard something like ""the less smooth your function $f$ is, the worse its Fourier transform $\hat{f}$ decay because its Fourier transform $\hat{f}$ needs more waves of high frequency"". I now would like to formulate the claim above properly. I am interested in relation of smoothness and decay property of Fourier transformation. I think this can be rigorously shown by the fundamental properties of Fourier transformation: $\widehat{\partial_{x}^n f}(\xi)=(i\xi)^n\hat{f}(\xi)$ and 
  $\widehat{(i\xi)^n f}(\xi)=\partial_{x}^n\hat{f}(\xi)$ From these equalities how can one conclude smoothness and decay property of Fourier transformation?","['fourier-analysis', 'functional-analysis']"
206364,Find the eclipse focal point,"A conic with equation
  $$
a x^2 + b y^2 = c
$$
  has two focus points, where $a=4$, $b=24$ and $c=65$. One of those focus points has a positive x -coordinate. To two decimal places, what is the value of that positive x -coordinate? I got the answer as 14.83, seems a bit too big is that right?
The above answer is according to this in my textbook","['hyperbolic-geometry', 'geometry']"
206367,Permute the values in each row in a matrix such that the columns sum to the same amount.,"The general problem Given a matrix, I would like to permute the order of values in each row, so that all the columns of the matrix sums to the same value. A simple example For example, given: 0     0     2     6
 0     0     6    18
 0     0    10    30
 0     0    14    42
 0     0    18    54
 0     0    22    66 One solution is: 0     0     2     6
 0    18     6     0
30     0    10     0
42     0    14     0
 0    54    18     0
 0     0    22    66 Notice that each column sums to 72. Of course, the solution is not unique; one may permute the columns themselves to obtain different solutions, such as: 0     0     2     6
18     0     6     0
 0    30    10     0
 0    42    14     0
54     0    18     0
 0     0    22    66 The specific problem Here I am looking at a simple $30 \times 5$ matrix. The matrix is defined thus: the contents of row $n$ is $[0, 0, 2f(n), 6f(n), 12f(n)+2]$ where $f(n) = 4n^2+4n+1$ and $n = 0, 1, 2, ...,29$. Here is what the matrix looks like: 0           0           2           6          14
       0           0          18          54         110
       0           0          50         150         302
       0           0          98         294         590
       0           0         162         486         974
       0           0         242         726        1454
       0           0         338        1014        2030
       0           0         450        1350        2702
       0           0         578        1734        3470
       0           0         722        2166        4334
       0           0         882        2646        5294
       0           0        1058        3174        6350
       0           0        1250        3750        7502
       0           0        1458        4374        8750
       0           0        1682        5046       10094
       0           0        1922        5766       11534
       0           0        2178        6534       13070
       0           0        2450        7350       14702
       0           0        2738        8214       16430
       0           0        3042        9126       18254
       0           0        3362       10086       20174
       0           0        3698       11094       22190
       0           0        4050       12150       24302
       0           0        4418       13254       26510
       0           0        4802       14406       28814
       0           0        5202       15606       31214
       0           0        5618       16854       33710
       0           0        6050       18150       36302
       0           0        6498       19494       38990
       0           0        6962       20886       41774 Obviously, the desired sum for each column is equal to the sum of all elements in the matrix divided by the number of columns. Here it is $\frac{1}{5}\left(60 + 20\sum_{n=0}^{29} f(n)\right) = 143972$. We certainly cannot do this by brute force: For an $m\times n$ matrix the number of possibilities are: $(n!)^m$ which combinatorially explodes. Here, two of the columns given are zeros so we have $\left(\frac{n!}{2}\right)^m$ unique ways to permute the values of each row - which is not much better. Fortunately, this matrix has a well-defined pattern to it, and I am wondering: can this pattern can be exploited to derive solutions more easily? EDIT: I have made a recursive depth-first search to find solutions. On each iteration, it attempts to construct a vector that sums to the desired result (in this case 143972) by choosing each entry in the vector from a different row in the matrix. Once one such vector has been created, it removes the chosen entries from the matrix thereby changing it from an $m\times n$ matrix to an $m \times n-1$ one. This repeats until either no solution can be found, or a the matrix becomes empty. In the worst case, it runs on the order of $n^m$ for an $m\times n$ matrix (but it turns out that finding one solution is fast because my matrix has many, many solutions apparently). Here are three sample solutions I have found using this approach: Solution 1 6          14           0           0           2
       0          54          18         110           0
      50           0           0         302         150
       0           0          98         590         294
       0           0         162         486         974
       0           0         242        1454         726
     338           0        1014           0        2030
       0         450           0        2702        1350
       0           0         578        1734        3470
       0           0         722        2166        4334
       0           0         882        2646        5294
       0           0        1058        3174        6350
       0           0        1250        3750        7502
       0           0        1458        4374        8750
       0           0        1682        5046       10094
       0           0        1922       11534        5766
       0        2178           0        6534       13070
       0           0        2450        7350       14702
       0           0        2738       16430        8214
       0           0        3042       18254        9126
    3362           0       20174       10086           0
       0        3698       22190       11094           0
       0       12150       24302        4050           0
       0       26510       13254        4418           0
       0       28814       14406        4802           0
   31214       15606        5202           0           0
   33710       16854        5618           0           0
   36302       18150        6050           0           0
   38990       19494        6498           0           0
       0           0        6962       20886       41774 Solution 2 6           0           2           0          14
       0         110           0          54          18
       0         150           0          50         302
     294         590           0           0          98
     486         974           0         162           0
     726         242        1454           0           0
    1014        2030           0         338           0
    2702         450        1350           0           0
    1734        3470         578           0           0
    4334        2166         722           0           0
    5294        2646         882           0           0
    3174        6350        1058           0           0
    7502        3750        1250           0           0
    8750        4374           0        1458           0
   10094        5046        1682           0           0
   11534        5766        1922           0           0
   13070        6534        2178           0           0
   14702        7350        2450           0           0
   16430        8214        2738           0           0
   18254        9126        3042           0           0
   20174       10086        3362           0           0
    3698       22190       11094           0           0
       0       24302       12150        4050           0
       0       13254       26510           0        4418
       0        4802       28814       14406           0
       0           0       15606       31214        5202
       0           0        5618       33710       16854
       0           0        6050       18150       36302
       0           0        6498       19494       38990
       0           0        6962       20886       41774 Solution 3 0          14           0           6           2
       0          18         110           0          54
       0           0         302         150          50
       0         590         294          98           0
     162         974           0         486           0
    1454         242         726           0           0
       0        1014        2030         338           0
     450        1350        2702           0           0
       0        1734        3470           0         578
     722        4334        2166           0           0
       0        2646        5294         882           0
    1058        3174        6350           0           0
       0        3750        7502        1250           0
    1458        4374        8750           0           0
       0        5046       10094        1682           0
    5766       11534        1922           0           0
    2178           0       13070        6534           0
    7350       14702        2450           0           0
       0        2738        8214       16430           0
   18254        9126        3042           0           0
       0        3362       10086       20174           0
   11094       22190        3698           0           0
       0        4050       12150       24302           0
   26510       13254        4418           0           0
       0           0        4802       14406       28814
   31214       15606        5202           0           0
       0           0        5618       16854       33710
   36302       18150        6050           0           0
       0           0        6498       19494       38990
       0           0        6962       20886       41774 But I still don't know whether there's a way to count the number of solutions, or how to generate more solutions more efficiently. And my depth-first-search algorithm is a rather brute-force way that doesn't take advantage of the known sequence that the original matrix is made up of.","['matrices', 'sequences-and-series', 'algorithms', 'combinatorics']"
206377,1-1 functions and Schroder-Bernstein Theorem,"Using Schroder-Bernsten Theorem. Assume there exists a 1-1 function $f:X \rightarrow Y$ and another 1-1 function $g:Y \rightarrow X$. If we define $f^{(-1)}(y)=x$, then $f^{(-1)}$ is a 1-1 function from $f(X)$ onto $X$. Follow the steps to show that there exists a 1-1, onto function $h:X \rightarrow Y$. I'm asking about part (a) of the problem: Let $x$ be in $X$ be arbitrary. Let the chain $Cx$ be the set consisting of all elements of the form $$
....,\, f^{(-1)}(g^{(-1)}(x)),\, g^{(-1)}(x),\,x,\,f(x), g(f(x)),\,f(g(f(x))),\,....
$$ Explain why the (distinct) number of elements to the left of $x$ in the above chain may be zero, finite, or infinite. Since the functions are 1-1, say $x$ map to a distinct $y$ in $Y$. 
So evaluating the chain (the $x$ in bold separates the left and right sides of the chain), you get:
$$
                ....x,\, y,\, \textbf{x},\, y,\, x,\, y,\, ...
$$
The left side of the chain is obviously composed of the $x$ and $y$ predefined above. I don't really understand what the question means. My interpretation is that the left side of the chain is finite because the functions, being 1-1, map a distinct $x$ to a distinct $y$, so those are finitely many elements (2 in this case). But I'm not sure if I'm right. Any input?
Thanks. Edit: Sorry I didn't mention that g^(-1) is also a 1-1 function, defined
          g^(-1): g(X)->Y","['elementary-set-theory', 'functions', 'analysis']"
206394,"Find a $4\times 4$ matrix $A$ where $A\neq I$ and $A^2 \neq I$, but $A^3 = I$.","Give an example of a $4 \times 4$ matrix where $A \neq I$, $A^2 \neq I$, and $A^3 = I$. I found a $2 \times 2$ matrix where $A \neq I$ and $A^2 = I$, but this problem is more complex and has me completely stumped.",['linear-algebra']
206397,What does $c.c.$ mean in this proof?,"This is a proof from Wikipedia of Moore-Penrose inverse being the optimal solution of a least squares problem, in which there is a acronym $c.c.$ occurred in some of the equations. Mind if I ask what does that represent?","['notation', 'linear-algebra']"
206406,What if every function in $C(X)$ has finite spectrum?,"Suppose that $X$ is a compact Hausdorf space, and that every continuous function on $X$ has finite range.  How do I conclude that $X$ is a finite set, hence with discrete topology?  So far, I have managed to use Urysohn to show that the closed maximal connected component decomposition of $X$ (as opposed to the path component decomposition) is one where every component is a 1 point set. This question arose from trying to solve the question that every C* algebra with all normal elements having finite spectra are finite dimensional.  A more direct solution to this general question would also suffice, because actually implies the special case I've reduced it to.  By taking a unitization, and then a MASA in the unitization, one gets to the case I've gotten to. Also, a topological question that is in the same setup but handles a related operator algebras question is this: if a net $u_i$ and $u$ in $X$ has the property that for all continuous $f \in C(X)$ one has that $f(u_i)$ converges to $f(u)$ then must $u_i$ converge to $u$ in topology?  This is for showing that the gelfand representation of a $C(X)$ space is itself.  I'd like this fact for $X$ locally compact Hausdorf, actually.","['general-topology', 'operator-algebras', 'functional-analysis']"
206411,Taking the exterior derivative of a 0-form,"I'm attempting to show that $dg(\vec{x})=\alpha$, where $\alpha=\Sigma^n_{i=1}f_idx_i$ and $g(\vec x)={1\over{p+1}}\Sigma_{i=1}^nx_if_i(\vec x)$...and $d$ is the exterior derivative.  The $f_i$ are all smooth and homogeneous of the same ($p\neq-1)$) degree, i.e. $f_i(t\vec x)=t^pf_i(\vec x)$. This latter fact gives us that $\large\Sigma_{j=1}^nx_j{\partial f_i\over \partial x_j}(\vec x)=pf_i(\vec x)$. I don't know whether it's all the summations involved or what, but I can't seem to get this to work out.  It so happens that I always have the j's and i's mixed in the wrong way...This might indicate that the question isn't true as stated...or more likely that I'm failing at some fairly basic bookkeeping. In the end I keep ending up with $\large dg={1\over{p+1}}\Sigma^n_{j=1}\Sigma^n_{i=1}x_i{\partial f_i\over \partial x_j}dx_j+f_i$, which won't really allow me to use any of the nice identities I've earned.","['multivariable-calculus', 'differential-forms', 'exterior-algebra']"
206486,Multivariate Taylor Polynomials,"Let $f: \mathbb{R}^n \to \mathbb{R}$ and additionally suppose that $f \in \mathcal{C}^{\infty}(\mathbb{R}^n)$. Given a point $a \in \mathbb{R}^n$, let the $l$-th Taylor polynomial of $f$ about $a$, $T_{a,l} : \mathbb{R}^n \to \mathbb{R}$ be given by: $$T_{a,l}(x) = f(a) + \sum_{|z|=1}^l \frac{1}{z!} \frac{ \partial^{z} f}{\partial x^{z}}(a)(x-a)^{z}$$ where $z$ is an $n$-dimensional multi-index. I would like to prove that $$\lim_{h \to 0} \frac{f(a+h)-T_{a,l}(a+h)}{||h||^l}=0$$ Any hints?","['multivariable-calculus', 'real-analysis']"
206508,A Continuity Argument in the Proof of Rouche's Theorem,"In Greene and Krantz's Function Theory of One Complex Variable , the proof of Rouche's theorem involves the following continuity argument. Let $f,g\colon U \to \mathbb{C}$ be holomorphic from an open set $U$. Let $\bar{D}(p,r) \subseteq U$, and 
  \begin{equation} 
\vert f(\zeta) - g(\zeta) \vert \le \vert f(\zeta) + g(\zeta) \vert
\end{equation} 
  for $\zeta \in \partial D(p,r).$ Define
  $$ f_t (\zeta) = tf(\zeta) + (1-t)\,g(\zeta), $$
  for $t\in [0,1]$. 
  Then the integral 
  $$ I_t = \frac{1}{2\pi i} \oint_{\partial D(p,r)} \frac{f'_t (\zeta)}{f_t (\zeta)}\,d\zeta $$
  is a continuous function of $t\in [0,1]$. They add in parenthases that the denominator does not vanish and the integrand depends continuously on $t$. Question: Would anyone be kind enough to supply the details behind this continuity of $I_t$ ?","['continuity', 'complex-analysis']"
206522,Ignoring $\max$ for discrete random variables,"Let $X,Y,Z$ be independent discrete random variables with $X\sim\text{Bin}(6,7/8),$ $Y\sim\text{Bin}(5,7/8)$ and $Z\sim\text{Geo(1/4)}$. Futhermore let $M:=\max(X+Y,Z)$. Compute $\Pr[M>10]$. My approach so far based on the fact that $X+Y\sim\text{Bin}(11,7/8)$: $$\Pr[M>10] = 1-\Pr[M\leq 10]=1-\Pr[X+Y\leq 10]\cdot\Pr[Z\leq 10]\\
\Pr[X+Y\leq 10] = 1-\Pr[X+Y=11]=1-(7/8)^{11}\approx 0.7698\\
\Pr[Z\leq 10]=1-(1-1/4)^{10}\approx 0.9437\\
\Longrightarrow \Pr[M>10]\approx 1-0.7698\cdot 0.9437=0.2735$$ However I think this cannot be true because I haven't considered $\max$ yet. Can anyone explain me what did I miss?","['probability-theory', 'discrete-mathematics', 'probability', 'random-variables']"
206523,Calculate a sum involving nth root of unity,"Calculate
$$1+2\epsilon+3\epsilon^{2}+\cdots+n\epsilon^{n-1}$$
Where $\epsilon$ is nth root of unity.
There is a hint that says: multiply by $(1-\epsilon)$ Doing this multiplication I get:
$$1+\epsilon+\epsilon^{2}+\epsilon^{3}+\cdots+\epsilon^{n-1}-n$$
The answer is: $-\frac{n}{1-\epsilon} $if $ \epsilon\neq1$ and $\frac{n(n+1)}{2}$ if $\epsilon=1$.
I can't see how to get this result...","['complex-numbers', 'complex-analysis']"
206538,Copies of $\ell_p$ in spaces with unconditional basis,"Is there a Banach space with an unconditional basis which contains an isomorphic copy of $\ell_p$ (for some $p\in (1,\infty)$) but such that no copy of $\ell_p$ is complemented?","['functional-analysis', 'banach-spaces']"
206550,Paley-Wiener type theorems for distributions?,"In general a theorem of Paley-Wiener type gives a relation between the decay of a function and the smoothness of its Fourier transformation, and there are plenty of them since there are many kinds of bound for decay rates of functions and many types of characterizations of smoothness. However,when the objects are tempered distributions I only know one such theorem, the one given in Wiki page as Schwartz's Paley-Wiener theorem , which deals only with the case of compact support distributions. I wonder whether there are other Paley-Wiener type theorems for distributions that might be less restrictive. Thanks!","['big-list', 'distribution-theory', 'fourier-analysis', 'functional-analysis']"
206552,Convergence in $L_\infty$ and $L_1$ even if infinite measure space,"Let $\{f_n\}_{n\in \mathbb{N}}$ be a sequence of measurable functions on a measure space and $f$ measurable.
In the literature, assuming the measure space $X$ has finite measure, if $f_n$ converges to $f$ in $L^{\infty}$-norm , then $f_n$ converges to $f$ in $L^{1}$-norm. Even if $X$ has infinite measure, does it converge to $f$ in $L^{1}$-norm?","['normed-spaces', 'measure-theory', 'convergence-divergence']"
206559,A question about finding a countable collection of open sets where intersection equal to S [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: How would one go about proving that the rationals are not the countable intersection of open sets? As the topic, prove that set $S$ of rational numbers in the interval (0,1), cannot be expressed as the intersection of a countable collection of open sets.",['general-topology']
206601,Deduce a unique number from number,"I work on the tree where each node has N children. In my case each node has a unique identifier. i want to deduce an identifier of father node from the child identifier. So, we can add an information on child identifier to deduce that for example: if the father's node is ""123"", the child node is ""123.3"" and then we deduce that the father of (123.3) is ""123"". but there is a problem where we have a large tree, then a node identifier can be ""12.3.4.1.2.4.5..."", not be a good solution. What would be the best approach to generate a child identifier with a simple number and then deduce the father identifier (considering that it is unique in the entire tree)?","['number-theory', 'combinatorics']"
206618,Positive outer measure set and nonmeasurable subset,"I'm attending a course of Measure and Integration and have some homework to do.
We don't have a specific book to follow, neither for exercise. I'm asked to proof that every set $A\subseteq\mathbb{R}$ with strictly positive outer measure contains a set nonmeasurable (Lebesgue). I thought about the Cantor set.
Thinking that A is homeomorphic to Cantor set and about sharing $[0,1]$ with a numerable family of copies disjointed of A.
But honestly I'm not sure how to do exactly, and I would like to get a precise answer 'cause I'll have to explain in a foreigner language so the better my notes are the easier it will be. I checked other questions on this website before asking without finding anything, just some references to this property as known; probably it's my fault, so if somebody knows where to find the answer please let me know. Update:
May be is not clear but A is strictly positive in the outer Lebesgue measure and I think that the subset has to be strictly included.","['measure-theory', 'real-analysis']"
206623,Solution to $AX=XB$ for $3\times3$ rotation matrices.,"Given the $3\times3$ rotation matrices $A$ and $B$, find the rotation matrix $X$ that satisfies $$AX=XB.$$","['matrix-equations', 'matrices', 'linear-algebra', 'rotations']"
206624,Differential equation $y''=\frac{1}{y^2}$,Please help me to solve the differential equation $$y''=\frac{1}{y^2}$$ Thank you very much!,['ordinary-differential-equations']
206641,Prove $\ell_1$ is first category in $\ell_2$,"Prove that $\ell_1$ is first category in $\ell_2$. I tried to solve this, but had no idea about the approach. Any suggestions are helpful. 
Thanks in advance.","['baire-category', 'functional-analysis', 'analysis']"
206645,Help understanding divisibility proofs,"Can someone please explain how to do this problem? Prove or disprove the statement If $a \mid b$ and $c \mid d$, then $(a + c)\mid(b + d)$.","['discrete-mathematics', 'divisibility']"
206650,What is the definition of a linear function?,"I'm curious what the definition of a linear function really is? I always hear that a linear function is a ""straight line."" That really isn't a definition- just a result. Based on the real definition, how is an inversely proportional function not linear (i.e. $y=(a/x)$?","['algebra-precalculus', 'functions']"
206652,"If composition of one function and the other holomorphic function is holomorphic, then the other should be holomorphic?","Actually, this is an exercise on Rudin's Real and Complex Analysis : Suppose $\Omega_1, \Omega_2$ are plane regions, $f$ and $g$ are nonconstant complex functions in $\Omega_1$, $\Omega_2$ resp. and $f(\Omega_1) \subset \Omega_2$, so that $h=g \circ f$ can be defined. If we know that $f$ and $h$ are holomorphic, is $g$ holomorphic as well? What if we know that $g$ and $h$ are holomorphic? The easiest example will be a constant function, but the problem does not allow this. I found it difficult to find counter examples. Can anyone help me?",['complex-analysis']
206659,Dividing circle into six equal parts and know the coordinates of each diving point ...,"I have a circle who center $(0, 0)$ and radius $100$ are known. That circle is divided into $6$ equal parts. I want to know the coordinates of all six points on the circle that divides it into $6$ parts. Can anyone please tell me the formula for this as I need to do this in a javscript code. Also give a  formula for doing the same thing with ellipse given the same data, center $(0, 0)$, $x$-radius and $y$-radius are known.","['geometry', 'circles']"
206660,Simultaneous diagonalization of quadratic forms,"I would like to collect references (or direct quotations) about as many ""simultaneous diagonalization"" results in linear algebra as possible. Let $V$ be an $n$ -dimentional ( $n$ finite) vector space over the field $\mathbb{K}$ .
Note that if the characteristic of $\mathbb{K}$ is $\neq$ from $2$ then speaking of quadratic forms is essentially the same as speaking of bilinear forms. Theorem 1. Let $\mathcal{S}$ be a set of diagonalizable operators on $V$ . Then $\mathcal{S}$ is simultaneously diagonalizable if and only if it commutes (i.e. $AB=BA\;\;\; \forall A,B\in\mathcal{S}$ ). Theorem 2. Let $\mathbb{K}=\mathbb{C}$ . Let $\langle\;|\;\rangle$ be a non-degenerate symmetric bilinear form and $b$ any symmetric bilinear form on $V$ . Write $b(\cdot,\cdot)=\langle A\cdot|\cdot\rangle$ for a $\langle\;|\;\rangle$ -symmetric operator $A$ . Suppose $A$ is diagonalizable with distinct eigenvalues $\lambda_1,\dots , \lambda_n$ . Then there is a $\langle\;|\;\rangle$ -orthonormal basis $\mathcal{B}$ in which the matrix of $b$ is diagonal with diagonal entries $\lambda_1,\dots , \lambda_n$ . Proof 2. Let $\mathcal{B}=\{ v_1,\dots , v_n \}$ a basis of eigenvectors for $A$ , with distinct eigenvalues $\lambda_1, \dots , \lambda_n$ . Then $\lambda_l\cdot\langle v_l|v_k \rangle=\langle \lambda_l\cdot v_l|v_k \rangle=\langle A(v_l) |v_k \rangle=\langle v_l |A^{T}(v_k) \rangle=\langle v_l| A(v_k)\rangle=\lambda_k\cdot\langle v_l|v_k \rangle$ , hence $(\lambda_l-\lambda_k)\cdot\langle v_l|v_k \rangle=0$ for all $l,k$ . Then eigenvectors of distinct eigenvalues are orthogonal. Furthermore, $\langle v_i|v_i \rangle\neq 0$ for all $i$ or $v_i$ would be orthogonal to $\mathcal{B}$ for some $i$ . Now let $\xi_i$ be a square root of $\lambda_i$ in $\mathbb{C}$ , and set $w_i:=\frac{1}{\xi_i}\cdot v_i$ . Then $\{ w_1,\dots , w_n \}$ is the basis we are seeking. Theorem 3. Let $\mathbb{K}=\mathbb{R}$ . Let $q$ be an indefinite quadratic form and $q'$ any quadratic form on $V$ . Suppose that, for every $v\in V$ , $q(v)=0$ implies $q'(v)=0$ . Then there is $\alpha\in\mathbb{R}$ such that $q'=\alpha \cdot q$ . Furthermore, if $\alpha\neq 0$ , also $q'$ is indefinite and, for all $v \in V$ , $q(v)=0$ if and only if $q'(v)=0$ . Note that in particular, by Sylvester's theorem, $q$ and $q'$ are simultaneously diagonalizable. Proof 3. See Elton, Indefinite quadratic forms and the invariance of the interval in Special Relativity . Theorem 4. Let $\mathbb{K}=\mathbb{R}$ . Let $q$ and $q'$ be two semidefinite quadratic forms on $V$ . Suppose that for all $v\in V$ $q(v)=0$ implies $q'(v)=0$ . Then $q$ and $q'$ are simultaneosly diagonalizable. Proof 4. See Elton, Indefinite quadratic forms and the invariance of the interval in Special Relativity . Theorem 5. Let $\mathbb{K}=\mathbb{R}$ . Let $\langle\;|\;\rangle$ be a non-degenerate symmetric bilinear form and $b$ any symmetric bilinear form on $V$ . Then there is a $\langle\;|\;\rangle$ -orthonormal basis $\mathcal{B}$ of $V$ in which the matrix of $b$ is diagonal. Proof 5. Write $b(\cdot,\cdot)=\langle A\cdot|\cdot\rangle$ for a $\langle\;|\;\rangle$ -symmetric operator $A$ . Then by the Spectral Theorem for real symmetric operators there is a $\langle\;|\;\rangle$ -orthogonal basis $\mathcal{B}=\{ e_1, \dots, e_n \}$ in which the matrix of $A$ is diagonal with diagonal entries $\lambda_1,\dots , \lambda_n$ . Then $b(e_i,e_j)=\langle Ae_i|e_j \rangle=\lambda_i\cdot\langle e_i|e_j \rangle=\lambda_i\cdot\delta_{ij}$ ( $\delta_{ij}$ is Kronecker's symbol), hence $\mathcal{B}$ diagonalizes $b$ . Theorem 6. Let $\mathbb{K}=\mathbb{C}$ . Let $\langle\;|\;\rangle$ be a Hermitian (i.e. a sesquilinear positive definite) form and $b$ any sesquilinear form on $V$ . Then there is a $\langle\;|\;\rangle$ -orthonormal basis $\mathcal{B}$ of $V$ in which the matrix of $b$ is diagonal. Proof 6. As in Theorem 5. but using the Spectral Theorem for Hermitian operators instead. Edit: I have collected two more theorems. Theorem 7. Let $\mathbb{K}$ be of characteristic $\neq 2$ . Let $\langle\; |\; \rangle_1$ , $\langle\; |\; \rangle_2$ be two non degenerate symmetric bilinear forms on $V$ . Let $\Phi_i:V\to V^*, v\mapsto \langle v | \;\rangle_i$ , $i=1,2$ . Then $\langle\; | \;\rangle_1$ and $\langle\; | \;\rangle_2$ are simultaneously diagonalizable if and only if $\Phi_2^{-1}\circ\Phi_1\in \mathrm{Aut}(V)$ is diagonalizable as an operator. Proof 7. See M.J.Wonenburger, Simultaneous Diagonalization of Symmetric Bilinear Forms . Remark: Note that $\Phi_2^{-1}\circ\Phi_1$ is symmetric w.r.t. $\langle\; | \;\rangle_2$ , and $\Phi_1^{-1}\circ\Phi_2$ is symmetric w.r.t. $\langle\; | \;\rangle_1$ . So, in case $\mathbb{K}=\mathbb{R}$ , we recover part of Theorem 5. Theorem 8. Let $\mathbb{K}$ be a real closed field . Let $f_1, f_2$ be two quadratic forms on $V$ such that there is no $v\neq 0$ in $V$ for which $f_1(v)=f_2(v)=0$ . Suppose $n=\dim V>2$ , then $f_1$ and $f_2$ are simultaneously diagonalizable. Proof 8. See M.J.Wonenburger, Simultaneous Diagonalization of Symmetric Bilinear Forms . Q1. I would like to know other theorems like the above ones (not deriving from them in a tautological way). Q2. Is there a more general theorem on the topic that treats all fields at once and reduces to (a subset of) the above theorems by specialization? Q3. What happens in characteristic $2$ ?","['quadratic-forms', 'linear-algebra']"
206668,Classic Hand shake question,"I am asked the following question: My wife and I were invited to a party attended by four other
  husband-wife couples, making a total of ten people. As people arrived,
  there was some hand shaking. No one shook their own hand, and there
  were no husband-wife hand shakes. When it was over, I asked each
  person ""How many people did you shake hands with?"" I asked nine people
  (not including myself) and got nine different answers. How many people
  did my wife shake hands with? Since there are 10 people in the room should I use the formula n(n-1)2 , which results in 10(10-1)/2=45 which would be the sum of all the handshakes. If I divide that by ten I would get 4.5 people shook his wife's hand. This doesn't seem correct at all. What is the right direction to head in order to solve this question? EDIT: I ended up trying to solve by pairing everyone together and drawing a graph showing the relations between everyone: But this wasn't complete apparently.",['discrete-mathematics']
206681,Why is kernel important? [closed],"It's difficult to tell what is being asked here. This question is ambiguous, vague, incomplete, overly broad, or rhetorical and cannot be reasonably answered in its current form. For help clarifying this question so that it can be reopened, visit the help center . Closed 11 years ago . Why are we interested in looking at the kernel and range (image) of a linear transformation on a linear algebra course?","['linear-algebra', 'soft-question']"
206701,"Completing $\Bbb R$ when some ""divergent"" sequences are Cauchy sequences","If I equip $\mathbb{R}$ with the metric $$
\rho(x,y) := \left|\arctan(x) - \arctan(y)\right|
$$ then sequences like for example $x_n = n$ are Cauchy sequences, so it is clear that $\mathbb{R}$ is not complete with respect to this metric. I need to give the completion, and it seems to be rather immediate that it can only be the extended real line. (where else could a non-oscillating non convergent sequence tend to after all ?) I am a little unhappy with my reasoning, how would I rigorously construct the completion? I would be very grateful for some hints.","['metric-spaces', 'sequences-and-series', 'real-analysis', 'analysis']"
206770,Lebesgue Measure of a ball in $\mathbb{R}^n$,"What is the relationship between the Lebesgue measure of a ball in $\mathbb{R}^n$ to the measure of a sphere? I've derived the measure of a sphere $S^{n-1}$ in $\mathbb{R}^n$ to be $\frac{2\pi^{n/2}}{\Gamma(n/2)}$, but I don't know how to relate the two. Please help and thanks in advance!",['measure-theory']
206772,Complete set of equivalence class representative,"Let  $\sim$ be a relation on $\mathbb{R}$ and $x\sim y$ if and only if $x-y\in \mathbb{Z}$. (a) Show that $\sim$ is an equivalence relation (b) Give a complete set of equivalence class representatives. (a) is easy to show, but I really dont understand (b). I know that: $$[a]_{\sim}:=\{y\in \mathbb{R} \mid a\sim y\}$$ so $$[0]_{\sim}=\{\dots,-2,-1,0,1,2,\dots\}$$ and that $$\dots=[-2]_{\sim}=[-1]_{\sim}=[0]_{\sim}=[1]_{\sim}=[2]_{\sim}=\,\dots$$ because if $x\sim y$ then $[x]=[y]$. But how can I find a complete set of equivalence class representatives? Thanks in advance!","['elementary-set-theory', 'abstract-algebra']"
206778,Common Ground between Real Analysis and Measure Theory,"I'm currently taking two introductory classes in Real Analysis (Rudin textbook) and Measure Theory (no textbook - but the material we cover is very standard). It seems as if there is a huge overlap between the material that is covered in both classes. In particular, I believe that Measure Theory is more of a specific application of Real Analysis. That said, I'm having a lot of difficulty seeing how the two fields relate to one another. This is all very broad, so here are some questions that I have: Are $\sigma$-fields a subtype of field? What are the ""real analysis"" type properties of a Borel set? (i.e. is it closed? open?compact?)"" What are the ""real analysis"" type properties of a Random Variable? What are the ""real analysis""-type properties of a Measure? Have I even covered enough material to see the ""common ground"" between these subjects? (in Real Analysis, we've covered Ch. 1-2 of Rudin and in Measure Theory, we've covered probability spaces and random variables). Any other insights are very much appreciated!","['measure-theory', 'real-analysis']"
206783,Find two other linearly independent solutions to the second order differential equation,"Fnd a general solution to the dierential equation $y'' - y' - 2y = 0$. Then, use the two solutions you found to write two other linearly independent solutions to the problem. Write a second general solution using your new linearly independent solutions. We have the characteristic equation: $r^2 - r - 2 = 0$ $(r-2)(r+1) = 0$ Thus, we have real, distinct roots $r_1 = 2$ and $r_2 = -1$.  Our independent solutions are then $c_1e^{r_1x}$ and $c_2e^{r_2x}$ and so our general solution is $y(x) = c_1e^{r_1x} + c_2e^{r_2x}$. Now, I'm just unsure how I would go about writing two other linearly independent solutions and the second general solution.  Can I just substitute two random values for $c_1$ and $c_2$? Thank you!",['ordinary-differential-equations']
206787,An injective map where each value is mapped to many others?,"I want ""something"" (""something"" because maybe it is not really a mathematical function, called F in the above image) that can describe what is shown on the image. A given value from a domain Xi can be mapped to many values of domain X{i+1}, and for two values $x \neq x'$, then $F(x) \neq F(x')$ It also should be invertible, i.e. $F^{-1}$ exists. Is it possible to have this ? If not, how can I have an alternative for this with something possible in the mathematics ? Maybe using a function where the elements of the codomain are vectors ? ... EDIT: I'm not just seeking a name for that. Let's call it a ""relation"". I want to define a relation F that allow me to generate a set of numbers $y1, y2, y3$ given a number x (that is, F(x) = {y1, y2, y3}), and I want it to be invertible, that is $F^{-1}(y1) = x$, $F^{-1}(y2) = x$ and $F^{-1}(y3) = x$. This numbers (elements of each domain $X_i$) may be natural, real, complex, or whatever ... Also, note that the domains $X_i$ does not overlap, that is elements are unique: for any given element x from $X_i$, there is no element y in any other $X_j$ such that x=y.","['applications', 'special-functions', 'functions', 'abstract-algebra', 'generating-functions']"
206790,Radon-Nikodym derivative relationship between two Gaussian measures,"I am trying to find out the the Radon-Nikodym derivative of $_1$ w.r.t $_2$ where  $_1$ is a Gaussian measure on $R^n$ with mean $a$, and standard deviation $$, and $_2$ is also a Gaussian measure, with mean $b$ and standard deviation $$. Solution Attempt Let $n\in N$ and let $B_0(R^n)$ denote the completion of the Borel $\sigma$-algebra on $R^n$. Let $\lambda^n:B_0(R^n)\rightarrow[0,R^+]$ denote the usual $n$-dimensional Lebesgue measure. Based on the definition of Gaussian measure and it's properties we know the following two equivalent relations 
$\lambda^{n} \ll \mu_1^{n} \ll \lambda^{n}$ and 
$\lambda^{n} \ll \mu_2^{n} \ll \lambda^{n}$ where $\ll$ stands for absolute continuity of measures;
Hence we have absolute continuity relations $\mu_1^{n} \ll \lambda^{n}$ and $\lambda^{n} \ll \mu_2^{n}$. Also since $\lambda^{n} \ll \mu_1^{n} \ll \lambda^{n}$
we can use the Radon-Nikodym property $\dfrac {d\lambda } {d\mu_1}=\left( \dfrac {d{\mu_1}} {d\lambda }\right) ^{-1}$ Since both Lebesgue and Gaussian measures are $\sigma$-finite and based on the above relations we should be apply the Radon-Nikodym Chain Rule here.
$$\dfrac {d\mu_2 } {d\mu_1} = \dfrac {d\mu_2 } {d\lambda}\dfrac {d\lambda } {d\mu_1} = \dfrac {d\mu_2 } {d\lambda}\left( \dfrac {d{\mu_1}} {d\lambda }\right) ^{-1}$$ The Gaussian measures $_1:B_0(R^n)\rightarrow[0,R^+]$ and $_2:B_0(R^n)\rightarrow[0,R^+]$ are defined as ${\mu_1}(E) = (2\pi{\sigma}^2)^\frac{-n}{2}\int _{E}exp\left( -\dfrac {1} {2\sigma ^{2}}\left\| x-a\right\| _{R_{n}}^{2}\right)d\lambda ^{n}\left( x\right)  $ and 
${\mu_2}(E) = (2\pi{\sigma}^2)^\frac{-n}{2}\int _{E}exp\left( -\dfrac {1} {2\sigma ^{2}}\left\| x-b\right\| _{R_{n}}^{2}\right)d\lambda ^{n}\left( x\right)  $ respectively. I am unsure though how to proceed further here, any help would be much appreciated. Thanks in advance.","['probability-theory', 'measure-theory']"
206792,"Are any of these notions of ""k-space"" equivalent if $X$ is not assumed weakly Hausdorff?","Is there a modern generally accepted answer regarding the notions of k-space or compactly generated space? For example there are currently at least 3 formally distinct notions of k-space in wide circulation: In Kelley's General Topology , $X$ is a k-space if for $S \subseteq X$ not closed in $X$ there is a closed compact subspace $C \subseteq X$ such that $C \cap S$ is not closed in $X$ . (This notion of k-space also appears in A. Wilansky's _Between T 1 nd T 2 (Amer. Math. Monthly, vol.74, no.3, pp.261-266).) According to nLab , $X$ is a k-space if whenever $S \subseteq X$ is not closed in $X$ , there exists a compact Hausdorff space $K$ and a map $f:K \to X$ such that the preimage of $S$ is not compact. This is equivalent to $X$ being compactly generated (CG) in Neil Strickland's note The category of CGWH spaces . Wikipedia declares that $X$ is a k-space (or a compactly generated space ) provided that whenever $S \subseteq X$ is not closed in $X$ , then there exists a compact subspace $C$ of $X$ , such that the intersection of $C$ and $S$ is not compact. Are any of definitions 1,2,3 equivalent if $X$ is not weakly Hausdorff?",['general-topology']
206798,Pulling cards from a deck without replacement to reach a goal: average draws needed?,"I have the following probability problem that I think must be quite common. The problem is as follows: Let's say I have a goal of drawing 3 jacks from a regular deck of 52 cards (in which there are 4 jacks). I conduct many experiments. In each experiment, I shuffle the deck and pull cards one-by-one and discard the card without replacement. When I reach my goal of having pulled 3
  jacks, I write down the number of cards I had needed to pull and stop the experiment . e.g. in the first experiment I might have hit the 3rd jack on the 40th card, so I write down '40'. I repeat this infinite times, and then average the number of cards pulled to reach 3 jacks. On average, how many cards did I need to pull before reaching 3 jacks? Note that I am stopping after pulling the third jack, so my last draw must be a successful jack draw. I think I can solve this problem using hypergeometric distributions, but the solution is ugly and complicated (it gives 31.8 draws on average are needed, which matches Monte Carlo simulations a colleague ran for me). I think I've stumbled upon a much simpler formula: average draws needed =  (n) * (x+1)/(y+1) where n is the number of jacks I want (3), x is the number of cards in the deck (52), and y is the number of jacks in the deck (4). Other than by blind luck of simple observation that I got playing around with numbers, I have no idea how to derive the above formula. Has anyone seen this problem and know how this simple formula might be derived? I should also note that the simple formula has been tested for many n, x, and y values and matches both the complicated formula and several simulations run for this problem. So there is a decent degree of confidence that it is correct.",['probability']
206800,Existence of Complex Structures on Complex Vector Bundles,"Let $E$ be a real vector bundle on a smooth manifold $X$. Let $J : E \to E$ be a vector bundle morphism (i.e. $\pi \circ J = \pi$, where $\pi : E \to X$ is the projection map) with $J^2 = -\textrm{id}$. Then $E$ is a complex vector bundle ($E_x$ has a complex structure given by $(a + bi)v = av + bJ_x(v)$). I will call $J$ an almost complex structure on $E$ - for $E = TX$, this is standard. Is there any relationship between an almost complex structure on a vector bundle $E$ and the existence of a complex structure on $E$ as a manifold? That is, is there anything we can say about $J$ that will help us to determine whether $E$ is a complex manifold? Another way of viewing this question is the following: If you have a smooth manifold, which happens to be a complex vector bundle over some other manifold, is it any easier to determine whether or not it has a complex structure?","['complex-geometry', 'almost-complex', 'vector-bundles', 'differential-geometry']"
206804,Convergence in measure does not imply $L^1$ convergence,"We know that for a sequence of measurable functions, $L^p$ convergence implies convergence in measure. However, the converse is false. I'm having trouble coming up with a counter-example, please help! Also, does convergence in measure differ from a.e. pointwise convergence?",['measure-theory']
206815,Is there a way to show that $\sqrt{p_{n}} < n$?,"Is there a way to show that $\sqrt{p_{n}} < n$? In this article , I show that $f_{2}(x)=\frac{x}{ln(x)} - \sqrt{x}$ is ascending, for $\forall x\geq e^{2}$. As a result, $\forall n \geq 3$ $$\frac{p_{n}}{ln(p_{n})} - \sqrt{p_{n}}\leq \frac{p_{n+1}}{ln(p_{n+1})} - \sqrt{p_{n+1}}$$
Also (and as a result), $\forall n \geq 3$ $$ \frac{p_{n}}{ln(p_{n})} - \sqrt{p_{n}} > 0$$
Or $$ \frac{\pi (p_{n})}{p_{n}/ln(p_{n})} < \frac{\pi (p_{n})}{\sqrt{p_{n}}}$$ According to PNT $$\displaystyle\smash{\lim_{n \to \infty }}\frac{\pi (p_{n})}{p_{n}/ln(p_{n})}=1$$
Or, $\forall \varepsilon >0$, $\exists N(\varepsilon )$: $\forall n>N(\varepsilon )$ $$1- \varepsilon < \frac{\pi (p_{n})}{p_{n}/ln(p_{n})} < 1+ \varepsilon$$
Or $$1- \varepsilon < \frac{\pi (p_{n})}{p_{n}/ln(p_{n})} < \frac{\pi (p_{n})}{\sqrt{p_{n}}}$$
As a result $\forall \varepsilon >0$, $\exists N(\varepsilon )$: $\forall n>N(\varepsilon )$ $$(1 - \varepsilon ) \cdot  \sqrt{p_{n}} < \pi (p_{n}) = n$$ But this is not enough. Interestingly, Andrica's conjecture is true iff function $f_{4}(x)=\pi (x) - \sqrt{x}$ is strictly ascending ($x < y \Rightarrow f(x) < f(y)$) for prime arguments. If $f_{4}(p_{n}) < f_{4}(p_{n+1})$ then $$\pi (p_{n}) - \sqrt{p_{n}} < \pi (p_{n+1}) - \sqrt{p_{n+1}}$$
Or $$\sqrt{p_{n+1}} - \sqrt{p_{n}} < \pi (p_{n+1}) - \pi (p_{n}) =1$$ And vice-versa, if $$\sqrt{p_{n+1}} - \sqrt{p_{n}} < 1$$
Then $$-\sqrt{p_{n}} < -\sqrt{p_{n+1}} + 1$$
Or $$\pi (p_{n})-\sqrt{p_{n}} < \pi (p_{n}) + 1 -\sqrt{p_{n+1}} = \pi (p_{n+1}) -\sqrt{p_{n+1}}$$ So, if Andrica's conjecture is true then $\forall n \geq 3$ $$\pi (p_{n})-\sqrt{p_{n}} > 0$$
Or $$\sqrt{p_{n}} < \pi (p_{n})= n$$","['prime-numbers', 'analytic-number-theory', 'number-theory']"
206829,What's the probability that Abe will win the dice game?,"Abe and Bill are playing a game.  A die is rolled each turn. If the die lands 1 or 2, then Abe wins. If the die lands 3, 4, or 5, then Bill wins. If the die lands 6, another turn occurs. What's the probability that Abe will win the game? I think that the probability is $\frac{2}{5}$ just by counting the number of ways for Abe to win. I'm not sure how to formalize this though in terms of a geometric distribution.",['probability']
206843,Big Rudin Exercise 3.26 - Which integral is larger,"This is exercise 3.26 in Rudin's Real & Complex Analysis: If $f$ is a positive measurable function on $[0,1]$, which is larger,
  $$\int_0^1 f(x) \log f(x) \, dx$$
  or
  $$\int_0^1 f(s) \, ds \int_0^1 \log f(t) \, dt$$ I tried a bunch of functions and always got the first to be larger, which suggests that Hlder's inequality won't help here (at least not a direct application). I couldn't find an example that made the second larger. I'm stuck otherwise. (This is self-study, not homework) Clarification : The integral here is the Lebesgue integral. The only answer so far is only applicable to Riemann integrable functions.","['measure-theory', 'real-analysis']"
206851,Generalisation of Dominated Convergence Theorem,"Wikipedia claims, if $\sigma$-finite the Dominated convergence theorem is still true when pointwise convergence is replaced by convergence in measure, does anyone know where to find a proof of this? Many thanks! Statement of the theorem: Let $\mu$ be $\sigma$-finite, $|f_n|\leq g$ and $f_n\rightarrow f$ in measure, then we must have $\int f_n \rightarrow \int f$ and $\int|f_n-f| \rightarrow 0$","['lebesgue-integral', 'measure-theory', 'convergence-divergence']"
206866,Expected number of Pareto-optimal points,"Suppose $S$ is a set of $n$ points in a plane.
A point is called maximal (or Pareto-optimal) if no other point in $S$ is both above and to the right of that point. If each point in $S$ is chosen independently and uniformly at random from the unit square $[0,1]\times [1,0]$.  What is the exact expected number of Pareto-optimal points in $S$?",['probability']
206888,A question about composition of the inverse image of a group homomorphism and the homomorphism itself,"Suppose $\phi:G_1 \rightarrow G_2$ is a group homomorphism and $H \leq G_1 $. Show that $\phi^{-1}(\phi(H))=H \cdot \ker(\phi) $. Attempt at a solution: I was easily able to show that $\phi^{-1}(\phi(H))\subseteq H\cdot \ker(\phi)$ due to the fact that if $h \in H$ and $k\in \ker(\phi)$ then $\phi(hk)=\phi(h)$. However I'm having trouble with the reverse inclusion. That is, showing that if $hk\in H\cdot \ker(\phi)$ then $hk\in \phi^{-1}(\phi(H))$. Any help would be greatly appreciated.","['group-theory', 'abstract-algebra']"
