question_id,title,body,tags
2354503,Find the value of n for circle $C_n$,"The problem statement is given like, For each natural number $k$, let $C_k$ denote the circle with radius $k$ centimetres & centre at the origin. On the circle $C_k$, a particle moves $k$ centimetres in the counter-clockwise direction. After completing its motion on $C_k$, the particle moves on $C_{k+1}$ in the radial direction. The motion of the particle continues in this manner. The particle starts at $(1, 0)$. If the particle crosses the positive direction of the x-axis for the first time on the circle $C_n$, then find the value of $n$. My approach is, For $C_1$, the particle moves 1 unit. On $C_2$, the particle moves 2 units. Let it crosses the X axis in $n^{th}$ move. So, in the $n^{th}$ move, it moves n units. Till now it has moved $1+2+3+...(n-1)$ units. So, when it moves $1+2+3+...(n-1) + n$ units it completes the circumference of the $n^{th}$ circle = $2*\pi*n$ $1+2+3+...(n-1) + n = 2*\pi*n$ $\frac {n*(n+1)}{2} = 2* \pi *n$ $n+1 = 4*\pi$ $n = 4*\pi-1$ = 11.56 Therefore it crosses the x axis for radius = 12. This approach is definitely wrong because it is not matching with the answers. But what's wrong in my thinking I can't figure it out. Any kind of help is appreciated. Thanks in advance.","['trigonometry', 'geometry']"
2354517,The minimal combination $\big|\pm p_1\pm\dots\pm p_n\big|$ for primes,"Conjecture: The minimal combination $\big|\pm p_1\pm\dots\pm p_n\big|$ is $0$ for odd $n>1$ and $1$ for even $n$, where $p_n$ is the $n$-th prime. Tested for $n\leq 17$ by me and for $n\leq 28$ by user AugSB. $\min \big|\pm p_1\pm\dots\pm p_n\big|=\frac{1}{2}\big(1+(-1)^n\big)$, if
  $n>1$.","['number-theory', 'conjectures', 'computational-mathematics', 'prime-numbers']"
2354555,Peeling the hyperapple,"The volume of a $d-$ball of radius $R$ is $$V_d(R) = C_d R^d$$ with $C_d$ a constant depending on $d$. This means that $$\frac{V_d(R-\delta)}{V_d(R)}=  \left(1 - \frac{\delta }{R} \right)^d$$ where we choose $\delta \in (0,R)$. For every choice of $\delta$ we can always find a value of $d$ such that $$\left(1 - \frac{\delta }{R} \right)^d < \epsilon$$ Since $V_d(R-\delta)$ represents what is left once we have removed from the ball a shell of thickness $\delta$, i.e. what is left once we have ""peeled the hyperapple"", this means that after we peel the hyperapple, we are left with nothing (if the number of dimensions is large enough). To say it in another (sloppy) way, for large $d$ all the volume of the $d-$ball is concentrated near the surface. My question is: how general is this property? Is it valid for any hypervolume we can consider?",['differential-geometry']
2354565,How to prove that $E[U_1U_2 \mid |U_1-U_2|<a]$ is the sum of two double integrals?,"Suppose that $U_1, U_2 \sim Unif(0,1)$ are iid random variables. I am trying to find: $$
E[U_1U_2 \mid |U_1-U_2|<a]
$$ for $a<\frac{1}{2}$. It appears that the answer is: $$
\int_{u_1 = 0}^1 \int_{u_2 = u_1}^{u_1 + a} u_1 u_2 
\text{d} u_2 \text{d} u_1
+
    \int_{u_2 = 0}^1 \int_{u_1 = u_2}^{u_2 + a} u_1 u_2 
\text{d} u_1 \text{d} u_2
$$ However, I have no idea how the conditional expectation was turned into two integrals with the bounds. Can anyone walk me through how exactly this result formally came about? Thanks.","['probability-theory', 'probability', 'statistics']"
2354584,Substitute for triangle inequality for Kullback-Leibler divergence,"I know that the Kullback-Leibler divergence does not satisfy the triangle inequality. But is there a substitute, maybe in one of the forms below?
$$
D(P|Q)\leq C\left(D(P|R)+D(R|Q)\right), \quad\text{for some} C> 0
$$
$$
D(P|Q)\leq D(R|P)+D(P|R)+D(R|Q)+D(Q|R),
$$
$$
D(P|Q)\leq D(R|P)^a+D(R|Q)^a\quad\text{for some } a> 0
$$","['information-theory', 'probability-theory', 'inequality']"
2354586,Objective metric to describe skill vs luck in games that include randomness,"There are many games that even though they include some random component (for example dice rolls or dealing of cards) they are skill games. In other words, there is definite skill in how one can play the game taking into account the random component. Think of backgammon or poker as good examples of such games. Moreover, novice players or outsiders might fail to recognise the skill involved and attribute wins purely to luck. As someone gains experience, they usually start to appreciate the skill involved, and concede that there is more to the game than just luck. They might even concede that there is ""more"" skill than luck. How do we quantify this? How ""much"" luck vs skill ? People can have very subjective feelings about this balance. Recently, I was reading someone arguing that backgammon is $9/10$ luck, while another one was saying it's $6/10$. These numbers mean very little other than expressing gut feelings. Can we do better? Can we have an objective metric to give us a good sense of the skill vs luck component of a game. I was thinking along these lines: Given a game and a lot of empirical data on matches between players with different skills, a metric could be: How many games on the average do we need to have an overall win (positive win-loss balance) with probability $P$ (let's use $P=0.95$) between a top level player and a novice? For the game of chess this metric would be $1$ (or very close to $1$). For the game of scissors-paper-rock it would be $\infty$. This is an objective measure (we can calculate it based on empirical data) and it is intuitive. There is however an ambiguity in what top-level and novice players mean. Empirical data alone does not suffice to classify the players as novices or experts. For example, imagine that we have the results from 10,000 chess games between 20 chess grandmasters. Some will be better, some will be worse, but analysing the data with the criterion I defined, we will conclude that chess has a certain (significant) element of luck. Can we make this more robust? Also, given a set of empirical data (match outcomes) how do we know we have enough data? What other properties do we want to include? Maybe a rating between $[0, 1]$, zero meaning no luck, and one meaning all luck, would be easier to talk about. I am happy to hear completely different approaches too.","['game-theory', 'probability', 'soft-question']"
2354591,How to show that there is a unique unbiased estimator of $p$?,"The taxis in a town are marked with reference numbers $1,2,...,p$ where $p$ is unknown. I am observing $n \leq p$ of them with pairwise different reference numbers $x_1,x_2,...,x_n$. It is to be assumed that every combination $(x_1,x_2,...,x_3)$ has the same probability to occure. Let $g:=\max x_i$.
How can I show that there is a unique function $f(g)$ being an unbiased estimator of $p$? Any hints?","['probability-theory', 'statistics']"
2354595,Carathéodory measurability condition for finite outer measure,"Let $\mu^*$ be a finite outer measure on a set $\Omega$. I read that the Carathéodory measurability condition simplifies to $\mu^*(E)+\mu^*(\Omega\smallsetminus E)=\mu^*(\Omega)$. Is it correct? EDIT  An answer in MO contains exactly this claim (52 upvotes, but no proof).",['measure-theory']
2354624,Proving an inequality of trigonometric functions,"I am trying to prove that $$(\cos x)^{\cos x} > (\sin x)^{\sin x}$$ for $x \in \left(0, \frac{\pi}{4}\right)$. I have plotted the graph of $y=(\cos x)^{\cos x} - (\sin x)^{\sin x}$ and see that my conjecture is supported.
Therefore, I tried to prove an equivalent statement $$ \cos x  \ln  \cos x> \sin x \ln \sin x$$.
I tried to use Calculus to prove the statement.
Let $$f(x)= \cos x  \ln  \cos x-\sin x \ln \sin x$$
then $$f'(x)=-\sin x\ln \cos x -\cos x \ln \sin x -\sin x - \cos x.$$
From here I don't know how to proceed.
Any help to prove the inequality will be much appreciated!","['exponential-function', 'inequality', 'trigonometry', 'calculus']"
2354629,Trouble connecting pieces of proof in Kesten's seminal paper on Sinai's random walk,"In Kesten's 1986 paper (Limit distribution of Sinai's Random Walk) we read: The proof of this lemma uses the fact that the symmetric simple random walk when properly rescaled converges to the Brownian motion. So far so good, But the problem begins when the author says: We can therefore evaluate $(2.6)$ as $$\lim_{n\to\infty}\frac{d}{d\lambda}E\left\{\exp\left(-\frac\theta n\tilde{s}_n\right);\tilde{M}_n\leqslant y\sqrt{n}\,\text{ and }\,\tilde{m}(\tilde{T}_n)\geqslant-\lambda\sqrt{n}|S_0=0\right\}.\tag{2.7}$$ The convergence in law would give us that
$$\frac{d}{d\lambda} \Bbb{E}\{ e^{-\theta s_+}; M_+ \leq y ; W(s_+)\geq -\lambda\}\\ = \frac{d}{d\lambda} \lim_n \Bbb{E}\{ e^{-\frac{\theta}{n} \tilde s_n}; \tilde M_n \leq y\sqrt n ; \tilde m( \tilde T_n)\geq -\lambda\sqrt{n}\} $$ We need an argument to take change the derivative with the limit. What would it be? Accepting that and moving forward, one reads, The question then is, how to use (2.11) in (2.7) to obtain Lemma (2.6). Note that there is a $\frac{d}{d\lambda}$ missing in (2.11) (or in the right hand side of (2.6)) and there is a missing $\sqrt{n}$ on (2.7). How can we close the proof? Edit To prove that
$$\frac{d}{d\lambda} \Bbb{E}\{ e^{-\theta s_+}; M_+ \leq y ; W(s_+)\geq -\lambda\}\\ = \frac{d}{d\lambda} \lim_n \Bbb{E}\{ e^{-\frac{\theta}{n} \tilde s_n}; \tilde M_n \leq y\sqrt n ; \tilde m( \tilde T_n)\geq -\lambda\sqrt{n}\}\\
= \lim_n\frac{d}{d\lambda}  \Bbb{E}\{ e^{-\frac{\theta}{n} \tilde s_n}; \tilde M_n \leq y\sqrt n ; \tilde m( \tilde T_n)\geq -\lambda\sqrt{n}\}$$ It requires a refined argument. Indeed, let $a(n,h) = 1_{n>1/h}$, then $$\lim_{h\to 0} \lim_{n\to \infty} E[a(n,h)] = 1 \\
 \lim_{n\to \infty} \lim_{h\to 0}E[a(n,h)] = 0 \\$$ So we need something more than just a simple Dominated convergence theorem.
We write
$$ \frac{d}{d\lambda} \Bbb{E}\{ e^{-\theta s_+}; M_+ \leq y ; W(s_+)\geq -\lambda\}\\ = \frac{d}{d\lambda} \lim_n \Bbb{E}\{ e^{-\frac{\theta}{n} \tilde s_n}; \tilde M_n \leq y\sqrt n ; \tilde m( \tilde T_n)\geq -\lambda\sqrt{n}\}\\
\lim_{h\to 0} \frac{1}{h}\big[\lim_n \Bbb{E}\{ e^{-\frac{\theta}{n} \tilde s_n}; \tilde M_n \leq y\sqrt n ; \tilde m( \tilde T_n)\geq -(\lambda+h)\sqrt{n}\}-\Bbb{E}\{ e^{-\frac{\theta}{n} \tilde s_n}; \tilde M_n \leq y\sqrt n ; \tilde m( \tilde T_n)\geq -(\lambda)\sqrt{n}\}\big]\\
\lim_{h\to 0} \frac{1}{h}\lim_n \Bbb{E}\{ e^{-\frac{\theta}{n} \tilde s_n}; \tilde M_n \leq y\sqrt n ; -(\lambda)\sqrt{n}>\tilde m( \tilde T_n)\geq -(\lambda+h)\sqrt{n}\}\\
$$ On the other hand
$$\lim_n \lim_{h\to 0} \frac{1}{h}\Bbb{E}\{ e^{-\frac{\theta}{n} \tilde s_n}; \tilde M_n \leq y\sqrt n ; -(\lambda)\sqrt{n}>\tilde m( \tilde T_n)\geq -(\lambda+h)\sqrt{n}\}\\=
\lim_n \Bbb{E}\{ e^{-\frac{\theta}{n} \tilde s_n}; \tilde M_n \leq y\sqrt n ;\tilde m( \tilde T_n) = -(\lambda)\sqrt{n}\}\\=
\Bbb{E}\{ e^{-\theta  s_+};  M_+ \leq y ;W( s_+) = -(\lambda)\} $$ **Edit 2 **
It may be usefull to add a couple of definitions given by the author: Here $S_n$ is a symmetric simple random walk tarting from $0$. That is
$S_n = \sum_{i=1}^n X_i$ where $X_i$ are iid. and $P(X_1 = 1) = P(X_1 = -1) = 1/2$","['weak-convergence', 'real-analysis', 'proof-verification', 'probability-theory']"
2354673,Proving uniform convergence of $x^n-x^{2n}$,I need help checking if the series of function {$x^n-x^{2n}$} on two cases: when $0\le x\le 1$ when $\frac{1}{3}\le x \le \frac{1}{2}$ I managed to prove that in the first case: the limit function is $f(x)=0$ so $r(x)=x^n-x^{2n}$ I have a maximum point when $x=\frac{1}{2}^{\frac{1}{n}}$ so $lim_{n\rightarrow \infty}r(x)=\frac{1}{4}\ne 0$ my question is why Dini's theorem does not apply on this case. for the second case: I don't have a maximum point so how do I prove it uniformly converges? any insight will be very helpful.,"['sequences-and-series', 'uniform-convergence']"
2354835,Rotate $xy=1$ by $\frac{\pi}{4}$ in a negative (clockwise) direction.,"I was studying hyporbolae for the first time and noticed that $y=\frac{1}{x}$ is a rotated hyperbola. I had seen equations like $y=\frac{1}{x}$ before but never noticed they where hyperbolae. Anyway using geometry and the general form of a hyperbola, $\frac{x^2}{a^2}-\frac{y^2}{b^2}=1$, I realised that $xy=1$ is $\frac{x^2}{2}-\frac{y^2}{2}=1$ which has been rotated clockwise by $\frac{\pi}{4}$. I tried to rotate $xy=1$ using the rotation matrix: $ \left( \begin{array}{cc} \cos\theta & \sin\theta\\ \sin\theta & \cos\theta\end{array} \right)$ $$\left( \begin{array}{cc} \cos\theta & \sin\theta\\ \sin\theta & \cos\theta\end{array} \right) \left( \begin{array}{cc} x \\ \frac{1}{x}\end{array} \right)=\left( \begin{array}{cc} x'\\ y' \end{array} \right)$$ $$\frac{x}{\sqrt{2}}+\frac{1}{\sqrt{2}x}=x', -\frac{x}{\sqrt{2}}+\frac{1}{\sqrt{2}x}=y'$$ I used two methods. The first worked and the second did not. I'd like to know where I'm going wrong with the second approach. In the first approach I squared both sides of the above equations and then used simultaneous equations to remove the $x$. Then dividing across by $2$ gives the desired result. Just out of curiosity I tried another method. I first multiplied across both equations by $\sqrt{2}x$ and rearranged to quadratic form: $$x^2-\sqrt{2}x'x+1=0, x^2-\sqrt{2}y'x-1=0$$ I equated the solutions of each to get: $$\frac{\sqrt{2}x' \pm\sqrt{2x'^2-4}}{2}=\frac{-\sqrt{2}y' \pm\sqrt{2y'^2+4}}{2}$$ The $\pm$s are ugly but I figured I could get rid of them through a series of squaring. I tried a few different ways starting with roots on opposite sides, roots on the same side etc. but I can't quite get it through. Should this work or am I going down a dead-end road ? Ok I got it: $$\frac{\sqrt{2}x \pm\sqrt{2x^2-4}}{2}=\frac{-\sqrt{2}y \pm\sqrt{2y^2+4}}{2}$$ simplifies to  $$\frac{x^2}{2}-\frac{y^2}{2}=1$$","['hyperbolic-functions', 'functions']"
2354839,Prove that $L^{\infty}(\mathbb R)\cap C(\mathbb R)$ is not dense in $L^{\infty}(\mathbb R)$,"Here $C(\mathbb R)$ is the set of all continuous functions in $\mathbb R$, so the problem asks me to prove that there exists $f \in L^\infty(\mathbb R)$ such that there is no sequence of functions in $\mathbb R$ converging under sup norm to $f$. Also, the continuous functions not necessarily have compact support. Does anyone have ideas? Thank you for your time.","['real-analysis', 'lp-spaces', 'lebesgue-integral', 'measure-theory']"
2354875,Partial derivatives vs. Total Derivatives for chain rule.,"If I had a function $f(x,y)$ where $x=x(s,t)$ and $y=y(s,t)$ then $$ \frac{df}{dt} = \frac{\partial f}{\partial x} \frac{\partial x}{\partial t} + \frac{\partial f}{\partial y} \frac{\partial y}{\partial t}. $$ I have been reading this and have spotted in case 2 that $$ \frac{\partial f}{\partial t} = \frac{\partial f}{\partial x} \frac{\partial x}{\partial t} + \frac{\partial f}{\partial y} \frac{\partial y}{\partial t}. $$ $f$ has no explicit $t$ dependence so how can this be correct? How can I have a chain rule for partial derivatives? A chain rule implies that there is no explicit dependence on the variable that we are differentiating with respect to, and I thought partial derivatives only deal with explicit dependencies and not implicit? Thanks","['multivariable-calculus', 'partial-derivative']"
2354894,Finding center of larger cloud of points?,"First of all, excuse the abstract wording of the title. I don't know the proper term for the concept I want to find, which is part of my problem I guess. I've got a cloud of points (in my case it's 3d points, but it shouldn't matter). They are placed in such a way that most of them are in a general area, but with groups of outliers. Take this picture as an example: I would like to find a value that gives me the center point of the big cloud of points, so to speak. That is, an equivalent of the average that isn't affected by the outliers. But there is an important detail: the bigger cloud should be defined as the larger cloud in size, not the cloud with most points. In the sample image, for example, it is possible that one of the clouds in the lower right has a larger number of points than the large cloud in the left, yet the one in the left should be the chosen cloud. The problem is that I don't know first hand how many outliers there will be or how far they are going to be from each other, so it's hard to define which points will ""form a cloud"". The reason for my question is that I'm basically trying to center a 3d model in a computer application.  Using just the denser area isn't valid, since it could represent just a small object that's modeled with high accuracy due to being round.","['3d', 'statistics', 'geometry']"
2354895,Does continuity depend on the distance function?,"I'm working through a book called ""Introduction to Topology"" and I'm currently working on a chapter regarding metric spaces and continuity. This is how my book defines continuity at a point: Let $(X,d)$ and $(Y,d')$ be metric spaces, and let $a\in X$. A function $f: X\to Y$ is said to be continuous at the point $a\in X$ if given $\epsilon \gt 0$, there is a $\delta \gt 0$, such that
  $$d'(f(x),f(a)) \lt \epsilon$$
  whenever $x\in X$ and
  $$d(x,a)\lt \delta$$ My question is this: is it possible that a function may be continuous in the metric spaces $(X,d)$ and $(Y, d')$ but not be continuous if one of the distance functions $d$ or $d'$ is changed to a different distance function? In other words, does the continuity of a function depend on the distance functions used to ""measure"" it?","['continuity', 'general-topology', 'elementary-set-theory']"
2354913,Evaluate the limit of $\sum\limits _ { k = 0} ^ { n } \mathrm{arctg} \frac { k + 1} { n ^ { 2} }$ when $n\to\infty$,"Evaluate $$\lim _ { n \rightarrow \infty } \sum _ { k = 0} ^ { n } \mathrm{arctg} \frac { k + 1} { n ^ { 2} }$$ At first I thought this was a Riemann sum, but I couldn't insert the $1/n$ and get the right form. I also tried to write it out, and it definitely looks like it would converge, but I'm not sure how to approach it.","['real-analysis', 'sequences-and-series', 'limits']"
2354934,Why is $U$ considered $T$ in sets and logic?,"Question in my text (Rosen): Prove :  $ A \cup U = U $ Solution: \begin{align*}
A \cup U &= \lbrace x \mid x \in A \vee x \in U \rbrace\\
&= \lbrace x \mid x \in A \vee T\rbrace\\
&= \lbrace x \mid T\rbrace\\
&=U.
\end{align*} Here $U$ denotes the universal set and $T$ denotes True. $A$ is a subset of $U$. While I intuitively know this is correct, if I'm asked why it is, I can't put it in words.","['logic', 'elementary-set-theory', 'discrete-mathematics']"
2354970,The dual of $L^\infty$ for Borel measures and $L^\infty$ functions vanishing at infinity,"It is known that the dual of $L^\infty (X, m)$ is the space of complex, finite, finitely additive measures on $X$ that are absolutely continuous with respect to $m$. I would like to know whether one can get better properties of the measures in the dual if $X$ is a topological space and $m$ is Borel, regular, $\sigma$-finite. Most importantly, I would like to know whether these measures become countably-additive. If $\omega \in L^\infty (X, m) ^*$ then there exist $\mu$, a complex, finite, finitely additive measure on $X$ that are absolutely continuous with respect to $m$, such that $\omega (f) = \int _X f \ \Bbb d \mu$. Since the space $C_0 (X)$ of continuous functions that vanish at infinity embeds continuously into $L^\infty (X, m)$, it follows that $\omega$ restricts to a continuous linear functional on $C_0 (X)$, and can be therefore represented by some finite, regular measure $\nu$. A consequence of this is that $\int _X f \ \Bbb d \mu = \int _X f \ \Bbb d \nu \quad \forall f \in C_0 (X)$. Does this allow us to conclude that $\mu$ is countably additive? (Quite frankly, I'd say that it doesn't, otherwise we could use the same technique to show that if $X$ is normal then the measures that form the dual of $C_b (X)$, which a priori are only finitely additive, should be countably additive. Nevertheless, I'm still hoping that $L^\infty (X, m)$ gets some nice properties from the topological properties of $m$.) Alternatively, could one define a $L^\infty$ space of functions vanishing at infinity, call it $L_0 ^\infty$, and hope that its dual be some happy mix of the spaces $L^\infty (X, m)$ and $rca(X)$?","['banach-spaces', 'duality-theorems', 'functional-analysis', 'lp-spaces', 'measure-theory']"
2354978,Relative quaternion rotation (delta rotation) produces unstable results,"Disclaimer: I asked this question here on game development before. Use case: I have a currentRotation quaternion and a targetRotation quaternion and need to calculate the relative rotation between them - as in: what rotation do I need to apply to transform an object (in a 3D scene) with currentRotation so that it has targetRotation. The standard solution seems to be to calculate the relative rotation (1) $q_{delta} = {q_{current}}^{-1}*q_{target}$ and then (later at some point) combine it with the object's current rotation (2) $q_{new} = q_{delta} * q_{current}$ to actually transform the object. Combining these, I get the formula (3) $q_{new} = {q_{current}}^{-1}*q_{target}*q_{current}$ which makes sense for me - ultimatively, I set the object's new rotation to be the target rotation. This method works well for most cases of current-target-rotations, but  unfortunately not for all - it is unstable and I don't understand why. I created a codepen example that shows a problematic case. To be more precise, calculating the relative rotation from (0°, 170°, 10°) to (0°, 170°, -10°) which should be in my opinion (0°, 0°, -20°) (written as XYZ-euler angles for readability) fails - combining the original rotation with the delta rotation does not yield the expected target rotation, so $q_{target} \neq q_{new} = {q_{current}}^{-1}*q_{target}*q_{current}$ (see (3) ) To wrap up: I am looking for your help to understand... My suspicion is that (1) produces incorrect delta rotations for some input values, so combining the rotations does not yield the correct result. Why? If so, how can I recognize ""problematic input values"" and handle them gracefully?","['quaternions', '3d', 'rotations', 'geometry']"
2355014,"if $f$ with continuous partial derivatives at $(x_0,y_0)$. Then there exists a unit vector $\vec{u}$ which $D_\vec{u} (f)(x_0,y_0)=0$","Prove or disprove: let $f$ be a function with continuous partial derivatives at $(x_0,y_0)$. Then there exists a unit vector $\vec{u}$ for which $D_\vec{u} (f)(x_0,y_0)=0$ It feels like it's not true, but I'm new to this material and don't really understand it.",['multivariable-calculus']
2355025,Number of polynomials of degree 4,"Find the numbers of all polynomials of degree $4$ you can create with the letters $x,y,z$. All coefficients must be $1$. I can create $\binom{6}{4}=15$ monomials of degree $4$ with $x,y,z$. Using the same rule I obtain $10,6,3,1$ monomials of degree $3,2,1,0$ respectively with the same letters. Now Call $A$ the set made of all subsets of monomials of degree $4$ (except for the null set), $|A|=2^{15}-1$, and call $B$ the set made by all subsets of monomials of degree from $3$ to $0$, $|B|=2^{20}$. All polynomials of degree $4$ are $$|A \times B|=(2^{15}-1)2^{20}=34358689792$$ which is huge. Is my answer correct?",['combinatorics']
2355227,"Limit of (x-y)/(x²-y²) as (x,y)->(1,1) using epsilon-delta?","My textbook asks the question $$f(x,y) = \frac{x-y}{x^2-y^2}$$
  Does $f(x,y)$ have a limit as $(x,y) \rightarrow (1,1)$? First step of finding a value is easy if we approach $(1,1)$ on the y-axis: $$\lim_{(x,0) \rightarrow (1,1)} f(x,y) = \lim_{(x,0) \rightarrow (1,1)} \frac{x-0}{x^2 - 0} = 1 $$ So if the limit exists it should be 1. Next is to examine it using the formal ($\epsilon$-$\delta$) definition: Choose $\delta,\epsilon > 0$ where $\delta = \delta(\epsilon)$ such that for all $x,y \in D_f$, $|f(x,y)-L| < \epsilon$ whenever $0 < \sqrt{(x-a)^2 + (y - b)^2} < \delta$ In this case the inequalities become $$ \left| \frac{x-y}{x^2-y^2} - 1\right| < \epsilon \quad \text{whenever} \quad 0 < \sqrt{(x-1)^2 + (y-1)^2} < \delta$$ Using the identity $(a+b)(a-b) = a^2 + b^2$ on the left inequality, and expanding the right inequality, we get $$ \left| \frac{1}{x+y} - 1\right| < \epsilon \quad \text{whenever} \quad 0 < \sqrt{x^2 + y^2 - 2x - 2y + 2} < \delta$$ But then I'm stuck, I can't get them to look like eachother, so I can neither prove nor disprove that a limit exists. What do I do from here?","['multivariable-calculus', 'epsilon-delta', 'limits-without-lhopital']"
2355261,Sum of $n$ integers from set of size $2n-1$ divides $n$,"Given any multiset of positive integers of size $2n-1$, is it possible to find a multisubset of size $n$ such that $n$ divides the sum of the integers in this multisubset? This problem has been circulating for a while in my friends group and none of us has been able to solve it. Someone in the friend group has claimed there is a solution using the Chevalley–Warning theorem, but has not actually shown us such a solution. A multiset is a set that may contain a number more than once.","['number-theory', 'finite-fields']"
2355309,"If $f_{n}\to f$ a.e on $[0,1]$ and $f_{n}, f \in L^{p}[0,1]$ , then for all $g \in L^{q}[0,1]$ show that $\int f_{n}.g \to \int f.g$","$f_{n}$ be a sequence of function in $L^{p}[0,1](1<p<\infty)$ and $f_{n}\to f$ pointwise a.e and $f\in L^{p}[0,1]$, and suppose that there is a constant $M$, such that $||f_{n}||_{p} \leq M$ for all $n$. Then for each function $g$ in $L^{q}[0,1]$, we have 
$$\int fg = \lim \int f_{n}.g $$ I know this problem has been posted a numerous times but I did a proof by myself and I want it to be verified. Most proofs I suppose use the Egoroff's theorem but I here used the Vitali's convergence theorem which is as follows: If $E$ be a set of finite measure and $f_{n}$ be a sequence of function on $E$ which is uniformly integrable. If $f_{n}\to f$ a.e on $E$, then $f$ is integrable and 
$$\lim_{n\to \infty}\int_{E} f_{n} = \int_{E}f$$ Now we have $f_{n}.g \to f.g$ a.e on $[0,1]$. I just want to prove that the sequence $f_{n}.g$ is uniformly integrable. So given $\epsilon >0$, I have to produce a $\delta >0$ such that for every $A \subseteq [0,1]$ with $m(A)< \delta$ then $\int_{A} |f_{n}.g| < \epsilon$. Now since $|g|^{q}$ is already integrable we have for given $\epsilon >0$ , then there exists a $\delta >0$ such that for all $A\subseteq [0,1]$ with $m(A)< \delta$ we have 
$$\int_{A} |g|^{q}<\left(\frac{\epsilon}{M}\right)^{q}.$$ Now 
$$\int_{A}|f_{n}.g| \leq ||f_{n}||_{p}\left(\int_{A} |g|\right)^{\frac 1q}\leq M.\left(\left(\frac{\epsilon}{M}\right)^{q}\right)^{1/q}< \epsilon$$ 
when $m(A)<\delta$. Hence the sequence $f_{n}.g$ is uniformly integrable and the result holds by using Vitali Convergence theorem. Thanks in advance!","['lebesgue-measure', 'proof-verification', 'lp-spaces', 'lebesgue-integral', 'measure-theory']"
2355315,What is the probability of traversing through an $n \times n$ board in exactly $K$ moves by moving uniformly at random?,"On a $n$-row $n$-column board, we want to move a piece from the square on the lower left corner to the square on the upper right corner following the commands of a light that blinks in $3$ different colors: Each color represents a move: up, right, or diagonal (up and to the right) . The probability of each one blinking is equal. What is the probability of reaching the square in the upper right corner using $K$ moves, knowing that when the piece reaches a square that it's impossible to make $1$ of the $3$ moves, that color stops blinking?","['combinatorics', 'probability']"
2355370,Need clarification in Riemann sum,"I am a self-learner and the book that I am engaged in gave me some basics of Riemann sums but I see that they are not enough to solve most of the problems related to Riemann sums. Can someone give me a little hand as to why $1/n$ always means that we are looking for the integral from $0$ to $1$ (Yes I know that $(b-a)$ here gives $1$ but is not it possible to consider the range not from $0$ to $1$ but from $5$ to $6$ as well?)? Generally, why does this condition below makes sense? $$\sum_{i=1}^n\frac{1}{n}f\left(\frac{i}{n}\right)\to\int_0^1f(x)dx$$","['integration', 'definite-integrals', 'calculus', 'riemann-sum']"
2355415,Solving $ z = -i \ln\left(-ci + \sqrt{(1+c)(1-c)} \right) $ for $c$,"Given, $$ z = -i \ln\left(-ci + \sqrt{(1+c)(1-c)} \right) $$ I would like to solve for $c$. First multiply through by $i$, $$  iz = \ln\left(-ci + \sqrt{(1+c)(1-c)} \right) .$$ Then take the exponential of both sides, $$ e^{iz} = -ci + \sqrt{(1+c)(1-c)} $$ Not sure where to go from here, can I say $$ \Im(e^{iz}) = \Im(-ci+\sqrt{(1+c)(1-c)}) \implies  \sin z = -c ? $$","['trigonometry', 'complex-numbers']"
2355429,sup of Norm equals sup of inner product,"Given $V$ a pre-Hilbert space and T a self-ajoint linear Operator $V \to V$
show that$$ \sup \|Tx\| =\sup |\langle Tx,x \rangle | \in \mathbb{R} \cup \{ \infty  \}$$ for all $ \|x\| =1$. I know that $\| x \| = \sup |\langle x,y \rangle | $ over all $y \in V$.
from cauchy-schwarz $|\langle Tx,x \rangle | \le \|Tx\| \| x \| = \|Tx\| $ 
But I cannot derive the wanted + I dont know how to bring the self-ajointness in. Greetings.","['functional-analysis', 'real-analysis', 'hilbert-spaces', 'inner-products']"
2355461,How many homomorphisms and isomorphisms,"This is a rather elementary question but I am teaching myself group theory and want to make sure I am getting the basics right! I am considering how many isomorphisms there are $C_n \rightarrow C_n$. For an isomorphism, an element of some order $k$ must be mapped onto an element of order $k$. So I thought that, if $a$ was the generator in the first group, then the homomorphism could map this onto any of the elements $b^i$ in the second group were $b$ generates the second group and $i$ has to be coprime with $n$, because any of the $b^i$ with $i$ being coprime with $n$ can be thought of as the generators for the group of order $n$? Is this correct? Secondly, I am asked how many homomorphisms there are $D_{2n}\rightarrow C_n$ Now for a homomorphism $f$, the order of $f(a)$ must divide the order of $a$. I will call the generator of order n in $D_{2n}$ r, and of order 2 $s$. And I will call a generator of order n in $C_n$ as $a$. Splitting the problem into cases according to the value of n: When n=1 have trivial case that both elements $e,s \in D_{2n}$ are both in the kernel of f When n=2, can choose either $f(r)=a$ and $f(s)=e$ ($e$ the ide9antity) or vice versa to satisfy the 'generator' requirement. For $n>2$, since $f(s)$ can only be order 1 or 2, it must be mapped to the identity and $f(r)=a$. But I am rather stuck as to what happens to the elements in $D_{2n}$ which are of the form $sr^i$ for some $i=1,2,...n-1$. If I consider the simple case of n=2, then I can think of $f(s\bullet r)=f(s)f(r)=ef(r)=a$ by definition for a homomorphism. Now if I consider $f(sr\bullet s)=f(sr)f(s)=f(sr)=f(r)=a$ which happens to be consistent here because $r$ is of order two and is self-inverse, so if we take $srs=ssr^{-1}=r^{-1}$ by definition for the dihedral group, this happens to be $r$ so indeed we get back $f(r)=a$ on the left hand side. But this does not work with any $n>2$ in general. In particular, if I assume as above that $f(s)=e$ and $f(r)=a$, then still the first case where I tried $f(s\bullet r^j)=f(s)f(r^j)=a^j$ suggesting that the $sr^j$ are mapped to $a^j$, like the $r^j$. On the other hand this suggests the second operation becomes $f(sr^j\bullet s)=f(sr^j)f(s)=f(r^j)=a^j$ but by definition for the dihedral group $sr^js=s^2r^{-j}=r^{-j}$, and clearly $f(r{-j})=a^{-j}\neq a^j$! I am not sure if I am doing something wrong here, or perhaps there aren't any homomorphisms? I would greatly appreciate any help.","['finite-groups', 'group-homomorphism', 'group-theory', 'group-isomorphism']"
2355463,Subsets of $\mathbb{R}$ with the same Lebesgue measure on any open set,"I'm looking for two sets in $\mathbb{R}$ which are both uncountable and dense, and where one is the complement of the other. I know the question has already been asked here , but the solutions still didn't feel quite right to me: the sets didn't feel ""even"" enough in $\mathbb{R}$. So I realized what the question was that I really wanted answered. Are there two Lebesgue measurable subsets of $\mathbb{R}$, one of which is the complement of the other, which have the same Lebesgue measure on any open bounded subset of $\mathbb{R}$? The density of each set in $\mathbb{R}$ is as well as their uncountability is obvious, and the sets feel ""even"" everywhere.","['real-analysis', 'real-numbers', 'lebesgue-measure', 'measure-theory']"
2355465,Verifying $|F(r)| \geq \frac{1}{1-r}\log(\frac{1}{1-r}) $ and $|F(re^{i \theta})| \geq c_{q/r}\frac{1}{1-r}\log({\log(\frac{1}{1-r})})$,"I'm attempting to take a Tauberian route in verifying the proposition in $(1)$ below, which is from Complex Analysis , by Elias M Stein and Rami M. Shakarchi. Let $F(z)$ be the following series: $$F(z) = \sum_{n=1}^{\infty}d(n)z^{n} \, \, \text{for} \, |z| < 1$$ $\text{Remark}$ One can also observe the following relationship: $$\sum_{n=1}^{\infty}d(n)z^{n} = \sum_{n=1}^{\infty} \frac{z^{n}}{1-z^{n}}$$ $(1)$ If $z=r$ with $0 < r < 1$, then as $r \rightarrow 1$, another case that be considered is $\theta=\frac{2\pi p}{q}$, where $p$ and $q$ are positive integers and then: $(1.2)$ $$|F(r)| \geq \frac{1}{1-r}\log\left(\frac{1}{1-r}\right)$$ $(1.3)$
$$\lvert F(re^{i \theta})\rvert \geq c_{q/r}\frac{1}{1-r}\log\left(\frac{1}{1-r}\right)$$ $\text{Lemma}$ Formally attacking $(1)$, one can make the initial observations for the case seen in $(1.2)$ $$\left\lvert \sum_{n=1}^{\infty} \frac{z^{n}}{1-z^{n}}\right\rvert \leq \frac{1}{1-r}\log\left( \frac{1}{1-r}\right)$$
$$\left\lvert\frac{z^{1}}{1-z^{1}} + \frac{z^{2}}{1-z^{2}} + \frac{z^{3}}{1-z^{3}} + \frac{z^{4}}{1-z^{4}} + \cdot \cdot \cdot + \frac{z^{n}}{1-z^{n}}\right\rvert \leq \frac{1}{1-r}\log\left( \frac{1}{1-r}\right)$$ Recall the archetypal technique of Abel summability as formally developed in $(2)$: $(2)$ $\text{Definition  (0.2)}$ A series $A(r)= \sum_{n=1}^{\infty}a_{n}r^{n}$ is said to Abel summable to $L$ if  $f(r)$ is convergent for all $\lvert r\rvert < L$ and if $f(r)$ converges to some limit $L$ as $r \rightarrow 1^{-}$:
$$A(r)= \sum_{n=1}^{\infty}a_{n}r^{n}$$ $\text{Remark}$: The developments of Abel summability, expressed within a prior definition, can be fully expressed as follows: $$\lim_{r \rightarrow 1^{}} A(r)= \lim_{r \rightarrow 1^{}} \sum_{n=1}^{\infty}a_{n}r^{n} = L$$ Now recall our previous observation with some added developments:
$$\left|\frac{z^{1}}{1-z^{1}} + \frac{z^{2}}{1-z^{2}} + \frac{z^{3}}{1-z^{3}} + \frac{z^{4}}{1-z^{4}} + \cdot \cdot \cdot + \frac{z^{n}}{1-z^{n}} = d(1)z^{1}  + d(2)z^{2} + d(3)z^{3} + \cdot \cdot \cdot + d(4)z^{4} + d(z)z^{n}\right| \leq \frac{1}{1-r}\log\left( \frac{1}{1-r}\right)$$ $$\left|d(1)z^{1}  + d(2)z^{2} + d(3)z^{3} + \cdot \cdot \cdot + d(4)z^{4} + d(z)z^{n}\right| \leq \frac{1}{1-r}\log\left( \frac{1}{1-r}\right)$$ $$\lim_{r \rightarrow 1^{}}|d(1)z^{1}  + d(2)z^{2} + d(3)z^{3} + \cdot \cdot \cdot + d(4)z^{4} + d(z)z^{n}| \leq \frac{1}{1-r}\log\left( \frac{1}{1-r}\right)$$ Are the recent developments valid so far? I feel like this approach is too ""archetypal."" If the developments are wrong, may I have an answer on an alternate approach?","['tauberian-theory', 'complex-analysis']"
2355476,How to get the splitting field of a polynomial?,"I'm sorry if I sound too ignorant. I don't have a high level of knowledge in math. While reading an article about Galois theory, I've become confused over the concept of a splitting field. The author defines the splitting Field of the polynomial $p(x)$ as the smallest field extension of $Q$ that contains all the roots of $p(x)$. He/She then gives the examples of $p(x)=x^2−2$, which splitting Field is $\mathbb{Q}[\sqrt2]$ since ""it contains all the roots of $p(x)$ and if it had fewer elements it either wouldn't contain all the roots or wouldn't be a field"" and that of $p(x)=x^4−5x^2+6$ which splitting field is $\mathbb{Q}[\sqrt 2,\sqrt 3]$, then the author decides to finish the paragraph by asking the question ""Can you see why?"". And that is the issue, I cannot see why :/ I struggled for a while trying to think of a general method or explanation to why those field extensions correspond to those polynomials, but I couldn't come up with anything. Any thoughts/ideas would be really appreciated!","['galois-theory', 'field-theory', 'splitting-field', 'group-theory']"
2355494,"Question about a proof of ""Graph $G$ has no odd cycles $\implies$ $G$ is bipartite""","To prove the statement above we solve the problems below. Starting at any vertex $A$ in any component of $G$ , assign the color red to $A$ and proceed to color vertices along simple paths from $A$ , alternating between red and blue. In that way every vertex in the component is eventually reached and colored. In the procedure described above, the color assigned to a vertex $V$ depends on the length of the path followed from $A$ to $V$ . A vertex reached by a path of odd length is colored blue, while a vertex reached by a path of even length is colored red. (a) Let $A, V$ be vertices in a graph that contains no odd cycles and suppose that there are two paths from $A$ to $V$ , one of odd length and one of even length. Show that this situation is impossible by deriving a contradiction. (b) Prove  if each component of a graph is bipartite, then the entire graph is bipartite. Then show that with the vertices of some component colored as described above, no edge has the same color assigned to both of its endpoints. My question is what are we proving by solving the problem (a)? Are we proving that no two edges share the same endpoints?","['combinatorics', 'graph-theory', 'discrete-mathematics']"
2355599,Heaviside Step Function,"In studying properties of 1/x, its derivatives and its integral,  I came across the following ""apparent"" identity. Plot it, and found that it appears to be the same as the Heaviside function.  Any post with reference to the RHS, or verifying/disproving would be appreciated. $$\frac{\arctan(1/x)+\arctan(x+1/2)+\arctan(2(x^2+1)+x)}{\pi} = H(x)$$ Thanks in advance.","['vector-analysis', 'ordinary-differential-equations', 'calculus', 'proof-verification']"
2355630,why fibre product is crucial in modern algebraic geometry,"Recently, I learn some algebraic geometry and notice that fibre product appears everywhere. I feel like that fibre product plays the same role as Cartesian product of variety in classical algebraic geometry. But I can't figure out that why one wants to use fibre product instead of Cartesian product.","['category-theory', 'abstract-algebra', 'algebraic-geometry']"
2355672,Prove Minkowski's Inequality for Integrals,"I am interested in proving the following claims : Suppose that ( $X$ , $\mathcal{M}$ , $\mu$ ) and ( $Y$ , $\mathcal{N}$ , $\nu$ ) are $\sigma$ -finite measure spaces, and let $f$ be an ( $\mathcal{M} \otimes \mathcal{N}$ )-measurable function on $X \times Y.$ a ) If $f \ge 0$ and $1 \le p < \infty$ , then $$ \left[\int \left(\int f(x,y) d\nu(y) \right)^pd\mu(x)\right]^\frac{1}{p} \le \int \left[\int f(x,y)^p d\mu(x)\right]^\frac{1}{p}d\nu(y)$$ b ) If $1 \le p \le \infty$ , $f(\cdot, y) \in L^p(\mu)$ for a.e. $y$ , and the function $y \to ||f(\cdot, y)||_p$ is in $L^1(\nu)$ , then $f(x, \cdot) \in L^1(\nu)$ for a.e. $x$ , the function $x \to \int f(x,y) d\nu(y)$ is in $L^p(\mu)$ , and $$\left|\left|\int f(\cdot, y)d\nu(y)\right|\right|_p \le \int||f(\cdot, y)||_pd\nu(y).$$","['real-analysis', 'integration', 'measure-theory', 'inequality']"
2355716,How small is an infinitesimal quantity?,"When speaking of infinitesimals, I see some mathematicians say that it represents an ""extremely small"" element, such as an infinitesimal area on a manifold. What bothers me about this naive definition is how small is, an infinitesimal area, for example, supposed to be for it to be called infinitesimal?","['infinitesimals', 'math-history', 'calculus']"
2355738,solve trigonometric lim with tan,"Hi guys I tried to solve the following problem lately and got stucked.
I'd love to get some help and guidance. 
consider this: $$\lim_{x \rightarrow\infty}\tan\left(\frac{\pi x}{2x+1}\right)^{\frac{1}{x}}
$$ I did the following:
1. break to sin and cos : $$
\lim_{x \rightarrow\infty}\tan\left(\frac{\pi x}{2x+1}\right)^{\frac{1}{x}} = \lim_{x\rightarrow\infty}\frac{\left(\sin\left(\frac{\pi x}{2x+1}\right)\right)^\frac{1}{x}}{\left(\cos\left(\frac{\pi x}{2x+1}\right)\right)^\frac{1}{x}}$$ use log rules: $$\lim_{x\rightarrow\infty}\frac{\left(\sin\left(\frac{\pi x}{2x+1}\right)\right)^\frac{1}{x}}{\left(\cos\left(\frac{\pi x}{2x+1}\right)\right)^\frac{1}{x}} =  \lim_{x\rightarrow\infty}\frac{e^{\frac{1}{x}\ln\left(\sin\left(\frac{\pi x}{2x+1}\right)\right)}}{e^{\frac{1}{x}\ln\left(\cos\left(\frac{\pi x}{2x+1}\right)\right)}}$$ Numerator converges to one so I am going to work with the denominator:
$$
 \lim_{x \rightarrow \infty}e^{\frac{1}{x}\ln\left(\cos\left(\frac{\pi x}{2x+1}\right)\right)} = e^\left(\lim_{x \rightarrow \infty}{\frac{1}{x}\ln\left(\cos\left(\frac{\pi x}{2x+1}\right)\right)}\right) 
$$ $$
\lim_{x \rightarrow \infty}{\frac{1}{x}\ln\left(\cos\left(\frac{\pi x}{2x+1}\right)\right)} = \frac{-\infty}{\infty}$$ at this point I tried to apply l'hopital but encountered a huge mess, and now I feel that maybe I chose the wrong way. Please help me guys.","['trigonometry', 'calculus', 'limits']"
2355787,Determinant of a matrix that contains the first $n^2$ primes.,"Let $n$ be an integer and $p_1,\ldots,p_{n^2}$ be the first prime numbers. Writing them down in a matrix
$$
\left(\begin{matrix}
p_1 & p_2 & \cdots & p_n \\
p_{n+1} & p_{n+2} & \cdots & p_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
\cdots & \cdots & \cdots & p_{n^2}
\end{matrix}
\right)
$$
we can take the determinant. How to prove that determinant is not zero for every $n$?","['number-theory', 'prime-numbers', 'linear-algebra', 'determinant']"
2355790,Where did I go wrong? Analyze the logical form of $\{n^2+n+1 | n \in \mathbb{N}\} \subseteq \{2n+1 | n \in \mathbb{N}\}$,"This question is taken from Velleman's $\textit{How to Prove it}$. It is in the exercises section of 2.3, Question 1c: $\{n^2+n+1 | n \in \mathbb{N}\} \subseteq \{2n+1 | n \in \mathbb{N}\}$ My work is as follows, The statement is equivalent to $\forall x(x \in \{n^2+n+1 | n \in \mathbb{N}\} \to x \in \{2n+1 | n \in \mathbb{N}\})$ (definition of a subset) $x \in \{n^2+n+1 | n \in \mathbb{N}\} \equiv \exists n \in \mathbb{N}(x=n^2+n+1)$ and $x \in \{2n+1 | n \in \mathbb{N}\} \equiv \exists n \in \mathbb{N}(x = 2n+1)$ so the final expression ends up as, $\forall x (\exists n \in \mathbb{N}(x=n^2+n+1) \to \exists n \in \mathbb{N}(x=2n+1))$ The solution provided is $\forall n \in \mathbb{N} \: \exists m \in \mathbb{N}(n^2+n+1=2m+1)$ which makes perfect sense to me looking at it in retrospect. I guess the overarching concern that I have is the methodology involved in solving the question - my approach was to break the statement down into smaller parts and then to rewrite after interpreting each individual segment (not an unreasonable strategy IMO, that seems to be what Velleman has been advocating up to this point). Was that approach incorrectly applied in this situation? Or did I make a technical error that I am just not aware of? Thanks in advance for any help/insight that can be given!","['logic', 'elementary-set-theory']"
2355827,Find the number of functions from a 5-element set onto a 3-element set,"In class we learned the number of functions from an $m$-element set to an $n$-element set is $n^{m}$. So this answer should be $5^{3}$? I just need confirmation if my answer is correct, if not explain to me why it's not.","['combinatorics', 'discrete-mathematics']"
2355843,"if a,b,c are roots of a cubic equation then for the following question... [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question If $a, b, c$ are roots of $x^3 -3x^2 + 2x +4 = 0$ and $$y= 1 + \frac{a}{x-a} + \frac{bx}{(x-a)(x-b)} + \frac{cx^2}{(x-a)(x-b)(x-c)}$$ then value of $y$ at $x=2$ is:","['calculus', 'functions']"
2355852,Bins and balls problem: expected number of balls placed given number of empty and non-empty bins?,"Given are $m$ bins with equal probability of choosing one of them. Unknown number of balls $n$ is placed into the bins, and, at the end of placement, we observe number of empty bins $m_e$ and non-empty bins $m_{n}$. Given $m$, $m_e$, $m_n$, what is the most likely number of balls $n$, which have been placed into bins? (UPD) possible additional information: number of bins with exactly one ball can be also known.","['combinatorics', 'probability', 'balls-in-bins', 'probability-distributions']"
2355878,Why isn't lambda notation popular among mathematicians?,"I am relatively new to the world of academical mathematics, but I have noticed that most, if not all, mathematical textbooks that I've had the chance to come across, seem completely oblivious to the existence of lambda notation. More specifically, in a linear algebra course I'm taking, I found it a lot easier to understand ""higher order functionals"" from the second dual space, by putting them in lambda expressions. It makes a lot more sense to me to put them in the neat, clear notation of lambda expressions, rather than in multiple variable functions where not all the arguments are of the same ""class"" as some are linear functionals and others are vectors. For example, consider the canonical isomorphism - 
$$A:V \rightarrow V^{**}$$ It would usually be expressed by $$Av(f) = f(v)$$
This was a notation I found particularly difficult to understand at first as there are several processes taking place ""under the hood"", that can be put a lot more clearly, in my opinion, this way: $$A = \lambda v \in V. \lambda f \in V^{*}. f(v)$$ I agree that this notation may become tedious and over-explanatory over time, but as a first introduction of the concept I find it a lot easier as it makes it very clear what goes where. My question is, basically, why isn't this widespread, super popular notation in the world of computer science, not as popular in the field of mathematics? Or is it, and I'm just not aware?","['lambda-calculus', 'notation', 'linear-algebra', 'dual-spaces']"
2355885,"If a topological space can be partitioned into finitely many second countable subspaces, is it second countable? [Collecting examples]","A topological space is second countable if its topology has a countable basis. Let $(X,\tau)$ be a topological space. Suppose there exists $S_1,\ldots, S_n$ is a finite partition of $X$ such that, for each $1\leq i \leq n$, the subspace $(S_i,\tau|_{S_i})$ is second countable. Does it follow that $(X,\tau)$ is second countable? A negative answer to this question has already been given, but I'd be interested knowing more counterexamples. David Hartley has suggested this follow-up question: If $(X,\tau)$ is first countable and it can be partitioned into finitely many second countable subspaces, is $(X,\tau)$ second countable?",['general-topology']
2355889,Pigeonhole principle- Show that two co-prime integers exist,"Suppose that you are given $n + 1$ different positive integers less than or equal
to $2n$. Show that there must exist two which are relatively prime. The book provides a nice hint which is difficult to come up with : Prove instead that there are two consecutive numbers. So, my solution differs a bit. It would be great if someone could proof-read my solution which goes as follows: If two numbers $a,b$ are not co-prime, then $\exists$ prime $p : p|a, p|b$. Therefore, both the elements must be two of $\lceil{\frac{2n}{p}}\rceil < \frac{2n}{p}$. Now, as we are counting pairs, and the $n+1$ numbers are unique, we can count $\frac{n}{p}$ slots for the pairs corresponding to p. So, overall we have $\frac{n}{2}+\frac{n}{3}+\frac{n}{5}+\cdots+\frac{n}{q}$ such that $q$ is the last prime less than $2n$ (actually $\sqrt{2n}$ should suffice) Now, we have $ {n+1 \choose 2 } = \frac{n*(n+1)}{2}$. So, as the above summation is less than $n+1 \choose 2$(every prime after 3 is greater than 2 and there are at most n terms), we must have some pair outside these multiplication tables hence two co-prime numbers among these must exist.","['combinatorics', 'pigeonhole-principle', 'proof-verification', 'elementary-number-theory']"
2355918,Is every $\mathbb{I}$-compact topological space compact?,"Let $\mathbb{I}$ denote the unit interval. Call a topological space $X$ $\mathbb{I}$-compact iff every continuous function $f : X \rightarrow \mathbb{I}$ attains its maximum at some point in $X$. Question. Is every $\mathbb{I}$-compact topological space compact? We can replace $\mathbb{I}$ with either of $[0,\infty]$ and/or $[-\infty,\infty]$, of course, without changing the meaning of the above definition.",['general-topology']
2356023,"Atiyah flop, flip and related toric computation","I am trying to understand the definitions of flips and flops by studying 
examples in this article of Hacon and McKernan. I would like to ask why the toric varieties constructed in Ex. 1.13 are indeed flips and flops. It is possible that my question can be solved simply answering how to compute relative canonical divisor of a toric morphism . As far as I know (please correct me if I am wrong), a flip $X_{-}\dashrightarrow X_{+}$ between termnal, $\mathbb Q$-factorial varieties is a birational map which is an isomorphism in codimension one and factors as $\varphi_{+}^{-1}\circ \varphi_{-}$, where: $\varphi_{-}\colon X_{-}\to X$ is a small extremal contraction, $\varphi_{+}\colon X_{+}\to X$ is a small contraction such that
$K_{X_{+}}$ is relatively ample. A flop is defined in the same way, but the above two conditions are replaced by: $\varphi_{-}$, $\varphi_{+}$ are small contractions such that $K_{X_{+}}$ and $K_{X_{-}}$ are relatively trivial. The variety $X$ above is only required to be normal. The well known Atiyah flop is constructed as follows: let $X$ be a cone over a quadric surface, $\tilde{X}\to X$ be a blowup of its vertex, and $X_{+}$ and $X_{-}$ are given by contracting one of the two rulings of the exceptional divisor inside $\tilde{X}$. My first question is: is it immediate to see that $K_{X_{-}}$ and $K_{X_{+}}$ are relatively trivial in this case? In the cited paper, Atiyah flop is given a following toric description: let $v_{1},v_{2},v_3,v_4\in \mathbb R^{3}$ be four vectors such that any three of them span the standard lattice $\mathbb Z^{3}$ and
$$\tag{$*$} v_{1}+v_{3}=v_{2}+v_{4}.$$
These vectors generate a full-dimensional cone. Now the fan of $X_{-}$ is constructed from this cone by adding a wall joining $v_{1}$ with $v_{3}$, and the fan of $X_{+}$ is constructed by adding a wall between $v_{2}$ with $v_{4}$ (adding both these walls is the same as adding a ray $v_{1}+v_{3}$, which gives $\tilde{X}$). Now again, my question is, how to use this description to compute the relative canonical divisors and show that $X_{-}\dashrightarrow X_{+}$ is a flop? Next, the authors say that one can obtain an example of a flip by replacing $(*)$ with, say,
$$\tag{$**$} 2v_{1}+v_{3}=v_{2}+v_{4},$$
and follow the same construction. Now $X_{-}$ is singular, $X_{+}$ is smooth. My question is, again, how to see that this is a flip ?","['birational-geometry', 'algebraic-geometry', 'toric-geometry']"
2356086,Show $f:\mathbb R \to \mathbb R$ by $f(x)=\frac{x}{2}+x^2\sin\frac{1}{x}$ is not injective in any neighbourhood of $0$,"Define $f:\mathbb R \to \mathbb R$ by $f(x)=\frac{x}{2}+x^2\sin\frac{1}{x}$ if $x \neq 0$ and $f(0)=0$. Compute $f'(x)$ for all $x \in \mathbb R$. Show that $f'(0)>0$, yet $f$ is not injective in any neighbourhood of $0$. My idea: $f'(x)=\frac{1}{2}+2x\sin{\frac{1}{x}}-\cos{\frac{1}{x}}$ $f'(0)=\frac{1}{2}$ so $f'(0)>0$. (is this correct?) How would I prove non-injectivity?Would I show multiple values for $x$ which both equal the same $f(x_1)=f(x_2)$?","['derivatives', 'real-analysis']"
2356152,"How do I count the number of increasing functions from $\{1, 2, 7\}$ to $\{1, 2, 3, 4, 5, 6, 7, 8\}$?","I can't seem to figure it out, one way I thought about it is: Let's take $f(1) = 1$: $f(2) = 1$ (because it's not strictly increasing) so for $f(7)$ I have $8$ possibilities $f(2) = 2$ so $f(7)$ now has $7$ possibilities $f(2) = 3$ so $f(7)$ now has $6$ possibilities . . and so on. So for $f(1) = 1$ we have $8+7+6+5+...+1$ functions (this can be expressed as the formula $\frac{(n+1)n}{2}$) So for $f(1) = 2$: $f(2) = 2$ results in $7$ possibilities of $f(7)$ . . and so on and it result in $7+6+5+..+1$ so by my reasoning I would say that the number of increasing functions is equal to: $S_8 + S_7 + S_6 + ... + S_1$ (where $S_n = \frac{(n+1)n}{2}$ ) But I'm pretty sure that's not right but I don't know how to think about it.","['combinatorics', 'functions']"
2356166,Stable Acute Triangles in a Grid,"The following combinatorial question came up while trying to prove a lemma for my research. Let $[N]$ denote the $N\times N$ grid inside the integer lattice $\mathbb{Z}\times\mathbb{Z}.$ The square corresponding to $x=(z_1,z_2)\in\mathbb{Z}\times\mathbb{Z}$ is $[z_1-.5,z_1+.5]\times [z_2-.5,z_2+.5]\subset\mathbb{R}\times\mathbb{R}.$ Denote this $S(x).$ Definition An acute three-tuple $\left\{x_1,x_2,x_3\right\}$ is a collection of three elements $x_i\in \mathbb{Z}\times \mathbb{Z}$ so that if $y_1\in S(x_1),$ $y_2\in S(x_2),$ and $y_3\in S(x_3),$ then the triangle with vertices (y1,y2,y3) is acute. Let $\lambda(N)$ be the size of the largest subset of $[N]$ with no acute three-tuple. Question Is $\lambda(N) = O(N^{1+\epsilon})$ for all $\epsilon>0$? I have shown that $\lambda(N) = O(N^{1.5}),$ but the argument is not easily strengthenable.","['combinatorics', 'ramsey-theory']"
2356188,One-sided derivative for a Lipschitz function and its limit,"Let $f(t)$ be a Lipschitz continuous function and let $ f'(t)=\lim_{\delta\downarrow 0 } \frac{f(t+\delta)-f(t)}{\delta}$ denote its one-sided right derivative in $t$.
Assume that $f'(0)$ exists. My question is about the equation:
$$
f'(0) = \lim_{t\downarrow 0} f'(t).
$$
Is this equation necessarily true provided that the limit in the RHS exists? In general, the equation above does not make sense because the RHS may not exists even when $f'(0)$ does, for instance $f(x)=x^2\sin(1/x)$, but if also the RHS exists, does it need to be equal to $f'(0)$?","['derivatives', 'real-analysis', 'lipschitz-functions', 'continuity']"
2356199,Method of moving frames for curves on $S^2$,"I am rather confused about elements of the method of moving frames and how to apply the method of moving frames. $S^2$ is a homegeneous space for the Lie group $SO(3)$. We want to construct a lift $\tilde{\alpha}:U\subset\mathbb{R} \to SO(3)$ of a curve $\alpha: U \subset \mathbb{R} \to S^2$ suitable to our curve geometry, and then compute the pullback of the Maurer-Cartan form to obtain invariants. Identifying the frame bundle with $SO(3)$, I get the following underdetermined lift:
$$ (\alpha(t), e_1(t), e_2(t)). $$ Now, since $\langle \alpha,\alpha \rangle =1$, we have $\langle \alpha', \alpha \rangle =0$, so if we choose (these choices are, I believe, $SO(3)$ invariant) \begin{align} e_1 &= \frac{\alpha'}{|\alpha'|} \\ e_2 &= \frac{e_1' - \langle e_1',\alpha \rangle \alpha}{| e_1' - \langle e_1',\alpha \rangle \alpha|} \end{align} we then pull back the Maurer-Cartan form and use the structure equations to compute the following two invariants: $$ | \alpha'| \ \text{and} \ \Bigg| \Bigg(\frac{\alpha'}{|\alpha'|} \Bigg)' - |\alpha'| \alpha \Bigg| .$$ Where, if anywhere, am I going wrong?","['curves', 'differential-forms', 'geometry', 'cartan-geometry', 'differential-geometry']"
2356211,Need help in limits that contain arithmetic progression,"Let $a_n$ be the $n$-th term of an arithmetic progression with the initial term $a_1=2$ and with the common difference 5. That is, $a_n=2+5(n-1).$
Evaluate $$\lim_{n\rightarrow\infty}n(\sqrt{a_n^2+3}-\sqrt{a_n^2-3}).$$ Well I consider that arithmetic progression here is increasing from 2 to infinity which makes me think that first term in the bracket is greater than the second one. So I think that answer should be positive infinity. But it is not. Can someone help me with it.","['arithmetic-progressions', 'limits-without-lhopital', 'calculus', 'limits']"
2356361,Find maximum value of $\int_{0}^{1}\left(f(x)\right)^3dx$,Find maximum possible value of $\int_{0}^{1}\left(f(x)\right)^3dx$ given that $-1\leq f(x)\leq 1$ and that $\int_{0}^{1}f(x)dx=0$. My attempt: I tried to guess such functions which could satisfy all the above conditions but could not arrive at any conclusion.,"['real-analysis', 'definite-integrals']"
2356399,"Given sequence of $L-$Lipschitz functions which converges pointwise, prove uniform convergence","Let $f_n:[a.b]\rightarrow \mathbb{R}$ be sequence of $L-$Lipschitz functions, that is: $$\forall x,y\in[a,b]: |f_n(x)-f_n(y)|\leq L|x-y|$$
  Suppose $f_n \rightarrow f$ pointwise, prove $f_n \rightrightarrows f$ I have all the parts of the puzzle for the proof, and I'm trying to put them all together, I'm using this in my answer. I would appreciate is you could correct my proof, and if you have an alternative proof, I would be more then happy to see it. My proof: Let $\epsilon>0.$ $f_n$ are uniformly continuous on $[a,b]:$ $\tag{1} \exists \delta>0\ \forall x,y\in[a,b]: |f_n(x)-f_n(y)|<\frac{\epsilon}{3}$ $f$ is also $L-$Lipschitz: $\tag{2} \forall x,y\in[a,b]:|f(x)-f(y)|<L|x-y|=\frac{\epsilon}{3}$ Let us set a partition of $[a,b]$ such as Stephen Montgomery-Smith suggests: Pick points $x_1,\dots,x_m \in [a,b]$ which are distance
  $\frac{\epsilon}{3}$ from each other. For each $1 \le i \le m$, find a number $N_i$ so that for all $n \ge
 N_i$ we have $|f_n(x_i)-f(x_i)| \le \epsilon/3$. Let $N = \max_{1 \le i \le m} N_i$ Now given any $x \in [a,b]$, pick $1 \le i \le m$ such that $|x-x_i| <\frac{\epsilon}{3L}: 
|f_n(x)-f(x)|<\frac{\epsilon}{3} \tag{3}$ $$\begin{align}|f_n(y)-f(y)| &=|f_n(y)-f_n(x)+f_n(x)-f(x)+f(x)-f(y)| \\ &\leq |f_n(y)-f_n(x)| + |f_n(x)-f(x)|+|f(x)-f(y)| \\ &< \frac{\epsilon}{3} + \frac{\epsilon}{3} + \frac{\epsilon}{3} = \epsilon \\\end{align}$$","['real-analysis', 'uniform-convergence', 'proof-writing', 'sequence-of-function', 'lipschitz-functions']"
2356430,"Rank of $A=BC$, when ranks of $B,C$ are given.","[NBHM-PhD Screening test-2015, Algebra(Q 1.7)] Let $B$ be a $5\times3$ matrix and let $C$ be a $3\times5$ matrix, both with real entries. Set $A=BC$ . Then what are the possible ranks of $A$ when (1) both $B$ and $C$ have rank $3$ (2) both $B$ and $C$ have rank $ 2$ I know that $\operatorname{rank}A\leq \min(\operatorname{rank}C,\operatorname{rank}B)$ . From this I can say in first case $\operatorname{rank}A\leq 3,$ and in second case $\leq2$ . What more we can say about rank of $A$ ? also is there any  general method to attack such kind of problems","['matrices', 'linear-algebra']"
2356489,Derivative of ratio of exponential functions: $ \frac{d}{dk}\left(\frac{x_{i}^{k}}{\sum_{j}x_{j}^{k}}\right). $,"Suppose we have a row vector $$X = [x_1\; \cdots \; x_n],$$
where $x_i>0$ for all $i$.
I have the function
\begin{equation}
\frac{d}{dk}\left(\frac{x_{i}^{k}}{\sum_{j}x_{j}^{k}}\right).\quad (1)
\end{equation} I'm trying to prove that (1) is negative for all $x_i\neq \max\{x_j\}$. This seems somewhat intuitive to me. However, my attempts to `prove' it have not been successful. The obvious approach is to use the quotient rule, i.e., 
\begin{align*}
\frac{d}{dk}\left(\frac{x_{i}^{k}}{\sum_{j}x_{j}^{k}}\right)&=\frac{x_{i}^{k}}{\left(\sum_{j}x_{j}^{k}\right)^{2}}\sum_{j}\frac{dx_{j}^{k}}{dk}-\frac{dx_{i}^{k}}{dk}\frac{\sum_{j}x_{j}^{k}}{\left(\sum_{j}x_{j}^{k}\right)^{2}} ,
\end{align*}
which could be carried forward as follows
\begin{align*}
\frac{d}{dk}\left(\frac{x_{i}^{k}}{\sum_{j}x_{j}^{k}}\right)&=\frac{x_{i}^{k}}{\left(\sum_{j}x_{j}^{k}\right)^{2}}\sum_{j}\frac{dx_{j}^{k}}{dk}-\frac{dx_{i}^{k}}{dk}\frac{\sum_{j}x_{j}^{k}}{\left(\sum_{j}x_{j}^{k}\right)^{2}} \\
& =\frac{x_{i}^{k}}{\left(\sum_{j}x_{j}^{k}\right)^{2}}\sum_{j}\frac{dx_{j}^{k}}{dk}-\frac{1}{\sum_{j}x_{j}^{k}}\frac{dx_{i}^{k}}{dk}\\
 & =\frac{1}{\sum_{j}x_{j}^{k}}\left(\frac{x_{i}^{k}\sum_{j}\frac{dx_{j}^{k}}{dk}}{\sum_{j}x_{j}^{k}}-\frac{dx_{i}^{k}}{dk}\right)\\
 & =\frac{1}{\sum_{j}x_{j}^{k}}\left(\frac{x_{i}^{k}\frac{d}{dk}\left(\sum_{j}x_{j}^{k}\right)}{\sum_{j}x_{j}^{k}}-\frac{dx_{i}^{k}}{dk}\right).
\end{align*} It's not clear to me whether this is the right track to be going down, or how the conclusion could be drawn from this. Can anyone help?","['derivatives', 'real-analysis', 'calculus', 'functional-analysis', 'functional-inequalities']"
2356520,Make up a reasonable definition for the bipartite complement of a bipartite graph,"I am shooting from the hip here and seeing what sticks. I tried this definition below which I am not sure works. If it doesn't, please, suggest more accurate definitions. The reason I need this is that I want to be able to replace the degrees in $(4,3,3,3,3,3,3,2,2)$ (which is a degree sequence of a bipartite graph)  with smaller numbers. Let $V$ be the set of vertices of a bipartite graph $G.$ Then $V$ is a union of two partite sets $X, Y$  and $\sum_{v_i \in X}deg(v_i) = \sum_{u_j \in Y}deg(u_j) = m.$ We can define graph $H = (A \cup B, F) = (\text {union of vertices, edges})$ to be bipartite complement of $G$ if $\sum_{d_i \in A}deg(d_i) = \sum_{e_j \in B}deg(e_j) = m.$ For example, suppose a bipartite(?) graph $T$ has partite sets of vertices represented by their degrees as $\{3, 4\}, \{2, 5\}.$ Then $T$'s bipartite complement has partite set of vertices represented by their degrees as $\{1, 6\}, \{1, 2, 4\}.$","['combinatorics', 'graph-theory', 'discrete-mathematics']"
2356541,Power series of a function related to Gamma function,"I'm having trouble solving the following exercise: Let $\alpha \in \mathbb C$ fixed and $f: D \to \mathbb C$  defined by $$f(z) := \frac{1}{(1-z)^\alpha}.$$
  Let $$f(z) = \sum_{n=0}^\infty a_n(\alpha) z^n $$
  be the power series representation of $f$. Show that for the coefficients $a_n(\alpha)$ the following holds:
  $$\lim_{n\to \infty}\frac{a_n(\alpha)}{n^{\alpha - 1}} = \frac{1}{\Gamma(\alpha)}$$ Where $D$ denotes the unit ball and $\Gamma$ the Gamma function. Attempt: I assume I need to find out explicit representation of the coefficients $a_n(\alpha)$ and then show the identity using the Gauß representation of the Gamma function: $$\Gamma(s) = \lim_{n\to \infty} \frac{n! n^s}{s(s+1) \cdot \cdot \cdot (s+n)}.$$ However, I was unable to find a useful one. Expanding the function $f$ into a Taylor series didn't work out (if I did not do it wrong). Is there an easier way to find out the coefficients?","['complex-analysis', 'gamma-function', 'power-series', 'analysis']"
2356579,Generative / Discriminative model for linear regression,"In Murphy's book , page 242-243, it is asked to describe the advantages and disadvantages of the generative model for linear regression, compared with the standard discriminative approach. I'm looking for a complete answer to this, since it is not clear what to say. What I got so far: Disvantages: It is an indirect method, since we have to estimate the joint distribution $Y,\mathbf{X}$ before finding the optimal predictor; There are too many parameters to estimate, namely $\frac{(p+1)(p+2)}{2}$ in the covariance matrix $\Sigma$ of the joint distribution, plus the $p+1$ parameters for the mean of $\textbf{X}$ and $Y$ . Advantages: Better accuracy for small training sets; One can use the joint distribution to generate new data similar to the existing data. There is also one disadvantage that I don't understand so well: it is said that the number of needed parameters is $p+1$ . I think that this refers to $\textbf{w}$ and $w_0$ , but I'm not sure. Thanks in advance.","['regression', 'machine-learning', 'statistics', 'linear-regression']"
2356604,(Bi)nary Relations in Set & Category Theory Notation,"I am new to both category & set theory. From what I have learned of set theory so far: Products between two(+) sets, A×B , create a ""grid"" of elements which completely covers all combinations of elements a ∈ A & b ∈ B (a,b) or (b,a) depending on which way round they were composed. Co-products between two(+) sets, A∪B , are essentially disjoint unions. Aka, all elements of sets A and B are put into a single set, C , and paired with a discriminator such that any overlaps (e.g. a=b ) are still kept and distinguished. (Bi)nary Relations are generalisations of products and co-products in that they represent distinct pairs. However, they do not guarantee every element pair, like products do, nor even that all elements in a given parent set will be used, like co-products. Now, my question is that products and co-products have their respective symbolic representations in category theory ( A×B & A∪B respectively), but I have yet to see how to define a generic (bi)nary relation in notation beyond calling it some arbitrary name (as with any other generic set). How do I correctly denote a set as being a binary relation between two sets, A & B , in both set theory and category theory? Thanks in advance.","['category-theory', 'relations', 'notation', 'elementary-set-theory']"
2356627,"Simplifying $\text{lcm}(a^{n/p_1}-1, a^{n/p_2}-1,\dots, a^{n/p_m}-1)$","Let $n=p_1^{\alpha_1}p_2^{\alpha_2}\dots p_m^{\alpha_m}$, it is possible to simplify
$$L=\text{lcm}(a^{n/p_1}-1, a^{n/p_2}-1,\dots, a^{n/p_m}-1)$$
where $a\in\mathbb{N}$? It would also be fine to assume that $a$ is prime if that aids the progress. My thought was to use cyclotomic polynomials and maybe mess around with some identities of them. Clearly
$$a^{n/\text{rad}(n)}-1\mid a^{n/p}-1$$
so we can pull this term out of the $\text{lcm}$ if desired, and if $m=2$ then using
$$\gcd(a^{n/p_1}-1,a^{n/p_2}-1)=a^{n/(p_1p_2)}-1$$
we can get the result, but I cannot generalize. This simply came up in some stuff I was working on so it may not have a nice solution. It would also help to find some $M$ such that $L\mid M$. Using one of the above observations one such $M$ could be
$$M=\frac{\prod_p (a^{n/p}-1)}{(a^{n/\text{rad}(n)}-1)^{m-1}}$$
which is better than just trivially multiplying all the arguments together. Also as Thomas points out,
$$M=\frac{a^n-1}{\Phi_n(a)}$$
works too.","['number-theory', 'cyclotomic-polynomials', 'elementary-number-theory']"
2356636,Set Theory Complement Function Representation in Category Theory,"In this video on category theory (Curry-Howard-Lambek Isomorphism), the tutor states that there is a 1 to 1 correspondence with boolean logic. My question, then, is how would the NOT function be represented in the category of sets? From my understanding, there could be no morphism between the two sets as no element used in A is used in ¬A . Is it as simple as ignoring the set contents, or do you need a function to the local universal set U , followed by a contra-variant (co) function to the opposite set ¬A ? Thanks in advance. EDIT: To clarify, I am after the category theory representation of the complement ( NOT ) function from set theory. Apologies for any misunderstanding.","['category-theory', 'elementary-set-theory']"
2356649,How to find the quaternion representing the rotation between two 3-D vectors?,"I have two 3-D vectors: $$
V_1 = 
\left[ 
\begin{array}{r}
 -0.9597 \\ -0.9597 \\ 8.8703
\end{array} 
\right]
$$ and $$
V_2 = 
\left[ \begin{array}{r}
-0.9568 \\ -0.9368 \\ 8.8432
\end{array} \right]
$$ How would I find the quaternion matrix to represent the rotation between $V_1$ and $V_2$? Specifically, what algorithm would I have to utilize to find it? MatLab code would be of great use! Thanks in advance.","['rotations', 'matrices', 'quaternions', 'linear-algebra', 'vectors']"
2356658,What can be said if $A^2+B^2+2AB=0$ for some real $2\times2$ matrices $A$ and $B$?,"Let $A,B\in M_2(\mathbb{R})$ be such that $A^2+B^2+2AB=0$ and $\det A= \det B$ . Our goal is to compute $\det(A^2 - B^2)$ .  According to the chain of comments on Art of Problem Solving , the following statements are true: $\det(A^2+B^2)+\det(A^2-B^2)=2(\det A^2+\det B^2)$ . (Is this well known?) (1) $\implies \det(A^2-B^2)=0$ . If $A,B\in M_2(\mathbb{C})$ satisfy $A^2+B^2+2AB=0$ , then $AB=BA$ . $(A+B)^2=0 \implies \det(A^2-B^2)=0$ . Can someone help me with justifying these statements? Edit. Doug M provided an explanation for (1) in the answers. Here is an explanation for (2): $A^2+B^2+2AB=O_2 \implies A^2+B^2=-2AB$ . So $\det(A^2+B^2)=4\det(AB)$ . Now using (1), $\det(A^2-B^2)= 2\left(\det(A^2)-2\det(AB)+\det(B^2)\right) = 2\left((\det(A)^2-\det(B)^2\right) = 0$ .","['matrices', 'linear-algebra']"
2356698,Complex curve:Topology genus and algebraic genus difference?,"This is a question on Gathmann's version 2014 notes on Algebraic Geometry Exercise 0.6. A polynomial of degree $d$ in two complex variables give rise to a surface of genus $\frac{(d-2)(d-1)}{2}$ where as a polynomial of degree $2n$ give rise to a surface of genus $n-1$. Why these two results do not contradict with each other? I took d=3 as an example. $z_2^2=(z_1-a)(z_1-b)(z_1-c)$ as a curve in $C^2$ and assume $a,b,c\in R$ with increment ordering. By taking square root, there will be branch cut $[a,b]$ and another cut $[c,\infty)$. After the procedure of 1 point compactification and gluing, I basically obtained a torus with a line segment removed where the line segment is away from the hole. It is basically torus with 1 point removed. However, there is no reason to believe that $g=\frac{(3-2)(3-1)}{2}=1$ which means 1 hole rather than 2 as I have shown above? Maybe I missed $\delta$ invariants defined on wikipedia for genus of algebraic curves? It would be better someone could kindly elaborate the point I missed here.","['algebraic-topology', 'complex-analysis', 'general-topology', 'algebraic-geometry']"
2356710,Gradient of function composed with linear transformation,"In one dimension we have the following easy result, $\frac{d}{dx} f(ax) = af'(ax)$ for any constant $a$. In higher dimensions, we have two ""reasonable"" candidates for $\frac{d}{d\mathbf{x}}f(A\mathbf{x})$, namely $A \nabla f(A \mathbf{x})$ and $A^T \nabla f(A \mathbf{x})$. By bashing out the algebra I can verify that the correct answer is the second option, but can an experienced mathematician explain why it's obviously the second one?","['multivariable-calculus', 'differential-geometry']"
2356721,"Number of $\mathbb{F}_p$ solutions where $p \equiv 3 \, (\text{mod 4})$ (Silverman's AEC Exercise 10.17a)","This is Exercise 10.17a from Silverman's $\textit{The Arithmetic of Elliptic Curves}$. Let $p \equiv 3 \, (\text{mod 4})$ be a prime and let $D \in \mathbb{F}_p^{\times}.$ Show directly that the equation $$C: v^2 = u^4 - 4D$$ has $p-1$ solutions $(u,v) \in \mathbb{F}_p \times \mathbb{F}_p.$ Hint: Since $p \equiv 3 \, (\text{mod 4})$, the map $u^2 \mapsto u^4$ is an automorphism of $(\mathbb{F}_p^{\times})^2$. (This is true due to the fact that $\left(\frac{-1}{p}\right) = -1$ for $p \equiv 3 \, (\text{mod 4})$ a prime.) I've been stuck on this problem for longer than I feel like I should. The directions indicate to ""show directly,"" but I feel like there are too many different cases to consider to do this efficiently. The only ""insight"" I've gotten so far is that if $-4D$ is a perfect square, then $(0,\pm \sqrt{-4D})$ are two solutions. If $-4D$ isn't a perfect square, then by the Hint, $4D$ is a perfect square and so $(\pm \sqrt[4]{4D}, 0)$ are two solutions. But this leaves $p-3$ solutions undetected (hooray for the case $p = 3$). My main issues are how to ""show directly"" there are $p-1$ solutions and where the Hint is mainly applied. I seem to have ideas that are indirect with no plans on how to tackle them directly.","['number-theory', 'elliptic-curves', 'algebraic-geometry', 'elementary-number-theory']"
2356738,$f\in L^{p}$ iff $\sum_{n=1}^{\infty} 2^{np}(\mu(\{\ x : |f(x)| > 2^{n} \}\ )) < \infty$,"Let $p\in [1, \infty)$, prove that if $f \in L^{p}(\mu)$ iff $$\sum_{n=1}^{\infty} 2^{np}(\mu(\{\ x : |f(x)| > 2^{n} \}\ )) < \infty $$ I tried the following ways but couldn't get any result: If $f\in L^{p}$ 
I considered the following sets: $$E_{n}= \{\ x : |f(x)|^{p} > 2^{np} \}\ =\{\ x : |f(x)| > 2^{n} \}\ $$
From that I derived that $$\sum_{n=1}^{\infty} 2^{np} \chi_{E_{n}}(x) \leq |f(x)|^{p} $$ (I hope that this inequality is correct). So then, if $f\in L^{p}$, then $\int \sum_{n=1}^{\infty}2^{np} \chi_{E_{n}} < \infty \implies \sum_{n=1}^{\infty} 2^{np}(\mu(\{\ x : |f(x)| > 2^{n} \}\ )) < \infty $. I am stuck on the converse though! Thanks in advance for any kind of help!","['lp-spaces', 'real-analysis', 'integration', 'measure-theory']"
2356763,The probability behind Bitcoin.,"I'm trying to understand the end of the foundational paper of Bitcoin In which the author plays a bit with probability to show how his system works. I'll try to explain the technicalities of bitcoin in exchange for some orientations in the probability calculations involved. We consider the scenario of an attacker trying to generate an
  alternate chain faster than the honest chain. The race between the
  honest chain and an attacker chain can be characterized as a Binomial
  Random Walk. The success event is the honest chain being extended by
  one block, increasing its lead by +1, and the failure event is the
  attacker's chain being extended by one block, reducing the gap by -1.
  The probability of an attacker catching up from a given deficit is
  analogous to a Gambler's Ruin problem. Here I'm assuming we are talking about a binomial distribution not about a negative binomial distribution. Some people however consider it corresponds to a negative binomial. I'm not aware that stating that it is a random walk has special implications. Suppose a gambler with unlimited credit starts at a deficit and plays
  potentially an infinite number of trials to try to reach break-even.
  We can calculate the probability he ever reaches break-even, or that
  an attacker ever catches up with the honest chain, as follows: p = probability an honest node finds the next block q = probability the attacker finds the next block $q_z$ = probability the attacker will
  ever catch up from z blocks behind $q_z= 1 \;if p \leq q$ and $q_z = \big(\frac{q}{p}\big)^z \; if p > q$ Given our assumption that p > q, the probability drops exponentially
  as the number of blocks the attacker has to catch up with increases.
  With the odds against him, if he doesn't make a lucky lunge forward
  early on, his chances become vanishingly small as he falls further
  behind. This all makes sense to me. And maybe here is where one could say that $q_z$ follows a negative binomial distribution. However, I expect the number of failures in a negative binomial distribution to remain constant. However in this situation every time that we get a success the difference between the honest chain and the attacker's chain increases, so that the attacker needs more successes to reach the honest chain. Maybe you can clarify this point. We now consider how long the recipient of a new transaction needs to
  wait before being sufficiently certain the sender can't change the
  transaction. We assume the sender is an attacker who wants to make the
  recipient believe he paid him for a while, then switch it to pay back
  to himself after some time has passed. The receiver will be alerted
  when that happens, but the sender hopes it will be too late. The receiver generates a new key pair and gives the public key to the
  sender shortly before signing. This prevents the sender from preparing
  a chain of blocks ahead of time by working on it continuously until he
  is lucky enough to get far enough ahead, then executing the
  transaction at that moment. Once the transaction is sent, the
  dishonest sender starts working in secret on a  parallel chain
  containing an alternate version of his transaction. The recipient waits until the transaction has been added to a block
  and z blocks have been linked after it. He doesn't know the exact
  amount of progress the attacker has made, but assuming the honest
  blocks took the average expected time per block, the attacker's
  potential progress will be a Poisson distribution with expected value $\lambda = z\frac{q}{p}$ Ok, so here definitely I think that we are using the fact that binomial negative or binomial distribution are related in the limit with Poisson's distribution, summarizing: $BN(n,p) \rightarrow_{n \rightarrow \infty, \lambda = n(1-p)} Poisson(\lambda)$ and $B(n,p) \rightarrow_{n \rightarrow \infty,\lambda = np}$ . Looking at the previous formulas I suspect that the author is going for the binomial one. But still I would need some clarification. To get the probability the attacker could still catch up now, we
  multiply the Poisson density for each amount of progress he could have
  made by the probability he could catch up from that point: $\sum_{k \geq 0} \frac{\lambda^ke^{-k}}{k!} \big(\frac{q}{p}\big)^{z-k}$ if $k \leq z$ and $\sum_{k \geq 0} \frac{\lambda^ke^{-k}}{k!} \cdot 1$ if $k > z$ Could you give me some insight to better understand this formula? What I ask for So, in summary I'm asking you to: Make an explicit statement of the random variable that is studied here, what is its distribution and to state whether random walks are important to understand the calculations that I showed. According to your answer to point one describe which of the limits I showed is used to derive the Poisson distribution and explain the idea of the last quotation. I don't really get what is being computed there. Please if you don't understand something about how bitcoin works comment.","['probability', 'probability-distributions']"
2356789,"What is the chance of picking y in a set of x objects, given x chances to pick at random?","Suppose you have a set of x objects. In it is an object y. Suppose you pick at random one object from this set. This set is uniformly distributed. There is a 1 / x chance of picking y. Let's say that you pick x times from the set, then eliminating it from the set. This means there is a 100% chance of picking y. But, let's say that after you picked an object from this set, it is not eliminated. What is the probability of picking y in that case? Would this (Link 1) apply? No, because it presumes you leave the marbles out of the bag, which is not what I mean. That would mean that logically scaling it up, there would be a 100% chance of picking object y, which I know not to be true. Or, would this (Link 2) apply? To simplify things, let's use an example. We have a bag with 10 marbles. 9 of them are white, and one is black. You pick one marble at a time at random, then drop it back in. If you do this 3 times, according logically, this would yield a 3/10 chance of picking the black marble. Now, suppose we scale this up to picking 10 marbles. At a quick glance, a 100% chance would be the logical answer, but if you think about it longer, you can pick the same marble more than once. So what is the probability, in this case, of picking the black marble? Link 1: Probability: best chance of picking a desired marble out of 10 Link 2: Picking a uniformly at random element from a random set",['probability']
2356808,How to prove the Lebesgue density theorem using martingales?,"The Lebesgue density theorem says that for almost every $x \in A \subset [0,1]$ with $A$ Lebesgue measurable $$\lim_{h \to 0^+} \frac{|A \cap (x-h, x+h) |}{2h}=1 \tag{1}.$$ Here, ""almost every"" is with respect to Lebesgue measure, which we denote by $|\cdot|$. This looks an awful lot like martingale convergence and I thought I could prove (1) with martingale methods, but I need a little help concluding. First, if $|A|=0$, then (1) is immediate, so it suffices to prove the result for $A$ in the Borel sigma-algebra $\mathscr{B}$ of $[0,1]$. Switching to ""probabilistic notation"", let $(\Omega, \mathscr{B}, P)$ be Lebesgue measure on the Borel subsets of $[0,1]$. We need a filtration $(\mathcal{F}_n)$ that generates $\mathscr{B}$. We'll use the standard dyadic partitions, that is, each $\mathcal{F}_n$ is generated by the partition $\{[0, 1/2^n),[1/2^n, 2/2^n)...,[1 - 1/2^n , 1) \}$. Then, by martingale convergence for conditional probabilities, for almost every $x$ $$P(A \mid \mathcal{F}_n)(x) \to \mathbf{1}_A(x) \tag{2}.$$ Let $F_n(x)$ be the cell of the partition generating $\mathcal{F}_n$ that contains $x$. By the properties of the conditional probability and (2), for almost every $x \in A$ $$\frac{P(A \cap F_n(x))}{P(F_n(x))} \to 1 \tag{3}.$$ This looks a lot like (1), but I'm having trouble concluding. The difficulty is that (1) considers every open interval centered at $x$, whereas (3) considers only dyadic intervals. Now, it seems likely that (1) follows rather quickly by some argument about approximating open intervals by dyadic ones, but I'm having trouble saying this in a precise way. Any help on this point would be appreciated.","['martingales', 'real-analysis', 'measure-theory', 'probability-theory']"
2356813,How to prove this strange limit? [duplicate],"This question already has answers here : If $f(x) + f'(x) + f''(x) \to A$ as $x \to \infty$, then show that $f(x) \to A$ as $x \to \infty$ (2 answers) Closed 6 years ago . Let $f:[0,\infty)\to\mathbb R$ be a function in $C^2$ such that 
$\lim_{x\to\infty} (f(x)+f'(x)+f''(x)) = a.$
Prove that $\lim_{x\to\infty} f(x)=a$","['real-analysis', 'calculus']"
2356839,Can you have a vertical tangent where a function is undefined?,"Can you have a vertical tangent where a function is undefined? For example, the function $y = 1/x$ is undefined at $x=0$, but that's where the denominator of its derivative is equal to $0$.",['derivatives']
2356957,Geometric interpretation of Gauss elimination,Solution of a set of linear equations is finding a point of intersection of all planes represented by those equations. But how can we relate it to gauss elimination method ? Suppose we have equations like- x + 3y = 4 (A) 2x - 6y = 8 (B) We are trying ti find common value of x and y that will satisfy both equations. So we do B-2A and find the value of y. But how can we explain B-2A geometrically in context of solving these equations ?,['linear-algebra']
2357006,The equation with binomial coefficient $\binom{n-m}{k+m}=\binom{n+m}{k-m}$,"Find all positive integers $n,k$ such that
  $$\binom{n-m}{k+m}=\binom{n+m}{k-m}$$ 1) I solved problem if $m=1$. Its here: $k=1; n=3$ 2) $$\binom{n-m}{k+m}=\binom{n+m}{k-m}$$
$k=m, n=3m$ is root of this equation. Does this equation have other roots?","['combinatorics', 'binomial-coefficients', 'integers']"
2357091,Derivative of trace functions using chain rule,"Let us consider $\text{trace}(f(AA^\top))$ where $f$ is some smooth function and $A \in \mathbb{R}^{n \times m}$. Here, function $f$ is a function of matrices (c.f., Higham's books). If $f(x) = x$, then $\text{trace}(f(AA^\top)) = \|A\|_F^2$ (Frobenius norm) and if $f(x) = x^{p/2}$, then $\text{trace}(f(AA^\top))$ is related to Schatten-$p$ norm. I would like to derivative $\text{trace}(f(AA^\top))$ with respect to matrix $A$. 
Let $g: X\in \mathbb{R}^{n \times n} \rightarrow \text{trace}(f(X)) \in \mathbb{R}$ and $h: A \in \mathbb{R}^{n \times m} \rightarrow A A^\top \in \mathbb{R}^{n \times n}$. By chain rule, it holds that
$$
\frac{\partial g(h(A))}{\partial A} = \frac{\partial g(h(A))}{\partial h} \frac{\partial h(A)}{\partial A}.
$$
To the best of my knowledge, $\frac{\partial g(h(A))}{\partial h} \in \mathbb{R}^{n \times n}$ and $\frac{\partial h(A)}{\partial A} \in \mathbb{R}^{n\times n \times n \times m}$. 
I was confused whether those two terms are productable or not. However, when $p=2$, this corresponds to square of Frobenius norm and its derivative is known as $2 A$. Any comment or advise would be highly appreciated! Thank you.","['matrices', 'trace', 'chain-rule', 'derivatives']"
2357124,Probability of x success with n d10s where a 10 is worth 2 successes,"I want to work out the probability of at least x successes on n D10's where 7 an above is a success but 10 counts as two successes. Easy enough without the 10's counting as two successes with binomial distribution. Probability of success is 0.4 per dice and can work out the probability for any value of x and n using an online calculator, excel etc. But with a 10 on a d10 counts as 2 successes instead of 1, I'm lost. How do I work this out mathematically? Edit This is for a game. A friend is making an excel worksheet to work out the probabilities of success based on varying dice pools ( n) and number of successes needed to pass ( x ). But he doesn't math. I kinda do... well once upon a time... I'm not after answers and explanations on how the math behind them work but the names of functions so I can work out how things work with the power of google would be appreciated. And it will all be plugged into excel eventually if possible so answers with that in mind would be appreciated.","['statistics', 'dice']"
2357127,Relations between matrix norm and determinant,"I was wondering whether there is a way to obtain the determinant of a matrix out of its norm (when the matrix is regular otherwise it is not true). If $A$ is a square matrix of dimension $n\geq 1$ , and $\det A\neq 0$ , do we have something like? $$|Ax|_2 \leq \|A\|_{\text{op}} |x|_2 \leq C_n |\det A| \ |x|_2 \leq \cdots$$ or similar? Or maybe a similar estimate for different norms for $A$ and $x$ if needed since many matrix norms are related to eigen- or singular values which are related to the determinant. Thanks a lot! :)","['inequality', 'matrices', 'normed-spaces', 'determinant', 'linear-algebra']"
2357172,Kolmogorov complexity vs. intuitive notion of simplicity,"Consider the infinite sequence $1,2,4,8,16,...$ If one were asked how the sequence continues the answer would likely be $32,64,..,2^k,..$ and one would implicitly assume the question to be about the ""simplest"" solution. Mathematically speaking the question is ill posed as there is no universal definition of ""simple"". Suppose we are given a finite, increasing sequence $(a_i)$. We define the simplest ""infinite expansion"" of $(a_i)$ to be the infinite language $L\subseteq\mathbb{N}$ for which we have the shortest Turing machine that recognizes $L$, and (assuming the natural ordering on $L$) $(a_i)$ would be the starting fragment of $L$. I would like to understand how well this definition agrees with the intuitive (vague) notion of simplicity. Has this been studied before and are there any examples of simplest solutions for some given starting fragment?","['computability', 'kolmogorov-complexity', 'logic', 'sequences-and-series']"
2357180,Sum of two rank deficient matrices,"Suppose I have two $m\times n$, where $m>n$, matrices $A$ and $B$. The rank of $A$ and the rank of $B$ are strictly less than $n$. Are there any (general) sufficient conditions under which one can guarantee that the rank of sum $A+B$  is strictly less than $n$?","['matrices', 'matrix-rank', 'linear-algebra']"
2357203,Surjections and Injections,"Please examine following Theorem and the accompanying proof. I understand the idea behind the proof, I am just concerned that I might not have put it in the correct words. Is the argument correct? If so can the write up be improved? Given that $f:A\to B$ and that $g:B\to C$.  Prove that if $f$ is not onto and $g$ is one-to-one , then $g\circ f$ is not onto . Proof. Assume that $f$ is not onto , $g$ is one-to-one and $g\circ f$ is onto . Since $f$ is not onto it follows that for some $x\in B$ it is that case that $$\forall a\in A(f(a)\neq x)\ (1)$$
  Since $g:B\to C$ it must be that for some $c\in C$, $g(x)=c$ and since $g$ is one-to-one , $$\forall y\in B(g(y)=c\implies y=x)\ (2)$$
  Since $g\circ f$ is onto it follows that for some $z\in A$, $g(f(z))=c$ but this implies the existence of some $\alpha\in B$ such that $(z,\alpha)\in f$ and $(\alpha,c)\in g$ but $g(\alpha)=c$ and $(2)$ entails that $\alpha=x$ but $(1)$ suggests that no element in $A$ has an image $x$ under $f$ thus no such $\alpha$ exists consequently $$\neg\exists a\in A(g(f(a))=c)$$ contradicting the assumption that $g\circ f$ is onto . $\blacksquare$","['elementary-set-theory', 'functions', 'proof-verification']"
2357226,Image of a circle under a complex valued function,"Find the image of $|z-1| = 1$ under the transformation $w = (1+i)z - 2$. This is confusing as I just started out in this topic. I drew the circle $(x-1)^2 + y^2 = 1$. I see that the equation first wants me to rotate and extend the length of each point (w.r.t its connection to the origin) of the circle by $\frac{\pi}{4}$ radians and by a multiple of $\sqrt{2}$ respectively. Then I shift the circle $2$ units to the left. However, I'm having trouble finding the equation for this. I would prefer a purely algebraic way to manipulate it into the equation.","['circles', 'complex-analysis']"
2357246,Mathematical notation for choosing an element randomly from a set?,I have a nonempty set $\mathcal{S}$ with finite number of elements. Is there any mathematical notation to randomly choose an element $x$ from the set $\mathcal{S}$ ? Each element in the set $\mathcal{S}$ has got equal probability (uniform probability) for getting chosen.,"['notation', 'elementary-set-theory']"
2357258,Is my proof for Schauder's theorem in non-Banach spaces correct?,"Schauder's theorem states: Let $X, Y$ be Banach spaces, let $T \in B(X, Y)$ be a bounded linear
  operator. Then $T$ is compact $\iff$ $T'$ is compact, where $T' \in B(Y', X')$ is the dual operator. The $\implies$ direction is true if $X, Y$ are just normed spaces, see for example E. Kreyszig, Introductory Functional Analysis with Applications, Theorem 8.2-5, pp. 416 (you can find it on google). For the other direction I have a proof that also seems to work if $X, Y$ are just normed spaces. Is it correct? Let $T' \in B(Y', X')$ be compact. Using ""$\implies$"" we have that $T'': \in B(X'', Y'')$ is compact. Let $J_X \colon X \to X''$ be the canonical embedding, $J_Y$ similarly. It is known that
$$
T'' J_X = J_Y T
$$
It follows that $T = J_Y^{-1} T'' J_X$, which is well defined if you consider $J_Y^{-1} : J_y(Y) \to Y$ which is linear and bounded since it's norm-preserving. But then $T$ is compact since $T''$ is compact (If $A$ is compact and $B$ and $C$ are bounded operators, then $BAC$ is compact).",['functional-analysis']
2357266,Are finite extensions of matrix groups also matrix groups?,"Let $G$ be a group and $n$ a positive integer.
I have two related questions: If $K\leq G$ is finite and $G/K$ embeds in $SL_n(\mathbb{Z})$, does $G$ necessarily embed in $SL_d(\mathbb{Z})$ for some $d$? If $K\leq G$ embeds in $SL_n(\mathbb{Z})$ and $G/K$ is finite, does $G$ necessarily embed in $SL_d(\mathbb{Z})$ for some $d$?","['algebraic-groups', 'group-theory']"
2357272,What is $\sum_{r=1}^\infty\frac{r+2}{2^{r+1}(r)(r+1)}$?,"Find out the sum of the following infinite series
$$\frac{3}{2^2(1)(2)} + \frac{4}{2^3(2)(3)} +\dots+\frac{r+2}{2^{r+1}(r)(r+1)}+\cdots
$$
up to $r\to\infty$. MY TRY:-  I tried to split $r+2$ as $[(r+1) +{(r+1)-r}]$ so that I can cancel one term from each terms in the numerator. Then I got an expression which was like Harmonic-Geometric series. But I could not do further any more after this.",['sequences-and-series']
2357275,Pointwise limits of the sequence of derivates of a fixed function =?,"Assume you are given a function $f:\mathbb R\to \mathbb R$ with the following properties: All derivatives $f^{(k)}$ exist everywhere The sequence $(f^{(k)})_k$ converges pointwise to a function $h:\mathbb R \to \mathbb R$ What can be said about the function $h$ ? I looked at a few examples and came up with functions like $f(x) = 3e^x+7e^{-\frac x 2} +42\sin(x/7)+x^{32}$. In this special example the limit funtion is
$h(x) = 3e^x$. What I would like to know: Is it always true that if you start with a function $f$ satisfying the assumptions above, that you end up with a function $h(x)$ which is just a scalar multiple of $e^x$ ?","['derivatives', 'pointwise-convergence', 'calculus']"
2357283,"If two measures are equal as distributions, are they equal as measures?","Consider two complex, regular, Borel measures $\mu$ and $\nu$ on some smooth manifold $M$. If $\int _M f \ \Bbb d \mu = \int _M f \ \Bbb d \nu$ for all Schwartz test functions $f$, does it follow that $\mu = \nu$? A variation of the above: if $M$ is just a topological space and $\int _M f \ \Bbb d \mu = \int _M f \ \Bbb d \nu$ for all bounded continuous functions $f$ (possibly that vanish at infinity), does it follow that $\mu = \nu$? I believe the answer to be positive: first, one proves the result for positive measures, using that $$\mu (E) = \sup \left\{ \int \limits _M f \ \Bbb d \mu ; \quad 0 \le f \le 1, \ \text{supp } f \subseteq E \right\} = \\
= \sup \left\{ \int \limits _M f \ \Bbb d \nu ; \quad 0 \le f \le 1, \ \text{supp } f \subseteq E \right\} = \nu (E)$$ for every open subset $E$; next, one shows that $\mu (E) = \nu (E)$ for every compact subset $E$, by outer regularity; next, $\mu (E) = \nu (E)$ for every measurable subset $E$ by inner regularity; finally, using the Jordan decompositions of the measures, one gets the result for complex measures. Is the above sketch correct? Where is the countable additivity hidden in it (I know that the equality may fail if one of the measures is only finitely additive)? Is finiteness hidden anywhere in it? Is regularity necessary or just convenient?","['distribution-theory', 'functional-analysis', 'lebesgue-integral', 'measure-theory', 'general-topology']"
2357304,theorem about inflection points in (polynomial times exponential),"We know that an exponential function ""kills"" a polynomial, sooner or later. Here I think of polynomials that are increasing and exponential functions that are decreasing.
For instance: $x^2e^{-x^2}$ will go to zero as $x$ grows, as will $x^7e^{-x^2}$, $(C_1\cdot x^9+C_2\cdot x^{111})e^{-x^7-3x^9}$ or any similar such function. These functions all decrease, for large enough $x$, and go to zero, asymptotically
(think of $C_1$, $C_2$ as positive). The way I set up and think about this problem, the exponential function can have no linear term in $x$. Furthermore, the polynomial should only has positive terms, and the exponential only negative terms. Now, my question is if there is a theorem saying that, after having reached its rightmost stationary point, and as x grows further, the function has only one inflection point, and changes exactly once from concave to convex, as it goes to zero? Is this an implication of the fact that the exponential function ultimately dominates the polynomial function? I would very much appreciate any insight on the generality of this ""hypothesis"". Thank you.","['derivatives', 'exponential-function', 'polynomials', 'convex-analysis']"
2357336,Hyper smooth and ultra smooth functions,"So I was mixing smooth functions with fractional calculus when I came upon the following idea.  We could have functions in $D^\alpha$ defined as follows: $f(x)\in D^1\iff\frac d{dx}f(x)=f'(x)$ exists. $f(x)\in D^2\iff\frac{d^2}{dx^2}f(x)=f''(x)$ exists. $f(x)\in D^k\iff\frac{d^k}{dx^k}f(x)=f^{(k)}(x)$ exists. $f(x)\in D^\omega\iff\forall k<\omega(f(x)\in D^k)$, which is equivalent to $f(x)$ being a smooth function. Next, we need to define fractional derivatives .  Per this question, I don't mind which fractional derivative you use, so long as it is one of the many well known and accepted fractional derivatives. Now, we may extend our derivatives further to what I will call hyper smooth functions. $f(x)\in D^{\omega+1}\iff\frac d{dt}f^{(t)}(x)=f^{(1,t)}(x)$ exists. $f(x)\in D^{\omega+2}\iff\frac{d^2}{dt^2}f^{(t)}(x)=f^{(2,t)}(x)$ exists. $f(x)\in D^{\omega+k}\iff\frac{d^k}{dt^k}f^{(t)}(x)=f^{(k,t)}(x)$ exists. $f(x)\in D^{\omega2}\iff\forall\alpha<\omega2(f(x)\in D^\alpha)$ $f(x)\in D^{\omega2+k}\iff\frac{d^k}{du^k}f^{(u,t)}(x)=f^{(k,u,t)}(x)$ exists. $f(x)\in D^{\omega3}\iff\forall\alpha<\omega3(f(x)\in D^\alpha)$ And so on, defining ourselves $D^\alpha$ for every $\alpha\le\omega^2$.  A function is called ultra smooth if we have: $f(x)\in D^{\omega^2}\iff\forall\alpha<\omega^2(f(x)\in D^\alpha)$ But are these functions unique?  Is $\{f(x)\in D^\omega\land f(x)\notin D^{\omega+1}\}$ an empty set or not?  It seems rather hard to find examples (and don't forget you are free to use whichever fractional derivative you choose).  In general, can a function be in $D^\alpha$ but not in $D^\beta$ for $\omega\le\alpha<\beta\le\omega^2$? Assuming we enforce a domain restriction that everything must be $\mathbb R\mapsto\mathbb R$, exponential functions are an appropriate example.  Under certain definitions and $a>0$, we have $$\frac{d^t}{dx^t}a^x=a^x(\ln(a))^t$$ However, when $0<a<1$, we find that $\frac d{dt}\frac{d^t}{dx^t}a^x$ does not exist (as a function $\mathbb R\mapsto\mathbb R$) and so this is an example of a function that is smooth but not hyper smooth.  Likewise this pattern can be used to show the existence of functions $f(x)\in D^{\omega k}$ and $f(x)\notin D^{\omega k+1}$. However, I cannot find any examples where $f(x)\in D^{\alpha+1}$ but $f(x)\notin D^{\alpha+2}$. Allowing functions to be $\mathbb C\mapsto\mathbb C$, I cannot find any other examples of this.","['derivatives', 'fractional-calculus', 'calculus']"
2357337,"If $\sqrt{1-\cos^2x}-\sqrt{1+\sin^2x}=k$, find $\sqrt{1-\cos^2x}+\sqrt{1+\sin^2x}.$ Additional data added","If $\sqrt{1-\cos^2x}-\sqrt{1+\sin^2x}=k$, find $\sqrt{1-\cos^2x}+\sqrt{1+\sin^2x}$ I raised $\sqrt{1-\cos^2x}+\sqrt{1+\sin^2x}$ to the second power in order to express $k$: \begin{align}&\color{white}=1-\cos^2x+2\sqrt{1-\cos^2x}\sqrt{1+\sin^2x}+1+\sin^2x\\&=1-\cos^2x+\sqrt{1+\sin^2x}(2\sqrt{1-\cos^2x}-\sqrt{1+\sin^2x})\\&=1-\cos^2x+\sqrt{1+\sin^2x}2k.\end{align} Since it doesn't give the answer, I also raised the second expression equalling $k$ to the second power. That didn't work out. The variants are: A)$1.5k$ B)$2k$ C)$\frac{2}{k}$ D)$-k$ E)$-\frac{1}{k}$ I have solved it in the way Fred did (having learnt from him) but as is obvious there is NOT such an answer in the variants above. The correct answer is E)$-\frac{1}{k}$ (according to the answer tables in the book). How to get to that correct answer E)???","['radicals', 'trigonometry']"
2357340,How to calculate $\sum_{r=1}^\infty\frac{8r}{4r^4+1}$?,"Calculate the following sum: $$\frac{8(1)}{4(1)^4+1} + \frac{8(2)}{4(2)^4+1} +\cdots+ \frac{8(r)}{4(r)^4+1} +\cdots+ \text{up to infinity}$$ MY TRY:- I took $4$ common from the denominator. and used $a^2+b^2=(a+b)^2-2ab$. It gave me two brackets, whose subtraction was written in numerator. so I did the same thing as we do in the method of partial fraction, and started putting $1,2,3$ and so on. my answer came didn't match with the right answer.",['sequences-and-series']
2357357,Expressing english in logic,"The sentence: The difference of two positive numbers is not necessarily positive, Is expressed as: $$ (\forall x\in\Bbb Z)((x>0)\land(y>0)\rightarrow(x+y >0))$$ Is this statement correctly expressed? If so, please give a brief(or detailed) explanation. This statement implies that if x > 0 and y > 0 then, x + y > 0, where's the necessarily part ? If the necessarily part comes from , the fact that if the R.H.S is False then the statement is false. Then, I'm confused in the contraction with the simple analogy of another statement: ""The product of two negative numbers is always positive"", expressed as: $$ (\forall x\forall y\in\Bbb Z)((x<0) \land (y<0)\rightarrow (x*y) > 0)$$ Which is always true, so, there's no necessarily part in this at all. What I mean is, if the first statement is stated correcly, means that there's a necessarily part in this first statement, in which case, there should also be a necessarily part in the second statement(by comparison), which should not be the case, because the statement is always true. Of course, if the first statement expressed with logic and quantifiers was wrong, everything is solved.(Note, the example the taken from Rosen's book of discrete mathematics.)","['first-order-logic', 'predicate-logic', 'quantifiers', 'logic', 'discrete-mathematics']"
2357380,Complex analysis inequalities,"Show that if $z$ is real, then $$\left|\frac{e^{iz}}{z^2 + 1}\right| \leq \frac{1}{|z|^2 + 1}.$$ I don't see how this is true. The left hand side simplifies as: $\left|\frac{e^{iz}}{z^2 + 1}\right| = \frac{1}{|z^2 + 1|} \geq \frac{1}{|z|^2 + 1}$ by triangle inequality. Am I missing something? Edit: It seems that for any real $z$, both sides equal to each other.......??",['complex-analysis']
2357412,Why is it that when a determinant = 0 then the homogeneous equations represented by the matrix has a non trivial solution? [duplicate],This question already has answers here : Why square matrix with zero determinant have non trivial solution (2 answers) Closed 6 years ago . As I was following a lecture the instructor seemed to assume this and when on solve for the equations where the right side was equal to 0 and proceed with the problem but I know if a determinant is non zero than an inverse matrix exists and visa versa but I cannot seem to relate this to this.  In any event I cannot see the intuition as to why when the determinant is non zero then there are or is a non trivial solution.  I assume in this case the equations are homogeneous.  Thank you,['linear-algebra']
2357416,Is it possible to find a solution to this differential equation?,"Suppose that $f_1(x,y), f_2(x,y), f_3(x,y)$ are known real valued functions. I am wondering if it is always possible to find another function $A(x,y)$ that satisfies: $f_1 \frac{\partial A}{\partial x} + f_2 \frac{\partial A}{\partial y} = f_3$. I am not even sure how to begin here, how should I proceed? Note that it isn't so important to actually find the function $A$, it would be enough to show that it exists.",['ordinary-differential-equations']
2357433,Domain of the function $f(x)=\frac{1+\tfrac{1}{x}}{1-\tfrac{1}{x}}$,"The domain of the function $f(x)=\frac{1+\tfrac{1}{x}}{1-\tfrac{1}{x}}$ is said to be $\mathbb R-\{0,1\}$, given $f(x)$ is a real valued function. I understand why that is the case, since for both $1$ and $0$ the denimonator becomes $0$ and the value is undefined. But,
$$
f(x)=\frac{1+\tfrac{1}{x}}{1-\tfrac{1}{x}}=\frac{x+1}{x-1}
$$
Now I don't see any problem with $x$ taking the value $0$. What really is the domain of the function and how do I justify both the scenarios ?","['algebra-precalculus', 'functions']"
