question_id,title,body,tags
621512,"if range of $f(x) = \frac{x^2+ax+b}{x^2+2x+3}$ is $[-5,4]$. Then $a$ and $b$ are","If Range of $\displaystyle f(x) = \frac{x^2+ax+b}{x^2+2x+3}$ is $\left[-5,4\; \right]$ for all $\bf{x\in \mathbb{R}}$. Then values of $a$ and $b$. $\bf{My\; Try}::$ Let $\displaystyle y=f(x) = \frac{x^2+ax+b}{x^2+2x+3} = k$,where $k\in \mathbb{R}$.Then $\displaystyle kx^2+2kx+3k=x^2+ax+b$ $\Rightarrow (k-1)x^2+(2k-a)x+(3k-b) = 0$ Now we will form $2$ cases:: $\bf{\bullet}$ If $(k-1)=0\Rightarrow k=1$, Then equation is $(2-a)x+(3-b)=0$ $\bf{\bullet}$ If $(k-1)\neq 0\Rightarrow k\neq 1$ means either $k>1$ or $k<1$ How can i solve after that Help Required Thanks",['algebra-precalculus']
621522,"Esoteric knowledge regarding statistic tests like $F$-test, $t$-test and $X^2$ (Chi-Square) etc.","For a year or two I've been doing/learning statistics using books written both for engineers and semi-professionals. I know how to apply most of the theory that statisticians use on job, but I'm still searching for answers why the theory behind statistics is the way it is. In books it is written when to use an $F$-test, $t$-test or $X^2$ (Chi-Square) etc. to solve problems, but the reason why these tests are used are never stated and the theory behind them is completely left out. Why are the theory that goes behind statistics so esoteric (hidden) ? Is it because it is very hard to understand ? Why are the theory / reasons for using these tests not shown in books ? Could someone tell me where to look up the theory, since doing something where you don't have the ""background"" knowledge seems unappealing to me.","['statistics', 'soft-question']"
621530,Why the largest eigenvalue is the bound?,"I am new to Linear Algebra, say introduction level (know the definition and some basic properties, theories about it but not really familiar with doing math on it). Please explain to me: If A is an inverse of a positive definite matrix, then why all of its eigenvalues are positive and why $\frac{x^TAAx}{1+x^TAx}$ is bounded above by the largest eigenvalue of A? Can you recommend some books that offer a higher level than introduction that can help me get over these kind of problems? I'm learning Machine Learning by the way. Thank you.","['eigenvalues-eigenvectors', 'machine-learning', 'vectors', 'matrices', 'linear-algebra']"
621552,Is every Hilbert space an $L^2$ space?,"Let $H$ be any Hilbert space. Must there exist a measure space $(X,\scr{M},\mu)$ such that we have a Hilbert space isomorphism:
$$H\cong L^2(\mu)$$ Thank you","['examples-counterexamples', 'measure-theory', 'hilbert-spaces', 'functional-analysis']"
621566,Generalization of Cayley-Hamilton,"I'm having trouble following a proof of this generalization of the Cayley-Hamilton theorem: Suppose that $M$ is an $A$-module generated by $n$ elements, and that $\varphi \in \operatorname{Hom}_A(M,M)$; let $I$ be an ideal of $A$ such that $\varphi(M) \subset IM$. Then there is a relation of the form $$(**)\quad \varphi^n + a_1 \varphi^{n-1} + \cdots + a_{n-1}\varphi + a_n = 0,$$ with $a_i \in I^i$ for $1 \leqslant i \leqslant n$ (where both sides are considered as endomorphisms of $M$). This is theorem 2.1 in Matsumura's Commutative Ring Theory . The proof there goes as follows: Let $M = A\omega_1 + \dots + A\omega_n$; by the assumption $\varphi(M) \subset IM$ there exist $a_{ij} \in I$ such that $\varphi(\omega_i) = \sum_{j=1}^n a_{ij}\omega_j$. This can be rewritten $$\sum_{j=1}^n(\varphi\delta_{ij} - a_{ij})\omega_j = 0 \quad (\text{for }\  1\leqslant i \leqslant n),$$ where $\delta_{ij}$ is the Kronecker symbol. The coefficients of this system of linear equations can be viewed as a square matrix $(\varphi\delta_{ij} - a_{ij})$ of elements of $A'[\varphi]$, the commutative subring of the endomorphism ring $E$ of $M$ generated by the image $A'$ of $A$ together with $\varphi$; let $b_{ij}$ denote its $(i,j)$th cofactor, and $d$ its determinant. By multiplying the above equation through by $b_{ik}$ and summing over $i$, we get $d\omega_k = 0$ for $1 \leqslant k \leqslant n$. Hence $d\cdot M = 0$, so that $d = 0$ as an element of $E$. Expanding the determinant $d$ gives a relation of the form $(**)$. I would like to understand this particular proof, but I'm having trouble concluding $d\omega_k = 0$ for $1 \leqslant k \leqslant n$ from the multiplication of the above equation by $b_{ik}$ and summing over $i$. It's clear that the right hand side remains zero, but I'm having trouble expanding the left hand side into a useful form. I'm pretty sure I have to use the fact that $d = \sum_{i=1}^n b_{ik} (\varphi\delta_{ik} - a_{ik})$ by the cofactor expansion of the determinant along the $k$th column, but I can only seem conclude $d\omega_k - d\omega_k = 0$, which is not very enlightening. Thanks in advance.","['modules', 'commutative-algebra', 'ring-theory', 'linear-algebra']"
621572,$\int\sin^6(x)\cos(x)dx$.,"$$\int\sin^6(x)\cos(x)\,dx.$$ Apparently... $$\int\sin^6(x)\cos(x)\,dx= \int\sin^6(x)\,d\sin(x)x = \frac{1}{7}\sin^7(x)+c.$$ Can somebody explain the second equality? Shouldn't there be a $dx$ after it?","['trigonometry', 'calculus', 'integration']"
621593,Contracting a contractible set in $\mathbb R^2$,"Assume that $A$ is compact, connected and contractible set in $\mathbb{R}^{2}$ (for example: simple square). If we contract this set to a point the space still will be homeomorphic to $\mathbb{R}^{2}$. Formally: the space $\mathbb{R}^{2}/{}_{\approx}$, where $\approx$ is equivalence relation which equivalence classes are $A$ and singletons, is homeomorphic to $\mathbb{R}^{2}$. This is should be know, it is propably a folklore in topology, but I could not find a source. It bring to my mind Mosers name, but I couldn't find a right theory. Can you bring proper reference?","['general-topology', 'algebraic-topology', 'reference-request']"
621601,"$T=-T^{*}$, show that $T+\alpha I$ is invertible.","Please don't answer the question. Just tell me if I am in the right direction. I should be able to solve this. We are given $T=-T^{*}$, show that $T+\alpha I$ is invertibe for all real alphas that aren't zero. What I did: $det(T+\alpha I) = det(-T^{*}+\alpha I)=det(-\bar T+\alpha I) = \overline {det(-T+\alpha I)}$ And here I'm pretty much stuck. Am I in the right direction?","['matrices', 'complex-numbers', 'linear-algebra', 'determinant']"
621645,What is the derivative of ${}^xx$,"How would one find:
$$\frac{\mathrm d}{\mathrm dx}{}^xx?$$
where ${}^ba$ is defined by $${}^ba\stackrel{\mathrm{def}}{=}\underbrace{ a^{a^{\cdot^{\cdot^{\cdot^a}}}}}_{\text{$b$ times}}$$ Work so far The interval that I am working in is $(0, \infty)$. It doesn't make much sense to consider negative numbers. Although there exists no extension to the reals for tetration I am going to assume that it exists. My theory is that it shouldn't change the algebra involved; (correct me if I am wrong). Some visual analysis on the curve and you can see that it diverges to $+\infty$ extremely rapidly. This means that the derivative is going to have similar properties as well. Let $f(x, y):={}^yx$ so we can rewrite our tetration as $f(x, x)$. Now using the definition of the total derivative: $D\;g(x, y)=\partial_xg(x, y)+\partial_yg(x, y)$. This should allow us to differentiate $f$. $$D\;f(x,y)=\frac{\partial}{\partial x}{}^yx+\frac{\partial}{\partial y}{}^yx$$ Let's focus on the first partial derivative $\partial_x{}^yx$. This is just the case of differentiating a finite power tower as $y$ is treated constant. Firstly looking at some examples do derive a general formula for $D\;\;{}^nx$:
$$
\begin{array}{c|c}
n & D\;\;{}^nx\\
\hline
0 & 0\\
1 & 1\\
2 & {}^2x(\log x + 1)\\
3 & {}^3x\times {}^2x\times x^{-1}(x\log x(\log x + 1)+1)
\end{array}
$$ It is easy to see that there is some pattern emerging however because of it's recursive nature I could not form a formula to describe it. Edit $$\dfrac{d}{dx}\left(e^{{}^nx \log(x)}\right)={}^{n+1}x\dfrac{d}{dx}\left({}^nx \log(x)\right)={}^{n+1}x\left(({}^nx)' \log(x)+\frac{{}^nx}{x}\right)$$
  The recursive formula for the partial was pointed out in comments however an explicit formula would be more useful for this purpose. The second partial derivative is interesting and relies on properties of tetration. I was hoping for it to be similar to exponention such that $$D_y \;x^y=D_y\;e^{y\log x}=e^{y \log x}\log x\;D_y\;y=x^y\log x$$
However I am not sure of an '$e$ for tetration' but I hope it would be something like this:
$$D_y \;{}^yx=D_y\;{}^{y\;\text{slog} x}t={}^{y\;\text{slog} x}t\;\text{slog} x\;D_y\;y={}^yx\;\text{slog}\; x$$
Where $\text{slog}$ denotes the super logarithm (slogorithm), an inverse of tetration. Edit This may as well be a possible identity which can easily be applied to the above:
  $$\text{slog}\;\left({}^yx\right)=\text{slog}^y\;(x)$$ I am unsure about using slogorithms and tetration in this way and I feel I might just be abusing notation. Work on Tetration I will update this section with more rigorous definitions and properties of tetration. I cannot prove all of them now. For $x\in \Bbb R$ and $n \in \Bbb N$, $${}^nx:=\underbrace{ x^{x^{\cdot^{\cdot^{\cdot^x}}}}}_{\text{$n$ times}}\tag{1}$$ For $x\in\Bbb R$ and $a,b\in\Bbb N$?, $${{}^b({}^ax)={}^{a^b}x\tag{$\not2$}}$$
Through simply algebra you can find that the above is not the case. Update: This is just differentiating the pentation function.","['tetration', 'derivatives', 'power-towers']"
621657,Places ramifying in an extension of number fields,"I came across the following statement in a number theory paper: Let $L/K$ denote an arbitrary Galois extension of number fields with Galois
group $G$. Let $S$ be a finite non-empty set of places of L containing all archimedean
places of L (if any) and all those which ramify in the extension $L/K$. What does it mean for a non-Archimedean place of $L$ to ramify in the extension $L/K$? Also can Archimedean places of $K$ ramify in $L$? Many thanks for your help.","['algebraic-number-theory', 'number-theory']"
621692,Advice: Algebra and category theory for geometry?,"I'm interested in learning a bit of geometry. To start I'm (slowly) working my way towards differential geometry via Lee's Introduction to Smooth Manifolds. But, later on, I'd also like to study some (real) algebraic geometry (I'm interest in how it interacts with optimisation). I have a fair bit of exposure to analysis (real/complex/functional, topology, measure theory, probability theory, optimisation, PDEs, stochastic processes, etc.) but virtually none to algebra (only linear algebra) or category theory. Last trimester I attended part of an introductory course on smooth manifolds (couldn't finish it because too many things were going on at the same time). In it the lecturer occasional discussed concepts from algebra (for example, groups) and category theory (for example, universal properties) and I felt that I was missing out. To rectify this I've been reading Conceptual Mathematics:
A first introduction to categories by Lawrence and Schanuel. However, I found this mo post which got me worried I might be going at this the wrong way round. So my questions are: With the end goal of acquiring a working knowledge of differential and algebraic geometry, how much algebra and/or category theory should one know? What references would you recommend to achieve the above, is Lawrence and Schanuel's book a good start? Even if so, what else would you recommend?","['differential-geometry', 'algebraic-geometry', 'abstract-algebra', 'category-theory', 'reference-request']"
621701,Limit of $(\arcsin x)^{\tan x}$ as $x$ tends to zero from the right,"I came across an interesting limit I could not solve: $$
\lim_{x \to 0^{+}}\left[\arcsin\left(x\right)\right]^{\tan\left(x\right)}
$$ Given we have not proven l'Hôpital's rule yet, I have to solve it without it. Also, I would rather not use advanced methods such as the taylor series (which yield $x^x$ here). Squeeze theorem does not (easily?) really help here, nor does the exponent function as far as I see it: $$
\lim_{x\rightarrow 0+}(\arcsin x)^{\tan\,x} = 
\lim_{x\rightarrow 0+} e^{{\tan(x)}\ln(\arcsin x)}
$$
Here again the exponent is an undefined term $(0 \cdot +\infty)$. Unlike all limits I practiced on however, this logarithm does not tend to $1$, so I don't really see how it cancels out. Is there an easy solution I am missing?",['limits']
621712,Fitting curve to more complicated exponential,"I've got a conjecture about the relationship of a dataset. My intuition says it's a decaying exponential, but I want to know which a and b in $e^{-ax^{b}}$ best fits the data. What's the best way to go about it? Most standard stat program doesn't seem to have this capability. I don't think looking at the log of the data would work unless I give it a b to work with either, right?",['statistics']
621715,Find the following limit: $\lim\limits_{x \to 1} \left(\frac{f(x)}{f(1)}\right)^{1/\log(x)}$,"find the following limit $f(x)$ is differentiable at $x=1$ and $f(1)>0$ $\lim\limits_{x\to 1}\left(\dfrac{f(x)}{f(1)}\right)^{\frac{1}{\log(x)}}$ why can i just substitute $x$ for $1$ and thats will be the limit (since $f$ is differentiable, it is also continuous...)","['calculus', 'limits']"
621729,dot product between vector and matrix,"In my book on fluid mechanics there is an expression
$$
\boldsymbol{\nabla}\cdot \boldsymbol{\tau}_{ij}
$$
where
$\boldsymbol{\tau}_{ij}$ is a rank-2 tensor (=matrix). Given that $\boldsymbol\nabla=(\partial_x, \partial_y, \partial_z)$, a vector, what do I get when I dot it with a matrix? If I was to write $\boldsymbol{\nabla}\cdot \boldsymbol{\tau}_{ij}$ in Einstein notation, then how would it look? The tensor $\boldsymbol{\tau}_{ij}$ is given by
$$
 \begin{pmatrix}
  \tau_{xx} & \tau_{yx} & \tau_{zx} \\
  \tau_{xy} & \tau_{yy} & \tau_{zy} \\
  \tau_{xz} & \tau_{yz} & \tau_{zz}
 \end{pmatrix}
$$
and the dot-product yields (by comparison with later expressions in the chapter) $$
\boldsymbol{\nabla}\cdot \boldsymbol{\tau}_{ij} = \mathbf{i}(\partial_x \tau_{xx} + \partial_y \tau_{yx} + \partial_z \tau_{zx})+\mathbf{j}(\partial_x \tau_{xy} + \partial_y \tau_{yy} + \partial_z \tau_{zy}) + \mathbf{k}(\partial_x \tau_{xz} + \partial_y \tau_{yz} + \partial_z \tau_{zz})
$$ However, I don't see how this last expression comes about.","['tensors', 'linear-algebra']"
621733,Evaluation of improper integrals,"Let $f(x)$ be a real-valued function of real variable $x$, whose anti-derivative is difficult to obtain. Suppose we wish to compute the definite integral $$I=\int_a^\infty f(x)\text{d}x,$$ where $a$ is finite. Assuming all standard attempts to evaluate the integral have failed, is the following method plausible and/or known? : Compute the power series of $f(x)$ at $\infty$ (so that we obtain a power series in terms of powers of $1/x$). Integrate the the resulting power series, possibly (?) over an interval, say $[0,y]$ or $[1,y]$, so as to avoid constants of integration, and assuming convergence, let $y\longrightarrow 0$. This should (?) give the limit of the anti-derivative of $f(x)$ at $\infty$. Compute the lower limit in a similar way. Subtract the two limits. The result should be the real number $I$.","['definite-integrals', 'improper-integrals', 'integration']"
621756,Set of integers with a particular additive property,"I have a set of integers $S = \{a_1,a_2,\ldots,a_n\}$. Let $K = a_1+a_2+\ldots+a_n$. Consider the space of all $n$-tuples whose values are taken from the set $S$. 
For example $(a_1,a_2,\ldots,a_n)$ is one $n$-tuple and its sum is $K$, $(a_1,a_1,a_2,a_2,\ldots,a_k)$ is another. 
I need $S$ such that the only $n$-tuple that sums to $K$ among the space of all $n$-tuples is $(a_1,a_2,\ldots,a_n)$. An example that wont work is, if $S = \{1,4,7\}$, $K = 12 (= 1+4+7)$. $\{1,4,7\}$ and $\{4,4,4\}$ both sum to $12$. Similarly if we take $S = \{1,2,3,4,5,6,7\}$, I can think of 2 $7$-tuples that add to $28$. I tried the set $S = \{1, 2, 4, 8, \ldots, 2^n\}$ and it seems to work. Can anyone give me an example that is polynomial instead of exponential in $n$. Would the set $S = \{1, 4, 9, 16, \ldots, n^2\}$ or $\{1, 8, 27,\ldots,n^3\}$ work? Thanks for the comments and suggestions.","['elementary-number-theory', 'combinatorics']"
621757,What are the partial derivatives of a map $f:\mathbb{R}^n \rightarrow \mathbb{R}^m$,"I was wondering what the definition of a partial derivative of such a map is? Is it $\partial_if_j$ or is it anything else? The reason why I have doubts is that I found the definition that a partial derivative is the total derivative of a function $f(\,\cdot\,,x_2): x_1 \mapsto f(x_1,x_2)$, where $(x_1,x_2)$ is some decomposition of $x \in \mathbb{R}^n$.","['calculus', 'partial-derivative', 'real-analysis', 'analysis', 'derivatives']"
621770,Show $\binom{n}{k}\binom{k}{a} = \binom{n}{a}\binom{n-a}{k-a}$ by block-walking interpretation of Pascal's triangle,"A combinatorial proof for the identity 
$$\binom{n}{k}\binom{k}{a} = \binom{n}{a}\binom{n-a}{k-a}$$ is the following ""committee"" argument, which seems the most common. There are $\binom{n}{k}$ ways to select $k$ from a set of $n$ to go on the committee, and then $\binom{k}{a}$ ways to select $a$ from that committee of $k$ to go on a sub-committee of size $a$.  This is equivalent to changing the order of selection to first  choosing the sub-committee of $a$ from the set of $n$, then choosing the remaining $k-a$ on the committee from $n-a$ possible. For anyone familiar with the ""block-walking"" interpretation of Pascal's triangle , how would you show the same identity with a block-walking argument? For those not familiar with block-walking, please observe the following without a   rigorous argument. There are $\binom{4}{2}$ possible paths to reach the point $(4,2)$ in the triangle below, since every path to $(4,2)$ requires $2$ traversals in the direction right out of $4$ traversals total.  As another example, there are $\binom{2}{0}$ paths to reach $(2,0)$. In general,there are $\binom{n}{k}$ ways to reach the point $(n,k$). An example of a ""block-walking"" combinatorial argument for Pascal's identity might be as follows. Observe that the count of possible ways to reach a point $(n,k)$ is exactly the sum of the possible ways to reach the two points which lead to it, namely $(n-1,k-1), (n-1,k)$. To say this algebraically, $\binom{n-1}{k-1} + \binom{n-1}{k} = \binom{n}{k} $.","['integer-lattices', 'binomial-coefficients', 'combinatorics']"
621779,Question regarding usage of residue theorem in a specific case,"I'm looking over the solution of an exercise in a course I'm taking and there's something I simply don't understand. Let $f(z)=\pi\cot(\pi z)$ and $\varphi(z) = \frac{1}{z^2}$.  $f$ has poles of order $1$ in the points $k\in\mathbb{Z}$ and $\varphi$ has a pole of order $2$ at $0$. Now in the solution of the exercise it is written that from the residue theorem the following holds: $$\frac{1}{2\pi i} \int_\gamma f\cdot\varphi \, dz=\operatorname{Res} (f\varphi,0) + \sum\varphi(k)\operatorname{Res}(f,k)$$ where $\gamma$ is a simple positively oriented close curve and the sum extends over the values of $k\in\mathbb{Z}$ contained in the interior of $\gamma$. Now the standard form of the theorem would be: $$\frac{1}{2\pi i} \int_\gamma f\cdot\varphi \, dz = \sum \operatorname{Res} (f\cdot\varphi,k)$$ So for some reason for $k\neq0$ it holds that $\operatorname{Res}(\varphi f,k) = \varphi(k) \operatorname{Res} (f,k)$, why is that? Is it more generally true that if $f,g$ are functions such that $z_0$ is a singularity of $f$ but not of $g$ then $\operatorname{Res}(f\cdot g,z_0) = g (z_0) \cdot \operatorname{Res} (f,z_0)$. Is it maybe necessary to assume that $z_0$ is not a zero of $g$ for this to be true? Help would be appreciated.",['complex-analysis']
621791,Sign of some permutation.,"I trying to find the sign of this permutation: $\left(\begin{array}{cccccccccc}
1 & 2 & 3 & \cdots & \cdots & \cdots & \cdots & \cdots & n-1 & n\\
2 & 4 & 6 & \cdots & 1 & 3 & 5 & \cdots & \cdots & \cdots
 \end{array}\right)$ I think that, I resolved that by counting inversions. If $n=10$ then we have $1$ cycle with length 10, so sign of permutation is equal $(-1)^{10-1}=-1$. $\left(\begin{array}{cccccccccc}
1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10\\
2 & 4 & 6 & 8 & 10 & 1 & 3 & 5 & 7 & 9
 \end{array}\right)=
\left(\begin{array}{cccccccccc}1 & 2 & 4 & 8 & 5 & 10 & 9 & 7 & 3 & 6 \end{array}\right)$ If I'd like to count inversions then I have this table $\begin{array}{ccccc}
(2,1)\\
(4,1) & (4,3)\\
(6,1) & (6,3) & (6,5)\\
(8,1) & (8,3) & (8,5) & (8,7)\\
(10,1) & (10,3) & (10,5) & (10,7) & (10,9)
\end{array}$ There is $\sum_{i=1}^{5}i=\frac{6\cdot 5}{2}=15$ inversions and sign of permutation is equal again $(-1)^{15}=-1$. For generalized form and even $n$ the last of row in this table has form: $(n,1)(n,3),\cdots,(n,n-1)$ Quantity of braces is equal $\frac{n}{2}$. Now we can count inversions $\sum_{i=1}^{\frac{n}{2}}i=\frac{\left(1+\frac{n}{2}\right)\frac{n}{2}}{2}=\frac{(n+2)n}{8}$ If $n$ is odd, then end of permutation has column $\begin{array}{c}n\\n\end{array}$. This is cycle with length $1$ and we can consider permutation of $n-1$ elements, then $n-1$ is even. Finally my result is $\sum_{i=1}^{\left\lfloor\frac{n}{2}\right\rfloor}=\frac{\left(1+\left\lfloor\frac{n}{2}\right\rfloor\right)\left\lfloor\frac{n}{2}\right\rfloor}{2}$ and sign of permutation is equal $(-1)^{\frac{\left(1+\left\lfloor\frac{n}{2}\right\rfloor\right)\left\lfloor\frac{n}{2}\right\rfloor}{2}}$. Exercise is founded in A.I.Kostrikin's book where result is $(-1)^{\frac{n+2}{2}}$. Is my result or result from book proper? And how can I resolve that without counting inversions? Only finding decomposition into disjoint cycles? Calculated values for $2\le n\le 101$. It seems that my formula is working. But I have still question about another way to achieve this result. $\begin{array}{|c|c|c|c|c|c|}
\hline
n & sign & \frac{\left(1+\left\lfloor\frac{n}{2}\right\rfloor\right)\left\lfloor\frac{n}{2}\right\rfloor}{2} & n & sign & \frac{\left(1+\left\lfloor\frac{n}{2}\right\rfloor\right)\left\lfloor\frac{n}{2}\right\rfloor}{2}\\
\hline
2 & -1 & 1 & 52 & -1 & 351\\
3 & -1 & 1 & 53 & -1 & 351\\
4 & -1 & 3 & 54 & 1 & 378\\
5 & -1 & 3 & 55 & 1 & 378\\
6 & 1 & 6 & 56 & 1 & 406\\
7 & 1 & 6 & 57 & 1 & 406\\
8 & 1 & 10 & 58 & -1 & 435\\
9 & 1 & 10 & 59 & -1 & 435\\
10 & -1 & 15 & 60 & -1 & 465\\
11 & -1 & 15 & 61 & -1 & 465\\
12 & -1 & 21 & 62 & 1 & 496\\
13 & -1 & 21 & 63 & 1 & 496\\
14 & 1 & 28 & 64 & 1 & 528\\
15 & 1 & 28 & 65 & 1 & 528\\
16 & 1 & 36 & 66 & -1 & 561\\
17 & 1 & 36 & 67 & -1 & 561\\
18 & -1 & 45 & 68 & -1 & 595\\
19 & -1 & 45 & 69 & -1 & 595\\
20 & -1 & 55 & 70 & 1 & 630\\
21 & -1 & 55 & 71 & 1 & 630\\
22 & 1 & 66 & 72 & 1 & 666\\
23 & 1 & 66 & 73 & 1 & 666\\
24 & 1 & 78 & 74 & -1 & 703\\
25 & 1 & 78 & 75 & -1 & 703\\
26 & -1 & 91 & 76 & -1 & 741\\
27 & -1 & 91 & 77 & -1 & 741\\
28 & -1 & 105 & 78 & 1 & 780\\
29 & -1 & 105 & 79 & 1 & 780\\
30 & 1 & 120 & 80 & 1 & 820\\
31 & 1 & 120 & 81 & 1 & 820\\
32 & 1 & 136 & 82 & -1 & 861\\
33 & 1 & 136 & 83 & -1 & 861\\
34 & -1 & 153 & 84 & -1 & 903\\
35 & -1 & 153 & 85 & -1 & 903\\
36 & -1 & 171 & 86 & 1 & 946\\
37 & -1 & 171 & 87 & 1 & 946\\
38 & 1 & 190 & 88 & 1 & 990\\
39 & 1 & 190 & 89 & 1 & 990\\
40 & 1 & 210 & 90 & -1 & 1035\\
41 & 1 & 210 & 91 & -1 & 1035\\
42 & -1 & 231 & 92 & -1 & 1081\\
43 & -1 & 231 & 93 & -1 & 1081\\
44 & -1 & 253 & 94 & 1 & 1128\\
45 & -1 & 253 & 95 & 1 & 1128\\
46 & 1 & 276 & 96 & 1 & 1176\\
47 & 1 & 276 & 97 & 1 & 1176\\
48 & 1 & 300 & 98 & -1 & 1225\\
49 & 1 & 300 & 99 & -1 & 1225\\
50 & -1 & 325 & 100 & -1 & 1275\\
51 & -1 & 325 & 101 & -1 & 1275\\
\hline
\end{array}$","['alternative-proof', 'permutations', 'combinatorics']"
621792,Evaluating the precision in the calculation of $\mathrm{e}$,"I'm calculating $\mathrm{e}$ using a computer like this:
$$
\mathrm{e} \approx \sum\limits_{i=0}^n {1\over i!}
$$
I'm storing it as a rational number. I was wondering, if I write down my rational number as a decimal number, could I determine, 
how many digits after the decimal point are correct for a given value of $n$?","['sequences-and-series', 'calculus', 'exponential-function', 'approximation', 'analysis']"
621794,Curve of length $L=1$ contained in a semicircle of diameter $2R=1$.,"How prove  that for any curve $\alpha(s)$ of length $L=1$ in the real plane, there is a semicircle of diameter $2R=1$ that contains it. Any hints would be appreciated.","['differential-geometry', 'real-analysis']"
621797,The residual field of $\operatorname{Spec}(\prod_{p} \overline{\mathbb{F}_p})$.,"Let $I$ be a set and $\mathfrak{U}$ be the set of all ultrafilters on $I$. If $E \subset I$ we define $\mathfrak{U}_E$ to be the set consisting of those elements of $\mathfrak{U}$ which contain $E$. We can endow $\mathfrak{U}$ with a topology for which a basis of open sets is given by the $\mathfrak{U}_E$'s. Let $(k_i)_{i\in I}$ be family of fields and put $A = \prod_{i \in I} k_i$. We can then show that for each $\mathscr{F} \in \mathfrak{U}$ $ \mathfrak{m}_{\mathscr{F}} = \{ (x_i)_{i\in I} \in A \;|\; \{i \in I \;|\; x_i = 0 \} \in \mathscr{F} \}$ is a maximal ideal of $A$. Furthermore the map $\mathscr{F} \mapsto \mathfrak{m}_{\mathscr{F}}$ is a homeomorphism from $\mathfrak{U}$ to \operatorname{Spec}(A)$. I've more or less been able to show all of this. But now I'm asked (this is from an old exam from my algebraic geometry course) to show that if $I$ is the set of prime numbers, $k_i = \overline{\mathbb{F}_i}$ and $\xi \in \operatorname{Spec}(A)$ is a point corresponding to a non principal ultrafiler of $I$ then $\kappa(\xi)$ (the residual field of $\xi$) is an algebraically closed field of characteristic zero. I haven't been able to prove this so I'm wondering if anyone can suggest a solution. I'm in fact even more interested in a reference for this result because I find it really cool (and I could check wether what I've done is correct). For information this is exercise $4$ of this exam (in french), you will find more details about ultrafilters in there : http://www.math.jussieu.fr/~lepage/TD/GeoAlg/termgeo-alg2012.pdf","['filters', 'algebraic-geometry']"
621802,is the unique solution of $\cos t = t$ a transcendental number?,"let $\alpha$ be the unique fixed point of $\cos:\mathbb{R} \rightarrow [-1,1]$ for any $t \in \mathbb{R} \setminus\{0\}$ if $t$ is algebraic then $\cos t$ is transcendental. thus if $\alpha$ were algebraic it must also be transcendental, a contradiction, since $\cos\alpha = \alpha$. hence $\alpha$ is transcendental. QUESTION is this argument valid? NOTE re the stated assumption, in answer to this recent question Prahlad Vaidyanathan pointed me to this Wikipedia entry re the Lindemann-Weierstrass theorem.","['trigonometry', 'transcendental-numbers']"
621815,Surface integrals and parametrisation and limits.,"This is a question in preparation for an exam I am going to sit. It is from a previous years exam and no solution has been provided. Let S be the surface in R3 given by $$z = (x^2 + y^2)^{1/2},x^2 + y^2 \leq 1$$
Let v be the vector field given by $${\bf F} = (z^2, z, y^2)$$
I wish to compute, without use of Stokes' theorem $\int_S(\nabla \times {\bf F}) \cdot d{\bf S}$ where dS is oriented inward toward the z axis. Initially I thought about how to parametrise the cone and eventually settled with ${\bf p}(u, v) = (u, v, (u^2 + v^2)^{1/2})$ as I had seen similar in other examples. Now I compute a vector which is perpendicular to the surface. $$\frac{\partial {\bf p}}{\partial u} \times \frac{\partial {\bf p}}{\partial v} = \left( \frac{-u}{(u^2 + v^2) ^ {1/2}}, \frac{-v}{(u^2 + v^2) ^ {1/2}}, 1 \right) $$
It is apparent that this vector points toward the z axis for all u and v. I think the integral should be computed as follows, my issue is I am unsure what the limits should be. $$\int_S(\nabla \times {\bf F}) \cdot d{\bf S} = \int_u\int_v (\nabla \times {\bf F})({\bf p}(u, v)) \cdot \left( \frac{\partial {\bf p}}{\partial u} \times \frac{\partial {\bf p}}{\partial v} \right) du dv$$ If you could help me to the final step of the calculation that would be great, thanks.","['multivariable-calculus', 'integration']"
621823,Probability My Opponent Has a Specific Scrabble Letter Mid-Game,"How does one calculate the probability that an opponent would have a specific letter mid-game? For example: my opponent would have to have a T in his rack in order to hit the Triple Word Score off the word I am considering playing. There are 50 tiles still in the bank (so, that doesn't include the 7 tiles currently on each of our racks.) There are 7 Ts total in the game (I'm actually playing Words With Friends), 2 Ts have been used on the board and I have 1 T in my rack, leaving 4 Ts unaccounted for. So how would I approach calculating the odds that my opponent currently has 1 or more of the remaining 4 Ts on his rack? Thank you!!!",['probability']
621853,What is arcsec (-2)?,"The question asks to solve $\operatorname{arcsec}(-2) $. Options are a) π/3 b) −(π/3) c) 5π/3 d) 4π/3 e) 2π/3 So my thoughts are: this is quadrant 2 or 3; on the unit circle, $ x = -1/2 $. $\cos(t) = 1/2$ where $t$ is 60°. In quadrant 2 that is 2π/3. In quadrant 3 it's 4π/pi. I though that the answer could be either d or e. The answer key says that the only right answer is d. The graphing calculator shows that the answer must be e. Who is right and why?",['trigonometry']
621868,Determine if two straight lines given by parametric equations intersect,"Does
$[x,y,z] = [4,-3,2] + t[1,8,-3]$ intersect with $[x,y,z] = [1,0,3] + v[4,-5,-9] ?$ Attempt To find out if they intersect or not, should i find if the direction vector are scalar multiples? Clearly they are not, so that means they are not parallel and should intersect right? But the correct answer is that they do not intersect. How do you do this? Thanks!","['vector-spaces', 'calculus']"
621869,Complex Analysis - function on open unit disk with $\Re(f(z)) \geq 0$,"Suppose $f:D \to \mathbb C$ is an analytic and non-constant function with $\Re(f(z)) \geq 0$ for all $z \in D$. Show that $\Re(f(z)) > 0$ for all $z \in D$, and that $\left|f(z)\right|\leq \frac{1+|z|}{1-|z|}$ for all $z \in D$ if given that $f(0)=1$. For the first part of the question, my attempt at a solution is brief: consider any $
z_0 \in D$ and any $0<r<\left||z_0|-1\right|$. By the Open Mapping Theorem, $f(B(z_0, r))$ is open in $\mathbb C$. But that means, assuming $\Re(f(z_0))=0$, that there must be some $\omega \in f(B(z_0,r))$ such that $\Re(\omega)<0$, since $f(B(z_0,r)) \cap \{z:\Re(z)<0\} \not = \emptyset$. Thus there is some $z_{\omega} \in D$ such that $\Re(f(z_{\omega}))<0$, a contradiction. Thus the first part in the statement is proved. For the second part of the question, however, I am not certain how to proceed. The setup looks very similar to the conditions for Schwartz' Lemma or the Schwartz-Pick Estimate, so I attempted to analyze $g(z)=f(z)-1$, unfortunately to no avail. Appreciate your input!",['complex-analysis']
621909,When affine variety is complete?,How to prove that an affine variety $X$is complete only if $\dim X=0$? It is clear that in this case $X$ must be a single point. But I don't known why its dimension should be zero. Could anyone help me? Thanks a lot!,['algebraic-geometry']
621922,Continuity in multivariable calculus,"I want to find out the points, where the function $f(x,y)=\dfrac{xy}{x-y}$ if $x\neq y$ and $f(x,y)=0$ otherwise, is continuous. I have shown that at all the points $(x,y)$, where $x\neq y$, $f$ is continuous. Also at all those points $(x,y)\in \mathbb R^2\setminus \{(0,0)\}$ such that $x=y$, $f$ is not continuous. But what would happen at $(0,0)$? I couldn't do. Please give a hint.","['multivariable-calculus', 'continuity', 'real-analysis']"
621947,The symmetrization inequality,"I am looking to prove the following: If $X$ is a real-valued RV such that its symmetrization ($X-X'$ with $X'$ an iid copy of $X$ defined on the same probability space) is $L^1$, then $X$ is actually $L^1$.  This would remove the additional hypothesis from the proof here of theorem 1.6.1 found on p.14.  I'm not too upset about the additional hypothesis just within the context of this theorem, but as far as I can see the author makes use of the stronger claim in the proof of theorem 2.5.2 p.29.  Please correct me if I'm mistaken.  He does not know anything about $X$ being integrable a priori there.",['probability-theory']
621948,How to compute (and check) this transform matrix?,"Background: This is a homework exercise which asks to compute a transform matrix. The answer has been published by our teacher. However, my approach goes a different way and gets a different solution. I checked over and over, but failed to identify the error. The Exercise Problem: Suppose $X \in R^{2 \times 2}$, define a linear transformation over $R^{2 \times 2}$ as: $ \mathbf{T(X)} = \begin{bmatrix} 1 & 1 \\ 2 & 2 \\ \end{bmatrix} X$.
Please compute its transform matrix under the following basis: $\mathbf{E_1} = \begin{bmatrix} 1 & 0 \\ 0 & 0 \\ \end{bmatrix}$, $\mathbf{E_2} = \begin{bmatrix} 1 & 1 \\ 0 & 0 \\ \end{bmatrix}$, $\mathbf{E_3} = \begin{bmatrix} 1 & 1 \\ 1 & 0 \\ \end{bmatrix}$, $\mathbf{E_4} = \begin{bmatrix} 1 & 1 \\ 1 & 1 \\ \end{bmatrix}$. My solution: My approach is simply to transform each of the vectors of the basis by $T$, then insert the result into the columns of a matrix.
      \begin{cases}
        T(E_1) &= \begin{bmatrix} 1 & 1 \\ 2 & 2 \\ \end{bmatrix}
        \begin{bmatrix} 1 & 0 \\ 0 & 0 \\ \end{bmatrix}
        = \begin{bmatrix} 1 & 0 \\ 2 & 0 \\ \end{bmatrix} = E_1 - 2E_3 + 2E_4.
        \\[15pt]
        T(E_2) &= \begin{bmatrix} 1 & 1 \\ 2 & 2 \\ \end{bmatrix}
        \begin{bmatrix} 1 & 1 \\ 0 & 0 \\ \end{bmatrix}
        = \begin{bmatrix} 1 & 1 \\ 2 & 2 \\ \end{bmatrix} = -E_2 + 2E_4.
        \\[15pt]
        T(E_3) &= \begin{bmatrix} 1 & 1 \\ 2 & 2 \\ \end{bmatrix}
		\begin{bmatrix} 1 & 1 \\ 0 & 1 \\ \end{bmatrix}
		= \begin{bmatrix} 1 & 2 \\ 2 & 4 \\ \end{bmatrix} = -E_1 - 2E_2 + 2E_3 + 2E_4.
		\\[15pt]
		T(E_4) &= \begin{bmatrix} 1 & 1 \\ 2 & 2 \\ \end{bmatrix}
		\begin{bmatrix} 1 & 1 \\ 1 & 1 \\\end{bmatrix}
		= \begin{bmatrix} 2 & 2 \\ 4 & 4 \\ \end{bmatrix} = -2E_2 + E_4.		
      \end{cases}
  Thus, the transform matrix of $T$ is:
    $B = \begin{bmatrix}
      1 & 0 & -1 & 0 \\
      0 & -2 & -2 & -2 \\
      -2 & 0 & 2 & 0 \\
      2 & 2 & 2 & 1 \\
    \end{bmatrix}$. My teacher's solution: This approach first computes the transform matrix of $T$ under the natural basis of $R^{2 \times 2}$, that is, $\mathbf{E_{11}} = \begin{bmatrix} 1 & 0 \\ 0 & 0 \\ \end{bmatrix}$, $\mathbf{E_{12}} = \begin{bmatrix} 0 & 1 \\ 0 & 0 \\ \end{bmatrix}$, $\mathbf{E_{21}} = \begin{bmatrix} 0 & 0 \\ 1 & 0 \\ \end{bmatrix}$, $\mathbf{E_{22}} = \begin{bmatrix} 0 & 0 \\ 0 & 1 \\ \end{bmatrix}$. 
      \begin{cases}
        T(E_{11}) &= \begin{bmatrix} 1 & 1 \\ 2 & 2 \\ \end{bmatrix}
        \begin{bmatrix} 1 & 0 \\ 0 & 0 \\ \end{bmatrix}
        = \begin{bmatrix} 1 & 0 \\ 2 & 0 \\ \end{bmatrix} = E_{11} + 0 E_{12} + 2E_{21} + 0E_{22}.
        \\[15pt]
        T(E_{12}) &= 0 E_{11} + E_{12} + 0 E_{21} + 2E_{22}.
        \\[15pt]
        T(E_{21}) &= E_{11} + 0 E_{12} + 2E_{21} + 0 E_{22}.
        \\[15pt]
        T(E_4) &= 0 E_{11} + 1 E_{12} + 0 E_{21} + 2E_{22}.		
      \end{cases}
Therefore,
        $T(E_{11},E_{12},E_{21},E_{22}) = (E_{11},E_{12},E_{21},E_{22}) \begin{bmatrix} 1 & 0 & 1 & 0 \\ 0 & 1 & 0 & 1 \\ 2 & 0 & 2 & 0 \\ 0 & 2 & 0 & 2 \end{bmatrix} = (E_{11},E_{12},E_{21},E_{22}) A$. It then takes advantage of the transform matrix $C$ from the natural basis to the target basis:
$C = \begin{bmatrix} 1 & 1 & 1 & 1 \\ 0 & 1 & 1 & 1 \\ 0 & 0 & 1 & 1 \\ 0 & 0 & 0 & 1 \end{bmatrix}$. So, the transform matrix of $T$ under the target basis is:
$B = C^{-1}AC = \begin{bmatrix} 1 & -1 & 0 & 0 \\ 0 & 1 & -1 & 0 \\ 0 & 0 & 1 & -1 \\ 0 & 0 & 0 & 1 \end{bmatrix} \cdot \begin{bmatrix} 1 & 0 & 1 & 0 \\ 0 & 1 & 0 & 1 \\ 2 & 0 & 2 & 0 \\ 0 & 2 & 0 & 2 \end{bmatrix} \cdot \begin{bmatrix} 1 & 1 & 1 & 1 \\ 0 & 1 & 1 & 1 \\ 0 & 0 & 1 & 1 \\ 0 & 0 & 0 & 1 \end{bmatrix} = \begin{bmatrix} 1 & 0 & 1 & 0 \\ -2 & -1 & -3 & -2 \\ 2 & 0 & 2 & 0 \\ 0 & 2 & 0 & 4 \end{bmatrix}$. My Question: As you can see, the two answers are different. Then, what is wrong with my solution? How to check whether a transform matrix has been correctly computed without the teacher's answer?","['matrices', 'linear-algebra', 'transformation']"
621949,Understanding the derivative as a linear transformation,"It's been a while now I am studying multivariable calculus and the concept of differentiation in space (or higher dimension). I saw relative posts but one question remains. I can't understand the concept of linear transformation that we use to define the Frechet derivative. In single variable the derivative is the best linear approximation of the function, so I guess this extends to multivariable but we can't use a number for this (why?) and instead we use a matrix. Can someone clears this for me in plain english?",['multivariable-calculus']
621957,Definition of Liouville measure on energy surface of Hamiltonian system,"This is a reference request, as I can't for the life of me find anything that answers my question in the literature. If $(M,\omega,H)$ is a Hamiltonian system, we know from Liouvile's theorem that its level sets $H^{-1}(c)$ for $c$ some regular value are tori. Several of the texts I am reading mention that there is a flow-invariant measure on these level sets called the Liouville measure . As I don't think this is trivial, but don't know how to construct it, how is the Liouville measure defined for arbitrary symplectic manifolds, and why is it given by
$$\frac{dS}{||\nabla H||},$$
where $S$ is ""surface area,"" for $M=\mathbb{R}^{2n}$ with the canonical symplectic form?","['measure-theory', 'symplectic-geometry', 'reference-request', 'differential-geometry']"
621960,"Continuous $f$ satisfying $f(2x)=f(x-1/4)+f(x+1/4)$ on $(-1/2,1/2)$","What are the continuous functions $f\colon (-\frac{1}{2},\frac{1}{2}) \to \mathbb{C}$ that satisfy the following functional equation, and how are they derived?
$$f(2x)=f(x-\frac{1}{4})+f(x+\frac{1}{4})\,\,\,\,\,\,\,\,\text{for }x \in (-\frac{1}{4},\frac{1}{4})$$ I think this could be interesting because in addition to the obvious solutions $f(x)=zx$, this is also satisfied by $f(x)=\ln (2\cos(\pi x))$.","['functions', 'real-analysis', 'functional-equations']"
621964,Solving matrix equation $AX = B$,"I want to solve the matrix equation $AX = B$, where the matrix $A$ and $B$ are given as follows $A = 
  \begin{bmatrix}
     0.1375 &   0.0737  &  0.1380  & 0.1169 &  0.1166 \\
    0.0926  &   0.0707   &  0.0957   &  0.0873  &   0.0733 \\
    0.0767   &   0.0642  &   0.0810    &  0.0766  &    0.0599 \\
    0.1593 &    0.1020 &    0.1636 &    0.1451   &  0.1317
  \end{bmatrix}$ $B = 
  \begin{bmatrix}
     0.2794   &   0.0065  &    0.2271    &  0.1265   &   0.2773\\
    0.1676  &  0.2365  &  0.1430  &  0.1015 &   0.0632 \\
     0.0645  &   0.2274 &    0.1009 &    0.1806 &    0.0503\\
    0.2326  &  0.1261  &  0.2867 &   0.2846  &  0.1979
  \end{bmatrix}$ Could anybody help me how to solve this problem? I need help with this. Thanks for the help.","['matrix-equations', 'matrices', 'linear-algebra']"
621977,Find $\sum_{n=0}^\infty\frac{2^n}{3^{2^{n-1}}+1}$,"Find $\sum_{n=0}^\infty\frac{2^n}{3^{2^{n-1}}+1}$. I already proved that it converges but I can't find the sum, Although I think it should be $1+\frac{1}{\sqrt3 +1}$, from calculations.",['sequences-and-series']
621991,Contour integration: $\int_0^\infty \frac{\cos x}{\sqrt{x}}dx$,A problem from a complex analysis qualifier: Find $$\int_0^\infty \frac{\cos x}{\sqrt{x}}dx$$ My answer so far: We want to integrate the function $$f(z) = \frac{\cos z}{\sqrt{z}}dx = e^{iz-\frac12 \log z} + e^{-iz-\frac12 \log z}$$ for a branch of $\log$.,"['complex-analysis', 'contour-integration']"
621993,convergence of the iterated cosine [duplicate],"This question already has answers here : Convergence of cos, sin, tan functions (2 answers) Closed 6 years ago . it can be demonstrated by elementary means that the curves $y=\cos x$ and $y=x$ meet exactly once, at a value $x=\alpha$ satisfying:
$$\cos \alpha = \alpha$$
it is also evident (empirically) that simple reiterated pressing of the cosine button on a calculator produces a sequence that seems to converge at a steady, modest pace, from any initial real value to $0.73908\dots$. however for some time I have fiddled about ineffectually attempting to prove this convergence. this is interesting from a psychological point of view -  because I believed the problem was just beyond my reach, I failed to spot a fairly simple proof-idea, which requires no more than high-school calculus and trigonometry. or at least that is my present thought! the following proof-idea seems OK, though i haven't dotted every i and crossed every t , and since I know myself to be error-prone, I would appreciate it if someone more experienced could check the argument, and remedy any deficiencies - or at worst detect some fundamental flaw I haven't noticed. I am uncertain how to finish off, and also about how to properly manage the role of $\delta$ - in fact the convergence, though not rapid, seems very robust with regard to initial values. thank you firstly, since we know the number $\alpha$ exists, this simplifies the demonstration. it suffices to show that: 
$$\exists \delta,\lambda \in (0,1) .  \forall x \in \mathbb{R}.|x-\alpha| \lt \delta \rightarrow  |\cos x - \alpha| \lt \lambda |x-\alpha|$$ set $\beta=\sin \alpha = \sqrt{1-\alpha^2}$ and let $x=\alpha +\epsilon$. then:
$$
|x-\alpha| = |\epsilon|
$$
and
$$\cos x = \cos \alpha \cos \epsilon - \sin \alpha \sin \epsilon = \alpha (1+O(\epsilon^2)) - \beta(\epsilon + O(\epsilon^3))
$$so:
$$ |\cos x - \alpha| = \beta |\epsilon|+O(\epsilon^2)= (\beta +O(\epsilon))|\epsilon|
$$ giving
$$ |\cos x - \alpha| = (\beta +O(\epsilon))|x-\alpha|
$$","['dynamical-systems', 'trigonometry', 'convergence-divergence']"
622010,How find this $\int_{1}^{2}f^2(x^2)dx+5\int_{2}^{3}f(x^2)dx+7\int_{3}^{4}f(x)dx=\dfrac{1871}{30}$,"Determine all function $f:R\to R$ for which
$$\int_{1}^{2}(f(x^2))^2dx+5\int_{2}^{3}f(x^2)dx+7\int_{3}^{4}f(x)dx=\dfrac{1871}{30}$$ show that
$$f(x)=x?$$
because we easy to find this follow value $$\int_{1}^{2}x^4dx+5\int_{2}^{3}x^2dx+7\int_{3}^{4}xdx=\dfrac{1871}{30}$$
also can see: http://www.wolframalpha.com/input/?i=%5Cint_%7B1%7D%5E%7B2%7Dx%5E4dx%2B5%5Cint_%7B2%7D%5E%7B3%7Dx%5E2dx%2B7%5Cint_%7B3%7D%5E%7B4%7Dxdx My try: since
$$\int_{3}^{4}f(x)dx=2\int_{\sqrt{3}}^{2}uf(u^2)du$$
and I can't
This problem is creat by Mihaly Bencze. I can solve follow this problem $$\int_{0}^{1}f(x)dx=\dfrac{1}{3}+\int_{0}^{1}f^2(x^2)dx$$
then
$$f(x)=\sqrt{x}$$
solution:note
$$\int_{0}^{1}x^2dx=\dfrac{1}{3},\int_{0}^{1}f(x)=\int_{0}^{1}2tf(t^2)dt$$
then
$$0=\int_{0}^{1}[f^2(x^2)-2xf(x^2)+x^2]dx=\int_{0}^{1}[f(x^2)-x]^2dx$$
so
$$f(x^2)=x\Longrightarrow f(x)=\sqrt{x}$$ But for my problem,I can't.Thank you",['integration']
622020,Lebesgue's criterion for Riemann integrability of functions of two variables,"Lebesgue's criterion for Riemann integrability for functions of one variable states that: $f:[a,b]\rightarrow \mathbb{R}$, with $a,b\in\mathbb{R},a\leq b$, is Riemann integrable if and only if $f$ is bounded and continuous $m$-a.e.,where $m$ is the Lebesgue measure on $\left(\mathbb{R},{\cal M}(\mathbb{R})\right)$. Is there such a statement (or similar) for Riemann integrability on $[a,b]\times[c,d]$, with $a,b,c,d\in\mathbb{R},a\leq b,c\leq d$,  of a function $f:[a,b]\times[c,d]\rightarrow \mathbb{R}$, in terms of boundedness and $m^2$-a.e. continuity, where $m^2$ is standard Lebesgue measure on $\left(\mathbb{R}^2,{\cal M}(\mathbb{R}^2)\right)$? Thank you very much. Comment : Thank you, Prahlad. Following Integration and Modern Analysis (Benedetto and Czaja), the proof of ""$\Leftarrow$"" in one variable needs basically the primitive $F(x) = \overline{\int_a^x}f(u)du$ (upper Riemann integral) whose derivative is equal to $f$ $m$-a.e. One then uses it to build a uniformly bounded sequence of functions $F_n(x) = n(F(x+1/n)-F(x))$ convergent to $f$ $m$-a.e. (LDC and some calculations then imply that the upper Riemann integral and Lebesgue integral are equal.) For the moment, I'm having trouble imagining correctly both $F$ and $F_n$ in two variables.","['measure-theory', 'lebesgue-measure', 'integration', 'real-analysis']"
622022,Can this be solved algebraically? $2^x (6 - x) = 8x$,"I've been working on this problem for a few days, but I haven't been able to find $x$ algebraically. (Maybe I'm missing something obvious?) $2^x (6 - x) = 8x$ Using a MATLAB program, I found the solutions $ x = 2, 3, 4 $. I tried using Wolfram|Alpha, but since it didn't provide steps, I assume it solved the equation numerically too. Which is not very elegant. Follow up: I guess the problem I was looking at was not well written, and should have asked for integer solution.",['algebra-precalculus']
622051,What are Green's almost primes?,"In a general-audience talk , Ben Green explains his famous proof with Terence Tao as an application of Szemerédi's theorem, but placing the primes within a smaller set of almost-primes in which they have relative density 50%. This may have been a simplification -- all that is needed is a positive lower density. He shows a slide around 44:30 in the video which gives the primes together with these almost primes, which seem to be: 35, 55, 65, 77, 85, 91, 95, 115, 119, 133, 143, 145, 155, 161, 185, 187, 203, 205, ... Now he claims that these are ""the same numbers that appeared in Chen's theorem"", that is, products of two primes, but that doesn't work. For one, many semiprimes are missing from the above list. For another, the primes have relative density 0 in the set of numbers with at most 2 prime factors. So what is this set? I tried to find an explanation in his 2004 paper , but as far as I can tell there is no sequence there, and the relevant portion (Proposition 9.1 if I am not mistaken) is just an existence result on relevant measures, not a concrete measure where at least one could find the numbers which have 'high' weight. I looked it up in the On-Line Encyclopedia of Integer Sequences and found no results. By omitting terms I could find some hits, special subsequences of odd semiprimes, but nothing promising. (I also tried adding in the primes and searching; no luck.) Even the superseeker failed. Any ideas?","['dynamical-systems', 'sequences-and-series', 'arithmetic-combinatorics', 'number-theory', 'prime-numbers']"
622063,Brouwer's fixed-point theorem and iterative convergence of a composition of circular functions,"let $\psi:[0,1]\times \{0,1\} \rightarrow [0,1]$ be defined by:
$$ \psi(x,\beta) = \beta \cos x + (1-\beta) \sin x $$ define $B_n$ as the set of $2^n$ binary strings $b=b_0b_1\dots b_{n-1}$ where each $b_j$ is a $0$ or a $1$. now, for a given $b \in B_n$ we define a set of $n$ functions: $\psi_{b,k}:[0,1] \rightarrow [0,1] \;(k=0,\dots n-1)$ as follows:
$$ \psi_{b,0}(x) = \psi(x,b_0)
$$ and for $k=1,\dots,n-1$
$$\psi_{b,k}(x) = \psi(\psi_{b,k-1}(x),b_k)
$$
an example may clarify this definition. let $n=5$ and take $b=01101$
then $$ \psi_{b,0}(x) = \psi(x,0) = \sin x \\
\psi_{b,1} (x)= \psi(\sin x,1) = \cos \circ \sin x \\
\psi_{b,2} (x)= \psi(\cos \circ \sin x ,1) = \cos \circ \cos \circ \sin x \\
\psi_{b,3} (x)= \psi(\cos \circ \cos \circ \sin x ,0) = \sin \circ \cos \circ \cos \circ \sin x \\
\psi_{b,4} (x)= \psi(\sin \circ \cos \circ \cos \circ \sin x ,1) = \cos \circ\sin \circ \cos \circ \cos \circ \sin x 
$$
in this fashion, for any bit-string $b$ of length $n$, we may define $\psi_b:[0,1] \rightarrow [0,1]$ as the last of these functions $\psi_{b,n-1}$ QUESTION my recent question about the convergence of the iterated cosine was answered by user44197 by applying Brower's fixed point theorem. this problem was in fact the case $\psi_1$. can the same method be used to assure the iterative convergence of any $\psi_b$?","['dynamical-systems', 'trigonometry', 'convergence-divergence']"
622076,Continuity $\Rightarrow$ Intermediate Value Property. Why is the opposite not true?,Continuity $\Rightarrow$ Intermediate Value Property. Why is the opposite not true? It seems to me like they are equal definitions in a way. Can you give me a counter-example? Thanks,"['continuity', 'examples-counterexamples', 'real-analysis']"
622095,Verifying that the ideal $(x^3-y^2)$ is prime,"How to prove that the ideal $I=(x^3-y^2)$ in $k[x,y]$ is prime? I have constructed a map from $k[x,y]$ to $k[t]$, which maps $x$ to $t^2$, and $y$ to $t^3$. Then, I want to show that the kernel is exactly $I$. But the difficulty is that how to prove the kernel is contained in $I$. 
Could you help me? Thanks a lot!","['commutative-algebra', 'ideals', 'abstract-algebra']"
622123,Proof of an inequality involving $e^x$.,"Prove that $e^{x-1} \geq x, $ for every $x$. I'm not allowed to use MVT or integrals, but IVT and derivatives are allowed. I tried to define a function $f(x)=e^{x-1}-x$ and then $\,f'(x)=e^{x-1}-1$ so the function has minimum in $x=1$ where $y=0$, thus the inequality holds. Is that good? Is there another way which does not involve derivatives? Thanks!","['inequality', 'calculus', 'derivatives']"
622126,Understanding cross ratio and harmonic conjugates,"I'm studying projective geometry and I'm really having trouble with ''grokking'' what's it all about. Is there an easy/intuitive/visual way to understand cross ratio? I understand that it's important because it's an invariant of projective transformations, I just don't understand how someone could discover that: oh, if I just take the ratio of these two points, and ratio of these two points... Not understanding cross ratio, of course I don't understand harmonic conjugates (I'm aware of complete quadrangle definition too, but it doesn't makes things easier for me) and why would someone want to define such a thing. I'm aware that this is maybe one of those situations where some concepts and definitions start to make sense after several new definitions and theorems, and you get that Ooooh, that's what we are trying to do here moment.
On the other hand, roots of projective geometry are in the drawings and art, so I have a feeling that these concepts maybe could be ''explainable'' in some easier way.","['geometry', 'intuition', 'projective-geometry']"
622142,"Obtaining a binary operation on $X \rightarrow Y$ from a binary operation on $Y$. What, if anything, to make of this observation?","Let $X$ and $Y$ denote sets. Then if $+$ is a binary operation on $Y$, then we can obtain a new binary operation $+'$ on $Y^X$ in a canonical way as follows. $$(f+' g)(x) = f(x)+g(x)$$ Question. The other day, I noticed a suggestive-looking variant of the above definition. However, I'm not sure what to make of this observation. Does it have any particular significance? The variant. Let us firstly assign to each $x \in X$ an ""evaluation"" function $\tilde{x} : Y^X \rightarrow Y$ with defining property $\tilde{x}(f) = f(x).$ This allows $+'$ to be defined as follows, where it is understood that $f$ and $g$ range over all functions $X \rightarrow Y$ and $x$ ranges over every element of $X$. $$\tilde{x}(f+' g) = \tilde{x}(f)+\tilde{x}(g)$$ In other words, we're defining that $+'$ is the unique binary operation such that for all $x \in X,$ we have that $\tilde{x}$ is a magma homomorphism with source $(Y^X, +')$ and target $(Y,+)$. Does this final characterization of $+'$ have any particular significance and/or does it ""go anywhere""?","['functions', 'abstract-algebra', 'universal-algebra', 'category-theory', 'soft-question']"
622190,Dynamical system equilibrium point increment,"I am reading through the dynamical systems theory and there is an example of a Mass-Spring system. The state equations are given by $\displaystyle \frac{d x_1}{dx}(t) = x_2(t)$ $\displaystyle \frac{d x_2}{dx}(t) = \frac{-k}{m}x_1(t)+\frac{f(t)}{m}$ Then we find the equilibrium point by setting $\displaystyle 0 = x_2(t)$ $\displaystyle 0 = \frac{-k}{m}x_1(t)+\frac{f(t)}{m}$ Which gives as result $x_{eq} =
\left[
\begin{array}{c}
x_{1} \\
x_{2} \\
\end{array}
\right]
=
\left[
\begin{array}{c}
f/k \\
0 \\
\end{array}
\right]$ Finally, the book defines the increment with respect to the equilibrium point $\Delta x(t) = x(t) - x_{eq}$. Substracting equation (1,3) and (2,4) the result is $\displaystyle \frac{d \Delta x_1}{dx}(t) = \Delta x_2(t)$ $\displaystyle \frac{d \Delta x_2}{dx}(t) = \frac{-k}{m}\Delta x_1(t)$ So far so good, but for the next step they get ""the general solution, parametrized by the initial state"" as $\displaystyle \Delta x_1(t) = \Delta x_1(0) cos(\omega t) + \frac{\Delta x_2(0)}{\omega} sin(\omega t)$ $\displaystyle \Delta x_2(t) = -\Delta x_1(0) \omega sin(\omega t) + \Delta x_2(0)cos(\omega t)$ This result I don't understand where does it comes from, could someone give me a hint?","['dynamical-systems', 'ordinary-differential-equations', 'systems-of-equations']"
622195,Taking a derivative with respect to a matrix,"I'm studying about EM-algorithm and on one point in my reference the author is taking a derivative of a function  with respect to a matrix. Could someone explain how does one take the derivative of a function with respect to a matrix...I don't understand the idea. For example, lets say we have a multidimensional Gaussian function: $$f(\textbf{x}, \Sigma, \boldsymbol \mu) = \frac{1}{\sqrt{(2\pi)^k |\Sigma|}}\exp\left( -\frac{1}{2}(\textbf{x}-\boldsymbol \mu)^T\Sigma^{-1}(\textbf{x}-\boldsymbol \mu)\right),$$ where $\textbf{x} = (x_1, ..., x_n)$,  $\;\;x_i \in \mathbb R$, $\;\;\boldsymbol \mu = (\mu_1, ..., \mu_n)$, $\;\;\mu_i \in \mathbb R$ and $\Sigma$ is the $n\times n$ covariance matrix. How would one calculate $\displaystyle \frac{\partial f}{\partial \Sigma}$? What about $\displaystyle \frac{\partial f}{\partial \boldsymbol \mu}$ or $\displaystyle \frac{\partial f}{\partial \textbf{x}}$ (Aren't these two actually just special cases of the first one)? Thnx for any help. If you're wondering where I got this question in my mind, I got it from reading this reference: (page 14) http://ptgmedia.pearsoncmg.com/images/0131478249/samplechapter/0131478249_ch03.pdf UPDATE: I added the particular part from my reference here if someone is interested :) I highlighted the parts where I got confused, namely the part where the author takes the derivative with respect to a matrix (the sigma in the picture is also a covariance matrix. The author is estimating the optimal parameters for Gaussian mixture model, by using the EM-algorithm): $Q(\theta|\theta_n)\equiv E_Z\{\log p(Z,X|\theta)|X,\theta_n\}$","['multivariable-calculus', 'matrix-calculus', 'derivatives', 'normal-distribution', 'scalar-fields']"
622212,Subspace Topology of a subset,"Show that if $Y$ is a subspace of $X$, and $A$ is a subset of $Y$, then the topology $A$ inherits as a subspace of $Y$ is the same as the topology it inherits as a subspace of $X$. First some notational specifications: Let us define $\tau$ as the topology of $X$
$\tau_{Y}=\{U \cap Y; U \in \tau \}$; $\tau_{A}^Y=\{V \cap A; V \in \tau_{Y} \}$ and $\tau_{A}^X=\{U \cap A; U \in \tau \}$ Let us show that $\tau_{A}^Y=\tau_{A}^X$ $\subset$: Let $V \cap A$ be an element of $\tau_{A}^Y$ such that $V \in \tau_{Y}$ Then, there exists $U\in \tau$ such that $V=U\cap Y$ $V\cap A=(U\cap Y)\cap A=U\cap (Y\cap A)= U\cap A$ Hence: $V\cap A \in \tau_{A}^X$ and so: $\tau_{A}^Y \subset \tau_{A}^X$ $\supset$: Let $U \cap A \in \tau_{A}^X$ $U\in \tau \iff U \text{ open in } X$ But $U \cap Y$ open in $Y \iff U \cap Y \in \tau_{Y}$ Hence $(U \cap Y) \cap A \in \tau_{A}^Y$ since $U \cap Y \in \tau_{Y}$ Therefore $U \cap A \in \tau_{A}^Y$ Hence: $\tau_{A}^X \subset \tau_{A}^Y$ Therefore: $\tau_{A}^Y=\tau_{A}^X$","['general-topology', 'solution-verification']"
622239,A question on integration,"I want to compute the following integral:
$$\raise 1ex{\Large\int} \frac{\sqrt{\ln(x+\sqrt{1+x^2}})}{1+x^2}\,dx$$","['integration', 'indefinite-integrals']"
622242,"Bijection from ordered pairs of $[0,n]$","I am looking for a simple expression to convert ordered pairs from  $[0,n]$ to the first smallest subset of $\mathbb N$.
For example if $n = 3$: $$ (0, 1) \rightarrow 0$$
$$ (0, 2) \rightarrow 1$$
$$ (0, 3) \rightarrow 2$$
$$ (1, 2) \rightarrow 3$$
$$ (1, 3) \rightarrow 4$$
$$ (2, 3) \rightarrow 5$$ What could be an explicit formula for that? To rephrase, I am looking for a formula $f_n(i, j)$ where $0 \le i < j \le n$ such that $0 \le f_n(i, j) < \left ( ^{n}_{2}\right )$ and $f_n$ is bijective. I would also like if possible the inverse bijection to retrieve $i$ and $j$ from an image of $f_n$. The values of the function do not matter as long as the set of values is the same. Cantor pairing functions are not applicable here because the bijection is not infinite.",['functions']
622271,Does the implicit function theorem imply Peano existence theorem,"In The implicit function theorem written by Krantz & Parks, it's said that the implicit function theorem implies the following existence theorem of ODE: Theorem 4.1.1 If $F(t,x)$, $(t,x)\in\mathbb R\times\mathbb R^N$, is continuous in the $(N+1)$-dimensional region $(t_0-a,t_0+a)\times B(x_0,r)$, then there exists a solution $x(t)$ of
  $$\frac{dx}{dt}=F(t,x),\qquad x(t_0)=x_0$$
  defined over an interval $(t_0-h,t_0+h)$. It's Peano existence theorem, I think. However, there seems a gap in their proof. WLOG, suppose $t_0=0$. They constructed $\mathcal H\colon[0,1]\times\mathcal B_1\to\mathcal B_0\times\mathbb R$, where $\mathcal B_0$ is the space of bounded continuous $\mathbb R^N$-valued functions on $(-a,a)$ normed canonically, and $\mathcal B_1$ is the space of bounded continuously differentiable $\mathbb R^N$-valued functions on $(-a,a)$ that also have a bounded derivative, normed canonically by $\sup\lvert f\rvert+\sup\lvert\dot f\rvert$, as follows:
$$\mathcal H[\alpha,X(\tau)]=[X'(\tau)-\alpha F(\alpha\tau,X(\tau)),X(0)-x_0]$$.
Note that $\mathcal H[0,x_0]=[0,0]$, where $x_0$ on the left side denotes the constant function. Then they claim that the existence theorem follows from the implicit function theorem. However, under the only condition that $F$ is continuous, there's no evidence that $\mathcal H$ is partially differentiable with respect to $X$ for $\alpha\in(0,x_0)$. Can we fix the preceding proof in some extent? PS: I posted the question not only because I want to comprehend such a proof, but also want to understand the relation between ODE and implicit functions. It seems certain that such a proof cannot be alright, since the canonical implicit function theorem is also a uniqueness theorem, which implies the local uniqueness of a solution of ODE. However, I want to know how to fix it. I doubt it might rely on a more general implicit function theorem.","['functional-analysis', 'ordinary-differential-equations', 'calculus-of-variations', 'real-analysis', 'implicit-function-theorem']"
622272,"According to $\lim_{n\to\infty}\frac{\sum_{k=1}^na_k}{n}=0,\lim_{n\to\infty}(a_{n+1}-a_n)=0,$ then can we get $\lim_{n\to\infty}a_n=0?$","Suppose that $\{a_n\}$ is a real sequence with $$\lim_{n\to\infty}\frac{\sum\limits_{k=1}^na_k}{n}=0,\lim_{n\to\infty}(a_{n+1}-a_n)=0,$$ then can we get $$\lim_{n\to\infty}a_n=0?$$ This simple problem has got on my nerves for two days, I've tried to prove that is ture, however, there's nothing I can get.","['sequences-and-series', 'real-analysis', 'limits']"
622278,Relation between the convergence of $\sum a_{n}$ and $\prod (1+a_{n})$ [duplicate],This question already has an answer here : sufficiency and necessity of convergence of $\sum a_n$ wrt convergence of $\prod (1 + a_n)$ (1 answer) Closed 10 years ago . What is the relation between the convergence of $\sum a_{n}$ and $\prod (1+a_{n})$ where $a_{n} \in \mathbb{C} \ \forall n$ ? Where can I find some references about this topic ?,"['infinite-product', 'sequences-and-series', 'reference-request', 'analysis', 'complex-analysis']"
622296,How to calculate $ \int \frac{x^3+x^2}{x^3-1} \mathrm{d}x$,"I was trying to solve this integral: $$ \int \frac{x^3+x^2}{x^3-1} \mathrm{d}x$$ I made the following steps: Polynomial division: $$ \frac{x^3+x^2}{x^3-1} = \left(1+\frac{x^2+1}{x^3-1}\right)$$ Hermite polynomials: $$ \frac{x^2+1}{x^3-1} = \frac{2}{3}\frac{1}{x-1}+\frac{\frac{x}{3}-\frac{1}{3}}{x^2+x+1}$$ So, now the integral becomes: $$x+\frac{2}{3}\log{|x-1|}+\int \dfrac{\frac{x}{3}-\frac{1}{3}}{x^2+x+1} \mathrm{d}x$$ But i think there's something wrong, i can not continue. Any ideas?","['integration', 'indefinite-integrals']"
622297,Express the mathematical constant $e$ in terms of a limit that goes to zero.,The mathematical expression of the mathematical constant $e$ in terms of a limit that goes to infinity is $$e = \lim\limits_{n\rightarrow \infty} \left(1+\frac{1}{n}\right)^n$$ But can we express the mathematical constant $e$ in terms of a limit that goes to zero; $e=\lim\limits_{n\rightarrow 0} ...$? Thank you. (problem from book of Spivak),"['constants', 'calculus', 'limits']"
622313,"Calculation of $\int^{\pi/2}_{0}\cos^{n}(x)\cos (nx)\,dx$, where $n\in \mathbb{N}$","Compute the definite integral $$
\int^{\pi/2}_{0}\cos^{n}(x)\cos (nx)\,dx
$$ where $n\in \mathbb{N}$. My Attempt: Using $\cos (x) = \frac{e^{ix}+e^{-ix}}{2}$, we get $$
\begin{align}
\int^{\pi/2}_{0}\cos^{n}(x)\cos (nx)\,dx&=\int_{0}^{\pi/2} \left(\frac{e^{ix}+e^{-ix}}{2}\right)^n\left(\frac{e^{inx}+e^{-inx}}{2}\right)\,dx\\
&= \frac{1}{2^n}\mathrm{Re}\left\{\int_{0}^{\pi/2} \left(e^{ix}+e^{-ix}\right)^n\cdot e^{inx}\,dx\right\}\\
&=\frac{1}{2^n}\mathrm{Re}\left\{\int_{0}^{\pi/2}\left(e^{2ix}+1\right)^n\,dx\right\}
\end{align}
$$ Letting $z=e^{4ix}$ gives us $$
\begin{align}
e^{4ix}dx &= \frac{1}{4i}dz\\
dx &= \frac{dz}{4iz}
\end{align}
$$ So the integral becomes $$\frac{1}{4\cdot 2^n}\mathrm{Re}\left\{\int_{C}\left(\sqrt{z}+1\right)\cdot \frac{dz}{iz}\right\}$$ How can I complete the solution from here?","['residue-calculus', 'calculus', 'complex-analysis', 'contour-integration']"
622321,Infinite product $(1+z)\prod_{n=1}^{+\infty}(1+z^{2^{n}})$,"I have to show that if $|z| < 1$, $z \in \mathbb{C}$, $$(1+z)\prod_{n=1}^{+\infty}(1+z^{2^{n}})= \frac{1}{1-z}$$ I want to understand how to do this kind of exercises, any hint ?","['convergence-divergence', 'sequences-and-series', 'infinite-product', 'analysis', 'complex-analysis']"
622322,Does integration by parts work for partial derivatives?,"Does integration by parts works for partial derivatives? Can we write $$\int_a^b \frac{\partial f(x,y)}{\partial x}g(x,y) dx = f(x,y)g(x,y)|_a^b - \int f(x,y)\frac{\partial g(x,y)}{\partial x}dx$$",['multivariable-calculus']
622323,How find this $\left(\frac{1}{x^2+a^2}\right)^{(n)}$,"Prove that
$$\left(\dfrac{1}{x^2+a^2}\right)^{(n)}=(-1)^{(n)}n!\dfrac{\sin{[(n+1)\cdot \mathrm{arccot}{(x/a)}]}}{a(x^2+a^2)^{(n+1)/2}}$$ my try:
since
$$\dfrac{1}{x^2+a^2}=\dfrac{1}{2ai}\left(\dfrac{1}{x-ai}-\dfrac{1}{x+ai}\right),i=\sqrt{-1}$$
so
$$\left(\dfrac{1}{x^2+a^2}\right)^{(n)}=\dfrac{(-1)^nn!}{2ai}\left(\dfrac{1}{(x-ai)^{n+1}}-\dfrac{1}{(x+ai)^{n+1}}\right)$$
so
let$$x=a\cot{\theta},0<\theta<\pi,$$
then
$$x\pm ai=a(\cos{\theta}\pm i\sin{\theta})/\sin{\theta}$$
so
$$\dfrac{1}{(x\pm ai)^{n+1}}=\dfrac{\sin^{n+1}{\theta}}{a^{n+1}}[\cos{(n+1)\theta}\mp i\sin{(n+1)\theta}]$$
so$$\left(\dfrac{1}{x^2+a^2}\right)^{(n)}=(-1)^{(n)}n!\dfrac{\sin{[(n+1)\cdot \mathrm{arccot}{(x/a)}]}}{a(x^2+a^2)^{(n+1)/2}}$$ Question: Have other methods? Because this is important reslut,so I think this have other methods?  Thank you","['calculus', 'derivatives']"
622343,Proving that a map between quotient groups is injective,"Let $G$ be a group, $H\leq G$, and $N\triangleleft G$ ($H$ is a subgroup, and $N$ is normal subgroup in $G$). Let us define $H\cap N=K$ Let $\phi:H/K\rightarrow G/N$ be a map between these two quotient groups (I proved that $H\cap N$ is a normal subgroup in H, so the quotient group $H/K$ is indeed a group). $\phi$ defined as: for every $aK\in H/K$; we have $\phi(aK)=aN$. I also proved that $\phi$ is well defined, meaning that for every $a,b\in H$, if $aK=bK$, then $\phi(aK)=\phi(bK)$. Now, there's only one last thing I need to prove: $\phi$ is injective, meaning that for every $aK, bK\in H/K$, if $\phi(aK)=\phi(bK)$, then $aK=bK$. So far, this is my work; If $\phi(aK)=\phi(bK)$ then it holds that $aN=bN$, so $a$ and $b$ are in the same coset of $N$, and so $an_0=bn_1$ for some $n_0, n_1\in N$. And that is it, basically, (not much, I know) but I just couldn't think of anything that will lead me to $aK=bK$. Any help would be greatly appreciated.","['group-theory', 'normal-subgroups']"
622376,More precise way of solving inequality,"I need to solve this function:
$$
\lvert x^2-1\rvert\ge 2x-2\\
$$ I solved this equation: For $x<0$, the solution is non existing, here I got negative root, when I tried to solve quadratic function and for $x\ge 0$ I got points $x_1=-1$ and $x_2=3$. My question is: How do I set the solution of equation. Is there any procedure, with wich I can determine is equation valid for $[-1,3]$ or $[-\infty, -1]\lor [3, +\infty]$. I know that I can just set the numbers and see the result, but I just want to now is there any other different way to do this. Thanks.","['inequality', 'functions']"
622424,Bijection of sets - Can't find proper bijection,"Let A be a set such $$A=(1,2]\cup{((3,4)\cap{\mathbb{Q}})}$$ and let B be a set such $$B=(0,1]\cup{(2,3]}\cup{((3,5)\cap{\mathbb{Q}})}$$ I need to find if B is isomorphic to A. I know that a bijection from A to B is needed, but I can't find a proper bijection. It is easy to find a bijection between $(1,2]$ and $(0,1]$ - $f(x)=x-1$, but I can't define a bijection from $(3,4)$ to $(2,5)$. How may I continue? is it even good start defining $f(x)=x-1$ for $x\in{(1,2]}$? Please help, thank you! Edit: After reading the comments, I realized that I need to construct 3 bijections: $f: \ (3,4)\cap{\mathbb{Q}} \rightarrow (3,5)\cap{\mathbb{Q}}$ - I constructed $f(x)=2x-3 \ , \ x\in{\mathbb{Q}}$. $g: \ \left(1,1 \frac{1}{2} \right] \rightarrow \left(0,1 \right]$ - I constructed $g(x)=2(x-1) \ , \ x\in{\mathbb{R}}$. $h: \ \left(1 \frac{1}{2},2 \right] \rightarrow \left(2,3 \right]$ - I constructed $h(x)=2\left(x-\frac{1}{2} \right)$ Finally, I defined $\phi(x)$ to be the proper function (f,g,h) in each range of x. If there any corrections needed, please show them. Thanks again!",['elementary-set-theory']
622444,"Prove that $ x_1+ \dotsb + x_k=n, \frac1{x_1}+ \dotsb + \frac1{x_k}=1$","How would one prove that there exists a positive integer $N$ such that, for every positive integer  $n\gt N$, there exist $k$ (depending on $n$) positive integers $x_1,x_2,\dotsc,x_k$ such that 1) $x_1\lt x_2\lt \dotsc \lt x_k$; 2) $x_1+ x_2+ \dotsb + x_k=n$; 3) $\frac1{x_1}+ \frac1{x_2}+ \dotsb + \frac1{x_k}=1$. I have no clue about it. Could anyone help me? Thanks a lot. P.S.  I encountered it when surfing the Internet.  I only know the problem was  from a math  student who got a perfect score on the IMO.","['elementary-number-theory', 'number-theory']"
622456,Evaluating $\int_0^{\pi/2}\sin(2nx)\sinh(a\sin x)\sin(a\cos x)dx $,"I want to prove that 
$$\int_0^{\pi/2}\sin(2nx)\sinh(a\sin x)\sin(a\cos x)dx =\frac{(-1)^{n+1}\pi a^{2n}}{4(2n)!}$$ any one have an idea","['definite-integrals', 'integration']"
622478,Some questions about a proof,"Proposition: a countable union of countable sets is countable. Proof: Write $X=\bigcup_{i\in\mathbb{N}} A_i$ where $|A_i|\leq|\mathbb{N}|$ and, without loss of generality, $A_i\bigcap A_j=\varnothing$ for all $i\neq j$.
Let $Q_n=\{q\in\mathbb{Q}:\;n-1< q\leq n\}$ for $n\geq 1$. Since $|Q_n|=|\mathbb{N}|$ we can consider an injection $\phi:\;A_i\to Q_i$ for each $i$. Then $\phi: X\to \bigcup_{i\in\mathbb{N}} Q_i=\mathbb{Q}^+$ and hence $|X|\leq |\mathbb{Q}^+|=|\mathbb{N}|\Rightarrow X$ is countable. This is fairly new to me, so I'd like to check that what I'm doing is acceptable: have I used the axiom of choice? is it alright to claim the existence of a $\phi$, as I have? is it acceptable to use $|\mathbb{Q}|=|\mathbb{N}|$ here, or is this a bit circular? (does the traditional 'counting along the diagonals' argument (to show $|\mathbb{Q}|=|\mathbb{N}|$) use the proposition above, in disguise? $-$ a fear of this is the reason I didn't use the argument to prove the main proposition)",['elementary-set-theory']
622490,express rational number as sum of squares of unit fraction,"Let $q$ be a rational number with $0\lt q\leq\dfrac{\pi^2}6-1$. Then show that there exists a set $S\subset \{2,3,4,\dotsc\}$, such that $$q=\sum_{n\in S}\frac1{n^2}$$ I have no clue about it. Could anyone help me? Thanks a lot. p.s.  I  encountered it when surfing the Internet. I only know the problem was from a math student who got perfect score on the IMO","['real-analysis', 'number-theory']"
622497,Show that a function almost everywhere continuous is measurable,"I want to prove that a function $f:\mathbb{R}^n\rightarrow \overline{\mathbb{R}}$ that is continuous everywhere except for a set $E$ of Lebesgue measure zero is a Lebesgue measurable function.
We know that $f$ is not continuous, so there are some open sets ${U_k}$ in $\overline{\mathbb{R}}$ such that $f^{-1}(U_k)$ is not open in $\mathbb{R}^n$.
But $f^{-1}(U_k)\subseteq E$, and so $f^{-1}(U_k)$ is still measurable because it has measure zero. I don't know if this works, because I'm not sure if $E$ contains actually the preimage of those open sets $U_k$.","['measure-theory', 'lebesgue-measure']"
622498,Is this of any real importance to the mathematical scientific community?,"I'm a 31 year old engineer, and I've recently came up with a way to exactly predict the probability of the number of prime numbers between two different integers. For example using my way, the number of prime numbers between $0$ and $100$ is between $0$ and $50$. And it turns out that it is correct, since there are $25$ primes between $0$ and $100$. But is this of any real importance that would lead me to publish a paper? Also my way is purely elementary and so I suspect that mathematicians would even bother to give it a look.","['prime-numbers', 'number-theory']"
622543,Rational distance from an equilateral triangle,"Is there a nice proof for the following fact? In a plane, there does not exist a square such that its vertices are at a rational distance from each vertex of some equilateral triangle. What if we replace the square with a cyclic quadrilateral? Well, it seems the following idea works for the first part of the question: 
It is well known that there is no equilateral triangle in the Cartesian plane with rational coordinates. Let $(x,y)$ be at rational distance from the square with vertices, $(0,0), (0,a), (a,a), (a,0)$. Then it is easily seen that $2a(x-a)$ is rational. Hence if the coordinate system is scaled by a factor of $a$ and the origin is shifted to $(a,a)$, the coordinates become rational.","['geometry', 'euclidean-geometry']"
622573,Almost sure weak convergence of empirical measure,"Do empirical measures converge weakly to the measure almost surely? In particular suppose $\mu$ is a Borel probability measure on $\mathbb R^d$ and that $X_1,X_2,\dots$ are IID drawn from $\mu$. Let $\hat\mu_N=\frac{1}{N}\sum_{i=1}^N\delta_{X_i}$. The Strong Law of Large numbers Says that $\mathbb P(\hat\mu_N(A)\to\mu(A))=1$ for every $A$. Almost sure weak convergence, on the other hand, would be that $\mathbb P(\hat\mu_N(A)\to\mu(A)\text{ for every continuity set $A$})=1$. Is that statement true? Note that this is very different from the stronger statement $\mathbb P(\sup_{\text{continuity set $A$}}\left|{\hat\mu_N(A)-\mu(A)}\right|\to0)=1$, which would require continuity sets to constitute a Glivenco-Cantelli class, something that only happens in $d=1$ as far as I understand. Applying the Hewitt–Savage zero–one law
( https://en.wikipedia.org/wiki/Hewitt%E2%80%93Savage_zero-one_law ) it's clear that $\mathbb P(\hat\mu_N(A)\to\mu(A)\text{ for every continuity set $A$})$ is either $1$ or $0$ and nowhere in between. Can we argue it cannot be $0$? If this is not true in general are there reasonable sufficient conditions on $\mu$ that would guarantee almost sure weak convergence of $\hat\mu_N$? My feeling is that something like compactness of support should do it. Thanks.","['convergence-divergence', 'weak-convergence', 'measure-theory', 'probability-theory', 'probability']"
622589,"In categorical terms, why is there no canonical isomorphism from a finite dimensional vector space to its dual?","I've read in several places that one motivation for category theory was to be able to give precise meaning to statements like, ""finite dimensional vector spaces are canonically isomorphic to their double duals; they are isomorphic to their duals as well, but not canonically."" I've finally sat down to work through this, and - Okay, yes, it is easy to see that the ""canonical isomorphism"" from $V$ to $V^{**}$ is a functor that has a natural isomorphism (in the sense of category theory) to the identity functor. Also, I see that there is no way that the functor $V\mapsto V^*$ could have a natural isomorphism to the identity functor, because it is contravariant whereas the identity functor is covariant. My question amounts to: Is contravariance the whole problem? To elaborate: I was initially disappointed by the realization that the definition of natural isomorphism doesn't apply to a pair of functors one of which is covariant and the other contravariant, because I was hoping that the lack of a canonical isomorphism $V\rightarrow V^*$ would feel more like a theorem as opposed to an artifact of the inapplicability of a definition. Then I tried to create a definition of a natural transformation from a covariant functor $F:\mathscr{A}\rightarrow\mathscr{B}$ to a contravariant functor $G:\mathscr{A}\rightarrow\mathscr{B}$. It seems to me that this definition should be that all objects $A\in\mathscr{A}$ get a morphism $m_A:F(A)\rightarrow G(A)$ such that for all morphisms $f:A\rightarrow A'$ of $\mathscr{A}$, the following diagram (in $\mathscr{B}$) commutes: $$\require{AMScd}\begin{CD}
F(A) @>m_A>> G(A)\\
@VF(f)VV @AAG(f)A\\
F(A') @>>m_{A'}> G(A')
\end{CD}$$ This is much more stringent a demand on the $m_A$ than the typical definition of a natural transformation.  Indeed, it is asking that $m_A=G(f)\circ m_{A'}\circ F(f)$, regardless of how $f$ or $A'$ may vary. Taking $\mathscr{A}=\mathscr{B}=\text{f.d.Vec}_k$, $F$ the identity functor and $G$ the dualizing functor, it is clear that this definition can never be satisfied unless $m_V$ is the zero map for all $V\in\text{f.d.Vec}_k$ (because take $f$ to be the zero map). In particular, it cannot be satisfied if $m_V$ is required to be an isomorphism. Is this the right way to understand (categorically) why there is no natural isomorphism $V\rightarrow V^*$? As an aside, are there any interesting cases of some kind of analog (the above definition or another) of natural transformations from covariant to contravariant functors? Note: I have read a number of math.SE answers regarding why $V^*$ is not naturally isomorphic to $V$. None that I have found are addressed to what I'm asking here, which is about how categories make the question and answer precise. ( This one was closest.) Hence my question here.","['vector-spaces', 'dual-spaces', 'abstract-algebra', 'linear-algebra', 'category-theory']"
622599,Identifying the joint distribution from some values of $t \cdot X$,"Suppose that $S$ is a subset of $\mathbb{R}^n$ and $X, Y$ are $\mathbb{R}^n$ valued RVs.  We already know that $X$ and $Y$ are equidistributed iff $t \cdot X=^d t\cdot Y$ for all $t \in \mathbb{R}^n$.  For which $S$ is it also true that $X$ and $Y$ are equidistributed iff $t \cdot X=^d t\cdot Y$ for all $t \in S$? Since the set of $t$ for which one has $t \cdot X=^d t\cdot Y$ is closed under scalar multiplication and limits (thanks to studying the characteristic function) we have that any $S$ for which $\mathbb{R}S$ is dense in $\mathbb{R}^n$ works.  Is there a characterization?  Particularly, I am interested in the case $n=2$ with $S$ being all 2-vectors of the form $(1, k^{1/2})$ where $k \in \mathbb{N}$.  But if a general characterization is available that is interesting to me too.","['probability-theory', 'linear-algebra', 'probability-distributions', 'random-variables']"
622604,When does the series $\sum_{n=1}^\infty \frac 1{nf(n)}$ converges?,"Let $f : \Bbb{N}\longrightarrow \Bbb{N}$ be a function. a. Suppose $M$ is fixed and for any $n$, $|f^{-1}(\{n\})| < M$. Show that $\sum_{n=1}^\infty \frac 1{nf(n)}$ is convergent. b. Suppose that for any $n$, $f^{-1}(\{n\})$ is finite. Does it mean that the series $\sum_{n=1}^\infty \frac 1{nf(n)}$ must be convergent !?","['sequences-and-series', 'calculus', 'combinatorics']"
622605,convergence of conditional expectations,"Let $\xi$ be a measurable partition on a compact metric space $X$. We can assume that $\xi$ is generated by a countable measurable sets $E_i$, that is, 
$\xi = \vee_{i=1}^{\infty} \{ E_i , X \backslash E_i \}$. Now the conditional expectation $E(\phi | \mathcal{B}(\xi))$ of a bounded measurable function $\phi$ is defined by $\lim_{n \rightarrow \infty } E(\phi | \mathcal{B}_n) $, where $\mathcal{B}_n$ is the finite sigma-algebra generated by sets $E_1,...,E_n$. My question is: if for a uniformly bounded measurable functions we have a pointwise limit $\phi_m \rightarrow \phi$, then $E(\phi_m | \mathcal{B}(\xi))$ converges to $E(\phi | \mathcal{B}(\xi))$ pointwise? This statement is implicitly assumed in the proof of disintegration into conditional measures in http://w3.impa.br/~viana/out/rokhlin.pdf .","['measure-theory', 'conditional-probability']"
622623,"Nowhere dense subsets of $[0,1]$ with positive measure other than fat Cantor sets","This is my first time on the board, so forgive me if I've posted incorrectly. In any case, I think my title is self-explanatory: the only examples I've encountered for nowhere dense subsets of $[0,1]$ with positive measure are fat Cantor sets. Is any one familiar with another example? If it exists, I'd like to find a more-or-less orthogonal example --- that is, I'm not so much interested in examples that are constructed in essentially the same way as a fat Cantor set. Thanks very much. Best,
T","['measure-theory', 'lebesgue-measure']"
622628,Suppose $Df(z)^TDf(z) = \lambda(z)I$. Show $f(z)$ is holomorphic or $\overline{f(z)}$ is holomorphic,"From an old qualifier: Let $z=x+iy$, $f=f(z)=u+iv$. Assume $\Omega$ is an open connected
  domain in $\mathbb{C}$, $f\in C^2(\Omega)$. Denote $$Df = \left[ 
 \begin{matrix} \frac{\partial u}{\partial x} & \frac{\partial
 u}{\partial y} \\ \frac{\partial v}{\partial x} & \frac{\partial
 v}{\partial y} \end{matrix} \right].$$ Suppose for every $z\in
 \Omega$, $$Df(z)^TDf(z) = \lambda(z)I$$ for some $\lambda(z)$, where
  $I$ is the 2x2 identity matrix. Then show that either $f(z)$ is
  holomorphic or $\overline{f(z)}$ is holomorphic. Ideas: We get $$\left( \frac{\partial u}{\partial x} \right)^2 + \left( \frac{\partial v}{\partial x} \right)^2 = \left( \frac{\partial u}{\partial y} \right)^2 + \left( \frac{\partial v}{\partial y} \right)^2 \quad \text{and}\tag{1}$$ $$\frac{\partial u}{\partial x}\frac{\partial u}{\partial y} + \frac{\partial v}{\partial x}\frac{\partial v}{\partial y} =0\tag{2}.$$ What I've been doing is differentiating (1) and (2) with respect to $x$ and $y$ and trying to cancel. One thing I ended up with is $$\Delta u \left(\frac{\partial u}{\partial x} - \frac{\partial u}{\partial y}\right) + \Delta v \left(\frac{\partial v}{\partial x} - \frac{\partial v}{\partial y}\right)=0.$$ But I need to show relations between $\partial u/\partial x$ and $\partial v/\partial y$ etc.","['matrices', 'complex-analysis']"
622630,Finding $y^{\prime \prime}$ of $2x^2+3y^2=4$,"Find $y^{\prime}$ and $y^{\prime \prime}$ of $2x^2+3y^2=4$ $$y^{\prime}=\dfrac{d}{dx}(2x^2)+\dfrac{d}{dx}(3y^2)=\dfrac{d}{dx}(4)$$ $$4x+6yy^{\prime}=0$$
$$y^{\prime}=\dfrac{-2x}{3y}$$ This is how I started finding $y^{\prime\prime}$:
$$y^{\prime\prime}=\dfrac{3y \dfrac{d}{dx}(-2x) - (-2x)\dfrac{d}{dx}(3y)}{(3y^2)}$$ $$\dfrac{3y(-2)-[-2x(3y^{\prime})]}{9y^2}$$
$$\dfrac{-6y-[-6xy^{\prime}]}{9y^2}$$ This isn't right since the correct answer is $\dfrac{-6y^2+4x^2}{9y^3}$ Can you please show how to find $y^{\prime\prime}?$ Thank you.","['calculus', 'derivatives']"
622631,What is the difference between a holomorphic function and a meromorphic function?,"As far as I can tell, if a function is holomorphic on its domain, then it's also meromorphic and vice versa. Can someone tell me what the difference between these two properties are (if any)? A counter-example and an explanation of why it's a counter-example would be nice.",['complex-analysis']
622639,Integral inequality $\int_0^1\log \left(f(x)\right)dx\leq \log\left(\int_0^1f(x)dx\right)$,"How to prove this inequality
$$\int_0^1\log \left(f(x)\right)dx\leq \log\left(\int_0^1f(x)dx\right)$$
for $f>0$.","['inequality', 'integration', 'real-analysis', 'integral-inequality']"
622650,Proving continuity of exp(x),"Well, my teacher went through a method of proving continuity of $\exp(x)$ which I don't like, so I tried to go about it a different way: We have proved the following (which I use) $\exp(x+y) = \exp(x)\exp(y)$ $\exp(0) = 1$ $\exp(x) \geq 1 + x \forall x \in \mathbb{R}$ firstly, I prove it's continuous at $ x = 0$ for $x \leq 0$ $\exp(-x) = \dfrac{1}{\exp(x)}$ $\exp(-x) = 1 + (-x) + \dfrac{(-x)^2}{2!} +... = 1 + $ +ve terms so $\exp(-x) \geq 1$ so $\exp(x) \leq 1$ $\Rightarrow  1 + x \leq \exp(x) \leq 1$ then by sandwich theorem $\lim_{x\to0^-}\exp(x) = 1$ for $x \geq 0 $ $-x \leq 0 \Rightarrow 1 - x \leq \exp(-x) = \dfrac{1}{\exp(x)} \leq 1$ by subbing in (-x) to the above
therefore if $ 0 \leq x < 1 $ $\dfrac{1}{1-x} \geq \exp(x) \geq 1$ therefore $\lim_{x\to0^+}\exp(x) = 1$ therefore $\lim_{x\to 0} \exp(x) = 1$, I have a query at this point, can I consider $0 \leq x < 1$ and conclude $\lim_{x\to0+}\exp(x) = 1$? Moving on, showing it is continuous for any $c \in \mathbb{R}$ assume a sequence $(x_n)$ is a seq. with $x_n \to c$ so $(x_n - c) \to 0 \Rightarrow \exp(x_n -c) \to 1$ (by the composition function theorem, and the step above) $\exp(x_n) = \exp((x_n -c) + c) = \exp(x_n -c)\exp(c) \to \exp(c) $ how can I conclude from here?","['exponential-function', 'continuity', 'analysis']"
622658,Axiom of Choice and Recursion Theorem exercise,"I would like to prove that if  $Χ$ is a non empty set with the property  $(\forall m\in X)[m\cap X\neq\emptyset]$ then there exists a function $f:\mathbb{N}\rightarrow X$ such that $(\forall n)[f(n+1)\in f(n)]$. My attempt to prove this is the following: I may use the Axiom of Choice (or any equivalent form of the Axiom of Choice) so there exists a function $\epsilon: \mathcal{P}(X)\setminus \{\emptyset\}\rightarrow X$ such that $\epsilon(m)\in m$. I can the define a function $h:X\rightarrow X$ such that $h(m)=\epsilon(m\cap X)$. From the recursion theorem there exists a function $f:\mathbb{N}\rightarrow X$ such that
$f(0)=\epsilon(X)$ and $f(n+1)=h(f(n))=\epsilon(f(n)\cap X)\in f(n)\cap X$ so $f(n+1)\in f(n)$.
Is my proof correct? What troubles me a bit is a question following this exercise that says “Is this an intuitively acceptable result?”. I don’t know what to say about that… So overall, is my proof correct? Any comments on that last question? Thank you in advance for your time and effort.","['elementary-set-theory', 'proof-verification']"
622659,Set of non-decreasing function in bijection with R,"I've learnt and understood the demonstration for ""the set of all non-decreasing function is uncountable"" with the diagonalization proof, but how could i demonstrate it is in bijection with R (the set of real numbers) or that the two sets are equipotent.","['elementary-set-theory', 'functions']"
622672,Determining the positioning of rational functions without plotting points,"When graphing rational functions, how do I determine the orientation of a rational function around the asymptotes without plotting points? For example, is it possible to determine which one of these is the correct graph of $\frac{2x}{x^2-1}$ without plugging in points and checking? Basically, how would I check which one of these is correct, once I've found the asymptotes, or is plotting points necessary?","['rational-functions', 'algebra-precalculus', 'graphing-functions']"
622704,Value of $\sum 1/p^p$,"A very simple question, but I can't seem to find anything relating to it : Is there any research, are there any results that have focused on or given insight on $\sum 1/p^p$, ${p \in \mathbb P}$ ? A very basic series, converges extremely fast, its value is around .29. What more can there be said about it ? From what little I know about more advanced number theory, similar sequences (I can think of a few similar ones that I can't find any relevant research or results about) can be very non-trivial to compute or to analyse.","['prime-numbers', 'sequences-and-series']"
622707,When $\cos{n^{\circ}}$ can be expressed in real radicals?,"So, the question is: $\cos{n^{\circ}}$ can be expressed in real radicals iff $3 \mid n$? Is it true? The first part is easy: if $3 \mid n$ we can express it, because $\cos{36^{\circ}}=\cos{\pi\over{5}}=\frac{\sqrt{5}+1}{4}$, thus we can express $\cos{18^{\circ}}$, and now also can $\cos{48^{\circ}}=\cos{(18^{\circ}+30^{\circ})}$. From it follows that we can express $\cos{3^{\circ}}$, because $3={48\over 16}$. Thus we can express $\cos{3k^{\circ}}$ for any $k\in \mathbb N$, using formula of $\cos(nx)=...$.
The main question is: why can't we express it if $n\neq3k$? Or we can?","['radicals', 'trigonometry']"
622738,Discontinuities of the derivative of a differentiable function on closed interval,"I have a question about the corollary to theorem 5.12 in Rudin's Principles of Mathematical Analysis (page 108): Suppose $f$ is a real differentiable function on $[a,b]$ and suppose $f'(a)< \lambda < f'(b)$ then there is a point $x \in (a,b)$ such that $f'(x) = \lambda$ Corollary : If $f$ is differentiable on $[a,b]$ then $f'$ cannot have any simple discontinuities on $[a,b]$ . Can someone help me to show how he uses the result in the ""main theorem"" in the corollary? (There are two cases of simple discontinuities $f(x+) = f(x-) \neq f(x)$ and $f(x +) \neq f(x-)$",['real-analysis']
622762,Formula for $\zeta(3)$ -verification,"By simple manipulating with some series, I have found the following formula for $\zeta(3)$ : $$\zeta(3)=\frac27\sum_{k=0}^{\infty}(-1)^kB_{2k}\frac{\pi^{2k+2}}{(2k+2)!},$$ where $b_k$ are Bernoulli numbers, defined from the equations: $$
B_0=1,\quad B_k=-\frac{1}{k+1}\sum_{i=0}^{k-1}\binom{k+1}{i} B_i,\quad k=1,2,3,\dots
$$ Questions: Is this formula for $\zeta(3)$ correct? Can somebody check it numerically? If it's correct, is this a well-known identity or not? Thanks for your help. Added. By using my identities another interesting formula follows: $$\ln 2=\sum_{k=0}^{\infty}(-1)^kB_{2k}\frac{\pi^{2k}}{(2k+1)!}$$ $$\zeta(3)=\frac45\sum_{k=0}^{\infty}(-1)^kB_{2k}\frac{\pi^{2k+2}}{(2k+3)!}$$","['riemann-zeta', 'analysis']"
622775,A problem V.I. Arnold solved as a primary school student,"According to a 1995 interview that Vladimir I. Arnold gave to the Notices of the AMS , 
his primary school teacher I.V. Morozkin gave in 1949 (when Arnold was 12 years old) to a Soviet classroom, most likely the 6th grade, the following question Two women started at sunrise and each walked at a constant velocity. One went from $A$ to $B$ and the other from $B$ to $A$ .  They met at noon and, continuing with no stop, 
  arrived respectively at $B$ at 4 p.m. and at $A$ at 9 p.m. At what time was the sunrise 
  that day? The question is not how to solve this problem, but rather How to solve this problem using what 12 year old kids know (or knew during the Soviet era). UPDATE. In the same interview, Arnold also said: I spent a whole day thinking on this
  oldie, and the solution (based on what
  is now called scaling arguments,
  dimensional analysis, or toric variety
  theory, depending on your taste) came
  as a revelation. It would be of interest to know how, in Arnold's mind, dimensional analysis and toric varieties are related to this problem.","['algebra-precalculus', 'education', 'math-history', 'popular-math', 'soft-question']"
622790,Absolute continuity of quadratic variation of continuous local martingales,"I am interested to know if there are any simple sufficient conditions on continuous local martingale to have absolutely continuous quadratic variation. In general , we know only that quadratic variation is non-decreasing and continuous for continuous local martingales. I could not find any sufficient conditions for absolute continuity in standard text books like Karatzas and Shreve. Any help/reference is highly appreciated. Thanks","['stochastic-processes', 'martingales', 'probability-theory', 'quadratic-variation', 'reference-request']"
622791,Measure theory qualifying exam question,"While studying old real analysis qualifying exams, I've gotten stuck trying to solve the following problem. Any hints would be appreciated. If $E$ is a Lebesgue measurable subset of $\mathbb R$, show that
$$
  \lim_{t \to 0} \mu( E \cap (E+t) ) = \mu(E).
$$
Here $\mu$ denotes Lebesgue measure.","['measure-theory', 'real-analysis']"
622800,"Size-biased picking, random exchangeable partitions","Let $\Pi$ be a random exchangeable (its law is invariant under action of any permutation with finite support) partition of $\mathbb{N}$. We define mass of a block of partition of $\mathbb{N}$ as $\left| B \right| = \lim_{n\to \infty} \frac{\left| B \cap \{1,2,\ldots , n \} \right|}{n}$.
Lets assume that there are only finite numbers of blocks.
We define $X$ to be mass of the block containing 1 and $Y$ to be mass of randomly choosen block of the random exchangeable partition. We are to prove that $\mathbb{P} \left( X \in dx \right)=\frac{x}{\mathbb{E} Y} \mathbb{P} \left( Y \in dx \right)$","['probability-theory', 'probability']"
622802,Geometric construction of catenary,"Can anyone explain the steps of the Leibniz geometric construction for the catenary curve? Leibniz does a complete job, I'm sure, but I still cannot follow with certainty: It is difficult to follow the progression of steps with only the one geometric figure. It would be awesome to see all the individual steps from blank page to completed diagram for the varying parameters such as (length of chain and width to develop depth, length of chain and depth to develop width, and width and depth to calculate length) . Thanks, Rick Rempe",['geometry']
622810,Prove that any two numbers of the form $2^{2^n}+1$ are coprime to one another.,"Full problem statement: Prove that any two numbers of the follwing sequence are relatively prime: $2 + 1, 2^2+1, 2^4 + 1, 2^8+1, ... 2^{2^n} + 1 $ So far I have tried to use Euclid's algorithm with mathematical induction. I have also proved that 3 is coprime to any number in the sequence, and have tried to use induction (using n = 0, i.e. 3, as the base case, and showing that the same property must be true for 5, 17, etc.)","['recreational-mathematics', 'problem-solving', 'number-theory']"
622817,Differentiable $f$ such that the set of translates of multiples of $f$ is a vector space of dimension two,"How can we derive all of the differentiable functions $f \colon \mathbb{R} \to \mathbb{R}$ such that $V=\{af_b : a,b \in \mathbb{R}\}$ is a vector space of dimension two, where $f_b\colon \mathbb{R} \to \mathbb{R}$ is defined as the translate $f_b(x)=f(x+b)$? An example is $f=\sin$. The set $V$ contains the linearly independent functions $\sin$ and $\cos$ (since $\cos(x)=\sin(x+\frac{\pi}{2})$). By elementary trigonometry we have $c\sin(x+\phi) = s\sin x + t\cos x$ for any $c, \phi \in \mathbb{R}$ and some $s,t \in \mathbb{R}$, so it follows that $V$ is a vector space of dimension two spanned by $\sin$ and $\cos$.","['functional-analysis', 'functions']"
